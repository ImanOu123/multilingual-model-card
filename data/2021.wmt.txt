{'en': 'GTCOM Neural Machine Translation Systems for WMT21', 'ar': 'أنظمة الترجمة الآلية العصبية GTCOM لـ WMT21', 'fr': 'Systèmes de traduction automatique neuronale GTCOM pour WMT21', 'es': 'Sistemas de traducción automática neuronal GTCOM para WMT21', 'pt': 'Sistemas de tradução automática neural GTCOM para WMT21', 'ja': 'WMT 21用GTCOM神経機械翻訳システム', 'zh': '以 WMT21 GTCOM 神经机器翻译统', 'hi': 'WMT21 के लिए GTCOM तंत्रिका मशीन अनुवाद सिस्टम', 'ru': 'Нейронные системы машинного перевода GTCOM для WMT21', 'ga': 'Córais Néar-Aistriúcháin Meaisín GTCOM do WMT21', 'el': 'Νευρικά συστήματα μηχανικής μετάφρασης GTCOM για WMT21', 'hu': 'GTCOM Neural Machine Translation Systems for WMT21', 'it': 'GTCOM Neural Machine Translation Systems per WMT21', 'lt': 'GTCOM neurologinių mašinų vertimo sistemos WMT21', 'kk': 'WMT21 үшін GTCOM нейрондық машинаны аудару жүйелеріName', 'mk': 'GTCOM неврални машински транслативни системи за WMT21', 'ms': 'Sistem Terjemahan Mesin Neural GTCOM untuk WMT21', 'mt': 'Sistemi ta’ Traduzzjoni ta’ Magni Newrali GTCOM għal WMT21', 'ka': 'WMT21Name', 'mn': 'WMT21 болон GTCOM мэдрэлийн машин хөгжүүлэх системүүд', 'no': 'GTCOM Neural Machine Translation Systems for WMT21', 'pl': 'Systemy tłumaczenia maszynowego GTCOM dla WMT21', 'ro': 'GTCOM Neural Machine Translation Systems pentru WMT21', 'so': 'GTCOM Neural machine Translation Systems for WMT21', 'ml': 'WMT21- നുള്ള ജിടിക്കോം നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷ സിസ്റ്റമുകള്\u200d', 'sr': 'GTCOM Neural Machine Translation Systems for WMT21', 'si': 'Comment', 'ur': 'Name', 'ta': 'WMT21 க்கான GTCOM புதிய இயந்திரம் மொழிபெயர்ப்பு அமைப்புகள்', 'sv': 'GTCOM Neural Machine Translation System för WMT21', 'uz': 'WMT21 uchun tarjima tizimi', 'vi': 'Chương trình dịch về máy thần kinh GTCOM cho WM21', 'bg': 'GTCOM неврални системи за машинен превод за WMT21', 'nl': 'GTCOM Neural Machine Translation Systemen voor WMT21', 'da': 'GTCOM Neural Machine Translation Systems til WMT21', 'hr': 'GTCOM Neural Machine Translation Systems for WMT21', 'de': 'GTCOM Neural Machine Translation Systeme für WMT21', 'id': 'Sistem Translation Mesin Neural GTCOM untuk WMT21', 'ko': 'WMT21의 GTCOM 신경 기계 번역 시스템', 'fa': 'سیستم ترجمه ماشین عصبی GTCOM برای WMT21', 'sw': 'Mfumo wa Tafsiri wa Mashine ya Kifaransa wa GTCOM kwa WMT21', 'af': 'Name', 'tr': 'WMT21 üçin GTCOM Neural Mazmunlar terjime sistemleri', 'sq': 'Sistemet e Translacionit të Makinës Neurale GTCOM për WMT21', 'am': 'ትርጉም', 'hy': 'GTCOM Neural Machine Translation Systems for WMT21', 'bn': 'WMT21 এর জন্য GTCOM নিউরাল মেশিন অনুবাদ সিস্টেম', 'az': 'WMT21 üçün GTCOM Nöral Makina Çeviri Sistemləri', 'ca': 'Sistemes de traducció de màquines neuronals GTCOM per a WMT21', 'cs': 'GTCOM Neurální strojové překlady systémů pro WMT21', 'bs': 'GTCOM Neural Machine Translation Systems for WMT21', 'et': 'GTCOM neuraalsed masintõlke süsteemid WMT21 jaoks', 'fi': 'GTCOM Neural Machine Translation Systems for WMT21', 'jv': 'GTTOm Neral Majin Terjamahan Sistem kanggo WW1', 'ha': 'Translate Systems for WMT21', 'he': 'GTCOM Neural Machine Translation Systems for WMT21', 'sk': 'GTCOM nevralni strojni prevajalni sistemi za WMT21', 'bo': 'GTCOM Neural Machine Translation Systems for WMT21'}
{'en': 'This paper describes the Global Tone Communication Co., Ltd.’s submission of the WMT21 shared news translation task. We participate in six directions : ', 'ar': 'تصف هذه الورقة تقديم شركة Global Tone Communication Co.، Ltd. لمهمة ترجمة الأخبار المشتركة WMT21. نشارك في ستة اتجاهات: الإنجليزية من / إلى الهوسا ، والهندية إلى / من البنغالية والزولو إلى / من Xhosa. أنظمتنا المقدمة غير مقيدة وتركز على لغة الترجمة متعددة اللغات والترجمة العكسية والترجمة إلى الأمام. نطبق أيضًا القواعد ونموذج اللغة لتصفية الجمل أحادية اللغة والمتوازية والجمل التركيبية.', 'pt': 'Este documento descreve a submissão da Global Tone Communication Co., Ltd. da tarefa de tradução de notícias compartilhadas do WMT21. Participamos em seis direções: Inglês de/para Hausa, Hindi para/de Bengali e Zulu de/para Xhosa. Nossos sistemas enviados são irrestritos e se concentram na tradução multilíngue odel, backtranslation e forward-translation. Também aplicamos regras e modelo de linguagem para filtrar frases monolíngues, paralelas e frases sintéticas.', 'fr': 'Cet article décrit le projet Global Tone Communication Co., Ltd. s soumission de la tâche de traduction de nouvelles partagées WMT21. Nous participons dans six directions\xa0: anglais vers/depuis le haoussa, hindi vers/depuis le bengali et zoulou vers/depuis le xhosa. Nos systèmes soumis ne sont pas limités et se concentrent sur le modèle de traduction multilingue, la rétro-traduction et la traduction avant. Nous appliquons également des règles et un modèle linguistique pour filtrer les phrases monolingues, parallèles et synthétiques.', 'es': "Este documento describe Global Tone Communication Co., Ltd. ' de la tarea de traducción de noticias compartidas del WMT21. Participamos en seis direcciones: inglés hacia/desde hausa, hindi hacia/desde bengalí y zulú hacia/desde xhosa. Nuestros sistemas presentados no tienen restricciones y se centran en el modelo de traducción multilingüe, la retrotraducción y la traducción anticipada. También aplicamos reglas y modelos de lenguaje para filtrar oraciones monolingües, paralelas y oraciones sintéticas.", 'ja': '本稿では、グローバルトーンコミュニケーションズ株式会社によるWMT 21共有ニュース翻訳タスクの提出について述べる。ハウサ語、ヒンディー語、ベンガル語、ズールー語、ショサ語の6つの言語に参加しています。当社の提出されたシステムは制約されておらず、多言語翻訳に焦点を当てています。odel、バックトランスレーション、フォワードトランスレーション。また、ルールと言語モデルを適用して、単語、並列文、合成文をフィルタリングします。', 'zh': '本文全球音响通信有限公司提交WMT21共新闻译。 余参六方:英语往返豪萨语,印地语往返孟加拉语与祖鲁语往返科萨语。 所提统不受约束,专注多言译、反译、转发译。 又以规矩、语言模单语、平行句句为句。', 'hi': 'यह पेपर ग्लोबल टोन कम्युनिकेशन कं, लिमिटेड के WMT21 साझा समाचार अनुवाद कार्य के प्रस्तुतीकरण का वर्णन करता है। हम छह दिशाओं में भाग लेते हैं: हौसा से / से अंग्रेजी, बंगाली से / से हिंदी और ज़ुलु से / हमारे प्रस्तुत प्रणालियों अप्रतिबंधित हैं और बहुभाषी अनुवाद odel, backtranslation और आगे अनुवाद पर ध्यान केंद्रित कर रहे हैं. हम मोनोलिंगुअल, समानांतर वाक्यों और सिंथेटिक वाक्यों को फ़िल्टर करने के लिए नियमों और भाषा मॉडल को भी लागू करते हैं।', 'ru': 'В настоящем документе описывается, как компания Global Tone Communication Co., Ltd. представила задание по совместному переводу новостей WMT21. Мы участвуем в шести направлениях: английский в/из Хауса, хинди в/из Бенгали и зулу в/из Хосы. Наши представленные системы не ограничены и сосредоточены на многоязычном переводе, обратном переводе и прямом переводе. Мы также применяем правила и языковую модель для фильтрации одноязычных, параллельных предложений и синтетических предложений.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht Global Tone Communication Co., Ltd. ar thasc aistriúcháin nuachta roinnte WMT21. Glacaimid páirt i sé threo: Béarla go dtí/ó Hausa, Hiondúis go/ó Bheangáilis agus Súlúis go/ó Xhosa. Tá na córais a sheolaimid isteach gan srian agus dírítear ar odel an aistriúcháin ilteangach, ar aisaistriúchán agus ar réamhaistriúchán. Cuirimid rialacha agus múnla teanga i bhfeidhm freisin chun abairtí aonteangacha, comhthreomhara agus abairtí sintéiseacha a scagadh.', 'ka': 'ეს დოლობალური ტონის კომუნიკაციის კომუნიკაციის კომუნიკაციის შეტყობინება WMT21-ს გაყობინება. ჩვენ შვიდი დანაწილეობით: ანგლისური დან/დან ჰოსადან, ჰინდის დან/ბენდალიდან და ზულუდან Xhosa-დან. ჩვენი შეტყობინებული სისტემები არიან დაკონსტირებულია და ფონსტირებულია მრავალენგური შეტყობინებული მოდელზე, შემდეგ შეტყობინებული და წინასწორებ ჩვენ მონოლენგიური, პარალელური სიტყვები და სინტეტიური სიტყვები ფილტრირებისთვის წესები და ენათის მოდელის გამოყენება.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή της κοινής εργασίας μετάφρασης ειδήσεων από την Global Tone Communication Co., Ltd. Συμμετέχουμε σε έξι κατευθύνσεις: Αγγλικά προς/από τη Χάουζα, Χίντι προς/από τη Βεγγάλη και Ζουλού προς/από τη Χώσα. Τα υποβαλλόμενα συστήματα μας είναι απεριόριστα και επικεντρώνονται στο πολύγλωσσο μοντέλο μετάφρασης, την οπισθοχώρηση και την προώθηση της μετάφρασης. Εφαρμόζουμε επίσης κανόνες και γλωσσικό μοντέλο για να φιλτράρουμε μονογλωσσικές, παράλληλες προτάσεις και συνθετικές προτάσεις.', 'hu': 'Ez a tanulmány bemutatja a Global Tone Communication Co., Ltd. által benyújtott WMT21 megosztott hírfordítási feladat benyújtását. Hat irányban veszünk részt: angol Hausa, hindi Bengáli és zulu Xhosa. Beküldött rendszereink korlátlanok, és a többnyelvű fordítási modellekre, visszafordításra és forward-fordításra összpontosítanak. Szabályokat és nyelvi modellt is alkalmazunk az egynyelvű, párhuzamos mondatok és szintetikus mondatok szűrésére.', 'it': "Questo articolo descrive l'invio da parte della Global Tone Communication Co., Ltd del compito condiviso di traduzione delle notizie WMT21. Partecipiamo in sei direzioni: Inglese a/da Hausa, Hindi a/da Bengali e Zulu a/da Xhosa. I nostri sistemi inviati sono senza vincoli e si concentrano su modelli di traduzione multilingue, backtranslation e forward-translation. Applichiamo anche regole e modelli linguistici per filtrare frasi monolingue, parallele e sintetiche.", 'lt': "This paper describes the Global Tone Communication Co., Ltd.'s submission of the WMT21 shared news translation task.  Mes dalyvaujame šešiose kryptimis: anglų kalba į Hausą (iš Hausos), Hindi į Bengalį (iš Bengalės) ir Zulį į Xhosą (iš Xhosos). Mūsų pateiktos sistemos yra neribotos ir daugiausia dėmesio skiriama daugiakalbiams vertimo odeliams, vertimui atgal ir vertimui į priekį. Mes taip pat taikome taisykles ir kalbos model į vienakalbiams, lygiagretiems sakiniams ir sintetiniams sakiniams filtruoti.", 'mk': 'Овој весник ја опишува поднесувањето на Global Tone Communication Co., Ltd. на задачата на заедничкиот превод на вести на WMT21. Ние учествуваме во шест насоки: англиски до/од Хауса, хинди до/од Бенгали и Зулу до/од Џоза. Нашите поднесени системи се неограничени и се фокусираат на мултијазички превод odel, backtranslation и forward- превод. We also apply rules and language model to filter monolingual, parallel sentences and synthetic sentences.', 'kk': 'Бұл қағаз WMT21 жаңалық аудару тапсырмасының Global Tone Communication Co., Ltd дегенді таңдайды. Алты бағыттарда қатынасыз: ағылшын тілінен Хауса, Хинди тілінен, Бенгали және Зулу тілінен Xhosa тілінен. Біздің жүйелеріміз бірнеше тілді аудару моделі, қадамдастыру және алғашқы аудару үшін орнатылмайды. Мұндай-ақ біз бір тіл үлгісін, параллелі сөздерді және синтетикалық сөздерді сүзгілеу үшін ережелер мен тіл үлгісін қолданамыз.', 'ms': 'Kertas ini menggambarkan penghantaran Global Tone Communication Co., Ltd tugas terjemahan berita berkongsi WMT21. Kami berpartisipasi dalam enam arah: bahasa Inggeris ke/dari Hausa, Hindi ke/dari Bengali dan Zulu ke/dari Xhosa. Sistem yang dihantar kita tidak terhalang dan fokus pada odel terjemahan berbilang bahasa, backtranslation dan forward-translation. Kami juga melaksanakan peraturan dan model bahasa untuk menapis kalimat monobahasa, selari dan kalimat sintetik.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni tal-Global Tone Communication Co., Ltd tal-kompitu tat-traduzzjoni tal-aħbarijiet kondiviża tad-WMT21. Aħna qed jipparteċipaw f’sitt direzzjonijiet: Ingliż għal/minn Hausa, Indjan għal/mill-Bengali u Zulu għal/minn Xhosa. Is-sistemi ppreżentati tagħna mhumiex ristretti u jiffokaw fuq mudell ta’ traduzzjoni multilingwi, traduzzjoni b’lura u traduzzjoni bil-quddiem. Aħna napplikaw ukoll regoli u mudell lingwistiku biex nifiltraw sentenzi monolingwi, paralleli u sentenzi sintetiċi.', 'mn': 'Энэ цаас WMT21 хуваалцаагүй мэдээний хөрөнгө оруулах ажлыг Global Tone Communication Co., Ltd-ын тайлбарлаж байна. Бид зургаан захиралд оролцож байна: Англи хэл, Хауса, Хинди, Бенгали, Зулу хоос, Хоса хоос. Our submitted systems are unconstrained and focus on multilingual translation odel, backtranslation and forward-translation. Бид мөн нэг хэл, параллел өгүүлбэрийг, синтетик өгүүлбэрийг шинжилэхэд хууль, хэл загварыг ашигладаг.', 'no': 'Denne papiret beskriver Global Tone Communication Co., Ltd. s øket til WMT21 delt nyhetskomsettingsoppgåva. Vi deltar i seks retningar: engelsk til/frå Hausa, Hindi til/frå Bengali og Zulu til/frå Xhosa. Våre sendte systema er ikkje installert og fokuserer på fleirspråksomsetjingskodul, tryggleikskodulering og framover- omsetjing. Vi bruker også reglar og språk-modell for å filtra monospråk, parallelle setningar og syntetiske setningar.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie przez Global Tone Communication Co., Ltd. wspólnego zadania tłumaczenia wiadomości WMT21. Uczestniczymy w sześciu kierunkach: angielski do/z Hausa, hindi do/z Bengali i Zulu do/z Xhosa. Nasze systemy są nieograniczone i koncentrują się na wielojęzycznym modelu tłumaczeń, backtranslation i forward-translation. Stosujemy również reguły i model językowy do filtrowania zdań jednojęzycznych, równoległych i syntetycznych.', 'sr': 'Ovaj papir opisuje podatak Global Tone Communication Co., Ltd. podataka WMT21 zajedničkog zadatka za prevod vesti. Učestvujemo u šest uputa: engleski do/iz Hause, hindi do/iz Bengalija i Zulu do/iz Xhose. Naši podignuti sistemi su neostavljeni i fokusirani na multijezički prevodni odel, backtranslation i forward-translation. Takođe primjenjujemo pravila i jezički model da filtriramo monojezičke, paralelne rečenice i sintetičke rečenice.', 'si': 'මේ පැත්තේ විශේෂ ටෝන් සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බ අපි ඉංග්\u200dරීසියාව හෝසා, හින්දි වල බෙන්ගාලි වලින් සුලූ වලින්/Xhosa වලින්. අපේ පිළිබඳු පද්ධතියක් නොස්ථාපනය කරලා තියෙන්නේ සහ ගොඩක් භාෂාවික වාර්තාව, පසුපසුපසුපසුප අපි නීති සහ භාෂාව මඩේල් එක භාෂාවක්, සමාන්\u200dය වාක්ය සහ සංකේතික වාක්ය සිද්ධා කරන්න.', 'so': "Warqadan wuxuu ku qoran yahay Global Tone Communication s Co., Ltd's submission of the WMT21 mission shared news translation. Lix dhinac ayaannu ka qeybqaadanaynaa: Ingiriis-ka-Hausa, Hindi-ka-Bengali iyo Zulu-ka-Xhosa. nidaamkayaga la soo dhiibay waa aan la burburin, waxaana ku kalsoonaan turjumista luuqadaha kala duduwan odel, backtranslation and forward-translation. Sidoo kale waxaynu u codsanaynaa qaababka sharciga iyo luqada si aan ugu baaraandegiso xarumaha luuqada, isbardhigyada iyo imtixaanka isku mid ah.", 'ml': 'ഈ പത്രത്തില്\u200d ഗ്ലോബല്\u200d ടോണ്\u200d കമ്മിക്കേഷന്\u200d കോ വിവരിച്ചിരിക്കുന്നു. WMT21 വിവരങ്ങള്\u200d പങ്കുചേര്\u200dത്ത വാര്\u200dത്ത പരിഭാ ആറു ദിശയില്\u200d ഞങ്ങള്\u200d പങ്കുചേര്\u200dക്കുന്നു; ഇംഗ്ലീഷിലേക്ക്/ഹൂസായിലേക്ക്/ഹിന്ദിയിലേക്ക്/ബാങ്കാലിയിലേക ഞങ്ങളുടെ സമ്മതിച്ച സിസ്റ്റങ്ങള്\u200d അസ്ഥാപിക്കപ്പെട്ടിരിക്കുന്നു. പല ഭാഷകങ്ങളുടെ പരിഭാഷകങ്ങളുടെ മേല്\u200d ശ് ഞങ്ങള്\u200d നിയമങ്ങളും ഭാഷ മോഡലും പ്രയോഗിക്കുന്നു, മോണോളില്\u200d ഭാഷ, പാരാളില്\u200d വാക്കുകളും സങ്കീര്\u200dത്തിക വാക്കുകളും', 'sv': 'Denna uppsats beskriver Global Tone Communication Co., Ltd:s inlﾃ､mnande av WMT21 delade nyhetsﾃｶversﾃ､ttningsuppgifter. Vi deltar i sex riktningar: engelska till/frﾃ･n Hausa, hindi till/frﾃ･n Bengali och zulu till/frﾃ･n Xhosa. Vﾃ･ra inlﾃ､mnade system ﾃ､r obegrﾃ､nsade och fokuserar pﾃ･ flersprﾃ･kig ﾃｶversﾃ､ttningsmodel, backtranslation och framﾃ･triktad ﾃｶversﾃ､ttning. Vi tillﾃ､mpar ﾃ､ven regler och sprﾃ･kmodell fﾃｶr att filtrera ensprﾃ･kiga, parallella meningar och syntetiska meningar.', 'ta': "This paper describes the Global Tone Communication Co, Ltd' s submission of the WMT21 shared news translation task. ஆறு திசைகளில் நாம் பங்கெடுக்கிறோம்: ஆங்கிலத்திலிருந்து ஹுusa, ஹின்டியிலிருந்து பெங்காலிலிருந்து ஜுல எங்கள் ஒப்புக்கொடுக்கப்பட்ட அமைப்புகள் நிறுவப்பட்டுள்ளன மற்றும் பல மொழிமாற்று மொழிபெயர்ப்பு odel, பின்ப நாம் விதிகளையும் மொழி மாதிரியையும் பயன்படுத்துகிறோம் மொத்த மாதிரிகளையும், ஒத்திசைப்பட்ட வாக்கியங்கள", 'ro': 'Această lucrare descrie transmiterea de către Global Tone Communication Co., Ltd a sarcinii de traducere a știrilor partajate WMT21. Participăm în șase direcții: engleză spre/de la Hausa, hindi spre/de la Bengali și zulu spre/de la Xhosa. Sistemele noastre trimise sunt fără constrângeri și se concentrează pe modelul de traducere multilingvă, backtranslation și forward-translation. De asemenea, aplicăm reguli și modelul lingvistic pentru a filtra propoziții monolingve, paralele și propoziții sintetice.', 'ur': "This paper describes the Global Tone Communication Co., Ltd.'s submission of the WMT21 shared news translation task. ہم چھ طریقے میں شرکت کرتے ہیں: انگلیسی سے ہاوسا سے، ہندی سے بنگالی اور زولوں سے Xhosa سے۔ ہمارے تحویل دیے ہوئے سیستموں کو بغیر محسوس کیا گیا ہے اور بہت زبان ترجمہ اوڈل، پشت ترجمہ اور آگے ترجمہ پر تمرکز کیا گیا ہے۔ ہم نے بھی ایک زبان کی، parallel sentences اور synthetic sentences فیلٹر کرنے کے لئے قانون اور زبان کی مدل لازم کیا ہے.", 'vi': 'Tờ giấy này mô tả công việc dịch chuyển tin tức truyền thông Toàn cầu Tone Company. Chúng tôi tham gia sáu hướng: tiếng Anh đến/từ Hausa, tiếng Hindi đến/từ Bengali và Zulu đến/từ Xhosa. Những hệ thống được gửi đến không được đào tạo và tập trung vào kĩ năng dịch chuyển đa dạng. Chúng tôi cũng áp dụng quy tắc và mô hình ngôn ngữ để lọc câu độc ngôn, song song và câu tổng hợp.', 'uz': "Ushbu hujjat WMT21 bilan bogʻliq xabar tarjima qilingan vazifasi Global Tone Communication s Co. Ltd' ning tarjima qilishi mumkin. Biz sakkizcha birga ega bo'lgan: Inglizchaga/Hausadan, Hindidan/Bengaldan va Zulu dan/Xhosadan. @ info: whatsthis We also apply rules and language model to filter monolingual, parallel sentences and synthetic sentences.", 'bg': 'Настоящата статия описва представянето на споделената задача за превод на новини от Глобал Тон Комуникация Ко ООД. Участваме в шест направления: английски до/от Хауса, хинди до/от Бенгали и зулу до/от Кхоса. Нашите подадени системи са неограничени и се фокусират върху многоезичен превод модел, обратен превод и предварителен превод. Също така прилагаме правила и езиков модел за филтриране на едноезични, паралелни изречения и синтетични изречения.', 'da': "Denne artikel beskriver Global Tone Communication Co., Ltd's indsendelse af WMT21 delte nyhedsoversættelsesopgave. Vi deltager i seks retninger: Engelsk til/fra Hausa, Hindi til/fra Bengali og Zulu til/fra Xhosa. Vores indsendte systemer er ubegrænsede og fokuserer på flersproget oversættelsesmodel, backtranslation og fremadrettet oversættelse. Vi anvender også regler og sprogmodel til at filtrere ensprogede, parallelle sætninger og syntetiske sætninger.", 'nl': 'Dit document beschrijft de indiening van de WMT21 gedeelde vertaaltaak door Global Tone Communication Co., Ltd. We doen mee in zes richtingen: Engels naar/van Hausa, Hindi naar/van Bengaals en Zulu naar/van Xhosa. Onze ingediende systemen zijn onbeperkt en richten zich op meertalige vertaalmodellen, backtranslation en forward-translation. We passen ook regels en taalmodel toe om eentalige, parallelle zinnen en synthetische zinnen te filteren.', 'hr': 'Ovaj papir opisuje podnošenje zadatka WMT21 zajedničkog prevoda vijesti Global Tone Communication Co., Ltd. Učestvujemo u šest smjera: engleski do/iz Hause, Hindi do/iz Bengalija i Zulu do/iz Xhose. Naši podignuti sustavi su neostavljeni i fokusirani na multijezički prevodni odel, backtranslation i forward-translation. Također primjenjujemo pravila i jezički model da filtriramo monojezičke, paralelne rečenice i sintetičke rečenice.', 'de': 'Dieses Papier beschreibt die Einreichung der gemeinsamen Nachrichtenﾃｼbersetzungsaufgabe WMT21 durch die Global Tone Communication Co., Ltd. Wir nehmen in sechs Richtungen teil: Englisch nach/von Hausa, Hindi nach/von Bengali und Zulu nach/von Xhosa. Unsere eingereichten Systeme sind uneingeschrﾃ､nkt und konzentrieren sich auf mehrsprachige ﾃ彙ersetzungsmodelle, Backtranslation und Forward-Translation. Wir wenden auch Regeln und Sprachmodell an, um einsprachige, parallele Sﾃ､tze und synthetische Sﾃ､tze zu filtern.', 'id': 'Kertas ini menjelaskan pengiriman Global Tone Communication Co., Ltd dari tugas terjemahan berita berbagi WMT21. Kami berpartisipasi dalam enam arah: bahasa Inggris ke/dari Hausa, Hindi ke/dari Bengali dan Zulu ke/dari Xhosa. Sistem yang kami kirim tidak terbatas dan fokus pada odel terjemahan multibahasa, backtranslation dan forward-translation. Kami juga menerapkan aturan dan model bahasa untuk filter kalimat monobahasa, paralel dan kalimat sintetis.', 'ko': '본고는 유니버설통미디어유한공사가 제출한 WMT21 공유 뉴스 번역 임무를 묘사한다.우리는 영어부터 호사어까지 / 호사어부터 인디언에서 방글라데시어까지 / 방글라데시어와 줄루어에서 코사어까지 / 코사어까지 여섯 가지 방향에 참여한다.우리가 제출한 시스템은 제한을 받지 않고 다국어 번역 모델, 역방향 번역과 정방향 번역에 전념한다.우리는 또한 규칙과 언어 모델을 응용하여 단문구, 평행문, 합성문을 필터한다.', 'fa': 'این کاغذ توصیف داده شده است که مسئول ترجمه\u200cهای خبرهای مشترک WMT21، Global Tone Communication Co., Ltd. ما در شش مسیر شرکت می کنیم: انگلیسی تا/از هاوسا، هندی تا/از بنگالی و زولو تا/از Xhosa. سیستم\u200cهای تحویل داده شده\u200cایم بی\u200cمحدودیت و تمرکز بر مدل\u200cهای ترجمه\u200cهای زیادی زبان، ترجمه\u200cهای پشتی و ترجمه\u200cهای پیش\u200cفرستاده\u200cاند. ما همچنین قانون و مدل زبان را برای فیلتر کردن جمله\u200cهای یک زبان، پارالی و جمله\u200cهای سنتریتی استفاده می\u200cکنیم.', 'sw': 'Gazeti hili linaelezea Co la Mawasiliano ya Tone ya Dunia, ujumbe wa Ltd wa kazi ya tafsiri ya habari iliyochapishwa na WMT21. Tunashiriki kwenye maelekezo sita: Kiingereza hadi/kutoka Hausa, Hindi hadi/kutoka Bengali na Zulu hadi/kutoka Xhosa. Mifumo yetu iliyoandaliwa hazijatikani na kuhusiana na utafsiri wa lugha mbalimbali, tafsiri za nyuma na tafsiri za mbele. Pia tunatumia kanuni na mtindo wa lugha kuchuja hukumu za lugha za kimapenzi, zilizofanana na hukumu za pamoja.', 'tr': "Bu kağıt WMT21'nin WMT21'nin paylaşyk haberler terjime görevini tanaýar. Biz alty yönünde: Iňlisçe Hausa, Hindistan, Bengali we Zulu we Xhosadan /görä goşulýarys. Biziň gönderilen sistemlerimiz baglanmaýar we köp dilli terjime modi, arka terjime we öňki terjime etmegiňe odaklanmýar. Biz hem monodil, parallel sözleri we sentetik sözleri süzgürmek üçin kurallar we dil nusgasyny uygulaýarys.", 'af': 'Hierdie papier beskrywe die Global Tone Communication Co., Ltd. se onderskrywing van die WMT21 deel nuusvertaling taak. Ons deel in ses rigtings: Engels tot/van Hausa, Hindi tot/van Bengali en Zulu tot/van Xhosa. Ons voorgestuurde stelsels is ongenstreekte en fokus op veelvuldige vertalingsodel, terugvertaling en vorentoe-vertaling. Ons het ook reëls en taal model aanwend om monolinglike, parallele setnings en sintetiese setnings te filter.', 'sq': 'Ky dokument përshkruan paraqitjen e Global Tone Communication Co., Ltd. të detyrës s ë përkthimit të lajmeve të përbashkëta WMT21. Ne marrim pjesë në gjashtë drejtime: anglisht për/nga Hausa, Hindi për/nga Bengali dhe Zulu për/nga Xhosa. Sistemet tona të paraqitura janë pa kufizime dhe përqëndrohen në përkthimin shumëgjuhës odel, përkthimin mbrapsht dhe përkthimin përpara. We also apply rules and language model to filter monolingual, parallel sentences and synthetic sentences.', 'am': 'ይህ ገጽ የዓለምአቀፍ Tone Communication Co፣ Ltd የWMT21 የዜና ትርጉም አድራጊ ጥያቄ ያሳየዋል፡፡ በስድስት መንገዶች ውስጥ እንጋጠማለን፤ እንግሊዘኛ ወደሀሱስ፣ Hindi ወደ ባንጋሊና ከዙሉ ወደ Xhosa እናጋራለን፡፡ የኢንተርኔት ስርዓታችን የቋንቋ ቋንቋዎች፣ backtranslation እና forward-translation. እና ሕግ እና ቋንቋ ሞዴል እናስቀምጣለን፡፡', 'hy': 'Այս աշխատանքը նկարագրում է Global Tune Connection Co., LT-ի ներկայացումը World MT21-ի ընդհանուր նորությունների թարգմանման խնդրի մասին: Մենք մասնակցում ենք վեց ուղղություններում. անգլերեն Հուզայից, հինդից Բենգալիից և Զուլուց Ջոզայից: Մեր ներկայացված համակարգերը անսահմանափակ են և կենտրոնանում են բազլեզու թարգմանման ոդելի, ետնաթարգմանման և առաջնաթարգմանման վրա: Մենք նաև կիրառում ենք կանոնները և լեզվի մոդելը միալեզվով, զուգահեռ նախադասությունների և սինթետիկ նախադասությունների ֆիլտրելու համար:', 'az': "Bu kańüńĪt WMT21 paylaŇüńĪlmńĪŇü x…ôb…ôr qurńüulamasńĪ iŇüini Global Tone Communication Co., Ltd'un t…ôblińü edir. Biz altńĪ t…ôr…ôfl…ôrd…ô: ńįngilizce - Hausa, Hindistan - Bengali v…ô Zulu - Xhosa t…ôr…ôfl…ôr…ô/t…ôr…ôfl…ôr…ô katńĪlńĪrńĪq. Bizim g√∂nd…ôrilmiŇü sisteml…ôrimiz √ßoxlu dil √ßevirim odeli, arka √ßevirim v…ô √∂n √ßevirim √ľz…ôrind…ô t…ôsirl…ônmir. Biz h…ôm√ßinin monodil, paralel s√∂zl…ôr v…ô sintetik s√∂zl…ôri filtrl…ôm…ôk √ľ√ß√ľn h√∂kml…ôr v…ô dil modeli uygulayńĪq.", 'bn': 'এই পত্রিকাটি গ্লোবাল টোন যোগাযোগ কোর ব্যাখ্যা করেছে, এলটিডির উইএমটি২১ সংবাদ অনুবাদ কাজ শেয়ার করা হয়েছে। We participate in six directions: English to/from Hausa, Hindi to/from Bengali and Zulu to/from Xhosa.  আমাদের প্রতিষ্ঠান সিস্টেম বাতিল করা হয়েছে এবং বহুভাষায় অনুবাদের কোডেল, ব্যাক-অনুবাদ এবং সামনে অনুবাদের উপর মন আমরা একই সাথে নিয়ম এবং ভাষার মডেল প্রয়োগ করি মোনোলিভাল, প্যারালেলের শাস্তি এবং সিন্টিটিক বাক্য পরিশোধ করতে।', 'bs': 'Ovaj papir opisuje podatak Global Tone Communication Co., Ltd. podataka WMT21 zajedničkog zadatka za prevod vijesti. Učestvujemo u šest uputa: engleski do/iz Hause, hindi do/iz Bengalija i Zulu do/iz Xhose. Naši podignuti sistemi su neostavljeni i fokusirani na multijezički prevodni odel, backtranslation i forward-translation. Također primjenjujemo pravila i jezički model da filtriramo monojezičke, paralelne rečenice i sintetičke rečenice.', 'cs': 'Tento příspěvek popisuje podání společnosti Global Tone Communication Co., Ltd. sdíleného překladu zpráv WMT21. Účastníme se šesti směry: angličtina do/z Hausa, hindština do/z bengálštiny a zulu do/z Xhosy. Naše předkládané systémy jsou neomezené a zaměřují se na vícejazyčný překlad, backtranslation a forward-translation. Používáme také pravidla a jazykový model k filtrování jednojzyčných, paralelních vět a syntetických vět.', 'ca': 'Aquest article descriu la presentació de Global Tone Communication Co., Ltd de la tasca de traducció compartida de notícies WMT21. Participem en sis direccions: anglès a Hausa, Hindi a Bengalí i Zulu a Xhosa. Els nostres sistemes submetits no estan restringits i es centren en el model de traducció multilingüe, la traducció backwards i la traducció forward. També aplicam regles i model de llenguatge per filtrar frases monolingües, paralleles i sintètiques.', 'et': 'Käesolevas artiklis kirjeldatakse Global Tone Communication Co., Ltd. esitamist WMT21 jagatud uudiste tõlkimise ülesande kohta. Osaleme kuues suunas: inglise keeles Hausasse, hindi bengalisse ja zulu Xhosasse. Meie esitatud süsteemid on piiramatud ja keskenduvad mitmekeelsele tõlkedodelile, tagasitõlkele ja edasitõlkele. Samuti rakendame reegleid ja keelemudelit ühekeelsete, paralleelsete ja sünteetiliste lausete filtreerimiseks.', 'fi': 'Tämä artikkeli kuvaa Global Tone Communication Co., Ltd:n toimittamaa WMT21:n jaettua uutiskäännöstä. Osallistumme kuuteen eri suuntaan: englanniksi Hausaan, hindi bengaliin ja zulu Xhosaan. Toimitetut järjestelmämme ovat rajattomia ja keskittyvät monikielisiin käännösmalleihin, takaisinkääntämiseen ja eteenpäin kääntämiseen. Käytämme myös sääntöjä ja kielimallia yksikielisten, rinnakkaisten ja synteettisten lauseiden suodattamiseen.', 'jv': 'Ngerti wigatining pasar iki oleh nggawe Global Tune komunication co, LTR. Awakdhéwé menyang pisan nganggo sampek urip: Inggris kanggo/suku hal-hal Sistem sing kang dipoleh ora ono nggawe lan sistem sing bisa ditambah lan nggawe oleh banter, terjamahan lan mulai-terjamahan. Awak dhéwé ngerasakno hukum lan model bangsane kanggo nyengké ngerasakno bangsane, kelalam kuwi buat kabèh lan sinaturan.', 'sk': 'Ta prispevek opisuje predložitev naloge prevajanja novic WMT21 s strani Global Tone Communication Co., Ltd. Sodelujemo v šestih smereh: angleščina v/iz Hause, hindijščina v/iz Bengali in zulu v/iz Xhose. Naši predloženi sistemi so neomejeni in se osredotočajo na večjezično prevajanje modelov, nazaj in naprej prevajanje. Prav tako uporabljamo pravila in jezikovni model za filtriranje enojezičnih, vzporednih stavkov in sintetičnih stavkov.', 'ha': "@ action: button Munã raba cikin hanyõyi sita: Ingiriya zuwa/daga Hausa, Hindu zuwa/daga Bangali da Zulu zuwa/daga Xhosa. translation and forward-translation Tuna amfani da misãlai da harshe dõmin za'a filter salofan, masu daidaita da salofa da haɗatiki.", 'bo': "འོག་གི་ཤོག་བྱང་འདིས་Global Tone Communication Co., Ltd.'ཡི་ས WMT21་ཡི་མཉམ་དུ་གསར་འགྱུར་གྱི་དོན་ལ་བཤད་ཀྱི་ཡོད། ང་ཚོས་གཞུང་ཕྱོགས་གཉིས་ཀྱི་གནད་སྡུད་ནས་: ཨིན་ཇིས་ཤི་ལས་/ཧུས་དང་་ཧུས་ལི་ལས་/བྷི་ན་གི་དང་ཛུ་ལུ་ཤི་ལས་/Xhosa་ Our submitted systems are unconstrained and focus on multilingual translation odel, backtranslation and forward-translation. ང་ཚོས་དབང་ཆ་དང་སྐད་རིགས་ཀྱི་མིག་དཔེ་དབྱིབས་གཅིག་སྐད་དང་ཚིག", 'he': "העיתון הזה מתאר את ההעברה של Global Tone Communication Co., Ltd של משימה התרגום חדשות משותפת WMT21. אנחנו משתתפים בשש כיוונים: אנגלית ל/מהאוסה, הינדי ל/מבנגלי וזולו ל/מג'וזה. המערכות המועברות שלנו לא מוגבלות ומוקדמות על אודל תרגום רב-שפתי, תרגום גב ותרגום קדימה. We also apply rules and language model to filter monolingual, parallel sentences and synthetic sentences."}
{'en': 'The TALP-UPC Participation in WMT21 News Translation Task : an mBART-based NMT Approach', 'ar': 'مشاركة TALP-UPC في مهمة ترجمة الأخبار WMT21: نهج NMT القائم على mBART', 'es': 'La participación de TALP-UPC en la tarea de traducción de noticias del WMT21: un enfoque de NMT basado en MBART', 'fr': 'La participation de TALP-UPC à la tâche de traduction de nouvelles du WMT21\xa0: une approche NMT basée sur MBART', 'pt': 'A participação da TALP-UPC na tarefa de tradução de notícias do WMT21: uma abordagem NMT baseada em mBART', 'ja': 'WMT 21ニュース翻訳タスクへのTALP - UPCの参加： mBARTベースのNMTアプローチ', 'zh': 'TALP-UPC与WMT21新闻译者,mBART之NMT法也', 'hi': 'WMT21 समाचार अनुवाद कार्य में TALP-UPC भागीदारी: एक mBART-आधारित NMT दृष्टिकोण', 'ru': 'Участие TALP-UPC в Задаче Перевода Новостей WMT21: Подход mBART-основанный NMT', 'ga': 'Rannpháirtíocht TALP-UPC i dTasc Aistriúcháin Nuachta WMT21: Cur Chuige NMT bunaithe ar mBART', 'ka': 'Name', 'el': 'Η συμμετοχή του TALP-UPC στο έργο μετάφρασης ειδήσεων WMT21: μια προσέγγιση NMT βασισμένη στο mBART', 'hu': 'A TALP-UPC részvétele a WMT21 Hírfordítási feladatban: mBART alapú NMT megközelítés', 'kk': 'WMT21 жаңалық аудару тапсырмасында TALP- UPC қатынасы: mBART- негіздеген NMT қатынасы', 'it': 'Partecipazione TALP-UPC al WMT21 News Translation Task: un approccio NMT basato su mBART', 'lt': 'TALP-UPC dalyvavimas WMT21 naujienų vertimo užduotyje: mBART grindžiamas NMT metodas', 'mk': 'Учеството на ТАЛП-УПЦ во задачата за превод на вести на WMT21: пристап на NMT базиран на mBART', 'ms': 'Perkongsian TALP-UPC dalam Tugas Terjemahan Berita WMT21: pendekatan NMT berasaskan mBART', 'ml': 'ടാഎല്\u200dപി- യുപിസി- വിഎംടി21 വിവരങ്ങളുടെ പങ്കാളി', 'mn': 'TALP-UPC WMT21 мэдээллийн хөрөнгө оруулалт: mBART-д суурилсан NMT Approach', 'mt': 'The TALP-UPC Participation in WMT21 News Translation Task: an mBART-based NMT Approach', 'pl': 'Udział TALP-UPC w zadaniu tłumaczenia wiadomości WMT21: podejście NMT oparte na mBART', 'no': 'TALP- UPC- deltakaren i WMT21 News Translation Task: ein mBART- basert NMT- tilnærming', 'sr': 'TALP-UPC učestvovanje u WMT21 Novinskom prevodnom zadatku: pristup na mBART-baziranom NMT-u', 'so': 'TALP-UPC Participation in WMT21 News Translation Task: an mBART-based NMT Approach', 'si': 'Name', 'ro': 'Participarea TALP-UPC la activitatea de traducere a știrilor WMT21: o abordare NMT bazată pe mBART', 'sv': 'TALP-UPC:s deltagande i WMT21 nyhets繹vers瓣ttningsuppdrag: en mBART-baserad NMT-metod', 'ur': 'Name', 'ta': 'The TALP-UPC Participation in WMT21 News Translation Task: an mBART-based NMT Approach', 'vi': 'Tập đoàn DMAP-UPC Công việc dịch Tin về WM21 Một phương pháp NMT dựa trên m BART', 'uz': 'Name', 'nl': 'De TALP-UPC Deelname aan WMT21 Nieuws Translation Task: een op mBART gebaseerde NMT aanpak', 'hr': 'TALP-UPC učestvovanje u WMT21 Novinskom prevodnom zadatku: pristup na mBART-baziranom NMT-u', 'de': 'Die TALP-UPC-Beteiligung an WMT21 News Translation Task: ein mBART-basierter NMT-Ansatz', 'bg': 'Участието на ТАЛП-ЮПС в задачата за превод на новини: подход на МБАРТ', 'fa': 'شرکت TALP-UPC در تابع ترجمه خبری WMT21: یک نزدیک NMT based on mBART', 'sw': 'Ushiriki wa TALP-UPC katika kazi ya Tafsiri ya Habari za WMT21: NMT anayeishi mBART', 'tr': 'WMT21 Haýsy Terjime Görevi: an mBART-based NMT Approach', 'da': 'TALP-UPC deltagelse i WMT21 Nyhedsoversættelsesopgave: en mBART-baseret NMT-tilgang', 'sq': 'Pjesëmarrja TALP-UPC në detyrën e përkthimit të lajmeve WMT21: një metodë NMT me bazë në mBART', 'am': 'TALP-UPC በWMT21 ዜና ትርጉም ማድረግ: MBART-based NMT Approach', 'id': 'TALP-UPC Participation in WMT21 News Translation Task: an mBART-based NMT Approach', 'af': 'Name', 'ko': 'WMT21 뉴스 번역 작업에 TALP-UPC 참여: mBART 기반 NMT 방법', 'bn': 'টাএলপি-উপিসি-উএমটি২১ সংবাদ অনুবাদ কাজ: এমবার্ট ভিত্তিক এনএমটি আগমন', 'ca': 'The TALP-UPC Participation in WMT21 News Translation Task: an mBART-based NMT Approach', 'cs': 'Účast TALP-UPC na WMT21 News Translation Task: NMT přístup založený na mBART', 'az': 'WMT21 Haber Çeviri Gözəli TALP-UPC Bölümü: mBART tabanlı NMT Yaxınlığı', 'et': 'TALP-UPC osalemine WMT21 uudiste tõlkimise ülesandes: mBART-põhine NMT lähenemisviis', 'bs': 'TALP-UPC učestvovanje u WMT21 Novinskom prevodnom zadatku: pristup na mBART-baziranom NMT-u', 'fi': 'TALP-UPC:n osallistuminen WMT21 News Translation Task: mBART-pohjainen NMT-lähestymistapa', 'hy': 'ՏԱLP-UPC-ի մասնակցությունը World MT21 նորությունների թարգմանման առաջադրանքում. mBAR-ի հիմնված NMT մոտեցում', 'jv': 'Tarjamahan kelas MALP-USC sing dibenakake ning weapon Haber Haber Tarjamahan: nggunakake mLP-basa NMT Method', 'he': 'המשתתפות TALP-UPC במשימת התרגום חדשות WMT21: גישה NMT מבוססת על mBART', 'ha': 'KCharselect unicode block name', 'sk': 'Sodelovanje TALP-UPC v nalogi prevajanja novic WMT21: pristop NMT, ki temelji na mBART', 'bo': 'The TALP-UPC Participation in WMT21 News Translation Task: an mBART-based NMT Approach'}
{'en': 'This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation group. The goal of the task is to translate German to French (De-Fr) and French to German (Fr-De). Our submission focuses on fine-tuning a pre-trained model to take advantage of ', 'es': 'Este artículo describe el envío a la tarea compartida de traducción de noticias del WMT 2021 por parte del grupo de Traducción Automática de la UPC. El objetivo de la tarea es traducir del alemán al francés (de-fr) y del francés al alemán (fr-De). Nuestra presentación se centra en ajustar un modelo previamente entrenado para aprovechar los datos monolingües. Ajustamos mBart50 con los datos filtrados y, además, entrenamos un modelo de Transformer con los mismos datos desde cero. En los experimentos, mostramos que el ajuste fino de mBart50 da como resultado 31,69 BLEU para De-Fr y 23,63 BLEU para Fr-De, lo que aumenta 2,71 y 1,90 BLEU en consecuencia, en comparación con el modelo que entrenamos desde cero. Nuestra presentación final es un conjunto de estos dos modelos, aumentando aún más 0.3 BLEU para Fr-De.', 'ar': 'تصف هذه الورقة التقديم إلى المهمة المشتركة لترجمة الأخبار WMT 2021 من قبل مجموعة الترجمة الآلية UPC. الهدف من المهمة هو ترجمة الألمانية إلى الفرنسية (De-Fr) والفرنسية إلى الألمانية (Fr-De). يركز تقديمنا على ضبط نموذج مدرب مسبقًا للاستفادة من البيانات أحادية اللغة. نقوم بضبط mBART50 باستخدام البيانات التي تمت تصفيتها ، بالإضافة إلى ذلك ، نقوم بتدريب نموذج محول على نفس البيانات من البداية. في التجارب ، أظهرنا أن الضبط الدقيق لـ mBART50 ينتج 31.69 BLEU لـ De-Fr و 23.63 BLEU لـ Fr-De ، مما يزيد 2.71 و 1.90 BLEU وفقًا لذلك ، مقارنة بالنموذج الذي ندربه من الصفر. تقديمنا النهائي عبارة عن مجموعة من هذين النموذجين ، مما أدى إلى زيادة 0.3 BLEU لـ Fr-De.', 'fr': "Cet article décrit la soumission à la tâche partagée de traduction des actualités WMT 2021 par le groupe de traduction automatique UPC. L'objectif de cette tâche est de traduire l'allemand vers le français (de-fr) et le français vers l'allemand (Fr-De). Notre soumission se concentre sur la mise au point d'un modèle pré-entraîné afin de tirer parti des données monolingues. Nous affinons MBart50 à l'aide des données filtrées et, en outre, nous entraînons un modèle Transformer sur les mêmes données à partir de zéro. Dans les expériences, nous montrons que le réglage fin de MBart50 donne 31,69 UEBL pour De-Fr et 23,63 BLEU pour Fr-De, ce qui augmente de 2,71 et 1,90 UEBL en conséquence, par rapport au modèle que nous entraînons à partir de zéro. Notre soumission finale est un ensemble de ces deux modèles, augmentant encore 0,3 UEBL pour Fr-De.", 'pt': 'Este artigo descreve o envio para a tarefa compartilhada de tradução de notícias do WMT 2021 pelo grupo de tradução automática do UPC. O objetivo da tarefa é traduzir alemão para francês (De-Fr) e francês para alemão (Fr-De). Nosso envio se concentra no ajuste fino de um modelo pré-treinado para aproveitar os dados monolíngues. Ajustamos o mBART50 usando os dados filtrados e, além disso, treinamos um modelo Transformer nos mesmos dados do zero. Nos experimentos, mostramos que o ajuste fino do mBART50 resulta em 31,69 BLEU para De-Fr e 23,63 BLEU para Fr-De, o que aumenta 2,71 e 1,90 BLEU de acordo, em comparação com o modelo que treinamos do zero. Nossa submissão final é um conjunto desses dois modelos, aumentando ainda mais 0,3 BLEU para Fr-De.', 'ja': '本稿では、UPC機械翻訳グループによるWMT 2021ニュース翻訳共有タスクへの提出について説明する。タスクの目標は、ドイツ語をフランス語（ De - Fr ）に、フランス語をドイツ語（ Fr - De ）に翻訳することです。私たちの提出物は、単一言語のデータを利用するために、事前にトレーニングされたモデルを微調整することに焦点を当てています。フィルタリングされたデータを使用してmBART 50を微調整し、さらに、同じデータに基づいてトランスフォーマーモデルを一からトレーニングします。実験では、ｍＢＡＲＴ ５ ０を微調整すると、Ｄｅ － Ｆｒでは３ １ ． ６ ９ Ｂｌｅｕ、Ｆｒ － Ｄｅでは２ ３ ． ６ ３ Ｂｌｅｕとなり、これにより、ゼロから訓練するモデルと比較して、２ ． ７ １及び１ ． ９ ０ Ｂｌｅｕが増加することが示されている。最終的な提案は、Fr - Deの0.3 BLEUをさらに増加させた、これら2つのモデルのアンサンブルです。', 'zh': '本文UPC机器翻译组向WMT 2021新闻翻译共之。 其任将德语翻译成法语(De-Fr)、法语至德语(Fr-De)。 臣等侧重于微调预练之形,以利用单语数。 漉后数微调于 mBART50 ,从头始同数练 Transformer 。 实验之中,明mBART50致De-Fr之31.69 BLEUFr-De之23.63 BLEU,比于始教之体,BLEU应增2.711.90。 遂合二模,益增Fr-De0.3 BLEU。', 'hi': 'यह पेपर यूपीसी मशीन अनुवाद समूह द्वारा साझा किए गए कार्य WMT 2021 समाचार अनुवाद के लिए सबमिशन का वर्णन करता है। कार्य का लक्ष्य जर्मन को फ्रेंच (De-Fr) और जर्मन (Fr-De) में फ़्रेंच का अनुवाद करना है। हमारा सबमिशन मोनोलिंगुअल डेटा का लाभ उठाने के लिए एक पूर्व-प्रशिक्षित मॉडल को ठीक करने पर केंद्रित है। हम फ़िल्टर किए गए डेटा का उपयोग करके mBART50 को ठीक करते हैं, और इसके अतिरिक्त, हम खरोंच से एक ही डेटा पर एक ट्रांसफॉर्मर मॉडल को प्रशिक्षित करते हैं। प्रयोगों में, हम दिखाते हैं कि ठीक ट्यूनिंग mBART50 के परिणामस्वरूप De-Fr के लिए 31.69 BLEU और Fr-De के लिए 23.63 BLEU होता है, जो तदनुसार 2.71 और 1.90 BLEU बढ़ जाता है, मॉडल की तुलना में हम खरोंच से प्रशिक्षित करते हैं। हमारा अंतिम सबमिशन इन दो मॉडलों का एक पहनावा है, जो आगे Fr-De के लिए 0.3 BLEU बढ़ रहा है।', 'ru': 'В этой статье описывается подача совместной задачи по переводу новостей WMT 2021 группой машинного перевода UPC. Цель задачи - перевести немецкий язык на французский (De-Fr) и французский на немецкий (Fr-De). В нашем представлении основное внимание уделяется доработке предварительно обученной модели с целью использования преимуществ одноязычных данных. Мы тонко настраиваем mBART50, используя отфильтрованные данные, и дополнительно обучаем Трансформаторную модель на тех же данных с нуля. В экспериментах мы показываем, что тонкая настройка mBART50 приводит к 31,69 BLEU для De-Fr и 23,63 BLEU для Fr-De, что соответственно увеличивает 2,71 и 1,90 BLEU по сравнению с моделью, которую мы тренируем с нуля. Наше окончательное представление представляет собой ансамбль из этих двух моделей, дополнительно увеличивая 0,3 BLEU для Fr-De.', 'ga': 'Déanann an páipéar seo cur síos ar an aighneacht a rinne grúpa Aistriúcháin Meaisín UPC do thasc roinnte aistriúcháin nuachta WMT 2021. Is é sprioc an taisc ná Gearmáinis a aistriú go Fraincis (De-Fr) agus Fraincis go Gearmáinis (Fr-De). Díríonn ár n-aighneacht ar mhionchoigeartú a dhéanamh ar mhúnla réamh-oilte chun leas a bhaint as sonraí aonteangacha. Déanaimid mionchoigeartú ar mBART50 ag baint úsáide as na sonraí scagtha, agus ina theannta sin, cuirimid oiliúint ar mhúnla Trasfhoirmeora ar na sonraí céanna ón tús. Sna turgnaimh, léirímid go mbíonn 31.69 BLEU le haghaidh De-Fr agus 23.63 BLEU le haghaidh Fr-De mar thoradh ar mhionchoigeartú mBART50, rud a mhéadaíonn 2.71 agus 1.90 BLEU dá réir sin, i gcomparáid leis an tsamhail a dtraenáilimid ón tús. Is ensemble den dá mhúnla seo an aighneacht deiridh atá againn, ag méadú tuilleadh 0.3 BLEU do Fr-De.', 'ka': 'ეს დოკუმენტი გამოსახულებს WMT 2021 ნუტური გაგრძელების გასაგულება, რომელიც UPC მაქინის გაგრძელების ჯგუფის გასაგულება. დავალების მიზეზი არის გერმანული ფრანუსში (De-Fr) და ფრანუსში გერმანურად (Fr-De). ჩვენი წარმოდგენება მონოლოგური მონაცემების გამოიყენება მონაცემების მონაცემების წარმოადგენება. ჩვენ mBART50-ს გამოყენებთ ფილტრუქტული მონაცემების გამოყენებით და დამატებით, ჩვენ ტრანტრუქტურის მოდელს ერთი მონაცემების გამოყენება. ექსპერიმენტებში ჩვენ აჩვენებთ, რომ mBART50 წარმოდგენა 31,69 BLEU-ს და 23,63 BLEU-ს Fr-De-ზე, რომელიც შესაბამისიდ 2,71 და 1,90 BLEU-ს გაზრდება, რომელიც ჩვენ მოდელზე გაზრუნდება. ჩვენი ბოლო წარმოდგენება არის ამ ორი მოდელის ანსტემბელი, რომელიც უფრო მეტია 0,3 BLEU-ს ფრო-დეს.', 'hu': 'Ez a tanulmány bemutatja a WMT 2021 hírfordítási feladatához való benyújtást az UPC Gépi Fordítás csoportja által. A feladat célja, hogy németül franciára (De-Fr) és franciára (Fr-De) fordítsa le. Jelentkezésünk egy előre képzett modell finomhangolására összpontosít, hogy kihasználja az egynyelvű adatokat. Az mBART50 finomhangolását a szűrt adatok segítségével finomhangoljuk, és ezenkívül a Transformer modellt ugyanazon adatokon az alapokon edzünk. A kísérletekben megmutatjuk, hogy az mBART50 finomhangolása 31,69 BLEU-t eredményez a De-Fr-nél és 23,63 BLEU-t a Fr-De-nél, ami ennek megfelelően 2,71 és 1,90 BLEU-t emel a semmiből edzett modellhez képest. A végső beadványunk e két modell együttese, amely tovább növeli a 0,3 BLEU-t Fr-De számára.', 'el': 'Αυτή η εργασία περιγράφει την υποβολή στην κοινή εργασία μετάφρασης ειδήσεων από την ομάδα μηχανικής μετάφρασης. Στόχος του έργου είναι η μετάφραση των γερμανικών στα γαλλικά (και των γαλλικών στα γερμανικά (π-ντε). Η υποβολή μας επικεντρώνεται στην τελειοποίηση ενός προ-εκπαιδευμένου μοντέλου για να εκμεταλλευτεί τα μονογλωσσικά δεδομένα. Βελτιστοποιούμε το χρησιμοποιώντας τα φιλτραρισμένα δεδομένα και επιπλέον εκπαιδεύουμε ένα μοντέλο μετασχηματιστή στα ίδια δεδομένα από την αρχή. Στα πειράματα, καταδεικνύουμε ότι ο λεπτός συντονισμός του έχει ως αποτέλεσμα 31.69 BLEU για De-Fr και 23.63 BLEU για Fr-De, η οποία αυξάνει ανάλογα 2.71 και 1.90 BLEU, σε σύγκριση με το μοντέλο που εκπαιδεύουμε από το μηδέν. Η τελική μας υποβολή είναι ένα σύνολο αυτών των δύο μοντέλων, αυξάνοντας περαιτέρω το 0.3 για τον π-Ντε.', 'it': "Questo articolo descrive l'invio al compito condiviso di traduzione delle notizie WMT 2021 dal gruppo UPC Machine Translation. L'obiettivo del compito è quello di tradurre dal tedesco al francese (De-Fr) e dal francese al tedesco (Fr-De). La nostra presentazione si concentra sulla messa a punto di un modello pre-addestrato per sfruttare i dati monolingue. Perfezioniamo mBART50 utilizzando i dati filtrati e, inoltre, addestriamo un modello Transformer sugli stessi dati da zero. Negli esperimenti, mostriamo che la messa a punto di mBART50 si traduce in 31,69 BLEU per De-Fr e 23,63 BLEU per Fr-De, che aumenta di conseguenza 2,71 e 1,90 BLEU, rispetto al modello che alleniamo da zero. La nostra presentazione finale è un insieme di questi due modelli, aumentando ulteriormente 0,3 BLEU per Fr-De.", 'kk': 'Бұл қағаз UPC машинаны аудару тобының WMT 2021 жаңалық аудару тапсырмасына жіберілгенін анықтайды. Тапсырманың мақсаты неміс тіліне французшаға (De-Fr) және французшаға (Fr-De) аудару. Біздің жіберіміз бірнеше тіл деректерінің артықшылығын қолдану үшін алдын- оқылған үлгілерді баптауға көмектеседі. Біз сүзгілеген деректерді қолдану үшін mBART50- ды жақсы баптап, және қосымша, бір деректерді жүктеу үшін түрлендіруші үлгісін оқыдық. Осы тәжірибелерде, мBART50 баптауларының 31,69 BLEU және 23,63 BLEU және Fr-De үшін ол 2,71 және 1,90 BLEU деп көрсетіледі. Бұл моделіне сәйкес келесі тәжірибелеріміздің үлгісіне салыстыру үлгісіне қарсы. Біздің соңғы келтіріміз - бұл екі үлгілердің белгісі. Бірақ Fr-De үшін 0,3 BLEU үлкен.', 'lt': 'Šiame dokumente aprašomas UPC mašinų vertimo grupės pateiktas WMT 2021 m. žinių vertimo bendras uždavinys. The goal of the task is to translate German to French (De-Fr) and French to German (Fr-De).  Mūsų pranešime daugiausia dėmesio skiriama parengtam modeliui patobulinti, kad būtų galima pasinaudoti vienkalbiniais duomenimis. Mes patobuliname mBART50 naudojant filtruotus duomenis ir, be to, mes treniruojame Transformer model į iš nulio ant tų pačių duomenų. In the experiments, we show that fine-tuning mBART50 results in 31.69 BLEU for De-Fr and 23.63 BLEU for Fr-De, which increases 2.71 and 1.90 BLEU accordingly, as compared to the model we train from scratch.  Mūsų galutinis pasiūlymas yra šių dviejų modelių rinkinys, toliau didinantis 0,3 BLEU Fr-De atveju.', 'mk': 'This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation group.  Целта на задачата е да се преведе германски на француски (De-Fr) и француски на германски (Fr-De). Нашето поднесување се фокусира на финетизирање на предобучен модел за да ги искористиме монојазичните податоци. Ние финетизираме mBART50 користејќи ги филтрираните податоци, и додатно, тренираме трансформен модел на истите податоци од нула. In the experiments, we show that fine-tuning mBART50 results in 31.69 BLEU for De-Fr and 23.63 BLEU for Fr-De, which increases 2.71 and 1.90 BLEU accordingly, as compared to the model we train from scratch.  Нашата последна поднесувачка е ансембл на овие два модели, со понатамошно зголемување на 0,3 БЛЕ за Фр-Де.', 'ml': 'ഈ പത്രത്തില്\u200d WMT 2021 വാര്\u200dത്തകളുടെ വിവരങ്ങള്\u200d പങ്കെടുത്ത ജോലി പങ്കെടുത്തിരിക്കുന്നു. യുപിസി മെഷീന്\u200d പരിഭാ ജോലിയുടെ ലക്ഷ്യം ജര്\u200dമന്\u200d ഫ്രെഞ്ചിലേക്കും ഫ്രെഞ്ചിലേക്കും ജര്\u200dമ്മനിലേക്കും പരിഭാഷപ്പെടുത്തേണ്ടതാണ്. നമ്മുടെ കീഴ്പെടുത്തുന്നത് മുമ്പ് പരിശീലിച്ച ഒരു മോഡലിനെ ശ്രദ്ധിക്കുന്നതാണ്. മോനോളില്\u200dഭാഷ വിവരങ്ങള്\u200d ഉപ ഫില്\u200dറ്റര്\u200dട്ട് ഡേറ്റ ഉപയോഗിച്ച് നമുക്ക് മെബിആര്\u200dട്ടിഫിള്\u200dട്ടില്\u200d നിന്നും ഒരു ട്രാന്\u200dസ്ഫോര്\u200d മോഡല്\u200d പരിശീലനം നല്\u200dകുന്ന പരീക്ഷണങ്ങളില്\u200d നമ്മള്\u200d കാണിച്ചു തരുന്നത് മെബാര്\u200dട്ടിഫ്രിക്ക് 31.69 ബില്ലിയുടെ ഫലങ്ങളാണ്. മിസ്റ്റര്\u200d ഡി വേണ്ടി 23.63 ബ്ലിയുടെ ഫലങ്ങള്\u200d, അത് 2.71 വര്\u200dദ്ധിപ്പിക്കുന്നു. 1.90 ബ നമ്മുടെ അവസാന സമ്മാനം ഈ രണ്ടു മോഡലുകളുടെ ഒരു മാതൃകയാണ്, മിസ്റ്റര്\u200d ഡിയുടെ 0.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni għat-traduzzjoni tal-aħbarijiet tad-WMT 2021 kompitu kondiviż mill-grupp ta’ traduzzjoni tal-magni tal-UPC. L-għan tal-kompitu huwa li l-Ġermaniż jiġi tradott għall-Franċiż (De-Fr) u l-Franċiż għall-Ġermaniż (Fr-De). Is-sottomissjoni tagħna tiffoka fuq l-irfinar ta’ mudell imħarreġ minn qabel biex tieħu vantaġġ mid-dejta monolingwi. Aħna nirranġaw il-mBART50 bl-użu tad-dejta ffiltrata, u barra minn hekk, inħarrġu mudell tat-Transformer fuq l-istess dejta mill-bidu. Fl-esperimenti, naraw li l-aġġustament fin tal-mBART50 jirriżulta fi 31.69 BLEU għal De-Fr u 23.63 BLEU għal Fr-De, li jżid 2.71 u 1.90 BLEU skont dan, meta mqabbel mal-mudell li nħarrġu mill-bidu. Our final submission is an ensemble of these two models, further increasing 0.3 BLEU for Fr-De.', 'mn': 'Энэ цаас WMT 2021 оны мэдээний хөрөнгө оруулах ажлыг UPC Машин хөрөнгө оруулах бүлэгтэй хуваалцсан ажлыг тайлбарладаг. Цагийн зорилго нь Германы французт (De-Fr) болон Французт Герман (Fr-De) руу орлуулах юм. Бидний хүлээн зөвшөөрөл нь нэг хэл өгөгдлийн хэрэглээний тулд сургалтын өмнө сургалтын загварыг тодорхойлдог. МБАРТ50-г цэвэрлэгдсэн өгөгдлийг ашиглан цэвэрлэгддэг. Мөн нэмэлтэй нь бид ижил өгөгдлийн дээр Трансфер загварын загварыг сургаж байна. Эдгээр туршилтуудын тулд бид мBART50-г дүгнэх 31.69 BLEU болон Fr-De-д 23.63 BLEU-г харуулж байна. Энэ нь 2.71 болон 1.90 BLEU-г нэмэгдүүлдэг. Бидний сүүлийн хэлэлцэл бол энэ хоёр загварын нэг тоо, Fr-De-д 0.3 BLEU-г нэмэгдүүлнэ.', 'no': 'Denne papiret beskriver å senda inn til WMT 2021 nyhetsgruppa delt oppgåve av UPC- maskinsomsetjingsgruppa. Målet på oppgåva er å oversette tysk til fransk (De-Fr) og fransk til tysk (Fr-De). Søket vårt fokuserer på å finne ein først treng modell for å bruka fordel av monospråk-data. Vi finn mBART50 med filtrerte data, og tillegg treng vi eit transformeringsmodell på samme data frå rulla. I eksperimentene viser vi at mBART50 finnstillingar resulterer i 31,69 BLEU for De-Fr og 23,63 BLEU for Fr-De, som aukar 2,71 og 1,90 BLEU, slik som sammenlignet med modellen vi treng frå rådet. Det siste oppføringa vårt er ein ensembel av desse to modelane, og større øker 0,3 BLEU for Fr-De.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie do wspólnego zadania tłumaczenia wiadomości WMT 2021 przez grupę tłumaczeń maszynowych UPC. Celem zadania jest tłumaczenie niemieckiego na francuski (De-Fr) i francuski na niemiecki (Fr-De). Nasze zgłoszenie skupia się na dostosowaniu wstępnie przeszkolonego modelu, aby wykorzystać dane jednojęzyczne. Dostrajamy mBART50 za pomocą filtrowanych danych, a dodatkowo szkolimy model Transformera na tych samych danych od podstaw. W eksperymentach pokazujemy, że dostosowanie mBART50 powoduje 31.69 BLEU dla De-Fr oraz 23.63 BLEU dla Fr-De, co odpowiednio zwiększa 2.71 i 1.90 BLEU w porównaniu do modelu, który trenujemy od zera. Naszym ostatecznym zgłoszeniem jest zespół tych dwóch modeli, dodatkowo zwiększający 0.3 BLEU dla ks. De.', 'ro': 'Această lucrare descrie transmiterea la sarcina comună de traducere a știrilor WMT 2021 de către grupul UPC Machine Translation. Scopul sarcinii este traducerea germană în franceză (De-Fr) și franceză în germană (Fr-De). Transmiterea noastră se concentrează pe reglarea fină a unui model pre-instruit pentru a profita de datele monolingve. Ajustăm mBART50 folosind datele filtrate și, în plus, antrenăm un model Transformer pe aceleași date de la zero. În experimente, arătăm că ajustarea fină a mBART50 rezultă în 31,69 BLEU pentru De-Fr și 23,63 BLEU pentru Fr-De, ceea ce crește 2,71 și 1,90 BLEU în consecință, comparativ cu modelul pe care îl antrenăm de la zero. Prezentarea noastră finală este un ansamblu de aceste două modele, crescând în continuare 0,3 BLEU pentru Fr-De.', 'sr': 'Ovaj papir opisuje podnošenje novinskog prevoda WMT 2021. godine podijeljenog zadatka grupe UPC mašinskih prevoda. Cilj zadatka je prevoditi njemački na francuski (De-Fr) i francuski na njemački (Fr-De). Naša podnošenja se fokusira na finaliziranje predobučenog modela da iskoristi monojezičke podatke. Potvrđujemo mBART50 sa filtriranim podacima, i dodatno, treniramo model transformera na istim podacima od ogrebotine. U eksperimentima, pokazujemo da je u usporedbi s modelom koji treniramo od ogrebotine 31,69 BLEU za De-Fr i 23,63 BLEU za Fr-De, što se povećava 2,71 i 1,90 BLEU. Naša poslednja predstava je kompleks ovih dva modela, dalje povećavajući 0,3 BLEU za Fr-De.', 'si': 'මේ පැත්තේ WMT 2021 වාර්තාවේ අවවාදය සමාගත වැඩක් UPC මැෂින් අවවාදය කණ්ඩායම් වලින් භාවිත කරන්න ප්\u200dරවේ මේ වැඩේ ඉලක්කම තමයි ජර්මන් වල ෆ්\u200dරෑන්ස් වලින් (ඩී-ෆ්\u200dරෑන්ස්) වලින් ෆ්\u200dරෑන්ස් වල ජර්මන්ස් ව අපේ පිළිගන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් ප්\u200dරශ්නයක් ප්\u200dරයෝජනයක් වෙන්න පුළුවන් ව අපි පරික්ෂණය කරපු දත්ත භාවිතා කරන්න mBART50 විශ්වාස කරනවා, ඒ වගේම, අපි පරික්ෂණය කරපු මොඩාලයක් පරික්ෂණය කරනවා. අපි පරීක්ෂණාවට පෙන්වන්නේ, මේ විශ්වාස කරපු mBART50 ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප අපේ අන්තිම පිළිගන්නය තමයි මේ මොඩේල් දෙකක් ගැන සංවිධානයක්, ෆ්\u200dරෝඩ් වෙනුවෙන් 0.3 බ්ලූස් වැඩ කරන්', 'so': 'Kanu warqaddan wuxuu ku qoran yahay submishada u soo dirista WMT 2021 news turjumista loo qaybiyey shaqada ay ku qoran yihiin UPC Machine Translation Group. Ujeedada shaqada waa in lagu turjumo German to French (De-Fr) and French to German (Fr-De). Guushanadeenu waxay ku kalsoonaan yihiin samooyin la tababaray horay si ay u isticmaalaan macluumaadka luuqada ah. MBART50 waxaynu si fiican ugu isticmaalnaa macluumaadka la filteriyay, waxaana sidoo kale ku tababarinnaa tusaale turjumid ah oo ku qoran isku macluumaad ah. Imtixaanka, waxaynu muujinaynaa midhihii wanaagsanaa ee MBART50 waxay ka dhigaan 31.69 BLEU for De-Fr iyo 23.63 BLEU for Fr-De, taasoo u kordhiya 2.71 iyo 1.90 BLEU si waafaqsan sameynta modelka aan ka tababarinno. Guusheena ugu dambaysta ah waa tusaale u ah labadan tusaale, kaas oo kordhaya 0.3 BLEU ee Fr-De.', 'sv': 'Denna uppsats beskriver inlﾃ､mningen av UPC:s maskinﾃｶversﾃ､ttning till WMT 2021-nyhetsﾃｶversﾃ､ttningsuppgift. Mﾃ･let med uppgiften ﾃ､r att ﾃｶversﾃ､tta tyska till franska (De-Fr) och franska till tyska (Fr-De). Vﾃ･r inlﾃ､mning fokuserar pﾃ･ att finjustera en fﾃ､rdigutbildad modell fﾃｶr att dra nytta av ensprﾃ･kiga data. Vi finjusterar mBART50 med hjﾃ､lp av filtrerade data, och dessutom trﾃ､nar vi en Transformer modell pﾃ･ samma data frﾃ･n grunden. I experimenten visar vi att finjustering av mBART50 resulterar i 31,69 BLEU fﾃｶr De-Fr och 23,63 BLEU fﾃｶr Fr-De, vilket ﾃｶkar 2,71 och 1,90 BLEU motsvarande, jﾃ､mfﾃｶrt med den modell vi trﾃ､nar frﾃ･n grunden. Vﾃ･r sista inlﾃ､mning ﾃ､r en ensemble av dessa tvﾃ･ modeller, som ytterligare ﾃｶkar 0,3 BLEU fﾃｶr Fr-De.', 'ta': 'This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation Group. பணியின் குறிப்பு என்னவென்றால் ஜெர்மன் மொழிபெயர்ப்பு( De- Fr) மற்றும் பிரெஞ்சுக்கு ஜெர்மன் (Fr- De) மொழிபெ எங்கள் உத்தரவு ஒரு முன் பயிற்சி மாதிரியில் நன்றாக முறைப்படுத்தல் கவனம் செலுத்துகிறது ஒரு மாதிரி மாதிரியி மேலும் அதே தகவலில் இருந்து மாற்றி மாதிரி மாதிரியை பயிற்சி செய்கிறோம். இந்த சோதனைகளில், நாம் காண்பிக்கிறோம் முன்னோட்டத்திற்கு 31.69 பிலியு மற்றும் 23.63 பிலியுவின் முடிவுகளை 31.69 பிலியு காட்டுகிறோம். அது 2.71 மற்றும் 1.90 பிலியு அதிகப்பட இந்த இரண்டு மாதிரிகளின் கடைசி ஒப்புக்காட்டு, மின்ஸ்-டி 0.3 பிலியு அதிகரிக்கும்.', 'ur': 'This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation group. اس کام کا موقع یہ ہے کہ جرمن (De-Fr) اور فرانسوی (Fr-De) کو جرمن (Fr-De) پر ترجمہ کرنا ہے۔ ہماری اطلاعات صرف ایک زبان دکھانے کے مطابق فائدہ اٹھانے کے لئے ایک پیش آموزش کی مدل کی تنظیم کرنے پر تمرکز کرتی ہے. ہم فیلٹر کیے ہوئے ڈیٹا کے مطابق mBART50 کو ٹھیک ٹینس کرتے ہیں، اور اضافہ بھی، ہم ایک ٹرنسفر موڈل کو ایک ہی ڈیٹا پر ترینس دیتے ہیں۔ آزمائش میں، ہم دکھاتے ہیں کہ دفار کے لئے 31.69 بلیوس اور 23.63 بلیوس کا نتیجہ ہے، جو 2.71 اور 1.90 بلیوس کے مطابق اضافہ کرتا ہے، اس موڈل کے مطابق جو ہم اسرار سے تطابق کرتے ہیں۔ ہماری آخری تسلیم یہ دو نمڈلوں کی ایک نشانی ہے، جو فرد دہ کے لئے 0.3 BLEU بڑھتی ہے۔', 'ms': 'Kertas ini menggambarkan penghantaran kepada tugas terjemahan berita WMT 2021 berkongsi oleh kumpulan Perjemahan Mesin UPC. Tujuan ini adalah untuk menerjemahkan Jerman ke Perancis (De-Fr) dan Perancis ke Jerman (Fr-De). Our submission focuses on fine-tuning a pre-trained model to take advantage of monolingual data.  Kami memperbaiki mBART50 menggunakan data ditapis, dan tambahan, kami melatih model Transformer pada data yang sama dari awal. Dalam eksperimen, kami menunjukkan bahawa penyesuaian mBART50 menghasilkan 31.69 BLEU untuk De-Fr dan 23.63 BLEU untuk Fr-De, yang meningkat 2.71 dan 1.90 BLEU sesuai dengan itu, dibandingkan dengan model yang kita latih dari awal. Our final submission is an ensemble of these two models, further increasing 0.3 BLEU for Fr-De.', 'uz': "Ushbu hujjat UPC Mashine tarjima guruhi bilan tarjima qilingan vazifani WMT 2021 news tarjima qiladi. Vazifaning maqsadi, Olmonchaga Fransuzcha (De- Fr) va Fransuzchaga Olmonchaga (Fr- De) tarjima qilish. Bizning tilimizning bir o'rganishdan oldin modelni o'xshash mumkin, monolingan maʼlumotdan foydalanish uchun. Biz filterlar maʼlumoti yordamida mBART50 yordamida yaxshi ma'lumot yordam beramiz. Ko'pchilikdan bir xil maʼlumotdan Transformer modelini o'rganamiz. Tez tajribalarda, biz MBART50 ta'lim natijalarini 31.69 BLEU for De-Fr va 23.63 BLEU for Fr-De'ning 23.63 BLEU natijalariga ko'rsamiz, bu 2.71 va 1.90 BLEU shunday qiladi, biz o'rganish modeldan o'rganadigan modelga o'xshash. Bizning oxirgi javob bu ikkita modelning misol, Fr-De uchun 0.3 BLEU yozib qo'yish mumkin.", 'vi': 'Tờ giấy này mô tả việc đệ trình dịch tin về WRT 2021 do tập hợp dịch phụ thuộc Đội Dịch Cỗ Máy UPC. Nhiệm vụ này là dịch Đức sang Pháp (De-Cha) và Pháp sang Đức (Cha-De). Sự cung cấp của chúng tôi tập trung vào việc tinh chỉnh một mô hình được đào tạo để tận dụng dữ liệu ngôn ngữ. Chúng tôi chỉnh điểm mBARTC50 bằng các dữ liệu đã lọc, và thêm nữa, chúng tôi đào tạo một mô hình transformer trên cùng một dữ liệu từ đầu. Trong các thí nghiệm, chúng tôi cho thấy kết quả hoàn chỉnh mBART50 dẫn đến 11.69 BleU for De-Cha và 23.63 bleU for Fru-De, which increass 2.71 và 1.90 bleU tương tự, so với mẫu chúng tôi rèn lại từ đầu. Kết luận cuối cùng của chúng ta là một kết hợp của hai mẫu này, tăng thêm O.3 tiếng bíp cho Cha De.', 'bg': 'Настоящата статия описва представянето на задачата за превод на новини, споделена от групата за машинен превод на ЮПС. Целта на задачата е превод на немски на френски (Де-Фра) и френски на немски (Де-Фра). Нашето представяне се фокусира върху фината настройка на предварително обучен модел, за да се възползва от едноезични данни. Ние фино настройваме използвайки филтрираните данни и допълнително обучаваме модел трансформатор на същите данни от нулата. В експериментите показахме, че фината настройка води до 31.69 БЛЕУ за Де-Фра и 23.63 БЛЕУ за Фр-Де, което съответно увеличава 2.71 и 1.90 БЛЕУ в сравнение с модела, който тренираме от нулата. Нашето окончателно представяне е ансамбъл от тези два модела, допълнително увеличавайки 0.3 Блеу за Фр-Де.', 'da': 'Dette dokument beskriver indsendelsen til WMT 2021-nyhedsoversættelsesopgaven delt af UPC Maskinoversættelsesgruppen. Målet med opgaven er at oversætte tysk til fransk (De-Fr) og fransk til tysk (Fr-De). Vores indsendelse fokuserer på at finjustere en præ-trænet model for at drage fordel af ensprogede data. Vi finjusterer mBART50 ved hjælp af de filtrerede data, og derudover træner vi en Transformer model på de samme data fra bunden. I eksperimenterne viser vi, at finjustering af mBART50 resulterer i 31,69 BLEU for De-Fr og 23,63 BLEU for Fr-De, hvilket øger 2,71 og 1,90 BLEU i overensstemmelse hermed, sammenlignet med den model vi træner fra bunden. Vores endelige indsendelse er et ensemble af disse to modeller, der yderligere øger 0,3 BLEU for Fr-De.', 'nl': 'Dit document beschrijft de inzending aan de gedeelde taak WMT 2021-nieuwsovertelling door de UPC Machine Translation groep. Het doel van de taak is om Duits naar Frans (De-Fr) en Frans naar Duits (Fr-De) te vertalen. Onze inzending richt zich op het finetunen van een voorgetraind model om te profiteren van monolingual data. We finetunen mBART50 met behulp van de gefilterde data, en daarnaast trainen we een Transformer model vanaf nul op dezelfde data. In de experimenten laten we zien dat het finetunen van mBART50 resulteert in 31.69 BLEU voor De-Fr en 23.63 BLEU voor Fr-De, die 2.71 en 1.90 BLEU dienovereenkomstig verhoogt in vergelijking met het model dat we vanaf nul trainen. Onze laatste inzending is een ensemble van deze twee modellen, waardoor 0.3 BLEU voor Fr-De verder wordt verhoogd.', 'de': 'Dieses Papier beschreibt die Einreichung an die gemeinsame Aufgabe der UPC-Gruppe für maschinelle Übersetzung von Nachrichten in WMT 2021. Ziel der Aufgabe ist es, Deutsch ins Französische (De-Fr) und Französisch ins Deutsche (Fr-De) zu übersetzen. Unsere Einreichung konzentriert sich auf die Feinabstimmung eines vortrainierten Modells, um die Vorteile von einsprachigen Daten zu nutzen. Wir optimieren mBART50 anhand der gefilterten Daten und trainieren zusätzlich ein Transformer-Modell auf den gleichen Daten von Grund auf. In den Experimenten zeigen wir, dass die Feinabstimmung von mBART50 zu 31.69 BLEU für De-Fr und 23.63 BLEU für Fr-De führt, was im Vergleich zu dem Modell, das wir von Grund auf trainieren, die 2.71 und 1.90 BLEU entsprechend erhöht. Unsere endgültige Einreichung ist ein Ensemble dieser beiden Modelle, das 0.3 BLEU für Fr-De weiter erhöht.', 'ko': '본고는 UPC 기계번역팀이 WMT 2021 뉴스 번역 공유 임무에 제출한 상황을 기술한다.이 임무의 목표는 독일어를 프랑스어(De Fr), 프랑스어를 독일어(Fr De)로 번역하는 것입니다.우리가 제출한 자료는 단어 데이터를 활용하기 위해 미리 훈련하는 모델에 중심을 두었다.우리는 필터된 데이터를 사용하여 mBART50을 미세하게 조정했고, 또한 같은 데이터에 따라 변압기 모형을 처음부터 훈련했다.실험에서 우리는 우리가 처음부터 훈련한 모델에 비해 미조정 mBART50 이후 DeFr의 BLEU는 31.69, FrDe의 BLEU는 23.63으로 이에 상응하여 2.71과 1.90 BLEU가 증가했다고 밝혔다.우리가 최종적으로 제출한 것은 이 두 모델의 집합으로 Fr-De의 0.3BLEU를 더욱 증가시켰다.', 'sw': 'Makala hii inaelezea ujumbe huo wa tafsiri ya habari ya WMT 2021 ulisambazwa na kundi la Tafsiri la Mashine ya UPC. Lengo la kazi ni kutafsiri Ujerumani kwenda Kifaransa (De-Fr) na Ujerumani (Fr-De). Ujumbe wetu unajikita kwenye kutangaza vizuri mtindo wa mafunzo wa awali ili kutumia taarifa za lugha za kiumbe. Tunawatunza vizuri mBART50 kwa kutumia taarifa zinazochapishwa, na kwa kuongeza, tunamfundisha muundo wa Transformer kwenye taarifa hizo zinazotokana na kuchapisha. Katika majaribio hayo, tunaonyesha matokeo mazuri ya mBART50 yaliyotokana na BLEU 31.69 kwa ajili ya De-Fr na 23.63 BLEU kwa ajili ya Fr-De, ambayo inaongezea 2.71 na 1.90 BLEU kwa namna hiyo, kama ilivyolinganisha na model tunayojifunza kutoka kwenye kipande hicho. Our final submission is an ensemble of these two models, further increasing 0.3 BLEU for Fr-De.', 'fa': 'این کاغذ تحویل دادن به ترجمه خبری WMT 2021 توسط گروه ترجمه ماشین UPC را توصیف می\u200cکند. هدف این کار این است که آلمانی را به فرانسوی (De-Fr) و فرانسوی به آلمانی (Fr-De) ترجمه کنیم. تسلیم ما روی تنظیم یک مدل پیش آموزش آموزش برای استفاده از داده های تک زبان تمرکز می کند. ما با استفاده از داده\u200cهای فیلتر داده می\u200cکنیم mBART50 را خوب تنظیم می\u200cکنیم، و به اضافه، ما یک مدل تغییر\u200cدهنده را روی یک داده\u200cای از خرچ آموزش می\u200cدهیم. در این آزمایشات، ما نشان می دهیم که mBART50 در مقایسه با مدل آموزش می\u200cکنیم، ۳۱.69 BLEU برای De-Fr و ۲۳.۶۳ BLEU برای Fr-De، که ۲.71 و ۱.۹۰ BLEU را افزایش می\u200cدهد. اخرین تسلیم ما یک جمله از این دو مدل است که بیشتر 0.3 BLEU برای Fr-De افزایش می کند.', 'id': 'Kertas ini menggambarkan pengiriman ke terjemahan berita WMT 2021 tugas berbagi oleh kelompok Perjemahan Mesin UPC. Tujuan ini adalah untuk menerjemahkan Jerman ke Perancis (De-Fr) dan Perancis ke Jerman (Fr-De). Pemberian kami fokus pada memperbaiki model yang terlatih untuk mengambil keuntungan dari data monobahasa. Kami memperbaiki mBART50 menggunakan data yang dipilter, dan tambahan, kami melatih model Transformer pada data yang sama dari nol. In the experiments, we show that fine-tuning mBART50 results in 31.69 BLEU for De-Fr and 23.63 BLEU for Fr-De, which increases 2.71 and 1.90 BLEU accordingly, as compared to the model we train from scratch.  Pengiriman akhir kami adalah sebuah ensemble dari dua model ini, meningkat lebih lanjut 0,3 BLEU untuk Fr-De.', 'af': "Hierdie papier beskryf die onderskrywing na die WMT 2021 nuusvertaling gedeelde taak deur die UPC Masjien Vertaling groep. Die doel van die taak is om Duitsk na Frans te vertaal (De-Fr) en Frans na Duitsk (Fr-De). Ons ondersteuning fokus op 'n voorsteunde model om voordeel van monolinglike data te neem. Ons fin-tune mBART50 gebruik die filtreerde data, en additionally, ons tref 'n Transformer model op dieselfde data van skrap. In die eksperimente wys ons dat fine-tuning mBART50 resultate in 31,69 BLEU vir De-Fr en 23,63 BLEU vir Fr-De, wat 2,71 en 1,90 BLEU volgens vergroot word, soos vergelyk met die model wat ons van skrap trein. Ons eindelike ondersteuning is 'n ensemble van hierdie twee modele, verder 0.3 BLEU vir Fr-De vergroot.", 'tr': "Bu kagyz WMT 2021 täze terjime etmegini UPC Maşynyň terjime toparynyň tarapyndan paýlaşýar. Bu zadyň maksady nemes dilini fransuzça (De-Fr) we fransuzça Almança terjime etmekdir. Biziň ilatymyz monolingüň maglumatyny ulanmak üçin öňünden öňünden bilim edilmiş bir nusga täzeden geçirmek üçin ünsümi bar. Biz filtreli maglumatlary ulanarak mBART50'i gowy düzenleyiriz we üstünde aynı maglumatlarda transformer modelini öwrendirik. Deneylerde, mBART50 düzgün taýýarlanmagyň 31,69 BLEU-a degişli Fr-De üçin 23,63 BLEU-a degişli ýagdaýynda 2,71 we 1,90 BLEU-a degişli ýagdaýynda deňleýäris. Biziň soňky görkezmemiz bu iki nusga üçin bir görkezme, Fr-De üçin 0.3 BLEU dyrlanýar.", 'am': 'ይህ ገጽ WMT 2021 ዜና ትርጉም በUPC Machine ትርጉም ጉባኤ የተካፈለው ስራ ይናገራል፡፡ የስራ ጉዳዩ ጀርመን ወደ ፈረንሳይኛ (De-Fr) እና ፈረንሳይኛ ወደ ጀርመን (Fr-De) ለመተርጉም ነው፡፡ Our submission focuses on fine-tuning a pre-trained model to take advantage of monolingual data.  አዲስ ጥያቄ እናስጠጋለን፡፡ በተፈተና ውስጥ የMBART50 ውጤቶች ለዲ-ፍር እና ለፊርድ-ዲ 23.63 ቢሊዩን እንደምናሳየው የ31.69 ብሊዩን እናሳየዋለን፡፡ Our final submission is an ensemble of these two models, further increasing 0.3 BLEU for Fr-De.', 'hy': 'Այս աշխատանքը նկարագրում է ԱՄԹ 2021-ի նորությունների թարգմանման հանձնարարությունը UPC-ի մեքենայի թարգմանման խմբի կողմից: The goal of the task is to translate German to French (De-Fr) and French to German (Fr-De).  Our submission focuses on fine-tuning a pre-trained model to take advantage of monolingual data.  Մենք լավագույնում ենք mBAR50-ը ֆիլտրված տվյալների օգտագործման միջոցով, և ավելին, մենք վարժեցնում ենք Transforme-ի մոդելը նույն տվյալների վրա զրոյից: Փորձարկումների ընթացքում մենք ցույց ենք տալիս, որ mBAR50-ը լավագույն կազմակերպման արդյունքում է 31.69 ԲԼԵՎ դե-Ֆրին և 23.63 ԲԼԵՎ դե-Ֆրին, ինչը համապատասխան 2.71 և 1.90 ԲԼԵՎ է աճում, համեմատած մեր զրոյից ուսուցման մոդելի հետ: Our final submission is an ensemble of these two models, further increasing 0.3 BLEU for Fr-De.', 'sq': 'This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation group.  The goal of the task is to translate German to French (De-Fr) and French to German (Fr-De).  Përdorimi ynë përqëndrohet në rregullimin e një modeli të paratrajnuar për të përfituar nga të dhënat monogjuhësore. Ne rregullojmë mBART50 duke përdorur të dhënat e filtruara, dhe shtesë, ne trajnojmë një model Transformer në të njëjtat të dhëna nga zero. Në eksperimentet, ne tregojmë se rregullimi i mBART50 rezultatet në 31.69 BLEU për De-Fr dhe 23.63 BLEU për Fr-De, që rrit 2.71 dhe 1.90 BLEU sipas kësaj, krahasuar me model in që trajnojmë nga zero. Përfaqja jonë përfundimtare është një ansambl i këtyre dy modeleve, duke rritur më tej 0.3 BLEU për Fr-De.', 'bn': 'এই পত্রিকাটি উইপিসি মেশিন অনুবাদ গ্রুপের দ্বারা উইএমটি ২০২১ সংবাদ অনুবাদ প্রদান করেছে। এই কাজের লক্ষ্য হচ্ছে জার্মান ফ্রেঞ্চ (ডি- ফ্রেঞ্চ) এবং ফরাসি থেকে জার্মান থেকে অনুবাদ করা। আমাদের উপস্থাপনা একটি প্রথম প্রশিক্ষিত মডেলের প্রতি মনোযোগ দিয়েছে মোনোলিভাষী তথ্যের সুবিধা নিতে। আমরা ফিল্টারের তথ্য ব্যবহার করে মিবার্টি৫০ সুন্দর ভাবে ট্রান্সফ্রান্সফার মডেল প্রশিক্ষণ করি। In the experiments, we show that fine-tuning mBART50 results in 31.69 BLEU for De-Fr and 23.63 BLEU for Fr-De, which increases 2.71 and 1.90 BLEU accordingly, as compared to the model we train from scratch.  আমাদের শেষ আত্মসমর্পণ হচ্ছে এই দুই মডেলের একটি উদাহরণ, আরো বৃদ্ধি হচ্ছে ফ্রি-ডির জন্য ০.', 'hr': 'Ovaj papir opisuje predavanje vijestima WMT 2021 zajedničkog zadatka skupine UPC uređaja za prevod. Cilj zadatka je prevoditi njemački na francuski (De-Fr) i francuski na njemački (Fr-De). Naša podnošenja usredotoči se na fino određivanje predobučenog modela da iskoristi monojezičke podatke. Potvrđujemo mBART50 s filtriranim podacima, i dodatno, treniramo model transformera na istim podacima od ogrebotine. U eksperimentima pokazujemo da je u usporedbi s model koji treniramo iz ogrebotine 31,69 BLEU-a za De-Fr i 23,63 BLEU-a za Fr-De, što odgovarajući povećava 2,71 i 1,90 BLEU-a. Naša posljednja predstava je kompleks ovih dva modela, dodatno povećavajući 0,3 BLEU za Fr-De.', 'az': "Bu kağıt WMT 2021 xəbər çevirisini UPC mašin çeviri qrupunun paylaşdığı işləri təsdiqləyib edir. Bu işin məqsədi Almanca Fransızca (De-Fr) və Fransızca Almanca (Fr-De) tərcümə etməkdir. Bizim təklifimiz monodil verilənlərin faydalanması üçün əvvəlcə təhsil edilmiş modeli düzəltməyə odaqlanır. Biz filtrləndirilmiş məlumatları kullanarak mBART50'i təmizləyirik. Sonra da, aynı məlumatlarda Transformer modelini təhsil edirik. Bu təcrübələrdə, biz de-Fr üçün 31,69 BLEU və Fra-De üçün 23,63 BLEU-nin sonuçlarını göstərdik ki, 2,71 və 1,90 BLEU-nin sonuçlarını çəkdiyimiz modeli ilə artırır. Bizim son təklifimiz bu iki modellərin körpüsüdür, Fr-De üçün 0.3 BLEU artırır.", 'cs': 'Tento článek popisuje podání do WMT 2021 sdíleného úkolu překladu zpráv skupinou Strojový překlad UPC. Cílem úkolu je překlad němčiny do francouzštiny (De-Fr) a francouzštiny do němčiny (Fr-De). Náš příspěvek se zaměřuje na jemné ladění předškoleného modelu tak, aby využíval výhod jednojjazyčných dat. MBART50 doladíme pomocí filtrovaných dat a navíc trénujeme model Transformeru na stejných datech od nuly. V experimentech jsme ukázali, že jemné ladění mBART50 má za následek 31.69 BLEU pro De-Fr a 23.63 BLEU pro Fr-De, což odpovídajícím způsobem zvyšuje 2.71 a 1.90 BLEU ve srovnání s modelem, který trénujeme od nuly. Naším závěrečným předložením je soubor těchto dvou modelů, který dále zvyšuje 0.3 BLEU pro Fr-De.', 'et': 'Käesolevas artiklis kirjeldatakse UPC masintõlke rühma poolt WMT 2021 uudiste tõlkimise ülesannet. Ülesande eesmärk on tõlkida saksa keelt prantsuse keelde (De-Fr) ja prantsuse keelt saksa keelde (Fr-De). Meie esitus keskendub eelnevalt koolitatud mudeli täpsustamisele, et kasutada ära ühekeelseid andmeid. Filtreeritud andmete abil häälestame mBART50 ja täiendavalt treenime Transformeri mudelit nullist peale samade andmete. Katsetes näitame, et mBART50 peenhäälestuse tulemuseks on 31,69 BLEU De-Fr ja 23,63 BLEU Fr-De, mis suurendab vastavalt 2,71 ja 1,90 BLEU võrreldes mudeliga, mida me nullist treenime. Meie lõplik esitus on nende kahe mudeli ansambel, suurendades veelgi 0,3 BLEU Fr-De jaoks.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvataan UPC:n konekﾃ､ﾃ､nnﾃｶsryhmﾃ､n jakamaa uutisten kﾃ､ﾃ､ntﾃ､mistﾃ､ WMT 2021 -ohjelmaan. Tehtﾃ､vﾃ､n tavoitteena on kﾃ､ﾃ､ntﾃ､ﾃ､ saksa ranskaksi (De-Fr) ja ranska saksaksi (Fr-De). Lﾃ､hetyksemme keskittyy esikoulutetun mallin hienosﾃ､ﾃ､tﾃｶﾃｶn monikielisen tiedon hyﾃｶdyntﾃ､miseksi. Tarkennamme mBART50:tﾃ､ suodatetun datan avulla ja lisﾃ､ksi harjoittelemme Transformer-mallia samoilla tiedoilla alusta alkaen. Kokeissa osoitetaan, ettﾃ､ hienosﾃ､ﾃ､tﾃｶ mBART50 tuottaa 31,69 BLEUn De-Fr:lle ja 23,63 BLEUn Fr-De:lle, mikﾃ､ kasvattaa vastaavasti 2,71 ja 1,90 BLEUn verrattuna nollasta kﾃ､sin harjoitettuun malliin. Lopullinen ehdotuksemme on nﾃ､iden kahden mallin kokonaisuus, joka lisﾃ､ﾃ､ entisestﾃ､ﾃ､n 0,3 BLEU Fr-De:lle.', 'ca': "This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation group.  L'objectiu de la tasca és traduir l'alemany al francès (De-Fr) i el francès a l'alemany (Fr-De). La nostra presentació es centra en ajustar un model pré-entrenat per aprofitar les dades monolingües. Afinem mBART50 fent servir les dades filtradas, i addicionalment entrenem un model Transformer amb les mateixes dades des de zero. In the experiments, we show that fine-tuning mBART50 results in 31.69 BLEU for De-Fr and 23.63 BLEU for Fr-De, which increases 2.71 and 1.90 BLEU accordingly, as compared to the model we train from scratch.  La nostra presentació final és un conjunt d'aquests dos models, augmentant més de 0,3 BLEU per Fr-De.", 'bs': 'Ovaj papir opisuje predavanje novinskog prevoda WMT 2021 podijeljenog zadatka skupine UPC mašinskih prevoda. Cilj zadatka je prevoditi njemački na francuski (De-Fr) i francuski na njemački (Fr-De). Naša podnošenja se fokusira na finaliziranje predobučenog modela da iskoristi monojezičke podatke. Potvrđujemo mBART50 sa filtriranim podacima, i dodatno, treniramo model Transformer a na istim podacima od ogrebotine. U eksperimentima, pokazujemo da je u usporedbi s modelom koji treniramo iz ogrebotine 31,69 BLEU za De-Fr i 23,63 BLEU za Fr-De, koji se odgovarajući povećava 2,71 i 1,90 BLEU. Naša poslednja predstava je kompleks ovih dva modela, dalje povećavajući 0,3 BLEU za Fr-De.', 'he': 'This paper describes the submission to the WMT 2021 news translation shared task by the UPC Machine Translation group.  המטרה של המשימה היא לתרגם גרמנית לצרפתית (De-Fr) וצרפתית לגרמנית (Fr-De). ההצגה שלנו מתמקדת בתיקון מודל מאומן מראש כדי לנצל נתונים monolingual. אנחנו מתאימים mBART50 באמצעות המידע המסונן, ובנוסף, אנחנו מאמן מודל טרנספורר על אותו נתונים מאפס. בניסויים, אנו מראים כי mBART50 מתאים יוצא ב 31.69 BLEU עבור De-Fr ו 23.63 BLEU עבור Fr-De, אשר מגביר 2.71 ו-1.90 BLEU בהתאם, בהשוואה לדוגמא שאנחנו מאמן מאפס. השימוש האחרון שלנו הוא אסמפל של שני הדוגמנים האלה, מגביר עוד 0.3 BLEU עבור Fr-De.', 'ha': '@ info: whatsthis Yagon aikin na is to translate Jarman to French (de- F) and French to Jarman (fr- de). MadagaskiyinMu yana muhalli wa tunkuɗe wani misali wanda aka yi wa zaman shirin da ya yi amfani da data masu mutane. @ info: whatsthis Aka cikin jarrabai, za mu nũna musamman mBarT50 matsala 31.69 BLEU wa de-FR da 23.63 BLEU wa fr-de, da za ta ƙara 2.71 da 1.90 BLEU kamar misalin mu na tsare daga skatch. Our final submission is an ensemble of these two models, further increasing 0.3 BLEU for Fr-De.', 'sk': 'Ta prispevek opisuje predložitev skupne naloge prevajanja novic WMT 2021 skupine UPC za strojno prevajanje. Cilj naloge je prevajanje nemščine v francoščino (De-Fr) in francoščine v nemščino (Fr-De). Naša predložitev se osredotoča na natančno nastavitev vnaprej usposobljenega modela za izkoriščanje enojezičnih podatkov. MBART50 natančno nastavimo z uporabo filtriranih podatkov in dodatno treniramo model transformatorja na istih podatkih od nič. V poskusih smo pokazali, da fino nastavitev mBART50 rezultat 31,69 BLEU za De-Fr in 23,63 BLEU za Fr-De, kar ustrezno poveča 2,71 in 1,90 BLEU v primerjavi z modelom, ki ga treniramo iz nič. Naša končna predložitev je komplet teh dveh modelov, ki dodatno povečuje 0,3 BLEU za Fr-De.', 'bo': 'ཤོག་བྱང་འདིས་WMT 2021་བརྡ་ཞིག་གི་ཆ་འཕྲིན་ལ་སྤྲོད་ཀྱི་ལས་འགུལ་རྒྱབ་སྐྱོར་བ་དེ་འགྲེལ་བཤད་ཡོད། དམིགས་ཡུལ་ནི་ཇར་མིན་ལ་སྐད་ཡིག་ཆའི་ནང་སྐད་ཡིག་ཆའི་ནང་སྐད་ཡིག་ཆེ། ང་ཚོའི་དབང་ཆ་ལྟ་བུའི་སྔོན་གྲངས་སྒྲིག་ཐབས་ལམ་ཞིག་ལས་མཐུན་རྐྱེན་བྱས་མེད་པའི་ཐབས་ལམ་ལ་དམིགས་བསལ་ཡོད།  We fine-tune mBART50 using the filtered data, and additionally, we train a Transformer model on the same data from scratch. experiments ནང་དུ་ངེད་ཚོའི་ནང་ནས་ mBART50་གི་མཐུན་རྐྱེན་བཟོ་བའི་རྣམ་པ་ཡིན། De-Fr དང་ 23.63 BLEU ཕྱི་རྣམ་པ་ཚོའི་རྣམ་པ་ལ་ཉེ་བར་མཚམས་འཇུག་ཡོད། དེ་ནས་ངེད་ཚོའི་མ་དཔེ་བཟོ་རྣམ་པས། མ་དཔ ང་ཚོའི་མཐའ་མཇུག་གི་མཇུག་གི་མིག་དཔེ་འདི་གཉིས་ཀྱི་རྣམ་པ་ཞིག', 'jv': 'Perintah iki rambarang nggawe tarjamahan kanggo nggambar bebas bakal ning banter nggawe gerasane nggawe kelompok, bakal ning upC Mas Terjamahan. Tarjamahan kanggo kelas kuwi Laymaning kanggo Perancis karo Perancis (de-Fra) karo Perancis kanggo kelas (Fra-de). Awakdhéwé nggunaké iku supok-tuning model sing wis nguasai luwih-luwih dumaten kanggo nggawe barang pengguna kuwi mau. Awak dhéwé wis rak-lak mBalt-5 digawe dadi sing nyimpen, lan tambah, dadi wis ngeralah, dadi Transformer kuwi model sing ngenggo dolanan sak dadi nyong lanjut Nang dhéwé éntuk éntuk sing paling-kaling nggambar mPART liman nganggo cara-cara nggawe lan ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol-ijol . Awak dhéwé sistem tukulah iki dadi sing larang sampek iki model, tambah liyane 0.3 B luwih kanggo Fra-de.'}
{'en': 'Mieind’s WMT 2021 Submission', 'ar': "تقديم Miðeind's WMT 2021", 'fr': 'Soumission WMT 2021 de Miðeind', 'es': 'Presentación del WMT 2021 de Miðeind', 'pt': 'Apresentação da Miðeind para o WMT 2021', 'ja': 'MiðeindのWMT 2021の提出物', 'hi': 'Miöeind का WMT 2021 सबमिशन', 'zh': 'MiðeindWMT 2021提交', 'ru': 'Представление Miðeind WMT 2021', 'ga': 'Aighneacht WMT 2021 ó Miðeind', 'ka': 'მიონდინდის WMT 2021-ის გარეშე', 'el': 'Υποβολή WMT 2021 του Mioeind', 'hu': 'Mioeind WMT 2021 benyújtása', 'it': 'Presentazione WMT 2021 di Mioeind', 'kk': "Mioeind' s WMT 2021 Submission", 'mk': 'ВМТ 2021 на Миоинд', 'ms': 'Submission WMT 2021 Mioeind', 'mt': 'Sottomissjoni WMT 2021 ta’ Mioeind', 'ml': 'മിയോയിന്\u200dറെ WMT 2021 സബ്മിഷന്\u200d', 'mn': 'Mioeind-ын WMT 2021-ийн даалгавар', 'pl': 'Zgłoszenie WMT 2021 firmy Mioeind', 'no': 'Mioeind sin WMT 2021 Submission', 'si': "Mioeind's WMT 2021 Sub-Mision", 'ro': 'Transmiterea WMT 2021 a lui Mioeind', 'sr': "Mioeind's WMT 2021 Submission", 'lt': 'Mioeind WMT 2021 pateikimas', 'sv': 'Mioeinds bidrag till WMT 2021', 'ta': "Mioeind's WMT 2021 Submission", 'ur': 'میوئینڈ کے WMT 2021 سرماشین', 'so': "Mioeind's WMT 2021 Submission", 'uz': 'Mioeind WMT 2021 Submission', 'vi': 'Quân đội quốc phòng Mioeind.', 'bg': 'Представяне на WMT 2021 на Mioeind', 'nl': 'WMT 2021 indiening van Mioeind', 'da': 'Mioeinds indsendelse af WMT 2021', 'hr': "Mioeind's WMT 2021 Submission", 'de': 'Mioeinds WMT 2021 Einreichung', 'fa': 'عمليات WMT 2021', 'sw': 'Ujumbe wa WMT 2021 wa Mioeind', 'ko': 'Mioeind 제출 WMT 2021', 'id': "Mioeind's WMT 2021 Submission", 'am': "Mioeind's WMT 2021 Submission", 'sq': "Dërgimi i Mioeind's WMT 2021", 'tr': "Mioeind's WMT 2021 Submission", 'bn': "Mioeind's WMT 2021 Submission", 'af': 'Mioeind se WMT 2021 Submission', 'bs': "Mioeind's WMT 2021 Submission", 'cs': 'Předložení WMT 2021 společnosti Mioeind', 'az': "Mioeind's WMT 2021 Submission", 'hy': "Mioeind's WMT 2021 Submission", 'fi': 'Mioeindin WMT 2021 -julkaisu', 'et': "Mioeind's WMT 2021 esitamine", 'ca': 'Submissió WMT 2021 de Mioeind', 'sk': 'Predložitev WMT 2021 Mioeind', 'ha': "MioyInd's WMT 2021 Submition", 'jv': "MIME's WT 2020 1 Subtask", 'bo': "Mioeind's WMT 2021 Submission", 'he': 'מוסר WMT 2021 של מיואינד'}
{'en': 'We present Mieind’s submission for the EnglishIcelandic and IcelandicEnglish subsets of the 2021 WMT news translation task. Transformer-base models are trained for ', 'ar': 'نقدم طلب Miðeind للمجموعات الفرعية الإنجليزية → الأيسلندية والأيسلندية → الإنجليزية لمهمة ترجمة الأخبار 2021 WMT. يتم تدريب نماذج قاعدة المحولات للترجمة على البيانات المتوازية لإنشاء ترجمات عكسية بشكل مكثف. يتم بعد ذلك تكييف نموذج mBART-25 الذي تم اختباره مسبقًا للترجمة باستخدام البيانات المتوازية بالإضافة إلى آخر تكرار للترجمة العكسية. ثم يتم استخدام هذا النموذج المعدَّل مسبقًا لإعادة إنشاء الترجمات العكسية ، ويستمر تدريب النموذج المعدَّل.', 'pt': 'Apresentamos a submissĂŁo de MiĂ°eind para os subconjuntos inglĂŞsâ†’islandĂŞs e islandĂŞsâ†’inglĂŞs da tarefa de traduĂ§ĂŁo de notĂ\xadcias do WMT 2021. Os modelos baseados em transformador sĂŁo treinados para traduĂ§ĂŁo em dados paralelos para gerar retrotraduĂ§Ăµes terativamente. Um modelo mBART-25 prĂ©-treinado Ă© entĂŁo adaptado para traduĂ§ĂŁo usando dados paralelos, bem como a Ăşltima iteraĂ§ĂŁo de retrotraduĂ§ĂŁo. Este modelo prĂ©-treinado adaptado Ă© entĂŁo usado para gerar novamente as retrotraduĂ§Ăµes e o treinamento do modelo adaptado Ă© continuado.', 'fr': "Nous présentons la soumission de Miðeind pour les sous-ensembles anglais→islandais et islandais→anglais de la tâche de traduction des actualités WMT 2021. Les modèles basés sur un transformateur sont entraînés pour la traduction sur des données parallèles afin de générer des rétrotraductions de manière itérative. Un modèle mBarT-25 préentraîné est ensuite adapté pour la traduction à l'aide de données parallèles ainsi que pour la dernière itération de rétrotraduction. Ce modèle préentraîné adapté est ensuite utilisé pour régénérer les backtranslations, et la formation du modèle adapté est poursuivie.", 'es': 'Presentamos la presentación de Miðeind para los subconjuntos inglés→islandés e islandés→inglés de la tarea de traducción de noticias del WMT 2021. Los modelos basados en transformadores están entrenados para la traducción de datos paralelos a fin de generar retrotraducciones iterativamente. A continuación, se adapta un modelo mBART-25 previamente entrenado para la traducción utilizando datos paralelos, así como la última iteración de retrotraducción. Este modelo adaptado previamente entrenado se utiliza para volver a generar retrotraducciones, y se continúa con el entrenamiento del modelo adaptado.', 'ja': '2021年WMTニュース翻訳タスクの英語→アイスランド語およびアイスランド語→英語サブセットのためのMiðeindの提出物を紹介します。トランスフォーマーベースモデルは、並列データの翻訳のために訓練され、驚異的に逆翻訳を生成します。次いで、事前に訓練されたｍＢＡＲＴ － ２ ５モデルを、並列データ及び最後の逆翻訳反復を使用して翻訳に適合させる。次いで、この適合させた事前訓練済みモデルを使用して、バック翻訳を再生成し、適合させたモデルの訓練を継続する。', 'zh': '言Miðeind为2021年WMT新闻翻译英语→冰岛语与冰岛语→英语子集交。 转换器之法,以并行数转之,以生反译。 然后并行数据及末回译迭代对预 mBART-25 模调之。 然后教之以重成回译,继之以应模形。', 'hi': 'हम 2021 WMT समाचार अनुवाद कार्य के अंग्रेजी→असीलैंडिक और आइसलैंडिक→अंगलिश सबसेट के लिए Miðeind के सबमिशन को प्रस्तुत करते हैं। ट्रांसफॉर्मर-बेस मॉडल को समानांतर डेटा पर अनुवाद के लिए प्रशिक्षित किया जाता है ताकि बैकट्रांसलेशन उत्पन्न किया जा सके। एक pretrained mBART-25 मॉडल तो समानांतर डेटा के रूप में के रूप में अच्छी तरह से अंतिम backtranslation पुनरावृत्ति का उपयोग कर अनुवाद के लिए अनुकूलित है. इस अनुकूलित pretrained मॉडल तो फिर से backtranslations उत्पन्न करने के लिए उपयोग किया जाता है, और अनुकूलित मॉडल के प्रशिक्षण जारी है.', 'ru': 'Мы представляем заявку Miðeind для английского→исландского и исландского→английских подмножеств задачи перевода новостей WMT 2021 года. Модели на основе трансформаторов обучены для перевода на параллельные данные, чтобы генерировать обратные преобразования в терапевтическом режиме. Предварительно обученную модель mBART-25 затем адаптируют для трансляции с использованием параллельных данных, а также последней итерации обратной трансляции. Эта адаптированная предварительно обученная модель затем используется для повторной генерации обратных трансляций, и обучение адаптированной модели продолжается.', 'ga': 'Cuirimid aighneacht Miðeind i láthair don fho-thacair Béarla → Íoslainnis agus Íoslainnis→ Béarla de thasc aistriúcháin nuachta WMT 2021. Cuirtear oiliúint ar mhúnlaí bunchlaochladáin le haistriú ar shonraí comhthreomhara chun aisaistrithe a ghiniúint go céimneach. Déantar samhail réamhoilte mBART-25 a oiriúnú ansin lena aistriú ag baint úsáide as sonraí comhthreomhara chomh maith leis an atriall ais-aistrithe deiridh. Úsáidtear an tsamhail réamhoilte oiriúnaithe seo ansin chun aisaistrithe a athghiniúint, agus leantar le hoiliúint an mhúnla oiriúnaithe.', 'ka': 'ჩვენ მივიონდის გადაწყენება ინგლისური და თლანდიური ინგლისური სუბუქტებისთვის, რომელიც 2021 წლის WMT ინგლისური გადაწყენება. Name mBART- 25 მოდელი შემდეგ გადაწყვეტილებისთვის პარალელი მონაცემების გამოყენება და შემდეგ შემდეგ შემდეგ შემდეგ გადაწყვეტილება. ეს ადაპტირებული მოდელი შემდეგ გამოყენება დაბრუნებისთვის, და აეპტირებული მოდელის განაკეთება გადასრულება.', 'el': 'Παρουσιάζουμε την υποβολή του για τα αγγλικά ισλανδικά και ισλανδικά αγγλικά υποσύνολα της εργασίας μετάφρασης ειδήσεων του 2021 WMT. Τα μοντέλα μετασχηματιστών-βάσης εκπαιδεύονται για τη μετάφραση σε παράλληλα δεδομένα για την παραγωγή μεταγραφικών μεταφράσεων τερατωδώς. Στη συνέχεια, ένα προσχεδιασμένο μοντέλο προσαρμόζεται για μετάφραση χρησιμοποιώντας παράλληλα δεδομένα καθώς και την τελευταία επανάληψη αντίστροφης μετάφρασης. Αυτό το προσαρμοσμένο προ-εκπαιδευμένο μοντέλο χρησιμοποιείται στη συνέχεια για την εκ νέου δημιουργία μεταγραφικών μεταφράσεων και συνεχίζεται η εκπαίδευση του προσαρμοσμένου μοντέλου.', 'hu': 'Bemutatjuk Mioeind beadványát a 2021-es WMT hírfordítási feladat angol izlandi és izlandi angol alcsoportjaira. A transzformátorbázis modelleket párhuzamos adatokon történő fordításra képezik, hogy a visszafordításokat teratív módon generálják. Az előkészített mBART-25 modellt ezután párhuzamos adatokkal és az utolsó visszafordítási iterációval adaptálják a fordításra. Ezt az adaptált előképzett modellt ezután visszafordítások újragenerálására használják, és folytatódik az adaptált modell képzése.', 'kk': '2021 WMT жаңалық аудару тапсырмасының ағылшын Исландиялық және Исландиялық ағылшын тілдеріне Майондың жіберілімін таңдаймыз. Трансформацияның негізгі үлгілері параллель деректерді аудару үшін теративті аудару үшін оқылған. Алдыңғы mBART- 25 үлгісі кейін параллель деректерді және соңғы ақпаратты қайталау үшін аудару үшін адаптацияланады. Бұл өзгертілген қайта аудармаларды құру үшін қолданылады, және адаптацияланған моделінің оқытуы жалғастырылады.', 'mk': 'Го претставуваме поднесувањето на Миоинд за англискиот исландски и исландски англиски подгрупи од задачата за превод на вестите на ВМТ 2021 година. Трансформски бази модели се обучени за превод на паралелни податоци за теративно генерирање на преводи. A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration.  Овој адаптиран предобучен модел потоа се користи за повторно генерирање на преведувања, а обуката на адаптираниот модел продолжува.', 'it': "Presentiamo la presentazione di Mioeind per i sottoinsiemi inglese islandese e islandese inglese del compito di traduzione delle notizie WMT 2021. I modelli Transformer-Base sono formati per la traduzione su dati paralleli per generare backtranslations teratamente. Un modello mBART-25 pre-addestrato viene quindi adattato per la traduzione utilizzando dati paralleli così come l'ultima iterazione di backtranslation. Questo modello pre-addestrato adattato viene poi utilizzato per ri-generare le backtranslations e la formazione del modello adattato è continuata.", 'ml': '2021 WMT വാര്\u200dത്ത വിവരങ്ങള്\u200d പരിഭാഷ പ്രവര്\u200dത്തിക്കുന്ന ഇംഗ്ലീഷ് ഇസ്ലാന്\u200dഡിക്കും ഇസ്ലാന്\u200dഡിക് ഇംഗ്ലീഷ് ആബ്ലിഷ്  ബാക്ക്\u200cട്രാന്\u200dസ്ട്രെന്\u200dഷന്\u200dസ് ടെരിവിറ്റീവില്\u200d നിര്\u200dമ്മിക്കുവാന്\u200d പാരാളില്\u200d ഡേറ്റായിട്ടുള്ള പരാലിയല്\u200d ഡാറ്റായും അവസാനത്തെ ബാക്കിന്റേഷനും ഉപയോഗിച്ചുകൊണ്ട് ഒരു പ്രത്യേകം ചെയ്ത mBART- 25 മോഡല്\u200d പിന്നീട് പരാജയപ പിന്നീട് വീണ്ടും ഭാഷകങ്ങള്\u200d ഉണ്ടാക്കുവാന്\u200d ഉപയോഗിക്കപ്പെടുന്ന ഈ മാതൃകയിലേക്കുള്ള പ്രദര്\u200dശനം തുടരുന്നു.', 'mn': 'Бид Mioeind-ын англи Исландийн, Исландийн Англи хэлний 2021 оны WMT мэдээллийн хөрөнгө оруулалтын даалгаврын даалгаврыг илтгэдэг. Transformer-base models are trained for translation on parallel data to generate backtranslations teratively. A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration. Энэ загварыг дахин хөгжүүлэхэд хэрэглэгддэг. Загварчлагдсан загварын дасгал хөгжүүлэхэд дахин хэрэглэгддэг.', 'no': 'Vi presenterer Mioeind sin s øknad til den engelske islandske og islandske engelske undergruppene av WMT-nyhetsverktålet 2021. Transformeringsbasemodeller vert trent for omsetjing på parallelle data for å laga tilbakeomsetjingar terativt. Eit mBART- 25- modell er derfor tilpassa for omsetjinga med parallelle data og siste tilbakeomsetjinga. Denne tilpassa modellen vert derfor brukt for å gjera tilbakeomsetjingar på nytt, og treninga av den tilpassa modellen vert fortsett.', 'pl': 'Przedstawiamy zgłoszenie Mioeind do podzbiorów angielskiego islandzkiego i islandzkiego angielskiego zadania tłumaczenia wiadomości WMT. Modele transformatorowe są przeszkolone do tłumaczenia na danych równoległych w celu teratycznego generowania tłumaczeń wstecznych. Wstępnie przeszkolony model mBART-25 jest następnie dostosowany do tłumaczenia za pomocą danych równoległych, jak również ostatniej iteracji backtranslation. Ten dostosowany wstępnie przeszkolony model jest następnie wykorzystywany do ponownego generowania tłumaczeń wstecznych, a szkolenie dostosowanego modelu jest kontynuowane.', 'ms': 'Kami perkenalkan penghantaran Mioeind untuk subkumpulan bahasa Inggeris Iceland dan Iceland dari tugas terjemahan berita WMT 2021. Model asas-pengubah dilatih untuk terjemahan pada data selari untuk menghasilkan terjemahan belakang secara teratif. Model mBART-25 terlatih dahulu kemudian disesuaikan untuk terjemahan menggunakan data selari serta iterasi terjemahan belakang terakhir. Model ini disesuaikan sebelum latihan digunakan untuk menghasilkan semula terjemahan belakang, dan latihan model disesuaikan terus dilanjutkan.', 'ro': 'Vă prezentăm depunerea lui Mioeind pentru subseturile engleză islandeză și islandeză din sarcina de traducere a știrilor WMT 2021. Modelele de bază transformatoare sunt instruite pentru traducerea pe date paralele pentru a genera traduceri înapoi terativ. Un model mBART-25 pre-instruit este apoi adaptat pentru traducere folosind date paralele, precum și ultima iterație de traducere înapoi. Acest model adaptat pre-instruit este apoi folosit pentru a re-genera traduceri înapoi, iar instruirea modelului adaptat este continuată.', 'lt': "We present Mioeind's submission for the English Icelandic and Icelandic English subsets of the 2021 WMT news translation task.  Transformuojantys baziniai modeliai rengiami vertimui lygiagrečiais duomenimis, kad būtų galima veiksmingai generuoti vertimus atgal. Tuomet iš anksto parengtas mBART-25 model is pritaikomas vertimui naudojant lygiagrečius duomenis ir paskutinį atgalinį vertimą kartojantį kartojimą. Tuomet šis pritaikytas išankstinio mokymo modelis naudojamas vėl generuojant grįžtamuosius vertimus ir tęsiamas pritaikyto modelio mokymas.", 'si': 'අපි මියෝයින්ඩ්ගේ ඉංග්\u200dරීස් අයිස්ලන්ඩික් සහ අයිස්ලන්ඩික් ඉංග්\u200dරීස් අයිස්ලන්ඩික් අයිස්ලන්ඩික්  Name Name මේ ප්\u200dරීට්\u200dරේන්ඩ් මොඩේල් එක පස්සේ පස්සේ පස්සේ වාර්තාවක් නිර්මාණය කරන්න භාවිත කරනවා, ඒ වගේම සැකසුම් ම', 'so': 'Waxan keenaynaa Mioeind warqadiisa ingiriisiga Icelandic and Icelandic subts of the 2021 WMT news translation mission. Tilmaamaha turjumaadda waxaa lagu baraa turjumista marka lagu baro macluumaadka lambarka ah si ay u sameeyaan turjubaan terativ. MBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration. Tusaaladan la beddelay waxaa lagu isticmaalaa in lagu soo celiyo turjubaan, waxbarashada modelka la beddelay ayaa sii soconaya.', 'sr': 'Predstavljamo Mioeindinu podnošenje engleskih islandskih i islandskih engleskih podnošenja zadatka za prevod novosti WMT 2021. godine. Модели трансформатора база су тренирани за превод на паралелни подати за производ теративно превода. Zatim se prilagođava model mBART-25 za prevod koristeći paralelne podatke, kao i poslednju iteraciju prevoda pozadine. Ovaj prilagođeni model se onda koristi za ponovno generiranje prevoda, a nastavlja se obuka prilagođenog modela.', 'sv': 'Vi presenterar Mioeinds bidrag för de engelska isländska och isländska engelska deluppsättningarna av WMT-nyhetsöversättningsuppgiften 2021. Transformerbasmodeller utbildas för översättning på parallella data för att generera bakåtöversättningar terativt. En förkränad mBART-25-modell anpassas sedan för översättning med parallella data samt den sista backtranslation iterationen. Denna anpassade förkränade modell används sedan för att återskapa bakåtöversättningar och utbildningen av den anpassade modellen fortsätter.', 'mt': "Aħna nippreżentaw is-sottomissjoni ta' Mioeind għas-sottosettijiet bl-Ingliż tal-Islanda u bl-Ingliż tal-Islanda tal-kompitu tat-traduzzjoni tal-aħbarijiet tal-2021 tad-WMT. Il-mudelli tal-bażi tat-trasformaturi huma mħarrġa għat-traduzzjoni fuq dejta parallela biex jiġġeneraw traduzzjonijiet retrospettivi b’mod terattiv. Imbagħad jiġi adattat mudell mBART-25 imħarreġ minn qabel għat-traduzzjoni bl-użu ta’ dejta parallela kif ukoll l-aħħar iterazzjoni ta’ traduzzjoni b’lura. Dan il-mudell adattat imħarreġ minn qabel imbagħad jintuża biex jerġa’ jiġġenera t-traduzzjonijiet lura, u t-taħriġ tal-mudell adattat jitkompla.", 'ta': '2021 WMT செய்தி மொழிபெயர்ப்பு பணியின் மீயோயின்ட் இங்கில்லாந்திக் மற்றும் ஐஸ்லாந்திக் ஆங்கிலத்தின் மீது கூ @ info: whatsthis @ info: whatsthis பின்பு மொழிபெயர்ப்புகளை மீண்டும் உருவாக்க பயன்படுத்தப்பட்டுள்ளது, மற்றும் ஏற்றுக் கொள்ளப்பட்ட மாதிரியின் பயிற', 'ur': 'ہم نے میئونڈ کی انگلیسی اسلاندی اور اسلاندی انگلیسی انگلیسی سوسٹوں کو 2021 WMT خبریں ترجمہ کا کام پیش کیا ہے. Name اس کے بعد مترجم کرنے کے لئے ایک پرٹرین mBART-25 موڈل اضافہ کی جاتی ہے اور آخری پچھلی ٹرینگ ٹرینگ ٹرینگ کے استعمال کے لئے۔ یہ اچھی طرح سے اچھی طرح کی مدل پھر پچھلی ترجمہ پیدا کرنے کے لئے استعمال کیا جاتا ہے، اور اچھی طرح کی مدل کی تعلیم ادامہ کی جاتی ہے.', 'uz': 'Biz 2021 WMT news tarjima vazifasi ingliz tilida Icelandcha va Icelandik ingliz tilining tub tarjimalari uchun Mioeind tilini taqdim qilamiz. @ info: whatsthis translation iteration Name', 'vi': 'Chúng tôi xin giới thiệu s ự chịu trách nhiệm của Mioeind cho the English Iceland và Iceland English subsnhóm của the 2021 WM Bây giờ dịch vụ. Các mô- đun biến hình được đào tạo để dịch trên dữ liệu song song để tạo bản dịch có thiệt hại. Một mẫu prerained m BART-25 được thích nghi để dịch bằng các dữ liệu song song cũng như lần bản dịch cuối cùng. This adapted prerained model is then used to tái tạo backtranslations, và đào tạo of the adapted model is continued.', 'bg': 'Представяме предложението на Миоинд за подразделенията на английски исландски и исландски английски език на задачата за превод на новини за 2021 г. Трансформаторните базови модели са обучени за превод на паралелни данни, за да генерират обратни преводи теративно. След това предварително трениран модел се адаптира за превод, използвайки паралелни данни, както и последната итерация на обратния превод. Този адаптиран предварително трениран модел се използва за повторно генериране на обратни преводи и обучението на адаптирания модел продължава.', 'da': 'Vi præsenterer Mioeinds indsendelse til de engelske islandske og islandske engelske undersæt af WMT-nyhedsoversættelsesopgaven 2021. Transformer-basemodeller er trænet til oversættelse på parallelle data for at generere tilbageførsler terativt. En forudtrænet mBART-25 model tilpasses derefter til oversættelse ved hjælp af parallelle data samt den sidste backtranslation iteration. Denne tilpassede prætrænede model bruges derefter til at gengenerere backtranslations, og træningen af den tilpassede model fortsættes.', 'hr': 'Predstavljamo Mioeind podatke za engleski islandski i islandski engleski podatke zadatka za prevod WMT novina 2021. godine. Modeli transformera baze obučeni su za prevod na paralelnim podacima kako bi terativno stvorili prevod pozadine. Zatim se prilagođava model mBART-25 za prevod koristeći paralelne podatke, kao i posljednju iteraciju prevoda pozadine. Ovaj prilagođeni model se onda koristi za ponovno proizvedenje prevoda, a nastavlja se obuka prilagođenog modela.', 'nl': "We presenteren Mioeind's inzending voor de Engels IJslands en IJslands Engels subsets van de 2021 WMT nieuws vertaaltaak. Transformer-basemodellen worden getraind voor vertaling op parallelle data om backtranslations teratief te genereren. Een vooraf getraind mBART-25 model wordt vervolgens aangepast voor vertaling met behulp van parallelle data en de laatste backtranslation iteratie. Dit aangepaste vooraf getrainde model wordt vervolgens gebruikt om backtranslations opnieuw te genereren en de training van het aangepaste model wordt voortgezet.", 'ko': 'Mioeind가 제출한 2021년 WMT 뉴스 번역 임무의 영어 아이슬란드어와 아이슬란드 영어 서브집을 제출했습니다.변압기 기초 모델은 훈련을 통해 병행 데이터에서 번역을 할 수 있고 교체 방식으로 반번역을 생성할 수 있다.그리고 병렬 데이터와 마지막 반역 교체를 사용하여 미리 훈련된 mBART-25 모델을 조정하여 번역한다.그리고 이 조정된 예비 훈련 모델을 사용하여 다시 번역을 생성하고 조정된 모델을 계속 훈련한다.', 'de': 'Wir präsentieren Mioeinds Einreichung für die englisch isländisch und isländisch-englisch Teilmengen der 2021 WMT Nachrichtenübersetzungsaufgabe. Transformatorbasierte Modelle werden für die Übersetzung auf parallelen Daten trainiert, um Rückübersetzungen terativ zu generieren. Anschließend wird ein vortrainiertes mBART-25 Modell für die Übersetzung mit parallelen Daten sowie der letzten Backtranslation Iteration adaptiert. Dieses angepasste, vortrainierte Modell wird dann verwendet, um Rückübersetzungen zu generieren und das Training des angepassten Modells wird fortgesetzt.', 'id': 'Kami mempersembahkan pengiriman Mioeind untuk subkelompok Inggris Icelandic dan Icelandic Inggris dari tugas terjemahan berita WMT 2021. Model Transformer-base dilatih untuk terjemahan pada data paralel untuk menghasilkan terjemahan belakang teratif. Model mBART-25 yang dilatih dahulu kemudian diadaptasi untuk terjemahan menggunakan data paralel serta iterasi terjemahan belakang terakhir. Model yang diadaptasi sebelum latihan ini kemudian digunakan untuk menghasilkan kembali terjemahan belakang, dan latihan model yang diadaptasi terus berlanjut.', 'fa': 'ما تسلیم مایویند را برای سوی انگلیسی اسلاندی و اسلاندی انگلیسی از وظیفه ترجمه خبری WMT ۲۰۱۲ پیشنهاد می\u200cکنیم. مدل\u200cهای پایه تغییر\u200cدهنده برای ترجمه بر داده\u200cهای پارالی برای تولید ترجمه پشتیبانی آموزش داده می\u200cشوند. یک مدل mBART- 25 پیش\u200cفرض برای ترجمه با داده\u200cهای parallel و آخرین ترجمه پشتیبانی adapted می\u200cشود. این مدل تغییر داده شده بعد از آن برای بازسازی ترجمه\u200cهای پشتی استفاده می\u200cشود و آموزش مدل تغییر داده ادامه می\u200cدهد.', 'sw': 'Tunawasilisha ujumbe wa Mioeind kwa ajili ya vipindi vya Kiingereza vya Icelandic na Icelandic Kiingereza vya kazi ya kutafsiri habari 2021 WMT. Mradi wa msingi wa zamani umefundishwa kwa kutafsiri takwimu za usambazaji ili kutengeneza tafsiri kwa sababu. Mfano wa mBART-25 unabadilishwa kwa kutafsiri kwa kutumia data za parallel pamoja na kifaa cha mwisho. Mfano huu uliobadilishwa na utafiti unatumiwa tena kutafsiri, na mafunzo ya muundo huo yanaendelea.', 'sq': 'Ne paraqesim paraqitjen e Mioeind për nëngrupet angleze islandeze dhe islandeze të detyrës s ë përkthimit të lajmeve WMT 2021. Modelet e transformuesve të bazës janë trajnuar për përkthimin e të dhënave paralele për të gjeneruar përkthimet mbrapsht në mënyrë terative. Një model mBART-25 i parastërvitur përshtatet pastaj për përkthimin duke përdorur të dhëna paralele si dhe iterimin e fundit të përkthimit mbrapsht. Ky model i përshtatur i parastërvitur përdoret pastaj për të rigeneruar përkthimet prapa dhe trajnimi i modelit të përshtatur vazhdon.', 'am': 'በ2021 WMT ዜና ትርጓሜ ስራ ለመንግሊዝኛ እና ለኢስላንድኛ እና ለኢስላንድ እንግሊዘኛ ጉዳዮችን ሚoeind አቀረብናል፡፡ ትርጉም translation iteration ይህ የተጠቃሚ ሞዴል በኋላም መግለጫ ለመፍጠር ይጠቀማል፡፡', 'az': "Biz Mioeind'in İngilizce İslandiya və İslandiya İngilizce ilahi təkrarlarına 2021 WMT haber tövsiyəsinin təkrarlayıcıs ı ilə təkrarlayırıq. Transformer-base modelləri paralel məlumatların çevirilməsi üçün təhsil edilir. Teratif çevirilməsi üçün təhsil edilir. Sonra paralel məlumatları və son tərcümə iterasını istifadə etmək üçün tərcümə edilən mBART-25 modeli uyğunlaşdırılır. Bu adapted pretrained modeli sonra geri çevirilmək üçün istifadə edilir, və adapted modeli təhsil sürüklənir.", 'bn': '২০২১ ডিউএমটি সংবাদ অনুবাদ কর্মসূচীর জন্য ইংরেজী আইস্লান্ডিক এবং ইসলান্ডিক ইংরেজি সাবটেটের মিয়োইন্ডের প্রতি উপস্ ব্যাকভাবে অনুবাদ তৈরি করার জন্য প্যারালেল ডাটায় অনুবাদের জন্য অনুবাদের ট্রান্সফার্নারের বেস মডেল প A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration.  পুনরায় ব্যাকভাবে অনুবাদ তৈরি করার জন্য এই আপডেট করা মডেলের প্রশিক্ষণ চলছে।', 'hy': "We present Mioeind's submission for the English Icelandic and Icelandic English subsets of the 2021 WMT news translation task.  Տանֆերմերների հիմնական մոդելները սովորեցված են զուգահեռ տվյալների թարգմանման համար, որպեսզի տերատիվ վերադարձություններ ստեղծեն: A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration.  Այս հարմարեցված նախադասավորված մոդելը հետո օգտագործվում է վերադարձ թարգմանություններ ստեղծելու համար, և հարմարեցված մոդելի վարժեքը շարունակվում է:", 'af': "Ons stel Mioeind se onderwerp voor die Engels Islandiese en Islandiese Engelse onderwerp van die 2021 WMT nuusvertalingstaak. Name 'n Pretrained mBART- 25 model is dan aanpas vir vertaling met parallele data en die laaste agtergrondtranslation iteration. Hierdie aanpasde pretreënde model word dan gebruik om terugvertalings te genereer, en die onderwerking van die aanpasde model word voortgaan.", 'bs': 'Predstavljamo Mioeind podnožbu za engleske islandske i islandske engleske podnožje za prijevod WMT novosti 2021. godine. Modeli transformera baze obučeni su za prevod na paralelnim podacima kako bi terativno stvorili prevod pozadine. Zatim se prilagođava model mBART-25 za prevod koristeći paralelne podatke, kao i posljednju iteraciju prevoda pozadine. Tada se ovaj prilagođeni pretkišni model koristi za ponovno generiranje povratnih prevoda, a nastavlja se obuka prilagođenog modela.', 'tr': "Biz Mioeind'iň Iňlisçe we Isländçe Iňlisçe jemgyýetlerini 2021-nji WBMT täzelikler terjime täzeliginiň jemgyýetlerini görkeýäris. Terjime terjime etmek üçin parallel maglumaty üçin terjime edilsin. Öňlerçe mBART-25 nusga we soňky terjime etmek üçin üýtgedildi. Bu ýakynlanan örän ýakynlanan nusga soňra arka terjimeleri döretmäge ullanýar we bu ýakynlanan nusga taýýarlanýar.", 'cs': 'Představujeme Mioeindův příspěvek pro podskupiny anglické islandské a islandské angličtiny v rámci úlohy překladu zpráv WMT. Transformátorové modely jsou trénovány pro překlad paralelních dat a generují zpětné překlady teraticky. Předtrénovaný model mBART-25 je pak upraven pro překlad pomocí paralelních dat a poslední iterace zpětného překladu. Tento adaptovaný předtrénovaný model je poté použit k opětovnému generování zpětných překladů a pokračuje ve školení adaptovaného modelu.', 'et': 'Esitleme Mioeindi esitlust 2021. aasta WMT uudiste tõlketöö inglise islandi ja islandi inglise alamrühmadele. Transformer-baasi mudelid on koolitatud tõlkimiseks paralleelsetele andmetele, et genereerida tagasitõlkeid teratiivselt. Seejärel kohandatakse eeltreenitud mBART-25 mudel tõlkimiseks paralleelsete andmete ja viimase tagasitõlkimise iteratsiooni abil. Seda kohandatud eeltreenitud mudelit kasutatakse seejärel tagasitõlkete taastamiseks ja kohandatud mudeli koolitust jätkatakse.', 'ca': "Presentam la presentació de Mioeind per als subgrups d'anglès islandès i islandès de la tasca de traducció de notícies WMT 2021. Els models de base transformadoras estan entrenats per traduir dades paralleles per generar traduccions inverses de manera terativa. Un model mBART-25 pré-entrenat es adapta per traducció utilitzant dades paralleles i l'última iteració de traducció inversa. Aquest model adaptat de pré-entrenament s'utilitza per a regenerar traduccions posteriors, i continua l'entrenament del model adaptat.", 'fi': 'Esittelemme Mioeindin ehdotuksen vuoden 2021 WMT:n uutiskäännöstyön englannin islanniksi ja islanniksi englanniksi -osioihin. Muuntajapohjaiset mallit on koulutettu kääntämään rinnakkain datan taaksekäännöksiä teratiivisesti. Tämän jälkeen esikäsitelty mBART-25-malli mukautetaan kääntämiseen rinnakkaistietojen sekä viimeisen takaisinkäännöksen iteraation avulla. Tätä mukautettua esikoulutettua mallia käytetään takaisinkäännösten tuottamiseen ja mukautetun mallin koulutusta jatketaan.', 'jv': 'Awak dhéwé mengko karo MIME sing berarti kanggo Kemerdekaan Inggris Isilan lan karo Gambaran Iilanggo sing berarti basa sing nggalakno bebasangan neng 2020 1 WWT translation translation Layout', 'he': "We present Mioeind's submission for the English Icelandic and Icelandic English subsets of the 2021 WMT news translation task.  Transformer-base models are trained for translation on parallel data to generate backtranslations teratively.  A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration.  המודל המתאים הזה משתמש לאחר מכן כדי ליצור מחדש תרגומות אחוריות, והאימון של המודל המתאים ממשיך.", 'sk': 'Predstavljamo Mioeindovo predstavitev za angleški islandski in islandski angleški podskupini prevajanja novic WMT 2021. Modeli transformatorske baze so usposobljeni za prevajanje na vzporednih podatkih za terativno ustvarjanje nazaj prevodov. Predtreniran model mBART-25 je nato prilagojen za prevod z uporabo vzporednih podatkov in zadnje ponovitve nazaj prevajanja. Ta prilagojeni predtrenirani model se nato uporablja za ponovno ustvarjanje nazaj prevodov in nadaljuje usposabljanje prilagojenega modela.', 'ha': "Tuna halatar da MioyInd'in da aka shigar wa English Icandan and Icandan English subs of the 2021 WMT news translation job. @ info: whatsthis translation item @ info: whatsthis", 'bo': 'ང་ཚོས་2021 WMT བརྡ་ཞིག་གི་ཚིག Transformer-base models are trained for translation on parallel data to generate backtranslations teratively. A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration. A pretrained mBART-25 model is then adapted for translation using parallel data as well as the last backtranslation iteration. This adapted pretrained model is then used to re-generate backtranslations, and the training of the adapted model is continued.'}
{'en': 'Allegro.eu Submission to WMT21 News Translation Task', 'pt': 'Allegro.eu Submissão para Tarefa de Tradução de Notícias do WMT21', 'ar': 'تقديم Allegro.eu إلى مهمة ترجمة الأخبار WMT21', 'fr': 'Soumission Allegro.eu au WMT21 News Translation Task', 'es': 'Envío de Allegro.eu a la tarea de traducción de noticias WMT21', 'ja': 'Allegro.eu WMT 21ニュース翻訳タスクへの送信', 'hi': 'WMT21 समाचार अनुवाद कार्य के लिए Allegro.eu सबमिशन', 'ru': 'Отправка Allegro.eu для выполнения задачи перевода новостей WMT21', 'zh': 'Allegro.eu śŹźšļ§WMT21śĖįťóĽŤĮĎ', 'ga': 'Allegro.eu Aighneacht chuig Tasc Aistriúcháin Nuachta WMT21', 'ka': 'ალვდპჲ. eu WMT21 ახალგაზომის გადაწყვეტის რაოდენობა', 'el': 'Άλεγρο. Υποβολή στο έργο μετάφρασης ειδήσεων WMT21', 'it': 'Allegro. eu Invio al WMT21 News Translation Task', 'hu': 'Allegro. eu Beküldés a WMT21 Hírek Fordítási feladata', 'kk': 'Аллегро. eu WMT21 жаңалық аудару тапсырмасына жіберу', 'ml': 'അല്ലെഗ്രോ. WMT21 വാര്\u200dത്ത വിവരങ്ങളുടെ ടാസ്കിലേക്ക് സബ്മിഷന്\u200d', 'mk': 'Allegro. Еу Пренесување на задачата за преведување на вести на WMT21', 'ms': 'Allegro. eu Submission to WMT21 News Translation Task', 'no': 'Allegro. eu Submission til WMT21 News Translation Task', 'lt': 'Allegro. eu Paskelbimas WMT21 naujienų vertimo darbui', 'ro': 'Allegro. eu Trimiterea la WMT21 News Translation Task', 'mn': 'Аллегро. eu WMT21 News Translation Task', 'si': 'ඇලෙග්\u200dරෝ. WMT21 වාර්තාව වාර්ථාව වැඩකට යවන්න', 'mt': 'Allegro. eu Sottomissjoni għal Xogħol ta’ Traduzzjoni tal-Aħbarijiet tad-WMT21', 'so': 'Allegro. eu Submission to WMT21 News Translation Task', 'sv': 'Allegro. eu Inlämning till WMT21 Nyheter Översättningsuppgift', 'ta': 'ஆல்கிரோ. WMT21 செய்தி மொழிபெயர்ப்பு பணி', 'ur': 'Allegro. eu Submission to WMT21 News Translation Task', 'pl': 'Allegro. eu Zgłoszenie do WMT21 News Translation Task', 'sr': 'Alegro. eu Submission to WMT21 News Translation Task', 'uz': 'Allegro. QNetworkAccessFileBackend', 'vi': 'Allegro! Thông tin về WM21', 'bg': 'Алегро. Изпращане в WMT21 задача за превод на новини', 'hr': 'Allegro. eu Submission to WMT21 News Translation Task', 'da': 'Allegro. eu Indsendelse til WMT21 Nyheder Oversættelsesopgave', 'nl': 'Allegro. eu Indiening aan WMT21 Nieuws Translation Task', 'de': 'Allegro. eu Einreichung bei WMT21 News Translation Task', 'fa': 'آلگرو eu Submission to WMT21 News Translation Task', 'sw': 'Allegro. eu Submission to WMT21 News Translation Task', 'ko': '쾌판EU가 WMT21에 제출한 뉴스 번역 임무', 'af': 'Allegro. eu Submission na WMT21 Nuus Vertaling Opdrag', 'sq': 'Allegro. eu Submission to WMT21 News Translation Task', 'id': 'Allegro. eu Submission to WMT21 News Translation Task', 'am': 'Allegro. የWMT21 ዜና ትርጉም ማድረግ', 'hy': 'Ալեգրո: ԵուՀ-ի ներկայացումը World MT21 նորությունների թարգմանման գործին', 'az': 'Allegro. WMT21 Haqq 칂eviri G칬nd톛rm톛si', 'bn': 'অ্যালেগ্রো। eu Submission to WMT21 News Translation Task', 'tr': 'Allegro. WMT21 Haýsy Terjime Görevi', 'bs': 'Alegro. eu Submission to WMT21 News Translation Task', 'fi': 'Allegro. eu Lähetys WMT21 News Translation Task', 'et': 'Allegro. eu Esitamine WMT21 uudiste tõlkimise ülesanne', 'ca': 'Allegro. eu Submission to WMT21 News Translation Task', 'cs': 'Allegro. eu Předání do WMT21 News Translation Task', 'ha': 'Allgreo. Submit to WMT21 News Translate Tasks', 'jv': 'Iki ngerti. e Submis kanggo WW1 Haji Terjamahan', 'sk': 'Allegro. eu Predložitev v WMT21 Prevajalska naloga novic', 'bo': 'ཆེ་ཆུང་དུ། eu Submission to WMT21 News Translation Task', 'he': 'Allegro. eu Submission to WMT21 News Translation Task'}
{'en': 'We submitted two uni-directional models, one for EnglishIcelandic direction and other for IcelandicEnglish direction. Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, ', 'pt': 'Apresentamos dois modelos unidirecionais, um para direĂ§ĂŁo inglĂŞsâ†’islandĂŞs e outro para direĂ§ĂŁo islandĂŞsâ†’inglĂŞs. Nosso sistema de traduĂ§ĂŁo de notĂ\xadcias Ă© baseado na arquitetura transformador grande, ele faz uso de filtragem de corpora, retrotraduĂ§ĂŁo e traduĂ§ĂŁo direta aplicada a dados paralelos e monolĂ\xadngues', 'ar': 'قدمنا نموذجين أحادي الاتجاه ، أحدهما للغة الإنجليزية ← الاتجاه الأيسلندي والآخر للاتجاه الأيسلندي ← الإنجليزي. يعتمد نظام ترجمة الأخبار لدينا على بنية المحولات الكبيرة ، فهو يستخدم تصفية المؤسسات والترجمة الخلفية والترجمة إلى الأمام المطبقة على البيانات المتوازية وأحادية اللغة على حد سواء', 'es': 'Presentamos dos modelos unidireccionales, uno para direcciĂłn inglĂ©sâ†’islandesa y otro para direcciĂłn islandesaâ†’inglĂ©s. Nuestro sistema de traducciĂłn de noticias se basa en la arquitectura de transformadores grandes, utiliza el filtrado de corpus, la traducciĂłn inversa y la traducciĂłn directa aplicadas a datos paralelos y monolingĂĽes por igual', 'fr': "Nous avons soumis deux modﾃｨles unidirectionnels, l'un pour la direction anglais竊段slandaise et l'autre pour la direction islandaise竊誕nglaise. Notre systﾃｨme de traduction de nouvelles est basﾃｩ sur l'architecture transformer-big, il utilise le filtrage des corpus, la rﾃｩtro-traduction et la traduction directe appliquﾃｩs aux donnﾃｩes parallﾃｨles et monolingues", 'ja': '片方向モデルを2つ提出しました。1つは英語の→アイスランド語の方向、もう1つはアイスランド語の→英語の方向です。当社のニュース翻訳システムは、変圧器-ビッグアーキテクチャに基づいており、パラレルおよびモノリンガルデータに適用されるコーポラルフィルタリング、バック翻訳、フォワード翻訳を使用しています', 'ru': 'Мы представили две однонаправленные модели, одна для английского→исландского направления и другая для исландского→английского направления. Наша система перевода новостей основана на архитектуре «большой трансформатор», она использует фильтрацию корпусов, обратный перевод и прямой перевод, применяемые как к параллельным, так и к одноязычным данным', 'zh': '二单向形,一以英语→冰岛,一以冰岛→英语。 吾新闻译系统于变压器大架构,其用语料库漉,反向译与正向译宜并行单语数', 'hi': 'हमने दो यूनि-डायरेक्शनल मॉडल प्रस्तुत किए, एक अंग्रेजी→असीलैंडिक दिशा के लिए और दूसरा आइसलैंडिक→अंगिलिश दिशा के लिए। हमारी समाचार अनुवाद प्रणाली ट्रांसफॉर्मर-बड़ी वास्तुकला पर आधारित है, यह कॉर्पोरेट फ़िल्टरिंग, बैक-ट्रांसलेशन और समानांतर और मोनोलिंगुअल डेटा पर समान रूप से लागू होने वाले आगे के अनुवाद का उपयोग करता है', 'ga': 'Chuireamar dhá mhúnla aontreoch isteach, ceann amháin don Bhéarla → treoir Íoslainnis agus an ceann eile don Íoslainnis → Béarla →. Tá ár gcóras aistriúcháin nuachta bunaithe ar ailtireacht an chlaochladáin mhóir, baineann sé úsáid as scagadh corpora, ais-aistriúchán agus aistriúchán ar aghaidh a chuirtear i bhfeidhm ar shonraí comhthreomhara agus aonteangacha araon.', 'el': 'Υποβάλαμε δύο μονοκατευθυνόμενα μοντέλα, ένα για αγγλική ισλανδική κατεύθυνση και άλλο για ισλανδική αγγλική κατεύθυνση. Το σύστημα μετάφρασης ειδήσεων μας βασίζεται στη μεγάλη αρχιτεκτονική μετασχηματιστών, χρησιμοποιεί φιλτραρίσματος σωμάτων, μεταγραφή και μεταγραφή προς τα εμπρός που εφαρμόζονται σε παράλληλα και μονογλωσσικά δεδομένα', 'ka': 'ჩვენ ორი ერთეთრექციონალური მოდელები, ერთი ინგლისური თლანდიული მიერდისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთ ჩვენი ახალგაზრულების შეტყობინება სისტემის დაბაზეულია ტრანფორმა-დიდი აქტიქტიქტურაზე, რომელიც კოპორატურის ფილტრინგის გამოყენება, შემდეგ შეტყობინება და გადატ', 'hu': 'Két egyirányú modellt küldtünk be, az egyiket az angol izlandi irányba, a másikat pedig az izlandi angol irányba. Hírfordító rendszerünk a transzformátor-nagy architektúrára épül, párhuzamos és egynyelvű adatokra egyaránt alkalmazott corpora szűrést, back-translation és forward fordítást használ.', 'mk': 'Испративме два уни-насоки модели, еден за англиска исландска насока и друг за исландска англиска насока. Нашиот систем за превод на вести е базиран на трансформаторската голема архитектура, користи корпора филтрирање, назад превод и напред превод аплициран на паралелни и монојазични податоци исто така', 'it': "Abbiamo presentato due modelli unidirezionali, uno per la direzione islandese inglese e l'altro per la direzione islandese inglese. Il nostro sistema di traduzione delle notizie si basa sull'architettura transformer-big, utilizza filtri corpora, back-translation e forward applicati a dati paralleli e monolingue", 'kk': 'Біз ағылшын тілінде екі бағытталған үлгі жібердік, біріншісі Исландия тілінде және біріншісі Исландия тілінде жібердік. Жаңалық аудару жүйесіміз үлкен архитектурасына негізделген. Бұл корпора сүзгілерін, қайта аудару және алғашқы аудару жүйесі параллелі және монолингілі деректерге сәйкес қолданы', 'lt': 'We submitted two uni-directional models, one for English Icelandic direction and other for Icelandic English direction.  Mūsų naujienų vertimo sistema grindžiama transformatoriaus didele architektūra, ji naudoja korpros filtravimą, grįžtamąjį vertimą ir išankstinį vertimą, taikomą lygiagretiems ir vienakalbiams duomenims.', 'mt': 'We submitted two uni-directional models, one for English Icelandic direction and other for Icelandic English direction.  Is-sistema tagħna tat-traduzzjoni tal-aħbarijiet hija bbażata fuq l-arkitettura kbira tat-trasformatur, tagħmel użu mill-filtrazzjoni corpora, traduzzjoni lura u traduzzjoni bil-quddiem applikata kemm għad-dejta parallela kif ukoll monolingwa', 'no': 'Vi sende to unidirektivne modeller, ein for engelsk islandsk retning og ein for islandsk engelsk retning. Det nye omsetjingssystemet er basert på transformeringsstor arkitektur. Det gjer bruk av korporfiltrering, tilbakeomsetjing og framført omsetjing som er brukt til parallelle og monospråk-data.', 'pl': 'Przedłożyliśmy dwa modele jednokierunkowe, jeden dla angielskiego kierunku islandzkiego i drugi dla islandzkiego kierunku angielskiego. Nasz system tłumaczenia wiadomości opiera się na architekturze transformatora, wykorzystuje filtrowanie korpusów, tłumaczenie wsteczne i tłumaczenie przednie stosowane zarówno do danych równoległych, jak i jednojęzycznych', 'ro': 'Am prezentat două modele unidirecționale, unul pentru direcția islandeză engleză și altul pentru direcția islandeză islandeză. Sistemul nostru de traducere a știrilor se bazează pe arhitectura transformator-big, utilizează filtrarea corporei, traducerea înapoi și traducerea înainte aplicată atât datelor paralele, cât și monolingve', 'ms': 'We submitted two uni-directional models, one for English Icelandic direction and other for Icelandic English direction.  Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, back-translation and forward translation applied to parallel and monolingual data alike', 'mn': 'Бид хоёр ганц загвар загварыг, нэгийг Англи хэлний Исландийн чиглэлд, нэгийг Исландийн Англи хэлний чиглэлд оруулсан. Бидний мэдээллийн хөрөнгө оруулах систем нь том архитектур дээр суурилсан. Энэ нь корпора сүзүүлэлтийг ашигладаг. Дараа нь хөрөнгө оруулах, хөрөнгө оруулах, параллел болон ганц хэл өгөгдлийн хувьд хэр', 'si': 'අපි ඉංග්\u200dරීස් අයිස්ලන්ඩික් පැත්තෙන් අයිස්ලන්ඩික් ඉංග්\u200dරීස් පැත්තෙන් අයිස්ලන්ඩ් අයිස්ලන්ඩ අපේ ආරංචික වාර්තාව පද්ධතිය පද්ධතිය ප්\u200dරමාණකය- ලොකු ස්ථාපනයේ අධාරණය කරනවා, ඒක කොර්පෝරා ෆිල්ටර් කරන්න, පසුපසු', 'so': 'Waxaannu u soo dhiibnay laba tusaalood oo hagaya afka Ingiriiska, mid u jeeda barashada Icelandika, mid kalena waxaan u dhiibnay hagitaanka Ingiriiska. Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, back-translation and forward translation applied to parallel and monolingual data alike', 'ml': 'നമ്മള്\u200d രണ്ടു യൂണിയനിര്\u200dദേശ മോഡലുകള്\u200d കൊടുത്തു, ഒന്ന് ഇംഗ്ലീഷ് ഇസ്ലാന്\u200dഡിക് വഴിയിലേക്കും, മറ്റൊന്ന് ഇസ്ല നമ്മുടെ വാര്\u200dത്ത പരിഭാഷ സിസ്റ്റം മാറ്റുന്നത്- വലിയ സ്ഥാനത്തിന്റെ അടിസ്ഥാനത്താണ്, അത് കോര്\u200dപ്പോര ഫില്\u200dട്രിങ്കല്\u200d ചെയ്യുന്നത്, പിന', 'ur': 'ہم نے انگلیسی ایسلندی کی دہشت کے لئے دو ایک دہشت موڈل بھیج دیئے اور ایک ایسلندی انگلیسی دہشت کے لئے۔ ہماری خبریں ترجمہ سیسٹم کی بنیادی ہے ترجمہ کرنے والی بڑی معماری پر، یہ کورپورا فیلٹرینگ، پیچھے ترجمہ اور آگے ترجمہ کا استعمال کرتا ہے جو سائل اور ایک زبان کے سامنے موجود ہے', 'sv': 'Vi skickade in två unidirectional modeller, en för engelsk isländsk riktning och en för isländsk engelsk riktning. Vårt nyhetsöversättningssystem bygger på transformatorstorarkitekturen och använder sig av korporafiltrering, bakåtöversättning och vidareöversättning som tillämpas på parallella och enspråkiga data.', 'ta': 'நாங்கள் இரண்டு திசை மாதிரிகளை கொடுத்தோம், ஒரு ஆங்கிலத்திற்கு ஐஸ்லாந்திக் திசைக்கு மற்றும் மற்றொரு ஐஸ் எங்கள் செய்தி மொழிபெயர்ப்பு அமைப்பு மாற்றுதல்- பெரிய அடிப்படையில் உள்ளது, அது கோர்போரா வடிகட்டி, மீண்டும் மொழிபெயர்ப்பு மற்றும் மொ', 'sr': 'Predložili smo dva jednosmjernog modela, jedan za islandsko pravo i drugi za islandsko englesko pravo. Naš novinski prevodni sistem je baziran na transformatorskoj arhitekturi, koristi filtriranje korporacije, prevod natrag i napredak primjenjen na paralelne i monojezičke podatke slično.', 'uz': 'Biz ikkita direktoriya modellarni, biri ingliz tilida Icelandik yoʻlni va boshqa Icelandik ingliz tilidagi tizimga qoʻllab berdik. @ info: whatsthis', 'vi': 'Chúng tôi đã gửi hai mô- đun chi hướng, một cho hướng Anh-lan và một cho hướng Anh-lan. Hệ thống dịch tin tức của chúng tôi dựa trên kiến trúc máy biến lớn, nó sử dụng cả hệ thống lọc cơ thể, dịch ngược và dịch chuyển trước được áp dụng cho dữ liệu song song và độc ngôn.', 'bg': 'Представихме два еднопосочни модела, един за английска исландска посока и друг за исландска посока. Нашата система за превод на новини се основава на архитектурата трансформатор-голям, тя използва филтриране на корпоративни корпуси, обратен превод и напред превод, прилагани както към паралелни, така и едноезични данни', 'da': 'Vi indsendte to ensrettede modeller, en for engelsk islandsk retning og en anden for islandsk engelsk retning. Vores nyhedsoversættelsessystem er baseret på transformer-big arkitektur, det gør brug af corpora filtrering, back-translation og fremad oversættelse anvendt til parallelle og ensprogede data', 'id': 'Kami mengirim dua model satu arah, satu untuk arah Inggris Islandia dan yang lain untuk arah Inggris Islandia. Sistem terjemahan berita kami berdasarkan arsitektur besar-transformator, menggunakan penyaringan corpora, terjemahan belakang dan terjemahan maju yang diterapkan untuk data paralel dan monobahasa sama', 'de': 'Wir haben zwei unidirektionale Modelle eingereicht, eines für englisch isländische Richtung und eines für isländisch-englische Richtung. Unser Nachrichtenübersetzungssystem basiert auf der Transformatorarchitektur und nutzt Korporafilterung, Rückübersetzung und Vorwärtsübersetzung für parallele und einsprachige Daten gleichermaßen', 'fa': 'ما دو مدل یک مسیر فرستادیم، یکی برای مسیر اسلاندی انگلیسی و دیگری برای مسیر انگلیسی اسلاندی. سیستم ترجمه خبری ما بر اساس معماری بزرگ تغییر دهنده استفاده از فیلترینگ شرکت، ترجمه پشتی و ترجمه پیش از آن برای داده های پارالی و یک زبان شبیه استفاده می کند', 'sw': 'Tulifanya mifano miwili yenye uongozi, moja kwa mwelekeo wa Kiingereza wa Iceland na mwingine kwa muelekeo wa Kiingereza. Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, back-translation and forward translation applied to parallel and monolingual data alike', 'hr': 'Predložili smo dvije jednosmjerne modele, jedne za islandski smjer i druge za islandski engleski smjer. Naš sustav prevoda vijesti se temelji na transformatorskoj arhitekturi, koristi filtriranje korporacije, prevod natrag i naprijed primjenjen na paralelne i monojezičke podatke slično.', 'nl': 'We hebben twee uni-directionele modellen ingediend, één voor Engelse IJslandse richting en een ander voor IJslandse Engelse richting. Ons nieuws vertaalsysteem is gebaseerd op de transformator-grote architectuur, het maakt gebruik van corporafiltering, back-translation en forward translation toegepast op zowel parallelle als eentalige gegevens', 'af': 'Ons het twee unidireksionale modele voorgestuur, een vir Engels Islandiese rigting en ander vir Islandiese Engelse rigting. Ons nuusvertalingsstelsel is gebaseer op die transformer-groot arkitektuur, dit maak gebruik van korpora filtering, terugvertaling en vorentoe vertaling wat aangepas word na parallele en monolinglike data lyk', 'ko': '우리는 두 개의 단방향 모델을 제출했는데 하나는 영어 아이슬란드어 방향이고 다른 하나는 영어 아이슬란드어 방향이다.Google 뉴스 번역 시스템은transformer big 구조를 바탕으로 자료 라이브러리 필터, 번역, 전역을 평행과 단어 데이터에 적용합니다', 'am': 'ሁለትን የኢስላንድኛ መንገድ እና አንዱን ለኢስላንድኛ መንገድ አንዱንም ለኢስላንድኛ እንግሊዘኛ መንገድ አቀረብን፡፡ የዜና ትርጓሜያችን ስርዓት በመለወጥ ትልቁ መሠረት ላይ ነው፣ የኮርፖራ አጣራ፣ የጀርባ ትርጓሜ እና የፊደል ትርጓሜ በማስተካከል እና በሞሎግልቋል ዳታዎችን በመጠቀም ይጠቅማል፡፡', 'tr': 'Biz iki bölek nusga gönderdik, bir iňlisçe iňlisçe görnüşler we bir iňlisçe görnüşler we bir iňlisçe görnüşler bilen gönderdik. Täzeliklerimiz terjime sistemimiz uly arhitektura daýanýar. Bu iş korpora filtrelemesini, arka terjime we öňe-täzeliklerimizi parallel we monodil maglumatlara uygulanýar.', 'az': 'Biz iki t톛k t톛r톛fli modeli t톛yin etdik, birini 캻ngilizce 캻slandiya t톛r톛fl톛rin톛 v톛 dig톛rini 캻slandiya 캻ngilizce t톛r톛fl톛rin톛 t톛yin etdik. Bizim x톛b톛rl톛r t톛rc칲m톛 sistemimiz b칲y칲k arhitektura dayanan, korpora filtrl톛m톛sini, arxa 칞evirimi v톛 칬n 칞evirimi paralel v톛 monodil veril톛r kimi istifad톛 edir.', 'sq': 'Ne paraqitëm dy modele njëdrejtimi, një për drejtimin anglez islandez dhe një tjetër për drejtimin islandez anglez. Sistemi ynë i përkthimit të lajmeve është bazuar në arkitekturën e madhe të transformuesit, që përdorë filtrimin e corporës, përkthimin mbrapa dhe përkthimin përpara të aplikuar në të dhënat paralele dhe monogjuhësore si', 'hy': 'Մենք ներկայացրեցինք երկու մեկ ուղղությամբ մոդել, մեկը անգլերեն իսլանդական ուղղությամբ և մյուսը իսլանդական անգլերեն ուղղությամբ: Մեր նորությունների թարգմանման համակարգը հիմնված է թարգմանիչ-մեծ ճարտարապետության վրա, այն օգտագործում է կոպորա ֆիլտրումը, հետադարձ թարգմանումը և առաջին թարգմանումը, որոնք կիրառվում են զուգահեռ և միալեզու տվյա', 'bs': 'Predložili smo dva jednosmjernog modela, jedan za islandski smjer, a drugi za islandski engleski smjer. Naš novinski sustav prevoda se temelji na transformaciji velikoj arhitekturi, koristi filtriranje korporacije, prevod natrag i napredak primjenjen na paralelne i monojezičke podatke slično.', 'bn': 'আমরা দুটি ইউনিডিয়াল মডেল জমা দিয়েছি, একটি ইংরেজী ইসলান্দিকের দিকে এবং অন্যটি ইসলাম্যান্ডিক ইংরেজি দিকে দিয় আমাদের সংবাদ অনুবাদ সিস্টেম পরিবর্তনের বিশাল কাঠামোর উপর ভিত্তিক, এটি কোর্পোরা ফিল্টারিং, পেছন-অনুবাদ এবং সামনে অনুবাদের ব্যবহার করে একই', 'cs': 'Předložili jsme dva jednosměrné modely, jeden pro anglický islandský směr a druhý pro islandský směr. Náš systém překladu zpráv je založen na transformátorové architektuře, využívá filtrování korpusů, zpětného překladu a předpřekladu aplikovaného na paralelní i jednojjazyčná data', 'et': 'Esitasime kaks ühesuunalist mudelit, üks inglise islandi suunas ja teine islandi inglise suunas. Meie uudiste tõlkesüsteem põhineb transformator-big arhitektuuril, see kasutab korpuste filtreerimist, tagasitõlkimist ja edasitõlkimist, mida rakendatakse paralleelsetele ja ühekeelsetele andmetele.', 'ca': "Vam presentar dos models unidireccionals, un per a la direcció islàndica anglesa i un altre per a l'anglès islàndic. Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, back-translation and forward translation applied to parallel and monolingual data alike", 'fi': 'Toimitimme kaksi yksisuuntaista mallia, joista toinen englanniksi islanniksi ja toinen islanniksi englanniksi. Uutiskirjestelmämme perustuu transformator-big-arkkitehtuuriin, se hyödyntää korpussuodatusta, back-translaatiota ja eteenpäin kääntämistä, joita sovelletaan rinnakkaisiin ja monikielisiin tietoihin.', 'jv': 'Awak dhéwé mulai model sing sampeyan uni-direction, sing sampeyan kanggo ngerasahan ingkang Iwak lan basa sing itlanjut kiye basa Inggris. Sistem wartané sing dibenakake karo architecture sing buk-buk, dadi wis nggawe barang kelas coropo, mulai terjamahan lan mulai terjamahan kanggo nyengkuyung kanggo data yang karo perusahaan karo ingkang sampeyan.', 'ha': 'Mun sami misãlai biyu masu shirya da uni, ɗayan zuwa shirin Ingiriya, da ɗayan zuwa shirin Ingiriya na lsandaki. @ info: tooltip', 'bo': 'ང་ཚོས་དབྱིན་ཡིག་གི་སྣེ་ཚོགས་གཅིག་གཤམ་དབྱེ་བ་གཉིས་ཀྱི་ནང་དུ་སྐྱེས་པ་ཡིན། Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, back-translation and forward translation applied to parallel and monolingual data alike', 'he': 'We submitted two uni-directional models, one for English Icelandic direction and other for Icelandic English direction.  Our news translation system is based on the transformer-big architecture, it makes use of corpora filtering, back-translation and forward translation applied to parallel and monolingual data alike', 'sk': 'Predložili smo dva enosmerna modela, enega za angleško islandsko smer in drugega za islandsko angleško smer. Naš sistem prevajanja novic temelji na transformator-big arhitekturi, uporablja filtriranje korpusov, retroprevajanje in naprej prevajanje, ki se uporablja tako za vzporedne kot enojezične podatke'}
{'en': 'Illinois Japanese   English News Translation for WMT 2021', 'fr': 'Illinois Japanese ↔ Traduction de nouvelles en anglais pour WMT 2021', 'pt': 'Illinois Japonês ↔ Inglês Tradução de Notícias para o WMT 2021', 'ar': 'ترجمة إلينوي اليابانية للأخبار الإنجليزية لـ WMT 2021', 'es': 'Illinois Japanese ↔ Traducción de noticias en inglés para el WMT 2021', 'zh': '伊利诺伊州日语↔英语新闻翻译 WMT 2021', 'ja': 'WMT 2021のためのイリノイ州日本語↔英語ニュース翻訳', 'ru': 'Перевод новостей с японского на ↔ английский для WMT 2021', 'hi': 'इलिनोइस जापानी ↔ अंग्रेजी समाचार WMT 2021 के लिए अनुवाद', 'ga': 'Illinois Japanese ↔ English News Aistriúchán do WMT 2021', 'ka': 'Name', 'el': 'Ιλινόις Ιαπωνικά Αγγλικά Μετάφραση ειδήσεων για WMT 2021', 'hu': 'Illinois japán angol híradó fordítás WMT 2021', 'kk': 'WMT 2021- ге Иллинойс жапон және ағылшын жаңалық аудармасы', 'lt': 'Illinois Japanese   English News Translation for WMT 2021', 'mk': 'Illinois Japanese   English News Translation for WMT 2021', 'ml': 'എലിലിനോയിസ് ജപ്പാനീസ്- ഇംഗ്ലീഷ് വാര്\u200dത്തയുടെ വിവരങ്ങള്\u200d', 'mt': 'Illinois Ġappuniż - Traduzzjoni tal-Aħbarijiet Ingliżi għad-WMT 2021', 'it': 'Illinois Giapponese Inglese News Traduzione per WMT 2021', 'pl': 'Illinois Japoński Angielski Wiadomości Tłumaczenie dla WMT 2021', 'ms': 'Jepun Illinois Terjemahan Berita Inggeris untuk WMT 2021', 'sr': 'Ilinois Japanski „Engleski novinski prevod za WMT 2021 „', 'si': 'Name', 'so': 'Illinois Japanese /Turjumista Ingiriis News for WMT 2021', 'mn': 'Иллинойс Япон', 'no': 'Illinois Japansk & # 160; English News Translation for WMT 2021', 'ro': 'Illinois Japoneză Engleză Traducere de știri pentru WMT 2021', 'sv': 'Illinois Japansk Engelska Nyheter Översättning för WMT 2021', 'ur': 'ایلینویس جاپانی ۔انگلیسی نیویس ترجمہ WMT 2021 کے لئے', 'ta': 'ইলிலினோயிஸ் ஜப்பானிஸ்- WMT 2021 க்கு ஆங்கிலம் செய்தி மொழிபெயர்ப்பு', 'vi': 'Illinois Japanese English News Translation for WRT 2021', 'uz': 'Illinois Japoniyasi - WMT 2021 uchun Inglizcha News tarjima', 'da': 'Illinois Japansk Engelsk Nyhedsoversættelse til WMT 2021', 'nl': 'Illinois Japans Engels Nieuws Vertaling voor WMT 2021', 'bg': 'Илинойс превод на японски английски новини за WMT 2021', 'de': 'Illinois Japanisch Englisch Nachrichten Übersetzung für WMT 2021', 'hr': 'Illinois japanski “ Engleski novinski prevod za WMT 2021', 'sw': 'Kijapani wa Illinois \\ Tafsiri ya Habari ya Kiingereza kwa ajili ya WMT 2021', 'ko': '일리노이 WMT 2021 영문 뉴스 번역', 'id': 'Illinois Japanese   English News Translation for WMT 2021', 'fa': 'ایلینویس ژاپنی \u200cترجمه خبرهای انگلیسی برای WMT 2021', 'am': 'Illinois Japanese   English News Translation for WMT 2021', 'tr': 'Illinois Japonça “ Iňlisçe Haýsy terjime WMT 2021 üçin', 'hy': 'Illinois Japanese   English News Translation for WMT 2021', 'sq': 'Illinois Japanese · English News Translation for WMT 2021', 'af': 'Illinois Japanse & # 160; Engelse Nuus Vertaling vir WMT 2021', 'bn': 'ইলিনোনিজ জাপানি - ইংরেজী সংবাদ অনুবাদ', 'az': 'Illinois Japonca “ WMT 2021 üçün İngiliz Haber Çeviri', 'et': 'Illinois Jaapani inglise uudiste tõlge WMT 2021 jaoks', 'bs': 'Illinois Japanski “ Engleski novinski prevod za WMT 2021', 'ca': 'Illinois Japanese   English News Translation for WMT 2021', 'fi': 'Illinois Japanin Englanti Uutiset Käännös WMT 2021', 'cs': 'Illinois Japonština Angličtina Překlad zpráv pro WMT 2021', 'sk': 'Illinois Japonski angleški prevod novic za WMT 2021', 'he': 'אילינוי יפני תורגם על ידי WMT 2021', 'jv': 'Ibombe Hapon  Perverses Inggris kanggo WêT 2020 1', 'ha': '@ item Spelling dictionary', 'bo': 'Illinois Japanese ། English News Translation for WMT 2021'}
{'en': 'This system paper describes an end-to-end NMT pipeline for the Japanese   English news translation task as submitted to WMT 2021, where we explore the efficacy of techniques such as tokenizing with language-independent and language-dependent tokenizers, normalizing by orthographic conversion, creating a politeness-and-formality-aware model by implementing a tagger, back-translation, model ensembling, and n-best reranking. We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models. The preprocessed corpora are trained with a Transformer neural network model. We found that combining various techniques described herein, such as language-independent BPE tokenization, incorporating politeness and formality tags, model ensembling, n-best reranking, and back-translation produced the best translation models relative to other experiment systems.', 'es': 'Este documento del sistema describe una canalización de NMT de extremo a extremo para la tarea de traducción de noticias en japonés ↔ inglés presentada al WMT 2021, donde exploramos la eficacia de técnicas como la tokenización con tokenizadores independientes del idioma y dependientes del idioma, la normalización mediante conversión ortográfica, la creación de un modelo consciente de la cortesía y la formalidad mediante la implementación de un etiquetador, traducción inversa, ensamblaje de modelos y reclasificación n-best. Utilizamos corpus paralelos proporcionados por los organizadores del WMT 2021 para la capacitación, y los datos de desarrollo y pruebas del WMT 2020 para la evaluación de diferentes modelos de experimentos. Los cuerpos preprocesados se entrenan con un modelo de red neuronal Transformer. Descubrimos que la combinación de varias técnicas descritas en el presente documento, tales como la tokenización de BPE independiente del idioma, la incorporación de etiquetas de cortesía y formalidad, el ensamblaje de modelos, la clasificación n-mejor y la traducción inversa produjeron los mejores modelos de traducción en relación con otros sistemas experimentales.', 'pt': 'Este documento do sistema descreve um pipeline NMT de ponta a ponta para a tarefa de tradução de notícias em japonês ↔ inglês, conforme submetido ao WMT 2021, onde exploramos a eficácia de técnicas como tokenização com tokenizers independentes e dependentes de idioma, normalizando por conversão ortográfica , criando um modelo com reconhecimento de polidez e formalidade implementando um tagger, tradução reversa, conjunto de modelos e reclassificação n-best. Usamos corpora paralelos fornecidos pelos organizadores do WMT 2021 para treinamento e dados de desenvolvimento e teste do WMT 2020 para avaliação de diferentes modelos de experimentos. Os corpora pré-processados são treinados com um modelo de rede neural Transformer. Descobrimos que a combinação de várias técnicas descritas aqui, como tokenização BPE independente de idioma, incorporação de etiquetas de polidez e formalidade, conjunto de modelos, n-melhor reclassificação e tradução reversa produziu os melhores modelos de tradução em relação a outros sistemas de experimentos.', 'ar': 'تصف ورقة النظام هذه خط أنابيب NMT من النهاية إلى النهاية لمهمة ترجمة الأخبار اليابانية إلى الإنجليزية كما تم تقديمها إلى WMT 2021 ، حيث نستكشف فعالية تقنيات مثل الترميز باستخدام الرموز المميزة المستقلة عن اللغة والمعتمدة على اللغة ، والتطبيع عن طريق التحويل الهجائي ، وإنشاء نموذج مدرك للأدب والشكليات من خلال تنفيذ علامة ، والترجمة الخلفية ، وتجميع النماذج ، وإعادة الترتيب الأفضل. نحن نستخدم المجموعات الموازية التي يوفرها منظمو WMT 2021 للتدريب ، وبيانات التطوير والاختبار من WMT 2020 لتقييم نماذج التجارب المختلفة. يتم تدريب المجموعات المُجهزة مسبقًا باستخدام نموذج الشبكة العصبية المحولات. وجدنا أن الجمع بين التقنيات المختلفة الموصوفة هنا ، مثل رموز BPE المستقلة عن اللغة ، ودمج العلامات الشكلية والتأدب ، وتجميع النماذج ، وإعادة الترتيب الأفضل ، والترجمة العكسية أنتج أفضل نماذج الترجمة بالنسبة لأنظمة التجارب الأخرى.', 'fr': "Ce document système décrit un pipeline NMT de bout en bout pour la tâche de traduction de nouvelles en japonais ↔ en anglais tel que soumis au WMT 2021, dans lequel nous explorons l'efficacité de techniques telles que la tokenisation avec des tokeniseurs indépendants et dépendants de la langue, la normalisation par conversion orthographique, la création d'un modèle conscient de la politesse et de la formalité en mettant en œuvre un tagger, une rétro-traduction, un assemblage de modèles et un nouveau classement n-best. Nous utilisons des corpus parallèles fournis par les organisateurs du WMT 2021 pour la formation, ainsi que les données de développement et de test du WMT 2020 pour l'évaluation de différents modèles d'expériences. Les corpus prétraités sont entraînés avec un modèle de réseau neuronal Transformer. Nous avons découvert que la combinaison de diverses techniques décrites ici, telles que la segmentation BPE indépendante de la langue, l'incorporation de balises de politesse et de formalité, l'assemblage de modèles, le re-classement n-best et la rétro-traduction produisait les meilleurs modèles de traduction par rapport à d'autres systèmes expérimentaux.", 'ja': '本システム論文では、WMT 2021に提出された日本語から↔英語へのニュース翻訳タスクのエンドツーエンドのNMTパイプラインについて説明し、そこでは、言語に依存しないトーナライザーと言語に依存しないトーナライザーでのトークン化、オルソグラフィー変換による正規化、タガーの実装による丁寧さと形式意識モデルの作成、逆翻訳、モデルアンサンブル、nベストリランキングなどのテクニックの有効性を探る。WMT 2021主催者から提供された平行コーパスをトレーニングに使用し、WMT 2020の開発およびテストデータをさまざまな実験モデルの評価に使用します。前処理されたコーパスは、トランスフォーマーのニューラルネットワークモデルで訓練されています。言語に依存しないBPEトークン化、丁寧さと形式タグの組み込み、モデルアンサンブル、n - best reranking、および逆翻訳など、本明細書に記載される様々な技術を組み合わせることで、他の実験システムと比較して最適な翻訳モデルが生成されることを見出した。', 'zh': '本统论文述交WMT 2021之日语↔英语新闻翻译务端到端NMT管道,其间讨论语言无关而依于语言之标器,正字转规范化,因成标器,反向译者,模形集成和n-best更立礼貌感知模形之功。 以WMT 2021组织者教之,以语料库教之,以WMT 2020发测试数据,以质实验形。 预处理之语料库用Transformer神经网络模形训练。 臣等所见,合本述术,如语言无关BPE标,礼貌标签,模形融合,n-best重名反译,生于实验统之最。', 'hi': 'यह सिस्टम पेपर जापानी ↔ अंग्रेजी समाचार अनुवाद कार्य के लिए एक एंड-टू-एंड एनएमटी पाइपलाइन का वर्णन करता है जैसा कि डब्ल्यूएमटी 2021 में प्रस्तुत किया गया है, जहां हम भाषा-स्वतंत्र और भाषा-निर्भर टोकनाइज़र के साथ टोकनाइज़िंग, ऑर्थोग्राफिक रूपांतरण द्वारा सामान्यीकरण, एक टैगर, बैक-ट्रांसलेशन, मॉडल ensembling, और n-best reranking को लागू करके एक विनम्रता-और-औपचारिकता-जागरूक मॉडल बनाने जैसी तकनीकों की प्रभावकारिता का पता लगाते हैं। हम प्रशिक्षण के लिए डब्ल्यूएमटी 2021 आयोजकों द्वारा प्रदान किए गए समानांतर कॉर्पोरेट का उपयोग करते हैं, और विभिन्न प्रयोग मॉडलों के मूल्यांकन के लिए डब्ल्यूएमटी 2020 से विकास और परीक्षण डेटा का उपयोग करते हैं। Preprocessed corpora एक ट्रांसफॉर्मर तंत्रिका नेटवर्क मॉडल के साथ प्रशिक्षित कर रहे हैं। हमने पाया कि यहां वर्णित विभिन्न तकनीकों के संयोजन, जैसे कि भाषा-स्वतंत्र बीपीई टोकनीकरण, विनम्रता और औपचारिकता टैग, मॉडल ensembling, n-best reranking, और बैक-अनुवाद को शामिल करने से अन्य प्रयोग प्रणालियों के सापेक्ष सबसे अच्छा अनुवाद मॉडल का उत्पादन हुआ।', 'ru': 'Этот системный документ описывает сквозной канал NMT для задачи перевода японских новостей ↔ на английский язык, представленный на WMT 2021, где мы исследуем эффективность таких методов, как токенизация с помощью языково-независимых и языково-зависимых токенизаторов, нормализация с помощью орфографического преобразования, создание модели, основанной на вежливости и формальности, путем реализации тегера, обратного перевода, сборки моделей и n-лучшего реранжинга. Мы используем параллельные корпуса, предоставленные организаторами WMT 2021, для обучения, а также данные разработки и тестирования из WMT 2020 для оценки различных моделей экспериментов. Предварительно обработанные тела обучаются с помощью модели нейронной сети Трансформатора. Мы обнаружили, что сочетание различных методов, описанных в данном документе, таких как независимая от языка токенизация BPE, включающая метки вежливости и формальности, сборка моделей, n-лучшее повторное ранжирование и обратный перевод, дало лучшие модели перевода по сравнению с другими экспериментальными системами.', 'ga': 'Déanann an páipéar córais seo cur síos ar phíblíne NMT ó cheann ceann go ceann don tasc aistriúcháin nuachta Seapáinise ↔ Béarla mar a cuireadh isteach chuig WMT 2021, áit a ndéanaimid iniúchadh ar éifeachtúlacht na dteicnící cosúil le tokenizing le comharthaí teanga-neamhspleách agus teanga-spleách, normalú trí chomhshó ortagrafach. , ag cruthú múnla atá feasach ar bhéasacht agus ar fhoirmiúlacht trí chlibeáil, aisaistriúchán, comhshamhlú samhlacha agus n-athrangú is fearr a chur i bhfeidhm. Bainimid úsáid as corpas comhthreomhar a sholáthraíonn eagraithe WMT 2021 le haghaidh oiliúna, agus sonraí forbartha agus tástála ó WMT 2020 chun samhlacha turgnamhacha éagsúla a mheas. Cuirtear oiliúint ar na corpora réamhphróiseáilte le samhail líonra néar-Trasfhoirmeora. Fuaireamar amach gur le chéile na teicníochtaí éagsúla a bhfuil cur síos orthu anseo, mar shampla comharthaíocht BPE teanga-neamhspleách, ag ionchorprú dea-bhéasacht agus clibeanna foirmiúlachta, samhlacha ensemble, n-athrangú is fearr, agus ais-aistriúchán a tháirgtear na múnlaí aistriúcháin is fearr i gcomparáid le córais turgnamh eile.', 'ka': 'ამ სისტემის წერტილის შესახებ NMT დასასრულებლად წაპონული „ინგლისური წერტილის გაგრძელების რაოდენობა, რომელიც WMT 2021 წერტილი, სადაც ჩვენ განსხვავებთ ტექნოგიების ეფექტიკურობას, როგორც ენის შესახებ მუშაობელი და ენის შესახებ ტექნენიზერებით, რომელიც ორტოგრაფიური გადა მოდელის შემოწმება და n-საუკეთესო შემოწმება. WMT 2021-ის ორგანიზატორები გამოყენება და განვითარება და ტესტის მონაცემები WMT 2020-ის განსხვავებაში განსხვავებული ექსპერიმენტის მოდელების შესაბამისათვის. პრეპროცესირებული კოპორაც ტრანფორმაციის ნეიროლური ქსელის მოდელით გასწავლა. ჩვენ აღმოჩნეთ, რომ განსხვავებული ტექნოგიები, როგორც ენერგიის განსარგებელი BPE ტექნონიზაცია, სხვა ექსპერიმენტის სისტემისთან მუშაობას და ფორმაციალური ტექნონიზაციას, მოდელის შემწყება, n-უკეთესი', 'el': 'Αυτή η εργασία συστήματος περιγράφει έναν ολοκληρωμένο αγωγό NMT για την εργασία μετάφρασης ιαπωνικών Αγγλικών ειδήσεων όπως υποβλήθηκε στο WMT 2021, όπου διερευνούμε την αποτελεσματικότητα τεχνικών όπως η επισήμανση με γλωσσικά ανεξάρτητα και γλωσσικά εξαρτώμενα επισημάνσεις, η ομαλοποίηση με ορθογραφική μετατροπή, η δημιουργία ενός μοντέλου ευγένειας-και-τυπικότητας με την εφαρμογή ενός tagger, πίσω-μετάφραση, μοντελοποίηση μοντέλων, και ν-καλύτερη επανακατάταξη. Χρησιμοποιούμε παράλληλα σώματα που παρέχονται από τους διοργανωτές για εκπαίδευση, και δεδομένα ανάπτυξης και δοκιμής από το για την αξιολόγηση διαφορετικών πειραματικών μοντέλων. Τα προ-επεξεργασμένα σώματα εκπαιδεύονται με ένα μοντέλο νευρικού δικτύου μετασχηματιστή. Διαπιστώσαμε ότι ο συνδυασμός διαφόρων τεχνικών που περιγράφονται στο παρόν, όπως η γλωσσική ανεξάρτητη επισήμανση, η ενσωμάτωση ετικετών ευγένειας και τυπικότητας, η σύνθεση μοντέλων, η επανακατάταξη και η μεταγραφή παρήγαγαν τα καλύτερα μεταφραστικά μοντέλα σε σχέση με άλλα πειραματικά συστήματα.', 'kk': 'Бұл жүйелік қағаз жапон және ағылшын жаңалық аудару тапсырмасы WMT 2021- ге жіберілген NMT концепциясының аяқтау жолын анықтайды. Біз тілден тәуелсіз және тілден тәуелсіз токенизаторлармен, ортографикалық аудару арқылы нормализацияланады, тегжерді, қайта аудару арқылы тегжерді, артық аудар Модель енсембрлеу және n- ең жақсы қайта енсембрлеу. WMT 2021 бағдарламалары бақылау, жасау және сынақтар үшін WMT 2020 бағдарламаларының бақылау үшін параллел корпорасын қолданамыз. Алдын- ала өткізілген корпора түрлендіруші невралдық желі үлгісімен оқылған. Біз осында таңдалған әртүрлі техникаларды біріктіру керек. Мысалы тілден тәуелсіз BPE токенизациясы, сәттілік мен официалдық тегтерді қосу үлгілері, үлгілерді жасау, n-ең жақсы қайта жасау және қайта аудару үлгілері', 'hu': 'Ez a rendszer tanulmány bemutatja a WMT 2021-re benyújtott japán angol hírfordítási feladathoz szükséges end-to-end NMT pipeline-t, ahol feltárjuk az olyan technikák hatékonyságát, mint a tokenizálás nyelvfüggetlen és nyelvfüggő tokenizálókkal, normalizálás ortográfiai konverzióval, udvariasság-és-formalitás-tudatos modell létrehozása címkéző bevezetésével, back-translation, modellszerelés, és n-legjobb rangsorolás. A WMT 2021 szervezői által biztosított párhuzamos korpuszokat használjuk a képzéshez, a WMT 2020 fejlesztési és tesztadatait pedig különböző kísérleti modellek értékeléséhez. Az előfeldolgozott testeket Transformer neurális hálózati modellel képezik. Megállapítottuk, hogy az itt leírt különböző technikák, mint például a nyelvfüggetlen BPE tokenizáció, az udvariasság és formaság címkék beépítése, a modell összeállítás, az n-best ranking és a back-translation kombinációja a legjobb fordítási modelleket eredményezte más kísérleti rendszerekhez képest.', 'it': "Questo documento di sistema descrive una pipeline NMT end-to-end per il compito di traduzione di notizie in inglese giapponese come presentato a WMT 2021, in cui esploriamo l'efficacia di tecniche come tokenizzazione con tokenizer indipendenti dalla lingua e dipendenti dalla lingua, normalizzazione mediante conversione ortografica, creazione di un modello consapevole della cortesia e formalità implementando un tag, back-translation, modellismo, e n-migliore ri-classifica. Utilizziamo corpi paralleli forniti dagli organizzatori WMT 2021 per la formazione, e dati di sviluppo e test di WMT 2020 per la valutazione di diversi modelli sperimentali. I corpi pre-elaborati sono addestrati con un modello di rete neurale Transformer. Abbiamo scoperto che combinando varie tecniche qui descritte, come la tokenizzazione BPE indipendente dal linguaggio, incorporando tag di cortesia e formalità, l'ensembling dei modelli, il n-best reranking e la traduzione posteriore hanno prodotto i migliori modelli di traduzione rispetto ad altri sistemi sperimentali.", 'lt': 'This system paper describes an end-to-end NMT pipeline for the Japanese   English news translation task as submitted to WMT 2021, where we explore the efficacy of techniques such as tokenizing with language-independent and language-dependent tokenizers, normalizing by orthographic conversion, creating a politeness-and-formality-aware model by implementing a tagger, back-translation, - modelio susijungimas ir n-geriausias pakartotinis susijungimas. Naudojame WMT 2021 organizatorių pateiktus lygiagrečius korprus mokymui, rengimui ir bandymų duomenims iš WMT 2020 skirtingų eksperimentinių modelių vertinimui. Perdirbtas korporas mokomas naudojant Transformer nervinio tinklo model į. Nustatėme, kad derinant įvairius šiame dokumente aprašytus metodus, pavyzdžiui, nepriklausomą nuo kalbos BPE tokenizaciją, į juos įtraukti mandagumo ir formalumo žymenys, modelių susirinkimą, n-geriausią pakartotinį susijungimą ir grįžtamąjį vertimą buvo sukurti geriausi vertimo modeliai, palyginti su kitomis eksperimentų sistemomis.', 'mk': 'Оваа системска хартија опишува нафтовод од крај до крај на НМТ за јапонската “ англиска задача за превод на вести како што е предадена на ВМТ 2021, каде ја истражуваме ефикасноста на техниките како што е токенизацијата со јазички и јазички независни токенизачи, нормализацијата со ортографска конверзија, создавањето на модел свесен за учтивост и формалност со спроведување Модел на ансемблирање и најдобро повторно вртење. Користиме паралелна корпора обезбедена од организаторите на ВМТ 2021 за обука, развој и тест податоци од ВМТ 2020 за проценка на различни експериментални модели. Препроцесираната корпора е обучена со модел на трансформирана нервна мрежа. Најдовме дека комбинацијата на различни техники опишани тука, како што е јазикот-независна потенцијализација на БПЕ, вклучувајќи љубезност и формалност ознаки, моделно ансемблирање, n-најдобро преврзување и назад превод ги произведуваше најдобрите модели на превод во однос на другите ек', 'ml': 'ഈ സിസ്റ്റത്തിന്റെ പേപ്പ് വിവരിക്കുന്നു "WMT 2021-ലേക്ക് നിയോഗിച്ച ഇംഗ്ലീഷ് വാര്\u200dത്ത വിവരങ്ങള്\u200d പരിശോധിച്ചിരിക്കുന്നു" ജാപ്പാന്\u200dകാര്\u200dക്കുള്ള അവസാനം NMT പൈപ്പെലൈന്\u200d വിവരിക്കുന്നു. അവിടെ ഞങ്ങള്\u200d ഭാഷ പിന്നെ മോഡലിന്റെ മുന്നില്\u200d നിന്നും മികച്ച വീണ്ടും പോകുന്നു. We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models.  മുന്നോട്ട് പ്രവര്\u200dത്തിപ്പിക്കപ്പെട്ട കോര്\u200dപ്പോര ഒരു ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d നെയൂറല്\u200d നെറ്റുറല്\u200d ന ഭാഷ സ്വാതന്ത്രതയുള്ള ബിപെയിന്റെ പ്രമാണത്തിന്റെയും ഫോര്\u200dമിറ്റിലിറ്റിയുടെയും ടാഗുകളില്\u200d ചേര്\u200dക്കുന്നതിനെയും മാതൃകയുടെയും മാതൃകയുടെയും വീണ്ടെടുക്കുന്നതിന', 'ms': 'Kertas sistem ini menggambarkan saluran paip NMT akhir-akhir untuk tugas terjemahan berita bahasa Inggeris Jepun yang dihantar ke WMT 2021, di mana kami mengeksplorasi kegunaan teknik seperti tokenizing dengan tokenizer bebas bahasa dan bebas bahasa, normalizing dengan pertukaran ortografik, mencipta model yang sedar kebaikan dan formaliti dengan melaksanakan tag, terjemahan balik,  model ensembling, and n-best reranking.  Kami menggunakan korpra selari yang disediakan oleh pengatur WMT 2021 untuk latihan, dan pembangunan dan ujian data dari WMT 2020 untuk penilaian model eksperimen yang berbeza. The preprocessed corpora are trained with a Transformer neural network model.  We found that combining various techniques described herein, such as language-independent BPE tokenization, incorporating politeness and formality tags, model ensembling, n-best reranking, and back-translation produced the best translation models relative to other experiment systems.', 'mt': 'This system paper describes an end-to-end NMT pipeline for the Japanese   English news translation task as submitted to WMT 2021, where we explore the efficacy of techniques such as tokenizing with language-independent and language-dependent tokenizers, normalizing by orthographic conversion, creating a politeness-and-formality-aware model by implementing a tagger, back-translation,  model ensembling, and n-best reranking.  We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models.  The preprocessed corpora are trained with a Transformer neural network model.  We found that combining various techniques described herein, such as language-independent BPE tokenization, incorporating politeness and formality tags, model ensembling, n-best reranking, and back-translation produced the best translation models relative to other experiment systems.', 'ro': 'Această lucrare de sistem descrie o conductă NMT end-to-end pentru sarcina de traducere a știrilor în limba engleză japoneză, așa cum a fost trimisă la WMT 2021, unde explorăm eficacitatea tehnicilor cum ar fi tokenizarea cu tokenizatori independenți de limbă și dependenți de limbă, normalizarea prin conversie ortografică, crearea unui model conștient de politețe și formalitate prin implementarea unui eticheter, back-translation, ansamblul modelului, şi n-cel mai bun re-ranking. Utilizăm corpore paralele furnizate de organizatorii WMT 2021 pentru instruire și date de dezvoltare și testare de la WMT 2020 pentru evaluarea diferitelor modele experimentale. Corporele preprocesate sunt antrenate cu un model de reţea neurală Transformer. Am constatat că combinarea diferitelor tehnici descrise aici, cum ar fi tokenizarea BPE independentă de limbă, încorporarea etichetelor de politețe și formalitate, ansamblarea modelelor, n-best re-ranking și back-translation au produs cele mai bune modele de traducere comparativ cu alte sisteme experimentale.', 'pl': 'Niniejszy artykuł systemowy opisuje kompleksową gałąź NMT dla zadania tłumaczenia wiadomości z języka angielskiego, zgłoszoną do WMT 2021, gdzie badamy skuteczność technik takich jak tokenizacja za pomocą tokenizatorów niezależnych od języka i języka, normalizacja przez konwersję ortograficzną, tworzenie modelu świadomego uprzejmości i formalności poprzez wdrożenie tagera, back-translation, zestawienie modeli i n-najlepsze zmiany rankingu. Korpusy równoległe dostarczane przez organizatorów WMT 2021 wykorzystujemy do szkoleń oraz dane rozwojowe i testowe z WMT 2020 do oceny różnych modeli eksperymentów. Wstępnie przetworzone korpusy są trenowane za pomocą modelu sieci neuronowej Transformera. Stwierdziliśmy, że łączenie różnych technik opisanych w niniejszym dokumencie, takich jak niezależna od języka tokenizacja BPE, włączanie znaczników uprzejmości i formalności, zestawienie modeli, zmiana rankingu n-best i tłumaczenie wsteczne dało najlepsze modele tłumaczenia w stosunku do innych systemów eksperymentu.', 'no': 'Denne systempapiret beskriver ein end-to-end NMT-røyr for den japanske og engelske nyhetsgiveringsoppgåva som sendt til WMT 2021, der vi utforskar effektiviteten av teknikkar som tokenisering med språk-uavhengige og språk-avhengige tokeniseringar, som normaliserer etter ortografiske konvertering, lagar ein modell med påverka og formalitet ved å implementera eit tagger, tilbakeomsetjing, Modellen som er sett inn, og n-beste gjenoppretting. Vi bruker parallelle korpora som er tilgjengeleg av WMT 2021-organiserar for opplæring, utvikling og testing av data frå WMT 2020 for evaluering av ulike eksperimentmodeller. Forhandterarte korpora er trent med eit transformeringsneuralnettverksmodell. Vi fann at kombinasjonen av forskjellige teknikk som er beskriven her, som språket-uavhengige BPE-tokenisasjon, inkluderer politeness- og formalitetstaggar, modellen ensembling, n-beste refankering, og tilbakeomsetjing produserte dei beste omsetjingsmedlene i forhold til andre eksperimentsystem.', 'mn': 'Энэ системийн цаас нь Япон болон Англи хэлний хөрөг хөрөг хөрөг хөрөг хөрөг хэлний төгсгөл болон хэлний хамааралтай тахианы үр дүнг судалж, ортографик хөрөг хөрөнгө оруулж, сайхан, официалтай загвар бүтээж, тэгвэр дахин хөрөнгө оруулж, Загвар загвар хадгалах, n-хамгийн сайн дахин загвар хадгалах. Бид WMT 2021 оны зохион байгуулагчид багш болон хөгжүүлэх, шинжлэх ухаан болон шинжлэх ухаан WMT 2020 оны өөр туршилтын загварын үнэлэх үед параллел корпора ашигладаг. Аль боловсруулсан корпора нь Трансформерийн мэдрэлийн сүлжээний загвартай суралцагдсан. Бид энд тайлбарласан олон технологиудыг нэгтгэхэд олж мэдсэн. Жишээ нь хэл-хамааралтай BPE тодорхойлолт, зөвхөн сэтгэл хандлага, загварын загварыг нэгтгэхэд, n-хамгийн сайн эргүүлэх, эргүүлэх, бусад туршилтын системтэй харьцуулсан хамгийн сайн орчуул', 'sv': 'Detta systemarbete beskriver en end-to-end NMT pipeline fﾃｶr den japanska engelska nyhetsﾃｶversﾃ､ttningsuppgiften som lﾃ､mnats in till WMT 2021, dﾃ､r vi undersﾃｶker effektiviteten av tekniker som tokenisering med sprﾃ･koberoende och sprﾃ･kberoende tokenizers, normalisering genom ortografisk konvertering, skapande av en artighet-och-formalitetsmedveten modell genom att implementera en taggare, back-translation, modell ensemblering, och n-bﾃ､st omrﾃ､kning. Vi anvﾃ､nder parallella korpor som tillhandahﾃ･lls av WMT 2021 organisatﾃｶrer fﾃｶr utbildning, och utveckling och testdata frﾃ･n WMT 2020 fﾃｶr utvﾃ､rdering av olika experimentmodeller. De fﾃｶrbehandlade korporarna ﾃ､r trﾃ､nade med en Transformers neurala nﾃ､tverksmodell. Vi fann att kombinationen av olika tekniker som beskrivs hﾃ､r, sﾃ･som sprﾃ･koberoende BPE tokenisering, infﾃｶrlivande av artighet och formalitet taggar, modellenensemblering, n-best re ranking och back-translation, producerade de bﾃ､sta ﾃｶversﾃ､ttningsmodellerna jﾃ､mfﾃｶrt med andra experimentsystem.', 'so': 'Qoraalkan nidaamkan ayaa qoraal u qoran dhammaadka ugu dambaysta NMT oo japaniya u qoran shaqada ingiriisiga oo loo soo dhiibay WMT 2021, halkaas oo aynu baaraynaa saamaynta techniques, sida tokenizing with luqada a an madax u independent iyo luqad-ku-trusted tokenizers, normalizing by orthographic conversion, creating a model politeness-and-formality-aware by implementing a tagger, back-translation, tusaale ahaan sameynta iyo dib u celinta Waxaynu isticmaalnaa shirkadaha lambarka ah oo WMT 2021 qabanqaabiya waxbarashada, iyo horumarinta iyo imtixaanka ee WMT 2020 si aan u qiimeyno samooyinka imtixaanka kala duduwan. The preprocessed corpora are trained with a Transformer neural network model.  Waxaynu helnay in lagu soo ururiyo qalabka kala duduwan oo lagu qoray, tusaale ahaan calaamadda BPE ee luqada madax u ah, in lagu soo galo qalabka madaxda iyo rasmiga ah, tusaale ahaan sameynta qaabilaadda, dib-u-dhigidda, iyo turjumidda dib-u-tarjumidda ayaa soo saaray modellada ugu wanaagsan ee la xiriira nidaamka kale ee tijaabiyada.', 'ta': 'இந்த அமைப்பு தாள் WMT 2021 க்கு வழங்கப்பட்ட ஒரு முடிவு NMT பைப்லைனை ஜாப்பானியனுக்கு விவரிக்கிறது. இதில் நாம் தொழில்நுட்ப மொழி சார்ந்த மற்றும் மொழி சார்ந்த சார்ந்த ஒற்றுக்கொள்ளும் தொழில்நுட்ப மாற்ற மாதிரி புதுப்பித்தல், மற்றும் n-சிறந்த மீண்டும் திரும்புதல். WMT 2021 அமைப்பாளர்களால் வழங்கப்பட்ட இணைய நிறுவனத்தை பயன்படுத்தி WMT 2020 லிருந்து பயிற்சி மற்றும் உருவாக்க மற்றும் சோதனை தரவுகளை பர முன்செயல்படுத்தப்பட்ட நிறுவனத்தில் மாற்று நரம்பு வலைப்பின்னல் மாதிரி நாம் கண்டுபிடித்தோம் மொழி சுதந்திரமான பிபெய் குறிப்புகளை ஒன்று சேர்க்கும் தொழில்நுட்பம், மாதிரி ஒழுங்கும், n சிறந்த மொழிமொழிபெயர்ப்பு, மற்ற சோதனை அமைப்புகள', 'ur': 'یہ سیستم کاغذ جپانیوں کے لئے آخر-to-end NMT پیپی لین کی توصیف کرتا ہے ۔انگلیسی خبریں ترجمہ کا تابع جس طرح WMT 2021 پر پیش کیا گیا ہے، جہاں ہم نے ٹاگر اور پیچھے ترجمہ کرنے کے ذریعے ایک ٹاگر، پیچھے ترجمہ کرنے کے ذریعے تغییر کے مطابق فعالیت کی تحقیق کرتی ہیں۔ Model ensembling, and n-best re-anking. ہم نے WMT 2021 کی تطارین، توسعہ اور تطارین کے لئے سائل کورپورا کا استعمال کیا ہے اور WMT 2020 سے مختلف آزمائش موڈل کا ارزیابہ کرنے کے لئے۔ پیش پردازش کی کورپورا ایک ترنسفور نیورال نیٹ ورک موڈل کے ساتھ آموزش کی جاتی ہے. ہم نے دیکھا کہ اس میں طرح طرح طرح طرح طرح کی تکنیک جمع کرتی ہے، جیسے زبان-مستقل BPE ٹوکنیزی، پاکیزگی اور فرمولی ٹاگ جمع کرتی ہے، نمڈل ensembling، n-best reranking اور پیچھے ترجمہ کے ساتھ بہترین ترجمہ موڈل اور دوسری آزمائش سیستموں کے مقابلہ میں پیدا کی ہے.', 'si': 'මේ පද්ධති පැත්තේ ජාපානිස් සඳහා end-to-end NMT පායිප්ලයින් විස්තර කරනවා . ඉංග්\u200dරීසි වාර්තාවක් භාෂා 2021 වලට පිළිබඳින් WMT 2021 වලට, අපි පරීක්ෂා කරනවා ප්\u200dරයෝජනයක් වලින් භාෂාව-ස්ථාවත්  මොඩේල් සංවිධානය සහ n-හොඳම ආරක්ෂණය. අපි WMT 2021 පරීක්ෂණාකරුවන්ගේ සමාන්\u200dය කොර්පෝරාව භාවිතා කරනවා වෙනස් පරීක්ෂණ විදිහට පරීක්ෂණාකරුවන් විදිහ මුලින් ප්\u200dරක්\u200dරියාත්මක කර්පෝරා ප්\u200dරියෝජනය කරලා තියෙන්නේ නිර්මාණකය ජාලයේ මොඩේලයෙ අපි හොයාගත්තා මෙතන විවිධ ප්\u200dරවේශය සම්බන්ධ කරනවා කියලා, භාෂාව-ස්වේශිත BPE ටොකෙනිස් වගේ, සාමාන්\u200dයතාවය සහ ප්\u200dරවේශය ටැග් සම්බන්ධ කරනවා, මොඩේල', 'sr': 'Ovaj sistemski papir opisuje cijevi NMT na kraju za japanski „engleski novinski prevod zadatak podignut WMT 2021“, gde istražujemo efikasnost tehnika poput tokeniranja jezika nezavisnih i jezičkih tokenizera, normalizirajući ortografijskim prevodom, stvarajući model koji zna pristojnost i formalnost, proveravajući znakove, prevod nazad, Model ensembliranja, i n-najbolja preokretanja. Koristimo paralelnu korporaciju organizatori WMT 2021 za obuku, razvoj i test podataka iz WMT 2020 za procjenu različitih modela eksperimenta. Preprocessirana korpora je obučena sa modelom transformera neuralne mreže. Našli smo da kombinacija različitih tehnika opisana ovdje, kao što je neovisna tokenizacija BPE jezika, uključujući pristojnost i formalnosti, model ensembliranje, n-najbolje preobraćanje i preobraćanje, proizvela su najbolje modele prevoda u odnosu na druge sisteme eksperimentacija.', 'uz': "@ info: whatsthis model ishlab chiqarish, va eng yaxshi ishlab chiqarish. Biz WMT 2021 mualliflari bilan ishlatilgan parallel corporatidan foydalanamiz, WMT 2020'dan foydalanuvchi, va taʼminlovchi va tizim maʼlumotlarini o'rganish uchun boshqa tizim modellarini qiymatish uchun. Name Biz bu yerda o'rganilgan har xil texnikalarni birlashtirishni topdik. Masalan tillar bilan boshqa tajriba tizimga murojaat qilish, qoidalik va formatlash teglarini qo'shish, modelni qo'shish, modelni o'zgartirish, eng yaxshi qayta tarjima qilish, va qayta tarjima qilish modellarini boshqa tizim tizimga bog'liq tarjima", 'vi': 'Tờ giấy này mô tả một đường ống NMT cuối cùng cho việc dịch chuyển tin tức tiếng Anh Nhật thuộc dạng được gửi cho WRT 2021, nơi chúng tôi khám phá hiệu quả của kỹ thuật như điều hòa bằng thẻ với những máy phát tín hiệu độc ngôn ngữ và những điều lệ, bình thường bằng việc chỉnh bằng cách cấu hình, tạo ra một mô hình phạt bằng cách thực hiện câu khẩu hiệu, dịch ngược, Kiểu dàn hợp, và trình lại tốt nhất. Chúng tôi sử dụng vật thể song song cung cấp bởi tổ chức WM 2021 cho huấn luyện, cho việc phát triển và kiểm tra dữ liệu từ WRT 2020 để đánh giá các mẫu thử khác nhau. Các hạ sĩ được xử lý trước được đào tạo bằng một mô hình thần kinh transformer. Chúng tôi phát hiện ra rằng kết hợp các kỹ thuật khác nhau được miêu tả ở đây, như hiệu ứng ngôn ngữ độc lập của BPE, gồm các thẻ phạt và hình thức, kết hợp mô hình mẫu, n-best tái phát lại, và dịch lại sản xuất ra những mô hình dịch tốt nhất so với các hệ thống thí nghiệm khác.', 'bg': 'Този системен доклад описва цялостен тръбопровод за превод на новини на японски английски език, представен в WMT 2021, където изследваме ефикасността на техники като токенизиране с езиково независими и езиково зависими токенизатори, нормализиране чрез ортографско преобразуване, създаване на модел, съобразен с учтивостта и формалността чрез въвеждане на тагер, обратен превод, Модел ансамблиране и най-добро пренареждане. Използваме паралелни корпуси, предоставени от организаторите за обучение, както и разработка и тестване на данни от ОМТ 2020 за оценка на различни експериментални модели. Предварително обработените корпуси се обучават с модел на трансформаторна невронна мрежа. Установихме, че комбинирането на различни техники, описани тук, като например езиково-независима токенизация, включване на етикети за учтивост и формалност, ансамблиране на модели, повторно ранкиране и обратен превод произвеждат най-добрите модели на превод в сравнение с други експериментални системи.', 'hr': 'Ovaj sustavni papir opisuje konačni NMT cijevi za japanski „engleski novinski prevod zadatak podignut WMT 2021, gdje istražujemo učinkovitost tehnika poput tokenizacije jezika nezavisnih i jezičkih tokenizera, normalizirajući ortografskim preobraćanjem, stvarajući model svijesti pristojnosti i formalnosti proverenjem znakova, prevoditelja, Model ensembliranja i n-najbolje preokretanje. Koristimo paralelnu korporaciju organizatorima WMT 2021 za obuku, razvoj i testiranje podataka iz WMT 2020 za procjenu različitih modela eksperimentacija. Preobrađena tijela je obučena sa modelom transformera neuralne mreže. Našli smo da kombiniranje različitih tehnika opisana ovdje, poput tokenizacije na jeziku nezavisnih BPE-a, uključujući pristojnosti i formalnosti etikete, model ensembliranje, n-najbolje preobraćanje i preobraćanje, proizvelo je najbolji model prevoda u odnosu na druge sustave eksperimentacija.', 'de': 'Dieses Systempapier beschreibt eine End-to-End-NMT-Pipeline fﾃｼr die japanische Nachrichtenﾃｼbersetzungsaufgabe, wie sie an WMT 2021 ﾃｼbermittelt wurde, in der wir die Wirksamkeit von Techniken wie Tokenizing mit sprachunabhﾃ､ngigen und sprachabhﾃ､ngigen Tokenizern untersuchen, Normalisierung durch orthographische Konvertierung, Schaffung eines hﾃｶflichkeits- und formalitﾃ､tsbewussten Modells durch Implementierung eines Taggers, Rﾃｼckﾃｼbersetzung, Modellensembling und n-beste Neurangierung. Wir verwenden parallele Korpora von WMT 2021 Organisatoren fﾃｼr Trainings und Entwicklungs- und Testdaten von WMT 2020 zur Auswertung verschiedener Experimentmodelle. Die vorverarbeiteten Korpora werden mit einem Transformer neuronalen Netzwerkmodell trainiert. Wir fanden heraus, dass die Kombination verschiedener hier beschriebenen Techniken, wie sprachunabhﾃ､ngiger BPE-Tokenisierung, Einbindung von Hﾃｶflichkeit und Formalitﾃ､t Tags, Modellensembling, n-best Reranking und Rﾃｼckﾃｼbersetzung die besten ﾃ彙ersetzungsmodelle im Vergleich zu anderen Experimentsystemen erzeugt.', 'id': 'Kertas sistem ini menggambarkan pipa NMT dari akhir ke akhir untuk tugas terjemahan berita bahasa Inggris seperti yang dikirim ke WMT 2021, di mana kita mengeksplorasi efisiensi teknik seperti tokenizing dengan tokenizer independen bahasa dan tergantung bahasa, normalisasi dengan konversi ortografik, menciptakan model sopan-dan-formalitas-sedar dengan memaksa tagger, terjemahan kembali, Model ensembling, dan n-terbaik rebanking. Kami menggunakan corpora paralel yang disediakan oleh organisasi WMT 2021 untuk latihan, dan pengembangan dan tes data dari WMT 2020 untuk evaluasi model eksperimen yang berbeda. Korpora yang diproses dilatih dengan model jaringan saraf Transformer. Kami menemukan bahwa menggabungkan berbagai teknik yang disebut di sini, seperti tokenisasi BPE bebas bahasa, memasukkan tags sopan dan formalitas, model ensembling, n-best reranking, dan terjemahan belakang menghasilkan model terjemahan terbaik berbanding sistem percobaan lain.', 'da': 'Dette systempapir beskriver en end-to-end NMT pipeline til den japanske engelske nyhedsoversættelsesopgave som indsendt til WMT 2021, hvor vi undersøger effektiviteten af teknikker som tokenisering med sproguafhængige og sprogafhængige tokenizere, normalisering ved ortografisk konvertering, skabelse af en høflighed-og-formalitetsbevidst model ved at implementere en tagger, back-translation, model sammensætning, og n-bedste omlægning. Vi bruger parallelle korpora leveret af WMT 2021 arrangører til træning, og udviklings- og testdata fra WMT 2020 til evaluering af forskellige eksperimentmodeller. De forbearbejdede korpora er trænet med en Transformer neural netværksmodel. Vi fandt ud af, at kombinering af forskellige teknikker beskrevet heri, såsom sproguafhængig BPE tokenisering, inkorporering af høflighed og formalitet tags, model ensembling, n-bedst re-ranking og back-translation producerede de bedste oversættelsesmodeller i forhold til andre eksperimentsystemer.', 'nl': 'Dit systeemdocument beschrijft een end-to-end NMT pijplijn voor de Japans Engels nieuws vertaaltaak zoals ingediend bij WMT 2021, waar we de effectiviteit onderzoeken van technieken zoals tokeniseren met taal-onafhankelijke en taal-afhankelijke tokenizers, normaliseren door orthografische conversie, het creëren van een beleefdheid-en-formaliteit bewust model door het implementeren van een tagger, back-translation, Model ensembling, en n-beste rangschikking. We gebruiken parallelle corpora van WMT 2021 organisatoren voor training, en ontwikkel- en testgegevens van WMT 2020 voor evaluatie van verschillende experimentmodellen. De voorgeverwerkte corpora worden getraind met een Transformer neural network model. We ontdekten dat het combineren van verschillende technieken die hierin beschreven zijn, zoals taalonafhankelijke BPE-tokenizatie, het integreren van beleefdheid en formaliteit tags, model ensembling, n-best herschikking en back-translation resulteerde in de beste vertaalmodellen ten opzichte van andere experimentsystemen.', 'ko': '이 시스템 파일은 WMT 2021에 제출된 일본어-영문 뉴스 번역 임무의 끝에서 끝까지의 NMT 파이프라인을 기술했다. 그 중에서 우리는 언어와 언어에 독립된 표기기를 사용하여 표기화, 정자법 전환을 통해 규범화, 표기기, 번역,모델 암호화와 n 최적 재배열.우리는 WMT 2021 조직자가 제공한 평행 어료 라이브러리를 사용하여 교육을 진행하고 WMT 2020의 개발과 테스트 데이터 평가가 서로 다른 실험 모델을 사용한다.미리 처리된 어료 라이브러리는 Transformer 신경 네트워크 모델로 훈련한다.우리는 다른 실험 시스템에 비해 본고에서 기술한 각종 기술, 예를 들어 언어에 독립된 BPE 표기화, 예의와 정식 표기, 모델 암호화, n-best 재배열과 역방향 번역을 결합하면 가장 좋은 번역 모델을 만들 수 있음을 발견했다.', 'sw': 'Gazeti hili la mfumo linaelezea pipeline ya mwisho wa NMT kwa Wajapani — kazi ya kutafsiri habari ya Kiingereza kama ilivyowasilishwa kwa WMT 2021, ambapo tunatafuta ufanisi wa mbinu kama vile kuonyesha kwa waandishi wa lugha huru na lugha inayotegemea lugha, zinazoweka kawaida kwa mabadiliko ya kiorthografia, kutengeneza modeli inayofahamika na usawa wa-usawa kwa kutekeleza tagger, tafsiri ya nyuma, mifano yenye uchunguzi, na vizuri zaidi. We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models.  Kampuni iliyopo mbele inafundishwa na muundo wa mtandao wa neura wa zamani. Tumegundua kuwa, kuunganisha mbinu mbalimbali zinazoelezwa hapa, kama vile ishara huru ya BPE ya lugha, kuingiza viungo vya uraia na usalama, vifaa vya mifano, vifaa vikubwa vizuri zaidi, na tafsiri ya nyuma ilizalisha mifano bora ya tafsiri inayohusiana na mfumo mwingine wa majaribio.', 'af': "Hierdie stelsel papier beskrywe 'n end-to-end NMT pipeline vir die japanse „Engelse nuus vertaling taak soos a an WMT 2021 ingestuur word, waar ons die effektiviteit van tekenisse soos tokeniseer met taal-onafhanklike en taal-afhanklike tokenissers, normaliseer deur ortografiese omskakeling, skep 'n belangrikheid-en-formaliteit-bewaarde model deur 'n etiker, terugvertaling te implementeer, Model ensembling en n-beste herankering. Ons gebruik parallele korpora wat deur WMT 2021 organiseerders verskaf word vir onderwerp en ontwikkeling en toets data van WMT 2020 vir evaluering van verskillende eksperimentmodelle. Name Ons het gevind dat die kombinasie van verskeie teknike hier beskrywe, soos taal-onafhanklike BPE-tokenisasie, die inkorporeer van belangrikheid en formaliteit etikette, model ensembling, n-beste heranking en terugvertaling die beste vertalingsmodele wat relatief tot ander eksperimentstelsels is.", 'fa': 'این کاغذ سیستم یک لوله NMT به پایان پایان برای تاریخ نویس انگلیسی که به WMT 2021 فرستاده شده است توصیف می\u200cکند، جایی که ما فعالیت\u200cهای تکنولوژی مثل توکین\u200cکننده\u200cهای مستقل به زبان و بستگی به زبان\u200cها را تحقیق می\u200cکنیم، توسط تغییر orthographic معمول\u200cسازی می\u200cشود، یک مدل آگاه\u200cکننده\u200cی پاکیزه و رسمی با تولید کردن یک تاگر،  Model ensembling, and n-best re-anking. ما از شرکت متفاوتی که توسط سازمان\u200cکنندگان WMT 2021 برای آموزش، توسعه و توسعه داده\u200cهای WMT 2020 برای ارزیابی مدل\u200cهای آزمایش مختلف استفاده می\u200cکنیم. شرکت پیش پردازش شده با یک مدل شبکه عصبی تغییر دهنده آموزش داده شده است. ما فهمیدیم که ترکیب فناوری مختلف را در اینجا توصیف کرده\u200cایم، مثل توکین\u200cسازی BPE مستقل به زبان، توکین کردن etiketهای پاکیزه و رسمی، توکین\u200cسازی مدل، نوشتن بهترین نوشتن n-بهترین و ترکیب پشت بهترین مدل\u200cهای ترکیب\u200cسازی نسبت به سیستم\u200cهای آزما', 'tr': "Bu sistem kagyzy WBMT 2021'e gönderilen iňlisler üçin end-to-end NMT pipeline hasaplaýar. Biz bu ýerde dil boýunça we dil baglanylan tokenizçiler bilen tokenizçilik etmek üçin teknikleriň etkinliýetini çykarýarys, ortografiýany terjime edilen, taýýarlar we formalitet-bil nusgasyny bejerip, terjime eden, Model ködleme, we n-iň gowy taýýarlama WMT 2021 düzenleyicileriniň okuwçylygy, gelişmeleri we çykarmak üçin WMT 2020-nji ýyldan üýtgeden parallel korpora ulanýarys. Öňden işledilen korpora nuýral a ýry bilen bilinmediler. Biz bu ýerde deskrip edilen çeşitli tekniklerden birleşdirdik, diýip dilinde bağımsız BPE tokenizacija ýaly, politenest we formalitet tägleri döretýäris, nusgasyn, n-iň gowy taýýarlamak we yzyna terjime etmek we beýleki deneyler sistemalaryna görä iň gowy terjime modelleri üretýäris.", 'sq': 'Ky dokument i sistemit përshkruan një tubacion nga fundi në fund NMT për detyrën e përkthimit të lajmeve angleze si dërguar në WMT 2021, ku ne eksplorojmë efektshmërinë e teknikave të tilla si tokenizimi me tokenizerë të pavarur nga gjuha dhe të varur nga gjuha, normalizimi nga konvertimi ortografik, krijimi i një modeli të mirëkuptueshëm nga polititeti dhe formaliteti duke zbatuar një tagger, përkthimi prapa,  model ensembling, and n-best reranking.  We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models.  Korpora e përgatitur është trajnuar me një model rrjeti nervor Transformer. Gjetëm se kombinimi i teknikave të ndryshme të përshkruara këtu, të tilla si tokenizimi BPE i pavarur nga gjuha, përfshirje e etiketave të sjellshme dhe formalitetit, mbledhje e modeleve, n-më të mirën ripërkthimi dhe përkthimi prapa prodhoi modelet më të mira të përkthimit n ë krahasim me sistemet e tjera eksperimentesh.', 'am': 'ይህ የድምፅ ፕሮግራም የኢንጂንግል ዜና ትርጓሜ አድራሻ WMT 2021 በመስጠት ለጃፓንኛ (የኢንጂንግድ ዜና ትርጉም ሥራ) የሚለውጥ የመጨረሻ ቀላል ነው፡፡ የሞዴል ስብስብ እና የተሻለ ስብሰብ የWMT 2021 ተማሪዎችን እና ከWMT 2020 የተሰናከረውን እና የድምፅ እና የድምፅ ዳታ ለልዩ ፈተና ምሳሌዎችን ለማስተምር እናስቀምጣለን፡፡ The preprocessed corpora are trained with a Transformer neural network model.  እንደዚሁም የቋንቋ-ነፃ BPE ማስታወቂያ፣ የፖለቲካዊ እና ፎርማት መክፈቻ፣ የሞዴል ስብስብ፣ የክፍለ ትርጉም እና የጀርባ ትርጓሜ መተርጓም ከሌሎች ተፈተና ስርዓቶች ጋር የተያያያየ መልካሙን ትርጉም ምሳሌዎች አቀረቡ፡፡', 'bs': 'Ovaj sistemski papir opisuje cijevi NMT do kraja za japanski „engleski novinski prevod zadatak podignut WMT 2021, gdje istražujemo učinkovitost tehnika poput tokenizacije jezika nezavisnih i jezičkih tokenizera, normalizirajući ortografijskim prevodom, stvarajući model pristojnosti i formalnosti, proveravajući znakove, prevod, Model ensembliranja i n-najbolje preokretanje. Koristimo paralelnu korporaciju organizatori WMT 2021 za obuku, razvoj i test podataka iz WMT 2020 za procjenu različitih modela eksperimenta. Preprocessirana korpora je obučena sa modelom transformera neuralne mreže. Našli smo da je kombinacija različitih tehnika opisana ovdje, kao što je tokenizacija BPE-nezavisnih jezika, uključujući pristojnost i formalnosti etikete, model ensembliranje, n-najbolje preobraćanje i preobraćanje proizvela najbolje modele prevoda u odnosu na druge eksperimentalne sisteme.', 'ca': "Aquest paper del sistema descriu un pipeline NMT de final a final per a la tasca de traducció de notícies anglesa en japonès, com va ser submetida a WMT 2021, on explorem l'eficacia de tècniques com la fitxa amb fitxes independents de llenguatge i de llenguatge, normalitzant-se per la conversió ortogràfica, creant un model conscient de politesa i formalitat implementant un etiquetador, una traducció retrospectiva, - l'assemblatge de models, i l'n-millor repetició. Utilitzem corpora paral·lela proporcionada pels organitzadors de WMT 2021 per formar, desenvolupar i testar dades de WMT 2020 per avaluar diferents models experimentals. El corpore preprocesat està entrenat amb un model de xarxa neural Transformer. Vam descobrir que combinar diverses tècniques descrites aquí, com la tecnicització BPE independent del llenguatge, incorporant etiquetes de politesa i formalitat, agrupament de models, n-best re-anking i retrotraducció van produir els millors models de traducció en comparació amb altres sistemes experimentals.", 'hy': 'Այս համակարգչային աշխատանքը նկարագրում է NMT խողովակաշար ճապոնացի ՝ անգլերեն նորությունների թարգմանման խնդիրների համար, ինչպես ներկայացված է ԱՄԹ 2021 թվականին, որտեղ մենք ուսումնասիրում ենք այնպիսի տեխնիկաների արդյունավետությունը, ինչպիսիք են լեզվից անկախ և լեզվից անկախ խողովակաշարների, նորմալիզացվում օրթոգրաֆիկ համընթացքում, ստեղծում ենք քա  model ensembling, and n-best reranking.  Մենք օգտագործում ենք երկարագույն կառուցվածքները, որոնք տրամադրվել են ԱՄԹ 2021-ի կազմակերպողների կողմից, ուսուցման, զարգացման և փորձարկումների մասին տեղեկատվությունների մասին, որոնք տրվում են ԱՄԹ 2020-ի տարբեր Կոպրոցեսված կառուցվածքը վարժեցվում է Transforme-ի նյարդային ցանցի մոդելի միջոցով: Մենք հայտնաբերեցինք, որ այստեղ նկարագրված տարբեր մեթոդներ համադրելով, ինչպիսիք են լեզվից անկախ BP-ի նշանները, ներառելով քաղաքավարությունը և ձևավոր նշանները, մոդելների համակարգը, n-լավագույն վերարտադրումը և հետադարձ թարգմանումը ստեղծեցին լավագույն թար', 'cs': 'Tento systémový příspěvek popisuje end-to-end NMT potrubí pro japonskou angličtinu překladu zpráv předložené WMT 2021, kde zkoumáme efektivitu technik jako tokenizace s jazykově nezávislými a jazykově závislými tokenizátory, normalizace ortografickou konverzí, vytvoření zdvořilosti a formality uvědoměného modelu implementací tagger, back-translation, sestavování modelů a n-nejlepší sestavování. K vyhodnocení různých experimentálních modelů využíváme paralelní korpusy poskytované organizátory WMT 2021 a vývojová a testovací data z WMT 2020. Předzpracované korpusy jsou trénovány pomocí Transformerového modelu neuronové sítě. Zjistili jsme, že kombinace různých technik popsaných zde, jako je jazykově nezávislá BPE tokenizace, zahrnující značky zdvořilosti a formality, sestavování modelů, přesměrování n-best a zpětný překlad vytváří nejlepší překladové modely ve srovnání s jinými experimentními systémy.', 'et': 'Käesolevas süsteemitöös kirjeldatakse WMT 2021-le esitatud jaapani inglise keele uudiste tõlkimise ülesande täielikku NMT juhendit, kus uurime selliste meetodite tõhusust nagu tokeniseerimine keelesõltumatute ja keelesõltuvate tokeniseerijatega, normaliseerimine ortograafilise muundamise teel, viisakuse ja formaalsuse teadliku mudeli loomine sildistaja, tagantõlke, mudeli koostamine ja n-parim ümberpaigutamine. Kasutame WMT 2021 korraldajate poolt pakutavaid paralleelseid korpuseid koolituseks ning WMT 2020 arendus- ja katseandmeid erinevate katsemudelite hindamiseks. Eeltöödeldud korpused on koolitatud Transformeri närvivõrgu mudeliga. Leidsime, et erinevate käesolevas kirjeldatud tehnikate kombineerimine, näiteks keelesõltumatu BPE tokeniseerimine, viisakuse ja formaalsuse siltide sisaldamine, mudeli ansambleerimine, n-best ümberjaotamine ja tagatõlge, andis parimad tõlkemudelid võrreldes teiste katsesüsteemidega.', 'bn': 'এই সিস্টেমের পত্রিকাটি জাপানীদের জন্য একটি শেষ পর্যন্ত এনএমটি পাইপেলাইন ব্যাখ্যা করছে যেখানে উইএমটি ২০২১-এ প্রদান করা হয়েছে, যেখানে আমরা প্রযুক্তির কার্যক্রম খুঁজে বের করি, যেমন ভাষার স্বাধীন এবং ভাষার ভাষার নির্ মডেলের সাথে পুনরুদ্ধার করা হয়েছে। বিভিন্ন পরীক্ষার মডেল মূল্যের মূল্যের মাধ্যমে আমরা উইএমটি ২০২০ থেকে প্রশিক্ষণ, উন্নয়ন এবং পরীক্ষার জন্য প্রতিষ্ঠাতা কর্পোরা প্ ট্রান্সফার্নার নিউরেল নেটওয়ার্ক মডেল দিয়ে প্রশিক্ষণ প্রদান করা হয়েছে। আমরা খুঁজে পেয়েছি যে ভাষার স্বাধীন বিপের প্রতিক্রিয়া, যেমন নীতি এবং ফরমেলিটি ট্যাগ, মডেল পুনরায় বিভিন্ন প্রযুক্তি, আর পেছনের অনুবাদ সৃষ্টি করেছে অন্যান্য পরীক্ষার স', 'fi': 'T채m채 j채rjestelm채artikkeli kuvaa lopusta p채채h채n -NMT-putkea japanilaisen englannin uutisten k채채nn철steht채v채채n WMT 2021:ss채, jossa tutkimme sellaisten tekniikoiden tehokkuutta kuin tokenisointi kieliriippumattomilla ja kieliriippuvaisilla tokenisoijilla, normalisointi ortografisella muunnoksella, kohteliaisuus- ja muodollisuustietoisen mallin luominen toteuttamalla tagger, back-translation, Mallikokoonpano ja n-paras uudelleenj채rjestely. K채yt채mme WMT 2021 -j채rjest채jien tarjoamia rinnakkaiskorpusia koulutukseen sek채 WMT 2020:n kehitys- ja testiaineistoa erilaisten kokeilumallien arviointiin. Esiprosessoidut korpuset on koulutettu Transformerin neuroverkkomallilla. Havaitsimme, ett채 erilaisten t채ss채 kuvattujen tekniikoiden yhdist채minen, kuten kieliriippumaton BPE-tokenisointi, kohteliaisuus- ja muodollisuustagien yhdist채minen, mallikokoonpano, n-best uudelleenj채rjestely ja takak채채nn철s tuottivat parhaat k채채nn철smallit verrattuna muihin kokeiluj채rjestelmiin.', 'az': 'Bu sistem kağıdı Japonca və İngiliz xəbəri çeviri işini WMT 2021 ilə təbliğ etdiyi kimi, dil-bağımsız və dil-bağımsız tokenizerlərlə tokenizerləndirilən, ortografik dönüşündən normalizləndirilən, etiketçi, geri çeviri ilə təklif-təklif modeli yaratdığımız kimi təklif-təhrif edən, təklif-təhrif-təhrif-təhrif-təhrif-təhrif təhrif edən, təhrif-təhr Model ensembling və n-best re-anking. WMT 2021 organizatorların təhsil etmək, təhsil etmək və təhsil etmək üçün WMT 2020-dən təhsil edən paralel korpora istifadə edirik. Preprocessed corpora is trained with a Transformer neural network model. Biz burada müxtəlif teknikləri birləşdirmək kimi dil-bağımsız BPE tokenizasyonu, kibarlıq və formalitə etiketləri, modeli ensembling, n-best reranking və geri-tercümləmə kimi daha yaxşı çevirim modellərini başqa eksperimentlər sistemlərinə qovuşdurduq.', 'he': 'נייר המערכת הזה מתאר צינור NMT סוף-סוף עבור משימה התרגום של חדשות אנגלית היפנית כפי שנשלח ל-WMT 2021, שבו אנו חוקרים את היעילות של טכניקות כמו לטקניזציה עם טקניזצים עצמאיים לשפה ומתמודדים לשפה, נורמליזציה על ידי שינוי אורטוגרפי, ליצור מודל מודע לנומס-ורמליות על ידי שימוש בתגים, תרגום אחורה, מודל מארגן, וארגן מחדש. אנו משתמשים בקופורה מקבילה שנספקה על ידי מארגנים WMT 2021 לאימונים, ולפיתוח ומבחנים נתונים מהWMT 2020 להערכה של דוגמנים ניסויים שונים. הקופורה המעובדת מתאמנת עם מודל רשת עצבית טרנספורטר. מצאנו ששילוב טכניקות שונות מתארות כאן, כמו טיקניזציה BPE עצמאית לשפה, מכיל מנומס ותגיות רשמיות, מסיבת דוגמנים, n-הקשר מחדש הטוב ביותר, ותרגום מאחור יצר את הדוגמנים הטובים ביותר לתרגום בהשוואה למערכות ניסויים אחרות.', 'ha': "@ info Mode na sami, da mai saukarwa. Tuna amfani da shirin samurai da WMT 2021 ke samar da shi dõmin wa'anar mafarin, da ciryawa da jarraba data daga WMT 2020, dõmin an ƙaddara misãlai masu cikin jarrabãwa. An sanar da firanin ta gaba ɗaya da wani misãlan jerin Naurar ta Transformer. Ba mu gane cewa a haɗi kowanki masu shirya ko da aka bayyana a baka, kamar shirin ayuka da ba'a da BLE ba, kuma a haɗi cikin shirin wata na'ura da kuma tsari, misalin da shirin ayuka, da masu samu'a da bakin-tarjiwa, sun sami misãlai masu kyaun fassarar da suka yi danganta da wasu na'urar fitina.", 'bo': 'This system paper describes an end-to-end NMT pipeline for the Japanese  English news translation task as submitted to WMT 2021, where we explore the efficacy of techniques such as tokenizing with language-independent and language-dependent tokenizers, normalizing by orthographic conversion, creating a politeness-and-formality-aware model by implementing a tagger, back-translation, Model ensembling, n-best reranking. We use parallel corpora provided by WMT 2021 organizers for training, and development and test data from WMT 2020 for evaluation of different experiment models. སྔོན་སྒྲིག་འཛུགས་བྱས་པའི་མཁའ་དབུགས་འདི་ནུས་མཐུན་བཟོ་བྱེད་ཀྱི་མ་དབུགས་དང་མཉམ་དུ་བསླབས་ཡོད། ངེད་ཚོའི་ནང་དུ་ཕྱིར་མཐོང་ཐབས་ལམ་འདྲ་བརྗོད་ཀྱི་ཐབས་ལམ་མིན་འདུག དཔེར་ན། སྐད་ཡིག་རྟོགས་པའི་BPE tokenization།', 'jv': "Perempir sistem iki rambarang tanggal end-to-end NMT kanggo ngbagian Balita . Perempir ingkang basa sing nyimpen kanggo WT 2020 1, supoyo awake dhéwé nyokot nggawe efekasi teknik sing koyo token karo token-nesaturan karo alêk dhèwèké tatarané sampeyan luwih-nesaturan karo alêk-nesaturan, iso nggawe ngubah ortografèke, nggawe model nggawe politenes-lan-akra informasi sing berarti perusahaan tagger,  model,utextattr,utextattr Awak dhéwé éntukno karo perusahaan sampeyan kanggo ngilanggar nggawe luwih dumateng, lan nggawe data nggo ujian sing suku 'WT 2020' kanggo ngerasakno model sing sampeyan gejer-ujian. ProgressBarUpdates Awak dhéwé éntuk nggambar nggawe teknik sing paling-pernik nggawe heren, kayata gambar tokenisaan BBE sing luwih-pernik, iso nggawe etiket politeness lan saiki-pernik, model sing wis nambah, n-akhir arno sing gawe ngubah uga, lan tarjamahan-terjamahan sing luwih apik dhéwé ning tarjamahan sing luwih lanjut ning sistèm", 'sk': 'Ta sistemski prispevek opisuje cevovod NMT od konca do konca za nalogo prevajanja novic v japonski angleščini, kot je bil predložen WMT 2021, kjer raziskujemo učinkovitost tehnik, kot so žetonizacija z jezikovno neodvisnimi in jezikovno odvisnimi žetonizatorji, normalizacija z ortografsko pretvorbo, ustvarjanje modela, ki se zaveda vljudnosti in formalnosti z uvedbo označevalca, nazaj prevajanja, Modelsko oblikovanje in n-najboljše prerazporejanje. Uporabljamo vzporedne korpuse organizatorjev WMT 2021 za usposabljanje, razvoj in testiranje podatkov WMT 2020 za vrednotenje različnih modelov eksperimentov. Predprocesirane korpuse so usposobljene z modelom transformatorskega živčnega omrežja. Ugotovili smo, da je kombinacija različnih tehnik, opisanih tukaj, kot so jezikovno neodvisna BPE žetonizacija, vključevanje vljudnosti in formalnosti oznak, ansambling modelov, n-best ponovno razvrščanje in nazaj prevajanje, ustvarila najboljše prevajalske modele v primerjavi z drugimi eksperimentalnimi sistemi.'}
{'en': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'ar': 'تقديمات فوجيتسو DMATH لترجمة الأخبار WMT21 ومهام الترجمة الطبية الحيوية', 'pt': 'As Submissões do Fujitsu DMATH para Tarefas de Tradução de Notícias e Tradução Biomédica do WMT21', 'es': 'Las presentaciones de Fujitsu DMATH para las tareas de traducción de noticias y traducción biomédica de WMT21', 'fr': 'Les soumissions DMATH de Fujitsu pour les tâches de traduction de nouvelles et de traduction biomédicale WMT21', 'ja': 'WMT 21ニュース翻訳と生物医学翻訳タスクのための富士通DMATH提出', 'zh': '富士通DMATH提交WMT21新闻译及生物医学译事', 'ru': 'Заявки Fujitsu DMATH для Перевода Новостей WMT21 и Биомедицинских Задач Перевода', 'hi': 'WMT21 समाचार अनुवाद और जैव चिकित्सा अनुवाद कार्यों के लिए Fujitsu DMATH प्रस्तुतियाँ', 'ga': 'Aighneachtaí Fujitsu DMATH maidir le Tascanna Aistriúcháin Nuachta agus Aistriúcháin Bithleighis WMT21', 'ka': 'Fujitsu DMATH-ს WMT21 ახალგაზრდან და ბიომედიციური გადაწყვეტილების მისამართები', 'el': 'Οι υποβολές της για εργασίες μετάφρασης ειδήσεων και βιοϊατρικής μετάφρασης', 'hu': 'A Fujitsu DMATH benyújtásai a WMT21 hírfordítási és bioorvosi fordítási feladatokra', 'it': 'Fujitsu DMATH presenta le sue proposte per i compiti di traduzione e traduzione biomedica delle notizie WMT21', 'kk': 'WMT21 жаңалық аудару және биомедикалық аудару тапсырмаларының Fujitsu DMATH бақылауы', 'mk': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'lt': 'Fujitsu DMATH pristatymas WMT21 naujienų vertimo ir biomedicinos vertimo užduotims', 'ms': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'ml': 'WMT21 വിവരങ്ങളുടെ വിവരങ്ങള്\u200dക്കും ബിയോമിഡിക്കല്\u200d പരിഭാഷകങ്ങള്\u200d', 'mt': 'Is-Sottomissjonijiet ta’ Fujitsu DMATH għal Kompiti ta’ Traduzzjoni tal-Aħbarijiet u Traduzzjoni Bijomediċina tad-WMT21', 'mn': 'Fujitsu DMATH WMT21 News Translation and Biomedical Translation Tasks for The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'no': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'pl': 'Zgłoszenia Fujitsu DMATH do zadań związanych z tłumaczeniem wiadomości WMT21 i tłumaczeniem biomedycznym', 'sr': 'Submissije Fujitsu DMATH za WMT21 Novinski prevod i biomedicinski prevod zadataka', 'ro': 'Depunerile Fujitsu DMATH pentru activităţile de traducere a ştirilor WMT21 şi traducere biomedicală', 'si': 'The Fujitsu DMATH Sub-Misions for WMT21 News translation and Biodoctor translation Jobs', 'so': 'Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation', 'sv': 'Fujitsu DMATH:s bidrag till WMT21 Nyheter Översättning och biomedicinsk översättning', 'ta': 'WMT21 செய்தி மொழிபெயர்ப்பு மற்றும் பையோமிடிக்கல் மொழிபெயர்ப்பு பணிகளுக்கான ஃபுஜிட்சு DMATH பிரச்சனை', 'ur': 'Fujitsu DMATH WMT21 News Translation and Biomedical Translation Tasks for Submissions', 'uz': 'Name', 'vi': 'Thông điệp Fujitsu DMATH cho thông tin WM21 Name', 'bg': 'Предложенията на ДМАТХ за превод на новини и биомедицински преводи', 'hr': 'Submissije Fujitsu DMATH za WMT21 Novinski prevod i biomedicinski prevod', 'nl': 'Fujitsu DMATH-inzendingen voor WMT21 Nieuws Vertalingen en Biomedische vertaaltaken', 'da': "Fujitsu DMATH's indsendelser til WMT21 Nyheder Oversættelse og biomedicinsk oversættelse", 'de': 'Fujitsu DMATH-Einreichungen für WMT21 News Übersetzungsaufgaben und biomedizinische Übersetzungsaufgaben', 'ko': 'Fujitsu DMATH, WMT21 뉴스 번역 및 생물 의학 번역 임무 제출', 'id': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'sw': 'Tuzo za Fujitsu DMATH kwa ajili ya Tafsiri za Habari za WMT21 na Tafsiri za Biomedical', 'fa': 'مأموریت\u200cهای فوجیتسو DMATH برای ترجمه خبری WMT21 و ترجمه\u200cهای بیولوژیک', 'tr': 'Fujitsu DMATH WMT21 Haýsy terjime we Biomedical terjime Görevleri', 'af': 'Die Fujitsu DMATH Submissions vir WMT21 Nuusvertaling en Biomediese Vertaling Opdragte', 'sq': 'Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'am': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'hy': 'Ֆուջիթսու DMATH-ի ներկայացումները աշխարհի 21 նորությունների թարգմանման և կենսաբժշկական թարգմանման առաջադրանքների համար', 'az': 'Fujitsu DMATH WMT21 Haber 칂eviri v톛 Biomedical 칂eviri G칬nd톛ril톛ri', 'bs': 'Submissije Fujitsu DMATH za WMT21 Novinski prevod i biomedicinski prevod', 'bn': 'WMT21 সংবাদ অনুবাদ এবং বায়োমিকাল অনুবাদ করার জন্য ফুজিতু ডিমাথ সাবমিশন', 'ca': 'Les presentacions de Fujitsu DMATH per a les tasques de traducció de notícies WMT21 i de traducció biomèdica', 'cs': 'Příspěvky Fujitsu DMATH pro úkoly překladu zpráv WMT21 a biomedicínského překladu', 'et': 'Fujitsu DMATH esitused WMT21 uudiste tõlkimise ja biomeditsiinilise tõlke ülesannetele', 'fi': 'Fujitsun DMATH-julkaisut WMT21 News Translation and Biomedical Translation Tehtäviin', 'sk': 'Fujitsujevi predlogi DMATH za naloge prevajanja novic WMT21 in biomedicinskega prevajanja', 'jv': 'Sub-misi kanggo WWT 1 Hawitan Terjamah lan Biyuan Dinasai Tulungan', 'ha': '@ info: whatsthis', 'bo': 'The Fujitsu DMATH Submissions for WMT21 News Translation and Biomedical Translation Tasks', 'he': 'הפרשומות של Fujitsu DMATH לתרגום חדשות WMT21 ומשימות התרגום ביורפואי'}
{'en': 'This paper describes the Fujitsu DMATH systems used for WMT 2021 News Translation and Biomedical Translation tasks. We focused on low-resource pairs, using a simple ', 'ar': 'تصف هذه الورقة أنظمة فوجيتسو DMATH المستخدمة في ترجمة الأخبار WMT 2021 ومهام الترجمة الطبية الحيوية. ركزنا على الأزواج منخفضة الموارد ، باستخدام نظام بسيط. أجرينا تجارب على اللغة الإنجليزية-الهوسا ، والخوسا-الزولو ، والإنجليزية-الباسكية ، وأرسلنا نتائج Xhosa → Zulu في مهمة ترجمة الأخبار ، و English → Basque في مهمة الترجمة الطبية الحيوية ، والمهام الفرعية لترجمة الملخصات والمصطلحات. يجمع نظامنا بين التسرب من BPE وميزات الكلمات الفرعية الفرعية والترجمة الخلفية مع نموذج محول (أساسي) ، مما يحقق نتائج جيدة في مجموعات التقييم.', 'pt': 'Este documento descreve os sistemas Fujitsu DMATH usados para tarefas de Tradução de Notícias e Tradução Biomédica do WMT 2021. Focamos em pares de poucos recursos, usando um sistema simples. Conduzimos experimentos em inglês-hausa, xhosa-zulu e inglês-basco, e apresentamos os resultados para xhosa→zulu na tarefa de tradução de notícias e inglês→basco na tarefa de tradução biomédica, subtarefas de tradução de resumos e terminologia. Nosso sistema combina o dropout BPE, recursos de sub-subword e back-translation com um modelo Transformer (base), obtendo bons resultados nos conjuntos de avaliação.', 'es': 'Este artículo describe los sistemas Fujitsu DMATH utilizados para las tareas de Traducción de Noticias y Traducción Biomédica del WMT 2021. Nos centramos en pares de bajos recursos, utilizando un sistema simple. Realizamos experimentos en inglés-hausa, xhosa-zulú e inglés-vasco, y enviamos los resultados para xhosa→zulú en la tarea de traducción de noticias, e inglés→euskera en la tarea de traducción biomédica, subtareas de traducción de resúmenes y terminología. Nuestro sistema combina la eliminación de BPE, las funciones de subpalabras y la traducción inversa con un modelo Transformer (base), logrando buenos resultados en los conjuntos de evaluación.', 'fr': "Cet article décrit les systèmes DMATH de Fujitsu utilisés pour les tâches de traduction de nouvelles et de traduction biomédicale WMT 2021. Nous nous sommes concentrés sur les paires à faibles ressources, à l'aide d'un système simple. Nous avons mené des expériences sur l'anglais-haoussa, le xhosa-zoulou et l'anglais-basque, et soumis les résultats pour le xhosa→zoulou dans la tâche de traduction des actualités, et l'anglais→basque dans la tâche de traduction biomédicale, les sous-tâches de traduction de résumés et de terminologie. Notre système combine l'abandon de BPE, les fonctionnalités de sous-sous-mots et la rétro-traduction avec un modèle Transformer (base), ce qui permet d'obtenir de bons résultats sur les ensembles d'évaluation.", 'ja': '本稿では、WMT 2021ニュース翻訳および生物医学翻訳タスクに使用される富士通DMATHシステムについて説明します。私たちは単純なシステムを使用して、低資源のペアに焦点を当てました。英語- Hausa, Xhosa - Zulu, English - Basqueの実験を行い、ニュース翻訳タスクではXhosa→ Zulu、生物医学翻訳タスクでは英語→バスク語の結果を提出し、要約と用語の翻訳サブタスクを提出した。当社のシステムは、BPEドロップアウト、サブワード機能、および逆変換をトランスフォーマー（ベース）モデルと組み合わせ、評価セットで良好な結果を達成します。', 'hi': 'यह पेपर WMT 2021 समाचार अनुवाद और बायोमेडिकल अनुवाद कार्यों के लिए उपयोग किए जाने वाले Fujitsu DMATH सिस्टम का वर्णन करता है। हमने एक साधारण प्रणाली का उपयोग करके कम संसाधन जोड़े पर ध्यान केंद्रित किया। हमने अंग्रेजी-हौसा, Xhosa-Zulu और अंग्रेजी-बास्क पर प्रयोग किए, और समाचार अनुवाद कार्य में Xhosa→Zulu के लिए परिणाम प्रस्तुत किए, और बायोमेडिकल अनुवाद कार्य में अंग्रेजी→बास्क, अमूर्त और शब्दावली अनुवाद उपकार्यक्रम। हमारी प्रणाली एक ट्रांसफॉर्मर (आधार) मॉडल के साथ BPE ड्रॉपआउट, उप-शब्द सुविधाओं और बैक-ट्रांसलेशन को जोड़ती है, जो मूल्यांकन सेट पर अच्छे परिणाम प्राप्त करती है।', 'zh': '本文引WMT 2021新闻译及生物医学译者富士通DMATH统。 专于低资源对,用一简之统。 吾于英语 - 豪萨语,科萨语 - 祖鲁语、英语 - 巴斯克语实验之,新闻译者科萨语→祖鲁语之,生物医学译者英语→Basque之,摘要术语之。 臣等统将 BPE 删、子词功能与反向译与 Transformer(本)相合,于评估集上取良效。', 'ru': 'В этой статье описываются системы Fujitsu DMATH, используемые для задач перевода новостей WMT 2021 и биомедицинского перевода. Мы сосредоточились на низкоресурсных парах, используя простую систему. Мы провели эксперименты по английскому-хауса, хоса-зулу и английско-баскскому языку и представили результаты для→ хоса-зулу в задаче перевода новостей и английскому-баскскому языку в→ задаче биомедицинского перевода, абстрактных подзадачах и подзадачах перевода терминологии. Наша система сочетает в себе выпадение BPE, особенности подслова и обратный перевод с моделью трансформатора (базовой), достигая хороших результатов на оценочных наборах.', 'ga': 'Déanann an páipéar seo cur síos ar na córais Fujitsu DMATH a úsáidtear le haghaidh tascanna Aistriúcháin Nuachta agus Aistriúchán Bithleighis WMT 2021. Dhírigh muid ar phéirí íseal-acmhainne, ag baint úsáide as córas simplí. Rinneamar turgnaimh ar Bhéarla-Hausa, Xhosa-Zulu agus Béarla-Bascais, agus chuireamar isteach na torthaí do Xhosa→Súlúis sa Tasc Aistriúcháin Nuachta, agus Béarla→Bascais sa Tasc Aistriúcháin Bithleighis, subtascanna aistriúcháin teibí agus téarmaíochta. Comhcheanglaíonn ár gcóras titim amach BPE, gnéithe fo-focal agus aisaistriúchán le múnla Trasfhoirmeora (bonn), rud a bhaineann torthaí maithe amach ar na tacair mheastóireachta.', 'ka': 'ეს დოკუმენტი გამოყენებულია სისტემები Fujitsu DMATH, რომელიც WMT 2021 წინასწორების გადაწყვეტა და ბიომედიციური გადაწყვეტა საქმებისთვის. ჩვენ მიმართ რესურსისების ზოგებისთვის ცოკუნტირებულია, რომელიც სისტემის გამოყენება. ჩვენ ექსპერიმენტები ინგლისური-ჰოსას, Xhosa-Zulu და ინგლისური-ბასკური შემდეგ გავაკეთეთ და Xhosa Zulu შემდეგ გავაკეთეთ ინგლისური განაცვლის რაოდენობაში და ინგლისური ბასკური ბიომედიციური განაცვლის რაოდენ ჩვენი სისტემა BPE-ს გადასრულება, საბეჭვა სიტყვების ფუნქციები და დასრულება შემდეგ გადასრულება (ბაზი) მოდელთან, რომელიც გამოიყენება კარგი შედეგები.', 'kk': 'Бұл қағаз WMT 2021 жаңалық аудару және биомедикалық аудару тапсырмалары үшін қолданылатын Fujitsu DMATH жүйелерін анықтайды. Қарапайым жүйе қолданатын төмен ресурстар екеуіне көздеген. Біз ағылшын-Хауса, Хоса-Зулу және ағылшын-Баск туралы эксперименттерді орындадық, және жаңалық аудару тапсырмасында Xhosa Zulu және ағылшын баск тілінде биомедицина аудару тапсырмасында, абстракты және терминология аудару суб Біздің жүйеміз BPE бақылау, суб- сөздің мүмкіндіктерін және қайта аудару үлгісімен біріктіреді. Бақылау баптауларының жақсы нәтижелерін жеткізеді.', 'it': "Questo articolo descrive i sistemi DMATH Fujitsu utilizzati per le attività di traduzione delle notizie WMT 2021 e traduzione biomedica. Ci siamo concentrati sulle coppie a basso contenuto di risorse, utilizzando un sistema semplice. Abbiamo condotto esperimenti su English-Hausa, Xhosa-Zulu e English-Basque, e presentato i risultati per Xhosa Zulu nel News Translation Task, e English Basque nel Biomedical Translation Task, abstract and terminologic translation subtask. Il nostro sistema combina l'abbandono BPE, le funzioni di sottoparola e la traduzione posteriore con un modello Transformer (base), ottenendo buoni risultati sui set di valutazione.", 'el': 'Η παρούσα εργασία περιγράφει τα συστήματα που χρησιμοποιούνται για τις εργασίες μετάφρασης ειδήσεων και βιοϊατρικής μετάφρασης. Εστιάσαμε σε ζευγάρια χαμηλών πόρων, χρησιμοποιώντας ένα απλό σύστημα. Πραγματοποιήσαμε πειράματα στα Αγγλικά-Χάουζα, Ξόσα-Ζουλού και Αγγλικά-Βασκικά, και υποβάλαμε τα αποτελέσματα για το Ξόσα Ζουλού στο έργο μετάφρασης ειδήσεων, και τα Αγγλικά Βασκικά στο έργο βιοϊατρικής μετάφρασης, αφηρημένων και ορολογίας δευτερεύουσες εργασίες. Το σύστημά μας συνδυάζει τα χαρακτηριστικά των υπολέξεων και την αντίστροφη μετάφραση με ένα μοντέλο μετασχηματιστή (βάσης), επιτυγχάνοντας καλά αποτελέσματα στα σύνολα αξιολόγησης.', 'hu': 'Ez a tanulmány bemutatja a WMT 2021 Hírfordítási és Bioorvosi Fordítási feladatokhoz használt Fujitsu DMATH rendszereket. Az alacsony erőforrású párokra összpontosítottunk, egy egyszerű rendszer segítségével. Kísérleteket végeztünk angol-háza, Xhosa-zulu és angol-baszk nyelven, és benyújtottuk az eredményeket Xhosa zulu nyelven a Hírfordítási feladatban, az angol baszk nyelven pedig a Bioorvosi fordítási feladatban, az absztrakt és terminológiai fordítási részfeladatokban. Rendszerünk kombinálja a BPE lemaradását, az alszó funkcióit és a visszafordítást egy Transformer (alap) modellel, így jó eredményeket ér el az értékelési készleteken.', 'lt': 'This paper describes the Fujitsu DMATH systems used for WMT 2021 News Translation and Biomedical Translation tasks.  Mes sutelkėme dėmesį į mažai išteklių turinčias poras, naudojant paprastą sistemą. Mes atlikome eksperimentus su anglų-Hausa, Xhosa-Zulu ir anglų-baskų kalbomis ir pateikėme Xhosa Zulu rezultatus žinių vertimo užduotyje, o anglų baskų kalba – su biomedicinos vertimo užduotyje, abstraktus ir terminologijos vertimo subtaskas. Our system combines BPE dropout, sub-subword features and back-translation with a Transformer (base) model, achieving good results on the evaluation sets.', 'ms': 'Kertas ini menggambarkan sistem DMATH Fujitsu yang digunakan untuk tugas WMT 2021 News Translation dan Biomedical Translation. Kami fokus pada pasangan sumber rendah, menggunakan sistem sederhana. Kami melakukan eksperimen pada Bahasa Inggeris, Xhosa-Zulu dan Bahasa Inggeris, dan menghantar keputusan untuk Xhosa Zulu dalam Tugas Terjemahan Berita, dan Bahasa Inggeris dalam Tugas Terjemahan Biomedis, subtaskan abstrak dan terminologi terjemahan. Sistem kami menggabungkan keluar BPE, ciri-ciri sub-kata dan terjemahan-balik dengan model Transformer (asas), mencapai keputusan yang baik pada set penilaian.', 'mk': 'This paper describes the Fujitsu DMATH systems used for WMT 2021 News Translation and Biomedical Translation tasks.  Се фокусиравме на парови со ниски ресурси, користејќи едноставен систем. Ние спроведовме експерименти на англиско-хауса, Џоса-Зулу и англиско-баски, и ги пренесовме резултатите за Џоса Зулу во задачата за преведување на вестите, и англиско-баски во задачата за биомедицински превод, апстрактни и терминолошки преводи. Нашиот систем ги комбинира оставките од БПЕ, функционите на подзборовите и назад-преводот со моделот Трансформер (база), постигнувајќи добри резултати на сетите на проценка.', 'mn': 'Энэ цаас WMT 2021 News Translation and Biomedical Translation tasks-д хэрэглэгдсэн Fujitsu DMATH системийг тайлбарладаг. Бид энгийн системийг ашиглан бага боловсролын хооронд төвлөрсөн. Бид Англи-Хауса, Хоса-Зулу, Англи-Баск дээр туршилт хийж, мэдээллийн хөрөнгө оруулах ажлын Xhosa Zulu-ын үр дүнг, Биомедицины хөрөнгө оруулах ажил, абстракт болон терминологийн хөрөнгө оруулах зохиолууд дээр Англи Баск хэлнэ. Бидний систем BPE-г халдварлах, суб-үг болон буцаад орчуулах загвартай холбогдож, үнэлгээний багц дээр сайн үр дүнг гаргаж байна.', 'ml': 'ഈ പത്രത്തില്\u200d WMT 2021 സംവാര്\u200dത്തകള്\u200dക്ക് ഉപയോഗിക്കുന്ന ഫുജിത്സു DMATH സിസ്റ്റം വിവരിക്കുന്നു ഒരു സാധാരണ സിസ്റ്റം ഉപയോഗിച്ച് ഞങ്ങള്\u200d കുറഞ്ഞ വിഭവങ്ങളുടെ ജോടികളെ ശ്രദ്ധിച്ചു. ഞങ്ങള്\u200d ഇംഗ്ലീഷ്-ഹൌസ, ഹോസാ-സുലൂ, ഇംഗ്ലീഷ്-ബാസ്കിന്റെയും പരീക്ഷണങ്ങള്\u200d നടത്തി; എക്സോസ സ സുലുവിന്റെയും ഫലങ്ങള്\u200d ബിയോമിഡിക്കല്\u200d പരിഭാഷകങ്ങളുടെ ടാസ്കില്\u200d എടുത നമ്മുടെ സിസ്റ്റത്തില്\u200d BPE ഡ്രോപ്പ് ചേര്\u200dക്കുന്നു, സബ്വോര്\u200dഡ് വിശേഷതകള്\u200d, പിന്നീട് ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ബേസ്- മോഡല്\u200d കൂട്ടു', 'no': 'Denne papiret skildrar Fujitsu DMATH- systema som brukar for WMT 2021 News Translation and Biomedical Translation tasks. Vi fokuserte på låge ressurspare, med eit enkel system. Vi oppførte eksperimenter på engelsk-Hausa, Xhosa-Zulu og engelsk-bask, og sende resultatet for Xhosa Zulu i oppgåva for omsetjing av nyhetar, og engelsk bask i undersøkingane for biomedisinsk omsetjing, abstrakt og terminologisk omsetjing. Sistemet vårt kombinerer BPE-slepp, underordfunksjonar og tilbakeomsetjingar med ein transformeringsmodell, og når det gjer gode resultat på evalueringsinnstillingane.', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi ta’ Fujitsu DMATH użati għall-kompiti tat-Traduzzjoni tal-Aħbarijiet u t-Traduzzjoni Bijomedika tad-WMT 2021. We focused on low-resource pairs, using a simple system.  Saru esperimenti fuq l-Ingliż-Hausa, Xhosa-Zulu u l-Ingliż-Bask, u ressqu r-riżultati għal Xhosa Zulu fil-Ħidma tat-Traduzzjoni tal-Aħbarijiet, u l-Bask Ingliż fil-Ħidma tat-Traduzzjoni Bijomediċina, sottomistoqsijiet ta’ traduzzjoni astratti u terminoloġika. Is-sistema tagħna tgħaqqad it-tneħħija tal-BPE, il-karatteristiċi tas-sottokliem u t-traduzzjoni lura ma’ mudell ta’ Trasformer (bażi), u tikseb riżultati tajbin fuq is-settijiet ta’ evalwazzjoni.', 'ro': 'Această lucrare descrie sistemele DMATH Fujitsu utilizate pentru sarcinile WMT 2021 News Translation și Biomedical Translation. Ne-am concentrat pe perechi cu resurse reduse, folosind un sistem simplu. Am efectuat experimente pe limba engleză-hausă, Xhosa-zulu și engleză-bască și am prezentat rezultatele pentru Xhosa Zulu în sarcina de traducere a știrilor, iar limba engleză bască în sarcina de traducere biomedicală, subsarcinile de traducere abstractă și terminologică. Sistemul nostru combină abandonul BPE, caracteristicile subcuvintelor și traducerea înapoi cu un model Transformer (bază), obținând rezultate bune pe seturile de evaluare.', 'sr': 'Ovaj papir opisuje sisteme Fujitsu DMATH korištene za zadatak WMT 2021 Novinskog prevoda i biomedicinskog prevoda. Fokusirali smo se na par niskih resursa, koristeći jednostavan sistem. Provodili smo eksperimente o engleskoj-Hausi, Xhosa-Zulu i engleskom-basku, i predali smo rezultate za Xhosa Zulu u zadatku za prevod vesti i engleskom basku u zadatku za biomedicinsku prevod, abstrakt i terminologiju. Naš sistem kombinira BPE propast, podrečne funkcije i prevod natrag sa modelom transformera (baza), ostvarivši dobre rezultate na setima procjene.', 'si': 'මේ පත්තුව ප්\u200dරවේශනය කරනවා WMT 2021 වාර්තාව අනුවාදය සහ ජීවිත්\u200dය මධ්\u200dයස්ථාන පද්ධතියට භාවිත කරලා තියෙනවා. අපි පරිමාණ පද්ධතියක් පාවිච්චි කරනවා. අපි ඉංග්\u200dරීසි-හෝසා, Xhosa-Zerlu සහ ඉංග්\u200dරීසි-බාස්ක් ගැන ප්\u200dරයෝජනය කළා, සහ ඉංග්\u200dරීසි බාස්ක් වලින් ප්\u200dරයෝජනය කරලා තියෙන්නේ Xhosa Zerlu වලින් ප්\u200dර අපේ පද්ධතිය BPE බ්\u200dරෝපූට්, සබ්-සබ් වචන අවශ්\u200dයය සහ පස්සේ අවශ්\u200dයය සඳහා පස්සේ අවශ්\u200dයය සඳහා පස්සේ අවශ්\u200dයය (මූලික', 'pl': 'Niniejszy artykuł opisuje systemy Fujitsu DMATH wykorzystywane do tłumaczenia wiadomości WMT 2021 i tłumaczenia biomedycznego. Skupiliśmy się na parach niskich zasobów, przy użyciu prostego systemu. Przeprowadziliśmy eksperymenty na języku angielskim-Hausa, Xhosa-Zulu i angielskim-baskijskim, a wyniki przekazaliśmy Xhosa Zulu w zadaniu tłumaczenia wiadomości oraz angielskim baskijskim w zadaniu tłumaczenia biomedycznego, abstrakcji i terminologii. Nasz system łączy w sobie opuszczenie BPE, funkcje podsłowa i tłumaczenie wsteczne z modelem Transformera (bazowym), osiągając dobre wyniki na zestawach oceny.', 'sv': 'Denna uppsats beskriver Fujitsus DMATH-system som används för WMT 2021 News Translation och biomedicinsk översättning. Vi fokuserade på lågresurspar, med hjälp av ett enkelt system. Vi genomförde experiment på engelska-Hausa, Xhosa-Zulu och engelsk-baskiska, och skickade in resultaten för Xhosa Zulu i nyhetsöversättningsuppgiften, och engelska baskiska i biomedicinsk översättningsuppgift, abstrakt och terminologiöversättning underuppgifter. Vårt system kombinerar BPE-avbrott, underordsfunktioner och bakåtöversättning med en Transformer-modell, vilket ger bra resultat på utvärderingen.', 'ta': 'Name நாங்கள் சுலபமான முறைமையை பயன்படுத்தி குறைந்த வளங்கள் ஜோடிகளை கவனம் செலுத்தினோம். நாங்கள் ஆங்கிலத்தில்- ஹusa, Xhosa- Zulu மற்றும் ஆங்கிலத்தில்- பாஸ்க் மீது சோதனைகளை செய்தோம் மற்றும் செய்தி மொழிபெயர்ப்பு பணியில் Xhosa Zulu மற்றும் ஆங்கிலத்தில் மொழ எங்கள் அமைப்பு BPE வெளியீடு, துணை உச்சொல் குணங்கள் மற்றும் பின் மொழிபெயர்ப்பு மாதிரியில் ஒன்று சேர்க்கிறது, மதிப்பு அமைப்பு', 'so': 'Kanu wuxuu ku qoran yahay nidaamka Fujitsu DMATH ee loo isticmaalay WMT 2021 News Translation and Biomedical Translation. Waxaynu ku kalsoonaynay labada nooc ee noocyada hoose, si aan u isticmaalno nidaam fudud. Waxaan imtixaamo ku sameynay Ingiriis-Hausa, Xhosa-Zulu iyo Ingiriis-Basque, waxaana ka soo dhiibnay resultiyada Xhosa Zulu oo ku qoraya shaqooyinka turjumaadda iyo ingiriisiga Basque oo ku qoran shaqooyinka turjumaadda ee Biomedical, abstract iyo terminology. nidaamkayaga wuxuu ku soo ururiyaa BPE-ka-soo-bixinta, tababarka hoose-word iyo dib-tarjumaadda sameynta model turjumista (asalka) oo ku sameynaya resultooyin wanaagsan oo ku saabsan kooxda qiimeynta.', 'ur': 'This paper describes the Fujitsu DMATH systems used for WMT 2021 News Translation and Biomedical Translation tasks. ہم نے کم منبع جوڑوں پر تمرکز کیا، ایک ساده سیستم کے مطابق۔ ہم نے انگلیسی-هاوسا، Xhosa-Zulu اور انگلیسی-Basque کے بارے میں آزمائش کی، اور نیویس ترجمہ ٹاکس میں Xhosa Zulu کے نتائج اور انگلیسی باسک کے ذریعے بیوڈیسی ترجمہ ٹاکس، abstract اور terminology ترجمہ ٹاکس میں پیش کیا. ہمارا سیستم BPE ڈروپوٹ، سوب-ورڈ فوکتوروں اور پیچھے ترجمہ کے ساتھ تغییر دینے والے (بنسٹ) موڈل کے ساتھ جمع کرتا ہے، ارزیابی سٹوں پر اچھے نتیجے پہنچاتے ہیں.', 'uz': 'Bu qogʻoz WMT 2021 News tarjima va Biomedical tarjima vazifalari uchun ishlatilgan Fujitsu DMATH tizimini anglatadi. Biz oddiy tizimdan foydalanuvchi qisqa manbalar qobiliyatiga qarasak. Biz Inglizcha- Hausa, Xhosa- Zulu va Ingliz- Basque haqida imtiyozni bajardik, va Xhosa Zulu uchun natijalarni Qidirish vazifasida va ingliz tilida Biomedical tarjima vazifasi, abstract va terminolog tarjima vazifalarining tub vazifalarida joʻnatdik. Bizning tizimimiz BPE tuzuvchi, sub-word xossalarini va back-tarjima modeli bilan birlashtiradi, qiymatlar moslamalarida yaxshi natijalarini bajarish mumkin.', 'vi': 'Tờ giấy này mô tả hệ thống Fujitsu DMATH được dùng cho dịch vụ WRT 2021 và dịch vụ sinh học. Chúng tôi tập trung vào các cặp ít tài nguyên, sử dụng một hệ thống đơn giản. Chúng tôi đã thực hiện thí nghiệm về dịch ngữ Anh-Hausa, Xhosa-Zulu và English-Basque, và đã đưa ra kết quả cho Xhosa Zulu trong Nhiệm vụ Dịch Tin tức, và English Basque trong Nhiệm vụ dịch dịch thuật phòng sinh học, luận văn và thuật ngữ. Hệ thống của chúng tôi kết hợp các tính năng rớt ra của BPE, dưới chữ và dịch lại với một mô hình transformer (căn cứ) để đạt được kết quả tốt trên các bộ đánh giá.', 'bg': 'Настоящата статия описва системите използвани за превод на новини и биомедицински превод. Фокусирахме се върху двойки с ниски ресурси, използвайки проста система. Проведохме експерименти на английски-хауса, ксоса-зулу и английски-баски и представихме резултатите за Xhosa зулу в Задачата за превод на новини, и английски баски в Задачата за превод на биомедицински превод, абстрактни и терминологични преводи. Системата ни съчетава отпадане, поддума функции и обратен превод с трансформаторен (базов) модел, постигайки добри резултати при оценките.', 'hr': 'Ovaj papir opisuje sustave Fujitsu DMATH korištene za zadatke za prevod novosti WMT 2021 i biomedicinski prevod. Fokusirali smo se na par niskih resursa, koristeći jednostavan sustav. Provodili smo eksperimente o engleskoj-Hausi, Xhosa-Zulu i engleskom-basku i predali rezultate za Xhosa Zulu u zadatku za prevod vijesti i engleskom basku u zadatku biomedicinskog prevoda, abstraktan i terminološki prevod. Naš sustav kombinira BPE propast, podriječje i prevod natrag s modelom transformera (baza), ostvarivši dobre rezultate na setima procjene.', 'da': 'Dette dokument beskriver Fujitsu DMATH-systemer, der anvendes til WMT 2021 Nyhedsoversættelse og biomedicinsk oversættelse opgaver. Vi fokuserede på par med lave ressourcer ved hjælp af et simpelt system. Vi gennemførte eksperimenter på engelsk-Hausa, Xhosa-Zulu og engelsk-baskisk, og indsendte resultaterne for Xhosa Zulu i Nyhedsoversættelsesopgaven, og engelsk baskisk i Biomedicinsk Oversættelsesopgave, abstrakt og terminologioversættelsesopgaver. Vores system kombinerer BPE dropout, underordsfunktioner og back-translation med en Transformer (base) model, hvilket opnår gode resultater på evalueringssættene.', 'nl': 'Dit artikel beschrijft de Fujitsu DMATH-systemen die worden gebruikt voor WMT 2021 Nieuws Vertaling en Biomedische Vertaling taken. We concentreerden ons op low-resource paren, met behulp van een eenvoudig systeem. We hebben experimenten uitgevoerd met Engels-Hausa, Xhosa-Zulu en Engels-Baskisch, en de resultaten voor Xhosa Zulu in de Nieuws Translation Task, en Engels Baskisch in de Biomedische Translatie Task, abstract en terminologie vertaling subtaken ingediend. Ons systeem combineert BPE dropout, sub-subword features en back-translation met een Transformer (basis) model, waardoor goede resultaten worden behaald op de evaluatiesets.', 'de': 'Dieses Papier beschreibt die DMATH-Systeme von Fujitsu, die fﾃｼr WMT 2021 Nachrichtenﾃｼbersetzungen und biomedizinische ﾃ彙ersetzungsaufgaben verwendet werden. Wir konzentrierten uns auf ressourcenarme Paare mit einem einfachen System. Wir fﾃｼhrten Experimente mit Englisch-Hausa, Xhosa-Zulu und Englisch-Baskisch durch und ﾃｼbermittelten die Ergebnisse fﾃｼr Xhosa Zulu in der News Translation Task und Englisch Baskisch in der Biomedical Translation Task, Abstract und Terminologie Translation Subtasks. Unser System kombiniert BPE-Dropout, Sub-Subword-Funktionen und Rﾃｼckﾃｼbersetzung mit einem Transformer (Basis)-Modell und erzielt gute Ergebnisse auf den Auswertungssﾃ､tzen.', 'ko': '본고는 WMT 2021 뉴스 번역과 생물의학 번역 임무에 사용되는 후지통 DMATH 시스템을 소개한다.우리는 낮은 자원에 중점을 두고 간단한 시스템을 사용한다.우리는 영어 호사어, 코사조루어와 영어 바스크어를 실험했고 뉴스 번역 임무에서 코사조루어의 결과를 제출했으며 생물의학 번역 임무, 요약과 용어 번역 서브 임무에서 영어 바스크어의 결과를 제출했다.우리 시스템은 BPE의 학업 중지, 자사 특징과 역방향 번역을 변환기(base) 모델과 결합시켜 평가집에서 좋은 결과를 얻었다.', 'id': 'Kertas ini menjelaskan sistem Fujitsu DMATH yang digunakan untuk tugas WMT 2021 News Translation dan Biomedical Translation. Kami fokus pada pasangan sumber daya rendah, menggunakan sistem sederhana. Kami melakukan eksperimen pada bahasa Inggris-Hausa, Xhosa-Zulu dan Bahasa Inggris-Basque, dan mengirimkan hasil untuk Xhosa Zulu dalam Tugas Terjemahan Berita, dan Bahasa Inggris dalam Tugas Terjemahan Biomedis, subtasks abstrak dan terminologi. Sistem kami menggabungkan keluar BPE, ciri-ciri sub-kata dan terjemahan kembali dengan model Transformer (dasar), mencapai hasil yang baik pada set evaluasi.', 'fa': 'این کاغذ سیستم\u200cهای DMATH Fujitsu را توصیف می\u200cکند که برای ترجمه\u200cهای خبری WMT 2021 و ترجمه\u200cهای بیولوژیکی استفاده می\u200cشود. ما روی جفت منابع کم تمرکز کردیم، با استفاده از یک سیستم ساده. ما آزمایش\u200cهای انگلیسی-هاوسا، Xhosa-Zulu و انگلیسی-Basque انجام دادیم، و نتیجه\u200cهای Xhosa Zulu را در تابع ترجمه\u200cهای خبری، و Basque انگلیسی را در تابع ترجمه\u200cهای بیولوژیک، مثبت و ترجمه\u200cشناسی تحویل دادیم. سیستم ما ویژگی\u200cهای زیر کلمه\u200cهای BPE را با یک مدل تغییر\u200cدهنده (بنیاد) ترکیب می\u200cکند و نتیجه\u200cهای خوب در مجموعه\u200cهای ارزیابی را می\u200cرساند.', 'sw': 'Gazeti hili linaelezea mfumo wa Fujitsu DMATH uliotumiwa kwa ajili ya utafsiri wa Habari 2021 na Tafsiri za Biomedical. Tulijikita kwenye viwili vya rasilimali chini, kwa kutumia mfumo rahisi. We conducted experiments on English-Hausa, Xhosa-Zulu and English-Basque, and submitted the results for Xhosa Zulu in the News Translation Task, and English Basque in the Biomedical Translation Task, abstract and terminology translation subtasks.  Mfumo wetu unaunganisha matokeo mazuri ya BPE, sifa za chini za maneno na utafsiri wa nyuma kwa mtindo wa Transfer (msingi) unaoendelea kupata matokeo mazuri kwenye seti za uchunguzi.', 'sq': 'Ky artikull përshkruan sistemet Fujitsu DMATH të përdorura për detyrat WMT 2021 News Translation dhe Biomedical Translation. Ne u përqëndruam në çifte me burime të ulëta, duke përdorur një sistem të thjeshtë. Ne kryem eksperimente në Anglisht-Hausa, Xhosa-Zulu dhe Anglisht-Bask dhe paraqitëm rezultatet për Xhosa Zulu në Detyrën e Përkthimit të Lajmeve, dhe anglisht-bask në Detyrën e Përkthimit Biomjekësor, nëndetyra abstrakte dhe terminologjike. Our system combines BPE dropout, sub-subword features and back-translation with a Transformer (base) model, achieving good results on the evaluation sets.', 'af': "Hierdie papier beskryf die Fujitsu DMATH stelsels wat gebruik word vir WMT 2021 Nuusvertaling en Biomedical Vertaling opdragte. Ons fokus op lae hulpbron paar, gebruik 'n eenvoudige stelsel. Ons het eksperimente gevoer op Engels-Hausa, Xhosa-Zulu en Engels-Basque en die resultate vir Xhosa Zulu in die Nuusvertalingstaak en Engels Basque in die Biomediese vertaling taak, abstrakte en terminologiese vertaling ondersteun. Ons stelsel kombinieer BPE dropout, sub- subwoord funksies en terugvertaling met 'n Transformer (base) model, wat goeie resultate op die evaluasie stelle bereik het.", 'am': 'ይህ ገጽ የፉjitsu DMATH ስርዓቶች WMT 2021 ዜና ትርጓሜ እና የቢዮምቲካል ትርጉም ስርዓቶችን ይጽፋል፡፡ ቀላል ስርዓት በመጠቀም የዝቅተኛ ሀብት ሁለትን እናስማራለን፡፡ We conducted experiments on English-Hausa, Xhosa-Zulu and English-Basque, and submitted the results for Xhosa Zulu in the News Translation Task, and English Basque in the Biomedical Translation Task, abstract and terminology translation subtasks.  ሲስተምረታችን BPE የውይይት አዳራሽ፣ ጥያቄ ቃላት እና የጀርባ ትርጉም በተርጓሜ (base) ሞዴል እና በተመሳሳይ ላይ መልካም ፍሬዎችን ለማግኘት ነው፡፡', 'hy': 'Այս հոդվածը նկարագրում է Ֆույջսի DMATH համակարգերը, որոնք օգտագործվում են ԱՄԹ 2021 նորությունների թարգմանման և կենսաբժշկական թարգմանման խնդիրների համար: Մենք կենտրոնացանք ցածր ռեսուրսների զույգերի վրա, օգտագործելով պարզ համակարգ: We conducted experiments on English-Hausa, Xhosa-Zulu and English-Basque, and submitted the results for Xhosa Zulu in the News Translation Task, and English Basque in the Biomedical Translation Task, abstract and terminology translation subtasks.  Մեր համակարգը միավորում է BP-ի դուրս գալը, ենթաբառի հատկությունները և վերադարձ թարգմանումը Transforme-ի (հիմնական) մոդելի հետ, որպեսզի ստանանք լավ արդյունքներ գնահատման համակարգերի վրա:', 'az': "Bu kağıt WMT 2021 Haber Çeviri və Biomedical Çeviri Görüş Görevlərinə istifadə edilən Fujitsu DMATH sistemlərini təsdiqləyir. Biz düşük ressurs çiftlərinə, basit sistemi istifadə edirik. Biz İngilizce-Hausa, Xhosa-Zulu və İngilizce-Bask haqqında təcrübələr etdik və Xhosa Zulu haqqında Xhosa Zulu'nun sonuçlarını Biomedical Translation Task, abstrakt və terminologiya çevirilməsi subtasklarında bildirdik. Sistemimiz BPE'nin çəkilməsi, apa-sözlərin fərqli və arka-tercümə modeli ilə birləşdirir, değerlendirmə qurğularında yaxşı sonuçlar yetirir.", 'bn': 'এই পত্রিকা উইএমটি ২০২১ সংবাদ অনুবাদ এবং বিয়োমিকাল অনুবাদের কাজের জন্য ব্যবহার করা ফুজিতসু ডিমাথ সিস্টেম বর্ণনা করছে। আমরা একটা সাধারণ সিস্টেম ব্যবহার করে নীচের সম্পদ জোড়ায় মনোযোগ দিয়েছিলাম। আমরা ইংরেজি হাউসা, Xhosa-জুলু এবং ইংরেজী বাস্কের উপর পরীক্ষা করেছি এবং সংবাদ অনুবাদ করার ফলাফল হোসা জুলুর জন্য প্রদান করেছি এবং ইংরেজি বাস্ক বাস্ক বায়োমেডিকাল অনুবাদ করার কা আমাদের সিস্টেম বিপের ড্রাপ, সাব-ওয়ার্ডের বৈশিষ্ট্য এবং পেছনে অনুবাদের সাথে একটি ট্রান্সফার্নার (বেস) মডেলের সাথে একত্রিত কর', 'bs': 'Ovaj papir opisuje sisteme Fujitsu DMATH korištene za zadatak WMT 2021 Novinskog prevoda i biomedicinskog prevoda. Fokusirali smo se na par niskih resursa, koristeći jednostavan sistem. Provodili smo eksperimente o engleskom-Hausu, Xhosa-Zulu i engleskom-basku, i predali smo rezultate za Xhosa Zulu u zadatku za prevod novina i engleskom basku u zadatku za biomedicinsku prevod, abstrakt i terminologiju. Naš sistem kombinira BPE propast, podriječne funkcije i prevod natrag sa modelom transformera (baza), ostvarivši dobre rezultate na setima procjene.', 'cs': 'Tento článek popisuje systémy Fujitsu DMATH používané pro úlohy překladu zpráv WMT 2021 a biomedicínského překladu. Zaměřili jsme se na páry s nízkými zdroji, pomocí jednoduchého systému. Provedli jsme experimenty na angličtině-Hausa, Xhosa-Zulu a angličtině-baskičtině a předložili výsledky pro Xhosa Zulu v překladu zpráv a angličtinu v biomedicínském překladu, abstraktních a terminologických podúkolech. Náš systém kombinuje BPE dropout, podslovní funkce a zpětný překlad s transformátorovým (základním) modelem, což dosahuje dobrých výsledků na hodnotících sadách.', 'et': 'Käesolevas artiklis kirjeldatakse Fujitsu DMATH süsteeme, mida kasutatakse WMT 2021 uudiste tõlkimiseks ja biomeditsiiniliseks tõlkimiseks. Me keskendusime madala ressursiga paaridele, kasutades lihtsat süsteemi. Me viisime läbi eksperimente inglise-hausa, xhosa-zulu ja inglise-baski keeles ning esitasime tulemused Xhosa Zulu kohta uudiste tõlke ülesandes ning inglise baski keeles biomeditsiinilise tõlke ülesandes, abstraktide ja terminoloogia tõlke alamülesannetes. Meie süsteem ühendab BPE väljalangemise, alamsõna funktsioonid ja tagasitõlke Transformer (baas)mudeliga, saavutades hindamiskomplektides häid tulemusi.', 'fi': 'Tässä artikkelissa kuvataan Fujitsun DMATH-järjestelmiä, joita käytetään WMT 2021 News Translation- ja Biomedical Translation -tehtävissä. Keskityimme vähävaraisiin pareihin yksinkertaisen järjestelmän avulla. Teimme kokeita English-Hausalla, Xhosa-Zululla ja English-Baskilla sekä toimitimme tulokset Xhosa Zululle News Translation Task -osiossa ja englannin baskille Biomedical Translation Task -osiossa, abstraktin ja terminologian käännöksen alatehtävissä. Järjestelmämme yhdistää BPE:n pudotuksen, alasanaominaisuuksien ja takaisinkääntämisen Transformer-malliin, mikä tuottaa hyviä tuloksia arviointisarjoissa.', 'ca': "Aquest article descriu els sistemes Fujitsu DMATH utilitzats per a les tasques de traducció de notícies i de traducció biomèdica de WMT 2021. Ens vam centrar en parelles de baixos recursos, utilitzant un sistema simple. We conducted experiments on English-Hausa, Xhosa-Zulu and English-Basque, and submitted the results for Xhosa Zulu in the News Translation Task, and English Basque in the Biomedical Translation Task, abstract and terminology translation subtasks.  El nostre sistema combina l'abandon de BPE, les característiques sub-subparaules i la traducció posterior amb un model Transformer (base), obtenint bons resultats en els conjunts d'evaluació.", 'tr': 'Bu kagyz Fujitsu DMATH sistemlerini WMT 2021 Haýsy terjime we Biomedical terjime zady üçin ullanýar. Biz esasy sistemany ulanarak iň az resurslar çiftlere üns berdik. Biz Iňlisçe-Hausa, Xhosa-Zulu we Iňlisçe-Bask hakynda experimentalary etdik we Haýzo terjime zadynda Xhosa Zulu üçin netijeleri bilen birleşdik we iňlisçe baskyny biomedical terjime zadynda, abstrakt we terminologiýa terjime edilmesinde çykardyk. Biziň sistemimiz BPE çapdarlygyny, alt sözleriň özelliklerini we arka terjime etmek üçin birleşýär. Ýükleme düzümlerinde gowy netijeleri ýetirýär.', 'sk': 'V prispevku so opisani Fujitsujevi sistemi DMATH, ki se uporabljajo za naloge prevajanja novic WMT 2021 in prevajanja biomedicina. S preprostim sistemom smo se osredotočili na pare z nizkimi viri. Izvedli smo poskuse na angleščini-hausa, Xhosa-zulu in angleščini-baskovščini ter poslali rezultate za Xhosa Zulu v nalogi za prevajanje novic, angleščini baskovščini pa v podnalogih za prevajanje biomedicinskih prevodov, povzetkov in terminoloških prevodov. Naš sistem združuje BPE opustitev, podbesedne funkcije in nazaj prevajanje z modelom transformatorja (osnovnega), s čimer doseže dobre rezultate pri vrednotenju sklopov.', 'he': "העיתון הזה מתאר את מערכות DMATH Fujitsu משמשות לתרגום חדשות WMT 2021 ותרגום ביורפואי משימות. התמקדנו בזוגות משאבים נמוכים, בשימוש במערכת פשוטה. ביצענו ניסויים באנגלית-האוסה, ג'וסה-זולו ובסקי-אנגלית, והעברנו את התוצאות של ג'וסה זולו במשימת התרגום החדשות, ובסקי אנגלי במשימת התרגום ביורפואית המערכת שלנו משלבת ביטול BPE, תכונות תת-מילים ותרגום מאחור עם מודל Transformer (בסיס), להשיג תוצאות טובות על קבוצות הערכה.", 'ha': "Wannan karatun na describe the FuJisu DMAth system used for WMT 2021 News Translate and Biomedical Translate tasks. Mun zura makõmar da mazauni biyu masu ƙaranci, da wani na'ura mai sauƙi. Hausa, Xhosa-Zulu da Ingiriya-Basque, kuma Muka samun matsala wa Xhosa Zulu a cikin Tafiyar Tarjima na Habari, da kuma Ingiriya Basque a Tafiyar da Farawa na Biomedical Tsarinmu ya haɗa BPA da wasu fassarar-abun-sub-word da aka samu wata misãlan Transformer (base) da kuma ya sami fassarar da masu kyau a kan salon evaluation.", 'jv': 'Perkara iki rambaran kanggo ngerasakno sistem Fjitun DMATT sing gambar nggo WT 2020 1 Hawigan Terjamahan karo Biyuan-Kemerdekangan Awak dhéwé éntuk sistem sing wis ana ing pernik-pernik sing wis ana. Awak dhéwé éntuk éntuk sing nggambar ning inggiles-Hasa, Xosa-Gulu lan inggiles-Basque, lan nambah dhéwé ngertuk kanggo Xosa Gulu nang Menu translation tasks, lan basa inggiles kanggo Biwodhèkan translation tasks, résumbé lan tarjamahan inggiles. Sistem awak dhéwé digawe DroPout, Sub-Awal karo mulai-terjamahan karo model Transformer', 'bo': 'This paper describes the Fujitsu DMATH systems used for WMT 2021 News Translation and Biomedical Translation tasks. ང་ཚོས་རྒྱུ་ནུས་ཆུང་ཆུང་བའི་གཉིས་ཆས་ཆུང་དུ་བློ་གཏོང་བ་འདུག་པས་སྟབས་བདེ་མ་ལག We conducted experiments on English-Hausa, Xhosa-Zulu and English-Basque, and submitted the results for Xhosa Zulu in the News Translation Task, and English Basque in the Biomedical Translation Task, abstract and terminology translation subtasks. ང་ཚོའི་མ་ལག་གིས་BPE སྒུལ་གཙང་གཅད་དང་ཡག་ལག་གཙོ་ཚིག་དང་རྒྱབ་སྐྱོར་མིན་འདུག'}
{'en': 'The University of Edinburgh’s Bengali-Hindi Submissions to the WMT21 News Translation Task', 'pt': 'Submissões Bengali-Hindi da Universidade de Edimburgo para a Tarefa de Tradução de Notícias do WMT21', 'es': 'Presentaciones bengalí-hindi de la Universidad de Edimburgo a la tarea de traducción de noticias WMT21', 'ar': 'التقديمات البنغالية الهندية من جامعة إدنبرة إلى مهمة ترجمة الأخبار WMT21', 'fr': "Les soumissions bengali-hindi de l'Université d'Édimbourg au WMT21 News Translation Task", 'ja': 'エディンバラ大学のベンガル語-ヒンディー語によるWMT 21ニュース翻訳タスクへの応募', 'zh': '爱丁堡大学WMT21新闻译者孟加拉语 - 印地语', 'hi': 'एडिनबर्ग विश्वविद्यालय के बंगाली-हिंदी प्रस्तुतियों WMT21 समाचार अनुवाद कार्य के लिए', 'ru': 'Заявления Университета Эдинбурга на бенгальском и хинди к задаче перевода новостей WMT21', 'ga': 'Aighneachtaí Beangáilis-Hiondúis Ollscoil Dhún Éideann chuig Tasc Aistriúcháin Nuachta WMT21', 'ka': 'ვებინდონის ბენგალი-ჰინდის სუნივერტის სამუშაო WMT21 გასაგულისხმების სამუშაო', 'el': 'Υποβολές του Πανεπιστημίου του Εδιμβούργου στα Βεγγαλικά-Χίντι στο έργο μετάφρασης ειδήσεων WMT21', 'hu': 'Az Edinburgh-i Egyetem bengáli-hindi anyagai a WMT21 Hírfordítási feladathoz', 'it': "Le presentazioni bengale-hindi dell'Università di Edimburgo al WMT21 News Translation Task", 'mk': 'Пренесувањата на Бенгали-Хинди на Универзитетот во Единбург на задачата за преведување на вестите на WMT21', 'kk': 'Эдинбург университетінің Бенгали-Хинди WMT21 жаңалық аудармалардың тапсырмасы', 'lt': 'Edinburgo universiteto bengalų ir hindų pristatymai WMT21 naujienų vertimo darbui', 'ml': 'എഡിന്\u200dബര്\u200dഗിന്\u200dറെ ബെന്\u200dഗാലി-ഹിന്ദി സബ്മിഷനുകള്\u200d WMT21 വാര്\u200dത്ത വിവരങ്ങളുടെ ടാസ്കിലേക്കു്', 'mt': 'Is-Sottomissjonijiet Bengali-Indjani tal-Università ta’ Edinburgh għall-Ħidma tat-Traduzzjoni tal-Aħbarijiet tad-WMT21', 'mn': 'Эдинбургын Их Сургуулийн Бенгали-Хинди WMT21 мэдээллийн хөрөнгө оруулах', 'ms': 'Submisi Bengali-Hindi Universiti Edinburgh ke Tugas Terjemahan Berita WMT21', 'no': "The University of Edinburgh's Bengali-Hindi Submissions to the WMT21 News Translation Task", 'pl': 'Bengalsko-hindi Uniwersytetu w Edynburgu Zgłoszenia do WMT21 News Translation Task', 'sr': 'Univerzitet Edinburga Bengali-Hindi podataka za WMT21 Novinski prevod', 'ro': 'Comunicarea bengali-hindi a Universității din Edinburgh la misiunea de traducere a știrilor WMT21', 'si': 'WMT21 වාර්තාව වාර්තාව භාවිතය වැඩකට බන්ගාලි හින්දි විශ්වාසිතාව', 'so': "Jaamacadda Edinburgh's Bengali-Hindi Submissions to the WMT21 News Translation Task", 'sv': "University of Edinburgh's bengali-hindi bidrag till WMT21 News Översättningsuppgift", 'ta': 'Edinburgh University of Bengali- Hindi Submissions to the WMT21 News Translation Task', 'ur': 'انڈینبورڈ یونیوریس کی بنگالی-ہندی سرماشین WMT21 نیویس ترجمہ ٹاکس کے لئے', 'uz': 'Edinburgh universitetet Bengali-Hindi Submissions to WMT21 News Tayyorlari', 'vi': 'Sự đệ trình Ben-Hindi của Đại học Edinburgh', 'bg': 'Предложенията на Университета в Единбург на Бенгали-хинди в задачата за превод на новини', 'hr': 'Univerzitet Edinburga Bengali-Hindi podaci na WMT21 novinski prevodni zadatak', 'da': "University of Edinburgh's bengali-hindi indsendelser til WMT21 Nyhedsoversættelsesopgave", 'nl': 'De Bengaals-Hindi-inzendingen van de Universiteit van Edinburgh bij de WMT21 Nieuws Vertalingstak', 'de': 'Bengalisch-Hindi-Beiträge der Universität Edinburgh zur WMT21 News Translation Task', 'id': 'Submisi Bengali-Hindi Universitas Edinburgh ke Tugas Terjemahan Berita WMT21', 'sw': 'Chuo Kikuu cha Edinburgh Vijumbe vya Bengali-Hindi kwa kazi ya Tafsiri ya Habari za WMT21', 'fa': 'دانشگاه بنگالی-هندی دانشگاه ادینبورگ برای ترجمه خبری WMT21', 'af': 'Die Universiteit van Edimburg se Bengali-Hindi Submissions na die WMT21 Nuusvertaling Taak', 'sq': 'Bengali-Hindi i Universitetit të Edinburgut paraqitet në detyrën e përkthimit të lajmeve të WMT21', 'ko': '에든버러 대학의 방글라데시어 - 인도어가 WMT21 뉴스 번역 임무에 제출', 'am': 'የኤዲንቡር ዩንቨርስቲ የቢንጋሊ-Hindi ጉዳይ ወደ WMT21 ዜና ትርጉም ስራ', 'hy': 'Էդինբուրգի համալսարանի Բենգալի-Հինդի ներկայացումները', 'tr': 'Edimburgyň Bengali-Hindi Uniwersiteti WMT21 Haýsy Çevirme Görevi', 'ca': "Les presentacions bengalí-hindí de la Universitat d'Edimburgue a la tasca de traducció de notícies WMT21", 'az': 'Edinburgin Bengali-Hindi Üniversitesi WMT21 Haqq Çeviri Görevi', 'et': 'Edinburghi Ülikooli bengali-hindi ettepanekud WMT21 uudiste tõlkimise ülesandele', 'bn': 'এডিনবার্গ বিশ্ববিদ্যালয়ের বেঙ্গালী-হিন্দি সাবমিশন উইএমটি২১ সংবাদ অনুবাদ করার কাজ', 'fi': 'Edinburghin yliopiston bengali-hindi-julkaisut WMT21 News Translation Task', 'bs': 'Univerzitet Edinburga Bengali-Hindi podataka za WMT21 Novinski prevod', 'cs': 'Bengálsko-hindština příspěvky Univerzity v Edinburghu do WMT21 Novinky Překladatelské úkoly', 'sk': 'Predložitve bengalsko-hindijske univerze Univerze v Edinburgu na nalogo prevajanja novic WMT21', 'he': 'הנישואים בנגלי-הינדי של אוניברסיטת אדינבורג למשימת התרגום חדשות WMT21', 'ha': "The University of Edinburgh's Bengali-Hindi Submissions to the WMT21 News Translation Task", 'jv': 'Ngubah Submisi BenGali-Haini sing Universite, gawe ngupakan Aksun Wêrbêt kanggo Terjamahan sing entuk Wêrbên', 'bo': "The University of Edinburgh's Bengali-Hindi Submissions to the WMT21 News Translation Task"}
{'en': 'We describe the University of Edinburgh’s BengaliHindi constrained systems submitted to the WMT21 News Translation task. We submitted ensembles of Transformer models built with large-scale back-translation and fine-tuned on subsets of training data retrieved based on similarity to the target domain.', 'ar': 'نحن نصف الأنظمة المقيدة البنغالية الهندية لجامعة إدنبرة المقدمة إلى مهمة ترجمة الأخبار WMT21. قدمنا مجموعات من نماذج المحولات التي تم إنشاؤها بترجمة رجعية واسعة النطاق وصقلناها على مجموعات فرعية من بيانات التدريب المسترجعة بناءً على التشابه مع المجال الهدف.', 'pt': 'Descrevemos os sistemas restritos bengali↔Hindi da Universidade de Edimburgo submetidos à tarefa de tradução de notícias do WMT21. Apresentamos conjuntos de modelos Transformer construídos com tradução reversa em larga escala e ajustados em subconjuntos de dados de treinamento recuperados com base na semelhança com o domínio de destino.', 'es': 'Describimos los sistemas restringidos bengalí ↔ hindi de la Universidad de Edimburgo presentados a la tarea de traducción de noticias WMT21. Presentamos conjuntos de modelos de Transformer creados con retrotraducción a gran escala y ajustados en subconjuntos de datos de entrenamiento recuperados en función de la similitud con el dominio de destino.', 'fr': "Nous décrivons les systèmes contraints Bengali ↔ Hindi de l'Université d'Édimbourg soumis à la tâche WMT21 News Translation. Nous avons soumis des ensembles de modèles de Transformer construits avec une rétro-traduction à grande échelle et affinés sur des sous-ensembles de données d'entraînement récupérés en fonction de leur similitude avec le domaine cible.", 'ru': 'Мы описываем системы ограниченного бенгальского↔хинди Эдинбургского университета, представленные задаче перевода новостей WMT21. Представлены ансамбли моделей трансформаторов, построенные с масштабной обратной трансляцией и доработанные на подмножествах обучающих данных, полученных на основе сходства с целевой областью.', 'hi': 'हम एडिनबर्ग विश्वविद्यालय के बंगालीहिंदी↔विवश प्रणालियों का वर्णन करते हैं जो WMT21 समाचार अनुवाद कार्य के लिए प्रस्तुत किए गए हैं। हमने बड़े पैमाने पर बैक-ट्रांसलेशन के साथ बनाए गए ट्रांसफॉर्मर मॉडल के ensembles प्रस्तुत किए और लक्ष्य डोमेन के लिए समानता के आधार पर पुनर्प्राप्त किए गए प्रशिक्षण डेटा के सबसेट पर ठीक-ठाक किया।', 'ja': 'WMT 21ニュース翻訳タスクに提出されたエディンバラ大学のベンガル↔語ヒンディー語制約システムについて説明します。私たちは、ターゲットドメインとの類似性に基づいて取得されたトレーニングデータのサブセット上で微調整された大規模な逆変換で構築されたトランスフォーマーモデルのアンサンブルを提出しました。', 'zh': '述爱丁堡大学孟加拉↔印度教约束系统,付WMT21新闻译事。 交用大反平移构Transformer之会,因与域相似性检索到之教数子集而微之。', 'ga': 'Déanaimid cur síos ar chórais shrianta Bengali↔Hindi de chuid Ollscoil Dhún Éideann a cuireadh isteach chuig tasc Aistriúcháin Nuachta WMT21. Chuireamar isteach ensembles de shamhlacha Transformer a tógadh le haisaistriúchán ar scála mór agus mionchoigeartaithe ar fho-thacair de shonraí oiliúna a fuarthas bunaithe ar chosúlacht leis an spriocfhearann.', 'ka': 'ჩვენ ვებინდონის ბენდალის ჰინდის სუნივერტის განვითარებით დავწერეთ სისტემები, რომლებიც WMT21 ახალგაზრულების გადაწყვეტა საქმე. ჩვენ ტრანსპერსერის მოდელების სენემბელები, რომლებიც უფრო დიდი მაგალითი დაწყვეტილია და უკეთესი დაწყვეტილია მონაცემების სენემბელებით, რომლებიც მიღებული მიზეზის', 'hu': 'Az Edinburgh-i Egyetem bengáli hindi korlátozott rendszereit ismertetjük, amelyeket a WMT21 News Translation feladatra terjesztettek. Transzformátor modellek együtteseit küldtük be, amelyeket nagyszabású háttérfordítással építettünk és finomhangoltunk a céltartományhoz való hasonlóság alapján visszakeresett képzési adatok részhalmazaira.', 'el': 'Περιγράφουμε τα περιοριστικά συστήματα του Πανεπιστημίου του Εδιμβούργου στα Βεγγαλικά Χίντι που υποβλήθηκαν στο έργο Μετάφραση ειδήσεων WMT21. Υποβάλαμε σύνολα μοντέλων μετασχηματιστών κατασκευασμένα με μεγάλης κλίμακας μεταγραφή πίσω και συντονισμένα σε υποσύνολα δεδομένων κατάρτισης που ανακτήθηκαν με βάση την ομοιότητα με τον τομέα προορισμού.', 'it': "Descriviamo i sistemi vincolati in hindi bengalese dell'Università di Edimburgo sottoposti al compito WMT21 News Translation. Abbiamo presentato insiemi di modelli Transformer costruiti con back-translation su larga scala e perfezionati su sottoinsiemi di dati di formazione recuperati in base alla somiglianza con il dominio di destinazione.", 'kk': 'Біз Эдинбург университетінің бенгали хинди бағытталған жүйелерді WMT21 жаңалық аудару тапсырмасына жіберілген. Біз үлкен масштабтағы қайта аударылған түрлендіруші үлгілерін және мақсатты доменге ұқсас салып алған оқыту деректерінің ішкі бөлігіне қарай жасалған түрлендіруші үлгілерін жі', 'lt': 'Mes apibūdiname Edinburgo universiteto Bengalų Hindi ribotas sistemas, pateiktas WMT21 naujienų vertimo uždaviniui. Mes pateikėme Transformer modelių rinkinius, pagamintus iš didelio masto atgalinio vertimo ir tiksliai pritaikytus prie mokymo duomenų, gautų panašiai į tikslinę sritį, pogrupių.', 'mk': "We describe the University of Edinburgh's Bengali Hindi constrained systems submitted to the WMT21 News Translation task.  Пренесовме ансембли на трансформерни модели изградени со голем превед на назад и фино прилагодени на подгрупи на податоци за обука кои се добиваат врз основа на сличност со доменот на целта.", 'ml': 'ഞങ്ങള്\u200d എഡിന്\u200dബര്\u200dഗിന്\u200dറെ ബെന്\u200dഗാലി ഹിന്ദിയുടെ സിസ്റ്റീമുകളെ വിവരിച്ചുകൊടുക്കുന്നു. WMT21 വിവരങ്ങളുടെ വിവരങ്ങള്\u200d  ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റര്\u200d മോഡലുകളുടെ കൂട്ടത്തില്\u200d ഞങ്ങള്\u200d നിര്\u200dമ്മിച്ചിരിക്കുന്നു. ഗോള്\u200dട്രെയിന്\u200d ഡോമെയിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d', 'ms': "We describe the University of Edinburgh's Bengali Hindi constrained systems submitted to the WMT21 News Translation task.  Kami menghantar kumpulan model Transformer yang dibina dengan terjemahan-balik skala besar dan disesuaikan pada subkumpulan data latihan yang diterima berdasarkan persamaan dengan domain sasaran.", 'mt': "Aħna niddeskrivu s-sistemi ristretti tal-Indja Bengali tal-Università ta' Edinburgh sottomessi għall-kompitu tat-Traduzzjoni tal-Aħbarijiet tad-WMT21. Intbagħtu ensembles ta’ mudelli Transformer mibnija b’traduzzjoni retrospettiva fuq skala kbira u aġġustati fuq sottosettijiet ta’ dejta ta’ taħriġ miġbura abbażi ta’ similarità għad-dominju fil-mira.", 'mn': 'Бид Эдинбургийн Их Сургуулийн Бенгали Хинди-ын хязгаарлагдсан системийг WMT21 News Translation Task-д тайлбарлаж байна. Бид Трансфер загварын загваруудыг том хэмжээний эргээд хэлбэрээр бий болгосон, дасгал өгөгдлийн сургалтын хэсэг дээр тодорхойлдог.', 'no': 'Vi beskriver Bengali Hindi Universiteten i Edinburgen som har begrenset systemer som er sendt til WMT21 News Translation task. Vi sende ensembler av transformeringsmodeller bygd med stor tilbakeomsetjing og fint oppsett på undergrupper av opplæringsdata som er henta basert på likhet til måldomsetjinga.', 'ro': 'Descriem sistemele constrânse bengali hindi ale Universității din Edinburgh supuse misiunii WMT21 News Translation. Am prezentat ansambluri de modele Transformer construite cu traducere înapoi la scară largă și reglate fin pe subseturi de date de instruire recuperate pe baza similarității cu domeniul țintă.', 'pl': 'Opisujemy systemy z ograniczeniami Hindi bengalskiego Uniwersytetu Edynburga podane do zadania WMT21 News Translation. Przesłaliśmy zestawy modeli Transformera zbudowanych z dużą skalą tłumaczeniem wstecznym i dostrojonych na podzbiorach danych treningowych pobieranych w oparciu o podobieństwo do domeny docelowej.', 'sr': 'Opisujemo ograničene sisteme Univerziteta Edinburga Bengali Hindi koji su predali zadatku WMT21 novinskog prevoda. Predložili smo ensemble modela transformera izgrađenih sa velikom obrazovanjem natrag i napravljenim na podskicama podataka obuke koji su dobili na temelju sličnosti ciljnoj domenu.', 'so': 'Waxaannu qoraynaa nidaamka qasabka ah ee Jaamacadda Edinburgh Bengali Hindi oo lagu soo dhiibay safaarada tarjumaadka ee WMT21. Waxaannu soo dhiibnay tusaalooyin kale oo lagu dhisay turjumaan aad u weyn oo dib-u-turjumid ah, waxaana ku qornaa kooxo kooxaha waxbarashada oo lagu soo bandhigay si isku mid ah goobta loogu talagalay.', 'sv': 'Vi beskriver universitetets bengaliska hindi-system som lämnats in för WMT21 News Translation uppgiften. Vi skickade in ensembler av Transformer-modeller byggda med storskalig bakåtöversättning och finjusterade på delmängder av träningsdata hämtade baserat på likhet med måldomänen.', 'si': 'අපි එඩින්බර්න් ගේ බෙන්ගාලි හින්දි විශ්වාසයේ විශ්වාසය විස්තර කරනවා WMT21 වාර්තාව වාර්තාවක් වැඩකට පැ අපි ලොකු ස්කේල් පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස්සේ පස', 'ta': "நாங்கள் எடின்பர்க் University of Edinburgh's Bengali Hindi கட்டுப்படுத்தப்பட்ட அமைப்புகளை விவரிக்கிறோம் WMT21 செய்தி மொழிபெயர்ப்பு பணிக நாங்கள் மாற்றும் மாதிரி மாதிரிகளின் ஒப்புக்கொண்டு உருவாக்கப்பட்ட பெரிய அளவு பின்பு மொழிபெயர்ப்பு மற்றும் சிறந்த த துண்டிக", 'ur': 'ہم نے ادینڈمبر کے بنگالی ہندی یونیوریس کی تحریر کی تحریر کی سیستموں کو WMT21 نیویس ترجمہ کے کام میں سپرد کیا ہے۔ ہم نے ترنفسر موڈل کے انڈامبل کو ڈیل ڈمین کے مطابق بہت سی اسکیل پیچھے ترنژیر کے ساتھ بنایا اور بہت سی ترنژیر ڈیٹوں کے سپٹوں پر استعمال کیا۔', 'vi': 'Chúng tôi mô tả hệ thống giới hạn của Đại học Bengal của Edinburgh được gửi cho nhiệm vụ dịch chuyển bản tin WM21. Chúng tôi đã cho xem một tập hợp các mô hình transformer được xây dựng với bản dịch ngược lớn và chỉnh sửa lại thành một nhóm dữ liệu đào tạo dựa trên nét giống với miền đích.', 'uz': "We describe the University of Edinburgh's Bengali Hindi constrained systems submitted to the WMT21 News Translation task.  Transformer modellari bilan birga katta tarjima tarjima qiladigan modellarni qoʻllab berdik, va qanday foydalanish asosida olingan taʼlim maʼlumotlar tarjimasini taʼminotga bog'langan.", 'hr': 'Opisujemo ograničene sustave Univerziteta Edinburga Bengalija Hindija podignute zadatku za prevod vijesti WMT21. Predložili smo ensemble modela transformera izgrađenih s velikom razmjerom povratnog prevoda i ispravljenim na podskicama podataka obuke koji su dobili na temelju sličnosti ciljnoj domenu.', 'bg': 'Описваме ограничените системи на Бенгалски хинди от Университета в Единбург, подадени на задачата WMT21 за превод на новини. Представихме ансамбли трансформаторни модели, изградени с мащабен обратен превод и фино настроени върху поднабори от тренировъчни данни, извлечени въз основа на сходството с целевата област.', 'nl': 'We beschrijven de Bengaals Hindi beperkte systemen van de Universiteit van Edinburgh die zijn ingediend voor de WMT21 News Translation taak. We hebben ensembles van Transformer-modellen ingediend, gebouwd met grootschalige back-translation en verfijnd op subsets van trainingsgegevens die zijn opgehaald op basis van gelijkenis met het doeldomein.', 'da': "Vi beskriver University of Edinburgh's Bengali Hindi begrænsede systemer, der er indsendt til WMT21 News Translation opgaven. Vi indsendte grupper af Transformer-modeller bygget med storstilet back-translation og finjusteret på delmængder af træningsdata hentet baseret på lighed med måldomænet.", 'id': 'Kami menggambarkan sistem terbatas Bengali Hindi Universitas Edinburgh yang dihantar ke tugas WMT21 News Translation. Kami mengirimkan ensembles model Transformer yang dibangun dengan skala besar terjemahan balik dan disesuaikan pada subset data pelatihan yang ditemukan berdasarkan persamaan dengan domain target.', 'de': 'Wir beschreiben die eingeschränkten Bengali-Hindi-Systeme der Universität Edinburgh, die für die WMT21 News Translation Aufgabe eingereicht wurden. Wir haben Ensembles von Transformer-Modellen eingereicht, die mit einer großflächigen Rückübersetzung erstellt wurden und auf Teilmengen von Trainingsdaten abgestimmt wurden, die basierend auf Ähnlichkeit mit der Zieldomäne abgerufen wurden.', 'fa': 'ما سیستم\u200cهای محدودیت بنگالی هندی دانشگاه انگلیسی را توصیف می\u200cکنیم که به وظیفه ترجمه خبری WMT21 ارائه شده است. ما نشانه\u200cهای مدل تغییر\u200cپذیر ساخته شده\u200cایم با ترجمه\u200cهای پشتیبانی بزرگ و پایه\u200cهای اطلاعات تمرین\u200cگیری که بر اساس شبیه به دامنۀ هدف گرفته شده\u200cایم.', 'ko': '우리는 에든버러대학이 WMT21 뉴스 번역 임무에 제출한 방글라데시어-인디언 제약 시스템을 묘사했다.우리는 대규모 반역을 통해 구축된 변압기 모형 집합을 제출했고 목표역과의 유사성에 따라 검색된 훈련 데이터 서브집합을 미세하게 조정했다.', 'sq': "We describe the University of Edinburgh's Bengali Hindi constrained systems submitted to the WMT21 News Translation task.  We submitted ensembles of Transformer models built with large-scale back-translation and fine-tuned on subsets of training data retrieved based on similarity to the target domain.", 'af': 'Ons beskrywe die Universiteit van Edimburg se Bengali Hindi beheindelike stelsels wat aan die WMT21 Nuusvertaling taak ingestuur word. Ons het ensemble van Transformer-modelles ingestuur wat gebou is met groot-skaal terugvertaling en fyn-tuned op subartikels van onderwerp data wat opgeneem is op gelykheid tot die doel domein.', 'sw': 'Tunaelezea mfumo wa Chuo Kikuu cha Edinburgh wa Bengali wa Hindi uliopo kwa ujumbe wa Tafsiri wa Habari za WMT21. Tulifanya viungo vya mifano ya Transfer vilivyojengwa na kutafsiri kwa kiwango kikubwa cha nyuma na vizuri kwenye viungo vya taarifa za mafunzo vilivyochukuliwa kwa sababu ya usawa kwa ajili ya maeneo yanayolenga.', 'hy': 'Մենք նկարագրում ենք Էդինբուրգի համալսարանի բենգալացի հնդիացի սահմանափակ համակարգերը, որոնք ներկայացված են աշխարհի ԱՄԹ21 նորությունների թարգմանման առաջադրանքին: Մենք ներկայացրեցինք Transforme մոդելների համակարգեր, որոնք կառուցվել են մեծ մակարդակի հետ թարգմանվող և բարելավված կրթության տվյալների ենթահամակարգերի վրա, որոնք ստացվել են նպատակային բնագավառի նմանության վրա:', 'bn': 'আমরা এডিনবার্গ বিশ্ববিদ্যালয়ের বেঙ্গালী হিন্দি ব্যবস্থার ব্যাপারে বর্ণনা করছি ডিএমটি২১ সংবাদ অনুবাদ কাজে জমা  আমরা ট্রান্সফ্রান্সফার মডেলের সংস্করণ প্রদান করেছি যারা বিশাল পরিমাণ পেছনে অনুবাদের নির্মাণ করেছে এবং টার্গেট ডোমেইনের সাথে যে', 'bs': 'Opisujemo ograničene sisteme Univerziteta Edinburga Bengali Hindi koji su predali zadatku za prevod novina WMT21. Predložili smo ensemble modela transformera izgrađenih sa velikom razmjerom povratnog prevoda i ispravnom napravljenim na podskicama podataka obuke koji su dobili na temelju sličnosti ciljnoj domenu.', 'tr': 'Biz Edimburgyň Bengali Hindileriň Uniwersiteti WMT21 Haýsy terjime täblisine goýup geçirildik. Biz büyük ölçekli arka terjime bilen inşa edilen transformer modelleriniň ensembllerini gönderdik we hedef domynyň beýlekiligine daýan edilen eğitim maglumatynyň subsetlerine süýtgedildi.', 'am': 'የኤዲንቡር ዩንቨርስቲ የቢንጋል ኪንዲ ወደWMT21 የዜና ትርጓሜ ስርዓት የተገኘውን የድጋፍ ስርዓት እናሳውቃለን፡፡ ትልቅ ትርጉም እና በተመሳሳይ አካባቢ ላይ በተመሳሳይ አካባቢ የተደረገውን ትምህርት ዳታዎችን በመጠቀም የተመሳሳይ የፍላጎችን ዓይነቶች አቀረብን፡፡', 'et': 'Kirjeldame Edinburghi Ülikooli bengali hindi piiratud süsteeme, mis on esitatud WMT21 uudiste tõlkimise ülesandele. Esitasime Transformerite mudelite ansamblid, mis on ehitatud ulatusliku tagantõlkega ja täpsustatud koolitusandmete alamkogumite põhjal, mis on saadud sarnasuse põhjal sihtdomeeniga.', 'fi': 'Kuvaamme Edinburghin yliopiston bengalin hindin rajoitetut järjestelmät, jotka toimitettiin WMT21 News Translation tehtävään. Toimitimme kokoelmia Transformer-malleista, jotka on rakennettu laajamittaisella taustakäännöksellä ja hienosäädetty koulutusdatan osajoukkoihin, jotka on haettu samankaltaisuuden perusteella kohdealueeseen.', 'az': 'Biz Edinburgin Bengali Hindi Üniversitesinin WMT21 Haqq Çeviri Göndərilən Sistemlərini təsdiqləyirik. Biz büyük ölçüdə geri dönüşü və təhsil məlumatlarının altında alınan təhsil məlumatlarına bənzəri ilə inşa edilmiş Transformer modellerinin ensembüllərini göndərdik.', 'ca': "Descrivem els sistemes de la Universitat d'Edimburgu que es limitaven en Hindi bengals submetits a la tasca de traducció de notícies WMT21. We submitted ensembles of Transformer models built with large-scale back-translation and fine-tuned on subsets of training data retrieved based on similarity to the target domain.", 'cs': 'Popisujeme bengálské hindštiny univerzity v Edinburghu omezené systémy předložené na WMT21 News Translation úkol. Předložili jsme soubory modelů Transformeru postavené s rozsáhlým zpětným překladem a jemně laděné na podmnožinách tréninkových dat získaných na základě podobnosti s cílovou doménou.', 'ha': "Tuna bayyana shi a University of edinburg'in Bangali Hinddi na taƙaita tsaro da aka ƙulla shi zuwa aikin Tarjibu na WMT21. Mun samar da wasu misãlai na Transformer wanda aka gina da shi mai girma-fassarar-mai-girma kuma an sami mai kyau a kan ƙanƙan da data na tsari da aka samu da shi a kan kwamfyutan fomat.", 'jv': "Awakdhéwé rakèh seneng nggawe Universite Bengal Hong's Bengal kuwi nggawe sistem sing nyimpen kanggo nggawe barang sing bebasan bantêr Wêmêr. We filed ensembedles of Transformer modes fixed with big-scale back-translation and Fin- tuned on Subts of Learning data requested on Simlarty to the goal domain.", 'sk': 'Opisujemo bengalsko hindijsko omejene sisteme Univerze v Edinburgu, ki so bili predloženi nalogi prevajanja novic WMT21. Predložili smo komplete transformatorskih modelov, zgrajenih z obsežnim retroprevodom in natančno nastavljenih na podnabore podatkov o usposabljanju, pridobljenih na podlagi podobnosti s ciljno domeno.', 'bo': "ང་ཚོས་Edinburgh's Bengali Hindi ཡི་ཆེན་ཚོའི་ནང་དུ་WMT21 བརྡ་སྤྲོད་ཀྱི་ལས་འགན་འགོད་བྱེད་ཀྱི་ཡོད། We submitted ensembles of Transformer models built with large-scale back-translation and fine-tuned on subsets of training data retrieved based on similarity to the target domain.", 'he': 'אנחנו מתארים את המערכות המוגבלות בנגאליות של אוניברסיטת אדינבורג שנשלחו למשימת התרגום חדשות WMT21. שלחנו סמלים של דוגמנים טרנספוררים בנויים עם תרגום גבוה בקנה מידה גדולה ומתאים על תחתיות של נתונים אימונים שנאספו בהתבסס על דומות לתחום המטרה.'}
{'en': 'The Volctrans GLAT System : Non-autoregressive Translation Meets WMT21', 'es': 'El sistema Volctrans GLAT: la traducción no autorregresiva cumple con WMT21', 'pt': 'O sistema Volctrans GLAT: tradução não autorregressiva atende ao WMT21', 'ar': 'نظام Volctrans GLAT: الترجمة غير الانحدارية تلتقي WMT21', 'fr': 'Le système Volctrans GLAT\xa0: la traduction non autorégressive répond à la norme WMT21', 'zh': 'Volctrans GLAT 系统:非自归转中 WMT21 准', 'ja': 'Volctrans GLATシステム：非自動回帰翻訳がWMT 21を満たしている', 'ru': 'Система Volctrans GLAT: неавторегрессивный перевод соответствует WMT21', 'hi': 'Volctrans GLAT सिस्टम: गैर-autoregressive अनुवाद WMT21 से मिलता है', 'ga': 'Córas Volctrans GLAT: Aistriúchán Neamh-uathchéimneach Comhlíonann WMT21', 'el': 'Το σύστημα της Βόλκτρανς: Η μη αυτοανακριτική μετάφραση συναντά το WMT21', 'ka': 'Name', 'hu': 'A Volctrans GLAT rendszer: A nem autoregresszív fordítás találkozik WMT21', 'lt': 'The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21', 'mk': 'Волктранскиот GLAT систем: Неавторегресивен превод се среќава со WMT21', 'ml': 'വോള്\u200dക്ട്രാന്\u200dസ് ഗ്ലാറ്റ് സിസ്റ്റത്ത്: വ്യുഎംടി21 വിഭാഗങ്ങള്\u200d', 'ms': 'Sistem GLAT Volctrans: Terjemahan Tidak-Autoregresif bertemu WMT21', 'mn': 'Volctrans GLAT System: Autoregressive Translation Not Meets WMT21', 'kk': 'Volctrans GLAT жүйесі: авторегрессиялық аудармалы емес WMT21- ге сәйкес келеді', 'mt': 'Is-Sistema GLAT tal-Volttrani: Traduzzjoni mhux awtoregressiva tilħaq id-WMT21', 'ro': 'Sistemul GLAT Volctrans: Traducerea non-autoregresivă întâlnește WMT21', 'it': 'Il sistema GLAT Volctrans: la traduzione non autoregressiva incontra WMT21', 'pl': 'System GLAT Volctrans: Tłumaczenie nieautoresywne spełnia WMT21', 'so': 'Volctrans GLAT System: Non-autoregressive Translation Meets WMT21', 'sv': 'Volctrans GLAT-system: Icke-autoregressiv översättning möter WMT21', 'no': 'Volktrans GLAT- systemet: Ikkje autoregressivt omsetjing møter WMT21', 'ur': 'Volctrans GLAT سیسٹم: غیر-autoregressive Translation meets WMT21', 'si': 'Volctran GLAT පද්ධති', 'sr': 'Volktrans GLAT sistem: Neautoregresivni prevod susreće WMT21', 'ta': 'Volctrans GLAT அமைப்பு: தன்னியக்கமான மொழிபெயர்ப்பு WMT21 சந்திக்கிறது', 'uz': 'Name', 'vi': 'Hệ thống GLAT điện. Dịch không tự động gặp WM', 'bg': 'Системата на Волктранс GLAT: Неавторегресивният превод отговаря на WMT21', 'hr': 'Volctrans GLAT sustav: Neautoregresivni prevod susreće WMT21', 'nl': 'Het GLAT-systeem van Volctrans: niet-autoregressieve vertaling voldoet aan WMT21', 'da': 'Volctrans GLAT System: Ikke-autoregressiv oversættelse møder WMT21', 'de': 'Das Volctrans GLAT System: Nicht-autoregressive Übersetzung trifft WMT21', 'ko': 'Volctrans GLAT 시스템: WMT21 호환', 'id': 'Sistem GLAT Volctrans: Translation Non-autoregressive bertemu WMT21', 'fa': 'Name', 'sw': 'Mfumo wa GLAT wa Volctrans: Tafsiri isiyo na uhuru unakutana na WMT21', 'af': 'Name', 'tr': "Volktranlar GLAT Sistemi: Otomatik Gaýşartmaýan terjime WMT21'y ýygna", 'sq': 'Sistemi GLAT i Volktransëve: Përkthimi jo-autoregresiv takon WMT21', 'am': 'ምርጫዎች', 'az': 'Volktrans GLAT Sistemi: Otomatik Reqressiv Çeviri WMT21 ilə qarşılaşır', 'bn': 'ভল্কট্র্যান্স GLAT সিস্টেম: অক্ষরিক অনুবাদ WMT21', 'bs': 'Volctrans GLAT sustav: Ne autoregresivni prevod susreće WMT21', 'cs': 'Systém GLAT Volctrans: Neautoregresivní překlad splňuje WMT21', 'et': 'Volctransi GLAT süsteem: mittearregressiivne tõlge vastab WMT21', 'fi': 'Volctrans GLAT System: Ei-autoregressiivinen käännös kohtaa WMT21', 'hy': 'Հոլկտրանսների GLATComment', 'ca': 'El sistema GLAT Volctrans: Traducció no autoregressiva troba WMT21', 'ha': 'KCharselect unicode block name', 'sk': 'Volctrans GLAT sistem: ne-avtoregresivni prevod ustreza WMT21', 'jv': 'GLAT Sistem Bolectrans: Gak-autoRegresno Terjamahan met Wt22', 'bo': 'The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21', 'he': 'מערכת GLAT Volctrans: תרגום לא אוטורגרסיבי פוגש WMT21'}
{'en': 'This paper describes the Volctrans’ submission to the WMT21 news translation shared task for German-English translation. We build a parallel (i.e., non-autoregressive) translation system using the Glancing Transformer, which enables fast and accurate parallel decoding in contrast to the currently prevailing ', 'fr': "Cet article décrit la soumission des Volctrans à la tâche partagée de traduction de nouvelles du WMT21 pour la traduction allemand-anglais. Nous construisons un système de traduction parallèle (c'est-à-dire non autorégressif) à l'aide du Glancing Transformer, qui permet un décodage parallèle rapide et précis, contrairement aux modèles autorégressifs actuels. À notre connaissance, il s'agit du premier système de traduction parallèle pouvant être adapté à un scénario aussi pratique que la compétition WMT. Plus important encore, notre système de traduction parallèle obtient le meilleur score BLEU (35,0) pour les tâches de traduction allemand-anglais, surpassant tous les bons homologues autorégressifs.", 'ar': 'تصف هذه الورقة تقديم Volctrans للمهمة المشتركة لترجمة الأخبار WMT21 للترجمة الألمانية-الإنجليزية. نحن نبني نظام ترجمة موازٍ (أي غير ذاتي الانحدار) باستخدام Glancing Transformer ، والذي يتيح فك تشفير متوازي سريع ودقيق على عكس النماذج الانحدارية السائدة حاليًا. على حد علمنا ، هذا هو أول نظام ترجمة موازية يمكن تحجيمه لسيناريو عملي مثل مسابقة WMT. والأهم من ذلك ، أن نظامنا للترجمة المتوازية يحقق أفضل درجة BLEU (35.0) في مهمة الترجمة الألمانية-الإنجليزية ، متفوقًا في الأداء على جميع نظرائه القوية ذات الانحدار الذاتي.', 'pt': 'Este artigo descreve a submissão do Volctrans à tarefa compartilhada de tradução de notícias do WMT21 para tradução alemão-inglês. Construímos um sistema de tradução paralelo (ou seja, não autorregressivo) usando o Glancing Transformer, que permite uma decodificação paralela rápida e precisa em contraste com os modelos autorregressivos atualmente predominantes. Até onde sabemos, este é o primeiro sistema de tradução paralela que pode ser dimensionado para um cenário tão prático como a competição WMT. Mais importante ainda, nosso sistema de tradução paralela alcança a melhor pontuação BLEU (35,0) na tarefa de tradução Alemão-Inglês, superando todas as contrapartes autorregressivas fortes.', 'es': 'Este artículo describe la presentación de los Volctrans a la tarea compartida de traducción de noticias del WMT21 para la traducción alemán-inglés. Construimos un sistema de traducción paralela (es decir, no autorregresiva) utilizando el Glancing Transformer, que permite una decodificación en paralelo rápida y precisa en contraste con los modelos autorregresivos actuales. Hasta donde sabemos, este es el primer sistema de traducción paralela que se puede adaptar a un escenario tan práctico como la competencia WMT. Y lo que es más importante, nuestro sistema de traducción paralela logra la mejor puntuación BLEU (35,0) en las tareas de traducción alemán-inglés, superando a todas las contrapartes autorregresivas fuertes.', 'zh': '本文Volctrans向WMT21新闻译者德英译共之。 吾以Glance Transformer构一并行(即非自归)转换系统,方之当今流行自归模样,当得速正并行解码。 以吾所知,此一可以扩WMT竞之实者并行译统也。 重者,并译系德语- 英语翻译最佳BLEU分(35.0),优于诸强者自归应物。', 'ja': '本稿では、ドイツ語と英語の翻訳のためのWMT 21ニュース翻訳共有タスクへのVolctransの提出について述べる。現在主流の自己回帰モデルとは対照的に、高速かつ正確な並列デコードを可能にするGlancing Transformerを使用して、並列（すなわち、非自己回帰）変換システムを構築します。私たちの知る限りでは、これはWMTコンペティションのような実用的なシナリオにスケーリングできる最初の並行翻訳システムです。さらに重要なことに、当社の並行翻訳システムは、ドイツ語と英語の翻訳タスクで最高のBLEUスコア（ 35.0 ）を達成し、すべての強力な自動回帰カウンターパートを上回っています。', 'hi': "यह पेपर जर्मन-अंग्रेजी अनुवाद के लिए WMT21 समाचार अनुवाद साझा कार्य के लिए Volctrans 'सबमिशन का वर्णन करता है। हम Glancing ट्रांसफॉर्मर का उपयोग करके एक समानांतर (यानी, गैर-autoregressive) अनुवाद प्रणाली का निर्माण करते हैं, जो वर्तमान में प्रचलित autoregressive मॉडल के विपरीत तेजी से और सटीक समानांतर डिकोडिंग को सक्षम बनाता है। हमारे ज्ञान का सबसे अच्छा करने के लिए, यह पहली समानांतर अनुवाद प्रणाली है कि WMT प्रतियोगिता की तरह इस तरह के एक व्यावहारिक परिदृश्य के लिए स्केल किया जा सकता है। इससे भी महत्वपूर्ण बात यह है कि हमारी समानांतर अनुवाद प्रणाली जर्मन-अंग्रेजी अनुवाद कार्य पर सबसे अच्छा BLEU स्कोर (35.0) प्राप्त करती है, जो सभी मजबूत ऑटोरिग्रेसिव समकक्षों को पछाड़ती है।", 'ru': 'Эта статья описывает представление Volctrans к общей задаче перевода новостей WMT21 для перевода на немецкий и английский языки. Мы создаем параллельную (т.е. неавторегрессивную) систему перевода с использованием Glancing Transformer, которая обеспечивает быстрое и точное параллельное декодирование в отличие от преобладающих в настоящее время авторегрессивных моделей. Насколько нам известно, это первая параллельная система перевода, которая может быть масштабирована до такого практического сценария, как конкуренция WMT. Что более важно, наша система параллельного перевода достигает лучшего балла BLEU (35,0) в задаче немецко-английского перевода, превосходя все сильные авторегрессивные аналоги.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht Volctrans chuig an tasc comhroinnte aistriúcháin nuachta WMT21 don aistriúchán Gearmáinis-Béarla. Déanaimid córas aistriúcháin comhthreomhar (i. Chomh fada agus is eol dúinn, is é seo an chéad chóras aistriúcháin comhthreomhar is féidir a scála go dtí cás praiticiúil cosúil le comórtas WMT. Níos tábhachtaí fós, baineann ár gcóras aistriúcháin comhthreomhar leis an scór BLEU is fearr (35.0) ar thasc aistriúcháin Gearmáinise-Béarla, rud a sháraíonn gach comhghleacaí uathchéimnitheach láidir.', 'ka': 'ამ დოკუნტის შეტყობინებაში WMT21 ინფორმაციის გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმებისთვის დააწერა. ჩვენ შევქმნით პარალელური (ანუ, არავტორეგრესიგური) გადაწყვეტილების სისტემა, რომელიც Glancing ტრანფორმაციის გამოყენებით, რომელიც ძალიან წყვეტილი და მარტივი პარალელური გადაწყვეტილების კონტრას ჩვენი უკეთესი მეცნიერებისთვის, ეს არის პირველი პარალელური გაგრძელების სისტემა, რომელიც შეიძლება იყოს ასეთი პრაქტიკური სინარიოში, როგორც WMT კონკრენტებ უფრო მნიშვნელოვანია, ჩვენი პარალელი გაგრძელების სისტემა უფრო მნიშვნელოვანია BLEU წერტილი (35.0) გერმანული-ანგლისური გაგრძელების საქმე, რომელიც ყველა ძალიან ავტო', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή των Volctrans στο κοινό έργο μετάφρασης ειδήσεων WMT21 για γερμανική-αγγλική μετάφραση. Κατασκευάζουμε ένα παράλληλο (δηλαδή μη αυτοανακριτικό) σύστημα μετάφρασης χρησιμοποιώντας τον μετασχηματιστή που επιτρέπει γρήγορη και ακριβή παράλληλη αποκωδικοποίηση σε αντίθεση με τα σημερινά μοντέλα αυτοανακριτικής. Από όσο γνωρίζουμε, πρόκειται για το πρώτο σύστημα παράλληλης μετάφρασης που μπορεί να κλιμακωθεί σε ένα τέτοιο πρακτικό σενάριο όπως ο διαγωνισμός WMT. Το πιο σημαντικό είναι ότι το σύστημα παράλληλης μετάφρασης μας επιτυγχάνει την καλύτερη βαθμολογία σε γερμανικό-αγγλικό μεταφραστικό έργο, ξεπερνώντας όλους τους ισχυρούς αυτοανακριτικούς ομολόγους.', 'it': "Questo articolo descrive l'invio dei Volctrans al compito condiviso di traduzione delle notizie WMT21 per la traduzione tedesco-inglese. Costruiamo un sistema di traduzione parallelo (cioè non autoregressivo) utilizzando il Glancing Transformer, che consente una decodifica parallela veloce e accurata in contrasto con i modelli autoregressivi attualmente prevalenti. Per quanto ne sappiamo, questo è il primo sistema di traduzione parallela che può essere scalato a uno scenario così pratico come il concorso WMT. Ancora più importante, il nostro sistema di traduzione parallela raggiunge il miglior punteggio BLEU (35,0) nel compito di traduzione tedesco-inglese, superando tutte le controparti autoregressive forti.", 'hu': 'Ez a tanulmány bemutatja a Volctrans benyújtását a WMT21 hírfordítási megosztott feladatra a német-angol fordításhoz. Párhuzamos (azaz nem autoregresszív) fordítási rendszert építünk a Glancing Transformer segítségével, amely gyors és pontos párhuzamos dekódolást tesz lehetővé a jelenleg uralkodó autoregresszív modellekkel szemben. Legjobb tudásunk szerint ez az első olyan párhuzamos fordítási rendszer, amely olyan gyakorlati forgatókönyvre bővíthető, mint a WMT verseny. Ami még fontosabb, párhuzamos fordítási rendszerünk a legjobb BLEU pontszámot (35,0) érte el a német-angol fordítási feladatokban, felülmúlva minden erős autoregresszív megfelelőt.', 'lt': 'Šiame dokumente aprašomas „Volctrans“ pateiktas WMT21 naujienų vertimo bendras darbas vokiečių ir anglų kalbomis. We build a parallel (i.e., non-autoregressive) translation system using the Glancing Transformer, which enables fast and accurate parallel decoding in contrast to the currently prevailing autoregressive models.  To the best of our knowledge, this is the first parallel translation system that can be scaled to such a practical scenario like WMT competition.  More importantly, our parallel translation system achieves the best BLEU score (35.0) on German-English translation task, outperforming all strong autoregressive counterparts.', 'ms': 'Kertas ini menggambarkan penghantaran Volctrans kepada tugas terkongsi terjemahan berita WMT21 untuk terjemahan bahasa Jerman-Inggeris. Kami membina sistem terjemahan selari (i.e., bukan-autoregresif) menggunakan Transformer Glancing, yang membolehkan penyahkodan selari yang pantas dan tepat secara bertentangan dengan model autoregresif yang kini berkuasa. Untuk yang terbaik dari pengetahuan kita, ini adalah sistem terjemahan paralel pertama yang boleh diperbaiki ke skenario praktik seperti persaingan WMT. Yang lebih penting, sistem terjemahan selari kita mencapai skor BLEU terbaik (35.0) pada tugas terjemahan Jerman-Inggeris, melebihi semua rekan-rekan yang kuat.', 'ml': 'ഈ പത്രത്തില്\u200d വോള്\u200dക്ട്രാന്\u200dസിന്\u200dറെ സന്ദേശങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നത് ജര്\u200dമ്മന്\u200d- ഇംഗ്ലീഷ് പരിഭാഷക്ക്  നിലവിലുള്ള സ്വതന്ത്രീകരണ മാതൃകങ്ങള്\u200dക്ക് വേഗത്തിലും കൃത്യമായ പാരാളല്\u200d ഡോകോഡിങ്ങിന് വേര്\u200dതിരിച്ചുകൊടുക്കുന്നതിന് വേണ്ടിയാണ് നാം ഒരു പരാ നമ്മുടെ അറിവിന്റെ ഏറ്റവും നല്ലതിന് ഇതാണ് ആദ്യത്തെ പാരാളില്\u200d പരാജയപ്പെടുത്തുന്ന സിസ്റ്റമാണ്. അത് WMT പോലുള്ള ഒരു പ്രാക കൂടുതല്\u200d പ്രധാനപ്പെട്ടതാണ്, നമ്മുടെ അടയാളപ്പെട്ട പരിഭാഷയുടെ സിസ്റ്റം ജര്\u200dമ്മന്\u200d- ഇംഗ്ലീഷ് പരിഭാഷണ ജോലിയില്\u200d ഏറ്റവും നല്ല ബില്ലൂ സ', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni tal-Volctrans għat-traduzzjoni tal-aħbarijiet tad-WMT21 kompitu kondiviż għat-traduzzjoni Ġermaniża-Ingliża. Aħna nibnu sistema ta’ traduzzjoni parallel a (jiġifieri, mhux awtoregressiva) bl-użu tat-Transformatur tal-Ħġi e ġ, li tippermetti dekodifikazzjoni parallela mgħa ġġla u preċi ża b’kuntrast mal-mudelli awtoregressivi attwali. Għall-a ħjar għarfien tagħna, din hija l-ewwel sistema ta’ traduzzjoni parallel a li tista’ tiġi skalata għal xenarju prattiku bħal kompetizzjoni WMT. Aktar importanti minn hekk, is-sistema ta’ traduzzjoni parallela tagħna tikseb l-aħjar punteġġ BLEU (35.0) dwar il-kompitu ta’ traduzzjoni Ġermaniża-Ingliż, u taqbeż il-kontropartijiet awtoregressivi b’saħħithom kollha.', 'kk': 'Бұл қағаз Волктрандардың WMT21 жаңалық аудармаларды неміс- ағылшын аудармаларының ортақ тапсырмасына жіберілуін анықтайды. Біз параллельді (т. е. авторегрессивні емес) аудару жүйесін Glancing транформациясы қолданып құрамыз. Бұл қазіргі авторегрессивні үлгілеріне қарсы тез және дұрыс параллельді декодтау мүмкіндік береді. Біздің біліміздің ең жақсы түсініктеріміз үшін, бұл WMT конкурсы сияқты, бірінші параллель аудару жүйесі. Ең маңызды, біздің параллелі аудармалар жүйесіміз неміс- ағылшын аудармалар тапсырмасының ең жақсы BLEU нәтижесін (35. 0) жеткізеді. Бүкіл күшті авторегрессиялық контрабаттарының', 'no': 'Denne papiret skildrar Volctrans- tillegget til WMT21- nyhetskomsettelsen delt oppgåve for tysk- engelsk omsetjing. Vi bygger eit parallell (t.d. ikkje-autoregressivt) omsetjingssystem ved hjelp av Glancing Transformer, som gjer rask og nøyaktig parallell dekoding i kontrast til den gjeldande autoregressiv modelane. Dette er den første parallelle omsetjingssystemet som kan skalerast til slik praktisk scenario som WMT-konkurranse. Det er viktigere at parallelle omsetjingssystemet vår når det er beste BLEU-poeng (35,0) på omsetjingssystemet tysk-engelsk, som utfører alle sterke autoregressive mottakarar.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie Volctrans do wspólnego zadania tłumaczenia wiadomości WMT21 dla tłumaczenia niemiecko-angielskiego. Budujemy równoległy (tj. nieautoregresywny) system tłumaczeń z wykorzystaniem transformatora Glancing, który umożliwia szybkie i dokładne dekodowanie równoległe w przeciwieństwie do obecnie panujących modeli autoregresywnych. Według naszej najlepszej wiedzy jest to pierwszy system tłumaczeń równoległych, który można skalować do tak praktycznego scenariusza jak konkurencja WMT. Co ważniejsze, nasz system tłumaczeń równoległych osiąga najlepszy wynik BLEU (35.0) w zadaniu tłumaczenia niemiecki-angielski, przewyższając wszystkie silne autoregresywne odpowiedniki.', 'mk': 'Овој весник ја опишува поднесувањето на Волктранс на заедничката задача за превод на вестите на WMT21 за германско-англиски превод. Создаваме паралелен (т.е., неавторегресивен) преводен систем со користење на Glancing Transformer, кој овозможува брзо и прецизно паралелно декодирање во разлика од моменталните авторегресивни модели. Според нашето знаење, ова е првиот паралелен преведувачки систем кој може да се промени на такво практично сценарио како натпреварот на ВМТ. Поважно е, нашиот паралелен преведувачки систем постигнува најдобра оценка БЛЕУ (35,0) за германско-англиската преведувачка задача, надминувајќи ги сите силни авторегресивни колеги.', 'ro': 'Această lucrare descrie transmiterea Volctrans la sarcina comună de traducere a știrilor WMT21 pentru traducerea germană-engleză. Construim un sistem de traducere paralel (adică non-autoregressiv) folosind Transformer-ul Glancing, care permite decodarea paralelă rapidă și precisă, în contrast cu modelele autoregressive actuale. Din câte știm, acesta este primul sistem de traducere paralelă care poate fi scalat la un astfel de scenariu practic precum concursul WMT. Mai important, sistemul nostru de traducere paralelă obține cel mai bun scor BLEU (35,0) în sarcina de traducere germană-engleză, depășind toate omologii autoregresivi puternici.', 'mn': 'Энэ цаас Волктрануудын WMT21 мэдээллийн орчуулалтыг Герман-Англи хэлний орчуулалтын хуваалцааны ажлыг тайлбарладаг. Бид одоогийн авторегрессийн загварын эсрэг хурдан, шууд параллел шилжүүлэх системийг бүтээж байна. Хамгийн сайн мэдлэгтэй нь энэ бол WMT өрсөлдөөнд анхны параллел орчуулах систем юм. Хамгийн чухал нь бидний параллель орчуулах систем Герман-Англи орчуулах ажлын хамгийн сайн BLEU оноо (35.0) гарч ирнэ. Бүх хүчтэй авторегрессийн хамтрагчдыг илүү хүчтэй болгодог.', 'so': 'Warqaddan waxaa ku qoran warqada loo soo dhiibay Volctrans warqada warqada WMT21 oo loo qeybiyey shaqada lagu turjumay Jarmal-Ingiriis. Waxaannu dhisnaa nidaamka turjumista (tusaale ahaan aan auto-regressive) oo lagu isticmaalayo Glancing Transfer, kaas oo awoodda u dhigi kara soodi iyo si saxda ah, si kala duwan sameynta qaababka aan horay u qornayn. ugu fiican aqoontayada, kanu waa nidaamka ugu horreeya turjumista ee lambarka ah, kaas oo loo dhigi karo qaab dhaqdhaqaaq ah oo u eg tartanka WMT. Inta ugu muhiimsan, nidaamka turjumaadda ee lambarka ah wuxuu gaadhaa kooxda ugu wanaagsan ee BLEU (35.0) oo ku qoran shaqada turjumidda Jarmalka- Ingiriiska, wuxuuna sameynayaa dhammaan saaxiibbada xoogga badan oo madax u adag.', 'sv': 'Denna uppsats beskriver Volctrans inlämnande till WMT21 nyhetsöversättning delade uppgift för tysk-engelsk översättning. Vi bygger ett parallellt (dvs. icke-autoregressivt) översättningssystem med hjälp av Glancing Transformer, som möjliggör snabb och exakt parallellavkodning i motsats till de nuvarande autoregressiva modellerna. Så vitt vi vet är detta det första parallella översättningssystemet som kan skalas till ett så praktiskt scenario som WMT-tävling. Ännu viktigare är att vårt parallellöversättningssystem uppnår den bästa BLEU-poängen (35,0) på tysk-engelska översättningsuppgifter, vilket överträffar alla starka autoregressiva motsvarigheter.', 'ur': "This paper describes the Volctrans' submission to the WMT21 news translation shared task for German-English translation. ہم ایک مشابہ (یعنی غیر autoregressive) ترجمہ سیستم کو گلانسینگ ترجمہ کرنے والے کے مطابق بناتے ہیں، جس نے سریع اور دقیق parallel decoding کو موجود ہونے والی autoregressive موڈل کے مقابلے میں قائم رکھا ہے. ہمارے بہترین علم کے لئے یہ سب سے پہلی parallel translation system ہے جو WMT مقابلہ کے مطابق اس طرح کی عمدہ سینارییو پر مٹا سکتی ہے۔ اور زیادہ اہم بات ہے کہ ہماری مختلف ترجمہ سیسٹم جرمن-انگلیسی ترجمہ کی تابع پر بہترین BLEU اسکور (35.0) حاصل کرتی ہے، تمام قوی autoregressive کنٹرپارتوں سے زیادہ زیادہ اضافہ کرتی ہے۔", 'si': 'මේ පැත්තේ වොල්ක්ටරාන්ස්ගේ පිළිබඳය WMT21 වාර්තාව අවවාදය සඳහා ජර්මාන්-ඉංග්\u200dරීසි අවවාදය සඳහා භ අපි සාමාන්\u200dය (ඉතින්, ස්වයංක්\u200dරියාන්\u200dය නොස්වයංක්\u200dරියාන්\u200dය) පද්ධතියක් නිර්මාණය කරන්නේ Glancing ප්\u200dරවර්තනයක් භාවිත කරන්න, ඒක ඉක්මනින් සහ ස අපේ දැනගන්න හොඳම දේවල්, මේක තමයි පළමු සමාන්\u200dය වාර්ථාව පද්ධතිය, ඒ වගේම WMT ප්\u200dරශ්නයක් වගේ ප්\u200dරයෝජනයක් වි වඩා වැදගත්, අපේ සාමාන්\u200dය වාර්තාව පද්ධතියේ හොඳම BLUE ප්\u200dරමාණය (35.0) ජර්මාන්-ඉංග්\u200dරීසි වාර්තාවේ සැලසුම් ස්වයංක්\u200dරී', 'ta': "This paper describes the Volctrans' submission to the WMT21 news translation shared task for German- English translation. நாங்கள் ஒரு இணைப்பு (அதாவது, தானியங்கி கட்டுப்படுத்தாத) மொழிபெயர்ப்பு அமைப்பை பயன்படுத்தி உருவாக்குகிறோம், அது தற்போது தானியங்கியுள்ள தானியங்கி கட எங்கள் அறிவின் சிறந்ததுக்கு, இது முதல் ஒப்பிட்ட மொழிபெயர்ப்பு அமைப்பு, WMT போன்ற ஒரு செயல்பாட்டிற்கு ஒப்பிட முடியும முக்கியமாக, எங்கள் இணைய மொழிபெயர்ப்பு அமைப்பு ஜெர்மன்- ஆங்கிலம் மொழிபெயர்ப்பு பணியில் சிறந்த பிலியு மதிப்பு (35. 0) பெறுகிறது, அனைத்த", 'sr': 'Ovaj papir opisuje podnošenje Volktransa na WMT21 novinski prevod zajedničkog zadatka za njemački-engleski prevod. Mi izgradimo paralelni (tj. ne-autoregresivni) prevodni sistem koristeći Glancing Transformer, koji omogućava brzu i tačnu paralelnu dekodiranje suprotno trenutnim prevladajućim autoregresivnim modelima. Za najbolje od našeg znanja, ovo je prvi paralelni sustav prevoda koji se može izmijeniti na takav praktični scenario poput natjecanja WMT-a. Važnije, naš paralelni prevodni sistem postiže najbolji BLEU rezultat (35,0) na njemačkom-engleskom prevodnom zadatku, iznosi sve jake autoregresivne kolege.', 'uz': 'Ushbu qogʻoz Olmon- Ingliz tarjima uchun WMT21 news tarjima tarjima qiladigan vazifani anglatadi. Biz Joriy yuqori avto- boshqarish modellari bilan tarjima qilish tizimini ishlab chiqaramiz. Bizning eng eng yaxshi aniqligimizga, bu WMT rivojlanishiga birinchi parallel tarjima tizimi. Muhimlik darajada, bizning parallel tarjima tizimimizning eng yaxshi BLEU scori (35. 0) Olmon- Ingliz tarjima vazifasini bajaradi, hamma maktab avto-regressiv komponentlarni bajaradi.', 'vi': 'Tờ giấy này mô tả sự đệ trình của điện tín đến bản dịch tin của WM21. Được chia sẻ thông tin Đức-Anh. Chúng tôi xây dựng một hệ thống dịch song song (tức là, không có tự lực) sử dụng một hệ thống Tranlão Kéo kính, cho phép giải mã song song song song song song nhanh và chính xác tương đương với các mô hình tự thụt lùi hiện thời. Theo những gì chúng tôi biết, đây là hệ thống dịch chuyển song song đầu tiên có thể được áp dụng cho một kịch bản thực như thi đấu với WRT. Quan trọng hơn, hệ thống dịch song song của chúng ta đạt được kết quả tốt nhất của LELIU (35.0) về nhiệm vụ dịch tiếng Đức-Anh, vượt qua mọi đối tác tự vệ mạnh.', 'bg': 'Настоящата статия описва представянето на Волктранс в превода на новини, споделена задача за превод на немски-английски език. Изграждаме паралелна (т.е. неавторегресивна) преводаческа система с помощта на Гледащия трансформатор, която позволява бързо и точно паралелно декодиране за разлика от преобладаващите в момента авторегресивни модели. Доколкото знаем, това е първата паралелна преводаческа система, която може да бъде мащабирана в такъв практически сценарий като състезанието за WMT. По-важното е, че нашата паралелна преводаческа система постига най-добрия резултат (35.0) при преводаческата задача на немски-английски език, надминавайки всички силни авторегресивни колеги.', 'da': "Denne artikel beskriver Volctrans' indsendelse til WMT21 nyhedsoversættelsesopgave til tysk-engelsk oversættelse. Vi bygger et parallelt (dvs. ikke-autoregressivt) oversættelsessystem ved hjælp af Glancing Transformer, som muliggør hurtig og nøjagtig parallel afkodning i modsætning til de aktuelt gældende autoregressive modeller. Så vidt vi ved, er dette det første parallelle oversættelsessystem, der kan skaleres til et så praktisk scenarie som WMT konkurrence. Endnu vigtigere er, at vores parallelle oversættelsessystem opnår den bedste BLEU-score (35,0) på tysk-engelsk oversættelsesopgave og overgår alle stærke autoregressive modparter.", 'nl': 'Dit artikel beschrijft de indiening van de Volctrans aan de WMT21 nieuwsovertelling gedeelde taak voor Duits-Engels vertaling. We bouwen een parallelle (d.w.z. niet-autoregressieve) vertaalsysteem met behulp van de Glancing Transformer, die snelle en nauwkeurige parallelle decodering mogelijk maakt in tegenstelling tot de huidige autoregressieve modellen. Voor zover wij weten is dit het eerste parallelle vertaalsysteem dat kan worden geschaald naar een dergelijk praktisch scenario als WMT competitie. Nog belangrijker is dat ons parallelle vertaalsysteem de beste BLEU-score (35.0) behaalt op Duits-Engels vertaaltaak en alle sterke autoregressieve tegenhangers overtreft.', 'hr': 'Ovaj papir opisuje podatke Volctransa na prijevod vijesti WMT21 zajedničkog zadatka za njemački-engleski prevod. Mi izgradimo paralelni (tj. ne-autoregresivni) prevodni sustav koristeći Glancing Transformer, koji omogućava brzu i tačnu paralelnu dekodiranje suprotno trenutnim prevladajućim autoregresivnim modelima. Najbolje od naših znanja, ovo je prvi paralelni sustav prevoda koji se može izmijeniti na takav praktični scenario poput natjecanja WMT-a. Što je važnije, naš paralelni sustav prevoda postiže najbolji rezultat BLEU-a (35,0) na njemačkom-engleskom prevodnom zadatku, koji je nadmašio sve jake autoregresivne kolege.', 'de': 'Diese Arbeit beschreibt die Einreichung der Volctrans an die gemeinsame Aufgabe der Nachrichtenübersetzung WMT21 für die deutsch-englische Übersetzung. Wir bauen ein paralleles (d.h. nicht autoregressives) Übersetzungssystem mit dem Glancing Transformer, das eine schnelle und genaue parallele Dekodierung im Gegensatz zu den derzeit vorherrschenden autoregressiven Modellen ermöglicht. Nach bestem Wissen ist dies das erste Parallelübersetzungssystem, das auf ein so praktisches Szenario wie WMT-Wettbewerb skaliert werden kann. Noch wichtiger ist, dass unser Parallelübersetzungssystem den besten BLEU-Score (35.0) für Deutsch-Englisch-Übersetzungsaufgaben erzielt und alle starken autoregressiven Pendants übertrifft.', 'fa': 'این کاغذ تحویل Volctrans را به ترجمه خبری WMT21 برای ترجمه آلمانی- انگلیسی مشخص می\u200cکند. ما سیستم ترجمه\u200cهای پارالی (یعنی غیر autoregressive) را با استفاده از ترجمه\u200cکننده گلانسینگ ساختیم که به سرعت و دقیق دستگاه\u200cهای پارالی در مقابل مدل\u200cهای خودگریزگریزگری که در حال حاضر فراگیر می\u200cکنند توانایی می\u200cدهد. برای بهترین دانش ما، این اولین سیستم ترجمه\u200cهای متفاوتی است که می\u200cتواند به چنین سیناریو عملی مثل رقابت WMT مقیاس شود. مهم\u200cتر از این، سیستم ترجمه\u200cهای مشابهی ما بهترین امتیاز BLEU (35.0) در کار ترجمه\u200cهای آلمان و انگلیسی را می\u200cرساند، که از تمام کنترل\u200cهای خودگریزگریزگریزگریزگری قوی\u200cتر انجام می\u200cدهد.', 'sw': 'Gazeti hili linaelezea mada ya Volctrans kwa tafsiri ya habari ya WMT21 ilisambazwa kazi kwa ajili ya tafsiri ya Kijerumani-Kiingereza. Tunajenga mfumo wa kutafsiri (yaani, usio na kudhibiti) kwa kutumia Transfer ya Glancing, ambao unawezesha kupunguza kwa haraka na sahihi tofauti na mifano ya kudhibiti kwa sasa. Kwa ufahamu mzuri zaidi, hii ni mfumo wa kwanza wa tafsiri uliofanana na usambazaji ambao unaweza kulinganishwa na hali halisi kama ushindani wa WMT. Kimuhimu zaidi, mfumo wetu wa kutafsiri uliofanana unafanikiwa vipindi bora vya BLEU (35.0) katika kazi ya utafsiri wa Kijerumani na Kiingereza, kwa kuwafanya wapinzani wote wenye nguvu za kudhibiti.', 'ko': '본고는 자원봉사자들이 WMT21 뉴스 번역 공유 임무에 제출한 덕영 번역을 묘사한다.우리는 스캔 변환기를 사용하여 병행(즉 비자귀환) 번역 시스템을 구축했다. 현재 유행하는 자귀환 모델에 비해 이 시스템은 신속하고 정확한 병행 디코딩을 실현할 수 있다.WMT 경연 등 실제 장면까지 확장할 수 있는 병행 번역 시스템은 이번이 처음인 것으로 알려졌다.더 중요한 것은 우리의 평행 번역 시스템이 독일어-영어 번역 임무에서 가장 좋은 BLEU 점수(35.0)를 얻었기 때문에 모든 강자 회귀 대응 시스템보다 우수하다.', 'tr': "Bu kagyz Volktranlaryň WMT21 täze terjime edilen nemes-iňlisçe terjime etmäge rugsat berýär. Biz parallel bir terjime sistemi Glancing Transformer'i ulanarak (meselâ, otoregressiv olmayan) terjime sistemini çalt we dogry bir ködleme sistemini häzirki ýerleşýän otoregressiv nusgalaryň üstine mümkin edip bilýäris. Bilgimiziň iň gowy bolsa, bu WMT ýaly praktik senaryýa çykyp biljek ilkinji parallel terjime sistemidir. Daha möhüm bolsa, parallel terjime sistemamyz bolan BLEU nişanlarynyň (35.0) iňlisçe terjime täblisinde iň gowy netijesini ýetip bilýär, hemme güýçli awtomatik gresif suratlarynyň üstünde çykarypdyr.", 'af': "Hierdie papier beskrywe die Volctrans se onderskrywing na die WMT21 nuusvertaling gedeelde taak vir Duits- Engels vertaling. Ons bou 'n parallel e (bv. non- autoregressive) vertalingsstelsel met gebruik van die Glancing Transformer, wat aktiveer vinnige en presies parallele dekoding in kontras met die huidiglik oorvloediende autoregressiewe modele. Op die beste van ons kennis is dit die eerste parallele vertalingsstelsel wat kan skaleer word na so 'n praktiese scenario soos WMT-mededing. Nog belangrik, ons parallele vertalingsstelsel bereik die beste BLEU-punt (35.0) op Duitse-Engelse vertalingstaak, uitgevoer alle sterke autoregressiewe kontrakenaars.", 'am': 'ይህ ፕሮግራም የፎልካራን ለWMT21 ዜና ትርጉም ለጀርመን-እንግሊዘኛ ትርጓሜ የተካፈለ ስራ ይናገራል፡፡ የግልጋሎችን ትርጓሜ በመጠቀም ተርጓሚዎች (አናም፣ ለራሱ-ሥርዓት የሌለው) ሲስተካከል እናደርጋለን፡፡ ይህም አሁን በተከበረው ራሳቸውን ሥልጣን ምሳሌዎችን በተለይታ ፈጥኖ እና አስተያየት ይችላል፡፡ ወደምናውቀው ወደሚሻለው ነገር፣ ይህ የመጀመሪያው ተርጓሚው ስርዓት ነው፤ እንደዚህ ወደ WMT ተቃውሞ ይደረግ ዘንድ ይችላል፡፡ ከዚህም ይልቅ የተለየ ትርጓሜያችን የባሕላዊ ትርጉም ስርዓት በጀርመን-እንግሊዘኛ ትርጉም ሥራ የተሻለ BLEU score (35.0) አግኝቷል፡፡', 'az': 'Bu kağıt Volktranların WMT21 xəbər çevirisini Alman-İngilizce çeviri üçün paylaşılan işləri təsdiqləyir. Biz Glancing Transformer vasitəsilə paralel (nəticə edilməz-autoregressiv) tercümə sistemini yaradırıq, bu da hızlı və düzgün paralel dekodini artıq yüksək autoregressiv modellərin əleyhinə edər. Bizim elmimizin ən yaxşısına gəldikdə, bu ilk paralel tercümə sistemidir ki, WMT müharibəsində böyük praktik senaryoya uyğunlaşdırılabilir. Daha çox önemlidir ki, paralel tercümə sistemimiz Alman-İngilizce tercümə işlərində ən yaxşı BLEU score (35.0) olar, bütün güclü autoregressiv counterpartların üstünə gəlir.', 'hy': 'Այս աշխատանքը նկարագրում է Վոլկտրանսի ներկայացումը Գերմաներեն-անգլերեն թարգմանման համագործակցած աշխատանքին: Մենք կառուցում ենք զուգահեռ (այսինքն, ոչ ինքնաարձագանքային) թարգմանման համակարգ օգտագործելով Glashing Transforme-ը, որը հնարավորություն է տալիս արագ և ճշգրիտ զուգահեռ կոդավորումը հակառակ ներկայիս ինքնաարձագանքային մոդելներին: Մեր լավագույն գիտելիքներից սա առաջին զուգահեռ թարգմանման համակարգն է, որը կարող է մեծանալ այնպիսի պրակտիկ սցենարիա, ինչպիսին է ՀՄԹ մրցակցությունը: Ավելի կարևոր է, որ մեր զուգահեռ թարգմանման համակարգը հասնում է գերմաներեն-անգլերեն թարգմանման ամենալավ գնահատականի (35.0), որը գերմաներեն-անգլերեն թարգմանման խնդիրների վրա է, առավել մեծ է քան բոլոր ուժեղ', 'id': 'Kertas ini menggambarkan pengiriman Volctrans ke terjemahan berita WMT21 tugas berbagi untuk terjemahan bahasa Jerman-Inggris. Kami membangun sistem terjemahan paralel (i.e., tidak-autoregresif) menggunakan Glancing Transformer, yang memungkinkan dekoding paralel cepat dan akurat dalam perbedaan dengan model autoregresif yang kini berkuasa. Untuk yang terbaik dari pengetahuan kita, ini adalah sistem terjemahan paralel pertama yang dapat diperbaiki ke skenario praktis seperti kompetisi WMT. More importantly, our parallel translation system achieves the best BLEU score (35.0) on German-English translation task, outperforming all strong autoregressive counterparts.', 'bn': "This paper describes the Volctrans' submission to the WMT21 news translation shared task for German-English translation.  আমরা একটি প্যারালেল (যেমন গ্লাঙ্কিং ট্রান্সফার্ন ব্যবহার করে না স্বয়ংক্রিয়ভাবে অনুবাদ সিস্টেম তৈরি করি, যা বর্তমানে স্বয়ংক্রিয় স্বয়ংক্রিয়ভাব আমাদের জ্ঞানের সবচেয়ে ভালোভাবে এটাই প্রথম সামান্য অনুবাদ সিস্টেম যা উইএমটি প্রতিযোগিতার মত একটি বাস্তবিক দৃশ্যের স আরো গুরুত্বপূর্ণ, আমাদের প্যারালেল অনুবাদ সিস্টেম জার্মান-ইংরেজী অনুবাদের কাজে সবচেয়ে ভালো বিলিউ স্কোর (৩৫. ০) অর্জন করে, যা সকল", 'bs': 'Ovaj papir opisuje podnošenje Volktransa novinskom prevodu WMT21 zajedničkom zadatku za njemački-engleski prevod. Mi izgradimo paralelni (tj. ne-autoregresivni) prevodni sustav koristeći transformator Glancing, koji omogućava brzu i tačnu paralelnu dekodiranje suprotno trenutnim prevladajućim autoregresivnim modelima. Najbolje od našeg znanja, ovo je prvi paralelni sustav prevoda koji se može izmijeniti na takav praktični scenario poput natjecanja WMT-a. Što je važnije, naš paralelni sustav prevoda postiže najbolji rezultat BLEU-a (35,0) na njemačkom-engleskom prevodnom zadatku, koji je nadmašio sve jake autoregresivne kolege.', 'cs': 'Tento článek popisuje podání Volctrans do sdíleného úkolu překladu zpráv WMT21 pro německo-anglický překlad. Vytváříme paralelní (tzn. non-autoregresivní) překladový systém pomocí Glancing Transformer, který umožňuje rychlé a přesné paralelní dekódování na rozdíl od aktuálně převládajících autoregresivních modelů. Podle našich nejlepších znalostí se jedná o první systém paralelního překladu, který lze škálovat na takový praktický scénář, jako je WMT soutěž. A co je důležitější, náš systém paralelního překladu dosahuje nejlepšího skóre BLEU (35.0) pro německo-anglický překlad úlohy a překonává všechny silné autoregresivní protějšky.', 'ca': 'Aquest article descriu la presentació dels Volctrans a la traducció compartida de notícies WMT21 per traducció alemana-anglesa. Construim un sistema de traducció paral·lel (és a dir, no autoregressiu) utilitzant el Glancing Transformer, que permet una descodificació paral·lel ràpida i precisa en contrast amb els models autoregressius que actualment prevalen. Per millor del nostre coneixement, aquest és el primer sistema de traducció paral·lel que pot ser escalat a un escenari tan pràctic com la competició WMT. More importantly, our parallel translation system achieves the best BLEU score (35.0) on German-English translation task, outperforming all strong autoregressive counterparts.', 'et': 'Käesolevas dokumendis kirjeldatakse Volctransi esitamist WMT21 uudiste tõlkimise jagatud ülesannet saksa-inglise tõlkimiseks. Ehitame paralleelse (st mittearregressiivse) tõlkesüsteemi Glancing Transformeri abil, mis võimaldab kiiret ja täpset paralleelset dekodeerimist erinevalt praegu valitsevatest autorregressiivsetest mudelitest. Meie teadmiste kohaselt on tegemist esimese paralleelse tõlkesüsteemiga, mida saab skaleerida sellise praktilise stsenaariumiga nagu WMT konkurents. Veelgi olulisem on see, et meie paralleelne tõlkesüsteem saavutab saksa-inglise tõlketöös parima BLEU skoori (35,0), ületades kõiki tugevaid autoregressiivseid vastastikke.', 'sq': 'Ky dokument përshkruan paraqitjen e Volktranëve në përkthimin e lajmeve WMT21 për përkthimin gjerman-anglez. Ne ndërtojmë një sistem përkthimi paralel (pra jo-autoregresiv) duke përdorur Glancing Transformer, i cili lejon dekodimin paralel të shpejtë dhe të saktë në kontrast me modelet aktuale autoregresiv. To the best of our knowledge, this is the first parallel translation system that can be scaled to such a practical scenario like WMT competition.  More importantly, our parallel translation system achieves the best BLEU score (35.0) on German-English translation task, outperforming all strong autoregressive counterparts.', 'fi': 'T채ss채 artikkelissa kuvataan Volctransin toimittamaa WMT21 uutisk채채nn철st채 koskevaa yhteist채 teht채v채채 saksa-englanti k채채nn철st채 varten. Rakennamme rinnakkaisen (eli ei-autoregressiivisen) k채채nn철sj채rjestelm채n Glancing Transformerin avulla, joka mahdollistaa nopean ja tarkan rinnakkaisdekoodauksen verrattuna nykyisiin autoregressiivisiin malleihin. Tietojemme mukaan t채m채 on ensimm채inen rinnakkaisk채채nn철sj채rjestelm채, joka voidaan skaalata t채llaiseen k채yt채nn철n skenaarioon, kuten WMT-kilpailuun. Mik채 t채rkeint채, rinnakkaisk채채nn철sj채rjestelm채mme saavuttaa parhaan BLEU-pisteen (35,0) saksa-englanti k채채nn철steht채v채ss채, mik채 on parempi kuin kaikki vahvat autoregressiiviset vastineet.', 'jv': "Ngerungkat iki rambarang nggawe volct rans kanggo tarjamahan balita WW1 1 kanggo nganggo tarjamahan German-Inggris. Awak dhéwé nggawe sistem sing perusahaan (mute, iso-autoRegresén) sing dibutuhke sistem sing dadi nggawe Transformer, dadi iso nggawe sistem dadi bisa ditambah sak, dadi sing dirangkamu karo akeh antara sampeyan sing bisa model sing gawe autoRegresén dadi. Panjenengan langkung saé awakdhéwé, iki sak sistem sing perusahaan banget kanggo nguasai perusahaan sing dirampakan kanggo sembarang pratiki, kaya sing bisa pasar WWT. Awak dhéwé, sistem sing paramelan kanggo tarjamahan sing gak nggawe gerakan sing paling-paling, paling-paling kanggo tarjamahan 'BEL' (5.0) sak tarjamahan sing nganggo tarjamahan-ingkang alam, mengko iso nggawe paling-paling sing autoRegrés.", 'ha': "@ info: whatsthis Mu gina wani fassarar tarjifani (misali, ba-regressive) da ke amfani da Transformer na glanking, wanda yana iya amfani da kwamfyutan da za'a yi kwamfyuta kafin da daidaita da misãlai masu da ke kai yanzu. To the best of our knowledge, this is the first parallel translation system that can be scaled to such a practical scenario like WMT competition.  Ki muhimu, na fassarar fassarar da fassararmu ya sami mafi kyaun BLEU score (35.0) a kan aikin fassarar jeruman-Ingiriya, na sami duk masu ƙarfin kandamati faransa.", 'sk': 'Ta prispevek opisuje Volctransovo predložitev skupni nalogi prevajanja novic WMT21 za nemško-angleško prevajanje. S pomočjo Glancing Transformerja gradimo vzporedni (t.j. ne-avtoregresivni) prevajalski sistem, ki omogoča hitro in natančno vzporedno dekodiranje v nasprotju s trenutno prevladujočimi avtoregresivnimi modeli. Kolikor vemo, je to prvi vzporedni prevajalski sistem, ki ga je mogoče prilagoditi tako praktičnemu scenariju, kot je tekmovanje WMT. Naš vzporedni prevajalski sistem doseže najboljšo rezultato BLEU (35,0) pri nemško-angleškem prevajanju, kar presega vse močne avtoregresivne rezultate.', 'bo': 'ཤོག་བྱང་འདིས་ཀྱིས་སྒེར་གྱི་ནང་དུ་ཡོད་པའི་བརྡ་སྤྲོད་ཀྱི་ཆ་འཕྲིན་ཡིག ང་ཚོས་Glancing Transformer་ལག་ལེན་འཐབ་པའི་parallel (དཔེར་ན། non-autoregressive)ཡིག་ཆའི་སྔོན་ལྟར་གཞུང་ཞིག་བཟོ་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་ཆེད་དུ་འཕགས་པ་ཤེས་ཚད་ལྡན་པའི་སྐྱོན་ཤིག་ནི། འདི་ནི་WMT འཕགས་རིས་འདྲ་བར་གྱི་སྒྲིག་ཆ་ལས་མཐུན་སྒྲིག More importantly, our parallel translation system achieves the best BLEU score (35.0) on German-English translation task, outperforming all strong autoregressive counterparts.', 'he': 'העיתון הזה מתאר את ההעברה של וולקטרנס לתרגום חדשות WMT21 משימה משותפת לתרגום גרמני-אנגלי. We build a parallel (i.e., non-autoregressive) translation system using the Glancing Transformer, which enables fast and accurate parallel decoding in contrast to the currently prevailing autoregressive models.  למיטב הידע שלנו, זו מערכת התרגום המקבילה הראשונה שאפשר להגדיל לתרחיש מעשי כזה כמו תחרות WMT. יותר חשוב, מערכת התרגום המזורית שלנו משיגה את נקודת BLEU הטובה ביותר (35.0) על משימה התרגום גרמני-אנגלית, ומעבירה את כל השותפים עצמי חזקים.'}
{'en': 'Tencent Translation System for the WMT21 News Translation Task', 'ar': 'نظام Tencent Translation الخاص بمهمة ترجمة الأخبار WMT21', 'es': 'Sistema de traducción Tencent para la tarea de traducción de noticias WMT21', 'fr': 'Système de traduction Tencent pour la tâche de traduction des actualités WMT21', 'pt': 'Sistema de tradução Tencent para a tarefa de tradução de notícias WMT21', 'ja': 'WMT 21ニュース翻訳タスクのためのテンセント翻訳システム', 'ru': 'Система Перевода Tencent для Задачи Перевода Новостей WMT21', 'zh': '腾讯WMT21新闻译者统之', 'hi': 'WMT21 समाचार अनुवाद कार्य के लिए Tencent अनुवाद प्रणाली', 'ga': 'Córas Aistriúcháin Tencent don Tasc Aistriúcháin Nuachta WMT21', 'ka': 'Name', 'el': 'Δέκατο Μεταφραστικό Σύστημα για το Μεταφραστικό Έργο ειδήσεων', 'hu': 'Tencent Translation System for the WMT21 News Translation Task', 'it': 'Tencent Translation System per il WMT21 News Translation Task', 'kk': 'WMT21 жаңалық аудару тапсырмасының Tencent аудару жүйесі', 'lt': 'WMT21 naujienų vertimo užduoties tvirta vertimo sistema', 'ml': 'WMT21 വാര്\u200dത്ത വിവരങ്ങളുടെ പരിഭാഷകങ്ങള്\u200dക്കുള്ള പത്തെന്റ് പരിഭാഷക സിസ്റ്റം', 'ms': 'Tencent Translation System for the WMT21 News Translation Task', 'no': 'Comment', 'pl': 'System tłumaczeń Tencent dla WMT21 News Translation Task', 'ro': 'Sistem de traducere Tencent pentru sarcina de traducere a știrilor WMT21', 'sr': 'Tencentni prevodni sistem za WMT21 novinski prevodni zadatak', 'mn': 'WMT21 News Translation Task-ийн Tencent Translation System', 'si': 'Name', 'mk': 'Tencent Translation System for the WMT21 News Translation Task', 'so': 'Tirada turjumista ee shaqada turjumista ee WMT21', 'sv': 'Tencent Översättningssystem för WMT21 News Översättningsuppgift', 'ta': 'WMT21 செய்தி மொழிபெயர்ப்பு பணிக்கான பத்து மொழிபெயர்ப்பு அமைப்பு', 'ur': 'Name', 'mt': 'Tencent Translation System for the WMT21 News Translation Task', 'uz': 'Tarjima- ketlikni tahrirlash', 'vi': 'Hệ thống dịch xu cho công việc dịch bản tin WM21', 'nl': 'Tencent vertaalsysteem voor de WMT21 Nieuws vertaaltaak', 'bg': 'Система за превод на Тенсент за задачата за превод на новини WMT21', 'da': 'Tencent Oversættelsessystem til WMT21 Nyheder Oversættelsesopgave', 'hr': 'Tencent prevoditeljski sustav za WMT21 novinski prevoditeljski zadatak', 'de': 'Tencent Translation System für die WMT21 News Translation Task', 'id': 'Tencent Translation System for the WMT21 News Translation Task', 'sw': 'Mfumo wa Tafsiri ya 10 kwa ajili ya kazi ya Tafsiri ya Habari WMT21', 'ko': '텐센트 WMT21 뉴스 번역 임무 번역 시스템', 'sq': 'Sistemi i përkthimit Tencent për detyrën e përkthimit të lajmeve WMT21', 'fa': 'Name', 'am': 'WMT21 News Translation Task', 'az': 'WMT21 Haber Çeviri Gözməsi üçün Tencent Çeviri Sistemi', 'af': 'Tensente Vertaling Stelsel vir die WMT21 Nuus Vertaling Opdrag', 'tr': 'WMT21 Haýsy terjime Görevi üçin Tencent terjime sistemi', 'bn': 'WMT21 সংবাদ অনুবাদ কাজের জন্য ১০ সেন্ট অনুবাদ সিস্টেম', 'bs': 'Tencentni prevodni sistem za WMT21 novinski prevodni zadatak', 'et': 'Tencenti tõlkesüsteem WMT21 uudiste tõlkimise ülesande jaoks', 'fi': 'Tencent Translation System for the WMT21 News Translation Task', 'cs': 'Překladatelský systém Tencent pro WMT21 Novinky Překladatelská úloha', 'hy': 'Գործողական թարգմանման համակարգը', 'ca': 'Sistema de traducció tendent per a la tasca de traducció de notícies WMT21', 'he': 'מערכת תרגום מתוקה עבור משימה תרגום חדשות WMT21', 'sk': 'Prevajalski sistem Tencent za nalogo prevajanja novic WMT21', 'jv': 'Tenent Terusan Sistem kanggo nggo rerambungan perangkat WWT 1', 'ha': '@ label: listbox', 'bo': 'WMT21 བརྡ་སྤྱི་ཚོལ་བྱ་འགུལ་གྱི་ཆོག་ཡིག་ལག་ལ་འཇུག་པ'}
{'en': 'This paper describes Tencent Translation systems for the WMT21 shared task. We participate in the news translation task on three language pairs : Chinese-English, English-Chinese and German-English. Our ', 'ar': 'تصف هذه الورقة أنظمة ترجمة Tencent لمهمة WMT21 المشتركة. نشارك في مهمة ترجمة الأخبار على ثلاث أزواج لغوية: الصينية - الإنجليزية ، والإنجليزية - الصينية ، والألمانية - الإنجليزية. أنظمتنا مبنية على نماذج محولات مختلفة بتقنيات جديدة مقتبسة من أعمالنا البحثية الأخيرة. أولاً ، نقوم بدمج طرق مختلفة لزيادة البيانات بما في ذلك الترجمة العكسية والترجمة الأمامية والتدريب من اليمين إلى اليسار لتوسيع بيانات التدريب. نحن نطبق أيضًا تحيز التغطية اللغوية وتجديد البيانات ونُهج أخذ العينات القائمة على عدم اليقين لتحديد بيانات ذات صلة بالمحتوى وعالية الجودة من مجموعات كبيرة متوازية وأحادية اللغة. نتوقع ضبطًا دقيقًا في المجال ، نقترح أيضًا نهجًا دقيقًا "نموذج واحد مجال واحد" لنمذجة خصائص أنواع الأخبار المختلفة في مراحل الضبط وفك التشفير. إلى جانب ذلك ، نستخدم خوارزمية المجموعات القائمة على الجشع وطريقة المجموعة التحويلية لزيادة تعزيز أنظمتنا. بناءً على نجاحنا في WMT الأخير ، استخدمنا باستمرار تقنيات متقدمة مثل التدريب على دفعات كبيرة واختيار البيانات وتصفية البيانات. أخيرًا ، حقق نظامنا الصيني-الإنجليزي المقيد 33.4 درجة BLEU حساسة لحالة الأحرف ، وهي الأعلى بين جميع الطلبات المقدمة. تم تصنيف النظام الألماني-الإنجليزي في المرتبة الثانية وفقًا لذلك.', 'pt': 'Este artigo descreve os sistemas Tencent Translation para a tarefa compartilhada WMT21. Participamos da tarefa de tradução de notícias em três pares de idiomas: chinês-inglês, inglês-chinês e alemão-inglês. Nossos sistemas são construídos em vários modelos de transformadores com novas técnicas adaptadas de nosso recente trabalho de pesquisa. Primeiro, combinamos diferentes métodos de aumento de dados, incluindo tradução reversa, tradução direta e treinamento da direita para a esquerda para ampliar os dados de treinamento. Também aplicamos o viés de cobertura linguística, rejuvenescimento de dados e abordagens de amostragem baseadas em incerteza para selecionar dados relevantes de conteúdo e de alta qualidade de grandes corpora paralelos e monolíngues. Com a expectativa de ajuste fino no domínio, também propomos uma abordagem refinada de “um modelo, um domínio” para modelar características de diferentes gêneros de notícias nos estágios de ajuste fino e decodificação. Além disso, usamos algoritmo de conjunto baseado em ganância e método de conjunto transdutivo para impulsionar ainda mais nossos sistemas. Com base em nosso sucesso no último WMT, empregamos continuamente técnicas avançadas, como treinamento em grandes lotes, seleção de dados e filtragem de dados. Por fim, nosso sistema restrito de chinês-inglês atinge 33,4 pontuação BLEU com distinção entre maiúsculas e minúsculas, que é a mais alta entre todos os envios. O sistema alemão-inglês é classificado em segundo lugar de acordo.', 'es': 'Este documento describe los sistemas de traducción de Tencent para la tarea compartida WMT21. Participamos en la tarea de traducción de noticias en tres combinaciones de idiomas: chino-inglés, inglés-chino y alemán-inglés. Nuestros sistemas se basan en varios modelos de Transformer con técnicas novedosas adaptadas de nuestro trabajo de investigación reciente. En primer lugar, combinamos diferentes métodos de aumento de datos, como la traducción inversa, la traducción hacia adelante y el entrenamiento de derecha a izquierda para ampliar los datos de entrenamiento. También aplicamos enfoques de sesgo de cobertura lingüística, rejuvenecimiento de datos y muestreo basado en la incertidumbre para seleccionar datos relevantes para el contenido y de alta calidad de grandes corpus paralelos y monolingües. Esperando un ajuste fino en el dominio, también proponemos un enfoque detallado de «un modelo, un dominio» para modelar las características de los diferentes géneros de noticias en las etapas de ajuste y decodificación. Además, utilizamos el algoritmo de conjunto basado en la codicia y el método de conjunto transductivo para impulsar aún más nuestros sistemas. Basándonos en nuestro éxito en el último WMT, empleamos continuamente técnicas avanzadas, como el entrenamiento de lotes grandes, la selección de datos y el filtrado de datos. Por último, nuestro sistema limitado de chino-inglés logra una puntuación BLEU de 33,4 con distinción entre mayúsculas y minúsculas, que es la más alta de todas las presentaciones. El sistema alemán-inglés ocupa el segundo lugar en consecuencia.', 'fr': "Ce livre blanc décrit les systèmes de traduction Tencent pour la tâche partagée WMT21. Nous participons à la tâche de traduction des actualités sur trois paires de langues\xa0: chinois-anglais, anglais-chinois et allemand-anglais. Nos systèmes sont construits sur différents modèles de transformateurs avec de nouvelles techniques adaptées de nos récents travaux de recherche. Tout d'abord, nous combinons différentes méthodes d'augmentation des données, y compris la rétrotranslation, la translation avant et l'entraînement de droite à gauche pour élargir les données d'entraînement. Nous appliquons également un biais de couverture linguistique, un rajeunissement des données et des approches d'échantillonnage basées sur l'incertitude pour sélectionner des données pertinentes au contenu et de haute qualité à partir de grands corpus parallèles et monolingues. Nous proposons également une approche fine «\xa0un modèle, un domaine\xa0» pour modéliser les caractéristiques de différents genres d'actualités aux étapes de réglage et de décodage. En outre, nous utilisons un algorithme d'ensemble basé sur la cupidité et une méthode d'ensemble transductive pour renforcer davantage nos systèmes. Sur la base de notre succès lors du dernier WMT, nous avons continuellement utilisé des techniques avancées telles que la formation par lots importants, la sélection des données et le filtrage des données. Enfin, notre système chinois-anglais contraint obtient un score BLEU sensible à la casse de 33,4, ce qui est le plus élevé parmi toutes les soumissions. Le système germano-anglais est classé deuxième en conséquence.", 'ja': '本稿では、WMT 21共有タスクのためのテンセント翻訳システムについて説明する。 中国語-英語、英語-中国語、ドイツ語-英語の3つの言語ペアでニュース翻訳タスクに参加します。 私たちのシステムは、私たちの最近の研究から適応された新しい技術を使用して、さまざまなトランスフォーマーモデルに基づいて構築されています。 まず、バックトランスレーション、フォワードトランスレーション、右から左へのトレーニングを含むさまざまなデータ拡張方法を組み合わせて、トレーニングデータを拡大します。 また、言語のカバレッジバイアス、データの若返り、不確実性ベースのサンプリングアプローチを適用して、大規模な並列および単一言語のコーラからコンテンツに関連する高品質のデータを選択します。 ドメイン内の微調整を期待し、微調整およびデコード段階で異なるニュースジャンルのモデル特性をモデル化するための微細化された「1つのモデル1つのドメイン」アプローチも提案します。 さらに、私たちはシステムをさらに強化するために、強欲ベースのアンサンブルアルゴリズムと変換アンサンブル法を使用しています。 前回のWMTでの成功を踏まえ、大規模なバッチトレーニング、データ選択、データフィルタリングなどの高度なテクニックを継続的に採用しました。 最後に、制約のある中国語-英語システムは、すべての提出物の中で最も高い33.4の大文字と小文字を区別するBLEUスコアを達成します。 ドイツ・イギリス系はそれに応じて2位にランクされる。', 'zh': '本文腾讯译系统以WMT21共之。 参以三言对新闻翻译:中文-英文、英文-中文、德文-英文。 吾统建于百变形金刚,用吾近治改编之术。 先合异数以增其法,包反其译,前从右到左以广其数。 又以言语覆盖率差,数据恢复与不确定性抽样法,并行单语语料库中高质量数。 凡域之微调,细粒度一域,调解码异新闻之建模。 此外,我们用基于贪婪的集成算法和转导集成法来更加升擢我们的系统。 盖吾前WMT之成功,吾等迭用先进之术,如大批量训练,数据选择数过漉。 最后,限中英制于BLEU得分上33.4分,为一切提交之最。 德英二国统相应地排在第二。', 'hi': 'यह पेपर WMT21 साझा कार्य के लिए Tencent अनुवाद सिस्टम का वर्णन करता है। हम तीन भाषा जोड़े पर समाचार अनुवाद कार्य में भाग लेते हैं: चीनी-अंग्रेजी, अंग्रेजी-चीनी और जर्मन-अंग्रेजी। हमारे सिस्टम हमारे हाल के शोध कार्य से अनुकूलित उपन्यास तकनीकों के साथ विभिन्न ट्रांसफॉर्मर मॉडल पर बनाए गए हैं। सबसे पहले, हम प्रशिक्षण डेटा को बड़ा करने के लिए बैक-ट्रांसलेशन, फॉरवर्ड-ट्रांसलेशन और दाएं-से-बाएं प्रशिक्षण सहित विभिन्न डेटा संवर्धन विधियों को जोड़ते हैं। हम बड़े समानांतर और मोनोलिंगुअल कॉर्पोरेट से सामग्री-प्रासंगिक और उच्च गुणवत्ता वाले डेटा का चयन करने के लिए भाषा कवरेज पूर्वाग्रह, डेटा कायाकल्प और अनिश्चितता-आधारित नमूना दृष्टिकोण भी लागू करते हैं। इन-डोमेन फाइन-ट्यूनिंग के लिए उम्मीद करें, हम ठीक-ट्यूनिंग और डिकोडिंग चरणों में विभिन्न समाचार शैलियों की मॉडल विशेषताओं के लिए एक ठीक-ठाक "एक मॉडल एक डोमेन" दृष्टिकोण का भी प्रस्ताव करते हैं। इसके अलावा, हम अपने सिस्टम को और बढ़ावा देने के लिए लालच-आधारित पहनावा एल्गोरिथ्म और ट्रांसडक्टिव एनसेंबल विधि का उपयोग करते हैं। पिछले WMT में हमारी सफलता के आधार पर, हमने लगातार उन्नत तकनीकों जैसे कि बड़े बैच प्रशिक्षण, डेटा चयन और डेटा फ़िल्टरिंग को नियोजित किया। अंत में, हमारी विवश चीनी-अंग्रेजी प्रणाली 33.4 केस-संवेदनशील BLEU स्कोर प्राप्त करती है, जो सभी प्रस्तुतियों में सबसे अधिक है। जर्मन-अंग्रेजी प्रणाली को तदनुसार दूसरे स्थान पर रखा गया है।', 'ru': 'В этой статье описываются системы перевода Tencent для общей задачи WMT21. Мы участвуем в задаче перевода новостей по трем языковым парам: китайско-английский, английско-китайский и немецко-английский. Наши системы построены на различных моделях трансформаторов с использованием новых технологий, адаптированных из наших недавних исследований. Во-первых, мы объединяем различные методы увеличения данных, включая обратный перевод, прямой перевод и обучение справа налево, чтобы увеличить данные обучения. Мы также применяем подходы, основанные на языковом охвате, омоложении данных и выборке на основе неопределенности, для отбора релевантных по содержанию и высококачественных данных из крупных параллельных и одноязычных корпусов. Ожидая тонкой настройки внутри домена, мы также предлагаем мелкозернистый подход «одна модель в одном домене» к характеристикам моделей различных жанров новостей на этапах тонкой настройки и декодирования. Кроме того, мы используем алгоритм ансамбля на основе жадности и метод трансдуктивного ансамбля для дальнейшего развития наших систем. Основываясь на нашем успехе в последней WMT, мы постоянно использовали передовые методы, такие как обучение больших партий, выбор данных и фильтрация данных. Наконец, наша ограниченная китайско-английская система достигает 33,4 балла BLEU с учетом регистра, что является самым высоким показателем среди всех представлений. Немецко-английская система занимает второе место соответственно.', 'ga': "Déanann an páipéar seo cur síos ar chórais Tencent Translation don tasc roinnte WMT21. Glacaimid páirt sa tasc aistriúcháin nuachta ar thrí phéire teanga: Sínis-Béarla, Béarla-Sínis agus Gearmáinis-Béarla. Tá ár gcórais tógtha ar mhúnlaí éagsúla Claochladáin le teicnící núíosacha a cuireadh in oiriúint ónár gcuid oibre taighde le déanaí. Ar an gcéad dul síos, cuirimid modhanna éagsúla méadaithe sonraí le chéile lena n-áirítear aisaistriúchán, réamhaistriúchán agus oiliúint ó dheas go clé chun na sonraí oiliúna a mhéadú. Cuirimid i bhfeidhm freisin cur chuige claonta clúdach teanga, athnuachan sonraí agus sampláil atá bunaithe ar éiginnteacht chun sonraí ardcháilíochta a bhaineann le hábhar a roghnú ó mhórchorparáidí comhthreomhara agus aonteangacha. Ag súil le mionchoigeartú san fhearann, molaimid freisin cur chuige mionghnéasach “réimse amháin múnla a haon” maidir le saintréithe samhlacha seánraí nuachta éagsúla ag céimeanna mionchoigeartaithe agus díchódaithe. Ina theannta sin, bainimid úsáid as algartam ensemble saintbhunaithe agus modh transductive ensemble chun ár gcórais a threisiú tuilleadh. Bunaithe ar an rath a bhí orainn sa WMT deiridh, d'úsáideamar ardteicníochtaí ar bhonn leanúnach mar oiliúint bhaisc mhóra, roghnú sonraí agus scagadh sonraí. Ar deireadh, baineann ár gcóras srianta Síneach-Béarla amach 33.4 scór cás-íogair BLEU, an líon is airde i measc na n-aighneachtaí go léir. Tá an córas Gearmánach-Béarla rangaithe sa dara háit dá réir.", 'el': 'Η παρούσα εργασία περιγράφει τα μεταφραστικά συστήματα Tencent για την κοινή εργασία WMT21. Συμμετέχουμε στο έργο μετάφρασης ειδήσεων σε τρία γλωσσικά ζεύγη: Κινέζικα-Αγγλικά, Αγγλικά-Κινέζικα και Γερμανικά-Αγγλικά. Τα συστήματά μας είναι χτισμένα σε διάφορα μοντέλα μετασχηματιστών με νέες τεχνικές προσαρμοσμένες από τις πρόσφατες ερευνητικές μας εργασίες. Πρώτον, συνδυάζουμε διαφορετικές μεθόδους αύξησης δεδομένων συμπεριλαμβανομένης της αντίστροφης μετάφρασης, της μετάφρασης προς τα εμπρός και της κατάρτισης από δεξιά προς τα αριστερά για να διευρύνουμε τα δεδομένα κατάρτισης. Εφαρμόζουμε επίσης προκατάληψη γλωσσικής κάλυψης, αναζωογόνηση δεδομένων και προσεγγίσεις δειγματοληψίας βασισμένες στην αβεβαιότητα για την επιλογή δεδομένων σχετικά με το περιεχόμενο και υψηλής ποιότητας από μεγάλα παράλληλα και μονογλωσσικά σώματα. Αναμένετε για τον συντονισμό εντός του τομέα, προτείνουμε επίσης μια λεπτή προσέγγιση "ένα μοντέλο ένα τομέα" για τα χαρακτηριστικά μοντέλων διαφορετικών ειδών ειδήσεων σε στάδια λεπτού συντονισμού και αποκωδικοποίησης. Εκτός αυτού, χρησιμοποιούμε αλγόριθμο συνόλων βασισμένο στην απληστία και τη μεταγωγική μέθοδο συνόλων για να ενισχύσουμε περαιτέρω τα συστήματά μας. Με βάση την επιτυχία μας στην τελευταία εφαρμογή εφαρμόσαμε συνεχώς προηγμένες τεχνικές όπως εκπαίδευση μεγάλων παρτίδων, επιλογή δεδομένων και φιλτράρισμα δεδομένων. Τέλος, το περιορισμένο κινέζικο-αγγλικό σύστημά μας επιτυγχάνει 33.4 βαθμολογία ευαίσθητη στις πεζές κεφαλαίων, η οποία είναι η υψηλότερη από όλες τις υποβολές. Το γερμανικό-αγγλικό σύστημα κατατάσσεται στη δεύτερη θέση ανάλογα.', 'hu': 'Ez a tanulmány a WMT21 megosztott feladat Tencent Translation rendszereit ismerteti. Három nyelvpárban veszünk részt a híradításban: kínai-angol, angol-kínai és német-angol. Rendszereink különböző Transformer modellekre épülnek, új technikákkal, amelyeket a legutóbbi kutatási munkánk alapján alakítottunk ki. Először is kombináljuk a különböző adatbővítési módszereket, beleértve a visszafordítást, az előre fordítást és a jobbról balra képzést, hogy bővítsük az edzési adatokat. Nyelvi lefedettségi előírásokat, adatfiatalítást és bizonytalanságon alapuló mintavételi megközelítéseket is alkalmazunk a tartalom releváns és kiváló minőségű adatok kiválasztására nagy párhuzamos és egynyelvű korpuszokból. A domain finomhangolásra számítva javasoljuk a különböző hírműfajok modelljellemzőinek finomhangolási és dekódolási szakaszaiban történő finomhangolását és dekódolását. Emellett kapzsiság alapú együttes algoritmust és transzduktív együttes módszert használunk, hogy tovább erősítsük rendszereinket. A legutóbbi WMT sikereinek köszönhetően folyamatosan fejlett technikákat alkalmaztunk, mint például a nagy kötegelt képzés, az adatok kiválasztása és az adatszűrés. Végül a korlátozott kínai-angol rendszerünk 33,4 esetérzékeny BLEU pontszámot ér el, ami a legmagasabb az összes beadvány közül. A német-angol rendszer ennek megfelelően a második helyen áll.', 'it': 'Questo articolo descrive i sistemi di traduzione Tencent per l\'attività condivisa WMT21. Partecipiamo al compito di traduzione delle notizie su tre coppie linguistiche: cinese-inglese, inglese-cinese e tedesco-inglese. I nostri sistemi sono costruiti su vari modelli di Transformer con tecniche innovative adattate dal nostro recente lavoro di ricerca. In primo luogo, combiniamo diversi metodi di aumento dei dati tra cui back-translation, forward-translation e training da destra a sinistra per ampliare i dati di formazione. Applichiamo anche approcci di campionamento basati sull\'incertezza per selezionare dati rilevanti e di alta qualità da grandi corpora parallele e monolingue. Prevediamoci per la messa a punto in-domain, proponiamo anche un approccio a grana fine "one model one domain" alle caratteristiche del modello di diversi generi di notizie in fase di messa a punto e decodifica. Inoltre, utilizziamo l\'algoritmo ensemble basato sull\'avidità e il metodo ensemble trasduttore per potenziare ulteriormente i nostri sistemi. Sulla base del nostro successo nell\'ultimo WMT, abbiamo utilizzato continuamente tecniche avanzate come la formazione su grandi lotti, la selezione dei dati e il filtraggio dei dati. Infine, il nostro sistema cinese-inglese vincolato raggiunge il punteggio BLEU 33,4 case-sensitive, che è il più alto tra tutti i contributi. Il sistema tedesco-inglese è classificato al secondo posto di conseguenza.', 'kk': "Бұл қағаз WMT21 ортақ тапсырманың Tencent аудару жүйелерін таңдайды. Name Біз жаңалық аудару тапсырмасына үш тіл екеуінде қатысушымыз: қытайлық-ағылшын, ағылшын-қытайлық және неміс-ағылшын. Біздің жүйелеріміз жаңа зерттеулердің жұмысынан өзгертілген романдық техникаларды түрлі түрлендіруші моделдеріне құрылады. Біріншіден, біз басқа деректерді көптеу әдістерін біріктіреміз. Біріншіден, қайта аудару, алдыңғы аудару және сол жақтан оң жақтан оң жақтан оң жақтан оңға аудар Мұндай-ақ біз тілдердің мәліметтерін қайта жасау, деректерді қайта жасау және мәліметтердің негіздеген мәліметтерді таңдау үшін үлкен параллель және монолингілік корпорасының мазмұның Доменде жақсы түзетуге күту үшін біз сондай-ақ қатар түрлі жаңалық жанрының түрлі түзету және декодтамасындағы түрлі жаңалық жанрының қасиеттерін үлгілеу үшін 'бір үлгі доменге' дегенді қо Қосымша, жүйеліктерімізді жалғастыру үшін сәтті негізделген енсембул алгоритм мен аударылған енсембул әдісін қолданамыз. Соңғы WMT сәттігімізге негізделген, біз үлкен топтарды оқыту, деректерді таңдау және деректерді сүзгілеу секілді көптеген техникаларды жұмыс істедік. Соңында, қытап-ағылшын жүйесіміздің шектелген қытап-ағылшын жүйесіміз 33.4 үлкен- кішілікті BLEU нәтижесін жеткізеді, бұл барлық жіберушілердің ең жоға Неміс- ағылшын жүйесі екінші жерде тұрады.", 'ka': "Name ჩვენ ახალგაზრულების გადაწყვეტილება სამი ენაზრულების ზოგში: ჩინგლისური-ანგლისური, ანგლისური-ჩინგლისური და გერმანული-ანგლისური. ჩვენი სისტემები განსხვავებული ტრანფორმეტრის მოდელზე შექმნილია, რომელიც პრომენტიკური ტექნოგიები, რომლებიც ჩვენი ახალი სწავლების სამუშა პირველი, ჩვენ განსხვავებული მონაცემების აგგენტირების მეტი, როგორც შემდეგ გადაწყვეტა, წინ გადაწყვეტა და მარცხენა მარცხენა გადაწყვეტა განაცემების გაზ ჩვენ ასევე გამოყენებთ ენის საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი საკუთარი და მაღალური საკუთარი სა დიომინში გამოყენებული კონფიგურაციის მონაცემები, ჩვენ ასევე გამოყენებთ განსხვავებული ინფორმაციის გენერების მოდელური მოდელური მოდელური 'ერთი მოდელური დიომინი' მონაცემების მოდელური მოდე დამატებით, ჩვენ გამოვიყენებთ ალგორიტიმ და ტრანგუკუტიური ანსტემბლის მეტი, რომ ჩვენი სისტემების უფრო მეტივად გახსნა. შემდეგ WMT-ში ჩვენი წარმატებით, ჩვენ მუშაობით განვითარებული ტექნოგიები, როგორც დიდი კონფიგურაცია, მონაცემები და მონაცემების ფილტრირება. საბოლოოდ, ჩვენი კინტერესო-ანგლისო სისტემა მიიღება 33.4 სურათების სისტემა BLEU, რომელიც ყველა სამუშაო სისტემა. გერმანული-ანგლისური სისტემა შესაძლებელად მეორე ადგილში იქნება.", 'ml': 'ഈ പത്രത്തില്\u200d WMT21 പങ്കുചേര്\u200dത്ത ജോലിക്കുള്ള പത്തെന്\u200dറ് ട്രാന്\u200dസെന്\u200dസ് ട്രാന്\u200dസിന്\u200dസിസ്റ്റ മൂന്നു ഭാഷകളുടെ ജോടികളില്\u200d ഞങ്ങള്\u200d വാര്\u200dത്ത പരിഭാഷയില്\u200d പങ്കുചേര്\u200dക്കുന്നു. ചൈനീസ്- ഇംഗ്ലീഷ്, ഇംഗ്ലീഷ നമ്മുടെ സിസ്റ്റമുകള്\u200d വ്യത്യസ്ത ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റ് മോഡലുകളില്\u200d നിര്\u200dമ്മിക്കപ്പെട്ടിരിക്കുന്നു.  ആദ്യം, നമ്മള്\u200d വ്യത്യസ്ത വിവരങ്ങള്\u200d കൂട്ടിചേര്\u200dക്കുന്ന രീതികളില്\u200d പിന്നിലെ പരിശീലനത്തിന്റെ വിവരങ്ങള്\u200d വര്\u200dദ്ധിപ്പിക We also apply language coverage bias, data rejuvenation and uncertainty-based sampling approaches to select content-relevant and high-quality data from large parallel and monolingual corpora.  ഡൊമെയിനിലെ സുന്ദരിയുടെ മുന്നില്\u200d പ്രതീക്ഷിക്കുക, നമ്മള്\u200d ഒരു മോഡല്\u200d മാതൃകയില്\u200d ഒരു ഡൊമെയിനില്\u200d നിന്നും ഒരു മാതൃകയെ പ്രായശ്ചിത്തം ചെയ്യ കൂടാതെ, നമ്മള്\u200d ലോഗ്യത്തിന്\u200dറെ അടിസ്ഥാനത്തിലുള്ള ആല്\u200dഗോരിത്മിനെയും ട്രാന്\u200dഡ്വാക്ടിവേറ്റിവ് ഇൻസ്പെലിന്\u200dറെ  അവസാനത്തെ WMT-ല്\u200d ഞങ്ങളുടെ വിജയം അടിസ്ഥാനത്തില്\u200d നമ്മള്\u200d വിജയിച്ചു, വലിയ ബാച്ച് പരിശീലനം, ഡേറ്റാ തെരഞ്ഞെടുക്കുന്നതും ഡേ അവസാനം, നമ്മുടെ നിര്\u200dബന്ധിതമായ ചൈനീസ്-ഇംഗ്ലീഷ് സിസ്റ്റത്തില്\u200d 33.4 കേസ് സെന്\u200dസിറ്റീവ് ബിലൂ സ്കോര്\u200d എത്തുന്നു. എല്ല ജര്\u200dമ്മന്\u200d-ഇംഗ്ലീഷ് സിസ്റ്റം രണ്ടാമത്തെ സ്ഥലത്ത് റാഞ്ച് ചെയ്തിരിക്കുന്നു.', 'ms': "Kertas ini menggambarkan sistem Terjemahan Tensen untuk tugas terkongsi WMT21. Kami berpartisipasi dalam tugas terjemahan berita pada tiga pasangan bahasa: bahasa Cina-Inggeris, bahasa Inggeris-Cina dan bahasa Jerman-Inggeris. Our systems are built on various Transformer models with novel techniques adapted from our recent research work.  Pertama, kita menggabungkan kaedah peningkatan data yang berbeza termasuk terjemahan-belakang, terjemahan-depan dan latihan-kanan-ke-kiri untuk meningkatkan data latihan. Kami juga melaksanakan bias penyamaran bahasa, pemulihan data dan pendekatan pemampilan berdasarkan ketidakpastian untuk memilih data berkaitan-kandungan dan kualiti tinggi dari korpra paralel dan monobahasa besar. Expect for in-domain fine-tuning, we also propose a fine-grained 'one model one domain' approach to model characteristics of different news genres at fine-tuning and decoding stages.  Selain itu, kita menggunakan algoritma ensemble berasaskan keserakahan dan kaedah ensemble transduktif untuk meningkatkan sistem kita. Berdasarkan kejayaan kami dalam WMT terakhir, kami terus-menerus menggunakan teknik maju seperti latihan batch besar, pemilihan data dan penapisan data. Akhirnya, sistem bahasa Cina-Inggeris terhalang kita mencapai 33.4 skor BLEU sensitif kes, yang paling tinggi di antara semua penghantaran. Sistem Jerman-Inggeris ditetapkan di tempat kedua sesuai.", 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tat-Traduzzjoni Tendenti għall-kompitu kondiviż tad-WMT21. Aħna qed jipparteċipaw fil-kompitu tat-traduzzjoni tal-aħbarijiet fuq tliet pari lingwistiċi: Ċiniż-Ingliż, Ingliż-Ċiniż u Ġermaniż-Ingliż. Is-sistemi tagħna huma mibnija fuq mudelli differenti ta’ Transformer b’tekniki ġodda adattati mill-ħidma riċenti tagħna ta’ riċerka. L-ewwel nett, aħna ngħaqdu metodi differenti ta’ żieda fid-dejta inklużi t-traduzzjoni lura, it-traduzzjoni bil-quddiem u t-taħriġ minn lemin għal xellug biex titkabbar id-dejta tat-taħriġ. Aħna napplikaw ukoll il-preġudizzju għall-kopertura tal-lingwi, it-tiġdid tad-dejta u l-approċċi tat-teħid ta’ kampjuni bbażati fuq l-inċertezza biex nagħżlu dejta rilevanti għall-kontenut u ta’ kwalità għolja minn korpura parallela u monolingwa kbira. L-istennija għal a ġġustament fin-dominju, qed nipproponu wkoll approċċ ta\' "mudell wieħed ta\' dominju wieħed" b\'għamla fina għall-karatteristiċi mudell ta\' ġeneri differenti ta\' aħbarijiet fi stadji ta\' aġġustament fina u dekodifikazzjoni. Barra minn hekk, aħna nużaw l-algoritmu tal-ensemble ibbażat fuq il-ganċ u l-metodu tal-ensemble trasduttiv biex ikomplu jsaħħu s-sistemi tagħna. Based on our success in the last WMT, we continuously employed advanced techniques such as large batch training, data selection and data filtering.  Fl-aħħar nett, is-sistema tagħna ristretta Ċiniża-Ingliża tilħaq 33.4 punteġġ BLEU sensittiv għall-każijiet, li huwa l-ogħla fost is-sottomissjonijiet kollha. Is-sistema Ġermaniża-Ingliża hija kklassifikata fit-tieni post skont dan.', 'mn': 'Энэ цаас WMT21 хуваалцаагийн Tencent Translation System-г тайлбарладаг. Бид мэдээллийн орчуулалт гурван хэл хоёр дээр оролцсон: Хятад-Англи, Англи-Хятад, Герман-Англи. Бидний систем шинэ судалгаанаас зохицуулагдсан шинэ техникуудыг олон Трансфер загварууд дээр бий болгож байна. Эхлээд бид өөр өөр өгөгдлийн нэмэгдүүлэлтийн аргыг нэгтгэдэг. Мөн буцаад орчуулалт, урд орчуулалт, баруун-зүүн сургалт, сургалт өгөгдлийг нэмэгдүүлэх боломжтой. Бид мөн хэл дээр хэлэлцэх bias, data rejuvenation, uncertainty-based sampling approach to select content-relevant and high-quality data from large parallel and monolingual corpora. Холбооны сайхан тохиромжтой байдлаар бид мөн нэг загварын нэг загварын нэг загварын арга загварын тулд өөр өөр мэдээллийн жанрлуудын загваруудыг сайхан тохиромжтой болон тохиромжтой загваруудын заг Үүнээс гадна бид хүлээн зөвшөөрөгдсөн алгоритм болон хөрөнгө оруулах арга хэрэглэдэг. Өнгөрсөн WMT-ийн амжилтын тулд бид үргэлж хөгжсөн технологийг ажиллаж байлаа. Жишээ нь том хэмжээний сургалт, өгөгдлийн сонголт, өгөгдлийн сүзүүлэлт. Эцэст нь бидний хязгаарлагдсан Хятад-Англи хэлний систем 33.4 тохиолдолд мэдрэгддэг BLEU оноо гарч ирнэ. Энэ бол бүх хүмүүсийн хамгийн өндөр оноо. Герман-Англи систем хоёр дахь газарт тэнцүү байдаг.', 'no': 'Denne papiret skildrar Tencent- oversettelsystemet for delt WMT21- oppgåve. Vi deltar i nyhetskomsettingsoppgåva på tre språkopar: kinesisk-engelsk, engelsk-kinesisk og tysk-engelsk. Systemet våre er bygd på ulike transformeringsmodeller med novelteknikk tilpassa frå våre nyleg forskningsarbeid. Først kombinerer vi ulike dataaugmentasjonsmetodar, inkludert tilbakeomsetjing, framover-omsetjing og høgre-til-venstre trening for å auka opplæringsdata. Vi bruker også språkkomslag, dataomslag og utviklingsbaserte prøvetilnærmingar for å velja innhaldsrelevante og høg kvalitetsdata frå store parallelle og monospråk korpora. Vent for fin-tuning i domenet, fører vi også ein tilnærming med fin-korn «ein model éin domenet» til modellen av ulike nyhetsgjenrar på fin-tuning og dekoding. I tillegg bruker vi algoritmen på grønnbasert ensembelt og transduktivt ensembelmetode for å framframføre systemet våre. Basert på suksessen vårt i den siste WMT, har vi kontinuerleg arbeida avanserte teknikk som stor opplæring, datautval og filtrering. Etter slutt, vår begrenset kinesisk-engelsk system oppnår 33,4 mellom små bokstavar og små bokstavar, som er den høgste mellom alle undersøkingar. Den tyske-engelske systemet er ordna på andre plass derfor.', 'pl': 'W artykule opisano systemy tłumaczeń Tencent dla wspólnego zadania WMT21. Uczestniczymy w zadaniu tłumaczenia wiadomości na trzech parach językowych: chińsko-angielski, angielsko-chiński i niemiecki-angielski. Nasze systemy są zbudowane na różnych modelach transformatorów z nowatorskimi technikami dostosowanymi z naszych ostatnich prac badawczych. Po pierwsze, łączymy różne metody powiększania danych, w tym tłumaczenie wsteczne, tłumaczenie do przodu i szkolenie od prawej do lewej, aby powiększyć dane szkoleniowe. Stosujemy również stronniczość pokrycia języka, odmładzanie danych i podejście do próbkowania oparte na niepewności do wyboru istotnych i wysokiej jakości danych z dużych równoległych i jednojęzycznych korpusów. Oczekując dostosowania w domenie, proponujemy również precyzyjne podejście "jeden model jedna domena" do charakterystyki modelu różnych gatunków wiadomości na etapach dostrajania i dekodowania. Poza tym, używamy algorytmu zespołu opartego na chciwości i metody transdukcyjnej zespołu, aby jeszcze bardziej poprawić nasze systemy. W oparciu o nasz sukces w ostatnim WMT stale stosowaliśmy zaawansowane techniki, takie jak szkolenia dużych partii, selekcja danych i filtrowanie danych. Wreszcie, nasz ograniczony system chińsko-angielski osiąga 33.4 wynik BLEU uwzględniający wielkość liter, który jest najwyższy spośród wszystkich zgłoszeń. System niemiecko-angielski znajduje się odpowiednio na drugim miejscu.', 'lt': "This paper describes Tencent Translation systems for the WMT21 shared task.  We participate in the news translation task on three language pairs: Chinese-English, English-Chinese and German-English.  Mūsų sistemos grindžiamos įvairiais transformatorių modeliais su naujais metodais, pritaikytais iš mūsų neseniai atliktų mokslinių tyrimų. First, we combine different data augmentation methods including back-translation, forward-translation and right-to-left training to enlarge the training data.  Mes taip pat taikome kalbų aprėpties pusiausvyrą, duomenų atnaujinimą ir neapibrėžtumu pagrįstus mėginių ėmimo metodus, kad atrinktume turiniui svarbius ir kokybiškus duomenis iš didelių lygiagrečių ir vienakalbių korporų. Expect for in-domain fine-tuning, we also propose a fine-grained 'one model one domain' approach to model characteristics of different news genres at fine-tuning and decoding stages.  Be to, siekdami toliau stiprinti mūsų sistemas, naudojame troškumo pagrindu pagrįstą ansamblio algoritmą ir transdukcinį ansamblio metodą. Atsižvelgdami į mūsų sėkmę paskutinėje VMT, mes nuolat taikėme pažangius metodus, pavyzdžiui, didelės partijos mokymą, duomenų atranką ir duomenų filtravimą. Galiausiai, mūsų ribota Kinijos ir anglų sistema pasiekia 33,4 atvejų jautrių BLEU rezultatų, kuris yra didžiausias iš visų pareiškimų. Vokietijos ir anglų sistema atitinkamai antroje vietoje.", 'mk': 'This paper describes Tencent Translation systems for the WMT21 shared task.  We participate in the news translation task on three language pairs: Chinese-English, English-Chinese and German-English.  Our systems are built on various Transformer models with novel techniques adapted from our recent research work.  Прво, комбинираме различни методи за зголемување на податоците вклучувајќи назад превод, напред превод и обука десно-лево за проширување на податоците за обука. Ние, исто така, применуваме пристрасност на јазичното покривање, повторно обновување на податоците и пристапи на примероци базирани на несигурност за избор на податоци релевантни за содржината и висококвалитетни податоци од големи паралелни и монојазични Очекуваме финетизирање во домен, исто така предложуваме финетизиран пристап „еден модел еден домен“ кон моделните карактеристики на различни новински генери во финетизирање и декодирање фази. Besides, we use greed-based ensemble algorithm and transductive ensemble method to further boost our systems.  На основа на нашиот успех во последниот ВМТ, континуирано употребувавме напредни техники како што се голема партија обука, избор на податоци и филтрирање на податоци. Најпосле, нашиот ограничен кинеско-англиски систем постигнува 33,4 оценки БЛЕУ чувствителни за случаите, што е највисоко од сите поднесувања. The German-English system is ranked at second place accordingly.', 'ro': 'Această lucrare descrie sistemele de traducere Tencent pentru sarcina partajată WMT21. Participăm la sarcina de traducere a știrilor pe trei perechi de limbi: chineză-engleză, engleză-chineză și germană-engleză. Sistemele noastre sunt construite pe diferite modele Transformer cu tehnici noi adaptate din activitatea noastră recentă de cercetare. În primul rând, combinăm diferite metode de mărire a datelor, inclusiv traducerea înapoi, traducerea înainte și instruirea de la dreapta la stânga pentru a extinde datele de formare. De asemenea, aplicăm abordări de eșantionare bazate pe incertitudine pentru a selecta date relevante pentru conținut și de înaltă calitate din corpuri paralele și monolingve mari. Așteptându-vă la reglarea fină în domeniu, propunem, de asemenea, o abordare fină "un model un domeniu" a caracteristicilor modelului diferitelor genuri de știri în etapele de reglare fină și decodare. În plus, folosim algoritmul de ansamblu bazat pe lăcomie și metoda ansamblului transductiv pentru a stimula și mai mult sistemele noastre. Pe baza succesului nostru în ultimul WMT, am folosit în permanență tehnici avansate, cum ar fi instruirea pe loturi mari, selectarea datelor și filtrarea datelor. În cele din urmă, sistemul nostru chinez-englez constrâns obține 33,4 punctaj BLEU sensibil la caz, care este cel mai mare dintre toate depunerile. Sistemul german-englez este clasat pe locul doi în consecință.', 'so': "Kanu wuxuu ku qoran yahay nidaamka turjumidda Tencent ee WMT21 oo lagu qeybiyay. Waxaannu ka qeybqaadannaa shaqada turjumista ee saddex luuqadood: Shiino-Ingiriis, Ingiriis-Shiino iyo Jarmal-Ingiriis. nidaamkayaga waxaa lagu dhisay qaabab kala duduwan oo turjumista ah, waxayna leeyihiin teknolojiyo warqada ah oo loo beddelay shaqadeedii baaritaanka ee ugu dambeeyey. Marka ugu horeysa, waxaynu ku soo bandhignaa qaabab kordhinta macluumaadka kala duduwan, kuwaas oo ah koorasyada dib-tarjumidda iyo waxbarashada midig-ilaa-bidix si loo sii kordhiyo macluumaadka waxbarashada. Sidoo kale waxaynu sidoo kale ka codsanaynaa daboolka luqada, dib u soo celinta macluumaadka iyo qaababka sameynta aqoonta la'aanta, si aan uga dooranno macluumaadka ku saabsan waxyaabaha ay isku xiran yihiin iyo waxyaabaha sare ee shirkadda waaweyn oo isku mid ah iyo noocyada afka. U sugta hab-wanaag, waxaynu sidoo kale soo jeedaynaa qaab qurxoon oo qurxoon ah, hal qaab keliya oo ku habboon qaab tusaale ahaan dabeecada jinsiyadaha kala duduwan oo ku qoran jaranjarada sawirada. Sidoo kale waxaynu isticmaalnaa algorithm oo ku saleysan lacag-maalka iyo hab-dhaqdhaqaaq ah si aan u sii kordhino nidaamka. U saleysan guulaysteena ugu dambeysay WMT, waxaynu marwalba shaqeynay qalabka horumarinta ah, sida waxbarashada batch, doorashada data iyo filtering. Finally, our constrained Chinese-English system achieves 33.4 case-sensitive BLEU score, which is the highest among all submissions.  Sidoo kale nidaamka Jarmalka-Ingiriiska waxaa lagu qeybiyaa marka labaad.", 'sr': 'Ovaj papir opisuje sisteme prevoda za delovanje WMT21. Mi učestvujemo u zadatku za prevod vesti o tri jezička parova: kineski-engleski, engleski-kineski i njemački-engleski. Naši sistemi su izgrađeni na raznim modelima Transformera sa novim tehnikama prilagođenim iz našeg poslednjeg istraživanja. Prvo, kombiniramo različite metode povećanja podataka uključujući natrag prevod, predvod i desno-levo obuku kako bi proširili podatke o obuci. Također primjenjujemo pristrasnost prikrivanja jezika, ponovno otkrivanje podataka i pristupe uzoraka na osnovu neodređenosti za izabranje podataka o sadržajima relevantnih i visokokvalitetnih podataka iz velike paralelne i monojezičke korpore. Oèekujemo fino podešavanje u domenu, takoðe predlažemo pristup "jedan model jedan domen" modelu karakteristika različitih novinskih genra na fino podešavanje i dekodiranju faza. Osim toga, koristimo algoritmus na zelenoj osnovi ensemble i metodu transduktivne ensemble kako bi dalje povećali naše sisteme. Na osnovu našeg uspeha u poslednjem WMT-u, stalno smo zaposlili napredne tehnike kao što su velika obuka grupe, selekcija podataka i filtriranje podataka. Konačno, naš ograničeni kineski-engleski sistem postiže 33,4 slučajno osjetljiv BLEU rezultat, koji je najveći od svih podataka. Njemački-engleski sistem je na drugom mestu u skladu sa tim.', 'si': 'Name අපි ආරංචිත වාර්තාවේ භාෂාව තුනක් දෙනුවෙන් සම්බන්ධ වෙනවා: චීනි-ඉංග්\u200dරීසි, ඉංග්\u200dරිසි- අපේ පද්ධතිය විවිධ විදිහට විවිධ ප්\u200dරවිද්\u200dයාපකය මඩේල් එක්ක නිර්මාණය කරලා තියෙනවා අපේ අලුත් පරී මුලින්, අපි වෙනස් දත්ත විශේෂ විධානය විධානය සම්බන්ධ කරනවා පස්සේ අවවාදය, පස්සේ අවවාදය සහ දකුණු වතුර අපි භාෂාව ආවරණය ප්\u200dරතිස්ථානය, දත්ත ආවරණය සහ අනිශ්චිත විශේෂතාවක් සැම්ප්ලීම් අවස්ථාවක් අවස්ථාවක් තෝරාගන්න සහ උ ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය වෙනුවෙන්, අපි ප්\u200dරශ්නය කරනවා වෙනස් වාර්තාවක් සහ ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය කරනවා. ඒ වගේම, අපි ග්\u200dරීඩ් අධාරිත ඇන්ස්ම්බුල් ඇල්ගෝරිතම් සහ ප්\u200dරවර්තනයක් පාවිච්චි කරනවා අපේ පද්ධතිය විශේ අන්තිම WMT එකේ අපේ සාර්ථක විශ්වාස විදිහට, අපි සාමාන්\u200dය විශ්වාස කරනවා විශාල ප්\u200dරධානයක් වගේ ලොකු බෑච් ප්\u200dර අන්තිමේදි, අපේ ප්\u200dරතික්\u200dරීය චීනි-ඉංග්\u200dරීසි පද්ධතිය 33.4 කේස් සංවේදනයක් ලැබෙනවා, ඒක තමයි හැම ප්\u200dරතික්\u200dරීයා ජර්මාන්ස්-ඉංග්\u200dරීසි පද්ධතිය අනුවෙන් දෙවෙනි තැනට ඉන්නවා.', 'sv': 'Denna uppsats beskriver Tencent Translation system f철r den delade uppgiften WMT21. Vi deltar i nyhets철vers채ttningsuppgiften p책 tre spr책kpar: kinesisk-engelska, engelsk-kinesiska och tysk-engelska. V책ra system bygger p책 olika Transformermodeller med nya tekniker anpassade fr책n v책rt senaste forskningsarbete. F철r det f철rsta kombinerar vi olika dataf철rst채rkningsmetoder inklusive bak책t철vers채ttning, fram책t철vers채ttning och h철ger-till-v채nster tr채ning f철r att ut철ka tr채ningsdata. Vi till채mpar ocks책 spr책kt채ckningsbias, dataf철ryngring och os채kerhetsbaserade samplingsmetoder f철r att v채lja inneh책llsrelevanta och h철gkvalitativa data fr책n stora parallella och enspr책kiga korpora. F철rv채nta dig finjustering inom dom채nen, f철resl책r vi ocks책 en finkornig "one model one domain"-metod f철r modellegenskaper f철r olika nyhetsgenrer vid finjustering och avkodning stadier. Dessutom anv채nder vi girighetsbaserad ensemblealgoritm och transduktiv ensemblemetod f철r att ytterligare st채rka v책ra system. Baserat p책 v책r framg책ng i den senaste WMT anv채nde vi kontinuerligt avancerade tekniker s책som stor batch utbildning, dataval och datafiltrering. Slutligen uppn책r v책rt begr채nsade kinesisk-engelska system 33,4 fallk채nsliga BLEU-po채ng, vilket 채r den h철gsta bland alla inl채mningar. Det tysk-engelska systemet rankas d채rmed p책 andra plats.', 'ta': "WMT21 பகிர்ந்த பணிக்கான பத்து மொழிபெயர்ப்பு அமைப்புகளை இந்த தாள் விளக்குகிறது. @ info எங்கள் அமைப்புகள் பல மாற்று மாதிரிகளின் மீது கட்டப்பட்டுள்ளது நமது சமீபத்திய ஆய்வு வேலையிலிருந்து புதிய த முதலில், நாம் மொழிபெயர்ப்பு, முன்- மொழிபெயர்ப்பு மற்றும் இடது புறம் பயிற்சியை அதிகப்படுத்த வேறு தரவு மேம்பாட்டு முற நாம் மொழி cover bias, data recovery மற்றும் நம்பிக்கையில்லாத மாதிரி முறைமைகளை பயன்படுத்துகிறோம் பெரிய இணைப்பு மற்றும் ஒழுங்கும் நிறுவனத்திலிருந் டோமைனில் அழகான தூண்டுதலை எதிர்பார்க்கவும், நாம் நன்றாக பிடிக்கப்பட்ட 'ஒரு மாதிரி ஒரு டோமைன்' முறைமையை பரிந்துரைக்கிறோம் வேறு செய்தி  அதற்கும் மேலும், நாங்கள் உலாப்பு அடிப்படையில் உள்ள முன்னேற்றம் அல்கோரிட்டம் மற்றும் transductive ensemble முறைமையை பயன்படுத்தி  கடைசி WMT-ல் எங்கள் வெற்றியை அடிப்படையில், நாங்கள் தொடர்ந்து முன்னேற்ற தொழில்நுட்பமான தொழில்நுட்பம் பயன்படுத்தினோம Finally, our constrained Chinese-English system achieves 33.4 case-sensitive BLEU score, which is the highest among all submissions.  ஜெர்மன்-ஆங்கிலம் அமைப்பு இரண்டாவது இடத்தில் வரிசைப்படுத்தப்பட்டது.", 'ur': "This paper describes Tencent Translation systems for the WMT21 shared task. ہم تین زبان جوڑوں پر خبریں ترجمہ کا کام میں شریک ہوتے ہیں: چینی-انگلیسی، انگلیسی-چینی اور جرمن-انگلیسی. ہماری سیستمات مختلف ٹرنفسر موڈل پر بنائی گئی ہے جو ہمارے اگلے تحقیقات کے کاموں سے اضافہ کی گئی ہے۔ پہلے، ہم مختلف ڈیٹا افزایش طریقے جمع کرتے ہیں، پیچھے ترجمہ، آگے ترجمہ اور دائیں بائیں ترجمہ کے لئے ترجمہ ڈیٹا بڑھنے کے لئے۔ ہم بھی زبان کی کاوپٹ کی بحث، ڈیٹا دوبارہ جوونشن اور غیر یقین کی بنیادی نمونشن کی مطابق استعمال کرتے ہیں، جو محتوا کے معاملہ اور بلند کیفیت ڈیٹا کو بڑے parallel اور ایک زبان کی کورپور سے منتخب کریں۔ ڈومین میں فین ٹونگ کے لئے انتظار کر رہے ہیں، ہم نے بھی اچھی ٹونگ اور ڈیکوڈنگ کے مطابق مختلف نویس ژانر کے ماڈل کے مطابق 'ایک ماڈل ایک ڈومین' کے مطابق اچھی دانے کے مطابق پیشنهاد کر رہے ہیں. اس کے علاوہ، ہم اپنے سیستموں کو اضافہ کرنے کے لئے گھوٹی بنیادی آنسبل الگوریتم اور ترجمہ انسبل کا طریقہ استعمال کرتے ہیں. آخرین WMT میں ہمارے کامیابی پر بنیاد ہے، ہم نے ہمیشہ پیشرفت کی تکنولوژی کی مثال بڑی باتچ ترکین، ڈیٹا انتخاب اور ڈیٹا فیلٹرینگ کے مطابق استعمال کیا۔ آخر میں، ہماری محدودہ چین-انگلیسی سیستم 33.4 کیس-حساس BLEU اسکور پہنچ جاتی ہے، جو سب مسلمانوں میں سب سے زیادہ بلند ہے۔ جرمن-انگلیسی سیسٹم اس طرح دوسری جگہ پر قائم ہے.", 'uz': "Name @ info Bizning tizimlarimiz yaqinda o'rganish ishlarimizdan o'zgartirilgan novel teknikalar bilan boshqa tarjima modellarida yaratiladi. Birinchi so'z, taʼminlovchi maʼlumotni oshirish uchun boshqa maʼlumot qoʻshish usullarini birlashtiramiz. Biz tillar bilan birlashtirish, maʼlumotni qayta yuklash va haqiqat asoslangan samol usullarini katta parallel va monolingual kompaniyadan maʼlumotni tanlashga qoʻllamiz. Domenning yaxshi bir usulni kutib turing, biz bir model kelib, bir domen modelini bir usulning boshqa xabarlar genlarining xususiyatlarini o'zgartirish va yaxshi paydo qilish holatida modellashni davom qilamiz. Ko'pchilik uchun biz tizimimizni koʻpaytirish uchun qo'l-asosiy ensembli algoritdan foydalanamiz. Based on our success in the last WMT, we continuously employed advanced techniques such as large batch training, data selection and data filtering.  Endi, bizning qanday Xitoycha-Ingliz tizimimiz 33.4 kashfiy sensitive BLEU scori topadi. Bu hamma imkoniyatlardan eng eng eng eng eng eng katta. Olmon-Ingliz tizimi bu ikkinchi joyda birinchi joyda.", 'vi': "Tờ giấy này mô tả: Hệ thống dịch xu cho công việc chia sẻ của WM21. Chúng tôi tham gia vào nhiệm vụ dịch tin tức về ba cặp ngôn ngữ: người Anh, người Anh, người Anh và người Đức-Anh. Hệ thống của chúng tôi được xây dựng trên các mô hình biến áp khác nhau với các kỹ thuật mới thích nghi từ công trình nghiên cứu gần đây. Đầu tiên, chúng ta kết hợp các phương pháp gia tăng dữ liệu khác nhau, gồm có hậu dịch, dịch chuyển trước và từ phải sang trái để mở rộng dữ liệu đào tạo. Chúng tôi cũng áp dụng khả năng che đậy ngôn ngữ, tái tạo dữ liệu và phương pháp thử nghiệm dựa trên độ mơ hồ để chọn các dữ liệu liên quan đến chất lượng và chất lượng cao từ vật thể song song và ngôn. Mong chờ độ cẩn thận trong miền, chúng tôi cũng đề xuất một phương pháp đặc chế'một miền mô hình'dành cho các đặc trưng của các thể loại tin khác nhau ở giai đoạn tinh chỉnh và giải mã. Bên cạnh đó, chúng tôi sử dụng thuật to án kết hợp có tính tham nhũng để tăng cường hệ thống. Dựa trên thành công trong lần thử thách cuối cùng, chúng tôi tiếp tục sử dụng kỹ thuật tiên tiến như huấn luyện hàng loạt lớn, chọn dữ liệu và lọc dữ liệu. Cuối cùng, hệ thống Anh-Trung Quốc hạn chế của chúng ta đạt được 33.4 tỉ lệ nhạy cảm của TIẾNG LEU, đó là thứ cao nhất trong tất cả các luận. Hệ thống Anh-Đức được xếp hạng hai ở vị trí tương thích.", 'hr': 'Ovaj papir opisuje sisteme prevoda za zajednički zadatak WMT21. Mi sudjelujemo u zadatku za prevod vijesti o tri jezička parova: kineski-engleski, engleski-kineski i njemački-engleski. Naši sustavi su izgrađeni na raznim modelima Transformera sa novim tehnikama prilagođenim iz posljednjeg istraživanja. Prvo, kombiniramo različite metode povećanja podataka uključujući natrag prevod, naprijed prevod i desno na lijevo obuku kako bi proširili podatke o obuci. Također primjenjujemo pristrasnost prikrivanja jezika, ponovno otkrivanje podataka i pristupe uzoraka podataka na temelju nejasnosti kako bi odabrali podatke o sadržaji relevantne i visoke kvalitete iz velike paralelne i monojezičke korpore. Očekujemo fino-tuniranje u domenu, također predlažemo pristup "jedan model jedan domen" modelu karakteristika različitih novinskih genra na fino-tuniranju i dekodiranju faza. Osim toga, koristimo algoritmus na zelenoj osnovi ensemble i metodu transduktivne ensemble kako bismo dalje povećali naše sustave. Na temelju našeg uspjeha u zadnjem WMT-u, stalno smo zaposlili napredne tehnike kao što su velika obuka grupe, izbor podataka i filtriranje podataka. Konačno, naš ograničeni kineski-engleski sustav postiže 33,4 slučajno osjetljiv BLEU rezultat, koji je najviši među svim podacima. Njemački-engleski sustav je u redu na drugom mjestu.', 'bg': 'Тази статия описва системите за превод на Tencent за споделената задача WMT21. Участваме в задачата за превод на новини на три езикови двойки: китайски-английски, английски-китайски и немски-английски. Нашите системи са изградени върху различни трансформаторни модели с нови техники, адаптирани от последните ни изследвания. Първо, комбинираме различни методи за увеличаване на данните, включително назад превод, напред превод и обучение от дясно на ляво, за да увеличим данните за обучение. Също така прилагаме пристрастия към езиковото покритие, подмладяване на данните и базирани на неопределеността извадкови подходи, за да подберем подходящи за съдържанието и висококачествени данни от големи паралелни и едноезични корпуси. Очакваме фина настройка в домейна, ние също така предлагаме фин подход "един модел едно домейн" към характеристиките на модела на различни жанрове новини на етапите фина настройка и декодиране. Освен това, ние използваме алгоритъм ансамбъл базиран на алчност и трансдуктивен ансамбъл метод, за да подобрим допълнително нашите системи. Въз основа на нашия успех в последната МУТ, ние непрекъснато прилагаме усъвършенствани техники като обучение на големи партиди, избор на данни и филтриране на данни. И накрая, нашата ограничена китайско-английска система постига 33,4 точки, чувствителни към букви, което е най-високата сред всички подадени предложения. Немско-английската система е класирана на второ място съответно.', 'nl': "Dit artikel beschrijft Tencent Translation systemen voor de gedeelde WMT21 taak. We nemen deel aan de vertaaltaak voor nieuws op drie taalparen: Chinees-Engels, Engels-Chinees en Duits-Engels. Onze systemen zijn gebouwd op verschillende Transformer modellen met nieuwe technieken aangepast aan ons recente onderzoekswerk. Ten eerste combineren we verschillende data augmentatie methoden waaronder back-translation, forward-translation en rechts-naar-links training om de trainingsgegevens te vergroten. We passen ook taaldekkingsbias, gegevensverjonging en onzekerheidsgebaseerde sampling-benaderingen toe om content-relevante en hoogwaardige gegevens uit grote parallelle en eentalige corpora's te selecteren. Verwacht voor in-domain fine-tuning, we stellen ook een fijngranige 'one model one domain'-benadering voor voor model kenmerken van verschillende nieuwgenres tijdens fine-tuning en decodering stadia. Daarnaast gebruiken we hebzucht-based ensemble algoritme en transductieve ensemble methode om onze systemen verder te stimuleren. Op basis van ons succes in de laatste WMT hebben we continu geavanceerde technieken toegepast zoals large batch training, dataselectie en datafiltering. Tot slot behaalt ons beperkt Chinees-Engels systeem 33.4 hoofdlettergevoelige BLEU score, die de hoogste is van alle inzendingen. Het Duits-Engelse systeem staat dienovereenkomstig op de tweede plaats.", 'da': "Dette dokument beskriver Tencent Translation systemer til WMT21 delte opgave. Vi deltager i nyhedsoversættelsesopgaven på tre sprogpar: kinesisk-engelsk, engelsk-kinesisk og tysk-engelsk. Vores systemer er bygget på forskellige Transformer modeller med nye teknikker tilpasset fra vores seneste forskningsarbejde. For det første kombinerer vi forskellige dataforøgelsesmetoder, herunder back-translation, fremad-translation og højre-til-venstre træning for at udvide træningsdataene. Vi anvender også sprogdækningsbias, dataforyngelse og usikkerhedsbaserede samplingsmetoder til at udvælge indholdsrelevante og højkvalitetsdata fra store parallelle og ensprogede korpora. Forventer inden for domænet finjustering, foreslår vi også en finkornet 'én model ét domæne' tilgang til model karakteristika for forskellige nyhedsgenerer ved finjustering og afkodning stadier. Desuden bruger vi grådighedsbaseret ensemble algoritme og transduktiv ensemble metode til yderligere at booste vores systemer. Baseret på vores succes i den sidste WMT anvendte vi løbende avancerede teknikker såsom stor batch træning, datavalg og datafiltrering. Endelig opnår vores begrænsede kinesisk-engelske system 33,4 case-sensitive BLEU score, hvilket er den højeste blandt alle indsendelser. Det tysk-engelske system er placeret på andenpladsen i overensstemmelse hermed.", 'de': 'Diese Arbeit beschreibt Tencent Translation Systeme für die gemeinsame Aufgabe WMT21. Wir nehmen an der Nachrichtenübersetzung an drei Sprachpaaren teil: Chinesisch-Englisch, Englisch-Chinesisch und Deutsch-Englisch. Unsere Systeme basieren auf verschiedenen Transformatormodellen mit neuartigen Techniken, die aus unseren jüngsten Forschungsarbeiten adaptiert wurden. Zunächst kombinieren wir verschiedene Methoden der Datenaugmentation, einschließlich Back-Translation, Forward-Translation und Rechts-nach-Links-Training, um die Trainingsdaten zu erweitern. Darüber hinaus wenden wir sprachliche Verzerrungen, Datenverjüngung und unsicherheitsbasierte Sampling-Ansätze an, um inhaltsrelevante und qualitativ hochwertige Daten aus großen parallelen und monolingualen Korpora auszuwählen. Im Hinblick auf die Feinabstimmung in der Domäne schlagen wir auch einen feinkörnigen Ansatz vor, der die Modelleigenschaften verschiedener Nachrichtengenres bei der Feinabstimmung und Dekodierung berücksichtigt. Außerdem verwenden wir gierbasierten Ensemble-Algorithmus und transduktive Ensemble-Methode, um unsere Systeme weiter zu steigern. Basierend auf unserem Erfolg im letzten WMT haben wir kontinuierlich fortschrittliche Techniken wie Big Batch Training, Datenauswahl und Datenfilterung eingesetzt. Schließlich erreicht unser eingeschränktes chinesisch-englisches System 33.4 Groß- und Kleinschreibung sensitiven BLEU-Score, der unter allen Einreichungen die höchste ist. Entsprechend belegt das deutsch-englische System den zweiten Platz.', 'fa': 'این کاغذ سیستم\u200cهای ترجمه تنسنت برای کار مشترک WMT21 را توصیف می\u200cکند. ما در وظیفه ترجمه\u200cهای خبری در سه جفت زبان شرکت می\u200cکنیم: چینی-انگلیسی، انگلیسی-چینی و آلمانی-انگلیسی. سیستم\u200cهای ما بر مدل\u200cهای تغییر\u200cپذیر مختلف ساخته شده\u200cاند با تکنیک\u200cهای رمانی که از کار تحقیقات اخیر ما adapted می\u200cشوند. اول، ما روش\u200cهای افزایش داده\u200cهای مختلف را ترکیب می\u200cکنیم، شامل ترکیب پشت، ترکیب پیش\u200cفرستادن و آموزش راست و چپ برای افزایش داده\u200cهای آموزش. ما همچنین برای انتخاب داده های محتوای ارتباط و کیفیت بالا از شرکت بزرگ parallel و یک زبان استفاده می کنیم. انتظار داشته باشیم که در دامنه نیکوترین تنظیم کنیم، ما همچنین پیشنهاد می\u200cکنیم یک روش «یک مدل یک دامنه» به ویژگی\u200cهای ویژه\u200cهای متفاوت در مرحله\u200cهای تنظیم و دکوندن\u200cکننده\u200cای. علاوه بر این، ما از الگوریتم آلودگی بر اساس آلودگی استفاده می\u200cکنیم و روش آلودگی ترجمه\u200cکننده برای بیشتر افزایش سیستم\u200cهای ما استفاده می\u200cکنیم. Based on our success in the last WMT, we continued employing advanced techniques such as large batch training, data selection and data filtering. بالاخره، سیستم چینی-انگلیسی محدود ما درجه 33.4 امتیاز BLEU حساس پرونده می\u200cرسد، که بالاترین از همه تحویل\u200cها است. سیستم آلمانی و انگلیسی به همین دلیل در جای دوم صفحه دارد.', 'ko': "본고는 텐센트 WMT21 공유 임무 번역 시스템을 소개했다.우리는 세 쌍의 언어의 뉴스 번역 임무인 한영, 영중, 덕영에 참여했다.우리의 시스템은 각종 변압기 모델을 바탕으로 최근 연구 과정에서 채택한 신기술을 채택하였다.우선, 우리는 서로 다른 데이터 강화 방법을 결합시켰는데 역방향 번역, 정방향 번역과 오른쪽에서 왼쪽까지의 훈련을 포함하여 훈련 데이터를 확대했다.우리는 또한 언어 덮어쓰기 편차, 데이터 업데이트와 불확실성을 바탕으로 하는 표본 추출 방법을 활용하여 대형 평행 자료 라이브러리와 단어 자료 라이브러리에서 내용과 관련된 고품질 데이터를 선택한다.역내 마이크로스피커를 제외하고 우리는 세립도의'한 모델 한 필드'방법을 제시하여 마이크로스피커와 디코딩 단계에서 서로 다른 뉴스 장르의 특징을 모델링하는 데 사용한다.그 밖에 우리는 탐욕을 바탕으로 하는 집적 알고리즘과 전도 집적 방법을 사용하여 우리의 시스템을 더욱 강화한다.지난번 WMT의 성공을 토대로 우리는 대량의 교육, 데이터 선택과 데이터 필터 등 선진적인 기술을 계속 채택하고 있다.마지막으로 우리의 제한된 중국어-영문 시스템은 33.4점의 BLEU 대소문자 민감 점수를 받았는데 이것은 모든 제출 서류 중 가장 높았다.독일 영어 시스템은 이로 인해 2위를 차지했다.", 'sw': "Gazeti hili linaelezea mfumo wa Tafsiri 10 kwa ajili ya kazi ya WMT21 zilizoshirikishwa. Tunashiriki katika jukumu la kutafsiri habari kwa ajili ya wawili watatu wa lugha: Kichina-Kiingereza, Kiingereza-Kichina na Kijerumani-Kiingereza. Mifumo yetu imejengwa kwenye mifano mbalimbali ya Tafsiri yenye mbinu za riwaya zilizobadilishwa na kazi zetu za utafiti hivi karibuni. Kwanza, tunaunganisha mbinu za kuongeza taarifa tofauti ikiwa ni pamoja na tafsiri ya nyuma, tafsiri ya mbele na mafunzo ya kulia-hadi kushoto ili kuongeza taarifa za mafunzo. Pia tunatumia taarifa za lugha za upendeleo, upya wa taarifa na mbinu za sampuli zisizo na uhakika ili kuchagua taarifa zinazohusiana na yenye kiwango kikubwa kutoka kwa kampuni kubwa inayofanana na lugha za kimapenzi. Tarajieni kuboresha mazingira ya ndani, pia tunapendekeza mbinu nzuri ya 'mifano moja ya ndani' ili kutengeneza sifa za jeni tofauti za habari katika jukwaa la kuboresha vizuri na kupunguza. Zaidi yake, tunatumia algorithi yenye uchumi na mbinu za kutengeneza mifumo yetu. Kwa mujibu wa mafanikio yetu katika WMT ya mwisho, tuliendelea kutumia mbinu za maendeleo kama vile mafunzo makubwa ya mbuga, uchaguzi wa data na kuchuja taarifa. Mwisho, mfumo wetu wa Kiingereza ambao umelazimika unafanikiwa score ya BLEU 33.4 yenye uchunguzi wa kesi, ambayo ni bora zaidi miongoni mwa mawasiliano yote. Mfumo wa Kijerumani-Kiingereza umepangwa katika nafasi ya pili kwa namna hiyo.", 'sq': "Ky dokument përshkruan sistemet e përkthimit Tencent për detyrën e përbashkët të WMT21. Ne marrim pjesë në detyrën e përkthimit të lajmeve në tre çifte gjuhësh: kinez-anglez, anglez-kinez dhe gjerman-anglez. Our systems are built on various Transformer models with novel techniques adapted from our recent research work.  Së pari, kombinojmë metoda të ndryshme të rritjes së të dhënave duke përfshirë përkthimin mbrapa, përkthimin përpara dhe trajnimin djathtas në majtë për të zgjeruar të dhënat e trajnimit. Ne gjithashtu aplikojmë paragjykimet për mbulimin e gjuhës, ripërtëritjen e të dhënave dhe metodat e marrjes së mostrave bazuar në pasiguri për të zgjedhur të dhënat e rëndësishme për përmbajtjen dhe cilësinë e lartë nga korpra e madhe paralele dhe monogjuhësore. Pritni për rregullimin në domeni, ne gjithashtu propozojmë një metodë të hollësishme 'një model një domeni' ndaj karakteristikave të modelit të gjenerëve të ndryshme të lajmeve në fazat e rregullimit dhe dekodimit. Përveç kësaj, ne përdorim algoritmin e ansamblit me bazë lakmi dhe metodën e ansamblit transduktiv për të rritur më tej sistemet tona. Bazuar në suksesin tonë në WMT të fundit, ne përdorëm vazhdimisht teknika të avancuara të tilla si stërvitja e loteve të mëdha, zgjedhja e të dhënave dhe filtrimi i të dhënave. Më në fund, sistemi ynë i kufizuar kinez-anglez arrin 33.4 pikë BLEU të ndjeshme për raste, e cila është më e larta midis të gjitha paraqitjeve. Sistemi gjermano-anglez renditet në vendin e dytë sipas kësaj.", 'id': "Kertas ini menjelaskan sistem Terjemahan Tensen untuk tugas bersama WMT21. Kami berpartisipasi dalam tugas terjemahan berita pada tiga pasangan bahasa: bahasa Cina-Inggris, bahasa Inggris-Cina dan bahasa Jerman-Inggris. Sistem kita dibangun pada berbagai model Transformer dengan teknik baru yang diadaptasi dari hasil penelitian baru-baru ini. Pertama, kita menggabungkan metode peningkatan data yang berbeda termasuk terjemahan belakang, terjemahan depan dan latihan kanan ke kiri untuk memperbesar data latihan. We also apply language coverage bias, data rejuvenation and uncertainty-based sampling approaches to select content-relevant and high-quality data from large parallel and monolingual corpora.  Menunggu penyesuaian dalam domain, kami juga mengusulkan pendekatan 'satu model satu domain' yang baik-baik untuk karakteristik model dari genre berita yang berbeda di tahap penyesuaian dan dekodifikasi. Selain itu, kita menggunakan algoritma ensemble berdasarkan keserakahan dan metode ensemble transduktif untuk meningkatkan sistem kita lebih lanjut. Berdasarkan sukses kita di WMT terakhir, kami terus-menerus menggunakan teknik maju seperti latihan batch besar, pemilihan data dan penapisan data. Finally, our constrained Chinese-English system achieves 33.4 case-sensitive BLEU score, which is the highest among all submissions.  The German-English system is ranked at second place accordingly.", 'hy': 'Այս հոդվածը նկարագրում է ԱՄԹ21-ի ընդհանուր հանձնարարության տենցենտ թարգմանման համակարգերը: Մենք մասնակցում ենք նորությունների թարգմանման առաջադրանքին երեք լեզու զույգերի վրա՝ չինական-անգլերեն, անգլերեն-չինական և գերմանացի-անգլերեն: Մեր համակարգերը կառուցվում են տարբեր տրանֆորմային մոդելների վրա, որոնց միջոցով նոր տեխնիկաներ են հարմարեցվել մեր վերջին ուսումնասիրություններից: Առաջինը, մենք համադրում ենք տարբեր տվյալների աճի մեթոդներ, ներառյալ վերջնական թարգմանություն, առաջնական թարգմանություն և ձախ-աջ ուսումնասիրություն, որպեսզի աճեցնենք ուսումնասիրության տվյալները: We also apply language coverage bias, data rejuvenation and uncertainty-based sampling approaches to select content-relevant and high-quality data from large parallel and monolingual corpora.  Սպասենք տիեզերքում բարձրացման, մենք նաև առաջարկում ենք մի մոդել մեկ տիեզերքում բարձրացված մոտեցում տարբեր նորությունների գեների առանձնահատկությունների մոդելների վերաբերյալ բարձրացման և կոդավորման ժամանակ: Ավելին, մենք օգտագործում ենք ագահությամբ հիմնված ամբողջ ալգորիթմ և տրանսուկտիվ ամբողջ մեթոդ մեր համակարգերի շարունակելու համար: Հաշվի առնելով մեր հաջողությամբ անցյալ աշխարհային տեխնոլոգիաներում, մենք շարունակ օգտագործում էինք զարգացած տեխնոլոգիաներ, ինչպիսիք են մեծ բաժիների ուսուցման, տվյալների ընտրության և տվյա Վերջապես, մեր սահմանափակ չինական-անգլերեն համակարգը հասնում է 33.4 դեպքերի զգայուն ԲԼԵՎ գնահատականի, որը ամենաբարձր է բոլոր ներկայացումների մեջ: Գերմանական-անգլերեն համակարգը համապատասխանաբար դասակարգում է երկրորդ տեղում:', 'af': "Hierdie papier beskrywe Tencent Vertaling stelsels vir die WMT21 gedeelde taak. Name Ons deel in die nuusvertaling taak op drie taal paar: Sinees-Engels, Engels-Sinees en Duits-Engels. Ons stelsels is gebou op verskeie Transformer-modelles met nuwe teknike wat van ons onlangse ondersoek werk aanpas is. Eerste, ons kombinieer verskillende data augmentasie metodes insluitend terug-vertaling, vorentoe-vertaling en regs-na-links onderwerp om die onderwerp data te vergroot. Ons het ook taal omdekking gewend, data heroorskryfing en onbevestigheid-gebaseerde samplingstoegange om inhoud-relevante en hoë-kwaliteit data te kies van groot parallele en monolinguele korpora. Verwag vir in-domein fyn-tuning, ons voorstel ook 'n fyn-koring 'een model een domein' toegang na model karakteristieke van verskillende nuusgenre op fyn-tuning en dekodering stadige. Ons gebruik ook groedgebaseerde ensembleem algoritme en transduktiewe ensembleem metode om ons stelsels verder te booster. Basies op ons sukses in die laaste WMT, het ons voortdurende gevorderde teknike, soos groot batch-oefening, data seleksie en data filtering gebruik. Eindelik, ons beperkte Sinees-Engels stelsel bereik 33.4 Kas-sensitief BLEU-punt, wat is die hoogste onder alle onderwerpe. Die Duitse-Engels stelsel is na tweede plek gelyk.", 'am': 'ይህ ገጽ ለWMT21 የተካፈለ ስራ አሥር ትርጉም ሲስተም ይናገራል፡፡ የዜና ትርጉም ሥራ በሦስት ቋንቋዎች ሁለት ላይ እናጋራለን፤ ቻይና-እንግሊዘኛ፣ እንግሊዘኛ-ቻይና እና ጀርመን-እንግሊዘኛ፡፡ Our systems are built on various Transformer models with novel techniques adapted from our recent research work.  መጀመሪያ፣ የግንኙነት ዳታ ማሰናከል እናስጠጋለን፡፡ በቋንቋ ላይ የሽፋኖችን ድጋፍ፣ የዳታ መቀናቀል እና የግንኙነት እና ከፍተኛ የውሃት ዳታዎችን ከትልቁ ባሕላዊ ኮርፖርት ለመምረጥ እናደርጋለን፡፡ በዶሜን ውስጥ ጥሩ ማድረግ ለመከላከል ተስፋ እና በጥያቄ እና ለልዩ ዜና ዜና ዜና ማሰናከል ጥያቄዎችን ለመዘርጋት እና ለጥያቄ ጥያቄ እና ለጥያቄ ማሰናከል፡፡ በተጨማሪም፣ የሀብት አሌጎሪትምን እና ተለይተን ስርዓታችንን ለመጨመር እናስቀምጣለን፡፡ በመጨረሻይቱ WMT ውስጥ ስኬተታችንን በመሠረት፣ እንደትልቅ የባክክ ትምህርት፣ ዳታ ምርጫ እና ዳታ አጣራጭ እንደሆነ የፊደል ስክተቶችን ዘወትር እየተጠቀመን ደረጃዎች አግኝተናል፡፡ በመጨረሻም የቻይና-እንግሊዘኛ ስርዓታችን 33.4 የሆኑት የቢሊዩን ደረጃ አግኝቷል፡፡ የጀርመን-እንግሊዘኛ ስርዓት በሁለተኛ ስፍራ ነው፡፡', 'tr': "Bu kagyz WMT21 bölegi üçin Tencent terjime sistemlerini tassyýar. Täzelikler terjime etmäge üç dil çift bilen chikanchasdyk: Çin çe-Iňlisçe, iňlisçe-Çinçe we Almança-Iňlisçe. Biziň sistemamyz soňky araştyrymyzdan üýtgedilen täze Transformer modellerinde guruldy. Birinjisi, biz öz terjime, öňe-terjime we saga-sola terjime etmek üçin farklı maglumat ekleme yöntemlerini birleştirip bileris. Biz hem dil ýazgyşlygyny, maglumat täzeden ýene-täzeden we kesinlikden daşary etmek üçin möhüm we ýokary kaliwatli maglumatlary uly parallel we monodil korporadan saýlamak üçin ullanýarys. domain fine-tuning üçin gözlenmek üçin, hem fin-grain bir nusga 'bir model bir domen' nusgasyny farklı haber jenerallerinin fine-tuning we dekoding sahnelerinde örneklere taýýarlamak teklif edip otyrsak. Ayrıca, suçlamalarymyzy arttırmak üçin algoritmus we terjime etmek üçin sistemlerimizi ulanýarys. WMT'iň soňky başarnyklarymyza görä, biz öňki topar okuwçysy, veri saýlamak we veri filtrelemek ýaly ösümli tekniklerimizi hemişe ýöredik. Soňunda biziň gyssaglyk Hytaý-Iňlisçe sistemamyz 33.4 kiçi-kiçi hassytly BLEU अंतर ýetip barýar, hemme suratlaryň iň ýokary iň ýokary. Alman-iňlisler sistemasy ikinji ýerde ýazylýar.", 'az': "Bu kağıt WMT21 paylaşılan işlər üçün Tencent tercümə sistemlərini tanımar. Biz xəbərlərin çeviri işin ə üç dil çift: Çin-İngilizce, İngilizce-Çin və Alman-İngilizce. Sistemlərimiz yeni araşdırma işlərimizdən uyğunlanan yeni tekniklərlə müxtəlif Transformer modellərə inşa edilmişdir. Birincisi, təhsil məlumatlarını genişləmək üçün fərqli məlumatları artırmaq metodlarını birləşdiririk. Biz həmçinin dil örtüklərindən çox paralelə və monodil korporadan olan məlumat və yüksək kaliteli məlumatları seçmək üçün məlumatları yenidən diriltmək və təqsirsizlik üzərində örtük metodlarını istifadə edirik. Domenin fin-tuning üçün gözləyin, biz də fin-tuning və dekoding sahələrində müxtəlif xəbər genlərinin modeli tərzlərinə 'bir modeli bir domenin' approach təklif edirik. Əksinə, sistemlərimizi daha artırmaq üçün istifadə edirik. Son WMT'də başarımıza baxmayaraq, böyük qrup təhsil, məlumat seçimləri və məlumat filtrləyici kimi tədbirli tekniklərdən istifadə edirik. Sonunda, çəkilən Çin-İngilizce sistemimiz 33.4 kişi-sensitiv BLEU nöqtəsinə yetirir, bu da bütün təbliğlərdən ən yüksək nöqtəsidir. Almanca-İngilizce sistemi buna görə ikinci yerdə səf edilir.", 'bn': "এই পত্রিকাটি WMT21 শেয়ার করা কাজের জন্য টেন্সেন্ট অনুবাদ সিস্টেম বর্ণনা করেছে। আমরা তিন ভাষার জোড়ায় সংবাদ অনুবাদের কাজে অংশগ্রহণ করি: চীনা-ইংরেজী, ইংরেজী-চীনা এবং জার্মান-ইংরেজী। আমাদের সিস্টেম বিভিন্ন ট্রান্সফ্রান্সফার মডেলে তৈরি করা হয়েছে যার মাধ্যমে আমাদের সাম্প্রতিক গবেষণার প্রথমত, প্রশিক্ষণের তথ্য বৃদ্ধি করার জন্য আমরা বিভিন্ন তথ্য যোগাযোগ মাধ্যমে একত্রিত করি যার মধ্যে রয়েছে পিছন-অনুবাদ, সামন আমরা ভাষার কাভারেজ বিয়া, তথ্য পুনরায় প্রতিষ্ঠান এবং নিশ্চিত ভিত্তিক নমুনার উপায় বেছে নিতে পারি বিশাল প্যারালেল এবং মানুষের কোর্পোরায় ভিন্ন সংবাদ জেনারের চরিত্র তৈরি করার জন্য আমরা একটি ভালোভাবে গ্রেফতার করি 'একটি মডেল একটি ডোমেইন' প্রস্তাব করি। এছাড়াও আমরা লোভ ভ ভিত্তিক অ্যালগরিদম ব্যবহার করি এবং ট্রান্ডডভিক্যাটিভ এনসেম্পেল পদ্ধতি আরো বৃদ্ধি করার জন্য। শেষ ডিউএমটিতে আমাদের সফলতার ভিত্তিতে আমরা বিশাল ব্যাচ প্রশিক্ষণ, তথ্য নির্বাচন এবং তথ্য ফিল্টারিং এর মতো অগ্রগতির উন্নত কৌ অবশেষে, আমাদের বাধ্যতামূলক চীনা-ইংরেজি সিস্টেম ৩৩. The German-English system is ranked at second place accordingly.", 'cs': 'Tento článek popisuje překladové systémy Tencent pro sdílenou úlohu WMT21. Účastníme se překladu zpráv na třech jazykových párech: čínsko-angličtina, anglicko-čínština a německo-angličtina. Naše systémy jsou postaveny na různých modelech transformátorů s novými technikami přizpůsobenými našimi nedávnými výzkumnými pracemi. Nejprve kombinujeme různé metody rozšíření dat, včetně zpětného překladu, překladu dopředu a školení doprava doleva, abychom rozšířili tréninková data. K výběru obsahově relevantních a vysoce kvalitních dat z velkých paralelních a jednojjazyčných korpusů aplikujeme také přístupy jazykového pokrytí, omlazení dat a vzorkování založené na nejistotě. Očekáváme jemné ladění v doméně, navrhujeme také jemný přístup "jeden model jedna doména" k modelovým charakteristikám různých zpravodajských žánrů ve fázi jemného ladění a dekódování. Kromě toho používáme algoritmus souborů založený na chamtivosti a transduktivní metodu souborů k dalšímu posílení našich systémů. Na základě našeho úspěchu v posledním WMT jsme neustále používali pokročilé techniky, jako je školení velkých dávek, výběr dat a filtrování dat. Konečně, náš omezený čínsko-anglický systém dosahuje 33.4 hodnocení BLEU, které je nejvyšší ze všech příspěvků. Německo-anglický systém je odpovídajícím způsobem umístěn na druhém místě.', 'bs': 'Ovaj papir opisuje sisteme prevoda za zajednički zadatak WMT21. Mi učestvujemo u zadatku za prevod vijesti o tri jezička parova: kineski-engleski, engleski-kineski i njemački-engleski. Naši sistemi su izgrađeni na raznim modelima Transformera sa novim tehnikama prilagođenim iz poslednjeg istraživanja. Prvo, kombiniramo različite metode povećanja podataka uključujući natrag prevod, naprijed prevod i desno na lijevo obuku kako bi proširili podatke o obuci. Također primjenjujemo pristrasnost prikrivanja jezika, ponovno otkrivanje podataka i pristupe uzoraka podataka na temelju nejasnosti kako bi odabrali podatke o sadržaju relevantne i visoke kvalitete iz velike paralelne i monojezičke korpore. Očekujemo fino-tuniranje u domenu, također predlažemo pristup "jedan model jedan domen" modelu karakteristika različitih novinskih genra na fino-tuniranju i dekodiranju faza. Osim toga, koristimo algoritmus na zelenoj osnovi ensemble i metodu transduktivne ensemble kako bi dalje povećali naše sisteme. Na osnovu našeg uspjeha u posljednjem WMT-u, stalno smo zaposlili napredne tehnike kao što su velika obuka grupe, izbor podataka i filtriranje podataka. Na kraju, naš ograničeni kineski-engleski sistem postiže 33,4 rezultat BLEU-a, koji je najviši među svim podacima. Njemački-engleski sistem je u redu na drugom mjestu.', 'fi': 'Tässä artikkelissa kuvataan Tencent Translation -järjestelmiä jaettuun WMT21-tehtävään. Osallistumme uutisten kääntämiseen kolmella kieliparilla: kiina-englanti, englanti-kiina ja saksa-englanti. Järjestelmämme perustuvat erilaisiin Transformer-malleihin, joissa hyödynnetään tuoreesta tutkimustyöstämme mukautettuja uusia tekniikoita. Ensin yhdistämme erilaisia datan lisäysmenetelmiä, kuten taaksekääntämistä, eteenpäin kääntämistä ja oikealta vasemmalle harjoittelua harjoitusdatan laajentamiseksi. Sovellamme myös kielipeitteen viuhoja, datan nuorentamista ja epävarmuuteen perustuvaa otantamenetelmää sisällön kannalta merkityksellisen ja laadukkaan tiedon valitsemiseen suurista rinnakkais- ja yksikielisistä korpusista. Odotamme verkkotunnusten hienosäätöä, ja ehdotamme myös hienojakoista "yhden mallin yksi alue" -lähestymistapaa eri uutisgenrien malliominaisuuksiin hienosäätö- ja dekoodausvaiheessa. Lisäksi käytämme ahneuteen perustuvaa ensemble algoritmia ja transductive ensemble -menetelmää järjestelmiemme tehostamiseksi entisestään. Viimeisen WMT:n menestyksen perusteella olemme jatkuvasti käyttäneet kehittyneitä tekniikoita, kuten suureräkoulutusta, tietojen valintaa ja tietojen suodatusta. Lopuksi, rajoitettu kiina-englanti järjestelmämme saavuttaa 33,4 tapauskohtaisen BLEU-pisteen, joka on korkein kaikista toimituksista. Saksalais-englantilainen järjestelmä sijoittuu vastaavasti toiseksi.', 'et': 'Käesolevas artiklis kirjeldatakse Tencenti tõlkesüsteeme WMT21 jagatud ülesande jaoks. Uudiste tõlkimisel osaleme kolmes keelepaaris: hiina-inglise, inglise-hiina ja saksa-inglise keel. Meie süsteemid on ehitatud erinevatele Transformerite mudelitele, kasutades uudseid tehnikaid, mis on kohandatud meie hiljutisest uurimistööst. Esiteks kombineerime erinevaid andmete suurendamise meetodeid, sealhulgas tagantõlke, edastõlke ja paremalt vasakule koolituse, et suurendada koolitusandmeid. Samuti rakendame keelelise katvuse kalduvuse, andmete noorendamise ja ebakindlusel põhinevate valimimismeetodite valimiseks sisuolulisi ja kvaliteetseid andmeid suurtest paralleelsetest ja ühekeelsetest korpustest. Oodates domeenisisest peenhäälestust, pakume välja ka peenhäälestuse "ühe mudeli ühe domeeni" lähenemisviisi erinevate uudiste žanrite mudelite omadustele peenhäälestuse ja dekodeerimise etapis. Lisaks kasutame ahnusel põhinevat ansambli algoritmi ja transduktiivset ansambli meetodit, et oma süsteeme veelgi tugevdada. Tuginedes oma edule viimases WMT-s, kasutasime pidevalt täiustatud tehnikaid, nagu suurte partiide koolitus, andmete valik ja andmete filtreerimine. Lõpuks saavutab meie piiratud hiina-inglise süsteem 33,4 tõstutundliku BLEU skoori, mis on kõigi esitatud tulemuste hulgas kõrgeim. Saksa-inglise süsteem on vastavalt teisel kohal.', 'ca': 'Aquest article descriu els sistemes de traducció tendents per a la tasca compartida WMT21. Participem en la tasca de traducció de notícies en tres parells de llengües: xinès-anglès, anglès-xinès i alemany-anglès. Els nostres sistemes estan construïts en diversos models de Transformer amb noves tècniques adaptades a partir del nostre recent treball de recerca. First, we combine different data augmentation methods including back-translation, forward-translation and right-to-left training to enlarge the training data.  També apliquem el bias de cobertura de llengües, la regeneració de dades i els enfocaments de recolliment de mostres basats en incertituds per seleccionar dades relevants per al contingut i d\'alta qualitat de grans corpores paralèls i monolingües. Esperem un ajustament fins en domini, també proposem un enfocament fins "un model un domini" a característiques models de diferents gèneres de notícies a etapes fins de ajustament i decodificació. A més, utilitzem algoritmes d\'ensembles basats en la ganança i mètode d\'ensembles transductius per impulsar més els nostres sistemes. Sobre la base del nostre èxit en l\'última MTM, vam utilitzar tècniques avançades com l\'entrenament en grans lots, la selecció de dades i la filtració de dades. Finally, our constrained Chinese-English system achieves 33.4 case-sensitive BLEU score, which is the highest among all submissions.  El sistema alemán-anglès es classifica en segon lloc en conseqüència.', 'jv': 'Perintah iki rambarang Sistem Terjamahan Tenent kanggo nggawe gerasi yang kompara WWT 1. Awak dhéwé mengko nglanggar aturan kanggo tarjamahan kanggo telu luwih: Cainan-Inggris, Inggris-Kibasa lan basa-Inggris. Sistem-sistem sing dibutuhi kanggo sampeyan model Transformer sampeyan ngono teknik sing apik dadi neng sampeyan karo istrawih dumadhi. Awak dhéwé, kita nguptan pengguna-pengguna sing wis dipun dadi, ngono mulai-terjamah lan mulai-terjamah lan kayah-lanjur kanggo ngilangno data yang cukup. Awak dhéwé éntuk nglebokake perusahaan anyar luwih, ngregani dipungot data lan nganggo-ngregani soko nggambar kuwi mau Awact for in-domain Fine-tuning, we again proposal a Fin-cered \'one model one domain\' method to model parameters of new tidgenrs at Fintuning and decoding phases. The first argument is "refreshing for in-domain Fine-tuning and decoding Yo wis rampung, kita wis nglanggar-sistem sistem anyar luwih basa gambar ngono nggawe sistem sing gawe barang nggawe. Tulung isi mbatalé ning barêng-barêng sing luwih nêmên, kéné ngulinakake tékno sing perusahaan, sing uwis seneng pisan banter, dadi sing dipileksi karo data donêng Soalé, sistem sing paling-uwong sing gagasar tentang Chinese-Inggris kuwi nggawe gerakan tanggal ; Sistem Alaman lan Inggris sing ditambah secondi kanggo segondi.', 'sk': 'V tem članku so opisani Tencentovi prevajalski sistemi za opravilo WMT21 v skupni rabi. Pri prevajanju novic sodelujemo na treh jezikovnih parih: kitajsko-angleščina, angleščina-kitajščina in nemščina-angleščina. Naši sistemi so zgrajeni na različnih modelih transformatorjev z novimi tehnikami, prilagojenimi našim nedavnim raziskovalnim delom. Najprej združujemo različne metode povečanja podatkov, vključno z nazaj prevajanjem, naprej prevajanjem in usposabljanjem od desne proti levi, da povečamo podatke o usposabljanju. Pri izbiri vsebinsko pomembnih in kakovostnih podatkov iz velikih vzporednih in enojezičnih korpusov uporabljamo tudi pristope jezikovne pokritosti, pomlajevanja podatkov in vzorčenja na podlagi negotovosti. Pričakujemo natančno nastavitev v domenu, predlagamo pa tudi natančen pristop "ena model ena domena" k značilnostim modelov različnih zvrsti novic v fazah natančnega nastavitve in dekodiranja. Poleg tega uporabljamo algoritem ansambla na podlagi pohlepa in metodo transduktivnega ansambla za nadaljnjo krepitev naših sistemov. Na podlagi uspeha v zadnjem WMT smo nenehno uporabljali napredne tehnike, kot so usposabljanje velikih serij, izbira podatkov in filtriranje podatkov. Nazadnje, naš omejen kitajsko-angleški sistem dosega 33,4 točke občutljivega BLEU rezultata, kar je najvišja med vsemi prispevki. Nemško-angleški sistem je ustrezno uvrščen na drugo mesto.', 'he': 'העיתון הזה מתאר מערכות התרגום הנכונות עבור המשימה המשותפת WMT21. אנחנו משתתפים במשימת התרגום החדשות בשלושה זוגות שפות: סיני-אנגלית, אנגלית-סינית וגרמנית-אנגלית. המערכות שלנו נבנות על דוגמנים שונים של טרנספורר עם טכניקות חדשות מתאימות מעבודת המחקר האחרונה שלנו. ראשית, אנחנו משלבים שיטות מגדלות נתונים שונות כוללות תרגום מאחור, תרגום קדימה ואימון ימין לשמאל כדי לגדל את נתוני האימון. אנו גם משתמשים בהתמחות כיסוי שפת, מחדש מידע ובגישות דגימות מבוססות על אי-בטוחות מצפים לתיקון מיוחד בתחום, אנחנו גם מציעים גישה מיוחדת של "דוגמנית אחת בתחום אחד" למופעים של גנרס חדשות שונים בשלבים של התיקון מיוחד וקישום. Besides, we use greed-based ensemble algorithm and transductive ensemble method to further boost our systems.  Based on our success in the last WMT, we continuously employed advanced techniques such as large batch training, data selection and data filtering.  סוף סוף, המערכת הסינית-אנגלית המוגבלת שלנו משיגה 33.4 נקודות BLEU רגישות למקרים, שהיא הגבוהה ביותר בין כל ההכנעות. המערכת הגרמנית-אנגלית מוצבת במקום השני בהתאם.', 'ha': "This paper describes Tencent Translation systems for the WMT21 shared task.  @ item Spelling dictionary An samar da system-yiwunmu a kan misãlai masu Transformer-na'urar da masu ko-zanen kodi da aka sami daga aikinmu na farko. Babban da, muna haɗa shiryoyin augutarwa na data daban-daban, kamar ƙarai-translation, forward-translation, kuma tsarin dama-hagu zuwa hagu don mu ƙara wa tsarin data. Tuna amfani da wasu misãlai masu tsari da harshen, yin juyin da data da ba'a sani ba dõmin za'a zãɓi data masu da inganci da kuma masu nau'i da girma daga makampuni mai girma da takarda da monoli-harshen. Don ka yi jira da tunkuɗe mai kyau cikin guda, ko kuma muna goyyade wata mai kyau wanda aka riƙe 'misãlai guda' zuwa motsi-sifati na genre-dabam a cikin juyin-tundin da ke yin kodi. Bayan haka, Munã yi amfani da algoritm da algoritin wanda aka baka wani abu na yi rõwa da shi, don ya ƙara ƙaranci na'uranmu. Basan da muke cin nasara a cikin WMT ta ƙarshe, sai muka yi aiki na technical masu ƙaranci kamar shirin batch mai girma, zaɓen data da filterin data. Ga ƙarshe, na tsarin China-Ingiriya da aka ƙunsa yana sãmu score 33.4 mai fassarar kashi na BLEU, wannan ne mafi girma daga duk kashfa. An sarar da tsarin Jarman-Ingiriya a wurin na biyu kamar hakki.", 'bo': "WMT21 མཉམ་དུ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་ཚིག་རྩིས་འཁོར་གྱི་འགྲེལ་བཤད་ཆེན་པོ་དེ་འགྲེལ་སྲིད་འདུག ང་ཚོས་བརྡ་ཞིག་གི་ལྗར་ཡིག་གཟུགས་གཅིག་ནང་གི་བྱ་འགུལ་འདོར་བ་དང་། རྒྱ་ནག་ཡིག་གཟུགས། དབུས་ཡིག་དང་། སྐད ང་ཚོའི་མ་ལག་གི་དབྱིབས་བཟོ་མ་གཟུགས་རིས་མིན་འདུག་ལས་བཟོ་བཅོས་ཐབས་ལམ་ལུགས་སྟེ། First, we combine different data augmentation methods including back-translation, forward-translation and right-to-left training to enlarge the training data. We also apply language coverage bias, data rejuvenation and uncertainty-based sampling approaches to select content-relevant and high-quality data from large parallel and monolingual corporation. Expect for in-domain fine-tuning, we also propose a fine-grained 'one model one domain' approach to model characteristics of different news genres at fine-tuning and decoding stages. Besides, we use greed-based ensemble algorithm and transductive ensemble method to further boost our systems. ང་ཚོའི་གྲུབ་འབྲས་ཆེན་མཐའ་མཇུག་གི་WMT ལ་གཞི་བརྟེན་ན། ང་ཚོས་རྒྱུན་གྱིས་མཐོ་རིམ་ལག་ལེན་འཐབ་པའི་ཐབས་ལམ་ལུགས་ཆེ་བ་ཞ མཐའ་མར་མ་དེར། ང་ཚོའི་རྩ་མེད་བཏང་བའི་རྒྱ་ནག་ཡིག་གི་མ་ལག་གི་ཚད་ལྡན་སྔོན་སྒྲིག་ཡོད། སྐད་ཡིག་དང་དབྱིན་ཡིག་གི་མ་ལག་དེ་གཉིས་པ་དང་གཅིག་མཚུངས་ཀྱི་གནས་སྟངས་གཉིས་པ་བསྡད་ཡོད།"}
{'en': 'HW-TSC’s Participation in the WMT 2021 News Translation Shared Task', 'ar': 'مشاركة HW-TSC في المهمة المشتركة لترجمة الأخبار WMT 2021', 'es': 'Participación de HW-TSC en la tarea compartida de traducción de noticias del WMT 2021', 'fr': 'Participation de HW-TSC à la tâche partagée de traduction des actualités WMT 2021', 'pt': 'Participação do HW-TSC na tarefa compartilhada de tradução de notícias do WMT 2021', 'ja': 'WMT 2021ニュース翻訳共有タスクへのHW - TSCの参加', 'zh': 'HW-TSCšłéWMT 2021śĖįťóĽŤĮĎŚÖĪšļč', 'hi': 'WMT 2021 समाचार अनुवाद साझा कार्य में HW-TSC की भागीदारी', 'ga': 'Rannpháirtíocht HW-TSC i dTasc Comhroinnte Aistriúcháin Nuachta WMT 2021', 'ru': 'Участие HW-TSC в совместной задаче по переводу новостей WMT 2021', 'ka': 'HW-TSC-ის დაწყვეტილება WMT 2021 გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმები', 'hu': 'A HW-TSC részvétele a WMT 2021 Hírek Fordítás Megosztott feladatában', 'el': 'Συμμετοχή του στην Παγκόσμια Μετάφραση των Νέα Κοινή Εργασία', 'it': 'La partecipazione di HW-TSC al WMT 2021 News Translation Shared Task', 'kk': 'HW- TSC WMT 2021 жаңалық аудару ортақтастырылған тапсырманың қатынасы', 'lt': 'HW-TSC dalyvavimas bendroje WMT 2021 m. naujienų vertimo užduotyje', 'mk': 'Учеството на ХВ-ТС во заедничката задача за превод на вести во WMT 2021', 'ms': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task", 'ml': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task", 'mn': 'HW-TSC-ын WMT 2021 News Translation Shared Task-д оролцсон', 'mt': 'Il-Parteċipazzjoni tal-HW-TSC fil-Kompitu Konġunt tat-Traduzzjoni tal-Aħbarijiet tad-WMT 2021', 'pl': 'Udział HW-TSC w WMT 2021 Aktualności Tłumaczenie Wspólne Zadanie', 'sr': 'Učestvovanje HW-TSC-a u WMT 2021 Novinskom prevodu', 'no': 'HW- TSC- deltakaren i WMT 2021 News Translation Shared Task', 'ro': 'Participarea HW-TSC la activitatea partajată de traducere a știrilor WMT 2021', 'so': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task", 'si': "HW-TSC's partition in the WMT 2021 News translation shared Job", 'sv': 'HW-TSC:s deltagande i WMT 2021 Nyhetsöversättning delad uppgift', 'ta': 'WMT 2021 செய்தி மொழிபெயர்ப்பு பகிர்ந்த பணி', 'ur': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task", 'uz': 'Name', 'vi': 'HW-TSC tham gia vào lần dịch chia s ẻ bản tin WM 2021', 'bg': 'Участието на ХУ-ТСК в Обща задача за превод на новини', 'nl': 'Deelname van HW-TSC aan de WMT 2021 Nieuws Vertaling Gedeelde taak', 'da': "HW-TSC's deltagelse i WMT 2021 Nyheder Oversættelse delt opgave", 'hr': 'Učestvovanje HW-TSC-a u razmjenom zadatku za prevod vijesti WMT 2021', 'id': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task", 'fa': 'شرکت HW-TSC در ترجمه خبری\u200cهای WMT 2021', 'de': 'Teilnahme des HW-TSC an der WMT 2021 News Übersetzung Gemeinsame Aufgabe', 'ko': 'WMT 2021 뉴스 번역 공유 임무에 HW-TSC 참여', 'sw': 'Ushiriki wa HW-TSC katika Tafsiri ya Habari WMT 2021', 'tr': 'HW-TSC WMT 2021 Haýsy Çeviri Paýlaşma Görevinden bölüşiklik', 'sq': 'Pjesëmarrja e HW-TSC në detyrën e përbashkët të përkthimit të lajmeve të WMT 2021', 'af': 'HW- TSC se Deelnadering in die WMT 2021 Nuusvertaling Gedeelde Taak', 'am': 'WMT 2021 ዜናዎች ትርጓሜ ተርጓሚዎች የተShared ስራ', 'hy': 'ՀՈւ-ՏՍԿ-ի մասնակցությունը 2021 թվականի աշխարհի նորությունների թարգմանման կիսված խնդրում', 'az': 'HW-TSC WMT 2021 Haqq Çeviri Bölünmüş Gözmü', 'bs': 'Učestvo HW-TSC-a u WMT 2021 Novinskom prevodu', 'ca': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task", 'bn': 'WMT ২০২১ সংবাদ অনুবাদ শেয়ার করা কাজে এইচউ-টিএসসির অংশগ্রহণ', 'et': 'HW-TSC osalemine WMT 2021 Uudiste tõlke jagatud ülesanne', 'cs': 'Účast HW-TSC na WMT 2021 Novinky Překlad Sdílený úkol', 'fi': 'HW-TSC:n osallistuminen WMT 2021 News Translation Shared Task', 'ha': "HW-TSC's Shared job in the WMT 2021 News Translate", 'sk': 'Sodelovanje HW-TSC v skupni nalogi WMT 2021 Prevajanje novic', 'he': 'השתתפות של HW-TSC במשימה משותפת לתרגום חדשות WMT 2021', 'jv': 'HWT-T-sc Ngubah sing dibenakake karo WWT 2020 1', 'bo': "HW-TSC's Participation in the WMT 2021 News Translation Shared Task"}
{'en': 'This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT 2021 News Translation Shared Task. We participate in 7 language pairs, including Zh / En, De / En, Ja / En, Ha / En, Is / En, Hi / Bn, and Xh / Zu in both directions under the constrained condition. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual datasets. Several commonly used strategies are used to train our models, such as ', 'ar': 'تقدم هذه الورقة تقديم مركز خدمات الترجمة من Huawei (HW-TSC) إلى المهمة المشتركة لترجمة الأخبار WMT 2021. نشارك في 7 أزواج لغوية ، بما في ذلك Zh / En و De / En و Ja / En و Ha / En و Is / En و Hi / Bn و Xh / Zu في كلا الاتجاهين في ظل الشرط المقيد. نحن نستخدم هندسة المحولات ونحصل على أفضل أداء عبر متغيرات متعددة ذات أحجام أكبر للمعلمات. نقوم بإجراء معالجة مسبقة تفصيلية وتصفية على مجموعات البيانات واسعة النطاق المتوفرة ثنائية اللغة وأحادية اللغة. يتم استخدام العديد من الاستراتيجيات الشائعة الاستخدام لتدريب نماذجنا ، مثل الترجمة العكسية ، والترجمة إلى الأمام ، والترجمة متعددة اللغات ، وتقطير المعرفة بالمجموعة ، وما إلى ذلك. حصل تقديمنا على نتائج تنافسية في التقييم النهائي.', 'fr': "Cet article présente la soumission du centre de services de traduction de Huawei (HW-TSC) à la tâche partagée de traduction des actualités WMT 2021. Nous participons à 7 paires de langues, y compris Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn et Xh/Zu dans les deux directions sous condition contrainte. Nous utilisons l'architecture Transformer et obtenons les meilleures performances grâce à de multiples variantes avec des tailles de paramètres plus importantes. Nous effectuons un prétraitement et un filtrage détaillés sur les ensembles de données bilingues et monolingues à grande échelle fournis. Plusieurs stratégies couramment utilisées sont utilisées pour former nos modèles, telles que la traduction rétrospective, la traduction avant, la traduction multilingue, la distillation des connaissances d'ensemble, etc. Notre soumission obtient des résultats compétitifs lors de l'évaluation finale.", 'pt': 'Este artigo apresenta o envio do Huawei Translate Services Center (HW-TSC) para a tarefa compartilhada de tradução de notícias do WMT 2021. Participamos de 7 pares de idiomas, incluindo Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn e Xh/Zu em ambas as direções sob condição restrita. Usamos a arquitetura Transformer e obtemos o melhor desempenho por meio de várias variantes com tamanhos de parâmetros maiores. Realizamos pré-processamento e filtragem detalhados nos conjuntos de dados bilíngues e monolíngues de grande escala fornecidos. Diversas estratégias comumente utilizadas são utilizadas para treinar nossos modelos, como Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc. Nossa submissão obtém resultados competitivos na avaliação final.', 'es': 'Este documento presenta la presentación del Centro de servicios de traducción de Huawei (HW-TSC) a la tarea compartida de traducción de noticias del WMT 2021. Participamos en 7 pares de idiomas, incluidos Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn y Xh/Zu en ambas direcciones bajo la condición restringida. Utilizamos la arquitectura Transformer y obtenemos el mejor rendimiento a través de múltiples variantes con tamaños de parámetros más grandes. Realizamos preprocesamiento y filtrado detallados en los conjuntos de datos bilingües y monolingües a gran escala proporcionados. Se utilizan varias estrategias de uso común para entrenar nuestros modelos, como la traducción inversa, la traducción directa, la traducción multilingüe, la destilación de conocimientos conjuntos, etc. Nuestra presentación obtiene resultados competitivos en la evaluación final.', 'zh': '本文引华为译服务中心(HW-TSC)共WMT 2021新闻译。 约束条件之下,与 7 种语言, Zh/En、De/En、Ja/En、Ha/En、Is/En、Hi/Bn 、 Xh/Zu。 吾用Transformer架构,大参数尺寸者变体获得最佳能。 臣等大双语单语数集行详预处理漉。 有数常用之策,以练吾形,如反向译,前向译,多言语译,集成知识提炼等。 吾曹提交,终得竞争力焉。', 'hi': 'यह पेपर डब्ल्यूएमटी 2021 समाचार अनुवाद साझा कार्य के लिए Huawei Translate Services Center (HW-TSC) को प्रस्तुत करता है। हम 7 भाषा जोड़े में भाग लेते हैं, जिसमें Zh / En, De / En, Ja / En, Ha / En, Is / En, Hi / Bn, और Xh / Zu दोनों दिशाओं में सीमित स्थिति के तहत शामिल हैं। हम ट्रांसफॉर्मर आर्किटेक्चर का उपयोग करते हैं और बड़े पैरामीटर आकार के साथ कई वेरिएंट के माध्यम से सबसे अच्छा प्रदर्शन प्राप्त करते हैं। हम प्रदान किए गए बड़े पैमाने पर द्विभाषी और मोनोलिंगुअल डेटासेट पर विस्तृत पूर्व-प्रसंस्करण और फ़िल्टरिंग करते हैं। कई आमतौर पर इस्तेमाल की जाने वाली रणनीतियों का उपयोग हमारे मॉडल को प्रशिक्षित करने के लिए किया जाता है, जैसे कि बैक ट्रांसलेशन, फॉरवर्ड ट्रांसलेशन, बहुभाषी अनुवाद, एनसेम्बल नॉलेज आसवन, आदि। हमारा सबमिशन अंतिम मूल्यांकन में प्रतिस्पर्धी परिणाम प्राप्त करता है।', 'ja': '本稿では、WMT 2021ニュース翻訳共有タスクへのHuawei Translate Services Center (HW - TSC)の提出について紹介します。制約条件下で、Zh/En、De/En、Ja/En、Ha/En、Is/En、Hi/Bn、Xh/Zuを含む7つの言語ペアに参加します。私たちはトランスフォーマーアーキテクチャを使用し、より大きなパラメータサイズを持つ複数のバリアントを介して最高のパフォーマンスを実現します。私たちは、提供された大規模なバイリンガルおよびモノリンガルデータセットに詳細な前処理およびフィルタリングを実行します。バック翻訳、フォワード翻訳、多言語翻訳、アンサンブルナレッジディスティレーションなど、いくつかの一般的に使用される戦略が当社のモデルをトレーニングするために使用されています。当社の提出物は、最終的な評価で競争的な結果を得ています。', 'ru': 'В этой статье представлена информация о работе Центра переводческих услуг Huawei (HW-TSC) над общей задачей WMT 2021 по переводу новостей. Мы участвуем в 7 языковых парах, включая Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn и Xh/Zu в обоих направлениях при ограниченном условии. Мы используем архитектуру трансформатора и получаем наилучшую производительность с помощью нескольких вариантов с большими размерами параметров. Мы выполняем детальную предварительную обработку и фильтрацию предоставленных крупномасштабных двуязычных и одноязычных наборов данных. Для обучения наших моделей используется несколько широко используемых стратегий, таких как Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation и т.д. Наше представление получает конкурентные результаты в финальной оценке.', 'ga': 'Cuirtear i láthair sa pháipéar seo aighneacht Ionad Seirbhísí Aistriúcháin Huawei (HW-TSC) chuig Tasc Comhroinnte Aistriúcháin Nuachta WMT 2021. Glacaimid páirt i 7 bpéire teanga, ina measc Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, agus Xh/Zu sa dá threo faoin gcoinníoll srianta. Bainimid úsáid as ailtireacht Trasfhoirmeoir agus bainimid an fheidhmíocht is fearr trí éagsúlachtaí iolracha le méideanna paraiméadar níos mó. Déanaimid réamhphróiseáil agus scagadh mionsonraithe ar na tacair sonraí dátheangacha agus aonteangacha ar mhórscála a chuirtear ar fáil. Baintear úsáid as go leor straitéisí a úsáidtear go coitianta chun ár múnlaí a oiliúint, mar Aistriú Siar, Aistriú Ar Aghaidh, Aistriúchán Ilteangach, Driogadh Eolais Ensemble, etc. Faigheann ár n-aighneacht torthaí iomaíocha sa mheastóireacht deiridh.', 'hu': 'Ez a tanulmány bemutatja a Huawei Translate Services Center (HW-TSC) beküldését a WMT 2021 News Translation Shared Task részére. 7 nyelvpárban veszünk részt, köztük Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn és Xh/Zu mindkét irányban, korlátozott feltételekkel. Transformer architektúrát használunk, és a legjobb teljesítményt több, nagyobb paraméterméretű változat segítségével érjük el. Részletes előfeldolgozást és szűrést végezünk a rendelkezésre álló nagyméretű kétnyelvű és egynyelvű adatkészleteken. Modelljeink képzéséhez számos gyakran használt stratégiát használunk, mint például a Visszafordítás, az Előfordítás, a Többnyelvű Fordítás, az Ensemble Knowledge Distillation stb. Jelentkezésünk versenyképes eredményeket ér el a végső értékelésben.', 'el': 'Η παρούσα εργασία παρουσιάζει την υποβολή του Κέντρου Μεταφραστικών Υπηρεσιών της στην κοινή εργασία μετάφρασης ειδήσεων του WMT 2021. Συμμετέχουμε σε επτά γλωσσικά ζεύγη, συμπεριλαμβανομένων των Ζ/Εν, Ντε/Εν, Τζα/Εν, Χα/Εν, Είναι/Εν, Hi/Bn, και Ξ/Zu και στις δύο κατευθύνσεις υπό την περιορισμένη συνθήκη. Χρησιμοποιούμε την αρχιτεκτονική μετασχηματιστών και επιτυγχάνουμε την καλύτερη απόδοση μέσω πολλαπλών παραλλαγών με μεγαλύτερα μεγέθη παραμέτρων. Πραγματοποιούμε λεπτομερή προεπεξεργασία και φιλτράρισμα στα παρεχόμενα δίγλωσσα και μονογλωσσικά σύνολα δεδομένων μεγάλης κλίμακας. Αρκετές κοινές στρατηγικές χρησιμοποιούνται για την εκπαίδευση των μοντέλων μας, όπως η Μετάφραση Πίσω, η Μετάφραση προς τα εμπρός, η Πολυγλωσσική Μετάφραση, η Απόσταγη Γνώσης του συνόλου κ.λπ. Η υποβολή μας επιτυγχάνει ανταγωνιστικά αποτελέσματα στην τελική αξιολόγηση.', 'ka': 'ამ დოკუმენტი სამუშაო სამუშაო სისტემის ცენტრის (HW- TSC) WMT 2021 გასაგულისხმების გასაგულისხმების გასაგულისხმების გასაგულისხმების გადასტანა. ჩვენ ვიყავით 7 ენის ზოგში, რომელიც Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, და Xh/Zu ორივე მხარდაჭირებაში, რომელიც დარწმუნებულია. ჩვენ გამოყენებთ ტრანფორმეტრის აქტიქტიქტურის და მივიღებთ უკეთესი პარამეტრის ზომის გამოყენება. ჩვენ გავაკეთებთ განსაზღვრებული მეორენგური და მონოლენგური მონაცემების კონფილტრების პროცესი და ფილტრირება. ბევრი საერთოდ გამოიყენებული სტრატიგიები გამოყენება ჩვენი მოდელების შემწავლობისთვის, როგორც Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc. ჩვენი შემწავლობა მიიღება კონსპექტიური შედეგები ბოლო', 'it': "Questo articolo presenta la presentazione di Huawei Translate Services Center (HW-TSC) al WMT 2021 News Translation Shared Task. Partecipiamo a 7 coppie linguistiche, tra cui Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, e Xh/Zu in entrambe le direzioni sotto la condizione vincolata. Usiamo l'architettura Transformer e otteniamo le migliori prestazioni grazie a più varianti con parametri di dimensioni maggiori. Eseguiamo pre-elaborazione e filtraggio dettagliati sui set di dati bilingui e monolingue forniti su larga scala. Diverse strategie comunemente utilizzate sono utilizzate per formare i nostri modelli, come Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, ecc. La nostra presentazione ottiene risultati competitivi nella valutazione finale.", 'kk': 'Бұл қағаз Huawei аудару қызметтерінің ортасына (HW- TSC) WMT 2021 жаңалық аудару ортақ тапсырмасына жіберіледі. Біз 7 тілінің екі жағында, Ж/Ен, Де/Ен, Ja/Ен, Ха/Ен, Is/Ен, Hi/Bn, және Xh/Zu шектелген жағдайда екі жағында қатынасыз келеді. Біз түрлендіруші архитектурасын қолданып, бірнеше параметрлердің өлшемі арқылы ең жақсы жылдамдығын аламыз. Біз келтірілген үлкен тілді және монолингі деректер қорларының егжей- тегжейін алдын- ала өңдеу және сүзгілеуді орындаймыз. Көп қолданылатын стратегиялар, мысалы Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, т.б. моделдерімізді оқыту үшін қолданылады. Біздің жіберіміз соңғы оқиғанда конкурентті нәтижелерді алады.', 'lt': 'Šiame dokumente pateikiamas Huawei vertimo paslaugomis centro (HW-TSC) pateikimas WMT 2021 žinių vertimo bendram uždaviniui. Mes dalyvaujame 7 kalbų porose, įskaitant Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn ir Xh/Zu abiem kryptimis ribotos sąlygos. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes.  Mes atliekame išsamų išankstinį apdorojimą ir filtravimą pateiktuose didelio masto dvikalbiniuose ir vienakalbiniuose duomenų rinkiniuose. Mūsų modeliams treniruoti naudojamos kelios dažnai naudojamos strategijos, pavyzdžiui, vertimas atgal, vertimas į priekį, daugiakalbis vertimas, bendros žinios distiliacija ir t. t. Mūsų pateikta informacija gauna konkurencinius rezultatus galutiniame vertinime.', 'ms': 'Kertas ini memperkenalkan penghantaran Pusat Perkhidmatan Terjemahan Huawei (HW-TSC) kepada Tugas Berkongsi Terjemahan Berita WMT 2021. Kami berpartisipasi dalam 7 pasangan bahasa, termasuk Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, dan Xh/Zu dalam kedua-dua arah dalam keadaan terhalang. Kami menggunakan arkitektur Transformer dan mendapatkan prestasi terbaik melalui variasi berbilang dengan saiz parameter yang lebih besar. Kami melakukan pemprosesan dan penapisan terperinci pada set data bilingual dan monobahasa yang diberikan pada skala besar. Beberapa strategi yang biasa digunakan untuk melatih model kita, seperti Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, dll.', 'mk': 'Овој весник го претставува пренесувањето на Центарот за транслатни услуги на Хуауеј (HW-TSC) на задачата на WMT 2021 News Translation Shared Task. Ние учествуваме во 7 јазички парови, вклучувајќи ги и З/Ен, Де/Ен, Ја/Ен, Ха/Ен, Ис/Ен, Здраво/Бн и Џ/Зу во двете насоки под ограничени услови. Ние ја користиме трансформарната архитектура и ја добиваме најдобрата резултат преку повеќе варијанти со поголеми големини на параметри. Ние спроведуваме детално преобработување и филтрирање на обезбедените големи двојјазични и монојазични податоци. Неколку често употребени стратегии се користат за обука на нашите модели, како што се Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation итн. Нашето поднесување добива конкурентни резултати во финалната оценка.', 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni taċ-Ċentru tas-Servizzi tat-Traduzzjoni Huawei (HW-TSC) lill-Kompitu Konġunt tat-Traduzzjoni tal-Aħbarijiet tad-WMT 2021. Aħna qed jipparteċipaw f’7 pari lingwistiċi, inklużi Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, u Xh/Zu fiż-żewġ direzzjonijiet taħt il-kundizzjoni ristretta. Aħna nużaw l-arkitettura Transformer u niksbu l-aħjar prestazzjoni permezz ta’ varjanti multipli b’daqsijiet akbar ta’ parametri. Għandna nagħmlu proċessar u filtrazzjoni dettaljati minn qabel fuq is-settijiet ta’ dejta bilingwi u monolingwi fuq skala kbira pprovduti. Diversi strateġiji użati b’mod komuni jintużaw biex jitħarrġu l-mudelli tagħna, bħat-Traduzzjoni ta’ wara, Traduzzjoni ’l quddiem, Traduzzjoni Multilingwi, Distillazzjoni ta’ Għarfien Ensemble, eċċ. Is-sottomissjoni tagħna tikseb riżultati kompetittivi fl-evalwazzjoni finali.', 'no': 'Denne papiret viser å senda Huawei Translate Services Center (HW-TSC) til WMT 2021 News Translation Shared Task. Vi deltar i 7 språkparar, inkludert Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, og Xh/Zu i begge retningar under begrenset tilstand. Vi brukar Transformeringsarkitektur og får det beste utviklinga via fleire variantar med større parameter-storleik. Vi utfører detaljerte førehandsaming og filtrering på dei tilgjengelege største bilinguelte og monospråk datasetta. Fleire vanleg brukte strategiar vert brukte for å trenja modelane våre, som tilbakeomsetjing, framover omsetjing, fleirspråk omsetjing, forstørring av kunnskap osv. Vårt omsetjing får konkurrentiv resultat i den siste evalueringa.', 'ml': 'ഈ പത്രത്തില്\u200d ഹുവായി ട്രാന്\u200dസ് സേവനങ്ങളുടെ സേന്ദ്രത്തിന്\u200dറെ (HW-TSC) കൊടുക്കുന്നത് WMT 2021 വിവരങ്ങളുടെ പരിഭാഷണത്തിന്\u200dറ ഞങ്ങള്\u200d 7 ഭാഷ ജോടികളില്\u200d പങ്കുചേര്\u200dക്കുന്നു, Zh/En, De/En, ja/En, Ha/En, Is/En, Hi/Bn, Xh/Zu, നിര്\u200dബന്ധപ്പെട്ട രണ്ട് നേര്\u200dവഴിയില്\u200d. നമ്മള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്കിട്ടേഷന്\u200d ഉപയോഗിക്കുന്നു. ഏറ്റവും വലിയ അളവുകളുമായി ഏറ്റവും നല്ല പ്രദര്\u200dശനം ലഭ നമ്മള്\u200d വിശദീകരിക്കുന്നത് മുന്\u200dപ് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന്\u200dറെയും ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നു. വലിയ ഭാഷക്കും മോ നമ്മുടെ മോഡലുകളെ പഠിപ്പിക്കാന്\u200d കുറച്ച് സാധാരണ ഉപയോഗിക്കുന്ന പ്രവർത്തകങ്ങള്\u200d ഉപയോഗിക്കുന്നു. പിന്നിലെ പരിഭാഷകള്\u200d, മുന്നോട്ട് പരിഭാഷ, പല ഭാഷകങ്ങളുട', 'mn': 'Энэ цаас Huawei Translate Services Center (HW-TSC) WMT 2021 News Translation Shared Task-д тайлбарладаг. Бид 7 хэл хоёр, Ж/Эн, Де/Эн, Ж/Эн, Ха/Эн, Is/En, Hi/Bn, Xh/Zu хоёр талд хоёуланг хязгаарлагдсан нөхцөлд оролцдог. Бид Трансформер архитектурыг ашиглаж, олон вариантуудын хувьд хамгийн сайн үйл ажиллагааг ашиглаж байна. Бид томоохон хоёр хэл болон ганц хэл өгөгдлийн суурь дээр нарийвчлалтай өмнө үйлдвэрлэх болон сүзүүлэх хэрэгтэй. Ихэнх олон ашиглагдсан стратеги нь Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, т.д. бидний загварын төгсгөлд өрсөлдөг үр дүнг гаргадаг.', 'pl': 'Niniejszy artykuł przedstawia zgłoszenie Centrum Usług Tłumaczeń Huawei (HW-TSC) do WMT 2021 News Translation Shared Task. Uczestniczymy w siedmiu parach językowych, w tym Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn i Xh/Zu w obu kierunkach w warunkach ograniczonych. Wykorzystujemy architekturę Transformera i uzyskujemy najlepszą wydajność poprzez wiele wariantów o większych rozmiarach parametrów. Wykonujemy szczegółowe wstępne przetwarzanie i filtrowanie na dostarczonych dużych zbiorach danych dwujęzycznych i jednojęzycznych. Do szkolenia naszych modeli stosuje się kilka powszechnie stosowanych strategii, takich jak tłumaczenie wsteczne, tłumaczenie przyszłe, tłumaczenie wielojęzyczne, destylacja wiedzy zespołowej itp. Nasza zgłoszenie uzyskuje konkurencyjne wyniki w ocenie końcowej.', 'ro': 'Această lucrare prezintă depunerea Centrului de servicii de traducere Huawei (HW-TSC) la sarcina partajată de traducere a știrilor WMT 2021. Participăm la 7 perechi de limbi, inclusiv Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn și Xh/Zu în ambele direcții în condiția constrânsă. Utilizăm arhitectura Transformer și obținem cele mai bune performanțe prin mai multe variante cu dimensiuni mai mari ale parametrilor. Efectuăm prelucrarea și filtrarea detaliată a seturilor de date bilingve și monolingve furnizate la scară largă. Mai multe strategii utilizate în mod obișnuit sunt utilizate pentru a instrui modelele noastre, cum ar fi traducerea spate, traducerea înainte, traducerea multilingvă, distilarea cunoștințelor ansamblului, etc. Depunerea noastră obține rezultate competitive în evaluarea finală.', 'so': 'Kanu warqaddan wuxuu u dhiibaa xarunta turjumaadda ee Huawei (HW-TSC) oo u qoran shaqo la sharciyey tarjumaadda ee WMT 2021 News. Waxaynu ka qeybqaadanaynaa 7 noocyo af ah, including Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, iyo Xh/Zu labada kooxood oo ku qoran xaalada qasabka ah. Waxaynu isticmaalnaa taariikhda turjumaanka, waxaynu heli doonnaa si aad u fiican wax looga sameeyo kala duwan oo ay leeyihiin tirada kala duduwan. Waxaannu sameynaa baaraandegista hore iyo baaritaanka lagu qoray labada luuqadood oo kala duduwan iyo labada luuqadood oo kala duduwan. Shaqooyin badan oo caadiga ah waxaa loo isticmaalaa in loo tababariyo tusaale ahaan turjumista dib, tarjumidda hore, tarjumidda luuqadaha badan, sharafta aqoonta la kordhiyo, tusaale ahaan loo soo diro waxay heli karaan arimaha tartanka ee ugu dambeeya qiimeynta.', 'sr': 'Ovaj papir predstavlja predavanje Huawei Translate Services Centra (HW-TSC) na WMT 2021 News Translation Shared Task. Učestvujemo u 7 jezičkih parova, uključujući Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn i Xh/Zu u oba smjera pod ograničenim stanjem. Koristimo arhitekturu transformera i dobijamo najbolje izvršenje putem višestrukih varianta sa većim veličinama parametara. Izvodimo detaljne predobrađivanje i filtriranje na pruženim velikim dvojezičkim i monojezičkim podacima. Nekoliko često korišćenih strategija se koristi za obuku našeg modela, kao što su Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, itd. Naša predstava dobija konkurentne rezultate u konačnoj procjeni.', 'si': 'මේ පැත්තේ හුවේයි වාර්ථාව පරිවර්තන සේවාව මධ්\u200dයස්ථානය (HW- TSC) ගැන පෙන්වන්න පුළුවන් වෙනවා WMT 2021 වාර්තාව අ අපි භාෂා ජෝඩි 7ක් සම්බන්ධ කරනවා, ජ්/එන්, ඩී/එන්, ජා/එන්, හා/එන්, හායි/බ්න්, සහ Xh/සූ දෙන්නම් ප්\u200dරතිකාරයක් තියෙනවා. Name අපි ප්\u200dරශ්නයක් කලින් ප්\u200dරක්\u200dරියාස කරනවා සහ ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා ලොකු ප්\u200dරමාණයේ දුවන් භාෂාවක සාමාන්\u200dයයෙන් භාවිත විද්\u200dයාපාර කරලා තියෙන්නේ අපේ මොඩේල්ස් ක්\u200dරියාන්ත කරන්න, හරියට Backtranslation, forward translation, Multilanguage translation, Ensemble KnowKnowKnowKnowKnowKnow Disturbation, etc. අපේ පිළිගන්නේ අවසාන වි', 'sv': 'Denna uppsats presenterar inlämningen av Huawei Translate Services Center (HW-TSC) till WMT 2021 News Translation Shared Task. Vi deltar i 7 språkpar, inklusive Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn och Xh/Zu i båda riktningarna under det begränsade villkoret. Vi använder Transformer arkitektur och får bästa prestanda via flera varianter med större parameterstorlekar. Vi utför detaljerad förbehandling och filtrering på de storskaliga tvåspråkiga och enspråkiga datauppsättningarna. Flera vanliga strategier används för att utbilda våra modeller, såsom Back Translation, Forward Translation, Flerspråkig översättning, Ensemble Knowledge Distillation, etc. Vår inlämning får konkurrenskraftiga resultat i slututvärderingen.', 'ta': 'இந்த தாள் Huawei மொழிபெயர்ப்பு சேவைகள் மையம் (HW- TSC) WMT 2021 செய்தி மொழிபெயர்ப்பு பகிர்ந்த பணிக்கு அனுப்புகிறது. நாம் 7 மொழி ஜோடி ஜோடிகளில் பங்கிடுகிறோம், Zh/En, De/En, ja/En, Ha/En, Is/En, Hi/Bn, and Xh/Zu, கட்டுப்படுத்தப்பட்ட இரு திசைகளில் உள்ளன. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes.  நாம் முன் செயல்படுத்தல் மற்றும் வடிகட்டி பெரிய அளவு இரு மொழி மற்றும் மொன்மொழி தரவு அமைப்புகளில் விவரமான முன்செயல பின் மொழிபெயர்ப்பு, மொழிபெயர்ப்பு, பல மொழிமாற்றி மொழிபெயர்ப்பு, பொதுவான அறிவிப்பு விதிமுறை மாதிரிகளை பயிற்சி செய்வதற்கு பொதுவாக பயன்படுத்தப்பட்ட பல தி', 'ur': 'This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT 2021 News Translation Shared Task. ہم سات زبان جوڑوں میں شریک ہوتے ہیں، جی/ان، دی/ان، جی/ان، ح/ان، یس/ان، ہی/ب، اور Xh/Zu دونوں سمتوں میں محدودہ حالت کے اندر. ہم ترنسفور معماری استعمال کرتے ہیں اور بہت بڑے پارامیٹ اندازے کے مطابق بہترین فعالیت حاصل کرتے ہیں. ہم پیش پردازش اور فلٹرینگ کے مطابق مشخص کر رہے ہیں جو بڑی صحیح دو زبان اور ایک زبان ڈاٹ سٹ پر ہے. بہت سی استراتژی استعمال کیے جاتے ہیں کہ ہمارے مدل کی تعلیم کریں، جیسے Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc. ہماری اطلاعات آخری تحقیق کے نتیجے پائیں گے.', 'uz': "Bu qogʻoz Huawei tarjima xizmatlari markaziga (HW-TSC) tarjima qiladigan vazifani WMT 2021 yangilari tarjima qilingan vazifani koʻrsatiladi. Биз 7 тил жуфтларини, Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn ва Xh/Zu, qanday holatda ikkita xil tarkibiga murojaat qilamiz. Biz Transfer architektordan foydalanamiz va bir necha varianter bilan katta parametr sizlari orqali eng yaxshi bajarish natijasini olib tashlamiz. Biz juda katta ko'p tillar va monolingan maʼlumotlar tarkibini bajaramiz. Koʻp nechta ishlatilgan strategiyadan foydalanadi, masalan Back tarjima, Forward tarjima, Multilingua tarjima qilish, ko'plab ilmiy tarjima tarjima qilish uchun foydalaniladi. Bizning joʻnatishimiz oxirgi qiymatga rivojlantirish natijalariga rivojlanadi.", 'vi': 'Tờ giấy này giới thiệu trung tâm Dịch vụ Hoa quả dịch (HW-TSC) cho Nhiệm vụ chia sẻ WM 2021. Chúng tôi tham gia các cặp ngôn ngữ 7, bao gồm Zhang/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, và XM/Zu ở cả hai hướng dưới điều kiện bị cưỡng bức. Chúng tôi sử dụng kiến trúc transformer và đạt được hiệu suất tốt nhất qua nhiều biến thể với kích thước Tham số lớn hơn. Chúng tôi xử lý và lọc chi tiết trên các nhà dữ liệu hai ngôn ngữ và chung ngôn ngữ được cung cấp. Các chiến lược thường được dùng để huấn luyện các mô hình của chúng ta, như Back Translation, Forward Translation, đa ngôn ngữ dịch, Ensemble knowledge Desellation, v. Sự cung cấp của chúng ta có kết quả cạnh tranh trong bài đánh giá cuối cùng.', 'bg': 'Настоящата статия представя представянето на Центъра за преводачески услуги на Уайвай (ХУ-ТСК) на споделената задача за превод на новини. Участваме в 7 езикови двойки, включително Дж/Ен, Де/Ен, Джа/Ен, Ха/Ен, Is/Ен, Ха/Бн и Xh/Зу в двете посоки при ограничени условия. Използваме архитектура на трансформатора и получаваме най-доброто представяне чрез множество варианти с по-големи размери на параметрите. Извършваме подробна предварителна обработка и филтриране на предоставените широкомащабни двуезични и едноезични набори от данни. Няколко често използвани стратегии се използват за обучение на нашите модели, като например назад превод, напред превод, многоезичен превод, ансамбъл дестилация на знанието и др.', 'hr': 'Ovaj papir predstavlja predavanje Huawei Translate Services Center (HW-TSC) podjeljenom zadatku WMT 2021 Novinskog prevoda. Mi učestvujemo u 7 jezičkih parova, uključujući Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn i Xh/Zu u oba smjera pod ograničenim stanjem. Koristimo arhitekturu Transformera i dobijemo najbolju učinku putem višestrukih varianta s većim veličinama parametara. Izvodimo detaljne predobrađivanje i filtriranje na pruženim velikim dvojezičkim i monojezičkim podacima. Nekoliko često korišćenih strategija se koristi za obuku našeg modela, kao što su Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, itd. Naša predstava dobija konkurentne rezultate u konačnoj procjeni.', 'nl': 'Dit document presenteert de indiening van Huawei Translate Services Center (HW-TSC) aan de WMT 2021 Nieuws Translation Shared Task. We nemen deel aan zeven taalparen, waaronder Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn en Xh/Zu in beide richtingen onder de beperkte voorwaarde. We gebruiken Transformer architectuur en verkrijgen de beste prestaties via meerdere varianten met grotere parametergroottes. We voeren gedetailleerde voorbewerking en filtering uit op de verstrekte grootschalige tweetalige en eentalige datasets. Verschillende veelgebruikte strategieën worden gebruikt om onze modellen te trainen, zoals Back Translation, Forward Translation, Meertalige Translation, Ensemble Knowledge Distillation, enz. Onze inzending behaalt concurrerende resultaten in de eindevaluatie.', 'da': 'Dette papir præsenterer indsendelsen af Huawei Translate Services Center (HW-TSC) til WMT 2021 News Translation Shared Task. Vi deltager i 7 sprogpar, herunder Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn og Xh/Zu i begge retninger under den begrænsede betingelse. Vi bruger Transformer arkitektur og opnår den bedste ydeevne via flere varianter med større parameterstørrelser. Vi udfører detaljeret forbehandling og filtrering på de leverede storstilede tosprogede og ensprogede datasæt. Flere almindeligt anvendte strategier bruges til at træne vores modeller, såsom Back Translation, Forward Translation, Flersproget Oversættelse, Ensemble Knowledge Distillation osv. Vores indsendelse opnår konkurrencedygtige resultater i den endelige evaluering.', 'id': 'Kertas ini menunjukkan pengiriman Huawei Translate Services Center (HW-TSC) ke WMT 2021 News Translation Shared Task. Kami berpartisipasi dalam 7 pasangan bahasa, termasuk Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, dan Xh/Zu dalam kedua arah dalam kondisi yang terbatas. Kami menggunakan arsitektur Transformer dan mendapatkan prestasi terbaik melalui variasi berbilang dengan ukuran parameter yang lebih besar. Kami melakukan preproses rincian dan penapisan pada set data yang diberikan skala besar bilingual dan monobahasa. Beberapa strategi yang biasa digunakan untuk melatih model kita, seperti Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, dll. penyerahan kita mendapatkan hasil kompetitif dalam evaluasi akhir.', 'de': 'Dieses Papier stellt die Einreichung des Huawei Translate Services Centers (HW-TSC) an die WMT 2021 News Translation Shared Task vor. Wir nehmen an 7-Sprachpaaren teil, einschließlich Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn und Xh/Zu in beiden Richtungen unter der eingeschränkten Bedingung. Wir verwenden Transformer-Architektur und erzielen die beste Leistung über mehrere Varianten mit größeren Parametergrößen. Wir führen eine detaillierte Vorverarbeitung und Filterung der bereitgestellten zweisprachigen und einsprachigen Datensätze durch. Mehrere häufig verwendete Strategien werden verwendet, um unsere Modelle zu trainieren, wie Rückübersetzung, Vorwärtsübersetzung, mehrsprachige Übersetzung, Ensemble Knowledge Distillation usw. Unsere Einreichung erzielt wettbewerbsfähige Ergebnisse in der abschließenden Bewertung.', 'fa': 'این کاغذ تحویل مرکز خدمات ترجمه Huawei (HW-TSC) را برای ترجمه\u200cهای خبری\u200cهای WMT 2021 نشان می\u200cدهد. ما در 7 جفت زبان شرکت می کنیم، شامل Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, and Xh/Zu در هر دو مسیر زیر شرایط محدودیت. ما از معماری تبدیل کننده استفاده می\u200cکنیم و بهترین عملکرد را با اندازه\u200cهای پارامتر بزرگ می\u200cگیریم. ما در مجموعه\u200cهای داده\u200cهای دو زبان و یک زبان بزرگ پیش\u200cپردازی و فیلتر کردن جزئیات را انجام می\u200cدهیم. تعدادی استراتژی که معمولاً استفاده می\u200cشود برای آموزش مدل\u200cهایمان استفاده می\u200cشود، مانند ترجمه\u200cهای عقب، ترجمه\u200cهای پیش\u200cفرستادن، ترجمه\u200cهای زیادی زبان\u200cها، تقسیم دانش\u200cهای فراوانی و غیر از آن. تحویل ما نتیجه\u200cهای مسابقه در ارزیابی نه', 'ko': '본고는 화웨이 번역서비스센터(HW-TSC)가 WMT 2021 뉴스 번역 공유 임무에 제출한 상황을 소개한다.제약조건 하에서 우리는 두 방향에서 7쌍의 언어에 참여했는데 그것이 바로 Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn과 Xh/Zu이다.우리는 더 큰 파라미터를 가진 여러 개의 변체를 통해 최상의 성능을 얻기 위해 Transformer 구조를 사용합니다.우리는 제공된 대규모 이중 언어와 단어 데이터 집합에 대해 상세한 사전 처리와 필터를 진행한다.우리는 회역, 전역, 다국어 번역, 통합 지식 추출 등 몇 가지 자주 사용하는 전략을 사용하여 우리의 모델을 훈련시켰다. 우리의 제출은 최종 평가에서 경쟁력 있는 결과를 얻었다.', 'sw': 'Makala hii inaonyesha ujumbe wa Kituo cha Tafsiri cha Huawei (HW-TSC) kwa Tafsiri ya Habari za WMT 2021. Tunashiriki wanaume wa lugha 7, ikiwa ni pamoja na Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, na Xh/Zu katika maelekezo yote chini ya hali ya kulazimika. Tunatumia ujenzi wa Transformer na kupata ufanisi bora kwa kupitia mabadiliko mengi yenye ukubwa wa kipimo kikubwa. Tunafanya taarifa zilizotolewa kwa lugha mbili na lugha za kiumbe. Mipango mingi iliyotumika kawaida inatumika kufundisha mifano yetu, kama vile Tafsiri ya Back, Tafsiri kwa ajili ya Utafiri wa lugha, Uchambuzi wa Maarifa, etc. Ujumbe wetu unapata mashindano ya kushindana na matokeo ya mwisho ya uchunguzi.', 'tr': 'Bu kagyz Huawei Terjime Servis Merkezi (HW-TSC) WMT 2021 Haýsy Terjime Paýlaşylyş Görevine gönderdi. Biz 7 dil çift bolup, Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn we Xh/Zu durumlaryň iki tarapynda goşulýarys. Biz Transformer arhitektegi ullanýarys we köp wariantçylar bilen iň gowy ukyplary al. Biz uly ölçekli iki dilli we monodilli veri setirlerinde detaylar öňe işleýän we süýşirdik. Birnäçe köplenç ulanylýan strategiýalary nusgalarymyzy öwretmek üçin, Şekil terjime, Iňe terjime, Birnäçe Diller terjime, Eňleşen Bilim Namaýyşymyz, we şeýle däldir. Biziň teslimanymyz soňky çykyş bolmagynyň netijesi gazanýar.', 'sq': 'Ky dokument paraqet paraqitjen e Qendrës së Shërbimeve Translate Huawei (HW-TSC) në detyrën e përbashkët të përkthimit të lajmeve WMT 2021. We participate in 7 language pairs, including Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn, and Xh/Zu in both directions under the constrained condition.  Ne përdorim arkitekturën Transformer dhe fitojmë performancën më të mirë nëpërmjet varianteve të shumta me madhësitë më të mëdha të parametrave. Ne kryejmë paraprocesim të hollësishëm dhe filtrim në të dhënat e dhëna në shkallë të madhe dygjuhëse dhe monogjuhëse. Disa strategji të përdorura zakonisht përdoren për të trajnuar modelet tona, të tilla si Përkthimi mbrapa, Përkthimi i Përparshëm, Përkthimi shumëgjuhës, Distilimi i njohurive të Bashkuara, etj. Përdorimi ynë merr rezultate konkurruese në vlerësimin përfundimtar.', 'am': 'ይህ ገጽ Huawei ትርጉም ማዕከላዎችን (HW-TSC) ወደ WMT 2021 ዜናዎች ትርጉም ስራዎችን አቀረበ፡፡ በ7 ቋንቋ ዓይነቶች ውስጥ Zh/En፣ De/En፣ Ja/En፣ Ha/En፣ Is/En፣ Hi/Bn እና Xh/Zu በተገደለበት ሁለተኛው ክፍል እናጋራለን፡፡ የተለየፉትን የመዝገብ ግንኙነት እናስቀምጣለን በተለይ ምርጫዎች መጠን እናስፈልጋለን፡፡ የደረጃ ልዩ ቋንቋ እና በሞሎልቋል ዳታዎች ላይ የተለየውን የፊደል ክፍተት እና አጣራ እናደርጋለን፡፡ በርካታ የተጠቀሙት ጦማሪያዎች እንደ ጀርባ ትርጉም፣ ለፊት ትርጓሜ፣ ለብዙ ቋንቋዎች ትርጉም፣ እውቀት መክፈቻ፣ በተጨማሪው እውቀት እውቀት፣ የፍጻሜውን ድምፅ አግኝተዋል፡፡', 'af': 'Hierdie papier voorstel die onderskrywing van Huawei Vertaling Deenste Sentrum (HW- TSC) na die WMT 2021 Nuusvertaling Deelde Taak. Ons deel in 7 taal paar, insluitend Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn en Xh/Zu in beide rigtings onder die beperkte voorwaardes. Ons gebruik Transformer arkitektuur en verkry die beste prestasie deur veelvuldige variante met groter parameter grootte. Ons uitvoer gedetaliseerde voorprosessering en filtrering op die verskaf groot- skaal twee- tale en monolinglike datastel. Verskeie gewoonlik gebruikte strategies word gebruik om ons modele te oefen, soos Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc. Ons onderwerp verkry mededingslike resultate in die eindelike evaluering.', 'bn': 'এই পত্রিকা হুয়াই অনুবাদ সার্ভিস সেন্টার (এইচডি-টিএসসি) উইএমটি ২০২১ সংবাদ অনুবাদের কাজ শেয়ার করেছে। আমরা ৭ ভাষায় জোড়ায় অংশগ্রহণ করি, যার মধ্যে আছে জি/এন, ডি/এন, জি/এন, হা/এন, আই/এন, হাই/বিন এবং এক্স/জু নিয়ন্ত্রণের দুই দিকেই। আমরা ট্রান্সফ্রান্সফারের আর্কিটার ব্যবহার করি এবং বেশী প্যারামিটার আকারের মাধ্যমে সেরা প্রভাব পেতে পারি। আমরা বিস্তারিত পূর্ব প্রক্রিয়া এবং ফিল্টার করি বিস্তারিত দ্বিতীয় ভাষা এবং মোনোলিভাল ডাটাসেটের উপর। বেশ কয়েকজন ব্যবহার করা কৌশল আমাদের মডেল প্রশিক্ষণের জন্য ব্যবহার করা হয়েছে, যেমন ব্যাক ট্রান্সভার, ফেরার্ড ভাষায় অনুবাদ, বহুভাষায় অনুবাদ, সাধারণ জ্ঞান বিভিন্', 'hy': 'This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT 2021 News Translation Shared Task.  Մենք մասնակցում ենք 7 լեզվի զույգերի մեջ, ներառյալ Ջ-Էն, Դե-Էն, Ջա-Էն, Հա-Էն, Իս-Էն, Բարև-Բն և Ջ-Զու երկու ուղղությամբ սահմանափակ պայմաններում: Մենք օգտագործում ենք Transforme ճարտարապետությունը և ստանում ենք լավագույն արդյունքը բազմաթիվ տարբերակների միջոցով, որոնք ունեն ավելի մեծ պարամետրերի չափսեր: Մենք կատարում ենք մանրամասն նախավերամշակում և ֆիլտրում երկլեզու և միալեզու տվյալների համակարգերի վրա: Մեր ներկայացումը վերջնական գնահատման մեջ մրցակցության արդյունքներ է ստանում:', 'bs': 'Ovaj papir predstavlja predavanje Huawei Translate Services Centra (HW-TSC) podijeljenom zadatku WMT 2021 za prevod novina. Mi učestvujemo u 7 jezičkih parova, uključujući Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn i Xh/Zu u oba smjera pod ograničenim stanjem. Koristimo arhitekturu Transformera i dobijamo najbolju funkciju putem višestrukih varianta sa većim veličinama parametara. Izvodimo detaljne predobrađivanje i filtriranje na pruženim velikim dvojezičkim i monojezičkim podacima. Nekoliko često korišćenih strategija se koristi za obuku našeg modela, kao što su Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, itd. Naša predstava dobija konkurentne rezultate u konačnoj procjeni.', 'cs': 'Tento článek představuje předložení centra Huawei Translate Services Center (HW-TSC) k WMT 2021 News Translation Shared Task. Účastníme se sedmi jazykových párů, včetně Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn a Xh/Zu v obou směrech za omezených podmínek. Používáme architekturu Transformer a dosahujeme nejlepšího výkonu prostřednictvím více variant s většími parametry. Na poskytnutých rozsáhlých dvojjazyčných a jednojjazyčných datových sadách provádíme detailní předzpracování a filtrování. Pro trénink našich modelů se používá několik běžně používaných strategií, jako je zpětný překlad, překlad dopředu, vícejazyčný překlad, destilace znalostí souborů atd. Náš příspěvek získává konkurenční výsledky v závěrečném hodnocení.', 'az': 'Bu kağıt, Huawei Tercümə Servis Merkezi (HW-TSC) WMT 2021 Haqq Tercümə Bölünən Gözməyə təyin edir. Biz 7 dil çiftlərə, həmçin in Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn və Xh/Zu də müəyyən edilmiş şəkildə yer alırıq. Biz Transformer arhitektarını kullanırıq və çoxlu variablar vasitəsilə ən yaxşı performans alırıq. Biz böyük-ölçülü iki dil və monodil veri qurularında detaylı ön işləmə və filtrləmə işlədik. Bizim modellərimizi təhsil etmək üçün çox sıradan istifadə edilən stratejilərdən istifadə edilir: Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc.', 'et': 'Käesolevas artiklis esitatakse Huawei tõlketeenuste keskuse (HW-TSC) esitamine WMT 2021 uudiste tõlkimise jagatud ülesandele. Osaleme 7 keelepaaris, sealhulgas Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn ja Xh/Zu mõlemas suunas piiratud tingimusel. Kasutame Transformeri arhitektuuri ja saavutame parima jõudluse mitme suurema parameetri suurusega variandi kaudu. Teeme pakutavate suurte kaks- ja ühekeelsete andmekogumite detailset eeltöötlust ja filtreerimist. Meie mudelite koolitamiseks kasutatakse mitmeid tavaliselt kasutatavaid strateegiaid, nagu tagasitõlkimine, edasitõlkimine, mitmekeelne tõlge, ansambli teadmiste destillatsioon jne. Meie esitus saavutab lõpphindamisel konkurentsivõimelised tulemused.', 'ca': 'Aquest article presenta la presentació del Huawei Translate Services Center (HW-TSC) al WMT 2021 News Translation Shared Task. Participem en 7 parelles de llengües, com Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn i Xh/Zu en ambdues direccions sota la condició restringida. Utilitzem arquitectura Transformer i obtenim el millor rendiment a través de múltiples variants amb grans mida de paràmetres. Fem un pré-processament detallat i filtrar els conjunts de dades bilingües i monolingües proporcionats a gran escala. Several commonly used strategies are used to train our models, such as Back Translation, Forward Translation, Multilingual Translation, Ensemble Knowledge Distillation, etc. Our submission obtains competitive results in the final evaluation.', 'fi': 'Tämä artikkeli esittelee Huawei Translate Services Centerin (HW-TSC) lähettämisen WMT 2021 News Translation Shared Task -tehtävään. Osallistumme seitsemään kielipariin, mukaan lukien Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn ja Xh/Zu molempiin suuntiin rajoitetuissa olosuhteissa. Käytämme Transformer-arkkitehtuuria ja saavutamme parhaan suorituskyvyn useilla muunnelmilla, joilla on isommat parametrikoot. Suoritamme yksityiskohtaisen esikäsittelyn ja suodatuksen toimitetuille suurille kaksikielisille ja yksikielisille aineistoille. Mallien kouluttamiseen käytetään useita yleisesti käytettyjä strategioita, kuten Back Translation, Forward Translation, Monikielinen Translation, Ensemble Knowledge Distillation jne. Lähetyksellämme saadaan kilpailukykyisiä tuloksia loppuarvioinnissa.', 'ha': "Wannan takardan na bãyar da wasiyyar da aka Fassarar Services Center (HW-TSC) zuwa the WMT 2021 News Translate Shared Takar. Zh/en, de/en, Ja/en, Hah/en, Is/en, hi/Bn, da Xh/Zu cikin dukkan hanyõyin da aka lazimta. Tuna amfani da tsarin Transformer kuma Muke sami mafarin aiki da ke fi kyauta a tsakanin wasu variants da girma. Munã cika fassarar-bayan-aiki da za'a filter a kan da aka bai wa data masu tsawo biyu-bilimi da sauri. Babu masu amfani da ko'ana ana ana yi amfani da tunkuɗe misalinmu, kamar misãlan Translate, Fassarori Forward, Tarjifani masu yawa, Ana Cilmi da Bayaniya, ko kuma an sami ƙarshen ƙaddara ƙarshen ƙaddara.", 'sk': 'Ta prispevek predstavlja predložitev središča za prevajalske storitve Huawei (HW-TSC) v skupno nalogo prevajanja novic WMT 2021. Sodelujemo v 7 jezikovnih parov, vključno z Zh/En, De/En, Ja/En, Ha/En, Is/En, Hi/Bn in Xh/Zu v obeh smereh pod omejenim pogojem. Uporabljamo arhitekturo transformatorjev in dosegamo najboljšo zmogljivost preko več različic z večjimi velikostmi parametrov. Izvajamo podrobno predobdelavo in filtriranje na zagotovljenih obsežnih dvojezičnih in enojezičnih naborih podatkov. Za usposabljanje naših modelov se uporablja več pogosto uporabljenih strategij, kot so nazaj prevajanje, naprej prevajanje, večjezični prevod, Ensemble Knowledge Distillation itd. Naša predložitev pridobi konkurenčne rezultate v končni oceni.', 'he': "This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT 2021 News Translation Shared Task.  אנחנו משתתפים בשבע זוגות שפות, כולל ז'אן, דה'אן, ג'ה'אן, הא'אן, איס'אן, הי'ב'ן, וג'ז'ו בשני הכיוונים תחת מצב מוגבל. אנחנו משתמשים בארכיטקטורה Transformer ולקבל את ההופעה הטובה ביותר באמצעות שונים רבים עם גודלים פרמטרים גדולים יותר. אנו מבצעים מעבדה מראש ומסרט מפורטת על קבוצות נתונים שתיים-שפותיים ומונולשפותיים ברמה גדולה. מספר אסטרטגיות משתמשות בדרך כלל משתמשות כדי לאמן את הדוגמנים שלנו, כמו תרגום אחורי, תרגום קדימה, תרגום רבולוגי, דסטילציה של ידע סמום, וכו.", 'jv': 'Gambar iki bakal ngewehi nggawe rerambungan huawei translation services center (HWT-T sc) kanggo nggawe WT 2020 1 Awak dhéwé tambah pating 7 dilangke sing dirampakno, tambah wé nggawe section Learn Mode politenessoffpolite"), and when there is a change ("assertive', 'bo': "ཤོག་བྱང་འདིས་Huawei Translate Services Center (HW-TSC)འདིའི་ནང་དུ་WMT 2021 News Translation Shared Task'ལ་སྔོན་སྟོན་པ་ཡིན། ང་ཚོས་སྐད་ཡིག་ཆའི་ཆ་གཅིག་གི་ནང་དུ་ཡོད་པའི་སྐད་ཡིག་གཉིས་ཀྱི་ནང་དུ་མཉམ་དུ་བསྡད་དགོས། We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes. ང་ཚོས་བྱིས་ཡོད་པའི་སྔོན་སྒྲིག་ཞིབ་དང་བསུབ་ནུས་པ་གཉིས་ཀྱི་སྒྲིག་ཆ་དང་གཅིག་སྐད་ཡིག་གཟུགས་ཀྱི་ཆ་འཕྲིན་ སྤྱིར་བཏང་བའི་ཐབས་ལམ་ལ་མང་པོ་ཞིག་ལག་ལེན་འཐབ་ཡོད་པ་ལས་ང་ཚོའི་དཔེར་ན། རྒྱབ་སྤྱི་ཚོགས། ཕྱིར་ལོག་སྔོན་སྒྲིག་གཏོང་་སྐད་བསྒྱུར་བཅོས་སོང་། ཆེན་སྐ"}
{'en': 'Small Model and In-Domain Data Are All You Need', 'fr': 'Les petits modèles et les données internes au domaine sont tout ce dont vous avez besoin', 'es': 'Todo lo que necesita son datos en el dominio y modelos pequeños', 'pt': 'Modelo pequeno e dados no domínio são tudo o que você precisa', 'ar': 'النموذج الصغير والبيانات داخل المجال هي كل ما تحتاجه', 'zh': '小形域内数,君所须也', 'ja': '小さなモデルとドメイン内データが必要です', 'hi': 'छोटे मॉडल और इन-डोमेन डेटा आपको सभी की आवश्यकता है', 'ru': 'Малая модель и внутридоменные данные - все, что вам нужно', 'ga': 'Samhail Bheaga agus Sonraí In-Fearann Is iad Gach Teastaíonn uait', 'ka': 'პატარა მოდელი და დიომენში მონაცემები უნდა ყველაფერი', 'el': 'Τα μικρά μοντέλα και τα δεδομένα εντός τομέα είναι όλα όσα χρειάζεστε', 'it': 'Piccoli modelli e dati di dominio sono tutto ciò di cui hai bisogno', 'hu': 'A kis modell és a tartományon belüli adatok minden, amire szüksége van', 'kk': 'Шағын үлгі мен домендегі деректер керек болып тұрсыз', 'lt': 'Mažas modelis ir domeno duomenys yra viskas, ko jums reikia', 'ml': 'നിങ്ങള്\u200dക്കെല്ലാം ആവശ്യമുണ്ട്', 'mk': 'Потребни се само мали модели и податоци во доменот', 'ms': 'Model Kecil dan Data Dalam Domain Adakah Yang Anda perlukan', 'mt': 'Mudell Żgħar u Dejta Domenika Huma Kollha Ħtieġa', 'pl': 'Mały model i dane wewnątrz domeny to wszystko, czego potrzebujesz', 'mn': 'Жижиг загвар болон домон өгөгдлийн мэдээллийг та бүхэн хэрэгтэй', 'no': 'Lite modell og inndomenedata er alt du treng', 'ro': 'Modelele mici și datele din domeniu sunt tot ce aveți nevoie', 'so': 'Dhammaan waa inaad u baahan tahay', 'sr': 'Mali model i podaci u domenu su sve što ti treba', 'si': 'පුංචි මොඩේල් හා ඇතුළු ඩොමේන් දත්ත ඔබට ඕනේ හැම දෙයක්ම', 'sv': 'Små modeller och domändata är allt du behöver', 'ur': 'چھوٹی موڈل اور دامین داٹا سب آپ کی ضرورت ہے', 'ta': 'சிறிய மாதிரி மற்றும் களம் தரவு நீங்கள் அனைத்தும் தேவைப்படுகிறது', 'uz': 'Comment', 'vi': 'Các mẫu nhỏ và dữ liệu nội thất là tất cả các bạn cần', 'bg': 'Малките модели и вътрешните данни са всичко, от което се нуждаете', 'da': 'Lille model og in-domæne data er alt hvad du behøver', 'hr': 'Mali model i podaci domena su sve što trebate', 'ko': '소형 모델과 역내 데이터만 필요합니다', 'nl': 'Kleine modellen en in-domein data zijn alles wat u nodig hebt', 'fa': 'مدل کوچک و اطلاعات دامنی تنها چیزی که نیاز دارید', 'sw': 'Kifaa kidogo na Data Nchini', 'id': 'Model Kecil dan Data Dalam Domain Apa Yang Anda butuhkan', 'tr': 'Ehlisiňiz gerek', 'de': 'Kleine Modell- und In-Domain-Daten sind alles, was Sie brauchen', 'hy': 'Փոքր մոդելներ և բնագավառի տվյալներ', 'af': 'Klein Model en In- Domein Data Is Alle Jy nodig', 'bn': 'ছোট মডেল এবং ডোমেইনের তথ্য আপনার সবকিছু দরকার', 'sq': 'Small Model and In-Domain Data Are All You Need', 'am': 'ትንሽ ሞዴል እና ዶሜን ዳታ ሁሉንም ያስፈልጋል', 'az': 'K칲칞칲k Model v톛 Domain Veril톛ri 캻htiyac캼n캼zd캼r', 'cs': 'Malý model a data v doméně jsou vše, co potřebujete', 'fi': 'Pieni malli ja sisäinen data ovat kaikki mitä tarvitset', 'bs': 'Mali model i podaci u domenu su sve što trebate', 'ca': 'El petit model i les dades internes són tot el que necessites', 'et': 'Väikesed mudelid ja domeenisisesed andmed on kõik, mida vajate', 'jv': 'string" in "context_BAR_stringLink', 'sk': 'Majhni modeli in notranji podatki so vse, kar potrebujete', 'ha': '@ action', 'he': 'מודל קטן ומידע בתחום הם כל מה שאתה צריך', 'bo': 'ཁྱོད་ཀྱིས་དགོས་པའི་མ་དབྱིབས་ཆུང་ཆུང་དང་དྲ་བ་ནང་གི་ཆ་འཕྲིན་ཡིག་ཆ་སྐྱེལ་འདུག'}
{'en': 'I participated in the WMT shared news translation task and focus on one high resource language pair : ', 'pt': 'Participei da tarefa de tradução de notícias compartilhadas do WMT e concentrei-me em um par de idiomas de alto recurso: inglês e chinês (duas direções, chinês para inglês e inglês para chinês). Os sistemas enviados (ZengHuiMT) focam na limpeza de dados, seleção de dados, tradução reversa e conjunto de modelos. As técnicas que usei para filtragem e seleção de dados incluem filtragem por regras, modelo de linguagem e alinhamento de palavras. Usei um modelo de tradução base treinado no corpus inicial para obter as versões de destino dos conjuntos de teste WMT21, depois usei modelos de idioma para descobrir os dados monolíngues mais semelhantes à versão de destino do conjunto de teste, esses dados monolíngues foram usados para fazer a tradução reversa. No conjunto de teste, meus melhores sistemas enviados alcançaram 35,9 e 32,2 BLEU para direções de inglês para chinês e chinês para inglês, respectivamente, que são bastante altos para um modelo pequeno.', 'es': 'Participé en la tarea de traducción de noticias compartidas del WMT y me centré en un par de idiomas de alto recurso: inglés y chino (dos direcciones, chino a inglés e inglés a chino). Los sistemas presentados (ZengHuimt) se centran en la limpieza de datos, la selección de datos, la retrotraducción y el conjunto de modelos. Las técnicas que utilicé para filtrar y seleccionar datos incluyen el filtrado por reglas, el modelo de lenguaje y la alineación de palabras. Usé un modelo de traducción base entrenado en el corpus inicial para obtener las versiones de destino de los conjuntos de pruebas WMT21, luego utilicé modelos de lenguaje para encontrar los datos monolingües que son más similares a la versión de destino del conjunto de pruebas, estos datos monolingües se usaron para hacer la traducción inversa. En el conjunto de pruebas, mis sistemas mejor presentados alcanzan 35.9 y 32.2 BLEU para las direcciones de inglés a chino y chino a inglés respectivamente, que son bastante altas para un modelo pequeño.', 'fr': "J'ai participé à la tâche de traduction de nouvelles partagées par WMT et je me suis concentrée sur une paire de langues à ressources élevées\xa0: l'anglais et le chinois (deux directions, du chinois vers l'anglais et l'anglais vers le chinois). Les systèmes soumis (ZengHuimt) se concentrent sur le nettoyage des données, la sélection des données, la rétro-traduction et l'ensemble de modèles. Les techniques que j'ai utilisées pour le filtrage et la sélection des données comprennent le filtrage par règles, par modèle linguistique et par alignement de mots. J'ai utilisé un modèle de traduction de base formé sur le corpus initial pour obtenir les versions cibles des ensembles de tests WMT21, puis j'ai utilisé des modèles de langage pour trouver les données monolingues les plus similaires à la version cible du jeu de tests, ces données monolingues ont ensuite été utilisées pour effectuer une rétro-traduction. Sur l'ensemble de test, mes systèmes les mieux soumis obtiennent respectivement 35,9 et 32,2 UEV pour les directions anglais-chinois et chinois vers anglais, ce qui est assez élevé pour un petit modèle.", 'ja': 'WMT共有ニュース翻訳タスクに参加し、1つの高いリソースの言語ペアに焦点を当てました。英語と中国語（中国語から英語、英語から中国語の2方向）です。提出されたシステム（ ZengHuiMT ）は、データクリーニング、データ選択、バック翻訳、およびモデルアンサンブルに焦点を当てています。データのフィルタリングと選択に使用したテクニックには、ルールによるフィルタリング、言語モデル、および単語の整列が含まれます。最初のコーパスで訓練されたベース翻訳モデルを使用して、WMT 21テストセットのターゲットバージョンを取得し、次に言語モデルを使用して、テストセットのターゲットバージョンに最も類似しているモノリンガルデータを調べました。そのようなモノリンガルデータは、その後、バック翻訳を行うために使用されました。テストセットでは、私が提出した最高のシステムは、英語から中国語、中国語から英語の方向でそれぞれ35.9と32.2のBLEUを達成しています。これは、小さなモデルではかなり高いです。', 'ar': 'شاركت في مهمة ترجمة الأخبار المشتركة WMT وركزت على زوج واحد من اللغات عالية الموارد: الإنجليزية والصينية (اتجاهان ، من الصينية إلى الإنجليزية ومن الإنجليزية إلى الصينية). تركز الأنظمة المقدمة (ZengHuiMT) على تنظيف البيانات واختيار البيانات والترجمة الخلفية ومجموعة النماذج. تتضمن الأساليب التي استخدمتها لتصفية البيانات واختيارها التصفية حسب القواعد ونموذج اللغة ومحاذاة الكلمات. لقد استخدمت نموذج ترجمة أساسيًا تم تدريبه على المجموعة الأولية للحصول على الإصدارات المستهدفة من مجموعات اختبار WMT21 ، ثم استخدمت نماذج اللغة لاكتشاف البيانات أحادية اللغة التي تشبه إلى حد كبير الإصدار المستهدف من مجموعة الاختبار ، ثم تم استخدام هذه البيانات أحادية اللغة للقيام بالترجمة الخلفية. في مجموعة الاختبار ، تحقق أفضل أنظمتي المرسلة 35.9 و 32.2 BLEU للغة الإنجليزية إلى الصينية والصينية إلى الإنجليزية على التوالي ، وهي نسبة عالية جدًا لنموذج صغير.', 'zh': '余预WMT共享新闻翻译务,而专注一高资源语言:英语、中文(两向,中文至英语、英语至中文)。 提交之统(ZengHuiMT)专注数清,数据选择,反向转换及模集成。 余于数选及选法、言语模形、单词对齐筛之。 余于初语料库上教习本译模以得WMT21试集之本,然后我以语言模形求其最相似者单语数,然后用此单语数以回溯之。 试集上,吾交之至统各得其35.9与32.2 BLEU之英语中文与中文至英语,于小形为高。', 'hi': 'मैंने डब्ल्यूएमटी साझा समाचार अनुवाद कार्य में भाग लिया और एक उच्च संसाधन भाषा जोड़ी पर ध्यान केंद्रित किया: अंग्रेजी और चीनी (दो दिशाएं, अंग्रेजी से चीनी और अंग्रेजी से चीनी)। प्रस्तुत सिस्टम (ZengHuiMT) डेटा सफाई, डेटा चयन, वापस अनुवाद और मॉडल पहनावा पर ध्यान केंद्रित करते हैं। डेटा फ़िल्टरिंग और चयन के लिए मैंने जिन तकनीकों का उपयोग किया, उनमें नियमों, भाषा मॉडल और शब्द संरेखण द्वारा फ़िल्टरिंग शामिल है। मैंने डब्ल्यूएमटी 21 परीक्षण सेट के लक्ष्य संस्करणों को प्राप्त करने के लिए प्रारंभिक कॉर्पस पर प्रशिक्षित एक आधार अनुवाद मॉडल का उपयोग किया, फिर मैंने मोनोलिंगुअल डेटा का पता लगाने के लिए भाषा मॉडल का उपयोग किया जो परीक्षण सेट के लक्ष्य संस्करण के समान है, इस तरह के मोनोलिंगुअल डेटा का उपयोग तब अनुवाद वापस करने के लिए किया गया था। परीक्षण सेट पर, मेरी सबसे अच्छी प्रस्तुत प्रणालियां क्रमशः चीनी और चीनी से अंग्रेजी दिशाओं के लिए अंग्रेजी के लिए 35.9 और 32.2 BLEU प्राप्त करती हैं, जो एक छोटे से मॉडल के लिए काफी अधिक हैं।', 'ru': 'Я участвовал в совместной задаче WMT по переводу новостей и сосредоточился на одной высокоресурсной языковой паре: английском и китайском языках (два направления: китайский - английский и английский - китайский). Представленные системы (ZengHuiMT) фокусируют на очистке данных, выборе данных, обратном переводе и ансамбле модели. Методы, которые я использовал для фильтрации и выбора данных, включают фильтрацию по правилам, языковой модели и выравниванию слов. Я использовал базовую модель перевода, обученную на исходном корпусе, чтобы получить целевые версии тестовых наборов WMT21, затем я использовал языковые модели, чтобы узнать одноязычные данные, которые наиболее похожи на целевую версию тестового набора, такие одноязычные данные затем использовались для выполнения обратного перевода. На тестовом наборе мои лучшие представленные системы достигают 35,9 и 32,2 BLEU для направления с английского на китайский и с китайского на английский соответственно, что довольно высоко для небольшой модели.', 'ga': 'Ghlac mé páirt i dtasc comhroinnte aistriúcháin nuachta WMT agus dhírigh mé ar phéire teanga ard-acmhainne amháin: Béarla agus Sínis (dhá threoir, Sínis go Béarla agus Béarla go Sínis). Díríonn na córais a cuireadh isteach (ZengHuiMT) ar ghlanadh sonraí, roghnú sonraí, aisaistriúchán agus ensemble samhlacha. I measc na dteicnící a d’úsáid mé le haghaidh scagadh agus roghnú sonraí tá scagadh de réir rialacha, samhail teanga agus ailíniú focal. D’úsáid mé bunmhúnla aistriúcháin oilte ar an gcorpas tosaigh chun na leaganacha sprice de thacair tástála WMT21 a fháil, ansin d’úsáid mé múnlaí teanga chun na sonraí aonteangacha is cosúla leis an spriocleagan den tacar tástála a fháil amach, baineadh úsáid as sonraí aonteangacha dá leithéid ansin. aistriúchán siar a dhéanamh. Ar an tsraith tástála, baineann na córais is fearr a chuir mé isteach 35.9 agus 32.2 BLEU do threoracha Béarla go Síneach agus Sínis go Béarla faoi seach, atá ard go leor do mhúnla beag.', 'hu': 'Részt vettem a WMT megosztott hírfordítási feladatában, és egy nagy erőforrásokkal rendelkező nyelvpárra összpontosítottam: angol és kínai (két irányban, kínai-angol és angol-kínai). A benyújtott rendszerek (ZengHuiMT) az adatok tisztítására, az adatok kiválasztására, a visszafordításra és a modellezésre összpontosítanak. Az adatszűréshez és kiválasztáshoz használt technikák közé tartozik a szabályok, a nyelvmodell és a szóigazítás. A WMT21 tesztkészletek célváltozatának megszerzéséhez egy alapfordítási modellt használtam, majd nyelvi modelleket használtam arra, hogy megtaláljam azokat az egynyelvű adatokat, amelyek leginkább hasonlítanak a tesztkészlet célváltozatához, majd ezeket az egynyelvű adatokat használtam a visszafordításhoz. A tesztkészleten a legjobb benyújtott rendszereim 35,9 és 32,2 BLEU-t érnek el az angol-kínai irányban, illetve a kínai-angol irányban, ami elég magas egy kis modell esetében.', 'ka': 'მე WMT-ის გაყოფილი ინფორმაციის გაგრძელება და ერთი მაღალი რესურსის ენაზონის ზოგის ფონსკურება: ანგლისური და ჩინეთი (ორი მიერ, ჩინეთი ანგლისური და ინგლისური კ შეტყობინებული სისტემები მონაცემების ფილტრირებისთვის და მონიშნისთვის გამოყენებული ტექნექციები არსებობს ფილტრირებისთვის წესების, ენის მოდელის და სიტყვების დამატე მე WMT21 ტესტის მისაწყვეტი ვერსიების შემდეგ გამოყენე ენის მოდელები, რომლებიც ტესტის მისაწყვეტი ვერსიებისთვის უფრო მსგავსი ვერსიის მონაცემების მონაცემების მონაცემებისთვის, რომელიც მონოლენგური მონაცემე ტესტის შესახებ, ჩემი ყველაზე საუკეთესო გამოყენებული სისტემები 35,9 და 32,2 BLEU-ს ანგლისურად ჩინგლისურად და ჩინგლისურად, ანგლისურად, რომელიც ძალიან დიდი მოდელზე', 'el': 'Συμμετείχα στο κοινό έργο μετάφρασης ειδήσεων και επικεντρώθηκα σε ένα υψηλό γλωσσικό ζεύγος πόρων: Αγγλικά και Κινέζικα (δύο κατευθύνσεις, Κινέζικα στα Αγγλικά και Αγγλικά στα Κινέζικα). Τα υποβαλλόμενα συστήματα (εστιάζουν στον καθαρισμό δεδομένων, την επιλογή δεδομένων, την πίσω μετάφραση και το σύνολο μοντέλων. Οι τεχνικές που χρησιμοποίησα για το φιλτράρισμα και την επιλογή δεδομένων περιλαμβάνουν φιλτράρισμα με βάση κανόνες, μοντέλο γλώσσας και ευθυγράμμιση λέξεων. Χρησιμοποίησα ένα βασικό μοντέλο μετάφρασης εκπαιδευμένο στο αρχικό σώμα για να αποκτήσω τις εκδόσεις-στόχους των σετ δοκιμών στη συνέχεια χρησιμοποίησα γλωσσικά μοντέλα για να ανακαλύψω τα μονογλωσσικά δεδομένα που είναι πιο παρόμοια με την έκδοση-στόχο του συνόλου δοκιμών, τέτοια μονογλωσσικά δεδομένα χρησιμοποιήθηκαν στη συνέχεια για να κάνω πίσω μετάφραση. Στο σετ δοκιμής, τα καλύτερα υποβαλλόμενα συστήματα μου επιτυγχάνουν 35.9 και 32.2 για αγγλικές προς κινεζικές και κινεζικές προς αγγλικές κατευθύνσεις αντίστοιχα, οι οποίες είναι αρκετά υψηλές για ένα μικρό μοντέλο.', 'kk': 'Мен WMT жаңалық аудармалардың тапсырмасына қатысу және бір ресурс тілінің көпшілігін: ағылшын және қытайша (екі бағытты, ағылшын және ағылшын тіліне қытайша)  Жіберілген жүйелер (ZengHuiMT) деректерді тазалау, деректерді таңдау, артқа аудару және үлгісін ендіру. Деректерді сүзгілеу және таңдау үшін қолданылатын техникалар ережелер, тіл үлгілері және сөздерді түзету үшін сүзгіледі. WMT21 сынақтарының мақсатты нұсқаларын алу үшін бастапқы корпустың негізгі аудару үлгісін қолдандым. Содан кейін мен тіл моделдерін қолдандым, сынақтардың мақсатты нұсқасының ең ұқсатты монолингілік деректерін табу үшін, он Сынақтар бағдарламасында, менің ең жақсы жүйелерім 35,9 және 32,2 BLEU ағылшын және қытайша ағылшын тіліне жеткізеді. Бұл кішкентай үлгілер үшін өте жоғары.', 'it': "Ho partecipato al compito condiviso di traduzione di notizie WMT e mi sono concentrato su una coppia di lingue ad alta risorsa: inglese e cinese (due direzioni, cinese all'inglese e inglese al cinese). I sistemi presentati (ZengHuiMT) si concentrano sulla pulizia dei dati, la selezione dei dati, la traduzione posteriore e l'insieme dei modelli. Le tecniche che ho utilizzato per il filtraggio e la selezione dei dati includono il filtraggio per regole, modello di lingua e allineamento delle parole. Ho usato un modello di traduzione di base addestrato sul corpus iniziale per ottenere le versioni target dei set di test WMT21, poi ho usato modelli linguistici per scoprire i dati monolingue più simili alla versione target del set di test, tali dati monolingue sono stati poi utilizzati per eseguire la traduzione posteriore. Sul set di test, i miei migliori sistemi presentati raggiungono rispettivamente 35.9 e 32.2 BLEU per le direzioni inglese-cinese e cinese-inglese, che sono abbastanza alti per un modello piccolo.", 'lt': 'Dalyvavau WMT bendroje žinių vertimo užduotyje ir sutelkiau dėmesį į vieną aukšto lygio kalbų porą: anglų ir kinų (dviejų krypčių, anglų į anglų ir anglų į kinų). Pateiktose sistemose (ZengHuiMT) daugiausia dėmesio skiriama duomenų valymui, duomenų atrankai, grįžtamajam vertimui ir modelio komplektui. Duomenų filtravimo ir atrankos metodai yra filtravimas pagal taisykles, kalbos model į ir žodžių suderinimą. Naudojau bazinį vertimo model į, apmokytą pradiniu korpusu, siekiant gauti tikslines WMT21 bandymų rinkinių versijas, tada naudojau kalbinius modelius, kad sužinočiau vienkalbius duomenis, kurie labiausiai panašūs į tikslinę bandymų rinkinio versiją, tada tokie vienkalbiai duomenys buvo naudojami grįžtamajam vertimui. On the test set, my best submitted systems achieve 35.9 and 32.2 BLEU for English to Chinese and Chinese to English directions respectively, which are quite high for a small model.', 'ms': 'Saya berpartisipasi dalam tugas terjemahan berita berkongsi WMT dan fokus pada satu pasangan bahasa sumber yang tinggi: bahasa Inggeris dan Cina (dua arah, bahasa Cina kepada bahasa Inggeris dan bahasa Inggeris kepada bahasa Cina). Sistem yang dihantar (ZengHuiMT) fokus pada pembersihan data, pemilihan data, terjemahan semula dan kumpulan model. Teknik yang saya gunakan untuk penapisan dan pemilihan data termasuk penapisan mengikut peraturan, model bahasa dan penyesuaian perkataan. Saya menggunakan model terjemahan asas dilatih pada corpus awal untuk mendapatkan versi sasaran set ujian WMT21, kemudian saya menggunakan model bahasa untuk mencari data monobahasa yang paling mirip dengan versi sasaran set ujian, data monobahasa seperti itu kemudian digunakan untuk melakukan terjemahan semula. Pada set ujian, sistem yang terbaik saya hantar mencapai 35.9 dan 32.2 BLEU untuk bahasa Inggeris kepada bahasa Cina dan bahasa Cina kepada bahasa Inggeris, yang cukup tinggi untuk model kecil.', 'mk': 'Учествував на заедничката задача за превод на вести на ВМТ и се фокусирав на еден пар висок јазик: англиски и кинески (две насоки, кинески на англиски и англиски на кинески). Пренесените системи (ZengHuiMT) се фокусираат на чистење на податоци, избор на податоци, превод назад и моделен ансембл. Техниките кои ги употребив за филтрирање и селекција на податоци вклучуваат филтрирање по правила, јазички модел и поправка на зборови. Користев базичен преведувачки модел трениран на првичниот корпус за да ги добијам метните верзии на тестовите на WMT21, потоа користев јазички модели за да дознаам монојазични податоци кои се најслични на метната верзија на тестовите, вакви монојазични податоци потоа се користеа за преведување назад. На тестот, моите најдобри поднесени системи достигнуваат 35,9 и 32,2 БЛЕ за англиски на кинески и кинески на англиски насоки, кои се прилично високи за мал модел.', 'ml': 'ഞാന്\u200d WMT വാര്\u200dത്തകാര്യങ്ങള്\u200d പങ്കെടുത്ത് ഒരു ഉയരത്തിലെ വിഭവഭാഷ ജോടിയില്\u200d പങ്കുചേര്\u200dത്തിരുന്നു. ഇംഗ്ലീഷും ചൈനീസും രണ്ടു വഴി The submitted systems (ZengHuiMT) focus on data cleaning, data selection, back translation and model ensemble.  ഡേറ്റാ ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നതിനും തെരഞ്ഞെടുക്കാനും ഞാന്\u200d ഉപയോഗിച്ച ടെക്നിക്കുകള്\u200d നിയമങ്ങള്\u200d, ഭാഷ മോഡല വിഎംടി21 ടെസ്റ്റ് സെറ്റുകളുടെ ലക്ഷ്യം ലഭ്യമാക്കാന്\u200d ഞാന്\u200d ഒരു ബേസ് പരിഭാഷ മോഡല്\u200d ഉപയോഗിച്ചിരുന്നു. പിന്നീട് ഞാന്\u200d ഭാഷ മോഡല്\u200d ഉപയോഗിച്ചു. പരീക്ഷ സെറ്റിന്റെ ലക്ഷ്യ ടെസ്റ്റ് സെറ്റില്\u200d, എന്\u200dറെ ഏറ്റവും മികച്ച സിസ്റ്റമുള്ള സിസ്റ്റം 35.9, 32.2 ബെലി യു എടുക്കുന്നു. ഇംഗ്ലീഷിലേക്കും ചൈനീസിലേക്ക', 'mn': 'Би WMT-д мэдээллийн хөрөнгө оруулалтын ажлыг хуваалцаж, англи болон Хятад хэл дээр төвлөрүүлсэн. Жөнөдөлгөн систем (ZengHuiMT) өгөгдлийн цэвэрлэх, өгөгдлийн сонголт, буцаад орчуулалт болон загварын загвар нь анхаарлаа хандуулдаг. Би өгөгдлийн сүзүүлэлт болон сонголтын техникууд дүрслэл, хэл загвар болон үг тохиргоололтоор сүзүүлэлт агуулдаг. Би анхны корпус дээр суурь орчуулах загварыг ашиглаж WMT21 тестийн загварын хувилбаруудыг авч, дараа нь хэл загваруудыг ашиглаж тестийн загварын хувилбаруудын хамгийн ижил нэг хэлний өгөгдлийг олж мэдэхэд хэрэглэгдсэн. Шинэ шалгалт дээр миний хамгийн шилдэг систем 35.9, 32.2 БЛЕУ-г Англи хэл болон Хятадад англи хэл рүү хүртэл хүртэл хүртэл байна. Энэ нь жижиг загварын төлөө маш өндөр.', 'mt': 'Parteċipajt fil-kompitu ta’ traduzzjoni tal-aħbarijiet kondiviża tad-WMT u ffokajt fuq par wieħed ta’ lingwi b’riżorsi għoljin: l-Ingliż u ċ-Ċiniż (żewġ direzzjonijiet, Ċiniż għal Ingliż u Ingliż għal Ċiniż). Is-sistemi sottomessi (ZengHuiMT) jiffokaw fuq it-tindif tad-dejta, l-għażla tad-dejta, it-traduzzjoni lura u l-ġabra tal-mudelli. The techniques I used for data filtering and selection include filtering by rules, language model and word alignment.  Uża mudell ta’ traduzzjoni bażi mħarreġ fuq corpus inizjali biex tikseb il-verżjonijiet fil-mira tas-settijiet tat-test WMT21, imbagħad użajt mudelli lingwistiċi biex issir taf id-dejta monolingwistika li hija l-aktar simili għall-verżjoni fil-mira tas-sett tat-test, tali dejta monolingwistika mbagħad intużat biex issir traduzzjoni lura. Fuq is-sett tat-test, is-sistemi l-a ħjar sottomessi tiegħi jiksbu 35.9 u 32.2 BLEU għall-Ingliż lejn id-direzzjonijiet Ċiniżi u Ċiniżi lejn l-Ingliż rispettivament, li huma pjuttost għoljin għal mudell żgħir.', 'pl': 'Uczestniczyłem w zadaniu wspólnego tłumaczenia wiadomości WMT i skupiłem się na jednej wysokiej parze językowej: angielskiej i chińskiej (dwa kierunki, chiński na angielski i angielski na chiński). Przesłane systemy (ZengHuiMT) koncentrują się na czyszczeniu danych, selekcji danych, tłumaczeniu wstecznym i zespole modeli. Techniki filtrowania i selekcji danych obejmują filtrowanie według reguł, modelu językowego i wyrównywanie słów. Użyłem podstawowego modelu tłumaczenia przeszkolonego na początkowym korpusie, aby uzyskać docelowe wersje zestawów testowych WMT21, następnie użyłem modeli językowych, aby znaleźć dane jednojęzyczne, które są najbardziej podobne do docelowej wersji zestawu testowego, takie jednojęzyczne dane zostały następnie wykorzystane do tłumaczenia wstecznego. Na zestawie testowym moje najlepiej przesłane systemy osiągają 35.9 i 32.2 BLEU dla kierunków angielskich na chiński i chiński na angielski, które są dość wysokie dla małego modelu.', 'ro': 'Am participat la activitatea WMT de traducere a știrilor și m-am concentrat pe o pereche de limbi cu resurse mari: engleză și chineză (două direcții, chineză în engleză și engleză în chineză). Sistemele trimise (ZengHuiMT) se concentrează pe curățarea datelor, selectarea datelor, traducerea înapoi și ansamblul modelului. Tehnicile pe care le-am folosit pentru filtrarea și selectarea datelor includ filtrarea după reguli, modelul limbii și alinierea cuvintelor. Am folosit un model de traducere de bază instruit pe corpul inițial pentru a obține versiunile țintă ale seturilor de testare WMT21, apoi am folosit modele lingvistice pentru a afla datele monolingve care sunt cel mai asemănătoare cu versiunea țintă a setului de test, astfel de date monolingve au fost apoi folosite pentru a face traduceri înapoi. Pe setul de testare, cele mai bune sisteme depuse ale mele obțin 35.9 și 32.2 BLEU pentru direcțiile engleză în chineză și, respectiv, chineză în engleză, care sunt destul de ridicate pentru un model mic.', 'no': 'Eg delta delt i WMT delt nyhetssomsetjing og fokuserer på ein høg ressursspråk par: engelsk og kinesisk (to retningar, kinesisk til engelsk og engelsk til kinesisk). Den sendte systema (ZengHuiMT) fokuserer på dataopprydding, datautval, omsetjing tilbake og modellen. Tehnikane eg bruka for filtrering og utval inneheld filtrering etter reglar, språk- modell og ordjustering. Eg brukte ein grunnleggjande omsetjingsmodul treng på startkorpus for å få målsettingar av WMT21- testsettet, og så brukte jeg språksmodeller for å finna ut dei monospråkslage dataene som er mest liknande til målsettingsversjonen av testsettet, slike monospråksdata vart derfor brukt for å gjera omsetjinga tilbake. På testsettet oppnår min beste tildelte systemet 35,9 og 32,2 BLEU for engelsk til kinesisk og kinesisk til engelsk retningar, som er ganske høg for ein liten modell.', 'sr': 'sudjelovao sam u zadatku WMT-a za prevod vesti i fokusirao se na jedan par visokog jezika: engleski i kineski (dvije smjere, kineski na engleski i i engleski na kineski). Predloženi sistemi (ZengHuiMT) fokusiraju se na čišćenje podataka, izbor podataka, prevod nazad i model. Tehnike koje sam koristio za filtrovanje i izbor podataka uključuju filtrovanje pravila, jezički model i poravnanje riječi. Koristio sam bazni model prevoda obučen na početnom korpusu da bi dobio ciljne verzije testova WMT21, a onda sam koristio jezičke modele da saznam monojezičke podatke koje su najsličnije ciljnoj verziji seta testova, takve monojezičke podatke su onda korišćene da bi vratili prevod. Na testiranju, moji najbolji podignuti sistemi postižu 35,9 i 32,2 BLEU za engleski na kineske i kineske upute na engleski jezik, koje su prilično visoke za mali model.', 'sv': 'Jag deltog i WMT:s delade nyhets철vers채ttningsuppgift och fokuserar p책 ett spr책kpar med h철g resurs: engelska och kinesiska (tv책 riktningar, kinesiska till engelska och engelska till kinesiska). De inl채mnade systemen (ZengHuiMT) fokuserar p책 datareng철ring, dataval, bak책t철vers채ttning och modellensemble. Teknikerna jag anv채nde f철r datafiltrering och urval inkluderar filtrering efter regler, spr책kmodell och ordjustering. Jag anv채nde en grundl채ggande 철vers채ttningsmodell utbildad p책 initial korpus f철r att f책 fram m책lversionerna av WMT21 testupps채ttningar, sedan anv채nde jag spr책kmodeller f철r att ta reda p책 de enspr책kiga data som liknar m책lversionen av testupps채ttningen, s책dana enspr책kiga data anv채ndes sedan f철r att g철ra bak책t철vers채ttning. P책 provupps채ttningen uppn책r mina b채sta inl채mnade system 35,9 och 32,2 BLEU f철r engelska till kinesiska respektive kinesiska till engelska riktningar, vilket 채r ganska h철ga f철r en liten modell.', 'so': 'WMT waxaan ka qeybqaaday shaqo turjumista news oo aan ku qoray labada luqada sare ee rasmi ah: Ingiriis iyo Shiino (laba hagoor, Shiino iyo Ingiriis iyo ingiriis-iyo Shiino). Isticmaalka la soo dhiibay (ZengHuiMT) waxay ku focus on nadiifsashada data, doorashada data, turjumista dib iyo model ensembel. Teqooyinka aan u isticmaalay baaritaanka iyo doorashada macluumaadka waxaa ka mid ah filteriyayaasha sharciyada, tusaale ahaan luqada iyo isbedelka hadalka. I used a base translation model trained on initial corpus to obtain the target versions of the WMT21 test sets, then I used language models to find out the monolingual data that is most similar to the target version of test set, such monolingual data was then used to do back translation.  Xafiiska imtixaanka, nidaamkayga ugu wanaagsan ee la soo dhiibay waxay u gaadhaan 35.9 iyo 32.2 BLEU si loo qoro afka ingiriisiga oo Shiino iyo Shiino ugu diro hagaha ingiriisiga, taasoo aad u sareeya model yar.', 'ta': 'நான் WMT செய்தி மொழிமாற்றி பணியில் பகிர்ந்து ஒரு உயர்ந்த மூலத்தின் ஜோடி: ஆங்கிலம் மற்றும் சீனா (இரண்டு திசைகள், சீனா மொழிமாற் கொடுக்கப்பட்ட அமைப்பு தரவு வடிகட்டி மற்றும் தேர்வு செய்வதற்கான பயன்படுத்தப்பட்ட தொழில்நுட்பம் விதிமுறைகள், மொழி மாதிரி மற்றும் வா WMT21 சோதனை அமைப்புகளின் இலக்கு பதிப்புகளை பெறுவதற்கான அடிப்படை மொழிமாற்ற மாதிரி பயிற்சி முறைமையை பயன்படுத்தினேன், பின்னர் நான் மொழி மாதிரி மாதிரிகளை கண்டுபிடிக்க சோதனை அமைப்பில், என் சிறந்த முறைமைகள் 35.9 மற்றும் 32.2 பிலியு ஆங்கிலத்திற்கு ஆங்கிலத்திற்கு மேலும் ஆங்கிலத்திற்கு மேலும் பெறு', 'si': 'මම WMT එක්ක වාර්තාව වාර්තාව භාෂාවෙන් සම්බන්ධ කරනවා ඒ වගේම ඉංග්\u200dරීසි සහ චීනි භාෂාවෙන් ප්\u200dරධානය කරනවා. පිළිබඳු පද්ධතිය (ZengHuiMT) දත්ත පිරික්ෂණය, දත්ත තෝරණය, පස්සේ වාර්ථාව සහ මදුල සංවිධානය සඳහා  මම දත්ත පරික්ෂණය සහ තෝරණය සඳහා ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය, භාෂා මොඩේල් සහ වචන පරික්ෂණය සඳහා ප මම WMT21 පරීක්ෂණ සෙට්ටුවේ ලක්ෂණ ප්\u200dරවේශයක් ලැබීමට පටන් ගත්ත පරීක්ෂණ ප්\u200dරවේශයක් භාවිතා කරනවා, ඊට පස්සේ මම භාෂාව මොඩේල් එක භාෂාවික දත්ත හොයා පරීක්ෂණය සම්බන්ධයෙන්, මගේ හොඳම පද්ධතිය පිළිගත්ත පද්ධතියෙන් ඉංග්\u200dරීසියාව චීනි සහ චීනියාව ඉංග්\u200dරීසියාව ප්\u200dර', 'ur': 'میں نے WMT میں نیویس ترجمہ کا کام شریک کیا تھا اور ایک بلند سراسر زبان کی جوڑی پر تمرکز کیا تھا: انگلیسی اور چینی (دو طریقے، انگلیسی اور انگلیسی سے چینی اور چینی سے)۔ ڈاٹ پاکیزگی، ڈاٹا انتخاب، پیچھے ترجمہ اور موڈل امبل پر تمرکز کیا گیا ہے. میں نے ڈیٹا فیلٹرینگ اور انتخاب کے لئے استعمال کیا ہے فیلٹرینگ، زبان مدل اور کلمات متصل کے ذریعہ۔ میں نے WMT21 امتحان سٹوں کی موجود ویورژوں کو حاصل کرنے کے لئے ایک بنسس ترجمہ موڈل کو استعمال کیا تھا پھر میں نے زبان موڈل کو استعمال کیا تھا کہ ایک زبان ویورژی ڈائٹ کو معلوم کریں جو ٹیس سٹ کی موجود ویورژی کے مطابق زیادہ برابر ہے، اس کے بعد ایک زبان ویورژی ڈائ آزمائش سٹ پر، میرے بہترین تحویل دیے ہوئے سیسٹم 35.9 اور 32.2 بلیوس کے لئے انگلیسی اور چینی کے لئے انگلیسی دکھانوں پر، جو ایک چھوٹے موڈل کے لئے بہت بلند ہیں۔', 'vi': 'Tôi đã tham gia vào công việc dịch chuyển tin tức chia sẻ WRT và tập trung vào một cặp ngôn ngữ cao: Anh và Trung Quốc (hai hướng, Trung Quốc, Anh-Anh-Trung Quốc và Trung Quốc) Các hệ thống được gửi đến tập trung vào việc quét dữ liệu, chọn dữ liệu, dịch ngược và kết hợp mẫu. Các kỹ thuật tôi dùng cho việc lọc dữ liệu và chọn bao gồm việc lọc theo các quy tắc, theo kiểu ngôn ngữ và cấu hình từ. Tôi đã sử dụng một mô hình dịch cơ bản được đào tạo trên tập đoàn đầu tiên để có được các phiên bản thử nghiệm đích của tập hợp thử nghiệm WM, sau đó tôi dùng các mô hình ngôn ngữ để tìm ra dữ liệu độc ngôn ngữ tương tự với phiên bản thử đích của tập hợp thử nghiệm. Sau đó, dữ liệu độc ngôn ngữ đó được dùng để dịch lại. Trên bộ thử nghiệm, hệ thống được gửi tốt nhất của tôi đạt được 35.9 và 32.2 cả tiếng Anh với tiếng Trung và Trung Quốc, với hướng dẫn tiếng Anh, khá cao đối với một mô hình nhỏ.', 'uz': "Men WMT xitoycha (ikkita boshqaruv, Xitoycha va Inglizchaga Inglizchaga Inglizchaga va Xitoycha tiliga) bir yuqori manbalar tillariga murojaat qildim. @ info: whatsthis @ info: whatsthis Men WMT21 sinov versiyalarini olish uchun asosiy tarjima modeli ishlatilgan edim. Keyin mening o'z tilning modellarini aniqlashga foydalandim, bu sinov versiyasining eng qiymatiga oʻxshash maʼlumotni aniqlashga foydalandim. Sinov sohasida eng eng yuqori tizim ingliz tilida xitoycha va Xitoycha tilida 35.9 va 32.2 BLEU bo'ladi. Bu bir kichkina model uchun juda uzun.", 'bg': 'Участвах в съвместната задача за превод на новини и се фокусирах върху една езикова двойка с висок ресурс: английски и китайски (две посоки, китайски на английски и английски на китайски). Представените системи се фокусират върху почистване на данни, подбор на данни, обратен превод и моделен ансамбъл. Техниките, които използвах за филтриране и подбор на данни включват филтриране по правила, езиков модел и подравняване на думите. Използвах базов преводачески модел, обучен върху първоначалния корпус, за да получа целевите версии на тестовите комплекти WMT21, след това използвах езикови модели, за да открия моноезичните данни, които са най-близки до целевата версия на тестовите комплекти, такива моноезични данни бяха използвани за извършване на обратен превод. На тестовия комплект най-добрите ми представени системи постигат съответно 35.9 и 32.2 за английски към китайски посоки и китайски към английски посоки, които са доста високи за малък модел.', 'nl': 'Ik nam deel aan de WMT shared news translation taak en richt me op één hoog resource taalpaar: Engels en Chinees (twee richtingen, Chinees naar Engels en Engels naar Chinees). De ingediende systemen (ZengHuiMT) richten zich op data cleaning, data selectie, back translation en model ensemble. De technieken die ik gebruikte voor het filteren en selecteren van gegevens omvatten filteren op regels, taalmodel en woorduitlijning. Ik gebruikte een basisvertaalmodel getraind op het eerste corpus om de doelversies van de WMT21 testsets te verkrijgen, vervolgens gebruikte ik taalmodellen om de eentalige gegevens te achterhalen die het meest lijken op de doelversie van de testset, dergelijke eentalige gegevens werden vervolgens gebruikt om terug te vertalen. Op de testset bereiken mijn best ingediende systemen 35.9 en 32.2 BLEU voor respectievelijk Engels naar Chinees en Chinees naar Engels, die vrij hoog zijn voor een klein model.', 'da': "Jeg deltog i WMT's delte nyhedsoversættelsesopgave og fokuserede på ét sprogpar med høj ressource: engelsk og kinesisk (to retninger, kinesisk til engelsk og engelsk til kinesisk). De indsendte systemer (ZengHuiMT) fokuserer på datarengøring, datavalg, tilbagevendende oversættelse og model ensemble. De teknikker, jeg brugte til datafiltrering og valg, omfatter filtrering efter regler, sprogmodel og ordjustering. Jeg brugte en grundlæggende oversættelsesmodel trænet på det indledende korpus til at få målversionerne af WMT21 testsættet, derefter brugte jeg sprogmodeller til at finde ud af de ensprogede data, der minder mest om målversionen af testsættet, sådanne ensprogede data blev derefter brugt til at lave back-oversættelse. På testsættet opnår mine bedste indsendte systemer 35,9 og 32,2 BLEU for henholdsvis engelsk til kinesisk og kinesisk til engelsk retninger, hvilket er ret højt for en lille model.", 'id': 'Saya berpartisipasi di WMT berbagi tugas terjemahan berita dan fokus pada satu pasangan bahasa sumber daya yang tinggi: Bahasa Inggris dan Cina (dua arah, bahasa Cina ke Inggris dan bahasa Inggris ke Cina). Sistem yang dikirim (ZengHuiMT) fokus pada pembersihan data, pemilihan data, terjemahan kembali dan ensemble model. Teknik yang saya gunakan untuk penapisan dan seleksi data termasuk penapisan oleh aturan, model bahasa dan penyesuaian kata. Saya menggunakan model terjemahan dasar yang dilatih pada corpus awal untuk mendapatkan versi sasaran dari set tes WMT21, kemudian saya menggunakan model bahasa untuk mencari tahu data monobahasa yang paling mirip dengan versi sasaran dari set tes, data monobahasa seperti itu kemudian digunakan untuk melakukan terjemahan kembali. Pada set tes, sistem terbaik yang saya kirim mencapai 35,9 dan 32,2 BLEU untuk bahasa Inggris ke Cina dan Cina ke arah Inggris, yang cukup tinggi untuk model kecil.', 'hr': 'sudjelovao sam u zadatku prijevoza vijesti WMT-a i fokusirao se na jedan par visokog jezika: engleski i kineski (dva smjera, kineski na engleski i i engleski na kineski). Predloženi sustavi (ZengHuiMT) fokusiraju se na čišćenje podataka, izbor podataka, prevod natrag i model. Tehnike koje sam koristio za filtrovanje i izbor podataka uključuju filtrovanje pravila, jezički model i poravnanje riječi. Koristio sam bazni model prevoda obučen na početnom korpusu kako bi dobio ciljne verzije testova WMT21, zatim sam koristio jezičke modele kako bi saznao monojezičke podatke koje su najsličnije ciljnoj verziji set a testova, takve monojezičke podatke su potom korišćene za povratak prevoda. Na testiranju, moji najbolji podignuti sustavi postignu 35,9 i 32,2 BLEU za engleski na kineske i kineske upute na engleski način, koje su prilično visoke za mali model.', 'de': 'Ich nahm an der WMT-gemeinsamen Nachrichten羹bersetzungsaufgabe teil und konzentrierte mich auf ein Sprachpaar hoher Ressourcen: Englisch und Chinesisch (zwei Richtungen, Chinesisch zu Englisch und Englisch zu Chinesisch). Die eingereichten Systeme (ZengHuiMT) konzentrieren sich auf Datenbereinigung, Datenauswahl, R羹ck羹bersetzung und Modellensemble. Die Techniken, die ich f羹r die Datenfilterung und -auswahl verwendet habe, umfassen das Filtern nach Regeln, Sprachmodell und Wortausrichtung. Ich benutzte ein Basis羹bersetzungsmodell, das auf dem ersten Korpus trainiert wurde, um die Zielversionen der WMT21-Tests瓣tze zu erhalten, dann verwendete ich Sprachmodelle, um die einsprachigen Daten herauszufinden, die der Zielversion des Testsets am 瓣hnlichsten sind. Solche einsprachigen Daten wurden dann f羹r die R羹ck羹bersetzung verwendet. Auf dem Testset erreichen meine am besten eingereichten Systeme 35.9 und 32.2 BLEU f羹r Englisch in Chinesisch und Chinesisch in Englisch, die f羹r ein kleines Modell recht hoch sind.', 'sw': 'I participated in the WMT shared news translation task and focus on one high resource language pair: English and Chinese (two directions, Chinese to English and English to Chinese).  Mfumo uliotolewa (ZengHuiMT) ulijikita kwenye usafi wa data, uchaguzi wa data, tafsiri ya nyuma na mfumo wa model. Teknolojia nilizotumia kwa ajili ya kuchuja taarifa na uchaguzi ni pamoja na kuchujwa kwa sheria, mitindo ya lugha na usambazaji wa maneno. Nilitumia mfumo wa utafsiri wa msingi ulioelekezwa kwenye vifaa vya mwanzo ili kupata toleo la seti za jaribio la WMT21, kisha nilitumia mifano ya lugha kutambua data za lugha ambazo ni sawa zaidi na toleo la mtihani, takwimu kama hizo za kimonolinguli zilitumika kufanya tafsiri tena. Katika kituo cha jaribio, mifumo yangu bora iliyotolewa inafanikiwa BLEU 35.9 na 32.2 kwa ajili ya Kiingereza na Kichina kwa namna moja ya maelekezo ya Kiingereza, ambayo ni ya juu kwa mfano mdogo.', 'ko': '저는 WMT 공유 뉴스 번역 임무에 참가했고 영어와 중국어(쌍방향, 중국어 대 영어와 영어 대 중국어)에 전념했습니다.제출된 시스템(ZengHuiMT)은 데이터 정리, 데이터 선택, 번역과 모델 통합에 전념한다.데이터 필터와 선택에 사용되는 기술은 규칙에 따라 필터하고 언어 모델과 단어를 정렬하는 것을 포함한다.저는 초기 언어 자료 라이브러리에서 훈련된 기초 번역 모델을 사용하여 WMT21 테스트 집합의 목표 버전을 얻은 다음에 언어 모델을 사용하여 테스트 집합의 목표 버전과 가장 비슷한 단어 데이터를 찾아낸 다음에 이런 단어 데이터로 반역을 합니다.테스트 집합에서 내가 제출한 가장 좋은 시스템은 각각 35.9와 32.2 BLEU의 중영문과 중영문 방향에 달하는데 이것은 소형 모델에 있어서 상당히 높다.', 'fa': 'من در عملیات ترجمه خبری WMT شریک شدم و روی یک جفت زبان بالا تمرکز کردم: انگلیسی و چینی (دو مسیر، چینی به انگلیسی و انگلیسی به چینی). سیستم\u200cهای پیشنهاد (ZengHuiMT) روی پاک کردن داده\u200cها، انتخاب داده\u200cها، ترجمه پشت و مدل تمرکز می\u200cکنند. تکنیک\u200cهایی که برای فیلتر کردن و انتخاب داده\u200cها استفاده کردم شامل فیلتر کردن با قوانین، مدل زبان و تنظیم کلمه است. من از یک مدل ترجمه بنیادی استفاده کردم که روی کورپوس اولیه آموزش داده شده است تا نسخه هدف\u200cهای مجموعه\u200cهای آزمایش WMT21 را بگیرم، سپس از مدل\u200cهای زبانی استفاده کردم تا اطلاعات monolingual را بفهمم که بیشتر شبیه نسخهٔ هدف\u200cهای مجموعه آزمایش است، این داده\u200cهای monolingual پس در مجموعه آزمایش، بهترین سیستم\u200cهای تحویل من 35.9 و 32.2 BLEU برای انگلیسی به چینی و چینی به مسیرهای انگلیسی رسیده است، که برای یک مدل کوچک بسیار بالا هستند.', 'sq': 'Unë morra pjesë në detyrën e përkthimit të lajmeve të përbashkëta të WMT dhe u përqëndrua në një çift të lartë burimesh gjuhësh: anglisht dhe kinez (dy drejtime, kinez në anglisht dhe anglisht në kinez). Sistemet e paraqitura (ZengHuiMT) përqëndrohen në pastrimin e të dhënave, zgjedhjen e të dhënave, përkthimin mbrapsht dhe ansamblin e modelit. Tekniket që kam përdorur për filtrimin dhe zgjedhjen e të dhënave përfshijnë filtrimin me rregulla, modelin gjuhësor dhe përshtatjen e fjalëve. Përdora një model përkthimi bazë të trajnuar në korpus fillestar për të marrë versionet objektive të grupeve testuese WMT21, pastaj përdora modelet gjuhësore për të zbuluar të dhënat monogjuhësore që janë më të ngjashme me versionin objektiv të grupit testues, të tilla të dhëna monogjuhësore u përdorën pastaj për të përkthyer përsëri. Në grupin e testeve, sistemet e mia më të mira të paraqitura arrijnë 35.9 dhe 32.2 BLEU për drejtimet angleze në kinez dhe kineze në angleze respektivisht, të cilat janë mjaft të larta për një model të vogël.', 'tr': 'WMT-de haberler terjime täbligine mejbur boldum we olaryň bir ýokary çeşme täbligine üns berdim: I ňlisçe we Çin çe (iki yönet, iňlisçe we iňlisçe Çinçe). Sahypa edilen sistemler (ZengHuiMT) maglumat temizlemegine, maglumat saýlamagyna fokus edýär. Maglumat süýtgetmek we saýlamak üçin ullanýan tekniklerde süýtgetmek düzgünlere, dil modellere we söz sözlerine görä meýilleşdirilýär. WMT21 testiň maksady düzümlerini almak üçin başlangyç korpusda bilinen baz terjime modelini ulandym, soňra testiň maksady düzümleriniň iň benzeri bolan monolingüň verisini tapmak üçin dil modellerini ulandym. Testlerde meniň iň gowy gönderilen sistemamyň 35,9 we 32,2 BLEU-a Iňlisçe we Hytaý dilinde diňlisçe ýokary bar, kiçi bir nusga üçin gaty uzyn.', 'hy': 'Ես մասնակցեցի ԱՄԹ-ի ընդհանուր նորությունների թարգմանման խնդիրներին և կենտրոնացա մեկ բարձր ռեսուրսների լեզվի զույգի վրա՝ անգլերեն և չինարեն (երկու ուղղություն, չինարեն անգլերեն և անգլերե Տեղադրված համակարգերը (ZengHUiMT) կենտրոնանում են տվյալների մաքրման, տվյալների ընտրության, վերադարձ թարգմանման և մոդելների համակարգի վրա: Տվյալների ֆիլտրման և ընտրության համար օգտագործված տեխնիկաները ներառում են ֆիլտրումը կանոնների, լեզվի մոդելի և բառերի հավասարման միջոցով: Ես օգտագործեցի մի հիմնական թարգմանման մոդել, որը սովորեցվել է սկզբնական կորպոսի վրա, որպեսզի ստանամ World MT21 փորձարկման համակարգերի նպատակային տարբերակները, հետո օգտագործեցի լեզվի մոդելներ, որպեսզի պարզեմ, որ միալեզվի տվյալները, որոնք ամենանման են փորձա Տեստերի ընթացքում իմ լավագույն ներկայացված համակարգերը հասնում են 35.9 և 32.2 անգլերեն, չինական և անգլերեն անգլերեն ուղղությունների համար, որոնք բավականին բարձր են փոքր մոդելի համար:', 'af': "Ek het gedeel in die WMT deel nuusvertaling taak en fokus op een hoë hulpbron taal paar: Engels en Sjinees (twee rigtings, Sjinees na Engels en Engels na Sjinees). Die ingestuurde stelsels (ZengHuiMT) fokus op data skoonmaak, data kies, terug vertaling en model ensemble. Die teknike wat ek gebruik het vir data filtering en kies insluit filtering deur reëls, taal model en woordopreging. Ek het 'n basis vertaling model gebruik wat op die aanvanklike korpus opgelei is om die doel weergawe van die WMT21 toets stel te kry, dan het ek taal modelle gebruik om die monotaal data te vind wat mees gelyk is aan die doel weergawe van toets stel, sodat monotaal data dan gebruik was om terug vertaling te doen. Op die toets stel, het my beste aangevoerde stelsels 35,9 en 32,2 BLES vir Engels tot Sjinees en Sjinees na Engelske rigtings, wat heeltemal hoog is vir 'n klein model.", 'az': 'WMT haqq çeviri işin ə daxil oldum və bir yüksək ressurs dili çift: İngilizə və Çincə (iki yönəlik, İngilizə və İngilizə Çincə ilə İngilizə və Çincə ilə Çincə) danışdım. İstifadə edilən sistemlər (ZengHuiMT) məlumatları təmizləməyə, məlumat seçimi, geri çeviri və modellərə odaqlanır. Mənim veri filtrləmək və seçim üçün istifadə etdiyim tekniklərdə filtrləmək, dil modeli və söz tərəfindən istifadə edilir. Mən WMT21 sınama qurğularının məqsəd versiyonlarını almaq üçün başlangıç korpusda təhsil edilmiş əsas çevirim modelini istifadə etdim. Sonra sınama qurğusunun ən bənzərini öyrənmək üçün dil modelini istifadə etdim. Bu monodil verilər geri çevirilmək üçün istifadə edildilər. Testdə ən gözəl sistemim İngilizce və Çinlə İngilizce üçün 35,9 və 32,2 BLEU nəticəsində İngilizce və Çinlə tərəflərə gəlir. Bu kiçik modellərə çox yüksək.', 'am': "WMT-ን የዜና ትርጉም አድራጊ እና በአንድ ከፍተኛ የክፍል ቋንቋ ሁለት ዓይነቶች ላይ ተማክቻለሁ፤ እንግሊዝኛ እና ቻይና (ሁለት directions, ቻይና ወደ እንግሊዘኛ እና እንግሊዘኛ ወደ ቻይና) የደረጃ ምርጫዎች (ZengHuiMT) ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s የመጀመሪያው ኮርፓስ የWMT21 ተርጓሚዎችን ለማግኘት የተጠቃሚ የደብዳቤ ትርጉም ሞዴል ተጠቃሚ ነበር፤ ከዚያም በኋላ የቋንቋ ዓይነቶች የሞክራዊ ዳታዎችን ለመግለጥ የሞክራዊ ድምፅ መልዕክት ለመግለጥ ተጠቀቅሜ ነበር፤ እንደዚህ በሞሎልቋል ዳታዎችን ለመመለስ ተጠቃሚ ነበር፡፡ On the test set, my best submitted systems achieve 35.9 and 32.2 BLEU for English to Chinese and Chinese to English directions respectively, which are quite high for a small model.", 'cs': 'Podílel jsem se na WMT sdíleném překladu zpráv a zaměřil jsem se na jeden jazykový pár vysokých zdrojů: angličtinu a čínštinu (dva směry, čínštinu do angličtiny a angličtinu do čínštiny). Předložené systémy (ZengHuiMT) se zaměřují na čištění dat, výběr dat, zpětný překlad a modelový soubor. Techniky, které jsem použil pro filtrování a výběr dat, zahrnují filtrování podle pravidel, jazykového modelu a zarovnání slov. Použil jsem základní překladový model trénovaný na počátečním korpusu k získání cílových verzí testovacích sad WMT21, pak jsem použil jazykové modely k zjištění jednojjazyčných dat, která jsou nejvíce podobná cílové verzi testovací sady, taková jednojjazyčná data byla pak použita k provedení zpětného překladu. Na testovací sadě dosahují mé nejlepší předložené systémy 35.9 a 32.2 BLEU pro angličtinu do čínštiny a čínštinu do angličtiny, které jsou poměrně vysoké pro malý model.', 'bn': 'আমি উইএমটি সংবাদ অনুবাদের কাজে অংশগ্রহণ করেছি এবং একটি উচ্চ সম্পদের জোড়ায় মনোযোগ দিয়েছি: ইংরেজি এবং চীন (দুই দিকের দিকে, চীনা থেকে ইংর জমা করা সিস্টেম (জেনহুইএমটি) ডাটা পরিষ্কার, তথ্য নির্বাচন, পেছনে অনুবাদ এবং মডেল এনএমবেলের উপর মনোযোগ দিয়েছে। ডাটা ফিল্টারিং এবং নির্বাচনের জন্য আমি ব্যবহার করেছিলাম এমন কৌশল যেগুলোর মধ্যে নিয়ম, ভাষা মডেল এবং শব্দের স্থ আমি একটি বেস অনুবাদ মডেল ব্যবহার করেছিলাম প্রাথমিক কোর্পাসে প্রশিক্ষণ করা হয়েছিলাম WMT21 টেস্ট সেটের লক্ষ্য সংস্করণ পাওয়ার জন্য, তারপর আমি ভাষার মডেল ব্যবহার করেছিলাম, যা পরীক্ পরীক্ষায় আমার সবচেয়ে ভালো জমা প্রদান করা সিস্টেম ৩৫. ৯ এবং ৩২.', 'bs': 'Učestvovao sam u zadatku za prevod vijesti WMT-a i fokusirao se na jedan par visokog jezika: engleski i kineski (dvije smjere, kineski na engleski i engleski na kineski). Predloženi sistemi (ZengHuiMT) fokusiraju se na čišćenje podataka, izbor podataka, prevod nazad i model. Tehnike koje sam koristio za filtrovanje i izbor podataka uključuju filtrovanje pravila, jezički model i poravnanje riječi. Koristio sam bazni model prevoda obučen na početnom korpusu kako bi dobio ciljne verzije kompleta WMT21 test a, a zatim sam koristio jezičke modele da saznam monojezičke podatke koje su najsličnije ciljnoj verziji seta testa, takve monojezičke podatke su onda korišćene za povratak prevoda. Na testiranju, moji najbolji podignuti sistemi postignu 35,9 i 32,2 BLEU za engleski na kineske i kineske upute na engleski jezik, koje su prilično visoke za mali model.', 'ca': "Vaig participar en la feina de traducció de notícies compartida de la WMT i em vaig centrar en un parell de llenguatges d'alt recurso: anglès i xinès (dues direccions, xinès a anglès i anglès a xinès). Els sistemes enviats (ZengHuiMT) es centren en la netejació de dades, la selecció de dades, la traducció posterior i el conjunt model. Les tècniques que vaig utilitzar per filtrar i seleccionar dades inclouen filtrar per regles, model lingüístic i alliniament de paraules. Vaig utilitzar un model de traducció bàsica entrenat en el corpus inicial per obtenir les versions alvo dels conjunts de prova WMT21, després vaig utilitzar models de llenguatge per descobrir les dades monolingües que són més similars a la versió alvo del conjunt de prova, aquestes dades monolingües es van utilitzar per tornar a traducció. En el conjunt d'exàmens, els meus millors sistemes submetits aconsegueixen 35,9 i 32,2 BLEU per anglès a xinès a anglès respectivament, que són bastant alts per un petit model.", 'et': 'Osalesin WMT jagatud uudiste tõlkimise ülesandes ja keskendusin ühele kõrge ressursiga keelepaarile: inglise ja hiina keele (kaks suunda, hiina keelest inglise ja inglise keelest hiina keelde). Esitatud süsteemid (ZengHuiMT) keskenduvad andmete puhastamisele, andmete valikule, tagasitõlkimisele ja mudeli ansamblile. Andmete filtreerimiseks ja valimiseks kasutatud tehnikad hõlmavad filtreerimist reeglite, keelemudeli ja sõnade joondamise järgi. WMT21 testikomplektide sihtversioonide saamiseks kasutasin algkorpusel koolitatud alustõlkemudelit, seejärel kasutasin keelemudeleid, et välja selgitada ühekeelsed andmed, mis sarnanevad kõige rohkem testikomplekti sihtversiooniga, seejärel kasutati ühekeelseid andmeid tagasitõlkimiseks. Testikomplektis saavutavad minu parimad esitatud süsteemid vastavalt 35,9 ja 32,2 BLEU inglise ja hiina ja inglise suunas, mis on väikese mudeli jaoks üsna kõrged.', 'fi': 'Osallistuin WMT:n jaettuun uutiskäännöstöön ja keskityin yhteen korkean resurssin kielipariin: englantiin ja kiinaan (kaksi suuntaa, kiinasta englantiin ja englannista kiinaan). Toimitetut järjestelmät (ZengHuiMT) keskittyvät tietojen puhdistukseen, tietojen valintaan, takaisinkääntämiseen ja mallikokonaisuuteen. Tietojen suodatus- ja valintatekniikoita ovat mm. sääntöjen, kielimallin ja sanalinjauksen suodatus. Käytin alkuperäiskorpusella koulutettua peruskirjoitusmallia WMT21-testien kohdeversioiden saamiseksi, sitten kielimalleilla selvitin monikielisen aineiston, joka on eniten samankaltainen kuin testisarjan kohdeversio, ja tällaista monikielistä aineistoa käytettiin jälkikääntämiseen. Testisetissä parhaat toimitetut järjestelmäni saavuttavat 35,9 ja 32,2 BLEU:n englannin ja kiinan ja englannin suuntiin, jotka ovat melko korkeat pienellä mallilla.', 'jv': 'Aku nyelangan ning basa sing nyebutaké WWT karo perusahaan anyari ingkang karo pawaran langkung banjur: Inggris karo Caino (durung bisa basa, Cino karo Inggris lan Inggris karo Chinese). Sistem-sistem sing nyimpen (JenghuiMT) kang dipungot dadi ngêrunggo data, dadi sing, mulai terjamahan lan model model. Teknik sing wis nggawe kanggo kowe nggambar barang data karo Kelangan luwih basa, model dan word alignment Aku gunakake sistem penting model sing ditambungan ning sampeyan sampeyan anyar tentang kanggo ngelakon versi sing gawe bakal terus nggawe geraksi yang cukup, dadi aku ngewehi model anyar sampeyan ingkang sampeyan bakal terus akeh akeh operasi kanggo ngerasai versi yang cukup kanggo ditambah sampeyan kanggo kaki dianggap, dadi lunak-ingkang sampeyan gegam Awak dhéwé éntuk sing beraksi, sistem sing luwih-luwih nggawe tanggal alam kanggo tinggal Inggris ning alam sing katêpakan karo Caino karo inggris, sing ndêngé awak dhéwé sing mengko akeh model sing mengko.', 'sk': 'Sodelovala sem pri deljeni nalogi prevajanja novic WMT in se osredotočila na en jezikovni par visokih virov: angleščina in kitajščina (dve smeri: kitajščina v angleščino in angleščina v kitajščino). Predloženi sistemi (ZengHuiMT) se osredotočajo na čiščenje podatkov, izbiro podatkov, prevajanje nazaj in ansambel modelov. Tehnike, ki sem jih uporabil za filtriranje in izbiro podatkov, vključujejo filtriranje po pravilih, jezikovni model in poravnavo besed. Za pridobitev ciljnih različic testnih sklopov WMT21 sem uporabil osnovni prevajalski model, usposobljen za začetni korpus, nato pa sem uporabil jezikovne modele za ugotovitev enojezičnih podatkov, ki so najbolj podobni ciljni verziji testnega sklopa, takšni enojezični podatki pa so bili nato uporabljeni za nazaj prevajanje. Na testnem kompletu so moji najboljši predloženi sistemi dosegli 35,9 in 32,2 BLEU za angleško-kitajsko smer oziroma kitajsko-angleško smer oziroma kitajsko-angleško smer, kar je precej visoko za majhen model.', 'ha': "Inayi shirin da WMT na share aikin fassarar lãbãri da kuma na yi makini a kan wata nau'i biyu na lugha sarki: Ingiriya da China (shiryarwa biyu, China zuwa Ingiriya da Ingiriya zuwa China). @ info: whatsthis The techniques I used for data filtering and selection include filtering by rules, language model and word alignment.  Ban yi amfani da wani motel na fassarar fassarar a kan kure na farko, dõmin in motsa versiyori na tsari na WMT21, sa'an nan na yi amfani da misalin harshen zuwa zane dõmin in san data masu motsi na mantoli da ke mafi daidai da versiyon sigar jarraba, wannan data na monolilugha aka amfani da shi dõmin a sake translation. A kan jarraba, mafiya kyakkyawan matsayina da aka saka ma'anaTa 35.9 da 32.2", 'bo': 'ངས་WMT ནང་དུ་གསར་འགྱུར་བརྗོད་ཀྱི་འགྲེལ་བཤད་ཀྱི་ལས་འགན་སྤྱད་ནས་མཐུན་རྐྱེན་ཐུབ་པའི་སྐད་རིགས་གཅིག་དང་མཐུན་སྤྱད་ཡོད། ཨིན་ The submitted systems (ZengHuiMT) focus on data cleaning, data selection, back translation and model ensemble. ངས་ཚགས་མ་འཚོལ་བཤེར་དང་གདམ་ཀ་ཡོད་པའི་ཐབས་ལམ་ལ་སྤྱོད་པའི་རྣམ་གྲངས་ཀ་དེ་ནི་དབུས་གཞུང་དང་སྐད་རིགས་མི་ I used a base translation model trained on initial corpus to obtain the target versions of the WMT21 test sets, then I used language models to find out the monolingual data that is most similar to the target version of test set, such monolingual data was then used to do back translation. བརྟག་ཞིབ་ཚད་ལ་འཛིན་བྱས་ན། ངའི་མ་ལག་ཆེན་ཡིན་པས་དབྱིན་ཡིག་དང་རྒྱ་ནག', 'he': 'השתתפתי במשימת התרגום החדשות המשותפת של WMT ומוקדמתי על זוג שפת משאבים גבוהה אחד: אנגלית וסינית (שתי כיוונות, סינית לאנגלית ואנגלית לסינית). The submitted systems (ZengHuiMT) focus on data cleaning, data selection, back translation and model ensemble.  הטכניקות שהשתמשתי לסנן ומבחר נתונים כוללות הסנן על ידי חוקים, מודל שפה ומתאים מילים. השתמשתי במודל התרגום הבסיסי מאומן בקורפוס הראשון כדי להשיג את גרסאות המטרה של קבוצות המבחנים WMT21, ואז השתמשתי במודלים שפות כדי לגלות את הנתונים המונושפתיים הכי דומים לגרסה המטרה של קבוצת המבחנים, נתונים מונושפתיים כאלה השתמשו לאחר מכן לתרגום בחזרה. במערכת הבדיקות, המערכות הטובות ביותר שלי משיגות 35.9 ו-32.2 BLEU לאנגלית לכיוונים סינים לאנגלית לכיוונים סינים לאנגלית, שהן די גבוהות למודל קטן.'}
{'en': 'The Mininglamp Machine Translation System for WMT21', 'es': 'El sistema de traducción automática Mininglamp para WMT21', 'pt': 'O Sistema de Tradução Automática Mininglamp para WMT21', 'ar': 'نظام الترجمة الآلية لمصابيح التعدين لـ WMT21', 'fr': 'Le système de traduction automatique Mininglamp pour WMT21', 'zh': '以 WMT21 矿灯机器翻译统', 'ja': 'WMT 21用マイニングランプ機械翻訳システム', 'hi': 'WMT21 के लिए माइनिंगलैंप मशीन अनुवाद प्रणाली', 'ru': 'Система машинного перевода Mininglamp для WMT21', 'ga': 'An Córas Aistriúcháin Meaisín Mininglamp do WMT21', 'ka': 'WMT21Name', 'el': 'Το σύστημα μηχανικής μετάφρασης Mininglamp για WMT21', 'kk': 'Comment', 'hu': 'A Mininglámpa gépi fordító rendszer WMT21 számára', 'it': 'Il sistema di traduzione automatica Mininglamp per WMT21', 'lt': 'WMT21 Mininglamp mašinų vertimo sistema', 'ml': 'WMT21- നുള്ള മിനിങ്ങിംഗ്ലാമ്പ് മെഷീന്\u200d പരിഭാഷ സിസ്റ്റം', 'ms': 'Sistem Terjemahan Mesin Mininglamp untuk WMT21', 'mt': 'Is-Sistema tat-Traduzzjoni tal-Makkinarju Mininglamp għad-WMT21', 'mk': 'The Mininglamp Machine Translation System for WMT21', 'mn': 'Mininglamp Machine Translation System for WMT21', 'pl': 'System tłumaczenia maszynowego Mininglamp dla WMT21', 'sr': 'Mininglamp Machine Translation System for WMT21', 'no': 'Name', 'si': 'WMT21Name', 'ro': 'Sistemul de traducere a mașinii Mininglamps pentru WMT21', 'sv': 'Mininglampan Machine Translation System för WMT21', 'ta': 'The Mininglamp Machine Translation System for WMT21', 'so': 'WMT21', 'ur': 'Name', 'uz': 'Name', 'vi': 'Hệ thống dịch máy thu nhỏ cho WM21', 'bg': 'Системата за машинен превод Mininglamp за WMT21', 'hr': 'Mininglamp Machine Translation System for WMT21', 'nl': 'Het Mininglamp Machine Translation Systeem voor WMT21', 'id': 'Sistem Translation Mesin Mininglamp untuk WMT21', 'fa': 'Name', 'da': 'Mininglamps maskinoversættelsessystem til WMT21', 'de': 'Das Mininglamp Machine Translation System für WMT21', 'ko': 'WMT21 Mininglamp 기계 번역 시스템', 'sw': 'Mfumo wa Tafsiri wa Mashine ya Mininglamp kwa WMT21', 'tr': 'WMT21 üçin Mininglamp Maşynyň terjime sistemi', 'af': 'Name', 'sq': 'Sistemi i Translacionit të Makinës Mininglamp për WMT21', 'am': 'መሀከል', 'bs': 'Mininglamp Machine Translation System for WMT21', 'az': 'Mininglamp Machine Translation System for WMT21', 'bn': 'WMT21- এর জন্য মিনিংল্যাম্বার মেশিন অনুবাদ সিস্টেম', 'hy': 'Աշխարհային Մինինգլամպի մեքենայի թարգմանման համակարգը', 'ca': 'The Mininglamp Machine Translation System for WMT21', 'cs': 'Strojový překlad Mininglamp pro WMT21', 'fi': 'Mininglamp Machine Translation System for WMT21', 'et': 'Mininglamp masintõlke süsteem WMT21 jaoks', 'jv': 'Name', 'sk': 'Sistem strojnega prevajanja Mininglamp za WMT21', 'he': 'מערכת ההתרשמות של מכונת Mininglamp עבור WMT21', 'ha': 'Translate system for WMT21', 'bo': 'The Mininglamp Machine Translation System for WMT21'}
{'en': 'This paper describes Mininglamp neural machine translation systems of the WMT2021 news translation tasks. We have participated in eight directions translation tasks for news text including ', 'pt': 'Este artigo descreve os sistemas de tradução automática neural Mininglamp das tarefas de tradução de notícias WMT2021. Participamos de oito tarefas de tradução de textos de notícias, incluindo chinês para/do inglês, hausa para/do inglês, alemão para/do inglês e francês para/do alemão. Nosso sistema fundamental foi baseado na arquitetura Transformer, com construção mais ampla ou menor para diferentes tarefas de tradução de notícias. Utilizamos principalmente o método de retrotradução, destilação de conhecimento e ajuste fino para impulsionar o modelo único, enquanto o ensemble foi usado para combinar modelos únicos. Nossa submissão final ficou em primeiro lugar na tarefa de inglês de/para Hausa.', 'ar': 'تصف هذه الورقة أنظمة الترجمة الآلية العصبية Mininglamp لمهام ترجمة الأخبار WMT2021. لقد شاركنا في ثمانية مهام ترجمة نصوص الأخبار بما في ذلك الصينية من / إلى الإنجليزية ، الهوسا إلى / من الإنجليزية ، الألمانية إلى / من الإنجليزية والفرنسية إلى / من الألمانية. كان نظامنا الأساسي يعتمد على هندسة المحولات ، مع بناء أوسع أو أصغر لمهام ترجمة الأخبار المختلفة. استخدمنا بشكل أساسي طريقة الترجمة العكسية وتقطير المعرفة والضبط الدقيق لتعزيز نموذج واحد ، بينما تم استخدام المجموعة لدمج النماذج الفردية. احتل تقديمنا النهائي المرتبة الأولى في مهمة اللغة الإنجليزية إلى / من الهوسا.', 'es': 'Este artículo describe los sistemas de traducción automática neuronal Mininglamp de las tareas de traducción de noticias del WMT2021. Hemos participado en tareas de traducción de ocho direcciones para textos de noticias, incluidos el chino a/desde el inglés, el hausa a/desde el inglés, el alemán a/desde el inglés y el francés a/desde el alemán. Nuestro sistema fundamental se basaba en la arquitectura Transformer, con una construcción más amplia o más pequeña para diferentes tareas de traducción de noticias. Utilizamos principalmente el método de retrotraducción, destilación de conocimientos y ajuste fino para impulsar el modelo único, mientras que el conjunto se utilizó para combinar modelos individuales. Nuestra presentación final ocupó el primer lugar para la tarea de inglés a/desde hausa.', 'fr': "Cet article décrit les systèmes de traduction automatique neuronale Mininglamp des tâches de traduction de nouvelles du WMT2021. Nous avons participé à huit tâches de traduction de directions pour le texte d'actualités, y compris le chinois vers/depuis l'anglais, le haoussa vers/depuis l'anglais, l'allemand vers/depuis l'anglais et Notre système fondamental était basé sur l'architecture Transformer, avec une construction plus ou moins grande pour différentes tâches de traduction d'actualités. Nous avons principalement utilisé la méthode de rétro-traduction, de distillation des connaissances et de réglage fin pour stimuler un modèle unique, tandis que l'ensemble a été utilisé pour combiner des modèles uniques. Notre soumission finale s'est classée première pour la tâche de l'anglais vers/depuis le haoussa.", 'ja': '本稿では、WMT 2021ニュース翻訳タスクのマイニングランプニューラル機械翻訳システムについて説明する。私たちは、中国語から英語へ、ハウサ語から英語へ、ドイツ語から英語へ、フランス語からドイツ語へなど、ニューステキストの8つの方向翻訳タスクに参加しています。当社の基本的なシステムは、トランスフォーマーのアーキテクチャに基づいており、さまざまなニュース翻訳タスクのための幅広いまたは小さな構造を備えていました。主にバックトランスレーション、ナレッジ蒸留、微調整の方法を活用してシングルモデルをブーストし、アンサンブルはシングルモデルを組み合わせて使用しました。私たちの最終提案は、Hausaタスクの英語とフランス語の間で1位になりました。', 'zh': '本文言WMT2021新闻翻译事Mininglamp神经机器翻译统。 参以八新闻文本之译,中文与英语、豪萨语与英语、德语、英语之际,法语德语之际。 本乎Transformer架构,新闻译之务,宽小之构。 凡反译、知识、微调之法,以升单模,而融合则合之。 终于英语往返豪萨语第一。', 'hi': 'यह पेपर WMT2021 समाचार अनुवाद कार्यों के माइनिंगलैंप न्यूरल मशीन अनुवाद प्रणालियों का वर्णन करता है। हमने समाचार पाठ के लिए आठ दिशाओं के अनुवाद कार्यों में भाग लिया है, जिसमें चीनी से / अंग्रेजी, हौसा से / अंग्रेजी, जर्मन से / अंग्रेजी और फ्रेंच से / जर्मन से शामिल हैं। हमारी मौलिक प्रणाली ट्रांसफॉर्मर आर्किटेक्चर पर आधारित थी, जिसमें विभिन्न समाचार अनुवाद कार्यों के लिए व्यापक या छोटे निर्माण थे। हमने मुख्य रूप से एकल मॉडल को बढ़ावा देने के लिए बैक-ट्रांसलेशन, ज्ञान आसवन और फाइन-ट्यूनिंग की विधि का उपयोग किया, जबकि पहनावा का उपयोग एकल मॉडल को संयोजित करने के लिए किया गया था। हमारे अंतिम सबमिशन ने हौसा कार्य से / से अंग्रेजी के लिए पहले स्थान पर रखा है।', 'ru': 'Эта статья описывает системы нейронного машинного перевода Mininglamp задач перевода новостей WMT2021. Мы приняли участие в восьми направлениях перевода текста новостей, включая китайский на/с английского, хауса на/с английского, немецкий на/с английского и французский на/с немецкий. Наша фундаментальная система была основана на архитектуре трансформаторов, с более широкой или меньшей конструкцией для различных задач перевода новостей. Мы в основном использовали метод обратного перевода, дистилляции знаний и тонкой настройки для повышения одиночной модели, в то время как ансамбль использовался для объединения одиночных моделей. Наша финальная заявка заняла первое место в задании «Английский язык в Хаусу/из Хаусы».', 'ga': 'Déanann an páipéar seo cur síos ar chórais nóral aistriúcháin Mininglamp de thascanna aistriúcháin nuachta WMT2021. Ghlacamar páirt in ocht gcinn de thascanna aistrithe treo do théacs nuachta lena n-áirítear Sínis go/ó Bhéarla, Hausa go/ó Bhéarla, Gearmáinis go/ó Bhéarla agus Fraincis go/ón nGearmáinis. Bhí ár gcóras bunúsach bunaithe ar ailtireacht Transformer, le tógáil níos leithne nó níos lú le haghaidh tascanna éagsúla aistriúcháin nuachta. Bhaineamar úsáid go príomha as an modh cúlaistriúcháin, driogadh eolais agus mionchoigeartaithe chun múnla aonair a threisiú, agus úsáideadh an ensemble chun samhlacha aonair a chur le chéile. Tá ár n-aighneacht deiridh sa chéad áit don tasc Béarla go dtí/ó Hausa.', 'ka': 'Name ჩვენ ახლა ახალგაზრულების ტექსტის გადაწყვეტილი 8 მიერ დაწყვეტილი დავამწევეთ, რომელიც ჩინგლისგან/ანგლისგან, ჰოსადან/ანგლისგან, გერმანეთიდან/ანგლისგან ჩვენი ფუნდამენტური სისტემა ტრანფორმენტერის აქტიქტიქტურის დაბაზეულია, რომელიც უფრო დიდი ან ცოტა კონფიგურაცია განსხვავებული ნუ ჩვენ ძირითად გამოყენებულეთ პროგრამის გამოყენება, ცნობილის დისტლილაცია და კონფიგურაცია, როგორც ერთი მოდელის გამოყენება, როცა ინსენბლის გამოყენება ერთი მოდელის გამოყ ნაქარა ოჲჟლვენა ოპვეჟრაგა ჱა ანდლთჟკთრვ თ ჲრ ჳჲსჟა პაბჲრა.', 'el': 'Η παρούσα εργασία περιγράφει τα νευρωνικά συστήματα μηχανικής μετάφρασης των εργασιών μετάφρασης ειδήσεων. Έχουμε συμμετάσχει σε εργασίες μετάφρασης οκτώ κατευθύνσεων για κείμενα ειδήσεων, συμπεριλαμβανομένων των κινεζικών προς/από τα αγγλικά, των Hausa προς/από τα αγγλικά, των γερμανικών προς/από τα αγγλικά και των γαλλικών προς/από τα γερμανικά. Το βασικό μας σύστημα βασίστηκε στην αρχιτεκτονική με ευρύτερη ή μικρότερη κατασκευή για διαφορετικές εργασίες μετάφρασης ειδήσεων. Χρησιμοποιήσαμε κυρίως τη μέθοδο της αντίστροφης μετάφρασης, απόσταξης γνώσης και συντονισμού για να ενισχύσουμε το ενιαίο μοντέλο, ενώ το σύνολο χρησιμοποιήθηκε για να συνδυάσουμε μεμονωμένα μοντέλα. Η τελική μας υποβολή κατατάχθηκε πρώτη για την εργασία των Αγγλικών προς/από Χάουζα.', 'it': "Questo articolo descrive i sistemi di traduzione automatica neurale Mininglamp dei compiti di traduzione delle notizie WMT2011. Abbiamo partecipato a otto attività di traduzione di testi di notizie tra cui cinese a/dall'inglese, hausa a/dall'inglese, tedesco a/dall'inglese e francese a/dal tedesco. Il nostro sistema fondamentale era basato sull'architettura Transformer, con una costruzione più ampia o più piccola per diversi compiti di traduzione di notizie. Abbiamo utilizzato principalmente il metodo di back-translation, distillazione della conoscenza e messa a punto per aumentare il modello singolo, mentre l'ensemble è stato utilizzato per combinare modelli singoli. La nostra presentazione finale si è classificata al primo posto per il compito inglese a/da Hausa.", 'hu': 'Ez a tanulmány bemutatja a Mininglamp neurális gépi fordítási rendszereit a WMT2011 hírfordítási feladatokhoz. Nyolc irányban vettünk részt hírszöveg fordításában, beleértve a kínai angolról/angolról, Hausa angolról/angolról, németről/angolról és franciáról/németről. Alapvető rendszerünk a Transformer architektúrán alapult, szélesebb vagy kisebb felépítéssel különböző hírfordítási feladatokhoz. Elsősorban a visszafordítás, a tudás desztilláció és a finomhangolás módszerét használtuk az egyes modellek fellendítésére, míg az együttes az egyes modellek kombinációjára használt. A végső pályázatunk az első helyen állt az angol és Hausa közötti feladat tekintetében.', 'kk': 'Бұл қағаз WMT2021 жаңалық аудару тапсырмаларының Mininglamp невралдық компьютерді аудару жүйелерін анықтайды. Name Біз жаңалықтар мәтінінің 8 бағыттарына қатысу тапсырмаларына қатысу келдік: Қытай тілінен/ағылшын тілінен/ағылшын тілінен/ағылшын тілінен/ағылшын тілінен/францу Біздің негізгі жүйеміз түрлендіру архитектурасына негізделген. Басқа жаңалық аудару тапсырмаларының үлкен немесе кішкентай құрылымыз. Біз негізінде қайта аудару, білім дистилляциясын және жалғыз үлгілерді көтеру үшін қолданатын әдістерді қолдандық, бір үлгілерді біріктіру үшін қолданылады. Біздің соңғы жіберіміз біріншіден ағылшын тілдеріне Хауса тапсырмасынан/тілдеріне сәйкес келді.', 'mk': 'This paper describes Mininglamp neural machine translation systems of the WMT2021 news translation tasks.  Ние учествувавме во осум насоки на преводни задачи за вести текст вклучувајќи кинески до/од англиски, хауса до/од англиски, германски до/од англиски и француски до/од германски. Нашиот фундаментален систем беше базиран на трансформена архитектура, со поширока или помала изградба за различни задачи за превод на вести. Главно го искористивме методот на превод, дистилација на знаење и фино прилагодување за поттикнување на еден модел, додека ансемблот беше искористен за комбинација на еден модел. Нашето последно поднесување е рангирано прво за англиските од/од Хауса задача.', 'ms': 'Kertas ini menggambarkan sistem terjemahan mesin saraf Mininglamp bagi tugas terjemahan berita WMT2021. Kami telah berpartisipasi dalam lapan arah tugas terjemahan untuk teks berita termasuk Cina ke/dari Inggeris, Hausa ke/dari Inggeris, Jerman ke/dari Inggeris dan Perancis ke/dari Jerman. Our fundamental system was based on Transformer architecture, with wider or smaller construction for different news translation tasks.  Kami terutama menggunakan kaedah terjemahan-belakang, pengusiran pengetahuan dan penyesuaian untuk meningkatkan model tunggal, sementara ensemble digunakan untuk menggabungkan model tunggal. Pemberian terakhir kami telah berturut-turut pertama untuk orang Inggeris ke/dari Hausa tugas.', 'lt': 'Šiame dokumente aprašomos WMT2021 naujienų vertimo užduočių Mininglamp nervinių mašinų vertimo sistemos. Dalyvavome aštuonių krypčių vertimo darbuose naujienų tekstui, įskaitant kinų tekstą anglų kalba (anglų kalba), Hausa anglų kalba (anglų kalba), vokiečių kalba (anglų kalba) ir prancūzų kalba (vokiečių kalba). Mūsų pagrindinė sistema buvo grindžiama Transformer architektūra, kurioje buvo platesnė ar mažesnė įvairių žinių vertimo užduočių statyba. Mes daugiausia panaudojome atgalinio vertimo, žinių distiliavimo ir patobulinimo metodą, kad paskatintume vieną model į, o komplektas buvo naudojamas vieniems modeliams derinti. Mūsų galutinis pranešimas buvo pirmasis anglų kalbos ir (arba) iš Hausos užduoties klausimas.', 'ml': 'ഈ പത്രത്തില്\u200d മിനിങ്ങില്\u200dലാന്\u200dഡ് ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ സിസ്റ്റം WMT2021 വാര്\u200dത്ത വിവരങ്ങളുടെ വിവരങ്ങള്\u200d വ ഞങ്ങള്\u200d എട്ടു ദിശങ്ങളില്\u200d പങ്കുചേര്\u200dന്നിരിക്കുന്നു. ചൈനീസിലേക്ക്/ഇംഗ്ലീഷിലേക്ക്/ഇംഗ്ലീഷിലേക്ക്/ഇംഗ്ലീഷിലേ നമ്മുടെ അടിസ്ഥാനമായ സിസ്റ്റം വ്യത്യസ്ത വാര്\u200dത്ത വിവരങ്ങളുടെ പരിഭാഷയ്ക്ക് വേണ്ടി വികസിക്കുന്ന പണിയുമായി  നമ്മള്\u200d പ്രധാനപ്പെട്ട പിന്നിലെ പരിഭാഷത്തിന്റെ രീതിയില്\u200d ഉപയോഗിച്ചു, അറിവ് വേര്\u200dതിരിക്കുന്നതും നല്ല മോഡലിനെ ഉയര്\u200dത്തുന്നതും മ ഞങ്ങളുടെ അവസാന സമ്മാനം ആദ്യം ഇംഗ്ലീഷിലേക്ക്/ഹൌസാ ജോലിയിലേക്ക് വേണ്ടിയാണ്.', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tat-traduzzjoni tal-magni newrali Mininglamp tal-kompiti tat-traduzzjoni tal-aħbarijiet WMT2021. Parteċipajna f’tmien direzzjonijiet kompiti ta’ traduzzjoni għal test tal-aħbarijiet inklużi ċ-Ċiniżi għal/mill-Ingliż, Hausa għal/mill-Ingliż, il-Ġermaniż għal/mill-Ingliż u l-Franċiż għal/mill-Ġermaniż. Is-sistema fundamentali tagħna kienet ibbażata fuq arkitettura Transformer, b’kostruzzjoni usa’ jew iżgħar għal kompiti differenti ta’ traduzzjoni tal-aħbarijiet. We mainly utilized the method of back-translation, knowledge distillation and fine-tuning to boost single model, while the ensemble was used to combine single models.  Is-sottomissjoni finali tagħna kklassifikat l-ewwel għall-kompitu Ingliż għal/minn Hausa.', 'mn': 'Энэ цаас WMT2021 мэдээллийн хөгжүүлэх даалгаварын Mininglamp мэдрэлийн мэдрэлийн машин хөгжүүлэх системийг тайлбарладаг. Бид Хятад, Англи, Хауса, Англи, Герман, Англи, Француз, Герман хүртэл/Герман хүртэл холбогдсон мэдээллийн текстүүд дээр найм хэсэгт оролцож байгаа юм. Бидний үндсэн систем Трансфер архитектур дээр суурилсан. Трансфер архитектур нь олон мэдээллийн хөгжлийн даалгаварын өргөн эсвэл жижиг бүтээлтэй. Бид ерөнхийдөө нэг загварыг дэмжихийн тулд эргээд орчуулах, мэдлэг сайжруулах, сайжруулах арга загварыг ашиглаж байсан. Бидний сүүлийн давтамж анх Англи хэлний хаусан ажлын төлөө хаусан.', 'no': 'Denne papiret skildrar Mininglamp neural machine translation systems for WMT2021 news translation tasks. Vi har delta i åtte retningar omsetjingsprogrammer for nyhetstekst inkludert kinesisk til/frå engelsk, Hausa til/frå engelsk, tysk til/frå engelsk og fransk til/frå tysk. Grunnleggjande systemet vårt var basert på Transformeringsarkitektur, med breidde eller mindre konstruksjon for ulike nyhetsgrensesoppgåver. Vi brukte hovudsakelig metoden for tilbakeomsetjing, kunnskapsdistillasjon og finnstilling for å styra enkelt modell, mens det var brukt for å kombinere enkelte modeller. Det siste opplysningen vårt har første rangert for engelske til/frå Hausa-oppgåva.', 'pl': 'Niniejszy artykuł opisuje neuronowe systemy tłumaczenia maszynowego Mininglamp dla zadań tłumaczenia wiadomości WMT2028. Uczestniczyliśmy w ośmiu kierunkach tłumaczenia tekstów wiadomości, w tym chińskiego na/z angielskiego, Hausa na/z angielskiego, niemieckiego na/z angielskiego i francuskiego na/z niemieckiego. Nasz fundamentalny system opierał się na architekturze Transformera, z szerszą lub mniejszą konstrukcją do różnych zadań tłumaczenia wiadomości. Wykorzystaliśmy głównie metodę backtranslacji, destylacji wiedzy i dostrajania, aby zwiększyć pojedynczy model, podczas gdy zespół został wykorzystany do łączenia pojedynczych modeli. Nasza ostateczna zgłoszenie zajęła się pierwszym miejscem dla zadania z angielskiego do/z Hausa.', 'ro': 'Această lucrare descrie sistemele de traducere automată neurală Mininglamp ale sarcinilor de traducere a știrilor WMT201. Am participat în opt direcții de traducere a textelor de știri, inclusiv chineză în/din engleză, hausa în/din engleză, germană în/din engleză și franceză în/din germană. Sistemul nostru fundamental a fost bazat pe arhitectura Transformer, cu construcție mai largă sau mai mică pentru diferite sarcini de traducere a știrilor. Am folosit în principal metoda de back-translation, distilarea cunoștințelor și reglarea fină pentru a stimula modelul unic, în timp ce ansamblul a fost folosit pentru a combina modele unice. Trimiterea noastră finală s-a clasat pe primul loc pentru sarcina engleză la/de la Hausa.', 'si': 'මේ පැත්තේ මිනින්ග්ලෑම්ප් න්\u200dයුරලෑම් මැෂින් වාර්තා පද්ධතියේ WMT2021 වාර්තා වාර්තා වාර්තාව අපි අංග්\u200dරීසියෙන්/ඉංග්\u200dරීසියෙන්, ජර්මානියෙන්/ඉංග්\u200dරීසියෙන්/ෆ්\u200dරෑන්සියාන්/ජර්මානියෙන්/ඉංග්\u200dර අපේ පද්ධතිය පද්ධතිය වෙනස් විවිධ වාර්තාවක් විසින් විවිධ වාර්තාවක් සඳහා විසින් විසින් විසින අපි ප්\u200dරධානයෙන් පිටිපස්සේ වාර්තාව, දන්නවන් විශේෂණය සහ හොඳ ප්\u200dරධානයක් භාවිත කරන්න ප්\u200dරයෝජනය කරලා තියෙන්නේ, එකම අපේ අන්තිම පිළිගන්න පුළුවන් ඉංග්\u200dරීසියාට හෝසා වැඩේ ඉඳන් ඉංග්\u200dරීසියාවෙන්.', 'so': 'Warqadan waxaa lagu qoraa Mininglamp neural machine translation systems of the WMT2021 news translation tasks. Waxaannu ka qeybqaadanay siddeed kooxood oo lagu turjumo warqada warqada warqada, kuwaas oo ah Shiino-ka/Ingiriis, Hausa-ka Ingiriis, Jarmal-ka/Ingiriis iyo Faraansiis-ka/Jarmal. nidaamkayaga aasaasiga ah waxay ku saleysan tahay dhismo turjuman, dhismo ballaadhan ama wax yar oo lagu sameyn karo shaqooyinka warbixinta kala duduwan. ugu horeyna waxaynu isticmaalnay qaababka turjumidda dib-u-dhigidda, aqoonta kala duwan iyo si fiican u kordhin tusaale kaliya, marka loo isticmaalay hal qaab keliya. Our final submission has ranked first for the English to/from Hausa task.', 'sv': 'Denna uppsats beskriver Mininglamps neurala maskin철vers채ttningssystem f철r WMT201s nyhets철vers채ttningsuppgifter. Vi har deltagit i 책tta 철vers채ttningsuppgifter f철r nyhetstexter inklusive kinesiska till/fr책n engelska, Hausa till/fr책n engelska, tyska till/fr책n engelska och franska till/fr책n tyska. V책rt grundl채ggande system byggde p책 Transformer-arkitektur, med bredare eller mindre konstruktion f철r olika nyhets철vers채ttningsuppgifter. Vi anv채nde fr채mst metoden f철r bak책t철vers채ttning, kunskapsdestillation och finjustering f철r att boosta enstaka modell, medan ensemblen anv채ndes f철r att kombinera enstaka modeller. V책rt slutliga bidrag har rankats f철rst f철r engelska till/fr책n Hausa uppgiften.', 'sr': 'Ovaj papir opisuje sisteme prevoda neuroloških mašina Mininglampa WMT2021 novinskih prevodnih zadataka. Mi smo sudjelovali u osam uputstva prevođenih zadataka za tekst vesti uključujući kineski na/od engleskog, Hausa na/od engleskog, njemačkog na/od engleskog i francuskog na/od njemačkog. Naš osnovni sistem je baziran na transformerskoj arhitekturi, sa širom ili manjom izgradnjom za različite novinske prevodne zadatke. Koristili smo uglavnom metodu prevoda pozadine, destilacije znanja i dobre prilagodbe za jačanje jednog modela, dok je ensembla korišćena za kombinaciju jednog modela. Naša poslednja podnošenja je prva za engleski do/iz Hausa zadatka.', 'ta': 'WMT2021 செய்தி மொழிபெயர்ப்பு பணிகளின் மினிங்லாண்ட் புதிய இயந்திரம் மொழிபெயர்ப்பு அமைப்புகளை விளக்கு நாங்கள் சீன செய்தி உரைக்கான எட்டு திசைகள் மொழிபெயர்ப்பு பணிகளில் பகிர்ந்து செய்திருக்கிறோம், ஆங்கிலத்திலிருந்து ஹாயுசா எங்கள் அடிப்படை அமைப்பு மாற்றும் அடிப்படையில் உள்ளது, வித்தியாசமான செய்தி மொழிபெயர்ப்பு பணிகளுக்கு விரிவாக அல் We mainly utilized the method of back-translation, knowledge distillation and fine-tuning to boost single model, while the ensemble was used to combine single models.  எங்கள் இறுதியாக ஒப்பு முதலில் ஆங்கிலத்திற்கு /ஹாusa வேலையிலிருந்து முதலில் உள்ளது.', 'ur': 'یہ کاغذ WMT2021 نویس ترجمہ کے کاموں کی مینینگ لامپ نیورل ماشین ترجمہ سیسٹم کی توصیف کرتا ہے. ہم نے آٹھ طریقے کی ترجمہ کے کاموں میں شامل ہوا ہے جو چینی اور انگلیسی سے، ہاوسا اور/انگلیسی سے، جرمانی اور انگلیسی اور فرانسوی سے اور/جرمانی سے شامل ہوتے ہیں. ہماری بنیادی سیسٹم ٹرنفسر معماری پر بنیاد ہے، مختلف نویس ترجمہ کے کاموں کے لئے بہت وسیع یا چھوٹی ساختار کے ساتھ۔ ہم نے اکثر پیچھے ترجمہ، علم الٹیسمل اور نیک ترونگ کا طریقہ استعمال کیا تھا کہ ایک موڈل کو اضافہ کرنے کے لئے، حالانکہ انسمبل ایک موڈل کو ترکیب کرنے کے لئے استعمال کیا گیا تھا. ہماری آخری مسلمانیت پہلے انگلیسی کے لئے ہوسا کا کام ہے۔', 'vi': 'Tờ giấy này mô tả các hệ thống dịch chuyển máy thần kinh khai thác của các công việc dịch chuyển tin WM2- 1. Chúng tôi đã tham gia vào tám hướng dịch vụ văn bản tin tức, kể cả Trung Quốc đến/ từ Anh, Hausa đến/ từ Anh, Đức đến/ từ Anh và Pháp đến/ từ Đức. Hệ thống cơ bản của chúng tôi dựa trên kiến trúc biến áp, với cấu trúc rộng lớn hoặc nhỏ hơn cho các công việc dịch chuyển tin khác nhau. Chúng tôi sử dụng chủ yếu phương pháp dịch ngược, chưng cất kiến thức và độ chín để tăng cường mô hình đơn, trong khi dàn nhạc được dùng để kết hợp mô hình đơn. Việc đệ trình cuối cùng của chúng tôi được xếp hạng đầu tiên cho nhiệm vụ ám sát:', 'uz': "Bu qogʻoz Mininglamp neural machine tarjima tizimlarini WMT2021 News translation vazifalarini anglatadi. Biz Xitoycha dan/inglizcha, Hausadan/Inglizchadan, Olmonchadan/Inglizchadan/Olmonchadan/Inglizchadan/Inglizchadan/Fransuzdan/Fransuzchadan/Olmonchadan 8 ta ta ta tarjima vazifalarga ega bo'lgan. Bizning asosiy tizimmiz Transformer architektorga asoslangan edi va har xil yangilik tarjima vazifalari uchun katta yoki kichkina yaratilgan edi. Biz oddiy tarjima qilish, aniqlarni ajratish va yaxshi bir modelni ko'paytirish usulini ishlatdik, ammo uning bir modelini birlashtirish uchun foydalanadi. Bizning oxirgi muzlatmiz ingliz tildan/Hausadan birinchi vazifa bo'lgan.", 'bg': 'Настоящата статия описва системите за невронен машинен превод на задачите за превод на новини. Участвали сме в осем направления превод на новинарски текстове, включително китайски на/от английски, хауса на/от английски, немски на/от английски и френски на/от немски. Нашата фундаментална система беше базирана на архитектурата на трансформатора, с по-широка или по-малка конструкция за различни задачи по превод на новини. Използвахме основно метода на обратен превод, дестилация на знанието и фина настройка за стимулиране на единичния модел, докато ансамбълът беше използван за комбиниране на единични модели. Окончателното ни представяне се класира на първо място в задачата по английски до/от Хауса.', 'de': 'Diese Arbeit beschreibt Mininglamp neuronale maschinelle ﾃ彙ersetzungssysteme der WMT2028 Nachrichtenﾃｼbersetzungsaufgaben. Wir haben an acht ﾃ彙ersetzungsaufgaben fﾃｼr Nachrichtentexte teilgenommen, darunter Chinesisch in/von Englisch, Hausa in/von Englisch, Deutsch in/von Englisch und Franzﾃｶsisch in/von Deutsch. Unser grundlegendes System basierte auf der Transformer-Architektur, mit breiterer oder kleinerer Konstruktion fﾃｼr verschiedene Nachrichtenﾃｼbersetzungsaufgaben. Wir nutzten hauptsﾃ､chlich die Methode der Rﾃｼckﾃｼbersetzung, Wissensdestillation und Feinabstimmung, um einzelne Modelle zu steigern, wﾃ､hrend das Ensemble verwendet wurde, um einzelne Modelle zu kombinieren. Unsere endgﾃｼltige Einreichung hat den ersten Platz fﾃｼr die Aufgabe Englisch zu/von Hausa belegt.', 'nl': 'Dit artikel beschrijft Mininglamp neurale machine translation systemen van de WMT2028 nieuwsovertelling taken. We hebben deelgenomen aan acht richtingen vertaaltaken voor nieuwsteksten, waaronder Chinees naar/van Engels, Hausa naar/van Engels, Duits naar/van Engels en Frans naar/van Duits. Ons fundamentele systeem was gebaseerd op Transformer architectuur, met bredere of kleinere constructie voor verschillende vertaaltaken van nieuws. We gebruikten voornamelijk de methode van back-translation, kennisdestillatie en fine-tuning om een enkel model te stimuleren, terwijl het ensemble werd gebruikt om enkele modellen te combineren. Onze uiteindelijke inzending staat op de eerste plaats voor de Engelse naar/van Hausa taak.', 'hr': 'Ovaj papir opisuje sustave prevoda neuroloških strojeva Mininglampa za prijevod WMT2021. Učestvovali smo u osam smjernica prevodne zadatke za tekst vijesti uključujući kineski na/od engleskog, Hausa na/od engleskog, njemačkog na/od engleskog i francuskog na/od njemačkog. Naš osnovni sustav je temeljen na građevini Transformera, sa širom ili manjim građevinom za različite novinske prevodne zadatke. Koristili smo uglavnom metodu prevoda pozadine, destilacije znanja i dobre prilagodbe za jačanje jednog modela, dok je ensembl korišten za kombinaciju jednog modela. Naša posljednja podnošenja je prva postavljena za engleski do/iz Hausa zadatka.', 'da': 'Denne artikel beskriver Mininglamps neurale maskinoversættelsessystemer for WMT201nyhedsoversættelsesopgaverne. Vi har deltaget i otte retningsoversættelsesopgaver for nyhedstekst, herunder kinesisk til/fra engelsk, Hausa til/fra engelsk, tysk til/fra engelsk og fransk til/fra tysk. Vores grundlæggende system var baseret på Transformer arkitektur, med bredere eller mindre konstruktion til forskellige nyhedsoversættelsesopgaver. Vi brugte hovedsageligt metoden til back-translation, viden destillation og finjustering for at booste single model, mens ensemblet blev brugt til at kombinere single modeller. Vores endelige indsendelse har rangeret første for den engelske til/fra Hausa opgave.', 'sw': 'Makala hii inaelezea mfumo wa utafsiri wa mashine ya ubongo wa Mininglamp wa kazi za tafsiri za habari za WMT2021. Tumeshiriki kazi za kutafsiri kwa njia nane za habari ikiwa ni pamoja na Kichina hadi/kutoka Kiingereza, Hausa hadi/kutoka Kiingereza, Kijerumani hadi/kutoka Kiingereza na Kifaransa hadi/kutoka Ujerumani. Mfumo wetu wa msingi ulitokana na ujenzi wa Transformer, na ujenzi mdogo au mdogo kwa ajili ya kazi za kutafsiri habari tofauti. Kwa ujumla tulitumia njia ya kutafsiri kwa upande wa nyuma, utofauti wa maarifa na kutangaza vizuri kwa ajili ya kukuza muundo mmoja, wakati mfumo huo ulitumiwa kuunganisha mifano moja. Ujumbe wetu wa mwisho umekuwa wa kwanza kwa ajili ya Kiingereza hadi/kutoka kazi ya Hausa.', 'id': 'Kertas ini menjelaskan sistem terjemahan mesin saraf Mininglamp dari tugas terjemahan berita WMT2021. Kami telah berpartisipasi dalam delapan arah tugas terjemahan untuk teks berita termasuk Cina ke/dari Inggris, Hausa ke/dari Inggris, Jerman ke/dari Inggris dan Perancis ke/dari Jerman. Our fundamental system was based on Transformer architecture, with wider or smaller construction for different news translation tasks.  We mainly utilized the method of back-translation, knowledge distillation and fine-tuning to boost single model, while the ensemble was used to combine single models.  Pengiriman terakhir kami telah berturut-turut pertama untuk Bahasa Inggris ke/dari Hausa tugas.', 'ko': '본고는 WMT2021 뉴스 번역 임무의 Mininglamp 신경 기계 번역 시스템을 묘사한다.우리는 중국어에서/영어, 호사에서/영어, 독일어부터/영어, 프랑스어부터/독일어까지 8개 방향의 뉴스 텍스트 번역 임무에 참여했다.우리의 기본 시스템은Transformer 구조를 바탕으로 서로 다른 뉴스 번역 임무에 대해 더욱 넓거나 작은 구조를 가진다.우리는 주로 반역, 지식 추출과 미세한 조정 방법을 채택하여 단일 모델을 향상시키고 집적은 단일 모델을 조합하는 데 사용한다.우리가 최종적으로 제출한 자료는 영국 왕복 호사 임무 중 1위를 차지했다.', 'fa': 'این کاغذ سیستم ترجمه\u200cهای ماشین عصبی مینینگ لامپ را توصیف می\u200cکند از کار ترجمه\u200cهای خبری WMT2021. ما در هشت تاریخ ترجمه برای متن اخبار، شامل چینی به/از انگلیسی، هاوسا به/از انگلیسی، آلمانی به/از انگلیسی و فرانسوی به/از آلمانی شرکت کردیم. سیستم بنیادی ما بر اساس معماری تغییر دهنده، با ساختمان گسترده یا کوچکتر برای کار های تغییر دهنده های خبری متفاوت بود. ما در اصل روش ترجمه پشتی، تفاوت دانش و تنظیم نیکویی را برای افزایش یک مدل استفاده کردیم، در حالی که انتشار برای ترجمه یک مدل استفاده شد. آخرین تسلیم ما اول برای کارهای انگلیسی به هاوسا درجه گرفته است.', 'tr': 'Bu kagyz WMT2021 täzelikler täzelikleriniň Mininglamp näural maşynyň terjime sistemlerini tassyýar. Biz täzelikler üçin täzelikler üçin sekiz yönelik täzeliklerde, hyt dilinden/iňlisçe, Hausa dilinden/iňlisçe, iňlisçe we fransuzça-da/nemesçe olara dahil etdik. Biziň esasy sistemimiz Transformer arhitektegi ýaly daşary ýa-da kiçiräk täzelikler üçin beýleki täzelikler üçin daşary edildi. Biz adatça arka terjime etmek, bilgi taýýarlamanyň we ýekeje nusgasyny bejermek üçin ullanýardyk we ensemble tek nusgasyny birleştirmek üçin ullanýardyk. Biziň soňky teslimatymyz iňlisçe hem Hausa işi üçin ilkinji gezek gabat geldi.', 'hy': 'Այս հոդվածը նկարագրում է "Ինինգլամպ" նյարդային մեքենայի թարգմանման համակարգերը, որոնք պատկանում են ԱՄԹ2021 նորությունների թարգմանման խնդիրներին: Մենք մասնակցել ենք ութ ուղղություններում նորությունների տեքստի թարգմանման խնդիրներին, ներառյալ չինական տեքստից անգլերենից, Հաուզայից անգլերենից, գերմաներենից անգլերենից և ֆրանսերենից գերմաներենից: Մեր հիմնարար համակարգը հիմնված էր Թանֆերմերների ճարտարապետության վրա, որն ավելի լայն կամ ավելի փոքր է կառուցվում տարբեր նորությունների թարգմանման խնդիրների համար: Մենք հիմնականում օգտագործեցինք վերադարձ թարգմանման, գիտելիքների դիսլիլացիայի և բարձրացման մեթոդը մեկ մոդելի աճելու համար, մինչդեռ էնսբուլը օգտագործվում էր մեկ մոդելի համադրելու համար: Մեր վերջին ներկայացումը առաջինն է անգլերենների համար Հաուզայից:', 'af': 'Hierdie papier beskryf Mininglamp neural masjien vertaling stelsels van die WMT2021 nuusvertaling opdragte. Name Ons het gedeeld in agt rigtings vertaling opdragte vir nuutsteks, insluitend Sjinees tot/van Engels, Hausa tot/van Engels, Duits tot/van Engels en Frans tot/van Duits. Ons fundamentale stelsel was gebaseer op Transformer-arkitektuur, met breide of kleiner konstruksie vir verskillende nuusvertalingstaak. Ons het hoofsaaklik die metode van terug-vertaling, kennis-destilasie en fyn-tuning gebruik om enkele model te booster, terwyl die ensemble gebruik word om enkele modele te kombinerer. Ons eindelike ondersoek het eerste rangeer vir die Engels tot/van Hausa taak.', 'az': 'Bu kağıt WMT2021 xəbər çeviri işlərinin Mininglamp nöral maşın çeviri sistemlərini təsdiqləyir. Biz xəbərlər mətnlərinin səkkiz yönəlməsi ilə Çin, İngilizdən və İngilizdən və/İngilizdən və Fransızdan və/Almanlardan dahil olan xəbərlər mətnlərinə qarşılaşdıq. Bizim fundamental sistemimiz Transformer arhitektüsünə dayandı, müxtəlif xəbər çeviri işləri üçün daha geniş və daha kiçik inşaat. Biz ilk dəfə təkrar çevirilməsi, elm destilasyonu və təkrar-təkrar modelini artırmaq üçün istifadə etdik, çünki ensemble yalnız modelləri birləşdirmək üçün istifadə edildi. Bizim son müsəlmanımız ilk dərəcə İngilizə ilə Hausa işindən gəldi.', 'bs': 'Ovaj papir opisuje sisteme prevoda neuroloških strojeva Mininglampa WMT2021 novinskih prevodnih zadataka. Mi smo sudjelovali u osam smjernica prevođenim zadacima za novinski tekst uključujući kineski na/od engleskog, Hausa na/od engleskog, njemačkog na/od engleskog i francuskog na/od njemačkog. Naš osnovni sistem je baziran na arhitekturi Transformera, sa širom ili manjim izgradnjom za različite novinske prevodne zadatke. Koristili smo uglavnom metodu prevoda pozadine, destilacije znanja i dobre prilagodbe kako bi se pojačali jedan model, dok je ensembl korišten za kombinaciju pojedinih modela. Naša poslednja podnošenja je prva za engleski do/iz Hausa zadatka.', 'ca': "Aquest article descriu els sistemes de traducció neural Mininglamp de les tasques de traducció de notícies WMT2021. Hem participat en vuit direccions tasques de traducció de text de notícies, incloent xinès a/d'anglès, Hausa a/d'anglès, alemany a/d'anglès i francès a/d'alemany. Our fundamental system was based on Transformer architecture, with wider or smaller construction for different news translation tasks.  Vam utilitzar principalment el mètode de retrotraducció, destilació del coneixement i ajustament per impulsar un model únic, mentre l'ensemble va ser utilitzat per combinar models únics. La nostra presentació final s'ha classificat primer per als anglesos fins a Hausa.", 'sq': 'Kjo letër përshkruan sistemet e përkthimit të makinave nervore Mininglamp të detyrave të përkthimit të lajmeve WMT2021. Ne kemi marrë pjesë në tetë drejtime detyrat e përkthimit për tekstin e lajmeve duke përfshirë kinezën për/nga anglisht, Hausa për/nga anglisht, gjerman për/nga anglisht dhe francez për/nga gjerman. Sistemi ynë themelor ishte bazuar në arkitekturën e Transformer, me ndërtimin më të gjerë apo më të vogël për detyra të ndryshme përkthimi të lajmeve. Ne përdorëm kryesisht metodën e përkthimit mbrapa, distillacionit të njohurive dhe rregullimit të hollësishëm për të nxitur modelin e vetëm, ndërsa ansambli përdorej për të kombinuar modele të vetme. Përdorimi ynë përfundimtar është renditur i pari për Anglezët në/nga detyra Hausa.', 'am': 'ይህ ፕሮግራም ሚኒንግlamp የናቡራል መሣሪያን ትርጓሜ ሲስተም WMT2021 የዜና ትርጉም ስራዎችን ይገልጻል፡፡ ከቻይና ጀምሮ ኢንጂልኛ፣ ሀusa ጀምሮ እንግሊዘኛ፣ ጀርመን ጀምሮ ጀምሮ ጀምሮ ጀርመን እስከ ፈረንሳይ/ጀምሮ እስከ ጀርመን ድረስ ለዜና ጽሑፍ ትርጉም ሥራ ስምንት መንገዶች ተጋርተናል፡፡ መሠረት ስርዓታችን በተለየ የዜና ትርጓሜ ስርዓት ላይ የተሰፋና ወይም ትንሹ የተመሠረተ መሠረት ነው፡፡ አብዛኛውም የኋላ ትርጉም፣ እውቀት ትርጉም እና ጥሩ ሞዴል ለመያበዛት የተጠቀሰን እና ምሳሌ ተጠቃሚ ነበር፡፡ የኋለኛው መልዕክታችን ለመጀመሪያ እንግሊዘኛ ወደ ሀሱስ ስራ መረጠ፡፡', 'et': 'Käesolev töö kirjeldab Mininglampi neuromasintõlkesüsteeme WMT22021 uudiste tõlkimise ülesannete kohta. Oleme osalenud uudiste tõlkimisel kaheksas suunas, sealhulgas hiina keelest inglise keelde, Hausa keelest inglise keelde, saksa keelest inglise keelde ja prantsuse keelest saksa keelde. Meie põhisüsteem põhines Transformer arhitektuuril, laiema või väiksema konstruktsiooniga erinevate uudiste tõlkimise ülesannete jaoks. Ühe mudeli tõstmiseks kasutasime peamiselt tagasitõlke, teadmiste destilleerimise ja peenhäälestuse meetodit, samas kui ansamblit kasutati ühe mudeli kombineerimiseks. Meie lõplik esitus on esimesel kohal inglise keelt Hausa ülesandel.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvataan Mininglampin neurokonekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmiﾃ､ WMT22021 uutiskﾃ､ﾃ､nnﾃｶstehtﾃ､viin. Olemme osallistuneet uutistekstien kﾃ､ﾃ､ntﾃ､miseen kahdeksaan eri suuntaan, mukaan lukien kiina englanniksi/englanniksi, Hausa englanniksi/englanniksi, saksaksi/englanniksi ja ranskaksi/saksaksi. Perusjﾃ､rjestelmﾃ､mme perustui Transformer-arkkitehtuuriin, jossa oli laajempi tai pienempi rakenne erilaisiin uutiskﾃ､ﾃ､nnﾃｶksiin. Hyﾃｶdynsimme pﾃ､ﾃ､sﾃ､ﾃ､ntﾃｶisesti takaisinkﾃ､ﾃ､ntﾃ､mistﾃ､, tiedon tislausta ja hienosﾃ､ﾃ､tﾃｶﾃ､ yhden mallin vahvistamiseksi, kun taas kokoonpanoa kﾃ､ytettiin yksittﾃ､isten mallien yhdistﾃ､miseen. Lopullinen ehdotuksemme on sijoittunut ensimmﾃ､iseksi englannin ja Hausasta -tehtﾃ､vﾃ､ssﾃ､.', 'bn': 'এই পত্রিকাটি উইএমটি২০১২ সংবাদ অনুবাদের কাজের মিনিঙ্গিল্যান্ড নিউরেল মেশিন অনুবাদ সিস্টেমের বর্ণন সংবাদ লেখার জন্য আমরা আটটি দিকে অনুবাদের কাজে অংশগ্রহণ করেছি, যার মধ্যে চীনা থেকে ইংরেজি থেকে/ইংরেজী, হাউসা থেকে/ইংরেজি থেকে  আমাদের মৌলিক ব্যবস্থা বিভিন্ন সংবাদ অনুবাদ কাজের জন্য ট্রান্সফার্নাফারের কাঠামোর উপর ভিত্তিক ছিল। আমরা মূলত পেছনে অনুবাদ, জ্ঞান বিচ্ছিন্ন এবং সুন্দর মডেল বৃদ্ধি করার পদ্ধতি ব্যবহার করেছি, যেখানে এক মডেল বৃদ্ধি করা হয়েছিল। আমাদের শেষ প্রতিক্রিয়া প্রথমে ইংরেজী থেকে/হাউসা কাজের জন্য চালু করেছে।', 'cs': 'Tento článek popisuje neuronové strojové překladové systémy Mininglamp pro úlohy překladu zpráv WMT2028. Účastnili jsme se osmi směrových překladatelských úkolů pro novinky včetně čínštiny do/z angličtiny, Hausa do/z angličtiny, němčiny do/z angličtiny a francouzštiny do/z němčiny. Náš základní systém byl založen na architektuře Transformer s širší nebo menší konstrukcí pro různé úkoly překladu zpráv. Použili jsme především metodu zpětného překladu, destilace znalostí a jemného ladění k posílení jednotlivých modelů, zatímco soubor byl použit k kombinaci jednotlivých modelů. Naše závěrečné příspěvky se dostaly na první místo pro úkol z angličtiny do/z Hausa.', 'sk': 'V prispevku so opisani sistemi nevronskega strojnega prevajanja Mininglamp za naloge prevajanja novic WMT22021. Sodelovali smo pri osmih nalogah prevajanja novic, vključno s kitajščino v/iz angleščine, Hauso v/iz angleščine, nemščino v/iz angleščine in francoščino v/iz nemščine. Naš temeljni sistem je temeljil na transformatorski arhitekturi, s širšo ali manjšo konstrukcijo za različne naloge prevajanja novic. V glavnem smo uporabili metodo retroprevajanja, destilacije znanja in finega uravnavanja za povečanje enega modela, ansambel pa je bil uporabljen za kombiniranje enega modela. Naša končna predložitev se je uvrstila na prvo mesto za nalogo angleščine v/iz Hausa.', 'jv': "Ngerungan iki oleh nggawe sistem itoleh 'Minngcand Neral' karo perangkat kanggo nganggo barang nggawe balêt, ning 'WW2020 1' Awakdhéwé wis ngubah tanggal sekolatan kanggo tarjamahan kanggo teks basa sing itlanjut Chinese kanggo/kanggo Inggris, Haisa kanggo/kanggo Inggris, German kanggo/kanggo Inggris karo Perancis kanggo/kanggo ngerancis. Sistem basic sing digawe ning architecture Transformer Awak dhéwé wis gunakake sistem kut-tarjamahan, nggilalahan punika lan ijol-ijol nggawe model sing beranduh, sampek akeh simbol wis nggawe model sing beranduh. Awakdhéwé éntuk dhéwé nggawe barang kelas telas nang inggilis sak/sak cara Halsa.", 'ha': "@ info: whatsthis Mun yi rabo da aikin fassarar aiki takwas zuwa matsayin lãbãri, ikin China zuwa/daga Ingiriya, Hausa zuwa/daga Ingiriya, Jarman zuwa/Faransa zuwa/Faransa. Ga na'uranmu na bincike, an sami tsarin Transformer, mai shimfiɗa ko mafi ƙaranci wa aikin masu fassarar lãbãra dabam. Ba mu yi amfani da shiryoyin fassarar-bayan-bayani, rarrabin ilmi da gyarata mai kyau zuwa boost motel guda, da kuma an yi amfani da shi ga haɗi misãlai guda. MusuluncinMu na ƙarshen ta fara ta farko ta zama na Ingiriya zuwa/daga aikin Hausa.", 'bo': 'This paper describes Mininglamp neural machine translation systems of the WMT2021 news translation tasks. ང་ཚོས་བརྡ་ཡིག་གི་ཚིག་ཡིག་ཆ་ལ་སྐད་ཡིག་གཟུགས་འགྲུལ་བྱེད་པའི་འགྲེལ་བཤད་འགྲུལ་བཞིན་པའི་ནང་དུ་ཡོད། ང་ཚོའི་རྨན་གཞུང་གི་མ་ལག་ནི་བཟོ་བཅོས་ལུགས་སྒྲིག ང་ཚོས་རྒྱ་ནག་གི་དབྱིབས་ཡུལ་ལྗོངས་དང་། སྟོན་པའི་ཕྱོགས་དབྱིབས་དང་གནད་དོན་གྱི་ཐབས་ལམ་ལ་ལག་ལེན་འཐབ་པ་ཡིན། ང་ཚོའི་མཐའ་མཇུག་གི་ཞབས་ཞུ་བ་ཡིན་ན་དབྱིན་ཡིག་ལས་ཀྱང་/ཧུས་ཤི་ལས་ཀྱང་།', 'he': 'העיתון הזה מתאר מערכות התרגום של מכונות עצביות Mininglamp של משימות התרגום חדשות WMT2021. We have participated in eight directions translation tasks for news text including Chinese to/from English, Hausa to/from English, German to/from English and French to/from German.  Our fundamental system was based on Transformer architecture, with wider or smaller construction for different news translation tasks.  אנחנו בעיקר השתמשנו בשיטה של התרגום האחורי, מיסטיל ידע ומתאים מיוחדים כדי לגדל מודל אחד, בעוד האנסמבל השתמש לשלב דוגמנים בודדים. Our final submission has ranked first for the English to/from Hausa task.'}
{'en': 'Improving Similar Language Translation With ', 'ar': 'تحسين ترجمة اللغات المشابهة باستخدام نقل التعلم', 'fr': "Améliorer la traduction linguistique similaire grâce à l'apprentissage par transfert", 'pt': 'Melhorando a tradução de idiomas semelhantes com o aprendizado por transferência', 'es': 'Mejorar la traducción de idiomas similares con el aprendizaje por transferencia', 'zh': '因迁学改善类语译', 'ja': '転送学習による類似言語翻訳の改善', 'hi': 'स्थानांतरण सीखने के साथ समान भाषा अनुवाद में सुधार', 'ru': 'Улучшение аналогичного перевода языка с помощью обучения переносу', 'ga': 'Aistriúchán Teanga Chomhchosúil a Fheabhsú Le Foghlaim Aistrithe', 'ka': 'სატრანსტრების სწავლებით განსხვავება', 'hu': 'Hasonló nyelvi fordítás javítása a transzfertanulással', 'el': 'Βελτίωση της μετάφρασης παρόμοιων γλωσσών με τη μάθηση μεταφοράς', 'it': 'Migliorare la traduzione di lingue simili con il trasferimento di apprendimento', 'kk': 'Тапсырмаларды оқытумен ұқсас тілді аудару', 'ms': 'Improving Similar Language Translation With Transfer Learning', 'mk': 'Improving Similar Language Translation With Transfer Learning', 'ml': 'Transfer Learning ഉപയോഗിച്ചു് സമമായ ഭാഷ പരിഭാഷകള്\u200d മുന്\u200dകൂട്ടുന്നു', 'mt': 'Improving Similar Language Translation With Transfer Learning', 'mn': 'Төмөргөлдөр суралцахад төстэй хэл хөрөнгө оруулах', 'no': 'Overføring av liknande språk med overføringslæring', 'pl': 'Poprawa tłumaczeń podobnych języków dzięki uczeniu się transferowemu', 'ro': 'Îmbunătățirea traducerii lingvistice similare cu învățarea transferului', 'sr': 'Poboljšanje sličnog prevoda jezika sa učenjem prijenosa', 'si': 'සමාන භාෂාව භාෂාව ප්\u200dරවර්තනය කරන්න පුළුවන්', 'so': 'Horumarinta tarjumista luuqada oo isku mid ah', 'sv': 'Förbättra översättning av liknande språk med Transfer Learning', 'lt': 'Gerinti panašų kalbų vertimą mokymosi perdavimu būdu', 'ta': 'Name', 'ur': 'سیمالی زبان کا ترجمہ سیکھنے کے ساتھ بہتر ہوتا ہے', 'uz': 'Comment', 'vi': 'Tăng trình ngôn ngữ học tương tự với truyền đạt', 'bg': 'Подобряване на подобни езикови преводи с трансферно обучение', 'nl': 'Vergelijkbare taalvertaling verbeteren met Transfer Learning', 'da': 'Forbedring af lignende sprogoversættelse med Transfer Learning', 'id': 'Menembangkan Translation Bahasa yang Sama Dengan Belajar Transfer', 'fa': 'بهتر ترجمه زبان شبیه با یادگیری انتقال', 'hr': 'Poboljšanje sličnog prevoda jezika sa učenjem prijenosa', 'sw': 'Kuboresha tafsiri ya lugha inayofanana na kujifunza', 'de': 'Verbesserung der Übersetzung ähnlicher Sprachen mit Transfer Learning', 'ko': '이동 학습을 활용하여 비슷한 언어의 번역을 개선하다', 'sq': 'Përmirësimi i përkthimit të ngjashëm gjuhësh me mësimin e transferimit', 'af': 'Verbeter Lykbare Taal Vertaling met Oordrag Leer', 'az': 'Transfer öyrənməsi ilə eyni dil tercüməsini yaxşılaşdırma', 'am': 'ትርጉም', 'tr': 'Transfer öwrenmesi bilen ýakyn dil terjimesini gowylaşdyr', 'bs': 'Poboljšanje sličnog prevoda jezika sa učenjem prijenosa', 'bn': 'ট্রান্সফারার শিক্ষা দ্বারা একই ভাষা অনুবাদ প্রদর্শন করা হচ্ছে', 'hy': 'Միևնույն լեզվի թարգմանման բարելավումը փոխանցման սովորելով', 'ca': "millorar la traducció de llenguatges semblants amb l'aprenentatge de transferències", 'cs': 'Zlepšení překladu podobných jazyků pomocí transferového učení', 'fi': 'Samankaltaisten kielten kääntämisen parantaminen siirtooppimisen avulla', 'et': 'Sarnase keeletõlke parandamine siirdeõppega', 'jv': 'njaluk Jejaring', 'sk': 'Izboljšanje podobnega prevoda jezikov s prenosnim učenjem', 'ha': '@ action', 'bo': 'གནས་སོར་བ་དང་གནས་སྦྱོར་ལ་མཚུངས་པའི་སྐད་རིགས་ཚོར་ཡར་རྒྱས་གཏོང', 'he': 'שיפור תרגום שפה דומה עם לימוד העברה'}
{'en': 'We investigate ', 'es': 'Investigamos el aprendizaje por transferencia basado en modelos de traducción automática neuronal previamente entrenados para traducir entre idiomas similares (de pocos recursos). Este trabajo forma parte de nuestra contribución a la tarea compartida de traducción de idiomas similares del WMT 2021, en la que enviamos modelos para diferentes pares de idiomas, incluidos francés-bambara, español-catalán y español-portugués en ambas direcciones. Nuestros modelos para catalán-español (82.79 BLEU) y portugués-español (87.11 BLEU) ocupan el primer lugar en la evaluación oficial de tareas compartidas, y somos el único equipo que presenta modelos para las parejas franco-bambara.', 'pt': 'Investigamos o aprendizado de transferência com base em modelos de tradução automática neural pré-treinados para traduzir entre idiomas semelhantes (com poucos recursos). Este trabalho é parte de nossa contribuição para a Tarefa Compartilhada de Tradução de Idiomas Semelhantes do WMT 2021, onde enviamos modelos para diferentes pares de idiomas, incluindo francês-bambara, espanhol-catalão e espanhol-português em ambas as direções. Nossos modelos para catalão-espanhol (82,79 BLEU) e português-espanhol (87,11 BLEU) estão em primeiro lugar na avaliação oficial de tarefas compartilhadas, e somos a única equipe a enviar modelos para os pares francês-bambara.', 'ar': 'نحن نحقق في نقل التعلم بناءً على نماذج الترجمة الآلية العصبية المدربة مسبقًا للترجمة بين اللغات المتشابهة (منخفضة الموارد). يعد هذا العمل جزءًا من مساهمتنا في المهمة المشتركة لترجمة اللغات المتشابهة لعام 2021 من WMT حيث قدمنا نماذج لأزواج لغوية مختلفة ، بما في ذلك الفرنسية - بامبارا ، والإسبانية - الكاتالونية ، والإسبانية - البرتغالية في كلا الاتجاهين. احتلت عارضاتنا للكتالونية الإسبانية (82.79 BLEU) والبرتغالية الإسبانية (87.11 BLEU) المرتبة الأولى في تقييم المهام المشتركة الرسمية ، ونحن الفريق الوحيد الذي قدم نماذج للأزواج الفرنسية-بامبارا.', 'fr': "Nous étudions l'apprentissage par transfert basé sur des modèles de traduction automatique neuronale pré-entraînés pour traduire entre des langues similaires (à faibles ressources). Ce travail fait partie de notre contribution au WMT 2021 Similar Languages Translation Shared Task où nous avons soumis des modèles pour différentes paires de langues, y compris le français-bambara, l'espagnol-catalan et l'espagnol-portugais dans les deux directions. Nos modèles catalan-espagnol (82,79 BLEU) et portugais-espagnol (87,11 BLEU) se classent parmi les premiers dans l'évaluation officielle des tâches partagées, et nous sommes la seule équipe à soumettre des modèles pour les couples français-bambara.", 'hi': 'हम (कम संसाधन) समान भाषाओं के बीच अनुवाद करने के लिए पूर्व-प्रशिक्षित तंत्रिका मशीन अनुवाद मॉडल के आधार पर स्थानांतरण सीखने की जांच करते हैं। यह काम WMT 2021 समान भाषाओं के अनुवाद साझा कार्य में हमारे योगदान का हिस्सा है, जहां हमने दोनों दिशाओं में फ्रेंच-बंबरा, स्पेनिश-कैटलन और स्पेनिश-पुर्तगाली सहित विभिन्न भाषा जोड़े के लिए मॉडल प्रस्तुत किए हैं। कैटलन-स्पेनिश (82.79 BLEU) और पुर्तगाली-स्पेनिश (87.11 BLEU) के लिए हमारे मॉडल आधिकारिक साझा कार्य मूल्यांकन में शीर्ष 1 रैंक करते हैं, और हम फ्रेंच-बंबारा जोड़े के लिए मॉडल प्रस्तुत करने वाली एकमात्र टीम हैं।', 'ja': '私たちは、（低資源の）類似言語間で翻訳するために、事前にトレーニングされたニューラルマシン翻訳モデルに基づいて転送学習を調査します。この研究は、WMT 2021類似言語翻訳共有タスクへの貢献の一部であり、フランス語-バンバラ語、スペイン語-カタルーニャ語、スペイン語-ポルトガル語を含む異なる言語ペアのモデルを両方向に提出しました。カタルーニャ-スペイン（ 82.79 BLEU ）とポルトガル-スペイン（ 87.11 BLEU ）のモデルは、公式の共有タスク評価で上位1位にランクされており、フランス-バンバラペアのモデルを提出する唯一のチームです。', 'ru': 'Мы исследуем трансферное обучение на основе предварительно обученных моделей нейронного машинного перевода для перевода между (малоресурсными) похожими языками. Эта работа является частью нашего вклада в совместную задачу WMT 2021 по переводу на аналогичные языки, где мы представили модели для разных языковых пар, включая французский-бамбара, испанско-каталонский и испанско-португальский в обоих направлениях. Наши модели для каталоно-испанских (82,79 BLEU)и португало-испанских (87,11 BLEU) занимают 1-е место в официальной оценке общих задач, и мы единственная команда, которая представляет модели для пар French-Bambara.', 'zh': '臣等考其先神经机器翻译之迁学,以(低资源)类言语之间译之。 此吾等WMT 2021类言语译共职之一体,吾于其事中提纳异言对,及法语 - 班巴拉语,西班牙语 - 加泰罗尼亚语与西班牙语 - 葡萄牙语两向。 吾加泰罗尼亚语-西班牙语(82.79 BLEU)、葡萄牙语-西班牙语(87.11 BLEU)形于官方共享其任,唯一提法国-班巴拉对模型之团队。', 'ga': 'Déanaimid imscrúdú ar fhoghlaim aistrithe bunaithe ar mhúnlaí néaraistriúcháin réamh-oilte chun aistriú idir teangacha comhchosúla (íseal-acmhainní). Tá an obair seo mar chuid dár rannchuidiú le Tasc Comhroinnte um Aistriú Teangacha Comhchosúla WMT 2021 inar chuireamar isteach múnlaí do phéirí teangacha éagsúla, lena n-áirítear Fraincis-Bambara, Spáinnis-Catalóinis, agus Spáinnis-Portaingéilis sa dá threo. Tá ár múnlaí don Chatalóinis-Spáinnis (82.79 BLEU) agus don Phortaingéilis-Spáinnis (87.11 BLEU) ar an gcéad cheann sa mheastóireacht oifigiúil ar thasc roinnte, agus is sinne an t-aon fhoireann a chuir samhlacha isteach do na péirí Francacha-Bambara.', 'el': 'Ερευνούμε τη μάθηση μεταφοράς βασισμένη σε προ-εκπαιδευμένα μοντέλα νευρωνικής μηχανικής μετάφρασης για τη μετάφραση μεταξύ παρόμοιων γλωσσών (χαμηλής περιεκτικότητας σε πόρους). Αυτή η εργασία αποτελεί μέρος της συνεισφοράς μας στην κοινή εργασία μετάφρασης παρόμοιων γλωσσών όπου υποβάλαμε μοντέλα για διαφορετικά ζεύγη γλωσσών, συμπεριλαμβανομένων γαλλικών-μπαμπαρών, ισπανικά-καταλανικών και ισπανικά-πορτογαλικών και προς τις δύο κατευθύνσεις. Τα μοντέλα μας για Καταλανικά-Ισπανικά (82.79 BLEU) και Πορτογαλικά-Ισπανικά (87.11 BLEU) κατατάσσονται στην πρώτη θέση στην επίσημη αξιολόγηση κοινών εργασιών και είμαστε η μόνη ομάδα που υποβάλλει μοντέλα για τα ζεύγη γαλλικών-μπαμπάρα.', 'hu': 'A transzfer tanulást előre képzett neurális gépi fordítási modellek alapján vizsgáljuk, hogy (alacsony erőforrású) hasonló nyelvek közötti fordításra fordítsuk. Ez a munka része a WMT 2021 hasonló nyelvű fordítási megosztott feladatának, ahol különböző nyelvpárok modelljeit küldtük be, beleértve a francia-bambarát, spanyol-katalán és spanyol-portugál mindkét irányban. Katalán-spanyol (82,79 BLEU) és portugál-spanyol (87,11 BLEU) modelleink első helyen állnak a hivatalos megosztott feladatok értékelésében, és mi vagyunk az egyetlen csapat, aki modelleket nyújt be a francia-bamara párokra.', 'ka': 'ჩვენ შევსწავლობთ ტრანსპერსტის სწავლებას, რომელიც უფრო განვითარებული ნეიროლური მაქინის გარგუმარების მოდელისთვის, რომ გარგუმარება (ცოტ ეს სამუშაო არის ჩვენი დამატების ნაწილი WMT 2021-ის მსგავსი ენების გასაგრძელების გასაგრძელების ნაწილი სამუშაოდ, სადაც ჩვენ განსხვავებული ენების ზოგებისთვის მოდელები გადავიტანეთ, რომელიც ფრანუს-ბამ ჩვენი მოდელები კატალან-სპანელისთვის (82.79 BLEU) და პორგუტებური-სპანელისთვის (87.11 BLEU) უფრო მეტი 1 წერტილი ფანჯარა ფანჯარა დაყოფილი დავამუშავებულებაში, და ჩვენ ვართ ერთადერთი ჯგუფი, რომელიც მო', 'it': "Investighiamo l'apprendimento di trasferimento basato su modelli di traduzione automatica neurale pre-addestrati per tradurre tra lingue simili (a basso contenuto di risorse). Questo lavoro fa parte del nostro contributo al WMT 2021 Similar Languages Translation Shared Task in cui abbiamo presentato modelli per diverse coppie di lingue, tra cui francese-Bambara, spagnolo-catalano e spagnolo-portoghese in entrambe le direzioni. I nostri modelli per catalano-spagnolo (82.79 BLEU) e portoghese-spagnolo (87.11 BLEU) si collocano al primo posto nella valutazione ufficiale dei compiti condivisi, e siamo l'unico team a presentare modelli per le coppie franco-bamara.", 'kk': 'Біз алдын- ала оқылған невралдық компьютердің аудару үлгілеріне негізделген аудару үйренімізді зерттейміз. Бұл жұмыс WMT 2021- ге ұқсас тілдерді аудару ортақ тапсырмасының бір бөлігі. Біз басқа тілдердің екі бағытта, француз- бамбара, испан- каталанша және Испан- Португалия тілдердің үлгілерін жібердік Біздің каталан-испан үлгілеріміз (82,79 BLEU) және португал-испан (87,11 BLEU) үлгілеріміз официально ортақ тапсырмаларды бағалау үшін жоғары 1 деп тұрады. Біз француз-Бамбара жиіліктерінің үлгілерін жа', 'ms': 'Kami menyelidiki pembelajaran pemindahan berdasarkan model terjemahan mesin saraf terlatih untuk menerjemahkan antara bahasa (sumber rendah) yang sama. Kerja ini merupakan sebahagian daripada kontribusi kami ke WMT 2021 Bahasa Terjemahan Berkongsi Di mana kami menghantar model untuk pasangan bahasa berbeza, termasuk Perancis-Bambara, Spanyol-Catalan, dan Spanyol-Portugis dalam kedua-dua arah. Model kami untuk Catalan-Spanyol (82.79 BLEU)dan Portugis-Spanyol (87.11 BLEU) berturut-turut 1 dalam penilaian tugas berkongsi rasmi, dan kami satu-satunya pasukan yang menghantar model untuk pasangan Perancis-Bambara.', 'ml': 'മുമ്പ് പരിശീലിക്കപ്പെട്ട ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷ മോഡലുകളില്\u200d അടിസ്ഥാനമായി നിങ്ങള്\u200d പരിശോധിക്കുന്നത് നമ്മള്\u200d അന്വേഷ This work is part of our contribution to the WMT 2021 Similar Languages Translation Shared Task where we submitted models for different language pairs, including French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions.  ഞങ്ങളുടെ മോഡലുകള്\u200d കാത്താലന്\u200d -സ്പാനിഷ് (82. 79 ബെലി) പോര്\u200dട്ടുഗീഷ്-സ്പാനിഷ് (87. 11 ബെലി) ഓഫീസില്\u200d പങ്കെടുത്ത ജോലിയുടെ വിലാസത്തില്\u200d മുകളില്\u200d മാത്രമാണ്. ഫ്', 'mn': 'Бид урд сургалтын мэдрэлийн машин хөрөнгө оруулах загвар дээр суралцах сургалтыг судалж байна. Энэ ажил WMT 2021 оны төстэй хэл хөрөнгө оруулалтын нэг хэсэг бөгөөд бид өөр хэл хоёр төрлийн загваруудын загварыг дамжуулсан. Энэ нь Француз-Бамбара, Испан-Каталан, Испан-Португалийн хоёр хэсэгт ч мөн адил. Бидний Каталан-Испан (82.79 BLEU) болон Португали-Испан (87.11 BLEU) загварын оюутнуудын оюутнуудын шалгалтын 1-р багтаж байна. Француз-Бамбара хоёрын загварын ганц баг болно.', 'mt': 'Aħna ninvestigaw it-tagħlim tat-trasferiment ibbażat fuq mudelli ta’ traduzzjoni tal-magni newrali mħarrġa minn qabel biex jittraduċu bejn lingwi simili (b’riżorsi baxxi). Dan ix-xogħol huwa parti mill-kontribut tagħna għall-Ħidma Kondiviża tat-Traduzzjoni tal-Lingwi Simili tad-WMT 2021 fejn ippreżentajna mudelli għal pari differenti ta’ lingwi, inklużi Franċiż-Bambara, Spanjol-Katalan, u Spanjol-Portugiż fiż-żewġ direzzjonijiet. Il-mudelli tagħna għall-Katalan-Spanjol (82.79 BLEU) u l-Portugiż-Spanjol (87.11 BLEU) jikklassifikaw l-ogħla wieħed fl-evalwazzjoni uffiċjali tal-kompiti kondiviżi, u aħna l-uniku tim li ressaq mudelli għall-par Franċiż-Bambara.', 'pl': 'Badamy uczenie się transferowe w oparciu o wstępnie przeszkolone neuronowe modele tłumaczenia maszynowego w celu tłumaczenia pomiędzy (niskimi zasobami) podobnymi językami. Praca ta jest częścią naszego wkładu w realizację Wspólnego Zadania Tłumaczenia Podobnych Języków WMT 2021, w którym przesłaliśmy modele dla różnych par językowych, w tym francusko-bamara, hiszpańsko-kataloński i hiszpańsko-portugalski w obu kierunkach. Nasze modele dla katalońsko-hiszpańskich (82.79 BLEU) i portugalsko-hiszpańskich (87.11 BLEU) zajmują pierwszą rangę w oficjalnej ocenie zadań wspólnych, a my jesteśmy jedynym zespołem, który zgłasza modele dla par francusko-bamara.', 'no': 'Vi undersøker læring av overføring basert på føretrainerte neuralmaskineoversettelsmodeller for å oversette mellom (låg ressurs) liknande språk. Dette arbeidet er delt av vårt bidrag til WMT 2021 delt delt oppgåve som liknar omsetjing av språk, der me sendte modeller for ulike språkopar, inkludert fransk-Bambara, spansk-katalansk og spansk-portugisisk i begge retningar. Våre modeller for katalansk-spansk (82,79 BLEU) og portugisisk-spansk (87,11 BLEU) er toppen 1 i den offisielle delte oppgåveevalueringa, og vi er den eneste gruppa som skal sende modeller for fransk-Bambara-par.', 'lt': 'Mes tiriame perdavimo mokymąsi, pagrįstą iš anksto parengtais nervinių mašinų vertimo modeliais, siekiant išversti panašias (mažai išteklių) kalbas. Šis darbas yra dalis mūsų indėlio į WMT 2021 panašių kalbų vertimo bendrą užduotį, kurioje abu kryptimis pateikėme įvairių kalbų poros pavyzdžius, įskaitant prancūzų-bambarą, ispanų-katalaną ir ispanų-portugalų kalbą. Mūsų katalanų-ispanų (82,79 BLEU) ir portugalų-ispanų (87,11 BLEU) modeliai oficialiai atliekant bendros užduoties vertinimą yra pirmasis, o mes esame vienintelė komanda, kuri pateikia pavyzdžius Prancūzijos-Bambaros poroms.', 'mk': 'Истражуваме трансферентно учење базирано на предобучени модели за превод на невројални машини за превод помеѓу (ниски ресурси) слични јазици. Оваа работа претставува дел од нашиот придонес за ВМТ 2021-та слична задача за заеднички превод на јазици каде што поднесовме модели за различни јазички парови, вклучително и француски-бамбарски, шпански-каталонски и шпански-португалски во двете насоки. Нашите модели за каталонско-шпанско (82,79 БЛЕ) и португалско-шпанско (87,11 БЛЕ) се рангираат на првата улога во официјалната заедничка оценка на задачите, а ние сме единствениот тим кој ги поднесува моделите за паровите француско-бамбарски.', 'ro': 'Investigăm învățarea transferului bazată pe modele de traducere automată neurală pre-instruite pentru a traduce între limbi similare (cu resurse reduse). Această lucrare face parte din contribuția noastră la WMT 2021 Similar Languages Translation Shared Task unde am trimis modele pentru diferite perechi de limbi, inclusiv franceză-Bambara, spaniolă-catalană și spaniolă-portugheză în ambele direcții. Modelele noastre pentru catalană-spaniolă (82.79 BLEU) și portugheză-spaniolă (87.11 BLEU) se situează în primul loc în evaluarea oficială a sarcinilor partajate și suntem singura echipă care depune modele pentru perechile francez-Bambara.', 'sr': 'Istražujemo učenje prevođenja na osnovu predobučenih modela prevođenja neuralnih mašina da prevodimo između sličnih jezika (niskih resursa). Ovaj rad je deo našeg doprinosa na WMT 2021. delovani zadatak za prevod jezika u kojem smo predali modele za različite jezičke pare, uključujući francusku-Bambaru, španjolsku-katalansku i španjolsku-portugalsku u oba smjera. Naši modeli za katalanski-španjolski (82,79 BLEU) i portugalski-španjolski (87,11 BLEU) u oficijalnoj zajedničkoj procjeni zadataka postaju najbolji 1. reda, a mi smo jedini tim koji podnosi modele za francuske-Bambarske pare.', 'si': 'අපි පරීක්ෂණය කරනවා ප්\u200dරධාන ප්\u200dරශ්නය කරපු න්\u200dයූරාල් මැෂින් පරීක්ෂණ මොඩේල්ස් එක්ක වගේ භාෂාවට ( මේ වැඩ තමයි WMT 2021 වලින් භාෂාව භාෂාව භාෂාව භාෂාව භාෂා කරපු කාර්යාලයට අපි වෙනස් භාෂාවක් ජෝඩු වලට මොඩේල් දාලා තියෙන්නේ, ෆ්\u200d අපේ මෝඩේල් කැටලාන්-ස්පැනිස් වලට (82.79 BLUE) සහ පොර්තුගිස්-ස්පැනිස් වලට (87.11 BLUE) ප්\u200dරධානික වැඩක් අවශ්\u200dය විශ්වාසයෙන් ඉහළ පහළ පහළ ප', 'so': 'Waxbarashada bedelka waxaynu ku baaraynaa samooyin lagu tababaray horay u tababaray qoraalka tarjumaadda maskaxda neurada si loo turjumo luqadaha u eg (low-resource). Shuqulkaas waa qayb ka mid ah contributions to the WMT 2021 Similar Languages Translation Shared Task where we submit models for labo kala duduwan, including French-Bambara, Spanish-Catalan, and Isbanish-Burtuqiis labada kooxood. Tusaalooyinkayada Katalan-Isbanish (82.79 BLEU) iyo Burtuqiis-Isbanish (87.11 BLEU) waxay leeyihiin heer 1 oo rasmi ah qiimeynta shaqada la qaybiyey, waxaana nahay kooxa kaliya oo loo soo dhiibo modello u ah labada Faraansiinta Bambara.', 'ta': 'முன் பயிற்சிக்கப்பட்ட புதிய இயந்திரத்தின் மொழிமாற்ற மாதிரிகளில் நாம் மாற்றும் கற்றலை தேடுகிறோம் அதே போன்ற மொ WMT 2021 போன்ற மொழிமாற்ற மொழிகள் பகிர்ந்த பணிக்கு இந்த வேலை எங்கள் பங்கிடையில் ஒரு பகுதியாகும் இது இரு திசையிலும் பிரெஞ்சு- பாம்பாரா, ஸ்பானிஷ்- காட்டல எங்கள் காட்டலான்- ஸ்பானிஷ் மாதிரிகள் (82. 79 BLEU) மற்றும் போர்த்துகீச்- ஸ்பானிஷ் (87. 11 BLEU) அலுவலக்கு பகிர்ந்த பணி மதிப்பில் மேல் 1 நிறுவனம் உள்ளது, பிரென்ச்- ப', 'sv': 'Vi undersﾃｶker transferinlﾃ､rning baserat pﾃ･ pre-utbildade neurala maskinﾃｶversﾃ､ttningsmodeller fﾃｶr att ﾃｶversﾃ､tta mellan (lﾃ･gresurs) liknande sprﾃ･k. Detta arbete ﾃ､r en del av vﾃ･rt bidrag till WMT 2021 Similar Languages Translation Shared Task dﾃ､r vi skickade in modeller fﾃｶr olika sprﾃ･kpar, inklusive franska-bamara, spanska-katalanska och spanska-portugisiska i bﾃ･da riktningarna. Vﾃ･ra modeller fﾃｶr katalansk-spanska (82,79 BLEU) och portugisisk-spanska (87,11 BLEU) rankas hﾃｶgst 1 i den officiella delade uppgiftsutvﾃ､rderingen, och vi ﾃ､r det enda laget som lﾃ､mnar in modeller fﾃｶr fransk-bamara paren.', 'ur': 'ہم پہلے تدریس کی نیورل ماشین کی ترجمہ موڈل پر استعمال کی ترجمہ کی تعلیم کی تحقیق کررہے ہیں کہ (کم سورسسور) جیسی زبانوں کے درمیان ترجمہ کریں۔ یہ کام WMT 2021 جیسا زبان ترجمہ شریک ٹاکس میں ہمارا حصہ ہے جہاں ہم نے مختلف زبان جوڑوں کے لئے نمونے ڈال دیے ہیں، فرنس-Bambara، اسپانیایی-کاتالان اور اسپانیایی-پورچوٹیز دونوں طریقوں میں۔ ہمارے ماڈلے کاٹلان-اسپانیایی (82.79 BLEU) اور پورتوگل-اسپانیایی (87.11 BLEU) کے ذریعہ سے اوپر 1 مرتبہ ہیں، اور ہم صرف فرنس-بامبارا جوڑوں کے لئے موڈلے مستقل کرنے والے تیم ہیں.', 'uz': "We investigate transfer learning based on pre-trained neural machine translation models to translate between (low-resource) similar languages.  Bu ishni WMT 2021 Similar Tillar tarjima qilingan vazifaning bir qismimiz. Bu yerda biz ikkita tarjima bilan boshqa tillar qo'llari uchun modellar, Fransuz-Bambara, Ispancha-Katalan va Ispanish-Portugalcha bilan bir xil tarjima qildik. Biz Katalan-Ispancha modellarimiz (82. 79 BLEU) va Portugalcha-Ispancha (87. 11 BLEU) tashkilotlarini qidirish uchun birinchi darajada yuqori darajaga ega bo'ladi. Biz Fransuzcha-Bambara parchalari uchun birinchi guruh.", 'vi': 'Chúng tôi điều tra việc học chuyển nhượng dựa trên các mô hình dịch cỗ máy thần kinh được đào tạo để dịch giữa các ngôn ngữ tương tự. Công trình này là một phần của sự đóng góp của chúng tôi cho giải dịch ngôn ngữ tương tự WRT 2021 nơi chúng tôi đã gửi mẫu cho các cặp ngôn ngữ khác nhau, gồm gồm French-Bambara, Spanish-Catalan, và Spanish-Portuguery ở cả hai hướng. Trong phần đánh giá chính thức của chúng tôi về Tây Ban Nha hai kiểu hai kiểu hai mang đều là bộ số hai. Chúng tôi là nhóm duy nhất có thể cung cấp mẫu cho các cặp Pháp-Bambara.', 'bg': 'Ние изследваме трансферното обучение въз основа на предварително обучени модели на невронен машинен превод за превод между (с нисък ресурс) подобни езици. Тази работа е част от нашия принос към Споделената задача за превод на сходни езици 2021, където представихме модели за различни езикови двойки, включително френски-бамбара, испански-каталонски и испански-португалски в двете посоки. Нашите модели за каталонско-испански (82.79 Блеу) и португалско-испански (87.11 Блеу) се класират на първо място в официалната оценка на споделените задачи и ние сме единственият екип, който представя модели за двойките Френско-Бамбара.', 'da': 'Vi undersøger overførselsindlæring baseret på prætrænede neurale maskinoversættelsesmodeller til oversættelse mellem (lav ressource) lignende sprog. Dette arbejde er en del af vores bidrag til WMT 2021 Lignende sprog Oversættelse delt opgave, hvor vi indsendte modeller for forskellige sprogpar, herunder fransk-bamara, spansk-catalansk og spansk-portugisisk i begge retninger. Vores modeller for catalansk-spansk (82,79 BLEU) og portugisisk-spansk (87,11 BLEU) rangerer top 1 i den officielle delte opgavevaluering, og vi er det eneste team, der indsender modeller til fransk-bamara par.', 'nl': 'We onderzoeken transfer learning op basis van vooraf getrainde neurale machine translation modellen om te vertalen tussen (low-resource) vergelijkbare talen. Dit werk maakt deel uit van onze bijdrage aan de WMT 2021 Vergelijkbare Talen Translation Shared Task, waarbij we modellen hebben ingediend voor verschillende taalparen, waaronder Frans-Bambara, Spaans-Catalaans en Spaans-Portugees in beide richtingen. Onze modellen voor Catalaans-Spaans (82.79 BLEU) en Portugees-Spaans (87.11 BLEU) staan bovenaan in de officiële gedeelde taakvoordeling, en we zijn het enige team dat modellen indient voor de Frans-Bambara paren.', 'hr': 'Istražujemo učenje prevođenja na temelju predobučenih modela prevođenja neuronskih strojeva kako bi prevođeni između sličnih jezika (niskih resursa). Ovaj rad je dio našeg doprinosa WMT 2021 sličnom zajedničkom zadatku prevoda jezika u kojem smo predali modele za različite jezičke pare, uključujući francusku-Bambaru, španjolsku-katalansku i španjolsku-portugalsku u oba smjera. Naši modeli za katalansku-španjolsku (82,79 BLEU) i portugalsku-španjolsku (87,11 BLEU) u službenoj zajedničkoj procjeni zadataka postavljaju najbolji prvi redak, a mi smo jedini tim koji podnosi modele za francuske-Bambarske pare.', 'de': 'Wir untersuchen Transferlernen basierend auf vortrainierten neuronalen maschinellen Übersetzungsmodellen, um zwischen (ressourcenarmen) ähnlichen Sprachen zu übersetzen. Diese Arbeit ist Teil unseres Beitrags zum WMT 2021 Ähnliche Sprachen Translation Shared Task, bei dem wir Modelle für verschiedene Sprachpaare eingereicht haben, darunter Französisch-Bambara, Spanisch-Katalanisch und Spanisch-Portugiesisch in beide Richtungen. Unsere Modelle für Katalanisch-Spanisch (82.79 BLEU) und Portugiesisch-Spanisch (87.11 BLEU) stehen in der offiziellen gemeinsamen Aufgabenbewertung an erster Stelle und wir sind das einzige Team, das Modelle für die Französisch-Bambara Paare einreicht.', 'id': 'Kami menyelidiki pembelajaran transfer berdasarkan model penerjemah mesin saraf terlatih untuk menerjemahkan antara bahasa (sumber daya rendah) yang sama. Pekerjaan ini adalah bagian dari kontribusi kita ke WMT 2021 Bahasa-Bahasa Sama Translation Shared Task dimana kami mengirim model untuk pasangan bahasa yang berbeda, termasuk Perancis-Bambara, Spanyol-Catalan, dan Spanyol-Portugis dalam kedua arah. Model kami untuk Catalan-Spanyol (82.79 BLEU) dan Portugis-Spanyol (87.11 BLEU) berturut-turut atas 1 dalam evaluasi tugas secara resmi berbagi, dan kami adalah satu-satunya tim yang mengirimkan model untuk pasangan Perancis-Bambara.', 'ko': '우리는 사전에 훈련된 신경기계 번역 모델을 바탕으로 이동 학습을 연구하여 (저자원) 비슷한 언어 사이에서 번역을 진행하였다.이 작업은 우리가 WMT 2021 유사 언어 번역 공유 임무에 기여한 일부분이다. 우리는 이 임무에서 프랑스어 반바라어, 스페인어 카탈로니아어, 스페인어 포르투갈어 양방향 번역 등 서로 다른 언어 쌍의 모델을 제출했다.우리의 카탈루냐 스페인어(82.79 BLEU)와 포르투갈어 스페인어(87.11 BLEU) 모델은 공식 공유 임무 평가에서 1위를 차지했으며, 프랑스 반바라 배합 모델을 제출한 유일한 팀이다.', 'fa': 'ما تحقیق یادگیری انتقال بر اساس مدل ترجمه\u200cهای ماشین عصبی پیش آموزش می\u200cکنیم تا بین زبانهای شبیه (منابع کم) ترجمه کنیم. این کار بخشی از دسترسی ما برای ترجمه کردن زبان\u200cهای شبیه به WMT 2021 است که ما مدل\u200cها برای جفت زبان\u200cهای مختلف ارسال کردیم، شامل فرانسوی-بامبرا، اسپانیایی-کاتالان و اسپانیایی-پورتوژیک در هر دو طرف. مدل\u200cهای ما برای کاتالان-اسپانیایی (82.79 BLEU) و پورتوژیک-اسپانیایی (87.11 BLEU) در ارزیابی عملیات مشترک رسمی بالا ۱ درجه دارند، و ما تنها تیم هستیم که مدل\u200cها را برای جفت فرانسوی-بامبارا تحویل دهیم.', 'sw': 'Tunafanya uchunguzi wa kujifunza kwa kutumia mbinu za tafsiri za mashine ya neura zilizofunzwa kabla ya kutafsiri kati ya lugha (rasilimali chini) zilizofanana. Kazi hii ni sehemu ya mchango wetu wa Tafsiri ya lugha inayofanana na WMT 2021 ambapo tuliwasilisha mifano kwa ajili ya ndoa tofauti za lugha, ikiwa ni pamoja na Kifaransa-Bambara, Kihispania-Katalani, na Kireno-Kihispania kwa njia zote. Mfano wetu wa Kikatalani-Kihispania (82.79 BLEU) na Kireno-Kihispania (87.11 BLEU) ni wa juu 1 katika tathmini rasmi za kazi zilizoshirikishwa, na sisi ni timu pekee ya kuwasilisha mifano kwa ajili ya wanandoa wa Kifaransa-Bambara.', 'tr': 'Biz öňünden öňünden bilinmeli näral maşynyň terjime modellerine ýaly diller arasynda terjime etmek üçin öwrenmegi barlagçy. WMT 2021-nji ýylda ýakyn diller terjime etmek üçin nusgalarymyzyň bir bölegidir. Biz bu işi WMT 2021-nji ýylda farklı dil çiftleri üçin nusgalary gönderdik, hem Fransuz-Bambara, espanyol-katalança we espanyol-portugalça hem ikimiz tarapynda. Biziň Katalan-Ispaniýaly nusgalarymyz', 'af': 'Ons ondersoek oordrag leer gebaseer op vooraf- ondersoekte neurale masjien vertaling modele om tussen (lae- hulpbron) gelyke tale te vertaal. Hierdie werk is deel van ons bydraai aan die WMT 2021 Likelike Taal Vertaling Deel Taal Taak waar ons model vir verskillende taal paar ingestuur het, insluitend Frans-Bambara, Spaanse-Katalan en Spaanse-Portugese in beide rigtings. Ons modele vir Katalan-Spaanse (82.79 BLEU) en Portugese-Spaanse (87.11 BLEU) rank bo 1 in die offisiele gedeelde taak evaluasie, en ons is die enigste span om modele vir die Frans-Bambara pare te onderskyn.', 'sq': 'Ne hetojmë mësimin e transferit bazuar në modelet e paratrajnuara të përkthimit të makinave nervore për të përkthyer mes gjuhëve të ngjashme (me burime të ulëta). Ky punë është pjesë e kontributit tonë në WMT 2021 Detyrën e Përkthimit të Lidhur të Përbashkët të Gjuhave ku paraqitëm modele për çifte të ndryshme gjuhësh, duke përfshirë Franco-Bambara, Spanjoll-Katalan dhe Spanjoll-Portuguese në të dy drejtimet. Modelet tona për katalan-spanjollët (82.79 BLEU) dhe portugal-spanjollët (87.11 BLEU) renditen në krye 1 në vlerësimin zyrtar të detyrës së përbashkët dhe ne jemi ekipi i vetëm që paraqet modele për çiftet francez-bambar.', 'am': 'እንደዚህ በተመሳሳይ ቋንቋዎች መካከል (low-resource) ትርጓሜዎችን ለመተርጓሜ በተደረገ የናውሬል መሣሪያን በመሠረት ላይ የተማርነውን ትርጓሜን እናምርመራለን፡፡ ይህ ሥራ በWMT 2021 ብጤያዊ ቋንቋዎች ትርጉም የተሰራው ስራ ነው፤ በሁለቱም መንገዶች፣ ፈረንሳይ-ባባባራ፣ ስፓኒሽ-ካታላን እና ስፓኒሽ-ፖርቱጋሊስ እና ለልዩ ቋንቋዎች ዓይነቶች ሞዴላዎችን አቀረብን፡፡ የካትላኒሽ-ስፓኒሽ ሞዴሎቻችን (82.79 BLEU) እና ፖርቱጋዊ-ስፓኒሽ (87.11 BLEU) ባለሥልጣኑ ስራ ማህበረሰብ ላይ 1 ደረጃዎች ናቸው፤ ለፈረንሳይ-ባምባራ ሁለት ዓይነቶች ማዘጋጀት የምንችል ብሔራዊ ቡድን ነን።', 'bn': 'পূর্ব প্রশিক্ষিত নিউরাল মেশিন অনুবাদ মডেলের ভিত্তিতে আমরা পরিবর্তন শিক্ষা অনুসন্ধান করি একই ভাষায় অনুবাদ করার জন্য। এই কাজ আমাদের উইএমটি ২০২১ সামান্য ভাষার অনুবাদ শেয়ার করার অংশ, যেখানে আমরা বিভিন্ন ভাষার জোড়ার জন্য মডেল প্রদান করেছি, যার মধ্যে ফরাসি-বাম্বারা, স্প্যানি আমাদের মডেল ক্যাটালান-স্প্যানিশ (৮2. 79 বিলিউ) এবং পর্তুগীজ-স্প্যানিশ (৮7. 11 বিলিউ) সরকারি কর্মকর্তার মূল্যের মধ্যে সর্বোচ্চ স্থানীয় রেখেছে, আর আমরা একমাত্র', 'hy': 'Մենք ուսումնասիրում ենք փոխանցման ուսումնասիրությունը, հիմնված նախապատրաստված նյարդային մեքենայի թարգմանման մոդելների վրա, որպեսզի թարգմանենք (ցածր ռեսուրսների) նման լեզուներ: This work is part of our contribution to the WMT 2021 Similar Languages Translation Shared Task where we submitted models for different language pairs, including French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions.  Մեր կատալան-իսպաներենի (82.79 ԲԼԵՎ) և պորտուգալան-իսպաներենի (87.11 ԲԼԵՎ) մոդելները համարվում են առաջինը պաշտոնական համեմատական խնդիրների գնահատման մեջ, և մենք միակ թիմը ենք, որ մոդելներ է ներկայացնում ֆրանսիական-բամբարայի զույգերի', 'bs': 'Istražujemo učenje prevođenja na osnovu predobučenih modela prevođenja neuralnih strojeva kako bi prevodili slične jezike (niske resurse). Ovaj rad je dio našeg doprinosa WMT 2021 sličnom zajedničkom zadatku prevoda jezika u kojem smo predali modele za različite jezičke pare, uključujući francusku-Bambaru, španjolsku-katalansku i španjolsku-portugalsku u oba smjera. Naši modeli za katalansku-španjolsku (82,79 BLEU) i portugalsku-španjolsku (87,11 BLEU) u službenoj zajedničkoj procjeni zadataka postavljaju najbolji 1. redak, a mi smo jedini tim koji podnosi modele za francuske-Bambarske pare.', 'ca': "Investiguem l'aprenentatge de transfer ència basat en models de traducció de màquines neurals pré-entrenats per traduir entre llengües similars (de baix recursos). Aquesta obra és part de la nostra contribució a la tasca compartida de traducció de llengües semblants del WMT 2021 on vam presentar models per parelles de llengües diferents, incloent francès-Bambara, espanyol-català i espanyol-portuguès en ambdues direccions. Els nostres models per català-espanyol (82,79 BLEU) i portuguès-espanyol (87,11 BLEU) es ranken en el primer lloc en l'evaluació oficial de les tasques compartides, i som l'únic equip a presentar models per als parells francès-bambar.", 'et': 'Uurime siirdeõpet, mis põhineb eelnevalt väljaõpetatud neuromasintõlke mudelitel, et tõlkida (vähese ressursiga) sarnaste keelte vahel. See töö on osa meie panusest WMT 2021 sarnaste keelte tõlke jagatud ülesandesse, kus esitasime mudelid erinevatele keelepaaridele, sealhulgas prantsuse-bambara, hispaania-katalaani ja hispaania-portugali keele mõlemas suunas. Meie katalaani-hispaania (82.79 BLEU) ja portugali-hispaania (87.11 BLEU) mudelid on ametlikus jagatud ülesannete hindamises esimesel kohal ning me oleme ainus meeskond, kes esitab mudeleid Prantsuse-Bambara paaridele.', 'az': 'Biz öyrənmək öyrənməsini öyrəndik, əvvəlcə təhsil edilmiş nöral maşın çevirim modellərinə görə bənzər dillər arasında çevirirlər. Bu işin WMT 2021 ilə eyni dillər tercüməsi paylaşılan işin bir parçasıdır. Biz fərqli dil çiftlərinin modelləri göndərdik, Fransız-Bambara, İspanyol-Katalan və İspanyol-Portugalca da. Katalan-İspanyolca modellərimiz (82.79 BLEU) və Portugal-İspanyolca (87.11 BLEU) ofisial paylaşılan işin değerlendirməsində ən yüksək dərəcələrimiz 1, Fransız-Bambara çiftlərinin modelləri təyin etmək üçün tək bir ekibimiz.', 'cs': 'Zkoumáme transferové učení založené na předškolených neuronových strojových modelech překladu pro překlad mezi (nízkými zdroji) podobnými jazyky. Tato práce je součástí našeho příspěvku na WMT 2021 Podobné jazyky Shared Task, kde jsme předložili modely pro různé jazykové páry, včetně francouzštiny-bambary, španělština-katalánština a španělština-portugalština v obou směrech. Naše modely pro katalánsko-španělštinu (82.79 BLEU) a portugalsko-španělštinu (87.11 BLEU) jsou v oficiálním hodnocení sdílených úkolů nejlepší a jsme jediným týmem, který předkládá modely pro francouzsko-bambarské páry.', 'fi': 'Tutkimme siirtooppimista ennalta koulutettujen neurokonekäännösmallien pohjalta kääntämään samankaltaisten kielten välillä. Tämä työ on osa osallistumistamme WMT 2021 Similar Languages Translation Shared Task -ohjelmaan, jossa toimitimme malleja eri kielipareille, mukaan lukien ranska-bambara, espanja-katalaani ja espanja-portugali molempiin suuntiin. Mallimme katalaani-espanja (82.79 BLEU) ja portugali-espanja (87.11 BLEU) sijoittuvat ykköseksi virallisessa jaettujen tehtävien arvioinnissa, ja olemme ainoa tiimi, joka toimittaa malleja ranskalais-bambara-pareille.', 'jv': 'Awak dhéwé yatêp nggunakaké ngerwih basa ning model itolen Neral karo ingkang sampeyan karo ingkang sampeyan (gambar-sistem) sampeyan. Wunggu iki barêng nggawe nganggep nggambar uwong karo WT 2020 1 Liwih Pasing Tarjamahan kanggo awak dhéwé ngetokaké model kanggo nggawe alih luwih apik, tambah French-Bambara, Spanish-Catalan lan Spanish-portugisisan sing dibutuhke tarjamahan. Rasané awak dhéwé dengané sing nyebutaké Catalan-Spalani', 'sk': 'Preučujemo prenosno učenje na podlagi vnaprej usposobljenih modelov nevronskega strojnega prevajanja za prevajanje med podobnimi jeziki (z nizkimi viri). To delo je del našega prispevka k skupni nalogi prevajanja podobnih jezikov WMT 2021, kjer smo predložili modele za različne jezikovne pare, vključno s francoščino-bambara, špansko-katalonščino in špansko-portugalščino v obeh smereh. Naši modeli za katalonsko-špansko (82,79 BLEU) in portugalsko-špansko (87,11 BLEU) se uvrščajo na prvo mesto v uradni oceni skupnih nalog in smo edina ekipa, ki je predložila modele za par francosko-bambara.', 'he': 'אנו חוקרים את הלימודים של העברה המבוססים על מודלים מתרגמים מוקדמים של מכונות עצביות כדי לתרגם בין שפות דומות (משאבים נמוכות). This work is part of our contribution to the WMT 2021 Similar Languages Translation Shared Task where we submitted models for different language pairs, including French-Bambara, Spanish-Catalan, and Spanish-Portuguese in both directions.  הדוגמנים שלנו לקטלנית-ספרדית (82.79 BLEU) ופורטוגזית-ספרדית (87.11 BLEU) מגיעים לראשונה בערכת המשימה המשותפת הרשמית, ואנחנו הצוות היחיד ששולח דוגמנים לזוגי הבמברה הצרפתיים.', 'ha': 'Tuna ƙidãya a kan transfer da aka yi amfani da shi a kan misãlai masu yin fassarwa na farko na aikin neural dõmin su translate between (lower-resource) harshen kamar harshen. Wannan aikin yana da rabon mu zuwa the WMT 2021 Similar languages Translate Shared Tajik where we Submit Models for lingui-par-language, include French-Bambara, spanish-Catalan, and spanish-Portugal in both direction. @ item license (short name)', 'bo': 'ང་ཚོས་ཀྱིས་སྔོན་གྲངས་སྒྲིག་གི་ནུས་པ་ལག་འཁོར་གྱི་དཔེ་དབྱིབས་གནས་སྐད་བསྒྱུར་ནུས་ཀྱི་དཔེ་དབྱིབས་ཞིབ་དཔྱད་བྱས འདི་ནི་ང་ཚོའི་ནང་དུ་WMT 2021 ལྟ་བུའི་སྐད་ཡིག ང་ཚོའི་མིག་གཟུགས་རིས་ཀྱི་རྣམ་པ་ལྟར་ཞིབ་བཤེར།'}
{'en': 'T4 T Solution : WMT21 Similar Language Task for the Spanish-Catalan and Spanish-Portuguese Language Pair', 'ar': 'حل T4T: مهمة لغة مماثلة WMT21 لزوج اللغتين الإسبانية والكتالونية والإسبانية والبرتغالية', 'fr': 'Solution T4T\xa0: tâche de langue similaire WMT21 pour la paire de langues espagnol-catalan et espagnol-portugais', 'pt': 'Solução T4T: Tarefa de idioma semelhante WMT21 para o par de idiomas espanhol-catalão e espanhol-português', 'es': 'Solución T4T: Tarea de idiomas similar al WMT21 para la combinación de idiomas español-catalán y español-portugués', 'ja': 'T 4 Tソリューション：スペイン語-カタルーニャ語およびスペイン語-ポルトガル語ペアのためのWMT 21類似言語タスク', 'hi': 'T4T समाधान: WMT21 स्पेनिश-कैटलन और स्पेनिश-पुर्तगाली भाषा जोड़ी के लिए समान भाषा कार्य', 'zh': 'T4T 解决方案曰:西班牙语-加泰罗尼亚语与西班牙语-葡萄牙语对 WMT21 类言', 'ru': 'Решение T4T: аналогичная языковая задача WMT21 для испано-каталанской и испано-португальской языковой пары', 'ga': 'Réiteach T4T: WMT21 Tasc Teanga Comhchosúla don Phéire Teanga Spáinnis-Catalóinis agus Spáinnis-Portaingéilis', 'hu': 'T4T megoldás: WMT21 Hasonló nyelvi feladat a spanyol-katalán és spanyol-portugál nyelvpár számára', 'ka': 'Name', 'el': 'Λύση Τ4Τ: Παρόμοια γλωσσική εργασία για το ζευγάρι Ισπανικών-Καταλανικών και Ισπανικών-Πορτογαλικών γλωσσών', 'it': 'Soluzione T4T: WMT21 Attività linguistica simile per la coppia di lingue spagnolo-catalano e spagnolo-portoghese', 'kk': 'T4T шешу: WMT21 Испан- Каталан және Испан- Португалиялық тіл пары үшін ұқсас тіл тапсырмасы', 'ms': 'Solusi T4T: Tugas Bahasa Serupa WMT21 untuk Pasangan Bahasa Spanyol-Catalan dan Spanyol-Portugis', 'mk': 'T4T решение: WMT21 слична задача на јазик за шпанско-каталонско и шпанско-португалско јазик пар', 'ml': 'സ്പാനിഷ്- കാത്താലാനും സ്പാനിഷ്- പോര്\u200dട്ടുഗീസ് ഭാഷ പായിരിക്കുന്നതിനും വിഎംടി21 സമമായ ഭാഷ', 'mn': 'T4T шийдэл: WMT21 Испан-Каталан, Испан-Португалийн хэл Pair', 'mt': 'T4T Soluzzjoni: WMT21 Kompitu Lingwistiku Similari għall-Paġna tal-Lingwistiċi Spanjola-Katalana u Spanjola-Portugiża', 'no': 'T4T- løysing: WMT21- like språk- oppgåve for spansk- katalansk og spansk- portugisisk språk Pair', 'lt': 'T4T sprendimas: WMT21 Panaši kalbos užduotis Ispanijos, katalonų ir ispanų, portugalų kalbų porai', 'ro': 'Soluție T4T: WMT21 Activitate lingvistică similară pentru perechea de limbi spaniolă-catalană și spaniolă-portugheză', 'pl': 'Rozwiązanie T4T: WMT21 Podobne zadanie językowe dla pary językowej hiszpańsko-katalońskiej i hiszpańsko-portugalskiej', 'sr': 'T4T Rešenje: WMT21 slični jezik zadatak za španjolski-katalanski i španjolski-portugalski pair jezika', 'si': 'Name', 'ta': 'T4T தீர்வு', 'so': 'T4T: WMT21 Shaqada u eg luqada Ispanish-Catalan iyo Pair Luqada Isbanish-Burtuqiis', 'ur': 'T4T حل: WMT21 جیسا زبان تاسک اسپانیایی-کاتالان اور اسپانیایی-پورٹوگل زبان پار کے لئے', 'sv': 'T4T-lösning: WMT21 Liknande språkuppgift för spansk-katalanska och spansk-portugisiska språkparet', 'uz': 'T4T toĘ»xtatish: WMT21 oĘ»xshash tillar Vazifani Ispaniya- Katalan va Ispanish- Portugalcha tili toĘ»plami uchun vazifa', 'vi': 'Tìm giải: giải pháp ngôn ngữ kiểu WM21 Giống như của Tây Ban Nha và Tây Ban Nha-Bồ Đào Nha', 'bg': 'Решение: Подобна езикова задача за испанско-каталонската и испанско-португалската езикова двойка', 'nl': 'T4T Oplossing: WMT21 Vergelijkbare Taaltaak voor het Spaans-Catalaans en Spaans-Portugees Taalpaar', 'da': 'T4T Løsning: WMT21 Lignende sprogopgave for spansk-catalansk og spansk-portugisisk sprogpar', 'hr': 'T4T rješenje: WMT21 slični jezički zadatak za španjolski-katalanski i španjolski-portugalski pair jezika', 'de': 'T4T Lösung: WMT21 Ähnliche Sprachaufgabe für das Spanisch-Katalanische und Spanisch-Portugiesische Sprachpaar', 'fa': 'حل T4T: WMT21 کار زبان شبیه برای جفت زبان اسپانیایی-کاتالان و اسپانیایی-پورتوژیک', 'ko': 'T4T 솔루션: 스페인어 - 카탈로니아어 및 스페인어 - 포르투갈어 쌍을 위한 WMT21 유사 언어 작업', 'sw': 'T4T Solution: Kazi ya Lugha inayofanana na WMT21 kwa Kihispania-Katalani na Pair ya Lugha ya Kihispania-Kireno', 'tr': 'T4T çözgüt: WMT21 Öňlikli dil Ispanýol-Katalança we Ispanýol-Portugalça dilleri Par', 'af': 'T4T Oplossing: WMT21 Similar Taal Opdrag vir die Spaanse-Katalaanse en Spaanse-Portugese Taal Pair', 'sq': 'Zgjidhje T4T: WMT21 Gjuha e ngjashme për çiftin spanjoll-katalan dhe spanjoll-portugal', 'hy': 'T4T Solution: WMT21 Similar Language Task for the Spanish-Catalan and Spanish-Portuguese Language Pair', 'bn': 'T4T সমাধান: স্প্যানিশ-ক্যাটালান এবং স্প্যানিশ-পর্তুগীজ ভাষা প্যায়ারের জন্য WMT21 অনুরূপ ভাষার কাজ', 'am': 'የስፓኒሽ-ካትላንኛ እና ስፓኒሽ-ፖርቱጋልኛ ቋንቋ ማር', 'id': 'Solusi T4T: WMT21 Tugas Bahasa Sama untuk Pasangan Bahasa Spanyol-Catalan dan Spanyol-Portugis', 'bs': 'T4T Rešenje: WMT21 slični jezik zadatak za španjolski-katalanski i španjolski-portugalski pair jezika', 'az': 'T4T Çözünüş: WMT21 İspanyol-Katalan və İspanyol-Portugal Dili Pair üçün eyni dil Taski', 'cs': 'T4T řešení: WMT21 Podobná jazyková úloha pro španělsko-katalánský a španělsko-portugalský jazykový pár', 'et': 'T4T lahendus: WMT21 sarnane keeleülesanne hispaania-katalaani ja hispaania-portugali keelepaarile', 'ca': 'T4T Solution: WMT21 Similar Language Task for the Spanish-Catalan and Spanish-Portuguese Language Pair', 'fi': 'T4T Ratkaisu: WMT21 Samanlainen kielitehtävä espanja-katalaani ja espanja-portugali kieliparille', 'jv': 'R4T Sing Resolusi: WTS 2 Samsul Language Job kanggo Spanish-Catalan lan Spanish-portugis Language Pair', 'ha': 'KCharselect unicode block name', 'sk': 'Rešitev T4T: WMT21 Podobna jezikovna naloga za špansko-katalonski in špansko-portugalski jezikovni par', 'bo': 'T4T Solution: WMT21 Similar Language Task for the Spanish-Catalan and Spanish-Portuguese Language Pair', 'he': 'T4T פתרון: WMT21 משימה שפת דומה לזוג שפת ספרדית-קטלנית וספרדית-פורטוגזית'}
{'en': 'The main idea of this ', 'ar': 'كانت الفكرة الرئيسية لهذا الحل هي التركيز على تنظيف الجسم وإعداده وبعد ذلك ، استخدم حلًا خارج الصندوق (OpenNMT) مع نموذج المحول الافتراضي المنشور. لتحضير المجموعة ، استخدمنا مجموعة من الأدوات القياسية (مثل نصوص موسى أو حزم بيثون) ، ولكن أيضًا ، من بين نصوص بايثون الأخرى ، أداة رمزية مخصصة للبيثون مع القدرة على استبدال الأرقام للمتغيرات ، وحل مشكلة الأحرف الكبيرة والصغيرة من المفردات وتوفر تقسيمًا جيدًا لمعظم علامات الترقيم. لقد بدأنا أيضًا خطًا لتنظيف الجسم بناءً على تقدير الاحتمال الإحصائي لجسم المصدر والهدف ، مع نتائج غير واضحة. أيضًا ، أجرينا بعض الاختبارات بتجزئة الكلمات المقطعية ، مرة أخرى بنتائج غير واضحة ، لذلك في النهاية ، بعد ترميز جملة الكلمات ، استخدمنا BPE SentencePiece لوحدات الكلمات الفرعية لتغذية OpenNMT.', 'fr': "L'idée principale de cette solution a été de se concentrer sur le nettoyage et la préparation du corpus, puis d'utiliser une solution prête à l'emploi (OpenNMT) avec son modèle de transformateur publié par défaut. Pour préparer le corpus, nous avons utilisé un ensemble d'outils standard (comme des scripts Moses ou des packages Python), mais aussi, entre autres scripts Python, un tokenizer personnalisé Python avec la capacité de remplacer les nombres pour les variables, de résoudre le problème des majuscules et des minuscules du vocabulaire et de fournir une bonne segmentation pour la plupart des ponctuation. Nous avons également lancé une ligne de nettoyage de corpus basée sur l'estimation statistique de la probabilité du corpus source-cible, avec des résultats peu clairs. En outre, nous avons effectué quelques tests avec la segmentation des mots syllabiques, encore une fois avec des résultats peu clairs, donc à la fin, après la segmentation des phrases de mots, nous avons utilisé BPE SentencePiece pour les unités de sous-mots pour alimenter OpenNMT.", 'pt': 'A ideia principal desta solução foi focar na limpeza e preparação do corpus e depois disso, usar uma solução pronta para uso (OpenNMT) com seu modelo de transformador padrão publicado. Para preparar o corpus, usamos um conjunto de ferramentas padrão (como scripts Moses ou pacotes python), mas também, entre outros scripts python, um tokenizer personalizado python com a capacidade de substituir números por variáveis, resolver o problema de maiúsculas/minúsculas de o vocabulário e fornecem boa segmentação para a maior parte da pontuação. Também iniciamos uma linha para limpar o corpus com base na estimativa estatística de probabilidade do corpus fonte-alvo, com resultados pouco claros. Além disso, executamos alguns testes com segmentação de palavras silábicas, novamente com resultados pouco claros, portanto, no final, após a tokenização de frases de palavras, usamos BPE SentencePiece para unidades de subpalavras para alimentar o OpenNMT.', 'es': 'La idea principal de esta solución ha sido centrarse en la limpieza y preparación del cuerpo y, después, utilizar una solución lista para usar (OpenNMT) con su modelo de transformador publicado por defecto. Para preparar el corpus, hemos utilizado un conjunto de herramientas estándar (como scripts de Moses o paquetes de Python), pero también, entre otros scripts de Python, un tokenizador personalizado de Python con la capacidad de reemplazar números por variables, resolver el problema de mayúsculas y minúsculas del vocabulario y proporcionar una buena segmentación para la mayoría de los puntuación. También hemos iniciado una línea para limpiar el corpus basado en la estimación de probabilidad estadística del corpus fuente-destino, con resultados poco claros. Además, hemos realizado algunas pruebas con segmentación de palabras silábicas, de nuevo con resultados poco claros, por lo que al final, después de la tokenización de frases de palabras, hemos utilizado BPE SentencePiece para unidades de subpalabras para alimentar OpenNMT.', 'ja': 'このソリューションの主なアイデアは、コーパスの洗浄と準備に焦点を当て、その後、デフォルトで公開されている変圧器モデルと共に箱外ソリューション（ OpenNMT ）を使用することです。コーパスを準備するために、標準的なツール（ MosesスクリプトまたはPythonパッケージなど）のセットを使用していますが、他のPythonスクリプトの中でも、変数の数値を置き換え、語彙の大文字/小文字の問題を解決し、句読点のほとんどに適切なセグメンテーションを提供することができるPythonカスタムトークナイザーも使用しています。また、ソース-ターゲットコーパスの統計的確率推定に基づいてコーパスをクリーンアップするラインを開始し、結果は不明です。また、音節単位の単語セグメンテーションを使用していくつかのテストを実行しましたが、再び結果が不明瞭なため、最後に、単語文トークン化の後、OpenNMTをフィードするためにサブワードユニットにBPE SentencePieceを使用しました。', 'zh': '凡解决方案之要,在于语料库清备,用开箱即用解决方案(OpenNMT)及其默认发之变压器。 为具语料库,用格具(如Moses脚本、python包),然其他python脚本中,又有python自定义分词器,能易变量数,决词汇大书/小写,多标点符号良分。 又以源语料库之计概率度始清语料库之行,未可知也。 此外音节分词行而试之,一不可知,故最后,标化单词句之后,BPE SentencePiece为子单词单元以供OpenNMT食。', 'ru': 'Основная идея этого решения заключалась в том, чтобы сосредоточиться на очистке и подготовке корпуса, а затем использовать готовое решение (OpenNMT) с его моделью трансформатора, опубликованной по умолчанию. Для подготовки корпуса мы использовали набор стандартных инструментов (таких как скрипты Мозеса или пакеты питона), а также, среди других скриптов питона, пользовательский токенизатор питона с возможностью замены чисел на переменные, решения проблемы верхнего/нижнего регистра словарного запаса и обеспечения хорошей сегментации для большей части пунктуации. Мы также начали линию по очистке тела на основе статистической оценки вероятности тела источника-цели, с неясными результатами. Кроме того, мы провели некоторые тесты со слоговым сегментированием слов, опять же с неясными результатами, поэтому в конце, после токенизации слов, мы использовали BPE SentencePiece для подсловов, чтобы кормить OpenNMT.', 'hi': 'इस समाधान का मुख्य विचार कॉर्पस सफाई और तैयारी पर ध्यान केंद्रित करना रहा है और उसके बाद, अपने डिफ़ॉल्ट प्रकाशित ट्रांसफार्मर मॉडल के साथ आउट ऑफ बॉक्स समाधान (ओपनएनएमटी) का उपयोग करें। कॉर्पस तैयार करने के लिए, हमने मानक उपकरणों के सेट का उपयोग किया है (मूसा स्क्रिप्ट या पायथन पैकेज के रूप में), लेकिन यह भी, अन्य पायथन स्क्रिप्ट के बीच, चर के लिए संख्याओं को बदलने की क्षमता के साथ एक पायथन कस्टम टोकनाइज़र, शब्दावली के ऊपरी / निचले मामले के मुद्दे को हल करें और अधिकांश विराम चिह्नों के लिए अच्छा विभाजन प्रदान करें। हमने अस्पष्ट परिणामों के साथ स्रोत-लक्ष्य कॉर्पस के सांख्यिकीय संभाव्यता अनुमान के आधार पर कॉर्पस को साफ करने के लिए एक लाइन भी शुरू की है। इसके अलावा, हमने सिलेबल शब्द विभाजन के साथ कुछ परीक्षण चलाए हैं, फिर से अस्पष्ट परिणामों के साथ, इसलिए अंत में, शब्द वाक्य टोकनीकरण के बाद हमने ओपनएनएमटी को खिलाने के लिए सबवर्ड इकाइयों के लिए बीपीई वाक्यपीस का उपयोग किया है।', 'ga': "Ba é príomh-smaoineamh an réitigh seo ná díriú ar ghlanadh agus ullmhú corpais agus ina dhiaidh sin, úsáid a bhaint as réiteach as an mbosca (OpenNMT) lena mhúnla réamhshocraithe claochladáin foilsithe. Chun an corpas a ullmhú, d'úsáideamar tacair uirlisí caighdeánacha (mar scripteanna Moses nó pacáistí python), ach freisin, i measc scripteanna python eile, tokenizer saincheaptha python a bhfuil an cumas uimhreacha a athsholáthar le haghaidh athróg, an cheist cás uachtair/íochtair a réiteach. an foclóir agus cuireann siad deighilt mhaith ar fáil don chuid is mó den phoncaíocht. Tá tús curtha againn freisin le corpas a ghlanadh bunaithe ar mheastachán dóchúlachta staitistiúla ar an gcorpas foinse-sprioc, le torthaí doiléir. Chomh maith leis sin, rinneamar roinnt tástálacha le deighilt siollabach focal, arís le torthaí doiléir, mar sin ag an deireadh, tar éis tokenization abairt focal d'úsáideamar BPE SentencePiece le haghaidh aonaid fofhocail chun OpenNMT a bheathú.", 'hu': 'Ennek a megoldásnak a fő ötlete az volt, hogy a corpus tisztítására és előkészítésére összpontosítsunk, majd ezt követően használjunk egy out of box megoldást (OpenNMT) az alapértelmezett publikált transzformátor modelljével. A korpusz előkészítéséhez szabványos eszközöket (Moses szkripteket vagy python csomagokat) használtunk, de többek között egy python szkriptet is, amely képes a változók számát helyettesíteni, megoldani a szókincs nagy/kisebb nagybetűs problémáját és jó szegmentálást biztosítani a legtöbb írásjelzés számára. A korpusz tisztítására irányuló vonalat is elindítottunk a forrás-cél korpusz statisztikai valószínűségi becslése alapján, tisztázatlan eredményekkel. Továbbá elvégeztünk néhány tesztet szótagos szegmentációval, ismét tisztázatlan eredményekkel, így a végén, a szómondatok tokenizációja után BPE SentencePiece-t használtunk alszóegységekhez az OpenNMT táplálására.', 'el': 'Η κύρια ιδέα αυτής της λύσης ήταν να επικεντρωθεί στον καθαρισμό και την προετοιμασία του σώματος και μετά να χρησιμοποιηθεί μια λύση εκτός κουτιού (OpenNMT) με το προεπιλεγμένο δημοσιευμένο μοντέλο μετασχηματιστή. Για να προετοιμάσουμε το σώμα, έχουμε χρησιμοποιήσει ένα σύνολο τυποποιημένων εργαλείων (όπως σενάρια Moses ή πακέτα Python), αλλά επίσης, μεταξύ άλλων σεναρίων Python, ένα προσαρμοσμένο Tokenizer Python με τη δυνατότητα να αντικαταστήσει αριθμούς για μεταβλητές, να λύσει το θέμα των κεφαλαίων/μικρών κεφαλαίων του λεξιλογίου και να παρέχει καλή τμηματοποίηση για το μεγαλύτερο μέρος της στίξης. Επίσης, έχουμε ξεκινήσει μια γραμμή καθαρισμού σώματος βασισμένη στη στατιστική εκτίμηση πιθανοτήτων του σώματος προέλευσης-στόχου, με ασαφές αποτελέσματα. Επίσης, έχουμε εκτελέσει κάποιες δοκιμές με συλλαβική κατάτμηση λέξεων, και πάλι με ασαφές αποτελέσματα, έτσι στο τέλος, μετά την επισήμανση λέξεων προτάσεων χρησιμοποιήσαμε για μονάδες υπολέξεων για να τροφοδοτήσουμε το OpenNMT.', 'ka': 'ამ პასუხის მნიშვნელოვანი იდეა იყო, რომ კორპუსს წაშლა და დაეყენება და შემდეგ გამოყენება კონფიგური პასუხის (OpenNMT) გამოყენება მისი ნაგულისხმებით გამოუშავებული რენ კორპუსს დააყენებლად, ჩვენ გამოყენეთ სტანდარტური ხელსაწყოების ნაწილი (როგორც მოსექსი სკრიპტი ან ოთტონის პოქეტები), მაგრამ სხვა პირონის სკრიპტის შორის, პირონის განსხვავებული ტოკენიზერი შესაძლებლობა გადაცვლა რიცხვების შესაძლებლო ჩვენ ასევე დავიწყეთ ხაზი, რომელიც სტატისტიკური შესაძლებლობა სტატისტიკური შესაძლებლობაზე გადავიწყეთ მსოფლიო სტატისტიკური შესაძლებლობა, რო ასევე, ჩვენ ვაკეთებთ რამდენიმე ტესტი სილაბიკულ სიტყვების სექმენტით, ახლა უცნობიერი წარმოდგენებით, ასე რომ საკუთარი წარმოდგენებით, როდესაც სიტყვების ტოკენიზაციის შემდეგ ჩვენ გამოყ', 'it': "L'idea principale di questa soluzione è stata quella di concentrarsi sulla pulizia e preparazione del corpo e, successivamente, utilizzare una soluzione fuori scatola (OpenNMT) con il suo modello di trasformatore predefinito pubblicato. Per preparare il corpus, abbiamo utilizzato un set di strumenti standard (come script Moses o pacchetti python), ma anche, tra gli altri script python, un tokenizer personalizzato python con la possibilità di sostituire i numeri per variabili, risolvere il problema maiuscolo/minuscolo del vocabolario e fornire una buona segmentazione per la maggior parte della punteggiatura. Abbiamo anche avviato una linea per pulire il corpo basata sulla stima statistica della probabilità del corpo sorgente-bersaglio, con risultati poco chiari. Inoltre, abbiamo eseguito alcuni test con segmentazione sillabica delle parole, sempre con risultati poco chiari, quindi alla fine, dopo la tokenizzazione delle parole abbiamo usato BPE SentencePiece per le unità di sottoparola per alimentare OpenNMT.", 'kk': 'Бұл шешімінің негізгі идеясы - корпус тазалау мен дайындау үшін көздеген және содан кейін, әдетті жарияланған түріндіру үлгісімен (OpenNMT) терезесінің шешімін қолдану. Корпусты дайындау үшін, біз стандартты құрылғыларды (Моисея скрипттері не питон дестелері ретінде) қолдандық, сондай-ақ басқа питон скрипттерінің арасында, айнымалыларды алмастыруға мүмкіндік беретін питон таңбашасы, сөздердің үлкен/ кіші әріптерін шешу және көп Мұндай-ақ біз корпус бағдарламасының статистикалық мақсаттық корпус бағалауына негізделген жолды тазаладық. Сонымен қатар, біз сөздерді сөздердің сегментациясы арқылы бірнеше сынақтарды жұмыс істедік. Сонымен соңында сөздердің токенизациясынан кейін, OpenNMT- тің ішкі сөздердің бірлігі үшін BPE SentencePiece- ті қолдан', 'ms': 'Idea utama penyelesaian ini adalah untuk fokus pada pembersihan dan persiapan corpus dan selepas itu, guna penyelesaian luar kotak (OpenNMT) dengan model pengubah diterbitkan lalai. To prepare the corpus, we have used set of standard tools (as Moses scripts or python packages), but also, among other python scripts, a python custom tokenizer with the ability to replace numbers for variables, solve the upper/lower case issue of the vocabulary and provide good segmentation for most of the punctuation.  Kami juga telah memulakan garis untuk membersihkan corpus berdasarkan penilaian kemungkinan statistik corpus sumber-sasaran, dengan keputusan yang tidak jelas. Juga, kami telah menjalankan beberapa ujian dengan segmen perkataan silabas, lagi dengan keputusan yang tidak jelas, jadi pada akhirnya, selepas tokenisasi perkataan kalimat kami telah menggunakan BPE SentencePiece untuk unit subword untuk memberi makan OpenNMT.', 'mk': 'The main idea of this solution has been to focus on corpus cleaning and preparation and after that, use an out of box solution (OpenNMT) with its default published transformer model.  За да го подготвиме корпусот, употребивме сет стандардни алатки (како Мојсеј скрипти или питонски пакети), но исто така, меѓу другите питонски скрипти, питонски сопствен токенизатор со способност да ги замени броевите за променливи, да го решиме прашањето на горниот/нискиот случај на речникот и да обезбеди добра сегментација за повеќето од точките Исто така, започнавме линија за чистење на корпусот врз основа на статистичката проценка на веројатноста на корпусот извор-мета, со нејасни резултати. Исто така, спроведовме некои тестови со силабална сегментација на зборовите, повторно со нејасни резултати, па на крајот, по токенизацијата на зборовите реченици, користевме BPE SentencePiece за подзборовите единици за храна на OpenNMT.', 'ml': 'ഈ പരിഹാരത്തിന്റെ പ്രധാന ആശയം കോര്\u200dപ്പുസ് വൃത്തിയാക്കുന്നതിനും തയ്യാറാക്കുന്നതിനും ശേഷം അതിനുശേഷം പെട്ടിയില്\u200d നിന്നും ഒരു പുറത കോര്\u200dപ്പുസ് തയ്യാറാക്കാന്\u200d ഞങ്ങള്\u200d സാധാരണ ഉപകരണങ്ങള്\u200d ഉപയോഗിച്ചിരിക്കുന്നു (മോസായുടെ സ്ക്രിപ്റ്റുകളോ പൈത്തോന്\u200d പാക്കേജുകളോ പോലെ), മറ്റു പൈത്തോന്\u200d സ്ക്രിപ്റ്റുകളിലും, മാറ്റങ്ങള്\u200dക്ക് സം നമ്മള്\u200d ഒരു ലൈന്\u200d തുടങ്ങിയിരിക്കുന്നു വൃത്തിയാക്കാന്\u200d കോര്\u200dപ്പുസിന്\u200dറെ സിസ്റ്റിക്കല്\u200d സാധ്യതയുള്ള ഊഹിപ്പിന്\u200dറെ  അതുകൊണ്ട്, ഞങ്ങള്\u200d ചില പരീക്ഷണങ്ങള്\u200d സിലാബിക്കല്\u200d വാക്കുകളുടെ വേര്\u200dഡ് പിങ്ങേഷന്\u200d കൊണ്ട് പ്രവര്\u200dത്തിച്ചിട്ടുണ്ട്, വീണ്ടും അപരിചിതമായ ഫലങ്ങള്\u200d കൊണ്ട്, അതുകൊണ', 'mt': 'L-idea ewlenija ta’ din is-soluzzjoni kienet li tiffoka fuq it-tindif u l-preparazzjoni tal-korpus u wara dan, tuża soluzzjoni barra mill-kaxxa (OpenNMT) bil-mudell tat-trasformatur ippubblikat b’mod awtomatiku. Biex tħejji l-korpus, użajna sett ta’ għodod standard (bħala skripti ta’ Moses jew pakketti ta’ python), iżda wkoll, fost skripti oħra ta’ python, tokenizer personalizzat bil-ħila li jissostitwixxi n-numri għal varjabbli, issolvi l-kwistjoni tal-każ ta’ fuq/inqas tal-vokabulari u tipprovdi segmentazzjoni tajba għall-biċċa l-kbira tal-puntwazzjoni. Aħna bdejna wkoll linja li tnaddaf il-korpus ibbażata fuq stima tal-probabbiltà statistika tal-korpus sors-mira, b’riżultati mhux ċari. Barra minn hekk, għamilna xi testijiet bis-segmentazzjoni tal-kliem sillabiku, għal darb’oħra b’riżultati mhux ċari, għalhekk fl-aħħar, wara t-tokenizzazzjoni tas-sentenza tal-kliem użajna BPE SentencePiece għal unitajiet ta’ sottokliem biex nużaw OpenNMT.', 'lt': 'Pagrindinė šio sprendimo idėja buvo sutelkti dėmesį į korpuso valymą ir paruošimą, o vėliau naudoti išorinį tirpalą (OpenNMT) su savo numatytu paskelbtu transformatoriaus modeliu. Norėdami paruošti korpusą, mes naudojome standartinių priemonių rinkinį (kaip Mozės scenarijai arba python paketai), bet taip pat, be kitų python scenarijų, python specialus tokenizer su gebėjimu pakeisti kintamųjų skaičių, išspręsti didžiausią ir mažesnę žodyno bylą ir užtikrinti gerą segmentaciją daugumai taškų. Mes taip pat pradėjome liniją, kuria siekiama švaryti korpusą, pagrįstą statistiniu tikslinio korpuso tikimybės įvertinimu, su neaiškiais rezultatais. Be to, atlikome keletą bandymų su silabine žodžių segmentacija, dar kartą su neaiškūs rezultatai, taigi galiausiai, po žodžio sakinio tokenizacijos mes naudojome BPE SentencePiece subword vienetams OpenNMT maitinti.', 'pl': 'Główną ideą tego rozwiązania było skupienie się na czyszczeniu i przygotowaniu korpusów, a następnie zastosowanie rozwiązania gotowego (OpenNMT) z domyślnym opublikowanym modelem transformatora. Do przygotowania korpusu użyliśmy zestawu standardowych narzędzi (jak skrypty Mosesa czy pakiety pythona), ale także, między innymi skrypty pythona, niestandardowego tokenizera pythona z możliwością zastępowania liczb zmiennych, rozwiązywania problemu małych i dużych liter słownictwa oraz zapewnienia dobrej segmentacji większości interpunkcji. Rozpoczęliśmy również linię czyszczenia korpusu opartą na statystycznej ocenie prawdopodobieństwa korpusu źródłowo-docelowego, z niejasnymi wynikami. Przeprowadziliśmy również kilka testów z segmentacją słów sylabicznych, ponownie z niejasnymi wynikami, więc na koniec, po tokenizacji zdań słowowych użyliśmy BPE SentencePiece dla jednostek podsłów do zasilania OpenNMT.', 'ro': 'Ideea principală a acestei soluții a fost de a se concentra pe curățarea și pregătirea corpurilor și, după aceea, utilizarea unei soluții out of box (OpenNMT) cu modelul său implicit de transformator publicat. Pentru a pregăti corpul, am folosit un set de instrumente standard (cum ar fi scripturile Moses sau pachetele python), dar și, printre alte scripturi python, un tokenizer personalizat python cu capacitatea de a înlocui numerele pentru variabile, de a rezolva problema majuscule/mici a vocabularului și de a oferi o segmentare bună pentru majoritatea punctuației. De asemenea, am început o linie de curățare a corpului bazată pe estimarea probabilității statistice a corpului sursă-țintă, cu rezultate neclare. De asemenea, am executat câteva teste cu segmentare silabică a cuvintelor, din nou cu rezultate neclare, astfel încât la sfârșit, după tokenizarea frazei de cuvinte am folosit BPE SentencePiece pentru unitățile de subcuvinte pentru a alimenta OpenNMT.', 'mn': 'Энэ шийдэлийн гол санаа нь корпус цэвэрлэх, бэлтгэл зориулах, дараа нь хайрцаг шийдэлээс (OpenNMT) ашиглах гэсэн үг. Корпус бэлдэхийн тулд бид стандарт хэрэгслүүдийг (Моссеийн скрипт эсвэл питон багцлагуудын тулд) ашиглаж байна. Мөн бусад питон скриптуудын тулд, тоонуудыг өөрчлөх чадвартай питон хувилбаруудын тулд тоонуудыг орлуулах чадвартай, үгүйсгэлийн том/жижиг хэсгийг шийдвэрл Мөн бид эх үүсвэр зорилготой корпусын статистикийн магадлалын тооцооллоор корпус цэвэрлэх шугам эхэлсэн. Мөн бид хэдэн үг хэмжээгээр шалгалт хийсэн. Дахин тодорхой үр дүнтэй. Тэгэхээр үг хэмжээний тодорхойлолтын дараа бид OpenNMT-г хооллох үед BPE SentencePiece-г ашигласан.', 'sr': 'Glavna ideja ovog rješenja je bila da se fokusiramo na čišćenje i pripremu korpusa i nakon toga koristimo izvan rešenja kutija (OpenNMT) sa svojim standardnim objavljenim modelom transformera. Da bi pripremili korpus, koristili smo set standardnih alata (kao što su Mosesovi skripti ili pitonski paketi), ali takođe, među drugim pitonskim skriptima, pitonski tokenizer običnog tokenizača sa sposobnošću zamijeniti brojeve za promjene, rešiti problem većih/manjih slučajeva rečenika i pružiti dobru segmentaciju za većinu tačke. Takođe smo započeli liniju za čišćenje korpusa na osnovu statističke procjene verovatnosti korpusa iz izvora ciljeva, sa neobičnim rezultatima. Takoðe, pokrenuli smo neke testove sa silabetskom segmentacijom reèi, opet sa neèistim rezultatima, pa na kraju, nakon tokenizacije reèi, koristili smo BPE SentencePiece za podreèi jedinice za hranu OpenNMT.', 'si': 'මේ විස්තරයේ ප්\u200dරධාන අදහස් තියෙන්නේ කොර්පස් සුදුසුම් සහ සූදානම් සඳහා පස්සේ, පොක්ස් විස්තරය (OpenNMT) වලින් ප්\u200dරතිර කොර්පස් සූදානම් කරන්න, අපි ප්\u200dරමාණික උපකරණ සූදානම් භාවිත කරලා තියෙනවා (මොසේස් ස්ක්\u200dරිප්ට් හා පිතෝන් පැකේජ් වලින්), ඒත්, අනිත් පිතෝන් ස්ක්\u200dරිප්ට් වලින්, පිත අපි පටන් ගත්තා කොර්පස් එක්ක සුදුසුම් කරන්න පටන් ගත්තා ඉදිරිපත්ත කොර්පස් එක්ක ස්ථානික විශ්වාසික විශ අපි සිලැබිකාල් වචන විශේෂණය සමග පරීක්ෂණා කරලා තියෙනවා, ආයෙත් අනිවාර්ය ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරත', 'ta': 'இந்த தீர்வின் முக்கிய ய யோசனை கார்ப்ஸ் சுத்தம் மற்றும் தயாரிப்பு மீது கவனம் செலுத்த வேண்டும். பின்னர் பெட்டி தீர்வு (OpenNMT) அதன்  கார்ப்ஸை தயாராக்க, நாம் நிலையான கருவிகளை பயன்படுத்தியுள்ளோம் (மூஸா சிறுநிரல் அல்லது பைதான் தொகுப்புகள் என்று) ஆனால் மற்ற பைதான் சிறுநிரல்களில், மாறிகளுக்கு எண்களை மாற்ற முடியும் பைதான்  We also have started a line to clean corpus based on statistical probability estimation of source-target corpus, with unclear results.  மேலும், நாம் சில சோதனைகளை செயல்படுத்தி வார்த்தை பிரிவுகளுடன், மீண்டும் தெரியாத விளைவுகளுடன், முடிவில், வார்த்தை குறிப்பிடும் பின்னர், நாம் துணை ச', 'no': 'Hovudsideen for denne løysinga er å fokusera på opprydding og forberedning av korpus og etter det bruka eit utboks- løysing (OpenNMT) med standardmodellen for utgjeven transformering. For å forberede korpusen, har vi brukt sett av standardverktøya (som Moses scripts eller python-pakkar), men også, blant andre Python-skriptar, ein python-eigne tokenisering med kapasiteten for å byta ut nummer for variabler, løysa oppgåva for store/små bokstavar av ordboka og gi god segmentasjon for dei fleste punktane. Vi har også starta ein linje for å tømme korpus basert på statistiske sannsynlighetsgrense for kjeldemålkorpus, med ukjende resultat. Vi har også køyrt nokre testar med syllabical ordsegmentasjon, igjen med ukjende resultat, så på slutten, etter tokenisering av ordsetningar har vi brukt BPE SentencePiece for underordeiningar for å køyre OpenNMT.', 'so': 'Fikirada ugu horeeya ee ay tahay inay ku kalsoonaadaan daahirinta iyo diyaarinta qoyska, waxaadna ka dib isticmaaleysaa xafiiska boxeed (OpenNMT) iyadoo ku qoran modelka bedelka oo la soo bandhigay. Si aannu u diyaarinno qofka, waxaan u isticmaalnay alaabta caalamiga ah (sida qorniinka Muuse ama baakadaha python), laakiin waxaan kaloo ku dhex jirnay qorniinka kale ee warqadaha python, kaasoo awood u leh in uu ku beddelo lambarka kala beddelada, si aad u xallisid arrimaha ugu sarreeya/hooseeya ee ereyga iyo in lagu sameeyo qayb wanaagsan. Sidoo kale waxaan bilownay xadhig aan nadiifsanno, taasoo lagu saleyn karo qiimeynta qiimaha rasmiga ah oo ay leedahay midhihiisa aan aqoon lahayn. Sidoo kale waxaynu imtixaanka qaarkood ku soconnay qeybinta hadalka galmada ah, mar kalena waxaynu ku soconnay resulto aan aqoon lahayn, sidaas darteed ugu dambaysta, qeybta ereyga ka dib waxaynu u u isticmaalnay BPE Heshiiska hoose-word si aan u quudinno OpenNMT.', 'sv': 'Huvudidén med denna lösning har varit att fokusera på korpusrengöring och beredning och därefter använda en out of box lösning (OpenNMT) med sin standardpublicerade transformatormodell. För att förbereda korpusen har vi använt oss av en uppsättning standardverktyg (som Moses-skript eller python-paket), men också, bland andra python-skript, en python anpassad tokenizer med möjlighet att ersätta tal för variabler, lösa det stora / små bokstäverna i ordförrådet och ge bra segmentering för de flesta av skiljetecken. Vi har också startat en linje för att rensa corpus baserat på statistisk sannolikhetsuppskattning av käll-målcorpus, med oklara resultat. Vi har också kört några tester med stavelsemässig ordsegmentering, återigen med oklara resultat, så i slutet, efter ordfrastokenisering har vi använt BPE SentencePiece för underordenheter för att mata OpenNMT.', 'ur': 'اس حل کی اصلی نظر یہ ہے کہ کورپوس پاکیزگی اور تیار کرنے پر تمرکز کرنا اور اس کے بعد بوکس کے حل (OpenNMT) سے ایک بیرون سے استعمال کرنا اس کے ڈیلٹ پیغام رسانٹر موڈل کے ساتھ۔ کورپوس کو تیار کرنے کے لئے ہم نے استاندارڈ ابزار (موسیٰ کے اسکریٹ یا پیٹون پاکیزوں کی طرح) استعمال کیا ہے، لیکن دوسرے پیٹون کے اسکریٹوں میں بھی ایک پیٹون طریقہ ٹوکنیزر کو بدلنے کے قابل رکھتا ہے کہ شماروں کو بدلنے کے لئے بدل سکیں، کلام کے اوپر/کم کس مسئلہ کو حل کریں اور بہترین نقطہ کے لئے ا ہم نے بھی ایک لائن شروع کی ہے کہ اسٹیسٹی امکانات کے مطابق سفید کرپوس کو سفید کرنا شروع کیا ہے، اس کے مطابق غیر معلوم نتائج کے ساتھ. اور ہم نے سیلابیکل لفظ سٹمنٹ کے ساتھ کچھ آزمائش کیا ہے، دوبارہ غیر معلوم نتیجے کے ساتھ، سو آخر میں لفظ ٹوکینیٹ کے بعد ہم نے OpenNMT کو کھانا کھلانے کے لئے BPE SentencePiece کو استعمال کیا ہے.', 'uz': "Ushbu tuzuvning asosiy fikri, corpus tozalash va tayyorlash uchun foydalanadi va keyin buning chegarasining andoza ochilgan transformer modeli bilan foydalaning. Kopusni tayyorlash uchun biz Andoza vositalarni (Moses skriptlar yoki python paketlari kabi) ishlatdik, lekin boshqa python skriptlarda, o'zgarishlar uchun sonlarni almashtirish imkoniyati bilan python foydalanuvchisi, vositalarning eng yuqori/kichik muammolasini aniqlash va ko'pchilik uchun yaxshi qismlarni yaratish. Va biz bir necha chiziqni o'zgartirib boshladik, statistical qiymatning qiymatiga asoslangan asoslangan statistical qiymatni o'rganish mumkin, va muvaffaqiyatli natijalar bilan o'zgartirish mumkin. Piece for subword units to feed OpenNMT' ga bir necha sinov tizimni bajaramiz.", 'vi': 'Mục đích chính của giải pháp này là tập trung vào việc lau dọn và chuẩn bị vật thể và sau đó, sử dụng một giải pháp mở hộp (OpenNMT) với mẫu máy biến thế được xuất bản mặc định. Để chuẩn bị cho tập thể, chúng tôi đã sử dụng các công cụ tiêu chuẩn (như kịch bản của Moses hoặc các gói mãng xà), nhưng cũng, trong những tập thể nhiều khác, một máy phát biểu tự động phấn đấu với khả năng thay thế số lượng cho các biến số, giải quyết các trường hợp trên/ dưới của các từ điển và cung cấp phân biệt tốt cho phần lớn các chấm. Chúng tôi cũng đã bắt đầu một dòng để làm sạch tập thể dựa trên khả năng xác suất thống kê của tập đoàn đích nguồn, với kết quả chưa rõ ràng. Chúng tôi cũng đã chạy một số thử nghiệm với phân đoạn từ âm tiết, một lần nữa với kết quả không rõ ràng, vậy tại kết thúc, sau hiệu ứng từ cuối, chúng tôi đã sử dụng một vài tập tin đồn thổi của BPE cho các đơn vị chữ phụ để nuôi OpenNMT.', 'bg': 'Основната идея на това решение е да се съсредоточи върху почистването и подготовката на корпуса и след това да се използва изходно решение с публикувания по подразбиране трансформаторен модел. За изготвянето на корпуса сме използвали набор от стандартни инструменти (като Мойсей скриптове или пакети питон), но също така, наред с други питон скриптове, персонализиран токенизатор с възможност за заместване на числа за променливи, решаване на проблема с малки и големи букви на речника и осигуряване на добра сегментация за по-голямата част от пунктуацията. Започнахме и линия за изчистване на корпуса въз основа на статистическа оценка на вероятността източник-целеви корпуси, с неясни резултати. Също така, направихме някои тестове със сричка сегментация на думите, отново с неясни резултати, така че в края, след токенизирането на думите изречения, използвахме за подсловни единици за подаване на OpenNMT.', 'da': 'Hovedideen med denne løsning har været at fokusere på korpusrengøring og forberedelse og derefter bruge en out-of-box løsning (OpenNMT) med sin standard offentliggjorte transformermodel. For at forberede korpuset har vi brugt et sæt standardværktøjer (som Moses-scripts eller python-pakker), men også, blandt andre python-scripts, en python brugerdefineret tokenizer med evnen til at erstatte tal for variabler, løse problemet med store/små bogstaver i ordforrådet og give god segmentering for de fleste tegnsætninger. Vi har også startet en linje til rensning af corpus baseret på statistisk sandsynlighed estimering af kilde-mål corpus, med uklare resultater. Vi har også kørt nogle tests med stavelsesmæssig ordsegmentering, igen med uklare resultater, så i slutningen, efter ordsætning tokenisering har vi brugt BPE SentencePiece til underordsenheder til at fodre OpenNMT.', 'hr': 'Glavna ideja ovog rješenja bila je fokusiranje na čišćenje i pripremu korpusa i nakon toga, koristiti izvan otopine kutije (OpenNMT) sa svojim standardnim objavljenim modelom transformacije. Da bi pripremili korpus, koristili smo skup standardnih alata (kao što su Moses skripti ili Python paketi), ali također, među ostalim Python skriptima, piton obični tokenizer sa sposobnošću zamijeniti brojeve za promjene, riješiti problem riječi riječi o gornjem/nižim slučajevima i pružiti dobru segmentaciju za većinu bodova. Također smo započeli liniju za čišćenje korpusa na temelju statističke procjene vjerojatnosti korpusa iz izvora cilja, s nejasnim rezultatima. Također, pokrenuli smo neke testove sa silabetskom segmentacijom riječi, opet s nejasnim rezultatima, tako da na kraju, nakon tokenizacije rečenica, koristili smo BPE SentencePiece za podriječje jedinice za hranu OpenNMT-a.', 'nl': 'Het belangrijkste idee van deze oplossing was om zich te richten op corpusreiniging en voorbereiding en daarna gebruik te maken van een out of box oplossing (OpenNMT) met het standaard gepubliceerde transformatormodel. Om het corpus voor te bereiden, hebben we een set standaard tools gebruikt (zoals Moses scripts of python pakketten), maar ook, onder andere python scripts, een python custom tokenizer met de mogelijkheid om getallen voor variabelen te vervangen, het hoofdletterprobleem van de woordenschat op te lossen en een goede segmentatie te bieden voor het grootste deel van de interpunctie. We zijn ook begonnen met een lijn om corpus schoon te maken op basis van statistische waarschijnlijkheidsschatting van bron-doelcorpus, met onduidelijke resultaten. Ook hebben we een aantal tests uitgevoerd met syllabische woordsegmentatie, opnieuw met onduidelijke resultaten, dus aan het einde, na woordzinntokenisering hebben we BPE SentencePiece gebruikt voor subwoordeenheden om OpenNMT te voeden.', 'de': 'Die Hauptidee dieser Lösung war, sich auf die Korpusreinigung und -vorbereitung zu konzentrieren und danach eine Out-of-Box-Lösung (OpenNMT) mit ihrem standardmäßig veröffentlichten Transformatormodell zu verwenden. Um den Korpus vorzubereiten, haben wir eine Reihe von Standardwerkzeugen (wie Moses-Skripte oder Python-Pakete) verwendet, aber auch, neben anderen Python-Skripten, einen benutzerdefinierten Python-Tokenizer mit der Fähigkeit, Zahlen für Variablen zu ersetzen, die Groß-/Kleinschreibung des Vokabulars zu lösen und eine gute Segmentierung für den Großteil der Interpunktion bereitzustellen. Wir haben auch eine Linie zur Reinigung von Korpus auf der Grundlage statistischer Wahrscheinlichkeitsschätzung von Quell-Ziel-Korpus mit unklaren Ergebnissen gestartet. Außerdem haben wir einige Tests mit syllabischer Wortsegmentierung durchgeführt, wieder mit unklaren Ergebnissen, so dass wir am Ende, nach der Wortsatztokenisierung, BPE SentencePiece für Unterworteinheiten verwendet haben, um OpenNMT zu speisen.', 'ko': '이 해결 방안의 주요 사상은 자료 라이브러리의 정리와 준비에 집중한 다음에 상자를 열면 바로 사용할 수 있는 해결 방안(OpenNMT)과 기본적으로 발표된transformer 모델을 사용하는 것이다.자료 라이브러리를 준비하기 위해서, 우리는 표준 도구 (예를 들어 Moses 스크립트나python 패키지) 를 사용했지만, 다른python 스크립트를 제외하고, 우리는 변수의 숫자를 바꾸고, 어휘표의 대소문자 문제를 해결하며, 대부분의 문장에 좋은 단락을 제공할 수 있는python 사용자 정의 태그를 사용했다.우리는 또한 원목 표어 자료 라이브러리의 통계 확률을 바탕으로 추정하는 자료 라이브러리 정리선을 가동했지만 결과는 분명하지 않았다.그 밖에 우리는 음절분사에 대해 몇 가지 테스트를 실시했는데 결과가 아직 명확하지 않기 때문에 마지막으로 단어-문장 표기화 후에 우리는 BPE SentencePiece를 하위 단어 단원으로 사용하여 OpenNMT에 정보를 제공한다.', 'id': 'Ide utama solusi ini adalah fokus pada pembersihan dan persiapan corpus dan setelah itu, gunakan solusi luar kotak (OpenNMT) dengan model transformer yang diterbitkan secara lalai. Untuk mempersiapkan corpus, kami telah menggunakan set alat standar (sebagai skrip Musa atau paket python), tetapi juga, diantara skrip python lainnya, tokenizer suai python dengan kemampuan untuk menggantikan angka untuk variabel, memecahkan masalah kasus atas/bawah dari vokabular dan menyediakan segmen yang baik untuk kebanyakan punctuasi. Kami juga telah memulai garis untuk membersihkan tubuh berdasarkan penilaian probabilitas statistik dari tubuh sumber-target, dengan hasil yang tidak jelas. Juga, kami telah melakukan beberapa tes dengan segmen kata silabis, lagi dengan hasil yang tidak jelas, jadi pada akhirnya, setelah tokenisasi kalimat kalimat kami telah menggunakan BPE SentencePiece untuk unit subword untuk memberi makan OpenNMT.', 'sw': 'Wazo kuu la suluhisho hili ni kuitilia makini kutafuta usafi na kujiandaa na baada ya hayo, kutumia suluhisho la kisanduku (OpenNMT) kwa kutumia modeli yake ya mabadiliko ya kawaida iliyochapishwa. Ili kuandaa vifaa hivyo, tumetumia seti za vifaa vya kawaida (kama vile vitabu vya Musa au vifaa vya python), lakini pia, miongoni mwa vitabu vingine vya python, mwangalizi wa utambulisho wa simu za python mwenye uwezo wa kubadilisha namba kwa mabadiliko, kutatua suala la juu/chini la lugha na kutoa sehemu nzuri kwa maeneo mengi. Pia tumeanzisha mstari wa kutafuta vifaa vilivyotokana na uwezekano wa takwimu wa makampuni yanayolenga, na matokeo yasiyo ya wazi. Pia, tumeendesha baadhi ya majaribio kwa kugawanya maneno ya kiutamaduni, kwa mara nyingine kwa matokeo yasiyo ya wazi, kwa hiyo mwishoni, baada ya kuonyesha hukumu ya kiungo cha BPE kwa ajili ya vitengo vya chini vya maneno ili kulisha OpenNMT.', 'fa': 'ایده اصلی این راه حل این است که روی پاک کردن و آماده کردن کورپوس تمرکز کنید و بعد از آن، از یک راه حل جعبه بیرون (OpenNMT) با مدل تغییر دهنده پیش\u200cفرض آن استفاده کنید. برای آماده کردن کورپوس، ما از مجموعه ابزار استاندارد استفاده کردیم (به عنوان نوشته\u200cهای موسی یا بسته\u200cهای پیتون) اما همچنین، بین دیگر نوشته\u200cهای پیتون، یک نوشته\u200cنوشته\u200cی پیتون با توانایی جایگزینش شماره\u200cهای تغییرات را برای تغییرات، مسئله\u200cی کلمه\u200cهای بالا/کوچک\u200cتر از کلمه\u200cهای واژ ما همچنین یک خط برای پاک کردن کورپوس بر اساس ارزیابی احتمال آماری از کورپوس هدف منبع شروع کردیم، با نتیجه\u200cهای مشخص. همچنین، ما بعضی آزمایش\u200cها را با جدایی کلمه\u200cهای عبارت انجام دادیم، دوباره با نتیجه\u200cهای ناشناخته، بنابراین در نهایت، بعد از توکین کردن کلمه\u200cهای عبارت از BPE برای واحدهای زیر کلمه برای تغذیه OpenNMT استفاده کردیم.', 'af': "Die hoofde idee van hierdie oplossing is om op korpus skoonmaak en voorbereiding te fokus en daarna, gebruik 'n uit boks oplossing (OpenNMT) met sy verstek gepubliseer transformeermodel. Om die korpus te berei, het ons gebruik stel van standaard nutsprogramme (soos Moses skripte of python pakkette), maar ook, tussen ander python skripte, 'n python pasmaak tokeniseer met die moontlikheid om getalle vir veranderlikes te vervang, die boonste/kleiner Kas-probleem van die woordeboek te los en goeie segmentasie vir die meeste van die puntuasie verskaf. Ons het ook 'n lyn begin om korpus skoon te maak, gebaseer op statistiese waarskynlikheid van bron-doel korpus, met onbekende resultate. Ons het ook 'n paar toets hardloop met syllabical woord segmentasie, weer met onbekende resultate, so na die einde, na woord settokenisasie het ons BPE SentencePiece gebruik vir subwoord eenhede om OpenNMT te voer.", 'tr': "Bu çözümüň esasy ideýasy korpus temizleme we taýýarlama üstine fokus etmek bolandy. Soňra öň bellenen üýtgeden çözümlerden (OpenNMT) ullanyň. Korpusu taýýarlamak için, biz standart aletleri (Moses skriptleri ya da Python paketleri olarak) kullandık. Diğer Python skriptleri arasında da sayıları değişikliklere almak için yetenekli bir Python şahsiy tokenizçisi kullandık, sözlerin üst/küçük meselesini çözerek ve birçoğu noktaları için iyi segmentasyon sağlayarak kullandık. Biz hem korpusy statistik maksady korpusyň çeşme maksadynyň ölçüsi barada temizlemek üçin bir çizgi başladyk. Munuň so ňunda, sözlem tanlamasyndan soňra OpenNMT'i süýtgetmek üçin biraz syllabical söz segmentasy bilen test etdik.", 'am': 'የዚህ አዋጅ አሳብ የቆርፓስ ማጥራት እና ማዘጋጀት ነው፡፡ To prepare the corpus, we have used set of standard tools (as Moses scripts or python packages), but also, among other python scripts, a python custom tokenizer with the ability to replace numbers for variables, solve the upper/lower case issue of the vocabulary and provide good segmentation for most of the punctuation.  የቆርፓስ ክሮፕስ በቁጥጥር የቆርፓስ ግንኙነት በተመሳሳይ የቆርፓስ ውጤት የተመሳሳይ ነው፡፡ በተጨማሪም የባሕላዊ ቃላት አካባቢ እናደርጋለን፣ ደግሞም ባይታወቀ ፍሬዎች እናደርጋለን፡፡', 'sq': 'Ideja kryesore e kësaj zgjidhje ka qenë të përqëndrohet në pastrimin dhe përgatitjen e korpusit dhe pas kësaj, të përdoret një zgjidhje jashtë kutisë (OpenNMT) me modelin e tij të paracaktuar të botuar transformues. Për të përgatitur korpusin, kemi përdorur një sërë mjete standarde (si skripte të Moisiut apo paketa python), por gjithashtu, midis skripteve të tjera python, një tokenizer i personalizuar python me aftësinë për të zëvendësuar numrat për ndryshuesit, zgjidhur çështjen e rastit të lartë/të ulët të fjalorit dhe siguruar segmentim të mirë për shumicën e piktimit. Ne kemi filluar gjithashtu një linjë për të pastruar trupin bazuar në vlerësimin statistik të probabilitetit të trupit burim-objektiv, me rezultate të paqarta. Gjithashtu, ne kemi bërë disa teste me segmentimin e fjalës silabike, përsëri me rezultate të paqarta, kështu që në fund, pas tokenizimit të fjalës fjalë ne kemi përdorur BPE SentencePiece për njësitë e nënfjalës për të ushqyer OpenNMT.', 'hy': 'The main idea of this solution has been to focus on corpus cleaning and preparation and after that, use an out of box solution (OpenNMT) with its default published transformer model.  Կորպուսի պատրաստելու համար մենք օգտագործել ենք ստանդարտ գործիքներ (ինչպես Մովսէսի գրառումներ կամ փիթոնի փաթեթներ), բայց նաև, մյուս հարաբերությունների համար, փիթոնի հատուկ տոկինեզեր, որն ունի փոփոխականների համար թվեր փոխարինելու հնարավորություն, բառարանի վերևի և ցածր դեպքերի խնդիրը լուծելու և լավ սեգմետրացիա տալու համար: Մենք նաև սկսեցինք մաքրել մարմինը, հիմնված աղբյուր-նպատակային մարմինի վիճակագրական հավանականության գնահատման վրա, որի արդյունքները անհասկանալի են: Մենք նաև որոշ թեստեր կատարեցինք սիլաբիկ բառերի սեգմետրացիայով, կրկին անհասկանալի արդյունքներով, ուստի վերջում, բառի նախադասությունից հետո մենք օգտագործեցինք BP SenSenSenSenSenSencePipe-ը բառերի ենթաբառերի միավորների համար OpenNMT-ը կերակրելու համար:', 'bn': 'The main idea of this solution has been to focus on corpus cleaning and preparation and after that, use an out of box solution (OpenNMT) with its default published transformer model.  করপাস প্রস্তুত করার জন্য আমরা স্থানান্তর টুল ব্যবহার করেছি (মোসা স্ক্রিপ্ট বা পাইথন প্যাকেজ হিসেবে), কিন্তু অন্যান্য পাইথন স্ক্রিপ্টগুলোর মধ্যে একটি পাইথন স্বনির্ধারিত স্বনির্ধারকারী যার ক সোর্স-টার্গেট কর্পুসের হিসেবে ভিত্তিক পরিসংখ্যান পরিষ্কার করার জন্য আমরা একটি লাইন শুরু করেছি যার ফলে পরিষ্কার করা হয়েছে। এছাড়াও, আমরা কিছু পরীক্ষা করেছি সিলাবিক শব্দ বিভাগের সাথে, আবার অজ্ঞাত ফলাফলের সাথে, তাই শেষ পর্যন্ত, শব্দটির বিপের সেন্টেন্সপিয়েক ব্যবহার করেছি ওপেনএ', 'bs': 'Glavna ideja ovog rješenja je bila da se fokusiramo na čišćenje i pripremu korpusa i nakon toga koristimo izvan rešenja kutija (OpenNMT) sa svojim standardnim objavljenim modelom transformera. Da bi pripremili korpus, koristili smo skup standardnih alata (kao što su Moses skripti ili Python paketi), ali također, među ostalim Python skriptima, piton običnog tokenizača sa sposobnošću zamijeniti brojeve za promjene, rešiti problem s većim/manjim slučajevima riječi riječi i pružiti dobru segmentaciju za većinu tačke. Također smo započeli liniju za čišćenje korpusa na temelju statističke procjene vjerojatnosti korpusa iz izvora ciljeva, sa neobičnim rezultatima. Također, pokrenuli smo neke testove sa silabetskom segmentacijom riječi, opet sa nesvjesnim rezultatima, tako da na kraju, nakon tokenizacije rečenica, koristili smo BPE SentencePiece za podriječje jedinice za hranu OpenNMT.', 'az': "Bu çətinliklərin ən böyük fikri korpus təmizlənməsi və təmizlənməsi və bundan sonra, ön tərzim təmizlənmiş transformer modeli ilə qutu çətinlikdən (OpenNMT) istifadə etməkdir. Korpusu hazırlamaq üçün, biz standart vasitələri (Musa skriptləri və Python paketləri kimi) istifadə etdik, həmçinin digər Python skriptləri arasında, sayıları dəyişikliklərə dəyişiklik etmək bacarığı ilə Python tərzi tokenizeri, sözlərin böyük/küçük məsələsini çəkib çoxluğu üçün yaxşı segmentasiya təyin etdik. Biz də təmizlənmək üçün bir sətir başladıq. İstatistik mümkünlüyünün mənbə korpusu təmizlənməsi üçün təmizlənmək mümkündür. Və sözlərin segmentasiyası ilə bir neçə sınaqlar yaratdıq. Sonunda sözlərin tokenisası sonunda OpenNMT'i yedirmək üçün BPE SentencePiece vasitəsilə birlikdə sözlər segmentasiyası yaratdıq.", 'ca': "La idea principal d'aquesta solució ha estat centrar-se en la neteja i preparació de corpus i després d'això, utilitzar una solució fora de caixa (OpenNMT) amb el seu model predefinit de transformador publicat. Per preparar el corpus, hem utilitzat un conjunt d'eines estàndard (com scripts de Moisés o paquets de python), però també, entre altres scripts de python, un tokenizer personalitzat de python amb l'habilitat de substituir números per variables, resoldre el problema de cas superior/inferior del vocabulari i proporcionar una bona segmentació per la majoria de la puntuació. També hem començat una línia per netejar el cos basada en l'estimació estadística de probabilitat del cos d'origen-alv, amb resultats poc clars. També hem fet alguns exàmens amb segmentació sílabica de paraules, un altre cop amb resultats poc clars, així que al final, després de tocenitzar frases de paraules hem utilitzat BPE SentencePiece per unitats de subparaules per alimentar OpenNMT.", 'et': 'Selle lahenduse peamiseks ideeks on olnud keskenduda korpuse puhastamisele ja ettevalmistamisele ning seejärel kasutada väljaspool kasutust olevat lahendust (OpenNMT) vaikimisi avaldatud trafomodelliga. Korpuse koostamiseks oleme kasutanud standardseid tööriistu (nagu Mosese skriptid või python paketid), kuid ka muude python skriptide hulgas python kohandatud tokenizer, mis suudab asendada numbreid muutujatele, lahendada sõnavara suur- ja väiketähtede probleemi ja tagada hea segmenteerimine enamiku vahemärkide jaoks. Samuti oleme alustanud rida puhastada korpust, mis põhineb allika-sihtkorpuse statistilisel tõenäosuse hindamisel, ebaselgete tulemustega. Samuti oleme teinud mõned testid silbilise sõna segmenteerimisega, jällegi ebaselgete tulemustega, nii et lõpus, pärast sõna lause tokeniseerimist oleme kasutanud BPE SentencePiece alamsõna ühikuteks OpenNMT toitmiseks.', 'cs': 'Hlavní myšlenkou tohoto řešení bylo zaměřit se na čištění a přípravu korpusů a poté použít out of box řešení (OpenNMT) s výchozím publikovaným modelem transformátoru. K přípravě korpusu jsme použili sadu standardních nástrojů (jako Moses skripty nebo Python balíčky), ale také, mimo jiné Python skripty, vlastní tokenizer Python se schopností nahradit čísla proměnných, řešit velká/malá slovní zásoba a poskytnout dobrou segmentaci pro většinu interpunkce. Rovněž jsme zahájili linii čištění korpusu na základě statistického odhadu pravděpodobnosti zdroje-cílového korpusu s nejasnými výsledky. Také jsme provedli některé testy se slabikovou segmentací slov, opět s nejasnými výsledky, takže na konci, po tokenizaci slovních vět jsme použili BPE SentencePiece pro podslovní jednotky k napájení OpenNMT.', 'fi': 'Ratkaisun pääajatuksena on ollut keskittyä korpusten puhdistukseen ja valmisteluun ja sen jälkeen käyttää out of box -ratkaisua (OpenNMT) oletusarvoisella julkaistulla muuntajamallilla. Korpusen laatimiseen olemme käyttäneet vakiotyökaluja (kuten Moses-skriptejä tai python-paketteja), mutta myös muiden python-skriptejä, python-mukautettua tokenizeria, joka pystyy korvaamaan muuttujien numerot, ratkaisemaan sanaston isot/pienet kirjaimet ja tarjoamaan hyvän segmentoinnin useimmille välimerkeille. Olemme myös käynnistäneet linjan puhtaaksi korpuseksi, joka perustuu lähde-kohdekorpusen tilastolliseen todennäköisyysarvioon, ja tulokset ovat epäselvät. Olemme myös suorittaneet joitain testejä tavusanasegmentoinnilla, jälleen epäselvillä tuloksilla, joten loppujen lopuksi, sanalauseen tokenisaation jälkeen olemme käyttäneet BPE SentencePiece-lausetta alisanayksikköinä syöttämään OpenNMT:tä.', 'ha': "The main idea of this solution has been to focus on corpus cleaning and preparation and after that, use an out of box solution (OpenNMT) with its default published transformer model.  Yana amfani da kayan aiki na daidaita (kamar misãlan takardar Mũsã ko kayan aiki na python), amma, kuma, cikin wasu mistakardan python, akwai wani mai nuna wa shirin ayuka na python, da awon ya musanya ko da wasu masu variant, sai ka nuna masu sakan sarki/ƙarƙashin cikin maganar, kuma ka bãyar da rabo mai kyau ga masu ƙaranci. Mun fara wani line da za'a tsarkake nau'i, a kan ƙidãya mai yiwuwa na ƙidãya na daman-maishi, da fassarata ba'a sani ba. Piece", 'jv': 'Panjenengan langkung wih-wih wong iki dadi kanggo ingkang karo perusahaan karo pawaran kanggo ndelok karo nggawe lan ijol-ijolan, iso nggawe sistem kutus (Open NMT) nganggo model sing wis mbukakipon. Jejaring Awak dhéwé mulai nggawe sistem kanggo mbelak cara-cara sing bisa perusahaan dadi, nik awak dhéwé kuwi nggawe perusahaan bukané kejahatan cara-cara sing ora dadi. Nambah, awak dhéwé wis nambah ujian karo segmentasipun kelalabar, dadi wis mulai dadi, soalé terus tokenisaan pawar dhéwé nggambar kelas tokenisaan sentence5 nggo unawit gambar kelas kotak nggawe Open NMT', 'he': 'The main idea of this solution has been to focus on corpus cleaning and preparation and after that, use an out of box solution (OpenNMT) with its default published transformer model.  כדי להכין את הקורפוס, השתמשנו בסט כלים סטנדרטיים (בתור תוכניות משה או חבילות פיתון), אבל גם, בין תוכניות פיתון אחרות, טוקניזר מיוחד פיתון עם היכולת להחליף מספרים לשתנים, לפתור את בעיה במקרה העליון/נמוך של המילים ולספק סגמנציה טובה לרוב הנקודה. התחלנו גם קו לנקות את הקורפוס בהתבסס על הערכת הסבירות הסטטיסטית של הקורפוס המקור-מטרה, עם תוצאות לא ברורות. Also, we have run some tests with syllabical word segmentation, again with unclear results, so at the end, after word sentence tokenization we have used BPE SentencePiece for subword units to feed OpenNMT.', 'sk': 'Glavna ideja te rešitve je bila, da se osredotočimo na čiščenje in pripravo korpusa, nato pa uporabimo zunaj škatle rešitev (OpenNMT) s svojim privzetim objavljenim transformatorskim modelom. Za pripravo korpusa smo uporabili niz standardnih orodij (kot so Mojzesove skripte ali paketi python), med drugimi skripti python pa tudi python žetonizer po meri s sposobnostjo zamenjave številk za spremenljivke, rešitve težave z velikimi in majhnimi črkami besedišča in zagotavljanja dobre segmentacije za večino ločil. Začeli smo tudi linijo čiščenja korpusa, ki temelji na statistični oceni verjetnosti vir-ciljnega korpusa, z nejasnimi rezultati. Prav tako smo opravili nekaj testov z zlobno segmentacijo besed, spet z nejasnimi rezultati, zato smo na koncu, po žetonizaciji besednih stavkov uporabili BPE SentencePiece za podbesedne enote za hranjenje OpenNMT.', 'bo': 'The main idea of this solution is to focus on corpus cleaning and preparation and after that, use an out of box solution (OpenNMT) with its default published transformer model. To prepare the corpus, we have used set of standard tools (as Moses scripts or python packages), but also, among other python scripts, a python custom tokenizer with the ability to replace numbers for variables, solve the upper/lower case issue of the vocabulary and provide good segmentation for most of the punctuation. ང་ཚོས་ཀྱང་འབྲེལ་མཐུད་དང་འབྲེལ་བ་ཡིན་པའི་དབུལ་རྩིས་བ་ཞིག་གཙང་དག་བཟོ་བ་ཞིག་འགོ་བཙུགས་ཡོད། མ་ཟད། ང་ཚོས་ཚིག་འདི་ཚིག་ཡིག་གི་སྐབས་ཀྱི་བརྟག་ཞིབ་མཉམ་དུ་འཁོར་བ་ཅིག་ལ།'}
{'en': 'Similar Language Translation for ', 'ar': 'ترجمة لغة مماثلة للكتالونية والبرتغالية والإسبانية باستخدام Marian NMT', 'es': 'Traducción de idiomas similares para catalán, portugués y español con Marian NMT', 'fr': "Traduction linguistique similaire pour le catalan, le portugais et l'espagnol utilisant Marian NMT", 'pt': 'Tradução de idiomas semelhantes para catalão, português e espanhol usando Marian NMT', 'ja': 'Marian NMTを使用したカタルーニャ語、ポルトガル語、スペイン語の類似言語翻訳', 'hi': 'कैटालैन, पुर्तगाली और स्पैनिश के लिए समान भाषा अनुवाद मैरियन एनएमटी का उपयोग करके', 'ru': 'Аналогичный перевод на каталанский, португальский и испанский языки с использованием Marian NMT', 'zh': '用玛丽安NMT加泰罗尼亚语,葡萄牙语与西班牙语类语译', 'ga': 'Aistriúchán Teanga Comhchosúil don Chatalóinis, don Phortaingéilis agus don Spáinnis le Marian NMT', 'ka': 'Name', 'el': 'Παρόμοια Γλώσσα Μετάφραση για Καταλανικά, Πορτογαλικά και Ισπανικά Χρησιμοποιώντας Μαριανικά', 'hu': 'Hasonló nyelvű fordítás katalán, portugál és spanyol nyelvre Marian NMT használatával', 'kk': 'Каталандық, португаль және испан тілдерінің ұқсас аудармасыName', 'lt': 'Panašus vertimas katalų, portugalų ir ispanų kalbomis naudojant Marian NMT', 'ms': 'Terjemahan Bahasa Sama untuk Catalan, Portugis dan Sepanyol Menggunakan Marian NMT', 'it': 'Traduzione di lingue simili per catalano, portoghese e spagnolo utilizzando Marian NMT', 'mk': 'Similar Language Translation for Catalan, Portuguese and Spanish Using Marian NMT', 'ml': 'Name', 'mn': 'Каталан, Португали болон Испанийн хэл хөрөнгө төстэй хэл хөрөнгө', 'pl': 'Podobny język tłumaczenia na język kataloński, portugalski i hiszpański przy użyciu Mariańskiego NMT', 'ro': 'Traducere lingvistică similară pentru catalană, portugheză și spaniolă folosind Marian NMT', 'sr': 'Slična prevoda jezika za katalanski, portugalski i španjolski korištenje Mariana NMT', 'so': 'Turjumista luuqada u eg ee Katalan, Burtuqiis iyo Isbanish isticmaalka Marian NMT', 'sv': 'Liknande språköversättning för katalanska, portugisiska och spanska med hjälp av Marian NMT', 'mt': 'Traduzzjoni tal-lingwa simili għall-Katalan, il-Portugiż u l-Ispanjol li jużaw Marian NMT', 'ta': 'Name', 'no': 'Lik språk- omsetjing for katalansk, portugisisk og spansk ved bruk av Marian NMT', 'ur': 'کیٹلان، پورٹیجی اور اسپانیایی کے لئے برابر زبان ترجمہ', 'si': 'Name', 'uz': 'Name', 'vi': 'Ngôn ngữ tương tự cho Catalan, Bồ Đào Nha và Tây Ban Nha, sử dụng Mariano NMT.', 'bg': 'Превод на подобен език за каталонски, португалски и испански с помощта на Мариански НМТ', 'hr': 'Slična prevoda jezika za katalanski, portugalski i španjolski korištenje Mariana NMT', 'nl': 'Vergelijkbare Taalvertaling voor Catalaans, Portugees en Spaans met behulp van Mariaans NMT', 'da': 'Lignende sprogoversættelse til catalansk, portugisisk og spansk ved hjælp af Marian NMT', 'de': 'Ähnliche Sprachübersetzungen für Katalanisch, Portugiesisch und Spanisch mit Marian NMT', 'id': 'Terjemahan Bahasa Similar untuk Catalan, Portugis dan Spanyol Menggunakan Marian NMT', 'fa': 'ترجمه زبان شبیه برای کاتالان، پورتوژیک و اسپانیایی با استفاده از NMT ماریایی', 'ko': 'Marian NMT를 사용하여 카탈루냐어, 포르투갈어, 스페인어 유사 언어 번역', 'sw': 'Tafsiri sawa na lugha kwa Kikatala, Kireno na Kihispania kwa kutumia Marian NMT', 'tr': 'Katalança, portugalça we espaýnça dili Marian NMT üçin meňzeş terjime', 'af': 'Likelike Taal Vertaling vir Katalaanse, Portugese en Spaanse gebruik Marian NMT', 'sq': 'Përkthimi i ngjashëm gjuhësh për katalan, portugal dhe spanjoll duke përdorur NMT Marian', 'am': 'ትርጉም', 'bn': 'ক্যাটালান, পর্তুগীজ এবং স্প্যানিশ ভাষার অনুবাদ ব্যবহার করে মারিয়ান NMT ব্যবহার করে', 'az': 'Catalan, Portugal və İspanyol üçün eyni dil çeviri Marian NMT qullanır', 'hy': 'Նմանատիպ լեզվի թարգմանություն կատալանի, պորտուգալերենի և իսպաներենի համար, օգտագործելով Մարիան NMT', 'bs': 'Slična prevoda jezika za katalanski, portugalski i španjolski korištenje Mariana NMT', 'cs': 'Podobný jazyk Překlad pro katalánštinu, portugalštinu a španělštinu pomocí mariánského NMT', 'et': 'Sarnase keele tõlge katalaani, portugali ja hispaania keeles Marian NMT abil', 'fi': 'Samankaltainen kielikäännös katalaanille, portugalille ja espanjalle Marian NMT:n avulla', 'ca': 'Traducció de llenguatge similar per català, portuguès i espanyol utilitzant Marian NMT', 'jv': 'Terjamahan Inggal kang Catalan, Putuk karo Spangguna Ngawe marian NMT', 'ha': '@ item Text character set', 'he': 'תרגום שפה דומה לקטלנית, פורטוגזית וספרדית', 'sk': 'Podobni jezikovni prevod za katalonščino, portugalščino in španščino z uporabo Marian NMT', 'bo': 'འདྲ་མཚུངས་ན། ཀེ་ཊ་ལཱན། པོ་རོཊ་ཇི་དང་སྐད་ཡིག་ལ་སྐད་ཡིག་འདིའི་སྤྱོད་པ་མི་རི་ཡཱན་NMT'}
{'en': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task. Using the Marian neural machine translation toolkit, translation systems based on Google’s transformer architecture were built in both directions of CatalanSpanish and PortugueseSpanish. The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers. According to their official evaluation results, the SEBAMAT system turned out to be competitive with rankings among the top teams and BLEU scores between 38 and 47 for the language pairs involving ', 'ar': 'تصف هذه الورقة مساهمة SEBAMAT في المهمة المشتركة لترجمة اللغات المماثلة 2021 WMT. باستخدام مجموعة أدوات الترجمة الآلية العصبية Marian ، تم بناء أنظمة الترجمة القائمة على بنية محولات Google في كلا الاتجاهين من الكاتالونية - الإسبانية والبرتغالية - الإسبانية. تم تدريب الأنظمة في إعدادين للمعلمات المتباينة (أحجام مفردات مختلفة لتشفير أزواج البايت) باستخدام المجاميع المتوازية فقط وليس المجموعات المماثلة التي يوفرها منظمو المهام المشتركة. وفقًا لنتائج التقييم الرسمية الخاصة بهم ، تبين أن نظام SEBAMAT قادر على المنافسة مع الترتيب بين الفرق الكبرى ودرجات BLEU بين 38 و 47 للأزواج اللغوية التي تشمل البرتغالية وما بين 76 و 80 للأزواج اللغوية التي تشمل الكتالونية.', 'pt': 'Este artigo descreve a contribuição do SEBAMAT para a tarefa compartilhada de tradução de idiomas semelhantes do WMT 2021. Usando o kit de ferramentas de tradução automática neural Marian, sistemas de tradução baseados na arquitetura de transformador do Google foram construídos em ambas as direções de catalão-espanhol e português-espanhol. Os sistemas foram treinados em duas configurações de parâmetros contrastantes (diferentes tamanhos de vocabulário para codificação de pares de bytes) usando apenas os corpora paralelos, mas não os comparáveis fornecidos pelos organizadores de tarefas compartilhadas. De acordo com os resultados da avaliação oficial, o sistema SEBAMAT mostrou-se competitivo com classificações entre as melhores equipes e pontuações BLEU entre 38 e 47 para os pares de idiomas que envolvem o português e entre 76 e 80 para os pares de idiomas que envolvem o catalão.', 'es': 'Este documento describe la contribución de SEBAMAT a la tarea compartida de Traducción de Idiomas Similares del WMT 2021. Con el kit de herramientas de traducción automática neuronal mariana, se construyeron sistemas de traducción basados en la arquitectura transformer de Google en ambas direcciones del catalán, español y portugués, español. Los sistemas se entrenaron en dos configuraciones de parámetros contrastivos (diferentes tamaños de vocabulario para la codificación de pares de bytes) utilizando solo los cuerpos paralelos, pero no los comparables, proporcionados por los organizadores de tareas compartidas. De acuerdo con los resultados oficiales de su evaluación, el sistema SEBAMAT resultó ser competitivo con clasificaciones entre los mejores equipos y BLEU puntuaciones entre 38 y 47 para las parejas de idiomas que involucran al portugués y entre 76 y 80 para las parejas de idiomas que involucran al catalán.', 'fr': "Cet article décrit la contribution de SEBAMAT à la tâche partagée WMT Similar Language Translation 2021. À l'aide de la boîte à outils de traduction automatique neuronale Marian, les systèmes de traduction basés sur l'architecture des transformateurs de Google ont été construits dans les deux sens\xa0: catalan-espagnol et portugais-espagnol. Les systèmes ont été formés à deux réglages de paramètres contrastifs (différentes tailles de vocabulaire pour le codage de paires d'octets) en utilisant uniquement les corpus parallèles mais non comparables fournis par les organisateurs de tâches partagés. Selon les résultats officiels de l'évaluation, le système SEBAMAT s'est avéré compétitif avec des classements parmi les meilleures équipes et le BLEU a obtenu entre 38 et 47 pour les paires de langues impliquant le portugais et entre 76 et 80 pour les paires de langues impliquant le catalan.", 'zh': '本文述SEBAMAT2021年WMT类言译共功。 用Marian神经机器翻译工具包,Googletransformer架构译系加泰罗尼亚语 - 西班牙语、葡萄牙语 - 西班牙语二方。 此二比参数设置(字节编码之异词汇大小)之教,并行而不用组织者共事者较语料库。 据其质实,SEBAMAT系顶级团队中排名有竞争力,且BLEU及葡萄牙语对者得分在3847之间,于加泰罗尼亚语语对,得分在7680之间。', 'ja': 'この論文では、2021年のWMT類似言語翻訳共有タスクへのSEBAMATの貢献について説明します。Marianニューラルマシン翻訳ツールキットを使用して、Googleの変圧器アーキテクチャに基づいた翻訳システムが、カタルーニャ語-スペイン語とポルトガル語-スペイン語の両方の方向に構築されました。システムは、共有タスクオーガナイザーによって提供された並列ではあるが同等のコーラのみを使用して、2つの対照的なパラメータ設定（バイトペア符号化のための異なるボキャブラリサイズ）でトレーニングされた。彼らの公式評価結果によると、SEBAMATシステムは、ポルトガル語を含む言語ペアでは38から47の間、カタルーニャ語を含む言語ペアでは76から80の間のランキングとBLEUスコアで競争力があることが判明した。', 'ru': 'В этой статье описывается вклад SEBAMAT в совместную задачу по переводу на аналогичный язык WMT в 2021 году. Используя набор инструментов для нейронного машинного перевода Marian, системы перевода, основанные на трансформаторной архитектуре Google, были построены в обоих направлениях: каталанско-испанском и португало-испанском. Системы были обучены двум настройкам контрастных параметров (различные размеры словарного запаса для кодирования пары байтов), используя только параллельные, но не сопоставимые корпуса, предоставленные организаторами общих задач. По результатам официальной оценки система SEBAMAT оказалась конкурентоспособной с рейтингом среди лучших команд и баллами BLEU от 38 до 47 для языковых пар с участием португальского языка и от 76 до 80 для языковых пар с участием каталонского языка.', 'hi': 'यह पेपर 2021 WMT समान भाषा अनुवाद साझा किए गए कार्य में SEBAMAT योगदान का वर्णन करता है। मैरियन न्यूरल मशीन अनुवाद टूलकिट का उपयोग करते हुए, Google के ट्रांसफॉर्मर आर्किटेक्चर पर आधारित अनुवाद प्रणालियों को कैटलन-स्पेनिश और पुर्तगाली-स्पेनिश दोनों दिशाओं में बनाया गया था। सिस्टम को दो कंट्रास्टिव पैरामीटर सेटिंग्स (बाइट जोड़ी एन्कोडिंग के लिए अलग-अलग शब्दावली आकार) में प्रशिक्षित किया गया था, जो केवल समानांतर का उपयोग करके लेकिन साझा कार्य आयोजकों द्वारा प्रदान किए गए तुलनीय कॉर्पोरेट का उपयोग नहीं करता था। उनके आधिकारिक मूल्यांकन परिणामों के अनुसार, SEBAMAT प्रणाली शीर्ष टीमों के बीच रैंकिंग के साथ प्रतिस्पर्धी साबित हुई और पुर्तगाली से जुड़े भाषा जोड़े के लिए 38 और 47 के बीच BLEU स्कोर और कैटलन से जुड़े भाषा जोड़े के लिए 76 और 80 के बीच।', 'ga': 'Déanann an páipéar seo cur síos ar an méid a chuir SEBAMAT le tasc comhroinnte Aistriúchán Teanga Comhchosúil WMT 2021. Ag baint úsáide as an bhfoireann uirlisí meaisín-aistrithe néar Marian, tógadh córais aistriúcháin bunaithe ar ailtireacht claochladáin Google sa dá threo ón gCatalóinis-Spáinnis agus Portaingéilis-Spáinnis. Cuireadh oiliúint ar na córais i dhá shuíomh chodarsnacha pharaiméadar (méideanna éagsúla foclóra le haghaidh ionchódú beart péire) ag baint úsáide as an gcomhthreomhar ach ní as an gcorpas inchomparáide a chuir na comheagraithe tasc ar fáil. De réir thorthaí an mheasúnaithe oifigiúil, bhí córas SEBAMAT iomaíoch le rangú i measc na bhfoirne is fearr agus scóir BLEU idir 38 agus 47 do na péirí teanga a raibh baint ag an bPortaingéilis leo agus idir 76 agus 80 do na péirí teanga a raibh baint acu leis an gCatalóinis.', 'hu': 'Ez a tanulmány bemutatja a SEBAMAT hozzájárulását a 2021-es WMT Hasonló Nyelvű Fordítás megosztott feladathoz. A Marian neurális gépi fordító eszközkészlet használatával a Google transzformátor architektúráján alapuló fordítási rendszereket mindkét irányban katalán-spanyol és portugál-spanyol nyelven építették. A rendszereket két kontrasztív paraméterbeállításra (különböző szókincsméretek a bájtpár kódoláshoz) képezték, csak a megosztott feladatszervezők által biztosított párhuzamos, de nem hasonló korpuszokat használva. Hivatalos értékelési eredményeik szerint a SEBAMAT rendszer versenyképes volt a legjobb csapatok közötti rangsorolással, a BLEU 38 és 47 közötti pontszámokkal a portugál nyelvpárok esetében, a katalán nyelvpárok esetében pedig 76 és 80 közötti pontszámokkal.', 'el': 'Η παρούσα εργασία περιγράφει τη συνεισφορά του SEBAMAT στο κοινό έργο μετάφρασης παρόμοιας γλώσσας. Χρησιμοποιώντας την εργαλειοθήκη μηχανικής μετάφρασης Μαριανών, συστήματα μετάφρασης βασισμένα στην αρχιτεκτονική μετασχηματιστών της κατασκευάστηκαν και στις δύο κατευθύνσεις Καταλανικά-Ισπανικά και Πορτογαλικά-Ισπανικά. Τα συστήματα εκπαιδεύτηκαν σε δύο διαφορετικές ρυθμίσεις παραμέτρων (διαφορετικά μεγέθη λεξιλογίου για κωδικοποίηση ζεύγους Byte) χρησιμοποιώντας μόνο τα παράλληλα αλλά όχι τα συγκρίσιμα σώματα που παρέχονται από τους κοινόχρηστους οργανωτές εργασιών. Σύμφωνα με τα επίσημα αποτελέσματα αξιολόγησης, το σύστημα αποδείχθηκε ανταγωνιστικό με τις βαθμολογίες μεταξύ των κορυφαίων ομάδων και τις βαθμολογίες μεταξύ 38 και 47 για τα γλωσσικά ζεύγη που περιλαμβάνουν τα πορτογαλικά και μεταξύ 76 και 80 για τα γλωσσικά ζεύγη που περιλαμβάνουν τα καταλανικά.', 'ka': 'ეს წიგნი აღწერს SEBAMAT დამატებას 2021 WMT მსგავსი ენის გადაწყვეტილების საქაღალდე. მარიანი ნეიროლური მანქანის გაგრძელების ხელსაწყოთა კიტის გამოყენება, Google-ის ტრანფორმეტრის აქტიქტურაციაზე ბაზეულია, კარალანი-სპანუალური და პორგუტური-სპა სისტემები ორი კონტრასტიური პარამეტრების პარამეტრებში (განსხვავებული სიტყვებული სიტყვების ზომაში) მხოლოდ პარაელელელი გამოყენებული, მაგრამ არა დამატებული კონტრასტიური კონტრა მათი უფრო მეტსალური განსაზღვრებას შესახებ, SEBAMAT-ის სისტემა იყო პრონექტიური პრონექტიური პრონექტიური პრონექტიური პრონექტიური პრონექტის შორის და BLEU-ის პრონექტის შორის 38-47 წლის წლის პორ', 'kk': 'Бұл қағаз 2021 WMT сияқты тілді аудару тапсырмасына SEBAMAT қатынасын анықтайды. Мариан неврал машинаның аудару құралдарының пайдалануын қолдану үшін Google түрлендіру архитектурасына негізделген аудару жүйелері Каталан- Испан және Португалия- Испания екі жағында құрылды. Жүйелер екі контрастырлық параметрлер параметрлерінде (байт екі кодтамасы үшін айырмалы сөздер өлшемі) тек параллельді қолданады, бірақ ортақ тапсырмалар ортақтастырушыларының келтірілген салыстырылатын кор Олардың оқыту нәтижесіне сәйкес, SEBAMAT жүйесі жоғары топтардың, 38- 47 арасындағы BLEU нәтижелері мен португаль тілдерінің және 76- 80 арасында Каталан тілдеріне қатысты тілдер жиындарына сәйкес болды.', 'mk': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  Користејќи го наборот за превод на маријанските нервни машини, системите за превод базирани на архитектурата на трансформаторот на Гугл се изградени во двете насоки на каталонско-шпанско и португалско-шпанско. Системите беа обучени во две контрастни параметри поставувања (различни големини на речникот за кодирање пар бајти) користејќи само паралелно но не паралелно корпора обезбедено од заедничките организатори на задачи. Според нивните официјални резултати на проценката, системот СЕБАМАТ се покажа да е конкурентен со рангирањето помеѓу најдобрите тимови и БЛЕУ резултати помеѓу 38 и 47 за паровите на јазик кои вклучуваат португалски и помеѓу 76 и 80 за паровите на јазик кои', 'it': "Questo articolo descrive il contributo SEBAMAT al compito condiviso WMT Similar Language Translation 2021. Utilizzando il kit di strumenti di traduzione automatica neurale mariana, i sistemi di traduzione basati sull'architettura dei trasformatori di Google sono stati costruiti in entrambe le direzioni catalano-spagnolo e portoghese-spagnolo. I sistemi sono stati addestrati in due impostazioni di parametri contrastanti (diverse dimensioni del vocabolario per la codifica di coppia di byte) utilizzando solo i corpora paralleli ma non comparabili forniti dagli organizzatori delle attività condivise. Secondo i risultati della valutazione ufficiale, il sistema SEBAMAT si è rivelato competitivo con le classifiche tra le migliori squadre e i punteggi BLEU tra 38 e 47 per le coppie linguistiche che coinvolgono il portoghese e tra 76 e 80 per le coppie linguistiche che coinvolgono il catalano.", 'ml': 'ഈ പത്രത്തില്\u200d 2021 WMT പോലുള്ള ഭാഷ പങ്കാളിയുടെ പങ്ക് സെബാമാറ്റിനെ വിശദീകരിക്കുന്നു. മാരിയാന്\u200d നെയൂറല്\u200d മെഷീന്\u200d പരിഭാഷ ഉപകരണങ്ങള്\u200d ഉപയോഗിച്ച്, ഗൂഗിളിന്റെ മാറ്റങ്ങളുടെ സ്ഥാനത്തില്\u200d അടിസ്ഥാനമായി പരിഭാഷപ്രവര്\u200dത്തനങ്ങള്\u200d കാത്താല പങ്കുചേര്\u200dക്കുന്ന ജോലി കോര്\u200dപ്പോറര്\u200d മാത്രം ഉപയോഗിക്കുന്ന രണ്ട് വിരോധമായ പരാമീറ്റര്\u200d സജ്ജീകരണങ്ങളില്\u200d പഠിപ്പിക്കപ്പെട്ടിരുന്നു (ബ അവരുടെ ഔദ്യോഗിക പരിഗണന ഫലങ്ങള്\u200d അനുസരിച്ച്, സെബാമാറ്റ് സിസ്റ്റം മുകളില്\u200d രാജാക്കന്മാരുടെ കൂട്ടത്തില്\u200d പ്രതിരോധിക്കുന്നത് 38-47 ന്നും പോര്\u200dട്ടുഗീസിലെ ഭാഷ ജോട്', 'lt': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  Naudojant Marijos nervinių mašin ų vertimo įrankių rinkinį, vertimo sistemos, pagrįstos Google transformatoriaus architektūra, buvo sukurtos abiem katalonų, ispanų ir portugalų kalbomis kryptimis. Sistemos buvo apmokytos dviem kontrastiniais parametrais (skirtingais žodyno dydžiais baitų porų kodavimui) naudojant tik lygiagrečią, bet ne panašią korporą, kurią suteikė bendri užduočių organizatoriai. According to their official evaluation results, the SEBAMAT system turned out to be competitive with rankings among the top teams and BLEU scores between 38 and 47 for the language pairs involving Portuguese and between 76 and 80 for the language pairs involving Catalan.', 'mt': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  Bl-użu tal-għodda tat-traduzzjoni tal-magni newrali Mariani, is-sistemi tat-traduzzjoni bbażati fuq l-arkitettura tat-trasformatur ta’ Google inbnew fiż-żewġ direzzjonijiet tal-Katalan-Spanjol u tal-Portugiż-Spanjol. The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers.  Skont ir-riżultati uffiċjali tal-evalwazzjoni tagħhom, is-sistema SEBAMAT uriet li hija kompetittiva mal-klassifikazzjonijiet fost l-ogħla timijiet u l-punteġġi BLEU bejn 38 u 47 għall-pari lingwistiċi li jinvolvu l-Portugiż u bejn 76 u 80 għall-pari lingwistiċi li jinvolvu l-Katalan.', 'ms': 'Kertas ini menggambarkan kontribusi SEBAMAT kepada tugas kongsi Perjemahan Bahasa Sama WMT 2021. Dengan alat terjemahan mesin saraf Marian, sistem terjemahan berdasarkan arkitektur pengubah Google dibina dalam kedua-dua arah Catalan-Spanyol dan Portugis-Spanyol. The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers.  According to their official evaluation results, the SEBAMAT system turned out to be competitive with rankings among the top teams and BLEU scores between 38 and 47 for the language pairs involving Portuguese and between 76 and 80 for the language pairs involving Catalan.', 'no': 'Denne papiret skildrar SEBAMAT-bidraga til delt oppgåve i WMT-omsetjinga som liknar språk. Bruk Mariansk neuralmaskineomsetjingsverktøykassa ble omsetjingssystemet basert på Google s in transformeringsarkitektur bygd i begge retningar av katalansk-spansk og portugisisk-spansk. Systema vart trengte i to kontrastiske parametrar (ulike ordlistestorleik for byte- par- koding) med berre parallelle, men ikkje den sammenlignbare korpora som delte oppgåve- organisatorene har tilgjengelege. Etter deres offisielle evalueringsresultat, viste SEBAMAT-systemet til å vera konkurente med rankingar mellom de øvste gruppene og BLEU-scorene mellom 38 og 47 for språkparene som involverer portugisiske og mellom 76 og 80 for språkparene som involverer katalansk.', 'pl': 'Niniejszy artykuł opisuje wkład SEBAMAT w wspólne zadanie tłumaczenia podobnych języków WMT. Korzystając z zestawu narzędzi do tłumaczenia neuronowego Marian, systemy tłumaczeniowe oparte na architekturze transformatora Google zostały zbudowane w obu kierunkach języka katalońsko-hiszpańskiego i portugalsko-hiszpańskiego. Systemy zostały przeszkolone w dwóch kontrastywnych ustawieniach parametrów (różne rozmiary słownictwa dla kodowania par bajtów) przy użyciu tylko równoległych, ale nie porównywalnych korpusów dostarczanych przez organizatorów współdzielonych zadań. Według oficjalnych wyników oceny system SEBAMAT okazał się konkurencyjny z rankingami wśród najlepszych drużyn oraz wynikami BLEU od 38 do 47 dla par językowych z udziałem portugalskiego oraz od 76 do 80 dla par językowych z udziałem katalońskiego.', 'sr': 'Ovaj papir opisuje doprinos SEBAMAT-a za zajednički zadatak WMT sličnog prevoda jezika 2021. godine. Koristeći korištenje alata za prevod marijskih neuralnih mašina, sistemi prevoda bazirani na Google-ovoj transformacijskoj arhitekturi izgrađeni su u oba smjera katalanskog-španjolskog i portugalskog-španjolskog. Sistemi su obučeni u dva kontrastivna parametra (različite veličine rečnika za kodiranje bajtskih parova) koristeći samo paralelne, ali ne usporedno korporacije koje su pružili zajednički organizatori zadataka. Prema njihovim zvaničnim rezultatima procjene, sistem SEBAMAT ispostavilo se da je konkurentni sa redovima među najvišim timovima i BLEU rezultatima između 38 i 47 za jezičke parove uključujući portugalce i između 76 i 80 za jezičke parove uključujući katalance.', 'ro': 'Această lucrare descrie contribuția SEBAMAT la sarcina partajată WMT pentru traducerea limbilor similare 2021. Folosind setul de instrumente de traducere automată neurală Mariană, sistemele de traducere bazate pe arhitectura transformatoarelor Google au fost construite în ambele direcții ale limbii catalano-spaniole și portughezo-spaniole. Sistemele au fost instruite în două setări de parametri contrastanti (dimensiuni diferite de vocabular pentru codificarea perechilor de octeți) folosind doar corpurile paralele, dar nu comparabile oferite de organizatorii activităților partajate. Conform rezultatelor evaluării oficiale, sistemul SEBAMAT s-a dovedit a fi competitiv cu clasamentele dintre echipele de top și cu scoruri BLEU între 38 și 47 pentru perechile lingvistice care implică portugheză și între 76 și 80 pentru perechile lingvistice care implică catalană.', 'si': 'මේ පත්තුවේ 2021 WMT සමාන භාෂාව භාෂාව භාවිත වැදගත් වැඩේ SEBAMAT සමාන වැදගත් කාර්ය විස්තර කරනවා. මැරියාන් න්\u200dයුරෝල් මැෂින් වාර්තාවක් භාවිත කරන්න, ගුගුල් ගේ වාර්තාවක් ස්ථාපනය අධාරිත පද්ධතිය කැටලාන්-ස්පැ @ info: tooltip ඔවුන්ගේ අධාරික විශ්ලේෂණ ප්\u200dරතිචාර පද්ධතිය අනුවෙන් SEBAMAT පද්ධතිය පුළුවන් වෙලා තියෙන්නේ ඉහළ කණ්ඩායම් සහ BLUE ප්\u200dරතිචාර පද්ධතිය සමග ඉ', 'so': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  Isticmaalidda qoraalka turjumista ee Marian neural machine neural, waxaa lagu dhisay nidaamka turjumista ee ku saleysan dhismaha beddelka ee Google iyo labada hagitaan ee Katalan-Spanish iyo Burtuqiis-Isbanish. Isticmaalka waxaa lagu tababariyey laba kooras oo kala duwan parameter oo kala duduwan (tirada hadalka kala duduwan ee labo koordid) oo lagu isticmaali karo parallel oo kaliya laakiin ma aha shirkadda u eg ee ay qabanqaabiyaan shaqaalaha qayb-qayb ah. Sida uu ku qoran resultimahooda qiimeynta rasmi ah, nidaamka SEBAMAT waxay u muuqatay inay is-khiyaano ku leedahay kooxaha sare iyo kooxaha BLEU oo u dhexeeya 38-47, kuwaas oo ah labada luqada ee Burtuqiis ku saabsan iyo u dhexeeya 76-80-jirka labada luqada ee ku saabsan Katalaan.', 'sv': 'Denna uppsats beskriver SEBAMAT:s bidrag till WMT:s gemensamma uppgift för översättning av liknande språk 2021. Med hjälp av Marians neurala maskinöversättningsverktyg byggdes översättningssystem baserade på Googles transformatorarkitektur i båda riktningarna katalanska-spanska och portugisisk-spanska. Systemen tränades i två kontrastiva parameterinställningar (olika ordförrådsstorlekar för byte par kodning) med endast parallella men inte jämförbara korpora som tillhandahölls av de delade uppgiftsorganisationerna. Enligt deras officiella utvärderingsresultat visade SEBAMAT-systemet sig vara konkurrenskraftigt med rankningar bland topplagen och BLEU-poäng mellan 38 och 47 för språkparen med portugisiska och mellan 76 och 80 för språkparen med katalanska.', 'ta': '2021 WMT ஒத்த மொழி மொழிபெயர்ப்பு பகிர்ந்த பணி மேரியான் புதிய இயந்திரம் மொழிபெயர்ப்பு கருவிப்பெட்டியை பயன்படுத்தி, கூகுலின் மாற்று உருவாக்கி அடிப்படையில் மொழிபெயர்ப்பு அமைப்புகள்  @ info அவர்களுடைய அரசியல் மதிப்பும் முடிவுகளை பூர்த்துகிச் செய்ய, SEBAMAT அமைப்பு மேல் குழுக்களில் இருந்து மேல்குழுக்களுக்கும் மேல்குழுக்களுக்கும் பிலியு மதிப்', 'mn': 'Энэ цаас 2021 оны WMT-тэй адилхан хэл хөрөнгө оруулах үйлдлийг SEBAMAT-ын зориулалтыг тайлбарладаг. Мариан мэдрэлийн механикийн хөгжүүлэх хэрэгсэл кутийг ашиглан Google-ын шилжүүлэх архитектуры үндсэн хөгжүүлэх системүүд Каталан-Испан, Португали-Испанийн хоёр талд бүтээсэн. Энэ систем нь зөвхөн параллел болон хуваалтын зохион байгуулагчид өгсөн харьцангуй корпора байгуулагчид өгсөн хоёр эсрэг параллел хэмжээнд суралцагдсан. Тэдний оюутнуудын оюутнуудын үр дүнд SEBAMAT систем дээд баг болон БЛЕС 38-47 хоорондын хувьд Португалийн хоёр болон 76-80 хоорондын хувьд Каталан хоорондын хэлний хоёр хоорондоо өрсөлдөг байв.', 'ur': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task. ماریان نیورل ماشین کی ترجمہ تولکیٹ کے مطابق، گوگل کی ترجمہ ساختاری پر بنیاد رکھی ہوئی ترجمہ سیستموں کو کاٹلان-اسپانیایی اور پورتوگل-اسپانیایی کے دونوں سمتوں میں بنایا گیا ہے. سیسٹم دو کنٹرسیٹ پارامیٹ سٹینٹوں میں آموزش کی گئی تھی (بائیٹ جوڑوں کا اکنوڈینگ) صرف parallel کے استعمال کرتی تھی لیکن مشترک ٹائک سازمان کرنے والوں کے ذریعہ مہمانی کرپورا نہیں تھا. ان کے رسمی ارزیابی نتیجے کے مطابق، SEBAMAT سیسٹم نے کٹلان میں شامل ہونے والی زبان جوڑوں کے لئے 38 اور 47 کے درمیان رئنڈ کے ساتھ رئنڈ کی ہے۔', 'vi': 'Tờ giấy này mô tả sự đóng góp của SEBAMAT tới bài kiểm dịch ngôn ngữ tương tự 2021 WM. Sử dụng thiết bị dịch chuyển cỗ máy của Marian, Hệ thống dịch dựa trên kiến trúc biến thế của Google được xây dựng cả hai chiều của Tây Ban Nha và Tây Ban Nha. Các hệ thống được huấn luyện theo hai thiết lập tham số tương phản (các kích cỡ từ khác nhau cho việc mã hóa hai cặp byte) chỉ sử dụng các cấu trúc song song song song nhưng không phải vật thể tương ứng được cung cấp bởi các tổ chức tác vụ chia sẻ. Theo kết quả đánh giá chính thức của họ, hệ thống SEBAMAT hóa ra lại được thi đấu với các đội đứng đầu và bảng bắn giữa 38 và 47 của các cặp ngôn ngữ gồm gồm gồm người Bồ Đào Nha và giá trị mọi thứ liên quan đến Catalan.', 'uz': "Bu qogʻoz 2021 WMT oʻxshash tilda tarjima qilingan vazifani SEBAMAT yaratish mumkin. Name Tizimlar faqat parametrlar bilan bir xil kodlash uchun ikkita parametrlar moslamalarida o'rnatildi, lekin ishga tayyorlangan vazifa organischilariga moslamalariga moslama boʻlmadi. According to their official evaluation results, the SEBAMAT system turned out to be competitive with rankings among the top teams and BLEU scores between 38 and 47 for the language pairs involving Portuguese and between 76 and 80 for the language pairs involving Catalan.", 'bg': 'Настоящата статия описва приноса на СЕБАМАТ към споделената задача за превод на подобен език през 2021 г. Използвайки инструментариума за невронен машинен превод на Мариан, преводачески системи, базирани на трансформаторната архитектура на Гугъл, са изградени в двете посоки на каталонско-испански и португалско-испански. Системите са обучени в две настройки на контрастни параметри (различни размери на речника за кодиране на двойки байтове), използвайки само паралелните, но не и съпоставимите корпуси, предоставени от организаторите на споделените задачи. Според официалните им резултати от оценката системата се оказа конкурентна с класиране сред топ отборите и резултати между 38 и 47 за езиковите двойки с португалски език и между 76 и 80 за езиковите двойки с каталунски език.', 'hr': 'Ovaj papir opisuje doprinos SEBAMAT-a za zajednički zadatak WMT sličnog prevoda jezika 2021. godine. Koristeći korištenje uređaja za prevođenje marijskih neuralnih strojeva, sustavi prevođenja na temelju Google-ove transformacijske arhitekture izgrađeni su u obje smjere katalanskog-španjolskog i portugalskog-španjolskog. Sistemi su obučeni u dvije kontrastivne parametre (različite riječne veličine za kodiranje bajtskih parova) koristeći samo paralelno, ali ne usporedno tijelo koje su pružili zajednički organizatori zadataka. Prema njihovim službenim rezultatima procjene, sistem SEBAMAT ispostavilo se da je konkurentni s redovima među najvišim timovima i BLEU rezultatima između 38 i 47 za jezičke parove uključujući portugalce i između 76 i 80 za jezičke parove uključujući katalance.', 'nl': "Dit artikel beschrijft de SEBAMAT-bijdrage aan de gezamenlijke taak voor WMT Vergelijkbare Taalvertaling. Met behulp van de Marian neural machine translation toolkit werden vertaalsystemen gebouwd op basis van Google's transformatorarchitectuur in beide richtingen van Catalaans-Spaans en Portugees-Spaans. De systemen werden getraind in twee contrastieve parameterinstellingen (verschillende vocabulaire groottes voor byte pair codering) met behulp van alleen de parallelle maar niet de vergelijkbare corpora die door de gedeelde taakomganisaties worden verstrekt. Volgens hun officiële evaluatieresultaten bleek het SEBAMAT-systeem concurrerend te zijn met rankings onder de topteams en BLEU-scores tussen 38 en 47 voor de taalparen met Portugees en tussen 76 en 80 voor de taalparen met Catalaans.", 'da': "I denne artikel beskrives SEBAMAT's bidrag til WMT's delte opgave for lignende sprogoversættelse i 2021. Ved hjælp af Marian neurale maskinoversættelsesværktøjssæt blev oversættelsessystemer baseret på Googles transformatorarkitektur bygget i begge retninger af catalansk-spansk og portugisisk-spansk. Systemerne blev trænet i to kontrastive parameterindstillinger (forskellige ordforråd størrelser for byte par kodning) ved hjælp af kun parallelle, men ikke sammenlignelige corpora leveret af de delte opgavearrangører. Ifølge deres officielle evalueringsresultater viste SEBAMAT-systemet sig at være konkurrencedygtigt med placeringer blandt de bedste hold og BLEU scorer mellem 38 og 47 for sprogpar, der involverer portugisisk, og mellem 76 og 80 for sprogpar, der involverer catalansk.", 'de': 'Dieser Beitrag beschreibt den SEBAMAT-Beitrag zur gemeinsamen Aufgabe für WMT-Übersetzung in ähnlicher Sprache. Mit Hilfe des marianischen Toolkits für neuronale maschinelle Übersetzung wurden Übersetzungssysteme basierend auf Googles Transformatorarchitektur in beide Richtungen von Katalanisch-Spanisch und Portugiesisch-Spanisch gebaut. Die Systeme wurden in zwei kontrastiven Parametereinstellungen trainiert (unterschiedliche Vokabelgrößen für Byte-Paar-Codierung), wobei nur die parallelen, aber nicht vergleichbaren Korpora verwendet wurden, die von den gemeinsamen Aufgabenorganisationen bereitgestellt wurden. Laut den offiziellen Bewertungsergebnissen erwies sich das SEBAMAT-System als wettbewerbsfähig mit Rankings unter den Top-Teams und BLEU-Ergebnissen zwischen 38 und 47 für die Sprachpaare mit Portugiesisch und zwischen 76 und 80 für die Sprachpaare mit Katalanisch.', 'ko': '본고는 SEBAMAT가 2021년 WMT 유사 언어 번역 공유 임무에 기여한 바를 묘사한다.Marian neural machine translation toolkit을 사용해 카탈루냐어 스페인어와 포르투갈어 스페인어 두 방향에서 구글 transformer 구조를 기반으로 한 번역 시스템을 구축했다.이 시스템들은 두 가지 비교 매개 변수 설정(바이트가 인코딩에 대한 서로 다른 어휘 크기)에서 훈련을 하고 공유 작업 조직자가 제공하는 평행 자료 라이브러리만 사용하며 비교할 수 있는 자료 라이브러리는 사용하지 않는다.이들의 공식 평가 결과에 따르면 SEBAMAT 시스템은 톱 팀에서 순위가 경쟁력이 있다. 포르투갈어를 다루는 언어는 BLEU에 38~47, 카탈로니아어를 다루는 언어는 BLEU에 76~80의 점수를 얻었다.', 'id': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  Menggunakan alat terjemahan mesin saraf Marian, sistem terjemahan berdasarkan arsitektur transformer Google dibangun dalam kedua arah Catalan-Spanyol dan Portugis-Spanyol. The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers.  Menurut hasil evaluasi resmi mereka, sistem SEBAMAT ternyata kompetitif dengan rangkaian diantara tim terbaik dan nilai BLEU antara 38 dan 47 untuk pasangan bahasa yang melibatkan Portugis dan antara 76 dan 80 untuk pasangan bahasa yang melibatkan Catalan.', 'sw': 'Gazeti hili linaelezea mchango wa SEBAMAT kwenye tafsiri ya lugha inayofanana na 2021 WMT. Kwa kutumia vifaa vya kutafsiri mashine ya kijamii vya Maria, mifumo ya kutafsiri kwa kutumia ujenzi wa mabadiliko ya Google ulijengwa katika njia zote za Kikatalani-Spanish na Kireno. The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers.  Kwa mujibu wa matokeo rasmi ya uchunguzi, mfumo wa SEBAMAT ulionekana kuwa jitihada na watawala wa rangi kati ya timu za juu na vipindi vya BLEU kati ya 38 na 47 kwa ajili ya wanandoa wa lugha wanaohusisha Kireno na kati ya 76 na 80 kwa ajili ya wanaume wa lugha wanaohusiana na Catalan.', 'fa': 'این کاغذ مشترک شرکت SEBAMAT را به کار مشترک ترجمه زبان شبیه WMT ۲۰۱۱ توصیف می\u200cکند. استفاده از ابزار ترجمه ماشین عصبی ماریان، سیستم ترجمه بر اساس معماری تغییر دهنده گوگل در هر دو مسیر کاتالان-اسپانیایی و پورتوژیک-اسپانیایی ساخته شده است. سیستم\u200cها در دو تنظیمات پارامتر متفاوتی (اندازه\u200cهای کلمات متفاوت برای رمزبندی جفت بایت) آموزش داده شده\u200cاند، تنها با استفاده از متفاوت، ولی نه corpora قابل مقایسه\u200cای که توسط سازمان\u200cکنندگان کار مشترک داده شده\u200cاند. بر اساس نتیجه ارزیابی رسمی\u200cشان، سیستم SEBAMAT معلوم شد که با رقابت\u200cها بین تیم\u200cهای بالایی و امتیاز BLEU بین 38 و 47 برای جفت زبانی که شامل پرتغالی است و بین 76 و 80 برای جفت زبانی که شامل کاتالان است رقابت می\u200cکند.', 'tr': "Bu kagyz 2021-nji WMT täsirli dilleriň terjime edilen işine SEBAMAT täsirini tassyklaýar. Google'yň üýtgewçi arhitekturyna daýanýan Mariýanyň neural maşynyň terjime çykyşynyň ýerini Katalan-Ispanýolça we Portugalça-Ispanýolça yönünde guruldy. Sistemler iki kontrast parameterler düzümlerinde (baýt çift ködlemeleri üçin farklı sözlük ullanylar) diňe parallel üçin ullanýarlar, ýöne paylaşyk düzümlerniň tarapyndan berilen ýakynlaşyk korpora däl. Resmi değerlendirmeleriniň netijesine görä, SEBAMAT sistemasy iň üst toparlar we BLES toparlar arasynda 38 we 47-de aralygynda portugalça we 76 we 80-de aralygynda Catalan bilen ilgili dil çiftleri üçin duşuşykly bolup göründi.", 'af': 'Hierdie papier beskrywe die SEBAMAT bydraai na die 2021 WMT Likelike Taal Vertaling gedeelde taak. Gebruik van die Marian neurale masjien vertaling nutsbalkit, vertaling stelsels gebaseer op Google se transformer arkitektuur is gebou in beide rigtings van Katalan-Spaanse en Portugese-Spaanse. Die stelsels is opgelei in twee kontrastiewe parameter instellings (verskillende woordeboek grootte vir byte paar kodering) gebruik slegs die parallele maar nie die vergelykbare korpora verskaf deur die gedeelde taak organiseerders nie. Volgens hulle offisiele evalueringsresultate, het die SEBAMAT stelsel uitgeskakel om te rekenaar met rangings tussen die boonste teams en BLES-tellings tussen 38 en 47 vir die taal paars wat Portugees en tussen 76 en 80 aansluit vir die taal paars wat Katalan aansluit.', 'am': "This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  Using the Marian neural machine translation toolkit, translation systems based on Google's transformer architecture were built in both directions of Catalan-Spanish and Portuguese-Spanish.  ስርዓቶች በተለየ ሁለት ተቃውሞ አካባቢዎች (ለባይት ሁለት ዓይነቶች የኢኮድ ክፍተት) በተለየ በተለየ ፓርቲው ብቻ ሳይተያያየው ኮርፖር ግን በተለየ ስራ አካባቢዎች እንዲሰጧቸው ነው፡፡ እንደ ባለሥልጣን ውጤቶች፣ የSEBAMAT ስርዓት ክፍል በ38 እና 47 ክፍል መካከል በፖርቱጋልኛ እና በካታላን መካከል ለቋንቋው ሚስቶች መካከል 76 እና 80 መካከለኛ ለቋንቋው ሁኔታ ጋር ተቃዋሚ ሆኖአል፡፡", 'sq': 'Ky dokument përshkruan kontributin e SEBAMAT në detyrën e përbashkët të përkthimit të gjuhës së ngjashme WMT 2021. Duke përdorur kompletin e mjeteve të përkthimit të makinave nervore mariane, sistemet e përkthimit bazuar në arkitekturën e transformuesit të Google u ndërtuan në të dy drejtimet e katalan-spanjoll dhe portugal-spanjoll. The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers.  Sipas rezultateve zyrtare të tyre të vlerësimit, sistemi SEBAMAT u bë konkurrues me renditjet midis ekipave më të larta dhe rezultatet BLEU midis 38 dhe 47 për çiftet e gjuhës që përfshijnë portugalisht dhe midis 76 dhe 80 për çiftet e gjuhës që përfshijnë katalanët.', 'hy': 'Այս հոդվածը նկարագրում է SEBAMAT-ի ներդրումը 2021 թվականին ՄԻԱՎ Նմանատիպ լեզվի թարգմանման ընդհանուր խնդիրը: Օգտագործելով Մարիայի նյարդային մեքենայի թարգմանման գործիքների շարքը, Google-ի վերափոխողի ճարտարապետության հիմնված թարգմանման համակարգերը կառուցվել են Կատալան-իսպաներեն և Պորտուգալ-իսպաներեն երկու ուղղություններում Այս համակարգերը վարժեցվել էին երկու հակադրական պարամետրերի միջոցով (բայտի զույգերի կոդավորման բառերի տարբեր չափսեր), օգտագործելով միայն զուգահեռ, բայց ոչ համեմատական կոպորան, որը տրամադրվել է ընդհանուր գործողությունների կազմակերպողների կո Ըստ իրենց պաշտոնական գնահատման արդյունքների, SEBAMAT համակարգը պարզվեց, որ մրցակցություն ունի լավագույն թիմերի գնահատականների հետ, իսկ ԲԼԵՎ գնահատականների 38-47 տարեկան գնահատականների համար, որոնք ներառում են պորտուգալերեն, և 76-80 տարեկան գնահատականների համար', 'bn': 'This paper describes the SEBAMAT contribution to the 2021 WMT Similar Language Translation shared task.  মারিয়ান নিউরেল মেশিনের অনুবাদ টুলকিট ব্যবহার করে গুগলের পরিবর্তনের স্থানান্তরের ভিত্তিক অনুবাদ সিস্টেম ক্যাটালান-স্প্যানিশ এবং পর্তুগ সিস্টেমের প্রশিক্ষণ দুটি বিরোধী প্যারামিটার বৈশিষ্ট্যে (বাইট জুড়ে এনকোডিং এর বিভিন্ন শব্দভাণ্ডারের আকার) শুধুমাত্র তালিকা ব্যবহার করে ক তাদের অফিসিয়াল মুল্যায়নের ফলাফল অনুসারে, সেবামাট সিস্টেম শীর্ষ দল এবং বিলিউ স্কোরের মধ্যে প্রতিযোগিতার সাথে প্রতিদ্বন্দ্বিতা করে দেখা গেছে যে তারা পোর্টুগীজে', 'az': "Bu kağıt 2021 WMT kimi dil tercüməsi paylaşılan işin SEBAMAT qismətini təsdiq edir. Qatalan-İspanyol-İspanyol və Portugal-İspanyolun hər ikisinin tərəfində qurulmuş Marian nöral maşın tərcümə aracılığı ilə Google'un transformer arhitektarına dayanan tərcümə sistemləri tərcümə edilmişdir. Sistemlər yalnızca paralel olaraq, paylaşılan işlər organizatorların təyin etdiyi kompatibil korpora ilə iki müxtəlif parametr ayarlarında təhsil edilmişdir. Onların resmi değerlendirmə sonuçlarına görə, SEBAMAT sistemi ən yüksək takımların arasında 38-47 arasında və BLEU nöqtələri arasında, portugalca və 76-80 arasında Catalan əlaqəsində olan dil çiftləri üçün yarışmağa başladı.", 'ca': "Aquest paper descriu la contribució del SEBAMAT a la tasca compartida de traducció de llenguatges semblants del 2021. Utilitzant el conjunt d'eines de traducció neuronal marià, els sistemes de traducció basats en l'arquitectura transformadora de Google van ser construïts en ambdues direccions català-espanyol i portuguès-espanyol. Els sistemes van ser entrenats en dos paràmetres contrastius (diferents tamanys de vocabulari per la codificació de parell de bytes) utilitzant només el corpora paral·lel però no comparable proporcionat pels organitzadors compartits de tasques. Segons els seus resultats oficials d'evaluació, el sistema SEBAMAT va resultar ser competitiu amb puntuacions entre els millors equips i puntuacions BLEU entre 38 i 47 per als parells de llenguatges que impliquen portuguès i entre 76 i 80 per als parells de llenguatges que impliquen catalans.", 'cs': 'Tento článek popisuje příspěvek SEBAMATu na sdílenou úlohu 2021 WMT Překlad podobných jazyků. Pomocí sady nástrojů Marian neuron strojového překladu byly postaveny překladové systémy založené na transformátorové architektuře Googlu v obou směrech katalánsky-španělštiny a portugalsko-španělštiny. Systémy byly trénovány ve dvou kontrastních parametrech (různé velikosti slovní zásoby pro kódování bajtových párů) pomocí paralelních, ale ne srovnatelných korpusů poskytovaných organizátory sdílených úloh. Podle oficiálních výsledků hodnocení se systém SEBAMAT ukázal být konkurenceschopný s žebříčky mezi nejlepšími týmy a BLEU skóre mezi 38 a 47 pro jazykové páry zahrnující portugalštinu a mezi 76 a 80 pro jazykové páry zahrnující katalánštinu.', 'bs': 'Ovaj papir opisuje doprinos SEBAMAT-a na zajednički zadatak WMT sličnog prevoda jezika 2021. godine. Koristeći uređaj za prevod marijskih neuralnih strojeva, sustavi prevoda na temelju Google-ove transformacijske arhitekture izgrađeni su u obje smjere katalanskog-španjolskog i portugalskog-španjolskog. Sistemi su obučeni u dva kontrastivna postavka parametara (različite veličine riječnika za kodiranje bajtskih parova) koristeći samo paralelnu, ali ne usporedbenu korporaciju koje su pružili zajednički organizatori zadataka. Prema njihovim službenim rezultatima procjene, sistem SEBAMAT ispostavilo se da je konkurentni sa redovima među najboljim timovima i BLEU rezultatima između 38 i 47 za jezičke parove uključujući portugalce i između 76 i 80 za jezičke parove uključujući katalance.', 'et': "Käesolevas dokumendis kirjeldatakse SEBAMATi panust 2021. aasta WMT sarnase keele tõlke jagatud ülesandesse. Mariani neuromasintõlke tööriistakomplekti abil ehitati Google'i transformaatori arhitektuuril põhinevad tõlkesüsteemid mõlemas katalaani-hispaania ja portugali-hispaania suunas. Süsteeme koolitati kahe kontrastse parameetri seadistusega (baidipaari kodeerimisel erinevad sõnavara suurused), kasutades ainult paralleelseid, kuid mitte võrreldavaid korpuseid, mida jagatud ülesannete korraldajad pakkusid. Ametlike hindamistulemuste kohaselt osutus SEBAMAT-süsteem konkurentsivõimeliseks parimate meeskondade hulgas ning BLEU tulemused olid portugali keelepaaride puhul 38–47 ning katalaani keelepaaride puhul 76–80.", 'fi': 'Tรคssรค artikkelissa kuvataan SEBAMATin panos vuoden 2021 WMT Similar Language Translation jaettuun tehtรคvรครคn. Marianin neurokonekรครคnnรถstyรถkalujen avulla rakennettiin Googlen muuntajaarkkitehtuuriin perustuvia kรครคnnรถsjรคrjestelmiรค molempiin suuntiin katalaani-espanjaksi ja portugali-espanjaksi. Jรคrjestelmรคt koulutettiin kahteen kontrastiin perustuvaan parametriasetukseen (tavuparin koodaukseen eri sanastokoot) kรคyttรคen vain rinnakkaisia mutta ei vertailukelpoisia korpusia, jotka jaettujen tehtรคvien jรคrjestรคjรคt antoivat. Virallisten arviointitulosten mukaan SEBAMAT-jรคrjestelmรค osoittautui kilpailukykyiseksi huippujoukkueiden joukossa ja BLEU:n pisteet olivat 38โ\x80\x9347 portugalin kielipareissa ja 76โ\x80\x9380 katalaanin kielipareissa.', 'jv': 'Pamir iki rambarang nggawe gerasane SEBIMAT nang nggawe gerasane nggawe gerasane, nggo langkung urip SEBIMAT karo nggawe gerasane kanggo nggawe gerasane Jejaring Ngawe nguwe barang pancen itoleh marian Neral, sistem itoleh sing bisa sabên karo architecture kanggo Google iki dadi sing dirampakan karo Catlan-Spanish karo Putuk-Spanish. Sistem sampeyan wis kelakon kelas telu nggo sampek durung contrast Suara kang dipolehasan urip punika dipolehasan, sistem SEPAMAT kuwi wis dipolehasan karo rangsane sing katêpakan karo rangsane sing dibuté katêpakan karo perangkat oleh sing nêmêr sing katêpakan karo bendhik sing katêpakan karo bendhik sing katêpakan karo bendhik sing katêpakan karo bendhik sing katêpakan karo tinggal sing isi', 'sk': 'V tem članku je opisan prispevek SEBAMAT k skupni nalogi WMT podobnega jezika prevajanja leta 2021. S pomočjo marianskega orodja za nevronsko strojno prevajanje so bili zgrajeni prevajalski sistemi, ki temeljijo na Googlovi transformatorski arhitekturi, v obeh smereh katalonsko-španskega in portugalsko-španskega. Sistemi so bili usposobljeni v dveh nastavitvah kontrastnih parametrov (različne velikosti besedišča za kodiranje bajtnih parov) z uporabo samo vzporednih, vendar ne primerljivih korpusov, ki so jih zagotovili organizatorji skupnih nalog. Po uradnih rezultatih ocenjevanja se je sistem SEBAMAT izkazal za konkurenčnega z lestvicami med najboljšimi ekipami in rezultati BLEU med 38 in 47 za jezikovne pare, ki vključujejo portugalščino, in med 76 in 80 za jezikovne pare, ki vključujejo katalonščino.', 'ha': "@ info: whatsthis @ info: tooltip An sanar da system cikin tsarin parameter biyu mai motsi (girma wa tsarin maganar kwamfyuta ko-biyu) da ke amfani da shi kawai da parallel kuma ba da daidaita korpo da aka ba da mãsu shirin aikin da aka raba shi. Li gori da fassararsu na rasmi, na'urar seBAMAT ya zama mai competiti a tsakanin jama'a sarki da matsayin BLEU na tsakanin 38 da 47 zuwa harshen nau'in da ke haɗa Portugueski da tsakanin 76 da 80 na harshen nau'in da ke haɗi Katalan.", 'he': 'העיתון הזה מתאר את התרומה של SEBAMAT למשימה המשותפת של WMT 2021. באמצעות ערכת כלי התרגום של מכונות עצביות מאריות, מערכות התרגום המבוססות על ארכיטקטורת המעבר של גוגל נבנו בשני הכיוונים של קטלן-ספרדי ופורטוגזי-ספרדי. המערכות הוכשרו בשני סדרות פארמטרים בניגוד (גודלים מילים שונים לקוד זוג בייטים) בשימוש רק במקביל, אך לא הקופורה השוואה שנספקה על ידי מארגני המשימה המשותפים. לפי תוצאות הערכה הרשמיות שלהם, מערכת SEBAMAT התבררה להיות תחרותית עם ציונים בין הקבוצות העליונות והציונים BLEU בין 38 ל-47 עבור זוגות שפות שמעורבים פורטוגזית ובין 76 ל-80 עבור זוגות שפות שמעורבים קטלנית.', 'bo': '2021 WMT དེ་ལྟ་བུའི་སྐད་ཡིག་ཆ་རྒྱབ་སྤྲོད་ཀྱི་ལས་འགུལ་འདིའི་ནང་དུ་SEBAMAT་གི་གོ་སྐབས་ཀྱི་འགྲེལ་བཤད་ཀྱི་ཡོད། གུ་གལ་གྱི་འགྱུར་ཆས་གཞུང་གི་མ་རེ་འཁོར་གཞུང་གིས་སྤྱད་ནས་དུ་གུ་གལ་སྲིད་གཞུང་བཟོ་བ་གི་བཟོ་བཅོས་རྩིས་གཞུང་གཉིས་ཀྱི་གདོང་སྣེ་ནས The systems were trained in two contrastive parameter settings (different vocabulary sizes for byte pair encoding) using only the parallel but not the comparable corpora provided by the shared task organizers. གཞུང་འབྲེལ་གྱི་དཔྱད་འགན་གཉིས་ཀྱི་རྒྱབ་ལུགས་ལ་བསྟུན། SEBAMAT་གྱི་མ་ལག་གི་ཚད་ལྟར་རྒྱལ་ཁབ་པའི་དབུགས་གནད་ཁྱེར་དང་སྒྲིག་དབུགས་གནད་ཁྱེར་གཉིས་ལས་ཀྱང་མཐུན་བཟོ་བ'}
{'en': 'Adapting ', 'ar': 'تكييف الترجمة الآلية العصبية للتحرير التلقائي اللاحق', 'pt': 'Adaptando a tradução automática neural para pós-edição automática', 'fr': 'Adaptation de la traduction automatique neuronale pour la post-édition automatique', 'es': 'Adaptación de la traducción automática neuronal para la post-edición automática', 'ja': '自動ポストエディットのための神経機械翻訳の適応', 'hi': 'स्वचालित पोस्ट-संपादन के लिए न्यूरल मशीन अनुवाद को अनुकूलित करना', 'zh': '使神经机器翻译应自译后辑', 'ru': 'Адаптация нейронного машинного перевода для автоматического пост-редактирования', 'ga': 'Aistriú Meaisín Néarthach a Oiriúnú le haghaidh Iar-Eagarthóireacht Uathoibríoch', 'ka': 'ავტომატური დარედაქტირებისთვის ნეიროლური მაქინის გადატყვება', 'it': 'Adattamento della traduzione automatica neurale per la post-modifica automatica', 'kk': 'Автоматты кейін өңдеу үшін нейрондық машинаның аудармасын адаптау', 'lt': 'Adapting Neural Machine Translation for Automatic Post-Editing', 'mk': 'Адаптирање на превод на неврална машина за автоматско постуредување', 'ms': 'Penyesuaian Terjemahan Mesin Neural untuk Pengeditan-Automatik', 'hu': 'A neurális gépi fordítás adaptálása az automatikus utószerkesztéshez', 'mt': 'Adattar tat-Traduzzjoni tal-Magna Newrali għal Post-Editar Awtomatiku', 'ml': 'Adapting Neural Machine Translation for Automatic Post-Editing', 'no': 'Tilpass neuralmaskinsomsetjing for automatisk post- redigering', 'mn': 'Автоматтын дараа засварлахын тулд мэдрэлийн машин хөгжүүлэх', 'el': 'Προσαρμογή νευρωνικής μηχανικής μετάφρασης για αυτόματη μετα-επεξεργασία', 'ro': 'Adaptarea traducerii automate neurale pentru editarea automată', 'pl': 'Dostosowanie neuronowego tłumaczenia maszynowego do automatycznej edycji post-edycyjnej', 'si': 'ස්වයංක්\u200dරීය පස්ස සංපාදනය සඳහා න්\u200dයූරාල් මැෂින් පරිවර්තනය', 'sr': 'Прадаптирање невралног превода за автоматично постредање', 'sv': 'Anpassning av neural maskinöversättning för automatisk efterredigering', 'ta': 'தானியங்கி பின்தொகுப்புக்கு மொழிபெயர்ப்புக்கான புதிய இயந்திரத்தை ஏற்றுகிறது', 'so': 'Turjumista machinka Neural ee Automatic-Editing', 'ur': 'اٹوٹوٹ پوسٹ ویڈینگ کے لئے نیورال ماشین ترجمہ اڈیٹ کیے جاتے ہیں', 'uz': 'Name', 'vi': 'Chỉnh sửa máy thần kinh cho Automatic Post-Editing', 'bg': 'Адаптиране на неврален машинен превод за автоматично пост-редактиране', 'da': 'Tilpasning af neural maskinoversættelse til automatisk post-redigering', 'hr': 'Prilagođenje Neuralnog prevoda za automatsko nakon uredbe', 'nl': 'Neuronale machinevertaling aanpassen voor automatische nabewerking', 'de': 'Anpassung der neuronalen maschinellen Übersetzung für die automatische Nachbearbeitung', 'ko': '자동 적응 신경 기계 번역의 자동 후기 편집', 'fa': 'تنظیم ترجمه ماشین عصبی برای بعد ویرایش خودکار', 'id': 'Mengadaptasi Translation Mesin Neural untuk Post-Editing Otomatis', 'sw': 'Tafsiri ya Mashine ya Kifaransa kwa ajili ya Kuhariri Baada ya Ufaransa', 'af': 'Name', 'am': 'ትርጉም', 'az': 'Avtomatik Post-Editing üçün Nöral Makinat Çeviri Adlandırma', 'tr': 'Otomatik Po-Editlemek üçin näral Maşynyň terjimesini bejermek', 'bn': 'স্বয়ংক্রিয়ভাবে পোস্ট সম্পাদনের জন্য নিউরাল মেশিন অনুবাদ আপডেট করা হচ্ছে', 'bs': 'Prilagođenje Neuralnog prevoda za automatsko posturedjenje', 'ca': 'Adaptar la traducció de màquines neuronals per a la postedició automàtica', 'cs': 'Přizpůsobení neurálního strojového překladu pro automatické posteditování', 'fi': 'Neuraalisen konekäännöksen mukauttaminen automaattiseen jälkimuokkaukseen', 'hy': 'Comment', 'sq': 'Adaptimi i përkthimit të Makinës Neurale për Posteditimin Automatik', 'et': 'Neuraalse masintõlke kohandamine automaatseks järeltöötluseks', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'Adapting Neural Machine Translation for Automatic Post-Editing', 'sk': 'Prilagajanje nevralnega strojnega prevajanja za samodejno post-urejanje', 'bo': 'རང་འགུལ་གྱིས་ཤུལ་བསྒྱུར་བཅོས་ལ་རང་འགུལ་གྱི་ལག་འཁྱེར་ལ་སྒྱུར་བཟོ་བྱེད་པ', 'ha': '@ action'}
{'en': 'Automatic post-editing (APE) models are usedto correct machine translation (MT) system outputs by learning from human post-editing patterns. We present the system used in our submission to the WMT’21 Automatic Post-Editing (APE) English-German (En-De) shared task. We leverage the state-of-the-art MT system (Ng et al., 2019) for this task. For further improvements, we adapt the MT model to the task domain by using WikiMatrix (Schwenket al., 2021) followed by fine-tuning with additional APE samples from previous editions of the ', 'ar': "تُستخدم نماذج التحرير اللاحق التلقائية (APE) لتصحيح مخرجات نظام الترجمة الآلية (MT) من خلال التعلم من أنماط التحرير اللاحقة البشرية. نقدم النظام المستخدم في إرسالنا إلى مهمة WMT'21 التلقائية للتحرير اللاحق (APE) الإنجليزية-الألمانية (En-De) المشتركة. نستفيد من أحدث أنظمة الترجمة الآلية (Ng et al. ، 2019) لهذه المهمة. لمزيد من التحسينات ، قمنا بتكييف نموذج MT مع مجال المهمة باستخدام WikiMatrix (Schwenket al. ، 2021) متبوعًا بضبط دقيق مع عينات APE إضافية من الإصدارات السابقة للمهمة المشتركة (WMT-16 ، 17 ، 18) والتجميع نماذج. تفوقت أنظمتنا على خط الأساس في درجات TER في مجموعة اختبار WMT'21.", 'es': "Los modelos de postedición automática (APE) se utilizan para corregir los resultados del sistema de traducción automática (MT) mediante el aprendizaje de los patrones de postedición humanos. Presentamos el sistema utilizado en nuestro envío a la tarea compartida de Postedición Automática (APE) Inglés-Alemán (En-De) del WMT'21. Aprovechamos el sistema de MT de última generación (Ng et al., 2019) para esta tarea. Para mejoras adicionales, adaptamos el modelo de MT al dominio de tareas mediante el uso de WikiMatrix (Schwenket al., 2021), seguido de un ajuste fino con muestras APE adicionales de ediciones anteriores de la tarea compartida (WMT-16,17,18) y el ensamblaje de los modelos. Nuestros sistemas superaron la línea de base en los puntajes TER en el conjunto de pruebas WMT'21.", 'fr': "Les modèles de post-édition automatique (APE) sont utilisés pour corriger les sorties du système de traduction automatique (MT) en apprenant des modèles de post-édition humains. Nous présentons le système utilisé dans notre soumission à la tâche partagée WMT'21 Automatic Post-Editing (APE) anglais-allemand (En-De). Nous utilisons le système de TA de pointe (Ng et al., 2019) pour cette tâche. Pour d'autres améliorations, nous adaptons le modèle de TA au domaine de tâches en utilisant WikiMatrix (Schwenket al., 2021), puis nous peaufinons avec des échantillons APE supplémentaires provenant des éditions précédentes de la tâche partagée (WMT-16,17,18) et en assemblant les modèles. Nos systèmes surpassent les scores TER de référence sur l'ensemble de test WMT'21.", 'pt': "Os modelos de pós-edição automática (APE) são usados para corrigir as saídas do sistema de tradução automática (MT) aprendendo com os padrões humanos de pós-edição. Apresentamos o sistema usado em nossa submissão para a tarefa compartilhada WMT'21 Automatic Post-Editing (APE) Inglês-Alemão (En-De). Aproveitamos o sistema de MT de última geração (Ng et al., 2019) para esta tarefa. Para melhorias adicionais, adaptamos o modelo MT ao domínio da tarefa usando WikiMatrix (Schwenket al., 2021) seguido de ajuste fino com amostras APE adicionais de edições anteriores da tarefa compartilhada (WMT-16,17,18) e ensembling os modelos. Nossos sistemas superaram a linha de base nas pontuações TER no conjunto de testes WMT'21.", 'ru': "Модели автоматического пост-редактирования (APE) используются для коррекции результатов системы машинного перевода (MT) путем обучения на основе шаблонов человеческого пост-редактирования. Мы представляем систему, использованную в нашем представлении совместной задаче WMT'21 Automatic Post-Editing (APE) English-German (En-De). Для выполнения этой задачи мы используем современную систему MT (Ng et al., 2019). Для дальнейших улучшений мы адаптируем модель MT к области задач с помощью WikiMatrix (Schwenket al., 2021) с последующей точной настройкой с дополнительными образцами ОБЕЗЬЯН из предыдущих редакций общей задачи (WMT-16,17,18) и ансамблем моделей. Наши системы опередили базовую линию по баллам TER на тестовом наборе WMT'21.", 'zh': "自译后辑 (APE) 模以学人工译后辑模式以正机器翻译 (MT) 统输。 向 WMT21 自译后编辑 (APE) 英语-德语 (En-De) 共享提交之统。 我因先进之机器翻译以统(Ng et al., 2019)以成其事。 以WikiMatrix(Schwenket al.2021)调MT,然后用共事者(WMT-16,1718)其他APE样本而整合之。 我们的系统在WMT'21测试集的TER分数上超过了基线。", 'ja': "自動ポストエディット（ APE ）モデルは、人間のポストエディットパターンから学習することによって機械翻訳（ MT ）システム出力を修正するために使用されます。WMT '21自動ポストエディット（ APE ）英独（ En - De ）共有タスクへの提出に使用されたシステムを提示します。このタスクには、最先端のMTシステム（ Ng et al., 2019 ）を活用しています。さらなる改善のために、我々は、ＷｉｋｉＭａｔｒｉｘ （ Ｓｈｗｅｎｋｅｔ ｅ ｔ ａ ｌ ． ， ２ ０ ２ １ ）を使用してタスクドメインにＭＴモデルを適応させ、続いて、共有タスクの以前のエディション（ ＷＭＴ － １ ６ ， １ ７ ， １ ８ ）からの追加の類人猿サンプルを用いて微調整し、モデルをアンサンブルする。我々のシステムは、WMT' 21試験装置のTERスコアのベースラインを超えています。", 'hi': "स्वचालित पोस्ट-एडिटिंग (एपीई) मॉडल का उपयोग मानव पोस्ट-एडिटिंग पैटर्न से सीखकर मशीन अनुवाद (एमटी) सिस्टम आउटपुट को सही करने के लिए किया जाता है। हम WMT'21 स्वचालित पोस्ट-एडिटिंग (APE) अंग्रेजी-जर्मन (En-De) साझा कार्य के लिए हमारे सबमिशन में उपयोग की जाने वाली प्रणाली को प्रस्तुत करते हैं। हम इस कार्य के लिए अत्याधुनिक एमटी सिस्टम (एनजी एट अल. 2019) का लाभ उठाते हैं। आगे के सुधार के लिए, हम Mt मॉडल को WikiMatrix (Schwenket al., 2021) का उपयोग करके कार्य डोमेन के लिए अनुकूलित करते हैं, जिसके बाद साझा कार्य (WMT-16,17,18) के पिछले संस्करणों से अतिरिक्त एपीई नमूनों के साथ ठीक-ट्यूनिंग और मॉडल को घेरते हैं। हमारे सिस्टम ने WMT'21 परीक्षण सेट पर TER स्कोर पर बेसलाइन को हराया।", 'ga': "Úsáidtear samhlacha uathoibríocha iar-eagarthóireachta (APE) chun aschuir chórais aistriúcháin mheaisín (MT) a cheartú trí fhoghlaim ó phatrúin iar-eagarthóireachta daonna. Cuirimid i láthair an córas a úsáideadh inár n-aighneacht don tasc roinnte Béarla-Gearmáinis (En-De) WMT'21 Uathoibríoch Iar-Eagarthóireachta (APE). Déanaimid giaráil ar an gcóras MT úrscothach (Ng et al., 2019) don tasc seo. Chun tuilleadh feabhsuithe a dhéanamh, cuirimid an tsamhail MT in oiriúint don réimse taisc trí úsáid a bhaint as WikiMatrix (Schwenket al., 2021) agus ina dhiaidh sin mionchoigeartú le samplaí APE breise ó eagráin roimhe seo den tasc comhroinnte (WMT-16,17,18) agus feannadh na múnlaí. Bhuaigh ár gcórais an bhunlíne ar scóir TER ar thacar tástála WMT'21.", 'hu': "Automatikus utószerkesztő (APE) modelleket használnak a gépi fordítási (MT) rendszer kimeneteinek helyesbítésére az emberi utószerkesztő mintákból való tanulás révén. Bemutatjuk a WMT'21 Automatic Post-Editing (APE) angol-német (En-De) megosztott feladathoz használt rendszert. Ehhez a feladathoz kihasználjuk a legkorszerűbb MT rendszert (Ng et al., 2019). További fejlesztések érdekében a WikiMatrix (Schwenket al., 2021) segítségével adaptáljuk az MT modellt a feladattartományhoz, majd finomhangoljuk további APE mintákkal a megosztott feladat korábbi kiadásaiból (WMT-16,17,18) és összeállítjuk a modelleket. Rendszereink legyőzték a TER pontszámokat a WMT'21 tesztkészleten.", 'it': "I modelli di post-editing automatico (APE) sono utilizzati per correggere gli output del sistema di traduzione automatica (MT) imparando dai modelli umani di post-editing. Presentiamo il sistema utilizzato nella nostra presentazione al compito condiviso WMT'21 Automatic Post-Editing (APE) inglese-tedesco (En-De). Facciamo leva sul sistema MT all'avanguardia (Ng et al., 2019) per questo compito. Per ulteriori miglioramenti, adattiamo il modello MT al dominio delle attività utilizzando WikiMatrix (Schwenket al., 2021) seguito da una messa a punto con ulteriori campioni APE delle precedenti edizioni del task condiviso (WMT-16,17,18) e assemblando i modelli. I nostri sistemi hanno battuto la base dei punteggi TER sul set di test WMT'21.", 'el': "Τα μοντέλα αυτόματης μετα-επεξεργασίας (APE) χρησιμοποιούνται για τη σωστή απόδοση συστημάτων μηχανικής μετάφρασης (MT) μαθαίνοντας από ανθρώπινα πρότυπα μετα-επεξεργασίας. Παρουσιάζουμε το σύστημα που χρησιμοποιήθηκε στην υποβολή μας στο κοινό έργο της αυτόματης μετα-επεξεργασίας (ΑΠE). Χρησιμοποιούμε το υπερσύγχρονο σύστημα ΜΤ (κ.α., 2019) για αυτό το έργο. Για περαιτέρω βελτιώσεις, προσαρμόζουμε το μοντέλο ΜΤ στον τομέα εργασιών χρησιμοποιώντας το WikiMatrix (Schwenket al., 2021) ακολουθούμενο από την τελειοποίηση με πρόσθετα δείγματα APE από προηγούμενες εκδόσεις της κοινής εργασίας (WMT-16,17,18) και τη σύνθεση των μοντέλων. Τα συστήματά μας νίκησαν τη βάση των βαθμολογιών TER στο σετ δοκιμών WMT'21.", 'lt': "Automatiniai po redakcijos (APE) modeliai naudojami mašininio vertimo (MT) sistemos rezultatams ištaisyti, mokant iš žmogaus po redakcijos modelių. We present the system used in our submission to the WMT'21 Automatic Post-Editing (APE) English-German (En-De) shared task.  Šiai uždavinei naudojame naujausią MT sistemą (Ng et al., 2019 m.). Siekiant tolesnių patobulinimų, MT model į pritaikome prie užduočių srities, naudojant WikiMatrix (Schwenket al., 2021), po to tiksliname papildomais APE pavyzdžiais iš ankstesnių bendros užduoties (WMT-16,17,18) leidinių ir sukuriant modelius. Mūsų sistemos viršijo pradinę reikšmę pagal TER rezultatus pagal WMT'21 bandymų rinkinį.", 'kk': "Автоматты кейін өңдеу (APE) үлгілері машинаны аудару (MT) жүйесінің шығысын адамды өңдеу үлгілерінен оқу үшін қолданылады. Біз WMT' 21 автоматты түрде өңдеу (APE) ағылшын- неміс (En- De) ортақтастырылған тапсырмаға қолданылатын жүйені таңдаймыз. Біз бұл тапсырма үшін MT жүйесінің күйі (Ng et al., 2019). Қосымша жақсартулар үшін біз MT үлгісін тапсырма доменіне WikiMatrix (Schwenket al., 2021) қолданып, өткен тапсырманың алдыңғы өзгертілген тапсырманың (WMT-16,17,18) өзгертілген APE үлгілерімен қосымша түзетулерін қолданып, үлгіле Жүйелеріміз WMT 21 сынақтағы TER нәтижелерінде негізгі жолды жетілді.", 'ms': "Model selepas-edit automatik (APE) digunakan untuk betulkan output sistem terjemahan mesin (MT) dengan belajar dari corak selepas-edit manusia. Kami memperkenalkan sistem yang digunakan dalam penghantaran kepada tugas kongsi WMT'21 Automatic Post-Editing (APE) English-German (En-De). Kami menggunakan sistem MT terbaik (Ng et al., 2019) untuk tugas ini. For further improvements, we adapt the MT model to the task domain by using WikiMatrix (Schwenket al., 2021) followed by fine-tuning with additional APE samples from previous editions of the shared task (WMT-16,17,18) and ensembling the models.  Sistem kita mengalahkan dasar pada skor TER pada set ujian WMT'21.", 'mk': "Automatic post-editing (APE) models are usedto correct machine translation (MT) system outputs by learning from human post-editing patterns.  Го претставуваме системот кој се користи за поднесување на заедничката задача на WMT'21 Automatic Post-Editing (APE) English-German (En-De). Ние го искористуваме најдобриот систем на МТ (Нг и ал., 2019) за оваа задача. For further improvements, we adapt the MT model to the task domain by using WikiMatrix (Schwenket al., 2021) followed by fine-tuning with additional APE samples from previous editions of the shared task (WMT-16,17,18) and ensembling the models.  Our systems beat the baseline on TER scores on the WMT'21 test set.", 'mt': "Automatic post-editing (APE) models are usedto correct machine translation (MT) system outputs by learning from human post-editing patterns.  Aħna nippreżentaw is-sistema użata fis-sottomissjoni tagħna lill-kompitu kondiviż tal-WMT'21 Automatic Post-Editing (APE) Ingliż-Ġermaniż (En-De). Nixprunaw is-sistema MT l-aktar avvanzata (Ng et al., 2019) għal dan il-kompitu. Għal aktar titjib, aħna nadattaw il-mudell MT għad-dominju tal-kompiti billi nużaw WikiMatrix (Schwenket al., 2021) segwit minn rfinar b’kampjuni APE addizzjonali minn edizzjonijiet preċedenti tal-kompitu kondiviż (WMT-16,17,18) u l-immuntar tal-mudelli. Is-sistemi tagħna qabżu l-linja bażi fuq il-punteġġi TER fis-sett tat-test WMT'21.", 'ml': "മനുഷ്യന്\u200d പിന്തുടരുന്ന രീതികളില്\u200d നിന്നും പഠിക്കുന്നതിനാല്\u200d സ്വയം ചിട്ടപ്പെടുത്തുന്ന (APE) മോഡലുകള്\u200d ശരിയായ മെഷീന്\u200d പരിഭാഷ WMT'21 സ്വയം പിന്നോട്ട് എഡിറ്റി (APE) പങ്കുചേര്\u200dത്ത ജെര്\u200dമ്മന്\u200d We leverage the state-of-the-art MT system (Ng et al., 2019) for this task.  കൂടുതല്\u200d മെച്ചപ്പെടുത്താന്\u200d, വികിമാട്രിക്സ് (ഷ്വെന്കെറ്റ് അല്\u200d, 2021) ഉപയോഗിച്ച് എംടി മോഡല്\u200d ജോലിയിലേക്ക് മാറ്റുന്നു. പിന്നീട് കൂടുതല്\u200d APE മാതൃകങ്ങള്\u200d മാതൃകങ്ങള്\u200d  നമ്മുടെ സിസ്റ്റം WMT'21 ടെസ്റ്റ് സെറ്റില്\u200d ടെയിര്\u200d സ്കോര്\u200dസില്\u200d അടിച്ചു.", 'mn': "Автоматтын дараагийн загвар (APE) загварууд нь хүн төрөлхтний дараагийн загвараас суралцаж машины хөрөнгө оруулах (MT) системийн үр дүнг зөв болгон ашигладаг. Бид WMT'21 Автоматик ПостEditing (APE) Англи-Германы (En-De) хуваалцааны ажил дээр хэрэглэгдсэн системийг тайлбарлаж байна. Бид энэ ажлын төлөө-урлагийн MT системийг (Ng et al., 2019) ашиглаж байна. Дараагийн сайжруулалтын тулд бид MT загварын загварыг WikiMatrix (Schwenket al., 2021) ашиглаж, өмнө нь хуваалцагдсан ажлын өмнөх загварын (WMT-16,17,18) нэмэлт APE үлгээнүүдийг сайжруулж, загваруудыг дамжуулж байна. Бидний систем WMT-ын 21 туршилтын TER оноо дээр суурь шугам шаардсан.", 'ka': "ავტომატური პოსტრედაქტირება (APE) მოდელები გამოყენებულია მაქსინური გაგრძელება (MT) სისტემის გადასწავლად ადამიანის პოსტრედაქტირების მონაცემებით. ჩვენ გამოიყენებთ სისტემა, რომელიც ჩვენი გადამუშაობაში გამოყენებული WMT'21 ავტომატური დარედაქტირება (APE) ინგლისური-გერმანური (En-De) დაყოფილი რამე. ჩვენ ამ დავალებისთვის MT სისტემა (Ng et al., 2019) სტატის სახელსაწყისთვის გამოყენებთ. დამატებით გაუკეთებელებისთვის, ჩვენ MT მოდელის მოდელის დავაკეთებთ დავაკეთებთ საქმე დემომინზე WikiMatrix (Schwenket al., 2021) გამოყენებით, შემდეგ დამატებით დამატებითი APE მოდელის წინა რედაქტირებით (WMT-16,17,18) და მოდელის შე ნაქთრვ ჟთჟრვმთ ოჲბვეთჳა ოჲჟლვენარა ლთნთწ ნა TER ოჲჟლვეგანთრვ ნა რვჟრ ნა WMT 21.", 'pl': "Automatyczne modele post-edycji (APE) są wykorzystywane do poprawnego wyjścia systemu tłumaczenia maszynowego (MT) poprzez uczenie się z ludzkich wzorców post-edycji. Przedstawiamy system wykorzystywany w naszej zgłoszeniu do wspólnego zadania WMT'21 Automatic Post-Editing (APE) angielsko-niemieckiego (En-De). Do tego zadania wykorzystujemy najnowocześniejszy system MT (Ng et al., 2019). W celu dalszych ulepszeń dostosowujemy model MT do domeny zadań za pomocą WikiMatrixa (Schwenket al., 2021), a następnie dopracowujemy o dodatkowe próbki APE z poprzednich edycji zadania wspólnego (WMT-16,17,18) oraz zestaw modeli. Nasze systemy pokonały wyniki TER w zestawie testów WMT'21.", 'no': "Automatiske postredigeringsmodeller (APE) blir brukt til å retta systemutdata av maskineomsetjing (MT) ved å læra frå menneske postredigeringsmønsterelement. Vi presenterer systemet som vert brukt i vårt tillegg til delt oppgåve i WMT'21 automatisk post- redigering (APE) i engelsk- tysk (En- De). Vi leverer tilstanden av kunstsystemet MT (Ng et al., 2019) for denne oppgåva. For meir forbetringar, tilpassar vi MT-modellen til oppgåvedomenet ved å bruka WikiMatrix (Schwenket al., 2021) etterfølgja av fin-tuning med fleire APE-prøver frå tidlegare redigeringar av delt oppgåve (WMT-16,17,18) og ensemblere modellen. Sistemet våre slår baseline på TER- poeng på WMT 21- testsettet.", 'sr': "Автоматични модели послередактирања (APE) се използвају за исправљање резултата система превода (MT) путем учења од људских потредачних модела редактирања. Predstavljamo sistem koji se koristi u našem podnošenju podijeljenom zadatku WMT'21 automatskom posledištu (APE) engleskog-nemačkog (En-De). Učinimo državni MT sistem (Ng et al., 2019) za ovaj zadatak. Za daljnje poboljšanje, prilagođavamo MT model na domenu zadataka koristeći WikiMatrix (Schwenket al., 2021), slijedeći finalnim prilagođavanjem sa dodatnim uzorcima APE-a iz prethodnih redakcija zajedničkog zadataka (WMT-16,17,18) i uključujući modele. Naši sistemi su pobijedili početnu liniju na rezultatima TER na testu WMT-21.", 'sv': "Automatiska efterredigeringsmodeller (APE) anvﾃ､nds fﾃｶr att korrigera maskinﾃｶversﾃ､ttningssystemets utgﾃ･ngar genom att lﾃ､ra sig frﾃ･n mﾃ､nskliga efterredigeringsmﾃｶnster. Vi presenterar det system som anvﾃ､nds i vﾃ･r inlﾃ､mning till WMT'21 Automatic Post-Editing (APE) engelsk-tyska (En-De) delade uppgiften. Vi utnyttjar det senaste MT-systemet (Ng et al., 2019) fﾃｶr denna uppgift. Fﾃｶr ytterligare fﾃｶrbﾃ､ttringar anpassar vi MT-modellen till aktivitetsdomﾃ､nen genom att anvﾃ､nda WikiMatrix (Schwenket al., 2021) fﾃｶljt av finjustering med ytterligare APE-prover frﾃ･n tidigare utgﾃ･vor av den delade aktiviteten (WMT-16,17,18) och sammansﾃ､ttning av modellerna. Vﾃ･ra system slog baslinjen pﾃ･ TER poﾃ､ng pﾃ･ WMT'21 testset.", 'so': "Automatic post-editing (APE) models are usedto correct machine translation (MT) system outputs by learning from human post-editing patterns.  Waxaynu soo bandhignaa nidaamka loo soo dhiibay WMT'21 Automatic Post-Editing (APE) shaqada loo qaybsaday Ingiriis-Jarmal (En-De). Shaqadan ayaannu u dhiibannaa xaaladda-sanadka MT (Ng et al., 2019). Horumarinta dheeraadka ah waxaa loo beddelaa samooyinka MT ee shaqada lagu isticmaalayo WikiMatrix (Schwenket al., 2021) waxaana ku soo bandhigaynaa samooyin kale oo APE ah oo ka horeeyey qoraalka shaqada la waday (WMT-16,17,18) waxaana sameynaynaa modellada. nidaamkayaga waxay ku jabsadeen kooxda TER-ka oo ku qoran qoraalka imtixaanka WMT-21.", 'si': "ස්වයංක්\u200dරියාත්මක පස්ස සංපාදනය (APE) මොඩේල් භාවිත කරනවා මිනිස්සු පස්සේ සංපාදනය කරන්න ප්\u200dරවේශනය (MT) පද්ධත අපි WMT' 21 ස්වයංක්\u200dරිය පොස්ටම් සම්පාදනය (APE) ඉංග්\u200dරීසි ජර්මන් (en- de) කාර්යයෙන් භාවිත කරන පද්ධතිය පෙන්වනවා. අපි මේ වැඩේ වෙනුවෙන් ස්ථානය MT පද්ධතිය (Ng et al., 2019). විකිමාට්\u200dරික්ස් (Schwenket al., 2021) භාවිත කරන්න සඳහා MT මොඩේල් එක අනුමාණය කරනවා, අපි විකිමාට්\u200dරික්ස් වලින් විකිමාට්\u200dරික්ස් වලින් ප්\u200dරයෝජනය කරන්න සඳහා ප්\u200dරයෝජන අපේ පද්ධතිය පරීක්ෂණාව WMT 21 පරීක්ෂණාව සම්බන්ධයේ TER පරීක්ෂණාවට පත්තු කරනවා.", 'ur': "اٹوٹوٹ پیسٹ ویڈینگ (APE) نمڈلوں کو ماشین ترجمہ (MT) سیسٹم آئٹپوٹ کے لئے استعمال کیا جاتا ہے۔ ہم اس سیسٹم کو WMT'21 اٹوٹوٹی پوسٹ ایڈیٹینگ (APE) انگلیسی-جرمن (En-De) شریک کام میں استعمال کیا جاتا ہے۔ ہم اس کام کے لئے ایٹ ایٹ سیسٹم (Ng et al., 2019) کا موقع استعمال کرتے ہیں۔ اور اضافہ تغییرات کے لئے، ہم ویکیماتریکس (Schwenket al., 2021) کے مطابق MT موڈل کو ٹاکس ڈومین کے ساتھ اضافہ کرنے کے لئے اضافہ APE نمونے کے مطابق (WMT-16,17,18) اور نمونے کے مطابق اضافہ مطابق مطابق مطابق کریں گے۔ ہماری سیستموں نے WMT's 21 تست سٹ پر TER اسکوروں پر بنیس لین کو دھنسا دیا۔", 'ro': "Modelele automate de post-editare (APE) sunt utilizate pentru a corecta ieșirile sistemului de traducere automată (MT) prin învățarea din modelele umane de post-editare. Vă prezentăm sistemul utilizat în trimiterea noastră la sarcina partajată WMT'21 Automatic Post-Editing (APE) engleză-germană (En-De). Folosim sistemul MT de ultimă generație (Ng et al., 2019) pentru această sarcină. Pentru îmbunătățiri suplimentare, adaptăm modelul MT la domeniul activităților folosind WikiMatrix (Schwenket al., 2021), urmat de reglarea fină cu mostre APE suplimentare din edițiile anterioare ale activității partajate (WMT-16,17,18) și ansamblarea modelelor. Sistemele noastre au depăşit scorurile TER din setul de teste WMT'21.", 'ta': "தானியங்கி தொகுப்பின் மாதிரி WMT'21 தானியங்கி பின்தொகுப்பு (APE) ஆங்கிலம்- ஜெர்மன் பகிர்ந்த பணிக்கு பயன்படுத்தப்பட்ட அமைப்பை காண்பிக்கிறோம். நாங்கள் இந்த பணிக்கான MT அமைப்பின் நிலையில் சேர்க்கிறோம் (Ng et al., 2019). மேலும் முன்னேற்றங்களுக்கு, நாம் விகிமாட்ரிக்ஸ் (Schwenket al., 2021) பயன்படுத்தி MT மாதிரியை செயல் களத்திற்கு ஒதுக்கிடுகிறோம். பின்னர் கூடுதல் APE மாதிரிகளை முந்தைய பகிர்ந WMT '21 சோதனை அமைப்பில் TER மதிப்பெண்களின் அடிப்படை கோட்டை வெற்றி விட்டது.", 'uz': "Name Biz WMT'21 avtomatik keyingi tahrirchi (APE) ingliz- Olmoncha (En-De) ishga tayyorlangan vazifani ishga tushirishga ishlatiladigan tizimni hosil qilamiz. Biz shu vazifa uchun MT tizimi (Ng et al., 2019) holatini bajaramiz. Koʻproq taʼminlovlovchilar uchun, biz WikiMatrix (Schwenket al., 2021) ishlab chiqarish uchun MT modelini ishlab chiqaramiz, keyin bizning oldingi birinchi tashkilotlar bilan qoʻshimcha APE misollarini (WMT-16,17,18) bilan boshqarish modellarini birlashtiramiz. Bizning tizimimiz WMT 21 sinov sohasida TER scorlarining asosiy satrini bajaradi.", 'vi': "Tự động kết nối (APE) các mô hình được sử dụng để kết xuất hệ thống dịch chính xác (MTV) bằng cách học từ các mẫu sau-sửa chữa con người. Chúng tôi giới thiệu hệ thống được sử dụng trong việc cung cấp cho WRT'21 Chính-Editing (APE) English-Đức (En-De) bị chia sẻ. Chúng ta sử dụng hệ thống kênh MTV hiện đại (Ngo et al., 209) cho nhiệm vụ này. Để cải tiến thêm, chúng tôi thích mô hình MTV với miền nhiệm vụ bằng cách dùng WikiLMa (Schwernet al., 2021) theo đó là độ cẩn thận với các mẫu APA khác từ các phiên bản trước của công việc chung (WRT-16,17,18) và kết hợp các mô hình. Hệ thống của chúng ta đã vượt qua điểm số con T trên bộ thử nghiệm WRT'21.", 'bg': "Моделите за автоматична пост-редактиране (АПЕ) се използват за коригиране на изходите на системата за машинен превод (МТ), като се учат от човешките модели за пост-редактиране. Представяме системата, използвана при подаването ни на споделената задача англо-немски език за автоматична пост-редакция. Ние използваме най-съвременната система за МТ (Нг и др., 2019 г.) за тази задача. За по-нататъшни подобрения адаптираме модела МТ към домейна на задачите, като използваме УикиМатрикс (Швенкет ал., 2021), последвано от фина настройка с допълнителни мостри от предишни издания на споделената задача (WMT-16,17,18) и ансамблиране на моделите. Нашите системи надминаха базовите резултати на тестовете WMT'21.", 'da': "Automatiske efterredigeringsmodeller (APE) bruges til at korrigere maskinoversættelsessystemets output ved at lære af menneskelige efterredigeringsmønstre. Vi præsenterer det system, der anvendes i vores indsendelse til WMT'21 Automatic Post-Editing (APE) engelsk-tysk (En-De) delte opgave. Vi udnytter det avancerede MT-system (Ng et al., 2019) til denne opgave. For yderligere forbedringer tilpasser vi MT-modellen til opgavdomænet ved hjælp af WikiMatrix (Schwenket al., 2021) efterfulgt af finjustering med yderligere APE-prøver fra tidligere udgaver af den delte opgave (WMT-16,17,18) og sammensætning af modellerne. Vores systemer slog baseline på TER score på WMT'21 testsættet.", 'nl': "Automatische post-editing (APE) modellen worden gebruikt om systeemoutputs van machinevertaling (MT) te corrigeren door te leren van menselijke post-editing patronen. We presenteren het systeem gebruikt in onze inzending aan de WMT'21 Automatic Post-Editing (APE) Engels-Duits (En-De) gedeelde taak. Hiervoor maken we gebruik van het state-of-the-art MT-systeem (Ng et al., 2019). Voor verdere verbeteringen passen we het MT-model aan het taakdomein aan door gebruik te maken van WikiMatrix (Schwenket al., 2021) gevolgd door fine-tuning met extra APE-samples uit eerdere edities van de gedeelde taak (WMT-16,17,18) en het ensembleren van de modellen. Onze systemen overtroffen de baseline op TER scores op de WMT'21 testset.", 'hr': "Upotrebljeni su automatski modeli nakon redakcije (APE) za ispravne ishode sustava za prevod strojeva (MT) učeći se iz ljudskih obrazaca nakon redakcije. Predstavljamo sustav koji se koristi u našem podnošenju podijeljenom zadatku WMT'21 automatskom posledištu editiranja (APE) engleskog-njemačkog (En-De). Učinimo državni MT sustav (Ng et al., 2019) za ovaj zadatak. Za daljnje poboljšanje, prilagođavamo model MT-a na domenu zadatka koristeći WikiMatrix (Schwenket al., 2021), slijedeći finalnim prilagođavanjem s dodatnim uzorcima APE-a iz prethodnih redakcija zajedničkog zadatka (WMT-16,17,18) i uključujući modele. Naši sustavi su pobijedili početnu liniju na rezultatima TER-a na testu WMT-a 21.", 'de': "Automatische Nachbearbeitungsmodelle (APE) werden verwendet, um Systemausgaben der maschinellen Übersetzung (MT) zu korrigieren, indem aus menschlichen Nachbearbeitungsmustern gelernt wird. Wir stellen das System vor, das in unserer Einreichung zur WMT'21 Automatic Post-Editing (APE) Englisch-Deutsch (En-De) Shared Task verwendet wurde. Für diese Aufgabe nutzen wir das hochmoderne MT-System (Ng et al., 2019). Für weitere Verbesserungen passen wir das MT-Modell an die Aufgabengebiete an, indem wir WikiMatrix (Schwenket al., 2021) verwenden, gefolgt von Feinabstimmungen mit zusätzlichen APE-Samples aus früheren Editionen des Shared Tasks (WMT-16,17,18) und Ensembles der Modelle. Unsere Systeme übertrafen die Baseline bei TER-Scores im WMT'21 Testset.", 'id': "Model post-edit otomatis (APE) digunakan untuk mengkoreksi sistem terjemahan mesin (MT) dengan belajar dari pola post-edit manusia. Kami mempersembahkan sistem yang digunakan dalam pengiriman kami ke WMT'21 Automatic Post-Editing (APE) Bahasa Inggris-Jerman (En-De) tugas berbagi. Kami menggunakan sistem MT terbaik (Ng et al., 2019) untuk tugas ini. Untuk memperbaiki lebih lanjut, kami menyesuaikan model MT ke domain tugas dengan menggunakan WikiMatrix (Schwenket al., 2021) diikuti dengan fine-tuning dengan sampel APE tambahan dari edisi sebelumnya tugas berbagi (WMT-16,17,18) dan mengumpulkan model. Sistem kita mengalahkan dasar pada skor TER pada set tes WMT'21.", 'fa': "مدلهای بعد از ویرایش (APE) خودکار برای ترجمه\u200cهای سیستم ماشین (MT) درست با یادگیری از الگوهای بعد از ویرایش انسان استفاده می\u200cشوند. ما سیستم استفاده در تسلیم کردن به کار مشترک انگلیسی-آلمانی (En-De) WMT'21 را پیشنهاد می\u200cکنیم. ما سیستم MT (Ng et al., 2019) را برای این کار تأثیر می\u200cدهیم. برای پیشرفتهای بیشتری، ما مدل MT را با استفاده از ویکیماتریکس (Schwenket al., 2021) با نمونه های اضافه APE از ویکیماتریکس قبلی از ویکیماتریکس (WMT-16,17,18) و مدل\u200cها را تغییر می\u200cدهیم. سیستم\u200cهایمان پایین\u200cخط\u200cهای TER را در مجموعه\u200cی امتحان WMT ۲۱ شکست دادند.", 'tr': "Otomatik taýdan editlemek (APE) nusgalary biljek sistemiň çykyşlaryny adalatmak üçin ullanýar. WMT'iň 21 Otomatik Po-Editlemesi (APE) Iňlisçe-Almança (En-De) işine ulanylýan sistemimizi gönderýäris. Biz bu işe üçin stat-of-the-art MT sistemini (Ng et al., 2019). Daha fazla gelişmeler üçin, WikiMatrix (Schwenket al., 2021) kullanarak MT modelini görev domenya uygulayıp, bu şekilde öňki paylaşyk görevinin (WMT-16,17,18) örneklerinden soňra fin-tuning örnekleri bilen düzeltildi. Bizim sistemlerimiz WMT 21 testi düzeninde TER kanallarynda üýtgedi.", 'sw': "Mradi wa kuhariri baada ya kujitegemea (APE) hutumiwa kutafsiri mashine sahihi (MT) kwa kujifunza kutoka miundo mbinu ya kuhariri baada ya binadamu. We present the system used in our submission to the WMT'21 Automatic Post-Editing (APE) English-German (En-De) shared task.  Tunaitumia mfumo wa sanaa wa MT (Ng et al., 2019) kwa kazi hii. Kwa maendeleo mengine zaidi, tunabadilisha mtindo wa MT kwenye eneo la kazi kwa kutumia WikiMatrix (Schwenket al., 2021) kufuatia sampuli kadhaa ya APE kutoka kwenye toleo la zamani la kazi hiyo (WMT-16,17,18) na kuingiza mifano. Mifumo yetu ilipiga msingi kwenye vituo vya TER kwenye seti ya mtihani wa WMT 21.", 'sq': "Modelet e posteditimit automatik (APE) përdoren për të korrektuar rezultatet e sistemit të përkthimit automatik (MT) duke mësuar nga modelet e posteditimit njerëzor. Ne prezantojmë sistemin e përdorur në dorëzimin tonë në detyrën e përbashkët të WMT'21 Automatic Post-Editing (APE) English-German (En-De). Ne përdorim sistemin më të lartë MT (Ng et al., 2019) për këtë detyrë. For further improvements, we adapt the MT model to the task domain by using WikiMatrix (Schwenket al., 2021) followed by fine-tuning with additional APE samples from previous editions of the shared task (WMT-16,17,18) and ensembling the models.  Sistemet tona mundën bazën e rezultateve të TER në grupin e testit WMT'21.", 'af': "Outomatiese post- redigeering (APE) modele word gebruik om masjien vertaling (MT) stelsel uitvoer te korrigeer deur te leer van menslike post- redigeering patrone. Ons vertoon die stelsel wat gebruik word in ons onderwerp aan die WMT' 21 Outomatiese Post- Redigering (APE) Engels- Duits (En- De) gedeelde taak. Ons verwyder die state-of-the-art MT stelsel (Ng et al., 2019) vir hierdie taak. Vir verdere verbeteringe, adapteer ons die MT-model na die taak domein deur die gebruik van WikiMatrix (Schwenket al., 2021) gevolg deur fyn-tuning met addisionele APE-voorbeelde van vorige redigeerings van die gedeelde taak (WMT-16,17,18) en die modelles ensembleer. Ons stelsels het die basislien op TER-telling op die WMT's 21 toets stel geslaan.", 'ko': "자동 사후 편집(APE) 모델은 인간 사후 편집 모드를 학습하여 기계 번역(MT) 시스템의 출력을 수정하는 데 사용된다.WMT'21 자동 사후 편집(APE) 영어-독일어(En-De) 공유 작업에 사용할 시스템을 소개합니다.우리는 최첨단 기계번역시스템(Ng 등, 2019년)을 이용해 이 임무를 완수했다.개선을 위해 WikiMatrix(Schwenket al., 2021)를 사용하여 기계 번역 모델을 작업 영역으로 조정한 다음 공유 작업(WMT-16,17,18) 이전 버전의 다른 APE 견본을 사용하여 미세하게 조정하고 모델을 통합합니다.우리 시스템은 WMT'21 테스트 세트의 TER 점수에서 기준선을 초과했다.", 'hy': 'Օգտագործվում են ավտոմատիկ հետխմբագրման (APE) մոդելները, որոնք օգտագործվում են մեքենային թարգմանման (MT) համակարգի արտադրությունների ճշգրիտելու համար՝ սովորելով մարդկային հետխմբագրման մոդելներից: Մենք ներկայացնում ենք համակարգը, որը օգտագործվում է մեր ներկայացման մեջ, աշխարհի Ավտոմատիկ Պետ-խմբագրման (APE) 21-ի անգլերեն-գերմաներեն (en-de) ընդհանուր խնդիրը: Մենք օգտագործում ենք ամենաբարձր MT համակարգը (Ng et al., 2019) այս խնդրի համար: Ավելի բարելավման համար մենք հարմարեցնում ենք MT մոդելը խնդրի տիեզերքին օգտագործելով WiKiMatrex (Schweincket al., 2021), հետո կատարելով ավելին APE-ի նմուշներ, որոնք հանձնարած խնդրի նախորդ հրատարակություններում էին (World MT-16,17,18) և համադրելով մոդելները: Մեր համակարգերը հաղթահարեցին աշխարհային տեխնոլոգիական տեխնոլոգիայի 21-ի փորձարկումների արդյունքները:', 'bn': "স্বয়ংক্রিয়ভাবে পোস্ট সম্পাদন (APE) মডেল সঠিক মেশিন অনুবাদ (MT) সিস্টেম আউটপুট ব্যবহার করা হয়ে আমরা সিস্টেম ব্যবহার করি WMT'21 স্বয়ংক্রিয়ভাবে পোস্ট-সম্পাদক (এপিই) ইংরেজী জার্মান (এন-ডি) শেয়ার কর্মসূচীতে আমাদের প আমরা এই কাজের জন্য রাষ্ট্রীয়-শিল্পী এমটি সিস্টেম (এনজি এ আল, ২০১৯)। For further improvements, we adapt the MT model to the task domain by using WikiMatrix (Schwenket al., 2021) followed by fine-tuning with additional APE samples from previous editions of the shared task (WMT-16,17,18) and ensembling the models.  আমাদের সিস্টেম WMT'21 পরীক্ষা সেটে টের স্কোরের বেস্ট লাইন হারিয়েছে।", 'bs': "Upotrebljeni su automatski modeli posledišnjeg redakcije (APE) za ispravne ishode sistema prevoda (MT) učeći se iz ljudskih obrazaca nakon redakcije. Predstavljamo sistem koji se koristi u našem podnošenju podijeljenom zadatku WMT'21 automatskom posledištu (APE) engleskog-nemačkog (En-De). Učinimo državni MT sistem (Ng et al., 2019) za ovaj zadatak. Za daljnje poboljšanje, prilagođavamo model MT na domenu zadataka koristeći WikiMatrix (Schwenket al., 2021), slijedeći finalnim prilagođavanjem s dodatnim uzorcima APE-a iz prethodnih redakcija zajedničkog zadataka (WMT-16,17,18) i uključujući modele. Naši sustavi su pobijedili početnu liniju na rezultatima TER-a na testu WMT-a 21.", 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s የWMT'21 አውቶማቲካዊ ፖስታ-አስተካክል (APE) የእንግሊዝኛ-ጀርመን (En-De) የተካፈለውን ስርዓት በመስጠት የተጠቀመውን ስርዓት እናቀርባታለን፡፡ ለዚህ ስራ የ-የ-የ-የ-art MT ስርዓት (Ng et al., 2019) እናስገድዳለን፡፡ ለሌላ ክፍተቶችን ለመጠቀም፣ WikiMatrix (Schwenket al., 2021) በተጨማሪው APE ምሳሌዎች ከቀድሞው ስራ ክፍተት (WMT-16,17,18) እና ምሳሌዎቹን በመጠቀም እናስቀሳቅሳለን፡፡ ሲስተምሮቻችን የቴር ነጥቦችን በWMT-21 ፈተና ሰዓት ላይ መደበቂያውን መታ።", 'az': "Avtomatik post-editing (APE) modelləri insan post-editing modellərdən öyrənib maşın çevirilməsi (MT) sistemin çıxışlarını düzəltmək üçün istifadə edilir. Biz WMT'21 Avtomatik Post-Editing (APE) İngiliz-Almanca (En-De) işin ə istifadə edilən sistemi göstəririk. Biz bu işə görə MT sistemi (Ng et al., 2019). Daha çox yaxşılaşdırmaq üçün MT modelini, WikiMatrix (Schwenket al., 2021) ilə istifadə edərək, daha öncə paylaşılan işlərin (WMT-16,17,18) düzəltdiklərindən və modellərin əvvəlki düzəltdiklərindən daha çox APE nümunələri ilə düzəltmək üçün uyğunlaşdırırıq. Sistemlərimiz WMT 21 sınama qutusunda TER dəyişikliklərində tədbir səhifəsini yendi.", 'ca': "Els models automàtics de postedició (APE) s'utilitzen per corregir els resultats del sistema de traducció màquina (MT) aprenent amb patrons humans de postedició. Presentam el sistema utilitzat en la subministració a la tasca compartida WMT'21 Automatic Post-Editing (APE) anglès-alemany. Utilitzem el sistema MT més avançat (Ng et al., 2019) per aquesta tasca. Per millorar més, adaptem el model MT al domini de tasca utilitzant WikiMatrix (Schwenket al., 2021) seguit d'ajustar amb mostres adicionals d'APE d'edicions anteriors de la tasca compartida (WMT-16,17,18) i agrupant els models. Els nostres sistemes van superar la base de puntuacions TER en el conjunt d'exàmens WMT'21.", 'cs': "Automatické posteditační modely (APE) se používají k správným výstupům systému strojového překladu (MT) učením se z lidských posteditačních vzorů. Představujeme systém použitý při předkládání společného úkolu WMT'21 Automatic Post-Editing (APE) anglicky-německy (En-De). Pro tento úkol využíváme nejmodernější MT systém (Ng et al., 2019). Pro další vylepšení přizpůsobujeme MT model doméně úloh pomocí WikiMatrixu (Schwenket al., 2021) následně jemně ladíme s dalšími APE vzorky z předchozích edicí sdíleného úlohu (WMT-16,17,18) a sestavením modelů. Naše systémy porazily základní výsledky TER na testovací sadě WMT'21.", 'fi': "Automaattisia jälkimuokkausmalleja (APE) käytetään konekäännösjärjestelmän tuotosten korjaamiseen oppimalla ihmisten jälkimuokkauskuvioista. Esittelemme järjestelmän, jota käytettiin lähetettäessä WMT'21 Automatic Post-Editing (APE) Englanti-Saksa (En-De) -jaettuun tehtävään. Hyödynnämme tähän tehtävään uusinta MT-järjestelmää (Ng et al., 2019). Lisäparannuksia varten sovitamme MT-mallin tehtäväalueeseen käyttämällä WikiMatrixia (Schwenket al., 2021), jonka jälkeen hienosäädämme APE-näytteitä aikaisemmista jaetun tehtävän versioista (WMT-16,17,18) ja kokoamme mallit. Järjestelmämme päihittivät TER-pisteet WMT'21 -testisarjassa.", 'et': "Automaatset järeltöötlusmudelit kasutatakse masintõlke (MT) süsteemi väljundite korrigeerimiseks, õppides inimese järeltöötlusmudelitest. Esitleme süsteemi, mida kasutasime WMT'21 automaatse järeltöötluse (APE) inglise-saksa (En-De) jagatud ülesande esitamisel. Selle ülesande täitmiseks kasutame kaasaegset MT süsteemi (Ng et al., 2019). Täiendavateks täiustusteks kohandame MT mudeli ülesandedomeenile WikiMatrixi (Schwenket al., 2021) abil, millele järgneb täpne häälestamine täiendavate APE näidistega eelmistest jagatud ülesande väljaannetest (WMT-16,17,18) ja mudelite komplekteerimine. Meie süsteemid jõudsid WMT'21 testikomplekti TER tulemuste tasemele.", 'sk': "Modeli samodejnega post-editiranja (APE) se uporabljajo za popravljanje izhodov sistema strojnega prevajanja (MT), tako da se učijo iz človeških post-editiranih vzorcev. Predstavljamo sistem, ki ga uporabljamo pri oddaji v skupno opravilo WMT'21 Automatic Post-Editing (APE) angleško-nemško (En-De). Za to nalogo uporabljamo najsodobnejši sistem MT (Ng et al., 2019). Za nadaljnje izboljšave smo model MT prilagodili domeni opravil z uporabo WikiMatrix (Schwenket al., 2021), ki mu sledi natančno nastavitev z dodatnimi vzorci APE iz prejšnjih izdaj skupnega opravila (WMT-16,17,18) in kompletiranje modelov. Naši sistemi so premagali izhodišče na TER rezultatih na WMT'21 testu.", 'he': "דוגמנים אוטומטיים לאחר העורה (APE) משתמשים כדי לתקן תוצאות מערכת התרגום המכונית (MT) על ידי לימוד מדפוסים אחרי העורה אנושיים. אנחנו מציגים את המערכת השתמשת בהעברה שלנו למשימה המשותפת של WMT'21 לאחר העורר אוטומטי (APE) אנגלי-גרמני (En-De). אנו מנצלים את מערכת MT המאוחרת ביותר (Ng et al., 2019) עבור המשימה הזאת. עבור שיפורים נוספים, אנו מתאימים את דוגמנית MT לתחום המשימה באמצעות WikiMatrix (Schwenket al., 2021) ואחר כך מתאים עם דגימות APE נוספות מההוצאות הקודמות של המשימה המשותפת (WMT-16,17,18) ולאסוף את הדוגמנים. המערכות שלנו ניצחו את הבסיס על נקודות TER בסט מבחן WMT'21.", 'ha': "@ action: button Tuna halatar da tsarin da aka amfani da shi zuwa aikin WMT'21 Munã cika halin-the-art MT (Ng et al., 2019) wa wannan aikin. Ko dõmin ƙari, za'a adadi misalin MT zuwa filin aiki da za'a yi amfani da WikiMatrix (Schkenket al., 2021) a ƙara da mai kyau-tun da misãlai ɗin applet daga zaman editorin da aka raba shi (WMT-1617,18) kuma ana sami misãlai. Our systems beat the baseline on TER scores on the WMT'21 test set.", 'bo': "Automatic post-editing (APE) models are used to correct machine translation (MT) system outputs by learning from human post-editing patterns. ང་ཚོས་WMT'd21རང་འགུལ་གྱི་རྗེས་སྒྲིག་འགོད་པ་ལ་རང་འགུལ་གྱིས་བཏོན་པའི་མ་ལག་ཅིག་སྟོན་པ། ང་ཚོས་བཀོལ་སྤྱོད་འདི་ལ་གནས་སྡོད་དང་ལྟ་བུའི་དོན་ཕྱོགས་ཀྱི་ཐབས་ལམ་སྒོ་ཕྱེ་བ་རེད། For further improvements, we adapt the MT model to the task domain by using WikiMatrix (Schwenket al., 2021) followed by fine-tuning with additional APE samples from previous editions of the shared task (WMT-16,17,18) and ensembling the models. Our systems beat the baseline on TER scores on the WMT's 21 test set.", 'jv': "@item:checkbox Awak dhéwé nggawe sistem sing nyimpen kanggo nggambar nggo yen nggo yen-nggambar barang nggambar barang-inggili (en-de) ké WêT'11 Awake dhéwé nggawe sistem state-of-the-arts MT (Ng et al, 2011) kanggo nggawe iki dadi. For additional advancements, we align the MT Sistem-sistem dhéwé kuwi nggawe barang kelas telu sing ditambah sabané terus ing batal sing 'test' ning pekenaké WT'22."}
{'en': 'HW-TSC’s Participation in the WMT 2021 Triangular MT Shared Task', 'ar': 'مشاركة HW-TSC في مهمة WMT 2021 Triangular MT المشتركة', 'pt': 'Participação da HW-TSC na Tarefa Compartilhada Triangular MT do WMT 2021', 'es': 'Participación de HW-TSC en la tarea compartida de MT triangular WMT 2021', 'ja': 'WMT 2021三角形MT共有タスクへのHW - TSCの参加', 'hi': 'WMT 2021 त्रिकोणीय MT साझा कार्य में HW-TSC की भागीदारी', 'zh': 'HW-TSCäøˇWMT 2021äø‰č§’MTå…±å…¶äŗ‹', 'ru': 'Участие HW-TSC в Трехсторонней совместной задаче MT WMT 2021', 'ga': 'Rannpháirtíocht HW-TSC i dTasc Comhroinnte MT Triantánach WMT 2021', 'fr': 'Participation de HW-TSC à la tâche partagée de MT triangulaire WMT 2021', 'ka': 'HW-TSC-ის დაწყვეტილება WMT 2021 სამკუთხელური MT გაყოფილი პარამეტრებში', 'hu': 'A HW-TSC részvétele a WMT 2021 háromszög alakú MT megosztott feladatában', 'el': 'Συμμετοχή στην Τριγωνική Κοινή Εργασία ΜΤ 2021', 'it': 'La partecipazione di HW-TSC al compito condiviso triangolare MT WMT 2021', 'kk': 'HW- TSC WMT 2021 үшбұрышты MT ортақтастырылған тапсырманың қатысуы', 'mk': 'Учеството на ХВ-ТС во Триаголната задача на МТ 2021', 'lt': 'HW-TSC dalyvavimas 2021 m. WMT trikampėje MT bendroje užduotyje', 'ms': "HW-TSC's Participation in the WMT 2021 Triangular MT Shared Task", 'mt': 'Il-Parteċipazzjoni tal-HW-TSC fil-Ħidma Kondiviża Triangolari tal-MT tad-WMT 2021', 'ml': 'WMT 2021 ട്രിangular MT പങ്കുചേര്\u200dത്ത ടിഎസ്സിയുടെ പങ്കാളി', 'mn': 'HW-TSC-ын WMT 2021-н гурвалжин MT хуваалтын ажил', 'no': 'HW- TSC- deltakaren i WMT 2021 delt trekantar MT- delt oppgåve', 'pl': 'Udział HW-TSC w WMT 2021 Trójkątne MT Shared Task', 'ro': 'Participarea HW-TSC la sarcina partajată triunghiulară MT WMT 2021', 'sr': 'Učestvo HW-TSC-a u delu WMT 2021-a', 'si': "HW-TSC's partition in the WMT 2021 Triangul MT shared Job", 'so': 'WMT 2021 Triangular MT Shared Task', 'sv': 'HW-TSC:s deltagande i WMT 2021 triangular MT Shared Task', 'ta': 'WMT 2021 முக்கோணம் MT பகிர்ந்த பணியில் HW- TSC கூட்டுதல்', 'ur': "HW-TSC's Participation in the WMT 2021 Triangular MT Shared Task", 'uz': 'Name', 'vi': 'HW-TSC tham gia vào công việc chia s ẻ WM 2021', 'bg': 'Участието на ВТС в триъгълната МТ 2021 споделена задача', 'nl': 'Deelname van HW-TSC aan de WMT 2021 Driehoekige MT Shared Task', 'da': "HW-TSC's deltagelse i WMT 2021 Trekant MT delt opgave", 'hr': 'Učestvo HW-TSC-a u WMT 2021 Triangular MT Shared Task', 'de': 'Teilnahme des HW-TSC an der WMT 2021 Triangular MT Shared Task', 'ko': 'WMT 2021 삼각 MT 공유 작업에 HW-TSC 참여', 'fa': 'شرکت HW-TSC در کار مشترک MT سه گوشه\u200cای WMT 2021', 'id': "HW-TSC's Participation in the WMT 2021 Triangular MT Shared Task", 'sw': 'Ushiriki wa HW-TSC katika Tamko la WMT 2021', 'tr': "HW-TSC'nin WMT 2021 Üçgeniş MT Paylaşım Görevi", 'af': 'HW- TSC se Deelnadering in die WMT 2021 Triangular MT Gedeelde Taak', 'sq': "HW-TSC's Participation in the WMT 2021 Triangular MT Shared Task", 'az': "HW-TSC'nin WMT 2021 Ücücü MT paylaşılmış işləri", 'bn': 'WMT ২০২১ ট্রিভাঙ্গার এমটি শেয়ার কর্মসূচিতে এইচউ-টিএসসির অংশগ্রহণ', 'am': 'WMT 2021 Triangular MT Shared Task', 'hy': 'ՀՈւ-ՏՍԿ-ի մասնակցությունը 2021 թվականի ԱՄԹ-ի եռանկյունային ՄԹ-ի ընդհանուր խնդրում', 'bs': 'Učestvo HW-TSC-a u WMT 2021 Triangular MT Shared Task', 'ca': "La participació de l'HW-TSC a la tasca compartida de MT triangular WMT 2021", 'cs': 'Účast HW-TSC na WMT 2021 Trojúhelníkové MT Shared Task', 'fi': 'HW-TSC:n osallistuminen WMT 2021 Triangular MT Shared Task -ohjelmaan', 'et': 'HW-TSC osalemine WMT 2021 kolmnurkses MT jagatud ülesandes', 'jv': "HWT-Bsc's partition in the WT 2020 1 Trianguular MT shared task", 'he': 'השתתפות של HW-TSC במשימה משולשת של WMT 2021', 'ha': '@ action', 'sk': 'Sodelovanje HW-TSC v skupni nalogi WMT 2021 Trikotni MT', 'bo': "HW-TSC's Participation in the WMT 2021 Triangular MT Shared Task"}
{'en': 'This paper presents the submission of Huawei Translation Service Center (HW-TSC) to WMT 2021 Triangular MT Shared Task. We participate in the Russian-to-Chinese task under the constrained condition. We use Transformer architecture and obtain the best performance via a variant with larger parameter sizes. We perform detailed data pre-processing and filtering on the provided large-scale bilingual data. Several strategies are used to train our models, such as Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, etc. Our ', 'ar': 'تقدم هذه الورقة تقديم مركز خدمة الترجمة من Huawei (HW-TSC) إلى مهمة WMT 2021 Triangular MT المشتركة. نشارك في المهمة الروسية إلى الصينية في ظل ظروف مقيدة. نحن نستخدم بنية المحولات ونحصل على أفضل أداء عبر متغير بأحجام معلمات أكبر. نقوم بإجراء معالجة مسبقة للبيانات وتصفية البيانات التفصيلية على البيانات ثنائية اللغة واسعة النطاق المقدمة. يتم استخدام العديد من الاستراتيجيات لتدريب نماذجنا ، مثل الترجمة متعددة اللغات ، والترجمة العكسية ، والترجمة إلى الأمام ، وتقليل الضوضاء ، ومتوسط نقطة التفتيش ، والمجموعة ، والضبط الدقيق ، وما إلى ذلك ، يحصل نظامنا على 32.5 BLEU على مجموعة التطوير و 27.7 BLEU في مجموعة الاختبار ، أعلى درجة بين جميع عمليات الإرسال.', 'fr': "Cet article présente la soumission du centre de services de traduction Huawei (HW-TSC) à la tâche partagée de traduction triangulaire WMT 2021. Nous participons à la tâche russo-chinoise dans des conditions restreintes. Nous utilisons l'architecture Transformer et obtenons les meilleures performances via une variante avec des tailles de paramètres plus grandes. Nous effectuons un prétraitement et un filtrage détaillés des données bilingues à grande échelle fournies. Plusieurs stratégies sont utilisées pour entraîner nos modèles, telles que la traduction multilingue, la traduction arrière, la traduction avant, le débruitage des données, le point de contrôle moyen, l'ensemble, le réglage fin, etc. Notre système obtient 32,5 BLEU sur le jeu de développement et 27,7 BLEU sur le jeu de test, le score le plus élevé parmi toutes les soumissions.", 'pt': 'Este artigo apresenta o envio do Huawei Translation Service Center (HW-TSC) para WMT 2021 Triangular MT Shared Task. Participamos da tarefa russo-chinês sob a condição restrita. Usamos a arquitetura Transformer e obtemos o melhor desempenho por meio de uma variante com tamanhos de parâmetros maiores. Realizamos pré-processamento e filtragem de dados detalhados nos dados bilíngues de grande escala fornecidos. Diversas estratégias são usadas para treinar nossos modelos, como Tradução Multilíngue, Tradução Reversa, Tradução Avançada, Denoising de Dados, Checkpoint Médio, Ensemble, Ajuste Fino, etc. Nosso sistema obtém 32,5 BLEU no conjunto dev e 27,7 BLEU no conjunto de teste , a maior pontuação entre todas as submissões.', 'es': 'Este documento presenta la presentación del Centro de servicios de traducción de Huawei (HW-TSC) a la tarea compartida Triangular MT de WMT 2021. Participamos en la tarea de ruso a chino bajo la condición restringida. Utilizamos la arquitectura Transformer y obtenemos el mejor rendimiento a través de una variante con tamaños de parámetros más grandes. Realizamos un procesamiento previo y filtrado de datos detallados en los datos bilingües a gran escala proporcionados. Se utilizan varias estrategias para entrenar nuestros modelos, como traducción multilingüe, traducción inversa, traducción directa, eliminación de ruido de datos, punto de control promedio, conjunto, ajuste fino, etc. Nuestro sistema obtiene 32,5 BLEU en el conjunto de desarrollo y 27,7 BLEU en el conjunto de prueba, la puntuación más alta entre todos los envíos.', 'ja': '本稿では、WMT 2021 Triangular MT Shared TaskへのHuawei Translation Service Center (HW - TSC)の提出を紹介する。制約された条件下でロシアから中国への任務に参加します。当社では、変圧器アーキテクチャを使用し、より大きなパラメータサイズのバリアントを介して最高のパフォーマンスを実現しています。提供された大規模なバイリンガルデータに対して、詳細なデータの事前処理とフィルタリングを実行します。マルチリンガル翻訳、バック翻訳、フォワード翻訳、データのノイズ除去、平均チェックポイント、アンサンブル、微調整など、さまざまな戦略を使用してモデルをトレーニングしています。当社のシステムは、開発セットで32.5 BLEU、試験セットで27.7 BLEUを取得しており、すべての提出物の中で最高のスコアです。', 'zh': '本文引华为译服务中心(HW-TSC)向WMT 2021三角机器翻译共享其事。 吾于有限俄中事也。 吾用Transformer架构,因大参数尺寸之变体获得最佳。 臣等大双语详数预处理漉。 有数策以练吾形,如多言译,反向译,正向译,数噪,均检查点,集成,微调等。 吾统得 32.5 BLEU于开发集上,得 27.7 BLEU于测试集上,此诸交文之最高分也。', 'ru': 'В этой статье представлена информация о передаче Центра обслуживания переводов Huawei (HW-TSC) на решение совместной задачи WMT 2021 Triangular MT Shared Task. Мы участвуем в российско-китайской задаче в стесненных условиях. Мы используем архитектуру трансформатора и получаем лучшую производительность благодаря варианту с большими размерами параметров. Мы выполняем детальную предварительную обработку данных и фильтрацию предоставленных крупномасштабных двуязычных данных. Для обучения наших моделей используется несколько стратегий, таких как многоязычный перевод, обратный перевод, прямой перевод, подавление шума данных, средняя контрольная точка, ансамбль, тонкая настройка и т. д. Наша система получает 32,5 БЛЮ на наборе DEV и 27,7 БЛЮ на тестовом наборе, самый высокий балл среди всех представлений.', 'hi': 'यह पेपर डब्ल्यूएमटी 2021 त्रिकोणीय एमटी साझा कार्य के लिए हुआवेई अनुवाद सेवा केंद्र (एचडब्ल्यू-टीएससी) को प्रस्तुत करता है। हम विवश स्थिति के तहत रूसी-से-चीनी कार्य में भाग लेते हैं। हम ट्रांसफॉर्मर आर्किटेक्चर का उपयोग करते हैं और बड़े पैरामीटर आकार के साथ एक संस्करण के माध्यम से सबसे अच्छा प्रदर्शन प्राप्त करते हैं। हम प्रदान किए गए बड़े पैमाने पर द्विभाषी डेटा पर विस्तृत डेटा पूर्व-प्रसंस्करण और फ़िल्टरिंग करते हैं। हमारे मॉडल को प्रशिक्षित करने के लिए कई रणनीतियों का उपयोग किया जाता है, जैसे कि बहुभाषी अनुवाद, बैक ट्रांसलेशन, फॉरवर्ड ट्रांसलेशन, डेटा डीनोइज़िंग, एवरेज चेकपॉइंट, एनसेंबल, फाइन-ट्यूनिंग, आदि। हमारी प्रणाली देव सेट पर 32.5 BLEU और परीक्षण सेट पर 27.7 BLEU प्राप्त करता है, जो सभी प्रस्तुतियों के बीच उच्चतम स्कोर है।', 'ga': 'Cuirtear i láthair sa pháipéar seo aighneacht Ionad Seirbhíse Aistriúcháin Huawei (HW-TSC) chuig Tasc Comhroinnte MT Triantánach WMT 2021. Glacaimid páirt sa tasc Rúisis-go-Sínis faoin gcoinníoll srianta. Bainimid úsáid as ailtireacht Transformer agus a fháil ar an fheidhmíocht is fearr trí mhalairt le méideanna paraiméadar níos mó. Déanaimid réamhphróiseáil agus scagadh sonraí mionsonraithe ar na sonraí dátheangacha ar mhórscála a chuirtear ar fáil. Baintear úsáid as go leor straitéisí chun ár múnlaí a oiliúint, mar shampla Aistriúchán Ilteangach, Aistriú Siar, Aistriú Ar Aghaidh, Díscaoileadh Sonraí, Meán-seicphointe, Ensemble, mionchoigeartú, etc. Faigheann ár gcóras 32.5 BLEU ar an tacar dev agus 27.7 BLEU ar an tacar tástála , an scór is airde i measc na n-aighneachtaí go léir.', 'el': 'Η παρούσα εργασία παρουσιάζει την υποβολή του Κέντρου Μεταφραστικών Υπηρεσιών (ΤΠΣ) στην Τριγωνική Κοινή Εργασία ΜΤ. Συμμετέχουμε στο ρωσικό-κινεζικό έργο υπό τον περιορισμένο όρο. Χρησιμοποιούμε αρχιτεκτονική μετασχηματιστών και επιτυγχάνουμε την καλύτερη απόδοση μέσω μιας παραλλαγής με μεγαλύτερα μεγέθη παραμέτρων. Πραγματοποιούμε λεπτομερή προεπεξεργασία και φιλτράρισμα δεδομένων στα παρεχόμενα δίγλωσσα δεδομένα μεγάλης κλίμακας. Διάφορες στρατηγικές χρησιμοποιούνται για την εκπαίδευση των μοντέλων μας, όπως η Πολυγλωσσική Μετάφραση, η Πίσω Μετάφραση, η Μετάφραση προς τα εμπρός, η Απονομοποίηση δεδομένων, το Μέσο σημείο ελέγχου, το σύνολο, ο λεπτός συντονισμός, κ.λπ. Το σύστημά μας αποκτά 32.5 για το σύνολο ανάπτυξης και 27.7 για το σύνολο δοκιμών, την υψηλότερη βαθμολογία μεταξύ όλων των υποβαλλόμενων.', 'hu': 'Ez a tanulmány bemutatja a Huawei Fordítási Szolgáltató Központ (HW-TSC) benyújtását a WMT 2021 háromszög alakú MT Shared Task számára. Az orosz-kínai feladatban a korlátozott feltételek mellett veszünk részt. Transformer architektúrát használunk, és a legjobb teljesítményt egy nagyobb paraméterméretű változattal érjük el. A rendelkezésre álló nagyméretű kétnyelvű adatokon részletes adatfeldolgozást és szűrést végezünk. Több stratégiát használunk modelleink képzésére, mint például többnyelvű fordítás, visszafordítás, továbbfordítás, adatnevezés, átlagos ellenőrzőpont, együttes, finomhangolás stb. Rendszerünk 32,5 BLEU-t kap a fejlesztői készleten és 27,7 BLEU-t a tesztkészleten, a legmagasabb pontszámot az összes beadott között.', 'ka': 'ამ დოკუმენტი სამკუთხედვი MT საზოგადოებული დავალების სამუშაოდ WMT 2021- ში გადატანა. ჩვენ პროსია-კინესური საქმენოში დავწყებთ დავწყებული სტრუქტური სტრუქტურაში. ჩვენ გამოყენებთ ტრანფორმეტრის აქტიქტიქტურის და მივიღებთ საუკეთესო პარამეტრის ზომის გარეშე. ჩვენ მონაცემებული მონაცემები წინ გავაკეთებთ და ფილტრირებით გავაკეთებთ დიდი შორის მონაცემებზე. მრავალი სტრატიგიები გამოიყენება ჩვენი მოდელების შემწავლობისთვის, როგორც მრავალენგური შემწავლობა, შემწავლობა, წინასწავლობა, მონაცემების განტოლება, საშუალო შემწავლობა, საშუალო შემწავლობა, საშუალო შემწავლობა, ანუ. ჩვენი სისტემა მიიღ', 'it': "Questo articolo presenta la presentazione di Huawei Translation Service Center (HW-TSC) al WMT 2021 Triangolar MT Shared Task. Partecipiamo al compito russo-cinese a condizione limitata. Utilizziamo l'architettura Transformer e otteniamo le migliori prestazioni tramite una variante con parametri di dimensioni maggiori. Eseguiamo pre-elaborazione e filtraggio dettagliati dei dati sui dati bilingui forniti su larga scala. Diverse strategie sono utilizzate per addestrare i nostri modelli, come Traduzione Multilingue, Traduzione Indietro, Traduzione Forward, Denoising dei dati, Checkpoint medio, Ensemble, Fine-tuning, ecc Il nostro sistema ottiene 32.5 BLEU sul set di sviluppo e 27.7 BLEU sul set di test, il punteggio più alto tra tutte le proposte.", 'lt': 'Šiame dokumente pateikiamas Huawei vertimo paslaugos centro (HW-TSC) pateikimas WMT 2021 m. trikampei MT bendrai uždavinei. Mes dalyvaujame Rusijos–Kinijos užduotyje ribotomis sąlygomis. Naudojame Transformer architektūrą ir gauname geriausius rezultatus naudojant variant ą su didesniais parametrų dydžiais. Atliekame išsamų duomenų išankstinį apdorojimą ir filtravimą pateiktais didelio masto dvikalbiais duomenimis. Mūsų modeliams treniruoti naudojamos kelios strategijos, pavyzdžiui, daugiakalbis vertimas, atgalinis vertimas, išankstinis vertimas, duomenų atmetimas, vidutinis tikrinimo taškas, vienkartinis derinimas, patobulinimas ir t. t. Mūsų sistema gauna 32,5 BLEU dev rinkinyje ir 27,7 BLEU bandymų rinkinyje, didžiausias rezultatas iš visų pareiškimų.', 'kk': 'Бұл қағаз Huawei аудару қызметінің ортасына (HW- TSC) WMT 2021 үшбұрышты MT ортақтастырылған тапсырмасына жіберіледі. Біз Руссия-Қытай тапсырмасына шектелген жағдайда қатынасыз. Біз түрлендіруші архитектурасын қолданып, үлкен параметрлердің өлшемі арқылы ең жақсы әрекеттерді аламыз. Егжей- тегжейлі деректерді алдын- ала өңдеу және сүзгілеу керек үлкен- тегжейлі екі тіл деректеріне орындаймыз. Біздің үлгілерімізді оқыту үшін бірнеше стратегиялар қолданылады, мысалы, көптілік аударылуы, қайта аударылуы, алдыңғы аударылуы, Деректердің денофикациясы, орташа тексеру нүктесі, Ensemble, Fine- tuning, т. б. жүйеміздің dev set- де 32. 5 BLEU және 27. 7 BLEU сынақтарында', 'ms': 'Kertas ini memperkenalkan penghantaran Pusat Perkhidmatan Terjemahan Huawei (HW-TSC) ke Tugas Berkongsi MT Segitiga WMT 2021. Kami berpartisipasi dalam tugas Rusia-China di bawah keadaan yang terhalang. Kami menggunakan arkitektur Transformer dan mendapatkan prestasi terbaik melalui varian dengan saiz parameter yang lebih besar. Kami melakukan preproses data terperinci dan penapisan pada data bilingual skala besar yang diberikan. Beberapa strategi digunakan untuk melatih model kita, seperti Translation Multilingual, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, dll.', 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni taċ-Ċentru tas-Servizz tat-Traduzzjoni ta’ Huawei (HW-TSC) lil WMT 2021 Triangular MT Shared Task. We participate in the Russian-to-Chinese task under the constrained condition.  Aħna nużaw l-arkitettura Transformer u niksbu l-a ħjar prestazzjoni permezz ta’ varjant b’daqsijiet akbar ta’ parametri. Għandna nagħmlu proċessar u filtrazzjoni dettaljati tad-dejta minn qabel dwar id-dejta bilingwi fuq skala kbira pprovduta. Diversi strateġiji jintużaw biex jitħarrġu l-mudelli tagħna, bħat-Traduzzjoni Multilingwi, Traduzzjoni ta’ wara, Traduzzjoni ’l quddiem, Denoising tad-Dejta, Punt ta’ Kontroll Medju, Ensemble, Irfinar, eċċ. Is-sistema tagħna tikseb 32.5 BLEU fuq is-sett dev u 27.7 BLEU fuq is-sett tat-test, l-ogħla punteġġ fost is-sottomissjonijiet kollha.', 'mk': 'Овој весник го претставува поднесувањето на Центарот за преведување на Хуауеј (ХВ-ТСЦ) на WMT 2021 Тријакуларна MT заедничка задача. Ние учествуваме во руско-кинеската задача под ограничени услови. Користиме трансформерна архитектура и ја добиваме најдобрата резултат преку варијант со поголеми големини на параметри. We perform detailed data pre-processing and filtering on the provided large-scale bilingual data.  Неколку стратегии се користат за обука на нашите модели, како што се Мултијазичен превод, Назаден превод, Напреден превод, Деноизирање на податоци, Просечна контролна точка, Енсембл, Фингулација итн. Нашиот систем добива 32,5 БЛЕ на дев сет и 27,7 БЛЕ на тестот сет, највисока оценка меѓу сите поднесувања.', 'ml': 'ഹുവായി പരിഭാഷ സേവനത്തിന്റെ സേന്ദ്രത്തിന്റെ (HW-TSC) കൊടുക്കുന്ന ഈ പേപ്പറ് WMT 2021 ട്രിയാങ്കിള്\u200d MT പങ്കുചേര്\u200dത്ത നിര്\u200dബന്ധിതമായ അവസ്ഥയില്\u200d ഞങ്ങള്\u200d റഷ്യന്\u200d മുതല്\u200d ചൈനീസ് ജോലിയില്\u200d പങ്കെടുക്കുന്നു. നമ്മള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്കിട്ടേഷന്\u200d ഉപയോഗിക്കുന്നു. ഏറ്റവും വലിയ പാരാമീറ്റര്\u200d വലിപ്പം കൊണ്ട് ഏറ്റവ നമ്മള്\u200d വിശദീകരിച്ച വിവരങ്ങള്\u200d മുന്\u200dപ് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനും ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നു. വലിയ ഭാഷ ഡ്യ നമ്മുടെ മോഡലുകളെ പരിശീലിപ്പിക്കാന്\u200d പലതും ഉപയോഗിക്കുന്നു. പല ഭാഷ പരിഭാഷകള്\u200d, പിന്നിലെ പരിഭാഷകള്\u200d, മുന്നോട്ട് പരിഭാഷകള്\u200d, ഡേറ്റാ പരിഭാഷകള്\u200d, ഡേറെയിജ് ചെക്ക്പോയിന്\u200dറ്, എണ്ണപ്പെടുത്തിയ, സിസ്റ്റം ഡ', 'no': 'Denne papiret viser å senda Huawei- omsetjingsteneste- sentrum (HW- TSC) til WMT 2021 delt oppgåve med trekantar MT- delt. Vi deltar i den russiske til kinesiske oppgåva under begrenset vilkår. Vi brukar Transformeringsarkitektur og får det beste utviklinga via ein variant med større parameter-storleik. Vi utfører detaljerte førehandsaming og filtrering av dei tilgjengelege største bilingueldata. Fleire strategier blir brukt til å trenja modelane våre, som fleirspråk omsetjing, tilbakeomsetjing, framover omsetjing, data- denoising, gjennomsnittpunkt, Ensemble, Fine- tuning osv. Systemet vårt får 32, 5 BLEU på dev- settet og 27, 7 BLEU på testsettet, høgste poeng mellom alle undersøkingar.', 'pl': 'Niniejszy artykuł przedstawia zgłoszenie Centrum Usług Tłumaczeń Huawei (HW-TSC) do WMT 2021 Trójkątnego MT Shared Task. Uczestniczymy w zadaniu rosyjsko-chińskim w ograniczonych warunkach. Wykorzystujemy architekturę Transformera i uzyskujemy najlepszą wydajność poprzez wariant o większych rozmiarach parametrów. Wykonujemy szczegółowe wstępne przetwarzanie i filtrowanie danych na dużej skali dwujęzycznych danych. Do szkolenia naszych modeli stosuje się kilka strategii, takich jak tłumaczenie wielojęzyczne, tłumaczenie wsteczne, tłumaczenie do przodu, denoising danych, średni punkt kontrolny, zespół, dostrajanie itp. Nasz system uzyskuje 32.5 BLEU na zestawie deweloperskim i 27.7 BLEU na zestawie testowym, najwyższy wynik spośród wszystkich zgłoszeń.', 'mn': 'Энэ цаас Huawei Translation Service Center (HW-TSC) WMT 2021-д гурван өнцөг MT хуваалтын ажлыг тайлбарладаг. Бид хязгаарлагдсан нөхцөлд Российн-Хятадын ажилд оролцсон. Бид Transformer архитектурыг ашиглаж, том параметр хэмжээтэй хамгийн сайн үйл ажиллагааг ашиглаж байна. Бид өгөгдлийн талаар ажиллаж, хоёр хэл өгөгдлийн талаар шинжилгээ хийдэг. Бидний олон хэл хөрөнгө оруулалт, буцаад хөрөнгө оруулалт, урд хөрөнгө оруулалт, өгөгдлийн Denoising, дундаж шалгалтын цэг, Ensemble, Fine-tuning, т.д. бидний систем 32.5 BLEU-г шалгалт дээр авдаг бөгөөд 27.7 BLEU-г шалгалт дээр авдаг бөгөөд бүх хүмүүсийн хамгийн өндөр оноо авдаг.', 'ro': 'Această lucrare prezintă depunerea Centrului de Servicii de Traduceri Huawei (HW-TSC) la WMT 2021 Triangular MT Shared Task. Participăm la sarcina ruso-chineză în condiţia constrânsă. Folosim arhitectura Transformer si obtinem cele mai bune performante printr-o varianta cu dimensiuni mai mari ale parametrilor. Efectuăm prelucrarea și filtrarea detaliată a datelor pe scară largă bilingvă furnizate. Mai multe strategii sunt folosite pentru a instrui modelele noastre, cum ar fi traducerea multilingvă, traducerea înapoi, traducerea înainte, denunțarea datelor, punctul de control mediu, ansamblul, reglarea fină etc. Sistemul nostru obține 32.5 BLEU pe setul de dezvoltare și 27.7 BLEU pe setul de test, cel mai mare scor dintre toate depunerile.', 'sr': 'Ovaj papir predstavlja predavanje Huawei Translation Service Centre (HW-TSC) na WMT 2021 Triangular MT Shared Task. Mi sudjelujemo u ruskom i kineskom zadatku pod ograničenim stanjem. Koristimo arhitekturu transformera i dobijamo najbolje izvršenje putem varijanta sa većim veličinama parametara. Izvodimo detaljne podatke predobrađivanja i filtriranja na pruženim velikim dvojezičkim podacima. Nekoliko strategija se koristi za obuku našeg modela, kao što su multijezički prevod, natrag prevod, napredni prevod, datum Denoising, srednji kontrolni punkt, Ensemble, Fine tuning itd. Naš sistem dobija 32,5 BLEU na setu dev i 27,7 BLEU na setu testa, najveći rezultat među svim podacima.', 'si': 'මේ පැත්තේ හුවේයි වාර්ථාපනය සේවාව මධ්\u200dයස්ථානය (HW- TSC) WMT 2021 ත්\u200dරිකෝණික MT කොටස් වලට පිළිගන්නවා. අපි රුසියානුවෙන් චීනියානුවෙන් ක්\u200dරියාවෙන් සම්බන්ධ වෙනවා. අපි ප්\u200dරවර්තනය විද්\u200dයාපකය විද්\u200dයාපකය භාවිතා කරනවා හැම හොඳම විද්\u200dයාපකය ප්\u200dරවර්තනයක් ලැබෙනවා වි අපි ප්\u200dරතිශේෂ දත්ත ප්\u200dරක්\u200dරියාස කරන්න සහ ප්\u200dරතිශේෂණය කරන්න පුළුවන් ලොකු ප්\u200dරමාණයේ දුවන් භාෂා වෙනත් සැලසුම් භාවිතාව භාවිතා කරනවා අපේ මොඩේල්ස් වලින්, Multilanguage translation, back translation, forward translation, Data Denoising, Average checkkPoints, Ensemble, Fine-tuning, etc. අපේ පද්ධතියේ 32.5 BLUE on the dev set and 27.7 BLUE on the testing set, the high score of all Sub-ssion.', 'sv': 'Denna uppsats presenterar inlämningen av Huawei Translation Service Center (HW-TSC) till WMT 2021 Triangular MT Shared Task. Vi deltar i den ryska-kinesiska uppgiften under det begränsade villkoret. Vi använder Transformer arkitektur och får bästa prestanda via en variant med större parameterstorlekar. Vi utför detaljerad databehandling och filtrering på de storskaliga tvåspråkiga data som tillhandahålls. Flera strategier används för att träna våra modeller, såsom flerspråkig översättning, bakåtöversättning, vidareöversättning, datadenoising, genomsnittlig kontrollpunkt, ensemble, finjustering, etc. Vårt system får 32,5 BLEU på utvecklingsuppsättningen och 27,7 BLEU på testuppsättningen, den högsta poängen bland alla inlämningar.', 'ur': 'This paper presents the submission of Huawei Translation Service Center (HW-TSC) to WMT 2021 Triangular MT Shared Task. ہم روسی سے چین کے کام میں مشارکت کرتے ہیں محدودہ شرط پر۔ ہم ترنسفور معماری استعمال کرتے ہیں اور بہترین فعالیت حاصل کرتے ہیں ایک الگو کے ذریعے بڑے پارامیٹ سایز کے ساتھ۔ ہم مفصل ڈیٹا پیش پرسس کرنے اور فیلٹرینگ کر رہے ہیں۔ ہمارے مدل کی تعلیم کے لئے بہت سی استراتژی استعمال کیے جاتے ہیں، جیسے Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning etc. ہماری سیستم کو ڈیو سٹ پر 32.5 BLEU حاصل کرتی ہے اور 27.7 BLEU کو آزمائش سٹ پر حاصل کرتی ہے، سب کے مسلمانوں میں سب سے زیادہ اچھا اسکور ملتی ہے.', 'so': "This paper presents the submission of Huawei Translation Service Center (HW-TSC) to WMT 2021 Triangular MT Shared Task.  Shaqada Ruushka iyo Shiino waxaynu ka qayb galnaa xaalada qasabka ah. Waxaynu isticmaalnaa taariikhda turjumista, waxaana helaynaa tababarka ugu wanaagsan ee ku qoran tirada tirada waaweyn. Waxaannu sameynaa macluumaad faa'iido ah oo ka horeysa baaraandegista iyo baaritaanka labada luuqadood oo kala duduwan. Shaqooyin badan waxaa loo isticmaalaa in loo tababariyo tusaale ahaan turjumista luuqadaha badan, dib-turjumidda, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning etc. systemkaygu wuxuu helaa 32.5 BLEU oo ku qoran qorshaha iyo 27.7 BLEU oo ku qoran imtixaanka, kooxda ugu sarreeya oo dhan.", 'ta': 'இந்த தாள் Huawei மொழிபெயர்ப்பு சேவை மையம் (HW- TSC) WMT 2021 முக்கோணம் MT பகிர்ந்த பணிக்கு அனுப்புகிறது. நாங்கள் கட்டுப்படுத்தப்பட்ட நிலையில் ருஷ்யன் முதல் சீனா பணியில் பங்கிடுகிறோம். பெரிய அளபுரு அளவுகள் மூலம் மாறியில் நாம் மாற்றி உருவாக்கத்தை பயன்படுத்தி சிறந்த செயல்பாடு பெறுகிறோம். நாம் விவரமான தகவல் முன் செயல்படுத்தல் மற்றும் வடிகட்டி பெரிய அளவு இரு மொழி தரவு பல மொழி மொழிபெயர்ப்பு, மொழிபெயர்ப்பு, முன்னோக்கி மொழிபெயர்ப்பு, தரவு நிராகரிப்பு, சராசரி செக்புள்ளி, ஒழுங்குப் புள்ளியை மேலும் பயிற்சி செய்ய பல திட்டங்கள் பயன்படுத்தப்படுகிறது. எங்கள் கணினியின் ம', 'uz': "This paper presents the submission of Huawei Translation Service Center (HW-TSC) to WMT 2021 Triangular MT Shared Task.  Biz qanday holatda Ruscha-Xitoycha vazifani qiziqaramiz. Biz Transformer architektordan foydalanamiz va katta parametrlar oʻlchami orqali eng yaxshi bajarish natijasida bajaramiz. Biz katta ko'plab ikkita tillar maʼlumotini boshqarish va filterlashni bajaramiz. Koʻp qancha strategiyadan bir necha xil tillarga tarjima qilish uchun foydalanadi, masalan muloqat tarjima qilish, orqaga tarjima qilish, maʼlumot tarjima qilish, shaxsiy cheksiz, soʻzni tekshirish, tugmalar tarjima qilishi mumkin. Bizning tizimmiz dev moslamalarida 32.5 BLEU va bir tizimning eng eng eng darajaga 27.7 BLEU mavjud.", 'vi': 'Tờ giấy này giới thiệu đơn trình của trung tâm dịch dịch thuật Huwei (HW-TSC) cho WRT 2021 Triangular MTV shared Task. Chúng tôi tham gia nhiệm vụ giữa Nga và Trung Quốc với những hạn chế. Chúng tôi sử dụng kiến trúc transformer và đạt được hiệu suất tốt nhất qua một biến thể có kích thước Tham số lớn hơn. Chúng tôi cung cấp dữ liệu sơ bộ và lọc chi tiết trên dữ liệu hai chiều rộng. Nhiều chiến lược được dùng để huấn luyện các mô hình của chúng ta, như đa ngôn ngữ, Back Translation, Forward translation, Data Denising, trung bình Checkpoint, Ensemble, fine-tinh, v. Hệ thống của chúng ta có 32.5 bleU on the dev set và 27 bleU on the test set, the highest score among all confess.', 'bg': 'Настоящата статия представя представянето на Центъра за преводи на Триъгълна МТ Споделена задача. Участваме в руско-китайската задача при ограничени условия. Използваме архитектура на трансформатора и получаваме най-добрата производителност чрез вариант с по-големи размери на параметрите. Извършваме подробна предварителна обработка и филтриране на предоставените широкомащабни двуезични данни. Няколко стратегии се използват за обучение на нашите модели, като например многоезичен превод, назад превод, напред превод, денонизиране на данни, среден контролен пункт, ансамбъл, фина настройка и др.', 'hr': 'Ovaj papir predstavlja predavanje centra za prevod Huawei (HW-TSC) na WMT 2021 Triangular MT zajednički zadatak. Mi sudjelujemo u ruskom i kineskom zadatku pod ograničenim uvjetom. Koristimo arhitekturu Transformer a i dobijamo najbolju učinku putem varijanta s većim veličinama parametara. Izvodimo detaljne podatke predobrađivanja i filtriranja na pruženim velikim dvojezičkim podacima. Nekoliko strategija se koristi za obuku našeg modela, poput multijezičkog prevoda, natrag prevoda, naprijed prevoda, prosječnog kontrolnog mjesta podataka, prosječnog kontrolnog mjesta, proizvodnja, dobra prilagodba itd. Naš sustav dobija 32,5 BLEU na setu dev-a i 27,7 BLEU na setu ispitivanja, najveći rezultat među svim podacima.', 'nl': 'Dit document presenteert de indiening van Huawei Translation Service Center (HW-TSC) aan WMT 2021 Triangular MT Shared Task. We nemen deel aan de Russisch-Chinese taak onder de beperkte voorwaarde. We gebruiken Transformer architectuur en verkrijgen de beste prestaties via een variant met grotere parametergroottes. Op de verstrekte grootschalige tweetalige gegevens voeren wij gedetailleerde voorbewerking en filtering uit. Verschillende strategieën worden gebruikt om onze modellen te trainen, zoals Meertalige Vertaling, Terugvertaling, Forward Translation, Data Denoising, Gemiddelde Checkpoint, Ensemble, Fine-tuning, enz. Ons systeem verkrijgt 32.5 BLEU op de dev set en 27.7 BLEU op de testset, de hoogste score onder alle inzendingen.', 'da': 'Dette papir præsenterer indsendelsen af Huawei Translation Service Center (HW-TSC) til WMT 2021 Triangle MT Shared Task. Vi deltager i den russisk-kinesiske opgave på den begrænsede betingelse. Vi bruger Transformer arkitektur og opnår den bedste ydeevne via en variant med større parameterstørrelser. Vi udfører detaljeret databehandling og filtrering på de leverede tosprogede data i stor skala. Flere strategier bruges til at træne vores modeller, såsom Flersproget Oversættelse, Back Translation, Fremadrettet Oversættelse, Data Denoising, Gennemsnitlig Checkpoint, Ensemble, Finjustering osv Vores system opnår 32,5 BLEU på udviklingssættet og 27,7 BLEU på testsættet, den højeste score blandt alle indsendelser.', 'de': 'Dieses Papier stellt die Einreichung des Huawei Translation Service Centers (HW-TSC) an WMT 2021 Triangular MT Shared Task vor. Wir beteiligen uns an der russisch-chinesischen Aufgabe unter den beschränkten Bedingungen. Wir verwenden Transformer-Architektur und erzielen die beste Performance über eine Variante mit größeren Parametergrößen. Wir führen eine detaillierte Datenaufbereitung und -filterung der bereitgestellten zweisprachigen Großdaten durch. Mehrere Strategien werden verwendet, um unsere Modelle zu trainieren, wie Mehrsprachige Übersetzung, Rückübersetzung, Vorwärtsübersetzung, Datendenoisierung, Durchschnittlicher Checkpoint, Ensemble, Feinabstimmung usw. Unser System erhält 32.5 BLEU auf dem Entwicklerset und 27.7 BLEU auf dem Testset, die höchste Punktzahl unter allen Einreichungen.', 'id': 'Kertas ini menunjukkan pengiriman Huawei Translation Service Center (HW-TSC) ke WMT 2021 Triangular MT Shared Task. Kami berpartisipasi dalam tugas Rusia-Cina di bawah kondisi terbatas. We use Transformer architecture and obtain the best performance via a variant with larger parameter sizes.  Kami melakukan preproses data rincian dan penapisan pada data bilingual yang diberikan skala besar. Beberapa strategi digunakan untuk melatih model kami, seperti Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, dll. Sistem kami mendapatkan 32,5 BLEU pada set dev dan 27,7 BLEU pada set tes, skor tertinggi diantara semua submissions.', 'ko': '본고는 화웨이 번역서비스센터(HW-TSC)가 WMT 2021 삼각 MT 공유 임무에 제출한 상황을 소개한다.우리는 유한한 조건 하에서 러시아와 중국의 임무에 참여했다.우리는 더 큰 파라미터의 변체를 통해 최상의 성능을 얻기 위해 Transformer 구조를 사용합니다.우리는 제공된 대규모 이중 언어 데이터에 대해 상세한 데이터 예처리와 필터를 진행했다.다국어 번역, 회역, 전역, 데이터 소음 제거, 평균 체크포인트, 집적, 미세조정 등 여러 가지 전략을 사용해 모델을 훈련시켰습니다. 저희 시스템은 개발집에서 32.5BLEU, 테스트집에서 27.7BLEU를 받았는데 이는 제출한 모든 자료 중 가장 높은 점수입니다.', 'fa': 'این کاغذ تحویل مرکز ترجمه خدمات Huawei (HW-TSC) را به WMT 2021 به کار مشترک MT سه زاویه نمایش می\u200cدهد. ما در وضعیت محدودیت روسیه و چینی شرکت می کنیم. ما از معماری تغییر دهنده استفاده می\u200cکنیم و بهترین عملکرد را از طریق یک تغییر با اندازۀ پارامتر بزرگ می\u200cگیریم. ما داده\u200cهای پیش\u200cپردازش و فیلتر کردن جزئیات را روی داده\u200cهای دو زبان بزرگ پیش\u200cفرض می\u200cکنیم. چندتا استراتژی برای آموزش مدلهای ما استفاده می\u200cشود، مثل ترجمه\u200cهای زیادی زبان، ترجمه\u200cهای عقب، ترجمه\u200cهای پیشینی، ترجمه\u200cهای داده\u200cهای دنویسینگ، چک\u200cنقطه\u200cهای متوسط، انزیمبل، تنظیم\u200cهای زیبا و غیر از آن. سیستم ما 32.5 BLEU در مجموعه\u200cی dev و 27.7 BLEU در مجموعه آزمایش می\u200cگیرد، بالاتری', 'tr': 'Bu kagyz Huawei Terjime Servis Merkezi (HW-TSC) WMT 2021 üç köp MT Paýlaşylyş Görevine ugraşyrýar. Biz ýok durumda Rusça-Çin çe işine goşulýarys. Biz Transformer arhitektegi ullanýarys we gowy ukyplary uly bir wariant ullanýarys. Biz maglumatlary ön-emeli işleýän we bellenen uly kalamlar iki dil maglumatynda süýşirdik. Birnäçe strategiýa modellerimizi öwrenmek üçin ullanýar, ýaly Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Orta Checkpoint, Ensemble, Fine-tuning, etc. Biziň sistemamyz dev düzümlerinde 32.5 BLEU we 27.7 BLEU testi düzümlerinde bolýar, ähli süýtgedeniň iň beýik netijesi bar.', 'af': "Hierdie papier voorstel die onderskrywing van Huawei Vertaling Deens Sentrum (HW- TSC) na WMT 2021 Triangular MT Gedeelde Opdrag. Ons deel in die Russe-na-Chinesese taak onder die beperkte voorwaardes. Ons gebruik Transformer Arkitektuur en verkry die beste prestasie deur 'n variant met groter parameter grootte. Ons uitvoer gedetaileerde data voorafverandering en filtering op die verskaf groot- skala twee-tale data. Verskeie strategies word gebruik om ons modele te oefen, soos Multilingual Vertaling, Terug Vertaling, Vorentoe Vertaling, Data Denoising, Gemiddelde Checkpoint, Ensemble, Fine- tuning, ensfh. Ons stelsel kry 32. 5 BLEU op die dev set en 27. 7 BLEU op die toets stel, die hoogste telling onder alle onderwerp.", 'sw': 'Gazeti hili linaonyesha ujumbe wa Kituo cha Tafsiri cha Huawei (HW-TSC) kwenye kazi ya MT ya Tamasha ya WMT 2021. Tunashiriki katika kazi ya Urusi na China chini chini ya hali inayolazimishwa. Tunatumia ujenzi wa Transformer na kupata ufanisi bora zaidi kupitia tofauti kubwa kwa kiwango kikubwa cha parameter. Tunafanya taarifa za kina za kabla ya upasuaji na kuchuja taarifa zinazotolewa kwa lugha mbili. Mipango kadhaa inatumika kufundisha mifano yetu kama vile Tafsiri ya lugha nyingi, Tafsiri ya nyuma, Utafiri wa Takwimu, Kukataa Mashindano ya Kuondolewa kwa Takwimu, Uchunguzi wa Takwimu, Uwekezaji mzuri, Mfumo wetu unapata BLEU 32.5 kwenye seti ya mpango huo na BLEU 27.7 kwenye seti, vipimo vya juu zaidi miongoni mwa mawasiliano yote.', 'sq': 'Ky artikull paraqet paraqitjen e Qendrës së Shërbimit të Përkthimit të Huaweit (HW-TSC) në WMT 2021 Triangular MT Shared Task. Ne marrim pjesë në detyrën ruse-kineze nën kushtin e kufizuar. We use Transformer architecture and obtain the best performance via a variant with larger parameter sizes.  Ne kryejmë paraprocesimin e të dhënave të detajuara dhe filtrimin e të dhënave dygjuhësore në shkallë të madhe. Disa strategji përdoren për të trajnuar modelet tona, të tilla si Translation Multilingual, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, etj. Sistemi ynë merr 32.5 BLEU në set dev dhe 27.7 BLEU në set test, rezultati më i lartë midis të gjitha paraqitjeve.', 'hy': 'Այս աշխատանքը ներկայացնում է Հուավեի թարգմանման ծառայության կենտրոնի (ՀW-ՏՍԿ) ներկայացումը 2021 թվականի ԱՄԹ եռանկյունային MT-ի կիսված խնդրին: Մենք մասնակցում ենք Ռուսաստանի-Չինաստանի առաջադրանքին սահմանափակ պայմաններում: Մենք օգտագործում ենք Transforme ճարտարապետությունը և ստանում ենք լավագույն արդյունքը մեծ պարամետրերի չափերի տարբերակի միջոցով: Մենք կատարում ենք մանրամասն տվյալներ նախավերամշակման և ֆիլտրման մեծ ծավալի երկլեզու տվյալների վրա: Մեր համակարգը ստանում է 32.5 ԲԼԵ-ն, և 27.7 ԲԼԵ-ն, ամենաբարձր գնահատականը բոլոր ներկայացումների մեջ:', 'am': 'ይህ ገጽ Huawei ትርጉም ማዕከላዊ ማዕከል (HW-TSC) ወደ WMT 2021 Triangular MT ተርጓሚ ስራ እንዲያሳየው ያቀርባል፡፡ በሥርዓት ሥርዓት በታች በሮሽኛ-ወደ ቻይና-ስራ ላይ እናጋራለን፡፡ ትልቅ ባርራሮች መጠን በተለየን የፊደል መሠረት እናስቀምጣለን፡፡ We perform detailed data pre-processing and filtering on the provided large-scale bilingual data.  ብዙ strategies are used to train modelሞቻችንን, like Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning etc. system is 32.5 BLEU on the dev set and 27.7 BLEU on the test set, the highest score among all submissions.', 'az': 'Bu kağıt Huawei Tercümə Servisi Merkezi (HW-TSC) WMT 2021 Ücücü MT paylaşdırılmış işləri təyin edir. Biz qüvvətli şəkildə Rus-Çin işin ə katılırıq. Biz Transformer arhitektarını kullanırıq və böyük parametr ölçüləri ilə ən yaxşı performans alırıq. Biz verilən böyük-ölçülü iki dil verilənlərin üstündə detaylı məlumatları ön işləmək və filtrləmək üçün işlədik. Bizim modellərimizi təhsil etmək üçün bir çox stratejik istifadə edilir: Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, etc. sistemimiz dev set və 27.7 BLEU test setdə 32.5 BLEU alır.', 'bn': 'এই পত্রিকাটি হুয়াই অনুবাদ সার্ভিস সেন্টার (এইচডি-টিএসসি) উইএমটি ২০২১ ট্রিভাঙ্গালী এমটি শেয়ার কর্মসূচীর প্রতি উপস্থ আমরা রাশিয়ান থেকে চীনা কাজে অংশগ্রহণ করি। আমরা ট্রান্সফ্রান্সফারের আর্কিটার ব্যবহার করি এবং বৃহত্তর প্যারামিটার আকারের মাধ্যমে ভিন্ন ভিন্ন ভিন্ন ভ আমরা বিস্তারিত তথ্য প্রক্রিয়ার পূর্ব প্রক্রিয়া এবং ফিল্টার করি বিস্তারিত তথ্য দুই ভাষার তথ্যের উপর। বেশ কয়েকটি কৌশল আমাদের মডেল প্রশিক্ষণের জন্য ব্যবহার করা হয়েছে, যেমন মাল্টিভাষার অনুবাদ, পিছনের অনুবাদ, ফোরার্ড অনুবাদ, ডাটা ডেনোজিং, সর্বোচ্চ চ চেক পয়েন্ট, এনসেমেবল, ফিন-টুনিং ইত্যাদি আমাদের সিস্', 'bs': 'Ovaj papir predstavlja predavanje Huawei Translation Service Center (HW-TSC) na WMT 2021 Triangular MT Shared Task. Mi sudjelujemo u ruskom i kineskom zadatku pod ograničenim stanjem. Koristimo arhitekturu Transformer a i dobijamo najbolje izvođenje putem varijanta sa većim veličinama parametara. Izvodimo detaljne podatke predobrađivanja i filtriranja na pruženim velikim dvojezičkim podacima. Nekoliko strategija se koristi za obuku našeg modela, kao što su multijezički prevod, natrag prevod, naprijed prevod, datum Denoising, srednji kontrolni punkt, Ensemble, Fine tuning itd. Naš sistem dobija 32,5 BLEU na setu dev i 27,7 BLEU na setu testa, najveći rezultat među svim podacima.', 'cs': 'Tento článek představuje předložení Huawei Translation Service Center (HW-TSC) do WMT 2021 Trojúhelníkové MT Shared Task. Podílíme se na rusko-čínském úkolu za omezených podmínek. Používáme architekturu Transformer a dosahujeme nejlepšího výkonu prostřednictvím varianty s většími parametry. Na poskytnutých rozsáhlých dvojjazyčných datech provádíme detailní předzpracování a filtrování dat. Pro trénink našich modelů se používá několik strategií, jako je vícejazyčný překlad, zpětný překlad, dopřední překlad, denoising dat, průměrný kontrolní bod, soubor, jemné ladění atd. Náš systém získává 32.5 BLEU na vývojové sadě a 27.7 BLEU na testovací sadě, nejvyšší skóre ze všech příspěvků.', 'et': 'Käesolevas artiklis esitatakse Huawei tõlketeenusekeskuse (HW-TSC) esitamine WMT 2021 kolmnurksele MT jagatud ülesandele. Me osaleme Vene-Hiina ülesandes piiratud tingimustel. Kasutame Transformeri arhitektuuri ja saavutame parima jõudluse suuremate parameetritega variandi kaudu. Me teostame esitatud suuremahuliste kakskeelsete andmete detailset eeltöötlust ja filtreerimist. Meie mudelite koolitamiseks kasutatakse mitmeid strateegiaid, nagu mitmekeelne tõlge, tagasitõlge, edasitõlge, andmete denoiseerimine, keskmine kontrollpunkt, ansambel, peenhäälestus jne Meie süsteem saab arenduskomplekti 32,5 BLEU ja testikomplekti 27,7 BLEU, mis on kõigi esitatud tulemuste hulgas kõrgeim tulemus.', 'fi': 'Tässä artikkelissa esitellään Huawei Translation Service Center (HW-TSC) -ohjelmiston lähettäminen WMT 2021 Triangular MT Shared Task -ohjelmaan. Osallistumme Venäjän ja Kiinan väliseen tehtävään rajoitetuissa olosuhteissa. Käytämme Transformer-arkkitehtuuria ja saavutamme parhaan suorituskyvyn suuremmalla parametrikoolla varustetulla variantilla. Suoritamme yksityiskohtaisen tietojen esikäsittelyn ja suodatuksen toimitetuille suurille kaksikielisille tiedoille. Mallien kouluttamiseen käytetään useita strategioita, kuten monikielinen käännös, taaksekääntäminen, eteenpäin kääntäminen, tietojen denoisointi, keskimääräinen tarkistuspiste, Ensemble, Fine-tuning jne. Järjestelmämme saa 32,5 BLEU kehityssarjassa ja 27,7 BLEU testisarjassa, korkein pistemäärä kaikista lähetetyistä.', 'ca': "Aquest article presenta la presentació del centre de serveis de traducció Huawei (HW-TSC) a WMT 2021 Triangular MT Shared Task. Participem en la tasca russa-xinesa sota la condició limitada. Utilitzem arquitectura Transformer i obtenim el millor rendiment a través d'una variant amb grans mida de paràmetres. Fem un preprocessament detallat de dades i filtrim les dades bilingues proporcionades a gran escala. Diverses estratègies s'utilitzen per formar els nostres models, com la traducció multilingüe, la traducció posterior, la traducció posterior, la negació de dades, el punt de control mitjà, Ensemble, Fine-tuning, etc. El nostre sistema obté 32,5 BLEU en el set dev i 27,7 BLEU en el set de prova, la puntuació més alta entre totes les presentacions.", 'jv': 'Ngerti iki bakal ngewehi nggambar aturan huawei translation service center (HWT-T S) kanggo WT 2020 1 Trianguular MT shared task. Awak dhéwé ngerti cara Rusi-karo Kitani kuwi wis nguasai durung bisa nguasai string" in "context_BAR_string section politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': "This paper presents the submission of Huawei Translation Service Center (HW-TSC) to WMT 2021 Triangular MT Shared Task.  Munã tãrayya da aikin Ruushi-zuwa-China a ƙarƙasan an an ƙudura. Tuna amfani da tsarin Transformer kuma munã sami mafarin aiki da ke fi girma a matsayin da tsohon parameter. Mu cika data na fassara-bayan-aiki da za'a filteri kan da aka bãyar da data masu tsawo biyu. Babu masu amfani da akan yin kõri ga misãlai masu motsi, kamar Translate na Lugari, Fassarar da Bayan aiki, Dakata Tsariya, Tsarawa na Dama Tsariya, Ana iya amfani da masu tsari da masu tsari da kuma 27.7 BLEU a kan jarraba, da kyauta mafi girma daga dukkan musulunci.", 'sk': 'Ta prispevek predstavlja predložitev prevajalskega servisnega centra Huawei (HW-TSC) za WMT 2021 Triangular MT Shared Task. V rusko-kitajski nalogi sodelujemo pod omejenimi pogoji. Uporabljamo arhitekturo transformatorjev in dosegamo najboljšo zmogljivost preko različice z večjimi velikostmi parametrov. Izvajamo podrobno predobdelavo in filtriranje podatkov na zagotovljenih obsežnih dvojezičnih podatkih. Za usposabljanje naših modelov se uporablja več strategij, kot so večjezični prevod, nazaj prevod, naprej prevajanje, denoiziranje podatkov, povprečna kontrolna točka, ansambel, fino nastavitev itd. Naš sistem pridobi 32,5 BLEU na razvojnem kompletu in 27,7 BLEU na testnem kompletu, kar je najvišja ocena med vsemi prispevki.', 'bo': "ཤོག་བྱང་འདིས་Huawei Translation Service Center (HW-TSC)འདི་WMT 2021 Triangular MT Shared Task'ཡི་མཇུག་བསྡུ་ཡོད། ང་ཚོས་རྒྱ་ནག་ལས་འཆར་གཞུང་གི་གནས་སྟངས་ལ་རྒྱ་ནག་གི་ལས་འགུལ་སྐྱོད་བྱེད་ཀྱི་ཡོད། We use Transformer architecture and obtain the best performance via a variant with larger parameter sizes. ང་ཚོས་བྱིས་ཟུར་གསུམ་གྱི་སྔོན་ལས་སྦྱོར་བ་དང་ཆ་འཕྲིན་གཉིས་ཀྱི་ཆ་འཕྲིན་གསལ་བཤད་བྱས་པ་ཡིན། Several strategies are used to train our models, such as Multilingual Translation, Back Translation, Forward Translation, Data Denoising, Average Checkpoint, Ensemble, Fine-tuning, etc. Our system obtains 32.5 BLEU on the dev set and 27.7 BLEU on the test set, the highest score among all submissions.", 'he': 'העבודה הזו מציגה את ההעברה של מרכז שירות התרגום של הואאווי (HW-TSC) למשימה משולשת של WMT 2021 MT משותפת. We participate in the Russian-to-Chinese task under the constrained condition.  We use Transformer architecture and obtain the best performance via a variant with larger parameter sizes.  אנו מבצעים מידע מפורט לפני העבודה וסנן על המידע השולשי הגדול שנספק. מספר אסטרטגיות משתמשות לאימון הדוגמנים שלנו, כמו תרגום רב-שפתי, תרגום מאחור, תרגום קדימה, דנויס נתונים, נקודת בדיקה ממוצעת, Ensemble, Fine-tuning, וכו.'}
{'en': 'Transfer Learning with Shallow Decoders : BSC at WMT2021’s Multilingual Low-Resource Translation for Indo-European Languages Shared Task', 'es': 'Transfiera el aprendizaje con decodificadores superficiales: BSC en la tarea compartida de traducción multilingüe de bajos recursos para idiomas indoeuropeos del WMT2021', 'pt': 'Transferência de aprendizado com decodificadores rasos: BSC na tarefa compartilhada de tradução multilíngue de poucos recursos para idiomas indo-europeus do WMT2021', 'fr': 'Apprentissage par transfert avec des décodeurs superficiels\xa0: BSC à la tâche partagée de traduction multilingue à faibles ressources pour les langues indo-européennes du WMT2021', 'ar': 'نقل التعلم باستخدام أجهزة فك التشفير الضحلة: BSC في مهمة مشتركة للترجمة متعددة اللغات منخفضة الموارد للغات الهندية الأوروبية في WMT2021', 'ja': '浅いデコーダで学習を転送： WMT 2021のインド・ヨーロッパ語学共有タスクのための多言語低リソース翻訳のBSC', 'ru': 'Передача обучения с помощью неглубоких декодеров: BSC на многоязычном малоресурсном переводе WMT2021 для совместной задачи по индоевропейским языкам', 'hi': 'उथले डिकोडर के साथ स्थानांतरण सीखना: WMT2021 के बहुभाषी कम-संसाधन अनुवाद में इंडो-यूरोपीय भाषाओं के लिए BSC साझा कार्य', 'zh': '用浅层解码器移学:WMT2021印欧语多言低资源译共事者平计分卡', 'ga': 'Aistrigh Foghlaim le Díchódóirí Éadomhain: BSC ag Tasc Comhroinnte Ilteangach Aistriúchán Íseal-Acmhainne do Theangacha Ind-Eorpacha WMT2021', 'ka': 'Name', 'hu': 'Transzfer tanulás a sekély dekóderekkel: BSC a WMT2011 többnyelvű alacsony erőforrású fordításán indoeurópai nyelvekhez Megosztott feladat', 'el': 'Μάθηση μεταφοράς με ρηχά αποκωδικοποιητές: στο Πολυγλωσσικό Μεταφράσιμο Χαμηλών Πόρων για Ινδοευρωπαϊκές Γλώσσες Κοινή Εργασία', 'lt': 'Mokymasis perkelti su šešėliniais dekoderiais: BSC WMT2021 daugiakalbio mažų išteklių vertimo užduotyje', 'mk': 'Трансферско учење со темни декодери: BSC на Мултијазичниот превод со ниски ресурси на WMT2021 за заедничка задача на индуевропските јазици', 'kk': 'Күлкін декодерлерден оқыту: WMT2021- дің көп тілді төмен ресурстар аудармасында BSC ортақтастырылған тапсырмаName', 'it': 'Trasferimento di apprendimento con decodificatori superficiali: BSC alla traduzione multilingue a basso contenuto di risorse di WMT22021 per le lingue indoeuropee', 'mt': 'It-Tagħlim tat-Trasferimenti b’Dekodifikaturi Shallow: BSC fit-Traduzzjoni Multilingwi b’Riżorsi Bażi tad-WMT2021 għal Kompitu Konġunt tal-Lingwi Indo-Ewropej', 'ms': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'ml': 'ശല്ലോ ഡികോഡുകളുമായി പഠിക്കുന്ന പഠിപ്പിക്കുക: WMT2021-ലെ പല ഭാഷകള്\u200d കുറവ്- വിഭവങ്ങള്\u200dക്കുള്ള അനുവാദങ്ങള്\u200d', 'mn': 'Трансфер суралцах суралцах бага зэрэгцээ: WMT2021-н олон хэлний бага боловсролын хөрөнгө оруулалт Индо-Европын хэлний хуваалтын ажил дээр BSC', 'no': 'Comment', 'si': 'Name', 'pl': 'Transfer Learning za pomocą płytkich dekoderów: BSC w wielojęzycznym tłumaczeniu niskich zasobów WMT2028 dla języków indoeuropejskich', 'ro': 'Transferul de învățare cu decodoare subțiri: BSC la traducerea multilingvă cu resurse scăzute a WMT201 pentru limbi indoeuropene sarcina partajată', 'sv': 'Överföring av lärande med grunda avkodare: BSC vid WMT201s flerspråkiga lågresursöversättning för indoeuropeiska språk delad uppgift', 'sr': 'Prebacivanje učenja sa slavim dekoderima: BSC na WMT2021-ovom multijezičkom prevodu niskih resursa za delovani zadatak Indoevropskih jezika', 'so': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': "Truyền giáo truyền đạt với các giải mã Shalow: BSC tại WM221's đa ngôn ngữ thấp-gây chia s ẻ Nhiệm vụ", 'bg': 'Прехвърляне на обучение с плитки декодери: Бакалавърска програма по многоезичен превод с ниски ресурси за индоевропейски езици', 'nl': "Transfer Learning met ondiepe decoders: BSC bij WMT2028's meertalige low-resource vertaling voor Indo-Europese talen Gedeelde taak", 'hr': 'Prebacivanje učenja sa slavim dekoderima: BSC na WMT2021-ovom multijezičkom prevodu niskih resursa za zajednički zadatak Indoeuropskih jezika', 'da': 'Overfør læring med grundlæggende dekodere: BSC ved WMT201s flersprogede lav ressource oversættelse til indoeuropæiske sprog delt opgave', 'de': 'Transfer Learning mit flachen Decodern: BSC bei WMT2020s mehrsprachiger ressourcenschonender Übersetzung für indoeuropäische Sprachen Gemeinsame Aufgabe', 'ko': '얕은 디코더를 이용한 이동 학습: WMT 2021의 인구어 다언어 저자원 번역 공유 임무 이학 학사', 'sw': 'Tafsiri ya lugha ndogo kwa lugha za Kihindi-Ulaya', 'id': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'fa': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'tr': "Shallow Decoder bilen öwrenmek üçin Transfer Learning: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'sq': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'am': "BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task", 'af': 'Oordrag Leer met Skaal Dekoders: BSC by WMT2021 se veelvuldige Lae- Hulpbron Vertaling vir Indo- Europeese Taal Gedeelde Taak', 'bn': 'শ্যালো ডিকোডারের সাথে শিক্ষা অনুবাদ: WMT2021 এর বহুভাষায় বিএসসি অনুবাদ করুন ইন্ডো-ইউরোপীয় ভাষার জন্য ভাষা শেয়ার করা কাজ', 'hy': 'Հնդեվրոպական լեզուների կիսված հանձնարարության բազմալեզու ցածր ռեսուրսների թարգմանությունը', 'ca': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low Resource Translation for Indo-European Languages Shared Task", 'az': "Öyrənməyi Qısqa Dekodlayıcılarla Transfer: WMT2021'nin çoxlu dil Aşağı-Avropa dillərin paylaşılmış işləri üçün BSC", 'cs': 'Transfer učení s mělkými dekodéry: BSC na vícejazyčném překladu s nízkými zdroji WMT2028 pro indoevropské jazyky Sdílená úloha', 'et': 'Üleminekuõpe madalate dekoodritega: BSC WMT2012 mitmekeelse madala ressursiga tõlke Indo-Euroopa keeltele jagatud ülesanne', 'bs': 'Prebacivanje učenja sa slavim dekoderima: BSC na WMT2021-ovom multijezičkom prevodu niskog resursa za zajednički zadatak Indoevropskih jezika', 'fi': 'Siirto oppimista matalalla dekooderilla: BSC WMT22021 monikielisessä vähävaraisessa käännöksessä indoeurooppalaisille kielille Jaettu tehtävä', 'ha': '@ action', 'sk': 'Prenos učenja s plitvimi dekodirji: BSC na večjezičnem prevajanju z nizkimi viri WMT2011 za indoevropske jezike', 'he': 'למידת העברה עם מפענחים שחורים: BSC בתרגום משאבים נמוכים רבים של WMT2021 עבור משימה משותפת לשפות אינדו-אירופאיות', 'jv': 'Name', 'bo': "Transfer Learning with Shallow Decoders: BSC at WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task"}
{'en': 'This paper describes the participation of the BSC team in the WMT2021’s Multilingual Low-Resource Translation for Indo-European Languages Shared Task. The system aims to solve the Subtask 2 : Wikipedia cultural heritage articles, which involves translation in four ', 'ar': 'تصف هذه الورقة مشاركة فريق BSC في ترجمة WMT2021 متعددة اللغات منخفضة الموارد للمهمة المشتركة للغات الهندية الأوروبية. يهدف النظام إلى حل المهمة الفرعية 2: مقالات التراث الثقافي في ويكيبيديا ، والتي تتضمن الترجمة بأربع لغات رومانسية: الكاتالونية والإيطالية والأوكيتانية والرومانية. النظام المقدم هو نموذج ترجمة آلية متعدد اللغات شبه خاضع للإشراف. يعتمد على نموذج لغة تم تدريبه مسبقًا ، وهو XLM-RoBERTa ، والذي تم ضبطه لاحقًا باستخدام بيانات متوازية تم الحصول عليها في الغالب من OPUS. على عكس الأعمال الأخرى ، فإننا نستخدم XLM فقط لتهيئة المشفر وتهيئة وحدة فك ترميز ضحلة بشكل عشوائي. النتائج التي تم الإبلاغ عنها قوية وذات أداء جيد لجميع اللغات المختبرة.', 'es': 'Este artículo describe la participación del equipo de BSC en la tarea compartida de traducción multilingüe de bajos recursos para idiomas indoeuropeos del WMT2021. El sistema tiene como objetivo resolver la subtarea 2: artículos del patrimonio cultural de Wikipedia, que implica la traducción a cuatro lenguas romances: catalán, italiano, occitano y rumano. El sistema presentado es un modelo de traducción automática semisupervisada multilingüe. Se basa en un modelo de lenguaje previamente entrenado, denominado XLM-Roberta, que luego se ajusta con datos paralelos obtenidos principalmente de OPUS. A diferencia de otros trabajos, solo utilizamos XLM para inicializar el codificador e inicializar aleatoriamente un decodificador superficial. Los resultados informados son sólidos y funcionan bien en todos los idiomas evaluados.', 'fr': "Cet article décrit la participation de l'équipe BSC à la tâche partagée de traduction multilingue à faibles ressources pour les langues indo-européennes du WMT2021. Le système vise à résoudre la sous-tâche 2\xa0: articles sur le patrimoine culturel de Wikipédia, qui implique la traduction en quatre langues romanes\xa0: le catalan, l'italien, l'occitan et le roumain. Le système soumis est un modèle de traduction automatique semi-supervisée multilingue. Il est basé sur un modèle de langage pré-formé, à savoir XLM-Roberta, qui est ensuite affiné avec des données parallèles obtenues principalement auprès d'OPUS. Contrairement à d'autres travaux, nous n'utilisons que XLM pour initialiser l'encodeur et initialiser aléatoirement un décodeur superficiel. Les résultats rapportés sont robustes et performants pour toutes les langues testées.", 'pt': 'Este artigo descreve a participação da equipe BSC na tarefa compartilhada de tradução multilíngue de baixo recurso para idiomas indo-europeus do WMT2021. O sistema visa resolver a Subtarefa 2: artigos do patrimônio cultural da Wikipédia, que envolve a tradução em quatro línguas românicas: catalão, italiano, occitano e romeno. O sistema submetido é um modelo de tradução automática semi-supervisionada multilíngue. Ele é baseado em um modelo de linguagem pré-treinado, chamado XLM-RoBERTa, que é posteriormente ajustado com dados paralelos obtidos principalmente do OPUS. Ao contrário de outros trabalhos, usamos apenas XLM para inicializar o codificador e inicializar aleatoriamente um decodificador superficial. Os resultados relatados são robustos e apresentam bom desempenho para todos os idiomas testados.', 'ja': '本稿では、WMT 2021のインド・ヨーロッパ語学共有タスクのための多言語低リソース翻訳へのBSCチームの参加について説明します。このシステムは、カタルーニャ語、イタリア語、オクシタニア語、ルーマニア語の4つのロマンス語の翻訳を含むサブタスク2 ：ウィキペディアの文化遺産の記事を解決することを目的としています。提出されたシステムは、多言語半監修の機械翻訳モデルです。これは、事前にトレーニングされた言語モデル、すなわちXLM - RoBERTaに基づいており、後にOPUSから主に得られた並列データで微調整されます。他の作品とは異なり、XLMを使用してエンコーダを初期化し、浅いデコーダをランダムに初期化するだけです。報告された結果は堅牢であり、テストされたすべての言語で良好なパフォーマンスを発揮します。', 'hi': 'यह पेपर WMT2021 के बहुभाषी कम-संसाधन अनुवाद में इंडो-यूरोपीय भाषाओं के साझा कार्य के लिए बीएससी टीम की भागीदारी का वर्णन करता है। इस प्रणाली का उद्देश्य Subtask 2: विकिपीडिया सांस्कृतिक विरासत लेखों को हल करना है, जिसमें चार रोमांस भाषाओं में अनुवाद शामिल है: कैटलन, इतालवी, Occitan और रोमानियाई। प्रस्तुत प्रणाली एक बहुभाषी अर्ध-पर्यवेक्षित मशीन अनुवाद मॉडल है। यह एक पूर्व-प्रशिक्षित भाषा मॉडल पर आधारित है, अर्थात् XLM-RoBERTa, जो बाद में ज्यादातर OPUS से प्राप्त समानांतर डेटा के साथ ठीक हो जाता है। अन्य कार्यों के विपरीत, हम केवल एनकोडर को प्रारंभ करने और बेतरतीब ढंग से एक उथले विकोडक को प्रारंभ करने के लिए एक्सएलएम का उपयोग करते हैं। रिपोर्ट किए गए परिणाम मजबूत हैं और सभी परीक्षण की गई भाषाओं के लिए अच्छा प्रदर्शन करते हैं।', 'zh': '本文引平衡计分卡团队与WMT2021印欧语多言低资源译共之。 其统旨在解子务2:维基百科文化遗产条目,其四罗曼语译:加泰罗尼亚语,意大利语,奥克西唐语及罗马尼亚语。 提交之统,多言半监机器翻译模。 其先训言语模样,即XLM-RoBERTa,后用主OPUS并行数微调。 与他作不同,但用XLM初始化编码器随机初始化浅层解码器。 告之可恃,而试言皆善。', 'ru': 'В этой статье описывается участие команды BSC в многоязычном низкоресурсном переводе WMT2021 для совместной задачи по индоевропейским языкам. Система нацелена на решение Подзадачи 2: Статьи о культурном наследии Википедии, которая включает в себя перевод на четыре романских языка: каталанский, итальянский, окситанский и румынский. Представленная система представляет собой многоязычную полунадзорную модель машинного перевода. Она основана на предварительно обученной языковой модели, а именно XLM-RoBERTa, которая позже была доработана с параллельными данными, полученными в основном из ОПУСОВ. В отличие от других работ, мы используем только XLM для инициализации кодера и случайной инициализации неглубокого декодера. Зарегистрированные результаты являются надежными и хорошо работают для всех протестированных языков.', 'ga': 'Déanann an páipéar seo cur síos ar rannpháirtíocht fhoireann an BSC i dTasc Comhroinnte Ilteangach Aistriúchán Íseal-Acmhainne do Theangacha Ind-Eorpacha WMT2021. Tá sé mar aidhm ag an gcóras na hailt faoi oidhreacht chultúrtha Fothasc 2: Vicipéid a réiteach, a bhaineann le haistriúchán i gceithre theanga Rómánsacha: an Chatalóinis, an Iodáilis, an Occitan agus an Rómáinis. Múnla ilteangach aistriúcháin meaisín leath-mhaoirsithe atá sa chóras a chuirtear isteach. Tá sé bunaithe ar mhúnla teanga réamh-oilte, eadhon XLM-RoBERTa, atá mionchoigeartaithe níos déanaí le sonraí comhthreomhara a fuarthas go príomha ó OPUS. Murab ionann agus saothair eile, ní úsáidimid ach XLM chun an t-ionchódóir a thúsú agus chun díchódóir éadomhain a thúsú go randamach. Tá na torthaí tuairiscithe láidir agus éiríonn go maith leo i ngach teanga a tástáladh.', 'ka': 'ამ დოკუმენტი აღწერა BSC ჯგუფის გადაწყვეტილება WMT2021-ის მრავალენგური დამატებული რესურსის გადაწყვეტილებაში ინდო-ევროპოული ენების გაყოფილი რაოდენობაში. სისტემის მიზეზია Subtask 2: Wikipedia კულტურური მივიღება, რომელიც სარგებლად 4 პრომინური ენაში: კატალანი, თრალიანი, Occitan და პრომინური. შეტყობინებული სისტემა არის მრავალენგური ნახევარწმუნებული მაქინის გაგრძელების მოდელი. ეს დაბაზიან საუბრუნო ენის მოდელზე, რომელიც XLM-RoBERTa, რომელიც შემდეგ პარალელური მონაცემებით OPUS-დან მიიღებულია. სხვა სამუშაოების განმავლობაში, ჩვენ მხოლოდ XLM გამოყენებთ კოდირების инициаლიზაციისთვის და გამოსაკითხველად კოდირების инициаლიზაციას. შეტყობინებული წარმოდგენები ძალიან ძალიან და გამოყენება ყველა ტესტირებული ენებისთვის.', 'it': "Questo articolo descrive la partecipazione del team BSC al compito condiviso multilingue a basso contenuto di risorse per le lingue indoeuropee di WMT201. Il sistema mira a risolvere il Sottocompito 2: Wikipedia articoli del patrimonio culturale, che prevede la traduzione in quattro lingue romanze: catalano, italiano, occitano e rumeno. Il sistema presentato è un modello multilingue semi-supervisionato di traduzione automatica. Si basa su un modello linguistico pre-addestrato, vale a dire XLM-RoBERTa, che viene successivamente perfezionato con dati paralleli ottenuti principalmente da OPUS. A differenza di altri lavori, usiamo XLM solo per inizializzare l'encoder e inizializzare casualmente un decoder poco profondo. I risultati riportati sono robusti e funzionano bene per tutte le lingue testate.", 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή της ομάδας στην Κοινή Εργασία Πολυγλωσσικής Μεταφράσεως Χαμηλών Πόρων για Ινδοευρωπαϊκές Γλώσσες του WMT2028. Το σύστημα στοχεύει στην επίλυση του υποσταδίου 2: Άρθρα πολιτιστικής κληρονομιάς της Βικιπαίδειας, το οποίο περιλαμβάνει μετάφραση σε τέσσερις Ρομαντικές γλώσσες: Καταλανικά, Ιταλικά, Οκιτανικά και Ρουμανικά. Το υποβαλλόμενο σύστημα είναι ένα πολύγλωσσο ημιεποπτικό μοντέλο μηχανικής μετάφρασης. Βασίζεται σε ένα προ-εκπαιδευμένο γλωσσικό μοντέλο, δηλαδή το XLM-RoBERTa, το οποίο αργότερα βελτιώνεται με παράλληλα δεδομένα που λαμβάνονται κυρίως από το OPUS. Σε αντίθεση με άλλα έργα, χρησιμοποιούμε μόνο για να αρχικοποιήσουμε τον κωδικοποιητή και τυχαία να αρχικοποιήσουμε έναν ρηχό αποκωδικοποιητή. Τα αποτελέσματα που αναφέρθηκαν είναι ισχυρά και αποδίδουν καλά σε όλες τις δοκιμασμένες γλώσσες.', 'hu': 'Ez a tanulmány bemutatja a BSC csapat részvételét a WMT22021 többnyelvű alacsony erőforrású fordítás indoeurópai nyelvekre megosztott feladatában. A rendszer célja a Wikipédia kulturális örökségi cikkeinek megoldása, amely négy román nyelvű fordítást foglal magában: katalán, olasz, okszitán és román nyelven. A benyújtott rendszer egy többnyelvű, félig felügyelt gépi fordítási modell. Ez egy előre képzett nyelvi modellre épül, nevezetesen XLM-RoBERTa-ra, amelyet később párhuzamos adatokkal finomhangolnak, főleg OPUS-ból származó adatokkal. Más munkákkal ellentétben mi csak XLM-et használunk a kódoló inicializálására és véletlenszerűen inicializálására egy sekély dekódoló. A bejelentett eredmények robusztusak és jól teljesítenek minden tesztelt nyelven.', 'kk': 'Бұл қағаз WMT2021- нің бірнеше тілді төмен ресурстардың аудармасының BSC тобының қатынасын анықтайды. Жүйелік 2- тапсырманы шешу мақсаты: Википедия мәдениеттің мақсаттары, төрт романдық тілдерінде аударылған: Каталан, итальян, окцитан және румандық. Жіберілген жүйе - көп тілді жарты бақылау компьютерді аудару үлгісі. Бұл алдын- оқылған тіл үлгісіне негізделген, бұл XLM- RoBERTa, кейін OPUS- ден алған параллель деректермен жақсы түзетіледі. Басқа жұмыстар сияқты, тек кодерді инициализациялау үшін XLM қолданамыз және кездейсоқ қалқымалы декодерді инициализациялау үшін. Хабарлаған нәтижелер дұрыс және барлық тексерілген тілдер үшін жақсы істейді.', 'ms': 'Kertas ini menggambarkan ketertarikan pasukan BSC dalam Translation Low-Resource Multilingual WMT2021 untuk Tugas Berkongsi Bahasa Indo-Eropah. Sistem ini bermaksud untuk menyelesaikan Subtask 2: artikel wira budaya Wikipedia, yang melibatkan terjemahan dalam empat bahasa Roman: Catalan, Itali, Occitan dan Roman. Sistem yang dihantar adalah model terjemahan mesin setengah-mengawasi berbilang bahasa. Ia berdasarkan model bahasa pra-dilatih, iaitu XLM-RoBERTa, yang kemudian ditetapkan dengan data selari yang diperoleh kebanyakan dari OPUS. Tidak seperti kerja lain, kami hanya menggunakan XLM untuk memulakan pengekod dan secara rawak memulakan pengekod rendah. Hasil yang dilaporkan adalah kuat dan berjalan dengan baik untuk semua bahasa yang diuji.', 'mk': 'Овој весник го опишува учеството на тимот на БСЦ во мултијазичкиот превод со ниски ресурси на ВМТ2021 за инду-европските јазици споделени задачи. Системот има за цел решавање на подзадачата 2: статиите за културното наследство на Википедија, кои вклучуваат превод на четири романски јазици: каталонски, италијански, окцитански и романски. Пренесениот систем е мултијазичен полунадгледуван машински превод модел. Таа се базира на предобучениот јазички модел, имено XLM-RoBERTa, кој подоцна е финетизиран со паралелни податоци добиени претежно од ОПУС. За разлика од другите дела, користиме XLM само за иницијализација на кодерот и случајно иницијализација на плошкиот декодер. Изјавените резултати се силни и се одлични за сите тестирани јазици.', 'mt': 'Dan id-dokument jiddeskrivi l-parteċipazzjoni tat-tim tal-BSC fit-Traduzzjoni Multilingwi b’Riżorsi Bażi tad-WMT2021 għal Kompitu Konġunt tal-Lingwi Indoeuropeċi. Is-sistema għandha l-għan li ssolvi s-Subkompitu 2: l-artikoli tal-wirt kulturali tal-Wikipedia, li jinvolvu t-traduzzjoni f’erba’ lingwi Romani: il-Katalan, it-Taljan, l-Oċċitan u r-Rumen. Is-sistema sottomessa hija mudell multilingwi ta’ traduzzjoni tal-magna semisorveljata. Hija bbażata fuq mudell lingwistiku mħarreġ minn qabel, jiġifieri XLM-RoBERTa, li aktar tard jiġi rfinut b’dejta parallel a miksuba l-aktar minn OPUS. Għall-kuntrarju ta’ xogħlijiet oħra, a ħna nużaw XLM biss biex ninzjalizzaw il-kodifikatur u b’mod każwali ninzjalizzaw dekoder baxx. Ir-riżultati rrappurtati huma robusti u jwettqu riżultati tajbin għall-lingwi kollha ttestjati.', 'lt': 'Šiame dokumente aprašomas BSC grupės dalyvavimas WMT2021 daugiakalbiame mažų išteklių vertimui bendra užduotis, skirta europinėms kalboms. Sistemos tikslas – išspręsti 2 posėdį: Vikipedijos kultūros paveldo straipsnius, kurie apima vertimą keturiomis rumunų kalbomis: katalanų, italų, okucinų ir rumunų kalbomis. Pateikta sistema yra daugiakalbis pusprižiūrimas mašinų vertimo model is. Jis grindžiamas iš anksto parengtu kalbos modeliu, t. y. XLM-RoBERTa, kuris vėliau yra patobulintas lygiagrečiais duomenimis, gautais daugiausia iš OPUS. Priešingai nei kiti darbai, mes naudojame XLM tik koduotojui inicijuoti ir atsitiktinai inicijuoti paviršinį dekoderį. Pranešti rezultatai yra patikimi ir gerai veikia visomis išbandytomis kalbomis.', 'ml': 'ഈ പത്രത്തില്\u200d ബിഎസിസി ടീമിലെ പങ്കെടുപ്പ് വിശദീകരിക്കുന്നു എന്ന് വിവരിക്കുന്നത് ഇന്റോ-യൂറോപ്പിയഭാഷകള്\u200dക്ക് വേണ്ടി വിദ്യാഭ ഈ സിസ്റ്റത്തിന്റെ നിര്\u200dദ്ദേശം 2: വിക്കിപിഡിയ സംസ്കാരത്തിന്റെ അവകാശപ്രമാണങ്ങള്\u200d പരിഹരിക്കുവാന്\u200d ഉദ്ദേശിക്കുന്നു. അത് നാലു റോമ സമ്മതിച്ചിരിക്കുന്ന സിസ്റ്റം പല ഭാഷയിലുള്ള മെഷീന്\u200d നിരീക്ഷിക്കപ്പെട്ട മോഡലാണ്. ഇത് മുന്\u200dപരിശീലിക്കപ്പെട്ട ഭാഷ മോഡലിനെ അടിസ്ഥാനമാക്കിയിരിക്കുന്നു. എക്സ്\u200cഎലി- റോബെര്\u200dട്ടാ എന്നാണ്. പിന്നീട് ഒപ്യൂസില്\u200d  മറ്റുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200dക്ക് വേറെയൊന്നുമില്ല, എക്സ്\u200cഎല്\u200dഎം ഉപയോഗിക്കുന്നത് എക്സോഡെര്\u200d ആരംഭിക്കാന്\u200d മാത് റിപ്പോര്\u200dട്ട് ചെയ്തതിന്റെ ഫലം എല്ലാ പരീക്ഷിക്കപ്പെട്ട ഭാഷകള്\u200dക്കും നല്ലതാണ്.', 'no': 'Denne papiret beskriver deltakaren av BSC- gruppa i WMT2021 s in fleirspråk lav- ressursomsetjing for delt oppgåve i Indoeuropeiske språk. Systemet mål å løyse underoppgåva 2: kulturelle erfaringsartiklar i Wikipedia, som involverer omsetjing i fire romske språk: katalansk, italsk, oksitsk og rumensk. Den sendte systemet er ein fleirspråk semioversikt maskinsomsetjingsmodul. Det er basert på eit før- treng språk- modell, dvs. XLM- RoBERTa, som seinare er fine- tunert med parallelle data som mest får frå OPUS. I motsetjing av andre arbeidar, bruker vi berre XLM for å starta kodaren og tilfeldig starta ein slag dekoder. Rapporterte resultatene er sterkt og utfører godt for alle teste språk.', 'mn': 'Энэ цаас WMT2021-ийн олон хэл бага боловсролын хөрөнгө оруулалтыг Индо-Европын хэлний хуваалтын ажил дээр BSC багийн оролцоог тайлбарладаг. Энэ систем хоёр дахь дахь ажил шийдвэрлэхэд зориулагддаг: Википедийн соёлын орны баримтууд. Энэ нь 4 Ромын хэл дээр орчуулагддаг: Каталан, Италиан, Окситан, Роман. Холбоотой систем бол олон хэлний хагас удирдлагатай машин орчуулах загвар юм. Энэ нь өмнө сургалтын хэл загвар дээр суурилсан. Энэ бол XLM-RoBERTa, дараа нь OPUS-аас ихэнхдээ авсан параллел өгөгдлийн хувьд сайн тохируулагдсан. Өөр ажлын ялгаатай, бид зөвхөн XLM-г зөвхөн кодчуудыг эхлүүлж, санамсаргүй хэлбэрээр нэвтрүүлэхэд ашигладаг. Харин зарцуулсан үр дүн нь хүчтэй, шалгалтын бүх хэл дээр сайн ажилладаг.', 'pl': 'Niniejszy artykuł opisuje udział zespołu BSC w wielojęzycznym tłumaczeniu niskich zasobów dla języków indoeuropejskich WMT2028. System ma na celu rozwiązanie podzadania 2: artykuły z dziedzictwa kulturowego Wikipedii, które obejmuje tłumaczenie na cztery języki romańskie: kataloński, włoski, okcytański i rumuński. Przesłany system jest wielojęzycznym modelem półnadzorowanego tłumaczenia maszynowego. Opiera się on na wstępnie przeszkolonym modelu językowym, mianowicie XLM-RoBERTa, który jest później dostrojony o równoległe dane uzyskane głównie z OPUS. W przeciwieństwie do innych prac, używamy XLM tylko do inicjalizacji kodera i losowo inicjowania płytkiego dekodera. Raportowane wyniki są solidne i sprawdzają się dobrze we wszystkich testowanych językach.', 'ro': 'Această lucrare descrie participarea echipei BSC la activitatea de traducere multilingvă cu resurse reduse pentru limbi indo-europene partajată WMT201. Sistemul își propune să rezolve Subsarcina 2: articole din patrimoniul cultural Wikipedia, care implică traducerea în patru limbi romanice: catalană, italiană, occitană și română. Sistemul transmis este un model multilingv semi-supravegheat de traducere automată. Acesta se bazează pe un model lingvistic pre-instruit, și anume XLM-RoBERTa, care este ulterior reglat fin cu date paralele obținute în principal de la OPUS. Spre deosebire de alte lucrări, folosim XLM doar pentru a inițializa codificatorul și inițializa aleatoriu un decoder superficial. Rezultatele raportate sunt robuste și funcționează bine pentru toate limbile testate.', 'sr': 'Ovaj papir opisuje sudjelovanje BSC tima u multijezičkom prevodu niskih resursa WMT2021-a za delovani zadatak Indoevropskih jezika. Sistem se cilja rešiti podzadatak 2: članak kulturnog nasledstva Wikipedije, koji uključuje prevod na četiri rumunske jezika: katalanski, italijanski, okcitanski i rumunski. Predloženi sistem je multijezički polu-nadzorni model prevoda mašine. On je zasnovan na predobučenom jezičkom modelu, a to je XLM-RoBERTa, koja je kasnije finalno prilagođena paralelnim podacima koji su dobili uglavnom od OPUS-a. Za razliku od drugih radova, koristimo XLM samo da bi inicijalizirali koder i slučajno inicijalizirali plitki dekoder. Izjavljeni rezultati su roboti i dobro održavaju za sve ispitivane jezike.', 'si': 'මේ පත්තුව තියෙනවා BSC කණ්ඩායම WMT2021 ගේ බොහොම භාෂාවක අඩු භාෂාවක් භාෂාවක් සමාගත වැඩකට සඳහා බොහොම භාෂාවක් අවව විකිපිඩියා සංස්කෘතික භාවිතාවයේ පද්ධතිය අදහස් කරනවා: කැටලාන්, ඉතාලියාන්, ඔක්සිතාන් සහ රෝමානියාන් භාෂාවයේ  පිළිබඳු පද්ධතිය තමයි බොහොම භාෂාවක් අධ්\u200dයභාෂාවක් පද්ධතිය පද්ධතිය පද්ධතිය. ඒක ප්\u200dරධානය කරපු භාෂාවක් මොඩේල් එකේ අධාරිත වෙනවා, කියන්නේ XLM-RoBERTa, ඒක පස්සේ ප්\u200dරධානය සමාන්\u200dය දත්තා සමඟ සඳහා ප අනිත් වැඩ වගේම, අපි XLM භාවිතා කරනවා කෝඩාර් පටන් ගන්න සහ ක්\u200dරමයික විදිහට ප්\u200dරමාණය කරන්න. වාර්තා කරලා තියෙන ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර', 'sv': 'Denna uppsats beskriver BSC-teamets deltagande i WMT201s flerspråkig lågresursöversättning för indoeuropeiska språk delad uppgift. Systemet syftar till att lösa Underuppgift 2: Wikipedia kulturarvsartiklar, som innebär översättning till fyra romanska språk: katalanska, italienska, occitanska och rumänska. Det inlämnade systemet är en flerspråkig halvövervakad maskinöversättningsmodell. Den bygger på en färdigutbildad språkmodell, nämligen XLM-RoBERTa, som senare finjusteras med parallella data som främst erhållits från OPUS. Till skillnad från andra verk använder vi bara XLM för att initiera kodaren och slumpmässigt initiera en ytlig avkodare. De rapporterade resultaten är robusta och presterar bra för alla testade språk.', 'so': "This paper describes the participation of the BSC team in the WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task.  Isticmaalku wuxuu ku qoran yahay xafiiska hoose 2: Wikipedia warqadaha dhaxalka dhaqamada, kaas oo ku saabsan turjumidda afarta luqadood oo Romaniyan ah: Katalan, Talyaani, Occitan iyo Romaniyan. Isticmaalka la soo dhiibay waa model turjumista machine oo luuqado kala duduwan ah. Waxaa lagu saleyn karaa tusaale ahaan afka hore oo lagu tababaray, XLM-RoBERTa, taas oo ugu dambeysan si fiican looga helo macluumaad lambarka ah oo ka soo baxay OPUS. Shaqooyin kale oo aan kala duwan, waxaynu XLM u isticmaalnaa si aan u bilowno codsiga oo aan si fudud ugu billaabno qodolka sahlan. Midhaha la soo sheegay waa in la dhacaa oo si wanaagsan loogu sameeyaa luuqadaha la tijaabiyey oo dhan.", 'ta': 'இந்த தாள் பிஎஸ்சி குழு பகிர்ந்த பணியில் பிஎஸ்சி குழுவில் பங்கிடுவதை விளக்குகிறது WMT2021 யின் பல மொழிகள் குறைந்த மூலம் மொழிமாற துணை பணி 2: விக்கிபிடியாவின் கலாச்சார உரையாடல் கட்டுரைகள், அது நான்கு ரோமென்ஸ் மொழிகளில் மொழிபெயர்ப்பை சேர்க்கிறது. காட்டாலான்,  கொடுக்கப்பட்ட முறைமை பல மொழிக்கான அரை- கண்காணிக்கப்பட்ட இயந்திர மொழிமாற்றி மாதிரி இது முன்பயிற்சி மொழி மாதிரி அடிப்படையில் உள்ளது, அது எக்ஸ்எஸ் இருந்து பெரும்பாலான இணைப்பு தரவுடன் நன்றாக முடிக்கப்பட்டுள்ளது. மற்ற வேலைகள் மாறுபட்டால், நாம் குறியீட்டினை துவக்க XLM மட்டும் பயன்படுத்தி குறியீட்டினை துவக்க மற்றும் குறிய @ info: status', 'ur': 'This paper describes the participation of the BSC team in the WMT2021 multilingual Low-Resource Translation for Indo-European languages Shared Task. اس سیسٹم کا ارادہ ہے کہ Subtask 2 کو حل کریں: ویکیپیڈیا کی فرهنگی وارث مقالہ، جو چار رومانس زبانوں میں ترجمہ کرتی ہے: کاتالان, ایتالیایی, اکسیتان اور رومانی. پیغام دینے والی سیسٹم ایک بہت سی زبان نصف-نظارت ماشین ترجمہ موڈل ہے. یہ ایک پیش آموزش کی زبان موڈل پر بنیاد ہے، یعنی XLM-RoBERTa، جو اس کے بعد بہت سے OPUS سے ملی ہوئی parallel data کے ساتھ ٹھیک ٹھیک ہے. اور دوسرے کاموں کے مطابق ہم صرف XLM کو استعمال کرتے ہیں کہ اس کا کوڈر آغاز کریں اور ایک گھٹی ڈیکڈر آغاز کریں۔ گزارش کی نتیجے ثابت ہیں اور تمام آزمائش زبانوں کے لئے اچھی طرح عمل کرتے ہیں.', 'uz': "Bu karatasi BSC guruhi WMT2021'ning bir necha tillar tarjima qilishini anglatadi. Name @ info Bu tildan oldin taʼminlovchi modeli, XLM-RoBERTAning asosida, keyin OPUS tomonidan olingan parallel maʼlumot bilan yaxshi bog'langan. @ info @ info: status", 'vi': 'Bài viết này mô tả s ự tham gia của đội BSC... trong tổ chức "Việc dịch đa ngôn ngữ thấp" của WM221 cho công việc chia sẻ ngôn ngữ Đông Âu. Hệ thống này muốn giải quyết loại trừ 2: Wikipedia cho truyền thuyết vào bốn ngôn ngữ Romance: Catalan, Ý, Occitan và Rumani. Hệ thống được gửi đến là một mô hình dịch cỗ máy có chế độ ngắn. Nó dựa trên một mô hình ngôn ngữ được đào tạo trước, là XMM-Roerbta, sau đó được hoàn thiện với các dữ liệu song song được thu thập chủ yếu từ OPU. Không như các tác phẩm khác, chúng tôi chỉ dùng XMM để khởi tạo mã hóa và ngẫu nhiên khởi động bộ giải ăn nông. Kết quả đã báo cáo đầy đủ và hoạt động tốt cho mọi ngôn ngữ được thử nghiệm.', 'hr': 'Ovaj papir opisuje učešće tima BSC-a u multijezičkom prevodu manjih resursa WMT2021-a za zajednički zadatak Indoeuropskih jezika. Sistem se cilja riješiti podzadatak 2: članak kulturnog nasledstva Wikipedije, koji uključuje prevod na četiri rumunske jezika: katalanski, italijanski, okcitanski i rumunski. Predloženi sustav je multijezički polu-nadzorni model prevoda stroja. Na temelju je predobučenog jezičkog model a, a to je XLM-RoBERTa, koja je kasnije finalno prilagođena paralelnim podacima koji su dobili uglavnom od OPUS-a. Za razliku od drugih djela, koristimo XLM samo da bi pokrenuli koder i slučajno počeli plitki dekoder. Prijavljeni rezultati su jak i dobro održavaju za sve ispitivane jezike.', 'bg': 'Настоящата статия описва участието на екипа на БСК в задачата за споделяне на многоезичен превод с ниски ресурси за индоевропейски езици. Системата има за цел да реши подзадача 2: Статии за културното наследство на Уикипедия, която включва превод на четири романски езика: каталонски, италиански, окситански и румънски. Предоставената система е многоезичен полунадзорен модел на машинен превод. Тя се основава на предварително обучен езиков модел, а именно XLM-RoBERTa, който по-късно е фино настроен с паралелни данни, получени предимно от OPUS. За разлика от други произведения, ние използваме само за инициализиране на кодера и случайно инициализиране на плитък декодер. Докладваните резултати са надеждни и работят добре за всички тествани езици.', 'nl': 'Dit artikel beschrijft de deelname van het BSC-team aan de meertalige low-resource vertaling voor Indo-Europese talen gedeelde taak van de WMT2028. Het systeem heeft tot doel de Subtaak 2: Wikipedia cultureel erfgoed artikelen op te lossen, die vertaald worden in vier Romaanse talen: Catalaans, Italiaans, Occitaans en Roemeens. Het ingediende systeem is een meertalig semi-supervised machine translation model. Het is gebaseerd op een vooraf getraind taalmodel, namelijk XLM-RoBERTa, dat later wordt verfijnd met parallelle gegevens verkregen voornamelijk uit OPUS. In tegenstelling tot andere werken gebruiken we alleen XLM om de encoder te initialiseren en willekeurig een ondiepe decoder te initialiseren. De gerapporteerde resultaten zijn robuust en presteren goed voor alle geteste talen.', 'de': 'Dieser Beitrag beschreibt die Beteiligung des BSC-Teams an der Mehrsprachigen Low-Resource Translation for Indo-European Languages Shared Task des WMT2028. Das System zielt darauf ab, die Unteraufgabe 2: Wikipedia Kulturerbeartikel zu lösen, die Übersetzungen in vier romanischen Sprachen beinhaltet: Katalanisch, Italienisch, Okzitanisch und Rumänisch. Das eingereichte System ist ein mehrsprachiges halbüberwachtes maschinelles Übersetzungsmodell. Es basiert auf einem vortrainierten Sprachmodell, nämlich XLM-RoBERTa, das später mit parallelen Daten aus OPUS verfeinert wird. Im Gegensatz zu anderen Werken verwenden wir nur XLM, um den Encoder zu initialisieren und zufällig einen flachen Decoder zu initialisieren. Die gemeldeten Ergebnisse sind robust und funktionieren für alle getesteten Sprachen gut.', 'id': 'Kertas ini menggambarkan pesertaan tim BSC dalam Translation Multilingual Low-Resource WMT2021 untuk Tugas Berkongsi Bahasa Indo-Eropa. The system aims to solve the Subtask 2: Wikipedia cultural heritage articles, which involves translation in four Romance languages: Catalan, Italian, Occitan and Romanian.  Sistem yang dikirim adalah model terjemahan mesin semi-terpantau berbagai bahasa. Ini berdasarkan model bahasa pra-dilatih, yaitu XLM-RoBERTa, yang kemudian disesuaikan dengan data paralel yang diperoleh kebanyakan dari OPUS. Tidak seperti pekerjaan lain, kita hanya menggunakan XLM untuk menginisialisasi pengekode dan secara acak menginisialisasi pengekode rendah. Hasil yang dilaporkan kuat dan berjalan dengan baik untuk semua bahasa yang diuji.', 'da': 'Dette papir beskriver BSC-holdets deltagelse i WMT201s Flersprogede Low-Resource Translation for Indoeuropæiske Languages Shared Task. Systemet har til formål at løse Underopgave 2: Wikipedia kulturarvsartikler, som involverer oversættelse til fire romanske sprog: catalansk, italiensk, occitansk og rumænsk. Det indsendte system er en flersproget halvovervåget maskinoversættelsesmodel. Den er baseret på en prætrænet sprogmodel, nemlig XLM-RoBERTa, der senere finjusteres med parallelle data, primært fra OPUS. I modsætning til andre værker bruger vi kun XLM til at initialisere encoderen og tilfældigt initialisere en lavvandet dekoder. De rapporterede resultater er robuste og fungerer godt for alle testede sprog.', 'sw': 'Gazeti hili linaelezea ushiriki wa timu ya BSC katika Tafsiri ya Rasilimali ya Kichini ya lugha za WMT2021 kwa lugha za Kihindi-Ulaya ilishiriki kazi. Mfumo unalenga kutatua makala za urithi wa utamaduni wa Wikipedia, ambazo zinahusisha tafsiri katika lugha nne za KiRomania: Kikatala, Kiitalia, Occitan na Romania. Mfumo uliotolewa ni modeli ya kutafsiri kwa lugha mbalimbali. Inazingatia mtindo wa lugha iliyoendelea kabla, kwa jina la XLM-RoBERTa, ambalo baadae huwekwa vizuri na takwimu zilizofanana zaidi kutoka OPUS. Tofauti na kazi nyingine, tunatumia XLM kuanzisha kodi na kuanzisha kodi kubwa. Matokeo yaliyoripotiwa ni mabomu na yanafanya vizuri kwa lugha zote zinazojaribiwa.', 'ko': '본고는 밸런스 채점 카드 팀이 WMT 2021의 인구어 공유 임무에 참여하는 다국어 저자원 번역을 묘사한다.이 시스템은 서브퀘스트 2: 위키백과 문화유산 문장을 해결하기 위해 네 가지 낭만적인 언어의 번역인 카탈로니아어, 이탈리아어, 오시탄어와 루마니아어를 포함한다.제출한 시스템은 다국어 반감독기계 번역 모델이다.이것은 사전에 훈련된 언어 모델인 XLM RoBERTA를 바탕으로 이 모델은 나중에 주로 OPUS에서 얻은 병렬 데이터를 통해 미세하게 조정되었다.다른 작업과 달리, 우리는 XLM 초기화 인코더만 사용하고, 무작위로 얕은 디코더를 초기화합니다.보고서의 결과는 믿을 만하며 모든 테스트 언어에 대해 양호하게 나타났다.', 'tr': "Bu kagyz WMT2021'iň Multilingual Low-Resource Çevirmesi Indo-Ýewropa Diller Paýlaşyş Görevleri üçin BSC toparyň chikanchaslygyny tassyklaýar. Sistem Subtask 2-ini çözmek amaçly: Wikipediýa kültürel miras makalaryny, 4-nji rumatlar dilinde terjime edenler: Katalan, Italiýa, Okitýan we Rumynça. Metini gönderilen sistem bir çoxly dilli ýarym-gözleýän maşynyň terjime nusgasydir. Bu ýer öňünden eğlenen dil nusgasyna daýanýar, ady XLM-RoBERTa, iň soňra OPUS-dan alınan parallel maglumatlar bilen düzeldiler. Başga işleriň ýaly, diňe ködlemeni başlatmak üçin XLM ullanys we puç bir ködlemeni başlatmak üçin. Bildirilen netijeler güýçli we ähli synanyşly diller üçin gowy dowam edýärler.", 'af': "Hierdie papier beskrywe die deelnadering van die Bcc team in die WMT2021 se Multilingual Lae- Hulpbron Vertaling vir Indo- Europeese Taal Deel Taak. Name Die stelsel bepaal om die Subtaak 2 te los: Wikipedia kulturele erfdeel artikels, wat oorsetting in vier Romiese tale: Katalan, Italiaanse, Okcitaanse en Romaniese. Die voorgestuurde stelsel is 'n multilinguele semi- superviseer masjien vertaling model. Dit is gebaseer op 'n voor-opgelei taal model, naamlik XLM- RoBERTa, wat later fin- tuned is met parallele data wat meeste van OPUS ontvang word. Ongelyks van ander werke, gebruik ons slegs XLM om die enkoder te inisialiseer en willekeurig 'n skaal dekoder te inisialiseer. Die verkondige resultate is sterk en goed uitvoer vir alle toets tale.", 'sq': 'Ky dokument përshkruan pjesëmarrjen e ekipit të BSC në Translacionin Shumë-gjuhësor të burimeve të ulta të WMT2021 për Detyrën e Përbashkët të Gjuhave Indo-Evropiane. Sistemi synon të zgjidhë nëndetyrën 2: artikujt e trashëgimisë kulturore të Wikipedias, që përfshin përkthimin në katër gjuhë rumune: katalane, italiane, okcitane dhe rumune. Sistemi i paraqitur është një model shumëgjuhës gjysmë-mbikqyrur i përkthimit të makinave. Ajo bazohet në një model gjuhësh të stërvitur përpara, veçanërisht XLM-RoBERTa, i cili më vonë është i përshtatur me të dhëna paralele të fituara kryesisht nga OPUS. Ndryshe nga punët e tjera, ne përdorim XLM vetëm për të inicializuar koduesin dhe rastësisht për të inicializuar një dekoder të sipërme. Rezultatet e raportuara janë të forta dhe funksionojnë mirë për të gjitha gjuhët e testuara.', 'am': 'ይህ ገጽ የBSC ቡድን በWMT2021 Multilingual-Resource Translation for Indo-European Languages Shared Task ውስጥ ተግባር እንዲሆን ይናገራል፡፡ ጥያቄ 2: Wikipedia የባሕላዊ ርስት ጽሑፎችን ለመፍታት ነው፡፡ ይህ በሮማኖስ ቋንቋዎች ላይ ትርጉም ነው፡፡ የተገኘው ስርዓት የቋንቋ ቋንቋዎች በsemi-supervised machine translation model ነው። በኋላው ከOPUS የተገኘው ተቃውሞ የቋንቋ ምሳሌ የተመሳሳይ ነው፡፡ በሌላ ሥራ ላይ የXLM ጽሑፉን ለመጀመሪያ እና በጭብጥ ቀለም መጀመሪያ እናደርጋለን፡፡ የተዘጋጀው ውጤቶች ለሞከሩ ቋንቋዎች ሁሉ ጥሩ ናቸው፡፡', 'fa': 'این کاغذ مشارکت تیم BSC را توصیف می\u200cکند در ترجمه\u200cهای زیادی منابع کم زبان WMT2021 برای کار مشترک زبان\u200cهای Indo-European. این سیستم هدف است که مقاله میراث فرهنگی ویکیپدیا را حل کند، که در چهار زبان رومانی شامل ترجمه است: کاتالان، ایتالیایی، اکسیتان و رومانی. سیستم تحویل داده شده یک مدل ترجمه ماشین با نیمه مراقبت زبانی است. آن بر اساس یک مدل زبان پیش آموزش شده است، به عنوان XLM-RoBERTa، که بعداً با داده های پارالی که بیشتر از OPUS دریافت شده است، درست شده است. برخلاف کارهای دیگر، ما فقط از XLM استفاده می کنیم تا آغاز کردن کوډر و تصادفی یک dekoder کوچک کوچک کنیم. نتایج گزارش داده شدن قوی هستند و برای همه زبانهای آزمایش خوب انجام می دهند.', 'az': "Bu kańüńĪt WMT2021'in Multilingual Low-Resource Translation for Indo-European Languages Shared Task'da BSC team's participation in the WMT2021's Multilingual Low-Resource Translation for Indo-European Languages. Sistem 2. Subtask'i √ß…ôkm…ôk ist…ôyir: Wikipedia m…ôd…ôniyy…ôt mirasńĪ madd…ôl…ôrini, d√∂rt Roma dilind…ô √ßeviril…ôn: Katalan, ńįtalyan, Oksitan v…ô Rumun dilind…ô. ńįstifad…ô edil…ôn sistem √ßoxlu dil yarńĪ-g√∂zl…ôyirli maŇüńĪn √ßeviri modeli idi. Bu, …ôvv…ôlc…ô t…ôhsil edilmiŇü dil modelinin d…ôyiŇüdirilm…ôsi kimi XLM-RoBERTa, daha sonra OPUS-d…ôn alńĪnan paralel m…ôlumatlarla m√ľ…ôyy…ôn edilmiŇüdir. BaŇüqa iŇül…ôr…ô b…ônz…ôr, kodlayńĪcńĪnńĪ baŇülatmaq √ľ√ß√ľn XLM istifad…ô edirik v…ô b√∂y√ľk kodlayńĪcńĪ baŇülatmaq √ľ√ß√ľn hazńĪrlanmńĪŇüdńĪr. ńįstifad…ô edilmiŇü sonu√ßlar g√ľcl√ľd√ľr v…ô h…ôr t…ôhsil edilmiŇü dill…ôr √ľ√ß√ľn yaxŇüńĪ iŇül…ôr edirl…ôr.", 'hy': 'Այս աշխատանքը նկարագրում է ԲՍՍ թիմի մասնակցությունը Հնդեվրոպական լեզուների կիսված հանձնարարությունների բազմալեզու ցածր ռեսուրսների թարգմանությունում: Համակարգը նպատակում է լուծել 2. ենթախնդիրը՝ Վիքիփեդիայի մշակութային ժառանգության հոդվածները, որոնք ներառում են թարգմանություն չորս ռոմանական լեզուներով՝ կատալան, իտալան, օքսիտական և ռոմանական: Հաշվի առկա համակարգը բազլեզու կիսավերահսկվող մեքենայի թարգմանման մոդել է: Այն հիմնված է նախապատրաստված լեզվի մոդելի վրա, հատկապես XLM-ROBERta-ի վրա, որը հետագայում կազմակերպված է զուգահեռ տվյալների հետ, որոնք ստացվում են հիմնականում ՕՊՍ-ից: Unlike other works, we only use XLM to initialize the encoder and randomly initialize a shallow decoder.  Աշխատած արդյունքները կայուն են և լավ են աշխատում բոլոր փորձարկված լեզուների համար:', 'bn': 'এই পত্রিকা বিএসসি দলের অংশগ্রহণের ব্যাখ্যা করেছে যা উইএমটি২০২১ এর বহুভাষায় অনুবাদ করা হয়েছে ইন্ডো-ইউরোপীয় ভাষাগুলোর জন্য ভাষাগুলো  The system aims to solve the Subtask 2: Wikipedia cultural heritage articles, which involves translation in four Romance languages: Catalan, Italian, Occitan and Romanian.  জবাব দিয়েছে সিস্টেম হচ্ছে বহুভাষায় সেমি পর্যবেক্ষণ করা মেশিন অনুবাদ মডেল। এটি পূর্ব প্রশিক্ষিত ভাষার মডেলের ভিত্তিতে ভিত্তিক, যার মাধ্যমে এক্সএলM-রোবের্তা, যা পরে অপিএস থেকে বেশীরভাগ তথ্য পাওয়া যায়,  অন্যান্য কাজের ভিন্ন ভিন্ন ভিন্ন ভিন্ন, আমরা শুধুমাত্র এক্সএলএম ব্যবহার করি এনকোডার শুরু করার জন্য এবং ক্ষতিগতভা সংবাদ প্রদান করা হয়েছে এই ফলাফল রোবট করা হয়েছে এবং সকল পরীক্ষা ভাষার জন্য ভালো কাজ করা হয়েছে।', 'bs': 'Ovaj papir opisuje sudjelovanje tima BSC-a u multijezičkom prevodu niskog resursa WMT2021-a za zajednički zadatak Indoevropskih jezika. Sistem se cilja rešiti podzadatak 2: članak kulturnog nasledstva Wikipedije, koji uključuje prevod na četiri rumunske jezika: katalanski, italijanski, okcitanski i rumunski. Predloženi sistem je multijezički polu-nadzorni model prevoda mašine. On se temelji na predobučenom jezičkom modelu, a to je XLM-RoBERTa, koja je kasnije finalno prilagođena paralelnim podacima koje su dobile uglavnom od OPUS-a. Za razliku od drugih radova, koristimo XLM samo da bi pokrenuli koder i slučajno počeli plitki dekoder. Prijavljeni rezultati su jak i dobro održavaju za sve ispitivane jezike.', 'cs': 'Tento článek popisuje účast týmu BSC na vícejazyčném překladu nízkých zdrojů WMT2028 sdíleném úkolu pro indoevropské jazyky. Systém si klade za cíl řešit články o kulturním dědictví Wikipedie, které zahrnují překlad do čtyř románských jazyků: katalánština, italština, okcitánština a rumunština. Předložený systém je vícejazyčný model polořízeného strojového překladu. Je založena na předškoleném jazykovém modelu, konkrétně XLM-RoBERTa, který je později doladěn paralelními daty získanými převážně z OPUS. Na rozdíl od jiných děl používáme XLM pouze k inicializaci kodéru a náhodně inicializaci mělkého dekodéru. Nahlášené výsledky jsou robustní a výkonné pro všechny testované jazyky.', 'et': 'Käesolevas dokumendis kirjeldatakse BSC meeskonna osalemist WMT22021 mitmekeelse madala ressursiga tõlke ülesandes Indo-Euroopa keelte jaoks. Süsteemi eesmärk on lahendada alamülesanne 2: Vikipeedia kultuuripärandi artiklid, mis hõlmab tõlkimist nelja romaani keelde: katalaani, itaalia, oktsitaani ja rumeenia keelde. Esitatud süsteem on mitmekeelne pooljärelevalvega masintõlke mudel. See põhineb eelnevalt koolitatud keelemudelil XLM-RoBERTa, mida hiljem täpsustatakse paralleelsete andmetega, mis saadakse peamiselt OPUSest. Erinevalt teistest töödest kasutame me XLM-i ainult kodeerija initsialiseerimiseks ja juhuslikult madala dekooderi initsialiseerimiseks. Esitatud tulemused on tugevad ja toimivad hästi kõigis testitud keeltes.', 'ca': "Aquest article descriu la participació de l'equip de BSC en la Translació Multilingüe de Baix Recursos de la WMT2021 per a la tasca compartida de llengües indoeuropees. El sistema mira a resoldre la Subtasca 2: Articles del patrimoni cultural de Wikipedia, que implica traducció en quatre llengües romanes: català, italià, occitan i rumà. El sistema enviat és un model multilingüe de traducció de màquines semisupervisada. Està basat en un model de llenguatge pré-entrenat, a saber XLM-RoBERTa, que després està perfeccionat amb dades paralleles obtenides principalment de l'OPUS. Unlike other works, we only use XLM to initialize the encoder and randomly initialize a shallow decoder.  Els resultats reportats són robustos i funcionen bé per a totes les llengües testades.", 'fi': 'Tässä artikkelissa kuvataan BSC-ryhmän osallistumista WMT22021:n monikieliseen vähävaraiseen kääntämiseen indoeurooppalaisille kielille jaettuun tehtävään. Järjestelmällä pyritään ratkaisemaan alatehtävä 2: Wikipedian kulttuuriperintöartikkelit, joka sisältää kääntämisen neljälle romaaniselle kielelle: katalaani, italia, oksitaani ja romania. Toimitettu järjestelmä on monikielinen puolivalvottu konekäännösmalli. Se perustuu esikoulutettuun kielimalliin, XLM-RoBERTa, jota myöhemmin hiotaan rinnakkaisilla tiedoilla, jotka saadaan pääosin OPUS:sta. Toisin kuin muut teokset, käytämme XLM-koodia vain kooderin alustamiseen ja pinnallisen dekooderin alustamiseen satunnaisesti. Raportoidut tulokset ovat vankkoja ja toimivat hyvin kaikilla testatuilla kielillä.', 'sk': 'Ta prispevek opisuje sodelovanje ekipe BSC pri večjezičnem prevajanju z nizkimi viri za indoevropske jezike WMT22021. Cilj sistema je rešiti podnalogo 2: Wikipedijski članki o kulturni dediščini, ki vključuje prevajanje v štiri romanske jezike: katalonščino, italijanščino, ocitanščino in romunščino. Predloženi sistem je večjezični polnadzorovani model strojnega prevajanja. Temelji na vnaprej usposobljenem jezikovnem modelu, in sicer XLM-RoBERTa, ki je kasneje natančno nastavljen z vzporednimi podatki, pridobljenimi večinoma iz OPUS. Za razliko od drugih del uporabljamo XLM samo za inicializacijo kodirja in naključno inicializacijo plitkega dekoderja. Sporočeni rezultati so robustni in dobro delujejo za vse preizkušene jezike.', 'ha': "Wannan karatun describes the role of the BSC team in the WMT2021's Low-Resource Translate for Indo-Eura languages Shared Tax. @ item license (short name) @ info: whatsthis An daidaita shi a kan wani misalin harshen mai zaman-tunkuɗe, kamar XLM-RoBERTa, wanda aka bambata mai kyau da data masu daidaita da aka motsa mafi yawa daga OPS. Yana daidaita wani aikin daban, za'a yi amfani da XLM kawai zuwa fara koda kuma a fara wani kodi mai zartar da kwamfyuta. Ana jarraba fassaran a goge kuma a yi aiki mai kyau ga dukkan harshen wanda aka jarraba.", 'he': 'העיתון הזה מתאר את השתתפות של צוות BSC בתרגום משאבים נמוכים רבים של WMT2021 למשימה משותפת לשונות אינדו-אירופאיות. המערכת מתכוונת לפתור את התפקיד השני: מאמרים של מורשת תרבותית ויקיפדיה, שמעסקים בתרגום בארבעה שפות רומניות: קטלאנית, איטלקית, אוקיטנית ורומנית. המערכת המועברת היא דוגמא מכונת תרגום חצי-שפותית. הוא מבוסס על מודל שפה מאומן מראש, כלומר XLM-RoBERTa, שמאוחר יותר מתאים עם נתונים מקבילים שנקבלים בעיקר מאופוס. בניגוד לעבודות אחרות, אנחנו משתמשים רק XLM כדי להתחיל את הקודד ולהתחיל אקראי את הקודד הקטן. התוצאות המדווחות חזקות והופכות היטב לכל השפות הנבחנות.', 'jv': 'Perintah iki oleh nggambar kelompok nggawe barang GSC nang nggawe multilengkang low-Resolusi kanggo Terjamahan kanggo Mbak-ingkang Singa-Yusuf. Sistem punika kanggo ngilangno Subtask 2 Sistem sing ngewehhit sistem dadi model sing akeh banter-sistem sing titimpen banget. Rasané digawe ning manut sing perusahaan bangsa, nambah XLM-RBERT, iki dadi kapan-kapan sedhaya punika dipepol karo data yang dipepol sing sumusukda OPUSUT. Sampeyan nganggo cara sing wis ranggo, kita gambar XLM kanggo inimalis koder Pametuné awak dhéwé luwih-luwih lan akeh njaluk kanggo awak dhéwé ujian sing bisa ujian.', 'bo': "ཤོག་བྱང་འདིས་འདིའི་ནང་དུ་WMT2021's Multilingual Low-Resource Translation for Indo-European Languages Shared Task(Task)་གི་བྱ་ཚུལ་གྱི་རྩོམ་པ་གཙོ་བོ་དང་འདྲ་བོ་ཡོད་པ མ་ལག་གི་དམིགས་ཡུལ་ནི་རྒྱབ་ལྗོངས་ཀྱི་ནང་དོན་ཡུལ་གཟུགས་འདོར་ཐབས་བྱེད་དགོས། ཝི་ཀེ་པི་ཡིས་ལམ་གྱི་ནང་དོན་ཡུལ་གྱི་ཡིག་ཆ་བཞིན་ནང་དུ་ བྱིས་འཇུག་པའི་མ་ལག་ནི་སྐད་རིགས་ལ་བསྡུར་བའི་ལག་ཆ་ལུགས་ཀྱི་དཔེ་དབྱིབས་རིགས་ཅིག་རེད། It is based on a pre-trained language model, namely XLM-RoBERTa, that is later fine-tuned with parallel data obtained mostly from OPUS. ལས་ཀ་གཞན་དང་མི་འདྲ་བ། ང་ཚོས་XLM་སྤྱད་ནས་ཨིན་ཀོ་ཌའི་འགོ་འཛུགས་བྱེད་པ་དང་མཐའ་རྩིས་འཁོར་ཞིག་འགོ་འཛུགས་པ རྗེས་བརྗོད་ཟིན་པའི་གྲུབ་འབྲས་མངོན་གསལ་པོ་ཞིག་ཡིན་པས་བརྟག་ཞིབ་བྱས་པ་ཡིན།"}
{'en': 'Back-translation for Large-Scale Multilingual Machine Translation', 'es': 'Traducción inversa para traducción automática multilingüe a gran escala', 'pt': 'Retrotradução para tradução automática multilíngue em grande escala', 'ar': 'الترجمة الخلفية للترجمة الآلية متعددة اللغات على نطاق واسع', 'fr': 'Rétro-traduction pour la traduction automatique multilingue à grande échelle', 'ja': '大規模多言語機械翻訳のためのバック翻訳', 'zh': '大言机器翻译反译', 'hi': 'बड़े पैमाने पर बहुभाषी मशीन अनुवाद के लिए बैक-अनुवाद', 'ru': 'Обратный перевод для крупномасштабного многоязычного машинного перевода', 'ga': "Cúl-aistriúchán d'Aistriúchán Meaisín Ilteangach ar Mhórscála", 'el': 'Πίσω-μετάφραση για πολυγλωσσική μηχανική μετάφραση μεγάλης κλίμακας', 'hu': 'Visszafordítás nagyméretű többnyelvű gépi fordításhoz', 'it': 'Back-translation per la traduzione automatica multilingue su larga scala', 'mk': 'Name', 'lt': 'Didelio masto daugiakalbio mašinų vertimo grįžtamasis vertimas', 'ka': 'დიდი- სკვილური მრავალური მაქინის განსაგულისხმებისთვის წინასწორება', 'ms': 'Terjemahan-belakang untuk Terjemahan Mesin Berbahasa Besar', 'ml': 'വലിയ- വലുതാക്കുന്നതിനുള്ള ബാക്ക്- പരിഭാഷ', 'kk': 'Үлкен- масштабтағы көп тілді машинаны аудару үшін қайта аудару', 'mt': 'Traduzzjoni lura għat-Traduzzjoni ta’ Magni Multilingwi fuq Skala kbira', 'no': 'Tilbakeomsetjing for stor skalering av fleirspråk maskinsomsetjing', 'ro': 'Traducere înapoi pentru traducerea automată multilingvă la scară largă', 'pl': 'Tłumaczenie wsteczne dla wielojęzycznego tłumaczenia maszynowego na dużą skalę', 'mn': 'Ихэнх хэлний машины хөрөнгө оруулалтын хувьд', 'si': 'ලොකු ස්කේල් ගොඩක් භාෂාවක් මැෂින් භාෂාව සඳහා පස්සේ අවවාදය', 'so': 'Translation', 'sv': 'Tillbaka-översättning för storskalig flerspråkig maskinöversättning', 'ta': 'பெரிய அளவு- அளவுக்கான பின்- மொழி மொழிபெயர்ப்புக்கான மொழிபெயர்ப்பு', 'sr': 'Povratni prevod za veliku skalu multijezičkog prevoda mašine', 'ur': 'بڑے-اسکیل Multilingual Machine Translation کے لئے پیچھے ترجمہ', 'vi': 'Dịch lại cho máy đa ngôn ngữ diện', 'uz': 'Katta- oÊṠlchami uchun tarjima- tarjima', 'bg': 'Обратен превод за мащабен многоезичен машинен превод', 'nl': 'Terug-vertaling voor grootschalige meertalige machinevertaling', 'de': 'Rückübersetzung für mehrsprachige maschinelle Übersetzung im großen Maßstab', 'hr': 'Povratni prevod za veliku skalu multijezičnog prevoda stroja', 'fa': 'ترجمه پشت برای ترجمه ماشین\u200cهای زیادی زبان', 'ko': '대규모 다국어 번역 중의 반역', 'da': 'Tilbage-oversættelse til stor skala flersproget maskinoversættelse', 'tr': 'Ullakan Ullanyş dili Mazmunlar Terjime üçin yzyna terjime', 'af': 'Terug- vertaling vir Groot- Skaal Veelvuldige Masjien Vertaling', 'sq': 'Përkthimi mbrapsht për përkthimin e makinës me shkallë të madhe shumëgjuhëse', 'am': 'ምርጫዎችBack-translation for Large-Scale Multilingual Machine translation', 'id': 'Terjemahan-belakang untuk Terjemahan Mesin Berbahasa Besar', 'az': 'Büyük-ölçülü çoxlu dil Makinelərin Tərcümü üçün geri dönüş', 'bn': 'বড়- আকার- মাল্টিভাষার মেশিন অনুবাদের জন্য ব্যাক- অনুবাদ', 'bs': 'Povratni prevod za veliki multijezički prevod mašine', 'cs': 'Zpětný překlad pro velký vícejazyčný strojový překlad', 'sw': 'translation', 'et': 'Tagasitõlge suure mitmekeelse masintõlke jaoks', 'hy': 'Բազլեզու մեքենայի թարգմանման մեջ', 'ca': 'Back-translation for Large-Scale Multilingual Machine Translation', 'fi': 'Takaisinkäännös suureen mittakaavaan monikieliseen konekäännökseen', 'sk': 'Nazaj prevajanje za večjezični strojni prevod velikega obsega', 'ha': '@ action', 'he': 'תרגום מאחור עבור תרגום מכונות רבות במידה גדולה', 'jv': 'Balik-Terjamahan kanggo Terjamahan kanggo Biwat-scale Multi-Linguke Mas Terjamahan', 'bo': 'རྩིས་ཤིང་ཚད་ཆེ་ཤོས་ཀྱི་སྐད་རིགས་མ་ལག་གི་སྐད་བསྒྱུར་ལོག'}
{'en': 'This paper illustrates our approach to the shared task on large-scale multilingual machine translation in the sixth conference on machine translation (WMT-21). In this work, we aim to build a single multilingual translation system with a hypothesis that a universal cross-language representation leads to better multilingual translation performance. We extend the exploration of different back-translation methods from bilingual translation to multilingual translation. Better performance is obtained by the constrained sampling method, which is different from the finding of the bilingual translation. Besides, we also explore the effect of ', 'ar': 'توضح هذه الورقة نهجنا تجاه المهمة المشتركة حول الترجمة الآلية متعددة اللغات واسعة النطاق في المؤتمر السادس حول الترجمة الآلية (WMT-21). في هذا العمل ، نهدف إلى بناء نظام ترجمة واحد متعدد اللغات مع فرضية أن التمثيل العالمي عبر اللغات يؤدي إلى أداء ترجمة متعدد اللغات أفضل. نحن نوسع استكشاف طرق مختلفة للترجمة العكسية من الترجمة ثنائية اللغة إلى الترجمة متعددة اللغات. يتم الحصول على أداء أفضل من خلال طريقة أخذ العينات المقيدة ، والتي تختلف عن اكتشاف الترجمة ثنائية اللغة. إلى جانب ذلك ، نستكشف أيضًا تأثير المفردات وكمية البيانات التركيبية. من المثير للدهشة أن الحجم الأصغر للمفردات يؤدي بشكل أفضل ، وتوفر البيانات الإنجليزية أحادية اللغة الواسعة تحسينًا متواضعًا. خضعنا لكل من المهام الصغيرة وحققنا المركز الثاني.', 'es': 'Este artículo ilustra nuestro enfoque de la tarea compartida de traducción automática multilingüe a gran escala en la sexta conferencia sobre traducción automática (WMT-21). En este trabajo, nuestro objetivo es construir un único sistema de traducción multilingüe con la hipótesis de que una representación universal entre idiomas conduce a un mejor rendimiento de la traducción multilingüe. Ampliamos la exploración de diferentes métodos de retrotraducción, desde la traducción bilingüe hasta la traducción multilingüe. Se obtiene un mejor rendimiento con el método de muestreo restringido, que es diferente del hallazgo de la traducción bilingüe. Además, también exploramos el efecto de los vocabularios y la cantidad de datos sintéticos. Sorprendentemente, el tamaño más pequeño de los vocabularios funciona mejor y los extensos datos de inglés monolingües ofrecen una mejora modesta. Nos sometemos a las tareas pequeñas y logramos el segundo lugar.', 'fr': "Cet article illustre notre approche de la tâche partagée sur la traduction automatique multilingue à grande échelle lors de la sixième conférence sur la traduction automatique (WMT-21). Dans ce travail, nous visons à construire un système de traduction multilingue unique avec l'hypothèse qu'une représentation universelle entre les langues entraîne de meilleures performances de traduction multilingue. Nous élargissons l'exploration de différentes méthodes de rétro-traduction, de la traduction bilingue à la traduction multilingue. Une meilleure performance est obtenue par la méthode d'échantillonnage contraint, qui est différente de la constatation de la traduction bilingue. En outre, nous explorons également l'effet des vocabulaires et la quantité de données synthétiques. Étonnamment, la taille réduite des vocabulaires est plus performante et les nombreuses données monolingues en anglais offrent une légère amélioration. Nous nous sommes soumis à la fois aux petites tâches et avons obtenu la deuxième place.", 'pt': 'Este artigo ilustra nossa abordagem à tarefa compartilhada de tradução automática multilíngue em larga escala na sexta conferência sobre tradução automática (WMT-21). Neste trabalho, pretendemos construir um único sistema de tradução multilíngue com a hipótese de que uma representação universal entre idiomas leva a um melhor desempenho da tradução multilíngue. Estendemos a exploração de diferentes métodos de retrotradução, desde a tradução bilíngue até a tradução multilíngue. Melhor desempenho é obtido pelo método de amostragem restrita, que é diferente do achado da tradução bilíngue. Além disso, também exploramos o efeito dos vocabulários e a quantidade de dados sintéticos. Surpreendentemente, o tamanho menor dos vocabulários apresenta melhor desempenho e os extensos dados monolíngues em inglês oferecem uma melhoria modesta. Submetemos-nos a ambas as pequenas tarefas e alcançamos o segundo lugar.', 'hi': 'यह पेपर मशीन अनुवाद (WMT-21) पर छठे सम्मेलन में बड़े पैमाने पर बहुभाषी मशीन अनुवाद पर साझा कार्य के लिए हमारे दृष्टिकोण को दर्शाता है। इस काम में, हम एक परिकल्पना के साथ एक एकल बहुभाषी अनुवाद प्रणाली का निर्माण करने का लक्ष्य रखते हैं कि एक सार्वभौमिक क्रॉस-भाषा प्रतिनिधित्व बेहतर बहुभाषी अनुवाद प्रदर्शन की ओर जाता है। हम द्विभाषी अनुवाद से बहुभाषी अनुवाद तक विभिन्न बैक-अनुवाद विधियों की खोज का विस्तार करते हैं। बेहतर प्रदर्शन विवश नमूना विधि द्वारा प्राप्त किया जाता है, जो द्विभाषी अनुवाद की खोज से अलग है। इसके अलावा, हम शब्दावली के प्रभाव और सिंथेटिक डेटा की मात्रा का भी पता लगाते हैं। हैरानी की बात है, शब्दावली का छोटा आकार बेहतर प्रदर्शन करता है, और व्यापक मोनोलिंगुअल अंग्रेजी डेटा एक मामूली सुधार प्रदान करता है। हमने दोनों छोटे कार्यों को प्रस्तुत किया और दूसरा स्थान प्राप्त किया।', 'ja': '本稿では、第6回機械翻訳会議（ WMT -21 ）における大規模多言語機械翻訳の共有課題に対する私たちのアプローチを示します。この研究では、普遍的なクロスリンガル表現がより良い多言語翻訳パフォーマンスにつながるという仮説で、単一の多言語翻訳システムを構築することを目指しています。私たちは、バイリンガル翻訳から多言語翻訳まで、さまざまなバック翻訳方法の探求を拡大します。より良いパフォーマンスは、制約付きサンプリング法によって得られます。これは、バイリンガル翻訳の発見とは異なります。さらに、語彙の効果や合成データ量についても探求しています。驚くべきことに、ボキャブラリーのサイズが小さいほどパフォーマンスが向上し、広範囲にわたる単一言語の英語データはわずかな改善を提供します。小さなタスクの両方に提出し、2位を達成しました。', 'zh': '本文阐述了我们在第六届机器翻译会议(WMT-21)中大成多言语机器翻译共同任务的方法。 我们的是立一个单一的多言语译统,其假设是通用的跨言语致多言语译性能。 我们将不同反向译法的探索从双语译到多言语译。 约束抽样善,与双语翻译异也。 又讨词汇合成数。 所讶者,小词汇量尤善,而广单语英语数供其所宜。 我从了两个小任,得第二名。', 'ru': 'Настоящий документ иллюстрирует наш подход к общей задаче по крупномасштабному многоязычному машинному переводу на шестой конференции по машинному переводу (WMT-21). В этой работе мы стремимся построить единую многоязычную систему перевода с гипотезой, что универсальное межъязыковое представление приводит к лучшей производительности многоязычного перевода. Мы расширяем исследование различных методов обратного перевода, начиная с двуязычного перевода и заканчивая многоязычным переводом. Лучшая производительность достигается с помощью метода ограниченной выборки, который отличается от нахождения двуязычного перевода. Кроме того, мы также исследуем влияние словарей и количество синтетических данных. Удивительно, но меньший размер словарей работает лучше, а обширные одноязычные английские данные предлагают скромное улучшение. Мы подчинялись как малым задачам, так и добиваемся второго места.', 'ga': 'Léiríonn an páipéar seo ár gcur chuige maidir leis an tasc comhroinnte ar aistriúchán meaisín ilteangach ar mhórscála sa séú comhdháil ar aistriúchán meaisín (WMT-21). San obair seo, tá sé mar aidhm againn córas aistriúcháin ilteangach amháin a thógáil le hipitéis go n-eascróidh feidhmíocht aistriúcháin ilteangach níos fearr as ionadaíocht uilíoch tras-teanga. Déanaimid iniúchadh ar mhodhanna éagsúla cúl-aistriúcháin ó aistriúchán dátheangach go haistriúchán ilteangach. Baintear feidhmíocht níos fearr as an modh samplála srianta, atá difriúil ó chinneadh an aistriúcháin dhátheangaigh. Ina theannta sin, déanaimid iniúchadh freisin ar éifeacht na stór focal agus ar an méid sonraí sintéiseacha. Is ionadh go n-éiríonn níos fearr le méid níos lú na stór focal, agus cuireann na sonraí fairsinge aonteangacha Béarla feabhas measartha ar fáil. Chuireamar isteach ar na tascanna beaga araon agus bhaineamar an dara háit amach.', 'hu': 'Ez a tanulmány bemutatja a nagyszabású, többnyelvű gépi fordítással kapcsolatos közös feladatunkat a gépi fordítás hatodik konferenciáján (WMT-21). Ebben a munkában egyetlen többnyelvű fordítási rendszer kialakítására törekszünk, amelynek feltételezése szerint az univerzális többnyelvű ábrázolás jobb többnyelvű fordítási teljesítményt eredményez. Kiterjesztjük a különböző visszafordítási módszerek feltárását a kétnyelvű fordítástól a többnyelvű fordításig. A kétnyelvű fordítás megállapításától eltérő korlátozott mintavételi módszerrel jobb teljesítményt érhetünk el. Emellett feltárjuk a szókincsek hatását és a szintetikus adatok mennyiségét is. Meglepő módon a szókincsek kisebb mérete jobban teljesít, és a kiterjedt, egynyelvű angol nyelvű adatok mérsékelt javulást kínálnak. Mindkét kis feladatnak alávetettük magunkat és elértük a második helyet.', 'el': 'Η παρούσα εργασία απεικονίζει την προσέγγισή μας στο κοινό έργο της μεγάλης κλίμακας πολυγλωσσικής μηχανικής μετάφρασης στο έκτο συνέδριο για τη μηχανική μετάφραση (WMT-21). Στην παρούσα εργασία, στοχεύουμε στην οικοδόμηση ενός ενιαίου πολυγλωσσικού μεταφραστικού συστήματος με την υπόθεση ότι μια καθολική διατύπωση οδηγεί σε καλύτερη απόδοση της πολυγλωσσικής μετάφρασης. Επεκτείνουμε την εξερεύνηση διαφορετικών μεθόδων αντίστροφης μετάφρασης από τη δίγλωσση μετάφραση έως την πολύγλωσση μετάφραση. Καλύτερη απόδοση επιτυγχάνεται με τη μέθοδο περιορισμένης δειγματοληψίας, η οποία διαφέρει από την εύρεση της δίγλωσσης μετάφρασης. Εκτός αυτού, διερευνούμε επίσης την επίδραση των λεξιλογίων και την ποσότητα των συνθετικών δεδομένων. Παραδόξως, το μικρότερο μέγεθος των λεξιλογίων αποδίδει καλύτερα και τα εκτεταμένα μονογλωσσικά αγγλικά δεδομένα προσφέρουν μια μέτρια βελτίωση. Υποθέσαμε και στα δύο μικρά καθήκοντα και πετύχαμε τη δεύτερη θέση.', 'it': "Questo articolo illustra il nostro approccio al compito condiviso sulla traduzione automatica multilingue su larga scala nella sesta conferenza sulla traduzione automatica (WMT-21). In questo lavoro, miriamo a costruire un unico sistema di traduzione multilingue con l'ipotesi che una rappresentazione universale cross-language porti a migliori prestazioni di traduzione multilingue. Estendiamo l'esplorazione di diversi metodi di back-translation dalla traduzione bilingue alla traduzione multilingue. Le migliori prestazioni si ottengono con il metodo di campionamento vincolato, che è diverso dal risultato della traduzione bilingue. Inoltre, esploriamo anche l'effetto dei vocabolari e la quantità di dati sintetici. Sorprendentemente, le dimensioni ridotte dei vocaboli funzionano meglio, e l'ampio dato monolingue inglese offre un modesto miglioramento. Ci siamo sottomessi a entrambi i piccoli compiti e raggiungere il secondo posto.", 'lt': 'Šiame dokumente parodomas mūsų požiūris į bendrą užduotį dėl plataus masto daugiakalbio vertimo mašinomis šeštojoje konferencijoje dėl mašin ų vertimo (WMT-21). Šiame darbe mes siekiame sukurti vieną daugiakalbį vertimo sistemą su hipoteze, kad universalus tarpkalbinis atstovavimas skatina geresnius daugiakalbius vertimo rezultatus. Mes išplečiame įvairių vertimo atgal metodų tyrimą nuo dvikalbio vertimo iki daugiakalbio vertimo. Geresni rezultatai pasiekiami taikant ribotą mėginių ėmimo metodą, kuris skiriasi nuo dvikalbio vertimo nustatymo. Be to, mes taip pat tiriame žodynų poveikį ir sintetinių duomenų kiekį. Įspūdinga, kad kuo mažesnis žodynų dydis yra geresnis, o plataus masto anglų kalbų duomenys yra nedidelis pagerėjimas. Mes pasiekėme tiek nedideles užduotis, tiek siekėme antrosios vietos.', 'mk': 'Овој документ го илустрира нашиот пристап кон заедничката задача за големиот мултијазичен машински превод на шестата конференција за машински превод (WMT-21). Во оваа работа, ние имаме за цел да изградиме еден мултијазичен преведувачки систем со хипотеза дека универзалното прекујазично претставување води до подобра мултијазична преведувачка перформанса. Ги прошируваме експлоатациите на различни методи на превод од двојјазичен превод до мултијазичен превод. Подобро резултати се постигнуваат со ограничениот метод на примерок, кој е различен од откритието на двојјазичкиот превод. Освен тоа, исто така го истражуваме ефектот на речниците и количината на синтетички податоци. Изненадувачки, помалата големина на речниците се подобри, а екстремните монојазични англиски податоци нудат скромно подобрување. Се поднесовме на двете мали задачи и го постигнавме второто место.', 'ms': 'Kertas ini memperlihatkan pendekatan kita kepada tugas berkongsi pada terjemahan mesin berbilang bahasa skala besar dalam persidangan keenam tentang terjemahan mesin (WMT-21). Dalam kerja ini, kami bertujuan untuk membina satu sistem terjemahan berbilang bahasa dengan hipotesis bahawa perwakilan secara melintasi bahasa universal membawa kepada prestasi terjemahan berbilang bahasa yang lebih baik. Kami memperluas pengeksplorasi kaedah terjemahan belakang yang berbeza dari terjemahan dua bahasa ke terjemahan berbilang bahasa. Performasi yang lebih baik diperoleh dengan kaedah pemilihan sampel yang dikuasai, yang berbeza dari penemuan terjemahan dua bahasa. Besides, we also explore the effect of vocabularies and the amount of synthetic data.  Mengejutkan, saiz lebih kecil vocabulari berjalan lebih baik, dan data bahasa Inggeris yang luas menawarkan peningkatan sederhana. Kami menyerahkan kepada kedua-dua tugas kecil dan mencapai tempat kedua.', 'ka': 'ეს დოკუნფიგურაცია ჩვენი მიღება დიდი მრავალური მანქანის გაგრძელებაზე ჩვენი მიღება მანქანის გაგრძელებაზე (WMT-21) შვიდი კონფიგურაციაში. ამ სამუშაოში, ჩვენ მინდა ერთი მრავალენგური გაგრძელების სისტემის შექმნა, რომელიც სამუშაო მრავალენგური გაგრძელების გამოყენება უფრო მეტი ენგური გაგრძელები ჩვენ განსხვავებული წინასწორებული მეტოვების განსხვავებას ორიენგური წინასწორებაზე მრავალენგური წინასწორებაზე გავაკეთებთ. უფრო დიდი გამოსახულება მიიღება, რომელიც განსხვავებულია ორიენგური გამოსახულება. დამატებით, ჩვენ ასევე ვაკეთებთ სიტყვებულების ეფექტის და სინტეტიკური მონაცემების რაოდენობა. სხვადასხვა, სიტყვებულების პატარა ზომა უკეთესია, და მონოლენგური ინგლისური მონაცემები უკეთესია გაუკეთება. ჩვენ მალკი დავალებებით და მეორე ადგილას მივიღეთ.', 'mt': 'Dan id-dokument juri l-approċċ tagħna għall-kompitu komuni dwar it-traduzzjoni multilingwi tal-magni fuq skala kbira fis-sitt konferenza dwar it-traduzzjoni tal-magni (WMT-21). In this work, we aim to build a single multilingual translation system with a hypothesis that a universal cross-language representation leads to better multilingual translation performance.  Aħna jestendu l-esplorazzjoni ta’ metodi differenti ta’ traduzzjoni lura mit-traduzzjoni bilingwi għat-traduzzjoni multilingwi. Prestazzjoni aħjar tinkiseb permezz tal-metodu ta’ teħid ta’ kampjuni ristrett, li huwa differenti mis-sejba tat-traduzzjoni bilingwi. Barra minn hekk, nistudjaw ukoll l-effett tal-vokabulari u l-ammont ta’ dejta sintetika. Bħala sorpriża, id-daqs iżgħar tal-vokabulari jwassal a ħjar, u d-dejta estensiva monolingwistika Ingliża toffri titjib modest. Aħna ppreżentajna kemm għall-kompiti ż-żgħar kif ukoll għat-tieni post.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മുടെ പങ്കെടുത്ത ജോലിയിലേക്ക് നമ്മുടെ നടപടി വ്യക്തമാക്കിയിരിക്കുന്നു. മെഷിന്\u200d പരിഭാഷണത്തിന്റെ ആറാം മെഷ In this work, we aim to build a single multilingual translation system with a hypothesis that a universal cross-language representation leads to better multilingual translation performance.  രണ്ടു ഭാഷ പരിഭാഷത്തില്\u200d നിന്നും പല ഭാഷയിലെ പരിഭാഷകളിലേക്കും വ്യത്യസ്ത പിന്തിരിപ്പുകളുടെ പരിശോധിയ്ക നിര്\u200dബന്ധപ്പെട്ട ട ടാമ്പിള്\u200d രീതിയില്\u200d നിന്നും നല്ല പ്രവര്\u200dത്തനം ലഭ്യമാക്കുന്നു. അത് രണ്ടു ഭാഷ പരിഭാഷത്തിന്റെ കണ പിന്നെ നമ്മള്\u200d പദവികളുടെ പ്രഭാവം പരിശോധിക്കുന്നു വാക്കുകളുടെ ചെറിയ വലിപ്പം നല്ലതാണ് പ്രവര്\u200dത്തിക്കുന്നത് അത്ഭുതകരമായിരിക്കുന്നു. വിശാലമായ മണ്ടോലില്\u200d ഇംഗ്ലീഷ ഞങ്ങള്\u200d രണ്ടാമത്തെ സ്ഥലം എത്തിക്കൊണ്ട് ചെറിയ ജോലികളെ കീഴ്പെടുത്തി.', 'kk': 'Бұл қағаз машина аудармасының алтыншы конференциясы (WMT- 21) үлкен көптілік механизм аудармасының ортақтастырылған тапсырманы көрсетеді. Бұл жұмыс ішінде бір көп тілді аудару жүйесін бірнеше тілді аудару жүйесін жасауға мақсат береміз. Бұл әлемдік көп тілді аудару жүйесі жақсы болады. Біз артық аудару әдістерін екі тілден бірнеше тілді аудару әдістерін зерттеуді көптеген. Екі тілді аудармасын табу арқылы шектелген мәліметтер арқылы жақсы жылдамдығын алады. Біз сондай-ақ сөздердің эффектін және синтетикалық деректердің саны зерттейміз. Бірақ, сөздердің кіші өлшемі жақсы жұмыс істейді, және оның көптеген ағылшын тілдегі деректері кіші жақсы жұмыс істейді. Біз кішкентай тапсырмаларына және екінші жерге жеткіздік.', 'mn': 'Энэ цаас машины хөрөнгө оруулах (WMT-21) 6-р конференцийн олон хэлний хэлний хөрөнгө оруулах ажлын тухай биднийг харуулдаг. Энэ ажлын тулд бид олон хэл хөгжлийн системийг бүтээх зорилго нь ертөнцийн олон хэл хөгжлийн хөгжлийг илүү олон хэл хөгжлийн үйл ажиллагаанд хүргэж байна. Бид хоёр хэл орчуулахаас олон хэл орчуулахаас өөр арван орчуулах арга замыг судалж нэмэгдүүлнэ. Хоёр хэл хэлний орчуулалтыг олж мэдэхээс ялгаатай, хязгаарлагдсан хэлбэрээр илүү сайн үйл ажиллагаа гаргадаг. Үүнээс гадна бид үг хэлний нөлөөг, синтетик өгөгдлийн хэмжээг судалж байна. Маш бага хэмжээний үг хэмжээний хэмжээнд илүү сайн ажилладаг. Илүү том англи хэл өгөгдлийн мэдээллийг бага зэрэг сайжруулдаг. Бид жижиг ажил хоёуланг дамжуулж, хоёр дахь газар хүрэх болсон.', 'no': 'Denne papiret illustrerer tilnærminga vårt til delt oppgåve på stor fleirspråk maskinsomsetjing i den sekste konferansen om maskinsomsetjinga (WMT-21). I dette arbeidet må vi bygge eit enkelt multispråksomsetjingssystem med eit hypotesis at eit universelt krysspråksrepresentasjon fører til bedre fleirspråksomsetjingssystem. Vi utvidar utforskinga av ulike tilbakeomsetjingsmetoder frå bilinguelt omsetjing til fleirspråk omsetjing. Det bedre utviklinga blir henta av den avgrensa samlingsmetoden, som er ulike frå å å finna den bilingåle omsetjinga. I tillegg utforskar vi også effekten av ordlister og mengden av syntetiske data. Manglar at den mindre storleiken på ordboklarar utfører betre, og den ekstra monospråk engelske data tilbyr ein modest forbetring. Vi sendte både dei små oppgåva og oppnå den andre plassen.', 'pl': 'Niniejszy artykuł ilustruje nasze podejście do wspólnego zadania dotyczącego wielojęzycznego tłumaczenia maszynowego na szóstej konferencji dotyczącej tłumaczenia maszynowego (WMT-21). W niniejszej pracy dążymy do zbudowania jednego wielojęzycznego systemu tłumaczeń z hipotezą, że uniwersalna reprezentacja wielojęzyczna prowadzi do lepszej wydajności tłumaczenia wielojęzycznego. Rozszerzamy eksplorację różnych metod tłumaczenia wstecznego od tłumaczenia dwujęzycznego do tłumaczenia wielojęzycznego. Lepszą wydajność uzyskuje się metoda ograniczonego próbkowania, która różni się od znalezienia tłumaczenia dwujęzycznego. Poza tym badamy również wpływ słowników i ilość danych syntetycznych. Co zaskakujące, mniejszy rozmiar słowników sprawdza się lepiej, a obszerne jednojęzyczne dane angielskie oferują niewielką poprawę. Poddawaliśmy się zarówno małym zadaniom, jak i osiągnęliśmy drugie miejsce.', 'ro': 'Această lucrare ilustrează abordarea noastră față de sarcina comună privind traducerea automată multilingvă la scară largă în cadrul celei de-a șasea conferințe privind traducerea automată (WMT-21). În această lucrare, ne propunem să construim un sistem unic de traducere multilingv, cu ipoteza că o reprezentare universală între limbi duce la o performanță mai bună de traducere multilingvă. Extindem explorarea diferitelor metode de traducere înapoi, de la traducerea bilingvă la traducerea multilingvă. O performanță mai bună este obținută prin metoda de eșantionare restricționată, care este diferită de constatarea traducerii bilingve. În plus, explorăm, de asemenea, efectul vocabularelor și cantitatea de date sintetice. Surprinzător, dimensiunea mai mică a vocabularelor performează mai bine, iar datele extinse monolingve în limba engleză oferă o îmbunătățire modestă. Ne-am supus atât sarcinilor mici și am obținut locul doi.', 'sr': 'Ovaj papir ilustruje naš pristup zajedničkom zadatku o velikoj multijezičkoj prevodi mašine u šestoj konferenciji o prevodu mašine (WMT-21). U ovom poslu, ciljamo da izgradimo jedan multijezički prevodni sistem sa hipotezom da univerzalna prejezična predstavljanja vodi do boljih višejezičkih prevoda. Proširili smo istraživanje različitih metoda prevoda iz dvojezičkog prevoda na multijezički prevod. Bolji izvod dobija ograničenim metodom uzoraka, što je drugačije od pronalaženja dvojezičkog prevoda. Osim toga, istražujemo efekat rečenika i količinu sintetičkih podataka. Iznenađujuće, manja veličina rečnika izvršava bolje, a široki monojezički engleski podaci nude skromno poboljšanje. Predložili smo i malim zadacima i ostvarili drugo mesto.', 'si': 'මේ පත්තුව පෙන්වන්නේ අපේ ප්\u200dරවේශනය ලොකු විශාල භාෂාවක් භාෂාවක් විශාල විශාල විධානය සඳහා විශාල විදි මේ වැඩේ අපි අල්ලගන්නවා එකම භාෂාවක් වාර්තාව පද්ධතියක් නිර්මාණය කරන්න, සාමාන්\u200dය භාෂාවක් වාර්තාව ප්\u200dරතිචාරයක්  අපි වෙනස් පිටිපස්සේ පරිවර්තන විදියට පස්සේ පරිවර්තන විදියට පරිවර්තන විදියට පරිවර්තන විදිය වඩා හොඳ ප්\u200dරමාණය ලැබෙන්නේ සැම්පල් විදියට, මේක දෙවල් භාෂාවක් වාර්තාවක් හොයාගන්න පුළුවන්. ඒ වගේම, අපි භාවිතාවක් සහ සංවිධාන දත්තේ ප්\u200dරශ්නයක් පරීක්ෂා කරනවා. විශ්වාසයෙන්, ශබ්ද විශ්වාසයේ පොඩි ප්\u200dරමාණය හොඳයි, සහ ප්\u200dරමාණ භාෂාවක් ඉංග්\u200dරීසි දත්ත ප්\u200dරමාණයක අපි පුංචි වැඩක් දෙන්නටම පුළුවන් කරලා දෙවෙනි තැනට පුළුවන් වුනා.', 'so': 'Qoraalkan waxaa loola jeedaa qaabilaadeenna u dhexeeya shaqada qayb-ka ah oo ku qoran tarjumaadda luuqadaha badan oo luuqadaha kala duduwan ku qoran conference lixaad oo ku qoran turjumaadda machine (WMT-21). Shuqulkaas, waxaynu ku daynaa inaannu dhisno nidaam turjumista luuqadaha kala duduwan oo kaliya, waxayna leedahay hypothesis, in kooxaha luqada caadiga ah uu ku hagaa muuqashada turjumaadda luuqadaha kala duduwan. Baaritaanka qaababka turjumista kala duduwan waxaan ka fidinaynaa turjumista labada luqadood ilaa turjumista luuqadaha kala duduwan. Dhaqdhaqaaqa waxaa laga helaa qaababka sameynta la qasbay, kaas oo ka duwan helitaanka turjumaadda labada luqadood. Sidoo kale waxaynu baaraynaa saamaynta hadallada iyo qiyaastii macluumaadka la xiriira. Waan la yaabaa in tirada yar ee luqada ku qoran uu sameeyo si wanaagsan, oo macluumaadka afka ingiriisiga oo ballaadhan waxaa bixiya hagaajinta habboon. Waxaannu hoos u dhiibnay shaqada yaryar, waxaana gaadhnay meeshii labaad.', 'sv': 'Denna uppsats illustrerar vårt förhållningssätt till den gemensamma uppgiften om storskalig flerspråkig maskinöversättning vid den sjätte konferensen om maskinöversättning (WMT-21). I detta arbete strävar vi efter att bygga ett enda flerspråkigt översättningssystem med en hypotes att en universell flerspråkig representation leder till bättre flerspråkig översättning prestanda. Vi utökar utforskningen av olika bakåtöversättningsmetoder från tvåspråkig översättning till flerspråkig översättning. Bättre resultat uppnås genom den begränsade provtagningsmetoden, som skiljer sig från den tvåspråkiga översättningen. Dessutom undersöker vi också effekten av vokabulären och mängden syntetiska data. Överraskande nog presterar den mindre storleken på vokabulären bättre, och de omfattande enspråkiga engelska data erbjuder en blygsam förbättring. Vi underkastade oss både de små uppgifterna och uppnådde andraplatsen.', 'ur': 'یہ کاغذ ہماری طریقہ کو ماشین ترجمہ (WMT-21) کے چھٹے کنفرانس میں ماشین کی چھٹی کنفرانس میں بہت سی صحیح ملتی زبان ماشین ترجمہ کے متعلق مشترک کام کے لئے دکھاتا ہے۔ اس کام میں ہم ایک متعدد زبان کی ترجمہ سیستم بنانے کا ارادہ کریں گے کہ ایک متعدد زبان کی ترجمہ سیستم کو بہترین ترجمہ کی فعالیت کی طرف لے جاتا ہے۔ ہم دونوں زبان کی ترجمہ سے مختلف پیچھے ترجمہ طریقوں کی تحقیق کو بہت سی زبان کی ترجمہ تک پھیلاتے ہیں۔ بہترین عملکرد کمزور نمونہ کے مطابق حاصل ہوتی ہے جو دوزخ کی ترجمہ پیدا کرنے سے مختلف ہے. اس کے علاوہ، ہم بھی لکھنے والوں اور سینٹیسی ڈیٹی کی مقدار کے اثر کا اثر دیکھتے ہیں۔ عجیب ہے کہ لکھنے والی باتوں کی چھوٹی اندازہ بہتر عمل کرتی ہے اور بڑی ایک زبان انگلیسی ڈاکٹی ایک کم ترقی پیش کرتی ہے۔ اور ہم نے دونوں چھوٹے کاموں کی اطاعت کی اور دوسری جگہ کو پہنچا دیا', 'ta': 'இந்த தாள் பங்கிடப்பட்ட பணிக்கு எங்கள் வழிமுறையை குறிப்பிடுகிறது பெரிய பல மொழிமொழிமாற்றி இயந்திரத்தின் ஆறு மொழிமாற்றி இந்த வேலையில், நாம் ஒரு பல மொழிமாற்று மொழிமாற்றும் அமைப்பை உருவாக்க வேண்டும். ஒரு பொதுவான குறிமுறை மொழி பிரதிநிதிப்பு ச இரண்டு மொழிமாற்றலிலிருந்து பல மொழிமாற்றி மொழிபெயர்ப்பில் இருந்து வேறு மாறுபாட்டு முறைகளை நாம் வ கட்டுப்படுத்தப்பட்ட மாதிரி முறைமையால் சிறந்த செயல்பாடு பெறுகிறது, அது இரு மொழிமாற்று மொழிபெயர்ப்பினை கண்டு மேலும், நாம் சொல்வளங்களின் விளைவையாட்டை மற்றும் கூட்டிணைப்பு தரவுகளின் அளவையும் கண்டறிகிறோம். ஆச்சரியமாக, சொல்வளங்களின் சிறிய அளவு நன்றாக செயல்படுத்துகிறது, மற்றும் விரிவாக்கமான மொனோலிங் ஆங்கிலத்தின் தகவல் ஒரு  நாங்கள் இரண்டு சிறிய பணிகளுக்கும் கீழ்படிந்து மற்றும் இரண்டாவது இடத்தை அடைந்தோம்.', 'uz': "Bu qogʻoz mashina tarjima (WMT-21) orqali katta tildagi bir necha tilda tarjima qiladigan vazifani ko'rsatadi. Bu ishda biz bir necha tilda tarjima tizimni yaratishni istaysizki, butun shaxsiy tilning taʼminlovchisi bir necha tillar tarjima qilish natijasi bir necha tilda yaxshi tarjima qilish natijasida bajaradi. Biz ikkita tildan bir tillar tarjimalaridan boshqa tarjima metodlarni ko'proq tillardan o'rganish uchun ko'proq tarjima qilamiz. @ info: whatsthis Ko'p, biz so'zlar va syntetik maʼlumotining effektini ko'rib chiqaramiz. Tasavvur qilingan, so'zlarning kichkina oʻlchami yaxshi bajaradi, va ko'proq ingliz tilining tarkibi maʼlumotlari juda yaxshi yaxshi yaxshi o'tiboradi. Biz ikkita kichkina vazifalarni таслим қилдик va keyingi vazifani bajardik.", 'vi': 'Bài báo này minh họa phương pháp của chúng ta với việc chia sẻ công việc dịch chuyển máy trên diện rộng lớn ở Thượng nghị viện về dịch vụ máy (WRT-21). Trong công việc này, chúng tôi dự định xây dựng một hệ thống dịch chuyển đa dạng đơn lẻ với giả thuyết rằng một đại diện ngôn ngữ chung dẫn đến hiệu suất dịch chuyển nhiều loại hơn. Chúng tôi mở rộng việc tìm kiếm các phương pháp dịch lại khác nhau từ dịch đôi đến dịch vụ đa dạng. Hiệu quả tốt hơn được lấy bằng phương pháp thử nghiệm bị hạn chế, khác với kết quả dịch hai thứ. Ngoài ra, chúng tôi cũng khám phá các hiệu ứng của vốn từ và lượng dữ liệu tổng hợp. Ngạc nhiên là, chức năng vốn từ nhỏ của chúng có hiệu quả tốt hơn, và thông tin về tiếng Anh rộng lớn cho thấy một tiến bộ khiêm tốn. Chúng tôi phục vụ cả những nhiệm vụ nhỏ và đạt được vị trí thứ hai.', 'nl': 'Dit document illustreert onze aanpak van de gedeelde taak op grootschalige meertalige machinevertaling tijdens de zesde conferentie over machinevertaling (WMT-21). In dit werk willen we een enkel meertalig vertaalsysteem bouwen met de hypothese dat een universele meertalige representatie leidt tot betere meertalige vertaalprestaties. We breiden de verkenning van verschillende back-translation methoden uit van tweetalige vertaling naar meertalige vertaling. Betere prestaties worden verkregen door de beperkte steekproefmethode, die verschilt van de bevinding van de tweetalige vertaling. Daarnaast onderzoeken we ook het effect van woordenschaten en de hoeveelheid synthetische data. Verrassend genoeg presteren de kleinere woordenschaten beter en biedt de uitgebreide eentalige Engelse data een bescheiden verbetering. We onderwerpen ons aan zowel de kleine taken en behalen de tweede plaats.', 'da': 'Denne artikel illustrerer vores tilgang til den fælles opgave om storstilet flersproget maskinoversættelse på den sjette konference om maskinoversættelse (WMT-21). I dette arbejde sigter vi mod at opbygge et enkelt flersproget oversættelsessystem med en hypotese om, at en universel tværsproget repræsentation fører til bedre flersprogede oversættelsesevne. Vi udvider undersøgelsen af forskellige back-oversættelsesmetoder fra tosproget oversættelse til flersproget oversættelse. Bedre resultater opnås ved hjælp af den begrænsede prøveudtagningsmetode, som adskiller sig fra resultaterne af den tosprogede oversættelse. Desuden undersøger vi også effekten af ordbøger og mængden af syntetiske data. Overraskende nok klarer den mindre størrelse af ordbøger bedre, og de omfattende ensprogede engelske data giver en beskeden forbedring. Vi underkastede os både de små opgaver og opnår andenpladsen.', 'id': 'This paper illustrates our approach to the shared task on large-scale multilingual machine translation in the sixth conference on machine translation (WMT-21).  In this work, we aim to build a single multilingual translation system with a hypothesis that a universal cross-language representation leads to better multilingual translation performance.  Kami memperluas eksplorasi metode terjemahan belakang yang berbeda dari terjemahan dua bahasa ke terjemahan berbeda bahasa. Pertunjukan yang lebih baik diperoleh dengan metode sampel yang terbatas, yang berbeda dari penemuan terjemahan dua bahasa. Selain itu, kita juga mengeksplorasi efek dari vokabular dan jumlah data sintetis. Mengejutkan, ukuran yang lebih kecil dari vokabular berhasil lebih baik, dan data monobahasa Inggris yang luas menawarkan peningkatan sederhana. Kami menyerahkan kepada kedua tugas kecil dan mencapai tempat kedua.', 'ko': '본고는 우리가 제6회 기계번역대회(WMT-21)에서 대규모 다국어 기계번역의 공동 임무에 대해 취한 방법을 논술하였다.이 작업에서 우리의 목표는 단일한 다중 언어 번역 시스템을 구축하고 통용되는 다중 언어 표현이 더욱 좋은 다중 언어 번역 성능을 가져올 수 있다고 가정하는 것이다.우리는 서로 다른 번역 방법에 대한 탐색을 이중 언어 번역에서 다중 언어 번역으로 확대할 것이다.이중 언어 번역의 발견과 달리 제약 표본 추출 방법은 더욱 좋은 성능을 얻었다.그 밖에 우리는 어휘와 합성 데이터량의 영향을 탐구했다.놀랍게도 어휘량이 작을수록 표현이 좋고 대량의 단어와 영어 데이터가 적당한 개선을 제공했다.우리는 작은 임무를 완수했을 뿐만 아니라, 또 2등을 했다.', 'bg': 'Настоящата статия илюстрира нашия подход към споделената задача по мащабния многоезичен машинен превод в шестата конференция по машинен превод (WMT-21). В тази работа се стремим да изградим единна многоезична преводаческа система с хипотеза, че универсалното междуезично представяне води до по-добра многоезична преводаческа ефективност. Разширяваме изследването на различни методи за обратен превод от двуезичен превод до многоезичен превод. По-добра производителност се постига чрез ограничения метод на вземане на проби, който е различен от намирането на двуезичния превод. Освен това изследваме ефекта на речниците и количеството синтетични данни. Изненадващо, по-малкият размер на речниците се представят по-добре, а обширните едноезични английски данни предлагат скромно подобрение. Подчинихме се както на малките задачи, така и на второто място.', 'hr': 'Ovaj papir ilustruje naš pristup zajedničkom zadatku o velikoj multijezičkoj prevodi strojeva u šestoj konferenciji o prevodu strojeva (WMT-21). U ovom poslu ciljamo izgraditi jedan multijezički sustav prevoda s hipotezom da univerzalna prejezična predstavljanja vodi do boljih učinka multijezičkih prevoda. Proširili smo istraživanje različitih metoda prevoda pozadine od dvojezičkog prevoda do multijezičkog prevoda. Bolji učinkoviti dobijaju se ograničenim metodom uzoraka, što je drugačije od pronalaženja dvojezičkog prevoda. Osim toga, istražujemo i učinak riječnika i količinu sintetičkih podataka. Iznenađujuće, manja veličina riječi čini bolje, a široki monojezički engleski podaci nude skromno poboljšanje. Predložili smo i malim zadacima i ostvarili drugo mjesto.', 'tr': 'Bu kagyz maşynyň terjime edilmeginde (WMT-21) altyndaky konferensiýada bölünýän zadymyzy golaýlaýar. Bu işde, bir çoklu dilli terjime sistemini düşünmek amaçlandyrýarys. Umumiy cross-language täze bir terjime etmek üçin daha gowy bir terjime etmäne yol a çar. Biz çäri dilden öňe-terjime metodlarynyň keşfedilmegini çapşyr. Iň gowy çykyş ýagdaýynyň çykyş döwleti tarapyndan berilýär. Bu ikinji dil terjime edilmesinden başga-başga. Ayrıca sözlerin ve sintetik maglumatyň täsirini keşfedýäris. Gaýratyn bolsa, sözleriniñ kiçi ululyky gowurak edýär we olaryň uly görnüş iňlisçe maglumatlary örän kiçi gelişmeleri tapar. Biz ikimiz kiçi zada hem teslim etdik we ikinji ýerine ýetirdik.', 'de': 'Dieser Beitrag veranschaulicht unseren Ansatz zur gemeinsamen Aufgabe der mehrsprachigen maschinellen Großübersetzung in der sechsten Konferenz zur maschinellen Übersetzung (WMT-21). In dieser Arbeit wollen wir ein einziges mehrsprachiges Übersetzungssystem aufbauen mit der Hypothese, dass eine universelle sprachübergreifende Repräsentation zu einer besseren mehrsprachigen Übersetzungsleistung führt. Wir erweitern die Erforschung verschiedener Backtranslationsmethoden von der zweisprachigen Übersetzung bis zur mehrsprachigen Übersetzung. Eine bessere Leistung wird durch die eingeschränkte Stichprobenmethode erzielt, die sich von der zweisprachigen Übersetzung unterscheidet. Außerdem untersuchen wir die Wirkung von Vokabeln und die Menge an synthetischen Daten. Überraschenderweise schneiden die kleineren Vokabeln besser ab und die umfangreichen einsprachigen englischen Daten bieten eine bescheidene Verbesserung. Wir haben uns den kleinen Aufgaben unterworfen und den zweiten Platz erreicht.', 'af': "Hierdie papier illustreer ons toegang tot die gedeelde taak op groot-skaal multitaal masjien vertaling in die sesde konferensie op masjien vertaling (WMT-21). In hierdie werk doen ons doel om 'n enkele multitaalse vertalingsstelsel te bou met 'n hipotees dat 'n universele kruistaalsvoorstelling lei na beter multitaalse vertalingsprestasie. Ons uitbrei die uitvoering van verskillende terugvertaling metodes van twee tale vertaling na veelvuldige vertaling. Beter prestasie word ontvang deur die beperkende versameling metode, wat is anders van die vinding van die tweedelingse vertaling. Ons exploreer ook die effek van woordeboeke en die hoeveelheid sintetiese data. Verwonderbaar is die kleiner grootte van woordeboeke beter uitvoer, en die uitbreiding monolinglike Engelske data offer 'n modeste verbetering. Ons het beide die klein taak ingestuur en die tweede plek bereik.", 'am': 'ይህ ፕሮግራም በስድስተኛው ጉዳይ በመሳዊ ትርጓሜ ላይ የተካፈለውን የልዩ ቋንቋ-ቋንቋ ትርጉም ላይ የተካፈለውን ሥርዓት ያሳያል፡፡ በዚህ ሥራ፣ አንዲት ብልቋንቋ ትርጉም ስርዓት መሥራት እናስፈልጋለን፡፡ ከሁለት ቋንቋ ትርጉም ጀምሮ እስከ ብዙ ቋንቋ ትርጉም ድረስ የተለየ ልዩ ልዩ-ጀርባ-ትርጉም ማረፊያ እናሳድጋለን፡፡ የሁለቱ ቋንቋዎች ትርጉም ማግኘት የተለየ ነው፡፡ ከዚህም በላይ የመልእክት አካባቢ እና የሲንቲካዊ ዳራዎችን እናሳውቃለን፡፡ በተደነቀቀ፣ የንግግሊዘኛ አዳራሽ በጣም ትንሽ መጠን ይሻላል፡፡ ታናሹን ስራዎችን አቀረብን ሁለተኛውንም ቦታ አግኝተናል፡፡', 'sq': 'Ky dokument ilustron qasjen tonë ndaj detyrës së përbashkët mbi përkthimin e makinave në shkallë të madhe shumëgjuhëse në konferencën e gjashtë mbi përkthimin e makinave (WMT-21). Në këtë punë, ne synojmë të ndërtojmë një sistem të vetëm përkthimi shumëgjuhës me një hipotezë se një përfaqësim universal ndërgjuhësor çon në performancë më të mirë përkthimi shumëgjuhës. Ne zgjerojmë eksplorimin e metodave të ndryshme të përkthimit prapa nga përkthimi dygjuhës në përkthimin shumëgjuhës. Ekzekutimi më i mirë arrihet nga metoda e kufizuar e kampionatit, e cila është ndryshe nga gjetja e përkthimit dygjuhësor. Përveç kësaj, ne gjithashtu eksplorojmë efektin e fjalorëve dhe sasinë e të dhënave sintetike. Surprisingly, the smaller size of vocabularies perform better, and the extensive monolingual English data offers a modest improvement.  Ne u dorëzuam të dy detyrave të vogla dhe arritëm vendin e dytë.', 'hy': 'Այս աշխատանքը ցույց է տալիս մեզ մոտեցումը մեծ մասշտաբով բազմալեզու մեքենայի թարգմանման հանդեպ վեցերորդ մեքենայի թարգմանման կոնֆերանսի ժամանակ (ԱՄԹ-21). Այս աշխատանքի ընթացքում մենք նպատակով ենք կառուցել մեկ բազլեզու թարգմանման համակարգ հիպոթեզով, որ համընդհանուր երկլեզու ներկայացումը հանգեցնում է ավելի լավ բազլեզու թարգմանման արտադրողությունների: Մենք ընդլայնում ենք երկլեզու թարգմանությունից մինչև բազլեզու թարգմանություն տարբեր թարգմանման մեթոդների ուսումնասիրությունը: Ավելի լավ արդյունք ստացվում է հարկավոր նմուշներ վերցնելու մեթոդի միջոցով, որը տարբերվում է երկլեզու թարգմանման գտնումից: Besides, we also explore the effect of vocabularies and the amount of synthetic data.  Զարմանալի է, որ բառագրերի փոքր չափերը ավելի լավ են աշխատում, և էքսպանսիվ անգլերեն տվյալները մի քիչ բարելավում են: Մենք ներկայացրեցինք երկու փոքր խնդիրներին և հասանք երկրորդ տեղին:', 'fa': 'این کاغذ روش ما را به کار مشترک در ترجمه ماشین\u200cهای زیادی زبان در ششمین کنفرانس در مورد ترجمه ماشین (WMT-21) نشان می\u200cدهد. در این کار، ما هدف داریم یک سیستم ترجمه\u200cهای متعدد زبان را با فرضی بسازیم که یک نمایش\u200cدهنده\u200cی متعدد زبان جهانی به انجام\u200cدهنده\u200cی متعدد زبان\u200cهای بهتر هدف می\u200cدهد. ما کشف روش\u200cهای عقب\u200cترجمه\u200cهای مختلف را از ترجمه\u200cهای دو زبان به ترجمه\u200cهای چند زبان گسترش می\u200cدهیم. عملکرد بهتر به وسیله نمونه\u200cهای محدودیت یافته می\u200cشود که از پیدا کردن ترجمه دو زبان متفاوت است. علاوه بر این، ما تاثیر کلمات و مقدار داده های سینتیک را تحقیق می کنیم. تعجب کننده است که اندازه کوچکترین کلمات بهتر عمل می\u200cکنند، و داده\u200cهای انگلیسی تنها زبان گسترده\u200cای بهترین پیشنهاد می\u200cدهد. ما به هر دو کار کوچک اطاعت کردیم و به جای دوم رسیدیم.', 'az': 'Bu kağıt maşın çevirilməsi barəsindəki altıncı konferans (WMT-21) ilə çox ölçülü dilli maşın çevirilməsi barəsindəki paylaşılmış işimizə tərzimizi göstərir. Bu işdə bir çoxlu dil tercümə sistemini təklif etmək istəyirik ki, universel dil çoxlu tercümə performansını daha yaxşı təhrif edir. Biz müxtəlif arka çeviri metodlarının keşfetməsini iki dildən çoxlu dil çeviriməsinə uzatdıq. İki dil çevirisini tapmaqdan daha yaxşı işlər alır. Biz də sözlərin və sintetik məlumatların etkisini keşfetirik. Bu təəccüblü sözlərin ən kiçik böyüklüyü daha xeyirli olar və genişliyi monodilli İngilizə verilən məlumatların ucuz uzlaşmasını təbliğ edir. Biz küçük işlərə təslim etdik və ikinci yerə yetişdik.', 'bn': 'এই পত্রিকাটি মেশিন অনুবাদের ছয় কনফারেন্সের (WMT-21) বিশাল মাল্টিভাল মেশিন অনুবাদের উপর আমাদের ভাগাভাগি করা কাজের কাছে আম এই কাজে আমরা একটি মাল্টিভাল ভাষার অনুবাদ সিস্টেম তৈরি করার উদ্দেশ্য হচ্ছি একটি হিসেবে যা বিশ্বব্যাপী ক্রস-ভাষার প্রতিনিধিত্বে আমরা দুই ভাষার অনুবাদ থেকে বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভাষায় অনুবাদের গবেষণা বৃদ্ধি করি। নিষিদ্ধ নমুনা পদ্ধতি দ্বারা ভালো কাজ পাওয়া যায়, যা দুই ভাষার অনুবাদ খুঁজে পাওয়ার থেকে ভিন্ন। এছাড়াও আমরা শব্দভাণ্ডারের প্রভাব ও সিন্টেটিক ডাটার পরিমাণ খুঁজে বের করি। বিস্ময়কর, শব্দভাণ্ডারের সামান্য আকার ভালো কাজ করে এবং বিস্তারিত ভাষায় ইংরেজি তথ্য একটি কম উন্নতি প্রদান করে। আমরা দুটোই ছোট কাজের প্রতি জমা দিয়েছি এবং দ্বিতীয় জায়গায় পৌঁছেছি।', 'bs': 'Ovaj papir ilustruje naš pristup zajedničkom zadatku o velikoj multijezičkoj prevodi strojeva u šestoj konferenciji o prevodu strojeva (WMT-21). U ovom poslu ciljamo izgraditi jedan multijezički prevodni sistem sa hipotezom da univerzalna prejezična predstavljanja vodi do boljih učinka multijezičkih prevoda. Proširili smo istraživanje različitih metoda prevoda pozadine od dvojezičkog prevoda do multijezičkog prevoda. Bolji učinkoviti se dobija ograničenim metodom uzoraka, što je drugačije od pronalaženja dvojezičkog prevoda. Osim toga, istražujemo i učinak riječnika i količinu sintetičkih podataka. Iznenađujuće, manja veličina riječnika izvršava bolje, a široki monojezički engleski podaci nude skromno poboljšanje. Predali smo i malim zadacima i ostvarili drugo mjesto.', 'ca': "Aquest paper ilustra el nostre enfocament a la tasca compartida de traducció multilingüe de màquines a gran escala a la sexta conferència sobre traducció màquina (WMT-21). In this work, we aim to build a single multilingual translation system with a hypothesis that a universal cross-language representation leads to better multilingual translation performance.  Estendem l'exploració de diferents mètodes de retrotraducció des de la traducció bilingüe a la traducció multilingüe. Un millor rendiment es obté amb el mètode de recolliment de mostres restringit, que és diferent de la trobada de la traducció bilingüe. A més, també explorem l'efecte dels vocabularis i la quantitat de dades sintètiques. Sorprenentment, la mida més petita dels vocabularis funciona millor, i les extenses dades monolingües d'anglès ofereixen una modest a millora. Ens vam subministrar a les petites tasques i vam aconseguir el segon lloc.", 'sw': 'Makala hii inaonyesha mbinu yetu ya kazi yetu ya kushirikiana katika tafsiri ya mashine yenye kiasi kikubwa katika kongamano la sita kuhusu tafsiri ya mashine (WMT-21). Katika kazi hii, tunakusudia kutengeneza mfumo wa kutafsiri wa lugha moja kwa moja na nadharia kwamba uwakilishi wa lugha za kimataifa unapelekea utendaji wa tafsiri wa lugha nyingine. Tunaendelea uchunguzi wa njia mbalimbali za kutafsiri kwa lugha mbili hadi tafsiri ya lugha nyingine. Utendaji bora unapatikana na njia ya sampuli inayolazimika, ambayo ni tofauti na kutafuta tafsiri ya lugha mbili. Zaidi yake, tunatafuta madhara ya lugha na kiasi cha taarifa za pamoja. Inashangaza, ukubwa mdogo wa maneno unafanya vizuri zaidi, na taarifa kubwa ya lugha za Kiingereza zinatoa maendeleo mazuri. Tulifanya kazi zote vidogo na kufikia nafasi ya pili.', 'et': 'Käesolev dokument illustreerib meie lähenemisviisi laiaulatusliku mitmekeelse masintõlke ühisele ülesandele kuuendal masintõlke konverentsil (WMT-21). Selles töös on meie eesmärk ehitada üks mitmekeelne tõlkesüsteem hüpoteesiga, et universaalne keeleülene esindus toob kaasa parema mitmekeelse tõlke tulemuslikkuse. Laiendame erinevate tagantõlkemeetodite uurimist alates kahekeelsest tõlkest kuni mitmekeelse tõlkeni. Paremat tulemust saavutatakse piiratud valimimeetodiga, mis erineb kahekeelse tõlke leiust. Lisaks uurime sõnavara mõju ja sünteetiliste andmete hulka. Üllataval kombel on sõnavara väiksem suurus parem ja ulatuslikud ühekeelsed inglise andmed pakuvad mõõdukat paranemist. Me allusime nii väikestele ülesannetele kui saavutasime teise koha.', 'fi': 'T채ss채 asiakirjassa kuvataan l채hestymistapaamme laajamittaiseen monikieliseen konek채채nt채miseen liittyv채채n yhteiseen teht채v채채n kuudennessa konek채채nt채mist채 k채sittelev채ss채 konferenssissa (WMT-21). T채ss채 ty철ss채 pyrimme rakentamaan yhden monikielisen k채채nn철sj채rjestelm채n olettamalla, ett채 monikielinen edustus johtaa parempaan monikieliseen k채채nn철kseen. Laajennamme erilaisten takak채채nn철smenetelmien tutkimista kaksikielisest채 k채채nn철ksest채 monikieliseen k채채nn철kseen. Parempi suorituskyky saavutetaan rajoitetulla n채ytteenottomenetelm채ll채, joka eroaa kaksikielisest채 k채채nn철ksest채. Lis채ksi tutkimme sanastojen vaikutusta ja synteettisen datan m채채r채채. Yll채tt채v채채 kyll채 sanastojen pienempi koko suoriutuu paremmin, ja laaja englanninkielinen aineisto tarjoaa v채h채ist채 parannusta. Me alistuimme sek채 pieniin teht채viin ett채 saavutimme toisen sijan.', 'cs': 'Tento příspěvek ilustruje náš přístup ke společnému úkolu v oblasti rozsáhlého vícejazyčného strojového překladu na šesté konferenci o strojovém překladu (WMT-21). V této práci se snažíme vytvořit jeden vícejazyčný překladatelský systém s hypotézou, že univerzální reprezentace mezi jazyky vede k lepší vícejazyčné překladatelské výkonnosti. Rozšiřujeme zkoumání různých metod zpětného překladu od dvojjazyčného překladu až po vícejazyčný překlad. Lepší výkon je dosažen metodou omezeného vzorkování, která se liší od zjištění dvojjazyčného překladu. Kromě toho zkoumáme také vliv slovníků a množství syntetických dat. Překvapivě, menší velikost slovníků funguje lépe a rozsáhlá jednojzyčná anglická data nabízejí mírné zlepšení. Podrobili jsme se oběma malým úkolům a dosáhli druhého místa.', 'he': 'העבודה הזו מציגה את הגישה שלנו למשימה המשותפת על תרגומת מכונות רבות-שפויות במערכת השישית על תרגומת מכונות (WMT-21). In this work, we aim to build a single multilingual translation system with a hypothesis that a universal cross-language representation leads to better multilingual translation performance.  אנו ממשיכים את חקירת שיטות התרגום האחורית שונות מתרגום שתיים לשפה רבה. ביצועים טובים יותר משיטת הדגימה המוגבלת, אשר שונה ממציאת התרגום השולשי. חוץ מזה, אנחנו גם חוקרים את ההשפעה של מילים וכמות הנתונים הסינטטיים. באופן מפתיע, הגודל הקטן ביותר של המילים מבצע טוב יותר, והנתונים המונושפתיים של אנגלית מציעים שיפור צנוע. הגענו לשני המשימות הקטנות ולהשגנו את המקום השני.', 'sk': 'Ta prispevek ponazarja naš pristop k skupni nalogi obsežnega večjezičnega strojnega prevajanja na šesti konferenci o strojnem prevajanju (WMT-21). V tem delu želimo zgraditi enoten večjezični prevajalski sistem s hipotezo, da univerzalna medjezikovna reprezentacija vodi k boljši večjezični učinkovitosti prevajanja. Razširimo raziskovanje različnih metod nazaj prevajanja od dvojezičnega prevoda do večjezičnega prevoda. Boljšo učinkovitost dosežemo z omejeno metodo vzorčenja, ki se razlikuje od ugotovitve dvojezičnega prevoda. Poleg tega raziskujemo tudi učinek besedišč in količino sintetičnih podatkov. Presenetljivo je, da je manjša velikost besedišč boljša, obsežni enojezični angleški podatki pa ponujajo skromno izboljšanje. Podredili smo se tako majhnim nalogam kot dosegli drugo mesto.', 'ha': "@ info Daga wannan aikin, Munã nufin mu ƙiƙira wani tsarin translation guda na mulki-lingui da wani teori wanda wani mai tsaro na fassarar-lugha na ƙari ya ƙara zuwa mafiya alhẽri ga fassarar mulki-lugha. Tuna shimfiɗa ƙidãyayn shiryoyin-bakin-translation-daban-daban daga translation-biyu zuwa fassarar mulki-lugha. Ka fi kyau ga gyarawa da metoden misãlai da aka kizimta, wanda yana mai sãɓãwa daga gano fassarar harshen biyu. Bayan haka, munã sami aikin maganar maganar da yawan data na haɗatiki. Ina yi amaki, girma mai ƙaranci na maganar, na samar da mafi alhẽri, kuma data mai shimfiɗawa na Ingiriya na farko na ƙara mafiya tsari. Sai muka sallama al'amarin kuma mun kasance mãsu sãmun babban rabo.", 'jv': 'Awakdhéwé iki ngono nggambar nganggo sampek ning akeh bantuan karo penting multi-scale lan ingkang sampek bantuan ing sampek bantayan neng sampek kanggo tarjamahan karo sistem (WWT-22). Nang barêng-barêng iki, kéné iso nggawe sistem sing karo akeh multilengkang karo suposipunge kuwi suposipunge kuwi suposipunge kapan universel karo lengkang basa sing bisa uga bantuan karo akeh multilengkang. Awak dhéwé nggawe tarjamahan karo perangkat-tarjamahan sing menyang banter, suku tarjamahan ingkang banter. Label lan tambah, kita sumulakno efek karo pergambar obaraning sampeyan karo data senetik. Awak dhéwé, ukuran langgar wigatining kuwi nggawe luwih apik, lan data yang dipunangke singular dan oleh kuwi nggawe luwih apik. Awak dhéwé ngeremut segala macem sing gak dhéwé lan sampek segala', 'bo': 'ཤོག འུ་ཅག་གི་ལས་འགན་འདིའི་ནང་དུ་ཚོར་སྤྲོད་ཀྱི་སྐད་ཡིག་ཐབས་ལམ་གཅིག་တည་འཛུགས་བྱེད་རྒྱུ་དང་། ང་ཚོས་རྒྱབ ངལ་ཚོགས་ཚད་གཞུང་བའི་དཔེ་དབྱིབས་ཀྱི་ལམ་ལུགས་ལས་ཕར་རྐྱེན་ཚད་ལེན་བྱས་པ་ཡིན། ད་དུང་། ང་ཚོས་བརྡ་སྤྲོད་ཀྱི་གནོད་ཚིག་དང་དབྱེ་སྡུད་ཆེན་གྱི་ཚད་ཀྱང་འཚོལ་ཞིབ་བྱེད་ཀྱི་ཡོད། ཡིད་མ་འཕགས་པའི་བརྡ་སྤྲོད་ཀྱི་ཆེ་ཆུང་ཀྱི་ཆེ་ཆུང་ཀུ་ཚོར་སྐྱོ་བར་བྱེད་ཀྱི་ཡོད། རྒྱ་ཆེ་བའི་སྐད་ཡིག ང་ཚོས་བྱ་རིམ་ཆུང་ཆུང་དུ་གཉིས་པ་དང་གནས་སུམ་གཉིས་པ་རེ་ཐོབ་པ་ཡིན།'}
{'en': 'Maastricht University’s Large-Scale Multilingual Machine Translation System for WMT 2021', 'fr': "Le système de traduction automatique multilingue à grande échelle de l'université de Maastricht pour WMT 2021", 'pt': 'Sistema de tradução automática multilíngue em grande escala da Universidade de Maastricht para WMT 2021', 'es': 'Sistema de traducción automática multilingüe a gran escala de la Universidad de Maastricht para WMT 2021', 'ar': 'نظام الترجمة الآلية متعدد اللغات واسع النطاق التابع لجامعة ماستريخت لـ WMT 2021', 'zh': '马斯特里赫特大学WMT 2021大言机器翻译统', 'ja': 'マーストリヒト大学のWMT 2021用大規模多言語機械翻訳システム', 'hi': 'WMT 2021 के लिए Maastricht University के बड़े पैमाने पर बहुभाषी मशीन अनुवाद प्रणाली', 'ru': 'Крупномасштабная многоязычная система машинного перевода Маастрихтского университета для WMT 2021', 'ga': 'Córas Aistriúcháin Meaisín Ilteangach ar Mhórscála Ollscoil Maastricht do WMT 2021', 'el': 'Πολυγλωσσικό σύστημα μηχανικής μετάφρασης μεγάλης κλίμακας του Πανεπιστημίου του Μάαστριχτ για το WMT 2021', 'ka': 'WMT 2021- ის მასტრიქტის სუნივერსიტის დიდი- სკვილის მრავალენგური მაქინის განსავლების სისტემა', 'hu': 'A Maastricht Egyetem nagyméretű többnyelvű gépi fordító rendszere a WMT 2021-hez', 'it': "Sistema di traduzione automatica multilingue su larga scala dell'Università di Maastricht per WMT 2021", 'lt': 'Mastrichto universiteto didelės apimties daugiakalbės mašinų vertimo sistema WMT 2021 m.', 'mk': "Maastricht University's Large-Scale Multilingual Machine Translation System for WMT 2021", 'kk': 'WMT 2021 үшін Маастрихт университетінің үлкен масштабының көп тілді машинаны аудару жүйесі', 'ms': 'Sistem Terjemahan Mesin Berbahasa Besar Universiti Maastricht untuk WMT 2021', 'ml': 'മാസ്ട്രിച്ച്ട് യൂണിവേഴ്സിറ്റിയിലെ വലിയ- വലിയ ഭാഷ മാറ്റല്\u200d ഭാഷ മെഷീന്\u200d പരിഭാഷ സിസ്റ്റം WMT 2021', 'mt': 'Is-Sistema ta’ Traduzzjoni Multilingwi tal-Magni fuq Skala kbira tal-Università ta’ Maastricht għad-WMT 2021', 'pl': 'Wielojęzyczny system tłumaczeń maszynowych na dużą skalę Uniwersytetu Maastricht dla WMT 2021', 'ro': 'Sistemul de traducere automată multilingvă la scară largă al Universității Maastricht pentru WMT 2021', 'no': "Maastricht University's Large-Scale Multilingual Machine Translation System for WMT 2021", 'sr': 'Velika skala multijezičkog sustava prevoda strojeva Univerziteta Maastricht za WMT 2021', 'so': "Maastricht University's Large-Scale Multilingual Machine Translation System for WMT 2021", 'si': 'WMT 2021 සඳහා මැස්ට්\u200dරිච්ට විශ්වාස්ත්තාවේ ලොකු විශාලයේ විශාලය ගොඩක් භාෂාවික මැෂින්', 'sv': 'Maastrichtuniversitetets storskaliga flersprĂ¥kiga maskinĂ¶versĂ¤ttningssystem fĂ¶r WMT 2021', 'ta': "மாஸ்ட்ரிச்ட் University's Large- Scale Multilingual Machine Translation System for WMT 2021", 'ur': 'WMT 2021 کے لئے ماسٹریچ یونیوریٹ کی بڑی اسکیل Multilingual Machine Translation System', 'mn': "Maastricht University's Large-Scale Multilingual Machine Translation System for WMT 2021", 'uz': 'Name', 'vi': 'Hệ thống dịch cơ bản đa ngôn ngữ lớn của Đại học Giao thông WRT 2021', 'nl': 'Het grootschalige meertalige machinevertaalsysteem van de Universiteit Maastricht voor WMT 2021', 'bg': 'Маастрихтската многоезична система за машинен превод на Университета в Маастрихт за WMT 2021', 'da': 'Maastricht Universitets storstilede flersprogede maskinoversættelsessystem til WMT 2021', 'hr': 'Velika skala multijezičkog sustava prevoda strojeva Univerziteta Maastricht za WMT 2021', 'de': 'Großes mehrsprachiges maschinelles Übersetzungssystem der Universität Maastricht für WMT 2021', 'id': 'Sistem Penerjemahan Mesin Berbahasa Besar Universitas Maastricht untuk WMT 2021', 'fa': 'سیستم ترجمه ماشین زیادی زبان\u200cهای دانشگاه Maastricht برای WMT 2021', 'sw': 'Kikuu cha Maastricht Chuo Kikuu cha Maastricht', 'tr': 'WMT 2021 üçin Maastricht Uniwersitetiň Uly Kalamy Çoklu Dilli Maşynyň terjime sistemi', 'ko': '마스트리히트 대학 WMT 2021을 위한 대규모 다국어 기계 번역 시스템', 'sq': 'Sistemi i përkthimit të makinave shumëgjuhëse në shkallë të madhe të Universitetit të Mastrichtit për WMT 2021', 'af': 'Maastricht Universiteit se Groot- Skaal Veelvuldige Masjien Vertalingsstelsel vir WMT 2021', 'am': "Maastricht University's Large-Scale Multilingual Machine Translation System for WMT 2021", 'hy': 'Մաասթրիխտի համալսարանի մեծ մասշտաբով բազմալեզու մեքենայի թարգմանման համակարգը', 'az': 'WMT 2021 체챌체n Maastricht Universitetinin b철y체k-철l챌체l체 챌oxlu dilli Makin 횉eviri Sistemi', 'bn': 'মাস্ট্রিচ্ট বিশ্ববিদ্যালয়ের ব্যাপার-মাল্টিভাষা মেশিন অনুবাদ সিস্টেম WMT ২০২১', 'bs': 'Velika skala multijezičkog sustava prevoda strojeva Univerziteta Maastricht za WMT 2021', 'ca': 'El sistema de traducció multilingüe de màquines a gran escala de la Universitat de Maastricht per al WMT 2021', 'cs': 'Velký vícejazyčný strojový překlad Maastrichtské univerzity pro WMT 2021', 'et': 'Maastrichti Ülikooli laiaulatuslik mitmekeelne masintõlke süsteem WMT 2021 jaoks', 'fi': 'Maastrichtin yliopiston laajamittainen monikielinen konekäännösjärjestelmä WMT 2021: lle', 'jv': "Masstrich University's Wid-scale Multilanguage Device translation System for WT 2020 1", 'ha': "Masastricht University's Large- scale multilinglanguage Translate system for WMT 2021", 'bo': "Maastricht University's Large-Scale Multilingual Machine Translation System for WMT 2021", 'he': 'מערכת התרגום של מכונות רבות שפות ברמה גדולה של אוניברסיטת מאסטריץ עבור WMT 2021', 'sk': 'Večjezični sistem strojnega prevajanja Univerze v Maastrichtu za WMT 2021'}
{'en': 'We present our development of the multilingual machine translation system for the large-scale multilingual machine translation task at WMT 2021. Starting form the provided ', 'fr': "Nous présentons notre développement du système de traduction automatique multilingue pour la tâche de traduction automatique multilingue à grande échelle au salon WMT 2021. À partir du système de base fourni, nous avons étudié plusieurs techniques pour améliorer la qualité de la traduction dans le sous-ensemble de langues cible. Nous avons pu améliorer de manière significative la qualité de la traduction en adaptant le système au sous-ensemble de langues cible et en générant des données synthétiques à l'aide du modèle initial. Les techniques appliquées avec succès dans la traduction automatique multilingue zero-shot (par exemple, régulariseur de similarité) n'ont eu qu'un effet mineur sur les performances de traduction finale.", 'ar': 'نقدم تطويرنا لنظام الترجمة الآلية متعدد اللغات لمهمة الترجمة الآلية متعددة اللغات على نطاق واسع في WMT 2021. بدءًا من النظام الأساسي المقدم ، بحثنا في العديد من التقنيات لتحسين جودة الترجمة على المجموعة الفرعية المستهدفة من اللغات. تمكنا من تحسين جودة الترجمة بشكل كبير من خلال تكييف النظام نحو المجموعة الفرعية المستهدفة من اللغات ومن خلال إنشاء بيانات تركيبية باستخدام النموذج الأولي. التقنيات التي تم تطبيقها بنجاح في الترجمة الآلية متعددة اللغات (مثل منظم التشابه) كان لها تأثير طفيف فقط على أداء الترجمة النهائي.', 'es': 'Presentamos nuestro desarrollo del sistema de traducción automática multilingüe para la tarea de traducción automática multilingüe a gran escala en el WMT 2021. Partiendo del sistema básico proporcionado, investigamos varias técnicas para mejorar la calidad de la traducción en el subconjunto de idiomas objetivo. Pudimos mejorar significativamente la calidad de la traducción adaptando el sistema al subconjunto de idiomas objetivo y generando datos sintéticos utilizando el modelo inicial. Las técnicas aplicadas con éxito en la traducción automática multilingüe de tiro cero (por ejemplo, el regularizador de similitud) solo tuvieron un efecto menor en el rendimiento de la traducción final.', 'pt': 'Apresentamos nosso desenvolvimento do sistema de tradução automática multilíngue para a tarefa de tradução automática multilíngue em larga escala no WMT 2021. A partir do sistema de linha de base fornecido, investigamos várias técnicas para melhorar a qualidade da tradução no subconjunto de idiomas de destino. Conseguimos melhorar significativamente a qualidade da tradução adaptando o sistema para o subconjunto de idiomas de destino e gerando dados sintéticos usando o modelo inicial. As técnicas aplicadas com sucesso na tradução automática multilíngue de tiro zero (por exemplo, regularizador de similaridade) tiveram apenas um efeito menor no desempenho final da tradução.', 'zh': '展我WMT 2021言机器翻译多言机器翻译统。 自基线系统,研寻数术,以崇译质。 因使统适应目标语言子集及用初模合成数,显加译质。 成功用于零镜头多言机器翻译之术(如相似性正则化器)终于译性之化小也。', 'ja': 'WMT 2021では、大規模な多言語機械翻訳タスクのための多言語機械翻訳システムの開発を発表しています。提供されたベースラインシステムの形から始めて、私たちは言語のターゲットサブセットの翻訳品質を向上させるためのいくつかのテクニックを調査しました。翻訳品質を大幅に向上させることができたのは、ターゲット言語のサブセットに合わせてシステムを適応させ、初期モデルを使用して合成データを生成することでした。ゼロショット多言語機械翻訳（類似性レギュレータなど）に適用されたテクニックは、最終的な翻訳パフォーマンスにわずかな影響しか与えなかった。', 'hi': 'हम डब्ल्यूएमटी 2021 में बड़े पैमाने पर बहुभाषी मशीन अनुवाद कार्य के लिए बहुभाषी मशीन अनुवाद प्रणाली के हमारे विकास को प्रस्तुत करते हैं। प्रदान की गई आधार रेखा प्रणाली से शुरू करते हुए, हमने भाषाओं के लक्ष्य सबसेट पर अनुवाद की गुणवत्ता में सुधार करने के लिए कई तकनीकों की जांच की। हम भाषाओं के लक्ष्य सबसेट की ओर सिस्टम को अनुकूलित करके और प्रारंभिक मॉडल का उपयोग करके सिंथेटिक डेटा उत्पन्न करके अनुवाद की गुणवत्ता में काफी सुधार करने में सक्षम थे। शून्य-शॉट बहुभाषी मशीन अनुवाद (जैसे समानता नियमित) में सफलतापूर्वक लागू तकनीकों का केवल अंतिम अनुवाद प्रदर्शन पर मामूली प्रभाव पड़ा।', 'ru': 'Мы представляем нашу разработку многоязычной системы машинного перевода для масштабной многоязычной задачи машинного перевода на WMT 2021. Начиная с предоставленной базовой системы, мы исследовали несколько методов для улучшения качества перевода на целевом подмножестве языков. Нам удалось значительно улучшить качество перевода, адаптировав систему к целевому подмножеству языков и сгенерировав синтетические данные с использованием исходной модели. Методы, успешно примененные в многоязычном машинном переводе с нулевым выстрелом (например, регуляризатор сходства), оказали лишь незначительное влияние на конечную производительность перевода.', 'ga': 'Cuirimid ár bhforbairt ar an gcóras aistriúcháin meaisín ilteangach don tasc aistriúcháin meaisín ilteangach ar scála mór i láthair ag WMT 2021. Ag tosú ón gcóras bunlíne a cuireadh ar fáil, rinneamar imscrúdú ar roinnt teicnící chun cáilíocht aistriúcháin an spriocfhothacar teangacha a fheabhsú. Bhíomar in ann cáilíocht an aistriúcháin a fheabhsú go suntasach tríd an gcóras a oiriúnú i dtreo na spriocfho-thacar teangacha agus trí shonraí sintéiseacha a ghiniúint ag baint úsáide as an múnla tosaigh. Ní raibh ach tionchar beag ag na teicníochtaí a cuireadh i bhfeidhm go rathúil in aistriúchán meaisín ilteangach náid (m.sh. rialtaitheoir cosúlachta) ar an bhfeidhmíocht aistriúcháin deiridh.', 'hu': 'A WMT 2021-en bemutatjuk a többnyelvű gépi fordítási rendszer fejlesztését a nagyszabású többnyelvű gépi fordítási feladathoz. A rendelkezésre álló alaprendszerből kiindulva több olyan technikát vizsgáltunk, amelyek javítják a fordítási minőséget a célnyelvek alcsoportján. Jelentősen javítani tudtuk a fordítási minőséget azáltal, hogy a rendszert a nyelvek célcsoportjához igazítottuk, és szintetikus adatokat generáltunk a kezdeti modell használatával. A nulla-shot többnyelvű gépi fordításban sikeresen alkalmazott technikák (pl. hasonlósági szabályozó) csak kisebb hatással voltak a végső fordítási teljesítményre.', 'el': 'Παρουσιάζουμε την ανάπτυξη του πολυγλωσσικού συστήματος μηχανικής μετάφρασης για τη μεγάλης κλίμακας εργασία πολυγλωσσικής μηχανικής μετάφρασης στο ΜΤ 2021. Ξεκινώντας από το παρεχόμενο σύστημα βάσης, ερευνήσαμε διάφορες τεχνικές για τη βελτίωση της ποιότητας της μετάφρασης στο υποσύνολο-στόχο των γλωσσών. Καταφέραμε να βελτιώσουμε σημαντικά την ποιότητα της μετάφρασης προσαρμόζοντας το σύστημα στο στοχευμένο υποσύνολο γλωσσών και δημιουργώντας συνθετικά δεδομένα χρησιμοποιώντας το αρχικό μοντέλο. Οι τεχνικές που εφαρμόστηκαν επιτυχώς στην πολύγλωσση μηχανική μετάφραση μηδενικού πυροβολισμού (π.χ. ρυθμιστής ομοιότητας) είχαν μόνο μικρή επίδραση στην τελική απόδοση της μετάφρασης.', 'ka': 'WMT 2021-ში ჩვენ მრავალენგური მაქანის გადარგზავნა სისტემის განვითარებას დიდი მრავალენგური მაქანის გადარგზავნა საქმე. ჩვენ დავიწყებეთ ფორმა, რომელიც დავიწყებული ფორმალური სისტემა, რამდენიმე ტექნექციები გადავიწყებთ, რომ უფრო მეტად წარმოიწყება სისტემალ ჩვენ შეგვიძლია მნიშვნელოვანად გავაკეთოთ თავისტრუმენტის კაalitეტის შესაძლებლობა, სისტემის მისამართლური საზოგადოებაზე და სინტეტიკური მონაცემების შესაძლებ ტექნექტიკები წარმატებით გამოყენებულია 0- სტრიქტის მრავალენგური მანქანის გარგულისხმებში (მაგალითად განსხვავებელი რეგილარიზაციელი) მხოლოდ ბოლო გარგულის', 'kk': 'Біз WMT 2021 жылы үлкен тілдерді аудару тапсырмасының көп тілдерді аудару жүйесінің құрамын көрсетедік. Келтірілген негізгі жол жүйесінің түрін бастау үшін бірнеше техникалық тілдерді аудару сапасын жақсарту үшін зерттедік. Біз аудармалардың сапатын өзгертуге мүмкін болдық, жүйені тілдердің мақсатты субөлігіне жасап, бастапқы үлгісімен синтетикалық деректерді құру үшін. Техникалық нөл түрлендірілген көптілік машинаның аудармасында (мысалы, ұқсас түрлендіру үшін) тек соңғы аудармасының жылдамдығына кішкентай эффекті болды.', 'it': 'Presentiamo il nostro sviluppo del sistema di traduzione automatica multilingue per il compito di traduzione automatica multilingue su larga scala a WMT 2021. Partendo dal sistema di base fornito, abbiamo studiato diverse tecniche per migliorare la qualità della traduzione sul sottoinsieme di lingue target. Siamo stati in grado di migliorare significativamente la qualità della traduzione adattando il sistema al sottoinsieme di lingue target e generando dati sintetici utilizzando il modello iniziale. Le tecniche applicate con successo nella traduzione automatica multilingue zero-shot (ad esempio regolarizzatore di somiglianza) hanno avuto solo un effetto minore sulle prestazioni finali della traduzione.', 'lt': 'Mes pristatome daugiakalbės mašinų vertimo sistemos plėtrą didelio masto daugiakalbės mašinų vertimo užduotims WMT 2021. Atsižvelgdami į pateiktą bazinę sistemą, ištyrėme kelis metodus, kuriais siekiama pagerinti vertimo kokybę tiksliniame kalbų pogrupyje. Mums pavyko gerokai pagerinti vertimo kokybę pritaikant sistemą prie tikslinio kalbų pogrupio ir sukuriant sintetinius duomenis naudojant pradinį model į. Techniques successfully applied in zero-shot multilingual machine translation (e.g. similarity regularizer) only had a minor effect on the final translation performance.', 'mk': 'Го претставуваме нашиот развој на мултијазичкиот машински превод систем за голема мултијазичка машинска превод на WMT 2021. Почнувајќи со формирањето на обезбедениот основен систем, истражувавме неколку техники за подобрување на квалитетот на преводот на метата на подгрупата јазици. We were able to significantly improve the translation quality by adapting the system towards the target subset of languages and by generating synthetic data using the initial model.  Техниките успешно аплицирани во нула-снимка мултијазичен машински превод (на пример регулаторизатор на сличноста) имаа само мал ефект на конечната преводна перформанса.', 'ms': 'Kami memperkenalkan pembangunan sistem terjemahan mesin berbilang bahasa untuk tugas terjemahan mesin berbilang bahasa besar di WMT 2021. Mula bentuk sistem asas yang diberikan, kami menyelidiki beberapa teknik untuk meningkatkan kualiti terjemahan pada subset sasaran bahasa. Kami mampu meningkatkan kualiti terjemahan secara signifikan dengan menyesuaikan sistem kepada subset sasaran bahasa dan dengan menghasilkan data sintetik menggunakan model awal. Teknik berjaya dilaksanakan dalam terjemahan mesin berbilang bahasa-sifar tembakan (contohnya pengaturan persamaan) hanya mempunyai kesan kecil pada prestasi terjemahan akhir.', 'ml': 'നമ്മുടെ പല ഭാഷ മെഷിന്\u200d പരിഭാഷ സിസ്റ്റത്തിന്റെ വിനിമയസ്ഥാനത്തിനായി ഞങ്ങള്\u200d കാണിക്കുന്നു. WMT 2021-ലെ വലിയ മാള്\u200dട്ട നല്\u200dകിയ ബെസ്ലൈന്\u200d സിസ്റ്റത്തിന്റെ രൂപം തുടങ്ങുന്നതിനാല്\u200d ഭാഷകളുടെ ലക്ഷ്യത്തിന്റെ അടിസ്ഥാനത്തില്\u200d പരിഭാഷക്ക ഭാഷകളുടെ ലക്ഷ്യത്തിന്റെ അടിസ്ഥാനത്തേക്ക് മാറ്റുന്നതിനാല്\u200d പരിഭാഷക്കുള്ള വിവരങ്ങള്\u200d വളരെ മെച്ചപ്പെടുത്താന്\u200d ഞങ്ങള്\u200dക്ക് കഴ സാങ്കേതികവിദ്യഭാഷയില്\u200d സാങ്കേതികവിദ്യ പ്രയോഗിച്ചിരിക്കുന്ന സാങ്കേതികവിദ്യ (ഉദാഹരണത്തിന് തുല്യമായ നിയന്ത്രണം) അവസാന പരി', 'mt': 'Aħna nippreżentaw l-iżvilupp tagħna tas-sistema ta’ traduzzjoni tal-magni multilingwi għall-kompitu ta’ traduzzjoni tal-magni multilingwi fuq skala kbira fid-WMT 2021. Billi bdejna jiffurmaw is-sistema ta’ bażi pprovduta, investigajna diversi tekniki biex itejbu l-kwalità tat-traduzzjoni fis-sottosett fil-mira tal-lingwi. Kienu kapaċi jtejbu b’mod sinifikanti l-kwalità tat-traduzzjoni billi tadatta s-sistema għas-sottosett fil-mira tal-lingwi u billi niġġeneraw dejta sintetika bl-użu tal-mudell inizjali. It-tekniki applikati b’suċċess fit-traduzzjoni tal-magni multilingwi b’użu żero (e ż. regolarizzatur ta’ similarità) kellhom biss effett żg ħir fuq il-prestazzjoni finali tat-traduzzjoni.', 'mn': 'Бид WMT 2021 онд олон хэл хэлний хөгжүүлэх машин хөгжүүлэх системийг илтгэдэг. Нэгдсэн суурь шугамны системийг эхлэхэд бид хэлний суурь хэлэнд орчуулах чадварыг сайжруулахын тулд олон техникуудыг судалсан. Бид системийг зориулагдсан хэлний суурь хэсэг рүү шилжүүлж, эхний загварыг ашиглан синтетик өгөгдлийг бүтээж чадна. Тэгш хэлний олон хэлний хөрөнгө оруулалт (жишээ нь тэгш хэлбэртэй тэгш хэлбэртэй тэгш хэлбэртэй тэгш хэлбэрээр) ашигласан техникууд сүүлийн хөрөнгө оруулалт дээр бага нөлөө үзүүл', 'ro': 'Vă prezentăm dezvoltarea sistemului de traducere automată multilingvă pentru sarcina de traducere automată multilingvă la scară largă la WMT 2021. Pornind de la sistemul de bază furnizat, am investigat mai multe tehnici de îmbunătățire a calității traducerii pe subsetul țintă de limbi. Am reușit să îmbunătățim semnificativ calitatea traducerii prin adaptarea sistemului la subsetul țintă de limbi și prin generarea de date sintetice folosind modelul inițial. Tehnicile aplicate cu succes în traducerea automată multilingvă zero-shot (de exemplu regularizatorul de similitudine) au avut doar un efect minor asupra performanței finale a traducerii.', 'pl': 'Na WMT 2021 prezentujemy nasz rozwój wielojęzycznego systemu tłumaczenia maszynowego do wielkojęzycznego zadania wielojęzycznego tłumaczenia maszynowego. Wychodząc z dostarczonego systemu bazowego, zbadaliśmy kilka technik poprawy jakości tłumaczenia dla docelowego podzbioru języków. Udało nam się znacząco poprawić jakość tłumaczenia poprzez dostosowanie systemu do docelowego podzbioru języków oraz generowanie danych syntetycznych z wykorzystaniem modelu początkowego. Techniki zastosowane z powodzeniem w zero-shot wielojęzycznym tłumaczeniu maszynowym (np. regulator podobieństwa) miały jedynie niewielki wpływ na ostateczną wydajność tłumaczenia.', 'no': 'Vi presenterer utviklinga vårt av multispråk maskinsomsetjingssystemet for det store stor multispråk maskinsomsetjingssystemet på WMT 2021. Startar form til den oppgjevne grunnlinjesystemet, så vi undersøkte fleire teknikk for å forbetra omsetjingskvaliteten på målssubdelen av språk. Vi kunne forbetra omsetjingskvaliteten betydelig ved å tilpassa systemet mot målsdelen av språk og laga syntetiske data ved å bruka opphavsmodulet. Teknisk er vellykket brukt i nullstatt fleirspråksomsetjing av maskina (f.eks. tilsvarande regulærar) har berre e in liten effekt på den siste omsetjinga.', 'sr': 'Predstavljamo naš razvoj multijezičkog sustava prevoda mašine za veliku veliku multijezičku prevodnu zadatak na WMT 2021. Počevši da formiramo obezbeđeni početni sistem, istražili smo nekoliko tehnika da bi poboljšali kvalitet prevođenja na ciljnoj subjekti jezika. Uspjeli smo značajno poboljšati kvalitet prevođenja prilagođavajući sistem prema ciljnom podskupu jezika i stvarajući sintetičke podatke koristeći prvi model. Tehnike su uspešno primjenjene u prevodu multijezičkih mašin a na nulu uputstva (npr. regularizatora sličnosti) imale samo manji uticaj na konačni izvod prevoda.', 'so': 'Waxaynu horumarinaynaa nidaamka tarjumaadda luuqadaha kala duduwan ee u qoran maamulka tarjumaadda luuqadaha kala duduwan ee WMT 2021. Markaad bilowdo foomka nidaamka qoraalka lagu qoray, waxaynu baaraynay qaabab badan, si aan u kordhino takhasuska turjumidda oo ku qoran koobsiga luqada. We were able to significantly improve the translation quality by adapting the system towards the target subset of languages and by generating synthetic data using the initial model.  Techniques wuxuu ku liibaanay tarjumaadka qoraalka luuqadaha kala duduwan (e.g. similarity regularizer) oo keliya waxay saameyn ku leedahay sameynta tarjumaadka ugu dambeeya.', 'sv': 'Vi presenterar v책r utveckling av det flerspr책kiga maskin철vers채ttningssystemet f철r den storskaliga flerspr책kiga maskin철vers채ttningsuppgiften p책 WMT 2021. Med utg책ngspunkt fr책n det angivna baslinjesystemet unders철kte vi flera tekniker f철r att f철rb채ttra 철vers채ttningskvaliteten p책 m책ldelen av spr책k. Vi kunde avsev채rt f철rb채ttra 철vers채ttningskvaliteten genom att anpassa systemet till m책ldelen av spr책k och genom att generera syntetiska data med hj채lp av den ursprungliga modellen. Tekniker som framg책ngsrikt till채mpades i flerspr책kig maskin철vers채ttning (t.ex. likformighetsregularizer) hade endast en mindre effekt p책 den slutliga 철vers채ttningen.', 'si': 'අපි WMT 2021 වලින් විශාල භාෂාවක් පද්ධතිය ගොඩක් භාෂාවක් පද්ධතියේ අපේ විකාශය පෙන්වන්න පුළුවන්. දෙන්න පුළුවන් පද්ධතිය පද්ධතිය පටන් ගන්න, අපි භාෂාවගේ ඉලක්ක සම්බන්ධයේ වාර්ථාවක් විශේෂය සඳහ අපිට පුළුවන් විශේෂය විශේෂය වැඩ කරන්න, පද්ධතිය භාෂාවගේ ඉලක්ක සම්බන්ධයෙන් සහ පටන්ගත් මොඩේල් භාවිතා කරන් තාක්ෂණය සමහර විශ්වාසයෙන් සුන්ධ විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපි', 'ur': 'ہم نے WMT 2021 میں بہت سی اسکیل ماشین ترجمہ کا کام کے لئے بہت سی زبان کی ماشین کی ترجمہ سیستم کی توسعہ دکھائی۔ ہم نے بہت سی ٹیکنیک کی تحقیق کی تابع کی کیفیت کو ترجمہ کرنے کے لئے زبانوں کے ساس سٹم کے ذریعے شروع کیا۔ ہم نے سیسٹم کو زبانوں کے تابع سپسٹ کی طرف اضافہ کرنے کے ذریعہ ترجمہ کی کیفیت کو اضافہ کر سکتے تھے اور آغاز موڈل کے مطابق سینٹیٹیک ڈاٹی بنانے کے ذریعہ۔ تخنیک موفقیت کے ساتھ صفر-شٹ multilingual machine translation (e.g. similarity regularizer) میں صرف آخری ترجمہ کے عمل پر تھوڑا اثر تھا.', 'ta': 'WMT 2021-ல் பெரிய பல மொழி மொழிமாற்றம் மொழிமாற்றும் செயல்பாட்டிற்கான பல மொழிமாற்றம் மொழிமாற்றும் அமைப்பின் மு கொடுக்கப்பட்ட அடிப்படை கோட்டு அமைப்பை துவங்குகிறது, நாங்கள் பல தொழில்நுட்ப மொழிகளின் மொழிப்பெயர்ப்பு தரம் மே மொழிகளின் குழுக்களை மாற்றி முழுமையை மாற்ற முடியவில்லை மற்றும் முதல் மாதிரியை பயன்படுத்தி தொடர்புடைய தகவலை உருவாக்குவதற்க தொழில்நுட்பம் வெற்றிகரமாக செயல்படுத்தப்பட்டது பூஜ்ஜியத்தில் பல மொழிமாற்றி மொழிபெயர்ப்பில் (உதாரணமாக ஒத்திசைப்படுத்துபவர்) கடைசி', 'vi': 'Chúng tôi giới thiệu sự phát triển của chúng tôi trong hệ thống dịch chuyển máy đa dạng của chúng tôi cho nhiệm vụ dịch cỗ máy lớn ở WRT 2021. Bắt đầu từ hệ cơ sở cung cấp, chúng tôi đã điều tra nhiều kỹ thuật để cải thiện chất lượng dịch trong nhóm ngôn ngữ đích. Chúng tôi đã có thể cải thiện chất dịch đáng kể bằng cách sửa hệ thống vào nhóm mục tiêu của ngôn ngữ và tạo ra dữ liệu tổng hợp bằng cách dùng mẫu ban đầu. Kỹ thuật được áp dụng thành công trong phiên dịch máy đa dạng không phát (v.d. bộ hoá hoá giống nhau) chỉ có tác động nhỏ đến hiệu ứng dịch cuối cùng.', 'uz': "Biz WMT 2021 yildagi katta tildagi bir necha tildagi mashina tarjima tizimini tahrirlash uchun bir necha tilning tarjima tizimini tajriba qilamiz. @ info Biz tizimni tilning qismlariga o'zgartirish va birinchi model bilan birinchi bir xil maʼlumot yaratish mumkin. @ info: whatsthis", 'bg': 'Представяме разработката на многоезичната система за машинен превод за мащабната задача за многоезичен машинен превод на ММТ 2021. Започвайки от предоставената базова система, изследвахме няколко техники за подобряване качеството на превода на целевата подгрупа езици. Успяхме значително да подобрим качеството на превода чрез адаптиране на системата към целевата подгрупа езици и генериране на синтетични данни с помощта на първоначалния модел. Техниките, приложени успешно при многоезичен машинен превод с нулев изстрел (напр. регуляризатор на сходството), имат само незначителен ефект върху ефективността на окончателния превод.', 'hr': 'Predstavljamo naš razvoj multijezičkog sustava prevoda strojeva za veliku mjeru multijezičkog prevodnog zadatka na WMT 2021. Počevši formirati pruženi početni sustav, istražili smo nekoliko tehnika za poboljšanje kvalitete prevoda na ciljnoj podjeli jezika. Uspjeli smo značajno poboljšati kvalitet prevođenja prilagođenjem sustava prema ciljnoj podjeli jezika i stvaranjem sintetičkih podataka s primjerenim modelom. Tehnike su uspješno primjenjene u prevodu multijezičkih strojeva (npr. regularizacija sličnosti) samo su imali manji učinak na konačnu učinku prevoda.', 'da': 'Vi præsenterer vores udvikling af det flersprogede maskinoversættelsessystem til den store flersprogede maskinoversættelsesopgave på WMT 2021. Med udgangspunkt i det leverede basissystem undersøgte vi flere teknikker til at forbedre oversættelseskvaliteten på målsætningen af sprog. Vi kunne forbedre oversættelseskvaliteten betydeligt ved at tilpasse systemet til målsætningen af sprog og ved at generere syntetiske data ved hjælp af den oprindelige model. Teknikker anvendt med succes i zero-shot flersproget maskinoversættelse (f.eks. lighedsregulering) havde kun en mindre effekt på den endelige oversættelseseffekt.', 'nl': 'Op WMT 2021 presenteren we onze ontwikkeling van het meertalige machinevertaalsysteem voor de grootschalige meertalige machinevertaaltaak. Uitgaande van het aangeboden basissysteem hebben we verschillende technieken onderzocht om de vertaalkwaliteit op de doelsubset talen te verbeteren. We hebben de vertaalkwaliteit aanzienlijk kunnen verbeteren door het systeem aan te passen aan de doelsubset talen en door synthetische gegevens te genereren met behulp van het initiële model. Technieken die succesvol werden toegepast in zero-shot meertalige machinevertaling (bv. gelijkenisregelaar) hadden slechts een klein effect op de uiteindelijke vertaalprestaties.', 'de': 'Auf der WMT 2021 stellen wir unsere Entwicklung des mehrsprachigen maschinellen Übersetzungssystems für die großflächige mehrsprachige maschinelle Übersetzungsaufgabe vor. Ausgehend von dem bereitgestellten Basissystem untersuchten wir verschiedene Techniken zur Verbesserung der Übersetzungsqualität für die Zielsprache. Wir konnten die Übersetzungsqualität deutlich verbessern, indem wir das System an die Zielteilmenge der Sprachen anpassen und synthetische Daten mithilfe des ursprünglichen Modells generieren. Erfolgreich angewandte Techniken in der mehrsprachigen maschinellen Übersetzung (z.B. Ähnlichkeitsregularisierung) wirkten sich nur geringfügig auf die endgültige Übersetzungsleistung aus.', 'id': 'We present our development of the multilingual machine translation system for the large-scale multilingual machine translation task at WMT 2021.  Mulai bentuk sistem dasar yang diberikan, kami menyelidiki beberapa teknik untuk meningkatkan kualitas terjemahan pada subset sasaran bahasa. Kami mampu meningkatkan kualitas terjemahan secara signifikan dengan mengadaptasi sistem menuju subset sasaran bahasa dan dengan menghasilkan data sintetis menggunakan model awal. Teknik berhasil diterapkan dalam penerjemah mesin multibahasa nol (contohnya regulariser persamaan) hanya memiliki efek kecil pada prestasi penerjemah akhir.', 'ko': '우리는 WMT 2021의 대규모 다국어 기계 번역 임무를 위해 개발한 다국어 기계 번역 시스템을 소개했다.제공된 기선 시스템부터 우리는 목표 언어의 서브집합 번역의 질을 향상시키는 몇 가지 기술을 연구했다.시스템이 목표 언어의 서브집합에 적응하고 초기 모델을 사용하여 합성 데이터를 생성함으로써 우리는 번역의 질을 현저하게 향상시킬 수 있다.제로 렌즈 다중 언어 기계 번역에서 성공적으로 응용된 기술(예를 들어 유사성 정규화기)은 최종 번역 성능에 대한 영향이 매우 적다.', 'fa': 'ما توسعه\u200cمون را از سیستم ترجمه\u200cهای ماشین\u200cهای زیادی زبان برای کار ترجمه\u200cهای ماشین\u200cهای زیادی زبان در WMT 2021 پیشنهاد می\u200cکنیم. شروع به شکل سیستم پایین\u200cخط ارائه می\u200cشود، ما چند تکنیک را تحقیق کردیم تا کیفیت ترجمه را در زیر\u200cخط هدف زبانها بهبود دهیم. ما توانستیم کیفیت ترجمه را با توجه سیستم به سوی زیر زیر هدف زبانها و با تولید داده های سینتیک با استفاده از مدل اولیه بهبود دهیم. تکنیک\u200cها با موفقیت در ترجمه\u200cهای ماشین\u200cهای متعدد زبان\u200cهای صفر (به عنوان قانونی\u200cترجمه\u200cکننده\u200cی شبیه\u200cانگیز) فقط تاثیر کوچک بر عملکرد نهایی ترجمه را داشتند.', 'sw': 'Tunaweza kuonyesha maendeleo yetu ya mfumo wa kutafsiri mashine ya lugha mbalimbali kwa kazi kubwa ya kutafsiri mashine ya lugha za lugha katika WMT 2021. Tulianza kuunda mfumo wa msingi, tulichunguza mbinu kadhaa za kuboresha kiwango cha tafsiri katika viungo vya lugha. Tuliweza kuboresha kiwango cha tafsiri kwa kubadilisha mfumo kwa lengo la lugha na kwa kutengeneza taarifa za pamoja kwa kutumia mifano ya mwanzo. Techniques successfully applied in zero-shot multilingual machine translation (e.g. similarity regularizer) only had a minor effect on the final translation performance.', 'tr': 'WMT 2021-de örän uly dilli maşynyň terjime täblisasy üçin guruldygymyzy görkezýäris. Berilen esaslar sistemini başlap başladyk, biz dillerin baýramçylygynyň üstine terjime etmek üçin birnäçe teknikleri bardyk. Biz sistemi dilleriň nişan toparyna üýtgetmek we başlangyç modelini ullanarak sintetik maglumatlary bejerip üstine çykyp bilýärdik. Tehnikler 0-atly köp dilli maşynyň terjimesinde (meselâ dörwärlik düzenlemeli) iň soňky terjime edeniň üstünde azajyk täsiri ýok boldy.', 'af': "Ons stel ons ontwikkeling van die multitaalslike masjien vertalingsstelsel voor die groot-skaal multitaalslike masjien vertalingstaak by WMT 2021. Beginne vorm van die verskaf basilyn stelsel, het ons verskeie teknike ondersoek om die vertalingskwaliteit op die doel subartikel van tale te verbeter. Ons kon betekeurig die vertalingskwaliteit verbeter deur die stelsel aan die doel subartikel van tale te pas en deur sintetiese data te genereer deur die aanvanklike model te gebruik. Tehnikasies het suksesvol gebruik in Nul-skoot veelvuldige masjien vertaling (bv. gelykenis regulariseerder) slegs 'n klein effek op die eindelike vertaling uitvoer.", 'am': 'በWMT 2021 ላሉት ለብዙ ቋንቋ ቋንቋዎች ትርጉም ስርዓታችንን አቀረብን፡፡ የደረጃ መግለጫ ስርዓት መፍጠር ጀምሮ በመግለጫው ቋንቋዎች ላይ የግንኙነቱን ጥያቄ ለማሻሻል በብዙ ጥያቄዎችን መረመርን፡፡ የቋንቋውን አካባቢ እና የመጀመሪያውን ዓይነት በመጠቀም የስንተርሚቱን አካባቢ እና የድምፅ መረጃዎችን በመፍጠር እናስቻለን፡፡ ቴክኖጂዎች በ0-shot በብዙ ቋንቋ-ቋንቋዎች ትርጓሜ (ምሳሌ similarity regulator) በመጨረሻው ትርጓሜ ማድረግ ላይ ትንሽ ጥያቄ ብቻ ነበር።', 'sq': 'Ne paraqesim zhvillimin tonë të sistemit të përkthimit të makinave shumëgjuhëse për detyrën e përkthimit të makinave në shkallë të madhe shumëgjuhëse në WMT 2021. Duke filluar të formojmë sistemin bazë të siguruar, ne hetuam disa teknika për të përmirësuar cilësinë e përkthimit në nëngrupin objektiv të gjuhëve. Ne ishim në gjendje të përmirësonim ndjeshëm cilësinë e përkthimit duke përshtatur sistemin drejt nëngrupit objektiv të gjuhëve dhe duke krijuar të dhëna sintetike duke përdorur modelin fillestar. Teknikët e aplikuara me sukses në përkthimin e makinës me gjuhë zero (për shembull rregulluesi i ngjashmërisë) kishin vetëm një efekt të vogël në performancën përfundimtare të përkthimit.', 'bn': 'আমরা উইএমটি ২০২১-এ বিশাল মাল্টিভাষার মেশিন অনুবাদের কাজের জন্য বহুভাষায় মেশিন অনুবাদ সিস্টেমের উন্নয়নের উন্নয়নে Starting form the provided baseline system, we investigated several techniques to improve the translation quality on the target subset of languages.  আমরা ব্যবস্থাটিকে লক্ষ্যবস্তুর সাবটের দিকে প্রতিষ্ঠান করতে এবং প্রথম মডেল ব্যবহার করে সিন্টেটিক ডাটা তৈরি করতে পারি। প্রযুক্তি শুধুমাত্র শুধুমাত্র মাল্টিলিভাল মেশিন অনুবাদের (যেমন একই ধরনের নিয়মিত নিয়ন্ত্রণালয়কারী) শেষ অনুবাদের প্রভাবের উপর', 'hy': 'Մենք ներկայացնում ենք մեր զարգացումը բազլեզու մեքենայի թարգմանման համակարգի մեծ մակարդակի բազլեզու մեքենայի թարգմանման խնդիրների համար ԱՄԹ 2021 թվականին: Սկսելով տրամադրված հիմնական համակարգը, մենք ուսումնասիրեցինք մի քանի մեթոդներ, որոնք օգնում էին բարելավել թարգմանման որակը լեզուների նպատակային ենթախմբի վրա: Մենք կարողացանք նշանակալի բարելավել թարգմանման որակը հարմարեցնելով համակարգը լեզուների նպատակային ենթախումբին և ստեղծելով սինթետիկ տվյալներ օգտագործելով սկզբնական մոդելը: Տեխնոլոգիաները, որոնք հաջողությամբ կիրառվել են զրոլեզվով բազմալեզվով մեքենայի թարգմանման մեջ (օրինակ նմանությունների վերահսկողը), միայն փոքր ազդեցություն ունեցան վերջնական թարգմանման արդյունքին:', 'bs': 'Predstavljamo naš razvoj multijezičkog sustava prevoda mašine za veliku mjeru multijezičkog prevodnog zadatka na WMT 2021. Počevši formirati obezbeđeni početni sistem, istražili smo nekoliko tehnika da bi poboljšali kvalitet prevoda na ciljnoj subjekti jezika. Uspjeli smo značajno poboljšati kvalitet prevoda prilagođavajući sistem prema ciljnoj podskupini jezika i stvarajući sintetičke podatke koristeći početni model. Tehnike su uspješno primjenjene u prevodu multijezičkih strojeva (npr. regularizacija sličnosti) samo su imali manji učinak na konačni učinak prevoda.', 'az': 'WMT 2021-də çox dilli maşın qurğulama törətməsi üçün çox dilli maşın sistemini təhsil edirik. Mərhəmətli tədbir sisteminin şəklinə başlayıb, dillərin məqsədilərin dəyişikliyini yaxşılaşdırmaq üçün bir neçə teknikləri araşdırdıq. Biz sistemi dillərin məqsədilərin dəstəsinə uyğunlaşdırmaq və başlangıç modeli vasitəsilə sintetik məlumatları yaratmaq üçün çox böyük tərcümə keyfiyyətini düzəltə bilərdik. Sıfır-shot çoxlu dil maşına çevirilməsində təhniklər müvəffəqiyyətlə istifadə edildilər (məsələn, bənzər regularizer) ancaq son çevirim performansına az bir etki vardır.', 'et': 'WMT 2021 raames tutvustame mitmekeelse masintõlke süsteemi arendamist laiaulatusliku mitmekeelse masintõlke ülesande jaoks. Alustades esitatud baassüsteemist uurisime mitmeid meetodeid tõlkekvaliteedi parandamiseks sihtkeelte alamhulgas. Tõlkekvaliteeti suutsime märkimisväärselt parandada, kohandades süsteemi sihtkeelte alamhulka ja genereerides esialgse mudeli abil sünteetilisi andmeid. Mittekeelses masintõlkes edukalt rakendatud meetoditel (nt sarnasuse regulariseerija) oli lõplikule tõlkele vaid väike mõju.', 'cs': 'Na WMT 2021 představujeme náš vývoj vícejazyčného strojového překladu systému pro velký vícejazyčný strojový překlad. Na základě poskytnutého základního systému jsme zkoumali několik technik ke zlepšení kvality překladu na cílové podmnožině jazyků. Podařilo se nám výrazně zlepšit kvalitu překladu přizpůsobením systému cílové podmnožině jazyků a generováním syntetických dat pomocí počátečního modelu. Techniky úspěšně aplikované v zero-shot vícejazyčném strojovém překladu (např. regularizátor podobnosti) měly jen malý vliv na konečný překlad.', 'fi': 'Esittelemme monikielisen konekäännösjärjestelmän kehittämistä laajamittaiseen monikieliseen konekäännöstöön WMT 2021 -messuilla. Lähtökohtaisesta perusjärjestelmästä tutkimme useita tekniikoita kääntämisen laadun parantamiseksi kohdekielillä. Pystyimme parantamaan käännöslaatua merkittävästi mukauttamalla järjestelmää kohdekieliin ja tuottamalla synteettistä dataa alkuperäisen mallin avulla. Nollashot monikielisessä konekäännöksessä onnistuneesti sovelletuilla tekniikoilla (esim. samankaltaisuuden säännöstelijällä) oli vain vähäinen vaikutus lopulliseen käännökseen.', 'ca': 'Presentam el nostre desenvolupament del sistema de traducció multilingüe de màquines per a la tasca de traducció multilingüe de màquines a gran escala a WMT 2021. Començant a formar el sistema de base proporcionat, vam investigar diverses tècniques per millorar la qualitat de traducció en el subconjunt de llengües. Vam poder millorar significativament la qualitat de traducció adaptant el sistema al subconjunt de llengües destinataris i generant dades sintètiques amb el model inicial. Les tècniques aplicades amb èxit en traducció de màquines multillengües de zero (per exemple regularitzador de la similitud) només tenien un efecte mínim en el rendiment final de la traducció.', 'jv': 'Awak dhéwé nggawe pengguna sing dibutuhke sistem kanggo tarjamahan karo akeh sistem multilanggar kanggo nggawe barang multilanggar sampek bantuan neng WT 2020 1. Nambah kang nggawe sistem sing nyimpen banget, kéné ujian akeh teka-teka kanggo nggawe kapan tarjamahan kanggo ngerewake tarjamahan kanggo nggawe barang langa. Awak dhéwé iso ngéwangi luwih-luwih kanggo ngerasar kaliwat itoleh ning sistem sak dadi supoyo tarjamahan kanggo nggawe barang-sistem sing berarti dadi sistem sing sampeyan senetik nggambar model inipun. text-tool-action', 'sk': 'Na WMT 2021 predstavljamo razvoj večjezičnega sistema strojnega prevajanja za obsežno večjezično strojno prevajanje. Na začetku predvidenega osnovnega sistema smo raziskali več tehnik za izboljšanje kakovosti prevajanja na ciljni podskupini jezikov. Kakovost prevajanja smo lahko bistveno izboljšali s prilagoditvijo sistema ciljnemu podnaboru jezikov in ustvarjanjem sintetičnih podatkov z uporabo začetnega modela. Tehnike, ki so bile uspešno uporabljene pri večjezičnem strojnem prevajanju brez strela (npr. urejevalnik podobnosti), so imele le manjše učinke na končno prevajanje.', 'bo': 'ང་ཚོས་རྒྱལ་སྤྱིའི་ནང་དུ་ཡིག་ཆ་མང་ཆེ་ཤོས་སྤྱོད་ཆས་ལུགས་སྤྱོད་ཆས་ཀྱི་ལས་རིམ་མང་ཆེ་ཤོས་ཡོད་པའི་ནང་དུ་WMT 2021 ང་ཚོས་བྱིས་ཡོད་པའི་རྨང་གཞིའི་མ་ལག་གི་བཟོ་བཅོས་ལ་དབྱེ་རིགས་གཞན་དང་ལྟ་ཞིབ་བྱས་པ་ཡིན་ན་སྐད་ཡིག We were able to significantly improve the translation quality by adapting the system to the target subset of languages and by generating synthetic data using the initial model. དངོས་སྤྱིར་བཏང་བ་དེ་ལྟར་མཐའ་ནས་རྩིས་འཁོར་གྱི་སྣ་ཚོགས་རྩིས་འཁོར་ནང་བེད་སྤྱོད་བྱས་ན།', 'he': 'אנחנו מציגים את הפיתוח שלנו של מערכת התרגום של מכונות רבות שפות למשימת התרגום של מכונות רבות שפות בקנה גדולה ב-WMT 2021. Starting form the provided baseline system, we investigated several techniques to improve the translation quality on the target subset of languages.  היינו מסוגלים לשפר באופן משמעותי את איכות התרגום על ידי להסתגל המערכת למטרה תת-קבוצת שפות וביצור נתונים סינטטיים באמצעות המודל הראשון. טכניקות שהשתמשו בהצלחה בתרגום מכונות רבות ללא יריות (למשל מתרגם דומות) היו רק השפעה קטנה על ביצועי התרגום הסופי.', 'ha': "Tuna gaurar da mafarin tarjibu na'urar mulki-birnin na'ura wa aikin fassarori masu girma na masu mulki-lugha a WMT 2021. @ info: whatsthis Mun iya amfani da shirin ayuka na farko. Technical has successful applied in no-shot multilingular translation (e.g. Similar Registrator) only had an yi amfani da ƙarami kan fassarar na ƙarshen translation."}
{'en': 'Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task', 'ar': 'أنظمة الترجمة الآلية متعددة اللغات من Microsoft للمهمة المشتركة WMT21', 'es': 'Sistemas de traducción automática multilingüe de Microsoft para tareas compartidas WMT21', 'fr': 'Systèmes de traduction automatique multilingues de Microsoft pour les tâches partagées WMT21', 'pt': 'Sistemas de tradução automática multilíngue da Microsoft para tarefa compartilhada WMT21', 'zh': '微软以WMT21共事者多言机器翻译统', 'hi': 'WMT21 साझा कार्य के लिए Microsoft से बहुभाषी मशीन अनुवाद सिस्टम', 'ru': 'Многоязычные системы машинного перевода от Microsoft для совместной задачи WMT21', 'ja': 'WMT 21共有タスク用マイクロソフトからの多言語機械翻訳システム', 'ga': 'Córais Ilteangacha Aistriúcháin Meaisín ó Microsoft le haghaidh Tasc Comhroinnte WMT21', 'hu': 'Többnyelvű gépi fordító rendszerek a Microsoft for WMT21 Shared Task-tól', 'el': 'Πολυγλωσσικά συστήματα μηχανικής μετάφρασης από τη Microsoft για κοινή εργασία WMT21', 'ka': 'WMT21 shared task', 'lt': 'Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task', 'mk': 'Мултијазични машински транслативни системи од Мајкрософт за WMT21 споделена задача', 'ms': 'Sistem Terjemahan Mesin Berbahasa dari Microsoft untuk Tugas Berkongsi WMT21', 'ml': 'മൈക്രോസോഫ്റ്റില്\u200d നിന്നും മൈക്രോസോഫ്റ്റില്\u200d നിന്നും പല ഭാഷ മെഷീന്\u200d പരിഭാഷകള്\u200d WMT21 പങ്കുചേര്\u200dത്ത പണ', 'mt': 'Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task', 'no': 'Multilingual Machine Translation Systems frå Microsoft for WMT21 delt oppgåve', 'pl': 'Wielojęzyczne systemy tłumaczenia maszynowego firmy Microsoft dla WMT21 Shared Task', 'it': 'Sistemi di traduzione automatica multilingue di Microsoft per WMT21 Shared Task', 'kk': 'WMT21 ортақтастырылған тапсырма үшін Microsoft- ден көп тілді машинаны аудару жүйелеріName', 'sr': 'Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task', 'so': 'Turjumista luuqadaha badan ee Machine', 'si': 'Name', 'ro': 'Sisteme de traducere automată multilingvă de la Microsoft pentru WMT21 Activitate partajată', 'sv': 'FlersprĂ¥kiga maskinĂ¶versĂ¤ttningssystem frĂ¥n Microsoft fĂ¶r WMT21 Delad uppgift', 'ur': 'Name', 'ta': 'WMT21 பகிர்ந்த பணிக்கான மைக்ரோசாஃப்டில் இருந்து பல மொழி இயந்திரம் மொழிபெயர்ப்பு அமைப்புகள்', 'mn': 'WMT21 хуваалтын ажлын Microsoft-ээс олон хэлний машин хөгжүүлэх системүүд', 'uz': 'Name', 'vi': 'Dịch lắp máy đa ngôn ngữ từ Microsoft cho Nhiệm vụ chia sẻ WM', 'bg': 'Многоезични системи за машинен превод от споделена задача', 'nl': 'Meertalige machinevertaalsystemen van Microsoft voor WMT21 Gedeelde taak', 'da': 'Flersprogede maskinoversættelsessystemer fra Microsoft til WMT21 Delt opgave', 'id': 'Sistem Terjemahan Mesin Berbahasa dari Microsoft untuk Tugas Berkongsi WMT21', 'hr': 'Multijezički sustavi prevoda strojeva iz Microsoft za WMT21 zajednički zadatak', 'fa': 'سیستم\u200cهای ترجمه ماشین\u200cهای زیادی زبان از مایکروسافت برای کار مشترک WMT21', 'sw': 'Mifumo ya Tafsiri ya Mashiniki ya lugha mbalimbali kutoka Microsoft kwa ajili ya kazi ya WMT21', 'de': 'Mehrsprachige maschinelle Übersetzungssysteme von Microsoft für WMT21 Shared Task', 'tr': "WMT21 Mazmunlar üçin Microsoft'dan köp dilli Mazmunlar terjime sistemleri", 'ko': 'WMT21 공유 작업을 위한 Microsoft 다국어 번역 시스템', 'am': 'Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task', 'sq': 'Sistemet shumëgjuhëse të përkthimit të makinave nga Microsoft për detyrën e përbashkët WMT21', 'hy': 'Բազլեզու մեքենայի թարգմանման համակարգեր Microsoft-ից', 'bn': 'WMT21 শেয়ার করা কাজের জন্য মাইক্রোসফ্ট থেকে বহুভাষী মেশিন অনুবাদ সিস্টেম', 'az': "WMT21 paylaşdırılmış işlər üçün Microsoft'dan çoxlu dilli Machine Translation Systems", 'af': 'Name', 'cs': 'Vícejazyčné strojové překlady systémy od společnosti Microsoft pro WMT21 Shared Task', 'fi': 'Monikieliset konekäännösjärjestelmät Microsoftilta WMT21 Shared Task', 'bs': 'Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task', 'et': 'Microsofti mitmekeelsed masintõlke süsteemid WMT21 jaoks jagatud ülesande jaoks', 'ca': 'Sistemes multilingües de traducció de màquines de Microsoft per a una tasca compartida WMT21', 'sk': 'Večjezični sistemi strojnega prevajanja iz Microsofta za opravilo WMT21 v skupni rabi', 'he': 'מערכות תרגום מכונות רבות ממיקרוסופט למשימה משותפת WMT21', 'ha': '@ action', 'jv': 'Multi-Linguial Mas Terjamahan Sistem Mulai komputer kanggo komputer Wmas', 'bo': 'Microsoft for WMT21 Shared Task'}
{'en': 'This report describes Microsoft’s ', 'ar': 'يصف هذا التقرير أنظمة الترجمة الآلية من Microsoft للمهمة المشتركة WMT21 في الترجمة الآلية متعددة اللغات على نطاق واسع. لقد شاركنا في جميع مسارات التقييم الثلاثة بما في ذلك المسار الكبير واثنين من المسارات الصغيرة حيث يكون الأول غير مقيد والآخران مقيدان تمامًا. تمت تهيئة عمليات الإرسال النموذجية الخاصة بنا إلى المهمة المشتركة باستخدام DeltaLM ، وهو نموذج عام لفك التشفير متعدد اللغات تم تدريبه مسبقًا مسبقًا ، وتم ضبطه وفقًا للبيانات الموازية الضخمة التي تم جمعها ومصادر البيانات المسموح بها وفقًا لإعدادات التتبع ، جنبًا إلى جنب مع تطبيق التعلم التدريجي والتكراري مناهج الترجمة العكسية لتحسين الأداء بشكل أكبر. احتلت تقديماتنا النهائية المرتبة الأولى على ثلاثة مسارات من حيث مقياس التقييم التلقائي.', 'es': 'Este informe describe los sistemas de traducción automática de Microsoft para la tarea compartida WMT21 sobre traducción automática multilingüe a gran escala. Participamos en las tres pistas de evaluación, incluidas las pistas grandes y las dos pequeñas, donde la primera no tiene restricciones y las dos últimas están totalmente restringidas. Nuestros envíos de modelos a la tarea compartida se inicializaron con DeltaLM, un modelo genérico de codificador-decodificador multilingüe previamente entrenado, y se ajustaron en consecuencia con los vastos datos paralelos recopilados y las fuentes de datos permitidas de acuerdo con la configuración de la pista, junto con la aplicación de aprendizaje progresivo e iterativo enfoques de retrotraducción para mejorar aún más el rendimiento. Nuestros envíos finales ocuparon el primer lugar en tres temas en términos de la métrica de evaluación automática.', 'fr': "Ce rapport décrit les systèmes de traduction automatique de Microsoft pour la tâche partagée WMT21 sur la traduction automatique multilingue à grande échelle. Nous avons participé aux trois pistes d'évaluation, y compris la grande piste et les deux petites pistes où la première n'est pas contrainte et les deux dernières sont entièrement limitées. Nos soumissions de modèles pour la tâche partagée ont été initialisées avec DeltaLM, un modèle générique encodeur-décodeur multilingue pré-entraîné, et affinées en conséquence avec les vastes données parallèles collectées et les sources de données autorisées en fonction des paramètres de piste, ainsi que l'application d'un apprentissage progressif et itératif des approches de rétro-traduction pour améliorer encore les performances. Nos soumissions finales se sont classées premières sur trois pistes en termes de métrique d'évaluation automatique.", 'pt': 'Este relatório descreve os sistemas de tradução automática da Microsoft para a tarefa compartilhada WMT21 em tradução automática multilíngue em grande escala. Participamos de todas as três trilhas de avaliação, incluindo Large Track e duas Small Tracks, onde a primeira é irrestrita e as duas últimas são totalmente restritas. Nossos envios de modelo para a tarefa compartilhada foram inicializados com o DeltaLM, um modelo genérico de codificador-decodificador multilíngue pré-treinado, e ajustados de forma correspondente com os vastos dados paralelos coletados e fontes de dados permitidas de acordo com as configurações da trilha, juntamente com a aplicação de aprendizado progressivo e iterativo abordagens de retrotradução para melhorar ainda mais o desempenho. Nossas submissões finais ficaram em primeiro lugar em três faixas em termos de métrica de avaliação automática.', 'zh': '本言微软大言机器翻译者WMT21共事机器翻译统。 凡三评估,包大二小,前不拘束,后二全受限。 凡受事之法 DeltaLM(通习多言编码器-解码器)初始化,并行数微,轨道设数据源,以渐进式学迭代反译以进一步提高性。 自评指标,终提第三。', 'hi': 'यह रिपोर्ट बड़े पैमाने पर बहुभाषी मशीन अनुवाद पर WMT21 साझा कार्य के लिए Microsoft की मशीन अनुवाद सिस्टमका वर्णन करती है. हमने बड़े ट्रैक और दो छोटे पटरियों सहित सभी तीन मूल्यांकन पटरियों में भाग लिया जहां पूर्व एक अप्रतिबंधित है और बाद के दो पूरी तरह से विवश हैं। साझा कार्य के लिए हमारे मॉडल सबमिशन को DeltaLM, एक सामान्य पूर्व-प्रशिक्षित बहुभाषी एन्कोडर-डिकोडर मॉडल के साथ शुरू किया गया था, और विशाल एकत्रित समानांतर डेटा के साथ तदनुसार ठीक-ट्यून किया गया था और ट्रैक सेटिंग्स के अनुसार डेटा स्रोतों की अनुमति दी गई थी, साथ ही साथ प्रगतिशील सीखने और पुनरावर्ती बैक-ट्रांसलेशन दृष्टिकोणों को लागू करने के साथ-साथ प्रदर्शन में और सुधार करने के लिए। हमारे अंतिम प्रस्तुतियों को स्वचालित मूल्यांकन मीट्रिक के मामले में तीन पटरियों पर पहले स्थान पर रखा गया है।', 'ja': 'このレポートでは、大規模な多言語機械翻訳に関するWMT 21共有タスクのためのマイクロソフトの機械翻訳システムについて説明します。前者は制約がなく、後者の2つは完全に制約されている大型トラックと小型トラックの2つを含む3つの評価トラックすべてに参加しました。私たちの共有タスクへのモデル提出は、汎用の事前訓練された多言語エンコーダーデコーダーモデルであるDeltaLMで初期化され、トラック設定に従って収集された膨大な並列データと許可されたデータソースと対応して微調整され、さらにパフォーマンスを向上させるためにプログレッシブラーニングと反復翻訳アプローチを適用しました。最終的な提出物は、自動評価指標で3つのトラックで1位になりました。', 'ru': 'В этом отчете описываются системы машинного перевода Microsoft для совместной задачи WMT21 по широкомасштабному многоязычному машинному переводу. Мы участвовали во всех трех оценочных направлениях, включая Большое направление и два Малых направления, где первое не ограничено, а два последних полностью ограничены. Наши представления модели для общей задачи были инициализированы с помощью DeltaLM, универсальной предварительно обученной многоязычной модели кодировщик-декодер, и отлажены соответственно с огромным объемом собранных параллельных данных и разрешенных источников данных в соответствии с настройками трека, наряду с применением прогрессивного обучения и итеративных подходов обратной трансляции для дальнейшего улучшения производительности. Наши окончательные заявки заняли первое место по трем показателям с точки зрения автоматической оценки.', 'ga': 'Déanann an tuarascáil seo cur síos ar chórais aistriúcháin mheaisín Microsoft don tasc roinnte WMT21 ar aistriúchán meaisín ilteangach ar scála mór. Ghlacamar páirt i ngach ceann de na trí rian meastóireachta lena n-áirítear Rian Mór agus dhá Rian Beag nach bhfuil srianta ar an gcéad cheann agus tá an dá cheann deiridh srianta go hiomlán. Cuireadh tús lenár n-aighneachtaí samhail don tasc comhroinnte le DeltaLM, samhail ionchódóra-ionchódóra ilteangach cineálach réamhoilte, agus rinneadh mionchoigeartú dá réir ar na sonraí comhthreomhara ollmhóra a bailíodh agus ceadaíodh foinsí sonraí de réir suímh rian, mar aon le foghlaim fhorásach agus atriallach a chur i bhfeidhm. cur chuige ais-aistriúcháin chun an fheidhmíocht a fheabhsú tuilleadh. Bhain ár n-aighneachtaí deiridh an chéad áit amach ar thrí rian i dtéarmaí na méadrach meastóireachta uathoibríoch.', 'hu': 'Ez a jelentés a Microsoft gépi fordítási rendszereit ismerteti a WMT21 megosztott feladathoz a nagyméretű, többnyelvű gépi fordítással kapcsolatos feladathoz. Mindhárom értékelési pályán részt vettünk, beleértve a Large Track-t és a két Small Track-t is, ahol az előbbi korlátlan, az utóbbi kettő teljesen korlátozott. A megosztott feladathoz történő modellbeküldéseinket a DeltaLM, egy általános, előre képzett többnyelvű kódoló-dekódoló modellel inicializáltuk, és ennek megfelelően finomhangoltuk a hatalmas összegyűjtött párhuzamos adatokkal, és engedélyeztük az adatforrásokat a sávbeállítások szerint, valamint progresszív tanulási és iteratív visszafordítási megközelítések alkalmazásával a teljesítmény további javítása érdekében. Az automatikus értékelési metrika szempontjából három pályán végső beadványaink első helyezésre kerültek.', 'el': 'Αυτή η έκθεση περιγράφει τα συστήματα μηχανικής μετάφρασης της για την κοινή εργασία WMT21 για τη μεγάλης κλίμακας πολυγλωσσική μηχανική μετάφραση. Συμμετείχαμε και στις τρεις διαδρομές αξιολόγησης συμπεριλαμβανομένων των μεγάλων και των δύο μικρών κομματιών όπου το πρώτο είναι απεριόριστο και τα δύο τελευταία είναι πλήρως περιορισμένα. Οι υποδείξεις μας για την κοινή εργασία αρχικοποιήθηκαν με ένα γενικό προ-εκπαιδευμένο πολύγλωσσο μοντέλο κωδικοποιητή-αποκωδικοποιητή, και προσαρμόστηκαν ανάλογα με τα τεράστια συλλεγόμενα παράλληλα δεδομένα και επιτρεπόμενες πηγές δεδομένων σύμφωνα με τις ρυθμίσεις κομματιού, μαζί με την εφαρμογή προοδευτικής μάθησης και επαναληπτικών προσεγγίσεων αντίστροφης μετάφρασης για περαιτέρω βελτίωση της απόδοσης. Οι τελικές μας υποβολές κατατάχθηκαν πρώτοι σε τρία κομμάτια από την άποψη της μετρικής αυτόματης αξιολόγησης.', 'kk': 'Бұл хабарлама WMT21 ортақтастырылған тапсырманың Microsoft- тың машинаның аудару жүйелерін үлкен көп тілді машинаны аудару үшін анықтайды. Name Біз үш бағалау жолдарына қатысу үшін Үлкен Жолсызық және екі Шағын Жолсызық болдық. Біріншісі шектелмеген және соңғы екі шектелмеген. Біздің ортақ тапсырманың үлгілеріміз DeltaLM дегенмен бастады. Бұл көп тілді кодер- декодер үлгісі, және бұл көп параллель деректерді жинақталған және деректер көзінің баптауларына сәйкес келтірілген деректер көзіне рұқсат етілген, және қайталану үшін қара Біздің соңғы жіберіміз автоматты түрде бағалау метрикалық түрде үш жолдарда бірінші жолды.', 'it': "Questo rapporto descrive i sistemi di traduzione automatica Microsoft per l'attività condivisa WMT21 sulla traduzione automatica multilingue su larga scala. Abbiamo partecipato a tutte e tre le tracce di valutazione tra cui Large Track e due Small Tracks dove il primo è privo di vincoli e gli ultimi due sono completamente vincolati. I nostri modelli inviati all'attività condivisa sono stati inizializzati con DeltaLM, un modello generico pre-addestrato di encoder-decoder multilingue, e perfezionati di conseguenza con i vasti dati paralleli raccolti e consentiti fonti di dati in base alle impostazioni di traccia, insieme all'applicazione di approcci di apprendimento progressivo e di back-translation iterative per migliorare ulteriormente le prestazioni. I nostri contributi finali si sono classificati al primo posto su tre tracce in termini di metrica di valutazione automatica.", 'lt': 'Šiame pranešime aprašomos Microsoft mašinų vertimo sistemos, skirtos bendroms WMT21 užduotims, susijusioms su didelio masto daugiakalbiu mašinų vertimu. Dalyvavome visuose trijuose vertinimo etapuose, įskaitant didelę kelią ir du mažus kelius, kuriuose pirmoji yra neribota, o antroji – visiškai apribota. Mūsų pavyzdiniai pranešimai apie bendrą užduotį buvo inicijuoti naudojant DeltaLM, generinį iš anksto parengtą daugiakalbį kodavimo kodavimo model į, ir atitinkamai patobulinti atsižvelgiant į plačius surinktus lygiagrečius duomenis ir leisti duomenų šaltinius, atsižvelgiant į juostos nustatymus, kartu taikant laipsnišką mokymąsi ir pakartotinius atgalinio vertimo metodus, siekiant toliau gerinti rezultatus. Mūsų galutiniai pareiškimai pirmiausia buvo suskirstyti į tris etapus pagal automatinio vertinimo metriją.', 'mk': 'Овој извештај ги опишува машинските преведувачки системи на Мајкрософт за заедничката задача на WMT21 за големиот мултијазичен превод на машините. Ние учествувавме на сите три проценки, вклучувајќи ја и Големата трага и две мали траги каде што поранешната е неограничена и последните две се целосно ограничени. Нашите моделни поднесувања на заедничката задача беа иницијализирани со DeltaLM, генеричен предобучен мултијазичен модел на кодер-декодирач, и финетирани односно со огромните собрани паралелни податоци и дозволени извори на податоци според поставувањата на траката, заедно со апликацијата на прогресивно учење и итеративните Нашите последни поднесувања се рангираа прво на три патеки во поглед на автоматската метрика на проценка.', 'ml': '@ info: status We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  പങ്കെടുക്കുന്ന ജോലിയിലേക്കുള്ള നമ്മുടെ മോഡല്\u200d സജ്ജീകരണങ്ങള്\u200d ഡല്\u200dടാല്\u200dഎമില്\u200d തുടങ്ങിയിരുന്നു. ഒരു സാധാരണ മുന്\u200dപരിശീലിക്കപ്പെട്ട പലില്\u200d കോഡോര്\u200d മോഡല്\u200d, പ്രധാനപ്പെട്ട പാരാള്\u200dലേല്\u200d ഡേറ്റാല്\u200d ഡേ നമ്മുടെ അവസാനത്തെ കീഴടങ്ങള്\u200d ആദ്യം മൂന്ന് ട്രാക്കില്\u200d നിര്\u200dത്തിയിരിക്കുന്നു. ആത്മാര്\u200dത്ഥികമായ വിലാ', 'mn': 'Энэ мэдээллийг WMT21-ын машины хөрөнгө оруулах системийг олон хэлний машины хөрөнгө оруулах талаар илэрхийлж байна. Бид бүх 3 дүгнэлтийн загварт том загвар болон хоёр жижиг загвар хамт оролцсон. Эхний загвар нь хязгаарлагддаггүй, дараагийн хоёр нь бүрэн хязгаарлагддаг. Бидний хуваалцагдсан ажлын загварын сургалтыг DeltaLM-ээр эхлүүлсэн бөгөөд олон хэл дээр сургалтын коддогч загвар юм. Мөн олон нийлүүлэгдсэн параллел өгөгдлийн хувьд багтаж өгөгдлийн эх үүсвэртэй холбоотой бөгөөд өгөгдлийн эх үүсвэрүүдтэй холбоотой бөгөөд хөгжлийн суралца Бидний сүүлийн хэвлэл нь автоматически дүгнэлтийн метрийн хувьд эхлээд гурван шугам дээр байв.', 'no': 'Denne rapporten beskriver Microsoft sin maskinsomsetjingssystem for WMT21 delt oppgåve på stor fleirspråk maskinsomsetjing. Vi delta i alle tre evalueringsspor, inkludert stor spor og to små spor der den tidlegare ikkje er avgrensa og dei siste to er fullstendig begrensa. Modellene våre til delt oppgåve er starta med DeltaLM, eit generiskt multispråk koderingsmodell som er forelært, og fint tilsvarande med dei vaste samla parallelle data og tillatte datakjeldene etter sporinnstillingar, saman med å bruka progressiv læring og gjentaktive tilbakeomsetjingar tilnærmingar for å forbedra utviklinga. Våre siste oppføringar rangerte først på tre spor i uttrykket av den automatiske evalueringsmetriken.', 'pl': 'Niniejszy raport opisuje systemy tłumaczenia maszynowego firmy Microsoft dla wspólnego zadania WMT21 dotyczącego wielojęzycznego tłumaczenia maszynowego na dużą skalę. Uczestniczyliśmy we wszystkich trzech ścieżkach ewaluacyjnych, w tym w Large Track i dwóch Small Track, gdzie pierwszy jest nieograniczony, a drugi dwa są w pełni ograniczone. Nasze zgłoszenia modeli do wspólnego zadania zostały zainicjowane za pomocą DeltaLM, ogólnego, wstępnie przeszkolonego wielojęzycznego modelu kodera-dekodera, i dostosowane odpowiednio do ogromnych zebranych danych równoległych i zezwalających na źródła danych zgodnie z ustawieniami ścieżek, wraz z zastosowaniem progresywnego uczenia się i iteracyjnego podejścia wstecznego do dalszej poprawy wydajności. Nasze ostateczne zgłoszenia zajęły pierwsze miejsce na trzech torach pod względem metryki automatycznej oceny.', 'ro': 'Acest raport descrie sistemele de traducere automată Microsoft pentru activitatea partajată WMT21 privind traducerea automată multilingvă la scară largă. Am participat la toate cele trei piese de evaluare inclusiv Large Track și două Small Tracks unde prima este fără constrângeri, iar cele din urmă două sunt complet constrânse. Depunerile noastre de modele la sarcina partajată au fost inițializate cu DeltaLM, un model generic pre-instruit multilingv codificator-decodor, și reglate corespunzător cu vastele date paralele colectate și permise surse de date în funcție de setările de urmărire, împreună cu aplicarea de învățare progresivă și abordări iterative back-translation pentru a îmbunătăți în continuare performanța. Trimiterile noastre finale s-au clasat pe primul loc pe trei piese în ceea ce privește metrica de evaluare automată.', 'sr': 'Ovaj izveštaj opisuje sisteme prevoda mašine za WMT21 zajednièki zadatak o velikoj multijezičkoj prevodu mašine. Učestvovali smo u svim tri traga procjene, uključujući Velike tragove i dve male tragove, gde je bivša bez ograničenja, a poslednja dva su potpuno ograničena. Naši podaci model a zajedničkog zadatka su inicijalizovani sa DeltaLM, generičnim pre-obučenim multijezičkim koderom-dekoderom modelom, i odgovarajući u skladu sa ogromnim prikupljenim paralelnim podacima i dozvoljenim izvorima podataka u skladu sa nastavama praćenja, zajedno s primjenom progresivnih pristupa učenja i iterativnog povratka za daljnje poboljšavanje funkcije. Naši poslednji podaci su prvi na tri traga u smislu automatske procjene metrike.', 'ka': 'Name ჩვენ ყველა სამი განსაზღვრებული სინამდვილეში გავაკეთებთ, რომელიც დიდი სინამდვილეში და ორი პატარა სინამდვილეში, სადაც მხოლოდ სინამდვილეში არ განსაზღვრებული და შემდე ჩვენი მოდელური მოდელური მონაცემები განსაზღვრებული მოდელზე DeltaLM-ის თნციალურად იქნება, რომელიც განსაზღვრებული მრავალური მრავალური კოდერი-ევკოდერის მოდელზე, და კოდენტურად კოდენტურად კოდენტურად კოდენტურად დააყენებული პარალელური მონაც ნაქთრვ ოჲჟლვენთ ოპჲეყლზვნთწ ჟა ოყპგთ ნა რპთ ჟლვეთ ჲრ მვრპთკა ჲრ აგრჲმართფნარა ვკჟვნუთწ.', 'mt': 'Dan ir-rapport jiddeskrivi s-sistemi ta’ traduzzjoni bil-magni tal-Microsoft għall-kompitu kondiviż tad-WMT21 dwar traduzzjoni bil-magni multilingwi fuq skala kbira. Parteċipajna fit-tliet binarji ta’ evalwazzjoni kollha inklużi l-binarji l-kbar u żewġ binarji ż-żgħar fejn l-ewwel waħda mhijiex ristretta u t-tnejn tal-aħħar huma ristretti bis-sħiħ. Our model submissions to the shared task were initialized with DeltaLM, a generic pre-trained multilingual encoder-decoder model, and fine-tuned correspondingly with the vast collected parallel data and allowed data sources according to track settings, together with applying progressive learning and iterative back-translation approaches to further improve the performance.  Is-sottomissjonijiet finali tagħna kklassifikaw l-ewwel fuq tliet binarji f’termini tal-metrika tal-evalwazzjoni awtomatika.', 'si': 'Name අපි ලොකු ට්\u200dරෑක් සහ පොඩි ට්\u200dරෑක් දෙකක් සම්බන්ධ විශ්ලේෂණය තුනක් තියෙන්නේ මුලින් ප්\u200dරවේශනය නැති තියෙන්නේ. අන් අපේ මොඩේල් සම්පූර්ණ වැඩක් වෙනුවෙන් DeltaLM එක්ක පටන් ගත්තා, සාමාන්\u200dය ප්\u200dරීක්ෂණිත වැඩි භාෂාවික කෝඩේර් කෝඩේර් මොඩේල් එක්ක, සහ ගොඩක් සම්පූර්ණ සම්පූර්ණ දත්ත ස අපේ අන්තිම පිළිගන්න ප්\u200dරධාන තුනක් පටන් ගත්තා ස්වයංක්\u200dරිය විශ්ලේෂණ මෙට්\u200dරික් වලට.', 'so': "Wargelinta waxaa ku qoran qoraalka microsoft's machine translation systems for the WMT21-shared task ku saabsan tarjumaadda luuqadaha badan. We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  Tusaale u soo dirista shaqada qayb-ka ah waxaa la bilaabay DeltaLM, model generic-trained multilingo-encoder-decoder, iyo si u eg, waxaana loo ogolaaday macluumaad faro badan oo lambarka ah, waxaana loo ogolaaday sourceed data si waafaqsan qoraalka, iyo codsashada waxbarasho progressive and iterative backtarjuman, si ay u sii kordhiso performance. Sujuudyadayadii ugu dambeeyey waxay marka ugu horraysay sadex jid oo ku qoran qaab ka mid ah baaritaanka qiimeynta.", 'sv': 'I den h채r rapporten beskrivs Microsofts maskin철vers채ttningssystem f철r den delade uppgiften WMT21 om storskalig flerspr책kig maskin철vers채ttning. Vi deltog i alla tre utv채rderingssp책r inklusive Large Track och tv책 Small Tracks d채r den f철rra 채r obegr채nsad och de senare tv책 채r helt begr채nsade. V책ra modellinl채mningar till den delade uppgiften initierades med DeltaLM, en generisk f철rutbildad flerspr책kig encoder-avkodarmodell, och finjusterades motsvarande de stora insamlade parallella data och till채t datak채llor enligt sp책rinst채llningar, tillsammans med till채mpning av progressivt l채rande och iterativa bak책t철vers채ttningsmetoder f철r att ytterligare f철rb채ttra prestandan. V책ra slutliga inl채mningar rankades f철rst p책 tre sp책r n채r det g채ller den automatiska utv채rderingsmetoden.', 'ur': 'یہ راپورت مایکروسفوٹ کے ماشین ترجمہ سیسٹم کو WMT21 کے لئے بڑے مزید زبان ماشین ترجمہ کے ذریعہ مشترک کام کے لئے بیان کرتا ہے. ہم نے تمام تین ارزیابی ٹریکیوں میں شامل ہوئے بڑے ٹریک اور دو چھوٹے ٹریک جن میں پہلی ٹریک بغیر محدود ہوئی ہے اور آخرین دو کامل محدود ہوئے ہیں ہماری مدل مہمانی مشترک کام کے لئے ڈیلٹال لم کے ساتھ آغاز کی گئی تھی، ایک ژنرال پیش آموزش کی مہمانی زبان کا کوڈر-ڈکوڈر موڈل، اور بہت بڑی مشترک ڈیٹا کے ساتھ مہمانی کر دی گئی تھی اور ڈیٹا سورج کو ترک سیٹیوں کے مطابق ترک سیٹیوں کے مطابق اجازت دی گئی تھی، اور اس کے ساتھ پیشرفت ہماری آخری تحویل تین ٹریک پر پہلے درجہ پہنچائی تھی آٹوٹی تحویل متریک کے مطابق۔', 'ta': '@ info பெரிய தடங்கள் மற்றும் இரண்டு சிறிய தடங்கள் உள்ள அனைத்து மூன்று மதிப்பு தடங்களுக்கும் நாங்கள் பங்கிடப்பட்டோம் முன்னால் ஒன்று ந பகிர்ந்த பணிக்கு எங்கள் மாதிரி ஒப்புக்கொடுக்கப்பட்டது டெல்டால்எம், பொதுவான முன்பயிற்சிக்கப்பட்ட பல மொழி குறியீட்டு குறியீட்டு மாதிரியாக துவங்கப்பட்டது, பொருத்தமான இணைப்பு தகவல் மற்றும் பொருத் எங்கள் இறுதியாக ஒப்புகள் மூன்று தடங்களில் முதலில் தானாகவே ஆய்வு மெட்ரிக்கு முறையில் முதலில் உள்ளது.', 'ms': 'Laporan ini menggambarkan sistem terjemahan mesin Microsoft untuk tugas berkongsi WMT21 pada terjemahan mesin berbilang bahasa skala besar. We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  Penghantaran model kita ke tugas berkongsi telah diawalkan dengan DeltaLM, model pengekod-dekoder berbilang-bahasa yang berlatih-biasa, dan disesuaikan dengan sesuai dengan data paralel yang terkumpul luas dan dibenarkan sumber data mengikut tetapan trek, bersama-sama dengan melaksanakan pembelajaran progresif dan pendekatan terjemahan-belakang iteratif untuk meningkatkan prestasi lebih lanjut. Pemberian terakhir kami berturut-turut di tiga trek dalam terma metrik penilaian automatik.', 'uz': "@ info We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  Bulgan vazifani qayta ishlatish modelimiz DeltaLM bilan ishga tushirilgan, bir necha tildan oldingi kodlash modeli bilan birinchi narsa ishga tushirilgan, va juda ko'proq tarjima maʼlumot bilan juda bogʻliq tarjima qilingan va tarjima maʼlumot manbaslarini taʼminlovchiga ruxsat berish va taʼminlovchi tizimni bajarish uchun bajarish mumkin. Bizning oxirgi imkoniyatlarimiz avtomatik qiymatni metrik darajada uchta yo'qni boshlagan.", 'vi': 'Bản báo cáo này mô tả hệ thống dịch phiên bản máy của Microsoft với tập đoàn WM21, chia s ẻ nhiệm vụ dịch thiết bị máy rộng rãi. Chúng tôi tham gia cả ba đường đánh giá bao gồm Đường ray Lớn và hai Đường ray nhỏ nơi con trước chưa được huấn luyện và hai con sau hoàn toàn bị hạn chế. Phần mềm của chúng tôi được cung cấp cho công việc chia sẻ đã được khởi tạo bằng DeltaxLM, một mẫu mã hóa đa dạng đa dạng đa dạng đã được đào tạo sẵn, và chỉnh chính xác tương ứng với dữ liệu song song song song tích khổng lồ thu thập và cho nguồn dữ liệu theo thiết lập theo dấu vết, cùng với áp dụng các phương pháp đào tạo lại phiên dịch phụ để tăng hiệu suất. Phần kết thúc của chúng tôi xếp hạng đầu trên ba đường ray theo tiêu chuẩn đo lường tự động.', 'da': 'Denne rapport beskriver Microsofts maskinoversættelsessystemer til den delte WMT21-opgave vedrørende maskinoversættelse i stor skala. Vi deltog i alle tre evalueringsspor, herunder Large Track og to Small Tracks, hvor det første er ubegrænset og de sidstnævnte to er fuldt begrænset. Vores model indsendelser til den delte opgave blev initialiseret med DeltaLM, en generisk præuddannet flersproget encoder-dekoder model, og finjusteret tilsvarende med de store indsamlede parallelle data og tilladte datakilder i henhold til sporindstillinger, sammen med anvendelse af progressiv læring og iterativ back-translation tilgange for yderligere at forbedre ydeevnen. Vores endelige indsendelser rangerede først på tre spor med hensyn til den automatiske evalueringsmetric.', 'de': 'Dieser Bericht beschreibt die maschinellen Übersetzungssysteme von Microsoft für die gemeinsame Aufgabe WMT21 für mehrsprachige maschinelle Großübersetzung. Wir haben an allen drei Evaluationsstrecken teilgenommen, einschließlich Large Track und zwei Small Tracks, wobei ersteres uneingeschränkt ist und letztere zwei vollständig eingeschränkt sind. Unsere Modellübermittlungen für die gemeinsame Aufgabe wurden mit DeltaLM initialisiert, einem generischen, vortrainierten mehrsprachigen Encoder-Decoder-Modell, und entsprechend den umfangreichen gesammelten parallelen Daten und erlaubten Datenquellen gemäß Track-Einstellungen, zusammen mit der Anwendung von progressivem Lernen und iterativen Back-Translation-Ansätzen, um die Leistung weiter zu verbessern. Unsere endgültigen Einreichungen belegten in Bezug auf die automatische Auswertungsmetrik auf drei Spuren den ersten Platz.', 'bg': 'Този доклад описва системите за машинен превод на Майкрософт за споделената задача за мащабен многоезичен машинен превод. Участвахме и в трите писти за оценка, включително Голяма писта и две Малки писти, където първата е неограничена, а последните две са напълно ограничени. Нашите предложения за модели за споделената задача бяха инициализирани с генеричен предварително обучен многоезичен кодер-декодер модел и фино настроени съответно с огромните събрани паралелни данни и позволени източници на данни според настройките на пистата, заедно с прилагането на прогресивно обучение и итеративни подходи за обратен превод за допълнително подобряване на производителността. Окончателните ни предложения се класираха на първо място в три песни по отношение на автоматичната оценка.', 'nl': 'Dit rapport beschrijft de machinevertaalsystemen van Microsoft voor de gedeelde WMT21 taak voor grootschalige meertalige machinevertaling. We hebben deelgenomen aan alle drie de evaluatietracks waaronder Large Track en twee Small Tracks waarbij de eerste niet beperkt is en de laatste twee volledig beperkt zijn. Onze modellen voor de gedeelde taak werden geïnitialiseerd met DeltaLM, een generiek voorgetraind meertalig encoder-decoder-model, en afgestemd op de enorme verzamelde parallelle gegevens en toegestane gegevensbronnen volgens track-instellingen, samen met het toepassen van progressief leren en iteratieve back-translation benaderingen om de prestaties verder te verbeteren. Onze laatste inzendingen stonden als eerste op drie tracks in termen van de automatische evaluatie metric.', 'hr': 'Ovaj izvještaj opisuje sisteme prevoda stroja Microsoft-a za zajednički zadatak WMT21 o velikoj mjeri prevoda multijezičkih strojeva. Učestvovali smo u svim tri traga procjene, uključujući Velike tragove i dvije male tragove, gdje je bivša bez ograničenja, a posljednja dva su potpuno ograničena. Naši podaci model a zajedničkom zadatku inicijalizirani su s DeltaLM, generičnim predobučenim multijezičkim koderom-dekoderom modelom, i odgovarajući odgovarajući prilagođenim ogromnim prikupljenim paralelnim podacima i dozvoljenim izvorima podataka u skladu s nastavama praćenja, zajedno s primjenom progresivnih pristupa učenja i iterativnog prijevoza za daljnje poboljšavanje učink Naši posljednji podaci su prvi na tri traga u smislu automatske procjene metrike.', 'fa': 'این گزارش سیستم\u200cهای ترجمه مایکروسافت برای کار مشترک WMT21 در ترجمه ماشین\u200cهای زیادی زبان توصیف می\u200cکند. ما در تمام سه رده ارزیابی شرکت کردیم که شامل رده بزرگ و دو رده کوچک جایی که سابق غیر محدودیت شده و دوتا کاملا محدودیت شده اند. تحویل مدل ما به کار مشترک با DeltaLM شروع شد، یک مدل قانونی از پیش آموزش داده شده\u200cای که قانونی\u200cدهنده\u200cهای زیادی زبان\u200cها را تغییر داده\u200cاند، و با اطلاعات مشترک فراوان جمع می\u200cشود و منبع داده\u200cها را بر اساس تنظیمات ردیابی اجازه داده\u200cاند، همراه با تحویل آموزش\u200cهای پیشرفته\u200cای و ترجمه\u200cهای پشت\u200cتا آخرین تحویل ما اول در سه رد به عنوان متریک ارزیابی اتوماتیک درجه گرفته شد.', 'tr': "WMT21 üçin bu rapor Microsoft'yň maşynynyň terjime sistemlerini uly düzümlendir. Biz bütün üç deňlenme hatlarynda Uly Trek we iki Kiçi Trek dahil hem öňki däldir we soňky iki mümkin däldir. Biziň modimiz paylaşyk görevine gönderilmeleri DeltaLM bilen başlandyryldy, umumy öň-bilim kodçylyk-kodçylyk modeli we golaý parallel maglumatlar bilen süýtgedildi we veri çeşmeleri takip eden ýagdaýda süregen öwrenme we tekrar terjime etmek üçin golaýlaşýar. Biziň soňky görkezilişimiz awtomatik deňlenme metrikleri ýaly ilkinji gezek üç hatda hatda geçdi.", 'ko': '이 보고서는 마이크로소프트가 대규모 다국어 기계 번역을 위한 WMT21 공유 임무를 위한 기계 번역 시스템을 기술했다.우리는 큰 궤도와 두 개의 작은 궤도를 포함한 세 개의 평가 궤도에 참여했는데, 그 중 하나는 구속이 없고, 두 개는 완전히 구속되었다.우리가 공유 임무에 제출한 모델은델타LM으로 초기화된 것이다. 델타LM은 사전 훈련을 거친 유니버설 다중 언어 디코더 모델이고 궤도 설정에 따라 대량으로 수집된 병행 데이터와 허용된 데이터 원본을 사용하여 상응하는 마이크로스피커를 하는 동시에 점진적인 학습과 교체 번역 방법을 응용하여 성능을 향상시킨다.자동 평가 지표의 경우 우리가 최종적으로 제출한 자료가 세 가지 측면에서 1위를 차지했다.', 'sq': 'Ky raport përshkruan sistemet e përkthimit të makinave të Microsoft për detyrën e përbashkët të WMT21 në përkthimin e makinave në shkallë të madhe shumëgjuhëse. We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  Our model submissions to the shared task were initialized with DeltaLM, a generic pre-trained multilingual encoder-decoder model, and fine-tuned correspondingly with the vast collected parallel data and allowed data sources according to track settings, together with applying progressive learning and iterative back-translation approaches to further improve the performance.  Paraqitja jonë përfundimtare u rendit e para në tre gjurmë lidhur me vlerësimin automatik.', 'am': 'ይህ ሪፖርት የሜክሮፎት መሳሪያን ትርጉም ሲስቶችን ለWMT21 የተካፈለ ስራ በብዙ ልዩ ቋንቋዊ መሣሪያን ትርጓሜ ይናገራል፡፡ ሁለተኛይቱ አንዱ ሳይነካ እና ሁለተኛይቱ ሁለተኛው ግንብ በጭራሽ ግንኙነት ውስጥ በታላቁ መንገዶች እና ሁለት ትንሽ መንገዶች እና ሁለተኛው ግንኙነት ተጋርተናል፡፡ Our model submissions to the shared task were initialized with DeltaLM, a generic pre-trained multilingual encoder-decoder model, and fine-tuned correspondingly with the vast collected parallel data and allowed data sources according to track settings, together with applying progressive learning and iterative back-translation approaches to further improve the performance.  የኋለኛይቱ መልዕክታችን አስቀድሞ በሦስት መድረክ ላይ የራሳቸውን አካሄድ ማተሚያ ማድረግ ነው፡፡', 'sw': 'Taarifa hii inaelezea mfumo wa utafsiri wa mashine ya Microsoft kwa ajili ya kazi ya WMT21 inayoshirikishwa katika tafsiri ya mashine ya lugha nyingi. Tumeshiriki katika barabara zote tatu za uchunguzi ikiwa ni pamoja na Trabara kubwa na Miongo Miwili madogo ambapo mtaa wa zamani haujafungwa na pili mbili zimewekwa vikali. Ujumbe wetu wa mifano kwa kazi hiyo ya ushirikiano ulianzishwa na DeltaLM, modeli ya kodi ya lugha iliyoendelea kwa ujumla wa zamani, na yenye ujumla mzuri kwa kulingana na takwimu kubwa zilizokusanywa na kuruhusu vyanzo vya taarifa kwa mujibu wa kutekeleza mipango, pamoja na kutumia njia za kujifunza maendeleo na kutafsiri kwa ujasiri ili kuboresha ufanisi. Mawasiliano yetu ya mwisho yalikuwa ya kwanza katika njia tatu kwa ajili ya utafiti wa kujitegemea.', 'az': "Bu xəbər WMT21'nin böyük ölçülü çoxlu dilli maşın çevirilməsi üçün Microsoft maşın çevirim sistemlərini təsdiqləyir. Biz bütün üç müqayisədə Büyük Trak və iki Küçük Trak də katıldıq. Öncüsünün müqayisədə olmadığı və son ikisinin tamamilə müqayisədə olmadığı yerdə. Bizim modellərimiz paylaşdırılmış iş işlərimiz DeltaLM ilə başlanğıçlandı, çoxlu dil kodlayıcı modeli, böyük paralel məlumatlarla birlikdə müəyyən edilmişdir və məlumatların qurğuları ilə müəyyən edilmişdir, progresiv öyrənmək və iterativ arka çevirim metodlarını daha yaxşılaşdırmaq üçün istifadə edilmişdir. Əvvəlki təbliğlərimiz, avtomatik değerlendirmə metrikləri ilə ilk dərəcədə üç dərəcədə səf çəkdilər.", 'af': "Hierdie raporteer beskrywe Microsoft se masjien vertaling stelsels vir die WMT21 gedeelde taak op groot- skaal veelvuldige masjien vertaling. Name Ons het in alle drie evaluasie snitte gedeel, insluitend Groot Snit en twee Klein Snitte waar die vorige een onbeheinde is en die laaste twee is volledig beheinde. Ons model onderskrifte aan die gedeelde taak is geïnisialiseer met DeltaLM, 'n algemene voor-ondersoekte multitaalse enkoder-dekoder-model, en fyn-tuned ooreenkomstig met die groot versamel parallele data en toegelaat data bronne volgens snit instellings, saam met toepassing van progresiewe leer en iteratiewe terugvertaling toegang om die prestasie verder te verbeter. Ons eindelike onderskrifte het eerste op drie snitte ingevolge die outomatiese evalueringsmetrie rangeer.", 'hy': "Այս զեկույցը նկարագրում է Մայքրոսոֆթի մեքենային թարգմանման համակարգերը, որոնք աշխատում են համագործակցած աշխատանքի համար' մեծ մակարդակի բազլեզու մեքենայի թարգմանման համար: We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  Մեր մոդելը ընդհանուր խնդրին ներկայացված էր Delta LM-ի միջոցով, մի ընդհանուր նախապատրաստված բազմալեզու կոդավորող-կոդավորող մոդելի միջոցով, և համապատասխանաբար կազմակերպված մեծ հավաքված զուգահեռ տվյալների հետ և թույլատրված տվյալների աղբյուրների միջոցով, ըստ ուղղությունների, միասին կիրա Մեր վերջնական ներկայացումները առաջինը 3 տողում էին ավտոմատիկ գնահատման մետրիկայի տեսքով:", 'bs': 'Ovaj izvještaj opisuje sisteme prevoda mašine za WMT21 zajednički zadatak o velikoj multijezičkoj prevodu mašine. Učestvovali smo u svim tri traga procjene, uključujući Velike tragove i dvije male tragove, gdje je bivša bez ograničenja, a posljednja dva su potpuno ograničena. Naši podaci model a zajedničkog zadatka su inicijalizirani sa DeltaLM, generičnim pre-obučenim multijezičkim koderom-dekoderom modelom, i odgovarajući u skladu s ogromnim prikupljenim paralelnim podacima i dozvoljenim izvorima podataka u skladu s nastavama praćenja, zajedno s primjenom progresivnih pristupa učenja i iterativnog povratka za daljnje poboljšavanje učinka. Naši poslednji podaci su prvi na tri traga u smislu metrika automatske procjene.', 'bn': 'এই রিপোর্টটি বিশাল মাল্টিভাল মেশিন অনুবাদের জন্য মাইক্রোসফটের মেশিন অনুবাদ সিস্টেম বর্ণনা করেছে। আমরা বিশাল ট্র্যাক এবং দুটি ছোট ট্র্যাক যেখানে প্রাক্তন ট্র্যাক নির্মাণ করা হয়েছে এবং পরবর্তী দুটি ট্র্যাক পুরোপুরি বাধ্য শেয়ার করা কাজের জন্য আমাদের মডেল প্রাথমিক প্রশিক্ষিত বহুভাষা এনকোডার মডেলের সাথে আমাদের মডেল শুরু করা হয়েছিল, যা পূর্বে প্রশিক্ষিত বহুভাষী কোডার-ডেকোডারের মডেল এবং অনুরূপ সংগ্রহ করা হয়েছিল বিশাল Our final submissions ranked first on three tracks in terms of the automatic evaluation metric.', 'et': 'Selles aruandes kirjeldatakse Microsofti masintõlkesüsteeme WMT21 ühise ülesande jaoks suuremahulise mitmekeelse masintõlke osas. Osalesime kõigil kolmel hindamisrajal, sealhulgas suur rada ja kaks väikerada, kus esimene on piiramatu ja kaks viimast on täielikult piiratud. Meie mudelite esitamised jagatud ülesandele initsialiseeriti DeltaLM-iga, mis on üldine eelnevalt koolitatud mitmekeelne kodeerija-dekooder mudel, ning täpsustati vastavalt tohututele kogutud paralleelsetele andmetele ja lubati andmeallikaid vastavalt raja seadetele, koos progressiivse õppimise ja iteratiivse tagatõlke lähenemisviiside rakendamisega jõudluse veelgi parandamiseks. Meie lõplikud esitused olid automaatse hindamismeetodi poolest kolmel rajal esimesed.', 'ca': "Aquest informe descriu els sistemes de traducció màquina de Microsoft per a la tasca compartida WMT21 en traducció màquina multillengua a gran escala. Vam participar en totes les tres pistes d'evaluació, incloent Big Track i dues Small Tracks on la primera no està restringida i les altres dues estan totalment restringides. Els nostres models de subministració a la tasca compartida van ser inicialitzats amb DeltaLM, un model genèric de codificador-decodificador multillenguatge pré-entrenat, i van ajustar corresponentment amb les immenses dades parallels recollides i van permetre fonts de dades segons les configuracions de la pista, juntament amb l'aplicació d'aprenentatge progressiu i d'enfocaments iteratius de retrotraducció per millorar més el rendiment. Les nostres presentacions finals es van classificar primer en tres pistes en termes de la mètrica d'evaluació automàtica.", 'fi': 'Tässä raportissa kuvataan Microsoftin konekäännösjärjestelmiä laajamittaista monikielistä konekäännöstä koskevaan jaettuun WMT21-tehtävään. Osallistuimme kaikkiin kolmeen arviointiradaan, mukaan lukien Large Track ja kaksi Small Track, joissa ensimmäinen on rajaton ja kaksi jälkimmäistä täysin rajoitettu. Mallilähetyksemme jaettuun tehtävään alustettiin DeltaLM-mallilla, joka on yleispätevä esikoulutettu monikielinen kooderi-dekooderimalli, ja hienosäädettiin vastaavasti laajalla kerätyllä rinnakkaisdatalla ja sallittiin tietolähteet radan asetusten mukaan sekä edistyksellisen oppimisen ja iteratiivisten back-translation lähestymistapojen soveltaminen suorituskyvyn parantamiseksi entisestään. Lopulliset hakemuksemme sijoittuivat kolmella raidalla ensimmäiseksi automaattisen arviointimittarin osalta.', 'cs': 'Tato zpráva popisuje systémy strojového překladu společnosti Microsoft pro sdílený úkol WMT21 pro velký vícejazyčný strojový překlad. Podíleli jsme se na všech třech hodnotících tratích včetně Large Track a dvou Small Track, kde první je neomezená a druhé dvě jsou plně omezené. Naše podání modelů do sdíleného úkolu bylo inicializováno pomocí DeltaLM, generického předškoleného vícejazyčného modelu kodéru a dekodéru, a odpovídajícím způsobem vyladěno s rozsáhlými shromážděnými paralelními daty a povolenými datovými zdroji podle nastavení stopy, spolu s aplikací progresivního učení a iterativních zpětného překladu pro další zlepšení výkonu. Naše závěrečné příspěvky byly na třech stopách první z hlediska metriky automatického vyhodnocování.', 'id': "This report describes Microsoft's machine translation systems for the WMT21 shared task on large-scale multilingual machine translation.  We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained.  Our model submissions to the shared task were initialized with DeltaLM, a generic pre-trained multilingual encoder-decoder model, and fine-tuned correspondingly with the vast collected parallel data and allowed data sources according to track settings, together with applying progressive learning and iterative back-translation approaches to further improve the performance.  Pemberian akhir kami berturut-turut pertama di tiga jejak dalam terma metrik evaluasi otomatis.", 'sk': 'To poročilo opisuje Microsoftove sisteme strojnega prevajanja za opravilo v skupni rabi WMT21 za obsežno večjezično strojno prevajanje. Sodelovali smo na vseh treh ocenjevalnih poteh, vključno z velikimi in dvema majhnima stezama, kjer je prva neomejena, druga dve pa popolnoma omejena. Naše predložitve modelov za skupno nalogo so bile inicializirane z DeltaLM, generičnim vnaprej usposobljenim večjezičnim modelom kodirnika-dekodirnika, in ustrezno nastavljene z obsežnimi zbranimi vzporednimi podatki in dovoljenimi viri podatkov glede na nastavitve sledi, skupaj z uporabo progresivnega učenja in iterativnih pristopov za nazaj prevajanje za nadaljnje izboljšanje učinkovitosti. Naši končni prispevki so se uvrstili na prvo mesto na treh skladbah glede na samodejno ocenjevalno metriko.', 'ha': "@ info Mun yi rabo da duk hanyõyi uku masu bincike da Gagon Large da Trabara biyu masu ƙarami, inda na farko ba'a tsare ta kuma ƙarshen biyu aka ƙudura. @ info: whatsthis Gani da gaskatanmu suka samu ta farko a kan hanyõyin uku a cikin metrikin da kake kanana.", 'bo': 'WMT21 ནང་དུ་སྙན་ཞུ་འདིས་རྩིས་འཁོར་གྱི་མ་ལག་གི་སྤྱི་ཚོལ་གྱི་ཐབས་ལམ་མང་ཆེ་རིང་གི་འགྲེལ་བཤད་ཀྱི་ཡོད། We participated in all three evaluation tracks including Large Track and two Small Tracks where the former one is unconstrained and the latter two are fully constrained. Our model submissions to the shared task were initialized with DeltaLM, a generic pre-trained multilingual encoder-decoder model, and fine-tuned correspondingly with the vast collected parallel data and allowed data sources according to track settings, together with applying progressive learning and iterative back-translation approaches to further improve the performance. Our final submissions ranked first on three tracks in terms of the automatic evaluation metric.', 'he': "This report describes Microsoft's machine translation systems for the WMT21 shared task on large-scale multilingual machine translation.  השתתפנו בשלושת עקבות הערכה כוללות עקבות גדולות ושני עקבות קטנות שבו הקודמות לא מוגבלות ושני האחרונות מוגבלות לחלוטין. ההעברות המודל שלנו למשימה המשותפת התחילו עם DeltaLM, מודל קודם-קודם multilingual מאומן מראש גנרי, ומתאים באופן מתאים עם נתונים קבועים ענקים שנאספו ומאפשרים מקורות נתונים לפי סדרות מסלול, יחד עם השימוש של לימוד מתקדם וגישוי התרגום מאחור מתדריך כדי לשפר את ההופעה. Our final submissions ranked first on three tracks in terms of the automatic evaluation metric.", 'jv': 'Ndelengkat iki rambarang sistem tarjamahan de Ubuntu kanggo nyelarang task banget, kiye banget nggo kalang langgar-kalang multi-lengkang teljamahan. Awak dhéwé éntuk durung telu milih sing dibutuhé ning acara Smooth track karo iki Smooth track sing gak dhéwé nggawe lan padha iki sampek ditulakipon liyane Awak dhéwé model sing berarti nggawe task gawe diuntingi podho Delta LM, model multi-lenguangkap sistem sing dibenalke nggawe multi-lenguangkap sistem sistem multi-lenguangkap modèl Awakdhéwé éntuk peduli sing ditambah tanggal telu track sing ditambah tanggal nggo metir sing otomatik.'}
{'en': 'HW-TSC’s Participation in the WMT 2021 Large-Scale Multilingual Translation Task', 'fr': 'Participation de HW-TSC à la tâche de traduction multilingue à grande échelle du WMT 2021', 'es': 'Participación de HW-TSC en la tarea de traducción multilingüe a gran escala del WMT 2021', 'ar': 'مشاركة HW-TSC في مهمة الترجمة متعددة اللغات واسعة النطاق 2021 WMT', 'pt': 'Participação da HW-TSC na Tarefa de Tradução Multilíngue em Grande Escala do WMT 2021', 'ja': 'WMT 2021大規模多言語翻訳タスクへのHW - TSCの参加', 'ru': 'Участие HW-TSC в задаче крупномасштабного многоязычного перевода WMT 2021', 'hi': 'WMT 2021 में HW-TSC की भागीदारी बड़े पैमाने पर बहुभाषी अनुवाद कार्य', 'zh': 'HW-TSC 参 WMT 2021 大言译', 'ga': 'Rannpháirtíocht HW-TSC i dTasc Aistriúcháin Ilteangacha ar Mhórscála WMT 2021', 'ka': 'HW- TSC- ის მოწყობილობა WMT 2021 დიდი- სკვილის მრავალენგური განსაგულისხმების რაოდენობაში', 'el': 'Συμμετοχή του στο έργο μεγάλης κλίμακας πολύγλωσσης μετάφρασης', 'lt': 'HW-TSC dalyvavimas WMT 2021 Didelio masto daugiakalbio vertimo užduotyje', 'kk': 'HW- TSC WMT 2021- нің үлкен- масштабтағы көп тілді аудару тапсырмасында қатынау', 'ms': 'Bahagian HW-TSC dalam Tugas Terjemahan Berbahasa Skala Besar WMT 2021', 'hu': 'A HW-TSC részvétele a WMT 2021 nagyszabású többnyelvű fordítási feladatban', 'ml': 'WMT 2021 വലിയ- വലിയ ഭാഷകങ്ങളുടെ ടിഎസ്സിയുടെ പങ്കാളി', 'mt': 'Il-Parteċipazzjoni tal-HW-TSC fil-kompitu tat-traduzzjoni multilingwi fuq skala kbira tad-WMT 2021', 'it': 'Partecipazione di HW-TSC al compito di traduzione multilingue su larga scala WMT 2021', 'pl': 'Udział HW-TSC w wielkojęzycznym zadaniu tłumaczeniowym WMT 2021', 'mk': 'Учеството на ХВ-ТСК во ВМТ 2021 Голема голема мултијазична преведувачка задача', 'mn': 'HW-TSC-ын WMT 2021 оны хувьд олон хэл хөрөнгө оруулалт', 'ro': 'Participarea HW-TSC la misiunea de traducere multilingvă WMT 2021', 'no': 'HW- TSC- deltakaren i WMT 2021 Stor- skala fleirspråksomsetjinga', 'sv': 'HW-TSC:s deltagande i den storskaliga flerspråkiga översättningsuppgiften WMT 2021', 'sr': 'Učestvovanje HW-TSC-a u WMT 2021 Velikoj skali višejezičkog prevodnog zadatka', 'si': "HW- TSC' s partition in the WMT 2021 Large- scaled Multilanguage translation Job", 'so': 'WMT 2021 Large-Scale Multilingual Translation Task', 'ta': 'WMT 2021 பெரிய- அளவு- பல மொழிமொழிபெயர்ப்பு மொழிபெயர்ப்பு பணியில் HW- TSC கூட்டுதல்', 'ur': "HW-TSC's Participation in the WMT 2021 Large-Scale Multilingual Translation Task", 'uz': 'Name', 'vi': 'HW-TSC tham gia vào Nhiệm vụ dịch đa ngôn ngữ lớn của WM 2021', 'hr': 'Učelnost HW-TSC-a u WMT 2021 Velikoj skali višejezičkog prevodnog zadatka', 'de': 'Teilnahme des HW-TSC an der WMT 2021 Large-Scale Multilingual Translation Task', 'bg': 'Участие на ЦРУ в мащабната многоезична задача за превод', 'da': "HW-TSC's deltagelse i WMT 2021's storstilede flersprogede oversættelsesopgave", 'nl': 'Deelname van HW-TSC aan de WMT 2021 grootschalige meertalige vertaaltaak', 'fa': 'شرکت HW-TSC در عملیات ترجمه\u200cهای زیادی زبان WMT 2021', 'ko': 'HW-TSC, WMT 2021 대규모 다국어 번역 작업 참여', 'id': "HW-TSC's Participation in the WMT 2021 Large-Scale Multilingual Translation Task", 'tr': "HW-TSC WMT 2021'iň Beýik-Kalamy Çoklu Diller terjime Taýýasy", 'af': 'HW- TSC se Deelnadering in die WMT 2021 Groot- Scale Veelvuldige Vertaling Opdrag', 'hy': 'ՀՈւ-ՏՍԿ-ի մասնակցությունը 2021 թվականի ԱՄԹ-ի մեծ մասշտաբի բազլեզու թարգմանման գործում', 'am': "HW-TSC's Participation in the WMT 2021 Large-Scale Multilingual Translation Task", 'sw': 'Ushiriki wa HW-TSC katika Task la Tafsiri kubwa la lugha 2021', 'az': "HW-TSC WMT 2021'nin Büyük-ölçü çoxlu dil Çeviri Gözəli", 'bn': 'WMT ২০২১ ব্যাপক- মাল্টিভাষার অনুবাদের কাজে HW-TSC এর অংশগ্রহণ', 'ca': 'La participació de la HW-TSC a la tasca de traducció multilingüe a gran escala del WMT 2021', 'cs': 'Účast HW-TSC na rozsáhlém vícejazyčném překladu WMT 2021', 'sq': 'Pjesëmarrja e HW-TSC në WMT 2021', 'bs': 'Učestvo HW-TSC-a u WMT 2021 Velikoj skali multijezičkog prevodnog zadatka', 'et': 'HW-TSC osalemine WMT 2021 laiaulatuslikus mitmekeelses tõlketöös', 'fi': 'HW-TSC:n osallistuminen WMT 2021 -laajamittaiseen monikieliseen käännöstyöhön', 'ha': '@ info: whatsthis', 'he': "HW-TSC's Participation in the WMT 2021 Large-Scale Multilingual Translation Task", 'sk': 'Sodelovanje HW-TSC v obsežni večjezični prevajalski nalogi WMT 2021', 'jv': "HWT-Bsc's partition in the WT 2020 1 big-scale Multilanguage translation task", 'bo': "HW-TSC's Participation in the WMT 2021 Large-Scale Multilingual Translation Task"}
{'en': 'This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task. We participate in Samll Track # 2, including 6 languages : ', 'ar': 'تقدم هذه الورقة تقديم مركز خدمات الترجمة من Huawei (HW-TSC) إلى مهمة الترجمة متعددة اللغات واسعة النطاق 2021 WMT. نشارك في Samll Track # 2 ، بما في ذلك 6 لغات: الجاوية (Jv) والإندونيسية (Id) والماليزية (Ms) والتاغالوغ (Tl) والتاميل (Ta) والإنجليزية (En) مع 30 اتجاهًا في ظل الشرط المقيّد. نحن نستخدم هندسة المحولات ونحصل على أفضل أداء عبر متغيرات متعددة ذات أحجام أكبر للمعلمات. نقوم بتدريب نموذج واحد متعدد اللغات لترجمة جميع الاتجاهات الثلاثين. نقوم بإجراء معالجة مسبقة تفصيلية وتصفية على مجموعات البيانات واسعة النطاق المتوفرة ثنائية اللغة وأحادية اللغة. يتم استخدام العديد من الاستراتيجيات شائعة الاستخدام لتدريب نماذجنا ، مثل الترجمة العكسية ، والترجمة إلى الأمام ، وتقطير المعرفة بالمجموعة ، والضبط الدقيق للمحول. نموذجنا يحصل على نتائج تنافسية في النهاية.', 'pt': 'Este artigo apresenta o envio do Huawei Translation Services Center (HW-TSC) para a tarefa de tradução multilíngue em grande escala do WMT 2021. Participamos da Samll Track #2, incluindo 6 idiomas: javanês (Jv), indonésio (Id), malaio (Ms), tagalog (Tl), tâmil (Ta) e inglês (En) com 30 direções sob a condição restrita. Usamos a arquitetura Transformer e obtemos o melhor desempenho por meio de várias variantes com tamanhos de parâmetros maiores. Treinamos um único modelo multilíngue para traduzir todas as 30 direções. Realizamos pré-processamento e filtragem detalhados nos conjuntos de dados bilíngues e monolíngues de grande escala fornecidos. Várias estratégias comumente usadas são usadas para treinar nossos modelos, como Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Nosso modelo obtém resultados competitivos no final.', 'fr': "Cet article présente la soumission du Huawei Translation Services Center (HW-TSC) à la tâche de traduction multilingue à grande échelle WMT 2021. Nous participons au Samll Track #2, comprenant 6 langues\xa0: javanais (Jv), Indonésien (Id), Malais (Ms), Tagalog (Tl), Tamil (Ta) et Anglais (En) avec 30 directions sous condition contrainte. Nous utilisons l'architecture Transformer et obtenons les meilleures performances grâce à de multiples variantes avec des tailles de paramètres plus importantes. Nous formons un modèle multilingue unique pour traduire les 30 directions. Nous effectuons un prétraitement et un filtrage détaillés sur les ensembles de données bilingues et monolingues à grande échelle fournis. Plusieurs stratégies couramment utilisées sont utilisées pour entraîner nos modèles, telles que la traduction arrière, la traduction avant, la distillation des connaissances d'ensemble, le réglage fin de l'adaptateur. Notre modèle obtient finalement des résultats compétitifs.", 'es': 'Este documento presenta la presentación del Centro de servicios de traducción de Huawei (HW-TSC) a la tarea de traducción multilingüe a gran escala del WMT 2021. Participamos en Samll Track #2, que incluye 6 idiomas: javanés (Jv), indonesio (Id), malayo (Ms), tagalo (Tl), tamil (Ta) e inglés (En) con 30 direcciones bajo la condición restringida. Utilizamos la arquitectura Transformer y obtenemos el mejor rendimiento a través de múltiples variantes con tamaños de parámetros más grandes. Entrenamos un solo modelo multilingüe para traducir las 30 direcciones. Realizamos preprocesamiento y filtrado detallados en los conjuntos de datos bilingües y monolingües a gran escala proporcionados. Se utilizan varias estrategias de uso común para entrenar nuestros modelos, como la traducción inversa, la traducción directa, la destilación del conocimiento conjunto y el ajuste fino del adaptador. Nuestro modelo obtiene resultados competitivos al final.', 'ja': '本稿では、WMT 2021大規模多言語翻訳タスクへのHuawei Translation Services Center （ HW - TSC ）の提出を紹介します。サムル・トラック# 2には、ジャワ語（ Jv ）、インドネシア語（ Id ）、マレー語（ Ms ）、タガログ語（ Tl ）、タミル語（ Ta ）、英語（ En ）の6言語を含む30の言語が制約条件下で参加しています。私たちはトランスフォーマーアーキテクチャを使用し、より大きなパラメータサイズを持つ複数のバリアントを介して最高のパフォーマンスを実現します。私たちは、30の方向すべてを翻訳するために、単一の多言語モデルをトレーニングします。私たちは、提供された大規模なバイリンガルおよびモノリンガルデータセットに詳細な前処理およびフィルタリングを実行します。バックトランスレーション、フォワードトランスレーション、アンサンブルナレッジディスティレーション、アダプターファインチューニングなど、当社のモデルをトレーニングするためによく使用されるいくつかの戦略が使用されています。私たちのモデルは、最終的に競争力のある結果を得ます。', 'zh': '本文引华为译服务中心(HW-TSC)大WMT 2021语言译事。 余参Samll Track #2,6种语:爪哇语(Jv),印度尼西亚语(Id),马来语(Ms),他加禄语(Tl),泰米尔语(Ta)、英语(En),在约束条件下有30向。 吾用Transformer架构,大参数尺寸者变体获得最佳能。 习一多言模以译30方。 臣等大双语单语数集行详预处理漉。 有数常用之策,以练吾模样,如反向译,正向译,集成知识提炼,适配器微调。 吾形终有竞争力矣。', 'hi': 'यह पेपर डब्ल्यूएमटी 2021 बड़े पैमाने पर बहुभाषी अनुवाद कार्य के लिए Huawei अनुवाद सेवा केंद्र (HW-TSC) की प्रस्तुति प्रस्तुत करता है। हम Samll ट्रैक # 2 में भाग लेते हैं, जिसमें 6 भाषाएं शामिल हैं: जावानीस (जेवी), इंडोनेशियाई (आईडी), मलय (एमएस), तागालोग (टीएल), तमिल (टा) और अंग्रेजी (एन) सीमित स्थिति के तहत 30 दिशाओं के साथ। हम ट्रांसफॉर्मर आर्किटेक्चर का उपयोग करते हैं और बड़े पैरामीटर आकार के साथ कई वेरिएंट के माध्यम से सबसे अच्छा प्रदर्शन प्राप्त करते हैं। हम सभी 30 दिशाओं का अनुवाद करने के लिए एक एकल बहुभाषी मॉडल को प्रशिक्षित करते हैं। हम प्रदान किए गए बड़े पैमाने पर द्विभाषी और मोनोलिंगुअल डेटासेट पर विस्तृत पूर्व-प्रसंस्करण और फ़िल्टरिंग करते हैं। कई आमतौर पर इस्तेमाल की जाने वाली रणनीतियों का उपयोग हमारे मॉडल को प्रशिक्षित करने के लिए किया जाता है, जैसे कि बैक ट्रांसलेशन, फॉरवर्ड ट्रांसलेशन, एनसेंबल नॉलेज आसवन, एडाप्टर फाइन-ट्यूनिंग। हमारा मॉडल अंत में प्रतिस्पर्धी परिणाम प्राप्त करता है।', 'ru': 'В этой статье представлено представление Центра услуг перевода Huawei (HW-TSC) для задачи крупномасштабного многоязычного перевода WMT 2021. Мы участвуем в Samll Track #2, включая 6 языков: яванский (Jv), индонезийский (Id), малайский (Ms), тагальский (Tl), тамильский (Ta) и английский (En) с 30 направлениями в ограниченных условиях. Мы используем архитектуру трансформатора и получаем наилучшую производительность с помощью нескольких вариантов с большими размерами параметров. Мы обучаем одну многоязычную модель для перевода всех 30 направлений. Мы выполняем детальную предварительную обработку и фильтрацию предоставленных крупномасштабных двуязычных и одноязычных наборов данных. Для обучения наших моделей используется несколько широко используемых стратегий, таких как Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. В итоге наша модель получает конкурентные результаты.', 'ga': 'Cuirtear i láthair sa pháipéar seo aighneacht Ionad Seirbhísí Aistriúcháin Huawei (HW-TSC) chuig Tasc Aistriúcháin Ilteangacha ar Mhórscála WMT 2021. Glacaimid páirt i Samll Track #2, lena n-áirítear 6 theanga: Iávais (Jv), Indinéisis (Id), Malaeis (Ms), Tagálaigis (Tl), Tamil (Ta) agus Béarla (En) le 30 treoir faoin gcoinníoll srianta. Bainimid úsáid as ailtireacht Trasfhoirmeoir agus bainimid an fheidhmíocht is fearr trí éagsúlachtaí iolracha le méideanna paraiméadar níos mó. Cuirimid oiliúint ar mhúnla ilteangach amháin chun na 30 treo ar fad a aistriú. Déanaimid réamhphróiseáil agus scagadh mionsonraithe ar na tacair sonraí dátheangacha agus aonteangacha ar mhórscála a chuirtear ar fáil. Baintear úsáid as roinnt mhaith straitéisí a úsáidtear go coitianta chun ár múnlaí a oiliúint, mar shampla Aistriú Siar, Aistriú Ar Aghaidh, Driogadh Eolais Ensemble, Mionchoigeartú Cuibheoirí. Faigheann ár múnla torthaí iomaíocha sa deireadh.', 'ka': 'ამ დოკუმენტი სამუშაო მრავალენგური თავისუფლების ცენტრის (HW- TSC) WMT 2021- ს მნიშვნელოვანი მრავალენგური თავისუფლების სამუშაო დაწყენება. ჩვენ Samll Track #2-ში მოთავსდებით, შეიძლება 6 ენები: Javanese (Jv), Indonesian (Id), Malay (Ms), Tagalog ჩვენ გამოყენებთ ტრანფორმეტრის აქტიქტიქტურის და მივიღებთ უკეთესი პარამეტრის ზომის გამოყენება. ჩვენ ერთი მრავალენგური მოდელის გაგრძნობა, რომ ყველა 30 წერტილების გაგრძნობა. ჩვენ გავაკეთებთ განსაზღვრებული მეორენგური და მონოლენგური მონაცემების კონფილტრების პროცესი და ფილტრირება. რამდენიმე საერთოდ გამოყენებული სტრატიგიები გამოყენება ჩვენი მოდელების გასწავლად, როგორც Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. ჩვენი მოდელი კონპეციენტიური შედეგების შესახებ.', 'hu': 'Ez a tanulmány bemutatja a Huawei Fordítási Szolgáltatóközpont (HW-TSC) benyújtását a WMT 2021 nagyméretű többnyelvű fordítási feladatra. Részt veszünk a Samll Track #2-ben, amely 6 nyelvet tartalmaz: jávai (Jv), indonéz (Id), maláj (Ms), tagalog (Tl), tamil (Ta) és angol (En), 30 irányban a korlátozott feltételek mellett. Transformer architektúrát használunk, és a legjobb teljesítményt több, nagyobb paraméterméretű változat segítségével érjük el. Egyetlen többnyelvű modellt képezünk, hogy lefordítsuk mind a 30 irányt. Részletes előfeldolgozást és szűrést végezünk a rendelkezésre álló nagyméretű kétnyelvű és egynyelvű adatkészleteken. Modelljeink képzéséhez számos gyakran használt stratégiát használnak, mint például a Visszafordítás, az Előre fordítás, az Ensemble Knowledge Destillation, az Adapter finomhangolás. Modellünk végül versenyképes eredményeket ér el.', 'el': 'Η παρούσα εργασία παρουσιάζει την υποβολή του Κέντρου Μεταφραστικών Υπηρεσιών της στο έργο Πολυγλωσσικής Μετάφραση μεγάλης κλίμακας. Συμμετέχουμε στο Σαμλ Track #2, συμπεριλαμβανομένων έξι γλωσσών: Χαβανέζικα (Jv), Ινδονησιακά (Id), Μαλαϊκά (Ms), Ταγκαλόγκ (Tl), Ταμίλ (Ta) και Αγγλικά (EN) με 30 κατευθύνσεις υπό τις περιορισμένες συνθήκες. Χρησιμοποιούμε την αρχιτεκτονική μετασχηματιστών και επιτυγχάνουμε την καλύτερη απόδοση μέσω πολλαπλών παραλλαγών με μεγαλύτερα μεγέθη παραμέτρων. Εκπαιδεύουμε ένα ενιαίο πολύγλωσσο μοντέλο για να μεταφράσουμε όλες τις 30 κατευθύνσεις. Πραγματοποιούμε λεπτομερή προεπεξεργασία και φιλτράρισμα στα παρεχόμενα δίγλωσσα και μονογλωσσικά σύνολα δεδομένων μεγάλης κλίμακας. Αρκετές κοινώς χρησιμοποιούμενες στρατηγικές χρησιμοποιούνται για την εκπαίδευση των μοντέλων μας, όπως η μεταγραφή πίσω, η μεταγραφή εμπρός, η απόσταξη γνώσης συνόλων, η τελειοποίηση προσαρμογής προσαρμογέων. Το μοντέλο μας επιτυγχάνει ανταγωνιστικά αποτελέσματα στο τέλος.', 'kk': 'Бұл қағаз Huawei аудару қызметтерінің орталығын (HW- TSC) WMT 2021- ге үлкен- масштабтағы көп тілді аудару тапсырмасына жібереді. Біз Samll Track #2 дегенге қатынасыз, 6 тілде: жаван (Jv), Индонезия (Id), Малай (Ms), Тагалог (Tl), Тамил (Ta) және ағылшын (En) тілдеріне 30 бағыттау керек. Біз түрлендіруші архитектурасын қолданып, бірнеше параметрлердің өлшемі арқылы ең жақсы жылдамдығын аламыз. Біз 30 бағыттарды аудару үшін бір көп тіл үлгісін үйренеміз. Біз келтірілген үлкен тілді және монолингі деректер қорларының егжей- тегжейін алдын- ала өңдеу және сүзгілеуді орындаймыз. Бірнеше рет қолданылатын стратегиялар, мысалы Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine- tuning моделдерімізді оқыту үшін қолданылады. Біздің моделіміз соңында жарықтық нәтижелерді алады.', 'ms': 'Kertas ini memperkenalkan penghantaran Pusat Perkhidmatan Terjemahan Huawei (HW-TSC) kepada Tugas Terjemahan Berbahasa Skala Besar WMT 2021. We participate in Samll Track #2, including 6 languages: Javanese (Jv), Indonesian (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) and English (En) with 30 directions under the constrained condition.  Kami menggunakan arkitektur Transformer dan mendapatkan prestasi terbaik melalui variasi berbilang dengan saiz parameter yang lebih besar. Kami melatih satu model berbilang bahasa untuk menerjemahkan semua 30 arah. Kami melakukan pemprosesan dan penapisan terperinci pada set data bilingual dan monobahasa yang diberikan pada skala besar. Beberapa strategi yang biasa digunakan untuk melatih model kita, seperti Terjemahan Kembali, Terjemahan Maju, Distillasi Pengetahuan Sampul, Penyesuaian Penyesuai. Model kita mendapatkan keputusan persaingan pada akhirnya.', 'ml': 'This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task.  നിര്\u200dബന്ധിതമായ അവസ്ഥയില്\u200d 30 തിരിച്ചുകൊണ്ട് ഞങ്ങള്\u200d സാമ്ള്\u200d ട്രാക്കില്\u200d പങ്കുചേര്\u200dക്കുന്നു # 2: ജാവാനീസ് (ജെവി), ഇന്തോനേഷ്യന്\u200d (ഐഡി), മലായി (മിസ്), ടാഗാ നമ്മള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്കിട്ടേഷന്\u200d ഉപയോഗിക്കുന്നു. ഏറ്റവും വലിയ അളവുകളുമായി ഏറ്റവും നല്ല പ്രദര്\u200dശനം ലഭ ഞങ്ങള്\u200d ഒരു മൊത്തം ഭാഷ മോഡലിനെ പരിശീലിപ്പിക്കുന്നു. 30 വഴികളെല്ലാം പരിശീലിക്കാന്\u200d. നമ്മള്\u200d വിശദീകരിക്കുന്നത് മുന്\u200dപ് പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന്\u200dറെയും ഫില്\u200dറ്റര്\u200d ചെയ്യുന്നു. വലിയ ഭാഷക്കും മോ സാധാരണ ഉപയോഗിക്കുന്ന ഒരുപാട് പദ്ധതികള്\u200d ഞങ്ങളുടെ മോഡലുകളെ പരിശീലിപ്പിക്കാന്\u200d ഉപയോഗിക്കുന്നു. പിന്നിലെ പരിഭാഷകള്\u200d, മുന്\u200dപോട്ട് പരിഭ നമ്മുടെ മോഡല്\u200d മത്സരത്തിലുള്ള ഫലങ്ങള്\u200d അവസാനിപ്പിക്കുന്നു.', 'it': "Questo articolo presenta la presentazione di Huawei Translation Services Center (HW-TSC) al WMT 2021 Large-Scale Multilingual Translation Task. Partecipiamo alla Samll Track #2, comprendente 6 lingue: Javanese (Jv), Indonesiano (Id), Malese (Ms), Tagalog (Tl), Tamil (Ta) e Inglese (En) con 30 indicazioni sotto la condizione vincolata. Usiamo l'architettura Transformer e otteniamo le migliori prestazioni grazie a più varianti con parametri di dimensioni maggiori. Formiamo un unico modello multilingue per tradurre tutte le 30 direzioni. Eseguiamo pre-elaborazione e filtraggio dettagliati sui set di dati bilingui e monolingue forniti su larga scala. Per addestrare i nostri modelli vengono utilizzate diverse strategie comunemente utilizzate, come Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Il nostro modello ottiene risultati competitivi alla fine.", 'mk': 'Овој весник го претставува поднесувањето на Центарот за преведувања на Хуауеј (ХВ-ТСЦ) на ВМТ 2021 Голема голема мултијазична преведувачка задача. Ние учествуваме на Samll Track #2, вклучувајќи 6 јазици: јавански (Јв), индонезиски (ИД), Малај (г-ѓо), Тагалог (Тl), Тамилски (Та) и англиски (Ен) со 30 насоки под ограничени услови. Ние ја користиме трансформарната архитектура и ја добиваме најдобрата резултат преку повеќе варијанти со поголеми големини на параметри. Тренираме еден мултијазичен модел за преведување на сите 30 насоки. Ние спроведуваме детално преобработување и филтрирање на обезбедените големи двојјазични и монојазични податоци. Неколку често употребени стратегии се користат за обука на нашите модели, како што се Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine tuning. Нашиот модел добива конкурентни резултати на крајот.', 'lt': 'Šiame dokumente pateikiamas Huawei vertimo paslaugų centro (HW-TSC) pateikimas WMT 2021 m. Didelio masto daugiakalbio vertimo uždaviniui. Dalyvaujame bandinio kelio Nr. 2, įskaitant 6 kalbas: Javano (Jv), Indonezijos (Id), Malajos (M.), Tagalogo (Tl), Tamilo (Ta) ir anglų (En), kuriose yra 30 krypčių ribotos sąlygos. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes.  We train a single multilingual model to translate all the 30 directions.  We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual datasets.  Mūsų modeliams treniruoti naudojamos kelios dažnai naudojamos strategijos, pavyzdžiui, vertimas atgal, vertimas į priekį, suvienodintas žinių distiliavimas, adaptoriaus patobulinimas. Mūsų modelis galiausiai gauna konkurencinius rezultatus.', 'no': 'Denne papiret viser å senda Huawei- omsetjingstenestesenteret (HW- TSC) til WMT 2021 Stor- skala fleirspråksomsetjingsverkt. Vi deltar i Samll Track #2, inkludert 6 språk: Javanese (Jv), Indonesisk (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) og engelsk (En) med 30 retningar under begrenset tilstand. Vi brukar Transformeringsarkitektur og får det beste utviklinga via fleire variantar med større parameter-storleik. Vi treng ein enkel multispråk modell for å oversette alle 30 retningane. Vi utfører detaljerte førehandsaming og filtrering på dei tilgjengelege største bilinguelte og monospråk datasetta. Fleire vanleg brukte strategiar vert brukte for å trenja modelane våre, slik som tilbakeomsetjing, framover omsetjing, forstørring av kjennomsetjing, adapter fintuning. Modellen vårt får konkurrentiv resultat i slutten.', 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni taċ-Ċentru ta’ Servizzi ta’ Traduzzjoni Huawei (HW-TSC) lill-Kompitu ta’ Traduzzjoni Multilingwi fuq Skala kbira tal-WMT 2021. Aħna qed jipparteċipaw fil-Samll Track #2, inklużi 6 lingwi: Ġavaniż (Jv), Indoneżjan (Id), Malaj (Ms), Tagalog (Tl), Tamil (Ta) u Ingliż (En) bi 30 direzzjoni taħt il-kundizzjoni ristretta. Aħna nużaw l-arkitettura Transformer u niksbu l-aħjar prestazzjoni permezz ta’ varjanti multipli b’daqsijiet akbar ta’ parametri. Aħna nħarrġu mudell multilingwi wieħed biex jittraduċu t-30 direzzjoni kollha. Għandna nagħmlu proċessar u filtrazzjoni dettaljati minn qabel fuq is-settijiet ta’ dejta bilingwi u monolingwi fuq skala kbira pprovduti. Diversi strateġiji użati b’mod komuni jintużaw biex jitħarrġu l-mudelli tagħna, bħat-Traduzzjoni ta’ wara, Traduzzjoni ’l quddiem, Distillazzjoni Ensemble Knowledge, Aġġustament Irfinat tal-Adattatur. Fl-aħħar mill-aħħar, il-mudell tagħna jikseb riżultati kompetittivi.', 'mn': 'Энэ цаас Huawei Translation Services Center (HW-TSC) WMT 2021-д том-scale олон хэл хөгжлийн хөгжлийн ажлыг тайлбарладаг. Бид Samll Track #2-д оролцож байна, 6 хэл нь: Яван (Jv), Индонез (Id), Малай (хатагтай), Тагалог (Tl), Тамил (Ta) болон Англи (En) хэлээр 30 зүйлийг хязгаарлагддаг. Бид Трансформер архитектурыг ашиглаж, олон вариантуудын хувьд хамгийн сайн үйл ажиллагааг ашиглаж байна. Бид 30 зүйлийг орлуулахын тулд нэг олон хэл загварын загварыг суралцдаг. Бид томоохон хоёр хэл болон ганц хэл өгөгдлийн суурь дээр нарийвчлалтай өмнө үйлдвэрлэх болон сүзүүлэх хэрэгтэй. Бидний загваруудыг суралцах, Back Translation, Forward Translation, Ensemble Knowledge Destillation, Adapter Fine-tuning зэрэг ихэвчлэн хэрэглэгддэг олон стратегийг ашигладаг. Бидний загвар нь төгсгөлд өрсөлдөөний үр дүн авдаг.', 'pl': 'Niniejszy artykuł przedstawia zgłoszenie Centrum Usług Tłumaczeniowych Huawei (HW-TSC) do wielkojęzycznego zadania tłumaczeniowego WMT 2021. Uczestniczymy w Samll Track #2, w tym w sześciu językach: jawańskim (Jv), indonezyjskim (Id), malajskim (Ms), tagalogu (Tl), tamilskim (Ta) i angielskim (En) z 30-kierunkami w ograniczonych warunkach. Wykorzystujemy architekturę Transformera i uzyskujemy najlepszą wydajność poprzez wiele wariantów o większych rozmiarach parametrów. Szkolimy jeden wielojęzyczny model, aby tłumaczyć wszystkie 30-kierunki. Wykonujemy szczegółowe wstępne przetwarzanie i filtrowanie na dostarczonych dużych zbiorach danych dwujęzycznych i jednojęzycznych. Do szkolenia naszych modeli stosuje się kilka powszechnie stosowanych strategii, takich jak tłumaczenie wsteczne, tłumaczenie do przodu, destylacja wiedzy zespołowej, dostrajanie adapterów. Nasz model osiąga w końcu konkurencyjne wyniki.', 'si': 'මේ පැත්තේ හුවේයි වාර්ථාපනය සේවාව මධ්\u200dයස්ථානය (HW- TSC) ගැන පෙන්වන්න පෙන්වන්න පුළුවන් වෙනවා WMT 2021 ලොකු ස්කේල්  අපි සැම්ල් ට්\u200dරැක් එක්ක #2, භාෂාවක් 6 සම්බන්ධ කරනවා: ජාවානේසි (Jv), ඉන්ඩෝනේසි (Id), මාලායි (Ms), ටැගොලෝග් (Tl), ටාමිල් සහ ඉංග්\u200dරීසිය ( Name අපි එකම භාෂාවක් මොඩල් ප්\u200dරකාරයක් ප්\u200dරධානය කරනවා හැම ප්\u200dරකාරයක්ම 30ක් පරිවර්තනය කරන්න. අපි ප්\u200dරශ්නයක් කලින් ප්\u200dරක්\u200dරියාස කරනවා සහ ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා ලොකු ප්\u200dරමාණයේ දුවන් භාෂාවක ගොඩක් සාමාන්\u200dය භාවිත විද්\u200dයාප්\u200dත විද්\u200dයාප්\u200dතියක් භාවිත වෙනවා අපේ මොඩේල්ස් ක්\u200dරියාන්ත කරන්න, හරියට Backtranslation, forward translation, Ensemble KnowKnowKnowKnowKnowKnowKnow Disturb අපේ මොඩල් එක අන්තිමේදී ප්\u200dරතිශ්නයක් ලැබෙනවා.', 'ro': 'Această lucrare prezintă depunerea Centrului de servicii de traducere Huawei (HW-TSC) la misiunea de traducere multilingvă WMT 2021 la scară largă. Participăm la Samll Track #2, incluzând 6 limbi: javaneză (Jv), indoneziană (Id), malaeză (Ms), tagalog (Tl), tamil (Ta) și engleză (En) cu 30 de direcții în condiția constrânsă. Utilizăm arhitectura Transformer și obținem cele mai bune performanțe prin mai multe variante cu dimensiuni mai mari ale parametrilor. Instruim un singur model multilingv pentru a traduce toate cele 30 de direcții. Efectuăm prelucrarea și filtrarea detaliată a seturilor de date bilingve și monolingve furnizate la scară largă. Mai multe strategii utilizate în mod obișnuit pentru a instrui modelele noastre, cum ar fi traducerea înapoi, traducerea înainte, distilarea cunoștințelor ansamblului, reglarea fină a adaptorului. Modelul nostru obține rezultate competitive în cele din urmă.', 'so': 'This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task.  Waxaynu ka qeybqaadannaa Samll Track #2, waxaana ka mid ah 6 luuqadood: Javanese (Jv), Indonesian (Id), Malay (Ms. Tagalog (Tl), Tamil (Ta) iyo Ingiriis (En) oo ku qoran 30 hagaajiya xaalada qasabka ah. Waxaynu isticmaalnaa taariikhda turjumaanka, waxaynu heli doonnaa si aad u fiican wax looga sameeyo kala duwan oo ay leeyihiin tirada kala duduwan. Tusaale kaliya oo luuqado kala duduwan ayaan ku tababarinnaa si aan ugu turjumno 30 waddooyinka oo dhan. Waxaannu sameynaa baaraandegista hore iyo baaritaanka lagu qoray labada luuqadood oo kala duduwan iyo labada luuqadood oo kala duduwan. Sida caadiga ah waxaa loo isticmaalaa qaababka noocyada, tusaale ahaan turjumista dib, tarjumidda Forward, Distriction of Knowledge, Adapter Fine-tuning. Tusaalkayagu wuxuu heli karaa dhamaadka matooyinka isjahaadada.', 'sr': 'Ovaj papir predstavlja predavanje centra za prevod Huawei usluga (HW-TSC) WMT 2021 Velikom skalom višejezičkog prevoda. Učestvujemo u Samll Track #2, uključujući 6 jezika: Javanski (Jv), Indonezijski (Id), Malajski (gđica), Tagalog (Tl), Tamil (Ta) i engleski (En) sa 30 uputa pod ograničenim stanjem. Koristimo arhitekturu transformera i dobijamo najbolje izvršenje putem višestrukih varianta sa većim veličinama parametara. Treniramo jednog multijezičkog model a da prevodimo sve 30 smjera. Izvodimo detaljne predobrađivanje i filtriranje na pruženim velikim dvojezičkim i monojezičkim podacima. Nekoliko često korišćenih strategija se koristi za obuku našeg modela, kao što su Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine tuning. Naš model dobija konkurentne rezultate na kraju.', 'sv': 'Denna uppsats presenterar inlämningen av Huawei Translation Services Center (HW-TSC) till WMT 2021 storskalig flerspråkig översättning uppgift. Vi deltar i Saml Track #2, inklusive 6 språk: Javanesiska (Jv), Indonesiska (Id), Malayska (Ms), Tagalog (Tl), Tamil (Ta) och Engelska (En) med 30 riktningar under det begränsade villkoret. Vi använder Transformer arkitektur och får bästa prestanda via flera varianter med större parameterstorlekar. Vi tränar en enda flerspråkig modell för att översätta alla 30 riktningar. Vi utför detaljerad förbehandling och filtrering på de storskaliga tvåspråkiga och enspråkiga datauppsättningarna. Flera vanliga strategier används för att träna våra modeller, till exempel bakåtöversättning, vidareöversättning, Ensemble Kunskapsdestillation, Adapter finjustering. Vår modell får i slutändan konkurrenskraftiga resultat.', 'ur': 'This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task. ہم سمل ٹراک #2 میں شامل ہوتے ہیں، 6 زبانیں شامل ہوتے ہیں: جاوانی (Jv), انڈونزی (Id), مالای (Ms), ٹاگلوگ (Tl), تامیل (Ta) اور انگلیسی (En) پر 30 دقیق مسائل ہیں۔ ہم ترنسفور معماری استعمال کرتے ہیں اور بہت بڑے پارامیٹ اندازے کے مطابق بہترین فعالیت حاصل کرتے ہیں. ہم ایک متعدد زبان کی مدل کی تعلیم کرتے ہیں کہ 30 دقیقا کو ترجمہ کریں۔ ہم پیش پردازش اور فلٹرینگ کے مطابق مشخص کر رہے ہیں جو بڑی صحیح دو زبان اور ایک زبان ڈاٹ سٹ پر ہے. بہت سی استراتژی استعمال کیے جاتے ہیں کہ ہمارے موڈل کو تطارین کریں، جیسے Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. ہماری مدل آخر میں مقابلہ نتیجہ حاصل کرتا ہے.', 'ta': 'இந்த தாள் Huawei மொழிபெயர்ப்பு சேவைகள் மையம் (HW- TSC) WMT 2021 பெரிய அளவு- மொழிமொழிமாற்றி பணிக்கு அனுப்புகிறது. நாங்கள் # 2 சாம்ல் தடத்தில் பகிர்ந்து கொள்கிறோம் 6 மொழிகளில் ஜாவானிஸ் (ஜேவ்), இந்தோனேசியா (Id), மாலா (Ms), டாகாலாக்(டில்), டாமில் (டா) மற்றும் ஆங்க பெரிய அளபுரு அளவுகள் மூலம் நாம் மாற்றி உருவாக்கத்தை பயன்படுத்தி சிறந்த செயல்பாட்டை பெறுகிறோம். 30 திசைகளை மொழிபெயர்த்த ஒரு பல மொழி மாதிரியை பயிற்சி செய்கிறோம். நாம் முன் செயல்படுத்தல் மற்றும் வடிகட்டி பெரிய அளவு இரு மொழி மற்றும் மொன்மொழி தரவு அமைப்புகளில் விவரமான முன்செயல பின் மொழிபெயர்ப்பு, மீண்டும் மொழிபெயர்ப்பு, பொதுவான அறிவு வீழ்ப்பு, அடிப்டர் நன்றி மூடுதல் போன்ற மாதிரிகளை பயிற்சிக்க பயன்படுத்தப நம் மாதிரி முடிவில் போராட்டியின் முடிவுகளை பெறுகிறது.', 'vi': 'Tờ giấy này giới thiệu việc giao dịch Trung tâm Dịch Vụ Hoài Cảnh (HW-TSC) cho Nhiệm vụ Dịch vụ WM 2021 Phòng đa ngôn ngữ lớn. Chúng tôi tham gia vào Samll track\\ 35; 2, bao gồm cả 6 ngôn ngữ: JavaScript (Jv), Indonesia (I), Malay (Ms), Tagalog (T1), Tamil (Ta) và Anh (Ân) với 30 hướng dưới điều kiện bị cưỡng bức. Chúng tôi sử dụng kiến trúc transformer và đạt được hiệu suất tốt nhất qua nhiều biến thể với kích thước Tham số lớn hơn. Chúng tôi đào tạo một mô- đun phát ngôn để dịch tất cả các hướng 30. Chúng tôi xử lý và lọc chi tiết trên các nhà dữ liệu hai ngôn ngữ và chung ngôn ngữ được cung cấp. Một số chiến lược thường được dùng để huấn luyện các mô hình của chúng ta, như Back Translation, Forward Translation, Ensemble knowledge Disllation, Adaptaer fine-tunning. Mẫu này cuối cùng sẽ có kết quả cạnh tranh.', 'uz': "Name We participate in Samll Track #2, including 6 languages: Javanese (Jv), Indonesian (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) and English (En) with 30 directions under the constrained condition.  Biz Transfer architektordan foydalanamiz va bir necha varianter bilan katta parametr sizlari orqali eng yaxshi bajarish natijasini olib tashlamiz. We train a single multilingual model to translate all the 30 directions.  Biz juda katta ko'p tillar va monolingan maʼlumotlar tarkibini bajaramiz. Koʻp nechta ishlatilgan strategiyalar modellarimizni o'rganish uchun ishlatiladi. Qaytadan tarjima qilish, orqaga tarjima qilish, taʼrif tarjima qilish, ta'lim tarjima qilish, Adapter Fine-tuning. Bizning modelimiz ijodkorlik natijalariga ega bo'ladi.", 'bg': 'Настоящата статия представя представянето на Центъра за преводачески услуги към задачата за многоезичен превод. Участваме в Самл писта #2, включваща 6 езика: джавански (JV), индонезийски (Id), малайски (Ms), тагалогски (Tl), тамилски (Ta) и английски (En) с 30 посоки при ограничени условия. Използваме архитектура на трансформатора и получаваме най-доброто представяне чрез множество варианти с по-големи размери на параметрите. Обучаваме един многоезичен модел за превод на всички 30 посоки. Извършваме подробна предварителна обработка и филтриране на предоставените широкомащабни двуезични и едноезични набори от данни. Няколко често използвани стратегии се използват за обучение на нашите модели, като например Обратен превод, Преден превод, Ансамбъл Дестилация на знанието, Адаптер фина настройка. Нашият модел постига конкурентни резултати в крайна сметка.', 'da': 'Dette papir præsenterer indsendelsen af Huawei Translation Services Center (HW-TSC) til WMT 2021 Large-Scale Multilingual Translation Task. Vi deltager i Saml Track # 2, herunder 6 sprog: Javanesisk (Jv), Indonesisk (Id), Malaysisk (Ms), Tagalog (Tl), Tamil (Ta) og engelsk (En) med 30 retninger under den begrænsede betingelse. Vi bruger Transformer arkitektur og opnår den bedste ydeevne via flere varianter med større parameterstørrelser. Vi træner en enkelt flersproget model til at oversætte alle de 30 retninger. Vi udfører detaljeret forbehandling og filtrering på de leverede storstilede tosprogede og ensprogede datasæt. Flere almindeligt anvendte strategier bruges til at træne vores modeller, såsom Back Translation, Forward Translation, Ensemble Knowledge Destillation, Adapter Fintuning. Vores model opnår konkurrencedygtige resultater i sidste ende.', 'hr': 'Ovaj papir predstavlja predavanje centra za prevod Huawei usluga (HW-TSC) WMT 2021 Velikom skalom višejezičkog prevoda. Učestvujemo u Samll Track #2, uključujući 6 jezika: japanski (Jv), Indonezijski (Id), Malajski (gđica), Tagalog (Tl), Tamil (Ta) i engleski (En) s 30 smjernica pod ograničenim uvjetom. Koristimo arhitekturu Transformera i dobijemo najbolju učinku putem višestrukih varianta s većim veličinama parametara. Treniramo jednog multijezičkog model a da prevodimo sve 30 smjera. Izvodimo detaljne predobrađivanje i filtriranje na pruženim velikim dvojezičkim i monojezičkim podacima. Nekoliko često korišćenih strategija se koristi za obuku našeg modela, kao što su Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Naš model dobija konkurentne rezultate na kraju.', 'ko': '본고는 화웨이 번역서비스센터(HW-TSC)가 WMT 2021 대형 다국어 번역 임무에 대한 제출 현황을 소개한다.우리는 자바어(Jv), 인도네시아어(Id), 말레이시아어(Ms), 타갈로어(Tl), 타밀어(Ta), 영어(En) 등 6개 언어에 참가해 제한된 조건에서 30개 방향을 제공했다.우리는 Transformer 구조를 사용하여 비교적 큰 파라미터 크기의 여러 변체를 통해 최상의 성능을 얻는다.우리는 모든 30개의 방향을 번역하기 위해 단일한 다국어 모델을 훈련했다.우리는 제공된 대규모 이중 언어와 단어 데이터 집합에 대해 상세한 사전 처리와 필터를 진행한다.우리는 역방향 번역, 정방향 번역, 통합 지식 추출, 어댑터 마이크로스피커 등 몇 가지 자주 사용하는 전략을 사용하여 우리의 모델을 훈련시켰다.우리의 모델은 마침내 경쟁력 있는 결과를 얻었다.', 'fa': 'این کاغذ تحویل مرکز خدمات ترجمه Huawei (HW-TSC) را به WMT 2021 کشور ترجمه\u200cهای زیادی زبان نشان می\u200cدهد. ما در ترک Samll #2 شرکت می\u200cکنیم، شامل ۶ زبان: ژاپنی (Jv), ایندانشی (Id), مالای (خانم) تاگالوگ (Tl), تامیل (Ta) و انگلیسی (En) با ۳۰ مسیر زیر شرایط محدودیت. ما از معماری تبدیل کننده استفاده می\u200cکنیم و بهترین عملکرد را با اندازه\u200cهای پارامتر بزرگ می\u200cگیریم. ما یک مدل متعدد زبان را آموزش می\u200cدهیم تا تمام ۳۰ مسیر را ترجمه کند. ما در مجموعه\u200cهای داده\u200cهای دو زبان و یک زبان بزرگ پیش\u200cپردازی و فیلتر کردن جزئیات را انجام می\u200cدهیم. تعدادی استراتژی که معمولاً استفاده می\u200cشود برای آموزش مدل\u200cهای ما استفاده می\u200cشود، مثل ترجمه\u200cهای عقب، ترجمه\u200cهای پیش\u200cفرستادن، خرابی دانش\u200cهای استفاده می\u200cشود، تنظیم\u200cکننده\u200cی اذاتگر نیکو. مدل ما نتیجه رقابتی را در آخر می گیرد.', 'sw': 'Gazeti hili linaonyesha ujumbe wa Kituo cha Tafsiri cha Huawei (HW-TSC) kwa kazi ya Tafsiri kubwa ya lugha 2021 WMT 2021. Tunashiriki katika Track #2, ikiwa ni pamoja na lugha sita: Wajavani (Jv), Indonesia (Id), Malay (Bi), Tagalog (Tl), Tamil (Ta) na Kiingereza (En) wakiwa na maelekezo 30 chini ya hali inayolazimika. Tunatumia ujenzi wa Transformer na kupata ufanisi bora kwa kupitia mabadiliko mengi yenye ukubwa wa kipimo kikubwa. Tunafundisha muundo mmoja wa lugha mbalimbali kutafsiri njia 30 zote. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual datasets.  Mipango kadhaa zilizotumika mara nyingi hutumiwa kufundisha mifano yetu kama vile Tafsiri ya Uhambuzi, Tafsiri ya Ujasusi, Utafiti wa Ujuzi unaoendelea, Mafunzo mazuri. Mfano wetu unapata matokeo ya ushindani mwishoni.', 'nl': 'Dit document presenteert de indiening van Huawei Translation Services Center (HW-TSC) aan de WMT 2021 Large-Scale Multilingual Translation Task. We nemen deel aan Samll Track #2, inclusief zes talen: Javaans (Jv), Indonesisch (Id), Maleis (Ms), Tagalog (Tl), Tamil (Ta) en Engels (En) met 30 richtingen onder de beperkte voorwaarde. We gebruiken Transformer architectuur en verkrijgen de beste prestaties via meerdere varianten met grotere parametergroottes. We trainen één meertalig model om alle 30-richtingen te vertalen. We voeren gedetailleerde voorbewerking en filtering uit op de verstrekte grootschalige tweetalige en eentalige datasets. Verschillende veelgebruikte strategieën worden gebruikt om onze modellen te trainen, zoals Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Ons model behaalt uiteindelijk concurrerende resultaten.', 'id': 'Kertas ini menunjukkan pengiriman Huawei Translation Services Center (HW-TSC) ke WMT 2021 Large-Scale Multilingual Translation Task. We participate in Samll Track #2, including 6 languages: Javanese (Jv), Indonesian (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) and English (En) with 30 directions under the constrained condition.  We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes.  Kami melatih satu model multibahasa untuk menerjemahkan semua 30 arah. We perform detailed pre-processing and filtering on the provided large-scale bilingual and monolingual datasets.  Beberapa strategi yang biasa digunakan untuk melatih model kita, seperti Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Model kita mendapatkan hasil kompetitif pada akhirnya.', 'tr': "Bu kagyz Huawei Terjime Servis Merkezi (HW-TSC) WMT 2021'e Ullakan-Kalamlar Çoklu Diller terjime Görevini görkez. Samll Track #2'da bölegimiz bar, 6 diller: Jawanyça (Jv), Indoneziýa (Id), Malaýça (Ms), Tagalog (Tl), Tamil (Ta) we Ingiliýa (En) diýilip 30 ýagdaýlary bar. Biz Transformer arhitektegi ullanýarys we köp wariantçylar bilen iň gowy ukyplary al. 30 yönlerini terjime etmek üçin bir köp dilli nusga öwredýäris. Biz uly ölçekli iki dilli we monodilli veri setirlerinde detaylar öňe işleýän we süýşirdik. Birnäçe köplenç ulanylan strategiýalary nusglarymyzy öwretmek üçin, iň terjime, ileri terjime etmek üçin ullanýar. Biziň nusgymyz soňunda ýaryşykly netijeleri gazanýar.", 'de': 'Dieses Papier stellt die Einreichung des Huawei Translation Services Center (HW-TSC) an die WMT 2021 Large-Scale Multilingual Translation Task vor. Wir nehmen am Samll Track #2 teil, einschließlich 6-Sprachen: Javanisch (Jv), Indonesisch (Id), Malaiisch (Ms), Tagalog (Tl), Tamil (Ta) und Englisch (En) mit 30-Richtungen unter der eingeschränkten Bedingung. Wir verwenden Transformer-Architektur und erzielen die beste Leistung über mehrere Varianten mit größeren Parametergrößen. Wir trainieren ein einziges mehrsprachiges Modell, um alle 30-Richtungen zu übersetzen. Wir führen eine detaillierte Vorverarbeitung und Filterung der bereitgestellten zweisprachigen und einsprachigen Datensätze durch. Mehrere häufig verwendete Strategien werden verwendet, um unsere Modelle zu trainieren, wie Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Finetuning. Unser Modell erzielt am Ende wettbewerbsfähige Ergebnisse.', 'af': "Hierdie papier stel die onderskrywing van Huawei Vertaling Deenste Sentrum (HW- TSC) aan die WMT 2021 Groot- Skaal Veelvuldige Vertaling Opdrag. Ons deel by Samll Snit #2, insluitend 6 tale: Javanese (Jv), Indonesiese (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) en Engels (En) met 30 rigtings onder die beperkte voorwaarde. Ons gebruik Transformer arkitektuur en verkry die beste prestasie deur veelvuldige variante met groter parameter grootte. Ons trein 'n enkele multilinglike model om alle 30 rigtings te vertaal. Ons uitvoer gedetaliseerde voorprosessering en filtrering op die verskaf groot- skaal twee- tale en monolinglike datastel. Verskeie gewoonlik gebruikte strategies word gebruik om ons modele te tref, soos Terug Vertaling, Vorentoe Vertaling, Ensemble Knowledge Distillation, Adapter Fine- tuning. Ons model kry mededingsresultate in die einde.", 'am': 'ይህ ፕሮግራም የHuawei ትርጉም ማዕከላዎችን (HW-TSC) ወደ WMT 2021 ትልቅ-ሚልቋንቋ ትርጉም ማዕከላውን ያቀርባል። በ6 ቋንቋዎች ውስጥ ሳምሌ መድረክ #2 እናጋራለን፤ ያvanese (Jv), ኢንዶኒያዊ (Id), ማላይ (Ms), ታክሎግ (Tl), ታሚል (Ta) እና እንግሊዘኛ (ዓይን) በታች 30 መንገዶች አሉ። የተለየፉትን የመዝገብ ግንኙነት እናስቀምጣለን በተለይ ምርጫዎች መጠን እናስፈልጋለን፡፡ 30 መንገዶችን ለመተርጉም አንዲትን ብልቋንቋ ሞዴል እናስተምራለን፡፡ የደረጃ ልዩ ቋንቋ እና በሞሎልቋል ዳታዎች ላይ የተለየውን የፊደል ክፍተት እና አጣራ እናደርጋለን፡፡ በርካታ የተጠቀሙት ስርዓት ምሳሌዎቻችንን እንደሚያስተምር፣ ቅድሚያ ትርጉም፣ ለፊት ትርጉም፣ እውቀት መግለጫ፣ አዳapter ፍሬን ማቀናጃ በመጠቀም ይጠቅማል፡፡ ሞዴሌያችን ፍሬያዎችን ለፍጻሜው ያገኛል፡፡', 'az': "Bu kağıt Huawei Tercümə Servisi Merkezi (HW-TSC) WMT 2021'nin böyük-ölçülü çoxlu dil tercümə işini təyin edir. Biz Samll Track #2 içində 6 dil içərisində daxil edirik: Javanese (Jv), Indoneziya (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) və İngilizə (En) müəyyən edilmiş şəkildə 30 yönəldir. Biz Transformer arhitektarını kullanırıq və çoxlu variablar vasitəsilə ən yaxşı performans alırıq. Biz 30 tərəfləri tərcümə etmək üçün bir çox dil modeli təhsil edirik. Biz böyük-ölçülü iki dil və monodil veri qurularında detaylı ön işləmə və filtrləmə işlədik. Bizim modellərimizi təhsil etmək üçün çoxlu sıradan istifadə edilən stratejilər, əvvəlki Tərcümə, İleri Tərcümə, Ensemble Bilgi Destillation, Adapter Fine-tuning kimi istifadə edilir. Modelimiz sonunda münafiq sonuçlarını alır.", 'hy': 'Այս թղթին ներկայացնում է Հուավեյի թարգմանման ծառայությունների կենտրոնի (HW-GTC) ներկայացումը 2021 թվականի ԱՄԹ-ի մեծ մասի բազլեզու թարգմանման գործին: Մենք մասնակցում ենք 2-րդ սեմլ տողում, ներառյալ 6 լեզուն՝ ջավաներեն (Jv), ինդոնեզիացի (ID), մալայի (տիկին), թագալոգ (Tl), թամիլ (Տա) և անգլերեն (Էն), 30 ուղղությամբ սահմանափակ վիճակում: Մենք օգտագործում ենք Transforme ճարտարապետությունը և ստանում ենք լավագույն արդյունքը բազմաթիվ տարբերակների միջոցով, որոնք ունեն ավելի մեծ պարամետրերի չափսեր: Մենք վարժեցնում ենք մեկ բազլեզու մոդել, որպեսզի թարգմանենք բոլոր 30 ուղղությունները: Մենք կատարում ենք մանրամասն նախավերամշակում և ֆիլտրում երկլեզու և միալեզու տվյալների համակարգերի վրա: Մեր մոդելների ուսուցման համար օգտագործվում են տարբեր սովորաբար օգտագործված ռազմավարություններ, ինչպիսիք են հետադարձ թարգմանությունը, առաջնադարձ թարգմանությունը, համակարգչային գիտելիքների դիստիլացիան, Ադապտերների բարելավումը: Մեր մոդելը վերջում մրցակցության արդյունքներ է ստանում:', 'bn': 'This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task.  আমরা স্যাম্ল ট্র্যাক #২-এ অংশগ্রহণ করি, যার মধ্যে ৬ ভাষা রয়েছে: জাভানিজ (জেভি), ইন্দোনেশিয়ান (আইডি), মালায় (মিস), ট্যাগালোগ (টিল), তামিল (টা) এবং ইংরেজী  আমরা ট্রান্সফ্রান্সফারের আর্কিটার ব্যবহার করি এবং বেশী প্যারামিটার আকারের মাধ্যমে সেরা প্রভাব পেতে পারি। We train a single multilingual model to translate all the 30 directions.  আমরা বিস্তারিত পূর্ব প্রক্রিয়া এবং ফিল্টার করি বিস্তারিত দ্বিতীয় ভাষা এবং মোনোলিভাল ডাটাসেটের উপর। বেশ কিছু সাধারণত ব্যবহার করা কৌশল আমাদের মডেল প্রশিক্ষণের জন্য ব্যবহার করা হয়েছে, যেমন ব্যাক ট্রান্সভার, ফিরে যাওয়ার অনুবাদ, জ্ঞান বিভ্র আমাদের মডেল শেষে প্রতিযোগিতার ফলাফল পেয়েছে।', 'ca': "Aquest article presenta la presentació del Huawei Translation Services Center (HW-TSC) a la tasca de traducció multilingüe a gran escala del WMT 2021. Participem en Samll Track #2, incloent 6 llengües: xavanès (Jv), indonésiu (Id), malày (Ms), Tagalog (Tl), tamil (Ta) i anglès (En) amb 30 direccions sota la condició restringida. Utilitzem arquitectura Transformer i obtenim el millor rendiment a través de múltiples variants amb grans mida de paràmetres. Ensenyem un únic model multilingüe per traduir totes les 30 direccions. Fem un pré-processament detallat i filtrar els conjunts de dades bilingües i monolingües proporcionats a gran escala. Diverses estratègies comunament utilitzades s'utilitzen per formar els nostres models, com Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. El nostre model obté resultats competitius al final.", 'cs': 'Tento příspěvek představuje předložení Centra překladatelských služeb Huawei (HW-TSC) k WMT 2021 Large-Scale Multilingual Translation Task. Účastníme se Samll Track #2, včetně šesti jazyků: javanština (Jv), indonéština (Id), malajština (Ms), tagalog (Tl), tamilština (Ta) a angličtina (En) s 30 směry za omezených podmínek. Používáme architekturu Transformer a dosahujeme nejlepšího výkonu prostřednictvím více variant s většími parametry. Trénujeme jeden vícejazyčný model pro překlad všech 30 směrů. Na poskytnutých rozsáhlých dvojjazyčných a jednojjazyčných datových sadách provádíme detailní předzpracování a filtrování. K tréninku našich modelů se používá několik běžně používaných strategií, jako je zpětný překlad, dopředu překlad, destilace znalostí souborů, jemné ladění adaptérů. Náš model nakonec dosahuje konkurenčních výsledků.', 'fi': 'Tässä artikkelissa esitellään Huawein käännöspalvelukeskuksen (HW-TSC) toimittaminen WMT 2021 Large-Scale Multilingual Translation Task -ohjelmaan. Osallistumme Samll Track #2, sisältäen 6 kieltä: javaani (JV), indonesia (Id), malai (Ms), tagalog (Tl), tamil (Ta) ja englanti (En) 30 suunnalla rajoitetussa tilassa. Käytämme Transformer-arkkitehtuuria ja saavutamme parhaan suorituskyvyn useilla muunnelmilla, joilla on isommat parametrikoot. Koulutamme yhden monikielisen mallin kääntämään kaikki 30 suuntaa. Suoritamme yksityiskohtaisen esikäsittelyn ja suodatuksen toimitetuille suurille kaksikielisille ja yksikielisille aineistoille. Mallien kouluttamiseen käytetään useita yleisesti käytettyjä strategioita, kuten Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Mallimme tuottaa lopulta kilpailukykyisiä tuloksia.', 'et': 'Käesolevas artiklis tutvustatakse Huawei tõlketeenuste keskuse (HW-TSC) esitamist WMT 2021 laiaulatuslikule mitmekeelsele tõlketööle. Osaleme Samll Track #2, sealhulgas 6 keelt: jaavan (JV), indoneesia (Id), malai (Ms), tagalog (Tl), tamil (Ta) ja inglise (En) 30 suunaga piiratud tingimusel. Kasutame Transformeri arhitektuuri ja saavutame parima jõudluse mitme suurema parameetri suurusega variandi kaudu. Me koolitame ühe mitmekeelse mudeli tõlkimiseks kõiki 30 suunda. Teeme pakutavate suurte kaks- ja ühekeelsete andmekogumite detailset eeltöötlust ja filtreerimist. Meie mudelite koolitamiseks kasutatakse mitmeid tavaliselt kasutatavaid strateegiaid, nagu tagasitõlkimine, edasitõlkimine, ansambli teadmiste destillatsioon, adapteri peenhäälestus. Meie mudel saavutab lõpuks konkurentsivõimelisi tulemusi.', 'sq': 'Ky artikull paraqet paraqitjen e Qendrës së Shërbimeve të Përkthimit të Huaweit (HW-TSC) në WMT 2021 Large-Scale Multilingual Translation Task. Ne marrim pjesë në Samll Track #2, duke përfshirë 6 gjuhë: xhavaneze (Jv), Indonezian (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) dhe Anglisht (En) me 30 drejtime nën kushtin e kufizuar. Ne përdorim arkitekturën Transformer dhe fitojmë performancën më të mirë nëpërmjet varianteve të shumta me madhësitë më të mëdha të parametrave. Ne trajnojmë një model të vetëm shumëgjuhës për të përkthyer të gjitha 30 drejtimet. Ne kryejmë paraprocesim të hollësishëm dhe filtrim në të dhënat e dhëna në shkallë të madhe dygjuhëse dhe monogjuhëse. Disa strategji të përdorura zakonisht përdoren për të trajnuar modelet tona, të tilla si Përkthimi mbrapa, Përkthimi i Përparshëm, Distilimi i Njohjes së Përbashkët, Përrregullimi i Adapterit. Modeli ynë merr rezultate konkurruese në fund.', 'bs': 'Ovaj papir predstavlja predavanje Centra za prevod Huawei usluga (HW-TSC) WMT 2021 Velikom skalom višejezičkog prevoda. Mi učestvujemo u Samll Track #2, uključujući 6 jezika: Japanski (Jv), Indonezijski (Id), Malajski (gđica), Tagalog (Tl), Tamil (Ta) i engleski (En) sa 30 uputa pod ograničenim uvjetom. Koristimo arhitekturu Transformera i dobijamo najbolju funkciju putem višestrukih varianta sa većim veličinama parametara. Treniramo jednog multijezičkog model a da prevedemo sve 30 smjera. Izvodimo detaljne predobrađivanje i filtriranje na pruženim velikim dvojezičkim i monojezičkim podacima. Nekoliko često korišćenih strategija se koristi za obuku našeg modela, kao što su Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Naš model dobija konkurentne rezultate na kraju.', 'sk': 'Ta prispevek predstavlja predložitev središča za prevajalske storitve Huawei (HW-TSC) za nalogo večjezičnega prevajanja WMT 2021. Sodelujemo na Samll Track #2, vključno s 6 jeziki: javanščina (JV), indonezijščina (Id), malajščina (Ms), tagaloščina (Tl), tamil (Ta) in angleščina (En) s 30 smeri pod omejenim pogojem. Uporabljamo arhitekturo transformatorjev in dosegamo najboljšo zmogljivost preko več različic z večjimi velikostmi parametrov. Usposabljamo en večjezični model za prevajanje vseh 30 smeri. Izvajamo podrobno predobdelavo in filtriranje na zagotovljenih obsežnih dvojezičnih in enojezičnih naborih podatkov. Za usposabljanje naših modelov se uporablja več pogosto uporabljenih strategij, kot so Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. Naš model na koncu doseže konkurenčne rezultate.', 'he': "העבודה הזו מציגה את ההעברה של מרכז שירות התרגום של הואאווי (HW-TSC) למשימה של WMT 2021 של מערכת התרגום רבולוגית בקנה גדול. אנחנו משתתפים במסלול מס' 2, כולל 6 שפות: יהואנית (Jv), אינדונזית (Id), מלאי (Ms), טאגלוג (Tl), טמיל (Ta) ואנגלית (En) עם 30 כיוונים תחת המצב המוגבל. אנחנו משתמשים בארכיטקטורה Transformer ולקבל את ההופעה הטובה ביותר באמצעות שונים רבים עם גודלים פרמטרים גדולים יותר. אנחנו מאמן מודל רב-שפוי אחד לתרגם את כל 30 הכיוונים. אנו מבצעים מעבדה מראש ומסרט מפורטת על קבוצות נתונים שתיים-שפותיים ומונולשפותיים ברמה גדולה. מספר אסטרטגיות משתמשות בדרך כלל משתמשות כדי לאמן את הדוגמנים שלנו, כמו תרגום מאחור, תרגום קדימה, דיסטיל ידע סמום, התאמה מתאימה. המודל שלנו מקבל תוצאות תחרותיות בסופו של דבר.", 'ha': "Wannan takardan na bãyar da wasiyyar da tsarin Translate Services Center (HW-TSC) zuwa the WMT 2021 Large- scale multilinglanguage. Tuna tãrayya da Samll Track #2, tare da harshen 6: Javan (JV), Industoniya (Id), Malay (Miss), Tagalog (Tl), Tamili (Ta) da Ingiriya (en) sunã da hanyõyi 30 a ƙarƙashin ƙayyade. Tuna amfani da tsarin Transformer kuma Muke sami mafarin aiki da ke fi kyauta a tsakanin wasu variants da girma. Tuna sanar da misalin mulki guda dõmin mu translate dukkan hanyõyin 30. Munã cika fassarar-bayan-aiki da za'a filter a kan da aka bai wa data masu tsawo biyu-bilimi da sauri. Ko da yawa aka yi amfani da kayan yi amfani da su tunkuɗe misalinmu, kamar Translate Back, Translate Forward, Disappearation of Cilmi da Ana Cilmi, Adappter Fine-tuning. Misalinmu yana iya samun matsala ta ƙarami.", 'jv': 'Gambar iki bakal ngewehhu nggambar urip nggambar huawei translation services center (HWT-T sc) kanggo the WT 2020 1 big-scale Multilanguage translation task. Awak dhéwé menyang pisan ning Samll track section Awak dhéwé luwih akeh sistem sing sampeyan kanggo tarjamah tanggal 30 Learn Mode politenessoffpolite"), and when there is a change ("assertivepoliteness Awakdhéwé model nyengé sawetara dadi kanggo ngwalé.', 'bo': 'This paper presents the submission of Huawei Translation Services Center (HW-TSC) to the WMT 2021 Large-Scale Multilingual Translation Task. ང་ཚོས་Samll Track #2 ནང་དུ་ཡོད་པའི་སྐད་ཡིག་གཟུགས་འགྲོ་བ་ནི། Javanese (Jv), Indonesian (Id), Malay (Ms), Tagalog (Tl), Tamil (Ta) and English (En) with 30 directions under the constrained condition. We use Transformer architecture and obtain the best performance via multiple variants with larger parameter sizes. ང་ཚོས་སྐད་ཡིག་གཟུགས་ཀྱི་མ་དབྱིབས་གཅིག ང་ཚོས་བྱིས་ཡོད་པའི་སྔོན་སྒྲིག་ཞིབ་དང་བསུབ་ནུས་པ་གཉིས་ཀྱི་སྒྲིག་ཆ་དང་གཅིག་སྐད་ཡིག་གཟུགས་ཀྱི་ཆ་འཕྲིན་ སྤྱིར་བཏང་བའི་འཇིག་སྟངས་མང་པོ་སྤྱད་ནས་ང་ཚོའི་མིག་དཔེར་ན། Back Translation, Forward Translation, Ensemble Knowledge Distillation, Adapter Fine-tuning. ང་ཚོའི་མ་དབྱིབས་མཐའ་མཇུག་གི་རྒྱལ་ཁབ་ཕྱིར་ཐོན་པ་རེད།'}
{'en': 'Just Ask ! Evaluating ', 'ar': 'فقط إسأل! تقييم الترجمة الآلية عن طريق طرح الأسئلة والإجابة عليها', 'pt': 'É só perguntar! Avaliando a tradução automática fazendo e respondendo perguntas', 'fr': 'Il suffit de demander\xa0! Évaluer la traduction automatique en posant des questions et en y répondant', 'es': '¡Solo pregunta! Evaluación de la traducción automática mediante la formulación y respuesta de preguntas', 'ja': '質問するだけ！質問して答えることで機械翻訳を評価する', 'zh': '但问! 问对以质机器翻译', 'hi': 'बस पूछो! प्रश्न पूछने और उत्तर देने से मशीन अनुवाद का मूल्यांकन करना', 'ru': 'Просто спросите! Оцените машинный перевод, задавая и отвечая на вопросы', 'ga': 'Just a Iarr! Aistriú Meaisín a Mheas trí Cheisteanna a chur agus a Fhreagairt', 'ka': 'ოპჲჟრჲ ოთრაი! Name', 'el': 'Απλά ρώτα! Αξιολόγηση της μηχανικής μετάφρασης κάνοντας ερωτήσεις και απαντώντας σε ερωτήσεις', 'hu': 'Csak kérdezz! A gépi fordítás értékelése kérdések feltevésével és megválaszolásával', 'lt': 'Tik paklausk! Evaluating Machine Translation by Asking and Answering Questions', 'it': 'Chiedi e basta! Valutare la traduzione automatica facendo e rispondendo alle domande', 'mk': 'Just Ask!  Evaluating Machine Translation by Asking and Answering Questions', 'kk': 'Сұраңыз! Сұрақтар мен жауап беру арқылы машинаның аудармасын оқу', 'mt': 'Staqsi biss! Evalwazzjoni tat-Traduzzjoni tal-Makkinarju permezz ta’ Mistoqsijiet u Tweġibiet', 'ms': 'Just Ask!  Mengevaluasi Terjemahan Mesin dengan Tanya dan Jawab Soalan', 'mn': 'Зөвхөн асуух! Машины орчуулалтыг асууж, хариулах асуултуудад', 'ml': 'ചോദിക്ക്! ചോദ്യങ്ങള്\u200d ചോദിക്കുന്നതിനും ഉത്തരം നല്\u200dകുന്നതിനുമായി മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നു', 'ro': 'Doar întreabă! Evaluarea traducerii automate prin punerea și răspunsul la întrebări', 'no': 'Spør berre! Evaluerer maskinsomsetjing ved å spørja og svara spørsmål', 'pl': 'Po prostu pytaj! Ocena tłumaczenia maszynowego poprzez zadawanie i odpowiadanie na pytania', 'sr': 'Samo pitaj! Procjenjivanje prevoda mašine pitanjem i odgovorom na pitanja', 'si': 'අහන්න! ප්\u200dරශ්න අහන්න සහ ප්\u200dරතිච්චාරයෙන් මැෂින් පරිවර්තනය විශ්ලේෂණය කරන්න', 'so': "Warso! Qiimeynta tarjumaadda mashiinka ee weydiinta iyo jawaabta su'aalaha", 'sv': 'Fråga bara! Utvärdera maskinöversättning genom att ställa och besvara frågor', 'ta': 'கேள்! கேள்விகள் மற்றும் பதில் அளிக்கப்படும் மொழிபெயர்ப்பை மதிப்பிடுகிறது', 'ur': 'سوال کرو! سوال پوچھنے اور جواب دینے کے ذریعے ماشین ترجمہ کا ارزش کیا جاتا ہے', 'uz': 'Soò£rash! Name', 'vi': 'Hỏi đi! Đánh giá máy dịch bằng cách hỏi và trả lời câu hỏi', 'nl': 'Vraag het gewoon! Machine Translation evalueren door vragen te stellen en te beantwoorden', 'bg': 'Просто попитай! Оценка на машинния превод чрез задаване и отговор на въпроси', 'de': 'Frag einfach! Bewertung der maschinellen Übersetzung durch Stellen und Beantworten von Fragen', 'hr': 'Samo pitaj! Procjenjivanje prevoda strojeva pitanjem i odgovorom na pitanja', 'da': 'Bare spørg! Evaluering af maskinoversættelse ved at stille og besvare spørgsmål', 'ko': '물어봐!질문과 대답을 통해 기계 번역을 평가하다', 'fa': 'فقط بپرس! ارزیابی ترجمه ماشین با پرسیدن و جواب سوالات', 'af': 'Vra net! Evalueer Masjien Vertaling deur vrae en Antwoord', 'sw': 'Unauliza! Kuthibitisha Tafsiri ya Mashini na Kuomba na kujibu maswali', 'id': 'Tanya saja! Evaluating Machine Translation by Asking and Answering Questions', 'am': 'Just Ask!  Evaluating Machine Translation by Asking and Answering Questions', 'hy': 'Պարզապես հարցրեք: Մեքենայի թարգմանություն գնահատելը հարցերի տալով և պատասխանելով', 'az': 'Sadəcə soruş! Soruşmaq və cavab verən suallar vasitəsilə mašin tercüməsini təmin edir', 'bs': 'Samo pitaj! Procjenjivanje prevoda mašine pitanjem i odgovorom na pitanja', 'tr': 'Diňe sora! Makin terjimesini sorap we jogap bermek üçin hasaplanjak', 'ca': 'Només pregunteu! Evaluar la traducció de màquines fent preguntes', 'cs': 'Prostě se zeptej! Hodnocení strojového překladu kladením a zodpovězením otázek', 'et': 'Lihtsalt küsi! Masintõlke hindamine küsimustele vastamise ja esitamise teel', 'bn': 'জিজ্ঞেস করো! প্রশ্ন এবং উত্তর প্রশ্নের মাধ্যমে মেশিন অনুবাদ পরিচালিত হচ্ছে', 'fi': 'Kysy vain! Konekäännöksen arviointi kysymällä ja vastaamalla kysymyksiin', 'sq': 'Vetëm pyet! Duke vlerësuar përkthimin e makinës duke bërë dhe përgjigjur pyetjeve', 'sk': 'Samo vprašaj! Ocenjevanje strojnega prevajanja z zastavljanjem in odgovarjanjem na vprašanja', 'ha': 'Just Ask!  Yana kasa tarjima na Maine da ake tambayar da kuma ana karɓa', 'he': 'רק תשאל! Evaluating Machine Translation by Asking and Answering Questions', 'bo': 'འདྲི་དགོས་པ། འདྲི་ཞིབ་དང་ལན་གསལ་བཤད་ལ་ལག་འཁྱེར་གྱི་ཚིག་རྒྱུན་ལྡན་བཟོ་བྱེད་པ', 'jv': 'Tulung sikir! Ngawe Perintah Panjenengan Terjamahan kanggo ngubah karo Perintah Panjenengan'}
{'en': 'In this paper, we show that automatically-generated questions and answers can be used to evaluate the quality of Machine Translation (MT) systems. Building on recent work on the evaluation of abstractive text summarization, we propose a new ', 'ar': 'في هذه الورقة ، نوضح أنه يمكن استخدام الأسئلة والأجوبة التي يتم إنشاؤها تلقائيًا لتقييم جودة أنظمة الترجمة الآلية (MT). بناءً على العمل الأخير على تقييم تلخيص النص التجريدي ، نقترح مقياسًا جديدًا لتقييم MT على مستوى النظام ، ومقارنته بأحدث الحلول الأخرى ، وإظهار قوتها من خلال إجراء تجارب لاتجاهات MT المختلفة.', 'pt': 'Neste artigo, mostramos que perguntas e respostas geradas automaticamente podem ser usadas para avaliar a qualidade dos sistemas de tradução automática (TA). Com base em trabalhos recentes sobre a avaliação da sumarização de texto abstrativa, propomos uma nova métrica para avaliação de TA em nível de sistema, comparamos com outras soluções de última geração e mostramos sua robustez realizando experimentos para várias direções de TA.', 'fr': "Dans cet article, nous montrons que les questions et réponses générées automatiquement peuvent être utilisées pour évaluer la qualité des systèmes de traduction automatique (TA). Sur la base de travaux récents sur l'évaluation de la synthèse de textes abstraits, nous proposons une nouvelle métrique pour l'évaluation MT au niveau du système, la comparons à d'autres solutions de pointe et montrons sa robustesse en menant des expériences pour différentes directions de TA.", 'zh': '于本文,展自生之理,与对案可质机器翻译(MT)系统之量。 近于抽象文本摘要评事,立一新统机器翻译评指标,比之先进之解决方案,实验诸MT方以验其鲁棒性。', 'es': 'En este artículo, mostramos que las preguntas y respuestas generadas automáticamente se pueden utilizar para evaluar la calidad de los sistemas de traducción automática (MT). Sobre la base del trabajo reciente sobre la evaluación de la síntesis de textos abstractivos, proponemos una nueva métrica para la evaluación de MT a nivel de sistema, la comparamos con otras soluciones de vanguardia y demostramos su solidez mediante la realización de experimentos para varias direcciones de MT.', 'hi': 'इस पेपर में, हम दिखाते हैं कि मशीन अनुवाद (एमटी) सिस्टम की गुणवत्ता का मूल्यांकन करने के लिए स्वचालित रूप से उत्पन्न प्रश्नों और उत्तरों का उपयोग किया जा सकता है। अमूर्त पाठ सारांशीकरण के मूल्यांकन पर हाल के काम पर निर्माण, हम सिस्टम-स्तर के एमटी मूल्यांकन के लिए एक नया मीट्रिक प्रस्तावित करते हैं, इसकी तुलना अन्य अत्याधुनिक समाधानों के साथ करते हैं, और विभिन्न एमटी दिशाओं के लिए प्रयोगों का संचालन करके इसकी मजबूती दिखाते हैं।', 'ja': 'この論文では、自動生成された質問と回答を使用して、機械翻訳（ MT ）システムの品質を評価できることを示しています。抽象的なテキスト要約の評価に関する最近の研究に基づいて、システムレベルのMT評価のための新しい指標を提案し、他の最先端のソリューションと比較し、様々なMT方向の実験を行うことによってその堅牢性を示します。', 'ru': 'В этой статье мы показываем, что автоматически генерируемые вопросы и ответы могут быть использованы для оценки качества систем машинного перевода (MT). Опираясь на недавнюю работу по оценке абстрактного текстового обобщения, мы предлагаем новую метрику для оценки МП на системном уровне, сравниваем ее с другими современными решениями и демонстрируем ее устойчивость путем проведения экспериментов по различным направлениям МП.', 'ga': 'Sa pháipéar seo, léirímid gur féidir ceisteanna agus freagraí a ghintear go huathoibríoch a úsáid chun cáilíocht na gcóras Aistriúcháin Meaisín (MT) a mheas. Ag tógáil ar an obair a rinneadh le déanaí ar mheastóireacht ar achoimriú teibí téacs, molaimid méadrach nua le haghaidh meastóireachta MT ar leibhéal an chórais, cuirfimid é i gcomparáid le réitigh nua-aimseartha eile, agus léirímid a stóinseacht trí thurgnaimh a dhéanamh le haghaidh treoracha MT éagsúla.', 'ka': 'ჩვენ ჩვენ აჩვენებთ, რომ ავტომატურად შექმნილი კითხვები და პასუხები შეიძლება გამოიყენება მაქსინური გადაწყვეტილების (MT) სისტემის კავილეტის გასამუშაობ აბსტრაქტიური ტექსტის სიმბოლოების განსაზღვრებისათვის შემდეგ ახალი მეტრიკის MT განსაზღვრებისათვის გავაკეთებთ და სხვა სახელის განსაზღვრებისათვის გადაკეთებთ და გამოჩვენებთ ძალიან ექსპერიმენტების გავაკეთებთ განსხვ', 'el': 'Στην παρούσα εργασία, καταδεικνύουμε ότι οι αυτόματα δημιουργημένες ερωτήσεις και απαντήσεις μπορούν να χρησιμοποιηθούν για την αξιολόγηση της ποιότητας των συστημάτων μηχανικής μετάφρασης (ΜΤ). Βασιζόμενοι σε πρόσφατες εργασίες για την αξιολόγηση της αφηρημένης σύνοψης κειμένου, προτείνουμε μια νέα μετρική για την αξιολόγηση του συστήματος, τη συγκρίνουμε με άλλες λύσεις τελευταίας τεχνολογίας, και αποδεικνύουμε την ανθεκτικότητά της με τη διεξαγωγή πειραμάτων για διάφορες κατευθύνσεις ΜΤ.', 'hu': 'Ebben a tanulmányban bemutatjuk, hogy az automatikusan generált kérdések és válaszok felhasználhatók a Gépi Fordítás (MT) rendszerek minőségének értékelésére. Az absztraktív szövegösszefoglalás értékelésével kapcsolatos közelmúltbeli munkákra építve új metrikát javasolunk rendszerszintű MT értékeléshez, összehasonlítjuk más korszerű megoldásokkal, és különböző MT irányokban végzett kísérletekkel mutatjuk meg robusztusságát.', 'lt': 'Šiame dokumente parodomi, kad automatiškai sukurti klausimai ir atsakymai gali būti naudojami vertinant mašinų vertimo (MT) sistemų kokybę. Remdamiesi pastaruoju metu atliktu abstrakčios teksto santraukos vertinimo darbu, siūlome naują MT vertinimo sistemos lygmeniu metriką, palyginti ją su kitais naujausiais sprendimais ir parodyti jo patikimumą atliekant įvairių MT krypčių eksperimentus.', 'kk': 'Бұл қағазда, автоматты түрде құрылған сұрақтар мен жауаптарды машина аудару (MT) жүйелерінің сапатын бағалау үшін қолданылады. Абстрактивті мәтін тұжырымдамасын бағалау үшін жаңа жұмыс істеу үшін жүйелік деңгейіндегі MT бағалау үшін жаңа метрикалық мәтінді ұсынып, оны басқа әртүрлі шешімдермен салыстырып, MT бағыттарына тұжырымдылығын көр', 'it': "In questo articolo, mostriamo che domande e risposte generate automaticamente possono essere utilizzate per valutare la qualità dei sistemi di traduzione automatica (MT). Basandoci sui recenti lavori sulla valutazione della sintesi astratta del testo, proponiamo una nuova metrica per la valutazione MT a livello di sistema, la confrontiamo con altre soluzioni all'avanguardia e mostriamo la sua robustezza conducendo esperimenti per varie direzioni MT.", 'mk': 'In this paper, we show that automatically-generated questions and answers can be used to evaluate the quality of Machine Translation (MT) systems.  Користејќи се на неодамнешната работа за проценка на апстрактивната резултатација на текстот, предложуваме нова метрика за проценка на МТ на системско ниво, ја споредуваме со другите најсовремени решенија и ја покажуваме својата силност со спроведување експерименти за различни МТ насоки.', 'mt': 'F’dan id-dokument, naraw li mistoqsijiet u tweġibiet ġenerati awtomatikament jistgħu jintużaw biex tiġi evalwata l-kwalità tas-sistemi tat-Traduzzjoni tal-Magni (MT). Filwaqt li nibnu fuq ħidma reċenti dwar l-evalwazzjoni tas-sommarju tat-test astrattiv, nipproponu metrika ġdida għall-evalwazzjoni MT fil-livell tas-sistema, nipparagunawha ma’ soluzzjonijiet l-aktar avvanzati oħra, u nuru r-robustezza tagħha billi nipproponu esperimenti għal diversi direzzjonijiet MT.', 'ms': 'Dalam kertas ini, kami menunjukkan bahawa soalan dan jawapan yang dijana secara automatik boleh digunakan untuk menilai kualiti sistem Terjemahan Mesin (MT). Membangun pada kerja baru-baru ini pada penilaian ringkasan teks abstraktif, kami cadangkan metrik baru untuk penilaian MT aras sistem, membandingkannya dengan penyelesaian-penyelesaian yang lain, dan menunjukkan kekuatannya dengan melakukan eksperimen untuk berbagai arah MT.', 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d കാണിക്കുന്നു, സ്വയം സൃഷ്ടിച്ച ചോദ്യങ്ങളും ഉത്തരം ഉപയോഗിക്കാന്\u200d സാധിക്കുന്നു മെഷീന്\u200d പരിഭാഷ (എംടി Building on recent work on the evaluation of abstractive text summarization, we propose a new metric for system-level MT evaluation, compare it with other state-of-the-art solutions, and show its robustness by conducting experiments for various MT directions.', 'no': 'I denne papiret viser vi at automatisk genererte spørsmål og svar kan brukast til å evaluera kvaliteten på maskineoversettelsystemet (MT). I oppbygging av nyleg arbeid på evalueringa av abstraktive tekstsammendrag, fører vi ein ny metrisk for systemnivå MT-evalueringa, sammenlignet det med andre kunstløysing, og vise kraftigheten ved å gjera eksperimenter for ulike MT-retningar.', 'pl': 'W artykule pokazujemy, że automatycznie generowane pytania i odpowiedzi mogą być wykorzystane do oceny jakości systemów tłumaczenia maszynowego (MT). Opierając się na najnowszych pracach nad oceną abstrakcyjnego podsumowania tekstu, proponujemy nową metrykę oceny MT na poziomie systemu, porównujemy ją z innymi najnowocześniejszymi rozwiązaniami oraz pokazujemy jej solidność poprzez prowadzenie eksperymentów dla różnych kierunków MT.', 'mn': 'Энэ цаасан дээр бид автоматаар үүсгэсэн асуултууд, хариултуудыг машин хөгжүүлэх (MT) системийн сайн чанарыг үнэлэхэд ашиглаж болно. Саяхан ажил дээр abstractive text summarization-ын үнэлгээ хийхэд бид системийн түвшинд MT-ийн үнэлгээ шинэ метрик санал болгож, бусад урлагийн шийдвэрлэлтэй харьцуулж, өөр төрлийн MT руу дамжуулан туршилтыг хийж чаддаг.', 'ro': 'În această lucrare, arătăm că întrebările și răspunsurile generate automat pot fi utilizate pentru a evalua calitatea sistemelor de traducere automată (MT). Bazându-ne pe lucrările recente privind evaluarea rezumatului abstractiv al textului, propunem o nouă metrică pentru evaluarea MT la nivel de sistem, o comparăm cu alte soluții de ultimă generație și demonstrăm robustețea acesteia prin efectuarea de experimente pentru diferite direcții MT.', 'so': "Warqadan waxaynu ku tusnaynaa in su'aalo iyo jawaabo ay automatic ka soo saaray ay u isticmaali karaan in lagu qiimeeyo qiimeynta nidaamka turjumidda Masiinka (MT). Buildidda shaqada ee ugu dambeeyay qiimeynta qiimeynta qoraalka ee abstractiv ah, waxaynu soo jeedaynaa metric cusub oo lagu qiimeeyo heerka MT ee nidaamka ah, waxaynu isbarbardhignaa xafiisyada farshaxanka kale, waxaana tusinaynaa dharkiisa ku sameynta imtixaanka hagitaanka MT oo kala duduwan.", 'sr': 'U ovom papiru pokazujemo da se automatski stvoreni pitanja i odgovori mogu koristiti za procjenu kvalitete sistema za prevod mašine (MT). Na osnovu nedavnog rada o procjeni sažetka abstraktivnog teksta, predlažemo novu metriku za procjenu MT-a na nivou sistema, usporediti ga sa drugim stanjem umjetnosti rješenja, i pokazati svoju snagu provođenjem eksperimenata za različite smjere MT-a.', 'sv': 'I denna uppsats visar vi att automatiskt genererade frågor och svar kan användas för att utvärdera kvaliteten på maskinöversättningssystem. Utifrån det senaste arbetet med utvärdering av abstraktiv textsammanfattning föreslår vi ett nytt mått för systemnivå MT utvärdering, jämför det med andra state-of-the-art lösningar och visar dess robusthet genom att genomföra experiment för olika MT riktningar.', 'si': 'මේ පැත්තේ, අපි පෙන්වන්නේ ස්වයංක්\u200dරියාවිතයෙන් නිර්මාණය කරපු ප්\u200dරශ්න සහ ප්\u200dරතිච්චි ප්\u200dරශ්නය සඳහා ප්\u200d අලුත් වැඩේ විශ්වාස කරලා තියෙන්නේ අවස්ථාවක් පාළුවක් සංශ්\u200dය විශ්වාස කරන්න, අපි පද්ධතිය-පද්ධතිය MT විශ්වාස සඳහා අලුත් මෙට්\u200dරික් ප්\u200dරතිචාර', 'ta': 'இந்த காகிதத்தில், நாம் தானாகவே உருவாக்கப்பட்ட கேள்விகள் மற்றும் பதில்களை காட்டுகிறோம் என்பதை தானாகவே இயந்திரத் மொழிபெயர்ப அண்மையில் செயல்பாடு உரை சுருக்கத்தின் மதிப்பீட்டை அமைப்பு நிலை MT மதிப்பிற்கு புதிய மெட்ரிக் நாம் பரிந்துரைக்கிறோம், அதை மற்ற நிலையில் கலை தீர்வுகளுடன் ஒப்பிடு', 'ur': 'ہم اس کاغذ میں دکھاتے ہیں کہ ماشین ترجمہ (MT) سیستموں کی کیفیت کا ارزش کرنے کے لئے سوال اور جواب استعمال کر سکتے ہیں۔ ہم نے سیسٹم-سطح MT ارزیابی کے لئے نو میٹریک پیشنهاد کریں، اس کو دوسری حالت-آرت حل کے ساتھ مقایسہ کریں، اور اس کی طاقت دکھائیں، مختلف MT طریقوں کے لئے آزمائش کریں.', 'uz': "Bu hujjatda biz avtomatik yaratilgan savollar va javoblar tizimning сифатini qidirish uchun ishlatiladi. Yaqinda, abstraktiv matn hisoblanishni qiymatida ishni yaratish, biz tizim darajasi MT qiymatiga yangi metrik rivojlanamiz, uning boshqa holatda qiymatlashni istasangiz, va uning o'zgarishni ko'rsatdik, har xil MT yordamlari uchun tizim tizimni qiymatlashni anglatamiz.", 'vi': 'Trong tờ giấy này, chúng tôi cho thấy các câu hỏi và câu trả lời tự động có thể được dùng để đánh giá chất lượng của máy Dịch (MTV) hệ thống. Dựa trên những nghiên cứu gần đây về việc đánh giá tóm tắt văn bản trừu tượng, chúng tôi đề xuất một hệ thống hoá mới để đánh giá MTV, so sánh nó với các giải pháp hiện đại, và thể hiện sự kiên trì của nó bằng cách tiến hành thí nghiệm theo các hướng MTV khác nhau.', 'bg': 'В тази статия показваме, че автоматично генерирани въпроси и отговори могат да бъдат използвани за оценка на качеството на системите за машинен превод (МТ). Въз основа на скорошна работа по оценка на абстрактното обобщаване на текста, ние предлагаме нов показател за оценка на МТ на системно ниво, сравняваме го с други съвременни решения и показваме неговата устойчивост чрез провеждане на експерименти за различни МТ направления.', 'nl': 'In dit artikel laten we zien dat automatisch gegenereerde vragen en antwoorden kunnen worden gebruikt om de kwaliteit van Machine Translation (MT) systemen te evalueren. Voortbouwend op recent werk over de evaluatie van abstracte tekstsamenvattingen, stellen we een nieuwe metric voor MT-evaluatie op systeemniveau voor, vergelijken deze met andere state-of-the-art oplossingen en tonen de robuustheid ervan aan door experimenten uit te voeren voor verschillende MT-richtingen.', 'hr': 'U ovom papiru pokazujemo da se automatski stvoreni pitanja i odgovori mogu koristiti za procjenu kvalitete sustava za prevod strojeva (MT). Na temelju nedavnog rada o procjeni sažetka abstraktivnog teksta, predlažemo novu metriku za procjenu MT-a na razini sustava, usporediti ga s drugim stanjem umjetnosti rješenja i pokazati svoju snagu provođenjem eksperimenata za različite smjere MT-a.', 'de': 'In diesem Beitrag zeigen wir, dass automatisch generierte Fragen und Antworten genutzt werden können, um die Qualität von maschinellen Übersetzungssystemen zu bewerten. Aufbauend auf aktuellen Arbeiten zur Evaluation abstrakter Textzusammenfassungen schlagen wir eine neue Metrik für die Bewertung von MT auf Systemebene vor, vergleichen sie mit anderen State-of-the-Art Lösungen und zeigen ihre Robustheit durch Experimente für verschiedene MT-Richtungen.', 'id': 'Dalam kertas ini, kami menunjukkan bahwa pertanyaan dan jawaban yang secara otomatis dapat digunakan untuk mengevaluasi kualitas sistem Translation Mesin (MT). Berdasarkan pekerjaan baru-baru ini pada evaluasi ringkasan teks abstraktif, kami mengusulkan metrik baru untuk evaluasi MT tingkat sistem, membandingkannya dengan solusi terbaik lainnya, dan menunjukkan kekuatannya dengan melakukan eksperimen untuk berbagai arah MT.', 'ko': '본고에서 우리는 자동적으로 생성된 문제와 답안을 보여줌으로써 기계번역(MT) 시스템의 질을 평가할 수 있다.최근 추상적인 텍스트 요약 평가 작업에 대한 토대에서 우리는 새로운 시스템급 기계 번역 평가 지표를 제시했고 이를 다른 가장 선진적인 해결 방안과 비교했으며 각종 기계 번역 방향에 대한 실험을 통해 노봉성을 증명했다.', 'fa': 'در این کاغذ، نشان می دهیم که سوالات و پاسخ\u200cها با توسط خودکار تولید شده\u200cاند برای ارزیابی کیفیت سیستم\u200cهای ترجمه ماشین (MT) استفاده می\u200cشوند. بر اساس کارهای اخیر روی ارزیابی پیام abstractive، ما یک متریک جدید برای ارزیابی MT سطح سیستم پیشنهاد می کنیم، آن را با بقیه راه حل های هنری مقایسه می کنیم، و استعداد آن را با انجام آزمایش های مختلف طریق MT نشان می دهیم.', 'da': 'I denne artikel viser vi, at automatisk genererede spørgsmål og svar kan bruges til at evaluere kvaliteten af maskinoversættelsessystemer. Med udgangspunkt i det seneste arbejde med evaluering af abstraktiv tekst resuméering foreslår vi en ny metric til systemniveau MT evaluering, sammenligner den med andre state-of-the-art løsninger, og viser dens robusthed ved at udføre eksperimenter for forskellige MT retninger.', 'af': "In hierdie papier, wys ons dat automaties genereerde vrae en antwoorde kan gebruik word om die kwaliteit van Masjien Vertaling (MT) stelsels te evalueer. By gebou op onlangse werk op die evaluering van abstraktiewe teks opsomming, voorstel ons 'n nuwe metriek vir stelsel-vlak MT evaluering, vergelyk dit met ander staat-van-kuns oplossing, en wys sy kragtigheid deur eksperimente vir verskillende MT rigtings te doen.", 'sw': 'Katika gazeti hili, tunaonyesha kwamba maswali na majibu yanayozaliwa kwa wenyewe yanaweza kutumika ili kutathmini ubora wa mfumo wa Tafsiri wa Mashine (MT). Kujenga kazi za hivi karibuni juu ya tathmini za muhtasari wa simu za mkono, tunapendekeza mbinu mpya kwa ajili ya uchunguzi wa mfumo wa MT, ukilinganisha na hali nyingine ya sanaa, na kuonyesha uchumi wake kwa kutekeleza majaribio kwa maelekezo mbalimbali ya MT.', 'hy': 'Այս թղթի մեջ մենք ցույց ենք տալիս, որ ինքնաբերաբար ստեղծված հարցեր և պատասխաններ կարող են օգտագործվել մեքենայի թարգմանման (MT) համակարգերի որակի գնահատման համար: Building on recent work on the evaluation of abstractive text summarization, we propose a new metric for system-level MT evaluation, compare it with other state-of-the-art solutions, and show its robustness by conducting experiments for various MT directions.', 'am': 'በዚህ ገጾች ውስጥ የተፈጠረ ጥያቄዎችን እና መልሶችን የመኪን ትርጉም (MT) ስርዓት ብልሃት ለማስተካከል ይቻላል ብለን እናሳያቸዋለን፡፡ አዲስ የጽሑፍ አቀማመጥ ማቀናጃ ላይ የሚሠራውን ሥራ በመሠረት፣ ለስርዓት ደረጃ MT ማስታወቂያ አዲስ ሚትሪክን እናስተያየዋለን፣ ለሌሎች የልዩ ትምህርት ትምህርት እና ልብሱን ለልዩ MT መንገዶች በመፈለግ እናሳየዋለን፡፡', 'bn': 'এই কাগজটিতে আমরা দেখাচ্ছি যে স্বয়ংক্রিয়ভাবে উদ্ভাবন করা প্রশ্ন এবং উত্তর ব্যবহার করা যাবে মেশিন অনুবাদের মান মূল্যায়নের জন্য। সাম্প্রতিক কাজ নির্মাণের উপর আত্মসংক্রান্ত টেক্সট সংক্ষেপের মূল্য নির্মাণ করা, আমরা সিস্টেম-পর্যায়ে এমটি মুল্যায়নের জন্য একটি নতুন মেট্রিক প্রস্তাব করছি, এটিকে অন্যান্য', 'tr': 'Bu kagyzda, biz otomatik üretilen soraglar we jogaplar maşynyň terjime sistemleriniň (MT) kalitesini deňlemek üçin ulanylýandygyny görkezip bilýäris. Ýakyndaky işe abstraktiw metin toplamynyň deňlemesi üzerine tapylýan, sistem-derejesi MT deňlemesi üçin täze metrik we muny başga möhüm çözümleri bilen karşılaştırıp, we muny ýolaryň güýçlenýänligini görkez we çäreleriň düýbünden MT yönlerine görkez.', 'sq': 'Në këtë letër, ne tregojmë se pyetje dhe përgjigje të gjeneruara automatikisht mund të përdoren për të vlerësuar cilësinë e sistemeve të përkthimit të makinave (MT). Building on recent work on the evaluation of abstractive text summarization, we propose a new metric for system-level MT evaluation, compare it with other state-of-the-art solutions, and show its robustness by conducting experiments for various MT directions.', 'ca': "En aquest article, demostram que les preguntes i respostes generades automàticament poden ser utilitzades per avaluar la qualitat dels sistemes de traducció màquina. Construïnt en la feina recent sobre l'evaluació de la resumització abstracta del text, proposem una nova mètrica per a l'evaluació MT a nivell sistemàtic, la comparem amb altres solucions d'última edat i demostrem la seva robustet fent experiments per diverses direccions MT.", 'cs': 'V tomto článku ukazujeme, že automaticky generované otázky a odpovědi mohou být použity k hodnocení kvality systémů strojového překladu (MT). Na základě nedávné práce na hodnocení abstraktivní textové shrnutí navrhujeme novou metriku pro hodnocení MT na systémové úrovni, porovnáváme ji s ostatními nejmodernějšími řešeními a ukážeme její robustnost prováděním experimentů pro různé směry MT.', 'et': 'Käesolevas töös näitame, et automaatselt genereeritud küsimusi ja vastuseid saab kasutada masintõlke (MT) süsteemide kvaliteedi hindamiseks. Toetudes hiljutisele abstraktse teksti kokkuvõtte hindamise tööle, pakume välja uue meetodi süsteemitasandi MT hindamiseks, võrdleme seda teiste kaasaegsete lahendustega ning näitame selle tugevust läbi katsete läbiviimise erinevates MT suundades.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa osoitetaan, ettﾃ､ automaattisia kysymyksiﾃ､ ja vastauksia voidaan kﾃ､yttﾃ､ﾃ､ konekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmien laadun arviointiin. Abstraktisen tekstitiivistelmﾃ､n arvioinnin pohjalta ehdotamme uutta mittaria jﾃ､rjestelmﾃ､tason MT-arviointiin, vertaamme sitﾃ､ muihin huippuluokan ratkaisuihin ja osoitamme sen kestﾃ､vyyden tekemﾃ､llﾃ､ kokeita eri MT-suuntiin.', 'az': 'Bu kańüńĪzda, otomatik t…ôŇükil edilmiŇü suallar v…ô cevaplar maŇüńĪn √ßeviriŇü sisteml…ôrinin keyfiyy…ôtini deńüerl…ôŇüdirm…ôk √ľ√ß√ľn istifad…ô edil…ô bil…ôc…ôyini g√∂st…ôririk. Son iŇül…ôrd…ô abstraktiv metin t…ômizl…ônm…ôsinin deńüerl…ônm…ôsi haqqńĪnda, sistem seviyy…ôtind…ô MT deńüerl…ônm…ôsi √ľ√ß√ľn yeni metrik t…ôklif edirik, dig…ôr Ňü…ôkild…ô sanat √ß…ôtinl…ôri il…ô qarŇüńĪlaŇüdńĪrńĪr, v…ô m√ľxt…ôlif MT y√∂nl…ôrind…ô eksperimentl…ôri t…ôŇükil edir.', 'bs': 'U ovom papiru pokazujemo da se automatski generirani pitanja i odgovori mogu koristiti za procjenu kvalitete sustava za prevod mašine (MT). Na temelju nedavnog rada o procjeni sažetka abstraktivnog teksta predlažemo novu metriku za procjenu MT-a na nivou sustava, uspoređujemo ga sa drugim stanjem umjetnosti rješenja, i pokažemo svoju snagu provođenjem eksperimenata u različitim smjerovima MT-a.', 'ha': "Daga wannan takardan, Munã nũna wa tambayar da aka haife su farat ɗaya da za'a iya amfani da su canza sifar tsarin Tafsiri na Mashine (MT). Kana samar da aikin na farko a kan evaluation of abõkan matsayin na kanrakati, muna buƙatan wata metric wa muhalli na tsari-MT, kuma mu sami shi da wasu halin-masu sanawa, kuma mu nuna tufãfinsa da ke samun majarin da ke samun shiryoyin MT-wasu.", 'he': 'In this paper, we show that automatically-generated questions and answers can be used to evaluate the quality of Machine Translation (MT) systems.  Building on recent work on the evaluation of abstractive text summarization, we propose a new metric for system-level MT evaluation, compare it with other state-of-the-art solutions, and show its robustness by conducting experiments for various MT directions.', 'sk': 'V prispevku smo pokazali, da je mogoče avtomatsko ustvarjena vprašanja in odgovore uporabiti za oceno kakovosti sistemov strojnega prevajanja (MT). Na podlagi nedavnega dela na področju vrednotenja abstraktivnega povzetka besedila predlagamo novo merilo za sistemsko vrednotenje MT, jo primerjamo z drugimi najsodobnejšimi rešitvami in pokažemo njeno robustnost z izvajanjem eksperimentov za različne smeri MT.', 'jv': 'Nang pepulan iki, kéné ngerasawa dipontong karo akeh automatik lan gambaran iso nggunakake karo kalitas karo sistem Anyar Terjamahan (MT). Ngawe nggawe barang sistem sing karo hal-hal perusahaan kelas depurasi teks, kita enyesteke sistem karo hal-hal MT kuwi nggawe barang sistem, nggawe gerarané karo perusahaan sistem sing gawe-perusahaan lan akeh podho nggawe nguasai perusahaan anyar sampeyan MT.', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་རང་འགུལ་གྱིས་རང་འགུལ་གྱིས་གསར་བསྐྲུན་ཡོད་པའི་དྲི་ཚིག་དང་ལན་གསལ་བ་ཚུ་སྤྱོད་ཐུབ་པ་འད Building on recent work on the evaluation of abstractive text summarization, we propose a new metric for system-level MT evaluation, compare it with other state-of-the-art solutions, and show its robustness by conducting experiments for various MT directions.'}
{'en': 'Evaluating Multiway Multilingual NMT in the ', 'ar': 'تقييم NMT متعدد اللغات في اللغات التركية', 'fr': 'Évaluation de la NMT multilingue multivoie dans les langues turques', 'es': 'Evaluación de la NMT multilingüe multidireccional en los idiomas túrquicos', 'pt': 'Avaliando o NMT multilíngue multidirecional nas línguas turcas', 'ja': 'テュルク諸語の多言語NMTの評価', 'hi': 'तुर्की भाषाओं में बहुभाषी NMT का मूल्यांकन करना', 'zh': '评估突厥语多途多语 NMT', 'ru': 'Оценка многоязычия НМТ на тюркских языках', 'ga': 'Meastóireacht a dhéanamh ar NMT Ilbhealaigh Ilteangach sna Teangacha Turcacha', 'ka': 'Multiway Multilingual NMT- ის განსაზღვრება ტერქიური ენაში', 'it': "Valutazione dell'NMT multilingue multimodale nelle lingue turche", 'el': 'Αξιολόγηση Πολυδιάστατης Πολυγλωσσικής ΜΤ στις Τουρκικές Γλώσσες', 'lt': 'Turkų kalbomis daugiakalbės NMT vertinimas', 'mk': 'Оценувањето на мултијазичната НМТ на турските јазици', 'ms': 'Menghargai NMT Berberbilang Jalan dalam Bahasa Turki', 'ml': 'ടുര്\u200dക്കിക് ഭാഷകളില്\u200d പല ഭാഷകളുടെ NMT പ്രക്രിയയിക്കുന്നു', 'mn': 'Турк хэл дээр олон хэл NMT-г үнэлэх', 'hu': 'Többutas többnyelvű NMT értékelése a török nyelveken', 'kk': 'Түрк тілдерінде көп тілді NMT бағалау', 'ro': 'Evaluarea NMT multilingv în limbile turce', 'no': 'Evaluerer fleirspråk NMT i tyrkiske språk', 'pl': 'Ocena wielojęzycznego NMT w językach tureckich', 'si': 'Multiway Multilanguage NMT විශ්ලේෂණය තුර්කික භාෂාවට', 'sv': 'Utvärdering av flervägs flerspråkig NMT på turkiska språk', 'so': 'Evaluating Multiway Multilingual NMT in the Turkic Languages', 'mt': 'Evalwazzjoni ta’ NMT Multilingwi fil-Lingwi Torok', 'ta': 'துருக்கி மொழிகளில் பல மொழி NMT மதிப்பிடப்படுகிறது', 'ur': 'ترکیک زبانوں میں Multiway Multilingual NMT کا ارزش کیا جاتا ہے', 'sr': 'Procjenjivanje Multiway Multilingual NMT-a na turskim jezicima', 'uz': "Turkcha tillarda ko'plab tillar NMT qiymati", 'vi': 'Đánh giá phát ngôn ngữ đa ngôn ngữ vô ngôn ngữ Thổ Nhĩ Kỳ', 'bg': 'Оценка на многостранната многоезична НМТ по турски езици', 'nl': 'Het evalueren van meertalige NMT in de Turkse talen', 'da': 'Evaluering af flersproget NMT i de tyrkiske sprog', 'hr': 'Procjenjivanje Multiway Multilingual NMT-a na turskim jezicima', 'de': 'Bewertung von Multiway Multilingual NMT in den türkischen Sprachen', 'fa': 'ارزیابی NMT Multiway Multilingual in the Turkic languages', 'ko': '돌궐어에서 다중 언어 NMT 평가', 'id': 'Mengevaluasi Multilingual NMT dalam Bahasa Turki', 'sw': 'Kupima lugha nyingi za lugha za Uturuki', 'af': 'Evalueer Multiway Multilingual NMT in die Turkse Taal', 'tr': 'Türk dillerinde köp dilli NMT sanyna çykýar', 'sq': 'Vlerësimi i NMT shumëgjuhës në gjuhët turke', 'am': 'በቱርክ ቋንቋዎች ውስጥ ብዙ ቋንቋዎች NMT በማረጋገጥ', 'hy': 'Թուրքիայի լեզուներում բազմալեզու NMT-ի գնահատումը', 'az': 'T√ºrk dill…ôrind…ô Multiway Multilingual NMT deƒüerlendirm…ôk', 'bn': 'তুর্কিক ভাষায় মাল্টিভাষা এনএমটি পরিমাপ করা হচ্ছে', 'ca': 'Evaluating Multiway Multilingual NMT in the Turkic Languages', 'bs': 'Procjenjivanje Multiway Multilingual NMT-a na turskim jezicima', 'cs': 'Hodnocení vícejazyčného NMT v tureckých jazycích', 'et': 'Mitmepoolse mitmekeelse NMT hindamine türgi keeltes', 'fi': 'Monikielisen NMT:n arviointi turkin kielillä', 'jv': 'Ngulang nggawe Multi-lengkang NMT ning langgambar turki', 'sk': 'Vrednotenje večjezične NMT v turških jezikih', 'ha': 'KCharselect unicode block name', 'he': 'הערכה של NMT רבות דרכים בשפות הטורקיות', 'bo': 'ཊར་ཀིའི་སྐད་ཡིག་ནང་གི་སྣ་ཚོགས་སྐད་རིགས་དབྱེ་ཞིབ་བྱེད་པ'}
{'en': 'Despite the increasing number of large and comprehensive machine translation (MT) systems, evaluation of these methods in various languages has been restrained by the lack of high-quality parallel corpora as well as engagement with the people that speak these languages. In this study, we present an evaluation of state-of-the-art approaches to training and evaluating MT systems in 22 languages from the ', 'ar': 'على الرغم من العدد المتزايد لأنظمة الترجمة الآلية (MT) الكبيرة والشاملة ، إلا أن تقييم هذه الأساليب بلغات مختلفة كان مقيدًا بسبب عدم وجود هيئات موازية عالية الجودة بالإضافة إلى التعامل مع الأشخاص الذين يتحدثون هذه اللغات. في هذه الدراسة ، نقدم تقييمًا لأحدث المناهج لتدريب وتقييم أنظمة الترجمة الآلية بـ 22 لغة من عائلة اللغة التركية ، معظمها لم يتم استكشافه جيدًا. أولاً ، نعتمد مجموعة TIL Corpus مع بعض التحسينات الرئيسية على مجموعات التدريب والتقييم. بعد ذلك ، نقوم بتدريب 26 خطًا أساسيًا ثنائي اللغة بالإضافة إلى نموذج MT العصبي متعدد الاتجاهات (MNMT) باستخدام المجموعة وإجراء تحليل شامل باستخدام المقاييس التلقائية بالإضافة إلى التقييمات البشرية. وجدنا أن نموذج MNMT يتفوق في الأداء على جميع خطوط الأساس ثنائية اللغة تقريبًا في مجموعات الاختبار خارج المجال ، كما يؤدي ضبط النموذج في مهمة متلقية لزوج واحد إلى زيادة هائلة في الأداء في كل من سيناريوهات الموارد المنخفضة والعالية. يشير تحليلنا اليقظ لمعايير تقييم نماذج الترجمة الآلية باللغات التركية أيضًا إلى ضرورة إجراء مزيد من البحث في هذا الاتجاه. نقوم بإصدار انشقاقات الجسم ومجموعات الاختبار وكذلك النماذج للجمهور.', 'es': 'A pesar del creciente número de sistemas de traducción automática (MT) grandes y completos, la evaluación de estos métodos en varios idiomas se ha visto restringida por la falta de corpus paralelos de alta calidad, así como por el compromiso con las personas que hablan estos idiomas. En este estudio, presentamos una evaluación de los enfoques más avanzados para la capacitación y evaluación de sistemas de MT en 22 idiomas de la familia de lenguas túrquicas, la mayoría de los cuales están muy poco explorados. Primero, adoptamos el Corpus TIL con algunas mejoras clave en los conjuntos de capacitación y evaluación. Luego, entrenamos 26 líneas de base bilingües, así como un modelo de MT neuronal multidireccional (MNMT) utilizando el corpus y realizamos un análisis exhaustivo utilizando métricas automáticas y evaluaciones en humanos. Encontramos que el modelo MNMT supera a casi todas las líneas de base bilingües en los conjuntos de pruebas fuera del dominio y el ajuste fino del modelo en una tarea descendente de un solo par también da como resultado un enorme aumento del rendimiento en escenarios de recursos bajos y altos. Nuestro análisis atento de los criterios de evaluación de los modelos de MT en lenguas túrquicas también apunta a la necesidad de seguir investigando en esta dirección. Damos a conocer al público las divisiones de corpus, los conjuntos de pruebas y los modelos.', 'pt': 'Apesar do número crescente de sistemas de tradução automática (TA) grandes e abrangentes, a avaliação desses métodos em vários idiomas foi restringida pela falta de corpora paralelos de alta qualidade, bem como pelo envolvimento com as pessoas que falam esses idiomas. Neste estudo, apresentamos uma avaliação de abordagens de última geração para treinar e avaliar sistemas de TA em 22 línguas da família turca, a maioria das quais extremamente subexploradas. Primeiro, adotamos o TIL Corpus com algumas melhorias importantes nos conjuntos de treinamento e avaliação. Em seguida, treinamos 26 linhas de base bilíngues, bem como um modelo de MT neural multidirecional (MNMT) usando o corpus e realizamos uma análise extensa usando métricas automáticas e avaliações humanas. Descobrimos que o modelo MNMT supera quase todas as linhas de base bilíngues nos conjuntos de teste fora do domínio e o ajuste fino do modelo em uma tarefa downstream de um único par também resulta em um enorme aumento de desempenho em cenários de baixo e alto recurso. Nossa análise atenta dos critérios de avaliação para modelos de TA em línguas turcas também aponta para a necessidade de mais pesquisas nessa direção. Nós liberamos as divisões de corpus, conjuntos de testes e modelos para o público.', 'fr': "Malgré le nombre croissant de systèmes de traduction automatique (TA) étendus et complets, l'évaluation de ces méthodes dans différentes langues a été entravée par le manque de corpus parallèles de haute qualité et par l'absence d'engagement avec les personnes parlant ces langues. Dans cette étude, nous présentons une évaluation des approches de pointe en matière de formation et d'évaluation des systèmes de TA dans 22 langues de la famille des langues turciques, dont la plupart sont extrêmement sous-explorées. Tout d'abord, nous adoptons le Corpus TIL avec quelques améliorations clés apportées à la formation et aux ensembles d'évaluation. Ensuite, nous formons 26 lignes de base bilingues ainsi qu'un modèle de TA neuronale multidirectionnelle (MNMT) à l'aide du corpus et effectuons une analyse approfondie à l'aide de métriques automatiques ainsi que d'évaluations humaines. Nous constatons que le modèle MNMT surpasse presque toutes les lignes de base bilingues dans les ensembles de tests hors domaine et que le réglage précis du modèle sur une tâche en aval d'une seule paire entraîne également une augmentation considérable des performances dans les scénarios de ressources faibles et élevées. Notre analyse attentive des critères d'évaluation des modèles de traduction automatique dans les langues turciques souligne également la nécessité de poursuivre les recherches dans ce sens. Nous publions les divisions de corpus, les ensembles de tests ainsi que les modèles au public.", 'ja': '大規模かつ包括的な機械翻訳（ MT ）システムが増加しているにもかかわらず、様々な言語でのこれらの方法の評価は、高品質の並行体の欠如と、これらの言語を話す人々との関わりによって抑制されています。 この研究では、テュルク語族の22言語のMTシステムを訓練し、評価するための最先端のアプローチの評価を提示します。これらのアプローチのほとんどは極めて研究不足です。 まず、TILコーパスを採用し、トレーニングセットと評価セットをいくつかの主要な改善を行います。 次に、26のバイリンガルベースラインと、コーパスを使用した多方向ニューラルMT （ MNMT ）モデルをトレーニングし、自動メトリックとヒト評価を使用して広範な分析を行います。 MNMTモデルは、ドメイン外テストセットのほぼすべてのバイリンガルベースラインを上回り、単一ペアのダウンストリームタスクでモデルを微調整することで、低リソースおよび高リソースの両方のシナリオでパフォーマンスが大幅に向上することがわかります。 突厥語のMTモデルの評価基準を注意深く分析した結果、この方向へのさらなる研究の必要性も指摘されている。 コーパススプリット、テストセット、そしてモデルを一般に公開します。', 'zh': '虽大机器翻译(MT)统数增益,而乏高质量并行语料库及接言者,估估有限。 本论之,评用突厥语系22种语训练机器翻译系统之最新,其大率皆未尽。 先用 TIL 语料库,而训练评集,多所改进。 然后以语料库教 26 双语基线及多路神经机器翻译 (MNMT) 形,而以自指标与人工论广。 吾见域外试集,MNMT 其性优于几双语基线,而微于下流之任,亦生于低资源、高之间。 我们对突厥语MT模样细心分析也指了向这里更加研究的必要性。 发于公众语料库拆分,试集及模形。', 'hi': 'बड़े और व्यापक मशीन अनुवाद (एमटी) प्रणालियों की बढ़ती संख्या के बावजूद, विभिन्न भाषाओं में इन तरीकों का मूल्यांकन उच्च गुणवत्ता वाले समानांतर कॉर्पोरेट की कमी के साथ-साथ इन भाषाओं को बोलने वाले लोगों के साथ जुड़ाव से रोक दिया गया है। इस अध्ययन में, हम तुर्क भाषा परिवार से 22 भाषाओं में एमटी सिस्टम के प्रशिक्षण और मूल्यांकन के लिए अत्याधुनिक दृष्टिकोणों का मूल्यांकन प्रस्तुत करते हैं, जिनमें से अधिकांश बेहद कम-खोजे जाते हैं। सबसे पहले, हम प्रशिक्षण और मूल्यांकन सेट में कुछ महत्वपूर्ण सुधारों के साथ टीआईएल कॉर्पस को अपनाते हैं। फिर, हम 26 द्विभाषी बेसलाइन के साथ-साथ कॉर्पस का उपयोग करके एक बहु-तरफ़ा तंत्रिका एमटी (एमएनएमटी) मॉडल को प्रशिक्षित करते हैं और स्वचालित मीट्रिक के साथ-साथ मानव मूल्यांकन का उपयोग करके एक व्यापक विश्लेषण करते हैं। हम पाते हैं कि MNMT मॉडल आउट-ऑफ-डोमेन परीक्षण सेट में लगभग सभी द्विभाषी बेसलाइन को मात देता है और एक ही जोड़ी के डाउनस्ट्रीम कार्य पर मॉडल को ठीक करने के परिणामस्वरूप कम और उच्च-संसाधन परिदृश्यों दोनों में एक बड़ा प्रदर्शन बढ़ावा मिलता है। तुर्क भाषाओं में एमटी मॉडल के लिए मूल्यांकन मानदंडों का हमारा चौकस विश्लेषण भी इस दिशा में आगे के शोध की आवश्यकता को इंगित करता है। हम कॉर्पस विभाजन, परीक्षण सेट के साथ-साथ जनता के लिए मॉडल जारी करते हैं।', 'ru': 'Несмотря на растущее число крупных и всеобъемлющих систем машинного перевода (МП), оценка этих методов на различных языках сдерживается отсутствием высококачественных параллельных корпусов, а также взаимодействием с людьми, которые говорят на этих языках. В данном исследовании мы представляем оценку современных подходов к обучению и оценке систем МП на 22 языках тюркской языковой семьи, большинство из которых крайне недоизучены. Во-первых, мы принимаем TIL Corpus с несколькими ключевыми улучшениями в обучении и наборах оценки. Затем мы обучаем 26 двуязычных базовых линий, а также многофакторную нейронную модель MT (MNMT), используя корпус, и выполняем обширный анализ, используя автоматические метрики, а также оценки человека. Мы обнаружили, что модель MNMT превосходит почти все двуязычные базовые линии во внедоменных тестовых наборах, и тонкая настройка модели на последующем задании одной пары также приводит к огромному повышению производительности как в сценариях с низкими, так и высокими ресурсами. Наш внимательный анализ критериев оценки для моделей МП на тюркских языках также указывает на необходимость дальнейших исследований в этом направлении. Мы выпускаем корпусные сплиты, тестовые наборы, а также модели для публики.', 'ga': 'In ainneoin an méadú ar líon na gcóras aistriúcháin meaisín mór agus cuimsitheach, tá an measúnú ar na modhanna seo i dteangacha éagsúla srianta ag an easpa corpora comhthreomhar ardcháilíochta chomh maith le teagmháil leis na daoine a labhraíonn na teangacha sin. Sa staidéar seo, cuirimid i láthair meastóireacht ar chur chuige úrscothach maidir le hoiliúint agus meastóireacht a dhéanamh ar chórais MT i 22 teanga ón teaghlach Turcach, agus an chuid is mó díobh tearc-iniúchta. Ar dtús, glacaimid an Corpas TIL le roinnt feabhsuithe tábhachtacha ar an oiliúint agus ar na tacair mheastóireachta. Ansin, déanaimid oiliúint ar 26 bonnlíne dhátheangach chomh maith le samhail néarchóras ilbhealaigh (MNMT) ag baint úsáide as an gcorpas agus déanaimid anailís fhairsing ag baint úsáide as méadracht uathoibríoch chomh maith le meastóireachtaí daonna. Feictear dúinn go sáraíonn samhail an MNMT beagnach gach bonnlíne dhátheangach sna tacair tástála lasmuigh den fhearann agus má dhéantar mionchoigeartú ar an tsamhail ar thasc iartheachtach de phéire singil tá borradh mór feidhmíochta i gcásanna íseal-acmhainne agus ard-acmhainne araon. Léiríonn ár n-anailís aireach ar chritéir mheastóireachta do mhúnlaí MT i dteangacha Turcacha go bhfuil gá le tuilleadh taighde sa treo seo. Scaoilimid na scoilteanna corpais, na tacair tástála agus na múnlaí don phobal.', 'ka': 'დიდი და ყველაფერი მანქანის გაგრძელება (MT) სისტემების უფრო დიდი და ყველაფერი სისტემების გაგრძელებას მაგრამ განსხვავებული ენაში ამ მეტოვების გაგრძელება განსხვავებულია მანქანელი პარალელი კოპორაზე,  ამ კვლევაში ჩვენ გავაკეთებთ მსოფლიოს სახელსაწვდომის გავაკეთებას და გავაკეთებას MT სისტემის 22 ენაში რუკური ენათა ოჯახიდან, რომლებიც უფრო მეტი გავაკეთებულია. პირველად, ჩვენ TIL კოპოსს გავიყენებთ რამდენიმე გასაკეთებელი გასაკეთებელებით განაკეთებაში და განაკეთებაში. შემდეგ, ჩვენ 26 ორიენგური ბაზი ხაზები და მრავალური ნეიროლური MT (MNMT) მოდელის გამოყენება კორპუსს და გამოყენება განსაზღვრებული ანალიზი ავტომატიკური მეტრიკის გამოყენება და ადამიანის განსა ჩვენ ვიცით, რომ MNMT მოდელი მხოლოდ ყველა ორიენგური ფესტური ხაზების გარეშე დემომინის ტესტის კონფიგურაციაში და მოდელის გარეშე მოდელს ერთი ზოგის გარეშე შემდეგ გავაკეთება დიდი კონფიგურაციის გარეშე, რომელიც ჩ ჩვენი მნიშვნელოვანი ანალიზია MT მოდელების მოდელების MT კრიტერიების შესახებ ტერქიკური ენაში ასევე უნდა დააწყვანოთ უფრო მნიშვნელოვანი ამ მხარეს მე ჩვენ კორპუსს გავუშვებთ, ტესტის შესაბამისი მოდელების შესაბამისი გარეშე.', 'it': "Nonostante il numero crescente di grandi e completi sistemi di traduzione automatica (MT), la valutazione di questi metodi in varie lingue è stata limitata dalla mancanza di corpora parallela di alta qualità e dall'impegno con le persone che parlano queste lingue. In questo studio presentiamo una valutazione degli approcci all'avanguardia per la formazione e la valutazione dei sistemi MT in 22 lingue della famiglia delle lingue turche, la maggior parte delle quali estremamente poco esplorate. In primo luogo, adottiamo il TIL Corpus con alcuni miglioramenti chiave ai set di formazione e valutazione. Successivamente, addestriamo 26 linee di base bilingue e un modello MT neurale multidirezionale (MNMT) utilizzando il corpo ed eseguiamo un'analisi approfondita utilizzando metriche automatiche e valutazioni umane. Troviamo che il modello MNMT supera quasi tutte le linee di base bilingue nei set di test out-of-domain e la messa a punto del modello su un'attività downstream di una singola coppia si traduce anche in un enorme aumento delle prestazioni in scenari sia a basso che ad alto contenuto di risorse. La nostra attenta analisi dei criteri di valutazione dei modelli MT nelle lingue turche evidenzia anche la necessità di ulteriori ricerche in questa direzione. Rilasciamo al pubblico i corpus split, i test set e i modelli.", 'el': 'Παρά τον αυξανόμενο αριθμό των μεγάλων και περιεκτικών συστημάτων μηχανικής μετάφρασης (ΜΤ), η αξιολόγηση αυτών των μεθόδων σε διάφορες γλώσσες έχει περιοριστεί από την έλλειψη υψηλής ποιότητας παράλληλων σωμάτων καθώς και από την εμπλοκή με τους ανθρώπους που μιλούν αυτές τις γλώσσες. Στην παρούσα μελέτη, παρουσιάζουμε μια αξιολόγηση των σύγχρονων προσεγγίσεων για την εκπαίδευση και την αξιολόγηση συστημάτων ΜΤ σε 22 γλώσσες από την οικογένεια των τουρκικών γλωσσών, οι περισσότερες από τις οποίες είναι εξαιρετικά υποδιερευνημένες. Πρώτον, υιοθετούμε το Σώμα ΤΙΛ με μερικές βασικές βελτιώσεις στην εκπαίδευση και τα σύνολα αξιολόγησης. Στη συνέχεια, εκπαιδεύουμε 26 δίγλωσσες γραμμές βάσης καθώς και ένα μοντέλο πολλαπλών οδών νευρωνικό ΜΤ (ΜΜΤ) χρησιμοποιώντας το σώμα και διενεργούμε εκτεταμένη ανάλυση χρησιμοποιώντας αυτόματες μετρήσεις καθώς και ανθρώπινες αξιολογήσεις. Διαπιστώνουμε ότι το μοντέλο ξεπερνά σχεδόν όλες τις δίγλωσσες γραμμές βάσης στα εκτός πεδίου σύνολα δοκιμών και ο συντονισμός του μοντέλου σε μια μεταγενέστερη εργασία ενός ζευγαριού οδηγεί επίσης σε μια τεράστια αύξηση απόδοσης τόσο σε σενάρια χαμηλού όσο και υψηλού πόρου. Η προσεκτική ανάλυση των κριτηρίων αξιολόγησης των μοντέλων ΜΤ στις τουρκικές γλώσσες δείχνει επίσης την ανάγκη για περαιτέρω έρευνα προς αυτή την κατεύθυνση. Απελευθερώνουμε τα τμήματα σώματος, τα σετ δοκιμών καθώς και τα μοντέλα στο κοινό.', 'hu': 'A nagy és átfogó gépi fordítási (MT) rendszerek növekvő száma ellenére e módszerek különböző nyelveken történő értékelését korlátozta a kiváló minőségű párhuzamos korpuszok hiánya, valamint az ezeket a nyelveket beszélő emberekkel való elkötelezettség. Ebben a tanulmányban bemutatjuk az MT rendszerek képzésének és értékelésének legkorszerűbb megközelítéseit a török nyelvcsalád 22 nyelvén, amelyek nagy része rendkívül alul feltárt. Először is elfogadjuk a TIL Corpust, néhány kulcsfontosságú fejlesztéssel a képzési és értékelési készleten. Ezt követően 26 kétnyelvű alapvonalat és egy többirányú neurális MT (MNMT) modellt képezünk a korpusz felhasználásával, és átfogó elemzést végezünk automatikus mérésekkel és emberi értékelésekkel. Úgy találjuk, hogy az MNMT modell szinte minden kétnyelvű alapkészletet felülmúlja a domain kívüli tesztkészletekben, és a modell finomhangolása egyetlen pár downstream feladatára is hatalmas teljesítménynövekedést eredményez mind alacsony, mind nagy erőforrásokkal rendelkező forgatókönyvekben. A török nyelvű MT modellek értékelési kritériumainak figyelmes elemzése szintén rámutat arra, hogy további kutatások szükségesek ebben az irányban. A corpus split-eket, tesztkészleteket és modelleket nyilvánosságra hozzuk.', 'kk': 'Үлкен және толық компьютер аудармаларының (MT) жүйелерінің саны артық, бұл әдістерді түрлі тілдерде бағалау үшін жоғары сапатты параллель корпора және бұл тілдерді сөйлейтін адамдармен бірге қатынауға болады. Бұл зерттеулерде MT жүйелерін 22 тілде Түрк тіл отбасынан оқыту және оқыту үшін көпшілігінің көпшілігін зерттеуді көрсетеді. Біріншіден, біз TIL корпусты бақылау және оқу бағдарламаларының бірнеше негізгі жақсартуларын қолданамыз. Содан кейін, біз 26 тілінің негізгі сызықтарын және көптеген невралдық MT (MNMT) моделін корпус қолданып, автоматты метрикалық және адамдардың оқиғаларын қолдану үшін кеңейтілген анализ жасап береміз. Біз MNMT үлгісі доменге шығыс сынақтардың барлық екі тілді негізгі сызықтарын жасап, бір екі тапсырманың төменгі тапсырмасының үлгісін жасап, сондай-ақ төменгі, жоғары ресурстардың сценариясында үлкен әсер етіліктерді к Түрк тілдерінде MT үлгілерінің бағалау критерияларының тәртіпсіздік анализ сондай-ақ осы бағыттағы зерттеулердің қажеттігін көрсетеді. Корпус бөліктерін шығару, сынақтар көпшіліктерге үлгілер жасайды.', 'ms': 'Walaupun jumlah yang meningkat sistem terjemahan mesin yang besar dan meliputi (MT), penilaian kaedah-kaedah ini dalam berbagai bahasa telah ditahan oleh kekurangan corpora paralel kualiti tinggi serta keterlibatan dengan orang-orang yang bercakap bahasa-bahasa ini. Dalam kajian ini, kami memperkenalkan penilaian pendekatan terbaik untuk latihan dan penilaian sistem MT dalam 22 bahasa dari keluarga bahasa Turki, sebahagian besar yang sangat tidak dikesan. Pertama, kita mengadopsi TIL Corpus dengan beberapa peningkatan utama untuk latihan dan set penilaian. Then, we train 26 bilingual baselines as well as a multi-way neural MT (MNMT) model using the corpus and perform an extensive analysis using automatic metrics as well as human evaluations.  We find that the MNMT model outperforms almost all bilingual baselines in the out-of-domain test sets and finetuning the model on a downstream task of a single pair also results in a huge performance boost in both low- and high-resource scenarios.  Analisis perhatian kami terhadap kriteria penilaian untuk model MT dalam bahasa Turki juga menunjukkan keperluan untuk kajian lanjut dalam arah ini. Kami melepaskan corpus splits, set ujian serta model kepada masyarakat.', 'mk': 'Despite the increasing number of large and comprehensive machine translation (MT) systems, evaluation of these methods in various languages has been restrained by the lack of high-quality parallel corpora as well as engagement with the people that speak these languages.  In this study, we present an evaluation of state-of-the-art approaches to training and evaluating MT systems in 22 languages from the Turkic language family, most of which being extremely under-explored.  Прво, го усвоивме ТИЛ Корпусот со неколку клучни подобрувања во обуката и оценката. Потоа, тренираме 26 двојјазични основни линии, како и мултипатичен нервен модел MT (MNMT) користејќи го корпусот и извршувајќи екстремна анализа користејќи автоматска метрика како и човечки проценки. Дознавме дека моделот МНМТ ги надминува речиси сите двојјазични основни линии во тестовите надвор од доменот и финетизирањето на моделот на понатамошната задача на еден пар исто така резултира со огромно зголемување на резултатите во сценаријата со ниски и високи ресурси. Нашата внимателна анализа на критериумите за евалуација на моделите на МТ на турските јазици, исто така, ја истакнува потребата за понатамошно истражување во оваа насока. We release the corpus splits, test sets as well as models to the public.', 'mt': 'Minkejja n-numru dejjem jikber ta’ sistemi kbar u komprensivi ta’ traduzzjoni bil-magni (MT), l-evalwazzjoni ta’ dawn il-metodi f’diversi lingwi ġiet ristretta min-nuqqas ta’ korpora parallela ta’ kwalità għolja kif ukoll l-involviment mal-persuni li jitkellmu dawn il-lingwi. F’dan l-istudju, qed nippreżentaw evalwazzjoni tal-approċċi l-aktar avvanzati għat-taħriġ u l-evalwazzjoni tas-sistemi MT fi 22 lingwa mill-familja tal-lingwa Torka, li l-biċċa l-kbira tagħhom huma estremament sottoesplorati. L-ewwel nett, niddottaw il-Korp TIL bi ftit titjib ewlieni għat-taħriġ u s-settijiet ta’ evalwazzjoni. Imbagħad, a ħna nħarrġu 26 linja bażi bilingwi kif ukoll mudell ta’ MT newrali multidirezzjonali (MNMT) bl-użu tal-korpus u nagħmlu analiżi estensiva bl-użu ta’ metriċi awtomatiċi kif ukoll evalwazzjonijiet umani. Aħna nsibu li l-mudell MNMT jaqbeż kważi l-linji bażi billingwi kollha fis-settijiet tat-testijiet barra d-dominju u l-irfinar tal-mudell fuq kompitu downstream ta’ par wieħed jirriżulta wkoll f’żieda kbira fil-prestazzjoni kemm fix-xenarji b’riżorsi baxxi kif ukoll għoljin. L-analiżi attenta tagħna tal-kriterji ta’ evalwazzjoni għall-mudelli MT fil-lingwi Torok tindika wkoll il-ħtieġa għal aktar riċerka f’din id-direzzjoni. Aħna nirrilaxxaw il-qasma tal-korpus, is-settijiet tat-testijiet kif ukoll il-mudelli lill-pubbliku.', 'ml': 'വലുതും പൂര്\u200dണ്ണമായ മെഷിന്\u200d പരിഭാഷകങ്ങളുടെ എണ്ണം വര്\u200dദ്ധിപ്പിച്ചാലും വ്യത്യസ്ത ഭാഷകളില്\u200d ഈ രീതികളുടെ വിലാസങ്ങള്\u200d നിര്\u200dബന്ധിക്കപ്പെട്ടിരിക്കുന്നു. ഈ ഭാഷകള ഈ പഠനത്തില്\u200d ഞങ്ങള്\u200d രാജ്യത്തിലെ കലാകാര്യങ്ങളുടെ പരിശീലനത്തിനും പരിശീലനത്തിനും 22 ഭാഷകളില്\u200d എംടി സിസ്റ്റം പരിശോധിക്കുന്നതിനും ഒരു വിലാസങ്ങള ആദ്യം, നമ്മള്\u200d ടിഐഎല്\u200d കോര്\u200dപ്പുസിനെ പ്രദര്\u200dശിപ്പിക്കുന്നത് പരിശീലനത്തിനും വിലാസങ്ങളും കുറച്ച് മെച്ചപ് പിന്നെ നമ്മള്\u200d 26 ഭാഷ ബേസ്ലെയിനുകള്\u200d പരിശീലിപ്പിക്കുന്നു. കോര്\u200dപ്പുസ് ഉപയോഗിക്കുന്ന ഒരു പല വഴിയിലെ ന്യൂറല്\u200d MT (MNMT) മോഡലും പരിശീലിക്കുന്നു. ആത നമ്മള്\u200d കണ്ടെത്തുന്നത് എംഎംഎംടി മോഡല്\u200d ഡോമെന്\u200d ടെസ്റ്റ് സെറ്റില്\u200d പുറത്തുള്ള എല്ലാ രണ്ടു ഭാഷകളും പ്രവര്\u200dത്തിപ്പിക്കുന്നുണ്ടെന്നും, ഒരു ജോടിയുടെ താഴ്വരയിലെ മോഡ ടുര്\u200dക്കിക്ക് ഭാഷകളില്\u200d MT മോഡലുകള്\u200dക്കുള്ള വിലാസങ്ങളുടെ പരിശോധനത്തെക്കുറിച്ച് നമ്മുടെ ആശ്വാസവിശ്വാസം ഈ വഴിയ നമ്മള്\u200d കോര്\u200dപ്പുസിന്റെ ഭാഗങ്ങള്\u200d വിടുന്നു, പരീക്ഷണത്തിന്റെ സെറ്റുകളും പൊതുക്കാര്\u200dക്കും മാതൃ', 'no': 'Til tross at det økte antall store og komplette maskinsomsetjingssystemer (MT), er evalueringa av desse metodane i ulike språk avgrensa av mangling av høg kvalitet parallelle korpora og engasjering med folk som snakker desse språka. I denne studien presenterer vi eit evaluering av tilstanden av kunsten nærmer på opplæring og evaluering av MT-systemet i 22 språk frå den turske språksfamilien, dei fleste av dei som er ekstremt undersøkte. Først kan vi adoptere TIL-korpusen med noen nøkkelforbetringar for opplæring og evalueringssettet. Så treng vi 26 bilinguelt baselinjer, og ein fleire måtar neuralt MT (MNMT) modell ved bruk av korpusen og utfør ein ekstra analyse med automatisk metrika og menneske evaluering. Vi finn at MNMT-modellen utfører nesten alle bilinguelte baselinjer i utdomenet- testsettet og finne ut modellen på ein nedstrekkoppgåve av ei enkelt par, resulterer også i ein stor utvikling i både låg og høg- ressursscenario. Vårt attentive analyse av evalueringskriteriar for MT-modeller i tyrkiske språk viser også nødvendighet for further forskning i denne retninga. Vi løyser korpussplitten, testen sett også modeller til offentlege.', 'pl': 'Pomimo rosnącej liczby dużych i kompleksowych systemów tłumaczenia maszynowego (MT), ocena tych metod w różnych językach została ograniczona przez brak wysokiej jakości korpusów równoległych oraz zaangażowanie się w osoby, które mówią tymi językami. W niniejszym opracowaniu przedstawiamy ocenę najnowocześniejszych podejść do szkolenia i oceny systemów MT w 22-językach z rodziny języków tureckich, z których większość jest niezbyt doświadczona. Po pierwsze, przyjmujemy korpus TIL wraz z kilkoma kluczowymi ulepszeniami w zestawach szkoleniowych i oceniających. Następnie trenujemy 26 dwujęzyczne linie bazowe oraz wielokierunkowy model neuronowy MT (MNMT) z wykorzystaniem korpusu i wykonujemy obszerną analizę z wykorzystaniem automatycznych metryk oraz ocen ludzkich. Odkrywamy, że model MNMT przewyższa prawie wszystkie dwujęzyczne linie bazowe w zestawach testowych poza domeną, a precyzyjne dostrojenie modelu na dalszym zadaniu pojedynczej pary skutkuje również ogromnym zwiększeniem wydajności zarówno w scenariuszach niskich, jak i wysokich zasobów. Nasza uważna analiza kryteriów oceny modeli MT w językach tureckich wskazuje również na konieczność dalszych badań w tym kierunku. Udostępniamy podziały korpusu, zestawy testowe oraz modele do publicznej wiadomości.', 'ro': 'În ciuda numărului tot mai mare de sisteme mari și cuprinzătoare de traducere automată (MT), evaluarea acestor metode în diferite limbi a fost limitată de lipsa corpurilor paralele de înaltă calitate, precum și de implicarea cu oamenii care vorbesc aceste limbi. În acest studiu, prezentăm o evaluare a abordărilor de ultimă oră pentru instruirea și evaluarea sistemelor MT în 22 de limbi din familia de limbi turce, majoritatea fiind extrem de subexplorate. În primul rând, adoptăm TIL Corpus cu câteva îmbunătățiri cheie ale seturilor de instruire și evaluare. Apoi, pregătim 26 de linii de bază bilingve, precum și un model MT neural multi-way (MNMT) utilizând corpul și efectuăm o analiză extinsă utilizând măsurători automate, precum și evaluări umane. Descoperim că modelul MNMT depășește aproape toate liniile de referință bilingve în seturile de teste din afara domeniului și că reglarea fină a modelului pe o sarcină din aval a unei singure perechi rezultă, de asemenea, într-o creștere uriașă a performanței atât în scenariile cu resurse mici, cât și în cele cu resurse mari. Analiza noastră atentă a criteriilor de evaluare a modelelor MT în limbile turcă indică, de asemenea, necesitatea unei cercetări suplimentare în această direcție. Eliberăm publicului fragmentele corpurilor, seturile de teste, precum și modelele.', 'lt': 'Nepaisant didėjančio didelių ir visapusiškų vertimo mašinomis sistemų skaičiaus, šių metodų vertinimą įvairiomis kalbomis ribojo aukštos kokybės lygiagrečių korprų trūkumas ir bendravimas su šiomis kalbomis kalbančiais žmonėmis. Šiame tyrime pristatome pažangiausių požiūrių į mokymą ir MT sistemų vertinimą 22 Turkijos kalbų šeimos kalbomis, iš kurių dauguma labai nepakankamai išnagrinėtos. First, we adopt the TIL Corpus with a few key improvements to the training and the evaluation sets.  Tuomet mokome 26 dvikalbes bazines linijas, taip pat daugiakalbį MT (MNMT) model į naudojant korpusą ir atliekame išsamią analizę naudojant automatines metrijas ir žmogaus vertinimus. Matome, kad MNMT modelis viršija beveik visas dvikalbes bazines linijas ne srities bandymų rinkiniuose ir modelio tobulinimas, atliekant vienos poros tolesnę užduotį, taip pat sukelia didelį rezultatų augimą mažų ir didelių išteklių scenarijuose. Mūsų nuodugni MT modelių Turkijos kalbomis vertinimo kriterijų analizė taip pat rodo būtinybę tęsti mokslinius tyrimus šia kryptimi. Mes išleidžiame korpuso padalijimus, bandymų rinkinius ir modelius visuomenei.', 'so': 'Inta kastoo ay kordhisan tirada tarjumaadka machine ee weyn oo hoos u dhigan (MT), waxaa la joojiyey qiimeynta qaababkan oo luqadaha kala duduwan, waayo, baahida shirkadaha isbardhiga sare iyo la xiriira dadka luqadahan ku hadla. In this study, we present an evaluation of state-of-the-art approaches to training and evaluating MT systems in 22 languages from the Turkic language family, most of which being extremely under-explored.  Marka ugu horeysa, waxaynu kordhisnaa korpuska TIL, horumarinta ugu horumarinta waxbarashada iyo xarumaha qiimeynta. Markaas waxaynu ku tababarinnaa 26 saldhigyo labaad oo af ah iyo sidoo kale qaab baaritaanka MT (MNMT) oo aad ku isticmaaleyso baaritaan aad u dheer isticmaalka maamulka iyo qiimeynta dadka. Tusaalada MNMT waxay ka muuqataa dhamaantood labada luqadood oo ku qoran jardiinada laga baxo-domain-ka-baaraandegista, waxaana sameynaynaa modelka ku qoran jardiinada hoose-hoose ee hal nooc ah, waxaana sidoo kale ku sababtaa booska firaaqada aad u weyn ee labada hoos-iyo-high resource scenariyadooda. Analyskayaga qiimeynta qiimeynta ah ee modelalka MT oo ku qoran luqadaha Turki waxaa sidoo kale ku qoran in lagu baahan yahay waxbarashada sii wadan. Waxaynu furanaynaa boosaska, imtixaanka iyo tusaalooyinka dadweynaha.', 'sr': 'Uprkos povećanjem broja velikih i sveobuhvatnih sistema prevoda mašina (MT), procjena tih metoda na različitim jezicima je ograničena nedostatkom visokokvalitetnog paralelnog korpora, kao i uključenjem sa ljudima koji govore ovim jezicima. U ovoj studiji predstavljamo procjenu pristupa države umjetnosti obuke i procjene MT-ova sistema na 22 jezika iz porodice turske jezike, većina njih je izuzetno pod istragom. Prvo, usvojimo TIL korpus sa nekoliko ključnih poboljšanja treninga i procjene. Onda treniramo 26 dvojezičkih osnovnih linija, kao i multi-putni neuralni MT (MNMT) model koristeći korpus i izvršavamo ogromnu analizu koristeći automatsku metriku i ljudske procjene. Nalazimo da model MNMT-a iznosi skoro sve dvojezičke osnovne linije u testovima izvan domena i finalizuje model na sledećem zadatku jednog par takođe rezultira u ogromnom poboljšanju učinka i u scenarijima niskih i visokih resursa. Naša pažnja analiza kriterija procjene MT modela na turskim jezicima takođe ukazuje na potrebu za daljnjim istraživanjima u ovom pravcu. Oslobodimo korpus delove, testove kao i modele javnosti.', 'si': 'විශාල සහ සම්පූර්ණ පද්ධතිය (MT) පද්ධතියේ විශාල සංඛ්යාවක් විතරයි, විවිධ භාෂාවට මේ පද්ධතිය ගැන විශාලනය කරලා තියෙන්නේ විවිධ මේ පරීක්ෂණයේදී, අපි තුර්කික් භාෂාව පවුලේ ඉඳන් MT පද්ධතියේ පරීක්ෂණය සහ අවශ්\u200dයානය කරන්න පුළුවන් විශ්වාසයක් පෙන්වන්නේ, ඒ මුලින්ම, අපි TIL කෝර්පුස් එක්ක ප්\u200dරධානය සහ විශ්ලේෂණය සඳහා ප්\u200dරධානය සඳහා ප්\u200dරධානයක් ටිකක් වැඩ ඊට පස්සේ, අපි දෙවෙනි භාෂාවක් අධ්\u200dයාත්මක විදිහට ප්\u200dරශ්නයක් 26 වලින් විදිහට ප්\u200dරශ්නයක් කරනවා කොර්පුස් භාවිත කරන්න සහ මනුෂ්\u200dය ව අපිට හොයාගන්න පුළුවන් විදියට MNMT මොඩල් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් හැම දෙවල් භාෂාවක් ප්\u200dරශ්නයක්ම ප්\u200dරශ්නයක්ම සඳහා ප්\u200dරශ්නයක අපේ අවධානය විශ්ලේෂණ විශ්ලේෂණය MT මෝඩේල් වලට තුර්කික භාෂාවල් වලට තියෙන්නේ මේ පැත්තේ තව පරීක්ෂ අපි කෝර්පුස් ස්පිල්ට් එකක් නිදහස් කරනවා, පරීක්ෂණය සහ ප්\u200dරජාතියෙන් මෝඩේල් එක්ක.', 'sv': 'Trots det 철kande antalet stora och omfattande maskin철vers채ttningssystem (MT) har utv채rderingen av dessa metoder p책 olika spr책k begr채nsats av bristen p책 h철gkvalitativa parallella korpora och engagemang med de m채nniskor som talar dessa spr책k. I denna studie presenterar vi en utv채rdering av toppmoderna metoder f철r utbildning och utv채rdering av MT-system p책 22 spr책k fr책n den turkiska spr책kfamiljen, varav de flesta 채r extremt underutforskade. F철rst antar vi TIL Corpus med n책gra viktiga f철rb채ttringar av utbildningen och utv채rderingen. Sedan tr채nar vi 26 tv책spr책kiga baslinjer samt en multiv채gs neural MT (MNMT) modell med hj채lp av korpusen och utf철r en omfattande analys med hj채lp av automatiska m채tv채rden samt m채nskliga utv채rderingar. Vi finner att MNMT-modellen 철vertr채ffar n채stan alla tv책spr책kiga baslinjer i testupps채ttningar utanf철r dom채nen och finjustering av modellen p책 en nedstr철msuppgift av ett enda par resulterar ocks책 i en enorm prestandaf철rb채ttring i b책de l책gresursscenarier och h철gresursscenarier. V책r noggranna analys av utv채rderingskriterier f철r MT-modeller p책 turkiska spr책k pekar ocks책 p책 behovet av ytterligare forskning i denna riktning. Vi sl채pper ut korpusdelningar, testupps채ttningar och modeller till allm채nheten.', 'ur': 'بڑے اور گھیرے ماشین ترجمہ (MT) سیستموں کی تعداد کے بغیر، ان طریقوں کا ارزش مختلف زبانوں میں محفوظ ہوا ہے کہ بالکل کیفیت parallel corpora کی کمزوری اور ان لوگوں کے ساتھ جو یہ زبانیں بولتے ہیں، ان کی کمزوری سے روک دی گئی ہے۔ اس مطالعہ میں ہم نے ترکیک زبان خاندان کے 22 زبانوں میں MT سیستم کی تعلیم اور مطالعہ کے قریب کی ایک ارزش مقرر کر دی ہے، ان میں سے اکثر بہت زیادہ تحقیق کی جاتی ہیں. پہلی بار ہم TIL کورپوس کو تعلیم اور ارزیابی سٹ کے چند کلیدوں کے ساتھ پکڑتے ہیں. پھر ہم 26 دو زبان بنسٹ لینڈ اور ایک multi-way neural MT (MNMT) موڈل کو کورپوس کے استعمال کرتے ہیں اور اپنی متریک اور انسان کی ارزیابی کے استعمال سے ایک بڑی تحلیل کریں۔ ہم دیکھتے ہیں کہ MNMT موڈل تقریباً ہر دو زبان بنیس لین کو ڈومین کے خارج آزمائش سٹوں میں عمل کرتا ہے اور ایک جوڑے کے نیچے نرم ترین کام پر موڈل کو مکمل کرتا ہے اور نیچے اور بالا رسسوس سناریوں میں بہت اضافہ کرتا ہے۔ ہماری تورک زبانوں میں MT موڈل کے ارزیابی کریٹروں کی تحقیقات کی تحقیقات کی تحقیقات کی تحقیقات بھی اس طرح کی ضرورت ہے۔ ہم کورپوس ٹکڑے چھوڑ دیتے ہیں، آزمائش بھی جمعیت کے لئے نمونے بھی ہیں۔', 'mn': 'Машин хөгжлийн олон том болон бүрэн томоохон (MT) системүүдийн тоо нэмэгдсэн ч, эдгээр аргыг олон хэл дээр үнэлэх нь өндөр чанартай параллель корпора байхгүй байдал болон эдгээр хэл ярьдаг хүмүүстэй холбоотой. Энэ судалгаанд бид Турк хэлний гэр бүлийн 22 хэл дээр MT системийг суралцах, үнэлэх тухай үнэлгээ дэвшүүлсэн. Ихэнх нь маш их судалгаагүй. Эхлээд бид TIL корпус-ыг суралцах болон үнэлгээний багш нарийн хэдэн чухал сайжруулалтаар хүргэж байна. Дараа нь бид 26 хоёр хэлний суурь шугам, олон төрлийн мэдрэлийн MT (MNMT) загварыг корпус ашиглаж автоматик метрик болон хүн төрөлхтний шалгалтыг ашиглаж маш их шинжилгээ хийдэг. МNMT загвар нь бараг хоёр хэл суурь шулуунуудыг хоорондоо шалгаж, нэг хоёр давхар давхар ажлын загварын загварын тулд бага болон өндөр нөөцийн хувилбаруудын тулд маш их үйл ажиллагааг нэмэгдүүлдэг. Турк хэлний MT загварын үнэлгээний шалгалтын ухаантай шинжилгээ мөн энэ талаар илүү олон судалгааны шаардлагатай талаар илэрхийлж байна. Бид корпус хуваагдаж, шалгалт олон нийтэд загварууд ч мөн адил загварууд гаргадаг.', 'ta': 'Despite the increasing number of large and comprehensive machine translation (MT) systems, evaluation of these methods in various languages has been restrained by the lack of high-quality parallel corpora as well as engagement with the people that speak these languages.  இந்த ஆராய்ச்சியில், துருக்கி மொழி குடும்பத்தில் இருந்து பயிற்சி மற்றும் எம்டி முறைமைகளை பரிசோதிக்க முடியும் நாம் மாநிலையில் ஒர முதலில், நாம் பயிற்சி மற்றும் மதிப்பு அமைப்பு பின்னர், நாம் 26 மொழி அடிக்கோடுகளுக்கும் ஒரு பல வழி பாதுகாப்பு MT (MNMT) மாதிரி பயிற்சி கொடுக்கிறோம் மற்றும் கார்புஸ் பயன்படுத்தி தானியங்கி மெட் MNMT மாதிரி குறைந்த இரண்டு மொழிக்கோடுகளை வெளியேற்றும் தளத்தில் செயல்படுத்துகிறது என்பதை நாம் கண்டுபிடிக்கிறோம். ஒரு ஜோடியின் கீழே தளத்தில் மாதிரியும் மாதிரி துருக்கி மொழிகளில் MT மாதிரிகளுக்கான மதிப்பீட்டு முறைமையின் ஆராய்ச்சி முறைமையை இந்த த திசையில் மேலும் ஆரா நாம் கோர்பாஸ் பிரிவுகளை வெளியேற்றுகிறோம், சோதனைகள் மற்றும் பொது மாதிரிகள் அமைக்கிறது.', 'uz': "Bu tillar bilan gapiradigan katta va katta kompyuterni tarjima qilish (MT) tizimlarini ko'paytirishda, bu usullarning qiymati har xil tillarda o'qiymatishni o'zgartiradi va bu tilni gapiradigan odamlarning yuqori balandlik kompaniya haqida o'zgarishga qaramadi. Bu taʼminotda, biz turki tilning oilidan 22 tillardan MT tizimlarini o'rganish va qiymatlashga davlat holatning holatini qiymatlashimiz mumkin. Buning ko'pchilik juda qidiriladi. Birinchisi, biz TIL Korpusni ta'lim va qiymatlar tarkibini bir necha muhim yaxshi o'zlashtiramiz. Keyin biz 26 tillar asosiy sonlarini o'rganamiz, ko'plab yo'l neyrolik modeli (MNMT) bilan bir necha yo'l neyron modelini o'rganamiz va avtomatik metrik va inson qiymatlari bilan kengaytirish natijasini bajaramiz. We find that the MNMT model outperforms almost all bilingual baselines in the out-of-domain test sets and finetuning the model on a downstream task of a single pair also results in a huge performance boost in both low- and high-resource scenarios.  Turkcha tillardagi MT modellarining qiymatlarimizni aniqlash kerakligimizni o'ylab, bu usulda koʻproq o'rganish kerakligini anglatadi. Biz pulni chiqaramiz, sinov va shaxsiy modellarni ko'rsatumiz.", 'vi': 'Mặc dù số hệ thống dịch cỗ máy lớn và toàn diện đang tăng lên, nhưng đánh giá các phương pháp này bằng nhiều ngôn ngữ khác nhau đã bị hạn chế bởi thiếu tính chất lượng cao và tham gia cùng với những người nói những ngôn ngữ này. Trong nghiên cứu này, chúng tôi giới thiệu một bài đánh giá về phương pháp huấn luyện và đánh giá hệ thống MTV ở 22 ngôn ngữ thực Turkish, đa số các phương pháp được khám phá chưa được khám phá kỹ. Trước tiên, chúng ta nhận nuôi TIL Corpus, với một vài cải tiến quan trọng trong các trường huấn luyện và đánh giá. Sau đó, chúng tôi huấn luyện 26 đường hầm hai thứ, cũng như mô hình con đường mạng thần kinh MTV, dùng tập thể hình và thực hiện một phân tích tích tích tích rộng bằng đo lường tự động cũng như đánh giá con người. Chúng tôi tìm thấy rằng mô hình M4T vượt trội hầu hết các thiết bị bắt giữ góc hai vùng trong bộ thử nghiệm ngoài miền và sửa chữa mẫu cho một nhiệm vụ xuôi dòng của một cặp cũng đưa ra hiệu quả cao hơn nhiều trong các viễn cảnh thấp và nguồn cao. Sự phân tích cẩn thận của chúng tôi về các tiêu chuẩn MTV ở Turkish languages cũng chỉ ra nhu cầu nghiên cứu thêm theo hướng này. Chúng tôi công bố những mảnh xương máu, những mẫu thử cũng như những mẫu cho công chúng.', 'bg': 'Въпреки нарастващия брой на големите и всеобхватни системи за машинен превод (МТ), оценката на тези методи на различни езици е възпрепятствана от липсата на висококачествени паралелни корпуси, както и от ангажираността с хората, които говорят тези езици. В това проучване представяме оценка на най-съвременните подходи за обучение и оценка на МТ системи на 22 езика от тюркското езиково семейство, повечето от които са изключително недостатъчно изследвани. Първо, ние приемаме ТИЛ Корпус с няколко ключови подобрения в набора от обучения и оценки. След това обучаваме 26 двуезични базови линии, както и многопосочен неврален модел с помощта на корпуса и извършваме обширен анализ с помощта на автоматични метрики, както и човешки оценки. Откриваме, че моделът превъзхожда почти всички двуезични базови линии в тестовите набори извън домейна и финото настройване на модела при задача надолу по веригата на една двойка също води до огромен повишаване на производителността както при сценарии с ниски, така и с високи ресурси. Нашият внимателен анализ на критериите за оценка на моделите на МТ на турски езици също показва необходимостта от допълнителни изследвания в тази посока. Ние пускаме корпусни разделения, тестови комплекти, както и модели на обществеността.', 'nl': "Ondanks het toenemende aantal grote en uitgebreide machine translation (MT) systemen, is de evaluatie van deze methoden in verschillende talen beperkt door het ontbreken van hoogwaardige parallelle corpora's en de betrokkenheid bij de mensen die deze talen spreken. In deze studie presenteren we een evaluatie van state-of-the-art benaderingen voor het trainen en evalueren van MT-systemen in 22-talen uit de Turkse taalfamilie, waarvan de meeste extreem onderverkend zijn. Ten eerste nemen we het TIL Corpus over met enkele belangrijke verbeteringen aan de training en de evaluatiesets. Vervolgens trainen we 26 tweetalige basislijnen en een multi-way neural MT (MNMT) model met behulp van het corpus en voeren we een uitgebreide analyse uit met behulp van automatische metrics en menselijke evaluaties. We merken dat het MNMT-model bijna alle tweetalige basislijnen in de out-of-domain testsets overtreft en het finetunen van het model op een downstream taak van één paar resulteert ook in een enorme prestatieboost in zowel low- als high-resource scenario's. Onze aandachtige analyse van evaluatiecriteria voor MT-modellen in Turkse talen wijst ook op de noodzaak van verder onderzoek in deze richting. We geven de corpussplits, testsets en modellen vrij aan het publiek.", 'hr': 'Uprkos povećanjem broja velikih i sveobuhvatnih sustava prevoda stroja (MT), procjena tih metoda na različitim jezicima ograničena je nedostatkom visokokvalitetnog paralelnog tijela, kao i uključenjem s ljudima koji govore te jezike. U ovom ispitivanju predstavljamo procjenu pristupa države umjetnosti obuke i procjene MT sustava na 22 jezika iz obitelji turskih jezika, većina njih je izuzetno nedovoljno istražena. Prvo, usvojimo TIL korpus s nekoliko ključnih poboljšanja obuke i razmatranja. Onda treniramo 26 dvojezičkih osnovnih linija, kao i multi-putni neuralni MT (MNMT) model koristeći korpus i izvršiti široku analizu koristeći automatsku metriku i ljudske procjene. Nalazimo da model MNMT-a iznosi skoro sve dvojezičke osnovne linije u testovima izvan domena i finalno uključivanje modela na donjem zadatku jednog par također rezultira ogromnom poboljšanju učinka u scenarijima niskih i visokih resursa. Naša pažnja analiza kriterija procjene MT modela na turskim jezicima također ukazuje na potrebu za daljnjim istraživanjima u ovom smjeru. Oslobodimo korpus podjele, testove kao i modele javnosti.', 'da': 'På trods af det stigende antal store og omfattende maskinoversættelsessystemer (MT) er evalueringen af disse metoder på forskellige sprog blevet begrænset af manglen på parallelle corpora af høj kvalitet samt engagement med de mennesker, der taler disse sprog. I denne undersøgelse præsenterer vi en evaluering af state-of-the-art tilgange til uddannelse og evaluering af MT-systemer på 22 sprog fra den tyrkiske sprogfamilie, hvoraf de fleste er yderst underudforskede. For det første vedtager vi TIL Corpus med et par vigtige forbedringer af uddannelses- og evalueringssættet. Derefter træner vi 26 tosprogede baselines samt en multivejs neural MT (MNMT) model ved hjælp af korpus og udfører en omfattende analyse ved hjælp af automatiske målinger såvel som menneskelige evalueringer. Vi finder ud af, at MNMT-modellen overgår næsten alle tosprogede baselines i de out-of-domæne testsæt, og finjustering af modellen på en downstream opgave af et enkelt par resulterer også i en enorm ydeevne boost i både lav- og høj ressource scenarier. Vores opmærksomme analyse af evalueringskriterier for MT-modeller på tyrkiske sprog peger også på nødvendigheden af yderligere forskning i denne retning. Vi frigiver corpus splits, testsæt samt modeller til offentligheden.', 'de': 'Trotz der zunehmenden Zahl großer und umfassender maschineller Übersetzungssysteme (MT) wurde die Evaluation dieser Methoden in verschiedenen Sprachen durch das Fehlen hochwertiger paralleler Korpora sowie die Interaktion mit den Menschen, die diese Sprachen sprechen, eingeschränkt. In dieser Studie präsentieren wir eine Evaluation von State-of-the-Art Ansätzen zur Ausbildung und Bewertung von MT-Systemen in 22-Sprachen aus der türkischen Sprachfamilie, von denen die meisten extrem wenig erforscht sind. Zunächst übernehmen wir das TIL Corpus mit einigen wesentlichen Verbesserungen der Trainings- und Evaluationssets. Anschließend trainieren wir 26 bilinguale Basislinien sowie ein multi-way neuronales MT (MNMT) Modell mit dem Korpus und führen eine umfangreiche Analyse mit automatischen Metriken sowie menschlichen Auswertungen durch. Wir stellen fest, dass das MNMT-Modell fast alle zweisprachigen Baselines in den Out-of-Domain-Testsets übertrifft und dass die Feinabstimmung des Modells auf eine nachgelagerte Aufgabe eines einzelnen Paars auch zu einem enormen Leistungssteigerung in Szenarien mit niedrigen und hohen Ressourcen führt. Unsere sorgfältige Analyse der Bewertungskriterien für MT-Modelle in türkischen Sprachen weist auch auf die Notwendigkeit weiterer Forschung in dieser Richtung hin. Wir veröffentlichen die Corpus Splits, Testsets sowie Modelle der Öffentlichkeit.', 'id': 'Meskipun jumlah yang meningkat dari sistem terjemahan mesin yang besar dan komprensif (MT), evaluasi metode-metode ini dalam berbagai bahasa telah ditahan oleh kekurangan kopora paralel kualitas tinggi serta keterlibatan dengan orang-orang yang berbicara bahasa-bahasa ini. Dalam studi ini, kami mempersembahkan sebuah evaluasi pendekatan terbaik untuk latihan dan evaluasi sistem MT dalam 22 bahasa dari keluarga bahasa Turki, sebagian besar yang sangat tidak dikenal. Pertama, kita mengadopsi TIL Corpus dengan beberapa peningkatan kunci dalam latihan dan evaluasi set. Kemudian, kami melatih 26 garis dasar dua bahasa serta model MT neural multi-jalan (MNMT) menggunakan tubuh dan melakukan analisis ekstensif menggunakan metrik otomatis serta evaluasi manusia. Kami menemukan bahwa model MNMT melebihi hampir semua garis dasar bilingual dalam set tes luar domain dan memperbaiki model pada tugas turun dari pasangan tunggal juga berasal dari peningkatan prestasi besar dalam skenario sumber daya rendah dan tinggi. Analisi perhatian kami dari kriteria evaluasi untuk model MT dalam bahasa Turki juga menunjukkan kebutuhan untuk penelitian lanjut dalam arah ini. Kami melepaskan corpus splits, tes set dan model untuk masyarakat.', 'sw': 'Pamoja na kuongezeka kwa mfumo wa kutafsiri mashine makubwa na yenye ujumla (MT), utafiti wa njia hizi kwa lugha mbalimbali umezuiwa na ukosefu wa makampuni yanayofanana na kiwango kikubwa pamoja na ushirikiano na watu wanaozungumza lugha hizi. Katika utafiti huu, tunaweka tathmini za mbinu za hali ya sanaa za kufundisha na kutathmini mfumo wa MT kwa lugha 22 kutoka familia ya lugha ya Uturuki, ambazo wengi wao wanaendelea kuchunguzwa sana. Kwanza, tunachukua makampuni ya TIL yenye maendeleo machache ya muhimu kwa mafunzo na seti za uchunguzi. Kisha, tunajifunza mistari 26 ya lugha mbili pamoja na modeli ya MT (MNMT) kwa njia mbalimbali kwa kutumia makampuni na kufanya uchambuzi wa kina kwa kutumia mbinu za kujitegemea pamoja na tathmini za binadamu. Tumegundua kuwa mtindo wa MNMT unaonyesha karibu misingi yote ya lugha mbili katika vituo vya nje ya majaribio ya ndani na kutengeneza mtindo kwenye kazi ya mto moja na pia inasababisha ongezeko kubwa la utendaji katika mitazamo ya chini na rasilimali kubwa. Uchambuzi wetu wa muhimu wa vigezo vya uchunguzi wa MT kwa lugha za Uturuki pia unaonyesha umuhimu wa kutafiti zaidi katika mwelekeo huu. Tunaachia mapambano, majaribio yanaweka pamoja na mifano kwa umma.', 'ko': '비록 대형 종합기계번역(MT)시스템의 수량이 끊임없이 증가하고 있지만 고품질의 평행어료 라이브러리와 이런 언어를 말하는 사람과의 접촉이 부족하기 때문에 각종 언어에서 이러한 방법에 대한 평가는 줄곧 제한을 받아 왔다.이 연구에서 우리는 돌궐어계 22가지 언어 기계 번역 시스템을 훈련하고 평가하는 최신 방법을 평가했는데 그 중 대다수 방법의 탐색 정도가 매우 낮았다.우선, 우리는 TIL 자료 라이브러리를 사용하고 훈련집과 평가집을 관건적인 개선을 했다.그리고 우리는 어료 라이브러리를 이용하여 26개의 이중 언어 기선과 하나의 다방향 신경기계 번역(MNMT) 모델을 훈련시키고 자동 도량과 인류 평가를 이용하여 광범위한 분석을 실시했다.우리는 MNMT 모델이 역외 테스트에서 집중된 성능이 모든 이중 언어 기선보다 거의 우수하다는 것을 발견했다. 또한 단일 쌍의 하류 임무에서 모델을 미세하게 조정하면 저자원과 고자원 장면에서 커다란 성능 향상을 가져올 수 있다.우리는 돌궐어 기계 번역 모델 평가 기준에 대한 상세한 분석도 이 방면에 대한 진일보한 연구의 필요성을 지적했다.우리는 언어 자료 라이브러리의 분할, 테스트 집합, 그리고 모델을 대중에게 발표한다.', 'fa': 'با وجود افزایش تعداد ترجمه\u200cهای ماشین بزرگ و کلی (MT) این روش\u200cها در زبان\u200cهای مختلف، توسط ناتوانی شرکت\u200cهای پارالی با کیفیت بالا و همچنین مشارکت با افرادی که این زبانها را می\u200cگویند، محدود شده است. در این مطالعه، ما یک ارزیابی از نزدیک ایالت هنر به آموزش و ارزیابی سیستم MT در ۲۲ زبان از خانواده زبان ترکیه را پیشنهاد می\u200cکنیم، بیشتر از آن خیلی زیر تحقیق شده است. اول، ما Corpus TIL را با چند تا بهتر شدن کلیدی برای آموزش و ارزیابی تأثیر می دهیم. سپس ما ۲۶ خطوط بنیادی دو زبان و یک مدل عصبی چندین طریقه با استفاده از کورپوس آموزش می دهیم و با استفاده از متریک اتوماتیک و ارزیابی انسان یک تحلیل وسیع انجام می دهیم. ما فهمیدیم که مدل MNMT تقریباً تمام خطوط بنیادی دو زبان در مجموعه\u200cهای آزمایش خارج از دامنه\u200cها انجام می\u200cدهد و مدل را در یک کار پایین\u200cترین جفت یک جفت هم به نتیجه افزایش عملکرد بزرگی در سیناریو\u200cهای پایین و بالا منبع می\u200cدهد. تحلیل مواظب ارزیابی ما برای مدل MT در زبان ترکیه نیازی برای تحقیقات بیشتری در این جهان نشان می دهد. ما قطعه\u200cهای کورپوس را آزاد می\u200cکنیم، آزمایش\u200cها و مدل\u200cها را برای مردم آزاد می\u200cکنیم.', 'tr': 'Ullakan we daşary makine terjimeleriniň (MT) sistemalary beýleki dillerde bu yönleriň ýokary kaliteli parallel korpora ýok bolmagynyň we bu dillerde gürleýän adamlaryň işi boýunça çykyp gitdi. Bu okuwçyda, MT sistemalaryny Türk dilleriniň maşgalasyndan 22 dilde öwrenmek we çykarmak üçin halkara golaýlaryny çykýarys. Ilkinji gezek, okuwçylyk we çykyş düzenleri üçin Küçük Körpüsini kabul edip görýäris. Sonra, biz 26 ikinji dilli temel hatlary we köp-ýoly neural MT (MNMT) modelini korpusy ulanýarys we awtomatik metrikleri we insan değerlendirmelerini ulanýarys. MNMT nusgasy domenyň daşarydaky testiň düzümlerinde diýen iki dil baseliniň üstüne çykar we ýeke bir çift işinde nusgasyny düşürmegi üçin ýük-ýok we ýokaryk senaryýasynda örän täsirli etkinleşendir. Türkçe dillerde MT modelleri üçin deňlenme kriteriýalarynyň dykgatly analyzasymyz şol yönde ýeterlik barlamak üçin gereklidigini hem görkezýär. Biz korpusyň bölegini seredip, testi hem halkara nusgalary hem çykarýarys.', 'sq': 'Megjithë numrin në rritje të sistemeve të mëdha dhe komprensive të përkthimit të makinave (MT), vlerësimi i këtyre metodave në gjuhë të ndryshme është kufizuar nga mungesa e korprave paralele të cilësisë së lartë si dhe angazhimi me njerëzit që flasin këto gjuhë. Në këtë studim, ne paraqesim një vlerësim të metodave më të larta për trajnimin dhe vlerësimin e sistemeve MT në 22 gjuhë nga familja e gjuhës turke, shumica e të cilave janë jashtëzakonisht nëneksploruar. First, we adopt the TIL Corpus with a few key improvements to the training and the evaluation sets.  Pastaj, ne trajnojmë 26 linja bazë dy gjuhësh si dhe një model neuronal MT (MNMT) me shumë rrugë duke përdorur korpusin dhe duke kryer një analizë të gjerë duke përdorur metrika automatike si dhe vlerësime njerëzore. Ne zbulojmë se modeli MNMT ekziston pothuajse të gjitha linjat bazë dygjuhëse në grupet e testeve jashtë domenisë dhe përmirësimi i modelit në një detyrë poshtë rrjedhës të një çifti të vetëm rezulton gjithashtu në një rritje të madhe performance në skenarët me burime të ulëta dhe të larta. Analiza jonë e vëmendshme e kritereve të vlerësimit për modelet MT në gjuhët turke tregon gjithashtu nevojën për kërkime të mëtejshme në këtë drejtim. Ne lëshojmë pjesët e trupit, grupet e testit si dhe modelet për publikun.', 'hy': 'Չնայած մեծ և ամբողջական մեքենային թարգմանման (MT) համակարգերի աճին, այս մեթոդների գնահատումը տարբեր լեզուներում սահմանափակվել է բարձր որակի զուգահեռ կառուցվածքի պակասի պատճառով, ինչպես նաև մարդկանց հետ, ովքեր խոսում են այս լեզուները: Այս ուսումնասիրության ընթացքում մենք ներկայացնում ենք Թուրքիայի լեզվի ընտանիքի 22 լեզուներով ուսումնասիրելու և գնահատելու ամենահետաքրքիր մոտեցումների գնահատումը, որոնցից շատերը չափազանց թերաուսումնասիրված են: First, we adopt the TIL Corpus with a few key improvements to the training and the evaluation sets.  Հետո մենք վարժեցնում ենք 26 երկլեզու հիմնական գծեր, ինչպես նաև բազմաուղիղ նյարդային ՄԹ (MNMT) մոդել, օգտագործելով կորպուսը և կատարելով էքսպենսիվ վերլուծություն՝ օգտագործելով ավտոմատիկ մետրիկա, ինչպես նաև մարդկային գնահատումներ Մենք հայտնաբերեցինք, որ MNMT-ի մոդելը գերազանցում է գրեթե բոլոր երկլեզու հիմնական գծերը արտաքին թեստերի համակարգերում և փոքրացնելով մոդելը մեկ զույգի ներքևի աշխատանքի վրա, նույնպես հանգեցնում է նշանակալի բարձր արդյունավետության աճի երկու սցենարներում: Մեր ուշադիր վերլուծությունը Թուրքիայի լեզուներում MT-մոդելների գնահատման քննարկումների մասին նաև ցույց է տալիս այս ուղղությամբ հետազոտությունների կարիքը: Մենք արձակում ենք մարմնի բաժանմունքները, փորձարկումները, ինչպես նաև մոդելները հանրության համար:', 'am': 'Despite the increasing number of large and comprehensive machine translation (MT) systems, evaluation of these methods in various languages has been restrained by the lack of high-quality parallel corpora as well as engagement with the people that speak these languages.  በዚህ ትምህርት ውስጥ በቱርክ ቋንቋ ቤተሰብ ላይ 22 ቋንቋዎች የኢሜቲ ስርዓቶችን ለማስተማርና ለማስተምር የሀገር ልግስና ግንኙነት እናደርጋለን፡፡ በመጀመሪያ የቲል ቆርፓስ ለትምህርት እና ማስታወቂያውን ለማድረግ ጥቂት የቁልፎች ማድረግ እናደርጋለን፡፡ ከዚህም በኋላ 26 የቋንቋዎች መሠረቶች እና የኮርፓስ (MNMT) ሞዴል እናስተምረዋለን እና በራካሚ ሜትሪክ እና የሰው ማስታወቂያ እናደርጋለን፡፡ የMNMT ሞዴል ከውጭ-ውጭ የድምፅ ፈተና መስመር ውስጥ የሁለት ቋንቋዎች መሠረት የሚደረገውን እና ሞዴላውን በጥልቅ ሁለት ዓይነቶች ላይ እና በዋይ እና ከፍተኛ የክፍለ ክፍለ ክፍል ላይ ትልቅ የድምፅ አካባቢ እና ትልቅ ድምፅ ያሳድጋል፡፡ በቱርክ ቋንቋዎች የMT ሞዴላዎችን የሚያስተምር ግንኙነታችን ደግሞ በዚህ መንገድ ለመግለጽ ግንኙነት ያስፈልጋል፡፡ የቆሮፕስ ስፋትን እናፈትናለን፣ ፈተና እና የህዝብ ምሳሌዎችን እናደርጋለን፡፡', 'bn': 'বিশাল এবং সম্পূর্ণ মেশিন অনুবাদ (এমটি) সিস্টেম বাড়তে থাকা সত্ত্বেও, বিভিন্ন ভাষায় এই পদ্ধতির মূল্যের বিষয়টি নিষিদ্ধ করা হয়েছে যারা এই ভাষায় কথা বলে তাদের এই গবেষণায় আমরা তুর্কি ভাষার পরিবারের ২২ ভাষায় প্রশিক্ষণ ও মূল্যায়নের জন্য রাষ্ট্র-শিল্পের প্রতিক্রিয়া সম্পর্কে মূল্যবোধ উপস্থাপন করেছি, য প্রথমত, আমরা টিআইল কোর্পাসের প্রশিক্ষণ এবং মূল্যায়ন সেটের কিছু কিছু উন্নতির সাথে গ্রহণ করি। তারপর আমরা ২৬টি দুই ভাষার বেসেলাইন প্রশিক্ষণ প্রশিক্ষণ করি এবং কোর্পাস ব্যবহার করে বহুভাষী নিউরেল এমটি (এমএমটি) মডেল প্রশিক্ষণ করি এবং স্বয়ংক্রিয় মেট্রিক আমরা খুঁজে পাচ্ছি যে এমএনএমটি মডেল প্রায় দুই ভাষার বেসাইনের বাইরে প্রায় দুই ভাষায় প্রকাশ করে এবং একটি জোড়ার কাজে মডেল উৎপাদন করে একটি নীচের দুই জোড়ার মাধ্যমেও একটি বিশাল প্রদর তুর্কিক ভাষায় এমটি মডেলের মূল্যের মূল্যের বিশ্লেষণ আমাদের গুরুত্বপূর্ণ বিশ্লেষণ এই দিকে আরো গবেষণার প্রয়োজন। আমরা কোর্পাসের বিভাগ ছেড়ে দেই, পরীক্ষার সাথে জনগণের কাছে মডেল দেই।', 'az': 'Büyük və bütün maşın çevirilməsi sistemlərin sayısını artırmağa rağmen, bu metodların müxtəlif dillərdə değerlendirməsi yüksək kaliteli parallel korpora yoxdur və bu dilləri danışan insanlarla birlikdə istifadə edilmişdir. Bu təcrübədə, Türk dil ailəsindən 22 dildə MT sistemlərini təhsil etmək və təcrübə etmək üçün müəyyən edilənlərin təcrübəsini göstərdik, çoxunun çoxunu çox aşağı təcrübə edilmişdir. İlk dəfə, TİL Korpusu təhsil və değerlendirmə qurmaqlarının bir neçə a çar düzəltməsi ilə istifadə edirik. Sonra, biz 26 dildə iki sətir və çoxlu yol nöral MT (MNMT) modeli korpusu istifadə edir və avtomatik metrik və insan değerlendirmələrini istifadə edir. MNMT modeli döyüşə çıxıb-domena sınamasında az qala iki dilli tərəflər çəkir və bir çiftin düşürülmüş işlərin modelini daha yaxşı tərəflər çəkir. Türk dillərində MT modellərinin qiyməti kritēriju analizimiz də bu tərəfdə daha çox araştırmaların ehtiyacını göstərir. Biz korpus parçalarını yayındırırıq, sınamaq halkı üçün modellər də hazırlayır.', 'ca': "Malgrat el creixent nombre de sistemes de traducció màquina (MT), l'evaluació d'aquests mètodes en diverses llengües ha estat restringida per la falta de corpora paralèl·lela d'alta qualitat i per la participació amb la gent que parla aquestes llengües. En aquest estudi, presentem una evaluació dels enfocaments més moderns de formació i evaluació dels sistemes MT en 22 llengües de la família turca, la majoria dels quals són extremadament poc explorats. Primer, adoptem el Corpus TIL amb algunes millores clau en els conjunts d'entrenament i evaluació. Then, we train 26 bilingual baselines as well as a multi-way neural MT (MNMT) model using the corpus and perform an extensive analysis using automatic metrics as well as human evaluations.  We find that the MNMT model outperforms almost all bilingual baselines in the out-of-domain test sets and finetuning the model on a downstream task of a single pair also results in a huge performance boost in both low- and high-resource scenarios.  La nostra atenta anàlisi dels criteris d'evaluació dels models de MT en les llengües turques també apunta a la necessitat de seguir investigant en aquesta direcció. Vam alliberar els fragments del cos, els conjunts de prova i els models al públic.", 'bs': 'Uprkos povećanjem broja velikih i sveobuhvatnih sustava prevoda stroja (MT), procjena tih metoda na različitim jezicima je ograničena nedostatkom visokokvalitetnog paralelnog korpora, kao i uključenjem s ljudima koji govore ovim jezicima. U ovom ispitivanju predstavljamo procjenu pristupa države umjetnosti obuke i procjene MT-ova sistema na 22 jezika iz porodice turske jezike, većina njih je izuzetno pod istragom. Prvo, usvojimo TIL korpus sa nekoliko ključnih poboljšanja za obuku i sete procjene. Onda treniramo 26 dvojezičkih osnovnih linija, kao i multi-putni neuralni MT (MNMT) model koristeći korpus i izvršiti ogromnu analizu koristeći automatsku metriku i ljudske procjene. Nalazimo da model MNMT-a iznosi skoro sve dvojezičke osnovne linije u testovima izvan domena i finalizira model na donjem zadatku jednog par također rezultira u ogromnom povećanju učinka u scenarijima niskih i visokih resursa. Naša pažnja analiza kriterija procjene MT modela na turskim jezicima također ukazuje na potrebu za daljnjim istraživanjima u ovom smjeru. Puštamo korpus splitke, testove kao i modele javnosti.', 'cs': 'Navzdory rostoucímu počtu rozsáhlých a komplexních systémů strojového překladu (MT) bylo hodnocení těchto metod v různých jazycích omezeno nedostatkem kvalitních paralelních korpusů a zapojením se s lidmi, kteří tyto jazyky hovoří. V této práci představujeme hodnocení nejmodernějších přístupů k výcviku a hodnocení MT systémů v 22 jazycích z turecké jazykové rodiny, z nichž většina je extrémně nedostatečně prozkoumaná. Nejprve přijmeme TIL Corpus s několika klíčovými zlepšeními ve výcviku a hodnotících sadách. Poté trénujeme 26 dvojjazyčné základní linky a multi-way neuron MT (MNMT) model pomocí korpusu a provádíme rozsáhlou analýzu pomocí automatických metrik a lidských hodnocení. Zjišťujeme, že model MNMT překoná téměř všechny dvojjazyčné základní linie v mimo doménu testovacích sadách a jemné ladění modelu na následném úkolu jednoho páru rovněž vede k obrovskému zvýšení výkonu v scénářích s nízkými i vysokými zdroji. Naše pozorná analýza hodnotících kritérií MT modelů v tureckých jazycích také poukazuje na nutnost dalšího výzkumu v tomto směru. Vydáváme korpusové splity, testovací sady i modely veřejnosti.', 'et': 'Vaatamata suurte ja terviklike masintõlkesüsteemide arvu suurenemisele on nende meetodite hindamist erinevates keeltes takistanud kvaliteetsete paralleelkorpuste puudumine ning nende keelte rääkijatega seotus. Käesolevas uuringus esitame hinnangu tipptasemel lähenemisviisidele koolitusele ja MT-süsteemide hindamisele 22 türgi keele perekonna keeles, millest enamik on äärmiselt alauuritud. Esiteks võtame vastu TIL Corpuse koos mõningate oluliste parandustega koolitus- ja hindamiskogumites. Seejärel koolitame korpuse abil 26 kakskeelset baasjoonet ja mitmesuunalist neuraalset MT (MNMT) mudelit ning teostame ulatusliku analüüsi, kasutades automaatseid mõõdikuid ja inimhinnanguid. Leiame, et MNMT mudel ületab peaaegu kõiki kakskeelseid lähtejooni domeenivälisetes testides ning mudeli täpsustamine ühe paari alljärgneval ülesandel toob samuti kaasa tohutu jõudluse tõusu nii madala kui ka suure ressursiga stsenaariumides. Türgi keeles kasutatavate MT mudelite hindamiskriteeriumide tähelepanelik analüüs osutab samuti vajadusele selles suunas edasiste uuringute järele. Avaldame avalikkusele korpuse osad, testikomplektid ja mudelid.', 'fi': 'Suurten ja kattavien konekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmien (MT) mﾃ､ﾃ､rﾃ､n kasvusta huolimatta nﾃ､iden menetelmien arviointia eri kielillﾃ､ on jarruttanut laadukkaiden rinnakkaisten korpusten puute ja sitoutuminen nﾃ､itﾃ､ kieliﾃ､ puhuviin ihmisiin. Tﾃ､ssﾃ､ tutkimuksessa esitellﾃ､ﾃ､n arvio moderneista lﾃ､hestymistavoista koulutukseen ja arviointiin turkkilaisen kieliperheen 22 kielellﾃ､, joista suurin osa on erittﾃ､in vﾃ､hﾃ､n tutkittu. Ensin otamme kﾃ､yttﾃｶﾃｶn TIL Corpuksen, jossa on muutamia keskeisiﾃ､ parannuksia koulutukseen ja arviointiin. Tﾃ､mﾃ､n jﾃ､lkeen koulutamme 26 kaksikielistﾃ､ peruslinjaa sekﾃ､ monisuuntaista neuro-MT-mallia kﾃ､yttﾃ､en korpusta ja suoritamme laajan analyysin kﾃ､yttﾃ､en automaattisia mittareita sekﾃ､ ihmisen arviointeja. Havaitsemme, ettﾃ､ MNMT-malli suoriutuu lﾃ､hes kaikista kaksikielisistﾃ､ perusviivoista toimialueen ulkopuolisissa testisarjoissa ja mallin hienosﾃ､ﾃ､tﾃ､minen yhden parin loppupﾃ､ﾃ､n tehtﾃ､vﾃ､ﾃ､n johtaa myﾃｶs valtavaan suorituskykyyn sekﾃ､ vﾃ､hﾃ､n ettﾃ､ paljon resursseja vaativissa skenaarioissa. Tarkka analyysimme turkkilaisten MT-mallien arviointikriteereistﾃ､ osoittaa myﾃｶs, ettﾃ､ tﾃ､hﾃ､n suuntaan tarvitaan lisﾃ､tutkimuksia. Julkaisemme corpus split, testisarjat ja mallit yleisﾃｶlle.', 'af': "Terwyl die vergroot aantal groot en kompenseerde masjien vertaling (MT) stelsels word, is die evaluering van hierdie metodes in verskeie tale onderhou deur die ontbreek van hoë-kwaliteit parallele korpora en die vergadering van die mense wat hierdie taal praat. In hierdie studie voorsien ons 'n evaluering van staat-van-die-kuns toegang tot oefening en evaluering van MT-stelsels in 22 tale van die turkiske taal familie, waarvan die meeste van hulle is ekstrem onder-ondersoek. Eerste, ons aanvaar die TIL Corpus met 'n paar sleutel verbeteringe aan die opvoering en die evalueringsstelle. Dan trein ons 26 twee-tonge basisline en ook 'n multi we ë neurale MT (MNMT) model gebruik die korpus en uitvoer 'n uitbreidige analisie gebruik automatiese metrike en menslike evaluering. Ons vind dat die MNMT-model byna al twee tale baselyne uitvoer in die buitekant-domein-toets stel en fin die model op 'n onderstreem taak van 'n enkele paar ook resultaat in 'n groot prestasie booster in beide lae- en hoë- hulpbron scenarios. Ons aandaglike analisie van evalueringskriteriërs vir MT-modelle in Turkse tale wys ook na die nodigheid vir verdere ondersoek in hierdie rigting. Ons verlos die korpus splitte, toets stel ook as model vir die publiek.", 'jv': 'Nanging kabeh kut mbok sing kudu akeh sistem sing toljamahan lan akeh kompleh, MT, kuwi nggawe sistem sing ditambah kuwi tindakan kudu nggawe nguasai perusahaan karo kaluwargane sampeyan luwih dumateng, lan akeh dumateng kuwi kaku kaku kudu podho akeh kaya perusahaan langkung sampeyan ngono akeh dumateng kuwi tind Nang barêng-barêng iki, kéné sumulakno karo halêng langkung banjur kuwi nggawe sistem MT kanggo kuwi 22 tindan sing suku kaya alêng turk, sing apik dhéwé kawulé sak ngelasakno. Awak dhéwé, kéné sumungi tanggal nggawe kelas telu (TIL) lan didoleh bantuan kanggo nggawe tarjamahan lan nggawe cending. Mungkin, kita diweh bantêng-sistem sing berlanjut asai angan langgar sampeyan karo model sing nyebu, MT (MNMT) sing nggawe barang nggawe sistem kuwi kawasai sistem sing gawe lanjut sampeyan ngono nggawe sistem mat otomatik Metiks tambah ngono nggawe panceni tambah bantêr. Awak dhéwé ngerti, MNMT model iso dianggawe mesthi kabèh Bilngual bakal dumadhi nggawe winih-bakal dumadhan ngono nggawe model iso dianggawe downtream task of a single dumadhan bukané dadi ono akeh lanjut sing paling dhéwé iso dianggawe barang awak dhéwé karbot sing paling dhéwé Awak dhéwé énsuri tanggal dipunangé karo akeh pisan kanggo model MT ning langgambar turc kuwi mau ngerasakno kanggo ngilanggar sampek dumadhi iki. Awak dhéwé mbukaké karo hal-hal kuwi wis rampung, ujian ngono model karo hal upnik.', 'he': 'למרות מספר הגדול של מערכות התרגום המכונית (MT) גדולות ומרחבות, הערכה של השיטות הללו בשפות שונות הוגבלה על ידי חוסר גופורה מקבילה איכות גבוהה במחקר הזה, אנחנו מציגים עריכה של גישות מוקדמות לאימון ולעריכת מערכות MT ב-22 שפות ממשפחת השפה הטורקית, רוב מהן נמצאות במיוחד מתעלמות. ראשית, אנו מאמץ את הקורפוס TIL עם כמה שיפורים מפתחיים לאימונים והעריכה. ואז, אנחנו מאמן 26 קווי בסיס שתיים ששונים, כמו גם מודל MT עצבי רב-כיוון (MNMT) בשימוש בקורפוס וביצוע ניתוח רחב בשימוש מטריקה אוטומטית כמו גם ערכות אנושיות. אנו מוצאים שהמודל MNMT מוביל כמעט את כל קווי הבסיס שתיים לשונות במבחנים מחוץ לתחום ולהגדיר את המודל על משימה מתחתית של זוג אחד גם מוביל לתעלות ביצועים ענקית בתנאים נמוכים וגבוהים של משאבים. הניתוח הקשיב שלנו של קריטורי הערכה למודלים MT בשפות טורקיות מצביע גם על הצורך למחקר נוסף בכיוון הזה. We release the corpus splits, test sets as well as models to the public.', 'sk': 'Kljub naraščajočemu številu obsežnih in celovitih sistemov strojnega prevajanja (MT) je vrednotenje teh metod v različnih jezikih oviralo pomanjkanje kakovostnih vzporednih korpusov in sodelovanje z ljudmi, ki govorijo te jezike. V študiji predstavljamo vrednotenje najsodobnejših pristopov k usposabljanju in vrednotenju sistemov MT v 22 jezikih iz turške jezikovne družine, od katerih je večina izredno premalo raziskanih. Najprej sprejmemo TIL Corpus z nekaj ključnimi izboljšavami nabora usposabljanja in vrednotenja. Nato z uporabo korpusa treniramo 26 dvojezičnih osnovnih linij in večsmerni nevronski model MT (MNMT) ter opravimo obsežno analizo z uporabo avtomatskih metrik in človeških vrednotenj. Ugotovili smo, da model MNMT presega skoraj vse dvojezične osnovne črte v zunajdomenskih preskusnih nizikih, natančna nastavitev modela pri nadaljnjem delu enega pare pa prav tako povečuje zmogljivost v scenarijih z nizkimi in visokimi viri. Naša pozorna analiza meril ocenjevanja modelov MT v turških jezikih kaže tudi na potrebo po nadaljnjih raziskavah v tej smeri. Javnosti objavljamo razdelitve korpusa, testne sklope in modele.', 'ha': "Inã rantsuwa da ƙarantar tarjima mai girma da fassarar mashine na jumla (MT), an kange evaluation of waɗannan metode cikin lugha daban-daban, kuma an kange manjanci da koropa mai daidaita da tsakanin sami da haɗi da mutane waɗanda ke faɗa wannan harshen. Daga wannan lõkaci, Munã halatar da an ƙidãya masu tsari da fassarar-sanar zuwa na wa'anar da ma'anar MT cikin lugha 22 na'ura daga jama'ar turki, mafiya yawansu ana ƙarfafa. Kayyan da, tuna ɗauki Shirin na TIL da masu kyauta masu ƙaranci zuwa ma'abũta aikin da muhimmanci. Sa'an nan, za'a sanar da bakin 26 na'ura da misalin MT (MNMT) mai amfani da nau'in-biyu na'ura, kuma za'a sami wani anadi mai shimfiɗa ɗãwa da amfani da metrics farat ɗaya da kuma misalin mutum. Tuna gane cewa misalin MNMT na fara duk biyu masu cikin jarraba-bayani na guda kuma ya buɗe motel a kan wani aikin da ke ƙarami guda guda, kuma yana ƙara ƙaramako mai girma ga aikin aiki da duk ƙasan-da-resource. Anarari masu inganci ga misãlai na MT cikin harshen Tkurki, yana shirya wa muhamako da za'a iya ƙara lõkaci cikin wannan shirin. Suna sami karatun, ko da misãlai ga mutane.", 'bo': 'སྐད་ཡིག ལྟ་བ་འདི་ནང་དུ་ང་ཚོས་གནས་སྟངས་གཙོ་རིམ་གྱི་ཐབས་ལམ་ལ་རྒྱལ་ཁབ་ཀྱི་གནད་དོན་ཡོད་མིན་ཐག་གཙོ་རིམ་དང་། མིན་འདུག་ནང་གི་སྐད་རིགས་༢༢་ནང་ལ དང་པོར་བརྗོད་ན། ང་ཚོས་ཤེས་ཡོད་ལ་གཙོ་ཅན་གྱི་རྩོམ་པ་ཞིག་གི་ཡར་རྒྱས་གཏོང་ལ་ཉུང་ཤས་ཤིག་དང་། དེ་ནས་ང་ཚོས་དབྱིབས་26 bilingual baselines་ཀྱང་སྦྱར་བའི་neural MT (MNMT)མ་དབྱིབས་ལག་ལེན་འཐབ་སྟེ། We find that the MNMT model outperforms almost all bilingual baselines in the out-of-domain test sets and finetuning the model on a downstream task of a single pair also results in a huge performance boost in both low-and high-resource scenarios. ང་ཚོའི་དབུས་མཐུན་གྱི་རིམ ང་ཚོས་མཐུང་མཁན་དབུགས'}
{'en': 'DELA Corpus-A Document-Level Corpus Annotated with Context-Related Issues', 'ar': 'مجموعة DELA - مجموعة على مستوى المستند مشروحة بقضايا متعلقة بالسياق', 'pt': 'DELA Corpus - Um Corpus em Nível de Documento Anotado com Problemas Relacionados ao Contexto', 'es': 'DELA Corpus: un corpus a nivel de documento anotado con cuestiones relacionadas con el contexto', 'fr': 'DELA Corpus - Corpus au niveau du document annoté avec des questions liées au contexte', 'ja': 'DELA CORPUS -コンテキスト関連の問題で注釈された文書レベルのコーパス', 'zh': 'DELA 语料库 - 带上下文相关注文档级语料库', 'hi': 'DELA कॉर्पस - संदर्भ से संबंधित मुद्दों के साथ एनोटेट किया गया एक दस्तावेज़-स्तर कॉर्पस', 'ru': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues (Дела Корпус - Корпус на уровне документа, аннотированный к вопросам, связанным с контекстом)', 'ga': 'DELA Corpus - Corpas ar Leibhéal an Doiciméid atá Anótáilte le Saincheisteanna a Bhaineann le Comhthéacs', 'ka': 'DELA Corpus - დოკუმენტის დოკუმენტის კონტექსტური განსაზღვრებით დაკავშირებული კონტექსტური განსაზღვრებით', 'hu': 'DELA Corpus - Dokumentumszintű Corpus a kontextushoz kapcsolódó kérdésekkel', 'el': 'Σώμα DELA: Ένα σώμα σε επίπεδο εγγράφου που σχολιάζεται με θέματα που σχετίζονται με το περιβάλλον', 'it': 'DELA Corpus - Un corpus a livello di documento annotato con problemi correlati al contesto', 'kk': 'DELA корпус - Контексті қатынау мәселелерімен белгіленген құжат деңгейіндегі корпус', 'lt': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'mk': 'ДЕЛА Корпус - Корпус на ниво на документ анотиран со прашања поврзани со контекст', 'ms': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'mt': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'ml': 'DELA കോര്\u200dപ്പുസ് - ഒരു രേഖയുടെ- നില കോര്\u200dപ്പുസ് വിവരങ്ങളുമായി അറിയിച്ചിരിക്കുന്നു', 'mn': 'DELA Corpus - Документын түвшинд хамааралтай асуудлуудтай анзаарсан', 'no': 'DELA Corpus – eit dokumentnivåkorpus annotated with Context-Related Issues', 'pl': 'DELA Corpus – Korpus na poziomie dokumentu z zagadnieniami kontekstowymi', 'ro': 'DELA Corpus - Un corpus la nivel de document adnotat cu probleme legate de context', 'sr': 'DELA Corpus - Korpus na nivou dokumenta Annotiran s kontekstskim pitanjima', 'si': 'DELA කෝර්පුස් - විස්තර සම්බන්ධ ප්\u200dරශ්නයක් සමඟ ප්\u200dරශ්නයක්', 'so': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'sv': 'DELA Corpus - En corpus på dokumentnivå kommenterad med sammanhangsrelaterade frågor', 'ta': 'DELA கார்புஸ் - சூழல் தொடர்புடைய விஷயங்களுடன் அறிவிக்கப்பட்ட ஆவணம்- நிலை கோர்புஸ்', 'ur': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'uz': 'Name', 'vi': 'DelA Corpus... một nhóm tài liệu cấp báo với các vấn đề liên quan.', 'bg': 'ДЕЛА Корпус - Корпус на ниво документ, анотиран с въпроси, свързани с контекста', 'nl': 'DELA Corpus is een corpus op documentniveau dat geannoteerd wordt met contextgerelateerde problemen', 'hr': 'DELA Corpus - Corpus na razini dokumenta annotiran s kontekstskim pitanjima', 'da': 'DELA Corpus - Et dokument-niveau corpus annoteret med kontekst-relaterede problemer', 'id': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'sw': 'DELA Corpus - Huduma ya Document-Level iliyotangazwa na masuala yanayohusiana na Mazungumzo', 'de': 'DELA Corpus – Ein Korpus auf Dokumentenebene mit Anmerkungen zu kontextbezogenen Problemen', 'af': "DELA Corpus - ' n Dokument- Vlak Corpus aangeteken met Konteks- Verwante Utgaande", 'ko': 'DELA 자료 라이브러리 - 컨텍스트 관련 문제 주석이 있는 문서 수준 자료 라이브러리', 'am': 'የDELA ኮርፓስ - ሰነድ- ደረጃ ኮርፓስ የተቀረጸ የውይይት-በተገኘ ጉዳዮች', 'hy': 'DELA Corpus - Թղթերի մակարդակի կորպուս, որը նշում է համատեքստի հարցերով', 'fa': 'DELA Corpus - یک Corpus Level Document-Annotated with Context-Related Issues', 'bn': 'DELA কোর্পাস - একটি ডকুমেন্ট- স্তর কোর্পাস বিষয়বস্তুর সাথে ঘোষণা করা হয়েছে', 'az': 'DELA Corpus - Context-Related Issues Annotated A Document-Level Corpus', 'ca': 'DELA Corpus - Un Corpus de nivell documental anotat amb qüestions relacionades amb el context', 'cs': 'DELA Corpus – Korpus na úrovni dokumentů s poznámkami souvisejícími s kontextem', 'et': 'DELA Corpus – dokumenditasemel korpus, millel on kontekstiga seotud probleemid', 'fi': 'DELA Corpus - Asiakirjatason Corpus, johon on merkitty kontekstiin liittyviä kysymyksiä', 'sq': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'bs': 'DELA Corpus - Korpus na nivou dokumenta annotiran s kontekstskim pitanjima', 'tr': 'DELA Korpus', 'ha': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues', 'he': 'DELA Corpus - A Document-Level Corpus Annotated with Context Related Issues', 'jv': 'DELA corpus - A document-Layer', 'sk': 'DELA Corpus – korpus na ravni dokumenta z opombami na vprašanja, povezana z kontekstom', 'bo': 'DELA Corpus - A Document-Level Corpus Annotated with Context-Related Issues'}
{'en': 'Recently, the Machine Translation (MT) community has become more interested in document-level evaluation especially in light of reactions to claims of human parity, since examining the quality at the level of the document rather than at the sentence level allows for the assessment of suprasentential context, providing a more reliable evaluation. This paper presents a document-level corpus annotated in English with context-aware issues that arise when translating from ', 'ar': 'في الآونة الأخيرة ، أصبح مجتمع الترجمة الآلية (MT) أكثر اهتمامًا بالتقييم على مستوى المستند خاصة في ضوء ردود الفعل على ادعاءات "التكافؤ البشري" ، نظرًا لأن فحص الجودة على مستوى المستند بدلاً من مستوى الجملة يسمح تقييم السياق فوق السطحي ، وتوفير تقييم أكثر موثوقية. تقدم هذه الورقة مجموعة على مستوى المستند مشروحة باللغة الإنجليزية مع مشكلات مدركة للسياق تنشأ عند الترجمة من الإنجليزية إلى البرتغالية البرازيلية ، وهي علامات الحذف ، والجنس ، والغموض المعجمي ، والعدد ، والمراجع ، والمصطلحات ، مع ستة مجالات مختلفة. يمكن استخدام المجموعة كمجموعة اختبار تحدي للتقييم وكمجموعة تدريب / اختبار لـ MT بالإضافة إلى التحليل اللغوي العميق لقضايا السياق. على حد علمنا ، هذا هو أول مجموعة من نوعها.', 'fr': "Récemment, la communauté de la traduction automatique s'est intéressée de plus en plus à l'évaluation au niveau du document, en particulier à la lumière des réactions aux allégations de «\xa0parité humaine\xa0», puisque l'examen de la qualité au niveau du document plutôt qu'au niveau de la phrase permet d'évaluer le contexte suprasententiel, fournir une évaluation plus fiable. Cet article présente un corpus au niveau du document annoté en anglais avec les problèmes contextuels qui se posent lors de la traduction de l'anglais vers le portugais brésilien, à savoir les points de suspension, le genre, l'ambiguïté lexicale, le nombre, la référence et la terminologie, avec six domaines différents. Le corpus peut être utilisé comme ensemble de tests de défi pour l'évaluation et comme corpus de formation/test pour la traduction automatique ainsi que pour l'analyse linguistique approfondie de questions contextuelles. À notre connaissance, il s'agit du premier corpus de ce type.", 'es': 'Recientemente, la comunidad de traducción automática (MT) se ha interesado más en la evaluación a nivel de documento, especialmente a la luz de las reacciones a las afirmaciones de «paridad humana», ya que el examen de la calidad a nivel del documento en lugar de a nivel de oración permite la evaluación del contexto suprasentencial. proporcionando una evaluación más fiable. Este artículo presenta un corpus a nivel de documento anotado en inglés con problemas sensibles al contexto que surgen al traducir del inglés al portugués brasileño, a saber, puntos suspensivos, género, ambigüedad léxica, número, referencia y terminología, con seis dominios diferentes. El corpus se puede utilizar como un conjunto de pruebas de desafío para la evaluación y como un corpus de capacitación/prueba para MT, así como para un análisis lingüístico profundo de cuestiones de contexto. Por lo que sabemos, este es el primer corpus de este tipo.', 'pt': 'Recentemente, a comunidade de tradução automática (MT) tornou-se mais interessada na avaliação em nível de documento, especialmente à luz de reações a alegações de “paridade humana”, uma vez que examinar a qualidade no nível do documento e não no nível da sentença permite a avaliação do contexto suprassentencial, proporcionando uma avaliação mais confiável. Este artigo apresenta um corpus em nível de documento anotado em inglês com questões contextuais que surgem ao traduzir do inglês para o português brasileiro, a saber, reticências, gênero, ambiguidade lexical, número, referência e terminologia, com seis domínios diferentes. O corpus pode ser usado como um conjunto de testes de desafio para avaliação e como um corpus de treinamento/teste para TA, bem como para análise linguística profunda de questões de contexto. Até onde sabemos, este é o primeiro corpus desse tipo.', 'ja': '最近、機械翻訳（ MT ）コミュニティは、特に「人間のパリティ」という主張への反応を考慮して、文書レベルの評価により関心を持つようになりました。文レベルではなく文書レベルで品質を調べることで、超精神的文脈の評価が可能になり、より信頼性の高い評価が提供されるからです。本稿では、英語からブラジルポルトガル語に翻訳する際に生じる文脈を意識した問題、すなわち省略記号、性別、語彙の曖昧さ、数、参照、および用語について、6つの異なるドメインを持つ英語で注釈を付けた文書レベルのコーパスを紹介する。コーパスは、評価のためのチャレンジテストセット、MTのトレーニング/テストコーパス、および文脈問題の深い言語学的分析として使用することができます。私たちの知る限りでは、これはその種の最初のコーパスです。', 'zh': '近者,机器翻译(MT)社区文档估益兴,特虑致人伦水平之应,盖文档级而非句级检质可以料上下文,而资其可恃者也。 本文引英语注文档级语料库,其英语翻译为巴西葡萄牙语上下文感知,即省略号,性别,词汇歧义数,引与术语,有六异域。 语料库可以评估挑战试集、机器翻译训练/试语料库,及上下文深入语析。 以吾所知,类之一语料。', 'hi': 'हाल ही में, मशीन अनुवाद (एमटी) समुदाय विशेष रूप से "मानव समानता" के दावों के लिए प्रतिक्रियाओं के प्रकाश में दस्तावेज़-स्तर के मूल्यांकन में अधिक रुचि रखता है, क्योंकि वाक्य स्तर के बजाय दस्तावेज़ के स्तर पर गुणवत्ता की जांच करने से सुप्रासेंटेंशियल संदर्भ के मूल्यांकन के लिए अनुमति मिलती है, जो अधिक विश्वसनीय मूल्यांकन प्रदान करता है। यह पेपर अंग्रेजी में एक दस्तावेज़-स्तरीय कॉर्पस को संदर्भ-जागरूक मुद्दों के साथ एनोटेट किया गया है जो अंग्रेजी से ब्राजील के पुर्तगाली में अनुवाद करते समय उत्पन्न होता है, अर्थात् एलिप्सिस, लिंग, लेक्सिकल अस्पष्टता, संख्या, संदर्भ और शब्दावली, छह अलग-अलग डोमेन के साथ। कॉर्पस का उपयोग मूल्यांकन के लिए एक चुनौती परीक्षण सेट के रूप में और एमटी के लिए प्रशिक्षण / परीक्षण कॉर्पस के साथ-साथ संदर्भ मुद्दों के गहरे भाषाई विश्लेषण के लिए किया जा सकता है। हमारे ज्ञान का सबसे अच्छा करने के लिए, यह अपनी तरह का पहला कॉर्पस है।', 'ru': 'В последнее время сообщество машинного перевода (МП) стало больше интересоваться оценкой на уровне документа, особенно в свете реакций на утверждения о «человеческом паритете», поскольку изучение качества на уровне документа, а не на уровне предложения позволяет оценить суперагентный контекст, обеспечивая более надежную оценку. В этой статье представлен корпус на уровне документа, аннотированный на английском языке с учетом контекста вопросов, которые возникают при переводе с английского на бразильский португальский, а именно многоточие, пол, лексическая двусмысленность, число, ссылка и терминология, с шестью различными областями. Корпус может использоваться в качестве набора контрольных тестов для оценки и в качестве корпуса для обучения/тестирования для MT, а также для глубокого лингвистического анализа вопросов контекста. Насколько нам известно, это первый корпус такого рода.', 'ga': 'Le déanaí, chuir pobal an Aistriúcháin Inneall (MT) níos mó suime i meastóireacht ar leibhéal doiciméad, go háirithe i bhfianaise freagairtí ar maímh maidir le “paireacht dhaonna”, ós rud é go gceadaíonn scrúdú a dhéanamh ar cháilíocht ag leibhéal an doiciméid seachas ag leibhéal na pianbhreithe. measúnú ar chomhthéacs uachtarach, ag soláthar meastóireacht níos iontaofa. Cuireann an páipéar seo corpas ar leibhéal doiciméad i láthair agus é anótáilte i mBéarla le saincheisteanna feasach ar chomhthéacs a thagann chun cinn nuair a aistrítear ón mBéarla go Portaingéilis na Brasaíle, is iad sin éilips, inscne, débhríocht fhoclóra, uimhir, tagairt, agus téarmaíocht, le sé fhearann éagsúla. Is féidir an corpas a úsáid mar thacar tástála dúshláin le haghaidh meastóireachta agus mar chorpas oiliúna/tástála don MT chomh maith le hanailís dhomhain teangeolaíoch ar cheisteanna comhthéacs. Chomh fada agus is eol dúinn, is é seo an chéad chorpas dá leithéid.', 'ka': 'მხოლოდ მაქსინური გადაწყვეტილება (MT) საზოგადოება უფრო ინტერესებულია დოკუმენტის განსაზომილებაში, განსაკუთრებით განსაზომილებების განსაზომილებაში "ადამიანური პერიცია", რომლებიც დოკუმენტის დოკუმენტის დოკუმენტის გა ეს დოკუმენტის კოპუპუტების დოკუმენტის კოპუპუტები, რომელიც კონტექსტურის შეცდომებით იქნება, როდესაც ანგლისდან ბრაზილური პორტეგუტებში გადატანა, ანუ, ელექსიკური, ლექსიკური ამბიდუტი კორპუსი შეიძლება გამოყენება როგორც განსაზღვრებისთვის განსაზღვრებული ტესტი და როგორც MT-ის განსაზღვრებული/ტესტირებული კორპუსი და კონტექსტის განსაზღვრებისთვის ენალი ჱა ნაი-ეჲბპვრჲ ჲრ ნაქთრვ ჱნანთწ, რჲგა ვ ოყპგთწრ კჲპოსჟ ჲრ ნვწ.', 'el': 'Πρόσφατα, η κοινότητα της μηχανικής μετάφρασης (ΜΤ) έχει αρχίσει να ενδιαφέρεται περισσότερο για την αξιολόγηση σε επίπεδο εγγράφων, ιδίως υπό το πρίσμα των αντιδράσεων σε ισχυρισμούς περί "ανθρώπινης ισοτιμίας", δεδομένου ότι η εξέταση της ποιότητας σε επίπεδο εγγράφου και όχι σε επίπεδο προτάσεων επιτρέπει την αξιολόγηση του υπερκοινωνικού πλαισίου, παρέχοντας μια πιο αξιόπιστη αξιολόγηση. Η παρούσα εργασία παρουσιάζει ένα σώμα σε επίπεδο εγγράφου που σχολιάζεται στα αγγλικά με ζητήματα που σχετίζονται με το περιβάλλον που προκύπτουν κατά τη μετάφραση από τα αγγλικά στα βραζιλιάνικα πορτογαλικά, δηλαδή ελλείπση, φύλο, λεξική ασάφεια, αριθμός, αναφορά και ορολογία, με έξι διαφορετικούς τομείς. Το σώμα μπορεί να χρησιμοποιηθεί ως δοκιμαστικό σύνολο για αξιολόγηση και ως σώμα εκπαίδευσης/δοκιμών για ΜΤ καθώς και για βαθιά γλωσσική ανάλυση θεμάτων περιβάλλοντος. Απ\' όσο γνωρίζουμε, αυτό είναι το πρώτο σώμα του είδους του.', 'hu': 'Az utóbbi időben a Gépi Fordítás (MT) közösség egyre inkább érdeklődött a dokumentumszintű értékelés iránt, különösen az "emberi egyenlőség" állításaira adott reakciók fényében, mivel a dokumentum szintjén történő vizsgálat, nem pedig mondatszinten, lehetővé teszi a szupracentiális kontextus értékelését, megbízhatóbb értékelést biztosítva. Ez a tanulmány egy angol nyelvű dokumentumszintű korpuszt mutat be, amely az angol nyelvről brazil portugálra történő fordítás során felmerülő kontextustudatos kérdésekkel, nevezetesen ellipszissel, nemmel, lexikai kétértelműséggel, számmal, hivatkozással és terminológiával, hat különböző területen. A korpusz felhasználható kihívási tesztkészletként értékelésre és képzési/tesztelési korpuszként MT-re, valamint kontextuskérdések mélyreható nyelvi elemzésére. Legjobb tudásunk szerint ez az első ilyen korpusz.', 'it': 'Recentemente, la comunità di Machine Translation (MT) è diventata più interessata alla valutazione a livello di documento soprattutto alla luce delle reazioni alle affermazioni di "parità umana", poiché esaminare la qualità a livello del documento piuttosto che a livello di frase consente di valutare il contesto soprasentenziale, fornendo una valutazione più affidabile. Questo articolo presenta un corpus a livello di documento annotato in inglese con problemi contestuali che sorgono quando si traducono dall\'inglese al portoghese brasiliano, vale a dire ellissi, genere, ambiguità lessicale, numero, riferimento e terminologia, con sei domini diversi. Il corpus può essere utilizzato come set di test di sfida per la valutazione e come corpus di formazione/test per MT, nonché per analisi linguistiche approfondite dei problemi di contesto. Per quanto ne sappiamo, questo è il primo corpus del suo genere.', 'lt': 'Pastaruoju metu mašin ų vertimo (MT) bendruomenė labiau suinteresuota dokumentų lygmens vertinimu, ypač atsižvelgiant į reakcijas į teiginius dėl "žmogaus lygybės", nes nagrinėjant kokybę dokumento lygmeniu, o ne bausmės lygmeniu, galima įvertinti viršbaudžiamąjį kontekstą ir suteikti patikimesnį vertinimą. Šiame dokumente pateikiamas dokumentų lygmens korpusas, užrašytas anglų kalba, kuriame pateikiami konteksto supratimo klausimai, kylantys vertant anglų kalba į Brazilijos portugalų kalbą, būtent elipsija, lytis, leksinis dviprasmiškumas, numeris, nuoroda ir terminologija, turintys šešias skirtingas sritis. Korpus gali būti naudojamas kaip iššūkių bandymas vertinimui ir kaip MT mokymo ir (arba) bandymo korpusas, taip pat kaip gili kalbinė konteksto klausimų analizė. To the best of our knowledge, this is the first corpus of its kind.', 'kk': 'Жуырда Машин аудару (MT) коммуникасы құжат деңгейінің бағалауына көп қызықты болды, осымен қатар "адамдардың паритеті" деңгейіндегі жағдайлардың қасиетін тексеру үшін, сөйлеменің деңгейінде қасиетті тексеру үшін, көбірек контексті бағалау үшін,  Бұл қағаз ағылшын тілінде белгіленген құжат деңгейіндегі корпус ағылшын тілінде ағылшын тілінен Бразилиялық португалға аударғанда, бұл - елипсис, гендер, лексикалық амбигивіт, нөмір, сілтеме, терминология, алты Корпус бағалау үшін және MT үшін оқыту/сынақтау корпус ретінде және контекстік мәселелердің тығыс лингвистикалық анализ үшін қолданылады. Біздің біліміздің ең жақсы түрімізге, бұл оның бірінші корпус.', 'mk': "Recently, the Machine Translation (MT) community has become more interested in document-level evaluation especially in light of reactions to claims of 'human parity', since examining the quality at the level of the document rather than at the sentence level allows for the assessment of suprasentential context, providing a more reliable evaluation.  Овој документ претставува корпус на ниво на документ анотиран на англиски со контекстни прашања кои се појавуваат кога се преведуваат од англиски на бразилски португалски, а тоа е елипса, пол, лексичка нејасност, број, референција и терминологија, со шест различни домени. Корпусот може да се користи како тест на предизвици за евалуација и како корпус за обука/тест за МТ, како и за длабока лингвистичка анализа на контекстните прашања. Според нашето знаење, ова е првиот корпус од ваков вид.", 'ms': "Baru-baru ini, komuniti Terjemahan Mesin (MT) telah menjadi lebih berminat dalam penilaian aras dokumen terutama dalam cahaya tindak balas kepada klaim 'pariti manusia', kerana memeriksa kualiti pada aras dokumen daripada pada aras kalimat membolehkan penilaian konteks suprasentential, menyediakan penilaian yang lebih dipercayai. Kertas ini menghasilkan corpus aras dokumen yang dicatat dalam bahasa Inggeris dengan isu-isu yang sedar-konteks yang muncul apabila diterjemahkan dari Inggeris ke Portugis Brazil, iaitu elipsis, jenis, ambiguiti leksikal, nombor, rujukan, dan terminologi, dengan enam domain yang berbeza. Korpus boleh digunakan sebagai set ujian cabaran untuk penilaian dan sebagai korpus latihan/ujian untuk MT serta untuk analisis bahasa dalam isu konteks. Menurut pengetahuan kita, ini adalah corpus pertama dari jenisnya.", 'mt': 'Dan l-a ħħar, il-komunità tat-Traduzzjoni bil-Makkinarju (MT) saret aktar interessata fl-evalwazzjoni fil-livell tad-dokument speċjalment fid-dawl tar-reazzjonijiet għal stqarrijiet ta\' "parità umana", billi l-eżami tal-kwalità fil-livell tad-dokument aktar milli fil-livell tas-sentenza jippermetti l-valutazzjoni tal-kuntest suprasentenzjali, li jipprovdi evalwazzjoni aktar affidabbli. Dan id-dokument jippreżenta korpus fuq livell ta’ dokument annotat bl-Ingliż b’kwistjonijiet konxji tal-kuntest li jinqalgħu meta jiġu tradotti mill-Ingliż għal Portugiż Brażiljan, jiġifieri elipsi, sess, ambigwità lexika, numru, referenza, u terminoloġija, b’sitt oqsma differenti. Il-korpus jista’ jintuża bħala sett ta’ test ta’ sfida għall-evalwazzjoni u bħala korpus ta’ taħriġ/ittestjar għall-MT kif ukoll għal analiżi lingwistika profonda ta’ kwistjonijiet ta’ kuntest. Għall-aħjar għarfien tagħna, dan huwa l-ewwel korpus tat-tip tiegħu.', 'no': 'Nyleg har samfunnet Machine Translation (MT) blitt meir interessert i evaluering av dokumentnivået, spesielt i lys av reaksjonar til tiltak av «menneskelige paritet», sidan du undersøker kvaliteten på dokumentnivået i staden for setningsnivået tillet evaluering av suprasententisk kontekst, og tilbyr ein betre evaluering. Denne papiret viser eit korpus med dokumentnivået merkt på engelsk med kontekstoppmerksomhet som oppstår når det vert omsett frå engelsk til Brasiliansk portugisisk, dvs. ellipser, gener, leksisk ambiguitet, nummer, referanse og terminologi, med seks ulike domene. Korpusen kan brukast som utfordringstest sett for evaluering og som opplæring/testing korpus for MT og for dypt språk analyse av kontekstproblemar. Dette er den første korpusen av denne typen.', 'mn': 'Сүүлийн үед Машин хөрөнгө оруулалт (MT) нийгэм баримтуудын түвшинд илүү сонирхолтой болсон. Ялангуяа "хүн төрөлхтний төвшин"-ын хариу үйлдлийн гэрэл, баримтуудын түвшинд хэмжээний талаар шалгаж өгүүлэлтийн түвшинд нь илүү итгэлтэй дүгнэлт гаргадаг. Энэ цаас Англи хэлний хэлбэрээс Англи хэлний хувьд англи хэлний хувьд зургаан өөр хэлбэртэй зурван зурван зурван зурван зурван зурван, гендер, лексик хэмжээсүүд, тоо, санал, терминологийг авч ирэх асуудлуудыг харуулдаг. Корпус нь үнэлэх шаардлагатай шаардлагатай шалгалт болон MT-ийн сургалт/тест корпус болон байгаль асуудлын гүн гүнзгий хэлний шинжилгээнд ашиглаж болно. Бидний мэдлэгийн хамгийн сайн хувьд энэ бол түүний анхны корпус.', 'ml': "അടുത്തുതന്നെ മെഷീന്\u200d പരിഭാഷ (എംടി) സമൂഹത്തില്\u200d 'മനുഷ്യരുടെ പാര്\u200dട്ടിറ്റി' പ്രതികരിക്കുന്നതിന്റെ പ്രതികരണങ്ങള്\u200dക്കുള്ള പ്രതികാരം വിശേഷിച്ചു മാറ്റിയിരിക്കുന്നു. വാക്ക് നില ഇംഗ്ലീഷില്\u200d നിന്ന് ഇംഗ്ലീഷിലേക്ക് പരിഭാഷപ്പെടുത്തുമ്പോള്\u200d ഇംഗ്ലീഷിലേക്ക് പോര്\u200dട്ടുഗീഷിലേക്ക് പരിഭാഷപ്പെടുത്തുമ്പോള്\u200d ഇംഗ്ലീഷിലേക്ക് പ വിലാസങ്ങള്\u200dക്കും എംടിക്ക് പരീക്ഷിക്കുന്നതിനും പരീക്ഷ കോര്\u200dപ്പുസിന്റെയും ആഴത്തിലുള്ള ഭാഷ അന്വേഷണങ്ങള്\u200dക്കും ഉപയോഗിക്കാം. നമ്മുടെ അറിവിന്\u200dറെ ഏറ്റവും നല്ലതിന് ഇതാണ് അതിന്\u200dറെ ആദ്യത്തെ കോര്\u200dപ്പുസ്.", 'pl': 'Ostatnio społeczność tłumaczeń maszynowych (MT) stała się coraz bardziej zainteresowana oceną na poziomie dokumentów, zwłaszcza w świetle reakcji na twierdzenia o "parytecie ludzkiej", ponieważ badanie jakości na poziomie dokumentu, a nie na poziomie zdania pozwala na ocenę kontekstu ponadsencjonalnego, zapewniając bardziej wiarygodną ocenę. W artykule przedstawiono korpus na poziomie dokumentu adnotacyjny w języku angielskim z zagadnieniami kontekstowymi, które pojawiają się podczas tłumaczenia z języka angielskiego na portugalski brazylijski, mianowicie elipsy, płci, dwuznaczności leksykalnej, liczby, odniesienia i terminologii, z sześcioma różnymi dziedzinami. Korpus może być wykorzystywany jako zestaw testów wyzwań do oceny i jako korpus szkoleniowy/testujący dla MT, jak również do głębokiej analizy językowej zagadnień kontekstowych. Według naszej wiedzy jest to pierwszy tego rodzaju korpus.', 'ro': 'Recent, comunitatea de traducere automată (MT) a devenit mai interesată de evaluarea la nivel de document, mai ales în lumina reacțiilor la afirmațiile de "paritate umană", deoarece examinarea calității la nivelul documentului, mai degrabă decât la nivelul propoziției permite evaluarea contextului suprasențial, oferind o evaluare mai fiabilă. Această lucrare prezintă un corpus la nivel de document adnotat în limba engleză cu probleme conștiente de context care apar atunci când traduc din engleză în portugheză braziliană, și anume elipsis, gen, ambiguitate lexică, număr, referință și terminologie, cu șase domenii diferite. Corpusul poate fi folosit ca set de teste de probă pentru evaluare și ca corpus de instruire / testare pentru MT, precum și pentru analiza lingvistică profundă a problemelor de context. Din câte ştim, acesta este primul corpus de acest gen.', 'sr': 'Nedavno, zajednica za prevod mašine (MT) postala je više zainteresovana za procjenu nivoa dokumenta, posebno u svjetlu reakcija na tvrdnje "ljudskog pariteta", pošto je pregledala kvalitet na nivou dokumenta umjesto na nivou rečenice omogućava procjenu suprasentativnog konteksta, pružajući pouzdaniju procjenu. Ovaj papir predstavlja korpus na nivou dokumenta annotiran na engleskom jeziku sa kontekstskim pitanjima koji se pojavljuju kada se prevodi iz engleskog na Brazilski portugalski, a to je ellipsis, spol, leksička ambiguitet, broj, referencija i terminologija, sa šest različitih domena. Korpus se može koristiti kao test izazova koji je postavljen za procjenu i kao korpus obuke/testiranja MT-a, kao i za duboku jezičku analizu kontekstskih problema. Za najbolje od našeg znanja, ovo je prvi korpus njegove vrste.', 'si': 'අවසානයෙන්, මේෂන් භාවිතය (MT) සමාජය විශ්වාස කරන්න විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේ This papers presents a file-level Corpus adverted in English with Contexts-Knowing challenges that rise from English to Brazilian Portugees, Namely Elipses, Genr, lexic Ambguity, number, Reference, and Terminal ology, with 6 vary domain. කොර්පුස් විශ්වාස කරන්න පුළුවන් විශ්වාස කරන්න අවශ්\u200dය පරීක්ෂණයක් විදිහට භාවිතා කරන්න, MT විදිහට ප්\u200dරශ්නය/පරීක් අපේ දැනගන්න හොඳම දේවල්, මේක තමයි ඒ වගේ පළමු කොර්පුස්.', 'so': 'Muddii u dhowaad ayaa bulshada turjumidda mashiinka (MT) aad ugu xiiseysay qiimeynta heerka qoraalka, khusuusan ka mid ah qiimeynta ku saabsan qiimeynta heshiiska dadka, sababtoo ah baaritaanka qiimeynta heerka dukumentiga ee heerka qofka ku qoran waxyaabaha lagu aamin karo. Qoraalkan waxaa soo saara qoraal heer oo warqad ku qoran afka Ingiriis ku qoran arrimaha aqoon leh oo soo bixinaya marka laga turjumo afka Ingiriiska ilaa Burtuqiis, tusaale ahaan ellipsis, jinsi, jimicsi, nambarka, reference, iyo terminology, waxay leeyihiin lix meelood oo kala duwan. Qoriga waxaa looga isticmaali karaa imtixaanka dhibaatooyinka lagu qiimeeyo iyo baaritaanka MT iyo baaritaanka luuqadda dheer oo ku saabsan arrimaha soo socda. To the best of our knowledge, this is the first corpus of its kind.', 'sv': 'P책 senare tid har maskin철vers채ttningsgruppen blivit mer intresserad av utv채rdering p책 dokumentniv책, s채rskilt mot bakgrund av reaktioner p책 p책st책enden om "m채nsklig j채mlikhet", eftersom en granskning av kvaliteten p책 dokumentet snarare 채n p책 meningsniv책 g철r det m철jligt att bed철ma 철verk채nsliga sammanhang, vilket ger en mer tillf철rlitlig utv채rdering. Denna uppsats presenterar en dokumentniv책 korpus kommenterad p책 engelska med kontextmedvetna fr책gor som uppst책r vid 철vers채ttning fr책n engelska till brasiliansk portugisiska, n채mligen ellipsis, genus, lexikal tvetydighet, tal, referens och terminologi, med sex olika dom채ner. Korpusen kan anv채ndas som en provupps채ttning f철r utv채rdering och som en utbildnings-/testkorpus f철r MT samt f철r djupg책ende spr책klig analys av kontextfr책gor. S책 vitt vi vet 채r detta den f철rsta korpusen av sitt slag.', 'ur': 'اچھے وقت، ماشین ترجمن (MT) کمونٹی دکمونٹ-سطح ارزیابی میں زیادہ علاقه مند ہو گئی ہے، مخصوصاً انسان پارکیٹی کی تعبیر کی روشنی کی روشنی کے ساتھ، کیونکہ دکمونٹ کے سطح کے سطح پر کیفیت کی تحقیق کرتی ہے بغیر مجموعہ سطح کے سطح کی ارزیابی کے لئے، بہت This paper presents a document-level corpus annotated in English with context-conscious issues that arise when translating from English to Brazilian Portuguese, namely ellipsis, gender, lexical ambiguity, number, reference, and terminology, with six different domains. کورپوس کا ارزیابی کے لئے چلنے کی آزمائش کے طور پر استعمال کر سکتا ہے اور MT کے لئے تطارین/امتحان کی کورپوس کے طور پر بھی اور کنٹنسیٹ مسائل کی عمیق زبان شناسی تحلیل کے لئے بھی استعمال کر سکتا ہے. ہمارے بہترین علم کے لئے یہ سب سے پہلی جسم ہے۔', 'ta': "சமீபத்தில், இயந்திரம் மொழிபெயர்ப்பு (MT) சமூகத்தில் ஆவண- மட்டத்தின் மதிப்பில் அதிக ஆர்வமாகி இருக்கிறது குறிப்பிட்ட 'மனித சார்ந்திரத்திற்கு' கூறும் பிரச்சனையில், வாக்கிய நிலையி இந்த தாள் ஆங்கிலத்திலிருந்து ஆங்கிலத்திலிருந்து பிராசிலியன் போர்த்துகீசிக்கு மொழிமாற்றி மொழிபெயர்ப்பில் இருந்து பிராசிலியான போர்த்துகீசிக்க இந்த கோர்பாஸ் ஒரு சவால் சோதனையாக பயன்படுத்தப்படும் மதிப்பு மற்றும் MT க்கான பயிற்சி/சோதனைக் குறியீடு மற்றும் சூழல் பிரச்னைகளி எங்கள் அறிவின் மிக மேலானது, இது அவரது வகையின் முதல் கோர்புஸ் ஆகும்.", 'uz': "Yaqinda, Mashine tarjima qilish (MT) jamiyati dokument darajasini qiymatga juda qiziqarli bo'lgan. Hujjatni tasdiqlash imkoniyatini o'rganish imkoniyatini ko'rsatadi. Hujjatni tasdiqlash imkoniyatini o'zgartirish imkoniyatini bajarishi mumkin. Bu qogʻoz ingliz tilida taʼminlovchi ingliz tilida qoʻllangan hujjatning darajasi tarjima qilinadi. Bu yerda inglizcha inglizcha portugisiga tarjima qilayotganda, ellipsiz, jinsiya, leksikal balandligi, raqam, taxminan va terminologiya bilan 6 boshqa domeya tarjima qilayotganda. Name Bizning eng yaxshi o'rganimiz uchun bu uning birinchi ko'pchiligi.", 'vi': 'Gần đây cộng đồng Machine Translation (MTV) đã trở nên thú vị hơn trong việc đánh giá tài liệu, đặc biệt trong ánh sáng của các phản ứng về yêu cầu "đẳng cấp con người", vì kiểm tra chất lượng ở mức tài liệu thay vì mức án cho phép đánh giá hoàn cảnh cường tráng lệ, cung cấp một đánh giá đáng tin cậy hơn. Bài báo này có một tập thể đầy tài liệu được ghi lại bằng tiếng Anh có những vấn đề nhận biết ngữ cảnh xuất hiện khi dịch từ Anh sang tiếng Bồ Đào Nha Brazil, đó là Ellipsis, giới tính, ngôn ngữ, số lượng, tham khảo và thuật ngữ, với sáu lĩnh vực khác nhau. Tập đoàn có thể được sử dụng như một thử thách để đánh giá và như một tập đoàn huấn luyện/kiểm tra MTV cũng như cho một kiểm tra ngôn ngữ sâu về các vấn đề ngữ cảnh. Theo như chúng tôi biết, đây là cơ thể đầu tiên của loại này.', 'nl': "De laatste tijd is de gemeenschap van machinevertaling (MT) meer geïnteresseerd geworden in evaluatie op documentniveau, vooral in het licht van reacties op beweringen van 'menselijke pariteit', omdat het onderzoeken van de kwaliteit op het niveau van het document in plaats van op het niveau van zinnen mogelijk maakt om de suprasententiele context te beoordelen, wat een betrouwbaardere evaluatie oplevert. Deze paper presenteert een document-level corpus geannoteerd in het Engels met contextbewuste problemen die zich voordoen bij het vertalen van het Engels naar het Braziliaanse Portugees, namelijk ellipsis, geslacht, lexicale ambiguïteit, getal, referentie en terminologie, met zes verschillende domeinen. Het corpus kan worden gebruikt als een challenge test set voor evaluatie en als een training/test corpus voor MT evenals voor diepgaande linguïstische analyse van contextvraagstukken. Voor zover wij weten is dit het eerste corpus in zijn soort.", 'bg': 'Наскоро общността на машинния превод (МТ) стана по-заинтересована от оценката на ниво документи, особено в светлината на реакциите на твърденията за "човешки паритет", тъй като изследването на качеството на ниво документа, а не на ниво изречение, позволява оценка на надчувствения контекст, осигурявайки по-надеждна оценка. Настоящата статия представя корпус на документно ниво, анотиран на английски език, с въпроси, свързани с контекста, които възникват при превод от английски на бразилски португалски език, а именно елипса, пол, лексикална двусмисленост, число, справка и терминология, с шест различни области. Корпусът може да бъде използван като изпитателен комплект за оценка и като обучителен/тестващ корпус за МТ, както и за задълбочен лингвистичен анализ на контекстни въпроси. Доколкото знаем, това е първият по рода си корпус.', 'hr': 'U nedavno vrijeme zajednica za prevod strojeva (MT) postala je više zainteresovana za procjenu nivoa dokumenta, posebno u svjetlu reakcija na tvrdnje "ljudskog pariteta", jer je pregledavanje kvalitete na razini dokumenta umjesto na razini rečenice omogućila procjenu suprasentativnog konteksta, pružajući pouzdaniju procjenu. Ovaj papir predstavlja korpus na razini dokumenta annotiran na engleskom jeziku s pitanjima s kontekstskim svjesnim pitanjima koji se pojavljuju kada se prevodi iz Engleskog na Brazilski portugalski portugalski, a to je ellipsis, spol, leksički ambiguitet, broj, referencija i terminologija, s šest različitih domena. Korpus se može koristiti kao test izazova koji je postavljen za procjenu i kao korpus obuke/testiranja MT-a, kao i za duboku jezičku analizu kontekstskih pitanja. Za najbolje od našeg znanja, ovo je prvi korpus njegove vrste.', 'id': "Recently, the Machine Translation (MT) community has become more interested in document-level evaluation especially in light of reactions to claims of 'human parity', since examining the quality at the level of the document rather than at the sentence level allows for the assessment of suprasentential context, providing a more reliable evaluation.  Kertas ini mempersembahkan corpus tingkat dokumen yang dicatat dalam bahasa Inggris dengan masalah-masalah yang menyadari konteks yang muncul ketika menerjemahkan dari bahasa Inggris ke bahasa Portugis Brazil, yaitu elipsis, gender, ambiguity lexical, number, reference, and terminology, with six different domains. Korpus dapat digunakan sebagai tes tantangan set untuk evaluasi dan sebagai korpus latihan/tes untuk MT serta untuk analisis bahasa dalam masalah konteks. Menurut pengetahuan kita, ini adalah corpus pertama dari jenisnya.", 'ko': "최근 기계번역(MT)계는 문서급 평가에 점점 흥미를 느끼고 있다. 특히'인간 대등'주장에 대한 반응을 감안하면 문서급이 아닌 문장급 검사의 질이 초문장 상하문을 평가해 더욱 믿을 만한 평가를 제공할 수 있기 때문이다.본고는 영어로 표시된 문서급 자료 라이브러리를 소개했는데 영어를 브라질 포르투갈어로 번역할 때 언어 감지 문제, 즉 생략, 성별, 어휘의 잘못된 의미, 숫자, 인용과 용어가 6개의 서로 다른 분야와 관련된다.이 자료 라이브러리는 평가의 도전 테스트 집합으로 할 수도 있고 기계 번역의 훈련/테스트 자료 라이브러리로 할 수도 있으며 언어 환경 문제에 대해 깊이 있는 언어 분석을 할 수도 있다.우리가 아는 바에 의하면, 이것은 첫 번째 이런 종류의 어료 라이브러리이다.", 'de': 'In letzter Zeit hat sich die Gemeinschaft der maschinellen Übersetzung (MT) mehr für die Bewertung auf Dokumentenebene interessiert, insbesondere angesichts der Reaktionen auf Behauptungen der "menschlichen Parität", da die Prüfung der Qualität auf Dokumentenebene und nicht auf Satzebene die Beurteilung des suprasentiellen Kontextes ermöglicht und eine zuverlässigere Bewertung ermöglicht. Dieser Beitrag stellt einen Korpus auf Dokumentenebene vor, der auf Englisch annotiert wird, mit kontextbewussten Fragen, die bei der Übersetzung aus dem Englischen ins Brasilianische Portugiesische auftreten, nämlich Ellipse, Geschlecht, lexikalische Ambiguität, Zahl, Referenz und Terminologie, mit sechs verschiedenen Domänen. Das Korpus kann als Challenge Test Set zur Evaluation und als Trainings-/Testkorpus für MT sowie zur tiefgehenden linguistischen Analyse von Kontextfragen verwendet werden. Nach bestem Wissen ist dies der erste Korpus seiner Art.', 'tr': "Soňky wagtlar, Maşynyň terjime (MT) jemgyýeti sened derejesi deňlemekde has gowy gyzyklanýar, ýöne 'adamlaryň parity' diýip jogaplarynyň üstünde hasaplamagyna gözleýän netijesi bolup, sözlemekde derejesinden boýunça hasaplamaga mümkin edýär. Bu kagyz Iňlislerden Braziliýa portugalça terjime edilýän wagtlar bilen iňlisçe görnüş hasaplanýan hasaplanyň derejesi bilen gürleýän bir korpusy görkezýär. Korpus deňlemek üçin kynçylyk synagy we MT üçin bilim/synagy çykarmak üçin we daňky lingwistiki kontekst meseleleriniň derjesi üçin ullanylabilir. Bilgimiziň iň gowy bolsa, bu özüniň ilkinji korpusy.", 'sw': 'Hivi karibuni, jumuiya ya Tafsiri ya Mashine (MT) imekuwa yenye hamasa zaidi ya kutathmini kiwango cha nyaraka has a kufuatia miitikio ya madai ya ‘bunge la binadamu’, kwa kuwa kuchunguza kiwango cha nyaraka badala ya kiwango cha hukumu kinaruhusu kutathmini muktadha wa kujitenga, na kutoa uchunguzi wa kuaminika zaidi. Gazeti hili linaleta makampuni yenye kiwango cha dokumentari yanayochapishwa kwa lugha ya Kiingereza na masuala yanayofahamika yanapotokea pale kutafsiri kutoka Kiingereza kwenda Kireno, kama maelezo ya jinsia, uchochezi wa kimapenzi, namba, maoni, na utambulisho wa kimapenzi, na majumbani sita tofauti. Kampuni hiyo inaweza kutumika kama jaribio la changamoto la kutathmini na kama makampuni ya mafunzo/jaribio kwa ajili ya MT pamoja na uchambuzi wa lugha za kina katika masuala ya muktadha. Kwa ufahamu mzuri, hii ni makampuni ya kwanza ya aina yake.', 'da': 'For nylig er maskinoversættelsessamfundet (MT) blevet mere interesseret i evaluering på dokumentniveau, især i lyset af reaktioner på påstande om "menneskelig lighed", da undersøgelse af kvaliteten på dokumentet snarere end på sætningsniveau giver mulighed for vurdering af overfølsom kontekst, hvilket giver en mere pålidelig evaluering. Denne artikel præsenterer et dokumentniveau korpus kommenteret på engelsk med kontekstbevidste problemer, der opstår ved oversættelse fra engelsk til brasiliansk portugisisk, nemlig ellipsis, køn, leksiksk tvetydighed, tal, reference og terminologi, med seks forskellige domæner. Korpusset kan bruges som udfordringstest til evaluering og som trænings-/testkorpus for MT samt til dyb sproglig analyse af kontekstspørgsmål. Så vidt vi ved, er dette det første korpus af sin art.', 'am': 'በቅርብ ዘመን የመኪን ትርጉም (MT) ማኅበረሰብ ለሰነድ-ደረጃ ማረጋገጫ ይልቁንም የሰው ፓርቲ ጥያቄን በመጠየቅ የተጠቃሚ ነው፡፡ ከክፍሉ ደረጃው ይልቅ ክፍል ደረጃውን ከመጠየቅ የተጠቃሚ ክፍተት ማረጋገጫ ይችላል፡፡ ይህ ሕገጽ በተለየ እንግሊዘኛ ወደ ፖርቱጋሊስ፣ የዝሙት፣ የግንኙነት፣ ቁጥር፣ መልዕክት እና ተርሚሎጂ፣ ስድስት የተለየ ውይይት፣ የፖርቲካዊ ፖርቱጋሊስ በመግለጽ በተደረገው በንግግሊዝኛ ውስጥ የሚታወቀውን የሰነድ ቁጥር-ደረጃ ኮርፓስ ያቀርባል፡፡ የኮርፓስ ድምፅ ለማስተዋል እና ለMT ማስተማር/ፈተና ቆርፓስ እና ለጥልቅ ቋንቋዊ ቋንቋዊ ጉዳዮች መፍትር እንዲሆን ይቻላል፡፡ እውቀታችን በሚሻለው ይህ የዓይነቱ ፊተኛይቱ ኮቴ ነው።', 'hy': 'Վերջերս, մեքենայի թարգմանման (MT) համայնքը ավելի շատ հետաքրքրվել է փաստաթղթի մակարդակի գնահատականներով, հատկապես մարդկային հավասարության փաստարկների արձագանքների հետ, քանի որ փաստաթղթի մակարդակի որակի ուսումնասիրելը, քան նախադասության մակարդակի վրա, հնարավորություն է տալիս գերպատենցի Այս աշխատանքը ներկայացնում է մի փաստաթղթի մակարդակի կորպուս, որը անգլերենում գրված է կոնտեքստի գիտակցական հարցերով, որոնք առաջանում են անգլերենից թարգմանելու դեպի բրազիլիական պորտուգալերեն, հատկապես էլիպսիա, գենդերս, լեքսիկական անորոշակիություն, թվեր Կորպուսը կարող է օգտագործվել որպես մարտահրավերի փորձարկում գնահատելու համար, ինչպես նաև որպես մարտահրավեր MT-ի համար, ինչպես նաև կոնտեքստի խնդիրների խորը լեզվաբանական վերլուծության համար: Ինչ գիտենք, սա իր տեսակի առաջին մարմինն է:', 'az': 'Son zamanlarda, Makin Çevirməsi (MT) toplumunun "insan parity" iddialarının reaksiyonların ışığına görə, sözlərin seviyyətindən əvvəl məlumatın qiymətini təsdiqləməsinə imkan verir və daha güvenilir değerlendirməsini təsdiqləyir. Bu kağıt, İngilizdən Braziliyalı Portugalca çevirirken İngilizce dilində təşkil edilən məsələlər ilə İngilizce dilində təşkil edilən bir dəstə korpusu göstərir, ki, altı müxtəlif domena ilə ellipsis, cins, leksik ambiguity, sayı, referans və terminoloji olar. Korpus değerlənmək üçün çətin sınaması və MT üçün təhsil/sınama korpusu kimi və məlumatların derin dil analizi üçün istifadə edilə bilər. Bizim elmimizin ən yaxşısına görə, bu onun ilk körpüsüdür.', 'fa': 'اخیراً جامعه ترجمه ماشین (MT) به ارزیابی سطح سند بیشتری علاقه\u200cمند شده، مخصوصاً در نور واکنش\u200cهای واکنش\u200cها به ادعا „پاریت انسان”، از آنجا که تحقیق کیفیت سطح سند به جای سطح جمله به ارزیابی محتوای بیشتری اجازه می\u200cدهد، و ارزیابی قابل اعتماد بیشتری این کاغذ یک قالب سطح سند را در انگلیسی نشان می دهد که در حالی که از انگلیسی به پورتوژیک برزیلی ترجمه می شود، به عنوان الیپسیس، جنس، غیرقابل زبان، شماره، ارتباط، و ترمینالوژی با شش دامنه متفاوت می شود. کورپوس می تواند به عنوان آزمایش چالش برای ارزیابی استفاده شود و به عنوان کورپوس آموزش/آزمایش برای MT و برای تحلیل زبانی عمیق مسائل محیط استفاده شود. برای بهترین دانش ما این اولین جسد از نوع خودش است.', 'bs': 'Nedavno, zajednica za prevod mašine (MT) postala je više zainteresovana za procjenu nivoa dokumenta, posebno u svjetlu reakcija na tvrdnje "ljudskog pariteta", pošto je pregledala kvalitet na nivou dokumenta umjesto na nivou rečenice omogućava procjenu suprasentativnog konteksta, pružajući pouzdaniju procjenu. Ovaj papir predstavlja korpus na nivou dokumenta annotiran na engleskom jeziku s pitanjima sa kontekstskim svjesnim pitanjima koji se pojavljuju kada se prevodi iz Engleskog na Brazilski portugalski, a to je ellipsis, spol, leksička ambiguitet, broj, referencija i terminologija, sa šest različitih domena. Korpus se može koristiti kao test izazova koji je postavljen za procjenu i kao korpus obuke/testiranja MT-a, kao i za duboku jezičku analizu kontekstskih problema. Za najbolje od našeg znanja, ovo je prvi korpus njegove vrste.', 'ca': 'Recentment, la comunitat de traducció màquina (MT) s\'ha tornat més interessata en l\'evaluació a nivell de documents, especialment a la llum de les reaccions a les afirmacions de "paritat humana", ja que l\'examen de la qualitat a nivell del document en comptes de la frase permet l\'evaluació del context suprasentencial, proporcionant una evaluació més fiable. Aquest paper presenta un corpus de nivell documental anotat en anglès amb problemes conscients del contexte que surten quan es traduis d\'anglès a portuguès brasiler, a saber, elipsi, gènere, ambigüitat lexical, nombre, referència i terminologia, amb sis dominis diferents. El corpus pot ser utilitzat com un conjunt de provas de repte per a l\'evaluació i com un corpus de formació/prova per a MT i per a l\'anàlisi lingüística profunda de problemes contextuals. To the best of our knowledge, this is the first corpus of its kind.', 'cs': 'V poslední době se komunita strojového překladu (MT) začala více zajímat o hodnocení na úrovni dokumentů zejména s ohledem na reakce na tvrzení "lidské parity", neboť zkoumání kvality na úrovni dokumentu spíše než na úrovni věty umožňuje posouzení nadsencionálního kontextu, což poskytuje spolehlivější hodnocení. Tento článek představuje korpus na úrovni dokumentů anotovaný v angličtině s kontextovými problémy, které vznikají při překladu z angličtiny do brazilského portugalštiny, konkrétně elipsis, gender, lexikální nejednoznačnost, číslo, reference a terminologie, se šesti různými doménami. Korpus může být využit jako výzva testovací sada pro hodnocení a jako tréninkový/testovací korpus pro MT, stejně jako pro hlubokou lingvistickou analýzu kontextových problémů. Podle našeho nejlepšího vědomí se jedná o první korpus svého druhu.', 'af': "Onlangs het die Masjien Vertaling (MT) gemeenskap meer geinteresseer in dokumentvlak evaluering, veral in die lig van reaksies na aansoek van 'menslike pariteit', omdat die kwaliteit op die vlak van die dokument ondersoek is, eerder as op die setvlak toelaat vir die evaluering van suprasentensie konteks, verskaf 'n meer betroubare evaluering. Hierdie papier stel 'n dokumentvlak korpus aangeteken in Engels met konteks-bevestig probleme wat opstaan wanneer van Engels na Braziliese Portugees vertaling word, bedoel ellipsies, geneem, leksiese ambiguiteit, nommer, verwysing en terminologie, met ses verskillende domene. Die korpus kan gebruik word as 'n uitdagingstoets stel vir evaluering en as 'n onderwerp/toets korpus vir MT en ook vir diep lingwisiese analisie van konteks probleme. Dit is die eerste korpus van sy soort.", 'fi': 'Viime aikoina konekäännösyhteisö on kiinnostunut enemmän asiakirjatason arvioinnista erityisesti, kun otetaan huomioon reaktiot väittämiin "ihmispariteetti", koska laadun tarkastelu asiakirjan tasolla pikemminkin kuin lausetasolla mahdollistaa ylikansallisen kontekstin arvioinnin, mikä tarjoaa luotettavamman arvioinnin. Tässä artikkelissa esitellään englanninkielinen dokumenttitason korpus, jossa on kontekstitietoisia kysymyksiä, joita syntyy käännettäessä englannista brasilialaiseen portugaliin, eli ellipsit, sukupuoli, sanaston epäselvyys, luku, viittaus ja terminologia, kuudella eri alalla. Korpusta voidaan käyttää arviointiin liittyvänä haasteena ja MT:n koulutus-/testauskorpusena sekä kontekstiakysymysten syvälliseen kielelliseen analyysiin. Tietojemme mukaan tämä on ensimmäinen laatuaan.', 'sq': "Kohët e fundit, komuniteti i përkthimit të makinave (MT) është bërë më i interesuar në vlerësimin e nivelit të dokumentit veçanërisht në dritën e reagimeve ndaj pretendimeve të 'paritetit njerëzor', pasi shqyrtimi i cilësisë në nivelin e dokumentit sesa në nivelin e dënimeve lejon vlerësimin e kontekstit suprasentencial, duke ofruar një vlerësim më të besueshëm. Ky artikull paraqet një korpus në nivel të dokumentit të anotuar në anglisht me çështje të ndërgjegjëshme në kontekst që ngrihen kur përkthyen nga anglisht në portugalisht brasilez, veçanërisht elipsi, gjin, dyshimi lexik, numër, referim dhe terminologji, me gjashtë fusha të ndryshme. Korpus mund të përdoret si një test sfide për vlerësimin dhe si një korpus trajnimi/testimi për MT si dhe për analizën gjuhësore të thellë të çështjeve konteksti. To the best of our knowledge, this is the first corpus of its kind.", 'bn': 'সম্প্রতি মেশিন অনুবাদ (এমটি) সম্প্রদায়ের মাধ্যমে নথিপত্র-স্তর পর্যালোচনার বিশেষ করে বিশেষ করে মানব সংসদের দাবীর প্রতিক্রিয়ার প্রতিক্রিয়া হিসেবে বেশী আগ্রহী হয়েছে, যেহেতু এই নথির মানে এই পত্রিকাটি ইংরেজি ভাষায় একটি নথিভুক্ত স্তরের কোর্পাস উপস্থাপন করেছে যা ব্রাজিলীয় পর্তুগীজ থেকে ইংরেজি ভাষায় অনুবাদ করা হয়েছে, যেখানে ছয় ভিন্ন ভিন্ন ডোমেনের সা এমটির জন্য প্রশিক্ষণ/পরীক্ষার প্রশিক্ষণ/পরীক্ষা কর্পাস হিসেবে এই কোর্পাস ব্যবহার করা যাবে এবং প্রেক্ষিত বিষয়ের গভীর ভাষায় বিশ্লে আমাদের জ্ঞানের সবচেয়ে ভালোর জন্য, এটাই তার প্রথম কোর্পাস।', 'et': 'Hiljuti on masintõlke kogukond muutunud rohkem huvitatuks dokumentide tasandil hindamisest, eriti arvestades reaktsioone "inimese pariteetsuse" väidetele, sest kvaliteedi uurimine dokumendi tasandil, mitte lause tasandil, võimaldab hinnata tundiülest konteksti, pakkudes usaldusväärsemat hindamist. Käesolevas töös esitatakse dokumenditasemel korpus, mis on inglise keeles annoteeritud kontekstiteadlike küsimustega, mis tekivad inglise keelest brasiilia portugali keelde tõlkimisel, nimelt ellipsis, sugu, leksikaalne ebaselgus, arv, viide ja terminoloogia, kuue erineva valdkonnaga. Korpust saab kasutada hindamise väljakutsetesti komplektina ja MT koolitus-/testikorpusena ning kontekstiküsimuste sügavaks keeleliseks analüüsiks. Meie teadmiste kohaselt on see esimene korpus sellist laadi.', 'jv': 'Deweke kudu, komunitas Manus Trabagun Perintah iki nambah karo bodho sing dadi nglanggar kelas telas nang Inggris karo sekondirno langkung sing gagal bantuan karo inglisan kang portugis Bracilian, nambah kelas, lahir, sampeyan, akeh langkung, nambah, ingkang, lan terminal sing mengko sampeyan. Ceng-shaped iki dianggap iso nggambar deweke seneng pisan kawit ujian kanggo nggawe luwih apik lan ngangge cara-ujian kanggo MT ngono nggawe nguasakno dumadhi kanggo dianglusisi diangresmi. Panjenengan langkung apik dhéwé, iki sakjane tualke perbudhakan kenal dhéwé.', 'he': 'לאחרונה, קהילת התרגום המכונית (MT) התעניינה יותר בערכת הערכה ברמה המסמכים במיוחד לאור תגובות לטענות של "שוויון אנושי", מאחר שבדיקת איכות ברמה המסמכים במקום ברמת המשפט מאפשרת לערכת הקשר על גבול משפט, ומספקת עריכה אמינה יותר. העבודה הזו מציגה קופוס רמה מסמכים שנמצא באנגלית עם בעיות מודעות לקונקסט שמגיעות כשמתרגמות מאנגלית לפורטוגזית ברזילית, כלומר אליפסה, מין, סביבות לקסיקה, מספר, התייחסות, וטרמינולוגיה, עם שש שדות שונים. הקורפוס יכול להשתמש בתור מבחן אתגר קבוע עבור הערכה וכגופוס אימון/מבחן עבור MT כמו גם עבור ניתוח שפתי עמוק של בעיות הקשר. למיטב הידע שלנו, זה הקורפוס הראשון של סוג זה.', 'sk': 'V zadnjem času je skupnost strojnega prevajanja postala bolj zainteresirana za ocenjevanje na ravni dokumentov, zlasti glede na odzive na trditve "človeške enakosti", saj preučevanje kakovosti na ravni dokumenta in ne na ravni stavka omogoča ocenjevanje nadkonteksta, kar zagotavlja zanesljivejšo oceno. V prispevku je predstavljen korpus na ravni dokumenta, označen v angleščini, z vprašanji, ki se pojavljajo pri prevajanju iz angleščine v brazilsko portugalščino, in sicer elipse, spol, leksikalna dvoumnost, število, referenca in terminologija, s šestimi različnimi področji. Korpus se lahko uporablja kot komplet izzivov za ocenjevanje in kot korpus usposabljanja/testiranja za MT ter za poglobljeno jezikovno analizo kontekstnih vprašanj. Kolikor vemo, je to prvi korpus te vrste.', 'ha': "A yanzu, jumuin Tafsiri na Mashine (MT) ya kasance mafi na son mafiya amfani da tunkuɗe takardar-daraja, haske da maras da ake yi wa kirãyi na'urar mutum), saboda an jarraba tsarin a daraja ga dukkan takardar, kuma don a sami muhimmin da ake yi wa muhimmin muhimmada, yana yarda ya yi ƙaddara yana da ƙaranci mai gaskatãwa. Wannan karatun na bãyar da wata takardar-leveli da aka yi taƙaita cikin Ingiriya da masu muhimmada da aka sani su zo idan za'a tarjima daga Ingiriya zuwa Portugal, kamar elipti, jini, ambiguity, namar, Reference, da taƙaitori, da sakan daban sita. Ana iya amfani da nauyi kamar jarrabo ta kanana ta ƙayyade dõmin ka yi evaluci, kuma kamar wata shirin mai tsaro/jarraba nau'in MT, da kuma dõmin anarari cikin linguistic da masu muhimmanci. Kuma wannan ne mafi alheri ga ilmi.", 'bo': 'མ་ཟད། རྩིས་འཁོར་གཞུང་གི་ཚོགས་སྤྱི་ཚོགས་དེ་ཡིག་ཆའི་གནས་སྟངས་ལ་བསམ་བློ་གཏོང This paper presents a document-level corpus annotated in English with context-aware issues that arise when translating from English to Brazilian Portuguese, namely ellipsis, gender, lexical ambiguity, number, reference, and terminology, with six different domains. The corpus can be used as a challenge test set for evaluation and as a training/testing corpus for MT as well as for deep linguistic analysis of context issues. ང་ཚོའི་ཤེས་ཚད་གང་འདྲ་ཡིན་པ་ལས་ཕལ་ཆེར་ཤོས་ཀྱི་ཆེད་མཁན་རེད།'}
{'en': 'Improving ', 'ar': 'تحسين الترجمة الآلية لحواس الكلمات النادرة وغير المرئية', 'fr': 'Améliorer la traduction automatique des sens des mots rares et invisibles', 'es': 'Mejora de la traducción automática de sentidos de palabras poco comunes e invisibles', 'pt': 'Melhorando a tradução automática de sentidos de palavras raras e invisíveis', 'ja': '希少で見えない言葉の感覚の機械翻訳の改善', 'zh': '改进罕见及不见之词义机器翻译', 'hi': 'दुर्लभ और अनदेखी शब्द इंद्रियों के मशीन अनुवाद में सुधार', 'ru': 'Улучшение машинного перевода редких и невидимых слов', 'ga': 'Feabhas a chur ar Aistriú Meaisín ar Chéadtaí Focal Neamhchoitianta agus Neamhfheicthe', 'ka': 'Name', 'hu': 'Ritka és láthatatlan szóérzékek gépi fordításának javítása', 'el': 'Βελτίωση της μηχανικής μετάφρασης σπάνιων και αόρατων αισθήσεων λέξεων', 'it': 'Miglioramento della traduzione automatica dei sensi delle parole rare e invisibili', 'kk': 'Қызық және көрмеген сөздердің аудармасын жақсарту', 'mk': 'Подобрување на машинскиот превод на ретки и непознати зборови', 'lt': 'Retų ir nematomų žodžių jutimų vertimo mašinomis gerinimas', 'ms': 'Perbaikan Terjemahan Mesin Sensa Perkataan Langka dan Tidak Dilihat', 'ml': 'മഴയും അദൃശ്യമായ വാക്കുകളുടെ അഭിപ്രായം മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നു', 'mt': 'Improving Machine Translation of Rare and Unseen Word Senses', 'mn': 'Хэдэн ховор болон харагдахгүй үг мэдрэмжүүдийн машины орчуулалтыг сайжруулах', 'no': 'Forbetra maskinsomsetjing av råd og ukjend ordfølelser', 'pl': 'Poprawa tłumaczenia maszynowego rzadkich i niewidocznych zmysłów słowa', 'ro': 'Îmbunătățirea traducerii automate a simțurilor cuvintelor rare și nevăzute', 'sr': 'Poboljšanje prevoda rijetkih i nevidljivih osjeæaja reèi', 'si': 'ප්\u200dරශ්ණය සහ නොදකින්න වචන වර්තනය සඳහා මැෂින් පරිවර්තනය වැඩ කරන්න', 'so': 'Improving machine Translation of Rare and hidden Word Senses', 'sv': 'Förbättra maskinöversättning av sällsynta och osynliga ordsinnen', 'ta': 'Name', 'ur': 'غریب اور غیر دیکھی کلمات سنسوں کا ماشین ترجمہ بہتر کرتا ہے', 'uz': 'Improving Machine Translation of Rare and Unseen Word Senses', 'vi': 'Sửa máy Dịch các cảm xúc chữ hiếm và không rõ ràng', 'bg': 'Подобряване на машинния превод на редки и невидими усещания за думи', 'da': 'Forbedring af maskinoversættelse af sjældne og usynlige ordsanser', 'hr': 'Poboljšavanje prevoda rijetkih i nevidljivih osjećaja rijetkih riječi', 'nl': 'Verbetering van machinevertaling van zeldzame en onzichtbare woordzinnen', 'fa': 'افزایش ترجمه ماشین احساسات کلمه نادیده و نادیده', 'id': 'Menembangkan Penerjemahan Mesin Senses Kata Langka dan Tak Terlihat', 'de': 'Verbesserung der maschinellen Übersetzung von seltenen und unsichtbaren Wortsinnen', 'ko': '희귀하고 보이지 않는 단어의 뜻을 개선하는 기계 번역', 'tr': 'Maşynyň yada görmedik sözleriň terjimesini gowylaşdyr', 'af': 'Verbeter Masjien Vertaling van Nuts en Onsien Woord Senses', 'sw': 'Kuboresha Tafsiri ya Mashiniki ya Mafuriko na Neno isiyofichikana', 'sq': 'Përmirësimi i përkthimit të fjalëve të rralla dhe të padukshme nga makina', 'am': 'ምርጫዎች', 'hy': 'Հազվադեպ և անտեսանելի բառերի զգացմունքների մեքենային թարգմանման բարելավումը', 'az': 'Əksiz və görmədən Sözlər Sensiyalarının Makinelərin Tercüməsini yaxşılaşdırma', 'bn': 'বৃষ্টি এবং অদৃশ্য শব্দের অনুবাদ প্রদর্শনের মেশিন', 'ca': 'millorar la traducció màquina dels sentits de paraules rares i invisibles', 'et': 'Haruldaste ja nähtamatute sõnade masintõlke parandamine', 'bs': 'Poboljšanje prevoda rijetkih i nevidljivih osjećaja rijetkih riječi', 'cs': 'Zlepšení strojového překladu vzácných a neviditelných slovních smyslů', 'fi': 'Harvinaisten ja näkymättömien sanaaistien konekääntämisen parantaminen', 'jv': 'Ngubah Ingkang Manculin Terjamahan sak Asem karo Kegambar Seneng Gak Dikenal', 'sk': 'Izboljšanje strojnega prevajanja redkih in nevidnih besednih čutov', 'ha': 'KCharselect unicode block name', 'he': 'Improving Machine Translation of Rare and Unseen Word Senses', 'bo': 'རླབས་པ་དང་མི་ཤེས་པའི་ཡིག་ཆ་ཚོར་ལ་འགྱུར་བ་དུ་གཏོང་དགོས་པ'}
{'en': 'The performance of NMT systems has improved drastically in the past few years but the translation of multi-sense words still poses a challenge. Since word senses are not represented uniformly in the ', 'ar': 'تحسن أداء أنظمة NMT بشكل كبير في السنوات القليلة الماضية ولكن ترجمة الكلمات متعددة المعاني لا تزال تشكل تحديًا. نظرًا لأن حواس الكلمات لا يتم تمثيلها بشكل موحد في المجموعات الموازية المستخدمة للتدريب ، فهناك استخدام مفرط للمعنى الأكثر شيوعًا في إخراج الترجمة الآلية. في هذا العمل ، نقترح CmBT (الترجمة الخلفية الملغومة بالسياق) ، وهي طريقة لتحسين ترجمة الكلمات متعددة المعاني التي تستفيد من تمثيلات الكلمات السياقية متعددة اللغات (CCWRs) المدربة مسبقًا. نظرًا لحساسيتها السياقية وبياناتها الكبيرة قبل التدريب ، يمكن لمستخدمي CCWRs بسهولة التقاط حواس الكلمات المفقودة أو النادرة جدًا في المجموعات المتوازية المستخدمة لتدريب الترجمة الآلية. على وجه التحديد ، يطبق CmBT تحريض المعجم ثنائي اللغة على CCWRs على جمل الهدف الخاصة بالمعنى من مجموعة بيانات أحادية اللغة ، ثم يقوم بترجمة هذه الجمل مرة أخرى لإنشاء مجموعة موازية زائفة كبيانات تدريب إضافية لنظام الترجمة الآلية. نحن نختبر جودة ترجمة الكلمات الغامضة في مجموعة اختبار MuCoW ، والتي تم تصميمها لاختبار فعالية توضيح معنى الكلمة في أنظمة الترجمة الآلية. نظهر أن نظامنا يعمل على تحسين ترجمة حواس الكلمات الصعبة وغير المرئية وذات التردد المنخفض.', 'fr': "Les performances des systèmes NMT se sont considérablement améliorées ces dernières années, mais la traduction de mots multisens pose toujours un défi. Étant donné que les sens des mots ne sont pas représentés uniformément dans les corpus parallèles utilisés pour l'entraînement, le sens le plus fréquent est utilisé de manière excessive dans les sorties de magnétoscopie. Dans ce travail, nous proposons CMBT (Contextually-mined Back-Translation), une approche pour améliorer la traduction de mots multi-sens en utilisant des représentations de mots contextuelles multilingues pré-entraînées (CCWR). En raison de leur sensibilité contextuelle et de leurs grandes données pré-entraînement, les CCWR peuvent facilement capturer les sens des mots absents ou très rares dans les corpus parallèles utilisés pour entraîner la TA. Plus précisément, le CMBT applique l'induction d'un lexique bilingue sur les CCWR pour extraire des phrases cibles spécifiques à un sens à partir d'un ensemble de données monolingue, puis traduit ces phrases pour générer un corpus pseudo-parallèle en tant que données d'apprentissage supplémentaires pour un système de TA. Nous testons la qualité de traduction de mots ambigus sur la suite de tests MuCow, qui a été conçue pour tester l'efficacité de la désambiguïsation du sens des mots des systèmes de TA. Nous montrons que notre système améliore la traduction des sens de mots difficiles, invisibles et à basse fréquence.", 'pt': 'O desempenho dos sistemas NMT melhorou drasticamente nos últimos anos, mas a tradução de palavras multi-sentido ainda representa um desafio. Como os sentidos das palavras não são representados uniformemente nos corpora paralelos usados para treinamento, há um uso excessivo do sentido mais frequente na saída da TA. Neste trabalho, propomos o CmBT (Contextually-mined Back-Translation), uma abordagem para melhorar a tradução de palavras multi-senso utilizando representações de palavras contextuais cruzadas pré-treinadas (CCWRs). Devido à sua sensibilidade contextual e seus grandes dados de pré-treinamento, os CCWRs podem capturar facilmente sentidos de palavras que estão faltando ou muito raros em corpora paralelos usados para treinar MT. Especificamente, o CmBT aplica indução de léxico bilíngue em CCWRs para extrair sentenças-alvo específicas de sentido de um conjunto de dados monolíngue e, em seguida, traduz essas sentenças para gerar um corpus pseudo paralelo como dados de treinamento adicionais para um sistema de MT. Testamos a qualidade da tradução de palavras ambíguas no conjunto de testes MuCoW, que foi construído para testar a eficácia da desambiguação do sentido da palavra dos sistemas de TA. Mostramos que nosso sistema melhora a tradução de sentidos de palavras difíceis, invisíveis e de baixa frequência.', 'es': 'El rendimiento de los sistemas de NMT ha mejorado drásticamente en los últimos años, pero la traducción de palabras multisentido sigue planteando un desafío. Dado que los sentidos de las palabras no están representados de manera uniforme en los cuerpos paralelos utilizados para el entrenamiento, hay un uso excesivo del sentido más frecuente en la producción de MT. En este trabajo, proponemos CMBT (Traducción inversa basada en el contexto), un enfoque para mejorar la traducción de palabras multisentido aprovechando las representaciones de palabras contextuales multilingües (CCWR) preentrenadas. Debido a su sensibilidad contextual y a su gran cantidad de datos previos al entrenamiento, los CCWR pueden capturar fácilmente los sentidos de las palabras que faltan o son muy raros en los cuerpos paralelos utilizados para entrenar a MT. Específicamente, CMBT aplica la inducción de léxico bilingüe en los CCWR para extraer oraciones objetivo de sentido específico de un conjunto de datos monolingüe, y luego retrotraduce estas oraciones para generar un corpus pseudo paralelo como datos de entrenamiento adicionales para un sistema de MT. Probamos la calidad de la traducción de palabras ambiguas en el conjunto de pruebas MuCow, que se creó para probar la eficacia de la desambiguación del sentido de las palabras de los sistemas de traducción automática. Demostramos que nuestro sistema mejora la traducción de sentidos de palabras difíciles invisibles y de baja frecuencia.', 'ja': 'NMTシステムのパフォーマンスはここ数年で大幅に向上しましたが、多義的な単語の翻訳は依然として課題となっています。 トレーニングに使用される並列体では、単語の感覚が一様に表現されないため、MT出力では最も頻繁な感覚が過度に使用されます。 この研究では、事前に訓練されたクロスリンガルコンテキスト単語表現（ CCWR ）を活用して、マルチセンスの単語翻訳を改善するためのアプローチであるCmBT （ Contextically - mineed Back - Translation ）を提案します。 CCWRは、そのコンテキスト感度と大規模な事前トレーニングデータのため、MTのトレーニングに使用される並列体では欠落している、または非常に稀な単語感覚を簡単にキャプチャできます。 具体的には、ＣｍＢＴは、ＣＣＷＲにバイリンガル辞書誘導を適用して、単一言語のデータセットからセンス固有の標的文を採掘し、次いでこれらの文を逆翻訳して、ＭＴシステムの追加の訓練データとして擬似並列コーパスを生成する。 MuCoWテストスイートの曖昧な単語の翻訳品質をテストします。これは、MTシステムの単語センスの曖昧さ解消効果をテストするために構築されました。 私たちのシステムは、見えにくい単語と低頻度の単語の感覚の翻訳を改善することを示しています。', 'hi': 'पिछले कुछ वर्षों में एनएमटी प्रणालियों के प्रदर्शन में काफी सुधार हुआ है, लेकिन बहु-अर्थ शब्दों का अनुवाद अभी भी एक चुनौती है। चूंकि प्रशिक्षण के लिए उपयोग किए जाने वाले समानांतर कॉर्पोरेट में शब्द इंद्रियों को समान रूप से प्रतिनिधित्व नहीं किया जाता है, इसलिए एमटी आउटपुट में सबसे अधिक बार अर्थ का अत्यधिक उपयोग होता है। इस काम में, हम CmBT (प्रासंगिक रूप से खनन बैक-ट्रांसलेशन) का प्रस्ताव करते हैं, जो कि पूर्व-प्रशिक्षित क्रॉस-लिंगुअल प्रासंगिक शब्द प्रतिनिधित्व (CCWRs) का लाभ उठाने वाले बहु-अर्थ शब्द अनुवाद में सुधार के लिए एक दृष्टिकोण है। उनकी प्रासंगिक संवेदनशीलता और उनके बड़े पूर्व-प्रशिक्षण डेटा के कारण, CCWRs आसानी से उन शब्द इंद्रियों को कैप्चर कर सकते हैं जो MT को प्रशिक्षित करने के लिए उपयोग किए जाने वाले समानांतर कॉर्पोरेट में गायब या बहुत दुर्लभ हैं। विशेष रूप से, CmBT एक मोनोलिंगुअल डेटासेट से अर्थ-विशिष्ट लक्ष्य वाक्यों को मेरा करने के लिए CCWRs पर द्विभाषी शब्दकोश प्रेरण लागू करता है, और फिर एक एमटी सिस्टम के लिए अतिरिक्त प्रशिक्षण डेटा के रूप में एक छद्म समानांतर कॉर्पस उत्पन्न करने के लिए इन वाक्यों का अनुवाद करता है। हम MuCoW परीक्षण सूट पर अस्पष्ट शब्दों की अनुवाद गुणवत्ता का परीक्षण करते हैं, जिसे एमटी सिस्टम की शब्द भावना बहुविकल्पीय प्रभावशीलता का परीक्षण करने के लिए बनाया गया था। हम दिखाते हैं कि हमारी प्रणाली कठिन अनदेखी और कम आवृत्ति शब्द इंद्रियों के अनुवाद पर सुधार करती है।', 'ru': 'За последние несколько лет производительность систем НМТ резко улучшилась, но перевод многосмысловых слов по-прежнему представляет собой проблему. Поскольку смыслы слов не представлены единообразно в параллельных телах, используемых для обучения, наблюдается чрезмерное использование наиболее частого смысла в выходе МП. В этой работе мы предлагаем CmBT (Contextually-mined Back-Translation) - подход к совершенствованию мультисмыслового перевода слов с использованием предварительно обученных кросс-лингвистических контекстных словопредставлений (CCWR). В силу своей контекстуальной чувствительности и своих больших предварительных данных, КНОР могут легко улавливать слова, которые отсутствуют или очень редко встречаются в параллельных корпусах, используемых для обучения МП. В частности, CmBT применяет двуязычную лексиконную индукцию на CCWR к целевым предложениям по минному смыслу из одноязычного набора данных, а затем переводит эти предложения назад, чтобы генерировать псевдопараллельный корпус в качестве дополнительных тренировочных данных для системы МП. Мы тестируем качество перевода неоднозначных слов в тестовом наборе MuCoW, который был создан для тестирования эффективности дезагрегирования смысла слова в системах MT. Мы показываем, что наша система улучшается при переводе сложных невидимых и низкочастотных слов.', 'zh': '往数年中,NMT统性颇重,而多义词译犹挑战。 词义不一于训练并行语料库,故机器翻译输过度用常见之义。 于是发CmBT(上下文掘反译),此乘豫练之跨言上下文单词示(CCCR)以改进多义单词译之道也。 其上下文敏感性、预练数据,CCWR可轻获以练机器翻译并行语料库阙失、奇词义.具体来说,CmBT于CCWR上用双语词典归,从单语数聚掘特定于感官之句,然后回译此句以成伪并行语料库为机器翻译统者附练之。 试于 MuCoW 套件试模棱两可单词译质,当套件旨于测试机器翻译系统之词义消歧义有效性。 明系统改进难见、低频词义译。', 'ga': 'Tá feabhas mór tagtha ar fheidhmíocht na gcóras NMT le blianta beaga anuas ach is dúshlán fós é aistriúchán ar fhocail ilchiallmhara. Ós rud é nach léirítear go haonfhoirmeach céadfaí na bhfocal sa chorpas comhthreomhar a úsáidtear don oiliúint, baintear úsáid iomarcach as an gciall is minicí in aschur MT. San obair seo, molaimid CmBT (Cúl-Aistriúchán atá bunaithe ar an gComhthéacs), cur chuige chun aistriúchán focal ilchiallaithe a fheabhsú trí úsáid a bhaint as léiriúcháin focal comhthéacsúla tras-teangacha réamhoilte (CCWRanna). Mar gheall ar a n-íogaireacht chomhthéacsúil agus a gcuid sonraí réamhoiliúna móra, is féidir le CCWRanna céadfaí focal atá in easnamh nó fíor-annamh a ghabháil go héasca i gcorpas comhthreomhar a úsáidtear chun MT a oiliúint. Go sonrach, cuireann CmBT ionduchtú foclóireachta dátheangach i bhfeidhm ar CCWRanna chun sprioc-abairtí a bhaineann go sonrach le ciall a bhaint as tacar sonraí aonteangacha, agus ansin déanann sé na habairtí seo a aisaistriú chun corpas comhthreomhar bréagach a ghiniúint mar shonraí oiliúna breise do chóras MT. Déanaimid tástáil ar cháilíocht aistriúcháin na bhfocal débhríoch ar an tsraith tástála MuCoW, a tógadh chun éifeachtúlacht dí-athbhrí na gcóras MT a thástáil. Léirímid go bhfeabhsaítear ár gcóras maidir le haistriúchán ar chiall focail dheacra nach bhfeictear agus ar mhinicíocht íseal.', 'ka': 'NMT სისტემების გამოყენება შემდეგ რამდენიმე წლის განმავლობაში დირაქტიკურად უფრო მეტი წლის განმავლობაში, მაგრამ მრავალური სიტყვების განმავლობა უფრო განმავლ იმიტომ, რომ სიტყვების სიტყვების სიტყვები არ იყოს სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა კოპ ამ სამუშაოში ჩვენ CmBT-ს (კონტექსტურად მინდომირებულია შეცვლელების შეცვლელების) პროგრამა მრავალური სიტყვების გასაგრძელება, რომელიც უფრო მეტი სიტყვების გასაგრძელება, რომელიც უფ მათი კონტექსტური სიგრძნობით და მათი დიდი წინატვირთვის მონაცემებისთვის, CCWRs შეუძლია ადვილად გააკვიროთ სიტყვების სიგრძნობები, რომლებიც არ არის ან ძალიან პარალელური კოპორაში, რომლებიც MT-ს გასწავლად გამოყენებული. სპექ და შემდეგ ამ სიტყვების დაბრუნდება, რომ პესეუდო პარალელი კორპუსს შექმნა, როგორც დამატებული მონაცემები MT სისტემისთვის. ჩვენ შევცვალობთ მუკოW ტესტის სუტის გადაწყვეტილი სიტყვების გადაწყვეტილება, რომელიც შექმნა MT სისტემების გადაწყვეტილების ეფექტიურობა. ჩვენ ვაჩვენებთ, რომ ჩვენი სისტემა უფრო მეტადებს ძალიან არახედნენ და ცოტა სიტყვების სიტყვების შეცვლაში.', 'el': 'Η απόδοση των συστημάτων έχει βελτιωθεί δραστικά τα τελευταία χρόνια, αλλά η μετάφραση λέξεων πολλαπλών αισθήσεων εξακολουθεί να αποτελεί πρόκληση. Δεδομένου ότι οι αισθήσεις λέξεων δεν εκπροσωπούνται ομοιόμορφα στα παράλληλα σώματα που χρησιμοποιούνται για την εκπαίδευση, υπάρχει υπερβολική χρήση της πιο συχνής έννοιας στην έξοδο ΜΤ. Σε αυτή την εργασία, προτείνουμε μια προσέγγιση για τη βελτίωση της μετάφρασης λέξεων πολλαπλών αισθήσεων χρησιμοποιώντας προ-εκπαιδευμένες διατυπώσεις λέξεων σε διαφορετικές γλώσσες. Λόγω της ευαισθησίας τους στο πλαίσιο και των μεγάλων δεδομένων προεκπαίδευσής τους, οι CCWR μπορούν εύκολα να συλλάβουν τις αισθήσεις λέξεων που λείπουν ή πολύ σπάνιες σε παράλληλα σώματα που χρησιμοποιούνται για την εκπαίδευση Συγκεκριμένα, το CmBT εφαρμόζει δίγλωσση επαγωγή λεξικού σε CCWR για την εξόρυξη συγκεκριμένων εννοιολογικών προτάσεων από ένα μονογλωσσικό σύνολο δεδομένων, και στη συνέχεια μεταφράζει πίσω αυτές τις προτάσεις για να δημιουργήσει ένα ψευδο παράλληλο σώμα ως πρόσθετα δεδομένα εκπαίδευσης για ένα σύστημα ΜΤ. Δοκιμάζουμε την ποιότητα της μετάφρασης των διφορούμενων λέξεων στη δοκιμαστική σουίτα η οποία κατασκευάστηκε για να ελέγξει την αποτελεσματικότητα της αποσαφήνισης λέξεων των συστημάτων ΜΤ. Δείχνουμε ότι το σύστημά μας βελτιώνεται στη μετάφραση δύσκολων αόρατων και χαμηλής συχνότητας λέξεων αισθήσεων.', 'hu': 'Az NMT rendszerek teljesítménye drasztikusan javult az elmúlt években, de a többérzékű szavak fordítása még mindig kihívást jelent. Mivel a szóérzékek nem jelennek meg egyenletesen az edzésre használt párhuzamos korpuszokban, az MT kimenet leggyakoribb értelmét túlzott mértékben használják. Ebben a munkában javasoljuk a CmBT (Contextually-mined Back-Translation), egy olyan megközelítést, amely a többértelmű szófordítás javítására irányul, amely az előre képzett, többnyelvű kontextuális szóreprezentációkat (CCWR) használja. Kontextuális érzékenységük és nagymértékű edzés előtti adataik miatt a CCWR-k könnyen rögzíthetik azokat a szóérzékeket, amelyek hiányznak vagy nagyon ritkák a párhuzamos corporákban, amelyeket az MT edzésére használnak. Konkrétan a CmBT kétnyelvű lexikon indukciót alkalmaz CCWR-ken, hogy érzékspecifikus célmondatokat bányásszon egy egynyelvű adatkészletből, majd visszafordítja ezeket a mondatokat, hogy egy pszeudo párhuzamos korpuszt generáljon, mint további edzési adatokat egy MT rendszer számára. A kétértelmű szavak fordítási minőségét teszteljük a MuCoW tesztcsomagon, amelyet arra építettünk, hogy teszteljük az MT rendszerek szóérzékek egyértelműsítésének hatékonyságát. Megmutatjuk, hogy rendszerünk javítja a nehéz láthatatlan és alacsony frekvenciájú szóérzékek fordítását.', 'it': "Le prestazioni dei sistemi NMT sono migliorate drasticamente negli ultimi anni, ma la traduzione di parole multi-senso rappresenta ancora una sfida. Poiché i sensi delle parole non sono rappresentati uniformemente nei corpi paralleli utilizzati per l'allenamento, c'è un uso eccessivo del senso più frequente nell'output MT. In questo lavoro, proponiamo CmBT (Contextually-mined Back-Translation), un approccio per migliorare la traduzione multi-senso delle parole sfruttando rappresentazioni contestuali cross-lingual pre-addestrate (CCWR). A causa della loro sensibilità contestuale e dei loro grandi dati pre-allenamento, i CCWR possono facilmente catturare i sensi delle parole mancanti o molto rari nei corpi paralleli utilizzati per addestrare la MT. Nello specifico, CmBT applica l'induzione lessicale bilingue sui CCWR per estrarre frasi target sensoriali specifiche da un set di dati monolingue, e poi traduce indietro queste frasi per generare uno pseudo corpus parallelo come dati di allenamento aggiuntivi per un sistema MT. Testiamo la qualità della traduzione di parole ambigue sulla suite di test MuCoW, che è stata costruita per testare l'efficacia della disambiguazione dei sensi delle parole dei sistemi MT. Mostriamo che il nostro sistema migliora la traduzione dei sensi difficili invisibili e a bassa frequenza delle parole.", 'mk': 'Преводот на НМТ системите драстично се подобри во изминатите неколку години, но преводот на мултисетивните зборови сé уште претставува предизвик. Бидејќи зборовите чувства не се претставени униформно во паралелната корпора која се користи за обука, постои прекумерна употреба на најчестото чувство во излезот на МТ. Во оваа работа, предлагаме CmBT (контекстно минуван назад-транслекција), пристап за подобрување на мултисенски превод на зборови со влијание на претренирани прејазици на текстови (CCWRs). Поради нивната контекстуална чувствителност и нивните големи податоци за предобука, CCWRs лесно можат да ги фатат зборните чувства кои недостасуваат или многу ретки во паралелни корпора кои се користат за обука на MT. Специфично, CmBT применува двојјазична индукција на лексикони на CCWRs за минирање на смислено специфични метни реченици И потоа ги преведува овие реченици за да генерира псевдо паралелен корпус како дополнителни податоци за обука за МТ систем. Ние го тестираме квалитетот на превод на двогледни зборови на тестирачкиот апартман MuCoW, кој беше изграден за тестирање на ефикасноста на раздвојувањето на зборот смисла на MT системите. Ние покажуваме дека нашиот систем се подобрува во преведувањето на тешки невидливи и ниски фреквентни зборни сензии.', 'lt': 'Per pastaruosius keletą metų NMT sistemų veiksmingumas smarkiai pagerėjo, tačiau daugiakalbių žodžių vertimas vis dar kelia sunkumų. Kadangi žodžio jutimai nėra vienodai atstovaujami lygiagrečioje korporoje, naudojamoje mokymui, MT išėjimo prasme dažniausiai naudojamas per daug. Šiame darbe siūlome CmBT (kontekste iškeltas grįžtamasis vertimas žodžiais), metodą, kuriuo siekiama pagerinti daugiakalbį vertimą žodžiais, naudojant iš anksto parengtus tarpkalbinius kontekstinius žodžių atstovavimus (CCWR). Atsižvelgiant į jų kontekstinį jautrumą ir didelius ikimokymo duomenis, CCWR gali lengvai surinkti žodžių jutimus, kurie trūksta arba labai reti lygiagrečioje korporoje, naudojamoje MT treniruoti. Konkrečiai, CmBT CCWR dvikalbį lexikono indukciją taiko tam tikro jautrumo tiksliniams sakiniams iš vienkalbių duomenų rinkinio, ir tuomet šiuos sakinius verta atgal, kad būtų sukurtas pseudolygiagretus korpus kaip papildomi MT sistemos mokymo duomenys. We test the translation quality of ambiguous words on the MuCoW test suite, which was built to test the word sense disambiguation effectiveness of MT systems.  Mes rodome, kad mūsų sistema gerina sunkių nematomų ir mažo dažnio žodžių jutimų vertimą.', 'kk': 'NMT жүйелерінің істемі өткен бірнеше жылдарда драстикалық жақсартылды, бірақ бірнеше сезімді сөздерді аудару әлі мәселе болады. Сөздердің сезімдері бірдей тәжірибе үшін қолданылатын параллель корпорада көрсетілмеген сияқты, MT шығысында ең көптеген сезімдердің қолдануы тым. Бұл жұмыс ішінде, біз CmBT (көптеген қайта аудармасын) ұсынамыз, көптеген сөздерді аудармасының көптеген көптеген көптеген мәтіндік мәтіндік мәтіндіктерді (CCWRs) түсініктемелерін жасау үшін қо Олардың контекстік сезімділігін және олардың үлкен алдын- оқыту деректерінің сезімдерінің сезімдері, MT- ді оқыту үшін жоқ немесе қарапайым корпораға қолданылатын сөздер сезімдерін оңай түсіріп алады. Әдетте, CmBT CCWRs- ге екі тілді лексикалық инду Содан кейін бұл сөйлемелерді MT жүйесінің қосымша оқыту деректері ретінде псевдо параллел корпус жасау үшін қайта аударады. Біз MuCoW сынақтарының аудармалы сөздердің сапатын тексеріп, MT жүйелерінің мәліметті өзгерту үшін құрылған. Біз жүйеміздің күшті көрсетілмеген және жиілікті сөздердің сезімдерінің аудармасын жақсартып жатқанын көрсетедік.', 'ml': 'കഴിഞ്ഞ കുറച്ചു വര്\u200dഷങ്ങളില്\u200d NMT സിസ്റ്റംകളുടെ പ്രകടനം വളരെ വികസിപ്പിച്ചിരിക്കുന്നു. പക്ഷെ പല വാക്കുകളുടെ അനുവാദങ പരിശീലനത്തിനായി ഉപയോഗിക്കുന്ന പാരാളല്\u200d കോര്\u200dപ്പോറിയില്\u200d വാക്ക് സെന്\u200dഷനുകള്\u200d ഒരുപോലെ പ്രതിനിധിയില്ലാത്തതിനാല്\u200d, എംടി  ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d CMBT (കെന്\u200dസ്റ്റെക്സ്ട്രെയിന്\u200dറ് മൈന്\u200dഡ് മൈന്\u200dഡ് ബാക്ക്- ട്രാന്\u200dസ് വാക്ക് പ്രദര്\u200dശിപ്പിക്കുന്നത്), മുന്\u200dപ് പരിശീലനം ക അവരുടെ നിലവിലുള്ള ബുദ്ധിമുന്നിലുള്ള വിവരങ്ങളും കാരണം സിസിഡവ്രിനിലുള്ള വാക്കുകള്\u200d എളുപ്പമായി പിടികൂടാന്\u200d സാധിക്കുന്നു. എംടി പരിശീലിക്കാന്\u200d ഉപയോഗിക്കുന്ന പാരാളല്\u200d കോര്\u200dപ്പോറില്\u200d കുറഞ്ഞ എന്നിട്ട് എംടി സിസ്റ്റത്തിനുള്ള കൂടുതല്\u200d ട്രെയിനിവേഷന്\u200d ഡേറ്റായി സൃഷ്ടിക്കുന്നതിനായി ഈ വാക്കുകള്\u200d പിന്നീ മുക്കോവ് ടെസ്റ്റ് സ്യൂട്ടിന്റെ വാക്കുകളുടെ അഭിപ്രായമായ വാക്കുകളുടെ ഗുണമായി ഞങ്ങള്\u200d പരീക്ഷിക്കുന്നു. അത് എംടി സിസ ഞങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ സിസ്റ്റത്തില്\u200d കഠിനമായ അഭിപ്രായശ്ചിത്രത്തിന്റെയും കുറഞ്ഞ വാക്', 'ms': 'Performasi sistem NMT telah berkembang secara drastik dalam beberapa tahun terakhir tetapi terjemahan perkataan berbilang-sens masih menantang. Kerana perasaan perkataan tidak mewakili secara serentak dalam korpra selari yang digunakan untuk latihan, terdapat penggunaan berlebihan dari perasaan paling sering dalam output MT. Dalam kerja ini, kami cadangkan CmBT (Contextually-mined Back-Translation), pendekatan untuk meningkatkan penerjemah perkataan berbilang-sens menggunakan penerjemah perkataan kontekstual salib-bahasa yang dilatih-terlatih (CCWRs). Kerana sensitiviti kontekstual mereka dan data praselatihan besar mereka, CCWR boleh mudah menangkap perasaan perkataan yang hilang atau sangat jarang dalam korpra selari yang digunakan untuk melatih MT. Secara khusus, CmBT melaksanakan induksi leksikon bilingual pada CCWR untuk tambang kalimat sasaran khusus sens dari set data monobahasa, Dan kemudian menerjemahkan semula kalimat ini untuk menghasilkan korpus selari pseudo sebagai data latihan tambahan untuk sistem MT. Kami menguji kualiti terjemahan kata-kata yang ambiguh pada suite ujian MuCoW, yang dibina untuk menguji efektif penyelesaian perkataan dari sistem MT. Kami menunjukkan bahawa sistem kami meningkat dalam terjemahan dari sens perkataan yang sulit tidak terlihat dan frekuensi rendah.', 'mn': 'NMT системийн үйл ажиллагаа өнгөрсөн хэдэн жилд маш их сайжруулсан. Гэхдээ олон ойлголтын үгийг хөгжүүлэх нь хэзээ ч асуудал бий болдог. Сургуульд хэрэглэгддэг параллел корпоратын мэдрэмжүүдийг нэгтгэхэд илэрхийлж чадахгүй учраас MT гаргалтын хамгийн ихэвчлэн мэдрэмжүүдийн хэрэглээ ихэвчлэн байдаг. Энэ ажлын хувьд бид CmBT (Төвшөөрөгдсөн буцаад хөрөнгө хөрөнгө оруулалт), олон ойлголтын үг хөрөнгө оруулах арга зам нь сургалтын өмнө сургалтын давхар хэлний үг илэрхийлэл (CCWRs) гэсэн үг илэрхийлэх Тэдний орчин үеийн мэдрэмжтэй байдал болон их өмнө сургалтын мэдээллээр CCWRs нь MT-г сургалтын тулд алдагдах эсвэл маш ховор үеийн мэдрэмжүүдийг амархан ойлгож чадна. МТ системийн нэмэлт сургалтын өгөгдлийг үүсгэхийн тулд эдгээр өгүүлбэрүүдийг буцаад орчуулдаг. Бид MuCoW шалгалтын шинжлэх ухааны тухай хэмжээний хэмжээний чанарыг шалгаж байлаа. Энэ нь MT системийн хэмжээний эффективностийг шалгахын тулд зохион байгуулагдсан. Бид систем маань хэцүү харагдахгүй, бага хэмжээний хэмжээний мэдрэмжүүдийг хөгжүүлэхийг харуулж байна.', 'no': 'NMT-systemet har forbetra drastisk i de siste få år, men omsetjinga av fleire sentrale ord fortsatt gjer eit utfordring. Sidan ordsensar ikkje er representert uniformt i den parallelle korpora som er brukt for opplæring, er det eit oversiktig bruk av den mest ofte følelsen i MT-utdata. I denne arbeida foreslår vi CmBT (kontekstært minert tilbakeomsetjing), ein tilnærming for å forbetra fleirsentralt ordomsetjing med å levera før-trenga krysspråksomsetjingar (CCWRs). På grunn av sine kontekstære følsomhet og dei store føreøvingsdata, kan CCWRs enkelt henta ordsensar som manglar eller veldig sjeldar i parallelle korpora brukt til å trenja MT. Særleg brukar CmBT bilinguelt leksikoninduksjon på CCWRs til minnespesifikske målsettingar frå ein monolinguelt dataset, Og så translaterer desse setningane tilbake for å laga ein pseudoparallell korpus som ekstra treningsdata for ein MT- system. Vi tester omsetjingskvaliteten av avgjengelege ord på MuCoW-testsuiten, som ble bygd for å testa ordfølelsen for å forstå forståking av MT-systemet. Vi viser at systemet vårt forbedrar omsetjinga av vanskeleg ukjende og låg frekvens ordsensar.', 'mt': 'Il-prestazzjoni tas-sistemi NMT tjiebet drastikament f’dawn l-a ħħar snin iżda t-traduzzjoni ta’ kliem b’sens multiplu għadha toħloq sfida. Peress li s-sensi tal-kliem mhumiex rappreżentati b’mod uniformi fil-korpra parallela użata għat-taħriġ, hemm użu eċċessiv tas-sens l-aktar frekwenti fil-produzzjoni MT. F’din il-ħidma, qed nipproponu CmBT (Traduzzjoni Ġenerali Minjata b’Kuntest), approċċ għat-titjib tat-traduzzjoni tal-kliem b’sensi multipli li jagħti spinta lil rappreżentazzjonijiet tal-kliem kuntestwali translingwi mħarrġa minn qabel (CCWRs). Because of their contextual sensitivity and their large pre-training data, CCWRs can easily capture word senses that are missing or very rare in parallel corpora used to train MT. Specifically, CmBT applies bilingual lexicon induction on CCWRs to mine sense-specific target sentences from a monolingual dataset, ) u mbagħad jittraduċi lura dawn is-sentenzi biex jiġġeneraw korpus psewdo parallel bħala dejta addizzjonali ta’ taħriġ għal sistema MT. Aħna ntestjaw il-kwalità tat-traduzzjoni ta’ kliem ambigwu fuq is-sett tat-test MuCoW, li nbena biex ittestja l-effettività tad-diżambigwazzjoni tas-sens tal-kelma tas-sistemi MT. Aħna nuru li s-sistema tagħna ttejjeb fit-traduzzjoni ta’ sensi ta’ kliem diffiċli li ma jidhrux u ta’ frekwenza baxxa.', 'pl': 'Wydajność systemów NMT drastycznie poprawiła się w ciągu ostatnich kilku lat, ale tłumaczenie wieloznacznych słów nadal stanowi wyzwanie. Ponieważ zmysły słowa nie są reprezentowane jednolitie w równoległych korpusach używanych do treningu, istnieje nadmierne wykorzystanie najczęstszego zmysłu w wyjściu MT. W niniejszej pracy proponujemy CmBT (Contextually-mined Back-Translation), podejście do usprawnienia wieloznacznego tłumaczenia słów wykorzystujące wstępnie przeszkolone, wielojęzyczne kontekstowe reprezentacje słów (CCWR). Ze względu na ich wrażliwość kontekstową i duże dane przedtreningowe, CCWR mogą łatwo uchwycić zmysły słowa, które brakują lub bardzo rzadko w równoległych korporach używanych do treningu MT. W szczególności CmBT stosuje dwujęzyczną indukcję leksykonu na CCWR do wydobywania zdań docelowych specyficznych dla zmysłów z jednojęzycznego zbioru danych, a następnie wstecz tłumaczy te zdania, aby wygenerować pseudo-równoległy korpus jako dodatkowe dane treningowe dla systemu MT. Testujemy jakość tłumaczenia dwujednoznacznych słów na pakiecie testowym MuCoW, który został zbudowany w celu sprawdzenia skuteczności rozdysjednoznaczności słów systemów MT. Pokazujemy, że nasz system ulepsza tłumaczenie trudnych niewidzialnych i niskiej częstotliwości zmysłów słowowych.', 'ro': 'Performanța sistemelor NMT s-a îmbunătățit drastic în ultimii ani, dar traducerea cuvintelor multi-sens reprezintă încă o provocare. Deoarece simțurile cuvântului nu sunt reprezentate uniform în corpurile paralele folosite pentru antrenament, există o utilizare excesivă a sensului cel mai frecvent în ieșirea MT. În această lucrare, propunem CmBT (Contextually-mined Back-Translation), o abordare pentru îmbunătățirea traducerii cuvintelor în mai multe sensuri, utilizând reprezentările contextuale cross-lingve pre-instruite (CCWR). Datorită sensibilității lor contextuale și a datelor lor mari pre-antrenament, CCWR pot capta cu ușurință simțurile cuvintelor care lipsesc sau sunt foarte rare în corpurile paralele utilizate pentru antrenarea MT. Mai precis, CmBT aplică inducția lexiconului bilingv pe CCWR pentru a extrage propoziții țintă specifice simțurilor dintr-un set de date monolingv, și apoi traduce înapoi aceste propoziții pentru a genera un corpus pseudo paralel ca date suplimentare de formare pentru un sistem MT. Testăm calitatea traducerii cuvintelor ambigue pe suita de test MuCoW, care a fost construită pentru a testa eficacitatea de dezambiguizare a sensului cuvântului a sistemelor MT. Noi arătăm că sistemul nostru îmbunătățește traducerea simțurilor dificile nevăzute și de joasă frecvență a cuvântului.', 'sr': 'Proizvodnja NMT-ovih sistema je u poslednjih nekoliko godina drastično poboljšala, ali prevod višesmislenih reči još uvijek predstavlja izazov. Budući da se osjećaji riječi ne predstavljaju uniformno u paralelnoj korpori korištenoj za obuku, postoji prevelika upotreba najčešćeg smisla u izlazu MT-a. U ovom poslu predlažemo CmBT (kontekstualno-mineralno-prevod), pristup unaprjeđivanju višesmislenog prevoda reèi koji utječu na predobučene međujezičke kontekstualne reèi (CCWRs). Zbog njihove kontekstualne osjetljivosti i njihovih velikih podataka pre obuke, CCWRs može lako uhvatiti osjećaje riječi koje nedostaju ili veoma rijetke u paralelnoj korpori koriste za obuku MT-a. Posebno, CmBT primjenjuje dvojezičku leksikonsku indukciju na CCWRs-a na moju ciljnu rečenicu iz jednojezičkog seta podataka, I onda ponovo prevodi te rečenice kako bi stvorili pseudoparalelni korpus kao dodatne podatke o obuci za MT sistem. Testiramo kvalitet prevoda neobičnih reči na MuCoW test apartmanu, koji je izgrađen kako bi testirao efektivnost disambiguacije reči MT sistema. Pokazujemo da je naš sistem poboljšao prevod teških nevidljivih i niskih čula za riječi o frekvenciji.', 'si': 'NMT පද්ධති පද්ධතියේ ප්\u200dරමාණයක් ගිය අවුරුදු කීපයකින් ප්\u200dරමාණය වැඩ කරලා තියෙනවා නමුත් විශේෂ වචන වචන අවධා වචන සංවේදනය සමාන්\u200dයයෙන් ප්\u200dරතිනිධානය කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරතිනිධානයක් නැති විදිහට, MT ප්\u200dරතිනිධානයේ සාමා මේ වැඩේදී, අපි CmBT (Contextally-mine back-translation) යෝජනා කරනවා, විශේෂ වචන අභාවිතය සඳහා ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් විතරයෙ මොකද ඔවුන්ගේ සම්බන්ධ සංවේදනය සහ ඔවුන්ගේ ලොකු ප්\u200dරධාන දත්ත, CCWrs පුළුවන් ලේසියෙන් අතුරුද්ධ වචන සංවේදනය අල්ලගන්න පුළුවන් වචන සංවේදනය සමහර විශේෂයෙන් MT ඒ වගේම පස්සේ මේ වාක්ෂාව පරිවර්තන කරනවා MT පද්ධතියක් වෙනුවෙන් තවත් ප්\u200dරධාන දත්ත විදියට පස්සේ සමාන්\u200dය කො අපි MuCoW පරීක්ෂණ සූටියේ අභිවිධාන වචන වචන වර්තනය පරීක්ෂණය කරනවා, ඒක MT පද්ධති වචන වචන අවශ්\u200dයතාවක් පරීක්ෂණය ක අපි පෙන්වන්නේ අපේ පද්ධතිය පුළුවන් වෙන්නේ අමාරුයි නොදන්නේ නැති වචන වචන අවවාදයක් ගැන.', 'so': 'Dhaqashada nidaamka NMT ayaa si fiican u bedeshay sanadihii hore, laakiin turjumidda hadalka badan oo kala duduwan weli waxay leedahay dhibaato. Sida darteed maandooriyaha hadalka aan si caadi ah ugu muuqanayn shirkadda lambarka ah ee loo isticmaalayo waxbarashada, waxaa jira isticmaal aad u badan isticmaalka soo baxa MT. Markaas waxan, waxaynu soo jeedaynaa CmBT (Contextext-mined Back-Translation), qaab u ah hagaajinta kordhinta tarjumaadda hadalka badan oo afka hore-trained oo af-luqada ah (CCWRs). CCWRs waxay si fudud ugu qabsan karaan sanooyin ay ka baahan yihiin ama aad u gaaban yihiin shirkadaha lambarka ah oo loo baran karo MT. Si gaar ah CmBT wuxuu u qaban karaa qalabka leksiga oo labada luqadood ah oo CCWRs ugu qoran karaa hababka waxyaabaha ay ku qoran yihiin waxyaabaha ay ku qoran yihiin waxyaabaha aan ku garan karo oo ay u baahan yihiin si fudud ugu filan oo ay u qaadaan xafiiska macluumaadka moolooyinka ah, Markaas waxaa dib loo turjumaa erayadan si ay u dhashaan cudur isku mid ah oo ay u eg yihiin macluumaad waxbarasho dheeraad ah oo u qoran MT. Waxaynu tijaabinaynaa tarjumaadka hadalka aan caqliga lahayn ee ku saabsan mudada imtixaanka MuCoW, kaas oo loo dhisay si aan u imtixaano waxyaabaha kaleemeyn ee nidaamka MT. Waxaynu muujinnaa in nidaamkayagu horumarinayo turjumidda waxyaabaha qarsoon ee maqan iyo waxyaabaha dhaqdhaqaaqa ah.', 'sv': 'NMT-systemens prestanda har förbättrats drastiskt under de senaste åren, men översättningen av ord med flera sinnen utgör fortfarande en utmaning. Eftersom ordsinnena inte representeras enhetligt i de parallella korpora som används för träning, används det en överdriven användning av den vanligaste betydelsen i MT output. I det här arbetet föreslår vi CmBT (Contextually-mined Back-Translation), ett tillvägagångssätt för att förbättra ordöversättning med flera sinnen genom att utnyttja förintränade tvärspråkiga kontextuella ordrepresentationer (CCWR). På grund av deras kontextuella känslighet och deras stora pre-training data, kan CCWR enkelt fånga ordsinnen som saknas eller mycket sällsynta i parallella korpora som används för att träna MT. Specifikt tillämpar CmBT tvåspråkig lexikoninduktion på CCWR för att utvinna sinnesspecifika målmeningar från en enspråkig datauppsättning, och sedan bakåtöversätter dessa meningar för att generera en pseudo parallell korpus som ytterligare träningsdata för ett MT-system. Vi testar översättningskvaliteten för tvetydiga ord på MuCoW testsviten, som byggdes för att testa ordets betydelse för uttydligande system. Vi visar att vårt system förbättrar översättningen av svåra osynliga och lågfrekventa ordsinnen.', 'ta': 'The performance of NMT systems has improved drastically in the past few years but the translation of multi-sense words still poses a challenge.  பயிற்சிக்கு பயன்படுத்தப்படும் அளபுரு கோர்ப்பில் வார்த்தை உணர்வுகள் தனிப்பயனாக குறிக்கப்படவில்லை என்பதால், MT வெளியீட்டி இந்த வேலையில், நாம் CmBT (உள்ளமைப்பில் நிகழ்ந்த பின்மொழிபெயர்ப்பு, முன் பயிற்சிக்கப்பட்ட மொழி மொழிபெயர்ப்பு மொழிபெயர்ப்பை மேம்படுத்துவதற்கான ஒர அவர்களுடைய தற்போதைய உணர்வு மற்றும் அவர்களுடைய பெரிய முன் பயிற்சி தகவல்கள் காரணமாக, CCWRs எளிதாகவே காணவில்லை அல்லது மிகவும் குறைந்த உணர்வுகளை எடுத்துக் கொள்ள முடியும் இணைக்குறிப்பில் MT பயிற்சிக்க எம்டி அமைப்பிற்கான கூடுதல் பயிற்சி தகவலாக உருவாக்க இந்த வாக்கியங்களை மீண்டும் மொழிமாற்றுகிறது. MT அமைப்புகளின் வார்த்தையின் பாதுகாப்பு பாதுகாப்பு சோதிக்க முடியாத வார்த்தைகளின் மொழிபெயர்ப்பு தரம், முக்கோவ நாம் எங்கள் அமைப்பு கடினமான மற்றும் குறைந்த அணுகல் வார்த்தை உணர்வுகள் மொழிபெயர்ப்பில் மேம்படுத்த', 'ur': 'NMT سیستموں کی عملکرد گزشتہ چند سالوں میں بہت اچھی طرح بہتر ہو چکی ہے لیکن بہت سی منطقی کلمات کی ترجمہ ابھی بھی ایک چال ہے۔ کیونکہ کلمات سنسوں کی تعلیم کے لئے استعمال کیے جاتے ہیں، اس کے بعد MT آئٹ میں بہت اضافہ سمجھ کا استعمال ہے. اس کام میں ہم CmBT (متوسط-منڈ پھیر-ترجمہ) کی پیشنهاد کریں گے، ایک طریقہ بہت سی منطقی کلمات ترجمہ کی پیش آموزش کی کرس-زبان متوسط کلمات کی پیشنهاد (CCWRs) کے لئے۔ ان کی کنٹکسٹیسٹ حساسیت اور ان کی بڑی پیشترینس ڈیٹے کی وجہ سے CCWRs آسان طور پر کلمات سنسوں کو پکڑ سکتے ہیں جو MT کی تعلیم کے لئے ناپذیر ہیں یا بہت نادر ہیں. اور اس کے بعد یہ جماعتوں کو MT سیستم کے لئے اضافہ ترسین ڈیٹے کے طور پر پیچھے ترجمہ کرتا ہے۔ ہم نے MuCoW تست سوئٹ پر غیر معمولی کلمات کی ترجمہ کی کیفیت کی آزمائش کی، جو MT سیستموں کی تست کے لئے بنائی گئی تھی۔ ہم دکھاتے ہیں کہ ہمارا سیستم مشکل غیب کی اور کم فرکانسی لفظ کی ترجمہ پر بہتر ہوتا ہے.', 'uz': "Name @ info: whatsthis In this work, we propose CmBT (Contextually-mined Back-Translation), an approach for improving multi-sense word translation leveraging pre-trained cross-lingual contextual word representations (CCWRs).  Ko'rsatilgan oddiy foydalanuvchi va ularning katta taʼminlovchi maʼlumotlari sababi, CCWRlar MT ta'minlashga ishlatiladigan amalni juda qisqa ko'p so'zlarni olib tashlab oladi. Keyin bu so'zlarni MT tizimi uchun qoʻshimcha trening maʼlumoti sifatida yaratish mumkin. Biz MuCoW sinov sohasida o'zgarishni tajriba qilamiz. Bu so'zni MT tizimning imkoniyatini tekshirish uchun yaratildi. Biz buning tizimimizni ko'rsatamiz, yomon ko'p ko'rinmagan va kam freym soʻzlar sensoriga tarjima qilishni o'zgartiradi.", 'vi': 'Các hệ thống NMT đã tiến bộ mạnh mẽ hơn trong vài năm qua nhưng dịch từ đa cảm vẫn là một thử thách. Vì các giác quan từ không được đại diện một cách đồng nhất trong cấu trúc cấu trúc song song được dùng cho huấn luyện, nên có một cách sử dụng quá nhiều các giác quan gần gũi nhất trong kết xuất MTV. Trong công việc này, chúng tôi đề nghị Điều chỉnh (Reconstruction ghép đôi, một cách để cải thiện dịch từ đa cảm, nhờ đó dịch chuyển nhiều từ được đào tạo xuyên ngôn ngữ ngữ ngữ ngữ ngữ, xuyên ngữ học. Dựa vào khả năng kiểm soát của họ và các dữ liệu trước khi đào tạo lớn, CCWR có thể dễ dàng thu thập các giác quan từ bị mất tích hoặc rất hiếm ở vật thể song song song phương được dùng để huấn luyện MTV. Cụ thể, Hoá chất Hoá chất Hoá chất Hoá ra Hoá đơn đặt từ ngữ thức của CCWR vào các câu đích của tôi từ một tập tin ngôn ngữ riêng, và sau đó dịch những câu này để tạo ra một tập đoàn giả lập song như dữ liệu đào tạo thêm cho một hệ thống MTV. Chúng tôi kiểm tra chất dịch của những từ mơ hồ trên phòng thử nghiệm MuCoW, được xây dựng để thử nghiệm hiệu quả biến dạng từ các hệ thống MTV. Chúng tôi cho thấy hệ thống của chúng tôi cải thiện việc dịch chuyển các giác quan từ khó thấy và tần số thấp.', 'bg': 'Ефективността на системите за НМТ се подобри драстично през последните няколко години, но преводът на многозначни думи все още представлява предизвикателство. Тъй като думите сетива не са представени равномерно в паралелните корпуси, използвани за обучение, има прекомерно използване на най-честия смисъл в МТ изхода. В тази работа ние предлагаме подход за подобряване на многозначния превод на думи, използващ предварително обучени междуезични контекстуални словесни представяния (ККР). Because of their contextual sensitivity and their large pre-training data, CCWRs can easily capture word senses that are missing or very rare in parallel corpora used to train MT. Specifically, CmBT applies bilingual lexicon induction on CCWRs to mine sense-specific target sentences from a monolingual dataset, и след това обратно превежда тези изречения, за да генерира псевдо паралелен корпус като допълнителни данни за обучение за система МТ. Тестваме качеството на превода на двусмислени думи на тестовия комплект който е създаден, за да тества ефективността на разграничаването на смисъла на думата на системите МТ. Показваме, че нашата система подобрява превода на трудни невидими и нискочестотни думи сетива.', 'da': "NMT-systemernes ydeevne er blevet drastisk forbedret i de seneste par år, men oversættelsen af flersansede ord udgør stadig en udfordring. Da ord sanser ikke er repræsenteret ensartet i de parallelle korpora, der anvendes til træning, er der en overdreven brug af den hyppigste betydning i MT output. I dette arbejde foreslår vi CmBT (Contextually-mined Back-Translation), en tilgang til forbedring af ordoversættelse med flere sanser ved hjælp af prætrænede tværsprogede kontekstuelle ordrepræsentationer (CCWR'er). På grund af deres kontekstuelle følsomhed og deres store før træning data, CCWR'er kan nemt fange ordsanser, der mangler eller meget sjældne i parallelle korpora, der bruges til at træne MT. Specielt anvender CmBT tosproget leksikoninduktion på CCWR'er til at udvinde sansespecifikke målsætninger fra et ensproget datasæt, og derefter oversætter disse sætninger tilbage for at generere et pseudo parallelt korpus som yderligere træningsdata for et MT-system. Vi tester oversættelseskvaliteten af tvetydige ord på MuCoW testpakken, som blev bygget til at teste ordets meningsfuldbyrdelseseffektivitet af MT-systemer. Vi viser, at vores system forbedrer oversættelsen af svære usynlige og lavfrekvente ordsanser.", 'hr': 'Proizvodnja NMT-ovih sustava u proteklih nekoliko godina drastično se poboljšala, ali prevod višesmislenih riječi još uvijek predstavlja izazov. Budući da se osjećaji riječi ne predstavljaju uniformno u paralelnom tijelu koje se koristi za obuku, postoji prekomjerna upotreba najčešćeg smisla u izlazu MT-a. U ovom poslu predlažemo CmBT (kontekstualno mineralno povratno prevodenje), pristup unaprjeđivanju višesmislenih riječi o prevodu riječima koji utječu na predobučene cross-lingual contextual riječi (CCWRs). Zbog njihove kontekstualne osjetljivosti i njihovih velikih podataka prije obuke, CCWRs može lako uhvatiti osjećaje riječi koje nedostaju ili vrlo rijetke u paralelnoj korpori koriste za obuku MT-a. Posebno, CmBT primjenjuje indukciju dvojezičkog leksikona na CCWRs-a na moja osjećajna ciljna rečenica iz jednojezičkog seta podataka, A onda povratak prevodi te rečenice kako bi stvorili pseudoparalelni korpus kao dodatne podatke o obuci za MT sustav. Testiramo kvalitet prevođenja ambigućih riječi na MuCoW test apartmanu, koji je izgrađen kako bi testirao učinkovitost disambiguacije reči MT sustava. Pokazujemo da se naš sustav poboljšava na prevodu teških nevidljivih i niskih čula riječi.', 'nl': "De prestaties van NMT-systemen zijn de afgelopen jaren drastisch verbeterd, maar de vertaling van multi-sense woorden vormt nog steeds een uitdaging. Aangezien woordzintuigen niet uniform worden vertegenwoordigd in de parallelle corpora gebruikt voor training, is er een overmatig gebruik van de meest voorkomende zin in MT-uitvoer. In dit werk stellen we CmBT (Contextually-mined Back-Translation) voor, een aanpak voor het verbeteren van multi-sense woordvertaling met behulp van vooraf getrainde cross-lingual contextual word representations (CCWR's). Door hun contextuele gevoeligheid en hun grote pre-training data kunnen CCWR's gemakkelijk woordzintuigen vastleggen die ontbreken of zeer zeldzaam zijn in parallelle corpora's die worden gebruikt om MT te trainen. en vertaalt deze zinnen terug om een pseudo parallelle corpus te genereren als aanvullende trainingsgegevens voor een MT-systeem. We testen de vertaalkwaliteit van dubbelzinnige woorden op de MuCoW testsuite, die is gebouwd om de effectiviteit van woordscheiding van MT-systemen te testen. We laten zien dat ons systeem verbetert in de vertaling van moeilijke onzichtbare en laagfrequente woordzintuigen.", 'de': 'Die Leistung von NMT-Systemen hat sich in den letzten Jahren drastisch verbessert, aber die Übersetzung von mehrsinnigen Wörtern stellt immer noch eine Herausforderung dar. Da Wortsinne in den parallelen Korpora, die für das Training verwendet werden, nicht einheitlich dargestellt werden, gibt es eine übermäßige Verwendung des häufigsten Sinnes in der MT-Ausgabe. In dieser Arbeit schlagen wir CmBT (Contextually-mined Back-Translation) vor, einen Ansatz zur Verbesserung der mehrsinnigen Wortübersetzung unter Verwendung von vortrainierten crosslingual contextual word representations (CCWRs). Aufgrund ihrer kontextuellen Sensibilität und ihrer großen Daten vor dem Training können CCWRs leicht Wortsinne erfassen, die in parallelen Korpora zum Trainieren von MT fehlen oder sehr selten sind. Diese Sätze werden dann rückübersetzt, um einen pseudo-parallelen Korpus als zusätzliche Trainingsdaten für ein MT-System zu generieren. Wir testen die Übersetzungsqualität von mehrdeutigen Wörtern auf der MuCoW Testsuite, die entwickelt wurde, um die Effektivität der Wortsense-Disambiguation von MÜ-Systemen zu testen. Wir zeigen, dass unser System die Übersetzung schwieriger unsichtbarer und niederfrequenter Wortsinne verbessert.', 'id': 'Pertunjukan sistem NMT telah meningkat drastis dalam beberapa tahun terakhir tapi terjemahan kata-kata multi-sens masih menantang. Karena sensor kata tidak mewakili secara seragam dalam korpra paralel yang digunakan untuk latihan, ada penggunaan berlebihan dari sensor yang paling sering dalam output MT. Dalam pekerjaan ini, kami mengusulkan CmBT (Contextually-mined Back-Translation), pendekatan untuk meningkatkan penerjemah kata multi-sensor menggunakan penerjemah kata kontekstual interbahasa yang dilatih sebelumnya (CCWR). Because of their contextual sensitivity and their large pre-training data, CCWRs can easily capture word senses that are missing or very rare in parallel corpora used to train MT. Specifically, CmBT applies bilingual lexicon induction on CCWRs to mine sense-specific target sentences from a monolingual dataset, Dan kemudian menerjemahkan kalimat-kalimat ini untuk menghasilkan corpus paralel pseudo sebagai data pelatihan tambahan untuk sistem MT. Kami menguji kualitas terjemahan dari kata-kata yang ambiguh di suite ujian MuCoW, yang dibuat untuk menguji efektif penyelesaian kata dari sistem MT. Kami menunjukkan bahwa sistem kami meningkat dalam terjemahan dari sulit tidak terlihat dan sensor kata frekuensi rendah.', 'sw': 'Utimizaji wa mifumo ya NMT umeboresha kwa kiasi kikubwa katika miaka michache iliyopita lakini tafsiri ya maneno mengi bado yanakuwa na changamoto. Kwa kuwa hisia za maneno hazina uwakilishi katika makampuni yanayotumiwa kwa ajili ya mafunzo, kuna matumizi mengi zaidi ya hisia katika matokeo ya MT. In this work, we propose CmBT (Contextually-mined Back-Translation), an approach for improving multi-sense word translation leveraging pre-trained cross-lingual contextual word representations (CCWRs).  Kwa sababu ya uelewa wao wa zamani na takwimu zao kubwa za mafunzo ya zamani, CCWRs wanaweza kuchukua hisia za neno ambazo hazionekani kwa urahisi au nadra sana katika makampuni yanayotumiwa kufundisha MT. Kwa hakika, CmBT hutumia uzalishaji wa lexico wa lugha mbili kwenye CCWRs ili kuweka sentensi maalum za malengo yangu kutoka kwenye seti ya takwimu za kimonolinguli, na kisha hutafsiri hukumu hizi za kutengeneza viungo vinavyofanana kama takwimu zaidi za mafunzo kwa mfumo wa MT. Tunajaribu tafsiri ya neno lisilo na maana juu ya suala la jaribio la MuCoW, ambalo lilijengwa ili kujaribu ufanisi wa maana ya kutokubalika kwa mfumo wa MT. Tunaonyesha kwamba mfumo wetu unaboresha tafsiri ya hali ngumu isiyo na ya kiwango cha umeme.', 'ko': '지난 몇 년 동안 NMT 시스템의 성능은 크게 향상되었지만 다의어의 번역은 여전히 도전이다.단어의 의미는 훈련에 사용되는 평행 어료 라이브러리에서 통일된 표시가 없기 때문에 기계 번역 출력에서 가장 흔히 볼 수 있는 의미를 과도하게 사용했다.이 작업에서 우리는 CmBT(상하문 발굴 번역)를 제기했는데 이것은 미리 훈련된 다중 언어 상하문어 표시(CCWRs)를 이용하여 다의어 번역을 개선하는 방법이다.컨텍스트의 민감성과 대량의 훈련 전 데이터 때문에 CCWRs는 기계 번역을 훈련하는 데 사용되는 평행 어료 라이브러리에서 부족하거나 매우 보기 드문 의미를 쉽게 포착할 수 있다. 구체적으로 말하면 CmBT는 CCWRs에 이중 언어 어휘 귀납법을 응용하여 단어 데이터에서 특정한 의미의 목표 문장을 집중적으로 발굴한다.그리고 이 문장을 반역하여 위조 평행 어료 라이브러리를 생성하여 기계 번역 시스템의 추가 훈련 데이터로 삼는다.MuCoW 테스트 키트에서 잘못된 단어의 번역 품질을 테스트했습니다. 이 테스트 키트는 기계 번역 시스템의 의미 분리 효과를 테스트하는 데 사용됩니다.우리의 연구에 의하면, 우리 시스템은 식별하기 어려운 저주파 단어의 의미를 번역했다.', 'fa': 'عملکرد سیستم\u200cهای NMT در چند سال گذشته به شدت بهتر شده است ولی ترجمه کلمات متفاوتی هنوز یک چالش می\u200cکند. چون احساسات کلمه\u200cها در شرکت\u200cهای متفاوتی که برای آموزش استفاده می\u200cشوند یکسان نمایش نمی\u200cشوند، استفاده از احساسات زیادی در نتیجه MT وجود دارد. در این کار، ما پیشنهاد می\u200cکنیم CmBT (به عنوان تغییرات پشتیبانی معدنی) یک روش برای بهتر کردن ترجمه کلمه\u200cهای مختلف منطقه\u200cای که برای نمایش\u200cهای کلمه\u200cهای مختلف زبان\u200cآموزش پیش آموزش داده می\u200cشود (CCWRs). به دلیل حساسیت موضوع و داده های پیش آموزش بزرگ آنها، CCWRs می\u200cتواند به آسانی حس\u200cهای کلمه\u200cای که در شرکت\u200cهای پارالی استفاده می\u200cشود یا بسیار نادر از MT آموزش می\u200cکنند را بگیرند. به طور خاص، CmBT به فعالیت دو زبانی در CCWRs برای مجموعه\u200cهای هدف خاصی به حس من از یک مجموعه داده\u200cهای متحد زبان و سپس این جمله را به عنوان اطلاعات آموزش اضافه برای یک سیستم MT تولید می کند. ما کیفیت ترجمه کلمات غیرقابل توجه به سوئت آزمایش MuCoW را آزمایش می کنیم که برای آزمایش فعالیت غیرقابل توجه به کلمات سیستم MT ساخته شده است. ما نشان می دهیم که سیستم ما در ترجمه کردن احساسات کلمه های نابینا و فرکانس پایین بهتر می شود.', 'tr': 'NMT sistemleriniň başarylygy geçen birnäçe ýylda köp gowydy ýöne, ýöne birnäçe düşünjeli sözlerin terjime edilmesi entägem kynçylyk edip bilýär. Çünki kelime duýgulary parallel korporada eğitim üçin bir şekilde ulanmaýandyr, MT çizgisinde iň köp duýgulary ýok bir ulanmak bar. Bu işde, CmBT (Kontrol-miner-terjime edilen arka terjime edilen), birnäçe sanly söz terjime edilen öňünden öňünden öňünden öňünden gelen çerçe-dilli terjime edilmeleri (CCWRs) teklip etmek üçin bir nusga teklip edýäris. Çünkü olaryň duýdury we uly öň-okuwçylygy üçin CCWR-ler MT öwretmek üçin ýok ýa-da parallel korporada ulanylan söz duýdurlaryny a ňsatlyk bilen alyp biler. Aňsatlyk bilen, CmBT CCWRs-yň ikinji dilli sözlerini monodil veri setirinden meniň duýdury hasaplamaga mümkin edýän sözlerini ulanýar. Bu sözleri MT sistemi için a şırı eğitim verileri olarak pseudo paralel korpus oluşturmak için geri çevirir. MuCoW testi suitinde wajyp sözlerin önümlerini çykarmak üçin test edildi. Bu sözlerin MT sistemlerinin çykarmak üçin guruldy. Biz sistemimiziň garaşylmadyk we azaltylyk sözlerin duýdurmanyň terjimesini gowylaşdyrýandygyny görkeýäris.', 'sq': 'Performanca e sistemeve NMT është përmirësuar drastikisht në vitet e fundit por përkthimi i fjalëve me shumë kuptime ende përbën një sfidë. Meqenëse ndjenjat e fjalës nuk përfaqësohen uniformisht në korprën paralele të përdorur për stërvitje, ekziston një përdorim i tepruar i ndjenjave më të shpeshta në daljen e MT. Në këtë punë, ne propozojmë CmBT (Përkthimi në lidhje me minierët kontekstuale), një qasje për përmirësimin e përkthimit të fjalëve me shumë kuptime duke nxitur përfaqësime fjalësh kontekstuale të paratrajnuara ndërgjuhësore (CCWRs). Për shkak të ndjeshmërisë kontekstuale të tyre dhe të dhënave të tyre të mëdha të paratrajnimit, CCWRs mund të kapin lehtë ndjenjat e fjalëve që mungojnë ose shumë të rralla në korpra paralele të përdorura për të trajnuar MT. Specifikisht, CmBT aplikon induksionin e lexikonëve dygjuhës në CCWRs për minierën e fjalëve të shënjestrave specifike të sensit nga një set të dhënash monogjuhësh, Dhe pastaj i përkthen këto fjalime për të gjeneruar një korpus pseudo paralel si të dhëna shtesë trainimi për një sistem MT. Ne testojmë cilësinë e përkthimit të fjalëve të dyshimta në suitën e testit MuCoW, e cila është ndërtuar për të testuar fjalën kuptim të efektshmërisë së çambiguacionit të sistemeve MT. Ne tregojmë se sistemi ynë përmirësohet në përkthimin e ndjenjave të vështira të padukshme dhe të frekuencës së ulët të fjalëve.', 'am': 'ባለፉት ጥቂት ዓመታት የNMT ሥርዓት መግለጫ በሙሉ ባደረገ ነገር ግን የብዙአዊ ቃላት መግለጫ ገና የጭንቀት ነው፡፡ የንግግር እውቀት በፓርላማ ኮርፖራ ውስጥ በተለየ ጥያቄ ሳይሆን፣ በMT ውጤት ውስጥ የበለጠ ጥያቄ ይኖራል፡፡ በዚህ ሥራ CmBT (Context-mined Back-Translation) የፊተኛ-trained cross-language contextual word representations (CCWRs) በማድረግ የብዙ-sense ትርጉም መግለጫ ማድረግ ማቅረብ አቅራቢያ ነው፡፡ ከቀድሞው ስህተታቸው እና ትልቁ የፍለጋዊ ዳታዎች CCWRs MT ለማስተማር በተጠቃሚ ኮርፖራ ውስጥ የሚጠቅሙትን ቃላት ወይም እጅግ ትንሽ የሚያስፈልጉትን ቃላት ማግኘት ይችላል፡፡  and then back-translates these sentences to generate a pseudo parallel corpus as additional training data for an MT system.  በሙCoW ተፈተና ጉዳይ ላይ ያሉትን የንግግርን ትርጓሜ ጥሩ እናፈትናለን፡፡ ይህም የMT ስርዓቶች ውስጥነት ለመፈተን የቃላትን አስተያየት ትርጓሜ እናደርጋለን፡፡ እናሳያቸዋለን የስርዓታችን ግጭት ስውር እና የፍሬት ቃላት ትንሽ ስህተት መተርጓሜ እንዲያበዛል፡፡', 'hy': 'ՆՄԹ համակարգերի արտադրողությունը վերջին մի քանի տարիների ընթացքում խիստ բարելավվել է, բայց բազմազգայական բառերի թարգմանությունը դեռևս մարտահրավեր է առաջացնում: Քանի որ բառի զգացմունքները միանգամայն չեն ներկայացված զուգահեռ մարմնում, որը օգտագործվում է մարզելու համար, MT-ի արտադրության ամենահաճախ զգացմունքը չափազանց շատ է օգտագործվում: Այս աշխատանքի ընթացքում մենք առաջարկում ենք CmBT (Կոնտեքստի մեջ հանված ետնաթարգմանություն), մի մոտեցում բառերի բառերի բարելավման համար, որն օգտագործում է նախապատրաստված լեզվի միջև կոնտեքստի բառերի ներկայացումներ (CC-Rs). Քանի որ իրենց կոնտեքստալ զգացմունքը և մեծ նախապատրաստ տվյալները կարող են հեշտությամբ ընկալել բառային զգացմունքներ, որոնք բացակայում են կամ շատ հազվադեպ են զուգահեռ կառուցվածքում, որոնք օգտագործվում են MT-ի պատրաստման համար, մասնավորապես, CmBT-ը կիրառում է երկլեզու լեքսիկոնի ինդուկցիա կա Այնուհետև վերադարձնում է այս նախադասությունները, որպեսզի ստեղծվի կեղծ զուգահեռ կորպուս որպես MT համակարգի ավելացրական վարժեցման տվյալներ: We test the translation quality of ambiguous words on the MuCoW test suite, which was built to test the word sense disambiguation effectiveness of MT systems.  We show that our system improves on the translation of difficult unseen and low frequency word senses.', 'af': "Die prestasie van NMT-stelsels is drastieke in die verlede paar jaar verbeter, maar die vertaling van multisensiewe woorde stel nog steeds 'n uitdrukking. Omdat woord senses nie eenvoudig in die parallele korpora gebruik word om te onderwerp nie, is daar 'n oortredige gebruik van die mees dikwels sin in MT uitvoer. In hierdie werk, voorstel ons CmBT (Kontekstelik gemineerde Terugvertaling), â\x80\x99n toegang vir die verbetering van multisensiewe woord vertaling met vooraf-onderwerpende kruistale konteksiewe woord vertalings (CCWRs). Omdat hulle kontekslike sensitiviteit en hulle groot voor-onderwerking data, kan CCWRs maklik word senses wat mis of baie rarig is in parallele korpora gebruik word om MT te oefen. Spesifieke, CmBT toewend twee-lingse leksikoon induksie op CCWRs na myne sin-spesifieke teikensette van 'n monolingese datastel, En dan terug-vertaling hierdie setings om 'n pseudo parallele korpus te genereer as addisionele onderwerking data vir 'n MT stelsel. Ons probeer die vertalingskwaliteit van onbediende woorde op die MuCoW toets suite, wat gebou is om die woord sens ontsamming effektiviteit van MT stelsels te test. Ons wys dat ons stelsel verbeter op die vertaling van moeilike ongesien en lae frekwensiewoord senses.", 'az': 'NMT sistemlərin performansı son bir neçə il içində drastik tərzdə yaxşılaşdı, amma çoxlu hiss sözlərin çeviri hələ də çətinliklərə bənzəyir. Söz duyguları təhsil etmək üçün istifadə edilən paralel korporada eyni olaraq göstərilmədiklərindən dolayı, MT çıxımında ən çox hisslərin istifadəsi var. Bu işdə, CmBT (müxtəlif-mined Back-Translation) təklif edirik, çoxlu hissəli söz çevirimi öyrənmək üçün çoxlu təhsil edilmiş, çoxlu dil müxtəlif söz təsirlərini (CCWRs) yaxşılaşdırmaq üçün təklif edirik. Çünki onların müxtəlif hissətləri və böyük öyrənmə məlumatları üzündən CCWR MT təhsil etmək üçün istifadə edilən paralelə korporada istifadə edilən söz duygularını asanlıqla yaxınlaşdıra bilər. Və sonra bu cümlələri MT sistemi üçün bir pseudo paralel korpus yaratmaq üçün artıq təhsil məlumatları olaraq geri çevirir. Biz MuCoW sınama sütusu üzerində müəyyən sözlərin çevirilməsini test edirik. Bu sözlərin MT sistemlərinin imtahana çəkmək üçün inşa edilmişdir. Biz sistemimizin çətin görmədiyimiz və düşük frekans sözlərin hisslərinin çevirildiyini göstəririk.', 'ca': "El rendiment dels sistemes NMT ha millorat dràsticament en els últims anys, però la traducció de paraules multisensorials encara representa un repte. Com que els sentits de paraula no són representats uniformementen el corpore paral·lel que s'utilitzen per a formar-se, hi ha un ús excessiu del sentit més freqüent en la producció MT. En aquest treball, proposem CmBT, un enfocament per millorar la traducció de paraules multisensorials que utilitzen representacions de paraules contextuals translingües (CCWRs) pré-entrenades. Gràcies a la seva sensibilitat contextual i a les seves grans dades de pré-entrenament, els CCWR poden capturar fàcilment sentits de paraules que falten o molt rars en corpores parallels utilitzats per entrenar MT. Concretament, el CmBT aplica inducció bilingüe de lexicòns en CCWR a minerar frases de mira específices per sentits d'un conjunt de dades monolingües, i després torna a traduir aquestes frases per generar un corpus pseudoparal·lel com a dades adicionals d'entrenament per un sistema MT. We test the translation quality of ambiguous words on the MuCoW test suite, which was built to test the word sense disambiguation effectiveness of MT systems.  Mostrem que el nostre sistema millora en la traducció de difícils sentits de paraules invisibles i de baixa freqüència.", 'bn': 'বিগত কয়েক বছরে এনএমটি সিস্টেমের প্রদর্শনীর প্রভাব বেড়ে গেছে, কিন্তু বহুবেক-মানুষের কথার অনুবাদ এখনো একটা চ্যালেঞ্জের মা যেহেতু প্রশিক্ষণের জন্য ব্যবহার করা প্যারালেল কর্পোরায় শব্দের সেন্স প্রতিনিধিত্ব করা হয়নি, এমটি আউটপুটের সবচেয়ে বেশী প্রায় এই কাজে আমরা সিএমবিটি (বিভিন্ন মিনিট ব্যাক-ট্রান্সভার) প্রস্তাব করি, পূর্বে প্রশিক্ষিত বিভিন্ন ভাষায় প্রতিনিধিত্বের প্রতিনিধিত্বের জন্য মাল্ট তাদের বিদ্যমান সংবেদনশীল এবং তাদের বিশাল প্রশিক্ষণের তথ্যের কারণে সিসিডিওবার্স সহজে শব্দের সেন্স গ্রহণ করতে পারে যারা মাত্রাল কর্পোরায় অনুপস্থিত অথবা খুব ব বেশি দুর্লভাবে এমবিটি প্রশিক্ষণ দেয়া হয়ে  and then back-translates these sentences to generate a pseudo parallel corpus as additional training data for an MT system.  আমরা মুকোউড পরীক্ষা স্যুটের ব্যাপারে অনুবাদের মান পরীক্ষা করি, যা এমটি সিস্টেমের বিভ্রান্তির কার্যকর পরীক্ষা করার জন্য ত আমরা দেখাচ্ছি যে আমাদের সিস্টেম অদৃশ্য এবং কম ফ্রাইভেন্স শব্দের অনুবাদের ব্যাপারে উন্নত হয়েছে।', 'bs': 'Proizvodnja NMT-ovih sustava u proteklih nekoliko godina je drastično poboljšala, ali prevod višesmislenih riječi još uvijek predstavlja izazov. Budući da se osjećaji riječi ne predstavljaju uniformno u paralelnoj korpori korištenoj za obuku, postoji prekomjerna upotreba najčešćeg smisla u izlazu MT-a. U ovom poslu predlažemo CmBT (kontekstualno-mineralno-prevod), pristup unaprjeđivanju višesmislanskog prevoda riječima koji utječu na predobučene cross-language contextual riječi (CCWRs). Zbog njihove kontekstualne osjetljivosti i njihovih velikih podataka pre obuke, CCWRs može lako uhvatiti osjećaje riječi koje nedostaju ili vrlo rijetke u paralelnom korporaciji koriste za obuku MT-a. Posebno, CmBT primjenjuje indukciju dvojezičkog leksikona na CCWRs-a na moju ciljnu rečenicu iz jednojezičkog seta podataka, I onda ponovo prevodi te rečenice kako bi stvorili pseudoparalelni korpus kao dodatne podatke o obuci za MT sistem. Mi testiramo kvalitet prevoda neobičnih riječi na MuCoW test apartmanu, koji je izgrađen kako bi testirao učinkovitost disambiguacije reči MT sustava. Pokazujemo da se naš sistem poboljšava na prevodu teških nevidljivih i niskih čula riječi.', 'cs': 'Výkon NMT systémů se v posledních letech drasticky zlepšil, ale překlad multismyslových slov stále představuje výzvu. Vzhledem k tomu, že slovní smysly nejsou reprezentovány rovnoměrně v paralelních korpusech používaných pro trénink, dochází k nadměrnému využití nejčastějšího smyslu v MT výstupu. V této práci navrhujeme CmBT (Contextually-mined Back-Translation), přístup ke zlepšení multismyslového překladu slov s využitím předškolených cross-jazyčných kontextových reprezentací slov (CCWR). Díky kontextové citlivosti a velkým předtréninkovým datům mohou CCWR snadno zachytit slovní smysly, které chybí nebo jsou velmi vzácné v paralelních korpusech používaných k tréninku MT. Konkrétně, CmBT aplikuje dvojjazyčné lexikonové indukce na CCWR k dolování cílových vět specifických pro smysl z jednojjazyčného datového souboru. a pak tyto věty zpět přeloží a vytvoří pseudo paralelní korpus jako další tréninková data pro MT systém. Testujeme kvalitu překladu nejednoznačných slov na testovací sadě MuCoW, která byla vytvořena pro testování efektivity rozšiřování slovních smyslů MT systémů. Ukazujeme, že náš systém zlepšuje překlad obtížně neviditelných a nízkofrekvenčních slovních smyslů.', 'et': 'NMT süsteemide jõudlus on viimastel aastatel märkimisväärselt paranenud, kuid mitmetasandiliste sõnade tõlkimine kujutab endiselt endast väljakutset. Kuna sõna meeled ei ole ühtlaselt esindatud paralleelsetes korpustes, mida kasutatakse koolituseks, kasutatakse MT väljundis kõige sagedasemat tähendust liigselt. Käesolevas töös pakume välja CmBT (Contextually-mined Back-Translation), lähenemisviisi mitme tähendusega sõnatõlke parandamiseks, kasutades eelnevalt väljaõpetatud keeleüleseid kontekstuaalseid sõnarepresentatsioone (CCWR). Tänu kontekstitundlikkusele ja suurtele koolituseelsetele andmetele saavad CCWR-d hõlpsasti jäädvustada sõnatundeid, mis puuduvad või väga haruldased paralleelsetes korpustes, mida kasutatakse MT koolitamiseks. Täpsemalt rakendab CmBT CCWR-de suhtes kahekeelset leksikoni induktsiooni, et kaevandada meelepõhiseid sihtlauseid ühekeelsest andmekogumist, ja seejärel tõlgib need laused tagasi, et luua pseudo paralleelne korpus täiendavate koolitusandmetena MT süsteemi jaoks. Testime mitmetähenduslike sõnade tõlkekvaliteeti MuCoW testikomplektis, mis on ehitatud MT süsteemide mõistete eristamise efektiivsuse testimiseks. Näitame, et meie süsteem parandab raskete nähtamatute ja madala sagedusega sõnameelte tõlkimist.', 'fi': 'NMT-järjestelmien suorituskyky on parantunut huomattavasti viime vuosina, mutta moniaististen sanojen kääntäminen on edelleen haasteellista. Koska sanaaistit eivät ole edustettuina tasaisesti rinnakkaisissa korpusissa, joita käytetään harjoitteluun, yleisintä termiä käytetään liikaa MT-tuotoksessa. Tässä työssä ehdotamme CmBT (Contextually-mined Back-Translation), lähestymistapaa monikielisen sanakäännöksen parantamiseen hyödyntäen esikoulutettuja monikielisiä kontekstuaalisia sanaesityksiä (CCWR). Koska CCWR:t ovat kontekstuaalisen herkkiä ja laajoja esikoulutusta edeltäviä tietoja, ne voivat helposti tallentaa sanaaistit, jotka puuttuvat tai ovat hyvin harvinaisia rinnakkaisissa korpusissa, joita käytetään MT:n kouluttamiseen. ja sitten kääntää nämä lauseet takaisin luodakseen pseudorinnakkaisen korpusen harjoitustietona MT-järjestelmälle. Moniselitteisten sanojen käännöslaatua testataan MuCoW testipaketilla, joka rakennettiin testaamaan MT-järjestelmien sanaaistin erottelutehokkuutta. Osoitamme, että järjestelmämme parantaa vaikeasti havaittavien ja matalataajuuksisten sanaaistien kääntämistä.', 'sk': 'Učinkovitost sistemov NMT se je v zadnjih nekaj letih drastično izboljšala, vendar prevajanje večsmiselnih besed še vedno predstavlja izziv. Ker besedni čuti niso enakomerno predstavljeni v vzporednih korpusih, ki se uporabljajo za trening, obstaja pretirana uporaba najpogostejšega pomena v MT izhodu. V tem delu predlagamo CmBT (Contextually-mined Back-Translation), pristop za izboljšanje večpomenskega prevajanja besed z vnaprej usposobljenimi večjezičnimi kontekstualnimi besednimi reprezentacijami (CCWR). Zaradi svoje kontekstualne občutljivosti in velikih podatkov pred usposabljanjem lahko CCWR zlahka zajamejo besedne čute, ki manjkajo ali so zelo redki v vzporednih korpusih, ki se uporabljajo za usposabljanje MT. Zlasti CmBT uporablja dvojezično indukcijo leksikona na CCWR za izbiranje ciljnih stavkov, specifičnih za čutek, iz enojezičnega nabora podatkov, in nato nazaj prevede te stavke, da ustvari psevdo paralelni korpus kot dodatne podatke o usposabljanju za sistem MT. Kakovost prevajanja dvoumnih besed testiramo na testiranju MuCoW, ki je bil zgrajen za testiranje učinkovitosti razločitve besednega pomena sistemov MT. Pokazujemo, da naš sistem izboljšuje prevajanje težkih nevidnih in nizkofrekvenčnih besednih čutov.', 'ha': "Tafiyar da na'urar NMT masu ƙari akan shẽkaru kaɗan da suka shige, kuma fassarar magana masu multi-sance bada ƙari yana da wata musamma. Since word senses are not represented uniformly in the parallel corpora used for training, there is an excessive use of the most frequent sense in MT output.  @ info: whatsthis Du da hisia'arin da data masu girma na zaman mafaka, CCWRs za su iya ɗauki sauri da sauri masu saka da za'a gane maganar da ko kuma ma'a sauri cikin shirin da aka yi amfani da shi a fasalin MT. Kayya, CmBT na amfani da fasalin leksikon biyu na lugha kan CCWRs zuwa maganar-muhimmanci na gane-ƙayyade daga danne na mantoli-harshen, dictionary variant Munã jarraba fassarar sarrafin maganar kwamfyuta a kan shawarar MuCoW, wanda aka gina dõmin a jarraba magana masu hankali da bambanci da amfani na tsarin MT. Tuna nũna cewa, ma'anarmu yana ƙaranci a kan fassarar magana masu nauyi da sauri.", 'he': 'ביצועים של מערכות NMT השתפרו באופן דרסטי בשנים האחרונות, אך התרגום של מילים רבות-חושים עדיין יוצר אתגר. מכיוון שהחושים המיליים לא מייצגים באופן יחסי בתוך הקופורה המזורית שמשתמשת לאימונים, יש שימוש מוגזם של החוש הכי תדיר בתוצאה MT. בעבודה הזו, אנו מציעים CmBT (התרגום האחורי מוכר בקשר לתחום), גישה לשיפור התרגום מילים רבות-חושים בגלל רגישות הקונטקטית שלהם ובנתונים גדולים לפני האימונים שלהם, CCWRs יכולים בקלות לתפוס חושים מילים חסרים או נדירים מאוד בקופורה מקבילה שמשתמשים לאימונים MT. במיוחד, CmBT משתמש בהדליקת לקסיקון שתיים לשונים על CCWRs למשפטי מטרה מסויימים לחוש ממוסד מידע מונולשוני, ואז מתרגם את המשפטים האלה בחזרה כדי ליצור קורפוס משותף pseudo כמידע אימון נוסף למערכת MT. אנחנו בודקים את איכות התרגום של מילים ספורות בסוויטת המבחנים MuCoW, שנבנתה כדי לבדוק את היעילות של המילה חוש הפרעה של מערכות MT. אנחנו מראים שהמערכת שלנו משתפרת בתרגום של תחושות מילים בלתי נראות קשות ותדירות נמוכה.', 'bo': 'NMT མ་ལག་གི་སྒྲུབ་གྲངས་ཀ་དེ་འདས་བའི་ལོ་ངོས་ཁྲོད་ཀྱི་རིང་ལ་ཕར་རྒྱས་གཏོང་བ་ཡིན་ནའང་ཕལ་ཆེན་ཚོའི་སྐད་ཡིག Since word senses are not represented uniformly in the parallel corpora used for training, there is an excessive use of the most frequent sense in MT output. འོན་ཀྱང་། ང་ཚོས་CmBT (རྗེས་སུ་ཀླད་པའི་ཕྱིར་ཡིག་གཟུགས་ནང་དུ་ཡོད་པའི་)སྤྲོད་ཀྱི་ཐབས་ལམ་ཞིག་ལ་ཕར་ཚེས དེའི་རྒྱུ་མཚན་ནི་ཁོང་ཚོའི་contextual sensitivity་དང་ཁོང་ཚོའི་སྔོན་གྲངས་བསྡུར་བའི་གནས་ཚུལ་མང་པོ་ཞིག་ལས་ CCWRs་ནང་དུ་བརླག་སྟོར་ཞུགས་པ་དང་ལས་ཉུང་བའི་ཚོར་མཁན་ཚོགས་རྣམས་འདུག དེ་ནས་ཚིག་ཕྱིར་ཕར་སླར་ཚུལ་འདི་ཚོགས་སྨུག་གཞུང་གི་མཐུད་ལམ་ལུགས་གཞན་ཞིག་བཟོ་བ་ཡིན། We test the translation of ambiguous words on the MuCoW test suite. Which was built to test the word sense disambiguation efficiency of MT systems. ང་ཚོའི་མ་ལག་གི་སྟངས་པར་དཀའ་ངལ་མེད་པའི་དབྱེ་རིམ་གྱི་ནང་དུ་ཚད་དཀའ་ངལ་མྱུར་བའི་ཐ་སྙད་ཚིག་བཅས་ལ', 'jv': 'Sistem NMT sing ditambah akeh sing luwih dumadhi nang sampeyan sing dumadhi, nganggep tarjamahan kelas perangkapan liyane sing isih bantayan Mungkin kelas nang kelas seneng dadi nggawe sapa perusahaan banget nggawe gerakan diolah, dadi, sing wis ngerasakno akeh banter seneng pisan banget neng MT. Nang barêng-barêng iki, kéné gunakake CmBT (context-mined back-translation), supoyo nggawe gerasane supoyo urip banter-sene multi-sene iwakken nglanggar tarjamahan luwih banter-sene perangkapan langgar sami bisa banter-sene perangkapan langgar sami pasar cara nggawe geranggap (CWS). Punika dipunangé perusahaan Sensitif lan akeh bantên prelimunipun kuwi, CmBT iso nguasai perusahaan winih dhéwé kuwi wis dipunangé awak dhéwé. Digasakno, CmBT iso nguasai akeh akeh langgar sampeyan nggo MT. Perusahaan langgar, CmBT iso nguasai perusahaan langgar sampeyan ingkang dipunangé kapan cuasakno sing perusahaan winih-perusahaan MT Awak dhéwé éntuk kaliwat itmaci gampang kanggo masalah urip mung MuCow, sing wis nggawe kanggo ujian pergambar kuwi tindakan sistem MT sing bisa nguasai perbudhakan maneh. Awak dhéwé éntuk sistem nambah ing njujug-njujug kuwi mau.'}
{'en': 'Findings of the WMT 2021 Shared Task on Quality Estimation', 'ar': 'نتائج مهمة WMT 2021 المشتركة حول تقدير الجودة', 'fr': "Résultats de la tâche partagée WMT 2021 sur l'estimation de la qualité", 'pt': 'Conclusões da Tarefa Compartilhada do WMT 2021 sobre Estimativa de Qualidade', 'es': 'Resultados de la tarea compartida del WMT 2021 sobre estimación de la calidad', 'zh': 'WMT 2021质评共同任务', 'ja': '品質見積もりに関するWMT 2021共有タスクの調査結果', 'hi': 'गुणवत्ता अनुमान पर डब्ल्यूएमटी 2021 साझा कार्य के निष्कर्ष', 'ru': 'Результаты совместной задачи WMT 2021 по оценке качества', 'ga': 'Torthaí Thasc Comhroinnte WMT 2021 ar Mheastachán Cáilíochta', 'el': 'Ευρετήματα της Κοινής Εργασίας για την Εκτίμηση της Ποιότητας', 'ka': 'WMT 2021 გაყოფილი საქაღალდე განსაზღვრება', 'hu': 'A WMT 2021 minőségbecsléssel kapcsolatos megosztott feladatának megállapításai', 'it': 'Risultati del compito condiviso WMT 2021 sulla stima della qualità', 'kk': 'WMT 2021 жылы сапа оқиғасындағы ортақ тапсырманың іздеу', 'lt': '2021 m. VMT bendros kokybės vertinimo užduoties išvados', 'mk': 'Најдовме заедничка задача за проценка на квалитетот во ВМТ 2021', 'ms': 'Kesimpulan Tugas Berkongsi WMT 2021 mengenai Estimasi Kualiti', 'ml': 'വിഎംടി 2021 പങ്കാളിയുള്ള ജോലിയുടെ കണ്ടുപിടിക്കുന്നു', 'mt': 'Sejbiet tad-WMT 2021 Kompitu Konġunt dwar l-Istima tal-Kwalità', 'mn': 'WMT 2021-ийн хуваалтын ажлын ололт', 'no': 'Finn av WMT 2021 delt oppgåve i kvalitetestimaen', 'pl': 'Wyniki wspólnego zadania WMT 2021 dotyczącego oceny jakości', 'sr': 'Pronaðenja WMT 2021 podeljenog zadatka o procjeni kvalitete', 'ro': 'Concluziile misiunii comune privind estimarea calității WMT 2021', 'si': 'WMT 2021 විශේෂතාව අනුමාණයේ සමාගත වැඩක් හොයාගන්න', 'so': 'Findings of the WMT 2021 Shared Shaqo on Tusaale Estimation', 'sv': 'Resultat av WMT 2021 delad uppgift om kvalitetsbedömning', 'ta': 'தரம் கணக்கீட்டில் WMT 2021 பகிர்ந்த பணியின் திட்டங்கள்', 'ur': 'WMT 2021 کے مشترک ٹاکس کی آزمائش کیفیت آزمائش پر', 'uz': 'Name', 'vi': 'Kết quả của tập đoàn về ước lượng chất lượng WM 2021', 'bg': 'Резултати от общата задача за оценка на качеството на ММТ 2021', 'da': "Resultater af WMT 2021's delte opgave om kvalitetsestimering", 'hr': 'Pronaći zajednički zadatak WMT 2021 o procjeni kvalitete', 'de': 'Ergebnisse des WMT 2021 Gemeinsame Aufgabe zur Qualitätsschätzung', 'nl': 'Resultaten van de WMT 2021 Gedeelde Taak Kwaliteitsschatting', 'ko': 'WMT 2021 품질 평가 공유 작업의 발견', 'sw': 'Matokeo ya kazi ya WMT 2021 iliyoshirikiana kwenye Hisabu', 'fa': 'پیدا کردن کار مشترک WMT ۲۰۱۱ در ارزیابی کیفیت', 'af': 'Finnings van die WMT 2021 Gedeelde Opdrag op Kwaliteit Estimasie', 'tr': 'WMT 2021 Maýylyklyk Hesaplamasynda Paýlaşan Görevlerin Tapylmak', 'sq': 'Zbulimet e detyrës së përbashkët të WMT 2021 mbi vlerësimin e cilësisë', 'am': 'አዲስ ዶሴ ፍጠር', 'hy': '2021 թվականի համաշխարհային տեխնոլոգիայի վերաբերյալ կազմակերպված որակի գնահատման հանձնարարությունները', 'az': 'WMT 2021 ≈ü…ôkil qiym…ôti haqqƒ±nda payla≈üƒ±lan i≈üin tapƒ±lmasƒ±', 'id': 'Penemuan dari WMT 2021 Task Berkongsi tentang Perkiraan Kualitas', 'bn': 'উইএমটি ২০২১ সালের শেয়ার করা কাজের অনুসন্ধান', 'ca': 'Resultats de la Task Shared on Quality Estimation de la WMT 2021', 'bs': 'Pronađenja WMT 2021. zajedničkog zadatka o procjeni kvalitete', 'cs': 'Zjištění společného úkolu WMT 2021 v oblasti odhadu kvality', 'et': 'WMT 2021 kvaliteedi hindamise ühisülesande tulemused', 'fi': 'WMT 2021:n laadunarviointia koskevan yhteisen tehtävän havainnot', 'jv': 'Finding', 'sk': 'Ugotovitve skupne naloge WMT 2021 o oceni kakovosti', 'ha': 'KCharselect unicode block name', 'bo': 'Findings of the WMT 2021 Shared Task on Quality Estimation', 'he': 'מציאות משימה משותפת WMT 2021 על הערכת איכות'}
{'en': 'We report the results of the WMT 2021 shared task on Quality Estimation, where the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels. This edition focused on two main novel additions : (i) ', 'pt': 'Relatamos os resultados da tarefa compartilhada do WMT 2021 sobre Estimativa de Qualidade, onde o desafio é prever a qualidade da saída de sistemas de tradução automática neural nos níveis de palavras e frases. Esta edição concentrou-se em duas novidades principais: (i) previsão para idiomas não vistos, ou seja, configurações de tiro zero e (ii) previsão de frases com erros catastróficos. Além disso, novos dados foram divulgados para vários idiomas, especialmente dados pós-editados. As equipes participantes de 19 instituições submeteram ao todo 1263 sistemas para diferentes variantes de tarefas e pares de idiomas.', 'ar': 'نقوم بالإبلاغ عن نتائج مهمة WMT 2021 المشتركة حول تقدير الجودة ، حيث يتمثل التحدي في التنبؤ بجودة مخرجات أنظمة الترجمة الآلية العصبية على مستوى الكلمات والجمل. ركزت هذه الطبعة على إضافتين جديدتين رئيسيتين: (1) التنبؤ باللغات غير المرئية ، أي إعدادات اللقطة الصفرية ، و (2) التنبؤ بالجمل ذات الأخطاء الكارثية. بالإضافة إلى ذلك ، تم إصدار بيانات جديدة لعدد من اللغات ، وخاصة البيانات المحررة لاحقًا. قدمت الفرق المشاركة من 19 مؤسسة ما مجموعه 1263 نظامًا إلى متغيرات مهام مختلفة وأزواج لغوية.', 'es': 'Presentamos los resultados de la tarea compartida del WMT 2021 sobre la estimación de la calidad, donde el desafío es predecir la calidad de la producción de los sistemas de traducción automática neuronal a nivel de palabras y oraciones. Esta edición se centró en dos novedades principales: (i) predicción de lenguajes no vistos, es decir, escenarios de tiro cero, y (ii) predicción de oraciones con errores catastróficos. Además, se publicaron nuevos datos para varios idiomas, especialmente datos post-editados. Los equipos participantes de 19 instituciones presentaron un total de 1263 sistemas a diferentes variantes de tareas y combinaciones de idiomas.', 'fr': "Nous présentons les résultats de la tâche partagée WMT 2021 sur l'estimation de la qualité, où le défi consiste à prédire la qualité de la sortie des systèmes de traduction automatique neuronale au niveau des mots et des phrases. Cette édition s'est concentrée sur deux nouveaux ajouts principaux\xa0: (i) la prédiction pour les langues invisibles, c'est-à-dire les réglages de tir zéro, et (ii) la prédiction de phrases comportant des erreurs catastrophiques. En outre, de nouvelles données ont été publiées pour un certain nombre de langues, en particulier des données post-éditées. Les équipes participantes de 19 institutions ont soumis au total 1263 systèmes à différentes variantes de tâches et paires de langues.", 'ja': '私たちは、WMT 2021の品質推定に関する共有タスクの結果を報告します。ここでの課題は、単語および文章レベルでのニューラル機械翻訳システムの出力の品質を予測することです。このエディションは、(i)見えない言語の予測、すなわちゼロショット設定、および(ii)壊滅的なエラーを伴う文章の予測という2つの主な新規追加に焦点を当てた。さらに、いくつかの言語、特に編集後のデータの新しいデータがリリースされました。19の機関からの参加チームは、さまざまなタスクバリアントと言語ペアに合計1263のシステムを提出した。', 'zh': '臣等白WMT 2021质料之同务,其挑战于单词句之品第测神经机器翻译系统输出之量。 本版重点二要:(i)不见之占,即零镜头设,及(ii)占有灾难性过之句。 陈若干语文新数,特为编辑后数。 自19一局参赛团队异务变体语言凡1263系统。', 'hi': 'हम गुणवत्ता अनुमान पर डब्ल्यूएमटी 2021 साझा कार्य के परिणामों की रिपोर्ट करते हैं, जहां चुनौती शब्द और वाक्य स्तरों पर तंत्रिका मशीन अनुवाद प्रणालियों के आउटपुट की गुणवत्ता की भविष्यवाणी करना है। यह संस्करण दो मुख्य उपन्यास परिवर्धन पर केंद्रित है: (i) अनदेखी भाषाओं के लिए भविष्यवाणी, यानी शून्य-शॉट सेटिंग्स, और (ii) भयावह त्रुटियों के साथ वाक्यों की भविष्यवाणी। इसके अलावा, कई भाषाओं के लिए नया डेटा जारी किया गया था, विशेष रूप से पोस्ट-संपादित डेटा। 19 संस्थानों की भाग लेने वाली टीमों ने विभिन्न कार्य रूपों और भाषा जोड़े के लिए कुल मिलाकर 1263 प्रणालियों को प्रस्तुत किया।', 'ru': 'Мы сообщаем о результатах совместной задачи WMT 2021 по оценке качества, где задача заключается в прогнозировании качества вывода систем нейронного машинного перевода на уровне слов и предложений. В этом издании основное внимание уделялось двум новым дополнениям: (i) прогнозированию невидимых языков, т.е. настройке нулевого выстрела, и (ii) прогнозированию предложений с катастрофическими ошибками. Кроме того, были опубликованы новые данные по ряду языков, особенно после редактирования данных. Участвовавшие группы из 19 учреждений представили в общей сложности 1263 системы для различных вариантов задач и языковых пар.', 'ga': 'Tuairiscímid torthaí tasc comhroinnte WMT 2021 ar Mheastachán Cáilíochta, áit a bhfuil sé ina dhúshlán cáilíocht aschuir córais néaraistriúcháin meaisín a thuar ag leibhéil focal agus abairte. Dhírigh an t-eagrán seo ar dhá phríomhbhreisiú úrscéalta: (i) tuar do theangacha nach bhfacthas riamh roimhe, i.e. socruithe náid, agus (ii) abairtí le hearráidí tubaisteacha a thuar. Ina theannta sin, eisíodh sonraí nua do roinnt teangacha, go háirithe sonraí iar-eagarthóireachta. Chuir foirne rannpháirteacha ó 19 n-institiúid 1263 córas ar fad isteach chuig éagsúlachtaí tascanna agus péirí teangacha éagsúla.', 'ka': 'WMT 2021 წარმოდგენით გაყოფილი საქაღალდე განსაზღვრებაზე, სადაც განსაზღვრება არის წარმოდგენა ნეიროლური მანქანის გაგრძელება სიტყვების და სიტყვების დონეზე. ამ რედაქტის კონუქტირებულია ორი პრომენტის დამატებით: i) წარმოდგენა ენების წარმოდგენა, მაგალითად 0-სტარტის პარამეტრებით, და ii) კატაროტური შეცდომებით წარმოდგენა. დამატებით, ახალი მონაცემები რამდენიმე ენათებისთვის გახსნა, განსაკუთრებით დარედაქტირებული მონაცემები. 19 ინსტუტისტების დაწყვეტილებელი ჯგუფები ყველაფერად 1263 სისტემაში განსხვავებული სამუშაო სამუშაო გარიანტებში და ენაზო ჯგუფებისთვის', 'hu': 'Beszámoljuk a WMT 2021 közös feladatának eredményeit a Minőségbecsléssel kapcsolatban, ahol a kihívás az idegi gépi fordító rendszerek kimenetének minőségének előrejelzése szó- és mondatszinten. Ez a kiadás két fő regény kiegészítésére összpontosított: (i) a láthatatlan nyelvek előrejelzése, azaz a nulla lövés beállítások, és (ii) a katasztrofális hibákkal rendelkező mondatok előrejelzése. Ezenkívül új adatok jelentek meg számos nyelvre, különösen az utólagos szerkesztéssel rendelkező adatokra. 19 intézmény résztvevő csapatai összesen 1263 rendszert nyújtottak be különböző feladatváltozatokra és nyelvpárokra.', 'el': 'Αναφέρουμε τα αποτελέσματα της κοινής εργασίας για την Εκτίμηση Ποιότητας, όπου η πρόκληση είναι να προβλεφθεί η ποιότητα της παραγωγής νευρικών συστημάτων μηχανικής μετάφρασης σε επίπεδο λέξεων και προτάσεων. Η έκδοση αυτή επικεντρώθηκε σε δύο κύριες προσθήκες μυθιστορήματος: (i) πρόβλεψη για αόρατες γλώσσες, δηλαδή ρυθμίσεις μηδενικού πυροβολισμού, και (ii) πρόβλεψη προτάσεων με καταστροφικά λάθη. Επιπλέον, κυκλοφόρησαν νέα δεδομένα για μια σειρά γλωσσών, ειδικά δεδομένα μετά την επεξεργασία. Συμμετέχοντες ομάδες από 19-ιδρύματα υπέβαλαν συνολικά 1263 συστήματα σε διαφορετικές παραλλαγές εργασιών και γλωσσικά ζεύγη.', 'it': "Riportiamo i risultati del compito condiviso WMT 2021 sulla Quality Estimation, dove la sfida è prevedere la qualità dell'output dei sistemi neurali di traduzione automatica a livello di parole e frasi. Questa edizione si è concentrata su due principali aggiunte al romanzo: (i) predizione per linguaggi invisibili, cioè impostazioni zero-shot, e (ii) predizione di frasi con errori catastrofici. Inoltre, sono stati rilasciati nuovi dati per un certo numero di lingue, in particolare per i dati post-modificati. I team partecipanti di 19 istituzioni hanno presentato complessivamente 1263 sistemi a diverse varianti di attività e coppie linguistiche.", 'kk': 'Біз WMT 2021 жылы сапалық оқиға туралы ортақ тапсырманың нәтижесін хабарлаймыз. Бұл мәселе сөз мен сөз деңгейінде невралдық компьютердің аудару жүйелерінің шығысының сапалын көрсету үші Бұл өзгерістер екі негізгі романдың қосымшасына назар ауыстырылды: i) көрсетілмеген тілдер үшін, мысалы, нөл- шарт параметрлері, және ii) қатты қателермен сөйлемелерді таңдау. Қосымша, жаңа деректер бірнеше тілдер үшін, өзгеше өзгертілген соң деректер үшін шығарылды. 19 институттардың қатысушылары 1263 жүйелерді басқа тапсырмалар мен тіл екеуіне жіберді.', 'lt': 'Mes pranešame apie WMT 2021 bendros kokybės vertinimo užduoties rezultatus, kuriuose uždavinys – prognozuoti nervinių mašinų vertimo sistemų išėjimo kokybę žodžių ir sakinių lygiu. Šiame leidinyje daugiausia dėmesio buvo skiriama dviem naujiems papildymams: i) nenumatytų kalbų prognozėms, t. y. nulinės nuotraukos nustatymams, ir ii) katastrofinių klaidų sakinių prognozėms. Be to, buvo paskelbti nauji duomenys apie daugelį kalbų, ypač po redakcijos atliktus duomenis. Dalyvaujančios 19 institucijų grupės iš viso pateikė 1263 sistemas įvairiems užduočių variantams ir kalbų poroms.', 'mk': 'Ние ги известуваме резултатите од заедничката задача на ВМТ 2021 за проценка на квалитетот, каде што предизвикот е да се предвиди квалитетот на излезот на системите за превод на неврални машини на нивото на зборови и реченици. Оваа издание се фокусираше на две главни романски додатоци: (i) предвидување за невидени јазици, т.е. поставувања со нула снимка, и (ii) предвидување на реченици со катастрофални грешки. Покрај тоа, новите податоци беа објавени за голем број јазици, особено постуредени податоци. Учесничките тимови од 19 институции поднесоа вкупно 1263 системи на различни варијанти на задачи и јазички парови.', 'ms': 'Kami laporkan keputusan tugas berkongsi WMT 2021 mengenai Estimasi Kualiti, di mana cabaran adalah untuk meramalkan kualiti output sistem terjemahan mesin saraf pada aras perkataan dan kalimat. Edisi ini fokus pada dua tambahan novel utama: (i) ramalan bahasa yang tidak terlihat, iaitu tetapan 0-shot, dan (ii) ramalan kalimat dengan ralat katastrofik. Selain itu, data baru telah dilepaskan untuk beberapa bahasa, terutama data selepas-edit. Pasukan yang berpartisipasi dari 19 institusi dihantar secara keseluruhan 1263 sistem kepada variasi tugas dan pasangan bahasa yang berbeza.', 'ml': 'വാക്കും വാക്കിന്റെ നിലയില്\u200d ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിന്റെ ഫലം പ്രവചിപ്പിക്കാനുള്ള വിലാസങ്ങള്\u200d നമ്മള്\u200d വിവരിക്കുന്നു. ഈ എഡിഷന്\u200d രണ്ടു പ്രധാന ന നോവല്\u200d കൂട്ടിചേര്\u200dക്കുന്നതിനെ ശ്രദ്ധിച്ചിരിക്കുന്നു: (i) രഹസ്യമായ ഭാഷകള്\u200dക്ക് പ്രവചിക്കുന്നത്, ഉദാഹരണമായ പൂജ് കൂടാതെ പുതിയ വിവരങ്ങള്\u200d പല ഭാഷകള്\u200dക്കും, പ്രത്യേകിച്ച് എടുത്തിട്ടുള്ള വിവരങ്ങള്\u200dക്കായി വിട്ട 19 സ്ഥാനങ്ങളില്\u200d നിന്നും പങ്കുചേര്\u200dക്കുന്ന ഗ്രൂപ്പുകള്\u200d മുഴുവന്\u200d 1263 സിസ്റ്റത്തിലേക്കും വ്യത്യസ്ത ജോലി', 'mt': 'We report the results of the WMT 2021 shared task on Quality Estimation, where the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels.  Din l-edizzjoni ffukat fuq żewġ żidiet ġodda ewlenin: (i) tbassir għal lingwi mhux viżibbli, jiġifieri settijiet b’zero shot, u (ii) tbassir ta’ sentenzi b’żbalji katastrofiċi. Barra minn hekk, ġiet rilaxxata dejta ġdida għal għadd ta’ lingwi, speċjalment dejta wara l-edizzjoni. Timijiet parteċipanti minn 19-il istituzzjoni ssottomettew b’kollox 1263 sistema lil varjanti differenti ta’ kompiti u pari lingwistiċi.', 'mn': 'Бид WMT 2021 оны хуваалцах ажлын үр дүнг хэлж байна. Үүний хэмжээ болон өгүүлбэр дээр мэдрэлийн машин орчуулах системийн үр дүнг таамаглах шаардлагатай. Энэ бичлэг нь хоёр чухал шинэ нэмэлтүүд дээр анхаарлаа төвлөрсөн: i) харагдахгүй хэл, т.е. 0-шүлэлтийн тохиолдол, мөн ii) гамшигтай алдаа гэсэн үг. Түүнчлэн, олон хэл дээр шинэ өгөгдлийг, ялангуяа дараа өөрчлөгдсөн өгөгдлийн хувьд гаргасан. 19 байгууллагуудын оролцогчдын баг бүрэн 1263 системийг өөр ажлын хувьд, хэл хоёрын хувьд оруулсан.', 'no': 'Vi rapporterer resultatet av WMT 2021 delt oppgåve om kvalitetestimaet, der utfordringen er å foregå kvaliteten til utdata av neuralmaskinsomsetjingssystemet på ordet og setningsnivå. Denne utdataen fokuserte på to hovudlegg til roman: i) forhåndsvising for ugjennomsiktige språk, t.d. innstillingar for null- bilete, og ii) forhåndsvising av setningar med katastrofiske feil. I tillegg vart nye data sletta for mange språk, spesielt etter redigeringsdata. Deltakende grupper frå 19 institusjonar sendte totalt 1263 system til ulike oppgåvevariantar og språkopar.', 'ro': 'Raportăm rezultatele misiunii comune WMT 2021 privind estimarea calității, unde provocarea constă în prezicerea calității rezultatelor sistemelor de traducere automată neurală la nivelul cuvântului și propoziției. Această ediție s-a concentrat pe două adăugări principale ale romanului: (i) predicția pentru limbile nevăzute, adică setările zero-shot, și (ii) predicția propozițiilor cu erori catastrofale. În plus, au fost lansate date noi pentru o serie de limbi, în special date posteditate. Echipele participante din 19 instituții au prezentat în total 1263 de sisteme diferite variante de sarcini și perechi de limbi.', 'pl': 'Raportujemy wyniki wspólnego zadania WMT 2021 w zakresie Ocena Jakości, gdzie wyzwaniem jest przewidywanie jakości wyjścia neuronowych systemów tłumaczenia maszynowego na poziomie słowa i zdań. Niniejsza edycja skupiała się na dwóch głównych dodatkach powieści: (i) przewidywaniu niewidzialnych języków, czyli ustawień zero-shot oraz (ii) przewidywaniu zdań z katastrofalnymi błędami. Ponadto wydano nowe dane dla wielu języków, zwłaszcza dla danych po edycji. Uczestniczące zespoły z 19-tych instytucji przesłały całkowicie systemy 1263 do różnych wariantów zadań i par językowych.', 'sr': 'Prijavljujemo rezultate zajedničkog zadatka WMT 2021 o procjeni kvalitete, gdje je izazov predviđati kvalitetu izvedenja sustava prevoda neuralnih mašina na nivou reči i rečenica. Ovo izdanje se fokusiralo na dve glavne dodatke romana: i) predviđanje za nevidljive jezike, tj. postavke nule snimke, i ii) predviđanje rečenica sa katastrofalnim greškama. Osim toga, novi podaci su objavljeni za broj jezika, posebno posledičnih podataka. Učesnici tima iz 19 institucija potpuno su podnijeli 1263 sistema različitim variantima zadataka i jezičkim parovima.', 'so': 'Waxaan wargelinaynaa dhamaadka shaqada WMT 2021 ee loo qaybsaday qiyaastii Qiimaanta, meesha ay dhibaatadu tahay in la sii sheego qiimaha soo baxa nidaamka turjumidda maskaxda neurada ee hadalka iyo imtixaanka heerarka. Tahrirkan wuxuu ku kalsoonaaday laba qodob oo asal ah: (i) wax u sii sheegidda luuqadaha qarsoon, tusaale ahaan xariijiyo zero-shot, iyo (ii) wixii lagu sii sheegay dhibaatooyin khatar ah. In addition, new data was released for a number of languages, especially post-edited data.  Kooxa ka qayb-qaadashada 19 machadyo waxay u dhiibeen dhammaan 1263 nidaam oo u bedela shaqo kala duduwan iyo labo luuqad ah.', 'si': 'අපි WMT 2021 විශේෂතාව අනුමාණය සඳහා කැමති වැඩේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර මේ ප්\u200dරධානය ප්\u200dරධාන කතාවක් සම්බන්ධයක් දෙකක් විතරයි: (i) අනතුරු භාෂාවක් සඳහා ප්\u200dරශ්නයක්, ඉතින්, ශූන්ත-ශෝට් සැක ඒවගේම, අළුත් දත්ත කිසිම භාෂාවක් ගැන, විශේෂයෙන්ම පස්සේ සංපාදනය කරලා තියෙන්නේ. සංස්ථානය 19 වල සාමාන්\u200dය කණ්ඩායම් සම්පූර්ණයෙන් 1263 පද්ධතියට වෙනස් වෙනස් විදියට සහ භාෂාවක්', 'sv': 'Vi rapporterar resultaten av WMT 2021 delade uppgift om kvalitetsbedömning, där utmaningen är att förutsäga kvaliteten på resultatet av neurala maskinöversättningssystem på ord- och meningsnivå. Denna utgåva fokuserade på två huvudsakliga romantillägg: (i) förutsägelse för osynliga språk, dvs nollskottsinställningar, och (ii) förutsägelse av meningar med katastrofala fel. Dessutom släpptes nya data för ett antal språk, särskilt efterredigerade data. Deltagande grupper från 19 institutioner skickade in totalt 1263 system till olika uppgiftsvarianter och språkpar.', 'ta': 'நாம் WMT 2021 க்கு பங்கிடப்பட்ட பணியின் முடிவுகளை அறிவிக்கிறோம் தரம் கணக்கீடு, சொல்லு மற்றும் வாக்கியம் மட்டத்தில் புதிய இயந்திரத் மொழிமாற்ற இந்த தொகுப்பு இரண்டு முக்கிய புதிய புதிய கூட்டுதல் மீது கவனம் செலுத்தப்பட்டது: (i) மறைக்கப்படாத மொழிகளுக்கு எதிர்பார்ப்பு, அதாவது பூஜ்ஜியமா In addition, new data was released for a number of languages, especially post-edited data.  19 அமைப்புகளில் இருந்து பங்கீட்டு குழுக்கள் முழுவதும் 1263 அமைப்புகள் முழுமையாக முறைமையாக மாறிகள் மற்ற', 'ur': 'ہم نے WMT 2021 کے مشترک کام کا نتیجہ گزارا ہے کیلوٹی ارزش کے بارے میں، جہاں چال یہ ہے کہ نئورل ماشین ترجمہ سیسٹم کے نتیجہ کا انتظام کرنا ہے کلام اور کلام سطح پر۔ یہ ویڈیشن دو اصلی رمان اضافہ پر تمرکز کیا گیا ہے: i) غیب کی زبانوں کے لئے پیش بینی، یعنی صفر-شٹ تنظیم، اور ii) مصیبت کی خطاوں کے ساتھ کلمات کی پیش بینی. اس کے علاوہ، بہت سی زبانوں کے لئے نیا ڈاٹا آزاد کیا گیا ہے، مخصوصاً پوسٹ ویڈیٹ ڈاٹا۔ ۱۹ سازمان کے ٹیموں میں شامل ہونے کے لئے 1263 سیستم مختلف ٹیموں اور زبان جوڑوں پر جمع ہوئے۔', 'uz': 'Biz WMT 2021 bilan birlashtirilgan vazifaning natijalarini hisoblash mumkin. Bu yerda soʻz va gapirish darajada neyrolik tarjima tizimning hajmini predict qilishi mumkin. Bu taʼminlovchi ikkita asosiy novel qoʻshishlariga foydalanadi: (i) ichki tillar uchun oldingan oldingan moslamalar, balki katta xatolar bilan gapiradigan soʻzlarni koʻrsatish mumkin. Qoʻshimcha, boshqa tahrirlangan maʼlumot bir necha tillar uchun yangi maʼlumot olingan. 19 tashkilotlar bir guruhi 1263 tizimlarga boshqa vazifa varianteri va tillar qoʻllangan guruhga ega.', 'vi': 'Chúng tôi báo cáo kết quả của công việc chia sẻ WM 2021, phân tích Chất lượng tử, nơi thử thách là dự đoán chất lượng sản xuất của hệ thống dịch chuyển máy thần kinh ở mức lời và câu. Phiên bản này tập trung vào hai bước thêm chính sách: i) dự đoán ngôn ngữ vô hình, tức là thiết lập bắn không, và Thêm vào đó, một số ngôn ngữ đã được tiết lộ, đặc biệt là những dữ liệu sau biên tập. Nhóm tham gia từ tổ chức 19 đã gửi hoàn to àn hệ thống 1263 cho các biến thể thao khác nhau và cặp ngôn ngữ.', 'hr': 'Prijavljujemo rezultate zajedničkog zadatka WMT 2021-a o procjeni kvalitete, gdje je izazov predviđati kvalitetu izlaza sustava prevoda neuralnih strojeva na razini riječi i rečenica. Ovo izdanje se fokusiralo na dvije glavne dodatke romana: i) predviđenje za nevidljive jezike, tj. postavke nule snimke, i ii) predviđenje rečenica sa katastrofalnim greškama. Osim toga, novi podaci su objavljeni za broj jezika, posebno nakon uredbe podataka. Učesnički timovi iz 19 institucija potpuno su podnijeli 1263 sustava različitim variantima zadatka i jezičkim parovima.', 'nl': 'We rapporteren de resultaten van de WMT 2021 gedeelde taak op Kwaliteitsschatting, waarbij de uitdaging is om de kwaliteit van de output van neurale machinevertaalsystemen te voorspellen op woord- en zinnenniveau. Deze editie richtte zich op twee belangrijke nieuwe toevoegingen: (i) voorspelling voor onzichtbare talen, d.w.z. zero-shot settings, en (ii) voorspelling van zinnen met catastrofale fouten. Daarnaast werden nieuwe gegevens vrijgegeven voor een aantal talen, met name post-edited data. Deelnemende teams van 19-instellingen hebben in totaal 1263-systemen ingediend voor verschillende taakvarianten en taalparen.', 'da': 'Vi rapporterer resultaterne af WMT 2021 delte opgave om kvalitetsestimering, hvor udfordringen er at forudsige kvaliteten af output af neurale maskinoversættelsessystemer på ord- og sætningsniveau. Denne udgave fokuserede på to vigtigste romantilføjelser: (i) forudsigelse for usynlige sprog, dvs. nulskudsindstillinger, og (ii) forudsigelse af sætninger med katastrofale fejl. Derudover blev der frigivet nye data for en række sprog, især postredigerede data. Deltagende hold fra 19 institutioner indsendte i alt 1263 systemer til forskellige opgavevarianter og sprogpar.', 'bg': 'Докладваме резултатите от споделената задача на Оценка на качеството, където предизвикателството е да се предвиди качеството на изхода на невронните системи за машинен превод на ниво дума и изречение. Това издание се фокусира върху две основни допълнения на романа: (i) прогнозиране за невидими езици, т.е. настройки за нулев изстрел, и (ii) прогнозиране на изречения с катастрофални грешки. Освен това бяха публикувани нови данни за редица езици, особено за пост-редактираните данни. Участващите екипи от 19 институции представиха общо 1263 системи на различни варианти на задачи и езикови двойки.', 'de': 'Wir berichten über die Ergebnisse der gemeinsamen Aufgabe WMT 2021 zur Qualitätsschätzung, bei der die Herausforderung darin besteht, die Qualität der Ausgabe neuronaler maschineller Übersetzungssysteme auf Wort- und Satzebene vorherzusagen. Diese Ausgabe konzentrierte sich auf zwei wichtige Neuerungen: (i) Vorhersage für unsichtbare Sprachen, d.h. Null-Schuss Einstellungen, und (ii) Vorhersage von Sätzen mit katastrophalen Fehlern. Darüber hinaus wurden neue Daten für eine Reihe von Sprachen veröffentlicht, insbesondere für nachbearbeitete Daten. Teilnehmende Teams von 19-Institutionen legten insgesamt 1263-Systeme unterschiedlichen Aufgabenvarianten und Sprachpaaren vor.', 'id': 'Kami melaporkan hasil dari tugas berbagi WMT 2021 tentang Perkiraan Kualitas, di mana tantangannya adalah untuk memprediksi kualitas output dari sistem terjemahan mesin saraf pada tingkat kata dan kalimat. Edisi ini fokus pada dua tambahan novel utama: (i) prediksi bahasa yang tidak terlihat, i.e. pengaturan zero-shot, dan (ii) prediksi kalimat dengan kesalahan katastrofik. Selain itu, data baru dibebaskan untuk beberapa bahasa, terutama data post-edit. Participating teams from 19 institutions submitted altogether 1263 systems to different task variants and language pairs.', 'ko': '우리는 WMT 2021 품질 평가 공유 임무의 결과를 보고했는데 그 중의 도전은 단어와 문장 단계에서 신경기계 번역 시스템의 출력 품질을 예측하는 것이다.이 버전은 두 가지 주요 증가에 중심을 두었다. (i) 보이지 않는 언어, 즉 제로 렌즈 설정과 (ii) 재난적인 오류를 예측하는 문장이다.이 밖에 일부 언어의 새로운 데이터, 특히 편집된 데이터도 발표했다.19개 기구의 참여팀은 서로 다른 임무 변수와 언어 쌍에 1263개의 시스템을 제출했다.', 'fa': 'ما نتیجه\u200cهای کار مشترک WMT ۲۰۱۱ را در مورد ارزیابی کیفیت گزارش می\u200cدهیم، جایی که چالش برای پیش\u200cبینی کیفیت خروج سیستم ترجمه\u200cهای ماشین عصبی در سطح کلمه و جمله است. این ویژه روی دو اضافه\u200cهای رمانی اصلی تمرکز کرد: (i) پیش\u200cبینی برای زبان\u200cهای غیر\u200cبینی، یعنی تنظیمات تصاویر صفر، و (ii) پیش\u200cبینی از جمله\u200cها با اشتباه\u200cهای فاجعه\u200cای. علاوه بر این، داده های جدید برای تعداد زبان آزاد شده، مخصوصا داده های بعد از ویرایش شده. تیم\u200cهای مشترک از ۱۹ موسسات کاملا ۱۲۶۳ سیستم\u200cهای عملیات متفاوت و جفت زبان را ارائه دادند.', 'sw': 'Tunatoa taarifa matokeo ya kazi ya WMT 2021 iliyoshirikiana na Uhitimu, ambapo changamoto ni kutabiri kiwango cha matokeo ya mfumo wa kutafsiri mashine ya ujasiri katika ngazi za neno na hukumu. toleo hili lililenga lengo la kuongezea riwaya mbili kuu: (i) kutabiri kwa lugha isiyo fichikana, yaani, mazingira yasiyo ya risasi sifuri, na (ii) kutabiri hukumu zenye makosa makubwa. In addition, new data was released for a number of languages, especially post-edited data.  Timu za kushiriki kutoka taasisi 19 zilitoa mifumo 1263 kwa ajili ya mabadiliko ya kazi na wanaume wa lugha tofauti.', 'af': 'Ons rapporteer die resultate van die WMT 2021 gedeelde taak op Kwaliteit Estimasie, waar die uitdrukking is om die kwaliteit van die uitvoer van die neurale masjien vertalingsstelsels te voorskou op die woord en setvlakke. Hierdie uitsiging fokus op twee hoofde novel byvoegings: i) voorskou vir ongesiende tale, bv. nul-skoot instellings, en ii) voorskou van teikene met katastrofiske foute. In addition, new data was released for a number of languages, especially post-edited data. Aangedeelde teams van 19 instellings het altyd 1263 stelsels aan verskillende taak variante en taal paar ingestuur.', 'sq': 'We report the results of the WMT 2021 shared task on Quality Estimation, where the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels.  Kjo edicion u përqëndrua në dy shtimet kryesore të novelit: (i) parashikimin për gjuhët e padukshme, pra rregullimet zero-shot dhe (ii) parashikimin e fjalëve me gabime katastrofike. Përveç kësaj, të dhënat e reja u lëshuan për një numër gjuhësh, veçanërisht të dhënat pas editimit. Skuadrat pjesëmarrëse nga 19 institucione paraqitën në tërësi 1263 sisteme për variante të ndryshme të detyrave dhe çifte gjuhësh.', 'am': 'የWMT 2021 ውጤቶችን በጥጋት ማስታወቂያው ላይ የተካፈለውን ስራ እናስታውቃለን፡፡ ይህ ክፍል በሁለት መጀመሪያ የአሁኑን ጠቅላላ ጥያቄዎች ላይ ያስተካክሎአል:(i) የተሰወረ ቋንቋዎች፣ ምናልባት zero-shot settings እና (ii) የክፋት ስህተት በተሳሳተ የፍርድ ትንቢት ነው፡፡ በተጨማሪም አዲስ ዳታ ለቋንቋዎች በተለየ በኋላ የተካፈሉት ዳታ አፈረሰ፡፡ ከ19 ተሟጋቾች የቡድን ተግባር በሙሉ 1263 ስርዓቶች ለሥራ ልዩ ልዩ እና ቋንቋ ዓይነቶች ሰጥተዋል፡፡', 'tr': 'WMT 2021-iň Kwalyk Taýýarlama barada ylalaşyk zadyň netijesini bildirip bilýäris, nähili kynçylyk şol ýerde näyral maşynyň terjime sistemleriniň netijesini sözler we sözleriň derejesinde çykyş bolup geçirmegidir. Bu düzgün iki esap roman eklenmesine üns berildi: (i) garaşylmadyk diller üçin öňünden geçirmek, diýipdir 0-aty düzümleri, we (ii) felaketler bilen sözleriň öňünden geçirmek. Beýleki, täze maglumatlar birnäçe diller üçin seredildi, iň bellenen soňra edit edilen maglumatlar üçin. 19 gurultatdan bäsleşikli toparlar 1263 sistemalary farklı täze warianatlara we dil çiftliklerine süýşürdi.', 'hy': 'Մենք զեկուցում ենք 2021 թվականի համաշխարհային աշխատանքի արդյունքները որակի գնահատման մասին, որտեղ մարտահրավերն է կանխատեսել նյարդային մեքենայի թարգմանման համակարգերի արտադրության որակը բառերի և նախադասությունների մակարդակներում: Այս հրատարակությունը կենտրոնացավ երկու հիմնական նորարարական ավելացումների վրա. i) անտեսանելի լեզուների կանխատեսումների վրա, այսինքն՝ զրոյի նկարների սահմանումների վրա, և i) ճակատագրական սխալներով նախատեսված նախադասությունների վրա: Ավելին, բազմաթիվ լեզուների համար նոր տվյալներ էին հրապարակում, հատկապես հետխմբագրված տվյալներ: 19 կազմակերպություններից մասնակցում գտնվող թիմերը ընդհանուր առմամբ 1263 համակարգ ներկայացրեցին աշխատանքի տարբեր տարբերակներին և լեզվի զույգերին:', 'az': 'WMT 2021 şəkildə paylaşılan işlərin sonuçlarını təbliğ edirik. Nəyral maşın çeviriş sistemlərinin sonuçlarını sözlər və cümlələr seviyesində təbliğ etməkdir. Bu yayınlıq iki ana roman əlavəsinə odaklandı: i) görünmədən dillər üçün tədbir, yox-shot ayarları və ii) katastrofi hataları olan cümlələrin tədbir edilməsi. Əvvəlcə, yeni məlumat bir neçə dil üçün yayınlışdı, özlərinə də post-edited məlumatlar. 19 kurumlardan paylaşan ekipler tamamilə 1263 sistemi müxtəlif işlər variablarına və dil çiftlərə təyin etdilər.', 'bn': 'আমরা উইএমটি ২০২১ এর ফলাফল সম্পর্কে প্রতিবেদন জানিয়েছি, যেখানে এই চ্যালেঞ্জ হচ্ছে শব্দ এবং শাস্তি পর্যায়ে নিউরেল মেশিন অনুবাদ সিস্টেমের মানের প্ এই সম্পাদনা দুই প্রধান নোভেল যোগাযোগের উপর মনোযোগ দিয়েছে: (i) অদৃশ্য ভাষার ভবিষ্যৎবাণী, যেমন শূন্য-গুলি বৈশিষ্ট্য এবং (ii) বিপর্যয়ের ভু এছাড়াও বেশ কয়েকটি ভাষার জন্য নতুন তথ্য প্রকাশ করা হয়েছে, বিশেষ করে পোস্ট সম্পাদন করা তথ্য। ১৯ প্রতিষ্ঠান থেকে অংশগ্রহণকারীদের দল পুরোপুরি ১২৩৩ সিস্টেম বিভিন্ন কাজের ভিন্ন ভিন্ন ভিন্ন এব', 'bs': 'Prijavljujemo rezultate zajedničkog zadatka WMT 2021 o procjeni kvalitete, gdje je izazov predviđati kvalitetu izlaza sustava prevođenja neuralnih strojeva na razini riječi i rečenica. Ovaj izdatak se fokusirao na dvije glavne dodatke romana: i) predviđanje za nevidljive jezike, tj. postavke nule snimke, i ii) predviđanje rečenica sa katastrofalnim greškama. Osim toga, novi podaci su objavljeni za broj jezika, posebno posledišnji podaci. Učesnici tima iz 19 institucija potpuno su podnijeli 1263 sustava različitim variantima zadataka i jezičkim parovima.', 'ca': 'Informem els resultats de la tasca compartida WMT 2021 sobre Estima de Qualitat, on el repte és predir la qualitat de la producció dels sistemes neuromàtics de traducció a nivells de paraules i frases. Aquesta edició es va centrar en dues noves adicions principals: (i) predicció de llengües invisibles, és a dir, configuracions de fotografies zero, i (ii) predicció de frases amb errors catastròfics. A més, es van publicar noves dades per a diverses llengües, especialment les dades posteditades. Els equips participants de 19 institucions van presentar un total de 1263 sistemes a diferents variants de tasca i parells de llenguatges.', 'cs': 'Předkládáme výsledky sdíleného úkolu WMT 2021 na odhadu kvality, kde je výzvou předpovědět kvalitu výstupu neuronových strojových překladových systémů na úrovni slova a věty. Toto vydání se zaměřilo na dva hlavní novely: (i) predikci neviditelných jazyků, tedy nastavení nulového záběru, a (ii) predikci vět s katastrofickými chybami. Kromě toho byla vydána nová data pro řadu jazyků, zejména pro post-editovaná data. Účastnící se týmy devatenácti institucí předložily celkově 1263 systémy různým variantám úkolů a jazykovým párům.', 'fi': 'Raportoimme WMT 2021:n jaetun laadunarviointitehtﾃ､vﾃ､n tuloksista, jossa haasteena on ennustaa neurokonekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmien tuotoksen laatua sana- ja lausetasolla. Tﾃ､mﾃ､ painos keskittyi kahteen keskeiseen romaanilisﾃ､ykseen: (i) nﾃ､kymﾃ､ttﾃｶmien kielten ennustamiseen, eli nollakuvausasetuksiin, ja (ii) lauseiden ennustamiseen katastrofaalisilla virheillﾃ､. Lisﾃ､ksi julkaistiin uutta dataa useille kielille, erityisesti jﾃ､lkimuokatulle datalle. Osallistujat 19 oppilaitoksesta toimittivat yhteensﾃ､ 1263 jﾃ､rjestelmﾃ､ﾃ､ eri tehtﾃ､vﾃ､variantteihin ja kielipareihin.', 'et': 'Raporteerime WMT 2021 jagatud kvaliteedi hindamise ülesande tulemustest, kus väljakutseks on prognoosida neuromasintõlkesüsteemide väljundi kvaliteeti sõna- ja lausetasemel. Käesolev väljaanne keskendus kahele peamisele uuendusele: i) nähtamatute keelte ennustamine, st null-shot seaded, ja ii) katastroofiliste vigadega lausete ennustamine. Lisaks avaldati uusi andmeid mitmete keelte kohta, eriti järeltöötatud andmete kohta. 19 institutsiooni osalevad meeskonnad esitasid kokku 1263 süsteemi erinevatele ülesannete variantidele ja keelepaaridele.', 'jv': 'Awak dhéwé Awak iki nyumbang ngetoke kanggo nambah durung kelas: i) supuran kanggo unggadi luwih Nambah, dadi sing dibutuhi kanggo langgar sampeyan luwih, dadi sing ngubah after editasi. Ngubah perintah sing sampeyan 19 institusi sing ngetoke 12-suoro sistem sing sampeyan karo perusahaan langkung sampeyan karo perusahaan', 'sk': 'Poročamo rezultate skupne naloge WMT 2021 o oceni kakovosti, kjer je izziv napovedati kakovost izhoda nevronskih strojnih prevajalskih sistemov na ravni besed in stavkov. Ta izdaja se osredotoča na dve glavni novi dodatki: (i) napovedovanje za nevidne jezike, tj. nastavitve brez strela, in (ii) napovedovanje stavkov s katastrofalnimi napakami. Poleg tega so bili objavljeni novi podatki za številne jezike, zlasti za podatke po urejanju. Sodelujoče ekipe iz 19 institucij so skupaj 1263 sistemov predložile različnim različicam nalog in jezikovnim parom.', 'ha': "Tuna rapa fassarar aikin WMT 2021 da aka raba shi a kan Hikima, a inda kansalar ta zama bayani ga sifar da matsalar na fassarar ɗin tarjibu na ƙarƙashin neural da ke cikin zane da muhalli. Wannan shirin ya fokus a kan addi biyu masu ƙari na nowaya:(i) mai bashiri wa lugha da aka ɓõye, misali, daidaita-sifo, da kuma (ii) ya yi gargaɗi ga sonar da ke cikin ɓata mai girma. Da wannan, aka saka data na sãbuwa wa wa wasu harshe, hususan data na bayan-edited. Sharing team daga 19 organisations sun saka kodi 1263 na'ura zuwa variants na aikin aiki da wasu mutane na harshe.", 'he': 'We report the results of the WMT 2021 shared task on Quality Estimation, where the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels.  העורך הזה התמקד בשני תוספות רומניות ראשיות: (i) חזיון לשפות בלתי נראות, כלומר סדרות אפס צילומים, ו (ii) חזיון של משפטים עם טעויות קטסטרופיות. בנוסף, נתונים חדשים שוחררו עבור מספר שפות, במיוחד נתונים אחרי העורר. צוותים משתתפים מ-19 מוסדות שלחו 1263 מערכות לגמרי לטווחים משימה שונים וזוגי שפה.', 'bo': 'We report the results of the WMT 2021 shared task on Quality Estimation, where the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels. འདི་བཟོ་ཚིག་འདིས་རྩ་བའི་གསར་གཏོད་ཁྱད་པར་བློ་གཏོང་བ་གཉིས་ཀྱི་སྔོན་ལྟར་སྟོན་ཡོད། ཁྱད་པར། སྐད་རིགས་ཀྱི་ཁྱད་པར་ཆ་འཕྲིན་གསར་བ་ཞིག་འཇུག་བྱས། ཁྱད་པར་ཡང་བསྐྱར་ཞིབ་བྱས་པའི་ཆ་འཕྲིན། མཉམ་སྦྲེལ་མཐུད་ཁང་19ལས་དབང་ཆ་སྤྱི་ཚོགས་ཀྱི་ལས་འགུལ་ལུགས་དང་། སྐད་ཆ་ཆ་གཅིག་ནུས་མེད་པའི་རྩིས་འཁོར་དང་།'}
{'en': 'Efficient ', 'pt': 'Tradução automática eficiente com poda e quantização de modelos', 'ru': 'Эффективный машинный перевод с обрезкой и квантованием моделей', 'fr': "Traduction automatique efficace grâce à l'élagage et à la quantification des modèles", 'ar': 'ترجمة آلية فعالة مع نموذج التقليم والكمية', 'zh': '模形剪量化成高效机器翻译', 'es': 'Traducción automática eficiente con recorte y cuantificación de modelos', 'ja': 'モデル枝刈りと量子化による効率的な機械翻訳', 'hi': 'मॉडल छंटाई और परिमाणीकरण के साथ कुशल मशीन अनुवाद', 'ga': 'Aistriúchán Meaisín Éifeachtach le Bearradh Múnla agus Cainníochtú', 'hu': 'Hatékony gépi fordítás modellmetszéssel és kvantizálással', 'ka': 'Name', 'el': 'Αποτελεσματική μηχανική μετάφραση με το μοντελοποιημένο κλάδεμα και την ποσοτικοποίηση', 'it': 'Traduzione automatica efficiente con potatura e quantizzazione dei modelli', 'mk': 'Efficient Machine Translation with Model Pruning and Quantization', 'ml': 'Name', 'ms': 'Efficient Machine Translation with Model Pruning and Quantization', 'mt': 'Traduzzjoni Effiċjenti tal-Magna bil-Mudell tal-Ħruġ u l-Kwantifikazzjoni', 'mn': 'Машин хөгжлийн загварын хөгжлийн болон хэмжээст хэмжээтэй үр дүнтэй хөгжлийн хөгжлийн оролцол', 'no': 'Name', 'pl': 'Wydajne tłumaczenie maszynowe dzięki przycinaniu modeli i kwantowaniu', 'ro': 'Traducere automată eficientă cu tăierea modelului și cuantificarea', 'sr': 'Efikasno prevodenje mašine sa modelom prebacivanjem i kvantizacijom', 'si': 'Name', 'lt': 'Efficient Machine Translation with Model Pruning and Quantization', 'kk': 'Өзгерту және көлемдеу үлгісімен жұмыс істейтін машинаның аударуы', 'ta': 'Name', 'ur': 'مدل پرونگ اور Quantization کے ساتھ عمدہ ماشین ترجمہ', 'sv': 'Effektiv maskinöversättning med modellbeskärning och kvantisering', 'so': 'Turjumista Efficient Machine with Model Pruning and Quantization', 'vi': 'Dịch chỉnh máy hiệu quả bằng cách Pruning và Quantico mẫu', 'uz': 'Name', 'bg': 'Ефективен машинен превод с подрязване на модели и квантоване', 'hr': 'Efikasno prevodenje strojeva sa modelom prebacivanje i kvantizacijom', 'da': 'Effektiv maskinoversættelse med modelbeskæring og kvantisering', 'nl': 'Efficiënte machinevertaling met model snoeien en kwantificeren', 'fa': 'ترجمه ماشین موثر با پیشرفت و Quantization مدل', 'de': 'Effiziente maschinelle Übersetzung mit Modellbeschnitt und Quantisierung', 'id': 'Translation Mesin Efisien dengan Model Pruning dan Quantization', 'ko': '모형 가위질과 양적 효율을 갖춘 고효율 기계 번역', 'sw': 'Tafsiri yenye ufanisi wa Mashine na Utafiti wa Model', 'tr': 'Mazmunlar Başyrma we Küçeleme bilen ýeterlik Mazmunlar terjime edip', 'sq': 'Përkthimi i Efikantë i Makinës me Model Pruning dhe Quantization', 'af': 'Name', 'am': 'ምርጫዎች', 'hy': 'Էֆեկցիոնալ մեքենայի թարգմանություն մոդելի պրոնինգով և քանակությամբ', 'az': 'Model Pruning və Quantization ilə Etkinlik Makina Çeviri', 'bs': 'Efikasno prevodenje mašine sa modelom prebacivanjem i kvantizacijom', 'bn': 'Name', 'ca': 'Una traducció màquina eficient amb models de presó i quantificació', 'cs': 'Efektivní strojový překlad s řezáním modelů a kvantizací', 'et': 'Tõhus masintõlge mudelite lõikamise ja kvantitatiivsusega', 'fi': 'Tehokas konekäännös mallinnuksella ja kvantitoinnilla', 'jv': 'EfEfEfent Mahine Terjamahan karo model Prouning lan Kwangatirasyon', 'he': 'Efficient Machine Translation with Model Pruning and Quantization', 'sk': 'Učinkovit strojni prevod z obrezovanjem modelov in kvantizacijo', 'ha': '@ action', 'bo': 'ནུས་ཡོད་པའི་མ་དབྱིབས་སྔོན་སྒྲིག་དང་ཚད་རྩིས་འབྲི་བ་དང་མཉམ་དུ་འཛུགས་པ'}
{'en': 'We participated in all tracks of the WMT 2021 efficient machine translation task : ', 'es': 'Participamos en todos los aspectos de la tarea de traducción automática eficiente del WMT 2021: CPU de un solo núcleo, CPU multinúcleo y hardware de GPU con condiciones de rendimiento y latencia. Nuestras presentaciones combinan varias estrategias de eficiencia: destilación de conocimiento, un decodificador de unidad recurrente simple (SSRU) más simple con una o dos capas, listas léxicas cortas, formatos numéricos más pequeños y poda. Para la pista de CPU, utilizamos modelos cuantizados de 8 bits. Para la pista de GPU, experimentamos con FP16 y enteros de 8 bits en tensorcores. Algunos de nuestros envíos optimizan el tamaño mediante la cuantificación de registros de 4 bits y la omisión de una lista corta léxica. Hemos extendido la poda a más partes de la red, haciendo hincapié en la poda a nivel de componentes y bloques que realmente mejora la velocidad, a diferencia de la poda basada en coeficientes.', 'fr': "Nous avons participé à toutes les étapes de la tâche de traduction automatique efficace WMT 2021\xa0: processeur monocœur, processeur multicœur et matériel GPU avec des conditions de débit et de latence. Nos soumissions combinent plusieurs stratégies d'efficacité\xa0: distillation des connaissances, décodeur d'unité récurrente simple (SSRU) plus simple avec une ou deux couches, listes lexicales restreintes, formats numériques plus petits et élagage. Pour la piste CPU, nous avons utilisé des modèles 8 bits quantifiés. Pour la piste GPU, nous avons expérimenté des FP16 et des entiers 8 bits dans les tensorcores. Certaines de nos soumissions optimisent la taille via la quantification logarithmique sur 4 bits et l'omission d'une liste restreinte lexicale. Nous avons étendu l'élagage à d'autres parties du réseau, en mettant l'accent sur l'élagage au niveau des composants et des blocs qui améliore réellement la vitesse contrairement à l'élagage par coefficient.", 'pt': 'Participamos de todas as etapas da tarefa de tradução automática eficiente do WMT 2021: CPU de núcleo único, CPU de vários núcleos e hardware de GPU com condições de taxa de transferência e latência. Nossas submissões combinam várias estratégias de eficiência: destilação de conhecimento, um decodificador de unidade simples recorrente (SSRU) mais simples com uma ou duas camadas, listas léxicas, formatos numéricos menores e poda. Para a trilha da CPU, usamos modelos quantizados de 8 bits. Para a trilha da GPU, experimentamos FP16 e inteiros de 8 bits em tensorcores. Alguns de nossos envios otimizam o tamanho por meio de quantização de log de 4 bits e omitindo uma lista léxica. Estendemos a poda para mais partes da rede, enfatizando a poda em nível de componente e bloco que realmente melhora a velocidade, ao contrário da poda de coeficiente.', 'ar': 'شاركنا في جميع مسارات مهمة الترجمة الآلية الفعالة WMT 2021: وحدة المعالجة المركزية أحادية النواة ، وحدة المعالجة المركزية متعددة النواة ، وأجهزة GPU مع ظروف الإنتاجية والكمون. تجمع تقديماتنا بين العديد من استراتيجيات الكفاءة: تقطير المعرفة ، وحدة فك ترميز بسيطة متكررة (SSRU) بطبقة واحدة أو طبقتين ، قوائم مختصرة معجمية ، تنسيقات رقمية أصغر ، وتقليم. بالنسبة لمسار وحدة المعالجة المركزية ، استخدمنا نماذج كمية 8 بت. بالنسبة لمسار GPU ، قمنا بتجربة FP16 و 8 بت في الأعداد الصحيحة tensorcores. يتم تحسين بعض عمليات الإرسال الخاصة بنا من حيث الحجم عبر تكميم السجل المكون من 4 بتات وحذف قائمة مختصرة معجمية. لقد قمنا بتوسيع التقليم ليشمل المزيد من أجزاء الشبكة ، مع التركيز على التقليم على مستوى المكونات والكتل الذي يعمل في الواقع على تحسين السرعة على عكس تقليم المعامل.', 'zh': '凡与 WMT 2021 高效机器翻译事者,有吞吐量迟单核 CPU、多核 CPU 、 GPU 硬件。 交合数策效率:知蒸馏,有一重二重之单元(SSRU)解码器,词汇选列表,小数字格式修剪。 于 CPU 轨道,我用量化 8 。 于 GPU 轨道,试 FP16 与 8 位全数之张量。 臣等所言,因 4 位日志量化与省略词法候选列表以优化大小。 已将剪至网络者更多,强组件块级,此实增其速,与系数异也。', 'ja': 'WMT 2021の効率的な機械翻訳タスクのすべてのトラックに参加しました：シングルコアCPU、マルチコアCPU、およびスループットとレイテンシ条件を備えたGPUハードウェア。当社の提出物には、ナレッジ蒸留、1つまたは2つのレイヤーを備えたより簡単な単純なリカレントユニット（ SSRU ）デコーダー、辞書ショートリスト、より小さな数値フォーマット、および枝刈りなど、いくつかの効率的な戦略が組み合わされています。CPUトラックには、量子化された8ビットモデルを使用しました。ＧＰＵトラックについては、ＦＰ １ ６と８ビット整数をテンソルコアで実験した。4ビットログ量子化によるサイズの最適化と、辞書の候補リストを省略した提出物もあります。当社は、より多くの部分のネットワークに枝刈りを拡張し、実際には係数的枝刈りとは異なり速度を向上させるコンポーネントレベルおよびブロックレベルの枝刈りを強調しました。', 'hi': 'हमने डब्ल्यूएमटी 2021 कुशल मशीन अनुवाद कार्य के सभी पटरियों में भाग लिया: एकल-कोर सीपीयू, मल्टी-कोर सीपीयू, और थ्रूपुट और विलंबता स्थितियों के साथ जीपीयू हार्डवेयर। हमारी प्रस्तुतियां कई दक्षता रणनीतियों को जोड़ती हैं: ज्ञान आसवन, एक या दो परतों के साथ एक सरल सरल आवर्तक इकाई (एसएसआरयू) विकोडक, लेक्सिकल शॉर्टलिस्ट, छोटे संख्यात्मक प्रारूप, और छंटाई। CPU ट्रैक के लिए, हमने क्वांटाइज्ड 8-बिट मॉडल का उपयोग किया। GPU ट्रैक के लिए, हमने टेंसरकोर में FP16 और 8-बिट पूर्णांकों के साथ प्रयोग किया। हमारे सबमिशन के कुछ 4-बिट लॉग परिमाणीकरण के माध्यम से आकार के लिए अनुकूलित और एक लेक्सिकल शॉर्टलिस्ट को छोड़कर. हमने नेटवर्क के अधिक हिस्सों में छंटाई का विस्तार किया है, घटक- और ब्लॉक-स्तर की छंटाई पर जोर दिया है जो वास्तव में गुणांक-वार छंटाई के विपरीत गति में सुधार करता है।', 'ru': 'Мы участвовали во всех треках задачи эффективного машинного перевода WMT 2021: одноядерный процессор, многоядерный процессор и оборудование графического процессора с пропускной способностью и условиями задержки. Наши заявки объединяют несколько стратегий эффективности: дистилляцию знаний, простой рекуррентный декодер (SSRU) с одним или двумя слоями, лексические короткие списки, меньшие числовые форматы и обрезку. Для трассы ЦП мы использовали квантованные 8-битные модели. Для трека GPU мы экспериментировали с FP16 и 8-битными целыми числами в тензорных ядрах. Некоторые из наших представлений оптимизируются по размеру за счет 4-битного квантования логарифма и пропуска лексического короткого списка. Мы распространили обрезку на большее количество частей сети, делая упор на обрезку на уровне компонентов и блоков, что фактически улучшает скорость, в отличие от обрезки по коэффициентам.', 'ga': "Ghlacamar páirt i ngach rian de thasc éifeachtach aistriúcháin meaisín WMT 2021: LAP aon-lárnach, LAP il-lárnach, agus crua-earraí GPU le coinníollacha tréchur agus latency. Comhcheanglaíonn ár n-aighneachtaí roinnt straitéisí éifeachtúlachta: driogadh eolais, díchódóir aonad athfhillteach simplí níos simplí (SSRU) le sraith amháin nó dhó, gearrliostaí foclóireachta, formáidí uimhriúla níos lú, agus bearradh. Maidir leis an rian LAP, d'úsáideamar samhlacha cainníochtaithe 8-giotán. Maidir leis an rian GPU, rinneamar turgnamh le slánuimhreacha FP16 agus 8-giotán i tensorcores. Déanann cuid dár n-aighneachtaí barrfheabhsú ar mhéid trí chainníochtú loga 4-giotán agus fágtar ar lár gearrliosta foclóireachta. Táimid tar éis bearradh a leathnú go dtí níos mó codanna den líonra, ag cur béime ar bhearradh ar leibhéal na gcomhpháirteanna agus na mbloc a fheabhsaíonn luas murab ionann agus bearradh comhéifeachtúil.", 'el': 'Συμμετείχαμε σε όλα τα κομμάτια της αποδοτικής εργασίας μηχανικής μετάφρασης: μονοπυρήνων ΚΜΕ, πολυπυρήνων ΚΜΕ και υλικό με συνθήκες απόδοσης και καθυστέρησης. Οι αιτήσεις μας συνδυάζουν διάφορες στρατηγικές αποδοτικότητας: απόσταξη γνώσης, απλούστερος αποκωδικοποιητής απλής επαναλαμβανόμενης μονάδας (με ένα ή δύο στρώματα, λεξικές συντομεύσεις, μικρότερες αριθμητικές μορφές και κλάδεμα. Για το κομμάτι CPU, χρησιμοποιήσαμε κβαντισμένα 8-bit μοντέλα. Για το κομμάτι πειραματιστήκαμε με ακέραιους αριθμούς FP16 και 8-bit σε τενσορκίδες. Ορισμένες από τις υποβολές μας βελτιστοποιούν για το μέγεθος μέσω 4-κβαντισμού καταγραφής και παραλείποντας μια λεξική λίστα συντομεύσεων. Έχουμε επεκτείνει το κλάδεμα σε περισσότερα μέρη του δικτύου, δίνοντας έμφαση στο κλάδεμα σε επίπεδο συστατικού και μπλοκ που βελτιώνει πραγματικά την ταχύτητα σε αντίθεση με το κλάδεμα βάσει συντελεστή.', 'ka': 'WMT 2021-ის ეფექტიური მანქანის გადაწყვეტილების ყველა მონაცემების მონაცემებში ჩვენ გავათავსებეთ: ერთმანეთი CPU, მრავალფერი CPU და GPU ჰაპექტირების შესახებ და დასაწყვეტი ჩვენი მომხმარებები უფრო ეფექტიკური სტრატიგიების გადაყენება: მეცნიერების დისტლიაცია, უფრო განვითარებული რეკურენტური ერთეული (SSRU) დიკოდირებით ერთ ან ორი ნაგულებით, ლექსიკური კო CPU-ის ტრაკისთვის, ჩვენ გამოიყენეთ კვანტიზული 8-ბიტის მოდელები. GPU-ის სტრიქტისთვის, ჩვენ ექსპერიმენტირებდით FP16 და 8-ბიტის მთელი რიცხვით ტენსორკორეში. ჩვენი მომხმარებების ზომას 4- ბიტური ლოგური კვანტიზაციის გამოყენება და ლექსიკალური კვანტიზაციის გამოყენება. ჩვენ ქსელის უფრო მეტი ნაწილებისთვის გავიზრდით, რომლებიც კომპონენტები და ბლოკური ნაწილებისთვის გავიზრდით სიჩქარე, რომლებიც მართლაც უფრო მეტი სიჩქარე', 'it': 'Abbiamo partecipato a tutte le tracce del compito di traduzione automatica efficiente WMT 2021: CPU single-core, CPU multi-core e hardware GPU con condizioni di throughput e latenza. Le nostre proposte combinano diverse strategie di efficienza: distillazione della conoscenza, decodificatore di unità ricorrente semplice semplice (SSRU) con uno o due strati, shortlist lessicali, formati numerici più piccoli e potatura. Per la traccia CPU, abbiamo usato modelli quantizzati a 8 bit. Per la traccia GPU, abbiamo sperimentato con FP16 e 8 bit interi in tensorcore. Alcune delle nostre proposte ottimizzano le dimensioni tramite quantizzazione di log a 4 bit e omettendo una shortlist lessicale. Abbiamo esteso la potatura a più parti della rete, enfatizzando la potatura a livello di componenti e blocchi che in realtà migliora la velocità a differenza della potatura coefficiente.', 'kk': 'Біз WMT 2021-нің эффективні компьютердің аудару тапсырмасының барлық жолдарына қатынасыз: бір- бір негізгі процессор, көп- негізгі процессор және GPU жабдықтарына қатынасыз келді. Біздің жіберіміздің бірнеше ефективдік стратегияларын біріктіреді: білім дистилляциясы, бірнеше қарапайым қайталану бірлігі (SSRU) бір не екі қабатты декодері, лексикалық қысқартулар тізімі, кіші Процессордың жолы үшін 8- бит үлгілерін қолдандық. GPU жолында, FP16 және 8- бит бүтін сандарды тензоркорларда тәжірибедік. Біздің кейбір жіберіміздің өлшемін 4- бит журналды квантизациялау мен лексикалық қысқартылық тізімін шешу арқылы оптимизациялау. Біз желінің көптеген бөліктеріне көтердік, компонентті және блок деңгейінің бөліктеріне көтердік. Сонымен қатар, коэффициентті бағыттауға қарай жылдамдығын жақсы кө', 'hu': 'Részt vettünk a WMT 2021 hatékony gépi fordítási feladatának minden pályáján: egymagos processzor, többmagos processzor és GPU hardver átviteli és késleltetési feltételekkel. Pályázataink több hatékonysági stratégiát ötvöznek: tudás desztilláció, egyszerűbb egyszerű visszatérő egység (SSRU) dekódoló egy vagy két rétegű, lexikai rövidlisták, kisebb numerikus formátumok és metszés. A CPU sávhoz kvantizált 8 bites modelleket használtunk. A GPU sáv esetében FP16 és 8 bites egész számokkal kísérleteztünk tenzorcorokban. Néhány beadványunk méretére optimalizálódik 4 bites log kvantizálással és lexikális rövidlista kihagyásával. Kiterjesztettük a metszést a hálózat több részére, hangsúlyozva az alkatrész- és blokkszintű metszést, amely valójában javítja a sebességet az együtthatós metszéssel szemben.', 'mk': 'We participated in all tracks of the WMT 2021 efficient machine translation task: single-core CPU, multi-core CPU, and GPU hardware with throughput and latency conditions.  Нашите поднесувања комбинираат неколку стратегии за ефикасност: дистилација на знаење, едноставен едноставен декодер на рецидентна единица (ССРУ) со еден или два слоја, лексикални кратки листи, помали броеви формати и прскање. For the CPU track, we used quantized 8-bit models.  For the GPU track, we experimented with FP16 and 8-bit integers in tensorcores.  Some of our submissions optimize for size via 4-bit log quantization and omitting a lexical shortlist.  Ние го проширивме исцепувањето на повеќе делови од мрежата, истакнувајќи го исцепувањето на компоненти и блокови ниво што всушност ја подобрува брзината во разлика од коефициентно исцепување.', 'lt': 'We participated in all tracks of the WMT 2021 efficient machine translation task: single-core CPU, multi-core CPU, and GPU hardware with throughput and latency conditions.  Mūsų pasiūlymuose derinamos kelios veiksmingumo strategijos: žinių distiliavimas, paprastesnis paprastas pakartotinis vieneto (SSRU) dekoderis su vienu ar dviem sluoksniais, leksiniai trumpalaikiai sąrašai, mažesni skaitmeniniai formatai ir smulkinimas. For the CPU track, we used quantized 8-bit models.  GPU bėgių atveju eksperimentavome su FP16 ir 8 bit ų sveikaisiais skaičiais tempikliuose. Some of our submissions optimize for size via 4-bit log quantization and omitting a lexical shortlist.  We have extended pruning to more parts of the network, emphasizing component- and block-level pruning that actually improves speed unlike coefficient-wise pruning.', 'ml': 'ഞങ്ങള്\u200d WMT 2021-ന്റെ എല്ലാ ട്രാക്കുകളിലും പങ്കുചേര്\u200dത്തിരിക്കുന്നു: ഏക- കോര്\u200d സിപിയു, multi-core സിപിയു, ജിപിയു ഹാര്\u200dഡ്\u200cവെയര്\u200d വാര്\u200dഡ് പൂട്ടിയ നമ്മുടെ സന്ദേശങ്ങള്\u200d കൂടുതല്\u200d പ്രവർത്തനങ്ങളെ കൂട്ടിചേര്\u200dക്കുന്നു: അറിവ് വേര്\u200dപെടുത്തുന്നതും, എളുപ്പമായി തിരിച്ചുവരുന്ന യൂണിറ്റര്\u200d (എസ്എസ്ആര്\u200dയൂ സിപിയു ട്രാക്കിന് വേണ്ടി, ഞങ്ങള്\u200d 8 ബിറ്റ് മോഡലുകള്\u200d ഉപയോഗിച്ചു. ജിപിയു ട്രാക്കിന് വേണ്ടി, ഞങ്ങള്\u200d എഫ്\u200cപി16, 8 ബിറ്റ് യൂണിറ്ററുകളുമായി പരീക്ഷിച്ചു. Some of our submissions optimize for size via 4-bit log quantization and omitting a lexical shortlist.  നമ്മള്\u200d നെറ്റര്\u200dനെറ്റിലേക്ക് കൂടുതല്\u200d ശ്രദ്ധയോടെ വിശാലമാക്കിയിരിക്കുന്നു. കോഫിക്സിഫിക്റ്റ് ബുദ്ധിമാന്റ് പോലെയുള്', 'ms': 'We participated in all tracks of the WMT 2021 efficient machine translation task: single-core CPU, multi-core CPU, and GPU hardware with throughput and latency conditions.  Our submissions combine several efficiency strategies: knowledge distillation, a simpler simple recurrent unit (SSRU) decoder with one or two layers, lexical shortlists, smaller numerical formats, and pruning.  For the CPU track, we used quantized 8-bit models.  For the GPU track, we experimented with FP16 and 8-bit integers in tensorcores.  Some of our submissions optimize for size via 4-bit log quantization and omitting a lexical shortlist.  Kami telah memperluas pemotong kepada lebih banyak bahagian rangkaian, menekankan pemotong komponen- dan tahap blok yang sebenarnya meningkatkan kelajuan tidak seperti pemotong koeficien-bijak.', 'mn': 'Бид WMT 2021-ийн бүх үр дүнтэй машины хөрөнгө оруулалтын ажил дээр оролцсон. Нэг төвөгтэй CPU, олон төвөгтэй CPU, GPU төхөөрөмжтэй. Бидний хүлээн зөвшөөрөл олон үр дүнтэй стратегийг нэгтгэдэг: мэдлэг сайжруулах, энгийн дахин дахин нэгж (SSRU) нэг эсвэл хоёр давхар, лексикийн богино жагсаалт, жижиг тооны хэлбэртэй, бөмбөмбөмбөг Процессорын загварын хувьд бид 8-бит хэмжээний загварыг ашигласан. GPU хуудас дээр бид FP16 болон 8-бит бүхэл тоонуудтай туршилт хийсэн. Зарим хүмүүс 4-бит лог квантизацийг ашиглан хэмжээг ашиглаж, лексикийн богино жагсаалт гаргаж байна. Бид сүлжээний олон хэсэг рүү хөгжүүлсэн бөгөөд компонент болон блок-түвшинд хөгжүүлсэн бөгөөд үнэндээ коэффициент удирдлагаас харьцаагүй хурдыг сайжруулдаг.', 'mt': 'We participated in all tracks of the WMT 2021 efficient machine translation task: single-core CPU, multi-core CPU, and GPU hardware with throughput and latency conditions.  Is-sottomissjonijiet tagħna jikkombinaw diversi strateġiji ta’ effiċjenza: distillazzjoni tal-għarfien, dekoder sempliċi ta’ unit à rikorrenti sempliċi (SSRU) b’saff wieħed jew żewġ saffi, shortlists lexiċi, formati numeriċi iżgħar, u pruning. Għall-binarju tas-CPU, użajna mudelli kwantifikati ta’ 8 bits. Għall-binarju GPU, esperimentajna bl-FP16 u numru sħiħ ta’ 8 bits f’tensorcores. Some of our submissions optimize for size via 4-bit log quantization and omitting a lexical shortlist.  Estendijna l-pruning għal aktar partijiet tan-netwerk, enfasizzaw il-pruning fil-livell tal-komponenti u tal-blokki li fil-fatt itejjeb il-veloċità għall-kuntrarju tal-pruning skont il-koeffiċjenti.', 'ro': 'Am participat la toate pistele activității de traducere automată eficientă WMT 2021: procesor single-core, procesor multi-core și hardware GPU cu condiții de throughput și latență. Cererile noastre combină mai multe strategii de eficiență: distilarea cunoștințelor, un decodor simplu recurent (SSRU) cu unul sau două straturi, liste scurte lexicale, formate numerice mai mici și tăiere. Pentru pista CPU, am folosit modele cuanticizate pe 8 biți. Pentru pista GPU, am experimentat cu FP16 și 8 biți întregi în tensorcore. Unele dintre trimiterile noastre se optimizează pentru dimensiune prin cuantificarea jurnalelor pe 4 biți și omiterea unei liste scurte lexicale. Am extins tăierea la mai multe părți ale rețelei, subliniind tăierea la nivelul componentelor și blocurilor, care îmbunătățește viteza spre deosebire de tăierea coeficientului.', 'sr': 'Učestvovali smo u svim tragovima učinkovitog zadatka za prevod strojeva WMT 2021: jedinstvenog procesora, multi core CPU i GPU hardver sa uvjetima prevoda i latencije. Naše podaci kombiniraju nekoliko strategija učinkovitosti: destilacija znanja, jednostavniji rekonstruirani jedini (SSRU) dekoder sa jednim ili dva slojeva, leksičkim kratkim listama, manjim brojnim formatima i pružanjem. Za CPU traku, koristili smo kvantizirane 8-bit modele. Za GPU trag eksperimentirali smo sa FP16 i 8-bit celim brojem u tenzorkorama. Neki od naših podataka optimiziraju veličinu kroz kvantizaciju 4-bit dnevnika i napuštaju leksičku kratku listu. Proširili smo pružanje na više delova mreže, naglašavajući komponentni i blokovni obrezak koji zapravo poboljšava brzinu u razliku od koeficijentalnog pružanja.', 'so': 'Waxaannu ka qeybqaadanay dhammaan waddooyinka WMT 2021 oo shaqeeya machine translation: single-core CPU, multiple-core CPU, and GPU hardware with throughput and latency conditions. Suuriyadayada waxaa ku qoran qoraalo shaqo badan: kala soocaynta aqoonta, qayb fudud oo dib u soo kireysanaya (SSRU) oo ku qoran hal ama labo qasab, gaadiidka leksikalka, noocyada tirada yar iyo xilliga. For the CPU track, we used quantized 8-bit models.  Jidadka GPU, waxan ku tijaabiyey FP16 iyo 8 bits oo ku jira tensorcore. Qayb kamid ah oo warqadeennu ku qoran yihiin qiyaastii qoraalka 4-bit kaddibna ka tegi karto liiska leksikal. Dhaqdhaqaaqa shabakadda qaarkood oo badan ayaannu ku kordhisnay, waxaynu ku sii dhiirranay alaabta kooxaha- iyo heerka kooxaha, taasoo horumarinaya dhaqdhaqaalaha si aan u eg caqliga xigmadda.', 'no': 'Vi delta i alle spor av WMT 2021 effektivt maskinsomsetjingsprogrammet: enkelkjerne CPU, fleirkjerne CPU og GPU-maskinvaren med gjennomsetjing og latensingsvilkår. Utføringane våre kombinerer fleire effektivitetsstrategiar: kunnskapsdistillasjon, enklare enklare rekurserande eining (SSRU) med ein eller to lag, leksiske kortliste, mindre numeriske formater og kryssing. For CPU- sporet brukte vi kvantiserte 8- bit modeller. For GPU- sporet eksperimenterte vi med FP16 og 8- bit heiltal i tensorkorar. Noen av våre innsendingar optimaliserer for storleik via 4- bit loggkvantisering og fjernar ut ein leksisk kortlist. Vi har utvidet opprinnelsen til fleire deler av nettverket, og understrekar komponent og blokknivå, som faktisk forbetrar farten i motsetjing av koeffisienten.', 'ta': 'WMT 2021 செயற்பாடு இயந்திரம் மொழிமாற்றும் பணியின் அனைத்து தடங்களிலும் நாங்கள் பங்கிடப்பட்டோம்: ஒற்றைமூல சிபியூ, பல- core CPU, மற்றும் ஜிபியு  நம்முடைய கட்டளைகள் பல விளைவு துறைகளை ஒன்று சேர்க்கிறது: அறிவு பிரிவு, எளிதான நிகழ்வு அலகு (எளிதாக இருக்கும் நிகழ்வு அலகு (எஸ்எஸ்ஆர்யூ சிபியு தடத்திற்கு, நாங்கள் எட்டு பிட் மாதிரிகளை பயன்படுத்தினோம். ஜிபியு தடத்திற்கு, நாங்கள் FP16 மற்றும் 8 பிட் முழுமையான எண்ணிக்கைகளில் சோதித்தோம். 4- பிட் பதிவு அளவு மூலம் எங்கள் கூறுதல்களில் சில தேர்வுகளை மாற்றுகிறது மற்றும் ஒரு லெக்சிகல் சுருக்க பட்டியலை விட நாம் வலைப்பின்னலின் அதிக பகுதிகளுக்கு புரிந்து விரிவாக்கி விட்டோம், பொருள் மற்றும் தொகுதி மட்டத்தில் புரிந்து கொள்கிறோ', 'sv': 'Vi deltog i alla spﾃ･r av WMT 2021 effektiva maskinﾃｶversﾃ､ttningsuppgifter: enkﾃ､rnig processor, flerkﾃ､rnig processor och GPU-hﾃ･rdvara med genomstrﾃｶmnings- och fﾃｶrdrﾃｶjningsfﾃｶrhﾃ･llanden. Vﾃ･ra bidrag kombinerar flera effektivitetsstrategier: kunskapsdestillation, en enklare enkel ﾃ･terkommande enhet (SSRU) avkodare med ett eller tvﾃ･ lager, lexikala kortlistor, mindre numeriska format och beskﾃ､rning. Fﾃｶr CPU-spﾃ･ret anvﾃ､nde vi kvantiserade 8-bitars modeller. Fﾃｶr GPU-spﾃ･ret experimenterade vi med FP16 och 8-bitars heltal i tensorcors. Nﾃ･gra av vﾃ･ra inlﾃ､mningar optimerar fﾃｶr storlek via 4-bitars loggkvantisering och utelﾃ､mnar en lexikal lista. Vi har utﾃｶkat beskﾃ､rningen till fler delar av nﾃ､tverket och betonat komponent- och blocknivﾃ･ beskﾃ､rning som faktiskt fﾃｶrbﾃ､ttrar hastigheten till skillnad frﾃ･n koefficientvis beskﾃ､rning.', 'ur': 'ہم نے WMT 2021 کے تمام ٹراکیوں میں شامل ہوا کہ ایک-core CPU، multicore CPU، اور GPU ہرڈیور پر قائم ہونے اور لاٹنسی شرایط کے ساتھ۔ ہماری اطلاعات بہت سی فعالیت استراتژی جمع کر رہی ہیں: علم جدائی، ایک ساده دوبارہ تکرار یونیٹ (SSRU) کے ساتھ ایک یا دو لائٹ، لکسیکل لنٹ لیست، چھوٹی numerical formats، اور پرینگ کے ساتھ آسان ہے. سی پی یو ٹراک کے لئے ہم نے کوانتیز 8 بیٹ موڈل استعمال کیا۔ GPU ٹراک کے لئے ہم نے FP16 اور 8-bit integers کے ساتھ تہینسورکور میں آزمائش کی۔ ہماری جماعتیں میں سے کچھ لوگ 4-bit log quantization کے ذریعہ اندازے کے لئے اچھی طرح کر رہے ہیں اور ایک لکسیکل لنٹ لیست کو چھوڑ دیتے ہیں۔ ہم نے نیٹ ورک کے زیادہ قسموں پر پرینگ گھسیٹ دی ہے، قسمت اور بلوک سطح پرینگ کی تسبیح کرتی ہے جو سطح میں سرعت کو مزید مزید کرتی ہے، بغیر اقتصادی سمجھانے والی پرینگ کے.', 'pl': 'Uczestniczyliśmy we wszystkich utworach wydajnego tłumaczenia maszynowego WMT 2021: procesora jednordzeniowego, procesora wielordzeniowego i sprzętu GPU z warunkami przepustowości i opóźnienia. Nasze zgłoszenia łączą kilka strategii efektywności: destylację wiedzy, prostszy dekoder jednostki powtarzającej (SSRU) z jedną lub dwoma warstwami, krótkie listy leksykalne, mniejsze formaty liczbowe i przycinanie. Do ścieżki CPU użyliśmy kwantyzowanych 8-bitowych modeli. W przypadku ścieżki GPU eksperymentowaliśmy z FP16 i 8-bitowymi liczbami całkowitymi w tensorzeniach. Niektóre z naszych zgłoszeń zoptymalizują rozmiar poprzez 4-bitową kwantyzację dziennika i pomijanie krótkiej listy leksykalnej. Rozszerzyliśmy przycinanie na więcej części sieci, podkreślając przycinanie komponentów i bloków, które rzeczywiście poprawia prędkość w przeciwieństwie do przycinania współczynnikowego.', 'si': 'අපි WMT 2021 විශ්වාසිත මැෂින් වාර්ථාව ක්\u200dරියාවේ සියළු ප්\u200dරකාරයෙන් සම්බන්ධ වෙලා තියෙනවා: එක-කෝර් CPU, විශ්වාසිත CPU අපේ සම්පූර්ණය සම්පූර්ණය සම්පූර්ණ විශේෂතාවක් සම්පූර්ණය කරනවා: දන්නය විශේෂණය, සරල පුරවර්ණ යුනිකාවක් (SSRU) ඩිකොඩර් එක CPU ට්\u200dරෑක් වෙනුවෙන්, අපි ක්වාන්ටිස් 8- බිට් මොඩේල් වියුතුයි. GPU ට්\u200dරෑක් වෙනුවෙන්, අපි FP16 සහ 8-බිට් පූර්ණ සංචාරයෙන් පරීක්ෂා කළා. අපේ සම්පූර්ණයෙන් සමහර දෙයක් ප්\u200dරමාණය 4- බිට් ලොක් ක්වාන්ටිසයෙන් විශේෂ කරන්න සහ ලෙක්සිකල් කොටි ලිස අපි ජාලයේ වැඩි කොටස් වලට ප්\u200dරශ්නය කරලා තියෙනවා, ප්\u200dරශ්නය කරලා තියෙනවා- සහ බ්ලොක් ක්\u200dරමයක් ප්\u200dරශ්නය කරනවා, ඒක ඇත්ත', 'uz': "Biz WMT 2021 ta'siri mashina tarjimasiga hamma qanday qismiga murojaat qildik: singi CPU, ko'plab ko'plab CPU, va GPU uskunalari Bizning imkoniyatlarimiz bir necha ta'sirlik strategiyasini birlashtiradi: ilmiy ajratish, oddiy davom etish bir yoki ikki qatlam (SSRU) cheksiz, leksikal qisqartmalar, kichkina raqamli formatlar va nuqta qilish. CPU yordamchisi uchun, biz 8- bit modellardan foydalanamiz. GPU yordamchisi uchun, biz FP16 va 8 bitta birga tensorkorlar bilan tizimni sinab ko'rdik. Bizning bir necha imkoniyatlarimiz 4- bit logning hajmini aniqlash va leksikal tugmalar roʻyxatini avto'tiradi. Biz tarmoqning bir necha qismlarga ko'proq qismlarga ko'ramiz, komponentni va kvartal darajaga qo'yish mumkin. Bu tashkilotni tasavvur qilishi haqida tezlik foydalanishini oshirish mumkin.", 'vi': 'Chúng tôi đã tham gia vào tất cả các đường ray của công việc dịch chuyển máy có hiệu quả của WRT 2021: đơn-core CPU, đa-core, và phần cứng GPU với quá trình và tình trạng trì hoãn. Những tài liệu của chúng tôi kết hợp nhiều chiến lược hiệu quả: Từ tri thức, đơn giản đơn giản là bộ giải mã thường (SSRU) với một hoặc hai lớp, liệt kê chữ viết, các mô số nhỏ hơn, và cắt tỉa. Chúng tôi dùng các mô hình số lượng nhỏ. Chúng tôi thí nghiệm với số nguyên tắc F16 và 8-cắn trong những hạt nhân Một số tài liệu của chúng tôi tối ưu cho kích cỡ qua phân lượng 4-cắn bản ghi và bỏ qua một danh sách ngắn có chữ. Chúng tôi đã mở rộng việc cắt tỉa thêm thành nhiều phần của mạng, nhấn mạnh việc cắt tỉa các thành phần và khối, điều đó thực sự cải thiện tốc độ, không như việc cắt tỉa hệ số.', 'bg': 'Участвахме във всички песни на ефективната задача за машинен превод: едноядрен процесор, многоядрен процесор и хардуер с условия на производителност и латентност. Нашите предложения съчетават няколко стратегии за ефективност: дестилация на знания, по-прост декодер с един или два слоя, лексикални кратки списъци, по-малки числови формати и подрязване. За проследяването на процесора използвахме квантизирани 8-битови модели. За GPU пистата експериментирахме с FP16 и 8-битови цели числа в тенсоркора. Някои от нашите предложения оптимизират размера чрез 4-битова логова квантизация и пропускане на лексикален списък. Разширихме подрязването до повече части от мрежата, подчертавайки подрязването на ниво компоненти и блокове, което всъщност подобрява скоростта за разлика от подрязването по коефициент.', 'da': 'Vi deltog i alle spor af WMT 2021 effektiv maskinoversættelsesopgave: single-core CPU, multi-core CPU og GPU hardware med gennemløb og latens betingelser. Vores indsendelser kombinerer flere effektivitetsstrategier: videndedestillation, en enklere enkel tilbagevendende enhed (SSRU) dekoder med et eller to lag, leksikalske shortlists, mindre numeriske formater og beskæring. Til CPU sporet brugte vi kvantiserede 8-bit modeller. Til GPU sporet eksperimenterede vi med FP16 og 8-bit heltal i tensorcore. Nogle af vores indsendelser optimerer til størrelse via 4-bit log kvantisering og udelader en leksikal shortlist. Vi har udvidet beskæringen til flere dele af netværket og understreget beskæring på komponent- og blokniveau, der faktisk forbedrer hastigheden i modsætning til koefficientvis beskæring.', 'hr': 'Učestvovali smo u svim tragovima učinkovitog zadatka za prevod strojeva WMT 2021: jednocore CPU, multi core CPU i GPU hardver s uvjetima prevoda i latencije. Naši podaci kombiniraju nekoliko strategija učinkovitosti: destilacija znanja, jednostavniji rekonstruirani jedinica (SSRU) dekoder sa jednim ili dva slojeva, leksičkim kratkom listom, manjim brojnim formatima i pružanjem. Za CPU traku, koristili smo kvantizirane 8 bit modele. Za GPU stazu, eksperimentirali smo sa FP16 i 8-bit cijelom broju u tenzorkorama. Neki od naših podataka optimiziraju veličinu kroz kvantizaciju 4-bit dnevnika i napuštaju leksičku kratku listu. Proširili smo pružanje na više dijelova mreže, naglašavajući pružanje komponenta i blokove razine koja zapravo poboljšava brzinu u razliku od koeficijentnog pružanja.', 'nl': 'We hebben deelgenomen aan alle tracks van de WMT 2021 efficiënte machinevertaaltaak: single-core CPU, multi-core CPU en GPU hardware met doorvoer- en latentievoorwaarden. Onze inzendingen combineren verschillende efficiëntiestrategieën: kennisdestillatie, een eenvoudigere eenvoudige recidivierende unit (SSRU) decoder met één of twee lagen, lexicale shortlists, kleinere numerieke formaten en snoeien. Voor de CPU track gebruikten we kwantiseerde 8-bit modellen. Voor de GPU track experimenteerden we met FP16 en 8-bit integers in tensorces. Sommige van onze inzendingen optimaliseren voor grootte via 4-bits logquantisatie en het weglaten van een lexicale shortlist. We hebben snoeien uitgebreid tot meer delen van het netwerk, waarbij de nadruk ligt op snoeien op component- en blokniveau dat de snelheid verbetert in tegenstelling tot snoeien op coëfficiënt-wijze.', 'id': 'We participated in all tracks of the WMT 2021 efficient machine translation task: single-core CPU, multi-core CPU, and GPU hardware with throughput and latency conditions.  Pengiriman kami menggabungkan beberapa strategi efisiensi: destilasi pengetahuan, dekoder unit rekuren sederhana (SSRU) sederhana dengan satu atau dua lapisan, daftar pendek lexik, format numerik yang lebih kecil, dan pruning. Untuk trek CPU, kami menggunakan model 8 bit kuantisasi. Untuk jalur GPU, kami eksperimen dengan FP16 dan 8 bit integer dalam tensor. Beberapa pengiriman kita optimisasi untuk ukuran melalui kuantisasi log 4-bit dan melewatkan daftar pendek lexik. Kami telah memperluas pemotong ke lebih banyak bagian jaringan, menekankan pemotong komponen- dan tahap blok yang sebenarnya meningkatkan kecepatan tidak seperti pemotong koeficien-bijak.', 'ko': 'WMT 2021 고효율 기계 번역 작업의 모든 트랙: 싱글 코어 CPU, 멀티 코어 CPU 및 처리량 및 지연 조건이 있는 GPU 하드웨어에 참여했습니다.우리가 제출한 파일은 몇 가지 효율 전략을 결합시켰다. 지식 추출, 간단한 단순 귀속 단원 (SSRU) 디코더 (한 층 또는 두 층), 어휘 짧은 목록, 비교적 작은 디지털 형식, 가지치기.CPU 추적에 대해 우리는 양적 8비트 모델을 사용한다.GPU 궤적에 대해 tensorcores에서 FP16과 8비트 정수를 시험했습니다.우리의 일부 투고는 네 개의 일지를 계량화하고 어휘 짧은 명단을 생략함으로써 크기를 최적화시킨다.우리는 이미 가지치기를 네트워크의 더 많은 부분으로 확장하여 구성 요소급과 블록급 가지치기를 강조하였는데, 이것은 계수급 가지치기와 달리 실제로는 속도를 높였다.', 'de': 'Wir haben an allen Tracks der WMT 2021 effizienten maschinellen Übersetzungsaufgabe teilgenommen: Single-Core-CPU, Multi-Core-CPU und GPU-Hardware mit Durchsatz- und Latenzbedingungen. Unsere Einreichungen kombinieren mehrere Effizienzstrategien: Wissensdestillation, ein einfacherer Simple Recurrent Unit (SSRU)-Decoder mit ein oder zwei Schichten, lexikalische Shortlists, kleinere numerische Formate und Beschneiden. Für die CPU-Spur verwendeten wir quantisierte 8-Bit-Modelle. Für die GPU-Spur experimentierten wir mit FP16- und 8-Bit-Ganzzahlen in Tensorcores. Einige unserer Einreichungen optimieren die Größe durch 4-Bit Log Quantisierung und Weglassen einer lexikalischen Shortlist. Wir haben das Beschneiden auf mehr Teile des Netzwerks ausgeweitet, wobei wir das Beschneiden auf Komponenten- und Blockebene betonen, das die Geschwindigkeit im Gegensatz zum Koeffizienten verbessert.', 'fa': 'ما در تمام نقاشی\u200cهای عملیات ترجمه\u200cکننده\u200cی ماشین\u200cهای موثر WMT 2021 شرکت کردیم: CPU single-core, CPU multicore and GPU hardware with Throughput and latency conditions. استراتژی\u200cهای ما چند استراتژی موثرت را ترکیب می\u200cکنند: تفریح علمی، واحد ساده\u200cترین تکرار ساده\u200cتر (SSRU) با یک یا دو لایه، لیست\u200cهای کوتاه\u200cتری لغوی، فرموده\u200cهای شماره\u200cتری کوچک\u200cتری و تفریح. برای مسیر CPU، ما از مدل ۸ بیت کوانتیز استفاده کردیم. برای مسیر GPU، با عدد FP16 و 8 بیت در تنسورکور آزمایش کردیم. بعضی از تحویل\u200cهای ما به اندازه\u200cی چهار بیت کوانتیزی\u200cسازی مجموعه می\u200cکنند و از یک لیست کوتاه\u200cسازی زبان ترک می\u200cکنند. ما به بخش\u200cهای بیشتری از شبکه، تضمین بخش\u200cها و سطح بلوک\u200cها را گسترش داده\u200cایم که در واقع سرعت را برخلاف تضمین\u200cهای موثر بهتر می\u200cکند.', 'sw': 'Tumeshiriki katika hatua zote za kazi za kutafsiri mashine yenye ufanisi wa WMT 2021: CPU moja kwa moja, CPU yenye asili nyingi, na vifaa vya GPU kwa hali ya hivi karibuni. Mawasiliano yetu yanaunganisha mikakati kadhaa ya ufanisi: utofauti wa maarifa, kituo rahisi cha kurudi tena (SSRU) kwa kiwango kimoja au mbili, vifupi vya lexico, aina ndogo ya taratibu, na kuelewa. Kwa njia ya CPU, tulitumia mifano ya takwimu 8. Kwa ajili ya timu ya GPU, tulijaribu kwa jumla za FP16 na viungo 8 katika viungo vya tensorcor. Baadhi ya ujumbe wetu huwezesha kuongezeka kwa kiwango cha ukubwa kupitia ukurasa wa log a 4-bit na kuacha orodha ya mfupi wa lexico. Tumeongeza kuelewa kwa sehemu zaidi ya mtandao, tunasisitiza vifaa- na kuelewa viwango vya kuzuia viwango vinavyobadilisha kasi tofauti na uelewa wa ufanisi.', 'tr': 'WMT 2021 täsirli maşynyň terjime täblisasynyň ähli parçalaryna goşuldyk: single-core CPU, multi-core CPU we GPU hardware-dan geçiş we geçiş şertleri bilen goşuldyk. Bizim gönderilenlerimiz birnäçe etkinlik stratejiklerini birleşdirýär: bilgi taýýarlanmasy, basit bir tekrarat birimi (SSRU) bir ýa-da iki katy bilen kodlaýar, leksiýal gysga listler, kiçi sanat biçimleri we süýşirmek üçin. CPU parçası için, 8-bit modelleri kullandık. GPU haty üçin, FP16 we 8-bit integer bilen synanyşdyrdyk. Bizim gönderilenlerimiz käbirleri 4-bit günlük quantizatlama bilen ululykna optimize et ve bir diski kısa listeden ayrılır. Biz şebekeniň köp bölümlerine süýtgedik, komponenti we blok derejesini süýtgedik ki, aslynda koefisyz bilen ýigrenýän süýtgedik ýaly ýigrenýän ýigrenýän ýigrençä.', 'sq': 'Ne morëm pjesë në të gjitha gjurmët e detyrës së përkthimit të makinave të efektshëm WMT 2021: CPU me një qendër, CPU me shumë qendër dhe hardware GPU me kushte të daljes dhe vonesës. Our submissions combine several efficiency strategies: knowledge distillation, a simpler simple recurrent unit (SSRU) decoder with one or two layers, lexical shortlists, smaller numerical formats, and pruning.  Për gjurmën e CPU-së, përdorëm modele të kuantizuara 8-bit. Për gjurmën GPU, ne eksperimentuam me FP16 dhe 8-bit të tëra në tensorcores. Disa nga paraqitjet tona optimizojnë madhësinë nëpërmjet kuantizimit të 4-bit logaritmi dhe harrojnë një listë të shkurtër lexike. Kemi zgjeruar shtrirjen në më shumë pjesë të rrjetit, duke theksuar shtrirjen e nivelit të komponenteve dhe bllokeve që në fakt përmirëson shpejtësinë në ndryshim nga shtrirja e koeficientit.', 'af': "Ons het gedeel in alle snitte van die WMT 2021 effektief masjien vertaling opdrag: enkelcore CPU, multi core CPU en GPU-hardwerf met deurgang en latensie voorwaardes. Ons onderdragte kombinieer verskeie effektiviteit strategies: kennis destilasie,  'n eenvoudiger eenheid herhaalde eenheid (SSRU) dekoder met een of twee laag, leksiese kortplyste, kleinere numeriese formate en pruning. Vir die CPU snit het ons quantiseer 8- bit modelle gebruik. Vir die GPU snit, het ons eksperimenteer met FP16 en 8- bit heelgetal in tensorkore. Sommige van ons onderdragte optimaliseer vir grootte deur 4- bit log quantiseer en verlaat 'n leksiese kortplys. Ons het uitgebrei van drukking na meer dele van die netwerk, uitgestrek van komponent en blok-vlak drukking wat eintlik spoed verbeter nie soos koeffisient-wyse drukking nie.", 'am': 'በWMT 2021 ጥሩ መሣሪያን ትርጉም ማድረግ ሁሉ አካባቢ ሆነን: አንድ-core CPU፣ በብዙ-core CPU እና የGPU hardware በመጠቀም እና በቀዳሚ ግንኙነት አካባቢ ነው፡፡ አካባቢዎች፣ የእውቀት ግንኙነት፣ ቀላል ቀዳሚ ክፍል (SSRU) አካባቢዎች በአንድ ወይም ሁለት ደረጃ፣ የሜክሲካዊ አካባቢዎች፣ ትንሽ ቁጥጥር እና አስተያየት፡፡ ለCPU መድረክ 8-ቢት ሞዴላዎችን ተጠቀምን፡፡ ለGPU መንገዱ፣ FP16 እና 8 ቢትኮር ተሞክረናል፡፡ የአንዳንዶቹ አካላቢዎች በ4 ቢትሮክ ማሰናከል እና የሌክሲካል አቋራጭ ዝርዝር ተወው፡፡ We have extended pruning to more parts of the network, emphasizing component- and block-level pruning that actually improves speed unlike coefficient-wise pruning.', 'bn': 'আমরা উইএমটি ২০২১ সাধারণ মেশিন অনুবাদ কর্মসূচীর সকল ট্র্যাকে অংশগ্রহণ করেছি: একক-মূল সিপিউ, বহুমূল সিপিউ এবং জিপিউ হার্ডওয়্যার হার্ডপুট এবং লা আমাদের উপস্থাপন বেশ কিছু কৌশলের সাথে একত্রিত: জ্ঞান বিচ্ছিন্ন, সাধারণ পুনরাবৃত্তিক ইউনিট (এসআরইউ), এক বা দুই স্তর, লেক্সিকাল সংক্রান্ত সংক্রান্ সিপিউ ট্র্যাকের জন্য আমরা ৮ বিট মডেল ব্যবহার করেছিলাম। জিপিউ ট্র্যাকের জন্য, আমরা এফপি১৬ এবং ৮ বিট ইউনিটের সাথে পরীক্ষা করেছি টেনসোর্কোরে। আমাদের কিছু উপস্থাপনের মাধ্যমে ৪-বিট লগের মাধ্যমে আকারের জন্য অপ্রায়শিক্ষা করে লেক্সিকাল সংক্ষিপ্ত ত তালি We have extended pruning to more parts of the network, emphasizing component- and block-level pruning that actually improves speed unlike coefficient-wise pruning.', 'hy': 'Մենք մասնակցեցինք 2021 թվականի ԱՄԹ-ի արդյունավետ մեքենայի թարգմանման բոլոր ճանապարհորդություններին՝ մեկ-հիմնական պրոցեբույսը, բազմահիմնական պրոցեբույսը և GPU-ի սարքավորումը, որոնք ունեն հաջողության և լայնության Մեր ներկայացումները միավորում են որոշ արդյունավետության ռազմավարություններ. գիտելիքների դիսլիլացիա, պարզ կրկնվող միավորի (SSRU) դեկոդեր մեկ կամ երկու շերտերի հետ, լեքսիկական կարճ ցուցակներ, փոքր թվային ֆորմատներ և կտրվածք: Մենք օգտագործեցինք քվանտավորված 8-բիտ մոդելներ: GPU-ի կառուցվածքի համար մենք փորձարկում էինք 16-ի և 8-բիտ ամբողջ թվերի օգնությամբ տենսորկորներում: Մեր ներկայացումներից ոմանք օպտիմացնում են չափսերը 4-բիտ լոգ քվանտիզացիայի միջոցով և թողնում են լեքսիկական կարճ ցուցակ: Մենք ընդլայնել ենք ցանցի ավելի շատ մասեր, ուշադրություն դարձնելով բաղադրիչների և բլոկի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակարդակի մակար', 'az': 'WMT 2021-nin müvəffəqiyyətli maşın çeviri işin ə katıldıq: tək-core CPU, çoxlu-core CPU və GPU hardwarlığına keçirdik. Bizim göndərilərimiz birkaç faydallıq stratejisini birləşdirir: elm distillasyonu, sadəcə olaraq tekrarlanan birimi (SSRU) bir ya da iki katla, leksik qısqa listeləri, daha kiçik numerik formatları və pruning. CPU parçası üçün kvantifikat 8 bit modelləri kullandıq. GPU yolu üçün FP16 və 8-bit bütün sayılarla təcrübə etdik. Bizim göndərmələrimizdən bəziləri 4-bit log kvantifikasiyası vasitəsilə böyüklüyü optimizləyir və leksik qısa listesini tərk edirlər. Biz şəbəkənin daha çox parçalarını uzatdıq, komponent və blok seviyyətinin təsirini təsirləndirdik ki, həqiqətən, koeficientli təsirli təsirlərin bənzərini təsirləndirmədən hızlandırır.', 'bs': 'Učestvovali smo u svim tragovima učinkovitog zadatka za prevod strojeva WMT 2021: jednocore CPU, multi core CPU, i GPU hardver sa uvjetima prevoda i latencije. Naši podaci kombiniraju nekoliko strategija učinkovitosti: destilacija znanja, jednostavniji jednostavniji rekonstruirani jedinica (SSRU) dekoder sa jednim ili dva sloja, leksički kratki listi, manji brojni formati i pružanje. Za CPU traku, koristili smo kvantizirane 8-bit modele. Za GPU stazu, eksperimentirali smo sa FP16 i 8-bit celim brojem u tenzorkorama. Neki od naših podataka optimiziraju veličinu kroz kvantizaciju 4-bit dnevnika i napuštaju leksičku kratku listu. Proširili smo pružanje na više dijelova mreže, naglašavajući pružanje komponenta i blokovnog nivoa koji zapravo poboljšava brzinu u razliku od koeficijentnog pružanja.', 'ca': "Vam participar en totes les pistes de la tasca de traducció màquina eficient de la WMT 2021: CPU únic, CPU múltiple i hardware GPU amb condicions de producció i latencia. Les nostres proposicions combinan diverses estratègies d'eficiència: distillació del coneixement, un simple decodificador recurrent d'unitat (SSRU) amb una o dues capes, llistes curtes lècsiques, formats numèrics més petits i pruning. Per a la pista del CPU, vam utilitzar models quantitzats de 8 bits. Per a la pista GPU, vam experimentar amb números complets de FP16 i 8 bits en tensorços. Algunes de les nostres presentacions optimizen la mida a través de la quantificació del registre de 4 bits i omiten una llista lèxica curta. Hem extinguit el pruning a més parts de la xarxa, enfatizant el pruning a nivell de components i blocs que millora la velocitat a diferència del pruning a nivell coeficient.", 'cs': 'Podíleli jsme se na všech stopách efektivního strojového překladu WMT 2021: jednojádrový CPU, vícejádrový CPU a GPU hardware s podmínkami propustnosti a latence. Naše příspěvky kombinují několik strategií efektivity: destilaci znalostí, jednodušší jednoduchý recidivní dekodér (SSRU) s jednou nebo dvěma vrstvami, lexikální seznamy, menší číselné formáty a řezání. Pro stopu CPU jsme použili kvantizované 8-bitové modely. Pro GPU stopu jsme experimentovali s FP16 a 8-bitovými celými čísly v tenzorcorcech. Některé z našich příspěvků optimalizují velikost pomocí 4-bitové kvantizace protokolu a vynechání lexikálního uživatelského seznamu. Rozšířili jsme prořezávání na více částí sítě a zdůraznili jsme prořezávání komponent a bloků, které ve skutečnosti zlepšuje rychlost na rozdíl od řezání koeficientem.', 'et': 'Osalesime WMT 2021 tõhusa masintõlke ülesande kõikidel radadel: ühetuumaline protsessor, mitmetuumaline protsessor ja GPU riistvara läbilaskevõime ja latentsustingimustega. Meie esitused ühendavad mitmeid efektiivsusstrateegiaid: teadmiste destilleerimine, lihtsam lihtne korduvühiku dekooder (SSRU) ühe või kahe kihiga, leksikaalsed lühinimekirjad, väiksemad numbriformaadid ja pügamine. CPU rajaks kasutasime kvantiseeritud 8-bitisi mudeleid. GPU rajal eksperimenteerisime FP16 ja 8-bitiste täisarvudega tensorkoorides. Mõned meie esitused optimeerivad suurust 4-bitise logikvantiseerimise ja leksikaalse lühinimekirja väljajätmise kaudu. Oleme laiendanud pügamist enamatele võrgu osadele, rõhutades komponentide ja plokkide tasandil pügamist, mis tegelikult parandab kiirust erinevalt koefitsientide põhjal.', 'fi': 'Osallistuimme WMT 2021:n tehokkaan konekäännöksen kaikkiin raitoihin: yksiytimisiin suorittimiin, moniytimisiin suorittimiin ja näytönohjaimiin laitteistoihin, joissa oli läpimenoaika ja viive. Lähetyksissämme yhdistyvät useita tehokkuusstrategioita: tietämyksen tislaus, yksinkertaisempi yksinkertainen toistuva yksikkö (SSRU) -dekooderi yhdellä tai kahdella kerroksella, leksikaaliset shortlists-luettelot, pienemmät numeeriset muodot ja karsiminen. Suorittimen raitaa varten käytimme kvantitoituja 8-bittisiä malleja. GPU-radalla kokeilimme FP16- ja 8-bittisiä kokonaislukuja tensorkoreissa. Osa lähetyksistämme optimoi koon 4-bittisellä lokikvantisoinnilla ja jättämällä pois lexikaalisen shortlistan. Olemme laajentaneet karsimista useampaan osaan verkostoa korostaen komponentti- ja lohkotasoa, joka itse asiassa parantaa nopeutta toisin kuin kerroinviisas karsinta.', 'sk': 'Sodelovali smo na vseh poteh učinkovite naloge strojnega prevajanja WMT 2021: enojedrni procesor, večjedrni procesor in GPU strojna oprema s pogoji pretoka in latence. Naši predlogi združujejo več strategij učinkovitosti: destilacija znanja, enostavnejši enostavni ponavljajoči se enoti (SSRU) dekoder z eno ali dvema slojema, leksikalni seznami, manjši numerični formati in obrezovanje. Za sled procesorja smo uporabili kvantizirane 8-bitne modele. Za sled GPU smo eksperimentirali s FP16 in 8-bitnimi celimi števili v tensorjerih. Nekatere od naših prispevkov optimizirajo velikost s 4-bitnim kvantizacijo dnevnika in izpustom leksikalnega seznama. Razširili smo obrezovanje na več delov omrežja, poudarili pa smo obrezovanje na ravni komponent in blokov, ki dejansko izboljšuje hitrost v nasprotju s koeficientom obrezovanja.', 'jv': 'Awak dhéwé pisan karo kabèh track ing the WT 2020 1 effectual translation task: single-source Awak dhéwé Coverage Terus nang traca GNU, kita diperénksi karo FP16 lan 8-bit gak bukal ning tenor cores Algorithm Awak dhéwé éntuk nglanggar wih-wih akèh liyane ing netahan, nguasai perusahaan karo nggawe barang-wih akèh lan soko nggawe barang langgar bantuan liyane', 'ha': "Mun yi rabo da duk hanyõyi na WMT 2021 masu fassarar mashine mai amfani da fassarar aiki: Sin-Core CPU, multi-Core CPU, da GPU na hanyoyi na hanyoyi da buƙata da kuma muhalli na latent. TsarinMu masu haɗi ko da taki masu sanki: separation of ilmi, mai sauƙi cikin shirin kirurgi (SSRU) na koma sauri guda ko biyu, rubuci-nau'in leksisi, ko ƙarami masu ƙaranci masu tarayya, da mai sauri. Ga sakan CPU, mun yi amfani da misãlai na 8-bitan. Ga hanyar GPU, mun jarraba FP16un da 8-bitan integre cikin tsorora. Babu wasu da ke samu'yinmu masu amfani da girmar, don a sami tsarin logogin 4-bitan kuma ka bar wani jerin mai loksiya. Mun shimfiɗa fikanci zuwa mafi ƙaranci zuwa tarayyan, kuma Mun yi emphasi ga fahimta-ƙananan- da-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane", 'he': 'השתתפנו בכל העקבות של משימה התרגום המכונה היעילה של WMT 2021: CPU אחד-ליבה, CPU רבה-ליבה, וחשמל GPU עם תנאי דרך ולאוטנציה. השימושים שלנו משלבים מספר אסטרטגיות יעילות: דסטילה ידע, פיקוד יחידה חדשה פשוטה יותר (SSRU) עם שכבות אחת או שתיים, רשימות קצרות לקסיקות, פורמטים מספריים קטנים יותר, וקרע. For the CPU track, we used quantized 8-bit models.  עבור מסלול GPU, ניסונו עם מספרים שלמים של FP16 ו-8 ביטים במתחם. חלק מהשליחות שלנו אופטימים בגודל באמצעות קוונטיזציה של לוג 4-ביטים ולהשאיר רשימה קצרה לקסיקה. הרחבנו את השקיעה לחלקים נוספים של הרשת, להדגיש את השקיעה ברמה של רכיבים ובלוקים שממשיך לשפר את המהירות בניגוד לשקיעה במיוחד.', 'bo': 'We participated in all tracks of the WMT 2021 efficient machine translation task: single-core CPU, multi-core CPU, and GPU hardware with throughput and latency conditions. Our submissions combine several efficiency strategies: knowledge distillation, a simpler simple recurrent unit (SSRU) decoder with one or two layers, lexical shortlists, smaller numerical formats, and pruning. For the CPU track, we used quantized 8-bit models. GPU གླེང་གི་རྒྱུད་ལམ་ལ་ངེད་ཚོས་FP16 དང་། tensorcores ནང་ཨང་ཀིའི་ནང་གི་འགྲེལ་བཤད་པ་ཡིན། Some of our submissions optimize for size via 4-bit log quantization and omitting a lexical shortlist. ང་ཚོས་དྲ་དམངས་ཀྱི་ཆ་ཤས་ཧེ་མར་ཞིབ་བྱས་ཡོད། དཔལ་འཛིན་གྱི་ཆ་ཤས་དང་གྲོང་གླེང་ཚད'}
{'en': 'Lingua Custodia’s Participation at the WMT 2021 Machine Translation Using Terminologies Shared Task', 'fr': "Participation de Lingua Custodia à la tâche partagée de traduction automatique à l'aide de terminologies WMT 2021", 'es': 'Participación de Lingua Custodia en el WMT 2021 Tarea compartida de traducción automática mediante terminologías', 'ar': 'مشاركة Lingua Custodia في مهمة الترجمة الآلية WMT 2021 باستخدام المصطلحات المشتركة', 'pt': 'Participação da Lingua Custodia na Tarefa Compartilhada de Tradução Automática do WMT 2021', 'zh': 'Lingua Custodia 与 WMT 2021 用术语共事机器翻译', 'ja': 'Lingua CustodiaのWMT 2021機械翻訳における用語を使用した共有タスクへの参加', 'hi': 'WMT 2021 मशीन अनुवाद में लिंगुआ कस्टोडिया की भागीदारी साझा कार्य शब्दावली का उपयोग करके', 'ru': 'Участие Lingua Custodia в WMT 2021 Machine Translation с использованием общих терминологий', 'ga': 'Rannpháirtíocht Lingua Custodia ag Aistriúchán Meaisín WMT 2021 ag Úsáid Téarmaíochta Tasc Comhroinnte', 'ka': 'Comment', 'hu': 'A Lingua Custodia részvétele a WMT 2021 gépi fordításon terminológiák használatával', 'kk': 'Comment', 'it': 'La partecipazione di Lingua Custodia alla traduzione automatica WMT 2021 utilizzando Terminologies Shared Task', 'lt': 'Kalbų apsaugos dalyvavimas WMT 2021 m. vertimui mašinomis naudojant bendrą terminologijų užduotį', 'mk': 'Учеството на Лингва Кустодија на WMT 2021-та машинска транслекција користејќи споделена задача на терминологиите', 'ms': 'Pesertaan Custodia Lingua di Perjemahan Mesin WMT 2021 menggunakan Tugas Berkongsi Terminologi', 'el': 'Συμμετοχή της στη μηχανική μετάφραση με χρήση ορολογιών Κοινή εργασία', 'ml': 'ടെര്\u200dമിനിലോളജികള്\u200d പങ്കുചേര്\u200dക്കുന്ന ടാസ്ക് ഉപയോഗിക്കുന്ന WMT 2021 മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതില്\u200d ലിങ്കു', 'pl': 'Udział Lingua Custodia w tłumaczeniu maszynowym WMT 2021 przy użyciu terminologii wspólnego zadania', 'mn': "Lingua Custodia's Participation at the WMT 2021 Machine Translation Using Terminologies Shared Task", 'no': 'Lingua Custodia- deltakaren på WMT 2021- maskinsomsetjinga ved bruk av terminologier delt oppgåve', 'mt': "Lingua Custodia's Participation at the WMT 2021 Machine Translation Using Terminologies Shared Task", 'ro': 'Participarea Lingua Custodia la traducerea automată WMT 2021 folosind sarcina partajată a terminologiilor', 'so': "Lingua Custodia's Participation at the WMT 2021 machine Translation using Terminologies Shared Task", 'sr': 'Učestvovanje Lingua Custodije na WMT 2021 prevodu mašine koristeći dijeljeni zadatak terminologija', 'ta': 'WMT 2021 இயந்திரம் மொழிபெயர்ப்பை பயன்படுத்தி முனையத்தை பகிர்ந்த பணி', 'si': 'Name', 'sv': 'Lingua Custodias deltagande i WMT 2021 maskinöversättning med hjälp av terminologier delad uppgift', 'ur': 'Name', 'uz': 'Name', 'vi': 'Liên lạc của Lingua Cusodia Tại the WM 2021 Machine translation using terminologes shared Task', 'bg': 'Участието на Лингуа Custódia в Машинен превод през 2021 г. чрез споделена задача на терминологиите', 'da': 'Lingua Custodias deltagelse i WMT 2021 maskinoversættelse ved hjælp af terminologier delt opgave', 'nl': 'Deelname van Lingua Custodia aan de WMT 2021 Machine Translation met behulp van terminologieën Gedeelde taak', 'hr': 'Učestvovanje Lingua Custodia na WMT 2021 prevodu strojeva korištenje dijeljenog zadatka terminologa', 'de': 'Teilnahme von Lingua Custodia an der WMT 2021 Maschinenübersetzung unter Verwendung von Terminologien Shared Task', 'fa': 'شرکت لینگوا کاستودیا در ترجمه ماشین WMT 2021 با استفاده از کار مشترک Terminologies', 'ko': 'WMT 2021 기계번역 용어 공유 작업에 Lingua Custodia 참여', 'id': 'Pesertaan Lingua Custodia di WMT 2021 Translation Machine Menggunakan Tugas Berkongsi Terminologi', 'sw': 'Ushiriki wa Lingua Custodia katika mashine ya WMT 2021 Utafiti wa Kutumia Tamko', 'tr': "WMT 2021 Makine Tercümesi kullanarak Lingua Kustodia'nun Participation at the WMT 2021 Machine Translation Using Terminologies Shared Task", 'af': 'Lingua Custodia se Deelnadering by die WMT 2021 Masjien Vertaling gebruik Terminologies Gedeelde Opdrag', 'sq': 'Pjesëmarrja e Kustodias s ë Lingua në WMT 2021 Përkthimin e Makinës duke përdorur detyrën e përbashkët të terminologjive', 'am': "Lingua Custodia's Participation at WMT 2021 Machine Translation using Terminologies Shared Task", 'az': "Lingua Custodia's Participation at the WMT 2021 Machine Translation using Terminologies Shared Task", 'bn': 'টার্মিনোলজিজ ব্যবহার করে টার্মিনোলজি শেয়ার করার কাজ ব্যবহার করে লিঙ্গুয়া কুস্টুডিয়ার অংশগ্রহন', 'bs': 'Učestvovanje Lingua Custodije na WMT 2021 prevodu strojeva korišćenje dijeljenog zadatka terminologija', 'cs': 'Účast Lingua Custodia na WMT 2021 Strojový překlad pomocí terminologií Shared Task', 'et': 'Lingua Custodia osalemine WMT 2021 masintõlkel terminoloogiate jagatud ülesande abil', 'ca': 'La participació de la Custòdia de Lingua a la traducció de màquines WMT 2021 utilitzant una tasca compartida de terminologies', 'fi': 'Lingua Custodian osallistuminen WMT 2021 -konekääntämiseen terminologioiden avulla', 'hy': 'Լինգուա Կուստոդիայի մասնակցությունը 2021 թվականի ԱՄԹ-ի մեքենայի թարգմանման մեջ՝ կիսված տերմինոլոգիաների միջոցով', 'jv': 'Ngubah Lingué Custodian kang WWT 2020 1 Masine Terjamahan Utusun Terminal Inlogies Sampeyan Taaksi', 'ha': 'KCharselect unicode block name', 'he': 'השתתפות של שומר לינגווה בתרגום מכונות WMT 2021', 'sk': 'Sodelovanje Lingue Custodia na strojnem prevajanju WMT 2021 z uporabo terminologij skupne naloge', 'bo': "Lingua Custodia's Participation at the WMT 2021 Machine Translation Using Terminologies Shared Task"}
{'en': 'This paper describes Lingua Custodia’s submission to the WMT21 shared task on ', 'ar': 'تصف هذه الورقة تقديم Lingua Custodia إلى مهمة WMT21 المشتركة حول الترجمة الآلية باستخدام المصطلحات. نأخذ في الاعتبار ثلاثة اتجاهات ، وهي الإنجليزية إلى الفرنسية والروسية والصينية. نحن نعتمد على بنية قائمة على المحولات باعتبارها لبنة بناء ، ونستكشف طريقة تقدم تغييرين رئيسيين للإجراء القياسي للتعامل مع المصطلحات. يتمثل الأول في زيادة بيانات التدريب بطريقة تشجع النموذج على تعلم سلوك النسخ عندما يواجه مصطلحات قيد المصطلحات. التغيير الثاني هو إخفاء رمز القيد ، والغرض منه تسهيل تعلم سلوك النسخ وتحسين تعميم النموذج. تظهر النتائج التجريبية أن طريقتنا تفي بمعظم قيود المصطلحات مع الحفاظ على جودة الترجمة العالية.', 'fr': "Cet article décrit la soumission de Lingua Custodia à la tâche partagée WMT21 sur la traduction automatique à l'aide de terminologies. Nous considérons trois directions, à savoir l'anglais vers le français, le russe et le chinois. Nous nous appuyons sur une architecture basée sur Transformer comme élément constitutif, et nous explorons une méthode qui introduit deux changements principaux dans la procédure standard pour gérer les terminologies. La première consiste à augmenter les données d'apprentissage de manière à encourager le modèle à apprendre un comportement de copie lorsqu'il rencontre des termes de contrainte terminologique. Le deuxième changement concerne le masquage de jetons de contrainte, dont l'objectif est de faciliter l'apprentissage du comportement de copie et d'améliorer la généralisation du modèle. Les résultats empiriques montrent que notre méthode satisfait à la plupart des contraintes terminologiques tout en maintenant une qualité de traduction élevée.", 'es': 'Este artículo describe la presentación de Lingua Custodia a la tarea compartida de WMT21 sobre traducción automática mediante terminologías. Consideramos tres direcciones, a saber, inglés a francés, ruso y chino. Nos basamos en una arquitectura basada en Transformer como componente básico y exploramos un método que introduce dos cambios principales en el procedimiento estándar para manejar terminologías. La primera consiste en aumentar los datos de entrenamiento de tal manera que se aliente al modelo a aprender un comportamiento de copia cuando se encuentra con términos de restricción terminológica. El segundo cambio es el enmascaramiento de tokens de restricción, cuyo propósito es facilitar el aprendizaje del comportamiento de copia y mejorar la generalización del modelo. Los resultados empíricos muestran que nuestro método satisface la mayoría de las restricciones terminológicas y mantiene una alta calidad de traducción.', 'pt': 'Este artigo descreve a submissão da Lingua Custodia à tarefa compartilhada WMT21 sobre tradução automática usando terminologias. Consideramos três direções, a saber, inglês para francês, russo e chinês. Contamos com uma arquitetura baseada em Transformer como um bloco de construção e exploramos um método que introduz duas mudanças principais no procedimento padrão para lidar com terminologias. A primeira consiste em aumentar os dados de treinamento de forma a encorajar o modelo a aprender um comportamento de cópia quando encontra termos de restrição terminológica. A segunda mudança é o mascaramento de token de restrição, cujo objetivo é facilitar o aprendizado do comportamento de cópia e melhorar a generalização do modelo. Os resultados empíricos mostram que nosso método satisfaz a maioria das restrições de terminologia, mantendo alta qualidade de tradução.', 'ja': '本稿では、用語を使用した機械翻訳に関するWMT 21共有タスクへのLingua Custodiaの提出について説明する。英語からフランス語、ロシア語、中国語の3つの方向性を検討しています。トランスフォーマーベースのアーキテクチャを基盤として、用語を扱うための標準的な手順に2つの主な変更を導入する方法を模索しています。1つ目は、モデルが用語の制約条件に遭遇したときにコピー動作を学習するように、トレーニングデータを拡張することです。2番目の変更は、制約トークンマスキングであり、コピー動作の学習を容易にし、モデルの一般化を改善することを目的としています。実証結果は、当社の方法が高い翻訳品質を維持しながら、ほとんどの用語の制約を満たしていることを示しています。', 'zh': '本文述Lingua Custodia言WMT21用术语之机器翻译。 臣等思三向,即英语至法语,俄语与中文。 因 Transformer 之架构以为构块,而求一术,引入术语二要。 一曰以劝模遇术语约项时学复制行以益练数。 二变约令牌掩码,其志简复制行学而模泛化。 经验结果表明,吾道足多术语约束,兼持高译。', 'hi': 'यह पेपर शब्दावली का उपयोग करके मशीन अनुवाद पर WMT21 साझा कार्य के लिए लिंगुआ कस्टोडिया के प्रस्तुतीकरण का वर्णन करता है। हम तीन दिशाओं पर विचार करते हैं, अर्थात् अंग्रेजी से फ्रेंच, रूसी और चीनी। हम एक बिल्डिंग ब्लॉक के रूप में एक ट्रांसफॉर्मर-आधारित आर्किटेक्चर पर भरोसा करते हैं, और हम एक ऐसी विधि का पता लगाते हैं जो शब्दावली को संभालने के लिए मानक प्रक्रिया में दो मुख्य परिवर्तनों का परिचय देती है। पहले एक में प्रशिक्षण डेटा को इस तरह से बढ़ाने में शामिल है कि मॉडल को एक प्रतिलिपि व्यवहार सीखने के लिए प्रोत्साहित किया जाए जब यह शब्दावली बाधा शर्तों का सामना करता है। दूसरा परिवर्तन बाधा टोकन मास्किंग है, जिसका उद्देश्य कॉपी व्यवहार सीखने को कम करना और मॉडल सामान्यीकरण में सुधार करना है। अनुभवजन्य परिणाम बताते हैं कि हमारी विधि उच्च अनुवाद गुणवत्ता को बनाए रखते हुए अधिकांश शब्दावली बाधाओं को संतुष्ट करती है।', 'ru': 'Эта статья описывает представление Lingua Custodia совместной задаче WMT21 по машинному переводу с использованием терминологии. Мы рассматриваем три направления, а именно: с английского на французский, русский и китайский. Мы полагаемся на архитектуру на основе трансформатора в качестве строительного блока и изучаем метод, который вносит два основных изменения в стандартную процедуру для обработки терминологии. Первый заключается в расширении обучающих данных таким образом, чтобы побудить модель к изучению поведения копирования, когда она сталкивается с терминологическими ограничениями. Второе изменение - это маскировка токенов ограничений, цель которой - облегчить обучение поведению копирования и улучшить обобщение модели. Эмпирические результаты показывают, что наш метод удовлетворяет большинству терминологических ограничений, сохраняя при этом высокое качество перевода.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht Lingua Custodia don tasc roinnte WMT21 maidir le haistriúchán meaisín ag baint úsáide as téarmaíocht. Breathnaímid ar thrí threoir, is iad sin Béarla go Fraincis, Rúisis agus Sínis. Táimid ag brath ar ailtireacht atá bunaithe ar Trasfhoirmeoir mar bhloc tógála, agus déanaimid iniúchadh ar mhodh a thugann dhá phríomhathrú isteach ar an nós imeachta caighdeánach chun téarmaíocht a láimhseáil. Is éard atá sa chéad cheann ná cur leis na sonraí oiliúna ar bhealach a spreagfaidh an tsamhail chun iompar cóipe a fhoghlaim nuair a thagann sé trasna ar théarmaí srianta téarmaíochta. Is é an dara hathrú ná cumhdach comharthaí srianta, arb é an aidhm atá leis ná foghlaim iompraíochta a chóipeáil a éascú agus ginearálú samhlacha a fheabhsú. Léiríonn torthaí eimpíreacha go sásaíonn ár modh an chuid is mó de shrianta téarmaíochta agus ardcháilíocht aistriúcháin á choinneáil ag an am céanna.', 'ka': 'ეს დოკუმენტი განახსენებს ლინგუა კუსტოდიის გადაწყვეტის WMT21 გაყოფილი რაოდენობაზე მაქინის გადაწყვეტის ტერმინოლოგიების გამოყენებით. ჩვენ ვფიქრობთ სამი დაწყვეტილება, ანგლისური, პრისური და ჩინეთი. ჩვენ ტრანფორმეტრის დაბათი აქტიქტიქტურაზე ვიყენებთ, როგორც კონფიგურაციის ბლოკზე, და ვიყენებთ მეთოდი, რომელიც ორი მნიშვნელოვანი ცვლილებები სტანდარტურა პირველი შეფარდება ტერმინოლოგიის შესაძლებლობის შესაძლებლობად მოდელის მოწყობილობას გასწავლა, როდესაც ტერმინოლოგიის შესაძლებლობის შესაძლებლობის შესაძლებლობაში. მეორე ცვლილება არის დარწმუნებული მასკენების მასკენი, რომელის მიზეზი არის გამოკლება ქცევის სწავლებას და უფრო მეტი გენერალზაციას. ამოვრიკალური წარმოდგენები ჩვენი მეთოდი უფრო მეთოდის ტერმინოლოგიის შესაძლებელება, როდესაც უფრო მეტი გადაწყვეტილება.', 'it': "Questo articolo descrive la sottomissione di Lingua Custodia al compito condiviso WMT21 sulla traduzione automatica utilizzando terminologie. Consideriamo tre direzioni, vale a dire dall'inglese al francese, dal russo e dal cinese. Facciamo affidamento su un'architettura basata su Transformer come elemento costitutivo ed esploriamo un metodo che introduce due modifiche principali alla procedura standard per gestire la terminologia. Il primo consiste nell'aumentare i dati di allenamento in modo da incoraggiare il modello ad apprendere un comportamento di copia quando incontra termini di vincolo terminologico. La seconda modifica è il mascheramento dei token di vincolo, il cui scopo è facilitare l'apprendimento del comportamento di copia e migliorare la generalizzazione dei modelli. I risultati empirici dimostrano che il nostro metodo soddisfa la maggior parte dei vincoli terminologici mantenendo un'elevata qualità della traduzione.", 'kk': 'Бұл қағаз терминологиялар арқылы компьютерді аудару үшін WMT21 ортақ тапсырмасына Lingua Custodia- ның жіберілуін анықтайды. Біз үш бағытты - ағылшын тіліне, французша, руссия және қытайша деп ойлаймыз. Біз түрлендіруші архитектурасын құрылғы блок ретінде тәуелдеп, терминологияларды басқару үшін стандартты процедураға екі негізгі өзгерістерді табу әдісін зерттейміз. Біріншісі терминологиялық шектелген терминологиялық шектеулерге қарсы көшірмелеу әрекетін оқыту үшін оқыту деректерін көшірмелеу үшін болады. Екінші өзгерістер - белгілер қалқасын шектеу, олардың мақсаты, қасиеттерді көшірмелеу және жалпы үлгілерді жақсарту үшін көшірмелеу. Эмпериялық нәтижелер біздің әдіміміз терминологиялық шектерін жоғары аудару сапасы сақтағанда сақтайды.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή της Lingua Custodia στο κοινό έργο WMT21 σχετικά με τη μηχανική μετάφραση χρησιμοποιώντας ορολογίες. Εξετάζουμε τρεις κατευθύνσεις, δηλαδή Αγγλικά προς Γαλλικά, Ρωσικά και Κινέζικα. Βασιζόμαστε σε μια αρχιτεκτονική βασισμένη στον μετασχηματιστή ως δομικό στοιχείο και εξερευνούμε μια μέθοδο που εισάγει δύο βασικές αλλαγές στην τυπική διαδικασία χειρισμού ορολογίας. Η πρώτη συνίσταται στην αύξηση των δεδομένων κατάρτισης με τέτοιο τρόπο ώστε να ενθαρρύνει το μοντέλο να μάθει μια συμπεριφορά αντιγραφής όταν συναντά όρους περιορισμού ορολογίας. Η δεύτερη αλλαγή είναι η μάσκα συμβολαίων περιορισμού, ο σκοπός του οποίου είναι να διευκολύνει την εκμάθηση συμπεριφοράς αντιγραφής και να βελτιώσει τη γενίκευση του μοντέλου. Τα εμπειρικά αποτελέσματα δείχνουν ότι η μέθοδος μας ικανοποιεί τους περισσότερους περιορισμούς ορολογίας διατηρώντας παράλληλα υψηλή ποιότητα μετάφρασης.', 'hu': 'Ez a cikk bemutatja, hogy a Lingua Custodia milyen feladatot nyújtott be a WMT21 gépi fordítással kapcsolatos megosztott feladathoz terminológiával. Három irányt veszünk figyelembe, nevezetesen angolul franciáig, oroszul és kínaiul. A transzformátor alapú architektúrára támaszkodunk, mint építőelemre, és egy olyan módszert vizsgálunk, amely két fő változtatást vezet be a terminológia kezelésére vonatkozó standard eljárásban. Az első az edzési adatok bővítéséből áll, hogy ösztönözze a modell másolási viselkedését, amikor terminológiai korlátozási kifejezésekkel találkozik. A második változás a korlátozás tokenmaszkolás, amelynek célja, hogy megkönnyítse a másolási viselkedés tanulását és javítsa a modell általánosítását. Az empirikus eredmények azt mutatják, hogy módszerünk megfelel a legtöbb terminológiai korlátozásnak, miközben magas fordítási minőséget biztosít.', 'ms': "This paper describes Lingua Custodia's submission to the WMT21 shared task on machine translation using terminologies.  We consider three directions, namely English to French, Russian, and Chinese.  We rely on a Transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies.  Yang pertama terdiri dalam menambah data latihan dengan cara untuk mendorong model untuk belajar perilaku salinan apabila ia bertemu terma ketat terminologi. The second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization.  Empirical results show that our method satisfies most terminology constraints while maintaining high translation quality.", 'mk': 'Овој весник го опишува поднесувањето на Лингва Кустодија на заедничката задача на WMT21 за машински превод со користење на терминологии. We consider three directions, namely English to French, Russian, and Chinese.  We rely on a Transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies.  Првата се состои од зголемување на податоците за обука на начин да го охрабри моделот да научи кописко однесување кога ќе се соочи со терминолошки обврски. The second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization.  Импирските резултати покажуваат дека нашиот метод ги задоволува повеќето терминолошки ограничувања и одржува висок квалитет на превод.', 'lt': 'Šiame dokumente aprašomas Lingua Custodia pateiktas WMT21 bendras darbas dėl vertimo mašinomis naudojant terminologijas. Mes svarstome tris kryptis: anglų kalba prancūzų, rusų ir kinų kalbomis. We rely on a Transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies.  Pirmasis – didinti mokymo duomenis taip, kad būtų skatinamas modelis mokytis kopijų elgesio, kai jis susiduria su terminologiniais apribojimais. Antrasis pakeitimas yra apribojimo žymenų maskavimas, kurio tikslas – palengvinti kopijų elgesio mokymąsi ir pagerinti modelio generalizaciją. Imperijos rezultatai rodo, kad mūsų metodas atitinka daugumą terminologinių apribojimų ir išlaiko aukštą vertimo kokybę.', 'no': 'Denne papiret skildrar å senda Lingua Custodia til WMT21 delt oppgåve på maskinsomsetjinga med terminologiar. Vi ser på tre retningar: engelsk til fransk, russisk og kinesisk. Vi har tilgang til ein transformeringsarkitektur som ein bygningsblok, og vi utforskar ein metode som introduserer to hovudendringar til standardprosessoren for handtering av terminologiar. Den første består i å auka opplæringsdata på slik måte som å oppfordre modellen til å lære ein kopiatferd når det oppstår med terminologiske begrensningsvilkår. Den andre endringa er avgrensa teiknmasker, som målet er å letta kopieringslæring og forbedra generellisering av modellen. Empiriske resultat viser at metoden vårt tilfredsstiller dei fleste terminologiske begrensningar mens høg omsetjingskvalitet vert lagt.', 'mn': 'Энэ цаас Лингуа Кустодийн WMT21-ийн хуваалцааны ажлыг терминологийг ашиглан машины хөрөнгө оруулах талаар тайлбарладаг. Бид англи хэлний, Орос, Хятад хэлний гурван зам гэж боддог. Бид Трансформер суурилсан архитектур барилга блок гэж итгэдэг. Бид терминологийг удирдах стандарт процедурын хоёр чухал өөрчлөлт хийх архитектурыг судалж байна. Эхний нэг нь сургалтын өгөгдлийг нэмэгдүүлэхэд үүнийг томъёог хязгаарлагддаг үед хууль загварыг сурах боломжтой болгодог. Хоёр дахь өөрчлөлт бол тодорхойлолтын газрын зураг, зорилго нь үйл ажиллагааны сургалтыг хялбарчлах, загварын ерөнхийлөгчийг сайжруулах. Эзэмшигийн үр дүнд бидний арга нь олон хэмжээний хэмжээний хязгаарлалтай байдаг гэдгийг харуулж байна.', 'ml': 'ടെര്\u200dമിനോളജികള്\u200d ഉപയോഗിച്ച് മെഷീന്\u200d പരിഭാഷണത്തില്\u200d പങ്കെടുത്ത ജോലിയുടെ അടുത്ത് ലിങ്കുവ കുസ്റ്റോട്ടിയുട നമ്മള്\u200d മൂന്നു വഴികളെ വിചാരിക്കുന്നു, ഫ്രെഞ്ച് ഇംഗ്ലീഷ്, റഷ്യന്\u200d, ചൈനീസിലേക്ക്. ടെര്\u200dമിനോളജികളെ കൈകാര്യം ചെയ്യാനുള്ള രണ്ട് പ്രധാന മാറ്റങ്ങള്\u200d പരിശോധിക്കുന്ന ഒരു രീതിയില്\u200d ഞങ്ങള്\u200d ആശ്രയിക്കുന്നു. ആദ്യം ട്രെയിനിലോളജി നിര്\u200dബന്ധിതമായ വ്യവസ്ഥകള്\u200d കണ്ടുമുട്ടുമ്പോള്\u200d ഒരു പകര്\u200dപ്പിക്കുന്ന സ്വഭാവം പഠിപ്പിക്കാന്\u200d മാതൃകയില്\u200d  രണ്ടാമത്തെ മാറ്റം ടോക്ക് മുഖം നിര്\u200dബന്ധിതമാക്കുന്നു. അതിന്റെ ലക്ഷ്യം പഠിക്കുന്നതിന്റെ പ്രവര്\u200dത്തനങ്ങള്\u200d പകര്\u200dത് എമിരിക്കല്\u200d ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ രീതിയില്\u200d മിക്കവാറും ടെര്\u200dമിനോളജി നിര്\u200dബന്ധങ്', 'pl': 'Niniejszy artykuł opisuje zgłoszenie Lingua Custodia do wspólnego zadania WMT21 dotyczącego tłumaczenia maszynowego z wykorzystaniem terminologii. Rozważamy trzy kierunki, a mianowicie angielski na francuski, rosyjski i chiński. Opieramy się na architekturze opartej na Transformerze jako budulcu i badamy metodę wprowadzającą dwie główne zmiany do standardowej procedury obsługi terminologii. Pierwszy polega na powiększeniu danych treningowych w taki sposób, aby zachęcić model do nauki zachowania kopiowania, gdy napotka terminologiczne terminologiczne terminologiczne ograniczenia. Druga zmiana to maskowanie tokenów ograniczeń, którego celem jest ułatwienie uczenia się zachowań kopiowania i poprawa uogólniania modelu. Wyniki empiryczne pokazują, że nasza metoda spełnia większość ograniczeń terminologicznych przy zachowaniu wysokiej jakości tłumaczeń.', 'mt': "This paper describes Lingua Custodia's submission to the WMT21 shared task on machine translation using terminologies.  Aħna nqisu tliet direzzjonijiet, jiġifieri l-Ingliż għall-Franċiż, ir-Russu u ċ-Ċiniż. Aħna nistrieħu fuq arkitettura bbażata fuq it-Trasformer bħala blokk tal-bini, u nesploraw metodu li jintroduċi żewġ bidliet ewlenin fil-proċedura standard għall-immaniġġjar tat-terminoloġiji. L-ewwel wieħed jikkonsisti fiż-żieda tad-dejta tat-taħriġ b’tali mod li jinkoraġġixxi lill-mudell jitgħallem imġiba ta’ kopja meta jiltaqa’ ma’ termini ta’ restrizzjoni terminoloġika. The second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization.  Empirical results show that our method satisfies most terminology constraints while maintaining high translation quality.", 'so': 'Warqaddan waxaa ku qoran warqada uu u dhiibo warqada WMT21 ee loo qaybiyey turjumaadda machine isticmaalka terminologies. We consider three directions, namely English to French, Russian, and Chinese.  Waxaynu isku hallaynaa dhismaha baabuurta ah sida dhismo oo kale, waxaynu baaraynaa qaab uu soo bandhigi karo laba beddelyo oo u bedela qalabka caadiga ah si ay u qabtaan terminology. Kii ugu horeysa waxaa ku jira in lagu kordhiyo macluumaadka waxbarashada sida qaabka aad u dhiirrigeliso tusaale ahaan in qaabka koobiga lagu barto hab-dhaqdhaqaaq marka uu buuxdo sharciga ku xadgudbay terminology. Isbedelka labaad waa maamul qasab ah, kaas oo qastigiisu waa inuu fududeeyo barashada koobiga iyo hagaajiyo qaababka sameynta. Xilliyadu waxay muuqataa in qaababkayagu uu ku raalli karo xaduudaha tirada galmada ee ugu badnaan marka uu sii haysto qiimaha turjumista sare.', 'ro': 'Această lucrare descrie transmiterea Lingua Custodia la sarcina partajată WMT21 privind traducerea automată folosind terminologii. Considerăm trei direcții, și anume engleză la franceză, rusă și chineză. Ne bazăm pe o arhitectură bazată pe Transformer ca element de bază și explorăm o metodă care introduce două modificări principale ale procedurii standard de gestionare a terminologiilor. Primul constă în creșterea datelor de formare astfel încât să încurajeze modelul să învețe un comportament de copiere atunci când întâlnește termeni de constrângere terminologică. A doua modificare este mascarea token-ului de constrângere, al cărui scop este de a ușura învățarea comportamentului de copiere și de a îmbunătăți generalizarea modelului. Rezultatele empirice arată că metoda noastră satisface majoritatea constrângerilor terminologice, menținând în același timp o calitate ridicată a traducerii.', 'sr': 'Ovaj papir opisuje podnošenje Lingua Custodije WMT21 zajedničkom zadatku o prevodu mašine koristeći terminologije. Smatramo tri smjera, a to je engleski francuski, ruski i kineski. Oslanjamo se na arhitekturu baziranu na transformatoru kao blok zgrade, i istražujemo metodu koja predstavlja dve glavne promene standardnoj proceduri za rješavanje terminologija. Prvi se sastoji u povećanju podataka obuke na način kako bi ohrabrili model da nauči kopijsko ponašanje kada se suočava sa terminološkim ograničenim uslovima. Druga promjena je ograničenje maskiranja znakova, čija je svrha je olakšanje učenja kopija ponašanja i poboljšanje modela generalizacije. Impirički rezultati pokazuju da naša metoda zadovoljava većinu terminologijskih ograničenja dok održava visoke kvalitete prevoda.', 'sv': 'Denna uppsats beskriver Lingua Custodias inlämning till WMT21 delade uppgift om maskinöversättning med hjälp av terminologier. Vi överväger tre riktningar, nämligen engelska till franska, ryska och kinesiska. Vi förlitar oss på en Transformer-baserad arkitektur som byggsten, och vi utforskar en metod som introducerar två huvudförändringar i standardproceduren för att hantera terminologier. Den första består i att utöka träningsdata på ett sådant sätt att modellen uppmuntras att lära sig ett kopieringsbeteende när den stöter på termer som begränsar terminologin. Den andra ändringen är tvångstokenmaskering, vars syfte är att underlätta inlärning av kopieringsbeteende och att förbättra modellgeneralisering. Empiriska resultat visar att vår metod uppfyller de flesta terminologikrav samtidigt som den håller hög översättningskvalitet.', 'ur': 'یہ کاغذ لینگو کوسٹوڈیا کے مطابق ٹریمولوژ کے استعمال کے ذریعے ماشین ترجمہ پر WMT21 مشترک کام کی سفارش کرتا ہے. ہم تین طریقے سمجھتے ہیں، یعنی انگلیسی، روسی اور چینی سے۔ ہم ایک ترنسفور بنیادی معماری پر ایک بنیادی بلاک کے طور پر بھروسہ کرتے ہیں، اور ہم ایک طریقہ کا تحقیق کرتے ہیں جس نے ترمینلوژوں کے تحمل کرنے کے لئے استاندارڈ پردازی کے دو اصلی تغییرات پیش کرتا ہے. پہلی شخص ایسے طریقے سے ہے کہ مدل کو کپی رفتار کی سفارش کرنا چاہے جبکہ اس سے ترمینلوژی محدودیت کی شرایطوں سے ملے۔ دوسری تغییر ٹوکین ماسک کرنے کی محدودیت ہے، جس کا مقصد یہ ہے کہ رفتار کی تعلیم آسانی کریں اور مدل کی عمومی تغییر کریں. امپراتیک نتائج دکھاتے ہیں کہ ہمارا طریقہ بہت سے ترمینلوژی محدودیت کرتا ہے جبکہ وہ بلند ترجمہ کیفیت حفاظت کرتا ہے۔', 'ta': 'இந்த தாள் லிங்குவா வழக்கம் WMT21 பகிர்ந்த பணி நாங்கள் மூன்று திசைகளை கருதுகிறோம், பிரெஞ்சு, ரஷ்சி, மற்றும் சீனியன் மீது ஆங்கிலம். நாங்கள் ஒரு கட்டுப்பாடு தொகுதியாக மாற்றும் அடிப்படையான அடிப்படையை நம்புகிறோம், நாம் ஒரு முறையை தேடுகிறோம், அது இரண்டு முக்கிய ம The first one consists in augmenting the training data in such a way as to encourage the model to learn a copy behavior when it encounters terminology constraint terms.  இரண்டாவது மாற்றம் குறியீட்டு மூடுதலை கட்டுப்படுத்தல் கட்டுப்படுத்தல், அதன் இலக்கு படிக்கப்பட்ட நடத்தையை எளிதாக்க மற்ற உயர்ந்த மொழிபெயர்ப்பு தரம் வைத்திருக்கும் போது எங்கள் முறைமையில் பெரும்பாலான முறையை திருப்தித் த', 'si': 'Name අපි පැත්තක් තුනක් හිතන්නේ ඉංග්\u200dරීසියාව ෆ්\u200dරෑන්ස්, රුසියාව, චීනියාව. අපි ගොඩනිර්මාණයක් විදිහට අධාරිත විදිහට විශ්වාස කරනවා, අපි ප්\u200dරධාන විදිහට පරික්ෂා කරනවා, තර්මිනේලෝජිකය පළමුවෙනි කෙනෙක් තියෙන්නේ ප්\u200dරධාන දත්ත විශාලනය කරලා තියෙන්නේ නිර්මාණයෙන් ප්\u200dරධානයක් ඉගෙන ගන්න ප්\u200dරධානයක්  දෙවෙනි වෙනස් තමයි ප්\u200dරමාණයක් තොකෙන් මාස්ක් කරනවා, එයාගේ අදහස් තමයි ප්\u200dරමාණයක් ඉගෙනගන්න සහ සාමාන්\u200dය වි අධ්\u200dයාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ විධානය අභ්\u200dයාෂික විශේෂ අභ්\u200dයාෂික විශේෂාව', 'vi': 'Tờ giấy này mô tả việc Lingua Cusodia đã đệ trình một nhiệm vụ chia s ẻ WM trong dịch vụ máy, sử dụng các tiên tri. Chúng tôi xem xét ba hướng, là Anh đến Pháp, Nga và Trung Quốc. Chúng ta dựa vào một kiến trúc biến hình nền như một khối nhà máy, và chúng ta khám phá một phương pháp đưa ra hai thay đổi chính trong thủ tục tiêu chuẩn để xử lý các tiên tri. Cái thứ nhất gồm việc tăng cường dữ liệu đào tạo để khuyến khích mô hình học hành vi sao chép khi nó gặp các điều khoản giới hạn thuật ngữ. Sự thay đổi thứ hai là biểu tượng giới hạn, có mục đích là dễ dàng học hành vi sao chép và cải thiện quy mô hình. Các kết quả của công nghệ cho thấy phương pháp này đáp ứng hầu hết các giới hạn về thuật ngữ, trong khi chất lượng dịch cao.', 'uz': "Name Biz uchta ta ta'limni o'ylaymiz, Fransuzcha, Ruscha va Xitoycha tilida. Biz o'zgarishga asoslangan arxituvchilarga ishlatamiz, va biz terminologni boshqarish uchun ikkita asosiy o'zgarishlarni o'rganamiz. Birinchi birinchi taʼminolog maʼlumotini oshirish mumkin, modelni terminalogi cheksiz soʻzlarda nusxa xususiyatlarni o'rganish mumkin. Ikkinchi oʻzgarishlar oddiy yozib qo'yish cheksiz, uning maqsadi o'rganish amalni saqlash va modelni yaratishni o'zgartirish mumkin. Empirical natijalari shunday ko'rsatadi, bizning usuli bir necha tarjima sifatini davom etishda ko'proq terminology tarjimalarini bajaradi.", 'hr': 'Ovaj papir opisuje podnošenje Lingua Custodia podijeljenom zadatku WMT21 o prevodu strojeva koristeći terminologije. Smatramo tri smjera, a to je engleski francuski, ruski i kineski. Oslanjamo se na građevinsku arhitekturu baziranu na transformeri kao blok zgrade, i istražujemo metodu koja predstavlja dvije glavne promjene standardnoj proceduri za rješavanje terminologija. Prvi se sastoji u povećanju podataka o obuci na način kako bi potaknuli model da nauči kopijsko ponašanje kada se suočava s terminološkim ograničenim uslovima. Druga promjena je ograničeno maskiranje znakova, čija je svrha je olakšanje učenja kopija ponašanja i poboljšanje modela generalizacije. Empirički rezultati pokazuju da naš metod zadovoljava većinu ograničenja terminologije dok održava visoke kvalitete prevoda.', 'nl': 'Dit artikel beschrijft de inzending van Lingua Custodia aan de gedeelde WMT21 taak over machinevertaling met behulp van terminologieën. We beschouwen drie richtingen, namelijk Engels naar Frans, Russisch en Chinees. We vertrouwen op een Transformer-gebaseerde architectuur als bouwsteen, en we verkennen een methode die twee belangrijke wijzigingen introduceert in de standaardprocedure voor terminologieën. De eerste bestaat uit het uitbreiden van de trainingsgegevens op een zodanige manier dat het model aanmoedigt om een kopieergedrag te leren wanneer het terminologiebeperkingen tegenkomt. De tweede wijziging is het maskeren van constraint token, met als doel het leren van kopieergedrag te vergemakkelijken en de generalisatie van modellen te verbeteren. Empirische resultaten tonen aan dat onze methode voldoet aan de meeste terminologische beperkingen en tegelijkertijd een hoge vertaalkwaliteit behoudt.', 'bg': 'Настоящата статия описва представянето на Lingua Custódia на споделената задача на WMT21 по машинен превод, използвайки терминологии. Разглеждаме три посоки, а именно английски към френски, руски и китайски. Разчитаме на базираната на трансформатор архитектура като градивен елемент и изследваме метод, който въвежда две основни промени в стандартната процедура за обработка на терминологиите. Първият се състои в увеличаване на данните за обучение по такъв начин, че да насърчи модела да научи поведение на копиране, когато срещне терминологични ограничения. Втората промяна е маскирането на символи с ограничения, чиято цел е да улесни ученето на поведение при копиране и да подобри обобщаването на модела. Емпиричните резултати показват, че методът ни отговаря на повечето терминологични ограничения, като същевременно поддържа високо качество на превода.', 'da': 'Dette dokument beskriver Lingua Custodias indsendelse til WMT21 delte opgave om maskinoversættelse ved hjælp af terminologier. Vi overvejer tre retninger, nemlig engelsk til fransk, russisk og kinesisk. Vi er afhængige af en Transformer-baseret arkitektur som byggesten, og vi undersøger en metode, der introducerer to hovedændringer i standardproceduren til håndtering af terminologier. Den første består i at udvide træningsdataene på en sådan måde, at modellen tilskyndes til at lære en kopiadfærd, når den støder på terminologibegrænsninger. Den anden ændring er begrænsning token masking, hvis formål er at lette kopiering adfærd læring og at forbedre model generalisering. Empiriske resultater viser, at vores metode opfylder de fleste terminologibegrænsninger og samtidig opretholder en høj oversættelseskvalitet.', 'de': 'Dieser Beitrag beschreibt die Einreichung von Lingua Custodia zur gemeinsamen Aufgabe WMT21 zur maschinellen Übersetzung unter Verwendung von Terminologien. Wir betrachten drei Richtungen, nämlich Englisch zu Französisch, Russisch und Chinesisch. Wir setzen auf eine Transformer-basierte Architektur als Baustein, und wir erforschen eine Methode, die zwei wesentliche Änderungen des Standardverfahrens für den Umgang mit Terminologien einführt. Die erste besteht darin, die Trainingsdaten so zu erweitern, dass das Modell ermutigt wird, ein Kopierverhalten zu erlernen, wenn es Terminologiebeschränkungen trifft. Die zweite Änderung ist das Maskieren von Constraint Token, dessen Zweck es ist, das Lernen von Kopierverhalten zu erleichtern und die Modellverallgemeinerung zu verbessern. Empirische Ergebnisse zeigen, dass unsere Methode die meisten terminologischen Einschränkungen erfüllt und gleichzeitig eine hohe Übersetzungsqualität beibehält.', 'fa': 'این کاغذ تحویل لینگوا کوستودیا را به کار مشترک WMT21 در ترجمه ماشین با استفاده از ترمنولوژی توصیف می\u200cکند. ما سه راه به نظر می گیریم، یعنی انگلیسی به فرانسوی، روسی و چینی. ما بر یک معماری بنیاد تغییر دهنده به عنوان یک بلوک ساختمان اعتماد داریم، و یک روش تحقیق می کنیم که دو تغییر اصلی را به روش استاندارد معرفی می کند تا با ترمینالوژی کنترل کند. اولین نفر در افزایش داده های آموزش به عنوان شکل تشویق به مدل برای یاد گرفتن رفتار کپی وقتی با شرایط محدودیت ترمینالوژی روبرو می شود. تغییر دوم ماسک نشانه\u200cهای محدودیت است که هدف آن است برای آسان کردن یادگیری رفتار و بهبود کردن مدل عمومی است. نتایج امپراطوری نشان می دهد که روش ما بیشترین محدودیت ترمینالوژی را در زمان حفظ کیفیت ترجمه بالا تحمل می کند.', 'ko': '본고는 Lingua Custodia가 WMT21 공유 작업에 제출한 용어를 사용하여 기계 번역에 대한 정보를 기술한다.우리는 영어부터 프랑스어, 러시아어, 중국어까지 세 가지 방향을 고려한다.우리는 변환기의 체계 구조를 바탕으로 구축 블록으로 삼아 처리 용어의 표준 과정에 대해 두 가지 주요 변경 방법을 모색했다.첫 번째 방법은 훈련 데이터를 늘려 모델이 용어의 구속 조건에 부딪혔을 때 복제 행위를 배우도록 장려하는 것이다.두 번째 변화는 제약 표지 엄폐인데 그 목적은 복제 행위 학습을 간소화하고 모델의 범위화를 개선하는 것이다.실증 결과에 의하면 우리의 방법은 높은 번역의 질을 유지하는 동시에 대부분의 용어의 제약을 만족시킨다.', 'sw': 'Gazeti hili linaelezea ujumbe wa Lingua Custodia uliofanywa na kazi ya WMT21 inayoshirikishwa kwenye tafsiri ya mashine kwa kutumia tamaduni. Tunaona maelekezo matatu, yaani Kiingereza kwa Kifaransa, Urusi na Kichina. Tunategemea jengo lililoko kwa mtazamo wa zamani kama kizuizi cha jengo, na tunatafuta njia ambayo inaonyesha mabadiliko makubwa mawili ya utaratibu wa kiwango cha kawaida ili kukabiliana na vitendo vya ngono. Kipindi cha kwanza kinahusisha kuongeza takwimu za mafunzo kwa namna ya kuhamasisha model kujifunza tabia za nusura pale inapokutana na vipengele vikwazo vya utekelezaji. Mabadiliko ya pili ni vikwazo vya kufungia alama, lengo lake ni kusaidia kujifunza na kujifunza na kuboresha uzalishaji wa mifano. Matokeo ya matumaini yanaonyesha kuwa njia yetu inaridhia vikwazo vingi vya uchunguzi wakati wa kudhibiti kiwango kikubwa cha tafsiri.', 'af': "Hierdie papier beskryf Lingua Custodia se onderskrywing na die WMT21 gedeelde taak op masjien vertaling deur terminologies te gebruik. Ons besluit drie rigtings, naamlik Engels tot Frans, Russe en Sjinees. Ons vertrou op 'n Transformer-gebaseerde arkitektuur as 'n boublok, en ons ondersoek 'n metode wat twee hoofveranderinge voorsien aan die standaard prosedure om terminologies te hanteer. Die eerste een bestaan in die vergroot onderwerp data op so 'n manier as om die model te bevestig om 'n kopie gedrag te leer wanneer dit teen terminologie beperking terme teentrek. Die tweede verandering is beheinde token maskering, wie se doel is om kopie gedrag leer te maak en om model generellisering te verbeter. Enige resultate wys dat ons metode die meeste terminologie beperk terwyl hoë vertaling kwaliteit onderhou.", 'tr': "Bu kağıt Lingua Custodia'nin WMT21'a terminolog kullanarak makine tercüme üzerinde paylaşın görevini tanıtır. Biz üç ýoly diýip pikir edýäris, iňlisçe, fransuzça, Rusça we Çinçe. Biz Transformer tabanly bir arhitektura bina blok hökmünde baglanýarys we terminologilary ýönetmek üçin 2 üns üýtgewini tapýarys. Ilkinji adam terminologiýanyň azaltylyk şartlary bilen nusgasyny öwrenmek üçin nusgasyny artýan ýaly şekilde guruldyrylýar. Ikinji üýtgeşik, token maskasy mümkin edýär. Olaryň maksady işleri öwrenmegi kolaylaşdyrmak we nusgasyny düzeltmekdir. Wagtlaýyn netijelerimiz terminologiýanyň iň köp terjime kaliýetini baglaýan ýagdaýda tanyş edýändigini görkezýär.", 'am': 'ይህ ገጽ የኢንተርሚኖሎጂ ተርሚኖጂዎች በተጠቃሚ የመረጃ ትርጓሜ ላይ የተካፈለውን ስራ ለሚያሳየው Lingua Custodia ያሳያል፡፡ እንግሊዘኛ፣ ፈረንሳይኛ፣ ራሽኛ እና ቻይናዊ የሦስት መንገድ እናስባለን፡፡ ተርሚኖሎጂን ለመቀበል ሁለት የዋና ለውጦች በሚያሳየው ሥርዓት ላይ የሚታመን የግንኙነት መሠረት እናደርጋለን፡፡ የመጀመሪያው ተማሪ ዳታዎችን በመጨመር እንደዚህ ሞዴል የኮፒ ሁኔታ ተርሚኖጂ ግንኙነት ግንኙነት ሲያገኝ ለማስተማር የሚችል ነው፡፡ ሁለተኛይቱ ለውጥ የግድ ምልክት ማሳየት ነው፡፡ የእነርሱም ጉዳዩ የቅጂ ትምህርት ማቀናቀል እና የሞዴል ማቀናቀል ማሻሻል ነው፡፡ የውጤቶች ፍሬዎች ከፍተኛ ትርጉም ጥሩ በመጠበቅ ጊዜ የሥርዓታችን ግንኙነትን አብዛኛውን ተርሚኖችን እንዲያደላድል ያሳያል፡፡', 'sq': 'Ky dokument përshkruan paraqitjen e Kustodias Lingua në detyrën e përbashkët të WMT21 për përkthimin e makinave duke përdorur terminologji. Ne konsiderojmë tre drejtime, në mënyrë angleze në francez, rus dhe kinez. Ne mbështetemi në një arkitekturë me bazë në Transformer si një bllok ndërtimi, dhe eksplorojmë një metodë që fut dy ndryshime kryesore në procedurën standard për trajtimin e terminologjive. I pari përbëhet në rritjen e të dhënave të trajnimit në mënyrë që të inkurajojë model in për të mësuar një sjellje kopje kur përballet me terma të kufizuara terminologjike. Ndryshimi i dytë është maskimi i kufizuar i token, qëllimi i të cilit është të lehtësojë mësimin e sjelljes së kopjes dhe të përmirësojë gjeneralizimin e modelit. Rezultatet perandore tregojnë se metoda jonë përmbush shumicën e kufizimeve terminologjike duke mbajtur cilësinë e lartë të përkthimit.', 'az': "Bu kağıt Lingua Custodia'nin WMT21'nin paylaşılmış işlərini terminoloqları vasitəsilə birlikdə maşın tercüməsində təsdiqləyib edir. Biz üç tərəf, yani Fransız, Rus və Çincə dilində İngilizce dilində düşünürük. Biz Transformer tabanlı bir arhitektura bina bloğu olaraq təvəkkül edirik və terminoloğu idarə etmək üçün standart prosedüsinə iki ana dəyişiklik göstərir. İlk təhsil məlumatlarını böyükləmək üçün modeli terminoloji sıxıntılı şartları ilə qarşılaşdığı zaman kopiya davranışlarını öyrənmək üçün təhsil etmək üçün məlumatları artırmaqdır. İkinci dəyişiklik, həqiqətən də, işlər öyrənməsini asanlaşdırmaq və modelləri generalizaşdırmaq üçün müəyyən edilən möcüzələr maskasıdır. Empirical results show that our method satisfies most terminology constraints while maintaining high translation quality.", 'bn': 'এই প্রবন্ধে লিঙ্গুয়া কুস্টুডিয়া টার্মিনোলজি ব্যবহার করে মেশিন অনুবাদের ব্যাপারে উইএমটি২১-এর প্রতি প্রকাশি আমরা তিনটি নির্দেশ বিবেচনা করি, যার মাধ্যমে ফরাসি, রাশিয়ান এবং চীনের ইংরেজী। আমরা একটি বিল্ডিং ব্লক হিসেবে একটি ট্রান্সফার্ন ভিত্তিক কাঠামোর উপর নির্ভর করি, আর আমরা একটি পদ্ধতি খুঁজে বের করি যা টার্মিনোলজির মাধ্যমে দ প্রথমে প্রশিক্ষণের তথ্য যোগাযোগ করার উদ্দেশ্যে মডেলটিকে অনুপ্রাণিত করার জন্য অনুপ্রাণিত করা হচ্ছে টার্মিনোলজি সীমাবদ্ধ শর্তে দ্বিতীয় পরিবর্তন হচ্ছে সীমাবদ্ধ চিহ্নের মুখোশ, যার উদ্দেশ্য হচ্ছে তাদের আচরণ শিক্ষা কপি শিক্ষা এবং মডেল সংস্করণ সম্মানিত ফলাফল দেখাচ্ছে যে আমাদের পদ্ধতি বেশীরভাগ টার্মিনোলজি নিয়মের প্রতি সন্তুষ্ট হয়েছে যখন উচ্চ অনুবাদের ম', 'id': "This paper describes Lingua Custodia's submission to the WMT21 shared task on machine translation using terminologies.  Kami mempertimbangkan tiga arah, yaitu bahasa Inggris ke Perancis, Rusia, dan Cina. We rely on a Transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies.  Yang pertama terdiri dalam meningkatkan data pelatihan dengan cara untuk mendorong model untuk belajar perilaku salinan ketika ia bertemu istilah batasan terminologi. The second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization.  Hasil kerajaan menunjukkan bahwa metode kita memenuhi kebanyakan batasan terminologi sambil mempertahankan kualitas terjemahan tinggi.", 'bs': 'Ovaj papir opisuje podnošenje Lingua Custodije podijeljenom zadatku WMT21 o prevodu mašine koristeći terminologije. Smatramo tri smjera, a to je engleski na francuski, ruski i kineski. Oslanjamo se na građevinu baziranu na transformatorskoj arhitekturi kao blok zgrade, i istražujemo metodu koja predstavlja dvije glavne promjene standardnoj proceduri za rješavanje terminologija. Prvi se sastoji u povećanju podataka o obuci na način kako bi ohrabrili model da nauči kopijsko ponašanje kada se suočava sa terminologijom s ograničenim uslovima. Druga promjena je ograničeno maskiranje znakova, čija je svrha je olakšanje učenja kopija ponašanja i poboljšanje modela generalizacije. Empirički rezultati pokazuju da naša metoda zadovoljava većinu ograničenja terminologije dok održava visoke kvalitete prevoda.', 'ca': "Aquest article descriu la presentació de Lingua Custodia a la tasca compartida WMT21 sobre traducció màquina utilitzant terminologies. Considerem tres direccions, a saber anglès a francès, rus i xinès. Esperem en una arquitectura basada en Transformer com un bloc de construcció, i explorem un mètode que introdueix dos canvis principals al procediment estàndard per gestionar terminologies. La primera consisteix en augmentar les dades d'entrenament d'una manera que anima el model a aprendre un comportament de còpia quan troba termes de restricció terminològica. El segon canvi és limitar la mascara de fitxes, l'objectiu del qual és facilitar l'aprenentatge del comportament de còpia i millorar la generalització del model. Els resultats empírics mostren que el nostre mètode satisfet la majoria de restriccions terminològices mantenint una alta qualitat de traducció.", 'cs': 'Tento článek popisuje podání Lingua Custodia do sdíleného úkolu WMT21 v oblasti strojového překladu pomocí terminologie. Zvažujeme tři směry, konkrétně angličtinu do francouzštiny, ruštinu a čínštinu. Spoléháme na architekturu založenou na Transformeru jako stavební blok a zkoumáme metodu, která zavádí dvě hlavní změny standardního postupu pro zpracování terminologie. První z nich spočívá v rozšíření tréninkových dat tak, aby se model naučil kopírovat chování, když narazí na termíny omezení terminologie. Druhou změnou je maskování tokenů omezení, jehož účelem je usnadnit učení se chování kopírování a zlepšit zobecnění modelu. Empirické výsledky ukazují, že naše metoda splňuje většinu terminologických omezení při zachování vysoké kvality překladu.', 'et': 'Käesolevas artiklis kirjeldatakse Lingua Custodia esitamist WMT21 ühisele masintõlke ülesandele terminoloogiate abil. Me kaalume kolme suunda, nimelt inglise kuni prantsuse, vene ja hiina. Me toetume transformaatoril põhinevale arhitektuurile kui ehitusplokile ning uurime meetodit, mis toob sisse kaks peamist muudatust standardprotseduuri terminoloogia käsitlemiseks. Esimene neist seisneb koolitusandmete täiendamises viisil, mis julgustab mudelit õppima kopeerimiskäitumist terminoloogiliste piirangutega seotud terminitega. Teine muudatus on piirangute märkide maskeerimine, mille eesmärk on lihtsustada kopeerimiskäitumise õppimist ja parandada mudeli üldistamist. Empiirilised tulemused näitavad, et meie meetod vastab enamikule terminoloogilistele piirangutele, säilitades samas kõrge tõlkekvaliteedi.', 'fi': 'Tässä artikkelissa kuvataan Lingua Custodian tekemää työtä WMT21:n yhteiseen tehtävään konekääntämisestä terminologian avulla. Tarkastelemme kolmea suuntaa, nimittäin englantia ranskaan, venäjää ja kiinaa. Luotamme Transformer-pohjaiseen arkkitehtuuriin rakennuspalikkana ja tutkimme menetelmää, joka tuo kaksi keskeistä muutosta termien käsittelyyn. Ensimmäinen on harjoitusdatan lisääminen siten, että malli oppii kopiointikäyttäytymisen kohdatessaan terminologisia rajoituksia. Toinen muutos on rajoitusmerkkien masking, jonka tarkoituksena on helpottaa kopiointikäyttäytymisen oppimista ja parantaa mallin yleistämistä. Empiiriset tulokset osoittavat, että menetelmämme täyttää useimmat terminologian vaatimukset säilyttäen samalla korkean käännöslaadun.', 'hy': 'Այս հոդվածը նկարագրում է Լինգուա Կուստոդիայի ներկայացումը ԱՄԹ21-ի համագործակցած աշխատանքի վերաբերյալ մեքենայի թարգմանման տերմինոլոգիաների միջոցով: Մենք դիտարկում ենք երեք ուղղություն, այն է՝ անգլերեն ֆրանսերեն, ռուսերեն և չինարեն: Մենք հիմնված ենք Թանֆորմերի հիմնված ճարտարապետության վրա որպես կառուցվածքային շրջանակ, և ուսումնասիրում ենք մի մեթոդ, որը ներկայացնում է երկու հիմնական փոփոխություն ստանդարտ գործընթացի վերաբերյալ տերմինոլոգիաների հետ: Առաջինը նշանակում է ավելացնել ուսուցման տվյալները այնպես, որ խրախուսել է մոդելը սովորել կոպիայի վարքագիծը, երբ այն հանդիպում է տերմինոլոգիայի սահմանափակումների տերմինների: Երկրորդ փոփոխությունը նշանների սահմանափակումն է, որի նպատակն է նվազեցնել կոպիայի վարքագծի սովորելը և բարելավել մոդելների ընդհանուր ընդլայնումը: Իմպրիկական արդյունքները ցույց են տալիս, որ մեր մեթոդը բավարարում է տերմինոլոգիական սահմանափակումները, մինչդեռ պահպանում է բարձր թարգմանման որակը:', 'jv': 'Ngetongkat iki rambarang nggambar Situang Linua Custodia s nang daftar arka WWT 22 neng penting panggunakan itoleng, gambar terminal. Awak dhéwé sawetara tanggal, nambah Inggris, Rus, lan Cines. We use on a Transformer-bazed architecture as a Binding blocks, and we istrage a method that preambes 2 basic change to the Standard method to handle terminal logies. Awak dhéwé sing rumangsa nêmên ngerasakno dadi aturan nggawe gerakan ning acara dadi, dadi nggawe modèl kanggo ngregani aturan kopi Display information Rejalakno empir sing ngomong nik nggambar sistem sing gagasar tentang kanggo ngerasar wigatining tentang', 'sk': 'Ta prispevek opisuje predložitev Lingue Custodia v skupno nalogo WMT21 o strojnem prevajanju z uporabo terminologije. Obravnavamo tri smeri, in sicer angleščina v francoščino, rusko in kitajsko. Kot gradnik se zanašamo na transformatorsko arhitekturo in raziskujemo metodo, ki uvaja dve glavni spremembi standardnega postopka obravnavanja terminologij. Prvi vključuje povečanje podatkov o usposabljanju tako, da se model spodbudi, da se nauči obnašanja kopiranja, ko naleti na terminološke omejitve. Druga sprememba je maskiranje žetonov omejitev, katerega namen je olajšati učenje kopiranja vedenja in izboljšati generalizacijo modela. Empirični rezultati kažejo, da naša metoda izpolnjuje večino terminoloških omejitev in hkrati ohranja visoko kakovost prevajanja.', 'ha': "@ info: whatsthis Tuna ƙaddara shiryarwa uku, kamar Ingiriya zuwa Faransa, Ruushi da China. We rely on a Transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies.  Kiwa na farko yana ƙara a ƙara da data masu amfani da kwamfyuta kamar yadda za'a kwaɗayi wa motel ya sanar da aikin kofi idan ya haɗi tsarin bakwai. Babu musanyi na biyu ana ƙayyade maɓallin ayuka, wanda ke so, don ya sauƙi kwamfyutan karantar kofi kuma ya kyautata ƙidãyar motel. Mataimakin Empirical na nuna cewa metodenmu yana yarda da tsari mafi yawanci na taƙaitãwa a lokacin da za'a tsare sifar fassarar.", 'he': 'העיתון הזה מתאר את ההעברה של לינגווה קוסטודיה למשימה משותפת WMT21 על תרגום מכונות באמצעות טרמולוגיות. אנחנו שוקלים שלושה כיוונים, כלומר אנגלית לצרפתית, רוסית וסינית. אנו סומכים על ארכיטקטורה מבוססת בטרנספורר כבלוק בניין, ואנחנו חוקרים שיטה שמציג שני שינויים ראשיים לנהל הסטנדרטי לטפל בטרמונולוגיות. הראשון כולל לגדל את נתוני האימון באופן שמעודד את המודל ללמוד התנהגות העתקית כשהוא פוגש בתנאים של מחסום טרמולוגי. השינוי השני הוא מסיכת סימנים מוגבלות, המטרה שלהם היא להקל את הלימוד של התנהגות העתקית ולהשפר את הגנרליזציה של מודל. התוצאות האימפריות מראות שהשיטה שלנו מספקת את רוב ההגבלות הטרמינולוגיות בזמן שמירת איכות התרגום גבוהה.', 'bo': "This paper describes Lingua Custodia's submission to the WMT21 shared task on machine translation using terminologies. ང་ཚོས་དབྱིན་ཡིག་གཟུགས་གསུམ་ལ་བསམ་བྱས་པ་ཡིན། མིན་ཚིག་དང་། རྒྱ་ནག་དང་། We rely on a Transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies. The first one consists in augmenting the training data in such a way as to encourage the model to learn a copy behavior when it encounters terminology constraint terms. The second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization. གཙོ་བ་འབྱོར་གྱི་འབྲུག"}
{'en': 'Kakao Enterprise’s WMT21 Machine Translation Using Terminologies Task Submission', 'ar': 'الترجمة الآلية WMT21 من Kakao Enterprise باستخدام إرسال مهام المصطلحات', 'pt': 'Tradução automática WMT21 da Kakao Enterprise usando terminologias Envio de tarefas', 'es': 'Traducción automática WMT21 de Kakao Enterprise mediante el envío de tareas terminológicas', 'fr': "Soumission de tâches de traduction automatique WMT21 à l'aide de terminologies de Kakao Enterprise", 'ja': 'カカオエンタープライズのWMT 21用語を使用した機械翻訳タスクの提出', 'hi': 'Kakao एंटरप्राइज़ के WMT21 मशीन अनुवाद शब्दावली कार्य सबमिशन का उपयोग कर', 'zh': 'Kakao 企业版 WMT21 机器翻译用术语事', 'ru': 'Перевод WMT21 Kakao Enterprise Машины Используя Представление Задачи Терминологий', 'ga': 'Aighneacht Tasc Aistriúcháin Inneallta ag Úsáid Téarmaíochta ag Kakao Enterprise WMT21', 'el': 'Η μηχανική μετάφραση WMT21 της εταιρείας Kakao χρησιμοποιώντας ορολογίες Υποβολή εργασιών', 'ka': 'Comment', 'lt': 'Kakao įmonės WMT21 mašinų vertimas naudojant terminologijas', 'it': 'Traduzione automatica WMT21 di Kakao Enterprise utilizzando terminologie', 'mk': 'Превод на WMT21 машински превод на Kakao Enterprise користејќи терминолошки задачи', 'kk': 'Comment', 'mt': 'It-Traduzzjoni tal-Makkinarju WMT21 tal-Intrapriża Kakao bl-Użu tat-Terminoloġiji', 'ms': 'Perjemahan Mesin WMT21 Kakao Enterprise menggunakan Submission Tugas Terminologi', 'hu': 'Kakao Enterprise WMT21 gépi fordítása terminológiák segítségével Feladat beküldése', 'pl': 'Tłumaczenie maszynowe WMT21 Kakao Enterprise z wykorzystaniem terminologii', 'ml': 'കാക്കാവോ എന്\u200dടെര്\u200dപ്രൈസ്സിന്\u200dറെ WMT21 മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നത് ടെര്\u200dമിനിലോജികളുടെ ടാസ്ക് സബ്', 'mn': "Kakao Enterprise's WMT21 Machine Translation Using Terminologies Task Submission", 'ro': 'Traducerea automată WMT21 a Kakao Enterprise folosind terminologii', 'si': 'Name', 'sr': "Kakao Enterprise's WMT21 Machine Translation Koristi Terminologies Task Submission", 'so': "Kakao Enterprise's WMT21 Machine Translation using Terminologies Task Submission", 'no': 'Comment', 'ta': "Kakao Enterprise' s WMT21 Machine Translation using terminalologies Task Submission", 'sv': 'Kakao Enterprise WMT21 maskinöversättning med hjälp av terminologier', 'ur': "Kakao Enterprise's WMT21 Machine Translation using Terminologies Task Submission", 'uz': 'Name', 'vi': "Máy Quay địa phương của Kakao Enterprise's WM21 Translation nhờ bộ dạng cuối cùng", 'bg': 'Машинен превод на Какао Ентърпрайз с използване на терминологии Изпращане на задачи', 'da': 'Kakao Enterprise WMT21 maskinoversættelse ved hjælp af terminologier Opgave Indsendelse', 'nl': 'WMT21 Machine Translation van Kakao Enterprise met behulp van terminologieën Taakindiening', 'hr': "Kakao Enterprise's WMT21 Machine Translation Koristi Terminologies Task Submission", 'ko': '카카오 Enterprise용 WMT21 번역 용어 작업 제출', 'id': "Kakao Enterprise's WMT21 Machine Translation Using Terminologies Task Submission", 'de': 'Die maschinelle Übersetzung WMT21 von Kakao Enterprise unter Verwendung von Terminologien', 'af': 'Comment', 'sw': 'Tafsiri ya Mashine ya WMT21 ya Kakao kwa kutumia Tamko la Tamko la Tamko', 'fa': 'ترجمه ماشین WMT21 از انترنپرایز Kakao', 'sq': 'Përkthimi i Makinës WMT21 i Kakao Enterprise duke përdorur detyrat e Terminologjisë', 'am': "Kakao Enterprise' s WMT21 Machine Translation using Terminologies Task Submission", 'tr': "Kakao Enterprise's WMT21 Machine Translation Using Terminologies Task Submission", 'bs': "Kakao Enterprise's WMT21 Machine Translation Koristi Terminologies Task Submission", 'ca': "Kakao Enterprise's WMT21 Machine Translation Using Terminologies Task Submission", 'cs': 'Strojový překlad WMT21 společnosti Kakao Enterprise s využitím terminologií', 'az': "Kakao Enterprise's WMT21 Machine Translation using Terminologies Task Submission", 'hy': 'Comment', 'bn': 'কাকাও এন্টারপ্রাইজের WMT21 মেশিন অনুবাদ ব্যবহার করে', 'et': 'Kakao Enterprise WMT21 masintõlge terminoloogiate ülesannete esitamise abil', 'fi': 'Kakao Enterprisen WMT21 Machine Translation using Terminologies Task Submission', 'jv': "Kalike EntrPrizer's Wt1 Masjin Tarjamahan Ngawe Terminal Inlogies task Submis", 'ha': 'KCharselect unicode block name', 'sk': 'Kakao Enterprise strojni prevod WMT21 z uporabo terminologij predložitev opravil', 'he': "Kakao Enterprise's WMT21 Machine Translation Using Terminologies Task Submission", 'bo': "Kakao Enterprise's WMT21 Machine Translation Using Terminologies Task Submission"}
{'en': 'This paper describes Kakao Enterprise’s submission to the WMT21 shared Machine Translation using Terminologies task. We integrate terminology constraints by pre-training with target lemma annotations and fine-tuning with exact target annotations utilizing the given terminology dataset. This approach yields a model that achieves outstanding results in terms of both translation quality and term consistency, ranking first based on COMET in the EnFr language direction. Furthermore, we explore various methods such as ', 'fr': "Cet article décrit la soumission de Kakao Enterprise à la tâche partagée de traduction automatique à l'aide de terminologies WMT21. Nous intégrons les contraintes terminologiques en effectuant un pré-entraînement avec des annotations de lemmes cibles et en les ajustant avec des annotations cibles exactes en utilisant l'ensemble de données terminologiques donné. Cette approche permet d'obtenir un modèle qui obtient des résultats exceptionnels en termes de qualité de traduction et de cohérence terminologique, se classant premier sur la base de COMET dans le sens de la langue En→Fr. En outre, nous explorons diverses méthodes telles que la rétro-traduction, la formation explicite de terminologies en tant que données parallèles supplémentaires et la sélection de données dans le domaine.", 'es': 'Este documento describe el envío de Kakao Enterprise a la tarea de traducción automática compartida mediante terminologías de WMT21. Integramos las restricciones terminológicas mediante el entrenamiento previo con anotaciones de lema objetivo y el ajuste con anotaciones objetivo exactas utilizando el conjunto de datos terminológico dado. Este enfoque produce un modelo que logra resultados sobresalientes en términos de calidad de la traducción y coherencia de los términos, ocupando el primer lugar en función de COMET en la dirección del lenguaje En→Fr. Además, exploramos varios métodos, como la retrotraducción, el entrenamiento explícito de terminologías como datos paralelos adicionales y la selección de datos en el dominio.', 'ar': 'تصف هذه الورقة تقديم Kakao Enterprise إلى مهمة الترجمة الآلية المشتركة WMT21 باستخدام المصطلحات. نقوم بدمج قيود المصطلحات من خلال التدريب المسبق مع شروح Lemma المستهدفة والضبط الدقيق مع التعليقات التوضيحية المستهدفة الدقيقة باستخدام مجموعة بيانات المصطلحات المحددة. ينتج عن هذا النهج نموذج يحقق نتائج رائعة من حيث جودة الترجمة واتساق المصطلح ، ويحتل المرتبة الأولى بناءً على COMET في اتجاه اللغة En → Fr. علاوة على ذلك ، نستكشف طرقًا مختلفة مثل الترجمة العكسية ، ومصطلحات التدريب بشكل صريح كبيانات موازية إضافية ، واختيار البيانات في المجال.', 'pt': 'Este artigo descreve o envio da Kakao Enterprise para a tarefa de tradução automática compartilhada do WMT21 usando terminologias. Integramos restrições de terminologia por meio de pré-treinamento com anotações de lema de destino e ajuste fino com anotações de destino exatas utilizando o conjunto de dados de terminologia fornecido. Esta abordagem produz um modelo que alcança excelentes resultados em termos de qualidade de tradução e consistência de termos, ficando em primeiro lugar com base no COMET na direção do idioma En→Fr. Além disso, exploramos vários métodos, como tradução reversa, terminologias de treinamento explícito como dados paralelos adicionais e seleção de dados no domínio.', 'ja': '本稿では、カカオエンタープライズがWMT 21共有機械翻訳タスクに提出した用語について説明する。私たちは、事前トレーニングをターゲットレンマアノテーションと統合し、与えられた用語データセットを使用してターゲットアノテーションを正確に微調整することによって、用語の制約を統合します。このアプローチは、翻訳品質と用語の一貫性の両方で卓越した結果を達成するモデルを生み出し、En→ Fr言語方向のCOMETに基づいて1位になります。さらに、バック翻訳、追加の並列データとして明示的にトレーニングする用語、ドメイン内データの選択など、さまざまな方法を探求しています。', 'zh': '本文引 Kakao Enterprise 共 WMT21 机器翻译用术语事者。 吾以所引注为预训练,因给定之术语数集对精者为微,以成术语约束。 其法生于译术语一致性,皆得其效,COMET于En→Fr言向第一。 又探索诸法,如回溯译、将术语显式训练为附并行数据及域内数据选择。', 'hi': 'यह पेपर Kakao एंटरप्राइज़ के WMT21 साझा मशीन अनुवाद के लिए प्रस्तुत करने का वर्णन करता है शब्दावली कार्य का उपयोग कर. हम दिए गए शब्दावली डेटासेट का उपयोग करके सटीक लक्ष्य एनोटेशन के साथ लक्ष्य लेमा एनोटेशन और ठीक-ट्यूनिंग के साथ पूर्व-प्रशिक्षण द्वारा शब्दावली बाधाओं को एकीकृत करते हैं। यह दृष्टिकोण एक मॉडल उत्पन्न करता है जो अनुवाद की गुणवत्ता और शब्द स्थिरता दोनों के संदर्भ में उत्कृष्ट परिणाम प्राप्त करता है, जो एन→एफआर भाषा दिशा में धूमकेतु के आधार पर पहले स्थान पर है। इसके अलावा, हम विभिन्न तरीकों का पता लगाते हैं जैसे बैक-ट्रांसलेशन, स्पष्ट रूप से अतिरिक्त समानांतर डेटा के रूप में शब्दावली को प्रशिक्षण देना, और इन-डोमेन डेटा चयन।', 'ru': 'В этой статье описывается представление Kakao Enterprise для совместного машинного перевода WMT21 с использованием терминологии. Мы интегрируем терминологические ограничения путем предварительного обучения с целевыми аннотациями леммы и точной настройки с точными целевыми аннотациями с использованием данного набора терминологических данных. Этот подход дает модель, которая достигает выдающихся результатов как с точки зрения качества перевода, так и согласованности терминов, занимая первое место на основе КОМЕТЫ в направлении языка En→Fr. Кроме того, мы исследуем различные методы, такие как обратный перевод, явное обучение терминологии в качестве дополнительных параллельных данных и выбор внутридоменных данных.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht Kakao Enterprise don tasc Aistriúcháin Meaisín comhroinnte WMT21 ag baint úsáide as Téarmaíocht. Comhtháthaimid srianta téarmaíochta trí réamhoiliúint le nodataí leamaí sprice agus mionchoigeartú le nodaireachtaí cruinne ag baint úsáide as an tacar sonraí téarmaíochta a thugtar. Cruthaíonn an cur chuige seo múnla a ghnóthaíonn torthaí sármhaithe ó thaobh cháilíocht an aistriúcháin agus comhsheasmhachta téarma araon, ag rangú ar dtús bunaithe ar COMET sa treo teanga En→Fr. Ina theannta sin, déanaimid iniúchadh ar mhodhanna éagsúla cosúil le haisaistriúchán, go sainráite oiliúint téarmaíochta mar shonraí comhthreomhara breise, agus roghnú sonraí in-fearainn.', 'el': 'Αυτή η εργασία περιγράφει την υποβολή του Kakao Enterprise στην κοινή εργασία μηχανικής μετάφρασης WMT21 χρησιμοποιώντας ορολογίες. Ενσωματώνουμε περιορισμούς ορολογίας με προεκπαίδευση με σχολιασμούς στοχευόμενων λεμμάτων και τελειοποίηση με σχολιασμούς ακριβούς στόχους χρησιμοποιώντας το δεδομένο σύνολο δεδομένων ορολογίας. Η προσέγγιση αυτή δίνει ένα μοντέλο που επιτυγχάνει εξαιρετικά αποτελέσματα τόσο όσον αφορά την ποιότητα της μετάφρασης όσο και τη συνοχή των όρων, με βάση το COMET στην κατεύθυνση της γλώσσας Εν Fr. Επιπλέον, διερευνούμε διάφορες μεθόδους όπως η μεταγραφή, η ρητή εκπαίδευση ορολογίας ως πρόσθετα παράλληλα δεδομένα και η επιλογή δεδομένων εντός του τομέα.', 'hu': 'Ez a tanulmány bemutatja a Kakao Enterprise által a WMT21 megosztott Gépi Fordítás terminológiák használatával kapcsolatos feladatnak való benyújtását. A terminológiai korlátozásokat előkészítő képzéssel integráljuk céllemma megjegyzésekkel és finomhangolással az adott terminológiai adatok felhasználásával. Ez a megközelítés olyan modellt eredményez, amely mind a fordítási minőség, mind a kifejezések következetessége tekintetében kiemelkedő eredményeket ér el, első helyen a COMET alapján az En Fr nyelvi irányban. Ezenkívül különböző módszereket vizsgálunk, mint például a visszafordítás, a terminológiák kifejezetten párhuzamos adatként történő képzése és a domain belüli adatok kiválasztása.', 'ka': 'Name ჩვენ ტერმინოლოგიის დასაწყვებით წინტერექტირებით წინტერექტირებით, რომლებიც მინიშვნელოვანი ლემის ანოტაციებით და წინტერექტირებით მინიშვნელოვანი ანოტაციებით, რომ ეს პროგრამა იქნება მოდელს, რომელიც განსხვავებული წარმოდგენების შესახებ განსხვავებული კოლეტურის და ტერმის კონსტენსტის შესახებ, რომელიც პირველი პროგრამა COMET-ზე ენ ფ დამატებით, ჩვენ განსხვავებთ განსხვავებული მეტოვები, როგორც დაბრუნება, განსხვავებული ტერმინოლოგიები, როგორც დამატებული პარალელური მონაცემები და მონაცემების მონიშ', 'lt': 'Šiame dokumente aprašomas Kakao Enterprise pateiktas WMT21 bendram mašinų vertimui naudojant terminologijų užduotį. Integruojame terminologinius apribojimus parengdami mokymą su tikslinėmis citrinų anotacijomis ir tiksliai koreguojame tikslinėmis tikslinėmis anotacijomis naudojant nurodytą terminologinių duomenų rinkinį. Šis metodas sukuria model į, kuriame pasiekti nepaprasti rezultatai vertimo kokybės ir termino nuoseklumo požiūriu, pirmiausia pagal COMET EN Fr kalbos kryptimi. Be to, tiriame įvairius metodus, pvz., grįžtamąjį vertimą, aiškiai rengiame terminologijas kaip papildomus lygiagrečius duomenis ir renkame duomenis srityse.', 'it': "Questo articolo descrive l'invio di Kakao Enterprise all'attività di traduzione automatica condivisa WMT21 utilizzando Terminologies. Integriamo i vincoli terminologici attraverso la pre-formazione con annotazioni lemma target e la messa a punto con annotazioni target esatte utilizzando il set di dati terminologici dato. Questo approccio produce un modello che raggiunge risultati eccezionali sia in termini di qualità della traduzione che di coerenza dei termini, posizionandosi al primo posto sulla base di COMET nella direzione linguistica En Fr. Inoltre, esploriamo vari metodi come la traduzione posteriore, la formazione esplicita di terminologie come dati paralleli aggiuntivi e la selezione dei dati in-domain.", 'kk': 'Бұл қағаз терминологиялық тапсырманы қолданып, Kakao Enterprise WMT21 ортақ машинаның аудармасына жіберілгенін анықтайды. Келтірілген терминология деректер жиынын қолданатын терминологиялық мәліметтермен алдын- оқыту үшін терминологиялық шектеулерді біріктіреміз. Бұл тәсілі енфр тілінің бірінші жолында COMET- ге негізделген үлгілер мен термин тәуелсіздігінің қасиетіне жеткізеді. Қосымша, біз қайта аудару, қосымша параллель деректер мен доменде деректерді таңдау үшін терминологияларды зерттеп, әртүрлі әдістерді іздейміз.', 'mk': 'Овој весник го опишува поднесувањето на Какао Ентерпрајз на WMT21 споделена машинска транслекција користејќи терминолошка задача. Ние ги интегрираме терминолошките ограничувања со предобука со анатации на мета лима и фино прилагодување со точни анатации на мета користејќи го дадениот терминолошки податок. Овој пристап дава модел кој постигнува неверојатни резултати во однос на квалитетот на преводот и константноста на терминот, рангирајќи се прво врз основа на COMET во насоката на јазикот En Fr. Покрај тоа, ги истражуваме различните методи како што се преведувањето назад, експлицитно обука на терминологиите како дополнителни паралелни податоци и селекција на податоци во доменот.', 'ms': 'Kertas ini menggambarkan penghantaran Kakao Enterprise kepada Perjemahan Mesin berkongsi WMT21 menggunakan tugas Terminologies. Kami mengintegrasikan keterangan terminologi dengan praselatihan dengan anotasi lemma sasaran dan penyesuaian dengan anotasi sasaran tepat menggunakan set data terminologi yang diberikan. pendekatan ini menghasilkan model yang mencapai keputusan yang luar biasa dalam term a kualiti terjemahan dan konsistensi terma, peringkat pertama berdasarkan COMET dalam arah bahasa En Fr. Selain itu, kami mengeksplorasi pelbagai kaedah seperti terjemahan balik, secara eksplicit latihan terminologi sebagai data selari tambahan, dan pemilihan data dalam domain.', 'ml': 'ഈ പത്രത്തില്\u200d കാക്കോ എന്\u200dടെര്\u200dപ്രൈസ്സിന്\u200dറെ സമര്\u200dപ്പിക്കുന്നത് ടെര്\u200dമിനോളജിയുടെ ജോലി ഉപയോഗിച്ച് വിഭാഗിച്ച മ ടെര്\u200dമിനോളജി ഡാറ്റാസറ്റാസെറ്റ് ഉപയോഗിക്കുന്ന ലക്ഷ്യം മുമ്പ് പരിശീലനത്തിന്റെ തടസ്സപ്പെടുത്തുന്നതിനാല്\u200d ഞങ്ങള്\u200d മുന്\u200dപ് പരിശ ഈ പ്രവര്\u200dത്തനത്തിന്റെ മാതൃകയ്ക്ക് ഒരു മോഡല്\u200d കൊണ്ടുവരുന്നു. അതിന്റെ പരിഭാഷക്കുറിച്ചും വാക്കിന്റെ സ്ഥിതിയുമായി ഉള്ള ഫലങ്ങള അതിനുശേഷം, പിന്നിലെ ടെര്\u200dമിനോളജികള്\u200d പോലെ', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni ta’ Kakao Enterprise lit-Traduzzjoni tal-Magni kondiviża tad-WMT21 bl-użu tal-kompitu Terminoloġiċi. Aħna nintegraw ir-restrizzjonijiet tat-terminoloġija permezz ta’ taħriġ minn qabel b’annotazzjonijiet tal-lemma fil-mira u l-aġġustament fin b’annotazzjonijiet fil-mira eżatti li jużaw is-sett ta’ dejta tat-terminoloġija mogħti. Dan l-approċċ jagħti mudell li jikseb riżultati pendenti kemm f’termini ta’ kwalità tat-traduzzjoni kif ukoll konsistenza fit-terminu, li l-ewwel jikklassifika abbażi tal-COMET fid-direzzjoni tal-lingwa En Fr. Barra minn hekk, nesploraw diversi metodi bħat-traduzzjoni lura, it-terminoloġiji ta’ taħriġ espliċitu bħala dejta parallela addizzjonali, u l-għażla tad-dejta fid-dominju.', 'mn': 'Энэ цаас Какао Энтерпрайзын WMT21 хуваалцаагүй машины хөгжлийг Terminologies ажил ашиглан тайлбарладаг. Бид терминологийн хязгаарлалтыг өмнө сургалтын тулд загвар өгөгдлийн санг ашиглах зорилготой лимма загвар өгөгдлийн санг ашиглаж байдаг. Энэ арга загвар нь энфр хэлний зэрэг COMET дээр анхны дараа нь хөгжүүлэх чадвартай болон томъёог харьцуулахад гайхалтай үр дүнг гаргадаг загвар юм. Мөн бид буцаад орчуулалт, нэмэлт параллель өгөгдлийг болон доторх өгөгдлийн сонголт гэх мэт олон арга замыг судалж байна.', 'ro': 'Această lucrare descrie transmiterea Kakao Enterprise la activitatea WMT21 de traducere automată partajată utilizând terminologii. Integrăm constrângerile terminologice prin pre-instruire cu adnotări lemma țintă și reglare fină cu adnotări țintă exacte utilizând setul de date terminologice dat. Această abordare oferă un model care obține rezultate remarcabile atât în ceea ce privește calitatea traducerii, cât și coerența termenilor, clasându-se pe primul loc pe baza COMET în direcția lingvistică En Fr. În plus, explorăm diferite metode, cum ar fi traducerea înapoi, formarea explicită a terminologiilor ca date paralele suplimentare și selectarea datelor în domeniu.', 'no': 'Denne papiret beskriver at Kakao Enterprise s øker til WMT21 delt maskinsomsetjing ved hjelp av Terminologies- oppgåve. Vi integrerer terminologiske begrensningar ved å foretrekke med mål lemmas- notasjonar og finnstilling med nøyaktige mål- notasjonar som brukar den oppgjevne terminologiske datasettet. Denne tilnærminga gjer eit modell som gjer utgåande resultat i uttrykk av både omsetjingskvaliteten og uttrykk konsistens, som rankerer første basert på COMET i en Fr-språkkretningen. I tillegg utforskar vi forskjellige metoder som tilbakeomsetjing, eksplisisk utlæring av terminologiar som tillegg parallelle data og utval av data i domenet.', 'si': 'Name අපි තර්මාන්\u200dය විධානය අවධානය සඳහා ඉලක්ක ලිමා අවධානය සඳහා ඉලක්කම් අවධානය සඳහා අවධානය අවධානය සඳහා අවධානය සඳ මේ විදියට ප්\u200dරමාණයක් ප්\u200dරමාණයක් ලැබෙනවා මොඩේල් එකක් එන්න පුළුවන් විදියට පත්තු විදියට පත්තු විදියට පත්තු විදියට ස තවත්, අපි වෙනස් විදිහට පරිවර්තන විදිහට පරීක්ෂණය කරන්න, ප්\u200dරශ්නයෙන් ප්\u200dරශ්නය විදිහට පරීක්ෂණය විදිහට පරිවර', 'so': "Warqaddan waxaa ku qoran warqada Kakao Enterprise uu u dhiibay wargelinta WMT21 oo lagu qoray tarjumaadda mashiinka ee lagu isticmaalayo shaqada Terminologies. Waxaannu u qabsanaynaa qasabka terminology-ka-horaadka lagu baranayo alaabta lemmada iyo si fiican loola isticmaalayo macluumaadka terminology ee la siiyey. Dhaqdhaqaaqin wuxuu soo saaraa model aad u samaysan midhaha tarjumaadda iyo xilliga isku mid ah, kaas oo marka ugu horeysa ku saleysan COMET xagga hagitaanka afka En Fr. Waxaa kale oo aan baaraynaa qaabab kala duduwan sida turjumista dib-u-dhigista, tusaale ahaan baaritaanka terminologiga si cad sida macluumaad faa'iido ah iyo doorashada macluumaadka internetka.", 'pl': 'Niniejszy artykuł opisuje zgłoszenie Kakao Enterprise do wspólnego tłumaczenia maszynowego WMT21 przy użyciu zadania Terminologii. Integrujemy ograniczenia terminologiczne poprzez szkolenie wstępne z adnotacjami docelowymi lemma oraz dostosowanie do dokładnych adnotacji docelowych z wykorzystaniem danego zbioru danych terminologicznych. Takie podejście daje model, który osiąga wyjątkowe wyniki zarówno pod względem jakości tłumaczenia, jak i spójności terminów, rankując się na pierwszym miejscu w oparciu o COMET w kierunku języka En Fr. Ponadto badamy różne metody, takie jak tłumaczenie wsteczne, wyraźne szkolenie terminologii jako dodatkowe dane równoległe oraz selekcja danych w domenie.', 'ta': "This paper describes Kakao Enterprise's submission to the WMT21 shared machine Translation using Terminology task. நாம் முன் பயிற்சி முறை அமைப்பு மற்றும் கொடுக்கப்பட்ட முனையமான தகவல் அமைப்பை பயன்படுத்தி சரியான இலக்கு அறிவிப்புகளை சேர்க்கிறோம். இந்த செயல்பாடு ஒரு மாதிரி வழங்குகிறது, அது மொழிபெயர்ப்பு தரம் மற்றும் சொற்றொடர் ஒத்திசையில் மேம்படுத்தும் முடிவுகளை பெறுக மேலும், நாம் பின் மொழிபெயர்ப்பு, வெளிப்படையாக பயிற்சி முறைமைகளை கூடுதல் இணைப்பு தரவுகள் மற்றும் domain data தேர்வுகள் போன்ற பல முற", 'sr': 'Ovaj papir opisuje podnošenje Kakao Enterprise na WMT21 zajedničku prevodu mašine koristeći zadatak termininologije. Integrujemo terminologijske ograničenje pre obuke sa ciljnim limunom annotacijom i ispravnim prilagodbama sa tačnim ciljnim annotacijom korištenjem određenih terminoloških podataka. Ovaj pristup pruža model koji postigne neizbježne rezultate u smislu kvalitete prevođenja i pojma konsekvencije, prvo postavljajući na COMET-u u direkciji jezika En Fr. Osim toga, istražujemo različite metode poput prevoda natrag, eksplicitno obuku terminologija kao dodatne paralelne podatke i izbora podataka u domenu.', 'ur': 'یہ کاغذ ٹریمینولوجیس کام کے مطابق کاکا انٹرپرائز کے مطابق WMT21 مشترک ماشین ترجمہ کے مطابق بیان کرتا ہے. ہم ترمینلوژی محدودیت کو پیش ترکین کے ذریعے موقع لیمہ انٹوریشن اور ٹھیک موقع انٹوریشن کے ذریعے تدبیر کر رہے ہیں جن کے ذریعے مطابق موقع کی انٹوریشن ڈیٹ سٹ استعمال کرتے ہیں اس طریقہ سے ایک موڈل پیدا کرتا ہے جو انفرا زبان کی طرف سے پہلے COMET پر بنیاد رکھتا ہے۔ اور اس کے بعد ہم مختلف طریقوں کی تحقیق کرتے ہیں جیسے پچھلی ترجمہ، صریح ترمینلوژوں کی ترمینلوژوں کی طرح اضافہ parallel data اور دامین ڈیٹ انتخاب میں۔', 'sv': 'Denna uppsats beskriver Kakao Enterprise inlämning till WMT21 delade maskinöversättning med hjälp av terminologier. Vi integrerar terminologibegränsningar genom fortbildning med mållemmaanteckningar och finjustering med exakta målanteckningar med hjälp av den givna terminologidatauppsättningen. Detta tillvägagångssätt ger en modell som uppnår enastående resultat när det gäller både översättningskvalitet och termkonsistens, och rankas först baserat på COMET i språkriktningen En Fr. Dessutom undersöker vi olika metoder som backöversättning, explicit utbildning av terminologier som ytterligare parallella data och val av data inom domänen.', 'uz': 'Name Biz Terminologiya tarmoqlarini birinchi taʼminlovdan oldin lemma taʼminotlari bilan birlashtiramiz va taʼminlovchi terminolog maʼlumotlardan foydalanishni tasdiqlash mumkin. @ info Furthermore, we explore various methods such as back-translation, explicitly training terminologies as additional parallel data, and in-domain data selection.', 'vi': 'Tờ giấy này mô tả việc Kakao Enterprise s ẽ chịu trách nhiệm chuyển đổi cỗ máy chia sẻ WM, sử dụng chiến dịch Terminologies. Chúng tôi nhập các giới hạn thuật ngữ nhờ tiền khóa huấn luyện với chú thích dung chú thích khuôn tiêu biểu và chỉnh sửa chính xác các bản ghi chú tiêu biểu sử dụng các tập tin tiêu biểu cụ thể. Cách này đạt được một kết quả đáng chú ý về chất lượng dịch và độ sánh thời gian, xếp hạng đầu tiên dựa trên tơ tằm, theo hướng ngôn ngữ. Hơn nữa, chúng tôi tìm hiểu các phương pháp khác nhau như dịch lại, thuật ngữ được đào tạo rõ ràng như các dữ liệu song song, và chọn dữ liệu nội bộ.', 'nl': 'Dit artikel beschrijft de inzending van Kakao Enterprise aan de WMT21 gedeelde Machine Translation met behulp van Terminologies taak. We integreren terminologiebeperkingen door vooraf te trainen met target lemma annotaties en fine-tuning met exacte target annotaties met behulp van de gegeven terminologie dataset. Deze aanpak levert een model op dat uitstekende resultaten behaalt op het gebied van vertaalkwaliteit en termconsistentie, waarbij de eerste rang is gebaseerd op COMET in de taalrichting En Fr. Daarnaast onderzoeken we verschillende methodes zoals back-translation, expliciete training van terminologieën als aanvullende parallelle data en in-domain data selectie.', 'bg': 'Тази статия описва представянето на Какао Ентърпрайз към споделената задача WMT21 Машинен превод чрез терминологии. Ние интегрираме терминологични ограничения чрез предварителна подготовка с целеви лемни анотации и фина настройка с точни целеви анотации, използвайки дадения терминологичен набор от данни. Този подход дава модел, който постига изключителни резултати както по отношение на качеството на превода, така и последователността на термините, като се класира на първо място въз основа на комет в езиковата посока. Освен това изследваме различни методи като обратен превод, изрично обучение на терминологии като допълнителни паралелни данни и избор на данни в областта.', 'de': 'Dieses Papier beschreibt die Einreichung von Kakao Enterprise an die gemeinsame WMT21 Machine Translation using Terminologies Aufgabe. Wir integrieren Terminologiebeschränkungen durch Vortraining mit Ziellemma-Annotationen und Feinabstimmung mit exakten Zielannotationen unter Verwendung des gegebenen Terminologiedatensatzes. Dieser Ansatz liefert ein Modell, das hervorragende Ergebnisse sowohl in Bezug auf Übersetzungsqualität als auch Terminkonsistenz erzielt, wobei COMET in der Sprachrichtung En Fr an erster Stelle steht. Darüber hinaus erforschen wir verschiedene Methoden wie Backtranslation, explizite Schulung von Terminologien als zusätzliche parallele Daten und In-Domain-Datenauswahl.', 'da': "Dette dokument beskriver Kakao Enterprise's indsendelse til WMT21 delte maskinoversættelse ved hjælp af terminologier. Vi integrerer terminologibegrænsninger ved forudtræning med mållemma annotationer og finjustering med nøjagtige mål annotationer ved hjælp af det givne terminologidatasæt. Denne tilgang giver en model, der opnår fremragende resultater med hensyn til både oversættelseskvalitet og termkonsistens, og rangerer først ud fra COMET i en Fr sprogretning. Desuden undersøger vi forskellige metoder såsom back-translation, eksplicit træning af terminologier som supplerende parallelle data og in-domain data valg.", 'hr': 'Ovaj papir opisuje podnošenje Kakao Enterprise podijeljenom WMT21 zajedničkom prevodu strojeva koristeći zadatak termininologije. Integriramo terminologijske ograničenje prije obuke s ciljnim oznakem lime i ispravnim prilagođavanjem s točnim ciljnim oznakem koji koriste određenu kompetu podataka terminologije. Ovaj pristup pruža model koji postigne neizbježne rezultate u smislu kvalitete prevođenja i određenosti termina, koji prvo postavlja na temelju COMET-a u smjeru jezika En Fr. Osim toga, istražujemo različite metode poput prevoda natrag, pojasno obuku terminologija kao dodatne paralelne podatke i izbora podataka u domenu.', 'sw': 'Gazeti hili linaelezea ujumbe wa Kakao Enterprise uliofanywa na WMT21 uliotumiwa na Tafsiri ya Mashine kwa kutumia kazi ya Terminology. Tunaunganisha vikwazo vya utamaduni kwa mafunzo ya kabla kwa lengo la kutangaza mabomu ya vimbunga na mabomu mazuri kwa kutumia seti ya takwimu za ngono zilizopewa. This approach yields a model that achieves outstanding results in terms of both translation quality and term consistency, ranking first based on COMET in the En Fr language direction.  Zaidi ya hayo, tunatafuta mbinu mbalimbali kama vile tafsiri za nyuma, mafunzo ya tatizo wazi kama vile data za ziada za usambazaji, na uchaguzi wa data za ndani.', 'ko': '본고는 카카오Enterprise가 WMT21 공유기기 번역 임무에 제출한 용어를 설명한다.우리는 목표 인용 주석을 사용하여 예비 훈련을 하고 주어진 용어 데이터 집합을 이용하여 정확한 목표 주석을 사용하여 미세하게 조정하여 용어의 제약을 통합시킨다.이런 방법으로 만들어진 모델은 번역의 질과 용어의 일치성에 있어 우수한 결과를 얻었고 영국-프랑스 언어 방향에서 COMET를 바탕으로 1위를 차지했다.그 밖에 우리는 반역, 명확한 용어 훈련을 추가 병행 데이터와 역내 데이터 선택으로 하는 등 여러 가지 방법을 연구했다.', 'tr': "Bu kagyz Kakao Enterprise'iň WMT21-iň beýleki maşynyň terjimesini Terminologies täbligini ulanan ylalaşygyny tassyýar. Biz terminologiýanyň ön öňünden eğitim bilen maksady lemma duýdurmalary bilen birleşdirdik we berilen terminologiýa datasetini ulanan noktalar bilen düzgün düzümlerni birleşdirdik. Bu ýagdaý çykyş En Fr dilinde COMET'a daýanýan ilkinji gezek çykyş şeklinde täsirli netijede bolan bir nusga getirir. Daha da, arka terjime edilen yöntemleri, terminologilere aşırı paralel veri ve domenin veri saýlaması gibi gözlenmek üçin farklı yöntemleri keşfetýäris.", 'id': 'Kertas ini menjelaskan pengiriman Kakao Enterprise ke WMT21 shared Machine Translation menggunakan tugas Terminologies. Kami mengintegrasikan batasan terminologi dengan praselatihan dengan anotasi lemma sasaran dan penyesuaian dengan anotasi sasaran tepat menggunakan set data terminologi yang diberikan. pendekatan ini memberikan model yang mencapai hasil yang luar biasa dalam term a kualitas terjemahan dan konsistensi istilah, ranking pertama berdasarkan COMET dalam arah bahasa En Fr. Selain itu, kami mengeksplorasi berbagai metode seperti terjemahan belakang, secara eksplisit melatih terminologi sebagai data paralel tambahan, dan seleksi data dalam domain.', 'sq': 'Ky artikull përshkruan paraqitjen e Kakao Enterprise në WMT21 të përbashkët Translation Machine duke përdorur detyrën e Terminologies. Ne integrojmë kufizimet e terminologjisë duke përdorur paratrajnimin me anotacionet e shënjestrave të limës dhe rregullimin me anotacionet e sakta të shënjestrave duke përdorur të dhënat e dhëna të terminologjisë. Ky qasje jep një model që arrin rezultate të jashtëzakonshme si në lidhje me cilësinë e përkthimit ashtu dhe konsistencën e afatit, renditjen e parë bazuar në COMET në drejtimin e gjuhës En Fr. Përveç kësaj, ne eksplorojmë metoda të ndryshme si përkthimi prapa, trajnimi eksplicit i terminologjive si të dhëna paralele shtesë dhe zgjedhja e të dhënave në domeni.', 'am': 'ይህ ፕሮግራም የካካኮ Enterprise ለWMT21 የተለየ የመኪን ትርጓሜ በተርሚናሎጂ ስራ በተጠቃሚ ትርጓሜ ይናገራል፡፡ We integrate terminology constraints by pre-training with target lemma annotations and fine-tuning with exact target annotations utilizing the given terminology dataset.  ይህም ሥርዓት በዓይን Fr ቋንቋ ክፍል ላይ በመጀመሪያ የCOMET ክፍል በመጠቀም የሚደረገውን ትርጓሜ ጥሩ እና የንግግር ክፍተት የሚደርስበትን ምሳሌ ያሳድጋል፡፡ ከዚህም በላይ፣ እንደኋላ-ትርጉም፣ በተጨማሪው ተርሚኖችን እና ዳታ እና የdomain ዳታ ምርጫዎችን እናፈልጋለን፡፡', 'az': "Bu kańüńĪt, Terminologies iŇüini kullanarak Kakao Enterprise'in WMT21 paylaŇüńĪlan maŇüńĪn √ßevirisini t…ôsdiql…ôyir. Biz terminoloji m√ľ…ôyy…ônl…ôŇüdirm…ôl…ôri, m…ôqs…ôd limma notasyonlarńĪ v…ô m√ľ…ôyy…ônl…ôŇüdirm…ôl…ôri il…ô birl…ôŇüdiririk. Bu t…ôrzim, En Fr dil y√∂n√ľnd…ô COMET-…ô dayanan ilk d…ôr…ôc…ô-d…ôr…ôc…ô √ß…ôkilm…ô keyfiyy…ôti v…ô term in konsistensiyy…ôti il…ô m√ľ…ôyy…ôn edil…ôn modell…ôri verir. Daha sonra, geri-terc√ľm…ô kimi f…ôrqli metodlarńĪ keŇüif edirik, …ôlav…ô paralel m…ôlumatlar kimi terminoloqlarńĪ v…ô domena m…ôlumatlarńĪnńĪn se√ßimi kimi a√ßńĪq-aydńĪn t…ôhsil edirik.", 'fa': 'این کاغذ تحویل کاکاو انترپرایز به ترجمه ماشین مشترک WMT21 با استفاده از کار Terminologies توصیف می\u200cکند. ما محدودیت ترمینالوژی را با تحصیل پیش آموزش با نشانه\u200cهای لیما هدف و تنظیمات کامل با نشانه\u200cهای کامل هدف استفاده از مجموعه داده\u200cهای ترمینالوژی داده می\u200cکنیم. این روش یک مدل می\u200cدهد که نتیجه\u200cهای غیرقابل توجه به عنوان کیفیت ترجمه و ترجمه\u200cای که اول بر اساس COMET در مسیر زبان En Fr می\u200cرسد. علاوه بر این، ما روش\u200cهای مختلف مثل ترجمه پشتی را تحقیق می\u200cکنیم، ترمینالوژی\u200cها را به طور واضح تمرین می\u200cکنیم مثل داده\u200cهای متفاوتی اضافه\u200cای و انتخاب داده\u200cهای دامنه\u200cی دامنه\u200cای.', 'bn': 'এই পত্রিকা কাকাও এন্টারপ্রাইজের উইএমটি২১ টার্মিনোলজিজ কাজ ব্যবহার করে প্রকাশিত মেশিন অনুবাদের প্রতি প্রদান করা হয় টার্মিনোলজি ডাটাসেট ব্যবহার করে আমরা পূর্ব প্রশিক্ষণ প্রশিক্ষণের মাধ্যমে টার্মিনোলজি নিষেধাজ্ঞার সাথে একত্রিত করি এবং সঠিক লক্ষ্যের এই প্রযুক্তিটি একটি মডেল প্রদান করে যা অনুবাদের মান এবং মেয়াদের সংশ্লিষ্ট মান এবং উভয়ের মাধ্যমে চমৎকার ফলাফল অর্জন করে, যা প্রথমে কোমে এছাড়াও, আমরা বিভিন্ন পদ্ধতি খুঁজে বের করি যেমন পিছন-অনুবাদ, স্পষ্ট প্রশিক্ষণ টার্মিনোলজি, যেমন আরো প্যারালেল ডাটা এবং ডোমেইন ডা', 'bs': 'Ovaj papir opisuje podnošenje Kakao Enterprise na WMT21 zajedničku prevodu mašine koristeći zadatak termininologije. Integrujemo ograničenja terminologije pre obuke sa ciljnim oznakem lime i ispravnim prilagođavanjem s točnim ciljnim oznakem koji koriste određenu kompletu podataka terminologije. Ovaj pristup pruža model koji postigne neizbježne rezultate u smislu kvalitete prevođenja i određenosti termina, koji prvo postavlja na COMET-u u direkciji jezika En Fr. Osim toga, istražujemo različite metode poput prevoda natrag, pojasno obuku terminologija kao dodatni paralelni podaci i izbora podataka u domenu.', 'af': "Hierdie papier beskrywe Kakao Enterprise se onderskrywing na die WMT21 gedeelde Masjien Vertaling met gebruik van Terminologies taak. Name Ons integreer terminologies beperkinge deur voor-onderwerp met doel lemma-annotasies en fyn-tuning met egte doel-annotasies wat die gegewe terminologie-datastel gebruik word. Hierdie toepassing gee 'n model wat uitgewonde resultate bereik in terms van vertaling kwaliteit en term konsistensie, ranking eerste gebaseer op COMET in die En Fr taal rigting. Ons verder ondersoek verskeie metodes soos terugvertaling, eksplisiese onderwerp terminologies as addisionele parallele data en in-domein data keuse.", 'cs': 'Tento článek popisuje podání společnosti Kakao Enterprise ke sdílenému strojovému překladu WMT21 pomocí úlohy Terminologie. Integrujeme terminologická omezení předškolením s cílovými lemmovými anotacemi a jemným laděním s přesnými cílovými anotacemi s využitím daného terminologického datového souboru. Tento přístup přináší model, který dosahuje vynikajících výsledků jak z hlediska kvality překladu, tak z hlediska konzistence termínů, který je na prvním místě založeném na COMET ve směru jazyka En Fr. Dále zkoumáme různé metody, jako je zpětný překlad, explicitní školení terminologie jako další paralelní data a výběr dat v doméně.', 'et': 'Käesolevas artiklis kirjeldatakse Kakao Enterprise esitamist WMT21 jagatud masintõlke ülesandele Terminoloogiad kasutades. Integreerime terminoloogilised piirangud eelkoolitusega sihtlemma-annotatsioonidega ja täpsete sihtannotatsioonidega täpse häälestamisega, kasutades antud terminoloogia andmekogumit. Selline lähenemisviis annab mudeli, mis saavutab silmapaistvaid tulemusi nii tõlkekvaliteedi kui ka terminite järjepidevuse osas, olles esimene COMET-i põhjal En Fr keele suunas. Lisaks uurime erinevaid meetodeid, nagu tagantõlkimine, terminoloogiate selgesõnaline koolitamine täiendavate paralleelsete andmetena ja valdkonnasisene andmete valik.', 'fi': 'Tässä artikkelissa kuvataan Kakao Enterprisen lähettämistä jaettuun WMT21 Machine Translation using Terminologies -tehtävään. Integroimme terminologiarajoitukset esikoulutuksella kohdelemma-annotoinnilla ja hienosäätimellä tarkkoja kohdeannotointeja käyttämällä annettua terminologiaaineistoa. Tämä lähestymistapa tuottaa mallin, joka saavuttaa erinomaisia tuloksia sekä käännöslaadun että termien johdonmukaisuuden suhteen, sijoittuen ensin COMET:n perusteella en Fr:n kielisuunnassa. Lisäksi tutkimme erilaisia menetelmiä, kuten takaisinkääntämistä, terminologian nimenomaista koulutusta rinnakkaisaineistona ja oman verkkotunnuksen tietojen valintaa.', 'ca': "Aquest article descriu la presentació de Kakao Enterprise a la traducció de màquines compartida WMT21 utilitzant la tasca de Terminologies. Integrem les restriccions de terminologia fent pré-entrenament amb anotacions de limó d'objectiu i ajustament amb anotacions d'objectiu exactes fent servir el conjunt de dades de terminologia dada. Aquest enfocament produeix un model que aconsegueix resultats excepcionals tant en termes de qualitat de traducció com de consistencia del terme, classificant-se primer basat en COMET en direcció de llenguatge en Fr. A més, explorem diversos mètodes com la retrotraducció, la formació explícita de terminologies com a dades paralleles adicionals i la selecció de dades en domini.", 'hy': 'Այս հոդվածը նկարագրում է Կակոյի Ենտերպրեյզի ներկայացումը ԱՄԹ21-ի ընդհանուր մեքենայի թարգմանություն՝ օգտագործելով տերմինոլոգիաների խնդիրը: Մենք ինտեգրում ենք տերմինոլոգիայի սահմանափակումները նախապատրաստման միջոցով նպատակային լիմմայի նոտացիաների հետ և կազմակերպում ենք նպատակային նոտացիաների հետ, օգտագործելով տվյալ տերմինոլոգիայի տվյալները: Այս մոտեցումը ստեղծում է մի մոդել, որը հասնում է բացառիկ արդյունքներ՝ ինչպես թարգմանման որակի, ինչպես նաև տերմինային համապատասխանատվության առումով, առաջինը դասակարգում է համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային Ավելին, մենք ուսումնասիրում ենք տարբեր մեթոդներ, ինչպիսիք են վերադարձ թարգմանությունը, բացահայտորեն վարժեցնում տերմինոլոգիաները որպես ավելացված զուգահեռ տվյալներ, և բնագավառի տվյալների ընտր', 'he': 'העיתון הזה מתאר את ההעברה של אימפרזיז Kakao לתרגום מכונות משותף WMT21 באמצעות משימה טרמינולוגיות. אנחנו משתלבים מחסומות בטרנולוגיה על ידי אימון מראש עם ציונים לימה מטרה ומתאים עם ציונים מטרה מדויקים הגישה הזאת נותנת מודל שמגיע תוצאות נפלאות במונחים של איכות התרגום ומקבילות המונח, המייצב ראשון מבוסס על COMET בכיוון השפה En Fr. חוץ מזה, אנחנו חוקרים שיטות שונות כמו התרגום האחורי, טמינולוגיות אימונים באופן ברור כנתונים מקבילים נוספים, ובחירת נתונים בתחום.', 'ha': "@ info Tuna haɗa taƙaitori na tamkar ta kafin da za'a yi amfani da shiryoyin limma na gabatar da kuma masu gyarata da alama masu yiwuwa da ke amfani da tsarin taƙaitori da aka ba da. Wannan hanyor ya bãyar da wata motel wanda ya sami fassara mai kyau cikin muhimman fassarar da muhimmanci, da randin ta farkon a kan COMET a cikin shirin A-F. Furan haka, munã ƙidãya wasu hanyõyi kamar misãlan-translation-back, na ƙidãya taƙaitori masu bayyani kamar addin data da za'a daidaita da kuma zaɓen data cikin-Domen.", 'sk': 'Ta prispevek opisuje predložitev podjetja Kakao Enterprise opravilu strojnega prevajanja v skupni rabi WMT21 z uporabo terminologij. Terminološke omejitve integriramo s predusposabljanjem z oznakami ciljne lemme in natančnim nastavitvijo z natančnimi ciljnimi oznakami z uporabo danega terminološkega nabora podatkov. Ta pristop prinaša model, ki dosega izjemne rezultate v smislu kakovosti prevodov in doslednosti izrazov, pri čemer se uvršča na prvo mesto glede na COMET v jezikovni smeri En Fr. Poleg tega raziskujemo različne metode, kot so nazaj prevajanje, izrecno usposabljanje terminologij kot dodatni vzporedni podatki in izbira podatkov na področju.', 'bo': 'ཤོག་བྱང་འདིས་ཀྱིས་Kakao Enterprise་གི་WMT21 རྣམས་ཉར་མཁན་གྱི་མིང་ཚོར་སྤྱོད་བཞིན་པའི་བརྡ་སྤྲོད་ཀྱི་ཡོད། We integrate terminology constraints by pre-training with target lemma annotations and fine-tuning with exact target annotations utilizing the given terminology dataset. This approach yields a model that achieves outstanding results in terms of translation quality and term consistency, ranking first based on COMET in the En Fr language direction. Furthermore, we explore various methods such as back-translation, explicitly training terminologies as additional parallel data, and in-domain data selection.', 'jv': 'Gambar iki rambaran bakal nekakak Kaas Enter Prijzer kanggo nyelaran Mas Terjamahan WWT We embed terminal limits by before-Learning with goal lemma anntations and fini- tuning with exact goal anntations used the given terminal dataset. If you do not have a option, you can use it here. Name In the last minute, we find new information about the selected template.'}
{'en': 'The SPECTRANS System Description for the WMT21 Terminology Task', 'ar': 'وصف نظام SPECTRANS لمهمة المصطلحات WMT21', 'pt': 'A descrição do sistema SPECTRANS para a tarefa de terminologia WMT21', 'fr': 'Description du système SPECTRANS pour la tâche de terminologie WMT21', 'es': 'Descripción del sistema SPECTRANS para la tarea terminológica WMT21', 'ja': 'WMT 21用語タスクのSPECTRANSシステム説明', 'zh': 'WMT21 术语事者 SPECTRANS 统也', 'ru': 'Описание системы SPECTRANS для терминологической задачи WMT21', 'hi': 'WMT21 शब्दावली कार्य के लिए SPECTRANS सिस्टम विवरण', 'ga': 'Cur síos ar an gCóras SPECTRANS don Tasc Téarmaíochta WMT21', 'el': 'Η περιγραφή του συστήματος για την εργασία ορολογίας WMT21', 'hu': 'A SPECTRANS rendszer leírása a WMT21 terminológiai feladathoz', 'ka': 'WMT21 ტერმინოლოგიის დავალებისთვის SPECTRANS სისტემის გამოსახულება', 'it': 'Descrizione del sistema SPECTRANS per il compito di terminologia WMT21', 'lt': 'SPECTRANS sistemos aprašymas WMT21 terminologijos užduotims', 'ms': 'Huraian Sistem SPECTRANS untuk Tugas Terminologi WMT21', 'mk': 'The SPECTRANS System Description for the WMT21 Terminology Task', 'mn': 'WMT21 Terminology Task-ийн SPECTRANS системийн тодорхойлолт', 'ml': 'WMT21 ടെര്\u200dമിനോളജി ജോലിക്കുള്ള എസ്പെക്ട്രാന്\u200dസ് സിസ്റ്റം വിശദീകരണം', 'mt': 'Deskrizzjoni tas-Sistema SPECTRANS għall-Kompitu tat-Terminoloġija WMT21', 'kk': 'WMT21 терминология тапсырмасының SPECTRANS жүйесінің сипаттамасы', 'no': 'SPECTRANS- systemskildring for WMT21- terminologiske oppgåve', 'sr': 'SPECTRANS sistemski opis za WMT21 terminološki zadatak', 'pl': 'Opis systemu SPECTRANS dla zadania terminologicznego WMT21', 'si': 'WMT21 වර්මිනෝලෝජික වැඩ සඳහා SPECTRANS පද්ධති විස්තර', 'sv': 'SPECTRANS-systembeskrivningen för WMT21 Terminologi-uppgiften', 'ro': 'Descrierea sistemului SPECTRANS pentru sarcina de terminologie WMT21', 'ta': 'WMT21 முனையம் பணிக்கான SPECTRANS அமைப்பு விவரம்', 'ur': 'WMT21 Terminology Task کے لئے SPECTRANS سیسٹم کا سپریشن', 'so': 'Tilmaamaha nidaamka SPECTRANS ee Shaqada Terminology ee WMT21', 'uz': 'WMT21 Terminalology vazifa uchun SPECTRANS tizim taʼrifi', 'vi': 'Mô tả hệ thống SPECTANS cho công việc kết nối của WM 1', 'da': 'SPECTRANS-systembeskrivelsen for WMT21 Terminologi-opgaven', 'hr': 'Opis sustava SPECTRANS za WMT21 terminološki zadatak', 'bg': 'Описание на системата SPECTRANS за терминологичната задача WMT21', 'nl': 'De SPECTRANS systeembeschrijving voor de WMT21 terminologie taak', 'id': 'Deskripsi Sistem SPECTRANS untuk Tugas Terminologi WMT21', 'sw': 'Maelezo ya Mfumo wa SPECTRANS kwa ajili ya kazi ya Terminalology WMT21', 'de': 'Die SPECTRANS Systembeschreibung für die WMT21 Terminologie Aufgabe', 'af': 'Die SPECTRANS Stelsel Beskrywing vir die WMT21 Terminologie Opdrag', 'ko': 'WMT21 용어 작업에 대한 SPECTRANS 시스템 설명', 'fa': 'Description of the SPECTRANS System for the WMT21 Terminology Task', 'tr': 'WMT21 Terminologiýa Gözmesi üçin SPECTRANS Sistem Wasp', 'az': 'WMT21 Terminoloji G칬z톛li 칲칞칲n SPECTRANS Sistem T톛rc칲m칲', 'hy': 'Comment', 'am': 'የSPECTRANS System መግለጫ for the WMT21 Terminology Task', 'sq': 'Përshkrimi i Sistemit SPECTRANS për Detyrën Terminologjike WMT21', 'ca': 'La descripció del sistema SPECTRANS per la tasca de terminologia WMT21', 'et': 'WMT21 terminoloogia ülesande SPECTRANS süsteemi kirjeldus', 'cs': 'Popis systému SPECTRANS pro úlohu terminologie WMT21', 'fi': 'SPECTRANS System Description for the WMT21 Terminology Task', 'bs': 'SPECTRANS sistemski opis za WMT21 terminološki zadatak', 'bn': 'WMT21 টার্মিনোলজি কাজের জন্য SPECTRANS সিস্টেম বিবরণ', 'sk': 'Opis sistema SPECTRANS za terminološko opravilo WMT21', 'jv': 'tab', 'ha': 'Description', 'he': 'The SPECTRANS System Description for the WMT21 Terminology Task', 'bo': 'WMT21 མཐའ་སྡོར་གྱི་དོན་ལྟའི་འགྲེལ་བཤད་ཀྱི་SPECTRANS མ་ལག་གི་འགྲེལ་བཤད་'}
{'en': 'This paper discusses the WMT 2021 terminology shared task from a meta perspective. We present the results of our experiments using the terminology dataset and the OpenNMT (Klein et al., 2017) and JoeyNMT (Kreutzer et al., 2019) toolkits for the language direction English to French. Our experiment 1 compares the predictions of the two ', 'ar': 'تناقش هذه الورقة مهمة المصطلحات المشتركة WMT 2021 من منظور "ميتا". نقدم نتائج تجاربنا باستخدام مجموعة بيانات المصطلحات ومجموعات أدوات OpenNMT (Klein et al. ، 2017) و JoeyNMT (Kreutzer et al. ، 2019) لاتجاه اللغة الإنجليزية إلى الفرنسية. تجربتنا 1 تقارن تنبؤات مجموعتي الأدوات. تستخدم التجربة 2 OpenNMT لضبط النموذج. نقوم بالإبلاغ عن النتائج التي توصلنا إليها للمهمة مع نص التقييم ولكننا نناقش في الغالب الخصائص اللغوية لمجموعة بيانات المصطلحات المقدمة للمهمة. نحن نقدم دليلًا على أهمية أنواع النص عبر الدرجات ، بعد أن كررنا نصوص التقييم.', 'fr': "Cet article traite de la terminologie de la tâche partagée WMT 2021 d'un point de vue «\xa0méta\xa0». Nous présentons les résultats de nos expériences en utilisant l'ensemble de données terminologiques et les boîtes à outils OpenNMT (Klein et al., 2017) et JoeyNMT (Kreutzer et al., 2019) pour l'orientation linguistique de l'anglais vers le français. Notre expérience 1 compare les prédictions des deux boîtes à outils. L'expérience 2 utilise OpenNMT pour affiner le modèle. Nous communiquons nos résultats pour la tâche à l'aide du script d'évaluation, mais nous discutons principalement des propriétés linguistiques du jeu de données terminologiques fourni pour la tâche. Nous apportons des preuves de l'importance des genres de textes dans toutes les partitions, après avoir répliqué les scripts d'évaluation.", 'pt': 'Este artigo discute a tarefa compartilhada de terminologia do WMT 2021 a partir de uma perspectiva “meta”. Apresentamos os resultados de nossos experimentos usando o conjunto de dados de terminologia e os kits de ferramentas OpenNMT (Klein et al., 2017) e JoeyNMT (Kreutzer et al., 2019) para a direção do idioma inglês para francês. Nosso experimento 1 compara as previsões dos dois kits de ferramentas. O Experimento 2 usa OpenNMT para ajustar o modelo. Relatamos nossos resultados para a tarefa com o roteiro de avaliação, mas discutimos principalmente as propriedades linguísticas do conjunto de dados de terminologia fornecido para a tarefa. Evidenciamos a importância dos gêneros textuais nas pontuações, tendo replicado os roteiros de avaliação.', 'es': 'Este documento analiza la tarea compartida de la terminología del WMT 2021 desde una perspectiva «meta». Presentamos los resultados de nuestros experimentos utilizando el conjunto de datos terminológicos y los kits de herramientas OpenNMT (Klein et al., 2017) y JoeyNMT (Kreutzer et al., 2019) para la dirección del idioma inglés al francés. Nuestro experimento 1 compara las predicciones de los dos juegos de herramientas. El Experimento 2 usa OpenNMT para ajustar el modelo. Reportamos los resultados de la tarea con el guion de evaluación, pero sobre todo discutimos las propiedades lingüísticas del conjunto de datos terminológicos proporcionado para la tarea. Proporcionamos evidencia de la importancia de los géneros de texto en las partituras, después de haber replicado los guiones de evaluación.', 'hi': 'यह पेपर WMT 2021 शब्दावली साझा कार्य को "मेटा" परिप्रेक्ष्य से चर्चा करता है। हम शब्दावली डेटासेट और OpenNMT (Klein et al., 2017) और JoeyNMT (Kreutzer et al., 2019) टूलकिट का उपयोग करके अपने प्रयोगों के परिणामों को अंग्रेजी से फ्रेंच भाषा की दिशा के लिए प्रस्तुत करते हैं। हमारा प्रयोग 1 दो टूलकिट की भविष्यवाणियों की तुलना करता है। प्रयोग 2 मॉडल को ठीक करने के लिए OpenNMT का उपयोग करता है। हम मूल्यांकन स्क्रिप्ट के साथ कार्य के लिए अपने परिणामों की रिपोर्ट करते हैं लेकिन ज्यादातर कार्य के लिए प्रदान किए गए शब्दावली डेटासेट के भाषाई गुणों पर चर्चा करते हैं। हम स्कोर भर में पाठ शैलियों के महत्व के सबूत प्रदान करते हैं, मूल्यांकन स्क्रिप्ट को दोहराया है।', 'ja': 'この論文では、「メタ」の観点からWMT 2021用語共有タスクについて説明します。私たちは、英語からフランス語への言語方向のための用語データセット、およびOpenNMT （ Klein et al., 2017 ）およびJoeyNMT （ Kreutzer et al., 2019 ）ツールキットを使用した実験の結果を提示します。私たちの実験1は、2つのツールキットの予測を比較します。実験2はOpenNMTを使用してモデルを微調整します。評価スクリプトを使用してタスクの結果を報告しますが、主にタスクに提供される用語データセットの言語的特性について説明します。私たちは、評価スクリプトを複製して、スコア全体にわたるテキストジャンルの重要性の証拠を提供します。', 'zh': '本文以"元"角论WMT 2021术语共之。 吾用术语数集及OpenNMT(Klein等,2017)与JoeyNMT(Kreutzer等,2019)工具包以展吾实验,施于言语英语法语。 吾实验 1 较二工具包之占。 实验 2 用 OpenNMT 对模型微调。 吾以估脚本告事,而主论术语数集之言属性。 共文本之要证,复制估脚本。', 'ru': 'В этом документе обсуждается терминология ВМТ 2021, разделяемая с точки зрения «мета». Мы представляем результаты наших экспериментов с использованием набора терминологических данных и инструментов OpenNMT (Klein et al., 2017) и JoeyNMT (Kreutzer et al., 2019) для направления языка с английского на французский. Наш эксперимент 1 сравнивает прогнозы двух наборов инструментов. Эксперимент 2 использует OpenNMT для точной настройки модели. Мы сообщаем наши результаты для задачи со сценарием оценки, но в основном обсуждаем лингвистические свойства набора терминологических данных, предоставленных для задачи. Мы предоставляем доказательства важности текстовых жанров во всех баллах, воспроизведя сценарии оценки.', 'ga': 'Pléann an páipéar seo tasc comhroinnte téarmaíochta WMT 2021 ó thaobh “meta” de. Cuirimid i láthair torthaí ár dturgnaimh ag baint úsáide as an tacar sonraí téarmaíochta agus na feiste uirlisí OpenNMT (Klein et al., 2017) agus JoeyNMT (Kreutzer et al., 2019) don treo teanga Béarla go Fraincis. Déanann ár dturgnamh 1 comparáid idir thuartha an dá fhoireann uirlisí. Úsáideann Turgnamh 2 OpenNMT chun an tsamhail a mhionchoigeartú. Tuairiscímid ár dtorthaí don tasc leis an script mheastóireachta ach den chuid is mó pléimid airíonna teangeolaíocha an tacair sonraí téarmaíochta a chuirtear ar fáil don tasc. Cuirimid fianaise ar fáil ar thábhacht seánraí téacs thar scóir, tar éis na scripteanna meastóireachta a mhacasamhlú.', 'el': 'Η παρούσα εργασία εξετάζει την κοινή εργασία ορολογίας WMT 2021 από μια "μετα" προοπτική. Παρουσιάζουμε τα αποτελέσματα των πειραμάτων μας χρησιμοποιώντας το σύνολο δεδομένων ορολογίας και τα κιτ εργαλείων OpenNMT (Klein et al., 2017) και JoeyNMT (Kreutzer et al., 2019) για την κατεύθυνση της γλώσσας Αγγλικά στα Γαλλικά. Το πείραμα μας 1 συγκρίνει τις προβλέψεις των δύο εργαλείων. Το πείραμα 2 χρησιμοποιεί OpenNMT για να ρυθμίσει το μοντέλο. Αναφέρουμε τα αποτελέσματά μας για την εργασία με το σενάριο αξιολόγησης αλλά κυρίως συζητάμε τις γλωσσικές ιδιότητες του συνόλου δεδομένων ορολογίας που παρέχονται για την εργασία. Παρέχουμε αποδείξεις για τη σημασία των ειδών κειμένου σε όλες τις παρτιτούρες, έχοντας αντιγράψει τα σενάρια αξιολόγησης.', 'hu': 'Ez a tanulmány a WMT 2021 terminológiai megosztott feladatát "meta" szempontból tárgyalja. Kísérleteink eredményeit a terminológiai adatkészlet, valamint az OpenNMT (Klein et al., 2017) és JoeyNMT (Kreutzer et al., 2019) eszköztárak segítségével mutatjuk be az angol-francia nyelvirányba. Az 1. kísérletünk összehasonlítja a két eszközkészlet előrejelzéseit. A 2. kísérlet OpenNMT-t használ a modell finomhangolására. A feladat eredményeit értékelő forgatókönyvvel jelentjük be, de leginkább a feladathoz rendelkezésre álló terminológiai adatok nyelvi tulajdonságait vitatjuk meg. Bizonyítékot adunk a szövegműfajok fontosságáról a kották között, miután replikáltuk az értékelő szkripteket.', 'ka': "ეს დოკუმენტი WMT 2021 ტერმინოლოგიის გაყოფილი რაოდენობა 'მეტა' პერვისტიდან განსაზღვრებულია. ჩვენ ჩვენი ექსპერიმენტების შედეგების გამოყენება ტერმინოლოგიის მონაცემების და OpenNMT (Klein et al., 2017) და JoeyNMT (Kreutzer et al., 2019) ხელსაწყობილობის სახელსაწყობილობის ინგლისური სახელსაწყობილო ჩვენი ექსპერიმენტი 1 შემდგომარებს ორი ხელსაწყობილობის წარმოდგენების. Name ჩვენ მივიღეთ მონაცემების შედეგი დავამუშაოთ მონაცემების სკრიპტის შესახებ, მაგრამ უფრო მეტი განსხვავებულია ტერმინოლოგიის მონაცემების ინფორმაცი ჩვენ დავიწყებთ ტექსტის გენერების მნიშვნელობა, რომელიც გარეშე სკრიპტის გარეშე.", 'it': "Questo articolo discute la terminologia condivisa di WMT 2021 da una prospettiva 'meta'. Presentiamo i risultati dei nostri esperimenti utilizzando il dataset terminologico e i toolkit OpenNMT (Klein et al., 2017) e JoeyNMT (Kreutzer et al., 2019) per la direzione linguistica dall'inglese al francese. Il nostro esperimento 1 confronta le previsioni dei due toolkit. L'esperimento 2 utilizza OpenNMT per ottimizzare il modello. Riportiamo i nostri risultati con lo script di valutazione, ma soprattutto discutiamo le proprietà linguistiche del set di dati terminologici fornito per il compito. Forniamo prove dell'importanza dei generi testuali attraverso le partiture, dopo aver replicato gli script di valutazione.", 'lt': 'Šiame dokumente kalbama apie WMT 2021 terminologijos bendrą užduotį „meta“ požiūriu. Pateikiame eksperimentų rezultatus naudojant terminologinių duomenų rinkinį ir OpenNMT (Klein et al., 2017) ir JoeyNMT (Kreutzer et al., 2019) įrankių rinkinius anglų kalbos kryptimi prancūzų kalba. Mūsų eksperimentas 1 palygina dviejų priemonių rinkinių prognozes. 2 eksperimente naudojamas OpenNMT modeliui patobulinti. Su vertinimo scenarijumi pranešame apie savo užduoties rezultatus, tačiau daugiausia aptariame užduoties terminologinių duomenų rinkinio kalbines savybes. Pateikiame įrodymus, kad teksto genrai svarbūs įvairiuose rezultatuose, pakartodami vertinimo scenarijus.', 'kk': "Бұл қағаз WMT 2021 терминологиясын 'meta' перспективінен ортақ тапсырманы талқылады. Біз терминология деректер қорларын және OpenNMT (Klein et al., 2017) және JoeyNMT (Kreutzer et al., 2019) тіл бағыттамасының ағылшын тілде французша құралдарының нәтижесін көрсетедік. Біздің тәжірибеміздің 1- і екі құралдардың алдын- ала көрсетілгенін салыстырады. 2- эксперимент үлгісін баптау үшін OpenNMT қолданылады. Біз тапсырманың нәтижесімізді бағалау скрипті арқылы хабарлаймыз, бірақ көпшілігімен тапсырма үшін келтірілген терминология деректер жиынының лингвистикалық қасиеттер Біз мәтін жанрлардың маңызды мәтін жанрларды оқу скрипттерін қайта жазып, қайта жазып жатыр.", 'mk': 'Овој весник дискутира за терминологијата на WMT 2021 споделена задача од перспектива на „мета“. Ги претставуваме резултатите од нашите експерименти користејќи го терминолошкиот датотек и OpenNMT (Klein et al., 2017) и JoeyNMT (Kreutzer et al., 2019) алатки за јазикот на англиски на француски. Нашиот експеримент 1 ги споредува предвидувањата на двете алатки. Експериментот 2 го користи OpenNMT за финетизирање на моделот. Ние ги известуваме нашите резултати за задачата со сценариото за евалуација, но претежно разговараме за јазичните сопствености на терминолошките податоци обезбедени за задачата. Ние обезбедуваме докази за важноста на текстовите генери во сите резултати, откако ги репликиравме сценаријата за проценка.', 'mn': "Энэ цаас WMT 2021 оны терминологийг 'мета' тодорхойлолтоос хуваалцах ажлыг ярьдаг. Бид терминологийн өгөгдлийн санг ашиглаж, OpenNMT (Klein et al., 2017) болон JoeyNMT (Kreutzer et al., 2019) хэлний хэлний багыг Французт руу хүртэл ашиглаж туршилтын үр дүнг тайлбарлаж байна. Бидний туршилт 1 нь хоёр хэрэгслийн таамаглалыг харьцуулдаг. 2-р туршилт нь OpenNMT-г загварыг сайжруулахын тулд ашигладаг. Бид ажлын үр дүнг үнэлэх скрипт дээр тайлбарлаж байна. Гэхдээ ихэнхдээ ажлын төлөвлөгөөний терминологийн өгөгдлийн хэмжээний талаар ярилцдаг. Бид текст жанрлуудын чухал ач холбогдолтой баталгаа өгч, үнэлгээний скриптүүдийг дахин давтсан.", 'ms': "Kertas ini membahas tugas kongsi terminologi WMT 2021 dari perspektif 'meta'. Kami memperkenalkan hasil eksperimen kami menggunakan set data terminologi dan set alat OpenNMT (Klein et al., 2017) dan JoeyNMT (Kreutzer et al., 2019) untuk arah bahasa Inggeris ke Perancis. Eksperimen kita 1 membandingkan ramalan dua toolkit. Eksperimen 2 menggunakan OpenNMT untuk menyesuaikan model. Kami melaporkan keputusan kami untuk tugas dengan skrip penilaian tetapi kebanyakan membincangkan ciri-ciri bahasa set data terminologi yang disediakan untuk tugas. Kami memberikan bukti kepentingan genre teks di seluruh skor, telah menyalin skrip penilaian.", 'ml': "ഈ പത്രത്തില്\u200d WMT 2021 ടെര്\u200dമിനോളജി പങ്കെടുത്ത ജോലിയെ സംസാരിക്കുന്നു 'മെറ്റ' കാഴ്ചയില്\u200d നിന്ന്. ഞങ്ങള്\u200d ടെര്\u200dമിനോളജി ഡാറ്റാസെറ്റും ഓപ്പെന്\u200dഎംടി (ക്ലിനെറ്റ് അല്., 2017) എന്നിട്ടും ജോയിന്\u200dഎംടി (ക്രിസ്സര്\u200d എറ്റ്., 2019) ഭാഷ തിരിച്ചു ഇംഗ്ലീഷില നമ്മുടെ പരീക്ഷണം 1 ഈ രണ്ട് ഉപകരണങ്ങളുടെ പ്രവചനങ്ങളെ താല്\u200dപ്പര്യമാക്കുന്നു. Experiment 2 uses OpenNMT to fine-tune the model.  നമ്മുടെ ജോലിയുടെ ഫലങ്ങള്\u200d ഞങ്ങള്\u200d വിലാസപ്പെടുത്തുന്നു. പക്ഷെ ജോലിക്കായി നല്\u200dകിയ ടെര്\u200dമിനിയോളജി ഡാറ്റാസറ്റിന്റെ ഭാഷ വ വിലാസങ്ങളുടെ പ്രധാനത്തിന്റെ പ്രധാനപ്പെട്ട തെളിവുകള്\u200d ഞങ്ങള്\u200d നല്\u200dകുന്നു. വിലാസപ്രകാരം സ്ക്രിപ്റ്റു", 'mt': "Dan id-dokument jiddiskuti l-kompitu kondiviż tat-terminoloġija tad-WMT 2021 minn perspettiva 'meta'. Aħna nippreżentaw ir-riżultati tal-esperimenti tagħna billi nużaw is-sett tad-dejta tat-terminoloġija u l-għodod OpenNMT (Klein et al., 2017) u JoeyNMT (Kreutzer et al., 2019) għad-direzzjoni lingwistika Ingliża għal Franċiża. L-esperiment tagħna 1 iqabbel il-previżjonijiet taż-żewġ settijiet ta’ għodod. L-esperiment 2 juża OpenNMT biex itejjeb il-mudell. Aħna nirrappurtaw ir-riżultati tagħna għall-kompitu bil-kitba tal-evalwazzjoni iżda l-aktar niddiskutu l-karatteristiċi lingwistiċi tas-sett tad-dejta tat-terminoloġija pprovdut għall-kompitu. Aħna nipprovdu evidenza tal-importanza tal-ġeneri tat-test fost il-punti, wara li rriplikaw l-iskripti tal-evalwazzjoni.", 'pl': 'W artykule omówiono terminologię wspólnego zadania WMT 2021 z perspektywy "meta". Przedstawiamy wyniki naszych eksperymentów z wykorzystaniem zbioru danych terminologicznych oraz zestawów narzędzi OpenNMT (Klein et al., 2017) i JoeyNMT (Kreutzer et al., 2019) dla kierunku języka angielskiego na francuski. Nasz eksperyment 1 porównuje przewidywania dwóch zestawów narzędzi. Eksperyment 2 używa OpenNMT do dostrojenia modelu. Nasze wyniki dla zadania raportujemy za pomocą skryptu ewaluacyjnego, ale głównie omawiamy właściwości językowe zestawu danych terminologicznych dostarczonych do zadania. Dostarczamy dowodów na znaczenie gatunków tekstowych w różnych partiturach, po replikacji skryptów oceniających.', 'ro': 'Această lucrare discută sarcina comună de terminologie WMT 2021 dintr-o perspectivă "meta". Prezentăm rezultatele experimentelor noastre folosind setul de date terminologice și seturile de instrumente OpenNMT (Klein et al., 2017) și JoeyNMT (Kreutzer et al., 2019) pentru direcția lingvistică din engleză în franceză. Experimentul nostru 1 compară previziunile celor două seturi de instrumente. Experimentul 2 folosește OpenNMT pentru a regla fin modelul. Raportăm rezultatele pentru sarcină cu scriptul de evaluare, dar discutăm mai ales proprietățile lingvistice ale setului de date terminologice furnizat pentru sarcină. Oferim dovezi ale importanței genurilor de text în toate partiturile, după ce am replicat scripturile de evaluare.', 'no': 'Denne papiret diskuterer terminologien WMT 2021 delt oppgåve frå ein «meta»-perspektiv. Vi presenterer resultatet av eksperimentene våre med terminologiske datasett og OpenNMT (Klein et al., 2017) og JoeyNMT (Kreutzer et al., 2019) verktøylinja for språkkretninga engelsk til fransk. Eksperimentet vårt 1 samanliknar forhåndsvising av dei to verktøylinjene. Eksperiment 2 brukar OpenNMT for å finna modellen. Vi rapporterer våre resultata for oppgåva med evalueringsskriptet, men hovudsakelig diskuterer språktiske eigenskapane til terminologiske datasettet som er tilgjengeleg for oppgåva. Vi tilbyr beviser om viktigheten for tekstsjanter over poeng, som har kopiert evalueringsskriptene.', 'sr': 'Ovaj papir razgovara o terminologiji WMT 2021. godine koji je delio zadatak iz perspektive meta. Predstavljamo rezultate naših eksperimenata korištenjem seta terminologije podataka i OpenNMT (Klein et al., 2017) i JoeyNMT (Kreutzer et al., 2019) alata za jezički pravac na francuski. Naš eksperiment 1 uspoređuje predviđanja dva alata. Eksperiment 2 koristi OpenNMT da ispravlja model. Prijavljujemo rezultate za zadatak scenarijom za procjenu, ali uglavnom razgovaramo o jezičkim vlasništvima seta podataka terminologije predviđenoj za zadatak. Mi pružamo dokaze važnosti tekstskih genra preko rezultata, kopirajući scenarije za procjenu.', 'si': "මේ පත්තුව WMT 2021 වර්තමාන්\u200dය ව්\u200dයාපෘතිකය 'මෙටා' පරික්ෂණයෙන් සම්බන්ධ කරනවා. අපි අපේ පරීක්ෂණයේ ප්\u200dරතිචාර දේවල් සඳහා OpenNMT (Klein et al., 2017) සහ JoeyNMT අපේ පරීක්ෂණය 1 සඳහා උපකරණය දෙකක් ගැන අනතුරු කරනවා. පරීක්ෂණ 2 OpenNMT පාවිච්චි කරනවා මොඩල් සුදුසු කරන්න. අපි විශ්ලේෂණ ස්ක්\u200dරිප්ට් එක්ක අපේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d අපි පරික්ෂණ ස්ක්\u200dරිප්ට් වලට පැත්තක් සංවේදනය ගැන සාක්ෂි දෙන්නේ, පරික්ෂණ ස්ක්\u200dරිප්ට් වලට ප", 'sv': 'Denna uppsats diskuterar WMT 2021 terminologi delad uppgift ur ett metaperspektiv. Vi presenterar resultaten av våra experiment med hjälp av terminologidatauppsättningen och verktygen OpenNMT (Klein et al., 2017) och JoeyNMT (Kreutzer et al., 2019) för språkriktningen engelska till franska. Vårt experiment 1 jämför förutsägelserna av de två verktygssatserna. Experiment 2 använder OpenNMT för att finjustera modellen. Vi rapporterar våra resultat för uppgiften med utvärderingsskriptet men diskuterar mestadels de språkliga egenskaperna hos den terminologidata som tillhandahålls för uppgiften. Vi ger bevis på vikten av textgenrer över noter, efter att ha replikerat utvärderingsskripten.', 'ta': "இந்த தாள் WMT 2021 முனையத்திற்கு பங்கிடப்பட்ட பணியை விவாதம் செய்கிறது 'meta' காட்சியில் இருந்து. நாங்கள் எங்கள் சோதனைகளின் முடிவுகளை முனையத்திற்கு தகவல் அமைப்பு மற்றும் OpenNMT (Klein et al., 2017) மற்றும் ஜோயிNMT (கிரியுட்சர் et al., 2019) மற்றும் பிரெஞ்சு மொழ நமது பரிசோதனை 1 இரண்டு கருவிகளின் முன்னோட்டங்களை ஒப்பிடுகிறது. பரிசோதனை 2 மாதிரியை சரியான- தூண்டுவதற்கு OpenNMT பயன்படுத்துகிறது. நாங்கள் வேலைக்கு எங்கள் முடிவுகளை அறிவிக்கிறோம் ஆயினும் பணிக்கு கொடுக்கப்பட்ட முனைய தரவுத்தளத்தின் மொழிய பண்புகளை பெர நாம் மதிப்பெண்களின் முக்கியமான உரை மரங்களின் முக்கியத்தைக் கொடுக்கிறோம், மதிப்பெண்களை மாற்றியமைத்த ப", 'so': "Warqadan ayaa ka sheekaynaya WMT 2021-kii shaqada loo qaybiyey aragtida 'meta' Imtixaanadeena waxaan soo bandhignaa midhihiisa isticmaalka garsoorida terminology iyo OpenNMT (Klein et al., 2017) iyo JoeyNMT (Kreutzer et al., 2019) qalabka qalabka afka Ingiriis-Ingiriis-Ingiriis Imtixaankayada 1 waxay isbarbardhigtaa wixii la sii sheegay labada qalabka. Imtixaanka 2 wuxuu ku isticmaalaa OpenNMT si uu u hago modelka. Waxaynu shaqada ku soo wargelinaynaa resultiyada kaartaynta, laakiin inta badan waxaynu kala sheekeysanaynaa hantida luqada ee macluumaadka garsooridda ee shaqada loo diyaariyey. Waxaynu siinaynaa caddeynta muhiimka qoraalka ah ee kooxda kooxaha, markii aan beddelnay qoraalka qiimeynta.", 'ur': "This paper discusses the WMT 2021 terminology shared task from a 'meta' perspective. ہم اپنی آزمائش کے نتائج کو ترمینلوژی ڈیٹ سٹ اور OpenNMT (Klein et al., 2017) اور JoeyNMT (Kreutzer et al., 2019) زبان کی سمندر انگلیسی کے لئے فرانسوی تک پہنچاتے ہیں۔ ہماری آزمائش ۱ نے دو تولیک کیٹوں کی پیش بینی کی مثال دی ہے۔ آزمائش 2 OpenNMT کو موڈل کو ٹھیک سمجھنے کے لئے استعمال کرتا ہے. ہم اس کام کے نتائج کو ارزیابی اسکریپٹ کے ساتھ گزارتے ہیں لیکن اکثر کام کے لئے پیش کیا گیا ترمینلوژی ڈیٹ سٹ کی زبان ویژگی کے خصوصے سے بحث کرتے ہیں. ہم اسکوروں میں تفصیل جنر کا اہم نشانی دیتے ہیں، اس کے ساتھ مطالعہ لکھنے لکھنے لکھنے کے لکھے ہوئے.", 'uz': "Bu qogʻoz 'meta' koʻrinishidan WMT 2021 terminologiya bilan bog'liqlangan vazifani ajratish mumkin. Biz jarayonlarimizning natijalarimizni Terminolog маълумотлари ва OpenNMT (Klein et 2017) va JoeyNMT (Kreutzer et al., 2019) tilning ingliz tili tilidan inglizcha elektron vositalarning asboblarini ko'rsamiz. Bizning 1 tajribamiz ikki asboblar oldini kamaytirish mumkin. Name Biz vazifaning qiymatni skript bilan natijalarimizni xabar qilamiz, ammo vazifa uchun berilgan terminalogi maʼlumotlar xossasini ko'pchilik bilan javob beramiz. Biz matn genlarining muhimligini qo'llanmalamiz, qiymatlar skriptlarini o'zgartiradik.", 'vi': "Bài báo này bàn về các thuật ngữ về WRT 2021 được chia sẻ nhiệm vụ từ góc nhìn'meta'. Chúng tôi cung cấp kết quả thí nghiệm bằng bộ dữ liệu thuật ngữ thuật và bộ cấu trúc OpenNMT (Klein et al., tê 7) và JoeyNMT (Kreutzer et al., 209) cho đường chỉ dẫn ngôn ngữ từ Anh sang Pháp. Thí nghiệm của chúng tôi 1 so sánh dự đoán của hai bộ kit. Thí nghiệm 2 sử dụng OpenNMT để chỉnh lại mô hình. Chúng tôi báo cáo kết quả của nhiệm vụ này với kịch bản đánh giá, nhưng chủ yếu là thảo luận về tính chất ngôn ngữ của bộ dữ liệu tiêu biểu dành cho nhiệm vụ này. Chúng tôi cung cấp bằng chứng về tầm quan trọng của các thể loại văn bản, đã sao chép các kịch bản đánh giá.", 'bg': 'Настоящата статия разглежда споделената задача на терминологията от мета перспектива. Представяме резултатите от нашите експерименти, използвайки терминологичния набор от данни и инструментариума за езиковата насока от английски към френски език. Нашият експеримент 1 сравнява прогнозите на двата инструментариума. Експеримент 2 използва OpenNMT за фина настройка на модела. Докладваме резултатите от задачата със скрипта за оценка, но най-вече обсъждаме лингвистичните свойства на терминологичния набор от данни, предоставен за задачата. Ние предоставяме доказателства за значението на текстовите жанрове в рамките на оценките, след като репликираме сценариите за оценка.', 'nl': "Dit artikel bespreekt de WMT 2021 terminologie shared task vanuit een 'meta' perspectief. We presenteren de resultaten van onze experimenten met behulp van de terminologie dataset en de OpenNMT (Klein et al., 2017) en JoeyNMT (Kreutzer et al., 2019) toolkits voor de taalrichting Engels naar Frans. Ons experiment 1 vergelijkt de voorspellingen van de twee toolkits. Experiment 2 maakt gebruik van OpenNMT om het model te verfijnen. We rapporteren onze resultaten voor de taak met het evaluatiescript, maar bespreken meestal de taalkundige eigenschappen van de terminologie dataset die voor de taak wordt verstrekt. We leveren bewijs van het belang van tekstgenres in verschillende partituren, nadat we de evaluatiescripts gerepliceerd hebben.", 'da': "Denne artikel diskuterer WMT 2021 terminologi delt opgave ud fra et 'meta'-perspektiv. Vi præsenterer resultaterne af vores eksperimenter ved hjælp af terminologidatasættet og OpenNMT (Klein et al., 2017) og JoeyNMT (Kreutzer et al., 2019) værktøjssættet til sprogretningen engelsk til fransk. Vores eksperiment 1 sammenligner forudsigelserne fra de to værktøjssæt. Eksperiment 2 bruger OpenNMT til at finjustere modellen. Vi rapporterer vores resultater til opgaven med evalueringsscriptet, men diskuterer hovedsageligt de sproglige egenskaber af det terminologidatasæt, der leveres til opgaven. Vi giver dokumentation for vigtigheden af tekstgenrer på tværs af partiturer, efter at have replikeret evalueringsscripts.", 'hr': 'Ovaj papir razgovara o terminologiji WMT 2021. godine podijeljenom zadatku iz perspektive meta. Predstavljamo rezultate naših eksperimenata koristeći komplet podataka terminologije i OpenNMT (Klein et al., 2017) i JoeyNMT (Kreutzer et al., 2019) alata za jezički pravac na francuski. Naš eksperiment 1 uspoređuje predviđanja dva alata. Eksperiment 2 koristi OpenNMT kako bi upravljali model. Prijavljujemo rezultate za zadatak scenarijom za procjenu, ali uglavnom razgovaramo o jezičkim vlasništvima seta podataka terminologije predviđenoj za zadatak. Mi pružamo dokaze važnosti tekstskih genra u raznim rezultatima, kopirajući procjene skripta.', 'ko': "본고는'원'의 관점에서 WMT 2021 용어 공유 임무를 논의했다.용어 데이터 세트와 OpenNMT(Klein 등, 2017년)와 Joey NMT(Kreutzer 등, 2019년) 키트를 사용해 영어부터 프랑스어까지 언어 지도에 활용한 실험 결과를 보여줬다.우리의 실험1은 두 개의 도구 꾸러미의 예측을 비교했다.실험 2는 OpenNMT를 사용하여 모델을 미세하게 조정합니다.우리는 평가 스크립트로 작업의 결과를 보고했지만, 주로 작업에 제공된 용어 데이터 집합의 언어 속성을 논의했다.우리는 평가 스크립트를 복제하여 텍스트 유형이 점수에서 얼마나 중요한지 증거를 제공했다.", 'sw': "Gazeti hili linajadili tatizo la WMT 2021 lililoshirikishwa na kazi kutoka kwenye mtazamo wa 'meta'. Tunaonyesha matokeo ya majaribio yetu kwa kutumia seti ya takwimu za utamaduni na OpenNMT (Klein et al., 2017) na JoeyNMT (Kreutzer et al., 2019) vifaa vya vifaa vya kiingereza kwa Kifaransa. Jaribio letu la 1 linalinganisha utabiri wa vifaa viwili. Mjaribu 2 hutumia OpenNMT kwa kutumia muundo mzuri. Tunatoa taarifa za matokeo yetu kwa jukumu hili kwa kutumia manufaa ya uchunguzi lakini kwa kiasi kikubwa tunajadili utafiti wa lugha wa taarifa za kitamaduni zilizotolewa kwa kazi hiyo. Tunatoa ushahidi wa umuhimu wa jeni za maandishi katika vipindi vyote, baada ya kubadilisha vitabu vya uchunguzi.", 'tr': "Bu kagyz WMT 2021-iň terminologiýasynyň 'meta' perspektibinden bölünen zadyny gürrüň edýär. Biz terminologiýa veri setirini we OpenNMT (Klein et al., 2017) we JoeyNMT (Kreutzer et al., 2019) dilinde fransuzça dil görkezilişinden netijelerimizi görkeýäris. Biziñ denetimiz 1-nji iki esbap guralynyň önümlerini çykarýar. OpenNMT'i nusgasyny düzeltmek üçin janlaşdyrýar. Biz netijelerimizi çykyş skripti bilen görkeýäris ýöne köplenç gören terminologiýa datasynyň dili häsiýetlerini taryşýarys. Biz çykyş skriptlerini kopiýa eden metin jenerallaryň wajyplygyny tassyklap edýäris.", 'de': 'In diesem Beitrag wird die WMT 2021 Terminologie Shared Task aus einer Meta-Perspektive diskutiert. Wir präsentieren die Ergebnisse unserer Experimente mit dem Terminologiedatensatz und den OpenNMT (Klein et al., 2017) und JoeyNMT (Kreutzer et al., 2019) Toolkits für die Sprachrichtung Englisch-Französisch. Unser Experiment 1 vergleicht die Vorhersagen der beiden Toolkits. Experiment 2 verwendet OpenNMT zur Feinabstimmung des Modells. Wir berichten unsere Ergebnisse für die Aufgabe mit dem Evaluationsskript, diskutieren aber meist die sprachlichen Eigenschaften des für die Aufgabe bereitgestellten Terminologiedatensatzes. Wir belegen die Bedeutung von Textgattungen über Partituren hinweg, indem wir die Bewertungsskripte repliziert haben.', 'fa': 'این کاغذ در مورد ترمینالوژی WMT ۲۰۱۱ از نظر "متا" صحبت می\u200cکند. ما نتیجه آزمایشات خود را با استفاده از مجموعه داده\u200cهای ترمینالوژی و OpenNMT (Klein et al., 2017) و JoeyNMT (Kreutzer et al., 2019) برای سمت انگلیسی به فرانسوی نشان می\u200cدهیم. آزمایش ما ۱ پیش بینی دو ابزار را مقایسه می کند. تجربه ۲ از OpenNMT استفاده می\u200cکند تا مدل را پاکیزه کند. ما نتیجه\u200cهایمان را با نوشته ارزیابی گزارش می\u200cدهیم اما بیشتر در مورد ویژه\u200cهای زبان\u200cشناسی داده\u200cهای ترمینالوژی که برای این کار ارزیابی می\u200cشود بحث می\u200cکنیم. ما مدرک اهمیت ژنترهای متن را در مقابل امتیاز می دهیم، که نوشته های ارزیابی را تکرار کردیم.', 'id': "This paper discusses the WMT 2021 terminology shared task from a 'meta' perspective.  Kami mempersembahkan hasil eksperimen kami menggunakan set data terminologi dan set alat OpenNMT (Klein et al., 2017) dan JoeyNMT (Kreutzer et al., 2019) untuk arah bahasa Inggris ke Perancis. Eksperimen kami 1 membandingkan prediksi dari dua toolkit. Eksperimen 2 menggunakan OpenNMT untuk memperbaiki model. Kami melaporkan hasil kami untuk tugas dengan skrip evaluasi tetapi kebanyakan mendiskusikan properti bahasa dari set data terminologi yang disediakan untuk tugas. Kami menyediakan bukti penting dari genre teks di seluruh skor, telah mereplikasi skrip evaluasi.", 'am': "This paper discusses the WMT 2021 terminology shared task from a 'meta' perspective.  የድምፅ ውጤቶችን ተርሚኖሎጂ ዳታተር እና የOpenNMT (Klein et al., 2017) እና ዮዮyNMT (Kreutzer et al., 2019) ለቋንቋው መመሪያ ወደ ፈረንሳይኛ ወደፈረንሳይኛ መዘዋወር እናቀርባለን፡፡ ፈተናችን 1 የሁለቱን መሣሪያዎች ትንቢት ያሳያል፡፡ ምርጫዎች ወደ ስራው ውጤቶችን በማድረግ ጽሑፍ እናስታውቃለን ነገር ግን አብዛኛውን ለስራ የተሰጠውን የተርሚኖሎጂ ዳታዎችን የቋንቋ ምርጫዎችን እናሳውቃለን፡፡ የጽሑፉን የሥርዓት ግንኙነት በቋንቋዎች ላይ የሚያስፈልገውን ማስረጃ እናደርጋለን፡፡", 'af': "Hierdie papier bespreek die WMT 2021 terminologie gedeelde taak van 'n 'meta' perspektief. Ons stel die resultate van ons eksperimente met die gebruik van die terminologie datastel en die OpenNMT (Klein et al., 2017) en JoeyNMT (Kreutzer et al., 2019) nutsprogramme vir die taal rigting Engels na Frans. Ons eksperiment 1 vergelyk die voorskou van die twee nutsbalke. Eksperiment 2 gebruik OpenNMT om die model te finaliseer. Ons rapporteer ons resultate vir die taak met die evalueringsskrip, maar meeste bespreek die lingwisiese eienskappe van die terminologie datastel wat vir die taak verskaf is. Ons verskaf getuienis van die belangrikheid van teks genre oor rekorde, terwyl ons die evalueringsskripte kopieer het.", 'bn': "এই প্রবন্ধে উইএমটি ২০২১ টার্মিনিলজি একটি 'মেটা' দৃষ্টিভঙ্গি থেকে ভাগাভাগি করা কাজ নিয়ে আলোচনা করেছে। আমরা আমাদের পরীক্ষার ফলাফল টার্মিনোলজি ডাটাসেট এবং ওপেন এমটি (ক্লিনেনে এল, ২০১৭) এবং জোয়াইএনএমটি (ক্রিউজারেরে এল., ২০১৯) ভাষার দিকে ইংরেজী থেকে ফ আমাদের পরীক্ষা ১ দুই টুলবিটের ভবিষ্যৎবাণীর তুলনা করেছে। Name আমরা এই কাজের জন্য আমাদের ফলাফল রিপোর্ট করি মূল্যের স্ক্রিপ্টের সাথে কিন্তু বেশীরভাগ ভাষায় টার্মিনোলজি ডাটাসেটের ভাষার আমরা স্কোরে টেক্সট জেনারের গুরুত্বপূর্ণ প্রমাণ প্রদান করি, মূল্যায়ন স্ক্রিপ্টের বদলে দিয়েছি।", 'bs': 'Ovaj papir razgovara o terminologiji WMT 2021-a koji je podijeljen zadatak iz perspektive "meta". Predstavljamo rezultate naših eksperimenata korištenjem seta terminologije podataka i OpenNMT (Klein et al., 2017) i JoeyNMT (Kreutzer et al., 2019) alata za jezički pravac na francuski. Naš eksperiment 1 uspoređuje predviđanja dva alata. Eksperiment 2 koristi OpenNMT kako bi upravljali model. Prijavljujemo rezultate za zadatak scenarijom procjene, ali uglavnom razgovaramo o jezičkim vlasništvima seta podataka terminologije predviđenoj za zadatak. Mi pružamo dokaze važnosti tekstskih genra preko rezultata, kopirajući scenarije procjene.', 'sq': "Ky dokument diskuton terminologjinë e përbashkët të WMT 2021 nga një perspektivë 'meta'. Ne paraqesim rezultatet e eksperimenteve tona duke përdorur kompletin e të dhënave të terminologjisë dhe paketat e instrumenteve OpenNMT (Klein et al., 2017) dhe JoeyNMT (Kreutzer et al., 2019) për drejtimin anglez në francez. Our experiment 1 compares the predictions of the two toolkits.  Eksperimenti 2 përdor OpenNMT për të rregulluar modelin. Ne raportojmë rezultatet tona për detyrën me scenarin e vlerësimit por kryesisht diskutojmë pronësitë gjuhësore të kompletit të dhënash të terminologjisë të ofruar për detyrën. We provide evidence of the importance of text genres across scores, having replicated the evaluation scripts.", 'cs': 'Tento článek pojednává o terminologickém sdíleném úkolu WMT 2021 z pohledu "meta". Představujeme výsledky našich experimentů s využitím terminologického datového souboru a sady nástrojů OpenNMT (Klein et al., 2017) a JoeyNMT (Kreutzer et al., 2019) pro jazykový směr angličtiny do francouzštiny. Náš experiment 1 porovnává predikce těchto dvou sad nástrojů. Experiment 2 používá OpenNMT k jemnému vyladění modelu. Výsledky pro daný úkol hlásíme pomocí hodnotícího skriptu, ale především diskutujeme o jazykových vlastnostech terminologického datového souboru poskytnutého pro daný úkol. Poskytujeme důkazy o významu textových žánrů napříč partiturami, po replikaci hodnotících skriptů.', 'ca': "Aquest paper discute la tasca compartida de terminologia WMT 2021 d'una perspectiva 'meta'. Presentam els resultats dels nostres experiments utilitzant el conjunt de dades de terminologia i els conjunts d'eines OpenNMT (Klein et al., 2017) i JoeyNMT (Kreutzer et al., 2019) per a la direcció del llenguatge anglès al francès. El nostre experiment 1 compara les prediccions dels dos paquets d'eines. L'experiment 2 utilitza OpenNMT per ajustar el model. Informem els nostres resultats per la tasca amb l'escriptura d'evaluació però principalment discutem les propietats lingüístices del conjunt de dades de terminologia proporcionat per la tasca. Oferecem proves de l'importància dels gèneres de text a través de les puntuacions, havent replicat els guions d'evaluació.", 'hy': 'Այս աշխատանքը քննարկում է 2021 թվականի ԱՄԹ տերմինոլոգիան, որը կիսվում է մետայի տեսանկյունից: Մենք ներկայացնում ենք մեր փորձարկումների արդյունքները՝ օգտագործելով տերմինոլոգիայի տվյալների համակարգը և OpenNMT (Կլեյնը և այլն., 2017) և ՋոյՆՄԹ (Կրեյզեր և այլն., 2019) գործիքների շարքերը լեզվի ուղղությամբ անգլերեն դեպի ֆրան Մեր փորձը 1-ը համեմատում է երկու գործիքների կանխատեսումները: Տարբերությունը 2-ն օգտագործում է OpenNMT-ը մոդելի բարելավման համար: Մենք զեկուցում ենք մեր արդյունքները վերաբերյալ գործին գնահատման գրաֆիկի միջոցով, բայց հիմնականում քննարկում ենք այս գործի համար տրամադրված տերմինոլոգիայի տվյալների լեզվային հատկությունները: Մենք ապացույցներ ենք տալիս տեքստի գեների կարևորության մասին գնահատման մեջ, վերարտադրելով գնահատման գրքերը:', 'et': 'Käesolevas artiklis käsitletakse WMT 2021 terminoloogia jagatud ülesannet "meta" vaatenurgast. Esitleme oma eksperimentide tulemusi, kasutades terminoloogia andmekogumit ning OpenNMT (Klein et al., 2017) ja JoeyNMT (Kreutzer et al., 2019) tööriistakomplekte keele suunas inglise kuni prantsuse keel. Meie eksperiment 1 võrdleb kahe tööriistakomplekti prognoose. Eksperiment 2 kasutab OpenNMT mudeli peenhäälestamiseks. Arutame ülesande tulemused hindamisskriptiga, kuid peamiselt arutleme ülesande jaoks ettenähtud terminoloogia andmekogumi keelelisi omadusi. Esitame tõendeid tekstižanrite tähtsusest skoorides, olles korrutanud hindamisskriptid.', 'fi': 'Tässä artikkelissa käsitellään WMT 2021 -terminologian yhteistä tehtävää "meta"-näkökulmasta. Kokeilujen tulokset esitellään käyttäen terminologiaaineistoa ja OpenNMT (Klein et al., 2017) ja JoeyNMT (Kreutzer et al., 2019) työkalupakkeja englannin ja ranskan kielen ohjaukseen. Kokeessa 1 vertaillaan näiden kahden työkalupakin ennusteita. Kokeilu 2 käyttää OpenNMT:tä mallin hienosäätöön. Raportoimme tehtävän tuloksista arviointiskriptin avulla, mutta enimmäkseen keskustelemme tehtävään sisältyvän terminologiaaineiston kielellisistä ominaisuuksista. Annamme näyttöä tekstigenrien merkityksestä pisteytyksissä toistettuamme arviointiskriptit.', 'az': "Bu kağıt WMT 2021 terminoloji 'meta' perspektivindən paylaşılan iş barəsində mübahisə edir. Biz təcrübələrimizin sonuçlarını terminoloji verilən qutusu və OpenNMT (Klein et al., 2017) və JoeyNMT (Kreutzer et al., 2019) dil tərəfindən Fransızca dil tərəfindən istifadə edirik. Bizim təcrübəmiz 1, iki araç çubuğunun təcrübələrini salır. 2-ci sınaq modeli düzəltmək üçün OpenNMT qullanır. Bizim sonuçlarımızı hesablama skriptləri ilə müşahidə edirik, amma çox iş üçün verilən terminoloji verilər qutusunun dil özelliklərini müşahidə edirik. Biz mətn genirlərinin möhkəmliğini göstəririk, değerlendirmə skriptlərini yenidən dəyişdirdik.", 'ha': "Wannan takardan na yi jayayya a haɗin aiki na WMT 2021 daga wurin 'meta'. We present the results of our experiments using the terminology dataset and the OpenNMT (Klein et al., 2017) and JoeyNMT (Kreutzer et al., 2019) toolkits for the language direction English to French.  Kayan jarrabonmu 1 yana kamfata misalin abubuwa biyu. Experiment 2 na amfani da Open NMT zuwa gyare-tune misalin. Munã sanar da matsalayinmu ga aikin da manuscriptan evaluation kuma amma mafi yawan ka yi jayayya masu tsarin littafan linguistic da aka ƙayyade wa aikin. Munã bãyar da bayani na muhimmin matsayin genre a kowace kowace, da aka musanya manuscriptun muhimmada.", 'sk': "Ta prispevek obravnava skupno nalogo terminologije WMT 2021 z 'meta' perspektive. Rezultate naših eksperimentov predstavljamo z uporabo terminološkega nabora podatkov in orodja OpenNMT (Klein et al., 2017) in JoeyNMT (Kreutzer et al., 2019) za jezikovno smer angleščine v francoščino. Naš eksperiment 1 primerja napovedi obeh orodij. Poskus 2 uporablja OpenNMT za natančno nastavitev modela. Naše rezultate za nalogo poročamo z ocenjevalnim scenarijem, večinoma pa obravnavamo jezikovne lastnosti terminološkega nabora podatkov za nalogo. Prikazujemo pomembnost besedilnih zvrsti v vseh ocenah, pri čemer smo ponovili ocenjevalne scenarije.", 'jv': "This paper talks about the WT 2020 terminal share task from a 'meta' perspective. Awak dhéwé ngejaraké perintah sing nggambar nggawe dataset Terminal nggambar lan Open NMT (klain et al, 2011) lan JoeyNMT (Kreutzer et al, 2011) sak alat kanggo langgambar inggilesuk kanggo Perancis. Where am I Name Awak dhéwé Cendelah dhéwé nggawe barang nggo nggambar cara-cara Language Awak dhéwé nggawe barang nggawe barang-barang seneng pisan kelas kuwi nggambar kelas kuwi nggawe barang seneng pisan nggambar.", 'he': 'העבודה הזאת מדברת על המשימה המשותפת של WMT 2021 מנקודת מבט מטה. אנחנו מציגים את תוצאות הניסויים שלנו באמצעות קבוצת מידע הטרמינולוגיה והכלים OpenNMT (Klein et al., 2017) ו JoeyNMT (Kreutzer et al., 2019) לכיוון השפה אנגלית לצרפתית. הניסוי שלנו 1 שווה את התחזויות של שתי כלים. הניסוי 2 משתמש OpenNMT כדי להתאים את המודל. אנחנו מדווחים על התוצאות שלנו למשימה עם תסריט הערכה אבל בעיקר מדברים על תכונות השפה של קבוצת מידע הטרמולוגיה שנספק למשימה. אנחנו מספקים ראיות על חשיבות של גנרס טקסט ברחבי הציונים, אחרי ששיכפלו את התסריטים הערכה.', 'bo': "This paper discusses the WMT 2021 terminology shared task from a 'meta' perspective. ང་ཚོས་བརྡ་ཆད་ལམ་ལུགས་གནད་སྡུད་ཆ་འཕྲིན་དང་། OpenNMT (Klein et al., 2017) དང་། JoeyNMT (Kreutzer et al., 2019) སྐད་ཡིག་གི་སྒྲུང་འཕྲིན་ལ་ཡན་ལག་ཆེན་འཐབ་སྟེ། ང་ཚོའི་experiment་ལྡན་༡་གིས་ལག་ཆས་གཉིས་ཀྱི་སྔོན་ཚོད་དང་མཉམ་འབྱུང་བ་རེད། Experiment 2 uses OpenNMT to fine-tune the model. We report our results for the task with the evaluation script but mostly discuss the linguistic properties of the terminology dataset provided for the task. ང་ཚོས་ཡིག་གི་རྣམ་གྲངས་ཀ་ལས་ཕར་བསྡད་བྱས་ནས་ཡིག་གི་དགའ་གལ་ཆེ་བ་སྟོན་བྱེད་ཀྱི་ཡོད།"}
{'en': 'Dynamic Terminology Integration for COVID-19 and Other Emerging Domains', 'pt': 'Integração de terminologia dinâmica para COVID-19 e outros domínios emergentes', 'ar': 'تكامل المصطلحات الديناميكي لـ COVID-19 والمجالات الناشئة الأخرى', 'es': 'Integración terminológica dinámica para COVID-19 y otros dominios emergentes', 'fr': "Intégration terminologique dynamique pour la COVID-19 et d'autres domaines émergents", 'ja': '新型コロナウイルスおよびその他の新興ドメインの動的用語統合', 'zh': '针 COVID-19 、新兴术语集', 'ru': 'Интеграция динамической терминологии для COVID-19 и других развивающихся областей', 'hi': 'कोविड-19 और अन्य उभरते डोमेन के लिए गतिशील शब्दावली एकीकरण', 'ga': 'Comhtháthú Téarmaíochta Dinimiciúla le haghaidh COVID-19 agus Fearainn Eile atá ag Teacht Chun Cinn', 'el': 'Δυναμική ενοποίηση ορολογίας για το COVID-19 και άλλους αναδυόμενους τομείς', 'hu': 'Dinamikus terminológiai integráció COVID-19 és egyéb feltörekvő területek számára', 'ka': 'დინამიკური ტერმინოლოგიის ინტერგრაცია COVID- 19 და სხვა გარეშე დემონიებისთვის', 'it': 'Integrazione terminologica dinamica per COVID-19 e altri domini emergenti', 'kk': 'COVID- 19 және басқа қызықты домендердің динамикалық терминологиялық интеграциясы', 'lt': 'Dinaminė terminologijos integracija COVID-19 ir kitų besiformuojančių sričių atžvilgiu', 'mk': 'Динамичка терминолошка интеграција за COVID-19 и други појавни домени', 'ms': 'Integrasi Terminologi Dinamik untuk COVID-19 dan Domain Terbangun Lain', 'ml': 'കോവിഡി- 19 എന്നിട്ടും മറ്റു എമ്പെര്\u200dമിങ്ങ് ഡോമെന്\u200dസിക് ടെര്\u200dമിനോളജി ഒരുമിച്ചുകൂട്ടുക', 'mt': 'Integrazzjoni tat-Terminoloġija Dinamika għal COVID-19 u Domani Emerġenti Oħra', 'mn': 'COVID-19 болон бусад гайхалтай зохиолуудын динамик терминологийн нэгтгэл', 'no': 'Dynamisk terminologisk integrering for COVID- 19 og andre avgrensingsdomene', 'pl': 'Dynamiczna integracja terminologii dla COVID-19 i innych powstających domen', 'ro': 'Integrarea dinamică a terminologiei pentru COVID-19 și alte domenii emergente', 'sr': 'Dinamička integracija terminologije za COVID-19 i druge hitne domene', 'si': 'COVID-19 සහ අනිත් ප්\u200dරශ්නයක් සඳහා සාධාන්\u200dය විද්\u200dයාවත්මක සම්බන්ධය', 'so': 'La qabsashada Terminology ee COVID-19 iyo hay’adaha kale ee xaaladaha degdega ah', 'sv': 'Dynamisk terminologiintegration för COVID-19 och andra framväxande domäner', 'ta': 'COVID- 19 மற்றும் மற்றும் வெளியேறும் தளங்களுக்கான Dynamic Terminalology Integration', 'ur': 'COVID-19 اور دوسری اضطراری ڈومین کے لئے داینامیک ترمیمینولوژی انٹرنگ', 'uz': 'Comment', 'vi': 'KCharselect unicode block name', 'hr': 'Dinamička integracija terminologije za COVID-19 i druge hitne domene', 'bg': 'Интеграция на динамична терминология за други нововъзникващи домейни', 'nl': 'Dynamische terminologie integratie voor COVID-19 en andere opkomende domeinen', 'de': 'Dynamische Terminologieentegration für COVID-19 und andere aufstrebende Domänen', 'da': 'Dynamisk terminologiintegration til COVID-19 og andre nye domæner', 'sw': 'Dynamic Terminology Integration for COVID-19 and Other Emerging Domains', 'id': 'Integrasi Terminologi Dinamik untuk COVID-19 dan Domain Terbangun lainnya', 'ko': '코로나와 기타 신흥 분야의 동적 용어 통합', 'fa': 'ترمینالوژی دینامیک برای COVID-19 و دیگر دامنهای فوری', 'tr': 'COVID-19 we Başga Emerging Domenalar üçin dinamik Terminologiýa Integrasiýasy', 'af': 'Dinamiese Terminologie Integrasie vir COVID- 19 en ander Emerging Domeine', 'hy': 'COVID-19 և այլ զարգացող ոլորտների դինամիկ տերմինոլոգիայի ինտեգրացիան', 'sq': 'Integrimi dinamik i terminologjisë për COVID-19 dhe fusha të tjera në zhvillim', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'bn': 'COVID-19 এবং অন্যান্য জরুরী ডোমেনের জন্য ডাইনামিক টার্মিনোলজি একত্রিত', 'bs': 'Dinamička integracija terminologije za COVID-19 i druge hitne domene', 'ca': 'Integració dinàmica de terminologia per COVID-19 i altres dominis emergents', 'az': 'COVID-19 v톛 Dig톛r Emerging Domenil톛r 칲칞칲n dinamik Terminoloji Integrasyonu', 'et': 'Dünaamiline terminoloogia integratsioon COVID-19 ja muude tekkivate domeenide jaoks', 'cs': 'Dynamická terminologická integrace pro COVID-19 a další vznikající domény', 'fi': 'Dynamic Terminology Integration for COVID-19 and other Emerging Domains', 'ha': 'KCharselect unicode block name', 'bo': 'Dynamic Terminology Integration for COVID-19 and Other Emerging Domains', 'jv': 'dynamics Terminal inumber', 'he': 'שיתוף טרמינולוגיה דינמי עבור COVID-19 ותחומים נוספים אחרים', 'sk': 'Dinamična terminaloška integracija za COVID-19 in druge nastajajoče domene'}
{'en': 'The majority of ', 'fr': "La plupart des domaines linguistiques nécessitent une utilisation prudente de la terminologie afin de garantir la clarté et l'adéquation des informations transmises. Bien que l'utilisation correcte de la terminologie pour certaines langues et certains domaines puisse être obtenue en adaptant des systèmes de TA à usage général sur de grands volumes de données parallèles internes au domaine, de telles quantités de données spécifiques à un domaine sont rarement disponibles pour les langues et les domaines de niche moins dotés de ressources. En outre, comme l'a récemment illustré la COVID-19, aucune donnée parallèle spécifique à un domaine n'est facilement disponible pour les domaines émergents. Cependant, la gravité de cette récente calamité a créé une forte demande de traduction fiable d'informations critiques concernant la prévention des pandémies et des infections. Ce travail fait partie de WMT2021 Shared Task\xa0: Machine Translation using Terminologies, où nous décrivons des systèmes de traduction automatique Tilde capables d'intégrer la terminologie dynamique au moment de la traduction. Nos systèmes atteignent jusqu'à 94\xa0% de précision d'utilisation des termes COVID-19 sur l'ensemble de tests de la paire de langues EN-FR sans avoir accès à aucune forme d'information dans le domaine pendant la formation du système.", 'es': 'La mayoría de los dominios lingüísticos requieren un uso prudente de la terminología para garantizar la claridad y adecuación de la información transmitida. Si bien el uso correcto de la terminología para algunos lenguajes y dominios se puede lograr adaptando los sistemas de MT de propósito general en grandes volúmenes de datos paralelos dentro del dominio, estas cantidades de datos específicos de dominio rara vez están disponibles para lenguajes con menos recursos y dominios especializados. Además, como lo ejemplificó recientemente la COVID-19, no hay datos paralelos específicos de dominio disponibles para los dominios emergentes. Sin embargo, la gravedad de esta reciente calamidad creó una gran demanda de traducción fiable de información crítica sobre la prevención de pandemias e infecciones. Este trabajo forma parte de la tarea compartida WMT2021: traducción automática mediante terminologías, donde describimos los sistemas Tilde MT que son capaces de integrar terminología dinámica en el momento de la traducción. Nuestros sistemas alcanzan hasta un 94% de precisión en el uso de términos de COVID-19 en el conjunto de pruebas de la combinación de idiomas EN-FR sin tener acceso a ningún tipo de información dentro del dominio durante la capacitación del sistema.', 'ar': 'تتطلب غالبية مجالات اللغة استخدامًا حكيمًا للمصطلحات لضمان وضوح المعلومات المنقولة وكفايتها. بينما يمكن تحقيق الاستخدام الصحيح للمصطلحات لبعض اللغات والمجالات من خلال تكييف أنظمة الترجمة الآلية للأغراض العامة على كميات كبيرة من البيانات المتوازية داخل المجال ، نادرًا ما تتوفر مثل هذه الكميات من البيانات الخاصة بالمجال للغات قليلة الموارد والمجالات المتخصصة. علاوة على ذلك ، كما يتضح من COVID-19 مؤخرًا ، لا توجد بيانات موازية خاصة بالمجال متاحة بسهولة للمجالات الناشئة. ومع ذلك ، أدت خطورة هذه الكارثة الأخيرة إلى ارتفاع الطلب على الترجمة الموثوقة للمعلومات الهامة المتعلقة بالوقاية من الجائحة والعدوى. هذا العمل جزء من مهمة مشتركة WMT2021: الترجمة الآلية باستخدام المصطلحات ، حيث نصف أنظمة Tilde MT القادرة على التكامل الديناميكي للمصطلحات في وقت الترجمة. تحقق أنظمتنا ما يصل إلى 94٪ من دقة استخدام مصطلح COVID-19 في مجموعة اختبار زوج اللغة EN-FR دون الوصول إلى أي شكل من أشكال المعلومات داخل المجال أثناء تدريب النظام.', 'pt': 'A maioria dos domínios linguísticos exige o uso prudente da terminologia para garantir clareza e adequação das informações transmitidas. Embora o uso correto da terminologia para alguns idiomas e domínios possa ser alcançado através da adaptação de sistemas de MT de uso geral em grandes volumes de dados paralelos no domínio, essas quantidades de dados específicos de domínio raramente estão disponíveis para idiomas com menos recursos e domínios de nicho. Além disso, conforme exemplificado recentemente pelo COVID-19, nenhum dado paralelo específico de domínio está prontamente disponível para domínios emergentes. No entanto, a gravidade dessa calamidade recente criou uma alta demanda por tradução confiável de informações críticas sobre prevenção de pandemias e infecções. Este trabalho faz parte da Tarefa Compartilhada WMT2021: Tradução Automática usando Terminologias, onde descrevemos sistemas Tilde MT que são capazes de integração terminológica dinâmica no momento da tradução. Nossos sistemas atingem até 94% de precisão de uso do termo COVID-19 no conjunto de teste do par de idiomas EN-FR sem ter acesso a qualquer forma de informação no domínio durante o treinamento do sistema.', 'ja': 'ほとんどの言語領域では、伝達される情報の明確さと妥当性を確保するために用語の慎重な使用が必要です。 いくつかの言語およびドメインの用語の正しい使用は、大量のドメイン内並列データに汎用MTシステムを適応させることによって達成することができるが、そのような大量のドメイン固有のデータは、リソースの少ない言語およびニッチドメインではほとんど利用できない。 さらに、最近のCOVID -19によって例示されるように、新興ドメインでは、ドメイン固有の並列データは容易に利用できません。 しかし、この最近の災害の深刻さは、パンデミックと感染防止に関する重要な情報の信頼できる翻訳に対する高い需要を生み出しました。 この作業は、WMT 2021 Shared Task: Machine Translation using Terminologyの一部であり、翻訳時に動的な用語統合が可能なTilde MTシステムについて説明しています。 当社のシステムは、システムトレーニング中にいかなる形式のドメイン内情報にもアクセスすることなく、EN - FR言語ペアのテストセットで最大94%のCOVID -19用語使用精度を達成します。', 'zh': '多言谨用术语,以保清晰度充分性。 虽以大域并行机器翻译统,可以正言语域术语,然少言利基域,鲜得此数特定。 此外如近COVID-19所明,于新兴域,无特定于域并行数据。 然近此难者严重性使可重译流行、感染之要。 此WMT2021共事:用术语之机器翻译,言其能动于译者术语波号机器翻译统也。 EN-FR言试集上达94%COVID-19术语用准确率,无求于统培训之间。', 'hi': 'अधिकांश भाषा डोमेन को व्यक्त की गई जानकारी की स्पष्टता और पर्याप्तता सुनिश्चित करने के लिए शब्दावली के विवेकपूर्ण उपयोग की आवश्यकता होती है। जबकि कुछ भाषाओं और डोमेन के लिए शब्दावली का सही उपयोग इन-डोमेन समानांतर डेटा की बड़ी मात्रा पर सामान्य-उद्देश्य एमटी सिस्टम को अनुकूलित करके प्राप्त किया जा सकता है, डोमेन-विशिष्ट डेटा की ऐसी मात्रा शायद ही कभी कम संसाधन वाली भाषाओं और आला डोमेन के लिए उपलब्ध होती है। इसके अलावा, जैसा कि हाल ही में कोविड -19 द्वारा उदाहरण दिया गया है, उभरते डोमेन के लिए कोई डोमेन-विशिष्ट समानांतर डेटा आसानी से उपलब्ध नहीं है। हालांकि, इस हालिया आपदा की गंभीरता ने महामारी और संक्रमण की रोकथाम के बारे में महत्वपूर्ण जानकारी के विश्वसनीय अनुवाद के लिए एक उच्च मांग पैदा की। यह काम WMT2021 साझा कार्य का हिस्सा है: शब्दावली का उपयोग करके मशीन अनुवाद, जहां हम टिल्ड एमटी सिस्टम का वर्णन करते हैं जो अनुवाद के समय गतिशील शब्दावली एकीकरण में सक्षम हैं। हमारे सिस्टम सिस्टम प्रशिक्षण के दौरान इन-डोमेन जानकारी के किसी भी रूप तक पहुंच के बिना EN-FR भाषा जोड़ी के परीक्षण सेट पर 94% तक कोविड -19 शब्द उपयोग सटीकता प्राप्त करते हैं।', 'ru': 'Большинство языковых областей требуют осмотрительного использования терминологии для обеспечения ясности и адекватности передаваемой информации. Хотя правильное использование терминологии для некоторых языков и доменов может быть достигнуто путем адаптации систем МТ общего назначения на больших объемах параллельных данных в пределах домена, такие объемы данных, специфичных для домена, редко доступны для языков с меньшими ресурсами и нишевых доменов. Кроме того, как показал недавний пример COVID-19, для новых доменов не существует доступных параллельных данных. Тем не менее, серьезность этого недавнего бедствия создала высокий спрос на надежный перевод критически важной информации о пандемии и профилактике инфекции. Эта работа является частью WMT2021 Shared Task: Machine Translation using Terminologies, где мы описываем системы Tilde MT, которые способны к динамической терминологической интеграции во время перевода. Наши системы достигают 94% точности использования терминов COVID-19 на тестовом наборе языковой пары EN-FR, не имея доступа к любой форме внутридоменной информации во время обучения системе.', 'ga': 'Teastaíonn úsáid stuama na téarmaíochta d’fhormhór na bhfearann teanga le soiléireacht agus leorgacht na faisnéise a chuirtear in iúl a chinntiú. Cé gur féidir úsáid cheart na téarmaíochta do theangacha agus d’fhearainn áirithe a bhaint amach trí chórais MT ilfheidhme a oiriúnú ar líon mór de shonraí comhthreomhara in-fhearainn, is annamh a bhíonn cainníochtaí sonraí a bhaineann go sonrach leis an bhfearann ar fáil do theangacha agus d’fhearainn nideoige is lú acmhainní. Ina theannta sin, mar atá léirithe ag COVID-19 le déanaí, níl aon sonraí comhthreomhara a bhaineann go sonrach leis an bhfearann ar fáil go héasca le haghaidh fearainn atá ag teacht chun cinn. Mar sin féin, de bharr thromchúis na tubaiste le déanaí seo bhí éileamh ard ar aistriúchán iontaofa ar fhaisnéis ríthábhachtach maidir le paindéim agus ionfhabhtú a chosc. Tá an obair seo mar chuid de WMT2021 Tasc Comhroinnte: Aistriúchán Meaisín ag baint úsáide as Téarmaíocht, áit a ndéanaimid cur síos ar chórais Tilde MT atá in ann comhtháthú dinimiciúil téarmaíochta ag am an aistriúcháin. Baineann ár gcórais suas le 94% cruinneas úsáide téarma COVID-19 amach ar thacar tástála an phéire teanga EN-FR gan rochtain a bheith acu ar aon chineál faisnéise san fhearann le linn oiliúna córais.', 'hu': 'A nyelvi területek többsége a továbbított információk egyértelműségének és megfelelőségének biztosítása érdekében a terminológia körültekintő használatát igényli. Míg bizonyos nyelvek és tartományok terminológiájának helyes használata elérhető az általános célú MT rendszerek nagy mennyiségű tartományon belüli párhuzamos adatokhoz történő hozzáigazításával, ilyen mennyiségű tartományspecifikus adat ritkán áll rendelkezésre a kevésbé erőforrásokkal rendelkező nyelvek és résidományok esetében. Továbbá, amint azt a COVID-19 példázza a közelmúltban, a feltörekvő tartományok esetében nem állnak rendelkezésre könnyen domainspecifikus párhuzamos adatok. A közelmúltbeli katasztrófa súlyossága azonban nagy igényt teremt a járvány és a fertőzések megelőzésével kapcsolatos kritikus információk megbízható fordítására. Ez a munka része a WMT201 Shared Task: Machine Translation terminológiákkal történő gépi fordításnak, ahol olyan Tilde MT rendszereket írunk le, amelyek a fordítás idején dinamikus terminológiai integrációra képesek. Rendszereink akár 94%-os COVID-19 kifejezési pontosságot érnek el az EN-FR nyelvpár tesztkészletén anélkül, hogy a rendszerképzés során bármilyen formában hozzáférnének a domain-információkhoz.', 'el': 'Οι περισσότεροι γλωσσικοί τομείς απαιτούν συνετή χρήση ορολογίας για να εξασφαλιστεί σαφήνεια και επάρκεια των μεταδιδόμενων πληροφοριών. Ενώ η ορθή χρήση ορολογίας για ορισμένες γλώσσες και τομείς μπορεί να επιτευχθεί με την προσαρμογή συστημάτων ΜΤ γενικής χρήσης σε μεγάλους όγκους παράλληλων δεδομένων εντός του τομέα, τέτοιες ποσότητες δεδομένων ειδικού τομέα σπάνια είναι διαθέσιμες για γλώσσες με λιγότερους πόρους και τομείς ειδικού τομέα. Επιπλέον, όπως αποδείχτηκε πρόσφατα από το COVID-19, κανένα παράλληλο στοιχείο για τους αναδυόμενους τομείς δεν είναι άμεσα διαθέσιμο. Ωστόσο, η σοβαρότητα αυτής της πρόσφατης καταστροφής δημιούργησε μεγάλη ζήτηση για αξιόπιστη μετάφραση κρίσιμων πληροφοριών σχετικά με την πανδημία και την πρόληψη των λοιμώξεων. Η εργασία αυτή είναι μέρος της Κοινής Εργασίας του όπου περιγράφουμε συστήματα που είναι σε θέση να ενσωματώσουν δυναμικά ορολογία κατά τη διάρκεια της μετάφρασης. Τα συστήματά μας επιτυγχάνουν έως 94% ακρίβεια χρήσης όρου στο σετ δοκιμών του γλωσσικού ζεύγους χωρίς να έχουν πρόσβαση σε οποιαδήποτε μορφή πληροφοριών εντός του τομέα κατά τη διάρκεια της εκπαίδευσης του συστήματος.', 'ka': 'უფრო მეტი ენების დიომენტების გამოყენება ჭირდება ტერმინოლოგიის გამოყენება, რომ დარწმუნოთ ინფორმაციის წარმოდგენება და მართლაობა. თუმცა ტერმინოლოგიის მარტივი გამოყენება რამდენიმე ენების და დომენების განმავლობაში შეიძლება მიიღება, როგორც სხვა ენების და დომენების განმავლობაში მნიშვნელოვანი MT სისტემების განმავლობაში დიდ დომენის პარალელი მონაცემე დამატებით, როგორც COVID-19 ახლა მომხმარებულია, კონფიგური პერალელი მონაცემები კონფიგურაციაში არაფერად მოხმარებული მონაცემებისთვის. მაგრამ ამ ბოლო კალიმატის გრავიტაცია შექმნა უფრო დიდი მოთხოვრება კრიტიკური ინფორმაციის დასაწყვება და ინფორმაციის პრეფიქციის შესახებ. ეს სამუშაო არის WMT2021 გაყოფილი სამუშაო დავალების ნაწილი: სამუშაო ტერმინოლოგიების გამოყენება, სადაც ჩვენ აღწერეთ Tilde MT სისტემი, რომელიც დინამიკური ტერმინოლოგიის ინტეგრაცი ჩვენი სისტემები 94% COVID-19 ტერმინზე გამოიყენება მართებულობა EN-FR ენის ზოგარის ტესტის შესახებ, რომელიც სისტემის სტრიქციის განმავლობაში არ აქვს პროგრამის ინფორმაციის ფორმის შე', 'lt': 'Daugumai kalbos sričių reikia apdairiai naudoti terminologiją, kad būtų užtikrintas perduotos informacijos aiškumas ir pakankamumas. Nors tinkamas terminologijos naudojimas kai kurioms kalboms ir domenams gali būti pasiektas pritaikant bendrosios paskirties MT sistemas prie didelių lygiagrečių domeno duomenų kiekių, tokie konkretiems domenams skirti duomenys retai prieinami mažiau išteklių turinčioms kalboms ir nišos domenams. Be to, kaip neseniai parodė COVID-19, naujoms sritims nėra lengvai prieinamų lygiagrečių duomenų konkrečioms sritims. Tačiau neseniai įvykusios nelaimės sunkumas sukėlė didelį poreikį patikimai išversti kritinę informaciją apie pandemijas ir infekcijų prevenciją. Šis darbas yra WMT2021 bendros užduoties dalis: mašinų vertimas naudojant terminologijas, kur apibūdinamos MT sistemos, galinčios dinamiškai integruoti terminologiją vertimo metu. Mūsų sistemos užtikrina iki 94 proc. COVID-19 termino naudojimo tikslumą EN-FR kalbos poros bandymų rinkinyje, tačiau sistemų mokymo metu neturi galimybės gauti jokios formos informacijos domene.', 'it': "La maggior parte dei settori linguistici richiede un uso prudente della terminologia per garantire chiarezza e adeguatezza delle informazioni trasmesse. Mentre l'uso corretto della terminologia per alcune lingue e domini può essere ottenuto adattando i sistemi MT di uso generale a grandi volumi di dati paralleli nel dominio, tali quantità di dati specifici del dominio sono raramente disponibili per lingue e domini di nicchia meno risorse. Inoltre, come esemplificato recentemente dal COVID-19, non sono disponibili dati paralleli specifici per domini emergenti. Tuttavia, la gravità di questa recente calamità ha creato una forte domanda di traduzione affidabile di informazioni critiche sulla pandemia e la prevenzione delle infezioni. Questo lavoro fa parte di WMT201 Shared Task: Machine Translation using Terminologies, dove descriviamo sistemi Tilde MT in grado di integrare terminologia dinamica al momento della traduzione. I nostri sistemi raggiungono fino al 94% di accuratezza nell'uso a termine COVID-19 sul set di test della coppia linguistica EN-FR senza avere accesso a alcuna forma di informazione nel dominio durante la formazione sul sistema.", 'mk': 'Повеќето јазички домени бараат внимателна употреба на терминологијата за да се осигури јасноста и соодветноста на пренесените информации. Иако правилната употреба на терминологијата за некои јазици и домени може да се постигне со адаптација на системите со генерална цел на МТ на големи количини паралелни податоци во доменот, ваквите количини податоци специфични за доменот ретко се достапни за јазици со помалку ресурси и ниши дом Покрај тоа, како што е примерено од COVID-19 неодамна, не се достапни паралелни податоци специфични за домен за нови домени. Сепак, гравитацијата на оваа неодамнешна несреќа создаде висока побарувачка за доверлив превед на критични информации во врска со пандемијата и спречувањето на инфекциите. Оваа работа е дел од WMT2021 Соделена задача: Машинска превод користејќи терминологии, каде што опишуваме МТ системи на плочи кои се способни за динамична терминолошка интеграција во времето на преводот. Нашите системи постигнуваат до 94 отсто прецизност во користењето на терминот COVID-19 на тестот на парот на EN-FR јазик без да имаат пристап до било каква форма на информации во домен за време на системската обука.', 'kk': 'Тілдердің көпшілігі терминологияның түсініктерін және мәліметтің тәуелдігін қамтамасыз ету үшін бақытты қолдану керек. Кейбір тілдер мен домендер үшін терминология дұрыс қолдану мүмкін болса, домендегі параллель деректердің үлкен томдарына жалпы MT жүйелерін адаптациялау үшін, осылай доменге арнаулы деректердің сандары жеткілікті тілдер мен нихи домендерін Қосымша, соңғы COVID- 19 дегеннің мысалы, доменге параллель деректер жасалған домендер үшін оңай жоқ. Бірақ бұл жаңа белсендіктің теңілігі пандемия және инфекцияларды сақтау үшін сенімді мәліметті аудару үшін жоғары талап етеді. Бұл жұмыс WMT2021 ортақтастырылған тапсырманың бөлігі: Терминологияларды қолданатын машинаның аударуы, оларды аудару уақытында динамикалық терминологиялық интеграциялау мүмкіндігін мүмкіндік беретін Tilde MT Біздің жүйелеріміз 94% COVID-19 терминіне жеткізеді. Жүйелік оқыту үшін кез келген домен мәліметіне қатынау үшін EN-FR тіл жиынының сынақтарында дұрыс қолданылады.', 'ml': 'മിക്കവാറും വിവരങ്ങളുടെ വ്യക്തമായ വിവരങ്ങളും ഉറപ്പ് വരുത്താന്\u200d വേണ്ടി ടെര്\u200dമിനോളജി ഉപയോഗിക്കേണ്ടി വരുന്നു. കുറച്ചു ഭാഷകള്\u200dക്കും ഡോമെന്\u200dസിനും വേണ്ടി ടെര്\u200dമിനോളജി ഉപയോഗിക്കുന്നത് ശരിയായിരിക്കുമ്പോള്\u200d ഡൊമെയിനിലെ വലിയ വിവരങ്ങളില്\u200d എംടി സിസ്റ്റമുകള്\u200d മാറ്റുന്നതിനാല്\u200d  കൂടാതെ, കോവിഡി- 19 അടുത്തുള്ള ഉദാഹരണമായി കൊടുത്തിട്ടുണ്ടെങ്കില്\u200d, പുറപ്പെടുന്ന ഡോമെന്\u200d പ്രത്യേകിച്ചുള്ള പാരാല എന്നാലും അടുത്ത ദുരന്തത്തിന്റെ ഗുരുതപ്പെടുത്തുന്നത് പാന്\u200dഡീമിക്കും infection തടസ്സപ്പെടുത്തുന്നതിനും വിശ്വസ്തമായ ഈ ജോലി WMT2021 പങ്കാളിയുള്ള പണിയില്\u200d ഒരു ഭാഗമാണ്: ടെര്\u200dമിനിലോളജികള്\u200d ഉപയോഗിച്ച് മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നത്. പരിഭാഷക്കുള്ള സമയത്ത് ടില്\u200d നമ്മുടെ സിസ്റ്റത്തില്\u200d 94% കോവിഡി-19 മെച്ചറില്\u200d പ്രയോഗിക്കുന്നത് സിസ്റ്റം പരീക്ഷണത്തില്\u200d EN-FR ഭാഷ ജോട്ടുകാരുടെ പരീക്ഷണത്തില്\u200d', 'ms': 'Kebanyakan domain bahasa memerlukan penggunaan terminologi yang bijak untuk memastikan keterangan dan keperluan maklumat yang dihantar. Walaupun penggunaan yang betul terminologi untuk beberapa bahasa dan domain boleh dicapai dengan menyesuaikan sistem MT-tujuan umum pada volum besar data selari dalam domain, kuantiti-data spesifik domain tersebut jarang tersedia untuk bahasa yang kurang sumber dan domain niche. Selain itu, sebagai contoh oleh COVID-19 baru-baru ini, tiada data selari-spesifik domain yang mudah tersedia untuk domain yang muncul. However, the gravity of this recent calamity created a high demand for reliable translation of critical information regarding pandemic and infection prevention.  Kerja ini adalah sebahagian dari Tugas Berkongsi WMT2021: Terjemahan Mesin menggunakan Terminologi, di mana kita menggambarkan sistem MT Tilde yang mampu untuk integrasi terminologi dinamik pada masa terjemahan. Sistem kita mencapai hingga 94% terma COVID-19 menggunakan ketepatan pada set ujian pasangan bahasa EN-FR tanpa mempunyai akses kepada sebarang bentuk maklumat dalam-domain semasa latihan sistem.', 'mt': 'Il-maġġoranza tad-dominji lingwistiċi jeħtieġu użu prudenti tat-terminoloġija biex tiġi żgurata ċ-ċarezza u l-adegwatezza tal-informazzjoni mogħtija. While the correct use of terminology for some languages and domains can be achieved by adapting general-purpose MT systems on large volumes of in-domain parallel data, such quantities of domain-specific data are seldom available for less-resourced languages and niche domains.  Barra minn hekk, kif eżemplat reċentement minn COVID-19, l-ebda dejta parallela speċifika għad-dominju mhi disponibbli faċilment għal dominji emerġenti. Madankollu, il-gravità ta’ din id-diżastru riċenti ħolqot domanda għolja għal traduzzjoni affidabbli ta’ informazzjoni kritika dwar il-prevenzjoni ta’ pandemija u infezzjonijiet. This work is part of WMT2021 Shared Task: Machine Translation using Terminologies, where we describe Tilde MT systems that are capable of dynamic terminology integration at the time of translation.  Is-sistemi tagħna jiksbu sa 94% tal-preċiżjoni tal-użu fit-terminu COVID-19 fuq is-sett tat-test tal-par tal-lingwa EN-FR mingħajr ma jkollhom aċċess għal kwalunkwe forma ta’ informazzjoni fid-dominju matul it-taħriġ tas-sistema.', 'no': 'Dei fleste språkdomene krev godt bruk av terminologi for å sikre klarhet og tilpassighet av informasjon som er sendt inn. Mens det rette bruken av terminologikk for nokre språk og domene kan oppnå ved å tilpassa generelle målsystemet MT på stor volum av parallelle data i domene, så mange domenespesifikke data er vanleg tilgjengelege for mindre ressurserte språk og niche domene. I tillegg er ingen domenespesifikke parallelle data lett tilgjengeleg for oppgåande domene som er brukt av COVID-19 nyleg. Tidstyrken på denne nyleg katalogen oppretta imidlertid ein høg etterspørselen for tiltruleg oversettelse av kritiske informasjon om forebygging av pandemikk og infeksjonar. Dette arbeidet er ein del av WMT2021 Delt oppgåve: Machine Translation using Terminologies, where we describe Tilde MT systems that are capable of dynamic terminology integration at the time of translation. Sistemet våre oppnår til 94 % COVID-19-uttrykk bruk nøyaktighet på testsettet av EN-FR språk par utan å ha tilgang til nokon form av informasjon i domenet under systemopplæring.', 'pl': 'Większość dziedzin językowych wymaga ostrożnego stosowania terminologii w celu zapewnienia jasności i adekwatności przekazywanych informacji. Chociaż prawidłowe wykorzystanie terminologii dla niektórych języków i domen można osiągnąć poprzez dostosowanie ogólnodostępnych systemów MT do dużych ilości danych równoległych wewnątrz domeny, takie ilości danych specyficznych dla domeny rzadko są dostępne dla języków o mniej zasobach i dziedzin niszowych. Ponadto, na przykładzie COVID-19 ostatnio, żadne dane równoległe dla domen powstających nie są łatwo dostępne. Jednak powaga tej ostatniej katastrofy stworzyła duże zapotrzebowanie na rzetelne tłumaczenie krytycznych informacji dotyczących pandemii i zapobiegania infekcjom. Praca ta jest częścią WMT2028 Shared Task: Tłumaczenie maszynowe przy użyciu terminologii, w którym opisujemy systemy Tilde MT zdolne do dynamicznej integracji terminologii w momencie tłumaczenia. Nasze systemy osiągają dokładność użytkowania terminów do 94% COVID-19 na zestawie testowym pary językowej EN-FR bez dostępu do jakiejkolwiek formy informacji wewnątrz domeny podczas szkolenia systemowego.', 'mn': 'Ихэнх хэл орон нутгийнхээ ихэнх нь мэдээллийн тодорхойлолт болон адилхан байдлыг тодорхойлдохын тулд зөвхөн терминологийг хэрэглэх шаардлагатай. Зарим хэл болон сүлжээнд томъёог зөв хэрэглэх нь томъёогоор томъёогоор томъёогоор томъёогоор томъёогоор томъёог зөв ашиглаж болно. Ийм томъёогоор тодорхой мэдээллийн хэмжээг бага ашиглаж чадахгүй хэл болон томъё Түүнчлэн, саяхан COVID-19-ын жишээ болгосон шиг тодорхойлолтой параллел өгөгдлийг шинээр гаргаж буй салбаруудын хувьд амархан хангалттай байхгүй. Гэхдээ энэ саяхан зовлонгийн таталцлын хүчирхэг нь пандемик болон халдвар халдварын сэргийлэлтийн тухай үнэмшилтэй мэдээллийн тухай үнэмшилтэй хэлбэрийг илүү их хүсэл болгосон Энэ ажлын нэг хэсэг нь WMT2021 хуваалтын ажлын нэг хэсэг: Терминологийг ашиглан машин хөгжүүлэлт, тэнд бид хөгжүүлэх үед динамик терминологийг хөгжүүлэх боломжтой Tilde MT системийг тайлбарладаг. Бидний систем COVID-19 хувь нь EN-FR хэл хоёрын туршилтын туршилтын тодорхойлолт 94 хувь хүртэл системийн сургалтын үед ямар ч хэлбэрээр мэдээлэл авч чадахгүй байдаг.', 'ro': 'Majoritatea domeniilor lingvistice necesită utilizarea prudentă a terminologiei pentru a asigura claritatea și caracterul adecvat al informațiilor transmise. În timp ce utilizarea corectă a terminologiei pentru anumite limbi și domenii poate fi realizată prin adaptarea sistemelor MT de uz general la volume mari de date paralele în domeniu, astfel de cantități de date specifice domeniului sunt rareori disponibile pentru limbi și domenii de nișă mai puțin resurse. În plus, după cum exemplifică recent COVID-19, nu există date paralele specifice domeniilor pentru domeniile emergente. Cu toate acestea, gravitatea acestei calamități recente a creat o cerere ridicată de traducere fiabilă a informațiilor critice referitoare la pandemie și prevenirea infecțiilor. Această lucrare face parte din WMT201 Shared Task: Machine Translation folosind terminologii, unde descriem sistemele Tilde MT capabile de integrare terminologică dinamică în momentul traducerii. Sistemele noastre obțin o precizie de până la 94% a utilizării termenului COVID-19 pe setul de testare al perechii de limbi EN-FR fără a avea acces la orice formă de informații în domeniu în timpul instruirii sistemului.', 'so': 'Degmooyinka luqada intooda badan waxay u baahan yihiin isticmaalka terminologi si caqli ah si ay u caddeyso iyo si ku filan macluumaadka loo soo bandhigayo. Inta lagu sameeyo isticmaalka terminology si saxda ah ee luuqadaha qaarkood iyo deegaanka qaarkood waxaa laga heli karaa in lagu beddelo nidaamka caadiga ah ee MT oo ku saabsan macluumaad faa’iido badan oo gudaha ku qoran, qiyaastii gaarka ah ee gudaha waxaa si yar looga heli karaa luuqadaha aan wax ku filnayn iyo meelaha lagu barto. Furthermore, sida tusaale ahaan ugu dhowaan COVID-19, uma heli karo macluumaad gaar ah oo degmooyinka soo baxa. However, the gravity of this recent calamity created a high demand for reliable translation of critical information regarding pandemic and infection prevention.  Shaqadaasu waa qayb ka mid ah Shaqada loo sharciyey WMT2021: Shaqada lagu turjumo machine turjumista isticmaalka Terminologies, kaas oo aynu ku qoraynaa nidaamka Tilde MT ee awoodda la qabsashada terminology xilliga turjumaadda. nidaamkayagu waxay gaadhaan ilaa 94% COVID-19 waxey isticmaali karaan si saxda ah marka lagu jiro imtixaanka labada luqada EN-FR oo aan helin nooca macluumaadka internetka xilliga waxbarashada nidaamka.', 'sr': 'Većina jezičkih domena zahteva pruženu upotrebu terminologije kako bi se osigurala jasnost i adekvatnost prenesenih informacija. Iako je ispravna upotreba terminologije za neke jezike i domene postignuta prilagođavajući generalne MT sisteme na velike volume paralelnih podataka u domenu, takve količine podataka specifičnih domena retko su dostupne za manje resursnih jezika i niche domena. Osim toga, kao primjer COVID-19 nedavno, nema paralelnih podataka za domene koje su specifične na domenu lako dostupne za nove domene. Međutim, gravitacija ovog nedavnog katastrofa stvorila je visok zahtev za pouzdan prevod kritičnih informacija o prevenciji pandemije i infekcije. Ovaj rad je deo delova WMT2021 zajedničkog zadatka: prevod mašine koristeći terminologije, gde opisujemo sisteme Tilde MT-a koji su sposobni dinamičnoj integraciji terminologije u vreme prevoda. Naši sustavi postižu do 94% COVID-19 termina upotrebe tačnosti na testovom setu EN-FR jezičkog parova bez pristupa bilo kojoj formi informacija u domenu tijekom treninga sistema.', 'si': 'භාෂාව ප්\u200dරමාණයේ බොහෝම භාෂාව ප්\u200dරයෝජනය අවශ්\u200dය වෙන්න පුළුවන් විදිහට අවශ්\u200dය විදිහට පරීක්ෂණය සමහර භාෂාවක් සහ ඩෝමේන්ස් වලට වර්තනය භාවිතාවක් සඳහා සාමාන්\u200dය-අරමුණ MT පද්ධතිය සමාන්\u200dය විශාල දත්ත සඳහා ලොකු විශාල දත්ත සඳහා සමාන්\u200dය විශ ඊට පස්සේ, COVID-19 නිර්මාණය වෙනුවෙන් නිර්මාණය කරලා තියෙන්නේ නැති ඩොමේන් වලට ප්\u200dරවෘත්ති වෙනුවෙන් ප්\u200dරවේශය නමුත්, මේ අලුත් අනතුරු අනතුරේ ග්\u200dරාවිත්තාවය නිර්මාණය කරන්න පුළුවන් විශ්වාසිත තොරතුරු ගැන විශ්වාස මේ වැඩේ WMT2021 සමාගත වැඩේ කොටසක්: වර්මිනෝලෝගිය භාවිත කරන්න මැෂින් පරිවර්තනය, තැන අපි ටිල්ඩ් MT පද්ධතිය විවෘත කරන්න පුළුව අපේ පද්ධතියේ ප්\u200dරමාණය 94% COVID-19 වර්තනය ප්\u200dරයෝජනය කරන්න පුළුවන් පරීක්ෂණයේ විශ්වාස කරන්නේ EN FR භාෂා ජෝඩාවේ පරීක්ෂණයේ සැ', 'sv': 'De flesta språkområden kräver en försiktig användning av terminologin för att säkerställa tydlighet och tillräcklig information. Även om en korrekt användning av terminologin för vissa språk och domäner kan uppnås genom att man anpassar MT-system för allmänna ändamål på stora volymer parallella data inom domänen, finns sådana mängder domänspecifika data sällan tillgängliga för språk med mindre resurser och nischdomäner. Dessutom finns inga domänspecifika parallella data tillgängliga för nya domäner, vilket COVID-19 nyligen illustrerade. Men allvarligheten av denna nyligen inträffade katastrof skapade en hög efterfrågan på tillförlitlig översättning av viktig information om pandemi och infektionsförebyggande. Detta arbete är en del av WMT201 Shared Task: Machine Translation using Terminologies, där vi beskriver Tilde MT-system som är kapabla till dynamisk terminologiintegration vid tidpunkten för översättning. Våra system uppnår upp till 94% COVID-19 termanvändning noggrannhet på testuppsättningen av språkparet EN-FR utan att ha tillgång till någon form av information inom domänen under systemutbildning.', 'ta': 'மொழி தளங்களில் பெரும்பாலானவர் செய்யப்பட்ட தகவல் தெளிவாகவும் சரியான பயன்படுத்த வேண்டும். சில மொழிகளுக்கும் களங்களுக்கும் சரியான முனையம் பயன்படுத்தல் பொதுவான MT அமைப்புகளை களம் இணைப்பு தரவுகளின் பெரிய அளவுகளில் ஏற்படுத்த முடியும் அதற்கு மேலும், COVID-19 சமீபத்தில் குறிப்பிட்ட இணைப்பு தரவு எளிதாக வரும் களங்களுக்கு கிடைக்கவில்லை. ஆனால், இந்த அண்மையில் இந்த துன்பத்தின் புவிஈர்ப்பு துன்பம் மற்றும் பாதிப்பு தடுப்பு பற்றிய மொழிபெயர்ப்பு தகவல் WMT2021 பகிர்ந்த பணியின் பகுதியில் இந்த வேலை: மொழிபெயர்ப்பு மொழிபெயர்ப்பு மொழிபெயர்ப்பு, மொழிபெயர்ப்பின் நேரத்தில் டில்டி MT அமைப்புகளை வ எங்கள் அமைப்புகள் 94% COVID-19 முறை பயன்படுத்தும் கணினி பயிற்சியில் எந்த வடிவமைப்பில் உள்ள தகவலை அணுகாமல் EN-FR மொழி ஜோடி சோதனையின் சரியான வ', 'ur': 'زبان کے اکثریت ڈمین کو ترمینلوژی کے مطابق واضح اور مطابق اطلاعات کے مطابق استعمال کرنے کی ضرورت ہے. While the correct use of terminology for some languages and domains can be achieved by adapting general-purpose MT systems on large volumes of domain parallel data, such quantities of domain-specific data rarely available for less-resourced languages and niche domains. اس کے علاوہ، جو COVID-19 نے اچھے وقت کی مثال دی ہے، کوئی ڈومین خاص پارالی ڈاٹی نہیں ہے جو اگلے ڈومین کے لئے آسانی طرح موجود ہے. However, this recent calamity gravity created a high demand for reliable translation of critical information about pandemic and infection prevention. یہ کام WMT2021 Shared Task کی حصہ ہے: Terminologies کے مطابق ماشین ترجمہ، جہاں ہم ٹیلڈ مٹی سیسٹم کو توصیف کرتے ہیں جو ترجمہ کے وقت تکامل ٹریمولوژیکوں کی ترجمہ کے قابل ہیں. ہمارے سیستموں کو 94% COVID-19 کلمات تک پہنچ سکتے ہیں کہ ان کی آزمائش کے لئے EN-FR زبان جوڑوں کی جڑ کی امتحان پر دقیق استعمال کریں بغیر اس کے کہ سیستموں کی آموزش کے وقت کسی طرح کے دامین معلومات کی دسترسی نہ کریں۔', 'uz': "Ko'pchilik tillar domenalari koʻrsatilgan maʼlumot haqida taqlash uchun terminologiya ishlatish kerak. @ info: whatsthis Keyingi soʻzda, COVID-19 yordamida misol qilingan, kelayotgan domen- specific parallel maʼlumot oddiy mavjud emas. Hozirda, bu yerda eng katta bo'lgan hayoti pandemik va infeksiz prevention haqida muhim maʼlumotni tarjima qilish uchun juda muhim talab qiladi. @ info Bizning tizimlarimiz tizimga tizim taʼminlovchi vaqtda hech qanday foydalanuvchi bo'lmaydi EN-FR tilning tizimini sinov qilish uchun 94% COVID-19 tilga foydalanadi.", 'vi': 'Hầu hết các lĩnh vực ngôn ngữ cần thận trọng sử dụng các thuật ngữ để đảm bảo sự rõ ràng và đủ số thông tin được truyền đi. Tuy có thể sử dụng đúng thuật ngữ cho một số ngôn ngữ và miền có thể được thực hiện bằng cách sửa đổi hệ thống MTV chung với một số lượng lớn dữ liệu song song lập trong miền, nhưng lượng dữ liệu đặc biệt miền hiếm khi có thể cung cấp cho những ngôn ngữ và khu vực liên kết ít nguồn. Hơn nữa, như COVID-19 cũng gần đây đã điển hình, không có dữ liệu song nào sẵn sàng cho các miền mới nổi lên cả. Sự nghiêm trọng của tai họa gần đây đã tạo ra một yêu cầu đáng tin cậy cho dịch chuyển thông tin quan trọng về bệnh dịch bệnh lây lan và chống nhiễm. Việc này là một phần của công việc chia sẻ của WMC2: Dịch cỗ máy bằng các mặt mẹ, nơi chúng tôi mô tả hệ thống giao hoà Lát-xu có khả năng cấu kết các thuật ngữ vận động vào thời điểm dịch chuyển. Hệ thống của chúng tôi đạt đến 94=$COVID-19 độ chính xác sử dụng trong vòng kiểm tra của đôi ngôn ngữ kiểu cất giữ một người không có quyền truy cập vào bất kỳ dạng nào trong lĩnh vực thông tin trong suốt quá trình đào tạo hệ thống.', 'bg': 'По-голямата част от езиковите области изискват разумно използване на терминологията, за да се гарантира яснота и адекватност на предаваната информация. Въпреки че правилното използване на терминологията за някои езици и области може да бъде постигнато чрез адаптиране на системите с общо предназначение за МТ на големи обеми паралелни в областта данни, такива количества специфични за областта данни рядко са налични за езици с по-малко ресурси и нишови области. Освен това, както напоследък показа COVID-19, за нововъзникващите домейни няма лесно налични паралелни данни, специфични за домейна. Тежестта на това неотдавнашно бедствие обаче създаде голямо търсене на надежден превод на критична информация относно пандемията и превенцията на инфекции. Тази работа е част от Споделена задача: Машинен превод с терминологии, в която описваме системи, способни на динамична терминологична интеграция по време на превода. Нашите системи постигат до 94% точност на използване на термини на тестовия комплект на езиковата двойка без да имат достъп до каквато и да е форма на вътрешна информация по време на системното обучение.', 'da': 'De fleste sprogområder kræver forsigtig brug af terminologi for at sikre klarhed og tilstrækkelighed af de videregivede oplysninger. Mens den korrekte brug af terminologi for nogle sprog og domæner kan opnås ved at tilpasse generelle MT-systemer til store mængder parallelle data inden for domænet, er sådanne mængder domænespecifikke data sjældent tilgængelige for mindre ressourcer sprog og nichedomæner. Desuden er der ingen domænespecifikke parallelle data let tilgængelige for nye domæner, som COVID-19 eksempler på for nylig. Men alvorligheden af denne nylige katastrofe skabte en høj efterspørgsel efter pålidelig oversættelse af kritiske oplysninger om pandemi og infektionsforebyggelse. Dette arbejde er en del af WMT201 Shared Task: Machine Translation via Terminologier, hvor vi beskriver Tilde MT-systemer, der er i stand til dynamisk terminologiintegration på oversættelsestidspunktet. Vores systemer opnår op til 94% COVID-19 termbrugsnøjagtighed på testsættet af sprogparret EN-FR uden at have adgang til nogen form for information inden for domænet under systemtræning.', 'nl': 'De meeste taaldomeinen vereisen een verstandig gebruik van terminologie om duidelijkheid en adequaatheid van de verstrekte informatie te waarborgen. Hoewel het juiste gebruik van terminologie voor sommige talen en domeinen kan worden bereikt door algemene MT-systemen aan te passen op grote volumes parallelle gegevens in het domein, zijn dergelijke hoeveelheden domeinspecifieke gegevens zelden beschikbaar voor talen met minder middelen en nichedomeinen. Bovendien zijn, zoals recent door COVID-19 is gebleken, geen domeinspecifieke parallelle gegevens beschikbaar voor opkomende domeinen. De ernst van deze recente calamiteit zorgde echter voor een grote vraag naar betrouwbare vertaling van kritische informatie over pandemie en infectiepreventie. Dit werk maakt deel uit van WMT2028 Shared Task: Machine Translation using Terminologies, waar we Tilde MT systemen beschrijven die in staat zijn om dynamische terminologie integratie op het moment van vertaling. Onze systemen bereiken tot 94% COVID-19 termijngebruiksnauwkeurigheid op de testset van het EN-FR taalpaar zonder toegang te hebben tot enige vorm van in-domein informatie tijdens systeemtraining.', 'hr': 'Većina jezičkih domena zahtijeva pruženu primjenu terminologije kako bi se osigurala jasnost i odgovarajuća prijavljena informacija. Iako se ispravna upotreba terminologije za neke jezike i domene može postići prilagođavanjem visokog cilja MT sustava na velike volume paralelnih podataka u domenu, takve količine podataka specifičnih domena rijetko su dostupne za manje resursnih jezika i niche domena. Osim toga, kao primjer COVID-19 nedavno, nije dostupan paralelni podaci specifičnih domena za nove domene. Međutim, gravitacija ovog nedavnog katastrofa stvorila je visok zahtjev za pouzdan prevod kritičnih informacija o prevenciji pandemije i infekcije. Ovaj rad je dio zajedničkog zadatka WMT2021: prevod strojeva koristeći terminologije, gdje opisujemo sisteme Tilde MT-a koje su sposobne za dinamičnu integraciju terminologije u vrijeme prevoda. Naši sustavi postignu do 94% COVID-19 termina upotrebe preciznosti na testu kompleta EN-FR jezičkog parova bez pristupa bilo kojem obliku informacija u domenu tijekom obuke sustava.', 'de': 'Die meisten Sprachbereiche erfordern eine umsichtige Terminologie, um Klarheit und Angemessenheit der vermittelten Informationen zu gewährleisten. Während die korrekte Verwendung der Terminologie für einige Sprachen und Domänen erreicht werden kann, indem universelle MÜ-Systeme auf große Mengen von parallelen In-Domain-Daten angepasst werden, sind solche Mengen domänenspezifischer Daten selten für Sprachen mit weniger Ressourcen und Nischendomänen verfügbar. Darüber hinaus sind, wie kürzlich COVID-19 gezeigt hat, für neu entstehende Domains keine domänenspezifischen parallelen Daten verfügbar. Die Schwere dieser jüngsten Katastrophe hat jedoch einen hohen Bedarf an zuverlässiger Übersetzung kritischer Informationen zur Pandemie- und Infektionsprävention verursacht. Diese Arbeit ist Teil von WMT2028 Shared Task: Machine Translation using Terminologies, wo wir Tilde MT-Systeme beschreiben, die zum Zeitpunkt der Übersetzung eine dynamische Terminologieentegration ermöglichen. Unsere Systeme erreichen bis zu 94% COVID-19 Term Use Genauigkeit auf dem Testset des EN-FR Sprachpaares, ohne während des Systemtrainings Zugriff auf jegliche Form von In-Domain-Informationen zu haben.', 'sw': 'Wengi wa maeneo ya lugha yanahitaji matumizi ya ukatili kwa ufanisi ili kuhakikisha ufanisi na usahihi wa taarifa zilizotangazwa. Wakati matumizi sahihi ya utamaduni kwa baadhi ya lugha na maeneo yanaweza kupatikana kwa kubadilisha mfumo wa MT kwa lengo la jumla kwenye kiasi kikubwa cha data za usambazaji wa ndani, kiasi hiki cha data maalum za ndani ni chache kinapatikana kwa lugha zisizo rasilimali na maeneo mazuri. Zaidi, kama ilivyo kwa mfano na COVID-19 hivi karibuni, hakuna taarifa maalum za ndani zinazofanana kwa urahisi kwa ajili ya maeneo yanayotokea. Hata hivyo, umuhimu wa janga hili la hivi karibuni ulitengeneza mahitaji makubwa ya kutafsiri taarifa muhimu kuhusu kuzuia ugonjwa na maambukizi. Kazi hii ni sehemu ya kazi inayoshirikishwa na WMT2021: Tafsiri ya Mashine kwa kutumia Terminalologies, ambapo tunaelezea mfumo wa Tilde MT ambao una uwezo wa kuunganisha kwa ajili ya kutafsiri utaratibu. Mfumo wetu unafikia kufikia asilimia 94 ya ukomo wa muhula wa COVID-19 hutumia uhakika kuhusu mfumo wa jaribio la wawili wa lugha ya EN-FR bila kuwa na upatikanaji wa aina yoyote ya taarifa za ndani wakati wa mafunzo ya mfumo.', 'ko': '대부분의 언어 분야는 전달된 정보의 명확성과 충분성을 확보하기 위해 용어를 신중하게 사용해야 한다.대량의 역내 병행 데이터에서 유니버설 기계 번역 시스템을 조정하여 특정 언어와 분야의 용어를 정확하게 사용할 수 있으나 자원이 비교적 적은 언어와 특정 분야에 대해서는 이런 특정 분야의 데이터를 사용할 수 없다.또한 코로나-19의 최근 사례와 같이 신흥분야에 적용할 수 있는 특정 영역의 평행 데이터는 없다.그러나 최근 이 재난의 심각성 때문에 사람들은 대유행과 감염 예방에 관한 관건적인 정보의 믿을 만한 번역에 대해 높은 요구를 제기했다.이 작업은 WMT2021 공유 작업의 일부입니다. 용어를 사용하는 기계 번역입니다. 우리는 번역할 때 용어를 동적으로 집적할 수 있는 Tilde 기계 번역 시스템을 설명합니다.우리 시스템은 EN-FR 언어 쌍의 테스트 세트에서 94%의 코로나 용어 사용 정확도를 실현하였으며, 시스템 교육 기간에는 어떤 형태의 도메인 정보도 접근할 수 없습니다.', 'id': 'Kebanyakan daerah bahasa membutuhkan penggunaan terminologi yang bijaksana untuk memastikan jelas dan keperluan informasi yang dikirim. Meskipun penggunaan terminologi yang benar untuk beberapa bahasa dan domain dapat dicapai dengan menyesuaikan sistem MT tujuan umum pada volum besar data paralel dalam domain, jumlah data spesifik domain tersebut jarang tersedia untuk bahasa yang kurang sumber daya dan domain niche. Selain itu, seperti contoh COVID-19 baru-baru ini, tidak ada data paralel spesifik domain yang mudah tersedia untuk domain yang muncul. Namun, gravitasi bencana ini baru-baru ini menciptakan permintaan tinggi untuk terjemahan yang dapat dipercaya informasi kritis mengenai pandemia dan prevensi infeksi. Pekerjaan ini merupakan bagian dari WMT2021 Shared Task: Machine Translation menggunakan Terminologies, di mana kita menggambarkan Tilde MT sistem yang mampu untuk integrasi terminologi dinamik pada waktu terjemahan. Sistem kita mencapai hingga 94% COVID-19 istilah menggunakan akurasi pada set tes sepasang bahasa EN-FR tanpa memiliki akses ke apa pun bentuk informasi dalam domain selama latihan sistem.', 'fa': 'بیشتر دامنهای زبان نیاز دارند که استفاده از ترمینالوژی با عقل باشند تا مطمئن شوند که واضح و قابلیت اطلاعات منتقل شده باشند. در حالی که استفاده درست از ترمینالوژی برای بعضی زبان و دامنه\u200cها می\u200cتواند با توجه به سیستم\u200cهای MT عمومی بر طبقه\u200cهای بزرگ از داده\u200cهای parallel در دامنه\u200cهای دامنه\u200cای موجود باشد، چنین اندازه داده\u200cهای ویژه\u200cهای دامنه\u200cای کمتر برای زبان\u200cهای کمتری منابع و دامنه علاوه بر این، همان طور که اخیرا توسط COVID-19 مثال داده شده است، هیچ داده\u200cای مشابه\u200cای برای دامنه\u200cهای پیدا نمی\u200cشود آسان. با این حال، گرانش این آسیب اخیر نیازی بالا برای ترجمه قابل اعتماد اطلاعات سنگینی در مورد جلوگیری پاندمیک و عفونت ایجاد کرد. این کار بخشی از کار مشترک WMT2021 است: ترجمه ماشین با استفاده از Terminologies، جایی که سیستم\u200cهای Tilde MT را توصیف می\u200cکنیم که در زمان ترجمه قادر به ترمینالوژی دینامیک هستند. سیستم\u200cهای ما تا 94 درصد کلمه COVID-19 استفاده از دقیق استفاده می\u200cکنند در مجموعه آزمایش جفت زبان EN-FR بدون دسترسی به هیچ شکل اطلاعات در دامنی در طول تمرین سیستم.', 'af': "Die meeste van taal domeine benodig verstandige gebruik van terminologie om klariteit en adekuateit van inligting uitgelei te verseker. Alhoewel die korrekte gebruik van terminologie vir sommige tale en domeine kan word bereik deur algemene-doel MT stelsels op groot volume van in-domein parallele data te pas, sodanige hoeveelheid domein-spesifieke data is selfs beskikbaar vir minder-hulpbron tale en niche domeine. Verder, soos voorbeeld deur COVID-19 onlangs, is geen domein-spesifieke parallele data leeg beskikbaar vir opkomstige domeine nie. Maar die graviteit van hierdie onlangse kaliteit het 'n hoë versoek gemaak vir betroubare vertaling van kritiese inligting aangaande pandemie en infeksie voorkoms. Hierdie werk is deel van WMT2021 Gedeelde Opdrag: Masjien Vertaling gebruik Terminologies, waar ons beskrywe Tilde MT stelsels wat in staat is van dinamiese terminologie integrasie by die tyd van vertaling. Ons stelsels bereik tot 94% COVID-19 termyn waarskynlik gebruik op die toets stel van die EN-FR taal paar sonder om toegang te kry tot enige vorm van in-domein inligting tydens stelsel oefening.", 'tr': 'Diller köp sahypalarynyň belli we ýerleşmegi mümkin etmek üçin terminologiýanyň düşünjeli ulanmasyny gerek. Käbir diller we domaýlar üçin terminologiýanyň dogry ulanmagy mümkin bir maksady MT sistemlerini domain parallel maglumatynyň uly хэлбätlerinde üýtgetmek üçin ýetip biler, şol bolsa domyň spesifik maglumatynyň sanlary azajyk geýtgeden diller we domaýlar üçin ýeterlik bar. Daha soňra, COVID-19 tarapyndan eserlenýän ýaly, köpürüş sahypalar üçin hiç hili domenyň esasy parallel maglumatlary ýeterli däl. Ýagna görä bu soňky calamyň çykyşlygyny pandemik we hasaplanjak önümlemesi barada ynamly maglumatlaryň terjime etmesi üçin ýokary uly talep etdi. Bu işi WMT2021 Beýleki Göreviň bir bölümidir: Terminologiýalary ulanan maşynyň terjime edilmesinde dinamik terjime edip biljek Tilde MT sistemlerini tasvir edip bilýäris. Bizim sistemlerimiz sistem öwrenmesi wagtynda EN-FR dil çiftiniň barlamasynda 94% COVID-19 termyna çenli dogrylyk bar.', 'am': 'አብዛኞቹ የቋንቋዎች ድምጾች ማስታወቂያውን እና ማስታወቂያውን ለማረጋገጥ በቋንቋዎች ውስጥ ማስታወቂያ እንዲጠይቁ ያስፈልጋል፡፡ ምንም እንኳን ለአንዳንዶች ቋንቋዎች እና ዶሜኖቹ የተግባር ተርሚኖሎጂ በመጠቀም የጠቅላላ-አቃውሞ MT-ስርዓቶች በዶሜን በተለይ ዳታ በመጠቀም ይችላል፡፡ ከዚህም በኋላ፣ COVID-19 እንደምሳሌ፣ በአሁኑ ጊዜ ለመውጣት አዲስ ዶሜን-የተለየ ምርጫዎች ዳታ አይገኙም፡፡ ነገር ግን የዚህ የቀድሞው ጉዳት ውርደት በጭንቀት እና የደዌብ መግለጫ ላይ የሚታመን የዝርዝር መረጃዎችን ለመግለጥ እጅግ የሚያስፈልገውን ጥያቄ አቀረበ፡፡ ይሄ ሥራ WMT2021 የተሰራጨው ስራ: የመኪን ትርጉም በተርሚናሎጂዎች በተጠቃሚ ትርጉም ነው፤ በተርጓሚው ጊዜ የሚችሉትን Tilde MT ስርዓቶች እናሳውቃለን፡፡ ሲስተምሮቻችን የEN-FR ቋንቋ ሁለትን በተፈተና ላይ ቁጥር 94 በመቶ COVID-19 የሚደርሱ ናቸው፡፡', 'sq': 'Shumica e domeneve gjuhësore kërkojnë përdorim të kujdesshëm të terminologjisë për të siguruar qartësinë dhe përshtatshmërinë e informacionit të transmetuar. Ndërsa përdorimi i saktë i terminologjisë për disa gjuhë dhe domene mund të arrihet duke përshtatur sistemet MT me qëllim të përgjithshëm në volume të mëdha të të dhënave paralele në domeni, sasi të tilla të dhënash specifike në domeni janë rrallë në dispozicion për gjuhë me më pak burime dhe domene niche. Përveç kësaj, siç shembulloi COVID-19 kohët e fundit, nuk ka të dhëna paralele specifike për domenin që janë në dispozicion lehtë për domenat në rritje. Megjithatë, graviteti i kësaj katastrofe të fundit krijoi një kërkesë të lartë për përkthimin e besueshëm të informacionit kritik lidhur me pandemikën dhe parandalimin e infeksionit. Ky punë është pjesë e WMT2021 Task Shared: Machine Translation duke përdorur Terminologies, ku ne përshkruajmë Tilde MT sistemet që janë në gjendje të integrimit dinamik të terminologjisë në kohën e përkthimit. Sistemet tona arrijnë deri në 94% të saktësisë së përdorimit të afatit COVID-19 në grupin e testimeve të çiftit gjuhësor EN-FR pa pasur akses në ndonjë form ë informacioni në domeni gjatë trajnimit të sistemit.', 'bn': 'সংখ্যাগরিষ্ঠ ভাষার ডোমেনের সংখ্যাগরিষ্ঠ ভাষার সংখ্যাগরিষ্ঠ তথ্য যুক্ত করার জন্য বুদ্ধিমান ব্যবহারের প্রয়োজন যদিও কিছু ভাষা এবং ডোমেনের জন্য সঠিক ভাষায় টার্মিনোলজি ব্যবহার করা সম্ভব হতে পারে সাধারণ উদ্দেশ্য এমটি সিস্টেমের মাধ্যমে ডোমেইনের প্যারালেল ডাটার মাধ্যমে প্রতিষ্ঠি এছাড়াও, সম্প্রতি কভিড-১৯ এর উদাহরণ হিসেবে উপস্থাপন করেছে, উদ্ভাবনের জন্য কোন ডোমেইন-নির্দিষ্ট পারালেল ডাটা সহজে পাওয়া যায় তবে সাম্প্রতিক দুর্যোগের গুরুত্বপূর্ণ দাবি তৈরি করেছে দুর্ভোগ এবং আক্রান্ত প্রতিরোধ সম্পর্কে সমালোচনার তথ্য সম্ এই কাজ হচ্ছে WMT2021 ভাগাভাগি করা কাজের অংশ: টার্মিনোলজি ব্যবহার করে মেশিন অনুবাদ, যেখানে আমরা টিল্ডে এমটি সিস্টেম বর্ণনা করি যা অনুবাদের সময় ক্ষমতাশ Our systems achieve up to 94% COVID-19 term use accuracy on the test set of the EN-FR language pair without having access to any form of in-domain information during system training.', 'hy': 'The majority of language domains require prudent use of terminology to ensure clarity and adequacy of information conveyed.  Մինչդեռ որոշ լեզուներում և բնագավառներում տերմինոլոգիայի ճիշտ օգտագործումը հնարավոր է հասնել ընդհանուր նպատակի MT համակարգերի հարմարեցման միջոցով բնագավառներում գտնվող զուգահեռ տվյալների մեծ ծավալների վրա, բնագավառներում նման տվյալներ հազվադե Ավելին, ինչպես օրինակում է COVID-19-ը վերջերս, նոր տիեզերքների համար անմիջապես հասանելի չեն որևէ տիեզերական զուգահեռ տվյալներ: Այնուամենայնիվ, այս վերջին աղետի ծանրությունը ստեղծեց բարձր պահանջը վստահելի թարգմանման կարևոր տեղեկությունների վերաբերյալ պանդեմիայի և վարակների կանխարգելու մասին: Այս աշխատանքը ԱՄԹ2021-ի ընդհանուր հանձնարարության մասն է. մեքենայի թարգմանություն տերմինոլոգիաների միջոցով, որտեղ մենք նկարագրում ենք Թիլդ ՄԹ համակարգեր, որոնք կարողանում են դինամիկ տերմինոլոգիայի ինտեգրացիա թարգմանման ժամանակ Մեր համակարգերը հասնում են մինչև 94 տոկոսի COVID-19 տերմին օգտագործելու ճշգրիտությունը այն լեզվի զույգի փորձարկումների վրա, առանց որևէ տիեզերական ինֆորմացիայի հասանելիության ունենալու համակարգի ուսումնասիրության ընթացքում:', 'ca': "La majoria dels dominis lingüístics requereixen un ús prudent de la terminologia per assegurar la claretat i adequació de la informació transmitida. Mentre que l'ús correcte de la terminologia per algunes llengües i dominys es pot aconseguir adaptant els sistemes MT de propòsit general en grans volums de dades paralleles en dominys, aquestes quantitats de dades específices per dominys rarament estan disponibles per llengües amb menys recursos i dominys nichos. A més, com ha estat exemplificat recentment en COVID-19, no hi ha dades paralleles específices per dominis fàcilment disponibles per dominis emergents. No obstant això, la gravetat d'aquesta calamitat recent va crear una gran demand a de traducció fiable d'informació crítica sobre la prevenció de pandèmies i infeccions. This work is part of WMT2021 Shared Task: Machine Translation using Terminologies, where we describe Tilde MT systems that are capable of dynamic terminology integration at the time of translation.  Els nostres sistemes aconsegueixen fins al 94% de la precisió del terme COVID-19 en el conjunt de proves del parell de llenguatges EN-FR sense tenir accés a cap forma d'informació en domini durant l'entrenament del sistema.", 'az': 'Dil sahələrinin əksəriyyəti bildirilmiş məlumatların açıq-aydınlığını və uyğunluğunu təsdiqlənmək üçün terminoloji istifadə etməsi lazımdır. Bazı dillər və domenalar üçün terminologiyanın düzgün istifadəsi olaraq, domenalı paralel məlumatların böyük volumlarında genel məqsədil MT sistemlərini adapt edərək, böyük domain məlumatlarının müəyyən sayıları çox az ressurslı dillər və niche domenalar üçün faydalanır. Daha sonra, COVID-19 ilə müəyyən etdiyi kimi, yenidən gələn domenalar üçün heç bir domena müəyyən paralel məlumat asanlıqla faydalanmaz. Ancaq bu son xəstəliyin çətinlikləri pandemik və infeksiya önlənməsi haqqında güvenilir məlumatların təkrarlanması üçün yüksək tələb etdi. Bu işin WMT2021 paylaşılan işin bir parçasıdır: Tərcümə vaxtında dinamik terminoloji integrasiya yetişə bilən Tilde MT sistemlərini təsdiqləyirik. Sistemlərimiz, sistem təhsilində heç bir dəyişiklik məlumatlarına istifadə etmədən, EN-FR dil çiftərinin sınamasında 94% COVID-19 term istifadə edilməsi üçün istifadə edilir.', 'bs': 'Većina jezičkih domena zahtijeva pruženu upotrebu terminologije kako bi se osigurala jasnost i adekvatnost prenesenih informacija. Iako se prava upotreba terminologije za neke jezike i domene može postići prilagođenjem generalnih MT sustava na velike volume paralelnih podataka u domenu, takve količine podataka specifičnih domena rijetko su dostupne za manje resursnih jezika i niche domena. Osim toga, kao primjer COVID-19 nedavno, nema paralelnih podataka na domenu koji su specifični za izražavanje domena lako dostupni. Međutim, gravitacija ovog nedavnog katastrofa stvorila je visok zahtjev za pouzdan prevod kritičnih informacija o prevenciji pandemije i infekcije. Ovaj rad je dio delova WMT2021 zajedničkog zadatka: prevod mašine koristeći terminologije, gdje opisujemo sisteme Tilde MT-a koje su sposobne za dinamičku integraciju terminologije u vrijeme prevoda. Naši sustavi postignu do 94% COVID-19 termina upotrebe preciznosti na testnom setu EN-FR jezičkog parova bez pristupa bilo kojoj formi informacija u domenu tijekom treninga sustava.', 'cs': 'Většina jazykových oblastí vyžaduje obezřetné používání terminologie k zajištění jasnosti a přiměřenosti předávaných informací. Zatímco správného použití terminologie pro některé jazyky a domény lze dosáhnout adaptací univerzálních MT systémů na velké množství paralelních dat v doméně, takové množství dat specifických pro doménu jsou zřídka k dispozici pro jazyky s menšími zdroji a niche domény. Kromě toho, jak bylo v poslední době ukázáno COVID-19, nejsou pro vznikající domény snadno dostupná paralelní data specifická pro doménu. Závažnost této nedávné katastrofy však vyvolala vysokou poptávku po spolehlivém překladu kritických informací týkajících se pandemie a prevence infekcí. Tato práce je součástí WMT2028 Shared Task: Strojový překlad pomocí terminologií, kde popisujeme systémy Tilde MT schopné dynamické integrace terminologie v době překladu. Naše systémy dosahují až 94% přesnosti použití termínu COVID-19 na testovací sadě jazykového páru EN-FR bez přístupu k jakékoliv formě informací v doméně během systémového školení.', 'et': 'Enamik keelevaldkondi vajab mõistlikku terminoloogia kasutamist, et tagada edastatava teabe selgus ja piisavus. Kuigi mõnede keelte ja valdkondade terminoloogia õiget kasutamist on võimalik saavutada, kohandades üldeesmärgilisi MT-süsteeme suurte koguste valdkonnasiseste paralleelsete andmete puhul, on sellised valdkonnaspetsiifilised andmed harva kättesaadavad vähem ressurssidega keelte ja nišivaldkondade puhul. Lisaks sellele, nagu näitab hiljuti COVID-19, ei ole arenevate domeenide kohta kergesti kättesaadavad domeenispetsiifilised paralleelsed andmed. Hiljutise õnnetuse tõsidus aga tekitas suure nõudluse pandeemiat ja nakkuste ennetamist käsitleva kriitilise teabe usaldusväärse tõlkimise järele. Käesolev töö on osa WMT22021 Shared Task: Machine Translation using Terminologies, kus kirjeldame Tilde MT süsteeme, mis on võimelised dünaamiliseks terminoloogia integratsiooniks tõlkimise ajal. Meie süsteemid saavutavad kuni 94% COVID-19 termini kasutamise täpsuse EN-FR keelepaari testikomplektis, ilma et neil oleks süsteemi koolituse ajal juurdepääs mis tahes domeenisisesele teabele.', 'fi': 'Suurin osa kielialueista edellyttää terminologian varovaista käyttöä, jotta voidaan varmistaa välitetyn tiedon selkeys ja riittävyys. Vaikka terminologian oikea käyttö joillakin kielillä ja toimialoilla voidaan saavuttaa mukauttamalla yleiskäyttöisiä tietojenkäsittelyjärjestelmiä suuriin määriin toimialojen rinnakkaista tiedoista, tällaisia määriä toimialoittakohtaisia tietoja on harvoin saatavilla vähemmän resursseilla varustetuille kielille ja erikoisaloille. Lisäksi, kuten COVID-19 hiljattain osoitti, uusien toimialueiden osalta ei ole helposti saatavilla toimialueekohtaisia rinnakkaisia tietoja. Äskettäisen katastrofin vakavuus aiheutti kuitenkin suurta kysyntää pandemiaa ja infektioiden ehkäisyä koskevien kriittisten tietojen luotettavalle kääntämiselle. Tämä työ on osa WMT22021 Shared Task: Machine Translation using Terminologies -ohjelmaa, jossa kuvataan Tilde MT -järjestelmiä, jotka pystyvät dynaamiseen terminologiaintegraatioon käännöshetkellä. Järjestelmämme saavuttavat jopa 94% COVID-19 termien käyttötarkkuuden EN-FR-kieliparin testisarjassa ilman, että heillä on pääsy minkäänlaisiin verkkotietoihin järjestelmäkoulutuksen aikana.', 'jv': 'Banyak uga luwih dumateng sing dipunanggunaké perusahaan pawang gerakan kanggo ngerasakno kesalahan lan kabèh dumateng informasi sing ngerasakno. When the right use of terminal logies for some language and domain ain can be accessable by modificationing General-goal MT sistems on big volumas of in-domain Paralelel data, so limits of domain-special data are Seldment available for not-Resurcemed language and NIChe domain ain. For example, as example by COMPID-19 recent, no domain-special Paralelel data is readly available for surging domain ain. Nanging, nggambar kapan dumadhi sing dumadhi kapan dumadhi iki banget nggawe akeh usul kanggo tarjamah bantuan informasi sing apik dhéwé kuwi tindakan Panem karo preransié Panem. Wulku iki barêng karo WWT 2020 1 Sampeyan Taaksi: Masine Terjamahan nggambar Terminal inputem, supoyo awak dhéwé ngpisan Tilde MT sistem sing bisa akeh penterêt terjamahan kanggo mbalkurik terjamahan. Sistem dhéwé iso nglanggar wigatining 1994% COMPID-19 teréné teka pangan kanggo nyeneng ujian winih kanggo ngilanggar oleh dumadhi, kuwi mau iso nggawe sistem terus-teréné.', 'ha': "Akwai masu yawa na saurari cikin harshen sun ƙayyade amfani da taƙaitacce mai hankali dõmin ya tabbatar da bayyani da inganci ga information da aka gaya. Waka da amfani da tumori mai daidai wa wasu harshen da sauniya ko daidai za'a iya sãmun su da kwamfyuta na tsarin MT-na'urar-nau'in-daidai masu cikin-Domen, za'a iya amfani da gwargwadon nau'in-daidai, ko kuma za'a iya sãmu da nau'in-daidai da wasu mutane na daidai. Furan, kamar an buga misãli da COV-19 na farko, ba za'a iya samar da data masu ƙayyade guda masu daidaita wa kima na sauri. Haƙĩƙa, girma ga wannan masĩfa na ƙara suka halicca wata talauci mai girma wa tafsiri na muhimmi a kan hanyor zargi da kuma hanyotar hanyor hanyoyi. @ action SystemyinMu za'a sami zuwa 94% COV-19 za'a yi amfani da tsari a kan jarrabar nau'in lugha-EN-FR ko kuma ba ya sami wani irin mutane na cikin tsari a lokacin da za'a yi amfani da shi ba.", 'sk': 'Večina jezikovnih področij zahteva preudarno uporabo terminologije, da se zagotovi jasnost in ustreznost posredovanih informacij. Čeprav je mogoče pravilno uporabo terminologije za nekatere jezike in področja doseči s prilagoditvijo splošnih sistemov MT na velike količine vzporednih podatkov na področju, so takšne količine podatkov, specifičnih za področje, redko na voljo za jezike z manj virov in nišna področja. Poleg tega za nastajajoče domene ni takoj na voljo nobenih vzporednih podatkov, specifičnih za domeno. Vendar je resnost te nedavne nesreče povzročila veliko povpraševanje po zanesljivem prevodu kritičnih informacij o pandemiji in preprečevanju okužb. To delo je del skupne naloge WMT22021: strojno prevajanje s terminologijami, kjer opisujemo Tilde MT sisteme, ki so sposobni dinamične terminološke integracije v času prevajanja. Naši sistemi dosegajo do 94% natančnost uporabe izrazov COVID-19 na testnem nizu jezikovnega par EN-FR brez dostopa do kakršnih koli oblik informacij v domeni med sistemskim usposabljanjem.', 'he': 'רוב תחומי השפה דורשים שימוש נבון בטרמולוגיה כדי להבטיח ברור ומתאים של המידע שנעבר. למרות שהשימוש הנכון של הטרמינולוגיה לכמה שפות ותחומים יכול להשיג על ידי שימוש מערכות MT למטרה כללית על כמויות גדולות של נתונים מקבילים בתחום, כמויות כאלה של נתונים ספציפיים לתחום נדירות זמינות לשפות פחות משאבים ותחומים נישי. בנוסף, כפי שדוגמה על ידי COVID-19 לאחרונה, אין נתונים מקבילים ספציפיים לתחום זמינים בקלות לתחומים מתפתחים. עם זאת, כבד האסון האחרון הזה יצר דרישה גבוהה לתרגום אמין של מידע קריטי בנוגע לפנדמיה ומניעת זיהומים. העבודה הזו היא חלק ממשימה משותפת WMT2021: תרגום מכונות בשימוש בטרמינולוגיות, שבו אנחנו מתארים מערכות MT טיילד שיכולות לאינטגרציה טרמינולוגית דינמית בזמן התרגום. המערכות שלנו משיגות עד 94% של מונח COVID-19 שימוש מדויק על קבוצת הבדיקה של זוג השפה EN-FR ללא גישה לכל סוג של מידע בתחום במהלך אימון מערכת.', 'bo': 'སྐད་ཡིག་ཚང་མས་ཆེ་ཆུང་མས་དུ་གསལ་བཤད་དང་བདེ་འཇགས་ཀྱི་གནས་ཚུལ་གསལ་བཤད་བྱེད་དགོས་པ་ཡིན། While the correct use of terminology for some languages and domains can be achieved by adapting general-purpose MT systems on large volumes of in-domain parallel data, such quantities of domain-specific data are seldom available for less-resourced languages and niche domains. Furthermore, as exemplified by COVID-19 recently, no domain-specific parallel data is readily available for emerging domains. འོན་ཀྱང་། ཉེ་ཆར་བྱུང་བར་དུ་གནོད་སྐྱིད་ཀྱི་གནས་ཚུལ་གསལ་བཤད་ནི་ལྷན་རིམ་སྟོན་པའི་དགོས་མཁན་ཞིག་ཡིན་པས། This work is part of WMT2021 Shared Task: Machine Translation using Terminologies, where we describe Tilde MT systems that are capable of dynamic terminology integration at the time of translation. ང་ཚོའི་མ་ལག་གི་གོ་སྐབས་ཡིག་ཆ་གི་ཚད་ལ་94% COVID-19་ཟིན་བྲིས་པའི་གསལ་བཤད་ཀྱི་ཞིབ་དཔྱད་ནི་EN-FR སྐད་ཡིག་ཆ་གི་རིགས་ཚན་ལ་འཛུལ་སྤྱོད'}
{'en': 'CUNI Systems for WMT21 : Terminology Translation Shared Task', 'fr': 'CUNI Systems for WMT21\xa0: tâche partagée de traduction terminologique', 'es': 'Sistemas CUNI para WMT21: tarea compartida de traducción terminológica', 'ar': 'أنظمة CUNI لـ WMT21: مهمة مشتركة لترجمة المصطلحات', 'pt': 'Sistemas CUNI para WMT21: Tarefa Compartilhada de Tradução de Terminologia', 'zh': '用 WMT21 CUNI 系统:术语译共之', 'ja': 'CUNI Systems for WMT 21: Terminology Translation Shared Task', 'hi': 'WMT21 के लिए CUNI सिस्टम्स: शब्दावली अनुवाद साझा कार्य', 'ru': 'Системы CUNI для WMT21: Общая Задача Перевода Терминологии', 'ga': 'Córais CUNI do WMT21: Tasc Comhroinnte um Aistriú Téarmaíochta', 'ka': 'Comment', 'el': 'Συστήματα CUNI για το WMT21: Κοινή εργασία μετάφρασης ορολογίας', 'hu': 'CUNI Systems for WMT21: Terminológiai fordítás Megosztott feladat', 'it': 'CUNI Systems for WMT21: Compito condiviso di traduzione terminologica', 'kk': 'WMT21- нің CUNI жүйелері: терминология аудармалары ортақ тапсырмасы', 'lt': 'CUNI sistemos WMT21: Terminologijos vertimo bendra užduotis', 'mk': 'CUNI системи за WMT21: Делена задача за терминолошки превод', 'ml': 'WMT21- നുള്ള സിയുണി സിസ്റ്റം: ടെര്\u200dമിനോളജി പരിഭാഷപ്പെടുത്തി പങ്കെടുത്ത പണി', 'mn': 'WMT21-ийн CUNI системүүд: Терминологийн хөгжлийн хуваалтын ажил', 'no': 'CUNI- systemer for WMT21: Delt oppgåve for terminologisk omsetjing', 'ms': 'Sistem CUNI untuk WMT21: Tugas Berkongsi Terjemahan Terminologi', 'ro': 'Sisteme CUNI pentru WMT21: Sarcină comună de traducere terminologică', 'pl': 'Systemy CUNI dla WMT21: Tłumaczenie terminologii Wspólne Zadanie', 'sr': 'CUNI sistemi za WMT21: Dijeljeni zadatak za prevod terminologije', 'si': 'Comment', 'ta': 'WMT21- க்கான CUNI அமைப்புகள்: முனைய மொழிபெயர்ப்பு பகிர்ந்த பணி', 'so': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'sv': 'CUNI Systems för WMT21: Delad uppgift för terminologiöversättning', 'mt': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'ur': 'Comment', 'uz': 'WMT21 uchun CUNI tizimi: Terminology tarjima qilingan vazifa', 'vi': 'Hệ thống CUPS cho WM21: Dịch thuyết chia sẻ Nhiệm vụ', 'da': 'CUNI Systems til WMT21: Fælles opgave for terminologioversættelse', 'bg': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'de': 'CUNI Systeme für WMT21: Gemeinsame Aufgabe der Terminologie Übersetzung', 'ko': 'WMT21의 CUNI 시스템:용어 번역 공유 작업', 'nl': 'CUNI-systemen voor WMT21: Gedeelde taak van terminologie vertaling', 'fa': 'Comment', 'hr': 'CUNI sustavi za WMT21: Dijeljeni zadatak za prevod terminologije', 'tr': 'WMT21 üçin CUNI Sistemler: Terminologiýa terjime Paýlaşdy Görevi', 'af': 'Name', 'sq': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'am': 'ተርሚኖሎጂ ትርጉም የተShared ስራ', 'sw': 'Mfumo wa CUNI kwa ajili ya WMT21: Tafsiri ya Terminalology', 'az': 'WMT21 üçün CUNI Sistemləri: Terminoloji Tərcümə Paylaşılan Task', 'hy': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'bn': 'WMT21- এর জন্য সিউনি সিস্টেম: টার্মিনোলজি অনুবাদ শেয়ার করা কাজ', 'ca': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'bs': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'et': 'CUNI Systems for WMT21: Terminoloogia tõlke jagatud ülesanne', 'fi': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'cs': 'CUNI Systémy pro WMT21: Překlad terminologie Shared Task', 'id': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'jv': 'CUNI Sistem kanggo WW1:Terminal', 'ha': 'KCharselect unicode block name', 'he': 'CUNI Systems for WMT21: Terminology Translation Shared Task', 'sk': 'CUNI Systems for WMT21: Terminologija Prevajanje v skupni rabi', 'bo': 'CUNI Systems for WMT21: Terminology Translation Shared Task'}
{'en': 'This paper describes Charles University sub-mission for Terminology translation Shared Task at WMT21. The objective of this task is to design a ', 'ar': 'تصف هذه الورقة المهمة الفرعية لجامعة تشارلز للمهمة المشتركة لترجمة المصطلحات في WMT21. الهدف من هذه المهمة هو تصميم نظام يقوم بترجمة مصطلحات معينة بناءً على قاعدة بيانات المصطلحات المتوفرة ، مع الحفاظ على جودة ترجمة عامة عالية. تنافسنا في زوج من اللغتين الإنجليزية والفرنسية. يعتمد نهجنا على توفير الترجمات المرغوبة جنبًا إلى جنب مع الجملة المدخلة وتدريب النموذج على استخدام هذه المصطلحات المتوفرة. نحن نلصق المصطلحات أثناء التدريب والاستدلال ، للسماح للنموذج بتعلم كيفية إنتاج أشكال سطحية صحيحة للكلمات ، عندما تختلف عن الأشكال المتوفرة في قاعدة بيانات المصطلحات. احتل تقديمنا المرتبة الثانية في مقياس "المطابقة التامة" والذي يقيم قدرة النموذج على إنتاج المصطلحات المطلوبة في الترجمة.', 'fr': "Cet article décrit la sous-mission de l'Université Charles pour la tâche partagée de traduction terminologique au WMT21. L'objectif de cette tâche est de concevoir un système qui traduit certains termes sur la base d'une base de données terminologique fournie, tout en préservant une qualité globale de traduction élevée. Nous avons concouru en binôme anglais-français. Notre approche est basée sur la fourniture des traductions souhaitées à côté de la phrase d'entrée et sur la formation du modèle à utiliser ces termes fournis. Nous lemmatisons les termes à la fois pendant la formation et l'inférence, afin de permettre au modèle d'apprendre à produire des formes de surface correctes des mots, lorsqu'elles diffèrent des formes fournies dans la base de données terminologiques. Notre soumission s'est classée deuxième dans la métrique Exact Match qui évalue la capacité du modèle à produire les termes souhaités dans la traduction.", 'pt': 'Este artigo descreve a submissão da Charles University para a tarefa compartilhada de tradução de terminologia no WMT21. O objetivo desta tarefa é projetar um sistema que traduza certos termos com base em um banco de dados de terminologia fornecido, preservando a alta qualidade geral da tradução. Competimos no par de idiomas inglês-francês. Nossa abordagem é baseada em fornecer as traduções desejadas juntamente com a frase de entrada e treinar o modelo para usar esses termos fornecidos. Lematizamos os termos tanto durante o treinamento quanto na inferência, para permitir que o modelo aprenda a produzir formas superficiais corretas das palavras, quando elas diferem das formas fornecidas no banco de dados de terminologia. Nosso envio ficou em segundo lugar na métrica Exact Match, que avalia a capacidade do modelo de produzir os termos desejados na tradução.', 'es': 'Este artículo describe la presentación de Charles University para la tarea compartida de traducción de terminología en WMT21. El objetivo de esta tarea es diseñar un sistema que traduzca ciertos términos en función de una base de datos terminológica proporcionada, manteniendo al mismo tiempo una alta calidad de traducción en general. Competimos en la combinación de idiomas inglés-francés. Nuestro enfoque se basa en proporcionar las traducciones deseadas junto con la frase de entrada y capacitar al modelo para que utilice estos términos proporcionados. Lematizamos los términos tanto durante el entrenamiento como durante la inferencia, para permitir que el modelo aprenda a producir formas superficiales correctas de las palabras, cuando difieren de las formas proporcionadas en la base de datos terminológica. Nuestra presentación ocupó el segundo lugar en la métrica de concordancia exacta, que evalúa la capacidad del modelo para producir los términos deseados en la traducción.', 'hi': 'यह पेपर चार्ल्स विश्वविद्यालय उप-मिशन का वर्णन करता है शब्दावली अनुवाद WMT21 में साझा कार्य के लिए। इस कार्य का उद्देश्य एक ऐसी प्रणाली को डिजाइन करना है जो उच्च समग्र अनुवाद गुणवत्ता को संरक्षित करते हुए, प्रदान की गई शब्दावली डेटाबेस के आधार पर कुछ शब्दों का अनुवाद करता है। हमने अंग्रेजी-फ्रेंच भाषा की जोड़ी में प्रतिस्पर्धा की। हमारा दृष्टिकोण इनपुट वाक्य के साथ वांछित अनुवाद प्रदान करने और इन प्रदान की गई शर्तों का उपयोग करने के लिए मॉडल को प्रशिक्षित करने पर आधारित है। हम प्रशिक्षण और अनुमान दोनों के दौरान शब्दों को lemmatize करते हैं, ताकि मॉडल को यह सीखने की अनुमति मिल सके कि शब्दों के सही सतह रूपों का उत्पादन कैसे किया जाए, जब वे शब्दावली डेटाबेस में प्रदान किए गए रूपों से भिन्न होते हैं। हमारे सबमिशन को सटीक मैच मीट्रिक में दूसरा स्थान दिया गया है जो अनुवाद में वांछित शब्दों का उत्पादन करने के लिए मॉडल की क्षमता का मूल्यांकन करता है।', 'zh': '本文述查理大学在WMT21上术语译共其事。 其务在设一统,据术语数据库译某术语,兼持高体译质。 吾以英语 - 法语争。 吾法基于输句之旁,供其译,习其术语。 吾于训理之间,词形还术语,以许模形学成单词之正文,当其与术语数据库异文。 精配指标第二,指标评译生术语。', 'ja': '本稿では、WMT 21における用語翻訳共有タスクのためのチャールズ大学のサブミッションについて述べる。このタスクの目的は、高い全体的な翻訳品質を維持しながら、提供された用語データベースに基づいて特定の用語を翻訳するシステムを設計することです。私たちは英語とフランス語のペアで競った。私たちのアプローチは、入力文とともに必要な翻訳を提供し、提供された用語を使用するためのモデルをトレーニングすることに基づいています。トレーニングと推論の両方の間に用語を統一し、モデルが用語データベースに提供されている形式と異なる場合に、単語の正しい表面形式を生成する方法を学習できるようにします。翻訳で目的の用語を生成するモデルの能力を評価する「完全一致」指標では、当社の提出物が2位にランクインしました。', 'ru': 'В этой статье описывается подмиссия Чарльзского университета по терминологическому переводу общей задачи на WMT21. Целью этой задачи является разработка системы, которая переводит определенные термины на основе предоставленной терминологической базы данных, сохраняя при этом высокое общее качество перевода. Мы соревновались в английско-французской языковой паре. Наш подход основан на предоставлении желаемых переводов наряду с входным предложением и обучении модели использованию этих предоставленных терминов. Мы лематизируем термины как во время обучения, так и во время вывода, чтобы модель научилась создавать правильные поверхностные формы слов, когда они отличаются от форм, предоставленных в терминологической базе данных. Наша заявка заняла второе место в метрике Exact Match, которая оценивает способность модели производить желаемые термины в переводе.', 'ga': 'Déanann an páipéar seo cur síos ar fhomhisean Ollscoil Charles maidir le Tasc Comhroinnte um Aistriú Téarmaíochta ag WMT21. Is é cuspóir an taisc seo ná córas a dhearadh a aistríonn téarmaí áirithe bunaithe ar bhunachar sonraí téarmaíochta a chuirtear ar fáil, agus a chaomhnaíonn ardchaighdeán aistriúcháin san iomlán. Bhí muid san iomaíocht i bpéire teanga Béarla-Fraincis. Tá ár gcur chuige bunaithe ar na haistriúcháin atá ag teastáil a sholáthar in éineacht leis an abairt ionchuir agus oiliúint a chur ar an tsamhail chun na téarmaí seo a úsáid. Déanaimid lammatize na dtéarmaí le linn na hoiliúna agus an tátail, chun ligean don mhúnla foghlaim conas foirmeacha cearta dromchla na bhfocal a tháirgeadh, nuair a bhíonn siad difriúil leis na foirmeacha a chuirtear ar fáil sa bhunachar téarmaíochta. Tháinig ár n-aighneacht sa dara háit i méadrach Meaitseáil Beacht a dhéanann meastóireacht ar chumas na samhla téarmaí inmhianaithe a tháirgeadh san aistriúchán.', 'hu': 'Ez a tanulmány bemutatja a Charles Egyetem terminológiai fordítási megosztott feladatát a WMT21-en. E feladat célja egy olyan rendszer kialakítása, amely bizonyos kifejezéseket fordít le a rendelkezésre álló terminológiai adatbázis alapján, miközben megőrzi a magas színvonalú fordítási minőséget. Angol-francia nyelvpárban versenyeztünk. Megközelítésünk alapja a kívánt fordítások biztosítása a beviteli mondat mellett, és a modellt a megadott kifejezések használatára képezi. Lemmatizáljuk a kifejezéseket mind a képzés, mind a következtetés során, hogy a modell megtanulhassa, hogyan állítsa elő a szavak helyes felületi formáit, ha azok eltérnek a terminológiai adatbázisban megadott formáktól. Beküldésünk a második helyen állt az Exact Match metriában, amely értékeli, hogy a modell képes-e a kívánt kifejezéseket előállítani a fordításban.', 'it': "Questo articolo descrive la sottomissione della Charles University per la traduzione terminologica Shared Task presso WMT21. L'obiettivo di questo compito è quello di progettare un sistema che traduca determinati termini sulla base di una banca dati terminologica fornita, pur mantenendo un'elevata qualità complessiva della traduzione. Abbiamo gareggiato in coppia inglese-francese. Il nostro approccio si basa sulla fornitura delle traduzioni desiderate insieme alla frase di input e sulla formazione del modello per utilizzare questi termini forniti. Lemmatizziamo i termini sia durante la formazione che durante l'inferenza, per consentire al modello di imparare a produrre forme superficiali corrette delle parole, quando differiscono dai moduli forniti nel database terminologico. La nostra presentazione si è classificata secondo nella metrica Exact Match che valuta la capacità del modello di produrre termini desiderati nella traduzione.", 'ka': 'ამ წიგნის შესახებ ფარლუს სუნივერსიტეტის სუბმისია ტერმინოლოგიის გასაგულისხმებისთვის WMT21-ში. ამ დავალების მიზეზი არის სისტემის შექმნა, რომელიც განახლებული ტერმინოლოგიის ბაზეზის ბაზეზაზე განახლება განახლებული სისტემის განახლება, რომელიც უფრო მეტი სისტემის გადა ჩვენ ინგლისური-ფრანგური ენაზის ზოგში კონტერირებდით. ჩვენი პროგორმა იგივეა, რომ მოთხოვრებული წესების დამატებით მოთხოვრებული წესების დამატებით და მოდელს გამოყენება ამ წესების გამოყენება. ჩვენ ლიმომატიზებთ სიტყვების შესახებ და ინფრენციის განმავლობაში, რომ მოდელის შესაძლებლობა მოვისწავლოთ როგორ წარმოადგენა სიტყვების მარტივი ფორმები, როცა ისინი განსხვავებულია ტ ჩვენი წარმოდგენება წარმოდგენა მეორე მეტრიკში, რომელიც მოდელის შესაძლებლობა გამოიყენოთ თითქონული წარმოდგენების შესაძლებლობა.', 'el': 'Η παρούσα εργασία περιγράφει την υποαποστολή του Πανεπιστημίου Καρόλου για τη μετάφραση ορολογίας στο WMT21. Στόχος του έργου αυτού είναι ο σχεδιασμός ενός συστήματος που μεταφράζει ορισμένους όρους με βάση μια παρεχόμενη βάση δεδομένων ορολογίας, διατηρώντας παράλληλα υψηλή συνολική ποιότητα μετάφρασης. Ανταγωνιστήκαμε στο ζευγάρι Αγγλικών-Γαλλικών γλωσσών. Η προσέγγισή μας βασίζεται στην παροχή των επιθυμητών μεταφράσεων παράλληλα με την πρόταση εισαγωγής και στην εκπαίδευση του μοντέλου για τη χρήση αυτών των παρεχόμενων όρων. Λεματοποιούμε τους όρους τόσο κατά τη διάρκεια της εκπαίδευσης όσο και κατά την εξαγωγή συμπερασμάτων, ώστε να επιτρέψουμε στο μοντέλο να μάθει πώς να παράγει σωστές επιφανειακές μορφές των λέξεων, όταν διαφέρουν από τις φόρμες που παρέχονται στη βάση δεδομένων ορολογίας. Η υποβολή μας κατατάχθηκε δεύτερη στη μέτρηση ακριβούς αντιστοίχισης που αξιολογεί την ικανότητα του μοντέλου να παράγει επιθυμητούς όρους στη μετάφραση.', 'kk': 'Бұл қағаз WMT21 терминология аудармасының Шарльз университетінің ішкі миссиясын таңдайды. Бұл тапсырманың мақсаты - келтірілген терминология деректер қорына негізделген терминология деректер қорына аударатын жүйені құрастыру, және жалпы аудармалардың сапасы жоғары. Біз ағылшын-француз тілінің екі тілінде бұлдық. Біздің тәсіліміз керек аудармаларды келтіріп, келтірілген терминдерді қолдану үшін үлгісін қолдану үшін қалаған аудармаларды негізделген. Олар терминологиялық деректер қорындағы пішімдерден қалай жасау үшін үлгілерді лимматикациялау үшін, сөздердің дұрыс пішімдерін оқытуға мүмкіндік береді. Біздің жіберіміздің екінші ретінде оның ақпаратты аудару үшін қалаған терминлерді жасау мүмкіндігін бағалады.', 'lt': 'Šiame dokumente aprašoma Charles University sub mission for Terminology translation Shared Task at WMT21. The objective of this task is to design a system which translates certain terms based on a provided terminology database, while preserving high overall translation quality.  Mes konkuravome anglų ir prancūzų kalbų pora. Mūsų požiūris grindžiamas norimų vertimų pateikimu kartu su įžanginiu sakiniu ir modelio mokymu, kaip naudotis šiomis pateiktomis sąlygomis. Mes lemmatizuojame terminus mokymo ir išvados metu, kad modelis galėtų išmokti gaminti teisingas žodžių paviršiaus formas, kai jie skiriasi nuo terminologijos duomenų bazėje pateiktų formų. Mūsų pranešimas buvo antrasis pagal tikslią atitiktį metriką, kuri vertina modelio gebėjimą išversti pageidaujamus terminus.', 'ms': 'Kertas ini menggambarkan sub-misi Universiti Charles untuk terjemahan Terminologi Tugas Berkongsi di WMT21. The objective of this task is to design a system which translates certain terms based on a provided terminology database, while preserving high overall translation quality.  Kami bersaing dalam bahasa Inggeris-Perancis pasangan. pendekatan kita berdasarkan menyediakan terjemahan yang diinginkan bersama kalimat input dan melatih model untuk menggunakan terma yang disediakan ini. Kami lemmatize terma kedua-dua semasa latihan dan kesimpulan, untuk membenarkan model untuk belajar bagaimana untuk menghasilkan bentuk permukaan yang betul perkataan, apabila ia berbeza dari bentuk yang diberikan dalam pangkalan data terminologi. Our submission ranked second in Exact Match metric which evaluates the ability of the model to produce desired terms in the translation.', 'mk': 'Овој весник ја опишува подмисијата на Универзитетот Чарлс за превод на терминологија Соделена задача на WMT21. Целта на оваа задача е да се дизајнира систем кој преведува одредени терминолошки терминолошки бази на податоци, при што ќе се зачува висок вкупен квалитет на преведување. Се натпреварувавме на англиско-француски пар. Нашиот пристап е базиран на обезбедување на желби преводи заедно со влезната реченица и обука на моделот за користење на овие обезбедени термини. Ги лиматизираме условите за време на обуката и конференцијата, за да му овозможиме на моделот да научи како да произведува правилни форми на површина на зборовите, кога се разликуваат од формулите што се обезбедуваат во базата на податоци за терминологија. Нашето поднесување се рангираше второ во метриката на точната совпаѓање, која ја оценува способноста на моделот да создаде желби за превод.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni tal-Università Charles għat-traduzzjoni tat-terminoloġija Kompitu Kondiviż fid-WMT21. L-għan ta’ dan il-kompitu huwa li tiġi ddisinjata sistema li tittraduċi ċerti termini bbażati fuq bażi ta’ dejta tat-terminoloġija pprovduta, filwaqt li tiġi ppreservata kwalità globali għolja tat-traduzzjoni. Konkurrejna f’par lingwistiku Ingliż-Franċiż. L-approċċ tagħna huwa bbażat fuq il-forniment tat-traduzzjonijiet mixtieqa flimkien mas-sentenza ta’ input u t-taħriġ tal-mudell biex jintużaw dawn it-termini pprovduti. We lemmatize the terms both during the training and inference, to allow the model to learn how to produce correct surface forms of the words, when they differ from the forms provided in the terminology database.  Is-sottomissjoni tagħna kienet ikklassifikata t-tieni f’Match Exact metric li tevalwa l-abbiltà tal-mudell li jipproduċi termini mixtieqa fit-traduzzjoni.', 'mn': 'Энэ цаас Чарльз Их Сургуулийн Терминологийн орчуулалт WMT21 дээрх хуваалтын ажлын сургуулийн давхаргыг тайлбарладаг. Энэ ажлын зорилго нь тодорхойлолтын өгөгдлийн сангийн үндсэн тодорхойлолтуудыг орлуулдаг системийг зохион байгуулах юм. Бид Англи-Француз хэл хоёрын хоёрын талаар өрсөлдөг. Бидний ойлголт нь хүсэлтэй орнуудын өгүүлбэртэй хамтдаа хүсэлтэй орнуудыг дамжуулж, эдгээр орнуудыг ашиглах загварыг суралцах юм. Бид суралцах болон халдварын үед томъёог хоёуланг загвараар хэрхэн зөв гадаргуу хэлбэрүүдийг бүтээхийг суралцах боломжтой болгож, терминологийн өгөгдлийн сан дээр өгөгдсөн хэлбэрээс ялгаатай. Бидний дамжуулалт нь "Exact Match" метрийн хоёрдугаар дүрслэгдсэн бөгөөд энэ загварын хүсэлтэй томъёог хөгжүүлэх чадварыг үнэлдэг.', 'ml': 'ഈ പത്രത്തില്\u200d ചാര്\u200dള്\u200dസ് യൂണിവേഴ്സിറ്റിയില്\u200d ടെര്\u200dമിനോളജി പരിഭാഷപ്പെടുത്തുന്നതിന് വിവരിക്കുന്നു ഈ ജോലിയുടെ ലക്ഷ്യം ഒരു സിസ്റ്റത്തിന്റെ നിര്\u200dമ്മിക്കുക, അത് നല്\u200dകിയ ടെര്\u200dമിനോളജി ഡാറ്റാബേസില്\u200d അടിസ്ഥാനമാക്കുന്ന വ ഞങ്ങള്\u200d ഇംഗ്ലീഷ്-ഫ്രെഞ്ച് ഭാഷ ജോടിയില്\u200d മത്സരിച്ചു. ഇന്\u200dപുട്ടിന്\u200dറെ വാക്കിനു പുറമെ ആഗ്രഹിക്കുന്ന വിഭാഷകങ്ങള്\u200d നല്\u200dകുന്നതിന്\u200dറെ അടിസ്ഥാനത്താണ് ഞങ്ങളുടെ പ്രായോ ടെര്\u200dമിനോളജി ഡാറ്റാബേസില്\u200d നിന്നും നല്\u200dകിയ രീതികളില്\u200d നിന്നും വ്യത്യാസപ്പെടുന്ന രീതികളില്\u200d നിന്നും വ്യത്യാസപ്പെടുന്ന രീതികളില്\u200d നിന നമ്മുടെ കീഴ്പെട്ട രണ്ടാമത്തെ പരിഭാഷയില്\u200d ആഗ്രഹിക്കുന്ന വാക്കുകള്\u200d ഉണ്ടാക്കാനുള്ള മോഡലിന്റെ കഴിവിനെ വിശദീ', 'no': 'Denne papiret beskriver undermission for Charles University for terminologisk omsetjing delt oppgåve på WMT21. Målet på denne oppgåva er å laga eit systemet som oversetter enkelte vilkår basert på ein tilgjengeleg terminologisk databasen, medan det lagrar høg overalt omsetjingskvalitet. Vi kompeterte med engelsk-fransk språk par. Tilnærminga vårt er basert på å gje dei ønskte omsetningane blant innsetningsetninga og opplæra modellen for å bruka desse tilgjengelege vilkåra. Vi lemmatiserer vilkåra både under opplæring og infeksjon, slik at modellen kan lære korleis å produsera rette overflatsformar av ord, når dei er ulike frå skjemane som er oppgjeve i terminologidatabasen. Søket vårt rangert andre i nøyaktig treff metrisk som evaluerer evnen på modellen til å produsera ønskte vilkår i omsetjinga.', 'sr': 'Ovaj papir opisuje podmisiju Čarlsa Univerziteta za prevod terminologije, podeljeni zadatak na WMT21. Cilj ovog zadatka je da dizajniramo sistem koji prevodi određene uslove na osnovu pružene terminološke baze podataka, dok čuva visoke kvalitete prevoda. Konkurirali smo se na francuskom i engleskom jeziku. Naš pristup je baziran na pružanju željnih prevoda pored rečenice za ulazak i obuku modela da koristi ove obezbeđene uslove. Lematiziramo uslove i tijekom treninga i infekcije, da bi omogućili model da nauči kako proizvesti ispravne oblike površine reči, kada se razlikuju od oblika pruženih u bazi podataka terminologije. Naša podnošljenja je određena druga u metrici Exact Match, koja procjenjuje sposobnost modela da proizvede željeni uslovi u prevodu.', 'pl': 'Niniejszy artykuł opisuje podmisję Uniwersytetu Karola do tłumaczenia terminologii Wspólne Zadanie w WMT21. Celem tego zadania jest zaprojektowanie systemu, który tłumaczy określone terminy w oparciu o dostarczoną bazę terminologiczną przy zachowaniu wysokiej ogólnej jakości tłumaczeń. Rywalizowaliśmy w parze językowej angielsko-francuskiej. Nasze podejście opiera się na dostarczeniu pożądanych tłumaczeń obok zdania wejściowego i przeszkoleniu modelu używania tych dostarczonych terminów. Lemmatyzujemy terminy zarówno w trakcie szkolenia, jak i wniosków, aby umożliwić modelowi nauczyć się wytwarzać poprawne formy powierzchniowe słów, gdy różnią się one od formularzy dostarczonych w bazie terminologicznej. Nasze zgłoszenie zajęło drugie miejsce w metryce Exact Match, która ocenia zdolność modelu do wytworzenia pożądanych terminów w tłumaczeniu.', 'ro': 'Această lucrare descrie submisiunea Universității Charles pentru traducerea terminologiei Shared Task la WMT21. Obiectivul acestei sarcini este de a concepe un sistem care să traducă anumiți termeni pe baza unei baze de date terminologice furnizate, păstrând în același timp o calitate generală ridicată a traducerii. Am concurat în perechea engleză-franceză. Abordarea noastră se bazează pe furnizarea traducerilor dorite alături de propoziția de introducere și instruirea modelului pentru a utiliza acești termeni furnizați. Lemmatizăm termenii atât în timpul instruirii, cât și în timpul inferenței, pentru a permite modelului să învețe cum să producă forme de suprafață corecte ale cuvintelor, atunci când acestea diferă de formularele furnizate în baza de date terminologică. Trimiterea noastră s-a clasat pe locul doi în metrica Exact Match, care evaluează capacitatea modelului de a produce termenii doriți în traducere.', 'si': 'මේ පැත්තේ චාර්ල්ස් විශ්වාසික විද්\u200dයාපිත්ත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත වි මේ වැඩේ ඉලක්ෂාව තමයි පද්ධතියක් සංවිධානය කරන්න, සම්පූර්ණ පද්ධතිය පද්ධතිය සඳහා කිසිම පද්ධතිය පද්ධතිය අපි ඉංග්\u200dරේන්සි-ෆ්\u200dරෑන්ස් භාෂාව දෙන්නේ තරඟ කළා. අපේ ප්\u200dරවේශනය අවශ්\u200dය වාර්ථාවක් සමඟ අවශ්\u200dය වාර්ථාවක් දෙන්නේ අවශ්\u200dය වාර්ථාවක් සහ ප්\u200dරවේශනය ස අපි පරීක්ෂණය සහ පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය කරනවා, පරීක්ෂණයට පරීක්ෂණය කොහොමද කියලා වචන වර්තන අපේ පිළිගන්නේ දෙවෙනි ප්\u200dරමාණයක් ඇති මෙට්\u200dරික් වලින් දෙවෙනි ප්\u200dරමාණයක් විශ්වාස කරනවා මොඩ්ලයේ අවශ්\u200d', 'so': 'Kanu warqaddan waxaa lagu qoraa Charles University sub-mission for Terminology translation Shared Task at WMT21. Ujeedada shaqadaas waa in la sameeyo nidaam oo ku turjuma qoraal cayiman oo ku saleysan shabakada garoonka terminology, iyadoo la ilaaliyo takhasuska turjumaadda oo dhan. Waxaannu ku guulaysannay laba af Ingiriis oo Faraansiis ah. Dhaqdhaqaalkayagu waxay ku saleysan tahay bixinta turjumaadda la doonayo oo la xiriira qoraalka soo gelinta iyo waxbarashada qaababka lagu isticmaalo sharciyadan. Waxbarashada iyo baahida ayaannu u qoraynaa qoraalka, si aan u oggolaano in uu u barto sida loo soo koriyo foomka saxda ah oo hadalka, marka ay ka duwan yihiin foomka lagu soo daayay shabakadda terminology. Guulyadeenu waxay ka soo bandhigtay labaad ee ku qoran qoraalka Matrix ee qiimeynaya awoodda modellka in lagu soo bixiyo qoraal la doonayo turjumaadda.', 'sv': 'Denna uppsats beskriver Charles University underuppdrag för Terminologi översättning Shared Task på WMT21. Syftet med denna uppgift är att utforma ett system som översätter vissa termer baserat på en tillhandahållen terminologidatabas, samtidigt som den övergripande översättningskvaliteten bibehålls. Vi tävlade i engelsk-franska språkpar. Vårt tillvägagångssätt bygger på att tillhandahålla önskade översättningar tillsammans med inmatningssatsen och träna modellen att använda dessa angivna termer. Vi lemmatiserar termerna både under utbildningen och slutresultatet, för att låta modellen lära sig att producera korrekta ytformer av orden, när de skiljer sig från de formulär som finns i terminologidatabasen. Vår inlämning rankades tvåa i Exact Match metric som utvärderar modellens förmåga att producera önskade termer i översättningen.', 'ta': 'இந்த தாள் சார்லஸ் University Sub-mission for Terminology translation Shared Task at WMT21. இந்த செயலின் குறிப்பிட்ட சில விளக்கங்களை மொழிமாற்றும் தரவுத்தளத்தின் அடிப்படையில் மொழிபெயர்ப்பில் சேமிக்கும் ப நாங்கள் ஆங்கிலத்தில் பிரெஞ்சு மொழியில் ஜோடி போட்டியிருந்தோம். எங்கள் செயல்பாடு உள்ளீட்டு வாக்கியத்துடன் விரும்ப மொழிபெயர்ப்புகளை வழங்குவது அடிப்படையாகும் மற்றும் இந்த க பயிற்சி மற்றும் குறைவு போகும் போது இருவரும் வார்த்தைகளையும் நாம் விளக்கம் செய்கிறோம், மாதிரியை எப்படி சரியான மேல் வடிவத்தை உருவாக்கு நாங்கள் மொழிபெயர்ப்பு மொழிபெயர்ப்பில் சரியான பொருத்தம் மெட்ரிக்கில் இரண்டாவது முறைமையில் உள்ளது மாதிரிய', 'ur': 'This paper describes Charles University sub-mission for Terminology translation Shared Task at WMT21. اس کام کا مقصد یہ ہے کہ ایک سیستم ڈیزائن کرنا ہے جس نے مقررہ شرایط کو ایک دیوار ٹریمولوژی ڈیٹابیس پر بنیاد رکھا ہے، جب تک بلند عمومی ترجمہ کیفیت کی حفاظت کرتی ہے. ہم انگلیسی-فرانسوی زبان جوڑوں میں مسابقه کرتے تھے۔ ہمارا طریقہ یہ ہے کہ ان معلومات کے مطابق خواہش کی ترجمہ کی تعلیم کریں اور مدل کی تعلیم کریں۔ ہم نے کلمات کی تعلیم اور کثرت کے درمیان کلمات کو لیمیٹ کر رکھا ہے کہ مدل کو سیکھ سکے کہ کلمات کی سیدھی سطح فرموں کو کس طرح پیدا کرے جب وہ ٹریمولوژی ڈیٹابیس میں دیے گئے فرموں سے مختلف ہوتے ہیں۔ ہماری اطاعت دوسری مرتبہ میں دقیق مٹریک میں تھا جو مدل کی قدرت کا ارزش کرتا ہے کہ ترجمہ میں خواہش کی شرایط پیدا کرے۔', 'uz': "Bu qogʻoz Charles University Terminology tarjimasini WMT21'da shart qilingan vazifani taʼrif qiladi. @ info: whatsthis Biz ingliz tilida Fransuz tili ikki qo'lingizda rivojlanamiz. Bizning fikrimiz qo'shilgan soʻzni qo'shish va bu soʻzlarni ishlatish uchun modelni tahrirlash asosida. We lemmatize the terms both during the training and inference, to allow the model to learn how to produce correct surface forms of the words, when they differ from the forms provided in the terminology database.  Bizning imzolarimiz ExExEx Match metrikida ikkinchi chegara boshlaydi. Bu modelning tarjima tarjima uchun kerak soʻzlarni yaratish imkoniyatini qiymaydi.", 'vi': 'Bài viết này mô tả phân công trường đại học Charles cho dịch thuyết chia sẻ Nhiệm vụ tại WM21. Mục tiêu của nhiệm vụ này là thiết kế một hệ thống dịch chuyển một số điều khoản dựa trên một cơ sở dữ liệu thuật ngữ cung cấp, đồng thời bảo vệ chất lượng dịch tổng quát cao. Chúng tôi thi đấu trong một cặp ngôn ngữ Anh-Pháp. Cách tiếp cận của chúng tôi dựa trên việc cung cấp những bản dịch mong muốn bên cạnh câu nhập và huấn luyện mô hình để sử dụng những điều khoản cung cấp này. Chúng tôi bắt buộc các chữ trong suốt thời gian huấn luyện và ngụ ý, để cho phép mô hình học cách tạo ra các dạng bề mặt chính xác của các từ ngữ, khi chúng khác với các dạng được cung cấp trong cơ sở dữ liệu các thuật ngữ. Bài đệ trình của chúng tôi xếp hạng nhì trong đo số đo Y hệt, đánh giá khả năng của mô- đun để sản xuất các thuật ngữ mong muốn trong bản dịch.', 'bg': 'Настоящата статия описва подмисията на Чарлзовия университет за споделена задача за превод на терминология в WMT21. Целта на тази задача е да се разработи система, която превежда определени термини въз основа на предоставена терминологична база данни, като същевременно запазва високо цялостно качество на превода. Състезавахме се на английски и френски език. Нашият подход се основава на предоставяне на желаните преводи заедно с входното изречение и обучение на модела да използва тези предоставени термини. Лематизираме термините както по време на обучението, така и по време на заключението, за да позволим на модела да се научи как да произвежда правилни повърхностни форми на думите, когато те се различават от формулярите, предоставени в терминологичната база данни. Нашето представяне се класира на второ място в метрика "Точно съвпадение", която оценява способността на модела да произвежда желани термини в превода.', 'da': 'Denne artikel beskriver Charles University undermission for Terminologi oversættelse delt opgave på WMT21. Formålet med denne opgave er at udforme et system, der oversætter visse termer baseret på en leveret terminologidatabase, samtidig med at oversættelseskvaliteten bevares. Vi konkurrerede i engelsk-fransk sprogpar. Vores tilgang er baseret på at levere de ønskede oversættelser sammen med input sætningen og træne modellen til at bruge disse leverede termer. Vi lemmatiserer begreberne både under træningen og slutningen, så modellen kan lære at producere korrekte overfladeformer af ordene, når de adskiller sig fra formularerne i terminologidatabasen. Vores indsendelse rangerede andenpladsen i Exact Match metric, som vurderer modellens evne til at producere ønskede termer i oversættelsen.', 'nl': 'Dit artikel beschrijft de submissie van de Charles University voor de vertaling van terminologie Shared Task bij WMT21. Het doel van deze taak is een systeem te ontwerpen dat bepaalde termen vertaalt op basis van een verstrekte terminologiedatabase, met behoud van een hoge algehele vertaalkwaliteit. We deden mee in Engels-Frans taalpaar. Onze aanpak is gebaseerd op het leveren van de gewenste vertalingen naast de invoerzin en het trainen van het model om deze gegeven termen te gebruiken. We lemmatiseren de termen zowel tijdens de training als tijdens de conclusie, zodat het model leert hoe de juiste oppervlaktevormen van de woorden te produceren, wanneer ze verschillen van de formulieren die in de terminologiedatabase worden verstrekt. Onze inzending scoorde op de tweede plaats in Exact Match metric, die de capaciteit van het model evalueert om de gewenste termen in de vertaling te produceren.', 'hr': 'Ovaj papir opisuje podmisiju Charlesa Univerziteta za prevod terminologije podijeljen zadatak na WMT21. Cilj ovog zadatka je dizajniranje sustava koji prevodi određene uvjete na temelju pružene baze podataka terminologije, dok čuva visoke kvalitete prevoda. Konkurirali smo se na francuskom i engleskom jeziku. Naš pristup je temeljen na pružanju željenih prevoda pored ulazne rečenice i obuku modela za upotrebu ovih predviđenih uvjeta. Lematiziramo termine i tijekom treninga i infekcije, kako bi modelu mogli naučiti kako proizvesti ispravne oblike površine riječi, kada se razlikuju od oblika pruženih u bazi podataka terminologije. Naša podnošenja je bila druga u metrici Exact Match-a koja procjenjuje sposobnost modela proizvodnje željenih uvjeta u prevodu.', 'id': 'Kertas ini menjelaskan sub-misi Universitas Charles untuk terjemahan Terminologi Tugas Berbagi di WMT21. Tujuan tugas ini adalah merancang sebuah sistem yang menerjemahkan istilah tertentu berdasarkan database terminologi yang disediakan, sementara mempertahankan kualitas terjemahan umum tinggi. Kami bersaing dalam bahasa Inggris-Perancis pasangan. pendekatan kita berdasarkan menyediakan terjemahan yang diinginkan bersama kalimat masukan dan melatih model untuk menggunakan istilah tersedia. We lemmatize the terms both during the training and inference, to allow the model to learn how to produce correct surface forms of the words, when they differ from the forms provided in the terminology database.  Pengiriman kami berturut-turut kedua dalam Match Exact metric yang mengevaluasi kemampuan model untuk menghasilkan terma yang diinginkan dalam terjemahan.', 'ko': '본고는 찰스대학 WMT21 용어 번역 공유 임무의 하위 임무를 묘사한다.본 임무의 목표는 제공된 용어 데이터베이스에 따라 일부 용어를 번역하고 비교적 높은 전체적인 번역 품질을 유지하는 시스템을 설계하는 것이다.우리는 영국과 프랑스 두 언어의 시합에 참가했다.우리의 방법은 입력 문장 옆에 필요한 번역을 제공하고 모델이 제공하는 용어를 사용하도록 훈련하는 데 기초를 두고 있다.훈련과 추리 과정에서 우리는 용어를 분류하여 모델이 단어의 표면 형식과 용어 데이터베이스에서 제공하는 형식이 정확한 단어의 표면 형식을 동시에 생성하지 않도록 했다.우리가 제출한 내용은 정밀 정합 도량 중 2위를 차지했고 정밀 정합 도량은 모델이 번역에 필요한 용어를 생성하는 능력을 평가했다.', 'de': 'Diese Arbeit beschreibt die Teilaufgabe der Charles University für Terminologie Übersetzung Shared Task bei WMT21. Ziel dieser Aufgabe ist es, ein System zu entwickeln, das bestimmte Begriffe auf Basis einer bereitgestellten Terminologiedatenbank übersetzt und dabei eine hohe Übersetzungsqualität gewährleistet. Wir traten im englisch-französischen Sprachpaar an. Unser Ansatz basiert auf der Bereitstellung der gewünschten Übersetzungen neben dem Eingabesatz und der Schulung des Modells zur Verwendung dieser bereitgestellten Begriffe. Wir lematisieren die Begriffe sowohl während des Trainings als auch während der Inferenz, damit das Modell lernen kann, korrekte Oberflächenformen der Wörter herzustellen, wenn sie sich von den Formularen in der Terminologiedatenbank unterscheiden. Unsere Einreichung belegte den zweiten Platz in der Exact Match Metrik, die die Fähigkeit des Modells bewertet, gewünschte Begriffe in der Übersetzung zu erzeugen.', 'fa': 'این کاغذ پای ماموریت دانشگاه چارلز برای ترجمه ترمینالوژی مشترک کار در WMT21 توصیف می\u200cکند. هدف این وظیفه این است که سیستم\u200cای را طراحی می\u200cکند که شرایط خاص را بر اساس یک داده\u200cهای داده\u200cهای ترمینالوژی ارائه می\u200cدهد، در حالی که حفظ کیفیت ترجمه\u200cای بالا است. ما در جفت زبان انگلیسی و فرانسوی رقابت کردیم. روش ما بر اساس دادن ترجمه\u200cهای خواسته\u200cای کنار جمله\u200cی جمله ورودی و آموزش مدل برای استفاده از این شرایط\u200cها است. ما کلمه\u200cها را در طول تمرین و آلودگی تغییر می\u200cدهیم، تا به مدل اجازه دهیم که چگونه شکل سطح درست از کلمه\u200cها تولید کند، وقتی آنها از شکل\u200cهایی که تولید شده در داده\u200cهای پایگاه\u200cشناسی تغییر می\u200cدهند. تسلیم ما در متریک دقیق درجه دوم بود که توانایی مدل را برای تولید شرایط خواسته در ترجمه ارزیابی می کند.', 'tr': "Bu kagyz Çarls Uniwersitetiň Terminologiýanyň terjime edilişi WMT21'da ýerleşýän zady üçin sub mission hasaplaýar. Bu zadyň maksady şu sistemiň beýleki terjime edilen terminologiýanyň daýasynda daýanýar terjime etmegi we beýleki terjime maksadyny goramakdyr. Biz iňlisçe-fransuzça dil çift bilen ýaryşdyk. Biziň ýaryşymyz isleýän terjimeleri girdi sözläniň ýanynda taýýarlanýar we bu şertleri ulanmak üçin modi eğitilýär. Biz bu sözleri hem okuw we çykyş durmuşynda limatlandyrýarys. Modeliň sözleriniň dogry şeklinde düzgün şekllerini öwrenmesine rugsat bermek üçin, terminologiýada üýtgeden formlaryň üýtgeşiklerinden üýtgeşirip bilýäris. Biziň ilatymyz 2-nji derejede Eýtgetmek üçin 2-nji derejede düzüldi. Bu nusganyň isleýän terjime edilmek üçin nusganyň ukypyny çykýar.", 'sq': 'Ky artikull përshkruan nënmisionin e Universitetit Çarls për përkthimin e Terminologjisë Detyrën e Përbashkët në WMT21. Qëllimi i kësaj detyre është të dizajnojë një sistem që përkthen disa terma bazuar në një bazë të dhënash terminologjike, duke ruajtur cilësinë e lartë të përkthimit të përgjithshëm. We competed in English-French language pair.  Përqasja jonë është bazuar në ofrimin e përkthimeve të dëshiruara së bashku me fjalën e hyrjes dhe trajnimin e modelit për të përdorur këto terma të dhëna. Ne lemmatizojmë termat gjatë trajnimit dhe përfundimit, për të lejuar model in të mësojë si të prodhojë formë të drejta sipërfaqe të fjalëve, kur ato ndryshojnë nga format e dhëna në bazën e terminologjisë. Përdorimi ynë u rendit i dyti në Match Exact metric që vlerëson aftësinë e modelit për të prodhuar termat e dëshiruara në përkthimin.', 'am': 'ይህም ፕሮግራም የቻርልስ ዩንቨርስቲ አካባቢ ሚኒሎጂ ትርጓሜ በWMT21 ላይ የተሰራጨ ስራዎችን ይናገራል፡፡ የዚህ ስራ ዕቅድ በተለየ ትርሚኖሎጂ ዳታቢስ ላይ በተመሳሳይ የተጠቃሚ ትርጉም ጥያቄን በመጠበቅ የተመሳሳይ ግንኙነትን ለመግለጽ ነው፡፡ እንግሊዘኛ-ፈረንሳይ ቋንቋ ሁለትን ተጋጋጅተናል:: የግንኙነታችን ግንኙነታችንን ከመጠቀም ጋር የሚፈልጉትን ትርጓሜዎች ማቅረብ ነው፡፡ በአስተማሪና በሙሉ ውስጥ ያሉትን ቃላትን እንዴት እንዲያሳርፍ እና እንዴት እንደምታስተምሩ እናስታውቃለን፡፡ የፊደል መልዕክታችን በሙሉ ማተርጓም የሚፈቅደውን እውቀት በመፍጠር በሚያስፈልገው የሞዴል ሥልጣን የሚያስተውል ሁለተኛ ነው፡፡', 'sw': 'Gazeti hili linaelezea jukwaa la Chuo Kikuu cha Charles kwa ajili ya tafsiri ya Terminology ilishirikishwa kazi katika WMT21. Lengo la kazi hii ni kutengeneza mfumo ambao unatafsiri vipengele fulani kwa kutumia taarifa za kitamaduni, wakati wakilinda kiwango kikubwa cha kutafsiri jumla. Tumeshindana kwa lugha ya Kiingereza na Kifaransa. Hatua yetu inatokana na kutoa tafsiri zinazohitajika pamoja na hukumu ya input na kufundisha mtindo wa kutumia vipengele hivi vilivyotolewa. Tunaiweka muhimu wote wakati wa mafunzo na ugonjwa, ili kuiruhusu muundo wa kujifunza jinsi ya kutengeneza aina sahihi ya uso wa maneno, pale wanapofautiana na aina zilizotolewa katika database ya tamaduni. Ujumbe wetu ulipandisha sekunde katika mitindo ya Exact Match ambayo ina tathmini uwezo wa muundo wa kutengeneza maneno yanayohitajika katika tafsiri.', 'hy': "Այս թղթին նկարագրում է Չարլզ համալսարանի թերմինոլոգիայի թարգմանման հանձնարարությունը' համագործակցել աշխարհի MT21-ում: Այս խնդիրը նպատակն է նախագծել մի համակարգ, որը թարգմանում է որոշ տերմինոլոգիայի բազայի վրա հիմնված տերմինոլոգիայի որոշ տերմինոլոգիաներ, մինչդեռ պահպանում է ընդհանուր թա Մենք մրցակցեցինք անգլերեն-ֆրանսերեն զույգով: Our approach is based on providing the desired translations alongside the input sentence and training the model to use these provided terms.  Մենք լեմմատիզացնում ենք տերմինները, ինչպես ուսուցման, ինչպես նաև եզրակացության ընթացքում, որպեսզի մոդելը սովորի ստեղծել բառերի ճիշտ մակերևույթի ձևեր, երբ դրանք տարբերվում են տերմինոլոգիայի բազայից: Մեր ներկայացումը երկրորդ դասակարգում էր Անհատուկ համապատասխանության մետրիկայում, որը գնահատում է մոդելի կարողությունը ստեղծել ցանկացած տերմիններ թարգմանության մեջ:", 'az': "Bu kağıt, WMT21'də Terminoloji tercüməsi üçün Charles Universitetinin apa-misyonunu təsdiqləyir. Bu işin məqsədi, təkrar edilmiş terminoloji verilənlərə dayanan bəzi şartları təkrar edən sistemi təkrar etməkdir, böyük təkrar qiymətini qoruyarkən. Biz İngilizce-Fransız dil çift ilə yarışdıq. Bizim yaxınlığımız istədiyi tercümələri giriş cümləsinin yanında təhsil etmək və modelini təhsil etmək üçün təhsil edir. Biz təhsil və təhsil sırasında, modeli sözlərin doğru surat formlarını təhsil etməyi öyrənmək üçün, terminoloji verilən formlardan fərqli olaraq, şəkilləri lemmatizirik. Bizim tətbiqimiz dərəcədə ikinci dərəcədə istisna Match metrikdə, model in in istədiyi şartları tətbiq etmək bacarılığını değerləşdirir.", 'af': "Hierdie papier beskryf Charles Universiteit Submission vir Terminologie Vertaling Gedeelde Opdrag by WMT21. Die doel van hierdie taak is om 'n stelsel te ontwerp wat sekere bedrywe vertaling gebaseer op' n verskaf terminologie databasis, terwyl die beveiliging van hoë heeltemal vertaling kwaliteit. Ons het in Engels-Frans taal paar gemeenskap. Ons toegang is gebaseer op die verskaffing van die versoekte vertalings by die invoer seting en die model onderwerp om hierdie verskaffinge terme te gebruik. Ons lemmatiseer die terme beide tydens die oefening en inferensie, om die model te laat leer hoe om korrekte oorspronklike vorms van die woorde te produseer, wanneer hulle verskil word van die vorms wat in die terminologie databasis verskaf word. Ons onderdrag het tweede in Exact Match metric gelyk wat die moontlikheid van die model beoorsaak om gewende terms in die vertaling te produseer.", 'bn': 'এই প্রবন্ধে চার্লস বিশ্ববিদ্যালয়ের সাব-মিশনের ব্যাখ্যা করেছে তার্মিনোলজি অনুবাদের জন্য বিশেষ করে WM এই কাজের উদ্দেশ্য হচ্ছে একটি সিস্টেম ডিজাইন করার জন্য যা একটি প্রদান করা টার্মিনোলজি ডাটাবেসের ভিত্তিতে নির্দিষ্ট শর্ত অনুব আমরা ইংরেজি ভাষায় প্রতিযোগিতা করেছিলাম। Our approach is based on providing the desired translations alongside the input sentence and training the model to use these provided terms.  টার্মিনোলজি ডাটাবেসে প্রদান করা ফর্ম থেকে তারা ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভি আমাদের আত্মসমর্পণের দ্বিতীয় সেকেন্ডের মিট্রিক ভাষায়, যা অনুবাদের অনুবাদের অনুবাদের ক্ষমতার মূল্যায়ন করে।', 'cs': 'Tento článek popisuje submisi Univerzity Karlovy pro překlad terminologie Shared Task ve WMT21. Cílem tohoto úkolu je navrhnout systém, který překládá určité termíny na základě poskytnuté terminologické databáze při zachování vysoké celkové kvality překladu. Soutěžili jsme v anglicko-francouzském jazykovém páru. Náš přístup je založen na poskytnutí požadovaných překladů vedle vstupní věty a školení modelu používat tyto poskytnuté termíny. Termíny lemmatizujeme jak v průběhu tréninku, tak i v průběhu inference, aby se model naučil vytvářet správné povrchové formy slov, pokud se liší od formulářů uvedených v terminologické databázi. Náš příspěvek byl druhý v metrice Exact Match, která hodnotí schopnost modelu vytvořit požadované termíny v překladu.', 'et': 'Käesolevas dokumendis kirjeldatakse Charles University alammissiooni terminoloogia tõlke jagatud ülesanne WMT21. Selle ülesande eesmärk on kujundada süsteem, mis tõlgib teatavaid termineid pakutava terminoloogiaandmebaasi põhjal, säilitades samas kõrge üldise tõlkekvaliteedi. Me võistlesime inglise-prantsuse keele paaris. Meie lähenemisviis põhineb soovitud tõlkete pakkumisel lisaks sisendlausele ja mudeli koolitamisel kasutama neid tingimusi. Me lemmatiseerime termineid nii koolituse kui ka järelduse käigus, et võimaldada mudelil õppida, kuidas valmistada õigeid pinnavorme sõnadele, kui need erinevad terminoloogia andmebaasis esitatud vormidest. Meie esitus oli täpse vaste mõõdikus teisel kohal, mis hindab mudeli võimet toota soovitud termineid tõlkes.', 'fi': 'Tässä artikkelissa kuvataan Charles University sub-mission for Terminology translation Shared Task at WMT21. Tämän tehtävän tavoitteena on suunnitella järjestelmä, joka kääntää tiettyjä termejä tarjotun terminologiatietokannan pohjalta säilyttäen samalla korkeatasoisen käännöslaadun. Kilpailimme englannin ja ranskan kieliparilla. Lähestymistapamme perustuu halutun käännöksen tuottamiseen syöttölauseen rinnalla ja mallin kouluttamiseen näiden termien käyttöön. Lemmatisoimme termit sekä koulutuksen että päättelyn aikana, jotta malli oppii tuottamaan oikeita pintamuotoja sanoista, kun ne eroavat terminologiatietokannassa olevista lomakkeista. Toimituksemme sijoittui toiseksi Exact Match -mittarissa, joka arvioi mallin kykyä tuottaa haluttuja termejä käännöksessä.', 'bs': 'Ovaj papir opisuje podmisiju Čarlsa Univerziteta za prevod terminologije, zajednički zadatak na WMT21. Cilj ovog zadatka je dizajnirati sistem koji prevodi određene uslove na osnovu pružene terminologije baze podataka, dok čuva visoke kvalitete prevoda. Konkurirali smo se na francuskom i engleskom jeziku. Naš pristup je baziran na pružanju željnih prevoda pored uvodne rečenice i obuku modela za upotrebu ovih pruženih uslova. Lematiziramo termine i tijekom treninga i infekcije, kako bi omogućili model da nauči kako proizvodi ispravne oblike površine riječi, kada se razlikuju od oblika pruženih u bazi podataka terminologije. Naša podnošenja je bila druga u metrici Exact Match, koja procjenjuje sposobnost modela proizvodnje željenih uslova u prevodu.', 'ca': "Aquest article descriu la submissió de la Universitat Charles per la traducció de terminologia Task Compartida a WMT21. L'objectiu d'aquesta tasca és dissenyar un sistema que traduis determinats termes basats en una base de dades de terminologia proporcionada, preservant la qualitat global de la traducció. Vam competir en un parell de llenguatge anglès-francès. El nostre enfocament es basa en proporcionar les traduccions desitjades juntament amb la frase d'entrada i formar el model per utilitzar aquests termes proporcionats. Llamatizem els termes tant durant l'entrenament com durant la inferència, per permetre al model aprendre a produir formes superficials correctes de les paraules, quan difereixen dels formularis proporcionats a la base de datos terminològica. La nostra presentació es va classificar en segon lloc en la mètrica Exact Match que evalua l'habilitat del model de produir termes desitjats en la traducció.", 'sk': 'Ta prispevek opisuje podmisijo Karlove univerze za terminologijo prevajanja v skupni nalogi WMT21. Cilj te naloge je oblikovati sistem, ki prevaja določene izraze na podlagi zagotovljene terminološke zbirke podatkov, hkrati pa ohranja visoko splošno kakovost prevodov. Tekmovala sva v angleško-francoskem jeziku. Naš pristop temelji na zagotavljanju želenih prevodov poleg vhodnega stavka in usposabljanju modela za uporabo teh navedenih izrazov. Izraze lemmatiziramo tako med usposabljanjem kot tudi sklepanjem, da se model nauči ustvarjati pravilne površinske oblike besed, kadar se razlikujejo od obrazcev v terminološki bazi. Naša predložitev se je uvrstila na drugo mesto v merilu natančnega ujemanja, ki ocenjuje sposobnost modela, da ustvari želene izraze v prevodu.', 'jv': 'Peraké iki rambarang mulai apa-misi kanggo terjamahan Terminal goal of this task is to design a sistem that translation the terms given by a given terminal data source, when present Awak dhèwèké mlakèn nganggo barang Inggris-Perancis. Awakdhéwé nggunaké supoyo urip nggawe tarjamahan kanggo ngilangno sistêm kuwi nggawe barang nggawe barang nggawe Awak dhéwé éntuk perusahaan langkung sampek karo ingkang dipatensi lan ijol-ijol Awak dhéwé nggawe sistem segondi nêmên tanggal gawe nêmên "ex Match" nggawe barang nggawe kapan anyar nggawe modèl kanggo ngelarang tambah apik dhéwé.', 'he': "העיתון הזה מתאר את התפקיד של אוניברסיטת צ'ארלס לתרגום טרמינולוגיה משימה משותפת ב-WMT21. The objective of this task is to design a system which translates certain terms based on a provided terminology database, while preserving high overall translation quality.  התחרנו בזוג שפה אנגלית-צרפתית. הגישה שלנו מבוססת על הספק התרגשות הנרצאות לצד משפט הכניסה ואימון הדוגמנית להשתמש בתנאים הנוספים האלה. אנו לומטים את התנאים במהלך האימון והתוצאה, כדי לאפשר למודל ללמוד איך לייצר צורות שטח נכונות של המילים, כאשר הם שונים מהטופסים שנוספים במאגר הנתונים הטרמולוגי. ההצגה שלנו התייצבה שנייה במטריקה של התאמה מדויקת אשר מעריכה את היכולת של המודל לייצר תנאים רצויים בתרגום.", 'ha': "Wannan karatun na describe the sub-Mission of charles University for therminogy translation Shared Tasks at WMT21. Jiyyan wannan aikin ya kasance ana designe wani na'urar da za'a fassara wasu salo a kan danne-danne na tsohon da aka bã su, kuma a tsare tsari da sifar fassarar jumla. Mun yi gauraya a cikin harshen Ingiriya-Faransa. Tsarinmu na kangara a kan ka bãyar da fassarar da aka so sami da salon da aka shigar da shi kuma ya yi kõri da misalin da za'a yi amfani da wannan tsari wanda aka ƙayyade. Munã sarrafa maganar su biyu a lokacin da aka yi wa aikin aikin da kuma aka yi wa motsi ya sanar da jinin za'a ƙãga zafi masu sahiya wa masu kalmõmi, idan sun sãɓã wa tsari da aka ba shi a cikin database na ƙarami. MusuluncinMu na ranar da na biyu a cikin ExExEx Match Metric wanda ke ƙaddara awon motel wa zata tsari cikin fassarar.", 'bo': 'This paper describes Charles University sub-mission for Terminology translation Shared Task at WMT21. The objective of this task is to design a system which translates certain terms based on a provided terminology database, while preserving high overall translation quality. ང་ཚོས་དབྱིན་ཡིག་དང་ཕུད་སྐད་ཀྱི་ཆ་གཅིག་ནང་སྤྲོད་བྱས་པ་ཡིན། ང་ཚོའི་གཟུགས་སྐོར་འདི་དག་གི་ཡིག་སྣོད་ནང་གི་ཚིག We lemmatize the terms both during the training and inference, to allow the model to learn how to produce correct surface forms of the words, when they differ from the forms provided in the terminology database. Our submission ranked second in Exact Match metric which evaluates the ability of the model to produce desired terms in the translation.'}
{'en': 'PROMT Systems for WMT21 Terminology Translation Task', 'es': 'Tarea de traducción de terminología de PROMT Systems for WMT21', 'fr': 'Tâche de traduction terminologique PROMT Systems for WMT21', 'pt': 'Tarefa de Tradução de Terminologia dos Sistemas PROMT para WMT21', 'ar': 'أنظمة PROMT لمهمة ترجمة المصطلحات WMT21', 'ja': 'WMT 21用PROMTシステム用用語翻訳タスク', 'hi': 'WMT21 शब्दावली अनुवाद कार्य के लिए PROMT सिस्टम', 'ru': 'Системы PROMT для задачи перевода терминологии WMT21', 'zh': '用 WMT21 术语译者 PROMT 统', 'ga': 'Córais PROMT do Thasc Aistriúcháin Téarmaíochta WMT21', 'hu': 'PROMT Systems for WMT21 Terminology Translation Task', 'el': 'Συστήματα PROMT για το έργο μετάφρασης ορολογίας WMT21', 'ka': 'WMT21 Terminology Translation Task', 'it': 'PROMT Systems for WMT21 Terminology Translation Task', 'kk': 'WMT21 терминология аудару тапсырмасының PROMT жүйелері', 'mk': 'PROMT Systems for WMT21 Terminology Translation Task', 'lt': 'PROMT Systems for WMT21 Terminology Translation Task', 'ml': 'WMT21 ടെര്\u200dമിനിലോളജി പരിഭാഷപ്പെടുത്തുന്നതിനുള്ള പ്രൊഎംടി സിസ്റ്റംകള്\u200d', 'ms': 'Sistem PROMT untuk Tugas Terjemahan Terminologi WMT21', 'no': 'PROMT- systemer for WMT21 terminologisk omsetjingsprogram', 'mn': 'WMT21 Terminology Translation Task-ын PROMT Systems for WMT21 Terminology Translation Task', 'mt': 'PROMT Systems for WMT21 Terminology Translation Task', 'pl': 'Systemy PROMT dla zadania tłumaczenia terminologii WMT21', 'ro': 'PROMT Systems for WMT21 Terminology Translation Task', 'so': 'PROMT Systems for WMT21 Terminology Translation Task', 'sr': 'PROMT sistemi za WMT21 terminološki prevod zadatak', 'si': 'WMT21 වර්මිනෝලෝගික වාර්ථාව වැඩ සඳහා PROMT පද්ධතිය', 'ta': 'WMT21 முனைமொழிபெயர்ப்பு பணிக்கு PROMT அமைப்புகள்', 'sv': 'PROMT Systems for WMT21 Terminology Translation Task', 'ur': 'WMT21 Terminology Translation Task کے لئے PROMT سیسٹم', 'uz': 'WMT21 Terminalologi tarjima vazifasi uchun PROMT tizimi', 'vi': 'Hệ thống ROM cho dịch hạch địa lý WM', 'nl': 'PROMT-systemen voor WMT21 Terminologie Translation Task', 'bg': 'PROMT Системи за задача за превод на терминология WMT21', 'da': 'PROMT Systems for WMT21 Terminologi Oversættelsesopgave', 'hr': 'PROMT sustavi za WMT21 terminološki prevod zadatak', 'id': 'PROMT Systems for WMT21 Terminology Translation Task', 'fa': 'سیستم PROMT برای ترجمه WMT21 ترمینالوژی', 'ko': 'WMT21 용어 번역 작업 PROMT 시스템', 'sw': 'Mfumo wa PROMT kwa ajili ya Tafsiri ya Utafiti wa Terminalology WMT21', 'de': 'PROMT Systeme für WMT21 Terminologie Translation Task', 'tr': 'WMT21 Terminologiýa terjime Görevi üçin PROMT Sistemleri', 'hy': 'PROMT Systems for WMT21 Terminology Translation Task', 'sq': 'PROMT Systems for WMT21 Terminology Translation Task', 'am': 'ትርጉም', 'az': 'WMT21 Terminoloji T톛rc칲m톛 G칬zm톛si 칲칞칲n PROMT Sisteml톛ri', 'bn': 'WMT21 টার্মিনোলজি অনুবাদ করার জন্য PROMT সিস্টেম', 'ca': 'PROMT Systems for WMT21 Terminology Translation Task', 'bs': 'PROMT sistemi za WMT21 terminološki prevod zadatak', 'af': 'Name', 'cs': 'PROMT systémy pro WMT21 Překlad terminologie', 'et': 'PROMT Systems for WMT21 Terminology Translation Task', 'fi': 'PROMT Systems for WMT21 Terminology Translation Task', 'jv': 'ProMT Sistem kanggo Wêmên Terminal Inogèji Tarjamahan', 'ha': 'KCharselect unicode block name', 'he': 'PROMT Systems for WMT21 Terminology Translation Task', 'sk': 'PROMT sistemi za nalogo prevajanja terminologije WMT21', 'bo': 'PROMT Systems for WMT21 Terminology Translation Task'}
{'en': 'This paper describes the PROMT submissions for the WMT21 Terminology Translation Task. We participate in two directions : ', 'pt': 'Este documento descreve os envios PROMT para a Tarefa de Tradução de Terminologia WMT21. Participamos em duas direções: inglês para francês e inglês para russo. Nossas submissões finais são sistemas neurais baseados em MarianNMT. Apresentamos duas tecnologias para tradução de terminologia: uma modificação do Dinu et al. (2019) abordagem de restrição suave e nossa própria abordagem chamada PROMT Smart Neural Dictionary (SmartND). Alcançamos bons resultados em ambas as direções.', 'ar': 'تصف هذه الورقة التقديمات PROMT لمهمة ترجمة المصطلحات WMT21. نشارك في اتجاهين: الإنجليزية إلى الفرنسية ومن الإنجليزية إلى الروسية. تقديماتنا النهائية هي أنظمة عصبية تعتمد على MarianNMT. نقدم تقنيتين لترجمة المصطلحات: تعديل Dinu et al. (2019) نهج مقيّد ونهجنا الخاص المسمى PROMT Smart Neural Dictionary (SmartND). نحقق نتائج جيدة في كلا الاتجاهين.', 'es': 'Este documento describe los envíos de PROMT para la tarea de traducción terminológica de WMT21. Participamos en dos direcciones: inglés a francés e inglés a ruso. Nuestras presentaciones finales son sistemas neuronales basados en MariannMT. Presentamos dos tecnologías para la traducción de terminología: una modificación del enfoque de restricción suave de Dinu et al. (2019) y nuestro propio enfoque llamado PROMT Smart Neural Dictionary (SmartND). Logramos buenos resultados en ambas direcciones.', 'fr': "Cet article décrit les soumissions PROMT pour la tâche de traduction terminologique WMT21. Nous participons dans deux directions\xa0: de l'anglais vers le français et de l'anglais vers le russe. Nos soumissions finales concernent les systèmes neuronaux basés sur MariannMT. Nous présentons deux technologies pour la traduction terminologique\xa0: une modification de l'approche à contraintes souples de Dinu et al. (2019) et notre propre approche appelée PROMT Smart Neural Dictionary (SmartND). Nous obtenons de bons résultats dans les deux sens.", 'zh': '本文引 WMT21 术语译者 PROMT 交。 与二方:英语至法语、英语至俄语。 终言基于MarianNMT之神经系统。 二术语译术:Dinu等(2019)软约之法,自号PROMT智能神经词典(SmartND)法。 两处俱成。', 'ja': 'この論文では、WMT 21用語翻訳タスクのPROMT提出について説明します。私たちは、英語からフランス語、英語からロシア語の2つの方向性で参加します。最終的に提出されたのはMarianNMTベースのニューラルシステムです。私たちは、Dinu et al .（ 2019 ）のソフト制約アプローチと、PROMT Smart Neural Dictionary （ SmartND ）と呼ばれる独自のアプローチの2つの用語翻訳技術を提示しています。双方向で良好な成績を収めています。', 'hi': 'यह पेपर WMT21 शब्दावली अनुवाद कार्य के लिए PROMT सबमिशन का वर्णन करता है। हम दो दिशाओं में भाग लेते हैं: अंग्रेजी से फ्रेंच और अंग्रेजी से रूसी। हमारे अंतिम प्रस्तुतियाँ MarianNMT-आधारित तंत्रिका प्रणालियों रहे हैं. हम शब्दावली अनुवाद के लिए दो प्रौद्योगिकियों को प्रस्तुत करते हैं: दीनू एट अल (2019) का एक संशोधन नरम-विवश दृष्टिकोण और हमारे अपने दृष्टिकोण को प्रोएमटी स्मार्ट न्यूरल डिक्शनरी (स्मार्टएनडी) कहा जाता है। हम दोनों दिशाओं में अच्छे परिणाम प्राप्त करते हैं।', 'ru': 'В этой статье описываются материалы PROMT для задачи перевода терминологии WMT21. Мы участвуем в двух направлениях: с английского на французский и с английского на русский. Наши окончательные представления - это нейронные системы на основе MarianNMT. Мы представляем две технологии для перевода терминологии: модификацию подхода Dinu et al. (2019) с мягкими ограничениями и наш собственный подход под названием PROMT Smart Neural Dictionary (SmartND). Мы добиваемся хороших результатов в обоих направлениях.', 'ga': 'Déanann an páipéar seo cur síos ar na haighneachtaí PROMT don Tasc Aistriúcháin Téarmaíochta WMT21. Glacaimid páirt i dhá threo: Béarla go Fraincis agus Béarla go Rúisis. Is iad na haighneachtaí deiridh atá againn ná córais néaracha atá bunaithe ar MarianNMT. Cuirimid dhá theicneolaíocht i láthair le haghaidh aistriúcháin téarmeolaíochta: modhnú ar an Dinu et al. (2019) cur chuige bog-srianta agus ár gcur chuige féin ar a dtugtar PROMT Smart Neural Dictionary (SmartND). Bainimid torthaí maithe amach sa dá threo.', 'el': 'Η παρούσα εργασία περιγράφει τις υποβολές του PROMT για το έργο μετάφρασης ορολογίας WMT21. Συμμετέχουμε σε δύο κατευθύνσεις: Αγγλικά προς Γαλλικά και Αγγλικά προς Ρωσικά. Οι τελικές μας υποβολές είναι νευρωνικά συστήματα βασισμένα στο MarianNMT. Παρουσιάζουμε δύο τεχνολογίες για τη μετάφραση ορολογίας: μια τροποποίηση της προσέγγισης μαλακών περιορισμών και τη δική μας προσέγγιση που ονομάζεται Έξυπνο Νευρικό Λεξικό (Έξυπνο Νευρικό Λεξικό). Επιτυγχάνουμε καλά αποτελέσματα και στις δύο κατευθύνσεις.', 'hu': 'Ez a tanulmány a WMT21 terminológiai fordítási feladathoz kapcsolódó PROMT beadványokat ismerteti. Két irányban veszünk részt: angolul franciáig és angolul oroszul. A végső beadványunk MarianNMT-alapú idegrendszerek. Két terminológiai fordítási technológiát mutatunk be: a Dinu et al. (2019) soft-limited megközelítésének módosítása és a PROMT Smart Neural Dictionary (SmartND) nevű saját megközelítésünk. Mindkét irányban jó eredményeket érünk el.', 'it': "Questo articolo descrive le proposte PROMT per il WMT21 Terminology Translation Task. Partecipiamo in due direzioni: dall'inglese al francese e dall'inglese al russo. I nostri contributi finali sono sistemi neurali basati su MarianNMT. Presentiamo due tecnologie per la traduzione terminologica: una modifica dell'approccio soft-constrained Dinu et al. (2019) e il nostro approccio chiamato PROMT Smart Neural Dictionary (SmartND). Otteniamo buoni risultati in entrambe le direzioni.", 'ka': 'WMT21 ტერმინოლოგიის გადაწყვეტის რაოდენობისთვის PROMT გადაწერა. ჩვენ ორი მხარდაჭირდებით: ანგლისური ფრანგური და ანგლისური პროსური მხარდაჭირდებით. ჩვენი საბოლოო წარმოდგენები არის მარიანNMT-დაბათებული ნეიროლური სისტემი. ჩვენ ტერმინოლოგიის გასაგულისხმებისთვის ორი ტექნოლოგია: Dinu et al. (2019) სტრუქტური დარწყვებული პროგრამის შეცვლა და ჩვენი პროგრამის გასაგულისხმები PROMT Smart Neural Dictionary (SmartND). ჩვენ მივიღეთ კარგი შედეგები ორივე მხარეს.', 'mk': 'Овој документ ги опишува поднесувањата на PROMT за WMT21 терминолошката преведувачка задача. Учествуваме во две насоки: англиски на француски и англиски на руски. Our final submissions are MarianNMT-based neural systems.  Презентираме две технологии за терминолошки превод: модификација на пристапот на Дину и други (2019) со меки ограничувања и нашиот сопствен пристап наречен PROMT Smart Neural Dictionary (SmartND). Добиваме добри резултати во двете насоки.', 'kk': 'Бұл қағаз WMT21 терминологиялық аудару тапсырмасының PROMT жіберілуін анықтайды. Біз екі бағытта қатынасыз: ағылшынша мен ағылшын тіліне қатынасыз. Соңғы келтіріміз - MarianNMT негіздеген невралдық жүйелер. Біз терминология аудармасының екі технологияларын таңдаймыз: Dinu et al. (2019) бағдарламалы шектелген жағдай және өзіміздің PROMT Smart Neural Dictionary (SmartND). Екі бағытта жақсы нәтижелерді жеткіземіз.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjonijiet tal-PROMT għall-Kompitu tat-Traduzzjoni tat-Terminoloġija WMT21. Nipparteċipaw f’żewġ direzzjonijiet: l-Ingliż għall-Franċiż u l-Ingliż għar-Russu. Is-sottomissjonijiet finali tagħna huma sistemi newrali bbażati fuq MarianNMT. Aħna nippreżentaw żewġ teknoloġiji għat-traduzzjoni tat-terminoloġija: modifika tal-approċċ ta’ Dinu et al. (2019) b’restrizzjoni mhux vinkolanti u l-approċċ tagħna stess imsejjaħ Dikjarnarju Newrali Intelliġenti (SmartND). Nikisbu riżultati tajbin fiż-żewġ direzzjonijiet.', 'ms': 'Kertas ini menggambarkan penghantaran PROMT untuk Tugas Terjemahan Terminologi WMT21. Kami berpartisipasi dalam dua arah: bahasa Inggeris ke Perancis dan bahasa Inggeris ke Rusia. Penghantaran terakhir kita adalah sistem saraf berasaskan MarianNMT. Kami perkenalkan dua teknologi untuk terjemahan terminologi: pengubahsuaian pendekatan Dinu et al. (2019) soft-constrained dan pendekatan kami sendiri yang dipanggil PROMT Smart Neural Dictionary (SmartND). Kita mencapai keputusan yang baik dalam kedua-dua arah.', 'mn': 'Энэ цаас WMT21 Terminology Translation Task-ийн PROMT-ын дамжуулалтыг тайлбарладаг. Бид хоёр талд оролцож байна: Англи, Француз, Англи, Орос хүртэл оролцож байна. Манай төгсгөлийн давталт бол MarianNMT-д суурилсан мэдрэлийн систем юм. Бид терминологийн орчуулалтын хоёр технологийг тайлбарлаж байна: Dinu et al. (2019) бага зэрэг хязгаарлагдсан арга зам болон өөрсдийн PROMT ухаантай мэдрэлийн сөрөгч (SmartND) гэдэг арга зам. Бид хоёр талд сайн үр дүн гаргадаг.', 'no': 'Denne papiret skildrar PROMT- tilføringane for WMT21 terminologisk omsetjingsverktøyet. Vi deltar i to retningar: engelsk til fransk og engelsk til russisk. Våre siste oppføringar er MarianNMT-basert neiralsystemet. Vi presenterer to teknologiar for terminologisk omsetjing: ein endring av Dinu et al. (2019) måk begrenset tilnærming og vår eigen tilnærming kalla PROMT Smart Neural Dictionary (SmartND). Vi oppnår gode resultat i begge retningar.', 'pl': 'Niniejszy artykuł opisuje zgłoszenia PROMT do zadania tłumaczenia terminologii WMT21. Uczestniczymy w dwóch kierunkach: angielski na francuski i angielski na rosyjski. Nasze ostatnie zgłoszenia to układy neuronowe oparte na MarianNMT. Prezentujemy dwie technologie tłumaczenia terminologii: modyfikację podejścia Dinu et al. (2019) miękkie ograniczenia oraz własne podejście o nazwie PROMT Smart Neural Dictionary (SmartND). Osiągamy dobre wyniki w obu kierunkach.', 'ml': 'ഈ പത്രത്തില്\u200d WMT21 ടെര്\u200dമിനിലോളജി പരിഭാഷ ടാസ്കിനുള്ള പ്രൊഎംടി സജ്ജീകരണങ്ങള്\u200d വിശദീകരിക്കുന്നു. രണ്ടു വഴികളില്\u200d ഞങ്ങള്\u200d പങ്കുചേര്\u200dക്കുന്നു; ഇംഗ്ലീഷിലേക്കും ഇംഗ്ലീഷിലേക്കും റഷ്യനിലേക നമ്മുടെ അവസാന കീഴടങ്ങള്\u200d മരിയാന്\u200dഎംഎംടി അടിസ്ഥാനമായ നെയൂറല്\u200d സിസ്റ്റമാണ്. ഞങ്ങള്\u200d ടെര്\u200dമിനോളജി പരിഭാഷണത്തിനായി രണ്ടു സാങ്കേതികവിദ്യയെ കാണിക്കുന്നു: ദിനു എറ്റ് അലിന്റെ മാറ്റം വരുത്തുന്നു. 2019, സാമ്പത്തില്\u200d നിര്\u200dബന് രണ്ട് വഴിയില്\u200d നമുക്ക് നല്ല ഫലങ്ങള്\u200d നേടും.', 'ro': 'Această lucrare descrie depunerile PROMT pentru misiunea WMT21 de traducere terminologică. Participăm în două direcții: din engleză în franceză și din engleză în rusă. Ultimele noastre propuneri sunt sisteme neuronale bazate pe MarianNMT. Prezentăm două tehnologii pentru traducerea terminologiei: o modificare a abordării soft-constrânged Dinu et al. (2019) și propria noastră abordare numită PROMT Smart Neural Dictionary (SmartND). Obţinem rezultate bune în ambele direcţii.', 'sr': 'Ovaj papir opisuje podatke PROMT za WMT21 terminološki prevod zadatak. Mi sudjelujemo u dva smjera: engleski na francuski i engleski na ruski. Naši poslednji podaci su na MarianNMT-bazirani neuralni sistemi. Predstavljamo dve tehnologije za prevod terminologije: modifikacija mekog ograničenog pristupa Dinu et al. (2019) i našeg vlastitog pristupa zvanog PROMT Pametan Neuralni rečnik (SmartND). Dobili smo dobre rezultate u oba smjera.', 'so': 'Warqadan waxaa ku qoran warqadda PROMT oo loo soo diro shaqo turjumista WMT21. Waxaannu ka qeybqaadannaa laba kooxood: Ingiriis ilaa Faraansiis iyo Ingiriis ilaa Ruush. Guushyadeena ugu dambeeya waa nidaamka neurada ee ku saleysan MarianNMT. Waxaynu soo bandhignaa laba teknolojiyo oo turjumista terminology: beddelinta Dinu et al. (2019) qaabab hoos-qasab ah iyo qaab-qaab gaar ah oo loo magacaabay PROMT luqada qaranka ah (SmartND). Waxaynu helaynaa midhaha wanaagsan labada dhinac.', 'lt': 'Šiame dokumente aprašomi PROMT pasiūlymai dėl WMT21 terminologijos vertimo užduoties. Dalyvaujame dviem kryptimis: anglų kalba prancūzų kalba, anglų kalba rusų kalba. Mūsų galutiniai pranešimai yra MarianNMT pagrįstos neurosistemos. Mes pristatome dvi terminologijos vertimo technologijas: Dinu et al. (2019 m.) pakeitimą „soft-constrained approach“ ir mūsų požiūrį „PROMT Smart Neural Dictionary“ (SmartND). Abiem kryptimis pasiekiame gerų rezultatų.', 'sv': 'Denna uppsats beskriver PROMT-inlämningarna för WMT21 Terminologi Translation Task. Vi deltar i två riktningar: engelska till franska och engelska till ryska. Våra sista bidrag är MarianNMT-baserade neurala system. Vi presenterar två tekniker för terminologiöversättning: en modifiering av Dinu et al. (2019) soft-restrictived approach och vårt eget tillvägagångssätt kallat PROMT Smart Neural Dictionary (SmartND). Vi uppnår goda resultat i båda riktningarna.', 'si': 'මේ පැත්තේ WMT21 වර්මිනෝලික වාර්ථාව වැඩකට PROMT පිළිබඳය විවෘත කරනවා. අපි පැත්තක් දෙකක් පැත්තක් වෙනුවෙන්: ඉංග්\u200dරීසියාව ෆ්\u200dරෑන්ස් සහ ඉංග්\u200dරීසියාව ර අපේ අන්තිම පිළිගන්නේ මේරියාන්NMT පද්ධතියේ න්\u200dයූරල් පද්ධතිය. අපි තර්මාන්\u200dයවිද්\u200dයාවයේ අවවාදය සඳහා තාක්ෂණාව දෙකක් පෙනුම් කරනවා: ඩිනු එට් අල්. අපි හොඳ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d', 'ur': 'This paper describes the PROMT submissions for the WMT21 Terminology Translation Task. ہم دو طریقوں میں شرکت کرتے ہیں: انگلیسی اور انگلیسی سے روسی سے۔ ہماری آخری مسلمانات مریان NMT بنیادی نیورال سیستم ہیں۔ ہم ترمینلوژی ترجمہ کے لئے دو تکنولوژی پیش کرتے ہیں: دینو اور ال کی تغییر۔ ہم دونوں طریقوں میں اچھے نتیجے حاصل کرتے ہیں.', 'ta': 'WMT21 மொழிபெயர்ப்பு மொழிபெயர்ப்பு பணிக்கு PROMT ஒப்புகளை இந்த தாள் விளக்குகிறது. நாம் இரண்டு திசைகளில் பகிர்ந்து கொள்கிறோம்: ஆங்கிலத்தில் பிரெஞ்சு மற்றும் ஆங்கிலத்தி எங்கள் இறுதியாக கட்டளைகள் மேரியன் NMT-அடிப்படையிலான புதிய முறைமைகள். நாங்கள் முறை மொழிபெயர்ப்பிற்கு இரண்டு தொழில்நுட்பத்தை கொண்டுள்ளோம்: Dinu et al. (2019) மென்மையான கட்டுப்படுத்தப்பட்ட நுழைமாற்றம் மற்றும் நம்முடை நாம் இரண்டு திசையில் நல்ல முடிவுகளை அடைக்கிறோம்.', 'vi': 'Tờ giấy này mô tả những kiến nghị nâng cao về dịch hạch WM t2 1. Chúng tôi tham gia hai hướng: Tiếng Anh, Pháp, Anh, Nga. Phần kết của chúng ta là hệ thần kinh dựa vào Mariana. Chúng tôi giới thiệu hai công nghệ dịch thuật ngữ thuật: một sự thay đổi của Dinu et al. (ng99) tiếp cận bị hạn chế mềm và phương pháp riêng được gọi là Quỹ Tự Do Thái Công Lý Công Lý Công Lý Công Nghệ bạt. Chúng ta đạt được kết quả tốt theo cả hai hướng.', 'uz': "Name Biz ikki boshqa birga ega bo'lishimiz: Inglizcha va ingliz tiliga Ruscha tiliga. Bizning oxirgi imkoniyatlar MarianNMT asosida neyrol tizimlarimiz. Biz terminalogik tarjima uchun ikkita teknologiyani hozirganamiz: Dinu et (2019) o'zgarishni o'zgartirish uchun o'zgartirish va bizning o'zimiz PROMT Smart Neural Lugʻat (SmartND) deb nomlangan. Biz ikkita ta'sirga yaxshi natijalarni bajaramiz.", 'bg': 'Настоящата статия описва предложенията на PROMT за задачата за превод по терминология WMT21. Участваме в две посоки: английски на френски и английски на руски. Последните ни предложения са базирани на Мариан НМТ невронни системи. Представяме две технологии за превод на терминологията: модификация на подхода с меки ограничения Дину и др. (2019) и наш собствен подход, наречен ПРОМТ интелигентен неврален речник (SmartND). Ние постигаме добри резултати и в двете посоки.', 'hr': 'Ovaj papir opisuje podatke PROMT-a za zadatak WMT21 terminologije za prevod. Mi sudjelujemo u dva smjera: engleski na francuski i engleski na ruski. Naši posljednji podaci su na MarianNMT-u bazirani nervni sustavi. Predstavljamo dvije tehnologije za prevod terminologije: izmjena mekog ograničenog pristupa Dinu et al. (2019) i našeg vlastitog pristupa zvanog PROMT pametnog neurološkog rečnika (SmartND). Dobili smo dobre rezultate u oba smjera.', 'da': 'Denne artikel beskriver PROMT-indsendelserne til WMT21 Terminologi Oversættelsesopgaven. Vi deltager i to retninger: engelsk til fransk og engelsk til russisk. Vores endelige indlæg er MarianNMT-baserede neurale systemer. Vi præsenterer to teknologier til terminologioversættelse: en ændring af Dinu et al. (2019) soft-limited tilgang og vores egen tilgang kaldet PROMT Smart Neural Dictionary (SmartND). Vi opnår gode resultater i begge retninger.', 'nl': 'Dit artikel beschrijft de PROMT inzendingen voor de WMT21 Terminologie Translation Task. We nemen deel in twee richtingen: Engels naar Frans en Engels naar Russisch. Onze laatste inzendingen zijn MarianNMT-gebaseerde neurale systemen. We presenteren twee technologieën voor terminologie vertaling: een aanpassing van de Dinu et al. (2019) soft-limited aanpak en onze eigen aanpak genaamd PROMT Smart Neural Dictionary (SmartND). We bereiken goede resultaten in beide richtingen.', 'de': 'Diese Arbeit beschreibt die PROMT-Einreichungen für die WMT21 Terminologie Translation Task. Wir nehmen in zwei Richtungen teil: Englisch zu Französisch und Englisch zu Russisch. Unsere letzten Einreichungen sind MarianNMT-basierte neuronale Systeme. Wir stellen zwei Technologien für die Terminologie-Übersetzung vor: eine Modifikation des Dinu et al. (2019) Soft-Constrainted-Ansatzes und unseren eigenen Ansatz namens PROMT Smart Neural Dictionary (SmartND). Wir erzielen gute Ergebnisse in beide Richtungen.', 'id': 'This paper describes the PROMT submissions for the WMT21 Terminology Translation Task.  Kami berpartisipasi dalam dua arah: Inggris ke Perancis dan Inggris ke Rusia. Pengiriman terakhir kami adalah sistem saraf berbasis MarianNMT. Kami mempersembahkan dua teknologi untuk terjemahan terminologi: sebuah modifikasi dari pendekatan Dinu et al. (2019) soft-constrained dan pendekatan kita sendiri disebut PROMT Smart Neural Dictionary (SmartND). Kita mencapai hasil yang baik dalam kedua arah.', 'fa': 'این کاغذ تحویل PROMT برای ترجمه\u200cشناسی WMT21 را توصیف می\u200cکند. ما در دو مسیر شرکت می کنیم: انگلیسی به فرانسوی و انگلیسی به روسی. آخرین تسلیم ما سیستم عصبی مریان NMT است. ما دو تکنولوژی برای ترجمه ترمینالوژی را پیشنهاد می\u200cکنیم: تغییر دستور نرم و محدودیت دینو و الگوی خودمان به نام PROMT Smart Neural Dictionary (SmartND). ما نتیجه\u200cهای خوب در هر دو مسیر می\u200cرسیم.', 'sw': 'Gazeti hili linaelezea ujumbe wa PROMT kwa ajili ya kazi ya Tafsiri ya Terminalology WMT21. Tunashiriki katika maelekezo mawili: Kiingereza hadi Kifaransa na Kiingereza hadi Urusi. Mawasiliano yetu ya mwisho ni mifumo yenye msingi wa MarianNMT. Tunaweza kutoa teknolojia mbili kwa kutafsiri utafiti wa maadili: mabadiliko ya Dinu na al. (2019) mbinu nyepesi na mbinu yetu yenyewe inaitwa Dictionary Small Neural (SmartND). Tunafanya matokeo mazuri katika njia zote mbili.', 'af': 'Hierdie papier beskryf die PROMT onderskrywings vir die WMT21 Terminologie Vertaling Opdrag. Name Ons deel in twee rigtings: Engels tot Frans en Engels tot Russies. Ons eindelike onderstellings is MarianNMT-gebaseerde neurale stelsels. Ons stel twee teknologies voor terminologies vertaling: â\x80\x99n verandering van die Dinu et al. (2019) sagte-beheinde toegang en ons eie toegang genoem PROMT Smart Neural Dictionary (SmartND). Ons bereik goeie resultate in beide rigtings.', 'tr': 'Bu kagyz WMT21 Terminologiýa terjime zady üçin PROMT arzanlaryny tassyýar. Biz iňlisçe fransuzça we iňlisçe Rusça bäri goşulýarys. Biziň soňky teslimatlarymyz MarianNMT-dan tabanly näral sistemalardyr. Biz terminologa terjime etmek üçin iki tehnologiýany görkeýäris: Dinu et al. (2019) ýumuş süýtgeli ýazşymyz we öz ýazşymyz PROMT Smart Neural Sözlük (SmartND). Biz ikimiz tarapynda gowy netijede ýetip bilýäris.', 'sq': 'Ky dokument përshkruan paraqitjet PROMT për detyrën e përkthimit të terminologjisë WMT21. Ne marrim pjesë në dy drejtime: anglisht në francez dhe anglisht në rusë. Paraqitjet tona përfundimtare janë sistemet neuronale të bazuara në NMT Marian. We present two technologies for terminology translation: a modification of the Dinu et al. (2019) soft-constrained approach and our own approach called PROMT Smart Neural Dictionary (SmartND).  Ne arrijmë rezultate të mira në të dy drejtimet.', 'am': 'This paper describes the PROMT submissions for the WMT21 Terminology Translation Task.  በሁለት መንገዶች እንጋጠማለን፤ እንግሊዘኛ ወደ ፈረንሳይ እና እንግሊዘኛ ወደ ሩሽኛ ነው፡፡ የኋለኛይቱ መልዕክታችን ማርያንያን NMT-based የnerural systems ናቸው፡፡ የዲን እና አል (2019) አቅራቢያ ስርዓት እና የፕOMT Smart የሕግ መዝገብ (SmartND) የሚባል የራሳችን ሥርዓት እናስቀራለን፡፡ በሁለቱ መንገዶች መልካም ፍሬዎችን እናደርጋለን፡፡', 'ko': '이 문서에서는 WMT21 용어 번역 작업의 PROMT 제출을 설명합니다.우리는 두 가지 방향에 참여한다. 그것이 바로 영어 대 프랑스어와 영어 대 러시아어이다.우리가 최종적으로 제출한 것은 Marian NMT 기반의 신경계이다.우리는 두 가지 용어 번역 기술을 소개했는데 그것이 바로 Dinu 등(2019)의 소프트 제약 방법의 개선과 우리 자신의 방법인 PROMT 스마트 신경 사전(SmartND)이다.우리는 두 방면에서 모두 양호한 성과를 거두었다.', 'hy': 'Այս հոդվածը նկարագրում է PROMT-ի ներկայացումները World MT21 տերմինոլոգիայի թարգմանման գործի համար: Մենք մասնակցում ենք երկու ուղղություններում. անգլերեն ֆրանսերեն, անգլերեն ռուսերեն: Մեր վերջնական ներկայացումները ՄարիանՆՄԹ-ի հիմնված նյարդային համակարգերն են: Մենք ներկայացնում ենք երկու տեխնոլոգիա տերմինոլոգիայի թարգմանման համար՝ Դինու և այլների (2019 թվականի) փոփոխությունը՝ փափուկ սահմանափակված մոտեցումը և մեր սեփական մոտեցումը, որը կոչվում է PROMT խելացի նյարդային բառարան (Խել Մենք երկու ուղղություններում լավ արդյունքներ ենք ստանում:', 'az': 'Bu kağıt WMT21 Terminoloji Çeviri Taskinin PROMT təbliğlərini təsdiqləyir. Biz iki tərəfə: İngilizce Fransızca və İngilizce Rusya ilə iştirak edirik. Əvvəlki təbliğlərimiz MarianNMT tabanlı nöral sistemləridir. Biz terminoloji tercüməsi üçün iki teknoloji təşkil edirik: Dinu et al. (2019) yumuşaq müəyyən approach və PROMT Smart Neural Dictionary (SmartND). Biz hər iki tərəfdə yaxşı nəticələri başarırıq.', 'bn': 'এই পত্রিকাটি WMT21 টার্মিনিলজি অনুবাদ কাজের জন্য প্রিওএমটি প্রতিবেদনের ব্যাখ্যা করেছে। আমরা দুটি দিকে অংশগ্রহণ করি: ইংরেজি থেকে ফরাসি এবং ইংরেজি থেকে রুশ থেকে ইংরেজি থেকে ইংরেজি  আমাদের শেষ প্রতিক্রিয়া হচ্ছে মারিয়ানএমটি ভিত্তিক নিউরেল সিস্টেম। আমরা টার্মিনোলজি অনুবাদের জন্য দুটি প্রযুক্তি উপস্থাপন করেছি: দিনু এন্ট আল (২০১৯) একটি পরিবর্তন এবং আমাদের নিজেদের পদক্ষেপ প প্রোমেট স্মার্ট নিউরেল অভ আমরা দুই দিকেই ভাল ফলাফল অর্জন করি।', 'cs': 'Tento článek popisuje podání PROMT pro WMT21 Terminologie Translation Task. Účastníme se dvou směrů: angličtina do francouzštiny a angličtina do ruštiny. Naše poslední podání jsou neuronové systémy založené na MarianNMT. Představujeme dvě technologie pro překlad terminologie: modifikaci přístupu Dinu et al. (2019) soft-limited a vlastní přístup PROMT Smart Neural Dictionary (SmartND). Dosahujeme dobrých výsledků v obou směrech.', 'et': 'Käesolevas dokumendis kirjeldatakse PROMT esitusi WMT21 terminoloogia tõlke ülesande jaoks. Osaleme kahes suunas: inglise keeles prantsuse keeles ja inglise keeles vene keeles. Meie viimased avaldused on MarianNMT-põhised närvisüsteemid. Esitleme terminoloogia tõlkimiseks kahte tehnoloogiat: Dinu jt. (2019) pehme piiratud lähenemisviisi modifikatsiooni ja meie enda lähenemisviisi PROMT Smart Neural Dictionary (SmartND). Me saavutame häid tulemusi mõlemas suunas.', 'bs': 'Ovaj papir opisuje prijave PROMT za zadatak WMT21 terminologije za prevod. Mi sudjelujemo u dva smjera: engleski na francuski i engleski na ruski. Naši poslednji podaci su na MarianNMT-bazirani nervni sistemi. Predstavljamo dvije tehnologije za prevod terminologije: modifikacija mekog ograničenog pristupa Dinu et al. (2019) i našeg vlastitog pristupa zvanog PROMT Smart Neural Dictionary (SmartND). Dobili smo dobre rezultate u oba smjera.', 'ca': "Aquest article descriu les presentacions PROMT per a la tasca de traducció de terminologia WMT21. Participem en dues direccions: anglès a francès i anglès a rus. Les nostres presentacions finals són sistemes neuronals basats en MarianNMT. Presentam dues tecnologies de traducció terminològica: una modificació de l'enfocament de Dinu et al. (2019) i el nostre propi enfocament anomenat PROMT Smart Neural Dictionary (SmartND). Obtenim bons resultats en ambdues direccions.", 'fi': 'Tässä artikkelissa kuvataan PROMT submissions for the WMT21 Terminology Translation Task. Osallistumme kahteen suuntaan: englanti ranskaan ja englanti venäjäksi. Viimeiset esityksemme ovat MarianNMT-pohjaisia hermojärjestelmiä. Esittelemme kaksi teknologiaa terminologian kääntämiseen: Dinu et al. (2019) -menetelmän modifiointi ja oma lähestymistapamme nimeltään PROMT Smart Neural Dictionary (SmartND). Saavutamme hyviä tuloksia molempiin suuntiin.', 'ha': 'Wannan takardan na describe the PROMT elements for the WMT21 Translate Mission. Munã raba cikin hanyõyi biyu: Ingiriya zuwa Faransa da Ingiriya zuwa Ruushi. MusuluncinMu na ƙarshen su ne tsarin neura na MarianNMT. Tuna halatar da technogi biyu wa translation of therminogy: a modification of the dinu et al. (2019) matsayin-binden mazaɓa da hanyarmu na kanana da sunan PROMT Smart Neural Dictionary (SmartND). Munã sãmu fassara mai kyau a biyu.', 'he': 'This paper describes the PROMT submissions for the WMT21 Terminology Translation Task.  We participate in two directions: English to French and English to Russian.  Our final submissions are MarianNMT-based neural systems.  We present two technologies for terminology translation: a modification of the Dinu et al. (2019) soft-constrained approach and our own approach called PROMT Smart Neural Dictionary (SmartND).  We achieve good results in both directions.', 'jv': 'Pesene iki rambarang nggawe tarjamahan ProMT kanggo ngilangno WWT 22 Terminal Awakdhéwé mengko tanggal durung: Inggris kanggo Perancis karo Inggris kanggo Rusis. Awak dhéwé mulai gawe sistem sing dibenakake marianNMT Awak dhéwé nglebok teknêlogi sing dibutêr terjamahan: turjamahan kanggo Dinu et al (2011) dadi ngêmêr-dérambaran sing nyebuté karo nganggep ngêmêr terjamahan sing nyebuté "ProMT Nom Neral Diyekunêm (SMND). Awak dhéwé ngerasah barang langkung éwé Kasunyatan', 'sk': 'Ta prispevek opisuje prispevke PROMT za nalogo prevajanja terminologije WMT21. Sodelujemo v dveh smereh: angleščina v francoščino in angleščina v ruščino. Naši zadnji prispevki so živčni sistemi MarianNMT. Predstavljamo dve tehnologiji za prevajanje terminologije: modifikacijo mehkega pristopa Dinu et al. (2019) in lastni pristop PROMT Smart Nevral Dictionary (SmartND). Dosegamo dobre rezultate v obeh smereh.', 'bo': 'WMT21 མཐའ་སྡོད་རིམ་དབྱིབས་སྤྲོད་ཀྱི་བྱ་ཚིག་ལ་PROMT་གསལ་བཤད་ཀྱི་ཡོད་པ་དེ་རྟོགས་འདོད་ཡོད། ང་ཚོས་དབྱིན་ཡིག་དང་དབྱིན་ཡིག་གཉིས་ཀྱི་གནད་སྡུད་གཉིས་ནང་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་མཐའ་མཇུག་གི་མཇུག་གི་ཞབས་ཞུ་ནི་མེ་རི་ཡིན་NMT་ལ་གཞི་བརྟེན་ནས་སྐྱེས་བ་མ་ལག་རེད། We present two technologies for terminology translation: a modification of the Dinu et al. (2019) soft-constrained approach and our own approach called PROMT Smart Neural Dictionary (SmartND). ང་ཚོས་གདོང་ཕྱོགས་གཉིས་པ་ནང་གི་འབྲས་འབོར་སྐྱོན་པ་རེད།'}
{'en': 'SYSTRAN @ WMT 2021 : Terminology Task', 'ar': 'SYSTRAN @ WMT 2021: مهمة المصطلحات', 'fr': 'SYSTRAN @ WMT 2021\xa0: Tâche terminologique', 'es': 'SYSTRAN @ WMT 2021: Tarea terminológica', 'pt': 'SYSTRAN @ WMT 2021: Tarefa de Terminologia', 'ja': 'SYSTRAN @ WMT 2021: Terminology Task', 'ru': 'SYSTRAN @ WMT 2021: Терминологическая задача', 'hi': 'SYSTRAN @ WMT 2021: शब्दावली कार्य', 'zh': 'SYSTRAN @ WMT 2021:术语任', 'ga': 'SYSTRAN @ WMT 2021: Tasc Téarmaíochta', 'ka': 'SYSTRAN @ WMT 2021: Terminology Task', 'hu': 'SYSTRAN @ WMT 2021: Terminológiai feladat', 'el': 'SYSTRAN.WMT 2021: Εργασία ορολογίας', 'it': 'SYSTRAN @ WMT 2021: Compito Terminologico', 'lt': 'SYSTRAN @ WMT 2021: Terminologijos užduotis', 'kk': 'SYSTRAN @ WMT 2021: Terminology Task', 'mk': 'SYSTRAN @ WMT 2021: Терминолошка задача', 'ml': 'SYSTRAN@ WMT 2021: Terminology Task', 'mt': 'SYSTRAN @ WMT 2021: Kompitu Terminoloġiku', 'ms': 'SYSTRAN @ WMT 2021: Tugas Terminologi', 'mn': 'SYSTRAN @ WMT 2021: Terminology Task', 'no': 'SYSTRAN @ WMT 2021: Terminology Task', 'pl': 'SYSTRAN.WMT 2021: Zadanie terminologiczne', 'sr': 'SYSTRAN @ WMT 2021: Terminološki zadatak', 'ro': 'SYSTRAN @ WMT 2021: Sarcina Terminologică', 'si': 'SYSTRAN', 'so': 'SYSTRAN @ WMT 2021: Terminology Task', 'sv': 'SYSTRAN @ WMT 2021: Terminologisk uppgift', 'ta': '@ WMT 2021: Terminology Task', 'ur': 'SYSTRAN @ WMT 2021: Terminology Task', 'vi': "SY STRAN'WRT 2021: Nhiệm vụ tục phân loại", 'uz': 'SYSTRAN@ WMT 2021: Terminology vazifa', 'bg': 'SYSTRAN @ WMT 2021: Терминологична задача', 'hr': 'SYSTRAN @ WMT 2021: Terminologijski zadatak', 'de': 'SYSTRAN.WMT 2021: Terminologieaufgabe', 'da': 'SYSTRAN @ WMT 2021: Terminologi Opgave', 'nl': 'SYSTRAN.WMT 2021: Terminologietak', 'fa': 'SYSTRAN @ WMT 2021: Terminology Task', 'sw': 'SYSTRAN @WMT 2021: Kazi ya Terminalology', 'id': 'SYSTRAN @ WMT 2021: Tugas Terminologi', 'tr': 'SYSTRAN', 'ko': 'SYSTRAN@WMT 2021: 용어 작업', 'af': '@ WMT 2021: Terminology Task', 'az': 'SYSTRAN @ WMT 2021: Terminoloji Task', 'am': 'SYSTRAN @WMT 2021: Terminology Task', 'sq': 'SYSTRAN @ WMT 2021: Terminology Task', 'hy': 'SYSTAN', 'bs': 'SYSTRAN @ WMT 2021: Terminološki zadatak', 'bn': 'সিস্ট্রান@উএমটি ২০২১: টার্মিনোলজি কাজ', 'ca': 'SYSTRAN @ WMT 2021: Tarefa de terminologia', 'et': 'SYSTRAN @ WMT 2021: Terminoloogia ülesanne', 'fi': 'SYSTRAN @ WMT 2021: Terminologian tehtävä', 'cs': 'SYSTRAN.WMT 2021: Terminologický úkol', 'ha': '@ WMT 2021: Tafiya', 'sk': 'SYSTRAN @ WMT 2021: Terminološka naloga', 'he': 'SYSTRAN @ WMT 2021: משימה טרמינולוגיה', 'jv': 'sYSTAR', 'bo': 'SYSTRAN @WMT 2021: Terminology Task'}
{'en': 'This paper describes SYSTRAN submissions to the WMT 2021 terminology shared task. We participate in the English-to-French translation direction with a standard Transformer neural machine translation network that we enhance with the ability to dynamically include terminology constraints, a very common industrial practice. Two state-of-the-art terminology insertion methods are evaluated based (i) on the use of placeholders complemented with morphosyntactic annotation and (ii) on the use of target constraints injected in the source stream. Results show the suitability of the presented approaches in the evaluated scenario where ', 'ar': 'تصف هذه الورقة عمليات إرسال SYSTRAN إلى المهمة المشتركة للمصطلحات WMT 2021. نشارك في اتجاه الترجمة من الإنجليزية إلى الفرنسية مع شبكة ترجمة آلية عصبية معيارية للمحولات نعززها بالقدرة على تضمين قيود المصطلحات ديناميكيًا ، وهي ممارسة صناعية شائعة جدًا. يتم تقييم طريقتين حديثتين لإدراج المصطلحات بناءً على (1) استخدام العناصر النائبة المكملة بالتعليق التوضيحي الصوري و (2) على استخدام قيود الهدف التي تم إدخالها في تدفق المصدر. تظهر النتائج مدى ملاءمة الأساليب المقدمة في السيناريو الذي تم تقييمه حيث يتم استخدام المصطلحات في نظام مدرب على البيانات العامة فقط.', 'fr': "Cet article décrit les soumissions SYSTRAN pour la tâche de partage de terminologie WMT 2021. Nous participons à la direction de la traduction de l'anglais vers le français avec un réseau de traduction automatique neuronale Transformer standard que nous améliorons avec la capacité d'inclure dynamiquement des contraintes terminologiques, une pratique industrielle très courante. Deux méthodes d'insertion terminologique de pointe sont évaluées sur la base (i) de l'utilisation d'espaces réservés complétés par une annotation morphosyntaxique et (ii) de l'utilisation de contraintes cibles injectées dans le flux source. Les résultats montrent la pertinence des approches présentées dans le scénario évalué où la terminologie est utilisée dans un système formé uniquement sur des données génériques.", 'pt': 'Este documento descreve os envios do SYSTRAN para a tarefa compartilhada de terminologia do WMT 2021. Participamos da direção de tradução de inglês para francês com uma rede de tradução automática neural padrão Transformer que aprimoramos com a capacidade de incluir dinamicamente restrições de terminologia, uma prática industrial muito comum. Dois métodos de inserção de terminologia de última geração são avaliados com base (i) no uso de placeholders complementados com anotação morfossintática e (ii) no uso de restrições de destino injetadas no fluxo fonte. Os resultados mostram a adequação das abordagens apresentadas no cenário avaliado onde a terminologia é utilizada em um sistema treinado apenas em dados genéricos.', 'es': 'Este documento describe los envíos de SYSTRAN a la tarea compartida de terminología del WMT 2021. Participamos en la dirección de traducción del inglés al francés con una red de traducción automática neuronal Transformer estándar que mejoramos con la capacidad de incluir dinámicamente restricciones terminológicas, una práctica industrial muy común. Se evalúan dos métodos de inserción terminológica de última generación basados en (i) el uso de marcadores de posición complementados con anotación morfosintáctica y (ii) el uso de restricciones objetivo inyectadas en el flujo fuente. Los resultados muestran la idoneidad de los enfoques presentados en el escenario evaluado en el que la terminología se utiliza en un sistema entrenado solo en datos genéricos.', 'zh': '本文介 SYSTRAN WMT 2021 术语共事申请。 吾Transformer神经机器翻译网络与英语法语之所向,吾以动容术语约之所能,以强其网络,此常见之行也。 评估二最先进之术语插入法,其法基于(i)用形句法注补之占位符,及(ii)用注源流之约束。 结果表明,所立法在估场之适用性,其术语止于通用训练之统。', 'ja': '本稿では、WMT 2021用語共有タスクへのSystranサブミッションについて説明します。私たちは、標準的なTransformerニューラル機械翻訳ネットワークを使用して、英語からフランス語への翻訳の方向性に参加しています。このネットワークは、非常に一般的な産業慣行である用語の制約を動的に含める能力で強化します。２つの最先端の用語の挿入方法は、（ ｉ ）形態素論的注釈で補完されたプレースホルダの使用、及び（ ｉ ｉ ）ソースストリームに注入された標的制約の使用に基づいて評価される。結果は、一般的なデータのみでトレーニングされたシステムで用語が使用される評価されたシナリオにおける提示されたアプローチの適合性を示しています。', 'hi': 'यह पेपर WMT 2021 शब्दावली साझा कार्य के लिए SYSTRAN सबमिशन का वर्णन करता है। हम एक मानक ट्रांसफॉर्मर न्यूरल मशीन अनुवाद नेटवर्क के साथ अंग्रेजी-से-फ्रांसीसी अनुवाद दिशा में भाग लेते हैं जिसे हम गतिशील रूप से शब्दावली बाधाओं को शामिल करने की क्षमता के साथ बढ़ाते हैं, एक बहुत ही आम औद्योगिक अभ्यास। दो अत्याधुनिक शब्दावली सम्मिलन विधियों का मूल्यांकन (i) मोर्फोसिंटैक्टिक एनोटेशन के साथ पूरक प्लेसहोल्डर्स के उपयोग पर और (ii) स्रोत स्ट्रीम में इंजेक्ट किए गए लक्ष्य बाधाओं के उपयोग पर आधारित है। परिणाम मूल्यांकन किए गए परिदृश्य में प्रस्तुत दृष्टिकोणों की उपयुक्तता दिखाते हैं जहां शब्दावली का उपयोग केवल जेनेरिक डेटा पर प्रशिक्षित सिस्टम में किया जाता है।', 'ru': 'В этой статье описываются представления SYSTRAN к терминологической совместной задаче WMT 2021. Мы участвуем в англо-французском направлении перевода со стандартной нейронной сетью машинного перевода Transformer, которую мы улучшаем с возможностью динамически включать терминологические ограничения, очень распространенная промышленная практика. Оценивают два современных терминологических метода вставки на основе (i) использования заполнителей, дополненных морфосинтаксической аннотацией, и (ii) использования целевых ограничений, введенных в исходный поток. Результаты показывают пригодность представленных подходов в оцениваемом сценарии, где терминология используется в системе, обученной только на общих данных.', 'ga': 'Déanann an páipéar seo cur síos ar aighneachtaí SYSTRAN do thasc comhroinnte téarmaíochta WMT 2021. Glacaimid páirt sa treo aistriúcháin Béarla-go-Fraincis le líonra caighdeánach Transformer nóral aistriúcháin meaisín a chuirimid leis an gcumas chun srianta téarmaíochta a áireamh go dinimiciúil, cleachtas tionsclaíoch an-choitianta. Déantar luacháil ar dhá mhodh úrscothach chun téarmaíocht a chur isteach bunaithe (i) ar úsáid sealbhóirí áite arna gcomhlánú le nótáil morphosyntacticeach agus (ii) ar úsáid na spriocshrianta a instealladh sa sruth foinseach. Léiríonn na torthaí oiriúnacht na gcur chuige a chuirtear i láthair sa chás measúnaithe ina n-úsáidtear an téarmaíocht i gcóras atá oilte ar shonraí cineálacha amháin.', 'el': 'Η παρούσα εργασία περιγράφει τις υποβολές του SYSTRAN στην κοινή εργασία ορολογίας WMT 2021. Συμμετέχουμε στην κατεύθυνση της αγγλικής-γαλλικής μετάφρασης με ένα τυποποιημένο νευρωνικό δίκτυο μηχανικής μετάφρασης το οποίο ενισχύουμε με τη δυνατότητα δυναμικά να συμπεριλάβουμε περιορισμούς ορολογίας, μια πολύ κοινή βιομηχανική πρακτική. Αξιολογούνται δύο σύγχρονες μέθοδοι εισαγωγής ορολογίας με βάση: (i) τη χρήση κράτησης θέσης που συμπληρώνονται με μορφοσυντακτική σχολιασμό και (ii) τη χρήση περιορισμών στόχων που εισάγονται στη ροή προέλευσης. Τα αποτελέσματα δείχνουν την καταλληλότητα των προτεινόμενων προσεγγίσεων στο αξιολογημένο σενάριο όπου η ορολογία χρησιμοποιείται σε ένα σύστημα εκπαιδευμένο μόνο σε γενικά δεδομένα.', 'hu': 'Ez a tanulmány bemutatja a SYSTRAN beadványait a WMT 2021 terminológiai megosztott feladathoz. Az angol-francia fordítási irányban egy szabványos Transformer neurális gépi fordítóhálózattal veszünk részt, amelyet a terminológiai korlátozások dinamikus bevonásának képességével fejlesztünk, ami egy nagyon gyakori ipari gyakorlat. Két korszerű terminológiai beszúrási módszer értékelésére kerül sor (i) a helyőrzők használata morfoszintatikus jegyzeteléssel kiegészítve és (ii) a forrásforrásba injektált célkorlátozások használata alapján. Az eredmények azt mutatják, hogy a bemutatott megközelítések alkalmasak az értékelt forgatókönyvben, ahol a terminológiát kizárólag generikus adatokra képzett rendszerben használják.', 'ka': 'ეს წერტილის შეტყობინება SYSTRAN-ს WMT 2021 ტერმინოლოგიის გაყოფილი საქმე. ჩვენ ინგლისურად-ფრანგურად გადაწყვეტილების მიერ სტანდარტრუქტურის ნეიროლური მაქსინის გადაწყვეტილების ქსელით, რომელიც ჩვენ დინამიკურად გავაკეთებთ ტერმინოლოგიის შედგენები ორი სურათის ტერმინოლოგიის შეყვარება მეტისები განსაზღვრებულია i) პლასექონტების გამოყენებაზე, რომელიც მოპორფსინტაქტიური ანოტაციაზე დამატებულია და ii) მიზეზეზეზეზეზების გამოყენებაზე. წარმოდგენები გამოყენებული მიღებების სამართლობას გამოყენება განსაზღვრებული სინარიოში, სადაც ტერმინოლოგია მხოლოდ განსაზღვრებული სისტემიში გამოყენება მხოლოდ განსაზღვრე', 'it': "Questo articolo descrive i contributi SYSTRAN all'attività condivisa della terminologia WMT 2021. Partecipiamo alla direzione di traduzione inglese-francese con una rete di traduzione automatica neurale Transformer standard che miglioriamo con la capacità di includere dinamicamente vincoli terminologici, una pratica industriale molto comune. Vengono valutati due metodi di inserimento terminologico all'avanguardia basati (i) sull'uso di segnaposto integrati da annotazioni morfosintattiche e (ii) sull'uso di vincoli target iniettati nel flusso sorgente. I risultati mostrano l'idoneità degli approcci presentati nello scenario valutato in cui la terminologia è utilizzata in un sistema addestrato solo su dati generici.", 'kk': 'Бұл қағаз WMT 2021 терминологиясының ортақ тапсырмасына SYSTRAN жіберілгенін анықтайды. Біз ағылшын тілінен французша аудару бағыттарына қатысу үшін стандартты түрлендіру невралдық компьютер аудару желіне қатысушымыз. Біз динамикалық терминологиялық шектеулерді, әрі жалпы инду Екі күй- жай терминология ендіру әдістері (i) морфосинтактикалық жазбаларды қолдану мен (ii) көзінің көзінде инжекцияланған мақсатты шектеулерді қолдану үшін қолданылады. Нәтижелер тек жалпы деректерге оқылған жүйелік деректерде терминология қолданылатын сценарияда келтірілген арқылы келтірілген арқылы мүмкіндігін көрсетеді.', 'lt': 'This paper describes SYSTRAN submissions to the WMT 2021 terminology shared task.  Mes dalyvaujame vertimo anglų ir prancūzų kalbomis kryptimi naudojant standartinį Transformer nervinių mašin ų vertimo tinklą, kuris stiprinamas gebėdami dinamiškai įtraukti terminologinius apribojimus, labai įprastą pramoninę praktiką. Vertinami du moderniausi terminologijos įterpimo metodai, pagrįsti i) placeholders, papildytų morfosintakcinėmis anotacijomis, naudojimu ir ii) tikslinių suvaržymų, įvestų į šaltinio srautą, naudojimu. Rezultatai rodo, kad įvertintame scenarijuje pateikiami metodai yra tinkami, kai terminologija naudojama tik bendrųjų duomenų sistemoje.', 'mk': 'Овој документ ги опишува поднесувањата на СИСТРАН на терминологијата WMT 2021 споделена задача. Ние учествуваме во англиско-француски превод со стандардна мрежа за превод на трансформирана невропска машина која ја зајакнуваме со способноста динамично да вклучиме терминолошки ограничувања, многу заедничка индустриска практика. Двајца најсовремени методи за вметнување на терминологијата се проценуваат врз основа на (i) употребата на плацидерите комплиментирани со морфосинтактичка анотација и (ii) употребата на обврските на метата инјектирани во изворот. Резултатите покажуваат соодветност на презентираните пристапи во проценетиот сценарио каде што терминологијата се користи во систем обучен само на генерални податоци.', 'ms': 'Kertas ini menggambarkan penghantaran SYSTRAN kepada tugas kongsi terminologi WMT 2021. Kami berpartisipasi dalam arah terjemahan bahasa Inggeris-Perancis dengan rangkaian terjemahan mesin saraf Transformer piawai yang kami meningkatkan dengan kemampuan untuk memasukkan dinamik keterangan terminologi, praktek industri yang sangat umum. Dua kaedah penyisihan terminologi state-of-the-art diteliti berdasarkan (i) penggunaan pemegang ganti yang ditambah dengan anotasi morfosintaksi dan (ii) penggunaan kewajiban sasaran yang disuntik dalam aliran sumber. Hasil menunjukkan kelajuan pendekatan yang ditetapkan dalam skenario yang ditetapkan dimana terminologi digunakan dalam sistem yang dilatih pada data generik sahaja.', 'ml': 'ഈ പേപ്പറിന്റെ വിവരം WMT 2021 ടെര്\u200dമിനോളജി പങ്കെടുത്ത ജോലിയില്\u200d SYSTRAN സജ്ജീകരണങ്ങള്\u200d വിവരിക്കുന്നു. We participate in the English-to-French translation direction with a standard Transformer neural machine translation network that we enhance with the ability to dynamically include terminology constraints, a very common industrial practice.  സ്രോതസ്സ് നദിയില്\u200d ഉള്ള ലക്ഷ്യങ്ങള്\u200d ഉപയോഗിക്കുന്നതിന്\u200dറെ (i) ഉപയോഗിച്ചിരിക്കുന്ന സ്റ്റേറ്റ് സ്ഥാനത്ത് രണ്ട് സ്റ്റേറ്റ് ടെര്\u200dമിനോളജി ഇന്\u200dസ്റ്റോള അന്ത്യഫലങ്ങള്\u200dക്ക് മുന്\u200dകൂട്ടിക്കൊടുക്കപ്പെട്ട സന്ദര്\u200dഭങ്ങളുടെ സാധാരണ വിവരങ്ങളില്\u200d മാത്രം പരിശീലിക്കുന്ന സിസ്റ്റത്ത', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjonijiet tas-SYSTRAN lill-kompitu kondiviż tat-terminoloġija WMT 2021. Aħna qed jipparteċipaw fid-direzzjoni tat-traduzzjoni Ingliż-Franċiż b’netwerk standard tat-traduzzjoni tal-magni newrali Transformer li a ħna ntejbu bil-kapaċità li jinkludi dinamikament restrizzjonijiet tat-terminoloġija, prattika industrijali komuni ħafna. Żewġ metodi ta’ inserzjoni tat-terminoloġija l-aktar avvanzati huma evalwati bbażati (i) fuq l-użu ta’ sostituti kkumplimentati b’annotazzjoni morfosintattika u (ii) fuq l-użu ta’ restrizzjonijiet fil-mira injettati fil-fluss tas-sors. Results show the suitability of the presented approaches in the evaluated scenario where terminology is used in a system trained on generic data only.', 'mn': 'Энэ цаас WMT 2021 терминологийн хуваалцааны ажил дээр SYSTRAN хэвлэлийг тайлбарладаг. Бид Англи болон Французтой хөгжлийн хэлбэрээр оролцох чадвартай нэг стандарт Трансформфер механикийн мэдрэлийн хөгжлийн сүлжээнд оролцож байна. Бид терминологийн хязгаар, маш ихэвчлэн аж үйлдвэрлэлийн дасга Хоёр урлагийн терминологийг оруулах аргыг (i) эх үүсвэрийн урсгал дотор инээмсэглэгдсэн морфосинтактикийн нэмэгдүүлэгчдийн хэрэглээ дээр нэмэгдүүлдэг ба (ii) зорилготой хязгаарлуудыг ашиглах аргыг үнэлдэг. Үүний үр дүнд зөвхөн ерөнхий өгөгдлийн сургалтын системд терминологи хэрэглэгддэг тодорхойлолтуудын тухай зөвхөн үнэлгээгдсэн хувилбаруудыг харуулдаг.', 'no': 'Denne papiret skildrar SYSTRAN-tillegg til delt oppgåve i WMT 2021-terminologien. Vi deltar i retningen på omsetjing av engelsk til fransk med eit standardtransformeringsnettverk som vi forbetrar med kapasiteten til å dynamisk inkludere terminologiske begrensningar, eit veldig vanleg industriell praksis. To metodar for innsetjing av terminologien i kunsten er evaluert basert i) på bruken av plassholdarar som er komplisert med morfosyntaktisk notasjon og ii) på bruken av målsgrenser som er injisert i kjeldestrømmet. Resultater viser korleis dei presenterte tilnærmingane er tilpassa i den evaluerte scenarioen der terminologien berre vert brukt i eit systemet trent på generelle data.', 'pl': 'Niniejszy artykuł opisuje zgłoszenia SYSTRAN do wspólnego zadania terminologicznego WMT 2021. Uczestniczymy w kierunku tłumaczenia angielsko-francuskiego ze standardową neuronową siecią maszynową Transformer, którą rozszerzamy o możliwość dynamicznego uwzględniania ograniczeń terminologicznych, bardzo powszechnej praktyki przemysłowej. Ocenia się dwie najnowocześniejsze metody wstawiania terminologii w oparciu o (i) zastosowanie symboli zastępczych uzupełnionych anotacją morfosyntaktyczną oraz (ii) zastosowanie ograniczeń docelowych wstrzykiwanych w strumieniu źródłowym. Wyniki wskazują na przydatność prezentowanych podejść w ocenianym scenariuszu, w którym terminologia jest stosowana w systemie przeszkolonym wyłącznie na danych ogólnych.', 'ro': 'Această lucrare descrie trimiterile SYSTRAN la sarcina partajată de terminologie WMT 2021. Participăm în direcția de traducere engleză-franceză cu o rețea standard de traducere automată neurală Transformer pe care o îmbunătățim prin capacitatea de a include dinamic constrângeri terminologice, o practică industrială foarte comună. Două metode de inserare terminologică de ultimă generație sunt evaluate pe baza (i) utilizării substituenților completați cu adnotări morfosintactice și (ii) utilizării constrângerilor țintă injectate în fluxul sursă. Rezultatele arată adecvarea abordărilor prezentate în scenariul evaluat în care terminologia este utilizată într-un sistem instruit numai pe date generice.', 'sr': 'Ovaj papir opisuje podatke SYSTRAN na delovanje terminologije WMT 2021. Mi učestvujemo u smjeru prevođenja engleskog i francuskog jezika sa standardnom mrežom prevođenja neuralnih mašin a transformera koji povećavamo sa sposobnošću da dinamički uključujemo ograničenja terminologije, veoma zajedničku industrijsku praksiju. Dva metoda uključenja terminologije u stanje umjetnosti procjenjuju se temeljno i) na upotrebi placeholdera dodatne morfosintaktičkom annotacijom i ii) na upotrebu ciljnih ograničenja injekcije u izvornom toku. Rezultati pokazuju prikladnost predstavljenih pristupa u procjenjenom scenariju u kojem se terminologija koristi u sistemu obučenom samo na generičkim podacima.', 'si': 'මේ පත්තුව සයිස්ටරාන් වලට WMT 2021 වර්තමාන්\u200dය විශේෂයෙන් සම්බන්ධ වැඩක් විස්තර කරනවා. අපි ඉංග්\u200dරීසි වලින් ෆ්\u200dරෑන්ස් වලින් වාර්තාව ප්\u200dරමාණයක් ප්\u200dරමාණය කරපු න්\u200dයූරාල් මැෂින් වාර්තාව ජාලයෙන් එක්ක සමඟ සම ස්ථානය- of- the- art වර්තමාන්\u200dය විශ්වාසය ඇතුළත් විධානය දෙකක් විශ්වාස කරලා තියෙනවා (i) ස්ථානය සඳහා මෝර්පොසින්ටැක්ටික අනතුරු සමග සම ප්\u200dරතිචාරය පෙන්වන්න පුළුවන් පෙන්වන්න පුළුවන් ප්\u200dරතිචාරයක් විශ්වාස කරලා තියෙන්නේ සාමාන්\u200dය දත්තේ පමණ', 'so': 'Warqadan waxaa looga qoraa SYSTRAN submissions to the WMT 2021 terminology shared task. We participate in the English-to-French translation direction with a standard Transformer neural machine translation network that we enhance with the ability to dynamically include terminology constraints, a very common industrial practice.  Waxaa lagu qiimeynayaa isticmaalka qoraalka qoraalka farshaxanka ah (i) oo lagu isticmaalayo qoyska ay ku dhamaystirsan tahay marphosyntactika iyo (ii) isticmaalka qasabka jiilaalka oo lagu qoray webiga sourceada. Resultadu waxay muuqataa habboon ku habboon soo dhowaanshaha lagu qiimeeyo, marka lagu isticmaalo terminology ka mid ah nidaamka lagu baranayo macluumaadka aasaasiga ah oo kaliya.', 'sv': 'Denna uppsats beskriver SYSTRAN-inlämningar till WMT 2021-terminologins delade uppgift. Vi deltar i översättningsriktningen engelsk-franska med ett vanligt Transformers neurala maskinöversättningsnätverk som vi förbättrar med förmågan att dynamiskt inkludera terminologibegränsningar, en mycket vanlig industripraxis. Två toppmoderna metoder för införande av terminologi utvärderas baserat på (i) användning av platshållare kompletterad med morfosyntaktisk notering och (ii) användning av målbegränsningar som injiceras i källflödet. Resultaten visar lämpligheten hos de presenterade tillvägagångssätten i det utvärderade scenariot där terminologin används i ett system som endast är utbildad på generiska data.', 'ur': 'This paper describes SYSTRAN submissions to the WMT 2021 terminology shared task. ہم انگلیسی سے فرانسوی ترجمہ دیگر میں شریک ہوتے ہیں ایک استاندارڈ ترفنسر نیورال ماشین ترجمہ نیٹ ورک کے ساتھ جو ہم دینامی سے ترمینلوژی محدودیت میں شامل ہونے کی طاقت سے زیادہ زیادہ دیتے ہیں، ایک بہت مشترک صنعت کی تعبیر دو شرکت ترمینلوژی سواری طریقے مطالعہ کئے جاتے ہیں (i) مورپوسینٹاکٹیک یادہانی کے ساتھ مطالعہ کئے جاتے ہیں اور (ii) موجود سینٹک سینٹک سینٹک سینٹک کے استعمال پر موجود محدودیت کے استعمال پر مطالعہ کئے جاتے ہیں۔ نتیجے ان موجودات کے مطابق موجودات کے مطابق مطابق دکھاتے ہیں جن میں ترمینلوژی صرف عمومی ڈیٹا پر استعمال کی جاتی ہے.', 'ta': 'This paper describes SYSTRAN submissions to the WMT 2021 terminalology shared task. நாங்கள் ஒரு நிலையான மாற்று புதிய பாதைய மொழிமாற்றி மொழிபெயர்ப்பு வலைப்பின்னலுடன் ஆங்கிலத்தில் இருந்து பிரெஞ்சு மொழிமாற்றி திசையில இரண்டு மாநிலை முறை செருகுதல் முறைமைகள் (i) மூலத்தின் கூட்டத்தில் உள்ள செயல்பாட்டு கட்டுப்பாடு @ info', 'uz': "Bu qogʻoz WMT 2021 terminologiya qayta vazifani SYSTRAN imzolashga qaraydi. Biz Andoza tarjima tarjima tarjima bilan ingliz tildan Fransuzcha tarjima tarjima qilamiz. Biz oddiy tarjima tarjima bilan tarjima qilamiz, terminologiya tarjimalarini qo'shish imkoniyatlariga qo'shishimiz, juda umumiy industrial muvaffaqiyatli. Andoza @ info: status", 'vi': 'Tờ giấy này mô tả bệnh dàn âm cho công việc chia sẻ thuật ngữ WM 2021. Chúng tôi tham gia vào hướng dịch chuyển giữa Anh-Pháp và một mạng dịch chuyển biến hình thần kinh của máy biến hình liên tục mà chúng tôi nâng cao với khả năng nhấn mạnh các giới hạn các thuật ngữ, một thói quen công nghiệp rất phổ biến. Hai phương pháp cấy ghép thuật ngữ nghệ thuật tiên tiến được đánh giá dựa trên: i) sử dụng các vật giữ vị trí bổ sung với ghi chú morphine cộng thêm và (II) sử dụng các giới hạn tiêu chuẩn được tiêm vào nguồn phát. Kết quả cho thấy phương pháp được trình bày thích hợp trong trường hợp đánh giá, nơi mà thuật ngữ được dùng trong một hệ thống chỉ dựa trên dữ liệu chung.', 'hr': 'Ovaj papir opisuje podatke SYSTRAN podataka podijeljenom zadatku WMT 2021 terminologije. Učestvujemo u smjeru prevođenja engleskog i francuskog prevođenja s standardnom mrežom prevođenja neuralnih strojeva transformera koja se povećava sposobnošću dinamički uključujući ograničenje terminologije, veoma zajedničku industrijsku praksiju. Dvije metode uključenja terminologije umjetnosti procjenjuju se temeljno i) na primjeni placeholdera dodatnih morfosintaktičkim annotacijom i ii) na primjenu ciljnih ograničenja injekcije u izvornom toku. Rezultati pokazuju prikladnost predstavljenih pristupa u procijenjenom scenariju kada se terminologija koristi u sustavu obučenom samo na općenitim podacima.', 'de': 'In diesem Beitrag werden SYSTRAN-Einreichungen für die gemeinsame Terminologie-Aufgabe WMT 2021 beschrieben. Wir beteiligen uns an der Übersetzungsrichtung Englisch-Französisch mit einem Standard-Transformer neuronalen maschinellen Übersetzungsnetzwerk, das wir um die Fähigkeit erweitern, Terminologiebeschränkungen dynamisch einzubeziehen, eine sehr gängige industrielle Praxis. Zwei moderne Methoden der Terminologie-Einfügung werden evaluiert, basierend auf (i) auf der Verwendung von Platzhaltern, ergänzt durch morphosyntaktische Annotation und (ii) auf der Verwendung von Target Constraints, die in den Quellstrom injiziert werden. Die Ergebnisse zeigen die Eignung der vorgestellten Ansätze für das evaluierte Szenario, in dem Terminologie in einem System verwendet wird, das nur auf generischen Daten trainiert ist.', 'da': 'Dette dokument beskriver SYSTRAN-indsendelser til WMT 2021 terminologidelt opgave. Vi deltager i den engelsk-fransk oversættelsesretning med et standard Transformer neuralt maskinoversættelsesnetværk, som vi forbedrer med evnen til dynamisk at inkludere terminologibegrænsninger, en meget almindelig industripraksis. To avancerede metoder til indsættelse af terminologi evalueres baseret på i) anvendelse af pladsholdere suppleret med morfosyntaktiske noteringer og ii) anvendelse af målbegrænsninger injiceret i kildestrømmen. Resultaterne viser egnetheden af de præsenterede fremgangsmåder i det evaluerede scenarie, hvor terminologi anvendes i et system, der kun er uddannet på generiske data.', 'bg': 'Настоящата статия описва предложенията на SYSTRAN към споделената задача за терминологията на WMT 2021. Участваме в посоката на превода от английски до френски със стандартна трансформаторна невронна машинна преводаческа мрежа, която подобряваме с възможността динамично включване на терминологични ограничения, много често срещана индустриална практика. Оценяват се два съвременни метода за въвеждане на терминология въз основа на i) използването на контейнери, допълнени с морфосинтактична анотация, и ii) използването на целеви ограничения, инжектирани в източника. Резултатите показват пригодността на представените подходи в оценения сценарий, при който терминологията се използва в система, обучена само върху общи данни.', 'nl': 'Dit artikel beschrijft SYSTRAN inzendingen aan de WMT 2021 terminologie gedeelde taak. We nemen deel aan de vertaalrichting Engels-Frans met een standaard Transformer neural machine translation netwerk dat we uitbreiden met de mogelijkheid om terminologische beperkingen dynamisch op te nemen, een zeer gebruikelijke industriële praktijk. Twee state-of-the-art terminologie invoegmethoden worden geëvalueerd op basis van (i) het gebruik van tijdelijke aanduidingen aangevuld met morfosyntactische annotatie en (ii) het gebruik van doelbeperkingen geïnjecteerd in de bronstroom. De resultaten tonen aan dat de gepresenteerde benaderingen geschikt zijn voor het geëvalueerde scenario waarin terminologie wordt gebruikt in een systeem dat alleen is getraind op generieke gegevens.', 'ko': '본고는 SYSTRAN이 WMT 2021 용어 공유 임무에 제출한 상황을 묘사한다.우리는 표준적인 Transformer 신경기계 번역 네트워크를 통해 영어에서 프랑스어의 번역 방향에 참여하고 용어의 제약을 동태적으로 포함하는 능력을 통해 이 네트워크를 강화하는 것은 매우 흔히 볼 수 있는 공업 실천이다.두 가지 가장 선진적인 용어 삽입 방법을 평가했다. (i)는 점위부호의 사용을 바탕으로 하고 형태문법 주석을 곁들인다. (ii)는 원류에 주입된 목표의 제약을 바탕으로 한다.그 결과 제시된 방법은 유니버설 데이터로만 교육된 시스템에서 용어를 사용하는 평가 장면에 적용된다.', 'tr': 'Bu kagyz SYSTRAN WMT 2021 terminologi첵asyna be첵leki zady tassy첵ar. I흫lis챌e-we fransuz챌a terjime edilen y철ntemde, be첵leki terjime edilen neural ma힊yny흫 terjime edilmesi bilen, dinamik 힊eklinde terminologi첵any흫 챌yky힊laryny we 철r채n umumy senagat praktikany bar. Iki sanat terminologi첵asy girdirme y철ntemlerine (i) morfosyntaktik du첵gulama bilen dolylan 첵erle힊첵채n 첵erle힊첵채n 첵erle힊첵채n 첵erle힊첵채n 첵erle힊첵채n 첵erle힊첵채n 첵erlerde de흫len첵채r. Netijenler di흫e jeneral maglumatlar bilen bilinen sistemde terminologi첵a ullan첵an sahypalary흫 첵erligini g철rkez첵채r.', 'id': 'Kertas ini menjelaskan pengiriman SYSTRAN ke tugas berbagi terminologi WMT 2021. Kami berpartisipasi dalam arah terjemahan bahasa Inggris-Perancis dengan jaringan terjemahan mesin saraf Transformer standar yang kami meningkatkan dengan kemampuan untuk secara dinamik meliputi batas terminologi, praktek industri yang sangat umum. Dua metode penerimaan terminologi terbaik diuji berdasarkan (i) penggunaan pemegang tempat yang ditambah dengan anotasi morfosintaksi dan (ii) penggunaan batas sasaran yang disuntik di aliran sumber. Hasil menunjukkan kemampuan pendekatan yang ditemukan dalam skenario yang diteliti dimana terminologi digunakan dalam sistem yang dilatih hanya pada data umum.', 'fa': 'این کاغذ تحویل\u200cهای SYSTRAN به کار مشترک ترمینالوژی WMT 2021 توصیف می\u200cکند. ما در مسیر ترجمه انگلیسی و فرانسوی با شبکه ترجمه\u200cکننده\u200cی ماشین\u200cهای عصبی استاندارد شرکت می\u200cکنیم که با توانایی تغییر\u200cدهنده\u200cی دینامیکی از محدودیت\u200cهای ترمینالوژی، یک تمرین صنعتی بسیار مشترک است. دو روش درآمد ترمینالوژی هنر بر اساس i) استفاده از استفاده از جایگزین\u200cها با آشنایی مورفوسینکتی و (ii) بر استفاده از محدودیت\u200cهای هدف که در سیم منبع تزریق شده\u200cاند ارزیابی می\u200cشوند. نتیجه\u200cها نیکویی از دسترسی\u200cهای پیشنهاد در سناریو ارزیابی نشان می\u200cدهند که ترمینالوژی تنها در سیستم آموزش داده\u200cهای عمومی استفاده می\u200cشود.', 'sw': 'Gazeti hili linaelezea ujumbe wa SYSTRAN kwa utaratibu wa tatizo la WMT 2021. Tunashiriki katika mwelekeo wa kutafsiri kwa Kiingereza-hadi Kifaransa kwa mtandao wa utafsiri wa mashine ya asili ya kawaida ya Transfer ambao tunaongezea kwa uwezo wa kidini unajumuisha vizuizi vya ngono, mazoea yanayofanana sana ya viwanda. Two state-of-the-art terminology insertion methods are evaluated based (i) on the use of placeholders complemented with morphosyntactic annotation and (ii) on the use of target constraints injected in the source stream.  Matokeo yanaonyesha uwezekano wa uwezekano wa hatua zilizotolewa katika eneo lililopitiwa ambapo utaratibu wa ngono unatumiwa katika mfumo unaoendeshwa kwa takwimu za kawaida tu.', 'am': 'This paper describes SYSTRAN submissions to the WMT 2021 terminology shared task.  በተጨማሪው የነፃ መረብ ማተርጓም እናበረታለን፡፡ የ-ሁኔታ ተርሚኖሎጂ የጨዋታ ሥርዓት (i) በመጠቀም በሞሮፎስSyntactic አዳራሽ በተጨማሪው የስፍራዎች ተጠቃሚ እና (ii) በምዕራብ ውኃ ውስጥ በተደረገ የግንኙነት ግንኙነት በተጠቃሚ ተጠቃሚ ላይ በሚያስተምሩ (i) ፍጥረቶቹ በተመለከተው የድምፅ መረጃዎች ብቻ በተማረ ስርዓት ውስጥ ተርሚኖጂ የሚጠቀሙበት ስርዓት ማድረግ የሚደረገውን ጥያቄ ያሳያል፡፡', 'af': "Hierdie papier beskrywe SYSTRAN-onderwerpe na die WMT 2021 terminologie gedeelde taak. Name Ons deelnadeer in die Engels-na-Franse vertaling rigting met 'n standaard Transformer neurale masjien vertaling netwerk wat ons met die moontlikheid om dinamies terminologies beperking te insluit, 'n baie gemeenskap industriese praksie. Twee staat-van-die-kunstens terminologie invoeg metodes word uitgewerk gebaseerde (i) op die gebruik van plekhouers met morfosyntaktike annotasie en (ii) op die gebruik van doel beheinings ingevoer in die bron stroom. Resultate wys die geskikheid van die voorgestelde toegang in die evalueerde scenario waar terminologie gebruik word in 'n stelsel wat slegs op generieke data geleer is.", 'sq': 'This paper describes SYSTRAN submissions to the WMT 2021 terminology shared task.  Ne marrim pjesë në drejtimin e përkthimit anglez-në-francez me një rrjet standard të përkthimit të makinave nervore Transformer që ne përmirësojmë me aftësinë për të përfshirë dinamikisht kufizimet e terminologjisë, një praktikë shumë të zakonshme industriale. Dy metoda më të larta të futjes së terminologjisë vlerësohen bazuar (i) në përdorimin e mbajtësve të vendeve të komplementuar me anotacionin morfosintaktik dhe (ii) në përdorimin e kufizimeve objektive të injektuara në rrjedhën e burimit. Rezultatet tregojnë përshtatjen e qasjeve të paraqitura në skenarin e vlerësuar ku terminologjia përdoret në një sistem të trajnuar vetëm me të dhëna gjenerale.', 'hy': 'Այս հոդվածը նկարագրում է SYSTAN-ի ներկայացումները 2021 թվականի համագործակցած տերմինոլոգիայի հանձնարարությանը: Մենք մասնակցում ենք անգլերեն-ֆրանսերեն թարգմանման ուղղությամբ ստանդարտ թարգմանման նյարդային մեքենայի ցանցով, որը մենք բարելավում ենք դինամիկ ներառելու հնարավորության հետ, շատ տարածված արդյունաբերական գործընթաց: Երկու ամենաբարձր տերմինոլոգիայի ներդրման մեթոդը գնահատվում է, հիմնված i) տեղադրողների օգտագործման վրա, որոնք լրացվում են մորֆոսինտակտիկ նոտացիայի միջոցով, և II) աղբյուր հոսանքում ներարկված նպատակային սահմանափակումների օգտագործման վրա: Results show the suitability of the presented approaches in the evaluated scenario where terminology is used in a system trained on generic data only.', 'bn': 'এই পত্রিকাটি উইএমটি ২০২১ টার্মিনিলজি শেয়ার কর্মসূচির প্রতি সাইস্ট্রান প্রদান করেছে। আমরা ইংরেজি থেকে ফ্রেঞ্চ অনুবাদের দিকে অংশগ্রহণ করি একটি স্ট্যান্ডার্ডার্ন্যান্ডার্নাফার্নাল নিউরাল মেশিন অনুবাদ নেটওয়ার্কের সাথে যেখ শিল্পের দুই রাষ্ট্রের টার্মিনোলজি যোগাযোগের মাধ্যমে (i) ভিত্তিক মূল্যায়ন করা হচ্ছে মোরোফোসিক্যাটিক্যাটিক ব্যাপারে সম্পূর্ণ প্রতিষ্ঠানের ব্যবহ ফলাফল দেখাচ্ছে এই মূল্যবান দৃশ্যে উপস্থিত প্রযুক্তির সাথে যোগ্যতার যোগ্যতা যেখানে সাধারণ তথ্য প্রশিক্ষিত একটি সিস্টেমে', 'az': 'Bu kağıt WMT 2021 terminoloji paylaşılan işlərə SYSTRAN göndərmələrini təsdiq edir. Biz İngilizə-Fransızca çeviriş yönteminə standart transformer nöral maşın çeviriş a ğı ilə birləşdiririk ki, dinamik olaraq terminoloji müəyyənləşdirmələri, çox ortaq industrial praksisi ilə birləşdiririk. İki sanat terminoloji istifadə metodlarını (i) mənbə suda istifadə edilən məqsəd müəyyənlərinin istifadəsində daxil edilənlər istifadəsində və (ii) istifadəsində istifadə edilənlər istifadəsində değerlənir. Sonuçlar təmin edilmiş tərzlərin uyğunluğunu ancaq nümunəlik məlumatları üzərində təhsil edilmiş sistemdə istifadə edilən şəkildə göstərər.', 'bs': 'Ovaj papir opisuje podatke SYSTRAN na podjelu terminologije WMT 2021. Učestvujemo u smjeru prevođenja engleskog i francuskog jezika sa standardnom mrežom prevođenja neuralnih strojeva Transformer a, koju povećavamo sa sposobnošću da dinamički uključujemo ograničenja terminologije, veoma zajedničku industrijsku praksiju. Dvije metode uključenja terminologije u stanju umjetnosti procjenjuju se temeljno i) na primjeni placeholdera dodatne morfosintaktičkom annotacijom i ii) na primjenu ciljnih ograničenja injekcije u izvornom toku. Rezultati pokazuju prikladnost predstavljenih pristupa u procjenjenom scenariju gdje se terminologija koristi u sustavu obučenom samo na generičnim podacima.', 'cs': 'Tento článek popisuje příspěvek SYSTRAN pro sdílený úkol terminologie WMT 2021. Podílíme se na směru překladu z angličtiny do francouzštiny se standardní neuronovou strojovou překladovou sítí Transformer, kterou rozšiřujeme o schopnost dynamicky zahrnout terminologická omezení, což je velmi běžná průmyslová praxe. Jsou hodnoceny dvě nejmodernější metody vkládání terminologie na základě (i) použití zástupných symbolů doplněných morfosyntaktickou anotací a (ii) použití cílových omezení vstřikovaných do zdrojového proudu. Výsledky ukazují vhodnost prezentovaných přístupů v hodnoceném scénáři, kdy je použita terminologie v systému trénovaném pouze na obecných datech.', 'ca': "Aquest paper descriu les presentacions de SYSTRAN a la tasca compartida de terminologia WMT 2021. Participem en la direcció de traducció anglès-francès amb una xarxa normal de traducció neural Transformer que millorem amb l'habilitat d'incloure dinàmicament restriccions de terminologia, una pràctica industrial molt comú. Dos mètodes d'insertió terminològica més avançats s'evaluen basats (i) en l'ús de tenedors de lloc complementats amb anotació morfosinàctica i (ii) en l'ús de restriccions d'objectiu injectades al flux de fonts. Els resultats demostren l'adequació dels enfocaments presentats en l'escenari avaluat en què la terminologia s'utilitza en un sistema entrenat només en dades genèriques.", 'et': 'Käesolevas artiklis kirjeldatakse SYSTRANi esitusi WMT 2021 terminoloogia jagatud ülesandele. Me osaleme inglise-prantsuse tõlke suunas standardse Transformeri neuromasintõlkevõrguga, mida täiustame võimega dünaamiliselt kaasata terminoloogilisi piiranguid, mis on väga levinud tööstustava. Hinnatakse kahte kaasaegset terminoloogia sisestamise meetodit, mis põhinevad i) kohatäidete kasutamisel, mida täiendavad morfosüntaktilised annotatsioonid, ja ii) lähtevooga süstitatud sihtpiirangute kasutamisel. Tulemused näitavad esitatud lähenemisviiside sobivust hinnatud stsenaariumis, kus terminoloogiat kasutatakse süsteemis, mis on koolitatud ainult üldiste andmetega.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvataan SYSTRAN-ehdotuksia WMT 2021 -terminologian yhteiseen tehtﾃ､vﾃ､ﾃ､n. Osallistumme englanti-ranska-kﾃ､ﾃ､nnﾃｶssuuntaan vakiomuotoisella Transformer-neurokonekﾃ､ﾃ､nnﾃｶsverkostolla, jota parannamme dynaamisesti sisﾃ､llyttﾃ､mﾃ､llﾃ､ terminologiarajoitteita, joka on hyvin yleinen teollinen kﾃ､ytﾃ､ntﾃｶ. Arvioinnissa arvioidaan kahta viimeisintﾃ､ terminologian lisﾃ､ysmenetelmﾃ､ﾃ､, jotka perustuvat i) paikkamerkkien kﾃ､yttﾃｶﾃｶn morfosyntaktisella annotoinnilla ja ii) lﾃ､hdevirtaan injektoitujen kohderajoitusten kﾃ､yttﾃｶﾃｶn. Tulokset osoittavat esitettyjen lﾃ､hestymistapojen soveltuvuuden arvioituun skenaarioon, jossa terminologiaa kﾃ､ytetﾃ､ﾃ､n vain yleisaineistoon koulutetussa jﾃ､rjestelmﾃ､ssﾃ､.', 'jv': "Ngerti wigatining manut kanggo ngerasakno sawari sYSTARIN kanggo ngilanggar perangkat WWT 2020 1 Awakdhéwé mengko nglanggar tarjamahan Inggris-karo Perancis karo netah kuwi alam sing berarting maneh Transformer Neral kuwi nggawe ngubah kapan karo sistem sing bisa nguasai perusahaan kanggo nyengkuyung kawit sistem limiting terminal, kuwi nguasai empresa manungsil sing apik. Awakdhéwé-Awakdhéwé-Awakdhéwé halungi-halungi terminal sistêm kuwi nggunakaé basa (i) nggunaké perusahaan Where's the use of a Placebar ambekan karo transformosYntatiki lan (i i) nggunaké aturan tambah nggawe nguasai winih dhéwé. Rejalaké wong nggawe kapan kanggo ngilanggar sampeyan anyar neng scenaro sing berarti", 'ha': "Wannan takardan na describe SYstanran wasiyyar zuwa the WMT 2021 therminogy share job. Tuna tãrayyar da shirin fassarar Ingiriya-zuwa-French da wani zanen tarjima na Transformer na'urar neural tarjibu wanda Muke ƙarfafa da abincin da za'a haɗa taƙaitũniya da taƙaitura tarminogi, wata aikin mai kawaici. Two state-of-the-art terminology insertion methods are evaluated based (i) on the use of placeholders complemented with morphosyntactic annotation and (ii) on the use of target constraints injected in the source stream.  Matsala na nuna wa'ura da aka bãyar da hanyari cikin wurin da aka evaluce, inda ana yi amfani da teraminogi cikin wata na'ura wanda aka yi wa shirin a kan data masu daman da aka sani kawai.", 'sk': 'V tem prispevku so opisani prispevki SYSTRAN v skupno opravilo terminologije WMT 2021. V angleško-francoski prevajalski smeri sodelujemo s standardno mrežo Transformer nevronskih strojnih prevodov, ki jo izboljšujemo s sposobnostjo dinamičnega vključevanja terminoloških omejitev, kar je zelo pogosta industrijska praksa. Ocenjujeta se dve najsodobnejši metodi vključevanja terminologije na podlagi (i) uporabe označb mest, dopolnjenih z morfosintaktičnimi opombami, in (ii) uporabe ciljnih omejitev, vnesenih v tok vira. Rezultati kažejo primernost predstavljenih pristopov v ocenjenem scenariju, kjer se terminologija uporablja v sistemu, usposobljenem samo za splošne podatke.', 'he': 'הנייר הזה מתאר את ההעברות של SYSTRAN למשימה המשותפת של WMT 2021. אנחנו משתתפים בכיוון התרגום אנגלי-לצרפתי עם רשת התרגום המכונה העצבית סטנדרטית שאנחנו משתפרים עם היכולת לכלול דינמית מחסומים בטרמונולוגיה, מעשה תעשייתי מאוד נפוץ. שתי שיטות הכניסה של הטרמינולוגיה מוקדמות מוערכות בהתבסס (i) על השימוש של מחזיקי המקום שמוספים בהערכה מורפוסינטקטית (ii) על השימוש של מחסומים מטרה שהזרקו אל זרם המקור. התוצאות מראות את התאימה של הגישויות המוצגת בתרחיש המעריך שבו הטרמולוגיה משתמשת במערכת מאומנת רק על נתונים גנרליים.', 'bo': 'ཤོག་བྱང་འདིས་SYSTRAN་གི་WMT 2021 མཐའ་མཇུག་བསྡུས་པའི་བྱ་རིམ་ལ་སྟོན་པ་དེ་འགྲེལ་བཤད་ཡོད། We participate in the English-to-French translation direction with a standard Transformer neural machine translation network that we enhance with the ability to dynamically include terminology constraints, a very common industrial practice. Two state-of-the-art terminology insertion methods are evaluated based (i) on the use of placeholders complemented with morphosyntactic annotation and (ii) on the use of target constraints injected in the source stream. གྲུབ་འབྲས་བྱ་ཚིག་ནང་དུ་འཆར་ཡོད་པའི་གཟུགས་རིས་ལྟར་མཚམས་འཇུག་སྟངས་མངོན་གསལ་བཤད་ཀྱི་ཡོད།'}
{'en': 'TermMind : Alibaba’s WMT21 Machine Translation Using Terminologies Task Submission', 'ar': "TermMind: الترجمة الآلية لـ Alibaba's WMT21 باستخدام إرسال مهمة المصطلحات", 'fr': "TermMind\xa0: Soumission de tâche de traduction automatique WMT21 d'Alibaba à l'aide de terminologies", 'es': 'TermMind: Traducción automática WMT21 de Alibaba mediante el envío de tareas terminológicas', 'pt': 'TermMind: tradução automática WMT21 do Alibaba usando terminologias envio de tarefas', 'ja': 'TermMind ：用語を使用したアリババのWMT 21機械翻訳タスクの提出', 'zh': '术语思:阿里巴巴WMT21机器翻译用术语任', 'hi': 'TermMind: अलीबाबा के WMT21 मशीन अनुवाद शब्दावली कार्य प्रस्तुत करने का उपयोग कर', 'ru': 'TermMind: Отправка задачи машинного перевода WMT21 Alibaba с использованием терминологии', 'ga': 'TermMind: Aistriúchán Meaisín WMT21 ag Alibaba ag Úsáid Téarmeolaíochta Aighneacht Tasc', 'ka': 'Comment', 'hu': 'TermMind: Alibaba WMT21 gépi fordítása terminológiák használatával Feladat benyújtása', 'el': 'Η μηχανική μετάφραση της Alibaba χρησιμοποιώντας ορολογίες Υποβολή εργασιών', 'it': 'TermMind: La traduzione automatica WMT21 di Alibaba utilizzando le terminologie', 'kk': "TermMind: Alibaba' s WMT21 Machine Translation Use Terminologies Task Submission", 'lt': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'ml': 'TermMind: അലിബാബാവിന്റെ WMT21 മെഷീന്\u200d പരിഭാഷ ഉപയോഗിക്കുന്ന ടെര്\u200dമിനോളജികളുടെ ടാസ്ക് സബ്മിഷന്\u200d', 'ms': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'mt': 'TermMind: Is-sottomissjoni tal-kompitu tat-traduzzjoni tal-makkinarju WMT21 ta’ Alibaba bl-użu tat-terminoloġiji', 'mn': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'no': 'TermMind: Alibaba sin WMT21- maskinsomsetjing ved bruk av termininologies Task Submission', 'pl': 'TermMind: Tłumaczenie maszynowe WMT21 firmy Alibaba za pomocą terminologii', 'ro': 'TermMind: Traducerea automată WMT21 de la Alibaba folosind terminologii', 'sr': 'TermMind: Alibaba-ova WMT21 mašinska prevoda korištenja terminoloških zadataka', 'so': "TermMind: Alibaba's WMT21 Machine Translation using Terminologies Task Submission", 'si': 'Comment', 'ta': 'TermMind: அலிபாபாவின் WMT21 இயந்திரம் மொழிபெயர்ப்பு', 'sv': 'TermMind: Alibaba WMT21 maskinöversättning med hjälp av terminologier Uppgift inlämning', 'ur': 'Terminologies Task Submission', 'mk': 'TermMind: Преведување на WMT21 машински превод на Алибаба користејќи терминолошки задачи', 'uz': 'TermMind: Alibabaning WMT21 Mashini Terminalology Vazifa Tashqi Submission yordamida tarjima qilish', 'vi': 'Giao dịch cơ bản của Alibaba s ử dụng các biện pháp cuối cùng', 'bg': 'Машинен превод чрез терминологии Изпращане на задачи', 'hr': 'TermMind: Alibaba-ova WMT21 uređajna prevoda koristeći terminološku podršku zadataka', 'da': "TermMind: Alibaba's WMT21 maskinoversættelse ved hjælp af terminologier Opgave Indsendelse", 'de': 'TermMind: Maschinelle Übersetzung WMT21 von Alibaba unter Verwendung von Terminologien Aufgabe Einreichung', 'id': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'nl': "TermMind: Alibaba's WMT21 Machine Translation met behulp van terminologieën Taakindiening", 'ko': 'Termmind: 알리바바의 WMT21 번역 용어 작업 제출', 'sw': 'TermMind: Tafsiri ya Mashine ya WMT21 ya Alibaba kwa kutumia Tamko la Tamko la Tamko', 'fa': "TermMind: Translation of Alibaba's WMT21 Machine Using Terminologies Task Submission", 'tr': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'am': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'af': 'TermMind: Alibaba se WMT21 Masjien Vertaling gebruik Terminologies Taak Submission', 'sq': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission", 'bn': 'টার্মিনোলজিজ টাস্ক সাবিমিশন ব্যবহার করে আলিবাবার ওয়াইমটি২১ মেশিন অনুবাদ', 'bs': 'TermMind: Alibaba-ova WMT21 uređajna prevoda koristeći terminološku podršku zadataka', 'hy': 'Comment', 'ca': "TermMind: La traducció de la màquina WMT21 d'Alibaba utilitzant terminològies Submission Task", 'cs': 'TermMind: Strojový překlad společnosti Alibaba WMT21 pomocí terminologií', 'et': 'TermMind: Alibaba WMT21 masintõlge kasutades terminoloogiaid ülesande esitamine', 'fi': 'TermMind: Alibaban WMT21 konekäännös käyttäen terminologioita Tehtävän lähettäminen', 'az': 'Terminologies Task Submission', 'sk': 'TermMind: Alibabin strojni prevod WMT21 z uporabo terminologij Predložitev nalog', 'jv': "Terminal Mind: Alibab's WB2 Device translation Using Terminal inulogies task Submis", 'ha': 'KCharselect unicode block name', 'he': 'TermMind: תרגום מכונת WMT21 של Alibaba בשימוש משימה טרמינולוגיות', 'bo': "TermMind: Alibaba's WMT21 Machine Translation Using Terminologies Task Submission"}
{'en': 'This paper describes our work in the WMT 2021 Machine Translation using Terminologies Shared Task. We participate in the shared translation terminologies task in English to Chinese language pair. To satisfy terminology constraints on ', 'fr': "Cet article décrit notre travail dans le cadre de la tâche partagée de traduction automatique à l'aide de terminologies WMT 2021. Nous participons à la tâche de terminologies de traduction partagées dans la paire de langues anglais-chinois. Pour répondre aux contraintes terminologiques liées à la traduction, nous utilisons une stratégie d'augmentation des données terminologiques basée sur le modèle Transformer. Nous avons utilisé des balises pour marquer et ajouter les termes traduits dans les phrases correspondantes. Nous avons créé des termes synthétiques à l'aide de tableaux de phrases extraits de corpus bilingues afin d'augmenter la proportion de traductions de termes dans les données de formation. Le prétraitement détaillé et le filtrage des données, le réglage fin dans le domaine et la méthode d'ensemble sont utilisés dans notre système. Notre soumission obtient des résultats compétitifs dans l'évaluation ciblée par la terminologie.", 'ar': 'تصف هذه الورقة عملنا في WMT 2021 الترجمة الآلية باستخدام المهام المشتركة للمصطلحات. نشارك في مهمة مصطلحات الترجمة المشتركة من الإنجليزية إلى الزوج اللغوي الصيني. لتلبية قيود المصطلحات على الترجمة ، نستخدم استراتيجية زيادة بيانات المصطلحات بناءً على نموذج المحولات. استخدمنا العلامات لتمييز وإضافة مصطلح ترجمات إلى الجمل المتطابقة. أنشأنا مصطلحات تركيبية باستخدام جداول العبارات المستخرجة من مجموعة ثنائية اللغة لزيادة نسبة ترجمات المصطلحات في بيانات التدريب. يتم استخدام المعالجة المسبقة والتصفية التفصيلية للبيانات ، والضبط الدقيق في المجال وطريقة التجميع في نظامنا. حصل تقديمنا على نتائج تنافسية في التقييم الذي يستهدف المصطلحات.', 'es': 'Este documento describe nuestro trabajo en la traducción automática del WMT 2021 mediante la tarea compartida de terminologías. Participamos en la tarea de terminología de traducción compartida en inglés a chino. Para satisfacer las restricciones terminológicas en la traducción, utilizamos una estrategia de aumento de datos terminológicos basada en el modelo Transformer. Usamos etiquetas para marcar y añadir las traducciones del término en las oraciones coincidentes. Creamos términos sintéticos utilizando tablas de frases extraídas de corpus bilingües para aumentar la proporción de traducciones de términos en los datos de entrenamiento. En nuestro sistema se utilizan el preprocesamiento y el filtrado detallados de los datos, el ajuste fino en el dominio y el método de ensamblaje. Nuestra presentación obtiene resultados competitivos en la evaluación orientada a la terminología.', 'pt': 'Este artigo descreve nosso trabalho na tradução automática do WMT 2021 usando a tarefa compartilhada de terminologias. Participamos da tarefa de tradução compartilhada de terminologias no par de idiomas inglês para chinês. Para satisfazer as restrições de terminologia na tradução, usamos uma estratégia de aumento de dados de terminologia baseada no modelo Transformer. Usamos tags para marcar e adicionar as traduções do termo nas frases correspondentes. Criamos termos sintéticos usando tabelas de frases extraídas do corpus bilíngue para aumentar a proporção de traduções de termos nos dados de treinamento. Pré-processamento detalhado e filtragem de dados, ajuste fino no domínio e método de conjunto são usados em nosso sistema. Nossa submissão obtém resultados competitivos na avaliação direcionada por terminologia.', 'ja': '本稿では、用語共有タスクを使用したWMT 2021機械翻訳における私たちの仕事について説明します。英語から中国語のペアで共有翻訳用語タスクに参加しています。翻訳に関する用語の制約を満たすために、トランスフォーマーモデルに基づいた用語データ拡張戦略を使用します。タグを使用して、マッチした文章にタームの翻訳をマークして追加しました。トレーニングデータにおける用語の翻訳の割合を増やすために、バイリンガルコーパスから抽出したフレーズテーブルを使用して合成用語を作成しました。データの詳細な前処理とフィルタリング、ドメイン内の微調整およびアンサンブル法が当社のシステムで使用されています。当社の提出物は、用語を対象とした評価で競合する結果を得ています。', 'zh': '本文言 WMT 2021 机器翻译中用术语共其事。 参英语中文共译术语务。 为厌译中术语约束,用Transformer模术语数增强策。 用标记术语译加匹配句中。 用双语语料库中短语表创合成术语,以增术语译训练比例。 我们的系统用了详细的数据预处理和过漉、域内微调和集成法。 提交于术语之评有竞争力焉。', 'ru': 'В этой статье описывается наша работа в области машинного перевода WMT 2021 с использованием терминологии общей задачи. Мы участвуем в совместном задании по терминологии перевода с английского на китайский язык. Чтобы удовлетворить терминологические ограничения на перевод, мы используем стратегию расширения терминологических данных, основанную на модели трансформатора. Мы использовали теги, чтобы отметить и добавить термины переводы в соответствующие предложения. Мы создали синтетические термины, используя таблицы фраз, извлеченные из двуязычного корпуса, чтобы увеличить долю переводов терминов в обучающих данных. В нашей системе используются подробная предварительная обработка и фильтрация данных, тонкая настройка в домене и метод ансамбля. Наше представление получает конкурентные результаты в терминологически-целевой оценке.', 'hi': 'यह पेपर WMT 2021 मशीन अनुवाद में हमारे काम का वर्णन करता है जो शब्दावली साझा कार्य का उपयोग करके करता है। हम अंग्रेजी से चीनी भाषा जोड़ी में साझा अनुवाद शब्दावली कार्य में भाग लेते हैं। अनुवाद पर शब्दावली बाधाओं को पूरा करने के लिए, हम ट्रांसफॉर्मर मॉडल के आधार पर एक शब्दावली डेटा वृद्धि रणनीति का उपयोग करते हैं। हमने मिलान किए गए वाक्यों में अनुवाद शब्द को चिह्नित करने और जोड़ने के लिए टैग का उपयोग किया। हमने प्रशिक्षण डेटा में शब्द अनुवाद के अनुपात को बढ़ाने के लिए द्विभाषी कॉर्पस से निकाले गए वाक्यांश तालिकाओं का उपयोग करके सिंथेटिक शब्द बनाए हैं। हमारे सिस्टम में डेटा पर विस्तृत पूर्व-प्रसंस्करण और फ़िल्टरिंग, इन-डोमेन फाइनट्यूनिंग और एनसेम्बल विधि का उपयोग किया जाता है। हमारा सबमिशन शब्दावली-लक्षित मूल्यांकन में प्रतिस्पर्धी परिणाम प्राप्त करता है।', 'ga': 'Déanann an páipéar seo cur síos ar ár gcuid oibre in Aistriúchán Meaisín WMT 2021 ag úsáid Tasc Comhroinnte Téarmaíochta. Glacaimid páirt sa tasc téarmaíochta aistrithe comhroinnte ó Bhéarla go Sínis. Chun srianta téarmaíochta ar aistriúchán a shásamh, bainimid úsáid as straitéis mhéadaithe sonraí téarmaíochta bunaithe ar shamhail Transformer. D’úsáideamar clibeanna chun na haistriúcháin téarma a mharcáil agus a chur leis na habairtí comhoiriúnaithe. Chruthaíomar téarmaí sintéiseacha ag úsáid táblaí frásaí a bhaintear as corpas dátheangach chun comhréir na n-aistriúchán téarma i sonraí oiliúna a mhéadú. Úsáidtear réamhphróiseáil agus scagadh mionsonraithe ar shonraí, mionchoigeartú san fhearann agus modh ensemble inár gcóras. Faigheann ár n-aighneacht torthaí iomaíocha sa mheastóireacht atá dírithe ar théarmaíocht.', 'hu': 'Ez a tanulmány bemutatja a WMT 2021 gépi fordításban végzett munkánkat terminológiák megosztott feladatával. Részt veszünk a megosztott fordítási terminológiai feladatban angol-kínai nyelvpárban. A fordítással kapcsolatos terminológiai korlátok kielégítése érdekében Transformer modellre épülő terminológiai adatbővítési stratégiát alkalmazunk. Címkékkel jelöltük meg és adtuk hozzá a kifejezés fordításait a megfelelő mondatokba. Szintetikus kifejezéseket hoztunk létre kétnyelvű korpuszból kivont kifejezési táblázatokkal, hogy növeljük a kifejezések fordításainak arányát a képzési adatokban. Rendszerünkben részletes adatfeldolgozást és adatszűrést, domain finomhangolást és együttes módszert alkalmazunk. Pályázatunk a terminológiai célú értékelésben versenyképes eredményeket ér el.', 'el': 'Αυτή η εργασία περιγράφει την εργασία μας στη μηχανική μετάφραση χρησιμοποιώντας κοινές εργασίες ορολογίων. Συμμετέχουμε στην κοινή εργασία ορολογίας μετάφρασης στα Αγγλικά σε Κινέζικα γλωσσικά ζεύγη. Για να ικανοποιήσουμε τους περιορισμούς ορολογίας στη μετάφραση, χρησιμοποιούμε μια στρατηγική αύξησης δεδομένων ορολογίας βασισμένη στο μοντέλο μετασχηματιστή. Χρησιμοποιήσαμε ετικέτες για να επισημάνουμε και να προσθέσουμε τις μεταφράσεις των όρων στις αντίστοιχες προτάσεις. Δημιουργήσαμε συνθετικούς όρους χρησιμοποιώντας πίνακες φράσεων που εξάγονται από δίγλωσσο σώμα για να αυξήσουμε το ποσοστό των μεταφράσεων όρων στα δεδομένα κατάρτισης. Στο σύστημά μας χρησιμοποιούνται λεπτομερής προεπεξεργασία και φιλτράρισμα δεδομένων, συντονισμός και μέθοδος συνόλου. Η υποβολή μας επιτυγχάνει ανταγωνιστικά αποτελέσματα στην αξιολόγηση με στόχο την ορολογία.', 'ka': 'ეს დოკუმენტი ჩვენი სამუშაო WMT 2021 მაქსინური თავისუშაოში გამოყენება ტერმინოლოგიების გაყოფილი სამუშაო. ჩვენ ჩვენ კინგლისური ენის ზოგლის გარეშე ტერმინოლოგიის რაოდენობაში ჩვენ გავათავსებთ. ტერმინოლოგიის შესაძლებლობის შესაძლებლობისთვის, ჩვენ ტერმინოლოგიის მონაცემების აგგენტირება სტრატიგიაზე გამოყენებთ. ჩვენ ჭდეები გამოყენეთ, რომლებიც მარტიკურად დამატებით და დამატებით სიტყვების გადამატებით. ჩვენ შევქმნა სინტეტიკური სიტყვების გამოყენება, რომელიც ორიენგური კორპუსდან გამოვიყენებული ფრაზების ტაბლოების გამოყენება, რომელიც გამოვიყენება ტემის ჩვენი სისტემაში გამოყენება მონაცემების, დემომინის კონტუნტურის და სენემბულის მეტი. ჩვენი წარმოდგენება მიიღება კონსპექტიური შედეგები ტერმინოლოგიის მიზეზებით.', 'it': "Questo articolo descrive il nostro lavoro nella traduzione automatica WMT 2021 utilizzando Terminologies Shared Task. Partecipiamo al compito condiviso di traduzione terminologica in coppia di lingue dall'inglese al cinese. Per soddisfare i vincoli terminologici della traduzione, utilizziamo una strategia di aumento dei dati terminologici basata sul modello Transformer. Abbiamo usato tag per contrassegnare e aggiungere le traduzioni dei termini nelle frasi corrispondenti. Abbiamo creato termini sintetici utilizzando tabelle di frasi estratte dal corpus bilingue per aumentare la percentuale di traduzioni di termini nei dati di formazione. Preelaborazione dettagliata e filtraggio dei dati, finetuning in-domain e metodo ensemble sono utilizzati nel nostro sistema. La nostra presentazione ottiene risultati competitivi nella valutazione mirata alla terminologia.", 'kk': 'Бұл қағаз WMT 2021 компьютерінің ортақ тапсырманы терминологиялық ортақ тапсырманы қолданып жұмыстарымызды анықтайды. Біз ағылшынша тілде жалғастырылған терминологиялар тапсырмасына қатынасыз. Түрлендіру үшін терминологиялық шектеулерді қолдану үшін, Түрлендіру үлгісіне негізделген терминологиялық деректерді көбейту стратегиясын қолданамыз. Біз тегтерді белгілеу және сәйкес сөздерге аудару үшін қолдандық. Біз синтетикалық терминлерді екі тілді корпустан таратылған фраз кестелерін қолдану үшін ұқсас беру мәліметтерінің бөлшегін көтеру үшін құрдық. Деректерді алдын- ала өңдеу және сүзгілеу, домендегі сүзгілеу жүйемізде қолданылады. Біздің келтіріміз терминологияның мақсатты оқу үшін конкурентті нәтижелерін алады.', 'lt': 'Šiame dokumente apibūdinamas mūsų darbas WMT 2021 m. mašin ų vertimui naudojant bendros užduoties terminologijas. Mes dalyvaujame bendroje vertimo terminologijų užduotyje anglų kalba ir kinų kalbų pora. To satisfy terminology constraints on translation, we use a terminology data augmentation strategy based on Transformer model.  Mes naudojome ženklus žymėti ir pridėti terminą vertimai į atitinkamus sakinius. Sukūrėme sintetinius terminus naudojant frazių lenteles, ištrauktas iš dvikalbio kūno, siekiant padidinti term in ų vertimų skaičių mokymo duomenise. Mūsų sistemoje naudojamas išsamus išankstinis duomenų apdorojimas ir filtravimas, domeno tobulinimas ir komplekso metodas. Mūsų pateiktame vertinime gaunami konkurenciniai rezultatai, susiję su terminologija.', 'mk': 'Овој весник ја опишува нашата работа во WMT 2021-та машинска превод користејќи терминологии споделена задача. Ние учествуваме во задачата на споделените преводни терминологии на англиски на кинески јазик пар. За да ги задоволиме терминолошките ограничувања на преводот, користиме терминолошка стратегија за зголемување на податоците базирана на трансформскиот модел. Користевме ознаки за обележување и додавање на терминот превод во соодветните реченици. Создадовме синтетички термини користејќи таблички за фрази извадени од двојјазичкиот корпус за да го зголемиме процентот на термински преводи во податоците за обука. Detailed pre-processing and filtering on data, in-domain finetuning and ensemble method are used in our system.  Our submission obtains competitive results in the terminology-targeted evaluation.', 'ms': 'Kertas ini menggambarkan kerja kita dalam WMT 2021 Terjemahan Mesin menggunakan Tugas Berkongsi Terminologi. Kami berpartisipasi dalam tugas terminologi terjemahan berkongsi dalam bahasa Inggeris kepada pasangan bahasa Cina. Untuk memenuhi keterangan terminologi pada terjemahan, kita menggunakan strategi peningkatan data terminologi berdasarkan model Transformer. Kami gunakan tag untuk menandakan dan tambah terjemahan terma ke dalam kalimat yang sepadan. Kami mencipta terma sintetik menggunakan jadual frasa yang dikeluarkan dari tubuh dua bahasa untuk meningkatkan proporsi terjemahan terma dalam data latihan. Detailed pre-processing and filtering on data, in-domain finetuning and ensemble method are used in our system.  Pemberian kami mendapatkan keputusan kompetitif dalam penilaian termologi-sasaran.', 'mt': 'Dan id-dokument jiddeskrivi x-xogħol tagħna fit-Traduzzjoni tal-Magni tad-WMT 2021 bl-użu ta’ Kompitu Kondiviż tat-Terminoloġiji. Aħna qed jipparteċipaw fil-kompitu ta’ terminoloġiji ta’ traduzzjoni kondiviżi bl-Ingliż għal par ta’ lingwi Ċiniżi. Biex jissodisfaw ir-restrizzjonijiet terminoloġiċi fuq it-traduzzjoni, a ħna nużaw strateġija ta’ żieda tad-dejta terminoloġika bbażata fuq il-mudell Transformer. Użajna tikketti biex nimmarkaw u jżidu t-traduzzjonijiet tat-terminu fis-sentenzi mqabbla. Ħolqien termini sintetiċi bl-użu ta’ tabelli ta’ frażi estratti mill-korpus bilingwi biex jiżdied il-proporzjon ta’ traduzzjonijiet ta’ terminu fid-dejta tat-taħriġ. Is-sistema tagħna tuża l-ipproċessar minn qabel u l-filtrazzjoni dettaljata tad-dejta, il-metodu ta’ rfinar fid-dominju u l-metodu ta’ ensemble. Is-sottomissjoni tagħna tikseb riżultati kompetittivi fl-evalwazzjoni mmirata lejn it-terminoloġija.', 'mn': 'Энэ цаас WMT 2021 оны машины хөгжлийн хөгжлийн ажлыг Terminologies Shared Task ашиглан тайлбарладаг. Бид Англи хэл дээр хуваалцах терминологийг Хятадын хэл хоёрын ажилд оролцож байна. Түүнчлэлийн терминологийн хязгаарлалтыг удирдахын тулд бид Түүнчлэлийн загварын үндсэн терминологийн өгөгдлийн нэмэлт стратегийг ашигладаг. Бид тэмдэгүүдийг тэмдэглэж, тэмдэгтийг холбоотой өгүүлбэрт нэмэхэд ашигласан. Бид хоёр хэлний корпус руу гаргасан хэлний хүснэгт ашиглаж өгөгдлийн дасгал өгөгдлийн хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны Манай системд нарийвчлалтай өмнө үйлдвэрлэл, мэдээллийг сүзүүлэх, холбоотой хэмжээсүүд болон эмзэмбэл арга хэрэглэгддэг. Бидний хүлээн зөвшөөрөл нь терминологийн зорилготой үнэлгээнд өрсөлдөг үр дүнг авдаг.', 'no': 'Denne papiret beskriver arbeidet vårt i WMT 2021- maskinsomsetjinga ved hjelp av terminologier delt oppgåve. Vi deltar i den delte omsetjingssterminologiske oppgåva i engelsk til kinesisk språk par. For å tilfredsstille terminologiske begrensningar på omsetjinga, bruker vi ein strategi for økning av terminologiske data basert på Transformer-modell. Vi brukte merkelappar for å merke og leggja til uttrykk om omsetjingane i dei samsvarte setningane. Vi oppretta syntetiske uttrykk ved å bruka fråtabeller utpakka frå bilinguelt korpus for å auka proporsjonen av uttrykk i øvingsdata. Detaljar førehandsaming og filtrering av data, finetuning i domenet og ensemblemmetode vert brukt i systemet vår. Søket vårt får konkurrentiv resultat i utvalet med terminologi.', 'pl': 'Niniejszy artykuł opisuje naszą pracę w ramach tłumaczenia maszynowego WMT 2021 przy użyciu terminologii wspólnego zadania. Uczestniczymy w zadaniu wspólnego tłumaczenia terminologii w języku angielskim na chiński. Aby sprostać ograniczeniom terminologicznym dotyczącym tłumaczenia, stosujemy strategię rozszerzania danych terminologicznych opartą na modelu Transformera. Użyliśmy tagów do oznaczenia i dodawania terminów do dopasowanych zdań. Stworzyliśmy syntetyczne terminy z wykorzystaniem tabel fraz ekstraktowanych z dwujęzycznego korpusu, aby zwiększyć udział tłumaczeń terminów w danych szkoleniowych. W naszym systemie stosujemy szczegółowe wstępne przetwarzanie i filtrowanie danych, w domenie finetuning i metodę ensemble. Nasze zgłoszenie uzyskuje konkurencyjne wyniki w ocenie ukierunkowanej na terminologię.', 'ro': 'Această lucrare descrie activitatea noastră în traducerea automată WMT 2021 folosind Terminologies Shared Task. Participăm la sarcina comună de traducere terminologică în limba engleză-chineză. Pentru a satisface constrângerile terminologice privind traducerea, folosim o strategie de augmentare a datelor terminologice bazată pe modelul Transformer. Am folosit etichete pentru a marca și adăuga traducerile termenilor în propozițiile potrivite. Am creat termeni sintetici folosind tabele de expresii extrase din corpul bilingv pentru a crește proporția traducerilor termenilor în datele de formare. Prelucrarea și filtrarea detaliată a datelor, reglarea în domeniu și metoda ansamblului sunt utilizate în sistemul nostru. Trimiterea noastră obține rezultate competitive în evaluarea orientată spre terminologie.', 'sr': 'Ovaj papir opisuje naš rad u WMT 2021-om mašinskom prevodu koristeći zajednički zadatak terminologija. Mi sudjelujemo u zadatku zajedničkih terminologija prevođenja na engleskom jeziku na kineskom parovu. Da bi zadovoljili ograničenja terminologije na prevodu, koristimo strategiju povećanja podataka terminologije na osnovu model a transformera. Koristili smo znakove za označavanje i dodanje termina prevoda u odgovarajuće rečenice. Stvorili smo sintetičke termine koristeći tablice fraze izvučene iz dvojezičkog korpusa kako bi povećali proporciju terminskih prevoda u podacima obuke. Detaljno preobrađivanje i filtriranje podataka, finetuniranje i ensemble metode u našem sistemu se koriste. Naša podnošenja dobija konkurentne rezultate u procjeni terminologije.', 'so': 'Kanu wuxuu ku qoraa shaqadayada ku qoran WMT 2021 Turjumidda mashiinka ee isticmaalaya Terminologies Shared Shaqada. Waxaannu ka qeybqaadannaa shaqada turjubaanka oo la xiriiray luuqada Ingiriiska noocyada labada luqada Shiino. Si aan u raalli karno xaduudaha terminology ee turjumidda, waxaynu isticmaalaynaa qoraal kordhiska takhasuska terminology oo ku saleysan qaababka turjubaanka. Waxaynu isticmaalnay alaabta si aan u tagno oo aan ugu darno turjumaadda hadalka oo aan ugu qorno erayada la isku mid ah. Waxaan sameynay qoraalo la mid ah oo lagu isticmaalay miisaska afka ah oo laga soo bixiyey labada luqadood si aan u kordhino tirada turjumaadda afka ee macluumaadka waxbarashada. Dalkayaga waxaa lagu isticmaalaa macluumaad ku saabsan horay u baaraandegista iyo baaritaanka ku saabsan macluumaadka, baaritaanka internetka iyo habka noocyada. Imtixaankayagu wuxuu heli karaa matooyin adag oo ku saabsan qiimeynta terminology.', 'si': 'මේ පැත්තේ WMT 2021 පණිවිඩයේ අපේ වැඩ විස්තර කරනවා වර්මිනෝලෝජික කාර්ය භාවිත කරන්න. අපි ඉංග්\u200dරීසි භාෂා ජෝඩාවෙන් ඉංග්\u200dරීසි භාෂා ජෝඩාවෙන් භාෂාවාදයේ සමාගත්ත භාවිතයේ තාර්මාන්\u200dය විශේෂ අවධානයක් සම්පූර්ණ කරන්න, අපි තාර්මාන්\u200dය විශේෂ දත්ත විශාලනයේ අ අපි ටැග් පාවිච්චි කරනවා සම්බන්ධ වාක්ය වලට පරිවර්තනය සම්බන්ධ කරනවා. අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරන්න බිල්ලි භාෂාවක් කොර්පුස් වලින් ප්\u200dරශ්නයක් නිර්මාණය කරල විස්තර කලින් ප්\u200dරක්\u200dරියාස කරන්න සහ පරික්ෂණය දත්ත, ඩොමේන් වලින් ප්\u200dරක්\u200dරියාව සහ පරික්ෂණය අපේ පද්ධතියේ භාව අපේ පිළිගන්න පුළුවන් තර්ජනයේ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් තියෙන්නේ.', 'ml': 'ടെര്\u200dമിനോളജികള്\u200d പങ്കുചേര്\u200dക്കുന്ന ജോലി ഉപയോഗിച്ച് ഞങ്ങളുടെ ജോലി WMT 2021 മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നത ഞങ്ങള്\u200d പങ്കാളിയുള്ള പരിഭാഷയുടെ ടെര്\u200dമിനോളജിയുടെ ജോലിയില്\u200d പങ്കുചേര്\u200dക്കുന്നു. ചൈനീസ് ഭാഷ ജോ ടെര്\u200dമിനിലോളജിയെ പരിഭാഷപ്പെടുത്താന്\u200d നിര്\u200dബന്ധങ്ങള്\u200d തൃപ്തിപ്പെടുത്താന്\u200d വേണ്ടി, ടെര്\u200dമിനോളജി ഡേറ്റാ ആഗ് We used tags to mark and add the term translations into the matched sentences.  ട്രെയിനിങ്ങളുടെ വാക്ക് പരിശീലനത്തിനുള്ള വിവരങ്ങളുടെ വിഭാഷകങ്ങളുടെ വിഭാഷകങ്ങള്\u200dക്കുള്ള വാക്കിന്റെ ടേബ്ള വിശദീകരിക്കുന്ന വിവരങ്ങള്\u200d, ഡൊമെയിന്\u200d ഫിന്തുലിങ്ങ് എന്നിവയുടെ രീതിയില്\u200d ഉപയോഗിക്കുന്നു നമ്മുടെ സമ്മതം മത്സരിക്കുന്നത് ടെര്\u200dമിനോളജിയുടെ ലക്ഷ്യത്തിനുള്ള പരിഗണനത്തിന്റെ ഫലങ്ങളാണ്.', 'sv': 'Denna uppsats beskriver v책rt arbete i WMT 2021 Machine Translation med hj채lp av Terminologies Shared Task. Vi deltar i den gemensamma 철vers채ttningsterminiouppgiften p책 engelska till kinesiska spr책kpar. F철r att uppfylla terminologibegr채nsningar f철r 철vers채ttning anv채nder vi en strategi f철r att 철ka terminologidata baserad p책 Transformer-modellen. Vi anv채nde taggar f철r att markera och l채gga till term철vers채ttningar i matchade meningar. Vi skapade syntetiska termer med hj채lp av frastabeller extraherade fr책n tv책spr책kig korpus f철r att 철ka andelen term철vers채ttningar i utbildningsdata. Detaljerad f철rbehandling och filtrering av data, in-domain finetuning och ensemble metod anv채nds i v책rt system. V책r inl채mning ger konkurrenskraftiga resultat i den terminologiinriktade utv채rderingen.', 'ta': 'இந்த தாள் WMT 2021 இயந்திரத்தில் எங்கள் வேலை மொழிபெயர்ப்பை குறிப்பிடுகிறது முனைனலியல் பங்கிட்ட பணியை பயன்பட நாங்கள் பங்கிடப்பட்ட மொழிபெயர்ப்பு மொழிமாற்றி பணியில் பகிர்ந்து சீன மொழி ஜோடிக்கு ஆங்கிலத்த மொழிபெயர்ப்பு மொழிபெயர்ப்பில் முனைய நிறுவனம் கட்டுப்பாடுகளை திருப்தி செய்ய, மாற்று மாதிரிமுறைமையை அடிப நாங்கள் ஒப்பிட்ட வாக்கியங்களை குறிக்க மற்றும் மொழிபெயர்ப்பை சேர்க்க பயன்படுத்தினோம். நாம் இரண்டு மொழிக்கோட்டிலிருந்து வெளியேற்றப்பட்ட சொற்றொடர் அட்டவணைகளை உருவாக்கி பயிற்சி தரவில் மொழிமாற்றுப தரவு, டோமைன் பின்துலிங் மற்றும் தனிப்பயன் முறைமையில் பயன்படுத்தப்படுகிறது. நம்முடைய சரணங்கள் பொருத்தும் விளைவுகளை பெறுகிறது முனைனஞ்சலியல் எதிர்பார்ப்பு மதிப்பில்.', 'ur': 'This paper describes our work in the WMT 2021 Machine Translation using Terminologies Shared Task. ہم انگلیسی زبان جوڑے میں شریک ترجمہ ٹریمولوژ کے کام میں شریک ہوتے ہیں۔ ترمینلوژی کی تعریف پر محدودیت کرنے کے لئے، ہم ترمینٹر موڈل پر بنیاد رکھتے ہیں ترمینٹلوژی ڈاٹ افزایش استراتژی استعمال کرتے ہیں. ہم نے ٹاگ کو علامت کے لئے استعمال کیا اور مطابق جماعتوں میں ترجمہ جمع کیا۔ ہم نے فریز ٹیبل کے مطابق پیدا کئے ہیں جو دو زبان کی کورپوس سے نکالے گئے ہیں تاکہ تربیت ڈیٹوں میں تربیت کا مقدار زیادہ کریں۔ ہمارے سیسٹم میں پھیرے جاتے ہیں ہماری مسلمانیت ترمینلوژی کے ذریعہ مطابق مقرر ہونے کے نتیجے حاصل کئے جاتے ہیں.', 'uz': "Bu qogʻoz WMT 2021 mashina tarjima qilishimizni Terminologlar bilan birlashtirilgan vazifani anglatadi. Biz bir xitoycha tildagi tarjimalarning vazifani ingliz tilida Xitoy tilning ikki xitoblarga qayta olamiz. Terminologi tarjima qilishni tahrirlash uchun, biz Transformer modelda asosida terminolog maʼlumot soʻzlashtirish strategini foydalanamiz. @ info: whatsthis @ info: whatsthis @ info: whatsthis Bizning javob berilganimiz terminologiya qanday qiymatga rivojlanish natijalariga ega bo'ladi.", 'vi': 'Tờ giấy này mô tả công việc của chúng ta trong bản Dịch cỗ máy WRT 2021 bằng Giao dịch Terminologies sẻ. Chúng tôi tham gia vào nhiệm vụ chuyển dịch chung trong tiếng Anh đến cặp ngôn ngữ Trung Quốc. Để thoả mãn các hạn chế thuật ngữ về dịch, chúng tôi sử dụng một chiến lược gia tăng dữ liệu theo thuật ngữ, dựa trên mô hình transformer. Chúng tôi đã sử dụng các thẻ để đánh dấu và thêm các thuật ngữ dịch vào các câu tương ứng. Chúng tôi tạo ra các thuật ngữ tổng hợp bằng các từ điển hình chiết xuất từ tập đoàn hai thứ hai để tăng tỷ lệ dịch thuật ngữ trong dữ liệu huấn luyện. Cách xử lý chi tiết và lọc chi tiết trên dữ liệu, cấu trừng và kết hợp trong miền được dùng trong hệ thống. Việc đệ trình của chúng tôi đạt kết quả cạnh tranh trong việc đánh giá tiêu chuẩn.', 'bg': 'Настоящата статия описва нашата работа в Машинен превод с използване на споделена задача терминологии. Участваме в съвместната задача за превод на терминологии от английски на китайски език. За да задоволим терминологичните ограничения при превода, използваме стратегия за увеличаване на терминологичните данни, базирана на модела на трансформатор. Използвахме тагове, за да маркираме и добавим преводи на термина в съвпадащите изречения. Създадохме синтетични термини, използвайки фразови таблици, извлечени от двуезичен корпус, за да увеличим дела на преводите на термини в данните за обучение. В нашата система се използват подробна предварителна обработка и филтриране на данни, фино настройване и ансамбъл метод. Нашите предложения получават конкурентни резултати в терминологично насочената оценка.', 'da': 'Dette dokument beskriver vores arbejde i WMT 2021 Machine Translation ved hjælp af Terminologies Shared Task. Vi deltager i den delte oversættelsesterminologi opgave på engelsk til kinesisk sprogpar. For at imødekomme terminologibegrænsninger i forbindelse med oversættelse anvender vi en strategi for forøgelse af terminologidata baseret på Transformer-modellen. Vi brugte tags til at markere og tilføje termoversættelser i de matchede sætninger. Vi skabte syntetiske termer ved hjælp af sætningstabler udvundet fra tosproget korpus for at øge andelen af termoversættelser i træningsdata. Detaljeret forbehandling og filtrering af data, in-domæne finjustering og ensemble metode anvendes i vores system. Vores indsendelse opnår konkurrencedygtige resultater i den terminologimålrettede evaluering.', 'de': 'Dieser Beitrag beschreibt unsere Arbeit in der WMT 2021 Machine Translation unter Verwendung von Terminologies Shared Task. Wir nehmen an der gemeinsamen Übersetzungsterminologieaufgabe in Englisch in Chinesisch teil. Um terminologische Einschränkungen bei der Übersetzung zu erfüllen, verwenden wir eine Strategie zur Erweiterung von Terminologiedaten auf Basis des Transformer-Modells. Wir haben Tags verwendet, um die Termübersetzungen zu markieren und in die passenden Sätze hinzuzufügen. Wir erstellten synthetische Begriffe mit Phrasentabellen, die aus bilingualen Korpus extrahiert wurden, um den Anteil von Termübersetzungen in Trainingsdaten zu erhöhen. Detaillierte Vorverarbeitung und Filterung von Daten, In-Domain-Feinabstimmung und Ensemble-Methode werden in unserem System verwendet. Unsere Einreichung erzielt wettbewerbsfähige Ergebnisse in der terminologieorientierten Auswertung.', 'hr': 'Ovaj papir opisuje naš rad u WMT 2021. prevodu strojeva koristeći dijeljeni zadatak terminologija. Mi učestvujemo u zadatku zajedničkih terminologija prevoda na engleskom jeziku na kineskom parovu. Da bi zadovoljili ograničenja terminologije na prevodu, koristimo strategiju povećanja podataka terminologije na temelju model a transformera. Koristili smo znakove za označavanje i dodanje termina prevoda u odgovarajuće rečenice. Stvorili smo sintetičke uvjete koristeći tablice fraze izvučene iz dvojezičkog korpusa kako bi povećali proporciju pojedinačnih prevoda u podacima obuke. Detaljno preobrađivanje i filtriranje podataka, metode finetuniranja i ensemble u domenu se koriste u našem sustavu. Naša predstava dobiva konkurentne rezultate u procjeni ciljanoj terminologiji.', 'nl': 'Dit artikel beschrijft ons werk in de WMT 2021 Machine Translation met behulp van Terminologies Shared Task. We nemen deel aan de gedeelde vertaalterminologietak in het Engels naar Chinees taalpaar. Om te voldoen aan terminologische beperkingen op vertaling, gebruiken we een strategie voor terminologie data augmentatie gebaseerd op Transformer model. We gebruikten tags om de termvertalingen te markeren en toe te voegen aan de overeenkomende zinnen. We hebben synthetische termen gemaakt met behulp van zinnentabellen die zijn geëxtraheerd uit tweetalig corpus om het aandeel van termvertalingen in trainingsgegevens te verhogen. Gedetailleerde voorbewerking en filtering van gegevens, in-domain finetuning en ensemble methode worden gebruikt in ons systeem. Onze inzending levert concurrerende resultaten op in de terminologiegerichte evaluatie.', 'ko': '본고는 우리가 WMT 2021 기계 번역에서 용어를 사용하여 임무를 공유하는 작업을 묘사한다.우리는 영한 언어 배합 중의 용어 공유 번역 임무에 참여했다.번역에 대한 용어의 제한을 충족시키기 위해 Transformer 모델을 바탕으로 하는 용어 데이터 확장 전략을 사용했습니다.우리는 라벨 표기 용어를 사용하여 번역하고 일치하는 문장에 추가합니다.우리는 이중 언어 자료 라이브러리에서 추출한 단어표를 사용하여 합성 용어를 만들어서 용어가 훈련 데이터에 번역되는 비율을 높인다.시스템은 상세한 데이터 예처리와 필터, 역내 마이크로스피커와 계통 방법을 채택했다.우리가 제출한 자료는 용어 목표 평가에서 경쟁력 있는 결과를 얻었다.', 'sw': 'Gazeti hili linaelezea kazi yetu katika Tafsiri ya Mashindano ya WMT 2021 kwa kutumia Tamko la Kugawanya Terminologies. We participate in the shared translation terminologies task in English to Chinese language pair.  Ili kuwaridhisha vizuizi vya utafsiri wa ngono, tunatumia mkakati wa kuongeza takwimu za utoaji wa tamaduni kwa kutumia mifano ya Transformer. Tulitumia alama za kuadhimisha na kuongeza tafsiri ya neno katika sentensi zilizofanana. Tumetengeneza maneno ya pamoja kwa kutumia meza zilizotolewa kutoka kwenye viungo vya lugha mbili ili kuongeza kiwango cha tafsiri za neno katika taarifa za mafunzo. Utafiti wa zamani na kuchuja taarifa za taarifa, uzazi wa ndani na mbinu za upinzani zinatumiwa katika mfumo wetu. Ujumbe wetu unapata matokeo ya ushindani katika tathmini za kimaadilojia.', 'id': 'Kertas ini menjelaskan pekerjaan kita di WMT 2021 Translation Machine menggunakan Terminologies Shared Task. Kami berpartisipasi dalam tugas terminologi terjemahan berbagi dalam bahasa Inggris ke pasangan bahasa Cina. Untuk memenuhi batas terminologi pada terjemahan, kita menggunakan strategi peningkatan data terminologi berdasarkan model Transformer. Kami menggunakan tag untuk menandai dan menambahkan terma terjemahan ke kalimat yang cocok. Kami menciptakan istilah sintetis menggunakan tabel frasa yang diekstraksi dari tubuh dua bahasa untuk meningkatkan proporsi terjemahan istilah dalam data latihan. Pre-proses dan penapisan rincian pada data, penentuan dalam domain dan metode ensemble digunakan dalam sistem kita. Pengiriman kami mendapatkan hasil kompetitif dalam evaluasi yang ditujukan terminologi.', 'fa': 'این کاغذ کار ما را در ترجمه ماشین WMT 2021 با استفاده از کار مشترک ترمینولوژی توصیف می کند. ما در کار ترمینالوژی مشترک در انگلیسی به جفت زبان چینی شرکت می کنیم. برای تعداد محدودیت ترمینالوژی بر ترجمه، استفاده از استراتژی افزایش داده\u200cهای ترمینالوژی بر اساس مدل ترجمه\u200cکننده استفاده می\u200cکنیم. ما از نقاشی استفاده کردیم تا علامت بگیریم و ترجمه\u200cها را به جمله\u200cهای متفاوت افزودیم. ما با استفاده از میز\u200cهای عبارتی که از شرکت دو زبان استخراج شده\u200cاند، برای افزایش مقدار ترجمه\u200cهای عبارتی در داده\u200cهای آموزش آفریدیم. روش پیش\u200cپردازی و فیلتر\u200cبندی\u200cهای جزئیات در داده\u200cها، پایین\u200cبندی\u200cهای دامنه\u200cی دامنه\u200cها و دستگاه\u200cبندی\u200cها در سیستم ما استفاده می\u200cشوند. تحويل ما نتايج مسابقه ي مسابقه رو در ارزيابي هدف ترمينالوژي پيدا ميکنه', 'tr': 'Bu kagyz WMT 2021-nji Maşynyň terjimesini Terminologies Paýlaşdyrylýan Görevlerimizi ulanyp barýar. Biz Iňlis dilinde Çin çe dil çiftine paýlaşan terjime täbliklerinde goşulýarys. Terjime etmekde terjime etmek üçin terminologiýanyň hasarlaryny saýlamak üçin, Transformer modelini daýanýan bir terminologiýa maglumaty ekleýän strategiýany ulanýarys. Tägleri nişan etmek üçin we terjime edilen sözlere eklemek üçin ullandyk Biz iki dilden çykan fraz täbliklerinden terjime etmek üçin syntetik şertleri yaratdyk. Detaylı ön işlem we filtrelemek, domençe finetuning we ensemble yöntemimiz sistemimizde ullanylar. Biziň gönüşümiz terminologiýanyň maksady çykyşynda ýaryşykly netijeleri gazanýar.', 'af': "Hierdie papier beskrywe ons werk in die WMT 2021 Masjien Vertaling met gebruik van Terminologies Deel Taak. Ons deel in die gedeelde vertalingsterminologies taak in Engels na Sjinese taal paar. Om terminologie beheinings op vertaling te voldoen, gebruik ons 'n terminologie data augmentasie strategie gebaseer op Transformer model. Ons het etikette gebruik om die term vertalings in die ooreenstemmende teikens te merk en byvoeg. Ons het sintetiese terme geskep met gebruik van frase tabelle uitgevoer van twee tale korpus om die proporsie van term vertalings in onderwerp data te vermeerder. Gedetaileerde voorafverwerking en filtering op data, in- domein finetuning en ensemble metode word gebruik in ons stelsel. Ons ondersteuning kry mededingsresultate in die bepaalde evaluering van terminologie.", 'sq': 'Ky artikull përshkruan punën tonë në WMT 2021 Machine Translation duke përdorur Terminologies Shared Task. Ne marrim pjesë në detyrën e përkthimit të përbashkët të terminologjive në anglisht në çiftin e gjuhës kineze. Për të përmbushur kufizimet e terminologjisë në përkthimin, ne përdorim një strategji të rritjes së të dhënave terminologjike bazuar në modelin Transformer. Ne përdorëm etiketa për të shënuar dhe shtuar përkthimet e termit në frazat e përshtatshme. Ne krijuam terma sintetike duke përdorur tabela frazësh të nxjerra nga trupi dy-gjuhës për të rritur proporcionin e përkthimeve termike në të dhënat e trajnimit. Në sistemin tonë përdoren paraprocesimi dhe filtrimi i detajuar i të dhënave, përmirësimi në domeni dhe metoda e mbledhjes. Subjektimi ynë merr rezultate konkurruese në vlerësimin e synuar nga terminologjia.', 'az': 'Bu kağıt WMT 2021 mašin in çevirilməsini Terminologies paylaşdırılmış iş vasitəsilə istifadə edir. Biz İngilizə dil çiftəsinə bölünən tercümə terminologilərinin işin ə katılırıq. Tercümə üzərində terminoloji müəyyənləşdirmələri təmizləmək üçün, Transformer modeli üzərində tabanlı terminoloji məlumatları artırmaq stratejisini istifadə edirik. Biz etiketləri işarə salmaq və sözlərin çevirilməsini eşitmək üçün istifadə etdik. İki dil korpusdan çıxarılmış fraz tabelaları ilə sintetik şəkilləri yaratdıq, təhsil məlumatlarında tercümələrin proporsiyasını artırmaq üçün. Məlumatların, domena finetuning və ensemble metodlarının detaylı ön işləməsi və filtrləməsi sistemimizdə istifadə edilir. Bizim təklifimiz terminoloji məqsədilə müqayisədi sonuçlarını verir.', 'bn': 'This paper describes our work in the WMT 2021 Machine Translation using Terminologies Shared Task.  আমরা ভাগাভাগি অনুবাদের টার্মিনোলজি কাজে অংশগ্রহণ করি চীনা ভাষার জোড়ায়। টার্মিনোলজি অনুবাদের উপর নিষেধাজ্ঞা পূর্ণ করার জন্য, আমরা টার্মিনোলজি ডাটা ব্যবহার করি ট্রান্সফার্ন মডেলের ভিত্ আমরা ট্যাগ ব্যবহার করেছি মিলিত বাক্যে শব্দ অনুবাদ যোগ করার জন্য। প্রশিক্ষণের তথ্যে শব্দ অনুবাদ বৃদ্ধি করার জন্য আমরা বাক্য টেবিল ব্যবহার করে সিন্টেটিক শব্দ সৃষ্টি করেছি। আমাদের সিস্টেমে বিস্তারিত পূর্ব প্রক্রিয়া এবং ফিল্টারিং তথ্য, ডোমেইন ফিন্সুটিং এবং এক্সপেল পদ্ধতি ব্যবহার করা হয় আমাদের সামনে প্রতিযোগিতার ফলাফল পেয়েছে টার্মিনোলজির লক্ষ্যের মূল্য।', 'hy': 'Այս հոդվածը նկարագրում է մեր աշխատանքը ԱՄԹ 2021 թվականի մեքենայի թարգմանությունում՝ օգտագործելով կիսված տերմինոլոգիաներ: Մենք մասնակցում ենք թարգմանման ընդհանուր տերմինոլոգիաների խնդիրներին անգլերենով չինական զույգով: Թարգմանության տերմինոլոգիայի սահմանափակումներին բավարարելու համար մենք օգտագործում ենք տերմինոլոգիայի տվյալների աճի ռազմավարություն, որը հիմնված է Թանֆորմերի մոդելի վրա: Մենք օգտագործեցինք թեգներ, որպեսզի նշենք և ավելացնենք տերմինը համապատասխան նախադասությունների մեջ: Մենք ստեղծեցինք սինթետիկ տերմիներ՝ օգտագործելով երկլեզու մարմնից ստացված արտահայտությունների աղյուսակներ, որպեսզի ավելացնենք արտահայտությունների թարգմանությունների համեմատությունը կրթության տվյալներում: Detailed pre-processing and filtering on data, in-domain finetuning and ensemble method are used in our system.  Our submission obtains competitive results in the terminology-targeted evaluation.', 'am': 'ይህ ገጽ በWMT 2021 የመኪን ትርሚኖሎጂዎች በተለየ ስራዎችን በመጠቀም የሚሠራንን ትርጉም ይናገራል፡፡ በተካፈለው ትርጉም ተርሚኖሎጂ ሥራ በንግግሊዝኛ ለቻይና ቋንቋ ሁለት እናጋራለን፡፡ ተርሚኖሎጂ ግንኙነትን ለመጠቀም፣ በተርጓሜው ሞዴል ላይ የተመሳሳይ ተርሚኖሎጂ ዳታ አጨማሪው strategy እናስጠጋለን፡፡ እና የቃላትን ትርጉም ወደ ተቃራኒው ንግግር ለመደበቅ እና ለመጨመር ምልክቶችን ተጠቀምን፡፡ በሁለት ቋንቋዎች ካርፓስ ውስጥ የንግግር ትርጓሜዎችን በመጠቀም የቋንቋዎች ጽሑፎችን በመጠቀም አንድነትን አፈጣጠርን፡፡ የጠቅላላ ምርጫዎች ታዋቂያችን በተቃውሞ የተርሚኖሎጂ ማስታወቂያውን አግኝቷል፡፡', 'bs': 'Ovaj papir opisuje naš rad u WMT 2021-om uređajnom prevodu koristeći zajednički zadatak terminologija. Mi učestvujemo u zadatku zajedničkog terminologa prevoda na engleskom jeziku na kineskom parovu. Da bi zadovoljili ograničenja terminologije na prevodu, koristimo strategiju povećanja podataka terminologije na osnovu model a transformera. Koristili smo znakove za označavanje i dodanje termina prevoda u odgovarajuće rečenice. Stvorili smo sintetičke termine koristeći tablice fraze izvučene iz dvojezičkog korpusa kako bi povećali proporciju terminalnih prevoda u podacima obuke. Detaljno preobrađivanje i filtriranje podataka, finetuniranje i ensembliranje domena se koriste u našem sistemu. Naša podnošenja dobija konkurentne rezultate u procjeni na terminologiju.', 'ca': "Aquest article descriu la nostra feina a la traducció de màquines WMT 2021 utilitzant la tasca compartida de terminològies. Participem en la tasca compartida de terminologies de traducció en anglès a xinès. Per satisfer les restriccions terminològiques en la traducció, utilitzem una estratègia d'augment de les dades terminològiques basada en el model Transformer. Vam utilitzar etiquetes per marcar i afegir els termes de traducció a les frases combinades. Vam crear termes sintètics utilitzant taules de frases extraïdes del cos bilingue per augmentar la proporció de traduccions de termes en dades d'entrenament. Detailed pre-processing and filtering on data, in-domain finetuning and ensemble method are used in our system.  La nostra presentació obté resultats competitius en l'evaluació mirada a la terminologia.", 'et': 'Käesolevas artiklis kirjeldatakse meie tööd WMT 2021 masintõlkes terminoloogiate jagatud ülesande abil. Osaleme ühise tõlke terminoloogia ülesandes inglise keelest hiina keelde. Tõlkimise terminoloogiliste piirangute rahuldamiseks kasutame Transformeri mudelil põhinevat terminoloogia andmete suurendamise strateegiat. Me kasutasime silte, et märkida ja lisada termini tõlked sobitatud lausetesse. Loosime sünteetilised terminid, kasutades kahekeelsest korpusest eraldatud fraasitabeleid, et suurendada terminitõlkete osakaalu koolitusandmetes. Meie süsteemis kasutatakse üksikasjalikku eeltöötlust ja andmete filtreerimist, domeenisisest peenhäälestust ja ensemble meetodit. Meie esitus annab terminoloogiale suunatud hindamisel konkurentsivõimelisi tulemusi.', 'cs': 'Tento článek popisuje naši práci ve strojovém překladu WMT 2021 pomocí sdílené úlohy terminologií. Podílíme se na sdíleném překladu terminologií v jazykovém páru z angličtiny do čínštiny. Pro splnění terminologických omezení překladu používáme strategii rozšíření terminologických dat založenou na modelu Transformer. Použili jsme tagy k označení a přidání termínů do shodných vět. Vytvořili jsme syntetické termíny pomocí frázových tabulek extrahovaných z dvojjazyčného korpusu, abychom zvýšili podíl překladů termínů v tréninkových datech. V našem systému se používá podrobné předzpracování a filtrování dat, in-domain finetuning a ensemble metoda. Náš příspěvek dosahuje konkurenčních výsledků v terminologicky cíleném hodnocení.', 'fi': 'T채ss채 artikkelissa kuvataan ty철t채mme WMT 2021 -konek채채nn철ksess채 k채ytt채en Terminologies Shared Task -teht채v채채. Osallistumme yhteiseen k채채nn철sty철teht채v채채n englanniksi kiinaksi. K채채nt채misen terminologiarajoitteiden t채ytt채miseksi k채yt채mme Transformer-malliin perustuvaa terminologian datan lis채채misstrategiaa. K채ytimme tunnisteita merkitse채ksemme ja lis채t채ksemme termik채채nn철kset vastaamaan lauseita. Luomme synteettisi채 termej채 k채ytt채m채ll채 kaksikielisest채 korpusesta poimittuja lausetaulukoita, jotta termik채채nn철sten osuutta koulutusaineistossa voitaisiin lis채t채. J채rjestelm채ss채mme k채ytet채채n yksityiskohtaista tietojen esik채sittely채 ja suodatusta, sis채ist채 hienos채채t철채 ja ensemble-menetelm채채. Tekstimme tuottaa kilpailukykyisi채 tuloksia terminologiaan kohdistetussa arvioinnissa.', 'ha': "@ title Tuna raba cikin aikin taƙaitori da aka raba shi a cikin Ingiriya zuwa sau biyu na harshen China. To, dõmin ya yarda da tsarin taƙaitori kan fassarar, za mu yi amfani da wani akadi na ƙararra da taƙaitori a kan misalin Transformer. Mun yi amfani da tagogi dõmin ka yi alama kuma mu ƙara fassarar magana cikin sonar da suka daidaita. Kuma Mun halicci maganar synthetic da Muka yi amfani da dukkan rasmi wanda aka samar da shi daga nau'in-biyu, dõmin ya ƙara tsakanin fassarar-fassarar cikin danne da za'a yi amfani da shi. @ info: whatsthis MadagaskiyinMu yana sami matsalar da ta yi jihãdi a cikin jarraba-jarraba.", 'sk': 'Ta prispevek opisuje naše delo v strojnem prevajanju WMT 2021 z uporabo opravila v skupni rabi terminologij. Sodelujemo pri skupni prevajalski terminologiji v angleščini v kitajščino. Za izpolnitev terminoloških omejitev pri prevajanju uporabljamo terminološko strategijo povečanja podatkov, ki temelji na modelu Transformer. Z oznakami smo označili in dodali prevode izraza v ujemajoče stavke. Ustvarili smo sintetične izraze s fraznimi tabelami iz dvojezičnega korpusa, da bi povečali delež prevodov izrazov v podatkih o usposabljanju. V našem sistemu se uporabljajo podrobna predobdelava in filtriranje podatkov, fine tuning in ensemble metoda. Naša predložitev dosega konkurenčne rezultate pri terminološko usmerjenem vrednotenju.', 'he': 'העיתון הזה מתאר את עבודתנו בתרגום מכונות WMT 2021 באמצעות משימה משותפת בטרמינולוגיות. אנחנו משתתפים במשימת הטרמולוגיות המשותפת באנגלית לזוג שפה סינית. כדי לספק מגבלות בטרמולוגיה על התרגום, אנחנו משתמשים באסטרטגיה של גידול נתונים בטרמולוגיה מבוססת על מודל טרנספורר. השתמשנו בתגים כדי לסמן ותוסיף את המונח התרגשות למשפטים המתאימים. יצרנו מונחים סינטטיים באמצעות שולחנות ביטויים שנוצרו מהגוף השולשי כדי להעלות את המספר של התרגשות המונחיות בנתונים האימונים. שיטת מערכת שלנו משתמשת במערכת. ההצגה שלנו מקבלת תוצאות תחרותיות בהערכה המתכוונת לטרמולוגיה.', 'jv': 'Perintah iki rambaran ning barêng-barêng nggawe uwis nêmên ning mbêng, WêT 2020 1 Mahine Terjamahan nggambar "Terminal inulogies Joined tasks" Awak dhéwé menyang pisan karo terjamahan kanggo nggambar ingkang karo pawaran Cainan. To fill terminal limits on translation, we use a terminal data agement policy supported on Transformer model. bookmark Anyone Detayed before-operation and filling on data, in-domain Finetuning and ensembedle method are used in we System. Rasané awakdhéwé éntuk sawetara dadi kapan ingkang dipunangé, ora dadi mebalé', 'bo': 'ཤོག ང་ཚོས་དབྱིན་ཡིག་གི་སྐད་རིགས་གཉིས་ཀྱི་ནང་དུ་དབྱིན་ཡིག To satisfy terminology constraints on translation, we use a terminology data augmentation strategy based on Transformer model. ང་ཚོས་ཤོག་བྱང་ཚིག་རྟགས ང་ཚོས་དབུགས་ཕྱོགས་ཀྱི་ཚིག་རྩོམ་པ་ལ་ལག་ལེན་འཐབ་པའི་ཐབས་ལམ་སྒྲིག་འཛུགས་བྱས་པ་ཡིན། Detailed pre-processing and filtering on data, in-domain finetuning and ensemble method are used in our system. ང་ཚོའི་དབྱིབས་ཡུལ་གྱིས་གནད་དོན་རྐྱེན་གྱིས་མཐའ་འབྲས་བ་རེད།'}
{'en': 'FJWU Participation for the WMT21 Biomedical Translation Task', 'fr': 'Participation de la FJWU à la tâche de traduction biomédicale WMT21', 'pt': 'Participação da FJWU na Tarefa de Tradução Biomédica do WMT21', 'es': 'Participación de la FJWU en la tarea de traducción biomédica WMT21', 'ar': 'مشاركة FJWU في مهمة الترجمة الطبية الحيوية WMT21', 'ja': 'WMT 21生物医学翻訳タスクへのFJWUの参加', 'zh': 'FJWU参WMT21生物医学译事', 'hi': 'WMT21 बायोमेडिकल अनुवाद कार्य के लिए FJWU भागीदारी', 'ru': 'Участие FJWU в задаче биомедицинского перевода WMT21', 'ga': 'Rannpháirtíocht FJWU i dTasc Aistriúcháin Bithleighis WMT21', 'hu': 'Az FJWU részvétele a WMT21 Bioorvosi Fordítási Feladatban', 'ka': 'Comment', 'el': 'Συμμετοχή του FJWU στο έργο βιοϊατρικής μετάφρασης του WMT21', 'it': 'Partecipazione FJWU al compito di traduzione biomedica WMT21', 'lt': 'FJWU dalyvavimas WMT21 Biomedicinos vertimo užduotyje', 'mk': 'Учеството на ФЈВЕ во задачата за биомедицински превод на WMT21', 'kk': 'FJWU WMT21 биомедикалық аудару тапсырмасының қатынасы', 'ml': 'WMT21 ബിയോമിഡിക്കല്\u200d പരിഭാഷകങ്ങളുടെ പണിയില്\u200d FJWU പങ്കാളി', 'ms': 'Perkongsian FJWU untuk Tugas Terjemahan Biomedis WMT21', 'mt': 'Parteċipazzjoni tal-FJWU għall-Kompitu tat-Traduzzjoni Bijomedika WMT21', 'mn': 'FJWU WMT21 Biomedical Translation Task-д оролцож байна', 'no': 'FJWU-deltakar for WMT21 biomedicinsk omsetjingsprogrammet', 'ro': 'Participarea FJWU la misiunea de traducere biomedicală WMT21', 'pl': 'Udział FJWU w zadaniu tłumaczenia biomedycznego WMT21', 'sr': 'FJWU sudjelovanje za WMT21 biomedicinski prevodni zadatak', 'si': 'Name', 'so': 'FJWU ka qayb-qaadashada shaqada WMT21 Biomedical Translation', 'ta': 'WMT21 பையோமிடிக்கல் மொழிபெயர்ப்பு பணிக்கான FJWU பகிர்வு', 'sv': 'FJWU:s deltagande i WMT21 biomedicinsk översättning', 'ur': 'FJWU مشارکت WMT21 Biomedical Translation Task کے لئے', 'uz': 'Name', 'vi': 'Liên kết FJWU cho Nhiệm vụ dịch hạch Khoa học WM21', 'bg': 'Участие на ФБУ в задачата за биомедицински превод на WMT21', 'hr': 'FJWU učestvovanje za WMT21 biomedicinski prevodni zadatak', 'nl': 'Deelname van de FJWU aan de WMT21 Biomedische vertaaltaak', 'da': "FJWU's deltagelse i WMT21 Biomedicinsk Oversættelsesopgave", 'de': 'FJWU Teilnahme an der WMT21 Biomedical Translation Task', 'id': 'FJWU Participation for the WMT21 Biomedical Translation Task', 'fa': 'شرکت FJWU برای ترجمه بیولوژیک WMT21', 'ko': 'FJWU, WMT21 생물의학 번역 작업 참여', 'sw': 'Ushiriki wa FJWU kwa ajili ya Task la Tafsiri ya Biomedical WMT21', 'tr': 'FJWU WMT21 Biwomedik terjime zadynyň bölegi', 'sq': 'Pjesëmarrja e FJWU për detyrën e përkthimit Biomjekësor WMT21', 'af': 'FJWU Deelnadering vir die WMT21 Biomediese Vertaling Taak', 'am': 'WMT21 Biomedical Translation Task', 'hy': 'FJW-ի մասնակցությունը World MT21 Բիոբիոբժշկական թարգմանման գործում', 'az': 'FJWU WMT21 Biomedical Translation Task', 'bn': 'WMT21 বায়োমিকাল অনুবাদের কাজের জন্য FJWU অংশগ্রহণ', 'ca': 'Participació de la FJWU en la tasca de traducció biomèdica WMT21', 'bs': 'FJWU učestvovanje za WMT21 biomedicinski prevodni zadatak', 'et': 'FJWU osalemine WMT21 biomeditsiinilise tõlke ülesandes', 'cs': 'Účast FJWU na biomedicínském překladu WMT21', 'fi': 'FJWU:n osallistuminen WMT21 Biomedical Translation Task -hankkeeseen', 'jv': 'FjWU Kemerdekaan kanggo terjamahan wék-utek kanggo WB9', 'sk': 'Sodelovanje FJWU pri nalogi biomedicinskega prevajanja WMT21', 'ha': 'FJWU Sharicin wa WMT21 Biomedical Translate', 'bo': 'FJWU Participation for the WMT21 Biomedical Translation Task', 'he': 'FJWU Participation for the WMT21 Biomedical Translation Task'}
{'en': 'In this paper we present the FJWU’s system submitted to the biomedical shared task at WMT21. We prepared state-of-the-art multilingual neural machine translation systems for three languages (i.e. German, ', 'ar': 'في هذه الورقة نقدم نظام FJWU المقدم إلى المهمة الطبية الحيوية المشتركة في WMT21. قمنا بإعداد أحدث أنظمة الترجمة الآلية العصبية متعددة اللغات لثلاث لغات (أي الألمانية والإسبانية والفرنسية) مع اللغة الإنجليزية كلغة مستهدفة. تم تدريب أنظمة NMT الخاصة بنا على أساس بنية المحولات ، على مجموعة من الشركات الموازية داخل المجال وخارج المجال التي تم تطويرها باستخدام تقنيات استرجاع المعلومات (IR) وتكييف المجال.', 'fr': "Dans cet article, nous présentons le système de la FJWU soumis à la tâche biomédicale partagée au WMT21. Nous avons préparé des systèmes de traduction automatique neuronale multilingues de pointe pour trois langues (allemand, espagnol et français) avec l'anglais comme langue cible. Nos systèmes NMT basés sur l'architecture Transformer ont été formés à la combinaison de corpus parallèles dans le domaine et hors domaine développés à l'aide de techniques de récupération d'informations (IR) et d'adaptation de domaine.", 'es': 'En este artículo presentamos el sistema de la FJWU presentado a la tarea biomédica compartida en el WMT21. Preparamos sistemas de traducción automática neuronal multilingüe de última generación para tres idiomas (es decir, alemán, español y francés) con el inglés como idioma de destino. Nuestros sistemas NMT, basados en la arquitectura Transformer, se capacitaron en la combinación de cuerpos paralelos dentro y fuera del dominio desarrollados mediante técnicas de recuperación de información (IR) y adaptación de dominio.', 'pt': 'Neste artigo apresentamos o sistema da FJWU submetido à tarefa biomédica compartilhada no WMT21. Preparamos sistemas de tradução automática neural multilíngue de última geração para três idiomas (ou seja, alemão, espanhol e francês) com o inglês como idioma de destino. Nossos sistemas NMT baseados na arquitetura Transformer, foram treinados na combinação de corpora paralelos no domínio e fora do domínio desenvolvidos usando técnicas de recuperação de informações (IR) e adaptação de domínio.', 'ja': '本稿では、WMT 21における生物医学的共有タスクに提出されたFJWUのシステムを紹介する。英語をターゲット言語とした3言語（ドイツ語、スペイン語、フランス語）の最先端の多言語ニューラル機械翻訳システムを準備しました。Transformerアーキテクチャに基づく当社のNMTシステムは、情報検索（ IR ）とドメイン適応技術を使用して開発されたインドメインとアウトドメインの並列コーパスの組み合わせについてトレーニングされました。', 'ru': 'В этой статье мы представляем систему FJWU, представленную для совместной биомедицинской задачи на WMT21. Мы подготовили современные многоязычные системы нейронного машинного перевода для трех языков (немецкий, испанский и французский) с английским в качестве целевого языка. Наши системы NMT, основанные на архитектуре Трансформатора, были обучены комбинации внутридоменных и внедоменных параллельных корпусов, разработанных с использованием методов извлечения информации (IR) и адаптации домена.', 'zh': '本文引WMT21生物医学共FJWU统。 吾为三语(即德语,西班牙语与法语)备先进多言神经机器翻译统,以英语为期。 盖Transformer架构之NMT系于用信息检索(IR)和域之应技术开发者,与域外并行语料库之组练焉。', 'hi': 'इस पेपर में हम WMT21 में बायोमेडिकल साझा कार्य के लिए प्रस्तुत FJWU की प्रणाली प्रस्तुत करते हैं। हमने लक्ष्य भाषा के रूप में अंग्रेजी के साथ तीन भाषाओं (यानी जर्मन, स्पेनिश और फ्रेंच) के लिए अत्याधुनिक बहुभाषी तंत्रिका मशीन अनुवाद प्रणाली तैयार की। ट्रांसफॉर्मर आर्किटेक्चर पर आधारित हमारे एनएमटी सिस्टम, इन-डोमेन और आउट-डोमेन समानांतर कॉर्पोरेट के संयोजन पर प्रशिक्षित किए गए थे, जो सूचना पुनर्प्राप्ति (आईआर) और डोमेन अनुकूलन तकनीकों का उपयोग करके विकसित किए गए थे।', 'ga': 'Sa pháipéar seo cuirimid i láthair córas an FJWU a cuireadh isteach don tasc roinnte bithleighis ag WMT21. D’ullmhaigh muid córais néar-aistrithe néaracha ilteangacha den scoth do thrí theanga (i.e. Gearmáinis, Spáinnis agus Fraincis) agus Béarla mar sprioctheanga acu. Cuireadh oiliúint ar ár gcórais NMT, atá bunaithe ar ailtireacht Trasfhoirmeora, ar mheascán de chorparáidí comhthreomhara laistigh agus lasmuigh den fhearann a forbraíodh ag baint úsáide as Aisghabháil Faisnéise (IR) agus teicnící oiriúnaithe fearainn.', 'hu': 'Ebben a tanulmányban bemutatjuk az FJWU rendszerét, amelyet a WMT21 orvostudományi közös feladata alá helyeztek. Három nyelvre (német, spanyol és francia) készítettünk korszerű, többnyelvű neurális gépi fordító rendszert, amelynek célnyelve angol. Transzformátor architektúrán alapuló NMT rendszereinket tartományon belüli és tartományon kívüli párhuzamos korpuszok kombinációjára képeztük, amelyeket információvisszaszerzési (IR) és domain adaptációs technikákkal fejlesztettek ki.', 'el': 'Στην παρούσα εργασία παρουσιάζουμε το σύστημα της FJWU που υποβλήθηκε στο βιοϊατρικό κοινό έργο στο WMT21. Προετοιμάσαμε υπερσύγχρονα πολύγλωσσα συστήματα νευρολογικής μηχανικής μετάφρασης για τρεις γλώσσες (δηλαδή γερμανικά, ισπανικά και γαλλικά) με την αγγλική ως γλώσσα-στόχο. Τα συστήματα μας βασισμένα στην αρχιτεκτονική μετασχηματιστών, εκπαιδεύτηκαν σε συνδυασμό παράλληλων σωμάτων εντός και εκτός τομέα που αναπτύχθηκαν χρησιμοποιώντας τεχνικές ανάκτησης πληροφοριών (IR) και προσαρμογής τομέα.', 'ka': 'ამ დომენტში ჩვენ FJWU-ის სისტემა, რომელიც WMT21-ში გაყოფილი ბიომედიციური გაყოფილი საქმე. ჩვენ მრავალური ნეიროლური მაქანის გაგრძელება სამი ენათებისთვის (მაგალითად, გერმანეთი, სპანუსი და ფრანუსი) ანგლისური ენათვის გაგრძელებული. ჩვენი NMT სისტემები ტრანფორმეტრის აქტიქტიქტურის ბაზაზე იყო, რომელიც დიომინში და გარეშე დიომინში პარალელი კოპორაზე განვითარებული ინფორმაციის მიღება (IR) და დიომინის აკაპო', 'it': "In questo articolo presentiamo il sistema della FJWU sottoposto al compito biomedico condiviso al WMT21. Abbiamo preparato sistemi di traduzione automatica neurale multilingue all'avanguardia per tre lingue (tedesco, spagnolo e francese) con l'inglese come lingua di destinazione. I nostri sistemi NMT basati sull'architettura Transformer, sono stati formati sulla combinazione di corpi paralleli in-domain e out-domain sviluppati utilizzando tecniche di recupero dell'informazione (IR) e adattamento del dominio.", 'lt': 'Šiame dokumente pristatome FJWU sistemą, pateiktą bendroms biomedicinos užduotims WMT21. Mes parengėme naujausias daugiakalbes nervinių mašinų vertimo sistemas trims kalboms (t. y. vokieči ų, ispanų ir prancūzų kalbomis) su anglų kalba kaip tiksline kalba. Mūsų NMT sistemos, grindžiamos Transformer architektūra, buvo išmokytos derinti lygiagrečias korporas domene ir ne domene, sukurtas naudojant informacijos gavimo (IR) ir domeno pritaikymo metodus.', 'kk': 'Бұл қағазда біз FJWU жүйесін WMT21-нің биомедикалық ортақтастырылған тапсырмаға таңдадық. Біз бірнеше тілдерді ағылшынша тіл ретінде бірнеше тілдерді аудару жүйелерін (яғни неміс, испан және французша) ағылшынша тілі болып тұрдық. Трансфер архитектурасына негізделген NMT жүйелеріміз доменге және сыртқы доменге параллель корпорацияның біріктірілген мәліметті қалау (IR) және доменге адаптациялау техникаларымен жасалған', 'mk': 'Во овој документ го претставуваме системот на ФЈВУ поднесен на биомедицинската заедничка задача на ВМТ21. Подготвивме најсовремени мултијазични системи за превод на невројални машини за три јазици (т.е. германски, шпански и француски) со англиски јазик како мета. Нашите НМТ системи базирани на трансформирана архитектура, беа обучени на комбинација на паралелни корпора во домен и надвор од домен развиени користејќи техники за привлекување информации (ИР) и адаптација на домен.', 'ms': 'Dalam kertas ini kami memperkenalkan sistem FJWU yang dihantar ke tugas berkongsi biomedis di WMT21. We prepared state-of-the-art multilingual neural machine translation systems for three languages (i.e. German, Spanish and French) with English as target language.  Our NMT systems based on Transformer architecture, were trained on combination of in-domain and out-domain parallel corpora developed using Information Retrieval (IR) and domain adaptation techniques.', 'mt': "F'dan id-dokument nippreżentaw is-sistema tal-FJWU sottomessa għall-kompitu kondiviż bijomediku fid-WMT21. Tħejjijna l-aktar sistemi moderni ta’ traduzzjoni tal-magni newrali multilingwi għal tliet lingwi (jiġifieri l-Ġermaniż, Spanjol u Franċi ż) bl-Ingliż bħala l-lingwa fil-mira. Is-sistemi NMT tagħna bbażati fuq l-arkitettura Transformer, ġew imħarrġa fuq kombinazzjoni ta’ korpora parallela fid-dominju u barra d-dominju żviluppati bl-użu ta’ tekniki ta’ ġbir ta’ informazzjoni (IR) u adattament tad-dominju.", 'ml': 'ഈ പത്രത്തില്\u200d നമ്മള്\u200d എഫ്ജെയുവിയുടെ സിസ്റ്റം WMT21-ല്\u200d ബൈയോമിക്കല്\u200d പങ്കെടുത്ത ജോലിയിലേക്ക് കൊടുത്ത മൂന്നു ഭാഷകള്\u200dക്ക് (ജര്\u200dമ്മന്\u200d ജര്\u200dമ്മന്\u200d, സ്പാനിഷ് ഫ്രെഞ്ച് എന്നിരിക്കുന്നു) മൂന്ന് ഭാഷകള്\u200dക്ക് വേണ്ടി ഞങ്ങള്\u200d സ്റ്റേറ്റ് ഓഫ്  നമ്മുടെ NMT സിസ്റ്റം ട്രാന്\u200dസ്ഫോര്\u200dഫര്\u200d ആര്\u200dക്കെക്റ്റര്\u200d അടിസ്ഥാനമായി പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു, ഡൊമെയിനും പുറത്തുള്ള പാര്\u200dമെല്\u200d കോര്\u200dപ', 'mn': 'Энэ цаасан дээр бид FJWU-ын системийг WMT21-д биологийн эмнэлгийн хуваалцааны ажил дээр тайлбарлаж байна. Бид олон хэлний мэдрэлийн мэдрэлийн машины түвшинд гурван хэл (яг Герман, Испан, Французтай) англи хэлний хувьд англи хэлний хувьд бэлдүүлсэн. Бидний NMT систем Трансформер архитектур дээр суурилсан. Холбооны холбоотой, гадна холбоотой параллел корпора нь мэдээлэл татах (IR) болон холбоотой адилгацийн технологийг ашиглан хөгжүүлсэн.', 'no': 'I denne papiret presenterer vi FJWU- systemet som er sendt til den biomediske delte oppgåva på WMT21. Vi har forberedt fleirspråksomsetjingssystemet for multispråk av kunsten for tre språk (t.d. tysk, spansk og fransk) med engelsk som målspråk. NMT-systemet våre basert på Transformer-arkitektur, ble trent på kombinasjon av i domene og ut-domene parallelle korpora utvikla med Information Retrieval (IR) og domeneadaptasjonssteknikk.', 'pl': 'W artykule przedstawiamy system FJWU poddany do wspólnego zadania biomedycznego WMT21. Przygotowaliśmy nowoczesne wielojęzyczne systemy tłumaczenia maszynowego neuronowego dla trzech języków (tj. niemieckiego, hiszpańskiego i francuskiego) z językiem docelowym angielskim. Nasze systemy NMT oparte na architekturze Transformera, zostały przeszkolone w kombinacji korpusów równoległych wewnątrz domeny i poza domeną opracowanych przy użyciu technik odzyskiwania informacji (IR) i adaptacji domeny.', 'ro': 'În această lucrare prezentăm sistemul FJWU supus sarcinii biomedicale comune de la WMT21. Am pregătit sisteme de traducere automată neurală multilingvă de ultimă generație pentru trei limbi (germană, spaniolă și franceză) cu limba engleză ca limbă țintă. Sistemele noastre NMT bazate pe arhitectura Transformer au fost instruite pe combinația corpurilor paralele în domeniu și în afara domeniului dezvoltate folosind tehnici de recuperare a informațiilor (IR) și adaptare la domeniu.', 'sr': 'U ovom papiru predstavljamo FJWU-ov sistem podignut biomedicinskom zajedničkom zadatku na WMT21. Pripremili smo multijezički sistem prevoda neuralnih strojeva za tri jezika (tj. njemački, španjolski i francuski) sa engleskim jezikom kao ciljni jezik. Naši NMT sistemi bazirani na arhitekturi transformera, bili su obučeni na kombinaciji paralelne korporacije u domenu i van domena razvijene uz pomoć tehnika prikupljanja informacija (IR) i adaptacije domena.', 'so': 'Warqadan waxaynu ku qornaa nidaamka FJWU ee loo dhiibay shaqada lagu qaybiyey dhakhtarka ee WMT21. Waxaannu u diyaarinay nidaamka tarjumaadda afka farshaxanka kala duduwan oo af saddex luqadood ah (tusaale ahaan Jarmal, Isbanish iyo Faraansiis) oo Ingiriis ku qoran luqad target ah. Nidaamka NMT ee ku saleysan dhismaha turjubaanka, waxaa lagu tababaray in la isku daro gudaha iyo shirkadaha dibadda ah oo la barto si siman ah oo lagu kordhiyey isticmaalka macluumaad Retrieval (IR) iyo qalabka bedelka ee gudaha.', 'sv': 'I denna uppsats presenterar vi FJWU:s system som ﾃｶverlﾃ､mnats till den biomedicinska gemensamma uppgiften pﾃ･ WMT21. Vi har fﾃｶrberett toppmoderna flersprﾃ･kiga neurala maskinﾃｶversﾃ､ttningssystem fﾃｶr tre sprﾃ･k (tyska, spanska och franska) med engelska som mﾃ･lsprﾃ･k. Vﾃ･ra NMT-system baserade pﾃ･ Transformer-arkitektur har trﾃ､nats i kombination av parallella korpora in-domain och out-domain utvecklade med hjﾃ､lp av informationshﾃ､mtningstekniker (IR) och domﾃ､nanpassningstekniker.', 'ta': 'இந்த காகிதத்தில் நாம் FJWU கணினியை WMT21-ல் உயிரியல் பங்கிட்ட பணிக்கு கொடுத்துள்ளோம். நாங்கள் மூன்று மொழிகளுக்கான மாநிலை - கலை மொழி புதிய பாதிர மொழிமாற்றல் அமைப்பு மாற்று உருவாக்கி அடிப்படையில் எங்கள் NMT அமைப்புகள் பயிற்சி செய்யப்பட்டுள்ளன - டோமைன் மற்றும் வெளியே இணைப்பு நிறுவனம் மூலம் தகவல் திரும்ப மீட்டு', 'si': 'මේ පත්තරේ අපි FJWU ගේ පද්ධතියට WMT21 වල ජීවිත වෛද්\u200dය විද්\u200dයාවක් සම්බන්ධ වැඩකට දාලා තියෙනවා. අපි ඉංග්\u200dරීසි භාෂාවෙන් ඉංග්\u200dරීසි භාෂාවෙන් ඉංග්\u200dරීසි වලින් ඉංග්\u200dරීසි වලින් තුනක් භාෂාවෙන් ඉන් අපේ NMT පද්ධතිය ප්\u200dරවර්තනය ස්ථාපනය සඳහා ප්\u200dරවර්තනය සහ ප්\u200dරවර්තනය සඳහා ප්\u200dරවර්තනය සඳහා ප්\u200dරවර්තනය සඳහා ප්\u200dරවර්තනය සඳහා ප්\u200d', 'ur': 'ہم اس کاغذ میں FJWU کے سیسٹم کو WMT21 کے بیولوڈیکسی مشترک کام پر پیش کیا گیا ہے۔ ہم نے انگلیسی زبان کے لئے تین زبانوں کے لئے (یعنی جرمن، اسپانیایی اور فرانسوی) انگلیسی کے ساتھ ملتی زبان کی ترجمہ نظام تیار کر رکھے ہیں۔ ہمارے NMT سیستموں پر ترنسفور معماری بنیاد ہے، ڈومین میں اور بیرون ڈومین پارالیل کورپورا کی تعلیم پر آموزش کی گئی تھی جو معلومات Retrieval (IR) اور ڈومین اضافہ تکنیک کے مطابق استعمال کر رہی تھی.', 'vi': 'Trong tờ giấy này chúng tôi giới thiệu hệ thống FJWU được giao nộp cho một nhiệm vụ chung y học tại WM21. Chúng tôi đã chuẩn bị các hệ thống dịch chuyển thiết bị thần kinh đa dạng của vũ trụ cho ba ngôn ngữ (Đức, Tây Ban Nha và Pháp) với tiếng Anh như ngôn ngữ đích. Hệ thống NMB của chúng tôi dựa trên kiến trúc biến hình, được huấn luyện trên sự kết hợp trong-miền và ngoài-miền song l. được phát triển bằng các kỹ thuật tìm kiếm thông tin (IR) và sửa chữa miền.', 'uz': "Bu hujjatda biz WMT21'da biomediya bilan birlashtirilgan vazifani joʻnatib, FJWU tizimini ko'rsamiz. Biz bir necha tillar uchun bir xil neyron tarjima tizimini uchta tillar (faqat tillari, ispancha va Fransuzcha) uchun ingliz tili tilida tayyorladik. Comment", 'hr': 'U ovom papiru predstavljamo FJWU-ov sustav podignut biomedicinskom zajedničkom zadatku na WMT21. Pripremili smo multijezički sustav prevoda neuralnih strojeva za tri jezika (tj. Njemački, španjolski i francuski) s engleskim jezikom kao ciljni jezik. Naši NMT sustavi na temelju arhitekture transformera, obučeni su na kombinaciji paralelne korporacije u domenu i van domena razvijene uz pomoć tehnika prikupljanja informacija (IR) i adaptacije domena.', 'nl': 'In dit artikel presenteren we het systeem van de FJWU dat is voorgelegd aan de biomedische gedeelde taak bij WMT21. We hebben geavanceerde meertalige neurale machinevertaalsystemen voorbereid voor drie talen (Duits, Spaans en Frans) met Engels als doeltaal. Onze NMT systemen gebaseerd op Transformer architectuur, zijn getraind op combinatie van in-domein en out-domein parallelle corpora ontwikkeld met behulp van Information Retrieval (IR) en domein adaptatie technieken.', 'bg': 'В настоящата статия представяме системата на ФБУ, подложена на биомедицинска споделена задача в МТ21. Подготвихме най-съвременни многоезични системи за невронен машинен превод за три езика (немски, испански и френски) с английски език като целеви език. Нашите НМТ системи, базирани на архитектурата на трансформаторите, бяха обучени на комбинация от паралелни корпуси в домейна и извън домейна, разработени с помощта на техники за извличане на информация (ИР) и адаптация на домейна.', 'id': 'Dalam kertas ini kami memperkenalkan sistem FJWU yang dihantar ke tugas biomedis yang dibagi di WMT21. Kami mempersiapkan sistem terjemahan mesin saraf multibahasa terbaik untuk tiga bahasa (i.e. Jerman, Spanyol dan Perancis) dengan bahasa Inggris sebagai bahasa sasaran. Sistem NMT kami berdasarkan arsitektur Transformer, dilatih dalam kombinasi dari korpora paralel dalam domain dan luar domain dikembangkan menggunakan teknik penerimaan informasi (IR) dan adaptasi domain.', 'da': "I denne artikel præsenterer vi FJWU's system, der er indsendt til den biomedicinske delte opgave på WMT21. Vi har udarbejdet avancerede flersprogede neurale maskinoversættelsessystemer til tre sprog (dvs. tysk, spansk og fransk) med engelsk som målsprog. Vores NMT-systemer baseret på Transformer arkitektur, blev uddannet i kombination af in-domæne og out-domæne parallelle korpora udviklet ved hjælp af Information Retrieval (IR) og domæne tilpasningsteknikker.", 'fa': 'در این کاغذ سیستم FJWU را به کار مشترک بیولوژیک در WMT21 پیشنهاد می\u200cکنیم. ما سیستم\u200cهای ترجمه\u200cی ماشین عصبی چندین زبان هنری را برای سه زبان (یعنی آلمان، اسپانیایی و فرانسوی) با انگلیسی به عنوان زبان هدف آماده کردیم. سیستم\u200cهای NMT ما بر اساس معماری تغییر\u200cدهنده آموزش داده شده\u200cاند، در ترکیب شرکت\u200cهای دامنه\u200cای و خارج از دامنه\u200cها با استفاده از تکنیک\u200cهای تغییر\u200cدهنده اطلاعات (IR) و دومین\u200cها توسعه داده شده\u200cاند.', 'sw': 'Katika karatasi hii tunaonyesha mfumo wa FJWU uliotolewa kwenye kazi ya kitabibu inayosambazwa na WMT21. Tuliandaa mfumo wa kutafsiri mashine ya asili ya lugha mbalimbali kwa lugha tatu (yaani Ujerumani, Kihispania na Kifaransa) kwa Kiingereza kama lugha ya lengo. Mfumo wetu wa NMT uliofanywa na ujenzi wa Transfer, walifundishwa kwa kuunganisha makampuni ya ndani na nje ya ndani yaliyotengenezwa kwa kutumia mbinu za kurejesha taarifa (IR) na kubadilisha ndani.', 'de': 'In diesem Beitrag stellen wir das System der FJWU vor, das der biomedizinischen gemeinsamen Aufgabe bei WMT21 unterzogen wurde. Wir haben modernste mehrsprachige neuronale maschinelle Übersetzungssysteme für drei Sprachen (Deutsch, Spanisch und Französisch) mit Englisch als Zielsprache vorbereitet. Unsere NMT-Systeme, die auf Transformer-Architektur basieren, wurden auf der Kombination von in-domain und out-domain parallelen Korpora trainiert, die mit Hilfe von Information Retrieval (IR) und Domänenanpassungstechniken entwickelt wurden.', 'af': 'In hierdie papier voorsien ons die FJWU se stelsel aan die biomediese gedeelde taak op WMT21 ondersteun. Ons het multitaalse neural e masjien vertalingsstelsels vir drie tale (dus Duitse, Spaanse en Frans) berei met Engels as doel taal. Ons NMT-stelsels gebaseer op Transformer-arkitektuur, is opgelei op kombinasie van in-domein en uit-domein parallele korpora ontwikkeld deur inligting ontvang (IR) en domein-adaptasie-teknike.', 'ko': '본고에서 우리는 FJWU가 WMT21 생물의학 공유 임무에 제출한 시스템을 소개했다.우리는 세 가지 언어(즉 독일어, 스페인어, 프랑스어)를 위해 가장 선진적인 다언어 신경기계 번역 시스템을 준비했는데 목표 언어는 영어이다.우리의 NMT 시스템은 Transformer 체계 구조를 바탕으로 정보 검색(IR)과 분야가 기술 개발에 적응하는 역내와 역외 병행 자료 라이브러리를 결합하여 교육을 진행한다.', 'am': 'በዚህ ካላት የFJWU ስርዓት በWMT21 ለተካፈሉት የባይቲክ ስራ እናቀርባታለን፡፡ የቋንቋ-ቋንቋ-ቋንቋ የብልሃዊ የናቡሬል መተርጓሚዎችን በሦስት ቋንቋዎች (የጀርመን፣ ስፓኒሽ እና ፈረንሳይኛ) እንግሊዘኛ እንደ ተቃውሞ ቋንቋ አዘጋጅተናል፡፡ የNMT ስርዓታችን በተመሳሳይ የመዝገብ መሠረት ላይ በመሠረት፣ የዶሜን እና የዶሜን ተቃውሞ ኮሬፖርት በመጠቀም መረጃ መመለስ (IR) እና ዶሜን አቀማመጥ ቴክክኖችንን በመጠቀም የተማሩ ናቸው፡፡', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք FJW-ի համակարգը, որը ներկայացվել է համագործակցած կենսաբժշկական խնդիրներին աշխարհում 21: Մենք պատրաստեցինք նորագույն բազմալեզու նյարդային մեքենայի թարգմանման համակարգերը երեք լեզուների համար (այսինքն՝ գերմաներեն, իսպաներեն և ֆրանսերեն) անգլերեն որպես նպատակային լեզու: Մեր NMT համակարգերը, որոնք հիմնված են Թանֆորմերի ճարտարապետության վրա, վարժեցվել են տիեզերքում և տիեզերքում գտնվող զուգահեռ կառուցվածքների համադրման վրա, որոնք զարգացվել են օգտագործելով տեղեկատվության վերադարձման (INR) և տի', 'tr': "Bu kagyzda FJWU sistemasyny WMT21'de bölünýän biýa-medenik zada görkezilýäris. Biz sanat sistemasyny üç diller üçin (meseläm, i ňlisçe, espanyol we fransuzça) Iňlisçe bilen maksady dil bilen taýýarlapdyk. NMT sistemlerimiz Transformer arhitektegisine dayanan, domenin ve dış domenin paralel korporasyndan gelişmiş informasyon Retrieval (IR) ve domenin adilama tekniklerini kullanarak geliştirildi.", 'az': "Bu kağızda FJWU sistemini WMT21'də biyoteksiya paylaşılan işlərə göndərdik. Biz sanatın çoxlu dilli nöral maşın çeviriş sistemlərini üç dil üçün (məsələn, Alman, İspanyol və Fransız dil kimi) İngilizə dili hazırlamışıq. NMT sistemlərimiz Transformer arhitektüsünə dayanan, domeinin və dış domenin paralel korporasının birləşdirilməsi üçün təhsil edilmişdir. Information Retrieval (IR) və domain adaptation teknikləri ilə təhsil edilmişdir.", 'sq': 'Në këtë letër prezantojmë sistemin e FJWU-s ë të paraqitur në detyrën e përbashkët biomedikale në WMT21. Ne përgatitëm sistemet e përkthimit të makinave nervore shumëgjuhëse më të moderne për tre gjuhë (i.e. gjermane, spanjolle dhe franceze) me anglisht si gjuhë objektive. Sistemet tona NMT bazuar në arkitekturën Transformer, u trajnuan në kombinimin e korprave paralele në domeni dhe jashtë domeni të zhvilluara duke përdorur teknikat e marrjes së informacionit (IR) dhe adaptimit në domeni.', 'bn': 'এই কাগজটিতে আমরা এফজেউইউ-এর বায়োমেডিকেল শেয়ার কর্মসূচির সামনে উপস্থিত করছি। আমরা তিনটি ভাষার জন্য রাষ্ট্র-অফ-শিল্পীয় নিউরেল মেশিন অনুবাদ সিস্টেম প্রস্তুত করেছি (যেমন জার্মান, স্প্যানিশ এবং ফরাসী) যার আমাদের এনএমটি সিস্টেম ট্রান্সফারেন আর্কিকেটের ভিত্তিক ভিত্তিতে প্রশিক্ষণ প্রদান করা হয়েছে ডোমেইন এবং বাইরে ডোমেইনের প্যারালেল কর্পোরা তথ্য পু', 'bs': 'U ovom papiru predstavljamo FJWU-ov sistem podignut biomedicinskom zajedničkom zadatku na WMT21. Pripremili smo multijezički sistem prevoda neuralnih strojeva za tri jezika (tj. njemački, španjolski i francuski) s engleskim jezikom kao ciljni jezik. Naši NMT sistemi bazirani na arhitekturi Transformera, bili su obučeni na kombinaciji paralelne korporacije u domenu i van domena razvijene uz pomoć tehnika prikupljanja informacija (IR) i adaptacije domena.', 'ca': "En aquest paper presentem el sistema de la FJWU submetit a la tasca biomèdica compartida a WMT21. Vam preparar sistemes de traducció neural multillengües més moderns per tres llengües (alemanès, espanyol i francès) amb l'anglès com a llenguatge d'objectiu. Els nostres sistemes NMT basats en arquitectura Transformer, van ser entrenats en combinació de corpores paralèls en domini i fora de domini desenvolupats utilitzant tècniques de recuperació d'informació (IR) i d'adaptació de domini.", 'et': 'Käesolevas töös tutvustame FJWU süsteemi, mis on esitatud biomeditsiinilisele jagatud ülesandele WMT21. Valmistasime välja tipptasemel mitmekeelsed neuromasintõlkesüsteemid kolmele keelele (st saksa, hispaania ja prantsuse) ning sihtkeeleks oli inglise keel. Meie transformaatori arhitektuuril põhinevad NMT-süsteemid on koolitatud domeenisiseste ja väljaspool domeeni paralleelsete korpuste kombineerimisel, mis on välja töötatud info hankimise (IR) ja domeeni kohandamise tehnikate abil.', 'cs': 'V tomto článku představujeme systém FJWU předložený k biomedicínskému sdílenému úkolu na WMT21. Připravili jsme nejmodernější vícejazyčné neuronové strojové překlady pro tři jazyky (tj. němčinu, španělštinu a francouzštinu) s angličtinou jako cílovým jazykem. Naše NMT systémy založené na transformátorové architektuře byly vycvičeny na kombinaci paralelních korpusů v doméně a mimo doménu vyvinutých pomocí technologie získávání informací (IR) a adaptace domény.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa esittelemme FJWU:n jﾃ､rjestelmﾃ､ﾃ､, joka on alistettu biolﾃ､ﾃ､ketieteen yhteiseen tehtﾃ､vﾃ､ﾃ､n WMT21. Valmistimme uusimmat monikieliset neurokonekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmﾃ､t kolmelle kielelle (saksa, espanja ja ranska) englannin kohdekielenﾃ､. Transformer-arkkitehtuuriin perustuvat NMT-jﾃ､rjestelmﾃ､mme on koulutettu yhdistﾃ､mﾃ､ﾃ､n domain-ja out-domain rinnakkaisia korpusia, jotka on kehitetty kﾃ､yttﾃ､en tiedonkeruuta (IR) ja domain-adaptointitekniikoita.', 'sk': 'V prispevku predstavljamo sistem FJWU, ki je bil predmet skupne biomedicinske naloge na WMT21. Pripravili smo najsodobnejše večjezične sisteme nevronskega strojnega prevajanja za tri jezike (nemščino, španščino in francoščino) z angleščino kot ciljnim jezikom. Naši NMT sistemi, ki temeljijo na transformatorski arhitekturi, so bili usposobljeni na kombinaciji domenskih in-domenskih vzporednih korpusov, razvitih z uporabo tehnik pridobivanja informacij (IR) in domenskih prilagoditev.', 'ha': "Ga wannan takardan da Muke halatar da tsarin FJWU da aka saka zuwa aikin da aka yi raba shi da bajiran da aka raba shi a WMT21. Mun yi tattali da halin-of-the-art-multi-lingui, na'urar fassarar manyan aikin neural na'ura wa harshen uku (misali, jerin, spanish da faransa) da Ingiriya kamar harshe na ƙayyade. An sanar da masu tsarin NMT a kan muhalli na tsarin Transformer, an ƙididdige shi da koma cikin-Domen da shirin kamera masu fitarwa da shirin ayukan da aka develope a bayan shirin Shiryarwa (IR) da masu adatarwa na guda.", 'jv': 'Nang paper iki kita nggawe sistem FjWU kang ngerasai kanggo ngilanggar biasane kanggo nyebuti nggawe barang dumaten ning wêrbêr. Awak dhéwé wis nggawe stad-karo akeh bantên-karo sistem Neral karo telu langa (ta.e.g. German, Spanish lan Perancis) nganggo Perancis kuwi basa tarjamahan. We NMT', 'bo': 'ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་FJWU་གི་མ་ལག་གིས་WMT21 ལ་སྨན་གཞུང་གི་ཆ་འཕྲིན་གྱི་ལས་འཆར་བཀོད་ཡོད། ང་ཚོས་སྐད་ཡིག་གསུམ་ལ་རང་ཉིད་ཀྱི་སྐད་ཡིག་དང་འཛམ་གླིང་ཡིག་ཆའི་ནང་དུ་རྒྱལ་ཁབ་ཀྱི་སྣང་ཚུལ་དང་འཛམ་གླིང་ཡིག Our NMT systems based on Transformer architecture, were trained on combination of in-domain and out-domain parallel corpora developed using Information Retrieval (IR) and domain adaptation techniques.', 'he': "In this paper we present the FJWU's system submitted to the biomedical shared task at WMT21.  הכינו מערכות התרגום של מכונות עצביות רבות שפות חדשות לשלושה שפות (כלומר גרמנית, ספרדית וצרפתית) עם אנגלית כשפה מטרה. Our NMT systems based on Transformer architecture, were trained on combination of in-domain and out-domain parallel corpora developed using Information Retrieval (IR) and domain adaptation techniques."}
{'en': 'Huawei AARC’s Submissions to the WMT21 Biomedical Translation Task : Domain Adaption from a Practical Perspective', 'ar': 'تقديمات Huawei AARC إلى مهمة الترجمة الطبية الحيوية WMT21: تكييف المجال من منظور عملي', 'es': 'Presentaciones de la AARC de Huawei a la tarea de traducción biomédica del WMT21: adaptación del dominio desde una perspectiva práctica', 'fr': "Soumissions de l'AARC Huawei à la tâche de traduction biomédicale WMT21\xa0: Adaptation de domaine d'un point de vue pratique", 'pt': 'Submissões da Huawei AARC para a Tarefa de Tradução Biomédica WMT21: Adaptação de Domínio de uma Perspectiva Prática', 'ja': 'Huawei AARCによるWMT 21生物医学翻訳タスクへの提出：実用的な視点からのドメインの適応', 'ru': 'Представления Huawei AARC к Задаче Биомедицинского Перевода WMT21: Адаптация Домена от Практически Перспективы', 'hi': 'WMT21 बायोमेडिकल अनुवाद कार्य के लिए Huawei AARC के सबमिशन: एक व्यावहारिक परिप्रेक्ष्य से डोमेन अनुकूलन', 'zh': '华为AARCWMT21生物医学转化提交之材:从受持角度看领地应之', 'ga': 'Aighneachtaí Huawei AARC chuig Tasc Aistriúcháin Bithleighis WMT21: Oiriúnú Fearainn ó Léargas Praiticiúil', 'ka': 'WMT21 ბიომედიციური განმყარება: პრაქტიკური პერვისტებიდან დომენის ადაპტიკაცია', 'it': 'I contributi di Huawei AARC al compito di traduzione biomedica WMT21: adattamento del dominio da una prospettiva pratica', 'kk': 'Huawei AARC WMT21 биомедикалық аудару тапсырмасына жіберу: Практикалық перспективадан домен адаптациясы', 'hu': 'A Huawei AARC benyújtásai a WMT21 bioorvosi fordítási feladathoz: Domain adaptáció gyakorlati szempontból', 'el': 'Υποβολές της στο έργο βιοϊατρικής μετάφρασης: Προσαρμογή τομέα από πρακτική σκοπιά', 'ms': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaptation from a Practical Perspective", 'lt': 'Huawei AARC pristatymai WMT21 Biomedicinos vertimo uždaviniui: Domaino pritaikymas praktinėje perspektyvoje', 'mn': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'mt': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'pl': 'Zgłoszenia Huawei AARC do zadania tłumaczenia biomedycznego WMT21: Adaptacja domeny z praktycznej perspektywy', 'ro': 'Depunerile Huawei AARC la sarcina de traducere biomedicală WMT21: Adaptarea domeniului dintr-o perspectivă practică', 'ml': 'WMT21 ബിയോമിക്കല്\u200d പരിഭാഷണ കാര്യങ്ങളിലേക്ക് ഹുവായി ആര്\u200dസിയുടെ സബ്മിഷന്\u200d', 'no': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'sr': 'Podaci Huawei AARC-a na WMT21 biomedicinski prevod zadatak: adaptacija domena iz praktične perspektive', 'si': "හුවේයි AARC's Sub-Misions to the WMT21 Biodoctor translation Job: Domain Adjust from a Practical Planet", 'so': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'sv': 'Huawei AARC:s bidrag till WMT21 biomedicinsk översättning Uppgift: Domänanpassning ur ett praktiskt perspektiv', 'ta': "WMT21 Biomedical Translation Task க்கு Huawei AARC' s Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical perspective", 'ur': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'mk': 'Предлозите на Хуауеи ААРЦ на ВМТ21 Биомедицинска преведувачка задача: Адапција на доменот од практична перспектива', 'uz': 'Name', 'vi': 'Tin đệ trình của Hoài An Xã hội phụ thuộc vào Nhiệm vụ dịch hạch Khoa học Y học WM:', 'nl': "Huawei AARC's inzendingen aan de WMT21 Biomedische vertaaltaak: Domeinaanpassing vanuit een praktisch perspectief", 'da': "Huawei AARC's indlæg til WMT21 Biomedicinsk Oversættelsesopgave: Domænetilpasning fra et praktisk perspektiv", 'hr': 'Podaci Huawei AARC-a na WMT21 Biomedicinski prevod zadatak: Adaptacija domena iz praktičke perspektive', 'bg': 'Предложенията на ААРК към задачата за биомедицински превод: адаптиране на домейна от практическа гледна точка', 'de': 'Beiträge von Huawei AARC zur biomedizinischen Übersetzungsaufgabe WMT21: Domänenanpassung aus praktischer Perspektive', 'ko': '화웨이 AARC가 WMT21 생물의학 번역 임무에 제출한 문서: 실천 차원에서 영역 조정', 'id': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'fa': 'وظیفه هائوی AARC برای ترجمه زیست پزشکی WMT21', 'sw': 'Vijumbe vya AARC vya Huawei kwenye kazi ya Tafsiri ya Biomedica ya WMT21: Utafiti wa Domain kutoka mtazamo wa Praktikali', 'tr': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'af': "Huawei AARC se Submissions na die WMT21 Biomediese Vertaling Taak: Domein Aanpassing van 'n Praktiese Perspektief", 'sq': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'am': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical perspective", 'hy': 'Հուաուեյի ԱԱՌՔ-ի ներկայացումները ՀՄԹ21 Բիոբիոբժշկական թարգմանման առաջադրանքին՝ Պրակտիկական տեսանկյունից բիոբժշկական հարմարեցման', 'az': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaptation from a Practical Perspective", 'bn': 'WMT21 বায়োমিকাল অনুবাদ করার কাজে হুয়াই অ্যার্সির সাবমিশন: প্রাক্টিকেল দৃষ্টিভঙ্গি থেকে ডোমেইন আপেশন', 'bs': 'Podaci Huawei AARC-a na WMT21 Biomedicinski prevod zadatak: Adaptacija domena iz praktične perspektive', 'cs': 'Příspěvky Huawei AARC k biomedicínskému překladu WMT21: Adaptace domény z praktického hlediska', 'et': 'Huawei AARC esitab WMT21 biomeditsiinilise tõlke ülesande: domeeni kohandamine praktilisest vaatenurgast', 'fi': 'Huawei AARC:n julkaisut WMT21 Biomedical Translation Task: verkkotunnuksen mukauttaminen käytännön näkökulmasta', 'ca': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaptation from a Practical Perspective", 'jv': "huawei AARC's Submisons to the WWT 22", 'sk': 'Huawei AARC predloži nalogo biomedicinskega prevajanja WMT21: prilagoditev domene s praktičnega vidika', 'he': "הואאווי AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaptation from a Practical Perspective", 'bo': "Huawei AARC's Submissions to the WMT21 Biomedical Translation Task: Domain Adaption from a Practical Perspective", 'ha': 'KCharselect unicode block name'}
{'en': 'This paper describes Huawei Artificial Intelligence Application Research Center’s neural machine translation systems and submissions to the WMT21 biomedical translation shared task. Four of the submissions achieve state-of-the-art BLEU scores based on the official-released automatic evaluation results (EN-FR, EN-IT and ZH-EN). We perform experiments to unveil the practical insights of the involved domain adaptation techniques, including finetuning order, terminology dictionaries, and ensemble decoding. Issues associated with ', 'pt': 'Este artigo descreve os sistemas de tradução automática neural do Huawei Artificial Intelligence Application Research Center e os envios para a tarefa compartilhada de tradução biomédica WMT21. Quatro das submissões alcançam pontuações BLEU de última geração com base nos resultados de avaliação automática divulgados oficialmente (EN-FR, EN-IT e ZH-EN). Realizamos experimentos para desvendar os insights práticos das técnicas de adaptação de domínio envolvidas, incluindo ordem de ajuste fino, dicionários de terminologia e decodificação de conjunto. Questões associadas com overfitting e under-translation também são discutidas.', 'fr': "Cet article décrit les systèmes de traduction automatique neuronale du centre de recherche sur les applications d'intelligence artificielle de Huawei et les soumissions pour la tâche partagée de traduction biomédicale WMT21. Quatre des soumissions obtiennent des scores UEBL de pointe sur la base des résultats d'évaluation automatique publiés officiellement (EN-FR, EN-IT et ZH-EN). Nous réalisons des expériences pour révéler les connaissances pratiques des techniques d'adaptation de domaines impliquées, y compris l'ordre de réglage fin, les dictionnaires terminologiques et le décodage d'ensemble. Les problèmes associés au suréquipement et à la sous-traduction sont également discutés.", 'ar': 'تصف هذه الورقة أنظمة الترجمة الآلية العصبية الخاصة بمركز أبحاث الذكاء الاصطناعي من Huawei والتقديمات إلى المهمة المشتركة للترجمة الطبية الحيوية WMT21. أربعة من الطلبات المقدمة تحقق أعلى درجات BLEU بناءً على نتائج التقييم التلقائي الصادرة رسميًا (EN-FR و EN-IT و ZH-EN). نجري تجارب لكشف النقاب عن الرؤى العملية لتقنيات تكييف المجال المعنية ، بما في ذلك الترتيب النهائي ، وقواميس المصطلحات ، وفك تشفير المجموعات. كما تمت مناقشة القضايا المرتبطة بالتجهيز الزائد ونقص الترجمة.', 'es': 'Este documento describe los sistemas de traducción automática neuronal del Centro de Investigación de Aplicaciones de Inteligencia Artificial de Huawei y los envíos a la tarea compartida de traducción biomédica WMT21. Cuatro de las presentaciones obtienen puntuaciones BLEU de última generación basadas en los resultados de la evaluación automática publicados oficialmente (EN-FR, EN-IT y ZH-EN). Realizamos experimentos para revelar los conocimientos prácticos de las técnicas de adaptación de dominio involucradas, incluidos el orden de ajuste, los diccionarios terminológicos y la decodificación de conjuntos. También se discuten los problemas asociados con el sobreajuste y la infraducción.', 'ja': '本稿では、Huawei Artificial Intelligence Application Research Centerのニューラル機械翻訳システムとWMT 21バイオメディカル翻訳共有タスクへの提出について説明する。公式に発表された自動評価結果（ EN - FR、EN - IT、ZH - EN ）に基づく最先端のBLEUスコアを達成したのは4件です。私たちは、微調整順序、用語辞書、およびアンサンブルデコードを含む、関連するドメイン適応技術の実用的な洞察を公開するための実験を行います。オーバーフィッティングと翻訳不足に関連する問題についても考察した。', 'zh': '本文引华为人工智能宜究心神经机器翻译统,并提交WMT21生物医学译共之。 其四分者,据官自料(EN-FR,EN-ITZH-EN)得先进BLEU分。 臣等实验之,以表所及领域适术之实见,微调次第,术语词典集成解码。 又议过度拟合译者不足问。', 'hi': 'यह पेपर Huawei Artificial Intelligence Application Research Center के neural machine translation systems और WMT21 Biomedical Translation shared task के लिए प्रस्तुतियों का वर्णन करता है। प्रस्तुतियों में से चार आधिकारिक रूप से जारी किए गए स्वचालित मूल्यांकन परिणामों (EN-FR, EN-IT और ZH-EN) के आधार पर अत्याधुनिक BLEU स्कोर प्राप्त करते हैं। हम शामिल डोमेन अनुकूलन तकनीकों की व्यावहारिक अंतर्दृष्टि का अनावरण करने के लिए प्रयोग करते हैं, जिसमें फाइनट्यूनिंग ऑर्डर, शब्दावली शब्दकोश, और पहनावा डिकोडिंग शामिल हैं। ओवरफिटिंग और अंडर-ट्रांसलेशन से जुड़े मुद्दों पर भी चर्चा की जाती है।', 'ru': 'Эта бумага описывает системы нейронного машинного перевода Центра прикладных исследований искусственного интеллекта Huawei и представления к совместной задаче биомедицинского перевода WMT21. Четыре заявки позволяют получить самые современные оценки BLEU на основе официально опубликованных результатов автоматической оценки (EN-FR, EN-IT и ZH-EN). Мы проводим эксперименты, чтобы раскрыть практические идеи задействованных методов адаптации домена, включая порядок тонкой настройки, терминологические словари и ансамблевое декодирование. Обсуждаются также вопросы, связанные с переоснащением и недопереводом.', 'ga': 'Déanann an páipéar seo cur síos ar chórais néar-aistrithe néarchóras Lárionad Taighde Feidhmchláir Intleachta Saorga Huawei agus ar aighneachtaí chuig tasc roinnte aistriúcháin bithleighis WMT21. Baineann ceithre cinn de na haighneachtaí amach scóir BLEU úrscothach atá bunaithe ar thorthaí na meastóireachta uathoibríocha a eisíodh go hoifigiúil (EN-FR, EN-IT agus ZH-EN). Déanaimid turgnaimh chun léargais phraiticiúla ar na teicníochtaí oiriúnaithe fearainn atá i gceist a nochtadh, lena n-áirítear ord mionchoigeartaithe, foclóirí téarmaíochta, agus díchódú ensemble. Pléitear freisin saincheisteanna a bhaineann le rófheisteas agus tearc-aistriúchán.', 'hu': 'Ez a tanulmány bemutatja a Huawei Artificial Intelligence Application Research Center neurális gépi fordítási rendszereit és a WMT21 orvosbiológiai fordítási megosztott feladathoz való beadványokat. A beadványok közül négy a hivatalosan közzétett automatikus értékelési eredmények alapján (EN-FR, EN-IT és ZH-EN) a legkorszerűbb BLEU pontszámot érte el. Kísérleteket végzünk, hogy felfedjük az érintett domain adaptációs technikák gyakorlati ismereteit, beleértve a finomhangolási sorrendet, terminológiai szótárakat és az együttes dekódolását. A túlteljesítéssel és az alulfordítással kapcsolatos kérdéseket is megvitatjuk.', 'ka': 'ამ დოკუმენტის აღწერა ჰუვავი ატრუქტიური ინტელექტიური ინტელექტიური ინტელექტიური ინტელექტიური ინტელექტიური ინტელექტიური ინტელექტიური ინტელექტიურ მეოთხე წარმოდგენების შესაძლებლობად სახელსაწარმოდგენება BLEU წარმოდგენებები, რომლებიც უფრო მეორტიურად გამოგენებული ავტომატური გაუმუშავება (EN-FR, EN-IT და ZH-EN). ჩვენ ექსპერიმენტები გავაკეთებთ, რომ გავაკეთებთ პრექტიკური მონაცემებების მონაცემები დემომინის აკაპტიფიკაციის ტექნოგიების შესახებ, შესახებ finetuning order, ტერმინოლოგიის შესაბამისი შესაბამისი და შესაბამისი შესაბამისი პრობლემები კითხვა.', 'it': "Questo articolo descrive i sistemi neurali di traduzione automatica dell'Intelligenza Artificiale di Huawei Application Research Center e le presentazioni al compito condiviso di traduzione biomedica WMT21. Quattro delle candidature ottengono punteggi BLEU all'avanguardia sulla base dei risultati di valutazione automatica pubblicati ufficialmente (EN-FR, EN-IT e ZH-EN). Eseguiamo esperimenti per svelare le conoscenze pratiche delle tecniche di adattamento del dominio coinvolte, tra cui l'ordine di fine tuning, dizionari terminologici e decodifica ensemble. Vengono inoltre discusse le questioni legate al sovradimensionamento e alla sottotraduzione.", 'kk': 'Бұл қағаз Хуаеви мақсатты интеллективтік қолданбаларды зерттеу орталығының невралдық машинаны аудару жүйелерін және WMT21 биомедикалық аудармаларды ортақтастыру тапсырмасына жіберіп бер Төрт тапсырмалардың күй- жайындағы BLEU нәтижелерін автоматты түрде шығарылған оқу нәтижелеріне негізделген (EN-FR, EN-IT және ZH-EN). Біз домен адаптациялау технологияларының практикалық түсініктерін таңдау үшін тәжірибелерді орындаймыз. Бұл домен адаптациялау технологияларының, финеттеу реті, терминологиялық сөзд Қайталанған және аудармалардың алдындағы мәселелер де талқылады.', 'lt': 'Šiame dokumente aprašomos Huawei dirbtinio žvalgybos mokslinių tyrimų centro neurologinių mašinų vertimo sistemos ir WMT21 biomedicinės vertimo bendrai užduotis. Four of the submissions achieve state-of-the-art BLEU scores based on the official-released automatic evaluation results (EN-FR, EN-IT and ZH-EN).  Eksperimentuojame, kad atskleistume praktinius su tuo susijusių sričių pritaikymo metodų supratimus, įskaitant tikslinimo tvarką, terminologinius žodynus ir ensemblių dekodiavimą. Taip pat aptariami su per dideliu įrengimu ir per mažu vertimu susiję klausimai.', 'mk': 'Овој весник ги опишува системите за превод на невропските машини на Центарот за истражување на уметничката интелигенција на Хуауеј и поднесувањата на заедничката задача за биомедициски превод на WMT21. Четири од пренесувањата постигнуваат најсовремени оценки БЛЕУ врз основа на резултатите на автоматската оценка објавена од официјалните лица (EN-FR, EN-IT и ZH-EN). We perform experiments to unveil the practical insights of the involved domain adaptation techniques, including finetuning order, terminology dictionaries, and ensemble decoding.  Исто така, се дискутираат и прашањата поврзани со прекумерното објектирање и недопреведување.', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi u s-sottomissjonijiet tat-traduzzjoni tal-magni newrali taċ-Ċentru tar-Riċerka dwar l-Applikazzjoni tal-Intelliġenza Artifikali Huawei għall-kompitu komuni tat-traduzzjoni bijomedika WMT21. Erba’ mis-sottomissjonijiet jiksbu punteġġi BLEU l-aktar avvanzati abbażi tar-riżultati tal-evalwazzjoni awtomatika rilaxxati uffiċjalment (EN-FR, EN-IT u ZH-EN). Għandna nagħmlu esperimenti biex niżvelaw l-għarfien prattiku tat-tekniki ta’ adattament tad-dominju involuti, inklużi l-ordni ta’ rfinar, id-dikjararji tat-terminoloġija, u d-dekodifikazzjoni tal-ensemble. Kwistjonijiet assoċjati ma’ tagħmir żejjed u traduzzjoni baxxa huma diskussi wkoll.', 'mn': 'Энэ цаас Хуаеви уран бүтээлч Интернэтийн судалгааны Центр нь мэдрэлийн механикийн хөрөнгө оруулалтын систем болон WMT21 биологийн эрүүл мэндийн хөрөнгө оруулалтын ажлыг тайлбарладаг. Дөрвөн давталтын дөрвөн нь автоматически гаргасан оюутнуудын үр дүн (EN-FR, EN-IT, ZH-EN) дээр автоматически гаргасан оюутнуудын үзүүлэлт гаргадаг BLEU оноо гаргадаг. Бид холбоотой адилтгалын технологиудын практикийн ойлголтыг илэрхийлэх туршилтыг хийдэг. Мөн цэвэрлэлтийн дарааллаар, терминологийн сөрөг үг болон шийдвэрлэлтийг бүрдүүлэх боломжтой. Үнэхээр тохиромжтой болон бага орчуулалтай холбоотой асуудлууд мөн ярилцдаг.', 'el': 'Αυτή η εργασία περιγράφει τα νευρωνικά συστήματα μηχανικής μετάφρασης του Κέντρου Ερευνών Εφαρμογών Τεχνητής Νοημοσύνης και τις υποβολές στο κοινό έργο βιοϊατρικής μετάφρασης. Τέσσερις από τις αιτήσεις επιτυγχάνουν υπερσύγχρονες βαθμολογίες BLEU με βάση τα επίσημα δημοσιευμένα αποτελέσματα αυτόματης αξιολόγησης (EN-FR, EN-IT και ZH-EN). Πραγματοποιούμε πειράματα για να αποκαλύψουμε τις πρακτικές γνώσεις των εμπλεκόμενων τεχνικών προσαρμογής τομέα, συμπεριλαμβανομένης της σειράς συντονισμού, των λεξικών ορολογίας και της αποκωδικοποίησης συνόλων. Εξετάζονται επίσης θέματα που σχετίζονται με την υπερπροσαρμογή και την υπομετάφραση.', 'ms': 'Kertas ini menggambarkan sistem penyerjemahan mesin saraf Pusat Penelitian Aplikasi Artificial Huawei dan penghantaran ke tugas terkongsi terjemahan biomedikal WMT21. Empat penghantaran mencapai skor BLEU terbaik berdasarkan keputusan penilaian automatik yang dibebaskan rasmi (EN-FR, EN-IT dan ZH-EN). Kami melakukan eksperimen untuk mengungkapkan pandangan praktik teknik penyesuaian domain yang terlibat, termasuk perintah penyesuaian, kamus terminologi, dan dekod ensemble. Masalah yang berkaitan dengan overfitting dan under translation juga dibahas.', 'ml': 'ഈ പത്രത്തില്\u200d ഹുവായി ആര്\u200dട്ടിഫിക്കല്\u200d ഇന്\u200dട്രിലിജെന്\u200dസ് പ്രയോഗത്തിന്\u200dറെ പരിശോധന സെന്റിന്\u200dറെ ന്യൂറല്\u200d മെഷീന്\u200d പരിശോധന സിസ്റ്റം വിവരിക്കുന Four of the submissions achieve state-of-the-art BLEU scores based on the official-released automatic evaluation results (EN-FR, EN-IT and ZH-EN).  നമ്മള്\u200d പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു, ഉള്\u200dപ്പെട്ട ഡൊമെയിന്\u200d അഡാപ്റ്റേഷന്\u200d സാങ്കേതികവിദ്യയുടെ പ്രാകൃതിക കണ്ണുകള്\u200d തുറക് അഴിവാക്കുന്നതിനും പരിഭാഷത്തിനും കീഴിലും ബന്ധപ്പെട്ട വിഷയങ്ങളും സംസാരിക്കുന്നു.', 'sr': 'Ovaj papir opisuje sisteme neuromašinskih prevođenja centra istraživanja inteligencije Huawei i podatke zajedničkom zadatku biomedicinskog prevođenja WMT21. Četiri od podataka postižu rezultate države umjetnosti BLEU na temelju službenih rezultata automatske procjene (EN-FR, EN-IT i ZH-EN). Izvodimo eksperimente da otkrijemo praktične uvide uključenih tehnika adaptacije domena, uključujući finetuning naređenja, terminološke diktorije i ensemble dekodiranja. Takođe se raspravljaju i problemi povezani sa preuređenjem i pod prevodom.', 'no': "Denne papiret beskriver Huawei Artificial Intelligence Research Center's neural machine translation system and submission to the WMT21 biomedical translation shared task. Før av tillegga er oppnådd BLEU-poeng i tilstand til kunsten basert på dei offisielle utgjevne automatiske evalueringsresultatene (EN-FR, EN-IT og ZH-EN). Vi utfører eksperimenter for å deklare praktiske innsyningar av dei tilhøyrande domenetilpassingsteknikka, inkludert finetuning rekkefølgje, terminologiske ordbokar og ensemble dekoding. Utgåver som er tilknytta med overpassa og underoversettelse er også diskutert.", 'si': 'මේ පැත්තේ හුවේයි විද්\u200dයාත්මක විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද ස්වයංග්\u200dරහයෙන් හතරයි ස්වයංග්\u200dරහයෙන් ස්වයංග්\u200dරහයෙන් ස්වයංග්\u200dරහයෙන් පිළිබඳින්නේ, ස්වයංග්\u200dරහයෙන් පිළිබඳි අපි පරීක්ෂණය කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්න පුළුවන් ප්\u200dරයෝජනය විද්\u200dයාප්\u200dතිකාර විද්\u200dයාප්\u200dතිකාරයේ ප්\u200dරයෝජනය අවස් ප්\u200dරශ්නයක් සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන්ධ විදිහට සහ අ', 'ro': 'Această lucrare descrie sistemele de traducere automată neurală ale Centrului de Cercetare a Aplicațiilor de Inteligență Artificială Huawei și trimiterile la sarcina comună de traducere biomedicală WMT21. Patru dintre depuneri obțin scoruri BLEU de ultimă generație pe baza rezultatelor evaluării automate publicate oficial (EN-FR, EN-IT și ZH-EN). Efectuăm experimente pentru a dezvălui perspectivele practice ale tehnicilor de adaptare a domeniului implicat, inclusiv ordinea fină, dicționarele terminologice și decodarea ansamblului. Sunt, de asemenea, discutate probleme asociate cu suprasolicitarea și subtraducerea.', 'ta': "This paper describes Huawei Artificial Intelligence Application Research Center's neural machine translation systems and submissions to the WMT21 biomedical translation shared task.  அனுமதிகளில் நான்கு பிலியு புள்ளி மதிப்புகளை அடிப்படையில் நிலையில் பெறுகிறது (EN- FR, EN- IT மற்றும் ZH-EN). நாங்கள் சோதனைகளை செய்கிறோம் பொருத்தப்பட்ட ட டொமைன் ஒதுக்கும் தொழில்நுட்பத்தின் செயல்பாடுகளை வெளியேற்றுவதற்கு, பின்னூட்டு வரி மாற்றுதல் மற்றும் மொழிபெயர்ப்பு கீழ் தொடர்புடைய விஷயங்களும் விவாதம் செய்யப்படுகிறது.", 'pl': 'Niniejszy artykuł opisuje neuronowe systemy tłumaczenia maszynowego Huawei oraz zgłoszenia do wspólnego zadania tłumaczenia biomedycznego WMT21. Cztery zgłoszenia uzyskują najnowocześniejsze wyniki oceny BLEU oparte na oficjalnie opublikowanych wynikach automatycznej oceny (EN-FR, EN-IT i ZH-EN). Przeprowadzamy eksperymenty w celu ujawnienia praktycznych spostrzeżeń dotyczących zaangażowanych technik adaptacji domen, w tym kolejności dostrajania, słowników terminologicznych i dekodowania zespołów. Omówione są również kwestie związane z nadmiernym dopasowaniem i niedostatecznym tłumaczeniem.', 'sv': 'Denna uppsats beskriver Huawei Artificial Intelligence Application Research Centers neurala maskinﾃｶversﾃ､ttningssystem och inlﾃ､mningar till WMT21 biomedicinsk ﾃｶversﾃ､ttning delade uppgift. Fyra av inlﾃ､ggen uppnﾃ･r toppmoderna BLEU-poﾃ､ng baserat pﾃ･ officiellt publicerade automatiska utvﾃ､rderingsresultat (EN-FR, EN-IT och ZH-EN). Vi utfﾃｶr experiment fﾃｶr att avslﾃｶja de praktiska insikterna i de involverade domﾃ､nanpassningsteknikerna, inklusive finjusteringsordning, terminologiordbﾃｶcker och ensembleavkodning. Frﾃ･gor som ﾃ､r fﾃｶrknippade med ﾃｶveranpassning och underﾃｶversﾃ､ttning diskuteras ocksﾃ･.', 'ur': "This paper describes Huawei Artificial Intelligence Application Research Center's neural machine translation systems and submissions to the WMT21 biomedical translation shared task. ان چار فرستادیوں میں سے آهنگ BLEU اسکورٹوں کو رسمی سے آزاد ہونے کے نتیجے پر (EN-FR, EN-IT اور ZH-EN) موجود ہوتے ہیں۔ ہم آزمائش کریں گے کہ درجے کے مطابق دفاع تکنیک کے قابل بصیرت کو ظاہر کریں، یہاں تک کہ فین ٹینٹونگ آرام، ٹینمولوژی لکھنے والی باتیں اور ڈیکوڈ ڈیکوڈ کے مطابق شامل ہو جائیں. بہت مناسب اور کم ترجمہ کے ساتھ مشکلات بھی جھگڑے جاتے ہیں.", 'so': 'Kanu waa qoraalka ku qoran xarunta baaritaanka ee xarunta koourada machine turjumaadda iyo hoosaysiinta qoraalka baabuurta ee WMT21. Afar ka mid ah foomka waxay gaadhaan xaalada-sanada BLEU score ku saleysan resultiyada qiimeynta rasmiga ah ee iskuulka ah (EN-FR, EN-IT iyo ZH-EN). We perform experiments to unveil the practical insights of the involved domain adaptation techniques, including finetuning order, terminology dictionaries, and ensemble decoding.  Sidoo kale waxaa loola hadlaa arrimaha la xiriira safarka iyo turjumidda hoostooda.', 'uz': "Bu qogʻoz Huawei Artific Application Research Center'ning neyural maskin tarjima tizimlarini va WMT21 biomedical tarjima qilingan vazifani qaytadan tarjima qiladigan vazifani aytadi. Joʻnatuvchilar to'rtta ta'minlovchi avtomatik qiymati natijasi (EN-FR, EN-IT ва ZH-EN) asosida bajariladigan BLEU qiymatning holatini bajaradi. We perform experiments to unveil the practical insights of the involved domain adaptation techniques, including finetuning order, terminology dictionaries, and ensemble decoding.  @ info: whatsthis", 'vi': 'Tờ giấy này mô tả hệ thống dịch chuyển máy thần kinh của trung tâm trí trí thức Nhân tạo Hoa quả nhân tạo của trung tâm nghiên cứu và s ức chịu trách nhiệm dịch chuyển sinh học WM21. Bốn trong số các tài liệu này đạt được đẳng cấp cấp cấp cấp cao nhất của Hệ thống Đèn xanh dựa trên các kết quả đánh giá tự động công bố (sở Một-NG, một-NG và một-NG). Chúng tôi thực hiện các thí nghiệm để tiết lộ ý kiến thực tế về các kỹ thuật sửa chữa miền liên quan, bao gồm lệnh tinh chỉnh độ, từ điển các thuật ngữ, và giải mã chung. Những vấn đề liên quan đến việc tăng cường và thiếu dịch chuyển.', 'da': 'Denne artikel beskriver Huawei Kunstig Intelligens Application Research Centers neurale maskinoversættelsessystemer og indsendelser til WMT21 biomedicinsk oversættelse delte opgave. Fire af indsendelserne opnår topmoderne BLEU-scorer baseret på de officielle automatiske evalueringsresultater (EN-FR, EN-IT og ZH-EN). Vi udfører eksperimenter for at afsløre den praktiske indsigt i de involverede domænetilpasningsteknikker, herunder finjusterende rækkefølge, terminologiordbøger og ensemble dekodning. Spørgsmål i forbindelse med overtilpasning og underoversættelse diskuteres også.', 'bg': 'Тази статия описва системите за невронен машинен превод на Центъра за изследване на приложенията за изкуствен интелект и подчиненията на споделената задача за биомедицински превод. Четири от заявленията постигат най-съвременни резултати въз основа на официално публикуваните резултати от автоматичната оценка (EN-FR, EN-IT и ZH-EN). Извършваме експерименти, за да разкрием практическите прозрения на свързаните техники за адаптация на домейна, включително фина настройка на реда, терминологични речници и декодиране на ансамбъли. Разгледани са и въпросите, свързани с пренасочването и недостатъчния превод.', 'nl': 'Dit artikel beschrijft de neurale machine translation systemen van het Huawei Artificial Intelligence Application Research Center en inzendingen aan de WMT21 biomedische vertaling gedeelde taak. Vier van de inzendingen behalen state-of-the-art BLEU scores op basis van de officieel gepubliceerde automatische evaluatieresultaten (EN-FR, EN-IT en ZH-EN). We voeren experimenten uit om de praktische inzichten van de betrokken domeinadaptatietechnieken te onthullen, waaronder finetuning volgorde, terminologie woordenboeken en ensemble decodering. Ook kwesties die verband houden met overfitting en ondervertaling worden besproken.', 'hr': 'Ovaj papir opisuje sustave za prevod neuralnih strojeva Centra istraživanja istraživanja inteligencije Huawei i podatke zajedničkom zadatku biomedicinskog prevoda WMT21. Četiri podaci postignu rezultate BLEU-a iz države umjetnosti na temelju rezultata automatske procjene oslobođenih na službenom nivou (EN-FR, EN-IT i ZH-EN). Izvodimo eksperimente kako bi otkrili praktične uvide uključenih tehnika adaptacije domena, uključujući naredbu finetuning, terminološke riječi i ensemble dekodiranja. Također se raspravljaju i pitanja povezanih s preuređenjem i nepromijeljenim prevodom.', 'de': 'Dieses Papier beschreibt die neuronalen maschinellen Übersetzungssysteme des Huawei Artificial Intelligence Application Research Centers und die Einreichungen für die gemeinsame Aufgabe der biomedizinischen Übersetzung WMT21. Vier der Einreichungen erzielen auf Basis der offiziell veröffentlichten automatischen Auswertungsergebnisse (EN-FR, EN-IT und ZH-EN) aktuelle BLEU-Scores. Wir führen Experimente durch, um die praktischen Erkenntnisse der beteiligten Domänenanpassungstechniken zu enthüllen, einschließlich Feinabstimmungsreihenfolge, Terminologiewörterbücher und Ensembledecodierung. Auch Fragen im Zusammenhang mit Überarbeitung und Unterübersetzung werden diskutiert.', 'ko': '본고는 화웨이 인공지능 응용연구센터의 신경기계 번역 시스템과 WMT21 생물의학 번역 공유 임무에 제출한 문서를 소개한다.공식 발표된 자동 평가 결과(EN-FR, EN-IT, ZH-EN)에 따르면 이 중 4개가 제출한 자료가 가장 선진적인 BLEU 점수에 이르렀다.우리는 실험을 통해 관련 분야의 자체 적응 기술에 대한 실제 견해를 제시했는데, 미조정 순서, 용어 사전, 통합 디코딩을 포함한다.과도한 의합과 번역 부족과 관련된 문제도 논의했다.', 'fa': 'این کاغذ سیستم ترجمه\u200cهای ماشین عصبی مرکز تحقیقات کاربرد مصنوعی هوئوی را توصیف می\u200cکند و تحویل دادن به وظیفه\u200cی ترجمه\u200cهای بیولوژیک WMT21 را مشترک می\u200cکند. چهار نفر از تحویل\u200cها به عنوان نتایج ارزیابی خودکار (EN-FR, EN-IT و ZH-EN) بر اساس رسمی آزاد شده\u200cاند. ما آزمایش\u200cها را انجام می\u200cدهیم تا آزمایش\u200cهای عملی را از تکنیک\u200cهای تغییر\u200cسازی دامنی مشترک باز کنیم، شامل سفارش پاکیزه\u200cسازی، لغوی\u200cهای ترمینالوژی و تغییر\u200cسازی. مسئله\u200cهایی که مربوط به تغییر مناسب و زیر ترجمه\u200cای هستند در مورد آن هم صحبت می\u200cشوند.', 'id': 'Kertas ini menjelaskan sistem penerjemah mesin saraf Pusat penelitian Huawei Intelligence Artificial Intelligence dan pengiriman ke tugas terbagi terjemahan biomedis WMT21. Empat dari pengiriman mencapai nilai BLEU terbaik berdasarkan hasil evaluasi otomatis yang diberikan resmi (EN-FR, EN-IT dan ZH-EN). Kami melakukan eksperimen untuk mengungkapkan pandangan praktis dari teknik adaptasi domain yang terlibat, termasuk perintah penentuan, kamus terminologi, dan dekodifikasi ensemble. Masalah yang berhubungan dengan overfitting dan under translation juga didiskusikan.', 'sw': 'Gazeti hili linaelezea mfumo wa utafiti wa kituo cha Utafiti wa Habari cha Huawei cha Utafiti wa Utafiti wa Habari na mfumo wa utafsiri wa mashine ya asili na ujumbe wa utafsiri wa kitabibu cha WMT21. Mawasiliano wanne yanafanikiwa vipindi vya sanaa vya BLEU kwa kutumia matokeo rasmi ya uchunguzi (EN-FR, EN-IT na ZH-EN). Tunafanya majaribio ili kufungua mitazamo halisi ya mbinu zinazohusika na kubadilisha ndani, ikiwa ni pamoja na amri ya kutoa faini, dictionary of terminology, na decodi za kidini. Masuala yanayohusiana na kusambaza na kutafsiri pia yanajadiliwa.', 'tr': 'Bu kagyz Huawei Yapça Inteleks Görniş Program Araştyrma Merkeziniň neural maşynyň terjime sistemlerini we WMT21 biýamedicin terjime edilmesine rugsat berir. Dört sanat submisiýasynda resmi-sereden awtomatik çykyş netijelerine daýanýan bolan BLEU sanatynyň durumyny tapylýar. Biz de etkinleşik sıralar, terminoloji sözlerini ve dekodini dahil etkinleştirmek için etkinleştirdik. Iň ýeterlik we aşa terjime eden meseleler hem gürleşýär.', 'af': 'Hierdie papier beskryf Huawei Kunstenaar Inteligentasie Toepassingsintrum se neurale masjien vertalingsstelsels en onderskrywings aan die WMT21 biomediese vertaling gedeelde taak. vier van die onderdragte bereik staat-van-die-kunstenaar BLEU-rekorde gebaseer op die offisieel-uitgevaardige outomatiese evalueringsresultate (EN-FR, EN-IT en ZH-EN). Ons uitvoer eksperimente om die praktiese inligtings van die betrokke domein-adaptasie-teknike te ontdek, insluitend finetuning volgorde, terminologies-woordeboeke en ensemble dekodering. Voorwerpe wat geassosieer word met oorvloediging en onder-vertaling is ook gespreek.', 'sq': 'Ky artikull përshkruan sistemet e përkthimit të makinave nervore të Qendrës s ë Kërkimit të Inteligjencës Artistike Huawei dhe dorëzimet në detyrën e përbashkët të përkthimit biomedik WMT21. Katër nga paraqitjet arrijnë rezultatet më të larta të BLEU bazuar në rezultatet e vlerësimit automatik të lëshuar zyrtarisht (EN-FR, EN-IT dhe ZH-EN). Ne bëjmë eksperimente për të zbuluar kuptimet praktike të teknikave të përshtatjes së fushës së përfshirë, duke përfshirë rendin e përshtatjes, fjalorët e terminologjisë dhe dekodimin e ansamblit. Çështjet lidhur me mbipajtimin dhe nënpërkthimin janë diskutuar gjithashtu.', 'am': 'ይህ ፕሮግራም Huawei አርስቲካዊ የኢንተርኔት ፕሮግራም መርምር ማዕከላዊ የናውሬል መሣሪያን እና የWMT21 biomedical translation ስርዓት የተካፈሉት ስርዓት እና ጥያቄዎችን ይናገራል፡፡ ከውጤቶች አራቱ የባሕላዊ አውቶማቲ አካል ውጤቶች (EN-FR, EN-IT እና ZH-EN) በመጠቀም የሀገር-የልዩን ሁኔታ አግኝቷል፡፡ የዶሜን አካባቢ ስክሮት፣ ተርሚኖሎጂ መዝገብ እና የድምፅ መዝገብ እና የክፍለ ክፍተቶችን እናደርጋለን፡፡ በይፋ እና በታች ትርጓሜ የተገኘ ጉዳዮች ደግሞ ተጨማሪ ናቸው፡፡', 'az': "Bu kağıt Huawei Yaxşı Intelligence Application Research Center'ın nöral maşın tərcümə sistemlərini və WMT21 biomedical tərcümə işləri paylaşır. Dördüncü təbliğ təbliğlərin resmi təbliğ edilmiş avtomatik değerlendirmə sonuçlarına ( EN-FR, EN-IT və ZH-EN) dayandırılmış şəkildə müəyyən edilmiş BLEU nöqtələrini başa düşür. Biz səviyyəni, terminoloji sözləri və dekodini inkişaf etmək üçün müxtəlif domeinin uyğunlaşdırma tekniklərinin praktik görünüşünü açıq etmək üçün imtahana çəkirik. Həmçinin çox uyğun və aşağı çevirilən məsələlər də mübahisə edilir.", 'hy': 'Այս հոդվածը նկարագրում է Հուավեի արվեստական ինտելեկցիայի ծրագրերի հետազոտության կենտրոնի նյարդային մեքենայի թարգմանման համակարգերը և ներկայացումները աշխարհի 21 կենսաբժշկական թարգմանման ընդհանուր խնդիրը: Այս ներկայացումներից չորսը հասնում են ամենահետաքրքիր ԲԼԵՎ-ի գնահատականների, հիմնված պաշտոնական արտադրված ավտոմատիկ գնահատականների արդյունքների վրա (ԷՆ-ՖՌ, ԷՆ-IT և ԶՀ-ԷՆ): Մենք փորձեր ենք կատարում, որպեսզի բացահայտենք ներգրավված բնագավառի ադապտացիայի տեխնիկայի պրակտիկ ընկալումները, ներառյալ փորձարկման կարգը, տերմինոլոգիական բառարանները և համակարգչային կոդավորումը: Issues associated with overfitting and under-translation are also discussed.', 'bn': 'এই পত্রিকাটি হুয়াই শিল্পীয় তথ্যের বিষয়বস্তু প্রশিক্ষণ কেন্দ্রের নিউরুল মেশিন অনুবাদ সিস্টেম এবং উইএমটি২১ বায়োমেডিকেল অনুবাদের সরকারি মুক্তির স্বয়ংক্রিয়ভাবে মুক্তির ফলাফলের ভিত্তিতে প্রাপ্ত চারজন সংস্কার পায় (EN-FR, EN-IT এবং ZH-EN)। আমরা পরীক্ষা করি যার মধ্যে জড়িত ডোমেইনের প্রযুক্তির বাস্তবতা প্রযুক্তির দৃষ্টিভঙ্গি প্রকাশ করার জন্য, যার মধ্যে রয়েছে ফিনিউশনিং আদেশ অনুবাদ এবং অনুবাদের সাথে সম্পর্কিত বিষয়গুলোও আলোচনা করা হয়েছে।', 'cs': 'Tento článek popisuje neuronové strojové překladové systémy a podání do sdíleného úkolu biomedicínského překladu WMT21. Čtyři příspěvky dosahují nejmodernějších bodů BLEU na základě oficiálně zveřejněných výsledků automatického hodnocení (EN-FR, EN-IT a ZH-EN). Provádíme experimenty s cílem odhalit praktické poznatky zapojených technik adaptace domén, včetně jemného ladění pořadí, terminologických slovníků a dekódování souborů. Jsou také diskutovány otázky spojené s nadměrným a nedostatečným překladem.', 'bs': 'Ovaj papir opisuje sisteme neuromašinskih prevodnih sustava i podatke u biomedicinski prevodni zadatak Huawei umjetnog istraživačkog centra za istraživanje inteligencije. Četiri podataka postignu rezultate BLEU-a iz države umjetnosti na temelju rezultata automatske procjene oslobođenih na službenom nivou (EN-FR, EN-IT i ZH-EN). Izvodimo eksperimente da otkrijemo praktične uvide uključenih tehnika adaptacije domena, uključujući naređenje finetuniranja, terminološke diktorije i osiguramo dekodiranje. Također se raspravljaju i pitanja povezane s preuređenjem i nepromijeljenim prevodom.', 'ca': "Aquest article descriu els sistemes de traducció neural de màquines del Centre d'Investigació en Inteligència Artificial Huawei i les presentacions a la tasca compartida de traducció biomèdica WMT21. Quatre de les proposicions aconsegueixen puntuacions BLEU més modernes basades en els resultats d'evaluació automàtica publicats oficialment (EN-FR, EN-IT i ZH-EN). Fem experiments per revelar les comprensions pràctiques de les tècniques d'adaptació del domini involucradas, incloent l'ordre d'ajustament, els diccionaris de terminologia i la decodificació d'ensembles. També es discuten les qüestions relacionades amb l'equipament excessiu i la infratraducció.", 'et': 'Käesolevas artiklis kirjeldatakse Huawei tehisintellekti rakenduste uurimiskeskuse neuromasintõlke süsteeme ja esitatakse WMT21 biomeditsiinilise tõlke jagatud ülesandele. Neli taotlust saavutavad ametlikult avaldatud automaatse hindamise tulemuste (EN-FR, EN-IT ja ZH-EN) alusel kaasaegsed BLEU tulemused. Teostame eksperimente, et avalikustada praktilised ülevaated asjaomastest domeenide kohandamise tehnikatest, sealhulgas peenhäälestuse järjekorrast, terminoloogia sõnaraamatutest ja ansamblite dekodeerimisest. Arutatakse ka üle- ja alatõlkimisega seotud küsimusi.', 'fi': 'T채ss채 artikkelissa kuvataan Huawein teko채lysovellusten tutkimuskeskuksen neurokonek채채nn철sj채rjestelmi채 ja toimituksia WMT21-biol채채ketieteelliseen k채채nn철kseen jaettuun teht채v채채n. Nelj채ll채 hakemuksella saavutetaan viimeisimpi채 BLEU-pisteit채, jotka perustuvat virallisesti julkaistuihin automaattisiin arviointituloksiin (EN-FR, EN-IT ja ZH-EN). Teemme kokeita paljastaaksemme k채yt채nn철n oivalluksia asiaan liittyvist채 toimialueen sopeutustekniikoista, mukaan lukien hienos채채t철j채rjestys, terminologiasanakirjat ja ensemble dekoodaus. Lis채ksi k채sitell채채n ylikuormitukseen ja alik채채nn철ksiin liittyvi채 kysymyksi채.', 'jv': 'Ngerti iki rambarang nggambar sistem penting nggambar apakno anu nggambar apakno anu nggambar barang nyang basa nyang banter, kiye anu nggambar barang nyang banter, gambar nggambar terjamahan piyane, ning bumi Artidical Informasi Aplikasi Jejaring Wong wong sing berarti nggawe barang-punika sing perusahaan-karo biji-perusahaan, sing basa supoyo barang-perusahaan uwong sisakake dipolehasan ora bisa perusahaan (en-fro, en-AR lan Z H-ENE). We do pilipen to unwrap the praecal logies of the connected domain Adjustment Methods, include Finetuning order, terminal words, and ensembedle decoding. Asmaci bener', 'sk': 'Ta prispevek opisuje sisteme nevronskega strojnega prevajanja Centra za raziskave aplikacij umetne inteligence Huawei in prispevke k skupni nalogi biomedicinskega prevajanja WMT21. Štiri predložene prijave dosegajo najsodobnejše rezultate BLEU na podlagi uradno objavljenih rezultatov avtomatičnega ocenjevanja (EN-FR, EN-IT in ZH-EN). Izvajamo poskuse, s katerimi razkrivamo praktične vpoglede na vključene tehnike prilagajanja domenskih področij, vključno z finimi nastavitvami vrstnega reda, terminološkimi slovarji in dekodiranjem ansamblov. Obravnavajo se tudi vprašanja, povezana s prevajanjem in premalo prevajanjem.', 'he': 'העיתון הזה מתאר את מערכות התרגום המכונית העצבית של מרכז מחקר התקשורת מודיעין מלאכותית יואווי והשליחות למשימה המשותפת של התרגום הביומדיקאי WMT21. ארבעה מההצעות מגיעות לתוצאות BLEU מוקדמות בהתבסס על תוצאות הערכה האוטומטית המשוחררות הרשמית (EN-FR, EN-IT ו-ZH-EN). אנו מבצעים ניסויים כדי לחשוף את ההבנות המטופלות של טכניקות ההתאמה לתחום המעורבת, כולל סדר ההתאמה, מילונים טרמולוגיים, ופיתוח אנסמבל. הנושאים הקשורים למתאימות יתר ומתורגם מתחת לתמונה גם נדון.', 'bo': "This paper describes Huawei Artificial Intelligence Application Research Center's neural machine translation systems and submissions to the WMT21 biomedical translation shared task. Four of the submissions achieve state-of-the-art BLEU scores based on the official-released automatic evaluation results (EN-FR, EN-IT and ZH-EN). We perform experiments to unveil the practical insights of the involved domain adaptation techniques, including finetuning order, terminology dictionaries, and ensemble decoding. ཚོར་བ་དང་བསུབ་པ་དང་ཡིག་སྐབས་ཀྱི་ནང་དོན་ཡོད་པའི་དཀའ་ངལ་ཚོགས་ཀྱང་བཤད་ཡོད།", 'ha': "This paper describes Huawei Artificial Intelligence Application Research Center's neural machine translation systems and submissions to the WMT21 biomedical translation shared task.  Four daga wasiyyan su sami state-of-the-art BLEU scores based on the offisive-bango data evaluation farat ɗaya (EN-FR, EN-It and ZH-EN). Munã jarraba jarrabo dõmin ka buɗe masu kasha da ke cikin masu adadi na guda, kamar ruɓanin fintufi, dictionary bakwai da kuma zaɓen kwamfyuta. Ana kula da masu husũma da mai canza da-fassarar."}
{'en': 'HW-TSC’s Participation at WMT 2021 Quality Estimation Shared Task', 'es': 'Participación de HW-TSC en la tarea compartida de estimación de calidad del WMT 2021', 'pt': 'Participação do HW-TSC na Tarefa Compartilhada de Estimativa de Qualidade do WMT 2021', 'fr': "Participation de HW-TSC à la tâche partagée d'estimation de la qualité WMT 2021", 'ar': 'مشاركة HW-TSC في المهمة المشتركة لتقدير الجودة WMT 2021', 'hi': 'WMT 2021 गुणवत्ता अनुमान साझा कार्य में HW-TSC की भागीदारी', 'ja': 'WMT 2021品質見積もり共有タスクへのHW - TSCの参加', 'zh': 'HW-TSC参WMT 2021质评估共任', 'ru': 'Участие HW-TSC в совместной задаче по оценке качества WMT 2021', 'ga': 'Rannpháirtíocht HW-TSC ag Tasc Comhroinnte Meastachán Cáilíochta 2021 WMT', 'hu': 'A HW-TSC részvétele a WMT 2021 minőségbecslési megosztott feladatában', 'el': 'Συμμετοχή του στην Εκτίμηση Ποιότητας Κοινή Εργασία', 'it': 'Partecipazione di HW-TSC a WMT 2021 Quality Estimation Shared Task', 'ka': 'HW-TSC-ის მოწყობილობა WMT 2021-ის განსაზღვრებული კვალეტის განსაზღვრება', 'mk': 'Учеството на ХВ-ТС на заедничката задача за проценка на квалитетот во WMT 2021', 'ms': 'Pesertaan HW-TSC pada Tugas Berkongsi Penghargaan Kualiti WMT 2021', 'ml': 'WMT 2021-ലെ HW-TSC പങ്കാളിയുടെ പങ്കാളി', 'kk': 'HW- TSC WMT 2021 сапасы бағалау ортақтастырылған тапсырманың қатысуы', 'mt': "HW-TSC's Participation at WMT 2021 Quality Estimation Shared Task", 'lt': "HW-TSC's Participation at WMT 2021 Quality Estimation Shared Task", 'mn': 'HW-TSC-ын WMT 2021-н чанарын төсөөлөл хуваалцах ажил', 'sr': 'Učestvovanje HW-TSC-a na WMT 2021. razmišljanju o procjeni kvalitete zajedničkog zadatka', 'no': 'HW-TSC- deltakaren på WMT 2021- kvalitetevaluering delt oppgåve', 'pl': 'Udział HW-TSC w szacowaniu jakości WMT 2021 Wspólne zadanie', 'si': "HW-TSC's partition at WMT 2021", 'ro': 'Participarea HW-TSC la activitatea partajată de estimare a calității WMT 2021', 'ur': "HW-TSC's Participation at WMT 2021 Quality Estimation Shared Task", 'sv': 'HW-TSC:s deltagande i WMT 2021 kvalitetsbedömning delad uppgift', 'so': 'WMT 2021 Quality Estimation Shared Task', 'ta': 'WMT 2021 தரமான கணக்கீட்டு பகிர்ந்த பணியில் HW- TSC கூட்டுதல்', 'uz': 'Comment', 'vi': 'HW-TSC tham gia vào công việc chia s ẻ chất lượng WM 2021', 'hr': 'Učestvovanje HW-TSC-a na procjenu kvalitete WMT 2021', 'bg': 'Участието на ХУ-ТСК в Оценка на качеството за 2021 Споделена задача', 'nl': 'Deelname van HW-TSC aan WMT 2021 Kwaliteitsschatting Gedeelde Task', 'de': 'Teilnahme von HW-TSC an der WMT 2021 Qualitätsschätzung Gemeinsame Aufgabe', 'da': "HW-TSC's deltagelse i WMT 2021 Quality Estimation Shared Task", 'ko': 'WMT 2021 품질 평가 공유 작업에 HW-TSC 참여', 'id': "HW-TSC's Participation at WMT 2021 Quality Estimation Shared Task", 'sw': 'Ushiriki wa HW-TSC katika Uwango wa WMT 2021', 'fa': 'شرکت HW-TSC در ارزیابی کیفیت WMT 2021', 'sq': 'Pjesëmarrja e HW-TSC në detyrën e përbashkët të vlerësimit të cilësisë WMT 2021', 'am': 'በWMT 2021 Quality Estimation Shared Task', 'af': 'HW- TSC se Deelnadering by WMT 2021 Kwaliteit Estimasie Gedeelde Taak', 'tr': "HW-TSC'nin WMT 2021 kalitesinden Bölünme Görevi", 'bn': 'WMT ২০২১ সালে HW-TSC এর অংশগ্রহণকারী', 'az': "HW-TSC'nin WMT 2021 kaliteli Görünüş Bölünməsi", 'ca': "Participació de la TSC en la tasca compartida d'estimació de qualitat del WMT 2021", 'bs': 'Učestvovanje HW-TSC-a na procjeni kvalitete WMT 2021', 'cs': 'Účast HW-TSC na odhadu kvality WMT 2021 Sdílený úkol', 'fi': 'HW-TSC:n osallistuminen WMT 2021 Quality Estimation Shared Task', 'hy': 'ՀՈւ-ՏՍԿ-ի մասնակցությունը 2021 թվականի համաշխարհային որակի գնահատման գործում', 'et': 'HW-TSC osalemine WMT 2021 kvaliteedi hindamisel jagatud ülesanne', 'jv': 'HWT-T-S partition at WT 2020 1 Quality', 'sk': 'Udeležba HW-TSC na skupni nalogi ocene kakovosti WMT 2021', 'ha': '@ info: status', 'bo': "HW-TSC's Participation at WMT 2021 Quality Estimation Shared Task", 'he': 'משתתפות HW-TSC במשימה משותפת בהערכת איכות WMT 2021'}
{'en': 'This paper presents our work in WMT 2021 Quality Estimation (QE) Shared Task. We participated in all of the three sub-tasks, including Sentence-Level Direct Assessment (DA) task, Word and Sentence-Level Post-editing Effort task and Critical Error Detection task, in all language pairs. Our systems employ the framework of Predictor-Estimator, concretely with a pre-trained XLM-Roberta as Predictor and task-specific classifier or regressor as Estimator. For all tasks, we improve our systems by incorporating post-edit sentence or additional high-quality translation sentence in the way of ', 'ar': 'تعرض هذه الورقة عملنا في المهمة المشتركة لتقدير الجودة (QE) WMT 2021. شاركنا في جميع المهام الفرعية الثلاث ، بما في ذلك مهمة التقييم المباشر على مستوى الجملة (DA) ، ومهمة جهد التحرير اللاحق على مستوى الكلمات والجمل ومهمة اكتشاف الأخطاء الحرجة ، في جميع أزواج اللغات. تستخدم أنظمتنا إطار عمل Predictor-Estimator ، بشكل ملموس مع XLM-Roberta المدربة مسبقًا كمتوقع ومصنف خاص بالمهمة أو مقدر كمقدر. بالنسبة لجميع المهام ، نقوم بتحسين أنظمتنا من خلال دمج جملة ما بعد التحرير أو جملة ترجمة إضافية عالية الجودة في طريقة التعلم متعدد المهام أو ترميزها باستخدام المتنبئين مباشرة. علاوة على ذلك ، في إعداد اللقطة الصفرية ، فإن إستراتيجيتنا لزيادة البيانات القائمة على Monte-Carlo Dropout تحقق تحسنًا كبيرًا في مهمة DA الفرعية. والجدير بالذكر أن عمليات الإرسال لدينا تحقق نتائج ملحوظة في جميع المهام.', 'pt': 'Este artigo apresenta nosso trabalho na Tarefa Compartilhada de Estimativa de Qualidade (QE) do WMT 2021. Participamos de todas as três subtarefas, incluindo tarefa de Avaliação Direta em Nível de Sentença (DA), tarefa de Esforço de Pós-edição de Palavras e Nível de Sentença e tarefa de Detecção de Erros Críticos, em todos os pares de idiomas. Nossos sistemas empregam a estrutura do Predictor-Estimator, concretamente com um XLM-Roberta pré-treinado como Predictor e classificador ou regressor específico da tarefa como Estimator. Para todas as tarefas, melhoramos nossos sistemas incorporando uma frase pós-edição ou uma frase adicional de tradução de alta qualidade na forma de aprendizado multitarefa ou codificando-a diretamente com preditores. Além disso, na configuração de tiro zero, nossa estratégia de aumento de dados com base no Monte-Carlo Dropout traz uma melhoria significativa na subtarefa DA. Notavelmente, nossos envios alcançam resultados notáveis em todas as tarefas.', 'fr': "Cet article présente notre travail dans le cadre de la tâche partagée d'estimation de la qualité (QE) WMT 2021. Nous avons participé aux trois sous-tâches, y compris la tâche d'évaluation directe (DA) au niveau de la phrase, la tâche de post-édition au niveau des mots et des phrases et la tâche de détection des erreurs critiques, dans toutes les paires de langues. Nos systèmes utilisent le cadre de Predictor-Estimator, concrètement avec un XLM-Roberta pré-formé comme prédicteur et un classificateur ou un régresseur spécifique à une tâche comme estimateur. Pour toutes les tâches, nous améliorons nos systèmes en incorporant une phrase post-édition ou une phrase de traduction supplémentaire de haute qualité dans le cadre de l'apprentissage multitâche ou en l'encodant directement avec des prédicteurs. De plus, dans le cadre du zéro tir, notre stratégie d'augmentation des données basée sur le décrochage de Monte-Carlo apporte une amélioration significative de la sous-tâche DA. Nos soumissions obtiennent notamment des résultats remarquables pour toutes les tâches.", 'ja': 'この論文では、WMT 2021品質推定（ QE ）共有タスクにおける私たちの仕事を紹介します。私たちは、文章レベル直接評価（ DA ）タスク、単語および文章レベル後編集努力タスク、および重大なエラー検出タスクを含む3つのサブタスクのすべてに、すべての言語ペアで参加しました。当社のシステムは、事前に訓練されたXLM - Robertaを予測因子として、タスク固有の分類子または回帰因子を推定因子として、予測因子-推定因子のフレームワークを採用しています。すべてのタスクについて、マルチタスク学習の方法でポストエディット文または追加の高品質翻訳文を組み込んだり、予測因子で直接エンコードしたりすることで、システムを改善しています。さらに、ゼロショット設定では、モンテカルロ・ドロップアウトに基づく当社のデータ拡張戦略は、DAサブタスクの大幅な改善をもたらします。特に、当社の提出物は、すべてのタスクで目覚ましい結果を達成しています。', 'zh': '本文引我WMT 2021质评估(QE)共享其事。 臣等参三子之事,句级直评(DA)务,单词与句级译后辑工作量及严重错误检测,凡言语是也。 吾统用预测器-度器之框架,具以豫练之XLM-Roberta为预测器,以特定任之器若归器为度器。 凡诸务,以多任务学入辑句若他高质量译句或径用占因编码以改吾统。 此外,于零触发设下,我们基于蒙特卡洛辍学的数据增强策略显著改进了DA子务。 值得注意者,所以成功也。', 'es': 'Este artículo presenta nuestro trabajo en la tarea compartida de estimación de calidad (QE) del WMT 2021. Participamos en las tres subtareas, incluida la tarea de evaluación directa (DA) a nivel de oración, la tarea de esfuerzo posterior a la edición de palabras y oraciones y la tarea de detección de errores críticos, en todas las combinaciones de idiomas. Nuestros sistemas emplean el marco de Predictor-Estimator, concretamente con un XLM-Roberta previamente entrenado como Predictor y un clasificador o regresor específico de la tarea como Estimador. Para todas las tareas, mejoramos nuestros sistemas incorporando oraciones posteriores a la edición u oraciones de traducción adicionales de alta calidad en forma de aprendizaje multitarea o codificándolas directamente con predictores. Además, en una configuración de tiro cero, nuestra estrategia de aumento de datos basada en la deserción de Montecarlo trae consigo una mejora significativa en la subtarea de DA. En particular, nuestras presentaciones logran resultados notables en todas las tareas.', 'hi': 'यह पेपर डब्ल्यूएमटी 2021 गुणवत्ता अनुमान (क्यूई) साझा कार्य में हमारे काम को प्रस्तुत करता है। हमने सभी भाषा जोड़े में वाक्य-स्तरीय प्रत्यक्ष मूल्यांकन (DA) कार्य, Word और वाक्य-स्तर पोस्ट-संपादन प्रयास कार्य और महत्वपूर्ण त्रुटि पहचान कार्य सहित सभी तीन उप-कार्यों में भाग लिया। हमारे सिस्टम भविष्यवक्ता-अनुमानक के ढांचे को नियोजित करते हैं, जो कि पूर्व-प्रशिक्षित XLM-Roberta के साथ भविष्यवक्ता के रूप में और कार्य-विशिष्ट क्लासिफायर या अनुमानक के रूप में regressor के रूप में ठोस रूप से। सभी कार्यों के लिए, हम मल्टीटास्क सीखने के रास्ते में पोस्ट-एडिट वाक्य या अतिरिक्त उच्च गुणवत्ता वाले अनुवाद वाक्य को शामिल करके या इसे सीधे भविष्यवाणियों के साथ एन्कोडिंग करके अपने सिस्टम में सुधार करते हैं। इसके अलावा, शून्य-शॉट सेटिंग में, मोंटे-कार्लो ड्रॉपआउट पर आधारित हमारी डेटा वृद्धि रणनीति डीए उप-कार्य पर महत्वपूर्ण सुधार लाती है। विशेष रूप से, हमारी प्रस्तुतियां सभी कार्यों पर उल्लेखनीय परिणाम प्राप्त करती हैं।', 'ru': 'В настоящем документе представлена наша работа по совместной задаче WMT 2021 Quality Estimation (QE). Мы участвовали во всех трех подзадачах, включая задачу прямой оценки на уровне предложения (Sentence-Level Direct Assessment, DA), задачу постредактирования на уровне слова и предложения и задачу обнаружения критических ошибок, во всех языковых парах. Наши системы используют структуру Predictor-Estimator, в частности, с предварительно обученным XLM-Roberta в качестве Predictor и специфическим для задачи классификатором или регрессором в качестве Estimator. Для всех задач мы улучшаем наши системы, вводя пост-редактированное предложение или дополнительное предложение высокого качества перевода в способ многозадачного обучения или кодируя его непосредственно предикторами. Кроме того, в режиме нулевого снимка наша стратегия расширения данных на основе Monte-Carlo Dropout приводит к значительному улучшению подзадачи DA. Примечательно, что наши представления достигают замечательных результатов по всем задачам.', 'ga': 'Cuireann an páipéar seo i láthair ár gcuid oibre i dTasc Comhroinnte um Mheastachán Cáilíochta (QE) WMT 2021. Ghlacamar páirt i ngach ceann de na trí fhothasc, lena n-áirítear tasc Measúnú Díreach ar Leibhéal Pianbhreithe (MA), tasc Iarrachta Iar-eagarthóireachta Word agus Leibhéal Pianbhreithe agus tasc Brath Earráidí Criticiúla, i ngach péirí teanga. Úsáideann ár gcórais creat an Réamh-Mheastacháin, go nithiúil le XLM-Roberta réamhoilte mar Thuarthóir agus aicmitheora nó aischéimnithí tasc-shonracha mar Mheastachán. Maidir le gach tasc, feabhsaítear ár gcórais trí phianbhreith iar-eagarthóireachta nó abairt aistriúcháin bhreise ardcháilíochta a ionchorprú chun ilthasc a fhoghlaim nó é a ionchódú go díreach le réamhaisnéiseoirí. Ina theannta sin, i socrú náid, tugann ár straitéis mhéadaithe sonraí bunaithe ar Monte-Carlo Dropout feabhas suntasach ar fhothasc DA. Go háirithe, baineann ár n-aighneachtaí torthaí suntasacha amach thar na tascanna go léir.', 'ka': 'ეს დოკუმენტი ჩვენი სამუშაო WMT 2021 წლის განსაზღვრება (QE) გაყოფილი სამუშაო. ჩვენ ყველა სამუშაო სამუშაო დავალებში დავწევთ, რომელიც სიტყვა და სიტყვა-დონეზე დარედაქტირებული მოქმედება და კრიტიკური შეცდომის განახსნა დავალება, ყველა ენაში. ჩვენი სისტემები პრედიქტორი-ესტიმატორის პარამეტრის გამოყენება, როგორც პრედიქტორი და დავაკეთებული კლასიფიკაცია ან რეგრესტორი როგორც ესტიმატორი. ყველა დავალებისთვის ჩვენი სისტემები უფრო მეტად გავაკეთებთ, რომელიც შემდეგ რედაქტირებული სიტყვა ან დამატებული უფრო მეტად კარგად გავაკეთებული სიტყვა multitasks სწავლების დამატებით, ჩვენი მონაცემების აგგენტირება სტრატიგიაში, მონტა-კაპლო ეპოპოტის ბაზედან მნიშვნელოვანი უფრო მეტადება სამუშაო სამუშაო და ნაქთრვ ოპვეოჲლჲზვნთწ ჟრთდნარ ნვგვპჲწრნთ პვჱსლრართ ჱა გჟთფკთ პაბჲრთ.', 'el': 'Η παρούσα εργασία παρουσιάζει την εργασία μας στην Κοινή Εργασία Εκτίμησης Ποιότητας (QE). Συμμετείχαμε και σε όλες τις τρεις δευτερεύουσες εργασίες, συμπεριλαμβανομένης της εργασίας άμεσης αξιολόγησης επιπέδου φράσεων, της εργασίας προσπάθειας επεξεργασίας κειμένου και φράσεων και της εργασίας ανίχνευσης κρίσιμων σφαλμάτων, σε όλα τα γλωσσικά ζεύγη. Τα συστήματά μας χρησιμοποιούν το πλαίσιο του Predictor-Estimator, συγκεκριμένα με ένα προ-εκπαιδευμένο ως Predictor και ειδικό καθορισμού εργασίας ή αναδρομέα ως Εκτιμητής. Για όλες τις εργασίες, βελτιώνουμε τα συστήματά μας ενσωματώνοντας πρόταση μετά την επεξεργασία ή πρόσθετη πρόταση μετάφρασης υψηλής ποιότητας με τρόπο εκμάθησης πολλαπλών εργασιών ή κωδικοποίησης της απευθείας με προγνωστές. Επιπλέον, σε μηδενική λήψη, η στρατηγική αύξησης δεδομένων που βασίζεται στο Μόντε Κάρλο Dropout φέρνει σημαντική βελτίωση στην υποεργασία DA. Ιδιαίτερα, οι αιτήσεις μας επιτυγχάνουν αξιοσημείωτα αποτελέσματα σε όλες τις εργασίες.', 'it': "Questo articolo presenta il nostro lavoro in WMT 2021 Quality Estimation (QE) Shared Task. Abbiamo partecipato a tutte e tre le attività secondarie, tra cui l'attività di valutazione diretta a livello di frase (DA), l'attività di sforzo post-modifica a livello di parola e frase e l'attività di rilevamento degli errori critici, in tutte le coppie di lingue. I nostri sistemi utilizzano il framework di Predictor-Estimator, concretamente con un XLM-Roberta pre-addestrato come Predictor e un classificatore specifico o regressore come Estimator. Per tutte le attività, miglioriamo i nostri sistemi incorporando frasi post-edit o frasi di traduzione aggiuntive di alta qualità nel modo di apprendimento multitask o codificandole direttamente con predittori. Inoltre, nell'impostazione zero-shot, la nostra strategia di aumento dei dati basata su Monte-Carlo Dropout porta un miglioramento significativo sul sub-task DA. In particolare, i nostri contributi raggiungono risultati notevoli su tutti i compiti.", 'kk': 'Бұл қағаз WMT 2021 сапасы оқиға (QE) ортақ тапсырманың жұмысын көрсетеді. Біз үш ішкі тапсырмалардың барлығына қатынасыз, сөз- деңгейінің дәл оценкасын (DA) тапсырмасы, сөз мен сөз- деңгейінің кейін өңдеу үшін тапсырмалар және критикалық қатені анықтау тапсырмасы барлық тілдер екеуін Біздің жүйелеріміз Predictor-Estimator бағдарламасын қолданып, алдындағы XLM-Roberta бағдарламасын Predictor және тапсырманың ерекше классификациясы немесе регрессорын Estimator ретінде қолданылады. Бүкіл тапсырмалар үшін, біз жүйеңізді өңдеу кезінде немесе көптеген тапсырмаларды оқыту немесе бақылаушылармен кодтамыз арқылы көптеген сапатты аудару үшін жүйеңізді жақсы жа Сонымен қатар, нөл түрінде, Monte-Carlo Dropout бағдарламасына негізделген деректерді көптеу стратегиясыз ДОК-ның ішкі тапсырмасына маңызды жақсарту жасайды. Әрине, біздің жіберіміз барлық тапсырмалардың арқылы белгілі нәтижелерін жеткізеді.', 'lt': 'Šiame dokumente pristatomas mūsų darbas WMT 2021 kokybės vertinimo (QE) bendroje užduotyje. Visose kalbų porose dalyvavome visose trijose subužduotyse, įskaitant tiesioginio vertinimo (DA) užduotį, žodžių ir nuosprendžių lygį po redagavimo ir kritinių klaidų nustatymo užduotį. Mūsų sistemose naudojama Prediktoriaus-įvertinimo sistema, konkrečiai su iš anksto parengta XLM-Roberta kaip Prediktoriaus ir užduoties specifinio klasifikatoriaus arba regressoriaus kaip įvertinimo sistema. For all tasks, we improve our systems by incorporating post-edit sentence or additional high-quality translation sentence in the way of multitask learning or encoding it with predictors directly.  Be to, nustačius nulinę nuotrauką, mūsų Monte-Carlo Dropout grindžiama duomenų didinimo strategija labai pagerina prokuratūros subužduotį. Notably, our submissions achieve remarkable results over all tasks.', 'hu': 'Ez a tanulmány bemutatja a WMT 2021 Quality Estimation (QE) Shared Task munkáját. Mindhárom alcsoportban részt vettünk, beleértve a mondatszintű közvetlen értékelést (DA) feladatot, a szó és mondatszintű szerkesztési erőfeszítést követő feladatot és a kritikus hibák észlelését, valamint az összes nyelvpárban. Rendszereink a Predictor-Estimator keretrendszerét alkalmazzák, konkrétan egy előre képzett XLM-Roberta mint Predictor és feladatspecifikus osztályozó vagy regressor mint Estimator. Minden feladat esetében fejlesztjük rendszereinket azáltal, hogy beépítjük a szerkesztés utáni mondatokat vagy további kiváló minőségű fordítási mondatokat a többfeladatos tanulás útjába, vagy közvetlenül előrejelzőkkel kódoljuk. Ezenkívül a Monte-Carlo Dropout-on alapuló adatbővítési stratégiánk nulla-shot beállításban jelentős javulást eredményez a DA alfeladathoz képest. Különösen, beadványaink figyelemreméltó eredményeket érnek el minden feladat során.', 'ms': 'Kertas ini memperkenalkan kerja kita dalam WMT 2021 Estimation Quality (QE) Shared Task. Kami berpartisipasi dalam semua tiga sub-tugas, termasuk tugas penilaian langsung aras hukuman (DA), tugas Pas-edisi Aras perkataan dan hukuman dan tugas Pendekaan Ralat Kritik, dalam semua pasangan bahasa. Sistem kami menggunakan kerangka Predictor-Estimator, secara konkret dengan XLM-Roberta yang dilatih-dilatih sebagai Predictor dan pengklasifikasi khusus tugas atau regressor sebagai Estimator. Untuk semua tugas, kita memperbaiki sistem kita dengan memasukkan kalimat pos-edit atau kalimat terjemahan berkualiti tinggi tambahan dalam cara belajar tugas berbilang atau mengekodkannya dengan prediksor secara langsung. Moreover, in zero-shot setting, our data augmentation strategy based on Monte-Carlo Dropout brings up significant improvement on DA sub-task.  Terutama, penghantaran kami mencapai keputusan yang luar biasa atas semua tugas.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ ജോലി WMT 2021 ഗുണത്തിന്റെ എസ്റ്റിമേഷന്\u200d (ക്യൂയി) പങ്കുചേര്\u200dത്ത പണിയില്\u200d കൊണ്ടു We participated in all of the three sub-tasks, including Sentence-Level Direct Assessment (DA) task, Word and Sentence-Level Post-editing Effort task and Critical Error Detection task, in all language pairs.  നമ്മുടെ സിസ്റ്റമുകള്\u200d പ്രിസ്ട്രീക്ടര്\u200d -എസ്റ്റിമേറ്റരുടെ ഫ്രെയിമെക്ക് ഉപയോഗിക്കുന്നു, മുമ്പ് പരിശീലനം ലഭിച്ച എക്സ്റ്റിമേറ്റര്\u200d എന എല്ലാ ജോലികള്\u200dക്കും വേണ്ടി നമ്മുടെ സിസ്റ്റത്തെ മെച്ചപ്പെടുത്തുന്നു. പിന്നീട് ചിട്ടപ്പെടുത്തുന്ന വാക്കുകള്\u200d ചേര്\u200dക്കുന്നതോ കൂടു പൂര്\u200dണ്ണമായ വെടിവെക്കുന്നതില്\u200d, മോണ്ട്-കാര്\u200dലോ ഡ്രോപ്പൌട്ടിനെ അടിസ്ഥാനമായി നമ്മുടെ ഡേറ്റാ കൂടുതല്\u200d കൂടുതല്\u200d വിവരങ്ങള്\u200d കൂ എല്ലാ ജോലികള്\u200dക്കും വേണ്ടി നമ്മുടെ കീഴ്പ്പെടുത്തിവെക്കുന്നത് വളരെ നല്ല ഫലമാണ്.', 'mt': 'Dan id-dokument jippreżenta x-xogħol tagħna fil-QE tal-Istima tal-Kwalità (WMT 2021). Parteċipajna fit-tliet sottokompiti kollha, inkluż il-kompitu ta’ Valutazzjoni Diretta tal-Livell tas-Sentenza (DA), il-kompitu ta’ Sforz ta’ Wara l-Edizzjoni tal-Livell tal-Kliem u tas-Sentenza u l-kompitu ta’ Detezzjoni ta’ Żbalji Kritiċi, fil-pari lingwistiċi kollha. Is-sistemi tagħna jużaw il-qafas tal-Estimatur-Predikatur, b’mod konkret ma’ XLM-Roberta mħarrġa minn qabel bħala Predikatur u klassifikatur jew rigressur speċifiku għall-kompiti bħala Estimatur. Għall-kompiti kollha, aħna ntejbu s-sistemi tagħna billi ninkorporaw sentenza ta’ wara l-edizzjoni jew sentenza addizzjonali ta’ traduzzjoni ta’ kwalità għolja fil-mod ta’ tagħlim multikompiti jew billi nkodifikawha direttament ma’ predikaturi. Moreover, in zero-shot setting, our data augmentation strategy based on Monte-Carlo Dropout brings up significant improvement on DA sub-task.  B’mod notevoli, is-sottomissjonijiet tagħna jiksbu riżultati notevoli fuq il-kompiti kollha.', 'mn': 'Энэ цаас WMT 2021-ийн сайн талаар (QE) хуваалцагдсан ажил дээр ажилладаг. Бид бүх гурван суб-даалгаварт оролцсон, өгүүлбэр-түвшин шууд оценка (DA) ажил, үг, өгүүлбэр-түвшин дараа-редактирэх үйл ажиллагаа, Critical Error Detection ажиллагаа, бүх хэл хоорондоо оролцсон. Бидний систем Predictor-Estimator-ын хөрөнгө оруулалт ашигладаг. Мөн өмнө сургалтын XLM-Roberta-г Predictor, task-specific classifier эсвэл regressor-г Estimator гэдэг. Бүх ажлын хувьд бид системийг олон ажлын суралцах эсвэл таамаглаачидтай шууд кодлох аргаар нэмэгдүүлэх үг эсвэл хамгийн өндөр чанартай хөрөнгө өгүүлэх үг бий болгож сайжруулдаг. Мөн тэгш шалгалт дээр Монте-Карло Дропут-ын үндсэн өгөгдлийн нэмэгдүүлэлтийн стратеги нь ДНХ-ын суб-ажил дээр маш чухал сайжруулалт гаргадаг. Үнэндээ бидний хүлээн зөвшөөрөл бүх ажил дээр гайхалтай үр дүн гардаг.', 'ro': 'Această lucrare prezintă activitatea noastră în activitatea partajată de estimare a calității WMT 2021 (QE). Am participat la toate cele trei subsarcini, inclusiv activitatea de evaluare directă la nivel de sentință (DA), activitatea efort post-editare la nivel de Word și sentință și activitatea de detectare a erorilor critice, în toate perechile de limbi. Sistemele noastre utilizează cadrul Predictor-Estimator, concret cu un XLM-Roberta pre-instruit ca Predictor și clasificator specific sarcinii sau regresor ca Estimator. Pentru toate sarcinile, îmbunătățim sistemele noastre prin încorporarea propoziției post-editare sau a propoziției de traducere suplimentare de înaltă calitate în modul de învățare multitask sau codificarea directă a acesteia cu predictori. Mai mult decât atât, în setarea zero-shot, strategia noastră de augmentare a datelor bazată pe Monte-Carlo Dropout aduce îmbunătățiri semnificative în ceea ce privește subsarcina DA. În special, depunerile noastre obțin rezultate remarcabile în toate sarcinile.', 'mk': 'Овој весник ја претставува нашата работа во заедничката задача за проценка на квалитетот на WMT 2021. We participated in all of the three sub-tasks, including Sentence-Level Direct Assessment (DA) task, Word and Sentence-Level Post-editing Effort task and Critical Error Detection task, in all language pairs.  Нашите системи ја користат рамката на предвидувач-проценувач, конкретно со предобучена XLM-Roberta како предвидувач и класификатор или регресор специфичен за задачи како проценувач. За сите задачи, ги подобруваме нашите системи со вклучување на пост-уредувачката реченица или дополнителна висококвалитетна реченица за превод на начинот на учење на мултизадачи или кодирање со директни предвидувачи. Moreover, in zero-shot setting, our data augmentation strategy based on Monte-Carlo Dropout brings up significant improvement on DA sub-task.  Notably, our submissions achieve remarkable results over all tasks.', 'no': 'Denne papiret viser arbeidet vårt i WMT 2021- kvalitetevaluering (QE) delt oppgåve. Vi delta i alle tre underoppgåvene, inkludert rett oppgåve for setningsnivå (DA), ordet og setningsnivå etter redigering av effektoppgåve og kritisk feiloppgåve, i alle språkopla. Sistemet våre bruker rammeverket til Predictor-Estimator, samtidig med ein først treng XLM-Roberta som Predictor og oppgåvespesifikke klassifiserer eller regressor som Estimator. For alle oppgåver er vi forbetra systemet våre ved å inkludere setningar etter redigering eller ekstra omsetjingar med høg kvalitet på måte å læra fleire oppgåver eller koda det med foregåver direkte. I tillegg til nullsatt, har vårt dataaugmentasjonsstrategi basert på Monte-Carlo Dropout oppretta signifikante forbedringar på underoppgåva av DA. I tillegg er søknadene våre oppnår merkelige resultat over alle oppgåver.', 'pl': 'Niniejszy artykuł prezentuje naszą pracę w zakresie wspólnego zadania WMT 2021 Quality Estimation (QE). Uczestniczyliśmy we wszystkich trzech podzadaniach, w tym w zadaniu bezpośredniej oceny zdań na poziomie zdań (DA), zadaniu wysiłku po edycji słów i zdań na poziomie zdań oraz zadaniu krytycznego wykrywania błędów, we wszystkich parach językowych. Nasze systemy wykorzystują framework Predictor-Estimator, konkretnie z wstępnie przeszkolonym XLM-Roberta jako Predictor i specyficzny klasyfikator lub regressor jako Estimator. Dla wszystkich zadań ulepszamy nasze systemy, włączając zdanie post-edycyjne lub dodatkowe wysokiej jakości zdanie tłumaczeniowe w sposób wielozadaniowego uczenia się lub kodowania go bezpośrednio z predyktorami. Ponadto w ustawieniu zero-shot nasza strategia powiększania danych oparta na Monte-Carlo Dropout przynosi znaczącą poprawę podzadania DA. W szczególności nasze zgłoszenia osiągają niezwykłe rezultaty we wszystkich zadaniach.', 'sr': 'Ovaj papir predstavlja naš rad u procjeni kvalitete WMT 2021 (QE) zajedničkog zadatka. Učelili smo u svim tri podzadatka, uključujući zadatak direktne procjene na nivou kazne (DA), zadatak, zadatak za posteditanje reči i reči na nivou kazne i zadatak za otkrivanje kritičnih grešaka, u svim jezičkim parovima. Naši sistemi upotrebljavaju okvir predsednika-procenatora, konkretno sa predobučenim XLM-Robertom kao predsednikom i klasifikatorom ili regressorom za određene zadatke kao procenator. Za sve zadatke, poboljšavamo naše sisteme uključujući rečenicu nakon editiranja ili dodatnu rečenicu za prevod kvalitete na način učenja multitask ili kodiranja ga direktno sa predvidatorima. Osim toga, u postavljanju nule pucnjave, naša strategija povećanja podataka na osnovu Monte-Carlo Dropout donosi značajno poboljšanje na podzadatku tužioca. Naravno, naši podaci postižu izvanredni rezultat svih zadataka.', 'ta': 'இந்த தாள் WMT 2021 தரம் கணக்கீடு (QE) பகிர்ந்த பணியில் எங்கள் வேலையை அளிக்கிறது. வாக்கியம்- மட்டத்தை நேரடி மதிப்பு (DA) செயல், வாக்கியம் மற்றும் வாக்கியம்- நிலை பின்தொகுப்பு முயற்சி பணி மற்றும் சுக்கியமான பிழை கண்டுபிடிப்பு பணியில எங்கள் அமைப்புகள் முன் பயிற்சி XLM-ராப்டாவின் சட்டத்தை எஸ்டிமேட்டராக அல்லது சில வகுப்பாளராக இருக்கும். அனைத்து பணிகளுக்கும், நாம் எங்கள் கணினிகளை மேம்படுத்துகிறோம் பின்தொகுப்பு வாக்கியத்தை அல்லது அதிக உயர்தரமான மொழிபெயர்ப்பு வாக்கியத்தை  மேலும், பூஜ்ஜியத்தில், மோண்ட்-கார்லோ ட்ரோப்புட் அடிப்படையில் எங்கள் தரவு மேம்படுத்தல் திட்டம் முக்கியமான முன்னேற்றம் DA குறிப்பிட்டு, எங்கள் கட்டளைகள் அனைத்து பணிகளுக்கும் மிகவும் பெரிய முடிவுகள் பெறுகிறது.', 'si': 'මේ පැත්තේ WMT 2021 විශේෂතාව අනුමාණය (QE) කොටස් වැඩේ අපේ වැඩ පෙන්වනවා. අපි සාමාන්\u200dය වැඩක් තුනක් සාමාන්\u200dය ව්\u200dයාපෘතියෙන් සම්බන්ධ වැඩක් කරනවා, වාර්තාව සහ වාර්තාව සම්බන්ධ වැඩක් සහ සාමාන්\u200dය භාෂාව සම්බන්ධ වැ අපේ පද්ධතියේ ප්\u200dරධානකර්ෂකය-ස්ටිමේටර්ගේ පරීක්ෂකය සමග ප්\u200dරධානකර්ශකයෙන් ප්\u200dරධානකර්ශකයෙන් විශේෂකයෙන් ප්\u200dරධානකර්ශකය සියළු වැඩ සඳහා, අපි අපේ පද්ධතිය පස්සේ සංපාදනය සඳහා වාර්තාවක් සම්බන්ධ කරනවා නැත්තම් වාර්තාවක් සඳහා වාර්තාවක් ස ඒ වගේම, ශුන්වර්ධ වෙඩි තියෙන්නේ අපේ දත්ත විශාලනය විදිහට, මොන්ට්-කාර්ලෝ ඩ්\u200dරොපුට් විසින් අපේ දත්ත විශ අනිවාර්යෙන්ම, අපේ පිළිගන්න විශේෂ ප්\u200dරතිචාරයක් හැම වැඩක්ම විසින් ප්\u200dරතිචාර ප්\u200dරති', 'so': 'Qoraalkan wuxuu keenaa shaqadeenna ku qoran WMT 2021 Qiimaynta qiimaynta (QE) ee la sharciyey shaqo. Shaqooyinkaas oo dhan waxaan ka qeybqaaday saddexda sub-marin, kuwaas oo ah shaqada heerka-Level Direct Assessta (DA), hadalka iyo Sense-Level post-editing efforts and Critical Error Detection mission, in all language pairs. nidaamkayagu waxay u shaqeeyaan saqafka madax-Estimator, si la mid ah XLM-Roberta oo ah madax-u-tababar iyo fasax gaar ah ama regressor. Shaqooyinka oo dhan waxaan ku hageynaa nidaamka si toos ah ugu qoraynaa qoraalka dib-editidda ama qoritaanka turjumista sare oo kale. Sidoo kale qoraalkayaga koritaanka ee macluumaadkayagu waxay ku saleysan Monte-Carlo Dropout wuxuu kordhin karaa si muhiim ah oo u kordhiya xafiiska DA. Xasuusyadeennu waxay heli karaan matooyin yaab leh oo ku saabsan shuqullada oo dhan.', 'sv': 'Denna uppsats presenterar vårt arbete i WMT 2021 Quality Estimation (QE) Shared Task. Vi deltog i alla de tre underuppgifterna, inklusive meningsnivå direkt bedömning (DA), ord- och meningsnivå efterredigering ansträngning aktivitet och kritisk felupptäckt uppgift, i alla språkpar. Våra system använder ramen för Predictor-Estimator, konkret med en förkunskaps XLM-Roberta som Predictor och uppgiftsspecifik klassificerare eller regressor som Estimator. För alla uppgifter förbättrar vi våra system genom att införliva post-edit mening eller ytterligare högkvalitativ översättning mening i vägen för multitasking lärande eller koda den med prediktorer direkt. Dessutom ger vår dataförstärkningsstrategi baserad på Monte-Carlo Dropout en betydande förbättring av DA-underuppgiften i nollskott. Framförallt uppnår våra bidrag anmärkningsvärda resultat över alla uppgifter.', 'ur': 'یہ کاغذ ہمیں WMT 2021 کیلوٹی آسانی (QE) شریک ٹاکس میں ہمارا کام دکھاتا ہے۔ ہم نے تمام تین sub-tasks میں شامل ہوا، Sentence-Level Direct Assessment (DA) task, Word and Sentence-Level Post-editing Effort task and Critical Error Detection task, in all languages pairs. ہماری سیستمات پردیکتور-اسٹیموٹر کے فرم استعمال کرتی ہیں، ایک پیش آموزش کی XLM-رابرٹا کے ساتھ ایک پردیکتور اور کام-خاصی کلاسیٹر یا ریگرس کا استعمال کرتا ہے۔ تمام کاموں کے لئے، ہم اپنے سیسٹم کو بہتر کر رہے ہیں، پیچھے ویڈیٹ جماعت یا اضافہ عالی کیفیت ترجمہ جماعت کے ذریعے multitask سیکھنے یا اسے پیش بینی کرنے والوں کے ساتھ سیدھے سیدھے انداز کرنے کے ذریعے. اس کے علاوہ، صفر-شٹ تنظیم میں، مونٹ-کارلو ڈروپوٹ پر بنیاد ہماری ڈیٹا اضافہ استراتژی ہے، ڈی آ سو-ٹاکس پر اضافہ کرتا ہے. یقیناً ہماری مسلمانوں کو ہر کام پر بڑے نتیجے پہنچ سکتے ہیں۔', 'uz': "Bu qogʻoz bizning vazifani boʻlishilgan WMT 2021 Quality Estimatsiya (QE) bilan ishni koʻrsatiladi. Biz har uchta sub-vazifalarga hamma vazifalarga qiymatga ega boʻlgan, har bir tillar soni va maxfiy soʻzni tahrirlash vazifasini va qiymati xato qidirish vazifasini hamma tillar sohasida qayta boʻlgan. Bizning tizimlarimiz Predictor-Estimator chegarasini boshlaydi, birinchi o'rganilgan XLM-Roberta, Predikator va vazifani tayyorlash va boshqaruvchisi Estimator deb ishlaydi. Hamma vazifalar uchun biz tizimimizni tahrirlash keyingi soʻzni yoki multitask o'rganish yoki tahrirlash orqali o'rganishni ko'proq kodlash orqali qoʻshish mumkin. Ko'rsatganda, Monte-Carlo Dropout asosida ma'lumotni qo'shish strategimiz Ko'rib, bizning imkoniyatlarimiz hamma vazifalar haqida ajoyib natijalarini bajaradi.", 'vi': 'Tờ giấy này trình bày công việc của chúng ta trong WM 2021 Name Chúng tôi đã tham gia vào tất cả các công việc phụ, bao gồm nhiệm vụ Bộ đánh giá trực tiếp Đường Câu, Công cụ Từ và Cấp Đọc Đọc Từ, Nhiệm vụ trinh sát lỗi quan trọng, trong mọi cặp ngôn ngữ. Hệ thống của chúng tôi sử dụng hệ thống định giá, cụ thể với loại chưa được đào tạo XLM-Roberta như Predator và chuyên gia phân loại đặc nhiệm, hay thụt lùi như Essửa. Với tất cả các công việc, chúng ta cải thiện hệ thống bằng việc thêm câu lệnh sau biên bản hay câu dịch chất chất cao thêm để có thể học tập đa nhiệm vụ hay mã hóa nó với người dự đoán trực tiếp. Hơn nữa, trong môi trường quay bằng không, chiến lược gia tăng dữ liệu dựa trên vụ Monte-Carlo từ bỏ mang tới một tiến bộ quan trọng về việc phân công tố. Tài liệu của chúng tôi đạt được kết quả đáng chú ý trong mọi nhiệm vụ.', 'bg': 'Настоящата статия представя нашата работа по Споделена задача за оценка на качеството (Оценка на качеството). Участвахме във всичките три подзадачи, включително задачата за директна оценка на ниво изречение, задачата за усилие след редактиране на думи и изречение и задачата за откриване на критични грешки, във всички езикови двойки. Нашите системи използват рамката на Предсказател-Оценител, конкретно с предварително обучен като Предсказател и специфичен за задачата класификатор или регресор като Оценител. За всички задачи подобряваме системите си чрез включване на изречение след редактиране или допълнително висококачествено преводно изречение в начина на многозадачно обучение или кодиране директно с предсказатели. Освен това, при настройка на нулев изстрел, нашата стратегия за увеличаване на данните, базирана на Монте Карло отпадане, води до значително подобрение на подзадачата ДА. По-специално, нашите предложения постигат забележителни резултати при всички задачи.', 'hr': 'Ovaj papir predstavlja naš rad u procjeni kvalitete WMT 2021 (QE) zajedničkog zadatka. Učestvovali smo u svim tri podzadatka, uključujući zadatak direktne procjene na razini kazne (DA), zadatak, zadatak za posteditanje snage i kritične otkrivanje grešaka na svim jezičkim parovima. Naši sustavi upotrebljavaju okvir predsjednika-procjenjivača, konkretno s predobučenim XLM-Robertom kao predsjednik i klasifikator ili regressor specifičnih zadataka kao procjenjivač. Za sve zadatke, poboljšavamo naše sustave uključujući nakon redakcije rečenicu ili dodatnu presudu za prevod visokokvalitete na način učenja multizadataka ili kodiranja ga direktno sa predvidjetnicima. Osim toga, u postavljanju nule pucnjave, naša strategija povećanja podataka na temelju Monte-Carlo Dropout donosi značajno poboljšanje na podzadatku tužioca. U svakom slučaju, naši podaci postignu izvanredne rezultate nad svim zadacima.', 'da': 'Dette papir præsenterer vores arbejde i WMT 2021 Quality Estimation (QE) Shared Task. Vi deltog i alle de tre underopgaver, herunder Sætningsniveau Direkte Vurdering (DA), Word og Sætningsniveau Efterredigering Indsatsopgave og Critical Error Detection opgave, i alle sprogpar. Vores systemer anvender rammerne af Predictor-Estimator, konkret med en forududdannet XLM-Roberta som Predictor og opgavespecifik klassificering eller regressor som Estimator. For alle opgaver forbedrer vi vores systemer ved at indarbejde post-edit sætning eller yderligere høj kvalitet oversættelse sætning i måden at multitask lære eller kode det direkte med forudsigere. Desuden bringer vores datastørrelsesstrategi baseret på Monte-Carlo Dropout betydelige forbedringer i forhold til DA-underopgaven. Især opnår vores indlæg bemærkelsesværdige resultater over alle opgaver.', 'nl': 'Dit document presenteert ons werk in WMT 2021 Quality Estimation (QE) Shared Task. We hebben deelgenomen aan alle drie de subtaken, waaronder de taak Direct Assessment (DA) op zinsniveau, de taak Post-editing op woord- en zinsniveau en de taak Critical Error Detection, in alle taalparen. Onze systemen maken gebruik van het framework van Predictor-Estimator, concreet met een voorgetrainde XLM-Roberta als Predictor en taakspecifieke classificator of regressor als Estimator. Voor alle taken verbeteren we onze systemen door post-edit zin of extra hoogwaardige vertaalzin op te nemen in de manier van multitask leren of deze direct te coderen met voorspellers. Bovendien brengt onze strategie voor gegevensvergroting op basis van Monte-Carlo Dropout, in zero-shot setting, een aanzienlijke verbetering op het gebied van DA sub-task. Met name onze inzendingen behalen opmerkelijke resultaten bij alle taken.', 'de': 'Dieses Papier stellt unsere Arbeit in WMT 2021 Quality Estimation (QE) Shared Task vor. Wir haben an allen drei Teilaufgaben teilgenommen, einschließlich der Aufgabe "Direkte Bewertung auf Satz-Ebene" (DA), der Aufgabe "Nachbearbeitung auf Wort- und Satz-Ebene" und der Aufgabe "Kritische Fehlererkennung", in allen Sprachpaaren. Unsere Systeme verwenden das Framework des Predictor-Estimator, konkret mit einem vortrainierten XLM-Roberta als Predictor und aufgabenspezifischem Klassifikator oder Regressor als Estimator. Für alle Aufgaben verbessern wir unsere Systeme, indem wir Post-Edit-Sätze oder zusätzliche hochwertige Übersetzungssätze im Wege des Multitask-Lernens integrieren oder direkt mit Prädiktoren kodieren. Darüber hinaus bringt unsere auf Monte-Carlo Dropout basierende Data Augmentation-Strategie im Zero-Shot-Setting eine deutliche Verbesserung der DA-Teilaufgaben. Besonders hervorzuheben ist, dass unsere Einreichungen bei allen Aufgaben bemerkenswerte Ergebnisse erzielen.', 'fa': 'این کاغذ کار ما را در ارزیابی کیفیت WMT 2021 (QE) مشترک می\u200cکند. ما در تمام سه وظیفه\u200cای شرکت کردیم، شامل تحقیقات مستقیم مرحله\u200cی سخنرانی، کلمه\u200cها و سطح\u200cهای سخنرانی بعد از ویرایش کوشش\u200cهای کوشش و شناسایی خطای کریتیک، در هر جفت زبان. سیستم\u200cهای ما چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهار را استفاده می\u200cکنند، با یک XLM-Roberta پیش آموزش آموزش شده، به عنوان پیش آموزش\u200cکننده و کلاس\u200cکننده\u200cی مشخص کار یا برای همه کار، سیستم\u200cهایمان را با توجه به جمله بعد از ویرایش یا ترجمه\u200cهای زیادی از کیفیت بیشتری در راه یادگیری چندین کار یا رمزبندی با پیش\u200cبینی\u200cها بهتر می\u200cکنیم. علاوه بر این، در تنظیمات صفر، استراتژی افزایش داده\u200cهای ما بر اساس مونت کارلو درپوت، بهترین شدید در زیر کار داده\u200cی داده\u200cی داده\u200cای را پیش می\u200cدهد. مخصوصاً تسلیم کردن ما نتیجه فوق العاده ای بر روی همه کارها رسیده اند.', 'id': 'Kertas ini memperkenalkan pekerjaan kami di WMT 2021 Quality Estimation (QE) Shared Task. Kami berpartisipasi dalam semua tiga sub-tugas, termasuk tugas Penilaian Langsung Tingkat-hukuman (DA), tugas Perkataan dan Tingkat-hukuman Setelah Menyunting Effort dan tugas Deteksi Kesalahan Kritis, dalam semua pasangan bahasa. Sistem kami menggunakan cadangan Predictor-Estimator, secara konkret dengan XLM-Roberta terlatih sebelumnya sebagai Predictor dan task-specific classifier atau regressor sebagai Estimator. Untuk semua tugas, kita memperbaiki sistem kita dengan memasukkan kalimat pos-edit atau kalimat terjemahan berkualitas tinggi tambahan dalam cara belajar multitugas atau merekodikannya dengan prediksor langsung. Selain itu, dalam seting zero-shot, strategi peningkatan data kita berdasarkan Monte-Carlo Dropout membawa peningkatan signifikan pada sub-tugas DA. Notably, our submissions achieve remarkable results over all tasks.', 'sw': 'Gazeti hili linaonyesha kazi zetu katika Uwango wa WMT 2021 (QE) Kushirikiana na kazi zetu. Tumeshiriki katika juhudi zote hizi tatu, ikiwa ni pamoja na jukumu la Utafiti wa moja kwa moja la Sentena (DA), Neno na Hatari za Uhariri baada ya Sentensi na Tambulisho la Tatizo la Kikosi, kwa viwili vyote vya lugha. Mfumo wetu unatumia mfumo wa Mbunge wa Mbunge, na kwa ujumla wa XLM-Roberta kama Mkurugenzi na mfanyakazi maalum wa kazi au mkandaji. Kwa kazi zote, tunaboresha mifumo yetu kwa kuingiza hukumu baada ya kuhariri au hukumu ya tafsiri yenye sifa kubwa kwa njia ya kujifunza au kuingiza kwa watabiri moja kwa moja. Zaidi ya hayo, katika mazingira yasiyo ya risasi, mkakati wetu wa kuongeza takwimu kwa msingi wa Monte-Carlo Dropout unaleta maboresho makubwa kwenye kazi ya DA. Tafadhali, ujumbe wetu hupata matokeo mazuri juu ya kazi zote.', 'af': "Hierdie papier stel ons werk in WMT 2021 Kwaliteit Estimation (QE) Gedeelde Taak voorsien. Ons het gedeel in al die drie sub-taak, insluitend Sentence-Vlak Direkte Assensie (DA) taak, Woord en Sentence-Vlak Post-redigering Effort taak en Kritiese Fout Opdekking taak, in alle taal paar. Ons stelsels gebruik die raamwerk van Predictor-Estimator, saamstig met 'n voor-onderwerp XLM-Roberta as Prediktor en taak-spesifieke klassifiseerder of regressor as Estimator. Vir alle opdragte, ons verbeter ons stelsels deur post-redigeer seting of addisionele hoë-kwaliteit vertaling seting in die manier van multitaak leer of kodering dit met voorskouers direk te inkorporeer. Ook, in nul-skoot opstelling, ons data-augmentasie strategie gebaseer op Monte-Carlo Dropout bring betekende verbetering op DA-subtaak op. Notief, ons onderwyselinge verkry merkelike resultate oor alle werke.", 'tr': "Bu käze WMT 2021-iň Quality Taýýarlama (QE) Mazmunlarymyzy aýdýar. Biz bu üç sub-zadyň hemmesine (DAA) zady, sözler we sözler-derejesi beýik edip duran Sözgüt we Kritik Hata tanamasynda dahil etdik. Bizim sistemlerimiz Prediktor-Taýýarlançylaryň çerçevesini hem öň-bilinmiş XLM-Roberta bir Prediktor we Taýýarlyk spesifikaly klassifikatçy ýa-da regressor hökmünde ulanýarlar. Hemme zadymyz üçin sistemamyzy ediň soňra sözläni ýa-da üstin-kaliwatly terjime sözläni multi-täbli öwrenmek ýa-da öwrenmekçiler bilen kodlaýän şeklinde geliştirip ýöredirik. Mundan soňra, Monte-Carlo Dropout'a daýanýan maglumatlarymyz ýüklemek strategiýasynda DA sub-işinde möhüm gelişmeleri gowuraýar. Adatça, biziň teslimatlarymyz hemme zadyň üstünde örän möhüm netijelerini ýetirýär.", 'sq': 'Ky artikull paraqet punën tonë në WMT 2021 Quality Estimation (QE) Task Shared. Ne morëm pjesë në të gjitha tre nëndetyrat, duke përfshirë detyrën e vlerësimit të drejtpërdrejtë të nivelit të dënimit (DA), detyrën e nivelit të fjalëve dhe dënimeve pas redigimit të përpjekjeve dhe detyrën e zbulimit të gabimeve kritike, në të gjitha palët gjuhësh. Sistemet tona përdorin kuadrin e parashikuesit-vlerësimit, konkretisht me një XLM-Roberta të paratrajnuar si parashikues dhe klasifikues specifik të detyrave apo regresor si parashikues. Për të gjitha detyrat, ne përmirësojmë sistemet tona duke përfshirë fjalën pas editimit ose fjalën shtesë të përkthimit të cilësisë së lartë në mënyrën e mësimit të shumëdetyrave apo kodimit të saj me parashikuesit drejtpërdrejt. Përveç kësaj, në vendosjen zero-shot, strategjia jonë e rritjes së të dhënave bazuar në Monte-Carlo Dropout sjell përmirësim të rëndësishëm në nëndetyrën e prokurorit. Në mënyrë të veçantë, paraqitjet tona arrijnë rezultate të çuditshme mbi të gjitha detyrat.', 'am': 'ይህም ገጽ በWMT 2021 ብጤት ቁጥር (QE) የተሰራጨውን ስራ ያሳያል፡፡ በቋንቋዎች ሁሉ ውስጥ የስርዓት-ደረጃን አቀናመጥ (DA) ስራ፣ ቃላት እና የስርዓት-ደረጃ በኋላ አስተካክል ጥያቄ እና የስህተት ስህተት ማግኘት ስራ እና የስህተት ስህተት ስርዓት እና በቋንቋዎች ሁሉ ሁለት ሲስተምሮቻችን የፕሬዚደር-አስታማሚ ፍሬሽን፣ አስቀድሞ ተማሪ XLM-Roberta እንደ ፕሬዚደር እና የስራ ክፍል መፍጠር ወይም አስተዳደር እንደ አስቲማቴር ነው፡፡ ለሁሉም ስራ፣ የፖስቲካ ክፍል ወይም በብዙ ትርጉም ትምህርት እናስተምር ወይም ከመቀናቢዎች ጋር አካባቢዎችን እናሳውቃለን፡፡ ከዚህም በላይ በክፍል በተደረገ፣ በMonte-Carlo Dropout ላይ የተመሳሳይ የዳርዮችን አካባቢ strategy በዲ አ.አ.አ. በተጨማሪም፣ የስራ ሁሉ ፍሬዎችን አግኝቷል፡፡', 'ko': '본고는 WMT 2021 품질평가(QE) 공유 임무에서의 업무를 소개한다.우리는 문장 수준의 직접 평가(DA) 임무, 단어와 문장 수준의 편집 후 노력 임무와 관건적인 오류 검출 임무를 포함한 세 가지 하위 임무에 모든 언어 대조에서 참여했다.우리 시스템은 예측-추정기의 구조를 채택했는데 구체적으로 말하면 미리 훈련된 XLM-roberta를 예측기로 하고 임무에 특정한 분류기나 회귀기를 추정기로 한다.모든 임무에 대해 우리는 다중 임무 학습을 하거나 예측기를 직접 사용하여 시스템을 인코딩하는 방식으로 편집된 문장이나 별도의 고품질 번역 문장을 추가하여 시스템을 개선합니다.또한 제로포 설치에서 몬테카로의 학업을 중지한 데이터 확충 전략을 바탕으로 DA자 임무를 현저히 개선했다.주의해야 할 것은 우리의 의견서가 모든 임무에서 현저한 성과를 거두었다는 것이다.', 'hy': "Այս հոդվածը ներկայացնում է մեր աշխատանքը 2021 թվականի համագործակցած աշխատանքի որակի գնահատման մեջ: Մենք մասնակցեցինք բոլոր երեք ենթախնդիրներին, ներառյալ նախադասությունների մակարդակի ուղղակի գնահատման (DA) խնդիրը, բառերի և նախադասությունների մակարդակի հետխմբագրման խնդիրը և կարևոր սխալների հայտնաբերման խնդիրը, բոլոր լեզվի զույգերում: Մեր համակարգերը օգտագործում են նախատեսողի-գնահատողի կառուցվածքը, հատկապես նախապատրաստված XLM-Ռոբերտայի հետ որպես նախատեսողի և խնդիրների հատուկ դասակարգիչ կամ ռեգրեսոր որպես գնահատողի: Բոլոր առաջադրանքների համար մենք բարելավում ենք մեր համակարգերը' ներառելով հետխմբագրման նախադասությունը կամ ավելին բարձր որակի թարգմանման նախադասությունը բազմախնդիրների ուսումնասիրության կամ անմիջապես կոդավորելով այն կանխատեսողների հետ: Ավելին, զրոյական նկարների ընթացքում, մեր տվյալների բարձրացման ռազմավարությունը, հիմնված Մոնտե-Կարլո Դրոպուտի վրա, առաջացնում է նշանակալի բարելավում DA-ի ենթախնդիրների վրա: Անշուշտ, մեր ներկայացումները հասնում են բոլոր խնդիրների ընթացքում արտահայտված արդյունքների:", 'bs': 'Ovaj papir predstavlja naš rad u procjeni kvalitete WMT 2021 (QE) zajedničkog zadatka. Učestvovali smo u svim tri podzadatka, uključujući zadatak direktne procjene na nivou kazne (DA), zadatak riječi i posledišnji zadatak za posteditanje napora na nivou kazne i zadatak za otkrivanje kritičnih grešaka, u svim jezičkim parovima. Naši sistemi upotrebljavaju okvir predsjednika-procenatora, konkretno sa predobučenim XLM-Robertom kao predsjednik i klasifikator ili regressor za određene zadatke kao procenator. Za sve zadatke, poboljšavamo naše sisteme uključujući rečenicu nakon editiranja ili dodatnu presudu za prevod visokokvalitete na način učenja multitask ili kodiranja ga direktno sa predvidjetnicima. Osim toga, u postavljanju nule pucnjave, naša strategija povećanja podataka na temelju Monte-Carlo Dropout donosi značajno poboljšanje na podzadatku tužioca. U svakom slučaju, naši podaci postignu izvanredne rezultate nad svim zadacima.', 'cs': 'Tento článek představuje naši práci v oblasti WMT 2021 Quality Estimation (QE) Shared Task. Účastnili jsme se všech tří dílčích úkolů, včetně úkolu přímého hodnocení na úrovni vět (DA), úkolu úsilí o post-editaci na úrovni slov a vět a úkolu detekce kritických chyb, ve všech jazykových párech. Naše systémy využívají rámec Predictor-Estimator, konkrétně s předškoleným XLM-Robertou jako Predictor a úlohově specifický klasifikátor nebo regressor jako Estimator. Pro všechny úkoly zlepšujeme naše systémy začleněním post-editační věty nebo další kvalitní překladové věty způsobem víceúlohového učení nebo jejího kódování s prediktory přímo. Naše strategie rozšíření dat založená na Monte-Carlo Dropout navíc v nastavení nulového výstřelu přináší výrazné zlepšení podúkolu DA. Především naše příspěvky dosahují pozoruhodných výsledků u všech úkolů.', 'ca': "Aquest paper presenta la nostra feina en la tasca compartida d'estimació de qualitat (QE) de WMT 2021. Vam participar en totes les tres sub-tasques, incloent la tasca d'Evaluació Directa de Livell de Sentences (DA), la tasca d'esforç post-edició de nivell de paraules i sentences i la tasca de detecció d'errors crítics, en tots els parells de llengües. Els nostres sistemes emplenen el marc de Predictor-Estimator, concretament amb una XLM-Roberta pré-entrenada com Predictor i una classificadora o regressor a específica per tasca com Estimator. Per a totes les tasques, millorem els nostres sistemes incorporant frases post-edicions o frases adicionals de traducció d'alta qualitat a la manera d'aprendre multitasques o codificar-lo directament amb preditors. A més, en un entorn de fotografies zero, la nostra estratègia de augment de dades basada en Monte-Carlo Dropout provoca una millora significativa en la subtasca del DA. Notablement, les nostres presentacions aconsegueixen resultats notables en totes les tasques.", 'az': "Bu kağıt WMT 2021 Nəbəti Görüntüləri (QE) paylaşılan işlərimizi göstərir. Bütün dil çiftlərdə, sözlər-seviyyəti Direkt Assessment (DA) işləri, Sözü və Sözü-seviyyəti İşləndirmək və Kritik Hata Tapma işləri dahil etdik. Bizim sistemlərimiz Prediktor-Estimator'un çerçevesini, əvvəlcə təhsil edilmiş XLM-Roberta ilə Prediktor və Task-specific klasifikatçı və regressor olaraq istifadə edir. Bütün işlər üçün sistemlərimizi çoxlu işlər öyrənməsi və ya öndəyicilərlə birlikdə kodlama yolunda çoxlu işlər öyrənməsi üçün çoxlu qiymətli cümləmi və daha yüksək qiymətli tercümə cümləsini birləşdirərək yaxşılaşdırırıq. Əksinə, sıfır-fəsad tərzində, Monte-Carlo Dropout vasitəsilə verilən məlumat artırma stratejimiz DA sub-task üzərində böyük bir xeyir artırar. Əlbəttə, müsəlmanlarımız bütün işlərin üstündə möhtərəm sonuçlarına nail olur.", 'bn': 'এই পত্রিকাটি উইএমটি ২০২১-এ আমাদের কাজের উপস্থাপন করেছে (কিউই) শেয়ার করা কাজ শেয়ার করেছে। সকল সাব-কাজের মধ্যে আমরা অংশগ্রহণ করেছি, যার মধ্যে সেন্স-স্তর সরাসরি মিস্টেম (ডিএ) কাজ, শব্দ এবং শাস্তি-স্তর পর্যন্ত সম্পাদনার প্রচেষ্টা এবং গুরুত্বপূর্ণ সমস্য আমাদের সিস্টেম প্রেসিডেক্টর-এস্টিমেটরের ফ্রেক্কার চালিয়ে যাচ্ছে, নিশ্চিতভাবে পূর্ব প্রশিক্ষিত এক্সএলএম-রবার্টা প্রেসিডেক্টর এবং  সকল কাজের জন্য আমরা আমাদের সিস্টেম উন্নত করি পোস্ট সম্পাদনের বাক্য বা বহুটিশিক্ষা শিক্ষা কিংবা প্রত্যেক ভবিষ্যদ্বাণীদের সাথে সরাসরি প্রতিব এছাড়াও, শূন্য গুলি ব্যবস্থায়, মোন্ট কার্লো ড্রোপআউটের ভিত্তিতে আমাদের তথ্য বাড়ানোর কৌশল তৈরি করা হয়েছে ডিএডিএ সাব কা অবশ্যই, আমাদের আত্মসমর্পণ সকল কাজের উপর চমৎকার ফলাফল অর্জন করে।', 'et': 'Käesolevas artiklis tutvustatakse meie tööd WMT 2021 kvaliteedi hindamise (QE) jagatud ülesandes. Osalesime kõigis kolmes alamülesandes, sealhulgas lausetaseme otsehindamise ülesandes (DA), sõna- ja lausetaseme järeltöötlemisülesandes ning kriitiliste vigade tuvastamise ülesandes, kõigis keelepaarides. Meie süsteemid kasutavad ennustaja-estimaatori raamistikku, konkreetselt eelkoolitud XLM-Roberta ennustajana ja ülesandespetsiifilist klassifitseerijat või regressorit hindajana. Kõigi ülesannete puhul täiustame oma süsteeme, lisades mitme ülesandega õppimiseks järgneva redigeerimisjärgse lause või täiendava kvaliteetse tõlke lause või kodeerides selle otse ennustajatega. Pealegi toob meie Monte-Carlo loobumisel põhinev andmete suurendamise strateegia null-shot seadistuses kaasa märkimisväärse arengu DA alamülesandes. Eelkõige saavutavad meie esitused märkimisväärseid tulemusi kõigi ülesannete puhul.', 'fi': 'Tämä artikkeli esittelee työtämme WMT 2021 Quality Estimation (QE) Shared Task -ohjelmassa. Osallistuimme kaikkiin kolmeen osatehtävään, mukaan lukien lausetason suora arviointi (DA), sana- ja lausetason jälkimuokkaustehtävä ja kriittisten virheiden tunnistus, kaikilla kielipareilla. Järjestelmämme käyttävät Predictor-Estimator-kehystä, konkreettisesti ennalta koulutetun XLM-Robertan ennustajana ja tehtäväkohtaisen luokittelijan tai regressorin estimaattorina. Kaikkiin tehtäviin parannamme järjestelmiämme sisällyttämällä jälkimuokkauslauseen tai ylimääräisen korkealaatuisen käännöksen lauseen monitehtäväoppimiseen tai koodaamalla sen suoraan ennustajilla. Lisäksi nollalaukauksessa Monte-Carlo Dropout -ratkaisuun perustuva datan lisäämisstrategiamme tuo merkittävää parannusta DA-alatehtävään. Erityisesti julkaisumme saavuttavat merkittäviä tuloksia kaikissa tehtävissä.', 'jv': "Ngerungkat-Ngerungkat kuwi nggawe uwis barêng nêmên ning werak-barêng, uwis Quality Awak dhéwé wis ngubah ning telu Sub-tasks, mulai Sentense-Grade directive assessment (Da) Sistem-sistem ain gunakake sistem sistem ning predikor-Esigator, sampeyan karo XLM-Robert padha iki prediktor karo prediktor karo task-special laser podho kelas Terus gak task, kita luwih sistem sing dibutuhke ditambah 'after-edit' seneng dadi supaya kang cuwih-kaliwat terjamahan ning maneh ya multitask Learn apa kode nggo Kebebasan layar. Mungkin daftar, iso nggambar nul-shot, dadi ampungasi sistem sing basa nang Mon-Karo DroPout iki dadi nggawe barang pengguna nggawe barang resmi SU Murak-warni, gungané kamulé sing dikarepaké barang iki dadi.", 'ha': "Wannan takardan na gauraya aikin mu a WMT 2021 Quality Kidar Taimation (QET) wanda aka Shara aiki. Mun yi rabo da duk aikin uku, kamar aikin Java-Lebba Directly Assaminta (DA), Kalma da Hazara-Lebba daga bayan editing da aikin na ƙori na Digita Mai Kirina, cikin duk harshe biyu. YafuyinMu ke amfani da firam na Predictor-Emimator, sami da wani mai zaman-mai amfani da XLM-Robbata kamar Predictor da mai ƙayyade wa aikin da ke zama Mai shirya. Ga duk aikin ƙwarai, za mu ƙara tsarinmu da za'a shigar da cewa na-edit-daban ko kuma mu haɗa salon sarrafa masu nau'i ga masu barar da multitaski ko kuma mu kodi shi tãre da mãsu bastarwa dira. Da haka, a cikin tsarin sifo-yin-shirka, zane-zane da za'a ƙara danganmu a kan mone-Karo-dropout ya ƙãga mafarinta mai girma a kan DA sub-aikin. Notably, our submissions achieve remarkable results over all tasks.", 'he': 'העיתון הזה מציג את עבודתנו במשימה משותפת של WMT 2021. השתתפנו בכל שלושת התפקידים, כולל משימת הערכה ישירה ברמה של גזרים, משימת מאמץ לאחר העורה של מילים ורמה של גזרים ובמשימת גילוי שגיאות קריטיות, בכל זוגות שפות. המערכות שלנו משתמשות במסגרת המערכת של Predictor-Estimator, במיוחד עם XLM-Roberta מאומנת מראש כPredictor וכמונה מסוימת למשימה או regressor כEstimator. לכל המשימות, אנחנו משתפרים את המערכות שלנו בכך שאנחנו מכילים משפט לאחר העורך או משפט תורגם איכות גבוהה נוספת בדרך ללמוד משימות רבות או לקוד אותו עם צפים ישירות. חוץ מזה, בסיס אפס-יריות, אסטרטגיה הזדמנות המידע שלנו מבוססת על מונט-קרלו דרופוט מביאה שיפור משמעותי בתפקיד התובע המחוזי. במיוחד, השיחות שלנו מגיעות לתוצאות מדהימות בכל המשימות.', 'sk': 'Ta prispevek predstavlja naše delo v skupni nalogi ocene kakovosti WMT 2021 (QE). Sodelovali smo pri vseh treh podnalogah, vključno z opravilom neposrednega ocenjevanja stavkov (DA), opravilom napora po urejanju besed in stavkov ter opravilom zaznavanja kritičnih napak, v vseh jezikovnih parih. Naši sistemi uporabljajo okvir Predictor-Estimator, konkretno z vnaprej usposobljenim XLM-Roberto kot Predictor in specifičnim za nalogo specifičnim klasifikatorjem ali regressorjem kot Estimator. Pri vseh nalogah izboljšujemo naše sisteme z vključitvijo stavka po urejanju ali dodatnega visokokakovostnega prevajalskega stavka v način večopravilnega učenja ali neposredno kodiranjem z napovedniki. Poleg tega naša strategija povečanja podatkov, ki temelji na Monte-Carlo Dropout, v nastavitvi ničelnega strela prinaša znatno izboljšanje podnaloge DA. Naši prispevki dosegajo izjemne rezultate pri vseh nalogah.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་ལས་ཀ་འདི་WMT 2021་དགའ་ཕྱོགས་སྒྲིག་ཚད་རྩ་སྒྲིག་ཀྱི་ལས་ཀ་འགུལ་སྤྱོད་པ། ང་ཚོས་ཚོར་བྱ་རིམ་གཞན་གསུམ་གྱི་ལྟ་བུའི་ནང་དུ་འཇུག་བྱས་པ་ཡིན། ང་ཚོའི་མ་ལག བྱ་འགུལ་གྱི་དོན་ལ་ང་ཚོ་རྒྱས་སྐྱོར་མེད་པར། འུ་ཅག་གི་མ་ལག ད་དུང་། Monte-Carlo Dropout ནང་ལ་བཙུགས་སྤྱོད་མི་་ཐག་ཡིན་པའི་སྒྲིག་འགོད་ནང་དུ་ང་ཚོའི་ཆ་འཕྲིན་བསྐྱེད་གྱི་ཐབས་ལམ་ལུགས་པས། རྒྱ་ནག་ དེར་བརྟན་ན། བསམ་འཆར་ཚུལ་ནི་བྱ་སྟངས་ཡོངས་རྫོགས་ལས་ཆེན་རྐྱེན་ཐུབ་པ་རེད།'}
{'en': 'The JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'pt': 'A submissão JHU-Microsoft para a tarefa compartilhada de estimativa de qualidade WMT21', 'fr': "Soumission JHU-Microsoft pour la tâche partagée d'estimation de la qualité WMT21", 'es': 'La tarea compartida de presentación de JHU-Microsoft para la estimación de calidad WMT21', 'ar': 'تقديم JHU-Microsoft للمهمة المشتركة لتقدير الجودة WMT21', 'zh': 'JHU-Microsoft 提交 WMT21 质估共享', 'ja': 'WMT 21品質推定共有タスクのJHU - Microsoftサブミッション', 'hi': 'WMT21 गुणवत्ता अनुमान साझा कार्य के लिए JHU-Microsoft सबमिशन', 'ru': 'Представление JHU-Microsoft для совместной задачи оценки качества WMT21', 'ga': 'Aighneacht JHU-Microsoft le haghaidh Tasc Comhroinnte Meastachán Cáilíochta WMT21', 'ka': 'Name', 'el': 'Η υποβολή JHU-Microsoft για κοινή εργασία εκτίμησης ποιότητας WMT21', 'it': "La presentazione di JHU-Microsoft per l'attività condivisa di stima della qualità WMT21", 'hu': 'A JHU-Microsoft benyújtása a WMT21 minőségbecslési megosztott feladathoz', 'kk': 'WMT21 сапасы оқу үшін JHU- Microsoft жіберілген тапсырманы ортақтастыру', 'lt': 'The JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'ml': 'WMT21 ഗുണത്തിനുള്ള എസ്റ്റിമേഷന്\u200d പങ്കുചേര്\u200dത്ത പണിയുടെ ജെഹുയു- മൈക്രോസഫ്റ്റ് സബ്മിഷന്\u200d', 'mk': 'JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'ms': 'Submission JHU-Microsoft untuk Tugas Berkongsi Penghargaan Kualiti WMT21', 'mt': 'Is-Sottomissjoni JHU-Microsoft għal Kompitu Konġunt għall-Istima tal-Kwalità tad-WMT21', 'mn': 'WMT21 Quality Estimation Shared Task for JHU-Microsoft Submission', 'no': 'JHU-Microsoft-Submission for WMT21- kvalitetestimer delt oppgåve', 'sr': 'Podmisija JHU-Microsoft za WMT21 procjenu kvalitete zajedničkog zadatka', 'pl': 'Zgłoszenie JHU-Microsoft do oceny jakości WMT21 Wspólne zadanie', 'si': 'Name', 'so': 'JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'ro': 'Depunerea JHU-Microsoft pentru activitatea partajată de estimare a calității WMT21', 'sv': 'JHU-Microsoft-inlämningen för delad uppgift för WMT21-kvalitetsbedömning', 'ta': 'WMT21 தரமான கணக்கீட்டு பகிர்ந்த பணி', 'ur': 'JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'vi': 'Công việc chia sẻ file JHU-Microsoft cho giải cung cấp chất lượng WM21', 'uz': 'Name', 'da': 'Den JHU-Microsoft-indsendelse til WMT21 Kvalitetsestimering delt opgave', 'hr': 'Podmisija JHU-Microsoft za procjenu kvalitete WMT21 zajedničkog zadatka', 'nl': 'De JHU-Microsoft Submission voor WMT21 Quality Estimation Shared Task', 'bg': 'Представянето на JHU-Microsoft за обща задача за оценка на качеството на WMT21', 'id': 'The JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'de': 'Die JHU-Microsoft Einreichung für WMT21 Qualitätsschätzung Shared Task', 'ko': 'JHU Microsoft에서 제출한 WMT21 품질 평가 공유 작업', 'fa': 'مأموریت JHU-Microsoft برای ارزیابی مشترک کیفیت WMT21', 'af': 'Die JHU-Microsoft Submission vir WMT21 Kwaliteit Estimation Gedeelde Taak', 'tr': 'WMT21 Quality Taýýarlama Mazmunlary üçin JHU-Microsoft Submission', 'sw': 'Ujumbe wa JHU-Microsoft wa Uhindi wa WMT21 ulishiriki kazi', 'sq': 'JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'az': 'WMT21 Nəviyyəti Görünüş İşləri üçün JHU-Microsoft Submission', 'am': 'አዲስ ዶሴ ፍጠር', 'hy': 'JHU-Microsoft-ի աշխարհի աշխարհի որակի գնահատման ընդհանուր հանձնարարությունը', 'bn': 'WMT21 কাজ শেয়ার করা কাজের জন্য JHU-মাইক্রোসফ্ট সাবমিশন', 'ca': 'La JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task', 'cs': 'Podání JHU-Microsoft pro odhad kvality WMT21 Shared Task', 'bs': 'Podmisija JHU-Microsoft za procjenu kvalitete WMT21 zajedničkog zadatka', 'et': 'JHU-Microsofti esitatud WMT21 kvaliteedi hindamise jagatud ülesanne', 'fi': 'JHU-Microsoftin toimittama WMT21 Quality Estimation Jaettu tehtävä', 'sk': 'JHU-Microsoftova predložitev za opravilo ocene kakovosti WMT21 v skupni rabi', 'he': 'הגישה של JHU-Microsoft למשימה משותפת להערכת איכות WMT21', 'jv': 'The jHU-Ubuntu Submis kanggo WWT 22 Quality', 'ha': 'KCharselect unicode block name', 'bo': 'JHU-Microsoft Submission for WMT21 Quality Estimation Shared Task'}
{'en': 'This paper presents the JHU-Microsoft joint submission for WMT 2021 quality estimation shared task. We only participate in Task 2 (post-editing effort estimation) of the shared task, focusing on the target-side word-level quality estimation. The techniques we experimented with include Levenshtein Transformer training and ', 'fr': "Cet article présente la soumission conjointe JHU-Microsoft pour la tâche partagée d'estimation de la qualité WMT 2021. Nous participons uniquement à la Tâche 2 (estimation de l'effort post-édition) de la tâche partagée, en nous concentrant sur l'estimation de la qualité au niveau des mots côté cible. Les techniques que nous avons expérimentées comprennent l'entraînement du transformateur de Levenshtein et l'augmentation des données avec une combinaison de traduction avant, arrière, aller-retour et pseudo post-édition de la sortie MT. Nous démontrons la compétitivité de notre système par rapport à la base OpenKiwi-XLM largement adoptée. Notre système est également le meilleur système sur la métrique MT MCC pour la paire de langues anglais-allemand.", 'es': 'Este artículo presenta la presentación conjunta de JHU-Microsoft para la tarea compartida de estimación de calidad del WMT 2021. Solo participamos en la Tarea 2 (estimación del esfuerzo posterior a la edición) de la tarea compartida, centrándonos en la estimación de la calidad a nivel de palabras del lado del objetivo. Las técnicas con las que experimentamos incluyen el entrenamiento de Levenshtein Transformer y el aumento de datos con una combinación de traducción hacia adelante, hacia atrás, ida y vuelta y seudo postedición de la salida de MT. Demostramos la competitividad de nuestro sistema en comparación con la base de OpenKiwi-XLM ampliamente adoptada. Nuestro sistema también ocupa el primer puesto en la métrica MT MCC para el par de idiomas inglés-alemán.', 'ar': 'تقدم هذه الورقة التقديم المشترك JHU-Microsoft للمهمة المشتركة لتقدير الجودة WMT 2021. نحن نشارك فقط في المهمة 2 (تقدير جهد التحرير اللاحق) للمهمة المشتركة ، مع التركيز على تقدير جودة مستوى الكلمة على مستوى الهدف. تتضمن التقنيات التي جربناها تدريب Levenshtein Transformer وزيادة البيانات مع مزيج من الترجمة الأمامية والخلفية وذاتية الذهاب والإياب والتحرير الزائف اللاحق لمخرجات الترجمة الآلية. نظهر القدرة التنافسية لنظامنا مقارنة بخط الأساس OpenKiwi-XLM المعتمد على نطاق واسع. نظامنا هو أيضًا النظام الأعلى تصنيفًا على مقياس MT MCC لزوج اللغة الإنجليزية الألمانية.', 'pt': 'Este artigo apresenta a submissão conjunta JHU-Microsoft para a tarefa compartilhada de estimativa de qualidade do WMT 2021. Participamos apenas da Tarefa 2 (estimativa de esforço pós-edição) da tarefa compartilhada, focando na estimativa de qualidade em nível de palavra do lado-alvo. As técnicas com as quais experimentamos incluem o treinamento do Levenshtein Transformer e o aumento de dados com uma combinação de tradução para frente, para trás, de ida e volta e pseudo pós-edição da saída da MT. Demonstramos a competitividade do nosso sistema em comparação com a linha de base OpenKiwi-XLM amplamente adotada. Nosso sistema também é o sistema de classificação mais alta na métrica MT MCC para o par de idiomas inglês-alemão.', 'zh': '本文引JHU-Microsoft合提交WMT 2021质评共任。 惟与共职2(译后辑工度),专注方字级量之。 试术兼Levenshtein Transformer练数增强,及MT输进退,往返译伪译编辑之组。 比之OpenKiwi-XLM基,示我统竞争力。 我们的系统也是英语-德语对 MT MCC 指标上排名靠前的系统。', 'ja': '本稿では、WMT 2021品質推定共有タスクのためのJHU - Microsoft共同提出を紹介する。私たちは、ターゲット側の単語レベルの品質推定に焦点を当てて、共有タスクのタスク2 （編集後の労力推定）にのみ参加します。私たちが実験したテクニックには、Levenshtein Transformerトレーニングと、MT出力の前方、後方、ラウンドトリップ翻訳、および疑似ポストエディットの組み合わせによるデータ拡張が含まれます。広く採用されているOpenKiwi - XLMベースラインと比較して、当社のシステムの競争力を実証しています。当社のシステムは、英語とドイツ語のペアのMT MCCメトリックのトップランクのシステムでもあります。', 'hi': 'यह पेपर WMT 2021 गुणवत्ता अनुमान साझा कार्य के लिए JHU-Microsoft संयुक्त सबमिशन प्रस्तुत करता है। हम केवल साझा कार्य के कार्य 2 (पोस्ट-संपादन प्रयास अनुमान) में भाग लेते हैं, लक्ष्य-साइड शब्द-स्तर गुणवत्ता अनुमान पर ध्यान केंद्रित करते हैं। जिन तकनीकों के साथ हमने प्रयोग किया है, उनमें लेवेन्स्टेन ट्रांसफॉर्मर प्रशिक्षण और डेटा वृद्धि शामिल है, जिसमें एमटी आउटपुट के आगे, पीछे, राउंड-ट्रिप अनुवाद और छद्म पोस्ट-एडिटिंग के संयोजन के साथ शामिल हैं। हम व्यापक रूप से अपनाए गए OpenKiwi-XLM बेसलाइन की तुलना में हमारे सिस्टम की प्रतिस्पर्धात्मकता का प्रदर्शन करते हैं। हमारा सिस्टम अंग्रेजी-जर्मन भाषा जोड़ी के लिए एमटी एमसीसी मीट्रिक पर शीर्ष रैंकिंग प्रणाली भी है।', 'ru': 'В этой статье представлена совместная заявка JHU и Microsoft для совместной задачи оценки качества WMT 2021. Мы участвуем только в Задаче 2 (оценка усилий после редактирования) общей задачи, фокусируясь на оценке качества на уровне целевого слова. Методы, с которыми мы экспериментировали, включают обучение трансформаторов Левенштейна и расширение данных с помощью комбинации прямого, обратного, обратного преобразования и псевдопостредактирования выходных данных MT. Мы демонстрируем конкурентоспособность нашей системы по сравнению с широко принятой базовой линией OpenKiwi-XLM. Наша система также является ведущей системой в метрике MT MCC для англо-немецкой языковой пары.', 'ga': 'Cuirtear i láthair sa pháipéar seo comhaighneacht JHU-Microsoft le haghaidh tasc comhroinnte um mheastachán cáilíochta WMT 2021. Ní ghlacaimid ach le Tasc 2 (meastachán iarrachta iar-eagarthóireachta) den tasc roinnte, ag díriú ar mheastachán cáilíochta ar leibhéal na bhfocal ar thaobh na sprice. I measc na dteicníochtaí ar bhaineamar triail astu bhí oiliúint Levenshtein Transformer agus méadú ar shonraí le meascán d’aistriúchán ar aghaidh, siar, bhabhta-turas, agus iar-eagarthóireacht bhréige ar an aschur MT. Léirímid iomaíochas ár gcóras i gcomparáid leis an mbunlíne OpenKiwi-XLM a nglactar go forleathan leis. Is é ár gcóras an córas is airde freisin ar mhéadrach MT MCC don phéire Béarla-Gearmáinis.', 'ka': 'ამ დოკუმენტის შესახებ JHU-Microsoft-ს ერთადერთი გადაწყვეტილება WMT 2021-ის განსაზღვრებელი საქაღალდე. ჩვენ მხოლოდ მხოლოდ მეორე საქაღალდე (დარედაქტირების შესაძლებლობა) გავამყავებთ საერთო საქაღალდე, რომელიც მისაღების სიტყვების საფუძლიო განსაზღვრებაზე დავყენ ტექნოგიები, რომლებიც ჩვენ ექსპერიმენტირებდით Levenshtein Transformer-ის განაკლება და მონაცემების აგგემენტირება, შემდეგ, გარეშე, გარეშე და პესეუდის შემდეგ რედაქტირება. ჩვენ ჩვენი სისტემის კონტეპექტიგურობას გამოჩვენებთ, რომლებიც უფრო გავაკეთებული OpenKiwi-XLM ბაზლინზე. ჩვენი სისტემა უფრო დიდი სისტემა MT MCC მეტრიკისთვის ინგლისური-გერმანური საზოგადოებისთვის.', 'el': 'Η παρούσα εργασία παρουσιάζει την κοινή υποβολή της JHU-Microsoft για την κοινή εργασία εκτίμησης ποιότητας WMT 2021. Συμμετέχουμε μόνο στην εργασία 2 (εκτίμηση προσπάθειας μετά την επεξεργασία) της κοινής εργασίας, εστιάζοντας στην εκτίμηση της ποιότητας του επιπέδου λέξεων στην πλευρά του στόχου. Οι τεχνικές με τις οποίες πειραματιστήκαμε περιλαμβάνουν εκπαίδευση και αύξηση δεδομένων με συνδυασμό μετάφρασης προς τα εμπρός, προς τα πίσω, προς τα πίσω και ψευδο-μετα-επεξεργασία της εξόδου ΜΤ. Αποδεικνύουμε την ανταγωνιστικότητα του συστήματός μας σε σύγκριση με την ευρέως υιοθετημένη βάση OpenKiwi-XLM. Το σύστημά μας είναι επίσης το κορυφαίο σύστημα στη μέτρηση ΜΤ για το αγγλο-γερμανικό γλωσσικό ζεύγος.', 'hu': 'Ez a tanulmány bemutatja a JHU-Microsoft közös benyújtását a WMT 2021 minőségbecslési megosztott feladatra. Csak a megosztott feladat 2. feladatában veszünk részt (szerkesztés utáni erőfeszítések becslésében), a céloldali szószintű minőségbecslésre összpontosítva. Az általunk kísérletezett technikák közé tartozik a Levenshtein Transzformátor tréning és az adatbővítés, amelynek kombinációja az MT kimenet előre, hátra, fordítás és pszeudo utószerkesztés. Bemutatjuk rendszerünk versenyképességét a széles körben elfogadott OpenKiwi-XLM alapképességhez képest. Rendszerünk az angol-német nyelvpár MT MCC metriájának legmagasabb rangú rendszere is.', 'it': "Questo articolo presenta la presentazione congiunta di JHU-Microsoft per il compito condiviso di stima della qualità WMT 2021. Partecipiamo solo al Task 2 (stima dello sforzo post-editing) del compito condiviso, concentrandoci sulla stima della qualità a livello di parola sul lato target. Le tecniche con cui abbiamo sperimentato includono la formazione Levenshtein Transformer e l'aumento dei dati con una combinazione di traduzione in avanti, indietro, andata e ritorno e pseudo post-editing dell'output MT. Dimostriamo la competitività del nostro sistema rispetto alla base OpenKiwi-XLM ampiamente adottata. Il nostro sistema è anche il sistema di top-ranking sulla metrica MT MCC per la coppia di lingue inglese-tedesco.", 'lt': 'Šiame dokumente pateikiamas JHU ir Microsoft bendras pasiūlymas dėl bendros WMT 2021 kokybės vertinimo užduoties. Mes dalyvaujame tik bendros užduoties 2 užduotyje (po redakcijos atliktos pastangos įvertinimas), daugiausia dėmesio skiriant tiksliniam žodžių kokybės įvertinimui. Mūsų eksperimentuojami metodai yra Levenshtein Transformer mokymas ir duomenų didinimas kartu su MT rezultato vertimu į priekį, atgal, apskritai ir pseudo po redakcijos. Mes parodome savo sistemos konkurencingumą, palyginti su plačiai priimtu OpenKiwi-XLM pagrindu. Mūsų sistema taip pat yra aukščiausios rangos sistema, taikoma anglų ir vokiečių kalbų poros MT MCC metrikai.', 'mk': 'Овој документ го претставува заедничкото поднесување на ЈУУ-Мајкрософт за заедничката задача за проценка на квалитетот на WMT 2021. Ние учествуваме само во задачата 2 (проценка на напорите по уредувањето) на заедничката задача, фокусирајќи се на проценката на квалитетот на целната страна на зборот. Техниките со кои експериментиравме вклучуваат тренинг на Levenshtein Transformer и зголемување на податоците со комбинација на напред, назад, круг-пат превод, и псевдо постуредување на MT излезот. Ја демонстрираме конкурентноста на нашиот систем во споредба со широко усвоената основа на OpenKiwi-XLM. Нашиот систем е, исто така, најрангираниот систем на метриката MT MCC за парот англиско-германски јазик.', 'kk': 'Бұл қағаз WMT 2021 сапасы бағалау үшін JHU- Microsoft ортақ тапсырманың біріктірімін көрсетеді. Біз тек ортақ тапсырманың 2- тапсырмасына (өңдеу көшірмесінен кейін) қатынасыз, мақсатты сөз деңгейінің сапатты бағалауына назар аударып тұрмыз. Біздің тәжірибедік техникалар Левенштейн түрлендіруші оқытуы және деректерді өзгерту және мәліметтердің алдыңғы, артқа, айналып жүріп аудару және MT шығысының псевдо кейін өзгерту Біз жүйеміздің конкуренциялығын ашық OpenKiwi-XLM негізгі жолымен салыстырып көрсетедік. Біздің жүйеміз сондай-ағылшын-неміс тіл екісінің MT MCC метрикалық жоғарғы жоғарғы жүйесі.', 'ms': 'Kertas ini memperkenalkan penghantaran kongsi JHU-Microsoft untuk tugas kongsi penghargaan kualiti WMT 2021. Kami hanya berpartisipasi dalam Tugas 2 (penghargaan usaha selepas-edisi) tugas berkongsi, fokus pada penghargaan kualiti aras perkataan-sisi sasaran. Teknik yang kami percubakan termasuk latihan Levenshtein Transformer dan peningkatan data dengan kombinasi terjemahan maju, mundur, perjalanan-bulat, dan pseudo pos-edit output MT. Kita menunjukkan kepekatan sistem kita dibandingkan dengan dasar OpenKiwi-XLM yang diadopsi secara luas. Sistem kita juga adalah sistem tertinggi pada metrik MCC MT untuk pasangan bahasa Inggeris-Jerman.', 'ml': 'ഈ പത്രത്തില്\u200d WMT 2021 ഗുണവിശേഷം പങ്കുചേര്\u200dത്ത ജെഹു-മൈക്രോസഫ്റ്റിന്റെ യൂട്ട് സജ്ജീകരണം നല്\u200dകുന്നു. നമ്മള്\u200d ടാസ്ക് 2-ല്\u200d പങ്കുചേര്\u200dക്കുന്നത് പങ്കുചേര്\u200dക്കുന്ന പണിയില്\u200d മാത്രമേ പങ്കുചേര്\u200dക്കുന്നുള്ളൂ. നമ്മള്\u200d പരീക്ഷിച്ചിട്ടുള്ള സാങ്കേതികവിദ്യകള്\u200d ലെവെന്\u200dഷ്ടെയിന്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d പരിശീലിപ്പിക്കുന്നതില്\u200d ഉള്\u200dപ്പെടുത്തുന്നു. ഡേ ഞങ്ങള്\u200d നമ്മുടെ സിസ്റ്റത്തിന്റെ മത്സരം കാണിച്ചുകൊണ്ടിരിക്കുന്നു. ഓപ്പെന്\u200dകിവി-എക്സ്\u200cഎക്സ്\u200cഎലിം ബെ ഞങ്ങളുടെ സിസ്റ്റം എംടി എംസിസി മെറ്റിക്കിന്റെ മുകളില്\u200d മേല്\u200dനോട്ടം സിസ്റ്റം ആണ് ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d', 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni konġunta JHU-Microsoft għall-kompitu kondiviż tal-istima tal-kwalità tad-WMT 2021. Aħna qed jipparteċipaw biss fil-Kompitu 2 (stima tal-isforz ta’ wara l-edizzjoni) tal-kompitu kondiviż, b’enfasi fuq l-istima tal-kwalità tal-livell tal-kliem min-naħa tal-mira. It-tekniki li esperimentajna magħhom jinkludu t-taħriġ ta’ Levenshtein Transformer u ż-żieda tad-dejta b’kombinazzjoni ta’ traduzzjoni ‘l quddiem, lura, round-trip, u psewdo post-edizzjoni tal-output MT. Aħna nuru l-kompetittività tas-sistema tagħna meta mqabbla mal-linja bażi OpenKiwi-XLM adottata b’mod wiesa’. Is-sistema tagħna hija wkoll l-ogħla sistema fuq il-metrika MT MCC għall-par lingwistiku Ingliż-Ġermaniż.', 'mn': 'Энэ цаас WMT 2021-ийн качествен баталгааны ажил дээр JHU-Microsoft-ын нийлбэр хэмжээний нийлбэр гаргадаг. Бид зөвхөн 2-р ажлын (захирал дахин өөрчлөгдөх хичээлийн төлөвлөгөөнд) хуваалцах ажил дээр оролцож, зорилготой хэмжээний хэмжээний үнэлгээнд анхаарлаа хандуулж байна. Бидний туршилтын техникууд Levenshtein Transformer суралцах болон өгөгдлийн нэмэгдүүлэлт нь алхам, буцаад, round-trip translation болон pseudo post-editing of the MT output. Бид системийн өрсөлдөөндөө ашигласан OpenKiwi-XLM суурь шугам дээр харьцуулсан. Бидний систем мөн Англи-Германы хэл хоёрын MT MCC-ийн хамгийн дээд хэмжээний систем юм.', 'no': 'Denne papiret viser JHU-Microsoft-tillegget for delt oppgåve for WMT 2021-kvalitetestisering. Vi deltar berre i oppgåva 2 (endringsverktøyesting etter redigering) av den delte oppgåva, som fokuserer på estimereringa av ord-nivå på målside. Tehnikane vi eksperimenterte med include Levenshtein Transformer training and data augmentation with a combination of forward, backward, round trip translation and pseudo post-editing of the MT output. Vi demonstrerer konkurentiteten av systemet vårt sammenlignet med den vaste aksepterte OpenKiwi-XLM baseline. Sistemet vårt er også den øvre rankeringssystemet på MT MCC-metrikken for engelsk-tysk språk par.', 'pl': 'Niniejszy artykuł przedstawia wspólne zgłoszenie JHU-Microsoft dla wspólnego zadania szacowania jakości WMT 2021. Uczestniczymy tylko w zadaniu 2 (oszacowaniu nakładu po edycji) wspólnego zadania, koncentrując się na oszacowaniu jakości słowa po stronie docelowej. Techniki, z którymi eksperymentowaliśmy, obejmują trening Levenstein Transformer oraz powiększanie danych z połączeniem tłumaczenia do przodu, do tyłu, w obrębie podróży i pseudo post-edycji wyjścia MT. Wykazujemy konkurencyjność naszego systemu w porównaniu z powszechnie przyjętym OpenKiwi-XLM bazowym. Nasz system jest również najwyższym systemem w metryce MT MCC dla pary językowej angielsko-niemieckiej.', 'sr': 'Ovaj papir predstavlja zajedničku prijavu JHU-Microsoft za zajedničku procenu kvalitete WMT 2021. Mi učestvujemo samo u zadatku 2 (procjenu posteditacije napora) zajedničkog zadatka, fokusirajući se na procjenu kvalitete reči na ciljnoj strani. Tehnike sa kojima smo eksperimentirali uključuju obuku Levenshtein a Transformera i povećanje podataka sa kombinacijom naprijed, unazad, prevodom okruglih putovanja i pseudom nakon redikcije MT-a. Pokazujemo konkurentnost našeg sistema u usporedbi sa široko usvojenim početnim linijom OpenKiwi-XLM. Naš sistem je takođe najbolji sistem na MT MCC metriku za njemački-engleski parov.', 'ro': 'Această lucrare prezintă depunerea comună JHU-Microsoft pentru sarcina comună de estimare a calității WMT 2021. Participăm doar la Sarcina 2 (estimarea efortului post-editare) a sarcinii partajate, concentrându-ne pe estimarea calității nivelului de cuvânt pe partea țintă. Tehnicile cu care am experimentat includ instruirea Levenshtein Transformer și mărirea datelor cu o combinație de traducere înainte, înapoi, dus-întors și pseudo post-editare a ieșirii MT. Demonstrăm competitivitatea sistemului nostru în comparație cu baza OpenKiwi-XLM adoptată pe scară largă. Sistemul nostru este, de asemenea, sistemul de top pe metrica MT MCC pentru perechea de limbi engleză-germană.', 'ta': 'This paper presents the JHU- Microsoft joint submit for WMT 2021 quality estimation shared task. நாங்கள் பகிர்ந்த பணியின் செயல் 2 (திருத்தி முயற்சி மதிப்பு) மட்டுமே பகிர்ந்து கொள்ள வேண்டும் சொல்லு நிலையின் மதிப்பு மதி நாங்கள் சோதித்த தொழில்நுட்பம் லெவன்ஷெயின் முன்னோக்க பயிற்சி மற்றும் தரவு கூட்டுதல் மூலம் முன்னோக்கு, பின்னோக்கு, சுற்றி பயிற்சி மொ நாங்கள் எங்கள் கணினியின் பிரச்சனையை வெளிப்படுத்துகிறோம் OpenKiwi-XLM அடிப்படை வரிசையில் ஒப்பிடுகிறது. எங்கள் அமைப்பு MT MCC மெட்ரிக்கான மேல் உயர்ந்த அமைப்பு ஆங்கிலம்- ஜெர்மன் மொழி ஜோடி.', 'si': 'මේ පැත්තේ JHU- Microsoft සම්පූර්ණ වැඩකට WMT 2021 ගොඩක් විශේෂතාව අවශ්\u200dයාවක් සම්පූර්ණය කරනවා. අපි වෙනුවෙන් වැඩේ 2 වැඩේ විතරයි (පස්ස සංපාදනය කරන්න ප්\u200dරයෝජනය විශ්වාස කරන්න) ක්\u200dරියාවක් විතරයි, ඉලක්ෂිත පැත්තේ  අපි පරීක්ෂණය කරලා ත්\u200dරක්ෂණය ලෙවෙන්ස්ටින් ප්\u200dරවේශකය සහ දත්ත ප්\u200dරවේශකය සම්බන්ධ කරලා තියෙනවා අපි අපේ පද්ධතියේ ප්\u200dරශ්නයක් පෙන්වන්නම් අපේ පද්ධතියේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විතරයි OpenKiwi XLM පද්ධ අපේ පද්ධතිය තමයි MT MCC මෙට්\u200dරික් එක්ක ඉංග්\u200dරීස්-ජර්මාන් භාෂා ජෝමියාව සඳහා උපරිම ප්\u200dරධානය.', 'so': 'Warqadan waxaa lagu soo bandhigayaa JHU-Microsoft wadajirka ah oo loo soo dhiibay qiimaynta qiimaynta qiimaynta qiimaynta la qaybiyey WMT 2021. Waxaynu ka qeybqaadannaa shaqo 2 (qiimeynta shaqada ee hagaajinta kadib) oo kaliya, waxaynu ku fiirsanaynaa qiimeynta qiimeynta saxda ee hadalka ee hagaajinta. Teqooyinka aan ku imtixaamaynay waxaa ka mid ah Levenshtein waxbarasho-horaadka ah iyo kordhiska data, kaas oo ku jira wadanka hore, gadaasha, turjumista safarka, iyo pseudo post-editing output MT. Waxaynu muujinnaa khiyaanada nidaamkayaga oo la barbardhigay saldhigga OpenKiwi-XLM. Sidoo kale nidaamkayagu waa nidaamka ugu sareeya ee MT MCC metriciga labada luqada Ingiriis-Jarmal.', 'ur': 'This paper presents the JHU-Microsoft joint submission for WMT 2021 quality estimation shared task. ہم صرف مشترک کام کے ٹاکس ۲ میں شرکت کرتے ہیں۔ ہم نے ان تخصیلیوں کے ساتھ آزمائش کی ہے جو Levenshtein Transformer تخصیلیں اور ڈاٹ اضافہ کے ساتھ آگے، پیچھے، راندٹریپ ترجمہ، اور مٹ آئٹ کے پیچھے سمجھنے کے ساتھ پسئوڈو پیچھے سمجھنے کے ساتھ۔ ہم نے اپنے سیستم کی رقابت دکھاتے ہیں، عمدہ طور پر اپنی کیوی-XLM بنسٹلین کے مقابلہ میں۔ ہمارا سیستم بھی MT MCC میٹریک کے اوپر رنگ سیستم ہے انگلیسی-جرمن زبان جوڑے کے لئے۔', 'sv': 'Denna uppsats presenterar JHU-Microsoft gemensamma inlämnande för WMT 2021 kvalitetsbedömning delad uppgift. Vi deltar endast i Uppgift 2 (uppskattning efter redigering) av den delade uppgiften, med fokus på målsidan ordnivå kvalitetsuppskattning. Teknikerna vi experimenterade med inkluderar Levenshtein Transformer utbildning och dataförstärkning med en kombination av framåt, bakåt, tur och retur översättning och pseudo post-redigering av MT output. Vi visar konkurrenskraften hos vårt system jämfört med den allmänt antagna OpenKiwi-XLM baseline. Vårt system är också det topprankade systemet på MT MCC-måttet för engelsk-tyska språkparet.', 'uz': "Name Biz faqat bilan birlashtirilgan vazifani 2 (tahrirlash vazifani qiymatga ega boʻlishimiz) bilan foydalanamiz, eng tomondan soʻz darajasini qiymatga qaramamiz. Levenshtein Transformer Training va maʼlumot yordamchisini birlashtirish uchun oldingi, backward, round trip tarjima qilish va MT natijasini tahrirlash uchun pseudo o o'zgarishni birlashtirish mumkin. We demonstrate the competitiveness of our system compared to the widely adopted OpenKiwi-XLM baseline.  Bizning tizimimiz ingliz-Olmon tili ikkita so'z MT MCC metrikida eng yuqori darajada tizimdir.", 'vi': 'Tờ giấy này trình bày việc đệ trình chung JHU-Microsoft để chia sẻ nhiệm vụ đánh giá chất lượng WRT 2021. Chúng tôi chỉ tham gia Nhiệm vụ 2 (ước lượng nỗ lực sau khi sửa xong) của công việc chia sẻ, tập trung vào ước lượng về từ ngữ đích. Những kỹ thuật chúng tôi thử nghiệm bao gồm việc huấn luyện phiên bản Tranlão Levenstein và gia tăng dữ liệu với sự kết hợp của bản dịch tua, lùi, quay-trip, và giả tạo sau việc sửa chữa MTV. Chúng tôi chứng minh khả năng của hệ thống so với cơ sở cơ bản OpenKiwi-XLM được thiết lập rộng. Hệ thống của chúng tôi cũng là hệ thống cấp cao nhất trên hệ thống đo lường MTV MCC cho cặp ngôn ngữ Anh-Đức.', 'bg': 'Настоящата статия представя съвместното представяне на задача за оценка на качеството на ОМТ 2021. Участваме само в Задача 2 (оценка на усилията след редактиране) на споделената задача, фокусирайки се върху оценката на качеството на целевата дума. Техниките, с които експериментирахме, включват обучение и увеличаване на данните с комбинация от напред, назад, обратен превод и псевдо пост-редактиране на изхода на МТ. Ние демонстрираме конкурентоспособността на нашата система в сравнение с широко приетата база. Нашата система е и най-високата система по метриката за англо-германската езикова двойка.', 'nl': 'Dit document presenteert de JHU-Microsoft gezamenlijke indiening voor WMT 2021 kwaliteitsschatting gedeelde taak. We nemen alleen deel aan Taak 2 (post-editing inspanning schatting) van de gedeelde taak, waarbij we ons concentreren op de doelkant kwaliteitsschatting op woordniveau. De technieken waarmee we geëxperimenteerd hebben, omvatten Levenstein Transformer training en data augmentatie met een combinatie van voorwaarts-, achterwaarts-, round-trip vertaling en pseudo post-editing van de MT output. We demonstreren het concurrentievermogen van ons systeem ten opzichte van de wijd aangenomen OpenKiwi-XLM baseline. Ons systeem is ook het hoogste systeem op de MT MCC metric voor het Engels-Duitse taalpaar.', 'hr': 'Ovaj papir predstavlja zajedničku prijavu JHU-Microsoft za zajedničku procjenu kvalitete WMT 2021. Mi sudjelujemo samo u procjenu zadatka 2 (nakon redakcije napora) zajedničkog zadatka, fokusirajući se na procjenu kvalitete riječi na ciljnoj strani. Tehnike s kojima smo eksperimentirali uključuju obuku Levenshtein a Transformera i povećanje podataka sa kombinacijom naprijed, unazad, prevodom okružnog putovanja i pseudom nakon uredbe MT-a. Pokazujemo konkurentnost našeg sustava u usporedbi s široko usvojenom početnom linijom OpenKiwi-XLM. Naš sustav je također najviši sustav na MT MCC metriku za njemački-engleski pair.', 'da': 'Dette papir præsenterer JHU-Microsoft fælles indsendelse til WMT 2021 kvalitetsestimering delt opgave. Vi deltager kun i opgave 2 (post-redigering indsats estimering) af den delte opgave, med fokus på målsidens ordniveau kvalitetsestimering. De teknikker, vi eksperimenterede med, omfatter Levenshtein Transformer træning og data augmentation med en kombination af fremad, tilbage, returoversættelse og pseudo post-redigering af MT output. Vi demonstrerer vores systems konkurrenceevne i forhold til den bredt vedtagne OpenKiwi-XLM baseline. Vores system er også det toprangerende system på MT MCC metric for det engelsk-tyske sprogpar.', 'de': 'Dieses Papier stellt die gemeinsame Einreichung von JHU und Microsoft für die gemeinsame Aufgabe WMT 2021 Qualitätsschätzung vor. Wir nehmen nur an Task 2 (Post-Editing Aufwandsschätzung) der gemeinsamen Aufgabe teil, wobei wir uns auf die zielseitige Qualitätsschätzung auf Wortebene konzentrieren. Zu den Techniken, mit denen wir experimentiert haben, gehören Levenstein Transformer Training und Datenaugmentation mit einer Kombination aus Vorwärts-, Rückwärts-, Hin- und Rückwärtsübersetzung und Pseudo-Nachbearbeitung der MT-Ausgabe. Wir demonstrieren die Wettbewerbsfähigkeit unseres Systems im Vergleich zur weit verbreiteten OpenKiwi-XLM-Basislinie. Unser System ist auch das Top-Ranking System in der MT MCC Metrik für das englisch-deutsche Sprachpaar.', 'id': 'Kertas ini mempersembahkan persembahan bersama JHU-Microsoft untuk penghargaan kualitas WMT 2021 tugas berbagi. Kami hanya berpartisipasi dalam Tugas 2 (penilaian usaha setelah editasi) dari tugas yang sama, fokus pada penilaian kualitas target-sisi kata-level. The techniques we experimented with include Levenshtein Transformer training and data augmentation with a combination of forward, backward, round-trip translation, and pseudo post-editing of the MT output.  Kita menunjukkan kompetitivitas sistem kita dibandingkan dengan dasar OpenKiwi-XLM yang diadopsi secara luas. Sistem kita juga adalah sistem tertinggi pada metrik MT MCC untuk pasangan bahasa Inggris-Jerman.', 'fa': 'این کاغذ برای ارزیابی مشترک کیفیت WMT 2021 ارزیابی JHU-Microsoft را نشان می دهد. ما تنها در وظیفه ۲ (ارزیابی تلاش بعد ویرایش) از وظیفه مشترک شرکت می\u200cکنیم، با تمرکز روی ارزیابی کیفیت سطح کلمه\u200cهای هدف. تکنیک\u200cهایی که با آن آزمایش کردیم شامل تمرین تغییر\u200cدهنده Levenshtein و افزایش داده\u200cها با ترکیب پیش، پشت، ترکیب\u200cدهنده\u200cهای دور و بعد از ویرایش\u200cدهنده\u200cی نتیجه MT است. ما مسابقه\u200cای از سیستم ما را در مقایسه با پایین\u200cخط OpenKiwi-XLM فراوان پذیرفته نمایش می\u200cدهیم. سیستم ما همچنین سیستم بالای درجه در MT MCC متریک برای جفت زبان انگلیسی و آلمانی است.', 'ko': '본고는 JHU-Microsoft가 공동으로 제출한 WMT 2021 품질 평가 공유 임무를 소개한다.우리는 공유 임무의 임무 2(편집 후 작업량 평가)에만 참여하고 목표 측면의 단어 등급의 품질 평가에 중점을 두었다.우리가 시험한 기술은 Levenshtein Transformer 훈련과 데이터 강화, 그리고 기계 번역 출력의 정향, 반향, 왕복 번역과 위조 후기 편집을 포함한다.널리 사용되는 OpenKiwi XLM 베이스라인과 비교하여 시스템의 경쟁력을 보여줍니다.우리 시스템도 영어-독일어 대 MT MCC 메트릭의 최상위 시스템입니다.', 'sw': 'Makala hii inaonyesha ujumbe wa pamoja wa JHU-Microsoft kwa ajili ya estimation ya ubora wa WMT 2021. Tunashiriki tu katika kazi 2 (kadiri ya juhudi za baada ya kuhariri) za kazi hiyo, tunalenga kuchukua kiwango cha kiwango cha maneno kwa lengo. Teknolojia tulizojaribu kwa pamoja ni pamoja na mafunzo ya zamani ya Levenshtein na kuongeza takwimu kwa muunganiko wa mbele, nyuma, tafsiri ya safari za nyuma, na pseudo baada ya kuhariri matokeo ya MT. Tunaonyesha ushindani wa mfumo wetu ukilinganishwa na msingi wa OpenKiwi-XLM uliotumiwa kwa kiasi kikubwa. Mfumo wetu pia ni mfumo wa juu juu kwenye mbinu za MCC kwa ajili ya mbili mbili za lugha ya Kiingereza na Kijerumani.', 'tr': 'Bu kagyz WMT 2021-iň kalitesinden bölýän zady üçin JHU-Microsoft birleşik gabdalygyny görkezýär. Biz diňe 2-nji Görevde (taýdan soňra düzenlemek üçin) bölünen zadyň hasaplanjak üçin üns berýäris. Levenshtein Transformer eğitimi we veri üýtgetmesi bilen denedik tekniklerimiz ileri, arkadan gezelen terjime edenler we MT çizginiň pseudo-düzenlemesi bilen birleşdirler. Biz sistemimiziň döwletligini OpenKiwi-XLM sebäpli üýtgedilen çykyşlygyna görä görkezilýäris. Biziň sistemimiz hem iňlisçe-nemesçe dil çiftleri üçin MT MCC metrikde iň üst depler sistemidir.', 'af': "Hierdie papier stel die JHU- Microsoft-koppelige onderskrywing vir WMT 2021-kwaliteit evaluering gedeelde taak voor te stel. Ons deel slegs in Taak 2 (post-editing effort estimatie) van die gedeelde taak, fokus op die doel-kant woord-vlak-kwaliteit estimatie. Die teknike wat ons eksperimenteer het met Levenshtein Transformer onderwerp en data vergroot met 'n kombinasie van vorentoe, terugkeer, rondtrek vertaling en pseudo post- redigeering van die MT uitvoer. Ons wys die mededingsheid van ons stelsel vergelyk met die vaste aangeneem OpenKiwi-XLM basislien. Ons stelsel is ook die top-ranking stelsel op die MT MCC metric vir die Engels-Duitse taal paar.", 'sq': 'This paper presents the JHU-Microsoft joint submission for WMT 2021 quality estimation shared task.  Ne marrim pjesë vetëm në detyrën 2 (vlerësimin e përpjekjes pas redaksionit) të detyrës së përbashkët, duke u përqëndruar në vlerësimin e cilësisë së nivelit të fjalëve në anën e objektivit. Teknikët me të cilat eksperimentuam përfshijnë trajnimin e Levenshtein Transformer dhe rritjen e të dhënave me një kombinim të përkthimit përpara, prapa, të udhëtimit të rrumbullakët, dhe pseudo pas-editimit të daljes MT. Ne demonstrojmë konkurrencën e sistemit tonë krahasuar me bazën e zgjeruar OpenKiwi-XLM. Sistemi ynë është gjithashtu sistemi më i lartë në metrikën MT MCC për çiftin gjuhë anglo-gjermane.', 'am': 'ይህ ገጽ የJHU-Microsoft ተካባሪዎችን የWMT 2021 ጥያቄ መጠን የተሰራጨውን ስራ ያቀርባል፡፡ የስራውን 2 (ካስተማርነው በኋላ ማሰቃየት) ብቻ እናጋራለን፡፡ በተፈተናነው ስህተት ውስጥ ሌvenshtein ትርጓሜ ትርጓሜ እና ዳታ ማድረግ እና የMT ውጤት አካባቢ በመጠቀም፣ ወደ ኋላ፣ በኋላው፣ የዞረ ጉዞ ትርጓሜ እና በpseudo post-edit. በOpenKiwi-XLM መደገፊያውን ከመተካካት ጋር የስርዓታችንን ፍላጎት እናሳያቸዋለን፡፡ የኢንጂልኛ-ጀርመን ቋንቋ ሁለትን በሚያስፈልገው MT MCC ሜትሪክ ላይ የደረጃ ደረጃዎች ሲስተም ነው፡፡', 'hy': 'Այս հոդվածը ներկայացնում է JHU-Մայքրոսոֆթ համագործակցական ներկայացումը ԱՄԹ 2021-ի որակի գնահատման ընդհանուր խնդրի համար: Մենք մասնակցում ենք միայն ընդհանուր առաջադրանքի 2-ի (խմբագրության հետագա փորձի գնահատման) մեջ, կենտրոնացնելով նպատակային բառի մակարդակի որակի գնահատման վրա: Մեր փորձարկումները ներառում են Լեվենսթեյնի տրանսֆերմերների ուսումնասիրությունը և տվյալների աճը՝ առաջ, ետ, շրջանակի թարգմանման և MT-ի արտադրության կեղծ հետխմբագրման համադրության հետ: Մենք ցույց ենք տալիս մեր համակարգի մրցակցությունը համեմատած լայնորեն ընդունված OpenKiWi-XLM հիմքի հետ: Մեր համակարգը նաև MT MCC մետրիկայի լավագույն համակարգն է անգլերեն-գերմանացի երկու լեզուների համար:', 'bn': 'এই পত্রিকাটি উইএমটি ২০২১ সালের মান হিসেবে শেয়ার করা কাজের জন্য জেএইচউ-মাইক্রোসফট যৌথ জমা প্রদান করেছে। আমরা শেয়ার কর্মসূচীর পরে কাজ ২ (সম্পাদনার প্রচেষ্টা হিসেবে) অংশগ্রহণ করি, লক্ষ্য-পাশের শব্দ-স্তরের মান হিসেবে দৃষ্টিগুলোর এমটি আউটপুট সম্পাদনের মাধ্যমে লেভেনশটেইন ট্রান্সফ্রেন্স প্রশিক্ষণ এবং ডাটা যোগাযোগের মাধ্যমে প্রযুক্তিগুলোকে আমরা পরীক্ষা করেছিলাম, যা  আমরা আমাদের সিস্টেমের প্রতিযোগিতা প্রদর্শন করি প্রশস্ত ওপেনকিউই-এক্সএলএম বেসাইনের তুলনায়। আমাদের সিস্টেম ইংরেজি -জার্মান ভাষার জোড়ার জন্য এমটি এমসিসি মেট্রিকে সর্বোচ্চ রেঙ্কিং সিস্টেম।', 'az': 'Bu kağıt WMT 2021 kaliteli qiymətləndirmək üçün JHU-Microsoft birləşdirilməsini göstərir. Biz sadəcə paylaşılmış işlərin paylaşılması üçün 2-ci işlərə (düzəltmə sonrası təcrübəsindən sonra) iştirak edirik, məqsəd-tərəf söz-seviyyəti qiymətinə odaqlanırıq. Levenshtein Transformer təcrübəsi və məlumat artırması ilə təcrübə etdiyimiz tekniklər, öndən, arxa tərəfindən, çevrilmiş çeviri və MT çıxışının pseudo-düzəltməsi ilə birləşdirilmişdir. Biz sistemimizin müqabiliyyətini geniş OpenKiwi-XLM baseline ilə göstəririk. Bizim sistemimiz də İngilizci-Alman dil çift üçün MT MCC metriklərinin üst səviyyəsi sistemidir.', 'ca': "Aquest paper presenta la presentació conjunta JHU-Microsoft per a la tasca compartida d'estimació de qualitat WMT 2021. Només participem a la tasca 2 (estimació de l'esforç post-edició) de la tasca compartida, centrant-nos en l'estimació de qualitat de la paraula al costat de l'objectiu. Les tècniques amb les que vam experimentar inclouen entrenament Levenshtein Transformer i augment de dades amb una combinació de traducció avançada, cap endavant, de viatge redond i pseudo post-edició de la producció MT. Demonstrem la competitivitat del nostre sistema comparat amb la base d'OpenKiwi-XLM amplament adoptada. El nostre sistema també és el sistema de millor rangde la mètrica MT MCC per al parell anglo-alemany.", 'cs': 'Tento článek představuje společné podání JHU-Microsoft pro sdílenou úlohu odhadu kvality WMT 2021. Podílíme se pouze na Úkolu 2 (odhadu intenzity po editaci) sdíleného úkolu se zaměřením na odhad kvality slova na cílové straně. Techniky, se kterými jsme experimentovali, zahrnují trénink Levenstein Transformer a rozšíření dat kombinací překladu dopředu, zpět, zpětného překladu a pseudo post-editace MT výstupu. Dokazujeme konkurenceschopnost našeho systému ve srovnání s široce přijímaným OpenKiwi-XLM základním principem. Náš systém je také nejlepším systémem v metrice MT MCC pro anglicko-německý jazykový pár.', 'et': 'Käesolevas töös tutvustatakse JHU-Microsofti ühist esitamist WMT 2021 kvaliteedihindamise jagatud ülesande jaoks. Osaleme ainult jagatud ülesande ülesandes 2 (redigeerimisjärgne jõupingutuse hindamine), keskendudes sihtküljele sõnatasemel kvaliteedi hindamisele. Tehnikad, millega me eksperimenteerisime, hõlmavad Levenshteini Transformeri koolitust ja andmete suurendamist koos edasi-, tagasi-, tagasi- ja edasi-tagasi tõlke ning MT väljundi pseudojärgse redigeerimisega. Näitame oma süsteemi konkurentsivõimet võrreldes laialdaselt kasutusele võetud OpenKiwi-XLM baasiga. Meie süsteem on ka inglise-saksa keele paari MT MCC mõõdiku kõrgeim süsteem.', 'bs': 'Ovaj papir predstavlja zajedničku prijavu JHU-Microsoft za zajedničku procjenu kvalitete WMT 2021. Mi sudjelujemo samo u procjenu zadatka 2 (nakon redakcije napora) zajedničkog zadatka, fokusirajući se na procjenu kvalitete riječi na ciljnoj strani. Tehnike s kojima smo eksperimentirali uključuju obuku Levenshtein a Transformera i povećanje podataka sa kombinacijom naprijed, unazad, prevodom okruglih putovanja i pseudom nakon redikcije MT-a. Pokazujemo konkurentnost našeg sistema u usporedbi sa široko usvojenim početnim linijom OpenKiwi-XLM. Naš sistem je također najbolji sistem na MT MCC metriku za njemački-engleski parov.', 'fi': 'Tässä artikkelissa esitellään JHU:n ja Microsoftin yhteinen toimitus WMT 2021 -laadunvarmistuksen yhteiseen tehtävään. Osallistumme vain jaetun tehtävän tehtävään 2 (jälkieditointityön estimointi) keskittyen kohdepuolen sanatason laadun estimointiin. Tekniikoita, joilla kokeilimme, ovat Levenshtein Transformer -koulutus ja datan lisääminen yhdistettynä eteenpäin, taaksepäin, edestakaisin ja MT-tuotoksen pseudo-jälkieditointiin. Osoitamme järjestelmämme kilpailukykyä verrattuna laajasti hyväksyttyyn OpenKiwi-XLM-lähtötilanteeseen. Järjestelmämme on myös englannin ja saksan kieliparin MT MCC -mittarin korkein järjestelmä.', 'jv': "Ngerungkat-Ngerungkat kuwi nggawe JeHU-Ubuntu sampeyan kanggo ngilanggar nggawe kalitas 'WT 2020 1' Awak dhéwé mengko nggambar 2 task (njaluk after-editing effortefforting) nggawe task gak nggawe, ngnggawe tarjamahan kanggo kowe Tarjamahan-side kuwi wis kalite donge kuwi. Teknik sing apik trus karo ingkang Lawenstitin Transformer aturan karo perusahaan dadi ampungan karo konbinksi buktuan, banter, round-torakake tarjamahan karo psepsepsepse after-editing of the MT output. Awak dhéwé éntuk kesempatan pangan ning sistem dhéwé nggawe gerarané karo Open Kiwi-XLM sing ngewehi gedhé. Sistem dhéwé kuwi nganggo sistem sing songan banter kanggo MT XMC Metric kanggo kelas pangan Inggris-German.", 'he': 'הנייר הזה מציג את ההצגה המשותפת של JHU-Microsoft עבור הערכת איכות משימה משותפת WMT 2021. אנחנו משתתפים רק במשימה 2 (הערכת מאמץ לאחר העורך) של המשימה המשותפת, מתמקדים על הערכת איכות צד המטרה. הטכניקות שאנחנו ניסויים איתן כוללות אימון Levenshtein Transformer וגדלת נתונים עם שילוב של התרגום קדימה, אחורה, מסע מסביב, ופסודו אחרי העורה של תוצאה MT. אנו מראים את התחרות של המערכת שלנו בהשוואה לבסיס OpenKiwi-XLM המאומץ. המערכת שלנו היא גם המערכת הגדולה ביותר במטרית MT MCC לזוג שפה אנגלית-גרמנית.', 'sk': 'V prispevku je predstavljena skupna predložitev JHU-Microsoft za skupno opravilo ocenjevanja kakovosti WMT 2021. Sodelujemo le v nalogi 2 (ocena napora po urejanju) skupnega opravila, pri čemer se osredotočamo na oceno kakovosti na ciljni strani besede. Tehnike, s katerimi smo eksperimentirali, vključujejo usposabljanje Levenshtein Transformer in povečanje podatkov s kombinacijo naprej, nazaj, povratnega prevajanja in psevdo post-urejanja MT izhoda. Prikazujemo konkurenčnost našega sistema v primerjavi s splošno sprejetimi osnovnimi podatki OpenKiwi-XLM. Naš sistem je tudi najboljši sistem na merilu MT MCC za angleško-nemški jezikovni par.', 'ha': "Wannan avir na bãyar da the JHU-Microsoft co-Islam for WMT 2021 qiimati da aka yi rabo aiki. Tuna bincike kawai cikin aikin 2 (ƙidãyar aikin da aka hana shi a bayan editori), munã kiyayya a kan kima mai girma ga kalmar-side-word-daraja. Technica da muka jarraba da shi include Lehenshtein Training na Transformer and addition data with a koma of forward, Backward, runaway-safari, and ppudo after-editing of the MT Outputs. Tune nuna competitive na'urarmu sami da aka riƙi bayanin Open Kiwi-XLM. Kayya, na'urarmu yana da mafĩfi na sarki a kan metric MT MCC wa lugha Ingiriya-jeruman.", 'bo': 'ཤོག་བྱང་འདིས་WMT 2021་རིང་མཐུན་སྒྲིག་གི་དོན་ལ་JHU-Microsoft་མཉམ་དུ་འཇུག་སྣོད་སྟོན་པ། ང་ཚོས་དབར་གྱི་བྱ་འགུལ་༢་ནང་དུ་དབར་ཞུགས་བྱེད་པ་ལས་མཐུན་སྐྱེལ་འདུག The techniques we experimented with include Levenshtein Transformer training and data augmentation with a combination of forward, backward, round-trip translation, and pseudo post-editing of the MT output. ང་ཚོས་མ་ལག་གི་རྒྱལ་སྤྲོད་དབང་ཚད་འདིའི་གྲངས་སུ་OpenKiwi-XLM་གཞི་རྩིས་གཞི་དང་མཉམ་དུ་གཏོང་བ་ཡོད། ང་ཚོའི་མ་ལག་གིས་དབྱིན་ཡིག་ཆ་དང་དབྱིན་ཡིག་གི་སྐད་རིགས་ཀྱི་མཐོ་ཚད་མཐོ་ཤོང་མཁན་གྱི་མ་ལག་རེད།'}
{'en': 'Papago’s Submission for the WMT21 Quality Estimation Shared Task', 'es': 'Presentación de Papago para la tarea compartida de estimación de calidad WMT21', 'pt': 'Envio de Papago para a Tarefa Compartilhada de Estimativa de Qualidade do WMT21', 'ar': 'تقديم Papago للمهمة المشتركة لتقدير الجودة WMT21', 'fr': "Soumission de Papago pour la tâche partagée d'estimation de la qualité WMT21", 'zh': 'Papago提交WMT21质量共享', 'ja': 'WMT 21品質見積もり共有タスクに対するPapagoの提出', 'ru': 'Представление Папаго для совместной задачи оценки качества WMT21', 'hi': 'WMT21 गुणवत्ता अनुमान साझा कार्य के लिए Papago के सबमिशन', 'ga': 'Aighneacht Papago don Tasc Comhroinnte um Mheastachán Cáilíochta WMT21', 'ka': 'ბაპადოს WMT21 კვალეტური განსაზღვრების გასაზღვრება', 'el': 'Υποβολή του Παπαγού για την Κοινή Εργασία Εκτίμησης Ποιότητας WMT21', 'hu': 'Papago benyújtása a WMT21 minőségbecslési megosztott feladathoz', 'it': "Presentazione di Papago per l'attività condivisa di stima della qualità WMT21", 'kk': 'WMT21 сапасының бөлек тапсырмасын бағалау үшін Папаго жіберілуі', 'lt': 'Papago pranešimas dėl bendros WMT21 kokybės vertinimo užduoties', 'ms': "Papago's Submission for the WMT21 Quality Estimation Shared Task", 'mk': 'Папаго ја поднесе задачата за заедничка проценка на квалитетот на WMT21', 'mt': "Sottomissjoni ta' Papago għall-Kompitu Konġunt tal-Istima tal-Kwalità tad-WMT21", 'ml': 'WMT21 ഗുണത്തിനുള്ള എസ്റ്റിമേഷന്\u200d പങ്കെടുത്ത പണി', 'mn': 'Бапаго-ын WMT21 Quality Estimation Shared Task-ын даалгавар', 'no': 'Papago s Submission for WMT21- kvalitetevaluering delt oppgåve', 'ro': 'Trimiterea lui Papago pentru sarcina partajată de estimare a calității WMT21', 'pl': 'Zgłoszenie Papago do wspólnego zadania oceny jakości WMT21', 'si': 'පාපාගෝගේ WMT21 කුළුවත් අනුමාණය සම්බන්ධ වැඩ සම්බන්ධය', 'sr': 'Papagova podmisija za procjenu kvalitete WMT21 zajedničkog zadatka', 'sv': 'Papagos bidrag till WMT21 kvalitetsbedömning delad uppgift', 'so': "Papago's Submission for the WMT21 Quality Estimation Shared Task", 'ur': 'پاپاپاگو کے واسطے WMT21 کیلوٹی آسانی شریک ٹاکس کے لئے', 'ta': 'WMT21 தரம் கணக்கீட்டு பகிர்ந்த பணி', 'vi': 'Người phụ trách Papago cho công việc chia s ẻ chất lượng WM21', 'uz': 'Name', 'bg': 'Представянето на Папаго за общата задача за оценка на качеството на WMT21', 'da': "Papago's indsendelse til WMT21 Quality Estimation delt opgave", 'nl': "Papago's inzending voor de WMT21 Quality Estimation Shared Task", 'hr': 'Papagova podmission za procjenu kvalitete WMT21 zajedničkog zadatka', 'de': 'Papagos Einreichung für die gemeinsame Aufgabe zur Qualitätsschätzung WMT21', 'fa': 'ماموریت پاپاپاگو برای ارزیابی مشترک کیفیت WMT21', 'id': "Papago's Submission for the WMT21 Quality Estimation Shared Task", 'sw': 'Ujumbe wa Papago kwa ajili ya Ubaguzi wa WMT21 ulishiriki kazi', 'ko': 'Papago가 제출한 WMT21 품질 평가 공유 작업', 'tr': "WMT21 kalitesi ölçümleri için Papago'nun göndermesi", 'af': 'Papago se Submission vir die WMT21 Kwaliteit Estimation Gedeelde Opdrag', 'am': "Papago's Submission for the WMT21 Quality Estimation Shared Task", 'sq': "Papago's Submission for the WMT21 Quality Estimation Shared Task", 'hy': 'Պապագոյի ներկայացումը ԱՄԹ21-ի որակի գնահատման ընդհանուր խնդրի համար', 'az': "Papago's Submission for the WMT21 Quality Estimation Shared Task", 'bn': 'WMT21 গুণত্ব শেয়ার করা কাজের জন্য পাপাগোর সাবমিশন', 'bs': 'Papagova podmission za procjenu kvalitete WMT21 zajedničkog zadatka', 'cs': 'Předložení Papaga pro odhad kvality WMT21 Sdílený úkol', 'et': 'Papago esitus WMT21 kvaliteedihinnangu jagatud ülesandele', 'fi': 'Papagon toimittama aineisto WMT21 Quality Estimation Shared Task', 'ca': "El Papago's Submission for the WMT21 Quality Estimation Shared Task", 'jv': 'Submis nang papago kanggo nggawe task sing dikarolan kalite, tengahan Universi', 'ha': 'KCharselect unicode block name', 'sk': 'Papagova predložitev za skupno nalogo ocene kakovosti WMT21', 'he': 'המשימה של פאפגו למשימה משותפת להערכת איכות WMT21', 'bo': "Papago's Submission for the WMT21 Quality Estimation Shared Task"}
{'en': 'This paper describes Papago submission to the WMT 2021 Quality Estimation Task 1 : Sentence-level Direct Assessment. Our multilingual Quality Estimation system explores the combination of Pretrained Language Models and Multi-task Learning architectures. We propose an iterative training pipeline based on pretraining with large amounts of in-domain synthetic data and ', 'ar': 'تصف هذه الورقة تقديم Papago إلى مهمة تقدير الجودة 1 WMT 2021: التقييم المباشر على مستوى الجملة. يستكشف نظام تقدير الجودة متعدد اللغات لدينا مزيجًا من نماذج اللغة المحددة مسبقًا وبنى التعلم متعدد المهام. نقترح خط أنابيب تدريب تكراري يعتمد على التدريب المسبق بكميات كبيرة من البيانات التركيبية في المجال والضبط الدقيق مع البيانات الذهبية (المسمى). ثم نقوم بضغط نظامنا عن طريق تقطير المعرفة من أجل تقليل المعلمات مع الحفاظ على الأداء القوي. تعمل أنظمتنا متعددة اللغات المقدمة بشكل تنافسي في إعدادات متعددة اللغات وجميع إعدادات أزواج اللغة الفردية البالغ عددها 11 بما في ذلك الإعدادات بدون طلقة.', 'fr': "Cet article décrit la soumission de Papago au WMT 2021 Quality Estimation Task 1\xa0: Sentence-level Direct Assessment. Notre système d'estimation de la qualité multilingue explore la combinaison de modèles linguistiques préformés et d'architectures d'apprentissage multitâches. Nous proposons un pipeline de formation itératif basé sur un pré-entraînement avec de grandes quantités de données synthétiques dans le domaine et un réglage précis avec des données Gold (labellisées). Nous compressons ensuite notre système par distillation des connaissances afin de réduire les paramètres tout en maintenant de bonnes performances. Nos systèmes multilingues soumis fonctionnent de manière compétitive dans le multilingue et dans les 11 paramètres de paires de langues individuelles, y compris le zéro tir.", 'es': 'Este artículo describe la presentación de Papago a la Tarea 1 de estimación de calidad del WMT 2021: Evaluación directa a nivel de oración. Nuestro sistema multilingüe de estimación de la calidad explora la combinación de modelos lingüísticos preentrenados y arquitecturas de aprendizaje multitarea. Proponemos una línea de capacitación iterativa basada en la capacitación previa con grandes cantidades de datos sintéticos en el dominio y el ajuste fino con datos de oro (etiquetados). Luego comprimimos nuestro sistema a través de la destilación de conocimientos para reducir los parámetros y mantener un rendimiento sólido. Nuestros sistemas multilingües presentados funcionan de manera competitiva en varios idiomas y en las 11 configuraciones de combinación de idiomas individuales, incluida la opción cero.', 'pt': 'Este documento descreve o envio da Papago para a Tarefa 1 de Estimativa de Qualidade do WMT 2021: Avaliação Direta em Nível de Sentença. Nosso sistema multilíngue de estimativa de qualidade explora a combinação de modelos de linguagem pré-treinados e arquiteturas de aprendizado multitarefa. Propomos um pipeline de treinamento iterativo baseado em pré-treinamento com grandes quantidades de dados sintéticos no domínio e ajuste fino com dados gold (rotulados). Em seguida, compactamos nosso sistema por meio da destilação de conhecimento para reduzir os parâmetros e manter um desempenho forte. Nossos sistemas multilíngues enviados têm um desempenho competitivo em configurações multilíngues e em todos os 11 pares de idiomas individuais, incluindo tiro zero.', 'ja': 'この論文では、WMT 2021品質推定タスク1 ：文章レベルの直接評価へのPapagoの提出について説明します。当社の多言語品質推定システムは、事前に訓練された言語モデルとマルチタスクラーニングアーキテクチャの組み合わせを探求しています。大量のドメイン内合成データによる事前トレーニングと、金（ラベル）データによる微調整に基づく反復トレーニングパイプラインを提案します。次に、パラメータを低減しながら強力なパフォーマンスを維持するために、ナレッジ蒸留を介してシステムを圧縮します。提出された多言語システムは、ゼロショットを含む11の個々の言語ペア設定で競争的に機能します。', 'zh': '本文引PapagoWMT 2021质料事1:句直评提交。 多言质料系统探预训言模形,与多任务学架构合。 建迭代教管道,盖合数于域内,而用黄金(表)数以微之。 然后因蒸馏以压缩吾统,以损参数而持强。 多言系于多言,11独语于设(零镜头)有竞争力。', 'hi': 'यह पेपर डब्ल्यूएमटी 2021 गुणवत्ता अनुमान कार्य 1: वाक्य-स्तर के प्रत्यक्ष मूल्यांकन के लिए पापगो सबमिशन का वर्णन करता है। हमारे बहुभाषी गुणवत्ता आकलन प्रणाली Pretrained भाषा मॉडल और बहु कार्य सीखने आर्किटेक्चर के संयोजन की पड़ताल करता है. हम इन-डोमेन सिंथेटिक डेटा की बड़ी मात्रा के साथ प्रीट्रेनिंग और सोने (लेबल) डेटा के साथ फाइनट्यूनिंग के आधार पर एक पुनरावर्ती प्रशिक्षण पाइपलाइन का प्रस्ताव करते हैं। फिर हम पैरामीटर को कम करने के लिए ज्ञान आसवन के माध्यम से हमारे सिस्टम को संपीड़ित करते हैं फिर भी मजबूत प्रदर्शन बनाए रखते हैं। हमारे प्रस्तुत बहुभाषी सिस्टम बहुभाषी और शून्य-शॉट सहित सभी 11 व्यक्तिगत भाषा जोड़ी सेटिंग्स में प्रतिस्पर्धी रूप से प्रदर्शन करते हैं।', 'ru': 'В настоящем документе описывается представление Папаго для выполнения задачи 1 по оценке качества WMT 2021: Прямая оценка на уровне предложения. Наша многоязычная система оценки качества исследует комбинацию предварительно обученных языковых моделей и многозадачных архитектур обучения. Мы предлагаем итеративный обучающий конвейер, основанный на предварительном обучении с большими объемами внутридоменных синтетических данных и тонкой настройке с данными золота (помеченными). Затем мы сжимаем нашу систему с помощью дистилляции знаний, чтобы уменьшить параметры, но сохранить высокую производительность. Наши представленные многоязычные системы работают конкурентоспособно в многоязычных и всех 11 отдельных настроек языковых пар, включая нулевой снимок.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht Papago chuig Tasc 1 Meastachán Cáilíochta 2021 WMT: Measúnú Díreach ar leibhéal na pianbhreithe. Déanann ár gcóras ilteangach Meastachán Cáilíochta iniúchadh ar an meascán de Mhúnlaí Teanga Réamhthraenáilte agus ailtireachtaí Foghlama Ilthasc. Molaimid píblíne oiliúna atriallach bunaithe ar réamhoiliúint le méideanna móra de shonraí sintéiseacha san fhearann agus mionchoigeartú le sonraí óir (lipéadaithe). Déanaimid ár gcóras a chomhbhrú ansin trí dhriogadh eolais chun paraiméadair a laghdú ach coinnímid feidhmíocht láidir. Feidhmíonn ár gcórais ilteangacha a sheoltar isteach go hiomaíoch i suíomhanna ilteangacha agus i ngach ceann de na 11 socrú péire teanga aonair lena n-áirítear aon seat nialasach.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή του Παπαγού στο έργο Εκτίμησης Ποιότητας 1: Άμεση Αξιολόγηση σε επίπεδο ποινής. Το πολύγλωσσο σύστημα Εκτίμησης Ποιότητας διερευνά τον συνδυασμό των Προκατασκευασμένων Γλωσσικών Μοντέλων και Αρχιτεκτόνων εκμάθησης πολλαπλών εργασιών. Προτείνουμε έναν επαναληπτικό εκπαιδευτικό αγωγό βασισμένο στην προεπεξεργασία με μεγάλες ποσότητες συνθετικών δεδομένων εντός του τομέα και τον συντονισμό με χρυσά (μαρκαρισμένα) δεδομένα. Στη συνέχεια συμπιέζουμε το σύστημά μας μέσω απόσταξης γνώσης προκειμένου να μειώσουμε τις παραμέτρους αλλά να διατηρήσουμε ισχυρή απόδοση. Τα υποβαλλόμενα πολύγλωσσα συστήματα μας εκτελούν ανταγωνιστικά σε πολυγλωσσικές και όλες τις 11 μεμονωμένες ρυθμίσεις γλωσσικών ζευγαριών, συμπεριλαμβανομένης της μηδενικής λήψης.', 'hu': 'Ez a tanulmány bemutatja a Papago benyújtását a WMT 2021 Minőségbecslési feladat 1: mondatszintű közvetlen értékelés. Többnyelvű minőségbecslési rendszerünk az előzetes nyelvi modellek és a többfeladatú tanulás architektúrák kombinációját vizsgálja. Javasolunk egy iteratív képzési folyamatot, amely előkészítésen alapul, nagy mennyiségű domain szintetikus adattal és arany (címkézett) adatokkal történő finomhangoláson. Ezt követően ismeretlepárlással tömörítjük rendszerünket a paraméterek csökkentése érdekében, mégis erős teljesítményt tartunk fenn. Beküldött többnyelvű rendszereink versenyképes teljesítményt nyújtanak többnyelvű és mind a 11 egyéni nyelvpár beállításban, beleértve a nulla lövést is.', 'ka': 'ეს წიგნი აღწერს ბაპაგოგის WMT 2021-ის კვალეტის განსაზღვრება სამუშაო დავალება 1: სიტყვების დონეზე Direkt განსაზღვრება. ჩვენი მრავალენგური კვალიტური განსაზღვრების სისტემა გამოვაკვირდება საკუთარი ენის მოდელების და მრავალენი დასწავლების არქტიქტურების კომბიზაციას. ჩვენ განვითარებთ თეტრატიური სარგებო სარგებო სარგებო სარგებო სარგებო მონაცემები, რომელიც დიდი სინტეტიური მონაცემები და სარგებო მონაცემებით (მართლა შემდეგ ჩვენ სისტემის კომპრექტირებით ცნობიერების დისტლიაციის გამოყენებით, რომ პარამეტრების შემცირებით, მაგრამ უფრო ძალიან გამოყენ ჩვენი მრავალენგური სისტემები მრავალენგური სისტემებში მრავალენგური და ყველა 11 ინდიველური ენგური კონფიგურაციაში გამოყენება, რომელიც ნულ-ს', 'it': 'Questo articolo descrive la presentazione di Papago al WMT 2021 Quality Estimation Task 1: Valutazione diretta a livello di frase. Il nostro sistema multilingue di valutazione della qualità esplora la combinazione di modelli linguistici pretrained e architetture di apprendimento multi-task. Proponiamo una pipeline di formazione iterativa basata sul pretraining con grandi quantità di dati sintetici in-domain e la finetuning con dati oro (etichettati). Comprimiamo quindi il nostro sistema tramite distillazione della conoscenza al fine di ridurre i parametri pur mantenendo forti prestazioni. I nostri sistemi multilingue presentati funzionano in modo competitivo nelle impostazioni multilingue e in tutte le 11 coppie linguistiche individuali, incluso zero-shot.', 'lt': 'Šiame dokumente aprašoma Papago pateikta WMT 2021 kokybės vertinimo 1 užduotis: tiesioginis nuosprendžių vertinimas. Mūsų daugiakalbės kokybės vertinimo sistema tiria iš anksto mokomų kalbų modelių ir daugiakalbių mokymosi architektūrų derinį. Siūlome pakartotinį mokymo vamzdyną, pagrįstą išankstiniu mokymu su dideliais domeninių sintetinių duomenų kiekiais ir tobulinimu aukso (pažymėtais) duomenimis. Tuomet suspaudžiame savo sistemą, distiliuodami žinias, kad sumažintume parametrus ir išlaikytume stiprius rezultatus. Mūsų pateiktos daugiakalbės sistemos konkuruoja daugiakalbėse ir visose 11 atskirose kalbų porose, įskaitant nulinę nuotrauką.', 'mk': 'Овој документ го опишува поднесувањето на Папаго на WMT 2021 задачата за проценка на квалитетот 1: Директна проценка на нивото на пресуда. Нашиот мултијазичен систем за проценка на квалитетот ја истражува комбинацијата на претренирани јазички модели и архитектури за учење на мултијазични задачи. Предложуваме итеративен гасовод за обука базиран на преобука со големи количини синтетички податоци во доменот и финетирање со златни (означени) податоци. Потоа го компресираме нашиот систем преку дистилација на знаење со цел да ги намалиме параметрите и да одржуваме силни резултати. Нашите поднесени мултијазични системи се конкурентни во мултијазични и сите 11 индивидуални поставувања на парови јазици вклучувајќи нула-снимка.', 'ms': 'Kertas ini menggambarkan penghantaran Papago ke Perkiraan Kualiti WMT 2021 Tugas 1: Perkiraan langsung aras-hukuman. Sistem penilaian Kualiti Berbahasa kami mengeksplorasi kombinasi Model Bahasa Terlatih dan Arkitektur Belajar Berbanyak Tugas. Kami cadangkan saluran paip latihan iteratif berdasarkan pralatihan dengan jumlah besar data sintetik dalam domain dan penentuan dengan data emas (labeled). Kemudian kita memaksa sistem kita melalui pengusiran pengetahuan untuk mengurangi parameter tetapi menjaga prestasi yang kuat. Sistem berbilang bahasa yang kami hantar berkompetitif dalam seting berbilang bahasa dan semua 11 pasangan bahasa individu termasuk 0-shot.', 'ml': 'This paper describes Papago submission to the WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment.  ഞങ്ങളുടെ പല ഭാഷകങ്ങളുടെ ഗുണവുമായ എസ്റ്റിമേഷന്\u200d സിസ്റ്റം പരിശോധിക്കുന്ന ഭാഷ മോഡലുകളുടെ കൂട്ടത്തില്\u200d പരിശോധിക് നമ്മള്\u200d ഒരു സാധാരണ പരിശീലനത്തിന്റെ പൈപ്പെലിന്\u200d പ്രെയിന്\u200d ചെയ്യുന്നു. ഡോമെന്\u200d സിന്തെറ്റിക്ക് ഡേറ്റായിട്ടുള്ള വലിയ വിവരങ് പിന്നീട് നമ്മുടെ സിസ്റ്റത്തെ അറിവുകള്\u200d വേര്\u200dപെടുത്തുവാന്\u200d വേണ്ടി നമ്മള്\u200d പരാമീറ്ററുകള്\u200d കുറവാക്കുവാ ഞങ്ങളുടെ മുതല്\u200d ഭാഷ സിസ്റ്റമുള്ള സംവിധാനങ്ങള്\u200d പല ഭാഷകളിലും പൂര്\u200dണ്ണമായി വെടിവെക്കുന്ന എല്ലാ 11 വ്യക്തിപരമായ ഭാഷ ജോ', 'kk': 'Бұл қағаз Папаго WMT 2021 сапасының оценкасының 1- ші тапсырмасы: сөз деңгейіндегі тікелей оценкасына жіберілсін. Біздің көптілік сапатты оқу жүйесіміз Тіл үлгілерін және көп тапсырмаларды оқу архитектураларының біріктірімін зерттеді. Біз домендегі синтетикалық деректер мен алтын (жарлық) деректерінің көп деңгейінде негізделген қайталау кеңіл сызығын ұсынамыз. Содан кейін білім дистилациясы арқылы жүйемізді басып, параметрлерді азайту үшін күшті істеу үшін көмектесеміз. Біздің көптілік тілдер жүйелеріміз көптілік тілдерде және 11 тілдердің екі параметрлерінде нөл шарттары бар.', 'mn': 'Энэ цаас Papago-ын WMT 2021-ийн качествен оюун шалгалтын ажил 1: өгүүлбэр-түвшинд шууд оюун шалгалтыг тайлбарладаг. Бидний олон хэл хэлний чадварын оюун ухааны систем "Pretrained Language Models" болон "Multi-task Learning Architects" бүтээлийг судалдаг. Бид холбоотой их хэмжээний синтетик өгөгдлийг, алт (нэрлэгдсэн) өгөгдлийг дахин дахин дасгал хөдөлгөөн шугам суурилуулдаг. Дараа нь бид системийг мэдлэг сайжруулахын тулд хүчтэй үйл ажиллагааг багасгахын тулд нэгтгэдэг. Бидний олон хэл системүүд олон хэл болон 11 хэл хоёр төлөвлөгөөнд өрсөлдөг байдаг.', 'no': 'Denne papiret beskriver Papago-tilføring til WMT 2021-kvalitetevalueringsoppgåva 1: Direkt vurdering av setningsnivå. Vårt multispråk kvalitetevalueringssystem utforskar kombinasjonen av språk- modeller og fleiroppgåver- læringsarkitekturar. Vi foreslår ein reinterativ treningsrøyr basert på å trekke med store mengdar syntetiske data i domenet og finetuning med gull (merket) data. Vi komprimerer systemet vårt derfor ved å distillera kunnskap for å redusera parametrar enno gjere sterke funksjonar. Våre tildelte fleirspråksystemet utfører konkurrentivt i fleirspråksystemet og alle 11 individuelle språkspar-innstillingar, inkludert nullsatt.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie Papago do WMT 2021 Quality Estimation Task 1: bezpośrednia ocena na poziomie zdania. Nasz wielojęzyczny system oceny jakości bada połączenie wstępnie przeszkolonych modeli językowych i architektur nauki wielozadaniowej. Proponujemy iteracyjną pipelinę szkoleniową opartą na wstępnym treningu z dużą ilością syntetycznych danych wewnątrz domeny i precyzyjnym dostrajaniu złotymi (etykietowanymi) danymi. Następnie kompresujemy nasz system poprzez destylację wiedzy w celu zmniejszenia parametrów przy jednoczesnym utrzymaniu silnej wydajności. Nasze przesłane systemy wielojęzyczne działają konkurencyjnie w wielojęzycznych i wszystkich 11 indywidualnych parach językowych, w tym zero-shot.', 'ro': 'Această lucrare descrie depunerea Papago la misiunea de estimare a calității WMT 2021 1: Evaluarea directă la nivel de sentință. Sistemul nostru multilingv de estimare a calității explorează combinația dintre modelele lingvistice pretrained și arhitecturile de învățare multi-sarcină. Propunem o conductă de instruire iterativă bazată pe pregătire cu cantități mari de date sintetice în domeniu și finetuning cu date aurii (etichetate). Apoi comprimăm sistemul nostru prin distilarea cunoștințelor pentru a reduce parametrii și menține performanțe puternice. Sistemele noastre multilingve prezentate funcționează competitiv în setări multilingve și toate cele 11 perechi de limbi individuale, inclusiv zero-shot.', 'sr': 'Ovaj papir opisuje podnošenje Papaga na zadatak za procjenu kvalitete WMT 2021: Direktna procjena nivoa kazne. Naš multijezički sistem procjene kvalitete istražuje kombinaciju preliječenih jezičkih modela i multitask učenja arhitekture. Predlažemo iterativnu potrebnu liniju za obuku na osnovu pretreniranja velikim količinama sintetičkih podataka u domenu i finetuniranja zlatnim podacima. Onda kompresiramo naš sistem putem destilacije znanja kako bi smanjili parametre, a ipak održali jaku funkciju. Naši podnošeni multijezički sistemi izvode konkurentno na multijezičkim i svih 11 individualnih postavljanja jezičkih parova uključujući nulu šansu.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjoni ta’ Papago għad-WMT 2021 Task 1 ta’ Stima tal-Kwalità: Valutazzjoni Diretta fil-livell tas-Sentenza. Is-sistema ta’ Stima ta’ Kwalità multilingwi tagħna tesplora l-kombinazzjoni ta’ Mudelli ta’ Lingwi Mħarrġa minn Qabel u arkitetturi ta’ Tagħlim Multi-Kompiti. Aħna nipproponu pipeline ta’ taħriġ iterattiv ibbażat fuq taħriġ minn qabel b’ammonti kbar ta’ dejta sintetika fid-dominju u l-irfinar b’dejta tad-deheb (ittikkettata). Imbagħad inkompressaw is-sistema tagħna permezz tad-distillazzjoni tal-għarfien sabiex inaqqsu l-parametri iżda nżammu prestazzjoni qawwija. Is-sistemi multilingwi ppreżentati tagħna jwettqu b’mod kompetittiv f’setturi multilingwi u l-11-il pari individwali tal-lingwa inklużi zero-shot.', 'so': "Kanu wuxuu warqaddan ka qoran yahay Papago oo loo soo dhiibay WMT 2021 Shaqada Qiimaanta Estimation 1: Heymiska xisaabta-level Direct Assessment. Istixaankayada qiimaynta luuqadaha kala duduwan wuxuu baaraandegayaa qalabka la bartay iyo dhismaha waxbarashada farsamada badan. Waxaynu soo jeedaynaa qoraal wax lagu baranayo oo ku saleysan qoraal aad u badan oo ka mid ah macluumaad koontarooyinka internetka iyo faa'iido ku leh macluumaad dahab ah (labeled). Markaas waxaynu nidaamka ku koobannaa aqoonta si aan u hoos dhigno parameteryadu weli u sii socono sameynta xoogga leh. nidaamka luuqadaha kala duduwan ee la soo dhiibay waxay si iskutaal ah u sameeyaan af luuqad kala duduwan iyo 11 xarumaha labada luuqadood oo kali ah, kuwaas oo ah nooca ganacsi.", 'si': 'මේ පැත්තේ පාපාගෝ විස්තර කරන්නේ WMT 2021 කුළුවත් අවශ්\u200dය අවශ්\u200dය වැඩ 1: වාර්තාව- ස්ථානය ප්\u200dරතිකාරය අවශ්\u200dයාවක අපේ ගොඩක් භාෂාවික කුළුවත් අනුමාණ පද්ධතිය ප්\u200dරීට්\u200dරේන්ඩ් භාෂ මොඩේල්ස් සහ ගොඩක් වැඩක් ඉගෙන ගන්න ස අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ් ඊට පස්සේ අපේ පද්ධතිය දැනගන්න විශේෂයෙන් ප්\u200dරමාණය අඩු කරන්න අපේ පද්ධතිය සම්පූර්ණය කරනවා. අපේ ගොඩක් භාෂාත්මක පද්ධතිය සම්පූර්ණයෙන් ගොඩක් භාෂාත්මක වලට සම්පූර්ණයෙන් සම්පූර්ණයෙන්', 'sv': 'Denna uppsats beskriver Papago inlämnande till WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment. Vårt flerspråkiga kvalitetsberäkningssystem utforskar kombinationen av prerained språkmodeller och Multi-Task Learning arkitekturer. Vi föreslår en iterativ träningspipeline baserad på förberedelse med stora mängder syntetiska data inom domänen och finjustering med guld (märkt) data. Vi komprimerar sedan vårt system via kunskapsdestillation för att minska parametrarna samtidigt som vi bibehåller en stark prestanda. Våra inlämnade flerspråkiga system presterar konkurrenskraftigt i flerspråkiga och alla 11 individuella språkparsinställningar inklusive nollskott.', 'ta': 'இந்த தாள் WMT 2021 தரமான கணக்கீட்டு பணிக்கு கூடிய பாப்போக்கு குறிப்பிடுகிறது 1: வாக்கியம்- நேரடி மதிப்பு. எங்கள் பல மொழிகளின் தரம் கணக்கீட்டு அமைப்பு முன்னேற்றப்பட்ட மொழி மாதிரிகளின் சேர்ப்பு மற்றும் பல பணி கற்றுக் கொண்டிருப நாம் ஒரு உருவாக்க பயிற்சி பைப்லைனை திருந்திக்கொள்கிறோம். பெரிய தொகுதி தகவல் மூலம் பெரிய தொகுதி மற்றும் பொருள் (அடையாளம்) தக We then compress our system via knowledge distillation in order to reduce parameters yet maintain strong performance.  எங்கள் மொழிமொழிமாற்று அமைப்புகள் பல மொழியில் பொருத்தமாக செய்கிறது மற்றும் எல்லா 11 தனிமொழியின் ஜோட் அமைப்புகளும்', 'ur': 'This paper describes Papago submission to the WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment. ہماری بہت سی زبان کی کیفیت کی آسانی سیسٹم پررین زبان مدلز اور بہت سی ٹاکس کی تعلیم معماری کی پیدا کرتی ہے. ہم ایک دوبارہ تطارین پیپ لین کی پیشنهاد کرتے ہیں جو ڈومین میں بہت سینٹیسی ڈاٹی اور سونے کے (لابلیٹ) ڈاٹوں سے زیادہ زیادہ سینٹیسی ڈاٹی کے ساتھ روشن کرتی ہے۔ پھر ہم نے اپنے سیستم کو علم الفاظت کے ذریعہ مضبوط کر دیا تاکہ پارامیٹروں کو کمزور کر دیں حالانکہ طاقت کے کامیابی کی حفاظت کریں. ہمارے مزید زبان کی سیستموں کو ملتی زبان میں اور تمام 11 زبان جوڑوں کے سامنے صفر-شٹ کے شامل مہربانی سے کام لیتے ہیں.', 'vi': 'Tờ giấy này mô tả gởi gởi Papago tới công việc dự đoán chất lượng WM 2021: đánh giá trực tiếp đường phố. Hệ thống ước lượng chất lượng đa dạng của chúng tôi nghiên cứu cấu trúc ngôn ngữ sẵn sàng và kiến trúc đa công việc học. Chúng tôi đề xuất một ống đào tạo lặp lại dựa trên việc sản xuất sản xuất với một lượng lớn dữ liệu nhân tạo trong miền và độ cẩn thận với dữ liệu vàng (nhãn). Sau đó chúng ta sẽ thu nhỏ hệ thống bằng việc chưng cất kiến thức để giảm các tham số nhưng có hiệu suất mạnh. Những hệ thống ngôn ngữ đa dạng được gửi đến sẽ được hoàn thiện cạnh tranh trong các thiết lập cặp ngôn ngữ khác nhau.', 'uz': "Bu qogʻoz WMT 2021 Quality Estimatsiya Vazifani Papago ishlatishni tahrirlaydi 1: Sensor- darajasi direkt Assessment. Bizning ko'pgina tillar qiymati tizimimiz o'rganilgan tillar modellari va bir necha vazifa o'rganish maktablarini birlashtiradi. Biz bir tashqi tibbiy o'rganish pipelining asosida, domen'ning katta bir necha tizim haqida qo'yish va nuqta (teglangan) maʼlumotlar bilan bir necha tizim bilan ishlatishni anglatamiz. Keyin, parametrlarni kamaytirish uchun tizimmizni aniqlash orqali murojaat qilamiz. Bizning ko'plab tillar tizimlarimiz bir tilda rivojlanish va hamma 11 tillar ikki xil moslamalari nuqta qo'llangan.", 'da': 'Dette dokument beskriver Papago indsendelse til WMT 2021 Quality Estimation Opgave 1: Direkte vurdering på sætningsniveau. Vores flersprogede kvalitetsestimeringssystem udforsker kombinationen af prætrænede sprogmodeller og Multi-task Learning arkitekturer. Vi foreslår en iterativ træningspipeline baseret på foruddannelse med store mængder syntetiske data inden for domænet og finjustering med guld (mærket) data. Vi komprimerer derefter vores system via videndedestillation for at reducere parametrene og samtidig opretholde en stærk ydeevne. Vores indsendte flersprogede systemer fungerer konkurrencedygtigt i flersprogede og alle 11 individuelle sprogpar indstillinger, herunder zero-shot.', 'nl': 'Dit artikel beschrijft Papago inzending aan de WMT 2021 Kwaliteitsschattingstaak 1: Direct Assessment op zinsniveau. Ons meertalige kwaliteitsschattingssysteem verkent de combinatie van voorgetrainde taalmodellen en multitask leerarchitecturen. We stellen een iteratieve trainingspipeline voor op basis van pretraining met grote hoeveelheden in-domain synthetische data en finetuning met gouden (gelabelde) data. Vervolgens comprimeren we ons systeem via kennisdestillatie om parameters te verminderen en tegelijkertijd sterke prestaties te behouden. Onze ingediende meertalige systemen presteren concurrerend in meertalige en alle 11 individuele taalparen instellingen, inclusief zero-shot.', 'bg': 'Тази статия описва подаването на Папаго към задача 1 за оценка на качеството на ММТ 2021: Директна оценка на ниво присъда. Нашата многоезична система за оценка на качеството изследва комбинацията от предварително обучени езикови модели и архитектури за многозадачи за обучение. Предлагаме итеративен тренировъчен канал, базиран на предтренинг с големи количества синтетични данни в домейна и фина настройка със златни (етикетирани) данни. След това компресираме нашата система чрез дестилация на знания, за да намалим параметрите и да поддържаме силна производителност. Нашите представени многоезични системи работят конкурентно в многоезични и всички 11 индивидуални настройки за езикови двойки, включително нулев изстрел.', 'hr': 'Ovaj papir opisuje podnošenje Papaga zadatku za procjenu kvalitete WMT 2021: Direktna procjena razine kazne. Naš multijezički sistem procjene kvalitete istražuje kombinaciju preliječenih jezičkih modela i arhitektura učenja višestrukih zadataka. Predlažemo iterativnu cijevinu obuke na temelju pretkivanja velikim količinama sintetičkih podataka u domenu i finetuniranja zlatnim podacima. Zatim kompresiramo naš sustav putem destilacije znanja kako bi smanjili parametre i dalje održali jaku učinku. Naši podnošeni multijezički sustavi izvode konkurentno na višejezičkim i svih 11 pojedinačnih postavljanja jezičkih parova uključujući nulu šansu.', 'de': 'Dieses Papier beschreibt Papago Einreichung an die WMT 2021 Quality Estimation Task 1: Satzence-level Direct Assessment. Unser mehrsprachiges Qualitätsschätzungssystem untersucht die Kombination von vortrainierten Sprachmodellen und Multi-Task Learning Architekturen. Wir schlagen eine iterative Trainingspipeline vor, die auf Vortraining mit großen Mengen an synthetischen In-Domain-Daten und Feinabstimmung mit Gold-Daten basiert. Anschließend komprimieren wir unser System mittels Wissensdestillation, um Parameter zu reduzieren und gleichzeitig eine starke Leistung zu erhalten. Unsere eingereichten mehrsprachigen Systeme funktionieren wettbewerbsfähig in mehrsprachigen und allen 11-individuellen Sprachpaareinstellungen einschließlich Zero-Shot.', 'id': 'Kertas ini menjelaskan pengiriman Papago ke WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment. Sistem penghargaan kualitas berbagai bahasa kami mengeksplorasi kombinasi Model Bahasa Terlatih dan Arkitektur Belajar Berbanyak Tugas. Kami mengusulkan sebuah pipa latihan iteratif berdasarkan pretraining dengan jumlah besar data sintetis dalam domain dan finetuning dengan data emas (labeled). Kemudian kita mengkompresi sistem kita melalui destilasi pengetahuan untuk mengurangi parameter namun mempertahankan prestasi yang kuat. Sistem berbagai bahasa yang kami berikan berkompetitif dalam berbagai bahasa dan semua 11 pengaturan pasangan bahasa individu termasuk zero-shot.', 'sw': 'Papa hii inaelezea kuasilishwa kwa Papago kwenye kazi ya Hesabu ya WMT 2021 1: Tathmini ya moja kwa moja ya Hukumu. Mfumo wetu wa Hesabu ya Kilugha unagundua muunganiko wa Modela za Lugha zilizojifunza na majengo mengi ya Kujifunza. Tunazipendekeza pipeli ya mafunzo ya vizuri inayotumiwa na kutengeneza matumizi makubwa ya data za pamoja na kutoa faini kwa takwimu za dhahabu (zilizowekwa alama). Kisha tunashinikiza mfumo wetu kwa kupitia utofauti wa maarifa ili kupunguza vipimo bado kuendelea na utendaji mzuri. Mifumo yetu iliyotolewa kwa lugha mbalimbali hufanya ushindani katika lugha mbalimbali na vituo vyote 11 vya lugha binafsi ikiwa ni pamoja na risasi sifuri.', 'tr': "Bu kağıt WMT 2021'in kalitesi Tahmin Görevi 1'ne Papago teslim edilmesini tasvir ediyor: Söz-düzey Direkt Tahmin Et. Bizim çoklu dillerimizin kalitesi tahmin sistemimiz Pretrained Dil Modelleri ve Çoklu-task öğrenme arhitektarlarının birleşmesini keşfetýär. Biz domain sintetik verileri ve altın (etiket edilen) verilerine dayanan bir tekrar eğitim borusunu teklif ediyoruz. Sonra sistemimizi bilgi taslaması bilen birleştirmek üçin parametreleri düşürmek üçin ýüzüne süýtgedýäris. Biziň gönderilen köp dilli sistemalarymyz birnäçe dil we ähli 11 dil çift düzümlerini 0 aty bilen duşuşykly edip otyrýarlar.", 'fa': 'این کاغذ پاپاگو را توصیف می\u200cکند که ارزیابی مستقیم مرحله\u200cی قوانین WMT 2021 را توصیف می\u200cکند. سیستم ارزیابی کیفیت زیادی زبان ما ترکیب مدلهای زبان زیادی و معماری یادگیری زیادی را کشف می کند. ما پیشنهاد می\u200cکنیم یک لوله تمرین دوباره بر اساس تغییر کردن با مقدار زیادی از داده\u200cهای سینتاتیک در دامنه\u200cها و تغییر با داده\u200cهای طلا (برچسب) را پیشنهاد کنیم. سپس سیستم\u200cمون را با توسط جدا کردن دانش به تزریق می\u200cدهیم تا پارامترها را کاهش دهیم و هنوز عملکرد قوی را حفظ کنیم. سیستم\u200cهای زیادی زبان\u200cهای ما با رقابت در زبان\u200cهای زیادی و همه ۱۱ تنظیم جفت زبان\u200cهای فردی، شامل صفر، انجام می\u200cدهند.', 'ko': '본고는 Papago가 WMT 2021 품질 평가 임무에 제출한 1: 문장 수준 직접 평가를 묘사한다.우리의 다중 언어 품질 평가 시스템은 예비 훈련 언어 모델과 다중 임무 학습 구조의 결합을 탐색했다.우리는 대량의 역내 합성 데이터에 대한 예비 훈련과 황금 (표기) 데이터에 대한 미세한 조정을 바탕으로 하는 교체 훈련 파이프를 제시했다.그리고 우리는 지식 추출을 통해 시스템을 압축하여 파라미터를 줄이고 강력한 성능을 유지한다.우리가 제출한 다중 언어 시스템은 다중 언어와 모든 11개 언어가 설정 (제로 샷 포함) 에 있어 경쟁력이 있다.', 'af': "Hierdie papier beskrywe Papago onderskrywing na die WMT 2021 Kwaliteit Estimasie Opdrag 1: Woord- vlak Direkte Assensie. Ons multitaalske Kwaliteit Estimation stelsel ondersoek die kombinasie van Pretrained Language Models en Multi-task Learning Architects. Ons voorstel 'n iteratiewe onderwerp pyplyn gebaseer op voorwerp met groot hoeveelheid in domein sintetiese data en finetuning met goud (etiket) data. Ons komprimeer dan ons stelsel deur kennis destilasie om parameters nog sterk prestasie te verminder. Ons ingestuur multitaalske stelsels uitvoer kompetief in multitaalske en al 11 individuele taalspaar instellings insluitend nulskoot.", 'am': 'ይህ ፕሮግራም ለWMT 2021 ብጤት ስራውን ለማስታወቂያ ለባቡክ ይገልጻል፡፡ የቋንቋዎች ብዛት ስርዓት ስርዓታችን የተጠቃሚ የቋንቋ ሞዴል እና የብዙ ትምህርት መሠረት መሠረትን ይፈልጋል፡፡ የዶሜን አካላዊ ዳታዎች እና የወርቅ (ቀለበ) ዳታዎችን በመፍጠር የተመሳሳይ የኢንተርኔት ማህበረሰብ ፕላይንን እናሳልቃለን፡፡ በዚያን ጊዜም እውቀት መለያየትን እናሳድጋለን፡፡ የብዙልቋንቋዎች ስርዓታችን በቋንቋ እና 11 የቋንቋ ሁለትን አካባቢዎች በቁጥር ቁጥጥር እና በቁጥጥር ይደረጋሉ፡፡', 'bn': 'এই পত্রিকাটি ব্যাখ্যা করেছে যে পাপাগাকে উইএমটি ২০২১ মান গণনা কাজের প্রতি প্রদান করা হয়েছে: শাস্তি-স্তরের সরাসরি মূ আমাদের মাল্টিভাষার মান গণনা সিস্টেম প্রশিক্ষিত ভাষা মডেল এবং বহুভাষী কাজ শিক্ষা শিক্ষা কাঠামো সম্পর্কে বিশেষ কর আমরা একটি প্রশিক্ষণ প্রস্তাব করি ডোমেইনের বিশাল পরিমাণ সিন্টেটিক ডাটা এবং স্বর্ণ (লেবেলেড) ডাটা দিয়ে স্বর্ণের সাথে বৃষ্টির ভিত্ তারপর আমরা জ্ঞানের বৈচিত্র্যের মাধ্যমে আমাদের সিস্টেম কমিয়ে দেই যাতে এখনও শক্তিশালী প্রভাব রাখার জন্য। আমাদের মাল্টিভাষার ব্যবস্থা প্রতিযোগিতায় প্রতিযোগিতা করা হয়েছে বহুভাষায় এবং সকল ১১ ভাষার জোড়া বৈশিষ্ট্য, যার', 'az': 'Bu kağıt Papago WMT 2021 Növbəti Görüntülmə Görüntülməsi 1: Sözü-səviyyəsi Direkt Görüntülməsi üçün təsdiqləyir. Bizim çoxlu dil Quality Estimation sistemimiz Pretrained Dil Modellərinin və Multi-task öyrənmə arhitektarının birləşdirilməsini keşfetir. Biz böyük dəyişiklik sintetik məlumatları və altın (etiketli) məlumatları ilə dəyişiklik etməyə dayanan bir tekrar təhsil pipeline təklif edirik. Sonra sistemimizi elm destilasyonu ilə sıkıştırırıq ki, parametroları azaltmaq üçün, hətta güclü performansı qorumaq üçün. Bizim göndərilmiş çoxlu dil sistemləri çoxlu dildə və tüm 11 dil çift ayarlarında sıfır şəkildə mübahisə edirlər.', 'bs': 'Ovaj papir opisuje podatak Papaga na procjenu kvalitete WMT 2021 zadatak 1: Direktna procjena razine kazne. Naš multijezički sistem procjene kvalitete istražuje kombinaciju preliječenih jezičkih modela i arhitektura učenja više zadataka. Predlažemo iterativnu cijevinu obuke na temelju pretkivanja velikim količinama sintetičkih podataka u domenu i finetuniranja zlatnim podacima. Zatim kompresiramo naš sistem putem destilacije znanja kako bi smanjili parametre i dalje održali jaku funkciju. Naši podnošeni multijezički sistemi izvode konkurentno na multijezičkim i svih 11 individualnih postavljanja jezičkih parova, uključujući nulu šansu.', 'ca': "Aquest paper descriu la presentació de Papago a la tasca 1 d'estimació de qualitat del WMT 2021: Evaluació directa del nivell de sentencia. Our multilingual Quality Estimation system explores the combination of Pretrained Language Models and Multi-task Learning architectures.  Proposem un tub iteratiu d'entrenament basat en pré-entrenament amb grans quantitats de dades sintètiques en domini i finament ajustad amb dades d'or (etiquetades). Llavors comprimim el nostre sistema a través de la distillació del coneixement per reduir els paràmetres però mantenim un fort rendiment. Els nostres sistemes multillengües submetits actuen competitivament en configuracions multillengües i totes les onze parelles individuals de llengües, incloent fotografies zero.", 'cs': 'Tento článek popisuje podání Papaga do WMT 2021 Quality Estimation Task 1: přímé hodnocení na úrovni věty. Náš vícejazyčný systém odhadu kvality zkoumá kombinaci předcvičených jazykových modelů a architektur víceúkolového učení. Navrhujeme iterativní tréninkovou pipelinu založenou na předtréninku s velkým množstvím syntetických dat v doméně a jemném ladění zlatými (označenými) daty. Náš systém pak stlačujeme pomocí znalostní destilace, abychom snížili parametry a přitom udrželi silný výkon. Naše předložené vícejazyčné systémy fungují konkurenčně ve vícejazyčném nastavení a ve všech 11 individuálních jazykových párech včetně nulového záběru.', 'hy': "Այս հոդվածը նկարագրում է Պափագոյի ներկայացումը ԱՄԹ 2021-ի որակի գնահատման առաջին հանձնարարությանը' դատաստանի մակարդակի ուղղակի գնահատման: Մեր բազլեզու որակի գնահատման համակարգը ուսումնասիրում է նախապատրաստված լեզվի մոդելների և բազլեզու խնդիրներ սովորելու ճարտարապետությունների համադրությունը: Մենք առաջարկում ենք կրկնվող փորձարկումների խողովակաշար, որը հիմնված է նախավարժման մեծ քանակությամբ բնագավառի սինթետիկ տվյալներով և փորձարկման ոսկու (պիտակուցված) տվյալներով: Այնուհետև մենք ընդլայնում ենք մեր համակարգը գիտելիքների դիսլիլացիայի միջոցով, որպեսզի նվազեցնենք պարամետրերը, սակայն պահպանենք ուժեղ արդյունավետությունը: Մեր ներկայացված բազլեզու համակարգերը համընդհանուր կերպ են գործում բազլեզու և բոլոր 11 անհատական լեզվի զույգերի միջոցով, ներառյալ զրոյի նկարները:", 'sq': 'Ky dokument përshkruan paraqitjen e Papagos në WMT 2021 Qëllimi i Vlerësimit të Kualitetit Task 1: Vlerësimi i drejtpërdrejtë në nivelin e dënimit. Our multilingual Quality Estimation system explores the combination of Pretrained Language Models and Multi-task Learning architectures.  Ne propozojmë një tubacion trajnimi të përsëritur bazuar në paratrajnimin me sasi të mëdha të dhënash sintetike në domeni dhe përmirësimin me të dhënat e artë (të etiketuara). Pastaj kompresojmë sistemin tonë nëpërmjet distillacionit të njohurive me qëllim që të zvogëlojmë parametrat dhe të mbajmë performancë të fortë. Sistemet tona shumëgjuhëse paraqiten konkurruesisht në shumëgjuhës dhe të gjitha 11 përcaktimet individuale të çifteve gjuhësh duke përfshirë zero-shot.', 'et': 'Käesolevas artiklis kirjeldatakse Papago esitamist WMT 2021 kvaliteedi hindamise ülesandele 1: karistustaseme otsene hindamine. Meie mitmekeelne kvaliteedi hindamise süsteem uurib eelnevate keelemudelite ja mitme ülesandega õppe arhitektuuride kombinatsiooni. Pakume välja iteratiivse koolitusjuhtme, mis põhineb eeltreeningul, millel on suured kogused domeenisisesed sünteetilised andmed ja peenhäälestus kuldsete (märgistatud) andmetega. Seejärel surume oma süsteemi teadmiste destilleerimise teel kokku, et vähendada parameetreid, kuid säilitada tugev jõudlus. Meie esitatud mitmekeelsed süsteemid toimivad konkurentsivõimeliselt mitmekeelses ja kõigis 11 individuaalses keelepaari seadistuses, sealhulgas null-shot.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvataan Papagon lﾃ､hettﾃ､mistﾃ､ WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment -ohjelmaan. Monikielinen laadunarviointijﾃ､rjestelmﾃ､mme tutkii esikoulutettujen kielimallien ja monitehtﾃ､vﾃ､oppimisen arkkitehtuurien yhdistelmﾃ､ﾃ､. Ehdotamme iteratiivista harjoitusputkea, joka perustuu esikoulutukseen, jossa on suuria mﾃ､ﾃ､riﾃ､ sisﾃ､istﾃ､ synteettistﾃ､ dataa ja hienosﾃ､ﾃ､tﾃｶﾃ､ kultaisilla (merkityillﾃ､) tiedoilla. Tﾃ､mﾃ､n jﾃ､lkeen puristamme jﾃ､rjestelmﾃ､mme tietﾃ､myksen tislauksen avulla, jotta parametreja voidaan pienentﾃ､ﾃ､ ja samalla sﾃ､ilyttﾃ､ﾃ､ vahva suorituskyky. Toimitetut monikieliset jﾃ､rjestelmﾃ､mme toimivat kilpailukykyisesti monikielisissﾃ､ ja kaikilla 11 yksittﾃ､isellﾃ､ kielipariasetuksella, mukaan lukien nollakuva.', 'jv': 'Ngerti wigat-wigat nggawe barang papagan tarjamahan kanggo nggawe WWT 2020 1 kalitas Ukusambarang nggawe barang 1: Sentense-evel Kita multi-language Quality Esmation sistem buktuang nggambar aturan Layout model karo Multi-task Learning architectures. We proposal an item ratiove tutorial wireline supported on presining with big amounts of in-domain format and Finetuning with golf (label) data. Awak dhéwé ngerasakno sistem dhéwé nang ngerasakno dadi nggawe gerakan perangkamus karo nggawe barang nggawe barang nggawe Awak dhéwé ngewat sistem sing sampeyan luwih akeh pengguna sakjane neng sampeyan liyang lan saben tanggal 11 sampeyan kanggo nggawe ngubah 0.', 'he': 'העיתון הזה מתאר את ההעברה של פאפגו למשימת הערכת איכות WMT 2021 משימה 1: הערכה ישירה רמת גזר. מערכת הערכת איכות רבת-שפותית שלנו חוקרת את שילוב של דוגמני שפות מתאמנים מראש וארכיטקטורות ללמוד רבות-משימות. אנו מציעים צינור אימון איטרטיבי מבוסס על אימון מראש עם כמויות גדולות של נתונים סינטטיים בתחום ומתמודדים עם נתונים זהבים. We then compress our system via knowledge distillation in order to reduce parameters yet maintain strong performance.  Our submitted multilingual systems perform competitively in multilingual and all 11 individual language pair settings including zero-shot.', 'ha': "Wannan takardan na faɗaɗa Gabbaprevi da aka jẽfa wasiyyar da wa WMT 2021 Quality Taimation 1: Percement-levels Direct Assistance. Ana karatun tsarin Kiawa na mulki-lingui na gane koma na Modalla na Pre-Trainin Lugha da Akwai masu Shirin Ayuka da Akwai masu yawa. Tuna goyya da wani runnin tamkar ta'urata, a kan karatun da bakin matuƙar yawan data na cikin-Domen da fintutura da data (wanda aka rubũta). Sa'an nan kuma muna fizge kanmu da fassarar da ilmi dõmin a ƙara parameter ko da za'a kiyaye mafiya ƙarfi. Zuwa'umyinMu da aka shigar da wasu na'ura, sai su yi gaugawa a cikin mulki-lingui, da dukkan kowane misalin harshe guda da sauri guda, tare da sifiri.", 'bo': 'This paper describes Papago submission to the WMT 2021 Quality Estimation Task 1: Sentence-level Direct Assessment. ང་ཚོའི་སྐད་ཡིག་ཆ་དབྱེ་སྟངས་ལྡན་གྱི་མ་ལག་གིས་ས Pretrained Language Models དང་Multi-task Learning architectures་གི་མཉམ་དུ་འཚོལ་ཞིབ་ཀྱི་ཡོད། We propose an iterative training pipeline based on pretraining with large amounts of in-domain synthetic data and finetuning with gold (labeled) data. Then compress our system via knowledge distillation in order to reduce parameters yet maintain strong performance. ང་ཚོའི་སྐད་ཡིག་ཆ་མང་པོ་ཞིག་གིས་སྐད་ཡིག་ཆ་དང་སྐད་ཡིག་ཆ་གཅིག་གི་སྒྲིག་སྟངས', 'sk': 'Ta prispevek opisuje predložitev Papaga v nalogo ocenjevanja kakovosti WMT 2021 1: Neposredna ocena na ravni kazni. Naš večjezični sistem ocenjevanja kakovosti raziskuje kombinacijo predtreniranih jezikovnih modelov in arhitektur večopravilnega učenja. Predlagamo iterativni program usposabljanja, ki temelji na predurjenju z velikimi količinami sintetičnih podatkov v domeni in fini nastavitvi z zlatimi (označenimi) podatki. Nato stisnemo naš sistem z destilacijo znanja, da bi zmanjšali parametre in ohranili močno zmogljivost. Naši predloženi večjezični sistemi delujejo konkurenčno v večjezičnih in vseh 11 nastavitvah posameznih jezikovnih parov, vključno z ničelnim strelom.'}
{'en': 'NICT Kyoto Submission for the WMT’21 Quality Estimation Task : Multimetric Multilingual Pretraining for Critical Error Detection', 'es': "Presentación de NICT Kyoto para la tarea de estimación de la calidad del WMT'21: preentrenamiento multilingüe multimétrico para la detección de errores críticos", 'fr': "Soumission NICT Kyoto pour la tâche d'estimation de la qualité WMT'21\xa0: Préformation multimétrique multilingue pour la détection des erreurs critiques", 'ar': "تقديم NICT Kyoto لمهمة تقدير الجودة WMT'21: التدريب المسبق متعدد اللغات متعدد اللغات لاكتشاف الأخطاء الحرجة", 'pt': "Apresentação NCT Kyoto para a Tarefa de Estimativa de Qualidade do WMT'21: Pré-treinamento Multimétrico Multilíngue para Detecção de Erros Críticos", 'ja': "WMT '21品質推定タスクのためのNICT京都提出：重大なエラー検出のためのマルチメトリック多言語事前トレーニング", 'zh': "NICT京都提交WMT'21质量评估:用于严重错误检测者多指标多指标预训练", 'hi': "WMT'21 गुणवत्ता आकलन कार्य के लिए NICT क्योटो सबमिशन: महत्वपूर्ण त्रुटि का पता लगाने के लिए बहुआयामी बहुभाषी Pretraining", 'ru': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'ga': "Aighneacht NICT Kyoto do Thasc Meastachán Cáilíochta WMT'21: Réamhoiliúint Ilmhéadrach Ilteangach chun Earráidí Criticiúla a Bhrath", 'ka': 'Comment', 'hu': "NICT Kyoto benyújtás a WMT'21 minőségbecslési feladathoz: Multimetrikus többnyelvű előkészítés kritikus hibák felismeréséhez", 'it': "Presentazione NICT Kyoto per il compito di stima della qualità WMT'21: Pretraining Multilingual per il rilevamento di errori critici", 'el': 'Υποβολή του Κιότο για το έργο εκτίμησης ποιότητας Πολυμετρική Πολυγλωσσική Προετοιμασία για την ανίχνευση κρίσιμων σφαλμάτων', 'ms': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'mk': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'ml': "WMT' 21 ഗുണവിശേഷത്തിനുള്ള പ്രവര്\u200dത്തനത്തിനുള്ള NICT കിയോട്ടോ സബ്മിഷന്\u200d: ക്രിട്ടിക്കല്\u200d പിശക് കണ്ടുപിടിക്കുന്നതിനുള", 'lt': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'kk': "WMT '21 сапатты оқу тапсырмасы үшін NICT Киотоның жіберілімі: Көпшілік қатені анықтау үшін көпшілікті көпшілік тілдерді тапсыру", 'mn': "NICT Киото WMT's 21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'pl': "NICT Kyoto zgłoszenie do zadania szacowania jakości WMT'21: multimetryczne wielojęzyczne wstępne treningi do wykrywania błędów krytycznych", 'ro': "NICT Kyoto depunere pentru sarcina de estimare a calității WMT'21: Pretrainare multilingvă multilingvă pentru detectarea erorilor critice", 'mt': 'Is-Sottomissjoni ta’ Kjoto NICT għall-Kompitu ta’ Stima tal-Kwalità tad-WMT’21: Tħarriġ Multilingwi Multimetriku għal Sejbien ta’ Żbalji Kritiċi', 'sr': "NICT Kyoto Submission za procjenu kvalitete WMT'21 zadatak: Multimetrička multijezička pretvaranja za otkrivanje kritičnih grešaka", 'si': "NICT කියෝටෝ සබ්මිසිය WMT' 21 කුළුවත් අවශ්\u200dය විශ්වාස කරන්න වැඩ: ගොඩමීටරික බාධාවත් භාෂාව ප්\u200dරතික්\u200dරීයාත", 'so': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'no': "NICT Kyoto Submission for WMT's 21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'sv': "NICT Kyoto Inl채mning f철r WMT'21 kvalitetsber채kningsuppgift: Multimetrisk flerspr책kig pretraining f철r uppt채ckt av kritiska fel", 'ta': "WMT' 21 தரம் கணக்கீட்டு பணிக்கான NICT Kyoto Submission: Critical Error Detection", 'ur': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'uz': 'Name', 'vi': "Tập tin dự phòng chất lượng NIRT Kyoto cho Nhiệm vụ dự đoán chất lượng WRT'21: bơm tiền đa ngôn ngữ cho phát hiện lỗi quan trọng", 'bg': "Представяне на NICT Киото за задачата за оценка на качеството на WMT'21: мултиметрично многоезично предобучение за откриване на критични грешки", 'hr': "NICT Kyoto podmission za procjenu kvalitete WMT'21 zadatak: Multimetrička multijezička pretvaranja za otkrivanje kritičnih grešaka", 'nl': "NICT Kyoto indiening voor de WMT'21 Kwaliteitsschattingstaak: Multimetrische meertalige pretraining voor kritische foutdetectie", 'da': "NICT Kyoto Indsendelse til WMT'21 Kvalitetsestimeringsopgaven: Multimetrisk flersproget prækursering for detektering af kritiske fejl", 'id': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'de': "NICT Kyoto Einreichung fﾃｼr die WMT'21 Qualitﾃ､tsschﾃ､tzungsaufgabe: Multimetrisches mehrsprachiges Vortraining fﾃｼr kritische Fehlererkennung", 'ko': "NICT 교토에서 제출한 WMT'21 품질 평가 임무: 다중 지표 다중 언어 예비 훈련, 관건적인 오류 검출에 사용", 'sw': "Tamko la NICT Kyoto kwa ajili ya kazi ya Hesabu ya WMT'21: mafunzo ya lugha nyingi kwa ajili ya Kugundua Tatizo la Kikosa", 'tr': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'af': "NICT Kyoto Submission vir die WMT' 21 Kwaliteit Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'fa': "Submission NICT Kyoto for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'sq': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'am': "Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'bn': "WMT'21 মান গণনা কাজের জন্য NICT Kyoto সাবমিশন: গুরুত্বপূর্ণ সমস্যা সনাক্ত করার জন্য বহুভাষী প্রশিক্ষণ", 'hy': "ՆԻԹԹ Կիոտոյի ներկայացումը' 21-ի աշխարհի որակի գնահատման առաջադրանքի համար. բազմալեզու բազմաչափություն քննադատական սխալների հայտնաբերման համար", 'az': "WMT'nin 21 N칬vb톛ti G칬r칲nt칲 G칬r칲nt칲 G칬r칲nt칲 칲칞칲n NICT Kyoto Submission: Kritik Hata G칬r칲nt칲s칲 칲칞칲n Multimetric Multilingual Pretraining", 'ca': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'bs': "NICT Kyoto podmission za procjenu kvalitete WMT'21 zadatak: Multimetrička multijezička pretvaranja za otkrivanje kritičnih grešaka", 'et': "NICT Kyoto esitamine WMT'21 kvaliteedi hindamise ülesandeks: mitmekeelne mitmekeelne eeltreening kriitiliste vigade tuvastamiseks", 'cs': "NICT Kjótský příspěvek pro úlohu odhadu kvality WMT'21: Multimetrické vícejazyčné předškolení pro detekci kritických chyb", 'fi': "NICT Kioton raportti WMT'21 Quality Estimation Task: Multimetrinen monikielinen esikoulutus kriittisten virheiden havaitsemista varten", 'jv': "NITT KiotoSubmis kanggo WWT'22 Quality", 'ha': '@ info: status', 'sk': "Predložitev NICT Kyoto za nalogo ocenjevanja kakovosti WMT'21: večjezično predvajanje za odkrivanje kritičnih napak", 'he': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection", 'bo': "NICT Kyoto Submission for the WMT'21 Quality Estimation Task: Multimetric Multilingual Pretraining for Critical Error Detection"}
{'en': 'This paper presents the NICT Kyoto submission for the WMT’21 Quality Estimation (QE) Critical Error Detection shared task (Task 3). Our approach relies mainly on QE model pretraining for which we used 11 language pairs, three sentence-level and three word-level translation quality metrics. Starting from an XLM-R checkpoint, we perform continued training by modifying the learning objective, switching from masked language modeling to QE oriented signals, before finetuning and ensembling the models. Results obtained on the test set in terms of ', 'ar': 'تقدم هذه الورقة تقديم NICT Kyoto للمهمة المشتركة لتقدير الجودة (QE) واكتشاف الأخطاء الحرجة (المهمة 3). يعتمد نهجنا بشكل أساسي على نموذج التيسير الكمي الذي استخدمنا فيه 11 زوجًا لغويًا ، وثلاثة مقاييس لجودة الترجمة على مستوى الجملة وثلاثة مقاييس لجودة الترجمة على مستوى الكلمات. بدءًا من نقطة تفتيش XLM-R ، نقوم بإجراء تدريب مستمر عن طريق تعديل هدف التعلم ، والتحول من نمذجة اللغة المقنعة إلى إشارات موجهة QE ، قبل ضبط النماذج وتجميعها. تُظهر النتائج التي تم الحصول عليها في مجموعة الاختبار من حيث معامل الارتباط ودرجة F أن المقاييس التلقائية والبيانات التركيبية تؤدي أداءً جيدًا في التدريب المسبق ، حيث احتلت عمليات الإرسال التي قدمناها المرتبة الأولى لاثنين من أصل أربعة أزواج لغوية. تشير نظرة أعمق إلى تأثير كل مقياس على مهمة المصب إلى أداء أعلى للمقاييس الموجهة نحو الرموز ، بينما تؤكد دراسة الاجتثاث على فائدة إجراء كل من التدريب المسبق تحت الإشراف الذاتي والتيسير الكمي.', 'es': "Este artículo presenta la presentación de NICT Kyoto para la tarea compartida de detección de errores críticos de estimación de calidad (QE) de WMT'21 (Tarea 3). Nuestro enfoque se basa principalmente en la capacitación previa del modelo de QE, para la que utilizamos 11 pares de idiomas, tres métricas de calidad de traducción a nivel de frase y tres a nivel de palabras. Partiendo de un punto de control XLM-R, realizamos un entrenamiento continuo modificando el objetivo de aprendizaje, cambiando del modelado de lenguaje enmascarado a señales orientadas a la QE, antes de ajustar y ensamblar los modelos. Los resultados obtenidos en el conjunto de pruebas en términos de coeficiente de correlación y puntuación F muestran que las métricas automáticas y los datos sintéticos funcionan bien para el preentrenamiento, y nuestras presentaciones ocuparon el primer lugar para dos de cada cuatro pares de idiomas. Un análisis más profundo del impacto de cada métrica en la tarea posterior indica un mayor rendimiento para las métricas orientadas a fichas, mientras que un estudio de ablación enfatiza la utilidad de llevar a cabo tanto la capacitación previa autosupervisada como la de QE.", 'pt': "Este documento apresenta a submissão NCT Kyoto para a tarefa compartilhada WMT'21 Quality Estimation (QE) Critical Error Detection (Tarefa 3). Nossa abordagem se baseia principalmente no pré-treinamento do modelo QE para o qual usamos 11 pares de idiomas, três métricas de qualidade de tradução em nível de sentença e três em nível de palavra. A partir de um checkpoint XLM-R, realizamos treinamento contínuo modificando o objetivo de aprendizagem, mudando de modelagem de linguagem mascarada para sinais orientados por QE, antes de ajustar e ensemble os modelos. Os resultados obtidos no conjunto de testes em termos de coeficiente de correlação e F-score mostram que métricas automáticas e dados sintéticos funcionam bem para pré-treinamento, com nossos envios classificados em primeiro lugar para dois dos quatro pares de idiomas. Uma análise mais profunda do impacto de cada métrica na tarefa downstream indica maior desempenho para métricas orientadas a token, enquanto um estudo de ablação enfatiza a utilidade de realizar pré-treinamento autossupervisionado e QE.", 'fr': "Cet article présente la soumission NTIC Kyoto pour la tâche partagée WMT'21 Quality Estimation (QE) Critical Error Detection (Task 3). Notre approche repose principalement sur la pré-formation du modèle QE pour laquelle nous avons utilisé 11 paires de langues, trois indicateurs de qualité de traduction au niveau de la phrase et trois indicateurs de qualité de traduction au niveau des mots. À partir d'un point de contrôle XLM-R, nous effectuons une formation continue en modifiant l'objectif d'apprentissage, en passant de la modélisation du langage masqué à des signaux orientés QE, avant d'affiner et d'assembler les modèles. Les résultats obtenus sur l'ensemble de tests en termes de coefficient de corrélation et de score F montrent que les mesures automatiques et les données synthétiques fonctionnent bien pour la pré-formation, nos soumissions se classant au premier rang pour deux paires de langues sur quatre. Un examen plus approfondi de l'impact de chaque métrique sur la tâche en aval indique des performances plus élevées pour les métriques orientées jetons, tandis qu'une étude d'ablation met l'accent sur l'utilité de mener à la fois une formation auto-supervisée et une pré-formation QE.", 'ja': "WMT '21 Quality Estimation (QE) Critical Error Detection shared task (Task 3)のNICT Kyoto提出を紹介する。私たちのアプローチは、主にQEモデルの事前トレーニングに依存しています。このトレーニングでは、11の言語ペア、3つの文レベルの翻訳品質指標、3つの単語レベルの翻訳品質指標を使用しました。XLM - Rチェックポイントから始まり、学習目標を変更し、マスクされた言語モデリングからQE指向のシグナルに切り替えて、モデルを微調整して組み立てる前に、継続的なトレーニングを行います。相関係数とFスコアの観点からテストセットで得られた結果は、自動指標と合成データが事前トレーニングに優れていることを示しており、私たちの提出物は4つの言語ペアのうち2つで1位でした。各指標が下流タスクに与える影響をより深く見ると、トークン指向指標のパフォーマンスが向上していることが示されます。一方、アブレーション研究では、自主監督およびQE事前トレーニングの両方を実施することの有用性が強調されています。", 'zh': "本文引 NICT Kyoto 提交 WMT'21 质评估 (QE) 严重错误检测共享(务 3)。 吾法主于QE模形预训练,为用11种语对,三句级及三字级译质量指标。 自XLM-R检查点始,改而学之,从屏蔽语言建模切换而QE之,然后微调封装形。 于相关系数F分数得测试集结果表明,自指标综数见于预练,四言第二。 深知指标之下流,明令牌指标之性高,而消融自督QE预训练之用也。", 'hi': "यह पेपर WMT'21 गुणवत्ता अनुमान (QE) महत्वपूर्ण त्रुटि का पता लगाने साझा कार्य (कार्य 3) के लिए NICT क्योटो सबमिशन प्रस्तुत करता है। हमारा दृष्टिकोण मुख्य रूप से क्यूई मॉडल प्रीट्रेनिंग पर निर्भर करता है जिसके लिए हमने 11 भाषा जोड़े, तीन वाक्य-स्तर और तीन शब्द-स्तरीय अनुवाद गुणवत्ता मीट्रिक का उपयोग किया था। एक XLM-R चेकपॉइंट से शुरू करते हुए, हम सीखने के उद्देश्य को संशोधित करके निरंतर प्रशिक्षण करते हैं, नकाबपोश भाषा मॉडलिंग से क्यूई उन्मुख संकेतों पर स्विच करते हैं, मॉडल को ठीक करने और घेरने से पहले। सहसंबंध गुणांक और एफ-स्कोर के संदर्भ में परीक्षण सेट पर प्राप्त परिणामों से पता चलता है कि स्वचालित मीट्रिक और सिंथेटिक डेटा प्रीट्रेनिंग के लिए अच्छी तरह से प्रदर्शन करते हैं, जिसमें हमारी प्रस्तुतियां चार भाषा जोड़े में से दो के लिए पहले स्थान पर हैं। डाउनस्ट्रीम कार्य पर प्रत्येक मीट्रिक के प्रभाव पर एक गहरी नज़र टोकन उन्मुख मीट्रिक के लिए उच्च प्रदर्शन को इंगित करती है, जबकि एक एब्लेशन अध्ययन आत्म-पर्यवेक्षित और क्यूई प्रीट्रेनिंग दोनों के संचालन की उपयोगिता पर जोर देता है।", 'ru': "В настоящем документе представлена информация, представленная NICT в Киото для совместной задачи WMT'21 Quality Estimation (QE) Critical Error Detection (Задача 3). Наш подход в основном основан на предварительном обучении модели QE, для которого мы использовали 11 языковых пар, три метрики качества перевода на уровне предложений и три метрики качества перевода на уровне слов. Начиная с контрольной точки XLM-R, мы проводим непрерывное обучение, изменяя цель обучения, переходя от моделирования языка в масках к сигналам, ориентированным на QE, прежде чем выполнять тонкую настройку и сборку моделей. Результаты, полученные на тестовом наборе с точки зрения коэффициента корреляции и F-показателя, показывают, что автоматические метрики и синтетические данные хорошо работают для предварительного обучения, при этом наши представления занимают первое место для двух из четырех языковых пар. Более глубокий взгляд на влияние каждой метрики на последующую задачу указывает на более высокую производительность для метрик, ориентированных на токены, в то время как исследование абляции подчеркивает полезность проведения как самостоятельного, так и предварительного обучения QE.", 'ga': "Cuireann an páipéar seo aighneacht Kyoto NICT i láthair don tasc roinnte um Brath Earráidí Criticiúla (Tasc 3) de chuid WMT'21 maidir le Meastachán Cáilíochta (QE). Braitheann ár gcur chuige go príomha ar réamhoiliúint ar mhúnla QE agus d’úsáideamar 11 phéire teanga, trí mhéadracht cáilíochta aistriúcháin leibhéal abairte agus trí leibhéal focal ina leith. Ag tosú le seicphointe XLM-R, déanaimid oiliúint leanúnach tríd an gcuspóir foghlama a mhodhnú, ag aistriú ó shamhaltú teanga chumhdaigh go comharthaí atá dírithe ar QE, sula ndéantar mionchoigeartú agus comhshamhlú na múnlaí. Léiríonn torthaí a fuarthas ar an tacar tástála i dtéarmaí comhéifeacht comhghaolaithe agus scóir F go n-éiríonn go maith le méadracht uathoibríoch agus sonraí sintéiseacha don réamhoiliúint, agus ár n-aighneachtaí rangaithe sa chéad áit do dhá phéire teanga as ceithre cinn. Léiríonn breathnú níos doimhne ar thionchar gach méadrach ar an tasc iartheachtacha feidhmíocht níos airde do mhéadracht chomhartha-dhírithe, agus leagann staidéar ablation béim ar a úsáidí atá sé réamhoiliúint féin-mhaoirsithe agus QE a dhéanamh.", 'el': "Η παρούσα εργασία παρουσιάζει την υποβολή του Κιότο για την κοινή εργασία ανίχνευσης κρίσιμων σφαλμάτων WMT'21 (εργασία 3). Η προσέγγισή μας βασίζεται κυρίως στην προεπιλογή μοντέλου QE για την οποία χρησιμοποιήσαμε 11-γλωσσικά ζεύγη, τρία επίπεδα προτάσεων και τρεις μετρήσεις ποιότητας μετάφρασης σε επίπεδο λέξεων. Ξεκινώντας από ένα σημείο ελέγχου διεξάγουμε συνεχή εκπαίδευση τροποποιώντας τον μαθησιακό στόχο, μεταβαίνοντας από τη μοντελοποίηση της μασκαρισμένης γλώσσας σε σήματα προσανατολισμένα στην QE, πριν τελειοποιήσουμε και συναρμολογήσουμε τα μοντέλα. Τα αποτελέσματα που ελήφθησαν στο τεστ όσον αφορά τον συντελεστή συσχέτισης και την βαθμολογία δείχνουν ότι οι αυτόματες μετρήσεις και τα συνθετικά δεδομένα αποδίδουν καλά για την προεπιλογή, με τις υποβολές μας να κατατάσσονται πρώτοι για δύο στα τέσσερα γλωσσικά ζεύγη. Μια βαθύτερη ματιά στον αντίκτυπο κάθε μετρικής στην μεταγενέστερη εργασία υποδεικνύει υψηλότερη απόδοση για μετρήσεις προσανατολισμένες σε μάρκες, ενώ μια μελέτη αφαίρεσης τονίζει τη χρησιμότητα της διεξαγωγής τόσο αυτοεπιτηρούμενης όσο και προεπιλογής QE.", 'hu': "Ez a tanulmány bemutatja a NICT Kyoto benyújtását a WMT'21 Minőségbecslés (QE) Critical Error Detection megosztott feladathoz (3. feladat). Megközelítésünk elsősorban a QE modell előkészítésére épül, amelyhez 11 nyelvpárt, három mondatszintet és három szószintű fordítási minőségi mutatót használtunk. Az XLM-R ellenőrzőponttól kiindulva folyamatos képzést végezünk a tanulási cél módosításával, a maszkos nyelvmodellezésről QE orientált jelekre váltással, mielőtt finomhangolnánk és összeállítanánk a modelleket. A tesztkészleten kapott korrelációs együttható és F pontszám szempontjából kapott eredmények azt mutatják, hogy az automatikus mutatók és a szintetikus adatok jól teljesítenek a képzés előtt, a benyújtások négy nyelvpárból kettő közül az első helyen állnak. Az egyes metrikák downstream tevékenységre gyakorolt hatásának mélyebb megvizsgálása a tokenorientált metrikák nagyobb teljesítményét mutatja, míg egy ablációs tanulmány hangsúlyozza az önfelügyelet és a QE előkészítés hasznosságát.", 'kk': "Бұл қағаз WMT '21 сапа оқиғасы (QE) үшін NICT Kyoto жіберілімін көрсетеді. Қате ортақ тапсырманы анықтау (3- тапсырма) қатесі. Біздің қасиетіміз, негізінде QE үлгісінің бірнеше тіл екі, үш сөз деңгейі және үш сөз деңгейінің аудармасының сапасы метрикалығын қолданып тұрады. XLM- R тексеру нүктесінен бастап, оқыту мақсатын өзгертіп, қалқан тілдерді QE бағытталған сигналдарға ауысып, үлгілерді бағыттау және ендіру алдында жалғастырып оқытуды орындаймыз. Кореляциялық коэффициентті және F- нәтижесінің сынақтағы нәтижелері автоматты метрикалық және синтетикалық деректері жақсы жасайтынын көрсетеді. Біздің жіберіміз төрт тілден екі ретінде бірінші ретінде орнатылды. Төменгі тапсырманың әрбір метрикалық нәтижесін қарау үшін тегіс бағытталған метрикалық метрикалық нәтижесін көрсетеді, бірақ қосу зерттеулері өзімен қарау және QE бағытталуының пайдалығын бағыттайды.", 'lt': "Šiame dokumente pateikiama NICT Kioto paraiška dėl WMT'21 kokybės vertinimo (QE) bendros užduoties nustatyti kritines klaidas (3 užduotis). Mūsų požiūris daugiausia grindžiamas QE modelio išankstiniu mokymu, kuriam naudojome 11 kalbų poros, tris sakinius ir tris žodžių lygio vertimo kokybės metrijas. Pradedant nuo XLM-R kontrolės taško, mes tęsiame mokymą modifikuodami mokymosi tikslą, pereinant nuo paslėptos kalbos modeliavimo prie QE orientuotų signalų, prieš tobulindami ir surinkdami modelius. Iš bandymų rezultatų, gautų koreliacijos koeficiento ir F balais požiūriu, matyti, kad automatinės metrijos ir sintetiniai duomenys gerai veikia išankstiniam mokymui, o mūsų pasiūlymai pirmiausia priskiriami dviem iš keturių kalbų poroms. Išsamesnė kiekvieno matavimo poveikio tolesnei užduotims apžvalga rodo, kad į ženklus orientuotų matavimo rodiklių veiksmingumas yra didesnis, o abliacijos tyrime pabrėžiamas savarankiško ir QE išankstinio mokymo naudingumas.", 'ka': "ამ დოკუნტის შესახებ, WMT'21 კაalitეტის განსაზღვრება (QE) კრიტიკური შეცდომა განსაზღვრება საზოგადომი დამუშავება NICT კიოტოს. ჩვენი პროგრამა უფრო მეტი QE მოდელზე დარწმუნდება, რომელიც ჩვენ გამოყენეთ 11 ენის ზოგი, სამი სიტყვების დონე და სამი სიტყვების წარმატების მეტრიკა. XLM-R შემოწმების წერტილიდან დავიწყებთ, ჩვენ გავაკეთებთ განაცვლის მიზეზი, მასკური ენის მოდელიდან QE მოდელირებული სიგნალზე გადაცვლით, მოდელის გადასრულება და გადასრულება. შედეგი, რომელიც შეიძლება კორელაციის კოეფიციენტის და F- სოდენტის შედეგი გამოიყენება, რომ ავტომატიკური მეტრიკა და სინტეტიკური მონაცემები საკმაოდ გამოყენება საკმაოდ საკმაოდ, ჩვენი მონაცემები პირ ყველა მეტრიკის შედეგების შედეგება ჩვენი დაკავშირებული საქმე დაახლოებით უფრო მეტრიკის შედეგება, როცა აბლაციის სწავლის შედეგება განახლოების გამოსაყენებელობას და QE-ს დაკავშირებას.", 'mk': "Овој документ го претставува поднесувањето на Киото на НИЦТ за заедничката задача за детектирање критички грешки (задача 3) за проценка на квалитетот на WMT'21. Нашиот пристап се зависи главно од претренирање на моделот QE за кој користевме 11 јазички парови, три реченици и три метрики на квалитетот на превод на зборови. Почнувајќи од контролна точка на XLM-R, ние спроведуваме континуиран тренинг со модификација на објектот за учење, префрлање од маскирано јазичко моделирање на сигнали ориентирани на QE, пред да ги финетираме и инсемблираме моделите. Резултатите добиени од тестот во поглед на коефициентот на корелација и F-оценката покажуваат дека автоматската метрика и синтетичките податоци се добри за претренирање, со нашите поднесувања рангирани прво за двајца од четирите јазички парови. Подлабок поглед на влијанието на секоја метрика врз задачата на понатамошниот тек покажува повисока резултатност на метриките ориентирани на знаците, додека студијата за аблација ја истакнува корисноста на спроведувањето на претренинг за самоупотреба и за QE.", 'ms': "Kertas ini memperkenalkan penghantaran Kyoto NICT untuk Perkiraan Kualiti WMT'21 (QE) Tugas berkongsi Pengesanan Ralat Kritik (Tugas 3). Pendekatan kami bergantung terutamanya pada pralatihan model QE yang kami gunakan 11 pasangan bahasa, tiga tahap kalimat kaliti terjemahan dan tiga tahap perkataan. Starting from an XLM-R checkpoint, we perform continued training by modifying the learning objective, switching from masked language modeling to QE oriented signals, before finetuning and ensembling the models.  Hasil yang diperoleh pada set ujian dalam terma koeficien korelasi dan skor-F menunjukkan bahawa metrik automatik dan data sintetik berjalan dengan baik untuk latihan awal, dengan penghantaran kami ditangkap pertama untuk dua daripada empat pasangan bahasa. Lihatlah lebih dalam kesan setiap metrik pada tugas turun menunjukkan prestasi yang lebih tinggi untuk metrik oriented token, sementara penelitian ablasi menekankan kebaikan menjalankan kedua-dua pengawasan diri dan latihan QE.", 'it': "Questo articolo presenta la presentazione NICT Kyoto per l'attività condivisa WMT'21 Quality Estimation (QE) Critical Error Detection (Task 3). Il nostro approccio si basa principalmente sul pre-training del modello QE per il quale abbiamo utilizzato 11 coppie linguistiche, tre parametri di qualità delle traduzioni a livello di frase e tre parole. Partendo da un checkpoint XLM-R, eseguiamo una formazione continua modificando l'obiettivo di apprendimento, passando dalla modellazione del linguaggio mascherato ai segnali orientati al QE, prima di mettere a punto e assemblare i modelli. I risultati ottenuti sul set di test in termini di coefficiente di correlazione e F-score mostrano che le metriche automatiche e i dati sintetici funzionano bene per il pre-training, con i nostri contributi classificati al primo posto per due coppie di lingue su quattro. Uno sguardo più approfondito sull'impatto di ogni metrica sull'attività downstream indica prestazioni più elevate per le metriche orientate ai token, mentre uno studio di ablazione sottolinea l'utilità di condurre sia il pretraining auto-supervisionato che QE.", 'mn': "Энэ цаас WMT's 21 Quality Estimation (QE) Critical Error Detection shared task (Task 3) дээр NICT Kyoto-ын хэвлэлийг харуулдаг. Бидний арга хэлбэл QE загвар дээр ихэвчлэн 11 хэл хоёр, 3 үгийн түвшинд, 3 үгийн түвшинд орчуулах чанарын метрик ашигладаг. XLM-R шалгалтын цэгээс эхлэхэд бид суралцах зорилго өөрчлөгдөхөд үргэлжлүүлсэн суралцах хөтөлбөрийг хийж, хэл загварын загвараас QE ориентиролт сигналууд руу шилжүүлж, загваруудыг бүтээхээс өмнө зориулан сура Харин харилцааны коэффициент болон F-тооны шалгалтын үр дүнд автоматик метрик болон синтетик өгөгдлийн хувьд зөвхөн хөгжүүлэхэд сайн ажилладаг гэдгийг харуулсан. Метрик бүр доорх ажил дээрх нөлөөлөлт нь илүү гүнзгий харах нь тодорхойлолтой метрик дээрх илүү өндөр үйл ажиллагааг илэрхийлж байна. Харин давхарлалтын судалгаа өөрийгөө удирдах болон QE хоёуланг удирдах хэрэгтэй байдлыг баталдаг.", 'ml': "ഈ പേപ്പറില്\u200d WMT'21 സ്ഥിതിയുടെ (QE) ക്രിസ്റ്റിക്കല്\u200d പിശക് തിരിച്ചറിയുന്നതിനുവേണ്ടി NICT കിയോട്ടോ പങ്കുചേര്\u200dക്കുന് നമ്മുടെ സമ്പ്രദായം പ്രധാനപ്പെട്ട ക്യൂഇ മോഡലില്\u200d ആശ്രയിച്ചിരിക്കുന്നു. അതിന്റെ പേരില്\u200d ഞങ്ങള്\u200d 11 ഭാഷ ജോടികള്\u200d, മൂന്നു വ Starting from an XLM-R checkpoint, we perform continued training by modifying the learning objective, switching from masked language modeling to QE oriented signals, before finetuning and ensembling the models.  ബന്ധപ്പെടുത്തുന്നതിന്റെയും എഫ് സ്കോര്\u200dട്ടിന്റെയും പരീക്ഷണത്തിന്റെയും ഫലങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു. സ്വയം മെറ്റിക്കകളും സിന്തിറ്റിക താഴ്ഭാഗത്തുള്ള എല്ലാ മെട്രിക്കിന്\u200dറെയും പ്രഭാവങ്ങളില്\u200d ആഴത്തോടെ നോക്കിക്കൊണ്ടിരിക്കുന്നു. ചിഹ്നങ്ങളുടെ മെട്രിക്കുകള്\u200dക്ക് ഉയര്\u200dന്ന പ്രവര്\u200dത്ത", 'no': "Denne papiret viser NICT Kyoto-tillegget for WMT's 21 Quality Estimation (QE) kritiske feiloppdaging delt oppgåve (Oppgåve 3). Tilnærminga vårt er hovudsakelig på QE-modellen som vi bruka 11 språkopar, tre setningsnivå og tre ordnivåomsetjingskvalitetsmeterikk. Startar frå eit XLM-R-kontrollpunkt, utfører vi fortsatt opplæring ved å endra læringsmålet, og byta frå maskerte språk-modellering til QE-orienterte signaler før modelane skal finne og ensembere. Resultatet som er oppretta på testsettet i forhold til korrelasjonskoeffisient og F- poeng viser at automatiske metrikar og syntetiske data utfører godt for trekking, med våre oppføringar rangerte først for to av fire språkopar. Eit dypere utsjånad på effekten av kvar metrisk på nedstrømmeoppgåva tyder høgare utviklingar for merkeorienterte metrikar, mens ein aktiveringsstudie tyder på at det er nyttig å gjera både sjølvovervåka og QE-trekking.", 'ro': "Această lucrare prezintă depunerea NICT Kyoto pentru activitatea partajată WMT'21 Quality Estimation (QE) Critical Error Detection (Task 3). Abordarea noastră se bazează în principal pe pregătirea modelului QE pentru care am folosit 11 perechi de limbi, trei măsurători de calitate a traducerii la nivel de frază și trei măsurători de calitate a traducerii la nivel de cuvânt. Pornind de la un punct de control XLM-R, efectuăm instruire continuă prin modificarea obiectivului de învățare, trecând de la modelarea limbajului mascat la semnalele orientate QE, înainte de a fin-tuning și ansambla modelele. Rezultatele obținute pe setul de test în ceea ce privește coeficientul de corelație și punctajul F arată că măsurătorile automate și datele sintetice performează bine pentru pre-pregătire, depunerile noastre fiind plasate pe primul loc pentru două din patru perechi de limbi. O analiză mai profundă a impactului fiecărei metrice asupra activității din aval indică performanțe mai mari pentru metricile orientate spre token, în timp ce un studiu de ablație subliniază utilitatea efectuării atât de auto-supravegheate, cât și de pre-formare QE.", 'sr': "Ovaj papir predstavlja podatke NICT Kyoto za procjenu kvalitete WMT'21 (QE) kritične greške za otkrivanje zajedničkog zadatka (zadatak 3). Naš pristup se oslanja uglavnom na QE model pretreniranja kojim smo koristili 11 jezičkih parova, tri rečenica i tri kvalitetne metrike za prevod rečenica. Počevši od kontrolne tačke XLM-R, nastavljamo obuku modificiranjem cilja učenja, prebacivanjem iz maskiranog jezika na signale orijentirane na QE, pre nego što se finetuju i obezbedimo modele. Rezultati koji su dobili na testu u pogledu koeficijenta korelacije i F-rezultata pokazuju da automatske metrike i sintetičke podatke dobro izvode za pretkivanje, a naša predstava su prva redovna za dva od četiri jezička parova. Dublji pogled na utjecaj svake metrike na zadatak dole ukazuje na veću učinku za znakove orientirane metrike, dok ispitivanje ablacije naglašava korisnost provođenja samopouzdanih i QE pretvaranja.", 'si': "මේ පැත්තේ WMT' 21 කුළුවත් අනුමාණය (QE) ගොඩක් වැරදි වැරදි පරීක්ෂණය (වැඩ 3) ගැන NICT කියෝටෝ පිළිබඳය පෙනුම් පෙන අපේ ප්\u200dරවේශය විශ්වාස කරන්නේ QE මොඩල් ප්\u200dරිට්\u200dරේන්ස් වලට, අපි භාෂාවක් දෙන්නා 11, වාක්ෂාවක් තුනක් සහ වාක්ෂාවක XLM-R පරීක්ෂණ පැත්තෙන් පටන් ගත්තා, අපි පටන් ගත්ත ඉදිරියට ප්\u200dරශ්නය කරන්න ඉදිරියට ඉදිරියට ඉදිරියට වෙනස් කරනවා, මුකුණු භාෂාව මද පරීක්ෂණය සඳහා පරීක්ෂණය සහ F- ස්කෝර් වලින් පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ස්වයංක්\u200dරීයාත් හැම මීට්\u200dරිකාවක්ම පහලට ප්\u200dරමාණයක් වෙනුවෙන් වඩා ගොඩක් බලන්න පුළුවන් වෙනුවෙන් ප්\u200dරමාණයක් පෙනුවන් වෙනුවෙන් ප්\u200dරමාණයක් පෙනුවෙන් ප්\u200dර", 'pl': "Niniejszy artykuł przedstawia zgłoszenie NICT Kyoto dla wspólnego zadania WMT'21 Quality Estimation (QE) Critical Error Detection (Task 3). Nasze podejście opiera się głównie na wstępnym szkoleniu modelu QE, do którego użyliśmy 11-par językowych, trzech wskaźników jakości tłumaczeń na poziomie zdań i trzech słów. Począwszy od punktu kontrolnego XLM-R, przeprowadzamy ciągłe szkolenia poprzez modyfikację celu uczenia się, przełączanie z modelowania języka maskowanego na sygnały zorientowane na QE, przed dopracowaniem i zestawieniem modeli. Wyniki uzyskane w zestawie testów pod względem współczynnika korelacji i wyniku F pokazują, że automatyczne wskaźniki i dane syntetyczne sprawdzają się dobrze podczas treningu wstępnego, a nasze zgłoszenia zajęły pierwsze miejsce dla dwóch na cztery pary językowe. Głębsze przyjrzenie się wpływowi każdej metryki na dalsze zadanie wskazuje na wyższą wydajność wskaźników zorientowanych na tokeny, podczas gdy badanie ablacji podkreśla przydatność przeprowadzania zarówno samodzielnego, jak i wstępnego treningu QE.", 'so': "Kanu warqaddan wuxuu u dhiibaa NICT Kyoto oo loo soo dhiibaa WMT'21 Tusaale Estimation (QE) Critical Error Detection (Task 3). Dhaqdhaqaalkayagu wuxuu ku xiran yahay tusaale QE ah oo aan u isticmaalnay 11 labo oo luqad ah, saddex heer oo ereyga ah iyo saddex qoraal-heer oo turjumista qiimo ah. Tan bilowga barta XLM-R, waxaynu ku sameynaa waxbarashada sii socota si aan u beddelinno goal waxbarashada, waxaynu ka beddelinaynaa muusikada afka maskaxda oo u beddelinaynaa sawirada QE-ka horjeeda, intaan sameyn sameynin modellada. Midhaha lagu soo bandhigay imtixaanka kooxda iyo kooxda F-kooxa waxay tustaa in automatic metric iyo synthetic macluumaad ay si wanaagsan u sameeyaan in ay u soo daabacaan, islamarkaasna ay soo direen ugu horraysay laba labo oo afar luqad ah. Fiiridda aad u dheer oo saameyn ku saabsan shaqada hoose-taalada ayaa ka muuqata sameynta dhaqdhaqaalaha sare ee ku jeeda metriciyada calaamada, xittaa waxbarashada daboolidda ayaa ku qoran faa'iidada sameynta suurtagalka iyo QE-tababarinta.", 'sv': "Denna uppsats presenterar NICT Kyoto-inlämningen för WMT'21 Quality Estimation (QE) Critical Error Detection delade uppgift (Uppgift 3). Vårt tillvägagångssätt bygger främst på QE-modellförberedelser där vi använde 11 språkpar, tre meningsnivåer och tre ordnivå för översättningskvalitet. Med utgångspunkt från en XLM-R checkpoint utför vi fortbildning genom att ändra inlärningsmålet, byta från maskerad språkmodellering till QE-orienterade signaler, innan vi finjusterar och ensemblerar modellerna. Resultat som erhållits på testuppsättningen i termer av korrelationskoefficient och F-poäng visar att automatiska mätvärden och syntetiska data presterar bra för pre-training, med våra bidrag rankade först för två av fyra språkpar. En djupare titt på effekten av varje mätvärde på nedströmsuppgiften indikerar högre prestanda för token-orienterade mätvärden, medan en ablationsstudie betonar nyttan av att genomföra både självövervakad och QE-förbehandling.", 'ta': "This paper presents the NICT Kyoto submit to the WMT '21 quality estimation (QE) Critical error Detection shared task (Task 3). நாங்கள் 11 மொழிகள் ஜோடி, மூன்று வாக்கு- மட்டத்தை பயன்படுத்தி மூன்று வார்த்தை மொழிமாற்றி மொழிமாற்றும் தரம் முறைமையை பயன XLM- R சரிபார்ப்புள்ளியிலிருந்து துவங்குகிறது, கற்றுப் பொருளை மாற்றுவதற்காக நாம் தொடர்ந்து பயிற்சியை இயக்குகிறோம், முகத்திலிருந்து  தொடர்பு குணங்கள் மற்றும் F- மதிப்புக்குறியில் கிடைக்கப்பட்ட முடிவுகள் தானாகவே மெட்ரிக்கள் மற்றும் கூட்டிணைப்பு தகவல்கள் முன்னெழுதுவதற்கு நன்ற ஒவ்வொரு மீட்ரிக்கும் தாக்கத்தின் ஆழமாக பார்க்கும் கீழ்நோக்கி செயல்பாட்டிற்கு அதிக செயல்பாட்டை குறிப்பிடுகிறது, மேலும் ஒரு உறுப்பிடும் படிப்", 'ur': "This paper presents the NICT Kyoto submission for the WMT'21 Quality Estimation (QE) critical error detection shared task (Task 3) for the NICT Kyoto submission. ہمارا طریقہ صرف QE موڈل پر ہے جس کے لئے ہم 11 زبان جوڑے استعمال کرتے تھے، تین جماعت سطح اور تین کلمات سطح کی ترجمہ کیفیت متریک. XLM-R چک پوینٹ سے شروع کیا گیا ہے، ہم نے سیکھنے کا موضوع بدلنے کے ذریعہ تطارین ادامہ کیا ہے، ماسک زبان موڈلینگ سے QE oriented سیگنالوں تک بدلنے سے پہلے موڈل کو اچھی طرح تطارین کرنا اور اچھی طرح تطارین کر دیا ہے. نتیجے جو آزمائش سٹ میں حاصل کئے گئے ہیں ان کی تعلق کے مطابق اور F-score کے مطابق نشان دیتے ہیں کہ آٹوٹی میٹریک اور سینٹریک ڈاٹی اچھی طرح حاصل کرتے ہیں، اور ہمارے مطابق چار زبان جوڑوں میں سے دو بار پہلے درجے ہیں۔ ایک عمیق نظر ہر متریک کے اثر کے ذریعہ ڈونسٹریم کی تابع پر زیادہ اثر کی نشانیاں دکھاتی ہیں ٹونک کی منطقی متریک کے لئے، حالانکہ ایک آبلیٹ تحقیق نے اپنے آپ کو نظر رکھا ہے اور QE تحقیر کرنے کے ذریعہ مفید ہے.", 'mt': 'Dan id-dokument jippreżenta s-sottomissjoni ta’ Kjoto tan-NICT għall-Istima tal-Kwalità tal-WMT’21 (QE) Kompitu kondiviż għad-Detezzjoni ta’ Żbalji Kritiċi (Kompitu 3). L-approċċ tagħna jiddependi prinċipalment fuq it-taħriġ minn qabel tal-mudell QE li għalih użajna 11-il par lingwistiċi, tliet livelli ta’ sentenza u tliet metriċi tal-kwalità tat-traduzzjoni fil-livell tal-kelma. Mill-punt ta’ kontroll XLM-R, nagħmlu taħriġ kontinwu billi mmodifikaw l-objettiv tat-tagħlim, inqalbu mill-mudellar tal-lingwa maskrata għal sinjali orjentati lejn il-QE, qabel l-irfinar u l-immuntar tal-mudelli. Ir-riżultati miksuba fuq is-sett tat-test f’termini ta’ koeffiċjent ta’ korrelazzjoni u punteġġ F juru li l-metrika awtomatika u d-dejta sintetika jwettqu tajjeb għat-taħriġ minn qabel, bis-sottomissjonijiet tagħna kklassifikati l-ewwel għal tnejn minn erba’ pari lingwistiċi. Ħarsa aktar fil-fond lejn l-impatt ta’ kull metrika fuq il-kompitu downstream tindika prestazzjoni ogħla għal metriċi orjentati lejn it-tokens, filwaqt li studju ta’ ablazzjoni jenfasizza l-utilità tat-twettiq kemm ta’ taħriġ minn qabel b’superviżjoni awtonoma kif ukoll ta’ taħriġ QE.', 'vi': "Tờ giấy này giới thiệu đơn trình khai thác chất lượng NIST Kyoto cho dự báo chất lượng WRT'21 (QE) Nhiệm vụ phân tích lỗi nghiêm trọng (Nhiệm vụ 3). Cách tiếp cận của chúng ta chủ yếu dựa trên kiểu QE. Trước đó chúng ta dùng dạng ngôn ngữ 11, ba mức án và ba mức độ phân dịch chất lượng từ. Bắt đầu từ điểm kiểm soát XLM-R, chúng tôi thực hiện đào tạo tiếp bằng cách sửa đổi mục tiêu học, chuyển từ thiết lập ngôn ngữ đeo mặt nạ sang tín hiệu hướng về QE, trước khi tinh chỉnh và kết hợp các mô hình. Kết quả của thử nghiệm với tỉ lệ tương quan và điểm F cho thấy âm lượng tự động và dữ liệu tổng hợp hoạt động tốt cho buổi hẹn hò, với kết quả xếp hạng đầu tiên cho hai trong bốn cặp ngôn ngữ. Một cái nhìn sâu hơn về tác động của mỗi hệ số trên các thao tác xuôi dòng cho thấy hiệu suất cao cho các âm lượng xu hướng, trong khi một nghiên cứu thoát nhấn mạnh sự hữu ích của việc tiến hành trước cả khả năng tự giám sát lẫn QE.", 'uz': "Name Biz murojaatiyatlarimiz asosiy QE modeliga ishlatadi, biz 11 tillar parchaga, uchta so'zlar darajaga va uchta so'zlar darajasi tarjima quality metriklarga ishlatdik. Name Name Ko'pchilik vazifasida har bir metrik natijasining yetarligini qo'yish mumkin, va qo'yish o'rganish muvaffaqiyatini o'zgartirish imkoniyatini qo'llash mumkin.", 'nl': "Dit document presenteert de NICT Kyoto inzending voor de WMT'21 Quality Estimation (QE) Critical Error Detection gedeelde taak (Task 3). Onze aanpak is voornamelijk gebaseerd op QE-model pretraining waarvoor we 11-taalparen, drie zinnen- en drie woordkwaliteitsmetrics gebruikten. Vanuit een XLM-R checkpoint voeren we voortgezette training uit door de leerdoelstelling te wijzigen, over te schakelen van gemaskerde taalmodellering naar QE georiënteerde signalen, voordat we de modellen finetunen en ensembleren. De resultaten van de testset in termen van correlatiecoëfficiënt en F-score tonen aan dat automatische metrics en synthetische gegevens goed presteren voor pretraining, waarbij onze inzendingen voor twee van de vier taalparen op de eerste plaats staan. Een diepere blik op de impact van elke metriek op de downstream taak wijst op hogere prestaties voor token georiënteerde metrics, terwijl een ablatieonderzoek het nut benadrukt van het uitvoeren van zowel zelfbegeleide als QE pretraining.", 'hr': "Ovaj papir predstavlja podatke NICT Kyoto za procjenu kvalitete WMT'21 (QE) kritičnog otkrivanja greška zajedničkog zadatka (zadatak 3). Naš pristup se oslanja uglavnom na QE modelu pretvaranja kojim smo koristili 11 jezičkih parova, tri razine rečenica i tri kvalitetne metrike za prevod riječi na razini riječi. Počevši od kontrolne to čke XLM-R, nastavljamo vježbati mijenjajući cilj učenja, mijenjajući se od maskiranog jezičkog modela na signale orijentirane na QE-u, prije nego što se finetuniraju i osiguramo modele. Rezultati dobiveni na testu u smislu koeficijenta korelacije i F-rezultata pokazuju da automatske metrike i sintetičke podatke dobro obavljaju za pretkivanje, s našim podacima prvo postavljeno za dva od četiri jezička parova. Dublji pogled na utjecaj svake metrike na zadatak dolje ukazuje na veću učinku za metike orijentirane na znakove, dok ispitivanje ablacije naglašava korisnost provođenja i samovjerenih i QE pretvaranja.", 'id': "Kertas ini mempersembahkan pengiriman Kyoto NICT untuk Perkiraan Kualitas WMT'21 (QE) Kesalahan Kritis Deteksi tugas berbagi (Tugas 3). pendekatan kami bergantung terutama pada model QE pretraining yang kami gunakan 11 pasangan bahasa, tiga tingkat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat kalimat. Mulai dari titik pemeriksaan XLM-R, kami melanjutkan pelatihan melanjutkan dengan mengubah tujuan belajar, berubah dari model bahasa bertopeng ke sinyal QE oriented, sebelum memperbaiki dan mengatur model. Hasil yang diperoleh pada set tes dalam terma koeficient korelasi dan skor F menunjukkan bahwa metrik otomatis dan data sintetis berjalan dengan baik untuk latihan, dengan pengiriman kami ranked pertama untuk dua dari empat pasangan bahasa. Sebuah pandangan lebih dalam pada dampak setiap metrik pada tugas turun menunjukkan prestasi yang lebih tinggi untuk metrik orientasi token, sementara sebuah studi ablasi menekankan kebutuhan dari melakukan both self-supervised and QE pretraining.", 'bg': 'Тази статия представя представянето на NICT Kyoto за споделената задача за откриване на критични грешки (задача 3). Нашият подход разчита основно на предварително обучение на модела, за което използвахме 11 езикови двойки, три измерители за качество на превода на ниво изречение и три думи. Започвайки от контролен пункт, извършваме продължаващо обучение чрез модифициране на учебната цел, преминаване от маскирано езиково моделиране към ориентирани сигнали, преди фина настройка и ансамблиране на моделите. Резултатите, получени по отношение на коефициента на корелация и резултата показват, че автоматичните показатели и синтетичните данни се представят добре за предтрениране, като нашите предложения са на първо място за две от четирите езикови двойки. По-задълбочен поглед върху въздействието на всеки показател върху задачата надолу по веригата показва по-висока производителност на токенови ориентирани показатели, докато аблационно проучване подчертава ползата от провеждането както на самостоятелно наблюдение, така и на предварително обучение.', 'da': "Dette dokument præsenterer NICT Kyoto-indsendelsen til WMT'21 Quality Estimation (QE) Critical Error Detection delte opgave (Opgave 3). Vores tilgang er primært afhængig af QE model foruddannelse, hvor vi brugte 11 sprogpar, tre sætningsniveau og tre ordniveau oversættelseskvalitetsmålinger. Med udgangspunkt i et XLM-R checkpoint udfører vi fortsat træning ved at ændre læringsmålet, skifte fra maskeret sprogmodellering til QE orienterede signaler, før vi finjusterer og sammensætter modellerne. Resultater opnået på testsættet med hensyn til korrelationskoefficient og F-score viser, at automatiske målinger og syntetiske data klarer sig godt til foruddannelse, med vores indsendelser rangeret først for to ud af fire sprogpar. Et dybere kig på effekten af hver metric på downstream-opgaven indikerer højere ydeevne for token-orienterede metrics, mens en ablationsundersøgelse understreger nytten af at udføre både selvovervåget og QE foruddannelse.", 'de': "Dieses Papier stellt die NICT Kyoto Einreichung für die gemeinsame Aufgabe WMT'21 Quality Estimation (QE) Critical Error Detection (Task 3) vor. Unser Ansatz basiert hauptsächlich auf QE-Modell Pretraining, für das wir 11-Sprachpaare, drei Sätze- und drei Wortqualitätsmetriken verwendet haben. Ausgehend von einem XLM-R Checkpoint führen wir Weiterbildungen durch, indem wir das Lernziel modifizieren, von maskierter Sprachmodellierung zu QE-orientierten Signalen wechseln, bevor wir die Modelle verfeinern und zusammenstellen. Die Ergebnisse des Testsets in Bezug auf Korrelationskoeffizienten und F-Score zeigen, dass automatische Metriken und synthetische Daten gut für das Pretraining geeignet sind, wobei unsere Einreichungen für zwei von vier Sprachpaaren den ersten Platz belegen. Ein tieferer Blick auf die Auswirkungen jeder Metrik auf die nachgelagerte Aufgabe weist auf eine höhere Leistung für Token-orientierte Metriken hin, während eine Ablationsstudie die Nützlichkeit der Durchführung von selbstüberwachten und QE-Vorbereitungen betont.", 'sw': "Gazeti hili linaleta ujumbe wa NICT Kyoto kwa ajili ya Hesabu ya WMT'21 (QE) Kugundua Kukosa Kikosa (Kazi 3). Matukio yetu yanategemea hasa kwenye mifano ya QE ya kutengeneza mvua ambayo tulitumia wawili wa lugha 11, kiwango cha sentence tatu na mitindo ya tafsiri ya kiwango cha neno tatu. Kuanzia kutoka kwenye kituo cha XLM-R, tunafanya mafunzo ya kuendelea kwa kubadilisha malengo ya kujifunza, kubadilisha kutoka kwenye mifano ya lugha ya kifunzo na kwenda kwenye alama zinazoelekezwa na QE, kabla ya kuzuia na kuzuia mifano. Matokeo yaliyopatikana kwenye jaribio lililotengenezwa kwa kiwango cha ufanisi wa mahusiano na vipindi vya F kinaonyesha kuwa mitindo na taarifa za kujitegemea zinafanya vizuri kwa ajili ya kutengeneza mvua, na mawasiliano yetu yalipangwa kwanza kwa ajili ya wawili kati ya nne lugha. Tazama ya kina zaidi ya athari ya kila mita kwenye kazi ya chini inaonyesha ufanisi mkubwa wa mitindo inayoelekezwa, wakati utafiti wa mabomu unasisitiza matumizi ya kutekeleza mifumo yenyewe na utafiti wa kiuchunguzi wa QE.", 'fa': "این کاغذ به عنوان تحویل NICT Kyoto برای ارزیابی کیفیت WMT'21 (QE) کاری مشترک خطای مشترک (Task 3) نشان می\u200cدهد. دستور ما بستگي به مدل پيراهنمايي QE وابستگي داره که ما از 11 جفت زبان استفاده کرديم، سه سطح جمله و سه متريک کفيت ترجمه سطح کلمه استفاده کرديم. از نقطه چک XLM-R شروع می\u200cکنیم، ما با تغییر هدف یادگیری ادامه می\u200cدهیم، از مدل\u200cسازی زبان ماسک به سیگنال\u200cهای اصلی QE، قبل از اینکه مدل\u200cها را تغییر دهیم و تغییر دهیم. نتیجه\u200cهایی که بر روی مجموعه آزمایش به عنوان تعداد تعداد ارتباطی و ثبت F نشان می\u200cدهند که متریک\u200cهای خودکار و داده\u200cهای سناتیک برای تسلیم کردن خوب انجام می\u200cدهند، با تسلیم\u200cهای ما اول برای دو از چهار جفت زبان درجه گرفته شده است. یک نگاه عمیق\u200cتر به تاثیر هر متریک روی کار پایین پایین نشان می\u200cدهد که عملکرد بالاتری برای متریک متریک\u200cهای مستقیم نشان می\u200cدهد، در حالی که یک مطالعه فعالیت تأثیر می\u200cدهد که فایده\u200cای از conducting both self-supervised and QE pretraining است.", 'tr': "Bu kagyz WMT'iň 21 Görnöşi Taýýarlama (QE) Kritik Hata Taýýarlama işini (Task 3) üçin NICT Kioto maglumaty görkezýär. Biziň ýaryşymyz QE nusgasyna görä 11 dil çift, üç sözlem derejesi we üç sözlem derejesi terjime etmek üçin ullanýardy. XLM-R barlamasyndan başlap, öwrenmek maksadyny üýtgeden, maskerden dil modellendirmesinden QE yönlendirilen signallere üýtgeden öň, modelleri söňlemekden öň. Netijenler koreleksiýa koefisyz we F-अ अ अंतर görä test düzeninde awtomatik metriýa we sintetik maglumatlaryň süýtgetmek üçin gowy edip bilýändigini görkez, biziň süýtgetmegimiz 4 dilden ikisi üçin ilkinji gezek derejä edildi. A şak zadyň her metriýanyň täsirini köpüräk seredişi token orientasyn metriýa üçin ýokary ukyplygyny görkezýär, ýagdaý öwrenmesi hem özi-üne gözleýän we hem QE süýtgetmeginiň ullanlygyny emplaýar.", 'af': "Hierdie papier stel die NICT Kyoto-onderskrywing voor die WMT' 21 Kwaliteit Estimatie (QE) Kritieke Fout Opdekking gedeelde taak (Taak 3). Ons toegang is heeltemal op QE-model wat ons 11 taal paar gebruik het, drie setningvlak en drie woord-vlak-oorsetting-kwaliteit metriek. Beginne van 'n XLM-R kontrolepunt, doen ons voortgaan onderwerp deur die onderwerp van die leer objekte te verander, wysig van maskeerde taal modellering na QE orienteerde signale voor die finetuning en ensembleer van die modele. Resultate ontvang op die toets stel in terms of correlation coefficient and F- score vertoon dat outomatiese metries en sintetiese data goed uitvoer vir pretraining, met ons onderhouers eerste rangeer vir twee uit vier taal paar. 'n Deeper kyk na die effek van elke metrie op die onderstreem taak wys hoër effektiviteit vir token orienteerde metries, terwyl 'n ablasie studie bepaal die gebruiklikheid van gedoen beide self-ondersoek en QE-voorsoek.", 'ko': "본고는 NICT 교토에서 제출한 WMT'21 품질평가(QE) 관건적인 오류 검출 공유 임무(퀘스트 3)를 소개한다.우리의 방법은 주로QE모델의 예훈련에 의존한다. 우리는 11가지 언어 쌍, 세 문장 등급과 세 단어 등급의 번역 품질 지표를 사용했다.XLM-R 검사점에서부터 우리는 학습 목표를 수정하고 복면 언어 모델링에서 QE를 위한 신호로 전환한 다음에 모델을 미세하게 조정하고 통합시켜 지속적인 교육을 실시한다.시험집에서 얻은 상관계수와 F점수의 결과 자동 도량과 합성 데이터는 훈련 전에 양호했고 우리가 제출한 데이터는 네 쌍의 언어 중 두 쌍이 1위를 차지했다.각 지표가 하류 임무에 미치는 영향을 깊이 연구한 결과 영패 가이드 지표의 실적이 더욱 높았고 융해 연구는 자기 감독과 양적 완화 예훈련의 유용성을 강조했다.", 'sq': "This paper presents the NICT Kyoto submission for the WMT'21 Quality Estimation (QE) Critical Error Detection shared task (Task 3).  Përqasja jonë mbështetet kryesisht në parastërvitjen e modelit QE për të cilin përdorëm 11 çifte gjuhësh, tre nivele fjalësh dhe tre metrika cilësie përkthimi në nivel fjalësh. Duke filluar nga një pikë kontrolli XLM-R, ne kryejmë trajnim të vazhdueshëm duke ndryshuar objektivin e mësimit, duke shkuar nga modelimi i gjuhës së maskuar në sinjale të orientuara në QE, përpara se të përmirësojmë dhe të mbledhim modelet. Rezultatet e fituara në grupin e testit në terma të koeficientit korrelacioni dhe rezultatit F tregojnë se metrika automatike dhe të dhënat sintetike funksionojnë mirë për parastërvitjen, me paragjykimet tona të renditura të para për dy nga katër palët gjuhësh. Një shikim më i thellë në ndikimin e çdo metrike në detyrën e poshtme tregon performancë më të lartë për metrikat e orientuara në token, ndërsa një studim ablacioni thekson dobinë e kryerjes si të vetëmbikqyrur ashtu dhe të parastërvitjes QE.", 'hy': 'Այս հոդվածը ներկայացնում է Կիոտոյի ՆիՏ-ի ներկայացումը, որպեսզի կատարենք աշխարհի 21-ի որակի գնահատման (QE) հանրային սխալների հայտնաբերման ընդհանուր հանձնարարությունը (3 հանձնարարություն): Մեր մոտեցումը հիմնականում հիմնված է QE մոդելի նախադասության վրա, որի համար մենք օգտագործեցինք 11 լեզվի զույգ, երեք նախադասությունների և երեք բառերի մակարդակի թարգմանման որակի մետրիկներ: Սկսելով XLM-R ստուգելու կետից, մենք շարունակում ենք վարժեցնել, փոխելով ուսուցման նպատակը, փոխելով պատկերված լեզվի մոդելներից QE-ի ուղղությամբ գտնվող ազդանշաններին, մինչև մոդելները կազմակերպելը և միավորումը: Փորձարկումների ընթացքում ստացված արդյունքները հաղորդակցման կոեֆեյցիոն և F-գնահատականի տեսքով ցույց են տալիս, որ ավտոմատիկ մետրիկան և սինթետիկ տվյալները լավ են աշխատում նախադասության համար, մեր ներկայացումները առաջինը դասակարգում են չորս լեզվից երկու զու A deeper look at the impact of each metric on the downstream task indicates higher performance for token oriented metrics, while an ablation study emphasizes the usefulness of conducting both self-supervised and QE pretraining.', 'az': "Bu kağıt WMT'nin 21-ci kalitel Görünüş (QE) kritik xəta Tanıması paylaşdığı işi üçün NICT Kyoto təklif edir. Yaxınlığımız QE modeli önləşdirilməsi üçün 11 dil çift, üç cümləlik seviyyəsi və üç söz seviyyəsi tərcüm kaliteti metriklərini istifadə etdik. XLM-R kontrol nöqtəsindən başlayıb, öyrənmək məqsədini dəyişdirərək, maskara dil modellərindən QE yönəlmiş sinyallərə dəyişdiririk, modelləri finetuning və ensembling etmədən əvvəl. Sonuçları correlation coefficient və F-score sayəsində test qurduğu təqdirdə, avtomatik metrik və sintetik məlumatların pretraining üçün yaxşı işlədiklərini göstərir. Bizim təhdidlərimiz dörd dildən iki dəfə ilk dəf edildi. Beləliklə, hər metrik düşürülmüş işin təsirini daha derin baxın ki, token tərəfindən göstərilmiş metriklər üçün daha yüksək performanslığı göstərir, bir ablasiya çalışması hər ikisinin özünün tərəfindən və QE tərəfindən istifadə edilməsini təsdiqləyir.", 'bn': "এই পত্রিকা WMT'21 মান গণনা (QE) গুরুত্বপূর্ণ ত্রুটি সনাক্ত করার জন্য NICT কিয়োটোকে উপস্থাপন করেছে (কাজ ৩) কাজ শেয়ার করা হয়েছে। আমাদের প্রতিযোগিতা মূলত কিউই মডেলের উপর নির্ভর করে যেখানে আমরা ১১ ভাষার জোড়া ব্যবহার করি, তিনটি শাস্তি স্তর এবং তিনটি শব্দ-স্তরে একটি XLM-R চেক পয়েন্ট থেকে শুরু করা শিক্ষার লক্ষ্য পরিবর্তনের মাধ্যমে আমরা শিক্ষা প্রশিক্ষণ চালিয়ে যাচ্ছি, মুখোশিত ভাষা মডেলের মডেল থেকে কিউই- সম্পর্কের কার্যক্রম এবং এফ স্কোরের মাধ্যমে পরীক্ষার ফলাফল পাওয়া গেছে যে স্বয়ংক্রিয় মেট্রিক এবং সিন্টেটিক ডাটা ভালো করে বৃষ্টির জন্য, যার ফলে আমাদের প্ A deeper look at the impact of each metric on the downstream task indicates higher performance for token oriented metrics, while an ablation study emphasizes the usefulness of conducting both self-supervised and QE pretraining.", 'ca': "Aquest paper presenta la presentació de Kyoto del NICT per a la tasca compartida de la WMT'21 Quality Estimation (QE) Critical Error Detection (tasca 3). El nostre enfocament es basa principalment en la pré-capacitació del model QE per al qual vam utilitzar 11 parelles de llenguatges, tres nivells de frases i tres mètriques de qualitat de traducció de nivell de paraules. A partir d'un punt de control XLM-R, fem entrenament continu modificant l'objectiu d'aprenentatge, passant de modelar llenguatges mascarats a senyals orientats a QE, abans d'ajustar i agrupar els models. Els resultats obtenits en el conjunt de proves en termes de coeficient de correlació i puntuació F mostren que les mètriques automàtiques i les dades sintètiques funcionen bé per a la pré-treinació, amb les nostres presentacions classificades primer per dos de cada quatre parells de llenguatges. Una mirada més profunda de l'impacte de cada mètrica en la tasca avall indica un rendiment més elevat per a les mètrices orientades a les fitxes, mentre que un estudi d'ablació enfatiza l'utilitat de fer pré-entrenaments tant autosupervisats com QE.", 'bs': "Ovaj papir predstavlja podatke NICT Kyoto za procjenu kvalitete WMT'21 (QE) podijeljeni zadatak za kritičnu otkrivanje greška (zadatak 3). Naš pristup se oslanja uglavnom na QE model pretreniranja kojim smo koristili 11 jezičkih parova, tri nivoa rečenica i tri kvalitetne metrike za prevod rečenica na nivou riječi. Počevši od kontrolne tačke XLM-R, nastavljamo obuku modificiranjem cilja učenja, prebacivanjem iz maskiranog jezika na signale orijentirane na QE, prije nego što se finetuniraju i omogućavamo modele. Rezultati koji su dobili na testu u smislu koeficijenta korelacije i F-rezultata pokazuju da automatske metrike i sintetičke podatke dobro obavljaju za pretkivanje, s našim podacima prvo postavljeno za dva od četiri jezička parova. Dublji pogled na utjecaj svake metrike na zadatak dolje ukazuje na veću učinku za metike orijentirane na znakove, dok ispitivanje ablacije naglašava korisnost provođenja i samovjerenih i QE pretvaranja.", 'cs': "Tento článek představuje předložení NICT Kyoto pro sdílený úkol WMT'21 Quality Estimation (QE) Critical Error Detection (Task 3). Náš přístup se opírá především o předškolení modelu QE, pro které jsme použili 11 jazykové páry, tři věty a tři metriky kvality překladu na úrovni slova. Od kontrolního bodu XLM-R provádíme další školení modifikací učebního cíle, přechodem z modelování maskovaného jazyka na signály orientované na QE, před jemným laděním a sestavením modelů. Výsledky získané na testovací sadě z hlediska korelačního koeficientu a F-skóre ukazují, že automatické metriky a syntetická data výkonně fungují pro předškolení, přičemž naše příspěvky byly na prvním místě u dvou ze čtyř jazykových párů. Hlubší pohled na dopad jednotlivých metrik na následný úkol ukazuje vyšší výkon pro metriky orientované na token, zatímco ablační studie zdůrazňuje užitečnost provádění jak samozřízeného, tak QE předškolení.", 'am': "ይህ ገጽ የNICT Kyoto ለWMT'21 ጥሩ አካባቢ ስህተት ማሳየት (QE) የተሰራጨውን ስራ (ስራ 3) የሚያቀርብ ነው፡፡ የደረጃ ግንኙነታችን በመጀመሪያው በQE ምሳሌ ላይ መዘርጋት ነው፡፡ ስለዚህም 11 ቋንቋዎች ሁለት፣ ሦስት የንግግር ደረጃ እና ሦስት ቃላት-ደረጃ ትርጉም ብዛት ማተሚያዎች ነው፡፡ ከXLM-R checkpoint ጀምሮ ትምህርት አካባቢውን በማሻሻል ትምህርት ማድረግ እና ከመስፈሪያው ቋንቋ ምሳሌ ወደ QE አቀማመጥ እና ምሳሌዎቹን ከመግለጥ በፊት ተማርተናል፡፡ ግንኙነት አካባቢ እና የF-score ጥያቄ የተደረገ ፍጥረቶችን ማሳየት በራሱ ማተሚያዎች እና ሰንቲካዊ ዳታዎችን ለመፍጠር መልካም እንዲያደርጉ ያሳያል፡፡ ወደ ታችኛው ሚትሪክ ሁሉ ላይ የሚደረገውን የጥልቅ ትምህርት በሚያሳየው የኢንተርኔት ትምህርት ማሳየት ነው፡፡", 'et': "Käesolevas artiklis esitatakse NICT Kyoto esitus WMT'21 kvaliteedi hindamise (QE) kriitiliste vigade tuvastamise jagatud ülesande jaoks (ülesanne 3). Meie lähenemine tugineb peamiselt QE mudeli eelõpetamisele, mille jaoks kasutasime 11 keelepaari, kolme lausetaseme ja kolme sõnataseme tõlkekvaliteedi mõõdikut. XLM-R kontrollpunktist alustades teostame jätkutreeninguid, muutes õppeeesmärki, lülitudes maskeeritud keele modelleerimiselt QE orienteeritud signaalidele, enne mudelite täpsustamist ja komplekteerimist. Testi tulemused korrelatsioonikoefitsiendi ja F-skoori osas näitavad, et automaatsed mõõdikud ja sünteetilised andmed toimivad eelkoolituse jaoks hästi, meie esitused olid neljast keelepaarist kahel esimesel kohal. Iga mõõdiku mõju põhjalikum analüüs alljärgnevale ülesandele näitab, et tokenile orienteeritud mõõdikud on paremad, samas kui ablatsiooniuuring rõhutab nii enese järelevalve kui ka kvaliteedi eelõpetamise kasulikkust.", 'fi': "Tässä artikkelissa esitellään NICT Kioton raportti WMT'21 Quality Estimation (QE) Critical Error Detection jaettuun tehtävään (Tehtävä 3). Lähestymistapamme perustuu pääasiassa QE-mallien esikoulutukseen, jossa käytimme 11 kieliparia, kolmea lausetason ja kolmea sanatason käännösten laatumittaria. XLM-R-tarkistuspisteestä alkaen suoritamme jatkokoulutusta muokkaamalla oppimistavoitetta, vaihtamalla maskitusta kielimallinnuksesta QE-suuntautuneisiin signaaleihin ennen mallien hienosäätöä ja kokoonpanoa. Testistä saadut tulokset korrelaatiokertoimella ja F-pisteellä osoittavat, että automaattiset metriikat ja synteettiset tiedot suoriutuvat hyvin esikoulutuksessa, ja julkaisumme sijoittuivat ensimmäiseksi kahdessa neljästä kieliparista. Syvempi tarkastelu kunkin mittarin vaikutuksesta loppupään tehtävään osoittaa, että token-orientoituneiden mittarien suorituskyky on parempi, kun taas ablaatiotutkimus korostaa sekä itsevalvotun että QE-esikoulutuksen hyödyllisyyttä.", 'sk': "Ta prispevek predstavlja predložitev NICT Kyoto za skupno opravilo za odkrivanje kritičnih napak WMT'21 (naloga 3). Naš pristop temelji predvsem na predusposabljanju modela QE, za katerega smo uporabili 11 jezikovnih parov, tri stavke in tri meritve kakovosti prevodov na ravni besed. Iz kontrolne točke XLM-R izvajamo nadaljnje usposabljanje s spreminjanjem učnega cilja, prehodom iz maskiranega jezikovnega modeliranja na QE usmerjene signale, preden natančno nastavimo in sestavimo modele. Rezultati, pridobljeni na testnem naboru v smislu korelacijskega koeficienta in F-rezultata, kažejo, da so avtomatske metrike in sintetični podatki dobro uspešni pri predurjenju, naši prispevki pa so uvrščeni na prvo mesto pri dveh od štirih jezikovnih parov. Podrobnejši pogled na vpliv vsake meritve na nadaljnje opravilo kaže na večjo uspešnost meritev, usmerjenih v žetone, medtem ko študija ablacije poudarja koristnost izvajanja samonadzorovanega in predusposabljanja QE.", 'jv': 'Gambar iki bakal ngewehi nggawe NIND Kiotong kanggo mbatalog nggo masara kalite, kalite, nggo yen-teman wigatik (task 3). Awak dhéwé nglanggar aturan tembangsa nik nggawe Tipe model sing paling nggawe 11 nggambar, telu nggambar lan telu nggambar tarjamahan kalite metika. Mulai XLM-R checkpoint, kita tutunggo yen ditambah podho tarjamahan kanggo ngubah cilihan cilihan, njaluk mulai alêh bantuan ingkang modeleling to qE tutunggo sembol sing usurti, tualke iso nggawe model. Meweke ono mulai perusahaan kelompok nggawe gerangkamu kelompok karo perusahaan lan F-punika menehi winih dhéwé, dadi otomatik karo sistem sing gawe ngubah perusahaan kanggo nyengkamu, karo hal-nyengkamu siji sing wis nguasai siji cara-warni iki sak lawangan langutan. Ndhek luwih-luwih wegah kuwi nggawe mbelak sistem sing dipunangé awak dhéwé nggawe barang nggawe barang token nggawe Metika sing nduwih apik, terus alih dhéwé urip nggawe ngupakan seneng nggawe nguasai perusahaan sampeyan ngon nggawe barang-urip iki banget.', 'ha': "Wannan takardar da ke bãyar da shirin NICT Kyoto wa Shirin Hana Kiawa na WMT'21 (QET) Kyatori mai Shara aikin da aka Share shi (Tafiyar 3). Mataimakinmu yana dõgara mainli a kan misalin QEki da ya yi daidai game da shi, mu yi amfani da nau'i 11 cikin harshen, da daraja uku da metrics masu nau'i ga fassarar-daraja uku. @ action Ana sami matsala a kan jarraba da aka ƙayyade girmar kofi da F-score ya nuna cewa data na farat ɗaya da za'a aikata mazaɓa wa kiraffi, da basalinmu suka ranka kwance a biyu daga nau'i huɗu. Ka dũba da mafi ƙaranci ga ajin kõwane metric a ƙarƙashi na ƙarƙashi, yana nũna babban performance wa metricikin da aka juyi wa ayuka, kuma a lokacin karatun an sa amfani da yin tafiyar da shi duk masu tsari da kuma QEki ya yi zafi.", 'he': "This paper presents the NICT Kyoto submission for the WMT'21 Quality Estimation (QE) Critical Error Detection shared task (Task 3).  הגישה שלנו תלויה בעיקר במודל QE שימוש על 11 זוגות שפות, שלוש רמת משפטים ושלושה מטריות איכות תרגום רמת מילים. מתחיל מנקודת בדיקה XLM-R, אנחנו מבצעים אימונים ממשיכים על ידי שינוי אובייקטיב הלימוד, להחליף מדוגל שפה מסוכנת לאותות ממיונים QE, לפני שידרוך ומסדר את הדוגמנים. תוצאות שנקבלו במבחן במונחים של קופיציונט התאמה ו-F-Score מראים כי מטריקה אוטומטית ומידע סינטטי מצליחים היטב לאימון מראש, עם ההעברות שלנו מודרגות קודם לשני מתוך ארבעה זוגות שפות. מבט עמוק יותר על ההשפעה של כל מטריקה על המשימה התחתונה מצביע על ביצועים גבוהים יותר למטריקות המיוחדות על סימנים, בעוד מחקר אובלציה מזכיר את השימוש של ביצוע גם ביצועים על פיקוח עצמי ו-QE.", 'bo': "ཤོག་བྱང་འདིས་NICT Kyoto་ཀྱི་གནད་སྡུད་ལ་WMT'21 རིགས་གཟུགས་རིམ་སྟོན་པ(QE)ཆེན་མཁན་གྱི་ནོར་འཁྲུལ་བསམ་བློ་གཏོང Our approach relies mainly on QE model pretraining for which we used 11 language pairs, three sentence-level and three word-level translation quality metrics. Starting from an XLM-R checkpoint, we perform continued training by modifying the learning objective, switching from masked language modeling to QE oriented signals, before finetuning and ensembling the models. Results obtained on the test set in terms of correlation coefficient and F-score show that automatic metrics and synthetic data perform well for pretraining, with our submissions ranked first for two out of four language pairs. A deeper look at the impact of each metric on the downstream task indicates higher performance for token oriented metrics, while an ablation study emphasizes the usefulness of conducting both self-supervised and QE pretraining."}
{'en': 'Direct Exploitation of Attention Weights for Translation Quality Estimation', 'ar': 'الاستغلال المباشر لأوزان الانتباه لتقدير جودة الترجمة', 'fr': "Exploitation directe des pondérations d'attention pour l'estimation de la qualité", 'es': 'Explotación directa de los pesos de atención para la estimación de la calidad', 'pt': 'Exploração direta de pesos de atenção para estimativa de qualidade de tradução', 'ja': '翻訳品質推定のための注意重みの直接的な利用', 'ru': 'Прямое использование весов внимания для оценки качества перевода', 'zh': '直用意权重译质', 'hi': 'अनुवाद गुणवत्ता अनुमान के लिए ध्यान वजन का प्रत्यक्ष शोषण', 'ga': 'Saothrú Díreach Meáchain Airde Chun Meastachán Cáilíochta an Aistriúcháin', 'hu': 'A fordítási minőségbecsléshez szükséges figyelemsúlyok közvetlen kihasználása', 'el': 'Άμεση αξιοποίηση των βαρών προσοχής για την εκτίμηση της ποιότητας της μετάφρασης', 'ka': 'თავისუფალური განსაზღვრებისთვის დაახლოების განსაზღვრება', 'it': 'Sfruttamento diretto dei pesi di attenzione per la stima della qualità della traduzione', 'lt': 'Tiesioginis dėmesio naudojimas vertimo kokybės vertinimui', 'mk': 'Директно искористување на вниманието тежини за проценка на квалитетот на преводот', 'ms': 'Penggunaan langsung berat perhatian untuk penilaian kualiti terjemahan', 'kk': 'Аудару сапасының тәртіпсіздік тегістерін тәртіпсіздік эксплуатация', 'mt': 'Esplojtazzjoni diretta ta’ Piżijiet ta’ Attenzjoni għall-Istima tal-Kwalità tat-Traduzzjoni', 'ml': 'പരിഭാഷപൂര്\u200dണ്ണത്തിനുള്ള എസ്റ്റീമേഷന്\u200d വൈറ്റുകളുടെ നേരിട്ട് എക്സ്പ്ലോയിട്ട് ചെയ്യുക', 'no': 'Direkt eksplodering av merksomhetsverker for estimating av omsetjingskvalitet', 'sr': 'Direktna eksplozija težina pažnje za procjenu kvalitete prevoda', 'mn': 'Шинэ хэлбэрээр орчуулахын тулд анхаарлын хэмжээсүүдийн шууд Exploitation of Attention Weights for Translation Quality Estimation', 'si': 'වාර්ථාව කුළුවත් අනුමාණය සඳහා අවධානය ගැන ප්\u200dරතික්\u200dරමණය', 'pl': 'Bezpośrednie wykorzystanie wag uwagi do oceny jakości tłumaczeń', 'ro': 'Exploatarea directă a greutăților de atenție pentru estimarea calității traducerii', 'ta': 'Direct Exploitation of Attention Weights for Translation Quality Estimation', 'so': 'Direct Exploitation of Attention Weights for Translation Quality Estimation', 'ur': 'ترجمہ کی کیفیت کا ارزش کے لئے دقیق توجه وزن کا انتشار', 'sv': 'Direkt utnyttjande av uppmärksamhetsvikter för bedömning av översättningskvalitet', 'uz': 'Name', 'vi': 'Phát triển trực tiếp các trọng lượng chú ý cho lớp dịch ước lượng chất lượng', 'bg': 'Директно използване на тежести за внимание за оценка на качеството на превода', 'hr': 'Direktna eksplozija težina pažnje za procjenu kvalitete prevoda', 'da': 'Direkte udnyttelse af opmærksomhedsvægte til vurdering af oversættelseskvalitet', 'nl': 'Directe benutting van aandachtsgewichten voor de schatting van de vertaalkwaliteit', 'fa': 'انفجار مستقیم وزن توجه برای ارزیابی کیفیت ترجمه', 'id': 'Eksploatasi langsung berat perhatian untuk penilaian kualitas terjemahan', 'de': 'Direkte Nutzung von Aufmerksamkeitsgewichten für die Schätzung der Übersetzungsqualität', 'ko': '주의권을 직접 이용하여 번역 품질 평가를 진행하다', 'tr': 'Terjime Quality Taýýarlama üçin Diňe Gaýd Etme Taýýarlamasy', 'af': 'Direct Exploitation of Attention Weights for Translation Quality Estimation', 'sq': 'Shfrytëzimi i drejtpërdrejtë i peshëve të vëmendjes për vlerësimin e cilësisë së përkthimit', 'sw': 'Matumizi ya moja kwa moja kwa ajili ya Usalama wa Tafsiri', 'am': 'ምርጫዎች', 'hy': 'Ուշադրության կենտրոնների ուղիղ օգտագործումը թարգմանության որակի գնահատման համար', 'az': 'Tərcümə Cənnətləri Ölçüsü Gözünün Ölçüsünün Doğru Exploitation of Attention Weights for Translation Quality Estimation', 'bn': 'অনুবাদের মান গণনার জন্য সরাসরি মনোযোগ উইটস ব্যবহার করুন', 'bs': 'Direktna eksplozija težina pažnje za procjenu kvalitete prevoda', 'cs': 'Přímé využití váhy pozornosti pro odhad kvality překladu', 'et': 'Tähelepanukaalude otsene kasutamine tõlkekvaliteedi hindamisel', 'fi': 'Huomiopainojen suora hyödyntäminen käännöksen laadun arvioinnissa', 'ca': "Explotació directa de pes d'atenció per estimar la qualitat de la traducció", 'he': 'Direct Exploitation of Attention Weights for Translation Quality Estimation', 'jv': 'Label', 'sk': 'Neposredno izkoriščanje uteži pozornosti za oceno kakovosti prevajanja', 'bo': 'སྤྱི་ཚོགས་དབྱེ་བ་ལུགས་ཀྱི་ཚད་ལ་ཐད་ཀར་གནད་དོན་ཕྲེང་ཚད', 'ha': 'Phonon:: MMF:: EffectFactory'}
{'en': 'The paper presents our submission to the WMT2021 Shared Task on Quality Estimation (QE). We participate in sentence-level predictions of human judgments and post-editing effort. We propose a glass-box approach based on attention weights extracted from ', 'ar': 'تقدم الورقة تقديمنا إلى مهمة WMT2021 المشتركة حول تقدير الجودة (QE). نشارك في التنبؤات على مستوى الجملة للأحكام البشرية وجهود ما بعد التحرير. نقترح نهج الصندوق الزجاجي على أساس أوزان الانتباه المستخرجة من أنظمة الترجمة الآلية. على عكس الأعمال السابقة ، نستكشف بشكل مباشر مصفوفات وزن الانتباه دون استبدالها بمقاييس عامة (مثل الانتروبيا). نظهر أنه يمكن تدريب بعض نماذجنا بكمية صغيرة من البيانات ذات العلامات عالية التكلفة. في غياب بيانات التدريب ، لا يزال نهجنا يوضح ارتباطًا خطيًا معتدلًا ، عند التدريب باستخدام البيانات التركيبية.', 'es': 'El artículo presenta nuestra presentación a la Tarea Compartida sobre Estimación de la Calidad (QE) del WMT2021. Participamos en las predicciones a nivel de oración de los juicios humanos y en el esfuerzo posterior a la edición. Proponemos un enfoque de caja de vidrio basado en los pesos de atención extraídos de los sistemas de traducción automática. A diferencia de los trabajos anteriores, exploramos directamente las matrices de ponderación de atención sin sustituirlas por métricas generales (como la entropía). Demostramos que algunos de nuestros modelos se pueden entrenar con una pequeña cantidad de datos etiquetados de alto costo. En ausencia de datos de entrenamiento, nuestro enfoque sigue demostrando una correlación lineal moderada, cuando se entrena con datos sintéticos.', 'fr': "Le document présente notre soumission à la tâche partagée WMT2021 sur l'estimation de la qualité (QE). Nous participons aux prédictions au niveau de la phrase des jugements humains et aux efforts de post-édition. Nous proposons une approche «\xa0boîte en verre\xa0» basée sur des poids d'attention extraits des systèmes de traduction automatique. Contrairement aux travaux précédents, nous explorons directement les matrices de pondération de l'attention sans les remplacer par des mesures générales (comme l'entropie). Nous montrons que certains de nos modèles peuvent être entraînés avec une petite quantité de données étiquetées à coût élevé. En l'absence de données d'entraînement, notre approche démontre toujours une corrélation linéaire modérée, lorsqu'elle est entraînée avec des données synthétiques.", 'pt': 'O documento apresenta nossa submissão à Tarefa Compartilhada WMT2021 sobre Estimativa de Qualidade (QE). Participamos de previsões em nível de sentença de julgamentos humanos e esforços de pós-edição. Propomos uma abordagem de caixa de vidro baseada em pesos de atenção extraídos de sistemas de tradução automática. Em contraste com os trabalhos anteriores, exploramos diretamente matrizes de peso de atenção sem substituí-las por métricas gerais (como entropia). Mostramos que alguns de nossos modelos podem ser treinados com uma pequena quantidade de dados rotulados de alto custo. Na ausência de dados de treinamento, nossa abordagem ainda demonstra uma correlação linear moderada, quando treinada com dados sintéticos.', 'ja': 'この論文では、WMT 2021 Shared Task on Quality Estimation （ QE ）への提出を紹介しています。私たちは、人間の判断とポストエディットの努力の文章レベルの予測に参加します。機械翻訳システムから抽出された注意重みに基づいたガラス箱アプローチを提案します。これまでの作品とは対照的に、（エントロピーのような）一般的な指標に置き換えることなく、注意重み行列を直接探索する。私たちのモデルのいくつかは、少量の高コストのラベル付けされたデータでトレーニングすることができることを示しています。トレーニングデータがない場合、合成データでトレーニングした場合でも、アプローチは中程度の線形相関を示します。', 'zh': '本文向我WMT2021质料(QE)的同务提交了我们的材料。 我们参加人们判断的句子和译后编辑。 立机器翻译统中提取注意权重玻璃盒法。 比之前事,直探权矩阵,不以众指标(熵)易之。 我们这些模样可以用少量的高成本标记数据训练。 未练数者,当用合数而教之,吾道犹有适线性相关性。', 'ru': 'В документе представлено наше представление для совместной задачи WMT2021 по оценке качества (QE). Мы участвуем в прогнозировании человеческих суждений на уровне предложений и в постредактировании. Мы предлагаем подход «стеклянный ящик», основанный на весах внимания, извлеченных из систем машинного перевода. В отличие от предыдущих работ, мы напрямую исследуем весовые матрицы внимания, не заменяя их общими метриками (например, энтропией). Мы показываем, что некоторые из наших моделей могут быть обучены с небольшим количеством дорогостоящих данных с маркировкой. При отсутствии обучающих данных наш подход по-прежнему демонстрирует умеренную линейную корреляцию при обучении синтетическим данным.', 'hi': 'पेपर गुणवत्ता अनुमान (क्यूई) पर WMT2021 साझा कार्य के लिए हमारे सबमिशन प्रस्तुत करता है। हम मानव निर्णय और पोस्ट-संपादन प्रयास की वाक्य-स्तरीय भविष्यवाणियों में भाग लेते हैं। हम मशीन अनुवाद प्रणालियों से निकाले गए ध्यान भार के आधार पर एक ग्लास-बॉक्स दृष्टिकोण का प्रस्ताव करते हैं। पिछले कार्यों के विपरीत, हम सीधे सामान्य मीट्रिक (जैसे एन्ट्रॉपी) के साथ उन्हें बदलने के बिना ध्यान वजन matrices का पता लगाने। हम दिखाते हैं कि हमारे कुछ मॉडलों को उच्च लागत वाले लेबल वाले डेटा की एक छोटी राशि के साथ प्रशिक्षित किया जा सकता है। प्रशिक्षण डेटा की अनुपस्थिति में हमारा दृष्टिकोण अभी भी एक मध्यम रैखिक सहसंबंध को दर्शाता है, जब सिंथेटिक डेटा के साथ प्रशिक्षित किया जाता है।', 'ga': 'Cuireann an páipéar ár n-aighneacht i láthair don Tasc Comhroinnte ar Mheastachán Cáilíochta (QE) WMT2021. Glacaimid páirt i réamh-mheastacháin ar leibhéal na pianbhreithe ar bhreithiúnais dhaonna agus ar iarracht iar-eagarthóireachta. Molaimid cur chuige bosca gloine bunaithe ar aird-ualú a bhaintear as córais aistriúcháin mheaisín. I gcodarsnacht leis na saothair roimhe seo, déanaimid iniúchadh díreach ar mhaitrísí aird-mheáchan gan méadracht ghinearálta (cosúil le heantrópacht) a chur ina n-ionad. Léiríonn muid gur féidir roinnt dár samhlacha a oiliúint le méid beag de shonraí lipéadaithe ardchostas. In éagmais sonraí oiliúna léiríonn ár gcur chuige comhghaol measartha líneach fós, nuair a chuirtear oiliúint ar shonraí sintéiseacha.', 'hu': 'A tanulmány bemutatja benyújtásunkat a WMT2011 Shared Task on Quality Estimation (QE) című közös feladatra. Részt veszünk az emberi ítéletek mondatszintű előrejelzéseiben és utószerkesztési erőfeszítéseiben. Üvegdobozos megközelítést javasolunk, amely a gépi fordító rendszerekből kivont figyelemsúlyokon alapul. Az előző munkákkal ellentétben közvetlenül feltárjuk a figyelemsúly mátrixokat anélkül, hogy általános metrikákkal (pl. entrópia) helyettesítenénk őket. Megmutatjuk, hogy néhány modellünk kis mennyiségű, magas költségű címkézett adattal képezhető. Edzési adatok hiányában a megközelítésünk mérsékelt lineáris korrelációt mutat, ha szintetikus adatokkal képzünk.', 'ka': 'დაახლოები ჩვენი გავამხსენება WMT2021 გაყოფილი საქმე განსაზღვრებაზე (QE). ჩვენ მოთავსდებით ადამიანის წესების და შემდეგ რედაქტირების წესების წარმოდგენებში. ჩვენ შეგიძლიათ მაქსინური გაგრძელება სისტემიდან გამოყენებული გონტაქტის გაზრძელება. მიმდინარე სამუშაოების კონტრესტაციაში, ჩვენ განვიხილოთ ინტერპოფიის მარტირებით გადაცვლით უბრალოდ მარტირებით (როგორც ენტერპოფია). ჩვენ ჩვენი მოდელების ზოგიერთი მოდელები შეგვიძლია აკეთება მარტივი მონაცემებით. თუმცა არსებობს მონაცემების მონაცემები, ჩვენი მონაცემები უკვე მომდინარე ლეინერი კორელაცია, როდესაც სინტეტიკური მონაცემებით გაგრძნობა.', 'it': "L'articolo presenta la nostra presentazione al WMT201 Shared Task on Quality Estimation (QE). Partecipiamo alle previsioni a livello di frase dei giudizi umani e allo sforzo post-editing. Proponiamo un approccio glass-box basato sui pesi di attenzione estratti dai sistemi di traduzione automatica. A differenza dei lavori precedenti, esploriamo direttamente le matrici di peso dell'attenzione senza sostituirle con metriche generali (come l'entropia). Mostriamo che alcuni dei nostri modelli possono essere formati con una piccola quantità di dati etichettati ad alto costo. In assenza di dati di allenamento il nostro approccio dimostra ancora una moderata correlazione lineare, se addestrato con dati sintetici.", 'el': 'Η εργασία παρουσιάζει την υποβολή μας στην Κοινή Εργασία Εκτίμησης Ποιότητας (QE). Συμμετέχουμε σε προβλέψεις σε επίπεδο ποινών ανθρώπινων κρίσεων και σε προσπάθεια μετεκδοσής. Προτείνουμε μια προσέγγιση γυάλινου κουτιού βασισμένη σε βάρη προσοχής που εξάγονται από συστήματα μηχανικής μετάφρασης. Σε αντίθεση με τα προηγούμενα έργα, εξερευνούμε άμεσα τους πίνακες βάρους προσοχής χωρίς να τους αντικαταστήσουμε με γενικές μετρήσεις (όπως η εντροπία). Δείχνουμε ότι ορισμένα από τα μοντέλα μας μπορούν να εκπαιδευτούν με μια μικρή ποσότητα ενός υψηλού κόστους επισημασμένων δεδομένων. Ελλείψει δεδομένων εκπαίδευσης η προσέγγισή μας εξακολουθεί να παρουσιάζει μέτρια γραμμική συσχέτιση, όταν εκπαιδεύεται με συνθετικά δεδομένα.', 'lt': 'Dokumente pristatomas mūsų pasiūlymas WMT2021 bendram kokybės vertinimo uždaviniui. Mes dalyvaujame numatant žmonių sprendimus bausmėse ir po redakcijos. Siūlome taikyti stiklo langelio metodą, pagrįstą dėmesio svoriais, gautais iš mašinų vertimo sistemų. Priešingai nei ankstesniuose darbuose, mes tiesiogiai tiriame dėmesio svorio matrizes, nenustatydami jų bendromis metrijomis (pvz., entropija). Mes parodome, kad kai kurie mūsų modeliai gali būti apmokomi nedideliu kiekiu didelių sąnaudų ženklintų duomenų. Nesant mokymo duomenų, mūsų metodas vis dar rodo vidutinę linijinę koreliaciją, kai jis mokomas su sintetiniais duomenimis.', 'kk': 'Қағаз WMT2021 сапатты оқиға (QE) үшін ортақ тапсырманы ортақ тапсырмаға жібереді. Біз адамдардың тұхбаттарын және өңдеу кейінгі әрекеттерінің тұхбаттарына қатынасыз. Біз машинаны аудару жүйелерінен шығарылған қатынас негізінде жақсы көшірмесін ұсынамыз. Алдыңғы жұмыстардың қарсы, біз оларды жалпы метрикалық (энтропия сияқты) алмастырып, тәртіпке қатынасыз матрицияларын зерттейміз. Біз өзіміздің кейбір моделдеріміздің кейбір мәліметтері жазылған жоғары мәліметтерімен оқытуға болады. Оқыту деректері жоқ болғанда, синтетикалық деректерді оқыту үшін біздің тәжірибеміз оқытуға болады.', 'mt': 'Id-dokument jippreżenta s-sottomissjoni tagħna lid-WMT2021 Task Konġunt dwar l-Istima tal-Kwalità (QE). Aħna qed jipparteċipaw fit-tbassir fil-livell tas-sentenzi tas-sentenzi umani u fl-isforz ta’ wara l-edizzjoni. Aħna nipproponu approċċ tal-kaxxa tal-ħġieġ ibbażat fuq il-piżijiet tal-attenzjoni estratti mis-sistemi tat-traduzzjoni tal-magni. B’kuntrast max-xogħlijiet preċedenti, aħna esploraw direttament il-matriċi tal-piż tal-attenzjoni mingħajr ma jissostitwixxuhom b’metriċi ġenerali (bħall-entropija). Aħna nuru li xi wħud mill-mudelli tagħna jistgħu jiġu mħarrġa b’ammont żgħir ta’ dejta ttikkettata bi spiża għolja. Fin-nuqqas ta’ dejta ta’ taħriġ l-approċċ tagħna għadu juri korrelazzjoni lineari moderata, meta mħarreġ b’dejta sintetika.', 'ml': 'ഈ പേപ്പറില്\u200d നമ്മുടെ കീഴ്പെടുത്തുന്നത് WMT2021 പങ്കെടുത്ത ജോലിയുടെ കീഴിലേക്കാണ്. മനുഷ്യരുടെ വിധികളും പിന്നെ എഡിറ്ററിങ്ങിനു ശ്രമിക്കുന്ന ശ്രമങ്ങളും ഞങ്ങള്\u200d ശിക്ഷയുടെ നില പ്രവചനങ്ങളി മെഷീന്\u200d പരിഭാഷണ സിസ്റ്റത്തില്\u200d നിന്നും പുറത്തെടുക്കപ്പെട്ട ഭാഗങ്ങള്\u200d അടിസ്ഥാനമായി ഒരു ഗ്ലാസ് ബോക മുമ്പുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200dക്ക് വിരോധമായി നമ്മള്\u200d നേരിട്ട് ഭാരം മാറ്റിക്കൊണ്ട് നോക്കുന്നു. പൊതുവായ മെറ്റി We show that some of our models can be trained with a small amount of a high-cost labelled data.  പരിശീലനത്തിന്റെ വിവരങ്ങള്\u200d ഇല്ലാത്തതിനാല്\u200d നമ്മുടെ പ്രായോഗ്യം ഇപ്പോഴും കാണിച്ചുകൊണ്ടിരിക്കുന്നു, സിന്തി', 'no': 'Papiret viser søket vårt til WMT2021 delt oppgåve om kvalitetevaluering (QE). Vi deltar i førehandsvising av setningsnivå på menneske sprøytebrukar og postredigeringspåminningar. Vi foreslår ein glass-boks tilnærming basert på oppmerksvekt utpakka frå maskineoversettelsystemet. I contrast to the previous works, we directly explore attention weight matrices without replacing them with general metrics (like entropy). Vi viser at nokre av våre modeller kan trenjast med ein liten mengd av eit høg kostnad merket data. Dersom det ikkje finst opplæringsdata, vil tilnærminga vårt fortsatt vise ein moderat lineær korrelasjon når det er trent med syntetiske data.', 'mk': 'Документот го претставува нашето поднесување на WMT2021-та заедничка задача за проценка на квалитетот (QE). Ние учествуваме во предвидувањата на нивото на казни за човечките пресуди и напорите по уредувањето. Предложуваме стаклен пристап базиран на теговите на вниманието извадени од машинските преведувачки системи. За разлика од претходните дела, директно ги истражуваме матриците на тежина на вниманието без да ги замениме со генерални метрики (како ентропија). Покажуваме дека некои од нашите модели можат да бидат обучени со мала количина на високи цени означени податоци. Во отсуството на податоци за обука нашиот пристап сé уште покажува умерена линијарна корелација, кога е обучен со синтетички податоци.', 'ms': 'Kertas ini memperkenalkan penghantaran kami kepada Tugas Berkongsi WMT2021 mengenai Estimasi Kualiti (QE). Kami berpartisipasi dalam ramalan tahap kalimat penghakiman manusia dan usaha post-edisi. Kami cadangkan pendekatan kotak kaca berdasarkan berat perhatian yang dikeluarkan dari sistem terjemahan mesin. Berbeza-beza dengan kerja sebelumnya, kita secara langsung mengeksplorasi matriks berat perhatian tanpa menggantikannya dengan metrik umum (seperti entropi). Kami menunjukkan bahawa beberapa model kita boleh dilatih dengan jumlah kecil data yang diberikan label harga tinggi. Dalam ketiadaan data latihan pendekatan kita masih menunjukkan korelasi linear yang sederhana, apabila dilatih dengan data sintetik.', 'sr': 'U novinama se predstavlja naše podatke podijeljenom zadatku WMT2021 za procjenu kvalitete (QE). Mi sudjelujemo u predviđanjima na nivou kazne o ljudskim osuđivanjima i naporima nakon redakcije. Predlažemo pristup staklenoj kutiji na osnovu težine pažnje izvučene iz sustava prevoda mašine. Pored prethodnih radova, direktno istražujemo matrice težine pažnje a da ih ne zamenimo općem metrikom (poput entropije). Pokazujemo da neki od naših modela mogu biti obučeni sa malim količinom podataka o visokim troškovima. U odsustvu podataka o obuci, naš pristup još uvijek pokazuje umjerenu linearnu korelaciju, kada je obučen sintetičkim podacima.', 'pl': 'W artykule przedstawiono naszą zgłoszenie do WMT2028 Shared Task on Quality Estimation (QE). Uczestniczymy w przewidywaniach ludzkich osądów na poziomie zdań oraz wysiłkach post-edycyjnych. Proponujemy podejście szklane oparte na wagach uwagi uzyskanych z systemów tłumaczenia maszynowego. W przeciwieństwie do poprzednich prac badamy bezpośrednio macierze wagi uwagi bez zastępowania ich ogólnymi wskaźnikami (np. entropią). Pokazujemy, że niektóre z naszych modeli mogą być przeszkolone z niewielką ilością wysoko kosztowych etykietowanych danych. W przypadku braku danych treningowych nasze podejście wciąż wykazuje umiarkowaną korelację liniową, przy użyciu danych syntetycznych.', 'ro': 'Lucrarea prezintă prezentarea noastră la misiunea WMT201 Shared Task on Quality Estimation (QE). Participăm la predicțiile la nivel de propoziții ale judecăților umane și eforturile post-editare. Propunem o abordare a cutiilor de sticlă bazată pe greutățile de atenție extrase din sistemele de traducere automată. Spre deosebire de lucrările anterioare, explorăm direct matricile greutății atenției fără a le înlocui cu metrici generale (cum ar fi entropia). Noi arătăm că unele dintre modelele noastre pot fi instruite cu o cantitate mică de date etichetate cu costuri ridicate. În absența datelor de antrenament, abordarea noastră demonstrează încă o corelație liniară moderată, atunci când este instruită cu date sintetice.', 'so': "Qoraalka warqaddu wuxuu soo bandhigaa warqaddayada loo soo dhiibay shaqo la sharciyey qiimaanshaha qiimaanshaha (QE). Waxaynu ka qeybqaadanaynaa wax ka sii sheegidda xaakinnada dadka iyo hawlaha wax ku hagaajiya ka dib. Waxaynu horumarinaynaa qaabilaad muraayad ah oo ku saleysan miisaanka miisaanka laga soo saaray nidaamka turjumidda machine. Si ka duwan shaqadii hore, si toos ah ayaannu u baaraynaa qalabka miisaanka ee miisaanka, iyadoon ku beddelin metrici caadiga ah (sida entropy). Waxaynu muujinnaa in qaababkayaga qaarkood lagu tababari karo tiro yar oo macluumaad ku qoran. Hadii aan la'jirin macluumaad waxbarasho, dhaqdhaqaalahayagu weli wuxuu muujiyaa xiriir hoos u dhexeeya, marka lagu baranayo macluumaad la xiriira.", 'mn': 'Энэ цаас WMT2021-ийн хуваалтын ажил (QE) талаар биднийг дэвшүүлж байна. Бид хүн төрөлхтний шүүмжлэх, захирах хичээлд оролцож байна. Бид машины орчуулах системээс гарсан анхаарлын жин дээр шилэн хайрцаг хандлага зааж байна. Өмнөх ажлын эсрэг бид анхаарлын жингийн матрицуудыг ерөнхий метрикийг орлуулахгүй шууд судалж байна. Бид зарим загваруудыг жижиг хэмжээний үнэ цэнэтэй мэдээллээр суралцаж болно гэдгийг харуулж байна. Сургуулийн өгөгдлийн байхгүй байхад бидний арга баримт нь синтетик өгөгдлийн сургалтын үед дундаж шулууны холбоотой байдлыг харуулдаг.', 'sv': 'Uppsatsen presenterar v책rt bidrag till WMT201s delade uppgift om kvalitetsuppskattning (QE). Vi deltar i meningsniv책f철ruts채gelser av m채nskliga bed철mningar och efterredigeringsarbete. Vi f철resl책r en glasl책da baserad p책 uppm채rksamhetsvikter som extraheras fr책n maskin철vers채ttningssystem. Till skillnad fr책n tidigare arbeten utforskar vi uppm채rksamhetsviktsmatriser direkt utan att ers채tta dem med generella m책tt (som entropi). Vi visar att vissa av v책ra modeller kan tr채nas med en liten m채ngd h철gkostnadsm채rkta data. I avsaknad av tr채ningsdata visar v책rt tillv채gag책ngss채tt fortfarande en m책ttlig linj채r korrelation, n채r det tr채nas med syntetiska data.', 'si': 'The papers presents our Sub-references to the WMT2021 shared Job on the Equity Estimation (QE). අපි මිනිස්සු නිරීක්ෂණය සහ පස්සේ සංපාදනය කරන්න ප්\u200dරයෝජනය කරනවා. අපි ග්\u200dලාස් බොක්ස් එක ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරනවා පද්ධතිය පද්ධතියෙන් අවධානය කරන්න ප්\u200dරශ්න මුලින් වැඩ වලට විරුද්ධ වෙනුවෙන්, අපි සාමාන්\u200dය මෙට්\u200dරොපි වලින් ඔවුන්ව ස්ථාපනය කරන්න බැරි අවධානය ගැන බලන අපි පෙන්වන්නේ අපේ මොඩේල් එක්කෙන් ප්\u200dරශ්නයක් වෙන්න පුළුවන් කියලා ප්\u200dරශ්නයක් වෙන්න පුළුවන් ව ප්\u200dරශ්නය දත්ත නැති වෙලාවට අපේ ප්\u200dරශ්නයක් තාමත් ප්\u200dරශ්නයක් තියෙනවා, සංවිධානය දත්ත සමග ප්\u200dරශ්නයක්', 'ta': 'காகிதம் WMT2021 பகிர்ந்த பணிக்கு எங்கள் சரணங்களை கூறுகிறது தரம் கணக்கீடு (QE). நாங்கள் மனித நியாயத்திற்கும் மற்றும் திருத்த முயற்சியும் வாக்கி நிலையில் பகிர்ந்து கொள்க கணினி மொழிபெயர்ப்பு அமைப்புகளிலிருந்து வெளியேற்றப்பட்ட எடைகளை அடிப்படையாக நாம் ஒரு கண்ணாடி பெட்ட முந்தைய வேலைகளுக்கு எதிராக, நாம் நேரடியாக கவனத்தை எடுத்து பொருள் மெட்ரிக்களை மாற்றாமல் கண்டறிகிறோம். நாம் எங்கள் மாதிரிகளில் சில பயிற்சி செய்ய முடியும் என்று காண்பிக்கிறோம் அதிக செலவு குறிப்பிட்ட தகவல் பயிற்சி தகவல் காணவில்லையில் எங்கள் செயல்பாடு இன்னும் ஒரு நடுவான வரிசை இணைப்பை காண்பிக்கிறது, ஒரு கூட்டிணைப்பு', 'ur': 'The paper presents our submission to the WMT2021 Shared Task on Quality Estimation (QE). ہم انسان کے فیصلے اور اس کے بعد سمجھنے کی کوشش میں شریک ہوتے ہیں۔ ہم ایک گلاس باکس کے تقریبا کی پیشنهاد کرتے ہیں جو ماشین ترجمہ سیستموں سے اٹھایا گیا ہے۔ پہلے کے کاموں کے مقابلہ میں ہم مستقیماً توجه کے ماٹریس کو دیکھتے ہیں بغیر ان کو عمومی متریک (انٹروپی کی طرح) بدل دیتے ہیں۔ ہم دکھاتے ہیں کہ ہمارے کچھ موڈلے ایک چھوٹی مقدار کے ذریعہ سے استعمال کیے جاتے ہیں۔ ہماری طریقہ کی آموزش دیٹا کے غیر موجود ہونے کے بعد جب سینٹیسی ڈیٹا کے ساتھ آموزش کی جاتی ہے، ایک متوسط خط مرتبہ کو دکھاتا ہے.', 'uz': "Qogʻoz WMT2021 bilan birlashtirilgan vazifani (QE) sifatida ishga tayyorlaydi. Biz inson Xukumlari va tahrirlash orqali gapiruvchiga ega bo'lishimiz mumkin. Biz mashinalar tarjima tizimlaridan tashqarilgan qismlarni asosida qo'llash qutisini rivojlanamiz. Oldingi ish bilan boshqa bo'lsa, biz ularni umumiy metrik bilan almashtirishni boshqaramiz. Biz bir necha modelimizning bir necha ko'plab o'rganishlarimizni ko'rsatganimiz mumkin. Taʼminlovchi maʼlumotlar mavjud emas, bizning tuyg'urish imkoniyatini o'rganishda hech qachon o'zgarishni o'rganadi.", 'vi': 'Tờ giấy này giới thiệu chúng tôi chịu trách nhiệm giao dịch về ước lượng chất lượng (QE). Chúng tôi tham gia dự đoán cấp độ án của con người và nỗ lực sau sửa chữa. Chúng tôi đề nghị một phương pháp hộp kính dựa trên trọng lượng được lấy ra từ hệ thống dịch chuyển máy. Tương đối với các tác phẩm trước, chúng ta nghiên cứu trực tiếp các tấm séc trọng lượng chú ý mà không thay thế chúng bằng thước đo chung (như entropy). Chúng tôi cho thấy một số mô hình của chúng tôi có thể được đào tạo với một lượng nhỏ các dữ liệu có giá cao. Do không có dữ liệu về huấn luyện, phương pháp của chúng tôi vẫn thể hiện một mối tương quan nhỏ, khi được đào tạo bằng dữ liệu tổng hợp.', 'bg': 'Статията представя нашето представяне на споделената задача за оценка на качеството (Оценка на качеството). Участваме в предвиждания на ниво изречение на човешки преценки и следредакционни усилия. Предлагаме подход към стъклена кутия, базиран на тежести на вниманието, извлечени от системи за машинен превод. За разлика от предишните работи, ние директно изследваме матриците на тежестта на вниманието, без да ги заменяме с общи показатели (като ентропия). Показваме, че някои от нашите модели могат да бъдат обучени с малко количество данни, етикетирани с висока цена. При липса на данни за обучение нашият подход все още демонстрира умерена линейна корелация, когато се обучава със синтетични данни.', 'hr': 'U novinama se predstavlja naše podatke podijeljenom zadatku WMT2021 za procjenu kvalitete (QE). Mi sudjelujemo u predviđanjima na razini kazne o ljudskim sudovima i posturednim naporima. Predlažemo pristup staklenoj kutiji na temelju pažnje izvučenog iz sustava prevoda stroja. Za suprotnost prethodnim radovima, direktno istražujemo matrice težine pažnje bez zamjene ih općem metrijom (poput entropije). Pokazujemo da neki od naših modela mogu biti obučeni sa malim količinom podataka o visokim troškovima. U odsustvu podataka o obuci naš pristup još uvijek pokazuje umjerenu linearnu korelaciju, kada je obučena sintetičkim podacima.', 'nl': 'De paper presenteert onze inzending aan de WMT2028 Shared Task on Quality Estimation (QE). We nemen deel aan voorspellingen op zinsniveau van menselijke oordelen en post-editing inspanningen. We stellen een glasbox benadering voor op basis van aandachtsgewichten die uit machinevertaalsystemen worden gehaald. In tegenstelling tot de vorige werken onderzoeken we aandachtsgewichtsmatrices direct zonder ze te vervangen door algemene metrics (zoals entropie). We laten zien dat sommige van onze modellen getraind kunnen worden met een kleine hoeveelheid dure gelabelde data. Bij gebrek aan trainingsgegevens vertoont onze aanpak nog steeds een matige lineaire correlatie, wanneer getraind met synthetische data.', 'da': 'Opgaven præsenterer vores indsendelse til WMT201 Shared Task on Quality Estimation (QE). Vi deltager i forudsigelser på sætningsniveau af menneskelige domme og post-redigering indsats. Vi foreslår en glaskassetilgang baseret på opmærksomhedsvægte udvundet fra maskinoversættelsessystemer. I modsætning til de tidligere værker undersøger vi opmærksomhedsvægtmatricer direkte uden at erstatte dem med generelle metrics (som entropi). Vi viser, at nogle af vores modeller kan trænes med en lille mængde af en høj pris mærket data. I mangel af træningsdata viser vores tilgang stadig en moderat lineær korrelation, når den trænes med syntetiske data.', 'de': 'Der Beitrag stellt unseren Beitrag zur WMT2028 Shared Task on Quality Estimation (QE) vor. Wir beteiligen uns an Vorhersagen menschlicher Urteile auf Satzebene und Post-Editing Bemühungen. Wir schlagen einen Glaskasten-Ansatz vor, der auf Aufmerksamkeitsgewichten basiert, die aus maschinellen Übersetzungssystemen extrahiert werden. Im Gegensatz zu den vorangegangenen Arbeiten untersuchen wir Aufmerksamkeitsgewichtsmatrizen direkt, ohne sie durch allgemeine Metriken (wie Entropie) zu ersetzen. Wir zeigen, dass einige unserer Modelle mit einer geringen Menge an kostenintensiven etikettierten Daten trainiert werden können. Ohne Trainingsdaten zeigt unser Ansatz immer noch eine moderate lineare Korrelation, wenn er mit synthetischen Daten trainiert wird.', 'id': 'Kertas ini menunjukkan pengiriman kita ke WMT2021 Shared Task on Quality Estimation (QE). Kami berpartisipasi dalam prediksi tingkat kalimat penghakiman manusia dan usaha post-edisi. Kami mengusulkan pendekatan kotak kaca berdasarkan berat perhatian yang dikeluarkan dari sistem terjemahan mesin. In contrast to the previous works, we directly explore attention weight matrices without replacing them with general metrics (like entropy).  Kami menunjukkan bahwa beberapa model kita dapat dilatih dengan jumlah kecil dari data yang diberikan dengan biaya tinggi. In the absence of training data our approach still demonstrates a moderate linear correlation, when trained with synthetic data.', 'fa': 'این کاغذ تحویل ما را به وظیفه مشترک WMT2021 در ارزیابی کیفیت (QE) نشان می دهد. ما در پیش\u200cبینی\u200cهای سطح مجازات و تلاش بعد از ویرایش انسان شرکت می\u200cکنیم. ما پیشنهاد می\u200cکنیم روش جعبه شیشه بر اساس وزن توجه که از سیستم ترجمه ماشین خارج شده است. در مقابل کارهای قبلی، ما مستقیما ماتریس وزن توجه را تحقیق می کنیم بدون جایگزینش آنها با متریک عمومی (مانند انتروپی). ما نشان می دهیم که بعضی از مدل\u200cهایمان می\u200cتوانند با یک مقدار کوچک از داده\u200cهای پر هزینه\u200cای آموزش داده شوند. در غیر از اطلاعات آموزش، دستور ما هنوز ارتباط خطی متوسط را نشان می دهد، وقتی با اطلاعات سینتیک آموزش می دهد.', 'sw': 'Gazeti hilo linaleta ujumbe wetu kwenye kazi ya WMT2021 iliyoashirikishwa kwenye Hesabu (QE). Tunashiriki na utabiri wa kiwango cha hukumu za binadamu na juhudi za baada ya kuhariri. Tunazipendekeza mbinu za vifaa vya glasi kwa kutumia mizani zilizotolewa kutoka kwenye mfumo wa kutafsiri mashine. Tofauti na kazi zilizopita, tunachunguza moja kwa moja matoleo ya uzito bila kuwabadilisha kwa njia ya jumla (kama vile ujasiri). Tunaonyesha kuwa baadhi ya mifano yetu inaweza kufundishwa kwa kiasi kidogo cha taarifa za gharama zilizotajwa. Kwa kutokuwepo na takwimu za mafunzo, mbinu zetu bado zinaonyesha uhusiano wa msimamo wa kati, pale ambapo imefundishwa na takwimu za pamoja.', 'tr': 'Häzirki WMT2021-iň Quality Taýýarlama (QE) barada biziň hökmümizi gönderýär. Biz sözlem derejesinde adamlaryň hökmünü we düzenlemeden soňra çalyşyklaryň önümlerine chikanchas edýäris. Biz maşynyň terjime sistemalardan çykylýan üns çeken çyzgylygyna daýanýan a ýaklyk gutynyň golaýyny teklip edip otyrrys. Önceki çalışmaların tersine, dikkati ağırlık matrislerini genel metriklere almadan (entropi gibi) inceleyiriz. Biziň modellerimiziň käbirleri kiçi beden hasaplanýan ýagdaýlary bilen eğitilebilir. Biziň ýaryşymyz ýok maglumatlarymyz ýok bolsa, syntetik maglumatlar bilen okuw edilen wagtlar moderat çyzgylyk bilen çyzgylygyny görkezýär.', 'sq': 'Gazeta paraqet paraqitjen tonë në WMT2021 Task Shared on Quality Estimation (QE). Ne marrim pjesë në parashikimet e nivelit të dënimeve të gjykimeve njerëzore dhe përpjekjeve pas redigimit. Ne propozojmë një qasje me kuti xhami bazuar në peshat e vëmendjes të nxjerra nga sistemet e përkthimit të makinave. Në kundërshtim me punët e mëparshme, ne drejtpërdrejt eksplorojmë matricat e peshës së vëmendjes pa i zëvendësuar ato me metrika të përgjithshme (si entropia). Ne tregojmë se disa nga modelet tona mund të trajnohen me një sasi të vogël të dhënash me kosto të larta të etiketuara. Në mungesë të të dhënave të stërvitjes metoda jonë demonstron ende një korrelacion linear të moderuar, kur stërvitur me të dhënat sintetike.', 'ko': '본고는 우리가 WMT2021 품질평가 공유임무(QE)에 제출한 보고서를 소개한다.우리는 인류 판단의 문장급 예측과 후기 편집 작업에 참여한다.우리는 기계 번역 시스템에서 주의력을 추출할 수 있는 유리 상자를 기반으로 하는 방법을 제시했다.이전의 작업에 비해 우리는 주의권 중량 행렬을 직접 탐색하고 일반적인 도량(예를 들어 엔트로피)을 사용하지 않는다.우리는 우리의 일부 모델이 소량의 고비용 표기 데이터로 훈련을 할 수 있다는 것을 보여 준다.훈련 데이터가 부족한 상황에서 합성 데이터를 사용하여 훈련을 할 때 우리의 방법은 여전히 적당한 선형 관련성을 나타낸다.', 'am': 'የፕሬዝዳንቱ ጉዳዩ የWMT2021 ስራችንን በሙሉ ቁጥር (QE) የሚያሳየው ነው፡፡ የሰው ፍርድ እና በኋላ አስተካክል ፍላጎችን የፍርድ ደረጃ ትንቢት እናጋራለን፡፡ ከጋስታዊ ትርጉም ሲስተካከል በሚያሳየው የግልጭት ቦታ መቀናቀል እናስባለን፡፡ የቀድሞው ሥራ በተለየ፣ የክብር ሚትሪኮችን በአጠቃላይ ሚትሪክ (እንደ ኢንተሮፕ) ሳይለወጥም እናሳውቃለን፡፡ እናሳያቸዋለን የሞዴላዎቻችን አንዳንዶቹ ከፍተኛ ዋጋ የተለየ ዳታዎችን ሊማር ይችላል፡፡ ከዳታ ባይኖር የልማድ ግንኙነታችን ግን በተማራች ዳታዎችን በተማረ ጊዜ የመካከለኛ ቅርብ ግንኙነት ታሳያል፡፡', 'af': "Die papier voorsien ons ondersteuning aan die WMT2021 Gedeelde Opdrag op Kwaliteit Estimatie (QE). Ons deel in sentence-level voorskoue van menslike oordelings en post-editing effort. Ons voorstel 'n glasboks toegang gebaseer op aanmerksgewigte wat uit masjien vertalingsstelsels uitgevoer is. In contrast to the previous works, we directly explore attention weight matrices without replacing them with general metrics (like entropy). Ons wys dat sommige van ons modele kan opgelei word met 'n klein hoeveelheid van 'n hoë koste gemerkte data. In die absence van onderwerp data, ons toegang steeds 'n moderate lineêre korrelasie vertoon, wanneer onderwerp is met sintetiese data.", 'hy': 'Այս թղթին ներկայացնում է մեր ներկայացումը ՈւՄԹ2021-ի համագործակցած որակի գնահատման խնդիրներին: Մենք մասնակցում ենք մարդկային դատողությունների մակարդակի կանխատեսումներին և խմբագրելուց հետո: Մենք առաջարկում ենք ապակի արկղի մոտեցում, որը հիմնված է ուշադրության կշիռների վրա, որոնք ստացվում են մեքենայի թարգմանման համակարգերից: Ի հակադրություն նախորդ գործերին, մենք ուղղակի ուսումնասիրում ենք ուշադրության կշիռի մատրիկները առանց փոխարինելու դրանք ընդհանուր մետրիկներով (ինչպիսիք են էնտրոպիան): Մենք ցույց ենք տալիս, որ մեր մոդելներից ոմանք կարող են սովորեցնել բարձր արժեքներով պիտակուցված տվյալներով: In the absence of training data our approach still demonstrates a moderate linear correlation, when trained with synthetic data.', 'az': "Kağıt WMT2021'nin Cənnət Gözəltməsi (QE) barəsində paylaşılmış iş işimizi göstərir. Biz insan hökmünün və düzəltdikdən sonra düzəltdikdən sonra cümlələrə səviyyə tədbirlərə katılırıq. Biz maşın çeviri sistemindən çıxarılan təsirlərin a ğırlığına dayanan cam qutusu tərzini təklif edirik. Əvvəlki işlərə qarşı, biz onları genel metriklərlə əvəz etmədən (entropiya bənzər) dikkati ağır matriklərə baxırıq. Bizim modellərimizin bəzi modelləri yüksək malik məlumatları ilə təhsil edilə biləcəyini göstəririk. Müəllif məlumatların yoxduğu halda, sintetik məlumatları ilə təhsil edildiyi zaman orta linear bağlantısını göstərir.", 'bn': 'এই পত্রিকাটি আমাদের উইএমটি২০১২-এর কাজের প্রতি উপস্থাপন করেছে মান সম্মানের (কিউই)। We participate in sentence-level predictions of human judgments and post-editing effort.  আমরা মেশিন অনুবাদ সিস্টেম থেকে বের করে আকর্ষণের উপর ভিত্তিক একটি গ্লাস বাক্সের প্রস্তাব করি। পূর্ববর্তী কাজের বিরুদ্ধে আমরা সরাসরি মনোযোগ মাত্রিক খুঁজে বের করি সাধারণ মেট্রিকের (যেমন এন্ট্রোপি) ব্যবহার করে না। আমরা দেখাচ্ছি যে আমাদের কিছু মডেল প্রশিক্ষণ প্রদান করা যাবে একটা বেশী বেতনের তথ্য দিয়ে। প্রশিক্ষণের অনুপস্থিতিতে আমাদের পদক্ষেপ এখনো মধ্যবর্তী লাইনের সংযোগ প্রদর্শন করে, যখন সিন্টেটিক ডাটা প্রশিক্ষণ করা হয়।', 'bs': 'U novinama se predstavlja naše podatke podijeljenom zadatku WMT2021 za procjenu kvalitete (QE). Mi učestvujemo u predviđanjima na razini kazne o ljudskim sudovima i posturednim naporima. Predlažemo pristup staklenoj kutiji na temelju težine pažnje izvučene iz sustava prevoda mašine. U suprotnosti sa prethodnim radovima, direktno istražujemo matrice težine pažnje bez zamjene ih općem metrijom (poput entropije). Pokazujemo da neki od naših modela mogu biti obučeni sa malim količinom podataka o visokim troškovima. U odsustvu podataka o obuci naš pristup još uvijek pokazuje umjerenu linearnu korelaciju, kada je obučena sintetičkim podacima.', 'cs': 'Článek představuje náš příspěvek k WMT2028 Shared Task on Quality Estimation (QE). Podílíme se na predikcích lidských úsudků na úrovni věty a posteditačním úsilí. Navrhujeme přístup skleněné krabice založený na pozornostních hmotnostech extrahovaných ze strojových překladatelských systémů. Na rozdíl od předchozích prací přímo zkoumáme matice hmotnosti pozornosti, aniž bychom je nahrazovali obecnými metrikami (například entropií). Ukazujeme, že některé z našich modelů lze trénovat s malým množstvím vysoce nákladově označených dat. Při absenci tréninkových dat náš přístup stále demonstruje mírnou lineární korelaci, když trénujeme se syntetickými daty.', 'et': 'Töös esitatakse meie ettepanekud WMT22021 ühisele kvaliteedi hindamise ülesandele. Osaleme inimotsuste prognoosimisel lausetasemel ja toimetamisjärgsetes pingutustes. Pakume välja klaaskastist lähenemisviisi, mis põhineb masintõlkesüsteemidest eraldatud tähelepanukaaludel. Erinevalt eelmistest töödest uurime otse tähelepanu kaalu maatrikse, asendamata neid üldmõõdikutega (nt entroopia). Näitame, et mõningaid meie mudeleid saab koolitada väikese hulga kõrge hinnaga märgistatud andmetega. Koolitusandmete puudumisel näitab meie lähenemine endiselt mõõdukat lineaarset korrelatsiooni, kui koolitatakse sünteetiliste andmetega.', 'fi': 'Tässä artikkelissa esitellään artikkelimme WMT22021 Shared Task on Quality Estimation (QE) -hankkeeseen. Osallistumme lausetason ennustuksiin ihmisten tuomioista ja jälkieditointiin. Ehdotamme lasilaatikkoa, joka perustuu konekäännösjärjestelmistä poimittuihin huomiopainoihin. Toisin kuin aiemmissa teoksissa, tutkimme suoraan huomiopainomatriiseja korvaamatta niitä yleisillä mittareilla (kuten entropialla). Osoitamme, että osa malleistamme voidaan kouluttaa pienellä määrällä kalliilla merkittyjä tietoja. Harjoitustietojen puuttuessa lähestymistapamme osoittaa edelleen kohtalaisen lineaarisen korrelaation synteettisellä datalla harjoitettaessa.', 'ca': "El paper presenta la nostra presentació al WMT2021 Shared Task on Quality Estimation (QE). Participem en prediccions del nivell de frases dels judicis humans i l'esforç post-edició. Proposem un enfocament de caixa de vidre basat en pes d'atenció extraïts dels sistemes de traducció màquina. A diferència dels treballs anteriors, explorem directament les matrius de pes de l'atenció sense substituir-les amb mètriques generals (com l'entropia). We show that some of our models can be trained with a small amount of a high-cost labelled data.  En l'absència de dades d'entrenament, el nostre enfocament encara demostra una correlació linear moderada, amb dades sintètiques.", 'jv': "Gambar nganggo nggawe rerakno nggawe Mbak-Ngerawat sing berarti ning cara-Ngerawat 'Quality Awak dhéwé éntukno karo pertualangan kanggo ngerasahan kanggo nggawe barang-barang kanggo ngilangno barang uwong. Awak dhéwé ngerasakno karo nganggo gampang kanggo ngilangno barang nggampang Genjer-Genjer Awak dhéwé éntuk sistem sing ditambah akeh barang sampek dadi sing butine ketahan. Gak ono perbudhakan data sing paling nggawe dadi, dadi sing wis ngerasakno karo perusahaan linear, terus nyimpen karo data senetik.", 'he': 'The paper presents our submission to the WMT2021 Shared Task on Quality Estimation (QE).  אנחנו משתתפים בחזויות רמת המשפטים של שיפוטים אנושיים ומאמץ לאחר העורר. אנחנו מציעים גישה בקופסא זכוכית מבוססת על משקלי תשומת לב מווצאים מערכות התרגום מכונות. בניגוד לעבודות הקודמות, אנו חוקרים ישירות מטריות משקל תשומת לב בלי להחליף אותם במטריקה כללית (כמו אנטרופיה). אנחנו מראים שחלק מהדוגמנים שלנו יכולים להיות מאומנים עם כמות קטנה של נתונים במחיר גבוה. בהיעדר נתוני אימון הגישה שלנו עדיין מראה תקשורת לינרית ממוצעת, כאשר מאומנת עם נתונים סינטטיים.', 'ha': "Gansa na gaskata injinmu zuwa WMT2021 Tuna kamata a cikin kunyar-daraja na gargaɗin mutane da aikin taƙaita bayan editori. Munã buɗa wani matsayi mai murasa a kan ƙanƙan da nau'i wanda aka samar daga tsarin fassarar masu ƙarami. Tsaransa da aikin da suka farko, sai mu sami matricikin masu nau'i ko kuma ba mu musanya su da komai (kamar entropy). Tuna nũna cewa, ko da wasu misalinmu za'a iya sanar da shi da ko kaɗan na'yan taƙalumai mai girma. In the absence of training data our approach still demonstrates a moderate linear correlation, when trained with synthetic data.", 'sk': 'V prispevku je predstavljena naša predložitev v skupni nalogi WMT2016 o oceni kakovosti (QE). Sodelujemo pri napovedovanju človeških sodb na ravni stavkov in prizadevanjih za urejanje. Predlagamo pristop steklene škatle, ki temelji na utežeh pozornosti, pridobljenih iz sistemov strojnega prevajanja. V nasprotju s prejšnjimi deli neposredno raziskujemo matrice teže pozornosti, ne da bi jih zamenjali s splošnimi metrikami (kot je entropija). Pokazali smo, da je nekatere naše modele mogoče usposabljati z majhno količino visokocenovno označenih podatkov. Ob pomanjkanju podatkov o usposabljanju naš pristop še vedno kaže zmerno linearno korelacijo, ko se trenira s sintetičnimi podatki.', 'bo': 'ཤོག་བྱང་དེའི་ནང་དུ་WMT2021 ལ་མཉམ་སྤྱོད་ཀྱི་བྱ་རིམ་གཟུགས་རིམ(QE)དང་མཉམ་དུ་སྤྲོད་ཡོད། ང་ཚོས་མིའི་ཆ་ལེན་བྱེད་དང་ཞུན་དག་བྱེད་པའི་སྔོན་ཚུལ་གྱི་འཛུལ་སྒྲིག་དང་ ང་ཚོས་རྩོམ་འཁོར་གྱི་མ་ལག་གི་སྐྱེས་ཆེན་ལ་རང་གི་ཡིག་གཟུགས་ཀྱི་ཐབས་ལམ་ཞིག་བཤད་ཀྱི་ཡོད། In contrast to the previous works, we directly explore attention weight matrices without replacing them with general metrics (like entropy). We show that some of our models can be trained with a small amount of a high-cost labelled data. ང་ཚོའི་ཐབས་ལམ་ལུགས་གཙོ་རིམ་གྱི་གནད་སྡུད་དག་དེ་ཡང་མ་མཐུད་ལམ་ལུགས་པའི་མཐུན་རྐྱེན་གྱི་ནང་དུ་བྱུང་།'}
{'en': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'ar': 'تقديم IST-Unbabel 2021 للمهمة المشتركة لتقدير الجودة', 'fr': "Soumission IST-Unbabel 2021 pour la tâche partagée d'estimation de la qualité", 'pt': 'Submissão IST-Unbabel 2021 para a Tarefa Partilhada de Estimativa de Qualidade', 'es': 'Presentación de IST-Unbabel 2021 para la tarea compartida de estimación de calidad', 'zh': 'IST-Unbabel 2021年质估共享之交', 'ja': 'IST - Unbabel 2021品質見積もり共有タスクの提出', 'hi': 'गुणवत्ता अनुमान साझा कार्य के लिए आईएसटी-अनबेबल 2021 सबमिशन', 'ru': 'Представление IST-Unbabel 2021 для совместной задачи оценки качества', 'ga': 'Aighneacht IST-Unbabel 2021 don Tasc Comhroinnte um Mheastachán Cáilíochta', 'ka': 'IST-Unbabel 2021 სტმისია კვალეტის განსაზღვრებული დავალებისთვის', 'hu': 'IST-Unbabel 2021 Bejelentkezés a minőségbecslés megosztott feladatára', 'el': 'IST-Unbabel 2021 Υποβολή για την Κοινή Εργασία Εκτίμησης Ποιότητας', 'it': 'IST-Unbabel 2021 Presentazione per il compito condiviso di stima della qualità', 'lt': 'IST-Unbabel 2021 m. kokybės vertinimo bendros užduoties pateikimas', 'mk': 'IST-Unbabel 2021 Предлога за заедничката задача за проценка на квалитетот', 'kk': 'IST-Unbabel 2021 сапатты оқиға ортақ тапсырма үшін жіберу', 'ms': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'ml': 'IST- Unbabel 2021 Submission for the quality of Estimation Shared Task', 'mt': 'IST-Unbabel 2021 Sottomissjoni għall-Kompitu Konġunt tal-Istima tal-Kwalità', 'mn': 'IST-Unbabel 2021-ийн качествен Нөлөөлөлт хуваалтын ажил', 'no': 'IST-Unbabel 2021 Submission for Quality Estimation Shared Task', 'pl': 'IST-Unbabel 2021 Zgłoszenie do oceny jakości Wspólne Zadanie', 'ro': 'IST-Unbabel 2021 depunere pentru sarcina partajată de estimare a calității', 'sr': 'IST-Unbabel 2021. podmission za zajednički zadatak za procjenu kvalitete', 'so': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'sv': 'IST-Unbabel 2021 Ansökan om delad kvalitetsbedömning', 'si': 'IST-Unbabel 2021 ප්\u200dරශ්ණතාවක් අනුමාණය සම්බන්ධය', 'ta': 'தரம் கணக்கீட்டு பகிர்ந்த பணிக்கான IST- Unbabel 2021 Submission', 'ur': 'IST-Unbabel 2021 کائلیٹی اثبات شریک ٹاکس کے لئے Submission', 'uz': 'IST- Unbabel 2021 Submission for the Quality Estimation Shared Vazifalar', 'vi': 'Trình duyệt cho công việc chia sẻ chất lượng', 'nl': 'IST-Unbabel 2021 Indiening voor de Kwaliteitsschatting Gedeelde Taak', 'da': 'IST-Unbabel 2021 Indsendelse til den delte opgave med kvalitetsestimering', 'hr': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'bg': 'Представяне за съвместната задача за оценка на качеството', 'id': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'de': 'IST-Unbabel 2021 Einreichung für die Qualitätsschätzung Gemeinsame Aufgabe', 'ko': 'IST 태그 해제 2021 품질 평가 공유 작업 제출', 'tr': 'IST-Unbabel 2021 Görnöşim Taýýarlama Mazmunlary Taýýarlama Görevi üçin', 'fa': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'af': 'Ist-Unbabel 2021 Submission vir die Kwaliteit Estimation Gedeelde Taak', 'sw': 'Ujumbe wa IST-Unbabel 2021 kwa ajili ya Uhindi wa Kugawa', 'sq': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'am': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'hy': 'Իստ-Ամբաբելը 2021 թվականի որակի գնահատման ընդհանուր առաջադրանքի ընթացքում', 'az': 'IST-Unbabel 2021 N칬vb톛ti G칬r칲nt칲lm톛 B칬l칲n톛n G칬r칲nt칲lm톛si 칲칞칲n Submission', 'bs': 'IST-Unbabel 2021 podmission za zajednički zadatak za procjenu kvalitete', 'cs': 'IST-Unbabel 2021 Podání pro odhad kvality Sdílený úkol', 'bn': 'আইএসটি- আনবাবেল ২০২১ সাবমিশন গুরুত্বপূর্ণ কাজ শেয়ার করার জন্য', 'ca': 'IST-Unbabel 2021 Submission for the Quality Estimation Shared Task', 'et': 'IST-Unbabel 2021 kvaliteedihinnangu esitamine jagatud ülesandeks', 'fi': 'IST-Unbabel 2021 Laatuarviointi Jaettu tehtävä', 'jv': 'IsT-Unbabel 2020 1 Submis kanggo Kealitas', 'ha': 'Submit for the Quality estimation Shared job', 'sk': 'Oddaja IST-Unbabel 2021 za skupno nalogo ocene kakovosti', 'he': 'IST-Unbabel 2021 הגישה למשימה משותפת להערכת איכות', 'bo': 'IST-Unbabel 2021 ས Quality Estimation Shared Task ལ་འཇུག་སྤྱོད་པ'}
{'en': 'We present the joint contribution of IST and Unbabel to the WMT 2021 Shared Task on Quality Estimation. Our team participated on two tasks : Direct Assessment and Post-Editing Effort, encompassing a total of 35 submissions. For all submissions, our efforts focused on training multilingual models on top of OpenKiwi predictor-estimator architecture, using pre-trained multilingual encoders combined with adapters. We further experiment with and uncertainty-related objectives and features as well as training on out-of-domain direct assessment data.', 'ar': 'نقدم مساهمة IST و Unbabel المشتركة في مهمة WMT 2021 المشتركة حول تقدير الجودة. شارك فريقنا في مهمتين: التقييم المباشر وجهود ما بعد التحرير ، والتي تشمل ما مجموعه 35 طلبًا. بالنسبة لجميع عمليات الإرسال ، ركزت جهودنا على تدريب النماذج متعددة اللغات فوق بنية متنبئ ومقدر OpenKiwi ، باستخدام برامج تشفير متعددة اللغات مدربة مسبقًا مع محولات. نقوم كذلك بتجربة الأهداف والميزات المتعلقة بعدم اليقين بالإضافة إلى التدريب على بيانات التقييم المباشر خارج المجال.', 'pt': 'Apresentamos o contributo conjunto do IST e da Unbabel para o WMT 2021 Shared Task on Quality Estimation. Nossa equipe participou de duas tarefas: Avaliação Direta e Esforço Pós-Edição, totalizando 35 submissões. Para todos os envios, nossos esforços se concentraram no treinamento de modelos multilíngues sobre a arquitetura preditor-estimador OpenKiwi, usando codificadores multilíngues pré-treinados combinados com adaptadores. Além disso, experimentamos objetivos e recursos relacionados à incerteza, bem como treinamento em dados de avaliação direta fora do domínio.', 'es': 'Presentamos la contribución conjunta de IST y Unbabel a la Tarea Compartida sobre Estimación de la Calidad del WMT 2021. Nuestro equipo participó en dos tareas: Evaluación directa y Esfuerzo posterior a la edición, que abarcaron un total de 35 presentaciones. Para todas las presentaciones, nuestros esfuerzos se centraron en capacitar modelos multilingües sobre la arquitectura predictor-estimador de OpenKiwi, utilizando codificadores multilingües previamente entrenados combinados con adaptadores. Experimentamos aún más con objetivos y características relacionados con la incertidumbre, así como capacitamos sobre datos de evaluación directa fuera del dominio.', 'fr': "Nous présentons la contribution conjointe d'IST et d'Unbabel à la tâche partagée WMT 2021 sur l'estimation de la qualité. Notre équipe a participé à deux tâches\xa0: l'évaluation directe et l'effort de post-édition, englobant un total de 35 soumissions. Pour toutes les soumissions, nos efforts se sont concentrés sur la formation de modèles multilingues en plus de l'architecture prédicteur-estimateur OpenKiwi, à l'aide d'encodeurs multilingues pré-entraînés combinés à des adaptateurs. Nous expérimentons également des objectifs et des fonctionnalités liés à l'incertitude, ainsi que des formations sur les données d'évaluation directe hors domaine.", 'ja': '私たちは、WMT 2021の品質見積もりに関する共有タスクに対するISTとUnbabelの共同貢献を提示します。私たちのチームは、直接評価と編集後の取り組みの2つのタスクに参加し、合計35件の提出物を含みました。すべての提出物について、事前にトレーニングを受けた多言語エンコーダとアダプタを組み合わせて、OpenKiwi予測評価アーキテクチャの上に多言語モデルをトレーニングすることに焦点を当てました。私たちは、ドメイン外の直接評価データに関するトレーニングだけでなく、関連する目標と機能をさらに実験し、不確実性を高めます。', 'zh': '吾言IST与UnbabelWMT 2021质评共功。 臣等团队参二务:直评译后辑,共包35分。 凡诸交文,在OpenKiwi预测器度器架构之上,练多言模,用预练者多言编码器适配器。 试与不确定性相关者,域外直评数培训之。', 'hi': 'हम गुणवत्ता आकलन पर डब्ल्यूएमटी 2021 साझा कार्य में आईएसटी और अनबाबेल का संयुक्त योगदान प्रस्तुत करते हैं। हमारी टीम ने दो कार्यों पर भाग लिया: प्रत्यक्ष मूल्यांकन और पोस्ट-संपादन प्रयास, जिसमें कुल 35 प्रस्तुतियां शामिल हैं। सभी प्रस्तुतियों के लिए, हमारे प्रयासों ने ओपनकिवी भविष्यवक्ता-अनुमानक वास्तुकला के शीर्ष पर बहुभाषी मॉडल को प्रशिक्षित करने पर ध्यान केंद्रित किया, जिसमें एडाप्टर के साथ संयुक्त पूर्व-प्रशिक्षित बहुभाषी एन्कोडर का उपयोग किया गया था। हम अनिश्चितता से संबंधित उद्देश्यों और सुविधाओं के साथ-साथ आउट-ऑफ-डोमेन प्रत्यक्ष मूल्यांकन डेटा पर प्रशिक्षण के साथ-साथ आगे प्रयोग करते हैं।', 'ru': 'Мы представляем совместный вклад IST и Unbabel в совместную задачу WMT 2021 по оценке качества. Наша команда участвовала в выполнении двух задач: прямой оценки и постредактирования, охватывающих в общей сложности 35 представлений. Для всех представлений наши усилия были сосредоточены на обучении многоязычных моделей поверх архитектуры прогноза и оценки OpenKiwi с использованием предварительно обученных многоязычных кодеров в сочетании с адаптерами. Мы также экспериментируем с целями и особенностями, связанными с неопределенностью, а также обучаем использованию данных о прямых оценках за пределами домена.', 'ga': 'Cuirimid i láthair rannpháirtíocht IST agus Unbabel le Tasc Comhroinnte WMT 2021 ar Mheastachán Cáilíochta. Ghlac ár bhfoireann páirt i dhá thasc: Measúnú Díreach agus Iarracht Iar-Eagarthóireachta, a chuimsigh 35 aighneacht san iomlán. I gcás gach aighneachta, dhírigh ár n-iarrachtaí ar mhúnlaí ilteangacha a oiliúint anuas ar ailtireacht meastacháin-mheastacháin OpenKiwi, ag baint úsáide as ionchódóirí ilteangacha réamhoilte in éineacht le hoiriúnóirí. Déanaimid tástáil bhreise ar chuspóirí agus ar ghnéithe a bhaineann le neamhchinnteacht chomh maith le hoiliúint ar shonraí measúnaithe díreach lasmuigh den fhearann.', 'ka': 'ჩვენ გავაჩვენეთ IST და Unbabel-ის ერთადერთი დამატება WMT 2021-ის გაყოფილი დავალების განსაზღვრებაზე. ჩვენი ჯგუფი მოთავსდება ორი საქმედებში: Direkt Assessment and Post-Editing Effort, რომელიც ყველაფერი 35 მომხმარებულებები. ყველა სამუშაოდ, ჩვენი ძალადობები მრავალენგური მოდელების განაკეთებაზე, OpenKiwi პროგრამეტრის განაკეთებელი აქტიქტურაციაზე, გამოყენებული მრავალენგური კოდერების გამოყენება, რომლები ჩვენ უფრო მეტი ექსპერიმენტებით დავკვირდებით და უცნობიერებით მიღებული ობიექტებით და განსაკუთრებით და განსაკუთრებით განსაკუთრებით განსაკუთრებ', 'hu': 'Bemutatjuk az IST és az Unbabel közös hozzájárulását a WMT 2021 közös minőségbecslési feladatához. Csapatunk két feladatban vett részt: közvetlen értékelés és utószerkesztési erőfeszítés, amelyek összesen 35 beadványt foglaltak magukban. Minden beadvány esetében erőfeszítéseink arra összpontosítottak, hogy többnyelvű modelleket képezzünk az OpenKiwi prediktor-becslő architektúráján felül, előre képzett többnyelvű kódolókat használva adapterekkel kombinálva. Továbbá kísérletezünk és bizonytalansággal összefüggő célkitűzésekkel és funkciókkal, valamint képzésekkel a területen kívüli közvetlen értékelési adatokkal kapcsolatban.', 'el': 'Παρουσιάζουμε την κοινή συνεισφορά του IST και της Unbabel στην Κοινή Εργασία Εκτίμησης Ποιότητας του WMT 2021. Η ομάδα μας συμμετείχε σε δύο εργασίες: Άμεση Αξιολόγηση και Μεταμοντάζ Προσπάθειας, που περιελάμβαναν συνολικά 35 υποβολές. Για όλες τις αιτήσεις, οι προσπάθειές μας επικεντρώθηκαν στην εκπαίδευση πολύγλωσσων μοντέλων πάνω από την αρχιτεκτονική προγνωστών-εκτιμητών του OpenKiwi, χρησιμοποιώντας προ-εκπαιδευμένους πολύγλωσσους κωδικοποιητές σε συνδυασμό με προσαρμογείς. Περαιτέρω πειραματιζόμαστε με στόχους και χαρακτηριστικά που σχετίζονται με την αβεβαιότητα, καθώς και εκπαίδευση σε δεδομένα άμεσης αξιολόγησης εκτός πεδίου.', 'it': "Presentiamo il contributo congiunto di IST e Unbabel al compito condiviso WMT 2021 sulla stima della qualità. Il nostro team ha partecipato a due compiti: valutazione diretta e sforzo post-editing, comprendendo un totale di 35 contributi. Per tutte le presentazioni, i nostri sforzi si sono concentrati sulla formazione di modelli multilingue oltre all'architettura predittore-estimatore OpenKiwi, utilizzando encoder multilingue pre-addestrati combinati con adattatori. Sperimentiamo ulteriormente obiettivi e caratteristiche legati all'incertezza, oltre a corsi di formazione su dati di valutazione diretta fuori campo.", 'kk': 'Біз IST және Unbabel бағдарламасының WMT 2021 жылы сапалық оқиғаларының ортақ тапсырмасын біріктіреміз. Біздің командамыз екі тапсырмаға қатысу үшін: тізім оценка және өңдеу күшін, жалпы 35 жіберуші бар. Барлық тапсырмалар үшін біздің көптеген тілді моделдерді OpenKiwi прогнозер- оқу архитектурасының үстінде көптеген көптеген көптеген тілді кодерлерді қолдану үшін көптеген көптеген. Біз доменге тәжірибесіздік мақсаттар мен мүмкіндіктерді және доменге тыс оқу деректері туралы оқу және көмектеспей тәжірибесіз.', 'lt': 'We present the joint contribution of IST and Unbabel to the WMT 2021 Shared Task on Quality Estimation.  Mūsų komanda dalyvavo dviejose užduotyse: tiesioginis vertinimas ir pastangos po redakcijos, apimančios iš viso 35 paraiškas. Visiems pareiškimams mūsų pastangos sutelktos į daugiakalbių modelių mokymą, be OpenKiwi prognozatorių ir vertinimo architektūros, naudojant iš anksto parengtus daugiakalbius kodatorius kartu su adapteriais. Toliau eksperimentuojame su netikrumu susijusiais tikslais ir savybėmis, taip pat rengiame mokymus tiesioginio vertinimo duomenimis ne srityse.', 'mk': 'Го претставуваме заедничкиот придонес на ИСТ и Унбабел за заедничката задача на ВМТ 2021 за проценка на квалитетот. Нашиот тим учествуваше во две задачи: Директна проценка и напори по редагирање, вклучувајќи вкупно 35 поднесувања. За сите поднесувања, нашите напори се фокусираа на обуката на мултијазичните модели врз архитектурата на предвидувачот-проценувачот на OpenKiwi, користејќи предобучени мултијазични кодери комбинирани со адаптери. Понатаму експериментираме со цели и карактеристики поврзани со несигурноста, како и обука за директни податоци за проценка надвор од доменот.', 'ms': 'We present the joint contribution of IST and Unbabel to the WMT 2021 Shared Task on Quality Estimation.  Pasukan kami berpartisipasi dalam dua tugas: Pengesahan langsung dan Effort Setelah-Editing, meliputi total 35 tunjukan. Untuk semua penghantaran, usaha kami fokus pada latihan model berbilang bahasa di atas arkitektur prediksor-penghargaan OpenKiwi, menggunakan pengekod berbilang bahasa terlatih terlatih bergabung dengan penyesuaian. Kami melanjutkan percubaan dengan tujuan dan ciri-ciri yang berkaitan dengan ketidakpastian serta latihan pada data penilaian langsung luar domain.', 'ml': 'നമ്മള്\u200d ഐസിറ്റിന്റെയും ഉന്ബാബേലിന്റെയും കൂട്ടിചേര്\u200dക്കുന്നത് WMT 2021 വേര്\u200dതിരിക്കുന്ന പണിയിലേക്കാണ്. ഞങ്ങളുടെ ടീം രണ്ടു ജോലികളില്\u200d പങ്കുചേര്\u200dന്നു: നേരിട്ട് വിശ്വസിക്കുന്നതും പിന്നീട് എഡിറ്ററിങ്ങിന്\u200dറെ ശ്രമം മൊ എല്ലാ കീഴടങ്ങള്\u200dക്കും ഞങ്ങളുടെ ശ്രമം ഓപ്പിക്കിവി പ്രവചിക്കുന്നവന്\u200d -എസ്റ്റിഗറ്റര്\u200d ആര്\u200dക്കിട്ടറിന്റെ മുകളില്\u200d പല ഭാഷ മോഡലുകള്\u200d പരിശീലനം നടത്ത നമ്മള്\u200d കൂടുതല്\u200d പരീക്ഷിക്കുന്നു, തിരിച്ചറിയാത്ത ലക്ഷ്യങ്ങളും വിശേഷതകളുമായി പരീക്ഷിക്കുന്നു. പിന്നെ നമ്മള്\u200d ഡൊമൈന', 'mn': 'Бид IST болон Unbabel-ын хамтдаа WMT 2021-ийн хуваалтын ажиллагаанд нийлүүлж байна. Бидний баг хоёр даалгаварт оролцсон: шууд оценка, эцэст засварлах чадвар, нийтлэг 35 даалгаврын хүрээнд оролцсон. Олон хэлний загваруудын тулд бидний хичээл нь OpenKiwi-ын таамаглаач баримтуудын дээд олон хэлний загваруудыг сургалтын тулд анхаарлаа төвлөрсөн. Бид дараа нь шууд тооцоолох өгөгдлийн талаар дамжуулан туршилт хийж, тодорхойгүй байдлын зорилготой зорилготой, харьцуулалт болон сургалтын талаар туршилт хийж байна.', 'no': 'Vi presenterer den samanlige bidraga av IST og Unbabel til WMT 2021 delt oppgåve om kvalitetestimering. Gruppet vårt delta på to oppgåver: Direkt vurdering og post- redigeringspålitet, som omsluttar totalt 35 oppgåver. For alle tillegg, våre forsøk fokuserte på trening av fleirspråksmodeller på toppen av OpenKiwi-foregåver-estimator-arkitektur, ved å bruka fleirspråkskodar kombinert med adapterer. Vi eksperimenterer meir med og usikkerhetsrelaterte mål og funksjonar, og opplæring om direkte vurderingsdata frå utdomenet.', 'mt': 'Aħna nippreżentaw il-kontribuzzjoni konġunta tal-IST u l-Unbabel għad-WMT 2021 Task Konġunt dwar l-Istima tal-Kwalità. It-tim tagħna pparteċipa f’żewġ kompiti: Valutazzjoni Diretta u Sforz ta’ Wara l-Editar, li jinkludu total ta’ 35 sottomissjoni. Għas-sottomissjonijiet kollha, l-isforzi tagħna ffukaw fuq it-taħriġ ta’ mudelli multilingwi fuq l-arkitettura ta’ preditor-stimatur OpenKiwi, bl-użu ta’ kodifikaturi multilingwi mħarrġa minn qabel flimkien ma’ adattaturi. We further experiment with and uncertainty-related objectives and features as well as training on out-of-domain direct assessment data.', 'pl': 'Przedstawiamy wspólny wkład IST i Unbabel w realizację wspólnego zadania WMT 2021 dotyczącego oceny jakości. Nasz zespół uczestniczył w dwóch zadaniach: Ocenę Bezpośrednią i Wysiłek Post-Editing, obejmujący łącznie 35 zgłoszeń. Dla wszystkich zgłoszeń nasze starania skupiały się na szkoleniu modeli wielojęzycznych na architekturze predykcyjno-estymatora OpenKiwi, wykorzystując wstępnie przeszkolone wielojęzyczne kodery w połączeniu z adapterami. Dodatkowo eksperymentujemy z celami i cechami związanymi z niepewnością, a także szkolimy na temat bezpośrednich danych oceny poza domeną.', 'ro': 'Vă prezentăm contribuția comună a IST și Unbabel la misiunea partajată WMT 2021 privind estimarea calității. Echipa noastră a participat la două sarcini: Evaluare directă și Efort post-editare, cuprinzând un total de 35 de depuneri. Pentru toate depunerile, eforturile noastre s-au concentrat pe instruirea modelelor multilingve pe partea superioară a arhitecturii predictoare-estimatoare OpenKiwi, folosind codificatoare multilingve pre-instruite combinate cu adaptoare. Experimentăm în continuare obiectivele și caracteristicile legate de incertitudine, precum și instruim pe date de evaluare directă din afara domeniului.', 'so': 'Waxaannu wadajirka ka wadajirka ah IST iyo Unbaal ugu keenaynaa WMT 2021 Shaqo la sharciyey Qiimo Estimation. Kooxdayagu waxay ka qeybqaadan jireen laba shaqooyin: Direct Assessment and After-Editing efforts, kaasoo kooxa total 35 submissions. Dhammaan sameynta, waxaa ku qoran sameynta tusaalaha luuqadaha kala duduwan oo ku qoran taariikhda OpenKiwi-preditaor-estimisor, iyagoo isticmaalaya kooxaha horay loo tababaray luuqado kala duduwan oo isku xiran adaptere. Imtixaan dheeraad ah ayaannu ku jirnaa waxyaabaha la xiriira iyo waxyaabaha la xiriira, iyo waxbarasho ku saabsan macluumaadka kaartaynta tooska ah ee gudaha.', 'sr': 'Predstavljamo zajednički doprinos IST-a i Unbabela na WMT 2021. podeljeni zadatak o procjeni kvalitete. Naš tim je sudjelovao u dva zadatka: Direktna procjena i posturedna snaga, uključujući ukupno 35 podataka. Za sve podatke, naši napori su fokusirani na obuku multijezičkih modela na vrhu arhitekture predviđača OpenKiwija, koristeći predobučene multijezičke kodere kombinovane sa adapterima. Dalje eksperimentiramo sa ciljevima i karakteristikama vezanim za nesigurnost, kao i obuku o podacima direktne procjene izvan domena.', 'sv': 'Vi presenterar IST och Unbabels gemensamma bidrag till WMT 2021 Shared Task on Quality Estimation. Vårt team deltog i två uppgifter: Direktbedömning och Post-Editing Effort, som omfattar totalt 35 inlämningar. För alla inlämningar fokuserade våra insatser på att utbilda flerspråkiga modeller ovanpå OpenKiwi prediktor-estimator arkitektur, med hjälp av förintränade flerspråkiga kodare kombinerade med adaptrar. Vi experimenterar vidare med och osäkerhetsrelaterade mål och funktioner samt utbildar oss i externa direktbedömningsdata.', 'si': 'අපි IST සහ අන්බාබෙල්ගේ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ සම්බන්ධ වැඩ අපේ කණ්ඩායම් වැඩක් දෙකට සම්බන්ධ වෙලා තියෙන්නේ: ප්\u200dරතික්ෂණය සහ පස්සේ සංපාදනය කරන්න ප්\u200dරයෝජනය, සම්බන්ධ 35 ඔක්කොම ප්\u200dරශ්නයක් වෙනුවෙන්, අපේ උත්සාහ කළා විශේෂ භාෂාවක් මොඩල් ප්\u200dරශ්නයක් වෙනුවෙන්, OpenKiwi වේ ප්\u200dරශ්නයක් විශ්වාස කර අපි තවත් පරීක්ෂණය සහ අනිශ්වාසයෙන් සම්බන්ධ අරමුණු සහ අවශ්\u200dයය සහ අවශ්\u200dයය සහ ප්\u200dරධානය සඳහා ප්\u200dරධානය', 'ta': 'நாம் IST மற்றும் Unbabel யுஎம்ட் 2021 பங்கிடப்பட்ட பணியின் இணைய பங்கை கூடுதலை கூட்டுகிறோம் தரம் கணக்கீட்டில் கூட்டி எங்கள் குழு இரண்டு பணிகளில் பங்கிடப்பட்டது: நேரடி சிகிச்சை மற்றும் பின்தொகுப்பு முயற்சி மொத்தம் 35 சரணங்களை சுற்றி  அனைத்து கொடுப்புகளுக்கும், எங்கள் முயற்சி முன்பயிற்சி பல மொழி மாதிரிகளை பயிற்சி செய்யும் ஓபன்கிவி முன்பு பயிற்சி பல மொழி குறியீடுகளை பயன் நாம் மேலும் தேர்வு செய்து கொண்டுள்ளோம் மற்றும் தெரியாத பொருள்கள் மற்றும் குணங்கள் மற்றும் பயிற்சி மற்றும் வெ', 'ur': 'ہم IST اور Unbabel کے ساتھ ملے ہوئے مسائل کو WMT 2021 میں مشترک ٹاکس کے ذریعے پیش کرتے ہیں. ہمارا تیم دو کاموں میں شریک ہوا: مستقیم آزمائش اور بعد ویڈینگ کی کوشش، 35 مسلمانوں کے سارے حضور ہے۔ تمام اطلاعات کے لئے، ہماری کوشش اوپن کیوی کی پیش آزمائش دینے والی معماری پر بہت سی زبان مدل کی تعلیم پر تمرکز کی گئی تھی، اس سے پہلے تعلیم کی بہت سی زبان کے اکڈر کے مطابق اڈپٹر کے ساتھ ملے ہوئے. ہم اس سے اور زیادہ آزمائش کریں گے اور غیر یقین کے ارتباط کے موضوع اور خصوصیات کے ساتھ اور خارج دومین کے سیدھے ارتباط ڈیٹوں پر آموزش کریں گے.', 'uz': "@ info Bizning guruhimiz ikkita vazifalarga qayta ishlashdi: Direct Assessment and Post Tahrirlash Effektlarimiz, butunlay 35 imkoniyatlarni ko'rsatadi. Ko'pchiliklar uchun, bizning jarayonlarimiz OpenKiwi'ning bir necha tili modellarini o'rganish uchun foydalanadi, oldin o'rganilgan muloqat kodlash kodlari bilan adapter bilan birlashtirilgan. Biz haqiqatgina bog'liq obʼektlar va xususiyatlar bilan boshqa tajriba qilamiz va hodisa domen soʻrov qiymatlar maʼlumotidan foydalanish.", 'vi': 'Chúng tôi xin giới thiệu các đóng góp chung của IST và bất khả thi cho công việc chia sẻ WM 2021 về ước lượng chất lượng. Nhóm của chúng tôi đã tham gia vào hai nhiệm vụ: Công việc nhận xét trực tiếp và hậu sửa đổi công trình, gồm cả một số kết quả 35. Trong tất cả các tài liệu, chúng tôi đã tập trung đào tạo các mô- đun đa dạng nằm trên kiến trúc dự đoán và tiêu chuẩn OpenKiwi, cùng với các bộ sạc. Chúng tôi còn thử nghiệm với các mục tiêu và tính năng không chắc chắn cũng như huấn luyện các dữ liệu đánh giá trực tiếp ngoài miền.', 'nl': 'We presenteren de gezamenlijke bijdrage van IST en Unbabel aan de WMT 2021 Shared Task on Quality Estimation. Ons team nam deel aan twee taken: Direct Assessment en Post-Editing Effort, met in totaal 35 inzendingen. Voor alle inzendingen waren onze inspanningen gericht op het trainen van meertalige modellen bovenop de OpenKiwi predictor-estimator architectuur, met behulp van voorgetrainde meertalige encoders gecombineerd met adapters. We experimenteren verder met en onzekerheidsgerelateerde doelstellingen en functies en trainen op out-of-domain directe beoordelingsgegevens.', 'bg': 'Представяме съвместния принос на ИСТ и Унбабел към общата задача за оценка на качеството на ММТ 2021. Екипът ни участва в две задачи: Директна оценка и пост-редактиране усилия, включващи общо 35 предложения. За всички предложения усилията ни се съсредоточиха върху обучението на многоезични модели в допълнение към архитектурата на предварителните оценки, използвайки предварително обучени многоезични кодери, комбинирани с адаптери. По-нататък експериментираме с цели и функции, свързани с несигурността, както и обучение по извъндомейнни данни за директна оценка.', 'da': 'Vi præsenterer IST og Unbabels fælles bidrag til WMT 2021 Shared Task on Quality Estimation. Vores team deltog i to opgaver: Direkte vurdering og Post-Editing Indsats, der omfattede i alt 35 indsendelser. For alle indsendelser fokuserede vores indsats på at træne flersprogede modeller oven i OpenKiwi predictor-estimator arkitektur ved hjælp af forududdannede flersprogede kodere kombineret med adaptere. Vi eksperimenterer yderligere med og usikkerhedsrelaterede mål og funktioner samt træner i out-of-domæne direkte vurderingsdata.', 'hr': 'Predstavljamo zajednički doprinos IST-a i Unbabela na zajednički zadatak WMT 2021 o procjeni kvalitete. Naš tim je sudjelovao u dva zadatka: Direktna procjena i posturedna snaga, uključujući ukupno 35 podataka. Za sve podatke, naši napori su usredotočeni na obuku multijezičkih modela na vrhu arhitekture predviđača OpenKiwi, koristeći predobučene multijezičke kodere kombinirane s adapterima. Mi dalje eksperimentiramo s ciljevima i karakteristikama povezanim s nejasnošću, kao i obuku o podacima direktne procjene izvan domena.', 'de': 'Wir stellen den gemeinsamen Beitrag von IST und Unbabel zur WMT 2021 Shared Task on Quality Estimation vor. Unser Team nahm an zwei Aufgaben teil: Direct Assessment und Post-Editing Effort, die insgesamt 35 Einreichungen umfassten. Bei allen Einreichungen konzentrierten sich unsere Bemühungen auf die Schulung mehrsprachiger Modelle auf die OpenKiwi Prädiktor-Schätzer-Architektur, wobei vorgetrainierte mehrsprachige Encoder in Kombination mit Adaptern verwendet wurden. Darüber hinaus experimentieren wir mit und mit unsicherheitsbezogenen Zielen und Features sowie trainieren auf externen direkten Bewertungsdaten.', 'id': 'Kami memperkenalkan kontribusi bersama dari IST dan Unbabel ke WMT 2021 Shared Task on Quality Estimation. Tim kami berpartisipasi dalam dua tugas: Penghargaan langsung dan Efor Setelah Editing, meliputi total 35 submissions. Untuk semua pengiriman, usaha kami fokus pada pelatihan model berbagai bahasa di atas arsitektur prediksor-penentu OpenKiwi, menggunakan koder berbagai bahasa terlatih bergabung dengan adaptor. Kami lebih lanjut eksperimen dengan tujuan dan fitur terkait ketidakpastian serta pelatihan pada data penghargaan langsung luar domain.', 'ko': 'WMT 2021 품질 평가 공유 임무에 대한 IST와 Unbabel의 공동 기여를 소개했다.우리 팀은 두 가지 임무에 참여했다. 바로 평가와 후기 편집 업무로 모두 35개의 의견서를 제출했다.제출한 모든 파일에 대해 OpenKiwi predictor estimator 구조를 바탕으로 다국어 모델을 훈련하고 미리 훈련된 다국어 인코더와 어댑터를 사용하는 것이 우리의 업무 중점이다.우리는 불확실성과 관련된 목표와 특징을 한층 더 실험하고 분야 밖의 직접 평가 데이터를 교육했다.', 'fa': 'ما مشترک مشترک IST و Unbabel را به کار مشترک WMT 2021 در مورد ارزیابی کیفیت پیشنهاد می کنیم. تیم ما در دو وظیفه شرکت کرد: ارزیابی مستقیم و تلاش بعد از ویرایش، که جمع 35 تسلیم شده است. برای تمامی تسلیم، تلاش ما روی آموزش مدل های زیادی زبان روی بالای معماری پیش\u200cبینی\u200cکننده\u200cی پیش\u200cبینی OpenKiwi تمرکز می\u200cکردند، با استفاده از کودرهای زیادی زبان\u200cآموزش پیش\u200cبینی که با adapters ترکیب می\u200cکردند. ما آزمایش بیشتری با هدف و ویژه\u200cهای مستقیم مربوط به مطمئن و بی\u200cمطمئن و آموزش داده\u200cهای ارزیابی مستقیم خارج از دومین انجام می\u200cدهیم.', 'sw': 'Tunawasilisha mchango wa pamoja wa IST na Unbabel kwa WMT 2021 Kushirikiana na Hisabu. Timu yetu ilishiriki katika kazi mbili: Utafiti wa moja kwa moja na jitihada za baada ya kuhariri, ikijumuisha jumla ya matamshi 35. Kwa ujumbe wote, juhudi zetu zilikuwa za kufundisha mifano ya lugha mbalimbali juu ya ujenzi wa watabiri wa OpenKiwi, kwa kutumia viungo vya lugha vilivyojifunza viwili vikiwa pamoja na mabadiliko. Tunafanya majaribio zaidi na malengo yanayohusiana na usio na uhakika pamoja na mafunzo ya takwimu za moja kwa moja za maendeleo.', 'tr': "Biz IST we Unbabel'yň WMT 2021-iň Kwalyk Taýramçylygy barada ylalaşyk işini WMT 2021-e görkezip berýäris. Biziň toparymyz iki işe goşuldy: Dogru çykyş we Editlemek Güçlişligi, toplamyň 35 süýşiklikleri bar. Hemme göndermeler üçin, biziň çabalarymyz OpenKiwi öňünden öňünden öňünden bilim kodçylar bilen birleştirilýär. Biz daşyrdan hem-de kesinliksiz maksadlary we özellikler we domena daşaryk ýüze çykyş vurgulama maglumatlary bilen test edip barýarys.", 'sq': 'Ne paraqesim kontributin e përbashkët të IST dhe Unbabel në WMT 2021 Task Shared on Quality Estimation. Ekipi ynë mori pjesë në dy detyra: vlerësimi i drejtpërdrejtë dhe përpjekja pas redaksionit, duke përfshirë një total prej 35 paraqitjesh. Për të gjitha paraqitjet, përpjekjet tona u përqëndruan në trajnimin e modeleve shumëgjuhësore në krye të arkitekturës parashikuese-vlerësuese OpenKiwi, duke përdorur koduesit shumëgjuhëtarë të paratrajnuar të kombinuar me adaptuesit. Ne eksperimentojmë më tej me objektivat dhe karakteristikat lidhur me pasigurinë si dhe trajnimin mbi të dhënat e vlerësimit të drejtpërdrejtë jashtë fushës.', 'af': "Ons stel die saamste bydraag van IST en Unbabel aan die WMT 2021 Gedeelde Opdrag op Kwaliteit Estimasie voor. Ons span het gedeel op twee taak: Direkte Assensie en Post-Editing Effekte, omsluit 'n totaal van 35 onderwerpe. Vir alle onderdragte, ons versoekte gefokus het op multitaalske modele op die bo van OpenKiwi voorskouer-estimatoer-arkitektuur, gebruik voor-onderwerp multitaalske koders gekombineer met adapters. Ons het verdere eksperimenteer met en onbevestigheid verwante objekte en funksies en onderwyseling van af-domein direkte evalueringsdata.", 'am': 'የIST እና Unbabel ድርጅት በቁጥጥር ላይ 2021 የተሰራጨውን ስራ ለWMT እናቀርባለን፡፡ የጦማሪያችን በሁለት ስራ ላይ ተጋጠሙ፡፡ ቀጥተኛ ማስታወቂያ እና በኋላ አስተካክል ፍለጋት እና በሙሉ 35 ድምፅ አካሄደ፡፡ ለሁሉም ግንኙነት፣ ሞከራችን በብዙ ቋንቋዎች ሞዴላዎችን በOpenKiwi ትንቢት-አስተዳደር-አካውንት ላይ በመፍጠር ላይ ያስተካክላል፡፡ አካባቢዎች እና የግንኙነት አዳራሾች እና የአፍላጎቶችን እና የውጭ የውጭ አዳራሽ አስተያየት ዳታዎችን እናስፈትናለን፡፡', 'hy': 'Մենք ներկայացնում ենք IT-ի և UNBABEL-ի միասին ներդրումը 2021 թվականի համագործակցած որակի գնահատման խնդիրը: Our team participated on two tasks: Direct Assessment and Post-Editing Effort, encompassing a total of 35 submissions.  Բոլոր ներկայացումների համար մեր ջանքները կենտրոնացել են բազմալեզու մոդելների ուսուցման վրա OpenKiWi կանխատեսողների-գնահատողների ճարտարապետության վրա, օգտագործելով նախապատրաստված բազմալեզու կոդերներ՝ համադրված ադապտերների հետ: Մենք շարունակում ենք փորձել անորոշությամբ կապված նպատակների և առանձնահատկությունների հետ, ինչպես նաև օտար բնագավառների անմիջական գնահատման տվյալների ուսումնասիրություն:', 'az': "Biz IST və Unbabel'in birləşdirilməsini WMT 2021'nin şəkil qiyməti haqqında paylaşdığı işə göstəririk. Bizim ekibimiz iki işdə iştirak etdi: Direkt Assessment and Post Editing Effort, total of 35 submissions. Tüm tətbiqlərimiz üçün çoxlu dil modellərini OpenKiwi predictor-estimator arhitektarının üstündə təhsil etdiyimiz üçün çoxlu dil kodlayıcıları ilə birlikdə təhsil edilən çoxlu kodlayıcılar istifadə etdik. Biz həmçinin təcrübələrlə və təcrübələrlə birlikdə təcrübə edirik.", 'bn': 'আমরা আইএসটি এবং আনবাবেলের যৌথ অংশগ্রহণের সাথে উইএমটি ২০২১ শেয়ার করা কাজ সম্পর্কে উপস্থাপন করছি। আমাদের দল দুটি কাজে অংশগ্রহণ করেছে: সরাসরি প্রশ্ন এবং পোস্ট সম্পাদকের প্রচেষ্টা, যার মোট ৩৫ জনের প্রেক্ষাপট। সকল উপস্থাপনের জন্য আমাদের প্রচেষ্টা পূর্বে প্রশিক্ষিত বহুভাষার মডেল প্রশিক্ষণের উপর মনোযোগ প্রদান করেছে ওপেনকিউই ভবিষ্যদ্বাণী এবং হিসেব কর্মীর আমরা আরো পরীক্ষা করি নিশ্চিতভাবে সংক্রান্ত উদ্দেশ্য এবং বৈশিষ্ট্য এবং ডোমেইনের বাইরে সরাসরি মূল্যায়নের তথ্যের প্রশিক্ষণ', 'bs': 'Predstavljamo zajednički doprinos IST-a i Unbabela na zajednički zadatak WMT 2021 za procjenu kvalitete. Naš tim je sudjelovao u dva zadatka: Direktna procjena i posturedna snaga, uključujući ukupno 35 podataka. Za sve podatke, naši napori su fokusirani na obuku multijezičkih modela na vrhu arhitekture predviđača OpenKiwi, koristeći predobučene multijezičke kodere kombinirane s adapterima. Mi dalje eksperimentiramo sa ciljevima i karakteristikama povezanim sa nesigurnošću, kao i obuku o podacima direktne procjene izvan domena.', 'ca': "Presentam la contribució conjunta de IST i Unbabel a la Task Shared on Quality Estimation WMT 2021. El nostre equip va participar en dues tasques: Evaluació directa i esforç post-editorial, amb un total de 35 presentacions. Per totes les presentacions, els nostres esforços van centrar-se en formar models multilingües a més de l'arquitectura preditor-estimador OpenKiwi, utilitzant codificadors multilingües pré-entrenats combinats amb adaptadors. Continuem experimentant amb objectius i característiques relacionats amb l'incertitud i treballant sobre dades d'avaluació directa fora de domini.", 'cs': 'Představujeme společný příspěvek IST a Unbabel k WMT 2021 Shared Task on Quality Estimation. Náš tým se podílel na dvou úkolech: Přímém hodnocení a Post-Editing Effort, zahrnujících celkem 35 příspěvků. U všech příspěvků se naše úsilí zaměřilo na školení vícejazyčných modelů na vrcholu architektury prediktor-estimator OpenKiwi, pomocí předškolených vícejazyčných kodérů kombinovaných s adaptéry. Dále experimentujeme s cíli a funkcemi souvisejícími s nejistotou, stejně jako školení na mimo doménu přímých hodnotících dat.', 'et': 'Tutvustame IST ja Unbabeli ühist panust WMT 2021 ühisesse kvaliteedi hindamise ülesandesse. Meie meeskond osales kahel ülesandel: otsese hindamise ja toimetamisjärgse jõupingutuse täitmisel, mis hõlmas kokku 35 avaldust. Kõigi taotluste puhul keskendusid meie jõupingutused mitmekeelsete mudelite koolitamisele OpenKiwi ennustaja-hindaja arhitektuuri kõrval, kasutades eelnevalt koolitatud mitmekeelseid kodeerijaid koos adapteritega. Edasi eksperimenteerime ja ebakindlusega seotud eesmärke ja funktsioone ning koolitame valdkonnaväliseid otsehindamise andmeid.', 'fi': 'Esittelemme IST:n ja Unbabelin yhteisen panoksen WMT 2021 Shared Task on Quality Estimation -ohjelmaan. Tiimimme osallistui kahteen tehtävään: Suoraan arviointiin ja jälkieditointiin, joihin osallistui yhteensä 35 hakemusta. Kaikkien ehdotusten osalta panostimme monikielisten mallien kouluttamiseen OpenKiwi-ennuste-estimaattoriarkkitehtuurin päälle käyttäen esikoulutettuja monikielisiä koodereita yhdistettynä sovittimiin. Lisäksi kokeilemme ja epävarmuuteen liittyviä tavoitteita ja ominaisuuksia sekä koulutamme toimialueen ulkopuolisia suoria arviointitietoja.', 'jv': 'Awak dhéwé nggawe barang nggawe IsT karo Unbabel kanggo ngilangno WWT 2020 1 Tarjamahan sing gawe barang kalite Awakdhéwé wis nambah éwé iki nggawe: directi assessment lan After-Edit Efforh, tambah èwèké total de 30 isungkil Punika kanggo kowe nggunakake, kesempatan kanggo nggawe modèl multilenguang dumaten karo akeh Open Kiwi supoyor-estematir architecture, nggawe multilenguang koder multilenguang bisa gekompok karo adaleter. We additional pilot with and unsertainky-Relative goal and roles as long as Learning on out-of-domain directive measurement data.', 'ha': "Tuna halatar da wadan rabon da aka samar da shi zuwa WMT 2021 Team na haɗa cikin aikin biyu: Directly Assessed and After-Editing Effekt, yana ƙunsa da jumla 35 silsilado. Ga duk da aka saka, aikinmu sun yi zura kan yin amfani da misãlai masu mulki-lingui, a kan saman ¦akin bayanin-littafin-estimat na Open Kiwi, kuma ana yi amfani da kodi masu yin fara-wa'anar mulki-lingui da aka haɗa da adaptori. Tuna sami ƙari game da abu da ba'a sani ba da masu husũma da masu husũma da haske da sami tare da shirin bayani na bayani na bayani na bayani-bayani masu iya iya bayani.", 'sk': 'Predstavljamo skupni prispevek IST in Unbabel k skupni nalogi WMT 2021 o oceni kakovosti. Naša ekipa je sodelovala pri dveh nalogah: neposredno ocenjevanje in prizadevanja po urejanju, ki so zajeli skupaj 35 prispevkov. Pri vseh prispevkih so se naša prizadevanja osredotočila na usposabljanje večjezičnih modelov na podlagi arhitekture OpenKiwi napovednikov-ocenjevalcev z uporabo vnaprej usposobljenih večjezičnih kodirnikov v kombinaciji z adapterji. Nadalje eksperimentiramo s cilji in funkcijami, povezanimi z negotovostjo, ter usposabljamo o zunajdomenskih neposrednih ocenjevalnih podatkih.', 'he': 'אנחנו מציגים את התרומה המשותפת של IST ואונבאבל למשימה המשותפת של WMT 2021 על הערכת איכות. Our team participated on two tasks: Direct Assessment and Post-Editing Effort, encompassing a total of 35 submissions.  לכל ההכנעות, המאמצים שלנו התמקדו באימון דוגמנים רבות שפות על גבי ארכיטקטורת ציפוי-ציפוי OpenKiwi, בשימוש בקודים רבות שפות מאומנים מראש ומשולבים עם מתאימים. אנו נוספים ניסויים עם מטרות ובתכונות קשורים לביטחון, כמו גם אימונים על נתוני הערכה ישירים מחוץ לתחום.', 'bo': 'ང་ཚོས་IST དང་Unbabel འི་མཐུན་སྒྲིག་གི་གནད་སྡུད་འདོད་པ་རྣམས་མཉམ་དུ་འཇུག ང་ཚོའི་གོ་མིང་གི་བྱ་འགུལ་གཉིས་ཀྱིས་མཉམ་དུ་འཇུག་སྟེ། ཐད་ཀར་ཞིབ་དཔྱད་ཞིབ་བྱེད་ཀྱི་སྒོ་ལས་ ཞིབ་དཔྱད་སྒྲུབ་བྱེད For all submissions, our efforts focused on training multilingual models on top of OpenKiwi predictor-estimator architecture, using pre-trained multilingual encoders combined with adapters. We further experiment with and uncertainty-related objectives and features as well as training on out-of-domain direct assessment data.'}
{'en': 'The IICT-Yverdon System for the WMT 2021 Unsupervised MT and Very Low Resource Supervised MT Task', 'pt': 'O sistema IICT-Yverdon para a tarefa de MT não supervisionada do WMT 2021 e tarefa de MT supervisionada com recursos muito baixos', 'ar': 'نظام IICT-Yverdon الخاص بمهمة MT 2021 غير الخاضعة للإشراف ومهمة الترجمة الآلية الخاضعة للإشراف ذات الموارد المنخفضة جدًا', 'fr': 'Le système IICT-Yverdon pour la tâche de MT non supervisée WMT 2021 et de MT supervisée à très faibles ressources', 'es': 'El sistema IICT-Yverdon para la tarea de MT supervisada y MT supervisada de muy pocos recursos del WMT 2021', 'ja': 'WMT 2021監督なしMTおよび非常に低資源監督付きMTタスクのためのIICT - Yverdonシステム', 'zh': '以WMT 2021无监机器翻译极低资源监机器翻译者IICT-Yverdon统', 'hi': 'WMT 2021 Unsupervised MT और बहुत कम संसाधन पर्यवेक्षित MT कार्य के लिए IICT-Yverdon सिस्टम', 'ga': 'Córas IICT-Yverdon do Thasc MT Gan Maoirseacht WMT 2021 agus MT faoi Mhaoirseacht Acmhainní An-Íseal', 'ru': 'Система IICT-Yverdon для неконтролируемого MT WMT 2021 и задачи MT с очень низким объемом ресурсов', 'ka': 'Comment', 'hu': 'Az IICT-Yverdon rendszer a WMT 2021 felügyelet nélküli MT és a nagyon alacsony erőforrás-felügyelet MT feladatokhoz', 'el': 'Το σύστημα ΙΙΤ-Υβερντον για το έργο ΜΤ 2021 Μη Εποπτευόμενο ΜΤ και Πολύ Χαμηλών Πόρων', 'it': 'Il sistema IICT-Yverdon per la MT non sorvegliata WMT 2021 e la MT supervisionata con risorse molto basse', 'lt': 'IICT-Yverdon sistema, skirta 2021 m. VMT nekontroliuojamai MT ir labai mažai išteklių prižiūrimai MT užduotims', 'mk': 'ИЛЦТ-Ивердонскиот систем за ненадгледуваната MT задача на WMT 2021 и многу ниски ресурси надгледувана MT задача', 'kk': 'WMT 2021 бағдарламасының IICT- Yverdon жүйесі MT және өте төмен ресурс бақылаған MT тапсырмасы', 'ml': 'WMT 2021-നുള്ള IICT- Yverdon സിസ്റ്റമാണു് നിരീക്ഷിച്ചിട്ടില്ലാത്ത MT വിഭവങ്ങളും വളരെ കുറഞ്ഞ വിഭവങ്ങളും മുഴുവന്\u200d പരിശോധി', 'ms': 'Sistem IICT-Yverdon untuk Tugas MT tanpa pengawasan WMT 2021 dan Sumber Tertinggi Tertinggi', 'no': 'IICT- Yverdon- systemet for WMT 2021 Ufullførte MT- og svært låg ressursovervakt MT- oppgåve', 'mn': 'WMT 2021 оны IICT-Yverdon систем багтаагүй MT болон маш бага нөөц багтаасан MT ажил', 'mt': 'Is-Sistema IICT-Yverdon għall-Ħidma MT Mhux Sorveljata tad-WMT 2021 u MT Sorveljata ta’ Riżorsi Baxxi Ħafna', 'si': 'WMT 2021 සඳහා IICT- Yverdon පද්ධතිය සහ ගොඩක් අඩු සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ සම්පූර්ණ MT කාර්ය', 'pl': 'System IICT-Yverdon dla WMT 2021 nienadzorowanego MT i zadania MT nadzorowane bardzo niskimi zasobami', 'sr': 'IICT-Yverdon sistem za WMT 2021 neodržavani MT i vrlo niski sustav nadzirani MT zadatak', 'ro': 'Sistemul IICT-Yverdon pentru activitatea MT nesupravegheată WMT 2021 și activitatea MT supravegheată cu resurse foarte scăzute', 'ta': 'WMT 2021 கண்காணிக்கப்படவில்லை', 'so': 'The IICT-Yverdon system for the WMT 2021 Unsupervised MT and Very Low Resource Supervised MT Task', 'sv': 'IICT-Yverdon-systemet för WMT 2021-uppgiften med icke-övervakad MT och mycket låg resursövervakning MT', 'ur': 'WMT 2021 کے لئے IICT-Yverdon سیسٹم ناپابندی MT اور بہت کم رسسور زیر نظارت کی MT ٹاکس', 'uz': 'Comment', 'vi': 'The IICT-Yveerdon system for the WRT 2021 Ungiám sát MTV và very low Resource giám sát MTV Task', 'bg': 'Системата Ивердон за МТ 2021 без надзор и задачата за МТ с много ниски ресурси', 'da': 'IICT-Yverdon-systemet til WMT 2021-opgaven med ukontrolleret MT og meget lavt ressourceovervåget MT', 'nl': 'Het IICT-Yverdon Systeem voor de WMT 2021 Onbewaakte MT en Zeer lage Resource Supervised MT Task', 'hr': 'IICT-Yverdon sustav za WMT 2021 neodržavani MT i vrlo niski sustav nadzirani MT zadatak', 'id': 'Sistem IICT-Yverdon untuk Tugas MT tanpa pengawasan WMT 2021 dan Ressource Terrendah Termengawasi MT', 'fa': 'سیستم IICT-Yverdon برای WMT 2021 MT و کامل MT مراقبت از منابع بسیار کم', 'de': 'Das IICT-Yverdon System für die WMT 2021 Unsupervised MT und sehr ressourcenarme überwachte MT Aufgabe', 'ko': 'WMT 2021 무감시 기계 번역 및 극저 자원 감시 기계 번역 임무를 위한 IICT Yverdon 시스템', 'sw': 'Mfumo wa IICT-Yverdon wa WMT 2021 usiotangaliwa na MT na rasilimali ndogo uliofanywa na MT', 'sq': 'Sistemi IICT-Yverdon për detyrën e MT-së pa mbikqyrje të WMT 2021 dhe MT-së me burime shumë të ulta të mbikqyrura', 'tr': "WMT 2021'iň IICT-Yverdon sistemi maslahat edilmedik MT we gaty düşük Ressurat Gözlemýän MT Görevi", 'af': 'Die IICT- Yverdon Stelsel vir die WMT 2021 Onondersteunde MT en Baie Lae Hulpbron Ondersoek MT Taak', 'hy': '2021 թվականի ԱՄԹ-ի անվերահսկված ՄԹ և շատ ցածր ռեսուրսների վերահսկված ՄԹ-ի համակարգը', 'am': 'The IICT-Yverdon System for the WMT 2021 Unsupervised MT and Very Low Resource Supervised MT Task', 'az': "WMT 2021'in IICT-Yverdon Sistemi təmin edilməmiş MT və çox düşük ressurs gözləyir MT işi", 'bs': 'Sistem IICT-Yverdon za WMT 2021 neodržavan MT i vrlo niski sustav nadzirani MT zadatak', 'bn': 'WMT ২০21-এর জন্য IICT-YVeron সিস্টেম এমটি এবং খুব কম সম্পদ সাপার্ভিভেট এমটি কাজ', 'cs': 'IICT-Yverdon systém pro WMT 2021 nekontrolované MT a MT úkol s velmi nízkými zdroji', 'fi': 'IICT-Yverdon-järjestelmä WMT 2021 valvomattomalle MT-tehtävälle ja erittäin vähän resursseja valvotulle MT-tehtävälle', 'et': 'IICT-Yverdoni süsteem WMT 2021 järelevalveta MT ja väga väikeste ressursside järelevalvega MT ülesande jaoks', 'ca': 'El sistema IICT-Yverdon per a la tasca MT sense supervisió del WMT 2021 i MT amb molts baixos recursos', 'jv': 'IIBT-YVerdon System kanggo WWT 2020 1 Gak Cocok MT lan ganyang bebas Reus Kapan MT Job', 'he': 'מערכת IICT-Yverdon עבור משימה MT ללא השגחה WMT 2021', 'ha': 'KCharselect unicode block name', 'sk': 'Sistem IICT-Yverdon za breznadzorovano MT WMT 2021 in nadzorovano nalogo MT z zelo nizkimi viri', 'bo': 'WMT 2021 ལ་རང་ཉིད་ཀྱི་IICT-Yverdon མ་ལག་གི་རྒྱུ་དངོས་ཡིན་པ་ལས་ཉུང་བའི་རྒྱུ་དངོས་མཐོང་སྐྱོང་རྒྱུ་ཡིན་པ MT Task'}
{'en': 'In this paper, we present the systems submitted by our team from the Institute of ICT (HEIG-VD / HES-SO) to the Unsupervised MT and Very Low Resource Supervised MT task. We first study the improvements brought to a ', 'fr': "Dans cet article, nous présentons les systèmes soumis par notre équipe de l'Institute of ICT (HEIG-VD/HES-SO) à la tâche de MT non supervisée et de MT supervisée à très faible ressource. Nous étudions d'abord les améliorations apportées à un système de base par des techniques telles que la rétro-traduction et l'initialisation à partir d'un modèle parent. Nous trouvons que les deux techniques sont bénéfiques et suffisent pour atteindre des performances comparables à celles des systèmes plus sophistiqués de la tâche de 2020. Nous présentons ensuite l'application de ce système à la tâche 2021 de traduction supervisée du haut-sorabe (HSB) vers l'allemand, dans les deux sens. Enfin, nous présentons un système contrastif pour le HSB-DE dans les deux sens, et pour la traduction non supervisée de l'allemand vers le bas sorabe (DSB), qui utilise une formation multitâche avec divers programmes de formation afin d'améliorer le niveau de base.", 'es': 'En este artículo, presentamos los sistemas presentados por nuestro equipo del Instituto de TIC (HEIG-VD/HES-SO) a la tarea MT no supervisada y MT supervisada de muy pocos recursos. Primero estudiamos las mejoras introducidas en un sistema de referencia mediante técnicas como la retrotraducción y la inicialización a partir de un modelo padre. Consideramos que ambas técnicas son beneficiosas y suficientes para alcanzar un rendimiento que se compara con los sistemas más sofisticados de la tarea de 2020. A continuación, presentamos la aplicación de este sistema a la tarea de 2021 para la traducción supervisada del alto sorabo (HSB) al alemán de bajos recursos, en ambas direcciones. Finalmente, presentamos un sistema contrastivo para HSB-DE en ambas direcciones, y para la traducción sin supervisión del alemán al bajo sorabo (DSB), que utiliza capacitación multitarea con varios programas de capacitación para mejorar la línea de base.', 'pt': 'Neste artigo, apresentamos os sistemas submetidos pela nossa equipa do Instituto de TIC (HEIG-VD / HES-SO) à tarefa de MT Não Supervisionado e MT Supervisionado de Recursos Muito Baixos. Primeiro estudamos as melhorias trazidas a um sistema de linha de base por técnicas como tradução reversa e inicialização de um modelo pai. Achamos que ambas as técnicas são benéficas e suficientes para alcançar um desempenho que se compara aos sistemas mais sofisticados da tarefa de 2020. Em seguida, apresentamos a aplicação deste sistema para a tarefa de 2021 para tradução do Alto Sorbio (HSB) supervisionada de baixo recurso para o alemão, em ambas as direções. Finalmente, apresentamos um sistema contrastivo para HSB-DE em ambas as direções, e para tradução não supervisionada de Alemão para Baixo Sorbio (DSB), que usa treinamento multitarefa com vários cronogramas de treinamento para melhorar a linha de base.', 'ar': 'في هذه الورقة ، نقدم الأنظمة المقدمة من قبل فريقنا من معهد تكنولوجيا المعلومات والاتصالات (HEIG-VD / HES-SO) إلى MT غير الخاضعة للإشراف ومهمة MT ذات الموارد المنخفضة جدًا. ندرس أولاً التحسينات التي تم إدخالها على نظام أساسي من خلال تقنيات مثل الترجمة الخلفية والتهيئة من نموذج أصلي. نجد أن كلتا الطريقتين مفيدتان وكافيتان للوصول إلى أداء يضاهي الأنظمة الأكثر تطوراً من مهمة 2020. نقدم بعد ذلك تطبيق هذا النظام إلى مهمة 2021 للترجمة الصربية العليا (HSB) منخفضة الموارد تحت الإشراف (HSB) إلى الترجمة الألمانية ، في كلا الاتجاهين. أخيرًا ، نقدم نظامًا تباينًا لـ HSB-DE في كلا الاتجاهين ، وللترجمة غير الخاضعة للرقابة من الألمانية إلى الصوربية السفلى (DSB) ، والتي تستخدم تدريبًا متعدد المهام مع جداول تدريب مختلفة لتحسين خط الأساس.', 'zh': '本文引ICT研究所(HEIG-VD / HES-SO)团队无监督MT极低资源督MT。 先论父之反移,与初始化之改基线。 此二术者,皆有益也,足以及2020年之系统也。 然后系统宜用于2021年低资源监督之上索布语(HSB)德语翻译之务,双向。 最后条上双向HSB-DE对统,及无监督德语至下索布语(DSB)译,其用训练之多任务训练改善基线。', 'hi': 'इस पेपर में, हम आईसीटी संस्थान (HEIG-VD / HES-SO) से हमारी टीम द्वारा प्रस्तुत प्रणालियों को असुरक्षित एमटी और बहुत कम संसाधन पर्यवेक्षित एमटी कार्य में प्रस्तुत करते हैं। हम पहले एक आधार रेखा प्रणाली में लाए गए सुधारों का अध्ययन करते हैं जैसे कि बैक-ट्रांसलेशन और पैरेंट मॉडल से प्रारंभिककरण जैसी तकनीकें। हम पाते हैं कि दोनों तकनीकें लाभकारी हैं और प्रदर्शन तक पहुंचने के लिए पर्याप्त हैं जो 2020 कार्य से अधिक परिष्कृत प्रणालियों के साथ तुलना करती हैं। फिर हम इस प्रणाली के आवेदन को 2021 कार्य के लिए प्रस्तुत करते हैं, जो दोनों दिशाओं में जर्मन अनुवाद के लिए कम संसाधन पर्यवेक्षित ऊपरी सोर्बियन (एचएसबी) के लिए है। अंत में, हम दोनों दिशाओं में एचएसबी-डीई के लिए एक विरोधाभासी प्रणाली पेश करते हैं, और असुरक्षित जर्मन से लोअर सोर्बियन (डीएसबी) अनुवाद के लिए, जो बेसलाइन पर सुधार करने के लिए विभिन्न प्रशिक्षण कार्यक्रमों के साथ बहु-कार्य प्रशिक्षण का उपयोग करता है।', 'ru': 'В этой статье мы представляем системы, представленные нашей командой из Института ИКТ (HEIG-VD/ HES-SO) для задачи «Неконтролируемый MT» и «Контролируемый MT с очень низким уровнем ресурсов». Сначала мы изучаем улучшения, внесенные в базовую систему такими методами, как обратный перевод и инициализация из родительской модели. Мы находим, что оба метода являются полезными и достаточными для достижения производительности, которая сравнивается с более сложными системами из задачи 2020 года. Затем мы представляем применение этой системы к задаче 2021 года для перевода с верхнесорбского (HSB) на немецкий язык с низким уровнем ресурсов в обоих направлениях. Наконец, мы представляем контрастную систему для HSB-DE в обоих направлениях и для неконтролируемого перевода с немецкого на нижний сорбский (DSB), которая использует многозадачное обучение с различными графиками обучения для улучшения по сравнению с базовой линией.', 'ja': '本稿では、当社チームがICT研究所（ HEIG - VD/HES - SO ）から提出したシステムを、監督されていないMTおよび非常に低資源監督されているMTタスクに提示します。まず、親モデルからの逆変換や初期化などの手法によってベースラインシステムにもたらされた改善を研究します。私たちは、両方のテクニックが有益であり、2020年のタスクのより洗練されたシステムと比較して、パフォーマンスに到達するのに十分であることを発見しました。次に、低資源監督下の上部ソルブ語（ HSB ）のドイツ語翻訳のための2021年のタスクへのこのシステムの両方向への適用を提示します。最後に、両方向のHSB - DEと、ドイツ語から下部ソルブ語（ DSB ）への翻訳のためのコントラストシステムを提示します。これは、ベースラインよりも改善するために、さまざまなトレーニングスケジュールを含むマルチタスクトレーニングを使用します。', 'ga': 'Sa pháipéar seo, cuirimid i láthair na córais atá curtha isteach ag ár bhfoireann ón Institiúid TFC (HEIG-VD / HES-SO) don tasc MT Gan Maoirseacht agus An-Íseal faoi Mhaoirseacht Acmhainne. Déanaimid staidéar ar dtús ar na feabhsuithe a tugadh ar chóras bunlíne trí theicnící mar ais-aistriúchán agus inisealú ó mhúnla tuismitheora. Faighimid amach go bhfuil an dá theicníocht tairbheach agus leordhóthanach chun feidhmíocht a bhaint amach i gcomparáid le córais níos sofaisticiúla ó thasc 2020. Cuirimid i láthair ansin cur i bhfeidhm an chórais seo ar thasc 2021 maidir le haistriúchán Gearmáinise go Gearmáinis faoi mhaoirsiú íseal-Sorbais, sa dá threo. Ar deireadh, cuirimid córas codarsnachta i láthair do HSB-DE sa dá threo, agus don aistriúchán Gearmáinise go Soirbis Íochtarach (DSB) gan mhaoirseacht, a úsáideann oiliúint il-tasc le sceidil oiliúna éagsúla chun feabhas a chur ar an mbonnlíne.', 'el': 'Στην παρούσα εργασία, παρουσιάζουμε τα συστήματα που υποβλήθηκαν από την ομάδα μας από το Ινστιτούτο ΤΠΕ (ΔΕΣ-ΣΟ) στην εργασία ΜΤ χωρίς εποπτεία και ΜΤ με πολύ χαμηλή εποπτεία πόρων. Αρχικά μελετάμε τις βελτιώσεις που επιφέρουν σε ένα σύστημα βάσης με τεχνικές όπως η μεταγραφή και η αρχικοποίηση από ένα γονικό μοντέλο. Διαπιστώνουμε ότι και οι δύο τεχνικές είναι ευεργετικές και επαρκείς για να επιτευχθεί απόδοση που συγκρίνεται με πιο εξελιγμένα συστήματα από την εργασία 2020. Στη συνέχεια, παρουσιάζουμε την εφαρμογή αυτού του συστήματος στην εργασία 2021 για την εποπτευόμενη Άνω Σορβική (HSB) σε Γερμανική μετάφραση χαμηλού πόρου, και προς τις δύο κατευθύνσεις. Τέλος, παρουσιάζουμε ένα αντιφατικό σύστημα για την HSB-DE και στις δύο κατευθύνσεις, καθώς και για τη μετάφραση χωρίς επίβλεψη από γερμανικά προς κατώτερα σορβικά (το οποίο χρησιμοποιεί εκπαίδευση πολλαπλών εργασιών με διάφορα προγράμματα κατάρτισης για να βελτιωθεί σε σχέση με τη βασική γραμμή.', 'hu': 'Ebben a tanulmányban bemutatjuk azokat a rendszereket, amelyeket csapatunk az IKT Intézetből (HEIG-VD / HES-SO) nyújtott be a Felügyelet nélküli MT és a Nagyon alacsony erőforrás felügyelet nélküli MT feladatra. Először is tanulmányozzuk az alapvető rendszer fejlesztéseit olyan technikákkal, mint például a visszafordítás és a szülőmodellből történő inicializálás. Úgy találjuk, hogy mindkét technika előnyös és elegendő ahhoz, hogy a 2020-as feladat kifinomultabb rendszereivel összehasonlítható teljesítményt érjünk el. Ezt követően bemutatjuk ennek a rendszernek a 2021-es feladatnak az alacsony erőforrású felső-szorbiai (HSB) német fordításra történő alkalmazását mindkét irányban. Végezetül bemutatjuk a HSB-DE kontrasztos rendszerét mindkét irányban, valamint a felügyelet nélküli német-alsó-szorbiai (DSB) fordításhoz, amely többfeladatos képzést használ különböző képzési ütemtervekkel, hogy javuljon az alaphelyzethez képest.', 'it': "In questo articolo presentiamo i sistemi presentati dal nostro team dall'Istituto di ICT (HEIG-VD / HES-SO) al compito MT non supervisionato e MT supervisionato con risorse molto basse. Per prima cosa studiamo i miglioramenti apportati a un sistema di base da tecniche come la traduzione posteriore e l'inizializzazione da un modello genitore. Troviamo che entrambe le tecniche siano utili e sufficienti per raggiungere prestazioni che si confrontano con sistemi più sofisticati dal compito 2020. Presentiamo quindi l'applicazione di questo sistema al compito 2021 per la traduzione Sorbiano Superiore (HSB) a Tedesco supervisionata a basse risorse, in entrambe le direzioni. Infine, presentiamo un sistema contrastante per HSB-DE in entrambe le direzioni, e per la traduzione non supervisionata dal tedesco alla Bassa Sorbia (DSB), che utilizza la formazione multi-task con vari programmi di allenamento per migliorare rispetto alla base.", 'ka': 'ამ დომენტში ჩვენ ჩვენი ჯგუფიდან ICT ინსტრუტიდან (HEIG-VD / HES-SO) მუშაობელი MT და მნიშვნელოვანი რესურსის დანახვა MT დავამუშაობით სისტემები ჩვენ ჩვენ გავამუშაობთ. ჩვენ პირველი ვისწავლით, რომ უფრო მეტადება, რომლებიც მეტადებელი მოდელიდან გადაწყვეტილი ტექნოგიებით გადაწყვეტილი და ინციალიზაცია. ჩვენ ვფიქრობთ, რომ ორივე ტექნექციები ბექნიფიკურია და მსგავსი, რომ გავაკეთოთ პროცექტირება, რომელიც 2020-ის დავალების უფრო სპორფიკურია სისტემის შემდეგ ჩვენ ამ სისტემის პროგრამაციას 2021 წლის სამუშაო რესურსისთვის, რომელიც უფრო მარტივი სორბიული (HSB) გადაწყენებულია გერმანეთის გარგულისთვის, ორივე საბოლოოდ, ჩვენ ჩვენ HSB-DE-ის კონტრასტიური სისტემის ჩვენებთ ორივე ნაწილში, და არასწორებული გერმანეთის კონტრასტიური სისტემის ჩვენებას, რომელიც გამოყენება მრავალური სამუშაო სამუშაო გან', 'kk': 'Бұл қағазда, біз командамыздың ICT институтынан (HEIG-VD / HES-SO) MT және MT тапсырмасына жіберілген жүйелерді таңдаймыз. Біз біріншіден негізгі жол жүйесіне қайта аудару және инициализациялау секілді технологиялар арқылы жұмысын зерттейміз. Біз 2020 жылы тапсырмасынан артық жүйелерді салыстыру үшін екі техникалық пайдалы және жеткілікті болады. Содан кейін бұл жүйеңіздің қолданбаны 2021 жылдың көп ресурстар бойынша жоғары сорбияның (HSB) аудармасына неміс аудармасына келтіреміз. Соңында, біз HSB-DE жүйесін екі бағытта және неміс тілдеріне төменгі сорбиян (DSB) аудармасына көп тапсырмаларды оқыту жоспарлармен қолданып, негізгі жолды жақсарту үшін көптеген тапсырмаларды оқыту жоспарларын', 'ml': 'ഈ പത്രത്തില്\u200d, നമ്മുടെ ടീമില്\u200d നിന്നും ഐസിഎസ്റ്റിട്ടിയില്\u200d നിന്നും കൊടുത്ത സിസ്റ്റീമുകള്\u200d എംടിയിലേക്കും കുറച്ച് വിഭവങ്ങള്\u200d മുഴുവന്\u200d പരിശോധിച We first study the improvements brought to a baseline system by techniques such as back-translation and initialization from a parent model.  2020 ജോലിയില്\u200d നിന്നും കൂടുതല്\u200d സോഫിസ്റ്റിക്കേറ്റ് സിസ്റ്റീമുകളോടൊപ്പം തുല്യമാക്കുന്ന രണ്ട് സാങ്കേതികവിദ് പിന്നീട് നമ്മള്\u200d ഈ സിസ്റ്റത്തിന്റെ പ്രയോഗത്തിന്റെ പ്രയോഗത്തെ 2021-ലേക്ക് കുറഞ്ഞ വിഭവങ്ങള്\u200dക്ക് മുകളില്\u200d നിരീക്ഷിക്കപ്പെ അവസാനം, നമ്മള്\u200d രണ്ടു വഴികളില്\u200d ഹെസ്ബി-ഡിയ്ക്ക് വിരോധമായ ഒരു സിസ്റ്റം കൊണ്ടുവരുന്നു. സംരക്ഷിക്കപ്പെടാത്ത ജര്\u200dമ്മന്\u200d സോര്\u200dബിയിലേക്ക് താഴെ പരിശീലിക്കുന', 'lt': 'Šiame dokumente pristatome sistemas, kurias mūsų komanda pateikė IRT instituto (HEIG-VD / HES-SO) nekontroliuojamam MT ir labai mažų išteklių kontroliuojamam MT uždaviniui. Pirmiausia tiriame patobulinimus, kurie buvo pasiekti pradinėje sistemoje taikant metodus, pvz., grįžtamąjį vertimą ir pradinį pradinį model į. Mes manome, kad abu metodai yra naudingi ir pakanka, kad būtų pasiekti rezultatai, palyginti su sudėtingesnėmis sistemomis nuo 2020 m. užduoties. Tada pristatysime šios sistemos taikymą 2021 m. uždaviniui mažai išteklių prižiūrima viršutinė sorbų kalba (HSB) vokiečių vertimui abiem kryptimis. Galiausiai mes pateikiame priešingą HSB-DE sistemą abiem kryptimis ir nekontroliuojamą vokiečių vertimą į žemesnę sorbų kalbą (DSB), kuri naudoja įvairių užduočių mokymą su įvairiais mokymo grafikais, kad pagerėtų lyginant su pradiniu lygiu.', 'mk': 'Во овој весник, ги претставуваме системите поднесени од нашиот тим од Институтот за ИКТ (ХИГ-ВД / ХЕС-СО) на ненадгледуваната MT и многу ниски ресурси надгледувана MT задача. Прво ги проучуваме подобрувањата што ги донесовме во основниот систем со техники како што се превод и иницијализација од родителски модел. Најдовме дека двете техники се корисни и доволни за да се постигнат резултати кои се споредуваат со пософистицирани системи од задачата за 2020 година. Потоа ја претставуваме апликацијата на овој систем на задачата од 2021 година за нискоресурсно надгледувана Горна Сорбија (ХСБ) на германски превод, во двете насоки. Конечно, претставуваме контрастивен систем за ХСБ-ДЕ во двете насоки, како и за ненадгледуван германски превод на ниска сорбија (ДСБ), кој користи мултизадачна обука со различни распоредки за обука за подобрување во однос на основата.', 'ms': 'Dalam kertas ini, kami memperkenalkan sistem yang dihantar oleh pasukan kami dari Institute of ICT (HEIG-VD / HES-SO) kepada tugas MT yang tidak dikendalikan dan MT yang dikendalikan Sumber Terrendah. Kami pertama-tama mempelajari peningkatan yang dibawa ke sistem as as dengan teknik seperti terjemahan-balik dan awalkan dari model induk. Kami mendapati bahawa kedua-dua teknik adalah berguna dan cukup untuk mencapai prestasi yang dibandingkan dengan sistem yang lebih canggih dari tugas 2020. Kemudian kami memperkenalkan aplikasi sistem ini kepada tugas 2021 untuk sumber rendah-mengawasi Upper Sorbian (HSB) kepada terjemahan Jerman, dalam kedua-dua arah. Akhirnya, kami memperkenalkan sistem bertentangan untuk HSB-DE dalam kedua-dua arah, dan untuk terjemahan Jerman ke Lower Sorbian (DSB) yang tidak diawasi, yang menggunakan latihan berbilang-tugas dengan pelbagai jadual latihan untuk memperbaiki atas asas.', 'mt': 'F’dan id-dokument, aħna nippreżentaw is-sistemi ppreżentati mit-tim tagħna mill-Istitut tal-ICT (HEIG-VD / HES-SO) lill-kompitu MT Mhux Sorveljat u MT b’Riżorsi Bażi Ħafna Sorveljat. L-ewwel nett nistudjaw it-titjib li sar f’sistema bażi permezz ta’ tekniki bħat-traduzzjoni lura u l-inizjalizzazzjoni minn mudell ġenitur. Aħna nsibu li ż-żewġ tekniki huma ta’ benefiċċju u biżżejjed biex tintlaħaq prestazzjoni li tqabbel ma’ sistemi aktar sofistikati mill-kompitu tal-2020. Imbagħad nippreżentaw l-applikazzjoni ta’ din is-sistema għall-kompitu tal-2021 għal Upper Sorbian (HSB) sorveljat b’riżorsi baxxi għat-traduzzjoni Ġermaniża, fiż-żewġ direzzjonijiet. Fl-a ħħar nett, qed nippreżentaw sistema ta’ kuntrast għal HSB-DE fiż-żewġ direzzjonijiet, u għat-traduzzjoni mhux sorveljata Ġermaniża għal Lower Sorbian (DSB), li tuża taħriġ multikompitu b’diversi skedi ta’ taħriġ biex titjieb fuq il-linja bażi.', 'no': 'I denne papiret presenterer vi systemene som er sendt av gruppa vår frå ICT-institusjonen (HEIG-VD / HES-SO) til MT-oppgåva som ikkje er oppretta og svært låg ressurs oversikt av MT-oppgåva. Vi studerer første forbedringane som førte til ein grunnlinjesystem med teknikk som tilbakeomsetjing og oppstarting frå eit foreldre modell. Vi finn at begge teknikkar er nyttig og tilstrekkelig for å nå utviklinga som samanliknar med meir sofistikerte systemar frå oppgåva 2020. Vi viser så programmet til denne systemet til 2021- oppgåva for låg ressurs oversikt over øvre sorbisk (HSB) til tysk oversettelse, i begge retningar. I slutt presenterer vi eit kontrastiv system for HSB-DE i både retningar, og for utviklinga av tysk til nedre sorbisk (DSB), som brukar fleire oppgåver med ulike treningsplanar for å forbetra baselinja.', 'pl': 'W niniejszym artykule przedstawiamy systemy zgłoszone przez nasz zespół z Instytutu ICT (HEIG-VD, HES-SO) do zadania MT nienadzorowanych i bardzo niskich zasobów. Najpierw badamy ulepszenia wprowadzone do systemu bazowego za pomocą technik takich jak tłumaczenie wsteczne i inicjalizacja z modelu macierzystego. Uważamy, że obie techniki są korzystne i wystarczające do osiągnięcia wydajności porównywanej z bardziej zaawansowanymi systemami z zadania 2020. Następnie przedstawiamy zastosowanie tego systemu do zadania 2021 dla tłumaczenia górnego sorbsorbskiego (HSB) na niemiecki, w obu kierunkach. Wreszcie przedstawiamy kontrastywny system dla HSB-DE w obu kierunkach, oraz dla tłumaczenia niemieckiego na dolsorbski (DSB), które wykorzystuje szkolenia wielozadaniowe z różnymi harmonogramami szkoleń, aby poprawić się nad bazą.', 'mn': 'Энэ цаасан дээр бид багийн ICT (HEIG-VD/HES-SO) Институтын MT болон маш бага нөөцийн Байгууллагын MT ажил руу дамжуулагдсан системийг тайлбарлаж байна. Эхлээд бид эцэг эхийн загвараас дахин хөгжүүлэх болон эхний загвараас эхлэх технологиудыг суурь шугам системд авч ирсэн. Бид 2020 оны ажил дээрх илүү нарийн системтэй харьцуулахад хэрэгтэй болон хангалттай технологиудыг олж мэднэ. Дараа нь бид энэ системийн хэрэглээ 2021 оны бага багасгал хөрөнгө оруулагдсан хэмжээнд Германы орчуулагч (HSB) руу Германы орчуулалт руу илэрхийлдэг. Эцэст нь бид HSB-DE-ын хоёр талд эсрэг системийг харуулж, Германыг доор сорб (DSB) руу дамжуулах боломжгүй, олон ажлын дасгал хөгжүүлэх төлөвлөгөөтэй ашигладаг.', 'ro': 'În această lucrare, prezentăm sistemele prezentate de echipa noastră de la Institutul de ICT (HEIG-VD / HES-SO) la sarcina MT nesupravegheată și MT cu resurse foarte scăzute. Mai întâi studiem îmbunătățirile aduse unui sistem de bază prin tehnici precum traducerea înapoi și inițializarea dintr-un model părinte. Considerăm că ambele tehnici sunt benefice și suficiente pentru a atinge performanțe care se compară cu sistemele mai sofisticate din sarcina 2020. Apoi prezentăm aplicarea acestui sistem la sarcina din 2021 pentru traducerea superioară (HSB) în germană supravegheată cu resurse reduse, în ambele direcții. În cele din urmă, prezentăm un sistem contrastant pentru HSB-DE în ambele direcții și pentru traducerea nesupravegheată din germană în Sorbiană Inferioară (DSB), care utilizează instruirea multi-task cu diverse programe de instruire pentru a îmbunătăți față de bază.', 'sr': 'U ovom papiru predstavljamo sisteme koje je naš tim podnio iz Instituta IKT (HEIG-VD / HES-SO) do zadatka MT-a i vrlo niskog resursa nadziranog MT-a. Prvo proučavamo poboljšanje koje su donijele u osnovni sistem tehnikama poput prevoda i inicijalizacije iz roditeljskog model a. Nalazimo da su obje tehnike korisne i dovoljne da postignu izvršnost koja se uspoređuje sa sofisticiranijim sistemima iz zadatka 2020. godine. Zatim predstavljamo primjenu ovog sistema na zadatak 2021. godine za niske resurse nadzorne na gornjem sorbijskom (HSB) njemačkom prevodu, u oba smjera. Konačno predstavljamo kontrastivni sistem za HSB-DE u oba smjera, i za neodređeni njemački premeštaj na niži Sorbijanski (DSB) prevod, koji koristi višestruku obuku sa različitim rasporedama obuke kako bi se poboljšao na osnovnoj liniji.', 'so': "Qoraalkan waxan ka soo bandhignaa nidaamka kooxdayaga laga soo dhiibay jaamacadda ICT (HEIG-VD/HES-SO) oo loo diro MT iyo Maamulka aad Resource Supered MT. Marka ugu horeysa waxaynu barannaa horumarinta lagu kordhiyey nidaamka aasaasiga ah, qaababka turjumista dib-u-turjumista iyo bilowga modelka waalidka. Waxaynu ognahay in labada teknikadoodu ay faa'iido u leeyihiin, waana ku filan yihiin in aad sameyn karto sameynta nidaamka sawirfaalka ah ee shaqada 2020. Markaas waxaynu soo bandhignaa codsiga nidaamkan ee 2021 shaqada hoose-resource oo lagu ilaaliyey Yuur Sorbian (HSB) xagga turjumista Jarmalka, labada hagid. Ugu dambaysta waxaan soo bandhignaa nidaam ka gees ah ee HSB-DE labada hagitaan, iyo turjumaadda aan la ilaalinayn Jarmalka ah oo lagu soo qoray qorshaha waxbarashada ee hooseeya Sorbiga (DSB), kaas oo isticmaalaya waxbarasho badan oo ku qoran waxbarasho kala duduwan si uu ugu beddelo qorshaha hoose.", 'sv': 'I den här uppsatsen presenterar vi de system som lämnats in av vårt team från IKT-institutet (HEIG-VD/HES-SO) till uppgiften Unsupervised MT och Very Low Resource Supervised MT. Vi studerar först förbättringarna av ett baslinjesystem genom tekniker som back-translation och initialisering från en överordnad modell. Vi finner att båda teknikerna är fördelaktiga och tillräckliga för att uppnå prestanda som jämförs med mer sofistikerade system från 2020-uppgiften. Vi presenterar sedan tillämpningen av detta system för 2021-uppgiften för lågresursövervakad övre sorbiska (HSB) till tyska översättning, i båda riktningarna. Slutligen presenterar vi ett kontrastivt system för HSB-DE i båda riktningarna, och för oövervakad tysk till nedre sorbiska (DSB) översättning, som använder multi-task träning med olika träningsscheman för att förbättra jämfört med baslinjen.', 'ta': 'இந்த காகிதத்தில், நாங்கள் எங்கள் குழு கொண்டுள்ள அமைப்புகளை காண்பிக்கிறோம் ICT அமைப்புகள் (HEIG-VD / HES-SO) மீது கண்காணிக்கப்படாத MT மற்றும் மிகவும முதலில் நாம் ஒரு பெற்றோர் மாதிரியில் இருந்து மொழிபெயர்ப்பு மொழிபெயர்ப்பு மற்றும் துவக்கத்தை போன்ற தொழில் 2020 பணியில் இருந்து மிகவும் சுக்கல் அமைப்புகளை ஒப்பிடுகிறது என்பதை நாம் கண்டுபிடிக்கிறோம் இரண்டு தொழில்நுட்பமும் ப பிறகு நாம் இந்த அமைப்பின் பயன்பாட்டை 2021 குறைந்த மூலத்திற்கு மேல் சோர்பியன் (HSB) மொழிபெயர்ப்பில் கண்காணிக்கப்பட்டுள்ள செ இறுதியில், HSB-DE க்கான மாறுபாட்டு அமைப்பை இரு திசைகளில் கொண்டு வருகிறோம், மற்றும் பாதுகாப்பாக்கப்படாத ஜெர்மன் சோர்பியன் (DSB) மொழிபெயர்ப்பிற்கு, அது ம', 'ur': 'اس کاغذ میں، ہم نے اپنے تیم کی طرف سے ICT (HEIG-VD / HES-SO) کے اینٹیوسٹ سے ناپاکیزہ MT اور بہت کم سرمایہ کا MT کام پر پیش کیا ہے۔ ہم پہلی بار تدریجی کے ذریعے بنیس لین سیسٹم کے لئے پیش کئے گئے ہیں جیسے پچھلی ترجمہ اور پچھلی موڈل سے آغاز کئے گئے ہیں۔ ہم دیکھتے ہیں کہ دونوں تکنیک فائدہ اٹھاتے ہیں اور کامیابی تک پہنچ جانے کے لئے کافی ہیں جو 2020 کے کام سے زیادہ مصنوعی سیستم سے مقایسہ کرتی ہے۔ اس کے بعد ہم نے اس سیسٹم کا کاروبار 2021 کے لئے نیچے سوربین (HSB) پر جرمن کی ترجمہ پر نظارت کیا ہے، دونوں طریقوں میں. آخر میں ہم HSB-DE کے لئے ایک مخالف سیستم کو دونوں طریقوں میں پیش کرتے ہیں اور نیچے سوربیان (DSB) کی تعلیم کے لئے جو مختلف طریقوں کی آموزش سیٹیوں کے ساتھ بہترین طریقوں سے استعمال کرتے ہیں۔', 'si': 'මේ පැත්තට, අපි අපේ කණ්ඩායමේ පද්ධතියේ ICT (HEIG-VD / HES-SO) සංස්ථානයෙන් පිළිගත්තා පද්ධතිය අපරික්ෂා MT සහ ගොඩක් අඩුම සම්පූර්ණ අපි මුලින්ම ප්\u200dරශ්නයක් අධානය කරනවා ප්\u200dරශ්නයක් පද්ධතියෙන් ආධානය පද්ධතියෙන් ගියා ප්\u200dරශ්නයක් වගේ  අපිට හොයාගන්න පුළුවන් තාක්ෂණය දෙන්නම ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය වෙන්න පුළුවන් වගේ අපි පස්සේ මේ පද්ධතියේ වැඩසටහන් 2021 වැඩසටහන් අඩු සෝර්බියාන් වලට (HSB) ජර්මන් වාර්ථාව, දෙන්නම් පැත්තෙන්. අන්තිමට, අපි HSB-DE වෙනුවෙන් ප්\u200dරතික්\u200dරියාත්මක පද්ධතියක් පෙන්වනවා දෙන්නම් ප්\u200dරතික්\u200dරියාත්මක වෙනුවෙන්, සහ ජර්මාන් නැති සොර්බියාන් (DSB)', 'uz': "Bu qogʻozda, biz guruhimizning ICT Institute (HEIG-VD/HES-SO) ga joʻnatilgan tizimlarni ko'rib chiqaramiz MT va juda kichkina Resource muammolar qilingan MT vazifasiga qaramamiz. Biz birinchi marta o'rganamiz, buning ota-onasi modeldan birinchi tarjima qilish va birinchi o'zgarishni o'rganamiz. Biz o'ylaymiz, ikkita teknologiz foydalanuvchi va 2020 vazifalardan ko'proq sofistik tizimlarga kamaytirish ishga yetarli yetarlicha bo'ladi. Keyin biz bu tizimni 2021 ta vazifani yuqori Sorbiya (HSB) ga qaror qiladigan yuqori narsalarni Olmoncha tarjima qilishga qaramamiz. Endi, biz ikkita tartibi bilan HSB-DE uchun contrast tizimni hozirganamiz, va asosiy tarjima qilish uchun Olmoncha Sorbiya (DSB) tarjimalarini saqlab qolish uchun ko'plab vazifani bajaradi.", 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu hệ thống được gửi đến bởi đội của chúng tôi từ Học viện I.T (HEGI-VD (HES-so) cho các kênh chưa được kiểm soát và tài nguyên cực thấp giám sát MTV. Đầu tiên chúng tôi nghiên cứu những cải tiến tiến được mang đến một hệ cơ sở cơ bản bằng kỹ thuật quay lại và khởi tạo từ mô hình phụ huynh. Chúng tôi thấy cả hai kỹ thuật đều thuận lợi và đủ để đạt được những hiệu quả so sánh với những hệ thống phức tạp hơn từ nhiệm vụ 2020. Chúng tôi đưa hệ thống này vào nhiệm vụ 2021 cho dịch vụ Upper Sorbian giám sát ít tài nguyên (HSB) cho Đức, theo cả hai hướng. Cuối cùng, chúng tôi giới thiệu một hệ thống tương phản với HSB-de cả hai chiều, và dịch của người Đức đến Lower Sorbian (DSB) không giám sát, chuyên môn đa nhiệm với các lịch huấn luyện khác nhau để cải thiện trên cơ sở cơ bản.', 'bg': 'В настоящата статия представяме системите, представени от екипа ни от Института по ИКТ (ХЕИГ-ВД/ХЕС-СО) на задачата "Неконтролирана МТ" и "Много нискоресурсно контролирана МТ". Първо изследваме подобренията, внесени в базовата система чрез техники като обратен превод и инициализация от родителски модел. Намираме, че и двете техники са полезни и достатъчни за постигане на резултати, които се сравняват с по-сложните системи от задачата 2020. След това представяме приложението на тази система към задачата 2021 г. за нискоресурсен надзорен Горно-сорбийски превод на немски език в двете посоки. На последно място, представяме контрастна система за превод от немски на долносорбийски (ДСБ), която използва многофункционално обучение с различни графици за обучение, за да се подобри спрямо базовата база.', 'da': 'I denne artikel præsenterer vi de systemer, som vores team har indsendt fra Institutet for IKT (HEIG-VD / HES-SO) til opgaven Uservised MT og Very Low Resource Supervised MT. Vi undersøger først de forbedringer, der er bragt til et baseline system ved hjælp af teknikker som back-translation og initialisering fra en overordnet model. Vi finder, at begge teknikker er gavnlige og tilstrækkelige til at opnå ydeevne, der sammenlignes med mere sofistikerede systemer fra opgaven 2020. Vi præsenterer derefter anvendelsen af dette system til 2021-opgaven for lav ressourceovervåget øversorbisk (HSB) til tysk oversættelse, i begge retninger. Endelig præsenterer vi et kontrastivt system for HSB-DE i begge retninger, og for uautoriseret tysk til Niedersorbisk (DSB) oversættelse, som bruger multi-task træning med forskellige træningsplaner til at forbedre i forhold til baseline.', 'nl': "In dit artikel presenteren we de systemen die door ons team van het Instituut voor ICT (HEIG-VD, HES-SO) zijn ingediend voor de taak Onbewaakte MT en Zeer lage Resource Supervised MT. We bestuderen eerst de verbeteringen van een basissysteem door technieken zoals back-translation en initialisatie vanuit een ouder model. We vinden dat beide technieken gunstig zijn en voldoende zijn om prestaties te bereiken die vergeleken kunnen worden met meer geavanceerde systemen uit de 2020-taak. Vervolgens presenteren we de toepassing van dit systeem op de 2021 taak voor low-resource supervised Upper Sorbisch (HSB) naar Duits vertaling, in beide richtingen. Tot slot presenteren we een contrastief systeem voor HSB-DE in beide richtingen, en voor onbeheerde Duits-Neder-Sorbische vertaling (DSB), waarbij gebruik wordt gemaakt van multi-task training met verschillende trainingsschema's om te verbeteren ten opzichte van de basislijn.", 'hr': 'U ovom papiru predstavljamo sustave koje je naš tim podnio iz Instituta ICT (HEIG-VD / HES-SO) na zadatak MT-a i vrlo niskog nadzornog MT-a. Prvo proučavamo poboljšanje koje su dovele do početnog sustava tehnikama poput prevoda i inicijalizacije iz roditeljskog model a. Smatramo da su obje tehnike korisne i dovoljne za postizanje učinka koja se uspoređuje sa sofisticiranijim sustavima iz zadatka 2020. godine. Zatim predstavljamo primjenu ovog sustava na zadatak 2021. godine za niske resurse nadziranog nadzora nad gornjem sorbijskom (HSB) njemačkom prevodu, u oba smjera. Konačno predstavljamo kontrastivni sustav za HSB-DE u oba smjera, i za neodređeni njemački premještaj na niži Sorbijanski (DSB), koji koristi višezadatačnu obuku s različitim rasporedama obuke kako bi se poboljšao na početnoj liniji.', 'de': 'In diesem Beitrag stellen wir die Systeme vor, die unser Team vom Institut für IKT (HEIG-VD, HES-SO) für die Aufgabe der unbeaufsichtigten MT und der sehr ressourcenschonenden überwachten MT eingereicht hat. Zunächst untersuchen wir die Verbesserungen, die durch Techniken wie Rückübersetzung und Initialisierung eines Elternmodells zu einem Basissystem gebracht wurden. Wir finden, dass beide Techniken vorteilhaft sind und ausreichen, um eine Leistung zu erreichen, die mit komplexeren Systemen aus der 2020-Aufgabe vergleichbar ist. Anschließend stellen wir die Anwendung dieses Systems auf die 2021-Aufgabe für ressourcenschonend betreute obersorbische Übersetzung (HSB) in beide Richtungen vor. Abschließend stellen wir ein kontrastives System für HSB-DE in beide Richtungen und für die unbeaufsichtigte Deutsch-Niedersorbische Übersetzung (DSB) vor, das Mehraufgabentraining mit verschiedenen Trainingsplänen verwendet, um sich gegenüber der Basislinie zu verbessern.', 'ko': '본고에서 우리 팀은 ICT연구소(HEIG-VD/HES-SO)에서 무감독기계번역과 극저자원감독기계번역 임무를 제출하는 시스템을 소개했다.우리는 먼저 부모형에서 역방향 번역과 초기화 등 기술이 기선 시스템에 대한 개선을 연구했다.2020년 과제에서 더 복잡한 시스템에 비해 이 두 가지 기술은 모두 유익하고 성능에 충분하다는 것을 알 수 있다.그리고 2021년 저자원 감독의 상소포어(HSB) 독일어 번역 임무에서 이 시스템의 응용을 소개했다.마지막으로 우리는 HSB-DE 쌍방향 대비 시스템과 독일어에서 저소포어(DSB) 번역 대비 시스템을 제시했다. 이 시스템은 다중 임무 훈련과 서로 다른 훈련 계획을 사용하여 기선을 개선한다.', 'fa': 'در این کاغذ، سیستم\u200cهایی را که توسط تیم ما از موسسه ICT (HEIG-VD / HES-SO) به وظیفه MT و منابع بسیار کم تحت نظر MT پیشنهاد می\u200cکنیم. ما اولین بار توسط تکنیک\u200cهایی که توسط ترجمه پشتیبانی و شروع از یک مدل والدین به سیستم پایین آورده شده\u200cایم تحقیق می\u200cکنیم. ما پیدا می\u200cکنیم که هر دو تکنیک سودمندانه و کافی است برای رسیدن به عملکرد که با سیستم\u200cهای پیچیده\u200cتر از کار 2020 مقایسه می\u200cکند. سپس کاربرد این سیستم را به وظیفه ۲۰۱۲ برای منابع کم تحت نظر قرار می دهیم که سوربیان بالا (HSB) به ترجمه آلمانی در هر دو جهان است. بالاخره، ما یک سیستم متفاوتی برای HSB-DE در هر دو مسیر و برای ترجمه آلمانی ناتوان به سوربیان پایین (DSB) را پیشنهاد می\u200cکنیم که از تمرین چندین کار با برنامه\u200cهای آموزش مختلف برای بهتر کردن بر خط پایین استفاده می\u200cکند.', 'sw': 'Katika karatasi hii, tunaonyesha mfumo uliotolewa na timu yetu kutoka Taasisi ya TEKNOHAMA (HEIG-VD/HES-SO) kwenda kwenye kazi za MT zisizoangaliwa na rasilimali zisizo na ujumbe wa MT. Kwanza tunasoma maendeleo yaliyopelekea kwenye mfumo wa msingi kwa njia kama vile tafsiri za nyuma na kuanzishwa kwa muundo wa wazazi. Tunapata kwamba mbinu hizo mbili zinafaa na zinatosha kufikia utendaji ambao unalinganisha na mfumo wa kisasa zaidi kuanzia kazi ya 2020. Kisha tunaonyesha matumizi ya mfumo huu kwenye kazi ya 2021 kwa rasilimali ndogo inayofuatiliwa na Ki-Sorbia Kuu (HSB) kwa utafsiri wa Kijerumani, kwa njia zote. Mwisho, tunaweka mfumo wenye utata wa HSB-DE katika mbili zote, na kwa tafsiri isiyo na usalama wa Kijerumani kwenda Kisombo Kichini (DSB), ambayo hutumia mafunzo ya kazi nyingi kwa mipango mbalimbali ya mafunzo ili kuboresha msingi.', 'tr': 'Bu kagyzda biziň toparymyzyň ICT Institutyndan (HEIG-VD / HES-SO) gaýd edilmedik MT we gaty düşük Ressurat Kontrol MT işine gönderilen sistemlary görkezip otyrdyk. Biz ilkinji gezek atasy nusgadan terjime edilen we başlançylygy ýaly tekniklerden üýtgeşmeleri üýtgedik. 2020-nji zadyň ýokary sofistikli sistemalary bilen görä çykmak üçin ikisi teknikleriň faydaly we ýeterlik bolup ýeterlik. Sonra bu sistemiň uygulamasyny 2021-nji ýylyň üst-sorbiýanyň (HSB) täsirinde Germaniýa terjime etmäge görkezilýäris. Soňunda biz HSB-DE üçin ikinji tarapynda kontrast sistemasyny we almanyň a şak Sorbiýa (DSB) terjime etmegini ulanýarys. Bu sistemi üýtgetmek üçin birnäçe işgär terjime etmek üçin birnäçe işgär terjime paýlaryny ulanýar.', 'am': 'በዚህ ካላት፣ የብልሃቶቻችንን ተሟጋቾች ከኢቴስቲ ዩንቨርስቲ (HEIG-VD / HES-SO) ወደ ያልተጠበቀው MT እና በጣም ጥቂት የክፍለ ሀብት ስራ እናቀርባለን፡፡ በመጀመሪያ የባላጆች ሞዴል እንደምትረጉም እና የመጀመሪያ ትርጉም እንደሆነ ወደ መሳሳይ ስርዓት የደረሰትን ጥናት እናስተምር፡፡ ከ2020 ስራ ጋር የሚተያያየው የስብሰባ ስርዓቶች የሚጠቅሙ እና የሚበቃቸው መሆኑን እናገኛለን፡፡ ከዚህም በኋላ የዚህን ስርዓት ፕሮግራሙን በ2021 ክፍል ወደ ላይ ሶርቢያ (HSB) ወደ ጀርመን ትርጓሜ እናስገድዳለን፡፡ በመጨረሻውም፣ ለHSB-DE በተቃዋሚ ስርዓት በሁለቱም መንገዶች እና የጀርመን ትርጓሜ ለመታጠቂያ (DSB) ትርጓሜ እናቀርባታለን፡፡', 'af': "In hierdie papier, ons voorsien die stelsels wat deur ons span ondersteun is van die Institute van ICT (HEIG-VD / HES-SO) na die Onondersteunde MT en baie lae hulpbron ondersoek MT taak. Ons studeer eerste die verbeteringe wat na 'n basilyn stelsel gebring het deur teknike soos terugvertaling en inisialisering van 'n ouer model. Ons vind dat beide teknike nuttig en voldoende is om performance te bereik wat vergelyk met meer sofistike stelsels van die taak 2020 af te vergelyk. Ons bring dan die aansoek van hierdie stelsel aan die 2021 taak vir lae hulpbron wat bo-sorbiese (HSB) na Duitse vertaling is, in beide rigtings. Eindelik stel ons 'n kontrastiewe stelsel vir HSB-DE in beide rigtings en vir onverondersteunde Duitse na Lower Sorbian (DSB) vertaling, wat gebruik veelvuldige taak onderwerking met verskillende onderwerking skedule om oor die basisline te verbeter.", 'id': 'Dalam kertas ini, kami memperkenalkan sistem yang dikirim oleh tim kami dari Institut ICT (HEIG-VD / HES-SO) kepada MT yang tidak diawasi dan MT yang mengawasi sumber daya yang sangat rendah. Kami pertama-tama mempelajari perbaikan yang dibawa ke sistem dasar dengan teknik seperti terjemahan belakang dan inisialisasi dari model orang tua. Kami menemukan bahwa kedua teknik berguna dan cukup untuk mencapai prestasi yang dibandingkan dengan sistem yang lebih canggih dari tugas 2020. We then present the application of this system to the 2021 task for low-resource supervised Upper Sorbian (HSB) to German translation, in both directions.  Akhirnya, kami mempersembahkan sistem kontras untuk HSB-DE dalam kedua arah, dan untuk terjemahan Jerman ke Lower Sorbian (DSB), yang menggunakan pelatihan multi-tugas dengan berbagai jadwal pelatihan untuk meningkat dari dasar.', 'sq': 'In this paper, we present the systems submitted by our team from the Institute of ICT (HEIG-VD / HES-SO) to the Unsupervised MT and Very Low Resource Supervised MT task.  Ne studiojmë së pari përmirësimet e sjellura në një sistem bazë me teknika të tilla si përkthimi prapa dhe inicializimi nga një model prindër. Ne zbulojmë se të dy teknikat janë të dobishme dhe mjaftueshme për të arritur performancë që krahasohet me sisteme më të sofistikuara nga detyra 2020. Pastaj prezantojmë aplikimin e këtij sistemi në detyrën e 2021 për burimet e ulëta të mbikqyrura nga Sorbia e Lartë (HSB) në përkthimin gjerman, në të dy drejtimet. Më në fund, ne paraqesim një sistem kontrastiv për HSB-DE në të dy drejtimet dhe për përkthimin gjerman pa mbikqyrje në Sorbin e Poshtëm (DSB), i cili përdor trajnimin me shumë detyra me skeda të ndryshme trajnimi për të përmirësuar mbi bazën.', 'az': 'Bu kağızda, ekibimizin ICT Institute (HEIG-VD / HES-SO) ilə mühafizə edilməmiş MT və çox düşük ressurs gözləyir MT işinə göndərilmiş sistemləri göstəririk. Biz ilk dəfə ata modelindən geri çevirilən və başlanğıçlandırmaq kimi təklikdən tədbir sisteminə gətirilən yaxşılıqları təhsil edirik. İki tekniklər 2020 işindən daha sofistikli sistemlərlə qarşılaşdırmaq üçün faydalı və yetər. Sonra bu sistemin uyğulamasını 2021-ci ilə yüksək sorbistan (HSB) ilə birlikdə alman tercüməsinə təyin edirik. Sonunda HSB-DE üçün hər iki tərəfdə müxtəlif bir sistemi göstərdik və əsas səhifələri üstündə yaxşılaşdırmaq üçün çoxlu təhsil təhsil təhsil etmək üçün Almanca ilə a şağı Sorbi (DSB) təhsil etmək üçün.', 'hy': 'Այս թղթի մեջ մենք ներկայացնում ենք համակարգերը, որոնք մեր թիմի կողմից տեղեկատվական ինստիտուտի (ՀԻԳ-ՎԴ և ՀԵՍ-ՍՕ) ներկայացված են անվերահսկված ՄԹ-ի և շատ ցածր ռեսուրսների վերահսկված ՄԹ-ի առաջադրանքին: Մենք առաջին անգամ ուսումնասիրում ենք հիմնական համակարգի բարելավումները, որոնք բերվել են այնպիսի տեխնիկաների միջոցով, ինչպիսիք են ծնողների մոդելի թարգմանությունը և սկզբնական գործընթացը: Մենք կարծում ենք, որ երկու տեխնիկաները օգտակար են և բավարար են, որպեսզի հասնենք արդյունքների, որոնք համեմատում են 2020-ի խնդիրներից ավելի բարդ համակարգերի հետ: Այնուհետև մենք ներկայացնում ենք այս համակարգի կիրառումը 2021 թվականին ցածր ռեսուրսների վերահսկվող վերևի սորբյան (HSB) խնդիրների համար գերմանացի թարգմանման համար, երկու ուղղությամբ: Վերջապես, մենք ներկայացնում ենք հակադրական համակարգ HSB-DE ի համար երկու ուղղություններում, ինչպես նաև անվերահսկված գերմանացի դեպի ցածր սորբյան (DSB) թարգմանման համար, որը օգտագործում է բազմախնդիր վարժեցման տարբեր ուսուցման ծրագրեր, որպեսզի բարելավվի', 'bn': 'এই কাগজটিতে আমরা আমাদের টিম অফ আইসিটিটিউটি (এইচজ-ভিডি/এইএস-এসও) থেকে আমাদের দলের প্রতি সিস্টেম উপস্থাপন করেছি অনভারডিও এমটি এবং খুব কম রিসোর্স স সার্ প্রথমে আমরা একটি বেসেলাইন সিস্টেমে উন্নয়ন গবেষণা করি প্রযুক্তি যেমন পিতামাতা মডেল থেকে পিছু অনুবাদ এবং প্রাথমিক আমরা দেখতে পাচ্ছি যে দুটি প্রযুক্তিগুলো সুবিধা আর যথেষ্ট প্রদর্শনের কাজে পৌঁছাতে পারে যা ২০২০ টি কাজ থেকে আরো সাফিক্ তারপর আমরা এই সিস্টেমের অ্যাপলিকেশন ২০২১ সালের দিকে জার্মান অনুবাদের দুই দিকে নিম্নলিখিত সম্পদের কাজে উপস্থাপন করি। শেষ পর্যন্ত আমরা এইচএসবি-ডি-এর একটি বিরোধী সিস্টেম দুই দিকে উপস্থাপন করি, আর জার্মানের সংরক্ষিত সোর্বিয়ান (ডিএসবি) অনুবাদের জন্য, যা বিভিন্ন প্রশিক্ষণের পরিকল্', 'bs': 'U ovom papiru predstavljamo sisteme koje je naš tim podnio od Instituta ICT (HEIG-VD / HES-SO) do zadatka MT-a i vrlo niskog nadzornog MT-a. Prvo proučavamo poboljšanje koje su donijele u osnovni sistem tehnikama poput prevoda i inicijalizacije iz roditeljskog model a. Mi smatramo da su obje tehnike korisne i dovoljne za postizanje učinka koja se uspoređuje sa sofisticiranijim sistemima iz zadatka 2020. godine. Zatim predstavljamo primjenu ovog sistema na zadatak 2021. godine za niske resurse nadzirane na gornjem sorbijskom (HSB) njemačkom prevodu, u oba smjera. Konačno predstavljamo kontrastivni sistem za HSB-DE u oba smjera, i za nepotrebnu njemačku premeštenje na niži Sorbijanski (DSB), koji koristi multizadatačnu obuku sa različitim rasporedama obuke kako bi se poboljšao na osnovnoj liniji.', 'ca': "En aquest article, presentem els sistemes presentats pel nostre equip de l'Institut de les TIC (HEIG-VD/HES-SO) a la tasca de MT no supervisada i de MT supervisada amb molts baixos recursos. Primer estudiem les millors que van portar a un sistema de referència mitjançant tècniques com la tornada de traducció i l'inicialització d'un model mare. Trobem que les dues tècniques són beneficioses i suficients per aconseguir un rendiment que es compara amb sistemes més sofisticats a partir de la tasca del 2020. Llavors presentem l'aplicació d'aquest sistema a la tasca del 2021 per a una sorbia superior (HSB) amb baix recursos a la traducció alemana, en ambdues direccions. Finalment, presentem un sistema contrastiu per HSB-DE en ambdues direccions, i per traducció alemana a baixa sorbia (DSB) sense supervisió, que utilitza capacitació multitasca amb diversos programes de capacitació per millorar sobre el punt de referència.", 'cs': 'V tomto příspěvku představujeme systémy předložené naším týmem z Ústavu ICT (HEIG-VD, HES-SO) na úlohu MT bez dohledu nad velmi nízkými zdroji. Nejprve studujeme zlepšení základního systému technikami, jako je zpětný překlad a inicializace z mateřského modelu. Zjišťujeme, že obě techniky jsou přínosné a dostačují k dosažení výkonu, který se srovnává s sofistikovanějšími systémy z úlohy 2020. Následně prezentujeme aplikaci tohoto systému na úlohu 2021 pro nízkoprostrojově dohlížený Horní Sorbština (HSB) do německého překladu v obou směrech. V závěru představujeme kontrastní systém pro HSB-DE v obou směrech a pro bez dozoru překlad z němčiny do dolosorbštiny (DSB), který využívá víceúlohový trénink s různými tréninkovými harmonogramy pro zlepšení nad základní hodnotou.', 'fi': 'Tässä artikkelissa esitellään ICT-instituutin (HEIG-VD / HES-SO) toimittamat järjestelmät valvomattoman MT:n ja erittäin vähän resursseja valvotun MT:n tehtävään. Ensin tutkimme perusjärjestelmän parannuksia tekniikoilla, kuten taustakäännös ja alustus emomallista. Molemmat tekniikat ovat mielestämme hyödyllisiä ja riittävät saavuttamaan suorituskykyä, joka on verrattavissa vuoden 2020 tehtävän kehittyneisiin järjestelmiin. Tämän jälkeen esittelemme järjestelmän soveltamisen vuoden 2021 tehtävään vähävaraisesti valvottuun yläsorbian (HSB) saksankieliseen käännökseen molempiin suuntiin. Lopuksi esittelemme kontrastijärjestelmän HSB-DE:lle molemmissa suunnissa ja valvomattomalle saksan-alemman sorbian käännökselle (DSB), joka hyödyntää monitehtäväkoulutusta ja erilaisia koulutusohjelmia parantaakseen lähtötasoon verrattuna.', 'et': 'Käesolevas töös tutvustame meie meeskonna poolt IKT Instituudi (HEIG-VD / HES-SO) poolt esitatud süsteeme järelevalveta MT ja väga madala ressursi järelevalvega MT ülesandele. Esmalt uurime algsüsteemi parandusi selliste meetodite abil nagu tagasitõlkimine ja initsialiseerimine algmudelist. Leiame, et mõlemad meetodid on kasulikud ja piisavad tulemuslikkuse saavutamiseks, mis on võrreldavad 2020. aasta ülesande keerukamate süsteemidega. Seejärel tutvustame selle süsteemi rakendamist 2021. aasta ülesandele madala ressursiga järelevalvega Ülemsorbia keele (HSB) saksa keele tõlkimiseks mõlemas suunas. Lõpuks esitame kontrastiivse süsteemi HSB-DE jaoks mõlemas suunas ja järelevalveta saksa keele tõlke jaoks Alam-Sorbi keelde (DSB), mis kasutab mitmeülesandelist koolitust erinevate koolitusprogrammidega, et parandada võrreldes lähtetasemega.', 'jv': 'Nang pentungé iki, kita nggawe sistem sing nyebutaké ning ayèn dhéwé ning acara kelompok kelompok nggawe Universite (HEIG-VD/HES-So) karo MT gawe barang nggawe barang kelompok ngon MT bepaling apat. Awak dhéwé éntuk perusahaan kanggo ngerewak dhéwé éntuk sistem sing wis ana dadi, nik kuwi nggawe tarjamahan karo mulai nggawe sistem sing wis ana dadi, nik kuwi wis tarjamahan karo model sing ngawehi. Awak dhéwé ngerasah sistem iki dadi bener lan saiki sufisitan kanggo nggawe gerakan karo sistem sophistiké karo nggawe 2020 Awak dhéwé nggawe aplikasi sistem iki kanggo nggawe 2020 1 dadi apakno kanggo langgar-apakno dadi super Lha soalé, kita mulai sistem sing komparasi kanggo HS B-de iki, lan kanggo terjamahan sing gak bandakan Jagad kanggo Kebebasan (SSB), sing isin akeh multi-task setungkat nganggo sistem sing dadi kapan kanggo mbatalé dianggap.', 'sk': 'V prispevku predstavljamo sisteme, ki jih je naša ekipa z Inštituta za IKT (HEIG-VD / HES-SO) predložila nalogi nadzorovane MT in nadzorovane MT z zelo nizkimi viri. Najprej preučujemo izboljšave osnovnega sistema s tehnikami, kot sta nazaj prevajanje in inicializacija iz matičnega modela. Ugotavljamo, da sta obe tehniki koristni in zadostni za doseganje uspešnosti, ki je primerljiva z bolj prefinjenimi sistemi iz naloge 2020. Nato predstavljamo uporabo tega sistema za nalogo leta 2021 za nizko-sredstveno nadzorovano zgornjo-sorbijsko prevajanje (HSB) v nemščino, v obeh smereh. Na koncu predstavljamo kontrastni sistem za HSB-DE v obeh smereh in za nenadzorovano prevajanje nemščine v spodnji sorbijščini (DSB), ki uporablja večopravilno usposabljanje z različnimi urniki usposabljanja za izboljšanje glede na izhodišče.', 'ha': "Ga wannan takardan, Munã halatar da system wanda teammanmu aka saka shi daga Installa na ICT (EMIG-V/AIS-SO) zuwa the Ungoverned MT and Very Low Resource Supered MT. Babu karanta mafarin ko da aka zo zuwa a matsayin salon na'urar kwamfyuta kamar misalin-tarjiwa da fara-tarjiwa daga misalin mahaifa. Tuna gane cewa dukansu masu da amfani ne kuma ma'ishi su isa ga aikin da ke sammenfani da wasu na'urar sofi da aikin 2020. Sa'an nan kuma muna halatar da shirin ayukan wannan na'ura zuwa aikin 2021 da aka yi wa wuri-resource domin tsari da Upper Sorbian (HSB) zuwa fassarar Jarman, cikin dukansu. Haƙĩƙa, Munã halatar da wata fassara mai motsi na HSB-DA cikin dukkan hanyõyi biyu, kuma don a sami-tsare jeruman zuwa Lower Sorbian (DSB), wanda ke amfani da aikin mulki-aikin da shiryoyin wahalar da ko wasu shiryoyin tababar da za'a samar da shi.", 'bo': 'འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོའི་མ་ལག་པོ་ཞིག་ལས་ICT (HEIG-VD / HES-SO)སྒྲིག་འཛུགས་པ་ཚོའི་ནང་དུ་བཏོན ང་ཚོས་དང་པོ་བརྗོད་ནས་ཡར་རྒྱས་ལྗོངས་དང་འགོ་འཛུགས་ཀྱི་ཐབས་ལམ་ལ་ཕྱིར་གཞི་རིམ་པ་ཞིག་གི་ནང་དུ་ཡར་རྒྱས་ལོངས་དང་འག ང་ཚོས་ལག་རྩལ་བ་གཉིས་ཀྱིས་ཡོད་པ་དང་ལས་སྒྲུབ་ཕྱོགས་ནུས་ཡོད་ཚད་ལྡན་བྱ་རིམ་དང་མཐུན་རྐྱེན་ཐབས་བ་ཡིན་པས འོན་ཀྱང་། ང་ཚོས་མ་ལག་འདིའི་བྱ་སྤྱོད་རིམ་ལ་2021 རིང་ཐོག་མཛོད་ཁང་ལ་ཉུང་བའི་རིམ་པ་ཞིག་ལ་སྟོན Finally, we present a contrastive system for HSB-DE in both directions and for unsupervised German to Lower Sorbian (DSB)translation, which uses multi-task training with various training schedules to improve the baseline.', 'he': 'In this paper, we present the systems submitted by our team from the Institute of ICT (HEIG-VD / HES-SO) to the Unsupervised MT and Very Low Resource Supervised MT task.  We first study the improvements brought to a baseline system by techniques such as back-translation and initialization from a parent model.  We find that both techniques are beneficial and suffice to reach performance that compares with more sophisticated systems from the 2020 task.  ואז אנו מציגים את ההשתמשות של המערכת הזאת למשימה של 2021 עבור משאבים נמוכים ששולטים על סורבית העליונה (HSB) לתרגום גרמני, בשני הכיוונים. Finally, we present a contrastive system for HSB-DE in both directions, and for unsupervised German to Lower Sorbian (DSB) translation, which uses multi-task training with various training schedules to improve over the baseline.'}
{'en': 'The ', 'pt': 'Os sistemas LMU Munich para a tarefa de tradução não supervisionada e de recursos muito baixos do WMT21', 'es': 'La LMU Munich Systems para la tarea de traducción sin supervisión y con muy pocos recursos de WMT21', 'ar': 'أنظمة LMU في ميونيخ لمهمة ترجمة WMT21 غير الخاضعة للإشراف وذات الموارد المنخفضة جدًا', 'fr': 'Les systèmes LMU Munich pour la tâche de traduction non supervisée WMT21 et à très faibles ressources', 'ja': 'WMT 21無監督および非常に低いリソースの翻訳タスクのためのLMUミュンヘンシステム', 'hi': 'WMT21 असुरक्षित और बहुत कम-संसाधन अनुवाद कार्य के लिए LMU म्यूनिख सिस्टम्स', 'zh': '以 WMT21 无监极低资源转易者慕尼黑 LMU 统', 'ru': 'LMU Мюнхенские системы для задачи неконтролируемого и очень малоресурсного перевода WMT21', 'ga': 'Córais München LMU do Thasc Aistriúcháin Gan Mhaoirseacht WMT21 agus Acmhainn an-Íseal', 'hu': 'Az LMU München rendszerei a WMT21 felügyeletlen és nagyon alacsony erőforrású fordítási feladathoz', 'ka': 'Name', 'it': 'I sistemi LMU di Monaco per il compito di traduzione WMT21 non supervisionato e con risorse molto ridotte', 'kk': 'WMT21 құрылмаған және өте төмен ресурстар аудару тапсырмасының LMU мюнхен жүйелері', 'mk': 'Мунхен систем на ЛМУ за ненадгледуваната и многу нискоресурсна преводна задача на WMT21', 'lt': 'München LMU sistemos, skirtos WMT21 nekontroliuojamai ir labai mažai išteklių vertimo darbui', 'el': 'Τα συστήματα LMU του Μονάχου για το έργο μετάφρασης χωρίς επιτήρηση και πολύ χαμηλών πόρων', 'ms': 'Sistem Munich LMU untuk Tugas Terjemahan WMT21 tanpa pengawasan dan Sumber Terrendah', 'mn': 'WMT21-ын LMU Мюнхен системүүд нь бага болон бага боловсролын хөгжлийн ажил', 'ml': 'WMT21 നിരീക്ഷിക്കപ്പെടാത്ത വിഭവങ്ങള്\u200d', 'pl': 'Systemy LMU Monachium dla zadań tłumaczeniowych WMT21 nienadzorowanych i bardzo niskich zasobów', 'mt': 'Is-Sistemi ta’ Munich tal-LMU għall-kompitu ta’ traduzzjoni mhux sorveljat u b’riżorsi baxxi ħafna tad-WMT21', 'ro': 'Sistemele LMU München pentru activitatea de traducere nesupravegheată și cu resurse reduse WMT21', 'sr': 'LMU Munich sistemi za WMT21 neodržavani i vrlo niski prijevod resursa', 'no': 'Name', 'si': 'Name', 'sv': 'LMU München-systemen för WMT21 som inte övervakas och kräver mycket resurser', 'so': 'LMU Munich Systems for the WMT21 Unsupervised and Very Low-Resource Translation Task', 'ta': 'WMT21 கண்காணிக்கப்படாத மற்றும் மிகவும் குறைந்த மூலம் மொழிபெயர்ப்பு பணிக்கான LMU முனைச் அமைப்புகள்', 'ur': 'Name', 'uz': 'Name', 'vi': 'Các hệ thống LMU Munich cho Nhiệm vụ Không giám sát và Dịch phụ thấp.', 'da': 'LMU München-systemerne til WMT21-oversættelsesopgaven uden overvågning og meget lav ressource', 'de': 'Die LMU München Systeme für die WMT21 unbeaufsichtigte und sehr ressourcenarme Übersetzungsaufgabe', 'hr': 'LMU Munich sustavi za WMT21 neodržavani i vrlo niski prijevod resursa', 'id': 'Sistem Munich LMU untuk Tugas Terjemahan Tak Tersupervisi dan Sangat Terrendah-Sumber WMT21', 'bg': 'Мюнхенските системи на Мюнхен за задачата за превод без надзор и с много ниски ресурси', 'ko': 'LMU 뮌헨 시스템은 WMT21의 감독이 없고 자원이 매우 낮은 번역 임무에 사용된다', 'nl': 'De LMU München-systemen voor de WMT21-vertaaltaak zonder toezicht en zeer lage resources', 'sw': 'Mfumo wa LMU Munich kwa ajili ya kazi ya Tafsiri za Rasilimali Zisizo na Kichini', 'tr': 'WMT21 nyşanlary bilen gaýd edilmedik we iň az Ressurat terjime etmek üçin LMU München Sistemleri', 'af': 'Name', 'fa': 'سیستم\u200cهای LMU Munich برای ترجمه\u200cهای WMT21 بی\u200cحفاظت و بسیار کم منابع', 'sq': 'Sistemet LMU të Muniçit për detyrën e përkthimit të burimeve të pakufishëm dhe shumë të ulët të WMT21', 'am': 'The LMU Munich Systems for the WMT21 Unsupervised and Very Low-Resource Translation Task', 'az': 'WMT21 qeyd edilməmiş və çox düşük ressurs çeviri işi üçün LMU Munich Sistemləri', 'hy': 'The LMU Munich Systems for the WMT21 Unsupervised and Very Low-Resource Translation Task', 'bs': 'LMU Munich sistemi za WMT21 neodržavani i vrlo niski prijevod resursa', 'bn': 'WMT21 অনভার্ভার করা এবং খুব কম-সম্পদ অনুবাদ করার জন্য এলএমইউ মুনিচ সিস্টেম', 'et': 'LMU M체ncheni s체steemid WMT21 j채relevalveta ja v채ga v채hese ressursiga t천lket철철 jaoks', 'cs': 'Mnichovské systémy LMU pro WMT21 bez dohledu a s velmi nízkými zdroji', 'ca': 'Els Sistemes LMU de Múnich per a la tasca de traducció no supervisada i de baix recursos del WMT21', 'fi': 'LMU Munich Systems for the WMT21 Unsupervised and very low-resource Translation Task', 'he': 'מערכות Münich LMU עבור משימה WMT21 ללא השגחה ומעוררת משאבים נמוכים מאוד', 'ha': 'KCharselect unicode block name', 'sk': 'Sistemi LMU München za prevajalsko nalogo brez nadzora in zelo nizkih virov WMT21', 'jv': 'Name', 'bo': 'WMT21 ཡི་སྐོར་མེད་པའི་LMU Munich དུས་ཚོད་ལག་ཆེན་ཡིན་པ་དང་ཐུག་ཁུངས་ཀྱི་ཆ་རྐྱེན་འདོགས་ཀྱི་ལས་ཀ་'}
{'en': 'We present our submissions to the WMT21 shared task in Unsupervised and Very Low Resource machine translation between ', 'pt': 'Apresentamos nossos envios para a tarefa compartilhada do WMT21 em tradução automática não supervisionada e com recursos muito baixos entre alemão e sérvio superior, alemão e sérvio inferior e russo e chuvash. Nossos sistemas de poucos recursos (alemão↔sérvio superior, russo↔chuvash) são pré-treinados em pares de idiomas relacionados com muitos recursos. Ajustamos esses sistemas usando os dados paralelos autênticos disponíveis e aprimoramos por retrotradução iterada. O sistema não supervisionado alemão↔Baixo sérvio é inicializado pelo melhor sistema sérvio superior e aprimorado por retrotradução iterada usando apenas dados monolíngues.', 'fr': "Nous présentons nos soumissions pour la tâche partagée WMT21 sur la traduction automatique non supervisée et à très faible ressource entre l'allemand et le haut-sorabe, l'allemand et le bas-sorabe, et le russe et le tchouvache. Nos systèmes à faibles ressources (allemand ↔ haut-sorabe, russe ↔ tchouvache) sont préformés sur des paires de langues apparentées riches en ressources. Nous affinons ces systèmes à l'aide des données parallèles authentiques disponibles et nous les améliorons par une rétro-traduction itérée. Le système allemand ↔ bas-sorabe non supervisé est initialisé par le meilleur système haut-sorabe et amélioré par une rétro-traduction itérée utilisant uniquement des données monolingues.", 'ar': 'نقدم تقديماتنا إلى مهمة WMT21 المشتركة في الترجمة الآلية غير الخاضعة للإشراف وذات الموارد المنخفضة للغاية بين الألمانية والصربية العليا والألمانية والصربية السفلى والروسية والتشوفاش. أنظمتنا منخفضة الموارد (الألمانية - الصوربية العليا ، الروسية - تشوفاش) مدربة مسبقًا على أزواج عالية الموارد من اللغات ذات الصلة. نقوم بضبط تلك الأنظمة باستخدام البيانات الموازية الأصلية المتاحة وتحسينها من خلال الترجمة العكسية المتكررة. تمت تهيئة النظام الصوربي الألماني الأدنى غير الخاضع للرقابة من قبل أفضل نظام صوربي العليا وتحسينه عن طريق الترجمة الخلفية المتكررة باستخدام البيانات أحادية اللغة فقط.', 'es': 'Presentamos nuestros envíos a la tarea compartida WMT21 en traducción automática sin supervisión y con muy pocos recursos entre alemán y alto sorabo, alemán y bajo sorabo, y ruso y chuvasio. Nuestros sistemas de bajos recursos (alemán ↔ alto sorabo, ruso ↔ chuvash) están preentrenados en pares de idiomas relacionados con muchos recursos. Ajustamos esos sistemas utilizando los datos paralelos auténticos disponibles y mejoramos mediante la retrotraducción iterada. El sistema alemán ↔ bajo sorabo sin supervisión se inicializa con el mejor sistema de sorabo superior y se mejora mediante la retrotraducción iterada utilizando solo datos monolingües.', 'ja': '私たちは、ドイツ語と上部ソルブ語、ドイツ語と下部ソルブ語、ロシア語とチュヴァシ語の間で、監督なしおよび非常に低い資源機械翻訳でWMT 21共有タスクに提出します。当社の低資源システム（ドイツ語、アッパーソルビア語、ロシア語、チュヴァシ↔語）は、高資源↔ペアの関連言語の事前トレーニングを受けています。利用可能な真正な並列データを使用してこれらのシステムを微調整し、反復翻訳によって改善します。監督されていないドイツの↔下部ソルブ語システムは、最高の上部ソルブ語システムによって初期化され、単一言語データのみを使用して反復翻訳することによって改善されます。', 'zh': '为WMT21提交,在德语上索布语,德语与下索布语及俄语、楚瓦什语之间无监督极低资源机器翻译中。 吾低资源系统(德语↔索布语,俄语↔Chuvash)预习于高言。 用可用之实并行数以微之,因迭代反译而改之。 无监督德语↔低速索布系统由上索布系统初始化,并用单语数迭代反向译改进。', 'hi': 'हम जर्मन और ऊपरी सोर्बियन, जर्मन और निचले सोर्बियन, और रूसी और चुवाश के बीच असुरक्षित और बहुत कम संसाधन मशीन अनुवाद में WMT21 साझा कार्य के लिए हमारी प्रस्तुतियाँ प्रस्तुत करते हैं। हमारे कम संसाधन प्रणालियों (GermanUpper↔Sorbian, RussianChuvash↔) संबंधित भाषाओं के उच्च संसाधन जोड़े पर पूर्व-प्रशिक्षित हैं। हम उपलब्ध प्रामाणिक समानांतर डेटा का उपयोग करके उन प्रणालियों को ठीक करते हैं और पुनरावृत्तीकृत बैक-अनुवाद द्वारा सुधार करते हैं। Unsupervised GermanLower↔Sorbian प्रणाली को सबसे अच्छी ऊपरी सोर्बियन प्रणाली द्वारा शुरू किया गया है और केवल मोनोलिंगुअल डेटा का उपयोग करके पुनरावर्ती बैक-अनुवाद द्वारा सुधार किया गया है।', 'ru': 'Мы представляем наши представления к совместной задаче WMT21 в неконтролируемом и очень низком ресурсном машинном переводе между немецким и верхним сорбским, немецким и нижним сорбским, а также русским и чувашским языками. Наши малоресурсные системы↔ (немецкий верхнесорбский, русский↔чувашский) предварительно обучены высокоресурсным парам родственных языков. Мы настраиваем эти системы, используя доступные аутентичные параллельные данные, и улучшаем их с помощью итераций обратного перевода. Неконтролируемая немецкая↔нижнесорбская система инициализируется лучшей верхнесорбской системой и улучшается путем итеративного обратного перевода с использованием только одноязычных данных.', 'ga': 'Cuirimid ár n-aighneachtaí i láthair don tasc comhroinnte WMT21 in aistriúchán meaisín Acmhainne Gan Mhaoirseacht agus An-Íseal idir Gearmáinis agus Sorbais Uachtarach, Gearmáinis agus Sorbais Íochtarach, agus Rúisis agus Suvaisis. Tá ár gcórais íseal-acmhainne (Gearmáinis↔Sorbais Uachtarach, Rúisis↔ Suvaisis) réamh-oilte ar phéirí ard-acmhainne de theangacha gaolmhara. Déanaimid mionchoigeartú ar na córais sin ag baint úsáide as na sonraí barántúla comhthreomhara atá ar fáil agus feabhsaítear iad trí ais-aistriúchán atriallach. Is é an córas Sorbais Uachtarach is fearr a thionscnaíonn an córas Gearmánach↔Íochtarach gan mhaoirseacht agus feabhsaítear é trí ais-aistriúchán atriallta ag úsáid sonraí aonteangacha amháin.', 'ka': 'ჩვენ გავაკეთებთ WMT21 გაყოფილი საქაღალდე საქაღალდე სამუშაო და მნიშვნელოვანი რესურსის მანქანის გაგრძელებაში გერმანეთი და ზემო სორბული, გერმანეთი და ქვემო სორბული, პროსია და ფუ ჩვენი დამატებული რესურსისტემა (გერმანეთი საპირო სორბიული, პროსია ფუგასი) უნდა უფრო მეტად განაკეთებულია მაღალი რესურსისტემა საერთო ენაზე. ჩვენ ამ სისტემის შესაძლებელი ავტონტიკური პარალელური მონაცემების გამოყენებით დავაკეთებთ და განახლებით განახლებით განახლებით. უკეთესი საუკეთესი სორბიული სისტემა დაიწყება და უკეთესი საუკეთესი სორბიული სისტემა დაიწყება და მხოლოდ მონოლენგური მონაცემების გამოყენებით გამოიყენება', 'el': 'Παρουσιάζουμε τις υποβολές μας στο κοινό έργο στη μηχανική μετάφραση χωρίς επιτήρηση και πολύ χαμηλούς πόρους μεταξύ γερμανικών και ανώτερων σορβικών, γερμανικών και χαμηλών σορβικών, και ρωσικών και Τσούβας. Τα συστήματα μας με χαμηλούς πόρους (Γερμανικά Άνω Σορβικά, Ρωσικά Τσούβας) είναι προ-εκπαιδευμένα σε ζεύγη συγγενών γλωσσών υψηλής περιεκτικότητας. Βελτιώνουμε αυτά τα συστήματα χρησιμοποιώντας τα διαθέσιμα αυθεντικά παράλληλα δεδομένα και βελτιώνουμε με επαναλαμβανόμενη μεταγραφή. Το σύστημα χωρίς επίβλεψη της γερμανικής Κάτω Σορβίας αρχικοποιείται από το καλύτερο σύστημα Άνω Σορβίας και βελτιώνεται με επαναληπτική μεταγραφή χρησιμοποιώντας μονογλωσσικά δεδομένα μόνο.', 'hu': 'A WMT21 megosztott feladatához benyújtott beadványainkat felügyeletlen és nagyon alacsony erőforrású gépi fordításban mutatjuk be német és felső-szorbiai, német és alsó-szorbiai, orosz és csuvász között. Alacsony erőforrású rendszereink (német felső-szorbiai, orosz csuvász) előre képzettek a rokon nyelvek nagy erőforrású párjaira. Ezeket a rendszereket finomhangoljuk a rendelkezésre álló hiteles párhuzamos adatok felhasználásával, és javítjuk az iterált visszafordítással. A felügyelet nélküli német alsó-szorbiai rendszert a legjobb felső-szorbiai rendszer inicializálja és csak egynyelvű adatokat használó ismételt fordítással javítja.', 'kk': 'Біз WMT21 ортақ тапсырманы неміс және жоғары сорб, неміс және төменгі сорб және руссия және Chuvash арасындағы өте төменгі ресурстар аудармасында көрсеткіземіз. Біздің төменгі ресурс жүйелеріміз (неміс жоғары сорб, руссия шавша) қатынастық тілдерді алдын- ала оқылған. Біз бұл жүйелерді автентификациялық параллель деректерді қолданатын және қайта аудару арқылы жақсартық. Төменгі неміс төменгі сорб жүйесі жақсы жоғары сорб жүйесінен инициализацияланады және тек монолингі деректерді қолдану арқылы қайта аудару арқылы жақсартылады.', 'it': 'Presentiamo le nostre osservazioni al compito condiviso WMT21 in traduzione automatica non controllata e molto bassa tra tedesco e sorbiano superiore, tedesco e sorbiano inferiore, russo e chuvash. I nostri sistemi a basso contenuto di risorse (tedesco Sorbiano Superiore, russo Chuvash) sono pre-formati su coppie di lingue affini ad alto contenuto di risorse. Aggiungiamo questi sistemi utilizzando i dati paralleli autentici disponibili e miglioriamo attraverso la traduzione iterata. Il sistema tedesco non supervisionato della Bassa Sorbia è inizializzato dal migliore sistema della Bassa Sorbia e migliorato dalla traduzione iterata utilizzando solo dati monolingue.', 'mk': 'Ние ги претставуваме нашите поднесувања на заедничката задача на ВМТ21 во ненадгледуван и многу ниски ресурси машински превод помеѓу германската и горната сорбијанка, германската и долната сорбијанка, и руската и Чувашката. Нашите системи со ниски ресурси (Германска Горна Сорбија, Руска Чуваша) се предобучени на парови со високи ресурси на поврзани јазици. Ги поправиме тие системи користејќи достапните автентични паралелни податоци и подобруваме со повторен превод. Ненадгледуваниот германски систем на долна Сорбија е иницијализиран од најдобриот систем на горна Сорбија и подобрен со итериран превод користејќи само монојазични податоци.', 'ms': 'Kami memperkenalkan penghantaran kami kepada tugas berkongsi WMT21 dalam terjemahan mesin Sumber Tak Disupervisi dan Sangat Rendah antara Jerman dan Sorbian Atas, Jerman dan Sorbian Bawah, dan Rusia dan Chuvash. Sistem sumber rendah kita (German Upper Sorbian, Russian Chuvash) telah dilatih pada pasangan sumber tinggi bahasa yang berkaitan. Kami memperbaiki sistem tersebut menggunakan data paralel yang sah dan meningkatkan dengan terjemahan-balik. Sistem Lower Sorbian Jerman yang tidak diawasi diawalkan oleh sistem Upper Sorbian yang terbaik dan diperbaiki oleh terjemahan-belakang berikut menggunakan data monobahasa sahaja.', 'lt': 'Mes pristatome savo pastabas WMT21 bendrai užduotims nekontroliuojamu ir labai mažų išteklių mašin ų vertimu tarp vokiečių ir aukštesnių sorbų, vokiečių ir žemųjų sorbų bei rusų ir Čuvašų. Mūsų mažai išteklių turinčios sistemos (Vokietijos viršutinsorbinė, Rusijos Čuvašas) iš anksto mokomos didelių išteklių turinčiomis susijusiomis kalbomis poromis. Mes patobuliname tas sistemas naudojant turimus autentiškus lygiagrečius duomenis ir patobuliname pakartotiniu vertimu atgal. Neprižiūrima Vokietijos apatinės sorbios sistema inicijuojama geriausia viršutinės sorbios sistema ir patobulinama pakartotiniu grįžtamuoju vertimu naudojant tik vienkalbius duomenis.', 'ml': 'ഞങ്ങള്\u200d നമ്മുടെ കീഴടങ്ങളെ വിശേഷിപ്പിക്കുന്നു. ഞങ്ങള്\u200d വ്യുഎംടി21 പങ്കാളികളുടെ ജോലിയിലേക്ക് കൊടുക്കുന്നു. നിരീക്ഷിക്കപ്പെട്ടിരിക്കുന് ഞങ്ങളുടെ കുറഞ്ഞ വിഭവങ്ങളുടെ (ജര്\u200dമ്മന്\u200d മുകളില്\u200d സോര്\u200dബിയന്\u200d, റഷ്യന്\u200d ചുവാഷ്) ഉയരത്തിലെ വിഭവങ്ങളില്\u200d ഉയര്\u200dത്തപ്പെട്ട ഭാഷകളി നമ്മള്\u200d ആ സിസ്റ്റമുകളെ ശരിയാക്കുന്ന പാരാളല്\u200d ഡേറ്റാകള്\u200d ഉപയോഗിച്ച് പിന്നീട് പരിഭാഷപ്പെടുത്തുന്നതിനാല്\u200d  സംരക്ഷിക്കപ്പെടാത്ത ജര്\u200dമ്മന്\u200d താഴ്ന്ന സോര്\u200dബിയന്\u200d സിസ്റ്റം മുകളിലെ ഏറ്റവും നല്ല സോര്\u200dബിയന്\u200d സിസ്റ്റത്താല്\u200d ആരംഭിക്കുന്നു. മോണോളി', 'pl': 'Przedstawiamy nasze zgłoszenia do wspólnego zadania WMT21 w zakresie tłumaczenia maszynowego bez nadzoru i bardzo niskiego zasobu między niemieckim i górnym sorbskim, niemieckim i dolnym oraz rosyjskim i czuwaszym. Nasze systemy niskosorbijskie (niemiecki górny sorbijski, rosyjski czuwasz) są wstępnie przeszkolone na wysokich zasobach pary języków pokrewnych. Dostosowujemy te systemy wykorzystując dostępne autentyczne dane równoległe i ulepszamy poprzez iterowane tłumaczenie wsteczne. Bez nadzoru niemiecki system dolnosorbijski jest inicjalizowany przez najlepszy system górnosorbijski i ulepszony poprzez iterowane tłumaczenie wsteczne wykorzystujące tylko dane jednojęzyczne.', 'mt': 'We present our submissions to the WMT21 shared task in Unsupervised and Very Low Resource machine translation between German and Upper Sorbian, German and Lower Sorbian, and Russian and Chuvash.  Is-sistemi tagħna b’riżorsi baxxi (il-Ġermaniż tas-Sorbja ta’ Fuq, iċ-Ċuvaż Russu) huma mħarrġa minn qabel fuq pari ta’ lingwi relatati b’riżorsi għoljin. Aħna nirranġaw dawk is-sistemi bl-użu tad-dejta parallela awtentika disponibbli u ntejbu permezz ta’ traduzzjoni ripetuta. The unsupervised German Lower Sorbian system is initialized by the best Upper Sorbian system and improved by iterated back-translation using monolingual data only.', 'no': 'Vi presenterer våre oppføringar til WMT21 delt oppgåve i Unupportert og Svært låg ressursmaskin mellom tysk og øvre sorbisk, tysk og nedersorbisk, og russisk og kyvask. Våre låg ressurssystemet (tysk øvre sorbisk, russisk čuvask) er først trent på høg ressurspar av relaterte språk. Vi setter opp dei systema med dei tilgjengelege autentiske parallelle data og forbetra ved gjentakinga av tilbakeomsetjinga. Den ukjende tyske nedsorbiske systemet er starta av den beste øvre sorbiske systemet og forbetra av gjentakinga av tilbakeomsetjinga med berre monospråk-data.', 'mn': 'Бид WMT21-д өөрсдийнхөө даалгаварыг Герман, Жерхэн Сорб, Герман, Доош Сорб, Орос болон Чуваш хоорондын машины хувьсалын тухай хуваалцаагүй ажлыг илтгэдэг. Бидний бага баялаг боловсролын систем (Герман дээд сорб, Орос Чуваш) холбоотой хэл дээр урьд сургалт авсан. Бид эдгээр системүүдийг зөв зөв параллел өгөгдлийг ашиглаж, дахин дахин дахин дахин хөгжүүлэх боломжтой болгодог. Хамгийн сайн дээд орбийн системээр Германы доош сорбийн системийг эхлүүлж, зөвхөн ганц хэл өгөгдлийг ашиглан дахин дахин дахин хөгжүүлсэн.', 'sr': 'Predstavljamo svoje podatke WMT21 zajedničkom zadatku u nepotrebnom i vrlo niskom prevodu mašine između njemačkog i gornjeg sorbijskog, njemačkog i donjeg sorbijskog, ruskog i čuvaskog. Naši niski resursni sistemi (Njemački gornji sorbijanski, ruski čuvaski) su predobučeni na par visokih resursa povezanih jezika. Mi upravljamo te sisteme koristeći dostupne autentične paralelne podatke i poboljšamo ponovnim prevodom. Nesuprotstavljeni njemački dolinski sorbijski sistem je inicijaliziran najboljim gornjem Sorbijanskom sistemom i poboljšan ponovnim prevodom samo sa monojezičkim podacima.', 'ro': 'Prezentăm lucrările noastre la sarcina comună WMT21 în traducerea automată nesupravegheată și foarte scăzută a resurselor între germană și Sorbiană Superioară, germană și Sorbiană Inferioară, rusă și Chuvash. Sistemele noastre cu resurse reduse (germană Sorbiană Superioară, rusă Chuvash) sunt pre-instruite pe perechi de limbi conexe cu resurse ridicate. Ajustăm aceste sisteme folosind datele paralele autentice disponibile și îmbunătățim prin traducerea înapoi iterată. Sistemul german nesupravegheat Sorbian Inferior este inițializat de cel mai bun sistem Sorbian Superior și îmbunătățit prin traducerea iterată înapoi folosind doar date monolingve.', 'so': 'Waxaannu soo dhiibnaa warqadeena WMT21 oo lagu qaybsan yahay Unsupervised and Very Low Resource machine translation between German and Upper Sorbian, Jarmal and Lower Sorbian, and Russian and Chuvash. nidaamkayaga hoose-resource (Jarmalka Upper Sorbian, Ruush Chuvash) waa horay loogu baran karo luqadaha sare resource badan oo kala duduwan. nidaamkaas waxaan si fiican u qoraynaa isticmaalka macluumaadka saxda ah oo la mid ah, waxaana horumarinaynaa tarjumaadka dib-tarjumaadda. Sistemada hoose ee Jarmalka ah ee Sorbiga waxaa lagu billaabiyaa nidaamka ugu fiican ee Sorbiga sare iyo waxaa lagu hagaajiyaa tarjumaadda dib-u-dhigista oo isticmaalaya macluumaadka afka oo kaliya.', 'sv': 'Vi presenterar våra bidrag till WMT21 delade uppgift i maskinöversättning med oövervakad och mycket låg resurs mellan tyska och övre sorbiska, tyska och nedre sorbiska samt ryska och chuvash. Våra lågresurssystem (tyska Övre Sorbiska, ryska Chuvash) är förberedda på högresurspar av besläktade språk. Vi finjusterar dessa system med tillgängliga autentiska parallella data och förbättrar genom itererad bakåtöversättning. Det oövervakade tyska nedre sorbiska systemet initieras av det bästa övre sorbiska systemet och förbättras genom itererad bakåtöversättning med enbart enspråkiga data.', 'si': 'අපි WMT21 එක්ක ක්\u200dරියාකාරයෙන් පෙන්වන්නේ නැහැ සහ ගොඩක් ප්\u200dරමාණයක් ජර්මන් සහ උපර සොර්බියාන්, ජර්මන් සහ පහර සොර්බියාන්, රුසියාන අපේ අඩුම සම්බන්ධ පද්ධතිය (ජර්මන් උපර සෝර්බියාන්, රුසියාන් චුවාෂ්) සම්බන්ධ භාෂාවන්ගේ අඩුම සම් අපි ඒ පද්ධතියට පුළුවන් සමාන්\u200dය දත්ත භාවිත කරන්න සහ ආයෙත් පස්සේ අවවාදය සඳහා වැඩ කරන්න. නැති ජර්මාන් නිමුණ සෝර්බියාන් පද්ධතිය පටන් ගත්තා හොඳම සෝර්බියාන් පද්ධතියෙන් හොඳම පද්ධතියෙන් පටන් ගත්තා වි', 'ur': 'ہم نے WMT21 کے ذریعے اپنے تسلیم کو مشترک کام میں پیش کیا ہے جرمن اور اوپر سوربیان، جرمن اور لائر سوربیان اور روسی اور چوووش کے درمیان بہت کم رسسور ماشین کی ترجمہ میں۔ ہمارے کم منبع سیسٹم (جرمانی اوپر سوربیان، روسی چووواش) مرتبہ زبانوں کے زیادہ منبع جوڑوں پر پیش آموزش کی جاتی ہیں۔ ہم اُن سیستموں کو پوری طرح طرح طرح کے مطابق موجود پارالی ڈیٹا کے مطابق تنظیم کر رہے ہیں اور دوبارہ تغییر کے مطابق اضافہ کر رہے ہیں. بے حفاظت جرمن لائر سوربین سیسٹم بہترین اوپر سوربین سیسٹم سے آغاز کی جاتی ہے اور صرف ایک زبان کی ڈاٹ کے مطابق دوبارہ تغییر کی جاتی ہے۔', 'ta': 'ஜெர்மன் மற்றும் மேல் சோர்பியன், ஜெர்மன்கள் மற்றும் கீழ் சோர்பியன், மற்றும் ருஷ்ஷ் மற்றும் சுவாஷ் இடையே உள்ள குறைந்த மூலம் மொழிமாற்றியில் WMT எங்கள் குறைந்த மூலங்கள் அமைப்புகள் (ஜெர்மன் மேல் சோர்பியன், ரஷ்ஷு சுவாஷ்) உயர்மூலத்தின் ஜோடி தொடர்புடைய மொழிகளில் முன்பய நாம் கிடைக்கும் அனைத்து அமைப்புகளையும் சரியாக குறிப்பிடுகிறோம் உண்மையான இணைப்பு தரவை பயன்படுத்தி மீண்டு காப்பாற்றப்படாத ஜெர்மன் கீழ் சோர்பிய அமைப்பு மேல் சிறந்த சோர்பியன் அமைப்பால் துவக்கப்பட்டது மற்றும் மோனோலிங்கால் தகவல் மட்டும்', 'uz': "Biz bir qanchalik Olmon va Yuqori Sorbiya, Olmon va pastki Sorbiy sobobi, Ruscha va Chuvash orasidagi qisqa Resource Mashinalarni WMT21 bilan birlashtirilgan vazifani ko'rsamiz. Bizning kichkina rasmlar tizimlarimiz (Olmoncha Sorbiya, Ruscha Chuvash) bir necha bog'liq tillarda o'rganishdan oldin. @ info The unsupervised German Lower Sorbian system is initialized by the best Upper Sorbian system and improved by iterated back-translation using monolingual data only.", 'vi': 'Chúng tôi xin trình bày các kiến nghị của chúng tôi về giải pháp WM đã chia sẻ nhiệm vụ trong dịch phụ thuộc tới tài nguyên nguyên vô danh và rất thấp giữa phân loại Đức và Upper Sorbian, Đức và hàm dưới, Nga và Chuvash. Hệ thống ít tài nguyên (chỉ số lượng lớn của Đức, Chuvash Nga) được đào tạo trước các cặp tài nguyên cao của ngôn ngữ liên quan. Chúng tôi chỉnh sửa những hệ thống đó bằng các dữ liệu song song đức và cải tiến bằng phiên bản lại. Hệ thống bậc thấp thấp của Đức không được giám sát, được khởi tạo bởi hệ thống phân loại Upper và cải tiến bằng cách lặp lại phiên bản, chỉ sử dụng dữ liệu ngôn ngữ.', 'hr': 'Predstavljamo svoje podatke WMT21 zajedničkom zadatku u nepotrebnom i vrlo niskom prevodu mašine između njemačkog i gornjeg sorbijskog, njemačkog i doljeg sorbijskog i ruskog i čuvaskog. Naši sustavi niskih resursa (Njemački gornji sorbijanski, ruski čuvaski) su predobučeni na par visokih resursa povezanih jezika. Mi upravljamo te sustave koristeći dostupne autentične paralelne podatke i poboljšavamo ponovnim prevodom. Nesuprotstavljeni njemački dolinski sorbijski sustav inicijalizira najbolji gornji Sorbijski sustav i poboljšava se ponovnim prevodom samo jednojezičkim podacima.', 'da': 'Vi præsenterer vores indlæg til WMT21 delte opgave i maskinoversættelse uden overvågning og meget lav ressource mellem tysk og øverste sorbisk, tysk og nederste sorbisk samt russisk og chuvash. Vores lav-ressource systemer (tysk øversorbisk, russisk chuvash) er præ-trænede på høj-ressource par af beslægtede sprog. Vi finjusterer disse systemer ved hjælp af de tilgængelige autentiske parallelle data og forbedrer ved itereret back-translation. Det uudviklede tyske Niedersorbiske system initialiseres af det bedste Øversorbiske system og forbedres ved itereret back-oversættelse udelukkende ved hjælp af ensprogede data.', 'bg': 'Представяме нашите предложения за съвместната задача по машинен превод без надзор и много нисък ресурс между немски и горно сорбийски, немски и долно сорбийски, руски и чуваш. Нашите нискоресурсни системи (немски горносорбийски, руски чуваш) са предварително обучени на високоресурсни двойки сродни езици. Ние фино настройваме тези системи, използвайки наличните автентични паралелни данни и подобряваме чрез итерационен обратен превод. Неконтролираната низорбийска система е инициализирана от най-добрата горносорбийска система и подобрена чрез итерационен обратен превод, използващ само едноезични данни.', 'nl': 'We presenteren onze inzendingen aan de gedeelde WMT21 taak in onbeheerde en zeer lage resource machinevertaling tussen Duits en Opper-Sorbisch, Duits en Neder-Sorbisch, en Russisch en Tsjovash. Onze low-resource systemen (Duits Oppersorbisch, Russisch Tsjouwash) zijn vooraf getraind op high-resource paren van verwante talen. We verfijnen die systemen met behulp van de beschikbare authentieke parallelle gegevens en verbeteren deze door iteratieve back-translation. Het Duitse Nedersorbische systeem zonder toezicht wordt geïnitialiseerd door het beste Bovensorbische systeem en verbeterd door iteratieve back-translation met alleen eentalige gegevens.', 'de': 'Wir präsentieren unsere Beiträge zur gemeinsamen Aufgabe WMT21 in der maschinellen Übersetzung ohne Aufsicht und mit sehr geringen Ressourcen zwischen Deutsch und Obersorbisch, Deutsch und Niedersorbisch sowie Russisch und Tschuwaschisch. Unsere ressourcenarmen Systeme (Deutsch Obersorbisch, Russisch Tschuwaschisch) sind auf ressourcenintensive Paare verwandter Sprachen vortrainiert. Wir optimieren diese Systeme mit den verfügbaren authentischen parallelen Daten und verbessern sie durch iterierte Rückübersetzung. Das unbeaufsichtigte deutsche Niedersorbische System wird durch das beste obersorbische System initialisiert und durch iterierte Rückübersetzung mit nur einsprachigen Daten verbessert.', 'fa': 'ما تحویل\u200cهای خود را به وظیفه\u200cای مشترک WMT21 در ترجمه دستگاه\u200cهای ناحفاظت و بسیار کم منابع بین آلمان و سوربیان بالا، آلمان و سوربیان پایین و روسیه و چوواش پیشنهاد می\u200cکنیم. سیستم\u200cهای کمترین منابع ما (سوربیان بالا آلمان، چوواش روسی) در جفت منابع بالا از زبانهای ارتباط پیش آموزش داده شده\u200cاند. ما این سیستم\u200cها را با استفاده از داده\u200cهای پارالی واقعی موجود تنظیم می\u200cکنیم و توسط ترجمه\u200cهای پشتیبانی دوباره بهبود می\u200cکنیم. سیستم سوربیان پایین آلمانی غیرقابل تحریک توسط بهترین سیستم سوربیان بالا آغاز می\u200cشود و توسط ترجمه پشتیبانی دوباره با استفاده از داده\u200cهای تنها یک زبان بهبود می\u200cشود.', 'sw': 'Tunawasilisha ujumbe wetu kwa kazi zetu za WMT21 zilizoshirikishwa katika utafsiri wa mashine ya rasilimali zisizo na kipungu kati ya Kijerumani na Sorbia Kuu, Kijerumani na KiSorbia wa chini, na Urusi na Chuvash. Mfumo wetu wa rasilimali zisizo chini (Kijerumani wa Sorbia Kuu, Kirusi wa Urusi) unafundishwa kabla kwa lugha zilizohusiana na rasilimali za juu. Tunafunga vizuri mifumo hiyo kwa kutumia taarifa zilizopatikana za uhalisia na kuboresha kwa tafsiri zilizotengenezwa. Mfumo wa Sorbia wa Kijerumani wa chini usio na uhakika ulioanzishwa na mfumo bora wa Sorbia wa Juu na umeboreshwa na tafsiri iliyotengenezwa kwa kutumia takwimu za lugha za kiutamaduni tu.', 'id': 'Kami mempersembahkan pengiriman kami ke WMT21 tugas berbagi dalam terjemahan mesin sumber daya yang tidak diawasi dan sangat rendah antara Jerman dan Upper Sorbian, Jerman dan Lower Sorbian, dan Rusia dan Chuvash. Sistem sumber daya rendah kita (German Upper Sorbian, Russian Chuvash) sudah dilatih pada pasangan sumber daya tinggi bahasa yang berhubungan. Kami memperbaiki sistem tersebut menggunakan data paralel autentik yang tersedia dan memperbaiki dengan terjemahan kembali. Sistem Lower Sorbian Jerman yang tidak diawasi diinisialisasikan oleh sistem Upper Sorbian terbaik dan diperbaiki oleh terjemahan kembali iterasi menggunakan data monobahasa saja.', 'ko': '우리는 WMT21 공유 임무에 독일어와 상소포어, 독일어와 하소포어, 러시아어와 큐바시어 사이에 감독이 없고 자원이 매우 낮은 기계 번역을 하는 보고서를 제출했다.우리의 저자원 시스템(독일어에서 소포어, 러시아어 Chuvash)은 관련 언어의 높은 자원에 대해 사전에 교육한 것이다.우리는 사용할 수 있는 실제 병렬 데이터를 사용하여 이 시스템을 미세하게 조정하고, 반복적인 역번역을 통해 개선합니다.감독이 없는 독일어 하소포 시스템은 최상의 상소포 시스템에서 초기화되었고, 단어 데이터만 사용하는 교체 번역을 통해 개선되었다.', 'sq': 'Ne paraqesim dorëzimet tona në detyrën e përbashkët të WMT21-së në përkthimin e makinerisë së Pambikqyrur dhe me burime shumë të ulta midis gjermanisë dhe sorbikes së lartë, gjermanisë dhe sorbikes së poshtme dhe ruse dhe chuvash. Sistemet tona me burime të ulëta (Sorbian e Lartë gjerman, Chuvash rus) janë të stërvitur në dy gjuhë të lidhura me burime të larta. We fine-tune those systems using the available authentic parallel data and improve by iterated back-translation.  Sistemi gjerman i ulët sorbik i pa mbikqyrur inicializohet nga sistemi më i mirë sorbik i lartë dhe përmirësohet nga përkthimi i përsëritur prapa duke përdorur vetëm të dhënat monogjuhësore.', 'tr': "WMT21'a gönderilen rugsatlarymyzy alman we üst-sorbça, nemesçe we aşak sorbça we Rusça we çuwaş bilen birleşmegimizde ylalaşýarlar. Biziň iň az resursy sistemamyz (Almança üst-sorbisce, rusça çuwaş) üst-çeşme bilimlerde birnäçe çeşmeler üçin öňünde bilim alýarlar. Biz bu sistemleri meňzeş parallel maglumatlary ulanyp ýene düzeldirip, we yzyna terjime edilen terjime görä düzeldiris. Iň sumalanmaýan Almança Ast Sorbi sistemasy diňe monodil maglumatlaryny ulanan iň gowy serbi sistemasy tarapyndan başlanýar we täze terjime edilmegi bilen geliştirilýär.", 'am': 'በጀርመን እና ላይኛይቱ ሶርቢያ፣ ጀርመን እና ታችኛይቱ ሶርቢያ፣ ሮሽኛ እና ታችኛይቱ ሶርቢያ እና ሩሽኛ እና ሹዋሽ መካከል የተካፈሉት ስራዎችን ወደ WMT21 በተካፈሉ እናቀርባለን፡፡ Our low-resource systems (German Upper Sorbian, Russian Chuvash) are pre-trained on high-resource pairs of related languages.  የሥርዓት ተርጓሚዎችን በመጠቀም እናሳድጋለን፡፡ ያልጠበቀው የጀርመን ዝቅተኛ ሶርቢ ስርዓት ከሁሉ በላይ ሶርቢያ ሲስተም የተጀመረ ነው፤ በሞሎልቋል ዳታ ብቻ የተጠቃሚ የጀርባ ትርጓሜ ተርጓም ነው፡፡', 'af': 'Ons stel ons ondersteunings aan die WMT21 deel opdrag in Onondersteunde en Baie Lae Hulpbron Masjien vertaling tussen Duits en Boonste Sorbiese, Duits en Laaier Sorbiese en Russiese en Chuvasse. Ons lae hulpbron stelsels (Duitse bo-Sorbiese, Russiese Chuvash) word vooraf opgelei op hoë-hulpbron paar van verwante tale. Ons fin-tuneer dié stelsels deur die beskikbaar authentiese parallele data te gebruik en verbeter deur iterateerde terugvertaling. Die onverondersteunde Duitse Laai Sorbiese stelsel word geïnisialiseer deur die beste Boonste Sorbiese stelsel en verbeter deur iterateerde terugvertaling deur slegs monolinglike data te gebruik.', 'hy': 'Մենք ներկայացնում ենք մեր ներկայացումները ԱՄԹ21-ի ընդհանուր առաջադրանքին անվերահսկված և շատ ցածր ռեսուրսների մեքենայի թարգմանման միջև գերմանացի և վերևի սորբյան, գերմանացի և ցածր սորբյան, Ռուսաստանի և Չուվասի միջև: Մեր ցածր ռեսուրսների համակարգերը (գերմանացի բարձր սորբյան, ռուս շվաշի) նախապատրաստված են բարձր ռեսուրսների զույգերի հետ կապված լեզուների վրա: Մենք բարելավում ենք այդ համակարգերը օգտագործելով հասանելի իրական զուգահեռ տվյալները և բարելավում ենք կրկնվող թարգմանման միջոցով: Անվերահսկված գերմանացի ցածր սորբյան համակարգը սկզբում է լավագույն վերևի սորբյան համակարգը և բարելավվում է կրկնվող ետնաթարգմանման միջոցով միայն միալեզվով տվյալներ:', 'bn': 'জার্মান এবং উপরের সোর্বিয়ান, জার্মান এবং নিচের সোর্বিয়ান, রুশ এবং চুভাশের মধ্যে আমাদের উইমটি২১ বিভাগে শেয়ার কর্মসূচির প্রতি আমাদের উপস্থাপন কর আমাদের কম সম্পদ ব্যবস্থা (জার্মান সোর্বিয়ান, রাশিয়ান চুভাশ) উচ্চ সম্পদের জোড়ায় সম্পর্কিত ভাষায় প্রশিক্ষিত। আমরা সেই সিস্টেম ব্যবহার করি প্রকৃত প্যারেল ডাটা ব্যবহার করে এবং ব্যাক-অনুবাদের দ্বারা উন্নত করি। সংরক্ষিত জার্মানী নিচের সোরবিয়ান সিস্টেম শুরু করা হয়েছে সর্বোচ্চ সোর্বিয়ান সিস্টেম এবং শুধুমাত্র মোনোলিভাল ডাটা ব্যবহার করে', 'bs': 'Predstavljamo svoje podatke WMT21 zajedničkom zadatku u nepotrebnom i vrlo niskom prevodu mašine između njemačkog i gornjeg sorbijskog, njemačkog i donjeg sorbijskog, ruskog i čuvaskog. Naši niski resursni sustavi (Njemački gornji sorbijanski, ruski čuvaski) su predobučeni na par visokih resursa povezanih jezika. Mi upravljamo te sisteme koristeći dostupne autentične paralelne podatke i poboljšavamo ponovnim prevodom. Nesuprotstavljeni njemački nižarski sustav inicijalizira najbolji gornji Sorbijski sustav i poboljšava ponovnim prevodom samo jednojezičkim podacima.', 'ca': 'Presentam les nostres presentacions a la tasca compartida de WMT21 en traducció de màquines sense supervisió i de recursos molt baixos entre alemanya i sorbia superior, alemanya i sorbia inferior, russa i chuvash. Els nostres sistemes de baix recursos (sorbia superior alemanya, chuvash russo) estan pré-entrenats en parells de llengües relacionades amb molts recursos. Afinem aquests sistemes fent servir les dades paralleles autèntiques disponibles i millorem repetidament. The unsupervised German Lower Sorbian system is initialized by the best Upper Sorbian system and improved by iterated back-translation using monolingual data only.', 'cs': 'Představujeme naše příspěvky na společný úkol WMT21 v oblasti strojového překladu bez dohledu a velmi nízkých zdrojů mezi němčinou a hornosorbštinou, němčinou a dolnosorbštinou a ruštinou a čuvašštinou. Naše systémy s nízkými zdroji (německá hornosorbština, ruská čuvaš) jsou předškoleny na vysoce zdrojové páry příbuzných jazyků. Tyto systémy doladíme pomocí dostupných autentických paralelních dat a zlepšujeme iterovaným zpětným překladem. Bez dozoru německý dolensorbský systém je inicializován nejlepším horensorbským systémem a vylepšen iterovaným zpětným překladem pouze s použitím jednojzyčných dat.', 'fi': 'Esitämme WMT21:n yhteisen tehtävän valvomattomassa ja erittäin vähäresurssisessa konekäännöksessä saksan ja yläsorbian, saksan ja alemman sorbian sekä venäjän ja tšuvashin välillä. Vähävaraiset järjestelmämme (saksan yläsorbian, venäjän tševašin) ovat esikoulutettuja korkean resurssin kielipareille. Tarkennamme näitä järjestelmiä käyttämällä saatavilla olevaa autenttista rinnakkaisdataa ja parannamme niitä iteroidulla takaisinkäännöksellä. Valvontaton alemman sorbiankielinen järjestelmä on alustettu parhaalla yläsorbiankielisellä järjestelmällä ja parannettu iteroidulla takakäännöksellä käyttäen vain yksikielistä dataa.', 'et': 'Esitleme oma ettepanekuid WMT21 ühisele ülesandele järelevalveta ja väga vähese ressursiga masintõlke valdkonnas saksa ja Ülem-Sorbia, saksa ja Alam-Sorbia ning vene ja tšuvaši vahel. Meie madala ressursiga süsteemid (saksa Ülemsorbiini, vene tšuvaš) on eelnevalt koolitatud kõrge ressursiga seotud keelte paaridele. Me täpsustame neid süsteeme, kasutades olemasolevaid autentseid paralleelseid andmeid ja parandame itereeritud tagasitõlke abil. Järelevalveta saksa alamsorbia süsteem on initsialiseeritud parima Ülemsorbia süsteemi poolt ja täiustatud itereeritud tagasitõlkega, kasutades ainult ühekeelseid andmeid.', 'az': 'Biz WMT21 vəzifələrimizi Alman, Yuxarı Sorbi, Alman, Aşağı Sorbi, Rus və Chuvash arasındakı çox düşük ressurs makinesi ilə birlikdə paylaşır. Bizim düşük kaynaqlar sistemimiz (Almanca Üst Sorbi, Rus Çuvası) çox yüksək kaynaqlar çift dillərinə öyrənmişdir. Biz bu sistemləri həqiqət paralel məlumatları istifadə edir və yenidən təkrar çevirilən təkrarları ilə yaxşılaşdırırıq. Ən yüksək Sorbi sistemi ilə müəyyən edilməmiş Almanca aşağı Sorbi sistemi başlanğıçlandırılır və yalnız monodil verilər vasitəsilə yenidən təkrar çevirilməsi ilə daha yaxşı təkrar edilir.', 'ha': "Tuna halatar da musuluntu zuwa the WMT21 share in Uncontrolled and Very Low Resource Machine translation between Jarman and Upper Sorbian, Jarman and Lower Sorbian, and Ruush and Chuva. Our low-resource systems (German ↔ @ item Spelling dictionary ↔ @ info: whatsthis Tuna gyarawa masu tsari da za'a iya amfani da data masu inganci da gaskiyar, kuma za'a samar da abun-translation @ item Spelling dictionary ↔ @ item Text character set", 'he': "אנחנו מציגים את ההעברות שלנו למשימה המשותפת של WMT21 בתרגום מכונת משאבים לא מפקחת ומאוד נמוכה בין גרמנית וסורבית העליונה, גרמנית וסורבית נמוכה, ורוסית וצ'וואש. Our low-resource systems (German ↔ סורבית העליונה, רוסית ↔ צ'וואש) מאומנים מראש על זוגות משאבים גבוהים של שפות קשורות. אנחנו מתאימים את המערכות האלה באמצעות המידע המזומן האנטיקטי הנוכחי ומשתפר על ידי התרגום המחזור. הגרמנים הלא משגיחים ↔ מערכת סורבית נמוכה מתחילה על ידי מערכת הסורבית העליונה הטובה ביותר ושתפוררת על ידי תרגום מאחור מחדש באמצעות נתונים מונושפתיים בלבד.", 'jv': 'Awak dhéwé éntuk kamuh sing berarti ning WWT 1, lan ijol-ijolan karo pakem karo perusahaan kanggo kelas teljamahan karo Pak Karo Jupêr-Sarbian, aleman karo perusahaan-suarbian lan Russish lan Cuvas. Sistem-sistem sing paling-alas (German) ↔ Name ↔ checkbox Awak dhéwé ngerti sistem sing paling-sistem kuwi nggawe dadi tanggal sing berarti dadi sing perusahaan karo nggawe tarjamahan. German kuwi ora bisa ngejaraké ↔ Ngucap Berbi sing ditambah akeh sistem sing dibutuhke Berbi sing dibutuhke sistem Berbi sing luwih apik lan mbukakipun ciptaaken mulai terus-terus kanggo gambar data Monlenggal.', 'bo': 'ང་ཚོས་WMT21 ལ་མཉམ་དུ་སྔོན་སྒྲིག་མེད་པའི་ལས་འགན་གཉིས་ཀྱི་ནང་དུ་ཆ་མཐུན་རྐྱེན་བྱས་མེད་པའི་ནང་གི་ ང་ཚོའི་རྒྱུ་ཆས་པ་ཆུང་དུ་ཉེན་མཁན་གྱི་མ་ལག་ ↔ རྒྱལ་པོ་སོ་རི་ཡཱན། རྒྱ་ནག ↔ འོད་ཀྱང་། ཅུ་vash(Chuvash)ནི་སྐྱེས་ཆུང་དང་འབྲེལ་བའི་སྐད་རིགས་མཐོ་ཁག་གི་ཆ་རྐྱེན་སྔོན་བསྒྲིག་ཡོད། ང་ཚོས་ལག་ཆ་དངོས་ཐུག་གི་བདེན་བཤད་ཀྱི་ཆ་འཕྲིན་ཡིག་ཆ་སྤྱོད་བཞིན་པའི་མ་ལག་དེ་སྒྲིག་འཇུག་བྱེད་ཀྱི་ཡོད། སྣང་མེད་ཉར་གསོ་མེད་པའི་ཇར་མན། ↔ འོག་ཏུ་འོག་མའི་སོ་རིས་མ་ལག་དེ་གིས་མཐོ་བའི་སྒོ་ལས་རིགས་དུ་འགོ་འཛུགས་བྱེད་པ་དང་རང་ཉིད་ཀྱི་རྒྱབ་སྐྱོར་མིང་ལ་ཡར་བསྐྱེད', 'sk': 'Predstavljamo naše prispevke k skupni nalogi WMT21 v strojnem prevajanju brez nadzora in zelo nizkih virov med nemščino in zgornjo sorbijščino, nemščino in spodnjo sorbijščino ter ruščino in čuvaščino. Naši sistemi z nizkimi viri (nemščina) ↔ Zgornji sorbijski, ruski ↔ Čuvaš) so predhodno usposobljeni za pare z visokimi viri sorodnih jezikov. Te sisteme natančno nastavimo z uporabo razpoložljivih pristnih vzporednih podatkov in izboljšamo s ponovitvijo nazaj prevajanja. Nenadzorovan Nemec. ↔ Spodnji sorbijski sistem je inicializiran z najboljšim zgornjisorbijskim sistemom in izboljšan z iteriranim nazaj prevodom z uporabo samo enojezičnih podatkov.'}
{'en': 'cushLEPOR : customising hLEPOR metric using Optuna for higher agreement with human judgments or pre-trained language model LaBSE', 'es': 'CushLePor: personalización de la métrica HLEPor con Optuna para un mayor acuerdo con los juicios humanos o el modelo de lenguaje preentrenado LabSE', 'ar': 'cushLEPOR: تخصيص مقياس hLEPOR باستخدام Optuna لاتفاق أعلى مع الأحكام البشرية أو نموذج اللغة المدربة مسبقًا LaBSE', 'fr': "CushLePor\xa0: personnalisation de la métrique HLEpor à l'aide d'Optuna pour une meilleure concordance avec les jugements humains ou le modèle de langage pré-formé LabSE", 'pt': 'cushLEPOR: customizando a métrica hLEPOR usando Optuna para maior concordância com julgamentos humanos ou modelo de linguagem pré-treinado LaBSE', 'zh': 'cushLEPOR:用 Optuna 自定义 hLEPOR 指标,以合人伦之言 LaBSE', 'ru': 'cushLEPOR: настройка метрики hLEPOR с использованием Optuna для более высокого согласия с человеческими суждениями или предварительно обученной языковой модели LaBSE', 'ja': 'cushLEPOR ：人間の判断または事前にトレーニングされた言語モデルLaBSEとのより高い合意のために、Optunaを使用してhLEPORメトリックをカスタマイズする', 'hi': 'cushLEPOR: मानव निर्णय या पूर्व प्रशिक्षित भाषा मॉडल LaBSE के साथ उच्च समझौते के लिए Optuna का उपयोग कर hLEPOR मीट्रिक को अनुकूलित करना', 'ga': 'cushLEPOR: méadrach hLEPOR a shaincheapadh ag baint úsáide as Optuna chun comhaontú níos fearr a dhéanamh le breithiúnais dhaonna nó samhail teanga réamhoilte LaBSE', 'ka': 'cushLEPOR: hLEPOR მეტრიკის შესაძლებლობა Optuna- ის გამოყენება ადამიანის შესაძლებლობისთვის ან წინასწარმოადგენებული ენის მოდელი LaBSE', 'el': 'Προσαρμογή της μετρικής με χρήση του Optuna για μεγαλύτερη συμφωνία με ανθρώπινες κρίσεις ή προσχεδιασμένο γλωσσικό μοντέλο', 'hu': 'cushLEPOR: a hLEPOR metrika testreszabása Optuna segítségével az emberi ítéletekkel való jobb megegyezés érdekében vagy az előkészített nyelvi modell LaBSE', 'it': 'cushLEPOR: personalizzazione della metrica hLEPOR utilizzando Optuna per un maggiore accordo con i giudizi umani o modello linguistico pre-addestrato LaBSE', 'lt': 'cushLEPOR: pritaikyti hLEPOR metriką naudojant Optuna, kad būtų geriau pritarta žmogaus sprendimams arba iš anksto parengtam kalbos modeliui LaBSE', 'mk': 'cushLEPOR: customising hLEPOR metric using Optuna for higher agreement with human judgments or pre-trained language model LaBSE', 'kk': 'cushLEPOR: Оптуна арқылы адамдардың тұхбаттаулары немесе алдын- оқылған тіл үлгісін LaBSE үлгісімен қатынау үшін hLEPOR метрикалығын баптау', 'ml': 'cushLEPOR: customising hLEPOR metric using Optuna for higher agreement with human judgments or pre-trained language model LaBSE', 'mt': 'cushLEPOR: l-adattament tal-metrika hLEPOR bl-użu ta’ Optuna għal qbil ogħla ma’ sentenzi umani jew mudell lingwistiku mħarreġ minn qabel LaBSE', 'mn': 'cushLEPOR: Хүн төрөлхтний шүүмжлэг эсвэл өмнө сургалтын хэл загвартай илүү өндөр зохицуулалт хийх Optuna-г ашиглаж hLEPOR метрийг өөрчлөх', 'no': 'cushLEPOR: tilpassar hLEPOR-metrisk bruk Optuna for høgare samtale med menneske sprøytebrukar eller før-treng språk-modell LaBSE', 'pl': 'cushLEPOR: dostosowanie metryki hLEPOR przy użyciu Optuna dla lepszej zgodności z ludzkimi osądami lub wstępnie przeszkolonym modelem językowym LaBSE', 'si': 'CuhLEPOR: මිනිස්සු නිරීක්ෂණය සහා ප්\u200dරධානය කරපු භාෂා මොඩේල් LaBSE සමඟ ප්\u200dරමාණය සඳහා Optuna භාවිතා hLEPOR මෙට්\u200dරික', 'ro': 'cushLEPOR: personalizarea metricii hLEPOR folosind Optuna pentru un acord mai mare cu judecatile umane sau modelul lingvistic pre-instruit LaBSE', 'ms': 'cushLEPOR: menyesuaikan metrik hLEPOR menggunakan Optuna untuk persetujuan yang lebih tinggi dengan penilaian manusia atau model bahasa terlatih-terlatih LaBSE', 'sr': 'cushLEPOR: prilagođenje metrike hLEPOR koristeći Optunu za veći sporazum sa ljudskim osuđivanjima ili predobučenim jezičkim modelom LaBSE', 'so': 'cushLEPOR: isticmaalka HLEPOR metric using Optuna si aad heshiis sare ugu heshiiso xukummada dadka ama model afka hore oo la tababaray LaBSE', 'sv': 'cushLEPOR: Anpassa hLEPOR-metriken med Optuna för högre samstämmighet med mänskliga bedömningar eller färdigutbildad språkmodell LaBSE', 'ta': 'உயர் ஒப்டுனாவை பயன்படுத்தும் HLEPOR மெட்ரிக் தனிப்பயனாக்குகிறது மனித விதிப்புகளுடன் அல்லது முன் பயிற்சி மொழி மாதிரி LaBSE', 'ur': 'cushLEPOR: hLEPOR متریک کو اپنا فیصلہ کرنے کے لئے اوپٹونا کے مطابق مطابق کر رہا ہے اور انسان کے فیصلے یا پہلے تربین کی زبان موڈل لاBSE کے ساتھ', 'vi': 'Dù là ai đi nữa, cũng có thể thay đổi định hướng lưu lượng hLEE POR để có thể đạt được quyết định con người hoặc là mô hình ngôn ngữ', 'uz': 'cushLEPOR: Optuna yordamida yuqori heshima uchun hLEPOR metric moslash', 'nl': 'cushLEPOR: aanpassing van de hLEPOR metric met Optuna voor een betere overeenstemming met menselijke oordelen of voorgetrainde taalmodel LaBSE', 'da': 'cushLEPOR: Tilpasning af hLEPOR metric ved hjælp af Optuna til højere overensstemmelse med menneskelige vurderinger eller forududdannet sprogmodel LaBSE', 'de': 'cushLEPOR: Anpassung der hLEPOR-Metrik mit Optuna für eine höhere Übereinstimmung mit menschlichen Urteilen oder vortrainiertem Sprachmodell LaBSE', 'id': 'cushLEPOR: menyesuaikan metrik hLEPOR menggunakan Optuna untuk kesepakatan yang lebih tinggi dengan penilaian manusia atau model bahasa terlatih LaBSE', 'hr': 'cushLEPOR: prilagođenje metrike hLEPOR koristeći Optunu za viši sporazum s ljudskim osuđivanjima ili predobučenim jezičkim modelom LaBSE', 'fa': 'cushLEPOR: با استفاده از Optuna متریک hLEPOR برای توافق بالاتر با قضاوت انسان یا مدل پیش آموزش زبانی LaBSE', 'bg': 'Персонализиране на метриката с помощта на Оптуна за по-високо съответствие с човешките преценки или предварително обучен езиков модел', 'ko': 'cushLEPOR: Optuna를 사용하여 hLEPOR 메트릭을 사용자 정의하여 인간의 판단이나 사전 훈련에 더욱 부합되는 언어 모델 LabSE', 'sw': 'cushLEPOR: customising hLEPOR metric using Optuna for higher agreement with human judgments or pre-trained language model LaBSE', 'sq': 'cushLEPOR: personalizimi i metrikës hLEPOR duke përdorur Optuna për marrëveshje më të lartë me gjykimet njerëzore apo modelin e gjuhës së paratrajnuar LaBSE', 'af': 'cushLEPOR: Pasmaak hLEPOR metrie met Optuna vir hoër ooreenkoms met menslike oordelings of vooraf-opgelei taal model LaBSE', 'tr': 'cushLEPOR: ýokary adatça ýa öňlerde bilinmiş dil nusgasy üçin Optuna üýtgetmek üçin hLEPOR metri ullanýar', 'hy': 'Comment', 'am': 'cushLEPOR: HLEPOR metric using Optuna for higher agreement with humane ፍርዶች or pre-trained language model LaBSE', 'az': 'cushLEPOR: İnsan hökmləri və əvvəlcə təhsil edilmiş dil modeli LaBSE ilə yüksək anlaşma üçün Optuna vasitəsilə hLEPOR metrini təhsil etmək', 'bn': 'কাস্লিপোর্ট: মানবিচার বা পূর্ব প্রশিক্ষিত ভাষার মডেল লাবিসের সাথে উচ্চ চুক্তি ব্যবহার করার জন্য এইচলিপোর মেট্রিক ব্যবহা', 'bs': 'cushLEPOR: prilagođenje metrike hLEPOR koristeći Optunu za viši sporazum sa ljudskim osuđivanjima ili predobučenim jezičkim modelom LaBSE', 'cs': 'cushLEPOR: přizpůsobení metriky hLEPOR pomocí Optuna pro vyšší shodu s lidskými úsudky nebo předškoleným jazykovým modelem LaBSE', 'et': 'cushLEPOR: hLEPOR mõõdiku kohandamine Optuna abil, et saavutada parem kooskõla inimese otsustega või eelõpetatud keelemudeliga LaBSE', 'fi': 'cushLEPOR: hLEPOR-mittarin mukauttaminen Optunan avulla paremman yhteensopivuuden saavuttamiseksi ihmisten arviointien kanssa tai ennalta koulutetun kielimallin LaBSE avulla', 'ca': 'cushLEPOR: personalitzar la mètrica hLEPOR utilitzant Optuna per acordar més amb els judicis humans o el model lingüístic pré-entrenat LaBSE', 'ha': 'QUnicodeControlCharacterMenu', 'jv': 'peru', 'bo': 'cushLEPOR: customising hLEPOR metric using Optuna for higher agreement with human judgments or pre-trained language model LaBSE', 'sk': 'cushLEPOR: prilagajanje merilnika hLEPOR z Optunom za boljše skladnost s človeškimi presojami ali vnaprej usposobljenim jezikovnim modelom LaBSE', 'he': 'cushLEPOR: מתאים מטריקה hLEPOR באמצעות אופטונה להסכם גבוה יותר עם שיפוטים אנושיים או מודל שפה מאומן מראש LaBSE'}
{'en': 'Human evaluation has always been expensive while researchers struggle to trust the ', 'ar': 'لطالما كان التقييم البشري مكلفًا بينما يكافح الباحثون من أجل الوثوق بالمقاييس التلقائية. لمعالجة هذا الأمر ، نقترح تخصيص المقاييس التقليدية من خلال الاستفادة من نماذج اللغة المدربة مسبقًا (PLM) والنتائج البشرية ذات العلامات المحدودة المتاحة. قمنا أولاً بإعادة تقديم العوامل المترية hLEPOR ، متبوعًا بإصدار Python الذي طورناه (تم نقله) والذي حقق الضبط التلقائي لمعلمات الترجيح في مقياس hLEPOR. ثم نقدم hLEPOR (cushLEPOR) المخصص الذي يستخدم إطار تحسين Optuna للمعامل الفائق لضبط معلمات ترجيح hLEPOR نحو اتفاق أفضل على نماذج اللغة المدربة مسبقًا (باستخدام LaBSE) فيما يتعلق بأزواج لغة MT الدقيقة التي يتم نشر cushLEPOR فيها. نقوم أيضًا بتحسين cushLEPOR نحو بيانات التقييم البشري الاحترافية بناءً على إطار عمل MQM و pSQM على أزواج اللغتين الإنجليزية والألمانية والصينية والإنجليزية. تُظهر التحقيقات التجريبية أن cushLEPOR تعزز أداء hLEPOR نحو اتفاقيات أفضل مع PLMs مثل LABSE بتكلفة أقل بكثير ، واتفاقيات أفضل للتقييمات البشرية بما في ذلك درجات MQM و pSQM ، وتنتج أداءً أفضل بكثير من BLEU. تظهر النتائج الرسمية أن عروضنا فازت بثلاث أزواج لغوية بما في ذلك الإنجليزية-الألمانية والصينية-الإنجليزية على نطاق الأخبار عبر cushLEPOR (LM) والإنجليزية-الروسية على نطاق TED عبر hLEPOR. (البيانات متاحة على https://github.com/poethan/cushLEPOR)', 'fr': "L'évaluation humaine a toujours été coûteuse alors que les chercheurs ont du mal à faire confiance aux métriques automatiques. Pour y remédier, nous proposons de personnaliser les mesures traditionnelles en tirant parti des modèles linguistiques préformés (PLM) et des scores labellisés humains disponibles limités. Nous réintroduisons d'abord les facteurs métriques HLEPOR, puis la version Python que nous avons développée (portée) qui a réalisé le réglage automatique des paramètres de pondération dans la métrique HLEPOR. Ensuite, nous présentons le HLEPOR personnalisé (CushLePor) qui utilise le framework d'optimisation des hyperparamètres Optuna pour affiner les paramètres de pondération HLEPOR afin de mieux s'accorder avec les modèles de langage pré-entraînés (à l'aide de LabSE) concernant les paires de langues MT exactes sur lesquelles CushLePor est déployé. Nous optimisons également CushLepor vers des données d'évaluation humaine professionnelles basées sur le cadre MQM et PSqM sur les paires de langues anglais-allemand et chinois-anglais. Les études expérimentales montrent que CushLePor augmente les performances de HLEPOR vers de meilleurs accords avec des PLM tels que LABSE avec un coût bien inférieur, et de meilleurs accords avec les évaluations humaines, y compris les scores MQM et PSQM, et donne des performances bien meilleures que BLEU. Les résultats officiels montrent que nos soumissions gagnent trois paires de langues, dont l'anglais-allemand et le chinois-anglais sur le domaine News via CushLePor (LM) et l'anglais-russe sur le domaine TED via HLEPOR. (données disponibles à l'adresse https://github.com/poethan/cushLEPOR)", 'es': 'La evaluación humana siempre ha sido costosa, mientras que los investigadores luchan por confiar en las métricas automáticas. Para hacer frente a esto, proponemos personalizar las métricas tradicionales aprovechando los modelos lingüísticos (PLM) preentrenados y las limitadas puntuaciones disponibles con etiqueta humana. Primero reintroducimos los factores métricos HLEPor, seguidos de la versión de Python que desarrollamos (portamos) que logró el ajuste automático de los parámetros de ponderación en la métrica HLEPor. A continuación, presentamos el HLEPor personalizado (CushLePor) que utiliza el marco de optimización de hiperparámetros de Optuna para ajustar los parámetros de ponderación de HLEPor con el fin de lograr una mejor conformidad con los modelos de lenguaje previamente entrenados (utilizando LabSE) con respecto a los pares de idiomas MT exactos en los que se implementa CushLePor. También optimizamos CushLepor para obtener datos de evaluación humana profesional basados en el marco MQM y PSqM en las combinaciones de idiomas inglés-alemán y chino-inglés. Las investigaciones experimentales muestran que CushLePor mejora el rendimiento de HLEPor hacia mejores acuerdos con PLM como LABSE con un coste mucho menor, y mejores acuerdos con evaluaciones humanas, incluidas las puntuaciones de MQM y PSqM, y produce rendimientos mucho mejores que BLEU. Los resultados oficiales muestran que nuestras presentaciones ganan tres pares de idiomas, incluidos inglés-alemán y chino-inglés en el dominio News a través de CushLePor (LM) e inglés-ruso en el dominio TED a través de HLePor. (datos disponibles en https://github.com/poethan/cushLEPOR)', 'pt': 'A avaliação humana sempre foi cara, enquanto os pesquisadores lutam para confiar nas métricas automáticas. Para resolver isso, propomos personalizar as métricas tradicionais, aproveitando os modelos de linguagem pré-treinados (PLMs) e as pontuações limitadas disponíveis por humanos. Primeiro, reintroduzimos os fatores da métrica hLEPOR, seguidos pela versão Python que desenvolvemos (portada) que alcançou o ajuste automático dos parâmetros de ponderação na métrica hLEPOR. Em seguida, apresentamos o hLEPOR personalizado (cushLEPOR) que usa a estrutura de otimização de hiperparâmetros Optuna para ajustar os parâmetros de ponderação do hLEPOR para uma melhor concordância com os modelos de linguagem pré-treinados (usando LaBSE) em relação aos pares de idiomas MT exatos nos quais o cushLEPOR é implantado. Também otimizamos o cushLEPOR para dados de avaliação humana profissional com base na estrutura MQM e pSQM em pares de idiomas inglês-alemão e chinês-inglês. As investigações experimentais mostram que o cushLEPOR aumenta o desempenho do hLEPOR para melhores acordos com PLMs como LABSE com custo muito menor e melhores acordos com avaliações humanas, incluindo pontuações MQM e pSQM, e produz desempenhos muito melhores do que BLEU. Os resultados oficiais mostram que nossos envios ganham três pares de idiomas, incluindo inglês-alemão e chinês-inglês no domínio News via cushLEPOR(LM) e inglês-russo no domínio TED via hLEPOR. (dados disponíveis em https://github.com/poethan/cushLEPOR)', 'hi': 'मानव मूल्यांकन हमेशा महंगा रहा है जबकि शोधकर्ता स्वचालित मीट्रिक पर भरोसा करने के लिए संघर्ष करते हैं। इसे संबोधित करने के लिए, हम पूर्व-प्रशिक्षित भाषा मॉडल (पीएलएम) और सीमित उपलब्ध मानव लेबल स्कोर का लाभ उठाकर पारंपरिक मीट्रिक को अनुकूलित करने का प्रस्ताव करते हैं। हम पहले hLEPOR मीट्रिक कारकों को फिर से पेश करते हैं, इसके बाद पायथन संस्करण हमने विकसित किया (पोर्ट किया गया) जिसने hLEPOR मीट्रिक में भार पैरामीटर की स्वचालित ट्यूनिंग प्राप्त की। फिर हम अनुकूलित hLEPOR (cushLEPOR) प्रस्तुत करते हैं जो ऑप्टुना हाइपर-पैरामीटर ऑप्टिमाइज़ेशन फ्रेमवर्क का उपयोग करता है ताकि पूर्व-प्रशिक्षित भाषा मॉडल (LaBSE का उपयोग करके) के लिए बेहतर समझौते की दिशा में hLEPOR भार पैरामीटर को ठीक किया जा सके। हम MQM और अंग्रेजी-जर्मन और चीनी-अंग्रेजी भाषा जोड़े पर pSQM ढांचे के आधार पर पेशेवर मानव मूल्यांकन डेटा की ओर cushLEPOR को भी अनुकूलित करते हैं। प्रयोगात्मक जांच से पता चलता है कि cushLEPOR बहुत कम लागत के साथ LABSE जैसे PLMs के लिए बेहतर समझौतों की ओर hLEPOR प्रदर्शन को बढ़ाता है, और MQM और pSQM स्कोर सहित मानव मूल्यांकन के लिए बेहतर समझौते, और BLEU की तुलना में बहुत बेहतर प्रदर्शन करता है। आधिकारिक परिणामों से पता चलता है कि हमारी प्रस्तुतियां hLEPOR के माध्यम से TED डोमेन पर cushLEPOR (LM) और अंग्रेजी-रूसी के माध्यम से समाचार डोमेन पर अंग्रेजी-जर्मन और चीनी-अंग्रेजी सहित तीन भाषा जोड़े जीतती हैं। (https://github.com/poethan/cushLEPOR पर उपलब्ध आंकड़े)', 'ja': '人間の評価は常に高価であり、研究者は自動指標を信頼することに苦労しています。 これに対処するために、事前にトレーニングされた言語モデル（ PLM ）と利用可能な限られた人間のラベル付きスコアの利点を利用して、従来の指標をカスタマイズすることを提案します。 まず、hLEPORメトリック係数を再導入し、次に、hLEPORメトリックの重み付けパラメータの自動チューニングを実現したPythonバージョンを開発しました（移植）。 次に、カスタマイズされたhLEPOR （ cushLEPOR ）を提示します。これは、オプトゥーナのハイパーパラメータ最適化フレームワークを使用して、hLEPORの重み付けパラメータを微調整し、cushLEPORが展開される正確なMT言語ペアに関して、事前に訓練された言語モデル（ LaBSEを使用）とのより良い合意に向けて調整します。 また、英語とドイツ語、中国語と英語のペアに関するmqmおよびpSQMフレームワークに基づいて、プロフェッショナルな人間の評価データに向けてcushLEPORを最適化します。 実験的調査によると、cushLEPORは、コストがはるかに低いLABSEのようなPLMへのより良い合意、mqmおよびpSQMスコアを含むヒト評価へのより良い合意に向けてhLEPORのパフォーマンスを向上させ、BLEUよりもはるかに優れたパフォーマンスをもたらすことが示されています。 公式の結果によると、当社の応募作品は、ニュースドメインの英語-ドイツ語と中国語-英語を含む3つの言語ペアを、hLEPORを介して、TEDドメインのcushLEPOR （ LM ）と英語-ロシア語を介して獲得できます。（データはhttps://github.com/poethan/cushLEPORから入手できます）', 'zh': '人工评价素贵,而治人难信指标。 凡此诸事,以预训之言(PLM)有限者,以人工纪分数为指标。 先入 hLEPOR 指标因子,次发(移植) Python 版本,当得 hLEPOR 指标中加权参数自调优。 然后言自定义之 hLEPOR(cushLEPOR),用 Optuna 超参数优化框架以微 hLEPOR 加权参数,以善与豫教之言(用 LaBSE)一,以定 cushLEPOR MT 言。 又据MQM、pSQM框架,英语 - 德语、中文 - 英语言语优化cushLEPOR业人料数。 实验研明,cushLEPOR增hLEPOR之性,使与LABSE等PLM达成之议,成本欲低得多,而与MQMpSQM分数在内之人评成其协,而胜于BLEU性多矣。 官方结果显示,三言而cushLEPOR(LM),新闻域英语 - 德语中文 - 英语 - 英语 - 英语与中文 - 英语 - 俄语HLEPOR于TED域。 (数据见 https://github.com/poethan/cushLEPOR)', 'ru': 'Человеческая оценка всегда была дорогостоящей, в то время как исследователи пытались доверять автоматическим метрикам. Для решения этой проблемы мы предлагаем адаптировать традиционные метрики, используя преимущества предварительно обученных языковых моделей (PLMS) и ограниченные доступные оценки, помеченные человеком. Сначала мы повторно вводим метрические коэффициенты hLEPOR, а затем разработанную (портированную) версию Python, которая достигла автоматической настройки параметров взвешивания в метрике hLEPOR. Затем мы представляем индивидуализированный hLEPOR (cushLEPOR), который использует фреймворк оптимизации гиперпараметров Optuna для точной настройки параметров взвешивания hLEPOR для лучшего согласования с предварительно обученными языковыми моделями (с использованием LaBSE) в отношении точных языковых пар MT, к которым применяется cushLEPOR. Мы также оптимизируем cushLEPOR к профессиональным данным оценки человека на основе MQM и pSQM фреймворка на англо-немецких и китайско-английских языковых парах. Экспериментальные исследования показывают, что cushLEPOR повышает производительность hLEPOR к лучшим соглашениям с PLM, такими как LABSE, с гораздо более низкой стоимостью и лучшими соглашениями с оценками человека, включая оценки mqm и pSQM, и дает гораздо лучшие характеристики, чем BLEU. Официальные результаты показывают, что наши заявки выигрывают три языковые пары, включая английско-немецкий и китайско-английский в домене новостей через cushLEPOR(LM) и английско-российский в домене TED через hLEPOR. (данные доступны по адресу https://github.com/poethan/cushLEPOR)', 'ga': "Bhí meastóireacht dhaonna costasach i gcónaí agus taighdeoirí ag streachailt le muinín a bheith acu as méadracht uathoibríoch. Chun aghaidh a thabhairt air seo, tá sé beartaithe againn méadracht thraidisiúnta a shaincheapadh trí bhuntáistí a bhaint as na samhlacha teanga réamhoilte (PLManna) agus na scóir teoranta lipéadaithe daonna atá ar fáil. Ar dtús déanaimid na fachtóirí méadrachta hLEPOR a thabhairt isteach arís, agus an leagan Python a d'fhorbair muid (ported) ina dhiaidh sin a bhain amach tiúnadh uathoibríoch na bparaiméadar ualaithe i méadrach hLEPOR. Ansin cuirimid an hLEPOR (cushLEPOR) saincheaptha i láthair a úsáideann creat optamaithe hyper-paraiméadar Optuna chun paraiméadair ualaithe hLEPOR a mhionchoigeartú i dtreo comhaontú níos fearr ar mhúnlaí teanga réamhoilte (ag baint úsáide as LaBSE) maidir leis na péirí teanga MT cruinn a bhfuil cushLEPOR imscaradh chucu. Déanaimid barrfheabhsú freisin ar cushLEPOR i dtreo sonraí meastóireachta daonna gairmiúla bunaithe ar chreat MQM agus pSQM ar phéirí Béarla-Gearmáinis agus Sínis-Béarla. Léiríonn na himscrúduithe turgnamhacha go neartaíonn cushLEPOR feidhmíochtaí hLEPOR i dtreo comhaontuithe níos fearr le PLManna cosúil le LABSE le costas i bhfad níos ísle, agus comhaontuithe níos fearr ar mheastóireachtaí daonna lena n-áirítear scóir MQM agus pSQM, agus torthaí i bhfad níos fearr feidhmíochta ná BLEU. Léiríonn torthaí oifigiúla go bhfuil trí phéire teanga buaite ag ár n-aighneachtaí lena n-áirítear Béarla-Gearmáinis agus Sínis-Béarla ar fhearann Nuacht trí cushLEPOR(LM) agus Béarla-Rúisis ar fhearann TED trí hLEPOR. (sonraí ar fáil ag https://github.com/poethan/cushLEPOR)", 'ka': 'ადამიანის განსაზღვრება ყოველთვის ძალიან ძალიან ძალიან, როდესაც მსწავლობელი ძალიან გაგრძელებენ ავტომატური მეტრიკაში. ამის შესახებ, ჩვენ მინდომავთ დავაკეთოთ ტრადიციონალური მეტრიკის შესახებ, რომელიც უნდა გავაკეთოთ წავლის მოდელების (PLMs) და ადამიანის შესახებ მნიშვნელოვანი მოდელები ჩვენ პირველი შევცვალოთ hLEPOR მეტრიკური ფაქტორების შემდეგ Python ვერსიის შემდეგ, რომელიც hLEPOR მეტრიკში ავტომატური შემდეგ გავაკეთეთეთ. შემდეგ ჩვენ განსაზღვრული hLEPOR (cushLEPOR), რომელიც გამოყენებს Optuna ჰიპერ-პარამეტრის ოპტიმიზაციის ფრამეტრის, რომელიც hLEPOR-ის გარჩენების პარამეტრების შესაძლებელად უფრო მუშაობით მსგავსისწორებაში საუკეთესო ენის მოდელების (LaBSE ჩვენ ასევე პროფეციალური ადამიანის განსაზღვრების მონაცემების პროფეციალურ მონაცემებისთვის, რომელიც MQM და pSQM ფრამეტური ინგლისურ-გერმანური და ჩინგლისური-ან ექსპერიმენტიური პასუხები აჩვენებენ, რომ კოსპორი იქნება hLEPOR გამოსახულებების შესაძლებელად, როგორც LABSE-თან უკეთესი შესაძლებელებებისთვის, და უკეთესი შესაძლებელებები ადამიანის განსახულებებისთვის, როგორც MQM და ჲტთუთალური წარმოდგენები აჩვენებენ, რომ ჩვენი წარმოდგენება სამი ენის ზოგები, включая ინგლისური-გერმანური და ჩინგლისური-ინგლისური ნუზების დიომინზე, კუქLEPOR(LM) და ინგლი (მონაცემები ხელმისაწარმოდგენა https://github.com/poethan/cushLEPOR )', 'it': "La valutazione umana è sempre stata costosa mentre i ricercatori faticano a fidarsi delle metriche automatiche. Per affrontare questo problema, proponiamo di personalizzare le metriche tradizionali sfruttando i modelli linguistici pre-formati (PLM) e i punteggi limitati disponibili con etichetta umana. Per prima cosa reintroduciamo i fattori metrici hLEPOR, seguiti dalla versione Python che abbiamo sviluppato (ported) che ha ottenuto la messa a punto automatica dei parametri di ponderazione nella metrica hLEPOR. Poi presentiamo il customized hLEPOR (cushLEPOR) che utilizza Optuna hyper-parameters optimization framework per ottimizzare i parametri di ponderazione hLEPOR verso un migliore accordo con modelli linguistici pre-addestrati (utilizzando LaBSE) per quanto riguarda le coppie linguistiche MT esatte a cui cushLEPOR è distribuito. Ottimizzamo inoltre cushLEPOR verso dati di valutazione umana professionali basati su MQM e pSQM su coppie di lingue inglese-tedesco e cinese-inglese. Le indagini sperimentali mostrano che CUSHLEPOR migliora le prestazioni di hLEPOR verso accordi migliori con PLM come LABSE con costi molto inferiori, e migliori accordi con valutazioni umane tra cui punteggi MQM e pSQM, e produce prestazioni molto migliori rispetto a BLEU. I risultati ufficiali mostrano che i nostri contributi vincono tre coppie linguistiche tra cui inglese-tedesco e cinese-inglese sul dominio News via cushLEPOR(LM) e inglese-russo sul dominio TED via hLEPOR. (dati disponibili all'indirizzo https://github.com/poethan/cushLEPOR )", 'hu': 'Az emberi értékelés mindig drága volt, miközben a kutatók nehezen bíznak az automatikus mutatókban. Ennek megoldása érdekében a hagyományos mutatók testreszabását javasoljuk, kihasználva az előképzett nyelvi modelleket (PLM) és a korlátozott, emberi jelöléssel ellátott pontszámokat. Először ismét bemutatjuk a hLEPOR metrikus tényezőket, majd az általunk kifejlesztett Python verzió (portált), amely a hLEPOR metrikus súlyozási paraméterek automatikus hangolását érte el. Ezután bemutatjuk a testreszabott hLEPOR (cushLEPOR), amely Optuna hiperparaméter optimalizálási keretrendszert használ a hLEPOR súlyozási paramétereinek finomhangolására, hogy jobban megegyezzünk az előképzett nyelvmodellekkel (LaBSE használatával) a pontos MT nyelvpárokkal, amelyekre a cushLEPOR telepítve van. Továbbá optimalizáljuk a cushLEPOR professzionális emberi értékelési adatokat az angol-német és kínai-angol nyelvpárokra vonatkozó MQM és pSQM keretrendszer alapján. A kísérleti vizsgálatok azt mutatják, hogy a LEPOR növeli a hLEPOR teljesítményét olyan PLM-ekkel, mint a LABSE, sokkal alacsonyabb költséggel, és jobb megállapodásokat biztosít az emberi értékelésekhez, beleértve az MQM és pSQM pontszámokat, és sokkal jobb teljesítményt eredményez, mint a BLEU. Hivatalos eredmények azt mutatják, hogy pályázataink három nyelvpárt nyertek, köztük angol-német és kínai-angol a Hírek domainen keresztül a cushLEPOR(LM) és angol-orosz a TED domainen keresztül a hLEPOR. (a következő címen rendelkezésre álló adatok: https://github.com/poethan/cushLEPOR )', 'kk': 'Адам бағалауы әрқашан бағатты, зерттеушілер автоматты метрикаға сену үшін күреседі. Бұл жағдайда қатынау үшін, әдетті метрикаларды баптау үшін алдыңғы тіл үлгілерін (PLMs) және адамдардың белгілерін шектеу үшін қолданамыз. Біз біріншіден hLEPOR метрикалық факторларын қайта таңдап, hLEPOR метрикалық өлшемі параметрлерін автоматты түрде баптауға жеткіздік. Содан кейін, Оптуна гипер параметрлерді оптимизациялау фреймін қолданатын hLEPOR бағалау параметрлерін алдын- ала оқылған тіл үлгілеріне (LaBSE қолданатын) жақсы келістіру үшін қолданатын hLEPOR параметрлерін таңдау үшін таңдайды. Мұндай-ағылшын-неміс және қытайлық-ағылшын тілдер екеуіне негізделген MQM және pSQM қоршауына негізделген адамдардың оқу деректеріне көшірмелейміз. Тәжірибелікті зерттеулерде, көп бағатты LABSE секілді PLMs-ге жақсы келесімдерді көтеру үшін hLEPOR жұмысын көтереді, және MQM және pSQM нәтижелерін қоса, адамдардың оқиғаларының жақсы келесімдерін көтереді, және BL Ақпаратты нәтижелер біздің жіберіміздің ағылшын-неміс және қытайлық-ағылшын доменінде, TED доменінде cushLEPOR(LM) және ағылшын-руссиялық тіл доменінде hLEPOR арқылы үш тіл екі же (деректер бар https://github.com/poethan/cushLEPOR )', 'el': 'Η ανθρώπινη αξιολόγηση ήταν πάντα δαπανηρή, ενώ οι ερευνητές αγωνίζονται να εμπιστευτούν τις αυτόματες μετρήσεις. Για να αντιμετωπιστεί αυτό, προτείνουμε να προσαρμόσουμε τις παραδοσιακές μετρήσεις αξιοποιώντας τα προ-εκπαιδευμένα γλωσσικά μοντέλα και τις περιορισμένες διαθέσιμες βαθμολογίες με ανθρώπινη σήμανση. Πρώτα εισάγουμε εκ νέου τους μετρικούς συντελεστές και ακολουθούμε την έκδοση που αναπτύξαμε (μεταφέρθηκε) η οποία επιτυγχάνει τον αυτόματο συντονισμό των παραμέτρων στάθμισης στη μετρική. Στη συνέχεια, παρουσιάζουμε το προσαρμοσμένο πλαίσιο βελτιστοποίησης υπερπαραμέτρων Optuna για την Feinabstimmung παραμέτρων στάθμισης hLEPOR προς καλύτερη συμφωνία με προ-εκπαιδευμένα γλωσσικά μοντέλα (χρησιμοποιώντας LaBSE) σχετικά με τα ακριβή ζεύγη γλωσσών ΜΤ στα οποία αναπτύσσεται το cushLEPOR. Βελτιστοποιούμε επίσης τα δεδομένα επαγγελματικής αξιολόγησης του ανθρώπου με βάση το πλαίσιο για ζεύγη αγγλικής-γερμανικής και κινέζικης-αγγλικής γλώσσας. Οι πειραματικές έρευνες δείχνουν ότι το cushLEPOR ενισχύει τις επιδόσεις του προς καλύτερες συμφωνίες με PLMs όπως το LABSE με πολύ χαμηλότερο κόστος, και καλύτερες συμφωνίες σε ανθρώπινες αξιολογήσεις συμπεριλαμβανομένων των βαθμολογιών MQM και pSQM, και αποδίδει πολύ καλύτερες επιδόσεις από το BLEU. Τα επίσημα αποτελέσματα δείχνουν ότι οι αιτήσεις μας κερδίζουν τρία γλωσσικά ζεύγη, μεταξύ των οποίων Αγγλικά-Γερμανικά και Κινέζικα-Αγγλικά στον τομέα ειδήσεων μέσω του και Αγγλικά-Ρωσικά στον τομέα TED μέσω του hLEPOR. (στοιχεία διαθέσιμα στο https://github.com/poethan/cushLEPOR )', 'lt': 'Žmogaus vertinimas visada buvo brangus, o mokslininkai stengiasi pasitikėti automatiniais rodikliais. Siekdami išspręsti šį klausimą, siūlome pritaikyti tradicinius metrinius rodiklius, pasinaudodami iš anksto parengtais kalbų modeliais (PLM) ir ribotais turimais žmogaus pažymėtais rezultatais. Pirmiausia iš naujo įvedame hLEPOR metrinius veiksnius, po to parengėme (portuojame) Python versiją, kuri automatiškai pritaikė kLEPOR metrinius svorio parametrus. Tuomet pristatysime pritaikytą hLEPOR (cushLEPOR), kuris naudoja Optuna hiperparatorių optimizavimo sistemą, kad tiksliau pritaikytų hLEPOR svorio parametrus, kad būtų geriau suderinti su iš anksto parengtais kalbos modeliais (naudojant LaBSE), susijusiais su tiksliomis MT kalbos poromis, kurioms naudojamas cushLEPOR. Mes taip pat optimizuojame cushLEPOR siekiant profesionalių žmogaus vertinimo duomenų, grindžiamų MQM ir pSQM sistema anglų-vokiečių ir kinų-anglų kalbų poromis. Eksperimentiniai tyrimai rodo, kad cushLEPOR didina hLEPOR rezultatus siekiant geresnių susitarimų su PLM, pavyzdžiui, LABSE, su kur kas mažesnėmis sąnaudomis, ir geresnių susitarimų su žmogaus vertinimais, įskaitant MQM ir pSQM rezultatus, ir duoda daug geresnių rezultatų nei BLEU. Oficialūs rezultatai rodo, kad mūsų pasiūlymai laimi tris kalbų poras, įskaitant anglų, vokiečių ir kinų anglų kalbas žinių domene per cushLEPOR(LM) ir anglų ir rusų kalbas TED domene per hLEPOR. (duomenys pateikiami https://github.com/poethan/cushLEPOR )', 'ml': 'മനുഷ്യരുടെ വില വില വിലയുണ്ടായിരുന്നു. അന്വേഷിക്കുന്നവര്\u200d സ്വയം മെട്രിക്കുകളെ വിശ്വസിക്കാന്\u200d പോരാടുന ഇതിനെ വിശദീകരിക്കാന്\u200d ഞങ്ങള്\u200d പ്രൊദ്ദേശിക്കുന്നു, മുന്\u200dപരിശീലിക്കപ്പെട്ട ഭാഷ മോഡലുകള്\u200d ഉപയോഗപ്പെടുത്തുന്നതും ലഭ്യമായ മനുഷ്യന്\u200d ലേ നമ്മള്\u200d ആദ്യം ഹെലിപോര്\u200d മെറ്റിക് കാര്യങ്ങള്\u200d പരിചയപ്പെടുത്തുന്നു, പിന്നീട് നമ്മള്\u200d നിര്\u200dമ്മിച്ച പൈത്തോന്\u200d പതിപ്പിന്\u200dറെ (പോര്\u200dട്ടെടുത്തി) പിന പിന്നീട് നമ്മള്\u200d സ്വകാര്യമായ ഹെലിപോര്\u200dട്ട് ഹൈപ്പര്\u200d പരാമീറ്റര്\u200d ഫ്രെയിമെറ്റ് ഉപയോഗിക്കുന്ന ഹെലിപ്പോര്\u200d എംക്യൂഎം, പിഎസ്ക്യൂഎം, ഇംഗ്ലീഷ്- ജര്\u200dമ്മന്\u200d, ചൈനീസ്-ഇംഗ്ലീഷ് ഇംഗ്ലീഷ് ഇംഗ്ലീഷ് ഇംഗ്ലീഷ് ഇംഗ്ലീഷ് ഇംഗ പരീക്ഷണത്തിന്\u200dറെ അന്വേഷണങ്ങള്\u200d കുശ്ലീപോര്\u200d ലാബെസിയെപ്പോലുള്ള നല്ല കരാറുകള്\u200dക്ക് വേണ്ടി ഉത്തമമായി പിലെപ്പോര്\u200d പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രദര്\u200dശിപ്പിക്കുന്നത് കാണിക്കുന്നു.  ഓഫീസല്\u200d ഫലങ്ങള്\u200d കാണിക്കുന്നത് നമ്മുടെ കീഴ്പെടുത്തിയ മൂന്നു ഭാഷ ജര്\u200dമ്മനികളും ചൈനീസ് ഇംഗ്ലീഷിലെ ഇംഗ്ലീഷുകളും കുശ്ലെപ്പോര്\u200dര്\u200d (LM) മു (data available at  https://github.com/poethan/cushLEPOR )', 'mk': 'Human evaluation has always been expensive while researchers struggle to trust the automatic metrics.  За да се реши ова, предлагаме да се прилагодат традиционалните метрики со искористување предности од предобучените јазички модели (ПЛМ) и ограничените достапни човечки оценки. Прво повторно ги воведуваме метричките фактори на hLEPOR, по кои следи питонската верзија која ја развивме (портиравме) која ја постигна автоматското прилагодување на параметрите на тежина во hLEPOR метричка. Потоа го претставуваме прилагодениот hLEPOR (cushLEPOR) кој ја користи рамката за оптимизација на хипер-параметрите на Optuna за финетизирање на параметрите за тежина hLEPOR кон подобар договор со предобучените јазички модели (користејќи LaBSE) во врска со точните MT јазички парови на кои се распоредува cushLEPOR. Ние, исто така, оптимизираме cushLEPOR кон професионални податоци за човечка проценка базирани на MQM и pSQM рамка за парови англиско-германски и кинеско-англиски јазик. Експерименталните истраги покажуваат дека cushLEPOR ги зголемува резултатите на hLEPOR кон подобри договори за PLM како ЛАБСЕ со многу пониски цени, и подобри договори за човечките проценки, вклучително и MQM и pSQM резултати, и дава многу подобри резултати од BLEU. Официјалните резултати покажуваат дека нашите поднесувања добиваат три пара јазици вклучувајќи англиско-германски и кинески-англиски на доменот News преку cushLEPOR( LM) и англиско-руски на доменот TED преку hLEPOR. (податоци достапни на https://github.com/poethan/cushLEPOR )', 'mn': 'Хүн төрөлхтний үнэлгээ үргэлж үнэтэй байсан ч судлаачид автоматик метрикийг итгэхэд хичээдэг. Үүнийг хэлэхэд бид уламжлалт метрикийг дасгал хөгжүүлэхэд урд сургалтын хэл загваруудын ашиг ашиглаж, хязгаарлагдсан хүн төрөлхтний тэмдэглэгдсэн тоонуудыг ашиглаж хувиргаж байна. Эхлээд бид hLEPOR метрийн хүчин зүйлсийг дахин танилцуулж, hLEPOR метрийн жингийн параметрыг автоматжуулан хөгжүүлсэн (хадгалагдсан) Python хувилбарыг дахин танилцуулж байна. Дараа нь бид Optuna гипер-параметр сайхан хангамжийг ашигладаг hLEPOR жингийн параметрлүүдийг илүү хөгжүүлэх хэл загваруудыг (LaBSE хэрэглэж) илүү сайхан хангамжийг ашигладаг hLEPOR хэл загваруудыг ашиглаж байна. Мөн бид үүнийг мэргэжлийн хүний үнэлгээ өгөгдлийг MQM болон pSQM-ын англи-Герман болон Хятад-Англи хэл хоёр дээр багтана. Судалгааны судалгаа нь HLEPOR нь LABSE шиг илүү бага үнэ цэнэтэй PLMs-тэй илүү зөвшөөрөл байгууллагуудыг дэвшүүлдэг ба MQM болон pSQM оноо, хүний үнэлгээнд илүү зөвшөөрөл байгууллагуудыг дэвшүүлдэг. Шинэ үндсэн үр дүнд бидний хэл хэлний хооронд англи-Герман, Хятад-Англи хэлний хамт мэдээллийн холбоонд cushLEPOR(LM) болон Англи-Орос хэлний холбоотой холбоотой гэдгийг харуулдаг. (өгөгдлийг ашиглах https://github.com/poethan/cushLEPOR )', 'mt': 'L-evalwazzjoni tal-bniedem dejjem kienet għalja filwaqt li r-riċerkaturi qed ibatu biex jafdaw il-metriċi awtomatiċi. Biex nindirizzaw dan, nipproponu li l-metriċi tradizzjonali jiġu adattati billi jittieħdu l-vantaġġi tal-mudelli lingwistiċi mħarrġa minn qabel (PLMs) u l-punteġġi limitati disponibbli bit-tikketta tal-bniedem. L-ewwel introduċejna mill-ġdid il-fatturi metriċi hLEPOR, segwiti mill-verżjoni Python li żviluppajna (portajna) li kisbet l-aġġustament awtomatiku tal-parametri tal-ippeżar fil-metrika hLEPOR. Imbagħad nippreżentaw l-hLEPOR personalizzat (cushLEPOR) li juża l-qafas għall-ottimizzazzjoni tal-parametri iperparatteristiċi tal-Optuna biex itaffi l-parametri tal-ippeżar tal-hLEPOR lejn qbil aħjar mal-mudelli lingwistiċi mħarrġa minn qabel (bl-użu tal-LaBSE) fir-rigward tal-pari MT eżatti tal-lingwa li għalihom jintuża l-cushLEPOR. Aħna nistabbilizzaw ukoll il-cushLEPOR lejn dejta professjonali ta’ evalwazzjoni umana bbażata fuq il-qafas MQM u pSQM dwar pari lingwistiċi Ingliż-Ġermaniż u Ċiniż-Ingliż. L-investigazzjonijiet sperimentali juru li cushLEPOR jagħti spinta lill-prestazzjonijiet ta’ hLEPOR lejn ftehimiet aħjar għal PLMs bħal LABSE bi spiża ħafna aktar baxxa, u ftehimiet aħjar għal evalwazzjonijiet umani inklużi l-punteġġi MQM u pSQM, u jagħti prestazzjonijiet ħafna aħjar minn BLEU. Official results show that our submissions win three language pairs including English-German and Chinese-English on News domain via cushLEPOR(LM) and English-Russian on TED domain via hLEPOR.  (data available at  https://github.com/poethan/cushLEPOR )', 'no': 'Menneske evaluering har alltid vært dyp mens forskere kjem til å stola på automatiske metrikar. For å handtera dette, foreslår vi å tilpassa tradisjonelle metrikar ved å bruka fordelene av dei først trengte språk- modelane (PLMs) og dei begrensede menneskelige merkelige poeng. Vi introduserer først hLEPOR-metriske faktorene på nytt, etterfølgt av Python-versjonen vi utvikla (portert) som oppnådd automatisk oppsett av vekkingsprogrammene i hLEPOR-metriske. Så presenterer vi den tilpassa hLEPOR (cushLEPOR) som brukar Optuna-hyper-parameter optimaliseringsrammeverket for å finne opp hLEPOR-vekteringsparametrar mot bedre samtale til først trengte språk-modeller (med LaBSE) om nøyaktige MT-språk-par som cushLEPOR er utført til. Vi optimaliserer også cushLEPOR mot profesjonale menneskelige evalueringsdata basert på MQM og pSQM-rammeverk på engelsk-tysk og kinesisk-engelsk språk par. Eksperimentale undersøkingar viser at cushLEPOR styrer hLEPOR-utføringar mot bedre avtaler til PLMs som LABSE med mykje mindre kostnad, og bedre avtaler til menneske evalueringar inkludert MQM og pSQM-poeng, og gjer mykje bedre utføringar enn BLEU. Ofisielle resultater viser at våre innslag vinner tre språkparar, inkludert engelsk-tysk og kinesisk-English på News domain via cushLEPOR(LM) og English-Russian på TED domain via hLEPOR. (data tilgjengeleg ved https://github.com/poethan/cushLEPOR )', 'pl': 'Ocena ludzka zawsze była kosztowna, podczas gdy naukowcy borykają się z zaufaniem do automatycznych wskaźników. Aby temu rozwiązać, proponujemy dostosowanie tradycyjnych wskaźników poprzez wykorzystanie wstępnie przeszkolonych modeli językowych (PLM) i ograniczonych dostępnych wyników oznaczonych przez człowieka. Najpierw ponownie wprowadzamy czynniki metryczne hLEPOR, a następnie opracowaną przez nas wersję Pythona (portowaną), która osiągnęła automatyczne dostrojenie parametrów wagowych w metryce hLEPOR. Następnie przedstawiamy spersonalizowany system hLEPOR (cushLEPOR), który wykorzystuje framework optymalizacji hiperparametrów Optuna do dostosowania parametrów ważenia hLEPOR w celu lepszego zgodności z wstępnie przeszkolonymi modelami językowymi (z wykorzystaniem LaBSE) w odniesieniu do dokładnych par językowych MT, do których wdrażany jest cushLEPOR. Optymalizujemy również cushLEPOR w kierunku profesjonalnych danych oceny człowieka opartych na ramach MQM i pSQM na parach językowych angielsko-niemieckich oraz chińsko-angielskich. Badania eksperymentalne wykazały, że cushLEPOR zwiększa wydajność hLEPOR w kierunku lepszych porozumień z PLM, takimi jak LABSE, przy znacznie niższych kosztach oraz lepszych porozumieniach z ocenami ludzkimi, w tym wynikami MQM i pSQM, i daje znacznie lepsze wyniki niż BLEU. Oficjalne wyniki pokazują, że nasze zgłoszenia zdobywają trzy pary językowe, w tym angielsko-niemiecki i chińsko-angielski w domenie News za pośrednictwem cushLEPOR(LM) oraz angielsko-rosyjski w domenie TED za pośrednictwem hLEPOR. (dane dostępne pod adresem https://github.com/poethan/cushLEPOR )', 'ro': 'Evaluarea umană a fost întotdeauna costisitoare în timp ce cercetătorii se luptă să aibă încredere în măsurătorile automate. Pentru a aborda acest lucru, propunem să personalizăm măsurătorile tradiționale, profitând de modelele lingvistice pre-instruite (PLM) și de scorurile limitate disponibile cu etichete umane. Mai întâi reintroducem factorii metrici hLEPOR, urmați de versiunea Python pe care am dezvoltat-o (purtată) care a realizat reglarea automată a parametrilor de ponderare în metrica hLEPOR. Apoi vă prezentăm hLEPOR personalizat (cushLEPOR), care utilizează cadrul de optimizare a hiperparametrului Optuna pentru a regla parametrii de ponderare hLEPOR în vederea unui acord mai bun cu modelele lingvistice pre-instruite (folosind LaBSE) în ceea ce privește perechile exacte de limbi MT în care cushLEPOR este implementat. De asemenea, optimizăm cushLEPOR către datele profesionale de evaluare umană bazate pe cadrul MQM și pSQM pe perechile de limbi engleză-germană și chineză-engleză. Investigațiile experimentale arată că LEPOR îmbunătățește performanțele hLEPOR spre acorduri mai bune pentru PLM-uri precum LABSE, cu costuri mult mai mici, și acorduri mai bune pentru evaluările umane, inclusiv scoruri MQM și pSQM, și oferă performanțe mult mai bune decât BLEU. Rezultatele oficiale arată că depunerile noastre câștigă trei perechi de limbi, inclusiv engleză-germană și chineză-engleză pe domeniul News prin cushLEPOR(LM) și engleză-rusă pe domeniul TED prin hLEPOR. (date disponibile la https://github.com/poethan/cushLEPOR )', 'sr': 'Ljudska procjena je uvek bila skupa dok se istraživači bore da veruju automatskoj metrici. Da bi se ovo riješili, predlažemo da prilagodimo tradicionalnu metriku koristeći predobučene jezičke modele (PLMs) i ograničene dostupne ljudske rezultate označene. Prvo smo upoznali metričke faktore hLEPOR, slijedili Python verziju koju smo razvili (prijavili) koja je ostvarila automatsku prilagodbu težinskih parametara u hLEPOR metriku. Onda predstavljamo prilagođeni hLEPOR (cushLEPOR) koji koristi optimizacijski okvir Optuna hiper-parametara kako bi ispravili parametre težine hLEPOR prema boljim sporazumom prema predobučenim jezičkim modelima (koristeći LaBSE) u vezi tačnih MT jezičkih parova na kojima se cushLEPOR raspoređuje. Takoðe optimizujemo i cushLEPOR na profesionalne ljudske procjene podatke na temelju MQM i pSQM okvira na parovima engleskog-njemaèkog i kineskog-engleskog jezika. Eksperimentalne istrage pokazuju da je cushLEPOR povećao performance hLEPOR-a prema boljim sporazumima PLMsima poput LABSE sa mnogo manjim troškovima, i boljim sporazumima ljudskim procenama uključujući rezultate MQM i pSQM-a, i daje mnogo bolje izvode od BLEU-a. Zvanični rezultati pokazuju da naši podaci dobijaju tri jezička parova uključujući engleski-nemački i kineski-engleski na novinskom domenu preko cushLEPOR(LM) i engleski-ruski na TED domenu preko hLEPOR. (podaci dostupni na https://github.com/poethan/cushLEPOR Da.', 'si': 'මිනිස්සු විශ්වාසය හැමවෙලේම විශ්වාස කරනවා ස්වයංක්\u200dරීය විශ්වාස කරනවා ස්වයංක්\u200dරීය මෙට්\u200dර මේක විශ්වාස කරන්න, අපි ප්\u200dරාමාණික මෙට්\u200dරික්ස් විශ්වාස කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා ප්\u200dරයෝජනය අපි මුලින්ම hLEPOR මෙට්\u200dරික් විශේෂකය ආපහු පෙන්නන්නම්, පස්සේ අපි ප්\u200dරවේශනය කරලා තියෙන පයිතෝන් විශේෂකය (පොර්ටෝඩ් විශේෂකය) ප ඊට පස්සේ අපි පෙන්වන්න පුළුවන් hLEPOR (CuhLEPOR) වෙනුවෙන් Optuna hyper-Parameter optimization system භාවිතා කරනවා හ LEPOR weight Parameters to Fine-tune hLEPOR weight Parameters to better compact to pre-train language Models (use LaBSE) on the right MT language pares that CuhLEPOR is deplored to. අපි ඉංග්\u200dරීසි-ජර්මන් සහ චීනි-ඉංග්\u200dරීසි භාෂාව සම්පූර්ණයේ MQM සහ pSQM පරීක්ෂණ පරීක්ෂණය සඳහා ප්\u200dරශ්ණි පරීක්ෂණ පරීක්ෂණය පෙන්වන්නේ කුස්ලපෝර් හොඳ සම්බන්ධතාවක් වගේ LABSE වගේ ලොකු සම්බන්ධතාවක් වගේම හොඳ සම්බන්ධතාවක් වගේම, සහ හ හොඳ සම්බන්ධතාවක් මි අධ්\u200dයාත්මක ප්\u200dරතිචාර ප්\u200dරතිචාරය පෙන්වන්නේ අපේ පිළිබඳු භාෂාව තුනක් දිනයි ඉංග්\u200dරීසිය-ජර්මන් සහ චීන් ඉංග්\u200dරීසි (දත්ත ප්\u200dරවේශයෙන් https://github.com/poethan/cushLEPOR )', 'sv': 'Mänsklig utvärdering har alltid varit dyr medan forskare kämpar för att lita på de automatiska mätvärdena. För att ta itu med detta föreslår vi att anpassa traditionella mätvärden genom att dra nytta av de pre-trained language models (PLM) och de begränsade tillgängliga humanmärkta poängen. Vi återintroducerar först de metriska faktorerna hLEPOR, följt av Python-versionen vi utvecklade (porterade) som uppnådde automatisk justering av viktningsparametrarna i hLEPOR metrik. Sedan presenterar vi den anpassade hLEPOR (cushLEPOR) som använder Optuna hyperparameter optimering ramverk för att finjustera hLEPOR viktningsparametrar för att bättre överensstämma med förutbildade språkmodeller (med LaBSE) gällande exakt MT språkpar som cushLEPOR distribueras till. Vi optimerar också cushLEPOR mot professionella mänskliga utvärderingsdata baserade på MQM och pSQM ramverk på engelsk-tyska och kinesisk-engelska språkpar. De experimentella undersökningarna visar att LEPOR ökar hLEPORs prestanda mot bättre avtal till PLM som LABSE med mycket lägre kostnad, och bättre avtal till mänskliga utvärderingar inklusive MQM och pSQM poäng, och ger mycket bättre prestanda än BLEU. Officiella resultat visar att våra bidrag vinner tre språkpar inklusive engelsk-tyska och kinesisk-engelska på nyhetsdomänen via cushLEPOR(LM) och engelsk-ryska på TED-domänen via hLEPOR. (uppgifter tillgängliga på https://github.com/poethan/cushLEPOR )', 'ta': 'ஆராய்ச்சியாளர்கள் தானியங்கி மெட்ரிக்களை நம்புவதற்கு போராடுகிறார்கள். இதை முகவரிப்பதற்கு, முன் பயிற்சி மொழி மாதிரிகள் (PLMs) மற்றும் கிடைக்கப்பட்ட மனித குறிப்பிட்ட மதிப்பெண்களை பயன்படுத்துவதற்கு நாம் பா நாம் முதலில் HLEPOR மெட்ரிக் காரணிகளை முதலில் குறிப்பிடுகிறோம், பின்பு நாம் உருவாக்கிய பைதான் பதிப்பு (துண்டிக்கப்பட்டது) அது HLEPOR மேட்ரிக்கு த பின்னர் நாம் தனிப்பயனாக்கப்பட்ட hLEPOR (cushLEPOR), அது Optuna hyper- parameteration optimization சட்டத்தை பயன்படுத்துகிறது நன்றாக HLEPOR அளவுருக்களை முன் பயிற்சிக்கப்பட்ட மொழி மாதிரிகளை பயன்படுத்தும் சரியான MT மொழி ஜோடிகள MQM மற்றும் pSQM சட்டத்தை அடிப்படையிலான தொழில்நுட்பமான மனித மதிப்பிடும் தகவல்களுக்கும் புதுப்பிலோபாரை நாம் விருப்பமாக The experimental investigations show cushLEPOR boosts hLEPOR performances towards better agreements to PLMs like LABSE with much lower cost, and better agreements to human evaluations including MQM and pSQM scores, and yields much better performances than BLEU.  தொழில்நுட்ப முடிவுகள் காட்டுகிறது எங்கள் அனுப்பப்பட்ட மூன்று மொழிகள் ஜோடி வெற்றி செய்யும் ஆங்கிலம்- ஜெர்மன் மற்றும் சீனீஸ்- ஆங்கிலம்  (data available at https://github.com/poethan/cushLEPOR )', 'ms': 'Evaluasi manusia sentiasa mahal sementara peneliti berjuang untuk mempercayai metrik automatik. Untuk mengatasi ini, kami cadangkan untuk menyesuaikan metrik tradisional dengan mengambil keuntungan model bahasa yang dilatih-dilatih (PLMs) dan skor manusia yang tersedia yang terbatas. Kita pertama-tama memperkenalkan semula faktor metrik hLEPOR, diikuti oleh versi Python yang kita kembangkan (dibuka) yang mencapai penyesuaian automatik parameter beratan dalam metrik hLEPOR. Kemudian kita perkenalkan hLEPOR (cushLEPOR) yang disesuaikan yang menggunakan kerangka optimisasi hyper parameter Optuna untuk menyesuaikan parameter berat hLEPOR kepada persetujuan yang lebih baik untuk model bahasa yang dilatih-dilatih (menggunakan LaBSE) mengenai pasangan bahasa MT yang tepat yang cushLEPOR digunakan. Kami juga optimum cushLEPOR kepada data penilaian manusia profesional berdasarkan kerangka MQM dan pSQM pada pasangan bahasa Inggeris-Jerman dan Cina-Inggeris. Penyelidikan percubaan menunjukkan cushLEPOR meningkatkan prestasi hLEPOR menuju perjanjian yang lebih baik untuk PLM seperti LABSE dengan biaya yang jauh lebih rendah, dan perjanjian yang lebih baik untuk penilaian manusia termasuk skor MQM dan pSQM, dan menghasilkan prestasi yang jauh lebih baik daripada BLEU. Official results show that our submissions win three language pairs including English-German and Chinese-English on News domain via cushLEPOR(LM) and English-Russian on TED domain via hLEPOR.  (data tersedia di https://github.com/poethan/cushLEPOR )', 'ur': 'انسان کا ارزش ہمیشہ بہت بڑا ہے جبکہ تحقیقات کرنے والوں نے اپنے متریک پر اعتماد کرنے کے لئے جہاد کیا ہے۔ اس کے بارے میں ہم پیش آموزش کی زبان نمڈلوں (PLMs) اور محدودہ انسان کے لابل لکھے ہوئے اسکوروں کے فائدہ اٹھانے کے ذریعہ سنتی میٹریک کو اختیار کرنے کی پیشنهاد کرتے ہیں. ہم پہلی بار hLEPOR منٹریک فکتوروں کو پہنچا رہے ہیں، پھر پیٹون ویرجون کے پیچھے ہم نے (پورت) پیدا کیا ہے جو hLEPOR منٹریک میں وزن پارامیٹروں کی اتماتیک تنظیم پہنچا رہے ہیں۔ پھر ہم نے اپنا خصوصی hLEPOR (cushLEPOR) کو پیش آموزش کی زبان نمڈلوں (LaBSE کے استعمال سے) مطابق MT زبان جوڑوں کے بارے میں جو cushLEPOR کے منتقل کئے جاتے ہیں مطابق اپنا اپنا اپنا اپنا اپنا پارامیزان فرام کرتا ہے۔ ہم نے اپنا مطابق اپنا مطابق مQM اور pSQM فرمود پر بنیاد رکھا ہے جو انگلیسی-جرمن اور چینی-انگلیسی زبان جوڑوں پر بنیاد ہے۔ آزمائش کی تحقیقات یہ دکھاتی ہے کہ HLEPOR نے اچھے مہمانوں کے لئے LABSE کی طرح بہت کم قیمت کے ساتھ اچھے مہمانوں کے ساتھ اچھے مہمانوں کے ساتھ اچھے مہمانوں کے ساتھ MQM اور pSQM اسکور کے ساتھ اچھے مہمانوں کو اضافہ کرتا ہے اور BLEU سے بہت اچھے مہمانوں کو اضافہ کر رسمی نتائج دکھاتے ہیں کہ ہماری مہمانی تین زبان جوڑوں میں انگلیسی-جرمانی اور چینی-انگلیسی کے شامل ہوتے ہیں ان کی مہمانی دامین پر cushLEPOR(LM) اور TED دامین پر انگلیسی-روسی کے ذریعہ۔ (ڈیٹا موجود ہے https://github.com/poethan/cushLEPOR )', 'so': 'Qiimeynta dadku mar walba waa qaali yahay, marka cilmi-baaritaanku ay u dagaalamayaan inay ku aaminsadaan qaababka automatika ah. Markaas waxan, waxaynu soo jeedaynaa in aan isticmaalno noocyada afka hore (PLMs) iyo noocyada qofka la qoray ee qofka la isticmaalay oo xadidhsan. Marka ugu horeysa waxaynu soo bandhignaa waxyaabaha ku saabsan hLEPOR, waxaana soo raacaynaa warqada Python ee aan horumarinnay (ported) oo koray koritaanka iskuulka miisaanka parameters oo ku qoran HLEPOR metricka. Markaas waxaynu soo bandhignaa HLEPOR (cushLEPOR) oo isticmaalaya koobka optimiska ee Optuna hyper-parameter to fine-tun hLEPOR weighing parameters xagga heshiiska wanaagsan oo horumarinta afka (using LaBSE) oo ku saabsan labada luqada oo sax ah ee cushLEPOR lagu soo dejiyo. Waxaynu sidoo kale ka faa’iidaynaa cushLEPOR xagga macluumaadka qiimeynta dadka ee xirfadda ah oo ku saleysan MQM iyo pSQM oo ku qoran labada luqada Ingiriis-Jarmal iyo Shiino-Ingiriis. Baaritaanka baaritaanka ee cushLEPOR waxay muujiyaan horumarinta hLEPOR oo u jeeda heshiiska wanaagsan ee PLMs. LABSE oo aad u yar, iyo heshiis ka wanaagsan qiimeynta dadka, kuwaas oo ah scoraha MQM iyo pSQM, waxayna bixisaa samooyin aad u fiican oo ka wanaagsan BLEU. Shaqooyinka rasmiga ah waxay muuqataa in soo diritaankayadu saddex luuqadood oo af Ingiriis-Jarmal iyo Shiino-Ingiriis ku guulaysan karto gudaha News via cushLEPOR(LM) iyo Ruush-Ruush oo ku qoran domain TED via hLEPOR. (data available in https://github.com/poethan/cushLEPOR )', 'uz': "Inson qiymatlari har doim qiymati qiymati, taʼminlovchilar avtomatik metriklarga ishonishga harakat qilayotganda. Buni boshqarish uchun biz o'rganilgan tillar modellari (PLMs) va oddiy oddiy qoʻllanilgan inson qoʻllanmalarning chegarasi. Biz birinchi marta HLEPOR metrik faktorini qaytadan ishlatimiz, keyin biz tuzuvchi Python versiyasi (ported) tomonidan foydalanadi, hLEPOR metrikdagi avtomatik o'zgartirish parametrlarini aniqlash mumkin. Keyin biz oddiy HLEPOR (cushLEPOR) dan foydalanamiz, bu Optuna hyper- parametr optimizing freymini yaxshi darajada ishlatiladi. OPEPOR taʼminlovchi tillar modellari (LaBSE) bilan ishlatilgan haqiqiqiy MT tili qoʻllanmalarini ishlatish mumkin. Biz MQM va pSQM freymi ingliz- Olmoncha va Xitoycha Ingliz tili xitoblar bo'lgan pSQM asosida oddiy inson qiymatiga asoslangan foydalanuvchi maʼlumotga asoslangan. Taʼminlovchi tajribalar SHLEPOR bajarishni SLPOR kabi LABSE kabi yaxshi axborot bilan oshirishni ko'rsatadi. Bu narsalarning ko'p qiymatlari haqida juda yaxshi qiymatlar bilan MQM va pSQM qiymatlarini ko'rsatadi, va BLEU'dan ko'proq bajarishlarni bajaradi. Official results show that our submissions win three language pairs including English-German and Chinese-English on News domain via cushLEPOR(LM) and English-Russian on TED domain via hLEPOR.  (maʼlumot mavjud emas https://github.com/poethan/cushLEPOR )", 'vi': 'Xét nghiệm con người luôn rất tốn kém trong khi các nhà nghiên cứu vật chất đặt niềm tin vào đo lường tự động. Để giải quyết việc này, chúng tôi đề nghị thay đổi âm lượng thông thường bằng cách sử dụng các mô hình ngôn ngữ đã được huấn luyện (PLM) và những ghi chép có nhãn con người giới hạn. Chúng tôi lần đầu tiên nhập lại hệ thống đo lường hLEE POR, theo sau là phiên bản Python chúng tôi phát triển (được đưa ra) đã đạt độ chỉnh tự động của tham số cân bằng theo đo mét hLEPOR. Sau đó chúng tôi giới thiệu: Hy vọng cá nhân có khả năng sử dụng hệ thống cải thiện siêu Tham số Optuna để hiệu chỉnh nhiệt cân lượng HLEPOR để đạt được sự đồng thuận tốt hơn đến các mô hình ngôn ngữ đã được đào tạo (dùng Lacrap) về các cặp ngôn ngữ MTV chính xác được dùng để gài đệm. Chúng tôi cũng đã nâng cao nệm sàn để đánh giá con người chuyên nghiệp dựa trên mô hình MQM và PSQM về cặp ngôn ngữ Anh-Đức và Trung Quốc-Anh. Các cuộc điều tra thử nghiệm cho thấy nhu cầu tăng lợi nhuận của HLEPOR để đạt được những thỏa thuận tốt hơn với những nạn nhân như LASSE với giá thấp hơn, và những thỏa thuận tốt hơn với đánh giá nhân, bao gồm điểm của MQM và PSQM, và đem lại hiệu quả tốt hơn cả tiếng bíp. Kết quả chính thức cho thấy tài liệu của chúng tôi thắng ba cặp ngôn ngữ, gồm cả Anh-Đức và Anh-Anh-Người Trung Quốc trên miền News, thông qua nệm-POR (LM) và Anh-Nga trên miền Ted thông qua hperPOR. (dữ liệu có ở https://github.com/poethan/cushLEPOR Name', 'da': "Menneskelig evaluering har altid været dyr, mens forskere kæmper for at stole på de automatiske målinger. For at løse dette foreslår vi at tilpasse traditionelle målinger ved at udnytte fordelene ved de prætrænede sprogmodeller (PLM'er) og de begrænsede tilgængelige menneskelige mærkede scorer. Vi genintroducerer først hLEPOR metriske faktorer, efterfulgt af Python-versionen vi udviklede (ported), som opnåede automatisk justering af vægtningsparametrene i hLEPOR metrik. Derefter præsenterer vi den skræddersyede hLEPOR (cushLEPOR), som bruger Optuna hyper-parameteroptimeringsramme til at finjustere hLEPOR vægtningsparametre for bedre overensstemmelse med forududdannede sprogmodeller (ved hjælp af LaBSE) vedrørende de præcise MT sprogpar, som cushLEPOR er installeret til. Vi optimerer også cushLEPOR til professionelle menneskelige evalueringsdata baseret på MQM og pSQM rammer på engelsk-tysk og kinesisk-engelsk sprogpar. De eksperimentelle undersøgelser viser, at LEPOR øger hLEPOR's præstationer i retning af bedre aftaler til PLM'er som LABSE med langt lavere omkostninger, og bedre aftaler til menneskelige evalueringer, herunder MQM og pSQM scores, og giver langt bedre præstationer end BLEU. Officielle resultater viser, at vores indsendelser vinder tre sprogpar, herunder engelsk-tysk og kinesisk-engelsk på Nyheder domæne via cushLEPOR(LM) og engelsk-russisk på TED domæne via hLEPOR. (data tilgængelige på https://github.com/poethan/cushLEPOR )", 'bg': 'Оценката на човека винаги е била скъпа, докато изследователите се борят да се доверят на автоматичните показатели. За да се справим с това, предлагаме да персонализираме традиционните показатели, като се възползваме от предварително обучените езикови модели (ПЛМ) и ограничените налични оценки с етикет за хора. Първо въвеждаме отново метричните фактори, последвани от разработената от нас версия на Питон, която постига автоматичното настройване на тегловните параметри в метриката. След това представяме персонализираната рамка за оптимизиране на хиперпараметрите на Оптуна за фино настройване на тегловните параметри за по-добро съгласуване с предварително обучените езикови модели (използвайки LaBSE) по отношение на точните езикови двойки, в които се използва. Също така оптимизираме данните за професионална оценка на човека въз основа на рамката на английски-немски и китайско-английски езикови двойки. Експерименталните изследвания показват, че повишава представянето на hLEPOR към по-добри споразумения с PLMs като LABSE с много по-ниски разходи, и по-добри споразумения за човешки оценки, включително MQM и pSQM резултати, и дава много по-добри резултати от BLEU. Официалните резултати показват, че нашите предложения печелят три езикови двойки, включително английски-немски и китайски-английски на домейн Новини чрез и английски-руски на домейн TED чрез hLEPOR. (налични данни на https://github.com/poethan/cushLEPOR )', 'de': 'Human Evaluation war immer teuer, während Forscher Schwierigkeiten haben, den automatischen Metriken zu vertrauen. Um dies anzugehen, schlagen wir vor, traditionelle Metriken anzupassen, indem wir die Vorteile der vortrainierten Sprachmodelle (PLMs) und der begrenzten verfügbaren human labelled Scores nutzen. Wir führen zuerst die hLEPOR-Metrikfaktoren neu ein, gefolgt von der von uns entwickelten Python-Version (portiert), die die automatische Abstimmung der Gewichtungsparameter in hLEPOR-Metrik erreichte. Anschließend stellen wir das kundenspezifische hLEPOR (cushLEPOR) vor, das das Optuna Hyper-Parameter Optimization Framework verwendet, um hLEPOR Gewichtungsparameter zu verfeinern, um eine bessere Übereinstimmung mit vortrainierten Sprachmodellen (unter Verwendung von LaBSE) bezüglich der genauen MT-Sprachpaare zu erreichen, für die cushLEPOR bereitgestellt wird. Darüber hinaus optimieren wir cushLEPOR für professionelle menschliche Evaluationsdaten basierend auf MQM und pSQM Framework auf Englisch-Deutsch und Chinesisch-Englisch Sprachpaaren. Die experimentellen Untersuchungen zeigen, dass cushLEPOR die hLEPOR-Leistung in Richtung besserer Vereinbarungen mit PLMs wie LABSE mit viel geringeren Kosten und besseren Vereinbarungen mit menschlichen Bewertungen einschließlich MQM- und pSQM-Scores steigert und deutlich bessere Leistungen erbringt als BLEU. Offizielle Ergebnisse zeigen, dass unsere Einreichungen drei Sprachpaare gewinnen, darunter Englisch-Deutsch und Chinesisch-Englisch auf News Domain via cushLEPOR(LM) und Englisch-Russisch auf TED Domain via hLEPOR. (Daten verfügbar unter https://github.com/poethan/cushLEPOR )', 'id': 'Evaluasi manusia selalu mahal sementara peneliti berjuang untuk mempercayai metrik otomatis. Untuk mengatasi hal ini, kami mengusulkan untuk menyesuaikan metrik tradisional dengan mengambil keuntungan dari model bahasa yang dilatih-dilatih (PLM) dan skor terbatas yang tersedia manusia labeled. Pertama kita memperkenalkan kembali faktor metrik hLEPOR, diikuti oleh versi Python yang kami kembangkan (portret) yang mencapai pengaturan otomatis dari parameter berat dalam metrik hLEPOR. Kemudian kami mempersembahkan hLEPOR (cushLEPOR) yang disesuaikan yang menggunakan kerangka optimisasi hyper parameter Optuna untuk memperbaiki parameter berat hLEPOR ke perjanjian yang lebih baik untuk model bahasa yang terlatih (menggunakan LaBSE) mengenai pasangan bahasa MT yang tepat yang dipakai cushLEPOR. Kami juga optimisasi cushLEPOR ke data evaluasi manusia profesional berdasarkan MQM dan pSQM pada pasangan bahasa Inggris-Jerman dan Cina-Inggris. Investigasi eksperimen menunjukkan cushLEPOR meningkatkan prestasi hLEPOR menuju perjanjian yang lebih baik untuk PLM seperti LABSE dengan biaya yang jauh lebih rendah, dan perjanjian yang lebih baik untuk evaluasi manusia termasuk skor MQM dan pSQM, dan memberikan prestasi jauh lebih baik dari BLEU. Hasil resmi menunjukkan bahwa pengiriman kita memenangkan tiga pasangan bahasa termasuk bahasa Inggris-Jerman dan bahasa Cina-Inggris di domain berita melalui cushLEPOR(LM) dan bahasa Inggris-Rusia di domain TED melalui hLEPOR. (data tersedia di https://github.com/poethan/cushLEPOR )', 'fa': 'ارزیابی انسان همیشه گرون بوده است در حالی که محققان می\u200cکوشند تا به متریک\u200cهای خودکار اعتماد کنند. برای حل این کار، ما پیشنهاد می\u200cکنیم که متریک سنتی را با استفاده از مدل\u200cهای پیش آموزش زبان (PLMs) و امتیاز\u200cهای محدودیت انسان\u200cهای مشخص شده\u200cاند تنظیم کنیم. ما اولین بار فاکتورهای متریک hLEPOR را دوباره معرفی می کنیم، بعد از نسخه Python که ما توسعه دادیم (ported) که به تنظیم خودکار پارامترهای وزن در متریک hLEPOR رسیده است. سپس ما پیشنهاد hLEPOR (cushLEPOR) را که از چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچ ما همچنین این LEPOR را به سمت داده های ارزیابی انسان حرفه ای بر اساس چهارچوب MQM و pSQM بر جفت زبان انگلیسی-آلمان و چینی-انگلیسی بهترین می کنیم. تحقیقات آزمایشی نشان می دهد که این LEPOR اجرای hLEPOR را به سوی توافق بهتر با PLMs مانند LABSE با هزینه\u200cهای زیادی کمتر، و توافق\u200cهای بهتر برای ارزیابی\u200cهای انسان، شامل امتیاز MQM و pSQM، و اجرای بیشتر از BLEU را می\u200cدهد. نتایج رسمی نشان می دهند که فرستادگان ما سه جفت زبان را برنده می کنند، شامل انگلیسی-آلمانی و چینی-انگلیسی در دامین خبری از طریق cushLEPOR(LM) و انگلیسی-روسی در دامین TED via hLEPOR. (داده\u200cهای موجود در https://github.com/poethan/cushLEPOR )', 'nl': "Menselijke evaluatie is altijd duur geweest terwijl onderzoekers moeite hebben om de automatische statistieken te vertrouwen. Om dit aan te pakken, stellen we voor om traditionele statistieken aan te passen door gebruik te maken van de voorgetrainde taalmodellen (PLM's) en de beperkte beschikbare human labelled scores. Eerst introduceren we de hLEPOR metrische factoren opnieuw, gevolgd door de Python versie die we ontwikkelden (ported) die de automatische afstemming van de wegingsparameters in hLEPOR metrische bereikte. Vervolgens presenteren we het aangepaste hLEPOR (cushLEPOR) dat gebruik maakt van Optuna hyper-parameter optimalisatie framework om hLEPOR weging parameters af te stemmen om beter overeen te stemmen met vooraf getrainde taalmodellen (met LaBSE) met betrekking tot de exacte MT taalparen waarvoor cushLEPOR wordt ingezet. We optimaliseren cushLEPOR ook naar professionele menselijke evaluatiegegevens op basis van MQM en pSQM framework op Engels-Duits en Chinees-Engels taalparen. Uit de experimentele onderzoeken blijkt dat cushLEPOR de prestaties van hLEPOR verhoogt naar betere overeenkomsten met PLM's zoals LABSE met veel lagere kosten, en betere overeenkomsten met menselijke evaluaties inclusief MQM en pSQM scores, en veel betere prestaties levert dan BLEU. Officiële resultaten tonen aan dat onze inzendingen drie taalparen winnen, waaronder Engels-Duits en Chinees-Engels op Nieuws domein via cushLEPOR(LM) en Engels-Russisch op TED domein via hLEPOR. (gegevens beschikbaar op https://github.com/poethan/cushLEPOR )", 'hr': 'Ljudska procjena je uvijek bila skupa dok se istraživači bore da vjeruju automatskoj metrici. Za rješavanje ovoga predlažemo prilagoditi tradicionalne metrike koristeći predobučene jezičke modele (PLMs) i ograničene dostupne ljudske rezultate označene. Prvo smo upoznali metričke faktore hLEPOR-a, slijedili Python verziju koju smo razvili (prijavili) koja je ostvarila automatsku prilagodbu težinskih parametara u hLEPOR metriku. Onda predstavljamo prilagođeni hLEPOR (cushLEPOR) koji koristi okvir optimizacije hiper-parametara Optuna kako bi ispravili parametre težine hLEPOR prema boljim sporazumom prema predobučenim jezičkim modelima (koristeći LaBSE) o to čnim MT jezičkim parovima na kojima se razvija cushLEPOR. Također optimiziramo cushLEPOR prema profesionalnim podacima o procjeni ljudske procjene na temelju MQM i pSQM okvira na pairima engleskog-njemačkog i kineskog-engleskog jezika. Eksperimentalne istrage pokazuju da je cushLEPOR povećao izvođenje hLEPOR-a prema boljim sporazumima PLMsima poput LABSE s mnogo manjim troškovima, i boljim sporazumima ljudskim procjenama uključujući rezultate MQM i pSQM-a, te daje mnogo bolje izvođenje od BLEU-a. Službeni rezultati pokazuju da naši podaci dobivaju tri jezička parova uključujući engleski-njemački i kineski-engleski na novinskom domenu preko cushLEPOR(LM) i engleski-ruski na TED domenu preko hLEPOR. (podaci dostupni na https://github.com/poethan/cushLEPOR -Da.', 'af': 'Die menslike evaluering is altyd koste, terwyl ondersoekers struikel om die outomatiese metrike te vertrou. Om hierdie adres te stel, stel ons voorstel om tradisionele metries te pasmaak deur voordeel te neem van die voorafgeleerde taal modele (PLMs) en die beperk beskikbaar menslike etiketeerde telling. Ons het eerste herintroduseer die hLEPOR metriese faktore, gevolg deur die Python weergawe wat ons ontwikkel (geporteer) wat die outomatiese tuning van die gewigtende parameters in hLEPOR metrie bereik het. Toe voorsien ons die pasmaak hLEPOR (cushLEPOR) wat gebruik Optuna hyper- parameter optimizasie raamwerk na fin- tune hLEPOR gewigtende parameters na beter ooreenkoms na vooraf- opgelei taal modele (gebruik LaBSE) aangaande die presies MT taal paar wat cushLEPOR is uitgebruik word na. Ons optimaliseer ook cushLEPOR tot profesionale menslike evalueringsdata gebaseer op MQM en pSQM raamwerk op Engels-Duits en Sjinese-Engels taal pare. Die eksperimentele insluiterings vertoon cushLEPOR versterk hLEPOR uitvoerings tot beter ooreenkoms aan PLMs soos LABSE met baie minder koste, en beter ooreenkoms aan menslike evaluiterings insluitend MQM en pSQM aantal, en gee baie beter uitvoerings as BLEU. Offisiele resultate wys dat ons onderhouers drie taal paar wen, insluitend Engels-Duits en Sjinees-Engels op Nuusdomein deur cushLEPOR(LM) en Engels-Russe op TED domein deur hLEPOR. (data beskikbaar by https://github.com/poethan/cushLEPOR )', 'tr': "Adamlar deňleşmeleri hemişe has bagly bolup, araştyranlar awtomatik metrikata ynanmak üçin mücadele edýärler. Muny çözmek üçin däpli metrikleri öňünden eğlenen dil nusgalarynyň (PLMs) we bar kişiň etitlenýän sanlaryň üstünlerini ulanarak şartlaşmagyny teklip edýäris. Ilkinji gezek hLEPOR metrik faktorlaryny täzeden tanyşdyrypdyk, diňe hLEPOR metriýasynda ýigrenýän (ported) Python wersiýasynyň yzynda ýene geldik. Sonra biz diňe hLEPOR (cushLEPOR) we Optuna hiper-parameterler optimizasyň çerçevesini hLEPOR taýýarlamak üçin gowy öňünden eğlenen dil nusgalaryna (LaBSE ullanýan) şeklinde çykyş edilen MT dil çiftleri barada ullanýarys. Biz hem cushLEPOR'i profesyonel adamlaryň baýramçylygy ýaly MQM we pSQM çerçevesinde Iňlisçe-nemes we Çinçe-iňlisçe dil çiftlerde guruldyrýarys. Deneysel araştırmalar, cushLEPOR hLEPOR düzgün sözleşmelerini LABSE ýaly PLMlaryň üstüne düşük düzgün sözleşmelerini güçlendirir we insan değerlendirmelerine daha gowy sözleşmeler we MQM we pSQM notlaryny dahil etýär we BLEU'den daha gowy etkinlik etýär. Resmi netijeler görkezilişimiz Iňlisçe-Almança we Çinçe-Iňlisçe Haýsy domaýynda cushLEPOR(LM) we Iňlisçe-Rusça TED domaýynda hLEPOR bilen üç dil çift ýeňdirýär. (maglumat ýeterli https://github.com/poethan/cushLEPOR )", 'sw': 'Utafiti wa binadamu umekuwa ghali wakati watafiti wanapambana kuamini mbinu za kujitegemea. Ili kukabiliana na hili, tunapendekeza kutumia mbinu za kitamaduni kwa kutumia matumizi ya mifano ya lugha iliyoendelea kabla (PLMs) na vipimo vikubwa vya binadamu vilivyopatikana. Kwa mara ya kwanza tunaanzisha vigezo vya kipimo cha HLEPOR, kufuatia toleo la Python tulilounda (lililopangwa) ambalo lilifanikiwa kupata mipango ya uzito katika mita ya hLEPOR. Kisha tunawasilisha hLEPOR (cushLEPOR) ambalo hutumia mfumo wa matumaini ya upepari wa Optuna ili kuvuma parameter nzuri kwa makubaliano bora zaidi ya mifano ya lugha iliyoendeshwa (kwa kutumia LaBSE) kuhusiana na wanandoa wa lugha za MT ambazo mpya LEPOR inatumiwa. Pia tunatumaini mphLEPOR kwa taarifa za kutathmini za binadamu kwa kutumia MQM na mfumo wa pSQM katika lugha ya Kiingereza na Kiingereza na Kiingereza. Uchunguzi wa majaribio unaonyesha maonyesho ya mpya ya MLEPOR kwa makubaliano bora zaidi ya PLS kama vile LABSE kwa gharama ndogo sana, na makubaliano bora zaidi ya uchunguzi wa binadamu ikiwa ni pamoja na vipindi vya MQM na pSQM, na hutoa maoni bora zaidi kuliko BLEU. Matokeo rasmi yanaonyesha kuwa ujumbe wetu unashinda ndoa tatu za lugha ikiwa ni pamoja na Waingereza-Ujerumani na Kichina-Kiingereza kwenye tovuti ya habari kupitia cushLEPOR(LM) na Kiingereza kwenye tovuti ya TED kupitia hLEPOR. (data available at https://github.com/poethan/cushLEPOR )', 'sq': 'Vlerësimi njerëzor ka qenë gjithmonë i shtrenjtë ndërsa kërkuesit përpiqen të besojnë në metrikat automatike. To address this, we propose to customise traditional metrics by taking advantages of the pre-trained language models (PLMs) and the limited available human labelled scores.  Së pari ne rishkruajmë faktorët metrikë hLEPOR, të ndjekur nga versioni Python që zhvilluam (portuam) që arriti rregullimin automatik të parametrave të peshimit në metrikën hLEPOR. Pastaj prezantojmë hLEPOR (cushLEPOR) të personalizuar që përdor kuadrin e optimizimit të hiper-parametrave Optuna për të përshtatur parametrat e peshimit hLEPOR drejt një marrëveshjeje më të mirë me modelet e gjuhës së paratrajnuar (duke përdorur LaBSE) lidhur me çiftet e sakta MT gjuhës në të cilat është vendosur cushLEPOR. Ne gjithashtu optimizojmë cushLEPOR drejt të dhënave profesionale të vlerësimit njerëzor bazuar në MQM dhe pSQM kuadrin mbi çiftet gjuhësh anglisht-gjermane dhe kineze-anglisht. Hetimi eksperimental tregon se cushLEPOR rrit performancat e hLEPOR drejt marrëveshjeve më të mira për PLMs si LABSE me kosto shumë më të ulët dhe marrëveshje më të mira për vlerësimet njerëzore duke përfshirë rezultatet MQM dhe pSQM dhe jep performanca shumë më të mira se BLEU. Rezultatet zyrtare tregojnë se paraqitjet tona fitojnë tre çifte gjuhësh duke përfshirë anglisht-gjerman dhe kinez-anglisht në domenin e lajmeve nëpërmjet cushLEPOR(LM) dhe anglisht-rusisht në domenin e TED nëpërmjet hLEPOR. (të dhënat në dispozicion në https://github.com/poethan/cushLEPOR )', 'am': 'የሰው ውጤቶች ሁልጊዜ የከበረ ሆኖአል፡፡ ለዚህ ለማግኘት፣ የባሕላዊ መተላለፊያ የቋንቋ ምሳሌዎች (PLMs) እና የተገኘውን የሰው ተቃውሞ ደረጃዎችን ለመጠቀም እናስባለን፡፡ መጀመሪያ የኤሌፖር ሜትሪክ ክፍተቶችን እናሳውቃለን፡፡ Then we present the customised hLEPOR (cushLEPOR) which uses Optuna hyper-parameter optimisation framework to fine-tune hLEPOR weighting parameters towards better agreement to pre-trained language models (using LaBSE) regarding the exact MT language pairs that cushLEPOR is deployed to.  በንግግሊዝና-ጀርመን እና ቻይናዊ-እንግሊዘኛ ቋንቋ-ቋንቋ-እንግሊዘኛ ያሉትን የprofessional የሰው ማስታወቂያ ዳታ እና pSQM ፍሬም በመጠቀም እናስመክራለን፡፡ ፈተናው ውይይት የኩልLEPOR የፕሌፖር ውጤቶች ከዋጋው የበለጠ የLABSE የፖሊስ አካሄዱን በማድረግ ያሳድጋል፣ እናም ከBLEU ይልቅ የሚሻለውን የህዝብ ውይይት እና የPSQM ውጤቶች በማድረግ የሚሻል ስህተት ያሳያል፡፡ የባለሥልጣናት ውጤቶች የቴድ ዶሜን በመጠቀም የንግግሊዝኛ-ጀርመን እና የቻይና-እንግሊዘኛ በዜናዎች ድምፅ ውስጥ ሦስት ቋንቋዎች አሸንፈዋል፡፡ ዳታ https://github.com/poethan/cushLEPOR )', 'hy': 'Մարդկային գնահատումը միշտ թանկ է եղել, մինչդեռ հետազոտողները պայքարում են վստահել ավտոմատիկ մետրիկներին: Այս խնդիրների լուծման համար մենք առաջարկում ենք համընդհատել ավանդական մետրիկները, օգտագործելով նախապատրաստված լեզվի մոդելների (PLM) առավելությունները և մարդկային պիտակումների սահմանափակ հասանելի գնահատականները: Առաջին հերթին մենք ներկայացնում ենք hLEPOR-ի մետրական գործոնները, հետո նաև մեր զարգացած (պորտեգրված) Պիթոնի տարբերակը, որը հասավ hLEPOR-ի մետրական կշիռի պարամետրերի ավտոմատիկ հարմարեցման: Հետո մենք ներկայացնում ենք հատուկ hLEPOR (CouchLEPOR), որը օգտագործում է Օպթունայի հիպեր-պարամետրերի լավագույնման շրջանակը, որպեսզի լավագույնենք hLEPOR-ի կենտրոնացման պարամետրերը, որպեսզի ավելի լավ համաձայնվեն նախապատրաստված լեզվի մոդելների (օգտագործելով Լաբսե) հետ կապված MT լեզվի Մենք նաև լավատեսում ենք «CouchLEPOR»-ը դեպի մարդկային գնահատման մասնագիտական տվյալներ, որոնք հիմնված են MQM-ի և pSQM-ի շրջանակներում անգլերեն-գերմաներեն և չինական-անգլերեն զույգերի վրա: Փորձարկվող հետազոտությունները ցույց են տալիս, որ CouchLEPOR-ը խրախուսում է hLEPOR-ի արտադրողությունները ավելի լավ համաձայնությունների ուղղությամբ PLM-ների, ինչպիսիք են LAB-ը, շատ ավելի ցածր գնով, և մարդկային գնահատման ավելի լավ համաձայնությունների հետ, ներառյալ MQM-ը և pSQM-ը,  Ազգային արդյունքները ցույց են տալիս, որ մեր ներկայացումները հաղթեցին երեք լեզվի զույգ, ներառյալ անգլերեն-գերմաներեն և չինական-անգլերեն նորությունների ոլորտում, օգտագործելով CouchLEPOR(LM) և անգլերեն-ռուսերեն TED ոլորտու (տեղեկատվությունը հասանելի է https://github.com/poethan/cushLEPOR )', 'az': "İnsan değerlendirməsi həmişə mal idi, araştırmacılar otomatik metriklərinə güvenirlər deyə mübahisə edirlər. Bunu çəkmək üçün, əvvəlcə təhsil edilmiş dil modellerinin (PLMs) və müəyyən edilmiş insanların etiketli nöqtələrinin faydalarını almaq üçün nəticə edirik. Biz ilk dəfə hLEPOR metrik faktorlarını yenidən tanıdıq, hLEPOR metriklərində ağırlıq parametrlərinin avtomatik düzəltməsini sağladığımız Python versiyonundan sonra. Sonra hLEPOR ağırlığı parametrlərini daha yaxşı təhsil edilmiş dil modellərinə (LaBSE kullanan) daha yaxşı anlaşmağa yol açmaq üçün Optuna hiper-parametr optimizasyon framework ünü istifadə edirik. Biz həmçinin İngilizce-Alman və Çin-İngilizce dil çiftlərinin MQM və pSQM frameworklərinə dayanan profesyonel insan değerlendirməsi məlumatlarına bu işi optimizləyirik. Müxtəlif araştırmalar, hLEPOR hLEPOR performanslarını LABSE kimi PLMs kimi daha düşük qiymətlər ilə daha yaxşı anlaşmalara çox artırar və insanların değerlendirmələrinə daha yaxşı anlaşmalar, MQM və pSQM qiymətlərini də dahil edər, və BLEU'dan daha yaxşı performanslar verir. Resmi sonuçlar göstərir ki, bizim göndərmələrimiz TED domain vasitəsilə cushLEPOR(LM) və İngilizce-Rus vasitəsilə İngilizce-Alman və Çin-İngilizce sahəsində üç dil çift kazandı. (məlumat faydalanır https://github.com/poethan/cushLEPOR )", 'ca': "Human evaluation has always been expensive while researchers struggle to trust the automatic metrics.  Per abordar això, proposem personalitzar les mètriques tradicionals prenent avantatges dels models de llenguatge pré-entrenats (PLM) i les puntuacions limitades disponibles amb etiquetes humanes. Primer reintrobem els factors mètrics hLEPOR, seguits de la versió Python que vam desenvolupar (portar) que va aconseguir el ajustament automàtic dels paràmetres de ponderació en hLEPOR mètric. Llavors presentem el hLEPOR personalitzat (cushLEPOR) que utilitza el marc d'optimització de hiper paràmetres d'Optuna per ajustar els paràmetres de ponderació hLEPOR cap a un millor acord amb els models de llenguatge pré-entrenats (utilitzant LaBSE) en relació amb els parells exacts de llenguatge MT a què es desplega cushLEPOR. També optimisem el cushLEPOR cap a dades d'evaluació humana profesional basades en el marc MQM i pSQM en parells de llenguatge anglès-alemany i xinès-anglès. Les investigacions experimentals mostran que cushLEPOR impulsa les performances hLEPOR cap a millors acords amb PLMs com LABSE amb molt més baix cost, i millors acords amb les evaluacions humanes, incloent les puntuacions MQM i pSQM, i produeix molt millors performances que BLEU. Els resultats oficials mostren que les nostres presentacions guanyen tres parells de llengües, incloent anglès-alemany i xinès-anglès en domini News a través de cushLEPOR(LM) i anglès-rus en domini TED a través de hLEPOR. (dades disponibles en https://github.com/poethan/cushLEPOR )", 'ko': '연구원들이 자동 도량을 믿기 위해 노력하는 동시에 인간의 평가는 줄곧 비싸다.이 문제를 해결하기 위해 우리는 미리 훈련된 언어모델(PLM)과 유한한 인간 표기 점수를 이용하여 전통적인 지표를 맞춤형으로 제작하는 것을 권장한다.우리는 먼저 hLEPOR 도량 인자를 다시 소개한 다음에 우리가 개발한 Python 버전 (ported) 을 소개했다. 이것은 hLEPOR 도량 중의 권중 파라미터의 자동 조정을 실현했다.그 다음에 우리는 맞춤형 hLEPOR(cushLEPOR)을 소개했다. 이것은 Optuna 초파라미터 최적화 프레임워크를 사용하여 hLEPOR 권중 파라미터를 미세하게 조정하여 미리 훈련된 언어 모델(LabSE 사용)과 더욱 일치하도록 한다. 이것은cushLEPOR이 배치한 정확한 기계 번역 언어와 관련이 있다.우리는 또한 MQM과 pSQM 프레임워크를 바탕으로 하는 전문적인 인간 평가 데이터의cushLEPOR를 최적화시켰다. 이 프레임워크는 영국과 중국어를 대상으로 한다.실험 연구에 의하면cushLEPOR는 더욱 낮은 원가로 hLEPOR의 성능을 향상시켜 PLM(예를 들어 LABSE)의 성능과 더욱 좋은 일치성을 얻었고 인류 평가(MQM과 pSQM 점수 포함)의 성능과 더욱 좋은 일치성을 얻었으며 BLEU보다 더 좋은 성능을 나타냈다.공식 결과에 따르면 우리의 의견서는 뉴스 분야의 영어-독일어와 중국어-영어, 헬레보르를 통해 TED 분야의 영어-러시아어 등 세 가지 언어를 얻었다.(데이터는https://github.com/poethan/cushLEPOR)', 'bn': 'স্বয়ংক্রিয় মেট্রিকের উপর বিশ্বাস করার জন্য মানুষের মূল্য সবসময় দামী ছিল। প্রথম প্রশিক্ষিত ভাষার মডেল (পিএলএমএস) এবং সীমিত মানুষের লেবেলেড স্কোরের সুবিধা নিয়ে আমরা প্রস্তাব করি। আমরা প্রথমে এইচলিপোর মেট্রিক কারণগুলোকে পুনরায় চিহ্নিত করি, তার পরে পাইথন সংস্করণ আমরা উন্নয়ন করেছি (পোর্ট করেছি) যা হেলিপার মেট্রিকের ওজনের প্যারাম তারপর আমরা স্বনির্বাচিত হেলিপোর্ট (কুশেলিপোর্ট) উপস্থাপন করি যেটি ওপ্টুনা হাইপার-প্যারামিটার অপেশিমেশন ফ্রেম ব্যবহার করে ভালো চুক্তি পূর্বে প্রশিক্ষিত ভাষার মডেল (লাবিসের ব্যবহ এমকিউএম এবং পিএসকিউএম ফ্রেমের উপর ভিত্তিক পেশাদার মানুষের মূল্যের তথ্যের বিরুদ্ধে আমরা প্রতিশ্রুতি প্রদান করি। পরীক্ষার তদন্তের দেখা যাচ্ছে পিএলএমএসের মতো ভালো চুক্তির বিরুদ্ধে কাস্পলিপোর প্রদর্শনীকে বাড়িয়ে দিচ্ছে এবং মানুষের মূল্যের সাথে মানুষের চুক্তি দিয়ে আরো ভালো চুক আনুষ্ঠানিক ফলাফল দেখা যাচ্ছে যে আমাদের প্রতিপাদক তিনটি ভাষায় জয়ী হয়েছে, যার মধ্যে ইংরেজী জার্মান এবং চীনা ইংরেজী ইংরেজী নিউজ ডোমেইনের মাধ্যম (তথ্য উপস্থিত https://github.com/poethan/cushLEPOR )', 'et': 'Inimeste hindamine on alati olnud kallis, samas kui teadlased ei suuda automaatseid mõõdikuid usaldada. Selle lahendamiseks teeme ettepaneku kohandada traditsioonilisi mõõdikuid, kasutades eelnevalt koolitatud keelemudeleid ja piiratud saadaolevaid inimmärgistatud hindeid. Esiteks tutvustame uuesti hLEPOR meetrikufaktoreid, millele järgneb meie väljatöötatud Pythoni versioon (porteeritud), mis saavutas kaalumisparameetrite automaatse häälestamise hLEPOR meetrikus. Seejärel tutvustame kohandatud hLEPOR (cushLEPOR), mis kasutab Optuna hüperparameetrite optimeerimise raamistikku hLEPOR kaalumisparameetrite täpsemaks häälestamiseks, et paremini kokku leppida eelnevalt koolitatud keelemudelitega (kasutades LaBSE) täpsete MT keelepaaride osas, millesse cushLEPOR kasutatakse. Samuti optimeerime cushLEPOR professionaalsete inimeste hindamise andmete suunas, mis põhinevad MQM ja pSQM raamistikul inglise-saksa ja hiina-inglise keele paaridel. Eksperimentaalsed uuringud näitavad, et cushLEPOR suurendab hLEPORi tulemusi paremate kokkulepete saavutamiseks PLM-idega, nagu LABSE, ja paremate kokkulepete saavutamiseks inimeste hindamistega, sealhulgas MQM ja pSQM skoorid, ning annab palju parema tulemuse kui BLEU. Ametlikud tulemused näitavad, et meie ettepanekud võidavad kolme keelepaari, sealhulgas inglise-saksa ja hiina-inglise keele uudiste domeenis cushLEPOR(LM) ja inglise-vene TED domeenis hLEPOR kaudu. (andmed kättesaadavad aadressil https://github.com/poethan/cushLEPOR )', 'fi': 'Ihmisten arviointi on aina ollut kallista, kun taas tutkijat kamppailevat luottamaan automaattisiin mittareihin. Tämän ratkaisemiseksi ehdotamme perinteisten mittareiden mukauttamista hyödyntämällä ennalta koulutettuja kielimalleja (PLM) ja rajallisia saatavilla olevia ihmisten merkitsemiä pisteitä. Ensin esittelemme uudelleen hLEPOR-metriset kertoimet, minkä jälkeen kehitimme Python-version, joka saavutti painotusparametrien automaattisen virityksen hLEPOR-metriikassa. Tämän jälkeen esittelemme räätälöidyn hLEPOR (cushLEPOR), joka käyttää Optuna hyperparametrien optimointikehystä hienosäätämään hLEPOR-painotusparametreja paremman yhteensopivuuden esikoulutettujen kielimallien (LaBSE) kanssa koskien tarkkoja MT-kielipareja, joihin cushLEPOR on otettu käyttöön. Optimoimme myös cushLEPORin ammattilaisten arviointidataan, joka perustuu MQM- ja pSQM-viitekehyksiin englannin-saksan ja kiinan-englannin kielipareissa. Kokeelliset tutkimukset osoittavat, että cushLEPOR parantaa hLEPORin suorituskykyä kohti parempia sopimuksia PLMs:n, kuten LABSE:n, kanssa paljon pienemmillä kustannuksilla, ja parempi yhteensopivuus ihmisten arviointeihin, mukaan lukien MQM ja pSQM, ja tuottaa paljon parempia suorituksia kuin BLEU. Viralliset tulokset osoittavat, että hakemuksemme voittavat kolme kieliparia, mukaan lukien englanti-saksa ja kiina-englanti News-verkkotunnuksella cushLEPOR(LM) ja englanti-venäjä TED-verkkotunnuksella hLEPOR-verkkotunnuksella. (saatavilla olevat tiedot osoitteessa https://github.com/poethan/cushLEPOR )', 'bs': 'Ljudska procjena je uvijek bila skupa dok se istraživači bore da vjeruju automatskoj metrici. Za rješavanje ovoga, predlažemo da prilagodimo tradicionalnu metriku koristeći predobučene jezičke modele (PLMs) i ograničene dostupne ljudske rezultate označene. Prvo smo upoznali metričke faktore hLEPOR, slijedili Python verziju koju smo razvili (prijavili) koja je ostvarila automatsku prilagodbu težinskih parametara u hLEPOR metriku. Onda predstavljamo prilagođeni hLEPOR (cushLEPOR) koji koristi okvir optimizacije hiper-parametara Optuna kako bi ispravili parametre težine hLEPOR prema boljim sporazumom prema predobučenim jezičkim modelima (koristeći LaBSE) o to čnim MT jezičkim parovima na kojima se šipLEPOR raspoređuje. Također optimiziramo cushLEPOR prema profesionalnim podacima o procjeni ljudskih ocjena baziranim na okviru MQM i pSQM na pairima engleskog-njemačkog i kineskog-engleskog jezika. Eksperimentalne istrage pokazuju da je cushLEPOR povećao izvode hLEPOR-a prema boljim sporazumima PLM-ovim poput LABSE sa mnogo manjim troškovima, i boljim sporazumima ljudskim procjenama uključujući rezultate MQM i pSQM-a, i donosi mnogo bolje izvode od BLEU-a. Zvanični rezultati pokazuju da naša podaci dobijaju tri jezička parova uključujući engleski-nemački i kineski-engleski na novinskom domenu preko cushLEPOR(LM) i engleski-ruski na TED domenu preko hLEPOR. (podaci dostupni na https://github.com/poethan/cushLEPOR Da.', 'cs': 'Lidské hodnocení bylo vždy drahé, zatímco výzkumníci se snaží důvěřovat automatickým metrikám. Abychom to řešili, navrhujeme přizpůsobit tradiční metriky využitím předškolených jazykových modelů (PLM) a omezených dostupných lidských značek skóre. Nejprve znovu představujeme metrické faktory hLEPOR, následuje Python verze, kterou jsme vyvinuli (portovali), která dosáhla automatického ladění váhových parametrů v metrice hLEPOR. Dále představujeme individuální hLEPOR (cushLEPOR), který využívá optimalizační framework hyperparametrů Optuna k jemnému ladění parametrů váhy hLEPOR pro lepší shodu s předškolenými jazykovými modely (pomocí LaBSE) ohledně přesných jazykových párů MT, do kterých je cushLEPOR nasazen. Kromě toho optimalizujeme cushLEPOR pro profesionální hodnocení lidí založené na MQM a pSQM frameworku na anglicko-německých a čínsko-anglických jazykových párech. Experimentální výzkumy ukazují, že cushLEPOR zvyšuje výkonnost hLEPOR směrem k lepším dohodám s PLM, jako je LABSE s mnohem nižšími náklady, a lepšími souhlasy s lidskými hodnoceními včetně MQM a pSQM skóre, a přináší mnohem lepší výkony než BLEU. Oficiální výsledky ukazují, že naše příspěvky vyhrávají tři jazykové páry včetně anglicko-němčiny a čínsko-anglicky na doméně News prostřednictvím cushLEPOR(LM) a anglicko-ruštiny na TED doméně přes hLEPOR. (údaje jsou k dispozici na adrese https://github.com/poethan/cushLEPOR )', 'jv': 'Ngucap Cino Ngawe ngerti ngobro iki, kita supoyo nggawe dadi perintasi sistem dadi kanggo diangkat oleh dumaten (PLM) lan oleh dumaten sing oleh nggawe barang dumaten. Awak dhéwé mulai nggawe perusahaan nggawe hLepo Metric karo ingkang, gewis dipoleh Perusahaan anyar ne seneng pisan (bantayan) nggawe barang otomatik dhéwé nggawe parameters nggawe hLepo Metric. Unya we present the custom hLeponR (CuhLeponR) that use Optuna caper-parameter Optimisation frame to Fine-tune hLeponR measurement parameters to BELUKAY concatenation to BELUKAY-TRANSLAN language modes (use LaGSE) about the exact MT language paras that CuhLeponR is depicted to. Awak dhéwé ngerasakno perbudhakan kanggo nggawe Perintah Pangaki karo Perancis, dadi kapan kanggo Kemerdekaan kanggo masakno Manual sing basa MqM karo pqM karo perintah Pangaki ingkang-Geman karo Pak-Inggris. istrangé sing perbudhakan langkung wigatining kelas nggawe luwih nggawe hLepo sing luwih basa sing luwih nggawe gerakan ingkang PLMs karo LAGSE karo akeh sing katêpakan karo akeh sing katêpakan, lan akeh dumadhi sing luwih dumadhi karo assembosi sing luwih dumadhi MqM karo pXMM lan akeh sing luwih dumadhi sing luwih dumadhi Ofisi dhéwé mungkahi karo awak dhéwé, dengané awak dhéwé karo tanggal inggiles-German lan Chinese-enggiles kanggo New domain throng CuhLepo(LM) lan French-Ruso sing nyebuté nggawe barang nggambar inggiles-German. (data kang sampeyan nang https://github.com/poethan/cushLEPOR )', 'sk': 'Vrednotenje človeka je bilo vedno drago, medtem ko raziskovalci težko zaupajo avtomatskim meritvam. Za reševanje tega predlagamo prilagoditev tradicionalnih meritev z izkoriščanjem predhodno usposobljenih jezikovnih modelov (PLM) in omejenih razpoložljivih ocen, označenih s človekom. Najprej ponovno predstavimo metrične faktorje hLEPOR, sledi različica Python, ki smo jo razvili (prenesli), ki je dosegla avtomatsko nastavitev parametrov tehtanja v metrični metriki hLEPOR. Nato predstavljamo prilagojeni hLEPOR (cushLEPOR), ki uporablja Optunov hiper-parametrski optimizacijski okvir za natančno nastavitev parametrov hLEPOR za boljše usklajevanje s predhodno usposobljenimi jezikovnimi modeli (z uporabo LaBSE) glede točnih jezikovnih parov MT, v katere je cushLEPOR uporabljen. Prav tako optimiziramo cushLEPOR za strokovne podatke o oceni človeka na podlagi MQM in pSQM okvira na angleško-nemških in kitajsko-angleških jezikovnih parov. Eksperimentalne raziskave kažejo, da cushLEPOR povečuje učinkovitost hLEPOR v smeri boljših dogovorov z PLM-ji, kot je LABSE, z veliko nižjimi stroški, in boljših dogovorov z ocenami ljudi, vključno z rezultati MQM in pSQM, ter prinaša veliko boljše učinkovitosti kot BLEU. Uradni rezultati kažejo, da so naši prispevki prejeli tri jezikovne pare, med drugim angleško-nemško in kitajsko-angleško na domeni Novice preko cushLEPOR(LM) in angleško-rusko na domeni TED preko hLEPOR. (podatki so na voljo na spletni strani https://github.com/poethan/cushLEPOR )', 'he': 'Human evaluation has always been expensive while researchers struggle to trust the automatic metrics.  כדי להתמודד עם זה, אנו מציעים לתאים מטריקה מסורתית על ידי לקחת יתרונות של דוגמני השפה המאמנות מראש (PLMs) והנקודות האנושיות המוגבלות זמינות. ראשית נציג מחדש את גורמים המטריים של hLEPOR, ואחריו בגרסה פיתון שפיתחנו (פורטנו) אשר השיגה את התאמה האוטומטית של הפרמטרים המשקלים במטרית hLEPOR. ואז אנו מציגים את hLEPOR (cushLEPOR) המתאים אשר משתמש במסגרת אופטימציה של הפרמטרים היפרפרמטרים אופטימציה אופטימציה אופטימציה אופטימציה אופטימציה אופטימציה אופטימציה אופטימציה של hLEPOR כדי להתאים פרמטרים משקלים של hLEPOR אל הסכם טוב יותר לדוגמאות שפות מאומנות מראש (באמצעות LaBS אנו גם אופטימים קושLEPOR לכיוון נתוני הערכה אנושית מקצועית מבוססים על MQM ומסגרת pSQM על זוגות שפת אנגלית-גרמנית וסינית-אנגלית. החקירות הניסיוניים מראות שקושלפור מגביר את ההופעות של hLEPOR לכיוון הסכם טוב יותר לפלימי כמו LABSE עם עלות הרבה יותר נמוכה, והסכם טוב יותר להערכות אנושיות כולל MQM ו pSQM נקודות, ומביא הופעות הרבה יותר טובות מאשר BLEU. התוצאות הרשמיות מראות שהשליחות שלנו מנצחות בשלושה זוגות שפות כולל אנגלית-גרמנית וסינית-אנגלית בתחום חדשות באמצעות cushLEPOR( LM) ואנגלית-רוסית בתחום TED באמצעות hLEPOR. (נתונים זמינים ב https://github.com/poethan/cushLEPOR -כן.', 'ha': "Ana ƙaddara mutum ko da yaushe ya kasance mai kyauta a lokacin da watani ke yin jihãdi ga aminci ga metricikin farat ɗaya. To, za mu buɗa wannan, za'a buƙata masu amfani da shiryoyin ayuka na zaman-wa'anar harshen (PLM) da wanda aka ƙunsa da fassarar mutane da aka rubuta. Tuna fara fara farata masu motsi na hLEPR, daban da version na Python wanda muka develope (da aka nuna) wanda ya sami tunkuɗe parameterin da aka yi nau'i cikin mitrikin hLEPR. Sa'an nan kuma muna halatar da wanda ke da ɗabi'a na hLEPR (na amfani da shi) wanda ke amfani da firam masu kwamfyuta da shirin ayuka na opertuna zuwa mai kyau-tun hLEPR, mai daidaita parameter zuwa da mafi kyau ga yarda da misalin harshen da aka yi amfani da shi a gaba ɗaya (na yi amfani da LaBCE) a kan ma'anar MT da aka saka shi zuwa. @ item license Kayan karatun masu jarrabi na nuna makarantar HLEPR na ƙarfafa su da mafi alhẽri Agreements zuwa PLM kamar LaBCE da mafi ƙaranci ko kuma mafi kyaun karãtun mutane da qiimako ko na MQM da pSQM, kuma yana ƙara mafiya kyakkyawan ajin da ba BLEU ba. Mataimakin offisiki na nuna cewa mataimakanmu masu rinjãya sau-nau'i uku cikin harshen Ingiriya-Jarman da Kinesi-Ingiriya a kan News Domen mainframai na CuhLEPoR(LM) da Ingiriya-Ruushi a kan Domen TeD maimakon hLEPR. (data yana da a kan https://github.com/poethan/cushLEPOR )", 'bo': 'Human evaluation has always been expensive while researchers struggle to trust the automatic metrics. To address this, we propose to customise traditional metrics by taking advantages of the pre-trained language models (PLMs) and the limited available human labelled scores. We first re-introduce the hLEPOR metric factors, followed by the Python version we developed (ported) which achieved the automatic tuning of the weighting parameters in hLEPOR metric. Then we present the customised hLEPOR (cushLEPOR) which uses Optuna hyper-parameter optimisation framework to fine-tune hLEPOR weighting parameters towards better agreement to pre-trained language models (using LaBSE) regarding the exact MT language pairs that cushLEPOR is deployed to. We also optimise cushLEPOR towards professional human evaluation data based on MQM and pSQM framework on English-German and Chinese-English language pairs. The experimental investigations show cushLEPOR boosts hLEPOR performances towards better agreements to PLMs like LABSE with much lower cost, and better agreements to human evaluations including MQM and pSQM scores, and yields much better performances than BLEU. Official results show that our submissions win three language pairs including English-German and Chinese-English on News domain via cushLEPOR(LM) and English-Russian on TED domain via hLEPOR. (སྤྱོད་སྤྱོད་པའི་ཆ་འཕྲིན་གྲངས https://github.com/poethan/cushLEPOR )'}
{'en': 'MTEQA at WMT21 Metrics Shared Task', 'ar': 'MTEQA في مهمة المقاييس المشتركة WMT21', 'fr': 'Tâche partagée MTEQA et WMT21 Metrics', 'pt': 'MTEQA na Tarefa Compartilhada de Métricas do WMT21', 'zh': 'MTEQA 于 WMT21 指标共之', 'es': 'Tarea compartida de métricas de MTEQA en WMT21', 'ja': 'WMT 21メトリクス共有タスクのMTEQA', 'hi': 'WMT21 मैट्रिक्स साझा कार्य पर MTEQA', 'ru': 'MTEQA на совместной задаче по метрикам WMT21', 'ga': 'MTEQA ag Tasc Comhroinnte Méadrachta WMT21', 'hu': 'MTEQA at WMT21 Metrics Shared Task', 'el': 'MTEQA στην κοινή εργασία μετρήσεων WMT21', 'ka': 'Comment', 'kk': 'MTEQA WMT21 метрикалық ортақ тапсырмасында', 'lt': 'MTEQA WMT21 Metrics Shared Task', 'it': 'MTEQA al WMT21 Metrics Shared Task', 'mk': 'MTEQA на WMT21 Metrics Shared Task', 'ml': 'MTEQA at WMT21 Metrics Shared Task', 'mn': 'WMT21 метрик хуваалтын ажил дээр MTEQA', 'ms': 'MTEQA pada Tugas Berkongsi Metriks WMT21', 'mt': 'MTEQA fil-Kompitu Konġunt tal-Metriki tad-WMT21', 'pl': 'MTEQA na WMT21 Metrics Shared Task', 'no': 'MTEQA ved WMT21 metrisk delt oppgåve', 'sr': 'MTEQA na WMT21 metrički delovani zadatak', 'ro': 'MTEQA la WMT21 Metrics Shared Task', 'si': 'Comment', 'so': 'MTEQA at WMT21 Metrics Shared Task', 'sv': 'MTEQA vid WMT21 Metrics delad uppgift', 'ta': 'WMT21 மெட்ரிக்ஸ் பகிர்ந்த பணியில் MTEQA', 'ur': 'MTEQA WMT21 متریک شریک ٹاکس پر', 'uz': 'Name', 'vi': 'Comment=Giao dịch Comment', 'bg': 'MTEQA при WMT21 Метрици споделена задача', 'nl': 'MTEQA bij WMT21 Metrics Shared Task', 'da': 'MTEQA ved WMT21 Metrics Shared Task', 'hr': 'MTEQA na WMT21 metrički zadatak', 'de': 'MTEQA bei WMT21 Metrics Shared Task', 'sw': 'MTEQA kwenye mbinu za WMT21', 'ko': 'WMT21 메트릭 공유 작업의 MTEQA', 'fa': 'MTEQA در کار مشترک WMT21 متریک', 'id': 'MTEQA di WMT21 Metrics Shared Task', 'tr': 'WMT21 Metrici Bölüniş Görevde MTEQA', 'sq': 'MTEQA në WMT21 Metrics Task Shared', 'hy': 'MTEQA', 'am': 'MTEQA at WMT21 Metrics Shared Task', 'az': 'WMT21 Metrics paylaşılan işdə MTEQA', 'af': 'MTEQA by WMT21 metries gedeelde taak', 'bs': 'MTEQA na WMT21 metrički zadatak', 'bn': 'WMT21 মেট্রিক শেয়ার কর্মে MTEQA', 'ca': 'MTEQA at WMT21 Metrics Shared Task', 'cs': 'MTEQA na WMT21 Metrics Shared Task', 'fi': 'MTEQA at WMT21 Metrics Shared Task', 'et': 'MTEQA WMT21 meetrite jagatud ülesanne', 'ha': 'KCharselect unicode block name', 'sk': 'MTEQA v skupni rabi meril WMT21', 'bo': 'MTEQA at WMT21 Metrics Shared Task', 'jv': 'MTeqA nang WWT 22 Metric Joined Job', 'he': 'MTEQA במשימה משותפת WMT21'}
{'en': 'In this paper, we describe our submission to the WMT 2021 Metrics Shared Task. We use the automatically-generated questions and answers to evaluate the quality of Machine Translation (MT) systems. Our submission builds upon the recently proposed MTEQA framework. Experiments on WMT20 evaluation datasets show that at the system-level the MTEQA metric achieves performance comparable with other state-of-the-art solutions, while considering only a certain amount of information from the whole translation.', 'es': 'En este artículo, describimos nuestro envío a la tarea compartida de métricas del WMT 2021. Utilizamos las preguntas y respuestas generadas automáticamente para evaluar la calidad de los sistemas de traducción automática (MT). Nuestra presentación se basa en el marco MTEQA recientemente propuesto. Los experimentos en conjuntos de datos de evaluación de WMT20 muestran que, a nivel de sistema, la métrica MTEQA logra un rendimiento comparable con otras soluciones de última generación, al tiempo que considera solo una cierta cantidad de información de toda la traducción.', 'pt': 'Neste documento, descrevemos nosso envio para a Tarefa Compartilhada de Métricas do WMT 2021. Usamos as perguntas e respostas geradas automaticamente para avaliar a qualidade dos sistemas de tradução automática (MT). Nossa submissão se baseia na estrutura MTEQA recentemente proposta. Experimentos em conjuntos de dados de avaliação WMT20 mostram que, no nível do sistema, a métrica MTEQA alcança desempenho comparável a outras soluções de última geração, considerando apenas uma certa quantidade de informações de toda a tradução.', 'ar': 'في هذه الورقة ، نصف تقديمنا إلى مهمة المقاييس المشتركة WMT 2021. نستخدم الأسئلة والأجوبة التي يتم إنشاؤها تلقائيًا لتقييم جودة أنظمة الترجمة الآلية (MT). يعتمد تقديمنا على إطار عمل MTEQA المقترح مؤخرًا. تُظهر التجارب على مجموعات بيانات تقييم WMT20 أن مقياس MTEQA على مستوى النظام يحقق أداءً مشابهًا لأحدث الحلول الأخرى ، مع مراعاة قدر معين فقط من المعلومات من الترجمة بأكملها.', 'fr': "Dans cet article, nous décrivons notre soumission à la tâche partagée WMT 2021 Metrics. Nous utilisons les questions et réponses générées automatiquement pour évaluer la qualité des systèmes de traduction automatique (TA). Notre soumission s'appuie sur le cadre MTEQA récemment proposé. Des expériences sur des ensembles de données d'évaluation WMT20 montrent qu'au niveau du système, la métrique MTEQA atteint des performances comparables à celles d'autres solutions de pointe, tout en ne tenant compte que d'une certaine quantité d'informations provenant de l'ensemble de la traduction.", 'ja': '本稿では、WMT 2021メトリクス共有タスクへの提出について説明します。自動生成された質問と回答を使用して、機械翻訳（ MT ）システムの品質を評価します。当社の提出物は、最近提案されたMTEQAフレームワークに基づいています。WMT 20評価データセットの実験では、システムレベルでは、MTEQAメトリックは、翻訳全体からの特定の量の情報のみを考慮しながら、他の最先端のソリューションと同等のパフォーマンスを達成することが示されています。', 'zh': '在本文中,我们将介绍向 WMT 2021 指标共享职务提交的文件。 吾以自生之理,与对案以质机器翻译 (MT) 统之量。 交材以近言MTEQA框架为基。 WMT20评数集上之实验,系统之级,MTEQA指标性比先进之解决方案,兼虑全转之数。', 'ru': 'В этой статье мы описываем наше участие в совместной задаче по метрикам WMT 2021. Мы используем автоматически генерируемые вопросы и ответы для оценки качества систем машинного перевода (MT). Наша заявка основана на недавно предложенной структуре MTEQA. Эксперименты с наборами оценочных данных WMT20 показывают, что на системном уровне метрика MTEQA достигает производительности, сопоставимой с другими современными решениями, учитывая только определенный объем информации из всего перевода.', 'hi': 'इस पेपर में, हम WMT 2021 मैट्रिक्स साझा कार्य के लिए हमारे सबमिशन का वर्णन करते हैं। हम मशीन अनुवाद (एमटी) सिस्टम की गुणवत्ता का मूल्यांकन करने के लिए स्वचालित रूप से उत्पन्न प्रश्नों और उत्तरों का उपयोग करते हैं। हमारा सबमिशन हाल ही में प्रस्तावित MTEQA ढांचे पर बनाता है। WMT20 मूल्यांकन डेटासेट पर प्रयोगों से पता चलता है कि सिस्टम-स्तर पर MTEQA मीट्रिक अन्य अत्याधुनिक समाधानों के साथ तुलनीय प्रदर्शन प्राप्त करता है, जबकि पूरे अनुवाद से केवल एक निश्चित मात्रा में जानकारी पर विचार करता है।', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar ár n-aighneacht do Thasc Comhroinnte Méadracht 2021 WMT. Bainimid úsáid as na ceisteanna agus na freagraí a ghintear go huathoibríoch chun cáilíocht na gcóras Aistriúcháin Meaisín (MT) a mheas. Tógann ár n-aighneacht ar an gcreat MTEQA a moladh le déanaí. Léiríonn turgnaimh ar thacair sonraí meastóireachta WMT20 go n-éiríonn le méadrach MTEQA ar leibhéal an chórais feidhmíocht atá inchomparáide le réitigh úrscothacha eile, agus gan ach méid áirithe faisnéise a mheas ón aistriúchán iomlán.', 'hu': 'Ebben a tanulmányban ismertetjük a WMT 2021 Metrics Shared Task előterjesztését. Az automatikusan generált kérdések és válaszok segítségével értékeljük a Gépi Fordítás (MT) rendszerek minőségét. Jelentésünk a közelmúltban javasolt MTEQA keretrendszerre épül. A WMT20 értékelési adatkészletekkel végzett kísérletek azt mutatják, hogy rendszerszinten az MTEQA mutató más korszerű megoldásokkal összehasonlítható teljesítményt ér el, miközben csak bizonyos mennyiségű információt vesz figyelembe a teljes fordítás során.', 'el': 'Σε αυτή την εργασία, περιγράφουμε την υποβολή μας στην κοινή εργασία μετρήσεων του WMT 2021. Χρησιμοποιούμε τις αυτόματα παραγόμενες ερωτήσεις και απαντήσεις για να αξιολογήσουμε την ποιότητα των συστημάτων μηχανικής μετάφρασης (ΜΤ). Η υποβολή μας βασίζεται στο πρόσφατα προτεινόμενο πλαίσιο MTEQA. Τα πειράματα σε σύνολα δεδομένων αξιολόγησης δείχνουν ότι σε επίπεδο συστήματος η μετρική επιτυγχάνει επιδόσεις συγκρίσιμες με άλλες λύσεις τελευταίας τεχνολογίας, λαμβάνοντας υπόψη μόνο ένα ορισμένο ποσό πληροφοριών από ολόκληρη τη μετάφραση.', 'ka': 'ამ დომენტში ჩვენ განახსოვრებთ ჩვენი გახსნა WMT 2021 მეტრიკის გაყოფილი რაოდენობა. ჩვენ ავტომატურად შექმნილი კითხვები და პასუხები გამოყენებთ მაქსინური გადაწყვეტილების (MT) სისტემის კაalitეტის შესაბამისათვის. ჩვენი წარმოდგენება მხოლოდ MTEQA პროგრამეტზე დააყენება. WMT20 განსაზღვრებული მონაცემების განსაზღვრების გამოცდილებები აჩვენებენ, რომ MTEQA მეტრიკაში სხვა განსაზღვრების განსაზღვრებით შემდგომარებულია სხვა განსაზღვრებით, რომელიც მხოლოდ განსაზღვრებული ინფორმა', 'it': "In questo articolo, descriviamo la nostra presentazione al WMT 2021 Metrics Shared Task. Utilizziamo le domande e le risposte generate automaticamente per valutare la qualità dei sistemi di traduzione automatica (MT). La nostra presentazione si basa sul framework MTEQA recentemente proposto. Esperimenti su set di dati di valutazione WMT20 mostrano che a livello di sistema la metrica MTEQA raggiunge prestazioni paragonabili ad altre soluzioni all'avanguardia, considerando solo una certa quantità di informazioni provenienti dall'intera traduzione.", 'lt': 'Šiame dokumente apibūdiname savo pranešimą WMT 2021 Metrics Shared Task. Mes naudojame automatiškai susidariusius klausimus ir atsakymus vertindami mašinų vertimo (MT) sistemų kokybę. Mūsų pasiūlymas grindžiamas neseniai pasiūlyta MTEQA sistema. Experiments on WMT20 evaluation datasets show that at the system-level the MTEQA metric achieves performance comparable with other state-of-the-art solutions, while considering only a certain amount of information from the whole translation.', 'mk': 'Во овој весник, го опишуваме нашето поднесување на WMT 2021 Metrics Shared Task. Ние ги користиме автоматски генерираните прашања и одговори за проценка на квалитетот на системите за машински превод (MT). Нашето поднесување се базира на неодамна предложената рамка на МТЕКА. Експериментите на податоците за проценка на ВМТ20 покажуваат дека на системско ниво метриката на МТЕКА постигнува перформанси споредливи со другите најсовремени решенија, при што се разгледува само одредена количина информации од целиот превод.', 'kk': 'Бұл қағазда, WMT 2021 метрикалық ортақтастырылған тапсырмаға жіберімізді анықтаймыз. Компьютердің аудармалы жүйелердің сапатын бағалау үшін автоматты түрде құрылған сұрақтар мен жауаптарды қолданамыз. Біздің жуырдағы MTEQA бағдарламасына қолданып тұрмыз. WMT20 бағалау деректер жиындарының тәжірибесі, MTEQA метрикалық жүйелік деңгейінде басқа орындау шешімдерімен салыстырылатын ықтималдығын көрсетеді, бірақ толық аудармадан тек бірнеше мәліметтің бөлігін қалай', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d WMT 2021 മെറ്റിക്സ് പങ്കെടുത്ത പണിയിലേക്ക് നമ്മുടെ സന്ദേശം വിശദീകരിക്കുന്നു. നമ്മള്\u200d സ്വയമായി ഉണ്ടാക്കപ്പെട്ട ചോദ്യങ്ങളും ഉത്തരം ഉപയോഗിക്കുന്നു. മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിന്\u200dറെ ഗുണവും  Our submission builds upon the recently proposed MTEQA framework.  WMT20 വില വിലാസങ്ങളുടെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നുവെങ്കില്\u200d സിസ്റ്റത്തിന്റെ നിലയില്\u200d MTEQA മെറ്റിക്ക് പ്രവര്\u200dത്തിപ്പിക്കുന്നത് മറ്റു രാജ്യത്തില', 'mt': 'F’dan id-dokument, aħna niddeskrivu s-sottomissjoni tagħna lill-Metriks Shared Task WMT 2021. Aħna nużaw il-mistoqsijiet u t-tweġibiet ġenerati awtomatikament biex jevalwaw il-kwalità tas-sistemi tat-Traduzzjoni tal-Magni (MT). Is-sottomissjoni tagħna tibni fuq il-qafas tal-MTEQA propost reċentement. Esperimenti fuq settijiet ta’ dejta ta’ evalwazzjoni WMT20 juru li fil-livell tas-sistema l-metrika MTEQA tikseb prestazzjoni komparabbli ma’ soluzzjonijiet l-aktar avvanzati oħra, filwaqt li tikkunsidra biss ċertu ammont ta’ informazzjoni mit-traduzzjoni kollha.', 'ms': 'Dalam kertas ini, kami menggambarkan penghantaran kami kepada Tugas Berkongsi Metriks WMT 2021. Kami menggunakan soalan dan jawapan yang dijana secara automatik untuk menilai kualiti sistem Terjemahan Mesin (MT). Pemberian kami berdasarkan kerangka MTEQA yang diusulkan baru-baru ini. Eksperimen pada set data penilaian WMT20 menunjukkan bahawa pada aras sistem metrik MTEQA mencapai prestasi yang boleh dibandingkan dengan penyelesaian-penyelesaian state-of-the-art lain, sementara mempertimbangkan hanya sejumlah maklumat tertentu dari seluruh terjemahan.', 'no': 'I denne papiret beskriver vi tillegget til WMT 2021 metriske delt oppgåve. Vi bruker dei automatisk genererte spørsmålene og svara for å evaluera kvaliteten til maskinsomsetjingssystemet (MT). Vårt søknad bygger på den nyleg foreslåde MTEQA-rammeverket. Eksperimentar på WMT20-evalueringsdatasett viser at MTEQA-metrikken når systemnivået gjer utviklinga sammenlignbar med andre kunstløysingar, mens du gjer berre ein viss mengd informasjon frå heile omsetjinga.', 'mn': 'Энэ цаасан дээр бид WMT 2021 метрик хуваалтын ажил дээр дамжуулалтыг тайлбарлаж байна. Бид автоматаар үүсгэсэн асуултууд болон хариултуудыг машин хөгжүүлэх (MT) системийн сайн чанарыг үнэлэхэд ашигладаг. Бидний хүлээн зөвшөөрөх нь саяхан MTEQA-ын төлөвлөгөө дээр байдаг. WMT20 үнэлгээний өгөгдлийн сангийн туршилтууд системийн түвшинд MTEQA метрийн үйл ажиллагааг бусад урлагийн шийдэлтэй харьцуулах боломжтой болгодог гэдгийг харуулдаг.', 'pl': 'W niniejszym artykule opisujemy naszą zgłoszenie do WMT 2021 Metrics Shared Task. Wykorzystujemy automatycznie generowane pytania i odpowiedzi do oceny jakości systemów tłumaczenia maszynowego (MT). Nasz wniosek opiera się na niedawno zaproponowanych ramach MTEQA. Eksperymenty na zbiorach danych oceny WMT20 pokazują, że na poziomie systemu metryka MTEQA osiąga wydajność porównywalną z innymi najnowocześniejszymi rozwiązaniami, przy jednoczesnym uwzględnieniu tylko pewnej ilości informacji z całego tłumaczenia.', 'ro': 'În această lucrare, descriem depunerea noastră la WMT 2021 Metrics Shared Task. Utilizăm întrebările și răspunsurile generate automat pentru a evalua calitatea sistemelor de traducere automată (MT). Prezentarea noastră se bazează pe cadrul MTEQA propus recent. Experimentele efectuate pe seturi de date de evaluare WMT20 arată că la nivel de sistem metrica MTEQA atinge performanțe comparabile cu alte soluții de ultimă generație, luând în considerare doar o anumită cantitate de informații din întreaga traducere.', 'sr': 'U ovom papiru opisujemo svoju predanost podijeljenom zadatku WMT 2021 metrika. Koristimo automatski generirane pitanja i odgovore za procjenu kvalitete sustava za prevod mašine (MT). Naša predanost se osnova na nedavno predloženom okviru MTEQA. Eksperimenti o podacima za procjenu WMT20 pokazuju da na nivou sistema metrika MTEQA postiže usporednost sa drugim stanjem umjetnosti rješenja, dok razmatra samo određenu količinu informacija iz cijelog prevoda.', 'ta': 'இந்த காகிதத்தில், நாம் WMT 2021 மெட்ரிக்ஸ் பகிர்ந்த பணிக்கு எங்கள் சரணங்களை விவரிக்கிறோம். நாங்கள் தானாகவே உருவாக்கப்பட்ட கேள்விகள் மற்றும் பதில்களை பயன்படுத்தி இயந்திர மொழிபெயர்ப்பு மொழிமாற்றும் அமைப் சமீபத்தில் MTEQA சட்டத்தில் எங்கள் உத்தரவு கட்டுகிறது. WMT20 மதிப்பீடு தரவுத்தளங்களின் சோதனைகள் கணினி மட்டத்தில் MTEQA மெட்ரிக் செயல்பாட்டை செய்யும் மற்ற நிலையில் கலை தீர்வுகளுடன் ஒப்பிடுகிறது, முழு மொழ', 'si': 'මේ පත්තරේ අපි WMT 2021 මීට්\u200dරික් එක්ක කාර්යාලයට අපේ පිළිගන්න විස්තර කරනවා. අපි ස්වයංක්\u200dරමයෙන් නිර්මාණය කරපු ප්\u200dරශ්න සහ ප්\u200dරතිචාරය පාවිච්චි කරන්න යන්ත්\u200dර පද්ධතියේ විශේ අපේ පිළිගන්නේ අවස්ථානයේ MTEQA සංවිධානයක් නිර්මාණය කරනවා. WMT20 විශ්වාස දත්ත සෙට්ටුවේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට MTEQA මෙට්\u200dරික් පරීක්ෂණය අනිත් ස්ථිතියේ ක්\u200dරියාත්මක විශේෂණය සමග ස', 'so': "Warqadan, waxaynu ku qornaa warqaddayada warqadda loo soo diro WMT 2021 Metrics Shared Shaqada. Waxaynu isticmaalnaa su'aalaha iyo jawaabaha si aan u qiimeyno nidaamka turjumidda Masiinka (MT). Our submission builds upon the recently proposed MTEQA framework.  Imtixaamo ku saabsan qoraalka qiimeynta ee WMT20 waxay muuqataa in heerka nidaamka MTEQA metric wuxuu gaadhaa sameynta si u eg xalalka kale ee dowladda farshaxanka, isagoo ka fiirsanaya macluumaad kamid ah oo ku saabsan turjumaadka oo dhan.", 'ur': 'اس کاغذ میں ہم نے WMT 2021 میٹریک شریک ٹاکس کی تحویل کی۔ ہم اپنے ساتھ پیدا کئے ہوئے سوال اور جواب استعمال کرتے ہیں ماشین ترجمہ (MT) سیستموں کی کیفیت کا ارزش کرنے کے لئے۔ ہماری مسلمانیت اخیرا پیشنهاد MTEQA فرم پر بنتی ہے. WMT20 ارزیابی ڈیٹ سٹ پر تجربے دکھاتے ہیں کہ سیسٹم-سٹم میں MTEQA متریک نے دوسرے ایٹ-آرت کے حل کے ساتھ مقایسہ کی عملکرد حاصل کرتی ہے، حالانکہ صرف ایک مقدار معلومات کو تمام ترجمہ سے سمجھتے ہیں.', 'sv': 'I denna uppsats beskriver vi vårt bidrag till WMT 2021 Metrics Shared Task. Vi använder de automatiskt genererade frågorna och svaren för att utvärdera kvaliteten på maskinöversättningssystem. Vårt bidrag bygger på det nyligen föreslagna ramverket för MTEQA. Experiment på WMT20 utvärderingsdata visar att MTEQA-mätaren på systemnivå uppnår prestanda jämförbara med andra toppmoderna lösningar, samtidigt som man endast beaktar en viss mängd information från hela översättningen.', 'uz': 'In this paper, we describe our submission to the WMT 2021 Metrics Shared Task.  Biz avtomatik yaratilgan savollar va javoblarni foydalanamiz, Mashine tarjima tizimning (MT) sifatini qiymatlashga. Yaqinda ishlatilgan MTEQA freymini yaratadi. Name', 'vi': 'Trong tờ giấy này, chúng tôi mô tả sự chịu trách nhiệm của chúng tôi cho công việc chia sẻ WM 2021. Chúng tôi sử dụng các câu hỏi và câu trả lời tự động để đánh giá chất lượng của máy Dịch (MTV) hệ thống. Việc đệ trình của chúng ta dựa trên cơ cấu tổ chức MTV mới. Thử nghiệm trên các tập tin đánh giá của WM cho thấy, hệ thống trên với hệ thống, đo lường tổ chức MTV đạt đến hiệu suất tương đương với các giải pháp hiện đại, trong khi xem xét chỉ một số thông tin nhất định từ toàn bộ bản dịch.', 'bg': 'В тази статия описваме нашето представяне към Споделената задача за измерване на метриците за 2021 г. Ние използваме автоматично генерирани въпроси и отговори, за да оценим качеството на системите за машинен превод (МТ). Нашето представяне се основава на наскоро предложената рамка за МТЕКА. Експерименти с данни за оценка на WMT20 показват, че на системно ниво показателят постига резултати, сравними с други съвременни решения, като същевременно отчита само определено количество информация от целия превод.', 'hr': 'U ovom papiru opisujemo naše podatke podijeljenom zadatku WMT 2021 metrika. Koristimo automatski proizvedena pitanja i odgovore za procjenu kvalitete sustava prevoda strojeva (MT). Naša podnošenja se temelji na nedavno predloženom okviru MTEQA-a. Eksperimenti o podacima za procjenu WMT20 pokazuju da na razini sustava metrika MTEQA postiže usporedbu s drugim stanjem umjetnosti rješenja, dok se razmatra samo određena količina informacija iz cijelog prevoda.', 'nl': 'In dit artikel beschrijven we onze inzending aan de WMT 2021 Metrics Shared Task. Wij gebruiken de automatisch gegenereerde vragen en antwoorden om de kwaliteit van Machine Translation (MT) systemen te evalueren. Onze indiening bouwt voort op het onlangs voorgestelde MTEQA-kader. Experimenten met WMT20 evaluatiedatasets tonen aan dat de MTEQA metric op systeemniveau prestaties behaalt die vergelijkbaar zijn met andere state-of-the-art oplossingen, terwijl slechts een bepaalde hoeveelheid informatie uit de hele vertaling in aanmerking wordt genomen.', 'da': 'I denne artikel beskriver vi vores indsendelse til WMT 2021 Metrics Shared Task. Vi bruger de automatisk genererede spørgsmål og svar til at evaluere kvaliteten af maskinoversættelsessystemer. Vores indlæg bygger på den nyligt foreslåede MTEQA-ramme. Eksperimenter med WMT20 evalueringsdatasæt viser, at MTEQA-metrikken på systemniveau opnår ydeevne sammenlignelige med andre state-of-the-art løsninger, samtidig med at der kun tages hensyn til en vis mængde information fra hele oversættelsen.', 'ko': '본고에서 우리는 WMT 2021 메트릭 공유 임무에 제출한 상황을 묘사했다.우리는 자동적으로 생성된 문제와 답안을 사용하여 기계번역(MT) 시스템의 질을 평가한다.우리가 제출한 문서는 최근에 제출한 MTEQA 프레임워크를 바탕으로 한다.WMT20 평가 데이터 집합에서의 실험에 따르면 시스템급에서 MTEQA 지표는 다른 최첨단 해결 방안과 비슷한 성능을 실현했고 전체 번역 중의 일정 수량의 정보만 고려했다.', 'id': 'Dalam kertas ini, kami menggambarkan penyerahan kami ke WMT 2021 Metrics Shared Task. Kami menggunakan pertanyaan dan jawaban yang dibuat secara otomatis untuk mengevaluasi kualitas sistem Translation Mesin (MT). Pengiriman kami dibangun pada cadangan MTEQA yang baru-baru ini diusulkan. Eksperimen pada set data evaluasi WMT20 menunjukkan bahwa pada tingkat sistem metrik MTEQA mencapai prestasi yang dapat dibandingkan dengan solusi terbaik lainnya, sementara mempertimbangkan hanya jumlah tertentu informasi dari seluruh terjemahan.', 'de': 'In diesem Beitrag beschreiben wir unsere Einreichung zum WMT 2021 Metrics Shared Task. Anhand der automatisch generierten Fragen und Antworten bewerten wir die Qualität von maschinellen Übersetzungssystemen. Unsere Einreichung baut auf dem kürzlich vorgeschlagenen MTEQA Framework auf. Experimente an WMT20-Auswertungsdatensätzen zeigen, dass die MTEQA-Metrik auf Systemebene eine mit anderen State-of-the-Art-Lösungen vergleichbare Leistung erzielt, wobei nur eine bestimmte Menge an Informationen aus der gesamten Übersetzung berücksichtigt wird.', 'sw': 'Katika gazeti hili, tunaelezea ujumbe wetu wa metric za WMT 2021 zilizoshirikishwa na kazi. Tunatumia maswali na majibu yanayozaliwa kwa wenyewe ili kutathmini ubora wa mfumo wa Tafsiri wa Mashine (MT). Ujumbe wetu unajenga kwenye mfumo wa hivi karibuni unapendekezwa na MTEQA. Jaribio la taarifa za uchunguzi wa WMT20 zinaonyesha kuwa katika ngazi za mfumo mfumo mbinu za MTEQA hufanikiwa utendaji unaofanana na suluhisho nyingine za sanaa, wakati wakifikiria kiasi fulani cha taarifa kutoka kwenye tafsiri yote.', 'tr': 'Bu kagyzda WMT 2021 metrikler bölüniş zada rugsat berdik. Makina terjime sistemleriniň kalitesini çözmek üçin otomatik üretilen soraglary we jogaplary ulanýarys. Biziň hökmümiz soňky täze MTEQA frameworkynda guruldy. WMT20 deňlenme veri tesbitleri sistemiň derejesinde MTEQA metriýasynyň başga çözümleri bilen hoýgörülýän çözümleri çykarýar we diňe bütin terjimedeniň beýleki hili maglumaty diýip pikir edýär.', 'af': "In hierdie papier beskrywe ons onderskrywing aan die WMT 2021 metries deelde taak. Ons gebruik die outomaties genereerde vrae en antwoorde om die kwaliteit van masjien vertaling (MT) stelsels te evalueer. Ons ondersteuning bou op die onlangs voorgestelde MTEQA raamwerk. Eksperimente op WMT20-evalueringsdatastel vertoon dat op die stelsel-vlak die MTEQA-metrie uitvoerings vergelykbaar bereik word met ander staat-van-die-kuns-oplossings, terwyl slegs 'n sekere hoeveelheid inligting van die hele vertaling aanneem.", 'sq': 'Në këtë letër, ne përshkruajmë dorëzimin tonë në WMT 2021 Metrics Shared Task. Ne përdorim pyetjet dhe përgjigjet e krijuara automatikisht për të vlerësuar cilësinë e sistemeve të përkthimit të makinave (MT). Përdorimi ynë mbështetet në kuadrin e propozuar kohët e fundit të MTEQA. Experiments on WMT20 evaluation datasets show that at the system-level the MTEQA metric achieves performance comparable with other state-of-the-art solutions, while considering only a certain amount of information from the whole translation.', 'am': 'በዚህ ፕሮግራም፣ ለWMT 2021 ማትሪክ ስራ የተሰራጨውን አዋጅ እናሳውቃለን፡፡ የመኪን ትርጉም (MT) ስርዓት ጥያቄዎችን ለማስተካከል እናጠይቃለን፡፡ አቀኑ በተፈጸመ MTEQA ፍሬማት ላይ ይሠራል፡፡ Experiments on WMT20 evaluation datasets show that at the system-level the MTEQA metric achieves performance comparable with other state-of-the-art solutions, while considering only a certain amount of information from the whole translation.', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք մեր ներկայացումը 2021 թվականի աշխարհի մետրիկայի ընդհանուր խնդրին: Մենք օգտագործում ենք ինքնաբերաբար ստեղծված հարցեր և պատասխաններ մեքենայի թարգմանման (MT) համակարգերի որակի գնահատելու համար: Մեր ներկայացումը հիմնված է վերջերս առաջարկված MTEQA-ի շրջանակի վրա: ՎԱՄԹ20-ի գնահատման տվյալների համակարգերի փորձարկումները ցույց են տալիս, որ համակարգչային մակարդակում MTEQA-ը համեմատական արդյունք է հասնում մյուս ամենահետաքրքիր լուծումների հետ, հաշվի առնելով միայն որոշ տեղեկատվություն ամբողջ թարգմանությունից:', 'az': 'Bu kańüńĪzda WMT 2021 metrik paylaŇüńĪlmńĪŇü iŇü iŇü…ô t…ôsdiql…ônm…ôyimizi tarif edirik. Biz maŇüńĪn √áeviri sisteml…ôrin kalitetini deńüerl…ôŇüdirm…ôk √ľ√ß√ľn avtomatik olaraq t…ôŇükil edilmiŇü suallarńĪ v…ô cavablarńĪnńĪ istifad…ô edirik. Bizim m√ľs…ôlmanńĪmńĪz yeni t…ôklif edilmiŇü MTEQA qurńüusu √ľz…ôrind…ô inŇüa edir. WMT20 deńüerlendirm…ô veril…ônl…ôrin sńĪnaqlarńĪ sistem seviyy…ôtind…ô MTEQA metrik baŇüqa Ňü…ôkild…ô m√ľ…ôyy…ôn edil…ôn √ß…ôtinlikl…ôrl…ô qarŇüńĪlaŇüdńĪrńĪlmńĪŇü performanslarńĪ baŇüqa √ß…ôtinlikl…ôrl…ô m√ľ…ôyy…ôn edir, yalnńĪz b√ľt√ľn √ßevirind…ôn b…ôzi m…ôlumatlar d√ľŇü√ľn√ľrl…ôr.', 'fa': 'در این کاغذ، ما تحویل ما را به وظیفه مشترک متریک WMT 2021 توصیف می کنیم. ما از سوالات و جواب\u200cهایی که از خودکار تولید شده\u200cاند استفاده می\u200cکنیم تا کیفیت سیستم\u200cهای ترجمه ماشین (MT) را ارزیابی کنیم. تسلیم ما بر روی چهارچوب MTEQA پیشنهاد اخیر بسته است. تجربه\u200cهای داده\u200cهای ارزیابی WMT20 نشان می\u200cدهند که در سطح سیستم متریک MTEQA با راه حل\u200cهای دیگر هنری قابل مقایسه انجام می\u200cشود، در حالی که تنها یک مقدار اطلاعات خاص از کل ترجمه را در نظر می\u200cگیرد.', 'ca': "En aquest article, descrivim la nostra presentació a la World Metrics Shared Task 2021. Utilitzem les preguntes i respostes generades automàticament per avaluar la qualitat dels sistemes de traducció màquina. La nostra presentació es basa en el marc proposat recentment per l'AQMT. Els experiments en conjunts de dades d'evaluació WMT20 mostren que a nivell sistemàtic la mètrica MTEQA aconsegueix un rendiment comparable amb altres solucions més avançades, mentre considerant només una certa quantitat d'informació de tota la traducció.", 'bn': 'এই পত্রিকায় আমরা উইএমটি ২০২১ মেট্রিক শেয়ার করা কাজের প্রতি আমাদের প্রতিষ্ঠান বর্ণনা করি। আমরা স্বয়ংক্রিয়ভাবে উৎপাদন করা প্রশ্ন এবং উত্তর ব্যবহার করি মেশিন অনুবাদের মান মূল্যায়নের জন্য। সম্প্রতি প্রস্তাবিত MTEQA ফ্রেমের উপর আমাদের আত্মসমর্পণ বানানো হয়েছে। WMT20 মুল্যায়ন ডাটাসেটের পরীক্ষা দেখা যাচ্ছে যে সিস্টেম-স্তরে MTEQA মেট্রিক কে অন্যান্য রাষ্ট্র-শিল্পের সমাধানের সাথে সমাধানের সাথে তুলনায় প্', 'cs': 'V tomto článku popisujeme náš příspěvek k WMT 2021 Metrics Shared Task. Automaticky generované otázky a odpovědi využíváme k hodnocení kvality systémů strojového překladu (MT). Náš příspěvek vychází z nedávno navrženého rámce MTEQA. Experimenty na vyhodnocovacích datových sadách WMT20 ukazují, že metrika MTEQA na systémové úrovni dosahuje výkonu srovnatelného s ostatními moderními řešeními, přičemž bere v úvahu pouze určité množství informací z celého překladu.', 'bs': 'U ovom papiru opisujemo svoju predanost podijeljenom zadatku WMT 2021 metrika. Koristimo automatski generirane pitanja i odgovore za procjenu kvalitete sustava prevoda mašine (MT). Naša predstava se temelji na nedavno predloženom okviru MTEQA-a. Eksperimenti o podacima za procjenu WMT20 pokazuju da na nivou sustava metrika MTEQA postiže usporedbu s drugim stanjem umjetnosti rješenja, dok se razmatra samo određena količina informacija iz cijelog prevoda.', 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvailemme julkaisuamme WMT 2021 Metrics Shared Task -tehtﾃ､vﾃ､ﾃ､n. Kﾃ､ytﾃ､mme automaattisesti luotuja kysymyksiﾃ､ ja vastauksia konekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmien laadun arviointiin. Lausuntomme perustuu ﾃ､skettﾃ､in ehdotettuun MTEQA-kehykseen. WMT20-arviointiaineistoilla tehdyt kokeet osoittavat, ettﾃ､ jﾃ､rjestelmﾃ､tasolla MTEQA-mittari saavuttaa suorituskyvyn, joka on verrattavissa muihin viimeisimpiin ratkaisuihin, ottaen huomioon vain tietyn mﾃ､ﾃ､rﾃ､n tietoa koko kﾃ､ﾃ､nnﾃｶksestﾃ､.', 'et': 'Selles artiklis kirjeldame oma esitamist WMT 2021 meetrite jagatud ülesandele. Kasutame automaatselt genereeritud küsimusi ja vastuseid masintõlke (MT) süsteemide kvaliteedi hindamiseks. Meie ettepanek põhineb hiljuti kavandatud MTEQA raamistikul. WMT20 hindamisandmekogumitega tehtud katsed näitavad, et süsteemi tasandil saavutab MTEQA mõõdik jõudluse, mis on võrreldav teiste kaasaegsete lahendustega, võttes arvesse ainult teatavat kogu tõlke teavet.', 'ha': "Ga wannan takardan, Munã bayyana injinmu zuwa WMT 2021 Metrics Shared Takar. Munã amfani da masu tambayar da aka ƙãga farat ɗaya da ake karɓa dõmin Mu evaluate tsarin tarjima na MT. Musuluncinmu na samar a kan firam na MTeQA na farkon da aka buƙata. Tajararin da ke kan tsarin evaluation na WMT20 na nuna cewa, metric na MTeQA na sami da wasu fassarar-na-kunyar, kuma idan kun yi tunãni kawai, ma'abun tsari daga fassarar-jumla kawai.", 'sk': 'V tem prispevku opisujemo našo predložitev v skupno opravilo meritev WMT 2021. Samodejno ustvarjena vprašanja in odgovore uporabljamo za oceno kakovosti sistemov strojnega prevajanja (MT). Naša predloga temelji na nedavno predlaganem okviru MTEQA. Eksperimenti z vrednotenjskimi nabori podatkov WMT20 kažejo, da merilnik MTEQA na sistemski ravni dosega zmogljivost, primerljivo z drugimi najsodobnejšimi rešitvami, pri čemer upošteva le določeno količino informacij iz celotnega prevoda.', 'jv': 'Nang pemilih iki, kita ngubah ngerasakno kanggo ngerasakno ning Mbak Metric Common Awak dhéwé nggunaké perusahaan-perusahaan lan mbutuhak kanggo nggunakake kuwi nggawe sistem Anyar Terjamahan (MT). Rasané awak dhéwé nggawe barang tambah karo sistem MTeqA sing nyenggawe Name', 'bo': 'ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་WMT 2021 རིང་ཐོག་ལས་དབུས་མཐུན་གྱི་ལས་ཀ་ལ་འགྲེལ་བཤད་པ་ཡིན། ང་ཚོས་རང་འགུལ་གྱིས་རང་འགུལ་གྱིས་གསར་བསྐྲུན་པའི་དྲི་ཚིག་དང་ལན་གསལ་བཤད་པ་དེ་ལག་ལེན་འཐབ་ཡོད་པ ང་ཚོའི་ཞབས་ཞུ་བ་ནི་ཉེ་ཆར་བྱུང་བའི་MTEQA དྲ་གཞི་བཟོ་སྐྲུན་ཡོད། Experiments on WMT20 evaluation datasets show that at the system-level the MTEQA metric achieves performance comparable with other state-of-the-art solutions, while considering only a certain amount of information from the whole translation.', 'he': 'בעיתון הזה, אנחנו מתארים את ההעברה שלנו למשימה המשותפת של מטריקס WMT 2021. אנו משתמשים בשאלות והתשובות המיוצרות באוטומטית כדי להעריך את איכות מערכות התרגום המכונית (MT). ההצגה שלנו בונה על המסגרת המוצעת לאחרונה של MTEQA. ניסויים על קבוצות מידע הערכה WMT20 מראים שברמת המערכת מטריקה MTEQA משיגה ביצועים שווים עם פתרונות חדשים אחרים, בעוד שוקלים רק כמות מסוימת של מידע מכל התרגום.'}
{'en': 'Are References Really Needed? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'es': '¿Son realmente necesarias las referencias? Presentación de Unbabel-ist 2021 para la tarea compartida de métricas', 'ar': 'هل المراجع مطلوبة حقًا؟ تقديم Unbabel-IST 2021 لمهمة المقاييس المشتركة', 'fr': 'Les références sont-elles vraiment nécessaires\xa0? Soumission Unbabel-IST 2021 pour la tâche partagée Metrics', 'pt': 'As referências são realmente necessárias? Submissão Unbabel-IST 2021 para a Tarefa Partilhada de Métricas', 'ja': '参考文献は本当に必要ですか？ Unbabel - IST 2021メトリクス共有タスクのサブミッション', 'ru': 'Действительно ли необходимы ссылки? Заявка Unbabel-IST 2021 для задачи «Общие метрики»', 'zh': '果须参考文献乎? 去标记 IST 2021 指标共事者', 'hi': 'क्या संदर्भ वास्तव में आवश्यक हैं? मेट्रिक्स साझा कार्य के लिए अनबेबल-आईएसटी 2021 सबमिशन', 'ga': 'An bhfuil Teistiméireachtaí de Dhíth ag Teastáil? Unbabel-IST 2021 Aighneacht don Tasc Comhroinnte Méadrachta', 'ka': 'რეფერენციები მნიშვნელოვანია? Unbabel-IST 2021 მეტრიკის გაყოფილი საქმე', 'hu': 'Tényleg szükség van a referenciára? Unbabel-IST 2021 Beküldés a Metrics megosztott feladathoz', 'el': 'Χρειάζονται πραγματικά αναφορές; Unbabel-IST 2021 Υποβολή για την Κοινή Εργασία Μετρικών', 'it': "Sono davvero necessarie referenze? Presentazione di Unbabel-IST 2021 per l'attività condivisa Metrics", 'lt': 'Ar nuorodos tikrai reikalingos? Unbabel-IST 2021 Metrikų bendros užduoties pateikimas', 'kk': 'Шынымен сілтемелер керек пе? Unbabel-IST 2021 метрикалық ортақтастырылған тапсырма үшін жіберу', 'ml': 'റെഫറന്\u200dസുകള്\u200d ശരിക്കും ആവശ്യമുണ്ടോ? മെറ്റ്രിക്സ് പങ്കാളിയുള്ള ജോലിക്കുള്ള അണ്\u200dബാബേല്\u200d- IST 2021 Submission', 'mn': 'References Really Need? Unbabel-IST 2021 Metrics Shared Task for the Metrics Submission', 'mk': 'Дали навистина се потребни референции? Предложение на Unbabel-IST 2021 за заедничката задача на Метрика', 'no': 'Er referanser verkeleg nødvendig? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'ms': 'Adakah Rujukan benar-benar diperlukan? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'mt': 'Hemm bżonn ta’ Referenzi verament? Sottomissjoni Unbabel-IST 2021 għall-Kompitu Konġunt tal-Metriki', 'ro': 'Sunt cu adevărat nevoie de referinţe? Unbabel-IST 2021 Trimitere pentru sarcina partajată Metrics', 'si': 'ඇත්තටම අවශ්\u200dයද? අන්බාබෙල්-IST 2021 මෙට්\u200dරික්ස් එක්කම් වැඩක් වෙනුවෙන් ප්\u200dරධානය', 'so': 'Ma xaqiiqa loo baahan yahay? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'pl': 'Czy referencje są naprawdę potrzebne? Unbabel-IST 2021 Zgłoszenie do wspólnego zadania metryki', 'sv': 'Behövs referenser verkligen? Unbabel-IST 2021 Inlämning för den delade uppgiften Metrics', 'ta': 'குறிப்புகள் உண்மையில் தேவைப்படுகிறதா? மெட்ரிக்ஸ் பகிர்ந்த பணிக்கு Unbabel- IST 2021 Submission', 'sr': 'Da li je stvarno potrebna referencija? Unbabel-IST 2021 podmission za podeljeni zadatak metrika', 'ur': 'کیا مرتبہ سچ ضرورت ہے؟ Unbabel-IST 2021 Submission for the Metrics Shared Task', 'vi': 'Có cần tham chiếu không? NAME OF TRANSLATORS', 'uz': 'References Unbabel- IST 2021 Submission for the Metrics Shared Vazifalar', 'nl': 'Zijn referenties echt nodig? Unbabel-IST 2021 Inzending voor de Gedeelde Metrics Task', 'bg': 'Наистина ли са необходими препоръки? Представяне за споделената задача за метрици', 'de': 'Sind Referenzen wirklich erforderlich? Unbabel-IST 2021 Einreichung für die gemeinsame Aufgabe Metriken', 'ko': '정말 추천자가 필요한가요?메트릭 공유 작업의 IST 2021 커밋 취소 레이블', 'da': 'Er referencer virkelig nødvendige? Unbabel-IST 2021 Indsendelse til Metrics delte opgave', 'hr': 'Da li je stvarno potrebna referencija? Unbabel-IST 2021 Podmission za dijeljeni zadatak metrika', 'id': 'Apakah Referensi Benarkah Dibutuhkan? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'af': 'Is verwysing regtig benodig? Unbabel-IST 2021 Submission vir die Metrike Gedeelde Taak', 'sw': 'Je, maoni yanahitajika kweli? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'fa': 'ارتباط واقعا لازمه؟ نابابل-IST 2021', 'tr': 'Çeşmeler hakykatdanam gerek? Submission for the Metrics Shared Task', 'az': 'Referanslar Gerçekten İhtiyardır? Unbabel-IST 2021 Metrics Shared Task Submission for the Metrics Shared Task', 'sq': 'A janë vërtet të nevojshme referime? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'am': 'ምርጫዎች በእውነት ያስፈልጋሉ? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'bs': 'Da li je stvarno potrebna referencija? Unbabel-IST 2021 podmission za podijeljeni zadatak metrika', 'hy': 'Իսկապե՞ս անհրաժեշտ են նշաններ: UNBABEL-INSTA 2021', 'bn': 'রেফারেন্স কি সত্যিই দরকার? মেট্রিক ভাগাভাগি করা কাজের জন্য আনবাবেল-IST ২০21 সাবমিশন', 'cs': 'Jsou reference opravdu potřebné? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'et': 'Kas soovitusi on tõesti vaja? Unbabel-IST 2021 Mõõdikute jagatud ülesande esitamine', 'fi': 'Tarvitaanko suosituksia? Unbabel-IST 2021 Lähetys Metrics Shared Task -tehtävään', 'ca': 'Are References Really Needed?  Unbabel-IST 2021 Submission for the Metrics Shared Task', 'jv': 'tutorial_basic Unbabel-IsT 2020 1 Submis kanggo Metric Joined Job', 'ha': 'Shin, ana ƙayyade References Gawa? Unbabel-IST 2021 Submission for the Metrics Shared Task', 'he': 'האם רמזים באמת זקוקים? Unbabel-IST 2021 הגישה למשימה משותפת Metrics', 'sk': 'Ali so reference res potrebne? Unbabel-IST 2021 Prijava za skupno opravilo meril', 'bo': 'ཁུངས་གཏུགས་ཡིན་མིན་དགོས་སམ Unbabel-IST 2021 Metrics Shared Task for the Submission for the Metrics'}
{'en': 'In this paper, we present the joint contribution of Unbabel and IST to the WMT 2021 Metrics Shared Task. With this year’s focus on Multidimensional Quality Metric (MQM) as the ground-truth human assessment, our aim was to steer COMET towards higher correlations with MQM. We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores. In our experiments we also show that reference-free COMET models are becoming competitive with reference-based models, even outperforming the best COMET model from 2020 on this year’s development data. Additionally, we present COMETinho, a lightweight COMET model that is 19x faster on ', 'ar': 'في هذه الورقة ، نقدم مساهمة Unbabel و IST المشتركة في مهمة المقاييس المشتركة WMT 2021. مع تركيز هذا العام على مقياس الجودة متعدد الأبعاد (MQM) باعتباره التقييم البشري الواقعي ، كان هدفنا هو توجيه نظام COMET نحو ارتباطات أعلى مع MQM. نقوم بذلك عن طريق التدريب المسبق أولاً على التقييمات المباشرة ثم ضبط درجات MQM المعيارية z. في تجاربنا ، نظهر أيضًا أن نماذج COMET الخالية من المراجع أصبحت قادرة على المنافسة مع النماذج المستندة إلى المراجع ، حتى أنها تفوقت على أفضل طراز COMET اعتبارًا من عام 2020 وفقًا لبيانات التطوير لهذا العام. بالإضافة إلى ذلك ، نقدم COMETinho ، وهو نموذج COMET خفيف الوزن أسرع 19 مرة على وحدة المعالجة المركزية من النموذج الأصلي ، مع تحقيق ارتباطات متطورة مع MQM. أخيرًا ، في مسار "التيسير الكمي كمقياس" ، شاركنا أيضًا مع نموذج التيسير الكمي الذي تم تدريبه باستخدام إطار عمل OpenKiwi الذي يستفيد من نتائج MQM والتعليقات التوضيحية على مستوى الكلمات.', 'fr': "Dans cet article, nous présentons la contribution conjointe d'Unbabel et d'IST à la tâche partagée WMT 2021 Metrics. Avec l'accent mis cette année sur la métrique de qualité multidimensionnelle (MQM) en tant qu'évaluation humaine de terrain, notre objectif était d'orienter COMET vers des corrélations plus élevées avec le MQM. Pour ce faire, nous procédons d'abord à une formation préalable sur les évaluations directes, puis en affinant les scores MQM normalisés en z. Dans nos expériences, nous montrons également que les modèles COMET sans référence deviennent compétitifs par rapport aux modèles basés sur des références, surpassant même le meilleur modèle COMET de 2020 sur les données de développement de cette année. De plus, nous présentons ComeTinho, un modèle COMET léger qui est 19 fois plus rapide sur le processeur que le modèle original, tout en réalisant des corrélations de pointe avec MQM. Enfin, dans le volet «\xa0QE as a metric\xa0», nous avons également participé avec un modèle QE formé à l'aide du framework OpenKiwi utilisant les scores MQM et les annotations au niveau des mots.", 'pt': 'Neste artigo, apresentamos a contribuição conjunta da Unbabel e do IST para a Tarefa Partilhada de Métricas do WMT 2021. Com o foco deste ano na Métrica de Qualidade Multidimensional (MQM) como a avaliação humana de verdade, nosso objetivo foi orientar o COMET para correlações mais altas com o MQM. Fazemos isso primeiro fazendo um pré-treinamento em Avaliações Diretas e depois ajustando as pontuações MQM normalizadas em z. Em nossos experimentos, também mostramos que os modelos COMET sem referência estão se tornando competitivos com os modelos baseados em referência, superando até mesmo o melhor modelo COMET de 2020 nos dados de desenvolvimento deste ano. Além disso, apresentamos o COMEtinho, um modelo COMET leve que é 19x mais rápido na CPU do que o modelo original, além de obter correlações de última geração com MQM. Por fim, na trilha “QE as a metric”, também participamos com um modelo de QE treinado usando a estrutura OpenKiwi, aproveitando as pontuações do MQM e as anotações em nível de palavra.', 'es': 'En este artículo, presentamos la contribución conjunta de Unbabel e IST a la tarea compartida de métricas del WMT 2021. Con el enfoque de este año en la Métrica de Calidad Multidimensional (MQM) como la evaluación humana real sobre el terreno, nuestro objetivo era dirigir COMET hacia correlaciones más altas con MQM. Para ello, primero formamos previamente las evaluaciones directas y luego ajustamos las puntuaciones de MQM normalizadas en z. En nuestros experimentos también mostramos que los modelos COMET sin referencia se están volviendo competitivos con los modelos basados en referencias, incluso superando al mejor modelo COMET de 2020 en los datos de desarrollo de este año. Además, presentamos ComeTinho, un modelo COMET ligero que es 19 veces más rápido en CPU que el modelo original, a la vez que logra correlaciones de última generación con MQM. Por último, en la pista «QE as a metric», también participamos con un modelo de QE entrenado utilizando el marco OpenKiwi que aprovecha las puntuaciones de MQM y las anotaciones a nivel de palabras.', 'ja': 'この論文では、UnbabelとISTのWMT 2021メトリクス共有タスクへの共同貢献を紹介します。今年は、多次元品質メトリック（ MQM ）に焦点を当てて、真実の人間の評価として、彗星をMQMとのより高い相関に誘導することを目指しました。これは、まず直接評価の事前トレーニングを行い、次にz正規化されたmqmスコアを微調整することによって行われます。我々の実験では、リファレンスフリーコメットモデルは、リファレンスベースのモデルと競合するようになっており、2020年からのベストコメットモデルを上回る今年の開発データを示しています。さらに、軽量彗星モデルであるCOMETinhoを発表しました。これは、元のモデルよりもCPUで19倍速く、mqmとの最先端の相関も実現しています。最後に、「メトリックとしてのQE」トラックでは、mqmスコアとワードレベルアノテーションを活用して、OpenKiwiフレームワークを使用してトレーニングされたQEモデルも参加しました。', 'zh': '本文中,言 Unbabel 与 IST WMT 2021 指标共功。 今年之重,多维质量指标(MQM)为地真,吾道COMET与MQM更高之相关性。 先估预训练,然后微调 z 标准化 MQM 分。 于我实验中,吾等犹明COMET与参形相竞争力,至于今年之数过于2020年之最佳COMET。 此外示COMETinho,此一款轻量级之COMET形,其CPU倍于原始型号19,兼得与MQM之最新联。 终于"QE为指标"之程,与OpenKiwi框架训练之QE,当框架用MQM分数及单词级注教之。', 'hi': 'इस पेपर में, हम WMT 2021 मैट्रिक्स साझा कार्य के लिए Unbabel और IST के संयुक्त योगदान को प्रस्तुत करते हैं। जमीनी-सत्य मानव मूल्यांकन के रूप में बहुआयामी गुणवत्ता मीट्रिक (एमक्यूएम) पर इस साल के ध्यान के साथ, हमारा उद्देश्य एमक्यूएम के साथ उच्च सहसंबंधों की ओर धूमकेतु को आगे बढ़ाना था। हम पहले प्रत्यक्ष मूल्यांकन पर पूर्व-प्रशिक्षण और फिर जेड-सामान्यीकृत एमक्यूएम स्कोर पर ठीक-ट्यूनिंग करके ऐसा करते हैं। हमारे प्रयोगों में हम यह भी दिखाते हैं कि संदर्भ-मुक्त धूमकेतु मॉडल संदर्भ-आधारित मॉडल के साथ प्रतिस्पर्धी हो रहे हैं, यहां तक कि इस वर्ष के विकास डेटा पर 2020 से सर्वश्रेष्ठ धूमकेतु मॉडल को भी पीछे छोड़ रहे हैं। इसके अतिरिक्त, हम COMETinho, एक हल्के धूमकेतु मॉडल है कि मूल मॉडल की तुलना में सीपीयू पर 19x तेजी से है, जबकि यह भी MQM के साथ राज्य के अत्याधुनिक सहसंबंधों को प्राप्त करने के प्रस्तुत करते हैं। अंत में, "एक मीट्रिक के रूप में क्यूई" ट्रैक में, हमने एमक्यूएम स्कोर और शब्द-स्तरीय एनोटेशन का लाभ उठाने वाले ओपनकिवी फ्रेमवर्क का उपयोग करके प्रशिक्षित क्यूई मॉडल के साथ भी भाग लिया।', 'ru': 'В этой статье мы представляем совместный вклад Unbabel и IST в общую задачу по метрикам WMT 2021. В этом году мы сосредоточились на многомерной метрике качества (mqm) В качестве оценки человеческой истины, и наша цель заключалась в том, чтобы направить КОМЕТУ в сторону более высоких корреляций с MQM. Мы делаем это, сначала проводя предварительное обучение по прямым оценкам, а затем тонкую настройку по Z-НОРМАЛИЗОВАННЫМ баллам mqm. В наших экспериментах мы также показываем, что БЕСКОНТАКТНЫЕ МОДЕЛИ КОМЕТ становятся конкурентоспособными по сравнению с эталонными моделями, даже превосходя лучшую модель КОМЕТ 2020 года по данным разработки этого года. Кроме того, мы представляем COMETinho, легкую модель КОМЕТЫ, которая в 19 раз быстрее на процессоре, чем исходная модель, а также достигает современных корреляций с MQM. Наконец, в треке «QE как метрика» мы также участвовали с моделью QE, обученной с использованием фреймворка OpenKiwi, используя оценки mqm и аннотации на уровне слов.', 'ga': 'Sa pháipéar seo, cuirimid i láthair rannpháirtíocht Unbabel agus IST le Tasc Comhroinnte Méadracht WMT 2021. Le fócas na bliana seo ar Mhéadracht Cáilíochta Iltoiseach (MQM) mar mheasúnú daonna ar an bhfírinne ar an talamh, bhí sé mar aidhm againn COMET a threorú i dtreo comhghaolta níos airde le MQM. Déanaimid é sin trí réamhoiliúint a dhéanamh ar Mheasúnuithe Díreacha ar dtús agus ansin mionchoigeartú a dhéanamh ar scóir Z-normalaithe MQM. Inár dturgnaimh léirímid freisin go bhfuil samhlacha COMET saor ó thagairt ag éirí iomaíoch le samhlacha atá bunaithe ar thagairtí, fiú ag déanamh níos fearr ná an tsamhail COMET is fearr ó 2020 ar shonraí forbartha na bliana seo. Ina theannta sin, cuirimid i láthair COMETinho, múnla éadrom COMET atá 19x níos tapúla ar an LAP ná an tsamhail bhunaidh, agus ag an am céanna baintear amach comhghaolta úrscothacha le MQM. Ar deireadh, sa rian “QE as a méadrach”, ghlacamar páirt freisin i múnla QE a bhí oilte ag baint úsáide as an gcreat OpenKiwi chun scóir MQM agus nótaí leibhéal focal a ghiaráil.', 'el': 'Στην παρούσα εργασία, παρουσιάζουμε την κοινή συνεισφορά της Unbabel και του IST στην κοινή εργασία μετρήσεων WMT 2021. Με την φετινή εστίαση στην Πολυδιάστατη Μετρική Ποιότητας (ΜQM) ως την ανθρώπινη αξιολόγηση της αλήθειας, στόχος μας ήταν να κατευθύνουμε το COMET προς υψηλότερες συσχετίσεις με ΜQM. Αυτό το κάνουμε με την πρώτη προεκπαίδευση στις Άμεσες Αξιολογήσεις και στη συνέχεια με την τελειοποίηση των βαθμολογιών ΜQM με κανονικές τιμές. Στα πειράματά μας αποδεικνύουμε επίσης ότι τα μοντέλα COMET χωρίς αναφορά γίνονται ανταγωνιστικά με τα μοντέλα αναφοράς, ακόμη και ξεπερνούν το καλύτερο μοντέλο COMET από το 2020 στα φετινά δεδομένα ανάπτυξης. Επιπλέον, παρουσιάζουμε ένα ελαφρύ μοντέλο COMET που είναι 19x ταχύτερο σε CPU από ό,τι το αρχικό μοντέλο, ενώ επιτυγχάνει επίσης συσχετισμούς τελευταίας τεχνολογίας με MQM. Τέλος, στο κομμάτι "QE as a metric", συμμετέχαμε επίσης με ένα μοντέλο QE εκπαιδευμένο χρησιμοποιώντας το πλαίσιο OpenKiwi αξιοποιώντας βαθμολογίες MQM και σχολιασμούς σε επίπεδο λέξεων.', 'ka': 'ამ დომენტში ჩვენ Unbabel და IST-ის ერთადერთი დამატებით WMT 2021 მეტრიკის გაყოფილი საქმე. ამ წლის ფონსკური მრავალეთმენტიური კოლექტურის მეტრიკისთვის (MQM) როგორც ადამიანის მსოფლიო მნიშვნელობაში, ჩვენი მიზეზი იყო COMET-ს უფრო მეტი კოლექტურებებისთ ჩვენ ამას გავაკეთებთ პირველი წინატრიქციის მისამართლური განსაზღვრებით და შემდეგ z-ნორმალურიზებული MQM მონაცემებით. ჩვენი ექსპერიმენტებში ჩვენ ასევე ჩვენ აჩვენებთ, რომ COMET მოდელები განსხვავებული მოდელთან კონპექტიურად ხდება რეფერიმენტიური მოდელთან, რომელიც 2020-დან უკეთესი COMET მოდელთან გავა დამატებით, ჩვენ COMETinho-ს გამოსახულებთ, COMET მოდელი, რომელიც 19x უფრო სიჩქარე CPU-ზე, ვიდრე ორიგინალური მოდელზე, და ასევე MQM-თან კორელეციების სტატურება მივიღებთ. საბოლოოდ, QE როგორც მეტრიკური მონაცემებით ჩვენ კონტრიკური მოდელზე გავაკეთებდით, როგორც გავაკეთებული OpenKiwi ფრამეტრიკური მონაცემებით MQM მონაცემებით და სიტყვა-დონე', 'hu': 'Ebben a tanulmányban bemutatjuk az Unbabel és az IST közös hozzájárulását a WMT 2021 Metrics Shared Task-hoz. Az idei többdimenziós minőségméretre (MQM) koncentrálva, mint az alap-igazság emberi értékelésre, célunk az volt, hogy a COMET-et magasabb korrelációk felé irányítsuk. Ezt először a Direct Assessments előkészítésével, majd a z-normalizált MQM pontszámok finomhangolásával tesszük meg. Kísérleteinkben azt is megmutatjuk, hogy a referencia-mentes COMET modellek versenyképessé válnak a referencia-alapú modellekkel, és az idei fejlesztési adatok alapján 2020-tól a legjobb COMET modellt is túllépik. Továbbá bemutatjuk a COMETinho-t, egy könnyű COMET modellt, amely 19x gyorsabb CPU-n, mint az eredeti modell, miközben a legkorszerűbb összefüggéseket ér el az MQM-vel. Végül a "QE mint metrikus" pályán részt vettünk egy OpenKiwi keretrendszer használatával képzett QE modellel is, amely MQM pontszámokat és szószintű jegyzeteket használ.', 'it': "In questo articolo, presentiamo il contributo congiunto di Unbabel e IST al WMT 2021 Metrics Shared Task. Con l'attenzione di quest'anno sulla Multidimensional Quality Metric (MQM) come valutazione umana di base, il nostro obiettivo era quello di indirizzare COMET verso maggiori correlazioni con MQM. Lo facciamo prima con un pre-training su valutazioni dirette e poi con la messa a punto dei punteggi MQM normalizzati z. Nei nostri esperimenti mostriamo anche che i modelli COMET privi di riferimento stanno diventando competitivi con i modelli basati su riferimento, superando persino il miglior modello COMET dal 2020 sui dati di sviluppo di quest'anno. Inoltre, presentiamo COMETinho, un modello COMET leggero che è 19x più veloce su CPU rispetto al modello originale, pur ottenendo correlazioni all'avanguardia con MQM. Infine, nella traccia 'QE as a metric', abbiamo partecipato anche con un modello QE addestrato utilizzando il framework OpenKiwi sfruttando punteggi MQM e annotazioni a livello di parola.", 'kk': "Бұл қағазда біз Unbabel және IST-тың біріктірімізді WMT 2021 метрикалық ортақтастырылған тапсырмаға таңдаймыз. Бұл жылдың көп өлшемді сапатты метрикалық (MQM) мәселесін бағалау үшін, біздің мақсатымыз COMET мәселесімен көптеген мәселелеріне көтеру. Біз бұл үшін бірінші алдын- ала тәжірибелеу және z- нормализияланған MQM нөмірлерінде тәжірибелеу арқылы жасаймыз. Біздің тәжірибемдерімізде сондай-ақ, сілтеме бос комET үлгілері сілтеме негіздеген үлгілерімен тәжірибе болып тұрып, 2020 жылдың жасау мәліметінің ең жақсы COMET үлгілерінен артық Сонымен қатар, біз COMETinho дегенді, процессорда 19x жылдам болатын COMET үлгісін көрсеткіземіз. Сонымен қатар, MQM дегенмен жұмыс істеу күйін жеткіземіз. Соңында, 'QE метрикалық' жолдары ретінде, сондай-ақ біз OpenKiwi фреймінің MQM нөмірлерін және сөз деңгейінің жазбаларын қолдану үшін QE моделіне қатынасыз.", 'lt': 'Šiame dokumente pristatome bendrą Unbabelio ir IST indėlį į WMT 2021 m. bendro metro uždavinio vykdymą. Šiais metais daugiausia dėmesio skiriant daugiapakopei kokybės metrozei (MQM), kaip žmogaus vertinimui iš esmės, mūs ų tikslas buvo nukreipti COMET link didesnių koreliacijų su MQM. We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores.  Mūs ų eksperimentuose taip pat parodome, kad be etaloninių COMET modelių konkurencingumas su etaloniniais modeliais tampa didesnis už geriausią COMET model į nuo 2020 m. remiantis šių metų vystymosi duomenimis. Be to, mes pristatome COMETinho, lengvąjį COMET model į, kuris yra 19x greitesnis CPU nei pradinis model is, kartu užtikrinant naujausias koreliacijas su MQM. Galiausiai "QE kaip metrinis" kelyje mes taip pat dalyvavome rengiant QE model į, parengtą naudojant OpenKiwi sistemą, svertinančią MQM rezultatus ir žodžių lygio anotacijas.', 'mk': 'Во овој документ го претставуваме заедничкиот придонес на Унбабел и ИСТ за заедничката задача на ВМТ 2021. Со овогодинешниот фокус на мултидимензионалната квалитетна метрика (МКМ) како човечка проценка на основната вистина, нашата цел беше да го насочиме КоМЕТ кон поголеми корелации со МКМ. Го правиме тоа со прва предобука за директни оценки, а потоа со финетизирање на Z-нормализираните MQM оценки. Во нашите експерименти, исто така, покажуваме дека моделите COMET без референции стануваат конкурентни со моделите базирани на референции, дури и надминувајќи го најдобриот COMET модел од 2020 година на овогодинешните податоци за развој. Покрај тоа, го претставуваме COMETinho, лесен COMET модел кој е 19x побрз на процесорот од оригиналниот модел, истовремено постигнувајќи и современи корелации со MQM. Конечно, на „QE како метрична“ трага, исто така учествувавме и со QE модел трениран со користење на OpenKiwi рамките со влијание на MQM резултатите и анотациите на зборови.', 'ms': "Dalam kertas ini, kami memperkenalkan kontribusi bersama Unbabel dan IST kepada Tugas Berkongsi Metriks WMT 2021. Dengan fokus tahun ini pada Metrik Kualiti Berberbilang (MQM) sebagai penilaian manusia-kebenaran tanah, tujuan kami adalah untuk mengarahkan COMET ke arah korelasi yang lebih tinggi dengan MQM. Kami melakukannya dengan praselatihan pertama pada penilaian langsung dan kemudian memperbaiki skor MQM z-normalisasi. Dalam eksperimen kami juga menunjukkan bahawa model COMET bebas rujukan menjadi kompetitif dengan model berdasarkan rujukan, walaupun melampaui model COMET terbaik dari 2020 pada data pembangunan tahun ini. Selain itu, kami memperkenalkan COMETinho, model COMET ringan yang 19x lebih cepat pada CPU daripada model asal, sementara juga mencapai korelasi state-of-the-art dengan MQM. Akhirnya, dalam trek 'QE sebagai metrik', kami juga berpartisipasi dengan model QE dilatih menggunakan kerangka OpenKiwi menggunakan skor MQM dan anotasi aras perkataan.", 'no': 'I denne papiret presenterer vi den samanlige bidraga av Unbabel og IST til WMT 2021 metriske delt oppgåve. Med denne året fokuserer på fledimensjonale kvalitetsmetrikk (MQM) som grunnsannheten menneskevurdering, målet vårt var å styra COMET mot høgare korrelasjonar med MQM. Vi gjer det ved første føreøving på direkte vurdering og så finnstilling på z- normaliserte MQM- poeng. I våre eksperimenter viser vi også at COMET-modeller som ikkje er referansfri blir konkurrente med referansbaserte modeller, selv som utfører den beste COMET-modellen frå 2020 på utviklingsdata i året. I tillegg presenterer vi COMETinho eit lett COMET-modell som er 19x raskare på CPU enn den opprinnelige modellen, mens også når det gjer korrelasjonane med MQM i kunsttilstanden. Etter slutt, i QE som ein metrisk spor delta vi også med eit QE-modell trent med OpenKiwi-rammeverket som leverer MQM-poeng og ord-nivånotasjonar.', 'ml': "ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഉന്\u200dബാബേലിന്\u200dറെയും ഐസ്റ്റിന്\u200dറെയും യൂണ്ടെഡിയോണ്ട് ഡോണ്\u200dട്രിക്സിലേക്ക് കൊണ്ടുവരുന്നു. ഈ വര്\u200dഷത്തിന്റെ മില്ടിഡിമെന്\u200dഷന്\u200d മെട്രിക്കിന്\u200dറെ (എംക്യൂഎം) ശ്രദ്ധിക്കുന്നതിനാല്\u200d, ഭൂമിയിലെ സത്യം മനുഷ്യരുടെ വിചാരണയായി നമ്മുട നേരിട്ട് വിശ്വസിക്കുന്നതിനെക്കുറിച്ച് ആദ്യ പരിശീലനത്തിനു മുന്\u200dപ് പരിശീലിക്കുന്നതിനാല്\u200d പിന്നെ സാധാരണ എ നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d നമ്മള്\u200d കാണിക്കുന്നുവെങ്കില്\u200d ഈ വര്\u200dഷത്തിന്റെ വികസിക്കുന്ന വിവരങ്ങളില്\u200d നിന്നും ഏറ്റവും നല്ല കോമെറ്റ് മോഡല്\u200d പ്രദര്\u200d കൂടാതെ നമ്മള്\u200d കോമെറ്റിനെ കൊണ്ടുവരുന്നു, ഒരു ലളിതമായ കോമെറ്റ് മോഡല്\u200d കൊണ്ടുവരുന്നു. അത് സിപിയുവിനെക്കാള്\u200d 19x പ്രായമായ മോഡലിനെക്കാള്\u200d വേഗത് Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations.", 'mt': "F’dan id-dokument, qed nippreżentaw il-kontribuzzjoni konġunta ta’ Unbabel u IST għall-Kompitu Konġunt tal-Metriks tad-WMT 2021. Bil-fokus ta’ din is-sena fuq il-Metriku ta’ Kwalità Multidimensjonali (MQM) bħala l-valutazzjoni tal-bniedem tal-verità tal-art, l-għan tagħna kien li nimxu l-COMET lejn korrelazzjonijiet ogħla mal-MQM. Aħna nagħmlu dan bl-ewwel taħriġ minn qabel dwar Valutazzjonijiet Diretti u mbagħad bl-irfinar fuq punteġġi MQM normalizzati z. In our experiments we also show that reference-free COMET models are becoming competitive with reference-based models, even outperforming the best COMET model from 2020 on this year's development data.  Barra minn hekk, qed nippreżentaw COMETinho, mudell COMET ħafif li huwa 19x aktar mgħa ġġel fuq is-CPU mill-mudell oriġinali, filwaqt li niksbu wkoll korrelazzjonijiet l-aktar avvanzati mal-MQM. Fl-a ħħar nett, fit-triq 'QE bħala metrika', ipparteċipajna wkoll b'mudell QE imħarreġ bl-użu tal-qafas OpenKiwi li jinfurza l-punteġġi MQM u l-annotazzjonijiet fil-livell tal-kliem.", 'mn': 'Энэ цаасан дээр бид Unbabel болон IST-ын хамтдаа WMT 2021-ийн метрик хуваалтын ажил дээр нийлүүлж байна. Энэ жилийн олон хэмжээст чанарын метрик (MQM) дээр хүн төрөлхтний үнэн дүгнэлт гэж анхаарлаа бидний зорилго нь COMET-г MQM-тэй өндөр холбоотой болгох юм. Бид үүнийг зөв оюутнуудын тухай анхны суралцах болон z-нормалтай MQM тоонуудын тухай дүгнэхэд хийдэг. Бидний туршилтуудын дараа бид мөн харуулж байгаагаар бид энэхүү жилийн хөгжлийн мэдээллээс 2020 оны COMET загвараас хамгийн сайн COMET загвараас илүү өрсөлдөг болж байна. Үүнээс гадна бид COMETinho-г илтгэдэг. COMET загвар нь эхний загвараас 19x хурдан CPU дээр илтгэдэг. Мөн MQM-тэй урлагийн холбоотой байдал хүртэл байна. Эцэст нь, QE метрик хэлбэрээр QE загвар дээр бид мөн ашигласан OpenKiwi хэлбэрээр MQM оноо болон үгний түвшинд анзаарах сургалтын загвартай оролцсон.', 'pl': 'W niniejszym artykule przedstawiamy wspólny wkład Unbabel i IST w realizację WMT 2021 Metrics Shared Task. W tym roku koncentrując się na wielowymiarowym metryce jakości (MQM) jako podstawowej ocenie ludzkiej, naszym celem było skierowanie COMET do wyższych korelacji z MQM. Robimy to poprzez najpierw wstępne szkolenie na temat ocen bezpośrednich, a następnie dostrajanie wyników znormalizowanych z MQM. W naszych eksperymentach pokazujemy również, że bezreferencyjne modele COMET stają się konkurencyjne wobec modeli opartych na referencjach, nawet przewyższając najlepszy model COMET z 2020 na tegorocznych danych rozwojowych. Dodatkowo prezentujemy COMETinho, lekki model COMET, który jest 19x szybszy na procesorze niż oryginalny model, jednocześnie osiągając najnowocześniejsze korelacje z MQM. Wreszcie w torze "QE as a metric" uczestniczyliśmy również z modelem QE przeszkolonym przy użyciu frameworku OpenKiwi wykorzystującego wyniki MQM i adnotacje na poziomie słowa.', 'ro': 'În această lucrare, prezentăm contribuția comună a Unbabel și IST la misiunea WMT 2021 Metrics Shared Task. Cu accentul din acest an pe Multidimensional Quality Metric (MQM) ca evaluare umană bazată pe adevărul de bază, scopul nostru a fost de a direcționa COMET către corelații mai mari cu MQM. Facem acest lucru prin pre-antrenament pe evaluări directe și apoi reglarea fină a scorurilor MQM normalizate z. În experimentele noastre demonstrăm, de asemenea, că modelele COMET fără referință devin competitive cu modelele bazate pe referință, chiar depășind cel mai bun model COMET din 2020 pe baza datelor de dezvoltare din acest an. În plus, vă prezentăm COMETinho, un model COMET ușor care este de 19 ori mai rapid pe CPU decât modelul original, obținând totodată corelații de ultimă oră cu MQM. În cele din urmă, în piesa "QE ca metrică", am participat și cu un model QE instruit folosind cadrul OpenKiwi utilizând scoruri MQM și adnotări la nivel de cuvânt.', 'sr': "U ovom papiru predstavljamo zajednički doprinos Unbabel i IST-a na delovani zadatak WMT 2021 metrika. S fokusiranjem ove godine na metriku multidimenzionalne kvalitete (MQM) kao ljudsku procjenu podzemne istine, naš cilj je bio da vodimo COMET ka većim korelacijama sa MQM. To radimo po prvoj predobuci o direktnoj procjeni, a zatim finaliziramo rezultate z-normaliziranih MQM-a. U našim eksperimentima takođe pokazujemo da su modeli bez referencije COMET-a postali konkurentni sa standardnim modelima, čak i nadmašući najbolji COMET model od 2020. na podacima o razvoju ove godine. Osim toga, predstavljamo COMETinho, lakši COMET model koji je 19x brži na CPU od originalnog model a, dok takođe postignemo state-of-the-art korelacije sa MQM. Na kraju, na putu 'QE kao metrički' takođe smo sudjelovali s modelom QE obučenim korištenjem okvira OpenKiwi koji utiču na rezultate MQM i annotacije na nivou reči.", 'si': "මේ පත්තරේ අපි අන්බාබෙල් සහ IST ගේ සම්බන්ධ සම්බන්ධ සම්බන්ධ වැඩක් WMT 2021 මීට්\u200dරික්ස් සම්බන්ධ වැඩකට පෙන් මේ අවුරුද්දේ ගොඩක් විශේෂතාවක් මීට්\u200dරික් (MQM) විශේෂ විශේෂ මිනිස්සු විශේෂ විශේෂ විශේෂ වෙනුවෙන්, අපේ අරමුණ අපි ඒක කරන්නේ පලවෙනි ප්\u200dරධානය ප්\u200dරධානය කරනවා ප්\u200dරධානය අවශ්\u200dයාවක් සහ z-සාමාන්\u200dය MQM ස්කෝර්ට් වලට සුදුසු  අපේ පරීක්ෂණයේ අපි පෙන්වන්නේ නිදහස් COMET මොඩල් වලින් ප්\u200dරශ්නයක් වෙන්නේ ප්\u200dරශ්නයක් පරීක්ෂණය අධ්\u200dයාත්මක මොඩල් වලින් ප්\u200dරශ අඩුම, අපි COMETinho වෙනුවෙන්, ලොක්කු COMET මොඩල් එකක්, මුලින් මොඩල් වඩා CPU වලට 19x වේගයෙන් ඉක්මනයි, ඒ වගේම MQM එක්ක ක්\u200dරියාත්මක සම්බන්ධ අන්තිමේදී, මෙට්\u200dරික් විදියට 'QE' ට්\u200dරේක් වලින්, අපි ප්\u200dරශ්නයක් කරලා තියෙන්නේ QE මොඩ්ලේක් එක්ක OpenKiwi ව් ක්\u200dරීමාර්කම් ප්\u200dරශ්න", 'sv': 'I denna uppsats presenterar vi Unbabels och IST gemensamma bidrag till WMT 2021 Metrics Shared Task. Med årets fokus på Multidimensional Quality Metric (MQM) som grundläggande mänsklig bedömning, var vårt mål att styra COMET mot högre korrelationer med MQM. Det gör vi genom att först utbilda på Direct Assessments och sedan finjustera på z-normaliserade MQM-poäng. I våra experiment visar vi också att referensfria COMET-modeller blir konkurrenskraftiga med referensbaserade modeller, till och med överträffar den bästa COMET-modellen från 2020 på årets utvecklingsdata. Dessutom presenterar vi COMETinho, en lätt COMET-modell som är 19x snabbare på CPU än den ursprungliga modellen, samtidigt som den uppnår state-of-the-art korrelationer med MQM. Slutligen, i spåret "QE as a metric", deltog vi också med en QE modell utbildad med OpenKiwi ramverk som utnyttjade MQM poäng och ordnivåkommentarer.', 'ta': "இந்த காகிதத்தில், நாம் Unbabel மற்றும் IST யின் இணைய பங்கீட்டை காண்பிக்கிறோம் WMT 2021 மெட்ரிக்ஸ் பகிர்ந்த பணி இந்த வருடத்தில் பல்பரிமாற்றம் தரம் மெட்ரிக் (MQM) மீது கவனம் செலுத்தும் போது, நிலத்தில் உண்மையான மனித மதிப்புக்குறிப்பு, நம் இலக்கு MQM உடன் உ நாம் நேரடி மதிப்புகள் மீது முன் பயிற்சியை முதலில் செய்து பின்னர் z-வழக்கப்பட்ட MQM மதிப்புகளை நன்றாக முன்னோட எங்கள் சோதனைகளில் நாம் காண்பிக்கிறோம் குறிப்பு இலவச COMET மாதிரிகள் குறிப்பிட்ட மாதிரிகளுடன் போராட்டிக் கொண்டிருக்கிறார் கூடுதலாக, COMETinho, ஒரு எளிய COMET மாதிரி காண்பிக்கிறோம். அது 19x முதல் மாதிரி மாதிரியை விட வேகமாக இருக்கும். மேலும் MQM முடியும் நிலையில் கலை இணை இறுதியாக, QE ஒரு மெட்ரிக்' தடத்தில், நாங்கள் ஒரு QE மாதிரியில் பங்கிடப்பட்டோம். OpenKiwi சட்டத்தில் MQM மதிப்புகள் மற்றும் சொல்ல- மட்டத்தின் அற", 'so': 'Warqadan waxan ku qornaa qayb wadajir ah ee Unbaal iyo IST ee WMT 2021 Metrics Shared. Hadii sanadkan focus on multidimensional Quality Metric (MQM) sida qiimeynta dhulka-runta ah ee dadka, qastigayagu wuxuu ahaa inuu COMET u hoggaamiyo xiriirka sare ee MQM. Waxaynu sameynaa marka ugu horeysa waxbarasho ku saabsan direkte assessments kadibna si fiican looga dhigo qiimaha z-normalized MQM scores. Imtixaanadeena waxaan sidoo kale ku muujinnaa in qaababka loo jeedo ee COMET-aan-lacag la’aantiis ay isku khilaafsan yihiin qaababka reference-based, xataa sameynta modelka ugu wanaagsan ee COMET ee sanadkan laga bilaabo 2020. Waxaa kaloo dheer, COMETinho, model fudud oo COMET ah 19x oo ku dhaqso CPU sameynta asalka, xittaa waxaynu gaadhnaa dowlad-of-the-art xiriir la xiriira MQM. Ugu dambaysta, waxaynu ka qeybqaadanay wadan QE oo lagu tababaray isticmaalka firaaqada OpenKiwi oo ku qoraya qiimaha MQM iyo heerka hadalka.', 'ur': 'اس کاغذ میں، ہم Unbabel اور IST کے ساتھ WMT 2021 متریک شریک ٹاکس کے لئے مشترک حصہ پیش کرتے ہیں. اس سال کے مطابق Multidimensional Quality Metric (MQM) پر تمرکز کیا گیا تھا کہ زمین حقیقی انسان کی ارزیابی کے طور پر، ہمارا مطابق تھا کہ COMET کو MQM کے ساتھ بلند مرتبہ کی طرف چلانا ہے. ہم ایسا کر رہے ہیں پہلے پیش آموزش کے ذریعہ مستقیم آزمائش اور اس کے بعد z-normalized MQM scores پر سیدھی تنظیم کرنے کے ذریعہ۔ ہمارے آزمائش میں ہم بھی دکھاتے ہیں کہ آزمائش کے بغیر منفی COMET موڈل اس سال کے ڈولیٹ ڈیٹوں کے بارے میں بہترین COMET موڈل سے بھی زیادہ مساوی ہوتے ہیں۔ اور اضافہ، ہم COMETinho کو پیش کرتے ہیں، ایک ہلکا بوجھ COMET موڈل جو CPU پر پہلی موڈل سے 19x سے زیادہ سریع ہے، اور MQM کے ساتھ اضافہ کی حالت تک پہنچ رہے ہیں. آخر میں، QE میں ایک متریک ٹراک کے طور پر، ہم نے بھی ایک QE موڈل کے ساتھ شرکت کی جو OpenKiwi فلم کے مطابق استعمال کی گئی تھی MQM اسکور اور کلمات سطح انٹیزوں کے مطابق استعمال کی۔', 'uz': "Bu hujjatda, biz Unbabel va IST'ning bir necha qanday qismini WMT 2021 metric bilan birlashtirilgan vazifani ko'rsamiz. Bu yildan ko'proq qiymatga (MQM) o'zgarishga qaramaydigan bir necha darajalik metriki (MQM) va yuqori inson haqida qiymatda, bizning maqsadimiz MQM bilan yuqori munosabatlarni boshqarish uchun COMETni boshqarish mumkin. We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores.  Bizning tajribalarimizda, bu yildan 2020 yildan eng eng yaxshi COMET modelini bajarish mumkinligini ko'rsatganimiz mumkin. Ko'pchilik, biz COMETinho, asl modeldan 19x yuqori CPU'da tez keladigan COMETinho modeli, va bu MQM bilan bir narsa boshqa murojaatlarni bajarish mumkin. Oxirgi, QE'ni metrik sifatida, biz MQM qiymatlari va soʻzning darajasi taʼminlovchisi bilan OpenKiwi freymi bilan ishlatadigan QE modeli bilan bogʻlandik.", 'vi': 'Trong tờ giấy này, chúng tôi xin giới thiệu đóng góp chung của Unbabel và IST cho công việc chia sẻ WM 2021. Với s ự tập trung của năm nay vào đa chiều chất lượng Metric (MQM) như một đánh giá chân lý của con người, mục tiêu của chúng tôi là hướng tơ chất lượng lên cao hơn với khẩu MQM. Chúng ta làm thế bằng việc đầu tiên tiến hành các đánh giá trực tiếp và sau đó cải thiện điểm MX-ổn định. Trong các thí nghiệm của chúng tôi, chúng tôi cũng cho thấy các mô-tơ tơ tơ tơ tơ tơ tơ tơ tơ tơ tơ miễn nhiễm đang dần cạnh tranh với các mô hình dựa trên tham khảo, thậm chí còn chạy tốt hơn cả mô hình tơ tơ tơ tơ tơ lên 2020 trên năm nay. Thêm nữa, chúng tôi giới thiệu chất kết hợp với chất lượng lớn, mô hình cáp lên với chất lượng lớn 19x nhanh hơn mẫu gốc, nhưng cũng đạt kết quả hiện đại với MX. Cuối cùng, trong đoạn "Trả lời nhanh như hệ thống đo lường", chúng tôi cũng tham gia với mô hình QE được đào tạo nhờ hệ thống OpenKiwi, nhờ vào điểm số của MX và ghi chú từ cấp độ.', 'bg': 'В настоящата статия представяме съвместния принос на Унбабел и ИСТ към Споделената задача за измерване на метриците на WMT 2021. С тазгодишния фокус върху Многоизмерната качествена метрика (МКВ) като основна човешка оценка, нашата цел беше да насочим Комет към по-високи корелации с МКВ. Правим това първо чрез предварителна подготовка за директни оценки и след това фино настройване на z-нормализирани резултати. В нашите експерименти също така показваме, че моделите без референции стават конкурентоспособни с референтни модели, дори надминавайки най-добрия модел от 2020 г. спрямо данните за разработката тази година. Освен това представяме лек модел, който е 19 пъти по-бърз на процесора от оригиналния модел, като същевременно постига най-съвременни корелации с МКМ. И накрая, в песента "QE as a metric", участвахме и с модел на QE, обучен с помощта на рамката използвайки резултати от МQM и анотации на ниво дума.', 'nl': "In dit artikel presenteren we de gezamenlijke bijdrage van Unbabel en IST aan de WMT 2021 Metrics Shared Task. Met de focus van dit jaar op Multidimensional Quality Metric (MQM) als basis-truth human assessment, was ons doel om COMET te sturen naar hogere correlaties met MQM. Dit doen we door eerst vooraf te trainen op Direct Assessments en vervolgens af te stemmen op z-genormaliseerde MQM scores. In onze experimenten laten we ook zien dat referentievrije COMET-modellen concurrerend worden met referentie-gebaseerde modellen, zelfs beter presteren dan het beste COMET-model uit 2020 op de ontwikkelingsdata van dit jaar. Daarnaast presenteren we COMETinho, een lichtgewicht COMET model dat 19x sneller is op CPU dan het originele model, terwijl ook state-of-the-art correlaties met MQM bereikt worden. Tot slot namen we ook deel aan de track 'QE as a metric' met een QE model dat is getraind met behulp van het OpenKiwi framework waarbij gebruik wordt gemaakt van MQM scores en aantekeningen op woordniveau.", 'de': 'In diesem Beitrag stellen wir den gemeinsamen Beitrag von Unbabel und IST zur WMT 2021 Metrics Shared Task vor. Mit dem diesjährigen Fokus auf Multidimensional Quality Metric (MQM) als Basis-Truth Human Assessment war es unser Ziel, COMET in Richtung höherer Korrelationen mit MQM zu lenken. Dazu trainieren wir zunächst Direct Assessments und optimieren dann z-normalisierte MQM-Scores. In unseren Experimenten zeigen wir auch, dass referenzfreie COMET-Modelle gegenüber referenzbasierten Modellen wettbewerbsfähig werden und sogar das beste COMET-Modell aus 2020 auf den diesjährigen Entwicklungsdaten übertreffen. Darüber hinaus präsentieren wir COMETinho, ein leichtes COMET-Modell, das auf CPU 19x schneller ist als das ursprüngliche Modell, während gleichzeitig modernste Korrelationen mit MQM erzielt werden. Schließlich nahmen wir am Track "QE as a metric" auch mit einem QE-Modell teil, das mit dem OpenKiwi-Framework trainiert wurde und MQM-Scores und Anmerkungen auf Wortebene nutzte.', 'id': "Dalam kertas ini, kami memperkenalkan kontribusi bersama Unbabel dan IST ke WMT 2021 Metrics Shared Task. With this year's focus on Multidimensional Quality Metric (MQM) as the ground-truth human assessment, our aim was to steer COMET towards higher correlations with MQM.  Kami melakukannya dengan prapelatihan pertama pada penilaian langsung dan kemudian memperbaiki skor z-normalisasi MQM. In our experiments we also show that reference-free COMET models are becoming competitive with reference-based models, even outperforming the best COMET model from 2020 on this year's development data.  Selain itu, kami mempersembahkan COMETinho, model COMET ringan yang 19x lebih cepat pada CPU daripada model asli, sementara juga mencapai korelasi state-of-the-art dengan MQM. Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations.", 'da': "I denne artikel præsenterer vi det fælles bidrag fra Unbabel og IST til WMT 2021 Metrics Shared Task. Med dette års fokus på Multidimensional Quality Metric (MQM) som grundlæggende menneskelig vurdering, var vores mål at styre COMET mod højere korrelationer med MQM. Det gør vi ved først at træne på direkte vurderinger og derefter finjustere på z-normaliserede MQM scores. I vores eksperimenter viser vi også, at referencefrie COMET-modeller er ved at blive konkurrencedygtige med referencebaserede modeller og endda overgå den bedste COMET-model fra 2020 på dette års udviklingsdata. Derudover præsenterer vi COMETinho, en let COMET model, der er 19x hurtigere på CPU end den oprindelige model, samtidig med at der opnås state-of-the-art korrelationer med MQM. Endelig deltog vi i 'QE as a metric' sporet med en QE model uddannet ved hjælp af OpenKiwi framework ved hjælp af MQM scores og ord-niveau annotationer.", 'ko': "본고에서 우리는 Unbabel과 IST가 WMT 2021 도량 공유 임무에 대한 공동 공헌을 소개했다.올해는 다차원 질량도량(MQM)이 인류 평가의 기본적인 사실로서 COMET와 MQM이 더 높은 관련성을 실현하도록 유도하는 것이 목표다.먼저 직접 평가를 사전 교육한 다음 z 표준화된 MQM 점수를 미세하게 조정했습니다.우리의 실험에서 우리는 참고가 없는 혜성모델이 참고를 바탕으로 하는 모델과 경쟁하고 있으며 심지어 올해의 발전 데이터에서 2020년 이래 가장 좋은 혜성모델을 넘어섰다는 것을 보여 주었다.또한 COMETinho를 소개했는데 이것은 경량급 COMET 모델로 CPU에서 원시 모델보다 19배 빠르고 MQM과 가장 선진적인 관계를 실현했다.마지막으로'QE는 일종의 도량'과정에서 OpenKiwi 프레임워크 교육을 사용하는 QE 모델에 참여했는데 이 프레임워크는 MQM 점수와 단어급 주석을 이용한다.", 'fa': 'در این کاغذ، ما مشترک مشترک Unbabel و IST را به وظیفه مشترک متریک WMT 2021 پیشنهاد می\u200cکنیم. با تمرکز این سال روی متریک کیفیت چند بعدی (MQM) به عنوان ارزیابی انسان\u200cهای حقیقت زمینی، هدف ما این بود که COMET را به سوی ارتباطات بالاتری با MQM هدایت کنیم. ما این کار را با اولین آموزش پیش از آموزش مستقیم در ارزیابی مستقیم انجام می دهیم و سپس در نتیجه\u200cهای MQM معمولی تغییر می\u200cدهیم. در آزمایشات ما همچنین نشان می دهیم که مدلهای COMET بی ارتباط با مدلهای مربوط به مربوط به مسابقه تبدیل می شوند، حتی بیشتر از بهترین مدل COMET از ۲۰۰۲ در داده های توسعه سال. علاوه بر این، ما COMETinho را نشان می دهیم، یک مدل COMET سبک که 19x سریع تر از مدل اصلی در CPU است، در حالی که همچنین به ارتباطات موجود هنر با MQM رسیده است. بالاخره، در مسیر QE به عنوان یک متریک، همچنین با یک مدل QE آموزش داده شده با استفاده از چهارچوب OpenKiwi با توجه به امتیاز MQM و توضیح سطح کلمات شرکت کردیم.', 'sw': "Katika gazeti hili, tunatoa mchango wa pamoja wa Unbabel na IST kwenye mbinu za WMT 2021. Wakati lengo la mwaka huu la utaratibu wa aina mbalimbali (MQM) kama utafiti wa ukweli wa ardhi, lengo letu lilikuwa kuwaongoza COMET kuelekea mahusiano ya juu na MQM. Tunafanya hivyo kwa mafunzo ya kwanza kuhusu Tathmini za moja kwa moja na kisha kuvutiwa vizuri juu ya score za MQM zilizo kawaida. Katika majaribio yetu pia tunaonyesha kuwa mitindo huru ya COMET yanageuka kushindana na mifano inayohusiana na maoni, hata kufanya mtindo bora wa COMET kuanzia 2020 kuhusu takwimu za maendeleo ya mwaka huu. Zaidi ya hayo, tunawasilisha COMETinho, modeli yenye uzito wa COMET yenye mwaka 19x haraka kwa CPU kuliko mifano ya awali, wakati pia tunapata mahusiano ya hali ya sanaa na MQM. Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations.", 'hr': "U ovom papiru predstavljamo zajednički doprinos Unbabel i IST-a na zadatak WMT 2021 metrika. S fokusiranjem ove godine na multidimenzionalnu kvalitetnu metriku (MQM) kao ljudsku procjenu zemaljske istine, naš cilj je bio voditi COMET ka višim korelacijama s MQM. To radimo po prvoj predobuci o direktnoj procjeni, a zatim ispravno ispravljamo rezultate z-normaliziranih MQM-a. U našim eksperimentima također pokazujemo da su modeli bez referencije COMET-a postali konkurentni s standardnim modelima, čak i nadmašući najbolji COMET model od 2020. na podacima o razvoju ove godine. Osim toga, predstavljamo COMETinho, lakši COMET model koji je 19x brži na CPU od originalnog model a, dok također postignemo state-of-the-art korelacije s MQM. Na kraju, na putu 'QE kao metrički' također smo sudjelovali s QE model obučenim koristeći okvir OpenKiwi koji utječe na rezultate MQM i annotacije na nivou riječi.", 'am': "በዚህ ፕሮግራም፣ Unbabel እና IST በ2021 ማትሪክ የተሰራጨውን ስራ ለWMT እናቀርባለን፡፡ የዚህ ዓመታት የብዛት ብልሃት ሚትሪክ (MQM) መሬት-እውነተኛ ሰብአዊ ማሰናከል ነው፡፡ We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores.  በሞከራችንን እናሳያቸዋለን፣ የፍቃድ ነጻ COMET ሞዴላዎች ከ2020 ጀምሮ በዓመቱ ፍጥረት ዳታዎች ላይ የተሻለ COMET ሞዴል እናደርጋለን፡፡ በተጨማሪም፣ COMETinho፣ 19x በCPU ላይ ከቀድሞ ሞዴል ይልቅ ፈጥኖ የኮሜቴት ሞዴል እናቀርባለን፣ ከMQM ጋር የሀብት-የ-art ግንኙነት እናደርጋለን፡፡ Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations.", 'sq': "Në këtë letër, ne paraqesim kontributin e përbashkët të Unbabel dhe IST në detyrën e përbashkët të WMT 2021 Metrics. Me përqëndrimin e këtij viti në Metrikën e Kualitetit Multidimensional (MQM) si vlerësimin njerëzor të vërtetë tokësore, synimi ynë ishte të drejtonim COMET drejt korrelacioneve më të larta me MQM. Ne e bëjmë këtë me parastërvitjen e parë në vlerësimet e drejtpërdrejta dhe pastaj përmirësimin e rezultateve z-normalizuar MQM. Në eksperimentet tona tregojmë gjithashtu se modelet COMET pa referencë po bëhen konkurruese me modelet bazuar në referencë, madje edhe duke kaluar modelin më të mirë COMET nga 2020 në të dhënat e zhvillimit të këtij viti. Përveç kësaj, ne paraqesim COMETinho, një model COMET i lehtë që është 19x më i shpejtë në CPU se modeli origjinal, duke arritur gjithashtu korrelacione më të larta me MQM. Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations.", 'tr': "Bu kagyzda Unbabel we IST'yň WMT 2021 metrikler paylaşyk işine mejbur gazanýarys. Bu ýylyň Multidimensional Quality Metrici (MQM) bilen ýerli adamlary barlamak üçin amalymyzda COMET'i MQM bilen ýokaryk bilen ýokaryk bilen gurulmagymyzdyr. Biz bu şekilde ilkinji dogry çykyşlar hakynda öňünden öňünden okaýarys we so ňra z-normaliziýan MQM notlarynda dogry çykyş etýäris. Biziň deneylerimizde hem bu ýylyň gelişme maglumatynda baýlaşmaýan COMET modelleriň 2020-nji ýyldan iň gowy COMET modeliniň döwletleri bilen duşuşykly bolup barýandygyny görkeýäris. Hemmäçe COMETinho'y görkezilýän, CPU'da 19x ýokary hızlydyr, hatda MQM bilen sungatlaşmalaryň durumyny ýetişýäris. Soňunda 'QE metrik' hatynda, biz hem OpenKiwi çerçewçiliginde MQM notlaryny we söz derejesi duýdurmalaryny ulanan QE nusgasyna dahil etdik.", 'bn': "এই কাগজটিতে আমরা আনবাবেল এবং আইএসটি উইএমটি ২০২১ মেট্রিক শেয়ার কর্মসূচিতে যৌথ অংশগ্রহণের সাথে উপস্থাপন করছি। এই বছর মাল্টিডিমেন্টেশনাল মেট্রিক (এমকিউএম) নিয়ে মনোযোগ প্রদান করা হয়েছে যেহেতু মানুষের সত্য মানুষের মূল্যায়ন হিসেবে, আমাদের লক্ষ্য হচ্ছে  আমরা এটা প্রথম প্রশিক্ষণের মাধ্যমে যাচ্ছি সরাসরি প্রশিক্ষণ এবং তারপর জি-স্বাভাবিক এমকিউএম স্কোরের উপর ভালোভাবে সুন্দর আমাদের পরীক্ষায় আমরা দেখাচ্ছি যে গণমুক্ত কমেট মডেলও গণভিত্তিক মডেলের সাথে প্রতিযোগিতায় পরিণত হচ্ছে, এমনকি ২০২০ সালের উন্নয়নের তথ্যের সবচেয়ে  এছাড়াও, আমরা কমেটিন্হো উপস্থাপন করছি একটি হাল্কা কমেট মডেল যা সিপিউ এর মূল মডেলের চেয়ে ১৯ক্স ত্বরান্বিত, আর এমকিউএম এর সাথে শিল্পের রাষ্ট্র-অফ-শিল শেষ পর্যন্ত 'কিউই মেট্রিক' ট্র্যাক হিসেবে আমরা একটি কিউই মডেলের সাথে অংশগ্রহণ করেছি যারা এমকিউএম স্কোর এবং শব্দ স্তরের বিষয়টি ব্যবহার করে প্রশ", 'af': "In hierdie papier, ons stel die saamste bydraag van Unbabel en IST aan die WMT 2021 metries deelde taak voor. Met hierdie jaar se fokus op Multidimensional Quality Metric (MQM) as die grond-waarheid menslike evaluering, was on s doel om COMET te steer na hoëre korrelasies met MQM. Ons doen so deur die eerste voor-onderwerp op direkte Assensies en dan fin-tuning op z-normaliseerde MQM telling. In on s eksperimente wys ons ook dat verwysing-vry COMET-modele gemeenskap word met verwysing-gebaseerde modele, selfs uitvoer die beste COMET model van 2020 op hierdie jaar se ontwikkelingsdata. In addition, we present COMETinho, a light weight COMET model that is 19x faster on CPU than the original model, while also aching state-of-the-art correlations with MQM. Eindelik, in die 'QE as 'n metriese' snit, het ons ook gedeel met 'n QE model wat onderwerp is deur die OpenKiwi raamwerk wat MQM poeiers en woord-vlak notasies verwyder.", 'az': "Bu kağızda, Unbabel və IST'in birlikdə WMT 2021 metrik paylaşılan işə təmin edirik. Bu ilin çox ölçülük kaliteli metrik (MQM) üzərində insanların ölçüs ü olaraq, bizim amacımız COMET'i MQM ilə yüksək bağlantılara yönəltmək idi. Biz bunu ilk dəfə do ğru təcrübələr haqqında təcrübə edirik, sonra z-normalizə MQM scoreları düzgün təcrübə edirik. Həmçinin bizim təcrübələrimizdə də göstəririk ki, bu il tədbirli məlumatlarında, 2020-dən ən yaxşı COMET modeli ilə müqayisədə olmayan COMET modellərinin müqayisədə olmasını belə göstərir. Daha da, biz COMETinho'yu, CPU'da 19x daha hızlı bir COMET modeli göstəririk, lakin MQM ilə möcüzə olan möcüzələri təşkil edirik. Sonunda, QE metrik kimi, biz də OpenKiwi framework ü ilə təhsil edilmiş QE modeli ilə MQM qiymətlərini və sözlərin səviyyəsini göstərmək üçün təhsil etdik.", 'cs': 'V tomto článku představujeme společný příspěvek Unbabel a IST k WMT 2021 Metrics Shared Task. S letošním zaměřením na multidimenzionální metriku kvality (MQM) jako základní lidské hodnocení bylo naším cílem nasměrovat COMET směrem k vyšší korelaci s MQM. Činíme tak nejprve předškolením na přímé hodnocení a následně jemným laděním na z-normalizovaných skórích MQM. V našich experimentech také ukazujeme, že bezreferenční modely COMET se stávají konkurenceschopnými s referenčními modely, dokonce překonávají nejlepší model COMET z 2020 na letošních vývojových datech. Navíc představujeme COMETinho, lehký COMET model, který je 19x rychlejší na CPU než původní model, a zároveň dosahuje nejmodernějších korelací s MQM. Nakonec jsme se na stopě QE jako metrika účastnili také QE modelu trénovaného pomocí OpenKiwi frameworku využívajícího MQM skóre a anotace na slovní úrovni.', 'et': 'Käesolevas dokumendis tutvustame Unbabeli ja IST ühist panust WMT 2021 Metrics Shared Task. Tänavu keskendudes mitmemõõtmelisele kvaliteedimeetrikule (MQM) kui põhjalikule inimhinnangule, oli meie eesmärk juhtida COMETi suuremate korrelatsioonide suunas MQM-iga. Me teeme seda esmalt eelõpetades otsese hindamise ja seejärel täpsustades z-normaliseeritud MQM skoore. Oma eksperimentides näitame ka, et referentsivabad COMET mudelid on muutumas konkurentsivõimeliseks referentsipõhiste mudelitega, isegi ületades selle aasta arendusandmete põhjal parimat COMET mudelit 2020. aastast. Lisaks tutvustame COMETinho kerget COMET mudelit, mis on protsessoril 19x kiirem kui algne mudel, saavutades samas kaasaegse korrelatsiooni MQM-iga. Lõpuks osalesime "QE as a metric" rajal ka QE mudeliga, mis oli koolitatud OpenKiwi raamistiku abil, kasutades MQM skoore ja sõnatasemel annotatsioone.', 'fi': "Tässä artikkelissa esittelemme Unbabelin ja IST:n yhteisen panoksen WMT 2021 Metrics Shared Task -tehtävään. Tämän vuoden painopisteenä oli Multidimensional Quality Metric (MQM) perustotuusarviointi, ja tavoitteena oli ohjata COMET kohti korkeampia korrelaatioita MQM:n kanssa. Teemme sen ensin esikouluttamalla suoria arviointeja ja hienosäätämällä z-normalisoituja MQM-pisteitä. Kokeissamme osoitamme myös, että referenssivapaat COMET-mallit kilpailevat referenssipohjaisten mallien kanssa, jopa tämän vuoden kehitystiedoista parhaan COMET-mallin kanssa vuodesta 2020 lähtien. Lisäksi esittelemme COMETinho-mallin, joka on 19 kertaa nopeampi suorittimella kuin alkuperäinen malli, samalla kun saavuttaa huipputason korrelaatiot MQM:n kanssa. Lopuksi 'QE as a metric' -radalle osallistuimme myös QE-mallilla, joka oli koulutettu käyttäen OpenKiwi-kehystä hyödyntäen MQM-pisteitä ja sanatason huomautuksia.", 'bs': "U ovom papiru predstavljamo zajednički doprinos Unbabel i IST-a na delovani zadatak WMT 2021 metrika. S koncentracijom ove godine na metriku multidimenzionalne kvalitete (MQM) kao ljudsku procjenu temeljne istine, naš cilj je bio voditi COMET ka višim korelacijama sa MQM. To radimo po prvoj predobuci o direktnoj procjeni, a zatim ispravno ispravljamo rezultate z-normaliziranih MQM-a. U našim eksperimentima također pokazujemo da su modeli bez referencije COMET-a postali konkurentni sa standardnim modelima, čak i nadmašući najbolji COMET model od 2020. na podacima o razvoju ove godine. Dodatno predstavljamo COMETinho, lakši COMET model koji je 19x brži na CPU nego originalni model, dok također postignemo state-of-the-art korelacije sa MQM. Na kraju, na putu 'QE kao metrički' također smo sudjelovali s modelom QE obučenim korištenjem okvira OpenKiwi koji utječe na rezultate MQM i annotacije na nivou riječi.", 'ca': "En aquest paper, presentem la contribució conjunta d'Unbabel i IST a la World Metrics Shared Task 2021. Amb l'enfocament d'aquest any en el mètric de qualitat multidimensional (MQM) com a valoració humana de la veritat terrestre, el nostre objectiu va ser orientar el COMET cap a correlacions més altes amb el MQM. We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores.  En els nostres experiments també demostrem que els model s COMET sense referència s'estàn convertint en competitius amb models basats en referència, fins i tot superant el millor model COMET a partir del 2020 en les dades de desenvolupament d'aquest any. A més, presentem COMETinho, un model COMET lliure que és 19x més ràpid en el CPU que en el model original, alhora que aconsegueixem correlacions més avançades amb MQM. Finalment, a la pista 'QE com a mètrica', també vam participar amb un model QE entrenat fent servir el marc OpenKiwi aprofitant puntuacions MQM i anotacions de nivell de paraules.", 'hy': "In this paper, we present the joint contribution of Unbabel and IST to the WMT 2021 Metrics Shared Task.  Այս տարվա կենտրոնացումը բազմաչափ որակային մետրիկայի (MQM) վրա, որպես մարդկային հիմնական ճշմարտության գնահատականի, մեր նպատակն էր ուղղություն տալ համակարգը ՄQM-ի հետ ավելի բարձր հաղորդակցման ուղղությամբ: We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores.  Մեր փորձարկումներում մենք նաև ցույց ենք տալիս, որ անվերաբերյալ ազատ համակարգչային համակարգչային համակարգչային մոդելները մրցակցում են վերաբերյալ հիմնված մոդելների հետ, նույնիսկ ավելի լավ համակարգչային համակարգչային համակարգչային համակարգչային Ավելին, մենք ներկայացնում ենք COմեթինո, թեթև COմեթ մոդելը, որը 19x ավելի արագ է պրոցեբույսի վրա, քան սկզբնական մոդելը, միաժամանակ հասնում է նաև նորագույն հաղորդակցման MQM-ի հետ: Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations.", 'jv': "Nang paper iki, kita mulai nyumbang nggawe Unbabel lan IsT iki bakal nggawe task sing dibenalke WT 2020 Metric Sumangkat barêng-barêng nggawe barang-barêng kuwi Multi-Dimension Quality Metric (MqM) nganggep kuwi kalem kuwi nggawe barang urip iki, awakmu dhéwé wis nguasai COMETE nggawe gerakan tambah sing luwih dumadhiné karo MqM. Awak dhéwé ngerti, nglakoni mulai terus-terus layang tanggal layang, ngono iso nggawe barang z-normal, lan mqM kuwi nggawe barang. Nang dhéwé éntuk éntuk éntuk sawian sistem reference-free COMET model kuwi wis mulasai, nik sampek iso dianggawe model COMETE nggawe data nggawe barêng-barêng. Mungkin tambah, kita susahe COMETIno, model COMETETing kang basa dong liyane 19 x luwih banter sulo perusahaan ingkang model sing dumateng, sampeyan iso dianggawe perusahaan suglasiya sampeyan MqM. Tulung ngono, ning 'GE' sing kelas metik, kita mulai ngejarang mèdang model GE sing ditambah podho nggambar aturan Open Kiwi nggawe dolanan sing nggawe Puntuan MKM lan kelas-kaliwat.", 'he': 'בעיתון הזה, אנחנו מציגים את התרומה המשותפת של אונבאבל ו-IST למשימה המשותפת של WMT 2021 Metrics. עם התמקדות השנה במטריקה איכותית רבמימדית (MQM) בתור הערכת האמת האנושית האדמה, המטרה שלנו היתה להוביל COMET לקשר גבוה יותר עם MQM. אנחנו עושים את זה על ידי האימונים הראשונים על הערכות ישירות ואז מתאימים על ציונים MQM נורמליים z. בניסויים שלנו אנחנו גם מראים שמדוגמנים COMET ללא התייחסות הופכים להתחרות עם דוגמנים מבוססים על התייחסות, אפילו יוצאים מהמודל COMET הטוב ביותר מהשנה 2020 על נתוני הפיתוח של השנה. בנוסף, אנו מציגים COMETinho, מודל COMET קל שהוא 19x מהיר יותר על CPU מהמודל המקורי, בעוד גם להשיג קשרים מצוינים עם MQM. סוף סוף, במסלול "QE כמטריק", השתתפנו גם עם מודל QE מאומן בשימוש במסגרת OpenKiwi משתמש בתוצאות MQM ומערכות רמת מילים.', 'ha': "Ga wannan takardan, Munã halatar da wadan rabon aiki na Unbabel da IS zuwa WMT 2021 Metrics Shared Aiki. Daga da aka fokus kan multidimental Quality Metric (MQM) kamar an ƙayyade bakin-gaske ga mutum, kanmu ne ke ƙara COMET zuwa mafi girma tsaro da MQM. Munã aikata shi da ta farkon kõra a kan Direct Assessements kuma sa'an nan gyãra kan score z-normal MQM. Daga jarrabõyinmu, za mu nuna cewa misalin komai da ba'a lissafa ba za su kasance masu yin ta'ada a kan misãlai na Reference, kõ kuwa suna sami mafi kyaun motsi na COMET daga 2020 a kan danne na ƙarami shekarar wannan. Da ƙaranci, munã halatar da COMETinho, wata mai sauƙi na COMET wanda ke kasancẽwa 19x mafi gaggãwa a kan CPU mafi sauri kan motsi na farko, kuma da kuma ke sami babban state-of-the-art links with MQM. Ga ƙarshe, a cikin shirin 'QEK kamar wata metric' mun yi shirin samun na QEki wanda aka sanar da shi a yi amfani da firam ɗin Open Kiwi da ke samar da score MQM da sunayen-leveli.", 'sk': 'V tem prispevku predstavljamo skupni prispevek Unbabel in IST k skupni nalogi WMT 2021 Metrics Shared Task. Z letošnjim osredotočanjem na večdimenzionalno mero kakovosti (MQM) kot osnovno oceno človeka, je bil naš cilj usmeriti COMET k višjim korelacijam z MQM. To naredimo s predusposabljanjem o neposrednih ocenah in nato z-normaliziranimi rezultati MQM. V naših eksperimentih smo tudi pokazali, da so brezreferenčni modeli COMET konkurenčni z referenčnimi modeli, celo z letošnjimi razvojnimi podatki presegli najboljši COMET model od leta 2020. Poleg tega predstavljamo COMETinho, lahek COMET model, ki je 19x hitrejši na procesorju kot prvotni model, hkrati pa dosega najsodobnejše korelacije z MQM. Nazadnje smo v sklopu "QE kot metrična" sodelovali tudi z modelom QE, usposobljenim z uporabo okvira OpenKiwi, ki je uporabljal rezultate MQM in opombe na ravni besed.', 'bo': "ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་Unbabel དང་IST (WMT 2021)ཡི་གྲངས་ཚད་རྩ་སྒྲིག་གི་ལས་ཀ་ཆ་མཐུན་གྱི་གུས་མཐུན་སྒྲིག་ཡོད། འདིའི་ལོ་ངོ་མའི་ནང་གི་སྣ་ཆེ་མཐོང་ཚད་ལྡན་གྱི་ནང་དུ་དམིགས་བསལ་བློ་གཏོང་ནི་ We do so by first pre-training on Direct Assessments and then fine-tuning on z-normalized MQM scores. In our experiments also show that reference-free COMET model s are becoming competitive with reference-based models, even outperforming the best COMET model from 2020 on this year's development data. Additionally, we present COMETinho, a light weight COMET model that is 19x faster on CPU than the original model, while also achieving state-of-the-art correlations with MQM. The following problems are: Finally, in the 'QE as a metric' track, we also participated with a QE model trained using the OpenKiwi framework leveraging MQM scores and word-level annotations."}
{'en': 'Simultaneous Neural Machine Translation with Constituent Label Prediction', 'fr': "Traduction automatique neuronale simultanée avec prédiction d'étiquette de constituants", 'ar': 'الترجمة الآلية العصبية المتزامنة مع التنبؤ بالتسمية التأسيسية', 'es': 'Traducción automática neuronal simultánea con predicción de etiquetas constituyentes', 'pt': 'Tradução automática neural simultânea com previsão de rótulos de constituintes', 'ja': '構成ラベル予測を伴う同時神経機械翻訳', 'zh': '有成分标占功能同声神经机器翻译', 'ru': 'Синхронный нейронный машинный перевод с предсказанием составной метки', 'hi': 'एक साथ न्यूरल मशीन अनुवाद के साथ घटक लेबल भविष्यवाणी', 'ga': 'Aistriúchán Meaisín Néarach Comhuaineach le Tuar Lipéad Comhpháirteach', 'ka': 'Name', 'hu': 'Egyidejű idegi gépi fordítás alkotócímke előrejelzéssel', 'it': "Traduzione automatica neurale simultanea con previsione dell'etichetta costituente", 'kk': 'Қарапайым нейралы машинаның аудармасы, тұрақты жарлықтың алдындағысы', 'mk': 'Симултан превод на неврална машина со предвидување на конститутната етикета', 'lt': 'Tuo pačiu metu atliekamas neurologinis mašinų vertimas su konstitucinės etiketės prognoze', 'el': 'Ταυτόχρονη νευρωνική μηχανική μετάφραση με πρόβλεψη ετικετών συστατικών', 'ms': 'Simultaneous Neural Machine Translation with Constituent Label Prediction', 'mt': 'Traduzzjoni simultanja tal-Magna Newrali bi Tbassir tat-Tikketta Kostitwenti', 'ml': 'സഹജമായ ലേബില്\u200d മുന്\u200dഗണന കൊണ്ട് നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുക', 'mn': 'Түүнчлэн сэтгэл мэдрэлийн машины хөрөнгө', 'no': 'Simulert neuralmaskinsomsetjing med førehandsvising av konstitusjonsmerkelapp', 'sr': 'Simultarna neuronska prevoda sa predviđanjem konstitucionog etiketa', 'pl': 'Równoczesne tłumaczenie maszynowe neuronowe z predykcją etykiet składowych', 'si': 'සාමාන්\u200dයය ලේබෙල් ප්\u200dරධානය සඳහා සාමාන්\u200dයය න්\u200dයූරල් මැෂින් පරිවර්තනය', 'ro': 'Traducere automată neurală simultană cu predicția etichetei constituente', 'so': 'Turjumista wadajirka ah ee Masiinka Neural with Constitution Label Prediction', 'ta': 'Name', 'sv': 'Samtidig neural maskinöversättning med förutsägelse av konstituerande etiketter', 'ur': 'سیمالٹ نیورال ماشین ترجمہ', 'uz': 'Simultaneous Neural Machine Translation with Constituent Label Prediction', 'vi': 'Mô phỏng máy thần kinh có kèm theo hiệu ứng', 'bg': 'Едновременен неврален машинен превод с предсказване на съставния етикет', 'nl': 'Simultane Neurale Machine Translation met Constituent Label Prediction', 'da': 'Samtidig neural maskinoversættelse med forudsigelse af konstituerende etiket', 'hr': 'Istodobna neuronska prevoda sa predviđanjem određene etikete', 'ko': '성분 라벨 예측 기반 신경 네트워크', 'fa': 'ترجمه ماشین عصبی شبیه با پیش\u200cبینی برچسب پایین', 'de': 'Simultane neuronale maschinelle Übersetzung mit Constituent Label Vorhersage', 'id': 'Translation Mesin Neural Simultaneous dengan Prediksi Label Konstitusi', 'sw': 'Tafsiri kwa wakati ule wa mashine ya Neural na Utawala wa Label', 'tr': 'Aýratyn Etiket Öňliki bilen Taýtget Maşynyň terjimesini', 'af': 'Gelykenis Neurale Masjien Vertaling met konstituent etiket voorvloediging', 'sq': 'Përkthimi i njëkohshëm i Makinës Neurale me parashikimin e etiketës së përbërshme', 'am': 'Simultaneous Neural Machine Translation with Constituent Label Prediction', 'hy': 'Միևնույն նյարդային մեքենայի թարգմանությունը կոնստիտուցիոն պիտակի կանխատեսումով', 'az': 'B칲t칲n n칬ral ma코in T톛rc칲m톛si Konstant Etiket 칐n칲m칲 il톛', 'bn': 'Name', 'bs': 'Simultarna neuronska prevoda sa predviđanjem određene etikete', 'cs': 'Současný neuronový strojový překlad s predikcí štítků', 'et': 'Samaaegne neuroaalne masintõlk koostisosa etiketi prognoosiga', 'ca': "Traducció simultànea de màquina neuronal amb predicció d'etiquetes", 'fi': 'Samanaikainen hermojen konekäännös ja komponentin etiketin ennustaminen', 'jv': "Janet Smith (that's the same name)", 'ha': '@ action', 'he': 'תורגם וסונכרן ע"י Qsubs מצוות', 'sk': 'Sočasni strojni živčni prevod z napovedjo nalepke sestavnega dela', 'bo': 'རྩ་མཐུན་ཅན་གྱི་ཤོག་བྱང་ལ་སྔོན་འཛུགས་དང་མཚོན་རྟགས་ཀྱི་ལག་འཁྱེར་གྱི་ཚོར་བ'}
{'en': 'Simultaneous translation is a task in which ', 'ar': 'الترجمة الفورية هي مهمة تبدأ فيها الترجمة قبل أن ينتهي المتحدث من التحدث ، لذلك من المهم تحديد موعد بدء عملية الترجمة. ومع ذلك ، فإن تحديد ما إذا كنت تريد قراءة المزيد من كلمات الإدخال أو البدء في الترجمة أمر صعب بالنسبة للأزواج اللغوية ذات ترتيب الكلمات المختلفة مثل الإنجليزية واليابانية. بدافع من مفهوم إعادة الترتيب المسبق ، نقترح بضع قواعد قرار بسيطة باستخدام تسمية المكون التالي الذي تنبأ به توقع التسمية التأسيسية التزايدية. في التجارب على الترجمة الفورية من الإنجليزية إلى اليابانية ، تفوقت الطريقة المقترحة على خطوط الأساس في مقايضة زمن انتقال الجودة.', 'es': 'La traducción simultánea es una tarea en la que la traducción comienza antes de que el orador haya terminado de hablar, por lo que es importante decidir cuándo iniciar el proceso de traducción. Sin embargo, decidir si leer más palabras de entrada o empezar a traducir es difícil para las combinaciones de idiomas con diferentes órdenes de palabras, como el inglés y el japonés. Motivados por el concepto de pre-reordenamiento, proponemos un par de reglas de decisión simples que utilizan la etiqueta del siguiente constituyente predicho por la predicción incremental de la etiqueta constituyente. En experimentos de traducción simultánea del inglés al japonés, el método propuesto superó a las líneas de base en la compensación calidad-latencia.', 'pt': 'A tradução simultânea é uma tarefa em que a tradução começa antes que o orador termine de falar, por isso é importante decidir quando iniciar o processo de tradução. No entanto, decidir se deve ler mais palavras de entrada ou começar a traduzir é difícil para pares de idiomas com ordens de palavras diferentes, como inglês e japonês. Motivados pelo conceito de pré-reordenação, propomos algumas regras de decisão simples usando o rótulo do próximo constituinte previsto pela predição incremental do rótulo do constituinte. Em experimentos de tradução simultânea de inglês para japonês, o método proposto superou as linhas de base na relação qualidade-latência.', 'fr': "La traduction simultanée est une tâche dans laquelle la traduction commence avant que l'orateur ait fini de parler. Il est donc important de décider quand commencer le processus de traduction. Cependant, il est difficile de décider s'il faut lire davantage de mots saisis ou commencer à traduire pour les paires de langues ayant des ordres de mots différents, comme l'anglais et le japonais. Motivés par le concept de pré-réorganisation, nous proposons quelques règles de décision simples utilisant l'étiquette du prochain constituant prédit par une prédiction incrémentielle d'étiquette de composant. Dans des expériences sur la traduction simultanée de l'anglais vers le japonais, la méthode proposée a surpassé les niveaux de référence en termes de compromis entre la qualité et la latence.", 'ja': '同時翻訳は、話者が話す前に翻訳が開始されるタスクであるため、翻訳プロセスを開始するタイミングを決定することが重要です。ただし、入力された単語をより多く読むか、翻訳を開始するかを決定することは、英語や日本語などの異なる単語順序を持つ言語ペアにとって困難です。事前順序付けの概念に動機づけられて、増分成分ラベル予測によって予測される次の成分のラベルを使用して、いくつかの単純な決定規則を提案します。英語から日本語への同時翻訳の実験では、提案された方法は品質-遅延トレードオフでベースラインを上回った。', 'zh': '同声传译者,先言而后译者也,故其始重也。 然于词序(如英语、日语)之言,读之益多单词与始译为难。 预重排序,立数策,用增量分标下一分标。 英语至日语同声传译之实验,其法优于质-迟权于基线。', 'ru': 'Синхронный перевод - это задача, в которой перевод начинается до того, как говорящий закончит говорить, поэтому важно решить, когда начинать процесс перевода. Тем не менее, решение о том, читать ли больше входных слов или начать переводить, трудно для языковых пар с разными порядками слов, такими как английский и японский. Основываясь на концепции предварительного упорядочения, мы предлагаем пару простых правил принятия решений с использованием метки следующего компонента, предсказанной с помощью инкрементного предсказания метки компонента. В экспериментах по синхронному переводу с английского на японский язык предлагаемый метод превзошел базовые показатели в плане компромисса между качеством и задержкой.', 'hi': 'एक साथ अनुवाद एक ऐसा कार्य है जिसमें वक्ता के बोलने से पहले अनुवाद शुरू होता है, इसलिए अनुवाद प्रक्रिया कब शुरू करनी है, यह तय करना महत्वपूर्ण है। हालांकि, यह तय करना कि क्या अधिक इनपुट शब्दों को पढ़ना है या अनुवाद करना शुरू करना अंग्रेजी और जापानी जैसे विभिन्न शब्द आदेशों के साथ भाषा जोड़े के लिए मुश्किल है। पूर्व-पुन: क्रमबद्ध करने की अवधारणा से प्रेरित होकर, हम वृद्धिशील घटक लेबल भविष्यवाणी द्वारा भविष्यवाणी किए गए अगले घटक के लेबल का उपयोग करके कुछ सरल निर्णय नियमों का प्रस्ताव करते हैं। अंग्रेजी-से-जापानी एक साथ अनुवाद पर प्रयोगों में, प्रस्तावित विधि ने गुणवत्ता-विलंबता ट्रेड-ऑफ में बेसलाइन को पछाड़ दिया।', 'ga': "Is tasc é aistriúchán comhuaineach ina gcuirtear tús leis an aistriúchán sula mbíonn an cainteoir críochnaithe ag labhairt, agus mar sin tá sé tábhachtach cinneadh a dhéanamh cén uair is cóir tús a chur leis an bpróiseas aistriúcháin. Mar sin féin, bíonn sé deacair ag péirí teangacha a bhfuil ord éagsúil focal acu ar nós Béarla agus Seapáinis a chinneadh cé acu ar cheart tuilleadh focal ionchuir a léamh nó tosú ar an aistriú. Arna spreagadh ag coincheap an réamh-athordaithe, molaimid cúpla riail chinnidh shimplí ag baint úsáide as lipéad an chéad chomhábhair eile arna thuar ag tuar incriminteach lipéad an chomhábhair. I dturgnaimh ar aistriúchán comhuaineach Béarla-go-Seapáinis, d'fheidhmigh an modh molta níos fearr ná na bunlínte sa chomhbhabhtáil cáilíochta-latency.", 'ka': 'QFontDatabase მაგრამ, გადაწყვება თუ უფრო მეტი შეტყობინებული სიტყვები ან დაწყვება სიტყვებისთვის განსხვავებული სიტყვებისთვის, როგორც ანგლისური და იაპონური მოტივირებულია პრე-ორდენტის კონფიგურაციაზე, ჩვენ გვეძლევა რამდენიმე უკეთესი გადაწყვეტილების კონფიგურაციას გამოყენებთ შემდეგი კონტიგურაციის ლებლის ლაბლის ექსპერიმენტებში ინგლისურად-იაპონურად ერთადერთი განგორმაციის შემთხვევაში, პროგრამის მეტი უფრო გავაკეთებულია ფესტური ხაზების შესაძლებლობაში.', 'hu': 'Az egyidejű fordítás olyan feladat, amelynek során a fordítás elkezdődik, mielőtt a felszólaló befejezte a beszédet, ezért fontos eldönteni, hogy mikor kezdje el a fordítási folyamatot. Azonban nehéz eldönteni, hogy több beviteli szót olvassanak-e el vagy fordítsanak-e a különböző szósorrendű nyelvpároknál, mint például angol és japán. Az előrendelés koncepciójának motiválására néhány egyszerű döntési szabályt javasolunk a következő alkotóelem címkéjének felhasználásával, amelyeket inkrementális alkotóelem címke előrejelzéssel előrejelzett. Az angol-japán szimultán fordítással kapcsolatos kísérletekben a javasolt módszer felülmúlta a minőség-késleltetés kereskedelmét.', 'el': 'Η ταυτόχρονη μετάφραση είναι ένα έργο στο οποίο η μετάφραση αρχίζει πριν τελειώσει ο ομιλητής, οπότε είναι σημαντικό να αποφασίσετε πότε θα ξεκινήσετε τη διαδικασία μετάφρασης. Ωστόσο, η απόφαση για το αν θα διαβάσετε περισσότερες λέξεις εισόδου ή να αρχίσετε να μεταφράζετε είναι δύσκολη για γλωσσικά ζεύγη με διαφορετικές τάξεις λέξεων, όπως τα αγγλικά και τα ιαπωνικά. Με κίνητρο την έννοια της προ-αναδιατάστασης, προτείνουμε δύο απλούς κανόνες απόφασης χρησιμοποιώντας την ετικέτα του επόμενου συστατικού που προβλέπεται από την προοδευτική πρόβλεψη της συστατικής ετικέτας. Σε πειράματα στην αγγλική-ιαπωνική ταυτόχρονη μετάφραση, η προτεινόμενη μέθοδος ξεπερνούσε τις γραμμές βάσης στο συμβιβασμό ποιότητας-καθυστέρησης.', 'it': "La traduzione simultanea è un compito in cui la traduzione inizia prima che l'oratore abbia finito di parlare, quindi è importante decidere quando avviare il processo di traduzione. Tuttavia, decidere se leggere più parole di input o iniziare a tradurre è difficile per coppie di lingue con ordini di parole diversi come inglese e giapponese. Motivati dal concetto di pre-riordino, proponiamo un paio di semplici regole decisionali utilizzando l'etichetta del costituente successivo prevista dalla previsione incrementale dell'etichetta costituente. Negli esperimenti sulla traduzione simultanea inglese-giapponese, il metodo proposto ha superato le linee di base nel trade-off qualità-latenza.", 'kk': 'Бірақ аудармалы - аудармалы орындаушы сөйлесу аяқталмаған алдында аудармалы тапсырма, сондықтан аудармалы процесін қазір бастау үшін мәселе беру үшін маңызды. Бірақ, бірнеше кіріс сөздерді оқу не аудару үшін бастау үшін тіл екеуі әртүрлі сөздерді ағылшын және япон тілдері секілді әртүрлі реттері үшін қиын. Алдын- қайта реттеу концепциясы бойынша жылжытылады, біз келесі концепциясының белгісін қолдану үшін көп қарапайым шешім ережелерін қолдануға болады. Ағылшын тілінен жапон тілінен бір-бір аудару туралы тәжірибелерде ұсынылған тәжірибелер сапаттың негізгі сызықтарын сапаттау.', 'mk': 'Симултанеозен превод е задача во која преводот започнува пред говорникот да заврши со говорот, па важно е да се одлучи кога да започне процесот на превод. Сепак, одлучувањето дали треба да читате повеќе внесени зборови или да почнете да преведувате е тешко за јазичките парови со различни наредби на зборови како што се англиски и јапонски. Мотивирано од концептот на прередовување, предложуваме неколку едноставни правила за одлука со користење на етикетата на следниот конститунт предвидена со провидување на поставувачките конститунти на етикетата. Во експериментите на истовремениот превод англиско-јапонски, предложениот метод ги надмина основните линии во размената за квалитет-лантенција.', 'lt': 'Simultaneous translation is a task in which translation begins before the speaker has finished speaking, so it is important to decide when to start the translation process.  However, deciding whether to read more input words or start to translate is difficult for language pairs with different word orders such as English and Japanese.  Motivated by the concept of pre-reordering, we propose a couple of simple decision rules using the label of the next constituent predicted by incremental constituent label prediction.  In experiments on English-to-Japanese simultaneous translation, the proposed method outperformed baselines in the quality-latency trade-off.', 'ms': 'Terjemahan bersamaan adalah tugas dimana terjemahan bermula sebelum pembicara selesai, jadi penting untuk memutuskan bila untuk memulakan proses terjemahan. Namun, memutuskan sama ada untuk membaca lebih banyak perkataan input atau mula menerjemahkan adalah sukar untuk pasangan bahasa dengan arahan perkataan berbeza seperti bahasa Inggeris dan Jepun. Dimotifkan oleh konsep pre-reordering, kami cadangkan beberapa peraturan keputusan sederhana menggunakan label komponen seterusnya dijangka oleh ramalan label komponen tambahan. In experiments on English-to-Japanese simultaneous translation, the proposed method outperformed baselines in the quality-latency trade-off.', 'mn': 'Үүнтэй адилхан орчуулалт бол орчуулагч яриаг дуусахаас өмнө орчуулалт эхлүүлэх үйл ажиллагаа юм. Тиймээс орчуулалтын процессийг хэзээ эхлүүлэхийг шийдэх нь чухал. Гэхдээ илүү олон орнуудын үгийг унших эсвэл хөгжүүлэх эсэхийг шийдэх нь хэл хоёр нь Англи, Япон зэрэг өөр үг дарааллаар хэцүү. Өмнөх эргүүлэлтийн ойлголтын хувьд хөдөлгөөнтэй, дараагийн загварын загварын загварын загварыг ашиглах хэдэн энгийн шийдвэрлэлтийг санал болгож байна. Англи болон Япон зэрэг одоогийн орчуулалтын туршилтуудын хувьд санал өгсөн арга нь үндсэн шугамнуудыг сайн сайжруулсан.', 'pl': 'Tłumaczenie symultaniczne to zadanie, w którym tłumaczenie rozpoczyna się zanim mówca skończy mówić, dlatego ważne jest, aby zdecydować, kiedy rozpocząć proces tłumaczenia. Jednak decyzja, czy przeczytać więcej słów wejściowych lub zacząć tłumaczyć, jest trudna dla par językowych o różnych kolejnościach słów, takich jak angielski i japoński. Motywowani koncepcją wstępnego porządkowania proponujemy kilka prostych reguł decyzji wykorzystujących etykietę następnego składnika przewidywaną przez przyrostową predykcję etykiety składnikowej. W eksperymentach nad tłumaczeniem symultanicznym angielsko-japońskim proponowana metoda przewyższyła linie bazowe w kompromisie jakości-opóźnienia.', 'no': 'Somme omsetjing er ei oppgåve som omsetjinga startar før taleren er ferdig å snakke, så det er viktig å bestemma kor gong omsetjingsprosessen skal startast. Dette er likevel vanskeleg å bestemme om fleire inndata- ord skal lesast eller starta å oversette for språkopar med ulike ordordordlister som engelsk og japansk. Forskyving av konsepten for forordning, foreslår vi ein par enkle avgjøringsreglar med merkelappen til neste konstituent som foreslått av forhåndsvising av ekstremt konstituent- merkelappen. I eksperimenter om samtidig omsetjing av engelsk-til-japansk har det foreslått metoden utført baselinjer i kvalitetsfargen.', 'ro': 'Traducerea simultană este o sarcină în care traducerea începe înainte ca vorbitorul să termine cuvântul, deci este important să decideți când să începeți procesul de traducere. Cu toate acestea, decizia dacă să citească mai multe cuvinte introduse sau să înceapă să traducă este dificilă pentru perechile de limbi cu ordine diferite de cuvinte, cum ar fi engleza și japoneza. Motivați de conceptul de pre-reordonare, propunem câteva reguli de decizie simple folosind eticheta următorului constituent prevăzută prin predicția incrementală a etichetei constituente. În experimentele privind traducerea simultană din engleză în japoneză, metoda propusă a depășit liniile de bază în compromisul calitate-latență.', 'ml': 'സ്പീക്ടര്\u200d സംസാരം പൂര്\u200dത്തിയാക്കുന്നതിനു മുമ്പായി അനുവാദം തുടങ്ങുന്ന ഒരു ജോലിയാണു് അതുകൊണ്ടു് പരിഭാഷപ്രക്ര എന്നാലും, ഇന്\u200dപുട്ട് വാക്കുകള്\u200d വായിക്കണമോ അല്ലെങ്കില്\u200d പരിഭാഷപ്പെടുത്താനോ തുടങ്ങുന്നതോ ഭാഷ ജോട്ടുകാര്\u200dക്ക്  വീണ്ടും നിര്\u200dദേശിക്കുന്നതിന്റെ ആശയം നമ്മള്\u200d പ്രാവര്\u200dത്തികമായി പ്രവചിക്കുന്നത് അടുത്ത കോണ്\u200dട്ടെന്\u200dറിന്\u200dറെ ലേബറിന്\u200dറെ ലേബില്\u200d ഉപ ഇംഗ്ലീഷില്\u200d നിന്നും ജപ്പാനീസിലേക്കും ഒരേ സമയത്തെ പരീക്ഷണങ്ങളില്\u200d പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയില്\u200d മാറ്റിയിരിക്ക', 'mt': 'It-traduzzjoni simultanja hija kompitu li fih tibda t-traduzzjoni qabel ma l-kelliem ikun lest jitkellem, għalhekk huwa importanti li jiġi deċiż meta jinbeda l-proċess tat-traduzzjoni. Madankollu, id-deċiżjoni dwar jekk għandekx taqra aktar kliem input jew tibda tittraduċi hija diffiċli għall-pari lingwistiċi b’ordnijiet ta’ kliem differenti bħall-Ingliż u l-Ġappuniż. Motivated by the concept of pre-reordering, we propose a couple of simple decision rules using the label of the next constituent predicted by incremental constituent label prediction.  In experiments on English-to-Japanese simultaneous translation, the proposed method outperformed baselines in the quality-latency trade-off.', 'si': 'සාමාන්\u200dය භාවිතානය තමයි භාවිතානය පටන් ගන්න පුළුවන් වැඩක්, ඉතින් භාවිතානය පටන් ගන්න පුළුවන් වැඩක්. නමුත්, වෙනස් වචන පණිවිඩයක් කියනවද නැත්නම් පටන් ගන්න පුළුවන් වෙනස් වචන පණිවිඩය සමග ඉංග්\u200dරීසි සහ ප්\u200dරස්ථාපනය සඳහා ප්\u200dරස්ථාපනය කරනවා, අපි ප්\u200dරස්ථාපනය කරනවා සාමාන්\u200dය තීරණ නීතියක් සඳහා ඊළඟ ප්\u200dරස්ථාපනය සඳහා ප්\u200dරශ් ඉංග්\u200dරීසියෙන් ජාපානියෙන් එකම වාර්තාවක් ගැන පරීක්ෂණාවක් වලින්, ප්\u200dරතිචාරිත විදියට ප්\u200dරතිචාරිත', 'so': "Turjumista isla markaasna waa shaqo ku qoran turjumista uu bilaabayo ka hor inta uu hadluhu dhamaado hadalka, sidaas darteed waa muhiim in aad go’aano goorma sameynta turjumaadda. Si kastaba ha ahaatee, go’aanka in la akhriyo hadalka warqada ah ama la bilaabo in lagu turjumo waa u adag yihiin labo luqada ah oo ku qoran amar kala duduwan sida Ingiriis iyo Jabanees. Waxaynu soo dhaqdhaqaaqnaa fikrada hore oo soo celinta, waxaynu soo jeedaynaa dhawr qaynuunno fudud oo go'aan ah, waxaynu isticmaalaynaa calaamadda qofka soo socda oo laguu soo sheegay wax laguu sii sheegay calaamada guud ee kordhiska. Imtixaanka ku qoran turjumaadda Ingiriiska-Japanese isla markaasna qaabkii la soo jeeday uu ku qoray qoraalka hoose-hoose ee ganacsiga-dhamaanka.", 'sv': 'Samtidig översättning är en uppgift där översättningen börjar innan talaren har talat färdigt, så det är viktigt att bestämma när översättningsprocessen ska påbörjas. Det är dock svårt att avgöra om du vill läsa fler inmatningsord eller börja översätta för språkpar med olika ordordningar som engelska och japanska. Motiverat av konceptet pre-order föreslår vi ett par enkla beslutsregler med hjälp av etiketten för nästa komponent som förutses genom inkrementell komponentetikett förutsägelse. I experiment med simultant översättning från engelska till japanska överträffade den föreslagna metoden baselines i kompromissen mellan kvalitet och latens.', 'ur': 'Simultaneous translation is a task in which translation begins before the speaker has finished speaking, so it is important to decide when to start the translation process. However, deciding whether to read more input words or start to translate languages pairs with different word orders such as English and Japanese. پیش آئندر کی نظریہ سے چلنا ہے، ہم ایک دوسرے ساده فیصلہ کے قانون کو آئندہ قانون کے لابلیٹ کے مطابق پیش آئندہ قانون کے ذریعے پیش آئندہ کیا گیا ہے. انگلیسی سے جاپانی کی تجربیات میں ایک دفعہ ترجمہ میں، پیشنهاد کی طریقہ نے کیفیت-لاٹنسی تجارت-اف میں بنیس لینوں کو زیادہ انجام دیا۔', 'ta': 'Simultaneous translation is a task in which translation begins before the speaker has finished speaking, so it is important to decide when to start the translation process.  However, deciding whether to read more input words or start to translate is difficult for language pairs with different word orders such as English and Japanese.  முன் வரிசையின் கருத்து மாற்றப்பட்டது, நாம் அடுத்த தேர்ந்தெடுக்கப்பட்ட அடுத்த த தீர்ப்பு விதிகளை பயன்படுத்தி சில எளிய தீர்ப்பு வித ஆங்கிலத்தில் இருந்து ஜப்பானிய மொழிபெயர்ப்பில் சோதனைகளில், திருந்திக்கப்பட்ட முறைமையில் தரம்- latency trade- off உள்ள அடிப்படை', 'sr': 'Istodobni prevod je zadatak u kojem prevod počinje pre nego što govor završi govoriti, tako da je važno odlučiti kada započeti proces prevoda. Međutim, odlučujući da li čitati više ulaznih reči ili početi prevoditi je teško za jezičke parove sa različitim naređenjima reči kao što su engleski i japanski. Motivirani koncepcijom prereordinacije, predlažemo par jednostavnih pravila odluke koristeći etiketu sljedećeg sastavnika predviđenog povećavajućim predviđanjem etiketa. U eksperimentima o istovremenom prevodu engleskog na japanski, predložena metoda je nadmašila osnovne linije u trgovini kvalitetom-latencijom.', 'uz': "@ info: whatsthis Lekin, ingliz va Япон kabi so'zlarni oʻqishni yoki tarjima qilishni boshlashni bir xil so'zlar uchun qiyin. Qaytarishdan oldin qo'yish tomonidan foydalanilgan, biz bir necha oddiy xabar qoidalarini keyingi qanday bogʻ'lash qoidasini ishlatish mumkin. Engliz-Yaponchaga bir xil tarjima tarjima qilish imtiyozlarida, taʼminlov qilingan usuli sifatida latency trading-off bilan bazalashtirilgan.", 'vi': 'Bản dịch đồng thời là một nhiệm vụ bắt đầu phiên dịch trước khi diễn giả nói xong, nên cần quyết định khi nào thì bắt đầu quá trình dịch. Tuy nhiên, việc quyết định nên đọc nhiều từ nhập hay bắt đầu dịch là rất khó đối với các cặp ngôn ngữ với các từ khác nhau như tiếng Anh và Nhật. Động đến khái niệm sắp xếp, chúng tôi đề xuất một vài quy tắc quyết định đơn giản, dùng nhãn của cử tri kế tiếp được dự đoán dựa trên các biểu tượng khác nhau. Trong thí nghiệm dịch đồng thời Anh-Qua-Nhật Bản, phương pháp được đề nghị hoàn thành trên nền tảng trong việc trao đổi tiềm năng tiềm ẩn.', 'hr': 'Istodobni prevod je zadatak u kojem prevod počinje prije nego što govor završi govoriti, tako da je važno odlučiti kada početi proces prevoda. Međutim, odlučivanje da li čitati više ulaznih riječi ili početi prevoditi je teško za jezičke parove s različitim naredbama riječi poput engleskog i japanskog. Pod motivacijom koncepta predoređenja, predlažemo par jednostavnih pravila odluke koristeći etiketu sljedećeg sastavnika predviđenog povećavajućim predviđanjem etiketa. U eksperimentima o istovremenom prevodu engleskog i japanskog jezika, predložena metoda je nadmašila osnovne linije u trgovini kvalitetom-latencijom.', 'bg': 'Едновременният превод е задача, при която преводът започва преди говорещият да приключи речта, така че е важно да решите кога да започнете преводния процес. Въпреки това, решаването дали да прочетете повече въведени думи или да започнете да превеждате е трудно за езикови двойки с различни реда на думите, като английски и японски. Мотивирани от концепцията за предварително пренареждане, ние предлагаме няколко прости правила за вземане на решение, използвайки етикета на следващата съставна съставка, прогнозирана чрез прогресивно прогнозиране на етикета на съставната съставна съставка. При експерименти на английски-японски симултанен превод предложеният метод надминава базовите линии в компромиса качество-латентност.', 'da': 'Samtidig oversættelse er en opgave, hvor oversættelsen begynder, inden taleren er færdig med at tale, så det er vigtigt at beslutte, hvornår oversættelsesprocessen skal startes. Det er imidlertid vanskeligt for sprogpar med forskellige ordrækkefølger som engelsk og japansk at beslutte, om du vil læse flere indtastede ord eller begynde at oversætte. Motiveret af begrebet pre-order foreslår vi et par enkle beslutningsregler ved hjælp af etiketten på den næste bestanddel, der forudsiges ved inkrementel komponent label forudsigelse. I forsøg med simultant oversættelse fra engelsk til japansk klarede den foreslåede metode sig bedre end basislinjerne i kompromiset mellem kvalitet og latens.', 'nl': 'Simultane vertaling is een taak waarbij de vertaling begint voordat de spreker klaar is met spreken, dus het is belangrijk om te beslissen wanneer het vertaalproces wordt gestart. Echter, de beslissing om meer invoerwoorden te lezen of te beginnen met vertalen is moeilijk voor taalparen met verschillende woordvolgorde zoals Engels en Japans. Gemotiveerd door het concept van pre-reordering, stellen we een paar eenvoudige beslissingsregels voor met behulp van het label van het volgende component voorspeld door incrementele component label voorspelling. In experimenten met simultane vertaling van Engels naar Japans presteerde de voorgestelde methode beter dan de basislijnen in de compromis tussen kwaliteit en latentie.', 'fa': 'ترجمه مشابه یک کار است که ترجمه قبل از اینکه صحبت کننده تموم شود شروع می\u200cشود، بنابراین برای تصمیم گرفتن فرآیند ترجمه زمانی مهم است. ولی تصمیم بگیرید که آیا کلمات ورودی بیشتری بخوانید یا شروع به ترجمه کردن برای جفت زبان با دستورات کلمات مختلف مثل انگلیسی و ژاپنی سخت است. توسط مفهوم پیش\u200cاندازی پیش\u200cاندازی، چند قانون تصمیم ساده را پیشنهاد می\u200cکنیم با استفاده از نقاشی نقاشی محیط بعدی که توسط پیش\u200cاندازی نقاشی\u200cهای پیش\u200cاندازی برچسب\u200cهای بیشتر پیش\u200cبینی می\u200cشود. در آزمایشات در ترجمه همزمان انگلیسی به ژاپن، روش پیشنهاد پایین\u200cخط\u200cهای زیرزمینی در تجارت کیفیت-latency-off را بیشتر انجام داد.', 'id': 'Simultaneous translation is a task in which translation begins before the speaker has finished speaking, so it is important to decide when to start the translation process.  Namun, memutuskan apakah untuk membaca lebih banyak kata input atau mulai menerjemahkan adalah sulit untuk pasangan bahasa dengan perintah kata yang berbeda seperti bahasa Inggris dan Jepang. Dimotifkan oleh konsep pre-reordering, kami mengusulkan beberapa aturan keputusan sederhana menggunakan label konstitusi berikutnya diprediksi oleh prediksi konstitusi incremental label. Dalam eksperimen pada terjemahan simultan bahasa Inggris-Jepang, metode yang diusulkan melampaui garis dasar dalam perdagangan kualitas-latensi.', 'tr': 'Tutaryş edilen bir täblisasdir, sözlediň gürrüňi bitirmeden öň terjime edilen täblisasynda başlaýan täblisasynda, şonuň üçin terjime edilen prosesini nähili başlatmak üçin wajypdyr. Iňlisçe we Japonça diller bilen terjime etmek üçin has kyn sözleri okamak ýa-da terjime etmek. Öňki düzenlemek concept tarapyndan Motiveýan, indiki konstituent etiket öňünden gelen etiketlerden ullanýan birnäçe basit karara teklif edip görýäris. Iňlis-ýa-japonça terjime edilen suratlarda teklip eden çykyşlarda görkezilen çykyş hasaplanja golaýlaşdy.', 'sw': 'Tafsiri moja kwa moja ni jukumu ambalo tafsiri inaanza kabla hotuba yake imekwisha kuzungumza, kwa hiyo ni muhimu kuamua lini kuanza mchakato wa tafsiri. Hata hivyo, kuamua kama kusoma maneno zaidi ya input au kuanza kutafsiri ni vigumu kwa ajili ya wanaume wa lugha wenye amri tofauti za maneno kama vile Kiingereza na Kijapani. Kuhamasishwa na dhana ya kuamuru kabla ya upya, tunapendekeza sheria kadhaa rahisi za uamuzi kwa kutumia alama ya mpiga kura ijayo iliyotabiriwa na utabiri wa alama ya ubunge wa ukubwa. Katika majaribio yanayohusu tafsiri ya Kiingereza hadi Japani kwa wakati mmoja, mbinu hiyo ya pendekezo ilionyesha msingi katika biashara ya ubora.', 'sq': 'Përkthimi në të njëjtën kohë është një detyrë në të cilën përkthimi fillon përpara se folësi të përfundojë duke folur, kështu që është e rëndësishme të vendosësh kur të fillosh procesin e përkthimit. Megjithatë, vendosja nëse duhet të lexosh më shumë fjalë të hyrjes apo të fillosh të përkthyesh është e vështirë për çiftet e gjuhës me urdhëra të ndryshme fjalësh të tilla si anglisht dhe japonez. Motivuar nga koncepti i pararenditjes, ne propozojmë disa rregulla të thjeshta vendimi duke përdorur etiketën e përbërësit të ardhshëm të parashikuar nga parashikimi shtesë i etiketës së përbërësve. Në eksperimentet në përkthimin e njëkohëshëm anglez-japonez, metoda e propozuar kaloi linjat bazë në kompromisin e cilësisë-vonesës.', 'de': 'Die Simultanübersetzung ist eine Aufgabe, bei der die Übersetzung beginnt, bevor der Sprecher mit dem Sprechen fertig ist. Daher ist es wichtig zu entscheiden, wann der Übersetzungsprozess begonnen werden soll. Für Sprachpaare mit unterschiedlichen Wortreihen wie Englisch und Japanisch ist es jedoch schwierig, zu entscheiden, ob Sie mehr eingegebene Wörter lesen oder mit der Übersetzung beginnen möchten. Motiviert durch das Konzept der Pre-Reorder, schlagen wir ein paar einfache Entscheidungsregeln vor, die das Label der nächsten Komponente verwenden, das durch inkrementelle Component Label Vorhersage vorhergesagt wird. In Experimenten zur Englisch-Japanisch-Simultanübersetzung übertraf die vorgeschlagene Methode die Baselines im Qualitäts-Latenz-Kompromiss.', 'af': "Ongelyklike vertaling is 'n taak waarin vertaling begin voor die spreker klaar spreek het, sodat dit is belangrik om te besluit wanneer na begin die vertaling proses. Maar die besluit of meer invoer woorde lees of begin om te vertaal is moeilik vir taal paars met verskillende woord ordorde soos Engels en Japanse. Gebeweging deur die konsepte van voor- herordening, voorstel ons 'n paar eenvoudige besluit reëls te gebruik die etiket van die volgende konstituent wat deur inkremensielike konstituent etiket voorskou is. In eksperimente oor Engels-na-Japanse samekomstige vertaling, het die voorgestelde metode uitgevoer basisline in die kwaliteit-latensie handel af.", 'am': 'በተመሳሳይ ትርጉም በተርጓሚው ንግግር ከመፈጸም በፊት ትርጉም የሚጀምርበት ስራ ነው፤ ስለዚህም ትርጉም ፕሮግራምን መጀመሪያ መፍጠር ያስፈልጋል፡፡ ምንም እንኳን፣ የበዛ የinput ቃላት ማነብ ወይም መተርጉም ለቋንቋ ዓይነቶች በተለየ ቃላት ሥርዓቶች እንደ እንግሊዘኛ እና ጃፓንኛ መሆኑን ማድረግ ግድ ነው፡፡ የቀድሞው ትርጉም በሚያሳየው አካባቢ፣ በአሁለተኛው ሰርቨርስቲ የመንግሥት ምልክት በመጠቀም የሚታወቀውን የውይይት ሕግ እናሳውቃለን፡፡ በንግግሊዝና-ወደ ጃፓን በተጨማሪው ትርጓሜ ላይ በተፈተና፣ በጥሩ-latency ንግድ-off የተፈጸመ ደረጃዎች ላይ የተፈጸመ ሥርዓት ነው፡፡', 'hy': 'Միևնույն թարգմանությունը մի խնդիր է, որտեղ թարգմանությունը սկսվում է մինչ խոսացողը ավարտել է խոսքը, ուստի կարևոր է որոշել, երբ սկսել է թարգմանման գործընթացը: Այնուամենայնիվ, որոշել, թե ավելի շատ ներմուծված բառեր կարդալ կամ սկսել թարգմանել, դժվար է լեզվի զույգերի համար, որոնք տարբեր բառերի կարգավորումներ ունեն, ինչպիսիք են անգլերենը և ճապոներենը: Հրաշարժված նախադասավորման գաղափարով, մենք առաջարկում ենք մի քանի պարզ որոշումների կանոններ, օգտագործելով հաջորդ բաղադրիչների պիտակը, որը կանխատեսվում է աճող բաղադրիչների պիտակի կանխատեսման միջոցով: Անգլերեն-ճապոներեն միևնույն թարգմանման փորձարկումներում առաջարկված մեթոդը գերազանցեց որակի-լանցիայի փոխարկման հիմնական գծերը:', 'az': 'Tərcümə tərcümə danışmaq bitməmişdən əvvəl tərcümə başlamaq üçün başlayan bir işdir, böylece tərcümə işlətməsi nə vaxt başlayacağına qərar vermək mövcuddur. Lakin, daha çox girdi sözləri oxumaq və ya tercümə etmək üçün dil çiftləri üçün müxtəlif söz sıraları kimi İngilizə və Japonca kimi çətin deyildir. Əvvəlcə-reordering konsepti ilə hərəkət edilmişdir, biz bir neçə basit karar kurallarını təklif edirik ki, sonraki constituent etiketinin etiketini artırmaq məqsədilə tədbir edilmişdir. İngilizə-Japonca ilə birlikdə çevirilən təcrübələrdə təklif edilən metod kaliteli-latenci ticarət dəyişdirilməsi üçün baz çətinliklərdən üstün olmuşdur.', 'bn': 'একই সাথে অনুবাদ হচ্ছে একটি কাজ যেখানে বক্তৃপক্ষকে কথা শেষ করার আগে অনুবাদ শুরু করা হয়, তাই অনুবাদ প্রক্রিয়া শুরু করার জন্য এটি  তবে সিদ্ধান্ত নেয়া হচ্ছে যে ভাষার জোড়ার জন্য বিভিন্ন শব্দের নির্দেশ যেমন ইংরেজি এবং জাপানীয়। পুনরায় নির্দেশের ধারণা দ্বারা প্রস্তাব করা হয়েছে, আমরা পরবর্তী ভোটেন্টের লেবেল ব্যবহার করে সাধারণ সিদ্ধান্ত নিয়ম প্রস্তাব করি। ইংরেজি থেকে জাপানীদের একই সাথে অনুবাদের পরীক্ষায় প্রস্তাবিত পদ্ধতি মান-লেটেন্সি ব্যান্ড-আফের মানে বেসারেন্ট', 'bs': 'Istodobni prevod je zadatak u kojem prevod počinje prije nego što govornik završi govoriti, tako da je važno odlučiti kada započeti proces prevoda. Međutim, odlučivanje da li čitati više ulaznih riječi ili početi prevoditi je teško za parove jezika sa različitim naredbama riječi poput engleskog i japanskog. Motivirani koncepcijom prereordinacije, predlažemo par jednostavnih pravila odluke koristeći etiketu sljedećeg sastavnika predviđenog povećavajućim predviđanjem etikete. U eksperimentima o istovremenom prevodu engleskog na japanski, predložena metoda je nadmašila osnovne linije u trgovini kvalitetom-latencijom.', 'cs': 'Současný překlad je úkol, při kterém překlad začíná dříve, než mluvčí dokončí mluvit, proto je důležité rozhodnout, kdy začít překladatelský proces. Nicméně, rozhodnutí, zda číst více vstupních slov nebo začít překládat, je obtížné pro jazykové páry s různými pořadími slov, jako je angličtina a japonština. Motivováni konceptem předřazení navrhujeme několik jednoduchých rozhodovacích pravidel s využitím štítku další složky predikované inkrementální predikcí štítku. V experimentech s simultánním překladem z angličtiny do japonštiny navržená metoda předčila základní linie v kompromisu kvality a latence.', 'ca': "La traducció simultànea és una tasca en la que comença la traducció abans que l'orador acabi de parlar, així que és important decidir quan començar el procés de traducció. Però decidir si llegir més paraules d'entrada o començar a traduir és difícil per a parelles de llengües amb diferents ordres de paraules com l'anglès i el japonès. Motivat pel concepte de pré-reorganització, proposem un parell de regles simples de decisió utilitzant l'etiqueta del següent constituent predit per predicció incremental de l'etiqueta constituent. En experiments de traducció simultànea anglès-japonès, el mètode proposat va superar les línies de base en el compromís entre la qualitat i la latencia.", 'et': 'Sünkroontõlge on ülesanne, kus tõlkimine algab enne kõneleja kõne lõpetamist, seega on oluline otsustada, millal alustada tõlkeprotsessi. Kuid otsustada, kas lugeda rohkem sisendsõnu või alustada tõlkimist, on keelepaaride jaoks raske erinevate sõnade järjekorras, nagu inglise ja jaapani keel. Motiveerituna eeljärjestuse mõistest pakume välja paar lihtsat otsusereeglit, kasutades järgmise koostisosa märgistust, mida prognoositakse täiendava koostisosa märgistuse prognoosimisel. Inglise-jaapani sünkroontõlke eksperimentides ületas kavandatud meetod lähtejooni kvaliteedi-latentsuse kompromiss.', 'fi': 'Simultaanik채채nn철s on teht채v채, jossa k채채nn철s alkaa ennen puhujan puheenvuoron p채채ttymist채, joten on t채rke채채 p채채tt채채, milloin k채채nn철sprosessi aloitetaan. Kuitenkin p채채t철s siit채, luetaanko lis채채 sy철tt철sanoja vai aletaanko k채채nt채채, on vaikea kielipareille, joilla on eri sanaj채rjestys, kuten englanti ja japani. Esij채rjestyksen k채sitteen motivoituneena ehdotamme muutamia yksinkertaisia p채채t철ss채채nt철j채 k채ytt채en seuraavan komponentin etiketti채, joka ennustetaan inkrementaalisella komponentin etiketin ennustuksella. Englannin-japanin simultaanik채채nn철ksen kokeiluissa ehdotettu menetelm채 ylitti l채ht철arvot laatu-viive-kompromississa.', 'ko': '동시통역은 말하는 사람이 말을 하기 전에 번역을 시작하는 임무이기 때문에 언제 번역 과정을 시작할지 결정하는 것이 중요하다.그러나 영어와 일본어 등 어순이 다른 언어는 입력된 단어를 더 많이 읽을지 번역을 시작할지 결정하기가 어렵다.예순열 개념의 계발을 받아 우리는 두 가지 간단한 결정 규칙을 제시했고 증량 성분 라벨로 예측한 다음 성분의 라벨을 사용했다.영어에서 일본어까지의 동시통역 실험에서 이 방법은 품질-지연 균형 방면에서 기선보다 우수하다.', 'jv': 'translation politenessoffpolite"), and when there is a change ("assertivepoliteness word Nang neng éntuk sing nggambar Inggris-kanggo Japon sampeyan, supoyo nggawe sistem sing ditambah barang kanggo tatara cara-teka.', 'ha': '@ info: tooltip @ label: listbox Akwai fara da zato na fara-umurni, muna goyyade cutar-biyu masu sauki da amfani da label na ƙari wanda aka yi gargaɗi da kuma an gabatar da littãfin na ƙari. In experiments on English-to-Japanese simultaneous translation, the proposed method outperformed baselines in the quality-latency trade-off.', 'sk': 'Sočasno prevajanje je naloga, pri kateri se prevajanje začne pred koncem govora, zato se je pomembno odločiti, kdaj začeti prevajanje. Vendar pa je odločitev, ali želite prebrati več vhodnih besed ali začeti prevajati, težko za jezikovne pare z različnimi vrstnimi redi besed, kot sta angleščina in japonščina. Motivirana s konceptom predhodnega razporejanja, predlagamo nekaj preprostih pravil odločanja z uporabo oznake naslednje sestavine, predvidene z napovedjo postopne nalepke sestavine. V poskusih simultanega prevajanja angleško-japonsko je predlagana metoda presegla izhodišče pri kompromisu kakovosti-latence.', 'he': 'התרגום באופן זמני הוא משימה שבה התרגום מתחיל לפני שהרמקול סיים לדבר, כך חשוב להחליט מתי להתחיל תהליך התרגום. עם זאת, להחליט אם לקרוא יותר מילים כניסה או להתחיל לתרגם זה קשה לזוגות שפות עם פקודות מילים שונות כמו אנגלית ויפנית. Motivated by the concept of pre-reordering, we propose a couple of simple decision rules using the label of the next constituent predicted by incremental constituent label prediction.  בניסויים על תרגומת אנגלית-ליפנית באותו זמן, השיטה המוצעת עברה את קווי הבסיס במסחר איכות-לאנטיות.', 'bo': 'Simultaneous translation is a task in which translation begins before the speaker has finished speaking. So it is important to decide when to start the translation process. ཡིན་ནའང་མིན་པར། འགྲེལ་བཙུགས་ཀྱི་གནད་སྡུད་མིན་འདུག Motivated by the concept of pre-reordering, we propose a couple of simple decision rules using the label of the next constituent predicted by incremental constituent label prediction. དབྱིན་ཡིག་ལས་ཉེ་ཧོང་གི་སྐད་ཆ་གཅིག་མཚུངས་ཀྱི་སྐད་འཚོལ་བྱ་ཚིག་ནང་།'}
{'en': 'Contrastive Learning for Context-aware Neural Machine Translation Using Coreference Information', 'fr': "Apprentissage contrastif pour la traduction automatique neuronale sensible au contexte à l'aide d'informations de coréférence", 'es': 'Aprendizaje contrastante para la traducción automática neuronal sensible al contexto mediante información de correferencia', 'pt': 'Aprendizado contrastivo para tradução automática neural sensível ao contexto usando informações de correferência', 'ar': 'التعلم التقابلي للترجمة الآلية العصبية الواعية بالسياق باستخدام معلومات Coreference', 'ja': 'コアリファレンス情報を使用した文脈認識ニューラル機械翻訳のための対照的な学習', 'ru': 'Контрастное обучение для контекстно-ориентированного нейронного машинного перевода с использованием информации Coreference', 'hi': 'कॉन्ट्रास्टिव लर्निंग फॉर कॉन्टेक्स्ट-अवेयर न्यूरल मशीन अनुवाद कोरफेरेंस जानकारी का उपयोग करके', 'zh': '用共推理信息者上下文感知神经机器翻译比学', 'ga': 'Foghlaim Chodarsnachta do Chomhthéacs Aistriúchán Inneall Néarach agus Buneolas á Úsáid', 'it': 'Apprendimento contrastante per la traduzione automatica neurale consapevole del contesto utilizzando le informazioni di Coreference', 'ka': 'კონტექსტიური მესწავლება კონტექსტის შესახებ ნეიროლური მაქინის გადატყვების გამოყენება ინფორმაციას', 'hu': 'Kontrasztus tanulás a kontextustudatos idegi gépi fordításhoz Coreferencia információk használatával', 'lt': 'Kontrastinis mokymasis su kontekstu susijusiam neurologinio mašinų vertimui naudojant koreferencinę informaciją', 'kk': 'Контексті қарайтын нейралы машинаны аудару үшін контрастық оқыту', 'el': 'Αντιστατική Μάθηση για Νευρική Μηχανική Μετάφραση με επίγνωση του Περιεχομένου Χρησιμοποιώντας Πληροφορίες Συνεργασίας', 'ms': 'Pembelajaran Kontrastensif untuk Terjemahan Mesin Neural yang Sedia-Konteks Menggunakan Maklumat Kesuaian', 'mk': 'Контрастивно учење за преведување на неврални машини со контекст со кореферентна информација', 'mt': 'Contrastive Learning for Context-aware Neural Machine Translation Using Coreference Information', 'ml': 'കോര്\u200dഫെന്\u200dസ് വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനുള്ള വിവരങ്ങള്\u200d', 'pl': 'Uczenie się kontrastywne dla kontekstowego tłumaczenia maszynowego neuronu za pomocą informacji Coreference', 'mn': 'Context-aware мэдрэмжтэй мэдрэмжтэй мэдрэмжтэй мэдрэмжтэй эсрэг суралцах', 'ro': 'Învățare contrastivă pentru traducerea automată neurală conștientă de context folosind informații corefente', 'sr': 'Kontrastivno učenje za neuronski prevod sa kontekstom korištenje informacija o korisnosti', 'si': 'සම්බන්ධ පරීක්ෂණය සඳහා ප්\u200dරතික්\u200dරියාත්මක පරීක්ෂණය සඳහා ප්\u200dරතික්\u200dරියාත්මක පරීක්ෂණය', 'no': 'Kontrastiv læring for omsetjing frå kontekstsverktøy, neuralmaskin- omsetjing ved bruk av koreferansinformasjon', 'sv': 'Kontrastivt lärande för kontextmedveten neural maskinöversättning med hjälp av Coreference-information', 'ta': 'சூழல் அறிந்த புதிய இயந்திரம் மொழிபெயர்ப்பிற்கான தொடர்பு கற்றுக் கொள்ளும் மாற்று மொழிபெயர்ப்பு', 'ur': 'Context-aware Neural Machine Translation for Contrastive Learning', 'so': 'Waxbarashada xiriirka ah ee macluumaadka koreference', 'uz': 'Name', 'vi': 'Tương phản học để dịch cỗ máy thần kinh tương ứng Dùng thông tin quốc phòng', 'bg': 'Контрастивно обучение за неврален машинен превод, осъзнаващ контекста, с помощта на информация за кореференцията', 'nl': 'Contrastief leren voor contextbewuste neuronale machinevertaling met behulp van Coreference-informatie', 'hr': 'Kontrastno učenje za prevod neuroloških strojeva na kontekstu koristeći informacije o korisnosti', 'da': 'Kontrastlæring til kontekstbevidst neural maskinoversættelse ved hjælp af Coreference-oplysninger', 'de': 'Kontrastives Lernen für kontextbewusste neuronale maschinelle Übersetzung mit Coreference-Informationen', 'ko': '공지 정보 기반의 상하문 감지 신경 기계 번역 비교 학습', 'id': 'Pelajaran Kontrastif untuk Translation Mesin Neural yang menyadari konteks menggunakan Informasi Koreferensi', 'fa': 'یادگیری متفاوتی برای ترجمه ماشین عصبی با آگاهی متن', 'sw': 'Tafsiri ya Mashine ya Ndani ya Utafiti wa Habari', 'af': 'Kontrastiewe leer vir Konteks- bewys Neurale Masjien Vertaling gebruik Koreferensieinformasie', 'tr': 'Kontekst bilen näral Maşynyň terjimesini ullanýan nusgatly öwrenmek', 'am': 'ይዞታዎች', 'az': 'Kontekst bilən nöral maşına çevirilən öyrənmək', 'bn': 'পরিচিত নিউরেল মেশিন অনুবাদ ব্যবহার করে কন্ট্রেক্স- সচেতনতার জন্য পরিচিত শিক্ষা', 'bs': 'Kontrastivno učenje za prevod neuroloških strojeva na kontekstu koristeći informacije o korisnosti', 'cs': 'Kontrastivní učení pro kontextový neuronový strojový překlad pomocí informací Coreference', 'ca': 'Aprendiment contrasteix per traducció de màquines neuronals conscients del contexte utilitzant informació de coreferència', 'sq': 'Mësimi Kontrastiv për Translacionin e Makinës Neurale me Kontekst duke përdorur informacionin e Koreferencës', 'fi': 'Kontrastitietoinen oppiminen kontekstitietoiseen neurokonekäännökseen Coreference-tietojen avulla', 'et': "Kontrastiline õpe kontekstiteadliku neuromasintõlke jaoks Coreference'i teabe abil", 'hy': 'Կոնտեքստի գիտակցած նեյրոնային մեքենայի թարգմանման հակադրական սովորելը օգտագործելով կորեֆերանսի տեղեկատվություն', 'sk': 'Kontrastno učenje za nevronski strojni prevod z uporabo informacij Coreference', 'ha': '@ action', 'jv': 'contrast', 'he': 'Contrastive Learning for Context-aware Neural Machine Translation Using Coreference Information', 'bo': 'Context-aware་དང་ཤེས་པའི་ལག་འཁྱེར་སྤྱོད་ལ་སྒྲིག་སྟངས་གཏོང་དགོས་པ'}
{'en': 'Context-aware neural machine translation (NMT) incorporates contextual information of surrounding texts, that can improve the translation quality of document-level machine translation. Many existing works on context-aware NMT have focused on developing new model architectures for incorporating additional contexts and have shown some promising results. However, most of existing works rely on cross-entropy loss, resulting in limited use of ', 'ar': 'تتضمن الترجمة الآلية العصبية الواعية بالسياق (NMT) معلومات سياقية للنصوص المحيطة ، والتي يمكن أن تحسن جودة الترجمة للترجمة الآلية على مستوى المستند. ركزت العديد من الأعمال الحالية على NMT الواعية بالسياق على تطوير بنى نموذجية جديدة لدمج سياقات إضافية وأظهرت بعض النتائج الواعدة. ومع ذلك ، فإن معظم الأعمال الحالية تعتمد على فقدان الانتروبيا ، مما يؤدي إلى استخدام محدود للمعلومات السياقية. في هذه الورقة ، نقترح CorefCL ، وهو مخطط جديد لزيادة البيانات والتعلم التباين يعتمد على المرجع بين المصدر والجمل السياقية. من خلال إفساد الإشارات المرجعية المكتشفة تلقائيًا في الجملة السياقية ، يمكن لـ CorefCL تدريب النموذج ليكون حساسًا لعدم تناسق المرجع. لقد جربنا طريقتنا على نماذج NMT المشتركة الواعية بالسياق ومهمتي ترجمة على مستوى المستند. في التجارب ، طريقتنا تعمل باستمرار على تحسين BLEU للنماذج المقارنة في المهام الإنجليزية-الألمانية والإنجليزية-الكورية. نوضح أيضًا أن طريقتنا تحسن بشكل كبير دقة المرجع في مجموعة اختبار التباين الإنجليزية الألمانية.', 'fr': "La traduction automatique neuronale sensible au contexte (NMT) intègre des informations contextuelles sur les textes environnants, ce qui peut améliorer la qualité de traduction de la traduction automatique au niveau du document. De nombreux travaux existants sur la NMT sensible au contexte se sont concentrés sur le développement de nouvelles architectures de modèles pour intégrer des contextes supplémentaires et ont donné des résultats prometteurs. Cependant, la plupart des œuvres existantes reposent sur la perte d'entropie croisée, ce qui entraîne une utilisation limitée des informations contextuelles. Dans cet article, nous proposons CoreFCL, un nouveau système d'apprentissage contrastif et d'augmentation des données basé sur la coréférence entre la source et les phrases contextuelles. En corrompant les mentions de coréférence détectées automatiquement dans la phrase contextuelle, CoreFCL peut entraîner le modèle à être sensible aux incohérences de coréférence. Nous avons expérimenté notre méthode sur des modèles NMT sensibles au contexte courants et sur deux tâches de traduction au niveau du document. Dans les expériences, notre méthode a constamment amélioré l'UEBL des modèles comparés sur des tâches anglais-allemand et anglais-coréen. Nous montrons également que notre méthode améliore considérablement la résolution de coréférence dans la suite de tests contrastifs anglais-allemand.", 'es': 'La traducción automática neuronal sensible al contexto (NMT) incorpora información contextual de los textos circundantes, lo que puede mejorar la calidad de la traducción automática a nivel de documento. Muchos trabajos existentes sobre NMT sensible al contexto se han centrado en el desarrollo de nuevas arquitecturas de modelos para incorporar contextos adicionales y han mostrado algunos resultados prometedores. Sin embargo, la mayoría de los trabajos existentes se basan en la pérdida de entropía cruzada, lo que resulta en un uso limitado de la información contextual. En este artículo, proponemos CoreFCL, un novedoso esquema de aumento de datos y aprendizaje contrastivo basado en la correferencia entre las oraciones fuente y contextuales. Al corromper las menciones de correferencia detectadas automáticamente en la oración contextual, CoreFCL puede entrenar al modelo para que sea sensible a la inconsistencia de correferencias. Experimentamos con nuestro método en modelos NMT comunes sensibles al contexto y dos tareas de traducción a nivel de documento. En los experimentos, nuestro método mejoró consistentemente el BLEU de los modelos comparados en las tareas inglés-alemán e inglés-coreano. También demostramos que nuestro método mejora significativamente la resolución de correferencia en el conjunto de pruebas de contraste inglés-alemán.', 'pt': 'A tradução automática neural sensível ao contexto (NMT) incorpora informações contextuais dos textos circundantes, que podem melhorar a qualidade da tradução automática no nível do documento. Muitos trabalhos existentes sobre NMT sensível ao contexto se concentraram no desenvolvimento de novas arquiteturas de modelo para incorporar contextos adicionais e mostraram alguns resultados promissores. No entanto, a maioria dos trabalhos existentes depende da perda de entropia cruzada, resultando em uso limitado de informações contextuais. Neste artigo, propomos o CorefCL, um novo esquema de aumento de dados e aprendizado contrastivo baseado na correferência entre a fonte e as sentenças contextuais. Ao corromper as menções de correferência detectadas automaticamente na sentença contextual, o CorefCL pode treinar o modelo para ser sensível à inconsistência de correferência. Experimentamos nosso método em modelos NMT com reconhecimento de contexto comuns e duas tarefas de tradução em nível de documento. Nos experimentos, nosso método melhorou consistentemente o BLEU de modelos comparados em tarefas inglês-alemão e inglês-coreano. Também mostramos que nosso método melhora significativamente a resolução de correferência no conjunto de testes contrastivos inglês-alemão.', 'ja': '文脈認識ニューラル機械翻訳（ NMT ）は、周囲のテキストの文脈情報を組み込み、文書レベルの機械翻訳の翻訳品質を向上させることができる。 文脈認識型NMTに関する多くの既存の研究は、追加の文脈を組み込むための新しいモデルアーキテクチャの開発に焦点を当てており、いくつかの有望な結果を示している。 しかし、既存の作品のほとんどはクロスエントロピー損失に依存しており、コンテキスト情報の使用が制限されています。 本稿では，ソース文と文脈文の間のコアレフィケーションに基づく新規のデータ拡張と対照的な学習スキームであるCorefCLを提案する． CorefCLは、コンテキスト文で自動的に検出されたコアリファレンスの言及を破壊することにより、コアリファレンスの不一致に敏感なモデルをトレーニングすることができます。 共通の文脈認識型NMTモデルと2つのドキュメントレベルの翻訳タスクに関する方法を実験しました。 実験では、私たちの方法は、英語とドイツ語、英語と韓国語の課題についてのBLEUモデルを比較して、一貫して改善されました。 また、この方法は、英独対照試験スイートのコアレファレンス分解能を大幅に向上させることを示しています。', 'zh': '上下文感神经机器翻译 (NMT) 含文本之上下文,可以崇文档级机器翻译译之质。 诸上下文知NMT者,皆注于开发新架构以并其上下文,以见所望也。 然大抵见文赖于交熵,而上下文信之用有限。 本文发CorefCL,盖源句、上下文句之间共指新型强对学方也。 破上下文句自动检测重复引用,CorefCL 可以训模异用。 常见上下文感 NMT 模形两文档译事试之。 实验之中,英语-德语与英语-韩语事BLEU不断改进。 吾道明矣英语-德语试套件之共指寻分辨率。', 'hi': 'संदर्भ-जागरूक तंत्रिका मशीन अनुवाद (एनएमटी) में आसपास के ग्रंथों की प्रासंगिक जानकारी शामिल है, जो दस्तावेज़-स्तर मशीन अनुवाद की अनुवाद गुणवत्ता में सुधार कर सकती है। संदर्भ-जागरूक एनएमटी पर कई मौजूदा कार्यों ने अतिरिक्त संदर्भों को शामिल करने के लिए नए मॉडल आर्किटेक्चर विकसित करने पर ध्यान केंद्रित किया है और कुछ आशाजनक परिणाम दिखाए हैं। हालांकि, अधिकांश मौजूदा कार्य क्रॉस-एन्ट्रॉपी हानि पर भरोसा करते हैं, जिसके परिणामस्वरूप प्रासंगिक जानकारी का सीमित उपयोग होता है। इस पत्र में, हम CorefCL, स्रोत और प्रासंगिक वाक्यों के बीच coreference के आधार पर एक उपन्यास डेटा वृद्धि और contrastive सीखने की योजना का प्रस्ताव करते हैं। प्रासंगिक वाक्य में स्वचालित रूप से पता लगाए गए coreference उल्लेखों को दूषित करके, CorefCL मॉडल को सह-संदर्भ असंगतता के प्रति संवेदनशील होने के लिए प्रशिक्षित कर सकता है। हमने सामान्य संदर्भ-जागरूक एनएमटी मॉडल और दो दस्तावेज़-स्तरीय अनुवाद कार्यों पर हमारी विधि के साथ प्रयोग किया। प्रयोगों में, हमारी विधि ने अंग्रेजी-जर्मन और अंग्रेजी-कोरियाई कार्यों पर तुलनात्मक मॉडल के BLEU में लगातार सुधार किया। हम यह भी दिखाते हैं कि हमारी विधि अंग्रेजी-जर्मन कंट्रास्टिव टेस्ट सूट में कोरेफेरेंस रिज़ॉल्यूशन में काफी सुधार करती है।', 'ru': 'Контекстно-ориентированный нейронный машинный перевод (НМП) включает в себя контекстную информацию окружающих текстов, которая может улучшить качество перевода машинного перевода на уровне документа. Многие текущие работы по контекстно-ориентированной НМТ были сосредоточены на разработке новых модельных архитектур для включения дополнительных контекстов и показали некоторые многообещающие результаты. Однако большинство существующих работ основаны на перекрестной энтропии, что приводит к ограниченному использованию контекстной информации. В этой статье мы предлагаем CorefCL, новую схему расширения данных и контрастного обучения, основанную на базовой ориентации между исходными и контекстными предложениями. Повреждая автоматически обнаруженные упоминания о базовой ориентации в контекстном предложении, CorefCL может обучить модель быть чувствительной к несоответствию базовой ориентации. Мы экспериментировали с нашим методом на общих контекстно-зависимых моделях НМТ и двух задачах перевода на уровне документа. В экспериментах наш метод последовательно улучшал BLEU сравниваемых моделей на англо-немецких и англо-корейских задачах. Мы также показываем, что наш метод значительно улучшает разрешение сердцевины в английском-немецком наборе контрастных тестов.', 'ga': 'Ionchorpraíonn aistriúchán meaisín néarach atá feasach ar an gcomhthéacs (NMT) faisnéis chomhthéacsúil na dtéacsanna máguaird, ar féidir leo cáilíocht aistriúcháin an aistriúcháin meaisín ar leibhéal doiciméad a fheabhsú. Dhírigh go leor oibreacha atá ann cheana féin ar NMT atá feasach ar an gcomhthéacs ar ailtireachtaí samhlacha nua a fhorbairt chun comhthéacsanna breise a ionchorprú agus léirigh siad roinnt torthaí a bhfuil gealladh fúthu. Mar sin féin, braitheann an chuid is mó de na hoibreacha atá ann faoi láthair ar chaillteanas tras-eantrópachta, rud a fhágann gur úsáideadh teoranta faisnéise comhthéacsúla. Sa pháipéar seo, molaimid CorefCL, scéim nua um mhéadú sonraí agus foghlama codarsnachta bunaithe ar chroí-chomhdháil idir an fhoinse agus abairtí comhthéacsúla. Trí luadh croíchomhdhála a bhraitear go huathoibríoch san abairt chomhthéacsúil a éilliú, is féidir le CorefCL oiliúint a chur ar an tsamhail le bheith íogair d’neamhréireacht croí-chomhréireachta. Rinneamar tástáil ar ár modh ar mhúnlaí comónta NMT a bhí feasach ar chomhthéacs agus ar dhá thasc aistriúcháin ag leibhéal doiciméad. Sna turgnaimh, chuir ár modh feabhas comhsheasmhach ar BLEU samhlacha comparáide ar thascanna Béarla-Gearmáinis agus Béarla-Cóiréis. Léirímid freisin go gcuireann ár modh feabhas suntasach ar réiteach croí-chomhdhála sa tsraith tástála codarsnachta Béarla-Gearmáinis.', 'hu': 'A kontextustudatos neurális gépi fordítás (NMT) tartalmazza a környező szövegek kontextuális információit, ami javíthatja a dokumentum szintű gépi fordítás fordítási minőségét. Számos, a kontextustudatos NMT-ről szóló már meglévő munka az új modellarchitektúrák fejlesztésére összpontosított további kontextusok beépítésére, és ígéretes eredményeket mutatott. A legtöbb meglévő munka azonban a kereszt-entrópia veszteségre támaszkodik, ami korlátozott környezeti információk használatát eredményezi. Ebben a tanulmányban javasoljuk a CorefCL-t, egy új adatbővítési és kontrasztív tanulási rendszert, amely a forrás és a kontextuális mondatok közötti korreferencián alapul. A kontextuális mondatban található automatikusan észlelt coreferencia-említések megrongálásával a CorefCL képes arra, hogy a modell érzékeny legyen a coreferencia-következetlenségre. Módszerünkkel közös kontextustudatos NMT modelleken és két dokumentumszintű fordítási feladaton kísérleteztünk. A kísérletek során módszerünk folyamatosan javította az angol-német és angol-koreai feladatokra vonatkozó összehasonlított modellek BLEU-ját. Azt is megmutatjuk, hogy módszerünk jelentősen javítja a coreferencia felbontást az angol-német kontrasztos tesztcsomagban.', 'it': "La traduzione automatica neurale contestuale (NMT) incorpora informazioni contestuali dei testi circostanti, che possono migliorare la qualità della traduzione automatica a livello di documento. Molti lavori esistenti su NMT context-aware si sono concentrati sullo sviluppo di nuove architetture modello per incorporare contesti aggiuntivi e hanno mostrato alcuni risultati promettenti. Tuttavia, la maggior parte delle opere esistenti si basa sulla perdita di entropia incrociata, con conseguente uso limitato di informazioni contestuali. In questo articolo, proponiamo CorefCL, un nuovo schema di aumento dei dati e apprendimento contrastante basato sulla coreferenza tra la fonte e le frasi contestuali. Corruendo le menzioni di coreferenza rilevate automaticamente nella frase contestuale, CorefCL può addestrare il modello ad essere sensibile all'incoerenza di coreferenza. Abbiamo sperimentato il nostro metodo su modelli NMT comuni e su due attività di traduzione a livello di documento. Negli esperimenti, il nostro metodo ha costantemente migliorato BLEU di modelli confrontati su compiti inglese-tedesco e inglese-coreano. Mostriamo anche che il nostro metodo migliora significativamente la risoluzione della coreferenza nella suite di test contrastanti inglese-tedesco.", 'kk': 'Контексті түсіндірілген невралдық компьютердің аудармасы Қосымша контексті таңдау үшін NMT бағдарламалардың көптеген жұмыстары жаңа үлгі архитектураларды құру үшін көптеген жұмыс істейді. Кейбір үлкен нәтижелер көрсеті Бірақ бар жұмыстардың көпшілігі бірнеше ентропиялық жоғалуына тәуелді, бұл көпшілік мәліметтерді шектеп қолдану үшін. Бұл қағазда CorefCL- тің жаңа деректерді көбейту және контрастық оқыту сұлбасына негізделген көзі мен контекстік сөйлемелердің арасындағы мәселелерді бағдарламасын ұсынамыз. Бұл мәтінде автоматты түрде таңдалған сәйкестіктерді бақылау үшін CorefCL үлгісін сәйкестіктерге сәйкестікті болу үшін оқытуға болады. Біз NMT үлгілерін және екі құжат деңгейіндегі аудару тапсырмаларының әдісімізмен тәжірибедік. Тәжірибелерде, біздің әдіміміз ағылшын-неміс және ағылшын-корея тапсырмаларында тәуелді BLEU үлгілерін салыстырды. Мұндай-ақ біз әдіміміздің ағылшын-неміс контрастық сынақтар сәйкестігінің көбірек айырмашылығын өзгертеді.', 'ka': 'კონტექსტის შესახებ ნეიროლური მანქანის გაგრძელება (NMT) შეიყვანეთ გარგებული ტექსტის კონტექსტური ინფორმაცია, რომელიც შეუძლია გაგრძელება დოკუმენ მრავალი კონტექსტურის შესახებ NMT-ზე ახალი მოდელური აქტიქტიქტურების განვითარებისთვის დამატებული კონტექსტურების შესახებ და გამოჩვენეთ რამდენიმე გასაკვებ მაგრამ ძალიან მსგავსი სამუშაო სამუშაო სამუშაო დაკავშირებაზე იქნება, რომელიც შეიძლება კონტექსტური ინფორმაციის გამოყენება და ამ დომენტში ჩვენ CorefCL-ს პროგრამებით, პრომენტიური მონაცემები და კონტრესტიური სწავლების სქემი, რომელიც გამოყენებულია წიგნის და კონტრესტიური სიტყვებ კონტექსტური სიტყვებში ავტომატურად განვიცნობით სწორედ სწორედ, CorefCL შეუძლია მოდელის გაგრძნოთ, რომ იყოს სწორედ სწორედ სწორედ სწორედ. ჩვენ განვიცემებით ჩვენი მეტისთვის საერთო კონტექსტური მოდელები და ორი დოკუმენტის გადაწყვეტილება. ექსპერიმენტებში ჩვენი მედიოდი ყველაფერად გაუკეთებულია BLEU-ს, რომელიც ინგლისური-გერმანური და ინგლისური-კორეული დავალების შემდგენებაში მოდე ჩვენ ასევე აჩვენებთ, რომ ჩვენი მეთოდი ძალიან უფრო მნიშვნელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელოვანელ', 'lt': 'Su kontekstu susipažinęs neurologinis vertimas (NMT) apima aplinkinių tekstų kontekstinę informaciją, kuri gali pagerinti dokumentų lygio vertimo mašina kokybę. Daugelis esamų su aplinkybėmis susijusių NMT susijusių darbų sutelkė dėmesį į naujų modelių architektūrų kūrimą siekiant įtraukti papildomas aplinkybes ir parodė kai kuriuos pažadėtinus rezultatus. Tačiau dauguma esamų darbų priklauso nuo tarpentropijos nuostolių, dėl kurių ribotai naudojama kontekstinė informacija. Šiame dokumente siūlome CorefCL, naują duomenų didinimo ir kontrastinio mokymosi sistemą, grindžiamą šaltinio ir kontekstinių sakinių atitiktimi. Korumpuodamas automatiškai aptiktas koreferencijos nuorodas kontekstiniame sakinyje, CorefCL gali mokyti model į būti jautrus koreferencijos neatitikimui. We experimented with our method on common context-aware NMT models and two document-level translation tasks.  Eksperimentuose mūsų metodas nuosekliai pagerino palyginamų anglų, vokiečių ir anglų Korėjos užduočių modelių BLEU. Taip pat rodome, kad mūsų metodas gerokai pagerina koreferencinę rezoliuciją anglų ir vokiečių kontrastiniame bandymų rinkinyje.', 'ms': 'Context-aware neural machine translation (NMT) incorporates contextual information of surrounding texts, that can improve the translation quality of document-level machine translation.  Many existing works on context-aware NMT have focused on developing new model architectures for incorporating additional contexts and have shown some promising results.  Namun, kebanyakan kerja yang ada bergantung pada kehilangan entropi salib, yang menyebabkan penggunaan terhad maklumat kontekstual. Dalam kertas ini, kami cadangkan CorefCL, skema pembesaran data baru dan pembelajaran bertentangan berdasarkan persamaan antara sumber dan kalimat kontekstual. Dengan merosakkan sebutan keterangan yang dikesan secara automatik dalam kalimat kontekstual, CorefCL boleh melatih model untuk sensitif kepada ketidakkonsistensi keterangan. Kami eksperimen dengan kaedah kami pada model NMT yang sedar-konteks umum dan dua tugas terjemahan-aras dokumen. Dalam eksperimen, kaedah kami secara konsisten meningkatkan BLEU model dibandingkan pada tugas Inggeris-Jerman dan Inggeris-Korea. Kami juga menunjukkan bahawa kaedah kami meningkatkan resolusi persamaan dalam suite ujian kontras Inggeris-Jerman.', 'ml': '@ info: status കൂടുതല്\u200d പദ്ധതികള്\u200d ചേര്\u200dക്കുന്നതിനായി പുതിയ മോഡല്\u200d ആര്\u200dക്ടിക്കറ്റുകള്\u200d ഉള്\u200dപ്പെടുത്തുന്നതിനായി നിലവിലുള്ള പല ജോലികളും പ്രത എന്നാലും നിലവിലുള്ള ഏറ്റവും പേരും ക്രിസ്റ്റോപ്പിയുടെ നഷ്ടത്തില്\u200d ആശ്രയിക്കുന്നു. അതിനാല്\u200d നിലവിലുള്ള വ ഈ പത്രത്തില്\u200d നമ്മള്\u200d കോര്\u200dഫിസിഎലിനെ പ്രൊദ്ദേശിക്കുന്നു, സ്രോതസ്സിന്റെയും വാക്കുകള്\u200dക്കുമിടയിലെ കോര്\u200dഫെന്\u200dസെന്\u200dസിന്\u200dറെയും  നിലവിലുള്ള വാക്കില്\u200d കോര്\u200dഫെന്\u200dസില്\u200d സ്വയം കോര്\u200dഫെന്\u200dസിന്\u200dറെ പേരുകള്\u200d കുഴപ്പമാക്കുന്നതിനാല്\u200d, കോര്\u200dഫെന്\u200dസില്\u200d അസാധ്യതയുള്ള മോഡല We experimented with our method on common context-aware NMT models and two document-level translation tasks.  പരീക്ഷണങ്ങളില്\u200d, നമ്മുടെ രീതിയില്\u200d ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d കൊറിയയിലെ പണികളില്\u200d താല്\u200dക്കാലികമായ മോഡലുകള്\u200d മുന്\u200dകൂട്ടി ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d പരീക്ഷണ സ്യൂട്ടില്\u200d നമ്മുടെ രീതിയില്\u200d കോര്\u200dഫെന്\u200dസിന്\u200dറെ രീതിയില്\u200d മെച്ചപ്പെടുത്ത', 'el': 'Η νευρολογική μηχανική μετάφραση με επίγνωση του περιβάλλοντος ενσωματώνει πληροφορίες περιβάλλοντος των κειμένων, οι οποίες μπορούν να βελτιώσουν την ποιότητα της μετάφρασης της μηχανικής μετάφρασης σε επίπεδο εγγράφων. Πολλά υπάρχοντα έργα σχετικά με τη γνώση του περιβάλλοντος έχουν επικεντρωθεί στην ανάπτυξη νέων αρχιτεκτονικών μοντέλων για την ενσωμάτωση πρόσθετων πλαισίων και έχουν δείξει πολλά υποσχόμενα αποτελέσματα. Ωστόσο, τα περισσότερα από τα υπάρχοντα έργα βασίζονται στην απώλεια διασταυρούμενης εντροπίας, με αποτέλεσμα την περιορισμένη χρήση πληροφοριών περιβάλλοντος. Σε αυτή την εργασία, προτείνουμε ένα νέο σχέδιο αύξησης δεδομένων και αντίθετης μάθησης βασισμένο στη συνάφεια μεταξύ της πηγής και των σχετικών προτάσεων. Με τη διαφθορά των αυτόματα ανιχνευμένων αναφορών συνάφειας στην πρόταση περιβάλλοντος, η συνάφεια μπορεί να εκπαιδεύσει το μοντέλο να είναι ευαίσθητο στην ασυνέπεια συνάφειας. Πειραματιστήκαμε με τη μέθοδο μας σε κοινά μοντέλα και δύο μεταφραστικές εργασίες σε επίπεδο εγγράφων. Στα πειράματα, η μέθοδος μας βελτίωσε σταθερά τα συγκριτικά μοντέλα σε αγγλογερμανικές και αγγλοκορεατικές εργασίες. Επίσης, καταδεικνύουμε ότι η μέθοδος μας βελτιώνει σημαντικά την ανάλυση της συνάφειας στην αγγλική-γερμανική σειρά δοκιμών αντίθεσης.', 'mn': 'Контекст ойлгомжтой мэдрэмжтэй мэдрэмжтэй мэдрэмжтэй мэдрэмжтэй байдаг. Энэ нь документийн түвшинд машины хөрөнгө оруулах чадварыг сайжруулж чадна. NMT-ийн орчин үеийн мэдлэгтэй олон ажиллууд нэмэлт нөхцөл байдлыг орлуулахын тулд шинэ загварын архитектуруудыг хөгжүүлж, зарим амлалтай үр дүнг харуулсан. Гэвч ихэнх оршин байгаа ажлын хувьд энтропийн алдагдалд байдаг. Энэ нь тохиромжтой мэдээллийн хэрэглээ хязгаарлагддаг. Энэ цаасан дээр бид CorefCL-г шинэ өгөгдлийн нэмэгдүүлэлт болон эсрэг суралцах схемээр санал болгож байна. Автоматтын сүүлийн үеэр CorefCL загварыг зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвшөөрөх боломжтой болно. Бид NMT загвар болон баримтын түвшинд орчуулах даалгаварыг судалсан. Эдгээр туршилтуудад бидний арга нь Англи-Герман, Англи-Солонгос даалгаварын харьцуулахын тулд BLEU-г сайжруулсан. Бид мөн бидний арга нь Англи-Германы эсрэг шалгалтын шалгалтын шийдвэрлэлийг үнэхээр сайжруулдаг гэдгийг харуулж байна.', 'no': 'Omsetjing av kontekstmaskin (NMT) inneheld kontekst- informasjon om omsetjande tekstar, som kan forbetra omsetjingskvaliteten av dokumentnivåmaskineomsetjinga. Mange eksisterande arbeidar på kontekstsverkt NMT har fokusert på å utvikla nye modellerarkitektur for å inkludere ekstra kontekstar og har vist nokre promessande resultat. Dei fleste eksisterande arbeida er imidlertid avhengig av tap på kryss- entropi, som fører til begrenset bruk av kontekstinformasjon. I denne papiret foreslår vi CorefCL, eit nytt data-augmentasjon og kontrastivt læringsskjema basert på koreferanse mellom kjelden og kontekstuttalene. Ved korruppa automatisk oppdaga hjelpefølgje som gjev i kontekstsetninga, kan CorefCL trenge modellen til å vera sensitiv til hjelpefølgje. Vi eksperimenterte med metoden vårt om vanlege kontekst- oppgåver for NMT- modeller og to dokumentnivåomsetjingar. I eksperimentene er metoden vårt konsekvent forbetra BLEU med sammenligning av modeller på engelsk-tysk og engelsk-koreansk oppgåver. Vi viser også at metoden vårt betydelig forbedrar oppløysinga for koreferanse i det engelsk-tysk kontrastiske testsuiten.', 'pl': 'Kontekstowe neuronowe tłumaczenie maszynowe (NMT) zawiera informacje kontekstowe otaczających tekstów, co może poprawić jakość tłumaczenia maszynowego na poziomie dokumentów. Wiele istniejących prac nad kontekstowym NMT koncentrowało się na opracowaniu nowych architektur modelowych umożliwiających włączenie dodatkowych kontekstów i wykazało kilka obiecujących rezultatów. Jednak większość istniejących prac opiera się na utracie entropii krzyżowej, co skutkuje ograniczonym wykorzystaniem informacji kontekstowych. W niniejszym artykule proponujemy CorefCL, nowy schemat powiększania danych i kontrastywnego uczenia się oparty na współzależności między zdaniem źródłowym i kontekstowym. Poprzez uszkodzenie automatycznie wykrytych wspomnień o koreferencji w zdaniu kontekstowym, CorefCL może trenować model wrażliwy na niespójność koreferencji. Eksperymentowaliśmy z naszą metodą na wspólnych kontekstowych modelach NMT i dwóch zadaniach tłumaczeniowych na poziomie dokumentów. W eksperymentach nasza metoda konsekwentnie ulepszała BLEU porównywanych modeli na zadania angielsko-niemieckie i angielsko-koreańskie. Pokazujemy również, że nasza metoda znacznie poprawia rozdzielczość koreferencji w angielsko-niemieckim zestawie testów kontrastywnych.', 'ro': 'Traducerea automată neurală conștientă de context (NMT) încorporează informații contextuale ale textelor din jur, care pot îmbunătăți calitatea traducerii automate la nivel de document. Multe lucrări existente privind NMT conștient de context s-au concentrat pe dezvoltarea de noi arhitecturi modele pentru încorporarea contextelor suplimentare și au arătat unele rezultate promițătoare. Cu toate acestea, majoritatea lucrărilor existente se bazează pe pierderea intropiei încrucișate, rezultând în utilizarea limitată a informațiilor contextuale. În această lucrare, propunem CorefCL, o nouă schemă de augmentare a datelor și de învățare contrastantă bazată pe corefența dintre frazele sursă și contextuale. Corupând mențiunile de corefență detectate automat în propoziția contextuală, CorefCL poate instrui modelul să fie sensibil la inconsecvența corefenței. Am experimentat metoda noastră pe modele NMT comune conștiente de context și două sarcini de traducere la nivel de document. În cadrul experimentelor, metoda noastră a îmbunătățit constant BLEU de modele comparate pe sarcini engleză-germană și engleză-coreeană. De asemenea, demonstrăm că metoda noastră îmbunătățește semnificativ rezoluția corefenței în suita de test contrastant engleză-germană.', 'si': 'සම්බන්ධ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණය (NMT) සම්බන්ධ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණය සඳහා පරී සම්බන්ධ විදියට තියෙන්න තියෙන හැම වැඩක්ම NMT විදියට අළුත් මොඩල් ස්ථාපනය විස්තර කරලා තියෙන්නේ අවශ්\u200dය ස නමුත්, විශ්වාසිත වැඩේ ගොඩක් වැඩේ විශ්වාස කරන්නේ ක්\u200dරිස්ටෙන්ට්\u200dරෝපිය නැතිවෙලා තියෙන්නේ, ඒ ව මේ පත්තරේ අපි CoreCL ප්\u200dරතිචාර කරනවා, නවාත්මක දත්ත විශාලනය සහ ප්\u200dරතිචාරණ සිද්ධාවක් ප්\u200dරතිචාරණය සහ ප්\u200dරතිචාරි ස්වයංක්\u200dරමයෙන් ස්වයංක්\u200dරමයෙන් හොයාගන්න පුළුවන් සම්බන්ධ වාක්ෂාවයෙන් කියලා, CoreCL පුළුවන් මොඩේල් එක සංව අපි අපේ පරීක්ෂණය සමග සාමාන්\u200dය සංවේදනය සහ NMT මොඩේල් සහ ලේඛන පරිවර්තන කාර්ය දෙකක් පරීක්ෂණය කළා. පරීක්ෂණයේ අපේ පරීක්ෂණය සාමාන්\u200dයයෙන් ඉංග්\u200dරීස්-ජර්මන් සහ ඉංග්\u200dරීසි-කෝරියාන් වැඩේ ඉන්ග්\u200dරීස්  අපි පෙන්වන්නේ අපේ විධානය ගොඩක් විශේෂයෙන් ඉංග්\u200dරීසිය-ජර්මන් ප්\u200dරතික්\u200dරමණ පරීක්ෂණ සූට් වල', 'sr': 'Kontekstski svestan neuronski prevod mašine (NMT) uključuje kontekstualne informacije o okruženim tekstima, koje mogu poboljšati kvalitet prevoda mašine na nivou dokumenta. Mnogi postojeći radovi na kontekstu svjesni NMT fokusirali su se na razvoj novih modelnih arhitektura za uključenje dodatnih konteksta i pokazali su neke obećavajuće rezultate. Međutim, većina postojećih radova se oslanja na gubitak kroz entropiju, što je dovelo do ograničenog upotrebe kontekstnih informacija. U ovom papiru predlažemo CorefCL, novu povećanju podataka i kontrastivnu shēmu učenja baziranu na pristojnosti između izvora i kontekstualnih rečenica. Korupcijom automatski otkrivenog pristojnosti spominjanja u kontekstualnoj rečenici, CorefCL može trenirati model da bude osjetljiv na neskladnost pristojnosti. Eksperimentirali smo svoju metodu o zajedničkim modelima NMT-a koji su svesni konteksta i dva zadataka za prevod na nivou dokumenta. U eksperimentima, naša metoda je stalno poboljšala BLEU usporedbenih modela na engleskom-njemačkom i engleskom-korejskom zadatku. Takođe pokazujemo da naša metoda značajno poboljšava rezoluciju dobrote u apartmanu za kontrastivne testove engleskog i njemačkog.', 'sv': 'Kontextmedveten neural maskinöversättning (NMT) innehåller kontextuell information om omgivande texter, vilket kan förbättra översättningskvaliteten för maskinöversättning på dokumentnivå. Många befintliga arbeten med kontextmedveten NMT har fokuserat på att utveckla nya modellarkitekturer för att integrera ytterligare kontexter och har visat några lovande resultat. De flesta befintliga verk förlitar sig dock på korsentropiförlust, vilket resulterar i begränsad användning av kontextuell information. I denna uppsats föreslår vi CorefCL, ett nytt dataförstorings- och kontrastlärningsschema baserat på korreferens mellan källmeningar och kontextuella meningar. Genom att korrumpera automatiskt identifierade coreferenzomnämnanden i den kontextuella meningen kan CorefCL träna modellen att vara känslig för coreferenzinkonsekvens. Vi experimenterade med vår metod på gemensamma kontextmedvetna NMT-modeller och två översättningsuppgifter på dokumentnivå. I experimenten förbättrade vår metod konsekvent BLEU av jämförda modeller på engelsk-tyska och engelsk-koreanska uppgifter. Vi visar också att vår metod avsevärt förbättrar coreferensupplösningen i den engelsk-tyska kontrasttestsviten.', 'mk': 'Свесен за контекст нервен машински превод (НМТ) вклучува контекстни информации за околните тексти, кои можат да го подобрат квалитетот на преводот на машински превод на ниво на документ. Многу постоечки дела на НМТ свесни за контекст се фокусираа на развојот на нови моделни архитектури за вклучување на дополнителни контексти и покажаа некои ветувачки резултати. However, most of existing works rely on cross-entropy loss, resulting in limited use of contextual information.  In this paper, we propose CorefCL, a novel data augmentation and contrastive learning scheme based on coreference between the source and contextual sentences.  Со корумпирање на автоматски детектираните спомени на соодветност во контекстната реченица, CorefCL може да го обучува моделот да биде чувствителен на соодветна несогласност. Експериментиравме со нашиот метод на заеднички контекстни НМТ модели и две преводни задачи на ниво на документи. In the experiments, our method consistently improved BLEU of compared models on English-German and English-Korean tasks.  We also show that our method significantly improves coreference resolution in the English-German contrastive test suite.', 'ta': '@ info NMT புதிய மாதிரி அட்டவணைகளை உருவாக்குவதற்கு மேலும் சேர்த்து சில வாக்கியங்களை காட்டுகிறது. ஆனால் இருக்கும் பெரும்பாலான வேலைகள் குறிக்கும் நுழைவுக்கு இழப்பை நம்புகின்றன, அதனால் தற்காலிக தகவல் பயன்பட இந்த காகிதத்தில், நாம் CorefCL, ஒரு புதிய தகவல் மேம்படுத்தல் மற்றும் மூலம் மற்றும் தற்காலிக வாக்கியங்களுக்கிடையில் முறைமையான முற தற்போதைய வாக்கியத்தில் தானாகவே குறிப்பிட்ட குறிப்பிட்ட குறிப்பிட்ட குறிப்புகளை அழித்து கொண்டு, கோரிப்சிஎல் மாதிரியை கு பொதுவான NMT மாதிரிகள் மற்றும் இரண்டு ஆவண- நிலை மொழிபெயர்ப்பு பணிகளில் எங்கள் முறையைக் கொண்டு சோதனைப்படுத பரிசோதனைகளில், எங்கள் முறைமையில் பிலியு ஒப்பிட்ட மாதிரிகளை முன்னேற்றி ஆங்கிலத்தில் ஜெர்மன் மற்றும் ஆங்கிலத்தி We also show that our method significantly improves coreference resolution in the English-German contrastive test suite.', 'mt': 'It-traduzzjoni tal-magni newrali (NMT) li tkun konxja mill-kuntest tinkorpora informazzjoni kuntestwali tat-testi tal-madwar, li tista’ ttejjeb il-kwalità tat-traduzzjoni tat-traduzzjoni tal-magni fil-livell tad-dokument. Many existing works on context-aware NMT have focused on developing new model architectures for incorporating additional contexts and have shown some promising results.  Madankollu, il-biċċa l-kbira tax-xogħlijiet eżistenti jiddependu fuq telf transentropiku, li jirriżulta f’użu limitat ta’ informazzjoni kuntestwali. F’dan id-dokument, qed nipproponu CorefCL, skema ġdida ta’ żieda fid-dejta u tagħlim kuntrastiv ibbażata fuq il-koerenza bejn is-sors u s-sentenzi kuntestwali. By corrupting automatically detected coreference mentions in the contextual sentence, CorefCL can train the model to be sensitive to coreference inconsistency.  Esperimentajna bil-metodu tagħna fuq mudelli NMT komuni u konxji mill-kuntest u żewġ kompiti ta’ traduzzjoni fil-livell tad-dokumenti. Fl-esperimenti, il-metodu tagħna tejjeb b’mod konsistenti l-BLEU ta’ mudelli mqabbla dwar kompiti Ingliż-Ġermaniż u Ingliż-Koreani. We also show that our method significantly improves coreference resolution in the English-German contrastive test suite.', 'so': "Turjumista qoraalka ku wareegsan (NMT) waxaa ku qoran taariikhda qoraalka ku wareegsan, kaas oo kordhin kara turjumista sifiimka qoraalka-level machine translation. Shaqooyin badan oo ku jira oo ku saabsan qoraal-aqoon NMT waxay focus on horumarinta dhismaha cusub ee model, si ay u soo geliyaan qoraal dheeraad ah, waxayna tuseen resulto ballan ah. Si kastaba ha ahaatee shaqaalaha badan ee la joogo waxay ku xiran yihiin khasaarada koronta, taasoo sababtoo ah isticmaalka macluumaadka joogtada ah ee xadidan. Qoraalkan waxaan ka soo jeedaynaa korefCL, korefCL oo ah qorshaha kordhiska macluumaadka saxda ah iyo qorshaha waxbarashada ka duwan oo ku saleysan xiriirka dhexe dhexe iyo erayada soo socda. Xarrigelinta xuquuqda ku qoran xarafka hore ee korefCL wuxuu sameyn karaa modelka si ay u jilicsan karto qiimeyn la'aanta. Waxaannu ku tijaabiynay qaabkeeneena oo ku saabsan qaababka ku saabsan noocyada NMT ee caadiga ah iyo labada shaqooyinka turjumaadda ee warqada ah. Imtixaanka, qaabkeenkeennu waxay si joogto ah u bedeshay BLEU tusaalooyin isbarbardhig oo ku saabsan hawlaha Ingiriis-Jarmal iyo Ingiriis-Korean. We also show that our method significantly improves coreference resolution in the English-German contrastive test suite.", 'ur': 'Context-aware neural machine translation (NMT) surrounding texts of contextual information incorporates, which can improve the translation quality of document-level machine translation. بہت سی موجود کام NMT کے متوجہ ہونے کے لئے نو موڈل معماروں کی تخلیق پر تمرکز کیا گیا ہے اور اضافہ متوجہ ہونے کے لئے اور بہت سے وعدہ دینے والے نتیجے دکھائے گئے ہیں. لیکن اکثر موجود کام کریس انتروپی کے خسارہ پر اعتماد رکھتے ہیں اور اس کے نتیجہ میں محدود معلومات کا استعمال ہوتا ہے. اس کاغذ میں ہم CorefCL کی پیشنهاد کریں گے، ایک نئی ڈیٹا افزایش اور مخالف تعلیم سیکھ، سورج اور متوسط جماعت کے درمیان مہربانی پر بنیاد ہے. فساد کے ذریعہ سے متوجہ شدہ فیصلہ میں مہربانی کا ذکر کرتا ہے، CorefCL موڈل کو مہربانی غیر قابل تعلیم دیتا ہے۔ ہم نے اپنے طریقے سے آزمائش کی ہے NMT موڈلوں اور دو دفتر سطح ترجمہ کے کاموں پر۔ آزمائش میں، ہمارا طریقہ انگلیسی-جرمن اور انگلیسی-کوریا کے کاموں کے مقایسہ نمونوں کے بل یورپ کو ثابت قدم کر دیا گیا ہے. ہم بھی دکھاتے ہیں کہ ہمارا طریقہ انگلیسی-جرمن کے کنٹرسیٹ تست سوئٹ میں مہربانی کی رضامندی کے ساتھ بہتر ہوتا ہے.', 'uz': "@ info: whatsthis Name Lekin, ko'pchilik mavjud vazifalar cross-entropy yoʻqolishiga ishonadi. Bu sababda davomida maʼlumotni cheksiz foydalanadi. Bu qogʻozda, biz CorefCL, novel maʼlumot yordamida o'rganish va tartibu o'rganish qolipini tasavvur qilamiz, manba va doim soʻzlar orasidagi bir xil soʻzlar asosida yaratilgan. Name Biz umumiy taʼminlovchi NMT modellari va ikkita hujjatning darajasi tarjima vazifalari bilan biror qilib ko'rdik. Tajribalar davomida bizning usuli ingliz- Olmon va Ingliz-Koriya vazifalari bilan o'xshash modellarning BLEU'ni davomida o'zgartirdi. Biz esa bizning usuli ingliz-Olmonchadan bir xil sinov tizimi boshqaruvchisining murojaatiyasini juda muhimiy yaxshi ko'ramiz.", 'vi': 'Liên kết thông tin ngữ cảnh về dịch thuật cỗ máy thần kinh (NMB) chứa đựng các thông tin ngữ chung của các văn bản xung quanh, có thể cải thiện chất dịch của bộ máy. Rất nhiều tác phẩm về công nghệ nhận diện ngữ cảnh NMB đã tập trung vào việc phát triển các kiến trúc mô hình mới để hợp thêm các nền cộng tác và đã cho thấy một số kết quả hứa hẹn. Tuy nhiên, hầu hết các công trình tồn tại dựa trên sự mất kết cấu chéo, dẫn đến việc sử dụng ít thông tin ngữ cảnh. Trong tờ giấy này, chúng tôi đề nghị CorefCL, một dự án gia tăng dữ liệu mới và một kế hoạch học tương phản dựa trên khả năng hạn hẹp giữa nguồn và các câu ngữ. Với việc phá hoại khả năng hạn chế bị phát hiện tự động đề cập trong câu ngữ cảnh, CorefCL có thể huấn luyện mô hình để tránh khỏi mâu thuẫn hạn hẹp. Chúng tôi thí nghiệm với phương pháp của mình về những mô hình NMT phổ biến chung và hai dịch vụ cấp tài liệu. Trong các thí nghiệm, phương pháp của chúng tôi hoàn toàn cải tiến hệ thống mô hình so sánh về công việc Anh-Đức và Anh-Hàn. Chúng tôi cũng cho thấy phương pháp của chúng tôi cải thiện cam kết đáng kể trong phòng thí nghiệm tương phản Anh-Đức.', 'bg': 'Неврологичният машинен превод (НМТ) включва контекстната информация на околните текстове, която може да подобри качеството на превода на машинния превод на ниво документ. Много от съществуващите работи по НМТ са фокусирани върху разработването на нови модели архитектури за включване на допълнителни контексти и показват някои обещаващи резултати. Въпреки това, повечето от съществуващите произведения разчитат на загуба на кръстосана ентропия, което води до ограничено използване на контекстуална информация. В настоящата статия ние предлагаме нова схема за увеличаване на данните и контрастивно обучение, базирана на кореференция между източника и контекстуалните изречения. Чрез повреждане на автоматично откритите споменавания за кореференция в контекстното изречение може да обучи модела да бъде чувствителен към несъответствие на кореференция. Експериментирахме метода си върху общи модели на НМТ и две задачи за превод на ниво документи. В експериментите методът ни последователно подобрява сравнимите модели на англо-немски и англо-корейски задачи. Показваме също, че методът ни значително подобрява резолюцията на кореференцията в англо-германския контрастивен тест комплект.', 'da': 'Kontekstbevidst neural maskinoversættelse (NMT) indeholder kontekstuel information om omgivende tekster, der kan forbedre oversættelseskvaliteten af maskinoversættelse på dokumentniveau. Mange eksisterende værker om kontekstbevidste NMT har fokuseret på at udvikle nye modelarkitekturer til at indarbejde yderligere kontekster og har vist nogle lovende resultater. De fleste af de eksisterende værker er dog afhængige af tab af cross-entropi, hvilket resulterer i begrænset brug af kontekstuel information. I denne artikel foreslår vi CorefCL, en ny dataforøgelse og kontrastiv læringsordning baseret på coreference mellem kilde og kontekstuelle sætninger. Ved at ødelægge automatisk registrerede coreferenceanmeldelser i den kontekstuelle sætning, kan CorefCL træne modellen til at være følsom over for coreferenceanmeldelser. Vi eksperimenterede med vores metode på fælles kontekstbevidste NMT modeller og to dokumentoversættelsesopgaver. I eksperimenterne forbedrede vores metode konsekvent BLEU af sammenlignede modeller på engelsk-tysk og engelsk-koreansk opgaver. Vi viser også, at vores metode forbedrer coreferenceopløsningen betydeligt i den engelsk-tyske kontrasttestpakke.', 'hr': 'U kontekstu se uključuje kontekstualne informacije o okruženim tekstima koje mogu poboljšati kvalitet prevoda strojeva na nivou dokumenta. Mnogi postojeći radovi na kontekstu svjesni NMT usredotočili su se na razvoj novih modelnih arhitektura za uključenje dodatnih konteksta i pokazali su neke obećavajuće rezultate. Međutim, većina postojećih radova oslanja se na gubitak preko entropije, što je rezultiralo ograničenom korištenju kontekstnih informacija. U ovom papiru predlažemo CorefCL, novu povećanju podataka i kontrastivnu shēmu učenja na temelju pristojnosti između izvora i contextualnih rečenica. Korupcijom automatski otkrivenog pristojnosti spominjanja u kontekstualnoj rečenici CorefCL može trenirati model da bude osjetljiv na neskladnost pristojnosti. Eksperimentirali smo sa svojim metodom o zajedničkim modelima NMT-a koji su svjesni konteksta i dva zadatka za prevod na razini dokumenta. U eksperimentima, naša metoda je stalno poboljšala BLEU usporedbenih modela na engleskom-njemačkom i engleskom-korejskom zadatku. Također pokazujemo da naš metod značajno poboljšava rješenje pristojnosti u apartmanu za kontrastne testove engleskog-njemačkog.', 'nl': 'Contextbewuste neurale machinevertaling (NMT) bevat contextuele informatie van omringende teksten, die de vertaalkwaliteit van machinevertaling op documentniveau kan verbeteren. Veel bestaande werken over contextbewuste NMT hebben zich gericht op het ontwikkelen van nieuwe modelarchitecturen voor het integreren van aanvullende contexten en hebben enkele veelbelovende resultaten laten zien. De meeste bestaande werken vertrouwen echter op cross-entropieverlies, wat resulteert in een beperkt gebruik van contextuele informatie. In dit artikel stellen we CorefCL voor, een nieuw data augmentatie en contrastief leerschema gebaseerd op corefeferentie tussen de bron en contextuele zinnen. Door automatisch gedetecteerde coreference vermeldingen in de contextuele zin te beschadigen, kan CorefCL het model trainen om gevoelig te zijn voor coreference inconsistentie. We experimenteerden met onze methode op gemeenschappelijke contextbewuste NMT-modellen en twee vertaaltaken op documentniveau. In de experimenten verbeterde onze methode consistent BLEU van vergeleken modellen op Engels-Duitse en Engels-Koreaanse taken. We laten ook zien dat onze methode de coreferentie resolutie aanzienlijk verbetert in de Engels-Duitse contrastieve testsuite.', 'id': 'Terjemahan mesin saraf yang menyadari konteks (NMT) mengandung informasi kontekstual teks sekitar, yang dapat meningkatkan kualitas terjemahan dari terjemahan mesin tingkat dokumen. Banyak pekerjaan yang ada pada NMT yang menyadari konteks telah fokus pada mengembangkan arsitektur model baru untuk mengikorporasi konteks tambahan dan telah menunjukkan beberapa hasil yang berjanji. Namun, kebanyakan pekerjaan yang ada bergantung pada kehilangan interentropi, yang menyebabkan penggunaan terbatas informasi kontekstual. Dalam kertas ini, kami mengusulkan CorefCL, peningkatan data baru dan skema belajar kontras berdasarkan koreferensi antara sumber dan kalimat kontekstual. Dengan merusak secara otomatis terdeteksi cerita koreferensi dalam kalimat kontekstual, CorefCL dapat melatih model untuk sensitif kepada ketidakkonsistensi koreferensi. Kami eksperimen dengan metode kami pada model NMT yang menyadari konteks umum dan dua tugas terjemahan tingkat dokumen. Dalam eksperimen, metode kami secara konsisten meningkatkan BLEU dari model dibandingkan pada tugas Inggris-Jerman dan Inggris-Korea. Kami juga menunjukkan bahwa metode kami meningkatkan secara signifikan resolusi koreferensi dalam suite ujian kontras Inggris-Jerman.', 'de': 'Die kontextbewusste neuronale maschinelle Übersetzung (NMT) integriert kontextbezogene Informationen von umgebenden Texten, die die Übersetzungsqualität maschineller Übersetzung auf Dokumentenebene verbessern können. Viele bestehende Arbeiten zum kontextbewussten NMT haben sich auf die Entwicklung neuer Modellarchitekturen zur Einbindung zusätzlicher Kontexte konzentriert und einige vielversprechende Ergebnisse gezeigt. Die meisten existierenden Arbeiten beruhen jedoch auf Cross-Entropieverlusten, was zu einer begrenzten Nutzung von Kontextinformationen führt. In diesem Beitrag schlagen wir CorefCL vor, ein neuartiges Data Augmentation und kontrastives Lernschema basierend auf der Koreferenz zwischen Quell- und Kontextsätzen. Durch Korruption automatisch erkannter Coreferenzerwähnungen im Kontextsatz kann CorefCL das Modell trainieren, empfindlich auf Coreferenzinkonsistenz zu reagieren. Wir experimentierten mit unserer Methode an gängigen kontextbewussten NMT-Modellen und zwei Übersetzungsaufgaben auf Dokumentenebene. In den Experimenten verbesserte unsere Methode die BLEU von Vergleichsmodellen auf englisch-deutsche und englisch-koreanische Aufgaben konsequent. Wir zeigen auch, dass unsere Methode die Coreferenzauflösung in der deutsch-englisch kontrastiven Testsuite signifikant verbessert.', 'ko': '컨텍스트 인식 신경기계번역(NMT)은 주변 텍스트의 컨텍스트 정보를 융합해 문서급 기계번역의 번역 질을 높일 수 있다.컨텍스트 인식 NMT에 대한 많은 기존 작업은 다른 컨텍스트를 결합하고 희망적인 결과를 보여주기 위해 새로운 모델 아키텍처를 개발하는 데 집중되어 있습니다.그러나 기존의 대다수 업무는 교차 엔트로피 손실에 의존하여 상하문 정보에 대한 사용에 한계가 있다.본고에서 우리는CorefCL을 제기했는데 이것은 새로운 원시어구와 상하문어구 간의 상호 참조를 바탕으로 하는 데이터 강화와 대비 학습 방안이다.컨텍스트 문장에서 자동으로 감지된 공지 언급을 파괴함으로써 CorefCL은 모델이 공지의 불일치성에 민감하도록 훈련할 수 있다.우리는 흔히 볼 수 있는 상하문 감지 NMT 모델과 두 개의 문서급 번역 임무에서 우리의 방법을 실험했다.실험에서 우리의 방법은 비교 모델이 영독과 영한 임무에 있어서의 BLEU를 지속적으로 개선했다.우리는 또 우리의 방법이 영덕 비교 테스트 세트의 공지 해소를 현저하게 향상시켰다는 것을 발견했다.', 'tr': "Kontekst bilen tanyş neural maşynyň terjimesini NMT kontekst bilen bilýän köp eserler täze modeller arhitekturlygyny bejermek üçin guruldy we köp wajyp beren netijeleri görkezildi. Ýöne bolan işleriň köp bölegi cross-entropiýa ýitişine ynanýar, bu sebäpli daşaryk maglumaty ýitirdi. Bu kagyzda CorefCL'i, çeşme we görnöşikli sözler arasynda täsirleşme şeklinde täze bir maglumaty ekleýän we nusgalan öwrenme taslaýyny teklip edýäris. KorefCL senediň içinde özünden özünden tanyş çeken çekişigi aňsatlyk bilen, nusgyny näsazlyk bilen hasaplap bolmagy üçin öwrenip biler. NMT nusgalary we 2 sened derejesi terjime etmek üçin biziň täzimimiz bilen synanyşdyrdyk. Deneylerde biziň metodamyz, Iňlisçe-nemes we iňlisçe-Koreýa işlerinde örän nusgalary diňe gowuraşdyrdy. Biz hem öz ýüregimiziň iňlisçe-nemesçe kontrast çözümlerde nähili ýüze çözümleşmegimizi gowuraýandygyny görkeýäris.", 'fa': 'ترجمه ماشین عصبی (NMT) با اطلاعات محیط اطلاعات محیط اطلاعات را شامل می\u200cکند که می\u200cتواند کیفیت ترجمه ماشین سطح سند را بهتر کند. بسیاری از کارهای موجود روی NMT آگاهی کنترل موجود روی توسعه معماری های مدل جدید برای شامل شرایط اضافی تمرکز کردند و بعضی نتیجه\u200cهای وعده\u200cدهنده را نشان دادند. ولی بیشتر کارهای موجود بر خسارت زیادی از انتروپی بستگی دارند، و به نتیجه از استفاده از اطلاعات محدود است. در این کاغذ، ما CorefCL را پیشنهاد می\u200cدهیم، یک برنامه\u200cی یادگیری تازه و برنامه\u200cی یادگیری متفاوتی بر اساس رضایت بین منبع و جمله\u200cهای متوسط. با تباه کردن به طور خودکار آگاهی\u200cهای رضایت را در مجازات متوسط، CorefCL می\u200cتواند مدل را آموزش دهد تا حساس باشد به ناراحتی رضایت. ما با روش خودمون در مورد مدل\u200cهای NMT با اطلاعات معمولی آزمایش کرده\u200cایم و دو کار\u200cهای ترجمه\u200cی سطح سند. در این آزمایشات، روش ما به طور کامل BLEU از مدل\u200cهای مقایسه کردن در کار انگلیسی-آلمان و انگلیسی-کره بهتر شد. ما همچنین نشان می دهیم که روش ما در سایت تست های مخالف انگلیسی و آلمانی به شدت بهتر است.', 'sw': 'Tafsiri ya mashine yenye ufahamu wa kikatili (NMT) inajumuisha taarifa za kisasa za maandishi yanayozunguka, ambazo zinaweza kuongeza kiwango cha tafsiri cha utafsiri wa mashine-level. Wengi wa kazi zilizopo kwenye mazingira yanayofahamika na NMT wamejikita katika kutengeneza majengo mpya ya mifano kwa ajili ya kuunganisha mikutano ya ziada na wameonyesha baadhi ya matokeo yanayoahidi. Hata hivyo, kazi nyingi zinazopo zinategemea hasara ya watu waliopitia kuingia, na kusababisha matumizi ya taarifa mpya. Katika karatasi hii, tunapendekeza CorefCL, kiwango cha taarifa za riwaya kuongeza na mpango wa kujifunza kinachotokana na uhakika kati ya chanzo na hukumu za kitabu. Kwa kuharibu utambulisho wa utambulisho wa kimataifa katika hukumu hiyo ya sasa, CorefCL anaweza kufundisha muundo wa kuwa na uelewa wa kutokuwepo kwa usawa. Tulijaribu kwa njia yetu katika mifano inayofahamika na mazingira ya NMT na kazi mbili za tafsiri za kiwango cha nyaraka. Katika majaribio hayo, mbinu yetu iliendelea kuboresha BLEU kwa mifano inayolinganisha katika kazi za Kiingereza na Kiingereza na Kiingereza. Tunaonyesha pia kuwa mbinu yetu inaboresha suluhisho la mafanikio kwa kiasi kikubwa katika kituo cha upinzani cha Kiingereza na Kijerumani.', 'af': "Konteks bewys neurale masjien vertaling (NMT) inkluit kontekslike inligting van omgekom teks wat die vertaling kwaliteit van dokumentvlak masjien vertaling kan verbeter. Baie bestaande werke op konteksbewyse NMT het gefokus op die ontwikkeling van nuwe model arkitektuur vir die inkorporering van addisionele konteks en het sommige beloftende resultate vertoon. Maar die meeste van bestaande werke vertrou op kruisentropie verlies, wat resultaat in beperkte gebruik van contextual informasie. In hierdie papier voorstel ons CorefCL, 'n nuwe data augmentasie en kontrastiewe leerskema gebaseer op koreferensie tussen die bron en contextual setings. Deur korrupsie automaties gevind korrupsief van korrupsief aansoek in die kontekslike seting, CorefCL kan die model trein om sensitief te wees na koreferensie inkonsistensie. Ons het met ons metode eksperimenteer op gemeenskaplike konteks-bewys NMT-modele en twee dokumentvlak-vertaling-taak. In die eksperimente het ons metode konsistentlik BLEU verbeter van vergelyking modele op Engels-Duits en Engels-Koreaanse opdragte. Ons wys ook dat ons metode betekenlik koreferensie-oplossing in die Engels-Duitse kontrastiese toetssuite verbeter.", 'hy': 'Կոնտեքստի գիտակցած նյարդային մեքենայի թարգմանությունը (NMT) ներառում է շրջապատող տեքստերի կոնտեքստային տեղեկատվությունը, որը կարող է բարելավել փաստաթղթի մակարդակի մեքենայի թարգմանման որակը: Շատ գոյություն ունեցող աշխատանքներ համատեքստով գիտակցած ՆՄԹ-ի վրա կենտրոնացել են նոր մոդելների ճարտարապետական կառուցվածքների զարգացման վրա, որպեսզի ներառեն ավելացյալ կոնտեքստ Այնուամենայնիվ, գոյություն ունեցող աշխատանքների մեծ մասը կախված է խաչը էնտրոպիայի կորստից, ինչը հանգեցնում է կոնտեքստալ տեղեկատվության սահմանափակ օգտագործման: Այս թղթի մեջ մենք առաջարկում ենք ԿորեֆԿԼ-ին, նոր տվյալների աճի և հակադրական ուսումնասիրության ծրագիր, որը հիմնված է աղբյուրի և կոնտեքստային նախադասությունների միջև համախմբման վրա: Կոռուպցիայի միջոցով ավտոմատ հայտնաբերված կոնտեքստային նախադասության մեջբերումները, ԿորեֆԿԼ-ը կարող է վարժեցնել մոդելը, որպեսզի զգալի լինի կոնտեքստային անհամապատասխանություններին: Մենք փորձարկում էինք մեր մեթոդի միջոցով ընդհանուր համատեքստով գիտակցած NMT մոդելների և երկու փաստաթղթի մակարդակի թարգմանման խնդիրների վրա: Փորձերի ընթացքում մեր մեթոդը մշտապես բարելավել է անգլերեն-գերմաներեն և անգլերեն-կորեացի խնդիրների համեմատական մոդելները: Մենք նաև ցույց ենք տալիս, որ մեր մեթոդը նշանակալիորեն բարելավում է անգլերեն-գերմանացի հակադրական փորձարկումների համակարգում կորֆերենսի լուծումը:', 'am': 'የሆኗል-የታወቀ የደዌብ መሣሪያን ትርጉም (NMT) የተጠቃሚ የጽሑፎችን ማህበረሰብ ይጠቅማል፤ ይችላል ትርጓሜውን የdocument-level machine translation. የNMT አዲስ የሞዴል አካውንት መሠረት ማድረግ ላይ ብዙ የሚኖሩት ሥራ በመጠቀም እና የተስፋ ፍሬዎችን ማሳየት ነው፡፡ ምንም እንኳን፣ አብዛኛዎቹ የሚኖሩት ሥራ በክፍል ተሳካቾች ላይ ይታመናሉ፤ የግንኙነቱ መረጃ ጥቅሟል ነው፡፡ በዚህ ፕሮግራም፣ በመsource እና በተቃውሞ ፍርድ ላይ የተመሳሳይ የዳታ አካባቢ እና የተቃውሞ ትምህርት ፕሮግራም የቆርፍ CL እና የአሁኑን ደንዳቤዎች መጨመር እና ትምህርት ማድረግ እና መግለጫ እናደርጋለን፡፡ በአሁኑ ግንኙነት ክፍል ውስጥ የኮርፌንሽን ግንኙነት በማጥፋት፣ ኮርፍCL ሞዴላውን ለማስተማርና ማሳየት ይችላል፡፡ የNMT ዓይነቶች እና ሁለት የሰነድ ደረጃ ትርጉም ስራዎችን በመጠቀም ሥርዓታችንን ፈተናን፡፡ በተፈተና ውስጥ፣ መንገዳችን በንግግሊዘኛ-ጀርመን እና እንግሊዘኛ-ኮሪያ-ስራዎችን በሚተካክል ብሊዩን አሻረ፡፡ እንግዲህ የእንግሊዝኛ-ጀርመን ተቃዋሚ ፈተና ፍትሕ አካባቢ ትክክል እንደሆነ እናሳያቸዋለን፡፡', 'sq': 'Context-aware neural machine translation (NMT) incorporates contextual information of surrounding texts, that can improve the translation quality of document-level machine translation.  Shumë punë ekzistuese mbi NMT të ndërgjegjshme në kontekst janë përqëndruar në zhvillimin e arkitekturave të reja modeli për përfshirjen e konteksteve shtesë dhe kanë treguar disa rezultate premtuese. Megjithatë, shumica e punëve ekzistuese mbështeten në humbjen e ndër-entropisë, që rezulton në përdorim të kufizuar të informacionit kontekstual. Në këtë letër, ne propozojmë CorefCL, një rritje të re të të dhënave dhe skemë të mësimit kontrastiv bazuar në koreferencë midis burimit dhe fjalëve kontekstuale. Duke korruptuar përmendimet e korreferencës të zbuluar automatikisht në fjalimin kontekstual, CorefCL mund të trajnojë model in për të qenë i ndjeshëm ndaj inkonsistencës së korreferencës. Ne eksperimentuam me metodën tonë në modele të përbashkëta NMT-në-kontekst dhe dy detyra përkthimi në nivelin e dokumentit. Në eksperimentet, metoda jonë përmirësoi vazhdimisht BLEU të modeleve të krahasuar në detyrat anglo-gjermane dhe anglo-koreane. We also show that our method significantly improves coreference resolution in the English-German contrastive test suite.', 'bn': 'বিদ্যমান-সচেতন নিউরেল মেশিন অনুবাদ (NMT) চারপাশের টেক্সট সম্পর্কে প্রাক্তন তথ্য অন্তর্ভুক্ত করে, যা নথি- স্তর মেশিন অনুবাদের অনু এনএমটিতে অনেক বিদ্যমান কাজের প্রতি মনোযোগ প্রদান করেছে যারা আরো কিছু প্রতিশ্রুতিশীল ফলাফল প্রদর্শন করেছে। তবে বেশীরভাগ বিদ্যমান কাজ ক্ষতির উপর নির্ভর করে, যার ফলে সীমাবদ্ধ তথ্য ব্যবহার করে। এই কাগজটিতে আমরা প্রস্তাব করেছি কোরেফ সিএল, সূত্র ও প্রাক্তন বাক্যের মধ্যে ভিত্তিক ভিত্তিক ভিত্তিক শিক্ষা পরিকল্পনায় একটি উপন্যাস স্বয়ংক্রিয় বাক্যে স্বয়ংক্রিয়ভাবে দুর্নীতির উল্লেখের মাধ্যমে কোরেফিসিএল এই মডেলের প্রশিক্ষণ প্রদান করতে পারে যে কোরেফেন্সের আমরা সাধারণ পরিচিত এনএমটি মডেল এবং দুই নথিটি স্তরের অনুবাদ কাজের উপর আমাদের পদ্ধতি দিয়ে পরীক্ষা করেছি। পরীক্ষার মধ্যে আমাদের পদ্ধতি ইংরেজি-জার্মান এবং ইংরেজী কোরিয়ার কাজের তুলনায় মডেলের তুলনায় উন্নত হয়েছে। আমরা একই সাথে দেখাচ্ছি যে আমাদের পদ্ধতি ইংরেজি-জার্মানের বিরোধী পরীক্ষা স্যুটে কোরিফেন্স সিদ্ধান্ত গুর', 'bs': 'U kontekstu se uključuje kontekstualna informacija o okruženim tekstima, koja može poboljšati kvalitet prevoda strojnog prevoda na nivou dokumenta. Mnogi postojeći radovi na kontekstu svjesni NMT fokusirali su se na razvoj novih modelnih arhitektura za uključenje dodatnih konteksta i pokazali su neke obećavajuće rezultate. Međutim, većina postojećih radova se oslanja na gubitak kroz entropiju, što je dovelo do ograničenog upotrebe kontekstnih informacija. U ovom papiru predlažemo CorefCL, novu povećanju podataka i kontrastivnu shēmu učenja na temelju pristojnosti između izvora i kontekstualnih rečenica. Korupcijom automatski otkrivenog pristojnosti spominjanja u kontekstualnoj rečenici, CorefCL može trenirati model da bude osjetljiv na neskladnost pristojnosti. Eksperimentirali smo svoju metodu o zajedničkim modelima NMT-a koji su svesni konteksta i dva zadatka za prevod na nivou dokumenta. U eksperimentima, naša metoda je stalno poboljšala BLEU usporedbenih modela na engleskom-njemačkom i engleskom-korejskom zadatku. Također pokazujemo da naša metoda značajno poboljšava rješenje pristojnosti u apartmanu za kontrastne testove engleskog i njemačkog.', 'ca': "La traducció neural de màquines conscients del context (NMT) incorpora informació contextual dels textos circundants, que pot millorar la qualitat de traducció de la traducció de màquines a nivell de document. Moltes treballes existents sobre la NMT conscient del context s'han centrat en desenvolupar noves arquitectures models per incorporar contextos adicionals i han demostrat alguns resultats prometedors. However, most of existing works rely on cross-entropy loss, resulting in limited use of contextual information.  En aquest paper, proposem CorefCL, un nou esquema d'augment de dades i d'aprenentatge contrastiu basat en la correferencia entre la font i les frases contextuals. Al corrompre les mentions de coreferència detectades automàticament en la frase contextual, CorefCL pot formar el model per ser sensible a la inconsistencia de coreferència. Hem experimentat amb el nostre mètode en models NMT comuns conscients del context i dues tasques de traducció a nivell de documents. En els experiments, el nostre mètode va millorar constantment el BLEU de models comparats sobre tasques anglo-alemanya i anglo-coreana. També demostram que el nostre mètode millora significativament la resolució de coreferencia en la suite de tests contrastius anglo-alemanya.", 'az': "Kontekstdən xəbərdar olan nöral maşın çevirimi (NMT) ətrafındakı mətnlər barəsindəki müxtəlif məlumatları birləşdirir ki, belə məlumat seviyyəti maşın çevirisinin çevirilməsinin keyfiyyətini yaxşılaşdırır. NMT-nin kontekstdən xəbərdar olan çox işlər yeni modellərin arhitektürlərini inkişaf etmək üçün fərqli olaraq və söz verən bir neçə nəticələri göstərdilər. Halbuki, mevcut işlərin əksəriyyəti çox entropiya zərəri üzərində təvəkkül edir, bu da müxtəlif məlumatların müəyyən edilməsi olar. Bu kağızda, CorefCL'i yeni məlumat artırmağı və müxtəlif öyrənmə taslağı mənbə və müxtəlif cümlələr arasındakı müqayisədə təklif edirik. Müxtəlif sözlərdə avtomatik olaraq tanıdıqları mərhəmətli mərhəmətli sözlərə görə, CorefCL modeli mərhəmətli müqabiliyyətə müvafiq olmaq üçün təhsil edə bilər. NMT modelləri və iki səviyyə təkrarlama işləri barəsində təcrübə etdik. Bu təcrübələrdə, bizim metodumuz İngilizce-Alman və İngilizce-Koreya işlərində müəyyən edilən modellərin BLEU-sini daha yaxşılaşdırdı. Biz də göstəririk ki, bizim metodumuz İngilis-Almanca müxtəlif sınama suitində mərhəmət çəkişməsini çox yaxşılaşdırır.", 'cs': 'Kontextový neuronový strojový překlad (NMT) obsahuje kontextové informace okolních textů, které mohou zlepšit kvalitu překladu strojového překladu na úrovni dokumentů. Mnoho stávajících prací na kontextově orientované NMT se zaměřilo na vývoj nových modelových architektur pro začlenění dalších kontextů a ukázalo některé slibné výsledky. Většina stávajících děl se však spoléhá na ztrátu křížové entropie, což vede k omezenému využití kontextových informací. V tomto článku navrhujeme CorefCL, nové schéma rozšíření dat a kontrastního učení založené na koreferenci mezi zdrojovou a kontextovou větou. Poškozením automaticky detekovaných zmínek o koreferenci v kontextové větě může CorefCL trénovat model tak, aby byl citlivý na nekonzistenci koreference. S naší metodou jsme experimentovali na běžných kontextově orientovaných NMT modelech a dvou překladatelských úlohách na úrovni dokumentů. V experimentech naše metoda důsledně zlepšovala BLEU srovnávaných modelů na anglicko-německé a anglicko-korejské úlohy. Dále ukazujeme, že naše metoda výrazně zlepšuje rozlišení koreference v anglicko-německé kontrastní testovací sadě.', 'et': 'Kontekstiteadlik neuromasintõlge (NMT) sisaldab ümbritsevate tekstide kontekstiteavet, mis võib parandada dokumenditasemel masintõlke tõlkekvaliteeti. Paljud olemasolevad kontekstiteadliku NMT-ga seotud tööd on keskendunud uute mudeliarhitektuuride väljatöötamisele täiendavate kontekstide kaasamiseks ja on näidanud mõningaid paljulubavaid tulemusi. Enamik olemasolevatest töödest tugineb siiski ristentroopia kaotusele, mille tulemuseks on kontekstiteabe piiratud kasutamine. Käesolevas töös pakume välja CorefCL-i, uudse andmete suurendamise ja kontrastiivse õppeskeemi, mis põhineb lähte- ja kontekstilausete vahelisel seosel. Korrupteerides konteksti lauses automaatselt tuvastatud ühisviidete märkusi, saab CorefCL koolitada mudelit tundlikuks ühisviidete ebajärjepidevuse suhtes. Katsetasime oma meetodit ühiste kontekstiteadlike NMT mudelite ja kahe dokumenditasemelise tõlketööga. Eksperimentide käigus parandas meie meetod järjekindlalt inglise-saksa ja inglise-korea ülesannete võrreldavate mudelite BLEU-d. Samuti näitame, et meie meetod parandab oluliselt koreferenssi resolutsiooni inglise-saksa kontrastsete testide komplektis.', 'fi': 'Kontekstitietoinen neurokonekäännös (NMT) sisältää kontekstitietoa ympäröivistä teksteistä, mikä voi parantaa dokumenttitason konekäännöksen käännöslaatua. Monet kontekstitietoista NMT:tä käsittelevät työt ovat keskittyneet uusien malliarkkitehtuurien kehittämiseen uusien kontekstien sisällyttämiseksi ja osoittaneet lupaavia tuloksia. Suurin osa olemassa olevista teoksista kuitenkin perustuu ristikkäisentropian menetykseen, mikä johtaa kontekstuaalisen tiedon rajalliseen käyttöön. Tässä työssä ehdotamme CorefCL:tä, uutta aineiston lisäämistä ja kontrastioppimista koskevaa järjestelmää, joka perustuu lähdelauseiden ja kontekstuaalisten lauseiden väliseen koreferenssiin. Korvaamalla automaattisesti havaittuja koreferenssiviittauksia asiayhteyteen liittyvässä lauseessa CorefCL voi kouluttaa mallin olemaan herkkä koreferenssin epäjohdonmukaisuudelle. Kokeilimme menetelmäämme yhteisillä kontekstitietoisilla NMT-malleilla ja kahdella asiakirjatason käännöstyöllä. Kokeissa menetelmämme paransi johdonmukaisesti englannin-saksan ja englannin-korean vertailumallien BLEU:ta. Osoitamme myös, että menetelmämme parantaa merkittävästi koreferenssin resoluutiota englannin-saksan kontrastitestisarjassa.', 'sk': 'Nevronski strojni prevod, ki se zaveda konteksta, vključuje kontekstne informacije okoliških besedil, ki lahko izboljšajo kakovost prevajanja strojnega prevoda na ravni dokumentov. Številna obstoječa dela na področju kontekstnega ozaveščanja NMT so se osredotočila na razvoj novih modelnih arhitektur za vključevanje dodatnih kontekstov in so pokazala nekaj obetavnih rezultatov. Vendar pa se večina obstoječih del opira na izgubo navzkrižne entropije, kar ima za posledico omejeno uporabo kontekstualnih informacij. V prispevku predlagamo CorefCL, novo shemo za povečanje podatkov in kontrastno učenje, ki temelji na koreferenci med izvornimi in kontekstualnimi stavki. S pokvarjevanjem samodejno zaznanih omemb korefeference v kontekstnem stavku lahko CorefCL usposobi model za občutljivost na nedoslednost koreference. Z našo metodo smo eksperimentirali na skupnih kontekstnih modelih NMT in dveh prevajalskih nalogah na ravni dokumentov. V poskusih je naša metoda dosledno izboljšala BLEU primerjavnih modelov angleško-nemških in angleško-korejskih nalog. Pokazali smo tudi, da naša metoda bistveno izboljša ločljivost koreference v angleško-nemškem kontrastnem testnem paketu.', 'ha': "translation Suna da yawa masu aiki da ke jira kan context-award NMT sun fokus a kiyaye masu tsarin shiryoyin misãlai na sami da wasu matsayin da ake yi musu wa'adi. A lokacin da, mafi yawansu masu aiki da ke jira sun dõgara a kan hasara ta guda-entropy, kuma yana ƙara da amfani da tsarin maɓallin wanda ke cikin yanzu. Ga wannan takardan, Munã buɗa CorifCL, wata shirin ƙarfafa da data na yanzu da zane-zane da taratibu a kan kwamfyuta a tsakanin sourcen da cire-sauri. Ga ka zartar da sunan mafarinta farat ɗaya a cikin cewa na haɗi, CorifCL yana iya ƙidãya wa motel wanda ya zama mai kifi ga matabbata. Mun jarraba hanyoyinmu a kan misãlai masu da aka sani wa NMT da aikin fassarar-daraja biyu. Daga jarrabai, hanyoyinmu ta fizge BLEU daidai da misãlai masu sammenliki a kan aikin Ingiriya-Jarman da Ingiriya-Koriya. Tuna nũna cewa hanyoyinmu yana ƙara rabo mai girma cikin matsayin taƙaita ta Ingiriya-jeruman.", 'he': 'התרגום של מכונת עצבית מודעת לקונקסט (NMT) מכיל מידע קונטקסטי של טקסטים סביבים, שיכול לשפר את איכות התרגום של התרגום של מכונת רמת המסמכים. עבודות רבות קיימות על NMT מודע לקונקסט התמקדו בפיתוח ארכיטקטורות דוגמניות חדשות לכילוי קשרים נוספים והראו כמה תוצאות מבטיחות. בכל אופן, רוב העבודות הקיומות תלויים על אובדן אנטרופיה צלב, מה שמוביל בשימוש מוגבל של מידע קונטקסטי. In this paper, we propose CorefCL, a novel data augmentation and contrastive learning scheme based on coreference between the source and contextual sentences.  על ידי שחיתה אוטומטית זיכרונות משפט הקשר, CorefCL יכול לאמן את הדוגמנית להיות רגישה לחוסר התאמה. ניסינו עם השיטה שלנו על מודלים NMT מודעים לקונקסט משותפים ושני משימות תרגום ברמה מסמכים. בניסויים, השיטה שלנו השתפרה באופן קבוע BLEU של דוגמנים משוואים על משימות אנגלית-גרמנית ואנגלית-קוריאנית. אנחנו גם מראים שהשיטה שלנו משפר באופן משמעותי את הפתרון המתאים בסוויטת הבדיקות ההתנגדות אנגלית-גרמנית.', 'bo': 'Context-aware neural machine translation (NMT) incorporates contextual information of surrounding texts, that can improve the translation quality of document-level machine translation. NMT ནང་དུ་གནས་ཡུལ་གྱི་རྒྱུ་དངོས་ཡོད་པ་མང་པོ་ཞིག་གིས་མཐུད་སྣེ་མཐོང་ནུས་མེད་སྒྲིག་གཞི་གསར་པ་ཚོར་སྒྲིག་འགོད་ཀྱི་ཡོད་ཚད་ ཡིན་ནའང་། གནས་ཡུལ་གྱི་ལས་ཀ་ཆེ་ཤོས་ཀྱིས་ཚུད་སྐོར་ལས་བརླག་སྟེ། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་CorefCL སྤྲོད་བྱས་པ་ཡིན་ནམ་ཡིག་ཆའི་ཆ་འཕྲིན་དང་། རྒྱབ་སྐྱོར་མོའི་ཐབས་ལམ་ལུགས་དང་། ནང་ད རང་བཞིན་གྱིས་ཞུགས་པ་དེ་རྟོགས་ཡོད་པའི་ཡིག་གཟུགས་རིས་ཚིག་ནང་གི་སྔོན་དུ་དམིགས་བསལ་ནི། CorefCL We experimented with our method on common context-aware NMT models and two document-level translation tasks. ལག་ལེན་བྱེད་པའི་ནང་དུ་ང་ཚོའི་ལམ་ལུགས་འདིས་དབྱིན་ཡིག་དང་ཨིན་རིས་ཀྱི་བྱ་འགུལ་གྱི་མིག ང་ཚོས་ཐབས་ལམ་ལ་ང་ཚོའི་དབྱིན་ཡིག་གཟུགས་འགྱུར་བའི་བརྟག་དཔྱད་ཚད་ལྟར་ཉེན་བརྟན་པར་མཐོང་བ།', 'jv': 'context-action Go online slot type Nang pepulan iki, kéné supoyo corefCL, awak dhéwé nggawe data Generasi lan jebulêm nggawe barang nggambar kuwi tindakan gar-awak dhéwé karo perangkapan langgar sapa nyimpen lan ujar-ujar. Terejer We Nang lan ujaran-ujaran, kita gampang sawetara sistem sing nyengkap mulasar nang model sing bisa basa Inggris-German lan basa Inggris-Korea. Awak dhéwé nganggep kuwi, paling dhéwé kuwi nggambar nggawe gerakan kanggo nggawe gerakan kanggo neteh sing bisa basa Inggris-German.'}
