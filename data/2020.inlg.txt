{'en': 'Assessing Discourse Relations in Language Generation from GPT-2', 'fr': 'Évaluation des relations de discours dans la génération du langage à partir du GPT-2', 'pt': 'Avaliando as relações discursivas na geração de linguagem da GPT-2', 'ar': 'تقييم علاقات الخطاب في توليد اللغة من GPT-2', 'es': 'Evaluación de las relaciones del discurso en la generación del lenguaje a partir de GPT-2', 'ja': 'GPT -2からの言語生成における発話関係の評価', 'hi': 'GPT-2 से भाषा पीढ़ी में प्रवचन संबंधों का आकलन', 'zh': '自GPT-2评语生中语', 'ru': 'Оценка отношений дискурса при генерации языка из GPT-2', 'ga': 'Caidreamh Dioscúrsa i nGiniúint Teanga a Mheasúnú ó GPT-2', 'el': 'Αξιολόγηση των σχέσεων συζήτησης στη δημιουργία γλωσσών από το GPT-2', 'hu': 'Beszédkapcsolatok értékelése a nyelvi generációban a GPT-2-ből', 'it': 'Valutazione delle relazioni discorse nella generazione linguistica da GPT-2', 'ka': 'GPT', 'ms': 'Mengesan Hubungan Berlaku dalam Jenerasi Bahasa dari GPT-2', 'kk': 'GPT- 2 дегеннен тілді құру қатынасын оқу', 'ml': 'GPT-2 ല്\u200d നിന്നും ഭാഷയുടെ ജനിപ്പില്\u200d നിന്നുള്ള ഡിസോര്\u200dസ് ബന്ധങ്ങള്\u200d വിശ്വസിക്കുന്നു', 'mk': 'Оценување на односите со дискурсот во генерацијата јазик од GPT- 2', 'lt': 'Vertinant kalbų kūrimo diskurso santykius pagal GPT-2', 'mt': 'Valutazzjoni tar-Relazzjonijiet tad-Diskors fil-Ġenerazzjoni tal-Lingwi mill-GPT-2', 'pl': 'Ocena relacji dyskursowych w generowaniu języków z GPT-2', 'ro': 'Evaluarea relațiilor de discurs în generarea limbilor străine de la GPT-2', 'no': 'Assenserer diskursrelasjonar i språk-generering frå GPT-2', 'sr': 'Procjenjivanje odnosa diskursa u generaciji jezika iz GPT-2', 'mn': 'GPT-2 холбоотой хэл үүсгэлийн ярианы харилцааны талаар', 'so': 'Ka qiimeynaya xiriirka arrimaha luqada ee GPT-2', 'ta': 'GPT- 2 யிலிருந்து மொழி உருவாக்கத்தில் தேவைப்படுகிறது', 'ur': 'GPT-2 سے زبان پیدائش میں دیسکورس رابطہ کی آزمائش', 'si': 'GPT-2 වලින් භාෂාව නිර්මාණයේ සංවේදන සම්බන්ධය අවශ්\u200dය කරන්න', 'sv': 'Bedömning av diskursrelationer i språkgenerering från GPT-2', 'uz': 'Name', 'vi': 'Đánh giá các liên hệ trong tạo ngôn ngữ từ GPT-2', 'bg': 'Оценка на дискурсните отношения в езиковото генериране от ГПТ-2', 'hr': 'Procjenjivanje odnosa diskursa u generaciji jezika iz GPT-2', 'da': 'Vurdering af diskursrelationer i sproggenerering fra GPT-2', 'nl': 'Evaluatie van discoursverhoudingen in taalgeneratie vanuit GPT-2', 'de': 'Bewertung von Diskursbeziehungen in der Sprachgenerierung von GPT-2', 'id': 'Mengevaluasi hubungan diskursus dalam generasi bahasa dari GPT-2', 'fa': 'ارزیابی رابطه\u200cهای صحبت در تولید زبان از GPT-2', 'ko': 'GPT-2에서 언어 생성에서의 언어 관계 평가', 'af': 'Assensie Afspraak Relasies in Taal Generasie van GPT- 2', 'am': 'ቋንቋ አቀማመጥ', 'sw': 'Assessing Discourse Relations in Language Generation from GPT-2', 'tr': "GPT-2'den Çykyş Derjesini Taryşdyrma", 'hy': 'GPT-2-ի միջոցով ստեղծվող լեզվի ընթացքում քննարկված հարաբերությունները', 'bn': 'GPT-2 থেকে ভাষা প্রজন্মের ভাষায় তথ্য পরিচালনা করা হচ্ছে', 'sq': 'Duke vlerësuar marrëdhëniet diskursore në Gjenerimin e Gjuhave nga GPT-2', 'az': "GPT-2'd…ôn dil yaradńĪlńĪŇüńĪnda diskurs iliŇükilerini t…ômin edir", 'bs': 'Procjenjivanje odnosa diskursa u generaciji jezika iz GPT-2', 'et': 'Diskursusuhtede hindamine keele genereerimisel GPT-2 põhjal', 'fi': 'Keskustelusuhteiden arviointi kielen tuottamisessa GPT-2:sta', 'ca': 'Evaluar les relacions de discurs en la generació de llenguatges a partir del GPT-2', 'cs': 'Hodnocení diskursních vztahů v generování jazyků z GPT-2', 'he': 'הערכה של יחסי דיסקורס ביצירת שפות מ-GPT-2', 'ha': 'KCharselect unicode block name', 'jv': 'Language', 'bo': 'Assessing Discourse Relations in Language Generation from GPT-2', 'sk': 'Ocena diskurznih odnosov pri ustvarjanju jezikov iz GPT-2'}
{'en': 'Recent advances in NLP have been attributed to the emergence of large-scale pre-trained language models. GPT-2, in particular, is suited for generation tasks given its left-to-right language modeling objective, yet the linguistic quality of its generated text has largely remain unexplored. Our work takes a step in understanding GPT-2’s outputs in terms of discourse coherence. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2’s outputs under both organic generation and fine-tuned scenarios. Results show GPT-2 does not always generate text containing valid discourse relations ; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario. We propose a decoupled strategy to mitigate these problems and highlight the importance of explicitly modeling discourse information.', 'ar': 'تُعزى التطورات الحديثة في البرمجة اللغوية العصبية إلى ظهور نماذج لغوية مدربة مسبقًا على نطاق واسع. إن GPT-2 ، على وجه الخصوص ، مناسب لمهام التوليد نظرًا لهدف نمذجة اللغة من اليسار إلى اليمين ، إلا أن الجودة اللغوية للنص الناتج ظلت إلى حد كبير غير مستكشفة. يأخذ عملنا خطوة في فهم مخرجات GPT-2 من حيث ترابط الخطاب. نقوم بإجراء دراسة شاملة حول صحة علاقات الخطاب الصريح في مخرجات GPT-2 في ظل كل من سيناريوهات التوليد العضوي والسيناريوهات الدقيقة. تظهر النتائج أن GPT-2 لا ينتج دائمًا نصًا يحتوي على علاقات خطاب صحيحة ؛ ومع ذلك ، فإن نصها يتماشى أكثر مع التوقعات البشرية في السيناريو الدقيق. نقترح استراتيجية منفصلة للتخفيف من حدة هذه المشاكل وتسليط الضوء على أهمية نمذجة معلومات الخطاب بشكل صريح.', 'es': 'Los avances recientes en la PNL se han atribuido a la aparición de modelos lingüísticos preentrenados a gran escala. GPT-2, en particular, es adecuado para tareas de generación dado su objetivo de modelado del lenguaje de izquierda a derecha, pero la calidad lingüística del texto generado ha permanecido inexplorada en gran medida. Nuestro trabajo da un paso adelante en la comprensión de los resultados de GPT-2 en términos de coherencia del discurso. Realizamos un estudio exhaustivo sobre la validez de las relaciones discursivas explícitas en los resultados de GPT-2 tanto en escenarios de generación orgánica como en escenarios ajustados. Los resultados muestran que GPT-2 no siempre genera texto que contenga relaciones de discurso válidas; sin embargo, su texto está más alineado con la expectativa humana en el escenario ajustado. Proponemos una estrategia disociada para mitigar estos problemas y destacar la importancia de modelar explícitamente la información del discurso.', 'pt': 'Avanços recentes na PNL têm sido atribuídos ao surgimento de modelos de linguagem pré-treinados em larga escala. O GPT-2, em particular, é adequado para tarefas de geração devido ao seu objetivo de modelagem de linguagem da esquerda para a direita, mas a qualidade linguística de seu texto gerado permanece em grande parte inexplorada. Nosso trabalho dá um passo na compreensão dos resultados do GPT-2 em termos de coerência discursiva. Realizamos um estudo abrangente sobre a validade das relações de discurso explícitas nas saídas do GPT-2 tanto em cenários de geração orgânica quanto em cenários de ajuste fino. Os resultados mostram que o GPT-2 nem sempre gera texto contendo relações discursivas válidas; no entanto, seu texto está mais alinhado com a expectativa humana no cenário ajustado. Propomos uma estratégia dissociada para mitigar esses problemas e destacamos a importância de modelar explicitamente as informações discursivas.', 'fr': "Les récents progrès de la PNL ont été attribués à l'émergence de modèles linguistiques préformés à grande échelle. GPT-2, en particulier, est adapté aux tâches de génération compte tenu de son objectif de modélisation linguistique de gauche à droite, mais la qualité linguistique du texte généré est restée largement inexplorée. Notre travail franchit une étape dans la compréhension des résultats de GPT-2 en termes de cohérence du discours. Nous effectuons une étude complète sur la validité des relations de discours explicites dans les sorties de GPT-2 à la fois dans des scénarios de génération organique et des scénarios affinés. Les résultats montrent que GPT-2 ne génère pas toujours de texte contenant des relations de discours valides\xa0; néanmoins, son texte est plus aligné sur les attentes humaines dans le scénario affiné. Nous proposons une stratégie découplée pour atténuer ces problèmes et souligner l'importance de modéliser explicitement les informations du discours.", 'ja': 'NLPの最近の進歩は、大規模な事前訓練された言語モデルの出現に起因するとされている。特に、ＧＰＴ － ２は、その左から右への言語モデリング目標を考慮すると、生成タスクに適しているが、生成されたテキストの言語学的品質は、ほとんど未調査のままである。私たちの研究は、議論の一貫性の観点からGPT -2のアウトプットを理解するための一歩を踏み出しています。私たちは、有機生成と微調整されたシナリオの両方で、GPT -2の出力における明示的な話題関係の妥当性に関する包括的な研究を行っています。結果は、GPT -2が必ずしも妥当な話題関係を含むテキストを生成するわけではないことを示しています。それでも、そのテキストは、微調整されたシナリオの中で人間の期待とより一致しています。これらの問題を軽減し、話題情報を明示的にモデリングすることの重要性を強調するために、分離された戦略を提案します。', 'zh': 'NLP之最新进展归因于大预训习言语模样。 GPT-2尤宜生事,以其从左到右言建模,而其文本语质未究也。 吾事在解GPT-2语连贯性出一步。 有机生微GPT-2输中显式语有效性周究。 结果显示,GPT-2非文本也。 然于微调之中,其文本更合人伦之望。 解耦策以纾之,而强显式建模言息之要。', 'hi': 'एनएलपी में हाल की प्रगति को बड़े पैमाने पर पूर्व-प्रशिक्षित भाषा मॉडल के उद्भव के लिए जिम्मेदार ठहराया गया है। जीपीटी -2, विशेष रूप से, अपने बाएं-से-दाएं भाषा मॉडलिंग उद्देश्य को देखते हुए पीढ़ी के कार्यों के लिए उपयुक्त है, फिर भी इसके उत्पन्न पाठ की भाषाई गुणवत्ता काफी हद तक अज्ञात रही है। हमारा काम प्रवचन सुसंगतता के संदर्भ में जीपीटी -2 के आउटपुट को समझने में एक कदम उठाता है। हम कार्बनिक पीढ़ी और ठीक-ठाक परिदृश्यों दोनों के तहत जीपीटी -2 के आउटपुट में स्पष्ट प्रवचन संबंधों की वैधता पर एक व्यापक अध्ययन करते हैं। परिणाम बताते हैं कि GPT-2 हमेशा मान्य प्रवचन संबंधों वाले पाठ को उत्पन्न नहीं करता है; फिर भी, इसका पाठ ठीक-ठाक परिदृश्य में मानव अपेक्षा के साथ अधिक संरेखित है। हम इन समस्याओं को कम करने और स्पष्ट रूप से मॉडलिंग प्रवचन जानकारी के महत्व को उजागर करने के लिए एक डिकॉप्ड रणनीति का प्रस्ताव करते हैं।', 'ru': 'Недавние достижения в области NLP объясняются появлением крупномасштабных заранее подготовленных языковых моделей. GPT-2, в частности, подходит для задач генерации, учитывая его цель моделирования языка слева направо, однако лингвистическое качество его сгенерированного текста в значительной степени остается неисследованным. Наша работа делает шаг в понимании результатов GPT-2 с точки зрения согласованности дискурса. Мы проводим комплексное исследование обоснованности явных дискурсивных отношений в выводах GPT-2 как в рамках органической генерации, так и в рамках тонкой настройки сценариев. Результаты показывают, что GPT-2 не всегда генерирует текст, содержащий действительные отношения дискурса; тем не менее, его текст больше соответствует ожиданиям человека в доработанном сценарии. Мы предлагаем отдельную стратегию для смягчения этих проблем и подчеркиваем важность прямого моделирования дискурсной информации.', 'ga': 'Tá dul chun cinn le déanaí san NLP curtha i leith na múnlaí teanga réamhoilte ar scála mór a tháinig chun cinn. Tá GPT-2, go háirithe, feiliúnach do thascanna giniúna i bhfianaise a chuspóir samhaltaithe teanga clé go deas, ach níl mórán taiscéalta déanta ar cháilíocht teanga an téacs ginte. Glacann ár gcuid oibre céim chun tosaigh chun aschuir GPT-2 a thuiscint i dtéarmaí comhleanúnachais dioscúrsa. Déanaimid staidéar cuimsitheach ar bhailíocht caidreamh dioscúrsa follasach in aschuir GPT-2 faoi ghiniúint orgánach agus cásanna mionchoigeartaithe. Léiríonn torthaí nach gineann GPT-2 téacs ina bhfuil caidreamh dioscúrsa bailí i gcónaí; mar sin féin, tá a téacs ailínithe níos mó le hionchas an duine sa chás mionchoigeartaithe. Molaimid straitéis díchúpláilte chun na fadhbanna seo a mhaolú agus chun béim a leagan ar an tábhacht a bhaineann le faisnéis dioscúrsa a shamhaltú go sainráite.', 'el': 'Πρόσφατες πρόοδοι στον τομέα της NLP έχουν αποδοθεί στην εμφάνιση μεγάλης κλίμακας προ-εκπαιδευμένων γλωσσικών μοντέλων. Ειδικότερα, το GPT-2 είναι κατάλληλο για εργασίες δημιουργίας δεδομένων του στόχου μοντελοποίησης γλώσσας από αριστερά προς δεξιά, ωστόσο η γλωσσική ποιότητα του παραγόμενου κειμένου του έχει παραμείνει σε μεγάλο βαθμό ανεξερεύνητη. Η εργασία μας κάνει ένα βήμα στην κατανόηση των αποτελεσμάτων του GPT-2 όσον αφορά τη συνοχή του λόγου. Πραγματοποιούμε μια ολοκληρωμένη μελέτη για την εγκυρότητα των ρητών σχέσεων συζήτησης στα αποτελέσματα του τόσο σε οργανικά σενάρια παραγωγής όσο και σε εκλεπτυσμένα σενάρια. Τα αποτελέσματα δείχνουν ότι το GPT-2 δεν παράγει πάντα κείμενο που περιέχει έγκυρες σχέσεις λόγου. Ωστόσο, το κείμενό του ευθυγραμμίζεται περισσότερο με τις ανθρώπινες προσδοκίες στο λεπτομερώς συντονισμένο σενάριο. Προτείνουμε μια αποσυνδεδεμένη στρατηγική για να μετριάσουμε αυτά τα προβλήματα και να τονίσουμε τη σημασία της ρητής μοντελοποίησης των πληροφοριών του λόγου.', 'hu': 'A nemzeti politika terén a közelmúltbeli előrelépéseket a nagyszabású, előkészített nyelvi modellek kialakulásának tulajdonították. A GPT-2 különösen alkalmas generációs feladatokra, tekintettel balról jobbra irányuló nyelvmodellezési célkitűzésére, de a generált szöveg nyelvi minősége nagyrészt feltáratlan maradt. Munkánk lépést tesz a GPT-2 kimeneteinek megértésében a diskurzuskoherencia szempontjából. Átfogó tanulmányt végzünk a GPT-2 kimeneteiben az explicit diskurzus kapcsolatok érvényességéről mind organikus generáció, mind finomhangolt forgatókönyvek között. Az eredmények azt mutatják, hogy a GPT-2 nem mindig generál érvényes diskurzusi kapcsolatokat tartalmazó szöveget; A finomhangolt forgatókönyvben azonban a szövege jobban összhangban áll az emberi elvárásokkal. Egy független stratégiát javasolunk e problémák enyhítésére, és kiemeljük a diskurzus információk kifejezett modellezésének fontosságát.', 'ka': 'Name GPT-2, განსაკუთრებულად, უფრო მსგავსი ტექსტის ლუქტური კაalitეტი უფრო მეტი უნდა იყოს მისი მარცხნივ ენის მოდელური მიზეზი. ჩვენი სამუშაო გავაგრძელება GPT-2-ის შემდეგ განსხვავებაში. ჩვენ გავაკეთებთ ყველაფერი განსხვავება GPT-2-ის გამოსახულებაში და ორგანიკური განსხვავებაში და სწორად განსხვავებული სენარიოში. შედეგი GPT- 2 ჩვენება არ ყოველთვის ტექსტის შექმნა დამატებული დისკურსის შესახებ. მაგრამ მისი ტექსტი უფრო სწორედ ადამიანის განმეხოვრებით სენარიოში. ჩვენ გვეძლევა განხორციული სტრატიგია, რომ ამ პრობლემების შემცირება და განაწეროთ გასანიშვნელოვანი დეკურსების ინფორმაციის მნიშვნელობა.', 'it': "I recenti progressi nel PNL sono stati attribuiti all'emergere di modelli linguistici pre-formati su larga scala. GPT-2, in particolare, è adatto per compiti di generazione dato il suo obiettivo di modellazione linguistica da sinistra a destra, eppure la qualità linguistica del testo generato è rimasta in gran parte inesplorata. Il nostro lavoro fa un passo nella comprensione dei risultati di GPT-2 in termini di coerenza del discorso. Realizziamo uno studio completo sulla validità delle relazioni esplicite del discorso negli output di GPT-2 sia in scenari di generazione organica che di fine-tuned. I risultati mostrano che GPT-2 non sempre genera testo contenente relazioni di discorso valide; Tuttavia, il suo testo è più allineato alle aspettative umane nello scenario perfezionato. Proponiamo una strategia disaccoppiata per mitigare questi problemi e sottolineare l'importanza di modellare esplicitamente le informazioni sul discorso.", 'kk': 'Жуырдағы NLP бағдарламалары үлкен- кеңейтілген тіл үлгілеріне арналған. GPT- 2, осымен қатар, сол жақтан оң жақтан тілді моделдеу мақсатына келтірілген тапсырмалар үшін қолданылады, бірақ оның құрылған мәтіннің лингвистикалық сапасы көбінде көбінде талап етпейді. Біздің жұмысамыз GPT-2-нің шығысын түсінуге қадам келеді. Біз GPT-2 бағдарламасының органикалық құрылымының және дұрыс жасалған сценарияларының қасиеттерінің дұрыстығын толық зерттеуді жасап отырмыз. Нәтижелер GPT- 2 дегенді әрқашанда дұрыс дисков қатынасы бар мәтін құрылмайды. Бірақ оның мәтіні адамдардың күтпеген сценариясында көбірек болады. Біз бұл мәселелерді көшірмелеу және дискурстардың мәліметін түсіндіру үшін бөліктірілген стратегияны ұсынамыз.', 'lt': 'Neseniai padaryta pažanga, susijusi su didelio masto išankstinio mokymo kalbomis modelių atsiradimu. Visų pirma GPT-2 pritaikoma generacijos užduotims, atsižvelgiant į jos kairės į dešin ę kalbos modeliavimo tikslą, tačiau jo sukurto teksto kalbinė kokybė iš esmės lieka neišnagrinėta. Mūs ų darbas yra žingsnis suprantant GPT-2 rezultatus kalbų nuoseklumo požiūriu. Atliekame išsamų tyrimą dėl aiškių diskursinių santykių, susijusių su GPT-2 rezultatais, galiojimo tiek ekologinės gamybos, tiek patobulintų scenarijų atveju. Rezultatai rodo, kad GPT-2 ne visada generuoja tekstą, kuriame yra galiojančių diskursinių santykių; vis dėlto jo tekstas labiau atitinka žmogaus lūkesčius suderintame scenarijuje. Siūlome atskirtą strategiją šioms problemoms sušvelninti ir pabrėžiama aiškiai modeliuojamos diskursinės informacijos svarba.', 'ms': "Kemajuan baru-baru ini dalam NLP telah ditakrif kepada muncul model bahasa yang dilatih-dilatih pada skala besar. GPT-2, secara khususnya, sesuai untuk tugas generasi kerana objektif pemodelan bahasa kiri-ke-kanan, namun kualiti bahasa teks yang dijana kebanyakan masih belum dikenalpasti. Kerja kita mengambil langkah dalam memahami output GPT-2 dalam terma kesecoherensi diskors. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2's outputs under both organic generation and fine-tuned scenarios.  Hasil menunjukkan GPT-2 tidak sentiasa menghasilkan teks yang mengandungi hubungan diskors yang sah; namun, teksnya lebih sesuai dengan harapan manusia dalam skenario yang sesuai. Kami cadangkan strategi terpisah untuk mengurangi masalah ini dan menyatakan pentingnya untuk mengurangi maklumat diskors secara eksplicit.", 'mk': 'Неодамнешните напредоци во НЛП се припишани на појавата на големи предобучени јазички модели. ГПТ-2, особено, е соодветен за генерациски задачи со оглед на нејзината цел на моделирање на лево во десно јазик, но јазичниот квалитет на нејзиниот генериран текст во голема мера останува неистражен. Нашата работа презема чекор во разбирањето на излезите на ГПТ-2 во поглед на дискурсната кохеренција. Ние спроведуваме комплетна студија за валидноста на експлицитните дискурсни односи во излезите на ГПТ-2 под органска генерација и фино прилагодени сценарија. Резултатите покажуваат дека GPT- 2 не секогаш генерира текст кој содржи валидни дискурсни односи; сепак, нејзиниот текст е посогласен со човечките очекувања во финетизираниот сценарио. Предложуваме раздвојена стратегија за олеснување на овие проблеми и ја истакнуваме важноста на експлицитно моделирање на дискурсните информации.', 'ml': 'NLP-ലെ അടുത്തുള്ള മുന്നോട്ടുള്ള മുന്നോട്ടുപഠിപ്പിക്കപ്പെട്ട ഭാഷ മോഡലുകളുടെ ഉയര്\u200dച്ചയ്ക്ക് വേണ്ടി പ GPT-2 പ്രത്യേകിച്ച്, അതിന്റെ ഇടത്തോട്ട് വലത്തോട്ട് ഭാഷ മോഡലിങ് ലക്ഷ്യം നല്\u200dകിയ തലമുറയുടെ ജോലികള്\u200d സംസാരിക്കുന്നതിനെക്കുറിച്ച് നമ്മുടെ ജോലി ജിപിടി 2-ന്റെ പുറത്തുള്ള പ്രകടനം മനസ്സിലാക്കുന്നതിന്  ജിപിടി-2-ന്റെ പുറത്തുള്ള വ്യക്തമായ സംസാര ബന്ധങ്ങളുടെ വ്യക്തമായ വ്യക്തമായ ഒരു പഠനം ഞങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു. ഓരോഗിക തലമുറയും  Results show GPT-2 does not always generate text containing valid discourse relations;  എന്നാലും അതിന്റെ പദാവലി മനുഷ്യന്റെ പ്രതീക്ഷ കൂടുതല്\u200d ഒരുമിച്ചിരിക്കുന്നു. ഈ പ്രശ്നങ്ങള്\u200d മുളപ്പിക്കാനും വ്യക്തമായി സംസാരിക്കുന്ന വിവരങ്ങളുടെ പ്രധാനപ്പെട്ടത് പ്രകടമാക്കാനും ഞങ്ങള്\u200d ഒരു വ', 'mt': "L-avvanzi reċenti fil-NLP ġew attribwiti għall-iżvilupp ta’ mudelli lingwistiċi mħarrġa minn qabel fuq skala kbira. Il-GPT-2, b’mod partikolari, huwa adattat għal kompiti ta’ ġenerazzjoni minħabba l-objettiv ta’ mudellar tal-lingwa mix-xellug għal-lemin tiegħu, iżda l-kwalità lingwistika tat-test iġġenerat tiegħu fil-biċċa l-kbira baqgħet mhux esplorata. Il-ħidma tagħna tieħu pass biex nifhmu r-riżultati tal-GPT-2 f'termini ta' koerenza tad-diskors. Għandna nagħmlu studju komprensiv dwar il-validità tar-relazzjonijiet ta’ diskors espliċiti fir-riżultati tal-GPT-2 kemm taħt xenarji ta’ ġenerazzjoni organika kif ukoll f’xenarji rfini. Ir-riżultati juru li GPT-2 mhux dejjem jiġġenera test li fih relazzjonijiet ta’ diskors validi; madankollu, it-test tiegħu huwa aktar allinjat mal-aspettattivi tal-bniedem fix-xenarju rfinut. Aħna qed nipproponu strateġija diżakkoppjata biex tnaqqas dawn il-problemi u tenfasizza l-importanza li tiġi mmudellata espliċitament l-informazzjoni dwar id-diskors.", 'mn': 'NLP-ийн саяхан хөгжлийн хөгжлийн талаар том хэл дасгал хөгжлийн загваруудыг харуулсан. Ялангуяа GPT-2 нь зүүн-зүүн-баруун хэл загварын зорилго өгсөн үйлдлийн даалгаваруудын тулд зорилготой. Гэхдээ үүнийг бүтээсэн хэлний хэлний чанар ихэвчлэн тайлбарлахгүй байна. Бидний ажил GPT-2-ын үр дүнг ойлгохын тулд нэг алхам хэрэгтэй. Бид GPT-2-ын органик үеийн болон сайн зохион байгуулалт дээр тодорхой ярианы харилцааны үнэ цэнэтэй талаар бүрэн судалгаа хийдэг. Үр дүн нь GPT-2-г үргэлж зөв ярианы холбоотой текст бий болгодоггүй. Гэхдээ үүний текст хүн төрөлхтний хүлээн зөвшөөрөгдсөн хувилбарт илүү холбоотой. Бид эдгээр асуудлыг багасгаж, ярианы мэдээллийг тодорхойлох хэрэгтэй талаар шийдэх стратегийг санал болгож байна.', 'no': 'Nyleg har avansert i NLP blitt attributtet til utviklinga av stor skala før- trenga språk- modeller. GPT-2 er spesielt passa for oppgåver som er gitt målet til å modelera så venstre til høgre språk, men den lingviske kvaliteten til den genererte teksten er stort uventa. Arbeidet vårt tar ein steg i forståelse av GPT-2-utgåver ved hjelp av diskurskoherens. Vi utfører ein komplett studie om gyldigheten av eksplisitt diskursrelasjonar i GPT-2-utgåva under både organiske generering og fint-oppsett scenarioar. Resultat viser GPT- 2 generer ikkje alltid tekst som inneheld gyldig diskursrelasjon. Den teksten er likevel mer alignert med menneskelig forventing i den finnstillingsscenarioen. Vi foreslår ein dekomplisert strategi for å redusera desse problemene og markera viktigheten til å modelera diskursinformasjon.', 'pl': 'Ostatnie postępy w dziedzinie NLP zostały przypisane pojawieniu się na dużą skalę wstępnie przeszkolonych modeli językowych. GPT-2, w szczególności, nadaje się do zadań generacyjnych ze względu na cel modelowania języka od lewej do prawej, jednak jakość językowa generowanego tekstu pozostała w dużej mierze niezbadana. Nasza praca stawia krok w zrozumieniu wyników GPT-2 pod kątem spójności dyskursu. Przeprowadzamy kompleksowe badanie nad ważnością wyraźnych relacji dyskursowych w wynikach GPT-2 zarówno w scenariuszach generacji organicznej, jak i dostrojonych. Wyniki pokazują, że GPT-2 nie zawsze generuje tekst zawierający ważne relacje dyskursowe; Niemniej jednak jego tekst jest bardziej dostosowany do ludzkich oczekiwań w dopracowanym scenariuszu. Proponujemy oddzielną strategię łagodzenia tych problemów i podkreślamy znaczenie wyraźnego modelowania informacji dyskursowych.', 'ro': 'Progresele recente în PNL au fost atribuite apariției unor modele lingvistice pre-instruite la scară largă. GPT-2, în special, este potrivit pentru sarcini de generare având în vedere obiectivul său de modelare lingvistică de la stânga la dreapta, însă calitatea lingvistică a textului generat a rămas în mare parte neexplorată. Activitatea noastră face un pas în înțelegerea rezultatelor GPT-2 în termeni de coerență a discursului. Realizăm un studiu cuprinzător privind validitatea relațiilor de discurs explicite în rezultatele GPT-2 atât în cadrul generației organice, cât și în scenarii bine reglate. Rezultatele arată că GPT-2 nu generează întotdeauna text care conține relații de discurs valide; Cu toate acestea, textul său este mai aliniat cu așteptările umane în scenariul bine reglat. Propunem o strategie decuplată pentru atenuarea acestor probleme și sublinierea importanței modelării explicite a informațiilor despre discurs.', 'sr': 'Nedavni napredak u NLP prikazan je slučaju velikih predobučenih jezičkih modela. GPT-2, posebno, odgovara je za zadatak generacije s obzirom na svoj cilj modeliranja lijevog-desnog jezika, ali jezička kvalitet njegovog proizvedenog teksta u velikoj meri ostaje neobjašnjiva. Naš rad preduzima korak u razumijevanju rezultata GPT-2 u smislu konsekvencije diskursa. Izvodimo sveobuhvatljivo istraživanje o validnosti eksplicitih diskurskih odnosa u rezultatima GPT-2 pod organskim generacijama i ispravnim scenarijama. Rezultati pokazuju da GPT- 2 ne uvek stvara tekst koji sadrži valjane veze sa diskursima; Ipak, njegov tekst je više usklađen sa ljudskim očekivanjem u finom scenariju. Predlažemo rasključenu strategiju za smanjenje tih problema i naglašavanje važnosti izravno modeliranja informacija o diskusijama.', 'si': 'Name GPT-2, විශේෂයෙන්, විශේෂයෙන්, පිළිබඳු වැඩක් වෙනුවෙන් පිළිබඳු වැඩක් සඳහා යුතුයි, ඒ වගේම වමුරු වලින් දකුණු භාෂ අපේ වැඩේ GPT-2 ගේ ප්\u200dරතිචාරයක් තේරුම් ගන්න පැත්තක් ගන්නවා කියලා කතාවක් සම්බන්ධ විදිහට. අපි සම්පූර්ණ පරීක්ෂණයක් කරන්නේ GPT-2 ගේ පිළිබඳ සම්බන්ධතාවක් සම්බන්ධතාවක් ගැන සම්බන්ධ විදිහට සම්බන්ධ විදිහට සහ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර ඒත් ඒකේ පාළුව තව මිනිස්සුන්ගේ බලාපොරොත්තුවක් සමග වැඩියි. අපි මේ ප්\u200dරශ්නයක් අඩුවෙන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් සැලසුම් කරනවා ඒ වගේම ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dර', 'so': 'Horumarinta u soo dhowaaday ee NLP waxaa sabab u ah soo baxa tusaalaha afka hore oo aad u horeysay. GPT-2, si gaar ah, waxaa loo habboon shaqooyinka generashada oo la siiyay hagitaanka midig-midig luuqadiisa, laakiin qiimaha luuqada afkiisa luuqada ah waxaa ugu badnaan jirta mid aan shaqeyn. Shaqo-keenistayada ayaa qaadanaya qalabka garashada soo bixinta GPT-2 ee ku saabsan hadalka labaad. Waxbarashada aasaasiga ah oo ku saabsan suurtagalka xiriirka hadalka oo cad ee GPT-2 ka hooseeya qarniga organiga ah iyo xilliga farsamada wanaagsan. Results show GPT-2 does not always generate text containing valid discourse relations;  Si kastaba ha ahaatee, qoraalkeeda waxaa lagu bedelaa rajada dadka oo ku jira aragti wanaagsan. Waxaynu soo jeedinaynaa qoraal qallafsan si aan u fududayno dhibaatadan iyo si cad loo tuso macluumaadka hadalka.', 'sv': 'De senaste framstegen inom det nationella handlingsprogrammet har tillskrivits uppkomsten av storskaliga förkortade språkmodeller. GPT-2 lämpar sig särskilt för generationsuppgifter med tanke på dess språkmodelleringsmål från vänster till höger, men den språkliga kvaliteten på den genererade texten har i stort sett inte utforskats. Vårt arbete tar ett steg i att förstå GPT-2:s resultat när det gäller diskurskoherens. Vi genomför en omfattande studie om validiteten av explicita diskursrelationer i GPT-2:s resultat under både organisk generation och finjusterade scenarier. Resultaten visar att GPT-2 inte alltid genererar text som innehåller giltiga diskursrelationer; Texten är dock mer anpassad till människans förväntningar i det finjusterade scenariot. Vi föreslår en frikopplad strategi för att mildra dessa problem och betona vikten av att uttryckligen modellera diskursinformation.', 'ur': 'NLP میں اچھی اگلوں سے اگلوں کی پیش آموزش کی زبان موڈل کی اضطراری کے لئے اضافہ کی گئی ہے۔ GPT-2، مخصوصاً نسل کے کاموں کے لئے مناسب ہے جو اس کے بائیں-دائیں زبان موڈلینگ کا موضوع دیا گیا ہے، لیکن اس کے پیدا کئے ہوئے متن کی زبان کی کیفیت بہت زیادہ غیر منتظر رہی ہے. ہمارا کام GPT-2 کے نتائج کو سمجھنے کے لئے ایک قدم لگا رہا ہے۔ ہم نے GPT-2 کے نتیجے میں صریح گفتگو کے ارتباط کے معاملہ کے بارے میں ایک محکم تحقیق کیا ہے جتنا سازمانی نسل اور بہترین سناریوں کے نیچے. نتیجے GPT- 2 کو ہمیشہ متن پیدا نہیں کرتے جن میں سمجھی ڈیکورس رابطہ ہے۔ لیکن اس کا پیغام بہت زیادہ انسان کی انتظار کے ساتھ ٹھیک ہے۔ ہم نے ان مشکلوں کو کمزور کرنے کے لئے ایک ڈکوپل ڈراٹی کی پیشنهاد کرتا ہے اور صحبت کی معلومات کی مثال صریح مدل کرنے کے لئے اہم کرتا ہے.', 'ta': 'NLP இன் சமீபத்தில் முன்னேற்றம் பெரிய அளவு முன் பயிற்சி மொழி மாதிரிகளின் வெளியேறுதலுக்கு குறிப்பிடப்பட்டது. @ info எங்கள் வேலை GPT-2 வெளியீடுகளை புரிந்து கொள்ள ஒரு படி எடுத்துக் கொள்கிறது. நாங்கள் ஜிபிடி-2 வெளியீட்டில் வெளிப்படையான பேச்சு தொடர்புகளின் சரியான முறையில் ஒரு முழுமையான ஆராய்ச்சி செய்கிறோம் அமைப Results show GPT-2 does not always generate text containing valid discourse relations;  ஆனாலும், அதன் உரையின் மேலும் ஒருங்கிணைக்கப்பட்டுள்ளது நன்றாக உள்ள காட்சியில் மனித எதிர்பார்ப்புடன். இந்த பிரச்சனைகளை அலங்காரத்திற்கு ஒரு வெளிப்படையாக்கப்பட்ட திட்டத்தை நாம் பரிந்துரைக்கிறோம் மற்றும் வெளிப்', 'uz': "@ info @ info: whatsthis Bizning ishimiz GPT-2 tashkilotlarini o'rganishga o'rganadi. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2's outputs under both organic generation and fine-tuned scenarios.  @ info: whatsthis Lekin, bu matnning eng yaxshi tashkilotda inson kutilgan narsalar bilan birlashtiradi. Bu muammolarni kamaytirish uchun bir nechta strategiya so'raymiz va suhbatning muhimligini aniqlash mumkin.", 'vi': 'Những tiến bộ gần đây trong ngôn ngữ ngọt ngào được cho là sự xuất hiện của các mô hình ngôn ngữ nguyên sơ. Đặc biệt là GPT-2, được phù hợp cho các nhiệm vụ hàng thế hệ vì mục tiêu tạo mẫu ngôn ngữ phải, nhưng chất lượng ngôn ngữ của nó vẫn còn chưa được khám phá. Công việc của chúng tôi có một bước trong việc hiểu kết quả của GPT-2 về s ự đồng bộ đàm luận. Chúng tôi thực hiện một nghiên cứu đầy đủ về giá trị của các mối quan hệ đàm phán trực tiếp trong kết xuất của GPT-2 trong các viễn cảnh sinh học hữu cơ và hoàn thiện. Kết quả cho thấy GPT-2 không phải lúc nào cũng tạo ra văn bản chứa mối quan hệ đàm luận hợp lệ; Tuy nhiên, văn bản của nó giống với sự chờ đợi của con người hơn trong kịch bản hoàn thiện. Chúng tôi đề xuất một chiến lược tách ra để giảm thiểu các vấn đề này và nhấn mạnh tầm quan trọng của việc mô tả thuyết trình trực tiếp.', 'nl': "Recente vooruitgang in NLP wordt toegeschreven aan de opkomst van grootschalige voorgetrainde taalmodellen. GPT-2, met name, is geschikt voor generatietaken gezien de doelstelling van links naar rechts taalmodellering, maar de linguïstische kwaliteit van de gegenereerde tekst is grotendeels onontdekt. Ons werk zet een stap in het begrijpen van GPT-2's outputs in termen van discourscoherentie. We voeren een uitgebreide studie uit naar de validiteit van expliciete discoursrelaties in GPT-2's outputs onder zowel organische generatie als verfijnde scenario's. Resultaten tonen aan dat GPT-2 niet altijd tekst genereert die geldige discoursrelaties bevat; Niettemin is de tekst meer afgestemd op de menselijke verwachtingen in het verfijnde scenario. We stellen een ontkoppelde strategie voor om deze problemen te beperken en benadrukken het belang van expliciete modellering van discoursinformatie.", 'hr': 'Nedavni napredak u NLP-u prikazan je slučaju velikih predobučenih jezičkih modela. GPT-2, posebno, odgovara je za zadatke generacije s obzirom na svoj cilj modeliranja lijevog-desnog jezika, ali jezička kvalitet njegovog proizvedenog teksta u velikoj mjeri ostaje neobjašnjiva. Naš rad zahtijeva korak u razumijevanju rezultata GPT-2 u smislu konsekvencije diskursa. Provodimo sveobuhvatljivo ispitivanje o validnosti pojasnih odnosa o diskusiji u rezultatima GPT-2 pod organskim generacijama i ispravnim scenarijama. Rezultati pokazuju da GPT- 2 ne uvijek stvara tekst koji sadrži vrijedne odnose o diskusiji; Ipak, njegov tekst je više usklađen s ljudskim očekivanjem u finom scenariju. Predlažemo rasključenu strategiju za smanjenje tih problema i naglašavanje važnosti pojasno modeliranja informacija o diskusijama.', 'bg': 'Последният напредък в НЛП се дължи на появата на широкомащабни предварително обучени езикови модели. GPT-2, по-специално, е подходящ за задачи за генериране, имайки предвид целта си за моделиране на езика отляво надясно, но езиковото качество на генерирания текст до голяма степен остава неизследвано. Работата ни прави стъпка в разбирането на резултатите на ГПТ-2 по отношение на дискурсната съгласуваност. Извършваме цялостно проучване на валидността на експлицитните дискурсни отношения в изходите на ГПТ-2 както при органично генериране, така и при фина настройка сценарии. Резултатите показват, че не винаги генерира текст, съдържащ валидни дискурсни отношения; въпреки това текстът му е по-съобразен с очакванията на хората в прецизния сценарий. Предлагаме отделна стратегия за смекчаване на тези проблеми и подчертаваме значението на изричното моделиране на дискурсната информация.', 'da': "De seneste fremskridt inden for NLP skyldes fremkomsten af omfattende præuddannede sprogmodeller. GPT-2 er især velegnet til generationsopgaver i betragtning af dens målsætning om sprogmodellering fra venstre til højre, men den sproglige kvalitet af dens genererede tekst er stort set stadig uudforsket. Vores arbejde tager et skridt i at forstå GPT-2's output i form af diskurskohærens. Vi udfører en omfattende undersøgelse af validiteten af eksplicitte diskursrelationer i GPT-2's output under både organisk generation og finjusterede scenarier. Resultaterne viser, at GPT-2 ikke altid genererer tekst, der indeholder gyldige diskursrelationer; Ikke desto mindre er teksten mere afstemt med menneskelige forventninger i det finjusterede scenario. Vi foreslår en afkoblet strategi for at afbøde disse problemer og fremhæve vigtigheden af eksplicit modellering af diskursinformation.", 'de': "Jüngste Fortschritte im NLP wurden auf das Aufkommen großangelegter vortrainierter Sprachmodelle zurückgeführt. GPT-2 eignet sich insbesondere für Generierungsaufgaben aufgrund seines Ziels der Sprachmodellierung von links nach rechts, die sprachliche Qualität des erzeugten Textes ist jedoch weitgehend unerforscht. Unsere Arbeit geht einen Schritt, um GPT-2's Outputs im Hinblick auf Diskurskohärenz zu verstehen. Wir führen eine umfassende Studie zur Validität expliziter Diskursbeziehungen in GPT-2 Outputs sowohl unter organischer Erzeugung als auch unter fein abgestimmten Szenarien durch. Die Ergebnisse zeigen, dass GPT-2 nicht immer Text generiert, der gültige Diskursbeziehungen enthält; Dennoch ist sein Text im fein abgestimmten Szenario stärker auf die menschlichen Erwartungen ausgerichtet. Wir schlagen eine entkoppelte Strategie vor, um diese Probleme zu mildern und die Bedeutung der expliziten Modellierung von Diskursinformationen hervorzuheben.", 'fa': 'پیشرفت های اخیر در NLP به اضطراری مدل های زبانی پیش آموزش فراوان تعلیم داده شده است. GPT-2، مخصوصاً برای وظیفه\u200cهای نسل به عنوان هدف مدل زبان چپ و راست، مناسب است، ولی کیفیت زبان\u200cشناسی متن تولید شده\u200cاش بسیار زیاد بی\u200cتوجه است. کارمون یه قدم برای فهمیدن نتایج GPT-2 در مورد هماهنگی صحبت می\u200cکند. ما یک مطالعه کامل در مورد قابلیت ارتباطات صحبت مشخصی در نتیجه\u200cهای GPT-2 تحت هر نسل و سناریو\u200cهای ساده\u200cای ارگانیک انجام می\u200cدهیم. نتیجه\u200cها نشان می\u200cدهند که GPT- 2 همیشه متن را تولید نمی\u200cکند که شامل رابطه\u200cهای صحبت معتبر است. با این حال، متن آن با انتظار انسان بیشتری در صحنه\u200cی مناسب است. ما یک استراتژی جدا شده را پیشنهاد می\u200cکنیم تا این مشکلات را کاهش دهیم و مهمترین اطلاعات گفتگو را مشخص کنیم.', 'id': 'Kemajuan baru-baru ini di NLP telah disebabkan oleh muncul model bahasa yang dilatih sebesar skala besar. GPT-2, secara khusus, cocok untuk tugas generasi karena tujuan model bahasa kiri-kanan, namun kualitas bahasa dari teks yang dihasilkannya kebanyakan tetap belum dikenalpasti. Pekerjaan kita mengambil langkah dalam memahami hasil GPT-2 dalam terma koherensi diskors. Kami melakukan penelitian komprensif tentang kehendak hubungan diskors eksplisit dalam hasil GPT-2 di bawah kedua generasi organik dan skenario yang disesuaikan. Hasil menunjukkan GPT-2 tidak selalu menghasilkan teks yang mengandung hubungan diskors yang valid; namun teksnya lebih sesuai dengan harapan manusia dalam skenario yang sesuai. Kami mengusulkan strategi terpisah untuk mengurangi masalah-masalah ini dan memperhatikan pentingnya untuk memmodelir secara eksplicit informasi diskors.', 'sw': 'Maendeleo ya hivi karibuni katika NLP yametokana na kuongezeka kwa mifano makubwa ya lugha zilizofunzwa kabla. GPT-2, hasa, inatumika kwa kazi za kizazi zinazopewa malengo yake ya kuonyesha lugha kushoto hadi kulia, lakini kiwango cha lugha cha kiingereza kimesababisha bila kuchanganyikiwa. Kazi yetu inachukua hatua ya kuelewa matokeo ya GPT-2 kwa sababu ya ushirikiano wa mazungumzo. Tunafanya utafiti wa kina kuhusu ukweli wa mahusiano ya mazungumzo ya wazi katika matokeo ya GPT-2 chini ya vizazi vya kiorganic na mazoea mazuri. Matokeo yanaonyesha GPT-2 haijatengeneza maandishi yenye mahusiano ya mazungumzo sahihi; Hata hivyo, ujumbe wake umetengenezwa zaidi na matumaini ya binadamu katika eneo lililotengenezwa vizuri. Tunazipendekeza mkakati wa kupunguza matatizo haya na kuonyesha umuhimu wa habari za mazungumzo ya wazi.', 'ko': 'NLP의 최신 진전은 대규모 예훈련 언어 모델의 출현 때문이다.GPT-2의 왼쪽에서 오른쪽까지의 언어 모델링 목표를 감안하면 특히 작업 생성에 적합하지만 텍스트 생성의 언어 질은 어느 정도 탐색이 필요하다.GPT-2가 문장의 일관성 방면의 출력을 이해하는 데 한 걸음 더 나아갔다.GPT-2 출력에서의 현성 언어 관계가 유기적 생성과 미세 조정 상황에서의 유효성에 대해 전면적으로 연구했다.결과에 따르면 GPT-2는 항상 유효한 문장 관계를 포함하는 텍스트를 생성하지 않는다.그럼에도 불구하고 그의 텍스트는 미세한 조정을 거친 장면에서 인류의 기대에 더욱 부합된다.우리는 이러한 문제들을 완화시키기 위해 결합 전략을 제시했고 현식 모델링 언어 정보의 중요성을 강조했다.', 'tr': "NLP'de ýakyndaky öňki gelişmeler uly ölçekli dil nusgalarynyň ýagdaýynda görkezildi. GPT Biziň işimiz GPT-2-iň netijesini çykarmak üçin bir adım çykýar. GPT-2'iň netijesinde we organik döwletlere we düzgün senaryýalaryň üstünde a çıklanan gürrüňler hakynda daňlap bir studiýa edýäris. Netijeler GPT-2 görkezilýän netijesi hemişe gadym diskurs baglaýyşlaryny barlamaýar. Yöne ýöne, onuň metini adamlaryň garaşylygy düzgün senaryda has gowy çykar. Biz bu meseleleri azaltmak üçin azalan strategiýany teklip edýäris we diskusiýa maglumatyny azaltmak üçin wajyplygyny ýagtylamak üçin guruldyrys.", 'af': "Onlangse avansies in NLP is geaktiveer aan die uitbreiding van groot- skaal voorafgeleerde taal modelle. GPT-2, in besonderhede, is geskik vir generasie-opdragte wat sy linker-na-regter taal modellering objek gegee het, maar die lingwisiese kwaliteit van sy genereerde teks het in groot manier onbekende bly. Ons werk neem 'n stap in verstaan van GPT-2 se uitvoerdes in terms of discourse coherence. Ons doen 'n komprehensiewe studie oor die geldigheid van eksplisiese diskursie relasies in GPT-2 se uitvoerdes onder beide organiese generasie en fin-tuned scenarios. @ info nogtans is sy teks meer gelyk met menslike verwagting in die fyn-gekonfigureer scenario. Ons voorstel 'n afkoppelde strategie om hierdie probleme te verminder en die belangrikheid van eksplisiese modeling van diskursie inligting te verlig.", 'sq': 'Përparimet e fundit në NLP janë atribuar shfaqjes së modeleve të gjuhës të stërvitura në shkallë të madhe. GPT-2, veçanërisht, është i përshtatshëm për detyrat e gjenerimit duke pasur parasysh objektivin e modelimit të gjuhës së tij të majtë në të djathtë, megjithatë cilësia gjuhësore e tekstit të gjeneruar të tij është mbetur kryesisht e pazgjidhur. Puna jonë merr një hap në kuptimin e rezultateve të GPT-2 në lidhje me koherencën e diskursit. Ne kryejmë një studim të përgjithshëm mbi vlerës in ë e marrëdhënieve të shprehura diskursore në rezultatet e GPT-2-s ë si sipas gjeneratës organike ashtu edhe sipas skenarëve të rregulluara. Rezultatet tregojnë se GPT-2 nuk gjeneron gjithmonë tekst që përmban marrëdhënie të vlefshme diskursore; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario.  Ne propozojmë një strategji të ndarë për të lehtësuar këto probleme dhe për të theksuar rëndësinë e modelimit eksplicit të informacionit diskursor.', 'bn': "এনএলপিতে সাম্প্রতিক অগ্রগতি বিশাল পরিমাপ পূর্ব প্রশিক্ষিত ভাষার মডেলের উৎপাদনের কারণে উল্লেখ করা হয়েছে। বিশেষ করে জিপিটি-২ প্রজন্মের জন্য প্রজন্মের কাজের জন্য সুযোগ রয়েছে যেখানে তার বাম থেকে ডান ভাষা মডেলিং উদ্দেশ্যের লক্ষ্য দিয়েছে, তবে  Our work takes a step in understanding GPT-2's outputs in terms of discourse coherence.  আমরা জিপিটি-২ এর প্রকাশ্য কথোপকথন সম্পর্কের বৈধতা সম্পর্ক সম্পর্কের বৈধতা সম্পর্কে একটি গুরুত্বপূর্ণ গবেষণা শুরু করি যা উভয় প্রজন্ম এবং ভা ফলাফল প্রদর্শন করা হয়েছে GPT-2 যার মধ্যে বৈধ কথোপকথন সম্পর্ক রয়েছে তা সবসময় তৈরি করে না। তবুও, তার লেখাটি ভালোভাবে মানুষের প্রত্যাশার সাথে আরো একত্রিত হয়েছে। আমরা এই সমস্যাগুলোকে কমিয়ে দেবার জন্য একটি প্রস্তাব প্রস্তাব করি এবং স্পষ্ট ভাবে মডেলিং তথ্যের গুরুত্ব উল্লেখ করি।", 'bs': 'Nedavni napredak u NLP prikazan je slučaju velikih predobučenih jezičkih modela. GPT-2, posebno, odgovara je za zadatke generacije s obzirom na svoj cilj modeliranja lijevog-desnog jezika, ali jezička kvalitet njegovog proizvedenog teksta u velikoj mjeri ostaje neobjašnjiva. Naš rad preduzima korak u razumijevanju rezultata GPT-2 u smislu konsekvencije diskursa. Izvodimo sveobuhvatljivo istraživanje o validnosti eksplicitih diskurskih odnosa u rezultatima GPT-2 pod organskim generacijama i ispravnim scenarijama. Rezultati pokazuju da GPT- 2 ne uvijek stvara tekst koji sadrži vrijedne odnose o diskusiji; Ipak, njegov tekst je više usklađen sa ljudskim očekivanjem u finom scenariju. Predlažemo rasključenu strategiju za smanjenje tih problema i naglašavanje važnosti pojasno modeliranja informacija o diskusijama.', 'am': 'በNLP ውስጥ የቀድሞው ቅድሚያ የቋንቋ ሞዴላዎችን ለመውጣት ነው፡፡ GPT-2 በተለየ ጊዜ ለትውልድ አድራጊዎች የግራ-to-ቀኝ ቋንቋ ምሳሌ አቃራቢ ነው፤ ነገር ግን የተፈጠረው ጽሑፉ የቋንቋዊ ጥሩ ብዛት ብዛት ያልተዘጋጀ ነው፡፡ የGPT-2 ውጤቶች በንግግር ብሔራዊ ግንኙነት ለማስተዋል ሥራችን አቅራቢያ ይወስዳል፡፡ በGPT-2 ውጤቶች ውስጥ ግንኙነት ግንኙነት አካባቢነት እና በኦጀርክ ትውልድ እና በጥሩ ስዕይት ውስጥ ያሉትን አካባቢ ትምህርት እናደርጋለን፡፡ ውጤቶች GPT-2 ሁልጊዜ እውነተኛ የንግግር ግንኙነት የሚያስፈልገውን ጽሑፍ አይፍጠርም፤ ነገር ግን ጽሑፉን በሰው ተስፋ በተለየ ጥያቄ ላይ የተለየ ነው፡፡ እነዚህን ጉዳዮች ለማሻሻል እና የንግግር መረጃዎችን ለመግለጥ ግልጽን እናሳውቃለን፡፡', 'hy': 'ՆԼՊ-ի վերջին զարգացումները պատասխանատու են մեծ մասշտաբով նախապատրաստված լեզվի մոդելների առաջացմանը: Հատկապես GPT-2-ը համապատասխանում է սերնդի առաջադրանքների համար, հաշվի առնելով իր ձախ դեպի աջ լեզվի մոդելավորման նպատակը, սակայն նրա ստեղծված տեքստի լեզվական որակը մեծ մասամբ մնացել է անուսումնասիրելի: Մեր աշխատանքը քայլ է անում GPT-2 արտադրանքների հասկանալու համար խոսակցության կոնցենցիայի առումով: Մենք կատարում ենք ընդհանուր ուսումնասիրություն GPT-2 արտադրությունների բացատրական խոսքի հարաբերությունների ճշմարտության մասին, ինչպես օրգանական սերունդների, ինչպես նաև բարձրացված սցենարների ընթացքում: Results show GPT-2 does not always generate text containing valid discourse relations;  այնուամենայնիվ, դրա տեքստը ավելի համապատասխան է մարդկային սպասելիքների հետ բարձրացված սցենարիայում: Մենք առաջարկում ենք բաժանված ռազմավարություն, որպեսզի նվազեցնենք այս խնդիրները և նշենք խոսակցական տեղեկատվության բացատրական մոդելավորման կարևորությունը:', 'az': "NLP'də son dəyişikliklər böyük ölçüdə öyrənmiş dil modellərinin yaradılışına qoyuldu. GPT-2, özlərinə də, sol-sağ dil modellik məqsədilinə verilən nəsil işləri üçün uyğunlaşdırılmışdır. Halbuki yaratdığı mətnin dillərin dili kaliteti çox yüksək dəyişiklik deyildir. Bizim işimiz GPT-2'nin sonuçlarını anlamaq üçün bir adım çəkir. Biz GPT-2 ilə müfəs s əl müzakirələrin müəyyən edilməsi barəsində müxtəlif bir təcrübə edirik. Növbətlər GPT-2 ilə müəyyən söhbət əlaqələri barəsində həmişə mətn yaratmaz. Ancaq, onun metini insan gözləməsindən daha çox çəkilir. Biz bu problemləri küçültmək və a çıq-aydın modelləşdirmək məlumatının münasibətini təklif edirik.", 'cs': 'Nedávné pokroky v NLP byly přičteny vzniku rozsáhlých předškolených jazykových modelů. Zejména GPT-2 je vhodný pro generační úlohy vzhledem k cíli modelování jazyka zleva doprava, přesto jazyková kvalita jeho generovaného textu zůstává do značné míry neprozkoumaná. Naše práce dělá krok k pochopení výstupů GPT-2 z hlediska koherence diskurzu. Provádíme komplexní studii o validitě explicitních diskurzních vztahů ve výstupech GPT-2 jak v organické generaci, tak v jemně laděných scénářích. Výsledky ukazují, že GPT-2 ne vždy generuje text obsahující platné diskurzní vztahy; Nicméně, její text je více sladěn s lidskými očekáváními v jemně laděném scénáři. Navrhujeme oddělenou strategii pro zmírnění těchto problémů a zdůrazňujeme důležitost explicitního modelování diskurzních informací.', 'ca': "Els avanços recents en NLP s'han atribuit a l'aparició de models de llenguatge a gran escala pré-entrenats. GPT-2, en particular, està adaptat a tasques de generació tenint en compte el seu objectiu de modelació de llenguatge d'esquerra a dreta, però la qualitat lingüística del seu text generat no ha estat explorada. La nostra feina fa un pas en entendre els resultats del GPT-2 en termes de coherencia del discurs. Fem un estudi complet sobre la validez de les relacions de discurs explícites en els productes del GPT-2, tant en la generació orgànica com en escenaris fins ajustats. Els resultats mostran que el GPT-2 no sempre genera text que conté relacions de discurs válides; tot i així, el seu text està més allinjat a les expectatives humanes en un escenari ben ajustat. Proposem una estratègia descoplada per atenuar aquests problemes i destacar l'importància de modelar explícitament la informació del discurs.", 'et': 'Hiljutised edusammud uue õppekava valdkonnas on omistatud ulatuslike eelõppe keelemudelite tekkele. GPT-2 sobib eelkõige generatsioonitöödeks, arvestades oma vasakult paremale keele modelleerimise eesmärki, kuid selle loodud teksti keeleline kvaliteet on suures osas uurimata. Meie töö astub sammu GPT-2 väljundite mõistmisel diskursuse sidususe osas. Teostame põhjaliku uuringu selgesõnaliste diskursussuhete kehtivuse kohta GPT-2 väljundites nii orgaanilise generatsiooni kui ka täpsustatud stsenaariumide puhul. Tulemused näitavad, et GPT-2 ei genereeri alati teksti, mis sisaldab kehtivaid diskursussuhteid; Siiski on selle tekst paremini kooskõlas inimlike ootustega täpsustatud stsenaariumis. Pakume välja sidumata strateegia nende probleemide leevendamiseks ja rõhutame diskursusteabe selgesõnalise modelleerimise tähtsust.', 'fi': 'NLP:n viimeaikaisen kehityksen on katsottu johtuvan laajojen esikoulutettujen kielimallien syntymisestä. Erityisesti GPT-2 soveltuu sukupolvitehtäviin vasemmalta oikealle -kielimallinnustavoitteensa vuoksi, mutta sen tuottaman tekstin kielellistä laatua ei ole juurikaan tutkittu. Työssämme otetaan askel GPT-2:n tulosten ymmärtämisessä diskurssin johdonmukaisuuden kannalta. Suoritamme kattavan tutkimuksen eksplisiittisten diskurssisuhteiden pätevyydestä GPT-2:n tuotoksissa sekä orgaanisen sukupolven että hienoviritetyn skenaarion puitteissa. Tulokset osoittavat, että GPT-2 ei aina luo tekstiä, joka sisältää päteviä diskurssisuhteita. Kuitenkin sen teksti vastaa paremmin ihmisten odotuksia hienoviritetyssä skenaariossa. Ehdotamme irrotettua strategiaa näiden ongelmien lieventämiseksi ja korostamme diskurssitiedon nimenomaisen mallintamisen merkitystä.', 'sk': 'Nedavni napredek pri novem delovnem programu je bil pripisan pojavu obsežnih predhodno usposobljenih jezikovnih modelov. Zlasti GPT-2 je primeren za generacijske naloge glede na svoj cilj modeliranja jezikov od leve proti desni, vendar jezikovna kakovost ustvarjenega besedila v veliki meri ostaja neraziskana. Naše delo naredi korak v razumevanju rezultatov GPT-2 v smislu diskurzne koherence. Izvedli bomo celovito študijo veljavnosti eksplicitnih diskurznih relacij v rezultatih GPT-2 v okviru organske generacije in natančno nastavljenih scenarijev. Rezultati kažejo, da GPT-2 ne ustvarja vedno besedila z veljavnimi diskurznimi relacijami; kljub temu je njegovo besedilo bolj usklajeno s človeškimi pričakovanji v finem scenariju. Predlagamo nevezano strategijo za ublažitev teh problemov in poudarjamo pomen eksplicitnega modeliranja diskurznih informacij.', 'he': 'התקדמות האחרונות ב-NLP הואשמות להופעה של דוגמנים לשפה מאומנים מראש במידה גדולה. GPT-2, במיוחד, מתאים למשימות הדור בהתחשב באובייקטיבי הדוגמניות השפה שמאל לימין שלה, אך איכות השפה של הטקסט המיוצר שלה נשארה בעיקר בלתי חוקרת. העבודה שלנו לוקחת צעד להבין את התוצאות של GPT-2 במונחים של תואם דיבורים. אנחנו מבצעים מחקר מורכב על האישיות של יחסי דיבור ברור בתוצאות של GPT-2 תחת גם דור אורגני וגם תרחישים מתאימים. התוצאות מראות שGPT- 2 לא תמיד יוצר טקסט שמכיל יחסי דיבור תקיים; NAME OF TRANSLATORS למרות זאת, הטקסט שלו מתאים יותר לצפייה אנושית בתרחיש המתאים. אנו מציעים אסטרטגיה נפרדת כדי להקל על הבעיות הללו ולדגיש את חשיבות הדוגמנים באופן ברור מידע דיבור.', 'ha': "@ info: whatsthis @ item license Kayyakanmu na karɓi wani takwara ga fahimtar GPT-2 da ke cikin mazaɓa. Tuna karatun da jumla'a a kan masu gaskiya na mazaɓa da mazaɓa cikin GPT-2's outputs a ƙarƙashin danni na organic da mai kyau. Matunan ya nuna GPT-2 bã zai iya ƙiƙiro matsayi wanda yana da danna mazaɓa mai inganci ba; A lokacin da, ma'anarsa na sami da tsammãni ga mutane da ke cikin wani mai kyau. Tuna goyya da wani takwai da ba'a saurari masu haske wa masu husũma na zane-zane da zane-zane-zane-zane.", 'jv': 'text-editor-action Name Awakdhéwé nglanggar kuwi basa kanggo ngerasakno nggawe barang-barang nggawe barang nggawe barang. Awak dhéwé éntuk akeh perusahaan akeh luwih dumadhi kanggo ngerasah barang langgar barang nggawe barang nggawe barang-barang nggawe barang dhéwé, nganggo perusahaan winih sing berarti lan alam sing berarti. echoH e l l o space w o r l d periodHelloworldHello worldkey echo Nanging kabeh, seneng langgambar luwih sedhaya punika sing gagasar ambe kapan uwong. Awak dhéwé ngéwangi tégatané sing nggawe ngéwangi perbudhakan iki lan ngéwangi nggawe barang nggawe informasi layang-layang kanggo nyelarakno.', 'bo': 'NLP ནང་གི་འཕེལ་རྒྱས་ཁབ་དེ་ལ་ཆེ་བའི་སྔོན་བསྒྲིག་གི་སྐད་རིགས་དཔེ་དབྱིབས་ཆེན་དང་མཐུན་རྐྱེན་ཡོད། GPT-2 འདི་ཁྱད་དུ་འཕགས་པ་ཞིག་ནི་མི་རབས་པའི་བྱ་འགུལ་དངོས་ཡིག་གཟུགས་རིས་གཅིག་གམ། ང་ཚོའི་ལས་ཀ་ལ་རྒྱབ་སྐྱོར་མིའི་གནད་སྡུད་གཉིས་ཀྱི་རྗེས་འབྲས་འདི་རྟོགས་པའི་གྲངས་ཀ་གཅིག་རེད། ང་ཚོས་GPT-2་ནང་གི་གནད་དོན་དག་ཕྱོགས་སྡུད་མིན་པའི་རྣམ་པ་དང་རང་ཉིད་ཀྱི་མི་རྣམས་ལས་བརྟན་དཔྱད་ཞིག་ཡོད། གྲུབ་འབྲས་འབྲས་པ་དེ་GPT-2་མངོན་འཆར་ཡོད་མི་རྟག་པར་ཕན་འབྲས་ཀྱི་སྐྱེལ་འབྲེལ་བ་ཡོད་པའི་ཡིག་གེ་ ཡིན་ནའང་། མི་ཚོའི་ཡིག་གེ་ཉིད་རྟོགས་ཀྱི་སྣང་ཚུལ་ལས་ཆེ་རུ་གཏོང་བ། ང་ཚོས་དཀའ་ངལ་འདི་ཚོ་ཆུང་བ་དང་གསལ་བཤད་དབྱིབས་གཏོང་བའི་ཐབས་ལམ་ཞིག་གནང་བ་རེད།'}
{'en': 'The CACAPO Dataset : A Multilingual, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation', 'ar': 'مجموعة بيانات CACAPO: مجموعة بيانات متعددة اللغات ومتعددة المجالات لخط أنابيب عصبي وإنشاء بيانات من طرف إلى طرف', 'es': 'El conjunto de datos CACAPO: un conjunto de datos multilingüe y multidominio para la generación integral de datos a texto y canalización neuronal', 'pt': 'O conjunto de dados CACAPO: um conjunto de dados multilíngue e de vários domínios para pipeline neural e geração de dados para texto de ponta a ponta', 'fr': 'Le jeu de données CACAPO\xa0: un jeu de données multilingue et multidomaine pour le pipeline neuronal et la génération de données en texte de bout en bout', 'ja': 'CACAPOデータセット：ニューラルパイプラインとエンドツーエンドのデータからテキストへの生成のための多言語、マルチドメインのデータセット', 'ru': 'Набор данных CACAPO: многоязычный, многодоменный набор данных для генерации нейронных каналов и сквозных данных в тексте', 'zh': 'CACAPO 数集:用神经管道及端至端数至文本多语言多域数集', 'hi': 'CACAPO डेटासेट: तंत्रिका पाइपलाइन और एंड-टू-एंड डेटा-टू-टेक्स्ट जनरेशन के लिए एक बहुभाषी, बहु-डोमेन डेटासेट', 'ga': 'Tacar Sonraí CACAPO: Tacar Sonraí Ilteangach, Ilfhearainn le haghaidh Píblíne Néarach agus Giniúint Sonraí go Téacs ó Dhéanamh', 'hu': 'A CACAPO adatkészlet: egy többnyelvű, több tartományból álló adatkészlet a neurális csővezetékek és a végpontok közötti adat-szöveg generálásához', 'el': 'Το σύνολο δεδομένων Ένα πολύγλωσσο σύνολο δεδομένων πολλαπλών τομέων για τη δημιουργία νευρωνικών αγωγών και End-to-End δεδομένων σε κείμενο', 'it': 'Il set di dati CACAPO: un set di dati multilingue e multi-dominio per la generazione di pipeline neurali e di dati end-to-end', 'kk': 'CACAPO деректер қоры: Нейрондық пипелин және соңғы деректерді мәтіннен жасау үшін көптілік, көпDomain деректер қоры', 'mk': 'Датотеката на CACAPO: Мултијазичен, мултидомен датотек за генерација на неврални цевки и од крај до крај на податоци до текст', 'lt': 'CACAPO duomenų rinkinys: Daugiakalbis, daugiadominis duomenų rinkinys, skirtas neurologiniams vamzdynams ir duomenų generacijai nuo galo iki galo', 'ms': 'Dataset CACAPO: Dataset berbilang bahasa, berbilang-domain untuk Pipeline Neural dan Jenerasi Data-ke-Teks Akhir-ke-Akhir', 'mt': 'Is-Sett ta’ Dejta CACAPO: Sett ta’ Dejta Multilingwi, Multi-Domeniċi għal Pipeline Newrali u Ġenerazzjoni ta’ Dejta sa Test minn Tmiem sa Tmiem', 'ml': 'CACAPO ഡേറ്റാസെറ്റ്: നെയുറല്\u200d പൈപ്പെലൈനിന്നും അവസാന വിവരങ്ങളില്\u200d നിന്നും അവസാനിക്കുന്ന പദാവലിയുടെ സൃഷ്ടിക്കുവേണ്ടി ഒരു പല', 'mn': 'CACAPO өгөгдлийн сан: Мөн хэл, олон домены мэдээллийн мэдээллийн багц, мэдээллийн төгсгөл-төгсгөл өгөгдлийн төгсгөл-төгсгөл', 'pl': 'Zestaw danych CACAPO: wielojęzyczny, wieloodzienny zestaw danych dla rurociągu nerwowego i generowania całościowego danych do tekstu', 'ka': 'CACAPO მონაცემები: მრავალენგური, მრავალენგური მონაცემები ნეიროლური პიპელინის და ბოლოდან დასრულებული მონაცემების ტექსტის შექმნა', 'ro': 'Setul de date CACAPO: un set de date multilingv, multi-domeniu pentru generarea de conducte neurale și de date end-to-end', 'no': 'CACAPO- databasen: Eit fleirspråk, fleirdomenedatabaser for generering av data til tekst', 'sr': 'CACAPO podaci: Multilingual, Multi Domain Dataset za Neural Pipeline i End- to- End Data- to- Text Generacija', 'si': 'CACAPO දත්ත සැකසුම: ගොඩක් භාෂාවක්, ගොඩක් ඩොමේන් දත්ත සැකසුම් නිර්මාණ පිප්ලින් සහ අවසාන දත්ත සැකසුම් සඳහා', 'so': 'The CACAPO Dataset: A Multilingua, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation', 'sv': 'CACAPO Dataset: En flerspråkig, flerdomänsdata för neural pipeline och end-to-end data-to-text generering', 'ta': 'CACAPO தகவல் அமைப்பு', 'ur': 'CACAPO ڈاٹیسٹ: نئورل پیپیپیلین اور پایان سے پایان Data- to- Text Generation کے لئے ایک بہت سی زبان، بہت سی- ڈومین ڈاٹیسٹ', 'uz': 'Name', 'vi': 'Bảng dữ liệu CACACACAO: Bộ dữ liệu đa ngôn ngữ, đa miền cho dây thần kinh ống và kết thúc Thế hệ dữ liệu tới văn bản', 'bg': 'Многоезичен, многодомейнен набор от данни за неврални тръбопроводи и генериране от данни до текст от край до край', 'da': 'CACAPO datasættet: Et flersproget datasæt med flere domæner til neural pipeline og end-to-end data-to-tekst generering', 'nl': 'De CACAPO Dataset: Een meertalige, meerdomeinige dataset voor neuronale pijpleidingen en end-to-end data-to-text generatie', 'hr': 'CACAPO podaci: multijezička, multidomena podaci za neuronsku govedinu i krajnju generaciju podataka do teksta', 'de': 'CACAPO Dataset: Ein mehrsprachiger, mehrdom瓣nen羹bergreifender Datensatz f羹r neuronale Pipeline und End-to-End Data-to-Text Generierung', 'id': 'Dataset CACAPO: Dataset Multibahasa, Multi-Domain untuk Pipeline Neural dan Generasi Data-ke-Teks Akhir-ke-Akhir', 'fa': 'پایگاه داده\u200cهای CACAPO: یک داده\u200cهای زیادی زبان، زیادی دامنی برای نسخه داده\u200cهای عصبی و پایان- تا پایان- به متن', 'sw': 'Taarifa za CACAPO: Zana ya lugha nyingi, Taarifa nyingi za Domain kwa ajili ya Pipeline za Neural na Uzalishaji wa Data-to-End-to-Text', 'tr': 'CACAPO Veri: Nöral Pipeline ve End-to-End Veri-to-Text Generation için Çok Dilli, Çok Domain Veri', 'af': 'Name', 'am': 'The CACAPO Dataset: A Multilingual, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation', 'sq': 'Dataseti CACAPO: Një Dataset Multilingual, Multi-Domain për Pipeline Neural dhe Gjenerimin e të dhënave nga fundi në fund', 'az': 'CACAPO veril톛nl톛ri: N칬ral Pipelin v톛 End-to-End Data-to-Text Generation 칲칞칲n 칞oxlu dilli, 칞oxlu Domain veril톛nl톛ri', 'bn': 'CACAPO ডাটাসেট: নিউরাল পাইপেলাইন এবং শেষ- থেকে তথ্যের প্রজন্মের জন্য একটি বহুভাষা, বহুভাষী ডোমেইন ডাটাসেট', 'ko': 'CACAPO 데이터 세트: 신경관과 끝에서 끝까지 데이터를 텍스트로 생성하는 다중 언어, 다중 도메인 데이터 세트', 'ca': 'El conjunt de dades CACAPO: Un conjunt de dades multillengües i multidominios per a la generació de tubs neuronals i de dades fins al final', 'cs': 'Dataset CACAPO: Vícejazyčná, vícedoménová datová sada pro neuronové potrubí a End-to-End generování dat-Text', 'et': 'CACAPO andmekogum: mitmekeelne mitmedomeeniline andmekogum neurotorustiku ja lõpp-lõpuni andmete genereerimiseks', 'fi': 'CACAPO Dataset: monikielinen, monikielinen tietosarja hermoputkilinjan ja pﾃ､ﾃ､stﾃ､ pﾃ､ﾃ､hﾃ､n datasta tekstiin generointiin', 'hy': 'CACAPO տվյալների համակարգը. Նյարդային խողովակների բազմալեզու, բազմաբևեռ տվյալների համակարգ և վերջ-վերջ տվյալների տեքստի ստեղծման համար', 'bs': 'CACAPO podaci: Multilingual, Multi Domain Dataset za Neural Pipeline i End- to- End Data- to- Text Generacija', 'jv': 'The CaCaCapo dataasset: A Multilanguage, Multi-domain dataase for Neral Pipeine and End-to-End data-to-Text Generation', 'sk': 'Zbirka podatkov CACAPO: večjezični, večdomenski nabor podatkov za živčni cevovod in generacijo podatkov od konca do konca v besedilo', 'ha': 'KCharselect unicode block name', 'he': 'קבוצת נתונים CACAPO: קבוצת נתונים רבות שפות רבות בתחום עבור צינור נוירולי וגידול נתונים מסוף לסוף לטקסט', 'bo': 'CACAPO Dataset: A Multilingual, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation'}
{'en': 'This paper describes the CACAPO dataset, built for training both neural pipeline and end-to-end data-to-text language generation systems. The dataset is multilingual (Dutch and English), and contains almost 10,000 sentences from human-written news texts in the sports, weather, stocks, and incidents domain, together with aligned attribute-value paired data. The dataset is unique in that the linguistic variation and indirect ways of expressing data in these texts reflect the challenges of real world NLG tasks.', 'ar': 'تصف هذه الورقة مجموعة بيانات CACAPO ، المصممة لتدريب كل من خطوط الأنابيب العصبية وأنظمة توليد لغة البيانات من طرف إلى طرف. مجموعة البيانات متعددة اللغات (الهولندية والإنجليزية) ، وتحتوي على ما يقرب من 10000 جملة من نصوص إخبارية كتبها الإنسان في مجال الرياضة والطقس والأسهم والحوادث ، جنبًا إلى جنب مع البيانات المقترنة ذات السمة والقيمة المتوافقة. تعتبر مجموعة البيانات فريدة من نوعها من حيث أن التباين اللغوي والطرق غير المباشرة للتعبير عن البيانات في هذه النصوص تعكس تحديات مهام NLG في العالم الحقيقي.', 'es': 'Este documento describe el conjunto de datos CACAPO, creado para el entrenamiento de sistemas de generación de lenguaje de datos a texto y canales neuronales de principio a fin. El conjunto de datos es multilingüe (holandés e inglés) y contiene casi 10 000 frases de textos noticiosos escritos por humanos en el dominio de deportes, clima, acciones e incidentes, junto con datos emparejados de atributo-valor alineados. El conjunto de datos es único en el sentido de que la variación lingüística y las formas indirectas de expresar datos en estos textos reflejan los desafíos de las tareas de NLG del mundo real.', 'pt': 'Este artigo descreve o conjunto de dados CACAPO, construído para treinar tanto o pipeline neural quanto os sistemas de geração de linguagem de dados para texto de ponta a ponta. O conjunto de dados é multilíngue (holandês e inglês) e contém quase 10.000 frases de textos de notícias escritos por humanos nos domínios de esportes, clima, ações e incidentes, juntamente com dados emparelhados de valor de atributo alinhados. O conjunto de dados é único, pois a variação linguística e as formas indiretas de expressar dados nesses textos refletem os desafios das tarefas de NLG do mundo real.', 'fr': "Cet article décrit le jeu de données CACAPO, conçu pour entraîner à la fois le pipeline neuronal et les systèmes de génération de langage de données en texte de bout en bout. Le jeu de données est multilingue (néerlandais et anglais) et contient près de 10 000 phrases tirées de textes d'actualités écrits par des humains dans le domaine des sports, de la météo, de la bourse et des incidents, ainsi que des données appariées attribut-valeur alignées. L'ensemble de données est unique en ce sens que la variation linguistique et les manières indirectes d'exprimer les données dans ces textes reflètent les défis des tâches du GNL dans le monde réel.", 'ja': '本稿では、ニューラルパイプラインとエンドツーエンドのデータツーテキスト言語生成システムの両方を訓練するために構築されたCACAPOデータセットについて説明する。データセットは多言語（オランダ語と英語）で、スポーツ、天候、株式、インシデントドメインの人間が書いたニューステキストからのほぼ10,000の文章と、整列された属性値ペアデータが含まれています。このデータセットは、言語的バリエーションとこれらのテキストでデータを表現する間接的な方法が、現実世界のNLGタスクの課題を反映しているという点でユニークです。', 'hi': 'यह पेपर CACAPO डेटासेट का वर्णन करता है, जो तंत्रिका पाइपलाइन और एंड-टू-एंड डेटा-टू-टेक्स्ट लैंग्वेज जनरेशन सिस्टम दोनों के प्रशिक्षण के लिए बनाया गया है। डेटासेट बहुभाषी (डच और अंग्रेजी) है, और इसमें खेल, मौसम, स्टॉक और घटनाओं डोमेन में मानव-लिखित समाचार ग्रंथों से लगभग 10,000 वाक्य शामिल हैं, साथ ही साथ संरेखित विशेषता-मूल्य युग्मित डेटा के साथ। डेटासेट इस बात में अद्वितीय है कि इन ग्रंथों में डेटा व्यक्त करने के भाषाई भिन्नता और अप्रत्यक्ष तरीके वास्तविक दुनिया के एनएलजी कार्यों की चुनौतियों को दर्शाते हैं।', 'zh': '本文述CACAPO数集,该数专为训练神经管道与端到端数据到文本语言生成系统而构。 其数集是多言之(荷兰语英语),含自体育、天、股票、事域中人物所编新闻文本近 10,000 一句,及齐性-配对数。 集之所独在,言异间接世NLG也。', 'ru': 'В этой статье описывается набор данных CACAPO, построенный для обучения как нейронных конвейеров, так и сквозных систем генерации данных в текстовый язык. Набор данных является многоязычным (голландский и английский языки) и содержит почти 10 000 предложений из написанных человеком текстов новостей в области спорта, погоды, запасов и инцидентов, а также согласованные данные парного значения атрибута. Набор данных уникален тем, что лингвистические вариации и косвенные способы выражения данных в этих текстах отражают вызовы реальных задач NLG.', 'ga': 'Déanann an páipéar seo cur síos ar thacar sonraí CACAPO, a tógadh chun oiliúint a chur ar phíblíne néaracha agus ar chórais giniúna teanga sonraí go téacs ó cheann ceann go ceann. Tá an tacar sonraí ilteangach (Ollainnis agus Béarla), agus cuimsíonn sé beagnach 10,000 abairt ó théacsanna nuachta scríofa ag an duine san fhearann spóirt, aimsire, stoic agus teagmhais, mar aon le sonraí péireáilte luach tréithe ailínithe. Tá an tacar sonraí uathúil sa mhéid is go léiríonn an éagsúlacht teanga agus na bealaí indíreacha chun sonraí a chur in iúl sna téacsanna seo na dúshláin a bhaineann le tascanna fíordhomhanda NLG.', 'hu': 'Ez a tanulmány bemutatja a CACAPO adatkészletet, amelyet mind neurális pipeline, mind pedig végpontos adat-szöveg nyelvgeneráló rendszerek képzésére építettek. Az adatkészlet többnyelvű (holland és angol) és közel 10 000 mondatot tartalmaz emberi írású hírszövegekből a sport, időjárás, részvények és incidensek területén, valamint összehangolt attribútum-érték párosított adatokkal. Az adatkészlet egyedülálló abban, hogy a nyelvi variációk és az adatok közvetett kifejezési módjai ezekben a szövegekben tükrözik a valós NLG feladatok kihívásait.', 'el': 'Αυτή η εργασία περιγράφει το σύνολο δεδομένων που κατασκευάστηκε για την εκπαίδευση τόσο των νευρωνικών αγωγών όσο και των ολοκληρωμένων συστημάτων δημιουργίας γλωσσών δεδομένων σε κείμενο. Το σύνολο δεδομένων είναι πολύγλωσσο (ολλανδικά και αγγλικά) και περιέχει σχεδόν 10.000 προτάσεις από κείμενα ειδήσεων γραμμένα από ανθρώπους στον τομέα του αθλητισμού, του καιρού, των μετοχών και των συμβάντων, μαζί με ευθυγραμμισμένα δεδομένα αντιστοίχισης χαρακτηριστικών-τιμής. Το σύνολο δεδομένων είναι μοναδικό στο ότι οι γλωσσικές παραλλαγές και οι έμμεσοι τρόποι έκφρασης δεδομένων σε αυτά τα κείμενα αντικατοπτρίζουν τις προκλήσεις των εργασιών του πραγματικού κόσμου.', 'ka': 'ამ დოკუნტის შესახებ CACAPO მონაცემების საზოგადომა, რომელიც შექმნა ნეიროლური ფეხლინი და დასრულებული მონაცემების ტექსტის მუშაობის სისტემი. მონაცემების კონფიგურაცია მრავალენგური (ჰოლდენური და ინგლისური) და მხოლოდ 10 000 მონაცემები ადამიანის წერილი ატრიქტური ტექსტიდან პორტის, დონტაციის, სახის და ინტერესტის დემომინში, და მონაცემების კონფიგურაცია უნიკალურია, რომ ლენგურისტიკური განცემები და უკეთესტური გზები ამ ტექსტში მონაცემების გამოსახულება რეალური მსოფლიოს NLG დავალების გან', 'it': "Questo articolo descrive il dataset CACAPO, costruito per la formazione sia di pipeline neurali che di sistemi end-to-end di generazione di linguaggi dati-testo. Il set di dati è multilingue (olandese e inglese) e contiene quasi 10.000 frasi da testi di notizie scritti dall'uomo nel campo dello sport, del tempo, delle azioni e degli incidenti, insieme a dati accoppiati attributo-valore allineati. Il set di dati è unico in quanto la variazione linguistica e i modi indiretti di esprimere i dati in questi testi riflettono le sfide dei compiti NLG del mondo reale.", 'lt': 'Šiame dokumente aprašomas CACAPO duomenų rinkinys, sukurtas mokymui ir nervinių vamzdynų, ir nuo pabaigos prie pabaigos duomenų iš kalbos į tekstą kūrimo sistemoms. The dataset is multilingual (Dutch and English), and contains almost 10,000 sentences from human-written news texts in the sports, weather, stocks, and incidents domain, together with aligned attribute-value paired data.  Duomenų rinkinys yra unikalus, nes kalbiniai skirtumai ir netiesioginiai šių tekstų duomenų išraiškos atspindi realaus pasaulio NLG uždavinių iššūkius.', 'mk': 'Оваа хартија ја опишува датотеката на CACAPO, изградена за обука на неуралниот гасовод и системите на генерација на податоци од крај до крај на јазик. Податоците се мултијазични (холандски и англиски) и содржат скоро 10.000 реченици од човековите вести во спортскиот, временскиот, акционскиот и инцидентскиот домен, заедно со податоци од парирана вредност на атрибутите. Податоците се уникатни во тоа што јазичката варијација и индиректните начини на изразување на податоците во овие тексти ги одразуваат предизвиците на реалните задачи на НЛГ.', 'kk': 'Бұл қағаз келтірілген CACAPO деректер жинағын, невралдық конец және соңғы деректерді мәтін тілдерді құру жүйелері үшін құрылған. Деректер жиыны бірнеше тілдік (голландша және ағылшын тілінде) және адамдардың жазылған жаңалық мәтіндерінен 10 000 сөз бар. Спорт, уақыт, сақтау және оқиғалар доменінде бірге тең атрибут мәнінен бірге қосы Деректер жинағы бірнеше емес дегенде, лингвистикалық өзгерістер және бұл мәтіндерде деректерді көрсету тәртіпсіздігін көрсетеді.', 'ms': 'Kertas ini menggambarkan set data CACAPO, dibina untuk melatih kedua-dua paip saraf dan sistem generasi bahasa data-ke-teks hujung-hujung. Set data berbilang bahasa (Belanda dan Inggeris), dan mengandungi hampir 10,000 kalimat dari teks berita ditulis oleh manusia dalam domain sukan, cuaca, stok, dan insiden, bersama dengan data pasangan nilai-atribut sepadan. Set data adalah unik dalam bahawa variasi bahasa dan cara langsung untuk mengekspresikan data dalam teks ini mencerminkan cabaran tugas NLG dunia nyata.', 'ml': 'This paper describes the CACAPO dataset, built for training both neural pipeline and end-to-end data-to-text language generation systems.  ഡാറ്റാസെറ്റ് പല ഭാഷ (ഡച്ചിലും ഇംഗ്ലീഷിലും) മാത്രം വാര്\u200dത്തകളുടെ വാക്കുകളില്\u200d നിന്നും മനുഷ്യര്\u200d എഴുതിയ വാര്\u200dത്തകാര്\u200dത്തകളില്\u200d നിന്നും പതിനായ ഈ ടെക്സ്റ്റുകളില്\u200d വിവരങ്ങള്\u200d പ്രസ്താവിപ്പിക്കുന്നതിന്റെ ഭാഷ വ്യത്യാസവും നേരിട്ടുള്ള വിവരങ്ങളും ഈ ലോകത്തിലെ വിവരങ്ങളുട', 'mn': 'Энэ цаас CACAPO өгөгдлийн санг тайлбарладаг, мэдрэлийн хоолойн шугам болон төгсгөлд нь өгөгдлийн хэл болон текст хэлний бүтээлтийн системүүд болон сургалтын тулд бүтээсэн. Мэдээллийн сангууд нь олон хэл (Далланд, Англи хэлний хэлний хэлний хэлний хэлний хэлний хэлний хэлний хэлний хэлбэр) юм. Хүн төрөлхтний бичсэн мэдээллийн текстүүдийн бараг 10,000 өгүүлбэрүүдийг спорт, цаг агаар, хугацаа, газры Өгөгдлийн суурь нь хэлний өөрчлөлт болон буруу арга баримт өгөгдлийг илэрхийлж байгаа нь үнэндээ дэлхийн НЛГ даалгаварын сорилтуудыг харуулдаг.', 'pl': 'Niniejszy artykuł opisuje zestaw danych CACAPO, zbudowany do szkolenia zarówno rurociągu neuronowego, jak i kompleksowych systemów generowania języków danych-tekstowych. Zestaw danych jest wielojęzyczny (holenderski i angielski) i zawiera prawie 10.000 zdań z tekstów wiadomości napisanych przez człowieka w dziedzinie sportu, pogody, akcji i incydentów, wraz z wyrównanymi danymi parowanymi atrybuty-wartość. Zestaw danych jest unikalny w tym kontekście, że zróżnicowanie językowe i pośrednie sposoby wyrażania danych w tych tekstach odzwierciedlają wyzwania związane z realnymi zadaniami NLG.', 'mt': 'Dan id-dokument jiddeskrivi s-sett tad-dejta CACAPO, mibni għat-taħriġ kemm ta’ pajpijiet newrali kif ukoll ta’ sistemi ta’ ġenerazzjoni ta’ dejta mit-tmiem għat-test. Is-sett tad-dejta huwa multilingwi (bl-Olandiż u bl-Ingliż), u fih kważi 10,000 sentenza minn testi tal-aħbarijiet miktuba mill-bniedem fid-dominju tal-isport, it-temp, l-istokkijiet, u l-in ċidenti, flimkien ma’ dejta allinjata bil-valur tal-attribut. Is-sett tad-dejta huwa uniku peress li l-varjazzjoni lingwistika u l-modi indiretti ta’ espressjoni tad-dejta f’dawn it-testi jirriflettu l-isfidi tal-kompiti tal-NLG fid-dinja reali.', 'ro': 'Această lucrare descrie setul de date CACAPO, construit pentru instruirea atât a conductelor neurale, cât și a sistemelor end-to-end de generare a limbajului de date-la-text. Setul de date este multilingv (olandeză și engleză) și conține aproape 10.000 de propoziții din texte de știri scrise de om în domeniul sportului, vremii, stocurilor și incidentelor, împreună cu date asociate atribute-valoare aliniate. Setul de date este unic prin faptul că variația lingvistică și modalitățile indirecte de exprimare a datelor în aceste texte reflectă provocările sarcinilor din lumea reală NLG.', 'no': 'Denne papiret beskriver CACAPO- datasettet, bygd for å trenga både neuralrøypipelinje og sluttspråkssystemet for data- til- tekst. Datasettet er fleirspråk (nederlandsk og engelsk), og inneheld nesten 10.000 setningar frå menneskelig skriven nyhetstekst i domenet for sport, vêr, stokker og hendingar, saman med tilsvarande attributtverdiar par data. Datasettet er unikt i at den lingviske variasjonen og indirekte måten å uttrykke data i desse tekstane reflekterer utfordringane av verkeleg NLG-oppgåver.', 'si': 'මේ පත්තුව CACAPO දත්ත සැට විස්තර කරනවා, න්\u200dයුරල් පායිප්ලින් සහ අන්තිම දත්ත සඳහා පත්තු භාෂාව පද්ධතිය සිද්ධ The data set is Multilanguage (Dutch and English), and holds close to 10,000 Words from the Human-write news texts in the sports, weather, stocks, and cases domain, with Alied Attribe-Price Paid data. දත්ත සෙට් එක විශේෂයි, භාෂාවික වෙනස් සහ නිර්දේශ ප්\u200dරවේශයෙන් දත්ත ප්\u200dරවේශනය කරන්නේ මේ පාළුවන් ඇත්ත ලෝකයේ NLG', 'so': 'Warqaddan waxaa ku qoran sawirada macluumaadka ee CACAPO, oo loo dhisay waxbarashada qoraalka neurada iyo dhammaadka danbiyada luuqada ee qoraalka. Taariikhda macluumaadku waa luuqado kala duduwan (Holand and Ingiriis), waxaa ku jira 10,000 oo imtixaan ah oo laga qoray qoraalka warqadaha dadka oo qoran jimicsiga, cimilada, sokooyinka iyo dhacdooyinka, waxaana ku jira macluumaad isku qoran qiimaha qiimaha ah. Taariikhda macluumaadku waa mid u gaar ah in bedelka luqada iyo qaababka si toos ah looga muujiyo macluumaadka qoraaladan ay ka muuqato dhibaatooyinka shaqada ee runta ah ee NLG.', 'sv': 'Denna uppsats beskriver CACAPO-datauppsättningen, byggd för utbildning av både neurala pipeline och end-to-end data-to-text språkgenereringssystem. Datauppsättningen är flerspråkig (nederländska och engelska) och innehåller nästan 10 000 meningar från människoskrivna nyhetstexter inom sport, väder, aktier och incidenter domänen, tillsammans med anpassade attribut-värde parade data. Datauppsättningen är unik genom att den språkliga variationen och indirekta sättet att uttrycka data i dessa texter återspeglar utmaningarna med verkliga NLG-uppgifter.', 'sr': 'Ovaj papir opisuje komplet podataka CACAPO-a, izgrađen za obuku i nervne cijevi i sisteme generacije podataka na tekst. Podaci su multijezički (holandski i engleski), i sadrže skoro 10.000 rečenica iz teksta o ljudskim novinama u domenu sporta, vremena, akcijama i incidenata, zajedno sa povezanim podacima o prikazivanju. Podaci su jedinstveni u tome što lingvistička varijacija i indirektni način izražavanja podataka u ovim tekstima odražavaju izazove stvarnih zadataka NLG-a na svijetu.', 'ta': 'This paper describes the CACAPO dataset, built for training both neural pipeline and end-to-end data-to-text language generation systems.  இந்த தகவல் அமைப்பு பல மொழிகள் (டச்சு மற்றும் ஆங்கிலம்) மற்றும் விளையாட்டு, வானிலை, கடிகாரத்தில் மற்றும் நிகழ்வுகள் களத்தில் உள்ள 10,000 வாக்குகள் உள்ளன, சேர இந்த தகவல் அமைப்பு தனிப்பட்டது, இந்த உரைகளில் தரவை வெளிப்படுத்துவதற்கான மொழிமாறுதல் மற்றும் நேரடியான வழிகளை வெளிப்படுத்தும் என்பத', 'ur': 'This paper describes the CACAPO data set, built for training both neural pipeline and end-to-end data-to-text language generation systems. ڈاٹ سٹ multilingual (Dutch and English) ہے، اور انسان کے نویس ٹیکسٹوں سے تقریباً 10,000 عبارت لکھی جاتی ہیں جو کھیل, ہوا، سٹاک اور ایڈینٹ ڈومین میں ہیں، اور ایک ساتھ تفریق کی ارزش کے ذریعہ جڑے ہوئے ڈاٹ کے ساتھ. ڈاٹا سٹ ایسا ہے کہ زبانی تغییرات اور غیر صحیح طریقے ان ٹیکسٹوں میں دکھانے کے لئے واقعی دنیا کے NLG ٹیکسٹوں کی چالیں دکھاتے ہیں.', 'uz': "Name Maʼlumotlar soni ko'plab tillar (Hollandi va Ingliz tilida) va o'rtacha, sport, havo, stocks va hodisalar domain ichidagi oddiy xabar matnlaridan 10,000 so'zlar mavjud. Maʼlumotlar sahifasi uning o'zgarishlari va bu matlarda maʼlumotlarni tashkilotga ega holatda o'zgarishga qaramadi.", 'vi': 'Tờ giấy này mô tả bộ dữ liệu CACACAO, được xây dựng để huấn luyện cả đường ống thần kinh và kết thúc hệ thống phát triển ngôn ngữ. The dataset là đa dạng (Dutch and English) và chứa gần chục,000 câu từ Tin tức được viết bằng người trong các tin về thể thao, thời tiết, chứng khoán và ngẫu nhiên, cùng với hỗn hợp các dữ liệu kết hợp giá trị của các tập thể. Bộ dữ liệu này rất độc đáo, vì sự biến đổi ngôn ngữ và cách phát biểu dữ liệu gián tiếp trong các văn bản này phản ánh những thách thức của các công việc thuộc thế giới thực về LG.', 'nl': 'Dit artikel beschrijft de CACAPO dataset, gebouwd voor het trainen van zowel neurale pipeline als end-to-end data-to-text taalgeneratiesystemen. De dataset is meertalig (Nederlands en Engels) en bevat bijna 10.000 zinnen uit door mensen geschreven nieuwsteksten op het gebied van sport, weer, aandelen en incidenten, samen met uitgelijnde attribuut-waarde gekoppelde data. De dataset is uniek doordat de taalkundige variatie en indirecte manieren om gegevens uit te drukken in deze teksten weerspiegelen de uitdagingen van de echte NLG-taken.', 'da': 'Denne artikel beskriver CACAPO datasættet, der er bygget til træning af både neurale pipeline og end-to-end data-to-end sproggenereringssystemer. Datasættet er flersproget (hollandsk og engelsk) og indeholder næsten 10.000 sætninger fra menneskeskrevne nyhedstekster inden for sport, vejr, aktier og hændelser domæne sammen med justerede attribut-værdi parrede data. Datasættet er unikt, fordi den sproglige variation og indirekte måde at udtrykke data på i disse tekster afspejler udfordringerne ved den virkelige verden NLG-opgaver.', 'hr': 'Ovaj papir opisuje komplet podataka CACAPO-a, izgrađen za obuku i nervnog cijevina i sustava generacije podataka na tekst do kraja. Podaci su multijezički (holandski i engleski) i sadrže skoro 10.000 rečenica iz teksta o ljudskim pisaćim vijestima u domenu sporta, vremena, akcijama i incidenata zajedno s povezanim podacima o prikazivanju vrijednosti. Podaci su jedinstveni u tome što su jezičke varijacije i indirektni načini izražavanja podataka u tim tekstima odražavali izazove stvarnih zadataka NLG-a na svijetu.', 'ko': '본고는 CACAPO 데이터 집합을 묘사하는데 이 데이터 집합은 텍스트 언어 생성 시스템의 신경 파이프와 끝에서 끝까지의 데이터를 훈련하는 데 사용된다.이 데이터 집합은 다국어(네덜란드어와 영어)로 스포츠, 날씨, 주식과 사건 분야에서 온 인류의 서면 뉴스 텍스트의 약 10000개의 문장과 일치하는 속성 값이 데이터를 배합한다.이 데이터 세트는 이들 텍스트의 언어 변이와 데이터를 표현하는 간접 방식이 현실 세계 NLG 미션의 도전을 반영한다는 점에서 독특하다.', 'fa': 'این کاغذ مجموعه داده\u200cهای CACAPO را توصیف می\u200cکند که برای آموزشی از لوله\u200cهای عصبی و سیستم\u200cهای تولید داده\u200cهای پایان و پایان به زبان متن ساخته شده است. مجموعه داده\u200cهای زیادی زبان (هلندی و انگلیسی) است، و تقریباً ۱۰۰۰۰ جمله از متن\u200cهای خبرهای انسان نوشته شده در ورزش، هوا، ذخیره\u200cها و دامنه\u200cهای حادثه، با داده\u200cهای جفت\u200cشده با ارزش\u200cهای ویژه\u200cهای متصل شده است. مجموعه داده\u200cها متفاوت است که فرق زبان\u200cشناسی و راه\u200cهای غیرمستقیم برای تعریف داده\u200cها در این متن\u200cها چالش\u200cهای دنیای واقعی NLG را نشان می\u200cدهد.', 'bg': 'Настоящата статия описва набора от данни създаден за обучение както на невронни тръбопроводи, така и на системи за генериране на език от край до край данни. Наборът от данни е многоезичен (холандски и английски) и съдържа почти 10 000 изречения от написани от човека новинарски текстове в областта на спорта, времето, акциите и инцидентите, заедно с подравнени данни, свързани с атрибут-стойност. Наборът от данни е уникален, тъй като езиковата вариация и косвените начини за изразяване на данните в тези текстове отразяват предизвикателствата на задачите на НЛГ в реалния свят.', 'de': 'Diese Arbeit beschreibt den CACAPO-Datensatz, der für das Training von neuronalen Pipelines und End-to-End-Daten-zu-Text-Sprachgenerierungssystemen entwickelt wurde. Der Datensatz ist mehrsprachig (Niederländisch und Englisch) und enthält fast 10.000 Sätze aus von Menschen geschriebenen Nachrichtentexten in den Bereichen Sport, Wetter, Aktien und Incidents, zusammen mit ausgerichteten Attribut-Wert-Paarungsdaten. Der Datensatz ist insofern einzigartig, als die sprachliche Variation und die indirekte Ausdrucksweise der Daten in diesen Texten die Herausforderungen der realen NLG-Aufgaben widerspiegeln.', 'tr': 'Bu kagyz CACAPO veri setirini tashylaýar, näyral pipeline we soňra metin dilinden ýerleşdirmek üçin guruldy. Veri setir köp dilli Berüvler düzümleri, bu metinlerde hatlary ifade etmek üçin lingwistiki üýtgeşmeler we dalga yollary bardyr. Gerçek dünýäde NLG zadynyň kynçylygyny görkezýär.', 'id': 'Kertas ini menggambarkan set data CACAPO, dibangun untuk melatih sistem generasi bahasa data-ke-teks dan paip saraf. Set data berbeda bahasa (Belanda dan Inggris), dan mengandung hampir 10.000 kalimat dari teks berita yang ditulis oleh manusia dalam domain olahraga, cuaca, stok, dan insiden, bersama dengan data pasangan atribut-nilai. Set data unik dalam bahwa variasi bahasa dan cara indirekt untuk mengekspresikan data dalam teks-teks ini mencerminkan tantangan dari tugas NLG dunia nyata.', 'sw': 'Gazeti hili linaelezea seti ya taarifa za CACAPO, iliyoandaliwa kwa ajili ya mafunzo ya pipeline za kisasa na mifumo ya uzalishaji wa lugha za mwisho wa data-hadi maandishi. Taarifa hiyo ni lugha mbalimbali (Uholanzi na Kiingereza), na ina hukumu ya takriban 10,000 kutoka kwenye maandishi ya habari za binadamu yaliyoandikwa katika michezo, hali ya hewa, maduka na matukio ya matukio, pamoja na takwimu za thamani zilizotengenezwa. Taarifa hiyo ni ya kipekee katika kuwa mabadiliko ya lugha na njia za moja kwa moja ya kuonyesha taarifa katika maandishi haya yanaonyesha changamoto za kazi za NLG za dunia halisi.', 'af': 'Hierdie papier beskryf die CACAPO datastel, gebou vir onderwerp beide neurale pipelyn en einde- to- end data- to- text taal generasie stelsels. Die datastel is veelvuldige (Nederlandse en Engels), en bevat amper 10,000 setnings van mensskryfe nuusteks in die sport, weer, stoeke en incidente domein, saam met gelyk attribute-waarde paar data. Die datastel is unieke in dat die lingwisiese veranderinge en indirekte maniere van uitdrukking van data in hierdie teks reflekteer die uitdrukkings van reël wêreld NLG-opdragte.', 'sq': 'Ky dokument përshkruan sistemin e të dhënave CACAPO, të ndërtuar për trajnimin si të tubacionit nervor, ashtu edhe të sistemeve të gjenerimit të të dhënave nga fundi në tekst. Set i të dhënave është shumëgjuhës (hollandez dhe anglez) dhe përmban pothuajse 10,000 fjalim nga tekstet e lajmeve të shkruara nga njerëzit në domenin e sportit, motit, stoqeve dhe incidenteve, së bashku me të dhënat e barazuara me vlerën e atributeve. Grupi i të dhënave është unik në atë që variacioni gjuhësor dhe mënyra indirekte e shprehjes së të dhënave në këto tekste pasqyrojnë sfidat e detyrave të botës reale NLG.', 'am': 'ይህ ገጽ የCACAPO ዳታተር ማሳየት፣ የናውሬው ፖሊን እና የዳታ-ወደ-ጽሑፍ ቋንቋ ትውልድ ስርዓቶችን ለማስተማር ይዘረዝራል፡፡ የዳታ ሳጥን በብዛት ቋንቋ (ድውልክ እና እንግሊዘኛ) እና በሰው ጽሑፎች ላይ የተጻፈውን የጽሑፍ ጽሑፎች በጨዋታ፣ መስኮት፣ ደመና፣ አካል እና ጉዳይ ጉዳይ እና የክፍለ ጉዳይ አካባቢ አካባቢ አካባቢ አካል ነው፡፡ የዳታ ሳጥን የቋንቋዊው መለወጫ እና የኢንተርኔት ዳታዎችን በመግለጥ እና የግንኙነት መንገዶች የእውነቱ ዓለም የNLG ስራ ጥቃቄዎችን የሚያስተካክሉ ነው፡፡', 'bs': 'Ovaj papir opisuje komplet podataka CACAPO-a, izgrađen za obuku i nervne cijevi i sisteme generacije podataka na tekst do kraja. Podaci su multijezički (holandski i engleski), i sadrže skoro 10.000 rečenica iz teksta o ljudskim novinama u domenu sporta, vremena, akcijama i incidenata, zajedno sa povezanim podacima o povezanim atributima. Podaci su jedinstveni u tome što lingvistička varijacija i indirektni način izražavanja podataka u ovim tekstima odražavaju izazove stvarnih svjetskih zadataka NLG-a.', 'bn': 'এই কাগজটি ক্যাকাপোর ডাটাসেট বর্ণনা করে, যা নিউরেল পাইপেলাইন এবং শেষ-পর্যন্ত তথ্য-টেক্সট প্রজন্মের জন্য প্রশিক্ষণের জন্য ডাটাসেট হচ্ছে বহুভাষী (ডাচ এবং ইংরেজী) এবং মানুষের ক্রীড়া, আবহাওয়া, স্ক্যাক এবং ঘটনার মাধ্যমে মানুষের লেখা সংবাদ লেখার প্রায় ১০,০০০ শাস্তি রয়েছ ডাটাসেট বিশ্বের বাস্তব এনএলজি কাজের চ্যালেঞ্জের প্রতিক্রিয়া প্রদর্শন করে ভাষাগত ভাষায় পরিবর্তন এবং পরিচালিত তথ্য প্রকাশের স', 'hy': 'Այս հոդվածը նկարագրում է CACAPO տվյալների համակարգը, որը ստեղծվել է նյարդային խողովակաշարերի և վերջ-վերջ տվյալների լեզվի ստեղծման համակարգերի ուսումնասիրության համար: Տվյալների համակարգը բազլեզու է (հոլանդացի և անգլերենի), և պարունակում է գրեթե 10,000 նախադասություն մարդկային գրված նորությունների տեքստներից սպորտային, ժամանակահատվածների, արժեքների և իրադարձությունների ոլորտում, միասին հարաբերված առանձնահատկությունների և արժե Տվյալների համակարգը յուրահատուկ է, որովհետև լեզվաբանական տարբերությունները և այս տեքստներում տեղեկատվությունների արտահայտության միջոցները արտացոլում են իրական աշխարհի ՆԼԳ խնդիրների մարտահրավերները:', 'cs': 'Tento článek popisuje datovou sadu CACAPO, vytvořenou pro trénink neuronového potrubí a end-to-end systémů generování jazyků dat-text. Datová sada je vícejazyčná (nizozemština a angličtina) a obsahuje téměř 10tisícové věty z lidských zpravodajských textů v oblasti sportu, počasí, akcie a incidentů, společně se sladěnými daty spárovanými s hodnotou atributů. Datová sada je jedinečná tím, že jazyková variace a nepřímé způsoby vyjádření dat v těchto textech odrážejí výzvy reálného světa NLG úkolů.', 'et': 'Käesolevas dokumendis kirjeldatakse CACAPO andmekogumit, mis on loodud nii neurotorujuhtme kui ka lõpust-lõpuni andmete genereerimise süsteemide koolitamiseks. Andmekogum on mitmekeelne (hollandi ja inglise keel) ja sisaldab peaaegu 10 000 lauset inimkirjutatud uudistest spordi-, ilmastiku-, varude- ja intsidentide valdkonnas ning ühtlustatud atribuudi-väärtusega seotud andmeid. Andmekogum on ainulaadne selles osas, et keeleline variatsioon ja kaudsed andmete väljendamise viisid nendes tekstides peegeldavad reaalsete NLG ülesannete väljakutseid.', 'az': 'Bu kańüńĪt CACAPO veri quruluńüunu t…ôhsil edir, n√∂ral pipeline v…ô end-to-end veri-to-text dil t…ôhsil sisteml…ôrini t…ôhsil edir. Veri qurńüularńĪ √ßoxlu dildir (Holandica v…ô ńįngilizca) v…ô insan yazńĪlmńĪŇü x…ôb…ôr m…ôtnl…ôrind…ôn az qala 10.000 c√ľml…ôl…ôr i√ß…ôrir, sportlarda, hava, qoyuqlarda v…ô olaraq m…ôlumatlarda birlikd…ô t…ôr…ôfl…ôndirilmiŇü attribute qiym…ôti il…ô birlikd…ô. Bu m…ôktublarda m…ôlumatlarńĪ ifad…ô etm…ôk √ľ√ß√ľn dil d…ôyiŇüiklikl…ôri v…ô d…ôyiŇüiklik yollarńĪ h…ôqiq…ôt d√ľnyanńĪn NLG iŇül…ôrinin √ß…ôtinlikl…ôrini t…ôsdiql…ôndirm…ôkd…ô t…ôhsil edir.', 'fi': 'Tässä artikkelissa kuvataan CACAPO-aineistoa, joka on rakennettu sekä neuroputken että päästä päähän datasta tekstiin -kielen tuottamiseen. Aineisto on monikielinen (hollanti ja englanti), ja se sisältää lähes 10 000 lausetta ihmisen kirjoittamasta uutistekstistä urheilu-, sää-, osake- ja tapahtumaalalta sekä tasattua attribuutti-arvoa paritettua dataa. Aineisto on ainutlaatuinen siinä mielessä, että kielellinen vaihtelu ja epäsuorat tavat ilmaista tietoa näissä teksteissä heijastavat todellisten NLG-tehtävien haasteita.', 'ca': "Aquest article descriu el conjunt de dades CACAPO, construït per formar tant els sistemes de generació de dades neuronals com de dades fins a text. El conjunt de dades és multilingüe (holandès i anglès), i conté gairebé 10.000 frases de textos de notícies escrits per humans en el domini esports, meteorològics, accions i incidents, juntament amb dades alineades entre valors d'atributs i valors parellats. El conjunt de dades és únic en que la variació lingüística i les maneres indirectes d'expressar les dades en aquests textos reflecteixen els reptes de les tasques de NLG del món real.", 'jv': 'Perintah iki dadi nggambaran seneng dataset, nggawe nggawe sistem dadi-kanggo ngilanggar langgar Neral karo mulai dataset iku multilanguage dataset iku kelangerung barêng-barêng kuwi ing perusahaan langkung karo akeh barang sing gak dhéwé kuwi nggawe data in kanggo nggambar kapan kanggo ngerasakno operasi NLG kuwi ngéwé.', 'sk': 'V prispevku je opisan nabor podatkov CACAPO, zgrajen za usposabljanje tako nevronskih cevovodov kot tudi sistemov generiranja jezikovnega jezika od konca do konca. Zbirka podatkov je večjezična (nizozemščina in angleščina) in vsebuje skoraj 10.000 stavkov iz človeških novic na področju športa, vremena, delnic in incidentov, skupaj z usklajenimi podatki o atributih in vrednostih. Zbirka podatkov je edinstvena, saj jezikovna variacija in posredni načini izražanja podatkov v teh besedilih odražajo izzive dejanskih nalog NLG.', 'ha': 'Wannan takardar na bayyana tsarin CACAPS, an gina dõmin yin amfani da tsarin tsarin ƙarƙashin neura da ƙarshen-zuwa-matsayin-zuwa-ƙari. Suna daidaita database na mulki-lingui (Dukkan da Ingiriya), kuma yana da cire 10,000 cewa daga matsayin mutane da aka rubuta na rubutu cikin littattafan mutane na idãnun firam, kwanan kwanan kwanan wata da aka samu da data masu haɗi da kimar ƙayyade. @ info: whatsthis', 'he': 'הנייר הזה מתאר את קבוצת נתונים CACAPO, בנויה לאימון גם צינור עצבי וגם מערכות יוצרת נתונים מסוף לסוף לשפה טקסטית. התערוכת המידע היא רבולוגית (הולנדית ואנגלית), והיא מכילה כמעט 10,000 משפטים מסמכי חדשות כתובים על ידי האדם בתחום הספורט, מזג האוויר, מניות ותקריות, יחד עם מידע שווים בערך תכונות. קבוצת המידע מיוחדת שבה ההתנהגות הלשונית והדרכים השוואות לבטא נתונים בטקסטים האלה משקפים את האתגרים של משימות NLG בעולם האמיתי.', 'bo': 'ཤོག་བྱང་འདིས་CACAPO་ཡིག་སྣོད་ཀྱི་སྒྲིག་འགོད་ཀྱི་གནད་དོན་ཡིག་ཆ་གསར་བསྐྲུན་བྱེད་ཀྱི་ཡོད། The dataset is multilingual (Dutch and English), and contains almost 10,000 sentences from human-written news texts in the sports, weather, stocks, and incidents domain, together with aligned attribute-value paired data. སྐད་ཡིག'}
{'en': 'DaMata : A Robot-Journalist Covering the Brazilian Amazon Deforestation', 'ar': 'DaMata: روبوت صحفي يغطي إزالة غابات الأمازون البرازيلية', 'fr': "DaMata\xa0: un robot-journaliste qui couvre la déforestation de l'Amazonie brésilienne", 'pt': 'DaMata: um robô-jornalista cobrindo o desmatamento da Amazônia brasileira', 'es': 'DaMata: un robot-periodista que cubre la deforestación de la Amazonía brasileña', 'ja': 'DaMata:ブラジルのアマゾン森林伐採を取材するロボットジャーナリスト', 'zh': 'DaMata曰:报道巴西亚马逊林伐机器人记者', 'hi': 'DaMata: ब्राजील के अमेज़ॅन वनों की कटाई को कवर करने वाला एक रोबोट-पत्रकार', 'ru': 'DaMata: Робот-журналист, освещающий обезлесение в бразильской Амазонии', 'ga': 'DaMata: Iriseoir róbait a chlúdaíonn Dífhoraoisiú Amazon na Brasaíle', 'ka': 'DaMata: პრობოტი-ჯერნალისტი, რომელიც ბრაზილური ამოზონის დეპოლოსტაციაციას აკეთებს', 'hu': 'DaMata: Robot-újságíró a brazil amazoni erdőtelepítésről', 'el': 'ΝταΜάτα: Ένας ρομπότ-δημοσιογράφος που καλύπτει την αποδάσωση του Αμαζονίου της Βραζιλίας', 'it': 'DaMata: un robot-giornalista che copre la deforestazione amazzonica brasiliana', 'kk': 'DaMata: Бразилиялық Amazon деморстациясының робот журналисті', 'lt': 'DaMata: Robot ų žurnalistas, aprėpiantis Brazilijos Amazonos miškų naikinimą', 'mk': 'Дамата: Роботски новинар кој ја покрива бразилската амазонска дешумација', 'ms': 'DaMata: Seorang jurnalis robot yang meliputi Pembuangan Amazon Brazil', 'ml': 'ദാമാറ്റ: ബ്രാസിലിയന്\u200d അമാസണ്\u200d ഡിഫോര്\u200dസ്റ്റേഷന്\u200d പൊതിയുന്ന ഒരു റോബോട്ട്-ജോലിസ്റ്റര്\u200d', 'mt': 'DaMata: Robot Journalist li jkopri d-Deforestazzjoni tal-Amażoni Brażiljani', 'mn': 'DaMata: Бразилийн Амазон салбарын газрыг дүгнэж байгаа робот-журналист', 'no': 'DaMata: Eit robot-Journalist Covering the Brazilian Amazon Deforestation', 'pl': 'DaMata: Robot-dziennikarz opisujący brazylijskie odlesianie Amazonii', 'ro': 'DaMata: Un jurnalist robot care acoperă despădurirea Amazonului brazilian', 'si': 'DaMata: රොබෝට්-ජාර්නලිස්ට් එකක් බ්\u200dරාජිලියාන් අමාසෝන් විනාශ කරනවා', 'sv': 'DaMata: En robotjournalist som täcker den brasilianska Amazonas beskogning', 'sr': 'DaMata: Robot-novinar koji pokriva Brazilsku Amazon deforestaciju', 'so': 'DaMata: A Robot-Journalist Covering the Brazilian Amazon Deforestation', 'ta': 'டாமாடா: ஒரு ரோபோட்- செய்தியாளர் பிரேசிலியன் அமாசான் வெளிப்பாடு', 'ur': 'داماتا: ایک روبوت-جرنیلیست جو برازیل ایمزین ڈھوٹ ڈھوٹ', 'uz': 'DaMata: Braziliya Amazon dizayning robot- journalisti', 'vi': 'Damata: Một robot-ký giả bao quanh rừng Mặc định Amazon Brazil', 'bg': 'ДаМата: Робот-журналист, отразяващ обезлесяването на Бразилска Амазонка', 'hr': 'DaMata: Robot-novinar koji pokriva Brazilsku Amazon deforestaciju', 'da': 'DaMata: En robot-journalist, der dækker den brasilianske Amazonas nedplantning', 'nl': 'DaMata: Een robotjournalist over de Braziliaanse Amazone Ontbossing', 'de': 'DaMata: Ein Roboter-Journalist über die Entwaldung des brasilianischen Amazonas', 'id': 'DaMata: Sebuah jurnalis robot yang meliputi deforestasi Amazon Brazil', 'ko': '다마타: 브라질 아마존 숲의 벌목을 보도한 로봇 기자', 'fa': 'داماتا: یک روبات-روزنامه\u200cگر که در آزمایشگاه آمازون برزیل پوشش می\u200cدهد', 'sw': 'DaMata: Mwandishi wa habari wa Robot anayeandika habari za Ulinzi wa Amazon wa Brazil', 'af': "DaMata: 'n Robot-Journalist Omdekking van die Braziliese Amazon-Deforestasie", 'tr': 'DaMata:Bir Robot-Gazeteci Braziliyalı Amazon Toparlama', 'sq': 'DaMata: Një robot-gazetar që mbulon dëbimin brazilian të Amazon ës', 'hy': 'Դամատա. Ռոբոտ-լրագրող, որը ծածկում է Բրազիլիայի Ամազոնի անտառապանքը', 'am': 'ዳማታ: የብራዚላዊ አማዞን ወቅት የሚሸፍን ሮቦት-ጋዜጠኛ', 'bn': 'দামাতা: ব্রাজিলিয়ান আমাজোন ডিফোরেশনের কাভার করছেন একজন রবোট-সাংবাদিক', 'az': 'DaMata: Braziliyal캼 Amazon t톛hl칲k톛sini 칬rt칲b Robot-Journalist', 'bs': 'DaMata: Robot-novinar koji pokriva Brazilsku Amazon deforestaciju', 'ca': "DaMata: Un periodista robot que cobreix la deforestació brasilera de l'Amazònia", 'cs': 'DaMata: Robotický novinář, který pokrývá brazilskou Amazonii', 'fi': 'DaMata: Robotti-journalisti, joka käsittelee Brasilian Amazonin metsien hävittämistä', 'et': 'DaMata: Brasiilia Amazonase metsade hävitamist käsitlev robotajakirjanik', 'jv': 'Damata: A Jobot-Perilistar Covering the BraBraBracilian Amarok Deforation', 'sk': 'DaMata: Robot-novinar, ki pokriva brazilsko krčenje Amazonke', 'ha': 'DaMata: A Robot-journalist covering the brazilian amazon Deforestation', 'he': 'דמאטה: עיתונאי רובוטים מכסה את היערות האמזוניות הברזילית', 'bo': 'DaMata:གསར་དེབ་སྐྱེས་པ་ཞིག་གིས་བྷི་ར་ཛིལ་གྱི་Amazon སྔར་སྒྲིག་ཡོད་པ་'}
{'en': 'This demo paper introduces DaMata, a robot-journalist covering deforestation in the Brazilian Amazon. The robot-journalist is based on a pipeline architecture of Natural Language Generation, which yields multilingual daily and monthly reports based on the public data provided by DETER, a real-time deforestation satellite monitor developed and maintained by the Brazilian National Institute for Space Research (INPE). DaMata automatically generates reports in Brazilian Portuguese and English and publishes them on the Twitter platform. Corpus and code are publicly available.', 'fr': "Ce document de démonstration présente DaMata, un robot-journaliste qui couvre la déforestation en Amazonie brésilienne. Le robot-journaliste est basé sur une architecture de pipeline de Natural Language Generation, qui produit des rapports quotidiens et mensuels multilingues basés sur les données publiques fournies par DETER, un moniteur satellite de la déforestation en temps réel développé et maintenu par l'Institut national brésilien de recherche spatiale (INPE) ). DaMata génère automatiquement des rapports en portugais brésilien et en anglais et les publie sur la plateforme Twitter. Le corpus et le code sont accessibles au public.", 'ar': 'تقدم هذه الورقة التجريبية DaMata ، وهو صحفي آلي يغطي إزالة الغابات في منطقة الأمازون البرازيلية. يعتمد الصحفي الآلي على هندسة خطوط الأنابيب لتوليد اللغة الطبيعية ، والتي تنتج تقارير يومية وشهرية متعددة اللغات بناءً على البيانات العامة التي يوفرها DETER ، وهو جهاز مراقبة أقمار صناعية لإزالة الغابات في الوقت الفعلي تم تطويره وصيانته بواسطة المعهد الوطني البرازيلي لأبحاث الفضاء ( INPE). ينشئ DaMata التقارير تلقائيًا باللغتين البرتغالية البرازيلية والإنجليزية وينشرها على منصة Twitter. المدونة والرمز متاحان للجمهور.', 'es': 'Este artículo de demostración presenta a DaMata, un robot-periodista que cubre la deforestación en la Amazonía brasileña. El robot-periodista se basa en una arquitectura de canalización de Natural Language Generation, que produce informes multilingües diarios y mensuales basados en los datos públicos proporcionados por DETER, un monitor satelital de deforestación en tiempo real desarrollado y mantenido por el Instituto Nacional Brasileño de Investigaciones Espaciales (INPE). ). DaMata genera automáticamente informes en portugués e inglés de Brasil y los publica en la plataforma de Twitter. El corpus y el código están a disposición del público.', 'pt': 'Este documento de demonstração apresenta DaMata, um robô-jornalista que cobre o desmatamento na Amazônia brasileira. O robô-jornalista é baseado em uma arquitetura de pipeline da Natural Language Generation, que produz relatórios multilíngues diários e mensais com base nos dados públicos fornecidos pelo DETER, um monitor de satélite de desmatamento em tempo real desenvolvido e mantido pelo Instituto Nacional de Pesquisas Espaciais (Instituto Nacional de Pesquisas Espaciais). INPE). A DaMata gera relatórios automaticamente em português e inglês do Brasil e os publica na plataforma do Twitter. Corpus e código estão disponíveis publicamente.', 'hi': 'यह डेमो पेपर ब्राजील के अमेज़ॅन में वनों की कटाई को कवर करने वाले एक रोबोट-पत्रकार दमाता का परिचय देता है। रोबोट-पत्रकार प्राकृतिक भाषा पीढ़ी की एक पाइपलाइन वास्तुकला पर आधारित है, जो डीईटीईआर द्वारा प्रदान किए गए सार्वजनिक डेटा के आधार पर बहुभाषी दैनिक और मासिक रिपोर्ट उत्पन्न करता है, जो ब्राजील के राष्ट्रीय अंतरिक्ष अनुसंधान संस्थान (आईएनपीई) द्वारा विकसित और बनाए रखा गया एक वास्तविक समय वनोन्मूलन उपग्रह मॉनिटर है। DaMata स्वचालित रूप से ब्राजील पुर्तगाली और अंग्रेजी में रिपोर्ट उत्पन्न करता है और उन्हें चहचहाना मंच पर प्रकाशित करता है। कॉर्पस और कोड सार्वजनिक रूप से उपलब्ध हैं।', 'ja': 'このデモ論文では、ブラジルのアマゾンでの森林破壊を取材したロボットジャーナリスト、DaMataを紹介しています。ロボットジャーナリストは、自然言語生成のパイプラインアーキテクチャに基づいており、ブラジル国立宇宙研究所（ INPE ）が開発および維持するリアルタイムの森林破壊衛星モニターであるDEISTが提供する公開データに基づいて、多言語の日報および月報を生成します。DaMataはブラジルポルトガル語と英語でレポートを自動生成し、Twitterプラットフォームで公開します。コーパスとコードは公開されています。', 'zh': '此篇示文DaMata,报道巴西亚马逊林伐机器人记者。 机器人记者基于自然语言生(Natural Language Generation)之管架构,当架构因DETER之公共数据生成多言日月度以告,DETER巴西空国研究所(INPE)开实时林伐卫星监视器。 DaMata以巴西葡萄牙语及英语自生告,发Twitter台上。 语料库代码明可用也。', 'ru': 'Эта демонстрационная статья знакомит с DaMata, робот-журналистом, освещающим обезлесение в бразильской Амазонии. Работа робота-журналиста основана на трубопроводной архитектуре системы "Natural Language Generation", которая позволяет получать ежедневные и ежемесячные многоязычные отчеты на основе публичных данных, предоставляемых компанией "DETER" - спутниковым монитором обезлесения в режиме реального времени, разработанным и поддерживаемым Бразильским национальным институтом космических исследований (ИНПЕ). DaMata автоматически создает отчеты на бразильском португальском и английском языках и публикует их на платформе Twitter. Корпус и код общедоступны.', 'ga': 'Tugann an páipéar taispeána seo isteach DaMata, robot-iriseoir a chlúdaíonn dífhoraoisiú san Amazon Brasaíle. Tá an róbat-iriseoir bunaithe ar ailtireacht phíblíne de Ghiniúint Teanga Nádúrtha, a thugann tuairiscí ilteangacha laethúla agus míosúla bunaithe ar na sonraí poiblí a sholáthraíonn DETER, monatóir satailíte dífhoraoisithe fíor-ama arna fhorbairt agus arna chothabháil ag Institiúid Náisiúnta na Brasaíle um Thaighde Spáis. INPE). Gineann DaMata tuarascálacha go huathoibríoch i bPortaingéilis agus i mBéarla na Brasaíle agus foilsíonn sé iad ar an ardán Twitter. Tá corpas agus cód ar fáil go poiblí.', 'hu': 'Ez a demó tanulmány bemutatja DaMata-t, egy robot-újságírót, aki a brazil amazoniai erdőirtásról szól. A robot-újságíró a Natural Language Generation csővezeték architektúráján alapul, amely a Brazil National Institute for Space Research (INPE) által kifejlesztett és karbantartott DETER által nyilvános adatok alapján többnyelvű napi és havi jelentéseket készít. A DaMata automatikusan brazil portugál és angol nyelvű jelentéseket készít, és közzéteszi azokat a Twitter platformon. A Corpus és a kód nyilvánosan hozzáférhető.', 'ka': 'ეს დემო დოკუმენტი დააჩვენება დამატა, რობოტი-ჯერნალისტი, რომელიც ბრაზილური ამოზაციაში დემოლოსტაციაციას. პრობოტი-ჯერნალისტი დაბაზეულია ნაირადი ენის განვითარების მიზეზი, რომელიც მრავალენგური და თველ წლის შეტყობინებების მიზეზი DETER-ის პობლიკური მონაცემებზე, რეალურად განვითარებული სატელეტის მონიტორი, რომელიც განვითარებული და დაე Name კჲპოსჟ თ კჲე ჟა ოსბლთფნჲ ეჲჟრყონთ.', 'el': 'Αυτή η δοκιμαστική εργασία παρουσιάζει τον ΝταΜάτα, έναν ρομπότ-δημοσιογράφο που καλύπτει την αποψίλωση των δασών στον Βραζιλιάνικο Αμαζόνιο. Ο ρομπότ-δημοσιογράφος βασίζεται σε μια αρχιτεκτονική αγωγού της δημιουργίας φυσικής γλώσσας, η οποία παράγει πολύγλωσσες ημερήσιες και μηνιαίες εκθέσεις με βάση τα δημόσια δεδομένα που παρέχονται από το DETER, ένα δορυφορικό όργανο αποψίλωσης σε πραγματικό χρόνο που αναπτύχθηκε και συντηρείται από το Εθνικό Ινστιτούτο Διαστημικής Έρευνας (INPE). Το DaMata δημιουργεί αυτόματα αναφορές στα βραζιλιάνικα πορτογαλικά και αγγλικά και τις δημοσιεύει στην πλατφόρμα Twitter. Το Σώμα και ο κώδικας είναι δημοσίως διαθέσιμοι.', 'it': "Questo articolo demo presenta DaMata, un robot-giornalista che parla della deforestazione nell'Amazzonia brasiliana. Il robot-giornalista si basa su un'architettura di pipeline di Natural Language Generation, che fornisce report multilingue giornalieri e mensili basati sui dati pubblici forniti dal DETER, un monitor satellitare di deforestazione in tempo reale sviluppato e mantenuto dall'Istituto Nazionale Brasiliano per la Ricerca Spaziale (INPE). DaMata genera automaticamente report in portoghese brasiliano e inglese e li pubblica sulla piattaforma Twitter. Corpus e codice sono pubblicamente disponibili.", 'kk': 'Бұл демократиялық қағаз Бразилиялық Амазондағы демократиялық демократиялық демократиялық демократиялық робот журналисті DaMata-ды таңдайды. Роботжурналист, Бразилиялық Ұлттық Исследования институты (INPE) бойынша күнделік және ай сайын күнделікті мәліметті деректерге негізделген Түзіндік тілдер құрылғысының қабырғы архитектурасына негізделген, шын уақытты дефлорестациялық сайт мониторы DaMata автоматты түрде Бразилиялық португаль мен ағылшын тілінде хабарламаларды жасап, оны Twitter платформасында жариялады. Код және код көпшілікті қол жеткізеді.', 'lt': 'Šiame demonstraciniame dokumente pristatomas robot ų žurnalistas DaMata, kuris aprėpia miškų naikinimą Brazilijos Amazonoje. Robotų žurnalistas grindžiamas gamtos kalbų generacijos vamzdynų architektūra, kurioje pateikiamos kasdienės ir mėnesinės daugiakalbės ataskaitos, grindžiamos vieša is duomenimis, kuriuos pateikė DETER, Brazilijos nacionalinis kosmoso mokslinių tyrimų institutas (INPE), kuriamas ir prižiūrimas realaus laiko palydovinis miškų naikinimo stebėtojas. DaMata automatiškai rengia ataskaitas Brazilijos portugalų ir anglų kalbomis ir jas skelbia Twitter platformoje. Korpus ir kodas yra viešai prieinami.', 'ms': 'Kertas demo ini memperkenalkan DaMata, seorang wartawan robot yang menutupi pemotongan hutan di Amazon Brazil. The robot-journalist is based on a pipeline architecture of Natural Language Generation, which yields multilingual daily and monthly reports based on the public data provided by DETER, a real-time deforestation satellite monitor developed and maintained by the Brazilian National Institute for Space Research (INPE).  DaMata secara automatik menghasilkan laporan dalam bahasa Portugis dan Inggeris Brazil dan menerbitkannya di platform Twitter. Korpus dan kod tersedia secara umum.', 'mk': 'Овој демонстрациски весник ја претставува Дамата, роботски новинар кој покрива дешумација во Бразилска Амазона. Робот-новинарот се базира на нафтоводска архитектура на генерацијата на природен јазик, која предава мултијазични дневни и месечни извештаи базирани на јавните податоци обезбедени од ДЕТЕР, сателитски монитор за дешумација во реално време, развиен и одржан од страна на Бразилскиот Национален институт за вс ДаМата автоматски генерира извештаи на бразилски португалски и англиски и ги објавува на Твитер платформата. Корпус и кодот се јавно достапни.', 'mt': 'Dan id-dokument ta’ demostrazzjoni jintroduċi DaMata, ġurnalist robotiku li jkopri d-deforestazzjoni fl-Amażona Brażiljana. Ir-robot-ġurnalist huwa bbażat fuq arkitettura tal-pipeline tal-Ġenerazzjoni tal-Lingwa Naturali, li tipproduċi rapporti multilingwi ta’ kuljum u ta’ kull xahar ibbażati fuq id-dejta pubblika pprovduta mid-DETER, monitor a ġġ tas-satellita tad-deforestazzjoni f’ħin reali żviluppat u miżmum mill-Istitut Nazzjonali Brażiljan għar-Riċerka Spazjali (INPE). DaMata awtomatikament tiġġenera rapporti bil-Portugiż Brażiljan u bl-Ingliż u tippubblikahom fuq il-pjattaforma ta’ Twitter. Il-korpus u l-kodiċi huma disponibbli għall-pubbliku.', 'ml': 'ഈ ജനാധിപത്രം ഡാമാത്തയെ പരിചയപ്പെടുത്തുന്നു. ബ്രാസിലിയന്\u200d അമാസണില്\u200d ഒരു റോബോട്ട്-പത്രിക്കാരന്\u200d ഡാമാത്ത. റോബോട്ട്-പത്രിപ്പാര്\u200dട്ട് സ്വാഭാവ ഭാഷയുടെ സ്ഥാനത്തില്\u200d അടിസ്ഥാനമാണ്. അത് ഡെയിറ്റര്\u200d നല്\u200dകിയ പൊതുവിവരങ്ങള്\u200dക്ക് അടിസ്ഥാനമായി പല ദിവസവും മാസവും റിപ്പോര്\u200dട്ട് നല്\u200dകുന്നു. ബ്രാസീല ഡാമാറ്റ സ്വയമായി ബ്രാസിലിയന്\u200d പോര്\u200dട്ടുഗീഷിലും ഇംഗ്ലീഷിലും റിപ്പോര്\u200dട്ടികള്\u200d ഉണ്ടാക്കുന്നു. ടൂട്ടര്\u200d പ് കോര്\u200dപ്പസും കോഡും പ്രസിദ്ധമാണ്.', 'mn': 'Энэ демократийн цаас Бразилийн Амазон дахь салбарын робот сэтгүүлч DaMata-г танилцуулдаг. Роботын сэтгүүлчид байгалийн хэл төрөлхтний хоолойн архитектур дээр суурилсан. Энэ нь DETER-ын олон хэлний өдөр, сарын турш олон хэлний мэдээллүүдийн үндсэн мэдээллүүдийн үндсэн мэдээллүүдийн санааг өгдөг. Бразилийн National Institute for Space Research (INPE) ажиллаж, хадгалагдсан. DaMata Бразилийн Португали болон Англи хэлний мэдээллийг автоматаар бий болгодог. Тэднийг Twitter платформад хэвлүүлнэ. Хэрэглэгч, код олон нийтэд ашиглагддаг.', 'no': 'Denne demopapiret introduserer DaMata, ein robotjornalista som dekkar deforestasjon i Brasilianske Amazon. Robotjornalista er basert på ein røyr-arkitektur av naturspråk-generering, som gjev fleirspråk daglige og månadlige rapporter basert på offentlige data som gjev av DETER, eit verkelig satelitmonitor for deforestasjon utvikla og vedlikehald av Brazilsk nasjonal Institute for Space Research (INPE). DaMata lagar automatisk rapporter i Brasiliansk portugisisk og engelsk og publiserer dei på Twitter-plattformet. Korpus og kode er tilgjengeleg offentlig.', 'pl': 'Ten artykuł demonstracyjny przedstawia DaMata, robota-dziennikarkę opisującą wylesianie w brazylijskiej Amazonii. Robot-dziennikarz opiera się na architekturze rurociągu Natural Language Generation, który przedstawia wielojęzyczne raporty dzienne i miesięczne w oparciu o dane publiczne dostarczone przez DETER, satelitarny monitor wylesiania w czasie rzeczywistym opracowany i utrzymywany przez Brazylijski Narodowy Instytut Badań Kosmicznych (INPE). DaMata automatycznie generuje raporty w języku brazylijskim portugalskim i angielskim i publikuje je na platformie Twitter. Korpus i kod są publicznie dostępne.', 'ro': 'Această lucrare demo prezintă DaMata, un robot-jurnalist care se ocupă de defrișări în Amazonul brazilian. Jurnalistul robot se bazează pe o arhitectură de conducte a Generației Limbajului Natural, care oferă rapoarte zilnice și lunare multilingve bazate pe datele publice furnizate de DETER, un monitor prin satelit de defrișare în timp real dezvoltat și întreținut de Institutul Național Brazilian pentru Cercetare Spațială (INPE). DaMata generează automat rapoarte în portugheză braziliană și engleză și le publică pe platforma Twitter. Corpul şi codul sunt disponibile publicului.', 'sr': 'Ovaj demo novinar predstavlja DaMatu, robot a-novinar koji pokriva deforestaciju u Brazilskoj Amazoni. Robot-novinar se temelji na građevinskoj arhitekturi generacije prirodnog jezika, koja daje višejezičke i mesečne izveštaje na temelju javnih podataka predstavljenih DETER-om, satelitski monitor za stvarno vrijeme deforestacije razvijen i održan Brazilskim Nacionalnim institutom za istraživanje svemira (INPE). DaMata automatski proizvodi izveštaje na Brazilskom portugalskom i engleskom jeziku i objavljuje ih na Twitter platformi. Korpus i kod su javno dostupni.', 'si': 'මේ ප්\u200dරධාන පත්තුරේ බ්\u200dරාසිලියාන් අමාසෝන් වල රොබෝට් ජාතිකයෙක් DaMata වෙනුවෙන්. රොබෝට්-ජාත්\u200dරිකාරියා අධාරණය කරනවා නියම භාෂාව නිර්මාණයේ පායිප්ලායින් ස්ථාපනය සඳහා, ඒකෙන් බ්\u200dරාජිලියාන් ජාතික සංස්ථාපනය සඳහා මාස්ත්\u200dරික දත් Name කෝර්පුස් සහ කෝඩ් සාමාන්\u200dයයෙන් ප්\u200dරතිකාරයෙන්.', 'so': 'Warqadan demo wuxuu soo bandhigaa DaMata oo ah journalist roboti oo ku qoran burburka Amazonka Brazil. Robot-journalist wuxuu ku saleysan yahay taariikhda afka asalka ah, kaas oo soo saara warqado luuqad kala duduwan oo bil ah oo ku saleysan taariikhda dadweynaha ee DETER, maamulka sayteti ee waqtiga rasmiga ah oo horumariyey oo u hoggaamiyey iyo dhaqaaleen Taasisi National Institute for Space Research (INPE). DaMata wuxuu si bilowgiis ah u soo bandhigaa warqado ku qoran Burtuqiis iyo Ingiriis, wuxuuna ku soo bandhigaa shabakadda Twitterka. Corpus and code are publicly available.', 'ta': 'இந்த குறிப்பு தாமதம், ஒரு ரோபோட்- பத்திரிக்காளர் டேமாடா அறிவிக்கிறது, ப்ராசிலியன் அமாசானில் உள்ள வீணாக்குதல The robot- journalist is based on a pipeline architecture of Natural Language Generation, which produces multilingual and monthly reports based on public data, based on real-time deforestation satellite monitor developed and maintained by Brazilian National Institute for Space Research (INPE). டாமாடா தானாகவே ப்ராசிலியன் போர்த்துகீசிஷ் மற்றும் ஆங்கிலம் அறிக்கைகளை உருவாக்குகிறது மற்றும் அவற்றை Twitter தளப கார்புஸ் மற்றும் குறியீடு பொதுவாக கிடைக்கும்.', 'sv': 'Detta demopapper presenterar DaMata, en robot-journalist som täcker avskogning i Brasilien Amazonas. Robotjournalisten bygger på en pipeline arkitektur av Natural Language Generation, som ger flerspråkiga dagliga och månatliga rapporter baserade på offentliga data från DETER, en satellitmonitor för avskogning i realtid som utvecklats och underhålls av Brasiliens nationella institut för rymdforskning (INPE). DaMata genererar automatiskt rapporter på brasilianska portugisiska och engelska och publicerar dem på Twitter-plattformen. Korpus och kod är allmänt tillgängliga.', 'ur': 'یہ دیمو کاغذ، ایک روبوٹ-جورنسٹ، برازیل ایمزانیوں میں ڈھماتا کو معرفی کرتا ہے۔ روبوٹ-جورنسٹ نے طبیعی زبان پیدا کرنے کی پائیپلین معماری پر بنیاد رکھی ہے، جو DETER کے دیے ہوئے عمومی ڈیٹوں پر بہت سی زبان اور ماہینے راپوروٹ دیتا ہے، ایک حقیقی زمانہ کی دھوٹ ڈیٹلیٹ مونیٹر جو برزیلین ملی اسپیرس کے انٹیسٹ (INPE) کے ذریعہ توسع ڈا ماتا برازیل پورچوٹ اور انگلیسی میں راپورت پیدا کرتا ہے اور انہیں ٹویٹر پٹرومٹ پر ظاہر کرتا ہے۔ Corpus اور code are publicly available.', 'uz': 'This demo paper introduces DaMata, a robot-journalist covering deforestation in the Brazilian Amazon.  Robot-journalisti Natalik Til Generatish (INPE) yaratilgan bir necha kun va har oy hafta tarkibini yaratadi. Braziliya National Institute for Space Research (INPE) yaratilgan har xil davlatga yaratadi. Name Korpus va kodlash umumiy mavjud.', 'vi': 'This demo paper giới thiệu Damata, một robot-ký giả về gỗ khai hoang trong Amazon Brazil. Người máy-báo cáo dựa trên một kiến trúc ống dẫn của Thế Hệ Ngôn ngữ tự nhiên, nó cung cấp báo cáo hàng ngày và hàng tháng đa dạng, dựa trên dữ liệu công cộng được cấp bởi DETER, một màn hình vệ tinh do thám từ khu rừng bị phát triển và duy trì bởi Viện nghiên cứu vũ trụ Brazil (INPE). Damata tự động phát hành các bản báo cáo bằng tiếng Bồ Đào Nha và Anh Brazil và đăng chúng trên Twitter. Xác sống và mật mã công khai sẵn sàng.', 'bg': 'Тази демо статия представя ДаМата, робот-журналист, отразяващ обезлесяването в Бразилската Амазония. Роботът-журналист се основава на тръбопроводна архитектура на генериране на естествен език, която изготвя многоезични ежедневни и месечни доклади въз основа на публичните данни, предоставени от сателитен монитор за обезлесяване в реално време, разработен и поддържан от Бразилския национален институт за космически изследвания (ИНПЕ). ДаМата автоматично генерира отчети на бразилски португалски и английски език и ги публикува в платформата Туитър. Корпусът и кодът са публично достъпни.', 'nl': 'Deze demo paper introduceert DaMata, een robotjournalist die over ontbossing in de Braziliaanse Amazone gaat. De robotjournalist is gebaseerd op een pipeline-architectuur van Natural Language Generation, die meertalige dagelijkse en maandelijkse rapporten levert op basis van de openbare gegevens verstrekt door DETER, een real-time ontbossingssatelliet monitor ontwikkeld en onderhouden door het Braziliaanse Nationaal Instituut voor Ruimteonderzoek (INPE). DaMata genereert automatisch rapporten in het Braziliaanse Portugees en Engels en publiceert deze op het Twitter-platform. Corpus en code zijn openbaar beschikbaar.', 'hr': 'Ovaj demografski papir predstavlja DaMatu, robotski novinar koji pokriva deforestaciju u Brazilskoj Amazoni. Robot-novinar se temelji na građevinskoj arhitekturi generacije prirodnog jezika, koja daje višejezičke i mjesečne izvještaje na temelju javnih podataka predstavljenih DETER-om, satelitski monitor za stvarno vrijeme deforestacije razvijen i održan Brazilskim Nacionalnim institucijom za istraživanje svemira (INPE). DaMata automatski proizvodi izvješće na Brazilskom portugalskom i engleskom jeziku i objavljuje ih na Twitter platformi. Corpus i kod su javno dostupni.', 'da': 'Denne demo papir introducerer DaMata, en robot-journalist, der dækker skovrydning i den brasilianske Amazonas. Robot-journalisten er baseret på en rørledningsarkitektur af Natural Language Generation, som giver flersprogede daglige og månedlige rapporter baseret på offentlige data leveret af DETER, en satellitskærm i realtid udviklet og vedligeholdt af det brasilianske nationale institut for rumforskning (INPE). DaMata genererer automatisk rapporter på brasiliansk portugisisk og engelsk og offentliggør dem på Twitter-platformen. Korpus og kode er offentligt tilgængelige.', 'de': 'Dieses Demopapier stellt DaMata vor, einen Roboter-Journalisten, der über die Entwaldung im brasilianischen Amazonas berichtet. Der Roboter-Journalist basiert auf einer Pipeline-Architektur von Natural Language Generation, die mehrsprachige Tages- und Monatsberichte liefert, basierend auf den öffentlichen Daten von DETER, einem Echtzeit-Abholzungssatellitenmonitor, der vom brasilianischen Nationalen Institut für Weltraumforschung (INPE) entwickelt und gepflegt wurde. DaMata generiert automatisch Berichte in brasilianischem Portugiesisch und Englisch und veröffentlicht diese auf der Twitter-Plattform. Corpus und Code sind öffentlich zugänglich.', 'id': 'This demo paper introduces DaMata, a robot-journalist covering deforestation in the Brazilian Amazon.  Robot-jurnalis berdasarkan arsitektur pipa dari Generasi Bahasa Alami, yang memberikan laporan berbeda bahasa sehari-hari dan bulanan berdasarkan data publik yang diberikan oleh DETER, monitor satelit deforestation real-time yang dikembangkan dan dikendalikan oleh Institut Nasional Brazil untuk Penelitian Luar Angkasa (INPE). DaMata secara otomatis menghasilkan laporan dalam bahasa Brazil Portugis dan Inggris dan mempublikasikannya di platform Twitter. Corpus and code are publicly available.', 'ko': '이 시연 기사는 브라질 아마존 숲의 벌목을 보도한 로봇 기자인 다마타를 소개했다.로봇 리포터는 자연 언어로 생성된 배관 체계 구조를 바탕으로 델트가 제공한 공공 데이터에 따라 다국어 일간지와 월보를 생성한다. 델트는 브라질 국립우주연구소(INPE)가 개발·유지하는 실시간 산림 벌목 위성 모니터다.다마타는 브라질 포르투갈어와 영어에 대한 보고서를 자동으로 생성해 트위터에 올린다.자료 라이브러리와 코드는 공개된 것이다.', 'sw': 'Gazeti hili la demo linamtambulisha DaMata, mwandishi wa habari wa roboti anayetangaza uharibifu katika eneo la Amazoni Brazil. Mwandishi wa roboti anategemea jengo la ujenzi wa lugha ya asili, ambalo hutoa taarifa za kila siku na kila mwezi kwa kutumia taarifa za umma zinazotolewa na DETER, monitoro la setilaiti kwa muda halisi liliundwa na kutengenezwa na Taasisi ya Taifa ya Utafiti wa Space (INPE) ya Brazil. DaMata anatengeneza taarifa za Kireno na Kiingereza nchini Brazil na inachapisha kwenye jukwaa la Twita. Korpus na sheria zinapatikana hadharani.', 'tr': "Bu demo kagyzy Braziliýa amazóndaky çölegini örän robot-žurnalisti DaMata'y tanyşdyrýar. Robot-žurnalisti Natal Dil Döwletleriniň pipeline arhitekteriýasyna daýanýar. Bu gündelik we a ý sany DETER tarapyndan berilen halk maglumatlaryna döwlet verilýär, bir sany wagt öwrülen we Briziliýa Milli Kosmos Araştyrmalary Instituty (INPE) tarapyndan gelinýär we ýeterlik edýär. DaMata Braziliýa portugalça we iňlisçe habarlaryny otomatik üreýär we olary Twitter platform ünde publikaýar. Ködler we köd publikak içinde bar.", 'fa': 'این کاغذ نمایش داماتا را معرفی می\u200cکند، یک روبات روزنامه\u200cکننده که در آمازون برزیلی پوشش می\u200cدهد. روبات روزنامه\u200cکننده بر اساس یک معماری لوله\u200cهای نسل زبان طبیعی است که روزانه و ماه\u200cها گزارش\u200cهای بسیاری از زبان\u200cها و روزانه بر اساس داده\u200cهای عمومی که توسط DETER داده می\u200cشود، یک موتور ماهواره\u200cهای لرزه\u200cسازی واقعی توسعه می\u200cکند و توسعه\u200cی موسسه ملی برزیلیایی برای تحقی داماتا به طور خودکار گزارش\u200cهایی در پورتوژیک و انگلیسی برزیل تولید می\u200cکند و آنها را روی پلاکتر توئیتر منتشر می\u200cکند. کورپوس و کد عموماً در دسترس هستند.', 'af': "Hierdie demopapier introduseer DaMata, 'n robot-journalist wat die deforestasie in die Braziliaanse Amazon bedek. Die robot-journalist is gebaseer op 'n pipeline arkitektuur van Natuurlike Taal Generasie, wat multitaal daglike en maandelike raporte gegee word, gebaseer op die publieke data wat deur DETER verskaf is, 'n reël-tyd deforestasie satellite monitor ontwikkel en onderhou deur die Braziliese Nasionale Institute for Space Research (INPE). DaMata genereer outomaties raporte in Braziliaanse Portugese en Engels en publiseer dit op die Twitter platform. Korpus en kode is openlik beskikbaar.", 'sq': 'Ky dokument demo prezanton DaMata, një robot-gazetar që mbulon dëbimin e pyjeve në Amazon ën Braziliane. Robot-gazetari bazohet në një arkitekturë tubacioni të Gjenerimit të Gjuhave Natyrore, e cila jep raporte shumëgjuhësore të përditshme dhe mujore bazuar në të dhënat publike të ofruara nga DETER, një mbikqyrës satelitor i deforestimit në kohë reale zhvilluar dhe mbajtur nga Instituti Kombëtar Brazilian për Kërkimin hapësiror (INPE). DaMata automatikisht gjeneron raporte në portugalisht dhe anglisht Brazilian dhe i boton ato në platform ën Twitter. Korpus dhe kodi janë në dispozicion publik.', 'am': 'ይህ አዲስ ወረቀት በBrazilian አማዞን የረቦት ጋዜጠኛ ዳማታ የሚያሳውቃት ነው፡፡ የሮቦት-ጋዜጠኛ የባራሲል ብሔራዊ የስፋት መረጃ (INPE) የተዘጋጀ እና የተደገመ የሰብዓዊ ድረ ገጽ (የብሔራዊ ቋንቋ ልዩ ቋንቋ ትውልድ) በሚያሳየው ብዙ ቋንቋ እና በየወራው ወራት በሚያሳየው የህዝብ ዳታዎችን በመሠረት ላይ የተመሳሳይ የቅርብ ጊዜ የሳተርኔት ሳተላይት ሞክራር የተደገመ ዳማታ በብራዚላዊ ፖርቱጋልኛ እና እንግሊዘኛ ሪፖርት አውጥቷል፡፡ ኮርፓስ እና ኮድ ግልፅ ይገኛሉ።', 'hy': 'Այս դեմո հոդվածը ներկայացնում է Դամատային, ռոբոտ-լրագրողին, որը ծածկում է անտառը Բրազիլիայի Ամազոնում: Ռոբոտ-լրագրողը հիմնված է բնական լեզվի ստեղծման խողովակաշարի ճարտարապետության վրա, որն ամեն օր և ամիս բազլեզու զեկույցներ է տալիս, հիմնված DETER-ի հանրային տվյալների վրա, իրական ժամանակի արտադրման համակարգչային մոնիտոր, որը զարգացվել է և պահպանվում է Բրազիլիայի տիեզ ԴաMata-ը ինքնաբերաբար ստեղծում է զեկույցներ Բրազիլիայի պորտուգալերենով և անգլերենով և հրատարակում է դրանք Թվիթերի հարթակի վրա: Կորպուսը և կոդը հանրային հասանելի են:', 'ca': "Aquest article de demostració presenta DaMata, un robot-periodista que cobre la deforestació a l'Amazònia brasilera. The robot-journalist is based on a pipeline architecture of Natural Language Generation, which yields multilingual daily and monthly reports based on the public data provided by DETER, a real-time deforestation satellite monitor developed and maintained by the Brazilian National Institute for Space Research (INPE).  DaMata genera informes automàticament en portuguès i anglès brasilers i els publica a la plataforma de Twitter. El Corpus i el codi estan disponibles al públic.", 'bs': 'Ovaj demo novinar predstavlja DaMatu, robot a-novinar koji pokriva deforestaciju u Brazilskoj Amazoni. Robot-novinar se temelji na građevinskoj arhitekturi generacije prirodnog jezika, koja daje višejezičke i mjesečne izvještaje na temelju javnih podataka predstavljenih DETER-om, satelitski monitor za stvarno vrijeme deforestacije razvijen i održan Brazilskim Nacionalnim institutom za istraživanje svemira (INPE). DaMata automatski proizvodi izvještaje na Brazilskom portugalskom i engleskom jeziku i objavljuje ih na Twitter platformi. Korpus i kod su javno dostupni.', 'bn': 'এই গণপত্র দামাতাকে ব্রাজিলিয়ার আমাজোনে ধ্বংসের সংবাদ প্রদান করা রোবট-সাংবাদিক দামাতাকে পরিচিত করেছে। রোবট-সাংবাদিক প্রাকৃতিক ভাষা জেনারেশনের একটি পাইপেলাইন স্থাপনের ভিত্তিতে ভিত্তি করেছেন, যা ডেটের দ্বারা প্রদান করা জনগণের তথ্যের ভিত্তিতে বহুভাষী এবং মাসিক রিপোর্ট দিয়েছেন দামাতা স্বয়ংক্রিয়ভাবে ব্রাজিলীয় পর্তুগীজ এবং ইংরেজীতে রিপোর্ট তৈরি করে টুইটার প্ল্যাটফর্মে তাদের প্ কোর্পাস এবং কোড প্রকাশ্যে পাওয়া যাচ্ছে।', 'az': "Bu demo kağıdı Braziliyan Amazondakı yoğunluğu örtüb edən robot-žurnalisti DaMata'yı tanıyır. Robot-žurnalisti Təbiətli Dil Məxluqatının qurbanlıq arhitektarına dayanır. Bu, DETER tarafından verilən halqlıq məlumatlarına dayanan çoxlu dil və aylıq raporlarını verir. Bu, Brezilya Milli Kosmos Araştırması Institute for Space Research (INPE) tarafından hazırlanmış və qoruyub saxlanmış, həqiqət zamanlı qurma uydu monitori. DaMata Braziliyalı Portugalca və İngilizce olaraq xəbərlər təşkil edir və onları Twitter platform ündə yayındır. Corpus və kodu açıq-aşkar mövcuddur.", 'et': 'See demotöö tutvustab DaMatat, robotajakirjanik, kes räägib Brasiilia Amazonase metsade hävitamisest. Robot-ajakirjanik põhineb Natural Language Generation torujuhtme arhitektuuril, mis koostab mitmekeelseid iga päev- ja kuuaruandeid, mis põhinevad Brasiilia Rahvusliku Kosmoseuuringute Instituudi (INPE) väljatöötatud ja hallatava reaalajas raadamise satelliitseire DETER avalikel andmetel. DaMata genereerib automaatselt aruanded Brasiilia portugali ja inglise keeles ning avaldab need Twitteri platvormil. Korpus ja kood on avalikult kättesaadavad.', 'fi': 'Tässä demojulkaisussa esitellään DaMata, robotti-toimittaja, joka käsittelee metsäkadoa Brasilian Amazonissa. Robotti-toimittaja perustuu Natural Language Generation -putkiarkkitehtuuriin, joka tuottaa monikielisiä päivittäisiä ja kuukausittaisia raportteja, jotka perustuvat Brasilian kansallisen avaruustutkimuslaitoksen (INPE) kehittämään ja ylläpitämään reaaliaikaiseen metsäkadon satelliittimonitoriin DETER:iin. DaMata luo automaattisesti raportteja Brasilian portugaliksi ja englanniksi ja julkaisee ne Twitter-alustalla. Korpus ja koodi ovat julkisesti saatavilla.', 'cs': 'Tento demo příspěvek představuje DaMata, robotického novináře zabývajícího se odlesňováním v brazilské Amazonii. Robot-novinář je založen na architektuře potrubí Natural Language Generation, která vytváří vícejazyčné denní a měsíční zprávy založené na veřejných datech poskytnutých DETER, satelitní monitor odlesňování v reálném čase vyvinutý a udržovaný brazilským národním institutem pro kosmický výzkum (INPE). DaMata automaticky generuje reporty v brazilském portugalštině a angličtině a publikuje je na platformě Twitter. Corpus a kód jsou veřejně dostupné.', 'jv': 'Awak-awak dhéwé iki nggawe Damata, Perintah-Perintah sing paling-perintah bot nang awak dhéwé basa sing ngenggukaaké awak dhéwé padha awak dhéwé. Radio Damata mbut ngewehke mbut kuwi nggawe barang portugis karo Inggris barang karo nganggo cara-cara kuwi nèng pengguna Tom. Kobudhakan karo kode kang dipuluhayo', 'sk': 'Ta demo članek predstavlja DaMata, robotsko novinarko, ki pokriva krčenje gozdov v Braziliji Amazonki. Robot-novinar temelji na arhitekturi cevovoda Natural Language Generation, ki pripravlja večjezična dnevna in mesečna poročila na podlagi javnih podatkov DETER, satelitskega monitorja krčenja gozdov v realnem času, ki ga je razvil in vzdrževal Brazilijski Nacionalni inštitut za vesoljske raziskave (INPE). DaMata samodejno ustvari poročila v brazilski portugalščini in angleščini ter jih objavi na platformi Twitter. Corpus in koda sta javno dostopna.', 'ha': 'Wannan karatun mutane yana gaya DaMata, wani rubuci mai kwatsan da ke rufe dama a cikin Amzon ya Breziliya. The Robot-journin is based on an architecture of Natural Lugha Kizalishi, which offers multi-daily da yearli, a based on data ga mutane da DATAR, an developed and retarda a real-time satelitan satura na tsare na Installar National Installation for Space Research (INPA). @ info Ana iya ƙayyade umarni da kodi.', 'he': 'העיתון הדמו הזה מציג את דאמאטה, עיתונאית רובוטית מכסה את העצירות באמזון הברזילית. הרובוט-עיתונאי מבוסס על ארכיטקטורת צינור של גרינת שפות טבעיות, שמוציאת דוחות רבות שפות יומיים ובחודשיים מבוססים על נתונים ציבוריים שנוספים על ידי DETER, מוניטור לוויני היער בזמן אמיתי שפותח ומשמר על ידי המכון הלאומי של ברזיל למחקר חלל (INPE). DaMata מייצר באופן אוטומטי דיווחים בפורטוגזית ובאנגלית ברזילית ומוציא אותם על פלטפורמת הטוויטר. קורפוס וקוד זמינים לציבור.', 'bo': 'སྤྱི་ཁོང་གི་ཤོག་བུ་འདིས་Brazilian Amazon་ནང་དུ་སྐྱེས་པའི་བརྡ་སྤྲོད་པ་ཞིག་གིས་DaMata་ལ་སྟོན་ཐུབ་པ་རེད། The robot-journalist is based on a pipeline architecture of Natural Language Generation, which yields multilingual daily and monthly reports based on the public data provided by DETER, a real-time deforestation satellite monitor developed and maintained by the Brazilian National Institute for Space Research (INPE). DaMata རང་འགུལ་གྱིས་བྷི་ར་ཛིལ་སི་པོ་རོཊ་ཇིས་དང་ཨིན་རིའི་ནང་ཚོར་བརྡ་གསར་འཛུགས་བྱེད་ཀྱི་ཡོད། རྩིས་འཁོར་དང་ཨང་རྟགས་སྤྱོད་མང་ཆོག་ཡོད་པ'}
{'en': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'ar': 'الأبوة والأمومة من خلال التعلم التعزيزي الملحد للنموذج لتصحيح السلوكيات المرضية في توليد البيانات إلى نص', 'fr': "Parenting via l'apprentissage par renforcement agnostique des modèles pour corriger les comportements pathologiques dans la génération de données en texte", 'es': 'La crianza de los hijos a través del aprendizaje de refuerzo independiente del modelo para corregir comportamientos patológicos en la generación de datos a texto', 'pt': 'PARENTING via Aprendizagem de Reforço de Modelo Agnóstico para Corrigir Comportamentos Patológicos na Geração de Dados para Texto', 'ru': 'PARENTing through Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation («Обучение анализу с помощью модели-агностического усиления для коррекции патологического поведения при генерации данных в текст»)', 'ja': 'データからテキストへの生成における病理学的行動を修正するためのモデル認識的強化学習を介したPARENTING', 'zh': '騰먼쪽駱뵗ARENTing,坍봱솎賴썮듼', 'hi': 'मॉडल-अज्ञेयवादी सुदृढीकरण सीखने के माध्यम से PARENTing डेटा-टू-टेक्स्ट जनरेशन में पैथोलॉजिकल व्यवहार को सही करने के लिए सीखना', 'ga': 'Tuismitheoireacht trí Mhúnla-Atreisiú Agnostic Ag Foghlaim le hIompar Paiteolaíocha a cheartú i nGiniúint Sonraí go Téacs', 'ka': 'PARENTing', 'el': 'Μάθηση για τη διόρθωση παθολογικών συμπεριφορών στη δημιουργία δεδομένων σε κείμενο', 'hu': 'A kóros viselkedések javításának tanulása az adatok szöveges generálásában', 'it': 'Imparare a correggere i comportamenti patologici nella generazione di dati a testo', 'kk': 'PARENTing via Model- Agnostic Reinforcement Learning to Correct Pathological Behaviours in Data- to- Text Generation', 'mk': 'ПАРЕНТИРАЊЕ преку модел-агностичко зајакнување на учењето за корекција на патолошките однесувања во генерацијата на податоци до текст', 'lt': 'PARENTavimas naudojant Agnostikos stiprinimo modelį Mokymasis koreguoti patologinį elgesį duomenų–teksto generacijoje', 'ms': 'PARENTing melalui Model-Agnostic Reinforcement Learning to Correct Pathological behaviors in Data-to-Text Generation', 'mt': 'PARENTAZZJONI permezz ta’ Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'mn': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviour in Data-to-Text Generation', 'ml': 'വിവരങ്ങളില്\u200d നിന്നും ടെക്സ്റ്റ് ജനിപ്പിക്കുന്നതിലേക്കുള്ള പാത്തോളോഗിക്കല്\u200d സ്വഭാവങ്ങള്\u200d ശരിയാക്കുവാന്\u200d പഠിക്ക', 'no': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviour in Data-to-Text Generation', 'ro': 'Învățarea de a corecta comportamentele patologice în generarea de date în text', 'sr': 'PARENTING kroz Model-Agnostičko pojačanje učenja za ispravljanje patoloških ponašanja u generaciji podataka do teksta', 'pl': 'PARENTOWANIE poprzez Model-Agnostic Enforcement Uczenie się korygowania zachowań patologicznych w generowaniu danych do tekstu', 'so': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological behaviours in Data-to-Text Generation', 'sv': 'Föräldrar via Model-Agnostic Reinforcement Lära sig att korrigera patologiska beteenden i Data-to-Text Generation', 'ta': 'தகவல்- முதல் உரை உருவாக்கத்தில் சரியான பாதோலோகிய செயல்பாடுகளுக்கு கற்றுக் கொடுப்பு மாதிரி- குறுக்கும் பிரிவு', 'si': 'PARENTing', 'ur': 'ماڈل-اگنیٹ کے ذریعہ سیکھنے کی سفارش دینے کے لئے ڈاٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ-ٹ', 'vi': 'Công bố thông qua Mô hình-Agnosic tiếp sức học để sửa chữa hành vi bệnh hoạn trong chế độ dữ liệu sang Văn bản', 'uz': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'bg': 'Учене за коригиране на патологичните поведения при генериране на данни към текст', 'nl': 'PARENTING via Model-Agnostic Reinforcement Learning om pathologisch gedrag te corrigeren bij het genereren van gegevens naar tekst', 'hr': 'PARENTING putem modela-Agnostičkog pojačanja učenje za ispravljanje patoloških ponašanja u generaciji podataka do teksta', 'da': 'Læring til at korrigere patologisk adfærd i data-til-tekst generering', 'de': 'PARENTING mittels Model-Agnostic Reinforcement Learning zur Korrektur pathologischer Verhaltensweisen bei der Daten-zu-Text-Generierung', 'fa': 'PARENTing via Model-Agnostic Strengthening Learning to Correct Pathological Behaviours in Data-to-Text Generation', 'id': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'ko': '모델을 통해 알 수 없는 강화 학습을 통해 데이터가 텍스트 생성에서의 병리 행위를 바로잡다', 'sw': 'Uchambuzi wa PARENI kupitia Ufumbuzi wa Model-Agnostic Kujifunza kwa Kusahihisha tabia za Kihological katika Uzalishaji wa Taarifa-hadi-maandishi', 'tr': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'af': 'Bepaal deur Model- Agnostiese Versterking Leer om Pathologiese Gedrag te korrigeer in Data- to- Text Generasie', 'am': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'sq': 'PARENTING nëpërmjet Model-Agnostic Reinforcement Mësimi për Korrektimin e sjelljeve patologjike në gjenerimin e të dhënave në tekst', 'az': 'PARENTing through Model-Agnostic Reinforcement Learning to Correct Pathological Behaviours in Data-to-Text Generation', 'hy': 'ՊԱՏԵՆՏՈւթյունը Մոդել-ագնոստիկ ուժեղացման միջոցով Փոտոլոգիական վարքագիծը ճիշտ սովորելը տվյալների տեքստի ընթացքում', 'bn': 'ডাটা থেকে টেক্সট প্রজন্মের মাধ্যমে মোডেল-আগনোস্টিক পুনর্গঠন শিক্ষা শিক্ষা প্রদান করা হচ্ছে', 'ca': 'PARENT a través de Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation', 'bs': 'PARENTING kroz Model-Agnostičko pojačanje učenje za ispravljanje patoloških ponašanja u generaciji podataka do teksta', 'cs': 'PARENTING prostřednictvím Model-Agnostic Enforcement Learning pro korekci patologických chování při generování dat na text', 'fi': 'PARENTOINTI Model-Agnostic Reforcement Oppiminen korjaamaan patologisia käyttäytymisiä datasta tekstiin -generoinnissa', 'et': 'PARENTeerimine mudeli-agnostilise tugevdamise abil patoloogiliste käitumiste korrigeerimiseks andmete-teksti genereerimisel', 'sk': 'PARENTiranje prek učenja modela-agnostične okrepitve za popravljanje patoloških vedenj pri ustvarjanju podatkov v besedilo', 'he': 'ההתנהגות באמצעות גיבוי אגנוסטי מודל ללמוד לתקן התנהגות פטולוגיות ביצירת נתונים לטקסט', 'ha': 'KCharselect unicode block name', 'jv': 'PAREENTing by Mode-Aostc Regforcement Learning to rectct Path Effects in data-to-Text Generation', 'bo': 'PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation'}
{'en': 'In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e., hallucinations or omissions), and to incorporate them erroneously in their own generations at inference. In this work, we build on top of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions. Evaluations on the widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this framework compared to state-of-the-art models.', 'fr': "Dans les modèles de génération de langage conditionnés par des données structurées, l'entraînement classique via le maximum de vraisemblance conduit presque toujours les modèles à détecter la divergence des ensembles de données (c'est-à-dire des hallucinations ou des omissions), et à les incorporer de manière erronée dans leurs propres générations lors de l'inférence. Dans ce travail, nous nous appuyons sur les approches précédentes basées sur l'apprentissage par renforcement et montrons qu'un framework agnostique basé sur la métrique PARENT récemment introduite est efficace pour réduire à la fois les hallucinations et les omissions. Les évaluations des benchmarks WikiBio et WebNLG largement utilisés démontrent l'efficacité de ce framework par rapport aux modèles de pointe.", 'pt': 'Em modelos de geração de linguagem condicionados por dados estruturados, o treinamento clássico via máxima verossimilhança quase sempre leva os modelos a captar divergências de conjuntos de dados (ou seja, alucinações ou omissões) e incorporá-los erroneamente em suas próprias gerações na inferência. Neste trabalho, construímos sobre abordagens anteriores baseadas em Aprendizado por Reforço e mostramos que uma estrutura agnóstica de modelo baseada na métrica PARENT recentemente introduzida é eficiente na redução de alucinações e omissões. Avaliações nos benchmarks WikiBIO e WebNLG amplamente utilizados demonstram a eficácia dessa estrutura em comparação com modelos de última geração.', 'es': 'En los modelos de generación de lenguaje condicionados por datos estructurados, el entrenamiento clásico a través de la máxima verosimilitud casi siempre lleva a los modelos a captar la divergencia de los conjuntos de datos (es decir, alucinaciones u omisiones) y a incorporarlos erróneamente en sus propias generaciones en la inferencia. En este trabajo, nos basamos en enfoques anteriores basados en el Aprendizaje por Refuerzo y demostramos que un marco independiente del modelo que se basa en la métrica PARENT recientemente introducida es eficiente para reducir tanto las alucinaciones como las omisiones. Las evaluaciones de los puntos de referencia ampliamente utilizados de WikiBio y WebNLG demuestran la eficacia de este marco en comparación con los modelos más avanzados.', 'ar': 'في نماذج توليد اللغة المشروطة ببيانات منظمة ، يؤدي التدريب الكلاسيكي عبر أقصى احتمال تقريبًا إلى قيام النماذج دائمًا بالتقاط تباعد مجموعة البيانات (أي الهلوسة أو الإغفالات) ، ودمجها بشكل خاطئ في أجيالهم عند الاستدلال. في هذا العمل ، نبني على المناهج السابقة القائمة على التعلم المعزز ونبين أن إطار العمل الحيادي النموذج الذي يعتمد على مقياس PARENT الذي تم تقديمه مؤخرًا فعال في تقليل كل من الهلوسة والإغفالات. تُظهر التقييمات على معايير WikiBIO و WebNLG المستخدمة على نطاق واسع فعالية هذا الإطار مقارنة بأحدث النماذج.', 'zh': '以结构化数为言,大似然之经,几于见数(幻遗),误合之世。 此立于强化之术,而恃近引之PARENT指标不可知框架可以有效而损幻遗也。 博用之WikiBIO,与WebNLG准之评验,比于先进之形,当框架之有效性。', 'ja': '構造化データによって条件付けられた言語生成モデルでは、最大尤度を介した古典的トレーニングは、ほとんどの場合、モデルがデータセットの乖離（すなわち、幻覚または省略）を検出し、推論でそれらを誤って自身の世代に組み込むことにつながる。この研究では、以前の強化学習ベースのアプローチに基づいて構築し、最近導入された親指標に依存するモデル非推測フレームワークが、幻覚と省略の両方を低減するのに効率的であることを示します。広く使用されているWikiBIOおよびWebNLGベンチマークに関する評価は、最先端のモデルと比較して、このフレームワークの有効性を示しています。', 'hi': 'संरचित डेटा द्वारा वातानुकूलित भाषा पीढ़ी के मॉडल में, अधिकतम संभावना के माध्यम से शास्त्रीय प्रशिक्षण लगभग हमेशा मॉडल को डेटासेट विचलन (यानी, मतिभ्रम या चूक) पर लेने के लिए प्रेरित करता है, और उन्हें अनुमान पर अपनी पीढ़ियों में गलत तरीके से शामिल करने के लिए। इस काम में, हम पिछले सुदृढीकरण सीखने आधारित दृष्टिकोणों के शीर्ष पर निर्माण करते हैं और दिखाते हैं कि हाल ही में पेश किए गए माता-पिता मीट्रिक पर भरोसा करने वाला एक मॉडल-अज्ञेयवादी ढांचा मतिभ्रम और चूक दोनों को कम करने में कुशल है। व्यापक रूप से उपयोग किए जाने वाले WikiBIO और WebNLG बेंचमार्क पर मूल्यांकन अत्याधुनिक मॉडल की तुलना में इस ढांचे की प्रभावशीलता को प्रदर्शित करते हैं।', 'ru': 'В моделях генерации языков, основанных на структурированных данных, классическое обучение с максимальной вероятностью почти всегда приводит к тому, что модели подхватывают расхождения в наборах данных (т.е. галлюцинации или упущения) и ошибочно включают их в свои собственные поколения при выводе. В этой работе мы основываемся на предыдущих подходах, основанных на обучении подкреплению, и показываем, что модельно-диагностическая структура, основанная на недавно введенной РОДИТЕЛЬСКОЙ метрике, эффективна для уменьшения как галлюцинаций, так и пропусков. Оценки широко используемых эталонов WikiBIO и WebNLG демонстрируют эффективность этой структуры по сравнению с современными моделями.', 'ga': 'I múnlaí giniúna teanga arna riochtú ag sonraí struchtúrtha, de thoradh na hoiliúna clasaiceacha trí uas-dóchúlacht beagnach i gcónaí faigheann múnlaí eolas ar éagsúlacht tacar sonraí (i.e. siabhránachtaí nó easnaimh), agus iad a ionchorprú go hearráideach ina nglúin féin ag an tátal. San obair seo, cuirimid leis na cineálacha cur chuige atá bunaithe ar Fhoghlaim Neartaithe a bhí ann roimhe seo agus léirímid go bhfuil creat samhail-agnostic ag brath ar mhéadrach PARENT a tugadh isteach le déanaí éifeachtach chun siabhránachtaí agus easnaimh a laghdú. Léiríonn meastóireachtaí ar thagarmharcanna WikiBIO agus WebNLG a úsáidtear go forleathan éifeachtacht an chreata seo i gcomparáid le samhlacha úrscothacha.', 'ka': 'ენის წარმოდგენის მოდელში, რომელიც სტრუქტურებული მონაცემებით შემდეგ კლასიკალური განათლება მაქსიმალური შესაძლებელობის გამოყენებაში უფრო ყოველთვის მოდელეების შესაძლებელობაში გადაიყენება მონაცემების განსხვავებას (მაგალითა ამ სამუშაოში, ჩვენ წინა სწავლების დამატებით დავიწყებთ და გამოჩვენებთ, რომ მოდელური ადნოსტიური ფრამეტრი, რომელიც მხოლოდ დავიწყებულია PARENT მეტრიკის მეტრიკის დამატებით ეფექტიურია, რომელიც უფრო გამოიყენებული ვიკიბიო და WebNLG ბანქმერის განსაზღვრებები გამოყენებულია ამ ფრამეტრის ეფექტიურობა, რომელიც შემდეგ სურათის მოდელთან.', 'hu': 'A strukturált adatok által feltételezett nyelvgenerációs modellekben a klasszikus képzés a maximális valószínűséggel szinte mindig arra készteti a modelleket, hogy felismerjék az adatkészleteltéréseket (azaz hallucinációkat vagy mulasztásokat), és következtetésekor tévesen beépítsék őket a saját generációjukba. Ebben a munkában a korábbi megerősítési tanuláson alapuló megközelítésekre építünk, és megmutatjuk, hogy egy modell-agnosztikus keretrendszer, amely a nemrégiben bevezetett szülői metriára támaszkodik, hatékonyan csökkenti a hallucinációkat és a mulasztásokat. A széles körben használt WikiBIO és WebNLG referenciaértékelések bizonyítják ennek a keretrendszernek a legkorszerűbb modellekhez képest való hatékonyságát.', 'el': 'Στα μοντέλα δημιουργίας γλωσσών που εξαρτώνται από δομημένα δεδομένα, η κλασική εκπαίδευση μέσω μέγιστης πιθανότητας οδηγεί σχεδόν πάντα τα μοντέλα να πιάσουν αποκλίσεις συνόλων δεδομένων (δηλαδή παραισθήσεις ή παραλείψεις), και να τα ενσωματώσουν εσφαλμένα στις δικές τους γενιές κατά την εξαγωγή. Σε αυτή την εργασία, χτίζουμε πάνω από προηγούμενες προσεγγίσεις που βασίζονται στη Μάθηση Ενίσχυσης και καταδεικνύουμε ότι ένα μοντέλο-αγνωστικό πλαίσιο που βασίζεται στην πρόσφατα εισαγόμενη μετρική είναι αποτελεσματικό στη μείωση τόσο των παραισθήσεων όσο και των παραλείψεων. Αξιολογήσεις των ευρέως χρησιμοποιούμενων κριτηρίων αναφοράς WikiBIO και WebNLG καταδεικνύουν την αποτελεσματικότητα αυτού του πλαισίου σε σύγκριση με μοντέλα τελευταίας τεχνολογίας.', 'it': "Nei modelli di generazione linguistica condizionati da dati strutturati, la formazione classica con la massima probabilità porta quasi sempre i modelli a cogliere la divergenza dei set di dati (cioè allucinazioni o omissioni) e ad incorporarli erroneamente nelle proprie generazioni. In questo lavoro, ci avvaliamo dei precedenti approcci basati sull'apprendimento di rinforzo e mostriamo che un quadro modello-agnostico basato sulla metrica PARENT recentemente introdotta è efficiente nel ridurre sia le allucinazioni che le omissioni. Le valutazioni sui benchmark WikiBIO e WebNLG ampiamente utilizzati dimostrano l'efficacia di questo framework rispetto ai modelli all'avanguardia.", 'kk': 'Құрылған деректер арқылы құрылған тілдер үлгілерінде классикалық оқыту максималдық мүмкіндіктері арқылы әрқашанда деректер жиындарының дивергенциясын (т.е. халлюзиялар немесе тапсырмаларды) алу үшін үлгілерін жасайды, және оларды өз әле Бұл жұмыс ішінде біз алдыңғы жақсарту оқиға негізделген арқылы құрамыз және соңғы келтірілген PARENT метрикасына сенетін үлгі агностикалық қоршауын көрсету үшін аллюцинацияларды және келмейді. Жалпы қолданылатын WikiBIO және WebNLG бағдарламаларының оқиғалары бұл бағдарламалардың күй- жайы моделдеріне салыстырылып тұратынын көрсетеді.', 'lt': 'Kalbų kūrimo modeliuose, kuriuos sąlygoja struktūrizuoti duomenys, klasikinis mokymas didžiausiomis tikimybėmis beveik visada lemia modelius nustatyti duomenų rinkinio skirtumus (t. y. haliucinacijas ar nepakankamumas) ir klaidingai įtraukti juos į savo pači ų kartų išvadose. Šiame darbe mes remiamės ankstesniais mokymosi sustiprinimu metodais ir parodomi, kad modelio agnostinė sistema, grindžiama neseniai įvesta PARENT metrija, veiksmingai mažina haliucinacijas ir praleidimus. Įvertinus plačiai naudojamus WikiBIO ir WebNLG lyginamuosius rodiklius įrodomas šios sistemos veiksmingumas, palyginti su naujausiais modeliais.', 'ms': 'Dalam model generasi bahasa yang dikundisikan oleh data struktur, latihan klasik melalui kemungkinan maksimum hampir sentiasa memimpin model untuk mengambil pada pelbagai set data (iaitu halusinasi atau ketiadaan), dan untuk memasukkannya dengan salah dalam generasi mereka sendiri pada kesimpulan. Dalam kerja ini, kami membina di atas pendekatan yang berdasarkan Penyukuran Penyukuran terdahulu dan menunjukkan bahawa kerangka model-agnostik bergantung pada metrik PARENT yang baru-baru ini diperkenalkan adalah efisien dalam mengurangi kedua-dua halusinasi dan ketidakhadiran. Penghargaan pada tanda referensi WikiBIO dan WebNLG yang digunakan luas menunjukkan keefektivitas kerangka ini dibandingkan dengan model-model-state-of-the-art.', 'mk': 'Во моделите на генерација на јазици условени со структурирани податоци, класичната обука преку максимална веројатност речиси секогаш води до прифаќање на дивергенцијата на податоците (т.е. халуцинации или омисии), и грешно нивно вмешање во нивните генерации по инференција. Во оваа работа, ние изградуваме врз претходните пристапи базирани на зајакнување на учењето и покажуваме дека модел-агностичка рамка која се потпира на неодамна воведената метрика на ПАРЕНТ е ефикасна за намалување на халуцинациите и пропуштањата. Оценувањата на широко употребените споредби на WikiBIO и WebNLG ја покажуваат ефикасноста на оваа рамка во споредба со најновите модели.', 'ml': 'നിര്\u200dമ്മിതമായ വിവരങ്ങള്\u200d കൊണ്ട് നിര്\u200dമ്മിക്കപ്പെട്ട ഭാഷ തലമുറകളില്\u200d, ഏറ്റവും കൂടുതല്\u200d സാധ്യതയുള്ള പരിശീലനത്തില്\u200d ക്ലാസിക്കല്\u200d പരിശീലനം എപ്പോഴും ഡാറ്റാസെറ്റിന്റെ  ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d മുമ്പുള്ള വിവരങ്ങളുടെ അടിസ്ഥാനത്ത് പഠിപ്പിക്കുന്ന മുകളില്\u200d പണിയുകയും, അടുത്തുതന്നെ പാരെന്\u200dറ് മെട്രിക്കില്\u200d ആശ്രയിക്കുന്ന ഒരു  വികിബിയോയും വെബ്നെന്\u200dഎല്\u200dജി ബെന്\u200dമാര്\u200dക്കുകളും വിശാലമായി ഉപയോഗിക്കുന്ന ഈ ഫ്രെയിമ്പിന്റെ പ്രവർത്തികമാണ് ഈ ഫ്രെയിമ്പിന', 'mt': 'Fil-mudelli tal-ġenerazzjoni tal-lingwi kkundizzjonati minn dejta strutturata, it-taħriġ klassiku permezz ta’ probabbiltà massima kważi dejjem iwassal għall-mudelli biex jiksbu d-diverġenza tas-sett tad-dejta (jiġifieri alluċinazzjonijiet jew ommissjonijiet), u biex jinkorporawhom b’mod żbaljat fil-ġenerazzjonijiet tagħhom stess fl-inferenza. F’dan ix-xogħol, a ħna nibnu fuq approċċi preċedenti bbażati fuq it-Tagħlim ta’ Rinforzament u nuru li qafas mudell-agnostiku li jiddependi fuq il-metrika PARENT introdotta reċentement huwa effiċjenti fit-tnaqqis kemm tal-alluċinazzjonijiet kif ukoll tal-ommissjonijiet. Evalwazzjonijiet dwar il-punti ta’ riferiment WikiBIO u WebNLG użati b’mod wiesa’ juru l-effettività ta’ dan il-qafas meta mqabbel mal-mudelli l-aktar avvanzati.', 'no': 'I språk-genereringsmodeller som er conditionert av strukturerte data, vil klassiske opplæring ved høgste sannsynligheten nesten alltid føre til modeller til å henta opp datasett-forskjellighet (t.d. hallusinasjonar eller omisisjonar), og å inkludere dei feil i dei eige generasjonane ved infeksjon. I dette arbeidet bygger vi øvre på tidlegare forstørringsbaserte tilnærmingar og viser at eit modell-agnostisk rammeverk som tilhøyrer den nyleg introduserte PARENT-metriken er effektivt ved å redusera både halusinasjonar og utslutningar. Evalueringar på de breidde brukte WikiBIO- og WebNLG-benchmarkene viser effektiviteten av dette rammeverket i sammenligning med kunstmodeller.', 'pl': 'W modelach generowania języków uwarunkowanych danymi ustrukturyzowanymi, klasyczne szkolenie poprzez maksymalne prawdopodobieństwo prawie zawsze prowadzi do wykorzystania rozbieżności zbiorów danych (tj. halucynacji lub pominięć) i do błędnego włączenia ich do własnych pokoleń przy wnioskowaniu. W niniejszej pracy opieramy się na poprzednich podejściach opartych na uczeniu się wzmocnienia i pokazujemy, że ramy agnostyczne oparte na wprowadzonej niedawno metryce PARENT są skuteczne w redukcji halucynacji i pominięć. Oceny szeroko stosowanych wskaźników referencyjnych WikiBIO i WebNLG pokazują skuteczność tego frameworku w porównaniu z najnowocześniejszymi modelami.', 'mn': 'Бүтээгдэхүүний өгөгдлийн шаардлагатай хэлний үеийн төрөлхтний загвар дээр, хамгийн их боломжтой байдлын дасгал хөдөлгөөн нь бараг л үргэлж өгөгдлийн сангийн өөрчлөлт (яг л халуулах, эсвэл алдагдах) загваруудыг ашиглах боломжтой болгодог. Энэ ажлын дээр бид өмнөх давхарлалтын суралцах суралцах сургалтын төвшин дээр бий болгож, саяхан танилцуулсан PARENT метрик дээр байдаг загварын агностик хэлбэрүүдийг багасгах болон алдагдлыг багасгах хэрэгтэй гэдгийг харуулж байна. WikiBIO болон WebNLG салбарт ашигласан өргөн хэрэглэгдсэн дүгнэлт нь энэ хэлбэрийн үр дүнг урлагийн загвартай харьцуулдаг.', 'ro': 'În modelele de generare a limbilor condiționate de date structurate, formarea clasică prin probabilitate maximă determină aproape întotdeauna modelele să recunoască divergențele seturilor de date (adică halucinații sau omisiuni) și să le încorporeze eronat în propriile generații la deducție. În această lucrare, ne bazăm pe abordările anterioare bazate pe Reinforcement Learning și arătăm că un cadru model-agnostic bazat pe metrica PARENT recent introdusă este eficient în reducerea atât halucinațiilor, cât și a omisiunilor. Evaluările referitoare la criteriile WikiBIO și WebNLG utilizate pe scară largă demonstrează eficacitatea acestui cadru în comparație cu modelele de ultimă generație.', 'sr': 'U modelima generacije jezika pod uslovom strukturiranih podataka, klasična obuka putem maksimalne verovatnosti skoro uvek vodi modele da se pokupi razlike u setu podataka (tj. halucinacije ili omisije), i da ih pogrešno uključuju u svoje generacije na infekciju. U ovom poslu, izgradili smo na vrhu prethodnih pristupa na osnovu učenja pojačanja i pokazali da je model-agnostički okvir koji se oslanja na nedavno uvedenu metriku PARENT efikasan u smanjenju halucinacija i bezbednosti. Procjenjivanja široko korištenih kriterija WikiBIO i WebNLG pokazuju učinkovitost ovog okvira u usporedbi sa modelima stanja umjetnosti.', 'si': 'භාෂාව පරීක්ෂණ මොඩල් සංවිධානය කරලා සංවිධානය කරලා තියෙන්නේ, ක්ලාසික සංවිධානය විසින් විශේෂ ප්\u200dරධානය විසින් හැමවෙලේම මොඩල් අරගෙන යන්න මේ වැඩේදී, අපි පසුගින් විශ්වාස කරන්න පුළුවන් විශ්වාස කරනවා ඉගෙන ගන්න අධාරිත විදියට සහ පෙන්වන්න පුළුවන් විදියට පෙන්වන්නේ මොඩේල්- විකිබියෝ සහ WebNLG බෙන්ච්මාර්ක්ස් වල විශ්වාස කරලා තියෙන්නේ මේ පරීක්ෂණයේ ප්\u200dරශ්ණතාවය පෙන්වන්නේ මේ පරීක්ෂණ', 'sv': 'I språkgenerationsmodeller som styrs av strukturerade data leder den klassiska utbildningen med maximal sannolikhet nästan alltid modellerna till att fånga upp datauppsättningsskillnader (dvs hallucinationer eller utelämnanden) och att felaktigt införliva dem i sina egna generationer vid slutsatsen. I detta arbete bygger vi vidare på tidigare Reinforcement Learning-baserade tillvägagångssätt och visar att ett modellagnostiskt ramverk som bygger på den nyligen introducerade föräldramätaren är effektivt för att minska både hallucinationer och utelämnanden. Utvärderingar av de allmänt använda WikiBIO- och WebNLG-riktmärkena visar hur effektiva ramverket är jämfört med de senaste modellerna.', 'so': "Tilmaamaha qaranka afka oo lagu sharrajiyey macluumaadka aasaaska ah, waxbarashada fasaxda e e ugu dhaqdhaqaaqsan sida ugu dhaqsaha ah ayaa mar walba ku hoggaamiya tusaalayaal in lagu soo qaado isbedelka danbiyada (tusaale ahaan hallucinations ama tababaridaha) iyo in lagu soo galo qarniyadooda si qalloocan ah waqtiga ay u baabba'aan. Markaas waxan, waxaynu ku dhisaynaa qaabab hore oo ku saleysan waxbarashada, waxaana tusaynaa in tusaale-qaab aragnostik ah oo ku tiirsanaya dhaqdhaqaaqa loo soo bandhigay PARENT ay faa’iido u leedahay inay hoosaysiiyaan daahirinta iyo dhamaanka. Qiimeynta ku saabsan WikiBIO iyo WebNLG waxyaabaha lagu isticmaali karo waxay muujiyaan shaqaalaha frameshan sameynta sameynta tusaalaha farshaxanka.", 'ta': 'உருவாக்கப்பட்ட தரவு மாதிரிகளில், அதிகபட்ச ச சாத்தியமான பயிற்சியின் மூலம் எப்போதும் தரவு அமைப்புகளின் வேறுபாடு மாதிரிகளை எடுத்துக் கொள்ள முடியும் (அதாவது, பாதிப்ப In this work, we build on top of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions.  WikiBIO மற்றும் WebNLG குறிப்புகளின் விரிவாக்கத்தை வெளிப்படையாக்குகிறது இந்த சட்டத்தின் விளைவுகளை நிலையான- கலை மாதிரிகளை ஒப்ப', 'ur': 'زبان کی نسل نمونڈلوں میں جو ساختہ ڈیٹا سے کنڈیسی کر رہے ہیں، کلاسیک تعلیم مزید احتمال کے ذریعہ تقریباً ہمیشہ ڈیٹ سٹ کے اختلاف پر موڈلوں کو اٹھانے کے لئے پیش کرتا ہے (یعنی hallucinations or omissions) اور ان کو اپنی نسلوں میں غلط طریقہ سے داخل کرتا ہے۔ اس کام میں ہم اگلے نیٹ فورسمینٹ سیکھنے کی روش پر بناتے ہیں اور دکھاتے ہیں کہ اچھے معلوم ہونے والے PARENT میٹریک پر بھروسہ ایک موڈل-agnostic فرم ہے جو ہلکوسینٹ اور چھوڑنے کے ذریعہ مفید ہے۔ ویکبی یو اور ویب NLG بانچمارک کے بارے میں وسیع استعمال کئے جاتے ہیں، اس فرم کی عملکرد کو اس حالت کی آرتی موڈل کے مقابلے میں دکھاتے ہیں.', 'uz': "Name Bu ishda, biz oldingi Reinfrastructur o'rganish asosida o'rganish usullarning yuqorida yaratib, yani yaqinda ishlatilgan PARENT metrikiga ishlatayotgan model-agnostik freymini ko'rsatdik, rivojlanishni va tashkilotlarni kamaytirishda foydalanishimiz mumkin. Name", 'vi': 'Trong các mô- đun sản xuất ngôn ngữ được cấu trúc dựa trên dữ liệu, tập luyện cổ đi ển dựa trên khả năng có khả năng cao gần như luôn dẫn đến các mô- tơ để thu thập các dữ liệu khác biệt (ảo giác hay sơ-khúc) và để kết hợp chúng sai lầm vào các thế hệ của mình tại kết luận. Trong công việc này, chúng ta xây dựng dựa trên các phương pháp tiếp cận về giáo dục tiếp cận trước đó và cho thấy một khung chẩn đoán dựa trên hệ thống Paris được giới thiệu gần đây có hiệu quả để giảm ảo giác và sơ suất. Nghiên cứu về tiêu chuẩn hàng loạt của WikiLBIO và WebNLI chứng minh hiệu quả của bộ khung này so với các mẫu hiện đại.', 'bg': 'В моделите на езиково генериране, обусловени от структурирани данни, класическото обучение чрез максимална вероятност почти винаги води моделите да възприемат дивергенцията на набора от данни (т.е. халюцинации или пропуски) и да ги включат погрешно в собствените си поколения при заключение. В тази работа ние изграждаме върху предишни подходи, базирани на подсилване на обучението, и показваме, че модел-агностична рамка, разчитаща на наскоро въведената ПАРЪНТ метрика, е ефективна за намаляване както на халюцинациите, така и на пропуските. Оценките на широко използваните показатели на УикиБИО и WebNLG показват ефективността на тази рамка в сравнение с най-съвременните модели.', 'hr': 'U modelima generacije jezika pod uslovom strukturiranih podataka, klasična obuka putem maksimalne vjerojatnosti skoro uvijek vodi modele na podizanje različitih različitih grupa podataka (tj. halucinacija ili omisija) i uključivanje ih pogrešno u svoje generacije na infekciji. U ovom poslu, izgradimo na vrhu prethodnih pristupa na osnovu učenja pojačanja i pokazujemo da je model-agnostički okvir koji se oslanja na nedavno uvedenu PARENT metriku učinkovit u smanjenju halucinacija i bezbjednosti. Procjenjivanja široko korištenih kriterija WikiBIO i WebNLG pokazuju učinkovitost ovog okvira u usporedbi s modelima stanja umjetnosti.', 'nl': 'In taalgeneratiemodellen die geconditioneerd zijn door gestructureerde data, leidt de klassieke training via maximale waarschijnlijkheid er bijna altijd toe dat modellen datasetdivergentie (hallucinaties of omissies) oppikken en bij conclusie foutief opnemen in hun eigen generaties. In dit werk bouwen we voort op eerdere Reinforcement Learning gebaseerde benaderingen en laten we zien dat een model-agnostisch raamwerk gebaseerd op de recent geïntroduceerde PARENT metric efficiënt is in het verminderen van zowel hallucinaties als omissies. Evaluaties van de veelgebruikte WikiBIO en WebNLG benchmarks tonen de effectiviteit van dit framework aan in vergelijking met state-of-the-art modellen.', 'da': 'I sproggenerationsmodeller, der er betinget af strukturerede data, fører den klassiske træning via maksimal sandsynlighed næsten altid modellerne til at opfange datasæt divergens (dvs. hallucinationer eller udeladelser) og til at indarbejde dem fejlagtigt i deres egne generationer ved slutningen. I dette arbejde bygger vi oven på tidligere forstærket læringsbaserede tilgange og viser, at en model-agnostisk ramme baseret på den nyligt indførte forældremål er effektiv til at reducere både hallucinationer og udeladelser. Evalueringer af de udbredte WikiBIO og WebNLG benchmarks viser effektiviteten af denne ramme sammenlignet med state-of-the-art modeller.', 'de': 'In Sprachgenerierungsmodellen, die durch strukturierte Daten konditioniert werden, führt das klassische Training über maximale Wahrscheinlichkeit fast immer dazu, dass Modelle Datensatzdivergenzen (d.h. Halluzinationen oder Auslassungen) aufgreifen und bei der Schlussfolgerung fälschlicherweise in ihre eigenen Generationen einfließen. In dieser Arbeit bauen wir auf früheren Reinforcement Learning basierten Ansätzen auf und zeigen, dass ein modellagnostisches Framework, das auf der kürzlich eingeführten PARENT-Metrik basiert, sowohl Halluzinationen als auch Auslassungen effizient reduziert. Auswertungen zu den weit verbreiteten WikiBIO- und WebNLG-Benchmarks belegen die Wirksamkeit dieses Frameworks im Vergleich zu aktuellen Modellen.', 'id': 'In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e., hallucinations or omissions), and to incorporate them erroneously in their own generations at inference.  In this work, we build on top of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions.  Evaluasi benchmark WikiBIO dan WebNLG yang digunakan secara luas menunjukkan efektif dari kerangka ini dibandingkan dengan model terbaik.', 'fa': 'در مدلهای نسل زبانی که توسط داده های ساخته شده، آموزش کلاسیک با احتمال بیشتری تقریباً همیشه مدلها را به اختلافات مجموعه داده ها (یعنی خلوت یا تباهی) هدایت می\u200cکند، و آنها را اشتباه در نسل\u200cهای خود در آلودگی شامل می\u200cکند. در این کار، ما روی بالای دستورات یادگیری بر اساس استوار پیشین ساختیم و نشان می دهیم که یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها ارزیابی در مقایسهٔ مدل\u200cهای هنری ویکیبیو و وب NLG استفاده شده\u200cاند.', 'ko': '구조화된 데이터를 조건으로 하는 언어 생성 모델에서 가장 큰 유사법을 통해 진행된 고전적인 훈련은 모델이 데이터 집합의 차이(즉 환각이나 누락)를 발견하고 추리할 때 이를 자신의 세대에 잘못 포함시킨다.이 작업에서 우리는 이전에 학습을 강화하는 방법을 바탕으로 구축했고 최근에 도입된 부도량에 의존하는 모델인 알 수 없는 구조가 환각과 누락을 줄이는 데 효과적임을 나타냈다.광범위하게 사용되는 위키비오와 위비엔LG 기준에 대한 평가는 최첨단 모델에 비해 이 프레임워크가 효과적이라는 것을 보여준다.', 'sw': 'In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e., hallucinations or omissions), and to incorporate them erroneously in their own generations at inference.  Katika kazi hii, tunajenga juu ya mbinu za mwanzo wa Kufundisha Maendeleo na kuonyesha kuwa mfumo wa mifano ya agnostic unategemea mbinu za hivi karibuni zilizoanzishwa na PARENT ni ufanisi katika kupunguza usafi na usafi. Tathmini za bendera za WikiBIO na WebNLG zinaonyesha ufanisi wa mfumo huu ukilinganisha na mifano ya sanaa.', 'tr': 'Diller döredilişi maglumatlar tarapyndan tassyklanan örneklerde, klasik okuw sistemasy mümkinçiligi görnüşi diýip hemişe daýlar düşürmegi üçin nusgalary çykaryp getirýär (meselâ, halucinasiýalar ýa-da omisiýalar), we olary öz döreloklerinde ýalňyşlyk bilen ýalňyşlyk bilen düşürmek üçin Bu işde öňki güýçlendirmek öwrenmeleriň üstünde guruldyk we şuny ýakynlaşdyryp biljek nusgalaryň hem hallucinasiýalary hem terjimeleri azaltmak üçin bir nusga agnostik çerçevesiniň üstünde etkinlik bar. WikiBIO we WebNLG kaliwatlarynda ulanylýan çykyşlar bu çerýäniň etkinliýetini sungat modalarynyň ýagdaýynda görä kanıtlaýarlar.', 'sq': 'In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e., hallucinations or omissions), and to incorporate them erroneously in their own generations at inference.  Në këtë punë, ne ndërtojmë mbi qasjet e mëparshme të Mësimit të Përforcimit dhe tregojmë se një kuadër model-agnostik mbështetur në metrikën e paraqitur kohët e fundit PARENT është efikas në reduktimin e hallucinacioneve dhe mungesave. Vlerësimet e pikave të përdorura gjerësisht nga WikiBIO dhe WebNLG tregojnë efektshmërinë e këtij kuadri krahasuar me modelet më të moderne.', 'hy': 'Լեզու ստեղծման մոդելներում, որոնք պայմանավորված են կառուցվածված տվյալների միջոցով, դասական ուսումնասիրությունը մեծագույն հավանականության միջոցով գրեթե միշտ առաջնորդում է մոդելներին վերցնել տվյալների համակարգի տարբերությունները (այսինքն, հալյուցինացիաները կամ բացակայությունները), և սխալ In this work, we build on top of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions.  ՎիքիԲԻՕ և ՎեբՆԼԳ-ի լայնորեն օգտագործված համեմատական նշանների գնահատումները ցույց են տալիս այս շրջանակի արդյունավետությունը, համեմատած ամենաբարձր մոդելների հետ:', 'am': 'በቋንቋ ትውልድ ምሳሌዎች በተመሠረተ ዳታዎች አካባቢ፣ የክላሲ ትምህርት በተመሳሳይ ማህበረሰብ ሁልጊዜ ዳታ-settings ትርፍ (ምናልባት ቅድሚያ ወይም ትክክለኛ) እና በተስህተት በትውልዳቸው በትክክል ማግባት ይችላል፡፡ በዚህ ሥራ፣ የቀድሞው ተማሪ መሠረት ላይ የሚደረገውን እና በቅርቢቱ ዘመን በተጠቃሚ የPARENT ሜትሪክ ላይ የሚታመን የሞዴል-አጎኖስቲ ፍሬማር ቅድስናና ስህተት እና ስሕተት ማጎድል በቻለ ነው ብለን እናሳያቸዋለን፡፡ Evaluations on the widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this framework compared to state-of-the-art models.', 'az': 'Yapılmış məlumatlar tarafından müəyyən edilmiş dil nəsli modellərdə, klasik təhsil maksimum mümkünlüyü vasitəsilə, neredeyse həmişə modelləri verilən qutusu müxtəlif fərqliyi (həmçin in halucinalılar və təhsil edilməsi) ilə istifadə edir və onları özlərinin nəsillərində xəta olaraq təhsil edir. Bu işdə, əvvəlkilərin Qüvvətləndirmək öyrənməsi tərzlərinin üstündə inşa edirik və yenidən tanıdıqları PARENT metriklərinə güvən modeli agnostik bir çerçive halucinaciya və təhlükəsizliklərini azaltmaq üçün faydalı olduğunu göstəririk. Üstündə istifadə edilən WikiBIO və WebNLG benchmarklərinin değerlendirmələri bu frameworkunun ehtimalını sanat modelleri ilə qarşılaşdırır.', 'bn': 'ভাষার প্রজন্মের মডেল যা কাঠামোর তথ্য দ্বারা ব্যবস্থা করে তৈরি করেছে, সেটি সর্বোচ্চ সম্ভাবনার মাধ্যমে ক্লাসিক প্রশিক্ষণের মাধ্যমে প্রায় সবসময় ডেটাসেট বিভ্রান্তির এই কাজে আমরা পূর্ববর্তী প্রতিষ্ঠান শিক্ষা শিক্ষা ভিত্তিক পদ্ধতির উপর নির্মাণ করি এবং দেখাচ্ছি যে সম্প্রতি প্রতিষ্ঠিত প্যারেন্ট মেট্রিকে নির্ভর করা একটি মডেল- উইকিবিওও এবং ওয়েব এনএলজি বেনম্যার্কের ব্যাপকভাবে ব্যবহার করা এই ফ্রেমের কার্যক্রমের প্রভাব প্রদর্শন করে যাচ্ছে রাষ্ট্র-অফ-শিল্', 'cs': 'V modelech generace jazyků podmíněných strukturovanými daty vede klasický trénink prostřednictvím maximální pravděpodobnosti téměř vždy modely k tomu, aby zachytily divergenci datových sad (tj. halucinace nebo opomenutí) a aby je při odvození chybně začlenily do svých vlastních generací. V této práci navazujeme na předchozí přístupy založené na Reinforcement Learning a ukazujeme, že model-agnostický rámec založený na nedávno zavedené metrice PARENT je efektivní při snižování halucinací i opomenutí. Hodnocení široce používaných referenčních hodnot WikiBIO a WebNLG ukazují efektivitu tohoto frameworku ve srovnání s nejmodernějšími modely.', 'et': 'Struktureeritud andmetest tingitud keele genereerimise mudelites viib klassikaline koolitus maksimaalse tõenäosuse kaudu peaaegu alati mudelitele andmekogumi erinevuste (s.t hallutsinatsioonide või väljajätmiste) üles võtma ja neid ekslikult oma põlvkondadesse järelduste tegemisel. Selles töös toetume varasematele tugevdusõppel põhinevatele lähenemisviisidele ja näitame, et hiljuti kasutusele võetud PARENT meetodil põhinev mudeliga agnostiline raamistik aitab vähendada nii hallutsinatsioone kui ka puudusi. Laialdaselt kasutatavate WikiBIO ja WebNLG võrdlusnäitajate hindamine näitab selle raamistiku tõhusust võrreldes kaasaegsete mudelitega.', 'fi': 'Strukturoidulla datalla ehdollistetuissa kieligenerointimalleissa klassinen harjoittelu maksimaalisen todennäköisyyden kautta johtaa lähes aina mallien poimimaan aineiston eroavaisuuksia (eli hallusinaatioita tai laiminlyöntejä) ja sisällyttämään ne virheellisesti omiin sukupolviinsa päättelyn yhteydessä. Tässä työssä rakennamme aiempien Vahvistusoppimiseen perustuvien lähestymistapojen päälle ja osoitamme, että hiljattain käyttöön otettuun PARENT-mittariin perustuva malliagnostinen kehys vähentää tehokkaasti hallusinaatioita ja puutteita. Laajasti käytettyjen WikiBIO- ja WebNLG-vertailuarvojen arvioinnit osoittavat tämän viitekehyksen tehokkuuden verrattuna uusimpiin malleihin.', 'bs': 'U modelima generacije jezika pod uslovom strukturiranih podataka, klasična obuka putem maksimalne vjerojatnosti skoro uvijek vodi modele da se pokupi različitost kompleta podataka (tj. halucinacije ili omisije), i da ih pogrešno uključuju u svoje generacije na infekciju. U ovom poslu, izgradimo na vrhu prethodnih pristupa na osnovu učenja pojačanja i pokazujemo da je model-agnostički okvir koji se oslanja na nedavno uvedenu metriku PARENT-a efikasan u smanjenju halucinacija i bezbjednosti. Procjenjivanja široko korištenih kriterija WikiBIO i WebNLG pokazuju učinkovitost ovog okvira u usporedbi s modelima stanja umjetnosti.', 'af': "In taal generasie-modeller wat deur struktureerde data gekondisieer is, lei die klassieke onderwerking deur maksimum waarskynlik amper altyd modele om op datastel verskilligheid te haal (i.e. hallusinasies of omisiones), en om hulle miskien in hul eie generasies by inferensie te inkorpreer. In hierdie werk bou ons bo-op die vorige versterking ondersteuning gebaseerde toegange en wys dat 'n model-agnostiese raamwerk wat op die onlangs ingevoerde PARENT metriek vertrou is effektief om beide halusinasies en omisiërs te reduseer. Evaluasies op die vaste gebruikte WikiBIO en WebNLG-benchmarke vertoon die effektiviteit van hierdie raamwerk vergelyk met staat van die kunstenmodele.", 'ca': "In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e., hallucinations or omissions), and to incorporate them erroneously in their own generations at inference.  En aquesta feina, construïm sobre els enfocaments anteriors basats en l'aprenentatge de reforç i demostrem que un marc model-agnòstic basat en la mètrica PARENT recentment introduïda és eficient en reduir tant les alucinacions com les omissions. Evaluations on the widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this framework compared to state-of-the-art models.", 'ha': "In tsaro na salon da aka ƙayyade data da aka tsare, wa'adin classical na tsakanin a tsakanin kowace, yana shirya misãlai da za'a nuna su a kan rarrabẽwa na danne-danne (misali, buƙata ko cire'a), kuma ya shigar da su ɓata a cikin 'yan'uwansu gabanin da ke iya ƙaranci. Daga wannan aikin, Munã samar da kofi na zaman Harakar da Akwai a kan hanyõyin da aka sani kuma Muke nũna cewa wata firam-agnostic, yana dõgara a kan a yanzu ta ƙara da aka farata PANT, yana da amfani da ƙaranci da hanyoyi. Bayaniyar da ake amfani da WikiBIO da WebNLG ɗin fancy sun nuna aikin wannan firam sami da misali-of-the-art.", 'sk': 'Pri modelih jezikovne generacije, ki jih pogojujejo strukturirani podatki, klasično usposabljanje prek največje verjetnosti skoraj vedno povzroči, da modeli zaznajo razlike v naboru podatkov (tj. halucinacije ali opustitve) in jih napačno vključijo v svoje generacije pri sklepanju. V tem delu gradimo na vrhu prejšnjih pristopov, ki temeljijo na okrepitvenem učenju, in pokažemo, da je model-agnostični okvir, ki temelji na nedavno uvedeni PARENT metriki, učinkovit pri zmanjševanju halucinacij in opustitev. Ocene široko uporabljenih referenčnih vrednosti WikiBIO in WebNLG kažejo učinkovitost tega okvira v primerjavi z najsodobnejšimi modeli.', 'he': 'בדוגמנים של יוצר שפות מתאימים על ידי נתונים מבוססים, האימונים הקלאסיים באמצעות סבירות מקסימלית כמעט תמיד מובילים לדוגמנים לאסוף את ההבדלות של קבוצת נתונים בעבודה הזו, אנו בונים על גבי גישות קודמות למידע התאוששות ומראות שמסגרת מודל-אגנוסטית תסמכת על מטריקת PARENT המוציאה לאחרונה היא יעילה בהפחית גם ההזיות וגם השכחות. הערכות על נקודות השימוש ברחבי WikiBIO ו WebNLG מראות את היעילות של המסגר הזה בהשוואה לדוגמאות חדשות.', 'bo': 'In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e. hallucinations or omissions), and to incorporate them into their own generation at inference. In this work, we build on top of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions. རྒྱ་བསྐྱེད་པའི་བྱ་ཚིག་གིས་སྤྱོད་པའི་WikiBIO དང་WebNLG དམག་གཟུགས་རིས་བཀོད་སྤྱོད་པའི་ནང་དུ་གྲངས་སྒྲིག', 'jv': 'Nanging model sing ditumpa tindahan sing sampeyan mrogram kuwi data structural, supoyo sukane karo perusahaan langkung sampeyan kuwi kesempatan kudu ditulak modèl kanggo nguasai perusahaan dataset Awak dhéwé nggawe barang nggawe barang nggawe Ngucap Universi dumadhi sing dumadhi karo ngono kuwi nggawe layang modèl-agestas kuwi diantesik sistem sing isiné supoyo PAREND Metric sing ora bisa jejaring, iso nggawe halusinung bantuan karo halusinung lan ijol-ijolan. Entekanuné kapan tengahane gambar nggambar sistem WiBIO karo webNLG gawe ngulinakake efetis barang iki nggawe gerarané karo model state-of-the-arts'}
{'en': 'Chart-to-Text : Generating Natural Language Descriptions for Charts by Adapting the Transformer Model', 'ar': 'رسم بياني إلى نص: إنشاء أوصاف لغة طبيعية للمخططات عن طريق تكييف نموذج المحولات', 'es': 'Gráfico a texto: Generación de descripciones en lenguaje natural para gráficos mediante la adaptación del modelo Transformer', 'fr': 'Chart-to-Text\xa0: Génération de descriptions en langage naturel pour les graphiques en adaptant le modèle de transformateur', 'pt': 'Chart-to-Text: Gerando Descrições de Linguagem Natural para Gráficos Adaptando o Modelo Transformer', 'ja': 'グラフからテキストへ：トランスフォーマーモデルを適応させることにより、グラフの自然言語説明を生成する', 'zh': '图表至文本:因转换器模形为图自然语言', 'ru': 'От диаграммы к тексту: создание описаний естественного языка для диаграмм путем адаптации модели трансформатора', 'hi': 'चार्ट-टू-टेक्स्ट: ट्रांसफॉर्मर मॉडल को अनुकूलित करके चार्ट के लिए प्राकृतिक भाषा विवरण जनरेट करना', 'ga': 'Cairt go Téacs: Cur síos ar Theanga Nádúrtha a Ghiniúint do Chairteacha tríd an Múnla Trasfhoirmeora a Oiriúnú', 'el': 'Γράφημα-σε-κείμενο: Δημιουργία περιγραφών φυσικής γλώσσας για γραφήματα με προσαρμογή του μοντέλου μετασχηματιστή', 'hu': 'Diagramról szövegre: Természetes nyelvleírások generálása diagramokhoz a transzformátor modelljének adaptálásával', 'ka': 'ტექსტის დირაფიკატის შესახებ: დირაფიკატის ნაირადი ენის აღწერების შექმნა', 'it': 'Grafico a testo: generazione di descrizioni del linguaggio naturale per i grafici adattando il modello del trasformatore', 'kk': 'Диаграмма- мен мәтін: Диаграммалардың табиғи тілдерді түрлендіру үлгісін өзгерту', 'lt': 'Ženklas į tekstą: Gamtinės kalbos apibūdinimų kūrimas Ženklams pritaikant transformatoriaus modelį', 'mk': 'График во текст: Генерирање на описи на природен јазик за графики со адаптирање на моделот на трансформирање', 'ms': 'Huraian-ke-Teks: Menjana Huraian Bahasa Biasa untuk Huraian dengan menyesuaikan Model Penukar', 'ml': 'KChart- to- Text: Transformer Model Adapting', 'mt': 'Iċ-Ċart għat-Test: Il-Ġenerazzjoni ta’ Deskrizzjonijiet tal-Lingwa Naturali għall-Ċerti bl-Adattament tal-Mudell tat-Trasferiment', 'mn': 'Диаграмм-ээс-текст: Диаграмтын байгалийн хэл тайлбарлалт бүтээж Төрвөлдөгч Загварын загварыг загварчлан', 'pl': 'Wykres-do-tekst: generowanie opisów języka naturalnego dla wykresów poprzez dostosowanie modelu transformatora', 'no': 'Grafikk til tekst: Lagar naturspråkkskildringar for grafikk ved å tilpassa transformeringsmodellen', 'ro': 'Diagramă în text: generarea descrierilor limbajului natural pentru diagrame prin adaptarea modelului transformatorului', 'sr': 'Chart- to- text: Generiranje prirodnih jezika opisa za grafike prilagođenjem modela transformera', 'sv': 'Diagram till text: Generera beskrivningar av naturligt språk för diagram genom att anpassa transformatormodellen', 'so': 'Chart-to-text: Generating Descriptions of Language Nature for Characters by Adapting the Model Transfer', 'si': 'චාර්ට් වෙනුවෙන් පාළුව: ස්වභාවික භාෂාව විස්තර කරන්නේ චාර්ට් වලින් විස්තර', 'ta': 'வரைபடத்திலிருந்து உரை: மாற்றும் மாதிரியை ஏற்றுமதி செய்து இயல்பான மொழி வரைவடிவமைப்புகளை உருவாக்குகிறது', 'ur': 'Chart- to- text: Natural Language Descriptions for Charts by Adapting the Transformer Model', 'uz': 'KChart- to- matn: Transfer Model', 'vi': 'Bản đồ Văn bản: Tạo ra các mô tả ngôn ngữ tự nhiên cho các bản đồ bằng cách sửa đổi mô hình biến hình', 'bg': 'Диаграма в текст: генериране на естествени езикови описания за диаграми чрез адаптиране на модела на трансформатора', 'nl': 'Grafiek-naar-tekst: Het genereren van beschrijvingen in natuurlijke taal voor grafieken door het transformatormodel aan te passen', 'hr': 'Grafik do teksta: Generiranje prirodnog jezika opisa za grafike prilagođenjem modela transformacije', 'da': 'Diagram til tekst: Generere beskrivelser af naturligt sprog for diagrammer ved at tilpasse transformatormodellen', 'id': 'Chart-to-Text: Menjana Deskripsi Bahasa Alami untuk Chart dengan menyesuaikan Model Transformer', 'de': 'Diagramm-zu-Text: Generieren natürlicher Sprachbeschreibungen für Diagramme durch Anpassung des Transformatormodells', 'ko': '그래프에서 텍스트로: Transformer 모델을 조정하여 그래프에 자연 언어 설명을 생성합니다', 'fa': 'نمودار به متن: توصیف زبان طبیعی برای نمودارها با تغییر مدل تغییردهنده', 'tr': 'Resim we Metin Saýlaw', 'sw': 'Mjumbe-hadi-maandishi: Kutengeneza maelezo ya lugha ya asili kwa ajili ya ramani kwa Kupitisha Modeli ya Tafsiri', 'sq': 'Chart-to-Text: Generating Natural Language Descriptions for Charts by Adapting the Transformer Model', 'af': 'Kaart- na- Teks: Genereer Natuurlike Taal Beskrywings vir Kaart deur aanpassing van die Transformer Model', 'hy': 'Տեքստի քարտեզ: Գեներացնում է բնական լեզվի նկարագրություններ քարտեզների համար՝ հարմարեցնելով փոխակերպող մոդելը', 'bn': 'চিত্র- থেকে টেক্সট: ট্রান্সফ্রান্সফার্নার মোডেল পাঠানোর মাধ্যমে প্রাকৃতিক ভাষা বিবরণ তৈরি করা হচ্ছ', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'bs': 'Grafik na tekst: Generiranje prirodnog jezika opisa za grafike prilagođenjem modela transformacije', 'ca': 'Gràfic a text: generar descripcions de llenguatge natural per a gràfics adaptant el model de transformador', 'az': 'Chart-to-Text: Diagramlar 칲칞칲n t톛bi톛tli dil T톛rc칲ml톛yici Modelini Adland캼ran', 'cs': 'Graf-to-Text: Generování popisů přirozeného jazyka pro grafy přizpůsobením modelu transformátoru', 'fi': 'Kaavio tekstiksi: Luonnollisten kielikuvausten luominen kaavioille muuntajamallin mukauttamisella', 'et': 'Diagramm tekstiks: diagrammide loomulike keelekirjelduste genereerimine teisendusmudeli kohandamise abil', 'he': 'גרט לטקסט: יצירת תיאור שפת טבעית עבור גרטים על ידי שינוי מודל המעבר', 'jv': 'structural navigation', 'sk': 'Grafikon v besedilo: Ustvarjanje opisov naravnega jezika za grafikone s prilagajanjem modela transformatorja', 'bo': 'Chart-to-Text: Generating Natural Language Descriptions for Charts by Adapting the Transformer Model', 'ha': 'KChart- to- Text: Creating KCharselect unicode block name'}
{'en': 'Information visualizations such as bar charts and line charts are very popular for exploring data and communicating insights. Interpreting and making sense of such visualizations can be challenging for some people, such as those who are visually impaired or have low visualization literacy. In this work, we introduce a new dataset and present a neural model for automatically generating natural language summaries for charts. The generated summaries provide an interpretation of the chart and convey the key insights found within that chart. Our neural model is developed by extending the state-of-the-art model for the data-to-text generation task, which utilizes a transformer-based encoder-decoder architecture. We found that our approach outperforms the base model on a content selection metric by a wide margin (55.42 % vs. 8.49 %) and generates more informative, concise, and coherent summaries.', 'ar': 'تحظى تصورات المعلومات مثل المخططات الشريطية والمخططات الخطية بشعبية كبيرة لاستكشاف البيانات وتوصيل الرؤى. قد يكون تفسير مثل هذه التصورات وفهمها أمرًا صعبًا بالنسبة لبعض الأشخاص ، مثل أولئك الذين يعانون من إعاقة بصرية أو لديهم معرفة القراءة والكتابة المرئية منخفضة. في هذا العمل ، نقدم مجموعة بيانات جديدة ونقدم نموذجًا عصبيًا لإنشاء ملخصات لغة طبيعية للمخططات تلقائيًا. توفر الملخصات التي تم إنشاؤها تفسيرًا للمخطط وتنقل الأفكار الرئيسية الموجودة في هذا المخطط. تم تطوير نموذجنا العصبي من خلال توسيع النموذج الحديث لمهمة إنشاء البيانات إلى النص ، والتي تستخدم بنية مفكك تشفير تعتمد على المحولات. وجدنا أن نهجنا يتفوق في الأداء على النموذج الأساسي على مقياس اختيار المحتوى بهامش عريض (55.42٪ مقابل 8.49٪) ويولد ملخصات أكثر إفادة وموجزة ومتماسكة.', 'es': 'Las visualizaciones de información, como los gráficos de barras y los gráficos de líneas, son muy populares para explorar datos y comunicar información valiosa. Interpretar y dar sentido a estas visualizaciones puede ser un desafío para algunas personas, como las que tienen una discapacidad visual o tienen un bajo nivel de alfabetización visual. En este trabajo, presentamos un nuevo conjunto de datos y presentamos un modelo neuronal para generar automáticamente resúmenes en lenguaje natural para gráficos. Los resúmenes generados proporcionan una interpretación del gráfico y transmiten las ideas clave que se encuentran en ese gráfico. Nuestro modelo neuronal se desarrolla ampliando el modelo de vanguardia para la tarea de generación de datos a texto, que utiliza una arquitectura de codificador-decodificador basada en transformadores. Descubrimos que nuestro enfoque supera al modelo base en una métrica de selección de contenido por un amplio margen (55,42% frente al 8,49%) y genera resúmenes más informativos, concisos y coherentes.', 'pt': 'As visualizações de informações, como gráficos de barras e gráficos de linhas, são muito populares para explorar dados e comunicar insights. Interpretar e dar sentido a tais visualizações pode ser um desafio para algumas pessoas, como aquelas com deficiência visual ou com baixa alfabetização em visualização. Neste trabalho, apresentamos um novo conjunto de dados e apresentamos um modelo neural para gerar automaticamente resumos em linguagem natural para gráficos. Os resumos gerados fornecem uma interpretação do gráfico e transmitem os principais insights encontrados nesse gráfico. Nosso modelo neural é desenvolvido estendendo o modelo de última geração para a tarefa de geração de dados para texto, que utiliza uma arquitetura de codificador-decodificador baseada em transformador. Descobrimos que nossa abordagem supera o modelo básico em uma métrica de seleção de conteúdo por uma ampla margem (55,42% vs. 8,49%) e gera resumos mais informativos, concisos e coerentes.', 'fr': "Les visualisations d'informations telles que les graphiques à barres et les graphiques en courbes sont très populaires pour explorer les données et communiquer des informations. L'interprétation et la compréhension de ces visualisations peuvent être difficiles pour certaines personnes, comme celles qui sont malvoyantes ou qui ont peu de connaissances en matière de visualisation. Dans ce travail, nous introduisons un nouveau jeu de données et présentons un modèle neuronal permettant de générer automatiquement des résumés en langage naturel pour les graphiques. Les résumés générés fournissent une interprétation du graphique et transmettent les principales informations qu'il contient. Notre modèle neuronal est développé en étendant le modèle de pointe pour la tâche de génération de données en texte, qui utilise une architecture encodeur-décodeur basée sur un transformateur. Nous avons constaté que notre approche surpasse largement le modèle de base sur une métrique de sélection de contenu (55,42\xa0% contre 8,49\xa0%) et génère des résumés plus informatifs, concis et cohérents.", 'ja': '棒グラフや折れ線グラフなどの情報可視化は、データの探索や洞察の伝達に非常に人気があります。そのような視覚化の解釈と理解は、視覚障害者や視覚化リテラシーが低い人々など、一部の人々にとって困難な場合があります。この研究では、新しいデータセットを紹介し、グラフの自然言語サマリーを自動生成するためのニューラルモデルを提示します。生成された要約は、チャートの解釈を提供し、そのチャート内で見つかった主要な洞察を伝えます。当社のニューラルモデルは、変圧器ベースのエンコーダデコーダアーキテクチャを利用したデータツーテキスト生成タスクの最先端モデルを拡張することで開発されています。当社のアプローチは、コンテンツ選択指標のベースモデルを大幅に上回り（ 55.42 ％対8.49 ％ ）、より情報量が多く、簡潔で一貫性のある要約を生成することがわかりました。', 'zh': '条形图与折线图等信息可视化探索传见甚受欢迎。 其于人也,解释之类可视化或有挑战性,视损可视化养下者也。 引入一新数集,立一神经模形,以成图自然语言摘要。 生成之摘要,资图表之说,传其要会。 吾神经者,所以广数而先事者也,因转换器之编码器 - 解码器架构也。 吾见其法指标大于本(55.42%于8.49%),而信息益丰,简洁连贯之摘要。', 'hi': 'बार चार्ट और लाइन चार्ट जैसे सूचना विज़ुअलाइज़ेशन डेटा की खोज और अंतर्दृष्टि संचार करने के लिए बहुत लोकप्रिय हैं। इस तरह के विज़ुअलाइज़ेशन की व्याख्या करना और समझना कुछ लोगों के लिए चुनौतीपूर्ण हो सकता है, जैसे कि वे जो नेत्रहीन हैं या कम विज़ुअलाइज़ेशन साक्षरता रखते हैं। इस काम में, हम एक नया डेटासेट पेश करते हैं और चार्ट के लिए प्राकृतिक भाषा सारांश स्वचालित रूप से उत्पन्न करने के लिए एक तंत्रिका मॉडल पेश करते हैं। जेनरेट किए गए सारांश चार्ट की एक व्याख्या प्रदान करते हैं और उस चार्ट के भीतर पाए जाने वाले प्रमुख अंतर्दृष्टि को व्यक्त करते हैं। हमारा तंत्रिका मॉडल डेटा-टू-टेक्स्ट जनरेशन कार्य के लिए अत्याधुनिक मॉडल का विस्तार करके विकसित किया गया है, जो एक ट्रांसफॉर्मर-आधारित एन्कोडर-डिकोडर आर्किटेक्चर का उपयोग करता है। हमने पाया कि हमारा दृष्टिकोण एक व्यापक मार्जिन (55.42% बनाम 8.49%) द्वारा सामग्री चयन मीट्रिक पर आधार मॉडल को मात देता है और अधिक जानकारीपूर्ण, संक्षिप्त और सुसंगत सारांश उत्पन्न करता है।', 'ru': 'Информационные визуализации, такие как гистограммы и линейные диаграммы, очень популярны для изучения данных и обмена идеями. Устный перевод и осмысление таких визуализаций может быть сложной задачей для некоторых людей, таких как люди с нарушениями зрения или с низкой грамотностью в области визуализации. В этой работе мы вводим новый набор данных и представляем нейронную модель для автоматического генерирования сводок естественного языка для диаграмм. Сформированные сводки обеспечивают интерпретацию диаграммы и передают ключевые выводы, найденные в этой диаграмме. Наша нейронная модель разработана путем расширения современной модели для задачи генерации данных в текст, которая использует архитектуру кодировщик-декодер на основе трансформатора. Мы обнаружили, что наш подход превосходит базовую модель по метрике выбора контента с большим запасом (55,42% против 8,49%) и генерирует более информативные, сжатые и последовательные сводки.', 'ga': 'Bíonn an-tóir ar léirshamhlú faisnéise ar nós barrachairteacha agus línechairteacha chun sonraí a iniúchadh agus chun léargais a chur in iúl. D’fhéadfadh sé a bheith dúshlánach do roinnt daoine léirmhíniú agus ciall a bhaint as léirshamhlú den sórt sin, mar iad siúd a bhfuil lagú amhairc orthu nó a bhfuil litearthacht íseal amharcléirithe acu. San obair seo, tugaimid tacar sonraí nua isteach agus cuirimid i láthair samhail néarúil chun achoimrí teanga nádúrtha a ghiniúint go huathoibríoch do na cairteacha. Soláthraíonn na hachoimrí ginte léirmhíniú ar an gcairt agus cuireann siad in iúl na príomhléargais a fhaightear sa chairt sin. Forbraítear ár múnla néarúil tríd an tsamhail úrscothach a leathnú don tasc giniúna sonraí-go-téacs, a úsáideann ailtireacht ionchódóra-díchódóra atá bunaithe ar chlaochladán. Fuaireamar amach go sáraíonn ár gcur chuige an bonn-mhúnla ar mhéadracht roghnú ábhair le corrlach leathan (55.42% vs. 8.49%) agus gineann sé achoimrí níos faisnéiseach, gonta agus níos soiléire.', 'ka': 'ინფორმაციის ვიზუალიზაციები, როგორც ბარის ფარატი და ხაზის ფარატი, ძალიან პოლუბურია მონაცემების და კომუნიკაციის შესახებისთვის. ასეთი ვიზუალიზაციების შესაძლებლობა შეიძლება იყოს გასაკეთებელი ადამიანებისთვის, როგორც ვიზუალიზაციურად დააკეთებული ადამიანებისთვის, ან ცოტა ვიზუალიზაციის სიტ ამ სამუშაოში, ჩვენ ახალი მონაცემების კონფიგურაციას ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენებთ და ჩვენ ჩვენებთ ნეიროლური მოდელს ჩვენ ჩვენებთ ჩვენ შექმნილი საზოგადოებები ჩატვირთვას ჩატვირთვას ჩატვირთვას და ჩატვირთვას ჩატვირთვა ჩატვირთვა ამ შატში. ჩვენი ნეიროლური მოდელი განვითარებულია, რომელიც მონაცემებით ტექსტის განვითარებისთვის მოდელს განზომილებით, რომელიც ტრანფორმებით გადატანგებული კოდერს-ევკოდერს აქტიქტი ჩვენ მივიღეთ, რომ ჩვენი მიღება უფრო გავაკეთება ბაზი მოდელის მონიშნულების მონიშნულების მეტრიკის გარეშე (55.42% vs. 8.49%) და უფრო ინფორმაციური, კონსტიური და კონსტენტიური გარეშე.', 'hu': 'Az információs megjelenítések, például a sávdiagramok és a vonaldiagramok nagyon népszerűek az adatok feltárásához és az információk kommunikálásához. Az ilyen vizualizációk értelmezése és értelmezése kihívást jelenthet egyes emberek számára, például azok számára, akik látássérültek vagy alacsony vizualizációs műveltséggel rendelkeznek. Ebben a munkában bemutatunk egy új adatkészletet és bemutatunk egy neurális modellt a diagramok természetes nyelvi összefoglalóinak automatikus generálására. A létrehozott összefoglalók értelmezik a diagramot, és közvetítik a diagramban található kulcsfontosságú betekintéseket. Neurális modellünket az adat-szöveg generálási feladat korszerű modelljének kiterjesztésével fejlesztjük ki, amely transzformátor alapú kódoló-dekóder architektúrát használ. Megállapítottuk, hogy megközelítésünk széles margóval (55,42% vs. 8,49%) felülmúlja az alapmodellt egy tartalom kiválasztására vonatkozóan, és információsabb, tömörebb és koherens összefoglalókat generál.', 'el': 'Οι οπτικοποιήσεις πληροφοριών, όπως γραφήματα ράβδων και γραφήματα γραμμών, είναι πολύ δημοφιλείς για την εξερεύνηση δεδομένων και την επικοινωνία πληροφοριών. Η διερμηνεία και η κατανόηση τέτοιων οπτικοποιήσεων μπορεί να είναι πρόκληση για ορισμένους ανθρώπους, όπως εκείνους που έχουν προβλήματα όρασης ή έχουν χαμηλό γραμματισμό οπτικοποίησης. Σε αυτή την εργασία, εισάγουμε ένα νέο σύνολο δεδομένων και παρουσιάζουμε ένα νευρωνικό μοντέλο για την αυτόματη δημιουργία σύνοψης φυσικής γλώσσας για γραφήματα. Οι περιλήψεις που δημιουργούνται παρέχουν μια ερμηνεία του διαγράμματος και μεταφέρουν τις βασικές πληροφορίες που βρέθηκαν μέσα σε αυτό το γράφημα. Το νευρωνικό μας μοντέλο αναπτύσσεται επεκτείνοντας το μοντέλο τελευταίας τεχνολογίας για την εργασία δημιουργίας δεδομένων σε κείμενο, το οποίο χρησιμοποιεί μια αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή βασισμένη σε μετασχηματιστή. Διαπιστώσαμε ότι η προσέγγισή μας ξεπερνά το μοντέλο βάσης σε μια μετρική επιλογή περιεχομένου κατά ένα ευρύ περιθώριο (55.42% έναντι 8.49%) και παράγει πιο ενημερωτικές, συνοπτικές και συνεκτικές περιλήψεις.', 'kk': 'Бар диаграммалар мен сызық диаграммалар секілді мәліметті визуализациялау деректерді зерттеу және байланысты көрсету үшін өте маңызды. Бұл визуализацияларды түсіндіру және түсіндіру кейбір адамдар үшін көпшілік көмектеседі, мысалы, визуализациялардың көмектесілігі немесе артық түсіндіру мүмкін. Бұл жұмыс ішінде, жаңа деректер жинағын келтіріп, диаграммалар үшін табиғи тілдерді автоматты түрде құру үшін невралдық моделін келтіреміз. Жасалған тұжырымдамалар диаграммасының түсініктемесін келтіріп, оның ішінде табылған кілттердің түсініктемесін береді. Біздің невралдық моделіміз деректер мен мәтін құру тапсырмасының күй- жай моделін кеңейту арқылы құрылады. Бұл түрлендіруші негізінде кодер- декодер архитектурасын қолданады. Біз тәсіліміздің мазмұнды таңдау метрикалық метрикалық негізгі үлгісін көбірек шегімен (55,42% vs. 8,49%) жасайды және көбірек мәлімет, тәсілдік және тәсілдік тәсіліктерді жа', 'lt': 'Informaciniai vizualizavimai, pavyzdžiui, juostų grafikai ir linijų grafikai, yra labai populiarūs duomenų žvalgymui ir informacijos perdavimui. Tokių vizualizacijų aiškinimas ir prasmė gali būti sunku kai kuriems žmonėms, pavyzdžiui, tiems, kuriems yra regėjimo sutrikimas arba kurie yra mažai vaizduojami raštu. Šiame darbe pristatome naują duomenų rinkinį ir pristatome nervinį model į, skirtą automatiškai kurti gamtinių kalbų santraukas grafikams. The generated summaries provide an interpretation of the chart and convey the key insights found within that chart.  Mūsų nervinis model is plėtojamas išplečiant naujausią model į, skirtą duomenų ir tekstų generavimo užduotims, kuria naudojama transformatoriumi pagrįsta kodavimo dekoderio architektūra. Nustatėme, kad mūsų požiūris yra didesnis už bazinį turinio atrankos metrinį model į plačiu maržu (55,42 proc., palyginti su 8,49 proc.) ir sukuria išsamesnes, glaudesnes ir nuoseklesnes santraukas.', 'it': "Le visualizzazioni di informazioni come grafici a barre e grafici a righe sono molto popolari per esplorare i dati e comunicare informazioni. Interpretare e dare un senso a tali visualizzazioni può essere difficile per alcune persone, come quelle che sono ipovedenti o hanno scarsa capacità di visualizzazione. In questo lavoro introduciamo un nuovo dataset e presentiamo un modello neurale per generare automaticamente riassunti di linguaggio naturale per i grafici. I riassunti generati forniscono un'interpretazione del grafico e trasmettono le informazioni chiave trovate all'interno di tale grafico. Il nostro modello neurale è sviluppato estendendo il modello all'avanguardia per il compito di generazione dati-testo, che utilizza un'architettura encoder-decoder basata su trasformatori. Abbiamo scoperto che il nostro approccio supera il modello base su una metrica di selezione dei contenuti di un ampio margine (55,42% vs. 8,49%) e genera riassunti più informativi, concisi e coerenti.", 'mk': 'Информациските визуализации како што се барови и линии карти се многу популарни за истражување на податоци и комуникација на информации. Интерпретањето и размислувањето за ваквите визуализации може да биде предизвик за некои луѓе, како што се оние кои се визуелно оштетени или имаат ниска визуализациска литература. Во оваа работа, ние воведуваме нови податоци и претставуваме нервен модел за автоматски генерирање на природни јазички резултати за графиките. Генеративните резултати обезбедуваат интерпретација на графиката и ги пренесуваат клучните информации пронајдени во таа графика. Нашиот нервен модел е развиен со проширување на најновиот модел за задачата на генерација на податоци до текст, која користи архитектура на кодер-декодер базирана на трансформатори. Најдовме дека нашиот пристап го надминува базичкиот модел на метричката селекција на содржината за широка маргина (55,42 отсто против 8,49 отсто) и генерира поинформативни, кратки и кохерентни резултати.', 'ms': 'Visualisasi maklumat seperti kad bar dan kad baris sangat populer untuk mengeksplorasi data dan berkomunikasi pandangan. Penjelasan dan memahami visualisasi tersebut boleh menjadi tantangan bagi beberapa orang, seperti orang-orang yang cacat visual atau mempunyai kecerdasan visualisasi rendah. In this work, we introduce a new dataset and present a neural model for automatically generating natural language summaries for charts.  Ringkasan yang dijana menyediakan interpretasi bagi kad dan menyampaikan pandangan kunci yang ditemui dalam kad itu. Model saraf kami dikembangkan dengan memperluas model-state-of-the-art untuk tugas generasi data-ke-teks, yang menggunakan arkitektur pengekod-dekoder berdasarkan pengubah. Kami mendapati bahawa pendekatan kita melebihi model asas pada metrik pemilihan kandungan dengan margin lebar (55.42% vs. 8.49%) dan menghasilkan ringkasan yang lebih maklumat, singkat, dan konsisten.', 'mt': "Il-viżwalizzazzjonijiet tal-informazzjoni bħal bar charts u line charts huma popolari ħafna għall-esplorazzjoni tad-dejta u l-komunikazzjoni tal-fehmiet. L-interpretazzjoni u s-sens ta’ viżwalizzazzjonijiet bħal dawn jistgħu jkunu ta’ sfida għal xi nies, bħal dawk li għandhom indeboliment viżwali jew li għandhom litteriżmu baxx ta’ viżwalizzazzjoni. F’dan ix-xogħol, a ħna nintroduċu sett ta’ dejta ġdid u nippreżentaw mudell newrali biex jiġġeneraw awtomatikament sommarji tal-lingwa naturali għall-mapep. Is-sommarji ġġenerati jipprovdu interpretazzjoni tal-grafika u jgħaddu l-fehmiet ewlenin li jinsabu f’dik il-grafika. Il-mudell newrali tagħna huwa żviluppat billi jestendi l-mudell l-aktar avvanzat għall-kompitu ta’ ġenerazzjoni tad-dejta għat-test, li juża arkitettura ta’ kodifikatur-dekoder ibbażata fuq it-trasformatur. Instabna li l-approċċ tagħna jaqbeż il-mudell bażiku fuq metrika tal-għa żla tal-kontenut b'marġini wiesa' (55.42% kontra 8.49%) u jiġġenera sommarji aktar informativi, konċiżi u koerenti.", 'ml': 'വിവരങ്ങളുടെ വിവരങ്ങള്\u200d ബാര്\u200d ചാര്\u200dട്ടും വരി ചിത്രങ്ങളും പരിശോധിക്കുന്നതിനും വിവരങ്ങള്\u200d പരിശോധിക്കുന്നതിനും വളരെ പ്ര ഇത്തരം കാഴ്ചപ്പെടുത്തുന്നതിന്റെയും മനസ്സിലാക്കുന്നതും ചില ആളുകള്\u200dക്ക് വേണ്ടി ചോദ്യം ചെയ്യാന്\u200d സാധിക്കുന്നതും കാണുന്ന ഈ ജോലിയില്\u200d, നമ്മള്\u200d ഒരു പുതിയ ഡാറ്റാസസെറ്റിനെ പരിചയപ്പെടുത്തുകയും ചിത്രങ്ങള്\u200dക്ക് സ്വാഭാവിക ഭാഷയുടെ ചുരുക്കം സൃ സൃഷ്ടിക്കപ്പെട്ട വിവരങ്ങള്\u200d ചാര്\u200dട്ടിന്\u200dറെ വിശദീകരണം നല്\u200dകുന്നു എന്നിട്ട് ആ ചാര്\u200dട്ടില്\u200d കണ്ടെത്തിയ ക നമ്മുടെ ന്യൂറല്\u200d മോഡല്\u200d നിര്\u200dമ്മിക്കപ്പെട്ടിരിക്കുന്നു. ഡേറ്റാ ടെക്സ്റ്റ് തലമുറതലമുറയ്ക്കുള്ള രീതിയിലെ മോഡല്\u200d വികസിപ്പിക്ക ഞങ്ങള്\u200d കണ്ടെത്തിയിരുന്നു നമ്മുടെ അടിസ്ഥാനത്തിന്\u200dറെ മോഡലിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d നിന്നും പ്രവര്\u200dത്തിപ്പിക്കുന്നത് (55.42% vs 8. 49%) വിശാലമായ വിവ', 'mn': 'Бар чарт, шугам чарт мэт мэдээллийн үзүүлэлт нь мэдээллийг судалж, харилцаа холбогдохын тулд их алдартай. Ийм дүрслэлүүдийг ойлгох болон ойлгох нь зарим хүмүүст төвөгтэй болж чадна. Яг харагдаж, харагдаж буй хүмүүст төвөгтэй байдаг. Энэ ажлын хувьд бид шинэ өгөгдлийн санг танилцуулж, диаграмм дээр байгалийн хэл дээр автоматжуулах мэдрэлийн загвар өгдөг. Бүтээгдэхүүний жинхэнэ дүрслэл нь диаграммын тухай ярьж, тэр диаграммын дотор олсон чухал ойлголтыг илтгэдэг. Бидний мэдрэлийн загвар нь өгөгдлийн хувьд текст бүтээлтийн ажлын байр суурь загварыг нэмэгдүүлснээр хөгжүүлж байна. Энэ нь шилжүүлэгч дээр суурилсан коддогч-декодер архитектурыг ашигладаг. Бид ойлголт нь тодорхойлолт сонголтын метрикийн суурь загварыг нэмэгдүүлдэг (55.42% vs. 8.49%) болон илүү мэдээллийн, тодорхойлолт, хоорондоо нийлүүлдэг.', 'no': 'Visualiseringar av informasjon, som listediagrammar og linjestykk, er veldig populært for å utforska data og kommunikasjonar. Omsetjing og gjennomsetjing av slike visualiseringar kan vera vanskeleg for nokre menneske, slik som dei som er synleg utvikla eller har låg visualisering. I dette arbeidet introduserer vi eit ny dataset og presenterer ein neuralmodell for automatisk laga naturspråk samandrag for diagrammar. Den genererte samandrag gjev eit tolking av diagrammet og flyttar nøkkelinnsiktene funne i diagrammet. Dette neuralmodellet er utvikla ved å utvide tilstanden av kunstmodellen for oppgåva for data- til- tekst, som brukar ein transformeringsbasert kodkoder- dekoderarkitektur. Vi fann at tilnærminga vårt utfører basemodellen på eit innhaldsutvalet metrisk med eit brett margin (55,42% mot 8,49%) og lager meir informativt, konkisert og koherent samandrag.', 'pl': 'Wizualizacje informacyjne, takie jak wykresy słupkowe i wykresy liniowe, są bardzo popularne do eksplorowania danych i przekazywania informacji. Tłumaczenie i uzyskanie sensu takich wizualizacji może stanowić wyzwanie dla niektórych osób, takich jak osób z upośledzeniem wzroku lub niską umiejętnością wizualizacji. W niniejszej pracy wprowadzamy nowy zestaw danych oraz przedstawiamy model neuronowy umożliwiający automatyczne generowanie podsumowań języka naturalnego dla wykresów. Generowane streszczenia zapewniają interpretację wykresu i przekazują kluczowe spostrzeżenia znalezione w tym wykresie. Nasz model neuronowy został opracowany poprzez rozszerzenie najnowocześniejszego modelu do zadania generowania danych do tekstu, który wykorzystuje architekturę kodera-dekodera opartą na transformatorze. Stwierdziliśmy, że nasze podejście przewyższa model bazowy dotyczący wyboru treści o duży margines (55,42% vs. 8,49%) i generuje bardziej informacyjne, zwięzłe i spójne podsumowania.', 'ro': 'Vizualizările informațiilor, cum ar fi diagramele cu bare și diagramele linii, sunt foarte populare pentru explorarea datelor și comunicarea informațiilor. Interpretarea și interpretarea unor astfel de vizualizări poate fi o provocare pentru unii oameni, cum ar fi cei care au deficiențe de vedere sau au o alfabetizare scăzută în vizualizare. În această lucrare, introducem un nou set de date și prezentăm un model neural pentru generarea automată a rezumatelor limbajului natural pentru diagrame. Rezumatele generate oferă o interpretare a graficului și transmit informațiile cheie găsite în acel grafic. Modelul nostru neural este dezvoltat prin extinderea modelului de ultimă generare a datelor-text, care utilizează o arhitectură codificator-decodor bazată pe transformator. Am constatat că abordarea noastră depășește modelul de bază pe o metrică de selecție a conținutului cu o marjă largă (55,42% față de 8,49%) și generează rezumate mai informative, concise și coerente.', 'si': 'දත්ත සහ සම්බන්ධ පරීක්ෂණය සඳහා බාර් චාර්ට්ස් සහ ලායින් චාර්ට්ස් වගේ තොරතුරු දර්ශනය සඳහා ගොඩක්  අනිවාර්යාත්මක කරන්න සහ අදහස් කරන්න පුළුවන් මිනිස්සු වෙනුවෙන් ප්\u200dරශ්නයක් වෙන්න පුළුවන්, හරියට ප්\u200dරශ්නයක් වෙ මේ වැඩේ අපි අළුත් දත්ත සෙට් එකක් පෙන්වන්න සහ චාර්ට්ස් වලට ස්වයංක්\u200dරිය භාෂාවක් සාමාන්\u200dය විදියට ස් නිර්මාණය කරලා තියෙන සංශ්\u200dය සංශ්\u200dය සංවේදනයක් චාර්ට් එකේ අභිවේදනයක් සඳහා ඒ චාර්ට් එකේ හ අපේ න්\u200dයූරාල් මොඩේල් විස්තර කරලා තියෙන්නේ දත්ත සිද්ධ විස්තර ක්\u200dරියාව සඳහා ස්ථිතිය-සිද්ධ විස්තරය සඳහා ස්ථිතිය-ක අපිට හොයාගත්තා අපේ ප්\u200dරවේශනය ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරන්න පුළුවන් සාමාන්\u200dය විකල්පයක් තෝරාගන්න (55.42% vs. 8.49%) වලින් පරීක්ෂණයක් ව', 'so': 'Wixii macluumaad lagu arko sida jardiinada barta iyo bandhigyadu waa kuwa aad u populan si ay u baaraandegaan macluumaadka iyo waxyaabaha la xiriira. Turjumidda iyo fikrada aragtida waxaa laga yaabaa in dad qaar ka mid ah caqabad, tusaale ahaan kuwa aragga laxaad la’aanta ama ay leeyihiin aqoon yar. Markaas waxan, waxaynu soo bandhignaa sawir cusub oo macluumaad ah, waxaana soo bandhignaa model neuro ah oo si automatic ah u sameynaya summarin luuqada asalka ah. Jardiinooyinka la soo saaray waxay fidiyaan turjumaadda kaarka, waxayna u sheegtaa aragtida furan ee laga helay kaarka gudaheeda. Tusaalkayaga neurada ah waxaa la horumariyey sida loo sii fidiyo qaabka xaaladda-farshaxanta, kaas oo isticmaalaya dhismaha sawir-sawir-u-qorid-ka-beddelista. Waxaynu helnay in dhaqdhaqaalkayagu uu ka muujiyo qaabka aasaasiga ah oo ku qoran baaritaanka waxyaabaha la doorto (55.42% vs. 8.49%) oo uu sameeyo macluumaad dheeraad ah, xaajooyin iyo xilli.', 'sv': 'Informationsvisualiseringar som stapeldiagram och linjediagram är mycket populära för att utforska data och kommunicera insikter. Att tolka och förstå sådana visualiseringar kan vara utmanande för vissa människor, till exempel de som är synskadade eller har låg visualiseringskompetens. I detta arbete introducerar vi en ny datauppsättning och presenterar en neural modell för att automatiskt generera naturliga språksammanfattningar för diagram. De genererade sammanfattningarna ger en tolkning av diagrammet och förmedlar de viktigaste insikterna i diagrammet. Vår neurala modell utvecklas genom att utöka den senaste modellen för data-till-text generation uppgift, som använder en transformatorbaserad encoder-dekoder arkitektur. Vi fann att vårt tillvägagångssätt överträffar basmodellen på ett innehållsval med en bred marginal (55,42% jämfört med 8,49%) och genererar mer informativa, koncisa och sammanhängande sammanfattningar.', 'sr': 'Informativne vizualizacije poput tablica i linijskih grafika su veoma popularne za istraživanje podataka i komunikaciju. Razumevanje i razmišljanje o takvim vizualizacijama može biti izazovno za neke ljude, kao što su oni koji su vizualno oštećeni ili imaju nisku vizualizaciju. U ovom poslu predstavljamo novi set podataka i predstavljamo neuralni model za automatsku stvaranje sažetaka prirodnog jezika za grafike. Generirani sažetci pružaju interpretaciju grafika i prenose ključne uvide koje su pronađene u tom grafiku. Naš neuralni model se razvija proširenjem stanja umetničkog model a za zadatak generacije podataka na tekst, koji koristi arhitekturu kodera na transformaciji. Pronašli smo da naš pristup iznosi bazni model na metriku selekcije sadržaja širom marginom (55,42% protiv 8,49%) i stvara informativnije, konkretnije i sasluženije sažetke.', 'ur': 'جیسے بار چارٹ اور لین چارٹ بہت محبوب ہیں ڈیٹا کا تحقیق اور بصیرت کا ارتباط کرنے کے لئے۔ اس طرح کی تصویزی کا تفصیل اور سمجھ کرنا بعض لوگوں کے لئے مشکل ہے، جیسے وہ لوگ جن کو نظر انداز ہو یا کم تصویزی کا ذریعہ ہے۔ ہم نے اس کام میں ایک نئی ڈاٹ سٹ کو معلوم کریں اور چارٹوں کے لئے طبیعی زبان کے سامنے آزاد کرنے کے لئے نئورل موڈل کو پیش کریں۔ پیدا کئے گئے سارے چارٹ کی تعبیر دیتے ہیں اور اس چارٹ کے اندر پائی ہوئی کلید معلومات کو پہنچاتے ہیں. ہمارا نئورل موڈل ڈیٹ پر ٹیکسٹ نسل کے کام کے لئے استعمال کرنے کے ذریعہ استعمال کیا گیا ہے جو ایک ٹیکسٹر-بنیادی اکڈر-ڈیکوڈر معماری کے مطابق استعمال کرتا ہے. ہم نے دیکھا کہ ہماری تقریبا ایک منزل منزل کے منزل کے منزل کے ذریعہ ایک وسیع منزل (55.42% vs. 8.49%) پر بنسٹ موڈل کو عمدہ کر رہا ہے اور اس سے زیادہ معلومات، معلومات اور مشکل ترکیب پیدا کرتا ہے۔', 'ta': 'தகவல் பார்வைகள் மற்றும் வரி வரி வரைபடங்கள் போன்ற தகவல் பார்வைகள் தகவல் மற்றும் தொடர்பு கூறும் குறிப்புகளை தேடுவதற்க இத்தகைய பார்வைகளை மொழிபெயர்ப்பு மற்றும் உணர்வு சில மக்களுக்கு சவாலாக இருக்கலாம், பார்வையில் குறைந்தவர்கள் அல்லது பார்வையில இந்த வேலையில், நாம் ஒரு புதிய தகவல் அமைப்பை குறிப்பிட்டு வரைபடங்களுக்கு தானாகவே இயல்பான மொழி சுருக்கங்களை உருவாக்கு The generated summaries provide an interpretation of the chart and convey the key insights found within that chart.  தகவல்- உரை உருவாக்கும் பணிக்கான நிலையின் மாதிரி மாதிரி உருவாக்கப்பட்டது, இது மாற்றும் அடிப்படையிலான குறியீட்டு குறியீட்டு அமைப்பை பயன்படு நாங்கள் கண்டுபிடித்துக் கொண்டோம் என்றால் நமது அடிப்படை மாதிரியை வெளியேற்றும் பொருள் தேர்ந்தெடுப்பு மெட்ரிக்கையில் செயல்படுத்துகிறது ஒரு', 'uz': "Name Ko'rinishni o'rganish va o'rganish bir necha odamlar uchun qanday qilishi mumkin, xuddi ko'rinishni ko'rinishni o'rganish yoki ko'rinishi haqida yaratish mumkin. Bu ishda, biz yangi maʼlumotlar tarkibini aniqlash va avtomatik raqamli tilning muhitirlari yaratish uchun neyrol modelini koʻrsatish. @ info: whatsthis Bizning neyrolik modelimiz taʼlumotlar matn yaratish vazifasi holatini ajratish mumkin. Bu vazifani o'zgartirish asosida kodkoder- dekoder architektidan foydalanadi. We found that our approach outperforms the base model on a content selection metric by a wide margin (55.42% vs. 8.49%) and generates more informative, concise, and coherent summaries.", 'vi': 'Các hình ảnh thông tin như các bảng thanh và các biểu đồ đường nét rất phổ biến để tìm hiểu thông tin và giao tiếp. Việc giải thích và hiểu rõ những hình ảnh như vậy có thể gây khó khăn cho một số người, như những người bị mù suy giảm hoặc có khả năng hiểu rõ hình ảnh thấp. Trong công trình này, chúng tôi giới thiệu một bộ dữ liệu mới và một mô hình thần kinh để tự động tạo ra các bản đồ ngôn ngữ tự nhiên. Những bản tóm tắt tạo ra cung cấp một cách giải thích của biểu đồ và truyền đạt những nhận thức chủ chốt tìm thấy trong biểu đồ đó. Hệ thống thần kinh của chúng tôi được phát triển bằng cách mở rộng hệ thống truyền dữ liệu sang văn bản, sử dụng cấu trúc mã hóa dựa vào máy biến. Chúng tôi phát hiện ra cách tiếp cận của chúng tôi hoàn thiện mô hình căn cứ dựa trên một thước đo nội dung bằng một khối lớn (5004=.=) và tạo ra các bản tóm tắt thêm thông tin, ngắn gọn và liên quan.', 'hr': 'Visualizacije informacija poput tablica i linijskih grafika su vrlo popularne za istraživanje podataka i komunikaciju. Razumijevanje i osjećanje takvih vizualizacija može biti izazovno za neke ljude, poput one koji su vizualno oštećeni ili niske vizualizacije. U ovom poslu predstavljamo novi set podataka i predstavljamo neuralni model za automatski proizvedenje sažetaka prirodnog jezika za grafike. Generirani sažetci pružaju interpretaciju grafika i prenose ključne uvjete pronađene u tom grafiku. Naš neuronski model se razvija proširenjem model a umjetnosti za zadatak generacije podataka na tekst, koji koristi arhitekturu kodera-dekodera na transformaciji. Pronašli smo da naš pristup nadmašuje bazni model na selekciji sadržaja metrika širom marginom (55,42% protiv 8,49%) i stvara informativnije, konkretnije i sasluženije sažetke.', 'da': 'Informationsvisualiseringer som stregdiagrammer og linjediagrammer er meget populære til at udforske data og formidle indsigt. At fortolke og give mening til sådanne visualiseringer kan være udfordrende for nogle mennesker, f.eks. dem, der er synshæmmede eller har lav visualiseringsfærdighed. I dette arbejde introducerer vi et nyt datasæt og præsenterer en neural model til automatisk generering af natursprog resuméer til diagrammer. De genererede resuméer giver en fortolkning af diagrammet og formidler de vigtigste indsigter, der findes i diagrammet. Vores neurale model er udviklet ved at udvide den state-of-the-art model for data-to-tekst generation opgave, som bruger en transformer-baseret encoder-dekoder arkitektur. Vi fandt ud af, at vores tilgang overgår basismodellen på en metric for indholdsvalg med en bred margin (55,42% mod 8,49%) og genererer mere informative, kortfattede og sammenhængende resuméer.', 'nl': 'Informatie visualisaties zoals staafdiagrammen en lijndiagrammen zijn erg populair voor het verkennen van gegevens en het communiceren van inzichten. Het interpreteren en begrijpen van dergelijke visualisaties kan een uitdaging zijn voor sommige mensen, zoals mensen met een visuele beperking of een lage visualisatie geletterdheid. In dit werk introduceren we een nieuwe dataset en presenteren we een neuraal model voor het automatisch genereren van natuurlijke taalsamenvattingen voor grafieken. De gegenereerde samenvattingen geven een interpretatie van de grafiek en brengen de belangrijkste inzichten uit die grafiek. Ons neurale model wordt ontwikkeld door het state-of-the-art model uit te breiden voor de data-to-text generatie taak, dat gebruikmaakt van een transformator gebaseerde encoder-decoder architectuur. We ontdekten dat onze aanpak het basismodel op een inhoudselectiemetriek met een grote marge overtreft (55,42% vs. 8,49%) en meer informatieve, beknopte en coherente samenvattingen genereert.', 'bg': 'Визуализациите на информация като бардиаграми и линейни диаграми са много популярни за проучване на данни и комуникация на прозрения. Тълкуването и осмислянето на такива визуализации може да бъде предизвикателство за някои хора, като например тези, които са със зрително увреждане или имат ниска визуална грамотност. В тази работа въвеждаме нов набор от данни и представяме невронен модел за автоматично генериране на резюмета от естествени езици за диаграми. Генерираните резюмета предоставят интерпретация на диаграмата и предават ключовите прозрения, намерени в тази диаграма. Нашият невронен модел е разработен чрез разширяване на най-съвременния модел за задачата за генериране на данни към текст, който използва базирана на трансформатор кодер-декодер архитектура. Установихме, че нашият подход превъзхожда базовия модел на метричен подбор на съдържание с широк марж (55.42% при 8.49%) и генерира по-информативни, кратки и съгласувани резюмета.', 'de': 'Informationsvisualisierungen wie Balkendiagramme und Liniendiagramme sind sehr beliebt, um Daten zu erkunden und Erkenntnisse zu vermitteln. Das Dolmetschen und Verstehen solcher Visualisierungen kann für manche Menschen eine Herausforderung darstellen, beispielsweise für Menschen mit Sehbehinderung oder geringer Visualisierungskompetenz. In dieser Arbeit stellen wir einen neuen Datensatz vor und stellen ein neuronales Modell zur automatischen Generierung natürlicher Sprachzusammenfassungen für Diagramme vor. Die generierten Zusammenfassungen liefern eine Interpretation des Diagramms und vermitteln die wichtigsten Erkenntnisse, die in diesem Diagramm gefunden werden. Unser neuronales Modell wird durch Erweiterung des State-of-the-Art Modells für die Daten-zu-Text-Generierungsaufgabe entwickelt, das eine transformatorbasierte Encoder-Decoder-Architektur nutzt. Wir fanden heraus, dass unser Ansatz das Basismodell für eine Inhaltsauswahlmetrik um einen großen Spielraum übertrifft (55,42% vs. 8,49%) und informativere, prägnantere und kohärentere Zusammenfassungen generiert.', 'id': 'Visualisasi informasi seperti bar chart dan line chart sangat populer untuk mengeksplorasi data dan komunikasi penglihatan. Interpretasi dan memahami visualisasi tersebut dapat menantang bagi beberapa orang, seperti orang-orang yang mengalami cacat visual atau memiliki kebijaksanaan visualisasi rendah. Dalam pekerjaan ini, kami memperkenalkan set data baru dan memperkenalkan model saraf untuk secara otomatis menghasilkan ringkasan bahasa alam untuk grafik. Ringkasan yang dihasilkan memberikan interpretasi dari grafik dan menyampaikan pandangan kunci yang ditemukan dalam grafik itu. Model saraf kita dikembangkan dengan memperluas model state-of-the-art untuk tugas generasi data-ke-teks, yang menggunakan arsitektur pengekode-dekoder berdasarkan transformer. Kami menemukan bahwa pendekatan kita melebihi model dasar pada metrik seleksi konten dengan margin lebar (55,42% vs. 8,49%) dan menghasilkan ringkasan yang lebih informatif, singkat, dan konsisten.', 'sw': 'Kuonyesha taarifa kama vile chart za baro na chart za mstari ni maarufu sana kwa kutafuta taarifa na maoni ya mawasiliano. Kutafsiri na kutambua maono kama haya yanaweza kuwa na changamoto kwa baadhi ya watu, kama wale ambao wameathirika kwa kuona au wana ufahamu mdogo wa kuona. Katika kazi hii, tunaonyesha seti mpya ya taarifa na kuweka mtindo wa neura kwa ajili ya kutengeneza muhtasari wa lugha za asili kwa ajili ya charts. Makala yaliyozaliwa yanatoa tafsiri ya ramani hiyo na kutoa maoni muhimu yaliyopatikana ndani ya ramani hiyo. Mradi wetu wa kiserikali umeundwa kwa kuongeza muundo wa hali ya sanaa kwa ajili ya kazi za kizazi cha taarifa hadi ujumbe wa ujumbe, ambazo hutumia ujenzi wa kodi-decode inayohusiana na mabadiliko. Tumegundua kuwa hatua yetu inafanya mifano ya msingi kwenye mitindo ya uchaguzi wa maudhui kwa kiasi kikubwa (55.42% vs. 8.49%) na inatengeneza muhtasari wa habari, mahususi na muhtasari wa pamoja.', 'fa': 'تصویرات اطلاعات مثل نقشه\u200cهای بار و نقشه\u200cهای خط بسیار مشهور برای تحقیق داده\u200cها و ارتباط با مشاهده\u200cها هستند. تعبیر و احساس این تصویر ها برای بعضی از مردم، مثل کسانی که به نظر آسیب دیده\u200cاید یا نوشته\u200cی تصویر کمی دارند، می\u200cتوانند سخت بگیرند. در این کار، ما یک مجموعه داده\u200cهای جدید را معرفی می\u200cکنیم و یک مدل عصبی را برای تولید کردن مجموعه\u200cهای زبان طبیعی برای نقشه\u200cها نشان می\u200cدهیم. جمع\u200cآوری\u200cها تولید شده\u200cاند یک تعبیر از نمودار را می\u200cدهند و مشاهده\u200cهای کلید در آن نمودار را می\u200cدهند. مدل عصبی ما توسعه می\u200cشود با افزایش مدل وضعیت هنری برای کار تولید داده\u200cها به متن، که از یک معماری که بر اساس تغییر دهنده\u200cها بنیاد می\u200cآید، استفاده می\u200cکند. ما فهمیدیم که دستور ما مدل بنیادی را بر یک منطقه انتخاب محتویات متریک با یک منطقه وسیع (55.42% vs. 8.49%) انجام می دهد و جمع\u200cآوری اطلاعات بیشتری، دقیق و هماهنگی می\u200cکند.', 'ko': '정보의 시각화(예를 들어 스트라이프맵과 접선도)는 데이터를 탐색하고 견해를 교류하는 데 매우 유행한다.일부 사람들에게 이런 시각화를 해석하고 이해하는 것은 도전일 수 있다. 예를 들어 시력이 손상되거나 시각화 소양이 낮은 사람들이다.이 작업에서 우리는 새로운 데이터 집합을 도입하고 도표의 자연 언어 요약을 자동으로 생성하는 신경 모델을 제시했다.생성된 요약은 도표에 대한 해석을 제공하고 이 도표에서 발견된 관건적인 견해를 전달한다.우리의 신경 모델은 데이터를 확장하여 텍스트 생성 임무를 수행하는 최신 모델을 통해 개발된 것으로 이 모델은 변압기 기반의 인코더-디코더 구조를 사용한다.우리는 내용 선택 지표에 있어서 우리의 방법이 기본 모델보다 훨씬 낫다(55.42% 대 8.49%)를 발견했고 더 많은 정보, 간결함과 일관된 요약을 생성했다.', 'tr': 'Çap çizgileri we hatlary ýaly maglumat görkezilişmeleri, maglumatlary gözlemek we geýinişlemek üçin örän meşhur. Böyle görselleri düşünmek we düşünmek käbir adamlar üçin kynçylyk edip biler, görsel hasaplanýan ýa-da düşük görselleştirme edebiýaty ýaly. Bu işde, täze bir dataseti tanyşdirip, täze diller üçin baýram dillerini öz-özüne bejermek üçin bir nural nusgasyny çykarýarys. üretilen toplamlar grafikiň bir terjimesini temin edip, we şol grafikiň içinde tapylan aç noktalary görkez. Biziň neiral nusgasymyz data-a-tekst döredişi işi üçin stat-of-the-art nusgasyny uzatmak bilen geliştirildi. Bu nusgasymyz sisteminde koder-dekoder arhitektegi ullanýar. Biziň ýaryşymyz daňry bir mahal saýlawyň metriklerinde üýtgeşik gabdalyk (55.42% vs. 8.49%) üstünde esasy nusgasyny çykýar we daňry informatiýa, konkes we coherent sammlary döredir.', 'af': "Informasie visualiserings soos balk kaarte en lyn kaarte is baie populaar vir ondersoek van data en kommunikasie inligtings. Interpreting en maak sens van sodanige visualiserings kan vir sommige mense uitgelyk wees, soos die wat visualiseer invloei is of het lae visualisering literateit. In hierdie werk, introduseer ons 'n nuwe datastel en voorsien 'n neurale model vir outomaties genereer natuurlike taal opsommings vir kaarte. Die genereerde opsommings verskaf 'n uitlegging van die kaart en bring die sleutel inligtings wat binne daardie kaart gevind is. Ons neurale model is ontwikkeld deur die state-of-the-art model te verleng vir die data-to-text generation taak, wat gebruik 'n transformer-gebaseerde enkoder-dekoder-arkitektuur. Ons het gevind dat ons toegang uitvoer die basis model op 'n inhoud keuse metrie deur 'n wyde marjin (55.42% teen 8.49%) en genereer meer inligtige, samekoms en samekoms.", 'sq': 'Vizualizimet e informacionit të tilla si kartat e linjave dhe kartat e linjave janë shumë të popullarizuara për eksplorimin e të dhënave dhe komunikimin e kuptimeve. Interpretimi dhe kuptimi i vizualizimeve të tilla mund të jetë sfidues për disa njerëz, të tillë si ata që janë të dëmtuar vizualisht apo kanë shkrim vizualizues të ulët. In this work, we introduce a new dataset and present a neural model for automatically generating natural language summaries for charts.  Përmbledhjet e gjeneruara ofrojnë një interpretim të grafikut dhe transmetojnë pamjet kryesore të gjetura brenda atij grafiku. Modeli ynë neural është zhvilluar duke zgjeruar modelin më të lartë për detyrën e gjenerimit të të dhënave në tekst, i cili përdor një arkitekturë koduesi-dekoderi bazuar në transformues. Ne zbuluam se qasja jonë e tejkalon modelin bazë në një metrikë zgjedhjeje të përmbajtjes me një margin të gjerë (55.42% krahasuar me 8.49%) dhe gjeneron përmbledhje më informative, të shkurtra dhe koherente.', 'am': 'ዳታ እና ማቀናጃ ማቀናቀል እና የመስመር ማህበረሰብ እንደምትመስል የሀብት ማህበረሰብ እጅግ የበለጠ ነው፡፡ እንደዚህ ባለ ራእይ መተርጓሜ እና ማሳየት ለአንዳንዶች፣ ያይነቱ ደካማ ወይም የራእይ ሐሳብ ያላቸው ሰዎች ማዋጋት ይችላል፡፡ በዚህ ሥራ አዲስ የዳታ ሰርተቶችን እናሳውቃለን እና ለባሕላዊ ቋንቋ ጉዳዮች ለካርተሮች ማሳየያ የደብዳቤ ሞዴል እናቀርባለን፡፡ የተፈጠረው አረንጓዴዎች የካርታ ትርጉም ይሰጣቸዋል፡፡ የናውሬው ሞዴል ለዳታ-ወደ-ጽሑፍ ትውልድ ስራ መዘርጋት የሀብት-የ-አርእስት ሞዴል መዘርጋት ነው፡፡ አካሄዳችን በመምረጥ ማተሚያ ላይ የሚደረገውን መሠረት (55.42 በመቶ ወደ8.49 በመቶ) እና የተመረጠውን፣ ቁጥጥር እና የተጨማሪውን አዋጅ እንዲያሳየው አግኝተናል፡፡', 'hy': 'Տեղեկատվական վիզուալիզացիաները, ինչպիսիք են խողովակները և գծերի գծերը, շատ հայտնի են տվյալների ուսումնասիրելու և տեղեկատվության ընկալումների համար: Այսպիսի վիզուալիզացիաների մեկնաբանությունը և իմաստավորումը կարող է դժվար լինել որոշ մարդկանց համար, ինչպիսիք են օրինակ նրանք, ովքեր վիզուալիզացիայի խնդիրներ ունեն կամ ովքեր ունեն ցածր վիզուալիզացիայի գրականություն: In this work, we introduce a new dataset and present a neural model for automatically generating natural language summaries for charts.  Գործված համառոտագրությունները տալիս են աղյուսակի մեկնաբանությունը և հաղորդում են այդ աղյուսակի մեջ գտնվող գլխավոր ընկալումները: Մեր նյարդային մոդելը զարգացվում է ընդլայնելով տվյալների ստեղծման վերջին մոդելը տեքստի առաջադրանքի համար, որը օգտագործում է վերափոխողի հիմնված կոդեր-կոդեր ճարտարապետություն: Մենք հայտնաբերեցինք, որ մեր մոտեցումը գերազանցում է հիմնական մոդելը պարունակության ընտրության մետրիկայի վրա լայն տարբերակով (55.42 տոկոս, համեմատած 8.49 տոկոսին), և ստեղծում է ավելի տեղեկատվական, կարճ և համապատասխան համառոտագրություններ:', 'az': 'Bar çizgələri və çizgi çizgələri kimi məlumatları keşfetmək və əlaqələri ilə əlaqə etmək üçün çox məşhurdur. Bütün bu vizualizasyonların anlaşılması və anlaşılması bəzisi insanlar üçün çətin olar, bəzisi şəkildə zəif olanlar və ya düşük vizualizasyon yazılımları olan insanlar kimi. Bu işdə, yeni verilən qurğunu tanıyırıq və çiftlər üçün təbiətli dil toplamlarını avtomatik olaraq yaratmaq üçün nöral modeli göstəririk. Yapılmış toplamlar diagramin yorumlayıcını təmin edir və bu diagramda bulunan anahtar anlayışları təmin edir. Bizim nöral modelimiz, data-to-text nəzəriyyəti işinin durumu-sanat modelini genişləndirək, transformer-tabanlı koder-dekoder arhitektarını istifadə edir. Yaxınlığımız məlumat seçimlərinin metriklərindən çox geniş qədər (55,42% vs. 8,49%) üssü modelini üstün edir və daha informativ, concise və coherent toplamlar yaradır.', 'bn': 'তথ্যের দৃষ্টিভঙ্গি যেমন বার চার্ট এবং লাইন চ্যার্ট অনেক জনপ্রিয়। এই ধরনের দৃষ্টিভঙ্গি সম্পর্কে ব্যাখ্যা এবং বুঝতে পারে কিছু মানুষের জন্য চ্যালেঞ্জ হতে পারে, যেমন যারা দৃষ্টিভঙ্গি হারিয়ে এই কাজে আমরা একটি নতুন ডাটাসেট পরিচয় করিয়ে দেই এবং স্বয়ংক্রিয়ভাবে প্রাকৃতিক ভাষার সারিম তৈরি করার জন্য একটি নিউরেল মডেল উপস তৈরি করা সংক্ষেপ এই চার্টের ব্যাখ্যা প্রদান করে এবং এই চ্যার্টের ভেতরে পাওয়া গেছে কী দৃষ্টিভঙ্গি প্রদান কর ডাটা থেকে টেক্সট প্রজন্মের কাজের জন্য আমাদের নিউরেল মডেল উন্নয়ন করা হয়েছে, যা পরিবর্তনের ভিত্তিক কোডার-ডেকোডার কাঠামো ব্যবহার করে। আমরা আবিষ্কার করেছি যে আমাদের প্রতিযোগিতা বিশাল মার্গিনের মাধ্যমে একটি বিষয়বস্তু নির্বাচিত মেট্রিকে বেশী প্রকাশ করে এবং আরো তথ্য, কনসিস এবং সংক্রান্ত', 'bs': 'Informativne vizualizacije poput tablica i linijskih grafika su veoma popularne za istraživanje podataka i komunikaciju uvida. Razumijevanje i osjećanje takvih vizualizacija može biti izazovno za neke ljude, kao što su oni koji su vizualno oštećeni ili imaju nisku vizualizaciju. U ovom poslu predstavljamo novi set podataka i predstavljamo neuralni model za automatski stvaranje sažetaka prirodnog jezika za grafike. Generirani sažetci pružaju interpretaciju grafika i prenose ključne uvide pronađene u tom grafiku. Naš neuronski model se razvija proširenjem model a stanja umjetnosti za zadatak generacije podataka na tekst, koji koristi arhitekturu kodera na transformaciji. Pronašli smo da naš pristup iznosi bazni model na metriku selekcije sadržaja širom marginom (55,42% protiv 8,49%) i stvara informativnije, konkretnije i sasluženije sažetke.', 'ca': "Visualitzacions d'informació com gràfics de barres i gràfics de línies són molt populars per explorar les dades i comunicar les informacions. Interpretar i tenir sentit d'aquestes visualitzacions pot ser un repte per a algunes persones, com per exemple aquelles que tenen deficiències visuals o tenen baixa alfabetització visual. En aquest treball, introduïm un nou conjunt de dades i presentem un model neural per generar automàticament resums de llenguatges naturals per a les gràfics. Els resums generats proporcionen una interpretació del gràfic i transmiten les idees clau trobadas dins aquest gràfic. El nostre model neural s'està desenvolupant estendre el model d'última generació de dades a text, que utilitza una arquitectura de codificador basada en transformadors. Vam descobrir que el nostre enfocament supera el model de base en una mètrica de selecció de continguts d'un gran marge (55,42% vs 8,49%) i genera resumes més informatius, concis i coherents.", 'cs': 'Informační vizualizace, jako jsou pruhové grafy a čárové grafy, jsou velmi oblíbené pro zkoumání dat a komunikaci přehledů. Tlumočení a dávání smyslu těchto vizualizací může být pro některé lidi náročné, například ty, kteří jsou zrakově postiženi nebo mají nízkou vizualizační gramotnost. V této práci představujeme novou datovou sadu a představujeme neuronový model pro automatické generování souhrnů přirozeného jazyka pro grafy. Generované souhrny poskytují interpretaci grafu a sdělují klíčové poznatky nalezené v tomto grafu. Náš neuronový model je vyvinut rozšířením nejmodernějšího modelu pro úlohu generování dat na text, který využívá transformátorovou architekturu kodéru a dekodéru. Zjistili jsme, že náš přístup předčí základní model na metrice výběru obsahu o široké rozpětí (55,42% vs. 8,49%) a generuje informativnější, stručnější a soudržnější shrnutí.', 'et': 'Teabe visualiseerimised, näiteks tribdiagrammid ja joonediagrammid, on väga populaarsed andmete uurimiseks ja ülevaate edastamiseks. Selliste visualiseerimiste tõlgendamine ja mõistmine võib olla keeruline mõnedele inimestele, näiteks neile, kes on nägemispuudega või kellel on madal visualiseerimisalastus. Käesolevas töös tutvustame uut andmekogumit ja tutvustame neuromudelit graafikutele looduskeele kokkuvõtete automaatseks genereerimiseks. Koostatud kokkuvõtted annavad diagrammi tõlgenduse ja annavad selles diagrammis leitud peamised ülevaated. Meie närvimudel on välja töötatud, laiendades andmete genereerimise ülesandeks kaasaegset mudelit, mis kasutab trafopõhist kodeerija-dekooderi arhitektuuri. Leidsime, et meie lähenemisviis on sisuvaliku mõõdiku baasmudelist suurem (55,42% vs 8,49%) ning loob informatiivsemad, lühikesemad ja sidusamad kokkuvõtted.', 'fi': 'Tietojen visualisoinnit, kuten palkkikaaviot ja viivakaaviot, ovat erittäin suosittuja tietojen tutkimiseen ja tietojen välittämiseen. Tällaisten visualisointien tulkinta ja järkeistäminen voi olla haastavaa joillekin ihmisille, kuten niille, jotka ovat näkövammaisia tai joilla on heikko visualisointi lukutaito. Tässä työssä esitellään uusi aineisto ja esitetään neuromalli luonnollisen kielen yhteenvetojen automaattiseen tuottamiseen kaavioille. Luodut yhteenvedot antavat tulkinnan kaaviosta ja välittävät kaaviosta löydetyt keskeiset näkemykset. Neuromallimme on kehitetty laajentamalla datasta tekstiin -luontitehtävään uusinta mallia, jossa hyödynnetään muuntajapohjaista kooderi-dekooderiarkkitehtuuria. Havaitsimme, että lähestymistapamme on sisällönvalintamittarin perusmallia parempi (55,42% vs. 8,49%) ja tuottaa informatiivisempia, tiiviimpiä ja johdonmukaisempia yhteenvetoja.', 'sk': 'Vizualizacije informacij, kot so vrsticni grafikoni in črtni grafikoni, so zelo priljubljene za raziskovanje podatkov in komuniciranje vpogledov. Tolmačenje in smiselno razumevanje takšnih vizualizacij je lahko za nekatere ljudi izziv, na primer tiste, ki so slabovidni ali imajo nizko vizualno pismenost. V tem delu predstavljamo nov nabor podatkov in predstavljamo nevronski model za samodejno generiranje povzetkov naravnega jezika za grafikone. Ustvarjeni povzetki zagotavljajo interpretacijo grafikona in predstavljajo ključne vpoglede, ki jih najdemo v grafikonu. Naš nevronski model je razvit z razširitvijo najsodobnejšega modela za nalogo generiranja podatkov v besedilo, ki uporablja transformatorsko arhitekturo kodirnika-dekodirnika. Ugotovili smo, da naš pristop presega osnovni model pri meritvi izbire vsebine za široko maržo (55,42% v primerjavi z 8,49%) in ustvarja bolj informativne, jedrnate in skladne povzetke.', 'he': 'ויזואליזציות מידע כמו רשימות ברדים ורשימות קווים מאוד פופולריות לחקור נתונים ולהתקשר לתבנות. ההתרשמות וההגיונית של חיזויים כאלה יכולות להיות מאתגרים עבור כמה אנשים, כמו אלה שיש להם פגיעות חיזויים או שיש להם ספרות חיזויים נמוכה. בעבודה הזו, אנחנו מציגים קבוצת נתונים חדשה ומציג מודל עצבי לייצור אוטומטי סדרות שפה טבעית לתרשים. הסרטים הנוצרים מספקים פירוש של התרשים ולהעביר את ההבנות המפתחות שנמצאו בתוך התרשים הזה. המודל העצבי שלנו פותח על ידי הרחיבה של המודל המאודם למשימת הדור של נתונים לטקסט, אשר משתמש בארכיטקטורת קודד-קידור מבוססת על מעבר. מצאנו שהגישה שלנו מעלית את הדוגמנית הבסיסית על מטריקת הבחירה של תוכן על ידי שווה רחבה (55.42% vs. 8.49%) ומוצרת סדרות מידעיות, קצרות וקשורות יותר.', 'ha': "Kunna zane-zane kamar bangon charter da jerin na jerin, sun zama mafiya popular dõmin su nẽmi gane da za'a haɗi da gannai. Ana fassarar da gareshi da za'a iya zama mai ƙaranci ga wasu mutane, kamar waɗanda aka raunanta ga gannai ko kuwa sunã da littafin ƙaranci. Daga wannan aikin, muna haɗa wani sabo na danne na yanzu, kuma muna sami wata motsi na neura dõmin a ƙiƙiro ƙararin harshen farat ɗaya wa zaɓe kurs ga KChart. QFontDatabase An buɗe shirin neural da ke shimfiɗa halin-sanar wa aikin data-to-text, wanda ke yi amfani da wani layin da aka bada-bane kode-coder. Mun gane cewa hanyoyinmu yana samar da misalin basasa a kan zaɓen wani metriki mai ƙunci (55.42% vers 8.49%) kuma yana samun ƙarami masu da labarai, ko da ƙarami.", 'jv': 'Visual Informasi sing dibutuhke gambar diagram karo linen diagram sing populer kanggo kebah data karo komunikasi Jejaring Nang barêng-barêng iki, kéné mulai nggawe dataset anyar lan gawe ngubah model nêr kuwi nggawe tarjamahan kanggo nggawe resmi adalah kanggo nggawe tarjamahan. Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define" means "Define Njuk model sing wis digawe oleh nggawe barang nggawe state-of-the-Art model nggo data-to-text Generation task, kuwi nggawe barang transformer-basa koder-decoder architecture. Awak dhéwé ngerti nggawe dadi nggawe modèl kuwi nggawe dadi, dadi iki dadi, nik awak dhéwé kesempatan (75.34% karo 8.49 %) lan nganggep sistem informasi, sampeyan karo coherent sampeyan.', 'bo': 'འཆར་བཤེར་དང་བྲལ་རིས་མང་ཆེ་བའི་ཆ་འཕྲིན་ལ་སྟོན་པར་ཆས། དབྱིན་བཟོ་བྱེད་དང་ལྟ་བུའི་རྣམ་པ་ཞིག་འདི་དག་པར་ཐད་ཀར་ཆེན་ཡིན། འོན་ཀྱང་། ང་ཚོས་བྱ་ཚིག་ནང་དུ་ཆ་འཕྲིན་ཡིག་ཆ་གསར་བ་ཞིག་སྟོན་པ་དང་རང་འགུལ་གྱིས་མིའི་རྣམ་གྲངས་སྒྲིག་ཆས་ གསར་བསྐྲུན་ཡོད་པའི་བཅུད་སྡུད་དེ་གི་རིས་བཀོད་རིས་ལ་གསལ་བཤད་བྱེད་ཀྱི་ཡོད་དོན་མིན་འདུག Our neural model is developed by extending the state-of-the-art model for the data-to-text generation task, which utilizes a transformer-based encoder-decoder architecture. We found that our approach outperforms the base model on a content selection metric by a wide margin (55.42% vs. 8.49%) and generates more informative, concise, and coherent summaries.'}
{'en': 'Disentangling the Properties of Human Evaluation Methods : A Classification System to Support Comparability, Meta-Evaluation and Reproducibility Testing', 'es': 'Desenredar las propiedades de los métodos de evaluación humana: un sistema de clasificación para apoyar las pruebas de comparabilidad, metaevaluación y reproducibilidad', 'ar': 'فصل خصائص طرق التقييم البشرية: نظام تصنيف لدعم المقارنة والتقييم التلوي واختبار القابلية للتكاثر', 'fr': "Démêler les propriétés des méthodes d'évaluation humaines\xa0: un système de classification pour soutenir la comparabilité, la méta-évaluation et les tests de reproductibilité", 'pt': 'Desembaraçando as propriedades dos métodos de avaliação humana: um sistema de classificação para apoiar comparabilidade, meta-avaliação e testes de reprodutibilidade', 'zh': '解人质:主可比性、元评、再现性试之统', 'ja': '人間の評価方法の特性の解離：比較性、メタ評価、再現性試験をサポートする分類システム', 'hi': 'मानव मूल्यांकन विधियों के गुणों को अलग करना: तुलनात्मकता, मेटा-मूल्यांकन और पुनरुत्पादन परीक्षण का समर्थन करने के लिए एक वर्गीकरण प्रणाली', 'ru': 'Распутывание свойств методов оценки человека: система классификации для поддержки сопоставимости, метаоценки и тестирования воспроизводимости', 'ga': 'Airíonna Modhanna Measúnaithe Daonna a Dhícheangal: Córas Aicmithe chun Tacú le Tástáil Inchomparáideachta, Meitea-mheastóireachta agus In-atáirgtheachta', 'el': 'Διασύνδεση των ιδιοτήτων των μεθόδων αξιολόγησης του ανθρώπου: Ένα σύστημα ταξινόμησης για την υποστήριξη της συγκρισιμότητας, της μετα-αξιολόγησης και της δοκιμής αναπαραγωγής', 'hu': 'Az emberi értékelési módszerek tulajdonságainak lebontása: osztályozási rendszer az összehasonlíthatóság, a metaértékelés és a reprodukciós vizsgálat támogatására', 'ka': 'ადამიანის განსაზღვრების განსაზღვრების განსაზღვრებების განსაზღვრება: კლასიფიკაციის სისტემა შესაძლებლობა, მეტა- განსაზღვრება და განსაზღვრებელობის ტესტის დამხმარება', 'it': 'Disentangling the Properties of Human Evaluation Methods: A Classification System to Support Comparability, Meta-Evaluation and Reproducibilità Testing', 'lt': 'Žmogaus vertinimo metodų savybių iškraipymas: klasifikavimo sistema, skirta palyginamumui, metavertinimui ir reprodukcijos bandymui remti', 'mk': 'Разбивање на сопственостите на методите на човечка оценка: Класификациски систем за поддршка на тестот за споредливост, мета-оценка и репродуктибилност', 'kk': 'Адам бағалау әдістерінің қасиеттерін шектеу: Сәйкестігін қолдау үшін классификация жүйесі', 'ms': 'Menghapuskan Ciri-ciri Kaedah Evaluasi Manusia: Sistem Klasifikasi untuk menyokong Perbandingan, Meta-Evaluasi dan Ujian Kemudahan Pendarahan', 'ml': 'മനുഷ്യന്\u200d Evaluation രീതികളുടെ ഗുണഗണങ്ങള്\u200d വെറുതെയിക്കുന്നു: പിന്തുണയ്ക്കാന്\u200d ഒരു ക്ലാസിഷന്\u200d സിസ്റ്റം പിന്തുണയ്ക്കുന്നത്, മെറ', 'mt': 'Id-diżanċjalizzazzjoni tal-Proprjetajiet tal-Metodi ta’ Evalwazzjoni mill-Bniedem: Sistema ta’ Klassifikazzjoni li tappoġġja l-Ittestjar tal-Komparabbiltà, il-Meta-Evalwazzjoni u r-Riproduċibbiltà', 'pl': 'Rozłączenie właściwości metod oceny człowieka: System klasyfikacji wspierający porównywalność, metaocenę i testy reprodukcyjności', 'mn': 'Хүн төрөлхтний үнэлэх арга баримтуудын шинж чанарыг удирдлага: Comparability, Meta-Evaluation, reproduction testing', 'no': 'Avsluttar eigenskapane for menneskelige evalueringsmetodar: Eit klassifikasjonssystem for å støtta kompatibelitet, metaevaluering og reproduktivtesting', 'ro': 'Demonstrarea proprietăţilor metodelor de evaluare umană: un sistem de clasificare pentru a sprijini comparabilitatea, metaevaluarea şi testarea reproductibilităţii', 'sr': 'Raspoređivanje vlasništva metoda procjene ljudskih ljudi: sistem klasifikacije za podršku usporednosti, metaprocjene i testovanja reproduktivnosti', 'si': 'මනුෂ්\u200dය විශේෂණ විධානයේ විශේෂතාවක් විශේෂ විධානය: ක්ලාසිෆික් පද්ධතියක් සම්බන්ධතාවක්, මෙටා- විශේ', 'sv': 'Avlägsnande av egenskaperna hos humana utvärderingsmetoder: Ett klassificeringssystem för att stödja jämförbarhet, metautvärdering och reproducerbarhetstest', 'so': 'Qeybinta hantida kaartaynta biniaadamka: Xafiiska kaalmada u dhigista, imtixaanka meta-assessmeynta iyo beddelinta', 'ta': 'மனித மதிப்பீட்டு முறைமைகளின் பண்புகளை மாற்றுகிறது: ஒப்புக்கொள்ள ஒரு வகுப்பாட்டு அமைப்பு, மெடா- மதிப்பீட்டு மற்றும் மாற்றுதல', 'ur': 'انسان کی Evaluation Methods کے خصوصوں کو بٹانٹل کر رہا ہے: مٹا-Evaluation اور Reproducibility Testing کی مدد کرنے کے لئے ایک کلاس سیستم', 'uz': 'Name', 'vi': 'Thay đổi tính chất của các phương pháp đánh giá con người: một hệ thống phân hạng để hỗ trợ khả năng so sánh, siêu đánh giá và kiểm tra lại khả năng', 'bg': 'Разкъсване на свойствата на методите за оценка на човека: класификационна система за подпомагане на сравнимостта, метаоценката и възпроизводимостта', 'hr': 'Raspoređivanje vlasništva metoda procjene ljudskih osoba: klasifikacijski sustav za podršku usporednosti, metaprocjene i ispitivanja reproduktivnosti', 'da': 'Afvikling af egenskaberne ved menneskelige evalueringsmetoder: Et klassificeringssystem til støtte for sammenlignelighed, metaevaluering og reproducerbarhedstest', 'nl': 'Ontmanteling van de eigenschappen van menselijke evaluatiemethoden: Een classificatiesysteem ter ondersteuning van vergelijkbaarheid, meta-evaluatie en reproduceerbaarheidstesten', 'de': 'Entflechtung der Eigenschaften menschlicher Evaluationsmethoden: Ein Klassifikationssystem zur Unterstützung von Vergleichbarkeit, Meta-Evaluation und Reproduzierbarkeitstests', 'id': 'Menghapus Properti Metode Evaluasi Manusia: Sistem Klasifikasi untuk mendukung Pengumparaban, Meta-Evaluasi dan Pengujian Kemudahan Reproduksi', 'ko': '인류 평가 방법의 속성을 풀기: 비교가능성, 원 평가와 재현성 테스트를 지원하는 분류 시스템', 'fa': 'طراحی ویژه\u200cهای روش\u200cهای ارزیابی انسان: یک سیستم کلاس\u200cسازی برای حمایت پیمانی، ارزیابی Meta-Evaluation و تأثیر بازسازی', 'sw': 'Kuzungumzia Tamko za Uthibitisho wa Binadamu: Mfumo wa Kusaidia Ushirikiano, Uchunguzi na Uchunguzi', 'tr': 'İnsan Ýardamçylyk Metinleriniň häsiýetlerini çykaryp bilmek: Tösümlilik Desteklemek üçin Klassifikasiýa Sistemi, Meta-Taýýarlama we Ýardamçylyk Testleri', 'af': "Verwyder die eienskappe van menslike evalueringsmetodes: ' n Klassifikasie Stelsel om te ondersteun Vergelykbaarheid, Meta- Evalueer en Reprodusibiliteit Testing", 'sq': 'Shkatërrimi i pronave të metodave të vlerësimit njerëzor: Një sistem klasifikimi për të mbështetur testimin e krahasueshmërisë, meta-vlerësimit dhe riprodhueshmërisë', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'az': 'ńįnsan deńüerlendirm…ô metodlarńĪnńĪn x√ľsusiyy…ôtl…ôrini √ß…ôkildirm…ôk: Comparability, Meta-Evaluation v…ô Reproducibility Testl…ôrini d…ôst…ôkl…ôm…ôk √ľ√ß√ľn Klasifikasyon Sistemi', 'hy': 'Disentangling the Properties of Human Evaluation Methods: A Classification System to Support Comparability, Meta-Evaluation and Reproducibility Testing', 'bn': 'মানুষের মূল্যায়নের বৈশিষ্ট্য নিষ্ক্রিয় করা হচ্ছে: সমর্থন করার জন্য একটি ক্লাসিকেশন সিস্টেম, মেটা-Evalualization এবং পুনরায় পরীক্ষা', 'bs': 'Raspoređivanje vlasništva metoda procjene ljudskih ljudi: Klasifikacijski sistem za podršku usporednosti, metaprocjene i ispitivanja reproduktivnosti', 'ca': 'Disentangling the Properties of Human Evaluation Methods: A Classification System to Support Comparability, Meta-Evaluation and Reproducibility Testing', 'cs': 'Rozdělení vlastností lidských hodnotících metod: Klasifikační systém na podporu srovnatelnosti, metahodnocení a testování reprodukovatelnosti', 'et': 'Inimeste hindamismeetodite omaduste hajutamine: klassifitseerimissĂŒsteem vĂ”rreldavuse, metahindamise ja reprodutseeritavuse testimise toetamiseks', 'fi': 'Ihmisten arviointimenetelmien ominaisuuksien erottaminen: Vertailukelpoisuuden, metaarvioinnin ja toistettavuuden testausta tukeva luokitusjärjestelmä', 'jv': 'Ngubah nggawe Ngerti Kabungan Perintah sing Mbalat Iwatahan Mhasar: A CLASIKATING System kanggo Mbalat Kompatibil, meta-measurement lan Test Jabungan', 'ha': '@ action', 'sk': 'Razkrivanje lastnosti metod ocenjevanja ljudi: sistem klasifikacije za podporo primerljivosti, metaevalvacije in reproduktibilnosti testiranja', 'he': 'מחלקת את תכונות שיטות הערכה האנושית: מערכת מערכת שימוש לתמוך בבדיקות שיוודות, מטה-הערכה ובדיקות שיתופיות', 'bo': 'འདིས་མིའི་རྒྱུ་དངོས་ལྡན་བཟོ་བྱེད་ཀྱི་རྒྱུ་དངོས། མཉམ་འབྱུང་རུང་བའི་དབྱེ་བ་ཞིག'}
{'en': 'Current standards for designing and reporting human evaluations in NLP mean it is generally unclear which evaluations are comparable and can be expected to yield similar results when applied to the same system outputs. This has serious implications for reproducibility testing and meta-evaluation, in particular given that human evaluation is considered the gold standard against which the trustworthiness of automatic metrics is gauged. % and merging others, as well as deciding which evaluations should be able to reproduce each other’s results. Using examples from NLG, we propose a classification system for evaluations based on disentangling (i) what is being evaluated (which aspect of quality), and (ii) how it is evaluated in specific (a) evaluation modes and (b) experimental designs. We show that this approach provides a basis for determining comparability, hence for comparison of evaluations across papers, meta-evaluation experiments, reproducibility testing.', 'pt': 'Os padrões atuais para projetar e relatar avaliações humanas em PNL significam que geralmente não está claro quais avaliações são comparáveis e pode-se esperar que produzam resultados semelhantes quando aplicadas às mesmas saídas do sistema. Isso tem sérias implicações para testes de reprodutibilidade e meta-avaliação, em particular porque a avaliação humana é considerada o padrão-ouro contra o qual a confiabilidade das métricas automáticas é avaliada. %e fundir outras, bem como decidir quais avaliações devem ser capazes de reproduzir os resultados umas das outras. Usando exemplos do NLG, propomos um sistema de classificação para avaliações baseado em separar (i) o que está sendo avaliado (qual aspecto da qualidade) e (ii) como é avaliado em (a) modos de avaliação específicos e (b) projetos experimentais . Mostramos que essa abordagem fornece uma base para determinar a comparabilidade, portanto, para comparação de avaliações entre artigos, experimentos de meta-avaliação, testes de reprodutibilidade.', 'ar': 'تعني المعايير الحالية لتصميم التقييمات البشرية والإبلاغ عنها في البرمجة اللغوية العصبية أنه من غير الواضح بشكل عام أي التقييمات قابلة للمقارنة ويمكن توقع أن تسفر عن نتائج مماثلة عند تطبيقها على نفس مخرجات النظام. وهذا له آثار خطيرة على اختبار القابلية للتكرار والتقييم التلوي ، لا سيما بالنظر إلى أن التقييم البشري يعتبر المعيار الذهبي الذي يتم على أساسه قياس مصداقية المقاييس التلقائية. ٪ ودمج الآخرين ، وكذلك تحديد التقييمات التي يجب أن تكون قادرة على إعادة إنتاج نتائج بعضها البعض. باستخدام أمثلة من NLG ، نقترح نظام تصنيف للتقييمات على أساس فك التشابك (1) ما يتم تقييمه (أي جانب من جوانب الجودة) ، و (2) كيف يتم تقييمه في (أ) أوضاع تقييم محددة و (ب) تصميمات تجريبية . نظهر أن هذا النهج يوفر أساسًا لتحديد القابلية للمقارنة ، وبالتالي لمقارنة التقييمات عبر الأوراق ، وتجارب التقييم التلوي ، واختبار التكاثر.', 'fr': "Les normes actuelles pour la conception et le compte rendu des évaluations humaines en PNL signifient qu'il n'est généralement pas clair quelles évaluations sont comparables et qu'on peut s'attendre à ce qu'elles produisent des résultats similaires lorsqu'elles sont appliquées aux mêmes extrants du système. Cela a de graves implications pour les tests de reproductibilité et la méta-évaluation, en particulier étant donné que l'évaluation humaine est considérée comme l'étalon-or par rapport auquel la fiabilité des métriques automatiques est évaluée. % et en fusionnant les autres, ainsi que de décider quelles évaluations devraient être en mesure de reproduire les résultats des autres. À l'aide d'exemples tirés du GNL, nous proposons un système de classification des évaluations basé sur la dissociation (i) de ce qui est évalué (quel aspect de la qualité) et (ii) de la façon dont il est évalué dans des modes d'évaluation spécifiques et (b) des plans expérimentaux spécifiques. Nous montrons que cette approche fournit une base pour déterminer la comparabilité, donc pour comparer les évaluations entre les articles, les expériences de méta-évaluation, les tests de reproductibilité.", 'es': 'Los estándares actuales para diseñar e informar evaluaciones humanas en PNL significan que generalmente no está claro qué evaluaciones son comparables y se puede esperar que arrojen resultados similares cuando se aplican a los mismos productos del sistema. Esto tiene serias implicaciones para las pruebas de reproducibilidad y la metaevaluación, en particular dado que la evaluación humana se considera el estándar de oro con el que se mide la confiabilidad de las métricas automáticas. % y fusionar otras, así como decidir qué evaluaciones deberían poder reproducir los resultados de cada una. Utilizando ejemplos de NLG, proponemos un sistema de clasificación para las evaluaciones basado en desenredar (i) lo que se está evaluando (qué aspecto de la calidad), y (ii) cómo se evalúa en (a) modos de evaluación y (b) diseños experimentales específicos. Mostramos que este enfoque proporciona una base para determinar la comparabilidad, por lo tanto, para la comparación de evaluaciones entre artículos, experimentos de metaevaluación y pruebas de reproducibilidad.', 'ja': 'NLPにおける人間の評価を設計および報告するための現在の基準は、どの評価が比較可能であり、同じシステム出力に適用された場合に同様の結果をもたらすことが期待できるかは一般的に不明であることを意味する。これは、再現性テストとメタ評価に深刻な影響を与えます。特に、人間の評価は、自動指標の信頼性を測定するためのゴールドスタンダードと見なされています。%と他のものをマージし、どの評価がお互いの結果を再現できるかを決定します。NLGの例を用いて、(i)評価対象（品質のどの側面）、(ii)特定の(a)評価モードでの評価方法、(b)実験設計に基づく評価の分類体系を提案する。このアプローチは、比較可能性を決定するための基礎を提供し、したがって、論文間の評価、メタ評価実験、再現性テストの比較のための基礎を提供することを示しています。', 'zh': '今于NLP中设意,与告人评估之意,常所未详,而于同统输出,可预期生类也。 此再现性试与元评估有大损益,特虑人伦评估,以为量自指标可信度之黄金也。 %并并他评估,及定何评估当复见彼此。 用NLG之例,立分离之统,以质(i)正(之),与(ii)之特定(a)与(b)实验设计之中。 吾明此法为定可比性资其本,故于论文之间,元评估实验,再现性测试。', 'ru': 'Нынешние стандарты проектирования и отчетности по оценкам человека в NLP означают, что, как правило, неясно, какие оценки сопоставимы и можно ожидать, что они дадут аналогичные результаты при применении к одним и тем же системным результатам. Это имеет серьезные последствия для тестирования воспроизводимости и мета-оценки, в частности, учитывая, что оценка человека считается золотым стандартом, по которому оценивается надежность автоматических метрик. %и слияние других, а также принятие решения о том, какие оценки должны быть в состоянии воспроизвести результаты друг друга. Используя примеры из NLG, мы предлагаем систему классификации для оценок, основанную на распутании (i) того, что оценивается (какой аспект качества), и (ii) того, как она оценивается в конкретных (a) режимах оценки и (b) экспериментальных проектах. Мы показываем, что этот подход обеспечивает основу для определения сопоставимости, следовательно, для сравнения оценок между работами, экспериментов по мета-оценке, тестирования воспроизводимости.', 'hi': 'एनएलपी में मानव मूल्यांकन को डिजाइन करने और रिपोर्ट करने के लिए वर्तमान मानकों का मतलब है कि यह आम तौर पर स्पष्ट नहीं है कि कौन से मूल्यांकन तुलनीय हैं और एक ही सिस्टम आउटपुट पर लागू होने पर समान परिणाम प्राप्त करने की उम्मीद की जा सकती है। यह reproducibility परीक्षण और मेटा-मूल्यांकन के लिए गंभीर निहितार्थ है, विशेष रूप से यह देखते हुए कि मानव मूल्यांकन को सोने का मानक माना जाता है जिसके खिलाफ स्वचालित मैट्रिक्स की विश्वसनीयता का अनुमान लगाया जाता है। %और दूसरों को विलय करना, साथ ही यह तय करना कि कौन से मूल्यांकन एक-दूसरे के परिणामों को पुन: उत्पन्न करने में सक्षम होना चाहिए। एनएलजी के उदाहरणों का उपयोग करते हुए, हम मूल्यांकन के लिए एक वर्गीकरण प्रणाली का प्रस्ताव करते हैं जो अलग-अलग (i) मूल्यांकन किया जा रहा है (i) क्या मूल्यांकन किया जा रहा है (गुणवत्ता का कौन सा पहलू), और (ii) विशिष्ट (ए) मूल्यांकन मोड और (बी) प्रयोगात्मक डिजाइनों में इसका मूल्यांकन कैसे किया जाता है। हम दिखाते हैं कि यह दृष्टिकोण तुलनात्मकता को निर्धारित करने के लिए एक आधार प्रदान करता है, इसलिए पेपर, मेटा-मूल्यांकन प्रयोगों, पुनरुत्पादन परीक्षण में मूल्यांकन की तुलना के लिए।', 'ga': 'Ciallaíonn caighdeáin reatha maidir le meastóireachtaí daonna a dhearadh agus a thuairisciú in NLP nach bhfuil sé soiléir go ginearálta cé na meastóireachtaí is inchomparáide agus is féidir a bheith ag súil go mbainfidh siad torthaí comhchosúla nuair a chuirtear i bhfeidhm iad ar na haschuir chórais chéanna. Tá impleachtaí tromchúiseacha aige sin maidir le tástáil in-atáirgtheachta agus meite-mheastóireacht, go háirithe ós rud é go meastar gurb í meastóireacht dhaonna an caighdeán óir a ndéantar iontaofacht méadrachta uathoibríoch a thomhas ina choinne. agus cinn eile a chumasc, chomh maith le cinneadh a dhéanamh ar na meastóireachtaí ba cheart a bheith in ann torthaí a chéile a atáirgeadh. Agus samplaí ó NLG á n-úsáid againn, molaimid córas aicmithe do mheastóireachtaí bunaithe ar dhícheangal (i) cad atá á mheas (cén gné den cháilíocht), agus (ii) conas a dhéantar é a mheas i sain- (a) modhanna meastóireachta agus (b) dearaí turgnamhacha. . Léirímid go soláthraíonn an cur chuige seo bonn chun inchomparáideacht a chinneadh, mar sin chun comparáid a dhéanamh idir meastóireachtaí trasna páipéir, turgnaimh mheitimheastóireachta, tástáil in-atáirgtheachta.', 'ka': 'მიმდინარე სტანდარტები, რომელიც განსაზღვრება და რეპორტირება ადამიანის განსაზღვრება NLP-ში, იგივე უცნობიერია, რომელიც განსაზღვრება შესაძლებელია და შეიძლება იგივე განსაზღვრება ეს აქვს ძალიან მნიშვნელოვანი განვიცემების ტესტის და მეტა-განსაზღვრებისთვის, განსაკუთრებით, რომ ადამიანის განსაზღვრების განსაზღვრება იქნება უფრო მნიშვნელოვანი, რომელიც ავტომატური მე და სხვების შეყვარება, რომელიც განსაზღვრება უნდა შეიძლება ერთმანეთის შესაძლებლობა გავამრავლოთ. NLG-ის მაგალითების გამოყენება, ჩვენ კლასიფიკაციის სისტემა გავაკეთებთ, რომელიც გავაკეთება (რომელიც განსაზღვრებას) განსაზღვრება (i) განსაზღვრება (რომელიც განსაზღვრებას) და (ii) როგორ გავაკეთება განსაზღვრებული a) განსაზ ჩვენ ჩვენ აჩვენებთ, რომ ეს პროგრამის გასაკეთებელობის განსაზღვრებისთვის ბაზა, რადგან განსაზღვრებისთვის განსაზღვრებისთვის განსაზღვრებისთვის განსაზღვრებისთვის, ამიტომ განსა', 'el': 'Τα ισχύοντα πρότυπα για τον σχεδιασμό και την υποβολή εκθέσεων ανθρώπινων αξιολογήσεων στο NLP σημαίνουν ότι γενικά δεν είναι σαφές ποιες αξιολογήσεις είναι συγκρίσιμες και μπορεί να αναμένεται να αποφέρουν παρόμοια αποτελέσματα όταν εφαρμόζονται στα ίδια αποτελέσματα συστήματος. Αυτό έχει σοβαρές επιπτώσεις στις δοκιμές αναπαραγωγής και μετα-αξιολόγησης, ιδίως δεδομένου ότι η ανθρώπινη αξιολόγηση θεωρείται το χρυσό πρότυπο βάσει του οποίου μετράται η αξιοπιστία των αυτόματων μετρήσεων.% και συγχώνευση άλλων, καθώς και η απόφαση ποιες αξιολογήσεις θα πρέπει να είναι σε θέση να αναπαράγουν τα αποτελέσματα του άλλου. Χρησιμοποιώντας παραδείγματα από το ΝΓΚ, προτείνουμε ένα σύστημα ταξινόμησης για αξιολογήσεις βασισμένο σε διαχωρισμό (i) τι αξιολογείται (ποια πτυχή της ποιότητας), και (ii) πώς αξιολογείται σε συγκεκριμένους (α) τρόπους αξιολόγησης και (β) πειραματικούς σχεδιασμού. Αποδεικνύουμε ότι αυτή η προσέγγιση παρέχει μια βάση για τον προσδιορισμό της συγκρισιμότητας, επομένως για τη σύγκριση αξιολογήσεων σε διάφορα έγγραφα, πειράματα μετα-αξιολόγησης, δοκιμές αναπαραγωγής.', 'hu': 'Az emberi értékelések tervezésére és bejelentésére vonatkozó jelenlegi normák az NLP-ben azt jelentik, hogy általában nem világos, hogy mely értékelések összehasonlíthatók, és várhatóan hasonló eredményeket fognak eredményezni, ha ugyanazon rendszer kimeneteire alkalmazzák. Ez komoly következményekkel jár a reprodukálhatósági tesztelésre és a metaértékelésre, különösen tekintettel arra, hogy az emberi értékelést az automatikus mérőszámok megbízhatóságának értékelésére. és mások egyesítése, valamint döntés arról, hogy mely értékelések képesek legyenek reprodukálni egymás eredményeit. Az NLG példáit felhasználva az értékelések osztályozási rendszerét javasoljuk (i) az értékelés alatt álló (a) értékelési módok és (b) kísérleti tervek alapján. Megmutatjuk, hogy ez a megközelítés alapjául szolgál az összehasonlíthatóság meghatározásához, így az értékelések összehasonlításához dolgozatok, metaértékelési kísérletek, reprodukálhatósági tesztek között.', 'it': "Gli attuali standard per la progettazione e la comunicazione delle valutazioni umane nel PNL significano che non è generalmente chiaro quali valutazioni siano comparabili e ci si può aspettare che producano risultati simili se applicate agli stessi output del sistema. Ciò ha gravi implicazioni per il test di riproducibilità e la meta-valutazione, in particolare dato che la valutazione umana è considerata il gold standard rispetto al quale si valuta l'affidabilità delle metriche automatiche.% e fondere gli altri, nonché decidere quali valutazioni dovrebbero essere in grado di riprodurre i risultati reciproci. Utilizzando esempi di NLG, proponiamo un sistema di classificazione per le valutazioni basato su (i) cosa viene valutato (quale aspetto della qualità), e (ii) come viene valutato in (a) modalità di valutazione specifiche e (b) progetti sperimentali. Dimostriamo che questo approccio fornisce una base per determinare la comparabilità, quindi per il confronto delle valutazioni tra documenti, esperimenti di meta-valutazione, test di riproducibilità.", 'lt': 'Dabartiniai žmonių vertinimų rengimo ir ataskaitų teikimo NLP standartai reiškia, kad apskritai neaišku, kurie vertinimai yra palyginami, ir galima tikėtis, kad taikant tuos pačius sistemos rezultatus bus gauti panašūs rezultatai. Tai daro rimtą poveikį reprodukcijos bandymams ir metavertinimui, visų pirma atsižvelgiant į tai, kad žmogaus vertinimas laikomas aukso standartu, pagal kurį vertinamas automatinių metrijų patikimumas. % ir sujungti kitus, taip pat nuspręsti, kurie vertinimai turėtų sugebėti atkurti vienas kito rezultatus. Naudodamiesi NLG pavyzdži a is, siūlome vertinimų klasifikavimo sistemą, grindžiamą i) įvertinimu (kokiu kokybės aspektu) ir ii) vertinimu pagal konkrečius a) vertinimo b ūdus ir b) eksperimentiniu dizainu. Mes rodome, kad šis metodas yra pagrindas palyginamumui nustatyti, taigi vertinimų palyginimui tarp dokumentų, metavertinimo eksperimentų, reprodukcijos bandymų.', 'kk': 'Қолданыстағы стандарттар NLP адамдарды бағалау және хабарлау үшін қандай бағалау салыстырылуы мүмкін емес және бір жүйелік шығысына қолданғанда ұқсас нәтижелерді беруге болады. Бұл қайталанушылығын тексеру және мета оқу үшін маңызды нәтижелері бар, осымен қатар, адамның оқу үшін алтын стандартты, автоматты метрикалық сенімділіктерінің көмегімен қатынау стандартты деп ойла Басқаларды біріктіру және бір-бірінің нәтижесін қай бағалау мүмкіндігін шешу үшін. NLG мысалдарын қолдану үшін, бұл (сапалық қайсы аспекті), мәселелерді (a) бағалау режімдерінде және b) эксперименталдық дизайндарында қалай бағалау үшін классификациялау жүйесін қолданамыз. Бұл тәсілді салыстырмалылығын анықтау үшін негізін көрсетедік. Сондықтан қағаздарды салыстыру үшін, мета оқу тәжірибелері, репродукциялық сынақтарын салыстыру үшін.', 'mk': 'Current standards for designing and reporting human evaluations in NLP mean it is generally unclear which evaluations are comparable and can be expected to yield similar results when applied to the same system outputs.  Ова има сериозни импликации за тестирањето на репродуктибилитетот и мета-евалуацијата, особено со оглед на тоа што човечката евалуација се смета за златен стандард со кој се проценува доверливоста на автоматската метрика. % и спојувањето на другите, како и одлучувањето кои оценки треба да можат да ги репродуктираат резултатите на еден на друг. Користејќи примери од НЛГ, предложуваме систем на класификација за евалуации базиран на разрешување (i) она што се евалуира (кој аспект на квалитетот), и (ii) како се евалуира во специфични (a) режими на евалуација и (b) експериментални дизајни. Ние покажуваме дека овој пристап обезбедува основа за одредување на споредливоста, оттука за споредба на евалуациите меѓу документите, мета-евалуациски експерименти, тестирање на репродуктибилноста.', 'ms': 'Standar semasa untuk merancang dan melaporkan penilaian manusia dalam NLP bermakna ia secara umum tidak jelas mana penilaian yang boleh dibandingkan dan boleh dijangka untuk memberikan keputusan yang sama apabila dilaksanakan kepada output sistem yang sama. Ini mempunyai implikasi serius untuk ujian reproduksi dan meta-penilaian, terutama kerana penilaian manusia dianggap piawai emas yang mana kepercayaan metrik automatik diukur. % dan menyatukan yang lain, serta memutuskan penilaian mana yang patut mampu mengembalikan hasil masing-masing. Dengan menggunakan contoh dari NLG, kami cadangkan sistem klasifikasi untuk penilaian berdasarkan pengeluaran (i) apa yang sedang diuji (aspek kualiti mana), dan (ii) bagaimana i a diuji dalam mod penilaian khusus (a) dan (b) rancangan percubaan. Kami menunjukkan bahawa pendekatan ini menyediakan dasar untuk menentukan perbandingan, oleh itu untuk perbandingan penilaian di seluruh kertas, eksperimen meta-penilaian, ujian perbandingan.', 'ml': "NLP-ലുള്ള മനുഷ്യരുടെ വിലാസങ്ങള്\u200d ഡിസൈന്\u200d ചെയ്യുകയും റിപ്പോര്\u200dട്ട് ചെയ്യുകയും ചെയ്യുന്നതിന്റെ ഇപ്പോഴത്തെ സ്ഥിതിയിലുള്ള സംവിധാനങ്ങള്\u200d പ പ്രവർത്തിക്കുന്നതിനും മേറ്റ-വിലയ്ക്കുമുള്ള പരീക്ഷണത്തിനും ഗുരുതരമായ പ്രശ്നങ്ങളുണ്ട്, പ്രത്യേകിച്ച് മനുഷ്യരുടെ വിലാസം സ്വര്\u200dണ്ണസ്ഥാന and merging others, as well as deciding which evaluations should be able to reproduce each other's results.  എംഎല്\u200dജിയില്\u200d നിന്നുള്ള ഉദാഹരണങ്ങള്\u200d ഉപയോഗിക്കുന്ന ഉപദേശങ്ങള്\u200d ഉപയോഗിക്കുന്നത് നമ്മള്\u200d വികസിപ്പിക്കുന്നത് എന്താണെന്ന് നിരീക്ഷിക്കുന്നത് (i) വിലയിക്കുന്നതിന നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നുണ്ടെങ്കില്\u200d ഈ പ്രവര്\u200dത്തനത്തിന് തുല്യമായ തീരുമാനിക്കാനുള്ള അടിസ്ഥാനമാണ്, അതുകൊണ്ട് പേപ്പറുകള", 'mt': 'L-istandards attwali għat-tfassil u r-rappurtar ta’ evalwazzjonijiet umani fil-NLP ifissru li ġeneralment mhuwiex ċar liema evalwazzjonijiet huma komparabbli u jistgħu jkunu mistennija li jagħtu riżultati simili meta applikati għall-istess riżultati tas-sistema. Dan għandu implikazzjonijiet serji għall-ittestjar tar-riproduċibbiltà u l-meta-evalwazzjoni, b’mod partikolari minħabba li l-evalwazzjoni tal-bniedem titqies bħala l-istandard tad-deheb li miegħu tiġi mkejla l-affidabbiltà tal-metriċi awtomatiċi. % u jingħaqdu oħrajn, kif ukoll jiddeċiedu liema evalwazzjonijiet għandhom ikunu jistgħu jirriproduċu r-riżultati ta’ xulxin. Bl-użu ta’ eżempji mill-NLG, qed nipproponu sistema ta’ klassifikazzjoni għall-evalwazzjonijiet ibbażati fuq id-diżantellar (i) dak li qed jiġi evalwat (liema aspett tal-kwalità), u (ii) kif jiġi evalwat f’modi speċifiċi (a) ta’ evalwazzjoni u (b) disinji sperimentali. Aħna nuru li dan l-approċċ jipprovdi bażi għad-determinazzjoni tal-komparabbiltà, għalhekk għat-tqabbil tal-evalwazzjonijiet fost id-dokumenti, esperimenti ta’ meta-evalwazzjoni, ittestjar tar-riproduċibbiltà.', 'mn': 'НЛП-д хүн төрөлхтний үнэлгээг зохион байгуулах, мэдээллийн орчин үеийн стандарт нь ижил системийн үр дүнд хэрэглэх үед ямар үнэлгээ харьцуулж болох вэ гэдгийг ойлгохгүй юм. Энэ нь үржих боломжтой тестийг шалгах, мета-тооцоолох маш чухал нөлөөтэй, ялангуяа хүн төрөлхтний үнэлгээ автоматикийн метрикийн итгэл үнэ цэнэтэй алт стандарт гэж үздэг. бусад хүмүүсийг нэгтгэх боломжтой. Харин бусад хүмүүсийн үр дүнг хэрхэн үржүүлэх боломжтой вэ? NLG-ийн жишээг ашиглан, бид (i) хэмжээний сайн талаар дүгнэлттэй дүгнэлттэй дүгнэлттэй системийг санал болгож байна. Бид энэ аргыг харьцуулах ёстой гэдгийг харуулж байна. Тиймээс цаасан дээр шалгалтыг харьцуулахад, мета-шалгалтын туршилт, үржигдэх тестийг тодорхойлдог.', 'no': 'Gjeldande standarder for utforming og rapportering av menneskelige evalueringar i NLP gjennomsnitt er det vanlegvis ukjent kva evalueringa er sammenlignbar og kan forventast at det vil gje like resultat når det er brukt på same systemutdata. Dette har alvorleg implikasjonar for reproduktivitetsfesting og metaevaluering, særskilt gjeven at menneskelige evalueringa blir kalla som gullstartet som vert tiltrudd for automatiske metrikar skal gjerast. % og samling av andre, og bestemmering av kva evalueringa skal kunna gjenoppretta kvarandre resultat. Bruk eksemplar frå NLG, foreslår vi ein klassifikasjonssystem for evalueringar basert på disentangling i) kva som blir evaluert (kva aspekt av kvalitet), og ii) korleis det blir evaluert i spesifikke a) evalueringsmodus og b) eksperimentalne designar. Vi viser at denne tilnærminga tilbyr ein grunn for å bestemme sammenlignbare, derfor for for sammenligning av evalueringar over papir, metaevalueringseksperimentar, reproduktivitettestar.', 'pl': 'Obecne normy dotyczące projektowania i raportowania ocen ludzi w NLP oznaczają, że generalnie nie jest jasne, które oceny są porównywalne i można oczekiwać, że przy zastosowaniu tych samych wyników systemu przyniesie podobne wyniki. Ma to poważne konsekwencje dla testów powtarzalności i metaoceny, w szczególności biorąc pod uwagę fakt, że ocena przez ludzi jest uważana za złoty standard, na podstawie którego ocenia się wiarygodność automatycznych wskaźników.% i łączenie innych, jak również decydowanie, które oceny powinny być w stanie odtworzyć wzajemnie wyniki. Na przykładach NLG proponujemy system klasyfikacji ocen oparty na rozłączeniu (i) tego, co jest oceniane (jaki aspekt jakości), oraz (ii) sposobu oceny w konkretnych (a) trybach oceny oraz (b) projektach eksperymentalnych. Pokazujemy, że podejście to stanowi podstawę do określenia porównywalności, a zatem do porównywalności ocen między artykułami, eksperymentów metaoceny, testów odtwarzalności.', 'ro': 'Standardele actuale pentru proiectarea și raportarea evaluărilor umane în PNL înseamnă că, în general, nu este clar care evaluări sunt comparabile și se poate aștepta să dea rezultate similare atunci când sunt aplicate acelorași rezultate ale sistemului. Acest lucru are implicații serioase pentru testarea reproductibilității și meta-evaluarea, în special având în vedere că evaluarea umană este considerată standardul de aur în raport cu care se evaluează fiabilitatea măsurătorilor automate.% și fuzionarea altora, precum și stabilirea evaluărilor care ar trebui să fie capabile să reproducă reciproc rezultatele. Folosind exemple din NLG, propunem un sistem de clasificare pentru evaluări bazat pe dezlegarea (i) a ceea ce este evaluat (ce aspect al calității) și (ii) modul în care este evaluat în (a) moduri specifice de evaluare și (b) proiecte experimentale. Aratăm că această abordare oferă o bază pentru determinarea comparabilității, prin urmare pentru compararea evaluărilor între lucrări, experimente de meta-evaluare, testarea reproductibilității.', 'sr': 'Trenutni standardi za dizajniranje i izvešavanje ljudskih procjena u NLP-u uobičajeno nije jasno koje su procjene usporedno i može se očekivati da će dobiti slične rezultate kada se primjenjuje na iste rezultate sistema. To ima ozbiljne implikacije za testiranje reproduktivnosti i metaprocjenu, posebno s obzirom na to da se ljudska procjena smatra zlatnim standardom, protiv kojeg se poverenost automatske metrike procjenjuje. % i skupljanje drugih, kao i odlučivanje koje procjene bi trebale biti sposobne da reproduktuju rezultate jedni druge. Koristeći primjere NLG-a, predlažemo klasifikacijski sistem za procjene na osnovu disentancije i procjene (koji aspekt kvalitete) i ii) kako se procjenjuje u specifičnim režimima a) procjene i b) eksperimentalnim dizajnima. Pokazujemo da ovaj pristup pruža osnovu za određivanje usporednosti, stoga za usporedbu procjena preko papira, eksperimenata metaprocjene, testiranje reproduktivnosti.', 'si': 'NLP වල මිනිස්සුන් විශ්ලේෂණය සහ වාර්තා කරන්න පුළුවන් ස්ථානයක් තියෙන්නේ ඒක සාමාන්\u200dය විශ්ලේෂණය සමාන්\u200dය විශ්ලේෂණය සමහ මේකට ප්\u200dරතිපරීක්ෂණය සහ මෙටා-පරීක්ෂණය සඳහා විශේෂ පරීක්ෂණයක් තියෙනවා, විශේෂයෙන්ම මිනිස්සු පරීක්ෂණය සඳහා සුන්ධ ප්\u200dර අනිත් අනිත් අනිත් එක්ක එකතු කරනවා, ඒ වගේම විශ්වාස කරන්න පුළුවන් මොන විශ්වාස කරන්න පුළුවන් කියල NLG වලින් උදාහරණයක් භාවිත කරනවා, අපි ක්\u200dරියාත්මක විශේෂණ පද්ධතියක් ප්\u200dරයෝජනය කරනවා (i) ක්\u200dරියාත්මක විශේෂණය සඳහා විශේෂණය සඳහා විශේෂණය සඳහා  අපි පෙන්වන්නේ මේ විදියට ප්\u200dරමාණයක් විශ්වාස කරන්න පුළුවන් විදියට, ඉතින් විදියට පරීක්ෂණ පරීක්ෂණය සමඟ පරීක්ෂණය', 'so': "Siradaha la soo jeedo ee ku qorayo iyo wargelinta qiimeynta biniaadamka ee NLP waxaa loola jeedaa wax aan garanayn, taasoo qiimeynaya ay u eg yihiin, waxaana suurtagal in la soo bixiyo midhaha la mid ah marka lagu codsaday isla nidaamka soo baxa. Tani waxay saamayn ku leedahay tijaabinta qoyska iyo qiimeynta dhalashada, khusuusan qiimeynta biniaadamka waxaa looga tirinayaa standardka dahabka oo ay aaminnimadu ku jirto baaritaanka bilowga ah. oo kuwa kale ku dardaaranaya, sidoo kale go'aanka qiimeynta ay awoodi karto in midba midka kale soo celiyo midhihiisa. Sida aan u isticmaalno tusaale ahaan NLG, waxaan soo bandhigaynaa nidaam fasax oo lagu qiimeynayo cudurada (i) waxa lagu qiimeynayaa (qaybta qiimeeyada), iyo (ii) sida loo qiimeynayo qaababka gaarka ah (a) qiimeynta iyo (b) qaababka baaritaanka. Waxaynu muujinaynaa in qaababkan ay ka dhigaan qiimeynta isku mid ah, sidaas darteed u sameynta qiimeynta warqadaha oo dhan, baaritaanka qiimeynta meta-qiimeynta, imtixaanka qoyska.", 'sv': 'Nuvarande standarder för utformning och rapportering av mänskliga utvärderingar i NLP innebär att det i allmänhet är oklart vilka utvärderingar som är jämförbara och kan förväntas ge liknande resultat när de tillämpas på samma systemresultat. Detta har allvarliga konsekvenser för reproducerbarhetstest och metautvärdering, särskilt med tanke på att mänsklig utvärdering anses vara den guldstandard mot vilken tillförlitligheten hos automatiska mätvärden mäts.% och sammanfoga andra, samt besluta vilka utvärderingar som ska kunna reproducera varandras resultat. Med hjälp av exempel från NLG föreslår vi ett klassificeringssystem för utvärderingar baserat på (i) vad som utvärderas (vilken aspekt av kvalitet), och (ii) hur det utvärderas i specifika (a) utvärderingssätt och (b) experimentella konstruktioner. Vi visar att detta tillvägagångssätt ger en grund för att fastställa jämförbarhet, därmed för jämförelse av utvärderingar över uppsatser, metautvärderingsexperiment, reproducerbarhetstest.', 'ta': 'NLP-ல் உள்ள மனித மதிப்புகளை வடிவமைப்பு மற்றும் அறிவிப்பதற்கான தற்போதைய நிலைமைகள் என்றால் அது பொதுவாக தெரியாது எந்த மதிப்புகள் ஒப்பிடுகிறது மற் இது பெண் பரிசோதிப்பு மற்றும் meta-evaluation பெரும் பாதிப்பு குறிப்புகள் உள்ளது, குறிப்பாக, மனிதன் மதிப்பு தானியங்கி மெட்ரிக்களின் நம்பிக்கையான தங மற்றவர்களை ஒன்று சேர்த்து, மற்றும் ஒருவருக்கொருவரின் முடிவை புதுப்பிக்க முடியும். NLG-ல் இருந்து உதாரணங்களை பயன்படுத்தி, நோயாளிக்கு அடிப்படையில் பிரிப்பு அமைப்பிற்கு நாம் பரிந்துரைக்கிறோம் என்ன மதிப்பு (தரம் என்று பார்ப்பது என்பது) மற்றும் (i i) கு We show that this approach provides a basis for determining comparability, hence for comparison of evaluations across papers, meta-evaluation experiments, reproducibility testing.', 'ur': 'NLP میں انسانوں کی ارزیابی طراحی اور راپورت کرنے کے لئے موجود استاندارڈ کا مطلب یہ معلوم ہے کہ یہ معلوم نہیں ہے کہ کس ارزیابی مقایسہ ہوتی ہے اور اس کی انتظار کی جاتی ہے کہ اس طرح برابر نتیجے حاصل کریں جب ان ہی سیسٹم کے نتیجے پر لا اس کے لئے دوبارگی آزمائش اور مٹا-ارزش کے لئے اہم اثرات ہیں، مخصوصاً اس لئے کہ انسان کی ارزش سونے کی استاندارڈ سمجھی جاتی ہے جس کے مقابلہ میں اتوماتیک میٹریک کی اعتماد کرتی ہے۔ اور دوسروں کو جمع کرنا اور کس قدرت کا فیصلہ کرنا چاہتا ہے کہ ایک دوسرے کے نتیجے دوبارہ پیدا کرسکیں۔ NLG سے مثالیں استعمال کرتے ہیں، ہم ایک کلاسپیٹ سیستم کی ارزیابی کریں گے جو (کیسی کیسی منظور کی) ارزیابی کی جاتی ہے، اور (i i) کیسے اس کا ارزیابی (a) ارزیابی موڈوں اور (b) آزمائش طراحوں میں کیا جاتا ہے۔ ہم دکھاتے ہیں کہ یہ طریقہ مقایسات کا فیصلہ کرنے کے لئے ایک بنیاد ہے، یہاں تک کہ کاغذوں میں مقایسات کے مقایسات کے لئے، مٹا-ارزش کی آزمائش، دوبارگی کی آزمائش کے لئے۔', 'uz': "Name Bu ta'sirlik tizimini tekshirish va meta qiymati uchun juda katta muammolar bor. Hullas, odamning qiymatlari avtomatik metriklarning ishonini avtomatik tozalash mumkin deb hisoblanadi. va boshqalarni birga birlashtirish va bir-бирлариning natijalarini qaytadan qayta olish kerak. Name We show that this approach provides a basis for determining comparability, hence for comparison of evaluations across papers, meta-evaluation experiments, reproducibility testing.", 'vi': 'Các tiêu chuẩn hiện thời cho việc thiết kế và báo cáo đánh giá con người ở N.P. cho thấy không rõ đánh giá nào có thể so sánh và có thể cung cấp kết quả tương tự khi được áp dụng cho kết xuất chung hệ thống. Điều này có tác động nghiêm trọng tới việc kiểm tra khả năng sinh sản và đánh giá đột biến, đặc biệt là khi đánh giá con người là tiêu chuẩn vàng dựa vào đo đo đo đo đo cẩn thận đo đo đo đo đo đo đo đo đo đo đo đo đo đo đo lường. và kết hợp những người khác, cũng như quyết định những đánh giá nào có thể mô phỏng kết quả của nhau. Sử dụng các ví dụ từ NLG, chúng tôi đề xuất một hệ thống phân loại dựa trên việc tách ra (i) những gì đang được đánh giá (về khía cạnh chất lượng nào) và (II) cách đánh giá nó theo các chế độ đánh giá cụ thể (a) đánh giá các chế độ đánh giá và (b) các thiết kế thử nghiệm. Chúng tôi cho thấy phương pháp này là cơ sở để xác định sự tương xứng, do đó cho việc so sánh đánh giá trên giấy tờ, thí nghiệm meta-DNA, thử nghiệm sinh sản.', 'bg': 'Настоящите стандарти за проектиране и докладване на оценки от хора в НЛП означават, че като цяло не е ясно кои оценки са сравними и може да се очаква да доведат до сходни резултати, когато се прилагат за едни и същи продукти на системата. Това има сериозни последици за тестването за възпроизводимост и мета-оценката, по-специално като се има предвид, че оценката на човека се счита за златен стандарт, спрямо който се измерва надеждността на автоматичните показатели.% и сливане на другите, както и вземане на решение кои оценки трябва да могат да възпроизвеждат резултатите помежду си. Използвайки примери от НЛГ, ние предлагаме класификационна система за оценки въз основа на разгадаване (и) какво се оценява (кой аспект на качеството), и (ii) как се оценява в конкретни (а) режими на оценка и (б) експериментални проекти. Показваме, че този подход осигурява основа за определяне на съпоставимостта, следователно за сравнение на оценките между докладите, експерименти с мета-оценка, тестване за възпроизводимост.', 'nl': 'De huidige normen voor het ontwerpen en rapporteren van menselijke evaluaties in NLP betekenen dat het over het algemeen onduidelijk is welke evaluaties vergelijkbaar zijn en vergelijkbare resultaten kunnen opleveren wanneer toegepast op dezelfde systeemoutputs. Dit heeft ernstige gevolgen voor reproduceerbaarheidstests en meta-evaluaties, met name gezien het feit dat menselijke evaluatie wordt beschouwd als de gouden standaard waarmee de betrouwbaarheid van automatische statistieken wordt gemeten.% en het samenvoegen van anderen, evenals het bepalen van welke evaluaties elkaars resultaten moeten kunnen reproduceren. Aan de hand van voorbeelden uit NLG stellen we een classificatiesysteem voor evaluaties voor op basis van ontkoppeling (i) wat wordt geëvalueerd (welk aspect van kwaliteit), en (ii) hoe het wordt geëvalueerd in specifieke (a) evaluatiemodi en (b) experimentele ontwerpen. We tonen aan dat deze benadering een basis biedt voor het bepalen van vergelijkbaarheid, dus voor vergelijking van evaluaties in verschillende documenten, meta-evaluatieexperimenten, reproduceerbaarheidstesten.', 'hr': 'Trenutni standardi za dizajniranje i izvještavanje ljudskih procjena u NLP-u obično nije jasno što su procjene usporedno i može se očekivati da će dobiti slične rezultate kada se primjenjuje na isti ishod sustava. To ima ozbiljne implikacije za testiranje reproduktivnosti i metaprocjenu, posebno s obzirom na to da se ljudska procjena smatra zlatnim standardom, protiv kojeg se poverenost automatske metrike izmjerila. % i skupljanje drugih, kao i odlučivanje kojih procjena treba biti u stanju reproduktirati rezultate jedni druge. Koristeći primjere NLG-a, predlažemo klasifikacijski sustav za procjene na temelju razmišljanja i procjene (koji aspekt kvalitete) i ii) kako se procjenjuje u specifičnim režimima a) procjene i b) eksperimentalnim dizajnima. Pokazujemo da taj pristup pruža temelj za određivanje usporednosti, stoga za usporedbu procjena preko papira, eksperimenti metaprocjene, testiranje reproduktivnosti.', 'da': 'De nuværende standarder for udformning og rapportering af menneskelige evalueringer i NLP betyder, at det generelt er uklart, hvilke evalueringer der er sammenlignelige og kan forventes at give lignende resultater, når de anvendes på de samme systemoutput. Dette har alvorlige konsekvenser for reproducerbarhedstest og meta-evaluering, især i betragtning af, at menneskelig evaluering betragtes som den guldstandard, som automatiske målingers troværdighed måles ud fra.% og sammenlægning af andre samt beslutning om, hvilke evalueringer der skal kunne gengive hinandens resultater. Ved hjælp af eksempler fra NLG foreslår vi et klassificeringssystem for evalueringer baseret på at adskille (i) hvad der evalueres (hvilket aspekt af kvalitet), og (ii) hvordan det evalueres i specifikke (a) evalueringsmetoder og (b) eksperimentelle designs. Vi viser, at denne tilgang danner grundlag for bestemmelse af sammenlignelighed og dermed for sammenligning af evalueringer på tværs af papirer, meta-evalueringseksperimenter, reproducerbarhedstest.', 'de': 'Aktuelle Standards für die Gestaltung und Berichterstattung menschlicher Evaluationen in NLP bedeuten, dass generell unklar ist, welche Evaluationen vergleichbar sind und ähnliche Ergebnisse erwarten können, wenn sie auf die gleichen Systemergebnisse angewendet werden. Dies hat schwerwiegende Auswirkungen auf Reproduzierbarkeitstests und Metabewertungen, insbesondere da die menschliche Bewertung als Goldstandard gilt, an dem die Vertrauenswürdigkeit automatischer Metriken gemessen wird.% und andere zusammenführen, sowie entscheiden, welche Auswertungen in der Lage sein sollen, die Ergebnisse der anderen zu reproduzieren. Anhand von Beispielen aus NLG schlagen wir ein Klassifizierungssystem für Evaluationen vor, das auf der Entkoppelung (i) dessen basiert, was bewertet wird (welcher Aspekt der Qualität) und (ii) wie es in bestimmten (a) Evaluationsmodi und (b) experimentellen Entwürfen bewertet wird. Wir zeigen, dass dieser Ansatz eine Grundlage für die Bestimmung der Vergleichbarkeit bietet, also für den Vergleich von Bewertungen über Paper hinweg, Meta-Evaluationsexperimente, Reproduzierbarkeitstests.', 'id': 'Standar saat ini untuk merancang dan melaporkan evaluasi manusia di NLP berarti umumnya tidak jelas evaluasi mana yang dapat dibandingkan dan dapat diharapkan untuk memberikan hasil yang sama ketika diaplikasikan pada hasil sistem yang sama. Ini memiliki implikasi serius untuk tes reproduksibilitas dan meta-evaluasi, terutama karena evaluasi manusia dianggap standar emas yang mana kepercayaan metrik otomatis diukur. % dan menggabungkan yang lain, serta memutuskan evaluasi mana yang harus mampu mereproduksi hasil satu sama lain. Menggunakan contoh dari NLG, kami mengusulkan sistem klasifikasi untuk evaluasi berdasarkan disentangling (i) apa yang sedang dievaluasi (aspek kualitas mana), dan (ii) bagaimana i a dievaluasi dalam modalitas (a) evaluasi spesifik dan (b) desain eksperimental. Kami menunjukkan bahwa pendekatan ini menyediakan dasar untuk menentukan perbandingan, sehingga untuk perbandingan evaluasi di seluruh kertas, eksperimen meta-evaluasi, tes reproduksi.', 'sw': "Kiwango cha sasa cha kutengeneza na kutoa taarifa za uchunguzi wa binadamu katika NLP kinamaanisha kwa ujumla haujaeleweka kwamba tafiti hizo zinafanana na zinaweza kutegemea matokeo yanayofanana pale yanapotumiwa kwenye matokeo hayo ya mfumo huo. Hili lina madhara makubwa kwa kujaribu uzazi na kutathmini utafiti wa meta, hasa kwa sababu utafiti wa binadamu unachukuliwa kuwa kiwango cha dhahabu ambacho uaminifu wa mimetri ya kujitegemea unagawanywa. % and merging others, as well as deciding which evaluations should be able to reproduce each other's results.  Kwa kutumia mifano kutoka NLG, tunapendekeza mfumo wa kutathmini kwa ajili ya kutathmini magonjwa (i) kile kinachotatuliwa (suala la ubora), na (ii) jinsi gani utafiti huo unavyopitiwa katika njia maalum (a) uchunguzi na (b) ubunifu wa majaribio. Tunaonyesha kwamba mbinu hii inatoa msingi wa kuamua ulinganisha, kwa hiyo kwa kulinganisha tafiti za magazeti, majaribio ya uchunguzi wa meta, majaribio ya uwazi.", 'fa': 'استانداردهای فعلی برای طراحی و گزارش ارزیابی انسان در NLP معنی است که معمولاً معلوم نیست که کدام ارزیابی قابل مقایسه است و می تواند انتظار داشته باشد که نتایج مشابه را در زمانی که بر نتایج همان سیستم کاربرد انجام دهد. این تأثیرات جدی برای آزمایش تولید پدید آوری و ارزیابی متا دارد، مخصوصا با توجه به اینکه ارزیابی انسان استاندارد طلا را در مقابل آن به نظر می رسد که ارزیابی متریک اتوماتیک در مقابل آن اعتماد دارد. % و جمع کردن بقیه\u200cها، و تصمیم گرفتن کدام ارزیابی باید نتیجه\u200cهای یکدیگر را بازسازی کند. با استفاده از مثالهایی از NLG، ما یک سیستم کلیسی برای ارزیابی بر اساس ناپذیری (i) که ارزیابی می\u200cشود، پیشنهاد می\u200cکنیم، و (ii) چگونه ارزیابی می\u200cشود در حالت (a) ارزیابی خاص و (b) طراحی آزمایشی. ما نشان می دهیم که این روش یک بنیادی برای تعیین مقایسه قابلیت را پیشنهاد می دهد، بنابراین برای مقایسه از ارزیابی\u200cهای مختلف کاغذها، آزمایش\u200cهای ارزیابی متا، آزمایش بازگشت.', 'af': "Huidige standaarde vir ontwerp en raporteer van menslike evaluasies in NLP bedoel dit is algemeen onbekende wat evaluasies is vergelykbaar en kan wees verwag om vergelykbare resultate te gee wanneer toegewend word na dieselfde stelsel uitvoerdes. Hierdie het ernstige implikasies vir reproduktiviteit toets en meta-evaluasie, in besonderhede gegee dat die menslike evaluasie die goue standaard aangesien word waarmee die vertrouworthiness van outomatiese metrike gegee word. % en versamel ander en besluit wat evaluasies kan wees om mekaar se resultate te reproduseer. By die gebruik van voorbeelde van NLG, voorstel ons 'n klassifikasie stelsel vir evaluasies gebaseer op afwysing (i) wat is evalueer (watter aspek van kwaliteit), en (ii) hoe dit in spesifieke (a) evaluasie modus en (b) eksperimentale ontwerpe is. Ons wys dat hierdie toegang 'n basis verskaf vir die bepaal van vergelykbaarheid, daarom vir vergelyking van evaluasies oor papiere, metaevaluasie eksperimente, reproduksibiliteit toets.", 'sq': 'Standardet aktuale për projektimin dhe raportimin e vlerësimeve njerëzore në NLP do të thotë se është përgjithësisht e paqartë se cilat vlerësime janë të krahasueshme dhe mund të pritet të japin rezultate të ngjashme kur të aplikohen në të njëjtat rezultate të sistemit. Kjo ka pasoja serioze për testimin e riprodhueshmërisë dhe meta-vlerësimin, veçanërisht duke ditur se vlerësimi njerëzor konsiderohet standarti i artë kundër të cilit vlerësohet besueshmëria e metrikave automatike. % dhe bashkimin e të tjerëve si dhe vendosjen se cilat vlerësime duhet të jenë në gjendje të riprodhojnë rezultatet e njëri-tjetrit. Duke përdorur shembuj nga NLG, ne propozojmë një sistem klasifikimi për vlerësime bazuar në zhvendosjen e (i) asaj që po vlerësohet (cili aspekt i cilësisë) dhe (ii) se si vlerësohet në modalitetet specifike (a) vlerësimi dhe (b) dizajnet eksperimentale. Ne tregojmë se kjo qasje ofron një bazë për përcaktimin e krahasueshmërisë, kështu që për krahasimin e vlerësimeve nëpërmjet dokumenteve, eksperimenteve të meta-vlerësimit, testimeve të riprodhimit.', 'tr': "Häzirki standartlar NLP'da adamlaryň deňlemelerini tassyklamak we raporda etmek üçin bu deňlemeler däldir we bir sistem netijesine üýtgedilen ýaly netijesi täze etmelidir. Munyň täzeliklik testi we meta-deňlemesi üçin wajyp täsir edýär, ýöne adamlaryň deňlemesi altyn standarty diýip pikir edýär. Bu üýtgeşmeleri awtomatik metriýasynyň güýçlenýänligine garaşýar. % Başgalaryny bir topar bilen birleştirip, bir-biriniň netijelerini nähili deňlemek üçin karar bermek üçin bolar. NLG'den mysal ullanýarys, deňlemek üçin klasifikasyon sistemasyny (i) deňlemek üçin deňlemek üçin terjime edip, we (ii) häzirki (a) deňlemek modlarda we (b) deneysel taslamalarda nähili deňlenmelidir. Biz bu ýagdaýy ýagdaýy çykarmak üçin esasy tapandyrýarys. Şonuň üçin kagyzyň üstünde deňlenmelerini, meta-deňlenme deneyleri, reproducibilitet testilerini karşılaşdyrmak üçin esasy tapandyrýarys.", 'am': 'በNLP ውስጥ የሰው ውጤቶች ማሳየት እና ማሳየት የአሁኑን ድጋፍ ማሰናከል አይቻልም፡፡ ይህ የጥንቃቄነት ፈተና እና የሀብት ማስታወቂያ የሚያስፈልገው ታላቅ ጉዳይ አለበት፤ በተለይም የሰው ውጤት የራሳቸው ማተማመኛ የታመነበት የወርቅ ድረ በዳ እንዲቆጠር ነው፡፡ ሌሎችንም አብረው፥ እርስ በርሳቸውም ፍጻሜውን እንዴት ሊመልስ የሚችል መሆኑን እወቁ። ከNLG ምሳሌዎች በመጠቀም፣ በ (i) ደካማዎች ላይ የተመሠረተውን (የትክክለኛ ክፍል) እና (ii) በተለያዩ (a) ክስተት ክፍሎች እና (b) የፈተና ጥናት እንዴት እንደተረጋገጠ እና እንዴት እንደምናስተምር እና እንደምናደርጋለን፡፡ ይህም ሥርዓት ትክክል ለማረጋገጥ መሠረትን እናሳያቸዋለን፡፡ ስለዚህም በጋዜጠቶች ሁሉ ላይ ማስታወቂያ፣ የmeta-evaluation ፈተና፣ የግንኙነት ፈተና እናደርጋለን፡፡', 'hy': 'ՆԼՊ-ում մարդկային գնահատումների նախագծման և տեղեկատվության ներկայիս ստանդարտները նշանակում են, որ ընդհանուր առմամբ անհասկանալի է, թե որոնք գնահատումները համեմատուկ են և կարելի է ակնկալել, որ նույն արդյունքները կբերեն, երբ կիրառվում են նու Սա լուրջ ազդեցություններ ունի վերարտադրողականության փորձարկումների և մետագնահատման վրա, հատկապես հաշվի առնելով այն, որ մարդկային գնահատումը համարվում է ոսկու ստանդարտ, որի համեմատ գնահատվում է ավտոմատիկ մետրիկայի վստահո և միավորել ուրիշներին, ինչպես նաև որոշել, թե ինչ գնահատումներ պետք է կարողանան վերարտադրել միմյանց արդյունքները: Using examples from NLG, we propose a classification system for evaluations based on disentangling (i) what is being evaluated (which aspect of quality), and (ii) how it is evaluated in specific (a) evaluation modes and (b) experimental designs.  Մենք ցույց ենք տալիս, որ այս մոտեցումը հիմք է տալիս համեմատությունը որոշելու համար, այսինքն՝ թղթերի, մետագնահատման փորձարկումների, վերարտադրողականության փորձարկումների համեմատության համար:', 'az': 'NLP içində insanların değerlendirmələrini tasarlamaq və raportlamaq üçün hazırkı standartlar anlamına gəlir ki, nə değerlendirmələrin karşılaşdırılabilir və eyni sistem çıxışlarına istifadə edilərkən bənzər sonuçlar yetirə bilər. Bu çoxluğunluğun sınaması və meta-değerlənməsi üçün ciddi implikası var. Özellikle ki, insan değerlənməsi avtomatik metriklərin güvenilişliyi müəyyən edildiyi altın standartlarına görədir. digərlərini birləşdirib, bir-birinin sonuçlarını yenidən dəyişdirmək üçün hansı değerləşdirmək mümkün olmalı. NLG nümunələrindən istifadə edərək, i) dəyişdirilən (hansı qiymətin aspekti), və ii) müəyyən (a) değerlendirmə modularında necə değerlendiriləcəyini və b) təcrüb ə dizaynlarına dayanılacağını təklif edirik. Biz göstəririk ki, bu tərzim karşılaşılabilir təyin etmək üçün bir əsas təyin edir, buna görə də kağıtlar arasında değerlendirmələrin qarşılaşılması, meta-değerlendirmə təcrübələrinin, reproducibility testinin.', 'bs': 'Trenutni standardi za dizajniranje i izvještavanje ljudskih procjena u NLP-u uopšte nije jasno koje su procjene usporedno i može se očekivati da će dobiti slične rezultate kada se primjenjuje na isti ishod sistema. To ima ozbiljne implikacije za testiranje reproduktivnosti i metaprocjenu, posebno s obzirom na to da se ljudska procjena smatra zlatnim standardom, protiv kojeg se poverenost automatske metrike izmjerila. % i skupljanje drugih, kao i odlučivanje koje procjene bi trebale biti sposobne da reproduktuju rezultate jedni druge. Koristeći primjere NLG-a, predlažemo klasifikacijski sistem za procjene na osnovu odvraćanja i procjene (koji aspekt kvalitete) i ii) kako se procjenjuje u specifičnim režimima a) procjene i b) eksperimentalnim dizajnima. Pokazujemo da taj pristup pruža osnovu za određivanje usporednosti, stoga za usporedbu procjena preko papira, eksperimenti metaprocjene, testiranje reproduktivnosti.', 'ca': "Els estàndards actuals per dissenyar i reportar evaluacions humanes en NLP significan que generalment no és clar quines evaluacions són comparables i es pot esperar que produeixin resultats similars quan s'aplican als mateixos productes del sistema. Això té conseqüències serioses per a la prova de reproducibilitat i la meta-evaluació, en particular tenint en compte que l'evaluació humana es considera l'estàndard d'or amb el qual es mesura la fiabilitat de les mètriques automàtiques. % i fusionar els altres, i decidir quines evaluacions haurien de poder reproduir els resultats dels altres. Utilitzant exemples de la NLG, proposem un sistema de classificació per a les evaluacions basades en la desorientació i) el que s'està evaluant (quin aspecte de qualitat) i ii) com s'està evaluant en mods específics a) d'evaluació i b) dissenys experimentals. Mostrem que aquest enfocament proporciona una base per a determinar la comparabilitat, per tant per a comparar les evaluacions entre documents, experiments de meta-evaluació, tests de reproducibilitat.", 'bn': 'এনএলপিতে মানুষের মূল্য পরিকল্পনা এবং প্রতিবেদনের বর্তমান মানে এটা সাধারণত পরিষ্কার নয় যে এই মূল্যের সমান এবং একই সিস্টেম আউটপুট প্রয়োগ করার সময় একই ধরনে এটি প্রবণতার পরীক্ষা এবং মেটা মূল্যের জন্য গুরুত্বপূর্ণ প্রভাব রয়েছে, বিশেষ করে যে মানুষের মূল্য স্বর্ণের মানুষকে বিবেচনা করা হচ্ছে যে স্বয়ংক এবং অন্যদের সাথে একত্রিত করে, এবং সিদ্ধান্ত নিয়েছি যে কোন মূল্যবোধ পাওয়া যাবে একে অপরের ফলাফল পুনরুদ্ধার করতে পারে। এনএলজি থেকে উদাহরণ ব্যবহার করে আমরা একটি ক্লাসিফিকেশন সিস্টেম প্রস্তাব করছি যেটা মূল্যায়ন করা হচ্ছে (কোন মানের দিকে) এবং (ই) কিভাবে এটি বিশেষ (a) মূল্যবোধ মোড এবং (b) পরীক্ষা আমরা দেখাচ্ছি যে এই প্রযুক্তিটি তুলনা নির্ধারণের জন্য একটি ভিত্তি প্রদান করেছে, যার ফলে পাপারের মূল্য, মেটা মূল্যায়ন পরীক্ষা, প্রবণত', 'ko': 'NLP에서 인류 평가를 설계하고 보고하는 현행 기준은 어떤 평가가 비교가 가능한지 잘 모르고 같은 시스템 출력에 적용될 때 비슷한 결과를 예상할 수 있음을 의미한다.이것은 재현성 테스트와 원 평가에 심각한 영향을 미친다. 특히 인류 평가가 자동 지표의 신뢰도를 평가하는 황금 기준으로 간주되는 것을 감안하면그리고 다른 평가를 합병하고 어떤 평가가 서로의 결과를 재현할 수 있을지 결정한다.NLG의 예를 이용하여 우리는 분리(i)가 무엇을 평가하고 있는지(품질의 어느 부분), 그리고 (ii)가 특정한 (a) 평가 모델과 (b) 실험 디자인에서 어떻게 평가하는지를 바탕으로 하는 평가 분류 시스템을 제시했다.우리는 이러한 방법은 비교가능성을 확정하는 데 기초를 제공했기 때문에 논문을 뛰어넘는 평가 비교, 원 평가 실험, 재현성 테스트에 사용할 수 있다.', 'cs': 'Současné standardy pro navrhování a vykazování hodnocení lidí v NLP znamenají, že obecně není jasné, která hodnocení jsou srovnatelná a lze očekávat, že při aplikaci na stejné výstupy systému přinesou podobné výsledky. To má vážné důsledky pro testování reprodukovatelnosti a metahodnocení, zejména vzhledem k tomu, že hodnocení lidí je považováno za zlatý standard, podle něhož se měří důvěryhodnost automatických metrik.% a sloučení ostatních, stejně jako rozhodování, která hodnocení by měla být schopna vzájemně reprodukovat výsledky. Na příkladech z NLG navrhujeme klasifikační systém hodnocení založený na rozpoznání (i) toho, co se hodnotí (jaký aspekt kvality), a (ii) toho, jak je hodnoceno v konkrétních (a) hodnotících režimech a (b) experimentálních návrzích. Ukazujeme, že tento přístup poskytuje základ pro stanovení srovnatelnosti, tedy pro srovnání hodnocení napříč články, metahodnocení experimentů, testování reprodukovatelnosti.', 'et': 'Praegused standardid inimeste hindamiste kavandamiseks ja aruandluseks uue tööprogrammi raames tähendavad, et üldiselt on ebaselge, millised hindamised on võrreldavad, ning samade süsteemi väljundite puhul võib eeldada, et need annavad sarnaseid tulemusi. Sellel on tõsine mõju reprodutseeritavuse testimisele ja metahindamisele, eelkõige arvestades, et inimeste hindamist peetakse kuldstandardiks, mille alusel hinnatakse automaatsete mõõdikute usaldusväärsust.% ja teiste ühendamine, samuti otsustamine, millised hindamised peaksid suutma üksteise tulemusi reprodutseerida. NLG näidete abil pakume välja hindamise klassifitseerimissüsteemi, mis põhineb i) hindamisel (milline kvaliteedi aspekt) ja ii) kuidas seda hinnatakse konkreetsetes hindamisviisides ja b) katseprojektides. Näitame, et see lähenemisviis annab aluse võrreldavuse kindlaksmääramiseks, seega hindamiste võrdlemiseks eri dokumentide vahel, metahindamiskatseteks, reprodutseeritavuse testimiseks.', 'fi': 'Nykyiset standardit ihmisten arviointien suunnittelua ja raportointia varten uudessa ohjelmassa tarkoittavat, että on yleisesti epäselvää, mitkä arvioinnit ovat vertailukelpoisia, ja niiden voidaan odottaa tuottavan samanlaisia tuloksia, kun niitä sovelletaan samoihin järjestelmän tuotoksiin. Tällä on vakavia vaikutuksia toistettavuustestaukseen ja meta-arviointiin, erityisesti kun otetaan huomioon, että ihmisten arviointia pidetään kultaisena standardina, jonka perusteella automaattisten mittausten luotettavuutta mitataan.% ja muiden yhdistäminen sekä päättäminen siitä, millä arvioinneilla olisi voitava toistaa toistensa tulokset. NLG:n esimerkkien avulla ehdotamme arviointien luokittelujärjestelmää, joka perustuu (i) arvioitavaan (mikä laadun osa) ja (ii) siihen, miten sitä arvioidaan tietyissä arviointimuodoissa ja (b) kokeellisissa suunnitelmissa. Osoitamme, että tämä lähestymistapa tarjoaa perustan vertailtavuuden määrittämiselle, eli arviointien vertailulle eri papereissa, meta-arviointikokeiluille ja toistettavuustestauksille.', 'jv': 'Sumangkat atual kanggo nggawe sistem sing beraksi lan nggawe perintahaan anyar tentang NLP merang kapan kuwi kesempalahan kanggo baliksi sing beraksi karo iso diandelak dhéwé, ngono iso diandelak oleh dadi sing paling dadi nggo ngwalikno dadi sistem sing beraksi. Digawe sing beraksi aké perbudhakan kanggo ujian akeh panelusuran karo meta-assempen, ngomong nik awak dhéwé kuwi tindakan kuwi nggawe barang gampang kuwi mau, sing nyimpen karo perbudhakan uwong. njaluk-njaluk liyane, lan disimpen-njaluk kanggo kowé nggawe luwih nyoto iso nggawe barang nggawe barang. Ngawe gunakake kalitas NLG, kita supoyo sistem tau kelas karo deweke nggunakake (i) sing dadi nyoto cara (Aspekt of Quality), lan (i i) sing dadi nyoto akeh nggawe modo (a) dadi nyoto bakal terus (b) dadi nyoto emperar. Awak dhéwé éntuk akses iki dadi nggawe geranggap karo perusahaan, dadi kapan karo nggawe geranggap karo cara-cara, ujaran meta-cara, ujaran ujaran karo perusahaan.', 'ha': "QUnicodeControlCharacterMenu Wannan yana da jiyyai mai girma ga jarrabar dubu da evaluation meta-meta, kuma haske da aka ƙayyade evaluation ga mutum a ƙayyade kimar zĩnãriya wanda ake yi aminci da aminci na metric farat ɗaya a gauge shi.% and merging others, as well as deciding which evaluations should be able to reproduce each other's results.  Yin amfani da misãlai daga NLG, sai mu buɗa wata kalsifikari ga tunkuɗe wa a b in da ke ƙaddara (i) a kan karatun kayan yi (ko bakin ƙaddara masu nau'a), da (ii) yadda ake evaluce shi a cikin misãlai na ƙaddara (a) muhimmanci da (b) zalumhin jarrabai. Tuna nũna cewa wannan hanyarwa yana da wani bincike wa a ƙaddara daidaita, sabõda haka, misãlai ga masu ƙaddara a cikin takardar takarda, jarrabi-evaluci na meta, da jarrabi za'anar a duba.", 'sk': 'Trenutni standardi za oblikovanje in poročanje o ocenah ljudi v novem programu pomenijo, da je na splošno nejasno, katere ocene so primerljive, in se lahko pričakuje, da bodo podobne rezultate, če se uporabljajo za iste rezultate sistema. To ima resne posledice za testiranje ponovljivosti in metavrednotenje, zlasti glede na to, da se ocenjevanje ljudi šteje za zlati standard, na podlagi katerega se ocenjuje zanesljivost samodejnih meritev.% in združevanje drugih, kot tudi odločanje, katere ocene naj bi omogočile reprodukcijo rezultatov drugih. Z uporabo primerov iz NLG predlagamo sistem klasifikacije vrednotenj, ki temelji na ločevanju (i) tistega, kar se ocenjuje (kateri vidik kakovosti) in (ii) kako se ocenjuje v specifičnih (a) načinih vrednotenja in (b) eksperimentalnih načrtih. Pokazali smo, da ta pristop zagotavlja osnovo za določanje primerljivosti, torej za primerjavo vrednotenj med članki, meta-evalvacijske poskuse, testiranje ponovljivosti.', 'he': 'הסטנדרטים הנוכחים לעיצוב ולדווח על הערכות האנושיות ב-NLP אומרים שבכלל לא ברור אילו הערכות שוואות ויכולים לצפות להביא תוצאות דומות כאשר יימשכו לאותה תוצאות מערכת. יש לזה השלכות רציניות לבדיקות ניתוח ניתוח ניתוח ומטה-הערכה, במיוחד בהתחשב בערכת הערכה האנושית נחשבת בסטנדרט זהב שבו ניתן למדוד את אמון המטריקות האוטומטית. % ומיזוג אחרים, כמו גם להחליט אילו ערכות צריכות להיות מסוגלות לשחזר את התוצאות של אחד את השני. באמצעות דוגמאות מ-NLG, אנו מציעים מערכת מערכת מערכת הערכות המבוססת על פירוק (i) מה עומד להעריך (איזה היבט של איכות), ו (ii) איך הוא מוערך בצורות (a) הערכה ספציפיות ו (b) עיצובים ניסויים. We show that this approach provides a basis for determining comparability, hence for comparison of evaluations across papers, meta-evaluation experiments, reproducibility testing.', 'bo': 'NLP ནང་གི་མིག This has serious implications for reproducibility testing and meta-evaluation, in particular given that human evaluation is considered the gold standard against which the trustworthiness of automatic metrics is gauged. % མཉམ་དུ་བསྡོམས་བྱེད་བཞིན་ན། ཡིག་རྩལ་ནི་གང་ཞིག་གིས་མཐུན་རྐྱེན་བཟོ་བྱེད་དགོས་ཀྱི་ཡོད། NLG ལས་དཔེར་ན། ང་ཚོས་རང་ཉིད་ཀྱིས་དབྱེ་རིམ་གྱི་གནས་ཚུལ་གསལ་བགྲངས་sistem་ཅིག་གཟུགས་བསམ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ཐབས་ལམ་འདིས་མཉམ་དུ་བཟོ་རྩོལ་བ་ཞིག་བྱེད་པར་གཞི་རྟེན་ཏུ་མཐུན་རྐྱེན་བཟོ་བ་ཞིག'}
{'en': 'Listener’s Social Identity Matters in Personalised Response Generation', 'ar': 'مسائل الهوية الاجتماعية للمستمع في توليد الاستجابة المخصصة', 'es': 'La identidad social del oyente es importante en la generación de respuestas personalizadas', 'fr': "L'identité sociale de l'auditeur est importante dans la génération de réponses personnalisées", 'pt': 'A identidade social do ouvinte é importante na geração de respostas personalizadas', 'ja': 'パーソナライズされた応答生成におけるリスナーの社会的アイデンティティの重要性', 'ru': 'Социальная идентичность слушателя имеет значение при формировании персонализированного ответа', 'zh': '听世在个性化应生之要', 'hi': 'श्रोता की सामाजिक पहचान व्यक्तिगत प्रतिक्रिया पीढ़ी में मायने रखती है', 'ga': 'Tá Aitheantais Shóisialta an éisteoir i nGiniúint Freagartha Pearsanta', 'ka': 'სოციალური იდენტიფიკაციის შესახებ პროცენალური განახლების შესახებ', 'hu': 'A hallgatók társadalmi identitása fontos a személyre szabott válasz generálásában', 'el': 'Η κοινωνική ταυτότητα του ακροατή έχει σημασία στη δημιουργία εξατομικευμένης αντίδρασης', 'kk': 'Тізімдердің әлемдік идентификациялық мәселелері', 'it': "L'identità sociale dell'ascoltatore è importante nella generazione di risposte personalizzate", 'lt': "Listener's Social Identity Matters in Personalised Response Generation", 'mk': 'Социјален идентитет на слушачот во генерацијата на лични одговори', 'ms': 'Masalah Identiti Sosial Pemdengar dalam Jenerasi Balasan Peribadi', 'ml': 'വ്യക്തിപരമായ പ്രതികരണം', 'mt': "Kwistjonijiet ta' Identità Soċjali tal-Listener fil-Ġenerazzjoni ta' Rispons Personalizzat", 'mn': 'Сүлэгчийн нийгмийн нэр тодорхойлолтын асуудал', 'no': 'Listener s sosiale identitetsmettar i oppretting av personalisert svar', 'pl': 'Tożsamość społeczna słuchacza ma znaczenie w generowaniu spersonalizowanych reakcji', 'ro': 'Identitatea socială a ascultătorului contează în generarea de răspunsuri personalizate', 'sr': 'Slušateljska socijalna identiteta u generaciji osobnog odgovora', 'si': 'පුද්ගලික ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක සාමාජික අඳුරණ ප්\u200dරශ්නයක්', 'so': 'Shaqooyiga arrimaha bulshada ee dhaqaalaha jawaabta shakhsiyeed', 'sv': 'Lyssnarens sociala identitet spelar roll i personaliserad responsgenerering', 'ta': 'Name', 'ur': 'سننے والے کی سوسیل شناسی موضوع شخصی جواب کی نسل میں', 'uz': "Listener's Social Identity Matters in Personalised Response Generation", 'vi': 'Hệ thống Nhận diện xã hội của người lắng nghe', 'bg': 'Социалната идентичност на слушателя има значение в генерирането на персонализирани отговори', 'nl': 'De sociale identiteit van de luisteraar is belangrijk in gepersonaliseerde responsgeneratie', 'hr': 'Slušatelji socijalne identitete u generaciji osobnog odgovora', 'da': 'Lytterens sociale identitet betyder noget ved personaliseret responsgenerering', 'de': 'Die soziale Identität des Zuhörers spielt eine Rolle bei der Generierung personalisierter Reaktionen', 'id': "Listener's Social Identity Matters in Personalised Response Generation", 'ko': '청중의 사회적 신분은 개성화된 반응 생성에서 매우 중요하다', 'fa': 'موضوع شناسایی اجتماعی شنونده در نسل جواب شخصی', 'sw': 'Masuala ya Utambulisho wa Kijamii katika Uzalishaji wa Jibu binafsi', 'tr': "Listener's Social Identity Matters in Personalized Response Generation", 'sq': 'Çështjet e identitetit social të dëgjuesit në gjenerimin e përgjigjes s ë personalizuar', 'af': 'Luister se sosiale identiteitsmatte in Persoonaliseerde Antwoord Generasie', 'am': 'የዶሴ ስም፦', 'hy': 'Հանձնական արձագանքի ստեղծման ընթացքում լսողի սոցիալական ինքնության հարցերը', 'bn': 'ব্যক্তিগত প্রতিক্রিয়া প্রজন্মের শ্রেণীর সামাজিক পরিচয় বিষয়', 'az': 'Ňěahsiyy…ôtli cavab GenerasńĪnda qulaqlarńĪnńĪn sosyal kimlik m…ôs …ôl…ôl…ôri', 'bs': 'Slušatelji socijalne identitete u generaciji osobnog odgovora', 'ca': "Les qüestions d'identitat social de l'escoltant en la generació de resposta personalitzada", 'et': 'Kuulaja sotsiaalne identiteet on isikliku reageerimise genereerimisel oluline', 'cs': 'Posluchačova sociální identita záleží na generaci personalizovaných reakcí', 'fi': 'Kuuntelejan sosiaalisella identiteetillä on merkitystä personoidun vastauksen luomisessa', 'jv': 'Attribute', 'sk': 'Družbena identiteta poslušalca je pomembna pri ustvarjanju osebnega odziva', 'ha': 'KCharselect unicode block name', 'he': 'ענייני הזהות החברתית של הקשיב ביצירת תגובה אישית', 'bo': "Listener's Social Identity Matters in Personalized Response Generation"}
{'en': 'Personalised response generation enables generating human-like responses by means of assigning the generator a social identity. However, pragmatics theory suggests that human beings adjust the way of speaking based on not only who they are but also whom they are talking to. In other words, when modelling personalised dialogues, it might be favourable if we also take the listener’s social identity into consideration. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener’s identity influences the language used in Chinese dialogues on social media. Also, we build personalised generators. The experiment results demonstrate that the listener’s identity indeed matters in the language use of responses and that the response generator can capture such differences in language use. More interestingly, by additionally modelling the listener’s identity, the personalised response generator performs better in its own identity.', 'ar': 'يتيح إنشاء الاستجابة المخصصة توليد استجابات شبيهة بالبشر عن طريق تخصيص هوية اجتماعية للمولد. ومع ذلك ، تشير نظرية البراغماتية إلى أن البشر يضبطون طريقة التحدث ليس فقط بناءً على من هم ولكن أيضًا على من يتحدثون. بعبارة أخرى ، عند نمذجة الحوارات الشخصية ، قد يكون من الأفضل أن نأخذ الهوية الاجتماعية للمستمع بعين الاعتبار. للتحقق من صحة هذه الفكرة ، نستخدم الجنس كمثال نموذجي لمتغير اجتماعي للتحقيق في كيفية تأثير هوية المستمع على اللغة المستخدمة في الحوارات الصينية على وسائل التواصل الاجتماعي. أيضا ، نحن نبني مولدات شخصية. توضح نتائج التجربة أن هوية المستمع مهمة بالفعل في استخدام اللغة للاستجابات وأن منشئ الاستجابة يمكنه التقاط مثل هذه الاختلافات في استخدام اللغة. الأكثر إثارة للاهتمام ، من خلال نمذجة هوية المستمع بالإضافة إلى ذلك ، يعمل منشئ الاستجابة الشخصية بشكل أفضل في هويته الخاصة.', 'es': 'La generación de respuestas personalizadas permite generar respuestas similares a las humanas mediante la asignación de una identidad social al generador. Sin embargo, la teoría pragmática sugiere que los seres humanos ajustan la forma de hablar en función no solo de quiénes son sino también con quién están hablando. En otras palabras, al modelar diálogos personalizados, podría ser favorable que también tuviéramos en cuenta la identidad social del oyente. Para validar esta idea, utilizamos el género como ejemplo típico de una variable social para investigar cómo la identidad del oyente influye en el idioma utilizado en los diálogos chinos en las redes sociales. Además, construimos generadores personalizados. Los resultados del experimento demuestran que la identidad del oyente es realmente importante en el uso del idioma de las respuestas y que el generador de respuestas puede captar tales diferencias en el uso del idioma. Más interesante aún, al modelar adicionalmente la identidad del oyente, el generador de respuestas personalizadas funciona mejor en su propia identidad.', 'pt': 'A geração de respostas personalizadas permite gerar respostas semelhantes às humanas por meio da atribuição de uma identidade social ao gerador. No entanto, a teoria pragmática sugere que os seres humanos ajustam a maneira de falar com base não apenas em quem são, mas também com quem estão falando. Em outras palavras, ao modelar diálogos personalizados, pode ser favorável se levarmos em consideração também a identidade social do ouvinte. Para validar essa ideia, usamos o gênero como exemplo típico de variável social para investigar como a identidade do ouvinte influencia a linguagem usada nos diálogos chineses nas mídias sociais. Além disso, construímos geradores personalizados. Os resultados do experimento demonstram que a identidade do ouvinte realmente importa no uso da linguagem das respostas e que o gerador de respostas pode capturar tais diferenças no uso da linguagem. Mais interessante, ao modelar adicionalmente a identidade do ouvinte, o gerador de respostas personalizadas tem um desempenho melhor em sua própria identidade.', 'fr': "La génération de réponses personnalisées permet de générer des réponses de type humain en attribuant au générateur une identité sociale. Cependant, la théorie pragmatique suggère que les êtres humains ajustent leur façon de parler en fonction non seulement de leur identité mais aussi de la personne à qui ils parlent. En d'autres termes, lors de la modélisation de dialogues personnalisés, il peut être préférable de prendre également en compte l'identité sociale de l'auditeur. Pour valider cette idée, nous utilisons le genre comme exemple typique de variable sociale afin d'étudier comment l'identité de l'auditeur influence la langue utilisée dans les dialogues chinois sur les réseaux sociaux. Nous fabriquons également des groupes électrogènes personnalisés. Les résultats de l'expérience démontrent que l'identité de l'auditeur est effectivement importante dans l'utilisation de la langue des réponses et que le générateur de réponses peut saisir de telles différences dans l'utilisation de la langue. Plus intéressant encore, en modélisant l'identité de l'auditeur, le générateur de réponse personnalisée fonctionne mieux dans sa propre identité.", 'ja': 'パーソナライズされた応答生成は、生成者に社会的アイデンティティを割り当てることによって、人間のような応答を生成することを可能にする。しかし、プラグマティクス理論は、人間が誰であるかだけでなく、話している相手に基づいて話し方を調整することを示唆しています。言い換えれば、パーソナライズされた対話をモデル化する際には、リスナーの社会的アイデンティティも考慮に入れるとよいかもしれない。このアイデアを検証するために、私たちはジェンダーを社会変数の典型的な例として使用して、リスナーのアイデンティティがソーシャルメディア上の中国語の対話で使用される言語にどのように影響するかを調査します。また、私たちはパーソナライズされた発電機を構築します。実験結果は、リスナーのアイデンティティが応答の言語使用において実際に重要であり、応答生成器が言語使用におけるそのような差異を取り込むことができることを実証する。さらに興味深いことに、リスナーのアイデンティティを追加的にモデル化することによって、パーソナライズされた応答ジェネレータは、独自のアイデンティティにおいてより良いパフォーマンスを発揮する。', 'zh': '个性化应生成器以成类也。 然语用学理以为人伦所据,而方与之言调之。 换句话说建模于个性化,虑闻于世,其有益也。 以性别为社会变量典,以论听众之化社交媒体上中文对言之语。 造个性化之发电机。 实验结果表明,听众之言诚重,而应生成器可得之异也。 更有趣者,别建模于听众,个性化之应生成器于己为愈。', 'hi': 'व्यक्तिगत प्रतिक्रिया पीढ़ी जनरेटर को एक सामाजिक पहचान निर्दिष्ट करने के माध्यम से मानव जैसी प्रतिक्रियाओं को उत्पन्न करने में सक्षम बनाती है। हालांकि, व्यावहारिक सिद्धांत से पता चलता है कि मनुष्य न केवल इस आधार पर बोलने के तरीके को समायोजित करता है कि वे कौन हैं, बल्कि वे किससे बात कर रहे हैं। दूसरे शब्दों में, व्यक्तिगत संवादों का मॉडलिंग करते समय, यह अनुकूल हो सकता है यदि हम श्रोता की सामाजिक पहचान को भी ध्यान में रखते हैं। इस विचार को मान्य करने के लिए, हम लिंग का उपयोग एक सामाजिक चर के एक विशिष्ट उदाहरण के रूप में करते हैं ताकि यह जांच की जा सके कि श्रोता की पहचान सोशल मीडिया पर चीनी संवादों में उपयोग की जाने वाली भाषा को कैसे प्रभावित करती है। इसके अलावा, हम व्यक्तिगत जनरेटर का निर्माण करते हैं। प्रयोग के परिणाम दर्शाते हैं कि श्रोता की पहचान वास्तव में प्रतिक्रियाओं के भाषा उपयोग में मायने रखती है और प्रतिक्रिया जनरेटर भाषा के उपयोग में इस तरह के अंतर को कैप्चर कर सकता है। अधिक दिलचस्प बात यह है कि श्रोता की पहचान को मॉडलिंग करके, व्यक्तिगत प्रतिक्रिया जनरेटर अपनी पहचान में बेहतर प्रदर्शन करता है।', 'ru': 'Индивидуальная генерация ответов позволяет генерировать человекоподобные ответы посредством присвоения генератору социальной идентичности. Однако теория прагматики предполагает, что люди приспосабливаются к тому, как говорить, основываясь не только на том, кто они, но и на том, с кем они разговаривают. Другими словами, при моделировании персонализированных диалогов может быть благоприятно, если мы также примем во внимание социальную идентичность слушателя. Чтобы подтвердить эту идею, мы используем пол в качестве типичного примера социальной переменной, чтобы исследовать, как личность слушателя влияет на язык, используемый в китайских диалогах в социальных сетях. Также мы создаем персонализированные генераторы. Результаты эксперимента показывают, что идентичность слушателя действительно имеет значение в использовании языка ответов и что генератор ответов может фиксировать такие различия в использовании языка. Более интересно, что, дополнительно моделируя идентичность слушателя, персонализированный генератор ответов работает лучше в своей собственной идентичности.', 'ga': "Cumasaíonn giniúint freagra pearsantaithe freagairtí cosúil le daoine a ghiniúint trí fhéiniúlacht shóisialta a thabhairt don ghineadóir. Mar sin féin, tugann teoiric na pragmataice le tuiscint go n-athraíonn daoine an bealach cainte bunaithe ní amháin ar cé hiad féin ach freisin cé leis a bhfuil siad ag caint. I bhfocail eile, agus comhphlé pearsantaithe á samhaltú, d'fhéadfadh sé a bheith fabhrach dá gcuirfimid féiniúlacht shóisialta an éisteoir san áireamh freisin. Chun an smaoineamh seo a bhailíochtú, bainimid úsáid as inscne mar ghnáthshampla d’athróg shóisialta chun imscrúdú a dhéanamh ar an tionchar a bhíonn ag féiniúlacht an éisteora ar an teanga a úsáidtear in idirphlé na Síne ar na meáin shóisialta. Chomh maith leis sin, tógann muid gineadóirí pearsantaithe. Léiríonn torthaí an turgnaimh go bhfuil tábhacht ag baint le féiniúlacht an éisteoir maidir le húsáid teanga na bhfreagraí agus gur féidir leis an ngineadóir freagraí na héagsúlachtaí sin in úsáid teanga a léiriú. Níos suimiúla fós, trí fhéiniúlacht an éisteora a shamhaltú freisin, is fearr a n-éiríonn leis an ngineadóir freagartha pearsanta ina fhéiniúlacht féin.", 'ka': 'პროცენალიზებული რეაქტის შესაძლებელია ადამიანის სხვადასხვა რეაქტის შესაძლებლობა, როგორც ადამიანის სხვადასხვა რეაქტის შესაძლებელია, როგორც გენერატორი მაგრამ პრაგმატიკური თეორია იტყვებს, რომ ადამიანები ადამიანებისთვის კონფიგურაციას არა მხოლოდ რომელსაც ისინი არიან, მაგრამ რომელსაც ისინი კითხვა. სხვა სიტყვებით, როდესაც პოციალური დიალოგების მოდელურება, შეიძლება იყოს სუციალური იდენტიფიკაციის შესახებ. ამ იდეაზე გავაკეთებთ, ჩვენ სოციალური ცვლილების ტიპონული მაგალითვის გამოყენებთ, როგორ სუციალური იდენტიფიკაციის იდენტიფიკაციის შესახებ ჩინეთის დიალოგში სოციალური მედიაში გამოყ ასევე, ჩვენ პორციალურად განვიყენებთ პერციალურად განვიყენება. ექსპერიმენტის შედეგები გამოყენებენ, რომ სურადღელი იდენტიფიკაცია მნიშვნელოვანია სახელის გამოყენებაში და რომ რექსპერიმენტის გენერიმენტი შეუძლია ასეთი განსხვავებები ოჲგვფვ თნრვპვჟნჲ, აკჲ ოჲგვფვ მჲევლთპაქ თნრვპვნრთრარა ნა ჟლსქაღთწ, პჲზთნალთჱთპან პვედვნვპარჲპ ოპაგთ ოჲ-ეჲბპვ გ ჟგჲწ თნრვპვნ', 'el': 'Η εξατομικευμένη δημιουργία απαντήσεων επιτρέπει την παραγωγή ανθρώπινων απαντήσεων μέσω της εκχώρησης στη γεννήτρια κοινωνικής ταυτότητας. Ωστόσο, η θεωρία της πραγματιστικής υποδηλώνει ότι οι άνθρωποι προσαρμόζουν τον τρόπο ομιλίας όχι μόνο με βάση το ποιοι είναι αλλά και με ποιον μιλάνε. Με άλλα λόγια, κατά την μοντελοποίηση εξατομικευμένων διαλόγων, θα ήταν θετικό να λάβουμε υπόψη και την κοινωνική ταυτότητα του ακροατή. Για να επικυρώσουμε αυτή την ιδέα, χρησιμοποιούμε το φύλο ως τυπικό παράδειγμα κοινωνικής μεταβλητής για να διερευνήσουμε πώς η ταυτότητα του ακροατή επηρεάζει τη γλώσσα που χρησιμοποιείται στους κινέζικους διαλόγους στα μέσα κοινωνικής δικτύωσης. Επίσης, κατασκευάζουμε εξατομικευμένες γεννήτριες. Τα αποτελέσματα του πειράματος καταδεικνύουν ότι η ταυτότητα του ακροατή πράγματι έχει σημασία στη γλωσσική χρήση των απαντήσεων και ότι η γεννήτρια απόκρισης μπορεί να καταγράψει τέτοιες διαφορές στη χρήση της γλώσσας. Πιο ενδιαφέρον είναι ότι με την επιπλέον μοντελοποίηση της ταυτότητας του ακροατή, η εξατομικευμένη γεννήτρια απόκρισης αποδίδει καλύτερα στη δική της ταυτότητα.', 'hu': 'A személyre szabott válasz generálása lehetővé teszi, hogy emberszerű válaszokat generáljon a generátor társadalmi identitásával. A pragmatikai elmélet azonban azt sugallja, hogy az emberek nemcsak azon alapul, hogy kik ők, hanem kivel is beszélnek. Más szóval, a személyre szabott párbeszédek modellezésekor kedvező lehet, ha a hallgató társadalmi identitását is figyelembe vesszük. Ennek érvényesítéséhez a nemet használjuk a közösségi változó tipikus példájaként annak vizsgálatára, hogy a hallgató identitása hogyan befolyásolja a kínai párbeszédekben használt nyelvet a közösségi médiában. Emellett személyre szabott generátorokat építünk. A kísérleti eredmények azt mutatják, hogy a hallgató identitása valóban számít a válaszok nyelvhasználatában, és hogy a válaszgenerátor képes felismerni a nyelvhasználat ilyen különbségeit. Érdekesebb, hogy a hallgató identitásának további modellezésével a személyre szabott válaszgenerátor saját identitásában jobban teljesít.', 'it': "La generazione di risposte personalizzate consente di generare risposte simili a quelle umane assegnando al generatore un'identità sociale. Tuttavia, la teoria pragmatica suggerisce che gli esseri umani adeguino il modo di parlare non solo in base a chi sono, ma anche a chi stanno parlando. In altre parole, quando si modellano dialoghi personalizzati, potrebbe essere vantaggioso prendere in considerazione anche l'identità sociale dell'ascoltatore. Per convalidare questa idea, usiamo il genere come tipico esempio di variabile sociale per indagare come l'identità dell'ascoltatore influenza la lingua utilizzata nei dialoghi cinesi sui social media. Inoltre, costruiamo generatori personalizzati. I risultati dell'esperimento dimostrano che l'identità dell'ascoltatore conta davvero nell'uso linguistico delle risposte e che il generatore di risposta può cogliere tali differenze nell'uso linguistico. Più interessante, modellando ulteriormente l'identità dell'ascoltatore, il generatore di risposta personalizzato funziona meglio nella propria identità.", 'lt': "Personalizuotas atsako generavimas leidžia generuoti žmogaus panašius atsakus suteikiant generatoriui socialinę tapatybę. Tačiau pragmatikos teorija rodo, kad žmonės koreguoja kalbos būdą ne tik remiantis tuo, kas jie yra, bet ir su kuo jie kalba. Kitaip tariant, modeliuojant individualius dialogus būtų naudinga atsižvelgti ir į klausytojo socialinę tapatybę. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener's identity influences the language used in Chinese dialogues on social media.  Taip pat statome personalizuotus generatorius. Eksperimentų rezultatai rodo, kad klausytojo tapatybė iš tikrųjų yra svarbi kalbos naudojimo atsakymams ir kad atsako generatorius gali nustatyti tokius kalbos naudojimo skirtumus. More interestingly, by additionally modelling the listener's identity, the personalised response generator performs better in its own identity.", 'kk': 'Дербес жауап құру адамдардың ұқсас жауаптарын жасауға мүмкіндік береді. Бірақ прагматикалық теориясы адамдардың сөйлесу жолын тек өзінің кімге негізделген емес, сондай-ақ олардың сөйлесіп тұрған адамдардың өзінің өзінің өзінің өзінің өзінің Басқа сөздерде, өзгеше диалогтарды моделдегенде, тыңдаушының әлеуметтік идентификациясын қарастыруға мүмкін болуы мүмкін. Бұл идеяны тексеру үшін, біз гендерді әдеттегі социалдық айнымалылығының мысалы ретінде қолданып, тыңдаушының идентификациясы қалай қытайлық диалогтарда қолданылатын тілдерге әсер етеді. Сонымен қатар, бұл жеке генераторларды құрамыз. Тәжірибенің нәтижесі тыңдаушының идентификациясы тілде жауаптарды қолданатын және жауап жасаушысы тілдердің қолдануындағы айырмашылығын түсінеді деп көрсетеді. Ең қызықтығы: тыңдаушының идентификациясын моделдеп, өзінің идентификациясының өзінің іс- әлпетін жасау жасаушысы жақсы жұмыс істейді.', 'mk': "Генерацијата на лични одговори овозможува генерирање на човечки одговори преку доделување на социјален идентитет на генераторот. Сепак, теоријата на прагматиката покажува дека човечките суштества го прилагодуваат начинот на зборување врз основа не само на тоа со кој се, туку и со кого зборуваат. Со други зборови, кога ќе се моделираат персонализирани дијалози, можеби би било поволно да го земеме во предвид и социјалниот идентитет на слушачот. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener's identity influences the language used in Chinese dialogues on social media.  Исто така, ние градиме персонализирани генератори. Резултатите од експериментите покажуваат дека идентитетот на слушачот навистина е важен во јазикот на употребата на одговорите и дека генераторот на одговорот може да ги фати ваквите разлики во употребата на јазикот. Поинтересно е, со дополнително моделирање на идентитетот на слушачот, генераторот на персонализиран одговор е подобар во својот идентитет.", 'ms': "Generasi balas peribadi membolehkan menghasilkan balas seperti manusia dengan menyerahkan identiti sosial pada generator. Namun, teori pragmatik menunjukkan bahawa manusia menyesuaikan cara bercakap berdasarkan bukan sahaja siapa mereka tetapi juga dengan siapa mereka bercakap. Dengan kata lain, apabila memmodelkan dialog pribadi, ia mungkin lebih baik jika kita juga mempertimbangkan identiti sosial pendengar. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener's identity influences the language used in Chinese dialogues on social media.  Juga, kami membina generator pribadi. Hasil eksperimen menunjukkan bahawa identiti pendengar benar-benar penting dalam penggunaan bahasa respon dan bahawa generator respon boleh menangkap perbezaan dalam penggunaan bahasa. Lebih menarik, dengan menambah model identiti pendengar, penjana balas personalisasi berfungsi lebih baik dalam identitinya sendiri.", 'ml': 'സ്വകാര്യമായ മറുപടി തലമുറയില്\u200d മനുഷ്യരെപ്പോലുള്ള ഉത്തരങ്ങള്\u200d ഉണ്ടാക്കാന്\u200d സാധ്യതയോടെ ജെനററേറ്ററിനെ സാമൂ എന്നാലും, മനുഷ്യര്\u200d സംസാരിക്കുന്നതിന്\u200dറെ രീതി മാത്രമല്ല, അവര്\u200d ആരാണെന്ന് അടിസ്ഥാനമാക്കിയിരിക്കുന്നത് മാത്രമല്ല, അവര മറ്റു വാക്കുകളില്\u200d മോഡല്\u200d ചെയ്യുമ്പോള്\u200d നമ്മള്\u200d കേള്\u200dക്കുന്നവന്റെ സാമൂഹ്യത്തിന്റെ അടിസ്ഥാനത്തെക്കുറിച്ച് ചിന് ഈ ഐഡിയയെ പരിശോധിപ്പിക്കാന്\u200d ഞങ്ങള്\u200d സാമൂഹിക മാറ്റമായി ഉപയോഗിക്കുന്നു പിന്നെ നമ്മള്\u200d വ്യക്തിപരമായ ജെനററുകള്\u200d പണിയുന്നു. പരീക്ഷണത്തിന്റെ ഫലം കാണിക്കുന്നു കേള്\u200dക്കുന്നവന്റെ identity ശരിക്കും ഉത്തരം ഉപയോഗിക്കുന്നതിന് ഭാഷയില്\u200d പ്രധാനപ്പെട്ടതാണെന്ന കൂടുതല്\u200d രസകരമായി, കേള്\u200dക്കുന്നവന്\u200dറെ identity മോഡല്\u200d ചെയ്യുന്നതില്\u200d, സ്വകാര്യമായ പ്രതികരിക്കുന്ന പ്രതികരണം സ്വന്തം identityില്\u200d നല്', 'mt': "Il-ġenerazzjoni personalizzata tar-rispons tippermetti l-ġenerazzjoni ta’ risponsi simili għall-bniedem permezz tal-assenjazzjoni ta’ identità soċjali lill-ġeneratur. Madankollu, it-teorija tal-pragmatika tissuġġerixxi li l-bnedmin jaġġustaw il-mod kif jitkellmu abbażi mhux biss ta’ min huma iżda wkoll ta’ min qed jitkellmu. Fi kliem ieħor, meta nimmudellaw djalogi personalizzati, jista’ jkun favorevoli jekk nikkunsidraw ukoll l-identità soċjali ta’ min jisma’. Biex tivvalida din l-idea, a ħna nużaw is-sess bħala eżempju tipiku ta' varjabbli soċjali biex ninvestigaw kif l-identità ta' min jisma' tinfluwenza l-lingwa użata fid-djalogi Ċiniżi dwar il-midja soċjali. Barra minn hekk, nibnu ġeneraturi personalizzati. Ir-riżultati tal-esperimenti juru li l-identità ta’ min jisma’ tassew hija importanti fl-użu tal-lingwa tar-risposti u li l-ġeneratur tar-rispons jista’ jaqbad dawn id-differenzi fl-użu tal-lingwa. Aktar interessanti, permezz ta’ mudell addizzjonali tal-identità ta’ min jisma’, il-ġeneratur ta’ rispons personalizzat iwettaq prestazzjoni aħjar fl-identità tiegħu stess.", 'mn': 'Хэрэглэгчийн хариу үйлдвэрлэл нь хүн төрөлхтний адил хариу үйлдвэрлэх боломж олгодог. Гэхдээ прагматикийн онол нь хүн төрөлхтний ярианы арга зөвхөн өөрсдийн хэн гэдгээр биш, мөн хэнтэй ярьж байгааг зөвхөн зөвхөн өөрсдийгөө зөвхөн зөвхөн зөвхөн зө Өөрөөр хэлбэл, хувийн диалогуудыг загварчлах үед сонсогчидын нийгмийн тодорхойлолтыг ч анхаарлаа бодож үзэх хэрэгтэй. Энэ санааг баталгаалахын тулд бид гендерийг нийгмийн өөрчлөлтийн жишээ болгон хэрхэн сонсогчийн мэдлэг хэрхэн Хятад хэл дээр нийгмийн мэдээлэл дээр хэрхэн ашигладаг талаар судлах хэрэгтэй. Мөн бид хувийн бүтээгдэхүүн бүтээж байна. Энэ туршилтын үр дүнд сонсогчийн хувьд хэл хариултын хэрэглээнд үнэхээр чухал гэдгийг харуулж байна. Хариулт гаргагч нь хэл хэрэглээнд ийм өөрчлөлт авч чадна. Илүү сонирхолтой нь, сонсогчидын идентификацийг дамжуулахад хувийн хариу үйлдвэрлэгч нь өөрийн идентификацийг илүү сайн хийдэг.', 'pl': 'Spersonalizowane generowanie odpowiedzi umożliwia generowanie odpowiedzi podobnych do człowieka poprzez przypisanie generatorowi tożsamości społecznej. Jednak teoria pragmatyki sugeruje, że ludzie dostosowują sposób mówienia nie tylko na podstawie tego, kim są, ale także z kim rozmawiają. Innymi słowy, przy modelowaniu spersonalizowanych dialogów korzystne byłoby, gdybyśmy uwzględnili również tożsamość społeczną słuchacza. Aby potwierdzić tę ideę, używamy płci jako typowego przykładu zmiennej społecznej, aby zbadać, w jaki sposób tożsamość słuchacza wpływa na język używany w chińskich dialogach w mediach społecznościowych. Budujemy również spersonalizowane generatory. Wyniki eksperymentu pokazują, że tożsamość słuchacza rzeczywiście ma znaczenie w wykorzystaniu odpowiedzi językowej i że generator odpowiedzi może uchwycić takie różnice w użyciu języka. Co ciekawsze, poprzez dodatkowe modelowanie tożsamości słuchacza, generator spersonalizowanych odpowiedzi lepiej sprawdza się we własnej tożsamości.', 'no': 'Generasjon av personaliserte svar slår på å laga menneskelige svar ved å tilordna generatoren ein sosialidentitet. Pragmatiske teorien tyder imidlertid at menneskene tilpassar måten å snakke på ikkje bare kva dei er, men også kva dei snakker med. I andre ord, når du modeller personaliserte dialogar, kan det vera nyttig om vi også ta opp den sosiale identiteten til lysaren. For å validera denne ideen, bruker vi seks som eit typisk eksempel på ein sosialt variabel for å undersøke korleis lyttaren identiteten påvirkar språket brukt i kinesiske dialogar på sosiale media. Vi bygger også personaliserte generatorer. Eksperiment-resultatet viser at lyttaren s in identitet vere viktig i språkkbruken av svar og at svargeneratoren kan henta slike forskjeller i språkkbruken. I meir interessant måte ved å modellere identiteten til lysaren, gjer den personlege svargeneratoren bedre i identiteten s in.', 'ro': 'Generarea personalizată a răspunsurilor permite generarea de răspunsuri asemănătoare omului prin atribuirea generatorului o identitate socială. Cu toate acestea, teoria pragmatică sugerează că ființele umane ajustează modul de a vorbi bazându-se nu numai pe cine sunt, ci și pe cine vorbesc. Cu alte cuvinte, atunci când modelăm dialoguri personalizate, ar putea fi favorabil să luăm în considerare și identitatea socială a ascultătorului. Pentru a valida această idee, folosim genul ca exemplu tipic de variabilă socială pentru a investiga modul în care identitatea ascultătorului influențează limba folosită în dialogurile chinezești pe rețelele de socializare. De asemenea, construim generatoare personalizate. Rezultatele experimentului demonstrează că identitatea ascultătorului contează într-adevăr în utilizarea limbii răspunsurilor și că generatorul de răspuns poate capta astfel de diferențe în utilizarea limbii. Mai interesant, prin modelarea suplimentară a identității ascultătorului, generatorul de răspuns personalizat performează mai bine în propria identitate.', 'sr': 'Personalizirana generacija odgovora omogućava stvaranje reakcija poput ljudskih ljudi pomoću određivanja generator a socijalnog identiteta. Međutim, pragmatička teorija predlaže da ljudska bića prilagođuju način govora na osnovu ne samo sa kim su, nego i sa kim razgovaraju. Drugim reèima, kada modeliramo personalizovane dijaloge, moglo bi biti od koristi ako i slušateljski socijalni identitet shvatimo u obzir. Da bismo potvrdili ovu ideju, koristili smo spol kao tipičan primjer socijalne promjene kako bi istražili kako je identitet slušaoca uticao na jezik koji se koristi u kineskim dijalogima na društvenim medijima. Takoðe, mi gradimo personalizovane generatore. Rezultati eksperimenta pokazuju da je identitet slušaoca zaista bitan u upotrebi jezika odgovora i da generator odgovora može uhvatiti takve razlike u upotrebi jezika. Zanimljivije je, dodatno modelirajući identitet slušaoca, generator ličnog odgovora bolje obavlja u sopstvenom identitetu.', 'so': 'Qarniga jawaabta ee shakhsiyanka ah wuxuu sameyn karaa jawaabo u eg dadka oo kale, taas oo lagu sameynayo qofka dhaliya aqoonsi bulshada. Si kastaba ha ahaatee fikrada caafimaadka waxaa looga jeedaa in dadku ay ku hagaajiyaan jidka hadalka, taasoo aan ku saleyn qofka ay ka hadlaan oo keliya, laakiin sidoo kale. Hadal kale, marka lagu sameynayo sameynta qaabilsan oo gaar ah, waxaa suurtagal ah in aynu ka fikirinno aqoonsiga bulshada ee maqalka. Si aan u xaqiijinno fikradan, waxaynu u isticmaalnaa jinsiga tusaale caadi ah oo kala bedela bulshada si aan u baaritaanno jinsi uu u saameyn karo aqoonsiga maqalka ee luqada ee ku qoran dialogueyda Shiino ee bulshada. Sidoo kale, waxaynu dhisaynaa dhaliyayaal gaar ah. Imtixaanka waxaa ka muuqata in aqoonsiga dhegta la’aantiisu ay muhiim ugu tahay isticmaalka jawaabaha luqada, iyo in dhaqaalaha jawaabsadu uu qabsan karo kala duwan oo ku saabsan isticmaalka luqada. Si xiiso badan, si kaloo loo sameynayo aqoonsiga dhegta, dhaqaalaha jawaabta ee shakhsiyanka ah ayaa si wanaagsan ugu sameeya aqoonsigiisa.', 'si': 'පුද්ගලික ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාවට මිනිස්සු වගේ ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විද නමුත්, ප්\u200dරාග්මැටික් සිද්ධානය ප්\u200dරශ්නයක් තියෙනවා මිනිස්සුන් කතා කරන්නේ කියලා කියලා කියලා කියලා කියලා කි අනිත් වචනයෙන්, පෞද්ගලික සංවාදය සංවාදයක් මොඩල් කරන්න පුළුවන්, අපි අහන්නේ අහන්නේ සමාජික අයිතිකතාව මේ අදහසක් විශ්වාස කරන්න, අපි සාමාජික වෙනස් වල සාමාජික වර්ගයක් වගේ සාමාජික උදාහරණයක් භාවිතා කරනවා සමාජික මාධ්\u200dයම අපි පෞද්ගලික විද්\u200dයාපිත විද්\u200dයාපිත කරනවා. පරීක්ෂණයේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ අහන්නේ කියලා භාෂාව ප්\u200dරතිචාරයක් ඇත්තටම ප්\u200dරතිචාරයේ භාෂා තව ප්\u200dරශ්නයෙන්, අහන්නේ අයිතිකාරයාගේ අයිතිකාරයාගේ අයිතිකාරයෙන් ප්\u200dරතික්\u200dරියාත්මක කරන්න, පුද්ගලික ප්\u200d', 'sv': 'Personlig responsgenerering möjliggör att generera människoliknande svar genom att tilldela generatorn en social identitet. Men pragmatisk teori antyder att människan anpassar sitt sätt att tala utifrån inte bara vem de är utan också vem de pratar med. Med andra ord, när man modellerar personliga dialoger kan det vara fördelaktigt om man också tar hänsyn till lyssnarens sociala identitet. För att validera denna idé använder vi genus som ett typiskt exempel på en social variabel för att undersöka hur lyssnarens identitet påverkar språket som används i kinesiska dialoger på sociala medier. Vi bygger också personliga generatorer. Experimentresultaten visar att lyssnarens identitet verkligen spelar roll i språkanvändningen av svar och att responsgeneratorn kan fånga upp sådana skillnader i språkanvändning. Ännu mer intressant är att genom att ytterligare modellera lyssnarens identitet presterar den personliga responsgeneratorn bättre i sin egen identitet.', 'ta': 'தனிப்பட்ட பதில் தலைமுறை மனித போன்ற பதில்களை உருவாக்கும் மூலம் உருவாக்கும் பொருள் உருவாக்குபவரை ஒரு சமூக அடையாளத் ஆனால், முக்கியமான திடீரி மனிதர்கள் பேசும் வழியை மாற்றுகிறது அவர்கள் யார் என்று அடிப்படையில் மட்டும் அல்ல, ஆனால் அவர்கள் பே வேறு வார்த்தைகளில், மாதிரிப்பு தனிப்பட்ட உரையாடல் போது, நாம் கேட்பவரின் சமூக அடையாளத்தை பார்த்துக் கொள்வது நன்மை இந்த கருத்தை சரிபார்க்க, நாம் பெண்களை ஒரு சாதாரண மாறியின் எடுத்துகாட்டாக பயன்படுத்துகிறோம். கேட்பவரின் அடையாளத்தை எப்படி சீனா உரையாடல மேலும், நாம் தனிப்பட்ட உருவாக்குபவர்களை கட்டுகிறோம். பரிசோதனை முடிவு மேலும் விருப்பமானது, கூடுதலாக கேட்பவரின் அடையாளத்தை மாதிரியில், தனிப்பட்ட பதில் உருவாக்கி தன்னுடைய அடையாளத்தில் சிறந்', 'ur': 'شخصی جواب کی نسل انسان جیسی جواب جواب دینے کے لئے اجازت دیتا ہے جینراٹر کو اجتماعی شناخت کے ذریعہ۔ لیکن مضبوط نظریہ یہ ہے کہ انسانوں کی بات کی طرح درست کرتی ہے نہ صرف کس پر ہیں بلکہ جس سے وہ بات کررہے ہیں۔ دوسرے کلمات سے، جب شخصی گفتگووں کی مدل کرتی ہے، یہ مناسب ہو سکتا ہے اگر ہم سننے والوں کی اجتماعی هویت کو بھی سمجھ لیتے ہیں. اس ایڈیوں کی تصدیق کرنے کے لئے، ہم جنس کو سوسیل میڈیا میں استعمال کرنے کے لئے ایک عام نمونہ کے طور پر استعمال کرتے ہیں کہ سننے والے کی شناست کس طرح سوسیل میڈیا میں چین کی گفتگووں میں استعمال کیا جاتا ہے۔ اور ہم شخصی جینراٹر بناتے ہیں۔ آزمائش کا نتیجہ دکھاتا ہے کہ سننے والے کی شناست یقیناً جواب دینے کی زبان کے استعمال میں اہم ہے اور یہ کہ جواب دینے والا زبان کے استعمال میں ایسی اختلاف حاصل کرسکتا ہے۔ اور زیادہ دلچسپ ہے، سننے والے کی شناسی کے ذریعہ اضافہ کے ذریعہ، شخصی جواب دینے والی جرائٹر اپنے شخصی شناسی میں بہتر عمل کرتا ہے.', 'uz': "Name Lekin, pragmatik tezasi odamlar gapiradigan so'zlarni faqat ular bilan gapirayotganlar asosida o'zgartiradi. Boshqa so'zlar bilan, shaxsiy dialoglar bilan modellash mumkin, biz tinglovchi shaxsiy shaxsiyatni tasavvur qilishimiz mumkin. Bu g'oyani to ʻgʻri qilish uchun, biz jamiyatli oʻzgarishni o'rganish uchun, tinglovchi shaxsiyatni Xitoycha muloqat oynalarida ishlatilgan tilni qanday influensa beradi. Shunday qilib, biz shaxsiy generatorlar yaramiz. Name More interestingly, by additionally modelling the listener's identity, the personalised response generator performs better in its own identity.", 'vi': 'Một thế hệ phản ứng tự chọn cho phép tạo ra các phản ứng giống người bằng cách trao cho máy phát một danh tính xã hội. Tuy nhiên, giả thuyết thực dụng cho thấy con người điều chỉnh cách nói chuyện không chỉ dựa trên con người mà còn là người mà họ đang nói chuyện. Nói cách khác, khi s ắp xếp các cuộc đối thoại riêng, sẽ tốt hơn nếu chúng ta cũng cân nhắc danh tính xã hội của người nghe. Để xác nhận ý tưởng này, chúng tôi dùng giới tính như một ví dụ điển hình của biến s ố xã hội để tìm hiểu làm thế nào danh tính của người nghe tác động ngôn ngữ được dùng trong các cuộc thoại Trung Quốc về các phương tiện xã hội. Chúng tôi cũng xây máy phát riêng. Kết quả thí nghiệm cho thấy danh tính của người nghe thực s ự quan trọng trong việc sử dụng ngôn ngữ các phản ứng và máy phát hành phản ứng có thể thu được những khác biệt trong việc sử dụng ngôn ngữ. Thú vị hơn, bằng cách mô phỏng danh tính của người nghe, máy tạo phản ứng cá nhân đạt hiệu quả tốt hơn trong danh tính của mình.', 'da': 'Personaliseret responsgenerering gør det muligt at generere menneskelignende reaktioner ved at tildele generatoren en social identitet. Men pragmatisk teori antyder, at mennesker justerer talemåden ud fra ikke blot, hvem de er, men også hvem de taler med. Med andre ord, når vi modellerer personlige dialoger, kan det være gunstigt, hvis vi også tager højde for lytterens sociale identitet. For at validere denne idé bruger vi køn som et typisk eksempel på en social variabel til at undersøge, hvordan lytterens identitet påvirker sproget i kinesiske dialoger på sociale medier. Vi bygger også personlige generatorer. Eksperimentets resultater viser, at lytterens identitet faktisk har betydning for sprogbrugen af svar, og at responsgeneratoren kan fange sådanne forskelle i sprogbrug. Mere interessant er, at ved yderligere at modellere lytterens identitet fungerer den personlige responsgenerator bedre i sin egen identitet.', 'bg': 'Персонализираното генериране на отговор позволява генерирането на човешки реакции чрез присвояване на генератора на социална идентичност. Въпреки това, теорията на прагматиката предполага, че човешките същества адаптират начина на говорене въз основа не само на това кои са те, но и на кого говорят. С други думи, при моделирането на персонализирани диалози би било благоприятно да вземем предвид и социалната идентичност на слушателя. За да утвърдим тази идея, използваме пола като типичен пример за социална променлива, за да изследваме как идентичността на слушателя влияе на езика, използван в китайските диалози в социалните медии. Също така изграждаме персонализирани генератори. Резултатите от експеримента показват, че идентичността на слушателя наистина има значение в езиковото използване на отговорите и че генераторът на отговор може да улови такива разлики в използването на езика. По-интересното е, че чрез допълнително моделиране на идентичността на слушателя генераторът на персонализирани отговори се представя по-добре в собствената си идентичност.', 'hr': 'Generacija osobnog odgovora omogućava stvaranje reakcija sličnih ljudima pomoću određivanja generator a socijalnog identiteta. Međutim, pragmatička teorija predlaže da se ljudska bića prilagođavaju način govora na temelju ne samo s kim su, već i s kim razgovaraju. Drugim riječima, kad modeliramo personalizovane dijaloge, moglo bi biti dobrodošlo ako bismo uzeli u obzir i socijalni identitet slušatelja. Da bismo potvrdili ovu ideju, koristili smo spol kao tipični primjer socijalne promjene kako bi istražili kako identitet slušatelja utjeca na jezik korišteni u kineskim dijalogima na društvenim medijima. Također, mi gradimo personalizirane generatore. Rezultati eksperimenta pokazuju da je identitet slušača zaista bitan u upotrebi jezika odgovora i da generator odgovora može uhvatiti takve razlike u upotrebi jezika. Zanimljivije je, dodatno modelirajući identitet slušača, generator ličnog odgovora bolje obavlja u vlastitom identitetu.', 'nl': 'Gepersonaliseerde responsgeneratie maakt het mogelijk om menselijke reacties te genereren door de generator een sociale identiteit toe te wijzen. De pragmatische theorie suggereert echter dat mensen de manier van spreken aanpassen op basis van niet alleen wie ze zijn, maar ook met wie ze praten. Met andere woorden, bij het modelleren van gepersonaliseerde dialogen kan het gunstig zijn als we ook rekening houden met de sociale identiteit van de luisteraar. Om dit idee te valideren, gebruiken we gender als typisch voorbeeld van een sociale variabele om te onderzoeken hoe de identiteit van de luisteraar de taal beïnvloedt die wordt gebruikt in Chinese dialogen op sociale media. Ook bouwen we gepersonaliseerde generatoren. De experimentresultaten tonen aan dat de identiteit van de luisteraar inderdaad belangrijk is bij het taalgebruik van antwoorden en dat de responsgenerator dergelijke verschillen in taalgebruik kan vastleggen. Nog interessanter is dat door de identiteit van de luisteraar extra te modelleren, de gepersonaliseerde responsgenerator beter presteert in zijn eigen identiteit.', 'de': 'Die personalisierte Response Generation ermöglicht es, menschenähnliche Antworten zu generieren, indem dem Generator eine soziale Identität zugewiesen wird. Die pragmatische Theorie legt jedoch nahe, dass Menschen die Art des Sprechens nicht nur darauf abstimmen, wer sie sind, sondern auch mit wem sie sprechen. Mit anderen Worten, bei der Modellierung personalisierter Dialoge könnte es vorteilhaft sein, wenn wir auch die soziale Identität des Zuhörers berücksichtigen. Um diese Idee zu validieren, verwenden wir Gender als typisches Beispiel für eine soziale Variable, um zu untersuchen, wie die Identität des Zuhörers die Sprache beeinflusst, die in chinesischen Dialogen in sozialen Medien verwendet wird. Außerdem bauen wir personalisierte Generatoren. Die experimentellen Ergebnisse zeigen, dass die Identität des Zuhörers beim Sprachgebrauch von Antworten tatsächlich von Bedeutung ist und dass der Antwortgenerator solche Unterschiede im Sprachgebrauch erfassen kann. Interessanter ist, dass der personalisierte Response-Generator, der zusätzlich die Identität des Hörers modelliert, in seiner eigenen Identität besser abschneidet.', 'ko': '개성화된 응답 생성은 생성기에 사회적 신분을 분배함으로써 유사한 인류의 응답을 생성한다.그러나 어용학 이론에 따르면 인류는 자신이 누구인지뿐만 아니라 누구와 이야기를 나누느냐에 따라 말투를 조정한다.개성화된 대화를 모의할 때 우리도 청자의 사회적 신분을 고려하면 유리할 수 있다는 얘기다.이러한 관점을 검증하기 위해 우리는 성별을 사회 변수의 전형적인 예로 삼아 청자의 신분이 소셜 미디어에서 중국어 대화에서 사용하는 언어에 어떻게 영향을 미치는지 연구할 것이다.이 밖에 우리는 개성화된 발전기도 생산한다.실험 결과 청자의 신분은 확실히 언어 사용에서 중요한 역할을 하는데 반응 생성기는 언어 사용에서의 이러한 차이를 포착할 수 있다.더욱 흥미로운 것은 청자의 신분에 대한 추가 모델링을 통해 개성화된 응답 생성기가 자신의 신분에서 더욱 잘 나타난다는 것이다.', 'id': "Generasi respon pribadi memungkinkan menghasilkan respon seperti manusia dengan mengatur generator identitas sosial. Namun, teori pragmatik menunjukkan bahwa manusia menyesuaikan cara berbicara berdasarkan bukan hanya siapa mereka tapi juga dengan siapa mereka berbicara. Dengan kata lain, ketika memmodelir dialog pribadi, mungkin lebih baik jika kita juga mempertimbangkan identitas sosial pendengar. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener's identity influences the language used in Chinese dialogues on social media.  Juga, kami membangun generator pribadi. Hasil eksperimen menunjukkan bahwa identitas pendengar benar-benar penting dalam penggunaan bahasa respon dan bahwa generator respon dapat menangkap perbedaan dalam penggunaan bahasa. Lebih menarik, dengan menambahkan model identitas pendengar, generator respon pribadi bekerja lebih baik dalam identitasnya sendiri.", 'fa': 'نسل پاسخ شخصی به تولید جواب مانند انسان به وسیله تعیین کردن ژنراتور هویت اجتماعی توان می\u200cدهد. ولی تئوری پراگرماتیک پیشنهاد می\u200cدهد که انسان\u200cها راه صحبت را بر اساس نه تنها کسانی که هستند، بلکه همچنین با کسانی که دارند صحبت می\u200cکنند تغییر می\u200cدهند. به عبارت دیگر، هنگامی که نمونه\u200cسازی گفتگوهای شخصی می\u200cشود، ممکن است اگر ما هویت اجتماعی گوش دهنده را در نظر بگیریم. برای تایید کردن این ایده، ما از جنس به عنوان مثال معمولی از یک متغیر اجتماعی استفاده می کنیم تا تحقیق کنیم که چگونه هویت گوش دهنده چگونه به زبانی که در گفتگوهای چینی در رسانه های اجتماعی استفاده می شود تأثیر می دهد. همچنین ما ژنراتور شخصی ساختیم. نتیجه آزمایش نشان می دهد که هویت گوش دهنده واقعاً در استفاده از زبان جواب اهمیت دارد و که ژنراتور پاسخ می تواند چنین تفاوت در استفاده از زبان بگیرد. علاقه\u200cمند تر از این، با نمونه\u200cبندی هویت گوش\u200cدهنده، ژنراتور پاسخ شخصی بهتر در هویت خودش انجام می\u200cدهد.', 'af': "Personaliseerde reaksie genereer die genereering van menslike reaksies deur die genereerder 'n sosiale identiteit te wys. Maar pragmatike teorie beveel dat mense die manier van praat wat gebaseer is nie alleen op wie hulle is nie, maar ook met wie hulle praat. In ander woorde, wanneer persoonlike dialoog modelleer, dit dalk moontlik wees as ons ook die luister se sosiale identiteit in aandag neem. Om hierdie idee te bevestig, gebruik on s gender as 'n tipiese voorbeeld van 'n sosiale veranderlike om te ondersoek hoe die luister se identiteit influens die taal wat gebruik word in Sjinese dialoog op sosiale media. Ons bou ook persoonlike genereerders. Die eksperiment resultate bevestig dat die luister se identiteit werklik saak in die taal gebruik van antwoord en dat die antwoord genereerder sodanige verskilde in taal gebruik kan opneem. Meir interessant, deur addisionele modellering van die luister se identiteit, doen die persoonlike reaksgenerator beter in sy eie identiteit.", 'sw': 'Kizazi cha kujibu binafsi kinawezesha kutengeneza majibu kama binadamu kwa njia ya kumweka muundo utambulisho wa kijamii. Hata hivyo, nadharia ya uongozi inapendekeza kuwa binadamu wanakubadilisha njia ya kuongea kwa msingi tu na siyo tu wale tu ambao wanazungumza nao pia. Kwa maneno mengine, pale mazungumzo ya watu binafsi, inaweza kuwa ni vizuri kama pia tutachukua utambulisho wa kijamii wa msikilizaji kuchukua hatua. Ili kuthibitisha wazo hili, tunatumia jinsia kama mfano wa kawaida wa mabadiliko ya kijamii ili kuchunguza jinsi utambulisho wa msikilizaji unavyoathiri lugha inayotumiwa katika mazungumzo ya Kichina kwenye mitandao ya kijamii. Pia, tunajenga vizazi binafsi. Matokeo hayo yanaonyesha kwamba utambulisho wa msikilizaji kwa hakika ni muhimu katika matumizi ya lugha na kwamba mtengenezaji wa majibu anaweza kukuta tofauti kama hizo kwa kutumia lugha. Cha kushangaza zaidi, kwa kuonyesha utambulisho wa msikilizaji, mtengenezaji wa kujibu binafsi anafanya vizuri katika utambulisho wake mwenyewe.', 'tr': 'Şahsy jogabat jeneraly adam ýaly jogaplary döredip, jenerator jemgyýet tanyşyny bejermek üçin mümkin edýär. Ýöne pragmatik teoriýasy adamlaryň diňe özüniň kim diňe gürleýänlerine daýanýar diýip gürleýänlerine daýanýar diýip düşünýär. Başga s özler bolsa, şahsy dialoglary görkezilýände, diňleýän adamlaryň sosyal kimligine göz öňüne almak üçin has gowy bolar. Bu ideýany takyklamak üçin, cinsiýany sosial üýtgeşiginiň örän görnüşi bolup diňleýän adamlaryň sosial mediýalarda Çin çe dialoglarda ullanýan diline nähili täsirleýändigini soramak üçin ullanýarys. Şahsy şekilde kişisel jeneratörler inşa edýäris. Testiň netijesi diňleýän diňleýäniň tanyşynyň dilinde jogaplaryň ullanyşynyň hakykatdanam möhüm bolandygyny we jogaplaryň döredicisiniň dilde üýtgeşiklerini tutup biler. Diňleýän adamyň kimligini daýalpak bilen şahsy jogabat jeneratöri öz kimligine has gowy dowam edýär.', 'sq': "Gjenerimi i personalizuar i përgjigjeve mundëson krijimin e përgjigjeve njerëzore nëpërmjet caktimit të gjeneratorit një identiteti shoqëror. Megjithatë, teoria e pragmatikës sugjeron se qeniet njerëzore rregullojnë mënyrën e të folurit bazuar jo vetëm në se kush janë, por gjithashtu me kë janë duke folur. In other words, when modelling personalised dialogues, it might be favourable if we also take the listener's social identity into consideration.  Për të vlerësuar këtë ide, ne përdorim gjininë si një shembull tipik të një ndryshuese sociale për të hetuar se si identiteti i dëgjuesit ndikon në gjuhën e përdorur në dialogun kinez në mediat sociale. Gjithashtu, ne ndërtojmë gjeneratorë personalizuar. Rezultatet e eksperimentit tregojnë se identiteti i dëgjuesit ka rëndësi në përdorimin e gjuhës të përgjigjeve dhe se gjeneratori i përgjigjeve mund të kapë dallime të tilla në përdorimin e gjuhës. Më interesante, duke modeluar në mënyrë shtesë identitetin e dëgjuesit, gjeneratori i përgjigjes personalizuar funksionon më mirë në identitetin e vet.", 'am': "የግል መልስ ትውልድ የሰው ብጤ መልስ ማህበራዊ ማኅበራዊ identity በመፍጠር ይችላል፡፡ ነገር ግን አካባቢ ታሪክ ሰዎች የሚናገሩት ሰዎች ብቻ ናቸው እንጂ የሚናገሩት ብቻ አይደለም፡፡ በሌላ ቃል፣ የጆሮውን ማኅበራዊ identity እና ማኅበራዊ ማኅበራዊ ማኅበራዊ መብት እናስብ እንደሆነ ይሻላል፡፡ ይህንን አሳብ ለማስተካከል፣ የጆሮው ግንኙነት በቻይና በማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበራዊ ማኅበረሰብ ላይ እንዴት እንደሚጠቅመው እናሳውቃለን፡፡ ደግሞም የራሳቸውን አዲስ ፍጥረት እንሠራለን:: ፈተናው ፍጻሜው የጆሮው ግንኙነት የድምፅ መልዕክቶች በመጠቀም ቋንቋ የሚያስፈልገው ነው፡፡ More interestingly, by additionally modelling the listener's identity, the personalised response generator performs better in its own identity.", 'hy': 'Հանձնական արձագանքի սերունդը հնարավորություն է տալիս ստեղծել մարդկային նման արձագանքներ, սերունդը հասարակական ինքնություն տալով: Այնուամենայնիվ, պրագմատիկայի տեսությունը ցույց է տալիս, որ մարդիկ հարմարեցնում են խոսքի ձևը, հիմնված ոչ միայն նրանց մասին, այլ նաև նրանց հետ, ում հետ խոսում են: Այլ կերպ ասած, անձնական հաղորդագրությունների մոդելավորման ժամանակ կարող է օգտակար լինել, եթե նաև հաշվի առնենք լսողի սոցիալական ինքնությունը: Այս գաղափարը հաստատելու համար մենք օգտագործում ենք գենդերը որպես սոցիալական փոփոխականի բնորոշ օրինակ, որպեսզի ուսումնասիրենք, թե ինչպես է լսողի ինքնությունը ազդում սոցիալական լրատվամիջոցներում օգտագործվող չինական խոսակցությունների Մենք նաև կառուցում ենք անձնական գեներատորներ: Փորձարկման արդյունքները ցույց են տալիս, որ լսողի ինքնությունը իսկապես կարևոր է արձագանքների լեզվի օգտագործման մեջ, և որ արձագանքի գեներատորը կարող է ընկալել լեզվի օգտագործման այդպիսի տարբերությունները: Ավելի հետաքրքիր է, լսողի ինքնությունը նաև մոդելավորելով, անձնական արձագանքի գեներատորը ավելի լավ է աշխատում իր ինքնության մեջ:', 'bn': "ব্যক্তিগত প্রজন্ম মানুষের মতো প্রতিক্রিয়া তৈরি করে জেনারেটরের একটি সামাজিক পরিচয় বানিয়ে দেয়ার মাধ্যমে। তবে প্রাক্ম্যামেক্টিক তত্ত্বাবধানে পরামর্শ দেয় যে মানুষ ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিতে কথা বলার অন্য কথায়, যখন মডেলিং ব্যক্তিগত আলোচনার মাধ্যমে আমরা শোনার সামাজিক পরিচয় বিবেচনা করি তখন এটা ভালো হতে পারে। এই চিন্তাটি বৈধ করার জন্য আমরা একটি সামাজিক পরিবর্তনের উদাহরণ হিসেবে লিঙ্গ ব্যবহার করি তদন্ত করার জন্য যে কিভাবে শ্রবণকারীর পরিচয় চীনা ডায়ালগেল এছাড়াও, আমরা ব্যক্তিগত জেনারেটর বানাই। পরীক্ষার ফলাফল দেখাচ্ছে যে শ্রবণকারীর পরিচয় সত্যিই ভাষায় প্রতিক্রিয়া ব্যবহার করার ব্যাপারে গুরুত্বপূর্ণ এবং এই প্রতিক্রিয়া জ More interestingly, by additionally modelling the listener's identity, the personalised response generator performs better in its own identity.", 'az': 'ŇěahsiyleŇüdirilmiŇü cavab n…ôsili insana b…ônz…ôr cavab ver…ô bil…ôr ki, generator a sosial kimlik verm…ôk vasit…ôsil…ô. Ancaq pragmatik teorisi insanlarńĪn danńĪŇümaq yolunu yalnńĪz kimi deyil, kimi d…ô danńĪŇüńĪrlar. BaŇüqa s √∂zl…ôr…ô, kiŇüisel dialoglarńĪ modell…ôy…ôrk…ôn, dinl…ôy…ônl…ôrin sosyal kimlińüini d…ô g√∂zl…ôyirik. Bu fikrini t…ôsdiql…ôm…ôk √ľ√ß√ľn, biz cinsini sosyal d…ôyiŇüiklik m…ôs …ôlin…ô istifad…ô edirik ki, dinl…ôy…ônl…ôrin kimlińüin in sosyal medya dill…ôrind…ô √áin dill…ôrind…ô istifad…ô edil…ôn dill…ôrin nec…ô etkisini incidir. H…ôm√ßinin kiŇüisel generat√∂rl…ôr inŇüa edirik. H…ôqiq…ôt…ôn, t…ôcr√ľb…ô sonu√ßlarńĪ dinl…ôy…ônl…ôrin kimlińüin in cavab verilm…ôsi dill…ôrin istifad…ôsind…ô m√∂vcuddur v…ô cavab generat√∂r√ľ dill…ôrin istifad…ôsind…ô b√∂y√ľk f…ôrqliyi yakalaya bil…ôr. Daha maraqlńĪ olaraq, qulaqlarńĪn kimlińüini daha √ßox modell…ôŇüdir…ôr…ôk, kiŇüisel cavab generat√∂r√ľ √∂z kimlińüind…ô daha yaxŇüńĪ iŇül…ôr edir.', 'bs': 'Generacija osobnog odgovora omogućava stvaranje reakcija poput ljudskih ljudi pomoću određivanja generator a socijalnog identiteta. Međutim, pragmatička teorija predlaže da ljudska bića prilagođuju način govora na temelju ne samo sa onim s kim su, već i sa kim razgovaraju. Drugim riječima, kad modeliramo personalizovane dijaloge, moglo bi biti dobrodošlo ako bismo uzeli u obzir i socijalni identitet slušača. Da bismo potvrdili ovu ideju, koristili smo spol kao tipični primjer socijalne promjene kako bi istražili kako identitet slušatelja utjeca na jezik koji se koristi u kineskim dijalogima na društvenim medijima. Također, mi gradimo personalizovane generatore. Rezultati eksperimenta pokazuju da je identitet slušača zaista bitan u upotrebi jezika odgovora i da generator odgovora može uhvatiti takve razlike u upotrebi jezika. Zanimljivije je, dodatno modelirajući identitet slušaoca, generator ličnog odgovora bolje izvršava u sopstvenom identitetu.', 'ca': "La generació de respostes personalitzades permet generar respostes similars a l'humà assenyant al generador una identitat social. Però la teoria de la pragmàtica suggereix que els éssers humans ajusten la manera de parlar basant-se no només en qui són, sinó també amb qui parlen. En altres paraules, quan modelem diàlegs personalitzats, podria ser favorable tenir en compte la identitat social de l'escoltant. Per validar aquesta idea, utilitzem el gènere com un exemple típic d'una variable social per investigar com la identitat de l'escoltant influeix en la llengua utilitzada en els diàlegs xinesos en els mitjans social s. També construïm generadors personalitzats. Els resultats de l'experiment demostren que la identitat de l'escoltant importa realment en l'ús del llenguatge de les respostes i que el generador de respostes pot capturar aquestes diferències en l'ús del llenguatge. Encara més interessant, modelant addicionalment la identitat de l'escoltant, el generador de resposta personalitzat actua millor en la seva pròpia identitat.", 'cs': 'Personalizované generování reakcí umožňuje generování lidských reakcí prostřednictvím přiřazení generátoru sociální identity. Pragmatická teorie však naznačuje, že lidské bytosti upravují způsob mluvení nejen na základě toho, kdo jsou, ale také s kým mluví. Jinými slovy, při modelování personalizovaných dialogů by mohlo být příznivé, kdybychom zohlednili také sociální identitu posluchače. K ověření této myšlenky používáme gender jako typický příklad sociální proměnné, abychom zkoumali, jak identita posluchače ovlivňuje jazyk používaný v čínských dialogech na sociálních médiích. Také vyrábíme individuální generátory. Výsledky experimentů ukazují, že identita posluchače skutečně záleží na jazykovém používání odpovědí a že generátor odpovědí dokáže zachytit tyto rozdíly v jazykovém používání. Ještě zajímavější je, že generátor personalizované odezvy navíc modelováním identity posluchače funguje lépe ve své vlastní identitě.', 'et': 'Personaliseeritud reageerimise genereerimine võimaldab genereerida inimlikke reageerimisi, andes generaatorile sotsiaalse identiteedi. Pragmaatika teooria näitab siiski, et inimesed kohandavad rääkimisviisi mitte ainult sellest, kes nad on, vaid ka sellest, kellega nad räägivad. Teisisõnu, isikupärastatud dialoogi modelleerimisel oleks soodne arvestada ka kuulaja sotsiaalse identiteediga. Selle idee kinnitamiseks kasutame soo tüüpilise sotsiaalse muutuja näitena, et uurida, kuidas kuulaja identiteet mõjutab hiina dialoogides sotsiaalmeedias kasutatavat keelt. Samuti ehitame personaalseid generaatoreid. Eksperimenti tulemused näitavad, et kuulaja identiteet on tõepoolest oluline vastuste keelekasutuses ja et vastusegeneraator suudab selliseid erinevusi keelekasutuses tabada. Veelgi huvitavam on, et lisaks kuulaja identiteedi modelleerimisele toimib isikupärastatud reageerimise generaator paremini oma identiteedis.', 'fi': 'Henkilökohtainen vastegeneraatio mahdollistaa ihmisen kaltaisten vastausten tuottamisen antamalla generaattorille sosiaalisen identiteetin. Pragmaattisen teorian mukaan ihmiset muuttavat puhetapaa sen perusteella, kuka he ovat, mutta myös kenelle he puhuvat. Toisin sanoen personoituja dialogeja mallinnettaessa voisi olla suotuisaa ottaa huomioon myös kuuntelijan sosiaalinen identiteetti. Tämän idean validoimiseksi käytämme sukupuolta tyypillisenä esimerkkinä sosiaalisesta muuttujasta selvittääksemme, miten kuulijan identiteetti vaikuttaa kiinalaisessa dialogissa sosiaalisessa mediassa käytettyyn kieleen. Rakennamme myös yksilöllisiä generaattoreita. Kokeilutulokset osoittavat, että kuuntelijan identiteetillä on todellakin merkitystä vastausten kielenkäyttössä ja että vastegeneraattori pystyy vangitsemaan tällaiset erot kielenkäyttössä. Mielenkiintoisempaa on, että myös kuuntelijan identiteettiä mallintamalla personoitu vastegeneraattori suoriutuu paremmin omassa identiteetissään.', 'jv': 'Perusahaan responsing kang dipunanggunaké iso nggawe responsaké sing mengko usul sing nganggep nggawe barang sampeyan tambahan. Nanging, theoriya pragattiki sing ngerasara supoyo wong liyané uwong nggawe barang-bakal sing nyimpen apik dhéwé sapa dhèwèké iki dadi apik dhèwèké bakal terusaha bakal terusaha winih. Wurung-wurung liya, pas iku model dialog perusahaan, iso dianggap nek awak dhéwé buturan kanggo sampek kang sampek. Ngawe ngubah akeh sing paling iki, kita ngubah géneru nganggep sistem sing perusahaan anyar tentang kanggo tukang kapan sampeyan nguasai perusahaan kanggo nggunakake tresnane kanggo nglanga langa sing isin kanggo nggalakno Pangan Sak Jaakan online. Mangkin, awake dhewe nggawe jiner-jiner perusahaan Ing arnong sing paling nggambar sapa-winih kanggo sampeyan luwih dumadhi iki ning langga iso nggambar barang karo winih sing arep maneh Iking langgar, nambah nambah layang sampeyan sampeyan liyané perusahaan, ngirim weruh sing luwih apik sing luwih apik.', 'sk': 'Prilagojena generacija odzivov omogoča ustvarjanje človeku podobnih odzivov z dodelitvijo generatorja družbene identitete. Vendar pragmatična teorija kaže, da ljudje prilagajajo način govora, ne samo glede na to, kdo so, ampak tudi s kom govorijo. Z drugimi besedami, pri modeliranju individualnih dialogov bi bilo morda ugodno, če upoštevamo tudi poslušalcevo socialno identiteto. Za potrditev te ideje uporabljamo spol kot tipičen primer družbene spremenljivke, da raziščemo, kako identiteta poslušalca vpliva na jezik, ki se uporablja v kitajskih dialogih na družbenih omrežjih. Izdelujemo tudi individualne generatorje. Rezultati eksperimenta kažejo, da je identiteta poslušalca resnično pomembna pri jezikovni uporabi odzivov in da lahko generator odzivov zajame take razlike v uporabi jezika. Še bolj zanimivo je, da z dodatnim modeliranjem identitete poslušalca osebni generator odzivov bolje deluje v lastni identiteti.', 'ha': "Kijan jibar da ɗabi'a, yana yarda ya ƙara masu kama da mutum, game da ya raba wani shawarar jami. Kayya, teori na lafaƙo yana madaidaitar da mutane a kan faɗi, ba da wanda kawai suke faɗa da shi ba. In da wasu kalmõmi, idan misalin zauren akwatin bayani na da ɗabi'a, akwai amfani idan an sami shaidar saurãre da shi a kan ka yi bincike. Yana amfani da mazan aiki kamar misali mai jama'a, dõmin mu yi amfani da mazan aiki a matsayin mutane dõmin ka tambayi yadda shaidar mai saurãre zai yi amfani da harshen wanda ke cikin zauren akwatin China a kan mita jami. Kayya, muna samar da zayen mutane. Matarin jarrabai ya nuna cewa shaidar mai saurãre yana da muhimmi cikin amfani da misalin maganar mai saurarwa, kuma zaɓen mai jibarwa yana iya kãma diffukan su cikin amfani da harshe. Ina son amfani da, a sami misalin shaidar mai saurãre, zaɓen mai amfani da matsayin saurari na da amfani da shi.", 'he': 'דור תגובה אישי מאפשר ליצור תגובות דומות לאדם באמצעות ההזדמנות של הגנרטור זהות חברתית. בכל אופן, תיאוריית הפרגמטיקה מצביעה שבני אדם מתאימים את הדרך לדבר בהתבסס לא רק על מי הם, אלא גם על מי הם מדברים. במילים אחרות, כאשר לדוגמא דיאלוגים אישיים, זה עלול להיות מועיל אם ניקח גם את הזהות החברתית של המקשיב בחשבון. כדי לאשר את הרעיון הזה, אנו משתמשים במין כדוגמא טיפוסית של משתנה חברתית כדי לחקור איך זהותו של המקשיב משפיעה על השפה השתמשת בדיולוגים סינים על תקשורת חברתית. בנינו גם גנרטורים אישיים. תוצאות הניסויים מראות שהזהות של המקשיב באמת חשובה בשפה השימוש של תגובות ושגנרטור התגובה יכול לתפוס הבדלים כאלה בשימוש בשפה. מעניין יותר, על ידי דגם נוסף זהותו של המקשיב, גנרטור התגובה האישי מופע טוב יותר בזהותו.', 'bo': 'རང་ཉིད་ཀྱི་རྒུལ་གཤིས་ལན་གསལ་བཤད་ཀྱི་མི་རྣམས་དང་མི་རྣམས་ལ་གནོད་པ་ཞིག་བཟོ་བཅུག་པ འོན་ཀྱང་། ལུས་བྱ་ཚིག་གཞུང་གིས་མི་རྣམས་ལས་ཁོང་ཚོས་གང་འདྲ་བྱེད་པའི་ཐབས་ལམ་ལྟར་བཟོ་བཅོས་བྱེད་ཀྱི་ཡོད། མ་ཟད་གཞན་ཞིག་གིས་མིར་བཟོ་བྱེད་པའི་ཌའི་ལོག་བློ་གཏོང་སྐབས་ན། ང་ཚོས་ཉན་མཁན་གྱི་སྤྱི་ཚོགས་འབྲེལ་མི་འདྲ་བ་དེ་བས འདི་ལྟ་བུ་ཞིབ་བཟོ་བྱས་ན། ང་ཚོས་མི་དང་མི་རིགས་འདི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་འགྱུར་བའི་དཔེ་བརྗོད་ཞིག་ལ་བལྟ་བྱེད་པའི་རྣམ ད་དུང་། ང་ཚོས་སྒེར་གྱི་ཆ་འཕྲིན་པ་ཇུས་གཏོང་བྱེད་ཀྱི་ཡོད། བརྟག་ཞིག་གི་གནད་དོན་འབྲུའི་ནང་དུ་ཉན་པའི་མིང་ཚོགས་དངོས་ཐུབ་སྐད་ཡིག འདི་ལས་འཕར་ཚུལ་ཆེ་བ་དེ་ནི་ཉན་མཁན་པའི་མིང་ཚུལ་རྣམས་ལས་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Schema-Guided Natural Language Generation', 'es': 'Generación de lenguaje natural guiada por esquemas', 'pt': 'Geração de linguagem natural guiada por esquema', 'fr': 'Génération de langage naturel guidée par des schémas', 'ar': 'توليد اللغة الطبيعية الموجه بالمخطط', 'ja': 'スキーマ指導型自然言語生成', 'zh': '架构导自然语言成', 'hi': 'स्कीमा-निर्देशित प्राकृतिक भाषा जनरेशन', 'ru': 'Генерация естественного языка на основе схемы', 'ga': 'Giniúint Teanga Nádúrtha Treoraithe Scéimre', 'el': 'Δημιουργία φυσικής γλώσσας με καθοδήγηση σχήματος', 'hu': 'Schema-vezérelt természetes nyelv generálása', 'it': 'Generazione del linguaggio naturale guidata da schemi', 'kk': 'Сұлба бағытталған табиғи тілді құру', 'mk': 'Schema-Guided Natural Language Generation', 'ka': 'Name', 'ms': 'Penjanaan Bahasa Alami Dipandang Skema', 'ml': 'സ്കീമ- വഴികാട്ടിയുള്ള സ്വാഭാവിക ഭാഷയുടെ ജനിപ്പി', 'mt': 'Ġenerazzjoni tal-Lingwa Naturali mmexxija mill-Iskema', 'mn': 'Схема-удирдлагатай байгалийн хэл үүсгэн', 'no': 'Generering av naturspråk med oppsett', 'pl': 'Generowanie języka naturalnego kierowanego schematem', 'lt': 'Schema-Guided Natural Language Generation', 'ro': 'Generarea limbajului natural ghidat pe schemă', 'sr': 'Generacija prirodnog jezika na šemu', 'si': 'Name', 'so': 'Schema-Guided Natural Language Generation', 'sv': 'Schemastyrd generering av naturligt språk', 'ta': 'திட்டம்- வழிகாட்டப்பட்ட இயல்பான மொழி உருவாக்கம்', 'ur': 'اسکیم-ہدایت کی طبیعی زبان پیدائش', 'uz': 'Name', 'vi': 'Hệ thống ngôn ngữ tự động', 'bg': 'Генериране на естествен език, ръководен от схема', 'da': 'Schema-Guided Natural Language Generation', 'nl': 'Schema-geleide natuurlijke taalgeneratie', 'hr': 'Generacija prirodnog jezika na šemu', 'de': 'Schema-gesteuerte Erzeugung natürlicher Sprache', 'ko': '패턴 안내의 자연 언어 생성', 'id': 'Generasi Bahasa Alam Dipandang Skema', 'fa': 'نسخه زبان طبیعی راهنمایی به نقشه', 'sw': 'Uzalishaji wa lugha ya asili', 'tr': 'Natal Dili janlaşdyrma', 'sq': 'Gjenerimi i gjuhës natyrore i udhëzuar nga skema', 'af': 'Skema- gids Natuurlike Taal Generasie', 'hy': 'Սխեմայի ուղղությամբ բնական լեզուների ստեղծումը', 'am': 'የተለመደው ዕይታ', 'bn': 'স্কীম- পরিচালিত স্বাভাবিক ভাষা প্রজন্ম', 'az': 'Ňěema-hiday…ôt t…ôbi…ôtli Dil √únvanńĪ', 'ca': 'Generació de llenguatges naturals orientada per esquema', 'bs': 'Generacija prirodnog jezika na šemu', 'cs': 'Generování přirozeného jazyka řízeného schématem', 'et': 'Skeemipõhine looduskeele genereerimine', 'fi': 'Schema-ohjattu luonnollisen kielen luominen', 'jv': 'Generasi Language Daerahing', 'sk': 'Ustvarjanje naravnega jezika po shemi', 'ha': 'KCharselect unicode block name', 'he': 'יצירת שפות טבעיות מונחת במערכת', 'bo': 'Schema-Guided Natural Language Generation'}
{'en': 'Neural network based approaches to data-to-text natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation. To facilitate the training of neural network models, researchers created large datasets of paired utterances and their meaning representations. However, the creation of such datasets is an arduous task and they mostly consist of simple meaning representations composed of slot and value tokens to be realized. These representations do not include any contextual information that an NLG system can use when trying to generalize, such as domain information and descriptions of slots and values. In this paper, we present the novel task of Schema-Guided Natural Language Generation (SG-NLG). Here, the goal is still to generate a natural language prompt, but in SG-NLG, the input MRs are paired with rich schemata providing contextual information. To generate a dataset for SG-NLG we re-purpose an existing dataset for another task : dialog state tracking, which includes a large and rich schema spanning multiple different attributes, including information about the domain, user intent, and slot descriptions. We train different state-of-the-art models for neural natural language generation on this dataset and show that in many cases, including rich schema information allows our models to produce higher quality outputs both in terms of semantics and diversity. We also conduct experiments comparing model performance on seen versus unseen domains, and present a human evaluation demonstrating high ratings for overall output quality.', 'ar': 'اكتسبت المناهج القائمة على الشبكة العصبية لتوليد اللغة الطبيعية من البيانات إلى النص (NLG) شعبية في السنوات الأخيرة ، بهدف إنشاء موجه لغة طبيعية يحقق تمثيلاً لمعنى الإدخال بدقة. لتسهيل تدريب نماذج الشبكة العصبية ، أنشأ الباحثون مجموعات بيانات كبيرة من الكلام المقترن وتمثيلاتها المعنى. ومع ذلك ، فإن إنشاء مجموعات البيانات هذه مهمة شاقة وتتكون في الغالب من تمثيلات بسيطة للمعنى تتكون من الفتحات ورموز القيمة التي يجب تحقيقها. لا تتضمن هذه التمثيلات أي معلومات سياقية يمكن أن يستخدمها نظام NLG عند محاولة التعميم ، مثل معلومات المجال وأوصاف الفتحات والقيم. في هذا البحث ، نقدم مهمة جديدة لتوليد اللغة الطبيعية الموجه بالمخطط (SG-NLG). هنا ، لا يزال الهدف هو إنشاء موجه لغة طبيعية ، ولكن في SG-NLG ، يتم إقران مدخلات MRs بمخططات غنية توفر معلومات سياقية. لإنشاء مجموعة بيانات لـ SG-NLG ، نقوم بإعادة تعيين مجموعة بيانات موجودة لمهمة أخرى: تتبع حالة الحوار ، والذي يتضمن مخططًا كبيرًا وغنيًا يمتد على العديد من السمات المختلفة ، بما في ذلك معلومات حول المجال وهدف المستخدم وأوصاف الفتحات. نقوم بتدريب مختلف النماذج الحديثة لتوليد اللغة الطبيعية العصبية على مجموعة البيانات هذه ونبين أنه في كثير من الحالات ، بما في ذلك معلومات المخطط الغنية ، تسمح لنماذجنا بإنتاج مخرجات عالية الجودة من حيث الدلالات والتنوع.\nنجري أيضًا تجارب تقارن أداء النموذج على المجالات المرئية مقابل المجالات غير المرئية ، ونقدم تقييمًا بشريًا يوضح درجات عالية لجودة المخرجات الإجمالية.', 'ja': 'データ対テキスト自然言語生成（ ＮＬＧ ）に対するニューラルネットワークベースのアプローチは、入力意味表現を正確に実現する自然言語プロンプトを生成することを目標として、近年人気を博している。 ニューラルネットワークモデルのトレーニングを容易にするために、研究者は対の発話とその意味表現の大規模なデータセットを作成した。 しかし、そのようなデータセットの作成は困難な作業であり、それらはほとんどの場合、実現されるスロットトークンとバリュートークンで構成される単純な意味表現で構成されています。 これらの表現は、ドメイン情報、スロットおよび値の説明など、一般化しようとするときにＮＬＧシステムが使用することができるいかなる文脈情報も含まない。 本稿では，スキーマ指導型自然言語生成（ SG - NLG ）の新規課題を紹介する． ここでは、まだ自然言語プロンプトを生成することを目標としていますが、SG - NLGでは、入力MRはコンテキスト情報を提供する豊富なスキーマとペアになっています。 SG - NLGのデータセットを生成するには、既存のデータセットを別のタスクに再利用します。ダイアログの状態トラッキングには、ドメイン、ユーザーの意図、スロットの説明など、複数の異なる属性にわたる大規模で豊富なスキーマが含まれます。 私たちは、このデータセット上でニューラル自然言語生成のためのさまざまな最先端モデルをトレーニングし、多くの場合、豊富なスキーマ情報を含む私たちのモデルは、意味論と多様性の両方でより高品質の出力を生成することができることを示します。\nまた、見えている領域と見えていない領域のモデル性能を比較する実験を行い、全体的な出力品質に対する高い評価を示す人間評価を提示します。', 'es': 'Los enfoques basados en redes neuronales para la generación de lenguaje natural (NLG) de datos a texto han ganado popularidad en los últimos años, con el objetivo de generar un mensaje de lenguaje natural que realice con precisión una representación del significado de entrada. Para facilitar el entrenamiento de los modelos de redes neuronales, los investigadores crearon grandes conjuntos de datos de expresiones emparejadas y sus representaciones de significados. Sin embargo, la creación de tales conjuntos de datos es una tarea ardua y en su mayoría consisten en representaciones de significado simples compuestas de fichas de ranura y valor para ser realizadas. Estas representaciones no incluyen ninguna información contextual que un sistema NLG pueda utilizar al intentar generalizar, como información de dominio y descripciones de ranuras y valores. En este artículo, presentamos la novedosa tarea de la Generación de Lenguaje Natural Guiada por Esquemas (SG-NLG). En este caso, el objetivo sigue siendo generar un mensaje de lenguaje natural, pero en SG-NLG, los MR de entrada se combinan con esquemas enriquecidos que proporcionan información contextual. Para generar un conjunto de datos para SG-NLG, reutilizamos un conjunto de datos existente para otra tarea: el seguimiento del estado del diálogo, que incluye un esquema amplio y rico que abarca varios atributos diferentes, incluida la información sobre el dominio, la intención del usuario y las descripciones de las ranuras. Entrenamos diferentes modelos de vanguardia para la generación de lenguaje natural neuronal en este conjunto de datos y demostramos que, en muchos casos, la inclusión de información de esquemas enriquecida permite a nuestros modelos producir resultados de mayor calidad tanto en términos de semántica como de diversidad.\nTambién realizamos experimentos que comparan el rendimiento del modelo en dominios visibles con los no vistos, y presentamos una evaluación humana que demuestra altas calificaciones para la calidad general de salida.', 'pt': 'Abordagens baseadas em redes neurais para geração de linguagem natural de dados para texto (NLG) ganharam popularidade nos últimos anos, com o objetivo de gerar um prompt de linguagem natural que realiza com precisão uma representação de significado de entrada. Para facilitar o treinamento de modelos de redes neurais, os pesquisadores criaram grandes conjuntos de dados de enunciados pareados e suas representações de significado. No entanto, a criação de tais conjuntos de dados é uma tarefa árdua e consiste principalmente em simples representações de significado compostas por slots e tokens de valor a serem realizados. Essas representações não incluem nenhuma informação contextual que um sistema NLG possa usar ao tentar generalizar, como informações de domínio e descrições de slots e valores. Neste artigo, apresentamos a nova tarefa de geração de linguagem natural guiada por esquema (SG-NLG). Aqui, o objetivo ainda é gerar um prompt de linguagem natural, mas no SG-NLG, os MRs de entrada são emparelhados com esquemas ricos que fornecem informações contextuais. Para gerar um conjunto de dados para SG-NLG, redirecionamos um conjunto de dados existente para outra tarefa: rastreamento de estado de diálogo, que inclui um esquema grande e rico abrangendo vários atributos diferentes, incluindo informações sobre o domínio, intenção do usuário e descrições de slot. Treinamos diferentes modelos de última geração para geração de linguagem natural neural neste conjunto de dados e mostramos que, em muitos casos, incluir informações ricas de esquema permite que nossos modelos produzam resultados de maior qualidade, tanto em termos de semântica quanto de diversidade.\nTambém realizamos experimentos comparando o desempenho do modelo em domínios visíveis versus não vistos e apresentamos uma avaliação humana demonstrando altas classificações para a qualidade geral da saída.', 'fr': "Les approches basées sur les réseaux neuronaux pour la génération de langage naturel (GNL) de données en texte ont gagné en popularité ces dernières années, dans le but de générer une invite de langage naturel qui réalise avec précision une représentation de signification d'entrée. Pour faciliter la formation de modèles de réseaux neuronaux, les chercheurs ont créé de grands ensembles de données d'énoncés appariés et de leurs représentations de signification. Cependant, la création de tels ensembles de données est une tâche ardue et ils consistent principalement en de simples représentations de signification composées de jetons d'emplacement et de valeur à réaliser. Ces représentations n'incluent aucune information contextuelle qu'un système de GNL peut utiliser lorsqu'il tente de généraliser, comme des informations de domaine et des descriptions de créneaux et de valeurs. Dans cet article, nous présentons la nouvelle tâche de génération de langage naturel guidée par les schémas (SG-NLG). Ici, l'objectif est toujours de générer une invite en langage naturel, mais dans SG-NLG, les MR d'entrée sont associés à des schémas riches fournissant des informations contextuelles. Pour générer un jeu de données pour SG-NLG, nous réaffectons un jeu de données existant pour une autre tâche\xa0: le suivi de l'état des boîtes de dialogue, qui inclut un schéma vaste et riche couvrant plusieurs attributs différents, y compris des informations sur le domaine, l'intention de l'utilisateur et des descriptions d'emplacements. Nous formons différents modèles de pointe pour la génération de langage naturel neuronal sur cet ensemble de données et montrons que, dans de nombreux cas, l'inclusion d'informations de schéma riches permet à nos modèles de produire des résultats de meilleure qualité tant en termes de sémantique que de diversité.\nNous menons également des expériences comparant les performances du modèle sur des domaines vus par rapport à des domaines non vus, et présentons une évaluation humaine démontrant des notes élevées pour la qualité globale de sortie.", 'ru': 'Нейронные сетевые подходы к генерации естественного языка (NLG) на основе данных в тексте за последние годы приобрели популярность с целью создания естественного языкового подсказки, которая точно реализует представление входного значения. Для облегчения обучения нейросетевых моделей исследователи создали большие наборы данных парных высказываний и их смысловых представлений. Однако создание таких наборов данных является трудной задачей, и они в основном состоят из простых представлений смысла, состоящих из слота и токенов ценности, которые должны быть реализованы. Эти представления не включают какую-либо контекстуальную информацию, которую система NLG может использовать при попытке обобщения, такую как информация о домене и описания слотов и значений. В этой статье мы представляем новую задачу Schema-Guided Natural Language Generation (SG-NLG). В данном случае цель по-прежнему заключается в создании подсказки на естественном языке, но в SG-NLG входные MR сопряжены с богатыми схемами, предоставляющими контекстную информацию. Для создания набора данных для SG-NLG мы повторно используем существующий набор данных для другой задачи: отслеживания состояния диалога, который включает в себя большую и богатую схему, охватывающую несколько различных атрибутов, включая информацию о домене, намерениях пользователя и описаниях слотов. Мы обучаем различные современные модели для генерации нейронных естественных языков на этом наборе данных и показываем, что во многих случаях, включая богатую схемную информацию, наши модели позволяют производить более качественные результаты как с точки зрения семантики, так и разнообразия.\nМы также проводим эксперименты по сравнению эффективности моделей в видимых и невидимых областях и представляем оценку человеческого фактора, демонстрирующую высокие оценки общего качества продукции.', 'zh': '近年以来,神经网络数至文本自然语言生(NLG)法益受欢迎,其致正自然语言也。 以便神经网络模,论者创为语义大集。 然而创此数集是一务,约义而成,所以成插槽价令牌也。 此文不备 NLG 系统尝试泛化所用一切上下文信息,如域中信息及槽直者。 于本文中,模式导自然语言成(SG-NLG)新任。 于是犹生自然语言示,而 SG-NLG 输 MR 与上下文息之丰式配对。 为 SG-NLG 生数集,以见数集复施于一务:一曰大富架构,三曰域、用户、槽。 吾于此数集上练其异者神经自然语言成其最先进者,明于众也,多其信,许其语义多样性而生高质量也。\n又为实验,较见域中及未见过域模形性能,并立一人工评估,证全体输评分甚高。', 'hi': 'डेटा-टू-टेक्स्ट प्राकृतिक भाषा पीढ़ी (एनएलजी) के लिए तंत्रिका नेटवर्क आधारित दृष्टिकोण ने हाल के वर्षों में लोकप्रियता हासिल की है, एक प्राकृतिक भाषा प्रॉम्प्ट उत्पन्न करने के लक्ष्य के साथ जो सटीक रूप से एक इनपुट अर्थ प्रतिनिधित्व का एहसास करता है। तंत्रिका नेटवर्क मॉडल के प्रशिक्षण को सुविधाजनक बनाने के लिए, शोधकर्ताओं ने युग्मित कथनों और उनके अर्थ प्रतिनिधित्व के बड़े डेटासेट बनाए। हालांकि, इस तरह के डेटासेट का निर्माण एक कठिन कार्य है और उनमें ज्यादातर स्लॉट और मूल्य टोकन से बने सरल अर्थ के प्रतिनिधित्व शामिल हैं। इन अभ्यावेदनों में कोई भी प्रासंगिक जानकारी शामिल नहीं है जिसका उपयोग NLG सिस्टम सामान्यीकृत करने का प्रयास करते समय कर सकता है, जैसे कि डोमेन जानकारी और स्लॉट और मानों का विवरण। इस पेपर में, हम स्कीमा-निर्देशित प्राकृतिक भाषा पीढ़ी (एसजी-एनएलजी) के उपन्यास कार्य को प्रस्तुत करते हैं। यहां, लक्ष्य अभी भी एक प्राकृतिक भाषा प्रॉम्प्ट उत्पन्न करना है, लेकिन एसजी-एनएलजी में, इनपुट एमआरएस को प्रासंगिक जानकारी प्रदान करने वाले रिच स्कीमाटा के साथ जोड़ा जाता है। एसजी-एनएलजी के लिए डेटासेट उत्पन्न करने के लिए हम किसी अन्य कार्य के लिए एक मौजूदा डेटासेट को फिर से उद्देश्य देते हैं: संवाद राज्य ट्रैकिंग, जिसमें डोमेन, उपयोगकर्ता के इरादे और स्लॉट विवरण के बारे में जानकारी सहित कई अलग-अलग विशेषताओं को फैलाने वाली एक बड़ी और समृद्ध स्कीमा शामिल है। हम इस डेटासेट पर तंत्रिका प्राकृतिक भाषा पीढ़ी के लिए विभिन्न अत्याधुनिक मॉडलों को प्रशिक्षित करते हैं और दिखाते हैं कि कई मामलों में, समृद्ध स्कीमा जानकारी सहित हमारे मॉडल को शब्दार्थ और विविधता दोनों के संदर्भ में उच्च गुणवत्ता वाले आउटपुट का उत्पादन करने की अनुमति देता है।\nहम देखे गए बनाम अनदेखी डोमेन पर मॉडल प्रदर्शन की तुलना में प्रयोगभी करते हैं, और समग्र आउटपुट गुणवत्ता के लिए उच्च रेटिंग का प्रदर्शन करने वाले मानव मूल्यांकन को प्रस्तुत करते हैं।', 'ga': 'Le blianta beaga anuas tá an-tóir ar chur chuige líonra néarbhunaithe maidir le giniúint teanga nádúrtha sonraí-go-téacs (NLG), agus é mar sprioc leid teanga nádúrtha a ghiniúint a réadaíonn go cruinn léiriú brí ionchurtha. Chun oiliúint samhlacha néarlíonra a éascú, chruthaigh taighdeoirí tacair shonraí mhóra de chainteanna péireáilte agus a gcuid léirithe brí. Mar sin féin, is tasc an-dian é tacair sonraí den sórt sin a chruthú agus is éard atá iontu den chuid is mó léiriúcháin brí shimplí comhdhéanta de shliotáin agus de chomharthaí luacha atá le baint amach. Ní chuimsíonn na huiríll sin aon fhaisnéis chomhthéacsúil is féidir le córas NLG a úsáid agus é ag iarraidh a ghinearálú, amhail faisnéis fearainn agus tuairiscí ar shliotáin agus luachanna. Sa pháipéar seo, cuirimid i láthair tasc nua Ghiniúint Teanga Nádúrtha faoi Threoir Scéimre (SG-NLG). Anseo, is é an sprioc fós leid teanga nádúrtha a ghiniúint, ach in SG-NLG, déantar na MRanna ionchuir a phéireáil le scéimeanna saibhir a sholáthraíonn faisnéis chomhthéacsúil. Chun tacar sonraí a ghiniúint do SG-NLG déanaimid athchuspóirí ar thacar sonraí atá ann cheana féin le haghaidh taisc eile: rianú staid dialóige, lena n-áirítear scéimre mór saibhir a chuimsíonn tréithe éagsúla, lena n-áirítear faisnéis faoin bhfearann, rún an úsáideora, agus tuairiscí sliotán. Cuirimid oiliúint ar mhúnlaí úrscothacha éagsúla do ghiniúint teanga nádúrtha néaraíoch ar an tacar sonraí seo agus taispeánann muid go ligeann sé d’ár múnlaí i go leor cásanna, lena n-áirítear faisnéis shaibhir scéimre, aschuir chaighdeán níos airde a tháirgeadh ó thaobh séimeantaice agus éagsúlachta araon.\nDéanaimid turgnaimh freisin a dhéanann comparáid idir feidhmíocht samhla ar fhearainn le feiceáil i gcomparáid le fearainn nach bhfeictear, agus cuirimid i láthair meastóireacht dhaonna a thaispeánann rátálacha arda do cháilíocht an aschuir fhoriomlán.', 'ka': 'ჩვენ ასევე ვქცევთ ექსპერიმენტები, რომლებიც მოდელური გამოყენება, რომლებიც ჩვენ ხედავთ, ან არახედავთ დემომენტები, და ადამიანის გამოყენება, რომლებიც უფრო', 'el': 'Επίσης, διεξάγουμε πειράματα συγκρίνοντας την απόδοση μοντέλων σε ορατά και αόρατα πεδία, και παρουσιάζουμε μια ανθρώπινη αξιολόγηση που αποδεικνύει υψηλές βαθμολογίες για τη συνολική ποιότητα παραγωγής.', 'it': "Conduciamo anche esperimenti che confrontano le prestazioni del modello su domini visti rispetto a quelli invisibili e presentiamo una valutazione umana che dimostra valutazioni elevate per la qualità complessiva dell'output.", 'hu': 'Kísérleteket végzünk a modell teljesítményének összehasonlítására láthatatlan és láthatatlan tartományokon, és bemutatunk egy emberi értékelést, amely magas minősítést mutat be az általános kimeneti minőségre vonatkozóan.', 'kk': 'Мұндай-ақ біз көрілмеген домендерге қарай үлгі жылдамдығын салыстырып, адамдардың оқиғаларын көрсету үшін жұмыс сапасы жоғары оқиғаларын көрсетеді.', 'ml': 'ഞങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്ന പരീക്ഷണങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നു, അദൃശ്യമായ ഡൊമെയിനുകള്\u200dക്ക് വിരോധമായി കാണുന്ന പരീക്ഷണങ', 'lt': 'We also conduct experiments comparing model performance on seen versus unseen domains, and present a human evaluation demonstrating high ratings for overall output quality.', 'mt': 'We also conduct experiments comparing model performance on seen versus unseen domains, and present a human evaluation demonstrating high ratings for overall output quality.', 'mn': 'Бид мөн харагдахгүй орон нутгийн загварын үйл ажиллагааг харьцуулж, хүн төрөлхтний оюун шалгалтыг харуулж байна.', 'no': 'Vi gjer også eksperimenter som samanliknar modellen på sett versus ukjende domene, og gjer eit menneskelig evaluering som viser høg evaluering for overalt utgangskvalitet.', 'pl': 'Przeprowadzamy również eksperymenty porównujące wydajność modelu w obszarach widzianych i niewidzialnych oraz przedstawiamy ocenę ludzką wykazującą wysokie oceny ogólnej jakości wyników.', 'ro': 'De asemenea, efectuăm experimente care compară performanța modelului pe domenii văzute versus nevăzute și prezentăm o evaluare umană care demonstrează evaluări ridicate pentru calitatea generală a ieșirii.', 'sr': 'Također provodimo eksperimente u usporedbi sa modelom izvedbi na viđenim i nevidljivim domenima, i predstavljamo ljudsku procjenu koja pokazuje visoke ocjene za ukupnu kvalitet izvedbe.', 'mk': 'Ние, исто така, спроведуваме експерименти во споредба со моделните резултати на видени и невидени домени, и претставуваме човечка оценка која демонстрира високи оценки за целокупниот квалитет на излез.', 'ms': 'Kami juga melakukan eksperimen membandingkan prestasi model pada domain yang terlihat dibanding domain yang tidak terlihat, dan mempersembahkan penilaian manusia yang menunjukkan nilai tinggi untuk kualiti output keseluruhan.', 'si': 'අපි පරීක්ෂණය කරනවා මොඩල් ප්\u200dරමාණය සම්බන්ධ වෙනුවෙන් දැක්කේ නැති ඩෝමේන්ස් වලට සම්බන්ධ වෙනුවෙන්, මිනිස්සු ග', 'so': 'Sidoo kale waxaynu sameynaa imtixaamo sameynta tusaale ahaan oo ka mid ah meelaha lagu arko oo ka gees ah meelaha qarsoon, waxaana soo bandhigaynaa qiimeynta dadka oo muujiyaya heerka sare oo u eg tijaamacada dhalashada oo dhan.', 'sv': 'Vi genomför även experiment som jämför modellprestanda på sedda respektive osedda domäner, och presenterar en mänsklig utvärdering som visar höga betyg för övergripande output kvalitet.', 'ta': 'நாம் மாதிரி செயல்பாட்டை ஒப்பிடும் சோதனைகளை செய்கிறோம் மறையாத களங்களை எதிர்பார்க்கும் முழு வெளியீட்டு தரம் உயர்ந', 'ur': 'ہم نے بھی آزمائش کیا ہے جو نمڈل کی عملکرد کی مقایسہ کرتی ہے دیکھے ہوئے دامنوں اور غیر دیکھے ہوئے دامنوں پر، اور ایک انسان کا ارزش کرتا ہے جو عمومی آوٹ کیفیت کے لئے بلند ریٹینگ دکھاتا ہے.', 'uz': "Yaqinda yil ichida tarmoqning asosiy tarmoq maʼlumot matn tili yaratishga (NLG) murakkablariga ega bo'ladi va asl tillarni yaratish maqsadi mumkin. Bu tarmoqni tasdiqlash imkoniyatini aniqlaydi. Name Lekin, bu maʼlumotlar tuzuvlarini yaratish juda qiyin vazifa. Ular ko'pchiligi, slot va qiymatning qiymatlarini aniqlash mumkin. Ushbu parametrlar hech qanday narsa maʼlumot yoʻq, bunday domen maʼlumot va qiymatlar va qiymatlarni aniqlashda, NLG tizimi yaratishi mumkin. In this paper, we present the novel task of Schema-Guided Natural Language Generation (SG-NLG).  Bu yerda, maqsad soddalik tilning soni yaratish uchun, lekin SG-NLG'da, kiritish MRs bilan taxminan maʼlumot yordamida qo'yiladi. @ info: whatsthis Biz bu maʼlumotlar tarkibida neyrolik tili yaratish uchun har xil holat modellarini o'rganamiz va ko'plab holatda, taxminan qolip maʼlumot yordamida, semantika va muloqatlarning darajada ko'proq darajada foydalanish imkoniyatini yaratishga imkoniyat beramiz.\nBiz esa ko'rinadigan narsalarning model drayveriga o'xshash imkoniyatlarini bajaramiz va hamma natijalar sifatida eng yuqori qiymatni ko'rsatamiz.", 'vi': 'Các phương pháp dựa trên mạng thần kinh để tạo ra ngôn ngữ tự nhiên (NLG) từ dữ liệu đến văn bản (ngôn ngữ tự động) đã được phổ biến nhiều năm gần đây, với mục đích tạo ra một dòng thiên nhiên mà thực hiện một cách chính xác Để dễ dàng đào tạo các mô hình mạng thần kinh, các nhà nghiên cứu tạo ra các tập tin đầy đủ các biểu hiện kết hợp và các biểu hiện ý nghĩa. Tuy nhiên, việc tạo ra các dữ liệu này là một nhiệm vụ khó khăn và chúng chủ yếu là các biểu tượng ý nghĩa đơn giản, gồm các biểu đồ thời gian và giá trị cần được thực hiện. Các biểu tượng này không chứa bất kỳ thông tin ngữ cảnh nào mà một hệ thống NLG có thể sử dụng khi cố tổng hợp lại, như thông tin về miền và mô tả các khe cửa và giá trị. Trong tờ giấy này, chúng tôi giới thiệu nhiệm vụ mới của Hệ thống ngôn ngữ tự nhiên được hướng dẫn (G-NLG). Ở đây, mục tiêu vẫn là phải tạo một dấu nhắc ngôn ngữ tự nhiên, nhưng trong G-NLG, MRX nhập được cộng với âm bản giàu có cung cấp thông tin ngữ cảnh. Để tạo một tập tin cho LG-NLG, chúng tôi tái mục đích một tập tin đã có cho một nhiệm vụ khác: dò trạng thái hộp thoại, gồm một giản đồ lớn và giàu có bao gồm nhiều khả năng khác nhau, gồm thông tin về miền, mục đích người dùng, và mô tả suất. Chúng tôi đào tạo các mô hình nghệ thuật khác nhau về hệ thống ngôn ngữ tự nhiên thần kinh trên bộ dữ liệu này và cho thấy rằng trong nhiều trường hợp, bao gồm những thông tin giản đồ giàu có cho phép các mẫu sản xuất chất lượng cao cả về ngữ pháp và đa dạng.\nChúng tôi cũng tiến hành thí nghiệm so sánh hiệu suất mô hình trên miền nhìn đối với không nhìn thấy, và trình bày một đánh giá nhân loại cao chất lượng xuất chung.', 'bg': 'Неврологичните мрежи подходи за генериране на естествен език от данни към текст (НЛГ) придобиха популярност през последните години с цел генериране на подкана на естествен език, който точно реализира представяне на входно значение. За да улеснят обучението на модели на невронни мрежи, изследователите създадоха големи набори от данни от сдвоени изказвания и техните значения. Създаването на такива набори от данни обаче е трудна задача и те се състоят предимно от прости символи, съставени от слот и стойностни символи, които трябва да бъдат реализирани. Тези представи не включват никаква контекстуална информация, която системата може да използва, когато се опитва да обобщи, като например информация за домейна и описания на слотове и стойности. В настоящата статия представяме новата задача на генериране на естествен език (СГ-НЛГ). Тук целта все още е да се генерира подкана на естествен език, но в входните MRs са сдвоени с богати схеми, предоставящи контекстуална информация. За да генерираме набор от данни за пренасочваме съществуващ набор от данни за друга задача: проследяване на състоянието на диалоговия прозорец, което включва голяма и богата схема, обхващаща множество различни атрибути, включително информация за домейна, намерението на потребителя и описанията на слотове. Обучаваме различни съвременни модели за генериране на невронен естествен език на този набор от данни и показваме, че в много случаи, включително богата информация за схемите, позволява на нашите модели да произвеждат по-качествени изходи както по отношение на семантиката, така и по отношение на многообразието.\nСъщо така провеждаме експерименти, сравняващи производителността на модела в видими и невидими области, и представяме оценка от човека, демонстрираща високи оценки за цялостното качество на продукцията.', 'nl': "Neuronale netwerkgebaseerde benaderingen voor het genereren van data-to-text natuurlijke taal (NLG) zijn de laatste jaren populairder geworden, met als doel een natuurlijke taal prompt te genereren die nauwkeurig een invoerbetekenisrepresentatie realiseert. Om de training van neurale netwerkmodellen te vergemakkelijken, creëerden onderzoekers grote datasets van gepaarde uitspraken en hun betekenisrepresentaties. Het creëren van dergelijke datasets is echter een zware taak en ze bestaan meestal uit eenvoudige betekenisrepresentaties die bestaan uit slot- en waardetokens die moeten worden gerealiseerd. Deze representaties bevatten geen contextuele informatie die een NLG-systeem kan gebruiken bij het generaliseren, zoals domeininformatie en beschrijvingen van slots en waarden. In dit artikel presenteren we de nieuwe taak van Schema-Guided Natural Language Generation (SG-NLG). Hier is het doel nog steeds om een natuurlijke taal prompt te genereren, maar in SG-NLG worden de invoer MR's gekoppeld aan rijke schema's die contextuele informatie verstrekken. Om een dataset te genereren voor SG-NLG gebruiken we een bestaande dataset opnieuw voor een andere taak: dialoogstatusverfolging, dat een groot en uitgebreid schema bevat dat meerdere verschillende attributen omvat, inclusief informatie over het domein, gebruikersintentie en slotbeschrijvingen. We trainen verschillende state-of-the-art modellen voor het genereren van neurale natuurlijke taal op deze dataset en laten zien dat onze modellen in veel gevallen, inclusief rijke schema-informatie, hogere kwaliteit outputs kunnen produceren, zowel op het gebied van semantiek als diversiteit.\nWe voeren ook experimenten uit met het vergelijken van modelprestaties op zichtbare en onzichtbare domeinen, en presenteren een menselijke evaluatie die aantoont dat hoge waarderingen voor de algehele outputkwaliteit worden aangetoond.", 'da': "Neurale netværksbaserede tilgange til data-til-tekst naturlig sproggenerering (NLG) har vundet popularitet i de seneste år, med det formål at generere en naturlig sprogprompt, der nøjagtigt realiserer en input betydning repræsentation. For at lette træningen af neurale netværksmodeller skabte forskere store datasæt af parrede udtalelser og deres meningsrepræsentationer. Men oprettelsen af sådanne datasæt er en besværlig opgave, og de består for det meste af simple meningsrepræsentationer bestående af slot og værdi tokens, der skal realiseres. Disse repræsentationer omfatter ikke kontekstuelle oplysninger, som et NLG-system kan bruge, når de forsøger at generalisere, såsom domæneoplysninger og beskrivelser af slots og værdier. I denne artikel præsenterer vi den nye opgave for Schema-Guided Natural Language Generation (SG-NLG). Her er målet stadig at generere en naturlig sprogprompt, men i SG-NLG parres input MR'erne med rige skemaer, der giver kontekstuelle oplysninger. For at generere et datasæt til SG-NLG genbruger vi et eksisterende datasæt til en anden opgave: sporing af dialogtilstande, som indeholder et stort og omfattende skema, der spænder over flere forskellige attributter, herunder oplysninger om domænet, brugerhensigt og slot beskrivelser. Vi træner forskellige state-of-the-art modeller til generering af neurale natursprog på dette datasæt og viser, at i mange tilfælde, herunder rig skema information, giver vores modeller mulighed for at producere output af højere kvalitet både i form af semantik og mangfoldighed.\nVi gennemfører også eksperimenter, der sammenligner model performance på seen versus usete domæner, og præsenterer en menneskelig evaluering, der viser høje vurderinger for den samlede output kvalitet.", 'de': 'Neuronale netzwerkbasierte Ansätze zur Erzeugung natürlicher Sprache (NLG) haben in den letzten Jahren an Popularität gewonnen, mit dem Ziel, eine natürliche Sprachaufforderung zu generieren, die eine Eingabebedeutungsrepräsentation präzise realisiert. Um das Training neuronaler Netzwerkmodelle zu erleichtern, erstellten Forscher große Datensätze von gepaarten Äußerungen und deren Bedeutungsrepräsentationen. Die Erstellung solcher Datensätze ist jedoch eine mühsame Aufgabe und besteht meist aus einfachen Bedeutungsdarstellungen, die aus zu realisierenden Slot- und Wertetonen bestehen. Diese Darstellungen enthalten keine Kontextinformationen, die ein NLG-System verwenden kann, um zu verallgemeinern, wie Domäneninformationen und Beschreibungen von Slots und Werten. In diesem Beitrag stellen wir die neuartige Aufgabe der Schema-Guided Natural Language Generation (SG-NLG) vor. Hier besteht das Ziel immer noch darin, eine Eingabeaufforderung in natürlicher Sprache zu generieren, aber in SG-NLG werden die Eingabe-MRs mit reichhaltigen Schemata gepaart, die kontextbezogene Informationen liefern. Um einen Datensatz für SG-NLG zu generieren, verwenden wir einen vorhandenen Datensatz für eine andere Aufgabe: Dialogzustandsverfolgung, die ein großes und umfangreiches Schema enthält, das mehrere verschiedene Attribute umfasst, einschließlich Informationen über die Domäne, Benutzerabsichten und Slot-Beschreibungen. Wir trainieren verschiedene State-of-the-Art Modelle zur Erzeugung neuronaler natürlicher Sprache auf diesem Datensatz und zeigen, dass unsere Modelle in vielen Fällen, einschließlich reichhaltiger Schema-Informationen, qualitativ hochwertigere Ergebnisse sowohl in Bezug auf Semantik als auch Diversität produzieren können.\nWir führen auch Experimente durch, die die Modellleistung auf sichtbaren und unsichtbaren Domänen vergleichen und präsentieren eine menschliche Bewertung, die hohe Bewertungen für die Gesamtausgabequalität zeigt.', 'hr': 'Neuralna mreža bazirana na pristupima generaciji prirodnog jezika (NLG) podataka do teksta dobila je popularnost u posljednjih godina, s ciljem stvaranja prirodnog jezika brzo što precizno shvaća predstavljanje ulaznog značenja. Da bi olakšali obuku modela neuralne mreže, istraživači su stvorili velike skupine podataka o parovima izjavama i njihovim značajnim predstavljanjima. Međutim, stvaranje takvih podataka je težak zadatak i uglavnom se sastoji od jednostavnih predstavljanja značenja koje su sastavljene od slota i znakova vrijednosti. Ove predstave ne uključuju nikakve contextualne informacije koje sustav NLG može koristiti kada pokušava generalizirati, poput podataka domena i opisa mjesta i vrijednosti. U ovom papiru predstavljamo novi zadatak generacije prirodnog jezika (SG-NLG). Ovdje je cilj i dalje stvoriti prirodni jezik brzinom, ali u SG-NLG, ulazni MR-ovi su povezani s bogatim šemom koji pružaju kontekstualne informacije. Da bi stvorili setu podataka za SG-NLG ponovno namjeravali postojeću setu podataka za drugi zadatak: praćenje država dijaloga, koja uključuje veliku i bogatu šemu koja širi više različitih atributa, uključujući informacije o domenu, namjeri korisnika i opisu slot a. Vježbamo različite modele stanja umjetnosti za generaciju neuroloških prirodnih jezika na ovom setu podataka i pokažemo da u mnogim slučajevima, uključujući bogate informacije o šemi, omogućavamo našim modelima da proizvode višeg kvalitetnog ishoda kako u smislu semantike i raznolikosti.\nTakođer provodimo eksperimente u usporedbi s modelom učinka na vidljivim i nevidljivim domenima, i predstavljamo ljudsku procjenu koja pokazuje visoke ocjene za ukupnu kvalitet izlaza.', 'id': 'Pendekatan jaringan saraf berdasarkan data-ke-teks generasi bahasa alam (NLG) telah meningkat popularitas dalam tahun-tahun terakhir, dengan tujuan untuk menghasilkan bahasa alam prompt yang akurat menyadari representasi makna input. Untuk memudahkan pelatihan model jaringan saraf, para peneliti menciptakan dataset besar dari ucapan pasangan dan representation artinya mereka. Namun, penciptaan set data seperti ini adalah tugas yang sulit dan mereka kebanyakan terdiri dari representation arti sederhana yang terdiri dari slot dan token nilai yang harus direalisasi. Perwakilan ini tidak termasuk informasi kontekstual apapun yang dapat digunakan sistem NLG ketika mencoba menyebarkan, seperti informasi domain dan deskripsi slot dan nilai. Dalam kertas ini, kami mempersembahkan tugas baru dari Generasi Bahasa Alami yang Dipandang Skema (SG-NLG). Di sini, tujuan masih untuk menghasilkan prompt bahasa alami, tapi di SG-NLG, input MR dipasang dengan skema kaya yang menyediakan informasi kontekstual. Untuk menghasilkan sebuah set data untuk SG-NLG kami mengatur ulang sebuah set data yang ada untuk tugas lain: pelacakan keadaan dialog, yang termasuk skema besar dan kaya yang meliputi atribut berbeda berbeda, termasuk informasi tentang domain, niat pengguna, dan deskripsi slot. We train different state-of-the-art models for neural natural language generation on this dataset and show that in many cases, including rich schema information allows our models to produce higher quality outputs both in terms of semantics and diversity.\nKami juga melakukan eksperimen membandingkan prestasi model pada domain yang terlihat dibandingkan domain yang tidak terlihat, dan mempersembahkan evaluasi manusia yang menunjukkan nilai tinggi untuk kualitas output umum.', 'fa': 'در سال های اخیر، دسترسی\u200cهای شبکه عصبی به نسل زبان طبیعی (NLG) داده\u200cها و متن\u200cهای طبیعی (NLG) با هدف تولید یک پیشنهاد زبان طبیعی که دقیقاً معنی ورودی را متوجه می\u200cشود، شهرت یافته است. برای آسانی آموزش مدلهای شبکه عصبی، محققان مجموعه\u200cهای داده\u200cهای بزرگ از زبان\u200cهای جفت و معنی آنها را ایجاد کردند. ولی ایجاد این مجموعه\u200cهای داده\u200cها یک کار سخت است و آنها بیشتر از معنی ساده\u200cهای معنی است که از نقطه\u200cها و نشانه\u200cهای ارزشمند برای فهمیدن است. این نمایش\u200cدهندگان هیچ اطلاعاتی که سیستم NLG می\u200cتواند در سعی عمومی استفاده کند، مانند اطلاعات دامنی و توضیح\u200cدهندگان جعبه\u200cها و ارزش\u200cها را شامل نمی\u200cشود. در این کاغذ، ما وظیفه\u200cی نویسی نسل زبان طبیعی (SG-NLG) را نشان می\u200cدهیم. هدف هنوز برای تولید یک پیشنهاد زبان طبیعی است، ولی در SG-NLG، MRs وارد شدن با برنامه های ثروتمندی که اطلاعات موضوع را می دهند، جفت دارند. برای تولید مجموعه داده\u200cها برای SG-NLG، یک مجموعه داده\u200cهای موجود برای کار دیگر را دوباره هدف می\u200cدهیم: ردیابی وضعیت محاوره، که شامل یک برنامه بزرگ و ثروتمندی است که ویژه\u200cهای متفاوتی را گسترش می\u200cدهد، شامل اطلاعات درباره\u200cی دامنه، هدف کاربر و تو ما مدل های موجود هنر مختلف را برای نسل زبان طبیعی عصبی روی این مجموعه داده آموزش می دهیم و نشان می دهیم که در بسیاری از موارد، شامل اطلاعات برنامه پولدار، مدل های ما اجازه می دهد که نتیجه های کیفیت بالاتر را به صورت semantics و diversity تولید کنند\nما همچنین آزمایش\u200cها را با مقایسه کردن اجرای مدل بر روی دیده\u200cهای غیبی انجام می\u200cدهیم، و یک ارزیابی انسان را نشان می\u200cدهیم که ارزیابی بالا برای کیفیت خروجی عمومی را نشان می\u200cدهد.', 'ko': '최근 몇 년 동안 신경 네트워크를 바탕으로 한 데이터부터 텍스트자연언어생성(NLG) 방법까지 광범위하게 응용되었는데 그 목표는 입력의 의미 표시를 정확하게 실현할 수 있는 자연언어 힌트를 생성하는 것이다.신경 네트워크 모델의 훈련을 촉진하기 위해 연구원들은 대량의 대화어와 그 의미 표징을 위한 데이터 집합을 만들었다.그러나 이러한 데이터 집합을 만드는 것은 어려운 작업이다. 대부분은 간단한 의미 표시로 구성되고 실현될 슬롯과 값 표시로 구성된다.이러한 표현에는 요약을 시도할 때 NLG 시스템에서 사용할 수 있는 도메인 정보, 간격 및 값과 같은 컨텍스트 정보가 포함되지 않습니다.본고에서 우리는 모델이 이끄는 자연 언어 생성(SG-NLG)의 새로운 임무를 제시했다.여기서 목표는 여전히 자연 언어 힌트를 생성하는 것이지만 SG-NLG에서 입력한 MRs는 상하문 정보를 제공하는 풍부한 도식과 일치한다.SG-NLG를 위해 데이터 집합을 생성하기 위해 우리는 기존의 데이터 집합을 다른 임무인 대화 상태 추적에 사용할 것이다. 그 중에서 여러 가지 서로 다른 속성을 뛰어넘는 대형 풍부한 모델을 포함하고 도메인, 사용자 의도와 슬롯에 대한 정보를 포함한다.우리는 이 데이터 집합에서 서로 다른 신경 자연 언어 생성 모델을 훈련시켰고 많은 상황에서 풍부한 모델 정보를 포함하여 우리의 모델이 의미와 다양성 측면에서 더욱 높은 품질의 출력을 할 수 있음을 나타냈다.\n우리는 또한 실험을 실시하여 모델이 가시역과 불가시역에서의 성능을 비교하고 인류 평가를 제시하여 전체 출력의 질에 대한 높은 평가를 나타냈다.', 'sw': 'Neural network based approaches to data-to-text natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation.  Ili kusaidia mafunzo ya mifano ya mtandao wa neura, watafiti walitengeneza seti kubwa ya hotuba mbili na maana yao. Hata hivyo, kutengeneza seti za taarifa hizi ni kazi ngumu na kwa ujumla huwa ni maonesho rahisi yaliyotengenezwa na alama za thamani zinazotambuwa. Wawakilishi hawajumuishi taarifa za kimataifa ambazo mfumo wa NLG unaweza kutumia wakati wa kujaribu kuzalisha, kama vile taarifa za ndani na maelezo ya mistari na thamani. Katika karatasi hii, tunaweka kazi ya riwaya ya Uzalishaji wa Lugha ya asili inayoongozwa na Schema (SG-NLG). Hapa, lengo linaendelea kutengeneza haraka la lugha ya asili, lakini katika SG-NLG, mashindano ya MRs yanaunganishwa na mpango wa utajiri wa kutoa taarifa za sasa. Kutengeneza seti ya taarifa kwa ajili ya SG-NLG tunalenga tena seti ya taarifa zilizopo kwa ajili ya kazi nyingine: ufuatiliaji wa serikali ya dialogue, ambayo ina mpango mkubwa na utajiri wa aina mbalimbali, ikiwa ni pamoja na taarifa kuhusu eneo hilo, lengo la watumiaji, na maelezo ya kisasa. Tunafundisha mifano tofauti ya hali ya sanaa kwa ajili ya kizazi cha lugha asili katika seti hii ya data na kuonyesha kwamba katika matukio mengi, ikiwa ni pamoja na taarifa za mpango wa utajiri, inaruhusu mifano yetu kutengeneza matokeo ya ubora wa kiwango kikubwa kwa ajili ya mifano na utofauti.\nPia tunafanya majaribio yanayofananisha utendaji wa mifano kuhusu kuonekana dhidi ya maeneo yasiyo onekana, na tunaweka tathmini za binadamu zinazoonyesha kiwango kikubwa cha kiwango cha uzalishaji kwa ujumla.', 'tr': 'NLG, iň soňky ýyllarda data-to-text dil döredilmesine (data-to-text language generation) daýan ýan gollaşyklar, tebigy dili döretmek üçin bir nusga düşürmek maksady bilen tapylýar. Nyöral şebek modelleriniň eğitimini bejermek üçin, araştırmalar üçin çift sözleriniň we olaryň nähili ifadelerini bejerdi. Ýöne bu ýaly veri setirleriniň bejerilmesi gaty kynçylyk täblidir we olaryň köplenç garaşan slot we mykdarlaryň işaretlerinden oluşan basit bir näme diýipdir. Bu gösterimler, NLG sisteminiň generalizasynda kullanılabileceğine dair bir contest bilgileri dahil etmez. Mesela domena bilgileri ve slot we değerlerinin tasvir edilmesi gibi. Bu kagyzda, biz Schema-gidirilen Doäbiň Dili döredişi (SG-NLG) atly zadyny görkeýäris. Bu ýerde maksady tebigy dil ýagdaýyny döretmekdir, emma SG-NLG içinde, MRlar daşary ýagdaýa maglumatlar bilen baglanýar. SG Biz bu berüvlerde näyral tebigy dil döredilmesi üçin farklı möhüm modalary öwredýäris we muny köpürde, baý şemalar maglumatlarymyzda modellerimiziň semantik we çeşitlilikde ýokary kaliwatly netijeleri döretmäge rugsat berýäris.\nBiz hem görülmeýän sahypalaryň we görnülmeýän sahypalaryň örän nusgalaryny karşılaştyryp barýarys we adam çykyş howpsuzlygyna görkezilýän çykyş çykyşlygyny görkez.', 'af': "Neurale netwerk gebaseerde toegang tot data- to- text natuurlike taal generasie (NLG) het in onlangse jaar populariteit ontvang, met die doel van 'n natuurlike taal prompt genereer wat presies 'n invoer betekening verskyn. Om die oefening van neurale netwerk modele te maak, het resekers groot datastelle van paarde uitspraak en hulle betekening verteenwoordings geskep. Maar die skepping van sodanige datastelle is 'n ongelukkige taak en hulle is meestal bestaan van eenvoudige betekenis verteenwoordings wat gemaak word van slot en waarde tekens om te bevestig. Hierdie voorstellings insluit nie enige contextual inligting wat 'n NLG stelsel kan gebruik wanneer probeer om generaliseer te word, soos domein inligting en beskrywings van slots en waardes. In hierdie papier, voorsien ons die novele taak van Skema-Geleide Natuurlike Taal Generasie (SG-NLG). Hier, die doel is nog steeds om 'n natuurlike taal prompt te genereer, maar in SG-NLG, die invoer MRs is paired met ryk skemas wat contextual inligting verskaf word. Om 'n datastel vir SG-NLG te genereer, ons herdoen 'n bestaande datastel vir 'n ander taak: dialoog staat navolg, wat insluit 'n groot en ryk skema wat veelvuldige verskillende eienskappe spanning, insluitend inligting oor die domein, gebruiker doel en slot beskrywings. Ons tref verskillende state-of-the-art modele vir neurale natuurlike taal generasie op hierdie datastel en wys dat in baie gevalle, insluitend ryk skema inligting, ons modele laat toe om hoër kwaliteit uitvoerdes te produseer beide in terms van semantiek en diversiteit.\nOns het ook eksperimente gedoen met vergelyking van model effektuur op gesien teen onverskyn domeine, en voorsien 'n menslike evaluering wat die hoë evaluering vir die hele uitset kwaliteit vertoon.", 'sq': 'Neural network based approaches to data-to-text natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation.  Për të lehtësuar trajnimin e modeleve të rrjetit nervor, kërkuesit krijuan grupe të mëdha të dhënash me shprehje të palëvizshme dhe përfaqësime të kuptimit të tyre. Megjithatë, krijimi i këtyre grupeve të dhënash është një detyrë e vështirë dhe ato përbëhen kryesisht nga përfaqësime të thjeshta me kuptim të përbërë nga shenjat e kohës dhe vlerave që duhet realizuar. Këto përfaqësime nuk përfshijnë asnjë informacion kontekstual që një sistem NLG mund të përdorë kur përpiqet të gjeneralizohet, të tillë si informacioni i dominit dhe përshkrimi i slots dhe vlerave. In this paper, we present the novel task of Schema-Guided Natural Language Generation (SG-NLG).  Këtu, qëllimi është ende të gjenerojmë një gjuhë natyrore të shpejtë, por në SG-NLG, input MR janë të barazuar me skema të pasura që ofrojnë informacion kontekstual. Për të gjeneruar një sërë të dhënash për SG-NLG ne rishikojmë një sërë të dhënash ekzistuese për një detyrë tjetër: ndjekje e gjendjes së dialogut, e cila përfshin një skemë të madhe dhe të pasur që përfshin shumë atribute të ndryshme, duke përfshirë informacion rreth domenit, qëllimit të përdoruesit dhe përshkrimit të slot. Ne trajnojmë modele të ndryshme më të moderne për gjenerimin e gjuhës natyrore nervore në këtë set të dhënash dhe tregojmë se në shumë raste, duke përfshirë informacionin e pasur të skemës lejon modelet tona të prodhojnë rezultate më të larta si në lidhje me semantikën ashtu edhe diversitetin.\nNe kryejmë gjithashtu eksperimente që krahasojnë performancën e modelit në domenat e parë ndaj të padukshme dhe paraqesim një vlerësim njerëzor që demonstron vlerësime të larta për cilësinë e përgjithshme të daljes.', 'am': 'የኔural network-based ዳታ-to-text-natural ቋንቋ ትውልድ (NLG) የቅርብ ዓመታት የፍጥረት ቋንቋ መፍጠር አግኝቷል፡፡ የናውሬል መረብ ምሳሌዎችን ለማስተማርና ለማግኘት፣ አስተማሪዎች ብዙ ዳታዎችን የሁለት ቃላት እና አእምሮአቸውን መግለጫ አቀረቡ፡፡ ምንም እንኳን እንደዚህ የዳታ መስመር መፍጠር አስቸጋሪ ስራ ነው፣ አብዛኛውም ለመግኘት የሚችሉትን ስህተት እና ዋጋ ምልክቶች የሚቆጠሩ አዋላጆች ናቸው፡፡ እነዚህ መልዕክቶች እንደዶሜን መረጃ እና ጽሑፎችን ለመጠቀም ሲሞከሩ የNLG ስርዓት ማድረግ የሚችሉትን መረጃ አያገኙም፡፡ በዚህ ገጽ የSchema-Guided Natural ቋንቋ ትውልድ (SG-NLG) አቀረብን፡፡ ይሄ፣ ጉዳዩ ግን የፍጥረት ቋንቋ ፈጥኖ እንዲወስድ ነው፤ ነገር ግን በSG-NLG ውስጥ input MRs በሀብታም ሰዓት የተቀናቀለ መረጃ እንዲሰጥሩ ነው፡፡ አዲስ ዶሴ ፍጠር የልዩ ልዩ ልዩ አርእስት ዓይነቶችን ለጠቅላዊ የቋንቋ ትውልድ ላይ እናስተምራለን፡፡\nእናም የውጤት ጥያቄ ጥያቄን ለመተካከል የምናደርገውን ምሳሌ እናደርጋለን፡፡', 'hy': "Նյարդային ցանցի հիմնված մոտեցումները տվյալներ-տեքստի բնական լեզվի ստեղծման (ՆԼԳ) ընթացքում հայտնի են դարձել վերջին տարիների ընթացքում, որպեսզի ստեղծենք բնական լեզվի արագ, որը ճշգրիտ հասկանա ներմուծման նշանակության ներկայաց Նյարդային ցանցի մոդելների ուսումնասիրելու համար հետազոտողները ստեղծեցին երկու արտահայտությունների մեծ տվյալների համակարգեր և նրանց իմաստային ներկայացումներ: Այնուամենայնիվ, այս տվյալների համակարգերի ստեղծումը դժվար խնդիր է, և դրանք հիմնականում կազմված են պարզ նշանակության ներկայացումներից, որոնք կազմված են իրականացնելու վայրերի և արժեքային նշաններից: Այս ներկայացումները չեն ներառում որևէ կոնտեքստային տեղեկություն, որը ՆԼԳ համակարգը կարող է օգտագործել ընդհանուր ընթացքում, ինչպիսիք են օրինակ բնագավառի տեղեկությունը և արժեքների պայմանները: Այս թղթի մեջ մենք ներկայացնում ենք Ստեմայի ուղղությամբ գտնվող բնական լեզվի ստեղծման (ՍԳ-ՆԼԳ) նոր խնդիրը: Այստեղ նպատակը դեռևս բնական լեզվի արագ ստեղծելու է, բայց ՍԳ-ՆԼԳ-ում մուտքագրման մագնիսական ռեժիշկները զուգավորվում են հարուստ սխեմատների հետ, որոնք տրամադրում են կոնտեքստալ տեղեկատվություն: Սգ-ՆԼԳ-ի համար ստացված տվյալների համակարգ ստեղծելու համար մենք վերականգնում ենք գոյություն ունեցող տվյալների համակարգը մեկ այլ խնդրի համար' բաղախոսային վիճակի հետևելու համար, որը ներառում է մեծ և հարուստ սխեմա, որը բազմաթիվ տարբեր առանձնահատկություններ է ընդգրկու Մենք այս տվյալների համակարգում ուսուցանում ենք տարբեր նորագույն մոդելներ նյարդային բնական լեզուների ստեղծման համար և ցույց ենք տալիս, որ շատ դեպքերում, ներառյալ հարուստ սխեմային տեղեկատվությունը, թույլ է տալիս մեր մոդելներին ստեղծել ավելի բարձր որակային արտադրանքներ\nՄենք նաև կատարում ենք փորձարկումներ, որոնք համեմատում ենք տեսանելի և անտեսանելի ոլորտների մոդելների արտադրողականությունը, և ներկայացնում ենք մարդկային գնահատականներ, որոնք ցույց են տալիս ընդհանուր արտադրողականության որակ", 'az': 'NLG, data-to-text təbiətli dil nəzəriyyətinə dayanan nöral a ğ tərəfindən gələn təbiətlər son illərdə məşğul olmuşdur. Bu təbiətli dil yaratmaq məqsədilə təbiətli bir məsəl olaraq, daxil olma məsələsini tam anlayır. Nəyral ağ modellərinin təhsil etməsini asanlaşdırmaq üçün, araştırmacılar böyük verilən sözlər və məsələləri yaratdılar. Lakin bu məlumatların yaradılması çox çətin bir işdir və onların çox olaraq istifadə ediləcək slot və qiymət möcüzələrindən oluşan basit məlumatlardandır. Bu göstəricilər NLG sisteminin genelləşdirməyə çalışırkən istifadə edə biləcəyi müxtəlif məlumatları, domena məlumatları və slotların və qiymətlərin tanımlamaları kimi. Bu kağızda, Schema-Guided Natural Language Generation (SG-NLG) yeni işini göstəririk. Burada, məqsəd hələ də təbiətli dil təbliğ etməkdir, amma SG-NLG içində, MRs girişi müxtəlif məlumatlar təbliğ edir. SG-NLG üçün verilən quruluş yaratmaq üçün başqa işlər üçün bir məlumat quruluşu yenidən məqsədilə yaradırıq: dialog durumu izləmək, bu da çoxlu fərqli tərzlərini genişləndirən böyük və zengin bir schema, domena, istifadəçi niyyəti və slot tərzlərini barəsində məlumat daxil edir. Biz bu məlumatlarda nöral təbiətli dil nəzəriyyəti üçün müxtəlif məlumatları təhsil edirik və çoxlu məlumatlarda, zəngin schema məlumatların içində modellərimizin semantik və müxtəlif məlumatları ilə daha yüksək kalitel sonuçlarını ürəkləməsinə imkan verir.\nBiz həmçinin görünmədiyimiz domenin və görünmədiyimiz domenin modellərini saldırmaq üçün təcrübələrini də təşkil edirik. İnsan təcrübəsini təşkil edir ki, böyük qiymətləri göstərir.', 'bn': 'সাম্প্রতিক বছরগুলোতে ডাটা থেকে প্রাকৃতিক ভাষার প্রজন্ম (এনএলজি) নিউরেল নেটওয়ার্কের ভিত্তিক প্রাকৃতিক প্রজন্মের কাছে প্রাকৃতিক ভাষা  নিউরেল নেটওয়ার্ক মডেলের প্রশিক্ষণের সুবিধা প্রদান করার জন্য, গবেষকরা বিশাল ডাটাটা সেট সৃষ্টি করেছেন জুড়ে যাওয়া ভ তবে এই ধরনের ডাটাসেটের সৃষ্টি একটি বিপদজনক কাজ এবং বেশীরভাগ সাধারণ মানে প্রতিনিধিত্ব রয়েছে স্লোট এবং মূল্যের প্রতীক যা বুঝতে প এই প্রতিনিধিগুলোর মধ্যে কোনো প্রতিনিধিত্ব নেই যে এনএলজি সিস্টেম জেনারেল করতে পারে, যেমন ডোমেইন তথ্য এবং স্লোট এবং মানের বর্ণনা  এই পত্রিকায় আমরা স্কিমা-গাইডেড প্রাকৃতিক ভাষার প্রজন্মের উপস্থাপন করছি (এসজি-এনএলজি)। এখানে উদ্দেশ্য এখনো প্রাকৃতিক ভাষার প্রাকৃতিক ব্যবস্থা তৈরি করার জন্য, কিন্তু এসজি-এনএলজি-এ ইনপুট এমআরগুলো সমৃদ্ধ স্কীমার সা SG-NLG এর জন্য একটি ডাটাসেট তৈরি করার জন্য আমরা অন্য কাজের জন্য একটি বিদ্যমান ডাটাসেটের উদ্দেশ্য পুনরায় উদ্দেশ্যে পুনরায় উদ্দেশ্য করি: ডায়ালগ রাষ্ট্র ট্র্যাকিং এর মধ্যে রয় We train different state-of-the-art models for neural natural language generation on this dataset and show that in many cases, including rich schema information allows our models to produce higher quality outputs both in terms of semantics and diversity.\nএছাড়াও আমরা অদৃশ্য ডোমেইনের বিরুদ্ধে দেখা মোডেল প্রদর্শনের তুলনায় পরীক্ষা করি এবং সারা আউটপুটের মানের জন্য মানুষের মানু', 'bs': 'Neuralna mreža bazirana na podacima generacije prirodnog jezika (NLG) na tekstu dobila je popularnost u posljednjih godina, s ciljem stvaranja prirodnog jezika brzo što precizno shvata predstavljanje ulaznog znaka. Da bi olakšali obuku modela neuralne mreže, istraživači su stvorili velike baze podataka zajedničkih izraza i njihovih značajnih predstavljanja. Međutim, stvaranje takvih podataka je težak zadatak i uglavnom se sastoji od jednostavnih predstavljanja značenja sastavljenih od slota i znakova vrijednosti koje treba shvatiti. Ove predstave ne uključuju nikakve kontekstne informacije koje NLG sustav može koristiti kada pokušava generalizirati, poput informacija domena i opisa mjesta i vrijednosti. U ovom papiru predstavljamo novi zadatak generacije prirodnog jezika (SG-NLG). Ovdje je cilj još uvek stvaranje prirodnog jezika brzina, ali u SG-NLG, ulazni MR su povezani sa bogatim šemom koji pružaju kontekstualne informacije. Da bi stvorili setu podataka za SG-NLG ponovo namjeravali postojeću setu podataka za drugi zadatak: praćenje država dijaloga, koja uključuje veliku i bogatu šemu koja širi više različitih atributa, uključujući informacije o domenu, namjeru korisnika i opisu slot a. Treniramo različite modele stanja umjetnosti za generaciju neuralne prirodne jezike na ovom setu podataka i pokazujemo da u mnogim slučajevima, uključujući bogate informacije o šemi, omogućavamo našim modelima da proizvode višeg kvalitetnog ishoda kako u smislu semantike i raznolikosti.\nTakođer provodimo eksperimente u usporedbi s modelom izvedbe na vidljivim i nevidljivim domenima, i predstavljamo ljudsku procjenu koja pokazuje visoke ocjene za ukupnu kvalitet izvedbe.', 'et': 'Närvivõrgupõhised lähenemisviisid andmete-teksti looduskeele genereerimisele (NLG) on viimastel aastatel populaarseks saanud eesmärgiga luua looduskeele viip, mis realiseerib täpselt sisendi tähenduse esituse. Närvivõrgu mudelite koolitamise hõlbustamiseks loosid teadlased suured andmekogumid paaritud väljenditest ja nende tähendusekujutustest. Selliste andmekogumite loomine on aga raske ülesanne ja need koosnevad enamasti lihtsatest tähendusekujutustest, mis koosnevad teenindusaegadest ja väärtustest, mida realiseeritakse. Need esitused ei sisalda kontekstiteavet, mida NLG-süsteem saaks kasutada üldistamisel, näiteks domeeniteavet ning teenindusaegade ja väärtuste kirjeldusi. Käesolevas töös tutvustame Schema-Guided Natural Language Generation (SG-NLG) uudset ülesannet. Siin on eesmärk endiselt luua looduskeele viip, kuid SG-NLG-s on sisendMR-d paaritud rikkalike skeemidega, mis annavad kontekstiteavet. SG-NLG andmekogumi genereerimiseks suuname olemasoleva andmekogumi ümber teise ülesande jaoks: dialoogi oleku jälgimiseks, mis sisaldab suurt ja rikkalikku skeemi, mis hõlmab mitut erinevat atribuuti, sealhulgas teavet domeeni, kasutaja kavatsuse ja teenindusaja kirjelduste kohta. Koolitame sellel andmekogumil erinevaid tipptasemel mudeleid neuroloomuliku keele genereerimiseks ja näitame, et paljudel juhtudel võimaldab meie mudelitel luua kvaliteetsemaid väljundeid nii semantika kui ka mitmekesisuse poolest.\nSamuti teeme katseid, milles võrreldakse mudeli jõudlust nähtud ja nähtamatute valdkondade puhul, ning esitame inimese hinnangu, mis näitab üldise väljundkvaliteedi kõrgeid hinnanguid.', 'cs': 'Přístupy k generování přirozeného jazyka (NLG) založené na neuronových sítích získaly v posledních letech popularitu s cílem generovat přirozený jazyk, který přesně realizuje reprezentaci vstupního významu. Pro usnadnění tréninku modelů neuronových sítí výzkumníci vytvořili velké datové sady párových výroků a jejich reprezentace významů. Vytvoření takových datových sad je však náročný úkol a většinou se skládají z jednoduchých významných reprezentací složených z slotů a hodnotových tokenů, které mají být realizovány. Tato reprezentace neobsahují žádné kontextové informace, které může systém NLG použít při pokusu o zobecnění, jako jsou informace o doméně a popisy slotů a hodnot. V tomto článku představujeme nový úkol Schema-Guided Natural Language Generation (SG-NLG). Cílem zde je stále generovat výzvu přirozeného jazyka, ale v SG-NLG jsou vstupní MR spárovány s bohatými schématy poskytujícími kontextové informace. Chcete-li generovat datovou sadu pro SG-NLG, znovu využijeme existující datovou sadu pro jiný úkol: sledování stavu dialogu, které obsahuje velké a bohaté schéma zahrnující více různých atributů, včetně informací o doméně, záměru uživatele a popisů slotů. Na tomto datovém souboru trénujeme různé nejmodernější modely pro generování nervového přirozeného jazyka a ukazujeme, že v mnoha případech včetně bohatých informací o schématech našim modelům umožňuje produkovat kvalitnější výstupy jak z hlediska sémantiky, tak z hlediska diverzity.\nDále provádíme experimenty srovnávající výkon modelu na viděných a neviditelných doménách a představujeme lidské hodnocení prokazující vysoké hodnocení celkové kvality výstupu.', 'fi': 'Neuroverkkopohjaiset lähestymistavat data-to-text natural language generation (NLG) ovat saaneet suosiota viime vuosina tavoitteena luoda luonnollisen kielen kehote, joka toteuttaa tarkasti syötteen merkityksen esittämisen. Neuroverkkomallien koulutuksen helpottamiseksi tutkijat loivat suuria tietokokonaisuuksia pareittain muodostetuista ilmaisuista ja niiden merkityksestä. Tällaisten aineistojen luominen on kuitenkin hankala tehtävä ja ne koostuvat enimmäkseen yksinkertaisista merkityksen esittämistä, jotka koostuvat slot- ja arvopoleteista, jotka on tarkoitus toteuttaa. Nämä esitykset eivät sisällä kontekstitietoja, joita NLG-järjestelmä voi käyttää yrittäessään yleistää, kuten verkkotunnustietoja sekä lähtö- ja arvokuvauksia. Tässä artikkelissa esitellään Schema-Guided Natural Language Generation (SG-NLG) uutta tehtävää. Tässä tapauksessa tavoitteena on edelleen luoda luonnollisen kielen kehote, mutta SG-NLG:ssä syötteen MR-arvot yhdistetään monipuoliseen kaavioon, joka tarjoaa kontekstitietoa. Luodaksemme datajoukon SG-NLG:lle, käytämme olemassa olevan datajoukon uudelleen toiseen tehtävään: valintaikkunan tilan seurantaan, joka sisältää suuren ja monipuolisen kaavion, joka kattaa useita eri attribuutteja, mukaan lukien tiedot verkkotunnuksesta, käyttäjän aikomuksesta ja korttipaikan kuvauksista. Koulutamme tässä aineistossa erilaisia moderneja malleja luonnollisen neurokielen tuottamiseen ja osoitamme, että monissa tapauksissa, mukaan lukien rikas skeematieto, mallimme voivat tuottaa laadukkaampia tuotoksia sekä semantiikan että monimuotoisuuden kannalta.\nTeemme myös kokeita, joissa verrataan mallin suorituskykyä nähtyillä ja näkymättömillä toimialueilla, ja esitämme ihmisen arvion, joka osoittaa korkeat arvosanat kokonaistuotannon laadulle.', 'ca': "Els enfocaments basats en la xarxa neuronal a la generació de llenguatges naturals (NLG) de dades a text han guanyat popularitat en els últims anys, amb l'objectiu de generar un llenguatge natural que s'adone de manera exacta d'una representació de significat d'entrada. Per facilitar l'entrenament de models de xarxa neural, els investigadors van crear grans conjunts de dades de frases parellades i representacions significatives. No obstant això, la creació d'aquests conjunts de dades és una tasca difícil i consisteixen principalment en representacions senzilles de significat compostes de signes de slot i valor que s'han de concretizar. Aquestes representacions no inclouen cap informació contextual que un sistema NLG pugui utilitzar quan intenta generalitzar, com la informació de domini i descripcions de slots i valors. En aquest article presentem la nova tasca de la generació de llenguatges naturals guiada per esquema (SG-NLG). Here, the goal is still to generate a natural language prompt, but in SG-NLG, the input MRs are paired with rich schemata providing contextual information.  Per generar un conjunt de dades per SG-NLG, reutilitzem un conjunt de dades existent per una altra tasca: el seguiment de l'estat del diàleg, que inclou un esquema gran i ric que abarca múltiples atributs diferents, incloent informació sobre el domini, l'intenció d'usuari i descripcions de slots. Ensenyem diferents models d'última generació de llenguatges naturals neurals en aquest conjunt de dades i demostrem que en molts casos, incloent informació d'esquema rics, permet als nostres models produir productes de més alta qualitat tant en termes de semàntica com de diversitat.\nTambé fem experiments comparant el rendiment del model en dominys visibles i no visibles, i presentem una evaluació human a que demostre altes valoracions per a la qualitat global de la producció.", 'sk': 'Pristopi, ki temeljijo na živčnih omrežjih k generiranju naravnega jezika (NLG), so v zadnjih letih pridobili priljubljenost s ciljem ustvarjanja poziva naravnega jezika, ki natančno uresničuje predstavitev vhodnega pomena. Da bi olajšali usposabljanje modelov nevronskih omrežij, so raziskovalci ustvarili velike podatkovne nabore združenih izgovorov in njihovih pomenskih reprezentacij. Vendar pa je ustvarjanje takih naborov podatkov težka naloga in so večinoma sestavljeni iz preprostih pomenskih predstavitev, sestavljenih iz rež in vrednostnih žetonov, ki jih je treba uresničiti. Te predstavitve ne vključujejo kontekstualnih informacij, ki jih lahko sistem NLG uporabi pri posploševanju, kot so informacije o domeni in opisi rež in vrednosti. V prispevku predstavljamo novo nalogo Schema-Guided Natural Language Generation (SG-NLG). Tu je cilj še vedno ustvariti poziv v naravnem jeziku, vendar so v SG-NLG vhodni MRs združeni z bogatimi shemami, ki zagotavljajo kontekstualne informacije. Za ustvarjanje nabora podatkov za SG-NLG preusmerimo obstoječi nabor podatkov za drugo opravilo: sledenje stanja v pogovornem oknu, ki vključuje veliko in bogato shemo, ki obsega več različnih atributov, vključno z informacijami o domeni, namenu uporabnika in opisi rež. Na tem naboru podatkov usposabljamo različne najsodobnejše modele za generiranje nevronskega naravnega jezika in pokažemo, da v mnogih primerih, vključno z bogatimi shemami informacije, omogočajo našim modelom ustvarjanje kakovostnejših rezultatov tako v smislu semantike kot raznolikosti.\nIzvajamo tudi poskuse, ki primerjajo zmogljivost modela na vidnih in nevidnih področjih, in predstavljamo oceno človeka, ki dokazuje visoke ocene za splošno kakovost izhoda.', 'jv': 'network Jejaring slot representation Nang pemilih iki, kita sembarang kelas kelentah ning kelas scheme-guided Body Language Generation (S G-NLG). Punika awak dhéwé isih njaluké oleh nggawe luwih-luwih, nguasai nG-NLG, akeh MRs seneng pisan akeh akeh iso nggawe informasi contextual. To Genere a dataset for S G-NLG we a re-goal an current dataset for one task: dialog state tracking, that include a big and wealth scheme spanding Multiple new attributions, include information about the domain, user enthusiasm, and slot descriptions. Awak dhéwé luwih-luwih sistem sing gak pernik state-of-the-Art model kanggo Generation languai Neral kuwi nggawe dataset iki ngono wong-wong kuwi akèh gadoh, terus teka informasi sistem sing permet nggawe model sing iso nggawe akeh sampek kudu winih dhéwé, sampek kang sampek karo akeh semati\nAwak dhéwé éntuk éntuk éntuk perbudhakan langgar nggambar model sing bisa ngelarang sak bingi, lan nggawe dolanan cara-layanan sing nggawe barang dhéwé nggawe kaliwat ujar.', 'ha': "@ label Ga ya sauƙaƙara wa shirin misãlai na jerin neural, watani na sami tsari masu yawa na haɗi magana biyu da fassararsu. A lokacin da, halittar wannan dataset yana da wani aikin aiki mai ƙwauro kuma yana ƙaranci cikin wasu masĩfa masu yiwuwa da aka sami wa slot da alama masu kima da za'a gane su. Waɗannan da ake gauraya ba su ƙunsa da wani maɓalli na takarda da wata na'urar NLG na iya amfani da idan an yi jarraba ɗabi'a, kamar, information na guda da misãlai wa slot da kimar. Ga wannan takardan, Munã halatar da aikin nan da aka shiryar da Lugha na Natural (SG-NLG). @ action: button Za iya ƙiƙiro wani tsari na SG-NLG, za'a sake zartar da wani tsari wanda ke jira wa wani aikin daban: Tuna kõre misãlai masu cikin-halin-sanar wa danne na tsari na takarda cikin wannan dataset, kuma Muke nuna cewa, a cikin misãlai masu yawa, idan akwai ƙidãya, ma'anar skima masu tajiri, yana yarda misalinmu su sami masu ƙaranci matsalar da sifati duk cikin masu mutane da tarawa.\nKayya, Munã samun jarrabo masu samfani da misalin misalin da aka gan shi versa bakwai da ba'a ɓõye ba, kuma Munã halatar da rabon mutum wanda ke nuna darajõji masu sarrafa ga sifar duk matsayin fitarwa.", 'bo': 'རང་བཞིན་པའི་ཆ་འཕྲིན་དྲ་བ་དང་མཐུད་སྤྲོད་ཀྱི་ཐབས་ལམ་ལ་རང་བཞིན་པའི་སྐད་རིགས་ལ་མཐུན་གྱི་ཐབས་ལམ་ལྟར་མཐུན་པས། ལྟ་བུ་ཚོའི་མཐུད་སྣེ་ཚོགས་ཀྱི་གླེང་སྒྲུང་ལ་སླེབས་འབོར་གྱི་རྩོལ་བ་ལ་ལས་སླེབས་བྱས་པར་སྤྲོད་གཏོང་། ཡིན་ནའང་། འདི་དག་གི་སྒྲིག་ཆ་འཕྲིན་གྲངས་སྒྲིག These representations do not include any contextual information that an NLG system can use when trying to generalize, such as domain information and descriptions of slots and values. ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་Schema-Guided Natural Language Generation (SG-NLG)ལས་བྱ་ཚིག་གསར་གཏོང་འདི་སྟོན་ཐུབ་ཀྱི་ཡོད། འདིར་བརྟེན་དམིགས་ཡུལ་ནི་རང་རུང་བའི་སྐད་ཡིག་གི་གསལ To generate a dataset for SG-NLG we re-purpose an existing dataset for another task: dialog state tracking, which includes a large and rich schema spanning multiple different attributes, including information about the domain, user intent, and slot descriptions. ང་ཚོས་རང་ཉིད་ཀྱི་སྐད་རིགས་ཀྱི་མིག་གཟུགས་རིས་མིན་འདུག་གི་མཐུན་རིམ་སྣེ་མང་པོ་ཞིག་གི་ཡིག་འཕྲིན་དང་། ཡང་ན་ཕལ་ཆེན་རྩ་བ་སྒྲིག་ཆ་འཕྲིན་དེ་བསྡ\nWe also conduct experiments comparing model performance on seen versus unseen domains, and present a human evaluation demonstrating high ratings for overall output quality.', 'he': 'Neural network based approaches to data-to-text natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation.  כדי להקל את האימונים של דוגמני רשת עצביות, מחקרים יצרו קבוצות מידע גדולות של מילים זוגות ומציגות המשמעות שלהם. עם זאת, יצירת קבוצות מידע כאלה היא משימה קשה, והן מורכבות בעיקר ממוצאות משמעות פשוטות מורכבות מסימנים של קופסאות ומערכים להבין. הייצגות הללו לא כוללות מידע קונטוקטואלי שמערכת NLG יכולה להשתמש בו בניסיון לגנרליזציה, כמו מידע שטח ותיאורים של נקודות ומערכים. בעיתון הזה, אנו מציגים את המשימה החדשה של הגנרציה של שפות טבעיות מונחות על סגמה (SG-NLG). Here, the goal is still to generate a natural language prompt, but in SG-NLG, the input MRs are paired with rich schemata providing contextual information.  כדי ליצור קבוצת נתונים עבור SG-NLG אנו משתמשים מחדש קבוצת נתונים קיימת עבור משימה אחרת: מעקב מצב הדיולוגים, שכלול תכנית גדולה ועשירה שמרחבת מספר תכונות שונות, כולל מידע על התחום, כוונת המשתמש, ותיאורי קופסאות. אנחנו מאמן דוגמנים חדשים לדור שפת טבעית עצבית על קבוצת הנתונים הזו, ומראים שבמקרים רבים, כולל מידע רשת עשירה מאפשר לדוגמנים שלנו לייצר תוצאות איכות גבוהה יותר גם בנוגע לסמנטיקה וגוון.\nאנחנו גם מבצעים ניסויים בהשוואה ביצועים מודל על שטחים נראים מול שטחים בלתי נראים, ומציגים עריכה אנושית שמוכיחת עריכות גבוהות לאיכות יציאה כללית.'}
{'en': 'Neural NLG for Methodius : From RST Meaning Representations to Texts', 'ar': 'NLG العصبية لـ Methodius: من تمثيلات المعنى RST إلى النصوص', 'pt': 'NLG Neural para Metódio: Das Representações de Significado RST aos Textos', 'es': 'NLG neuronal para Metodio: de las representaciones de significado de RST a los textos', 'fr': 'NLG neuronal pour Methodius\xa0: des représentations de signification RST aux textes', 'zh': 'Methodius之神经NLG:以RST义示文本', 'ja': 'メトディウス用ニューラルNLG ： RSTの意味表現からテキストへ', 'ru': 'Нейронная NLG для Methodius: от представлений значений RST к текстам', 'hi': 'Methodius के लिए तंत्रिका NLG: RST अर्थ से ग्रंथों के लिए प्रतिनिधित्व', 'ga': 'NLG NLG do Methodius: Ó Léirithe Brí RST go Téacsanna', 'ka': 'ნეიროლური NLG მეტედიოსებისთვის: RST ნიშნავულ გამოსახულებებიდან ტექსტისთვის', 'hu': 'Neurális NLG a módszerhez: az RST jelentési reprezentációktól a szövegekig', 'el': 'Νευρική ΝΛΓ για τον Μεθοδίο: Από τις αναπαραστάσεις σημασιολογίας στα κείμενα', 'it': 'NLG neurale per Metodio: dalle rappresentazioni di significato RST ai testi', 'kk': 'Методиус үшін нейрондық NLG: RST дегеннен мәтіндерге ауыстырулары', 'lt': 'Neuralinė NLG metodui: nuo RST reikšmingų atstovavimų iki tekstų', 'mk': 'Неурална NLG за Методиус: Од RST значење на претставувања до тексти', 'ms': 'NLG saraf untuk Kaedah: Dari Perwakilan Maksud RST ke Teks', 'ml': 'മെറ്റോഡിയസിനുള്ള നെയുറല്\u200d NLG: RST മുതല്\u200d പദാവലികള്\u200dക്കുള്ള പ്രതിനിധികള്\u200d', 'mt': 'NLG newrali għall-Metodu: Minn Rappreżentazzjonijiet tat-tifsira RST sat-Testi', 'mn': 'Методиусын мэдрэлийн NLG: RST гэсэн утгатай үзүүлэлт нь текст руу', 'no': 'Neural NLG for Methodius: Fra RST Meaning Representations to Texts', 'pl': 'Neuronalne NLG dla Metody: Od reprezentacji znaczenia RST do tekstów', 'sr': 'Neuralni NLG za Metodij: od RST značajnih predstavljanja na tekst', 'ro': 'NLG neural pentru metodiu: de la reprezentările semnificației RST la texte', 'si': 'විධානය සඳහා නිර්මාණික NLG: from RST means repositions to texts', 'so': 'Aqoonsiga guud ee Methodius: RST macnaheedka loogu jeedo Texts', 'sv': 'Neural NLG för Methodius: Från RST Meaning Representations till Texter', 'ta': 'முறைமைக்கான நெருக்கல் NLG: RST லிருந்து உரைக்கு பிரதிநிதிகள்', 'ur': 'مٹیڈیوس کے لئے NLG: RST منظور معلومات سے ٹیکسٹ تک', 'uz': 'Name', 'vi': 'Neural NLI for Methoius: from RST meaning Representation to Texts', 'bg': 'Нервна НЛГ за Методий: От представянето на значението на RST до текстове', 'nl': 'Neural NLG voor Methodius: Van RST betekenisrepresentaties naar Teksten', 'da': 'Neural NLG for Methodius: Fra RST betydning repræsentationer til tekster', 'hr': 'Neuralni NLG za Methodius: Od RST značajnih predstavljanja na tekste', 'de': 'Neuronale NLG für Methodius: Von RST Bedeutungsdarstellungen zu Texten', 'id': 'NLG Neural for Methodius: From RST Meaning Representations to Texts', 'ko': 'Methodius의 신경 NLG: RST 의미 표징에서 텍스트로', 'fa': 'NLG عصبی برای Methodius: از RST یعنی نمایندگان به متن', 'sw': 'NLG ya NLG kwa ajili ya Methodius: Kutoka RST Inamaanisha Maandamano ya Maandishi', 'af': 'Neurale NLG vir Methodius: Van RST betekening voorstellings na teks', 'tr': 'Neural NLG for Methodius: From RST Meaning Representations to Texts', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'az': 'Metodius 칲칞칲n n칬ral NLG: RST m톛s톛l톛sind톛n m톛s톛l톛l톛r톛', 'hy': 'Մեթոդի նյարդային ՆԵԳ՝ ՌՍԹ նշանակության ներկայացումներից մինչև տեքստներ', 'bn': 'মেথোডিয়াসের জন্য নিউরেল এনএলজি: RST থেকে টেক্সট পর্যন্ত প্রতিনিধি', 'bs': 'Neuralni NLG za Methodius: od RST značajnih predstavljanja na tekste', 'cs': 'Neurální NLG pro Metoděj: Od reprezentací RST významu k textům', 'et': 'Neuraalne NLG Methodiuse jaoks: RST tähendusest tekstideni', 'ca': 'NLG neural for Methodius: From RST Meaning Representations to Texts', 'fi': 'Neural NLG for Methodius: RST Meaning Representations to Texts', 'sq': 'NLG neuronal për Metodius: Nga përfaqësimet e kuptueshme RST në tekste', 'jv': 'Neral NLG kanggo Methodium:', 'he': 'NLG neural for Methodius: From RST Meaning Representations to Texts', 'sk': 'Nevralni NLG za Metodij: Od predstavitev pomena RST do besedil', 'ha': 'KCharselect unicode block name', 'bo': 'Neural NLG for Methodius: From RST Meaning Representations to Texts'}
{'en': 'While classic NLG systems typically made use of hierarchically structured content plans that included discourse relations as central components, more recent neural approaches have mostly mapped simple, flat inputs to texts without representing discourse relations explicitly. In this paper, we investigate whether it is beneficial to include discourse relations in the input to neural data-to-text generators for texts where discourse relations play an important role. To do so, we reimplement the sentence planning and realization components of a classic NLG system, Methodius, using LSTM sequence-to-sequence (seq2seq) models. We find that although seq2seq models can learn to generate fluent and grammatical texts remarkably well with sufficiently representative Methodius training data, they can not learn to correctly express Methodius’s similarity and contrast comparisons unless the corresponding RST relations are included in the inputs. Additionally, we experiment with using self-training and reverse model reranking to better handle train / test data mismatches, and find that while these methods help reduce content errors, it remains essential to include discourse relations in the input to obtain optimal performance.', 'ar': 'في حين أن أنظمة NLG الكلاسيكية تستخدم عادةً خطط المحتوى المهيكلة بشكل هرمي والتي تضمنت علاقات الخطاب كمكونات مركزية ، فإن الأساليب العصبية الأكثر حداثة قد رسمت في الغالب مدخلات بسيطة ومسطحة للنصوص دون تمثيل علاقات الخطاب بشكل صريح. في هذه الورقة ، نتحرى ما إذا كان من المفيد تضمين علاقات الخطاب في المدخلات لمولدات البيانات العصبية إلى نص للنصوص حيث تلعب العلاقات الخطابية دورًا مهمًا. للقيام بذلك ، قمنا بإعادة تنفيذ تخطيط الجملة ومكونات الإدراك لنظام NLG الكلاسيكي ، Methodius ، باستخدام نماذج LSTM من التسلسل إلى التسلسل (seq2seq). وجدنا أنه على الرغم من أن نماذج seq2seq يمكن أن تتعلم إنشاء نصوص نحوية بطلاقة بشكل ملحوظ مع بيانات تدريب Methodius تمثيلية بشكل كافٍ ، إلا أنها لا تستطيع تعلم التعبير بشكل صحيح عن مقارنات التشابه والتباين في Methodius ما لم يتم تضمين علاقات RST المقابلة في المدخلات. بالإضافة إلى ذلك ، نجرب استخدام التدريب الذاتي وإعادة ترتيب النموذج العكسي للتعامل بشكل أفضل مع عدم تطابق بيانات التدريب / الاختبار ، ووجدنا أنه بينما تساعد هذه الأساليب في تقليل أخطاء المحتوى ، يظل من الضروري تضمين علاقات الخطاب في المدخلات للحصول على الأداء الأمثل.', 'pt': 'Enquanto os sistemas NLG clássicos normalmente faziam uso de planos de conteúdo hierarquicamente estruturados que incluíam relações discursivas como componentes centrais, as abordagens neurais mais recentes mapearam principalmente entradas simples e planas para textos sem representar relações discursivas explicitamente. Neste artigo, investigamos se é benéfico incluir relações discursivas na entrada de geradores neurais de dados para texto para textos onde as relações discursivas desempenham um papel importante. Para isso, reimplementamos os componentes de planejamento e realização de sentenças de um sistema NLG clássico, Methodius, usando modelos LSTM sequência a sequência (seq2seq). Descobrimos que, embora os modelos seq2seq possam aprender a gerar textos fluentes e gramaticais notavelmente bem com dados de treinamento de Methodius suficientemente representativos, eles não podem aprender a expressar corretamente as comparações de semelhança e contraste de Methodius, a menos que as relações RST correspondentes sejam incluídas nas entradas. Além disso, experimentamos o uso de autotreinamento e reclassificação de modelo reverso para lidar melhor com incompatibilidades de dados de treinamento/teste e descobrimos que, embora esses métodos ajudem a reduzir erros de conteúdo, continua sendo essencial incluir relações de discurso na entrada para obter um desempenho ideal.', 'fr': "Alors que les systèmes de GNL classiques utilisaient généralement des plans de contenu structurés hiérarchiquement qui incluaient les relations de discours comme composants centraux, les approches neuronales plus récentes ont pour la plupart mappé des entrées simples et plates à des textes sans représenter explicitement les relations de discours. Dans cet article, nous étudions s'il est avantageux d'inclure les relations de discours dans l'entrée des générateurs de données neuronales en texte pour les textes où les relations de discours jouent un rôle important. Pour ce faire, nous réimplémentons les composants de planification et de réalisation de phrases d'un système classique de GNL, Methodius, à l'aide de modèles séquence-à-séquence LSTM (seq2seq). Nous trouvons que, bien que les modèles seq2seq puissent apprendre à générer des textes fluides et grammaticaux remarquablement bien avec des données d'entraînement Methodius suffisamment représentatives, ils ne peuvent pas apprendre à exprimer correctement les comparaisons de similitude et de contraste de Methodius à moins que les relations RST correspondantes ne soient incluses dans les entrées. . De plus, nous expérimentons l'utilisation de l'auto-apprentissage et du reclassement des modèles inverses pour mieux gérer les incohérences entre les données train/test, et nous avons constaté que, bien que ces méthodes aident à réduire les erreurs de contenu, il reste essentiel d'inclure des relations de discours dans les entrées pour obtenir des performances optimales.", 'es': 'Mientras que los sistemas clásicos de NLG solían utilizar planes de contenido estructurados jerárquicamente que incluían las relaciones del discurso como componentes centrales, los enfoques neuronales más recientes han mapeado en su mayoría entradas simples y planas a los textos sin representar explícitamente las relaciones del discurso. En este artículo, investigamos si es beneficioso incluir las relaciones del discurso en la entrada a los generadores neuronales de datos a texto para textos en los que las relaciones discursales desempeñan un papel importante. Para hacerlo, reimplementamos los componentes de planificación y realización de oraciones de un sistema NLG clásico, Methodius, utilizando modelos LSTM secuencia a secuencia (seq2seq). Descubrimos que, aunque los modelos seq2seq pueden aprender a generar textos gramaticales y fluidos notablemente bien con datos de entrenamiento de Metodio suficientemente representativos, no pueden aprender a expresar correctamente las comparaciones de similitud y contraste de Metodio a menos que las relaciones RST correspondientes se incluyan en las entradas . Además, experimentamos con el uso del autoaprendizaje y la reorganización inversa del modelo para manejar mejor los desajustes de datos de entrenamiento/prueba, y descubrimos que, si bien estos métodos ayudan a reducir los errores de contenido, sigue siendo esencial incluir relaciones de discurso en la entrada para obtener un rendimiento óptimo.', 'ja': '古典的なNLGシステムは、典型的には、話題関係を中心的な構成要素として含む階層構造化されたコンテンツプランを使用していたが、より最近のニューラルアプローチでは、話題関係を明示的に表すことなく、ほとんどの場合、単純で平坦な入力をテキストにマッピングしている。 本稿では，神経データ対テキストジェネレータへの入力に，神経データ対テキストが重要な役割を果たすテキストについて，神経データ対テキストジェネレータへの入力に神経データ関係を含めることが有益であるかどうかを検討する。 これを行うために、我々は、LSTMシーケンスツーシーケンス（ seq 2 seq ）モデルを使用して、古典的なNLGシステムであるメトディウスの文章計画および実現コンポーネントを再実装する。 Seq 2 seqモデルは、十分に代表的なメトディウスのトレーニングデータで流暢で文法的なテキストを非常にうまく生成することを学ぶことができますが、対応するRST関係が入力に含まれていない限り、メトディウスの類似性とコントラストの比較を正しく表現することを学ぶことはできません。 さらに、自己訓練とリバースモデルリランキングを使用して、トレイン/テストデータの不一致をより適切に処理することを実験し、これらの方法はコンテンツエラーを減らすのに役立ちますが、最適なパフォーマンスを得るためには、インプットに話題関係を含めることが依然として不可欠であることを発見しました。', 'zh': '虽经典之NLG,统用层构之计,兼言语以为心组件,而近神经之法多将简易,扁平输映于文本,而未明示言语也。 本文者,论其要神经数其生成器输之有益也。 是以LSTM序于序(seq2seq)重成经典NLG统Methodius句规成组件。 虽 seq2seq 模可以善学流利之语法,足以代表性 Methodius 练数,不能正 Methodius 之相似性,非输之 RST 也。 又试用自修及反向模形更排名以善处之/测试数据不配,虽有损益之谬,而含语于输入之中,以获得最佳性为重。', 'ru': 'В то время как классические системы NLG обычно использовали иерархически структурированные планы контента, которые включали отношения дискурса в качестве центральных компонентов, более поздние нейронные подходы в основном отображали простые, плоские входы в тексты, не представляя отношения дискурса явно. В этой статье мы исследуем, целесообразно ли включать отношения дискурса во входные данные нейронных генераторов данных в текст для текстов, где отношения дискурса играют важную роль. Для этого мы повторно реализуем компоненты планирования и реализации предложений классической системы NLG, Methodius, используя модели последовательности-последовательности LSTM (seq2seq). Мы обнаружили, что, хотя модели seq2seq могут научиться генерировать свободно и грамматические тексты удивительно хорошо с достаточно репрезентативными обучающими данными Мефодия, они не могут научиться правильно выражать сравнения сходства и контрастности Мефодия, если соответствующие отношения RST не включены в входные данные. Кроме того, мы экспериментируем с использованием самообучения и перестановки реверсивных моделей для лучшей обработки несоответствий данных поезда/тестирования и обнаруживаем, что, хотя эти методы помогают уменьшить ошибки контента, по-прежнему важно включать в входные данные отношения дискурса для достижения оптимальной производительности.', 'hi': 'जबकि क्लासिक एनएलजी सिस्टम ने आमतौर पर पदानुक्रमित रूप से संरचित सामग्री योजनाओं का उपयोग किया, जिसमें केंद्रीय घटकों के रूप में प्रवचन संबंधों को शामिल किया गया था, हाल के तंत्रिका दृष्टिकोणों ने ज्यादातर स्पष्ट रूप से प्रवचन संबंधों का प्रतिनिधित्व किए बिना ग्रंथों के लिए सरल, फ्लैट इनपुट मैप किए हैं। इस पेपर में, हम जांच करते हैं कि क्या ग्रंथों के लिए तंत्रिका डेटा-टू-टेक्स्ट जनरेटर के इनपुट में प्रवचन संबंधों को शामिल करना फायदेमंद है जहां प्रवचन संबंध एक महत्वपूर्ण भूमिका निभाते हैं। ऐसा करने के लिए, हम LSTM अनुक्रम-टू-अनुक्रम (seq2seq) मॉडल का उपयोग करके एक क्लासिक NLG सिस्टम, Methodius के वाक्य योजना और प्राप्ति घटकों को फिर से लागू करते हैं। हम पाते हैं कि यद्यपि seq2seq मॉडल पर्याप्त रूप से प्रतिनिधि मेथोडियस प्रशिक्षण डेटा के साथ उल्लेखनीय रूप से अच्छी तरह से धाराप्रवाह और व्याकरणिक ग्रंथों को उत्पन्न करना सीख सकते हैं, वे मेथोडियस की समानता और विपरीत तुलनाओं को सही ढंग से व्यक्त करना नहीं सीख सकते हैं जब तक कि संबंधित आरएसटी संबंधों को इनपुट में शामिल नहीं किया जाता है। इसके अतिरिक्त, हम ट्रेन / परीक्षण डेटा बेमेल को बेहतर ढंग से संभालने के लिए आत्म-प्रशिक्षण और रिवर्स मॉडल रीरैंकिंग का उपयोग करने के साथ प्रयोग करते हैं, और पाते हैं कि जब ये विधियां सामग्री त्रुटियों को कम करने में मदद करती हैं, तो इष्टतम प्रदर्शन प्राप्त करने के लिए इनपुट में प्रवचन संबंधों को शामिल करना आवश्यक है।', 'ga': 'Cé gur bhain córais chlasaiceacha NLG úsáid go hiondúil as pleananna ábhair struchtúrtha ordlathach a chuimsigh caidreamh dioscúrsa mar chomhpháirteanna lárnacha, is mó a rinne cur chuige néarúil níos déanaí a mhapáil ionchuir shimplí, chomhréidh chuig téacsanna gan caidreamh dioscúrsa a léiriú go sainráite. Sa pháipéar seo, déanaimid iniúchadh ar cibé an bhfuil sé tairbheach caidreamh dioscúrsa a áireamh san ionchur chuig gineadóirí néaracha sonraí-go-téacs do théacsanna a bhfuil ról tábhachtach ag caidreamh dioscúrsa iontu. Chun é sin a dhéanamh, déanaimid athchur ar na comhpháirteanna pleanála agus réadaithe pianbhreithe de chóras clasaiceach NLG, Methodius, ag baint úsáide as samhlacha seicheamh-go-seicheamh (seq2seq) LSTM. Faighimid amach cé gur féidir le samhlacha seq2seq foghlaim conas téacsanna líofa agus gramadaí a ghiniúint go han-mhaith le sonraí oiliúna Methodius atá ionadaíoch go leor, ní féidir leo a fhoghlaim conas comparáidí cosúlachta agus codarsnachta Methodius a chur in iúl i gceart mura bhfuil na caidrimh RST comhfhreagracha san áireamh sna hionchuir. Ina theannta sin, déanaimid triail as féin-oiliúint agus athrangú samhlacha droim ar ais chun mí-oiriúnuithe sonraí traenach/tástála a láimhseáil ar bhealach níos fearr, agus aimsímid cé go gcuidíonn na modhanna seo le hearráidí ábhair a laghdú, tá sé ríthábhachtach caidreamh dioscúrsa a áireamh san ionchur chun an fheidhmíocht is fearr a bhaint amach.', 'ka': 'თუმცა კლასიკური NLG სისტემები იერაქტიკურად სტრუქტურებული მხოლოდ გამოყენებულია, რომლებიც კონტრალური კომპონენტების შესახებ იყო, უფრო ახლა ნეიროლური შესახებ უფრო მხოლოდ დაკაპოთ ამ დომენტში, ჩვენ შევხედავთ თუ ბეჭიროა დეკურსური შესახებ ჩატვირთვაში ნეიროლური მონაცემების ტექსტის გენერატორის შესახებ, სადაც დეკურსური შესახებ მნიშვნელოვანი რომელიც გავაკეთებთ, ჩვენ კლასიკური NLG სისტემის პროგრამის და რეალიზაციის კომპონენტების კომპონენტების გადავიყენებთ, რომელიც LSTM-სკენესიკენესიკენესიკენესიკენესიკენე ჩვენ აღმოჩნეთ, რომ თუმცა seq2seq მოდელები შეუძლია ვისწავლოთ ფლუნტური და გრამიტური ტექსტის წარმოიქმნა მნიშვნელოვანი მარტივისთან განაკეთებული მონაცემებით, ისინი არ შეუძლია ვისწავლოთ მარტივისთან სწორად გამოსახულებ დამატებით, ჩვენ ექსპერიმენტირებით თავისუფლიო განსწავლების გამოყენებით და შემდეგ მოდელის გამოყენებით, რომელიც უკეთესი განსწავლების/ტესტის მონაცემების შემდეგების შემდეგების შემდეგების შემდეგება, და', 'hu': 'Míg a klasszikus NLG rendszerek általában hierarchikusan strukturált tartalomterveket használtak, amelyek központi elemként tartalmazták a diskurzus kapcsolatokat, a legújabb neurális megközelítések többnyire egyszerű, lapos bemeneteket térképeztek fel a szövegekhez, anélkül, hogy kifejezetten reprezentálnák a diskurzus kapcsolatokat. Ebben a tanulmányban azt vizsgáljuk, hogy előnyös-e a diskurzus kapcsolatok beépítése a neurális adat-szöveg generátorok bemenetébe olyan szövegek esetében, ahol a diskurzus kapcsolatok fontos szerepet játszanak. Ehhez egy klasszikus NLG rendszer, a Methodius mondattervezési és megvalósítási komponenseit újra alkalmazzuk LSTM szekvencia-szekvencia (seq2seq) modellekkel. Megállapítjuk, hogy bár a seq2seq modellek rendkívül jól tudják megtanulni folyékony és nyelvtani szövegeket generálni kellően reprezentatív Methodius képzési adatokkal, nem tudják megfelelően kifejezni Methodius hasonlóságát és kontraszt összehasonlítását, hacsak a megfelelő RST kapcsolatokat nem tartalmazzák a bemenetekben. Ezenkívül kísérletezünk az önképzéssel és a fordított modell átrendezéssel a vonat/teszt adatok hiányosságainak jobb kezelése érdekében, és megállapítjuk, hogy miközben ezek a módszerek segítenek csökkenteni a tartalomhibákat, alapvető fontosságú továbbra is, hogy az optimális teljesítmény elérése érdekében a diskurzus kapcsolatokat bevonjuk a bemenetbe.', 'el': 'Ενώ τα κλασικά συστήματα χρησιμοποιούν συνήθως ιεραρχικά δομημένα σχέδια περιεχομένου που περιελάμβαναν σχέσεις λόγου ως κεντρικά συστατικά, οι πιο πρόσφατες νευρωνικές προσεγγίσεις έχουν ως επί το πλείστον χαρτογραφήσει απλές, επίπεδες εισόδους σε κείμενα χωρίς να αντιπροσωπεύουν ρητά τις σχέσεις λόγου. Στην παρούσα εργασία, διερευνούμε αν είναι ωφέλιμο να συμπεριληφθούν οι σχέσεις λόγου στην εισαγωγή σε νευρωνικές γεννήτριες δεδομένων-κειμένου για κείμενα όπου οι σχέσεις λόγου διαδραματίζουν σημαντικό ρόλο. Για να γίνει αυτό, επανεπεξεργάζουμε τα συστατικά σχεδιασμού και υλοποίησης προτάσεων ενός κλασικού συστήματος, του Μεθοδίου, χρησιμοποιώντας μοντέλα ακολουθίας σε ακολουθία (seq2seq). Διαπιστώνουμε ότι παρόλο που τα μοντέλα μπορούν να μάθουν να παράγουν άπταιστα και γραμματικά κείμενα αξιοσημείωτα καλά με αρκετά αντιπροσωπευτικά δεδομένα εκπαίδευσης Μεθοδίου, δεν μπορούν να μάθουν να εκφράζουν σωστά την ομοιότητα και τις συγκρίσεις αντίθεσης του Μεθοδίου εκτός αν οι αντίστοιχες σχέσεις περιλαμβάνονται στις εισόδους. Επιπλέον, πειραματιζόμαστε με τη χρήση αυτοκατάρτισης και αντίστροφης κατάταξης μοντέλων για να αντιμετωπίσουμε καλύτερα τις αναπροσαρμογές δεδομένων τρένων/δοκιμών, και διαπιστώνουμε ότι ενώ αυτές οι μέθοδοι βοηθούν στη μείωση των σφαλμάτων περιεχομένου, παραμένει απαραίτητο να συμπεριληφθούν σχέσεις συζήτησης στην εισαγωγή για να επιτευχθεί η βέλτιστη απόδοση.', 'it': "Mentre i classici sistemi NLG in genere utilizzavano piani di contenuto strutturati gerarchicamente che includevano le relazioni del discorso come componenti centrali, gli approcci neurali più recenti hanno principalmente mappato input semplici e piatti ai testi senza rappresentare esplicitamente le relazioni del discorso. In questo articolo, esaminiamo se sia utile includere le relazioni di discorso nell'input ai generatori neurali di dati-testo per i testi in cui le relazioni di discorso svolgono un ruolo importante. Per fare ciò, reimplettiamo le componenti di pianificazione e realizzazione di frasi di un sistema NLG classico, Methodius, utilizzando modelli sequenziali LSTM (seq2Seq). Troviamo che, sebbene i modelli seq2seq possano imparare a generare testi fluenti e grammaticali notevolmente bene con dati di formazione Methodius sufficientemente rappresentativi, essi non possono imparare a esprimere correttamente la somiglianza e i confronti di contrasto di Methodius a meno che le corrispondenti relazioni RST non siano incluse negli input. Inoltre, sperimentiamo con l'utilizzo di auto-training e reverse model resenking per gestire meglio le disallineazioni dei dati treno/test, e scopriamo che, mentre questi metodi aiutano a ridurre gli errori di contenuto, rimane essenziale includere le relazioni di discorso nell'input per ottenere prestazioni ottimali.", 'mk': 'Иако класичните НЛГ системи обично ги користат хиерархички структурираните планови за содржина кои вклучуваа дискурсни односи како централни компоненти, понатамошните неурални пристапи претежно ги мапираа едноставните, рамни влози во текстовите без експлицитно да ги претставуваат диск Во овој весник, истражуваме дали е корисно да се вклучат дискурсните односи во влогот на генераторите на неурални податоци до текст за тексти каде дискурсните односи имаат важна улога. За да го направиме тоа, ги преимплементираме компонентите на планирање и реализација на речениците на класичен NLG систем, Методиус, користејќи ги моделите LSTM секвенца до секвенца (seq2seq). Најдовме дека иако моделите seq2seq можат да научат да генерираат течни и граматични тексти извонредно добро со доволно репрезентативни податоци за обука на Методиус, тие не можат да научат правилно да ја изразат сличноста на Методиус и споредбите на контраст освен ако соодветните РСТ односи не се вклучени Покрај тоа, експериментираме со употреба на самообука и повторно враќање на моделот за подобро да се справи со несоодветностите на податоците од возот/тестот, и откриваме дека додека овие методи помогнат во намалувањето на грешките во содржината, останува суштинско да се вклучат дискурсните одн', 'lt': 'Nors klasikinėse NLG sistemose paprastai naudojami hierarchiškai struktūrizuoti turinio planai, į kuriuos diskursiniai santykiai buvo įtraukti kaip pagrindiniai komponentai, naujausi neurologiniai metodai daugiausia apibūdino paprastus ir plokščius tekstų įvedimus aiškiai nenurodant diskursinių santykių. Šiame dokumente tiriame, ar naudinga įtraukti diskursinius santykius į įrašą į nervinių duomenų generatorius tekstams, kuriuose diskursiniai santykiai atlieka svarbų vaidmenį. Tuo tikslu iš naujo įgyvendiname klasikinės NLG sistemos Metodius sakinių planavimo ir realizavimo komponentus, naudojant LSTM sekos po sekos (seq2seq) modelius. Mes manome, kad nors seq2seq modeliai gali išmokti gerai gaminti skystus ir gramatinius tekstus su pakankamai reprezentatyviais Metodo mokymo duomenimis, jie negali išmokti teisingai išreikšti Metodo panašumą ir kontrastų palyginimus, nebent atitinkami RST santykiai yra įtraukti į įvedimus. Be to, eksperimentuojame naudojant savarankišką mokymą ir atvirkštinį model į, kad būtų geriau tvarkomi traukinio ir bandymų duomenų neatitikimai, ir nustatome, kad nors šie metodai padeda sumažinti turinio klaidas, vis dar labai svarbu įtraukti diskursinius santykius į įvestį siekiant optimalių rezultatų.', 'kk': 'Классикалық NLG жүйелері кәдімгі дискурстар қатынасын ортақ компоненттер ретінде қолданып, иерархиялық құрылған мазмұның пландарын қолдануға болады, жаңа невралдық қатынастары көбінесе қарапайым, көбінесе дискурстар қатынасын көрсе Бұл қағазда, дискурстар қатынастарының маңызды роль орындалатын мәтіндерге невралдық деректер мен мәтіндерге қатынастарды енгізу мүмкіндігін зерттеуде болады. Бұл үшін, біз классикалық NLG жүйесінің, Методиусының, LSTM ретінде ретінде (seq2seq) үлгілерін қолданатын сөйлемелерді планировау мен реализациялау компоненттерін қайта жасадық. Біз seq2seq үлгілері жылдамдық және грамматикалық мәтіндерді жеткілікті методиус оқыту деректерімен жақсы жасауға үйрене алатын болса да, олар методиус ұқсастығын және контрастығын дұрыс көрсетуді үйрене алмайды. Сәйкес RST қатынасы келтірілген Сонымен қатар, біз өзімізді оқыту және қайтару үлгісін қолдану үшін тескерту үлгісін қайтаруға жұмыс істеп, олар мазмұның қатесін азайту көмектеседі. Осы әдістер оқыту үшін оптимал істеу үшін келтірілген', 'ms': 'Sementara sistem NLG klasik biasanya menggunakan rancangan kandungan struktur secara hierarkis yang termasuk hubungan diskors sebagai komponen pusat, pendekatan saraf yang baru-baru ini kebanyakan telah memetakan input mudah, rata ke teks tanpa mewakili hubungan diskors secara jelas. Dalam kertas ini, kita menyelidiki sama ada ia berguna untuk menyertakan hubungan diskors dalam input ke generator data-ke-teks saraf untuk teks di mana hubungan diskors bermain peran penting. Untuk melakukannya, kita tambahkan semula perancangan kalimat dan komponen realizasi sistem NLG klasik, Metodius, menggunakan model LSTM jujukan-ke-jujukan (seq2seq). Kami mendapati bahawa walaupun model seq2seq boleh belajar untuk menghasilkan teks fluent dan grammatik dengan sangat baik dengan data pelatihan Metodius yang mewakili cukup, mereka tidak boleh belajar untuk mengekspresikan dengan betul perbandingan persamaan Metodius dan kontras kecuali hubungan RST yang sepadan termasuk dalam input. Selain itu, kami eksperimen dengan menggunakan latihan diri dan mengubah model mengikat semula untuk mengendalikan lebih baik ketidakpadanan data kereta api/ujian, dan mencari bahawa walaupun kaedah ini membantu mengurangi ralat kandungan, ia tetap penting untuk menyertai hubungan diskors dalam input untuk mendapatkan prestasi optimal.', 'mt': 'While classic NLG systems typically made use of hierarchically structured content plans that included discourse relations as central components, more recent neural approaches have mostly mapped simple, flat inputs to texts without representing discourse relations explicitly.  F’dan id-dokument, ninvestigaw jekk huwiex ta’ benefiċċju li jiġu inklużi r-relazzjonijiet ta’ diskors fl-input għal ġeneraturi ta’ dejta newrali mat-test għal testi fejn ir-relazzjonijiet ta’ diskors għandhom rwol importanti. Biex nagħmlu dan, a ħna nimplimentaw mill-ġdid il-komponenti tal-ippjanar u r-realizzazzjoni tas-sentenzi ta’ sistema klassika NLG, Methodius, bl-użu ta’ mudelli ta’ sekwenza għal sekwenza LSTM (seq2seq). Issibu li għalkemm il-mudelli seq2seq jistgħu jitgħallmu jiġġeneraw testi fluwenti u grammatiċi b’mod notevolment tajjeb b’dejta ta’ taħriġ tal-Metodu rappreżentattiva biżżejjed, ma jistgħux jitgħallmu jesprimu b’mod korrett is-similarità tal-Metodu u t-tqabbil tal-kuntrast sakemm ir-relazzjonijiet RST korrispondenti ma jkunux inklużi fl-inputs. Barra minn hekk, aħna qed nagħmlu esperimenti bl-użu ta’ taħriġ awtonomu u l-mudell tar-rivers li jerġa’ jinvolvi ruħna biex jimmaniġġjaw aħjar id-diskrepanzi bejn id-dejta tal-ferrovija u t-testijiet, u nsibu li filwaqt li dawn il-metodi jgħinu jnaqqsu l-iżbalji fil-kontenut, għadu essenzjali li jiġu inklużi relazzjonijiet diskorsi fl-', 'mn': 'Хэдийгээр классик НЛГ системүүд ихэвчлэн төв компонент болгон ярианы холбоотой байдлаар бүтээгдэхүүний төлөвлөгөөг ашигладаг ч саяхан мэдрэлийн ойлголт ихэвчлэн энгийн, энгийн харилцааны харилцааны харилцааныг илэрхийлж чаддаггүй текст руу хөрөнг Энэ цаасан дээр бид ярианы харилцаа чухал үүрэг тоглодог текстүүдэд мэдрэлийн өгөгдлийн болон текстүүдэд ярианы харилцаа оруулах хэрэгтэй эсэхийг судалж байна. Үүнийг хийхэд бид классик NLG системийн хэмжээсүүдийг LSTM дарааллаас дарааллаар (seq2seq) загварыг ашиглан дахин төлөвлөе. Бид нар seq2seq загварууд шингэн, грамматикийн текст бүтээж чадна гэхдээ методиус суралцах өгөгдлийг хангалттай сайн ойлгохыг суралцаж чадахгүй ч тэд методиусын адилхан болон эсрэг харьцуулалтыг зөв илэрхийлж чадахгүй. Мөн бид өөрсдийгөө суралцах болон эргүүлэх загварыг илүү сайн удирдах боломжтой боломжтой мэдээллийн буруу байдлыг ашиглан туршилт хийж, эдгээр арга нь content errors багасгах тулд хамгийн чухал зүйл бий.', 'no': 'Mens klassiske NLG-systemer vanlegvis brukte av hierarkisk strukturerte innhaldsplanar som inkluderer diskursrelasjonar som sentralkomponentar, har det mest nyere nøyraltilnærmingar kartert enkle, flate inndata til tekstar utan å representera diskursrelasjonar eksplisitt. I denne papira undersøker vi om det er nyttig å inkludere diskursrelasjonar i inndata til neirale data- til- tekstgeneratorer for tekstar der diskursrelasjonar speler ein viktig rolle. For å gjera det, vi bytter på nytt setningsplanning og realiseringskomponenten av ein klassisk NLG-system, Methodius, med LSTM-sekvens-to-sekvens-modeller (seq2seq). Vi finn at selv om seq2seq-modeller kan lære å laga fluent og grammatiske tekstar merkelig godt med nok reprezentativ metodius-treningsdata, kan dei ikkje lære å rett uttrykke metodius liknande og kontrastsammenlikningar med mindre dei tilsvarande RST-relasjonane er inkludert i inndata. I tillegg eksperimenterer vi med å bruka sjølvøvinga og omvenda modell som gjer tilbake til betre handtering av treff/test-data mismatch, og finn at mens desse metodane hjelper å redusera innhaldsfeil, er det viktig å inkludere diskursrelasjonar i inndata for å få optimal utvikling.', 'ml': 'ക്ലാസിക്ക് NLG സിസ്റ്റത്തിന്റെ സാധാരണയായി ഹിയെരാര്\u200dച്ചിക്കക്കായി നിര്\u200dമ്മിക്കപ്പെട്ട വസ്തുക്കളുടെ പദ്ധതികള്\u200d ഉപയോഗിക്കുമ്പോള്\u200d സംസാരം നടപ്പിലുള്ള ബന്ധ ഈ പത്രത്തില്\u200d, സംസാരിക്കുന്ന ബന്ധങ്ങള്\u200d ഇന്\u200dപുട്ടില്\u200d ഉള്\u200dപ്പെടുത്തുന്നതില്\u200d പ്രധാനപ്പെട്ടതാണോ എന്ന് ഞങ്ങള്\u200d അന്വേഷിക്കുന്നു. വാക്ക To do so, we reimplement the sentence planning and realization components of a classic NLG system, Methodius, using LSTM sequence-to-sequence (seq2seq) models.  സെക്ക്2സെക്ക് മോഡലുകള്\u200dക്ക് ഫ്ലൈന്\u200dറും ഗ്രാമാറ്റിക്കല്\u200d പദാവലികള്\u200d ഉണ്ടാക്കാന്\u200d പഠിക്കാന്\u200d കഴിയുമെങ്കിലും മതിയായ മെതോഡിയസ് പരിശീലന വിവരങ്ങള്\u200dക്ക് പ്രസ്താവിക്കാന്\u200d അവര്\u200dക്ക് മെ കൂടാതെ, ട്രെയിന്\u200d/പരീക്ഷണത്തിന്റെ തെറ്റുകള്\u200d കൈകാര്യം ചെയ്യാന്\u200d ഞങ്ങള്\u200d സ്വയം പരിശീലനം ഉപയോഗിക്കുകയും മോഡല്\u200d തിരിച്ചറിയുകയും ചെയ്യുന്നതിനാല്\u200d പരീക്ഷണത്തിന് ശ', 'pl': 'Podczas gdy klasyczne systemy NLG zazwyczaj korzystały z hierarchicznie ustrukturyzowanych planów treści, które uwzględniały relacje dyskursowe jako główne komponenty, nowsze podejścia neuronowe w większości mapowały proste, płaskie wejścia do tekstów bez wyraźnego reprezentowania relacji dyskursowych. W niniejszym artykule badamy, czy korzystne jest włączenie relacji dyskursowych do wejścia do neuronowych generatorów danych-tekstowych dla tekstów, w których relacje dyskursowe odgrywają ważną rolę. W tym celu ponownie wdrażamy komponenty planowania i realizacji zdań klasycznego systemu NLG Methodius, wykorzystując modele sekwencji LSTM (seq2seq). Stwierdzamy, że chociaż modele seq2seq mogą nauczyć się generować płynne i gramatyczne teksty niezwykle dobrze z wystarczająco reprezentatywnymi danymi treningowymi Metody, nie mogą nauczyć się prawidłowo wyrażać podobieństwa i porównań kontrastu Metody, chyba że w danych wejściowych uwzględniono odpowiednie relacje RST. Dodatkowo eksperymentujemy z wykorzystaniem samokształcenia i odwrotnego przestawiania modeli, aby lepiej radzić sobie z niedopasowaniem danych treningowych/testowych i stwierdzamy, że choć metody te pomagają zmniejszyć błędy treści, niezbędne jest uwzględnienie relacji dyskursu w danych, aby uzyskać optymalną wydajność.', 'ro': 'În timp ce sistemele clasice NLG utilizau de obicei planuri de conținut structurate ierarhic care includeau relațiile discursului ca componente centrale, abordările neurale mai recente au mapat în mare parte intrările simple și plate ale textelor fără a reprezenta în mod explicit relațiile discursului. În această lucrare, investigăm dacă este benefic să includem relațiile de discurs în intrarea în generatoarele neurale de date-text pentru texte în care relațiile de discurs joacă un rol important. Pentru a face acest lucru, reinmplementăm componentele de planificare și realizare a propozițiilor dintr-un sistem clasic NLG, Methodius, folosind modele LSTM secvență-to-secvență (seq2seq). Considerăm că, deși modelele seq2seq pot învăța să genereze texte fluente și gramaticale remarcabil de bine cu date suficient de reprezentative de instruire Methodius, ele nu pot învăța să exprime corect comparațiile de similitudine și contrast ale lui Methodius decât dacă relațiile RST corespunzătoare sunt incluse în intrări. În plus, experimentăm cu utilizarea auto-antrenamentului și a relocarizării modelului invers pentru a gestiona mai bine neconcordanțele de date tren/test și constatăm că, deși aceste metode ajută la reducerea erorilor de conținut, rămâne esențial să includem relațiile de discurs în intrare pentru a obține performanțe optime.', 'sr': 'Iako su klasični NLG-ovi sistemi obično korišteni hijerarhički strukturovanim planovima sadržaja koji su uključivali diskurske odnose kao centralne komponente, skoriji neuronski pristupi su uglavnom mapirani jednostavnim, ravnim ulazima u tekstove bez objašnjenja diskurskih odnosa. U ovom papiru istražujemo da li je korisno uključiti diskurske odnose u ulaz u generatore neuralnih podataka na tekst za tekste u kojima ima važna uloga igraju diskurske odnose. Da bi to uradili, ponovimo komponente planiranja i realizacije rečenica klasičnog NLG sistema, Metodija, koristeći LSTM sekvenčne do sekvence (seq2seq) modele. Nalazimo da, iako modeli seq2seq mogu naučiti da stvaraju tekućine i gramatične tekste izvanredno dobro sa dovoljno reprezentativnim podacima o obuci Metodija, oni ne mogu naučiti da ispravno izraze sličnost Metodija i kontrastne usporedbe osim ako se odgovarajući odnosi RST uključuju u inpute. Osim toga, eksperimentiramo sa korištenjem samoovježbanja i obrnutog modela koji se preobraćaju da bi bolje rješavali nesklade vlaka/testa podataka i saznali da, iako te metode pomažu smanjiti greške sadržaja, ostaje važno uključiti diskurske odnose u ulaz kako bi dobili optimalnu funkciju.', 'so': "Inta lagu isticmaalo nidaamka kooxaha NLG ayaa si caadi ah u isticmaalay qorshaha qorshaha waxyaabaha la dhisay ee ku jira xiriirka hadalka sida kooxaha dhexe, dhaqdhaqaaqyada neurada ee ugu dambeeyey ayaa si fudud u sawiray, qoraalka sawirro ah oo aan bayaan u representin xiriirka hadalka. Qoraalkan waxaynu ka baaraynaa inay faa’iido u leedahay in laguugu soo qoro xiriirka hadalka iyo in loo sameeyo macluumaadka neurada iyo qoraalka, meesha ay xiriirka hadalku leeyihiin qayb muhiim ah. Sida darteed waxaynu dhammaynaa qorshaha iyo baaritaanka qeybaha ka mid ah nidaamka klassik ee NLG, Methodius, tusaalaha LSTM-soo-xigta (seq2seq). Waxaynu helnaa in kastoo muusikada seq2seq ay baran karaan in ay sameeyaan qoraal aad u sahlan iyo qoraal aad u wanaagsan, oo ay macaamiisha waxbarashada ku filan ee Methodius, ma baran karaan si saxda ah si ay u muujiyaan isku eg iyo is-hoosaysiinta, haddii aysan ku qoran xiriirka RST ee isku mid ah. Sidoo kale waxaynu ku tijaabinaynaa isticmaalka iskuul-tababarinta iyo dib-u-bedelaynaa modelka si aan u hagaajinno si aad u hagaagsan karto baaritaanka tareenka/imtixaanka, waxaynu ogaanaynaa in marka qaababkan ay u caawinayaan inay hoos u dhigto qaladka waxyaabaha ku jira, waxaa muhiim ah in lagu soo wadayo xiriirka hadalka si ay u hesho sameynta faa'iid", 'sv': 'Medan klassiska NLG-system vanligtvis använde sig av hierarkiskt strukturerade innehållsplaner som inkluderade diskursrelationer som centrala komponenter, har nyare neurala tillvägagångssätt oftast kartlagt enkla, platta ingångar till texter utan att representera diskursrelationer uttryckligen. I denna uppsats undersöker vi om det är fördelaktigt att inkludera diskursrelationer i indata till neurala data-till-text generatorer för texter där diskursrelationer spelar en viktig roll. För att göra detta återamplicerar vi meningsplanerings- och realiseringskomponenterna i ett klassiskt NLG-system, Methodius, med hjälp av LSTM sekvens-till-sekvens (seq2Seq) modeller. Vi finner att även om sek2seq modeller kan lära sig att generera flytande och grammatiska texter anmärkningsvärt bra med tillräckligt representativa Methodius träningsdata, kan de inte lära sig att korrekt uttrycka Methodius likhet och kontrastjämförelser såvida inte motsvarande RST-relationer ingår i input. Dessutom experimenterar vi med att använda självträning och omvänd modellranking för att bättre hantera missmatchningar mellan tåg och testdata, och finner att även om dessa metoder bidrar till att minska innehållsfel, är det viktigt att inkludera diskursrelationer i indata för att uppnå optimal prestanda.', 'si': 'සාමාන්\u200dය NLG පද්ධතිය සාමාන්\u200dය විශේෂයෙන් භාවිත කරලා තියෙන සැකසුම් සැලසුම් සැලසුම් වලින් භාවිතා කරලා තියෙන්නේ කතාවක් සම්බන්ධතාවක් වගේ ක මේ පත්තරේ අපි පරීක්ෂණය කරනවා වැදගත් සම්බන්ධයක් තියෙන්නේ න්\u200dයූරල් දත්ත සහ පත්තර සිද්ධ කරනවා කියලා, පාළුවන්ගේ පාළුවන එහෙම කරන්න, අපි ප්\u200dරමාණික NLG පද්ධතිය, මත්තියුස්, LSTM sequence-to-sequence (seq2seq) මෝඩල් භාවිත කරනවා වාක්ය සැලසුම් සහ අවස්ථාව සඳහා ප්\u200dර අපි හොයාගන්නවා ඒ වගේම seq2seq මොඩේල්ස් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන් ව තවත්, අපි ස්වයංග ප්\u200dරීක්ෂණය සහ ආපහු ප්\u200dරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ප', 'ta': 'வகுப்பான NLG அமைப்புகள் வழக்கமாக மையமாக உருவாக்கப்பட்ட உள்ளடக்க திட்டங்களை உபயோகிக்கும் போது, பேச்சு தொடர்புகளை மையமான பகுதிகளாக சேர்க்கப்பட்டுள்ளது, அதில் சமீபத்திய பு இந்த காகிதத்தில், பேச்சு தொடர்புகளை உள்ளீட்டில் சேர்க்க பயனுள்ளதா என்பதை நாம் ஆராய்ச்சி செய்கிறோம் புதிய தகவல்- to- text உரை உருவாக்குபவர் இதைச் செய்ய, நாம் வாக்கு திட்டமைப்பு மற்றும் தெரியும் பொருளை மீண்டும் பூர்த்தி செய்கிறோம் ஒரு வகுப்பான NLG அமைப்பு, முறைமையில், LSTM பின் நாம் கண்டுபிடிக்க வேண்டுமென்றாலும் பொருத்தமான RST தொடர்புகளை உள்ளீடுகளில் சேர்க்கப்படாத வரையில் சரியாக முடியாது. கூடுதலாக, நாமே பயிற்சியை பயன்படுத்தி மாதிரி மீண்டும் மாதிரியை மீண்டும் மாற்றி சோதனைப்படுத்துகிறோம் சிறந்த பயிற்சி/சோதனை தரவு தவறான பொருத்தங்களை பாதுகா', 'ur': 'اگرچہ کلاسیک NLG سیستموں کی عمدہ طور پر حیراتی طریقے کی منظم طریقے سے استعمال کیے جاتے ہیں جن میں ڈیکورس رابطے مرکزی رقموں کے طور پر شامل ہوتے ہیں، اچھی نئورل طریقے سے زیادہ ساده نقطہ طریقے کے مطابق سادھے، فلاٹ اینپوٹ ٹ ہم اس کاغذ میں تحقیق کرتے ہیں کہ کیا یہ فائدہ ہے کہ نئورل ڈیٹ سے ٹیکسٹ جینراٹر کے اندر صحبت کی رابطہ شامل کریں جہاں صحبت کی رابطہ ایک اہم رول ہے۔ ایسا کرنا چاہیے، ہم ایک کلاسیک NLG سیسٹم، مٹوڈیوس کے مطابق LSTM sequence-to-sequence (seq2seq) نمڈلوں کے مطابق جماعت کی تدبیر اور تدبیر کرنے کے لئے دوبارہ تدبیر کرتے ہیں. ہم کو معلوم ہے کہ اگرچہ سq2seq موڈلز فلئونٹ اور گراماتیکی ٹیکسٹ پیدا کرنے کی تعلیم کے ساتھ بہت اچھی طرح سیکھ سکتے ہیں، وہ مطالبہ مطالبہ مطالبہ اور مقابلہ مقابلہ کے ساتھ سیکھ نہیں سکتے، مگر یہ کہ مسلسل RST رابطہ اضافہ میں شامل ہو جائیں۔ اور اضافہ، ہم نے اپنی تدریس کے مطابق آزمائش کے ساتھ آزمائش کی اور ٹرین/ٹیسٹ ڈیٹے غلط مطابق کے ساتھ دوبارہ ریرنگ کی مدل کے مطابق آزمائش کی، اور دیکھتے ہیں کہ جب یہ طریقے منزل خطائیں کاٹ دینے کی مدد کرتی ہیں، اس کے مطابق اچھی عملکرد', 'vi': 'Trong khi hệ thống địa chấn điển điển điển hình đã sử dụng các kế hoạch nội dung cấu trúc theo thứ tự, bao gồm các mối quan hệ ngôn luận như các thành phần trung tâm, các tiếp cận thần kinh gần đây chủ yếu đã vẽ các nội dung đơn giản, phẳng vào các văn bản mà không đại diện các quan hệ. Trong tờ giấy này, chúng tôi tìm hiểu xem có nên gồm quan hệ ngôn luận trong các nguồn cung cấp dữ liệu-văn bản thần kinh cho các văn bản nơi các quan hệ diễn thuyết đóng vai trò quan trọng không. Để làm được điều đó, chúng tôi hoàn thành lại phần cấu trúc án và phần thực hiện của một hệ thống NIG điển hình, Methoius, sử dụng các mô hình dãy---tới-dãy (seq2seq). Chúng tôi thấy rằng mặc dù các mô hình dáng dáng dáng dáng dáng dáng dáng dáng dáng phân loại có thể tạo ra các văn bản thông thạo và ngôn ngữ khá tốt với dữ liệu giáo huấn đủ đại diện của Giám Lý, nhưng họ không thể học chính xác cách diễn tả nét giống nhau của Giám Lý và tương phản trừ khi các quan hệ thống RST nằm trong nội dung. Thêm vào đó, chúng tôi thử sử dụng việc tự đào tạo và chỉnh sửa lại mẫu ngược để điều khiển sai lệch dữ liệu giữa tàu và kiểm tra tốt hơn, và phát hiện rằng trong khi những phương pháp này giúp giảm lỗi nội dung, vẫn cần thiết phải có mối quan hệ đối tượng trong nội dung để đạt được hiệu suất tối đa.', 'uz': "While classic NLG systems typically made use of hierarchically structured content plans that included discourse relations as central components, more recent neural approaches have mostly mapped simple, flat inputs to texts without representing discourse relations explicitly.  Bu hujjatda, biz ma'lumot taʼminlovchilarini kiritish kerak va ma'lum matn generatorlariga qo'shish kerak bo'lganligini o'rganamiz. Bu yerda talab munosabatlar muhim roli oʻynalishi mumkin. Bunday qilib, biz bir so'zni boshqarish va aniqlash uchun klassik NLG tizimning qismlarini qaytadan qo'yish mumkin, Metodius, LSTM sequence to- seq2seq modellaridan foydalanishimiz. Biz o'ylaymiz, seq2seq modellari suv va grammatikal matnlarni yaratishni o'rganadi. Metodius taʼminlovchi maʼlumotni juda yaxshi yaxshi ko'proq o'rganadi, ammo o o'z tuzuvga murojaat qiladigan RST bogʻliqlarini qo'llanmagan holatda o'rganib boʻlmaydi. Ko'pchilik, biz o'zimni o'zining o'zini o'zgartirib o'rganish modeli bilan o'rganamiz va taʼminlovchi taʼminlovchilarni yaxshi ko'rsatish mumkin. Bu usullar maʼlumot xatolarni kamaytirish yordam berayotganda, ularning tarkibi xatolarni kamaytirish muhim bo'lganda, kiritilgan mazmuni aloqal", 'bg': 'Докато класическите системи обикновено използват йерархично структурирани планове за съдържание, които включват дискурсните отношения като централни компоненти, по-новите неврални подходи са картографирали най-вече прости, плоски входове към текстовете, без да представят дискурсните отношения изрично. В настоящата статия изследваме дали е полезно да включим дискурсните отношения във входа към нервните генератори данни-текст за текстове, в които дискурсните отношения играят важна роля. За целта повтаряме компонентите за планиране и реализация на изреченията на класическата система Методий, използвайки модели от последователност към последователност (seq2seq). Установяваме, че макар моделите да могат да се научат да генерират плавни и граматически текстове забележително добре с достатъчно представителни данни за обучението на Методий, те не могат да се научат да изразят правилно сравненията на Методий за сходство и контраст, освен ако съответните релации не са включени в входящите данни. Освен това експериментираме с използването на самообучение и повторно класиране на моделите, за да се справим по-добре с несъответствията на данните от влака/теста, и откриваме, че макар тези методи да помагат за намаляване на грешките в съдържанието, остава от съществено значение да включим дискурсните връзки във входа, за да се постигне оптимално представяне.', 'nl': 'Terwijl klassieke NLG-systemen meestal gebruikten van hiërarchisch gestructureerde contentplannen die discoursrelaties als centrale componenten bevatten, hebben recentere neurale benaderingen meestal eenvoudige, platte inputs in teksten in kaart gebracht zonder discoursrelaties expliciet te vertegenwoordigen. In dit artikel onderzoeken we of het nuttig is om discoursrelaties op te nemen in de invoer van neurale data-to-text generatoren voor teksten waar discoursrelaties een belangrijke rol spelen. Om dit te doen, herimplementeren we de zinnenplanning en realisatie componenten van een klassiek NLG systeem, Methodius, met behulp van LSTM seq2seq (seq2seq) modellen. Hoewel seq2seq modellen opmerkelijk goed kunnen leren vloeiende en grammaticale teksten te genereren met voldoende representatieve Methodius trainingsgegevens, kunnen ze niet leren de gelijkenis en contrastvergelijkingen van Methodius correct uit te drukken tenzij de overeenkomstige RST relaties in de inputs zijn opgenomen. Daarnaast experimenteren we met zelftraining en reverse model heringering om mismatches tussen trein/test data beter aan te pakken. Hoewel deze methoden helpen contentfouten te verminderen, blijft het essentieel om discoursrelaties in de input op te nemen om optimale prestaties te behalen.', 'da': 'Mens klassiske NLG-systemer typisk gjorde brug af hierarkisk strukturerede indholdsplaner, der inkluderede diskursrelationer som centrale komponenter, har nyere neurale tilgange for det meste kortlagt enkle, flade input til tekster uden at repræsentere diskursrelationer eksplicit. I denne artikel undersøger vi, om det er gavnligt at inkludere diskursrelationer i input til neurale data-til-tekst generatorer til tekster, hvor diskursrelationer spiller en vigtig rolle. For at gøre dette gennemfører vi sætningsplanlægnings- og realiseringskomponenterne i et klassisk NLG-system, Methodius, ved hjælp af LSTM sekvens-til-sekvens (seq2Seq) modeller. Vi finder, at selv om sek2seq modeller kan lære at generere flydende og grammatiske tekster bemærkelsesværdigt godt med tilstrækkeligt repræsentative Methodius træningsdata, kan de ikke lære korrekt at udtrykke Methodius lighed og kontrastsammenligninger, medmindre de tilsvarende RST-relationer er inkluderet i input. Derudover eksperimenterer vi med at bruge selvtræning og omvendt modelranking for bedre at håndtere tog-/testdata mismatch, og finder ud af, at selvom disse metoder hjælper med at reducere indholdsfejl, er det stadig vigtigt at inkludere diskursrelationer i input for at opnå optimal ydeevne.', 'hr': 'Iako klasični sustavi NLG obično koriste hijerarhički strukturirane planove sadržaja koji uključuju odnose o diskusiji kao centralne komponente, nedavnije neuronske pristupe uglavnom su mapirane jednostavne, ravne ulaze u tekstove bez jasno predstavljanja odnosa o diskusiji. U ovom papiru istražujemo da li je korisno uključiti diskurske odnose u ulaz neuralnim generatorima podataka na tekst za tekste u kojima ima važna uloga igraju odnose diskursa. Da bismo to učinili, ponovimo komponente planiranja i realizacije rečenica klasičnog NLG sustava, Methodius, koristeći LSTM sekvenčne do sekvence (seq2seq) modele. Mi smatramo da, iako modeli seq2seq mogu naučiti stvarati tekuće i gramatičke tekste izvanredno dobro sa dovoljno reprezentativnim podacima o obuci Methodiusa, oni ne mogu naučiti ispravno izraziti sličnost i kontrastne usporedbe Methodiusa osim ako se odgovarajući odnosi RST-a ne uključuju u ulaze. Osim toga, eksperimentiramo s korištenjem samouvježbe i okrenutom modelom preobraćajući se kako bi bolje rješavali nesklade vlaka/ispitivanja podataka, i saznali smo da, iako te metode pomažu smanjiti greške sadržaja, ostaje važno uključiti veze s diskusijama u ulaz kako bi dobili optimalnu funkciju.', 'de': 'Während klassische NLG-Systeme typischerweise auf hierarchisch strukturierte Inhaltspläne zurückgreifen, die Diskursbeziehungen als zentrale Komponenten beinhalten, haben neuere neuronale Ansätze meist einfache, flache Eingaben in Texte abgebildet, ohne Diskursbeziehungen explizit darzustellen. In diesem Beitrag untersuchen wir, ob es vorteilhaft ist, Diskursbeziehungen in die Eingabe neuronaler Daten-zu-Text-Generatoren für Texte einzubeziehen, bei denen Diskursbeziehungen eine wichtige Rolle spielen. Dazu implementieren wir die Satzplanungs- und Realisierungskomponenten eines klassischen NLG-Systems Methodius mit LSTM Sequenz-to-Sequenz (seq2seq)-Modellen neu. Obwohl seq2seq Modelle lernen können, fließende und grammatische Texte mit ausreichend repräsentativen Methodius Trainingsdaten bemerkenswert gut zu generieren, können sie nicht lernen, Methodius Ähnlichkeiten und Kontrastvergleiche korrekt auszudrücken, es sei denn, die entsprechenden RST-Beziehungen sind in den Eingaben enthalten. Darüber hinaus experimentieren wir mit der Verwendung von Selbsttraining und Reverse Model Reranking, um Fehlübereinstimmungen von Train/Test-Daten besser zu handhaben, und stellen fest, dass diese Methoden zwar helfen, inhaltliche Fehler zu reduzieren, es jedoch wichtig bleibt, Diskursbeziehungen in den Input einzubeziehen, um eine optimale Leistung zu erzielen.', 'fa': 'در حالی که سیستم\u200cهای کلاسیک NLG معمولاً از نقشه\u200cهای محتوای ساخته شده\u200cای استفاده می\u200cکنند که شامل رابطه\u200cهای صحبت به عنوان بخش\u200cهای مرکزی بودند، نزدیک\u200cهای عصبی اخیراً بیشتر ساده و پایین به متن\u200cها نقشه\u200cبندی می\u200cکنند بدون نشان دادن رابطه\u200cهای ص در این کاغذ، ما تحقیق می\u200cکنیم که آیا رابطه\u200cهای گفتگو در ورودی به ژنراتورهای داده\u200cهای عصبی و متن برای متن\u200cها که رابطه\u200cهای گفتگو یک نقش مهم دارند، سودمند است یا نه. برای این کار، ما بخش\u200cهای برنامه\u200cریزی و realizacion جمله\u200cهای یک سیستم NLG کلاسیک، Methodius را به استفاده از مدل\u200cهای LSTM sequence-to-sequence (seq2seq) بازیابی می\u200cکنیم. ما متوجه می\u200cشویم که هر چند مدل\u200cهای seq2seq می\u200cتوانند متن\u200cهای آبی و گراماتیکی را بسیار خوب تولید کنند با داده\u200cهای آموزش metodius به اندازه کافی، آنها نمی\u200cتوانند یاد بگیرند که شبیه و مقایسه\u200cهای مخالفت metodius را درست بیان کنند، مگر اینکه ارتباط\u200cهای RST متعلق به اندازه\u200cی آن وارد شوند. به اضافه، ما با استفاده از آموزش خودمان آزمایش می\u200cکنیم و مدل بازگرداندن برای بهتر کنترل داده\u200cهای قطار/آزمایش غیرمسابقه\u200cای، و پیدا می\u200cکنیم که در حالی که این روش\u200cها اشتباه\u200cهای محتویات را کاهش می\u200cدهند، آن باقی مانده است که رابطه\u200cهای گفتگو در ورودی', 'id': 'Sementara sistem NLG klasik biasanya menggunakan rencana konten terstruktur secara hierarkis yang termasuk hubungan diskors sebagai komponen pusat, pendekatan saraf yang baru-baru ini kebanyakan telah memetakan masukan sederhana, datar ke teks tanpa mewakili hubungan diskors secara eksplicit. Dalam kertas ini, kami menyelidiki apakah itu berguna untuk memasukkan hubungan diskors dalam input ke generator data-ke-teks saraf untuk teks di mana hubungan diskors bermain peran penting. Untuk melakukannya, kami mengimplementasi ulang komponen rencana kalimat dan realizasi dari sistem NLG klasik, Metodius, menggunakan model LSTM sequence-to-sequence (seq2seq). Kami menemukan bahwa meskipun model seq2seq dapat belajar untuk menghasilkan teks fluent dan grammatik dengan sangat baik dengan data pelatihan Metodius yang cukup mewakili, mereka tidak dapat belajar untuk mengekspresikan dengan benar persamaan Metodius dan perbandingan kontras kecuali hubungan RST yang sesuai termasuk dalam masukan. Additionally, we experiment with using self-training and reverse model reranking to better handle train/test data mismatches, and find that while these methods help reduce content errors, it remains essential to include discourse relations in the input to obtain optimal performance.', 'ko': '클래식한 NLG시스템은 통상 차원 구조의 콘텐츠 계획을 사용해 말관계를 핵심 구성요소로 활용하지만, 최근의 신경 접근법은 대부분 간단하고 평탄한 입력을 텍스트에 비추고 말관계를 명확하게 나타내지 않고 있다.본고에서 우리는 텍스트 생성기의 신경 데이터 입력에 문장 관계를 포함하는 것이 문장 관계가 중요한 역할을 발휘하는 데 도움이 되는 텍스트인지 연구했다.이를 위해 우리는 LSTM 시퀀스에서 시퀀스(seq2seq) 모델로 클래식 NLG시스템 Methodius의 문장 기획과 실현 구성 요소를 다시 실현했다.비록 seq2seq모델은 충분한 대표적인 Methodius 트레이닝 데이터를 통해 유창한 문법 텍스트를 잘 생성할 수 있지만 입력에 해당하는 RST 관계가 포함되지 않으면 Methodius의 유사성과 대비도 비교를 정확하게 표현할 수 없다는 것을 알 수 있다.또한 훈련/테스트 데이터의 일치하지 않는 부분을 자기 훈련과 역방향 모델을 사용하여 재배열해 보았고, 이러한 방법은 내용 오류를 줄이는 데 도움이 되지만 입력에 언어 관계를 포함시켜 최상의 성능을 얻을 필요가 있음을 발견했다.', 'sw': 'Wakati mifumo ya NLG ya klasi kawaida imetumia mipango ya maudhui yaliyotengenezwa kwa kiasi kikubwa ambazo zilijumuisha mahusiano ya mazungumzo kama sehemu za katikati, hatua za hivi karibuni zimekuwa za ramani rahisi, matumizi ya bure kwa maandishi bila kuwakilisha mahusiano ya mazungumzo wazi. Katika karatasi hii, tunachunguza kama inafaa kuwajumuisha mahusiano ya mazungumzo katika input kwa watengenezaji wa taarifa za kisasa kwa ujumbe ambapo mahusiano ya mazungumzo yanafanya kazi muhimu. Ili kufanya hivyo, tunarudisha viungo vya mipango ya mipango na kutambua hukumu ya mfumo wa NLG, Methodius, kwa kutumia mifano ya LSTM kwa mfululizo (seq2seq). Tunapata kwamba ingawa mifano ya seq2seq inaweza kujifunza kutengeneza ujumbe wa mafunzo na maarufu kwa kiasi kikubwa na taarifa za mafunzo ya Methodius ya kutosha, hawawezi kujifunza kuonyesha sawa na ulinganisho wa Methodius na tofauti isipokuwa mahusiano yanayohusiana na RST yanajumuisha kwenye maudhui. Zaidi ya hayo, tunajaribu kwa kutumia mafunzo ya kujitegemea na kubadilisha mifano kwa ajili ya kushughulikia vibaya vya taarifa za treni/kujaribu, na kutambua kwamba wakati njia hizi zinasaidia kupunguza makosa ya maudhui, bado ni muhimu kuingiza mahusiano ya mazungumzo katika kituo hicho ili kupata ufanisi bora.', 'tr': 'Klasik NLG sistemalary hemişe hijerarhiýa düzümlenmiş maksady planlaryny ulanýarlar, diskurs baglaýyşlary orta komponent diýip ýazmaýarlar, iň soňky näyral golaýlary köpüräk görkezilýän basit, düz girişikler tekstlere görkezilýän çykyş baglaýyşlary görkezmeden. Bu kagyzda, sözleşmeler wajyp roli çalýan çykyş gürrüňlerini näyral data we tekst jeneratorlaryna daşary etmek üçin faydaly dälmidigini soradyk. Böylece etmek üçin, biz sözlerin klasik NLG sisteminiň, Metodowyň, LSTM sequence-to-sequence (seq2seq) modellerini ýene bejerdik. Biz seq2seq modelleri fluent we gramatik metinleri oluşan we ýeterlik temelli Metodowyň eğitim maglumaty bilen gowy öwrenip bilmeýändiklerini tapýarys. Eğer metodowyň meňzeşliklerini düzgün ifade etmegi we tersleşliklerini, girişinde täsirli RST baglaýyşlary dahil etmediklerini öwrenip bilmezler. Munuň üstünde, biz özümizi okuwçylygy ulanyp we özümizi yzarlamak üçin gol/test berüjileriniň iň gowy çykarmak üçin örän nusga çykyp barýarys we şu ýagdaýlar mazmunlaryň ýalňyşyny azaltmakda kömek edýän wagtlary optimal etkinlik gazanmak üçin girişde gürrüňler', 'am': 'የክላሲክ NLG systems በተለያዩ ጊዜ የንግግር ግንኙነት እንደ ማዕከል ክፍሎች የሚያስቀምጥ የክፍተት ጥናት በተቀናቀለ ጊዜ፣ የቀድሞው የነዌብ ግንኙነት በተለይ ግንኙነት ሳይታወቅ ለጽሑፎች ቀላል፣ የጥሩ ግንኙነት ገልጾችን ለጽሑፍ ማቀላቀል ነው፡፡ በዚህ ፕሮግራም፣ የንግግር ግንኙነት ግንኙነት በጥያቄው ውስጥ ለመጨመር ጠቅሟል እናደርጋለን፡፡ እንደዚህ እናደርጋለን፣ የክላሲ NLG ስርዓት ክፍተቶችን እናሳውቃለን፤ LSTM ስርዓት (seq2seq) ምሳሌዎችን በመጠቀም እናደርጋለን፡፡ የseq2seq ዓይነት ምሳሌዎች ፍላጎት እና የgrammatik ጽሑፎችን በመፍጠር ይማራሉ ብዙም በኩል አስተያየት ማድረግ የሚችል የሜትዮስ ትምህርት እና ተቃውሞ የRST ግንኙነት በጥያቄዎች ውስጥ ካልደረጉ በቀር አስተያየት አይችሉም፡፡ በተጨማሪም፣ የራሳችንን ትምህርት እና የሞዴል ተቃውሞ በመጠቀም እና የመሻለውን የቴርኔን/የድምፅ ዳታዎችን በመቀበል እናስሞክራለን፡፡', 'sq': 'Ndërsa sistemi klasik NLG tipikisht përdori planet e përmbajtjeve të strukturuara hierarkikisht që përfshijnë marrëdhëniet diskursore si komponente qendrore, qasjet më të fundit nervore kryesisht kanë hartuar hyrje të thjeshta dhe të pjatta në tekste pa përfaqësuar eksplicitesht marrëdhëniet diskursore. Në këtë letër, ne hetojmë nëse është e dobishme të përfshihemi marrëdhëniet diskursore në hyrjen e gjeneratorëve nervorë të të dhënave në tekst për tekste ku marrëdhëniet diskursore luajnë një rol të rëndësishëm. Për ta bërë këtë, ne rimplikohemi komponentet e planifikimit dhe realizimit të fjalëve të një sistemi klasik NLG, Metodius, duke përdorur modelet LSTM sekuencë-në-sekuencë (seq2seq). Ne zbulojmë se megjithëse modelet seq2seq mund të mësojnë të gjenerojnë tekste fluente dhe grammatike jashtëzakonisht mirë me të dhëna të trajnimit të mjaftueshëm përfaqësuese Metodius, ata nuk mund të mësojnë të shprehin korrekt ngjashmërinë e Metodius dhe krahasimet e kontrastit përveç nëse marrëdhëniet korrispondente RST janë përfshirë në hyrje. Përveç kësaj, ne eksperimentojmë me përdorimin e vetë-stërvitjes dhe ndryshimin e model it për të trajtuar më mirë mospërputhjet e të dhënave tren/test dhe gjejmë se ndërsa këto metoda ndihmojnë reduktimin e gabimeve të përmbajtjes, mbetet thelbësore të përfshihen marrëdhëniet diskursore në hyrjen për të arritur performancën optimale.', 'af': "Alhoewel klassieke NLG stelsels tipies gebruik het van hierarkies struktureerde inhoud planne wat diskursie relasies as sentrale komponente ingesluit het, meer onlangse neurale toegange het mees eenvoudige, plat inputs na tekste gemaak sonder om diskursie relasies te verteenwoordig eksplisief. In hierdie papier, ons ondersoek of dit nuttig is om diskursie relasies in die invoer na neurale data- to- text genereerders te insluit vir teks waar diskursie relasies 'n belangrike rol speel. Om dit te doen, ons verplitter die setplanning en realisasie komponente van 'n klassieke NLG stelsel, Methodius, gebruik LSTM sekvensie-na-sekvensie (seq2seq) modele. Ons vind dat alhoewel seq2seq-modelles kan leer om fluent en grammatiese teks te genereer, betekenlik goed met genoeg reprezentant Methodius-onderwerking data, hulle kan nie leer om die gelykheid en kontras-vergelykings reg te uitdruk tensy die ooreenstemmende RST-relasies in die inputs ingesluit word. In addition, we experiment with using self-training and reverse model reranking to better handle train/test data mismatches, and find that while these methods help reduce content errors, it remains essential to include discourse relations in the input to obtain optimal performance.", 'az': "Klasik NLG sistemləri genellikle hiyerarhiqli müxtəlif məlumat planlarına istifadə etdikləri halda, daha yeni nöral yaxınlıqları çox olaraq çox asanlıqla, fərqli məlumatlara istifadə edilmişdir. Bu kağızda, söhbət əlaqələri möhüm rol oynadığı məktublar üçün nöral məlumat-məlumat generatorlarına daxil olmaq faydalı olub olmadığını araşdırırıq. Bunu etmək üçün, Sözlük planlaması və realizasyon komponentlərini, metodiyus, LSTM sequence-to-sequence (seq2seq) modellərini istifadə edirik. Biz seq2seq modelləri fluent və gramatik textləri təhsil etməyi öyrənə bilərdik ki, Methodius təhsil məlumatları ilə kifayət qədər yaxşı təhsil edə bilərlər, onlar Methodius'un similaritəsini və əlaqəsini doğru ifadə etməyi öyrənə bilməzlər. Əgər müəyyən edilən RST əlaqəsi inputlərdə dahil olmasa istisna olmaqla. Əksinə, biz özümüzü təhsil etmək və modeli daha yaxşı təhsil/test verilənlərin uyğunlaşması üçün yenidən təhsil etmək üçün imtahana çəkirik və bu metodlar içərisində xətaları azaltmağa kömək edərkən, optimal performansı almaq üçün çəkişmə əlaqələrini daxil etmək daha vacibdir.", 'hy': 'Մինչդեռ դասական ՆԼԳ համակարգերը սովորաբար օգտագործում էին հիերարխիկապես կառուցվածված պարունակության պլաններ, որոնք ներառում էին խոսակցական հարաբերությունները որպես կենտրոնական բաղադրիչներ, վերջին նյարդային մոտեցումները հիմնականում քարտեզագրում էին պարզ, հարթ In this paper, we investigate whether it is beneficial to include discourse relations in the input to neural data-to-text generators for texts where discourse relations play an important role.  Այսպիսով, մենք վերափոխում ենք նախադասությունների պլանավորման և իրականացման բաղադրիչները դասական ՆԼԳ համակարգի, Մեթոդիոսի, օգտագործելով LSMT-ի հաջորդականություն-հաջորդականություն (SeQ2SeQ) մոդելներ: Մենք հայտնաբերում ենք, որ չնայած որ SeQ2SeQ մոդելները կարող են սովորել ստեղծել հեղուկ և գրամատիկ տեքստեր բավականաչափ լավ, բավականաչափ ներկայացնող Մեթոդի ուսումնասիրության տվյալներով, նրանք չեն կարող ճիշտ ուսումնասիրել Մեթոդի նմանությունը և հակադրությունը համեմատել, եթե համապատաս Ավելին, մենք փորձում ենք օգտագործել ինքնավարժություն և հակադարձ մոդելը, որպեսզի ավելի լավ վերահսկենք գնացքի և թեստերի տվյալների անհամապատասխանությունը, և հայտնաբերենք, որ մինչ այս մեթոդները օգնում են նվազեցնել պարունակության սխալները, ապա անհրաժեշտ է ներմուծի մեջ', 'bs': 'Iako klasični NLG sustavi obično koriste hijerarhički strukturirane planove sadržaja koji su uključivali diskurske odnose kao centralne komponente, skoriji neuronski pristupi su uglavnom mapirali jednostavne, ravne ulaze u tekstove bez objašnjenja odnosa diskursa. U ovom papiru istražujemo da li je korisno uključiti diskurske odnose u ulaz u generatore neuralnih podataka na tekst za tekste u kojima ima važna uloga igraju veze diskursa. Da bismo to uradili, ponovimo komponente planiranja i realizacije rečenica klasičnog NLG sistema, Methodius, koristeći LSTM sekvenčne do sekvence (seq2seq) modele. Mi smatramo da, iako modeli seq2seq mogu naučiti stvarati tekuće i gramatičke tekste izuzetno dobro sa dovoljno reprezentativnim podacima o obuci Methodiusa, oni ne mogu naučiti kako ispravno izraziti sličnost Methodiusa i kontrastne usporedbe osim ako se odgovarajući odnosi RST-a ne uključuju u ulaze. Osim toga, eksperimentiramo s korištenjem samouvježbe i obrnutog modela preobraćajući se kako bi bolje rješavali nesklade vlaka/testovanja podataka i saznali da, iako te metode pomažu smanjiti greške sadržaja, ostaje važno uključiti veze diskursa u ulaz kako bi dobili optimalnu funkciju.', 'bn': 'যদিও ক্লাসিক এনএলজি সিস্টেম সাধারণত হিয়ারার্কিক গঠনের বিষয়বস্তু পরিকল্পনা ব্যবহার করা হয় যায় যার মধ্যে কথোপকথন সম্পর্ক ক কেন্দ্রীয় উপাদান হিসেবে রয়েছে, সাম্প্রতিক নিউ In this paper, we investigate whether it is beneficial to include discourse relations in the input to neural data-to-text generators for texts where discourse relations play an important role.  এরকম করার জন্য আমরা ক্লাসিক এনএলজি সিস্টেমের ক্লাস্টিকের পরিকল্পনা এবং বুঝতে পারি মেটোডিয়াসের ক্লাস্টিক এনএলজি সিস্টেম ব্যবহার করে এলএসএমসের স আমরা খুঁজে পাচ্ছি যে যদিও সেক্ট২সেক মডেল ফ্লায়েন্ট এবং গ্রামাটিক্যাল টেক্সট তৈরি করতে শিখতে পারে যথেষ্ট প্রতিনিধি মেথোডিয়াসের প্রশিক্ষণের তথ্য তৈরি করতে পারে, তারা ইনপুটের মধ্যে স এছাড়াও আমরা স্বেচ্ছাসেবক প্রশিক্ষণ ব্যবহার করি এবং মডেল ব্যবহার করে ভালো ট্রেন/পরীক্ষা তথ্যের মিশ্রিত ব্যবহার করার জন্য পরীক্ষা করি এবং আবিষ্কার করি যে এই পদ্ধতি বিষয়বস্তু', 'et': 'Kuigi klassikalised NLG-süsteemid kasutasid tavaliselt hierarhiliselt struktureeritud sisuplaane, mis sisaldasid diskursussuhteid kesksete komponentidena, on hilisemad närvilähenemisviisid enamasti kaardistanud lihtsaid ja tasaseid sisendeid tekstidesse, ilma et need oleksid diskursussuhteid selgesõnaliselt esindanud. Käesolevas töös uurime, kas on kasulik kaasata diskursussuhted neuroandmete-teksti generaatorite sisendisse tekstides, kus diskursussuhted mängivad olulist rolli. Selleks rakendame uuesti klassikalise NLG süsteemi Methodius lauseplaneerimise ja realiseerimise komponendid, kasutades LSTM jada-jada (seq2seq) mudeleid. Leiame, et kuigi seq2seq mudelid suudavad õppida looma sujuvaid ja grammatilisi tekste märkimisväärselt hästi piisavalt representatiivsete Methodiuse koolitusandmetega, ei saa nad õppida õigesti väljendama Methodiuse sarnasust ja kontrasti võrdlusi, kui sisendites ei ole lisatud vastavaid RST-suhteid. Lisaks eksperimenteerime eneseõppe ja pöördmudelite ümberpaigutamise kasutamist, et paremini käsitleda rongi-/katseandmete ebakõlasid, ning leiame, et kuigi need meetodid aitavad vähendada sisuvigu, on endiselt oluline lisada sisendisse diskursussuhted optimaalse jõudluse saavutamiseks.', 'ca': "Mentre els sistemes clàssics de NLG normalment utilitzen plas de continguts jeràrquicament estructurats que inclouen relacions de discurs com components centrals, els enfocaments neuronals més recents han mapejat principalment entrades simples i planes als textos sense representar explicitament les relacions de discurs. En aquest paper, investigam si és beneficiós incloure relacions de discurs en la entrada a generadors neuronals de dades a text per textos on les relacions de discurs juguen un paper important. Per fer-ho, rempliquem els components de planificació i realizació de frases d'un clàssic sistema NLG, Methodius, utilitzant models LSTM seq2seq. Trobem que encara que els models seq2seq poden aprendre a generar textos fluent s i gramàtics molt bé amb dades suficientment representatives d'entrenament del Métode, no poden aprendre a expressar correctament la similitud i comparacions de contrast del Métode a no ser que les relacions RST correspondents siguin incloses en les entrades. Additionally, we experiment with using self-training and reverse model reranking to better handle train/test data mismatches, and find that while these methods help reduce content errors, it remains essential to include discourse relations in the input to obtain optimal performance.", 'fi': 'Klassiset NLG-järjestelmät käyttivät tyypillisesti hierarkisesti jäsenneltyjä sisältösuunnitelmia, joissa diskurssisuhteet olivat keskeisiä komponentteja, mutta uudemmat neurolähestymistavat ovat lähinnä kartoittaneet yksinkertaisia, litteitä syötteitä teksteihin edustamatta diskurssisuhteita nimenomaisesti. Tässä artikkelissa selvitämme, onko hyödyllistä sisällyttää diskurssisuhteet neurodatan ja tekstin generaattoreiden syötteeseen teksteissä, joissa diskurssisuhteet ovat tärkeässä roolissa. Tätä varten toteutamme uudelleen klassisen NLG-järjestelmän, Methodius, lausesuunnittelu- ja toteutuskomponentit käyttäen LSTM sekvenssi-to-sekvenssimalleja (seq2seq). Havaitsemme, että vaikka seq2seq-mallit oppivat tuottamaan sujuvaa ja kieliopillista tekstiä huomattavan hyvin riittävän edustavalla Methodius-koulutustiedolla, ne eivät pysty ilmaisemaan Methodiuksen samankaltaisuutta ja kontrastivertailua oikein, ellei niihin sisälly vastaavia RST-suhteita. Lisäksi kokeilemme itseharjoittelun ja käänteisen mallin uudelleenjärjestelyn käyttöä juna-/testidatan yhteensopimattomuuden käsittelemiseksi paremmin ja huomaamme, että vaikka nämä menetelmät auttavat vähentämään sisältövirheitä, on tärkeää sisällyttää diskurssisuhteet syötteeseen optimaalisen suorituskyvyn saavuttamiseksi.', 'cs': 'Zatímco klasické NLG systémy obvykle využívaly hierarchicky strukturované obsahové plány, které obsahovaly diskurzní vztahy jako centrální složky, novější neuronové přístupy většinou mapovaly jednoduché, ploché vstupy do textů, aniž by explicitně reprezentovaly diskurzní vztahy. V tomto článku zkoumáme, zda je výhodné zahrnout diskurzní vztahy do vstupu do nervových generátorů dat-textu pro texty, kde diskurzní vztahy hrají důležitou roli. K tomu opětovně implementujeme komponenty plánování a realizace vět klasického NLG systému Methodius pomocí LSTM sekvence-to-sekvence (seq2seq) modelů. Zjišťujeme, že ačkoli seq2seq modely se mohou naučit generovat plynulé a gramatické texty pozoruhodně dobře s dostatečně reprezentativními metodějovými tréninkovými daty, nemohou se naučit správně vyjádřit Metodějovu podobnost a kontrastní srovnání, pokud nejsou do vstupů zahrnuty odpovídající RST vztahy. Kromě toho experimentujeme s využitím vlastního tréninku a reverzního modelového přesměrování, abychom lépe zvládli nesoulad dat s vlakem/testováním, a zjistili jsme, že i když tyto metody pomáhají omezit chyby obsahu, zůstává nezbytné zahrnout diskurzní vztahy do vstupu pro dosažení optimálního výkonu.', 'ha': "Waku da tsarin NLG'ura na classic aka yi amfani da shiryoyin kayan ƙunci na hiterarchically da aka daidaita kayan ƙunci waɗanda ke cikin haɗi da mazaɓa kamar composer masu tsakiya, masu ƙarƙashin hanyarwa na takarda masu sauri, ko kuma an bayyana mazaunin magana bayani. Daga wannan takardan, Munã tambaya ko yana da amfani da ka haɗa mazaɓa cikin a cikin shirin da aka shigar da su zuwa wajen-data-zuwa-text wa littãfin da aka yi amfani da idan mazaɓa sun yi amfani da wani roli na muhimu. To, don haka, za mu cika kalma na shirin yin shirin da gaske cikin tsarin NLG mai classic, Methodius, don mu yi amfani da misalin LSSM-da-sequence (seq2seq). Tuna gane cewa, kuma kõ dã misalin seq2seq za su iya iya ƙiƙiro littãfin masu buƙata da grammati mai girma da data masu tsari na Methodius da ɗan sha'awa, bã za su iya karanta bayan bayyana daidaita da misãlin Methodius kuma da daidaita, sai ba su haɗi da danganta na RTR da inganci ba cikin inputai. Ina ƙara, za mu jarraba game da amfani da masu yin amfani da shiryarwa na kanana, kuma za mu kõma misalin misalin motsi dõmin ka sami tsarin tog/jarrabo data wanda ba su yi daidai ba, kuma ka gane cewa, a lokacin da waɗannan metode sunã taimakon su ƙara ɓata masu ciki, sai na da muhimu ya kamata ka haɗi da mazaɓa cikin shirin da za'a iya samun aikin da za", 'jv': 'Mungkin usul kelas NLG sistem sing digawe akeh operasi tentang karo akeh perusahaan winih Nang kuwi iki, awak dhéwé ujian menehi nggawe barang nggawe gerakan kelompok nggawe barang langgar sampeyan ingkang data-to-text nggambar texting Ngawe di ngerti, kita mulai nggawe kelompok nggawe barang seneng pisan karo sistem CLG, Metojus, iso nggambar model SLT-to-sekondi (seq2seq). Awak dhéwé luwih ngerti, nik sampeyan seq2seq model iso nggambar kelaleng langgar sampeyan lan nggambar textil sing dadi nggawe metutêrung metutêr, yo ora iso nggambar nggambar sampeyan karo metutêr sampeyan karo ngrebut mên dhéwé. Label', 'he': 'While classic NLG systems typically made use of hierarchically structured content plans that included discourse relations as central components, more recent neural approaches have mostly mapped simple, flat inputs to texts without representing discourse relations explicitly.  בעיתון הזה, אנו חוקרים אם זה מועיל לכלול יחסי דיבור בתכנית לגנרטורים של נתונים עצביים לטקסט לטקסטים שבו יחסי דיבור משחקים תפקיד חשוב. כדי לעשות זאת, אנחנו משלים מחדש את רכיבי תכנון המשפטים והביצוע של מערכת NLG קלאסית, Metodius, בשימוש מודלים LSTM רצף-לרצף (seq2seq). אנו מוצאים שלמרות שהדוגמנים seq2seq יכולים ללמוד ליצור טקסטים נוזלים וגרמטיים היטב ביותר עם נתוני אימון שיטה מייצגים מספיק, הם לא יכולים ללמוד להביע נכון את הדמיון של Metodius ושוואות ההתנגדות אלא אם יחסי RST תוכלו להיכנס. בנוסף, אנו מנסים להשתמש באימונים עצמיים ולהפוך מודל מחדש שקשור כדי להתמודד טוב יותר עם אי-התאמות של נתוני רכבת/מבחן, ולמצוא שאם השיטות האלה עוזרות להפחית טעויות בתוכן, זה נשאר חיוני לכלול יחסי דיבור בתכנית כדי להשיג ביצועים אופטימיים.', 'sk': 'Medtem ko so klasični sistemi NLG običajno uporabljali hierarhično strukturirane vsebinske načrte, ki so vključevali diskurzne odnose kot osrednje komponente, so novejši nevralni pristopi večinoma preslikali preproste, ravne vnose v besedila, ne da bi izrecno predstavljali diskurzne odnose. V prispevku raziskujemo, ali je koristno vključiti diskurzne relacije v vnos nevronskih generatorjev podatkov-besedilo za besedila, kjer imajo diskurzne relacije pomembno vlogo. V ta namen ponovno izvajamo komponente načrtovanja in uresničevanja stavkov klasičnega sistema NLG Methodius z uporabo modelov LSTM zaporedja v zaporedje (seq2seq). Ugotavljamo, da čeprav se modeli seq2seq naučijo ustvarjati tekoča in slovnična besedila izjemno dobro z dovolj reprezentativnimi Metodijevimi podatki o usposabljanju, se ne morejo naučiti pravilno izraziti Metodijeve podobnosti in kontrastnih primerjav, razen če so v vnose vključene ustrezne relacije RST. Poleg tega eksperimentiramo z uporabo samousposabljanja in ponovnega razvrščanja modelov za boljše obvladovanje neskladij podatkov med vlakom in preskusom ter ugotavljamo, da je ključnega pomena vključiti diskurzne relacije v vnos, da bi dosegli optimalno učinkovitost.', 'bo': 'While classic NLG systems typically made use of hierarchically structured content plans that included discourse relations as central components, more recent neural approaches have mostly mapped simple, flat inputs to texts without representing discourse relations explicitly. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཡིག To do so, we reimplement the sentence planning and realization components of a classic NLG system, Methodius, using LSTM sequence-to-sequence (seq2seq) models. ང་ཚོས་ཀྱིས་seq2seq དཔེ་དབྱིབས་ཡུལ་གྱིས་པ་དང་གྲངས་རིག་གྱི་ཡིག Additionally, we experiment with using self-training and reverse model reranking to better handle train/test data mismatches, and find that while these methods help reduce content errors, it remains essential to include discourse relations in the input to obtain optimal performance.'}
{'en': 'From Before to After : Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain', 'ar': 'من "قبل" إلى "بعد": توليد تعليمات اللغة الطبيعية من أزواج الصور في مجال بصري بسيط', 'es': 'Del «antes» al «después»: generación de instrucciones en lenguaje natural a partir de pares de imágenes en un dominio visual simple', 'fr': "De «\xa0Avant\xa0» à «\xa0Après\xa0»\xa0: Génération d'instructions en langage naturel à partir de paires d'images dans un domaine visuel simple", 'pt': 'De “Antes” a “Depois”: Gerando instruções de linguagem natural a partir de pares de imagens em um domínio visual simples', 'ja': '「Before」から「After」へ：シンプルなビジュアルドメイン内の画像ペアから自然言語のインストラクションを生成する', 'zh': '自"前"至"后":从"视"至"后",从"后"至"后"至', 'hi': '"पहले" से "के बाद" तक: एक साधारण दृश्य डोमेन में छवि जोड़े से प्राकृतिक भाषा निर्देश उत्पन्न करना', 'ru': 'От «До» до «После»: создание инструкций на естественном языке из пар изображений в простой визуальной области', 'ga': 'Ó “Roimh” go “I ndiaidh”: Treoracha Teanga Nádúrtha a Ghiniúint ó Phéirí Íomhánna i bhFearann Simplí Amhairc', 'ka': "'წინ' დან 'შემდეგ': გამოსახულებული სახელსაწყოთა დისტრუქტურაციების შექმნა", 'hu': '"Előtte" és "Utána": Természetes nyelvi utasítások generálása képpárokból egy egyszerű vizuális tartományban', 'el': 'Από το "πριν" στο "μετά": Δημιουργία οδηγιών φυσικής γλώσσας από ζεύγη εικόνων σε έναν απλό οπτικό τομέα', 'lt': 'Nuo „Prieš“ iki „Po“: gamtos kalbos instrukcijų kūrimas iš vaizdo poros paprastoje vizualinėje srityje', 'kk': "'Алдында' дегеннен 'Келесіден кейін' дегенге: Кескіннің қосымшаларынан қарапайым көрінетін доменге табиғи тіл құқықтарын құру", 'it': "Da 'Prima' a 'Dopo': Generare istruzioni di linguaggio naturale da coppie di immagini in un semplice dominio visivo", 'mk': 'Од „ Пред “ до „ После “: генерирање инструкции за природен јазик од парови слики во едноставен визуелен домен', 'ml': "'പിന്നെ' മുമ്പ് 'പിന്നീട്' വരെ: ചിത്രത്തില്\u200d നിന്നും പേയിരില്\u200d നിന്നും സ്വാഭാവികമായ ഭാഷ ഉപദേശങ്ങള്\u200d സൃഷ്ടി", 'mt': "From 'Before' to 'After': Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain", 'ms': "Dari 'Sebelum' ke 'Selepas': Menjana Arahan Bahasa Semulajadi dari pasangan Imej dalam Domain Visual Mudah", 'ro': 'De la "Înainte" la "După": generarea instrucțiunilor de limbaj natural din perechi de imagini într-un domeniu vizual simplu', 'mn': "'Өмнө'-ээс 'Дараа'-ээс': Хурдан харагдах Холбооны Байгалийн Холбооны Зөвлөлтийг Ингэж", 'no': 'Frå « før » til « etter »: Lagar naturleg språk- instruksjonar frå biletparer i eit enkelt synleg domene', 'pl': 'Od "przed" do "po": generowanie instrukcji języka naturalnego z par obrazów w prostej domenie wizualnej', 'so': "From 'Hore' to 'After': Generating Talobixinta afka asalka ah from Pairs in a Simple Visual Domain", 'si': "'කලින්' වෙනුවෙන් 'පස්සේ' වෙනුවෙන්: පින්තූර ජාතිකයෙන් පින්තූරණය සඳහා සාමාන්\u200dය ප්\u200dරදේශ විදි", 'sv': 'Från "Före" till "Efter": Generera instruktioner för naturligt språk från bildpar i en enkel visuell domän', 'sr': "Od 'Pre' do 'After': Generiranje prirodne jezičke instrukcije iz Pare slika u jednostavnom vizualnom domenu", 'ur': "'پہلے' سے 'بعد' - تصویر کے جوڑوں سے سادہ نظر والی ڈومین میں سادہ بصیرت میں طبیعی زبان کی تعلیمات پیدا کی جاتی ہے", 'ta': "From 'Before' to 'After': Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain", 'uz': "From 'Before' to 'After': Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain", 'vi': "Từ'Trước'đến'Sau': Tạo ra hướng dẫn ngôn ngữ tự nhiên từ các thợ bút ảnh trong một miền nhìn đơn giản", 'da': "Fra 'Før' til 'Efter': Generering af instruktioner til naturligt sprog fra billedpar i et simpelt visuelt domæne", 'bg': 'От "Преди" до "След": Генериране на естествени езикови инструкции от двойки изображения в прост визуален домейн', 'hr': "Od 'prije' do 'poslije': Generiranje prirodnih jezičkih instrukcija iz pare slika u jednostavnom vizualnom domenu", 'nl': "Van 'voor' naar 'na': het genereren van instructies voor natuurlijke taal van beeldparen in een eenvoudig visueel domein", 'fa': "از 'قبل' تا 'بعد' : تولید دستورات زبان طبیعی از جفت تصویر در یک دامنه ساده\u200cی ویژه", 'de': "Von 'Vorher' zu 'Nachher': Erzeugen natürlicher Sprachanweisungen von Bildpaaren in einer einfachen visuellen Domäne", 'id': "Dari 'Sebelum' ke 'Setelah': Menjana Instruksi Bahasa Alami dari Pair Gambar dalam Domain Visual Sederhana", 'ko': 'Before에서 After까지: 간단한 시각 영역의 이미지에서 자연 언어 생성 명령', 'sw': "Kutoka 'Kabla' hadi 'Baada': Kutengeneza Ufunzo wa lugha ya asili kutoka Pamoja la Picha katika Domain ya Visual Simple", 'af': "Van 'Voor' na 'Na' Genereer Natuurlike Taal Instruksies van Beeld Pairs in' n Eenvoudige Visuele Domein", 'tr': "'Öňden' we 'Ondan soňra': Resim Ködlemelerinden bejerli Diller Döküşir", 'hy': '«Նախկինում» մինչև «Հաջորդ»: Պարզ տեսողական դասակարգում բնական լեզվի դասակարգումներ ստեղծելը պատկերների զույգերից', 'az': "'Daha öncə' ilə 'Daha sonra': Görünüş Domasında Qəbiətli Dil Öyrənməsi", 'am': "ከ'በፊት' ወደ 'በኋላ': Generating Natural language instructions from Image Pairs in a simple Visual Domain", 'bn': "'পরবর্তী' থেকে 'পরবর্তী' থেকে: সাধারণ ভাষা থেকে ছবির পেয়ার থেকে স্বাভাবিক ভাষা নির্দেশাবলী তৈরি করা হচ্ছে", 'bs': "Od 'prije' do 'poslije': Generiranje prirodnih jezičkih instrukcija iz pare slika u jednostavnom vizualnom domenu", 'cs': "Od 'Před' do 'Po': Generování instrukcí přirozeného jazyka z obrazových párů v jednoduché vizuální doméně", 'et': '"Enne" kuni "Pärast": looduslike keelejuhiste genereerimine pildipaaridest lihtsas visuaalses domeenis', 'fi': 'Ennen ja jälkeen: Luonnollisten kieliohjeiden luominen kuvapareista yksinkertaisella visuaalisella alueella', 'ca': "Des de 'abans' a 'Després': generar instruccions de llenguatge natural a partir de parelles d'imatges en un domini visual senzill", 'sq': "Nga 'Para' në 'Pas': Gjenerimi i Instruksioneve për gjuhën natyrore nga palët e imazheve në një domen të thjeshtë vizual", 'jv': 'text-tool-action', 'ha': '@ action: button', 'bo': "From 'Before' to 'After': Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain", 'sk': "Od 'Pred' do 'Po': Ustvarjanje naravnih jezikovnih navodil iz slikovnih parov v preprosti vizualni domeni", 'he': "מ 'לפני' ל 'אחרי': לייצר הוראות לשפה טבעית מזוגי תמונות בתחום חזותי פשוט"}
{'en': 'While certain types of instructions can be com-pactly expressed via images, there are situations where one might want to verbalise them, for example when directing someone. We investigate the task of Instruction Generation from Before / After Image Pairs which is to derive from images an instruction for effecting the implied change. For this, we make use of prior work on instruction following in a visual environment. We take an existing dataset, the BLOCKS data collected by Bisk et al. (2016) and investigate whether it is suitable for training an instruction generator as well. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning. Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it ; and by creating template-based targeted instructions), we investigate areas for improvement. We find that captioning models get some way towards solving the task, but have some difficulty with it, and future improvements must lie in the way the change is detected in the instruction.', 'ar': 'بينما يمكن التعبير عن أنواع معينة من التعليمات بشكل متوافق عبر الصور ، إلا أن هناك مواقف قد يرغب فيها المرء في التعبير عنها لفظيًا ، على سبيل المثال عند توجيه شخص ما. نحن نحقق في مهمة إنشاء التعليمات من أزواج الصور قبل / بعد والتي تتمثل في اشتقاق تعليمات من الصور لإحداث التغيير الضمني. لهذا ، فإننا نستفيد من العمل السابق على التعليمات التالية في البيئة المرئية. نأخذ مجموعة بيانات حالية ، وبيانات الكتل التي تم جمعها بواسطة Bisk et al. (2016) وتحقق مما إذا كان مناسبًا لتدريب منشئ التعليمات أيضًا. نجد ذلك ، ونبحث في عدة خطوط أساسية بسيطة ، ونأخذها من المهمة ذات الصلة بالتعليق على الصورة. من خلال سلسلة من التجارب التي تبسط المهمة (عن طريق جعل معالجة الصور أسهل أو تخطيها جانبًا تمامًا ؛ ومن خلال إنشاء إرشادات مستهدفة قائمة على القوالب) ، نتحرى مجالات التحسين. نجد أن نماذج التسميات التوضيحية تجد طريقًا ما نحو حل المهمة ، ولكن لديها بعض الصعوبة في حلها ، ويجب أن تكمن التحسينات المستقبلية في الطريقة التي يتم بها اكتشاف التغيير في التعليمات.', 'es': 'Si bien ciertos tipos de instrucciones se pueden expresar de forma compacta a través de imágenes, hay situaciones en las que uno puede querer verbalizarlas, por ejemplo, al dirigir a alguien. Investigamos la tarea de Generación de instrucciones a partir de pares de imágenes antes/después, que consiste en derivar de las imágenes una instrucción para efectuar el cambio implícito. Para ello, utilizamos el trabajo previo sobre la instrucción que sigue en un entorno visual. Tomamos un conjunto de datos existente, los datos de BLOCKS recopilados por Bisk et al. (2016) e investigamos si también son adecuados para entrenar a un generador de instrucciones. Descubrimos que sí, e investigamos varias líneas de base simples, tomando estas de la tarea relacionada de la subtitulación de imágenes. A través de una serie de experimentos que simplifican la tarea (al facilitar el procesamiento de imágenes o al eludirlo por completo, y al crear instrucciones específicas basadas en plantillas), investigamos áreas de mejora. Descubrimos que los modelos de subtitulado consiguen resolver la tarea, pero tienen algunas dificultades con ello, y las mejoras futuras deben estar en la forma en que se detecta el cambio en la instrucción.', 'pt': 'Embora certos tipos de instruções possam ser expressas de forma compacta por meio de imagens, há situações em que se pode querer verbalizá-las, por exemplo, ao dirigir alguém. Investigamos a tarefa de Geração de Instrução a partir de Pares de Imagens Antes/Depois que é derivar das imagens uma instrução para efetuar a mudança implícita. Para isso, utilizamos um trabalho prévio de instrução seguindo em ambiente visual. Tomamos um conjunto de dados existente, os dados BLOCKS coletados por Bisk et al. (2016) e investigar se é adequado para treinar um gerador de instruções também. Descobrimos que sim e investigamos várias linhas de base simples, tirando-as da tarefa relacionada de legendagem de imagens. Por meio de uma série de experimentos que simplificam a tarefa (tornando o processamento de imagens mais fácil ou evitando-o completamente; e criando instruções direcionadas baseadas em modelos), investigamos áreas de melhoria. Achamos que os modelos de legendagem de alguma forma conseguem resolver a tarefa, mas têm alguma dificuldade com isso, e melhorias futuras devem estar na forma como a mudança é detectada na instrução.', 'fr': "Bien que certains types d'instructions puissent être exprimés de manière compacte via des images, il existe des situations où l'on peut vouloir les verbaliser, par exemple lorsqu'on dirige quelqu'un. Nous étudions la tâche de génération d'instructions à partir de paires d'images avant/après qui consiste à dériver des images une instruction pour effectuer le changement implicite. Pour cela, nous utilisons des travaux antérieurs sur le suivi des instructions dans un environnement visuel. Nous prenons un ensemble de données existant, les données BLOCKS collectées par Bisk et al. (2016) et étudions s'il convient également à la formation d'un générateur d'instructions. Nous trouvons que c'est le cas et examinons plusieurs lignes de base simples, en les prenant à partir de la tâche connexe de sous-titrage d'image. Grâce à une série d'expériences qui simplifient la tâche (en simplifiant le traitement de l'image ou en le contournant complètement\xa0; et en créant des instructions ciblées basées sur des modèles), nous étudions les domaines à améliorer. Nous constatons que les modèles de sous-titrage parviennent à résoudre le problème, mais qu'ils ont quelques difficultés à le faire, et les améliorations futures doivent résider dans la façon dont le changement est détecté dans l'instruction.", 'ja': '特定の種類の指示は、画像を介して正確に表現することができますが、例えば、誰かを指揮するときに、それらを口頭で伝えたい場合があります。 画像から暗示的な変化をもたらすための指示を導き出す、画像ペアの前後からの命令生成のタスクを調査する。 そのために、視覚的環境でのインストラクションに従った先行作業を活用している。 Bisk et al .( 2016)によって収集されたブロックデータである既存のデータセットを取得し、インストラクションジェネレータのトレーニングにも適しているかどうかを調査します。 いくつかの単純なベースラインを調査しますこれらは画像のキャプション付けに関連するタスクから取られています タスクを簡素化する一連の実験を通じて（画像処理を簡単にするか、完全に横に踏み込むか、そしてテンプレートベースのターゲット指示を作成することによって）、改善すべき領域を調査します。 キャプションモデルは、タスクを解決するために何らかの方法を得るが、それにいくつかの困難があり、今後の改善は、インストラクションでの変更の検出方法に依存しなければならないことがわかります。', 'hi': 'जबकि कुछ प्रकार के निर्देशों को छवियों के माध्यम से कॉम-पैक्टली व्यक्त किया जा सकता है, ऐसी स्थितियां हैं जहां कोई उन्हें मौखिक रूप से व्यक्त करना चाह सकता है, उदाहरण के लिए जब किसी को निर्देशित किया जाता है। हम पहले / बाद में छवि जोड़े से निर्देश पीढ़ी के कार्य की जांच करते हैं जो छवियों से निहित परिवर्तन को प्रभावित करने के लिए एक निर्देश प्राप्त करना है। इसके लिए, हम एक दृश्य वातावरण में निम्नलिखित निर्देश पर पूर्व कार्य का उपयोग करते हैं। हम एक मौजूदा डेटासेट लेते हैं, बिस्क एट अल द्वारा एकत्र किए गए ब्लॉक डेटा (2016) और जांच करते हैं कि क्या यह एक निर्देश जनरेटर के प्रशिक्षण के लिए भी उपयुक्त है। हम पाते हैं कि यह है, और कई सरल आधार रेखाओं की जांच करें, इन्हें छवि कैप्शनिंग के संबंधित कार्य से ले रहे हैं। प्रयोगों की एक श्रृंखला के माध्यम से जो कार्य को सरल बनाते हैं (छवि प्रसंस्करण को आसान या पूरी तरह से साइड-स्टेपिंग करके; और टेम्पलेट-आधारित लक्षित निर्देश बनाकर), हम सुधार के लिए क्षेत्रों की जांच करते हैं। हम पाते हैं कि कैप्शनिंग मॉडल को कार्य को हल करने की दिशा में कुछ रास्ता मिलता है, लेकिन इसके साथ कुछ कठिनाई होती है, और भविष्य में सुधार ों को निर्देश में परिवर्तन का पता लगाने के तरीके में झूठ बोलना चाहिए।', 'zh': '虽形可象,人或欲言,如在指导之时。 考之于前/后之成令,即象之隐变也。 因此,我们因为在视觉中遵奉指令的前务。 臣等所采见数集,即Bisk等(2016)所集BLOCKS数,并究其亦宜训练指生成器。 验其简基线,取基线于图字幕。 以列简者实验(以图像处理易尽避也;以创模板者,以)也。 吾见字幕有以决之,有以难之,未来之改进,必在指令检改之道。', 'ru': 'В то время как некоторые типы инструкций могут быть коллективно выражены через изображения, есть ситуации, когда кто-то может захотеть их словесно выразить, например, когда направляет кого-то. Мы исследуем задачу генерации инструкций из до/после пары изображений, которая заключается в том, чтобы получить из изображений инструкцию для осуществления подразумеваемого изменения. Для этого мы используем предыдущую работу по обучению, следуя в визуальной среде. Мы берём существующий набор данных, блокируем данные, собранные Bisk et al. (2016), и исследуем, подходит ли он также для обучения генератора инструкций. Мы обнаружили, что это так, и исследовали несколько простых базовых линий, взяв их из связанной задачи субтитров изображений. С помощью серии экспериментов, которые упрощают задачу (делая обработку изображения проще или полностью перешагнув через нее; и создавая целевые инструкции на основе шаблонов), мы исследуем области для улучшения. Мы обнаружили, что модели субтитров получают некоторый путь к решению задачи, но испытывают определенные трудности с ней, и будущие улучшения должны заключаться в том, как в инструкции обнаруживается изменение.', 'ga': 'Cé gur féidir cineálacha áirithe treoracha a chur in iúl go dlúth trí íomhánna, tá cásanna ann inar mhaith le duine iad a chur i bhfocail, mar shampla agus duine á stiúradh. Déanaimid imscrúdú ar an tasc a bhaineann le Giniúint Teagaisc ó Phéirí Íomhánna Roimh/I nDiaidh, is é sin treoir chun an t-athrú intuigthe a chur i bhfeidhm a dhíorthú ó íomhánna. Chuige seo, bainimid úsáid as réamhobair ar theagasc a leanann i dtimpeallacht amhairc. Glacaimid tacar sonraí atá ann cheana féin, na sonraí BLOCKS bailithe ag Bisk et al. (2016) agus fiosróidh sé an bhfuil sé oiriúnach chun gineadóir teagaisc a oiliúint freisin. Faighimid go bhfuil sé, agus fiosraíonn muid roinnt bonnlínte simplí, á gcur seo ón tasc gaolmhar le fotheidealú íomhánna. Trí shraith turgnaimh a shimplíonn an tasc (trí phróiseáil íomhá a dhéanamh níos éasca nó go hiomlán taobhchéimnithe; agus trí threoracha spriocdhírithe bunaithe ar theimpléad a chruthú), déanaimid imscrúdú ar réimsí atá le feabhsú. Faighimid amach go n-éiríonn le samhlacha fotheidealaithe bealach éigin i dtreo an tasc a réiteach, ach go mbíonn deacracht éigin acu leis, agus caithfidh feabhsuithe sa todhchaí a bheith sa tslí a bhraitear an t-athrú sa treoir.', 'ka': 'თუმცა განსაკუთრებული ტიპი ინსტუქციები შეიძლება com-პასუტურად გამოსახულება, არსებობს სიტუქციები, რომლებიც ერთი შეიძლება მინდა გაგრძელოთ, მაგალითად როცა ვინმე ჩვენ ინსტრუქტურაციის შექმნის დავასწავლობთ წინ/შემდეგ გამოსახულების პარამეტრებიდან, რომელიც გამოსახულებიდან იქნება ინსტრუქტურაცია, რომელიც იქნება ინს ამისთვის, ჩვენ ვიყენებთ წინასწორი სამუშაო ინსტრუქციის შემდეგ ვიზუალური გარეშე. ჩვენ მივიღეთ მონაცემების კონფიგურაცია, BLOCKS მონაცემები, რომელიც Bisk et al. (2016) და გამოვაკეთებთ თუ ეს საჭიროა ინსტრუქციის генენერатоრის განაკეთებაში. ჩვენ აღმოჩნეთ, რომ ეს არის, და გამოვაკვიროთ რამდენიმე საუკეთესო ფესტური ხაზები, რომლებიც გამოყენებული საქაღალდედან გამოყენება. ექსპერიმენტის სერიომენტების გამოყენებით, რომლებიც დავამუშავებენ რაოდენობას (გამოსახულების გამოყენება უფრო მარტივი ან უფრო მხოლოდ მხოლოდ მხოლოდ დავწყებენ;  ჩვენ აღმოჩნეთ, რომ მოდელები საკუთარი მოდელები მიიღებენ რაღაც დავაწყებენ, მაგრამ მათგან მათგანი არაფერი დარწმუნდება, და მომავალე შესაძლებელებები უნდა იყოს როგორც შეცვლ', 'el': 'Ενώ ορισμένοι τύποι οδηγιών μπορούν να εκφραστούν από κοινού μέσω εικόνων, υπάρχουν καταστάσεις όπου μπορεί κανείς να θέλει να τις εκφράσει προφορικά, για παράδειγμα όταν διευθύνει κάποιον. Ερευνούμε το καθήκον της δημιουργίας οδηγιών από ζεύγη εικόνας πριν/μετά που είναι να αντλήσει από εικόνες μια οδηγία για την πραγματοποίηση της υπονοούμενης αλλαγής. Για το σκοπό αυτό, χρησιμοποιούμε προηγούμενες εργασίες για οδηγίες που ακολουθούν σε ένα οπτικό περιβάλλον. Λαμβάνουμε ένα υπάρχον σύνολο δεδομένων, τα δεδομένα που συλλέγονται από την κ.α. (2016) και διερευνούμε αν είναι κατάλληλα για την εκπαίδευση μιας γεννήτριας οδηγιών. Βρίσκουμε ότι είναι, και ερευνούμε αρκετές απλές γραμμές βάσης, παίρνοντας αυτές από το σχετικό έργο της λεζάντας εικόνας. Μέσα από μια σειρά πειραμάτων που απλοποιούν την εργασία (κάνοντας την επεξεργασία εικόνας ευκολότερη ή παρέκκλισέ την εντελώς και δημιουργώντας στοχευμένες οδηγίες βάσει προτύπων), διερευνούμε τομείς βελτίωσης. Διαπιστώνουμε ότι τα μοντέλα λεζάντας παίρνουν κάποιο τρόπο προς την επίλυση της εργασίας, αλλά έχουν κάποια δυσκολία με αυτό, και οι μελλοντικές βελτιώσεις πρέπει να βρίσκονται στον τρόπο με τον οποίο ανιχνεύεται η αλλαγή στην οδηγία.', 'hu': 'Míg bizonyos típusú utasításokat képeken keresztül is összhangban lehet kifejezni, vannak olyan helyzetek, amikor szóban szeretné őket mondani, például ha valaki irányít. Vizsgáljuk az Instruction Generation from before/after Image Pairs feladatát, melynek célja, hogy a képekből az implicit változás végrehajtására vonatkozó utasítást alakítsuk ki. Ehhez a vizuális környezetben végzett oktatást követő előzetes munkát veszünk igénybe. Felvesszük a meglévő adatkészletet, a Bisk et al. (2016) által összegyűjtött BLOCKS adatokat, és megvizsgáljuk, hogy alkalmas-e egy oktatási generátor képzésére is. Megtaláljuk, hogy igen, és több egyszerű alapvonalat vizsgálunk, ezeket a kapcsolódó képfeliratozási feladatból vettük. A feladatot egyszerűsítő kísérletsorozat révén (a képfeldolgozás megkönnyítésével vagy teljesen elkerülésével; sablon alapú célzott utasítások létrehozásával) vizsgáljuk a fejlesztésre szoruló területeket. Úgy találjuk, hogy a feliratozási modellek eljutnak valamilyen utat a feladat megoldásához, de nehézségeink vannak vele, és a jövőbeli fejlesztéseknek abban kell alakulniuk, hogy a változás észlelhető az utasításban.', 'it': "Mentre alcuni tipi di istruzioni possono essere espressi in modo coerente tramite immagini, ci sono situazioni in cui si potrebbe voler verbalizzare, ad esempio quando si dirige qualcuno. Investighiamo il compito di Generazione delle Istruzioni da Coppie di Immagine Prima/Dopo che è quello di derivare dalle immagini un'istruzione per effettuare il cambiamento implicito. Per questo, facciamo uso del lavoro precedente sulle istruzioni seguendo in un ambiente visivo. Prendiamo un set di dati esistente, i dati BLOCKS raccolti da Bisk et al. (2016) e indaghiamo se è adatto anche per la formazione di un generatore di istruzioni. Scopriamo che lo è, e indaghiamo diverse semplici linee di base, prendendo questi dal relativo compito di didascalia delle immagini. Attraverso una serie di esperimenti che semplificano il compito (rendendo l'elaborazione delle immagini più facile o completamente fuori luogo; e creando istruzioni mirate basate su template), indaghiamo le aree di miglioramento. Troviamo che i modelli di didascalia ottengono qualche modo per risolvere il compito, ma hanno qualche difficoltà con esso, e i miglioramenti futuri devono risiedere nel modo in cui il cambiamento viene rilevato nell'istruzione.", 'kk': 'Кескіндер арқылы кейбір мәліметтердің түрлері com- арқылы кескіндерді көрсетуге болады, мысалы, кейбірді бағыттау кезінде оны вербализациялау мүмкін болады. Біз кескіндерден келтірілген өзгерістерді әсер ету үшін кескіндерден алдында/ кейін құру құрылғының тапсырмасын зерттейміз. Бұл үшін біз алдыңғы жұмыс істеуді көрініс ортасында көрсетуге қолданамыз. Біз бар деректер жинағын, Биск et al. (2016) жинақталған BLOCKS деректерін қолданатын және мәлімет генераторын оқыту үшін керек пе екенін зерттеп береміз. Біз ол кескін айдарының қатынастық тапсырмасынан алып, бірнеше қарапайым негізгі сызықтарды зерттейміз. Тапсырманы қарапайым көмектесетін бірнеше тәжірибелер арқылы (кескінді өзгерту оңай немесе толық жағынан басып, үлгі негіздеген нақты мәліметтерді құру арқылы) жақсарту үшін аумақтарды Біз айдарлық үлгілерін тапсырманы шешу үшін бірнеше жолы табылады, бірақ оның ішінде бірнеше мәселелер болады, және болашақ жақсартулар мәліметтің өзгерістерін анықтау үшін қалай жа', 'mk': 'Иако одредени типови на инструкции можат да се изразат компактно преку слики, постојат ситуации во кои може да се сака да се вербализираат, на пример кога се управува со некого. Ние ја истражуваме задачата на генерација инструкции од парови на слики пред/после која е да се извлече од слики инструкција за влијание на имплицираната промена. За ова, користиме претходна работа на инструкциите кои следат во визуелна средина. Земаме постоечки податоци, БЛОКС податоци собрани од Биск и други (2016) и истражуваме дали се соодветни и за обука на генератор на инструкции. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning.  Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  Најдовме дека моделите за насловување имаат некаков начин да ја решат задачата, но имаат некакви тешкотии со неа, и идните подобрувања мора да лежат на начинот на кој се детектира промената во инструкцијата.', 'ms': 'Sementara jenis tertentu arahan boleh diungkapkan dengan mudah melalui imej, terdapat situasi di mana seseorang mungkin ingin mengucapkannya secara verbal, misalnya apabila mengarahkan seseorang. Kami menyelidiki tugas Penjanaan Arahan dari Pasangan Imej Sebelum/Selepas yang mana adalah untuk berasal dari imej arahan untuk mempengaruhi perubahan yang termasuk. Untuk ini, kita menggunakan kerja sebelumnya pada arahan mengikuti dalam persekitaran visual. We take an existing dataset, the BLOCKS data collected by Bisk et al. (2016) and investigate whether it is suitable for training an instruction generator as well.  Kami mendapati bahawa ia adalah, dan menyelidiki beberapa garis dasar sederhana, mengambil ini dari tugas berkaitan dengan captioning imej. Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  Kami mendapati bahawa model captioning mendapat beberapa cara untuk menyelesaikan tugas, tetapi mempunyai beberapa kesulitan dengan ia, dan peningkatan masa depan mesti terletak dalam cara perubahan dikesan dalam arahan.', 'lt': 'Nors tam tikrų tipų instrukcijos gali būti aiškiai išreikštos per vaizdus, yra situacijų, kai gali būti norima jas žodžiu išreikšti, pavyzdžiui, kai kažkas nurodo. Mes tiriame instrukcijų generavimo iš prieš ir po paveikslėlių poros užduotį, kuri turi būti parengta iš paveikslėlių instrukcija daryti numatomą pokytį. For this, we make use of prior work on instruction following in a visual environment.  Imame esamą duomenų rinkinį, BLOCKS duomenis, kuriuos surinko Bisk et al. (2016), ir tiriame, ar jis taip pat tinka mokymui instrukcijos generatoriui. Mes suprantame, kad tai yra ir tiriame keletą paprastų bazinių linijų, paimame juos iš susijusios užduoties, susijusių su vaizdo antraštėmis. Atliekant keletą eksperimentų, kuriais supaprastinama užduotis (palengvinant vaizdo apdorojimą arba visiškai jį nukreipiant į šoną ir sukuriant šablonus pagrįstas tikslines instrukcijas), tiriame sritis, kuriose reikia tobulinti. Mes manome, kad pavadinimo modeliai turi tam tikrą kelią užduoties sprendimui, tačiau turi tam tikrų sunkumų su ja, o būsimi patobulinimai turi būti susiję su mokymo pokyčių nustatymu.', 'ml': 'ചില തരത്തിലുള്ള ഉപദേശങ്ങള്\u200d ചില ചിത്രങ്ങള്\u200d സൂക്ഷ്മമായി ചിട്ടപ്പെടുത്താന്\u200d സാധിക്കുമ്പോള്\u200d ചില സ്ഥിതികള്\u200d ഉണ്ട്, ഒരാള്\u200dക ചിത്രത്തിനു ശേഷം മുന്\u200dപ്/പിന്നീട് മാറ്റങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നതിനുള്ള ഉപദേശം നാം അന്വേഷിക്കുന്നു. ഇതിനു വേണ്ടി, നിര്\u200dദേശങ്ങളുടെ പിന്നാലെ കാണാനുള്ള പരിസ്ഥിതിയില്\u200d നാം മുമ്പ് ജോലി ഉപയോഗിക്കും. ഞങ്ങള്\u200d നിലവിലുള്ള ഡാറ്റാസെറ്റ് എടുക്കുന്നു, ബിസ്ക് എറ്റ് അല്\u200d. (2016) സംഘടിപ്പിച്ച ബിസ്ക് എറ്റ് ഡേറ്റാറ്സ് എടുക്കുന്ന അതാണെന്ന് നമുക്ക് തോന്നുന്നു, കുറച്ച് എളുപ്പമുള്ള ബേസ്ലെയിനുകള്\u200d അന്വേഷിക്കുകയും ചെയ്യുന്നു, ചിത്ര പ്രവര്\u200dത്തിക്കുന്നത് എളുപ്പമാക്കുന്ന ഒരു പരീക്ഷണങ്ങളിലൂടെ (ചിത്രം പ്രവര്\u200dത്തിപ്പിക്കുന്നത് എളുപ്പമോ മുഴുവന്\u200d ഭാഗത്തുനിന്നും പുറത്തുകൂട ഈ ജോലി തീരുമാനിക്കാന്\u200d ഒരു വഴിയുണ്ടെന്ന് നമുക്ക് കണ്ടെത്താം, പക്ഷെ അതില്\u200d കുറച്ച് പ്രശ്നമുണ്ട്, ഭാവിയുടെ മെച്ചപ്പെടുത്തി', 'mt': 'Filwaqt li ċerti tipi ta’ struzzjonijiet jistgħu jiġu espressi b’mod kompat permezz ta’ immaġni, hemm sitwazzjonijiet fejn wieħed jista’ jkun irid iwassalhom b’mod verbali, pereżempju meta jingħata direzzjoni lil xi ħadd. Aħna ninvestigaw il-kompitu tal-Ġenerazzjoni tal-Istruzzjonijiet minn Pawġi ta’ Qabel/Wara l-Immaġni li għandu jiġi minn immaġni struzzjoni biex issir il-bidla implikata. Għal dan, nagħmlu użu minn xogħol preċedenti fuq l-istruzzjoni li ssegwi f’ambjent viżwali. Aħna nieħdu sett ta’ dejta eżistenti, id-dejta tal-BLOCKS miġbura minn Bisk et al. (2016) u ninvestigaw jekk huwiex adattat għat-taħriġ ta’ ġeneratur ta’ tagħlim ukoll. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning.  Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  Aħna nsibu li l-mudelli tal-intestatura jsibu xi mod lejn is-soluzzjoni tal-kompitu, iżda għandhom xi diffikultà bih, u titjib futur għandu jkun fil-mod kif tinstab il-bidla fl-istruzzjoni.', 'mn': 'Хэдийгээр зарим төрлийн заавал зурагт com-хурдан илэрхийлэгдэж болно гэхдээ хэн нэгнийг удирдах үед хэн нэгнийг илэрхийлэх хэрэгтэй нөхцөл байдаг. Бид өмнөх/дараах зураг төрөлхтний захирал төрөлхтний даалгаварыг судалж байна. Энэ нь зурагтаас гарч ирэх захирал юм. Үүний тулд бид өмнөх ажлыг харааны орчинд дагах заавал дээр хэрэглэдэг. Бид Bisk et al-ын цуглуулсан BLOCKS өгөгдлийн санг аваад өгөгдлийг судалж өгдөг. Бид хэд хэдэн энгийн суурь шулуунуудыг судалж, эдгээрийг зураг зураг удирдах үйл ажилаас авч үзсэн. Ажлыг хялбарчилж буй олон туршилтаар (зураг боловсруулах нь илүү амархан эсвэл бүрэн талаар дамжуулах боломжтой болгож, шалгалтын суурь зориулан заавал бүтээхээр) бид сайжруулах талаар судалж байна. Бид ажлыг шийдвэрлэх арга замыг олж мэднэ. Гэхдээ үүнд хэцүү хэцүү байдаг. Ирээдүй сайжруулалт нь заавал дээр өөрчлөлтийг олж мэдэх арга зам дээр байх ёстой.', 'pl': 'Podczas gdy pewne rodzaje instrukcji mogą być wspólnie wyrażane za pomocą obrazów, istnieją sytuacje, w których można chcieć je werbalizować, na przykład kiedy kogoś kieruje. Badamy zadanie generowania instrukcji z par obrazów przed/po, polegające na wyprowadzeniu z obrazów instrukcji dokonywania domniemanej zmiany. W tym celu korzystamy z wcześniejszych prac nad instrukcjami podążającymi za nimi w środowisku wizualnym. Wykorzystujemy istniejący zbiór danych, dane BLOCKS zebrane przez Bisk et al. (2016) i badamy, czy nadaje się on również do szkolenia generatora instrukcji. Odkrywamy, że tak jest i zbadamy kilka prostych linii bazowych, biorąc je z powiązanego zadania podpisywania obrazów. Poprzez serię eksperymentów, które upraszczają zadanie (ułatwiając przetwarzanie obrazu lub całkowicie je omijając; oraz tworząc ukierunkowane instrukcje oparte na szablonach), badamy obszary wymagające ulepszenia. Odkrywamy, że modele podpisów mają jakiś sposób na rozwiązanie zadania, ale mamy z nim pewne trudności, a przyszłe ulepszenia muszą leżeć w sposobie wykrywania zmian w instrukcji.', 'no': 'Mens enkelte typar instruksjonar kan verta uttrykt via bilete, er det situasjonar der ein kan ønskja å verbalisere dei, for eksempel når du direkterer nokon. Vi undersøker oppgåva for oppretting av instruksjon frå før/etter biletparer som skal utførast frå bilete ein instruksjon for å gjera det impliserte endringa. For dette bruker vi førre arbeid på instruksjon følgjande i eit visuell miljø. Vi tar eit eksisterande datasett, BLOCKS-data samla av Bisk et al. (2016) og forsøk om det er passande for å trenja ein instruksjonsgenerator også. Vi finn at det er, og undersøker fleire enkle grunnlinjer, og tar desse frå den relaterte oppgåva av biletet. Med ein rekkje eksperimenter som forenklar oppgåva (ved å gjera biletet enklare eller fullstendig sidestegande, og ved å laga malebaserte målrette instruksjonar), så undersøker vi område for forbedring. Vi finn at tittelmodeller får litt måte mot å løyse oppgåva, men har noen vanskeleg forbedringar med det, og framtidige forbedringar må ligge på måten endringa vert oppdaga i instruksjonen.', 'ro': 'În timp ce anumite tipuri de instrucțiuni pot fi exprimate compact prin imagini, există situații în care cineva ar putea dori să le verbalizeze, de exemplu atunci când regizează pe cineva. Investigăm sarcina Generației Instrucțiunilor din Perechile de Imagini Înainte/După care este de a obține din imagini o instrucțiune pentru efectuarea schimbării implicite. Pentru aceasta, facem uz de lucrul anterior pe urmărirea instrucțiunilor într-un mediu vizual. Preluăm un set de date existent, datele BLOCKS colectate de Bisk et al. (2016) și investigăm dacă este adecvat și pentru instruirea unui generator de instrucțiuni. Descoperim că este și investigăm mai multe linii de referință simple, luând acestea din sarcina aferentă a subtitrării imaginilor. Printr-o serie de experimente care simplifică sarcina (prin simplificarea procesării imaginilor sau depășirea completă a acesteia; și prin crearea de instrucțiuni specifice bazate pe șabloane), investigăm domenii de îmbunătățire. Considerăm că modelele de subtitrare ajung într-un fel spre rezolvarea sarcinii, dar au unele dificultăți cu ea, iar îmbunătățirile viitoare trebuie să stea în modul în care schimbarea este detectată în instrucțiune.', 'si': 'පින්තූර වලින් කිසිම වර්ගයක් සඳහා කිසිම ප්\u200dරකාරයක් com-Pacically ප්\u200dරකාශ කරන්න පුළුවන්, කිසිම කෙනෙක්ව ප්\u200dරකාශ කරපු වෙ අපි කලින්/පස්සේ පින්තූර සම්බන්ධයෙන් පින්තූරයෙන් පින්තූරයෙන් පින්තූරයෙන් පිළිබඳු වෙනස් කරන්න ප්\u200dරකා මේකට, අපි ප්\u200dරධාන වැඩක් පාවිච්චි කරනවා ප්\u200dරධාන විදිහට පස්සේ ප්\u200dරධාන විදිහට. අපි තියෙන්න තියෙන්නේ දත්ත සෙට් එකක්, බිස්ක් ට් ල් එක්ක සංගුණු BLOCKS දත්ත (2016) සහ පරීක්ෂා කරන්න ඒක පුළුවන් දෙයක් ප්\u200dරධ අපිට හොයාගන්න පුළුවන් විදිහට ඒක තමයි කියලා, සරල ප්\u200dරමාණ පරීක්ෂණය කරන්න පුළුවන් විදිහට පින්තූ පින්තූර පරීක්ෂණයක් සමහර විදිහට පරීක්ෂණයක් සඳහා වැඩ කරන්න (පින්තූර පරීක්ෂණය සමහර විදිහට පුළුවන් නැත්නම් පුළුවන් පැ අපිට හොයාගන්න පුළුවන් විදිහට වැඩ කරන්න විදිහක් තියෙනවා, ඒත් ඒකට අමාරුවක් තියෙනවා, ඒ වගේම අනාගතය පුළුවන් විදිහට වෙනස් ව', 'so': 'Inta lagu sameeyo tusaale ahaan tusaale ahaan marka lagu hago qof. We investigate the task of Instruction Generation from Before/After Image Pairs which is to derive from images an instruction for effecting the implied change.  For this, we make use of prior work on instruction following in a visual environment.  Waxaynu qaadannaa saxda macluumaadka, BLOCKS macluumaadkooda ay ka soo ururiyeen Bisk et al. (2016) waxaana baaritaannaa in ay u habboon tahay in la baro dhaqaalaha hagitaanka. Waxaynu ogaanaynaa in taasu tahay, waxaana baaraynaa qaar hab fudud, waxaana ka qaadanay shaqada la xiriira sawirka. Imtixaano kala duduwan oo shaqada sahlisan (marka lagu sameeyo sawirka si fudud ama si buuxda ah u baaraandegista; iyo sameynta hagitaanka macluumaadka lagu hagayo), waxaynu baaritaan meelaha la hago. Waxaynu heli nahay in sameynta qaababka lagu sameynayo, laakiin ay ku adag yihiin in ay ku jirto dhibaato, horumarinta mustaqbalku waa in ay ku jiraan sida loo soo ogaado in beddelka lagu soo beddelo.', 'sv': 'Vissa typer av instruktioner kan uttryckas på ett kompromisslöst sätt via bilder, men det finns situationer där man kanske vill verbalisera dem, till exempel när man regisserar någon. Vi undersöker uppgiften med Instruktionsgenerering från Före/Efter bildpar som är att härleda från bilder en instruktion för att genomföra den implicita förändringen. För detta använder vi oss av tidigare arbete med instruktionsförföljning i en visuell miljö. Vi tar ett befintligt dataset, BLOCKS data som Bisk m.fl. (2016) samlar in och undersöker om det är lämpligt för utbildning av en instruktionsgenerator också. Vi finner att det är det, och undersöker flera enkla baslinjer, med utgångspunkt från den relaterade uppgiften med bildtextning. Genom en serie experiment som förenklar uppgiften (genom att göra bildbearbetningen enklare eller helt kringgående; och genom att skapa mallbaserade riktade instruktioner), undersöker vi områden för förbättring. Vi finner att bildtextningsmodeller får något sätt att lösa uppgiften, men har vissa svårigheter med den, och framtida förbättringar måste ligga i hur förändringen upptäcks i instruktionen.', 'sr': 'Iako se određene vrste instrukcija mogu izraziti na putu slika, postoje situacije u kojima se možda želi verbalizirati, na primer, kad nekoga upućuje. Istražujemo zadatak generacije instrukcije iz prethodnih/nakon pare slika koji je da se izvuče iz slika instrukcija za učinkovitost impliciranih promjena. Za to koristimo ranije rad na instrukciji slijedećim u vizualnom okruženju. Uzimamo postojeću setu podataka, podatke o BLOCKS-u koje je sakupljao Bisk et al. (2016) i istražujemo je li i odgovarajuće za obuku generatora instrukcije. Pronašli smo da jeste i istražujemo nekoliko jednostavnih osnovnih linija, uzimajući ih iz povezanih zadataka snimanja slika. Kroz niz eksperimenata koji pojednostavljaju zadatak (olakšajući obradu slika ili potpuno stajanje na strani; i stvarajući ciljne upute na šablonu), istražujemo područje za poboljšanje. Našli smo da modeli kapcijacije dobijaju neki naèin ka rješavanju zadatka, ali imaju problema s tim, i budući poboljšanja moraju da leže na način otkrivanja promene u uputi.', 'ta': 'சில வகையான கட்டளைகள் படிமங்கள் மூலம் மெதுவாக வெளிப்படுத்தப்படும் போது, சில நிகழ்வுகள் இருக்கிறது, எடுத்துகாட்டும் போது, யாரை நாம் முன்/பிம்பத்திற்குப் பின்னால் இருந்து நிறுவனம் உருவாக்கும் பணியை ஆராய்ச்சி செய்கிறோம். பிம்பத்திலிருந் இதுக்கு, நாம் முன்னால் வேலை பயன்படுத்துகிறோம் ஒரு பார்வையான சூழலில் பின்பற்றும் கட்டளைகளில். நாம் ஏற்கெனவே இருக்கும் தகவல் அமைப்பு, பிஸ்க் மற்றும் அல் சேகரிக்கப்பட்ட தகவல்களை எடுத்து ஒரு கட்டளை உருவாக்குபவருக்கு பொருத்தமா என்பதை ச அது தான் என்று நாம் கண்டுபிடிக்கிறோம் மற்றும் சில எளிய அடிப்பகுதிகளை ஆராய்ச்சி செய்கிறோம், இதை பிம்பத் செயலை எளிதாக்கும் சில சோதனைகளின் மூலம் (பிம்பத்தை செயல்படுத்துவது எளிதாக அல்லது முழு பக்கத்தில் முழுவதும் படிக்கிறது; வார்ப்புருவை சேர்க பிடிப்பு மாதிரிகள் பணியை தீர்க்க ஒரு வழி கிடைக்கும் என்று நாம் கண்டுபிடிக்கும், ஆனால் அதில் சில சில பிரச்சனைகள் இருக்கிறது, மற்', 'ur': 'اگرچہ تصویر کے ذریعے کچھ طریقے کی تعلیمات کام-آسانی طریقے سے واضح کر سکتے ہیں، کچھ ایسے موقعیت ہیں جن میں کسی کو دکھاتے ہیں، جیسے کسی کو دکھاتے ہیں. ہم نے تصویر کے جوڑے سے پہلے/بعد کی ابتداء کی کوشش کی تحقیق کی جو تصویروں سے ایک ہدایت حاصل کرنے کے لئے ہے. اس کے لئے ہم پہلے سے کام کریں گے کہ ایک نظر آنکھوں میں اچھی سفارش کے ذریعہ۔ ہم ایک موجود ڈیٹ سٹ لیتے ہیں، بلاکس ڈیٹ جو Bisk et al (2016) سے جمع کیے گئے ہیں، اور تحقیق کرتے ہیں کہ یہ بھی ایک ایسے علم جنرائیٹر کی آموزش کے لئے مناسب ہے. ہم دیکھتے ہیں کہ یہ ہے، اور چند سادھے بنسٹ لینوں کی تحقیق کریں، ان کو تصویر کپٹینگ کے ارتباط کے کام سے لے لیتے ہیں. ایک سری آزمائش کے ذریعہ سے جو کام کو آسان کر دیتے ہیں (تصویر پرسس کرنے کے ذریعہ اسے آسان یا کامل سائڈ-سٹپٹ کرنے کے ذریعہ، اور ٹمپلٹ-بنیادی موقع یادہانی بنانے کے ذریعہ) ہم مصلحت کے لئے منطقہ کی تح ہم دیکھتے ہیں کہ کپٹیونٹ نمڈلوں کا کام حل کرنے کے لئے کچھ طریقہ حاصل کرتا ہے، لیکن اس کے ساتھ کچھ مشکل ہو جاتا ہے، اور مستقبل تغییرات کی تعلیم کی طریقہ پر ہونا چاہیے۔', 'vi': 'Trong khi một số loại hướng dẫn có thể được tương ứng qua các hình ảnh, có những trường hợp có thể nói ra chúng, ví dụ khi chỉ đạo ai đó. Chúng tôi điều tra nhiệm vụ có thể điều khiển với những người có thể điều khiển với những hình ảnh Cho việc này, chúng tôi sử dụng những nghiên cứu về hướng dẫn theo hướng dẫn trong một môi trường hình ảnh. Chúng tôi lấy một bộ dữ liệu tồn tại, các dữ liệu BLOckS thu thập bởi Bisk et al. (Tập tin phần lớn) và điều tra xem nó có thích hợp để huấn luyện một máy phát hành hướng dẫn không. Chúng tôi tìm thấy nó, và điều tra vài con đường nền đơn giản, lấy chúng từ nhiệm vụ xác định ảnh tương tự. Qua một loạt các thí nghiệm có thể làm đơn giản việc này (bằng cách làm việc xử lý hình ảnh dễ dàng hoặc đảo ngược hoàn toàn; và bằng cách tạo ra các hướng dẫn nhắm vào mẫu), chúng tôi tìm hiểu các khu vực cần cải thiện. Chúng tôi nhận thấy rằng mô hình viết tắt có một cách nào đó để giải quyết nhiệm vụ, nhưng có một số khó khăn với nó, và những cải tiến tương lai phải nằm trong cách mà thay đổi được phát hiện trong hướng dẫn.', 'uz': "Koʻrsatilgan foydalanuvchi turlari rasmlar bilan foydalanishi mumkin, bu yerda ularni bir misol qoʻshishda yordam berishni istasangiz mumkin. Biz rasm buyruqlaridan oldin/keyin Tashkilot Generatish vazifani qidirib, bu rasmlaridan foydalanadigan oʻzgarishni ishga tushirish uchun imkoniyat qilamiz. Bu uchun, biz ko'rinish muhitida birinchi ishni foydalanamiz. Biz mavjud maʼlumotlar tarkibini olib, BLOCKS haqida olingan BLOCKS maʼlumotlarini (Bill et al.(2016) va bu dastur generatorini ishlatishga yetarlicha kerak deb o'rganamiz. Biz buni ko'p oddiy asboblarni o'rganamiz, ularni tashkilotlar tashkilotdan olib tashlanadi. Vazifani oddiy qilish orqali bir necha tajribalar orqali (rasm jarayonlarini oson qilish yoki butunlay bir tomonda qo'yish orqali bajarish orqali, namuna asosida qo'llangan imtiyozlar yaratish orqali, yaxshilash maydonlarini tahrirlash. Biz o'ylaymiz, modellarni ishni aniqlash uchun yoʻl yo'l bo'ladi, lekin uni qanday qiyin bo'ladi, va kelajak o'zgarishlar taʼminotni aniqlashda o'zgarishlar o'zgarishni o'zgartirish kerak.", 'nl': 'Hoewel bepaalde soorten instructies gecompliceerd kunnen worden uitgedrukt via beelden, zijn er situaties waarin men ze zou willen verbaliseren, bijvoorbeeld bij het sturen van iemand. We onderzoeken de taak van Instructie Genereren van Voor/Na Beeldparen, dat is om uit beelden een instructie af te leiden voor het doorvoeren van de impliciete verandering. Hiervoor maken we gebruik van vooraf werk aan instructie volgen in een visuele omgeving. We nemen een bestaande dataset, de BLOCKS data verzameld door Bisk et al. (2016) en onderzoeken of deze geschikt is voor het trainen van een instructie generator. We ontdekken dat het zo is, en onderzoeken verschillende eenvoudige basislijnen, uitgaande van de gerelateerde taak van beeldbijschriften. Door middel van een reeks experimenten die de taak vereenvoudigen (door beeldverwerking gemakkelijker te maken of volledig opzij te stappen; en door template-gebaseerde gerichte instructies te creëren), onderzoeken we verbeterpunten. We merken dat ondertitelingsmodellen een manier krijgen om de taak op te lossen, maar er enige moeite mee hebben, en toekomstige verbeteringen moeten liggen in de manier waarop de verandering wordt gedetecteerd in de instructie.', 'da': 'Mens visse typer instruktioner kan udtrykkes sammen via billeder, er der situationer, hvor man måske ønsker at formulere dem verbalt, f.eks. når man instruerer nogen. Vi undersøger opgaven med instruktionsgenerering fra før/efter billedpar, som er at udlede fra billeder en instruktion til at gennemføre den implicitte ændring. Til dette gør vi brug af forudgående arbejde på instruktion følgende i et visuelt miljø. Vi tager et eksisterende datasæt, BLOCKS data indsamlet af Bisk et al. (2016) og undersøger, om det også er egnet til træning af en instruktionsgenerator. Vi finder ud af, at det er, og undersøger flere enkle basislinjer, der tager disse fra den relaterede opgave med billedtekster. Gennem en række eksperimenter, der forenkler opgaven (ved at gøre billedbehandling lettere eller helt uden for den; og ved at skabe skabelonbaserede målrettede instruktioner), undersøger vi områder, der kan forbedres. Vi finder ud af, at billedtekstmodeller får en vis vej til at løse opgaven, men har nogle problemer med den, og fremtidige forbedringer skal ligge i den måde ændringen opdages i instruktionen.', 'hr': 'Iako se određene vrste uputstva mogu izraziti putem slika, postoje situacije u kojima bi se možda htjela verbalizirati, na primjer kad nekoga upućuje. Istražujemo zadatak generacije instrukcije iz prethodnih/nakon pare slika koji će se izvući iz slika uputstvo za učinku implicirane promjene. Za to koristimo ranije rad na instrukciji nakon vizualnog okruženja. Uzimamo postojeću setu podataka, podatke o BLOCKS skupljenim od Bisk et al. (2016) i istražujemo je li i odgovarajuće za obuku generatora instrukcije. Pronašli smo da jeste i istražujemo nekoliko jednostavnih osnovnih linija, uzimajući ih iz povezanih zadataka snimanja slika. Kroz niz eksperimenata koji pojednostavljaju zadatak (olakšavajući obradu slika ili potpuno stajeći na strani; i stvarajući ciljne upute na osnovu šablona), istražujemo područje za poboljšanje. Nalazimo da se modeli kapicijalnih mjera nađu način na rješavanje zadatka, ali imaju problema s tim, a budući poboljšanja moraju biti na način otkrivanja promjene u uputi.', 'bg': 'Въпреки че някои видове инструкции могат да бъдат изразени чрез изображения, има ситуации, в които човек може да иска да ги изрази вербализирано, например когато насочва някого. Проучваме задачата на генериране на инструкции от двойки изображения преди/след, която е да извлече от изображенията инструкция за извършване на подразбиращата се промяна. За тази цел се възползваме от предишна работа по следване на инструкции във визуална среда. Вземаме съществуващ набор от данни, събрани от Биск и др. (2016) и проучваме дали е подходящ и за обучение на генератор на инструкции. Намираме, че е така, и разследваме няколко прости базови линии, като ги вземаме от свързаната задача за надписване на изображения. Чрез серия от експерименти, които опростяват задачата (като улесняват обработката на изображения или напълно я отстъпват; и като създават целеви инструкции, базирани на шаблони), изследваме области за подобрение. Намираме, че моделите за надпис имат някакъв път към решаването на задачата, но имат известни трудности с нея и бъдещите подобрения трябва да лежат в начина, по който промяната се открива в инструкцията.', 'de': 'Während bestimmte Arten von Anweisungen durch Bilder kompakt ausgedrückt werden können, gibt es Situationen, in denen man sie verbalisieren möchte, zum Beispiel bei der Regie. Wir untersuchen die Aufgabe der Instruktionsgenerierung aus Vorher/Nachher Bildpaaren, die darin besteht, aus Bildern eine Anweisung zur Durchführung der implizierten Veränderung abzuleiten. Hierfür nutzen wir Vorarbeiten zur Unterweisung in einer visuellen Umgebung. Wir nehmen einen vorhandenen Datensatz, die von Bisk et al. (2016) gesammelten BLOCKS-Daten, und untersuchen, ob dieser auch für das Training eines Instruktionsgenerators geeignet ist. Wir stellen fest, dass dies der Fall ist, und untersuchen mehrere einfache Grundlinien, die von der damit verbundenen Aufgabe der Bildunterschriftung ausgehen. Durch eine Reihe von Experimenten, die die Aufgabe vereinfachen (durch Erleichterung der Bildverarbeitung oder gänzliche Umgehung; und durch Erstellen von vorlagenbasierten zielgerichteten Anweisungen), untersuchen wir Verbesserungsmöglichkeiten. Wir stellen fest, dass Untertitelmodelle einen Weg zur Lösung der Aufgabe haben, aber einige Schwierigkeiten damit haben, und zukünftige Verbesserungen müssen in der Art und Weise liegen, wie die Änderung in der Anweisung erkannt wird.', 'fa': 'در حالی که برخی از نوع دستورات می\u200cتوانند از طریق تصاویر به راهنمایی com-pacely استفاده می\u200cشوند، موقعیت\u200cهایی وجود دارد که ممکن است یک نفر بخواهد آنها را ویژه\u200cسازی کند، برای مثال وقتی به کسی هدایت کند. ما کار تولید تولید یادآوری از قبل و بعد از جفت تصویر تحقیق می کنیم که از تصویر آموزشی برای انجام تغییر معلوم است. برای این، ما از کارهای قبلی در مورد آموزش در محیط دیده استفاده می کنیم. ما یک مجموعه داده\u200cهای موجود، داده\u200cهای BLOCKS که توسط بیسک و ال جمع شده است، می\u200cگیریم. (۲۰۱۶) و تحقیق کنیم که آیا برای آموزش یک ژنراتور آموزش مناسب است یا نه. ما فهمیدیم که این است، و چند خط بنیادی ساده را تحقیق کنیم، این را از کار مربوط به عنوان عنوان تصویر گرفتیم. Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement. ما پیدا می\u200cکنیم که مدل\u200cهای کاپیتان راهی به راه حل کار می\u200cگیرند، ولی با آن مشکلی دارند، و پیشرفتهای آینده باید در راهی که تغییر در دستورات شناسایی می\u200cشود بر روی آن باشد.', 'id': 'While certain types of instructions can be com-pactly expressed via images, there are situations where one might want to verbalise them, for example when directing someone.  Kami menyelidiki tugas Generasi Instruksi dari Pasangan Sebelum/Setelah Gambar yang berasal dari gambar instruksi untuk mempengaruhi perubahan yang dimaksud. For this, we make use of prior work on instruction following in a visual environment.  We take an existing dataset, the BLOCKS data collected by Bisk et al. (2016) and investigate whether it is suitable for training an instruction generator as well.  We find that it is, and investigate several simple baselines, taking these from the related task of image captioning.  Melalui sejumlah eksperimen yang menyederhanakan tugas (dengan membuat proses gambar lebih mudah atau sepenuhnya melangkah sisi; dan dengan menciptakan instruksi sasaran berdasarkan templat), kami menyelidiki daerah untuk peningkatan. We find that captioning models get some way towards solving the task, but have some difficulty with it, and future improvements must lie in the way the change is detected in the instruction.', 'ko': '어떤 유형의 지령은 이미지를 통해 간결하게 표현할 수 있지만, 어떤 경우, 사람들은 그것을 구두로 표현해야 할 수도 있다. 예를 들어 누군가를 지휘할 때.우리는 은밀한 변경을 실현하기 위해 앞뒤 이미지에서 생성 명령에 대한 임무, 즉 이미지에서 명령을 파생시키는 것을 연구했다.이를 위해 우리는 시각 환경에서 이전의 지도 업무를 이용한다.Bisk et al.(2016)에서 수집한 기존 블록 데이터를 활용하여 교육 명령 생성기에도 적합한지 검토했습니다.우리는 확실히 이와 같다는 것을 발견했고, 이러한 기선은 이미지 자막과 관련된 임무에서 나온 몇 가지 간단한 기선을 연구했다.일련의 간소화 작업 실험을 통해 (이미지 처리를 더욱 쉽거나 완전히 빙빙 돌리게 하고, 템플릿 기반 목표 명령을 창설함으로써) 우리는 개선해야 할 분야를 연구했다.우리는 자막 모형이 임무를 해결하는 데 어느 정도 방법이 있다는 것을 발견했지만 약간의 어려움이 있다. 미래의 개선은 반드시 검측 지령의 변화 방식에 있어야 한다.', 'sw': 'Wakati baadhi ya aina fulani ya maelekezo yanaweza kuchapishwa kwa kasi kupitia picha, kuna hali ambapo mtu anaweza kutaka kuwasilisha, kwa mfano wakati akimwongoza mtu. Tunafahamu jukumu la uzalishaji wa Uongozi kutoka kabla/Baada ya Waziri wa Picha ambalo linatokana na picha maelekezo ya kutekeleza mabadiliko yanayohitajika. Kwa hili, tunatumia kazi za kabla kuhusu maelekezo yanayofuata katika mazingira ya kuona. Tunachukua seti ya taarifa zilizopo, data za BLOCKS zilizokusanywa na Bisk et al. (2016) na kuchunguza kama inafaa kwa mafunzo ya mtengenezaji wa maelekezo pia. Tunapata kwamba ni, na kuchunguza misingi kadhaa rahisi, na kuchukua hizi kutoka kwenye kazi inayohusiana na kuchukua picha. Kwa kupitia mfululizo wa majaribio yanayosahau kazi hiyo (kwa kutengeneza picha rahisi au kuingia upande kamili; na kwa kutengeneza maelekezo yanayolengwa na namba), tunachunguza maeneo ya kuboresha. Tunapata kwamba kuchukua mifano yanaweza kupata njia ya kutatua kazi hiyo, lakini kuna vigumu zaidi na hivyo, na maboresho ya baadaye ni lazima iwe katika namna mabadiliko yanavyogunduliwa katika maelekezo hayo.', 'tr': 'Çykyş görkezilişi görkezilýän belli hiller görkezilişi görkezilip biler, meselâ birini yönlendirip görkezilýän ýagdaýlar bardyr. Resim Içiliklerinden öň/soň Instruksiýa Döwletleriniň görevini çykarýarys. Bu suratlardan üýtgeşmeleri etmäge bir görkezme däldir. Şonuň üçin öňki işi görsel çevrede görnüş gurlama üçin ulanýarys. Biz bar bir veri setini, Bisk et al tarapyndan toplanýan BLOCKS maglumatlaryny al ýarys we bu sowgat generatöri üçin mümkin dälmidigini barlaň. Biz bu şekilde görüp, birnäçe basit hatlary barlaýarys we bunlary surat käpşeniň görnüşinden alaýarys. Görevi ýeňil etmek üçin birnäçe eserleşdirilen deneyler bilen (surat işlemek üçin a ňsatlyk ýa-da tamamlamak üçin ýüze çekerek; we nusgasyna tabanly maksady görkezmeler bilen), gelişmeler üçin sahypalary barlaýarys. Biz kellän nusgalary işi çözmek üçin bir ýagdaý tapýarys, ýöne onuň bilen kynçylyk bar we gelejekde üýtgewler gurulmanyň ýolynda göz öňünde bolmaly.', 'af': "Terwyl sekere tipes instruksies kan com- pactly uitgevoer word deur beelde, is daar situasies waar een dalk wil hê na verbaliseer hulle, byvoorbeeld wanneer iemand vertel. Ons ondersoek die taak van Instruksie Generasie van voor/na Beeld Pairs wat is om van beelde 'n instruksie af te maak vir effekteer van die impliseerde verander. Vir hierdie gebruik ons vooraf werk op instruksie volgens in 'n visuele omgewing. Ons neem 'n bestaande datastel, die BLOCKS data versamel deur Bisk et al. (2016) en ondersoek of dit geskik is vir onderwerp van 'n instruksiegenereerder ook. Ons vind dat dit is, en ondersoek verskeie eenvoudige basisline, neem dit van die verwante taak van beeldtitel. Deur 'n reeks eksperimente wat die taak eenvoudig maak (deur beeld verwerking makliker of heeltemal side-stepping dit te maak; en deur die skep van sjabloon-gebaseerde doelgemaakte instruksies), ons ondersoek areas vir verbetering. Ons vind dat die opskriftemodules 'n paar manier kry om die taak te los, maar het sommige moeilikheid daarmee, en toekomstige verbeteringe moet lê op die manier waarop die verandering in die instruksie gevind word.", 'am': 'ምንም እንኳን የዓይነት ትምህርት በተገኘ ምስሎች በተለየ ቁጥጥር ሲገልጹ፣ ምሳሌ ማንኛውን በመግለጽ የሚችል ጉዳይ አለ፡፡ የምስል ዕቅድን ከቀድሞ/በኋላ የምስል ዕቅድን እናምርመራለን፡፡ For this, we make use of prior work on instruction following in a visual environment.  We take an existing dataset, the BLOCKS data collected by Bisk et al. (2016) and investigate whether it is suitable for training an instruction generator as well.  እንደሆነ እናገኘዋለን፣ እና ብዙ ቀላል መሠረቶች እና እነዚህን ከተገኘው የምስል ስራ ለመቀበል እናፈልጋለን፡፡ ስራውን በሚገልጹት በብዙ ፈተናዎች (ምስሉን ማቀናጃ ቀላል ወይም ሙሉ በኩል ማቀናቀል እና በጉዳዩ ላይ የተመሳሰለውን ትምህርት በመፍጠር፣ የምንሻለበትን ቦታዎች እናምር፡፡ ምሳሌዎችን በመፍታት ስራውን ለመፈጸም የሚችል መንገድ እንዲያገኝ እናገኛለን ነገር ግን ጭንቀት አግኝቷል፣ ፍጻሜውም ለውጥ በተገኘው ግንኙነት እንዲደርስ ያስፈልጋል፡፡', 'hy': 'Մինչդեռ որոշ տեսակի հրահանգներ կարելի է համահամեմատաբար արտահայտել պատկերների միջոցով, կան իրավիճակներ, երբ մեկը կարող է ցանկանալ արտահայտել դրանք, օրինակ ինչ-որ մեկի ուղղությամբ: Մենք ուսումնասիրում ենք նախ և հետո պատկերների զույգերից ստեղծված պատմությունների ստեղծման խնդիրը, որը պատկերներից հանգեցնում է ենթադրված փոփոխության ազդեցության պատմություն: Այս դեպքում մենք օգտագործում ենք նախորդ աշխատանքը վիզուալ միջավայրում հետևող ուսուցման վրա: Մենք վերցնում ենք գոյություն ունեցող տվյալների համակարգ, Բլոքսների տվյալները, որոնք հավաքվել են Բիսկ և այլների կողմից (2016) և ուսումնասիրում ենք, արդյոք այն համապատասխան է նաև ուսուցման գեներատորի ուսուցման համար: Մենք հայտնաբերում ենք, որ դա այդպես է, և ուսումնասիրում ենք մի քանի պարզ հիմնական գծեր, վերցնելով դրանք պատկերի վերնագրման կապված խնդիրից: Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  Մենք հայտնաբերում ենք, որ վերնագրման մոդելները որոշ ձևեր են հասնում խնդիրը լուծելու համար, բայց դրանց հետ որոշ դժվարություններ են ունենում, և ապագա բարելավումները պետք է գտնվեն այն կերպ, ինչպես փոփոխությունը հայտնաբերվում է դասավանդման մեջ:', 'sq': 'While certain types of instructions can be com-pactly expressed via images, there are situations where one might want to verbalise them, for example when directing someone.  Ne hetojmë detyrën e Gjenerimit të Instruksioneve nga Parët para/pas imazheve që është të nxjerrim nga imazhet një udhëzim për të efektuar ndryshimin e implikuar. Për këtë, ne përdorim punën e mëparshme në mësimin që ndjek në një mjedis vizual. Ne marrim një set të dhënash ekzistuese, të dhënat BLOCKS të mbledhura nga Bisk et al. (2016) dhe hetojmë nëse është e përshtatshme për trajnimin e një gjeneratori instruksionesh gjithashtu. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning.  Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  Ne zbulojmë se modelet e titullimit marrin një mënyrë drejt zgjidhjes së detyrës, por kanë disa vështirësi me të, dhe përmirësimet e ardhshme duhet të qëndrojnë në mënyrën se si ndryshimi është zbuluar në udhëzim.', 'az': 'Bazı təsirlər şəkillər vasitəsilə com-pacely ifadə edilə bilərsə, bəzisini yönəltdikdə, bəzisini verbalizə etmək istəyən şəkillər var. Biz əvvəl/sonra Rəsm Üstünlüyünün vəzifəsini təşkil edirik ki, şəkillərdən təşkil edilmiş dəyişiklikləri etmişdir. Buna görə, biz əvvəlki işi görsel ortamda göstərilmək üçün istifadə edirik. Biz Bisk et al. tarafından toplanmış BLOCKS verilənləri al ırıq və təhsil generatoru təhsil etmək üçün uyğun mümkün mümkün müəyyən müddətini incidirik. Biz bunu görürük, və birkaç basit sətir araşdırırıq, bunları görüntü başlıqlarının əlaqəsindən alırıq. Gözməni asanlaşdıran bir sürü təcrübə vasitəsilə (görüntü işləməsini daha asanlaşdırmaq və ya tamamilə tərəfdən uzaqlaşdırmaq üçün) və şəkillə tabanlı təcrübələr yaratmaq üçün, daha yaxşılıq məlumatlarını incidirik. Biz qeyri-qüsusi modellərin işləri çəkməyə bir yol tapırıq, amma buna bəzi çətinliklərə sahib olmalıyıq, və gələcək tədbirlərin dəyişikliklərin öyrənməsi kimi olmalı.', 'bs': 'Iako se određene vrste instrukcija mogu izraziti putem slika, postoje situacije u kojima se možda želi verbalizirati, na primjer kad nekoga upućuje. Istražujemo zadatak generacije instrukcije iz prethodnih/nakon pare slika koji je da se izvuče iz slika uputstvo za učinku implicirane promjene. Za to koristimo prethodni rad na instrukciji slijedećim u vizualnom okruženju. Uzimamo postojeću setu podataka, podatke o BLOCKS-u koje je sakupljao Bisk et al. (2016) i istražujemo je li i odgovarajuće za obuku generatora instrukcije. Nalazimo da jeste i istražujemo nekoliko jednostavnih osnovnih linija, uzimajući ih iz povezanih zadataka snimanja slika. Kroz niz eksperimenata koji pojednostavljaju zadatak (olakšajući obradu slika ili potpuno stajanje na strani; i stvarajući ciljne upute na osnovu šablona), istražujemo područje za poboljšanje. Pronašli smo da modeli kapicijalnog stanja dobijaju način na rješavanje zadatka, ali imaju problema s tim, i budući poboljšanja moraju biti na način otkrivanja promjene u uputi.', 'bn': 'যদিও কিছু ধরনের নির্দেশনাগুলো ছবির মাধ্যমে স্থায়ীভাবে প্রকাশ করা যায়, তবে কিছু পরিস্থিতি আছে যেখানে কেউ কাউকে নির্দেশ দেয় চিত্রের পূর্ব/পরে নির্দেশ প্রজন্মের কাজ আমরা তদন্ত করি যা ছবির কাছ থেকে একটি নির্দেশ প্রদান করা হয়েছে যাতে প্রার্থিত পরিবর্তন এর জন্য আমরা দৃশ্য পরিবেশে নির্দেশ নিয়ে আগের কাজ ব্যবহার করি। আমরা একটি বিদ্যমান ডাটাসেট নিয়ে যাচ্ছি, বিস্ক এন্ট আল. (২০১৬) দ্বারা সংগ্রহ করা বিলকসের তথ্য নিয়ে যাচ্ছি এবং তদন্ত করা যাচ্ছে যে এটি ক আমরা খুঁজে পাচ্ছি যে এটা হচ্ছে, আর বেশ কয়েকটি সাধারণ বেসেলাইন অনুসন্ধান করি, যেগুলো ছবির কাজ থেকে নিয়ে যাচ্ছে। Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  আমরা খুঁজে পাচ্ছি যে এই কাজ সমাধানের জন্য মডেল ধরার কোন উপায় পাওয়া যায়, কিন্তু তার কাছে কিছু কষ্ট আছে, আর ভবিষ্যতের উন্নতি নির্দেশের কা', 'cs': 'Zatímco určité typy instrukcí mohou být kompaktně vyjádřeny prostřednictvím obrázků, existují situace, kdy je člověk může chtít slovně vyjádřit, například při řízení někoho. Zkoumáme úkol generování instrukcí z párů před/po obrazu, kterým je odvodit z obrazů instrukce pro provedení implikované změny. K tomu využíváme předchozí práce na následování instrukcí ve vizuálním prostředí. Vezmeme existující datovou sadu, data BLOCKS shromážděná společností Bisk et al. (2016) a zkoumáme, zda je vhodná i pro trénink generátoru instrukcí. Zjišťujeme, že je, a zkoumáme několik jednoduchých základních linek, které vycházejí z souvisejícího úkolu popisků obrázků. Prostřednictvím série experimentů, které tento úkol zjednodušují (usnadněním zpracování obrazu nebo zcela překročením jeho zpracování; a vytvořením cílených instrukcí založených na šablonách), zkoumáme oblasti pro zlepšení. Zjišťujeme, že titulkové modely dostanou nějakou cestu k řešení úkolu, ale mají s ním určité potíže a budoucí zlepšení musí spočívat ve způsobu detekce změny v instrukci.', 'fi': 'Vaikka tietyntyyppiset ohjeet voidaan ilmaista yhdessä kuvin, on tilanteita, joissa niitä halutaan sanallistaa esimerkiksi ohjata. Tutkimme ennen/jälkeen kuvapareista tapahtuvan ohjeen generoinnin tehtävää, joka on johtaa kuvista ohjeistus implisiittisen muutoksen aikaansaamiseksi. Tätä varten hyödynnämme aikaisempaa opetustyötä visuaalisessa ympäristössä. Otamme käyttöön olemassa olevan aineiston, Bisk et al. (2016) keräämän BLOCKS-aineiston, ja selvitämme, soveltuuko se myös opetusgeneraattorin koulutukseen. Havaitsemme, että se on, ja tutkimme useita yksinkertaisia lähtölinjoja, ottaen nämä aiheeseen liittyvästä kuvatekstityksen tehtävästä. Tehtävää yksinkertaistavien kokeilujen avulla (helpottamalla kuvankäsittelyä tai sivuuttamalla sen kokonaan ja luomalla mallipohjaisia kohdennettuja ohjeita) tutkimme parannuskohteita. Havaitsemme, että tekstitysmallit pääsevät jonkin verran ratkaisuun, mutta niillä on jonkin verran vaikeuksia sen kanssa, ja tulevaisuuden parannusten täytyy olla siinä, miten muutos havaitaan ohjeissa.', 'et': 'Kuigi teatud tüüpi juhiseid võib piltide kaudu kokkuvõtlikult väljendada, võib esineda olukordi, kus neid võib soovida sõnaliselt sõnaliselt väljendada, näiteks kellegi suunamisel. Uurime juhendi genereerimise ülesannet enne/pärast pildipaaridest, mis on tuletada piltidest juhend kaudse muudatuse teostamiseks. Selleks kasutame eelnevat tööd visuaalses keskkonnas järgimise juhendamisel. Võtame olemasoleva andmekogumi, Bisk et al. (2016) kogutud BLOCKS andmed ja uurime, kas see sobib ka õppegeneraatori koolitamiseks. Me leiame, et see on, ja uurime mitmeid lihtsaid lähtejooni, võttes need seotud ülesande pildi pealdiste. Ülesannet lihtsustavate eksperimentide abil (lihtsustades pilditöötlust või lõpetades selle täielikult kõrvale ning luues mallipõhiseid sihtjuhiseid) uurime täiustamist vajavaid valdkondi. Leiame, et pealdiste mudelid saavad ülesande lahendamiseks mingil moel, kuid neil on sellega mingeid raskusi ja tulevased parandused peavad seisnema selles, kuidas muudatus juhendis tuvastatakse.', 'ca': "Mentre que alguns tipus d'instruccions poden ser expressades de manera comoda a través d'imatges, hi ha situacions en les que potser volem verbalitzar-les, per exemple quan dirigeixes a algú. Investiguem la tasca de generació d'instruccions de parells d'imatges abans/després que és derivar d'imatges una instrucció per efectuar el canvi implicat. For this, we make use of prior work on instruction following in a visual environment.  Prenem un conjunt de dades existent, les dades BLOCKS recollides per Bisk et al. (2016) i investigam si és apropiada per formar també un generador d'instruccions. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning.  A través d'una sèrie d'experiments que simplifiquen la tasca (fent el processament d'imatges més fàcil o completament al costat; i creant instruccions mirades basades en models), investigam àrees per a millorar. We find that captioning models get some way towards solving the task, but have some difficulty with it, and future improvements must lie in the way the change is detected in the instruction.", 'he': 'למרות שסוגים מסוימים של הוראות יכולים להיות מבטחים באופן קומפקטי באמצעות תמונות, יש מצבים שבו אפשר לרצות להזמין אותן במילים, למשל כאשר להוביל מישהו. אנו חוקרים את המשימה של יצירת ההוראות מ"זוגות תמונות לפני/אחרי" אשר היא להוציא מהתמונות הוראה להשפיע על השינוי המרמז. For this, we make use of prior work on instruction following in a visual environment.  אנחנו לוקחים קבוצת נתונים קיימת, נתונים בלוקס שנאספו על ידי ביסק ואל. (2016) ולחקור אם זה מתאים לאימון גנרטור הוראות גם כן. אנו מוצאים שזה, וחקירים כמה שורות בסיסיים פשוטות, לוקחים אותם מהמשימה הקשורה של ציור תמונות. Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement.  אנו מוצאים שדוגמנים לשימוש מקבלים דרך כלשהי לפתור את המשימה, אבל יש להם קצת קשה איתה, ושיפורים עתידים חייבים לשכב בדרך שהשינוי נגלה בהוראות.', 'ha': "Kuma a lokacin da wasu irin shiryarwa za'a iya bayyana komo-pace da aka yi bayani da zane, akwai halin da wani mutum ya so zai nuna su, misali idan an shiryar da wani. Tuna ƙidãya aikin Kizaɓen Shiryarwa daga Kabla/Bayan Zani'in da za'a iya motsa daga zane wata wa'azi wa mai amfani da musanyawa da aka ƙayyade. Daga wannan, Munã amfani da aikin gabani a kan umarnin da ke ƙara cikin muhimman gani. Tuna sami wani tsari da ke gaba, data na BLECKS wanda aka samu da Bisk et al. (2016) kuma ka gane kwamfyuta yana da amfani da shirin mai shiryarwa da shi. Muna gane cewa wannan, kuma ana sami bakin bayani masu sauƙi, kuma masu samun wannan daga aikin da ke samu-zane. Ga wasu jarrabo masu sauƙi ga aikin (da za'a yi aiki da zane masu sauƙi ko kuma ke cikakken hanyoyi; kuma da kuma a ƙiƙira shiryoyin ayuka da aka ƙayyade shi ga kalma), muna tambayar filinaiki masu kyautatawa. Tuna gane cewa masu kãma misalin za'a sami hanya zuwa ga solar aikin, kuma amma yana da masu bukãta da shi, kuma masu gaba, za'a sami musanyawa a gaba ɗaya kamar yadda za a gane musanyawa a cikin shirin.", 'sk': 'Čeprav je določene vrste navodil mogoče kompaktno izraziti s slikami, obstajajo situacije, v katerih bi jih morda želeli besedno izraziti, na primer pri usmerjanju nekoga. Raziskujemo nalogo Ustvarjanja navodil iz slikovnih parov pred/po, ki je izpeljati iz slik navodila za izvedbo implicitne spremembe. Za to uporabljamo predhodno delo na navodilih za sledenje v vizualnem okolju. Vzamemo obstoječi nabor podatkov, podatke BLOCKS, ki so jih zbrali Bisk et al. (2016), in preverimo, ali je primeren tudi za usposabljanje generatorja inštrukcij. Ugotovimo, da je, in raziskujemo več preprostih osnovnih črt, ki jih vzamemo iz povezane naloge napisovanja slik. Z vrsto poskusov, ki poenostavljajo nalogo (tako, da olajšajo obdelavo slik ali jo popolnoma premaknejo; in z ustvarjanjem usmerjenih navodil na podlagi predlog), raziskujemo področja za izboljšave. Ugotovili smo, da modeli napisovanja nekako prispevajo k reševanju naloge, vendar imajo nekaj težav z njo, prihodnje izboljšave pa morajo biti v načinu, kako se sprememba zazna v navodilih.', 'bo': 'གཟུགས་རིས་ལ་བསྟུན་ནས་སྐབས་འཆར་བརྗོད་ཀྱི་དབྱེ་རིགས་ཁ་ཤས་ཡོད་པ་དང་བསྟུན་ནས། We investigate the task of Instruction Generation from Before/After Image Pairs which is to derive from images an instruction for effecting the implied change. འོན་ཀྱང་། ང་ཚོས་མཐོང་བའི་རང་རུང་ལ་སྔོན་གྱི་ལས་འགུལ་གྱི་མཐོང་སྣང་དང་། ང་ཚོས་གནས་ཡོད་པའི་ཆ་འཕྲིན་གྲངས་སྒྲིག་ཆ་ཞིག་བྱེད་ཀྱི་ཡོད། Bisk et al(2016)རྣམས་མཉམ་དུ་བསྡད་པའི་BLOCKS་ཆ་འཕྲིན་ཡིག ང་ཚོས་བརྙན་པར་དབུགས་ཡུལ་གྱི་ལས་འགུལ་འདི་དག་ལས་སླ་གཏོང་བྱས་ཆོས་ཉིད་ཅིག་རེད། ལྡོག་རིམ་གྱི་སྒེར་གྱི་སྐོར་ལས་བརྟན་པར་སྔོན ང་ཚོས་རྗེས་མཁན་མིག་དཔེ་གཟུགས་རིས་དེ་ལས་ཀྱང་དཀའ་ངལ་ཅིག', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness Awakdhéwé menehi perbudhakan Instruction Generation nggo Ketokan Kasama Gambar Saiki iki, kita ngubah njaluk wong liyane ing nggawe aturan banter pek kapan-kapan anyar Awak dhéwé ngéwangi dataset sing isih, dadi CLOCKS sing beraksi karo bisk et al (2013) lan ujian sisakake kapan nggawe ngupakan seneng cukup maning. Awak dhéwé ngerti, lan ujian akeh akeh basa sampeyan, nggawe lan ngono nggawe barang iki sampeyan karo aturan gambar nggawe So that\'s really fun. Awak dhéwé ngerti, model sing nggawe kelas kuwi dianggap dadi, ora bisa dianggap kanggo kalaman sekang dianggap karo, lan dianggap iso dianggap banjur iki dianggap kanggo ngerti winih dhéwé.'}
{'en': 'Rapformer : Conditional Rap Lyrics Generation with Denoising Autoencoders', 'ar': 'Rapformer: إنشاء كلمات راب مشروط باستخدام أجهزة تشفير تلقائية لتقليل الضوضاء', 'es': 'Rapformer: generación condicional de letras de rap con autocodificadores de eliminación de ruido', 'pt': 'Rapformer: geração de letras de rap condicional com autoencoders de redução de ruído', 'fr': 'Rapformer\xa0: Génération de paroles de rap conditionnel avec autoencodeurs débruités', 'hi': 'Rapformer: सशर्त रैप गीत Denoising Autoencoders के साथ पीढ़ी', 'ja': 'Rapformer:デノイジングオートエンコーダーを使用した条件付きラップ歌詞の生成', 'zh': 'Rapformer:噪编码器自歌', 'ru': 'Рэпформатор: Conditional Rap Lyrics Generation with Denoising Autoencoders', 'ga': 'Rapformer: Conditional Rap Lyrics Generation with Denoising Autoioncoders', 'ka': 'Rapformer: კონდიციონალური პაპ სიტყვები განვითარება დენოიზის ავტოკოდერებით', 'hu': 'Rapformer: Feltételes Rap Lyrics Generation with Denoising Autoencoder', 'el': 'Δημιουργία στίχων υπό όρους με αυτόματους κωδικοποιητές αποκωδικοποίησης', 'kk': 'Rapformer: Шарты Rap сөздері Denoising автокодерлерімен жасау', 'it': 'Rapformer: Generazione condizionale di testi Rap con denoising Autoencoder', 'lt': 'Rapsuotojas: Sąlyginių rapsų tekstų generavimas su atmetančiais autokodatoriais', 'ml': 'മഴപ്പൂര്\u200dവ്വമല്ല: നിര്\u200dബന്ധമായ റാപ്പ് ലൈറ്റിക്സ് ജനിപ്പിക്കുക', 'ms': 'Penyerang: Penjanaan Lirik Rap Bersyarat dengan Pengekod Auto Menolak', 'mt': 'Raffatur: Ġenerazzjoni Kundizzjonali ta’ Liriki Rap b’Awtokodifikaturi li Jiċaħdu', 'mn': 'Rapformer: Шинэ тохиолдол үгүйсгэгч Дэноизинг автокоддогч', 'no': 'Rapformer: Generering av vilkårlege rapporteringar med autokodar', 'pl': 'Rapformer: warunkowe generowanie tekstów rapowych z autokoderów denoisingowych', 'ro': 'Rapformer: Generația de versuri Rap condiționată cu autoencodere denunțate', 'sr': 'Rapformer: Generacija uvjetnih rap tekstova sa Denoising Autoencoderima', 'si': 'Rapex: සාමාන්තික රැප් ලියික්ස් නිර්මාණය Denoising ස්වයංකේතකය සමග', 'mk': 'Раптерка: Генерација на условни реписки со одбивачки автокодери', 'so': 'Rap former: Conditional Rap Lyrics Generation with Denoising Autoencoders', 'ta': 'Rapformer: Conditional Rap Lyrics Generation with Denoising Autocode', 'sv': 'Rapformer: Villkorlig Rap Lyrics Generation med Denoising Autoencoders', 'ur': 'Rapformer: Conditional Rap Lyrics Generation with Denoising Autoencoders', 'uz': 'Koò£rib chiqish', 'vi': 'Phát ngôn: Hệ thống phát mã hóa Rap', 'bg': 'Рапформър: Условно генериране на рап текстове с денонизиращи автокодери', 'hr': 'Rapformer: Generacija uvjetnih tekstova rapa sa autokoderima Denoising', 'nl': 'Rapformer: Conditionele Rap Lyrics Genereren met Denoising Autoencoders', 'da': 'Rapformer: Betinget Rap Lyrics Generation med Denoising Autoencoders', 'de': 'Rapformer: Conditional Rap Lyrics Generation mit Denoising Autoencoders', 'id': 'Rapformer: Generasi Lirik Rap Kondisional dengan Autokoder Menolak', 'ko': '래퍼: 소음 제거 자동 인코더로 조건 랩 가사 만들기', 'fa': 'Rapformer: Generation of Conditional Rap Lyrics with Denoising Autoencoders', 'sw': 'Rapformer: Uzalishaji wa Lugha za Mapinduzi kwa Kujitenga', 'tr': 'Rap ködlemeler bilen şartlı rap sözleri', 'sq': 'Raptor: Gjenerimi i lirikës Rap me kusht me kundërshtimin e autokoduesve', 'af': 'Rapformer: Bedinge Rap Lyrisse Genereer met Denoising Autoencoders', 'am': 'Conditional Rap Lyrics Generation with Denoising Autocode', 'hy': 'Ռաֆերմերն. Հանգամական Ռափ գրքերի ստեղծումը մերժող ավտոկոդերների միջոցով', 'az': 'Rapformer: ŇěartlńĪ Rap s√∂zl…ôri Denoising Autoencoderl…ôri il…ô M…ôxluqat', 'bs': 'Rapformer: Generacija uvjetnih rap tekstova sa Denoising Autoencoderima', 'bn': 'র\u200d্যাপ্ফোর্ড: স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয়ভাবে এনকোডারের সাথে প্রজন্ম', 'ca': 'Raptor: La generació de lletres Rap Conditional amb autorcodificadors negadors', 'et': 'Rapformer: Tingimuslik Rap Lyrics Generation koos Denoising Autoencoders', 'cs': 'Rapformer: Generování podmíněných rapových textů s denoisačními autokodéry', 'fi': 'Rapformer: Conditional Rap Lyrics Generation with Denoising Autoencoders', 'ha': 'KCharselect unicode block name', 'sk': 'Rapformer: Pogojna Rap Lyrics Generacija z Denoizing Autoencoders', 'he': 'רמפרטור: יצירת מילים רפ תנאי עם קודנים אוטומטיים משכחים', 'jv': 'Layout', 'bo': 'Rapformer: Conditional Rap Lyrics Generation with Denoising Autoencoder'}
{'en': 'The ability to combine symbols to generate language is a defining characteristic of human intelligence, particularly in the context of artistic story-telling through lyrics. We develop a method for synthesizing a rap verse based on the content of any text (e.g., a news article), or for augmenting pre-existing rap lyrics. Our method, called Rapformer, is based on training a Transformer-based denoising autoencoder to reconstruct rap lyrics from content words extracted from the lyrics, trying to preserve the essential meaning, while matching the target style. Rapformer features a novel BERT-based paraphrasing scheme for rhyme enhancement which increases the average rhyme density of output lyrics by 10 %. Experimental results on three diverse input domains show that Rapformer is capable of generating technically fluent verses that offer a good trade-off between content preservation and style transfer. Furthermore, a Turing-test-like experiment reveals that Rapformer fools human lyrics experts 25 % of the time.', 'ar': 'تعد القدرة على دمج الرموز لتوليد اللغة سمة مميزة للذكاء البشري ، لا سيما في سياق رواية القصص الفنية من خلال كلمات الأغاني. نقوم بتطوير طريقة لتجميع آية الراب بناءً على محتوى أي نص (على سبيل المثال ، مقال إخباري) ، أو لزيادة كلمات أغاني الراب الموجودة مسبقًا. تعتمد طريقتنا ، التي تسمى Rapformer ، على تدريب برنامج إزالة الضوضاء التلقائي القائم على Transformer لإعادة بناء كلمات الراب من كلمات المحتوى المستخرجة من الكلمات ، في محاولة للحفاظ على المعنى الأساسي ، مع مطابقة النمط المستهدف. يتميز Rapformer بمخطط إعادة صياغة جديد قائم على BERT لتحسين القافية مما يزيد من متوسط كثافة القافية للكلمات الناتجة بنسبة 10٪. تظهر النتائج التجريبية على ثلاثة مجالات إدخال متنوعة أن Rapformer قادر على إنشاء آيات بطلاقة تقنيًا تقدم مفاضلة جيدة بين حفظ المحتوى ونقل النمط. علاوة على ذلك ، كشفت تجربة شبيهة باختبار Turing أن Rapformer يخدع خبراء كلمات الأغاني البشرية بنسبة 25٪ من الوقت.', 'fr': "La capacité de combiner des symboles pour générer un langage est une caractéristique déterminante de l'intelligence humaine, en particulier dans le contexte de la narration artistique par le biais de paroles. Nous développons une méthode pour synthétiser un couplet de rap basé sur le contenu de n'importe quel texte (par exemple, un article de presse), ou pour augmenter les paroles de rap préexistantes. Notre méthode, appelée Rapformer, est basée sur la formation d'un autoencodeur de débruitage basé sur Transformer pour reconstruire les paroles de rap à partir des mots de contenu extraits des paroles, en essayant de préserver le sens essentiel, tout en respectant le style cible. Rapformer propose un nouveau schéma de paraphrase basé sur Bert pour l'amélioration des rimes qui augmente la densité moyenne des rimes des paroles de sortie de 10\xa0%. Les résultats expérimentaux sur trois domaines d'entrée différents montrent que Rapformer est capable de générer des versets techniquement fluides qui offrent un bon compromis entre la préservation du contenu et le transfert de style. De plus, une expérience similaire à Turing-Test révèle que Rapformer trompe les experts en paroles humaines 25\xa0% du temps.", 'es': 'La capacidad de combinar símbolos para generar lenguaje es una característica definitoria de la inteligencia humana, particularmente en el contexto de la narración artística de historias a través de las letras. Desarrollamos un método para sintetizar un verso de rap basado en el contenido de cualquier texto (por ejemplo, un artículo de prensa), o para aumentar las letras de rap preexistentes. Nuestro método, llamado Rapformer, se basa en entrenar un autocodificador de eliminación de ruido basado en Transformer para reconstruir letras de rap a partir de palabras de contenido extraídas de las letras, tratando de preservar el significado esencial, al mismo tiempo que se ajusta al estilo objetivo. Rapformer presenta un novedoso esquema de paráfrasis basado en Bert para mejorar la rima que aumenta la densidad media de rimas de las letras de salida en un 10%. Los resultados experimentales en tres dominios de entrada diversos muestran que Rapformer es capaz de generar versos técnicamente fluidos que ofrecen un buen equilibrio entre la conservación del contenido y la transferencia de estilos. Además, un experimento similar a la prueba de Turing revela que Rapformer engaña a los expertos en letras humanas el 25% de las veces.', 'pt': 'A capacidade de combinar símbolos para gerar linguagem é uma característica definidora da inteligência humana, particularmente no contexto da narrativa artística por meio de letras. Desenvolvemos um método para sintetizar um verso de rap com base no conteúdo de qualquer texto (por exemplo, uma notícia) ou para aumentar letras de rap pré-existentes. Nosso método, chamado Rapformer, é baseado no treinamento de um autoencoder denoising baseado em Transformer para reconstruir letras de rap a partir de palavras de conteúdo extraídas das letras, tentando preservar o significado essencial, ao mesmo tempo em que combina com o estilo alvo. O Rapformer apresenta um novo esquema de paráfrase baseado em BERT para aprimoramento de rima que aumenta a densidade média de rima das letras de saída em 10%. Resultados experimentais em três domínios de entrada diversos mostram que o Rapformer é capaz de gerar versos tecnicamente fluentes que oferecem um bom equilíbrio entre preservação de conteúdo e transferência de estilo. Além disso, um experimento semelhante ao teste de Turing revela que o Rapformer engana especialistas em letras humanas 25% das vezes.', 'ja': '記号を組み合わせて言語を生成する能力は、特に歌詞を通じた芸術的なストーリーテリングの文脈において、人間の知性の決定的な特徴です。 私たちは、任意のテキスト（例えば、ニュース記事）の内容に基づいてラップ節を合成するための方法、または既存のラップ歌詞を拡張するための方法を開発します。 Rapformerと呼ばれる当社の方法は、トランスフォーマーベースのデノイジングオートエンコーダーをトレーニングして、歌詞から抽出されたコンテンツワードからラップの歌詞を再構築し、ターゲットスタイルに合わせて本質的な意味を維持しようとすることに基づいています。 Rapformerは、韻律強化のための斬新なBERTベースのパラフレーズスキームを特徴とし、出力歌詞の平均韻律密度を10%増加させます。 3つの多様な入力ドメインの実験結果は、Rapformerがコンテンツの保存とスタイルの転送の間に良いトレードオフを提供する技術的に流暢な節を生成することができることを示しています。 さらに、チューリングテストのような実験では、Rapformerが25%の時間で人間の歌詞の専門家を騙していることが明らかになっています。', 'zh': '合符号者,人智之决定性也,特因歌词述艺之背景。 开一法,用一切文本(如新闻文)合说唱诗句,或用增强预存之说歌词。 吾法谓之Rapformer,盖练基于Transformer者,噪自编码器,取诸歌词单词中重建说唱歌词,图存其本义,兼配风格。 Rapformer有新BERT之释义,施于韵,可将歌词之均押韵密度崇10%。 三输域上之实验结果表明,Rapformer能成技流诗,存风移之权衡。 又图灵试之实验,Rapformer于25%时愚弄人词家。', 'hi': 'भाषा उत्पन्न करने के लिए प्रतीकों को संयोजित करने की क्षमता मानव बुद्धि की एक परिभाषित विशेषता है, विशेष रूप से गीतों के माध्यम से कलात्मक कहानी कहने के संदर्भ में। हम किसी भी पाठ की सामग्री (जैसे, एक समाचार लेख) के आधार पर एक रैप कविता को संश्लेषित करने के लिए एक विधि विकसित करते हैं, या पहले से मौजूद रैप गीतों को बढ़ाने के लिए। हमारी विधि, Rapformer कहा जाता है, एक ट्रांसफॉर्मर आधारित denoising autoencoder प्रशिक्षण पर आधारित है सामग्री गीत से निकाले गए शब्दों से रैप गीत पुनर्निर्माण करने के लिए, लक्ष्य शैली मिलान करते हुए आवश्यक अर्थ को संरक्षित करने की कोशिश कर रहा है। Rapformer कविता वृद्धि के लिए एक उपन्यास BERT-आधारित paraphrasing योजना है जो आउटपुट गीत के औसत कविता घनत्व को 10% तक बढ़ाता है सुविधाएँ. तीन विविध इनपुट डोमेन पर प्रयोगात्मक परिणाम बताते हैं कि Rapformer तकनीकी रूप से धाराप्रवाह छंद उत्पन्न करने में सक्षम है जो सामग्री संरक्षण और शैली हस्तांतरण के बीच एक अच्छा व्यापार-बंद प्रदान करता है। इसके अलावा, एक ट्यूरिंग-टेस्ट-जैसे प्रयोग से पता चलता है कि रैपफॉर्मर मानव गीत विशेषज्ञों को 25% समय मूर्ख बनाता है।', 'ru': 'Способность комбинировать символы для генерации языка является определяющей характеристикой человеческого интеллекта, особенно в контексте художественного повествования через лирику. Мы разрабатываем способ синтеза стихотворения рэпа, основанный на содержании любого текста (например, новостной статьи), или для дополнения ранее существовавших текстов рэпа. Наш метод, называемый Rapformer, основан на обучении шумопоглощающего автокодировщика на базе Transformer для реконструкции текстов рэпа из контентных слов, извлеченных из текстов, пытаясь сохранить существенное значение, в то же время согласовывая целевой стиль. Rapformer отличается новой схемой перефразирования на основе BERT для усиления рифмы, которая увеличивает среднюю плотность рифмы выходных текстов на 10%. Экспериментальные результаты по трем различным входным доменам показывают, что Rapformer способен генерировать технически свободные стихи, которые предлагают хороший компромисс между сохранением контента и передачей стиля. Кроме того, подобный эксперимент Тьюринга показывает, что Rapformer в 25% случаев обманывает экспертов по человеческой лирике.', 'ga': 'Is saintréith d’intleacht an duine é an cumas siombailí a chomhcheangal le teanga a ghiniúint, go háirithe i gcomhthéacs na scéalaíochta ealaíonta trí liricí. Forbraímid modh chun véarsa rap a shintéisiú bunaithe ar ábhar téacs ar bith (m.sh., alt nuachta), nó chun cur le liricí rap atá ann cheana féin. Tá ár modh, ar a dtugtar Rapformer, bunaithe ar oiliúint a chur ar uathchódóir denoising Trasfhoirmeoir-bhunaithe a athchruthú liricí rap ó fhocail ábhar a bhaintear as na liricí, ag iarraidh an bhrí riachtanach a chaomhnú, agus an stíl sprice á mheaitseáil. Tá scéim athinsinte úrscríofa bunaithe ar BERT le haghaidh feabhsú ríme i gceist le Rapformer, rud a ardaíonn 10% ar an meán-dlús ríme sna liricí aschuir. Léiríonn torthaí turgnamhacha ar thrí réimse ionchuir éagsúla go bhfuil Rapformer in ann véarsaí atá líofa go teicniúil a ghiniúint a thairgeann comhbhabhtáil mhaith idir caomhnú ábhair agus aistriú stíle. Ina theannta sin, taispeánann turgnamh atá cosúil le Turing go ndéanann Rapformer amadán ar shaineolaithe liricí daonna 25% den am.', 'hu': 'Az emberi intelligencia egyik meghatározó jellemzője, hogy a szimbólumokat a nyelv létrehozása érdekében kombináljuk, különösen a művészi történetmesélés összefüggésében szövegeken keresztül. Kifejlesztünk egy módszert egy rap vers szintetizálására bármely szöveg tartalma alapján (pl. hírek), vagy a már meglévő rap dalszövegek kiegészítésére. A Rapformer nevű módszerünk egy Transformer alapú autoencoder képzésén alapul, hogy rekonstruálja a rap szövegeket a szövegből kivont tartalmi szavakból, megpróbálja megőrizni az alapvető jelentést, miközben megfelel a célstílusnak. A Rapformer egy új BERT alapú parafrázási sémát tartalmaz a rímek javítására, amely 10%-kal növeli a kimeneti szövegek átlagos rímsűrűségét. Három különböző bemeneti tartományon végzett kísérleti eredmények azt mutatják, hogy a Rapformer képes technikailag folyékony verseket generálni, amelyek jó kompromisszumot kínálnak a tartalom megőrzése és a stílusátadás között. Továbbá egy Turing-teszt-szerű kísérlet kiderül, hogy a Rapformer az esetek 25%-ában átveri az emberi szövegszakértőket.', 'el': 'Η ικανότητα συνδυασμού συμβόλων για την παραγωγή γλώσσας αποτελεί καθοριστικό χαρακτηριστικό της ανθρώπινης νοημοσύνης, ιδιαίτερα στο πλαίσιο της καλλιτεχνικής αφήγησης ιστοριών μέσω στίχων. Αναπτύσσουμε μια μέθοδο σύνθεσης ενός ραπ στίχους με βάση το περιεχόμενο οποιουδήποτε κειμένου (π.χ. ενός άρθρου ειδήσεων), ή για την αύξηση των προϋπάρχοντων ραπ στίχων. Η μέθοδος μας, που ονομάζεται Rapformer, βασίζεται στην εκπαίδευση ενός αυτόματου κωδικοποιητή αποκωδικοποίησης με βάση τον μετασχηματιστή για την ανακατασκευή των στίχων ραπ από λέξεις περιεχομένου που εξάγονται από τους στίχους, προσπαθώντας να διατηρήσουμε το ουσιαστικό νόημα, ενώ ταιριάζουν με το στυλ στόχου. Το Rapformer διαθέτει ένα νέο σύστημα παράφρασης βασισμένο στο BERT για την ενίσχυση των ρίμων που αυξάνει τη μέση πυκνότητα των στίχων παραγωγής κατά 10%. Τα πειραματικά αποτελέσματα σε τρεις διαφορετικούς τομείς εισαγωγής δείχνουν ότι το Rapformer είναι ικανό να παράγει τεχνικά εύπλαστους στίχους που προσφέρουν μια καλή ανταλλαγή μεταξύ διατήρησης περιεχομένου και μεταφοράς στυλ. Επιπλέον, ένα πείραμα που μοιάζει με τεστ Τούρινγκ αποκαλύπτει ότι ο Rapformer ξεγελά τους ειδικούς στίχους των ανθρώπων 25% του χρόνου.', 'ka': 'სიმბოლოების შესაძლებლობა სიმბოლოების განვითარება არის ადამიანის ინტელექციის განსაზღვრებული პერატიკური პერატიკური, სხვადასხვადასხვადასხვადასხვადასხვადასხვა სიტყვების ჩვენ განვითარებთ მეტი, რომელიც ყველა ტექსტის შესახებ (მაგალითად, ახალგაზომის статილის) ან წინ არსებობენ პაპ ლირიკების შესახებ. ჩვენი მეთოდი, რომელიც სახელი Rapformer, არის განაკეთებული ტრანფორმეტრის ბაზეულად განაკეთებული ავტოკოდერის განაკეთებაზე, რომელიც რეპ სიტყვებისგან გამოყენებული სიტყვებისგან გამოყენებული სიტყვებისგან, რომელიც Rapformer-ს პრომენტი ბერტის დაბათებული პარაფრაზების სქემი რიმების უფრო მეტირებისთვის, რომელიც 10%-ით უფრო მეტი რიმების საშუალება. ექსპერიმენტიური შედეგები სამი განსხვავებული მონაცემების დიომენზე გამოჩვენება, რომ Rapformer შეუძლებელია ტექნონიკურად ფუნქციური სერიზების შექმნა, რომლებიც საკუთარი შეცემულ ჲჟგვნ რჲგა, რსპთნდჲგ ვკჟოვპთმვნრ ჲრკპთგა, ფვ პაოტთპყგ დლსოაგა ფჲგვქკთ ლთპთკთ ვკჟოვპრთ 25% ჲრ გპვმვრჲ.', 'it': "La capacità di combinare simboli per generare linguaggio è una caratteristica distintiva dell'intelligenza umana, in particolare nel contesto del racconto artistico attraverso i testi. Sviluppiamo un metodo per sintetizzare un versetto rap basato sul contenuto di qualsiasi testo (ad esempio, un articolo di notizie), o per aumentare testi rap preesistenti. Il nostro metodo, chiamato Rapformer, si basa sulla formazione di un autoencoder basato su Transformer per ricostruire i testi rap da parole di contenuto estratte dai testi, cercando di preservare il significato essenziale, abbinando allo stile di destinazione. Rapformer presenta un nuovo schema di parafrasi basato su BERT per migliorare le rime che aumenta la densità media delle rime dei testi in uscita del 10%. Risultati sperimentali su tre diversi domini di input mostrano che Rapformer è in grado di generare versi tecnicamente fluenti che offrono un buon compromesso tra conservazione dei contenuti e trasferimento di stile. Inoltre, un esperimento simile a Turing rivela che Rapformer inganna il 25% delle volte gli esperti di testi umani.", 'kk': 'Тілді құру үшін символдарды біріктіру мүмкіндігі - адамдардың бақылау мүмкіндігін анықтайтын қасиеттері, әсіресе әртүрлі оқиғаларды сөздермен айтқанда. Біз кез келген мәтіннің мазмұнына негізделген рап нұсқасын синтезализациялау әдісін (мысалы, жаңалық мазмұнын) немесе алдындағы рап тізімдерін көтеру әдісін құрамыз. Біздің Rapformer деп аталатын әдіміміз, автокодерді қайта құру үшін реп сөздерінің мазмұнынан шығарылған сөздерден түрлендіруші негізгі мазмұнын сақтау үшін түрлендіруші негізінде негізделген. Rapformer - BERT- негіздеген парафраз сұлбасының орташа римдер жиілігін 10% дегенге көтереді. Үш әртүрлі кіріс доменінің тәжірибелі нәтижелері Rapformer мазмұнын сақтау мен стиль передастыру арасындағы жақсы тәжірибелік нәтижелерді құру мүмкіндігін көрсетеді. Қосымша, Туринг тесті тәжірибесі ретінде Раффильм адамдардың әріптерін 25% күнін ақылдырады.', 'lt': 'Galimybė derinti simbolius kurti kalbą yra apibrėžianti žmogaus žvalgybos savybė, ypač kalbant apie meninę istoriją. Mes parengiame metodą, kuriuo remiantis bet kurio teksto turiniu (pvz., naujienų straipsniu) sintetizuojame rap versiją arba papildome jau esamas rap tekstas. Mūsų metodas, vadinamas Rapformer, grindžiamas mokymu Transformer-based denoising autoencoder atkurti rap tekstus iš tekste ištrauktų turinio žodžių, stengiantis išsaugoti esminę reikšmę, kartu suderinant tikslinį stilą. Rapformuotojas turi naują BERT pagrįstą parafrazės sistemą, skirtą rimų stiprinimui, kuri padidina vidutinį išėjimo tekstų ritmo tankį 10 %. Eksperimentiniai trijų įvairaus įvedimo sričių rezultatai rodo, kad Rapformer gali sukurti techniniu požiūriu fluktuojančius veršus, kurie siūlo gerą kompromisą tarp turinio išsaugojimo ir stiliaus perdavimo. Be to, panašus į „Turing“ bandymą parodė, kad „Rapformer“ 25 proc. laiko kvaila žmonių tekstų ekspertus.', 'mk': 'Можноста да се комбинираат симболи за генерирање јазик е дефинирачка карактеристика на човечката интелигенција, особено во контекст на уметничката приказна преку текст. Развиваме метод за синтезирање на реп верс базиран на содржината на било кој текст (на пример, вести), или за зголемување на препостоечките реп тексти. Нашиот метод, наречен Раформер, се базира на обуката на трансформер-базиран деноизирачки автокодер за реконструкција на реп текстовите од зборовите на содржина извадени од текстовите, обидувајќи се да го зачува основното значење, при што се совпаѓа со стилот на метата. Рафармерот има нова шема на парафразирање базирана на БЕРТ за подобрување на римите, која ја зголемува просечната густина на римите на излезните реченици за 10 отсто. Експерименталните резултати на три различни домени на внесување покажуваат дека Раформер е способен да генерира технички течни верзи кои нудат добра размена помеѓу зачувување на содржината и трансфер на стил. Покрај тоа, експеримент сличен на тестот на Туринг открива дека Раформ ги лаже експертите за човечки зборови 25 отсто од времето.', 'ml': 'ഭാഷ സൃഷ്ടിക്കാനുള്ള ചിഹ്നങ്ങളെ കൂട്ടിച്ചേര്\u200dക്കാനുള്ള കഴിവ് മനുഷ്യബുദ്ധിയുടെ വിവരങ്ങളാണ്, പ്രത്യേകിച്ച് ശബ്ദങ്ങള ഏതെങ്കിലും പദാവലിയുടെ ഉള്ളടക്കം അടിസ്ഥാനമാക്കിയ ഒരു ബലാലാവസ്ഥയെ സങ്കീകരിക്കാനുള്ള രീതിയാണ് ഞങ്ങള്\u200d നിര്\u200dമ്മിക്കുന്നത്, അല്ലെങ്കി നമ്മുടെ രീതി റാപ്ഫോര്\u200dമാര്\u200dഫോര്\u200dക്ക് ഒരു നോവല്\u200d ബെര്\u200dടി അടിസ്ഥാനത്തുള്ള പാരാഫ്രസിങ്ങ് സ്ക്രീമിന് നല്\u200dകുന്നു. അത് പുറപ്പെടുത്തുന്ന ശബ്ദം പത മൂന്നു വ്യത്യസ്ത ഇന്\u200dപുട്ട് ഡോമെനുകളിലെ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു റാപ്ഫോര്\u200dക്ക് സാങ്കേതിക വിദ്യാഭ്യാസം  അതിനുശേഷം, ഒരു ട്രിങ്ങിംഗ് ടെസ്റ്റ് പോലുള്ള പരീക്ഷണം കാണിച്ചു കൊണ്ടിരിക്കുന്നു, മുമ്പ് വിഡ്ഢികളായ മനുഷ', 'mt': 'Il-kapaċità li jingħaqdu simboli biex jiġġeneraw il-lingwa hija karatteristika definittiva tal-intelliġenza umana, partikolarment fil-kuntest tal-istorja artistika permezz tal-lirika. Aħna niżviluppaw metodu g ħas-sintesi ta’ verżjoni rap ibbażat fuq il-kontenut ta’ kwalunkwe test (e ż., artikolu tal-a ħbarijiet), jew għaż-żieda tal-lirika rap eżistenti minn qabel. Il-metodu tagħna, imsejjaħ Rapformer, huwa bbażat fuq it-taħriġ ta’ awtokodifikatur denużiv ibbażat fuq it-Trasformer biex jirrikostruċi l-lirika rap minn kliem ta’ kontenut estratt mil-lirika, li jipprova jippreserva t-tifsira essenzjali, filwaqt li jaqbel mal-istil fil-mira. Ir-raptur għandu skema ġdida ta’ parafrażizzazzjoni bbażata fuq BERT għat-titjib tar-rima li żżid id-densità medja tar-rima tal-lirika tal-output b’10 %. Experimental results on three diverse input domains show that Rapformer is capable of generating technically fluent verses that offer a good trade-off between content preservation and style transfer.  Barra minn hekk, esperiment simili għat-test Turing jiżvela li Rapformer iqiegħed lill-esperti tal-lirika umana 25% tal-ħin.', 'no': 'Kan kombinere symboler for å laga språk er ein definering av menneskelige intelligens, spesielt i konteksten for artistiske historier gjennom tekstar. Vi utviklar ein metode for å syntisera ein rapversjon basert på innhaldet av alle tekstar (f.eks. ein nytt artikkel) eller for å auka før eksisterande rapstrekar. Metoden vårt, kalla Rapformer, er basert på opplæring av ein transformeringsbasert koder som styrer automatisk rapportering for å gjenoppretta rapporteringar frå innhaldsord som er ekstrahert frå teksten, prøver å beholda den viktige meningen medan det passar med målsstilen. Rapformer har eit romant BERT-basert parafrasing- skjema for forbetringa av rimer som aukar gjennomsnittlig rimettstyrken på utdatatekstar med 10%. Eksperimentale resultat på tre ulike inndatadomene viser at Rapformer er i stand til å laga teknisk fluent versjonar som tilbyr ein god utvikling mellom innhaldsverking og stiloverføring. I tillegg vil ein eksperiment som er tilgjengeleg Turing-test opne at Rapformer forfeil menneskelige lysrekstar eksperter 25% av tiden.', 'mn': 'Хүмүүсийн оюун ухааны тодорхойлолт, ялангуяа уран бүтээлийн түүхийн тухай ярьж өгүүлэх тухай нэгтгэх чадвар юм. Бид бүх текст (жишээ нь мэдээний өгүүлбэр), эсвэл өмнө нь өмнө байгаа рап үгийг нэмэгдүүлэх арга зохион байгуулах арга замыг бүтээж байна. Rapformer гэдэг арга нь өөрийн шинжлэх ухаан зохион байгуулагчийн сургалтын сургалтын төлөвлөгөөнд суурилсан. Рэп үгийг дуулгахаас гарч ирсэн үгийг дахин бүтээх, зорилготой хэлбэртэй холбоотой, үндсэн утгыг хадгалах гэж хичээдэг. Rapformer нь BERT-д суурилсан шинэ парафраз схемийг нэмэгдүүлдэг. Энэ нь дундаж үржүүлэх дундаж армийн жинтэй нь 10%-аар нэмэгдүүлдэг. Гурван төрлийн орлуулалт дээрх туршилтын үр дүнг Rapformer нь техникийн шингэн утаснуудыг бүтээж чадна гэдгийг харуулдаг. Дараа нь Туринг шиг туршилтын туршилт нь Рэпприйн дуу дуу мэргэжилтнүүдийг 25% хугацааны туршилтыг харуулдаг.', 'pl': 'Umiejętność łączenia symboli w celu generowania języka jest definiującą cechą ludzkiej inteligencji, szczególnie w kontekście artystycznego opowiadania historii poprzez teksty. Opracowujemy metodę syntetyzacji wersetów rapowych w oparciu o treść dowolnego tekstu (np. artykułu wiadomościowego) lub rozszerzania istniejących wcześniej tekstów rapowych. Nasza metoda, zwana Rapformerem, opiera się na treningu automatycznego kodera denoisującego opartego na Transformerze do rekonstruowania tekstów rapowych z treści wyekstrahowanych z tekstów tekstowych, starając się zachować istotne znaczenie, przy jednoczesnym dopasowaniu do stylu docelowego. Rapformer zawiera nowy oparty na BERT schemat parafrazowania do poprawy rymu, który zwiększa średnią gęstość rymu tekstów wyjściowych o 10%. Wyniki eksperymentalne na trzech różnych domenach wejściowych pokazują, że Rapformer jest w stanie generować płynne technicznie wersety, które oferują dobry kompromis między zachowaniem treści a transferem stylu. Co więcej, eksperyment podobny do testu Turinga ujawnia, że Rapformer oszukuje ludzkich ekspertów tekstów 25% czasu.', 'ro': 'Abilitatea de a combina simboluri pentru a genera limbaj este o caracteristică definitorie a inteligenței umane, în special în contextul povestirii artistice prin versuri. Dezvoltăm o metodă de sintetizare a unui vers rap bazat pe conținutul oricărui text (de exemplu, un articol de știri), sau de amplificare a versurilor rap preexistente. Metoda noastră, numită Rapformer, se bazează pe instruirea unui autoencoder bazat pe Transformer pentru a reconstrui versurile rap din conținutul cuvintelor extrase din versuri, încercând să păstreze sensul esențial, potrivit stilului țintă. Rapformer prezintă o nouă schemă de parafrazare bazată pe BERT pentru îmbunătățirea rimei, care crește densitatea medie a rimei versurilor de ieșire cu 10%. Rezultatele experimentale pe trei domenii diferite de intrare arată că Rapformer este capabil să genereze versete fluente tehnic care oferă un bun compromis între conservarea conținutului și transferul stilului. Mai mult decât atât, un experiment asemănător testului Turing dezvăluie că Rapformer păcălește experții în versuri umane 25% din timp.', 'ms': 'Kemampuan untuk menggabungkan simbol untuk menghasilkan bahasa adalah karakteristik yang menentukan kecerdasan manusia, terutama dalam konteks cerita-cerita seniman melalui lirik. Kami mengembangkan kaedah untuk sintesikan ayat rap berdasarkan kandungan mana-mana teks (cth., artikel berita), atau untuk menambah lirik rap yang terdapat. Kaedah kami, dipanggil Rapformer, berdasarkan latihan pengekod otomatik berdasarkan Transformer untuk membina semula lirik rap dari perkataan kandungan yang dikeluarkan dari lirik, cuba untuk menyimpan makna penting, sementara sepadan dengan gaya sasaran. Rapformer mengandungi skema parafrasa berasaskan BERT baru untuk peningkatan rima yang meningkatkan jumlah rima rata-rata lirik output dengan 10%. Experimental results on three diverse input domains show that Rapformer is capable of generating technically fluent verses that offer a good trade-off between content preservation and style transfer.  Selain itu, eksperimen seperti Turing mengungkapkan bahawa Rapformer bodoh pakar lirik manusia 25% masa.', 'so': 'awoodda la isku xiriiro calaamado la abuuro luqada waa mid aqoon leh waxgarashada biniaadamka, khusuusan marka lagu qorayo warqadda farshaxanka ee ku qoran luuqadaha. Waxaynu horumarinaa qaab u soo bandhigista rapaal verse ahaan ku saleysan waxyaabaha ay ku jirto qoraal kasta (tusaale ahaan qoraal warqad ah), ama si aan u kordhinno qoraal dheeraad ah oo horay u jira. Metalkeena la yidhaahdo Rapformer waxay ku saleysan tahay waxbarashada codsiga koronta ah si uu u cusboonaysiiyo qoraalka bakhtiga oo laga soo bixiyo qoraalka, wuxuuna isku dayaa in uu ilaaliyo micneheeda muhiimka ah, isagoo u eg qaababka goalka. Rapformer waxay leedahay qorshaha farshaxanka ku qoran BERT-based oo ku qoran qorshaha qoyska ee kordhinta xiliga qaynuunnada ku baxa 10 boqolkiiba. Imtixaanka waxaa ku qoran saddex meelood oo gudaha ah oo kala duduwan waxay muuqataa in Rapformer awood u yeelan karo calaamado dhaqdhaqaaqa teknikada ah oo bixinaya baahida wanaagsan oo u dhexeeya ilaalinta waxyaabaha ku jira iyo wareejinta tababarka. Imtixaanka imtixaanka Turing oo kale wuxuu muujiyaa in cilmiga nacasyada ee hore ee Rappow ay yaqaanaan 25% wakhtiga.', 'sr': 'Sposobnost kombinacije simbola za proizvodnju jezika je definisana karakteristika ljudske inteligencije, posebno u kontekstu umjetničkih pričanja kroz tekstove. Razvijamo metodu za sinteziranje stihova rap a na osnovu sadržaja bilo kojeg teksta (npr. novinskog članaka) ili za povećanje pre-postojećih tekstova rapa. Naša metoda, zvana Rapformer, zasnovana je na obuci transformator-baziranog autokodera kako bi rekonstruisala tekstove rapa iz sadržajnih reči izvedenih iz tekstova, pokušavajući čuvati temeljno značenje, dok odgovara ciljnom stilu. Rapformer prikazuje novu parafrazaciju na BERT-u za poboljšanje rima koja povećava prosječnu gustinu rima tekstova proizvodnje na 10%. Eksperimentalni rezultati na tri različita domena ulaska pokazuju da je Rapformer sposoban da stvara tehnički tekuće stihove koji nude dobru trgovinu između zaštite sadržaja i transfer a stila. Osim toga, eksperiment sličan na Turing test pokazuje da Rapformer budala ljudske tekstove eksperte 25% vremena.', 'si': 'භාෂාව නිර්මාණය කරන්න සංකේතය සම්බන්ධ කරන්න පුළුවන් තමයි මිනිස්සු බුද්ධිමත්වයේ විශේෂයෙන් විශේෂයෙන්  අපි රැප් වර්ෂයක් සංවිධානය කරන්න විධානයක් විස්තර කරනවා (උදාහරණය, වාර්තාවක් ලේඛනයක්), නැත්තම් මුලින් තියෙන්නේ රැප්  අපේ විධානය, Rapforme කියලා කියලා, ස්වයංක්\u200dරීයාවක් ස්වයංක්\u200dරීයාවක් ස්වයංක්\u200dරීයාවක් සංවිධානය කරන්න ස්වයංක්\u200dරීයාවක් නිර්මාණය කරන්න, ප Rapform අවස්ථාවක් BERT-අධාරිත පැරැෆ්\u200dරේසින් සැකසුම් සඳහා රිම් විශාලනය සඳහා සාමාන්\u200dය රිම් ගුරුත්වය 10% විතරයි. විවිධ ඇතුළුම් දේමින් තුනක් පරීක්ෂණ ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන් කියලා Rapform ප්\u200dරතිචාරිතයෙන් ප්\u200dරතිචාරිත්ත තවත්, ටුරින්ග් පරීක්ෂණයක් වගේ පරීක්ෂණයක් ප්\u200dරකාශ කරනවා කියලා රැප්ලින්ග් මෝඩයෙන් මිනිස්සු සංකේත ව', 'sv': 'Förmågan att kombinera symboler för att generera språk är en avgörande egenskap för mänsklig intelligens, särskilt i samband med konstnärlig berättelse genom texter. Vi utvecklar en metod för att syntetisera en rapvers baserad på innehållet i någon text (t.ex. en nyhetsartikel), eller för att utöka befintliga raptexter. Vår metod, kallad Rapformer, bygger på att träna en Transformer-baserad denoising autoencoder för att rekonstruera raptexter från innehållsord som extraheras från texterna, försöka bevara den väsentliga innebörden, samtidigt som den matchar målstilen. Rapformer har ett nytt BERT-baserat parafraseringsschema för rimförbättring som ökar den genomsnittliga rimtätheten i texterna med 10%. Experimentella resultat på tre olika inmatningsdomäner visar att Rapformer kan generera tekniskt flytande verser som erbjuder en bra avvägning mellan innehållsbevarande och stilöverföring. Dessutom avslöjar ett Turing-test-liknande experiment att Rapformer lurar mänskliga textexperter 25% av tiden.', 'ta': 'மொழியை உருவாக்குவதற்கு குறியீட்டை ஒன்று சேர்க்க இயலும் அது மனித புலங்களின் தன்மையை குறிப்பிடும், குறிப்பாக கலைஞர் கதை மூ @ info நம்முடைய முறை, ராப்போர் என்று அழைக்கப்பட்டது, ஒரு மாற்று அடிப்படையில் உள்ள தானியங்கி குறியீட்டை பயிற்சியை அடிப்படையில் உள்ளது, இலக்கு பாணியை பொருத்தும் ப வெளியீட்டு விளக்கங்களின் சராசரி வெளியீட்டு வெளியீட்டு வெளியீட்டு வரிகளின் அடர்த்தியை 10% அதிகப்படுத்தும் சராசரி விளையாட்டு வ மூன்று வேறு வித்தியாசமான உள்ளீட்டு தளங்களில் சோதனையின் முடிவுகள் காட்டுகிறது ராப்போர் தொழில்நுட்பமான தொழில்நுட்பத்தில்  மேலும், ஒரு திரும்பும் சோதனைப் போன்ற சோதனையின் வெளிப்படுத்துகிறது அந்த நேரத்தில் 25% முட்டாள்கள் மனித குரல்கள்', 'ur': 'زبان کے پیدا کرنے کے لئے نشانیاں ترکیب کرنے کی قابلیت انسان کی بصیرت کی تعریف کرتی ہے، مخصوصاً کلارت کی کہانیاں کے ذریعے۔ ہم ایک راپ verse کو سینسٹیز کرنے کے لئے ایک طریقہ پیدا کرتے ہیں جو ہر پیغام کے منصوبات پر بنیاد ہے یا اس سے پہلے موجود راپ لکھانے کے لئے۔ ہمارا طریقہ، Rapformer کا نام ہے، ایک ترنسفور بنیاد رکھنے والی آٹ انکوڈر کی تدبیر پر بنیاد ہے کہ آٹ انکوڈر کی تدبیر کرتا ہے کہ راپ لکھانے کے لئے منصوبہ لکھانے والی لکھانے والی لکھانوں سے دوبارہ ساختہ کرے، اس کی ضروری معنی کو حفاظت کرنے راپفریٹ ایک نوم BERT بنیادی پارافریٹ سیکیم کی شامل ہے کہ ریم افزایش کے لئے متوسط ریم کی گہری 10% سے زیادہ کرتا ہے۔ تین مختلف انٹرنیٹ ڈمین پر تجربہ کا نتیجہ دکھاتا ہے کہ راپفریٹ تکنیکی طریقے سے روشن آیتیں پیدا کرنے کے قابل ہے جو منزل حفاظت اور استیل ترافرس کے درمیان اچھی تجارت کے ساتھ پیش کرتی ہے. اور اس کے علاوہ، ایک تورینگ تست کی طرح کی آزمائش ظاہر کرتا ہے کہ راپفریٹ انسان کی آیتیں مصحبت کرتا ہے اس وقت کی 25% کی۔', 'uz': "Tilni yaratish uchun harflarni birlashtirish imkoniyati inson intellektlarning xususiyatlarini aniqlashdir. Hullas, rasmlar orqali rasmlar orqali rasmlarni aytish haqida. Biz bir qanday matn tarkibini (m.eks. yangilik maqola) asosida, tep tarkibini birlashtirish usulini yaratishmiz yoki oldingi mavjud rap tilini oshirish uchun. Bizning usuli Rapformer deb nomlangan, Transformer asosida avtomatik kodlash qoidasini o'rganish asosida o'rganish mumkin, so'zlardan tashqi so'zlardan qayta ishlab chiqarish mumkin, muhim ma'nosini saqlashni istaysiz, target uslubda bir qismini saqlashni istaysiz. Name Uch turli kiritish domenalarida tajriba natijalari ko'rsatadi, Rapformer qismini saqlash va uslub tarkibini saqlash orqali yaxshi fikrlarni yaratish mumkin. Ko'rsatganda, Turing sinovligiga o'xshash imtiyozni ko'rsatadi, o'sha vaqtdan 25% odamlar o'rganishni o'rganadi.", 'vi': 'Khả năng kết hợp các biểu tượng tạo ra ngôn ngữ là đặc trưng của trí tuệ con người, đặc biệt là trong trường hợp thuật kể chuyện nghệ thuật qua lời ca. Chúng tôi phát triển một phương pháp tổng hợp một đoạn nhạc rap dựa trên nội dung của bất cứ văn bản nào (v.d., một bài báo), hoặc để phát triển lời rap tồn tại trước. Cách thức của chúng tôi, được gọi là sớm Rapunzel, dựa trên việc huấn luyện một con robot biến hình có tính tự mã hóa biến hình để phục hồi lời rap từ lời trích ra từ lời bài hát, cố gắng bảo tồn ý nghĩa thiết yếu, đồng thời khớp với kiểu đích. Trong giai đoạn ngắn ngắn ngắn ngắn được viết bằng một bài diễn văn giả giả được cung cấp bởi trường hợp thiếu niên. Kết quả thí nghiệm trên ba khu vực nhập khác nhau cho thấy Hiếp có khả năng tạo ra thông điệp thông thạo về mặt kỹ thuật cung cấp một giao dịch tốt giữa bảo tồn nội dung và truyền phong cách. Hơn nữa, một thử nghiệm Turing-kiểm tra cũng cho thấy rằng tay nghề của những kẻ ngây ngô xuất hiện cao 25.', 'nl': 'Het vermogen om symbolen te combineren om taal te genereren is een bepalend kenmerk van menselijke intelligentie, met name in de context van artistieke verhalen vertellen door middel van teksten. We ontwikkelen een methode om een rapvers te synthetiseren op basis van de inhoud van een tekst (bijvoorbeeld een nieuwsbericht), of om bestaande rapteksten aan te vullen. Onze methode, genaamd Rapformer, is gebaseerd op het trainen van een Transformer-gebaseerde denoising autoencoder om rap teksten te reconstrueren van inhoudelijke woorden die uit de teksten zijn gehaald, proberen de essentiële betekenis te behouden, terwijl ze overeenkomen met de doelstijl. Rapformer beschikt over een nieuw BERT-gebaseerd parafraseringsschema voor rijmverbetering dat de gemiddelde rijmdichtheid van uitvoerteksten met 10%. Experimentele resultaten op drie verschillende invoerdomeinen tonen aan dat Rapformer in staat is om technisch vloeiende verzen te genereren die een goede afweging bieden tussen contentbehoud en stijltransfer. Bovendien blijkt uit een Turing-test-achtig experiment dat Rapformer menselijke tekstexperts 25% van de tijd voor de gek houdt.', 'bg': 'Способността да се комбинират символи за генериране на език е определяща характеристика на човешката интелигентност, особено в контекста на художественото разказване на истории чрез текстове. Разработваме метод за синтезиране на рап стих въз основа на съдържанието на всеки текст (например новинарска статия), или за увеличаване на съществуващите рап текстове. Методът ни, наречен Рапформър, се основава на обучението на базиран на трансформатор, за да възстанови рап текстовете от съдържанието на думи, извлечени от текстовете, опитвайки се да запази същественото значение, като същевременно съответства на целевия стил. Рапформър разполага с нова базирана парафразираща схема за подобряване на римите, която увеличава средната плътност на римите на изходящите текстове с 10%. Експерименталните резултати на три различни входни домейна показват, че е способен да генерира технически плавни стихове, които предлагат добър компромис между запазването на съдържанието и трансфера на стил. Освен това експеримент, подобен на Тюринг тест разкрива, че рапформър заблуждава експертите по човешки текстове 25% от времето.', 'da': 'Evnen til at kombinere symboler for at skabe sprog er et definerende kendetegn for menneskelig intelligens, især i forbindelse med kunstnerisk historiefortælling gennem tekster. Vi udvikler en metode til at syntetisere et rapvers baseret på indholdet af enhver tekst (f.eks. en nyhedsartikel), eller til at forøge allerede eksisterende rap tekster. Vores metode, kaldet Rapformer, er baseret på at træne en Transformer-baseret denoising autoencoder til at rekonstruere rap tekster fra indholdsord udvundet fra teksterne, forsøge at bevare den væsentlige betydning, samtidig med at de matcher målstilen. Rapformer indeholder en ny BERT-baseret parafraseringsordning til rimforbedring, som øger den gennemsnitlige rimtæthed af outputtekster med 10%. Eksperimentelle resultater på tre forskellige input domæner viser, at Rapformer er i stand til at generere teknisk flydende vers, der tilbyder en god afvejning mellem indholdsbeskyttelse og stiloverførsel. Desuden afslører et Turing-test-lignende eksperiment, at Rapformer narrer menneskelige tekster eksperter 25% af tiden.', 'hr': 'Sposobnost kombiniranja simbola za proizvodnju jezika je definirajuća karakteristika ljudske inteligencije, posebno u kontekstu umjetničkog pričanja priče kroz tekstove. Razvijamo metodu za sinteziranje stihova rap a na temelju sadržaja bilo kojeg teksta (npr. novinskog članaka) ili za povećanje prije postojećih tekstova rapa. Naša metoda, zvana Rapformer, temeljena je na obuci transformatorskog kodera koji naziva autokodera kako bi rekonstruisala tekstove rapa iz sadržaja riječi izvučene iz tekstova, pokušavajući čuvati temeljno značenje, dok odgovara ciljnom stilu. Rapformer prikazuje novu parafrazacijsku shēmu na temelju BERT-a za poboljšanje rima koja povećava prosječnu gustinu rima tekstova na 10%. Eksperimentalni rezultati na tri različita domena ulaska pokazuju da je Rapformer sposoban stvoriti tehnički tekuće stihove koji nude dobru trgovinu između očuvanja sadržaja i prenošenja stila. Osim toga, eksperiment sličan na Turing test pokazuje da Rapformer budala ljudske tekstove stručnjake 25% vremena.', 'id': 'Kemampuan untuk menggabungkan simbol untuk menghasilkan bahasa adalah karakteristik mendefinisikan intelijen manusia, terutama dalam konteks cerita-cerita seniman melalui lirik. Kami mengembangkan metode untuk sintesis ayat rap berdasarkan isi teks apapun (misalnya artikel berita), atau untuk meningkatkan lirik rap yang ada sebelumnya. Metode kami, disebut Rapformer, berdasarkan pelatihan sebuah transformer-berdasarkan denoising autoencoder untuk rekonstruksi lirik rap dari kata-kata konten yang diekstraksi dari lirik, mencoba untuk mempertahankan arti penting, sementara cocok dengan gaya sasaran. Rapformer memiliki skema parafrasasi berbasis BERT baru untuk peningkatan rima yang meningkatkan jumlah rima rata-rata lirik keluaran dengan 10%. Hasil eksperimen pada tiga domain masukan berbeda menunjukkan bahwa Rapformer mampu menghasilkan ayat-ayat yang secara teknis fluent yang menawarkan perdagangan baik antara pemeliharaan konten dan transfer gaya. Selain itu, eksperimen seperti Turing mengungkapkan bahwa Rapformer bodoh pakar lirik manusia 25% dari waktu.', 'de': 'Die Fähigkeit, Symbole zu kombinieren, um Sprache zu erzeugen, ist ein bestimmendes Merkmal der menschlichen Intelligenz, insbesondere im Kontext der künstlerischen Erzählung durch Texte. Wir entwickeln eine Methode, um einen Rap-Vers basierend auf dem Inhalt eines beliebigen Textes (z.B. eines Nachrichtenartikels) zu synthetisieren oder bestehende Rap-Texte zu ergänzen. Unsere Methode, genannt Rapformer, basiert auf dem Training eines Transformer-basierten Denoising Autoencoders, um Rap-Lyrics aus Inhaltswörtern zu rekonstruieren, die aus den Texten extrahiert wurden, wobei versucht wird, die wesentliche Bedeutung zu bewahren und gleichzeitig dem Zielstil anzupassen. Rapformer verfügt über ein neuartiges BERT-basiertes Paraphrasierungsschema zur Reimverbesserung, das die durchschnittliche Reimdichte von Ausgangstexten um 10%. Experimentelle Ergebnisse auf drei verschiedenen Eingabedomänen zeigen, dass Rapformer in der Lage ist, technisch fließende Verse zu erzeugen, die einen guten Kompromiss zwischen Inhaltserhaltung und Stiltransfer bieten. Darüber hinaus zeigt ein Turing-Test-ähnliches Experiment, dass Rapformer menschliche Textexperten 25% der Zeit verarscht.', 'ko': '기호를 결합시켜 언어를 생성하는 능력은 인류 지능의 결정적인 특징이다. 특히 가사를 통해 예술 이야기를 하는 배경에서 그렇다.우리는 어떤 텍스트(예를 들어 뉴스 기사)의 내용을 바탕으로 랩시를 합성하거나 기존의 랩 가사를 강화하는 방법을 개발했다.우리의 방법은 랩퍼라고 하는데 그 기초는 변압기를 기반으로 하는 소음 제거 자동 인코더를 훈련시켜 가사에서 추출한 내용어를 랩 가사로 재구성하고 기본적인 의미를 보존하며 목표 스타일과 일치하도록 하는 것이다.Rapformer는 버트의 해석을 바탕으로 하는 새로운 방안을 채택하여 압운을 강화하고 출력 가사의 평균 압운 밀도를 10% 높였다.세 개의 서로 다른 입력 영역에서의 실험 결과에 의하면 랩퍼는 기술이 유창한 시구를 생성하여 내용 보존과 스타일 전환 사이에 좋은 균형을 제공할 수 있다.또 툴링 테스트와 같은 실험에 따르면 래퍼의 어리석은 사람의 가사 전문가는 25%의 시간을 보냈다.', 'fa': 'قابلیت ترکیب نماد برای تولید زبان یک ویژگی تعریف کننده از هوش انسان است، مخصوصا در محیط داستان هنری که از طریق زبان می گوید. ما روش سازی یک آهنگ راپ را بر اساس محتوای هر متن (مثال یک مقاله اخبار) یا برای افزایش آهنگ راپ پیش از آن توسعه می\u200cکنیم. روش ما، به نام راپ\u200cفریز، بر روی آموزش یک تغییر\u200cدهنده بر اساس یک تغییر\u200cدهنده\u200cی متن\u200cدهنده\u200cای است که تغییر\u200cدهنده\u200cی آهنگ\u200cهای خود را برای بازسازی آهنگ\u200cهای راپ از کلمات محتویات خارج شده از آهنگ\u200cها است، سعی می\u200cکند معنی Rapformer یک برنامه\u200cی پارافریز بر بنیاد BERT برای افزایش ریم\u200cها را ویژه می\u200cدهد که افزایش میانگین میانگین میانگین ریم\u200cهای زبان\u200cهای خروجی به 10 درصد افزایش می\u200cدهد. نتیجه\u200cهای تجربه روی سه دامنه\u200cهای ورودی مختلف نشان می\u200cدهد که راپ\u200cفریج قادر به تولید آهنگ\u200cهای فناوری روان است که یک تجارت خوب بین حفاظت محتویات و انتقال طرح را پیشنهاد می\u200cدهد. علاوه بر این، یک آزمایش مانند تورینگ آزمایش نشان می دهد که راپ فورینگ 25% از زمان متخصص آهنگ انسان را احمق می کند.', 'sw': 'Uwezo wa kuunganisha alama za kuzalisha lugha ni utaalamu wa uelewa wa binadamu, hasa katika muktadha wa simulizi za sanaa kupitia lugha. Tunaendelea njia ya kukusanyika kwa ubakaji tofauti kwa kutumia maudhui yoyote ya maandishi (kwa mfano makala ya habari), au kwa kuongeza elimu za ubakaji zilizopo kabla. Utawala wetu, unaoitwa Rapformer, unajikita na mafunzo ya kufundisha kodi inayojiweka kwa ajili ya kujenga tena mashairi ya ubakaji kutoka kwenye maneno yaliyotokana na mashairi, kujaribu kulinda maana muhimu, wakati akilinganisha na mtindo wa malengo. Rapformer inaonyesha mpango wa mpiga kurasa anayeishi BERT kwa ajili ya kuongezeka kwa umaarufu wa wastani wa kiwango cha wastani wa mashairi ya uzalishaji kwa asilimia 10. Matokeo ya majaribio juu ya maeneo matatu tofauti yanaonyesha kuwa Rapformer ana uwezo wa kutengeneza ishara za mafanikio ya kiufundi zinazotoa biashara nzuri kati ya kuhifadhi maudhui na uhamishaji wa mtindo. Zaidi ya hayo, jaribio linalofanana na Turing linaonyesha kuwa wataalam wa lugha za kijinga wa Rapway wataalam 25% ya wakati huo.', 'tr': "Dili janlaşdyrmak üçin sembollary birleşdirmek üçin ukyplary ynsan zekatynyň has üýtgetmelidir, ýöne-ýöne sungat hekaýalary sözleriň aralygynda. Biz rap sanatyny guramak üçin bir yöntemi geliştirdik (meselâ, täzelikler makalasyny) ýa-da öň bar rap sanatynyň içine daýanýar. Rapformer diýilip atlanan yöntemimiz, rap sözlerini sözden çekilýän maksadyndan gaýd etmek üçin özüni terjime etmek üçin tabanly terjime etmäge tabanly. Rapformer, BERT'a tabanly parafraz taslamasynyň arasynda çykyş sözleriniň ýuwaşlygyny 10%-a artýar. Üç çeşitli girdi alanyndaky örän netijeler Rapformer-yň teknikiýa ýuwy barlag saýlamak we stil göçürmegi arasynda gowy türleşme teknikiýaly nusgalary döredip biljekdigini görkez. Gaýratyn-de, Turing testisi ýaly bir synag Rapformer adamlaryň sözlerini ukyplarynyň 25% ukypdygyny görkeýär.", 'af': "Die moontlik om simbole te kombinieer om taal te genereer is 'n definieerde karakteristiek van menslike inteligensie, veral in die konteks van kunstiese storie vertel deur lyrike. Ons ontwikkel 'n metode vir sintetiseer van 'n rap versel gebaseer op die inhoud van enige teks (bv. 'n nuus artikel), of vir voor-bestaande rap lyre te vergroot. Ons metode, wat Rapformer genoem word, is gebaseer op die onderwerp van 'n Transformer-gebaseerde onderwerp van autoencoder om rap lyre te herkonstrukteer van inhoud woorde uitgevoer van die lyrike, probeer om die nuwe betekening te bewaar, terwyl ooreenstemmende met die doel styl. Rapformer funksie 'n roman BERT-gebaseerde parafrasing skema vir rime verbetering wat die gemiddelde rime-densiteit van uitset lyre by 10% verhoog. Eksperimentale resultate op drie verskillende invoer domeine vertoon dat Rapformer is in staat om tekniks fluent verse te genereer wat 'n goeie handel-af tussen inhoud beveiliging en styl oordrag aanbied. Maar 'n Turing-toets-soos eksperiment openbaar dat Rapformer dwaas menslike lyrisse eksperimente 25% van die tyd.", 'sq': 'The ability to combine symbols to generate language is a defining characteristic of human intelligence, particularly in the context of artistic story-telling through lyrics.  Ne zhvillojmë një metodë për sintetizimin e një verseti rap bazuar në përmbajtjen e çdo teksti (për shembull, një artikull lajmesh), ose për shtimin e lirikës rap-ekzistuese. Metoda jonë, e quajtur Rapformer, është bazuar në trajnimin e një autokoduesi me bazë në Transformer për të rindërtuar lirikën rap nga fjalët e përmbajtjes të nxjerrura nga lirikë, duke u përpjekur të ruajë kuptimin thelbësor, ndërsa përputhet me stilin e objektivit. Rapformer ka një skemë parafrazimi të re me bazë në BERT për përmirësimin e ritmit që rrit densitetin mesatar të ritmit të lirikës së daljes me 10%. Rezultatet eksperimentale në tre fusha të ndryshme të hyrjes tregojnë se Rapformer është në gjendje të krijojë versete teknikisht fluente që ofrojnë një kompromis të mirë midis ruajtjes së përmbajtjeve dhe transferimit të stilit. Përveç kësaj, një eksperiment i ngjashëm me testin Turing zbulon se Rapformer mashtron ekspertët e lirisë njerëzore 25% të kohës.', 'hy': 'Լեզու ստեղծելու խորհրդանիշներ համադրելու ունակությունը մարդկային ինտելեկտության սահմանափակումն է, հատկապես արվեստի պատմություններ պատմելու համատեքստում, բառերի միջոցով: Մենք ստեղծում ենք մի մեթոդ, որը հիմնված է ցանկացած տեքստի պարունակության վրա (օրինակ, նորությունների հոդվածի) կամ նախկինում գոյություն ունեցող ռեպ տեքստի ավելացման համար: Our method, called Rapformer, is based on training a Transformer-based denoising autoencoder to reconstruct rap lyrics from content words extracted from the lyrics, trying to preserve the essential meaning, while matching the target style.  Rapformer features a novel BERT-based paraphrasing scheme for rhyme enhancement which increases the average rhyme density of output lyrics by 10%.  Երեք բազմազան ներմուծքային ոլորտների փորձարկման արդյունքները ցույց են տալիս, որ Ռաֆերմերը ունի ստեղծել տեխնիկապես հեշտ երգեր, որոնք լավ փոխանակում են պարունակության պահպանության և ոճի փոխանցման միջև: Ավելին, Թուրինգ-տեստերի նման փորձը բացահայտում է, որ Ռաֆերմերը հիմար է մարդկային տեքստի մասնագետներին 25 տոկոսին:', 'az': "Dili yaratmaq üçün simbolları birləşdirmək qüvvəti insan intellektinin tanımlayan xüsusiyyətləridir, özlərinə də sanatçı hekayələri sözlərlə danışmaq məqsədilə. Biz hər hansı bir mətnin məlumatına dayanan rap versesini sintezləşdirmək üçün bir metodu təhsil edirik (məsələn, bir məlumat məlumatı), yaxud əvvəlki rap sözlərini artırmaq üçün. Rapformer adlı metodumuz, özünüzü təhsil edən Transformer təhsil etməyə dayanılır, rap sözlərini sözlərdən çıxarılan məsələlərdən yenidən inşa etmək üçün, məqsədilə istifadə edilən məsələləri qorumağa çalışırlar. Rapformer yeni BERT tabanlı parafraze taslağı üçün rhyme artırması üçün yaradılır ki, ortalama rhyme yoğunluğunu 10%-ə artırar. Üç müxtəlif girdi domeinlərin təcrübə sonuçları Rapformer'in teknik olaraq fəaliyyətli verselər yaratmağa qadir olduğunu göstərir ki, məlumat qoruması və stil transfersi arasındakı yaxşı ticarət təklif edir. Daha sonra, Turing sınaması kimi bir eksperiment Rapformer insan sözlərinin ehtimallarının %25 olduğunu göstərir.", 'am': 'ቋንቋን ለመፍጠር የሚችል ኃይል የሰው intelligence አስተያየት ነው፣ በተለየ በቋንቋዎች ላይ ታሪክ ታሪክ በሚናገር ግንኙነት ነው፡፡ በጽሑፍ (ለምሳሌ የዜና ጽሑፍ) ወይም አስቀድሞ የአካባቢው የrap ዝርዝሮች ለመማሰናከል፣ የቀድሞው የረኀብ ድምፅ ለመማሰናከል የሚችሉትን ሥርዓት እናደርጋለን፡፡ የረፕፎር ስም፣ የግንኙነታችንን ግንኙነት በመስጠት በተቃራኒ ቃላት ከታሪክ ወጥቶ የረኀብ ዝርዝሮች ለመሠረት የተደረገ ነው፡፡ ምርጫዎች በሦስት ልዩ የደረጃ ድምፅ ውጤቶች ላይ የተፈተና ውጤቶች ማሳየት እና በይዞታው ማቀናቀል እና በሥርዓት መዘዋወር መካከል መልካም ንግድ ማድረግ እንዲችል ያሳያል፡፡ ከዚህም በላይ የTuring-like ፈተና፣ የቀድሞው ሰነፎች የዘመኑን 25 በመቶ አስተያየት የሚያሳውቃቸዋል፡፡', 'bn': 'ভাষা উৎপাদনের প্রতীক একত্রিত করার ক্ষমতা হচ্ছে মানুষ গুরুত্বপূর্ণ বৈশিষ্ট্য, বিশেষ করে শিল্পী গল্পের গল্পের মাধ্যমে শিল্ আমরা কোন টেক্সটের বিষয়বস্তু ভিত্তিতে ধর্ষণের বিভিন্ন সাথে একত্রিত করার একটি পদ্ধতি তৈরি করি (যেমন সংবাদ প্রবন্ধ), অথবা বিদ্যমান ধর্ষণের পূর্ব আমাদের পদ্ধতি, যার নাম র্যাপফোর্নাম, তারা টার্গেট স্টাইল থেকে বেরিয়ে যাওয়া বিষয়গুলোর বিষয়গুলো থেকে ধর্ষণের কথা পুনঃনির্মাণ করার জন্য ট্রান্সফ্রেন ভ র\u200d্যাপ্ফোর্ড ব্যাপারেট ভিত্তিক ভিত্তিক প্যারাফ্রেসিং বিন্যাসের পরিকল্পনা ব্যবহার করেছে যা আউটপুটের গায়ক গায়কের গড়ির মান গ তিনটি বিভিন্ন ইনপুট ডোমেনে পরীক্ষার ফলাফল দেখা যাচ্ছে যে রাপ্ফোর্স প্রযুক্তিগত প্রযুক্তিগত ফ্লায়েন্ট প্রতিষ্ঠান তৈরি করতে সক্ষম এছাড়াও, টার্নিং পরীক্ষার মত এক পরীক্ষা প্রকাশ করেছে যে রাপ্রাক্তন বোকার মানুষের গায়েব বিশেষজ্ঞ ২৫ শতাংশ সময়ের মধ্', 'bs': 'Sposobnost kombiniranja simbola za proizvedenje jezika je definicija karakteristike ljudske inteligencije, posebno u kontekstu umjetničkih pričanja kroz tekstove. Razvijamo metodu za sinteziranje stihova rap a na temelju sadržaja bilo kojeg teksta (npr. novinskog članaka) ili za povećanje pre-postojećih tekstova rapa. Naša metoda, zvana Rapformer, je temeljena na obuci transformator-baziranog autokodera kako bi rekonstruisala tekstove rapa iz sadržajnih riječi izvučenih iz tekstova, pokušavajući čuvati temeljno značenje, dok odgovara ciljnom stilu. Rapformer ima novu parafrazacijsku shēmu na BERT-u za poboljšanje rima koja povećava prosječnu gustinu rima tekstova na 10%. Eksperimentalni rezultati na tri različita domena ulaska pokazuju da je Rapformer sposoban stvoriti tehnički tekuće stihove koji nude dobru trgovinu između očuvanja sadržaja i transfer a stila. Osim toga, eksperiment sličan na Turing test pokazuje da Rapformer budala ljudske tekstove stručnjake 25% vremena.', 'ca': "L'habilitat de combinar símbols per generar llenguatge és una característica definidora de la intel·ligència human a, especialment en el context de la narració artística a través de les lletres. Desenvolvem un mètode per sintetitzar un versícul rap basat en el contingut de qualsevol text (per exemple, un article de notícies), o per augmentar les lletres rap pre-existents. El nostre mètode, anomenat Rapformer, es basa en la formació d'un autocodificador denòstic basat en Transformer per reconstruir les lletres rap de les paraules de contingut extraïdes de les lletres, intentant preservar el significat essencial, al mateix temps que coincideix amb l'estil d'objectiu. Rapformer té un nou esquema de parafrases basat en BERT per a millorar el ritme que augmenta la densitat mitjana de ritmes de les lletres de producció en un 10%. Els resultats experimentals en tres dominis d'entrada diversos mostran que Rapformer és capaç de generar versos tècnicament fluents que ofereixen un bon compromís entre la conservació del contingut i la transfer ència d'estil. A més, un experiment semblant a la prova de Turing revela que Rapformer enganya els experts en liriques humanes el 25% del temps.", 'cs': 'Schopnost kombinovat symboly k generování jazyka je určující charakteristikou lidské inteligence, zejména v kontextu uměleckého vyprávění příběhů prostřednictvím textů. Vyvíjíme metodu syntetizace rapového verše na základě obsahu libovolného textu (např. zpravodajského článku) nebo pro rozšíření již existujících rapových textů. Naše metoda, nazvaná Rapformer, je založena na tréninku autokodéru založeného na Transformeru, který rekonstruuje rapové texty z obsahových slov extrahovaných z textů, snaží se zachovat základní význam a současně odpovídat cílovému stylu. Rapformer obsahuje nové parafrázovací schéma založené na BERT pro vylepšení rýmu, které zvyšuje průměrnou hustotu rýmu výstupních textů o 10%. Experimentální výsledky na třech různých vstupních doménách ukazují, že Rapformer je schopen generovat technicky plynulé verše, které nabízejí dobrý kompromis mezi uchováváním obsahu a přenosem stylu. Kromě toho experiment podobný Turingovým testem odhaluje, že Rapformer oklamává lidské textové experty 25% času.', 'et': 'Võime kombineerida sümboleid keele genereerimiseks on inimintelligentsi iseloomulik omadus, eriti kunstilise jutustamise kontekstis sõnade kaudu. Töötame välja meetodi räpi salmi sünteesimiseks, mis põhineb mis tahes teksti sisul (nt uudiste artikkel), või olemasolevate räpi sõnade täiendamiseks. Meie meetod, mida nimetatakse Rapformeriks, põhineb Transformeril põhineva denoiseeriva automaatkodeerija koolitamisel, et rekonstrueerida rap sõnad sõnadest välja võetud sisusõnadest, püüdes säilitada oluline tähendus, samas sobitades sihtstiili. Rapformer sisaldab uudset BERT-põhist parafraseerimisskeemi riimide täiustamiseks, mis suurendab väljundsõnade keskmist riimide tihedust 10%. Kolme erineva sisenddomeeni eksperimentaalsed tulemused näitavad, et Rapformer suudab luua tehniliselt sujuvaid salme, mis pakuvad head kompromisse sisu säilitamise ja stiiliülekande vahel. Lisaks näitab Turingi testilaadne eksperiment, et Rapformer lollitab inimeste sõnade eksperte 25% ajast.', 'fi': 'Kyky yhdistää symboleja kielen tuottamiseksi on ihmisen älykkyyden määrittelevä ominaisuus erityisesti taiteellisen tarinankerronnan kontekstissa sanoitusten avulla. Kehitämme menetelmän minkä tahansa tekstin (esim. uutisartikkelin) sisältöön perustuvan rap-säkeen syntetisointiin tai olemassa olevien rap-lyriikkojen lisäämiseen. Menetelmämme, nimeltään Rapformer, perustuu Transformer-pohjaisen denoising-automaattikooderin kouluttamiseen rekonstruoimaan rap-sanoituksia sanoista, jotka on otettu sanoista, yrittäen säilyttää oleellisen merkityksen ja samalla sovittaa kohdetyyliin. Rapformerissa on uusi BERT-pohjainen parafrasointijärjestelmä riimien parantamiseen, joka lisää lähtösanoitusten keskimääräistä riimitiheyttä 10%. Kokeelliset tulokset kolmella eri syöttöalueella osoittavat, että Rapformer pystyy tuottamaan teknisesti sujuvasti jakeita, jotka tarjoavat hyvän kompromissin sisällön säilyttämisen ja tyylin siirron välillä. Lisäksi Turingin kaltainen kokeilu paljastaa, että Rapformer huijaa ihmisten sanoituksia asiantuntijoita 25% ajasta.', 'ha': "Taimar da ya haɗa symboli da za'a zaɓe harshe shi ne mai ƙayyade karatun na mutane, hususanci, cikin muhallin da ke gaya hadishi na fassarar da lissafi. Tuna buɗe wata hanyoyi wa synthesizing wani rape verse da ke cikin ƙunsa da wani matsayi (misali, wani makala da la'anar lãbãri), ko dõmin ƙarfafa littafan da ke gaba ɗaya. Tayiyinmu, ana kalmar Rapformer, yana a kan yin amfani da kodi mai bastarwa farat ɗaya na Transformer dõmin ya sake rekodi lyrici na bakin rubutu daga maganar da aka fito daga linsafi, kuma yana jarraba yin tsari ga muhimmin, a lokacin da ya daidaita misalin goan. @ info: whatsthis Tajararin matsala a kan tsari da shishi mai tsaro da salon. Furan haka, jarrabi mai kama da turing ya bayyana cewa watayyan karãtun mutane na Rapformer ne 25% daga lokacin.", 'he': 'היכולת לשלב סמלים לייצור שפה היא אופיינת מגדירה של אינטליגנציה אנושית, במיוחד בקשר לסיפור אמני דרך מילים. אנחנו מפתחים שיטה לסינטזיה של פסל רפ מבוסס על התוכן של כל טקסט (למשל, מאמר חדשות), או לגדל מילים רפ קיימות קודם. Our method, called Rapformer, is based on training a Transformer-based denoising autoencoder to reconstruct rap lyrics from content words extracted from the lyrics, trying to preserve the essential meaning, while matching the target style.  Rapformer features a novel BERT-based paraphrasing scheme for rhyme enhancement which increases the average rhyme density of output lyrics by 10%.  תוצאות ניסיוניות בשלושה תחומות כניסה מגוונות מראות שרפפורר מסוגל ליצור הודעות שטויות טכנית שמציעות סחר טוב בין שמירת תוכן ועברת סגנון. חוץ מזה, ניסוי דומה למבחן טורינג מגלה שראפרס מטופש מומחים במילים אנושיים 25% מהזמן.', 'sk': 'Sposobnost združevanja simbolov za ustvarjanje jezika je odločilna značilnost človeške inteligence, zlasti v kontekstu umetniškega pripovedovanja zgodb skozi besedilo. Razvijamo metodo za sintetizacijo rap verzov, ki temelji na vsebini katerega koli besedila (npr. novinarskega članka), ali za dopolnitev že obstoječih rap besedil. Naša metoda, imenovana Rapformer, temelji na usposabljanju samokodirnika, ki temelji na transformatorju, da rekonstruira rap besedila iz besedil vsebine, pridobljenih iz besedil, poskuša ohraniti bistveni pomen, hkrati pa ustrezati ciljnemu slogu. Rapformer vsebuje novo BERT-jevo parafraziranje shemo za izboljšanje rim, ki poveča povprečno gostoto rim izhodnih besedil za 10%. Eksperimentalni rezultati na treh različnih vhodnih domenah kažejo, da je Rapformer sposoben ustvariti tehnično tekoče verze, ki ponujajo dober kompromis med ohranjanjem vsebine in prenosom sloga. Poleg tega Turing testu podoben eksperiment razkriva, da Rapformer preslepi strokovnjake za človeška besedila 25% časa.', 'jv': 'Kapan kanggo ngubah Simbol kanggo ngelangubah luwih dumadhi peringatan kapan ning sampeyan nguasai perusahaan, supayano sak aturan akeh artis-ingkang kelas Awak dhéwé nggunakake sistem kanggo seneng perverse rap sing basa gambar nggawe layar seneng pisar, ingkang nggawe nggawe barang seneng rap sing susahe tuatah. Awakdhéwé, rapex, wis akèh nggunakake tresnaning basa transformer sampek autokoder nggawe ngupakan kelas rap sing dikarep gambaran seneng pisan dhéwé, njaluké iso nggawe barang langgar sampek nggawe gerakan seneng winih sing apik dhéwé. (rap) R Label, testing-test yo koyo ngono rap paler perbudhakan sing paling apik sing paling apik maneh, limangatan pakan karo limangatan pakan karo limangatan pakan karo limangatan.', 'bo': 'སྐད་རིགས་གསར་བསྐྲུན་འབད་ནི་ཆ་རྟགས་མཉམ་དུ་བསྡད་ན་ཡིན་མིའི་ཆ་རྐྱེན་ཀྱི་ཁྱད་ཆོས་ཉིད་ཅིག་ཡིན། ང་ཚོས་ཡིག་གེ་གང་ཡིག་གི་ནང་དུ་ཡིག་ཆ་སྒྲིག་ཐབས་ལམ་ཞིག་གསར་བསྐྲུན་བྱེད་ཀྱི་ཡོད། Our method, called Rapformer, is based on training a Transformer-based denominating autoencoder to reconstruct rap lyrics from content words extracted from the lyrics, trying to preserve the essential meaning, while matching the target style. Rapformer འདི་ལྟ་བུའི་ཚིག Experimental results on three different input domains show that Rapformer is capable of generating technically fluent verses that offer a good trade-off between content preservation and style transfer. འོན་ཀྱང་། Turing་བརྟག་དཔྱད་བྱ་ཚིག་ཞིག་གིས་Rapformer སྐོར་གྱིས་མི་རྣམས་ལས་བརྟག་པར་གཏོང་མཁན་དབྱེ་བ་སྤེལ་གྱི་ཐབས་ལམ'}
{'en': 'Policy-Driven Neural Response Generation for Knowledge-Grounded Dialog Systems', 'pt': 'Geração de Resposta Neural Orientada por Políticas para Sistemas de Diálogo Baseados no Conhecimento', 'es': 'Generación de respuestas neuronales basada en políticas para sistemas de diálogo basados en el conocimiento', 'ar': 'توليد الاستجابة العصبية المدفوعة بالسياسات لأنظمة الحوار القائمة على المعرفة', 'fr': 'Génération de réponses neuronales pilotées par des politiques pour les systèmes de dialogue fondés', 'zh': '盖知识之策动神经响应生成', 'ja': '知識基盤型ダイアログシステムのためのポリシー駆動型ニューラルレスポンス生成', 'hi': 'ज्ञान-आधारित संवाद प्रणालियों के लिए नीति-संचालित तंत्रिका प्रतिक्रिया पीढ़ी', 'ru': 'Формирование нейронной реакции на основе политики для систем диалога, основанных на знаниях', 'ga': 'Giniúint Freagartha Néaracha atá Tiomanta ag Beartas do Chórais Dialóige Bunaithe ar an Eolas', 'ka': 'Name', 'el': 'Δημιουργία νευρωνικής απόκρισης βάσει πολιτικής για συστήματα διαλόγου βασισμένα στη γνώση', 'hu': 'Politikai vezérelt idegrendszerek generálása a tudásalapú párbeszédrendszerekhez', 'it': 'Generazione di risposta neurale guidata dalle politiche per sistemi di dialogo basati sulla conoscenza', 'kk': 'Мәлімді түрлі диалог жүйелерінің ережелер- драйвері нейралық жауап беру', 'lt': 'Politikos pagrindu grindžiamo neurologinio atsako generavimas žiniomis grindžiamoms dialogo sistemoms', 'ms': 'Penjanaan Balasan Neural Pemacu Polisi untuk Sistem Dialog Berdasarkan Pengetahuan', 'mk': 'Policy-Driven Neural Response Generation for Knowledge-Grounded Dialog Systems', 'ml': 'Policy-Driven Neural Response Generation for Knowledge-Grounded Dialog Systems', 'mn': 'Мэдлэг-хөндлөн диалог системийн сэтгэл санааны хариу үйлдвэрлэл', 'no': 'Generering av nøyralsvar på politikkdrivaren for kjennområde dialogsystemer', 'pl': 'Generowanie reakcji neuronowych opartych na polityce dla systemów dialogu opartych na wiedzy', 'mt': 'Ġenerazzjoni ta’ Rispons Newrali mmexxi mill-Politika għal Sistemi ta’ Djalogu bbażati fuq l-Għarfien', 'ro': 'Generarea de răspuns neural bazată pe politici pentru sistemele de dialog bazate pe cunoaștere', 'si': 'Name', 'sr': 'Generacija neuroloških odgovora na politiku za sisteme razmaženog dijaloga znanja', 'so': 'Isticmaalka aqoonta-asalka', 'sv': 'Politiskt driven generering av neural respons för kunskapsbaserade dialogsystem', 'ur': 'علم-Grounded Dialog Systems کے لئے پولیسیٹی-ڈرائین نیورال اعتراض پیدا کرنا', 'ta': 'அறிவிப்பு- விரிவாக்கப்பட்ட உரையாடல் அமைப்புகளுக்கான கொள்கை- இயக்கிய புதிய பதில் உருவாக்கம்', 'uz': 'Name', 'vi': 'Hệ thống xung động thần kinh vớ vẩn cho hệ thống hộp thoại', 'da': 'Politikdrevet generering af neural respons til vidensbaserede dialogsystemer', 'nl': 'Beleidsgestuurde neurale responsgeneratie voor kennisgebaseerde dialoogsystemen', 'hr': 'Generacija neuroloških odgovora na politiku za sustave dijaloga pod znanjem', 'de': 'Politikgetriebene Generierung neuronaler Reaktionen für wissensbasierte Dialogsysteme', 'id': 'Generasi Respon Neural Driven Kebijaksanaan untuk Sistem Dialog Berdasarkan Pengetahuan', 'fa': 'تولید پاسخ عصبی سیاست رانندگی برای سیستم\u200cهای گفتگوی شناخته شده', 'sw': 'Sera inayoendeshwa na Majibu ya asili kwa ajili ya Mfumo wa Dialogu inayotumiwa na ufahamu', 'tr': 'Bilgi-Grounded Dialog Systemleri üçin polítika sürüjili Näral Response Jeşirmesi', 'af': 'Politika- dryf Neurale Antwoord Genereer vir kennis- grootte dialoog stelsels', 'bg': 'Генериране на невронни реакции, базирани на политиките, за диалогови системи', 'sq': 'Gjenerimi i përgjigjeve neuronale të udhëhequra nga politika për sistemet e dialogut të bazuar në njohuri', 'am': 'ምርጫዎች', 'hy': 'Գիտության հիմնված հաղորդակցման համակարգերի համար քաղաքականության հիմնված նեյրոնալ արձագանքը', 'ko': '전략 기반의 지식 기반 대화 시스템 신경 응답 생성', 'az': 'Bilim-d톛st톛kli Dialoog Sisteml톛ri 칲칞칲n siyasi-s칲r칲c칲 n칬ral cavab Yenilm톛si', 'bn': 'জ্ঞান-ভূমিকম্প ডায়ালগ সিস্টেমের জন্য নীতি-ড্রাইভেন নিউরাল প্রতিক্রিয়া প্রজন্ম', 'bs': 'Generacija neuroloških odgovora na politiku za sisteme dijaloga pod znanjem', 'ca': 'Generació de resposta neuronal basada en polítiques per sistemes de diàleg basats en el coneixement', 'cs': 'Generování nervové reakce založené na politice pro dialogové systémy založené na znalostech', 'et': 'Poliitikapõhine neuroreaktsioon teadmistepõhiste dialoogisüsteemide jaoks', 'fi': 'Poliittinen neurovaste osaamiseen perustuvia vuoropuhelujärjestelmiä varten', 'jv': 'ProgressBarUpdater', 'ha': 'KCharselect unicode block name', 'sk': 'Ustvarjanje živčnega odziva na politiko za sisteme dialoga, temelječe na znanju', 'he': 'הגורלת תגובה נוירולית מונעת על מדיניות למערכות דיאלוג מבוססות על ידע', 'bo': 'Knowledge-Grounded Dialog Systems(Policy-Driven Neural Response Generation for Knowledge-Grounded Dialog Systems)'}
{'en': 'Open-domain dialog systems aim to generate relevant, informative and engaging responses. In this paper, we propose using a dialog policy to plan the content and style of target, open domain responses in the form of an action plan, which includes knowledge sentences related to the dialog context, targeted dialog acts, topic information, etc. For training, the attributes within the action plan are obtained by automatically annotating the publicly released Topical-Chat dataset. We condition neural response generators on the action plan which is then realized as target utterances at the turn and sentence levels. We also investigate different dialog policy models to predict an action plan given the dialog context. Through automated and human evaluation, we measure the appropriateness of the generated responses and check if the generation models indeed learn to realize the given action plans. We demonstrate that a basic dialog policy that operates at the sentence level generates better responses in comparison to turn level generation as well as baseline models with no action plan. Additionally the basic dialog policy has the added benefit of controllability.', 'ar': 'تهدف أنظمة حوار المجال المفتوح إلى إنشاء استجابات ذات صلة وغنية بالمعلومات وجذابة. في هذه الورقة ، نقترح استخدام سياسة الحوار لتخطيط محتوى وأسلوب الهدف ، وفتح استجابات المجال في شكل خطة عمل ، والتي تتضمن جمل معرفية تتعلق بسياق الحوار ، وأعمال الحوار المستهدفة ، ومعلومات الموضوع ، وما إلى ذلك. التدريب ، يتم الحصول على السمات الموجودة في خطة العمل عن طريق التعليق تلقائيًا على مجموعة بيانات Topical-Chat التي تم إصدارها للجمهور. نحن نشترط مولدات الاستجابة العصبية في خطة العمل والتي يتم تحقيقها بعد ذلك على أنها كلمات مستهدفة على مستوى الانعطاف والجملة. نحن أيضًا نحقق في نماذج سياسات الحوار المختلفة للتنبؤ بخطة عمل في ضوء سياق الحوار. من خلال التقييم الآلي والبشري ، نقيس مدى ملاءمة الاستجابات المتولدة ونتحقق مما إذا كانت نماذج التوليد تتعلم بالفعل كيفية تحقيق خطط العمل المحددة. نوضح أن سياسة الحوار الأساسية التي تعمل على مستوى الجملة تولد استجابات أفضل مقارنة بتوليد المستوى وكذلك النماذج الأساسية بدون خطة عمل. بالإضافة إلى ذلك ، فإن سياسة الحوار الأساسية لها فائدة إضافية تتمثل في إمكانية التحكم.', 'pt': 'Os sistemas de diálogo de domínio aberto visam gerar respostas relevantes, informativas e envolventes. Neste artigo, propomos usar uma política de diálogo para planejar o conteúdo e o estilo das respostas alvo, de domínio aberto na forma de um plano de ação, que inclui sentenças de conhecimento relacionadas ao contexto do diálogo, atos de diálogo direcionados, informações do tópico, etc. treinamento, os atributos dentro do plano de ação são obtidos anotando automaticamente o conjunto de dados Topical-Chat divulgado publicamente. Condicionamos os geradores de resposta neural no plano de ação que é então realizado como enunciados alvo nos níveis de turno e sentença. Também investigamos diferentes modelos de políticas de diálogo para prever um plano de ação dado o contexto do diálogo. Por meio de avaliação automatizada e humana, medimos a adequação das respostas geradas e verificamos se os modelos de geração de fato aprendem a realizar os planos de ação dados. Demonstramos que uma política básica de diálogo que opera em nível de sentença gera melhores respostas em comparação à geração de nível de turno, bem como modelos de linha de base sem plano de ação. Além disso, a política básica de diálogo tem o benefício adicional de controlabilidade.', 'fr': "Les systèmes de dialogue de domaine ouvert visent à générer des réponses pertinentes, informatives et engageantes. Dans cet article, nous proposons d'utiliser une stratégie de dialogue pour planifier le contenu et le style des réponses de domaine ouvert cible sous la forme d'un plan d'action, qui inclut des phrases de connaissances liées au contexte du dialogue, des actes de dialogue ciblés, des informations sur le sujet, etc. Pour la formation, les attributs du plan d'action sont obtenu en annotant automatiquement le jeu de données Topical-Chat publié publiquement. Nous conditionnons les générateurs de réponse neuronale sur le plan d'action qui est ensuite réalisé sous forme d'énoncés cibles au niveau du tour et de la phrase. Nous étudions également différents modèles de politique de dialogue afin de prédire un plan d'action en fonction du contexte de dialogue. Grâce à une évaluation automatisée et humaine, nous mesurons la pertinence des réponses générées et vérifions si les modèles de génération apprennent effectivement à réaliser les plans d'action donnés. Nous démontrons qu'une politique de dialogue de base qui fonctionne au niveau de la phrase génère de meilleures réponses par rapport à la génération de niveaux de virage ainsi que des modèles de base sans plan d'action. De plus, la stratégie de dialogue de base présente l'avantage supplémentaire de la contrôlabilité.", 'es': 'Los sistemas de diálogo de dominio abierto tienen como objetivo generar respuestas relevantes, informativas y atractivas. En este artículo, proponemos utilizar una política de diálogo para planificar el contenido y el estilo de las respuestas de dominio abierto objetivo en forma de un plan de acción, que incluye oraciones de conocimiento relacionadas con el contexto del diálogo, actos de diálogo dirigidos, información sobre temas, etc. Para la capacitación, los atributos dentro del plan de acción son obtenido mediante la anotación automática del conjunto de datos de chat tópico publicado públicamente. Condicionamos los generadores de respuesta neuronal al plan de acción que luego se realiza como enunciados objetivo en los niveles de giro y oración. También investigamos diferentes modelos de políticas de diálogo para predecir un plan de acción dado el contexto del diálogo. A través de la evaluación automatizada y humana, medimos la idoneidad de las respuestas generadas y comprobamos si los modelos de generación realmente aprenden a realizar los planes de acción dados. Demostramos que una política de diálogo básica que opera a nivel de oración genera mejores respuestas en comparación con la generación a nivel de turno, así como los modelos de referencia sin plan de acción. Además, la política de diálogo básica tiene el beneficio adicional de la capacidad de control.', 'ja': 'オープンドメインのダイアログシステムは、関連性が高く、情報量が多く、魅力的な回答を生成することを目的としています。 本稿では，対象の内容やスタイルを計画するためのダイアログポリシーを用いて，ダイアログコンテキストに関連する知識文言，対象とするダイアログアクト，トピック情報などを含むアクションプランの形でオープンドメイン対応を提案する． トレーニングでは、アクションプラン内の属性は、公開されているTopical - Chatデータセットに自動的に注釈を付けることによって取得されます。 アクションプランに基づいてニューラルレスポンスジェネレータを調整し、ターンおよび文レベルでターゲット発話として実現します。 また、さまざまなダイアログポリシーモデルを調査して、ダイアログのコンテキストでアクションプランを予測します。 自動評価と人間評価を通じて、生成された応答の適切性を測定し、生成モデルが与えられたアクションプランを実現することを実際に学んでいるかどうかを確認します。 文レベルで動作する基本的なダイアログポリシーは、アクションプランのないベースラインモデルだけでなく、ターンレベル生成と比較してより良い応答を生成することを実証します。 さらに、基本的なダイアログポリシーには、コントロール性の利点があります。', 'zh': '开域语系统,信息富且引人入胜。 建言用对策以规风格,行动计划以开域应,上下文关知句,针对性对行,主题信息。 其于训练,行动计划之性,因自注明发之 Topical-Chat 数集来取之。 置神经生成器于行动计划上,然后致之以句。 又论异策,以给定上下文占行动计划。 自与人工料之,量生应之适性,而审其成模之实给定之行动计划。 吾证与无行动计划之转生,与无基线之形比,句之大略,可以生应。 此外,略有可控性之益。', 'hi': 'ओपन-डोमेन संवाद प्रणालियों का उद्देश्य प्रासंगिक, जानकारीपूर्ण और आकर्षक प्रतिक्रियाएं उत्पन्न करना है। इस पेपर में, हम लक्ष्य की सामग्री और शैली की योजना बनाने के लिए एक संवाद नीति का उपयोग करने का प्रस्ताव करते हैं, एक कार्य योजना के रूप में डोमेन प्रतिक्रियाओं को खोलते हैं, जिसमें संवाद संदर्भ से संबंधित ज्ञान वाक्य, लक्षित संवाद कार्य, विषय जानकारी आदि शामिल हैं। प्रशिक्षण के लिए, कार्य योजना के भीतर विशेषताओं को स्वचालित रूप से सार्वजनिक रूप से जारी किए गए सामयिक-चैट डेटासेट को एनोटेट करके प्राप्त किया जाता है। हम कार्य योजना पर तंत्रिका प्रतिक्रिया जनरेटर की स्थिति रखते हैं जो तब बारी और वाक्य स्तरों पर लक्ष्य कथन के रूप में महसूस किया जाता है। हम संवाद संदर्भ को देखते हुए एक कार्य योजना की भविष्यवाणी करने के लिए विभिन्न संवाद नीति मॉडल की भी जांच करते हैं। स्वचालित और मानव मूल्यांकन के माध्यम से, हम उत्पन्न प्रतिक्रियाओं की उपयुक्तता को मापते हैं और जांचते हैं कि क्या पीढ़ी के मॉडल वास्तव में दिए गए कार्य योजनाओं को महसूस करना सीखते हैं। हम प्रदर्शित करते हैं कि एक बुनियादी संवाद नीति जो वाक्य स्तर पर संचालित होती है, वह टर्न लेवल जेनरेशन के साथ-साथ बिना किसी कार्य योजना के बेसलाइन मॉडल की तुलना में बेहतर प्रतिक्रियाएं उत्पन्न करती है। साथ ही मूल संवाद नीति नियंत्रणीयता का अतिरिक्त लाभ है।', 'ru': 'Диалоговые системы открытого домена нацелены на генерирование актуальных, информативных и привлекательных ответов. В данной работе мы предлагаем использовать диалоговую политику для планирования содержания и стиля целевых, открытых доменных ответов в виде плана действий, который включает в себя предложения знаний, связанные с контекстом диалога, целевые диалоговые акты, информацию о теме и т. д. Для обучения атрибуты в рамках плана действий получаются путем автоматической аннотации публично выпущенного набора данных Topical-Chat. Мы обусловливаем генераторы нейронных ответов планом действий, который затем реализуется как целевые фразы на уровне поворота и предложения. Мы также изучаем различные модели политики диалога для прогнозирования плана действий с учетом контекста диалога. Посредством автоматизированной и человеческой оценки мы измеряем уместность генерируемых ответов и проверяем, действительно ли модели поколения учатся реализовывать данные планы действий. Мы демонстрируем, что базовая политика диалога, которая работает на уровне предложения, генерирует лучшие ответы по сравнению с генерацией уровня поворота, а также базовыми моделями без плана действий. Кроме того, базовая политика диалога имеет дополнительное преимущество - управляемость.', 'ga': 'Tá sé mar aidhm ag córais dialóige fearainn oscailte freagraí ábhartha, faisnéiseacha agus tarraingteach a ghiniúint. Sa pháipéar seo, molaimid úsáid a bhaint as beartas dialóige chun ábhar agus stíl sprioc a phleanáil, freagraí fearainn oscailte i bhfoirm plean gníomhaíochta, lena n-áirítear abairtí eolais a bhaineann leis an gcomhthéacs dialóige, gníomhartha dialóige spriocdhírithe, faisnéis faoi ábhair, etc. oiliúna, faightear na tréithe laistigh den phlean gníomhaíochta tríd an tacar sonraí Topical-Chat a eisítear go poiblí a anótáil go huathoibríoch. Cuirimid gineadóirí freagartha néaracha ar an bplean gníomhaíochta a réadaítear ansin mar spriocfhocail ag leibhéil casa agus pianbhreithe. Déanaimid imscrúdú freisin ar mhúnlaí beartais dialóige éagsúla chun plean gníomhaíochta a thuar i gcomhthéacs an chomhthéacs dialóige. Trí mheastóireacht uathoibrithe agus dhaonna, tomhaisimid oiriúnacht na bhfreagairtí ginte agus seiceálaimid an bhfoghlaimíonn na samhlacha giniúna go deimhin na pleananna gníomhaíochta tugtha a réadú. Léirímid go ngineann bunbheartas dialóige a fheidhmíonn ag leibhéal na habairte freagraí níos fearr i gcomparáid le giniúint ag leibhéal an ionaid chomh maith le samhlacha bonnlíne gan aon phlean gníomhaíochta. Ina theannta sin tá buntáiste breise ag an mbunbheartas dialóige maidir le hinrialaitheacht.', 'el': 'Τα ανοικτά συστήματα διαλόγου στοχεύουν στη δημιουργία σχετικών, ενημερωτικών και ελκυστικών απαντήσεων. Στην παρούσα εργασία, προτείνουμε τη χρήση μιας πολιτικής διαλόγου για τον σχεδιασμό του περιεχομένου και του στυλ των στοχευόμενων απαντήσεων ανοικτού τομέα με τη μορφή ενός σχεδίου δράσης, το οποίο περιλαμβάνει προτάσεις γνώσης που σχετίζονται με το πλαίσιο διαλόγου, στοχευμένες πράξεις διαλόγου, πληροφορίες θέματος κ.λπ. Για την εκπαίδευση, τα χαρακτηριστικά του σχεδίου δράσης λαμβάνονται αυτόματα σχολιάζοντας το δημόσια δημοσιευμένο σύνολο δεδομένων Τοπικής συνομιλίας. Ρυθμίζουμε τις γεννήτριες νευρικής απόκρισης στο σχέδιο δράσης το οποίο στη συνέχεια υλοποιείται ως στοχευμένες εκφράσεις σε επίπεδο στροφής και πρότασης. Ερευνούμε επίσης διαφορετικά μοντέλα πολιτικής διαλόγου για να προβλέψουμε ένα σχέδιο δράσης δεδομένης του πλαισίου διαλόγου. Μέσω αυτοματοποιημένης και ανθρώπινης αξιολόγησης, μετράμε την καταλληλότητα των παραγόμενων απαντήσεων και ελέγχουμε αν τα μοντέλα παραγωγής μαθαίνουν πράγματι να υλοποιούν τα δεδομένα σχέδια δράσης. Αποδεικνύουμε ότι μια βασική πολιτική διαλόγου που λειτουργεί σε επίπεδο πρότασης παράγει καλύτερες απαντήσεις σε σύγκριση με την παραγωγή επιπέδου στροφής καθώς και με μοντέλα βάσης χωρίς σχέδιο δράσης. Επιπλέον, η βασική πολιτική διαλόγου έχει το πρόσθετο πλεονέκτημα της δυνατότητας ελέγχου.', 'hu': 'A nyílt domain párbeszédrendszerek célja, hogy releváns, informatív és vonzó válaszokat generáljanak. Ebben a tanulmányban párbeszédházirend használatát javasoljuk a cél tartalmának és stílusának megtervezésére, nyitott domain válaszok cselekvési terv formájában, amely tartalmazza a párbeszéd kontextusához kapcsolódó tudásképtelenségeket, célzott párbeszédaktusokat, témainformációkat stb. A képzéshez a cselekvési tervben található attribútumokat a nyilvánosan kiadott Topical-Chat adathalmaz automatikus jegyzetelével szerezzük meg. Neurális válasz generátorokat kondicionálunk a cselekvési tervben, amelyek aztán célkitűzésként valósulnak meg a forduló- és mondatszintekben. Ezenkívül különböző párbeszédpolitikai modelleket is vizsgálunk, hogy előrejelezzük a cselekvési tervet a párbeszédkörnyezet alapján. Automatizált és emberi értékeléssel mérjük a generált válaszok megfelelőségét, és ellenőrizzük, hogy a generációs modellek valóban megtanulják-e megvalósítani az adott cselekvési terveket. Bemutatjuk, hogy a mondatszinten működő alapvető párbeszédpolitika jobb válaszokat generál a fordulószint generálásához képest, valamint a cselekvési terv nélküli alapvető modellekhez képest. Ezenkívül az alapvető párbeszédházirend további előnyökkel jár a vezérelhetőség.', 'ka': 'დიალოგის გახსნა დიალოგის სისტემის მისამართება შესაბამისი, ინფორმატიური და დაკავშირებელი პასუხების შექმნა. ამ დომენტში ჩვენ მინდომებით დიალოგის პოლიტიკის გამოყენება, საქმე პლანს გახსნა დიომენტის პარამეტრები, რომელსაც დიალოგის კონტექსტისთვის შესახებ ცნობიერი სიტყვები, მინიშვნელი დიალოგის მოქმედები, თემეტური ინფორმაცია, ანუ. აღმო ჩვენ განვიყენებთ ნეიროლური რეგენერაციის გენერაციის პლანზე, რომელიც შემდეგ გავიყენება, როგორც მინიშვნელოვანი სიტყვები და სიტყვების უფლებში. ჩვენ ასევე განსხვავებული დიალოგის პოლიტიკური მოდელების განსხვავება, რომელიც დიალოგის კონტექსტის აკეთება პლანეტის განსხვავება. ავტომატიური და ადამიანის განსაზღვრებით, ჩვენ განვითარებული პასუხების შესაძლებლობას გადაწყენებთ და დავწეროთ თუ მოდელები ნამდვილად ვისწავლოთ, რომ გავაგრძელოთ მიუთითებული მო ჩვენ ევმონსტრაცით, რომ ბაზულ დიალოგის პოლიტი, რომელიც მუშაობა სიტყვების დონეში უფრო უკეთესი პასუხი იქნება, რომელიც შემდგომარებული დონეზე დავიწყებთ დამატებით, ფონტური დიალოგის პოლიტიკაში კონტროლური შესაძლებლობას დამატებული გამოიყენება.', 'it': "I sistemi di dialogo open-domain mirano a generare risposte pertinenti, informative e coinvolgenti. In questo articolo, proponiamo di utilizzare una politica di dialogo per pianificare il contenuto e lo stile di destinazione, risposte a dominio aperto sotto forma di piano d'azione, che include frasi di conoscenza relative al contesto di dialogo, atti di dialogo mirati, informazioni sugli argomenti, ecc. Per la formazione, gli attributi all'interno del piano d'azione sono ottenuti annotando automaticamente il dataset Topical-Chat pubblicato pubblicamente. Condizioniamo i generatori di risposta neurale sul piano d'azione che viene poi realizzato come pronunciamenti target a livello di curva e frase. Esaminiamo anche diversi modelli di policy di dialogo per prevedere un piano d'azione dato il contesto di dialogo. Attraverso la valutazione automatizzata e umana, misuriamo l'adeguatezza delle risposte generate e controlliamo se i modelli di generazione imparano davvero a realizzare i piani d'azione indicati. Dimostriamo che una politica di dialogo di base che opera a livello di frase genera risposte migliori rispetto alla generazione di turni e ai modelli di base senza piano d'azione. Inoltre, la politica di dialogo di base ha il vantaggio aggiunto della controllabilità.", 'lt': 'Atviro domeno dialogo sistemomis siekiama sukurti atitinkamus, informacinius ir įtraukius atsakymus. Šiame dokumente siūlome naudoti dialogo politiką tikslo turinio ir stiliaus planavimui, atviros srities atsakymams veiksmų plano form a, kuriame pateikiami žinių sakiniai, susiję su dialogo kontekstu, tiksliniai dialogo aktai, tematinė informacija ir t. t. Mokymui veiksmų plano požymiai gaunami automatiškai anotuojant viešai paskelbtą teminių pokalbių duomenų rinkinį. Mes įtvirtiname neurologinio atsako generatorius veiksmų plane, kuris bus įgyvendintas kaip tikslinis išraiškas posūkio ir sakinio lygiu. Taip pat tiriame skirtingus dialogo politikos modelius, siekiant numatyti veiksmų plan ą atsižvelgiant į dialogo kontekstą. Atliekant automatizuotą ir žmogišką vertinimą vertiname sukauptų atsakų tinkamumą ir patikriname, ar kartos modeliai iš tikrųjų išmoko įgyvendinti konkrečius veiksmų planus. Mes įrodome, kad pagrindinė dialogo politika, veikianti sakinių lygiu, sukuria geresnius atsakymus, palyginti su lygio generavimu, taip pat bazinius modelius be veiksmų plano. Be to, pagrindinė dialogo politika turi papildomos kontroliuojamumo naudos.', 'kk': 'Доменді ашу диалог жүйелері қатынасыз, мәліметті және қатынасыз жауаптарды құру үшін мақсатты. Бұл қағазда, мақсатты мен стилін жоспарлау үшін диалог ережесін қолдануға, әрекеттің жауаптарын ашу планы ретінде, диалог контексті, мақсатты диалог әрекеттері, нақышты мәліметтері және т. б. бақылау үшін әрекеттің планы атрибуттары автоматты түрде шығарылған Topical- Chat Біз невралдық жауап жауап жасаушыларын әрекеттің планетасында, содан кейін мақсатты сөйлемелер мен сөйлемелер деңгейінде түсінуге болады. Сонымен қатар, диалогтың контексті көрсетілген әрекетті таңдау үшін әртүрлі диалог ережелер үлгілерін зерттейміз. Автоматты және адамдарды бағалау арқылы, жасалған жауаптардың адамдарының адамдарының адамдарының адамдарының адамдарының адамдарын өлшеп, құрылған үлгілердің келтірілген әрекеттердің пла Біз сұлбаның деңгейінде жұмыс істейтін негізгі диалог ережесі әрекетті жоспарламай деңгейіні құру үшін және негізгі үлгілер үлгілерін салыстырып жауап береді. Қосымша, негізгі диалог ережесі басқару мүмкіндігінің қосымша пайдасы бар.', 'mk': 'Системите за дијалог со отворен домен имаат за цел генерирање релевантни, информативни и вклучителни одговори. Во овој документ, предложуваме користење на дијалог политика за планирање на содржината и стилот на целта, отворени одговори на домените во форма на акционен план, кој вклучува реченици на знаење поврзани со дијалогот, дејства на дијалог со цел, информации за тема итн. За обука, атрибутите во рамките на акционниот план се добиваат автоматски анотирајќи Ние ги условуваме генераторите на нервен одговор на акциониот план кој потоа се реализира како целни изрази на нивото на свртување и реченица. Исто така истражуваме различни дијалошки модели за политика за предвидување на акционен план со оглед на дијалогот контекст. Through automated and human evaluation, we measure the appropriateness of the generated responses and check if the generation models indeed learn to realize the given action plans.  Демонстрираме дека основната дијалошка политика која функционира на нивото на речениците генерира подобри одговори во споредба со генерацијата на ниво, како и основните модели без акциски план. Покрај тоа, основната политика на дијалогот има додадена корист од контролативноста.', 'ml': 'പ്രധാനപ്പെട്ട, വിവരങ്ങള്\u200d ഉണ്ടാക്കുവാനും ഉത്തരങ്ങള്\u200d ചേര്\u200dക്കുവാനും ഉദ്ദേശിക്കുന്ന ഡൊമെയിന്\u200d ഡയലോഗ ഈ പത്രത്തില്\u200d, ലക്ഷ്യത്തിന്റെ ഉള്ളടക്കവും ശൈലിയും പദ്ധതിയും പ്ലാന്\u200d ചെയ്യാന്\u200d ഞങ്ങള്\u200d ഒരു ഡയലോഗ് പോളിസി ഉപയോഗിക്കുന്നു. ഒരു പ്ലാനില്\u200d തുറന്ന ഡൊമെയിന്\u200d ഉത്തരങ്ങള്\u200d ഉള്\u200dപ്പെടുന്നു. ഡയലോഗ് കെന്\u200dസ്റ്റ പ്രവര്\u200dത്തിപ്പിക്കുന്ന പ്ലാനിലെ ന്യൂറല്\u200d പ്രതികര്\u200dത്താക്കള്\u200d നമ്മുടെ അവസ്ഥ നിലനിര്\u200dത്തുന്നു. പിന്നീട് അതിന് വ്യത്യസ്ത ഡയലോഗ് പോളിസി മോഡലുകളും നമ്മള്\u200d അന്വേഷിക്കുന്നു. ഡയലോഗ് കെന്\u200dസ്റ്റോണ്\u200dട്ട് നല്\u200dകിയ ഒരു പ്ല സ്വയം നിര്\u200dമ്മിക്കപ്പെടുന്നതും മനുഷ്യരുടെ വിലയിലൂടെയും കൊണ്ട് നമ്മള്\u200d ഉല്\u200dപാദിച്ചതിന്\u200dറെ ഉത്തമവും അളന്നുകൊടുക്കുന്നു. തലമ വാക്ക് നിലയില്\u200d പ്രവര്\u200dത്തിക്കുന്ന ഒരു അടിസ്ഥാന ഡയലോഗ് പോളിസിക്ക് നല്ല ഉത്തരങ്ങള്\u200d ഉണ്ടാക്കുന്നു. നില തലമുറയും ബെസ്ലൈന്\u200d മോഡലുകള Additionally the basic dialog policy has the added benefit of controllability.', 'ms': 'Sistem dialog-domain terbuka bertujuan untuk menghasilkan balasan yang relevan, maklumat dan mempengaruhi. Dalam kertas ini, kami cadangkan menggunakan polisi dialog untuk merancang kandungan dan gaya sasaran, jawapan domain terbuka dalam bentuk rancangan tindakan, yang termasuk kalimat pengetahuan berkaitan dengan konteks dialog, tindakan dialog sasaran, maklumat topik, dll. Untuk latihan, atribut dalam rancangan tindakan dicapai secara automatik dengan anotasi set data Topical-Chat yang dibebaskan secara awam. We condition neural response generators on the action plan which is then realized as target utterances at the turn and sentence levels.  Kami juga menyelidiki model polisi dialog berbeza untuk meramalkan rancangan tindakan diberikan konteks dialog. Melalui penilaian automatik dan manusia, kita mengukur keperluan respon yang dijana dan periksa jika model generasi benar-benar belajar untuk menyadari rancangan tindakan yang diberikan. Kami menunjukkan bahawa kebijakan dialog as as yang berfungsi pada aras kalimat menghasilkan respon yang lebih baik dibandingkan untuk mengubah generasi aras serta model asas tanpa rancangan tindakan. Lagipun polisi dialog asas mempunyai keuntungan tambahan dari kawalan.', 'mt': 'Is-sistemi ta’ djalogu b’dominju miftuħ għandhom l-għan li jiġġeneraw reazzjonijiet rilevanti, informativi u involuti. F’dan id-dokument, qed nipproponu l-użu ta’ politika ta’ djalogu għall-ippjanar tal-kontenut u l-istil tal-mira, risposti miftuħa fid-dominju fil-forma ta’ pjan ta’ azzjoni, li jinkludi sentenzi ta’ għarfien relatati mal-kuntest tad-djalogu, atti ta’ djalogu mmirati, informazzjoni dwar is-suġġett, eċċ. Għat-taħriġ, l-attributi fil-pjan ta’ azzjoni jinkisbu billi jiġu annotati awtomatikament is-sett ta Aħna nikkundizzjonaw il-ġeneraturi tar-rispons newrali fuq il-pjan ta’ azzjoni li mbagħad jitwettaq bħala espressjonijiet fil-mira fil-livelli tad-dawra u tas-sentenza. Investigaw ukoll mudelli differenti ta’ politika ta’ djalogu biex nipprevedi pjan ta’ azzjoni fid-dawl tal-kuntest ta’ djalogu. Permezz ta’ evalwazzjoni awtomatizzata u umana, aħna nqisu l-adegwatezza tar-reazzjonijiet iġġenerati u niċċekkjaw jekk il-mudelli ta’ ġenerazzjoni tabilħaqq jitgħallmux iwettqu l-pjanijiet ta’ azzjoni mogħtija. Aħna nippruvaw li politika bażika ta’ djalogu li topera fil-livell tas-sentenza tiġġenera risposti a ħjar meta mqabbla mal-ġenerazzjoni tad-dawran tal-livell kif ukoll mudelli bażiċi mingħajr pjan ta’ azzjoni. Barra minn hekk, il-politika bażika tad-djalogu għandha l-benefiċċju miżjud tal-kontroll.', 'mn': 'Дэлхийн нээлттэй диалог системүүд хамааралтай, мэдээллийн болон хариултыг бий болгох зорилго юм. Энэ цаасан дээр бид зорилго болон хэлбэрийн тодорхойлолтыг төлөвлөхийн тулд диалог бодлогыг ашиглаж, үйл ажиллагааны төлөвлөгөөнд нээлттэй зорилго хариу өгүүлэх төлөвлөгөөний хэлбэрээр нээлттэй, диалог сэтгэл хөдлөл, сэдвийн мэдээллүүд, т.д. Бид мэдрэлийн хариу үйлдвэрлэх төлөвлөгөө дээр нөлөөлдөг. Тэгээд дараа нь өөрчлөлт болон өгүүлбэрийн түвшинд зориулагдсан хэлбэрүүдийг ойлгож болно. Мөн бид өөр диалог бодлогын загварыг судалж, диалог дахь үйл ажиллагааны төлөвлөгөөг таамаглах боломжтой. Автоматик болон хүн төрөлхтний үнэлгээгээр бид үүсгэсэн хариу үйлдвэрлэлийн тухай зөв байдлыг хэмжиж, үеийн загварууд өгөгдсөн үйлдвэрлэлийн төлөвлөгөөг ойлгох суралцдаг эсэхийг шалгаж Бид өгүүлбэрийн түвшинд ажилладаг үндсэн диалог бодлого нь хэмжээний түвшинд нь илүү сайн хариулт өгдөг. Төвшин үеийнх болон үйл ажиллагааны төлөвлөгөөгүй суурь шугам загваруудыг харьцуулахад ил Мөн үндсэн диалогын бодлого нь хяналт чадварын нэмэлт ашигтай.', 'ro': 'Sistemele de dialog open-domain vizează generarea de răspunsuri relevante, informative și interesante. În această lucrare, propunem utilizarea unei politici de dialog pentru a planifica conținutul și stilul țintei, răspunsurile domeniului deschis sub forma unui plan de acțiune, care include propoziții de cunoaștere legate de contextul dialogului, acte de dialog orientate, informații despre subiecte etc. Pentru formare, atributele din planul de acțiune sunt obținute prin adnotarea automată a setului de date Topical-Chat publicat. Condiționăm generatoarele de răspuns neural pe planul de acțiune care este apoi realizat ca rostiri țintă la nivelul de viraj și propoziție. De asemenea, investigăm diferite modele de politici de dialog pentru a prezice un plan de acțiune dat fiind contextul dialogului. Prin evaluarea automată și umană, măsurăm adecvarea răspunsurilor generate și verificăm dacă modelele de generație învață într-adevăr să realizeze planurile de acțiune date. Demonstrăm că o politică de dialog de bază care funcționează la nivelul propoziției generează răspunsuri mai bune în comparație cu generarea de nivel de turn, precum și modele de bază fără plan de acțiune. În plus, politica de dialog de bază are avantajul suplimentar al controlului.', 'sr': 'Sistemi dijaloga otvorenog domena imaju cilj da stvaraju relevantne, informativne i uključujuće odgovore. U ovom papiru predlažemo korištenje politike dijaloga kako bi planirali sadržaj i stil cilja, otvorene odgovore domena u obliku akcijskog plan a, koja uključuje znanje rečenice vezane za kontekst dijaloga, ciljane dijalogske akcije, informacije o temi itd. Za obuku, atributi unutar akcijskog plana dobijaju automatski annotirajući javno objavljenu setu podataka Topical-Chat. Stavljamo generatore neuroloških reakcija na akcijski plan koji se onda shvati kao ciljne reči na nivou okretanja i rečenica. Takođe istražujemo različite modele politike dijaloga kako bi predvidjeli akcijski plan s obzirom na kontekst dijaloga. Kroz automatsku i ljudsku procjenu, mjerimo pristojnost proizvedenih odgovora i provjerimo da li modeli generacije zaista nauče shvatiti određene akcije planove. Pokazujemo da osnovna politika dijaloga koja funkcioniše na nivou rečenice stvara bolji odgovor u usporedbi sa okrenutom generacijom nivoa, kao i početnim modelima bez akcijskog plan a. Osim toga, osnovna politika dijaloga ima dodatnu korist kontrolne sposobnosti.', 'pl': 'Systemy dialogowe otwarte domeny mają na celu generowanie istotnych, informacyjnych i angażujących odpowiedzi. W niniejszym artykule proponujemy zastosowanie polityki dialogowej do planowania treści i stylu odpowiedzi docelowych, otwartych domen w formie planu działania, który obejmuje zdania wiedzy związane z kontekstem dialogu, ukierunkowane akty dialogowe, informacje tematyczne itp. W przypadku szkolenia atrybuty w planie działania są uzyskiwane poprzez automatyczne adnotacje publicznie publikowanego zestawu danych Topical-Chat. Urządzamy generatory reakcji neuronowych na plan działania, który jest następnie realizowany jako wypowiedzi docelowe na poziomie skrętów i zdań. Badamy również różne modele polityki dialogowej, aby przewidzieć plan działania biorąc pod uwagę kontekst dialogu. Poprzez zautomatyzowaną i ludzką ocenę mierzymy adekwatność generowanych odpowiedzi i sprawdzamy, czy modele generacji rzeczywiście uczą się realizować dane plany działania. Pokazujemy, że podstawowa polityka dialogu działająca na poziomie zdań generuje lepsze reakcje w porównaniu z generowaniem poziomu obrotu oraz modelami bazowymi bez planu działania. Dodatkowo podstawowa polityka dialogowa ma dodatkową zaletę kontroli.', 'si': 'විවෘත සංවාදය පද්ධතිය සැකසුම් සම්බන්ධ, තොරතුරු සහ ප්\u200dරතික්\u200dරියාවක් නිර්මාණය කරන්න. මේ පැත්තේ, අපි සංවාදය ප්\u200dරයෝජනයක් භාවිත කරන්න ප්\u200dරයෝජනය කරනවා ලක්ෂණය සහ විස්තාරයක් සැලසුම් කරන්න, ක්\u200dරියාව සැලසුම් සැකසුමේ ප්\u200dරයෝජනය සඳහා දන්න සංවාදය සම්බන්ධ විදිහ අපි ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර සැලැස්මකට ස්ථාපනය කරනවා, ඊට පස්සේ ඉලක්ෂ ප්\u200dරතිචාර ප්\u200dරතිච අපි වගේම වෙනස් සංවාදය පොලිසි මෝඩල් පරීක්ෂා කරනවා සංවාදය සම්බන්ධයෙන් දෙන්න ක්\u200dරියාව ස ස්වයංක්\u200dරියාත්මක සහ මිනිස්සු විශ්වාසයෙන්, අපි නිර්මාණය කරපු ප්\u200dරතික්\u200dරියාවගේ අවස්ථාවක් පරීක්ෂා කරනවා සහ ප අපි ප්\u200dරකාශ කරනවා මූලික සංවාද ප්\u200dරතිස්ථාපනයක් වාර්තා කරනවා කියලා වාක්ෂාව ස්ථානයේ හොඳ උත්තර ප්\u200dරතිචාරයක් ස තවත් මූලික සංවාදය පාලනය තියෙනවා පාලනය කරන්න ප්\u200dරයෝජනය.', 'sv': 'Dialogsystem med öppen domän syftar till att generera relevanta, informativa och engagerande svar. I denna uppsats föreslår vi att man använder en dialogpolicy för att planera innehåll och stil för mål, öppna domänsvar i form av en handlingsplan, som inkluderar kunskapsmeningar relaterade till dialogsammanhang, riktade dialogakter, ämnesinformation, etc. För utbildning erhålls attributen i handlingsplanen genom att automatiskt kommentera den offentligt publicerade Topical-Chat datauppsättningen. Vi konditionerar neurala responsgeneratorer på handlingsplanen som sedan realiseras som måluttryck på sväng- och meningsnivå. Vi undersöker också olika dialogpolicymodeller för att förutsäga en handlingsplan med tanke på dialogsammanhang. Genom automatiserad och mänsklig utvärdering mäter vi lämpligheten av de genererade svaren och kontrollerar om generationsmodellerna verkligen lär sig att förverkliga de givna handlingsplanerna. Vi visar att en grundläggande dialogpolicy som fungerar på meningsnivå genererar bättre svar jämfört med turn level generation samt basmodeller utan handlingsplan. Dessutom har den grundläggande dialogprincipen den extra fördelen av kontrollerbarhet.', 'so': "nidaamka dialogka ee furan ee degmooyinka waxaa loogu talagalay in la sameeyo jawaabo la xiriira, macluumaad iyo ku habboon. Qoraalkan waxaynu ka soo jeedaynaa qoraal ku qoran qorshaha ku qoran waxyaabaha iyo qaabka goalka, ku qoran qorshaha waxqabashada, kaas oo ku qoran erayada aqoonta la xiriira qoraalka, falimaha diyaarinta, macluumaadka maadooyinka la jeedo, tusaale ahaan waxbarashada waxaa qorshaha waxqabashada lagu helaa si automatic ah oo lagu caddeeyo macluumaadka macluumaadka la bixiyo Topical-Chat. We condition neural response generators on the action plan which is then realized as target utterances at the turn and sentence levels.  Sidoo kale waxaynu baaritaan qaabab siyaasadeed oo kala duduwan si aan ugu hor tagno qorshaha waxqabadka oo la siiyey qorshaha dialogka. Qiimeynta iskaa loo gaaray iyo dadka, waxaynu qiyaasaynaa qiimeynta jawaabaha dhalay, waxaana hubinnaa in tusaalaha qarnigu ay ku bartaan inay ogaadaan qorshaha waxqabadka la siiyey. Waxaan muujinnaa in siyaasadda dialogka aasaasiga ah oo heerka ereyga ka shaqeeyo uu sameeyo jawaabo ka wanaagsan si barbarbarka u beddelo farshaxanka heerka iyo modelalka hoose oo aan qorshaha action lahayn. Sidoo kale siyaasadda dialogka aasaasiga ah waxaa ku jira faa'iido dheeraad ah oo ku saabsan awoodda la xiriira.", 'no': 'Opna domenedialogsystemet må laga relevant, informativ og engasjerande svar. I denne papiret foreslår vi å bruka eit dialogpolitikk for å planlegge innhaldet og stilen til mål, opna domenesvar i form av eit handlingsplan, som inneheld kjennesetningar som er relatert til dialogkonteksten, måltidige dialoghandlingar, emneformasjon osv. For opplæring blir attributtane i handlingsplanen fått ved automatisk oppmerking av datasettet som er publisert i Topical-Chat. Vi betyr generatorer for neuralsvar på handlingsplanen som så blir oppdaga som målsettingar på snu og setningsnivå. Vi undersøker også ulike dialogregelmodeller for å forhåndsvisa eit handlingsplan gjeven dialogkonteksten. Med automatisk og menneskelig evaluering måler vi tilpassigheten av dei genererte svara og kontrollere om generasjonsmodelane faktisk lærer å oppnå dei oppgjevne handlingsplanene. Vi viser at ein grunnleggjande dialogpolitikk som fungerer på setningsnivået gjer betre svar i sammenligning med å gjera nivågenerering og baselinjer med ingen handlingsplan. I tillegg har det grunnleggjande dialogpolitikken tilgjengeleg fordel av kontrollpolitikken.', 'ta': 'திறந்த டோமைன் உரையாடல் அமைப்புகள் தொடர்புடைய, தகவல் மற்றும் பதில்களை சேர்க்க வேண்டும் என்பதை உருவாக்குக இந்த காகிதத்தில், நாம் இலக்கு உள்ளடக்கத்தையும் பாணியையும் திட்டமைக்க ஒரு செயல் திட்டத்தில் திறந்த களத்தின் பதில்களையும் திட்டமைப்பதற்கான உரையாடல் கொள்கையையும், சேர்க்கப்பட்ட உரையாடல் செயல்கள், தல நாம் செயல் திட்டத்தில் நிலையான புதிய பதில் உருவாக்குபவர்கள் நிலைமை நிறுத்துகிறோம். பிறகு செயல் திட்டத்தில் ம நாம் வேறு வித்தியாசமான உரையாடல் கொள்கை மாதிரிகளை ஆராய்ச்சி செய்து உரையாடல் மூலம் கொடுக்கப்பட்ட ச தானியங்கி மற்றும் மனித மதிப்பின் மூலம், நாம் உருவாக்கப்பட்ட பதில்களின் சரியான மதிப்பை அளந்து கொள்கிறோம் மற்றும் உருவாக்கப்பட் வாக்கு நிலையில் செயல்படும் அடிப்படையான உரையாடல் கொள்கையை நாம் காட்டுகிறோம் என்றால் மட்டத்தின் உருவாக்கத்தையும் அடிப்படைக்க மேலும் அடிப்படையான உரையாடல் கொள்கையில் கட்டுப்பாட்டு சேர்க்கப்பட்ட பயன்பாடுகள் உள்ளது.', 'ur': 'کھولنے والی ڈومین ڈیلوگر سیسٹم کا ارتباط ہے، معلومات اور جواب حاصل کرنے کے لئے۔ اس کاغذ میں ہم ایک ڈالیٹ پولیس کے استعمال کرنے کے لئے پیشنهاد کرتے ہیں تاکید کے منصوبے اور استیل کے لئے، ایک کام پولیس کے شکل میں دامنی جواب دینے کے لئے کھول دیئے جاتے ہیں، جس میں سمجھانے کے منصوبے کے معاملات کا علم جمع ہوتا ہے، موقع دیalog عمل، موضوع معلومات، غیر اضافہ کیے جاتے ہیں. ترکینس کے لئے، اقدام پولیس کے ہم نے نیورال جواب جوڑانے والوں کو اس طرح کی تدبیر پر موجود رکھا ہے جو اس کے بعد ہدایت کلام کے طور پر متوجہ ہو جاتا ہے۔ ہم نے بھی مختلف ڈیلوگر پولیس موڈل کی تحقیق کریں کہ ڈیلوگر کے کنٹکس کے لئے ایک اقدام پلان کی پیش بینی کریں. ہم اپنے ساتھ اور انسان کی ارزیابی کے ذریعہ سے پیدا کئے ہوئے جواب کے مطابق اندازہ لیتے ہیں اور جان لیتے ہیں کہ آیا پیدا کئے ہوئے اقدام کے مطابق مطابق معلوم ہوتے ہیں؟ ہم دکھاتے ہیں کہ ایک بنیادی دیالوگ پولیس جو کلام سطح میں عمل کرتی ہے اس کے مقابلہ میں بہترین جواب دیتا ہے کہ سطح کی نسل کو تبدیل کرنے کے لئے اور بنیاس لین موڈل کو بدل دیتا ہے اور کسی کام کی تدبیر کے بغیر۔ اور زیادہ بنیادی ڈالیلوگ پولیس کنٹرول قابلیت کا فائدہ اضافہ کرتا ہے.', 'uz': "@ info Ushbu qogʻozda, биз targetning tarkibi va uslubini boshqarish uchun muloqat qoidadan foydalanishimiz talab qilamiz. Ushbu amalning tarkibi oynada ochiq domen javoblarini boshqarishimiz, muloqat muhit bilan bogʻliq maʼlumot soʻzlari, qanday muloqat amallari haqida maʼlumot yoʻnalishi mumkin. Biz ma'lum javob yaratuvchilar davomida holatda holatmiz. Keyin keyin bu so'zlarni o'zgartirish va maxfiy soʻzlarda qanday so'zlarni anglatadi. Biz boshqa dialog qoidasi modellarini tahrirlash uchun muloqat muvaffaqiyatli muloqat muvaffaqiyatlarini oldin. Through automated and human evaluation, we measure the appropriateness of the generated responses and check if the generation models indeed learn to realize the given action plans.  Biz so'zlar darajada ishlatadigan asosiy dialog qoidasi, darajaga yaratish va asosiy modellarni amalni boshqarish imkoniyatini yaratish mumkin. Qoʻshimcha oyna qoidasi boshqaruv qoidasi qoʻshilgan foydalanadi.", 'vi': 'Hệ thống hộp thoại mở miền nhằm tạo phản ứng liên quan, thông tin và hấp dẫn. Trong tờ giấy này, chúng tôi đề nghị sử dụng một chính sách hộp thoại để lên kế hoạch nội dung và kiểu của mục tiêu, phản ứng miền mở dưới dạng một kế hoạch hành động, gồm câu hỏi về ngữ cảnh hộp thoại, các hành động mục tiêu, các thông tin về chủ đề, v.v. Để đào tạo, các thuộc tính này sẽ được lấy bằng việc ghi chú các tập tin dữ liệu Topical-Chat công khai ra. Chúng tôi điều chỉnh các máy phát điện từ phản ứng thần kinh trong kế hoạch hành động sau đó được thực hiện như những lời nhắn đích thực tại tại mức án. Chúng tôi cũng điều tra các mô hình chính sách hộp thoại khác nhau để dự đoán một kế hoạch hành động dựa trên hộp thoại. Bằng ca đánh giá tự động và con người, chúng tôi đo lường sự phù hợp của các phản ứng đã tạo ra và kiểm tra xem các mô- đun đã học cách thực hiện các kế hoạch hành động. Chúng tôi chứng minh rằng một chính sách hộp thoại cơ bản hoạt động ở mức án tạo ra các phản ứng tốt hơn so với sản xuất cấp độ xoay cũng như các mô hình cơ bản không có kế hoạch hành động. Thêm vào đó chính sách hộp thoại cơ bản có lợi thêm của khả năng điều khiển.', 'bg': 'Диалоговите системи с отворен домейн имат за цел да генерират подходящи, информативни и ангажиращи отговори. В настоящата статия предлагаме използването на диалогова политика за планиране на съдържанието и стила на целевите отговори, отворени домейни под формата на план за действие, който включва изречения от знания, свързани с диалоговия контекст, целеви диалогови действия, тематична информация и др. За обучение атрибутите в плана за действие се получават чрез автоматично анотиране на публично публикувания набор от данни за тематичен чат. Конфигурираме генератори на невронни реакции в плана за действие, който след това се реализира като целеви изказвания на ниво завой и изречение. Също така изследваме различни модели на политика на диалога, за да предвидим план за действие предвид диалоговия контекст. Чрез автоматизирана и човешка оценка измерваме целесъобразността на генерираните отговори и проверяваме дали генерационните модели наистина се научават да реализират дадените планове за действие. Ние демонстрираме, че основна политика на диалогов диалог, която действа на ниво изречение, генерира по-добри отговори в сравнение с генерирането на нива на обръщане, както и базови модели без план за действие. Освен това основната политика на диалоговия прозорец има добавената полза от контролируемостта.', 'nl': 'Open-domein dialoogsystemen zijn gericht op het genereren van relevante, informatieve en boeiende reacties. In dit artikel stellen we voor om een dialoogbeleid te gebruiken om de inhoud en stijl van target, open domein reacties in de vorm van een actieplan te plannen, dat kenniszinnen bevat met betrekking tot de dialoogcontext, gerichte dialooghandelingen, onderwerp informatie, enz. Voor training worden de attributen binnen het actieplan verkregen door automatisch annoteren van de openbaar vrijgegeven Topical-Chat dataset. We conditioneren neurale responsgeneratoren op het actieplan dat vervolgens wordt gerealiseerd als doeluitingen op turn- en zinsniveau. We onderzoeken ook verschillende dialogbeleidsmodellen om een actieplan te voorspellen gezien de dialoogcontext. Door middel van geautomatiseerde en menselijke evaluatie meten we de geschiktheid van de gegenereerde reacties en controleren we of de generatiemodellen daadwerkelijk leren om de gegeven actieplannen te realiseren. We tonen aan dat een basisdialoogbeleid dat werkt op zinnenniveau betere reacties genereert in vergelijking met het genereren van draainiveaus en basismodellen zonder actieplan. Daarnaast heeft het basisdialoogbeleid het bijkomende voordeel van beheersbaarheid.', 'da': 'Dialogsystemer med åbent domæne sigter mod at generere relevante, informative og engagerende svar. I denne artikel foreslår vi, at der bruges en dialogpolitik til at planlægge indholdet og stilen på mål, åbne domænesvar i form af en handlingsplan, som indeholder videnssætninger relateret til dialogkonteksten, målrettede dialoghandlinger, emneoplysninger osv. Til træning opnås attributterne i handlingsplanen ved automatisk at notere det offentligt frigjorte Topical-Chat datasæt. Vi betinger neurale responsgeneratorer på handlingsplanen, som derefter realiseres som måludtalelser på sving- og sætningsniveauet. Vi undersøger også forskellige dialogpolitiske modeller for at forudsige en handlingsplan i betragtning af dialogkonteksten. Gennem automatiseret og menneskelig evaluering måler vi hensigtsmæssigheden af de genererede reaktioner og kontrollerer, om generationsmodellerne faktisk lærer at realisere de givne handlingsplaner. Vi demonstrerer, at en grundlæggende dialogpolitik, der fungerer på sætningsniveau, genererer bedre svar i forhold til turn level generation såvel som basismodeller uden handlingsplan. Desuden har den grundlæggende dialogpolitik den ekstra fordel af styrbarhed.', 'hr': 'Sistemi dijaloga otvorenog domena imaju cilj proizvesti relevantne, informativne i uključujuće odgovore. U ovom papiru predlažemo korištenje politike dijaloga kako bi planirali sadržaj i stil cilja, otvorene odgovore domena u obliku akcijskog plan a, uključujući znanje kazne vezane za kontekst dijaloga, ciljane dijalogske akcije, informacije o temi itd. Za obuku, atributi unutar akcijskog plana dobijaju automatski označavajući javno objavljenu setu podataka Topical-Chat. Zastavljamo generatore neuroloških odgovora na akcijski plan koji se onda shvati kao ciljne izreke na nivou okretanja i rečenica. Istražujemo i različite modele politike dijaloga kako bi predvidjeli akcijski plan s obzirom na kontekst dijaloga. Kroz automatsku i ljudsku procjenu, mjerimo pristojnost proizvedenih odgovora i provjerimo da li modeli generacije zaista uče shvatiti određene akcijske planove. Pokazujemo da osnovna politika dijaloga koja djeluje na razini rečenice stvara bolji odgovor u usporedbi s pretvaranjem generacije razine, kao i početne modele bez akcijskog plan a. Osim toga, osnovna politika dijaloga ima dodatnu korist kontrole.', 'de': 'Open-Domain-Dialogsysteme zielen darauf ab, relevante, informative und ansprechende Antworten zu generieren. In diesem Beitrag schlagen wir die Verwendung einer Dialogrichtlinie vor, um Inhalt und Stil von Ziel-, Open-Domain-Antworten in Form eines Aktionsplans zu planen, der Wissenssätze im Zusammenhang mit dem Dialogkontext, gezielte Dialoghandlungen, Themeninformationen usw. für Schulungen werden die Attribute innerhalb des Aktionsplans durch automatische Annotierung des öffentlich veröffentlichten Topical-Chat-Datensatzes erhalten. Wir konditionieren neuronale Reaktionsgeneratoren an den Aktionsplan, der dann als Zieläußerungen auf Turn- und Satzebene realisiert wird. Wir untersuchen auch verschiedene Dialogrichtlinienmodelle, um einen Aktionsplan unter Berücksichtigung des Dialogkontexts vorherzusagen. Durch automatisierte und menschliche Auswertung messen wir die Angemessenheit der generierten Antworten und prüfen, ob die Generationsmodelle tatsächlich lernen, die vorgegebenen Aktionspläne zu realisieren. Wir zeigen, dass eine grundlegende Dialogrichtlinie, die auf Satzebene funktioniert, bessere Reaktionen generiert im Vergleich zur Turn-Level-Generierung sowie zu Baseline-Modellen ohne Aktionsplan. Zusätzlich bietet die grundlegende Dialogrichtlinie den zusätzlichen Vorteil der Steuerbarkeit.', 'id': 'Sistem dialog-domain terbuka bermaksud untuk menghasilkan respon yang relevan, informatif dan menarik. Dalam kertas ini, kami mengusulkan menggunakan kebijakan dialog untuk merencanakan isi dan gaya sasaran, respons domain terbuka dalam bentuk rencana aksi, yang termasuk kalimat pengetahuan berkaitan dengan konteks dialog, tindakan dialog bertujuan, informasi topik, dll. Untuk latihan, atribut dalam rencana aksi diperoleh dengan otomatis anotasi dataset Topical-Chat yang terbuka secara publik. Kami kondisi generator respon saraf pada rencana aksi yang kemudian direalisasikan sebagai target utterance pada tingkat putaran dan kalimat. We also investigate different dialog policy models to predict an action plan given the dialog context.  Melalui evaluasi otomatis dan manusia, kita mengukur keperluan reaksi yang dihasilkan dan memeriksa apakah model generasi benar-benar belajar untuk menyadari rencana tindakan yang diberikan. Kami menunjukkan bahwa kebijakan dialog dasar yang beroperasi di tingkat kalimat menghasilkan respon yang lebih baik dibandingkan untuk mengubah generasi tingkat serta model dasar tanpa rencana tindakan. Lagipula kebijakan dialog dasar memiliki manfaat tambahan dari pengendalian.', 'fa': 'سیستم محاورۀ محاورۀ باز دامین هدف برای تولید پاسخهای مربوط، اطلاعات و مشترک است. در این کاغذ، ما پیشنهاد می\u200cدهیم که از یک سیاست محاورۀ محاورۀ و طرح هدف برنامه ریزی کنیم، پاسخ\u200cهای دامنۀ باز در شکل نقشه\u200cی حرکت، که شامل جمله\u200cهای محاورۀ علم مربوط به محیط محاورۀ محاورۀ محاورۀ محاورۀ محاورۀ محاورۀ هدف، اطلاعات موضوع و غیر از آن باشد.  ما ژنراتورهای پاسخ عصبی را بر روی نقشه اقدام قرار می دهیم که بعدش به عنوان کلمات هدف در سطح تبدیل و جمله متوجه می شود. ما همچنین مدل\u200cهای سیاسی محاورۀ مختلف را تحقیق می\u200cکنیم تا نقشه\u200cی حرکت را پیش\u200cبینی کنیم که در محاورۀ محاورۀ محاورۀ محاورۀ محاورۀ محاو از طریق ارزیابی خودکار و انسان، ما مناسب پاسخ\u200cهای تولید را اندازه می\u200cگیریم و بررسی می\u200cکنیم که آیا مدل\u200cهای نسل واقعاً برنامه\u200cهای عمل را درک می\u200cکنند. ما نشان می دهیم که یک سیاست محاورۀ بنیادی که در سطح محاورۀ عمل می کند، پاسخهای بهتر در مقایسه با تبدیل به نسل سطح و مدل\u200cهای بنیادی بدون نقشه اقدام تولید می\u200cکند. علاوه بر این، سیاست بنیادی گفتگو سود کنترل اضافه شده است.', 'ko': '개방 분야 대화 시스템은 관련 정보가 풍부하고 매력적인 응답을 하기 위한 것이다.본고에서 우리는 대화 전략을 사용하여 행동 계획의 형식으로 목표, 개방역 응답의 내용과 스타일을 기획하는 것을 권장한다. 대화 상하문, 목표 대화 행위, 주제 정보 등과 관련된 지식 문장을 포함한다. 교육에 있어 행동 계획의 속성은 자동으로 주석을 달아 공개적으로 발표된 주제 채팅 데이터 집합을 통해 얻어진다.우리는 행동 계획에 신경반응 발생기를 설치한 후 라운드와 문장 차원에서 이를 목표 언어로 실현한다.우리는 또 서로 다른 대화 전략 모델을 연구하여 대화의 상하문에 대한 행동 계획을 예측했다.자동화와 인공 평가를 통해 우리는 생성 응답의 적절성을 평가하고 생성 모델이 주어진 행동 계획을 실현하는 것을 배웠는지 검사한다.우리는 문장 차원에서 운행되는 기본적인 대화 전략이 화륜 차원에서의 생성과 행동 계획이 없는 기선 모델에 비해 더욱 좋은 호응을 얻을 수 있음을 증명했다.이 밖에 기본적인 대화 전략은 통제할 수 있는 추가적인 장점도 가지고 있다.', 'sw': 'Mfumo wa mazungumzo ya ndani unalenga kutengeneza masuala yanayohusika, taarifa na kujihusisha. Katika karatasi hii, tunapendekeza kutumia sera ya mazungumzo ili kupanga maudhui na mitindo ya malengo, mipango ya wazi ya ndani katika mpango wa action, ambayo inajumuisha sentensi za maarifa zinazohusiana na mazungumzo ya mazungumzo, matendo ya mazungumzo yanayolengwa, taarifa za mada, etc. Kwa mafunzo, vigogo vya ndani ya mpango wa action vinapatikana kwa kutumia taarifa za habari zilizotolewa wazi za Mazungumzo ya Kimasomo. Tunakuwa na mazingira ya majibu ya kiserikali kuhusu mpango wa hatua ambao baadae unagundua kuwa lugha zinazolenga katika ngazi za geuzi na hukumu. Pia tunachunguza mbinu tofauti za sera za mazungumzo ili kutabiri mpango wa hatua uliofanywa na muktadha wa mazungumzo. Through automated and human evaluation, we measure the appropriateness of the generated responses and check if the generation models indeed learn to realize the given action plans.  Tunaonyesha kuwa sera ya mazungumzo ya msingi inayofanya kazi katika ngazi ya hukumu inaleta miitikio bora kwa kulinganisha kizazi cha ngazi pamoja na mifano ya msingi bila mpango wa hatua. Zaidi ya hayo sera ya msingi ya mazungumzo inaongezeka faida ya udhibiti.', 'tr': 'Aç-domena düzenlemesi gerekli, bilgili ve sorgulama oluşturmak amaçları. Bu kagyzda, biz maýdanyň maksady we stilini planlamak üçin bir dialogdan ullanmagy teklip edip, eylem planynyň şeklinde a ç domenyň jogaplaryny barlamak üçin bir dialog duşuşygy, maksady dialogdan geçirilen sözleri, meýdança maglumatlary we bölegi barlanýar Biz neural jogabat jeneratörlerini eylem planynda saýlaýarlar. Şol soňra sözleriň sözleriň derejesi we maksady diýip kabul edilen noktadyr. Biz hem başga dürli dialog politika nusgalaryny diýip barýarys. Otomatik we insan değerlendirmeleri bilen, üretilen cevaplaryň uyumluluğunu ölçüp, değerlendirilen modellerinin hakykatdanam berilen eylemler planlarını çözmeyi öğrenip bilmedigini kontrol ediyoruz. Biz sözleriň derejesinde işleýän temel dialogyň politikasynyň derejesi ýok jogaplary düzenlemek üçin derejesi döretmäge deň derejesi we eylem plany bolmadyk basit nusgalary döretýäris. Esasy dialogdan hem zady kontrol edip biljek üçin eklendir.', 'sq': 'Sistemet e dialogut të dominiu të hapur synojnë të gjenerojnë përgjigje të rëndësishme, informative dhe përfshirëse. Në këtë letër, propozojmë përdorimin e një politike dialogu për të planifikuar përmbajtjen dhe stilin e objektivit, përgjigjet e hapura të domenit në form ën e një plani veprimi, i cili përfshin fjalimet e njohurive lidhur me kontekstin e dialogut, veprimet e dialogut të caktuara, informacionin tematik, etj. Për trajnimin, atributet brenda planit veprimi janë të fituar duke anotuar automatikisht të dhënat e lëshuara publikisht Topical-Chat Ne kushtojmë gjeneratorët e përgjigjes nervore në planin e veprimit që pastaj realizohet si fjalim objektiv në nivelet e kthesës dhe fjalimit. Ne gjithashtu hetojmë modele të ndryshme të politikës së dialogut për të parashikuar një plan veprimi duke marrë parasysh kontekstin e dialogut. Nëpërmjet vlerësimit të automatizuar dhe njerëzor, ne matëm përshtatjen e përgjigjeve të gjeneruara dhe kontrollojmë nëse modelet e gjeneratës mësojnë të realizojnë planet e dhëna të veprimit. Ne demonstrojmë se një politikë bazë dialogu që funksionon në nivelin e fjalimit gjeneron përgjigje më të mira në krahasim me gjenerimin e nivelit të kthehet si dhe modelet bazë pa plan veprimi. Përveç kësaj, politika bazë e dialogut ka përfitimin e shtuar të kontrollueshmërisë.', 'am': 'አዲስ ዶሴ ፍጠር In this paper, we propose using a dialog policy to plan the content and style of target, open domain responses in the form of an action plan, which includes knowledge sentences related to the dialog context, targeted dialog acts, topic information, etc. For training, the attributes within the action plan are obtained by automatically annotating the publicly released Topical-Chat dataset.  የጠቅላላ መልስ አዳራጊዎችን በጥያቄ ፕላን ላይ እናስገራለን፡፡ የጥያቄ ፕሮግራሙን ለመጠየቅ የተለያየ የጥያቄ ፖሊሲ ምሳሌዎችን እናምርመራለን፡፡ በአካባቢ እና በሰው ማስታወቂያ፣ የፍጥረት መልስ አዋቂውን እናስመስላለን እናስታውቃለን፡፡ አዲስ የደረጃ ትውልድ እና የደረጃ ትውልድ እና ጥያቄ ፕሮግራም ሳይኖር የመስመር ጥያቄ የሚሠራ የሥልጣን ጥያቄ ፖለቲካ እንዲያሳየው እናሳያልን፡፡ በተጨማሪም ጥያቄ የጥያቄ ጥቅማቸው ነው፡፡', 'af': "Open- domain dialoog stelsels doel om relevant, informatiewe en geantwoordes te genereer. In hierdie papier, ons voorstel om 'n dialoog beleid te gebruik om die inhoud en styl van doel te planeer, oop domein reaksies in die vorm van 'n aksie plan, wat insluit kennis setinge verwante met die dialoog konteks, doel dialoog aktiwiteite, onderwerp inligting, ens. Vir onderwerp, word die eienskappe binne die aksie plan ontvang deur outomaties die publiek verlossing van Topical-Chat data Ons bevestig neurale antwoord genereerders op die aksie plan wat dan as doel uitspraak by die draai en sentence vlakke is bevestig. Ons ondersoek ook verskillende dialoog beleidmodel om 'n aksie plan te voorskou wat die dialoog konteks gegee het. Deur outomatiese en menslike evaluasie, maak ons die toepassing van die genereerde reaksies en kontroleer of die generasie modele sekerlik leer om die gegewe aksie planne te bevestig. Ons wys dat 'n basiese dialoog beleid wat op die setvlak werk, beter antwoordes genereer in vergelyking om vlak generasie te skakel en baselyn modelle te skakel met geen aksie plan nie. Additionally the basic dialog policy has the added benefit of controllability.", 'hy': 'Բաց բնագավառի հաղորդակցման համակարգերը նպատակով են ստեղծել հարմար, ինֆորմատիվ և ներգրավող պատասխաններ: Այս թղթի մեջ մենք առաջարկում ենք օգտագործել դասախոսության քաղաքականություն, որպեսզի պլանավորենք նպատակի բովանդակությունը և ոճը, բաց դասախոսությունները գործողության պլանի ձևով, որը ներառում է գիտելիքների նախադասություններ, որոնք կապված են դասախոսության կոնտեքստին, նպատակային դասախոսությունների գործողություններին, թեմային տեղեկատվությունը և այլն: Ար Մենք նյարդային արձագանքի գեներատորները պայմանավորում ենք գործողության պլանի վրա, որը հետո իրականացվում է որպես նպատակային արտահայտություններ շրջանակի և նախադասության մակարդակում: Մենք նաև ուսումնասիրում ենք տարբեր դասախոսության քաղաքականության մոդելներ, որպեսզի կանխատեսենք գործողության պլանը, հաշվի առնելով դասախոսության կոնտեքստը: Ավտոմատիկ և մարդկային գնահատման միջոցով մենք չափում ենք ստեղծված արձագանքների համապատասխանությունը և ստուգում ենք, արդյոք սերնդի մոդելները իսկապես սովորում են իրականացնել տվյալ գործողության պլանները: Մենք ցույց ենք տալիս, որ նախադասությունների մակարդակում գործող հիմնական պատմության քաղաքականությունը ավելի լավ պատասխաններ է ստեղծում, համեմատելով մակարդակի սերունդը, ինչպես նաև հիմնական մոդելները առանց գործողության պլանի: Ավելին, հիմնական հաղորդակցման քաղաքականությունը ունի վերահսկողականության ավելացված առավելություն:', 'bn': 'খোলা ডোমেইন ডায়ালগ সিস্টেমের উদ্দেশ্য হচ্ছে প্রযুক্ত, তথ্য এবং প্রতিক্রিয়া তৈরি করার জন্য। এই কাগজটিতে আমরা টার্গেটের বিষয়বস্তু এবং ধরনের পরিকল্পনা করার জন্য একটি ডায়ালগ নীতি ব্যবহার করার প্রস্তাব প্রস্তাব করি, একটি কাজ পরিকল্পনার মাধ্যমে খোলা ডোমেইন প্রতিক্রিয়া প্রস্তাব করি, যার মধ্যে ডায়ালগের প্রেক্ আমরা নিউরেল প্রতিক্রিয়া জেনারেটরা এই প্ল্যানের ব্যাপারে পরিস্থিতি জানাচ্ছি যা পরিবর্তন এবং শাস্তি পর্যায়ে গুর এছাড়াও আমরা বিভিন্ন ডায়ালগ নীতির মডেল অনুসন্ধান করি যাতে ডায়ালগের প্রেক্ষাপট প্রদান করা একটি কার্যকলাপ স্বয়ংক্রিয়ভাবে এবং মানুষের মূল্যের মাধ্যমে আমরা প্রজন্মের প্রতিক্রিয়ার মূল্য পরিমাপ করি এবং পরীক্ষা করি প্রজন্মের মডেল কি সত্ আমরা দেখাচ্ছি যে একটি মৌলিক ডায়ালগ নীতি যা বাক্য স্তরে কাজ করে তার তুলনায় স্তরের প্রজন্ম এবং বেসালাইন মডেলের সাথে কোন কাজ পরিকল্পনা নেই,  এছাড়াও মৌলিক ডায়ালগ নীতি নিয়ন্ত্রণের সুবিধা প্রদান করেছে।', 'ca': "Els sistemes de diàleg de domini obert tenen l'objectiu de generar respostes relevants, informatives i atractives. En aquest paper, proposem utilitzar una política de diàleg per planificar el contingut i l'estil de respostes de domini oberts en form a de pla d'acció, que inclou frases de coneixement relacionades amb el context de diàleg, actes de diàleg destinats, informació sobre tema, etc. Per a formar, els atributs del pla d'acció es obtienen anotant automàticament el conjunt de dades publicat Topical-Chat. Condicionem els generadors de resposta neuronal en el pla d'acció que es concretiza després com a expressions d'objectiu a nivells de gir i frase. També investigam diferents models de política de diàleg per predir un pla d'acció en el context del diàleg. A través d'una evaluació automatitzada i humana, mesurem l'apropiació de les respostes generades i compruem si els models de generació aprenen a concretizar els planes d'acció dados. Demonstrem que una política de diàleg bàsica que funciona a nivell de frases genera millors respostes en comparació amb la generació de nivell de gir i els models de base sense cap pla d'acció. A més, la política de diàleg bàsic té el benefici adicionat de la controlabilitat.", 'cs': 'Otevřené dialogové systémy mají za cíl generovat relevantní, informativní a poutavé odpovědi. V tomto článku navrhujeme použití dialogové politiky k plánování obsahu a stylu cílových odpovědí, otevřených domén ve formě akčního plánu, který zahrnuje znalostní věty související s kontextem dialogu, cílené dialogové akce, informace o tématech apod. Pro školení jsou atributy akčního plánu získány automatickým anotováním veřejně zveřejněné datové sady Topical-Chat. Generátory nervové odezvy upravujeme na akční plán, který je pak realizován jako cílové výroky na úrovni otočení a věty. Dále zkoumáme různé modely dialogových politik, abychom předpověděli akční plán vzhledem k kontextu dialogu. Prostřednictvím automatizovaného a lidského hodnocení měříme vhodnost generovaných reakcí a kontrolujeme, zda se generační modely skutečně naučí realizovat dané akční plány. Ukážeme, že základní dialogová politika, která funguje na úrovni věty, generuje lepší reakce ve srovnání s generováním úrovně otočení a modely základního základního plánu bez akčního plánu. Kromě toho má základní zásada dialogu další výhodu ovladatelnosti.', 'bs': 'Sistemi dijaloga otvorenog domena ciljaju da stvore relevantne, informativne i uključujuće odgovore. U ovom papiru predlažemo korištenje politike dijaloga kako bi planirali sadržaj i stil cilja, otvorene odgovore domena u obliku akcijskog plan a, koja uključuje znanje rečenice vezane sa kontekstom dijaloga, ciljanim dijalogskim aktovima, informacijama o temi itd. Za obuku, atributi unutar akcijskog plana dobijaju automatski annotirajući javno objavljenu setu podataka Topical-Chat. Mi stavljamo generatore neuroloških reakcija na akcijski plan koji se onda shvati kao ciljni izraz na nivou okretanja i rečenica. Također istražujemo različite modele politike dijaloga kako bi predvidjeli plan akcije s obzirom na kontekst dijaloga. Kroz automatsku i ljudsku procjenu, mjerimo pristojnost proizvedenih odgovora i provjerimo da li modeli generacije zaista nauče shvatiti određene akcije planove. Pokazujemo da osnovna politika dijaloga koja djeluje na razini rečenice stvara bolji odgovor u usporedbi s pretvaranjem generacije nivoa, kao i početnih modela bez akcijskog plan a. Osim toga, osnovna politika dijaloga ima dodatnu korist kontrolabilnosti.', 'et': 'Avatud domeeni dialoogisüsteemide eesmärk on luua asjakohaseid, informatiivseid ja kaasavaid vastuseid. Käesolevas töös pakume välja dialoogipoliitika kasutamise eesmärgi sisu ja stiili planeerimiseks, avatud domeeni vastused tegevuskava kujul, mis sisaldab dialoogi kontekstiga seotud teadmisi lauseid, sihipäraseid dialoogiatoiminguid, teemateavet jne. Koolituse jaoks saadakse tegevuskava atribuudid automaatselt avaldatud teemavestluse andmekogumi märgistamisega. Konfigureerime närvireaktsiooni generaatorid tegevuskavale, mis realiseeritakse siis sihtväljenditena pöörde- ja lausetasemel. Samuti uurime erinevaid dialoogipoliitika mudeleid, et prognoosida dialoogi kontekstis tegevuskava. Automatiseeritud ja inimliku hindamise kaudu mõõdame genereeritud vastuste sobivust ja kontrollime, kas generatsioonimudelid õpivad tõepoolest ellu viima antud tegevuskavasid. Näitame, et lausetasemel toimiv põhiline dialoogipoliitika annab paremaid vastuseid võrreldes pöördtaseme genereerimisega ja tegevuskavata baasmudelitega. Lisaks on dialoogipoliitika põhiline eelis kontrollitavus.', 'az': 'Açıq-domena dialogu sistemləri məlumatlı, informativ və işarə ilə cavab vermək məqsədilə məşğul olacaq. Bu kağızda, məlumatı və tarzını planlamaq üçün dijalog siyasətini istifadə etmək üçün təklif edirik, a çıq domena cavablarını bir eylemi plan ı formasında açar, bu da Dialog məlumatı, məlumatı diyalələri, məlumatı məlumatı və ya da məlumatı barəsindəki bilim cümlələri, məlumatı məlumatı və ya. təhsil üçün, eylemi planının xüsusiyyətləri avtomatik olaraq açı Biz nöral reaksiya generatörlərini hərəkət plan ına təsdiqləyirik. Sonra sözlərin səviyyələrində məqsəd sözləri olaraq təsdiqlənirik. Biz də müxtəlif dialoğu siyasi modellərini araşdırdıq ki, dialoğu məlumatlarına verilən eyni plan ı təmin edək. Avtomatik və insan değerlendirməsi vasitəsilə, biz yaratdığımız cavabların uyğunluğunu ölçürük və nəsil modellərinin verilmiş işlər planlarını anlamağı öyrəndiyini kontrol edirik. Biz göstəririk ki, cümlənin səviyyəsində işlədiyi temel dialoğu siyasəti həmçin in səviyyədə səviyyə nəsillərini və hərəkət plan ı olmayan səviyyədə daha yaxşı cavab verər. Əvvəlcə temel dialoq siyasası kontrol qabiliyyətinin faydası var.', 'fi': 'Avoimen verkkotunnuksen dialogijärjestelmät pyrkivät luomaan relevantteja, informatiivisia ja mukaansatempaavia vastauksia. Tässä artikkelissa ehdotamme dialogipolitiikkaa kohdesisällön ja tyylin suunnitteluun, avoimen verkkotunnuksen vastauksia toimintasuunnitelman muodossa, joka sisältää dialogin kontekstiin liittyviä tietolauseita, kohdennettuja dialogitoimintoja, aihetietoja jne. Koulutusta varten toimintasuunnitelman attribuutit saadaan automaattisesti merkitsemällä julkisesti julkaistua Topical-Chat -aineistoa. Kontrolloimme neurovastegeneraattorit toimintasuunnitelmaan, joka toteutuu kohdelauseina käännös- ja lausetasolla. Tutkimme myös erilaisia dialogipolitiikkamalleja, joilla voidaan ennustaa toimintasuunnitelmaa dialogin kontekstissa. Automatisoidun ja inhimillisen arvioinnin avulla mitataan tuotettujen vastausten asianmukaisuutta ja tarkistetaan, oppivatko generaatiomallit todella toteuttamaan annetut toimintasuunnitelmat. Osoitamme, että lausetasolla toimiva perusdialogipolitiikka tuottaa parempia vastauksia verrattuna käännöstason luomiseen sekä perusmalleihin, joilla ei ole toimintasuunnitelmaa. Lisäksi perusvalintaikkunan käytäntöön on lisätty hallittavuus.', 'jv': 'Open-domain dialog sistem goal to Genere Relative, informaative and engaging responses. In this paper, we proposal use a dialog policy to design the Contents and style of goal, open domain responses in the format of an action scheme, that include knowings words connected to the dialog context, goal dialog action, Subject information, msg. For tutorial, the attributs in the action scheme are available by automatically anntating the Publical-Talk dataset. Awakdhéwé éntuk oleh operasi alat sing nganggo perusahaan anyar mên iki dadi, kita nguasai tanggal sing dirampakan lan tambah kuwi nggawe Awakdhéwé énujuhé model sing sampeyan dialog kanggo uréng aksi nggawe dialog Dhewe kalah-sistem sing berarti karo perbudhakan langgar sampeyan nguasai perbudhakan karo nggawe barang nggawe barang nggawe barang manut Awak dhéwé éntukno sistem dialog sing diangkat sing wis ana ing dadi aturan sing luwih dumadhi karo nggawe barang sing luwih dumadhi kanggo nggantgantgantané teka kalih-sangan ngono model sing basa sing ora oleh tur aksi sing apik. dialog-title', 'sk': 'Cilj pogovornih sistemov odprtega domena je ustvarjanje ustreznih, informativnih in privlačnih odzivov. V tem prispevku predlagamo uporabo politike dialoga za načrtovanje vsebine in sloga cilja, odgovorov odprte domene v obliki akcijskega načrta, ki vključuje znanje stavkov, povezanih s pogovornim kontekstom, ciljne dialogne akte, tematske informacije itd. Za usposabljanje se atributi akcijskega načrta pridobijo s samodejnim označevanjem javno objavljenega nabora podatkov o tematskem klepetu. Generatorje nevronskega odziva prilagajamo na akcijski načrt, ki se nato uresniči kot ciljni izgovori na nivoju obrata in stavka. Prav tako raziskujemo različne modele politike dialoga za napovedovanje akcijskega načrta glede na dialog kontekst. Z avtomatiziranim in človeškim vrednotenjem merimo ustreznost ustvarjenih odzivov in preverimo, ali se generacijski modeli resnično naučijo uresničiti dane akcijske načrte. Pokazali smo, da osnovna politika dialoga, ki deluje na ravni stavka, ustvarja boljše odzive v primerjavi z generacijo ravni obratov in osnovnimi modeli brez akcijskega načrta. Poleg tega ima osnovni pravilnik pogovornega okna dodano prednost nadzora.', 'ha': "@ action: button Daga cikin wannan takardan, muna buɗa mu yi amfani da wata kalma na zauren akwatin bayani don ka ƙayyade tsarin maɓallin akwatin tagan, ana buɗe masu karɓar guda cikin shirin akwatin aiki, wanda yana ƙunsa da maganar ilmi masu husũma da mazaɓan akwatin bayani, da takardan zauren akwatin bayanin da aka yi amfani da, da maɓallin akwatin bayani, da kuma da tsarin maɓallin akwatin aiki, za'a mottar da su ƙayyade kayan aiki fara Mu ƙayyade wajen ajiya na neura kan shirin action which is then an gane shi as goani ga maganar da za'a danne shi. Ko kuma munã ƙidãya misãlai masu cikin zauren akwatin bayani don ka ƙayyade wani shirin aiki wanda aka bai wa mazaɓan zauren akwatin bayani. Ina iya ƙayyade shirin mutum farat ɗaya da mutum, sai mu ƙaddara iyakar ajirar da aka ƙãga, kuma ka dũba idan misalin ƙarin za'a iya fahimta shirin aiki. We demonstrate that a basic dialog policy that operates at the sentence level generates better responses in comparison to turn level generation as well as baseline models with no action plan.  Furan wata, wata na'urar zauren akwatin bayani na ƙari yana da amfani da kanana kanana.", 'he': 'מערכות דיאלוג בתחום פתוח מכוונות לייצר תשובות רלוונטיות, מידעיות ומעניינות. בעיתון הזה, אנו מציעים להשתמש במדיניות דיאלוג כדי לתכנן את התוכן וסגנון של המטרה, תגובות שטח פתוחות בצורה של תוכנית פעולה, שכוללת משפטי ידע קשורים לקשר הדיולוג, פעולות דיאלוג מיועדים, מידע נושא וכו. עבור האימונים, התכונות בתוך תוכנית הפעולה ניתנות על ידי הערות אוטומטית על קבוצת נתונים של השיחה הנ We condition neural response generators on the action plan which is then realized as target utterances at the turn and sentence levels.  אנחנו חוקרים גם מודלים מדיניות דיאלוג שונים כדי לחזות תוכנית פעולה בהתחשב בקשר לדיולוג. באמצעות הערכה אוטומטית ואנושית, אנחנו ממדידים את התאימות של התגובות המיוצרות ולבדוק אם דוגמני הדור באמת לומדים להבין את תוכניות הפעולה הנתונות. We demonstrate that a basic dialog policy that operates at the sentence level generates better responses in comparison to turn level generation as well as baseline models with no action plan.  בנוסף, למדיניות הדיולוג הבסיסית יש יתרון מווסף של יכולת שליטה.', 'bo': 'Open-domain dialog systems aim to generate relevant, informative and engaging responses. In this paper, we propose using a dialog policy to plan the content and style of target, open domain responses in the form of an action plan, which includes knowledge sentences related to the dialog context, targeted dialog acts, topic information, etc. For training, the attributes within the action plan are obtained by automatically annotating the publicly released Topical-Chat dataset. ང་ཚོས་བྱ་འགུལ་གྱི་གྲོས་མཐུད་སྒོ་འབྱེད་ཀྱི་ནུས་པ་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ཀྱང་བྱ་འགུལ རང་འགུལ་གྱིས་དང་མི་རིགས་གྱིས་དཔྱད་ཡོད་པ་ལས། ང་ཚོས་རང་བཞིན་གྱིས་ཡོད་པའི་ལན་གསལ་བཤད་ཀྱི་འོང་ཚད་དང་ལྟ་ཞིབ་བྱེད་དགོས་མི ང་ཚོས་ཚིག རྨང་གཞི་གླེང་སྒྲོམ་གྱི་ཐབས་ལམ་དེ་ལ་ཚད་འཛིན་སྟངས་ཀྱི་ཁྱད་ཆོས་ཁ་སྐོང་ཡོད།'}
