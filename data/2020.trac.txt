{'en': 'Aggression Identification in  Social Media  : a Transfer Learning Based Approach', 'ar': 'تحديد العدوان في وسائل التواصل الاجتماعي: نهج قائم على التعلم', 'pt': 'Identificação de Agressão nas Mídias Sociais: uma Abordagem Baseada em Transferência de Aprendizagem', 'fr': "Identification de l'agression dans les médias sociaux\xa0: une approche basée sur l'apprentissage par transfert", 'es': 'Identificación de agresiones en las redes sociales: un enfoque basado en el aprendizaje de transferencia', 'ja': 'ソーシャルメディアにおける攻撃性の特定：転送学習ベースのアプローチ', 'zh': '社交媒体之攻击性识:一基于迁学', 'hi': 'सामाजिक मीडिया में आक्रामकता पहचान: एक स्थानांतरण सीखने के आधार पर दृष्टिकोण', 'ru': 'Идентификация агрессии в социальных сетях: подход, основанный на обучении передаче', 'ga': 'Aitheantas Ionsaithe sna Meáin Shóisialta: Cur Chuige Aistrithe Bunaithe ar Fhoghlaim', 'el': 'Αναγνώριση επιθετικότητας στα μέσα κοινωνικής δικτύωσης: μια προσέγγιση βασισμένη στη μάθηση μεταφοράς', 'hu': 'Aggressziós azonosítás a közösségi médiában: transzfer tanulás alapú megközelítés', 'ka': 'სოციალური მედიაში ადგრესიის იდენტიფიკაცია: Transfer Learning Based Approach', 'it': "Identificazione dell'aggressività nei social media: un approccio basato sull'apprendimento del trasferimento", 'kk': 'Америкалық медиақтағы сәйкестік идентификациясы: аудару оқыту негізінде қатынау', 'lt': 'Social in ės žiniasklaidos agresijos identifikavimas: mokymosi perdavimu grindžiamas metodas', 'mk': 'Идентификација на агресијата во социјалните медиуми: пристап базиран на трансферско учење', 'ms': 'Identifikasi Aggression in Social Media: a Transfer Learning Based Approach', 'ml': 'സോഷ്യല്\u200d മീഡിയയില്\u200d ഗ്രാഗ്രേഷന്\u200d തിരിച്ചറിയുക: ഒരു മാറ്റം പഠിക്കുന്നത് അടിസ്ഥാനമായ സമ്പാദിക്', 'mt': 'Aggression Identification in Social Media: a Transfer Learning Based Approach', 'mn': 'Нийгмийн Мэдээлэл дээрх хамгаалалтын тодорхойлолт: Трансфер суралцах сургалтын үндсэн ойлголт', 'no': 'Identifikasjon av agresjon i sosiale mediar: ein overføringsslæring basert tilgang', 'pl': 'Identyfikacja agresji w mediach społecznościowych: podejście oparte na transferowym uczeniu się', 'sr': 'Identifikacija Agresije u društvenim medijima: osnovan pristup prijevoza', 'ro': 'Identificarea agresiunii în rețelele sociale: o abordare bazată pe transfer de învățare', 'si': 'සාමාජික මාධ්\u200dයමයේ සංවිධානයක් පරීක්ෂණය: සංවිධානයක් ඉගෙනගන්න ප්\u200dරමාණයක්', 'so': 'Aqoonsiga horumarinta ee macluumaadka bulshada: A Learning Transfer Based Approach', 'sv': 'Aggressionsidentifiering i sociala medier: en metod baserad på överföring av lärande', 'ta': 'சமூக ஊடகங்களில் ஏற்றுமதி அடையாளம்:', 'ur': 'سوسیل میڈیا میں گریس شناسایی: ایک ترنسفور سیکھنے کی بنیادی تقریبا', 'uz': 'Name', 'vi': 'Nhận diện cưỡng bức trên phương tiện xã hội: phương pháp truyền giáo', 'bg': 'Идентификация на агресията в социалните медии: подход, базиран на трансферно обучение', 'da': 'Aggressionsidentifikation i sociale medier: en Transfer Learning Baseret Tilgang', 'hr': 'Identifikacija agresije u društvenim medijima: osnovan pristup prijenosnom učenju', 'de': 'Aggressions-Identifikation in Social Media: ein Transfer Learning basierter Ansatz', 'id': 'Identifikasi Aggression in Social Media: a Transfer Learning Based Approach', 'ko': '소셜 미디어에서의 공격 식별: 이동 학습 기반 방법', 'fa': 'Identification of Aggression in Social Media: a Transfer Learning Based Approach', 'tr': 'Sosyal Medýdançalaryň içinde arzanylyk kimligi: öwrenmek üçin bir nusga', 'sw': 'Utambulisho wa Makubaliano katika Vyombo vya Habari vya kijamii: Utafiti wa Uhamiaji', 'af': 'Aggresieidentifikasie in sosiale media: √¢¬Ä¬ôn Oordrag leer ondersteunde toegang', 'sq': 'Identifikimi i agresionit në mediat sociale: një metodë e mbështetur në mësimin e transferimit', 'am': 'የመስጠት ውይይት ማኅበራዊ ሚዲያ: መተማር መሠረት አቀማመጥ', 'hy': 'Սոցիալական լրատվամիջոցներում գտնվող ագրեսիայի հայտնաբերումը. փոխանցման ուսուցման հիմնված մոտեցում', 'nl': 'Agressie Identificatie in Social Media: een transfer learning based aanpak', 'az': "Sosyal Medya'da Agresiya Kimlik: Transfer √ñyr…ônm…ôsi √ñyr…ônm…ôsi", 'bn': 'সামাজিক প্রচার মাধ্যমে গ্রেগারেশন পরিচয়: একটি ট্রান্সফারেন্স শিক্ষা ভিত্তিক অভিযোগ', 'bs': 'Identifikacija agresije u društvenim medijima: osnovan pristup prijenosa', 'ca': "Identificació de l'agressió als mitjans socials: un enfocament basat en l'aprenentatge de transferència", 'cs': 'Identifikace agrese v sociálních médiích: přístup založený na transferovém učení', 'et': 'Aggressiooni tuvastamine sotsiaalmeedias: siirdeõppepõhine lähenemisviis', 'fi': 'Aggression tunnistaminen sosiaalisessa mediassa: siirtooppimiseen perustuva lähestymistapa', 'jv': 'name', 'sk': 'Identifikacija agresije v socialnih medijih: pristop, ki temelji na prenosu učenja', 'ha': '@ action: button', 'he': 'זיהוי התקף במדיה חברתית: גישה מבוססת על לימוד העברה', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་ཏུ་འཛམ་གླིང་དཔལ་འཛིན་དང་། སྤྱིར་གྱིས་གཞི་རྟེན་ནས་གནད་དོན་དང་།'}
{'en': 'The way people communicate have changed in many ways with the outbreak of  social media . One of the aspects of  social media  is the ability for their information producers to hide, fully or partially, their identity during a discussion ; leading to  cyber-aggression  and interpersonal aggression. Automatically monitoring  user-generated content  in order to help moderating it is thus a very hot topic. In this paper, we propose to use the transformer based language model BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) to identify aggressive content. Our  model  is also used to predict the level of  aggressiveness . The evaluation part of this paper is based on the  dataset  provided by the TRAC shared task (Kumar et al., 2018a). When compared to the other participants of this shared task, our  model  achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.', 'es': 'La forma en que las personas se comunican ha cambiado de muchas maneras con el surgimiento de las redes sociales. Uno de los aspectos de las redes sociales es la capacidad de sus productores de información para ocultar, total o parcialmente, su identidad durante una discusión, lo que lleva a la ciberagresión y la agresión interpersonal. Supervisar automáticamente el contenido generado por los usuarios para ayudar a moderarlo es, por lo tanto, un tema muy candente. En este artículo, proponemos utilizar el modelo de lenguaje basado en transformadores BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) para identificar contenido agresivo. Nuestro modelo también se utiliza para predecir el nivel de agresividad. La parte de evaluación de este documento se basa en el conjunto de datos proporcionado por la tarea compartida del TRAC (Kumar et al., 2018a). En comparación con los demás participantes de esta tarea compartida, nuestro modelo logró el tercer mejor rendimiento según la medida F1 ponderada en las colecciones de Facebook y Twitter.', 'fr': "La façon dont les gens communiquent a changé à bien des égards avec l'apparition des médias sociaux. L'un des aspects des médias sociaux est la capacité de leurs producteurs d'informations à cacher, totalement ou partiellement, leur identité au cours d'une discussion, ce qui conduit à la cyberagression et à l'agression interpersonnelle. La surveillance automatique du contenu généré par les utilisateurs afin de faciliter sa modération est donc un sujet très brûlant. Dans cet article, nous proposons d'utiliser le modèle de langage basé sur le transformateur BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) pour identifier le contenu agressif. Notre modèle est également utilisé pour prédire le niveau d'agressivité. La partie évaluation de ce document est basée sur l'ensemble de données fourni par la tâche partagée TRAC (Kumar et al., 2018a). Comparé aux autres participants à cette tâche partagée, notre modèle a obtenu la troisième meilleure performance selon la mesure pondérée F1 sur les collections Facebook et Twitter.", 'pt': 'A forma como as pessoas se comunicam mudou de muitas maneiras com o surgimento das mídias sociais. Um dos aspectos das mídias sociais é a capacidade de seus produtores de informação ocultarem, total ou parcialmente, sua identidade durante uma discussão; levando à agressão cibernética e à agressão interpessoal. Monitorar automaticamente o conteúdo gerado pelo usuário para ajudar a moderá-lo é, portanto, um tópico muito importante. Neste artigo, propomos usar o modelo de linguagem baseado em transformador BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) para identificar conteúdo agressivo. Nosso modelo também é usado para prever o nível de agressividade. A parte de avaliação deste artigo é baseada no conjunto de dados fornecido pela tarefa compartilhada TRAC (Kumar et al., 2018a). Quando comparado aos demais participantes desta tarefa compartilhada, nosso modelo obteve o terceiro melhor desempenho de acordo com a medida F1 ponderada nas coleções do Facebook e Twitter.', 'ar': 'لقد تغيرت الطريقة التي يتواصل بها الناس من نواح كثيرة مع انتشار وسائل التواصل الاجتماعي. يتمثل أحد جوانب وسائل التواصل الاجتماعي في قدرة منتجي المعلومات على إخفاء هويتهم كليًا أو جزئيًا أثناء المناقشة ؛ مما يؤدي إلى العدوان السيبراني والعدوان بين الأشخاص. إن المراقبة التلقائية للمحتوى الذي ينشئه المستخدم من أجل المساعدة في الإشراف عليه يعد موضوعًا ساخنًا للغاية. في هذه الورقة ، نقترح استخدام نموذج اللغة القائم على المحولات BERT (تمثيل التشفير ثنائي الاتجاه من المحول) (Devlin et al. ، 2019) لتحديد المحتوى العدواني. يستخدم نموذجنا أيضًا للتنبؤ بمستوى العدوانية. يعتمد جزء التقييم في هذه الورقة على مجموعة البيانات المقدمة من مهمة TRAC المشتركة (Kumar et al. ، 2018a). عند مقارنتها بالمشاركين الآخرين في هذه المهمة المشتركة ، حقق نموذجنا ثالث أفضل أداء وفقًا لمقياس F1 المرجح في كل من مجموعات Facebook و Twitter.', 'zh': '随社交媒体之发,人通多变。 社交媒体一者信息生产者能尽隐其身。 致网络侵讦。 故自守用户成,以助核热门。 本文,臣等议用变压器语BERT(自Transformer双向编码器示)(Devlin等,2019)以识侵略性。 吾模犹以占主动性级。 本文评估本TRAC共供数集(Kumar等,2018a)。 比之他参与者,以FacebookTwitter合加权F1度之,吾形得第三善。', 'hi': 'सोशल मीडिया के प्रकोप के साथ लोगों के संवाद करने का तरीका कई मायनों में बदल गया है। सोशल मीडिया के पहलुओं में से एक उनके सूचना उत्पादकों के लिए चर्चा के दौरान अपनी पहचान को पूरी तरह से या आंशिक रूप से छिपाने की क्षमता है; साइबर आक्रामकता और पारस्परिक आक्रामकता के लिए अग्रणी। स्वचालित रूप से उपयोगकर्ता-जनित सामग्री की निगरानी करने के लिए इसे मॉडरेट करने में मदद करने के लिए इस प्रकार एक बहुत ही गर्म विषय है। इस पेपर में, हम आक्रामक सामग्री की पहचान करने के लिए ट्रांसफॉर्मर आधारित भाषा मॉडल BERT (ट्रांसफॉर्मर से द्विदिश एन्कोडर प्रतिनिधित्व) (Devlin et al., 2019) का उपयोग करने का प्रस्ताव करते हैं। हमारे मॉडल का उपयोग आक्रामकता के स्तर की भविष्यवाणी करने के लिए भी किया जाता है। इस पेपर का मूल्यांकन भाग TRAC साझा कार्य (कुमार एट अल। जब इस साझा कार्य के अन्य प्रतिभागियों की तुलना में, हमारे मॉडल ने फेसबुक और ट्विटर संग्रह दोनों पर भारित एफ 1 माप के अनुसार तीसरा सबसे अच्छा प्रदर्शन हासिल किया।', 'ru': 'То, как люди общаются, изменилось во многих отношениях со вспышкой социальных сетей. Одним из аспектов социальных сетей является способность их производителей информации полностью или частично скрывать свою личность во время обсуждения, что приводит к кибер-агрессии и межличностной агрессии. Таким образом, автоматический мониторинг пользовательского контента, чтобы помочь модерировать его, является очень горячей темой. В этой статье мы предлагаем использовать лингвистическую модель на основе трансформатора BERT (Двунаправленное представление кодировщика от трансформатора) (Devlin et al., 2019) для выявления агрессивного контента. Наша модель также используется для прогнозирования уровня агрессивности. Часть оценки этого документа основана на наборе данных, предоставленных общей задачей ПРОФ (Kumar et al., 2018a). По сравнению с другими участниками этой общей задачи, наша модель достигла третьей лучшей производительности по взвешенному показателю F1 как в Facebook, так и в Twitter коллекциях.', 'ja': 'ソーシャルメディアの流行により、人々のコミュニケーションの方法は多くの点で変化しました。ソーシャルメディアの側面の1つは、情報制作者がディスカッション中にアイデンティティを完全または部分的に隠すことができることです。サイバー攻撃や対人攻撃につながります。モデレートに役立つように、ユーザーが作成したコンテンツを自動的に監視することは、したがって非常に重要なトピックです。本稿では，トランスベース言語モデルBERT （ Bidirectional Encoder Representation from Transformer ） （ Devlin et al., 2019 ）を用いて，攻撃的なコンテンツを同定することを提案する．私たちのモデルは、攻撃性のレベルを予測するためにも使用されます。本論文の評価部分は、TRAC共有タスクによって提供されるデータセットに基づいている（ Kumar et al., 2018 a ）。この共有タスクの他の参加者と比較した場合、当社のモデルは、FacebookとTwitterの両方のコレクションで重み付けされたF 1メジャーに従って3番目に優れたパフォーマンスを達成しました。', 'ga': 'Tá an bealach cumarsáide daoine athraithe ar go leor bealaí le briseadh amach na meán sóisialta. Ceann de na gnéithe de na meáin shóisialta is ea an cumas atá ag a dtáirgeoirí faisnéise a bhféiniúlacht a cheilt, go hiomlán nó go páirteach, le linn díospóireachta; as a dtagann cibear-ionsaitheacht agus ionsaí idirphearsanta. Is ábhar an-te mar sin é monatóireacht uathoibríoch a dhéanamh ar ábhar a ghintear leis an úsáideoir chun cabhrú leis a mhaolú. Sa pháipéar seo, tá sé beartaithe againn úsáid a bhaint as an tsamhail teanga bunaithe ar chlaochladán BERT (Déthreoshuíomh Ionchódóra ón gClaochladán) (Devlin et al., 2019) chun ábhar ionsaitheach a shainaithint. Úsáidtear ár múnla freisin chun leibhéal na ionsaitheachta a thuar. Tá an chuid meastóireachta den pháipéar seo bunaithe ar an tacar sonraí a sholáthair tasc comhroinnte TRAC (Kumar et al., 2018a). Nuair a chuirtear i gcomparáid le rannpháirtithe eile an taisc chomhroinnte seo, bhain ár múnla an tríú feidhmíocht is fearr amach de réir an bhirt ualaithe F1 ar bhailiúcháin Facebook agus Twitter araon.', 'hu': 'Az emberek kommunikációs módja sokféleképpen megváltozott a közösségi média kitörésével. A közösségi média egyik aspektusa az, hogy információgyártóik képesek teljesen vagy részben elrejteni identitásukat egy beszélgetés során; Kiber-agresszióhoz és interperszonális agresszióhoz vezet. A felhasználók által generált tartalom automatikus figyelése annak érdekében, hogy segítsen moderálni, így nagyon forró téma. Jelen tanulmányban a transzformátor alapú nyelvi modell BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) használatát javasoljuk az agresszív tartalom azonosítására. Modellünket arra is használjuk, hogy megjósoljuk az agresszivitás szintjét. A tanulmány értékelési része a TRAC közös feladat (Kumar et al., 2018a) által biztosított adatkészleten alapul. A megosztott feladat többi résztvevőjével összehasonlítva modellünk a harmadik legjobb teljesítményt érte el a Facebook és Twitter gyűjtemények súlyozott F1 mérése szerint.', 'el': 'Ο τρόπος επικοινωνίας των ανθρώπων έχει αλλάξει με πολλούς τρόπους με το ξέσπασμα των μέσων κοινωνικής δικτύωσης. Μια από τις πτυχές των μέσων κοινωνικής δικτύωσης είναι η ικανότητα των παραγωγών πληροφοριών τους να αποκρύπτουν, πλήρως ή εν μέρει, την ταυτότητά τους κατά τη διάρκεια μιας συζήτησης. που οδηγεί σε κυβερνοεπιθεση και διαπροσωπική επιθετικότητα. Η αυτόματη παρακολούθηση περιεχομένου που δημιουργείται από τους χρήστες προκειμένου να βοηθήσει στη συντήρησή του είναι επομένως ένα πολύ καυτό θέμα. Στην παρούσα εργασία, προτείνουμε να χρησιμοποιήσουμε το μοντέλο γλώσσας βασισμένο στον μετασχηματιστή για τον εντοπισμό επιθετικού περιεχομένου. Το μοντέλο μας χρησιμοποιείται επίσης για να προβλέψει το επίπεδο επιθετικότητας. Το τμήμα αξιολόγησης της παρούσας εργασίας βασίζεται στο σύνολο δεδομένων που παρέχει η κοινή εργασία TRAC (Kumar et al., 2018α). Σε σύγκριση με τους άλλους συμμετέχοντες σε αυτό το κοινό έργο, το μοντέλο μας πέτυχε την τρίτη καλύτερη απόδοση σύμφωνα με το σταθμισμένο μέτρο F1 τόσο στις συλλογές Facebook όσο και στο Twitter.', 'ka': 'როგორც ადამიანები კომუნიკაციას გადაცვლა სოციალური მედიაზე. სოციალური მედიაზე ერთი აპექტირები არის იგივე შესაძლებლობა, რომ ინფორმაციის პროექტირებისთვის, ყველაფერად ან ნაწილაფერად, იგივე იდენტიფიკაცია გან საიბერ-ადრესია და ინტერპირონული ადრესია. მომხმარებლის შექმნილი ინტერმაციის ავტომატურად მონარტირება, როგორც მისი მომედირების შესაძლებელად იყო მნიშვნელოვანი თემა. ამ დომენტში ჩვენ მინდა გამოყენოთ ტრანფორმენტრისტური ენის მოდელი BERT (ორდირექციონალური ინფორმენტრისტურის რესპენტაცია) (Devlin et al., 2019) ადრესიური ინტერნეტის განსაზღვრება. ჩვენი მოდელი ასევე გამოყენებულია, რომ აგრესიფერების დონე წარმოდგინოთ. ამ დომენტის განსაზღვრების ნაწილი იქნება TRAC გაყოფილი დანაწილე დანაწილე მონაცემების ნაწილზე (Kumar et al., 2018a). როდესაც ამ საზოგადო დავალების სხვადასხვა მონაცემებთან შედგენა, ჩვენი მოდელი მიიღეთ მესამე საუკეთესო შესაძლებლობა, როდესაც F1 მოზომის შესაძლებელია Facebook და Twitter-ის კ', 'it': "Il modo in cui le persone comunicano è cambiato in molti modi con lo scoppio dei social media. Uno degli aspetti dei social media è la capacità dei loro produttori di informazioni di nascondere, in tutto o in parte, la loro identità durante una discussione; che porta all'aggressione informatica e all'aggressione interpersonale. Monitorare automaticamente i contenuti generati dagli utenti al fine di contribuire a moderarli è quindi un argomento molto caldo. In questo articolo, proponiamo di utilizzare il modello di linguaggio basato su trasformatori BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) per identificare contenuti aggressivi. Il nostro modello viene utilizzato anche per prevedere il livello di aggressività. La parte di valutazione di questo articolo si basa sul set di dati forniti dal compito condiviso TRAC (Kumar et al., 2018a). Rispetto agli altri partecipanti a questo compito condiviso, il nostro modello ha raggiunto la terza migliore prestazione secondo la misura ponderata F1 sia sulle collezioni Facebook che Twitter.", 'lt': 'Su social in ės žiniasklaidos protrūkiu žmonių bendravimas daugeliu būdų pasikeitė. One of the aspects of social media is the ability for their information producers to hide, fully or partially, their identity during a discussion;  dėl to kyla kibernetinė agresija ir asmenų tarpusavio agresija. Todėl labai karšta tema yra automatiškai stebėti naudotojo sukauptą turinį, kad būtų galima jį sumažinti. Šiame dokumente siūlome naudoti transformatoriumi pagrįstą kalbos model į BERT (dvikrypčio kodo atstovavimas iš transformatoriaus) (Devlin et al., 2019 m.) agresyvumui nustatyti. Mūsų model is taip pat naudojamas agresyvumo lygiui prognozuoti. Šio dokumento vertinimo dalis grindžiama TRAC bendros užduoties duomenų rinkiniu (Kumar ir kt., 2018a). Palyginti su kitais šios bendros užduoties dalyviais, mūsų modelis pasiekė trečią geriausią rezultatą pagal svertinę F1 priemonę Facebook ir Twitter kolekcijose.', 'kk': 'Адамдар қатынау арқылы социаллық медиаға қатынау арқылы көптеген өзгертілді. Америкалық медиақтарының бір бөлігі - олардың мәлімет производушыларының өзінің идентификациясын дискуссия кезінде жасырып, толық немесе бөлігін жасыру мүмкінд Киберагрессия және жеке агрессия арқылы. Пайдаланушының құрылған мазмұнын автоматты түрде бақылау үшін оны көмектесу үшін өте жылу нақышы болады. Бұл қағазда, BERT тілді түрлендіруші үлгісін қолдану үшін (Трансформацияның екі бағытты кодтардың таңдауы) (Devlin et al., 2019) қолданып, агрессивні мазмұнын анықтау үшін қолданамыз. Біздің үлгіміз де агресивтік деңгейін таңдау үшін қолданылады. Бұл қағаздың бағалау бөлігі TRAC ортақ тапсырмасының (Kumar et al., 2018a) деректер қорларына негізделген. Бұл ортақтастырған тапсырманың басқа қатысушыларымен салыстырғанда, біздің үлгіміз Facebook мен Twitter жинақтарындағы F1 өлшемінің үшінші ең жақсы істеуіне сәйкес келді.', 'mk': 'Начинот на кој луѓето комуницираат се промени на многу начини со експлозијата на социјалните медиуми. Еден од аспектите на социјалните медиуми е способноста нивните производители на информации да го кријат, целосно или делумно, нивниот идентитет за време на дискусијата; водејќи до кибер-агресија и меѓулична агресија. Автоматско мониторирање на содржината генерирана од корисникот со цел да помогне во модерирањето е така многу жешка тема. Во овој весник, предложуваме да се користи јазичкиот модел базиран на трансформаторот БЕРТ (Бидирекционална претстава на кодерот од трансформаторот) (Devlin et al., 2019) за идентификување на агресивната содржина. Нашиот модел се користи и за предвидување на нивото на агресивност. Делот на проценката на овој документ се базира на наборот на податоци обезбедени од заедничката задача на TRAC (Kumar и ал., 2018а). Во споредба со другите учесници на оваа заедничка задача, нашиот модел ја постигна третата најдобра перформанса според тежираната мерка F1 на колекциите на Фејсбук и Твитер.', 'ms': 'Cara orang berkomunikasi telah berubah dalam banyak cara dengan outbreak media sosial. Salah satu aspek media sosial ialah kemampuan bagi produser maklumat mereka untuk menyembunyikan, sepenuhnya atau sebahagian, identiti mereka semasa perbincangan; yang menyebabkan agresi siber dan agresi antara peribadi. Mengawasi kandungan yang dijana oleh pengguna secara automatik untuk membantu mengutamakannya adalah topik yang sangat panas. Dalam kertas ini, kami cadangkan untuk menggunakan model bahasa berdasarkan pengubah BERT (Perwakilan Pengekod Dua Arah dari Penukar) (Devlin et al., 2019) untuk mengenalpasti kandungan agresif. Model kita juga digunakan untuk meramalkan tahap agresif. Bahagian penilaian kertas ini berdasarkan set data yang diberikan oleh tugas berkongsi TRAC (Kumar et al., 2018a). Apabila dibandingkan dengan peserta lain dalam tugas berkongsi ini, model kami mencapai prestasi terbaik ketiga menurut ukuran F1 berat pada koleksi Facebook dan Twitter.', 'ml': 'ആളുകള്\u200d സാമൂഹിക മാധ്യമങ്ങളുടെ പുറത്ത് വരുന്നതിനാല്\u200d പല വഴികളില്\u200d മാറിയിരിക്കുന്നു. സാമൂഹ്യ മാധ്യമങ്ങളുടെ ഒരു കാര്യത്തില്\u200d ഒരു വിവരങ്ങള്\u200d അവരുടെ വിവരങ്ങള്\u200d ഉല്\u200dപാദിപ്പിക്കുന്നവര്\u200dക്ക് അവരുടെ വിവരങ്ങള്\u200d ഒ സൈബര്\u200d അക്രമത്തിനും വ്യക്തിപരമായ അക്രമത്തിനും കൊണ്ട് വരുന്നു. ഉപയോക്താവ് സൃഷ്ടിച്ചിരിക്കുന്ന വസ്തുക്കള്\u200d സ്വയം നിരീക്ഷിക്കുന്നതിനായി നിരീക്ഷിക്കുന്നതിനാ ഈ പത്രത്തില്\u200d നമ്മള്\u200d മാറ്റുന്ന ഭാഷ മോഡല്\u200d ബെര്\u200dട്ടി (ട്രാന്\u200dസ്ഫോര്\u200dമാരില്\u200d നിന്നുള്ള ബൈഡഡലിക്കല്\u200d കോഡിയര്\u200d പ്രതിനിധികള്\u200d) (ഡെവെല്\u200dലിന Our model is also used to predict the level of aggressiveness.  ഈ പത്രത്തിലെ വിലാസഭാഗം TRAC പങ്കുവെച്ച ജോലിയുടെ ഡാറ്റാസറ്റ് അടിസ്ഥാനത്താണു് (കുമാര്\u200d എറ്റ് അല്\u200d, 2018a). ഈ പങ്കാളിയുള്ള ജോലിയുടെ മറ്റുള്ള പങ്കാളികളോട് താരതമ്യം ചെയ്തപ്പോള്\u200d ഫെക്കൂട്ടുകാരുടെയും ടൂട്ടറിലുള്ള F1 അളവും ത', 'mt': 'The way people communicate have changed in many ways with the outbreak of social media.  Waħda mill-aspetti tal-midja soċjali hija l-kapaċità għall-produtturi tal-informazzjoni tagħhom li jaħbu, kompletament jew parzjalment, l-identità tagħhom matul diskussjoni; li jwassal għal ċiberaggressjoni u aggressjoni interpersonali. Il-monitoraġġ awtomatiku tal-kontenut iġġenerat mill-utent sabiex jgħin fil-moderazzjoni tiegħu huwa għalhekk suġġett sħun ħafna. F’dan id-dokument, qed nipproponu li jintużaw il-mudell lingwistiku bbażat fuq it-trasformatur BERT (Rappreżentazzjoni Bidirezzjonali tal-Kodifikatur mit-Transformatur) (Devlin et al., 2019) biex jiġi identifikat kontenut aggressiv. Il-mudell tagħna jintuża wkoll biex jipprevedi l-livell ta’ aggressività. Il-parti tal-evalwazzjoni ta’ dan id-dokument hija bbażata fuq is-sett tad-dejta pprovdut mill-kompitu kondiviż tat-TRAC (Kumar et al., 2018a). When compared to the other participants of this shared task, our model achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.', 'pl': 'Sposób komunikacji ludzi zmienił się na wiele sposobów wraz z wybuchem mediów społecznościowych. Jednym z aspektów mediów społecznościowych jest zdolność producentów informacji do ukrycia, w pełni lub częściowo, swojej tożsamości podczas dyskusji; prowadzące do cyberagresji i agresji interpersonalnej. Automatyczne monitorowanie treści generowanych przez użytkowników w celu pomocy w ich moderowaniu jest zatem bardzo gorącym tematem. W artykule proponujemy wykorzystanie transformatorowego modelu językowego BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) do identyfikacji agresywnych treści. Nasz model służy również do przewidywania poziomu agresywności. Część oceniająca niniejszego artykułu opiera się na zbiorze danych dostarczonym przez TRAC shared task (Kumar et al., 2018a). W porównaniu do innych uczestników tego wspólnego zadania, nasz model osiągnął trzecią najlepszą wydajność według ważonej miary F1 zarówno na kolekcjach Facebooka, jak i Twittera.', 'mn': 'Хүмүүс холбоотой байдлаар нийгмийн мэдээллийн эмгэгтэй олон аргаар өөрчлөгдсөн. Нийгмийн хэвлэлийн нэг асуудал нь тэдний мэдээллийн производчид ярилцлаганд бүрэн эсвэл хэсэг хэсгийг нуугдах чадвар юм. Цибер-агресс болон хувийн агресс болгож байна. Хэрэглэгчийн бий болгосон материалуудыг автоматаар ажиллах нь маш халуун сэдэв юм. Энэ цаасан дээр бид өөрчлөгчийн хэл загварыг BERT-ээр ашиглах санал болгож байна. Бидний загвар мөн халдвартай байдлыг таамаглахад хэрэглэгддэг. Энэ цаасын дүгнэлтийн хэсэг нь TRAC хуваалтын ажлын өгөгдлийн санг (Kumar et al., 2018a) дээр үндсэн. Энэ хуваалцааны бусад оролцогчдын харьцуулахад бидний загвар нь Фейсбук болон Твиттерийн цуглуулалтын хэмжээнд жинтэй F1 хэмжээний 3 дахь сайн үйл ажиллагааг гаргасан.', 'ro': 'Modul în care oamenii comunică s-a schimbat în multe moduri odată cu izbucnirea rețelelor sociale. Unul dintre aspectele rețelelor sociale este capacitatea producătorilor lor de informații de a-și ascunde, integral sau parțial, identitatea în timpul unei discuții; conducând la agresiune cibernetică și agresiune interpersonală. Monitorizarea automată a conținutului generat de utilizatori pentru a ajuta la moderarea acestuia este astfel un subiect foarte fierbinte. În această lucrare, propunem utilizarea modelului de limbaj bazat pe transformator BERT (bidirecțional Encoder Representation from Transformer) (Devlin et al., 2019) pentru a identifica conținutul agresiv. Modelul nostru este folosit și pentru a prezice nivelul de agresivitate. Partea de evaluare a acestei lucrări se bazează pe setul de date furnizat de sarcina comună TRAC (Kumar et al., 2018a). În comparație cu ceilalți participanți la această sarcină partajată, modelul nostru a obținut a treia cea mai bună performanță conform măsurii ponderate F1 atât pe colecțiile Facebook, cât și Twitter.', 'no': 'Måten folk kommunikasjonen har endra på mange måtar med utbrekking av sosiale media. Ein av aspektane på sosiale medier er den muligheten for å gøyma, fullstendig eller delvis, identiteten sine under diskusjon. som fører til cyber-aggresjon og interpersonleg aggresjon. Overvak automatisk innhald i brukaren for å hjelpa å moderera det er derfor eit veldig varmt emne. I denne papiret foreslår vi å bruka transformeringsspråk-modellen BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) for å identifisera aggressive innhald. Modellen vårt er også brukt for å foregå nivået på agresivitet. Evalueringsdelen av denne papiret er basert på datasettet oppgjeven av TRAC-delt oppgåve (Kumar et al., 2018a). Når det sammenlignet med dei andre deltakarane av denne delte oppgåva, har modellen vårt oppnådd den tredje beste utviklinga etter vekta F1-målet på både Facebook og Twitter-samlingar.', 'sr': 'Naèin na koji se ljudi komuniciraju promenili su se na mnogo načina sa uzbuðenjem društvenih medija. Jedan od aspekta društvenih medija je sposobnost da njihovi proizvođa či informacija sakrije, potpuno ili djelomično, njihov identitet tokom rasprave; koji vodi do kiberagresije i međuosobne agresije. Automatski prati sadržaj proizveden korisnikom kako bi pomogla umjeriti to je tako vruća tema. U ovom papiru predlažemo da upotrebimo preobrazni jezički model BERT (predstavljanje dvosmjernog kodera iz transformera) (Devlin et al., 2019) kako bi identifikovali agresivni sadržaj. Naš model se takođe koristi da predvidimo nivo agresivnosti. Оценка део овог документа је базирана на набору данных, предоставеном од обједног задача TRAC (Kumar et al., 2018a). U usporedbi sa drugim sudionicima ovog zajedničkog zadatka, naš model je postigao treći najbolji izvor u skladu sa težinom mjerom F1 na Facebook i Twitter kolekcijama.', 'si': 'මිනිස්සු සම්බන්ධ විදියට සම්බන්ධ විදියට සාමාජික මාධ්\u200dයාත්මක විදියට වෙනස් වුනා. සාමාජික මාධ්\u200dයමාධ්\u200dයමයේ එක ප්\u200dරශ්නයක් තමයි ඔවුන්ගේ තොරතුරු නිර්මාණකයන්ට සම්පූර්ණයෙන්ම හෝ අ සායිබර්-ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් වෙනුවෙන්. ස්වයංක්\u200dරියාවිතයෙන් ප්\u200dරවේශකය නිර්මාණය කරපු සාමාව පරීක්ෂණය කරන්න ඒක මධ්\u200dයමාණය කරන්න උදව් කරන්න මේ පත්තරේ අපි ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්න බෙර්ට් භාෂාව ආධාරිත භාෂාව ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා (Dev අපේ නිර්මාණය පාවිච්චි කරන්න පුළුවන් මේ පැත්තගේ විශ්ලේෂණ කොටස් අධාරණය කරනවා TRAC කොටස් එක්ක ක්\u200dරියාව (Kumar et al., 2018a). මේ වැදගත් වැඩේ අනිත් අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අං', 'so': 'Sida ay dadku u xidhiidhaan waxay ku beddeleen qaab badan oo ay ku bedelaan burburka shabakadda bulshada. Mid ka mid ah macluumaadka bulshada ayaa awood u yeelan kara dadka macluumaadkooda soo saara inay qariyaan, si buuxsan ama qeyb ah aqoonsigooda marka la hadlo; oo ku hoggaamiya xadgudub-isticmaalka iyo xadgudub gaar ah. Sida darteed si aad u caawineyso horumarinta, waa maadooyinka aad u kulul. In this paper, we propose to use the transformer based language model BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) to identify aggressive content.  Tusaale ahaan waxaa kaloo loo isticmaalaa inuu horumariyo heerka cadaawayaasha. Qiimeynta qeybta warqaddan waxaa ku saleysan taariikhda lagu siiyo shaqada la qaybsaday TRAC (Kumar et al., 2018a). Marka isbarbarbardhigta kuwa kale oo ka qayb galay shaqadaas, modelheyagu wuxuu gaadhay sameynta saddexaad ee ugu wanaagsan sida qiyaasta F1 ee ku saabsan Facebook iyo Twitter.', 'sv': 'Sättet människor kommunicerar har förändrats på många sätt med utbrottet av sociala medier. En av aspekterna av sociala medier är möjligheten för sina informationsproducenter att helt eller delvis dölja sin identitet under en diskussion. som leder till cyberaggression och mellanmänsklig aggression. Automatisk övervakning av användargenererat innehåll för att hjälpa till att moderera det är därför ett mycket hett ämne. I denna uppsats föreslår vi att man använder den transformatorbaserade språkmodellen BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) för att identifiera aggressivt innehåll. Vår modell används också för att förutsäga graden av aggressivitet. Utvärderingsdelen i denna uppsats bygger på datauppsättningen från TRAC:s gemensamma uppgift (Kumar et al., 2018a). Jämfört med de andra deltagarna i denna delade uppgift uppnådde vår modell den tredje bästa prestandan enligt det viktade F1 måttet på både Facebook och Twitter samlingar.', 'ta': 'மக்கள் தொடர்பு கொள்வது வழியில் பல வழிகளால் மாறிவிட்டது சமூக ஊடகங்களின் வெளியேற்றது. ஒரு சமூக ஊடகங்களில் ஒன்று தான் அவர்களுடைய தகவல் உருவாக்குபவர்கள் ஒரு விவாதத்தில் வாசிக்கையில் அவர்களுடைய அடையாளத்தை மறைக் சைப்பர் எதிர்பார்ப்பு மற்றும் தனிப்பட்ட எதிர்பார்ப்பு பயனர் உருவாக்கப்பட்ட உள்ளடக்கங்களை தானாகவே கண்காணிக்கவும், அதனால் இது மிகவும் சூடான தலைப்பு. இந்த காகிதத்தில், நாம் மாற்றி அடிப்படையான மொழி மாதிரி BERT (மாற்றியிலிருந்து இருதிசை குறியீட்டு பிரதிநிதியை பயன்படுத்த வேண்டும்) நம்முடைய மாதிரி அக்கிரமம் நிலையை முன்வாக்க பயன்படுத்தப்படுகிறது. இந்த தாளின் பகுதியின் மதிப்பீடு TRAC பகிர்ந்த பணியின் தரவுத்தளத்தை அடிப்படையாக உள்ளது (Kumar et al., 2018a). இந்த பகிர்ந்த பணியின் மற்ற பங்கீட்டாளர்களுடன் ஒப்பிடும் போது, எங்கள் மாதிரி மூன்றாவது சிறந்த செயல்பாடு பெற்றது, மாதிரி முறை', 'ur': 'انسانوں کی تعامل کی طرح بہت سی طریقوں سے سوسیل میڈیا کے اثر سے بدل گئی ہے۔ سوسیل میڈیا کی ایک حصہ یہ ہے کہ ان کے معلومات پیدا کرنے والوں کے لئے پورے یا حصہ سے چھپائیں، ان کی معلومات کو ایک بحث میں چھپائیں، سایبر-گرسنی اور مختلف شخصی گرسنی کی وجہ سے۔ اس طرح ایک بہت گرم موضوع ہے۔ ہم اس کاغذ میں تغییر دینے والی زبان موڈل BERT (ترنسفور سے دودہرٹیونل اکڈر ریسپرنسیٹ) (Devlin et al., 2019) کو استعمال کرنے کے لئے پیشنهاد کرتے ہیں۔ ہمارا مدل بھی گراذ کے سطح کی پیش بینی کرنے کے لئے استعمال کیا جاتا ہے۔ اس کاغذ کا ارزیابی حصہ TRAC مشترک کام (Kumar et al., 2018a) کے دیٹ سٹ پر بنیاد ہے. جب اس مشترک کام کے دوسرے مشترکین کے مقابلہ میں، ہمارا مدل تیسرا بہترین کامل پہنچا گیا، فیسبوک اور ٹویٹر کی جماعتیں کے مطابق وزن F1 اندازے کے مطابق.', 'uz': "Одамлар қўшимча усулга тўлиқ таркиб чиққан ҳолда ўзгартириб қўйилган. Мулоҳат вақтида ўз маълумотлари муфассалларини беркитиш, тўп ёки қисман сифатларини беркитиш қодир бўлиши мумкин. shaxsiy harakat qilishga ega bo'ladi. Name Bu hujjatda, biz bir xil tarkibini aniqlash uchun o'zgartirish asosiy tilning modeli BERT (Transformer dan ikkita xil kodlash qoidasi) (Devlin et, 2019) bilan aniqlashni talab qilamiz. Bizning modelimizning atributlarning darajasini ko'rib tushunish uchun ishlatiladi. Bu qogʻozning qiymati TRAC bogʻliq vazifasi (Kumar et al, 2018a) yaratilgan maʼlumot bazasining asosida. When compared to the other participants of this shared task, our model achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.", 'vi': 'Cách người ta giao tiếp đã thay đổi theo nhiều cách với sự bùng phát của truyền thông xã hội. Một trong những khía cạnh của các phương tiện truyền thông xã hội là khả năng cho nhà sản xuất thông tin che giấu, hoàn to àn hay phần nào, danh tính của mình trong cuộc thảo luận; dẫn đến tấn công mạng và tấn công con người. Tự động theo dõi nội dung của người dùng để giúp giảm nó là một chủ đề rất nóng. Trong tờ giấy này, chúng tôi đề nghị sử dụng mô hình ngôn ngữ biến đổi BERT (Đài Truyền Mã hoá) từ Transformer (Devlin et al., 99) để nhận diện nội dung tích cực. Mẫu mã của chúng tôi cũng được dùng để dự đoán mức độ hung dữ. Phần đánh giá của tờ giấy này dựa trên bộ dữ liệu được cung cấp bởi tập tin bố trí theo giao thức TRAC (Kumar et al., 20ra). So với những thành viên khác của công việc chia sẻ này, mẫu của chúng ta đạt đến hiệu suất tốt thứ ba nhất dựa trên con số F1 được cân nhắc trên cả các bộ sưu tập Facebook lẫn Twitter.', 'bg': 'Начинът, по който хората общуват, се промени в много отношения с избухването на социалните медии. Един от аспектите на социалните медии е способността на своите информационни производители да скрият изцяло или частично своята идентичност по време на дискусия; води до киберагресия и междуличностна агресия. Автоматичното наблюдение на генерирано от потребителите съдържание, за да помогне за модерирането му, е много гореща тема. В настоящата статия предлагаме да се използва трансформаторният езиков модел за идентифициране на агресивно съдържание. Нашият модел се използва и за прогнозиране на нивото на агресивност. Частта за оценка на настоящата статия се основава на набора от данни, предоставени от споделената задача на ТРАК (Кумар и др., 2018а). В сравнение с останалите участници в тази споделена задача, нашият модел постигна третото най-добро представяне според претеглената мярка както във Фейсбук, така и в Туитър колекции.', 'hr': 'Način komunikacije ljudi se promijenio na mnogim načinama s uzbuđenjem društvenih medija. Jedan od aspekta društvenih medija je sposobnost da njihovi proizvođa či informacija sakrije, potpuno ili djelomično, njihov identitet tijekom rasprave; koji vodi do kiberagresije i međuosobne agresije. Automatski prati sadržaj proizveden korisnikom kako bi pomogla umjeriti to je tako vruća tema. U ovom papiru predlažemo da koristimo model jezika transformatora BERT (predstavljanje dvosmjernog kodera iz Transformera) (Devlin et al., 2019) kako bi identifikovali agresivni sadržaj. Naš model se također koristi za predviđanje nivoa agresivnosti. Odjel procjene ovog papira temeljen je na podacima koje je predložio podatak zajednički zadatak TRAC-a (Kumar et al., 2018a). U usporedbi s ostalim učesnicima ovog zajedničkog zadatka, naš model je postigao treću najbolju učinku u skladu s mjerom težine F1 na Facebook-u i Twitter-u.', 'da': "Den måde, folk kommunikerer på, har ændret sig på mange måder med udbruddet af sociale medier. Et af aspekterne ved sociale medier er deres informationsproducenters evne til helt eller delvist at skjule deres identitet under en diskussion; der fører til cyberaggression og interpersonel aggression. Automatisk overvågning af brugergenereret indhold for at hjælpe med at moderere det er derfor et meget varmt emne. I denne artikel foreslår vi at bruge den transformerbaserede sprogmodel BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) til at identificere aggressivt indhold. Vores model bruges også til at forudsige niveauet af aggressivitet. Evalueringsdelen af dette dokument er baseret på datasættet fra TRAC's delte opgave (Kumar et al., 2018a). Sammenlignet med de andre deltagere i denne delte opgave opnåede vores model den tredjebedste præstation ifølge den vægtede F1 måling på både Facebook og Twitter samlinger.", 'nl': 'De manier waarop mensen communiceren is op vele manieren veranderd met de uitbraak van sociale media. Een van de aspecten van sociale media is de mogelijkheid voor hun informatieproducenten om hun identiteit volledig of gedeeltelijk te verbergen tijdens een discussie; die leiden tot cyberaanventie en interpersoonlijke agressie. Het automatisch monitoren van door gebruikers gegenereerde content om het te helpen modereren is dus een zeer hot topic. In dit artikel stellen we voor om het transformatorgebaseerde taalmodel BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) te gebruiken om agressieve inhoud te identificeren. Ons model wordt ook gebruikt om het niveau van agressiviteit te voorspellen. Het evaluatiedeel van dit artikel is gebaseerd op de dataset die wordt verstrekt door de TRAC shared task (Kumar et al., 2018a). In vergelijking met de andere deelnemers aan deze gedeelde taak behaalde ons model de op drie na beste prestaties volgens de gewogen F1-meting op zowel Facebook als Twitter-collecties.', 'id': 'Cara orang berkomunikasi telah berubah dalam banyak cara dengan wabah media sosial. Salah satu aspek media sosial adalah kemampuan para produser informasi mereka untuk menyembunyikan, sepenuhnya atau sebagian, identitas mereka selama diskusi; yang menyebabkan agresi cyber dan agresi interpersonal. Otomatis memantau isi yang dibuat oleh pengguna untuk membantu memandainya adalah topik yang sangat panas. Dalam kertas ini, kami mengusulkan untuk menggunakan model bahasa berdasarkan transformer BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) untuk mengidentifikasi isi agresif. Model kita juga digunakan untuk memprediksi tingkat agresif. Bagian evaluasi dari kertas ini berdasarkan set data yang diberikan oleh tugas TRAC berbagi (Kumar et al., 2018a). Ketika dibandingkan dengan peserta lainnya dalam tugas berbagi ini, model kami mencapai prestasi terbaik ketiga menurut ukuran F1 berat di koleksi Facebook dan Twitter.', 'fa': 'راهی که مردم ارتباط می\u200cکنند با بیماری رسانه\u200cهای اجتماعی به طریق بسیاری تغییر داده اند. یکی از نقطه\u200cهای رسانه\u200cهای اجتماعی توانایی برای تولید کنندگان اطلاعات خود است که در طول بحث هویت خود را پنهان کنند، کامل یا قسمتی پنهان کنند. به سوی آتشفشار سایبر و حمله شخصی. مراقبت محتوای تولید شده از کاربر به طور خودکار برای کمک به مدرسه کردن آن یک موضوع بسیار گرم است. در این کاغذ، ما پیشنهاد می کنیم از مدل زبان متغیر کننده BERT استفاده کنیم (Representation of Bidirectional Encoder from Transformer) (Devlin et al., 2019) برای شناسایی محتوای agresively. مدل ما هم برای پیش بینی سطح حمله استفاده می\u200cشود. بخش ارزیابی این کاغذ بر اساس مجموعه داده\u200cها توسط کار مشترک TRAC (Kumar et al., 2018a) است. زمانی که در مقایسه با بقیه شرکتگران این کار مشترک، مدل ما بهترین عملکرد سوم را بر اساس اندازه وزن F1 در هر دو جمعیت فیسبوک و توئیتر رسید.', 'de': 'Die Art und Weise, wie Menschen kommunizieren, hat sich mit dem Ausbruch der sozialen Medien in vielerlei Hinsicht verändert. Einer der Aspekte sozialer Medien ist die Fähigkeit ihrer Informationsproduzenten, ihre Identität während einer Diskussion ganz oder teilweise zu verbergen; die zu Cyber-Aggression und zwischenmenschlichen Aggressionen führen. Benutzergenerierte Inhalte automatisch zu überwachen, um sie zu moderieren, ist daher ein sehr heißes Thema. In diesem Beitrag schlagen wir vor, das transformatorbasierte Sprachmodell BERT (Bidirektional Encoder Representation from Transformer) (Devlin et al., 2019) zu verwenden, um aggressive Inhalte zu identifizieren. Unser Modell wird auch verwendet, um den Grad der Aggressivität vorherzusagen. Der Evaluationsteil dieser Arbeit basiert auf dem Datensatz der TRAC Shared Task (Kumar et al., 2018a). Im Vergleich zu den anderen Teilnehmern dieser gemeinsamen Aufgabe erzielte unser Modell die drittbeste Leistung entsprechend der gewichteten F1-Messung sowohl auf Facebook als auch auf Twitter.', 'ko': '소셜 미디어가 흥하기 시작하면서 사람들의 교류 방식은 여러 방면에서 변화가 생겼다.소셜 미디어의 한 측면은 정보 생산자가 토론에서 자신의 신분을 완전히 또는 일부 숨기는 능력이다.사이버 공격과 인간 공격을 초래하다.따라서 사용자가 생성한 내용을 자동으로 감시하여 조절하는 데 도움을 주는 것은 매우 핫한 화제다.본고에서 우리는 변환기 기반의 언어 모델인 BERT(transformer의 양방향 인코더 표시)(Devlin et al., 2019)를 사용하여 공격적인 내용을 식별하는 것을 권장합니다.우리의 모형도 공격적인 수준을 예측하는 데 쓰인다.본고의 평가 부분은 TRAC 공유 임무가 제공한 데이터 집합(Kumar 등, 2018a)을 바탕으로 한다.페이스북과 트위터의 가중 F1 지표에 따르면 이 공유 임무의 다른 참여자에 비해 우리 모델은 세 번째로 좋은 성능을 얻었다.', 'sw': 'Namna ya kuwasiliana watu wamebadilika kwa namna nyingi na kutokea kwa mitandao ya kijamii. Moja ya mambo ya mitandao ya kijamii ni uwezo wa watengenezaji taarifa zao kujificha, kwa ujumla au kwa sehemu, utambulisho wao wakati wa mjadala; yanasababisha ukatili wa mtandaoni na ukatili wa binafsi. Kufuatilia maudhui yaliyotengenezwa kwa wenyewe ili kusaidia kuboresha mada hii ni ya moto sana. Katika karatasi hii, tunapendekeza kutumia muundo wa mabadiliko wa lugha yenye msingi wa lugha BERT (Representation of Bidirectional Encoder from Transformer) (Devlin et al., 2019) kutambua maudhui ya kibaguzi. Mfano wetu pia umetumiwa kutabiri kiwango cha ukatili. Utafiti wa makaratasi haya unategemea kwenye seti ya taarifa zilizotolewa na kazi ya TRAC inayoshirikishwa (Kumar et al., 2018). Wakati kulinganisha na washiriki wengine wa kazi hii ya ushirikiano, mwelekeo wetu ulifanikiwa kufanya kazi ya tatu bora kwa mujibu wa hatua zilizopungua F1 kwenye mikusanyiko ya Facebook na Twita.', 'tr': "Adamlar bilen habarlaşaşyşyň ýoly sosyal medýýatlaryň ýoly bilen köp ýoly üýtgedi. Sosyal medýdanlaryň biri görnüşleri bolsa, olaryň maglumat näsazlyklarynyň söhbetdeşleri wagtynda, tamamlaryny ýa-da bölümleri gizlemegi ukypdyr; cyber-agresiýa we şahsy agresiýa çevrilýär. Ullançy ýagdaýlamak üçin meýdançasyny otomatik gözlemek üçin ullanýan meýdançalary. Bu yüzden bu nähili yst meýdançasynda ýazmak üçin ullanýar. Bu kagyzda, BERT'yň tabanly dil nusgasyny ulanmagy teklip edýäris (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019). Biziň nusgymyz hem agressiv derejesini öňden geçirmek üçin ulanylýar. Bu kagyzyň çykyş bolmagy TRAC tarapyndan berilen veri setirine dayalýar (Kumar et al., 2018a). Bu paylaşyk işiniň beýleki iştirakçilerine deňleşdikde, biziň modelimiz Facebookda we Twitter toplumlarynda iň kiçi bolan F1 ölçüsi ýaly üçünji iň gowy iş ýetirdi.", 'af': "Die manier waarmee mense kommunikasie het in baie maniere verander met die uitbreek van sosiale media. Een van die aspekte van sosiale media is die moontlikheid vir hul inligting produseerders om hul identiteit te verberg, volledig of gedeeltelik in 'n diskusie; en wat lei na cyber-aggresie en interpersoonlike aggresie. Automaties monitoreer gebruiker genereerde inhoud om dit te help om te modereer is dus 'n baie warm onderwerp. In hierdie papier, ons voorstel om die transformeerder gebaseerde taal model BERT te gebruik (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) om aggressive inhoud te identifiseer. Ons model is ook gebruik om die vlak van agresiviteit te voorskou. Die evaluering deel van hierdie papier is gebaseer op die datastel wat deur die TRAC gedeelde taak verskaf word (Kumar et al., 2018a). Wanneer vergelyk het met die ander deelnimmers van hierdie gedeelde taak, het ons model die derde beste prestasie bereik volgens die geweegte F1-maat op Facebook en Twitter-samlings.", 'sq': 'Mënyra se si njerëzit komunikojnë ka ndryshuar në shumë mënyra me shpërthimin e medias sociale. Një nga aspektet e medias sociale është aftësia për prodhuesit e tyre të informacionit të fshehin, plotësisht apo pjesërisht, identitetin e tyre gjatë një diskutimi; duke shpjerë në agresionin kibernetik dhe agresionin ndërpersonal. Monitorimi automatik i përmbajtjes së gjeneruar nga përdoruesit me qëllim që të ndihmojë moderimin e saj është kështu një temë shumë e nxehtë. Në këtë letër, propozojmë të përdorim modelin e gjuhës me bazë në transformuesin BERT (Përfaqësimi i koduesit dy-drejtues nga Transformer) (Devlin et al., 2019) për të identifikuar përmbajtjen agresive. Modeli ynë përdoret gjithashtu për të parashikuar nivelin e agresivitetit. Pjesa e vlerësimit e këtij dokumenti bazohet në grupin e të dhënave të ofruara nga detyra e përbashkët e TRAC (Kumar et al., 2018a). When compared to the other participants of this shared task, our model achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.', 'am': 'የሰዎች ግንኙነት በማኅበራዊ አውታር በመውሰድ በብዙ መንገዶች ተለውጦአል፡፡ ማኅበራዊ አውታር ማኅበራዊ ማድረግ አንዱ የመረጃ አዋቂዎችን፣ ሙሉ ወይም ተካፋይ፣ identiቸውን በተጨማሪው ወቅት ሊሸሽግ መቻል ነው፤ የcyber-aggression እና የግል ግፍ የተጠቃሚ ጉዳዩ እንዲያስተካክሉ ተጠቃሚዎችን በመጠበቅ ይታያል፡፡ በዚህ ፕሮግራም፣ የደረጃ ቋንቋ ምሳሌ BERT (ከሀይዳዲያዊ የፊደል ኮድ መልዕክት ዲቪሊን እና 2019) በአስቸጋሪው ጥያቄን ለማግኘት እናስባለን፡፡ ምሳሌያችን የዓመፅ ደረጃን ለመቀበል ይጠቀማል፡፡ የዚህ ገጽ ክፍል ማስታወቂያው TRAC የተካፈለ ስራ (Kumar et al, 2018a) የተሰራጨው ዳታተር የተደረገ ነው፡፡ ይህ ስራ ከሚካፈሉት ሌሎችን ተጋሪዎች በተደረገ ጊዜ በፌስቡክ እና በትዊተር ሰብስብ ላይ እንደሚመዘን የሦስተኛውን የሻለ የድምፅ ውጤት አግኝቷል፡፡', 'hy': 'Մարդկանց հաղորդակցման ձևը շատ ձևերով փոխվել է սոցիալական լրատվամիջոցների աճի հետ: Սոցիալական լրատվամիջոցների առանձնահատկություններից մեկն այն է, որ իրենց տեղեկատվական արտադրողները կարող են ամբողջովին կամ մասամբ թաքցնել իրենց ինքնությունը քննարկության ընթացքում: որը հանգեցնում է կիբեր-ագրեսիային և միջանձնական ագրեսիային: Օգտագործողի կողմից ստեղծված պարունակությունը ավտոմատիկ վերահսկելու համար, որպեսզի օգնենք նվազեցնել այն, այսպիսով, շատ տաք թեմա է: Այս թղթի մեջ մենք առաջարկում ենք օգտագործել վերափոխողի հիմնված լեզվի մոդելը BER (Երկու ուղղությամբ կոդավորված ներկայացումը վերափոխողից) (Devin et al., 2019) ագրեսիվ պարունակության հայտնաբերելու համար: Մեր մոդելը նաև օգտագործվում է ագրեսիվության մակարդակի կանխատեսման համար: Այս թղթի գնահատման մասը հիմնված է ԹՌԱԿ-ի ընդհանուր հանձնարարության տվյալների համակարգի վրա (Kuar et al., 2018a). Երբ համեմատեցինք այս ընդհանուր խնդրի մյուս մասնակիցների հետ, մեր մոդելը հասավ երրորդ լավագույն արդյունքին, ըստ ֆեյսբուքի և Թվիթերի հավաքածուների կենտրոնացված F1 չափի:', 'az': "İnsanların əlaqəsi ilə çox yolla sosyal media döyüşündə dəyişdi. Sosyal media tərzlərinin bir hissəsi onların məlumat üreticilerinin müzakirə vaxtında, tamamilə ya da bölünmə gizlənməsi bacarığıdır; sajber-agresiya və şəxsi agresiya təşkil edir. İstifadəçi yaratdığı məlumatı modernizə yardım etmək üçün avtomatik olaraq gözləyir. Beləliklə, bu çox sıcak məlumatdır. Bu kağızda, transformer dil modelini BERT (Transformer'dan ikiyönəlmiş Encoder Representation) (Devlin et al., 2019) istifadə etmək üçün təklif edirik. Bizim modelimiz də agresifik səviyyəsini təmin etmək üçün istifadə edilir. Bu kağıdının değerlendirmə parçası TRAC paylaşılan işlər təyin etdiyi verilənlər qutusuna dayanılır (Kumar et al., 2018a). Bu paylaşılmış işin başqa paylaşıcılarıyla qarşılaşdığında, modellərimiz Facebook və Twitter koleksiyonlarında çəkilmiş F1 ölçüsünə görə üçüncü ən yaxşı performans qəbul etdi.", 'bn': 'যেভাবে মানুষ যোগাযোগ করে সামাজিক প্রচার মাধ্যমের বিপর্যয়ের সাথে অনেক ভাবে পরিবর্তন করেছে। সামাজিক প্রচার মাধ্যমের একটি বিষয় হচ্ছে আলোচনার সময় তাদের তথ্য উৎপাদকদের ক্ষমতা লুকিয়ে রাখা, পুরোপুরি বা অংশে তাদের পর যার ফলে সাইবার-আক্রমণ এবং ব্যক্তিগত আক্রমণ স্বয়ংক্রিয়ভাবে ব্যবহারকারী উৎপাদন করা বিষয়বস্তু পর্যবেক্ষণ করার জন্য এটি অনেক গরম বিষয়। এই কাগজটিতে আমরা প্রস্তাব করছি যে পরিবর্তনের ভিত্তিক ভাষার মডেল বিআরটি (ট্রান্সফার্ন থেকে বাইডেডিয়াল এনকোডার প্রতিনিধি (ডেভিলিন এন্ট এল আমাদের মডেল ব্যবহার করা হয়েছে যে আক্রমণের পরিমাণ ভবিষ্যদ্বাণী করা। এই পত্রিকার অংশের মূল্যের ভিত্তিতে ট্রিএসএ শেয়ার করা কাজের (কুমার এন্টি আল, ২০১৮)। যখন এই শেয়ার কর্মসূচীর অন্যান্য অংশগ্রহণকারীদের তুলনায় আমাদের মডেল ফেসবুক এবং টুইটার সংগ্রহের মাধ্যমে ওজন ফেসবুক ও টুইটারের মাপ', 'bs': 'Način na koji se ljudi komuniciraju promenili su se na mnogim načinama sa uzbuđenjem društvenih medija. Jedan od aspekta društvenih medija je sposobnost da njihovi proizvođa či informacija sakrije, potpuno ili djelomično, njihov identitet tokom rasprave; koji vodi do kiberagresije i međuosobne agresije. Automatski prati sadržaj proizveden korisnikom kako bi pomogla umjeriti to je tako vrlo vruća tema. U ovom papiru predlažemo da koristimo model jezika transformatora BERT (predstavljanje dvosmjernog kodera iz Transformera) (Devlin et al., 2019) kako bi identifikovali agresivni sadržaj. Naš model se također koristi za predviđanje nivoa agresivnosti. Dio procjene ovog papira se temelji na setu podataka predstavljenom podijeljenim zadatkom TRAC-a (Kumar et al., 2018a). U usporedbi s ostalim učesnicima ovog zajedničkog zadatka, naš model je postigao treći najbolji izvor u skladu s mjerom težine F1 na Facebook-u i Twitter-u.', 'cs': 'Způsob komunikace lidí se v mnoha ohledech změnil s propuknutím sociálních médií. Jedním z aspektů sociálních médií je schopnost jejich výrobců informací skrýt, zcela nebo částečně, svou identitu během diskuse; vedoucí k kyberagresi a mezilidské agresi. Automatické sledování obsahu generovaného uživatelem za účelem jeho moderování je tedy velmi žhavým tématem. V tomto článku navrhujeme využít transformátorový jazykový model BERT (Bidirektional Encoder Representation from Transformer) (Devlin et al., 2019) k identifikaci agresivního obsahu. Náš model se také používá k předpovědi úrovně agresivity. Hodnotící část tohoto příspěvku je založena na datové sadě poskytnuté sdíleným úkolem TRAC (Kumar et al., 2018a). Ve srovnání s ostatními účastníky tohoto sdíleného úkolu dosáhl náš model třetího nejlepšího výkonu podle váženého měřítka F1 na kolekcích Facebooku i Twitteru.', 'fi': 'Viestintätapa on muuttunut monin tavoin sosiaalisen median puhkeamisen myötä. Yksi sosiaalisen median näkökulmista on tiedon tuottajien kyky piilottaa kokonaan tai osittain identiteettinsä keskustelun aikana. joka johtaa verkkoaggressioon ja ihmisten väliseen aggressioon. Käyttäjän luoman sisällön automaattinen seuranta sen moderoinnin helpottamiseksi on näin ollen erittäin kuuma aihe. Tässä työssä ehdotamme muuntajapohjaisen kielimallin BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) käyttöä aggressiivisen sisällön tunnistamiseen. Malliamme käytetään myös aggressiivisuuden tason ennustamiseen. Arviointiosa perustuu TRAC:n yhteisen tehtävän (Kumar et al., 2018a) tuottamaan aineistoon. Muihin jaettuun tehtävään osallistuviin verrattuna mallimme saavutti kolmanneksi parhaan tuloksen painotetun F1-mittarin mukaan sekä Facebook- että Twitter-kokoelmissa.', 'ca': "La manera en què la gent es comunica ha canviat de moltes maneres amb l'erupció dels mitjans socials. Un dels aspectes dels mitjans socials és l'habilitat dels seus productors d'informació d'amagar, completament o parcialment, la seva identitat durant una discussió; portant a ciberagressió i agressió interpersonal. Monitoritzar automàticament el contingut generat pels usuaris per ajudar a moderar-lo és un tema molt calent. En aquest article, proposem utilitzar el model de llenguatge basat en el transformador BERT (Representation Bidirectional Encoder from Transformer) (Devlin et al., 2019) per identificar continguts agressius. El nostre model també s'utilitza per predir el nivell d'agressivitat. La part d'evaluació d'aquest paper es basa en el conjunt de dades proporcionat per la tasca compartida TRAC (Kumar et al., 2018a). When compared to the other participants of this shared task, our model achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.", 'et': 'Kuidas inimesed suhtlevad on sotsiaalmeedia puhkemisega mitmel moel muutunud. Sotsiaalmeedia üks aspekte on teabetootjate võime diskussiooni ajal oma identiteeti täielikult või osaliselt varjata; põhjustab küberagressiooni ja isikutevahelist agressiooni. Kasutaja loodud sisu automaatne jälgimine, et aidata seda modereerida, on seega väga kuum teema. Käesolevas töös teeme ettepaneku kasutada trafopõhist keelemudelit BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) agressiivse sisu tuvastamiseks. Meie mudelit kasutatakse ka agressiivsuse taseme prognoosimiseks. Käesoleva dokumendi hindamise osa põhineb TRACi jagatud ülesande andmekogumil (Kumar et al., 2018a). Võrreldes teiste jagatud ülesandega saavutas meie mudel kolmanda parima tulemuse vastavalt kaalutud F1 mõõdule nii Facebooki kui Twitteri kollektsioonis.', 'ha': "Namnan mutane sun musanya a cikin hanyõyi mãsu yawa da tsurin mitandai na jamii. Bayan abu daga mitandai da jamii yana da awon mataimakonsu da ke iya ɓõye, cikakken ko rabon, shaidar su a lokacin da ake yi musu magana; yanada ta sami harassurin cyberi da kibiyoyi na mutane. @ action: button Ga wannan takardan, za'a buƙata amfani da misalin ayukan ayuka da aka saɓa ta BERT (Bi-Directive Encoder Reposition from Transformer) (Devlin et al., 2019) zuwa a gane maɓallin agogo. Ana amfani da misalinmu ke gabani ga leveln suriyar. Ana ƙaddara rabon wannan takardar, a kan asalin da aka ba da shi na TRac mai raba aiki (Kumar et al., 2018a). A lõkacin da aka daidaita da masu haɗi da wannan aikin da aka raba shi, misalinmu ya sami aikin na uku da gwargwadon F1 da aka cika ma'aunin biyu a Facebook da Twitter.", 'sk': 'Način komuniciranja ljudi se je z izbruhom socialnih medijev na več načinov spremenil. Eden od vidikov družbenih medijev je sposobnost njihovih proizvajalcev informacij, da v celoti ali delno skrijejo svojo identiteto med razpravo; ki vodi v kibernetsko agresijo in medosebno agresijo. Samodejno spremljanje vsebin, ki jih ustvarijo uporabniki, da bi jih lahko moderirali, je zato zelo vroča tema. V prispevku predlagamo uporabo transformatorskega jezikovnega modela BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) za identifikacijo agresivne vsebine. Naš model se uporablja tudi za napovedovanje stopnje agresivnosti. Ocenjevalni del tega prispevka temelji na naboru podatkov, ki jih zagotavlja skupna naloga TRAC (Kumar et al., 2018a). V primerjavi z ostalimi udeleženci te skupne naloge je naš model dosegel tretjo najboljšo uspešnost glede na tehtano merilo F1 v zbirkah Facebook in Twitter.', 'jv': 'Awak dhéwé komunikasi éntuk-uwong ngerti dadi iki banget karo sekolahan dolanan sing dirampakan media sotiki. Iki sampeyan karo media sotiné iki kapan kanggo penyataké cercetawake informasi kanggo ngilanggar, sapa-sapa uwong, sampek-sapa ngono sapa-sapa pangan kanggo ngilanggar tarjamahan; dadi donge sembarang-angkang karo akeh saben uwis nêmên. politenessoffpolite"), and when there is a change ("assertivepoliteness Nang pepulan iki, kita supoyo nggawe tresnaning nggawe model model model transformer BERT (Bidirectial modellu iki wis kelompok nggo ngerasai perusahaan podho aksis. Perintah sing dipunanggé uwong iki dipunanggé ning dataset sing ngewehku nggawe TRAK nyelarang nggawe barang (Kumar et al, 2011 8 a). Terasaé mengko karo hal-hal sing nganggo perkaran-wong liyane ing nggawe task-iki, model sing gawe nyimpen tanggal sing tolakan arah sing katêpakan karo hal-iki sing nyimpen F1 sampek karo cokakéwan Google karo Google.', 'he': 'הדרך בה אנשים מתקשרים השתנתה בדרכים רבות עם התפרצות של התקשורת החברתית. אחד היבטים של התקשורת החברתית הוא היכולת למפיק המידע שלהם להסתיר, באופן מלא או חלקי, את זהותם במהלך דיון; leading to cyber-aggression and interpersonal aggression.  מעקב אוטומטי על התוכן שנוצר ע"י משתמשים כדי לעזור להקל אותו הוא נושא מאוד חם. בעיתון הזה, אנו מציעים להשתמש במודל השפה המבוסס על המעבר BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) לזהות תוכן אגרסיבי. Our model is also used to predict the level of aggressiveness.  החלק הערכה של הנייר הזה מבוסס על קבוצת המידע שנספק על ידי המשימה המשותפת של TRAC (Kumar et al., 2018a). בהשוואה לשתתפים האחרים במשימה המשותפת הזו, הדוגמא שלנו השיגה את ההופעה הטובה ביותר השלישית לפי המידד F1 המשובש על אוסף פייסבוק וטוויטר.', 'bo': 'མི་མང་གི་འབྲེལ་མཐུད་དྲ་རྒྱ་ནི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་གི་འཕྱུར་བ་འགྱུར་བ་འགྱུར་བ་རེད། སྤྱི་ཚོགས་འབྲེལ་མཐུད་འཇུག་ཟམ་གྱི་ལྟ་བ་གཅིག་ནི་ཁོང་ཚོའི་གནས་ཚུལ་པོ་བྱེད་མཁན་གྱི་ཆ་ཤིག་ཡིན་ན་ཁོང་ཚོའི་གནས་ཚ དྲ་བར་གསལ་བཅད་དང་སྒེར་གྱི་གཤིས་འགྱུར་བ་གཉིས་ཀྱིས་གཏོང་བྱེད་ཀྱི་ཡོད། རང་འགུལ་གྱིས་སྤྱོད་མཁན་གྱིས་བཟོ་བཅོས་བྱེད་པའི་ནང་དོན འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་གཞི་བརྗོད་པའི་སྐད་རིགས་ཀྱི་མ་དཔེ་གཞི་བྱས་ནས་བེད་སྤྱོད་དགོས། BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) ཡིན་ད ང་ཚོའི་མ་དབྱིབས་ཀྱིས་དྲ་རྒྱ་ཆེ་མཐོང་ཚད་གི་སྔོན་དཔག་བྱེད་ཀྱི་ཡོད། ཤོག་བྱང་འདིའི་གྲངས་སུ་ཞིབ་དཔྱད་ཆ་ནི་TRAC མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་གནད་སྡུད་གཞི་རྟེན་ནས། ང་ཚོའི་མིག་དཔེ་དབྱིབས་འདིའི་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གཞན་པ་དང་མཉམ་དུ་བསྡུར་ན་ང་ཚོའི་མིག་སྔར་སྒྲིག་གི་ལས་འཕར་གསུམ་པ་'}
{'en': 'A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data H indi- E nglish Code-Mixed Data', 'pt': 'Um estudo comparativo de diferentes métodos de detecção de discurso de ódio de última geração em dados mistos de código hindi-inglês', 'ar': 'دراسة مقارنة لمختلف طرق الكشف عن الكلام الذي يحض على الكراهية الحديثة في بيانات مختلطة كود هندية-إنجليزية', 'es': 'Un estudio comparativo de diferentes métodos de detección de discursos de odio de última generación en datos mixtos de código hindi-inglés', 'fr': 'Une étude comparative de différentes méthodes de pointe de détection des discours haineux dans des données mixtes de code Hindi-Anglais', 'ja': 'ヒンディー語と英語のコード混合データにおける最先端のヘイトスピーチ検出法の比較研究', 'zh': '印地语-英语代码-混合数中不同最先进者较之', 'hi': 'हिंदी-अंग्रेजी कोड-मिश्रित डेटा में विभिन्न अत्याधुनिक हेट स्पीच डिटेक्शन विधियों का तुलनात्मक अध्ययन', 'ru': 'Сравнительное исследование различных современных методов обнаружения ненавистнической речи в смешанных данных на хинди и английском языке', 'ga': 'Staidéar Comparáideach ar Mhodhanna Éagsúla úrscothach chun fuathchain a bhrath i sonraí cód-mheasctha Hiondúis-Béarla', 'ka': 'განსხვავებული განსხვავებული განსხვავებული განსხვავებული განსხვავებული განსხვავებული განსხვავებული განსხვავებული მეტოვების განსხვავება ჰინდი-ანგლისური კოდის შესაბამისი მონაცემე', 'hu': 'A különböző korszerű gyűlölet beszédfelismerési módszerek összehasonlító tanulmánya hindi-angol kód-vegyes adatokban', 'el': 'Μια συγκριτική μελέτη διαφορετικών σύγχρονων μεθόδων ανίχνευσης ομιλίας μίσους σε δεδομένα μικτού κώδικα Χίντι-Αγγλικού', 'it': "Uno studio comparativo dei diversi metodi di rilevazione del discorso d'odio all'avanguardia in Hindi-English Code-Mixed Data", 'kk': 'Хинди-ағылшын код араластырылған деректерінің айырмашылық күйінің жұмыс сөздерін анықтау әдістерін салыстыру', 'lt': 'Lyginamasis skirtingų kalbų apie neapykantą nustatymo metodų, taikomų anglų-hindų kodų mišiniuose duomenise, lyginamasis tyrimas', 'mk': 'Спаративна студија на различни методи за детектирање на говорот за омраза во хинди-англиски код мешани податоци', 'ms': 'Name', 'mn': 'Хинди-Англи хэлний код-холбогдсон өгөгдлийн хувьд өөр төрлийн улс-урлагийн хэт хэт хэлэлцээний судалгааны харьцуулсан судалгаа', 'mt': 'A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data', 'ml': 'ഹിന്ദി- ഇംഗ്ലീഷ്- കോഡ്- മിക്സഡ് ഡേറ്റായിലെ വ്യത്യസ്ത സ്റ്റേറ്റ്- ഓഫ്- ആർട്ട് വെറുപ്പുള്ള വാക്ക് ഡിറ്റീഷന്\u200d ര', 'no': 'Name', 'ro': 'Un studiu comparativ al diferitelor metode de detectare a discursului de ură de stat-of-the-art în limba hindi-engleză cod-mixt date', 'pl': 'Porównawcze badanie różnych najnowocześniejszych metod wykrywania mowy nienawiści w danych mieszanych kodem hindi-angielskim', 'sr': 'Upravo ispitivanje različitih metoda otkrivanja reči mržnje u indijskom-engleskom kodeksu', 'si': 'A comparison study of Differnt state-of-the-Art Hate Talk Detection Metodos in Hindi-English Code-Missed Data', 'so': 'A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data', 'sv': 'En jämförande studie av olika state-of-the-art hattalsdetekteringsmetoder i hindi-engelska kodblandade data', 'ta': 'Name', 'ur': 'ہندی-انگلیسی کوڈ-میکس ڈاٹ میں مختلف ایٹیٹ-از-آرت hate speech detection methodologies کے مقابلہ تحقیق', 'uz': 'Name', 'vi': 'Một cuộc nghiệp biểu diễn biệt thời đại quốc của bang khác về thuật thời đại hướng bằng Tiếng Thái', 'bg': 'Сравнително проучване на различни методи за откриване на речта на омразата в хинди-английски кодово смесени данни', 'da': 'En sammenlignende undersøgelse af forskellige state-of-the-art hade tale detektion metoder i hindi-engelsk kode-blandede data', 'nl': 'Een vergelijkende studie naar verschillende state-of-the-art methoden voor haatspraak detectie in Hindi-Engels code-gemengde data', 'hr': 'Upravo ispitivanje različitih metoda otkrivanja govora mržnje u indijskom-engleskom kodeksu', 'fa': 'مطالعه مقایسه\u200cای از روش\u200cهای شناسایی سخنرانی دشمنی هندی-انگلیسی متفاوت', 'de': 'Eine vergleichende Studie verschiedener State-of-the-Art Methoden zur Erkennung von Hassreden in Hindi-Englisch Code-Mixed Daten', 'id': 'Sebuah Studi Comparative of Different State-of-the-Art Speech Detection Methods in Hindi-English Code-Mixed Data', 'ko': '인디언-영어 코드 혼합 데이터 중 서로 다른 증오 음성 검출 방법의 비교 연구', 'tr': 'Hindi-iňlisçe Däpli Haltany Hata sözlerini gözlemek üçin Hindi-iňlisçe Däpli Maglumatlar', 'af': "'n Vergelyk Studie van Verskillende State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data", 'sw': 'Utafiti wa Kilinganisha wa Taifa tofauti ya Kuchunguza Hotuba za Kisanaa katika Taarifa zilizotenganishwa kwa Kiingereza', 'sq': 'Një studim krahasues i metodave të ndryshme të zbulimit të fjalëve të urrejtjes në kod të përzier Hindi-English', 'az': 'Hindi-İngilizci Kod-Karıştırılmış Verilərin Müxtəlif Eyalet-in-the-Art Hate Speech Detection Methods in Comparison Study of Different State-of-the-Art Hate Speech Detection', 'bn': 'হিন্দি-ইংরেজি কোড-মিক্সেড ডাটাতে বিভিন্ন রাষ্ট্র-অফ-আর্টের ঘৃণা বাক বক্তৃতা ডিটেক্টরেশনের একটি তুলনামূলক গবেষণা', 'am': 'የልዩ ሀገር-of-the-Art-Hate Speech Detection methods in Hindi-English Code-Mixed Data', 'hy': 'Հինդի-անգլերենի կոդի խառնված տվյալների տարբեր ատելության նախագծման մեթոդների համեմատական ուսումնասիրությունը', 'ca': "Un estudi comparatiu de diferents mètodes de detecció de discurs d'odi d'última generació en dades mixtes de codi hindí-anglès", 'cs': 'Srovnávací studie různých nejmodernějších metod detekce nenávisti řeči v hindštině-anglickém kódu', 'et': 'Erinevate kaasaegsete vihakõne tuvastamise meetodite võrdlev uuring hindi-inglise koodsega andmetes', 'bs': 'U usporednom ispitivanju različitih metoda otkrivanja reči mržnje u indijskom-engleskom kodeksu', 'fi': 'Vertaileva tutkimus erilaisista viimeisimpistä vihapuheen havaitsemismenetelmistä hindi-englantilaisessa koodisekoitetussa datassa', 'sk': 'Primerjalna študija različnih najsodobnejših metod odkrivanja sovražnega govora v hindujsko-angleškem kodnem mešanem podatku', 'he': 'מחקר משווה של שיטות גילוי שנאה שונות במדינה המאומנת', 'ha': 'KCharselect unicode block name', 'jv': 'Samsul ujaran kanggo langgambar luwih-luwih-luwih-luwih basa gambar-kanggo ngerasai barang-ingles', 'bo': 'རྒྱ་ནག་མིའི་ནང་གི་སྔོན་ལྟའི་གནས་སྟངས་དཀའ་བ་བཀོད་པའི་ཐབས་ལམ་ལ་བཟོ་བཅོས་ནི།'}
{'en': 'Hate speech detection in  social media communication  has become one of the primary concerns to avoid conflicts and curb undesired activities. In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora. In our work, we attempt to analyze, detect and provide a comparative study of  hate speech  in a code-mixed social media text. We also provide a Hindi-English code-mixed data set consisting of Facebook and Twitter posts and comments. Our experiments show that  deep learning models  trained on this code-mixed corpus perform better.', 'pt': 'A detecção de discurso de ódio na comunicação em mídias sociais tornou-se uma das principais preocupações para evitar conflitos e coibir atividades indesejadas. Em um ambiente em que falantes multilíngues alternam entre vários idiomas, a detecção de discurso de ódio se torna uma tarefa desafiadora usando métodos projetados para corpora monolíngues. Em nosso trabalho, tentamos analisar, detectar e fornecer um estudo comparativo do discurso de ódio em um texto de mídia social com código misto. Também fornecemos um conjunto de dados misto de código hindi-inglês que consiste em postagens e comentários do Facebook e Twitter. Nossos experimentos mostram que os modelos de aprendizado profundo treinados neste corpus de código misto têm melhor desempenho.', 'es': 'La detección del discurso de odio en la comunicación en las redes sociales se ha convertido en una de las principales preocupaciones para evitar conflictos y frenar actividades no deseadas. En un entorno en el que los hablantes multilingües cambian entre varios idiomas, la detección de la incitación al odio se convierte en una tarea difícil mediante el uso de métodos diseñados para cuerpos monolingües. En nuestro trabajo, intentamos analizar, detectar y proporcionar un estudio comparativo de la incitación al odio en un texto de redes sociales con código mixto. También ofrecemos un conjunto de datos de código hindi-inglés que consta de publicaciones y comentarios de Facebook y Twitter. Nuestros experimentos muestran que los modelos de aprendizaje profundo entrenados en este corpus de código mixto funcionan mejor.', 'ar': 'أصبح اكتشاف الكلام الذي يحض على الكراهية في وسائل التواصل الاجتماعي أحد الاهتمامات الأساسية لتجنب النزاعات وكبح الأنشطة غير المرغوب فيها. في بيئة يتنقل فيها المتحدثون متعددو اللغات بين لغات متعددة ، يصبح اكتشاف الكلام الذي يحض على الكراهية مهمة صعبة باستخدام طرق مصممة للجماعات أحادية اللغة. في عملنا ، نحاول تحليل خطاب الكراهية واكتشافه وتقديم دراسة مقارنة له في نصوص وسائط اجتماعية مختلطة برمز. نوفر أيضًا مجموعة بيانات مختلطة من الأكواد الهندية والإنجليزية تتكون من منشورات وتعليقات على Facebook و Twitter. تُظهر تجاربنا أن نماذج التعلم العميق المُدرَّبة على هذه المجموعة المختلطة من الأكواد تؤدي أداءً أفضل.', 'fr': "La détection des discours haineux dans la communication sur les réseaux sociaux est devenue l'une des principales préoccupations pour éviter les conflits et freiner les activités indésirables. Dans un environnement où les locuteurs multilingues basculent entre plusieurs langues, la détection des discours haineux devient une tâche ardue à l'aide de méthodes conçues pour les corpus monolingues. Dans notre travail, nous tentons d'analyser, de détecter et de fournir une étude comparative du discours de haine dans un texte de médias sociaux à code mixte. Nous fournissons également un ensemble de données mixtes hindi-anglais composé de publications et de commentaires Facebook et Twitter. Nos expériences montrent que les modèles d'apprentissage profond formés sur ce corpus mixte de codes fonctionnent mieux.", 'zh': '社交媒体通信之仇言,检为避突遏不良活动之大关注点。 多言使用者切换于多种语言之间,用专为单语语料库计之法,仇言检为一挑战性之任。 于我之事,我试图之,检给代码混社交媒体文本仇言者较之。 给一印地语 - 英语代码混合数集,FacebookTwitter帖论。 吾实验明代码混合语料库上深习模则善。', 'ja': 'ソーシャルメディアのコミュニケーションにおけるヘイトスピーチ検出は、紛争を回避し、望ましくない活動を抑制するための主要な懸念事項の1つとなっています。多言語話者が複数の言語を切り替える環境では、ヘイトスピーチ検出は、単一言語のコーラのために設計された方法を使用して困難な課題となる。私たちの研究では、コードが混在したソーシャルメディアテキストにおけるヘイトスピーチの比較研究を分析、検出、提供しようとしています。また、FacebookとTwitterの投稿とコメントからなるヒンディー語と英語のコードミックスデータセットも提供しています。私たちの実験は、このコード混合コーパスでトレーニングされたディープラーニングモデルがより良いパフォーマンスを発揮することを示しています。', 'hi': 'सोशल मीडिया संचार में हेट स्पीच डिटेक्शन संघर्षों से बचने और अवांछित गतिविधियों को रोकने के लिए प्राथमिक चिंताओं में से एक बन गया है। एक ऐसे वातावरण में जहां बहुभाषी वक्ताओं कई भाषाओं के बीच स्विच करते हैं, हेट स्पीच डिटेक्शन उन तरीकों का उपयोग करके एक चुनौतीपूर्ण कार्य बन जाता है जो मोनोलिंगुअल कॉर्पोरेट के लिए डिज़ाइन किए गए हैं। हमारे काम में, हम एक कोड-मिश्रित सोशल मीडिया पाठ में नफरत भरे भाषण का विश्लेषण, पता लगाने और तुलनात्मक अध्ययन प्रदान करने का प्रयास करते हैं। हम एक हिंदी-अंग्रेजी कोड-मिश्रित डेटा सेट भी प्रदान करते हैं जिसमें फेसबुक और ट्विटर पोस्ट और टिप्पणियां शामिल हैं। हमारे प्रयोगों से पता चलता है कि इस कोड-मिश्रित कॉर्पस पर प्रशिक्षित गहरे सीखने के मॉडल बेहतर प्रदर्शन करते हैं।', 'ru': 'Обнаружение ненавистнической речи в социальных сетях стало одной из главных забот, чтобы избежать конфликтов и обуздать нежелательную деятельность. В среде, где многоязычные говорящие переключаются между несколькими языками, обнаружение ненавистнической речи становится сложной задачей, используя методы, разработанные для одноязычных корпусов. В своей работе мы пытаемся проанализировать, обнаружить и предоставить сравнительное исследование ненавистнических высказываний в кодово-смешанном тексте в социальных сетях. Мы также предоставляем смешанный набор данных на хинди и английском языке, состоящий из постов и комментариев в Facebook и Twitter. Наши эксперименты показывают, что модели глубокого обучения, обученные на этом корпусе со смешанным кодом, работают лучше.', 'ga': 'Tá braiteadh fuatha cainte i gcumarsáid na meán sóisialta ar cheann de na príomhábhair imní anois chun coinbhleachtaí a sheachaint agus srian a chur ar ghníomhaíochtaí neamh-inmhianaithe. I dtimpeallacht ina n-aistríonn cainteoirí ilteangacha i measc teangacha iolracha, is tasc dúshlánach é fuathchainte a bhrath trí úsáid a bhaint as modhanna atá deartha le haghaidh corpóra aonteangach. Inár gcuid oibre, déanaimid iarracht staidéar comparáideach ar chaint fuatha a anailísiú, a bhrath agus a sholáthar i dtéacs cód-mheasctha meán sóisialta. Soláthraímid freisin tacar sonraí cód-mheasctha Hiondúis-Béarla ina bhfuil postálacha agus tuairimí Facebook agus Twitter. Léiríonn ár dturgnaimh go n-éiríonn níos fearr le samhlacha domhainfhoghlama atá oilte ar an gcorpas cód-mheasctha seo.', 'el': 'Η ανίχνευση λόγου μίσους στην επικοινωνία στα μέσα κοινωνικής δικτύωσης έχει γίνει μια από τις κύριες ανησυχίες για την αποφυγή συγκρούσεων και τον περιορισμό ανεπιθύμητων δραστηριοτήτων. Σε ένα περιβάλλον όπου πολύγλωσσοι ομιλητές αλλάζουν μεταξύ πολλών γλωσσών, η ανίχνευση φωνής μίσους γίνεται μια πρόκληση χρησιμοποιώντας μεθόδους που έχουν σχεδιαστεί για μονογλωσσικά σώματα. Στην εργασία μας, επιχειρούμε να αναλύσουμε, να εντοπίσουμε και να παρέχουμε μια συγκριτική μελέτη της ρητορικής μίσους σε ένα κείμενο των μέσων κοινωνικής δικτύωσης με μικτό κώδικα. Παρέχουμε επίσης ένα σύνολο δεδομένων από ινδικό-αγγλικό κώδικα που αποτελείται από δημοσιεύσεις και σχόλια στο Facebook και στο Twitter. Τα πειράματά μας δείχνουν ότι τα μοντέλα βαθιάς μάθησης που εκπαιδεύονται σε αυτό το σώμα με μικτό κώδικα αποδίδουν καλύτερα.', 'ka': 'სოციალური მედიაციის კომუნიკაციაში წარმოადგენების განსახულება ხდება ერთი პირველური დარწმუნებაში, რომ გამოწვება კონფლიქტები და გამოწვება განსახულებული ე მრავალენგური სიტყვარები მრავალენგური სიტყვარებისთვის გადაცვლენ, მრავალენგური სიტყვარების გამოყენება შესაძლებელი რაოდენობა, რომელიც მონოლენგური კორპორ ჩვენი სამუშაოში, ჩვენ ვცდილობთ ანალიზაცია, განაკვირთვა და გავაკეთოთ კონფირეტური სამუშაო სოციალური მედია ტექსტის კონფირეტური კითხვა. ჩვენ ასევე ინდლისური კოდენტიკური მონაცემების კოდენტიკური კოდენტიკური კოდენტიკური კოდენტიკური კოდენტიკური კოდენტიკური დავყენ ჩვენი ექსპერიმენტები აჩვენებენ, რომ ძალიან სწავლების მოდელები, რომლებიც ამ კოპპუსს შემდეგ შემდეგ გავაკეთებენ უფრო მეტი.', 'hu': 'A gyűlöletbeszéd felismerése a közösségi média kommunikációban az egyik legfontosabb problémává vált a konfliktusok elkerülése és a nemkívánatos tevékenységek megfékezése érdekében. Egy olyan környezetben, ahol a többnyelvű beszélők több nyelv között váltanak, a gyűlöletbeszéd felismerése kihívást jelentő feladattá válik az egynyelvű korpuszokra tervezett módszerekkel. Munkánk során megpróbáljuk elemezni, felismerni és összehasonlító tanulmányt nyújtani a gyűlöletbeszédről egy kódkevert közösségi média szövegben. Hindi-angol kódkevert adatkészletet is biztosítunk, amely Facebook és Twitter bejegyzésekből és megjegyzésekből áll. Kísérleteink azt mutatják, hogy az erre a kódkevert korpuszra képzett mélytanulási modellek jobban teljesítenek.', 'lt': 'Hate speech detection in social media communication has become one of the primary concerns to avoid conflicts and curb undesired activities.  Aplinkoje, kurioje daugiakalbiai kalbėtojai keičiasi įvairiomis kalbomis, neapykantos kalbos aptikimas tampa sunkia užduotimi taikant metodus, skirtus vienakalbei korpūrai. Mūsų darbe bandome analizuoti, aptikti ir pateikti lyginamąjį neapykantos kalbos tyrimą su kodais mišriu social in ės žiniasklaidos tekstu. Mes taip pat pateikiame Hindi ir anglų kodų mišrų duomenų rinkinį, sudarytą iš Facebook ir Twitter postų ir komentarų. Mūsų eksperimentai rodo, kad gilaus mokymosi modeliai, apmokyti ant šito kodų mišraus korpuso, geriau veikia.', 'kk': 'Әлеуметтік медиақпараттың байланысында сөйлейтін сөйлейтінің негізгі маңыздығы болды. Көптілік тілдерді бірнеше тілдерге ауыстыру ортасында, сөйлерді анықтау үшін бірнеше тілді корпора үшін құрылған әдістерді қолдану үшін көпшілікті тапсырма болады. Біздің жұмысымызда, код арасындағы социалдық медиа мәтінде салыстырмалы сөздерді анализ, анықтау және салыстырмалы зерттеуді қолданамыз. Мұндай-ағылшын тілінде Фейсбук, Твиттер және түсініктемелерден туралы ханды-ағылшын код араластырылған деректер жиынын қамтамасыз. Біздің тәжірибеміз осы кодты аралас корпус үшін оқыту үлгілерін жақсы жұмыс істейтінін көрсетеді.', 'it': "Il rilevamento del discorso d'odio nella comunicazione sui social media è diventato una delle preoccupazioni principali per evitare conflitti e frenare attività indesiderate. In un ambiente in cui i parlanti multilingue passano da più lingue, il rilevamento del discorso d'odio diventa un compito impegnativo utilizzando metodi progettati per corpora monolingue. Nel nostro lavoro, cerchiamo di analizzare, rilevare e fornire uno studio comparativo del discorso di odio in un testo di social media codificato. Forniamo anche un set di dati misto di codice hindi-inglese composto da post e commenti su Facebook e Twitter. I nostri esperimenti dimostrano che i modelli di deep learning formati su questo corpus misto di codice funzionano meglio.", 'mk': 'Детектирањето на говорот на омраза во комуникацијата со социјалните медиуми стана една од главните загрижености за избегнување конфликти и ограничување на нежелбите активности. Во средина каде мултијазичните говорници се менуваат меѓу повеќето јазици, детекцијата на говорот на омраза станува предизвикувачка задача користејќи методи кои се дизајнирани за монојазични корпора. Во нашата работа, се обидуваме да анализираме, детектираме и обезбедиме споредлива студија на говорот на омраза во текст на социјалните медиуми со код. Ние, исто така, обезбедуваме ханди-англиски мешан набор на податоци кој се состои од постови и коментари на Фејсбук и Твитер. Нашите експерименти покажуваат дека моделите за длабоко учење обучени на овој код-мешан корпус се подобри.', 'ms': 'Pengesanan ucapan benci dalam komunikasi media sosial telah menjadi salah satu kebimbangan utama untuk menghindari konflik dan menghalang aktiviti tidak diingini. Dalam persekitaran di mana pembicara berbilang bahasa bertukar di antara bahasa berbilang, pengesan ucapan benci menjadi tugas yang mencabar menggunakan kaedah yang direka untuk korpra monobahasa. Dalam kerja kami, kami cuba untuk menganalisis, mengesan dan menyediakan kajian perbandingan tentang ucapan kebencian dalam teks media sosial bercampur kod. Kami juga menyediakan set data campuran kod Hindi-Inggeris yang terdiri dari pos Facebook dan Twitter dan komentar. Eksperimen kami menunjukkan bahawa model belajar dalam dilatih pada kod-campuran corpus ini berjalan lebih baik.', 'ml': 'Hate speech detection in social media communication has become one of the primary concerns to avoid conflicts and curb undesired activities.  പല ഭാഷകളുടെ ഇടയില്\u200d പല ഭാഷകള്\u200d സംസാരിക്കുന്ന ഒരു പരിസ്ഥിതിയില്\u200d, വെറുപ്പ് സംസാരിക്കുന്നത് വെറുപ്പ് സംസാരിക്കുന്നത് മോനോ നമ്മുടെ ജോലിയില്\u200d നമ്മള്\u200d ശ്രമിക്കുന്നു, കണ്ടുപിടിക്കുകയും വെറുപ്പ് സംസാരിക്കുന്നതിനെ താല്\u200dപര്യമായി പഠിപ്പിക ഫെസ്ക്കും ട്രൂട്ടര്\u200d പോസ്റ്റുകളും കണക്കുനോക്കുന്ന ഹിന്ദി-ഇംഗ്ലീഷ് കോഡ് മിഷ്ടപ്പെട്ട ഡാറ്റാ സെറ നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് ഈ കോഡ് മിക്കില്\u200d പഠിക്കുന്ന ഗുരുതരമായ മോഡലുകള', 'mt': 'L-individwazzjoni tad-diskors ta’ mibegħda fil-komunikazzjoni tal-midja soċjali saret waħda mit-tħassib primarju biex jiġu evitati kunflitti u jitrażżnu l-attivitajiet mhux mixtieqa. F’ambjent fejn il-kelliema multilingwi jaqilbu fost diversi lingwi, id-detezzjoni tad-diskors tal-mibegħda ssir kompitu ta’ sfida bl-użu ta’ metodi mfassla għal korpura monolingwi. Fil-ħidma tagħna, a ħna nippruvaw tanalizzaw, niskopru u nipprovdu studju komparattiv tad-diskors tal-mibegħda f’test tal-midja soċjali mħallat bil-kodiċi. Aħna nipprovdu wkoll sett ta’ dejta mħallat mal-kodiċi Indjan-Ingliż li jikkonsisti minn postijiet u kummenti fuq Facebook u Twitter. L-esperimenti tagħna juru li mudelli ta’ tagħlim profond imħarrġa fuq dan il-korpus imħallat bil-kodiċi jwettqu aħjar.', 'mn': 'Нийгмийн хэвлэлийн мэдээллийн холбоотой хэлэлцээний үзэн ядуурлын нээлт нь зөрчилдөөнөөс, хүсээгүй үйл ажиллагаанаас зогсохын тулд анхны асуудал болсон. Олон хэл хэлний яриачдын олон хэлний хооронд өөрчлөгдөж байгаа орчинд үзэн ядуурлын яриаг олох нь нэг хэлний корпора-д зориулагдсан аргыг ашиглан хэцүү ажил болно. Бид ажлын хувьд код холбогдсон нийгмийн мэдээллийн текст дээр үзэн ядуурлын ярианы харьцуулалтын судалгааг шинжилгээ, олж мэдэхэд хичээдэг. Бид мөн Хинди-Англи хэлний код холбогдсон өгөгдлийн санг Фейсбук, Твиттерийн захидал, сэтгэл дүрслэлүүдийн тусламжтай гаргадаг. Бидний туршилтууд энэ кодлого холбогдсон корпус дээр сургалтын гүнзгий суралцах загварууд илүү сайн хийдэг.', 'no': 'Hent oppdaging av tale i sosiale media-kommunikasjon har blitt ein av dei primære bekymringane for å unngå konflikt og kurb utvalde aktivitetar. I eit miljø der fleire språkstaler byter mellom fleire språk, blir hatt oppdaging av språk ein vanskeleg oppgåve ved hjelp av metodar som er laga for monospråkskorpa. I arbeidet vårt prøver vi å analysera, oppdaga og gjera ei sammenlignbare studie av hatespråk i eit tekst med kode-blandet sosialmedia. Vi tilbyr også ein hindisk-engelsk kode-blandet data set som inneheld Facebook-og Twitter-post og kommentarar. Eksperimentane våre viser at dype læringsmodeller som trengte på denne mellom korpusen utfører bedre.', 'pl': 'Wykrywanie mowy nienawiści w komunikacji w mediach społecznościowych stało się jednym z głównych problemów unikania konfliktów i ograniczania niepożądanych działań. W środowisku, w którym wielojęzyczni mówcy przełączają się między wieloma językami, wykrywanie mowy nienawiści staje się trudnym zadaniem przy użyciu metod przeznaczonych dla jednojęzycznych korpusów. W naszej pracy staramy się analizować, wykrywać i przeprowadzić porównawcze badanie mowy nienawiści w tekście mieszanym kodem w mediach społecznościowych. Udostępniamy również hindi-angielski zestaw danych z kodem mieszanym, składający się z postów i komentarzy na Facebooku i Twitterze. Nasze eksperymenty pokazują, że modele głębokiego uczenia trenowane na tym korpusie mieszanym kodem działają lepiej.', 'ro': 'Detectarea discursului de ură în comunicarea social media a devenit una dintre preocupările principale pentru evitarea conflictelor și limitarea activităților nedorite. Într-un mediu în care vorbitorii multilingvi comută între mai multe limbi, detectarea vorbirii la ură devine o sarcină dificilă folosind metode concepute pentru corpore monolingve. În munca noastră, încercăm să analizăm, să detectăm și să oferim un studiu comparativ al discursului de ură într-un text de social media amestecat cu coduri. De asemenea, vă oferim un set de date combinat de coduri hindi-engleză format din postări și comentarii pe Facebook și Twitter. Experimentele noastre arată că modelele de învățare profundă instruite pe acest corpus mixt de coduri performează mai bine.', 'sr': 'Otkrivanje govora mržnje u komunikaciji društvenih medija postalo je jedna od glavnih briga za izbjegavanje sukoba i izbjegavanje nevidljivih aktivnosti. U okruženju gde se višejezički govornici mijenjaju među višejezicima, otkrivanje govora mržnje postaje izazovni zadatak koristeći metode koje su dizajnirane za monojezičku korporu. U našem poslu pokušavamo analizirati, otkriti i pružiti usporednu studiju govora mržnje u tekstu socijalnih medija. Takođe pružamo indijski-engleski kompleks podataka koji se sastoje od Facebook i Twitter postova i komentara. Naši eksperimenti pokazuju da duboki modeli učenja obučeni na ovom korpusu mešanom kodu bolje izvode.', 'si': 'සාමාජික මිඩියාව සම්බන්ධයේ කතාව හොයාගන්න ප්\u200dරධාන ප්\u200dරශ්නයක් වෙලා තියෙන්නේ ප්\u200dරධාන ප්\u200dරශ්නයක් සහ විශාල භාෂාවක් කතාකරුවන් විශාල භාෂාවක් වලින් වෙනස් කරනවා, වෛර කතාවක් හොයාගන්න ප්\u200dරශ්නයක් වෙනවා වගේ ප අපේ වැඩේ අපි විශ්ලේෂණය, පරීක්ෂණය, පරීක්ෂණය සහ සාමාජික මාධ්\u200dයම පාළුවක් විශ්ලේෂණය කරන්න උත්සාහ කරනවා. අපි හින්දි-ඉංග්\u200dරීසි කෝඩ් මික්ස් තොරතුරු සම්බන්ධ කරනවා ෆේස්බුක් සහ ට්විටර් පොස්ට් සහ ප්\u200dරත අපේ පරීක්ෂණය පෙන්වන්නේ ගොඩක් ඉගෙන ගන්න ප්\u200dරශ්නයක් මේ කෝඩ් මික්ස් කොර්පුස් එක්ක හොඳයි.', 'so': 'Hadal nacayb ah oo ku saabsan xiriirka shabakadda bulshada ayaa noqday mid ka mid ah khatar ugu horeeya si uu ka ilaaliyo muran iyo habboon waxqabad aan la falin. Xiriir ay ku leeyihiin hadal luuqado badan oo luuqado kala duduwan, aqoonta hadalka nebcaaddu wuxuu noqon karaa shaqo dhibaato leh oo lagu isticmaalo qaabab loo sameeyo shirkadaha muuqaalka ah. Waxaynu isku dayaynaa in aan wax analyeyno, baaritaanno, waxaynu sameynaa waxbarasho la baro hadalka nebcaadiga ah oo ku qoran qoraal macluumaadka bulshada. Waxaynu sidoo kale siinaynaa kooban macluumaad ku qoran kooxaha aqoonsiga Ingiriiska ee Hindi-Ingiriis, kaas oo ka mid ah buugaagta Facebook iyo Twitter iyo commentarka. Imtixaankayada waxay muuqataa in qaababka waxbarashada mool dheer lagu baray kooxdan isku xiran ay si wanaagsan u sameeyaan.', 'sv': 'Detektering av hattal i sociala medier har blivit en av de främsta problemen att undvika konflikter och begränsa oönskade aktiviteter. I en miljö där flerspråkiga talare växlar mellan flera språk blir hattalsdetektering en utmanande uppgift med metoder som är utformade för enspråkiga korpor. I vårt arbete försöker vi analysera, upptäcka och tillhandahålla en jämförande studie av hatpropaganda i en kodblandad social media text. Vi tillhandahåller också en hindi-engelsk kodblandad datauppsättning bestående av Facebook och Twitter inlägg och kommentarer. Våra experiment visar att djupinlärningsmodeller tränade på denna kodblandade korpus presterar bättre.', 'ta': 'வெறுப்பு பேச்சு கண்டுபிடிப்பு சமூக ஊடக தொடர்புகளில் ஒரு முதன்மையான கவலையாகிவிட்டது குழப்பங்களை மற்றும் பாது பல மொழி பேசுபவர்கள் பல மொழிகளுக்கு இடையே மாறும் சூழலில், வெறுப்பு பேச்சு கண்டுபிடிப்பது ஒரு சவாலிக்கான செயலாகும், மொத்த மொழி எங்கள் வேலையில், நாங்கள் ஒரு குறியீடு கலக்கப்பட்ட சமூக ஊடக உரையில் வெறுப்பு பேச்சின் ஒப்பிட்ட படிப்பாட்டை வழங்க மு நாம் ஒரு ஹின்டி- ஆங்கிலத்தின் குறியீடு கலக்கப்பட்ட தகவல் அமைப்பை வழங்குகிறோம் Facebook மற்றும் Twitter posts and comments. எங்கள் சோதனைகள் இந்த குறியீடு கலந்த கோர்ப்ஸில் பயிற்சி ஆழமான கற்ற மாதிரிகளை காட்டுகிறது என்று.', 'ur': 'سوسیل میڈیا ارتباط میں سخنرانی کی تلاش کی ناپسند کی وجہ سے مخالفت اور ناپسند فعالیتوں سے بچنے کے لئے سب سے زیادہ مشکل ہو گیا ہے۔ ایک محیط میں جہاں بہت سی زبان بولنے والے بہت سی زبانوں میں تبدیل ہوتے ہیں، نفرت بولنے کی شناسایی ایک مشکل کام ہوتی ہے جو ایک زبان بولنے کے لئے طراحی کی جاتی ہیں. ہمارے کام میں، ہم ایک کوڈ میڈیا متصلہ متن میں ناپسندیدہ بات کا مقایسہ تحقیق کرنا، شناسایا اور تحقیق کرنے کی کوشش کرتے ہیں. ہم نے ایک ہندی انگلیسی کوڈ میکسٹ ڈیٹ سٹ کو فیس بوک اور ٹویٹر پوسٹ اور ٹوکیٹ ٹوکیٹ میں شامل کیا ہے۔ ہماری آزمائش دکھاتی ہے کہ اس کوڈ میکس کورپوس پر تعلیم کی عمیق سیکھنے کی مدل بہتر عمل کرتی ہے.', 'uz': "Name Ko'pchilik tillar bir necha tillar orqali o'zgartirib turgan muhimda, yolg'on tilni o'zgartirish qiyin qiladi, o'z monolik kompaniyalar uchun yaratilgan usullarni ishlatish mumkin. Biz ishimizda, biz qo'shilgan jamiyat media matnini aniqlash, aniqlashni ko'rib chiqqamiz va o'qishni o'rganamiz. Biz esa Facebook, Twitter postlari ва comments kabi Hindi- Ingliz kodi minglab maʼlumot tarkibini yaratdik. Bizning tajribalarimiz bu kodlash qoidadagi o'rganish modellari yaxshi ishlaydi.", 'vi': 'Nhận diện ngôn ngữ căm ghét trong thông tin truyền thông xã hội đã trở thành mối quan tâm chính để tránh xung đột và kiềm chế hoạt động không được mong đợi. Trong một môi trường nơi những người nói ngôn ngữ đa dạng, việc phát hiện ngôn ngữ ghét biến thành một nhiệm vụ khó khăn bằng các phương pháp được thiết kế cho cơ thể ngôn ngữ. Trong công việc của chúng tôi, chúng tôi cố gắng phân tích, phát hiện và cung cấp một nghiên cứu về tiếng nói thù ghét trong một văn bản xã hội. Chúng tôi cung cấp một bộ dữ liệu trộn nhỏ tiếng Hindi gồm các bài viết trên Facebook và Twitter và các câu trả lời. Những thí nghiệm của chúng tôi cho thấy những mô hình học sâu được rèn luyện trên cơ thể hỗn hợp này tốt hơn.', 'bg': 'Откриването на речта на омразата в социалните медии се превърна в една от основните грижи за избягване на конфликти и ограничаване на нежеланите дейности. В среда, в която многоезичните говорители превключват между няколко езика, откриването на речта на омразата се превръща в трудна задача, използвайки методи, предназначени за едноезични корпуси. В нашата работа се опитваме да анализираме, откриваме и предоставяме сравнително изследване на речта на омразата в кодово смесен текст в социалните медии. Ние също така предоставяме хинди-английски кодово смесен набор от данни, състоящ се от публикации и коментари във Фейсбук и Туитър. Нашите експерименти показват, че моделите на дълбоко обучение, обучени по този кодово смесен корпус, се представят по-добре.', 'hr': 'Otkrivanje govora mržnje u komunikaciji društvenih medija postalo je jedna od glavnih zabrinutosti kako bi izbjegao sukobe i izbjegao nevidljive aktivnosti. U okruženju gdje višejezički govornici mijenjaju među višejezicima, otkrivanje govora mržnje postaje izazovni zadatak koristeći metode dizajnirane za monojezičku korporu. U našem poslu pokušavamo analizirati, otkriti i pružiti usporedno ispitivanje govora mržnje u tekstu društvenih medija u kodima. Također predstavljamo indijski-engleski broj podataka koji se sastoje od Facebook-a i Twitter-a i komentara. Naši eksperimenti pokazuju da duboki modeli učenja obučeni na ovom kombiniranom korpusu izvršavaju bolje.', 'da': 'Detektering af hadefulde taler i kommunikation på sociale medier er blevet en af de primære bekymringer for at undgå konflikter og bremse uønskede aktiviteter. I et miljø, hvor flersprogede talere skifter mellem flere sprog, bliver hadeforståelse en udfordrende opgave ved hjælp af metoder, der er designet til ensprogede korpora. I vores arbejde forsøger vi at analysere, opdage og levere en komparativ undersøgelse af hadefuldtale i en kode-blandet tekst på sociale medier. Vi leverer også et hindi-engelsk kodeblandet datasæt bestående af Facebook- og Twitter-indlæg og kommentarer. Vores eksperimenter viser, at deep learning modeller trænet på dette kode-blandede korpus fungerer bedre.', 'nl': 'Hate speech detectie in social media communicatie is uitgegroeid tot een van de belangrijkste aandachtspunten om conflicten te voorkomen en ongewenste activiteiten tegen te gaan. In een omgeving waar meertalige sprekers schakelen tussen meerdere talen, wordt haatspraakdetectie een uitdagende taak met behulp van methoden die zijn ontworpen voor eentalige corpora. In ons werk proberen we hate speech te analyseren, op te sporen en een vergelijkende studie te leveren in een code-mixed social media tekst. We bieden ook een Hindi-Engels code-mixed dataset bestaande uit Facebook en Twitter posts en commentaren. Onze experimenten tonen aan dat deep learning modellen getraind op dit code-mixed corpus beter presteren.', 'ko': '소셜 미디어 전파 중의 증오 언어 검출은 이미 충돌을 피하고 불량 활동을 억제하는 주요 관심사 중의 하나가 되었다.다중 언어 사용자가 다양한 언어 사이를 전환하는 환경에서 증오 음성 검측은 도전적인 임무가 되고 단어 자료 라이브러리에 대한 디자인 방법을 사용한다.우리의 업무에서, 우리는 코드가 혼합된 소셜 미디어 텍스트의 증오 발언을 분석하고, 검측하고, 비교하려고 한다.페이스북과 트위터의 댓글과 댓글을 포함한 인도어-영어 코드 혼합 데이터 세트도 제공했다.우리의 실험은 이러한 코드 혼합 어료 라이브러리에서 훈련된 깊이 있는 학습 모델이 더욱 잘 표현되었다는 것을 보여 주었다.', 'de': 'Die Erkennung von Hassreden in der Kommunikation in sozialen Medien ist zu einem der Hauptanliegen geworden, um Konflikte zu vermeiden und unerwünschte Aktivitäten einzudämmen. In einer Umgebung, in der mehrsprachige Sprecher zwischen mehreren Sprachen wechseln, wird die Erkennung von Hassreden mit Methoden, die für einsprachige Korpora entwickelt wurden, zu einer herausfordernden Aufgabe. In unserer Arbeit versuchen wir, Hassrede in einem Code-Mixed-Social-Media-Text zu analysieren, aufzudecken und vergleichend zu untersuchen. Wir bieten auch einen Hindi-Englisch Code-Mixed Datensatz bestehend aus Facebook und Twitter Posts und Kommentaren. Unsere Experimente zeigen, dass Deep-Learning-Modelle, die auf diesem Code-Mixed-Korpus trainiert werden, besser funktionieren.', 'id': 'Deteksi pidato kebencian dalam komunikasi media sosial telah menjadi salah satu kepentingan utama untuk menghindari konflik dan menahan aktivitas tidak diinginkan. Dalam lingkungan di mana pembicara berbagai bahasa bertukar diantara berbagai bahasa, deteksi pidato kebencian menjadi tugas yang menantang menggunakan metode yang dirancang untuk korpora monobahasa. Dalam pekerjaan kami, kami mencoba untuk menganalisis, mendeteksi dan menyediakan studi perbandingan tentang pidato kebencian dalam teks kode-campuran media sosial. Kami juga menyediakan set data campuran kode Hindi-Inggris yang terdiri dari posting Facebook dan Twitter dan komentar. Eksperimen kami menunjukkan bahwa model belajar dalam dilatih pada kode-campuran corpus ini berhasil lebih baik.', 'fa': 'کشف سخنرانی در ارتباط رسانه\u200cهای اجتماعی نفرت یکی از نگرانی اولیه برای جلوگیری از اختلاف\u200cها و فعالیت\u200cهای غیر خواسته\u200cای تبدیل شده است. در محیط جایی که زبان\u200cهای متعدد زبان\u200cها بین زبان\u200cهای متعدد تغییر می\u200cدهند، کشف سخنرانی متنفر یک کار سخت\u200cگیری می\u200cشود که با استفاده از روش\u200cهای طراحی برای یک کوپرا زبان\u200cهای متعدد شده است. در کار ما، سعی می کنیم تحلیل، شناسایی و تحلیل مقایسه\u200cای از سخنرانی متنفر را در متن رسانه\u200cهای اجتماعی با کد مختلف کنیم. ما همچنین یک مجموعه داده\u200cهای مختلف با کد انگلیسی هند و انگلیسی را تهیه می\u200cکنیم که از فیسبوک و توئیتر و توضیح\u200cها وجود دارد. آزمایشات ما نشان می دهند که مدل یادگیری عمیقی که روی این کورپوس متصل شده آموزش داده شده بهتر انجام می دهد.', 'sw': 'Kugundua hotuba ya chuki katika mawasiliano ya mitandao ya kijamii imekuwa moja ya wasiwasi wa msingi wa kuepuka migogoro na kuzuia shughuli zisizo na haki. In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora.  Katika kazi yetu, tunajaribu kuchambua, kutambua na kutoa utafiti uliofanana na hotuba ya chuki katika maandishi ya mitandao ya kijamii yanayochanganyika. Pia tunatoa kituo cha taarifa mchanganyiko wa aina ya Kiingereza kinachojumuisha makala za Facebook na Twita na maoni. Majaribio yetu yanaonyesha kuwa mifano ya kujifunza kwa kina yaliyofundishwa kwenye makundi haya yanayochanganya vizuri zaidi.', 'sq': 'Zbulimi i fjalimit të urrejtjes në komunikimin e medias sociale është bërë një nga shqetësimet kryesore për të shmangur konfliktet dhe për të penguar veprimtaritë e padëshiruara. Në një mjedis ku folësit shumëgjuhës ndryshojnë midis gjuhëve të shumta, zbulimi i fjalës së urrejtjes bëhet një detyrë sfiduese duke përdorur metoda që janë projektuar për korpra monogjuhëse. Në punën tonë, ne përpiqemi të analizojmë, të zbulojmë dhe të ofrojmë një studim krahasues të fjalimit të urrejtjes në një tekst të përzier me kode të medias sociale. Ne gjithashtu ofrojmë një set të dhënash të përziera kod-anglisht që përbëhet nga postimet dhe komentet e Facebook-it dhe Twitter-it. Eksperimentet tona tregojnë se modelet e mësimit të thellë të trajnuar në këtë korpus të përzier me kode funksionojnë më mirë.', 'tr': 'Sosyal medýdançalaryň habarlarynda sözlerini ýok etmek üçin çykyşlyklardan we nusgalardan çykmak üçin esasy çykyşlyklardan biri bolup geçdi. Birnäçe dilli diller arasynda çalşyrýan bir ortamda, çykyş tanyşyny ýigrenýän çykyş, monolingual korpora üçin tasarlanýan yönlerden ullanýan täzelikler bolar. Biz işimizde ýigrenç sözlerini çözümlemek, detek etmek we çykarmak üçin cödleşikli sosyal medýdanlaryň metinde çykyşlygyny barlamaga synanyşýarys. Biz hem Hindi-iňlisçe birleşmiş hatlary Facebookda, Twitter powtlaryna we terjimelerinden guruldyrýarys. Biziň deneylerimiz çukur öwrenme nusgalarymyz bu ködleşdirilmiş korpusda gowy işleýändigini görkeýär.', 'am': 'በማኅበራዊ ሚዲያ ግንኙነት ላይ የጥል ንግግር ማግኘት ግጭት እና ያልተቃወመ ተግባራት ለመራቀቅ የመጀመሪያው ጥያቄ ሆነዋል፡፡ ብዙ ቋንቋዎች የሚናገሩ በቋንቋዎች መካከል በሚለወጡበት አካባቢ ውስጥ፣ የጥል ንግግር ግንኙነት ለብሔራዊ ኮርፖርተር የተዘጋጁት ሥርዓት በመጠቀም የጥላቻ ሥራ ሆነዋል፡፡ በሥራችን፣ የጥላቻን ንግግር በማኅበራዊ ሚዲያ ጽሑፍ ለመተካከል እናሳውቃለን እናሳውቃለን፡፡ በፌስቡክ እና በትዊተር ደብዳቤዎች እና ትዊተር ጽሑፎች እና አስተያየት የሚቆጠሩ የHindi-እንግሊዘኛ የኮድ-ተለይቷል፡፡ ፈተናዎቻችን የጥልቅ ትምህርት ምሳሌዎች በዚህ ኮድ በተለየ ቆርፓስ የተማሩ ይሻላሉ፡፡', 'hy': 'Սոցիալական լրատվամիջոցների հաղորդակցման մեջ ատելության հայտնաբերումը դարձավ հակամարտությունների խուսափելու և անցանկանալի գործողությունների սահմանափակելու հիմնական խնդիրներից մեկը: Միջակա միջավայրում, որտեղ բազմալեզու խոսնակները փոխվում են բազմալեզուների միջև, ատելության խոսքի հայտնաբերումը դառնում է դժվար խնդիր՝ օգտագործելով մեթոդներ, որոնք նախագծված են միալեզու մարմնի համար: Մեր աշխատանքում մենք փորձում ենք վերլուծել, հայտնաբերել և ապահովել ատելության խոսքի համեմատական ուսումնասիրություն կոդի խառնված սոցիալական լրատվամիջոցների տեքստում: Մենք նաև հունդի-անգլերեն կոդի խառնված տվյալների համակարգ ենք կազմում, որը կազմված է Ֆեյսբուքի, Թվիթերի պոստերից և մեկնաբանություններից: Մեր փորձարկումները ցույց են տալիս, որ խորը ուսումնասիրության մոդելները, որոնք վարժեցվել են այս կոդի խառնված մարմնի վրա, ավելի լավ են աշխատում:', 'az': 'Sosyal media komunikasındakı nifrət sözlərini keşfetmək münafiqlərdən çəkinmək və istəməməz fəaliyyətlərdən çəkinmək üçün ilk endirilənlərdən biri oldu. Bir çevredə çoxlu dil danışanları çoxlu dillər arasında dəyişdirirlər, nefret danışmağı tanımlaması monodil korporası üçün dizayn edilən metodları ilə çətin bir iş olar. Çalışmalarımızda, kodla karışmış sosyal media mətnlərində nifrət sözlərini analizə, keşfetməyə və təmin etməyə çalışırıq. Biz həmçinin Hindi-İngilizce kodu ilə birləşdirilmiş məlumatlar quruluruq, Facebook, Twitter məlumatları və məlumatları içərisində. Bizim eksperimentlərimiz bu còd karışıqlı korpus üzərində təhsil edilmiş derin öyrənmə modellərinin daha yaxşısını göstərir.', 'bn': 'সামাজিক প্রচার মাধ্যমের যোগাযোগ যোগাযোগের ভাষণের ঘৃণা প্রকাশ করা হয়েছে সংঘর্ষ এবং অসন্তুষ্ট কার্যক্রম থেকে বাঁধ In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora.  আমাদের কাজে আমরা একটি কোড মিশ্রিত সামাজিক প্রচার মাধ্যমের লেখায় ঘৃণা ভাষণ বিশ্লেষণ, সন্ধান এবং তুলনায় গবেষণা প্রচেষ্টা করছ আমরা ফেসবুক এবং টুইটার পোস্ট এবং মন্তব্যের অন্তর্ভুক্ত একটি হিন্দি ইংরেজী কোড মিশ্রিত তথ্য সেট প্রদান করি। আমাদের পরীক্ষা দেখাচ্ছে যে গভীর শিক্ষার মডেল এই কোড মিশ্রিত কর্পাসের প্রশিক্ষণ প্রদান করা হয়েছে।', 'bs': 'Otkrivanje govora mržnje u komunikaciji društvenih medija postalo je jedna od glavnih zabrinutosti kako bi izbjegao sukobe i izbjegao nevidljive aktivnosti. U okruženju u kojem se multijezički govornici mijenjaju među mnogim jezicima, otkrivanje govora mržnje postaje izazovni zadatak koristeći metode koje su dizajnirane za monojezičku korporu. U našem poslu pokušavamo analizirati, otkriti i pružiti usporedno ispitivanje govora mržnje u tekstu socijalnih medija. Također predstavljamo indijski-engleski kompleks podataka koji se sastoje od Facebook i Twitter postova i komentara. Naši eksperimenti pokazuju da duboki modeli učenja obučeni na ovom korpusu miješanom kodu bolje izvode.', 'ca': "La detecció de l'odi en la comunicació amb els mitjans socials s'ha convertit en una de les principals preocupacions per evitar conflictes i limitar les activitats indesirades. En un entorn on els parlants multilingües canvien entre múltiples llengües, la detecció del discurs d'odi es converteix en una tasca difícil fent servir mètodes dissenyats per a corpora monolingüe. En la nostra feina intentem analitzar, detectar i proporcionar un estudi comparatiu de discurs d'odi en un text de mitjans socials combinats de codi. També proporcionem un conjunt de dades mixtes de codi hindí-anglès compost de publicacions i comentaris de Facebook i Twitter. Els nostres experiments demostren que els models d'aprenentatge profund entrenats en aquest cos combinat de codis actuen millor.", 'cs': 'Detekce nenávistné řeči v komunikaci na sociálních médiích se stala jedním z hlavních zájmů, jak se vyhnout konfliktům a omezit nežádoucí aktivity. V prostředí, kde vícejazyční mluvčí přepínají mezi více jazyky, se detekce nenávistné řeči stává náročným úkolem pomocí metod určených pro jednojjazyčné korpusy. V naší práci se snažíme analyzovat, detekovat a poskytnout srovnávací studii nenávistné řeči v textu sociálních médií smíšeném kódem. Poskytujeme také hindsky-anglický kód smíšený datový soubor sestávající z příspěvků a komentářů na Facebooku a Twitteru. Naše experimenty ukazují, že modely hlubokého učení trénované na tomto kódově smíšeném korpusu fungují lépe.', 'fi': 'Vihanpuheen havaitsemisesta sosiaalisessa mediassa on tullut yksi tärkeimmistä huolenaiheista konfliktien välttämiseksi ja ei-toivottujen toimintojen hillitsemiseksi. Ympäristössä, jossa monikieliset puhujat vaihtavat useita kieliä, vihapuheen havaitsemisesta tulee haastava tehtävä käyttämällä monikielisiä korpusia. Työssämme pyrimme analysoimaan, havaitsemaan ja tuottamaan vertailevaa tutkimusta vihapuheesta koodisekoitetussa sosiaalisen median tekstissä. Tarjoamme myös hindi-englanti koodisekoitetun datajoukon, joka koostuu Facebook- ja Twitter-viesteistä ja kommenteista. Kokeemme osoittavat, että tällä koodisekoitetulla korpusella koulutetut syväoppimismallit toimivat paremmin.', 'et': 'Vihakõne avastamine sotsiaalmeedias on muutunud üheks peamiseks mureks konfliktide vältimisel ja soovimatute tegevuste piiramisel. Keskkonnas, kus mitmekeelsed kõnelejad vahetavad mitme keele vahel, muutub vihakõne tuvastamine keeruliseks ülesandeks, kasutades meetodeid, mis on mõeldud ühekeelsetele korpustele. Oma töös püüame analüüsida, avastada ja pakkuda võrdlevat uuringut vihakõne koodisegatud sotsiaalmeedia tekstis. Samuti pakume hindi-inglise koodisega andmekogumit, mis koosneb Facebooki ja Twitteri postitustest ja kommentaaridest. Meie eksperimendid näitavad, et sellel koodisega korpusel koolitatud sügavõppe mudelid toimivad paremini.', 'af': "Hatte spraak beskrywing in sosiale media-kommunikasie het een van die primêre bekommerdes geword om konflikte te te verdwyn en onversoekte aktiwiteite te kry. In 'n omgewing waar veelvuldige talesprekkers onder veelvuldige tale verander, haat spraak ontdekking word 'n pragtige taak met gebruik van metodes wat vir monotale korpora ontwerp word. In ons werk probeer ons om 'n vergelykbare studie van haat spreek in 'n kode gemengde sosiale media teks te analyseer, ontdek en verskaf. Ons verskaf ook 'n Hindi-Engels kode gemengde data stel wat bestaan van Facebook en Twitter-pos en kommentaar. Ons eksperimente wys dat diep leer modele op hierdie kode gemengde korpus beter uitvoer.", 'jv': 'Genah apakno kanggo ngilanggar kuwi komunikasi komunikasi komunikasi komunikasi tambah dumadhi iki sakjane perbudhakan kanggo nganggo nggabi negoro iki o nggawe operasi sing ora bisa pasakno. Anyone Nang barêng-barêng, kéné saiki tau jewat urip nêmên, ngêkaké karo perusahaan langgambar barang seneng pisan kuwi nggambar barang seneng pisan rewang. Awak dhéwé mulai akeh kode-nggiles barang kelas barang pengguna neng pisang-pakan bukane, gambarang penggunan neng Google lan Komentar. Awakdhéwé éntuk éntuk sistem anyar tentang karo perusahaan banget nggawe barang langgar.', 'sk': 'Odkrivanje sovražnega govora v komunikaciji na družbenih medijih je postalo ena izmed glavnih skrbi za preprečevanje konfliktov in omejevanje neželenih dejavnosti. V okolju, kjer večjezični govorniki preklapljajo med več jeziki, postane zaznavanje sovražnega govora zahtevna naloga z metodami, ki so zasnovane za enojezične korpuse. V svojem delu poskušamo analizirati, odkrivati in zagotoviti primerjalno študijo sovražnega govora v besedilu, ki je mešano s kodami, družbenih medijev. Zagotavljamo tudi hindijsko-angleško kodno mešan nabor podatkov, sestavljen iz Facebook in Twitter objav in komentarjev. Naši eksperimenti kažejo, da so modeli globokega učenja, usposobljeni na tem korpusu z mešanimi kodami, boljši.', 'ha': "Kunna hoti na ƙiyayi a cikin mawasicin mitandai da jamii ya kasance daga muhimmin wa'azi ga kuɓutar da conflict da haramtar da ba'a zartar da aiki. A cikin wata muhalli da wasu masu magana masu cikin harshe masu yawa, za'a musanya magana na ƙiyayya ta zama wani abu mai fassarwa da ke amfani da metodi wanda aka ƙayyade wa makampuni na sauri. Daga aikinmu, Munã jarraba yin anayyar, gane, kuma mu sami wani littãfi na magana na ƙeta a cikin littafin mitandaki da aka haɗa shi. Tuna sami da kodi-da-Ingiriya da aka haɗa shi na Facebook da posten Twitter. Kayan jarrabõyinmu, za'a nũna misãlai da aka sanar da su a kan wannan kodi da aka haɗa shi, su aikata mafi alhẽri.", 'he': 'גילוי נאום שנאה בתקשורת התקשורת החברתית הפך לאחד הדאגות העיקריות כדי להימנע ממתקרבות ולגבול פעילות בלתי רצויות. בסביבה בה מדברים רבים משתנים בין שפות רבות, זיהוי נאום שנאה הופך למשימה מאתגרת באמצעות שיטות שנועדו עבור גופורה מונושפתית. בעבודתנו, אנו מנסים לנתח, לגלות ולספק מחקר שיוותי של נאום שנאה בטקסט של תקשורת חברתית מעורבת. אנחנו גם מספקים קבוצת נתונים מעורבת קודים הינדי-אנגלית שמכילה משלוחי פייסבוק וטוויטר ותערות. הניסויים שלנו מראים שדוגמנים למידה עמוקה מאומנים על הקורפוס הערבב הזה מבצעים טוב יותר.', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ནང་གི་ཐད་བརྗོད་རྙོག་པ་ལས་གནད་དོན་དག་ཆེན་དག་པ་ཞིག་དང་། སྐད་རིགས་སྣ་མང་པོ་ཞིག་གི་ནང་དུ་སྐད་རིགས་འདི་མང་པོ་ཞིག་བསྒྱུར་བཅུག་པའི་ནང་དུ་གཏོང་གཞིའི་ནང་དུ་གཏོང་བཤེར་ནི་ལྟ་བུ་གནད་ད ང་ཚོའི་ལས་ཀ་དེ་ལྟར་བཅས་ཀྱིས་དབྱེ་ཞིབ་བྱེད་དང་། རྟོགས་བྱེད་རྩོད་ཡོད་པའི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་ཡིག་གི་ནང་ ང་ཚོས་ཀྱང་ངོ་དེབ་དང་ཌིས་ཌིར་ཐོག་འགོད་དང་བཤད་ཀྱི་ཆ་འཕྲིན་སྒྲིག་ཆ་འཕྲིན་གྱི་རྩིས་བ་དང་མཉམ་སྒྲིག་ཡོ ང་ཚོའི་ལག་འཁྱེར་སྟངས་ནི་སྒྲིག་འཛིན་གྱི་ཐབས་ལམ་འདིའི་ནང་གི་མཐོ་བྱུང་མཁན་གྱི་ལས་འགན་སྐྱོང་བྱེད་མི་འདུག'}
{'en': 'Bagging BERT Models for Robust Aggression Identification BERT  Models for Robust Aggression Identification', 'ar': 'نماذج التعبئة BERT لتحديد العدوان القوي', 'fr': "Modèles BERT d'ensachage pour une identification robuste des agressions", 'pt': 'Modelos de ensacamento BERT para identificação de agressão robusta', 'es': 'Embolsamiento de modelos BERT para una identificación robusta de', 'ja': '強固な侵略の識別のためのBERTモデルの袋詰め', 'zh': '以鲁棒攻击性识装袋 BERT 模', 'hi': 'मजबूत आक्रामकता पहचान के लिए BERT मॉडल बैगिंग', 'ru': 'Упаковка моделей BERT для надежной идентификации агрессии', 'ga': 'Bagging Múnlaí BERT le haghaidh Aithint Ionsaitheach Láidir', 'ka': 'ბერტის მოდელები პრობსტის ადგრესიის იდენტიფიკაციისთვის', 'hu': 'BERT modellek a robusztus agressziós azonosításhoz', 'el': 'Μοντέλα για την εύρωστη αναγνώριση επιθετικότητας', 'it': "Modelli BERT per l'identificazione di aggressività robusta", 'lt': 'BERT maišelių tvirto agresijos identifikavimo modeliai', 'kk': 'Робуст агрессия идентификациясының BERT үлгілері', 'ms': 'Mengisi Model BERT untuk Pengenalan Aggresi Kuat', 'mk': 'Вметнување на модели BERT за идентификација на силна агресија', 'ml': 'Bagging BERT Models for Robust Aggression Identification', 'mt': 'Mudelli BERT għall-ippakkjar għall-Identifikazzjoni b’Aggressjoni robusta', 'mn': 'БЕРТ загвар Робуст Агрессийн Тодорхойлолтын тулд', 'no': 'Bagging BERT-modeller for robust Aggressidentifikasjon', 'ro': 'Modele BERT pentru identificarea agresiunii robuste', 'pl': 'Modele BERT do pakowania do solidnej identyfikacji agresji', 'sr': 'Modeli BERT za robotnu identifikaciju agresije', 'si': 'බැග්ගින් BERT මොඩේල්ස් විශ්වාසීය සංඥානය සඳහා', 'so': 'Bagging BERT Models for Robust Aggression Identification', 'sv': 'BERT-modeller för identifiering av robust aggression', 'ta': 'Comment', 'ur': 'روبوسٹ آگریس شناسایی کے لئے بغنگ BERT موڈل', 'uz': 'Comment', 'vi': 'Chế độ chuyển động cân bằng', 'bg': 'Модели BERT за идентифициране на здрава агресия', 'hr': 'Modeli BERT-a za stabilnu identifikaciju agresije', 'nl': 'BERT-modellen voor robuuste identificatie van agressie in zakken', 'da': 'Sæk BERT-modeller til identifikation af robust aggression', 'de': 'BERT-Modelle für die robuste Aggressionserkennung', 'id': 'Mengisi Model BERT untuk Identifikasi Aggresi Kuat', 'ko': '루팡 공격 식별의 Bagging-BERT 모형', 'fa': 'Models BERT bagging for robust Aggression Identification', 'sw': 'Bagging BERT Models for Robust Aggression Identification', 'tr': 'Robust Aggresiýasy Kimligi üçin peýdalanýan BERT nusgalar', 'af': 'Bagging BERT Models vir Robust Aggressie Identifikasie', 'sq': 'Modelet BERT për identifikimin e agresionit të fortë', 'hy': 'ԲԵՌԹ մոդելների բաժանելը ուժեղ ագրեսիայի հայտնաբերման համար', 'bn': 'রোবাস্ট অ্যাগ্রেশন পরিচয়ের জন্য ব্যাগিং বিরেট মোডেল', 'am': 'Bagging BERT Models for Robust Aggression Identification', 'bs': 'Modeli BERT za robotu identifikaciju agresije', 'ca': "Models BERT d'identificació d'agressió robusta", 'az': 'Q칲vv톛tli Agresiya Kimlikl톛ri 칲칞칲n BERT Modell톛ri', 'fi': 'BERT-mallit kestävään aggression tunnistamiseen', 'cs': 'Modely BERT pro robustní identifikaci agrese', 'et': 'BERTi tugeva agressiivse identifitseerimise mudelid', 'jv': 'Mulalah BERT nggo nambah apa-obahan', 'he': 'דוגמנים BERT לשימוש זיהוי התקף חזק', 'sk': 'Modeli BERT za prepoznavanje robustne agresije', 'ha': '@ action', 'bo': 'Robust Aggression Identification (Bagging BERT Models for Robust Aggression Identification)'}
{'en': 'Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks. This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as  decision trees . While the complex models fit training data well (low bias), they also come with an unwanted high variance. Especially when fine-tuning them on small datasets, the  classification  performance varies significantly for slightly different training data. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging). In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name : Julian). Our submission is the best-performing  system  for five out of six subtasks. For example, we achieve a weighted F1-score of 80.3 % for task A on the test dataset of English social media posts. In our experiments, we compare different model configurations and vary the number of models used in the  ensemble . We find that the F1-score drastically increases when ensembling up to 15 models, but the returns diminish for more models.', 'ar': 'النماذج الحديثة القائمة على المحولات مع مئات الملايين من المعلمات ، مثل BERT ، تحقق نتائج مبهرة في مهام تصنيف النص. ينطبق هذا أيضًا على تحديد العدوانية واكتشاف اللغة الهجومية ، حيث تتفوق مناهج التعلم العميق باستمرار على النماذج الأقل تعقيدًا ، مثل أشجار القرار. في حين أن النماذج المعقدة تناسب بيانات التدريب جيدًا (انحياز منخفض) ، فإنها تأتي أيضًا مع تباين كبير غير مرغوب فيه. يختلف أداء التصنيف بشكل كبير باختلاف بيانات التدريب اختلافًا طفيفًا ، خاصة عند ضبطها على مجموعات بيانات صغيرة. للتغلب على التباين العالي وتقديم تنبؤات أكثر قوة ، نقترح مجموعة من نماذج BERT متعددة مضبوطة بدقة استنادًا إلى تجميع التمهيد (التعبئة). في هذه الورقة ، نصف نظام المجموعات هذا ونقدم تقديمنا للمهام المشتركة حول تحديد العدوان 2020 (اسم الفريق: جوليان). إرسالنا هو النظام الأفضل أداءً لخمسة من أصل ست مهام فرعية. على سبيل المثال ، نحقق درجة F1 مرجحة بنسبة 80.3٪ للمهمة A في مجموعة بيانات الاختبار الخاصة بمنشورات الوسائط الاجتماعية باللغة الإنجليزية. في تجاربنا ، نقارن تكوينات النماذج المختلفة ونغير عدد النماذج المستخدمة في المجموعة. نجد أن درجة F1 تزداد بشكل كبير عند تجميع ما يصل إلى 15 نموذجًا ، لكن العوائد تتضاءل لمزيد من الطرز.', 'pt': 'Modelos modernos baseados em transformadores com centenas de milhões de parâmetros, como BERT, alcançam resultados impressionantes em tarefas de classificação de texto. Isso também vale para identificação de agressão e detecção de linguagem ofensiva, onde as abordagens de aprendizado profundo superam consistentemente modelos menos complexos, como árvores de decisão. Embora os modelos complexos se ajustem bem aos dados de treinamento (baixo viés), eles também vêm com uma alta variação indesejada. Especialmente ao ajustá-los em pequenos conjuntos de dados, o desempenho da classificação varia significativamente para dados de treinamento ligeiramente diferentes. Para superar a alta variância e fornecer previsões mais robustas, propomos um conjunto de vários modelos BERT ajustados com base na agregação de bootstrap (bagging). Neste artigo, descrevemos esse sistema de conjunto e apresentamos nossa submissão às tarefas compartilhadas sobre identificação de agressão 2020 (nome da equipe: Julian). Nosso envio é o sistema de melhor desempenho para cinco das seis subtarefas. Por exemplo, alcançamos uma pontuação F1 ponderada de 80,3% para a tarefa A no conjunto de dados de teste de postagens de mídia social em inglês. Em nossos experimentos, comparamos diferentes configurações de modelos e variamos o número de modelos usados no conjunto. Descobrimos que a pontuação F1 aumenta drasticamente ao agrupar até 15 modelos, mas os retornos diminuem para mais modelos.', 'es': 'Los modelos modernos basados en transformadores con cientos de millones de parámetros, como BERT, logran resultados impresionantes en las tareas de clasificación de textos. Esto también es válido para la identificación de agresiones y la detección de lenguaje ofensivo, donde los enfoques de aprendizaje profundo superan sistemáticamente a los modelos menos complejos, como los árboles de decisión. Si bien los modelos complejos se ajustan bien a los datos de entrenamiento (sesgo bajo), también vienen con una alta varianza no deseada. Especialmente al ajustarlos en conjuntos de datos pequeños, el rendimiento de la clasificación varía significativamente para datos de entrenamiento ligeramente diferentes. Para superar la alta varianza y proporcionar predicciones más sólidas, proponemos un conjunto de múltiples modelos BERT ajustados basados en la agregación bootstrap (embolsado). En este artículo, describimos un sistema de conjunto de este tipo y presentamos nuestra presentación a las tareas compartidas sobre la identificación de la agresión 2020 (nombre del equipo: Julian). Nuestra presentación es el sistema de mejor rendimiento para cinco de las seis subtareas. Por ejemplo, logramos una puntuación F1 ponderada del 80,3% para la tarea A en el conjunto de datos de prueba de publicaciones en redes sociales en inglés. En nuestros experimentos, comparamos diferentes configuraciones de modelos y variamos el número de modelos utilizados en el conjunto. Descubrimos que la puntuación F1 aumenta drásticamente al ensamblar hasta 15 modelos, pero los rendimientos disminuyen para más modelos.', 'fr': "Les modèles modernes basés sur des transformateurs avec des centaines de millions de paramètres, tels que BERT, permettent d'obtenir des résultats impressionnants lors des tâches de classification de texte. Cela vaut également pour l'identification de l'agressivité et la détection du langage offensant, où les approches d'apprentissage profond surpassent systématiquement les modèles moins complexes, tels que les arbres décisionnels. Bien que les modèles complexes s'ajustent bien aux données d'entraînement (biais faible), ils présentent également une variance élevée non désirée. En particulier lorsque vous les affinez sur de petits ensembles de données, les performances de classification varient considérablement pour des données d'entraînement légèrement différentes. Pour surmonter la variance élevée et fournir des prévisions plus robustes, nous proposons un ensemble de multiples modèles BERT affinés basés sur l'agrégation bootstrap (ensachage). Dans cet article, nous décrivons un tel système d'ensemble et présentons notre soumission aux tâches partagées sur l'identification des agressions 2020 (nom de l'équipe\xa0: Julian). Notre soumission est le système le plus performant pour cinq sous-tâches sur six. Par exemple, nous obtenons un score F1 pondéré de 80,3\xa0% pour la tâche A dans l'ensemble de données de test des publications sur les réseaux sociaux en anglais. Dans nos expériences, nous comparons différentes configurations de modèles et varions le nombre de modèles utilisés dans l'ensemble. Nous constatons que le score F1 augmente considérablement lorsque vous assemblez jusqu'à 15 modèles, mais que les rendements diminuent pour un plus grand nombre de modèles.", 'ja': 'BERTなど、数億のパラメータを備えた最新の変圧器ベースのモデルは、テキスト分類タスクで印象的な結果を達成します。 これは、深層学習アプローチが意思決定ツリーなどのより複雑でないモデルを一貫して上回る、侵略の識別と攻撃的な言語検出にも適用されます。 複雑なモデルはトレーニングデータにうまくフィットしますが（低バイアス）、望ましくない高い分散があります。 特に小さなデータセットで微調整すると、わずかに異なるトレーニングデータでは分類パフォーマンスが大きく異なります。 高い分散を克服し、より堅牢な予測を提供するために、ブートストラップ集約（バギング）に基づいて、複数の微調整されたBERTモデルのアンサンブルを提案します。 本稿では、このようなアンサンブルシステムについて説明し、侵略の識別に関する共有タスク2020 （チーム名： Julian ）への提出を提示する。 当社の提出物は、6つのサブタスクのうち5つに最適なパフォーマンスのシステムです。 たとえば、英語のソーシャルメディア投稿のテストデータセットでは、タスクAの加重F 1スコア80.3%を達成しています。 実験では、異なるモデル構成を比較し、アンサンブルで使用されるモデルの数を変化させます。 15機種まで組み立てるとF 1スコアが大幅に上がることがわかりますが、より多くの機種ではリターンが減少します。', 'zh': '有数亿参数(如 BERT)之基于转换器,而取深于文本之类。 此亦宜用于攻击性识犯性语言检测,其深度学术终优于不杂者,如决策树。 虽复模拟合训数(差),亦有不须之高方差。 特于小数集微调时,于略有不同练数,分类性能大异。 克高方差而给更健之占,立基于导引(bagging)数微BERT之会。 于本文中,述此一集成系统,并向2020年侵识(团队名:Julian)之同务言之。 我们提交是六个子务中五子任中性能最佳的系统。 如英语社交媒体帖之测试数据集上成务 A 者加权 F1 分数 80.3%。 于我实验中,我较其形,而变其数。 臣等见封装至15,F1分益急,多报减少。', 'ru': 'Современные трансформаторные модели с сотнями миллионов параметров, такие как BERT, достигают впечатляющих результатов в задачах классификации текста. Это также относится к выявлению агрессии и обнаружению оскорбительных языков, где подходы к глубокому обучению последовательно превосходят менее сложные модели, такие как дерево решений. Хотя сложные модели хорошо подходят к обучающим данным (низкая систематическая ошибка), они также имеют нежелательную высокую дисперсию. Особенно при их точной настройке на небольших наборах данных, эффективность классификации значительно варьируется для немного отличающихся данных обучения. Чтобы преодолеть высокую дисперсию и предоставить более надежные прогнозы, мы предлагаем ансамбль из нескольких тонко настроенных моделей BERT, основанных на агрегации бутстреп (пакетировании). В этой статье мы описываем такую ансамблевую систему и представляем наше представление к общим задачам по выявлению агрессии 2020 (название команды: Джулиан). Наша подача - это самая эффективная система для пяти из шести подзадач. Например, мы достигаем взвешенного показателя F1 80,3% для задачи A в тестовом наборе данных английских постов в социальных сетях. В наших экспериментах мы сравниваем различные конфигурации моделей и варьируем количество моделей, используемых в ансамбле. Мы обнаружили, что показатель F1 резко увеличивается при объединении до 15 моделей, но доходность уменьшается для большего количества моделей.', 'hi': 'BERT जैसे लाखों मापदंडों के सैकड़ों के साथ आधुनिक ट्रांसफॉर्मर-आधारित मॉडल, पाठ वर्गीकरण कार्यों में प्रभावशाली परिणाम प्राप्त करते हैं। यह आक्रामकता की पहचान और आक्रामक भाषा का पता लगाने के लिए भी रखता है, जहां गहरी सीखने के दृष्टिकोण लगातार कम जटिल मॉडल, जैसे कि निर्णय पेड़ों से बेहतर प्रदर्शन करते हैं। जबकि जटिल मॉडल प्रशिक्षण डेटा को अच्छी तरह से फिट करते हैं (कम पूर्वाग्रह), वे एक अवांछित उच्च विचरण के साथ भी आते हैं। विशेष रूप से जब उन्हें छोटे डेटासेट पर ठीक-ट्यूनिंग किया जाता है, तो वर्गीकरण प्रदर्शन थोड़ा अलग प्रशिक्षण डेटा के लिए काफी भिन्न होता है। उच्च विचरण को दूर करने और अधिक मजबूत भविष्यवाणियां प्रदान करने के लिए, हम बूटस्ट्रैप एग्रीगेटिंग (बैगिंग) के आधार पर कई ठीक-ट्यून किए गए BERT मॉडल की एक टुकड़ी का प्रस्ताव करते हैं। इस पेपर में, हम इस तरह के एक पहनावे की प्रणाली का वर्णन करते हैं और आक्रामकता पहचान 2020 (टीम का नाम: जूलियन) पर साझा कार्यों के लिए अपना सबमिशन प्रस्तुत करते हैं। हमारा सबमिशन छह उप-कार्यों में से पांच के लिए सबसे अच्छा प्रदर्शन करने वाली प्रणाली है। उदाहरण के लिए, हम अंग्रेजी सोशल मीडिया पोस्ट के परीक्षण डेटासेट पर कार्य ए के लिए 80.3% का भारित एफ 1-स्कोर प्राप्त करते हैं। हमारे प्रयोगों में, हम विभिन्न मॉडल कॉन्फ़िगरेशन की तुलना करते हैं और पहनावा में उपयोग किए जाने वाले मॉडल की संख्या में भिन्नता रखते हैं। हम पाते हैं कि 15 मॉडलों तक ensembling करते समय F1-स्कोर काफी बढ़ जाता है, लेकिन रिटर्न अधिक मॉडल के लिए कम हो जाता है।', 'ga': "Baineann samhlacha nua-aimseartha atá bunaithe ar chlaochladán leis na céadta milliún paraiméadair, mar BERT, torthaí suntasacha amach ag tascanna aicmithe téacs. Baineann sé seo freisin le haithint ionsaithe agus braite teanga maslach, áit a n-éiríonn níos fearr le cineálacha cur chuige domhainfhoghlama i gcónaí ná samhlacha nach bhfuil chomh casta, mar chrainn chinnidh. Cé go n-oireann na samhlacha casta go maith do shonraí oiliúna (claonadh íseal), tagann siad le hathraithis ard nach dteastaíonn. Go háirithe agus iad á mionchoigeartú ar thacair sonraí beaga, athraíonn an fheidhmíocht aicmithe go mór i gcás sonraí oiliúna atá beagán difriúil. Chun an t-athraitheas ard a shárú agus tuar níos daingne a sholáthar, molaimid ensemble d'ilmhúnlaí BERT mionchoigeartaithe bunaithe ar chomhiomlánú bootstrap (bagging). Sa pháipéar seo, déanaimid cur síos ar chóras ensemble den sórt sin agus cuirimid ár n-aighneacht i láthair na dtascanna roinnte ar shainaithint ionsaithe 2020 (ainm foirne: Julian). Is é ár n-aighneacht an córas is fearr feidhmíochta le haghaidh cúig cinn as sé fhothasc. Mar shampla, bainimid amach scór F1 ualaithe de 80.3% do thasc A ar thacar sonraí tástála na bpost meán sóisialta Béarla. Inár dturgnaimh, déanaimid comparáid idir cumraíochtaí samhlacha éagsúla agus athraímid líon na múnlaí a úsáidtear sa ensemble. Feictear dúinn go méadaíonn an scór F1 go suntasach nuair a dhéantar suas le 15 samhail a chomhcheangal, ach laghdaítear na torthaí i gcás níos mó samhlacha.", 'hu': 'A modern, több százmillió paraméterrel rendelkező transzformátor alapú modellek, mint például a BERT, lenyűgöző eredményeket érnek el a szövegosztályozási feladatok során. Ez vonatkozik az agressziós azonosításra és a sértő nyelvi felismerésre is, ahol a mélytanulási megközelítések következetesen felülmúlják a kevésbé összetett modelleket, például a döntési fákat. Míg a komplex modellek jól illeszkednek az edzési adatokhoz (alacsony elfogultság), nem kívánt nagy varianciával is rendelkeznek. Különösen kis adatkészletekre történő finomhangolás esetén az osztályozási teljesítmény jelentősen eltérő a kissé eltérő edzési adatok esetében. A nagy variancia leküzdése és a robusztusabb előrejelzések biztosítása érdekében több finomhangolt BERT modellt javasolunk bootstrap aggregáción (bagging) alapuló rendszer-összesítésen. Ebben a tanulmányban egy ilyen együttes rendszert írunk le, és bemutatjuk a 2020-as agresszió azonosítására vonatkozó közös feladatoknak való benyújtásunkat (csapatnév: Julian). A benyújtásunk a hat részfeladatból öt legjobban teljesítő rendszer. Például az "A" feladat esetében 80,3%-os F1 pontszámot érünk el az angol közösségi média bejegyzések tesztadatkészletén. Kísérleteink során különböző modellkonfigurációkat hasonlítunk össze és változtatjuk az együttesben használt modellek számát. Úgy találjuk, hogy az F1 pontszám drasztikusan növekszik akár 15 modell összeállításakor, de a megtérülés csökken több modell esetében.', 'el': 'Τα σύγχρονα μοντέλα μετασχηματιστών με εκατοντάδες εκατομμύρια παραμέτρους, όπως το επιτυγχάνουν εντυπωσιακά αποτελέσματα σε εργασίες ταξινόμησης κειμένου. Αυτό ισχύει επίσης για τον εντοπισμό επιθετικότητας και την ανίχνευση προσβλητικών γλωσσών, όπου οι προσεγγίσεις βαθιάς μάθησης ξεπερνούν σταθερά λιγότερο πολύπλοκα μοντέλα, όπως τα δέντρα αποφάσεων. Ενώ τα σύνθετα μοντέλα ταιριάζουν καλά στα δεδομένα προπόνησης (χαμηλή προκατάληψη), έρχονται επίσης με μια ανεπιθύμητη υψηλή διακύμανση. Ειδικά όταν τα ρυθμίζετε σε μικρά σύνολα δεδομένων, η απόδοση ταξινόμησης ποικίλει σημαντικά για ελαφρώς διαφορετικά δεδομένα προπόνησης. Για να ξεπεράσουμε την υψηλή διακύμανση και να παρέχουμε πιο ισχυρές προβλέψεις, προτείνουμε ένα σύνολο πολλαπλών εκλεπτυσμένων μοντέλων βασισμένων στη συγκέντρωση (σακούλα). Στην παρούσα εργασία περιγράφουμε ένα τέτοιο σύστημα συνόλων και παρουσιάζουμε την υποβολή μας στα κοινά καθήκοντα για τον προσδιορισμό επιθετικότητας 2020 (όνομα ομάδας: Τζούλιαν). Η υποβολή μας είναι το σύστημα με τις καλύτερες επιδόσεις για πέντε στις έξι δευτερεύουσες εργασίες. Για παράδειγμα, επιτυγχάνουμε μια σταθμισμένη βαθμολογία F1 80,3% για την εργασία Α στο σύνολο δεδομένων δοκιμών των αγγελιών κοινωνικών μέσων. Στα πειράματά μας, συγκρίνουμε διαφορετικές διαμορφώσεις μοντέλων και διαφοροποιούμε τον αριθμό των μοντέλων που χρησιμοποιούνται στο σύνολο. Διαπιστώνουμε ότι η βαθμολογία αυξάνεται δραστικά όταν συνδυάζεται έως και 15 μοντέλα, αλλά οι αποδόσεις μειώνονται για περισσότερα μοντέλα.', 'ka': 'მოდინარე ტრანფორმეტრის დაბათი მოდელები, რომლებიც მელიონი პარამეტრები, როგორც BERT, ტექსტის კლასიფიკაციის დავალებაში, მიიღება ინტერფექციური შედეგი. ეს ასევე აქვს ადრესიის განსაზღვრებისთვის და განსაზღვრებისთვის ენის განსაზღვრებისთვის, სადაც ძალიან ძალიან სწავლებისთვის უფრო კომპლექსიკური მოდელები, როგორც გადა თუმცა კომპლექსიკური მოდელები საკმაოდ შეეძლება განაკეთებული მონაცემები (ცოტა წარმოდგენები), ისინი ასევე უნდა გარიანსი გარჩენა. განსაკუთრებით, როცა მათ პატარა მონაცემების კონფიგურაცია განსხვავებულია მალზე განსხვავებული განსხვავებული მონაცემებისთვის. უფრო ძალიან ძალიან გარიანსი და უფრო ძალიან წარმოდგენების შესაძლებლობისთვის, ჩვენ გვეძლოთ ბერტი მოდელების ანსტებლის გარეშე, რომელიც ბუტების აგგრეგიაციისთვის (bagging)  ამ დომენტში ჩვენ ასეთი სისტემა დავწერეთ და ჩვენი წევრება აგრესის ინდენტიფიკაციის 2020 წევრებისთვის ჩვენი დავწერეთ. ჩვენი დამუშაობა არის საუკეთესო სისტემა, რომელიც ხუთი შვიდი საკუთარი საკუთარი საკუთარი. მაგალითად, ჩვენ მივიღეთ 80,3% ფუნქციის გარშემო მონაცემების ინგლისური სოციალური მედია პოსტის ტესტის მონაცემების შესახებ. ჩვენი ექსპერიმენტებში, ჩვენ განსხვავებული მოდელური კონფიგურაციების შემდგომარებით და განსხვავებით მოდელური რაოდენობა, რომელიც იყენებულია ინ ჩვენ ვიფიქრობთ, რომ F1 წერტილის დირასტიკურად გაზრდება, როდესაც 15 მოდელზე გაზრდება, მაგრამ უფრო მეტი მოდელების გაზრდება.', 'it': "I moderni modelli basati su trasformatori con centinaia di milioni di parametri, come BERT, raggiungono risultati impressionanti nelle attività di classificazione del testo. Ciò vale anche per l'identificazione delle aggressioni e il rilevamento del linguaggio offensivo, dove gli approcci di deep learning superano costantemente modelli meno complessi, come gli alberi decisionali. Mentre i modelli complessi si adattano bene ai dati di allenamento (bias basso), vengono anche con un'alta varianza indesiderata. Specialmente quando vengono perfezionati su piccoli set di dati, le prestazioni di classificazione variano significativamente per dati di allenamento leggermente diversi. Per superare l'alta varianza e fornire previsioni più robuste, proponiamo un insieme di più modelli BERT perfezionati basati sull'aggregazione bootstrap (bagging). In questo articolo, descriviamo un tale sistema di ensemble e presentiamo la nostra sottomissione ai compiti condivisi sull'identificazione delle aggressioni 2020 (nome del team: Julian). La nostra presentazione è il sistema più performante per cinque sottoattività su sei. Ad esempio, otteniamo un punteggio F1 ponderato dell'80,3% per l'attività A sul set di dati di test dei post sui social media inglesi. Nei nostri esperimenti, confrontiamo diverse configurazioni di modello e variamo il numero di modelli utilizzati nell'insieme. Troviamo che il punteggio F1 aumenta drasticamente quando si assemblano fino a 15 modelli, ma i rendimenti diminuiscono per più modelli.", 'kk': 'БЕРТ секілді жүздеген миллион параметрлердің негізінде қазіргі түрлендіруші үлгілері мәтін классификациялау тапсырмаларында әсер етпейді. Сонымен қатар, агрессия идентификациясы және қарсы тілді анықтау үшін бар. Алыс оқыту үшін, шешім ағаштары секілді көп комплекс үлгілерінен артық болады. Комплекс үлгілер оқыту деректеріне жақсы (төмен қарсы) келеді, сонымен қажетті жоғары айырмашылығымен келеді. Әсіресе, оларды кішкентай деректер қорларына тәртіптеу кезінде, классификациясы бірнеше оқыту деректеріне өзгертіледі. Жоғары айырмашылығын көтеру үшін және көбірек таңдау үшін, біз бірнеше бағдарламалық BERT үлгілерін бағдарламасына негізделген (бағдарламалық) бағдарламаларына негізделген бірнеше жақсы Бұл қағазда біз бұл жүйені таңдап, 2020 жылдың агрессия идентификациясының ортақ тапсырмаларына жібереміз. Біздің жіберіміз алты суреттің бес жүйесінің ең жақсы жүйесі. Мысалы, біз A тапсырмасының тесті ағылшын социалдық медиақтар жіберіліктерінің тесті деректер жиынында 80,3% деген F1 деңгейін жеткіземіз. Өзіміздің тәжірибелерімізде, біз басқа моделдерді баптауларды салыстырып, олардың қолданылатын моделдердің санын өзгертіп тұрмыз. Біз F1 нөмірі 15 модельге дейін дейін драстикалық көбейтеді, бірақ қайтаратын үлгілер үшін көбейтеді.', 'lt': 'Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks.  Tai taip pat taikoma agresijos nustatymui ir įžeidžiančių kalbų nustatymui, kai gilaus mokymosi metodai nuosekliai viršija mažiau sudėtingus modelius, pvz., sprendimų medžius. Nors sudėtingi modeliai gerai atitinka mokymo duomenis (nedidelė pusiausvyra), jie taip pat turi nepageidaujamą didelį skirtumą. Ypač tikslinant juos mažuose duomenų rinkiniuose, klasifikavimo rezultatai šiek tiek skirtingi mokymo duomenys labai skiriasi. Siekiant įveikti didelius skirtumus ir teikti patikimesnes prognozes, siūlome keletą gerai pritaikytų BERT modelių, grindžiamų įjungimo juosta (maišeliais). Šiame dokumente apibūdiname tokią komplekso sistemą ir pristatome bendrąsias užduotis, susijusias su agresijos identifikavimu 2020 m. (komandos pavadinimas Julian). Mūsų pasiūlymas yra geriausia sistema penkiams iš šešių paklausymų. Pavyzdžiui, siekiame 80,3 % svertinio A užduoties F1 rezultato anglų socialinės žiniasklaidos postų bandymų duomenų rinkinyje. Mūsų eksperimentuose palyginame skirtingas modelių konfigūracijas ir skiriamės modelių, naudojamų ensemble, skaičius. Nustatome, kad F1 rezultatas labai didėja, kai susijungia iki 15 modelių, tačiau grąža mažėja daugiau modelių.', 'mk': 'Модерните модели базирани на трансформатори со стотици милиони параметри, како што е БЕРТ, постигнуваат импресивни резултати на задачите за класификација на текст. Ова, исто така, важи и за идентификација на агресијата и детекција на офанзивниот јазик, каде длабоко учење постојано се приближува константно надминува помалку комплексни модели, како што се дрвјата на одлуките. И покрај тоа што комплексните модели добро се вклопуваат во податоците за обука (ниска пристрасност), тие исто така доаѓаат со неочекувана висока варијанција. Особено кога се прилагодуваат на мали податоци, резултатите на класификацијата значително се разликуваат за малку различни податоци за обука. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging).  In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name: Julian).  Нашето поднесување е најдобриот систем за пет од шест потпрашања. На пример, постигнуваме тежирана оценка F1 од 80,3 отсто за задачата А на тестовите на англиските социјални медиуми. Во нашите експерименти, ги споредуваме различните моделни конфигурации и го разликуваме бројот на модели кои се користат во ансамблот. Најдовме дека оценката Ф1 драстично се зголемува кога се собира до 15 модели, но враќањата се намалуваат за повеќе модели.', 'ms': 'Modern model berasaskan pengubah dengan ratusan juta parameter, seperti BERT, mencapai keputusan yang mengesankan pada tugas klasifikasi teks. Ini juga mengandungi pengenalan agresi dan pengesan bahasa yang menyerang, di mana pembelajaran dalam mendekati secara konsisten melebihi model yang kurang kompleks, seperti pokok keputusan. Sementara model kompleks muat dengan data latihan dengan baik (bias rendah), mereka juga datang dengan variasi tinggi yang tidak diinginkan. Terutama apabila menyesuaikan mereka pada set data kecil, prestasi klasifikasi berbeza secara signifikan untuk data latihan yang sedikit berbeza. Untuk mengatasi variasi tinggi dan menyediakan ramalan yang lebih kuat, kami cadangkan kumpulan beberapa model BERT yang ditetapkan baik berdasarkan penggabungan tali bot. In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name: Julian).  Pengiriman kami adalah sistem yang paling berkesan untuk lima daripada enam subtasks. Contohnya, kita mencapai skor F1 berat 80.3% untuk tugas A pada set data ujian pos media sosial Inggeris. Dalam eksperimen kita, kita membandingkan konfigurasi model yang berbeza dan mengubah bilangan model yang digunakan dalam ensemble. Kami dapati skor F1 meningkat secara drastik apabila mengumpulkan hingga 15 model, tetapi kembalian berkurang untuk lebih banyak model.', 'ml': 'നൂറുകണക്കിന് ലക്ഷത്തിനായി പരാമീറ്ററുകളുള്ള ആദ്യഭിന്നതയിലുള്ള മോഡലുകള്\u200d, ബെര്\u200dട്ടി പോലെ ടെക്സ്റ്റ് ക്ലാസ്ഫിക്ഷന്\u200d  This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as decision trees.  പ്രശ്നമായ മോഡലുകള്\u200d പരിശീലനത്തിന്റെ വിവരങ്ങള്\u200dക്ക് നന്നായി സമ്മതിക്കുമ്പോള്\u200d( കുറഞ്ഞ വിവരങ്ങളില്\u200d നിന്നും പ്രത്യേകിച്ച് ചെറിയ ഡാറ്റാസറ്റുകളില്\u200d അവയെ സുന്ദരിപ്പിക്കുമ്പോള്\u200d, ക്ലാസ്ഫിക്ഷന്\u200d പ്രവര്\u200dത്തനങ്ങള്\u200d വ്യത്യസ്തമ അത്യുന്നതമായ വ്യത്യാസങ്ങള്\u200d പരാജയപ്പെടുത്തുകയും കൂടുതല്\u200d റോബ്സ്റ്റ് പ്രവചനങ്ങള്\u200d നല്\u200dകുകയും ചെയ്യുന്നതിന് വേണ്ടി, ബൂട്ട് സ്ട്രാപ്പ്  ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഇത്രയും വിവരങ്ങള്\u200d വിശദീകരിക്കുകയും, നമ്മുടെ ജോലികളെ ഞങ്ങള്\u200d പങ്കുചേര്\u200dക്കുകയും ചെയ്യുന്നു. അക്രമത്തിന്\u200dറെ ത നമ്മുടെ കീഴ്പ്പെടുത്തുന്നത് ആറു സബ്ജിസില്\u200d അഞ്ചിന് ഏറ്റവും നല്ല പ്രവര്\u200dത്തനങ്ങളാണ്. ഉദാഹരണത്തിന്, ഞങ്ങള്\u200d എടുക്കുന്നത് 80.3% ജോലിക്കുള്ള ഒരു ഭാരം എഫ്\u200c1 സ്കോര്\u200d എടുക്കുന്നു. ഇംഗ്ലീഷ് സോഷ്യല്\u200d മേഡി നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d നമ്മള്\u200d വ്യത്യസ്ത മോഡല്\u200d ക്രമീകരണങ്ങളെ തുല്യമാക്കുകയും, ഇങ്ങനെ ഉപയോഗിക്കുന്ന മോഡലുകളു നമുക്ക് കണ്ടെത്തുന്നത് F1-സ്കോര്\u200d 15 മോഡലിലേക്ക് കൂടുതല്\u200d വലുതാണെന്നാണ്, പക്ഷെ കൂടുതല്\u200d മോഡലുകള്\u200dക്ക് തിരിച്ചുവര', 'mn': 'Орчин үеийн шилжүүлэгч суурилсан загварууд нь хэдэн сая сая параметрлүүдтэй, Жишээлбэл БЕРТ, текст хуваалтын ажил дээр гайхалтай үр дүнг гаргадаг. Энэ нь мөн халдварлах хэлний тодорхойлолтын тулд байдаг. Гүн гүнзгий суралцах нь шийдвэр гаргах моделуудын тулд бага цогц загваруудыг дамжуулдаг. Комплексийн загварууд сургалтын өгөгдлийг сайн харьцуулдаг ч тэд мөн хүсэхгүй өндөр өөрчлөлт гарч ирдэг. Ялангуяа жижиг өгөгдлийн санг тодорхойлох үед хуваалцах үйл ажиллагаа бага зэрэг өөр сургалтын өгөгдлийн хувьд чухал өөрчлөгдөж байна. Өндөр өөрчлөлтийг даван, илүү хүчтэй таамаглалт өгөхийн тулд бид олон төрлийн BERT загварын загварыг багасгах (багаж) дээр суурилуулдаг. Энэ цаасан дээр бид ийм загварын системийг тайлбарлаж, 2020 оны agression identification (баг: Жулиан) дээр хуваалцах үйл ажиллагааг тайлбарлаж байна. Бидний хүлээн зөвшөөрөх нь 6 дахин 5 дахин хамгийн сайн үйл ажиллагааны систем юм. Жишээлбэл, бид Англи нийгмийн мэдээллийн сургуулийн туршилтын А ажил дээр 80.3% жингийн F1 оноо гаргадаг. Бид өөр загварын загварыг харьцуулж, загварын тоо өөрчлөгдөж байна. Бид F1 оноо 15 загвар хүртэл маш их нэмэгддэг гэдгийг олж мэднэ. Гэхдээ илүү загварын хувьд хариулт багасч байна.', 'no': 'Moderne transformeringsmodeller med hundre millioner av parametra, som BERT, oppnår uttrykkelige resultat på tekstklassifikasjonsprogrammer. Dette inneheld også for oppdaging av agresiv- identifikasjon og offensiv språk, der dyp læring nærmer seg konsekvent over mindre komplekse modeller, som beslutningstemmer. Mens komplekse modeller passar opplæringsdata godt (låg forsiktighet), kommer dei også med eit uventa høg varianse. Spesielt når dei finne opp på små datasett, varierer klassifikasjonen betydelig for litt ulike opplæringsdata. For å overføra høg varianse og gjera meir robust forhåndsvising, foreslår vi ein ensembel av fleire fine-tuned BERT-modeller basert på oppstartstrap aggregating (bagging). I denne papiret beskriver vi så ein ensembelsystem og presenterer vårt oppføring til dei delte oppgåva om aggresjonssidentifikasjonen 2020 (gruppenamn: Julian). Vårt oppføring er det beste utføringssystemet for fem av seks underspørsmål. For eksempel, vi oppnår ein vekt F1- poeng med 80,3% for oppgåve A på testdatasettet av engelske sosiale mediepost. I eksperimentene våre sammenliknar vi ulike modelloppsett og varierer talet på modeller brukt i ensemblen. Vi finn at F1- punktet drastisk øker når det er sett opp til 15 modeller, men returneret minsker for fleire modeller.', 'pl': 'Nowoczesne modele oparte na transformatorach o setki milionów parametrów, takich jak BERT, osiągają imponujące rezultaty w zadaniach klasyfikacji tekstu. Dotyczy to również identyfikacji agresji i wykrywania obraźliwych języków, w których podejścia głębokiego uczenia konsekwentnie przewyższają mniej złożone modele, takie jak drzewa decyzyjne. Podczas gdy złożone modele dobrze pasują do danych treningowych (niskie uprzedzenie), mają również niechcianą wysoką wariancję. Zwłaszcza podczas dostrajania ich na małych zbiorach danych, wydajność klasyfikacji różni się znacznie dla nieco różnych danych treningowych. Aby przezwyciężyć wysoką wariancję i zapewnić bardziej solidne prognozy, proponujemy zespół wielu dostrojonych modeli BERT opartych na agregacji bootstrap (bagging). W artykule opisujemy taki system zespołu i przedstawiamy nasze poddanie wspólnym zadaniom dotyczącym identyfikacji agresji 2020 (nazwa zespołu: Julian). Nasze zgłoszenie jest najlepiej wydajnym systemem dla pięciu z sześciu podzadań. Na przykład osiągamy ważony wynik F1 w wysokości 80,3% dla zadania A na zestawie danych testowych angielskich postów w mediach społecznościowych. W naszych eksperymentach porównujemy różne konfiguracje modeli i różnimy liczbę modeli użytych w zespole. Odkrywamy, że wynik F1 drastycznie wzrasta podczas montażu do 15-tych modeli, ale zwroty zmniejszają się w przypadku większej liczby modeli.', 'ro': 'Modelele moderne bazate pe transformatoare, cu sute de milioane de parametri, cum ar fi BERT, obțin rezultate impresionante la sarcinile de clasificare a textelor. Acest lucru este valabil și pentru identificarea agresiunii și detectarea limbajului ofensator, în cazul în care abordările de învățare profundă depășesc în mod constant modelele mai puțin complexe, cum ar fi arborii de decizie. În timp ce modelele complexe se potrivesc bine datelor de antrenament (părtinire scăzută), ele vin, de asemenea, cu o variație ridicată nedorită. Mai ales atunci când le reglați fin pe seturi de date mici, performanța clasificării variază semnificativ pentru datele ușor diferite de antrenament. Pentru a depăși variația ridicată și pentru a oferi previziuni mai robuste, propunem un ansamblu de mai multe modele BERT reglate fin, bazate pe agregarea bootstrap (bagging). În această lucrare, descriem un astfel de sistem de ansamblu și prezentăm supunerea noastră la sarcinile comune de identificare a agresiunii 2020 (numele echipei: Julian). Trimiterea noastră este cel mai performant sistem pentru cinci din șase subactivități. De exemplu, obținem un scor F1 ponderat de 80,3% pentru sarcina A pe setul de date de testare al postărilor din rețelele de socializare engleze. În experimentele noastre, comparăm diferite configurații de model și variazăm numărul de modele utilizate în ansamblu. Considerăm că punctajul F1 crește drastic atunci când combinăm până la 15 modele, dar randamentul scade pentru mai multe modele.', 'sr': 'Moderni modeli na transformaciji sa stotine miliona parametara, kao što je BERT, ostvarili su impresivne rezultate na zadatkima klasifikacije teksta. To takođe drži za identifikaciju agresije i detekciju ofanzivnog jezika, gde se duboko učenje stalno približava manjim kompleksnim modelima, poput drveća odluke. Dok kompleksni modeli dobro uklapaju podatke o obuci (niske predrasude), takođe dolaze sa neželjenom visokom varijancijom. Posebno kad ih središ na malim podacima, klasifikacija se značajno razlikuje za malo različite podatke o obuci. Da bi preživjeli visoke varijacije i pružili robnije predviđanje, predlažemo ensemble višestruko finalnih modela BERT-a baziranog na aggregaciji jabuka. U ovom papiru opisujemo takav sistem ensemble i predstavljamo podatke zajedničkim zadacima o identifikaciji agresije 2020 (ime timova: Julian). Naša podnošenja je najbolji sistem za pet od šest podkaza. Na primjer, postigli smo težinu F1 rezultata od 80,3% za zadatak A na testnom setu podataka engleskih socijalnih medija. U našim eksperimentima uspoređujemo različite modele konfiguracije i razlikujemo broj modela koji se koristi u ensemblu. Nalazimo da se rezultat F1 drastično povećava kada se uključuje do 15 modela, ali se vraćanje smanjuje za više modela.', 'so': "Tusaalooyinka hore ee isbedelka ah oo ku yaala boqol milyan oo milyan parameters, tusaale ahaan BERT, waxay ka heli karaan fasaxyo wanaagsan oo ku saabsan shaqooyinka fasaxa qoraalka. Sidoo kale waxaa laga helaa aqoonsiga cadaawayaasha iyo aqoonsiga luqada cadaawayaasha ah, halkaas oo waxbarashada aad u dheer ku soo socota, sida geedaha go'aanka. Inta lagu jiro sameynta qalabka adag waxay ku habboon waxbarashada si wanaagsan (tababarka hoose), waxay sidoo kale ku yimaadaan isbedel dheer oo aan fileyn. Si gaar ah marka lagu sameynayo macluumaadka yaryar, tababarka fasaxu waxey si muhiim ah ugu kala duwan yihiin macluumaad waxbarasho oo kala duduwan. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging).  Qoraalkan waxaynu ku qornaa nidaam cayiman oo kale, waxaynu u soo dhiibnaa shaqaalahayaga la qaybsaday aqoonsiga galmada 2020 (magaca kooxda: Julian). Guusheena waa nidaamka ugu wanaagsan ee lagu sameeyo shan ka mid ah lix shabakad. Tusaale ahaan waxaynu helnaa koox la miisaamay F1 boqolkiiba 80.3 oo shaqo A ku qoran koorasyada tijaabada ee warqadaha bulshada Ingiriis. Imtixaanadeena, waxaynu isbarbardhignaa qaabab kala duduwan, waxaana kala duwan nahay tirada modelalka ee lagu isticmaalay muusikada. Waxaynu ognahay in kooxda F1 ay si aad u korodhaan marka uu sameynayo 15 tusaalooyin, laakiin dib u soo celinta waxay u yaraanaysaa tusaalooyin badan.", 'si': 'අධ්\u200dයාත්මක වෙනස් කරණාකරණය සඳහා මොඩල් මිලියන් ප්\u200dරමාණයක් සමග, BERT වගේ, පාළුවන් විශේෂණ කාර්යාවට ප්\u200dරශ මේක තියෙන්නේ අපරාධ පරීක්ෂණය සහ අපරාධ භාෂාව හොයාගන්න, ගොඩක් ඉගෙනගන්න පුළුවන් පුළුවන් පරීක්ෂණ මදුල්  සම්පූර්ණ මොඩේල් හොඳටම ප්\u200dරශ්නය දත්ත හොඳයි (අඩුම ප්\u200dරශ්නයක්), ඔවුන් අවශ්\u200dය වෙනස් වෙනුවෙන්  විශේෂයෙන්ම ඔවුන්ව පුංචි දත්ත සේට් වලට හොඳින් සැකසුම් කරන්න, විශේෂණ ක්\u200dරියාත්මක වෙනස් වෙනස් ව අධ්\u200dයම විශාල විදියට පැහැදිලි කරන්න සහ තරම් ශක්තිමත් ප්\u200dරශ්නයක් දෙන්න, අපි ප්\u200dරශ්නයක් කරන්නේ බුට්ස්ට්\u200dරෑප් සම්පූර්ණ මේ පත්තරේ අපි ඒ වගේ පද්ධතියක් විස්තර කරනවා ඒ වගේම අපේ පද්ධතිය පෙන්වන්න සහ අපේ පෙන්වන්න පුළුවන් විදිහට පත්තර කර අපේ පිළිගන්න පුළුවන් තමයි හොඳම පද්ධතිය පිළිගන්න පුළුවන් පද්ධතිය. උදාහරණයෙන්, අපි ඉංග්\u200dරීසි සාමාජික මාධ්\u200dයම පොස්ටල් පරීක්ෂණයේ පරීක්ෂණ දත්ත සූදානයේ වැඩේ 80.3% කිරීමේ  අපේ පරීක්ෂණාවට, අපි වෙනස් මොඩල් සැකසුම් සමග වෙනස් කරනවා ඒ වගේම පරීක්ෂණයෙන් භාවිත වෙනස් කරනවා. අපිට හොයාගන්න පුළුවන් විදිහට F1-ස්කෝර් විශේෂයෙන් වැඩි වෙනවා මොඩේල් 15ක් වෙනුවෙන්, ඒත් වැඩි මොඩේල් වලට ආ', 'sv': 'Moderna transformatorbaserade modeller med hundratals miljoner parametrar, som BERT, ger imponerande resultat vid textklassificeringsuppgifter. Detta gäller även för aggressiv identifiering och kränkande språkidentifiering, där djupinlärningsmetoder konsekvent överträffar mindre komplexa modeller, såsom beslutsträd. Även om de komplexa modellerna passar träningsdata väl (låg bias), kommer de också med en oönskad hög varians. Särskilt när man finjusterar dem på små dataset varierar klassificeringens prestanda avsevärt för något olika träningsdata. För att övervinna den höga variansen och ge mer robusta förutsägelser föreslår vi en uppsättning av flera finjusterade BERT-modeller baserade på bootstrap aggregering (bagging). I den här uppsatsen beskriver vi ett sådant ensemblesystem och presenterar vårt bidrag till gemensamma uppgifter om aggressionsidentifiering 2020 (teamnamn: Julian). Vårt bidrag är det bästa systemet för fem av sex underuppgifter. Till exempel uppnår vi en viktad F1-poäng på 80,3% för uppgift A på testdatauppsättningen för engelska sociala medier inlägg. I våra experiment jämför vi olika modellkonfigurationer och varierar antalet modeller som används i ensemblen. Vi finner att F1-poängen ökar drastiskt när man sätter ihop upp till 15 modeller, men avkastningen minskar för fler modeller.', 'ur': 'سنوں میلیون پارامیٹر کے ساتھ مدرن ترنسفور بنیادی موڈل، جیسے BERT، متن کلسفون کے کاموں میں اثر انگیز نتیجے حاصل کرتے ہیں. یہ بھی گھبراہٹ کی شناسایی اور فساد کی زبان کی شناسایی کے لئے ہے جہاں عمیق سیکھنے کی تقریبا کم پیچیدہ موڈل سے کام لیتے ہیں، جیسے فیصلہ کے درخت. اگرچہ پیچیدہ موڈلز ڈیٹا بہت اچھے مطابق مطابق ہوتے ہیں (کم بغیر اچھی بغیر اچھی بغیر اچھی بغیر اچھی تفاوت کے ساتھ بھی آتے ہیں۔ مخصوصاً جب ان کو چھوٹے ڈیٹسٹ پر سیدھی تنظیم کرتا ہے، کلاسیفوں کی عملکرد تھوڑی مختلف ترینس ڈیٹ کے لئے اضافہ ہوتی ہے. بلند متفاوت پر غالب ہونے کے لئے اور زیادہ مضبوط پیش بینی کرنے کے لئے، ہم بہت سی مضبوط BERT موڈلیوں کے مطابق بوٹ سٹرپ جمع کرنے (bagging) پر بنیاد رکھتے ہیں۔ اس کاغذ میں ہم ایسی ایک انسبیل سیسٹم کو توصیح دیتے ہیں اور ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیشہ ہمیش ہماری اطاعت چھ دفعہ سے پانچ کے لئے بہترین عمل کرنے والی سیستم ہے۔ مثال، ہم ایک وزن F1-اسکور پہنچ رہے ہیں جو کام A کے لئے 80.3% کی ہے انگلیسی سوسیل میڈیا پوسٹ کے امتحان ڈیٹسٹ پر۔ ہمارے آزمائش میں، ہم مختلف موڈل کی سازواریزوں کی مقایسہ کرتے ہیں اور انسبل میں استعمال کی موڈل کی تعداد تغییر کرتے ہیں. ہم دیکھتے ہیں کہ F1-اسکور 15 نمڈلوں تک اضافہ ہوتا ہے لیکن دوبارہ مدلوں کے لئے کم ہوتا ہے۔', 'ta': 'BERT போன்ற நூற்று மில்லியன் அளபுருக்களுடன் தற்போதைய மாற்றம் அடிப்படையான மாதிரிகளை பெறுக இதுவும் தீர்ப்பு மரங்கள் போன்ற குறைந்த சிக்கலான மாதிரிகளை கண்டுபிடிக்கும் மொழி கண்டுபிடிப்பு மற்றும் தீர்ப்பு  சிக்கலான மாதிரிகள் பயிற்சி தரவுகளை நன்றாக பொருத்தும் போது, அவர்கள் எதிர்பாராத மாறுபாடுகளுடன் வருகின்றனர். Especially when fine-tuning them on small datasets, the classification performance varies significantly for slightly different training data.  அதிக மாறுபாட்டை வெற்றி மற்றும் அதிக ரோப்ட் முன்னோட்டுகளை கொடுக்க, நாம் துவக்குதலை குறிப்பிடுதலை அடிப்படையில் சார்ந்த பல நன்றா இந்த காகிதத்தில், நாம் இவ்வாறு ஒரு ஒதுங்கும் அமைப்பை விவரிக்கிறோம் மற்றும் நாங்கள் எங்கள் பணிகளை கூட்டிடுகிறோம் பகிர் ஆறு துணை பணிகளில் ஐந்து ஐந்து சிறந்த செயல்படுத்தும் அமைப்பு தான். எடுத்துக்காட்டாக, நாங்கள் 80.3% எடையான F1- புள்ளி எங்கள் சோதனைகளில், நாம் வேறு மாதிரி வடிவமைப்புகளை ஒப்பிட்டு மாதிரிகளின் எண்ணிக்கையை மாறுகிறோம். F1- மதிப்பெண்கள் 15 மாதிரிகளை சேர்க்கும் போது அதிகமாக அதிகரிக்கும் என்பதை நாம் கண்டுபிடிக்கிறோம், ஆனால் அதிக மாதிர', 'mt': 'Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks.  This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as decision trees.  Filwaqt li l-mudelli kumplessi jaqblu tajjeb mad-dejta tat-taħriġ (bias baxx), huma wkoll ġejjin b’varjanza għolja mhux mixtieqa. Speċjalment meta jiġu rfinuti fuq settijiet żgħar ta’ dejta, il-prestazzjoni tal-klassifikazzjoni tvarja b’mod sinifikanti għal dejta ta’ taħriġ kemmxejn differenti. Biex tingħeleb il-varjanza għolja u nipprovdu tbassir aktar robust, nipproponu ensemble ta’ mudelli BERT multipli aġġustati fini bbażati fuq l-aggregazzjoni tal-bootstrap (bagging). F’dan id-dokument, niddeskrivu sistema ta’ ensemble bħal din u nippreżentaw is-sottomissjoni tagħna lill-kompiti kondiviżi dwar l-identifikazzjoni tal-aggressjoni 2020 (isem it-tim: Julian). Is-sottomissjoni tagħna hija s-sistema bl-aħjar prestazzjoni għal ħames minn kull sitt sottomistoqsijiet. For example, we achieve a weighted F1-score of 80.3% for task A on the test dataset of English social media posts.  Fl-esperimenti tagħna, aħna nqabblu konfigurazzjonijiet differenti tal-mudelli u jvarjaw in-numru ta’ mudelli użati fl-ensemble. We find that the F1-score drastically increases when ensembling up to 15 models, but the returns diminish for more models.', 'uz': "Name Bu tilni aniqlashni ko'rsatish va ta'minlovchi tilni aniqlashga ega bo'ladi. Bu yerda eng yuqori o'rganishlar murakkab modellarni, tushunish daraxtlari kabi murakkab modellarni bajaradi. Ko'rsatilgan murakkab modellar yaxshi taʼminlovchi maʼlumotga ega bo'lganda, ular juda muhim o'zgarishlar bilan keladi. Maxsus, ularni kichkina maʼlumotlar tarkibida yaxshi ko'paytirishda darajalashtirish bajarishi bir necha xil taʼminlovchi maʼlumot uchun juda muhimi. Ko'pchilik o'zgarishni oshirish va ko'proq qo'shish uchun biz boshqaruvchi BERT modellarining asosida ko'plab ajoyib ko'plab chiqqan modellarni tasavvur qilamiz. Bu qogʻozda biz bunday foydalanuvchi tizimni anglatamiz va 2020 tashkilotlarimizni qisqarish qismlariga ega qilamiz (guruh nomi: Juli). Bizning ishimiz 6 ta vazifalardan 5 ta vazifalar uchun eng yaxshi bajarish tizimdir. Masalan, biz Ingliz jamiyati medya postlarining sinov maʼlumotlari haqida 80.3% вазифаси Aga o'xshaymiz. In our experiments, we compare different model configurations and vary the number of models used in the ensemble.  Biz qidirib, F1 scori 15 modelga qo'yish paytida o'zgartirib ko'payapmiz, lekin ko'proq modellar uchun qaytadi.", 'vi': "Sự biến đổi hiện đại với hàng trăm triệu thông số, như BERT, đã đạt được những kết quả ấn tượng trong các nhiệm vụ phân loại văn bản. Điều này cũng dành cho việc nhận dạng hung thủ và phát hiện ngôn ngữ tấn công, nơi các phương pháp học sâu liên tục vượt trội các mô hình ít phức tạp, như cây quyết định. Trong khi các mô hình phức tạp phù hợp với dữ liệu huấn luyện tốt (khuynh hướng thấp), chúng cũng có một sự khác biệt lớn không mong muốn. Đặc biệt khi chỉnh sửa chúng trên các bộ dữ liệu nhỏ, tỉ lệ phân hạng thay đổi rất nhiều với các dữ liệu huấn luyện hơi khác nhau. Để vượt qua sự thay đổi lớn và cung cấp những dự đoán mạnh mẽ hơn, chúng tôi đề xuất một kết hợp các mô hình hỗn hợp BERT hoàn chỉnh dựa trên khởi động tụ tập (túi nhỏ). Trong tờ giấy này, chúng tôi mô tả một hệ thống kết hợp như vậy và giới thiệu sự chịu trách nhiệm chung về việc xác định tấn công 2020 (biệt danh: Julian). Việc đệ trình của chúng tôi là hệ thống làm tốt nhất cho năm phần sáu. Thí dụ như, chúng ta đạt được trọng lượng F1 của 80.3='cho nhiệm vụ A trên tập tin thử nghiệm của các bài báo mạng xã hội Anh Quốc. Trong các thí nghiệm, chúng tôi so sánh cấu hình mô hình khác nhau và thay đổi số mẫu được dùng trong dàn nhạc. Chúng tôi thấy điểm số F1 tăng mạnh khi kết hợp với mô hình 15, nhưng điểm thu lại giảm vì nhiều mô hình.", 'bg': 'Модерните трансформаторни модели със стотици милиони параметри, като например постигат впечатляващи резултати при задачите за класификация на текста. Това важи и за идентифициране на агресия и откриване на офанзивен език, където подходите за дълбоко учене постоянно превъзхождат по-малко сложните модели, като например дърветата за вземане на решения. Докато сложните модели се вписват добре в данните за тренировка (ниско отклонение), те също така идват с нежелана висока вариация. Особено при фина настройка на малки набори от данни, класификационните показатели варират значително за малко по-различни данни за обучение. За да преодолеем високата вариация и да осигурим по-стабилни прогнози, предлагаме ансамбъл от множество фино настроени модели базирани на агрегиране на bootsstrap (опаковане). В настоящата статия описваме такава ансамбълна система и представяме нашето подчинение на споделените задачи по идентификация на агресията 2020 (име на екипа: Джулиан). Нашето подаване е най-добрата система за пет от шест подзадачи. Например, ние постигаме претеглен резултат от 80,3% за задача А на тестовия набор от данни на публикациите в социалните медии в Англия. В нашите експерименти сравняваме различни конфигурации на моделите и варираме броя на моделите, използвани в ансамбъла. Откриваме, че резултатът драстично се увеличава при ансамблиране до 15 модела, но възвръщаемостта намалява при повече модели.', 'hr': 'Moderni modeli na transformaciji s stotinama milijuna parametara, poput BERT, postignu impresivne rezultate na zadatkima klasifikacije teksta. To se također drži za identifikaciju agresije i otkrivanje ofanzivnog jezika, gdje se duboko učenje stalno približava manjim složenim modelima, poput drveća odluke. Iako kompleksni modeli dobro odgovaraju podacima obuke (niske predrasude), također dolaze s neočekivanom visokom varijancijom. Posebno kad ih ispravljaju na malim podacima, učinkovitost klasifikacije značajno razlikuje za malo različite podatke o obuci. Za prevladavanje visokog varijansa i pružanje jača predviđanja, predlažemo ensemble višestrukog finalnog modela BERT-a temeljnog na aggregaciji jabuka. U ovom papiru opisujemo takav sistem ensemble i predstavljamo podatke zajedničkim zadatkima o identifikaciji agresije 2020 (ime timova: Julian). Naša podnošenja je najbolji sustav za pet od šest poduzeća. Na primjer, postigli smo težinu F1 rezultata od 80,3% za zadatak A na testnom setu podataka engleskih socijalnih medija. U našim eksperimentima uspoređujemo različite modele konfiguracije i promijenimo broj modela korištenih u ensemblu. Nalazimo da se rezultat F1 drastično povećava kada se uključuje do 15 modela, ali se vraćanje smanjuje za više modela.', 'da': 'Moderne transformatorbaserede modeller med hundredvis af millioner parametre, såsom BERT, opnår imponerende resultater ved tekstklassifikationsopgaver. Dette gælder også for aggressionsidentifikation og stødende sprogdetektering, hvor dyb læring konsekvent overgår mindre komplekse modeller, såsom beslutningstræer. Mens de komplekse modeller passer godt til træningsdata (lav bias), kommer de også med en uønsket høj varians. Især når de finjusteres på små datasæt, varierer klassificeringsydelsen betydeligt for lidt forskellige træningsdata. For at overvinde den høje varians og give mere robuste forudsigelser, foreslår vi et sæt af flere finjusterede BERT-modeller baseret på bootstrap aggregering (bagging). I denne artikel beskriver vi et sådant ensemblesystem og præsenterer vores indsendelse til de fælles opgaver om aggressionsidentifikation 2020 (holdnavn: Julian). Vores indsendelse er det bedste system til fem ud af seks underopgaver. For eksempel opnår vi en vægtet F1-score på 80,3% for opgave A på testdatasættet af engelske indlæg på sociale medier. I vores eksperimenter sammenligner vi forskellige modelkonfigurationer og varierer antallet af modeller, der anvendes i ensemblet. Vi oplever, at F1-scoren stiger drastisk, når der samles op til 15 modeller, men afkastet falder for flere modeller.', 'nl': 'Moderne transformatormodellen met honderden miljoenen parameters, zoals BERT, bereiken indrukwekkende resultaten bij tekstclassificatietaken. Dit geldt ook voor agressie identificatie en aanstootgevende taaldetectie, waarbij deep learning benaderingen consequent beter presteren dan minder complexe modellen, zoals beslissingsbomen. Hoewel de complexe modellen goed aansluiten op trainingsgegevens (low bias), hebben ze ook een ongewenste hoge variantie. Vooral bij het finetunen op kleine datasets variëren de classificatieprestaties aanzienlijk voor iets verschillende trainingsgegevens. Om de hoge variantie te overwinnen en robuustere voorspellingen te bieden, stellen we een ensemble voor van meerdere verfijnde BERT modellen gebaseerd op bootstrap aggregatie (bagging). In dit artikel beschrijven we een dergelijk ensemblesysteem en presenteren we onze inzending aan de gedeelde taken over agressie identificatie 2020 (teamnaam: Julian). Onze inzending is het best presterende systeem voor vijf van de zes subtaken. Zo bereiken we een gewogen F1-score van 80,3% voor taak A op de testdataset van Engelse social media posts. In onze experimenten vergelijken we verschillende modelconfiguraties en variëren we het aantal modellen dat in het ensemble wordt gebruikt. We merken dat de F1-score drastisch toeneemt bij het samenstellen van tot 15-modellen, maar dat het rendement bij meer modellen afneemt.', 'ko': '수억 개의 파라미터를 가진 현대 변환기 기반 모델(예를 들어 버트)은 텍스트 분류 작업에서 인상적인 결과를 얻었다.이것도 공격적 식별과 공격적 언어 검측에 적용되고 깊이 있는 학습 방법은 결정 트리 등 복잡하지 않은 모델보다 우수하다.복잡한 모델은 훈련 데이터(낮은 편차)를 잘 맞췄지만 불필요한 높은 편차를 가져왔다.특히 소형 데이터 집합에서 미세하게 조정할 때 약간 다른 훈련 데이터에 대해 분류 성능은 현저한 차이가 있을 수 있다.높은 방차를 극복하고 더욱 안정적인 예측을 제공하기 위해 우리는 bootstrap 집합(bagging)을 바탕으로 하는 여러 개의 마이크로스피커 BERT 모델의 통합을 제시했다.본고에서 우리는 이러한 통합 시스템을 묘사하고 2020년 공격인식 공유 임무(팀명: Julian)에 우리의 보고서를 제출했다.여섯 개의 하위 임무 중 다섯 개의 하위 임무에 대해 우리의 제출은 성능이 가장 좋은 시스템이다.예를 들어 영어 소셜미디어 게시물의 테스트 데이터 세트에서 임무 a의 F1 가중점수는 80.3%였다.우리의 실험에서 우리는 서로 다른 모델의 배치를 비교하고 집합에서 사용하는 모델의 수량을 바꾸었다.우리는 15개의 모델을 집합할 때 F1 점수가 급격히 증가하지만 더 많은 모델의 수익은 감소한다는 것을 발견했다.', 'de': 'Moderne transformatorbasierte Modelle mit hunderten Millionen Parametern wie BERT erzielen beeindruckende Ergebnisse bei Textklassifikationsaufgaben. Dies gilt auch für Aggressionserkennung und offensive Spracherkennung, bei denen Deep-Learning-Ansätze weniger komplexe Modelle, wie Entscheidungsbäume, durchweg übertreffen. Während die komplexen Modelle gut zu Trainingsdaten passen (low bias), weisen sie auch eine ungewollt hohe Varianz auf. Gerade bei der Feinabstimmung auf kleinen Datensätzen variiert die Klassifikationsleistung bei leicht unterschiedlichen Trainingsdaten erheblich. Um die hohe Varianz zu überwinden und robustere Vorhersagen zu liefern, schlagen wir ein Ensemble aus mehreren fein abgestimmten BERT-Modellen vor, die auf Bootstrap Aggregation (Bagging) basieren. In diesem Beitrag beschreiben wir ein solches Ensemblesystem und stellen unsere Einreichung zu den gemeinsamen Aufgaben zur Aggressionserkennung 2020 (Teamname: Julian) vor. Unsere Einreichung ist das leistungsstärkste System für fünf von sechs Teilaufgaben. So erreichen wir beispielsweise einen gewichteten F1-Score von 80,3% für Aufgabe A auf dem Testdatensatz englischer Social Media Posts. In unseren Experimenten vergleichen wir verschiedene Modellkonfigurationen und variieren die Anzahl der im Ensemble verwendeten Modelle. Wir stellen fest, dass die F1-Punktzahl beim Zusammenstellen von bis zu 15-Modellen drastisch ansteigt, aber die Renditen bei mehr Modellen sinken.', 'id': 'Modern model berbasis transformer dengan ratusan juta parameter, seperti BERT, mencapai hasil yang mengesankan pada tugas klasifikasi teks. Ini juga berlaku untuk identifikasi agresi dan deteksi bahasa yang menyerang, di mana pendekatan belajar dalam secara konsisten melebihi model yang kurang kompleks, seperti pohon keputusan. Sementara model kompleks cocok dengan data latihan dengan baik (bias rendah), mereka juga datang dengan variasi tinggi yang tidak diinginkan. Terutama ketika memperbaiki mereka pada set data kecil, prestasi klasifikasi bervariasi signifikan untuk data latihan yang sedikit berbeda. Untuk mengatasi variasi tinggi dan menyediakan prediksi yang lebih kuat, kami mengusulkan sebuah ensemble dari banyak model BERT yang disesuaikan baik berdasarkan agregasi bootstrap. Dalam kertas ini, kami menggambarkan sistem ensemble seperti itu dan mempersembahkan kami untuk tugas berbagi tentang identifikasi agresi 2020 (nama tim: Julian). Pengiriman kami adalah sistem yang terbaik untuk lima dari enam subtasks. Contohnya, kita mencapai nilai F1 berat 80,3% untuk tugas A pada set data tes dari pos media sosial Inggris. Dalam eksperimen kami, kami membandingkan konfigurasi model yang berbeda dan mengubah jumlah model yang digunakan dalam ensemble. Kami menemukan bahwa skor F1 secara drastis meningkat ketika mengumpulkan sampai 15 model, tetapi kembaliannya berkurang untuk lebih banyak model.', 'sw': 'Mifano ya mabadiliko ya sasa yenye mamia ya mamilioni ya parameter, kama vile BERT, hupata matokeo mazuri katika kazi za usambazaji wa maandishi. Hii pia inahusu kutambua uvunjifu na kutambua lugha ya ghasia, ambapo mafunzo ya kina ya kujifunza yanatokana na mifano ya tatizo, kama vile miti ya uamuzi. Wakati mifano ngumu inafaa mafunzo ya taarifa nzuri (upendeleo mdogo), pia wanakuja na tofauti kubwa isiyotarajiwa. Hasa pale wanapokuwa wakitunza vizuri kwenye seti ndogo, utendaji wa usambazaji unatofauti sana kwa takwimu tofauti za mafunzo. Ili kushinda tofauti kubwa na kutoa utabiri zaidi wa kibaguzi, tunapendekeza mfumo wa mitindo mbalimbali ya BERT kwa msingi wa kupambana na mabomu. Katika gazeti hili, tunaelezea mfumo wa aina hiyo na kuweka ujumbe wetu wa kazi zetu zinazoshirikishwa juu ya utambulisho wa ukatili wa 2020 (jina la timu: Julian). Ujumbe wetu ni mfumo bora wa kufanya kazi tano kati ya kazi sita. Kwa mfano, tunapata kipimo cha F1 cha asilimia 80.3 kwa kazi A kwenye seti ya taarifa za mitandao ya kijamii ya Kiingereza. Katika majaribio yetu, tunalinganisha mabadiliko tofauti ya mifano na kubadilisha idadi ya mifano iliyotumika kwenye mfumo huo. Tunapata kwamba score za F1 huongezeka kwa kiasi kikubwa pale unapoingia kwenye mifano 15, lakini kurudi hupungua kwa mifano zaidi.', 'tr': '횦체zler챌e milyon parameterler bilen modern transformer nusgalary, BERT 첵aly, metin klasifikasynda t채sirli netijesi ba힊ar첵ar. Bu hem agresi첵a tanamak we suyt eden diller deteksi첵asy 체챌in bar. Derrew 철wrenmek hem 챌yky힊 힊eklinde karar 챌yky힊 힊eklinde azajyk nusgalary 챌ykar첵ar. Karma힊캇k nusgalar okuw챌ylyk maglumatlaryna gowy gabat gel첵채n bolsa hem isleme첵채n 첵okary 체첵tge힊ik bilen gelirler. Adat챌a ki챌i datawatlary흫 체stine s체첵tgetmeginde, klasifikasi첵a eserle힊meleri biraz farkl캇 e휓itim maglumaty 체챌in 철r채n 체첵tge힊ikdir. Y체ksek warianty흫 체st체ne ge챌irmek we daha g체챌l체 tahmin etmek 체챌in, boot strap toplamas캇na dayanan BERT modellerinin bir k철p체si teklif ediyoruz. Bu kagyzda, biz 힊e첵le bir sy첵asaty tassy첵ardyk we olary흫 suratymyzy 2020-nji 첵ylda b철l체n첵채n zadymyzy (topar ady: 횦uli첵an) ber첵채ris. Bizi흫 teslim edi힊imiz alty 챌철z체mden be힊 체챌in i흫 gowy 체st체nlik sistemidir. mysal bolsa, biz I흫lis챌e sosyal med첵dan챌alary흫 첵erle힊dirilip barlag 체챌in 80.3% ta첵첵arlyk 첵etip bardyk. Bizi흫 deneylerimizde, farkl캇 nusgalary d체zenle첵채ris we ensemblerde ulanylan nusgalary흫 sanyny 체첵tge힊dir첵채ris. F1 noktalary 15 nusga 첵agda첵a d체힊체rkende, 첵철ne k철p nusga 체챌in azalt첵ar.', 'sq': 'Modelet moderne me bazë transformuese me qindra miliona parametra, të tillë si BERT, arrijnë rezultate mbresëlënëse në detyrat e klasifikimit të tekstit. Kjo mban gjithashtu për identifikimin e agresionit dhe zbulimin ofensiv të gjuhës, ku afrohet mësimi i thellë vazhdimisht më tepër se modelet më pak komplekse, të tilla si pemët e vendimeve. Ndërsa modelet komplekse përshtaten mirë me të dhënat e trainimit (paragjykim i ulët), ato vijnë gjithashtu me një variancë të lartë të padëshiruar. Veçanërisht kur i përshtatet ato në grupe të dhënash të vogla, performanca e klasifikimit ndryshon ndjeshëm për të dhënat e trainimit pak të ndryshme. Për të kapërcyer variancën e lartë dhe të ofrojmë parashikime më të forta, ne propozojmë një komplet të modeleve të shumëfishtë të rregulluar BERT bazuar në agregimin e bootstrap (bagging). Në këtë letër, ne përshkruajmë një sistem të tillë ansambli dhe paraqesim paraqitjen tonë ndaj detyrave të përbashkëta mbi identifikimin e agresionit 2020 (emri i ekipit: Julian). Përdorimi ynë është sistemi më i mirë për pesë nga gjashtë nënpyetje. Për shembull, ne arrijmë një rezultat të peshuar F1 prej 80.3% për detyrën A në grupin e të dhënave të testit të postimeve të medias sociale angleze. In our experiments, we compare different model configurations and vary the number of models used in the ensemble.  Ne zbulojmë se rezultati F1 rritet drastikisht kur mblidhet deri në 15 modele, por kthimet zvogëlohen për më shumë modele.', 'fa': 'مدل\u200cهای تغییر\u200cپذیر مدرن با صدها میلیون\u200cها پارامتر، مثل BERT، نتیجه\u200cهای تاثیر\u200cپذیر در وظیفه\u200cهای تغییر\u200cپذیر متن را می\u200cرساند. این همچنین برای شناسایی تجاوز و کشف زبان تجاوز دارد، جایی که یادگیری عمیق به طور کامل نزدیک می شود مدل های پیچیده کمتر از آن انجام می دهد، مانند درختان تصمیم گرفتن. در حالی که مدلهای پیچیده به اطلاعات آموزشی (طبقه\u200cای کم) مناسبی دارند، همچنین با تغییر بالا نمی\u200cخواهند. مخصوصا هنگامی که آنها را در مجموعه\u200cهای داده\u200cهای کوچک تنظیم می\u200cکند، عملکرد تنظیم برای داده\u200cهای آموزش\u200cهای کوچک معنی متفاوت می\u200cکند. برای تغییرات بالا و پیش\u200cبینی\u200cهای قوی\u200cتر پیشنهاد می\u200cکنیم، ما پیشنهاد می\u200cکنیم یک جمله از مدل\u200cهای BERT بسیار تنظیم شده بر اساس جمع\u200cآوری (بسته\u200cهای بسته\u200cها). در این کاغذ، ما چنین سیستم انجمن را توصیف می\u200cکنیم و تحویل ما را به وظیفه\u200cهای مشترک در مورد شناسایی تجاوز ۲۰۰۲ (اسم تیم: جولیان) پیشنهاد می\u200cکنیم. تسلیم ما بهترین سیستم اجرایی برای پنج از شش پایگاه است. برای مثال، ما یک نمونه وزن F1 از 80.3 درصد برای کار A در مجموعه داده های آزمایش پوست رسانه های اجتماعی انگلیسی رسیدیم. در آزمایشات ما، ما پیکربندی\u200cهای مدل مختلف را مقایسه می\u200cکنیم و تعداد مدل\u200cهای استفاده شده در انجمل تغییر می\u200cدهیم. ما پیدا می\u200cکنیم که نمونه\u200cهای F1 در حالی که به ۱۵ مدل جمع می\u200cشود، اضافه می\u200cشود، اما بازگشت برای مدل بیشتری کمتر می\u200cشود.', 'af': "Moderne transformer-gebaseerde modele met honderd van miljoene parameters, soos BERT, bereik inpresief resultate by teks klassifikasie taak. Hierdie hou ook vir agressie identifikasie en offensivele taal-opdekking, waar diep leer toegang tot konsistent meer komplekse modele uitvoer, soos besluit bome. Alhoewel die komplekse modele goed opvoer opvoer data (lae bias), kom hulle ook met 'n onverwagte hoë variasie. Spesiaal wanneer hulle op klein datastelle fin- tuning, varieer die klassifikasie prestasie betekenlik vir klein verskillende onderwerking data. Om die hoë verandering te oorwin en meer sterkte voorskou te verskaf, voorstel ons 'n ensemble van veelvuldige fyn-tuned BERT modele gebaseer op bootstrap aggregating (bagging). In hierdie papier beskryf ons sodanige 'n ensemble stelsel en voorsien ons ondersteuning aan die gedeelde taak op agresieidentifikasie 2020 (team name: Julian). Ons ondersteuning is die beste uitvoerde stelsel vir vyf uit ses subtaske. Byvoorbeeld, ons kry 'n gewigte F1- telling van 80. 3% vir taak A op die toets datastel van Engelske sosiale media pos. In ons eksperimente vergelyk ons verskillende model konfigurasies en verander die aantal modele gebruik in die ensemble. Ons vind dat die F1- telling drastiese vergroot word wanneer opstel tot 15 modele, maar die terugkeer verklein vir meer modele.", 'am': 'የአሁኑ የለውጥ ምሳሌ በመቶ ሚሊዮን ሚሊዮን parameters such as BERT የጽሑፍ መግለጫ ስራዎችን የሚያደርግ ፍሬዎችን ያገኛል፡፡ ይህም ደግሞ የአስቸጋሪ መፍታት እና የቋንቋ ማግኘት ይኖራል፤ ጥልቅ ትምህርት እንደዚህ የፍርድ ዛፎች እንደምትሆን ትንሽ ትክክለኛ ምሳሌዎችን ያሳያል፡፡ አካባቢው ምሳሌዎቹ ለዳታ መግለጫ ጥሩ ሲገኙ (ዝናብ ቢስ) በተለየ ከፍተኛ ልዩነት ደግሞ ይመጣሉ፡፡ በተለይም በተለየ ትንሽ ዳታዎችን በመጠቀም ጊዜ የተለያየው የሥርዓት ሥርዓት ለጥቂት የተለየ ትምህርት ዳታ በትክክል ይለያያል፡፡ ከፍተኛ ልዩነት ለማሸንፋት እና የበዛ የረኀብ ትንቢት ለማድረግ፣ የብኤርቴን ዓይነቶች በመጠቀም በብዙ ጥሩ ብኤርቴን ሞዴል እናሳልቃለን፡፡ በዚህ ገጾች ውስጥ እንዲህ ያለ አዲስ ስርዓት እናሳውቃለን፡፡ የስድስት ደብዳቤዎች አምስት የሚደረገው ትልቅ ስርዓት ነው፡፡ ለምሳሌ፣ ለእንግሊዝኛ ማኅበራዊ አውታር ሚዲያዎች የድምፅ መረጃዎችን በመስመር አ በሚዛን F1.3 በመቶ አግኝተናል፡፡ በሞከራችን ውስጥ የተለየን የሞዴል ምርጫዎችን እናሳያታለን እና በዓይነባቢል ውስጥ የሚጠቀሙትን የሞዴላዎችን ቁጥር እንለካለን፡፡ F1-score ወደ 15 ምሳሌዎች ሲሰብስብ በኃይል ሲጨመር እናገኛለን፣ ነገር ግን ለብዙዎች ምሳሌዎችን ሲጎድል እናገኛለን፡፡', 'hy': 'Հիմա ժամանակակից վերափոխողների հիմնված մոդելներ, որոնք ունեն հարյուրավոր միլիոնավոր պարամետրեր, ինչպիսիք են ԲԵՌթը, ունեն տպավորիչ արդյունքներ տեքստի դասակարգման խնդիրներում: This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as decision trees.  Մինչդեռ բարդ մոդելները լավ համապատասխանում են ուսուցման տվյալներին (ցածր կողմնականություն), նրանք նաև ունեն անցանկանալի բարձր տարբերակներ: Հատկապես, երբ դրանք փոքր տվյալների համակարգերի վրա բարձրացնում են, դասակարգման արդյունքները նշանակալի տարբերվում են փոքր տարբեր ուսուցման տվյալների համար: Բավականին տարբերակների հաղթահարելու և ավելի ուժեղ կանխատեսումների ապահովելու համար մենք առաջարկում ենք BER-ի բազմաթիվ բարձրակարգված մոդելների համակարգ, որը հիմնված է Boot strap-ի ագրեգացիայի վրա: Այս թղթի մեջ մենք նկարագրում ենք այդպիսի համակարգ և ներկայացնում ենք մեր ներկայացումը համագործակցած խնդիրներին, որոնք վերաբերում են ագրեսիայի 2020-ին հայտնաբերելուն (թիմի անունը Ջուլիան): Մեր ներկայացումը ամենաարդյունավետ համակարգն է վեց ենթահարցերից հինգ մեկի համար: Օրինակ, մենք հասնում ենք Անգլերենի սոցիալական լրատվամիջոցների փորձարկումների A-ի համար 80.3 տոկոսի կենտրոնացված F1-գնահատականը: Մեր փորձարկումներում մենք համեմատում ենք տարբեր մոդելների կառուցվածքները և տարբերում ենք համակարգում օգտագործվող մոդելների քանակը: Մենք հայտնաբերում ենք, որ F1-ի գնահատականը խիստ աճում է մինչև 15 մոդելներ համադրելիս, բայց եկամուտը ավելի շատ մոդելների դեպքում նվազում է:', 'az': "Yüzlərlə milyonlarca parametru olan moderni transformer-tabanlı modelləri, BERT kimi, metin klasifikasyonunda etkileyici sonuçlar yetişir. Bu həmçinin aggressiya kimlikləri və həddi-büluq dillərini keşfetməsi üçün də var. Derin öyrənməsi həmişə daha az kompleks modellərdən, bəlkə karar ağacları kimi daha çox çətin modellərdən istifadə edir. Kompleksik modellər təhsil məlumatlarına yaxşı uyğun gəlirsə də, onlar istəməyən yüksək dəyişiklik ilə gəlirlər. Özellikle ki, kiçik verilən qurğularda onları düzəltdikdə, klasifikasiya performansı biraz fərqli təhsil verilən məlumatları üçün çox dəyişiklik edir. Yüksek dəyişiklikləri üstün etmək və daha qüvvətli tədbirləri təmin etmək üçün, bootstrap aggregation (bagging) üzərində dayanan çoxlu tədbirli BERT modellərin bir körpüsünü təklif edirik. Bu kağızda, böyük bir ensemble sistemini təsbiq edirik və 2020-ci aggressiya kimliğinin paylaşılmış işlərə tətbiq edirik. Bizim müsəlmanımız altı dəstədən beş müsəlmanların ən yaxşı performans sistemidir. Misal olaraq, biz İngilizə sosyal media poçtalarının sınaması üçün A'nin 80,3%-dən a ğırlı F1 dəqiqəsini qəbul edirik. Bizim təcrübələrimizdə, müxtəlif modellər yapılandırmalarını salıyır və ensemblində kullanılan modellərin sayını dəyişdiririk. F1 nöqtəsi 15 modellərə qovuşduğunda dərin artırdığını görürük, lakin geri dönüş daha çox modellərə azaldır.", 'bn': 'আধুনিক পরিবর্তনের ভিত্তিক মডেল, যার মাধ্যমে শত লক্ষ লক্ষ মাত্রা রয়েছে, যেমন বিবের্ট, লেখা ক্লাসাফিকেশন কাজে আকর্ষণীয় ফলাফল অর্জন কর এছাড়াও এ ধরনের আক্রমণের পরিচয় এবং আক্রমণের ভাষা সনাক্ত করার জন্য রয়েছে, যেখানে গভীর শিক্ষা প্রতিক্রিয়ায় কম জটিল মডেল, যেমন স While the complex models fit training data well (low bias), they also come with an unwanted high variance.  বিশেষ করে যখন সামান্য ডাটাসেটে তাদের সুন্দর ভালোভাবে প্রশিক্ষণের তথ্যের জন্য বিভিন্ন ভিন্ন ভিন্ন প্রশিক্ষণের জন্ উচ্চ ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিত্তিতে বুটস্ট্র্যাপ ব্যাগিং (ব্যাগিং) ভিত্তিক ভিত্তি এই কাগজটিতে আমরা এরকম একটি বিশেষ সিস্টেম বর্ণনা করি এবং ২০২০ (টিম নাম: জুলিয়ান)-এর বিভিন্ন আক্রান্ত চিহ্নিত কর্মসূচিতে আমা আমাদের আত্মসমর্পণ হচ্ছে ছয় সাবটাসের মধ্যে পাঁচ জনের জন্য সবচেয়ে ভালো প্রদর্শনী সিস্টেম। উদাহরণস্বরূপ, আমরা ইংরেজি সামাজিক মিডিয়া পোস্টের পরীক্ষার ডাটাসেটে ৮০. আমাদের পরীক্ষায় আমরা ভিন্ন মডেল কনফিগারেশনের তুলনা করি এবং এনস্পেলে ব্যবহৃত মডেলের সংখ্যা ভিন্ন। আমরা দেখতে পাচ্ছি যে এফ১ স্কোর ১৫ মডেল পর্যন্ত ন্যায় বৃদ্ধি পায়, কিন্তু আরো মডেলের জন্য ফিরে যায়।', 'ca': "Modens models basats en transformadors amb centenars de milions de paràmetres, com BERT, aconsegueixen resultats impressionants en tasques de classificació de text. Això també es aplica a la identificació d'agressió i la detecció ofensiva de llenguatges, on els enfocaments d'aprenentatge profund superen constantment models menys complexos, com els arbres de decisió. Mentre que els models complexos encaixen bé amb les dades d'entrenament (baix bias), també tenen una gran variació no desitjada. Especialment quan les ajustes en petits conjunts de dades, el rendiment de la classificació varia significativament per a les dades d'entrenament una mica diferents. Per superar la gran variància i proporcionar prediccions més robustes, proposem un conjunt de múltiples models BERT fins ajustads basats en l'agregació de bootstrap. En aquest article, descrivim un sistema d'ensemble així i presentem la nostra subministració a les tasques compartides sobre l'identificació de l'agressió 2020 (nom d'equip: Julian). Our submission is the best-performing system for five out of six subtasks.  Per exemple, aconsegueixem una puntuació F1 ponderada del 80,3% per a la tasca A en el conjunt de dades de prova dels mitjans socials anglesos. En els nostres experiments, comparem diferents configuracions de models i variam el nombre de models utilitzats en el conjunt. Trobem que la puntuació F1 augmenta dràsticament quan s'agrupa fins a 15 models, però el rendiment disminueix per a més models.", 'cs': 'Moderní transformátorové modely se stovkami milionů parametrů, například BERT, dosahují působivých výsledků při klasifikaci textu. To platí také pro identifikaci agrese a detekci urážlivých jazyků, kde hluboké učení konzistentně překonává méně složité modely, jako jsou rozhodovací stromy. Zatímco komplexní modely dobře odpovídají tréninkovým datům (nízká předbiasnost), přicházejí také s nežádoucí vysokou rozptylou. Zejména při jejich jemném ladění na malých datových sadách se klasifikační výkon výrazně liší u mírně odlišných tréninkových dat. Pro překonání vysoké rozptyly a poskytnutí robustnějších predikcí navrhujeme soubor několika jemně laděných modelů BERT založených na agregaci bootstrap (bagging). V tomto článku popisujeme takový souborový systém a představujeme náš podpis sdíleným úkolům na identifikaci agrese 2020 (název týmu: Julian). Naše podání je nejlépe výkonným systémem pro pět ze šesti dílčích úkolů. Například dosáhneme váženého F1 skóre 80,3% pro úkol A na testovací sadě dat anglických příspěvků na sociálních sítích. V našich experimentech porovnáváme různé konfigurace modelů a měníme počet modelů použitých v souboru. Zjišťujeme, že F1 skóre se drasticky zvyšuje při sestavování až patnácti modelů, ale výnosy se snižují u více modelů.', 'et': 'Kaasaegsed trafopõhised mudelid, millel on sadu miljoneid parameetreid, näiteks BERT, saavutavad teksti klassifitseerimisel muljetavaldavaid tulemusi. See kehtib ka agressiooni tuvastamise ja solvava keele tuvastamise puhul, kus sügavõppe lähenemisviisid on pidevalt vähem keerukad mudelid, näiteks otsustuspuud. Kuigi keerulised mudelid sobivad hästi treeninguandmetega (madal kallutus), on neil ka soovimatu suur varieeruvus. Eriti väikeste andmekogumite täpsustamisel varieerub klassifikatsioonijõudlus veidi erinevate treeninguandmete puhul märkimisväärselt. Kõrge dispersiooni ületamiseks ja tugevamate prognooside pakkumiseks pakume välja mitmete peenhäälestuslike BERT mudelite komplekti, mis põhinevad bootstrapi agregatsioonil (kottides). Käesolevas töös kirjeldame sellist ansambli süsteemi ja esitame oma alluvust agressiooni tuvastamise jagatud ülesannetele 2020 (meeskonna nimi: Julian). Meie esitamine on parim süsteem viiele kuuest alamülesandest. Näiteks saavutame kaalutud F1-skoori 80,3% ülesande A puhul inglise sotsiaalmeedia postituste testiandmekogumis. Oma katsetes võrdleme erinevaid mudelikonfiguratsioone ja varieerime ansamblis kasutatavate mudelite arvu. Me leiame, et F1-skoor suureneb drastiliselt kuni 15 mudeli komplekteerimisel, kuid tulu väheneb rohkemate mudelite puhul.', 'fi': 'Nykyaikaiset muuntajapohjaiset mallit, joissa on satoja miljoonia parametreja, kuten BERT, saavuttavat vaikuttavia tuloksia tekstiluokitustehtävissä. Tämä pätee myös aggression tunnistamiseen ja loukkaavan kielen havaitsemiseen, joissa syväoppimismenetelmät ovat johdonmukaisesti vähemmän monimutkaisia malleja, kuten päätöspuita. Vaikka monimutkaiset mallit sopivat hyvin harjoitustietoihin (matala bias), niissä on myös ei-toivottu suuri varianssi. Erityisesti pienillä tietoaineistoilla hienosäädettäessä luokituksen suorituskyky vaihtelee huomattavasti hieman erilaisessa harjoitusaineistossa. Korkean varianssin voittamiseksi ja vankempien ennusteiden tuottamiseksi ehdotamme useita hienoviritettyjä BERT-malleja, jotka perustuvat bootstrap aggregointiin (pussitukseen). Tässä artikkelissa kuvailemme tällaista ryhmäjärjestelmää ja esittelemme sitoutumisemme aggression tunnistamisen yhteisiin tehtäviin 2020 (tiimin nimi: Julian). Lähetyksemme on paras järjestelmä viidelle kuudesta alitehtävästä. Saamme esimerkiksi tehtävän A osalta 80,3% painotetun F1-pisteen englanninkielisten sosiaalisen median julkaisujen testiaineistossa. Kokeissamme vertailemme eri mallikokoonpanoja ja muutamme kokoonpanossa käytettyjen mallien määrää. Havaitsemme, että F1-pisteet kasvavat huomattavasti jopa 15 mallin kokoonpanossa, mutta tuotto pienenee useammilla malleilla.', 'bs': 'Moderni modeli na transformaciji koji imaju stotine miliona parametara, poput BERT, postignu impresivne rezultate na zadatkima klasifikacije teksta. To također drži za identifikaciju agresije i detekciju ofanzivnog jezika, gdje se duboko učenje stalno približava manjim kompleksnim modelima, poput drveća odluke. Dok kompleksni modeli dobro uklapaju podatke o obuci (niske predrasude), također dolaze sa neočekivanom visokom varijancijom. Posebno kad ih ispravljaju na malim podacima, klasifikacija se značajno razlikuje za malo različite podatke o obuci. Da bi preživjeli visoke varijacije i pružili robnije predviđanje, predlažemo ensemble višestruko finalnih modela BERT-a temeljnog na aggregaciji jabuka. U ovom papiru opisujemo takav sistem ensemble i predstavljamo podatke zajedničkim zadacima o identifikaciji agresije 2020 (ime timova: Julian). Naša podnošenja je najbolji sustav za pet od šest poduzeća. Na primjer, postigli smo težinu F1 rezultata od 80,3% za zadatak A na testnom setu podataka engleskih socijalnih medija. U našim eksperimentima, uspoređujemo različite modele konfiguracije i promijenimo broj modela koji se koristi u ensemblu. Nalazimo da se rezultat F1 drastično povećava kada se uključuje do 15 modela, ali se vraćanje smanjuje za više modela.', 'he': "מודלים מודרניים מבוססים על מעבר עם מאות מיליוני פרמטרים, כמו BERT, להשיג תוצאות מרשים במשימות מסווג טקסט. זה גם מתאים לזהות אגרסיה וגילוי שפת פגיעה, שבו לימוד עמוק מתקרב באופן קבוע מעל מודלים פחות מורכבים, כמו עצי החלטות. למרות שהדוגמנים המורכבים מתאימים היטב למידע האימוני (ציון נמוך), הם גם מגיעים עם גילוי גבוה לא רצוי. במיוחד כשמתאים אותם על קבוצות מידע קטנות, ביצועי ההקלטה משתנים באופן משמעותי עבור מידע אימון קצת שונה. כדי להתגבר על ההתנגדות הגבוהה ולספק חזקות יותר, אנו מציעים אסמבל של דוגמנים BERT מרובים מתאימים ומבוססים על התאגרוף (תיקים). בעיתון הזה, אנחנו מתארים מערכת אנסמבל כזו ולהציג את ההעברה שלנו למשימות המשותפות על זיהוי אגרסיה 2020 (שם צוות: ג'וליאן). ההצגה שלנו היא המערכת הכי טובה עבור חמישה מתוך שש תחתונות. לדוגמה, אנחנו משיגים נקודת F1 משקלת של 80.3% למשימה A על קבוצת נתונים מבחן של משימות תקשורת חברתית אנגלית. בניסויים שלנו, אנחנו משוותים תצורות דוגמניות שונות ושינויים את מספר הדוגמנים המשתמשים באנסמבל. אנו מוצאים שהנקודת F1 מגבילה באופן דרסטי כשמסדרת עד 15 דוגמנים, אך החזרות מתפחות עבור עוד דוגמנים.", 'ha': "@ info: whatsthis Wannan yana da ganin bayani na kibiyoyi da gane harshen mai ƙyãma, a inda matsayin ƙaranci ke ƙaranci misãlai masu kamwai, kamar itãcen zaɓani. Waka da misãlai masu adadi sun fito da tsarin data mai kyau (masu ƙaranci), sai su zo da wata variant mai tsawo ba'a so. @ label: listbox KDE style To domin domin varianin sarki da kuma mu samar da kunnuwa masu ƙaranci, za'a goyi wani misãlai masu samu'a biyu da aka samu'a wa BERT, a kan karatun danganiya (baggagg). Daga wannan takardan, muna bayyana misalin wannan na'urar fanel kuma muna halatar da mu zuwa aikin da aka raba su a kan shaidar agogo 2020 (sunan jama'a: Julian). Musuluncinmu ne mafiya kyakkyawan aikin aiki shan daga 6. Misali, za mu sami wani nauyi na F1 matsayin 80.3 wa aikin A kan jarraba matsayin tsari na jumuiya masu mitanda na Ingiriya. Ga majarinmu, za mu daidaita tsarin misãlai daban kuma munã rarraba ƙidãyar motsi masu amfani da cikin fanel. Muna gane cewa F1-score yana ƙara haske idan an haɗi zuwa misalin 15, kuma amma yana ƙara cikin misãlai masu ƙari.", 'sk': 'Sodobni transformatorski modeli z več sto milijoni parametrov, kot je BERT, dosegajo impresivne rezultate pri opravilih klasifikacije besedila. To velja tudi za identifikacijo agresije in zaznavanje žaljivega jezika, kjer pristopi globokega učenja dosledno presegajo manj kompleksne modele, kot so drevesa odločanja. Medtem ko kompleksni modeli dobro ustrezajo podatkom o vadbi (nizka pristranskost), imajo tudi neželeno visoko varianco. Zlasti pri natančnem nastavitvi na majhnih naborih podatkov se klasifikacijska uspešnost znatno razlikuje za nekoliko drugačne podatke o usposabljanju. Da bi premagali visoko varianco in zagotovili robustnejše napovedi, predlagamo komplet več natančno nastavljenih BERT modelov, ki temeljijo na združevanju bootstrap (bagging). V prispevku opisujemo takšen ansambelni sistem in predstavljamo svojo predložitev skupnim nalogam identifikacije agresije 2020 (ime ekipe: Julian). Naša predložitev je najboljši sistem za pet od šestih podnalog. Na primer, dosežemo ponderiran rezultat F1 80,3% za nalogo A na testnem naboru objav angleških družbenih omrežij. V naših poskusih primerjamo različne konfiguracije modelov in spreminjamo število modelov, ki se uporabljajo v ansamblu. Ugotovili smo, da se rezultat F1 drastično poveča pri sestavljanju do 15 modelov, vendar se donosi zmanjšajo za več modelov.', 'jv': 'Parameter Digawe iki wis angkang nggunakake tresnaning lan nggunakake tresnaning, kawe nglanggar langkung sampeyan apik batar tentang. Saying slot type Ngubah berlak ketemu karo akeh variant sing luwih lan akeh lanian akeh sing beraksi, kita ngomongke tindakan model BERT sing basa saboh nggawe barang nggawe barang nggawe Nang paper iki, kéné rambarang Sistem ayakno lan nganggo sisané awakmu nggawe gerakan kanggo nambah 2020 (jenenge: Julin). Awakdhéwé sing beraksi barêng-barêng sing dibenakaké kanggo limo tanggal sing isih. sample Nang dhéwé éntuk éntuk, kita sampek nggawe model sampeyan ngono caffes nambarang model sing gagetyeng nêmên. Awak dhéwé luwih-luwih lané diangkampun F1 lan akeh basa sing ditambah nêmêr, dadi mburu model sing wis mburu, njuké awak dhéwé wis mburu model sing luwih nêmêr.', 'bo': 'Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks. This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models such as decision trees. ཆེས་རྙིང་འཛིན་གྱི་མིག་གཟུགས་འགྱུར་བ་དེ་ལས་ཀྱང་འགྱུར་བའི་ཚད་ལྡན་ཡོད་པ་རེད། ཁྱད་པར་ན། གསལ་བཤད་ཆེན་སྒྲིག་ཆ་ཆུང་གི་ནང་དུ་བཏོན་གཏོང་བ་ཡིག་ཆ་ཉུང་བའི་སྒྲིག་འགོད་བྱས། To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging). འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་རྒྱ་ནག་གི་དྲ་རྒྱ་སྟངས་ལ་ང་ཚོའི་ནང་དུ་བཏོན་གཏོང་བ་དང་། སྤྱི་ཚོགས་གྱི་མིང་(ཇོ་ལི་ཡཱན) ང་ཚོའི་མཉམ་འཛུགས་ནི་རྒྱབ་སྐྱོར་མེད་པར་གྱི་མ་ལག་གཙོ་ཤིག་རེད། དཔེར་ན། ང་ཚོས་དབྱིན་ཡིག་འབྲེལ་མཐུད་གནས་ཚུལ་གྱི་བརྟག་བཤད་ཚད་ལྟར་འགྲོ་བ་ཡིན་པ། ང་ཚོའི་ལག་འཁྱེར་སྟངས་ནང་དུ་མ་དབྱིབས་སྒྲིག ང་ཚོས་F1་གྲངས་ཀ་དེ་ལས་ཚད་ལྡན་པའི་མིག་གཟུགས་འགྱུར་བའི་སྐབས་ཀྱི་ཚད་ལྡན་ཡར་རྒྱས་བཞིན་ཡོད།'}
{'en': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification : Bert Based Ensemble Learning Approach TRAC -2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'es': 'Scmhl5 en TRAC-2 Tarea compartida sobre identificación de agresiones: enfoque de aprendizaje conjunto basado en Bert', 'fr': "Scmhl5 au TRAC-2 Tâche partagée sur l'identification de l'agressivité\xa0: Approche d'apprentissage d'ensemble basée sur Bert", 'ar': 'Scmhl5 في TRAC-2 المهمة المشتركة حول تحديد العدوان: نهج التعلم الجماعي القائم على بيرت', 'pt': 'Scmhl5 no TRAC-2 Tarefa Compartilhada sobre Identificação de Agressão: Abordagem de Aprendizagem de Conjunto Baseada em Bert', 'ja': 'Scmhl 5 at TRAC -2: Shared Task on Aggression Identification: BERTベースのアンサンブル学習アプローチ', 'zh': 'Scmhl5 at TRAC-2 攻击性之共同任务:伯特之学也', 'hi': 'TRAC-2 पर Scmhl5 आक्रामकता पहचान पर साझा कार्य: बर्ट आधारित पहनावा सीखने के दृष्टिकोण', 'ru': 'Scmhl5 на TRAC-2 Общая задача по выявлению агрессии: подход к обучению на основе ансамбля Bert', 'ga': 'Scmhl5 ag TRAC-2 Tasc Comhroinnte ar Aithint Ionsaithe: Cur Chuige Foghlama Ensemble Bunaithe ar Bert', 'ka': 'Scmhl5 TRAC-2 გაყოფილი პარამეტრებში Aggression Identification: Bert Based Ensemble Learning Approach', 'el': 'Κοινή εργασία για τον προσδιορισμό της επιθετικότητας: προσέγγιση εκμάθησης συνόλων με βάση τον Μπερτ', 'hu': 'Scmhl5 at TRAC-2 Shared Task on Aggresszió Identification: Bert Based Ensemble Learning Approach', 'it': "Scmhl5 al TRAC-2 Compito condiviso sull'identificazione dell'aggressione: approccio Bert Based Ensemble Learning", 'kk': 'TRAC- 2 ортақтастырылған тапсырманың идентификациясында Scmhl5: Bert негізіндегі ұқсас оқыту жағдайы', 'lt': 'Scmhl5 TRAC-2 bendra užduotis dėl agresijos identifikavimo: sėdynės pagrindu grindžiamas bendro mokymosi metodas', 'mk': 'Scmhl5 на TRAC-2 споделена задача за идентификација на агресијата: пристап на Ensemble Learning', 'ml': 'എഗ്രേഷന്\u200d തിരിച്ചറിയുന്നതിനുള്ള ട്രിഎസ്- 2 പങ്കാളിയുള്ള ജോലിയില്\u200d സ്ക്മ്ലെല്\u200d5: ബെര്\u200dട്ട് അടിസ്ഥാനമായി പ', 'mn': 'TRAC-2 хуваалтын ажил Агрессийн тодорхойлолтын тухай Scmhl5', 'ms': 'Scmhl5 pada Tugas Berkongsi TRAC-2 mengenai Pengenalan Aggresi: Pendekatan Pelajaran Bert Bert', 'mt': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'ro': 'Scmhl5 la TRAC-2 Sarcină comună privind identificarea agresiunii: abordarea de învățare a ansamblului bazată pe Bert', 'no': 'Scmhl5 ved TRAC-2 delt oppgåve på Aggressidentifikasjon: Bert-basert læringstilgang', 'sr': 'Scmhl5 na podijeljenom zadatku TRAC-2 o identifikaciji agresije: Bert na osnovu pristupa učenja prosjeka', 'pl': 'Scmhl5 w TRAC-2 Wspólne zadanie dotyczące identyfikacji agresji: podejście do uczenia się zespołów oparte na Bert', 'si': 'Scml5 at TRAC-2 shared Job on Aggression ID: Bern based Ensemble Training approach', 'so': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemable Learning Approach', 'sv': 'Scmhl5 på TRAC-2 Delad uppgift om Aggressionsidentifiering: Bert baserad Ensemble Learning Approach', 'ur': 'TRAC-2 مشترک ٹاکس پر انگریس شناسایی پر Scmhl5: Bert Based Ensemble Learning Approach', 'ta': 'TRAC- 2 பகிர்ந்த பணி', 'uz': 'Name', 'vi': 'Trình tập tin chung về xung kích: cách tiếp cận giáo dục đa dạng:', 'bg': 'Споделена задача за идентифициране на агресията: подход за учене на ансамбъл базиран на Бърт', 'hr': 'Scmhl5 na podijeljenom zadatku TRAC-2 o identifikaciji agresije: Bert temeljeni pristup učenju prosjeka', 'da': 'Scmhl5 på TRAC-2 delt opgave om aggressiv identifikation: Bert baseret Ensemble Learning Approach', 'nl': 'Scmhl5 op TRAC-2 Gedeelde Task over Aggressieidentificatie: Bert Based Ensemble Learning Approach', 'de': 'Scmhl5 auf TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Ansatz', 'id': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'ko': 'TRAC-2의 Scmhl5 공유 공격 식별 작업: 버트 기반 통합 학습 방법', 'fa': 'Name', 'sw': 'Scmhl5 kwenye TRAC-2 Mipango ya Kushirikishwa na Kutambuliwa kwa Makubaliano: Utafiti wa Kujifunza Kipindi', 'tr': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'af': 'Scmhl5 by TRAC- 2 Gedeelde Opdrag op Aggressie Identifikasie: Bert Based Ensemble Learning Approach', 'am': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemable Learn Approach', 'az': 'TRAC-2 İşləşdirilməsi İşləndirməsi barəsində Scmhl5', 'hy': 'Comment', 'bn': 'গ্রেজেশন পরিচয়পত্রের ব্যাপারে ট্রাসি-২ ভাগাভাগি করা কাজের স্ক্যামল৫: বার্ট ভিত্তিক শিক্ষা প্রযুক্তি', 'bs': 'Scmhl5 na podijeljenom zadatku TRAC-2 o identifikaciji agresije: Bert-Based Ensemble Learning Approach', 'sq': 'Scmhl5 në TRAC-2 Task Shared on Aggression Identification: Bert Based Ensemble Learning Approach', 'ca': 'Scmhl5 del TRAC-2 Task Shared on Aggression Identification: Bert Based Ensemble Learning Approach', 'cs': 'Scmhl5 na TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'fi': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'et': 'Scmhl5 TRAC-2 jagatud ülesanne agressiooni tuvastamiseks: Bert Based Ensemble Learning Approach', 'jv': 'shift', 'he': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach', 'sk': 'Scmhl5 na TRAC-2 skupni nalogi o identifikaciji agresije: Bert Based Ensemble Learning Approach', 'ha': 'KCharselect unicode block name', 'bo': 'Scmhl5 at TRAC-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach'}
{'en': 'This paper presents a system developed during our participation (team name : scmhl5) in the TRAC-2 Shared Task on aggression identification. In particular, we participated in English Sub-task A on three-class classification (‘Overtly Aggressive’, ‘Covertly Aggressive’ and ‘Non-aggressive’) and English Sub-task B on binary classification for Misogynistic Aggression (‘gendered’ or ‘non-gendered’). For both sub-tasks, our method involves using the pre-trained Bert model for extracting the text of each instance into a 768-dimensional vector of embeddings, and then training an ensemble of  classifiers  on the embedding features. Our method obtained  accuracy  of 0.703 and  weighted F-measure  of 0.664 for Sub-task A, whereas for Sub-task B the  accuracy  was 0.869 and  weighted F-measure  was 0.851. In terms of the rankings, the weighted F-measure obtained using our method for Sub-task A is ranked in the 10th out of 16 teams, whereas for Sub-task B the weighted F-measure is ranked in the 8th out of 15 teams.', 'ar': 'تقدم هذه الورقة نظامًا تم تطويره أثناء مشاركتنا (اسم الفريق: scmhl5) في مهمة TRAC-2 المشتركة بشأن تحديد العدوان. على وجه الخصوص ، شاركنا في المهمة الفرعية باللغة الإنجليزية (أ) في تصنيف من ثلاث فئات ("عدواني بشكل علني" و "عدواني بشكل سري" و "غير عدواني") والمهمة الفرعية باللغة الإنجليزية "ب" بشأن التصنيف الثنائي للعدوان الكاره للنساء ("الجنس" أو "غير جنساني"). لكلتا المهمتين الفرعيتين ، تتضمن طريقتنا استخدام نموذج Bert المدرب مسبقًا لاستخراج نص كل حالة في متجه 768 بعدًا من التضمينات ، ثم تدريب مجموعة من المصنفات على ميزات التضمين. حصلت طريقتنا على دقة قدرها 0.703 وقياس F مرجح قدره 0.664 للمهمة الفرعية A ، بينما بالنسبة للمهمة الفرعية B ، كانت الدقة 0.869 وكان قياس F الموزون 0.851. فيما يتعلق بالتصنيفات ، تم تصنيف مقياس F المرجح الذي تم الحصول عليه باستخدام طريقتنا للمهمة الفرعية A في المرتبة العاشرة من أصل 16 فريقًا ، بينما بالنسبة للمهمة الفرعية B ، تم تصنيف مقياس F المرجح في المرتبة الثامنة من بين 15 فريقًا .', 'es': "Este artículo presenta un sistema desarrollado durante nuestra participación (nombre del equipo: scmhl5) en la tarea compartida TRAC-2 sobre identificación de agresiones. En particular, participamos en la Subtarea A en inglés sobre la clasificación de tres clases (`Aggressive Aggressive', `Covertly Aggressive' y `Non-aggressive') y en la Subtarea B en inglés sobre la clasificación binaria para la agresión misógina («de género» o «sin género»). Para ambas subtareas, nuestro método implica el uso del modelo Bert previamente entrenado para extraer el texto de cada instancia en un vector de incrustaciones de 768 dimensiones y, a continuación, entrenar un conjunto de clasificadores en las funciones de incrustación. Nuestro método obtuvo una precisión de 0.703 y la medida F ponderada de 0.664 para la subtarea A, mientras que para la subtarea B la precisión fue de 0.869 y la medida F ponderada fue de 0.851. En términos de clasificación, la medida F ponderada obtenida con nuestro método para la subtarea A se clasifica en la décima de 16 equipos, mientras que para la subtarea B, la medida F ponderada se clasifica en la octava de 15 equipos.", 'fr': "Cet article présente un système développé lors de notre participation (nom de l'équipe\xa0: scmhl5) à la tâche partagée TRAC-2 sur l'identification de l'agression. En particulier, nous avons participé à la sous-tâche A en anglais sur la classification en trois classes («\xa0ouvertement agressif\xa0», «\xa0secrètement agressif\xa0» et «\xa0non agressif\xa0») et à la sous-tâche anglaise B sur la classification binaire pour l'agression misogyne («\xa0gender\xa0» ou «\xa0non-gender\xa0»). Pour les deux sous-tâches, notre méthode consiste à utiliser le modèle de Bert pré-entraîné pour extraire le texte de chaque instance dans un vecteur d'intégrations de 768 dimensions, puis à entraîner un ensemble de classificateurs sur les caractéristiques d'intégration. Notre méthode a obtenu une précision de 0,703 et une mesure F pondérée de 0,664 pour la sous-tâche A, alors que pour la sous-tâche B, la précision était de 0,869 et la mesure F pondérée était de 0,851. En termes de classement, la mesure F pondérée obtenue à l'aide de notre méthode pour la sous-tâche A est classée dans la 10e sur 16 équipes, tandis que pour la sous-tâche B, la mesure F pondérée est classée dans la 8e sur 15 équipes.", 'pt': "Este artigo apresenta um sistema desenvolvido durante nossa participação (nome da equipe: scmhl5) na Tarefa Compartilhada TRAC-2 sobre identificação de agressão. Em particular, participamos da Subtarefa A de Inglês sobre classificação de três classes ('Agressiva aberta', 'Agressiva secreta' e 'Não-agressiva') e da Subtarefa B de Inglês sobre classificação binária para Agressão Misógina ('Gendered' ou 'sem gênero'). Para ambas as subtarefas, nosso método envolve o uso do modelo Bert pré-treinado para extrair o texto de cada instância em um vetor de embeddings de 768 dimensões e, em seguida, treinar um conjunto de classificadores nos recursos de embedding. Nosso método obteve acurácia de 0,703 e medida F ponderada de 0,664 para a Subtarefa A, enquanto para a Subtarefa B a acurácia foi de 0,869 e a medida F ponderada foi de 0,851. Em termos de classificação, a medida F ponderada obtida pelo nosso método para a Subtarefa A é classificada na 10ª das 16 equipes, enquanto para a Subtarefa B a medida F ponderada é classificada na 8ª das 15 equipes .", 'ja': '本稿では、侵略行為の特定に関するTRAC -2共有タスクへの参加（チーム名： scmhl 5 ）中に開発されたシステムを紹介します。 特に、3つのクラス分類（「露骨に攻撃的」、「密かに攻撃的」、「非攻撃的」）に関する英語サブタスクAと、ミソジニー的攻撃（「ジェンダー化」または「非ジェンダー化」）に関するバイナリ分類に関する英語サブタスクBに参加しました。 両方のサブタスクについて、私たちの方法は、埋め込みの768次元ベクトルに各インスタンスのテキストを抽出するための事前にトレーニングされたBERTモデルを使用し、埋め込み機能に関する分類子のアンサンブルをトレーニングすることを含みます。 我々の方法は、サブタスクAの精度が0.703、加重F測定値が0.664であったのに対し、サブタスクBの精度は0.869、加重F測定値は0.851であった。 ランキングでは、サブタスクAについては当社の方法で得られた加重Fメジャーが16チーム中10位にランクされ、サブタスクBについては15チーム中8位にランクされています。', 'zh': '本文引TRAC-2共同任务(团队名:scmhl5)间侵略识别之统。 三英语子之类(公攻击性,隐蔽攻击性非攻击性),与英语子任B恶女攻击性(性别化,非性别化)二元之类也。 凡此二子者,吾法及用预练者Bert取例本于嵌768维向量中,然后练分类器于嵌。 子职A,吾道得0.703之精,与0.664之加权F度,而子B之精为0.869,加权F度值为0.851。 于排名者,用吾法得子职A者加权F量值在16团队中排名第10位,而于子务B,加权F量值在15团队中排名第8位。', 'ru': 'В настоящем документе представлена система, разработанная в ходе нашего участия (название команды: scmhl5) в совместной задаче по выявлению агрессии ПРОФ-2. В частности, мы участвовали в английской подзадаче A по классификации трех классов («явная агрессия», «скрытая агрессия» и «неагрессивный») и английской подзадаче B по двоичной классификации для женоненавистнической агрессии («гендерная» или «негендерная»). Для обеих подзадач наш метод включает использование предварительно обученной модели BERT для извлечения текста каждого экземпляра в 768-мерный вектор вложений, а затем обучение ансамбля классификаторов по признакам вложений. Наш метод получил точность 0,703 и взвешенное F-измерение 0,664 для подзадачи A, тогда как для подзадачи B точность составляла 0,869, а взвешенное F-измерение составляло 0,851. С точки зрения рейтинга, взвешенная F-мера, полученная с помощью нашего метода для подзадачи A, занимает 10-е место из 16 команд, тогда как для подзадачи B взвешенная F-мера занимает 8-е место из 15 команд.', 'hi': "यह पेपर आक्रामकता की पहचान पर TRAC-2 साझा कार्य में हमारी भागीदारी (टीम का नाम: scmhl5) के दौरान विकसित एक प्रणाली प्रस्तुत करता है। विशेष रूप से, हमने तीन-वर्ग वर्गीकरण ('अत्यधिक आक्रामक', 'गुप्त रूप से आक्रामक' और 'गैर-आक्रामक') पर अंग्रेजी उप-कार्य ए में भाग लिया और अंग्रेजी उप-कार्य बी में भाग लिया, जो कि गलत तरीके से आक्रामकता ('लिंग' या 'गैर-लिंग') के लिए बाइनरी वर्गीकरण पर था। दोनों उप-कार्यों के लिए, हमारी विधि में प्रत्येक उदाहरण के पाठ को एम्बेडिंग के 768-आयामी वेक्टर में निकालने के लिए पूर्व-प्रशिक्षित बर्ट मॉडल का उपयोग करना शामिल है, और फिर एम्बेडिंग सुविधाओं पर क्लासिफायरों की एक टुकड़ी को प्रशिक्षित करना शामिल है। हमारी विधि ने उप-कार्य ए के लिए 0.703 की सटीकता और 0.664 का भारित एफ-माप प्राप्त किया, जबकि उप-कार्य बी के लिए सटीकता 0.869 थी और भारित एफ-माप 0.851 था। रैंकिंग के संदर्भ में, उप-कार्य ए के लिए हमारी विधि का उपयोग करके प्राप्त भारित एफ-माप को 16 टीमों में से 10 वें स्थान पर रखा गया है, जबकि उप-कार्य बी के लिए भारित एफ-माप को 15 टीमों में से 8 वें स्थान पर रखा गया है।", 'ga': "Cuireann an páipéar seo i láthair córas a forbraíodh le linn ár rannpháirtíochta (ainm foirne: scmhl5) i dTasc Comhroinnte TRAC-2 ar shainaithint ionsaitheachta. Go háirithe, ghlacamar páirt i bhFothasc Béarla A ar aicmiú trí aicme (`Overtly Aggressive', `Covertly Aggressive' agus `Non-aggressive') agus i bhFothasc Béarla B ar aicmiú dénártha le haghaidh Ionsaitheach Misogynistic (`gendered' nó `neamh-inscne'). Maidir leis an dá fhothasc, is éard atá i gceist lenár modh úsáid a bhaint as samhail Bert réamh-oilte chun téacs gach cás a bhaint amach i veicteoir 768-tríthoiseach de leabú, agus ansin grúpa aicmitheoirí a oiliúint ar na gnéithe leabaithe. Fuair ár modh cruinneas 0.703 agus tomhas F ualaithe de 0.664 d'Fho-thasc A, ach d'fhothasc B ba é 0.869 an cruinneas agus ba é F-tomhas ualaithe 0.851. I dtéarmaí na rangú, tá an F-bheart ualaithe a fhaightear ag baint úsáide as ár modh d’fhothasc A rangaithe sa 10ú as 16 fhoireann, ach i gcás Fothasc B tá an beart F ualaithe rangaithe san 8ú as 15 fhoireann. .", 'ka': "ეს დოკუმენტი ჩვენი დაწყვეტილების განვითარებულია სისტემა (სახელი: scmhl5) TRAC-2 გაყოფილი დავალება აგრესის ინდენტიფიკაციაზე. განსაკუთრებულია, ჩვენ ანგლისური A-ს სამკლასი კლასიფიკაციაში (სამკლასი განსაკუთრებულია, `სამკუთრებულია Aggressive' და `არადრესიური') და ანგლისური სამკუთრებულია B-ს ბიუნური კლასიფიკაციაზე Misogynistic Aggression (gendered) ან `non-gendered'). ორივე სამუშაო დავალებებისთვის, ჩვენი მეტი დააყენება წინ დააყენებული ბერტის მოდელის გამოყენება, რომელიც ყოველ ინსტანციის ტექსტის გამოყენება 768 განზომილებული გვექტორიში, და შემდეგ კლასიფიკაციის ინსენბ ჩვენი მეთოდი 0.703 და 0.664-ის განმავლებული F-ზომი A-ზე, მაგრამ ჩვენი მეთოდი B-ის განმავლობა 0.869 და განმავლებული F-ზომი 0.851 იყო. პრენგიზების შესახებ, განსაზღვრებული F-ზომა, რომელიც მიღებული ჩვენი პროგრამის გამოყენებაში ჩვენი პროგრამის გამოყენებაში A-ს დასაზღვრებულია 16-ჯგუფის 10-ში, მაგრამ საზოგადო B-ზე განსაზღვრებული F-ზომა 8-", 'hu': "A tanulmány bemutatja a TRAC-2 megosztott agressziós azonosítási feladatban való részvételünk során kifejlesztett rendszert (csapatnév: scmhl5). Különösen részt vettünk a három osztályos osztályozásban (`Túlságosan agresszív', 'Túlságosan agresszív' és 'Nem agresszív'), valamint az angol B osztályozásban a nőgyűlölő agresszió bináris osztályozásában (`nemed' vagy 'nemed'). Mindkét alfeladat esetében a módszerünk magában foglalja az előre képzett Bert modell használatát az egyes példányok szövegének kivonására a beágyazások 768 dimenziós vektorába, majd osztályozók együttese kiképzését a beágyazási funkciókra. Módszerünk 0,703 pontosságot és 0,664 súlyozott F-mérést kapott az A. alcsoportnál, míg a B. alcsoportnál a pontosság 0,869, súlyozott F-mérést 0,851 volt. A rangsorolás szempontjából a 16 csapat közül a 10. helyen, míg a B. helyen a 15 csapat közül a 8. helyen áll a súlyozott F-mérték.", 'el': "Η παρούσα εργασία παρουσιάζει ένα σύστημα που αναπτύχθηκε κατά τη διάρκεια της συμμετοχής μας (όνομα ομάδας: στην κοινή εργασία για την αναγνώριση επιθετικότητας TRAC-2). Ειδικότερα, συμμετείχαμε στην Αγγλική Υποεργασία Α για την ταξινόμηση τριών τάξεων (`Υπερβολικά επιθετική', `Κρυμμένα επιθετική' και `Μη επιθετική') και στην Αγγλική Υποεργασία Β για τη δυαδική ταξινόμηση για τη μισογυνιστική Aggression (`φυλετική' ή `μη-φυλετική'). Και για τις δύο δευτερεύουσες εργασίες, η μέθοδος μας περιλαμβάνει τη χρήση του προ-εκπαιδευμένου μοντέλου για την εξαγωγή του κειμένου κάθε παρουσίας σε ένα 768-διαστατικό διάνυσμα ενσωμάτωσης, και στη συνέχεια την εκπαίδευση ενός συνόλου ταξινομητών σχετικά με τα χαρακτηριστικά ενσωμάτωσης. Η μέθοδος μας απέκτησε ακρίβεια 0.703 και σταθμισμένο μέτρο F 0.664 για την Υποεργασία Α, ενώ για την Υποεργασία Β η ακρίβεια ήταν 0.869 και το σταθμισμένο μέτρο F ήταν 0.851. Όσον αφορά την κατάταξη, το σταθμισμένο μέτρο που λαμβάνεται με τη μέθοδο μας για την Υποεργασία Α κατατάσσεται στη δέκατη από τις 16 ομάδες, ενώ για την Υποεργασία Β το σταθμισμένο μέτρο κατατάσσεται στην 8η από τις 15ες ομάδες.", 'lt': "Šiame dokumente pateikiama sistema, sukurta mūsų dalyvavimo TRAC-2 bendroje agresijos identifikavimo užduotyje metu (komandos pavadinimas scmhl5). Visų pirma dalyvavome anglų kalbos A poskirsnyje dėl trijų klasių klasifikacijos (`Overly Aggressive', `Covertly Aggressive' ir `Non-aggressive') ir anglų kalbos B poskirsnyje dėl dviejų klasifikacijų Misogynistic Aggression (`gendered' arba `non-gender'). Abiejų subužduočių atveju mūsų metodas apima iš anksto apmokyto Bert modelio naudojimą kiekvienos instancijos tekstui ištraukti į 768 matmenį įterpimo vektorių, o vėliau klasifikatorių rinkinį apmokyti įterpimo charakteristikas. Mūsų metodas gavo tikslumą 0,703 ir svertinį F-matavimą 0,664 A pakopos užduoties atveju, o B pakopos tikslumas 0,869 ir svertinį F-matavimą 0,851. In terms of the rankings, the weighted F-measure obtained using our method for Sub-task A is ranked in the 10th out of 16 teams, whereas for Sub-task B the weighted F-measure is ranked in the 8th out of 15 teams.", 'it': "Questo articolo presenta un sistema sviluppato durante la nostra partecipazione (nome del team: scmhl5) al TRAC-2 Shared Task sull'identificazione delle aggressioni. In particolare, abbiamo partecipato al Sottocompito A in inglese sulla classificazione a tre classi (`Overtly Aggressive', 'Coverly Aggressive' e 'Non-aggressive') e al Sottocompito B in inglese sulla classificazione binaria per l'Aggressione Misogina (`gender' o 'non-gender'). Per entrambi i sottocompiti, il nostro metodo prevede l'utilizzo del modello Bert pre-addestrato per estrarre il testo di ogni istanza in un vettore 768-dimensionale di incorporazioni, e quindi formare un insieme di classificatori sulle caratteristiche di incorporazione. Il nostro metodo ha ottenuto un'accuratezza di 0,703 e una F-misura ponderata di 0,664 per il Sottocompito A, mentre per il Sottocompito B l'accuratezza era di 0,869 e la F-misura ponderata di 0,851. In termini di classifica, la misura F ponderata ottenuta utilizzando il nostro metodo per la sottomissione A è classificata al 10 ° posto su 16 squadre, mentre per la sottomissione B la misura F ponderata è classificata all'8 ° posto su 15 squadre.", 'kk': 'Бұл қағаз біздің қатысуымыздың (топ атауы: scmhl5) TRAC- 2 ортақ тапсырманың агрессия идентификациясында жасалған жүйесін көрсетеді. Мысалы, біз ағылшын тілінде A суб- тапсырмасына үш класс классификациясында («Үлкен Aggressive», «Covertly Aggressive» және «Non-aggressive») және "Misogynistic Aggression" (гендер емес) бинарлық классификациясының B суб- тапсырмасына қатысу үшін қатысулық болдық Екі ішкі тапсырмалар үшін, біздің әдіміміз әрбір инстанцияның мәтінін 768- өлшемді инвестингтердің векторына тарту үшін алдын- оқылған Берт үлгісін қолдануға болады. Содан кейін ендіру мүмкіндіктерінің Біздің әдіміміз 0,703 деген дұрыс және F-өлшемі 0,664 деген A-тапсырма үшін, бірақ B-тапсырма үшін дұрыс 0,869 болды және F-өлшемі 0,851 болды. Жолдары бойынша, біздің A-тапсырманың әдісімізді қолдану үшін F-өлшемі 10-тапсырманың 16 тобында орнатылады, бірақ B-тапсырманың өлшемі 8-тапсырманың 15 тобында орнатылады.', 'ms': "Kertas ini memperkenalkan sistem yang dikembangkan semasa kita berpartisipasi (nama pasukan: scmhl5) dalam Tugas Berkongsi TRAC-2 mengenai pengenalan agresi. Secara khususnya, kami berpartisipasi dalam Sub-tugas Inggeris A pada kelas tiga (`Overly Aggressive', `Covertly Aggressive' and `Non-aggressive') dan Sub-tugas Inggeris B pada kelas binari untuk Aggression Misogynistic (`gendered' or `non-gender'). Untuk kedua-dua sub-tugas, kaedah kami melibatkan menggunakan model Bert yang dilatih-dilatih untuk mengekstrak teks setiap contoh ke dalam vektor 768-dimensi penyembedding, dan kemudian melatih kumpulan klasifikasi pada ciri-ciri penyembedding. Kaedah kami mendapat ketepatan 0.703 dan ukuran F berat 0.664 untuk Subtugas A, sementara untuk Subtugas B ketepatan 0.869 dan ukuran F berat 0.851. In terms of the rankings, the weighted F-measure obtained using our method for Sub-task A is ranked in the 10th out of 16 teams, whereas for Sub-task B the weighted F-measure is ranked in the 8th out of 15 teams.", 'ml': "ഈ പത്രത്തില്\u200d നമ്മുടെ പങ്കെടുക്കുമ്പോള്\u200d ഒരു സിസ്റ്റമുണ്ടാക്കുന്നു In particular, we participated in English Sub-task A on three-class classification (`Overtly Aggressive', `Covertly Aggressive' and `Non-aggressive') and English Sub-task B on binary classification for Misogynistic Aggression (`gendered' or `non-gendered').  രണ്ടു സബ് ജോലികള്\u200dക്കും നമ്മുടെ രീതിയില്\u200d പഠിപ്പിക്കപ്പെട്ട ബെര്\u200dട്ട് മോഡല്\u200d ഉപയോഗിക്കുന്നു. ഓരോ ഉദാഹരണത്തിന്റെയും ടെക്സ്റ്റ് പുറത്തെടുക്കുന്നതിന് 768 ഡിമെന ഞങ്ങളുടെ രീതിയില്\u200d 0. 703 ന്റെ ശരിയായി കിട്ടിയിരിക്കുന്നു. അതിന്റെ സുബ് ജോലി A ന്നുള്ള F-അളവ് തൂക്കിയിരിക്കുന്നു. റാങ്കിങ്ങുകളുടെ കാര്യത്തില്\u200d, ഞങ്ങളുടെ സുബ്-ജോലി A രീതി ഉപയോഗിച്ച് ലഭ്യമായ F-തൂക്കം ലഭ്യമാക്കിയ രീതിയില്\u200d 16 ടീമില്\u200d പത്താം ടീമില്\u200d ഉയര്\u200dന്നിരിക്കുന", 'mt': "Dan id-dokument jippreżenta sistema żviluppata matul il-parteċipazzjoni tagħna (isem it-tim: scmhl5) fil-Kompitu Konġunt TRAC-2 dwar l-identifikazzjoni tal-aggressjoni. B’mod partikolari, ipparteċipajna fis-Subkompitu Ingliż A dwar il-klassifikazzjoni ta’ tliet klassijiet (`Overly Aggressive', `Covertly Aggressive' u `Non-aggressive') u fis-Subkompitu Ingliż B dwar il-klassifikazzjoni binarja għall-Aggressjoni Misoġynistika (`sessed' jew `non-gender'). Għa ż-żewġ sottokompiti, il-metodu tagħna jinvolvi l-użu tal-mudell Bert imħarreġ minn qabel għall-estrazzjoni tat-test ta’ kull istanza f’vettur 768-dimensjonali tal-inkorporazzjonijiet, u mbagħad it-taħriġ ta’ ensemble ta’ klassifikaturi dwar il-karatteristiċi tal-inkorporazzjoni. Il-metodu tagħna kiseb preċiżjoni ta’ 0.703 u miżura F ippeżata ta’ 0.664 għas-Subkompitu A, filwaqt li għas-Subkompitu B l-preċiżjoni kienet ta’ 0.869 u miżura F ippeżata kienet ta’ 0.851. F’termini tal-klassifikazzjonijiet, il-miżura F ippeżata miksuba bl-użu tal-metodu tagħna għas-Subkompitu A hija kklassifikata fl-10 minn 16-il tim, filwaqt li għas-Subkompitu B il-miżura F ippeżata hija kklassifikata fit-8 minn 15-il tim.", 'mn': "Энэ цаас бидний оролцох үед (баг нэр: scmhl5) системийг харуулж байна. ТРAC-2 хамааралтай ажлын тухай хамааралтай ажил. Ялангуяа бид Англи хэлний A-ын суб-дасгал дасгал дасгал 3-р ангид оролцсон (`Ихэнх нэр хүндрэлтэй', `Мөн хүндрэлтэй' болон `Агрессийн биш') болон Англи хэлний B-ийн суб-дасгал дасгал дасгал дасгал нь Misogynistic Aggression (`гендер' эсвэл 'гендер Хоёр суб-даалгаварын хувьд бидний арга нь тохиолдол бүрийн текстийг 768-хэмжээст вектор болгоход урд сургалтын Берт загварыг ашиглаж, дараа нь хамтдаа нэг хэмжээст хуваагдагчийн загварыг сургалтын тулд сургалтын загвар Бидний арга нь 0.703-ийн зөв бөгөөд F-ийн жинг нь 0.664-ийн жинг нь A-ын жинг бөгөөд B-ийн жинг нь 0.869 байсан ба F-ийн жинг нь 0.851 байсан. Шагналын хувьд бидний A-ын суб-даалгаварын аргыг ашиглаж авсан weighted F-хэмжээ нь 16 багийн 10-д хуваагдана. Гэвч B-н суб-даалгаварын жингийн F-хэмжээг нь 8-т 15 багийн 8-д хуваагдана.", 'no': 'Denne papiret viser eit systemet utvikla under deltakaren vårt (team name: scmhl5) i TRAC-2 delt oppgåve om aggresjonssidentifikasjon. I særskilt delte vi i engelsk underoppgåve A på tre klassesklassifikasjon (« overAggressive », « Covertly Aggressive » og « Non-aggressive ») og engelsk underoppgåve B på binærklassifikasjon for Misogynistic Aggression (« gendered » eller « non-gendered »). For begge underoppgåver er metoden vårt involvert å bruka den først trengte Bert-modellen for å ekstrahera teksten av kvar instans til ein 768-dimensjonal vektor av innbygging, og så trenga ein ensembel av klassifikatorar på innbyggingsfunksjonane. Metoden vårt fikk nøyaktighet på 0,703 og vekta F-målet på 0,664 for underoppgåve A, men for underoppgåve B var nøyaktighet 0,869 og vekta F-målet var 0,851. I tillegg til rankingane er vekta F-målet som er fått med vår metode for underoppgåve A rankert i 10 av 16 grupper, mens for Sub-oppgåve B er vekta F-målet rankert i 8. av 15 grupper.', 'pl': "W artykule przedstawiono system opracowany podczas naszego udziału (nazwa zespołu: scmhl5) w TRAC-2 Shared Task na temat identyfikacji agresji. W szczególności uczestniczyliśmy w angielskim podzadaniu A na klasyfikacji trzech klas (`Overtly Aggressive', `Covertly Aggressive' i `Non-agressive') oraz angielskim podzadaniu B na klasyfikacji binarnej dla agresji misogynistycznej (`gendered' lub `non-gendered'). W przypadku obu podzadań nasza metoda polega na wykorzystaniu wstępnie przeszkolonego modelu Berta do ekstrakcji tekstu każdej instancji do 768-wymiarowego wektora osadzeń, a następnie na szkoleniu zespołu klasyfikatorów na temat cech osadzania. Nasza metoda uzyskała dokładność 0,703 i ważoną miarę F 0,664 dla podzadania A, natomiast dla podzadania B dokładność wynosiła 0,869, a ważoną miarę F wynosiła 0,851. Pod względem rankingów ważona miara F uzyskana przy użyciu naszej metody dla podzadania A jest rankingowa w dziesiątej z 16-tych drużyn, natomiast dla podzadania B ważona miara F jest rankingowa w ósmej z 15-tych drużyn.", 'sr': 'Ovaj papir predstavlja sistem razvijen tokom našeg sudjelovanja (ime timova: scmhl5) u delnom zadatku TRAC-2 o identifikaciji agresije. Posebno smo učestvovali na engleskom podzadatku A o klasifikaciji troklasa („pretjerano agresivno“, „pretjerano agresivno“ i „ne agresivno“) i na engleskom podzadatku B o binarnoj klasifikaciji za misoginističku agresiju („spolno“ ili „ne-seksualno“). Za obe podzadatke, naša metoda uključuje koristiti predobučeni model Berta za izvlačenje teksta svakog instanca u 768-dimenzionalni vektor ugrađenja, a zatim obuku ensemble klasifikatora na ugrađene karakteristike. Naša metoda je dobila tačnost od 0,703 i težina F-mjera od 0,664 za podzadatak A, dok je za podzadatak B tačnost bila 0,869 i težina F-mjera bila 0,851. U odnosu na ranke, težina F-mjera dobijena koristeći našu metodu podzadatka A je rankirana u 10 od 16 tima, dok za podzadatka B težina F-mjera je rankirana u 8 od 15 tima.', 'si': "මේ පත්තුව පෙන්වන්නේ අපේ සම්බන්ධතාවය (කණ්ඩායම නම: scmmel5) සම්බන්ධතාවක් පද්ධතියක් තියෙන්නේ. විශේෂයෙන්, අපි ඉංග්\u200dරීසියේ ඉංග්\u200dරීසිය සුබ-කාර්ය A වල තුනක් ලාස්ත්\u200dරීය වලට සම්බන්ධ වෙලා තියෙනවා (`overly Aggressive', `Covertly Aggressive' සහ `Non-aggressive') සහ ඉංග්\u200dරීසිය සුබ-කාර්ය B අපේ විධානය සබ-කාර්ය දෙන්නටම, අපේ විධානය සම්බන්ධ වෙන්නේ ප්\u200dරධානය කරන්න බෙර්ට් මොඩේල් භාවිතා කරන්න, හැම ප්\u200dරධානයේ පාළුව 768-වෙක්ටර් වල අපේ විධානය 0.703 වල සිද්ධතාවක් ලැබුණා සබ-වැඩ A වල 0.664 වල සිද්ධතාවක් ලැබුණා, ඒ වගේම සබ-වැඩ B වල සිද්ධතාවක් 0.869 වල සිද්ධතාවක් ලැබුණා ස ප්\u200dරමාණ වලින්, අපේ ප්\u200dරමාණ වලින් F-මාර්ගය පාවිච්චි කණ්ඩායම් 16 වලින් 10 වලින් සාමාණ වලින් සාමාණ වලින් සාමාණ වලින් සාමාණ වලින් සාමාණ වලි", 'mk': "Овој документ претставува систем развиен за време на нашето учество (името на тимот: scmhl5) во Соделената задача TRAC-2 за идентификација на агресијата. In particular, we participated in English Sub-task A on three-class classification (`Overtly Aggressive', `Covertly Aggressive' and `Non-aggressive') and English Sub-task B on binary classification for Misogynistic Aggression (`gendered' or `non-gendered').  За двете подзадачи, нашиот метод вклучува користење на предобучениот модел Берт за извлекување на текстот на секоја инстанција во 768-димензионален вектор на вградувања, а потоа обука на ансембл на класификатори за вградувачките карактеристики. Нашиот метод ја доби точноста од 0,703 и тежираната F-мерка од 0,664 за подзадачата А, додека за подзадачата Б точноста беше 0,869 и тежираната F-мерка беше 0,851. Во поглед на рангирањето, тежираната F-мерка добиена со користење на нашиот метод за подзадача А е рангирана во 10 од 16 тимови, додека за подзадача Б тежираната F-мерка е рангирана во 8 од 15 тимови.", 'sv': "Denna uppsats presenterar ett system som utvecklats under vårt deltagande (teamnamn: scmhl5) i TRAC-2 Shared Task om aggressionsidentifiering. I synnerhet deltog vi i Engelska Underuppgiften A om tre klassers klassificering (`Overtly Aggressive', 'Coverly Aggressive' och 'Non-aggressive') och Engelska Underuppgiften B om binär klassificering för Misogynic Aggression (`gended' eller 'non-gended'). För båda deluppgifterna innebär vår metod att använda Bert-modellen för att extrahera texten i varje instans till en 768-dimensionell vektor av inbäddningar, och sedan träna en ensemble av klassificerare på inbäddningsfunktionerna. Vår metod fick noggrannhet på 0,703 och viktat F-mått på 0,664 för deluppgift A, medan noggrannheten för deluppgift B var 0,869 och viktat F-mått var 0,851. Beträffande rankningen rankas det viktade F-måttet som erhållits med vår metod för deluppgift A på tionde plats av 16 lag, medan det viktade F-måttet för deluppgift B rankas på åttonde plats av 15 lag.", 'ta': "TRAC- 2 பகிர்ந்த பணி குறிப்பிட்டு, நாங்கள் மூன்று வகுப்பில் ஆங்கிலத்தின் துணை பணியில் பங்கிடப்பட்டோம் ('மேலும் Aggressive', 'Covertly Aggressive' மற்றும் 'அக்கிரமமில்லாத') மற்றும் ஆங்கிலத்திற்கு இருமுறை வகுப்பு B (' துணை பணிகளுக்கும், எங்கள் முன் பயிற்சி பெர்ட் மாதிரியை பயன்படுத்தி ஒவ்வொரு நிகழ்விலும் உரையை வெளியேற்றுவதற்கு 768-dimensional வெக்டார், பின்னர் உள்ளிடும் குணங்களின் குண 0.703-ன் சரியான முறையில் கிடைத்து துணை செயல் A-க்கு F-ன் அளவை எடுத்துக் கொண்டுள்ளது, துணை செயல் B-க்கு 0.869 ஆகும் F-அளவு 0.851 ஆகும். துணை செயல் A முறையை பயன்படுத்தி கிடைக்கப்பட்ட F-அளவு 16 குழுக்களில் பத்தாவது குழுக்களில் நிறுவப்பட்டுள்ளது, துணை செயல் B-ல் எடை F-அளவு 15 குழுக்களில் எட்டாவது க", 'ro': "Această lucrare prezintă un sistem dezvoltat în timpul participării noastre (numele echipei: scmhl5) la TRAC-2 Shared Task privind identificarea agresiunii. În special, am participat la subsarcina engleză A privind clasificarea pe trei clase (`Overtly Agressive', 'Coverly Agressive' și 'Non-agresive') și subsarcina engleză B privind clasificarea binară pentru agresiunea mizogină (`gender' sau `non-gender'). Pentru ambele subsarcini, metoda noastră implică utilizarea modelului Bert pre-instruit pentru extragerea textului fiecărei instanțe într-un vector 768-dimensional de încorporări și apoi instruirea unui ansamblu de clasificatori cu privire la caracteristicile de încorporare. Metoda noastră a obținut o precizie de 0,703 și o măsură F ponderată de 0,664 pentru Subsarcina A, în timp ce pentru Subsarcina B precizia a fost de 0,869 și F ponderată de 0,851. În ceea ce privește clasamentul, măsura F ponderată obținută folosind metoda noastră pentru Subsarcina A este clasată pe locul 10 din 16 echipe, în timp ce pentru Subsarcina B măsura F ponderată este clasată pe locul 8 din 15 echipe.", 'so': "Warqadan wuxuu soo bandhigaa nidaam horumarinta marka aan ka qeyb galno (kooxda magac: scmhl5) oo ku qoran shaqada TRAC-2 ee loo sharciyey aqoonsiga aggression. Si gaar ah, waxaynu ka qeybqaadanay fasalka afka Ingiriiska Sub-task A oo ku qoran saddex-fasalka (`Overly Aggressive', `Covertly Aggressive' iyo `Non-aggressive') iyo Ingiriis Sub-task B oo ku saabsan fasalka labaad ee Misogynistic Aggression (`sex' ama `non-jinsig'). For both sub-tasks, our method involves using the pre-trained Bert model for extracting the text of each instance into a 768-dimensional vector of embeddings, and then training an ensemble of classifiers on the embedding features.  Metalkeena waxaa helay saxda 0.703 oo miisaaminayna F-qiyaas 0.664, laakiin Sub-task B waxaa loo qoray saxda 0.869 oo miisaanka F-miisaankuna wuxuu ahaa 0.851. Xiriirka, kooxda kooxa A waxaa ka mid ah 10 koox, kooxda Sub-Saxda B waxaa lagu qiyaasaa kooxda siddeedaad oo koox ah.", 'ur': 'This paper presents a system developed during our participation (team name: scmhl5) in the TRAC-2 Shared Task on aggression identification. مخصوصا، ہم تین کلاس کلاس کلاسیفوں پر انگلیسی کے Sub-Task A میں شریک ہوئے (بہت اگریسی، کاپورٹی اگریسی اور غیر اگریسی) اور انگلیسی Sub-Task B میں Misogynistic Aggression (جنسی یا غیر جنسی) کے دو کلاسیفوں پر۔ دونوں سوب-ٹاکسٹوں کے لئے ہمارا طریقہ ہے کہ ہر مثال کے متن کو ایمبڈینگ کے 768-اندازے ویکتور میں اضافہ کرنے کے لئے پیش آموزش کی برٹ موڈل کے استعمال کرنے کے لئے اور اس کے بعد انبوڈینگ ویکتوروں پر کلاسیٹر کا انتظام کرتا ہے. ہمارا طریقہ 0.703 کی دقیق حاصل ہوا اور 0.664 کی تولید غیر کار A کے لئے 0.664 کی تولید ہوئی، حالانکہ Sub-task B کے لئے دقیق 0.869 تھا اور وزن F-measure 0.851 تھا. درجے کے مطابق، وزن F-ناپ کو ہمارے طریقے کے مطابق پاک تابع A کے لئے حاصل کیا گیا ہے، اس طرح پاک تابع B کے مطابق وزن F-ناپ کو پاک تابع میں ہے، اور پاک تابع B کے مطابق وزن F-ناپ کو پاک تابع میں ہے۔', 'uz': 'Ushbu qogʻoz, biz murojaat identifikatidagi TRAC-2 bilan bogʻliq vazifani (guruh nomli: scmhl5) bilan birlashtirilgan tizimni koʻrsatiladi. Biz uchta darajada ingliz tilidagi sub-vazifa A (ko\'pgina Aggressiv), \'Toʻgʻri-Aggressiv\' va \'aggressiv\' emas\' va ingliz tilidagi "Misogistic Aggressionning ikkinchi darajasini `jinsiyasi\' yoki \'jinsiy\' emas\' bilan bir xil darajasini boshqarishga ega bo\'lgan. Ushbu ikkita vazifalar uchun bizning bir taʼminlovchi bert modelini ishlatish mumkin, har bir misol matnni 768 ta-dimensional vektoriga olish uchun, va keyin bir xil tugmalar birikmasini o\'rganadi. Bu vazifa A uchun 0.703\'ning foydalanishimiz 0.664\'ning 0.664 ўлчовini o\'zgartirdi, va sub vazifa B uchun tasdiqli 0.869 va F- ўлчовning 0.851 edi. Tashkilotlar davomida, sub-vazifa A usulini ishlatilgan F-ўлчовlar, 16 guruhdagi 10 guruhdan boshlanadi, va sub- vazifa B uchun, F-ўлчовning 8 guruhidagi 8 guruhdan boshlanadi.', 'vi': 'Tờ giấy này đưa ra một hệ thống được phát triển trong suốt sự tham gia của chúng ta (nhóm: sơ Chân Chúa) trong tập đoàn TRAC-2 "Phân tích tấn công". Chúng tôi tham gia đặc biệt vào phân loại A tiếng Anh thuộc dạng tam cấp (\'Vùng hung hãn\',\'Ẩn dụ hung dữ\'và\'Không hung hăng\') và con phân Nhiệm vụ tiếng Anh B) về phân loại nhị phân loại của Ăn bám Misogynistic (« Hiến dred » hay « không nộp ». Đối với cả hai công việc phụ, phương pháp của chúng ta là sử dụng mô hình Bert đã được đào tạo sẵn để trích văn bản của mỗi trường vào ô tô! Cách của chúng tôi đã có sự chính xác của 0.703 và đánh áF kiệm 0 Về mặt hàng loại, con số F cân nặng được lấy theo phương pháp phân loại A được phân loại trong đội 10th trên 16, trong khi Đối với con chạy dưới Nhiệm vụ B, con số F cân nặng được phân loại trong đội 8th out of 15.', 'da': "Denne artikel præsenterer et system udviklet under vores deltagelse (teamnavn: scmhl5) i TRAC-2 Shared Task om identifikation af aggression. Især deltog vi i engelsk underopgave A om tre-klasses klassificering ('Overtly Aggressive', 'Coverly Aggressive' og 'Non-aggressive') og engelsk underopgave B om binær klassificering for misogistisk aggression ('kønned' eller 'non-kønned'). For begge underopgaver indebærer vores metode at bruge den forududdannede Bert model til at udtrække teksten i hver instans i en 768-dimensionel vektor af indlejringer, og derefter træne et ensemble af klassificere i indlejringsfunktionerne. Vores metode opnåede nøjagtighed på 0,703 og vægtet F-mål på 0,664 for Sub-opgave A, mens nøjagtigheden for Sub-opgave B var 0,869 og vægtet F-mål var 0,851. Med hensyn til placeringen er det vægtede F-mål opnået ved hjælp af vores metode til Underopgave A placeret på 10. ud af 16 hold, mens det vægtede F-mål for Underopgave B placeret på 8. ud af 15 hold.", 'bg': "Настоящата статия представя система, разработена по време на нашето участие (име на екипа: СКМХ5) в Споделена задача за идентифициране на агресията. По-специално участвахме в английска подзадача А за трикласова класификация ('прекалено агресивна', 'скрито агресивна' и 'неагресивна') и английска подзадача Б за двоична класификация за мизогинистична агресия ('полова' или 'не-полова'). За двете подзадачи методът ни включва използването на предварително обучен модел на Бърт за извличане на текста на всяка инстанция в 768-измерен вектор на вграждания, а след това обучение на ансамбъл от класификатори за вграждащите функции. Нашият метод получи точност 0,703 и претеглена F-мярка 0,664 за Подзадача А, докато за Подзадача Б точността е 0,869 и претеглена F-мярка 0,851. По отношение на класирането претеглената F-мярка, получена по метода ни за Подзадача А, се класира в 10-то от 16 отбора, докато за Подзадача Б претеглената F-мярка се класира в 8-то от 15 отбора.", 'nl': "Deze paper presenteert een systeem ontwikkeld tijdens onze deelname (teamnaam: scmhl5) aan de TRAC-2 Shared Task over agressie identificatie. In het bijzonder namen we deel aan Engelse Sub-taak A op drie-klassen classificatie (`Overtly Aggressive', `Covertly Aggressive' en `Non-agressieve') en Engelse Sub-taak B op binaire classificatie voor Misogynistische Aggressie (`gendered' of `non-gendered'). Voor beide deeltaken gebruiken we het vooraf getrainde Bert-model om de tekst van elke instantie te extraheren in een 768-dimensionale vector van embeddings, en vervolgens een ensemble classificatoren te trainen op de embedding-functies. Onze methode behaalde nauwkeurigheid van 0,703 en gewogen F-maat van 0,664 voor Sub-taak A, terwijl voor Sub-taak B de nauwkeurigheid 0,869 en gewogen F-maat 0,851 was. In termen van de ranglijsten wordt de gewogen F-maat verkregen met behulp van onze methode voor Subtaak A gerangschikt in de 10e van 16-teams, terwijl voor Subtaak B de gewogen F-maat in de 8e van 15-teams wordt gerangschikt.", 'hr': 'Ovaj papir predstavlja sustav razvijen tijekom našeg sudjelovanja (ime timova: scmhl5) u podijeljenom zadatku TRAC-2 o identifikaciji agresije. Posebno smo učestvovali na engleskom podzadatku A o klasifikaciji troklasa („pretjerano agresivno”, „pretjerano agresivno” i „ne agresivno”) i na engleskom podzadatku B o binarnoj klasifikaciji Misogynističke agresije („spolno“ ili „ne-seksualno“). Za oba podzadataka, naša metoda uključuje koristiti predobučeni model Berta za izvlačenje teksta svakog instanca u 768-dimenzionalni vektor ugrađenja, a zatim obučavanje ensemble klasifikatora na ugrađenim karakteristikama. Naša metoda je dobila preciznost od 0,703 i težina F-mjera od 0,664 za podzadatak A, dok je točnost podzadatak B bila 0,869 i težina F-mjera bila 0,851. U pogledu redova, težina F-mjera dobijena koristeći našu metodu podzadatka A je redovna u 10-oj od 16 tima, dok za podzadatka B težina F-mjera je redovna u 8-oj od 15 tima.', 'de': "Diese Arbeit stellt ein System vor, das während unserer Teilnahme (Teamname: scmhl5) an der TRAC-2 Shared Task zur Aggressionserkennung entwickelt wurde. Insbesondere beteiligten wir uns an der englischen Unteraufgabe A zur Drei-Klassen-Klassifizierung (`Overtly Aggressive', `Covertly Aggressive' und `Non-Aggressive') und der englischen Unteraufgabe B zur binären Klassifizierung für misogynistische Aggression (`gendered' oder `non-gendered'). Für beide Teilaufgaben verwenden wir das vortrainierte Bert-Modell, um den Text jeder Instanz in einen 768-dimensionalen Vektor von Einbettungen zu extrahieren und anschließend ein Ensemble von Klassifikatoren zu den Einbettungsfunktionen zu trainieren. Unsere Methode erzielte Genauigkeit von 0,703 und gewichtetes F-Maß von 0,664 für Teilaufgabe A, während für Teilaufgabe B die Genauigkeit 0,869 und gewichtetes F-Maß 0,851 war. In Bezug auf die Rangliste wird die gewichtete F-Kennzahl, die mit unserer Methode für Teilaufgabe A erhalten wurde, im zehnten von 16-Teams rangiert, während für Teilaufgabe B die gewichtete F-Kennzahl im achten von 15-Teams rangiert.", 'ko': "본고는 우리(팀명:scmhl5)가TRAC-2공격인식공유임무에 참여하는 동안 개발한 시스템을 소개한다.특히 3가지 분류('공개 공격성','은폐 공격성','비공격성')에 관한 영어 서브퀘스트 A와 여성 혐오 공격('성별화'또는'비성별화')에 관한 이원적 분류의 영어 서브퀘스트 B에 참여했다.이 두 개의 하위 임무에 대해, 우리의 방법은 미리 훈련된 버트 모형을 사용하여 모든 실례의 텍스트를 768차원의 삽입 벡터에 추출한 다음에 삽입 특징에 따라 훈련 분류기를 집합하는 것이다.우리의 방법은 하위 임무 A의 정확도가 0.703이고 가중 F-측정은 0.664이며 하위 임무 B의 정확도는 0.869이고 가중 F-측정은 0.851이다.순위의 경우 우리의 방법으로 얻은 하위 퀘스트 A의 가중 F 측정치는 16개 팀 중 10위, 하위 퀘스트 B의 가중 F 측정치는 15개 팀 중 8위였다.", 'id': "Kertas ini mempersembahkan sistem yang dikembangkan saat kita berpartisipasi (nama tim: scmhl5) dalam Tugas Berkongsi TRAC-2 mengenai identifikasi agresi. Terutama, kami berpartisipasi dalam Sub-tugas Inggris A pada klasifikasi tiga kelas (`Overly Aggressive', `Covertly Aggressive' dan `Non-aggressive') dan Sub-tugas Inggris B pada klasifikasi binari untuk Aggression Misogynistic (`gendered' atau `non-gendered'). Untuk kedua-dua sub-tugas, metode kita melibatkan menggunakan model Bert yang terlatih-terlatih untuk mengekstraksi teks dari setiap contoh ke vektor 768-dimensi penerbangan, dan kemudian melatih ensemble klasifikasi pada fitur penerbangan. Metode kami mendapatkan akurasi 0,703 dan F-ukuran berat 0,664 untuk Subtugas A, sementara untuk Subtugas B akurasi 0,869 dan F-ukuran berat 0,851. Dalam peringkat, F-ukuran berat yang diperoleh menggunakan metode kami untuk Sub-tugas A adalah peringkat ke-10 dari 16 tim, sementara untuk Sub-tugas B F-ukuran berat adalah peringkat ke-8 dari 15 tim.", 'fa': 'این کاغذ سیستم توسعه شده در زمان شرکت ما (نام تیم: scmhl5) در کار مشترک TRAC-2 در مورد شناسایی تجاوز را نشان می\u200cدهد. مخصوصا، ما در زیر کاری انگلیسی A در کلاس سه کلاس شرکت کردیم («خیلی گریز», «غیر گریز» و «غیر گریز» و «غیر گریز») و زیر کاری B انگلیسی در مورد classification binary for Misogynistic Aggression («جنسی» یا «غیر جنسی»). برای هر دو زیر کار، روش ما از مدل برت پیش آموزش شده برای استفاده از متن هر مثال به یک ویکتور 768 بعدی از استفاده کردن استفاده می\u200cکند، و بعد از آموزش یک برچسب از مخلوقات در ویژه\u200cهای استفاده می\u200cکند. روش ما دقیق 0.703 و وزن F-اندازه 0.664 برای زیر کار A گرفته است، در حالی که دقیق زیر کار B 0.869 بود و وزن F-اندازه 0.851 بود. در مورد صفحه\u200cها، اندازه وزن F با استفاده از روش ما برای Sub-Task A در صفحه ۱۰ از ۱۶ تیم صفحه می\u200cشود، در حالی که برای Sub Task B اندازه وزن F در صفحه ۸م از ۱۵ تیم صفحه می\u200cشود.', 'sw': "Gazeti hili linaonyesha mfumo ulioandaliwa wakati wa ushiriki wetu (jina la timu: scmhl5) katika kazi ya TRAC-2 iliyohusika na utambulisho wa ukatili. Kwa hakika, tulishiriki katika kazi ya Uingereza Kuu-A kwenye darasa tatu ('Kuvutiwa sana', 'Kuvutiwa sana' na 'Kuvurugu isiyo na kibaguzi') na kazi ya Kiingereza B kwa ajili ya kutangazwa kwa makubaliano ya Kimisogynsia ('watu wanajinsia' au 'wasio na jinsia'). Kwa kazi zote mbili za subira, mbinu yetu inahusisha kutumia modeli ya Bert iliyoendelea kabla ya kuondoa maandishi ya kila mfano katika vector ya viwango 768, na kisha kufundisha vifaa vya wataalamu katika vipengele vya habari. Utawala wetu ulipata sahihi wa 0.703 na kupunguzwa F-kiasi cha 0.664 kwa ajili ya kazi za subira A, wakati kwa ujumbe wa subira B sahihi ilikuwa 0.869 na kupunguzwa F-measure ilikuwa 0.851. Kuhusu mabadiliko hayo, kipimo cha F kinachopatiwa kwa kutumia njia yetu ya kufanya kazi ya Sub-Sub-A ni chenye rangi ya 10 kati ya timu 16, wakati kwa kazi ya Sub-Sub-task B kipimo cha F kinapangwa katika timu 8 kati ya 15.", 'tr': "Bu kagyz bizi흫 chikanchasymyzda geli힊mi힊 sistemi (topar adymyz: scmhl5) TRAC-2 Be첵leki G철rn체힊ler barda 첵erle힊diril첵채r. I흫lis챌e, biz I흫lis챌e Sub-Task A 체챌-synp klasifikasynda (dereje Aggressive, `Covertly Aggressive' we `Non-aggressive') we I흫lis챌e Sub-task B Misogynist Aggresi첵asy 체챌in ikinji klasifikasynda go힊uldyk Iki alt i힊e 체챌in, bizi흫 y철ntemimiz Bert modelini her 철rnekini흫 metini 768-boyutlu integr vekt철r체ne a 챌mak 체챌in ullan첵ar, we so흫ra klassifikat챌ilerin k철p체sini da힊artmak 체챌in ulan첵ar. Bizi흫 첵체regimiz 0.703 we ilat t채bligi A 체챌in 0.664 dyrlyklygyny aldy we ilat t채bligi B 체챌in dogrylygyny 0.869 we 챌ykyl첵an F 철l챌체si 0.851 di첵ipdir. Di흫e seredeni흫e g철r채, Sub-task A 체챌in yzarlan첵an F-철l챌체si we bu 첵erde 10-nji topardan 16 topardan b철legi di첵첵채r, 첵철ne Sub-task B 체챌in yzarlan첵an F-철l챌체si 8-nji we 15 topardan b철legi di첵첵채r.", 'af': "Hierdie papier stel 'n stelsel ontwikkeld tydens ons deelnaam (span naam: scmhl5) in die TRAC- 2 Gedeelde Opdrag op agresie identifikasie. In besonderhede het ons in Engelske Sub-taak A gedeel op drie klasse klasifikasie (`Oorsaaklik Aggressief', `Omheerlik Aggressief' en `Non-aggressive') en Engelske Sub-taak B op binêre klasifikasie vir Misogynistiese Aggressie (`gendered' of `non-gendered'). Vir beide subopdragte, het ons metode aangehandel met die gebruik van die voorafoerende Bert model vir uitpakking van die teks van elke voorbeeld in 'n 768-dimensjonale vektor van inbêding, en dan onderrig 'n ensemble van klassifiseerders op die inbêring funksies. Ons metode het presies van 0.703 ontvang en geweeg F-maat van 0.664 vir Sub-taak A, terwyl vir Sub-taak B die presies was 0.869 en geweeg F-maat was 0.851. In terms of die rankings, die geweegte F-maat wat gebruik ons metode vir Sub-taak A is, is in die 10de uit 16 teame rangeer, terwyl vir Sub-taak B die geweegte F-maat in die 8de uit 15 teame rangeer is.", 'sq': "Ky dokument paraqet një sistem të zhvilluar gjatë pjesëmarrjes sonë (emri i ekipit: scmhl5) në Trac-2 Task Shared mbi identifikimin e agresionit. Në veçanti, ne morëm pjesë në Nëndetyrën Angleze A në klasifikimin e tre klasave (`Shumë Aggresiv', `Shumë Aggresiv' dhe `Jo-Aggresiv') dhe Nëndetyrën Angleze B në klasifikimin binar për Aggresionin Misogynist (`gjind' apo `jo-gjind'). Për të dy nëndetyrat, metoda jonë përfshin përdorimin e modelit Bert të paratrajnuar për të nxjerrë tekstin e çdo rasti në një vektor 768-dimensional të përfshirjeve, dhe pastaj trajnimin e një ansambli klasifikues në karakteristikat e përfshirjes. Metoda jonë mori saktësinë 0.703 dhe matjen e peshuar F 0.664 për nëndetyrën A, ndërsa për nëndetyrën B saktësia ishte 0.869 dhe matja e peshuar F 0.851. Në lidhje me renditjet, matja e peshuar F e fituar duke përdorur metodën tonë për Subdetyrën A renditet në të dhjetën nga 16 ekipe, ndërsa për Subdetyrën B matja e peshuar F renditet në të tetën nga 15 ekipe.", 'am': 'ይህ ፕሮግራም በተጨማሪነታችን (የቡድን ስም: scmhl5) የTRAC-2 ተጋራጭ ስራዎችን በአስቸጋሪ ማረጋገጥ ያሳየዋል፡፡ በተለይም እንግሊዝኛ አ በሦስት ክፍል ክፍል ማቀናቀፍ (በሙሉ ጉዳይ፣ ‘ክፍለ ጉዳይ’ እና ‹ተቋማሚ›› እና እንግሊዝኛ ደብዳቤ ቢ ለብያዊ የስጦታዊ ጉዳይ ክፍተት ‹ሴት› ወይም ‹ሴት› ያልተወው› ላይ ተካፈልን፡፡ ለሁሉም ደብዳቤዎች ሥርዓታችን፣ ቀድሞ ተማሪ የቤርት ሞዴል በመጠቀም የሁሉንም ምሳሌ ጽሑፉን ወደ 768-የሜኑባዊ የሜኑባዊ መንገድ ለመውጣት እና በኋላም የክፍለ ምርጫዎችን ማስተካከል እና አስተማርናለን፡፡ Our method obtained accuracy of 0.703 and weighted F-measure of 0.664 for Sub-task A, whereas for Sub-task B the accuracy was 0.869 and weighted F-measure was 0.851.  በሥርዓት ጉዳዩ ላይ የF-ሚዛን ለSub-ስራ A ሥርዓታችንን በመጠቀም የተገኘው የአሥር ጭፍሮች ውስጥ አሥረኛው ደረጃዎች ነው፡፡', 'hy': "Այս հոդվածը ներկայացնում է համակարգ, որը զարգացել է մեր մասնակցության ժամանակ (թիմի անունը՝ Scm-5) համագործակցության միջոցով համագործակցել է ագրեսիայի հայտնաբերման մասին: Մենք մասնակցեցինք Անգլերենի Ա-հանձնարարության երեք դասակարգում (`Անգլերեն ագրեսիվ', 'Անգլերեն ագրեսիվ', 'Անգլերեն ագրեսիվ' և `Ոչ-ագրեսիվ') և Անգլերենի Բ-հանձնարարության երկու դասակարգում միսոգլերեն ագրեսիվ (`սեռ' կամ `ոչ-սեռ'): Երկու ենթախնդիրների համար մեր մեթոդը ներառում է նախապատրաստված Բերթ մոդելի օգտագործումը յուրաքանչյուր օրինակի տեքստը ստանալու համար ներգրավման 768-չափ վեկտոր, հետո դասակարգումների համակարգը պատրաստում է ներգրավման առանձնահատկությունների վրա: Մեր մեթոդը ստացավ 0.703 ճշգրտություն և 0.664 F-չափություն A-ի ենթախնդրի համար, մինչդեռ B-ի ենթախնդրի համար ճշգրտությունը 0.859 էր, իսկ F-չափությունը 0.851: Ինչ վերաբերում է դասակարգումներին, F-չափումը, որը ստացվել է օգտագործելով մեր մեթոդը A-ի ենթախնդրի համար, դասակարգում է 16-ից 10-րդ թիմում, մինչդեռ B-ի ենթախնդրի համար F-չափումը դասակարգում է 15-ից 8-րդ թիմում:", 'az': "Bu kağıt bizim (team name: scmhl5) istifadə etdiyimiz vaxt istifadə edilmiş sistemi göstərir. Özellikle, biz İngilizə A apa-görevi üç sınıf klasifikasyonu (`Çox Aggressive', `Covertly Aggressive' və `Non-aggressive') və Misogynist Aggresi üçün ikili klasifikasyon barəsində İngilizə bölümünə katıldıq. İki alt-işlər üçün, metodumuz hər instansinin metini 768-ölçülü bir inbadinglərin vektörünə çıxartmaq üçün öyrənmiş Bert modelini istifadə etmək və sonra inbadinglərin özelliklərində klasifikatçıların ensembliyini təhsil edir. Bizim metodumuz 0.703 ilə dəqiqliyi qəbul etdi və F-ölçüsi 0.664 ilə A apar görevi üçün çəkildi, halbuki B apar görevi üçün dəqiqliyi 0.869 idi və F-ölçüsi 0.851 idi. Sərgənlərə görə, A Sub-Task metodumuzun istifadəsində alınan ağırlı F-ölçüsi 10 dəstədə 16 dəstədə dəstəklənir, Halbuki B Sub Task üçün ağırlı F-ölçüsi 8 dəstədə 15 dəstədə dəstəklənir.", 'bn': "এই পত্রিকাটি আমাদের অংশগ্রহণের সময় একটি সিস্টেমের উন্নয়ন উপস্থাপন করেছে (টিমের নাম: scmhl5) ট্রাক-২ শেয়ার করা কাজের উপর আক্রান বিশেষ করে আমরা ইংরেজি সাব-কাজ A-এ অংশগ্রহণ করেছি ('অত্যন্ত গ্রাগ্রাসিভ', 'কাভার্টিভিস্ট গ্রাগ্রাফেশন' এবং 'অআক্রমণকারী নয়' আর ইংরেজি সাব-কাজ বিভিন্ন ভিনিস্টিক গ্রেগেশনের বাইনারি বি সাব-কাজের জন্য, আমাদের পূর্ব প্রশিক্ষিত বার্ট মডেল ব্যবহার করে প্রত্যেকটি উদ্দেশ্যের টেক্সট বের করার জন্যে আমাদের মাধ্যমে একটি ৭৬৮-ডিমেন্ট ভেক্টরে বের করা হয়েছে এবং তা আমাদের পদ্ধতি 0.703 এর পরিমাপ পেয়েছে এবং সাব-কাজ A এর জন্য F-মাপ পরিমাপের পরিমাপ পেয়েছে এবং সাব-কাজ বিরুদ্ধে সাব-কাজের জন্য সাব-কাজের জন্য তার সঠিক র\u200d্যাঙ্কিং এর ব্যাপারে আমাদের সাব-কাজের মাধ্যমে ব্যবহার করে আমাদের মাধ্যমে পাওয়া F-মাপ ১০ টি দলের মধ্যে সাব-কাজের জন্য ভার করা হয়েছে, যেখানে ১৫টি দলের মধ্যে ম", 'bs': 'Ovaj papir predstavlja sustav razvijen tijekom našeg sudjelovanja (ime timova: scmhl5) u podijeljenom zadatku TRAC-2 o identifikaciji agresije. Posebno smo učestvovali na engleskom podzadatku A o klasifikaciji troklasa („pretjerano Aggresivno“, „pretjerano Aggresivno“ i „ne-agresivno“) i na engleskom podzadatku B o binarnoj klasifikaciji za misoginističku agresiju („spolno“ ili „ne-seksualno“). Za obe podzadatke, naša metoda uključuje koristiti predobučeni model Berta za izvlačenje teksta svakog instanca u 768-dimenzionalni vektor ugrađenja, a onda obučavanje ensemble klasifikatora na ugrađene funkcije. Naša metoda je dobila tačnost od 0,703 i težina F-mjera od 0,664 za podzadatak A, dok je tačnost podzadatak B bila 0,869 i težina F-mjera bila 0,851. U pogledu redova, težina F-mjera dobijena koristeći našu metodu podzadataka A je redovna u 10 od 16 tima, dok za podzadatak B težina F-mjera je redovna u 8 od 15 tima.', 'ca': "Aquest paper presenta un sistema desenvolupat durant la nostra participació (nom d'equip: scmhl5) en la Task Compartida TRAC-2 sobre l'identificació d'agressió. En particular, vam participar en la Subtasca A en anglès en la classificació de tres classes ('Overly Aggressive', 'Covertly Aggressive' i 'Non-aggressive') i en la Subtasca B en anglès en la classificació binaria de l'Aggression Misogynistic ('gendered' o 'non-gender'). Per ambdues subtasques, el nostre mètode consisteix en utilitzar el model Bert pré-entrenat per extrair el text de cada instancia en un vector 768 dimensional d'incorporacions, i després entrenar un conjunt de classificadors sobre les característiques incorporacions. El nostre mètode va obtenir una precisió de 0,703 i una F-mesura ponderada de 0,664 per la Subtasca A, mentre que per la Subtasca B la precisió era de 0,869 i una F-mesura ponderada de 0,851. En termes de classificacions, la mesura F ponderada obtenida usant el nostre mètode de Subtasca A es classifica en la décima de cada 16 equips, mentre que en la Subtasca B la mesura F ponderada es classifica en la vuit de cada 15 equips.", 'cs': "Tento článek představuje systém vyvinutý během naší účasti (název týmu: scmhl5) v TRAC-2 Shared Task na identifikaci agrese. Konkrétně jsme se zúčastnili anglického podúkolu A na třítřídní klasifikaci (`Overtly Aggressive', `Covertly Aggressive' a `Non-agresivní') a anglického podúkolu B na binární klasifikaci pro misogynistickou agresi (`gendered' nebo `non-gendered'). U obou dílčích úkolů naše metoda zahrnuje použití předškoleného Bertova modelu pro extrakci textu každé instance do 768-dimenzionálního vektoru vkládání a následné školení souboru klasifikátorů na vkládání prvků. Naše metoda získala přesnost 0,703 a vážená F-měřítka 0,664 pro podúkol A, zatímco pro podúkol B byla přesnost 0,869 a vážená F-měřítka 0,851. Z hlediska žebříčku je vážená míra F získaná naší metodou pro podúkol A řazena v desátém ze šestnácti týmů, zatímco pro podúkol B je vážená míra F řazena v osmém z patnácti týmů.", 'et': "Käesolevas töös tutvustatakse süsteemi, mis on välja töötatud meie osalemise ajal (meeskonna nimi: scmhl5) TRAC-2 Shared Task on agressiooni identifitseerimine. Eelkõige osalesime inglise alamülesandes A kolmeklassi klassifikatsiooni (`Overtly Aggressive', `Covertly Aggressive' ja `Non-aggressive') ja inglise alamülesandes B misogünistliku agressiooni binaarse klassifikatsiooni (`sugered' või `non-sugered'). Mõlema alamülesande puhul hõlmab meie meetod eelnevalt väljaõpetatud Berti mudeli kasutamist iga eksemplari teksti ekstraheerimiseks 768-dimensiooniliseks põimimisvektoriks ja seejärel klassifitseerijate ansambli koolitamist põimimisfunktsioonide kohta. Meie meetodil saavutati alaülesande A puhul täpsus 0,703 ja kaalutud F-mõõt 0,664, alamülesande B puhul täpsus 0,869 ja kaalutud F-mõõt 0,851. Meie alamülesande A meetodil saadud kaalutud F-mõõt on järjestatud kümnendas meeskonnas 16-st, samas kui alamülesande B puhul on kaalutud F-mõõt 15-st meeskonnast 8-s.", 'fi': "Tässä artikkelissa esitellään järjestelmä, joka kehitettiin osallistumisemme aikana (tiimin nimi: scmhl5) TRAC-2 Shared Task on aggression identifikaatio. Osallistuimme erityisesti Englannin alitehtävään A kolmiluokkaisessa luokituksessa (`Overtly Aggressive', `Covertly Aggressive' ja `Non-aggressiivinen') ja Englannin alitehtävään B Misogynistisen aggression binääriluokituksessa (`sukupuolinen' tai `ei-sukupuolinen'). Molemmissa osatehtävissä menetelmämme sisältää esikoulutetun Bert-mallin, jolla poimitaan kunkin tapauksen teksti 768-ulotteiseen upotusvektoriin ja koulutetaan sitten luokittelijoiden joukko upotusominaisuuksista. Menetelmämme tarkkuus oli 0,703 ja painotettu F-mitta 0,664 osatehtävässä A, kun taas osatehtävässä B tarkkuus oli 0,869 ja painotettu F-mitta 0,851. Sijoitusten osalta alitehtävä A -menetelmällä saatu painotettu F-mitta sijoittuu kymmenenneksi 16 joukkueesta, kun taas alitehtävässä B painotettu F-mitta sijoittuu kahdeksanneksi 15 joukkueesta.", 'sk': "V prispevku je predstavljen sistem, razvit med našim sodelovanjem (ime ekipe: scmhl5) v skupni nalogi TRAC-2 za identifikacijo agresije. Še posebej smo sodelovali v angleški podnalogi A o treh razredih klasifikacije (`Overtly Aggressive', `Covertly Aggressive' in `Non-aggressive') in angleški podnalogi B o binarni klasifikaciji za misoginistično agresijo (`gendered' ali `non-gendered'). Pri obeh podnalogah naša metoda vključuje uporabo vnaprej usposobljenega Bertovega modela za ekstrakcijo besedila vsakega primera v 768-dimenzionalni vektor vdelav in nato usposabljanje ansambla klasifikatorjev o vdelavi funkcij. Naša metoda je dosegla natančnost 0,703 in tehtano F-merilo 0,664 za podnalogo A, medtem ko je bila za podnalogo B natančnost 0,869 in tehtano F-merilo 0,851. Glede na lestvice je tehtana F-merila, pridobljena z našo metodo za Podnalogo A, uvrščena v 10. izmed 16 ekip, medtem ko je za Podnalogo B tehtana F-merila uvrščena v 8. izmed 15 ekip.", 'ha': "Wannan takardan na bãyar da wani na'urar da aka buɗe shi a lokacin da mu haɗa (sunan team: skmhl5) a cikin shirin aiki na TRac-2 Tsammãnin, mun yi mataimaki a kan ƙanshi na-aikin Ingiriya A kan fassarar-nau'i uku (`Totally Aggressive', `Conversely Aggressive' da`Na'a-aggretive') da kuma masu bin-aikin Ingiriya B kan classified biyu na Misogyustic Aggression (`gender' ko `non-gender'). Ga masu shawara biyu, hanyoyinmu yana amfani da misalin Bert ta gabã ɗaya dõmin ya fitar littãfin kowace misali zuwa a cikin wata 7 68-dimisional shiryarwa na embedded, kuma ta yi amfani da wani samfanel na fasihai masu cikin tsari. Tsarinmu ya sami 0.703 kuma an sami F-ma'auni 0.664 wa Sub-aikin A, kuma da hakki ya zama 0.869 kuma ma'auni F-balanci ya kasance 0.851. Ga buƙatan ranjan, ma'aunin F da aka samu hancin mu da hanyarmu wa Sub-aikin A, yana danganta cikin jama'a 10 daga 16th, kuma a kan Sub-aikin B, ma'aunin F da aka aza shi cikin jama'a 8 na cikin jama'a 15.", 'jv': "Ngetokno iki gunakake sistem sing nggawe nang sampeyan akeh ning sesilhan (jenengan kelompok: scm-5) ning TRA2-2 Sampeyan task nang kana antaraning ngomong, kita wis ngerasakno barêng-barêng nganggo Sub-task A sing wis ana saben kelas telu-kelas (terus dikarolan 'Ajak mberêng', 'Covertly agegress' lan 'No-agegress') lan nganggo Sub-task B sing mengko urip kanggo Kemerdekaan dhuwur kesempatan kanggo MisogYstik (terus 'Genred' lan 'no-Genred'). Daerah éwang Sub-tasks, kita method wis dipolete Awak dhéwé éntukno kesèhku 0.2007 3 lan nèhku 0.6 kanggo Sub-task A, opo sing kanggo Sub-task B ono wektu wis 0. Awak dhéwé, nglanggar ranèh, nggawe F-measurement ono nggawe Metèd ngéwé Sub-task A wis dislompok ning 10 out 16 ekipe, terêng ono ngéwé Sub-task B ono langgambar lanjut F-measurement wis dislompok ning 8 out sing petsane ekipe.", 'he': "הנייר הזה מציג מערכת שפותחה במהלך השתתפות שלנו (שם צוות: scmhl5) במשימה משותפת TRAC-2 על זיהוי אגרסיה. במיוחד, השתתפנו בתת משימה אנגלית א על שיעור שלוש כיתה ('Overly Aggressive', 'Covertly Aggressive' and 'Non-aggressive') ו התת משימה אנגלית ב על שיעור בינרי עבור Aggression Misogynistic ('gendered' or `non-gendered'). לשני התפקידים, השיטה שלנו כוללת להשתמש במודל ברט מאומן מראש כדי להוציא את הטקסט של כל דוגמה לוקטור 768-מימדי של קישורים, ואז לאמן אסמבל של קלאסיפורים על תכונות הקשורים. השיטה שלנו השיגה מדויקה של 0.703 ו-F-מדידה משקלת של 0.664 עבור Sub-Task A, בעוד עבור Sub-Task B מדויקה הייתה 0.869 ו-F-מדידה משקלת הייתה 0.851. במונחים של הדרגות, מדד F המשקל שנקבל באמצעות השיטה שלנו לתת-משימה A מוצב ב-10 מתוך 16 קבוצות, בעוד לתת-משימה B מדד F משקל מוצב ב-8 מתוך 15 קבוצות.", 'bo': 'འོག་གི་ཤོག་བྱང་འདིས་ང་ཚོའི་མཉམ་སྤྱོད་པའི་དུས་ལ་མིང་ཞིག་སྟོན་པ(team name: scmhl5) ང་ཚོས་ཁྱད་པར་ལྡན་པར། དབྱིན་ཡིག་གཟུགས་བཀོད་པའི་ལྡར་གསུམ་གྱི་ཐོག་ལས་དབྱེ་སྟངས་དང་བཤད་པ། འདི་ལྟ་བུའི་sub-tasks གཉིས་ལས་ང་ཚོའི་ལམ་ལུགས་འདིས་སྔོན་གྱིས་འཛུགས་པའི་Bert མ་དཔེ་དབྱིབས་ཡོད་པ་རེ་རེར་སྤྱད་ནས་ཕར་ཆེན་བྱེད་སྟངས་ཀྱི་ཚན་བ(768-dimensional vector of embeddings ང་ཚོའི་ཐབས་ལམ་ལྟར་པར་ཐང་ཚད་0.703 དང་ཞེང་ཚད་0.664 རྩིས་ཡོད། Sub-task B་དག་ཚད་0.869 ཞིག་ཡོད། F-measure་ཚད་0.851 རེད། གྲལ་མིན་གྱི་གནད་དོན་དག་ཚད་ལྟར། བྱ་ཚིག་གི་ཕྱོགས་པ་ཞིག་འཇུག་གི་ཐབས་ལམ་ལ་རྒྱབ་ཐག་ཡོད།'}
{'en': 'Spyder : Aggression Detection on Multilingual Tweets S pyder: Aggression Detection on Multilingual Tweets', 'es': 'Spyder: detección de agresiones en tuits multilingües', 'ar': 'سبايدر: كشف العدوان على التغريدات متعددة اللغات', 'fr': "Spyder\xa0: détection de l'agressivité sur les tweets multilingues", 'pt': 'Spyder: detecção de agressão em tweets multilíngues', 'ja': 'Spyder:多言語ツイートでの侵略検知', 'zh': 'Spyder:多言推文之攻击性检', 'hi': 'स्पाइडर: बहुभाषी Tweets पर आक्रामकता का पता लगाना', 'ru': 'Spyder: Обнаружение агрессии в многоязычных твитах', 'ga': 'Spyder: Brath Ionsaithe ar Tweetanna Ilteangacha', 'ka': 'Spyder: მრავალენგური Tweets- ში Aggression Detection', 'el': 'Ανίχνευση επιθετικότητας σε πολυγλωσσικά tweets', 'hu': 'Spyder: Aggresszió észlelése többnyelvű tweeteken', 'mk': 'Спајдер: Детектирање на агресија на мултијазични твитови', 'ms': 'Spyder: Pengesanan Aggresi pada Tweet Berbahasa', 'it': 'Spyder: Rilevamento di aggressività sui tweet multilingui', 'mt': 'Spyder: Sejbien ta’ Aggressjoni fuq Tweets Multilingwi', 'kk': 'Спидер: Көптілікті Tweets- тегінде сәйкестік анықтау', 'no': 'Spyder: Aggressingsoppdaging på fleirspråk tweeter', 'pl': 'Spyder: Wykrywanie agresji na wielojęzycznych tweetach', 'lt': 'Spyder: Aggresijos nustatymas daugiakalbėse Tweetėse', 'sr': 'Spyder: Detekcija agresije na višejezičkim tweetima', 'si': 'ස්පායිඩර්: ගොඩක් භාෂාවක් ට්විට්ස් වල සංවේදනය හොයාගන්න', 'so': 'Spyder: Gariirka heshiiska ee luqadaha badan Tweet', 'ml': 'സ്പൈഡര്\u200d: അഗ്രാഗ്രേഷന്\u200d ഡിറ്റീറ്റീഷന്\u200d പല ഭാഷകളുടെ ടൂട്ടുകള്\u200d', 'sv': 'Spyder: Upptäckt av aggression på flerspråkiga tweets', 'mn': 'Спидер: Ихэнх хэл tweets дээр асуудлын тодорхойлолт', 'ur': 'اسپیڈر: Multilingual Tweets پر Aggression Detection', 'ro': 'Spyder: Detectarea agresiunii pe tweeturile multilingve', 'ta': 'Spyder: Aggression Detection on Multilingual Tweets', 'uz': 'Spyder: Tashkilot aniqlashni bir necha tillar foydalanish', 'vi': 'Gián điệp: Phát hiện xung kích trên Tweet ngôn ngữ', 'hr': 'Spyder: Detekcija agresije na višejezičkim Tweets', 'nl': 'Spyder: Aggressiedetectie op meertalige tweets', 'bg': 'Спайдър: Откриване на агресия при многоезични туитове', 'da': 'Spyder: Påvisning af aggression på flersprogede tweets', 'fa': 'اسپایدر: شناسایی افزایش روی Tweets Multilingual', 'de': 'Spyder: Aggressionserkennung auf mehrsprachigen Tweets', 'tr': 'Süpler: Çoklu dilli Tweets üzerinde küçümsel tanınması', 'id': 'Spyder: Aggression Detection on Multilingual Tweets', 'ko': 'Spyder: 다국어 트위터의 공격 탐지', 'sw': 'Spyder: Kutambuliwa kwa Makubaliano kwa Twita za lugha nyingi', 'hy': 'Սպիդեր. Ագրեսիայի հայտնաբերումը բազմալեզու թվիթերի վրա', 'af': 'Spyder: Aggresiebeskrywing op Multilingual Tweets', 'az': 'Spyder: Çoxlu Dil Tövetlərində Agresiya Keşfeti', 'bn': 'Spyder: Aggression Detection on Multilingual Tweets', 'sq': 'Spyder: Detektimi i agresionit në Tweets shumëgjuhës', 'am': 'Spyder: Aggression Detection Multilingual Tweets', 'ca': 'Spyder: Detection of Aggression on Multilingual Tweets', 'cs': 'Spyder: Detekce agrese na vícejazyčných tweetech', 'fi': 'Spyder: aggression tunnistus monikielisissä twieteissä', 'et': 'Spyder: Agressiooni tuvastamine mitmekeelsetes tweetides', 'bs': 'Spyder: Detekcija agresije na višejezičkim tweetima', 'jv': 'Spanish', 'sk': 'Spyder: Zaznavanje agresije na večjezičnih Tweets', 'ha': 'Phonon:: MMF:: EffectFactory', 'he': 'ספיידר: גילוי התקף על טוויטים רבים שפותיים', 'bo': 'སྒྲུང་ཐེངས་: སྐད་རིགས་གྱི་Tweets ཐོག་ཏུ་འཕགས་རིས་བསམ་བྱུང་།'}
{'en': 'In the last few years,  hate speech  and aggressive comments have covered almost all the social media platforms like  facebook ,  twitter  etc. As a result hatred is increasing. This paper describes our (Team name : Spyder) participation in the Shared Task on  Aggression Detection  organised by TRAC-2, Second Workshop on  Trolling ,  Aggression  and  Cyberbullying . The Organizers provided datasets in three languages    English ,  Hindi  and  Bengali . The task was to classify each instance of the test sets into three categories   Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-Aggressive (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and  machine learning based classifiers . We obtained  f1 score  of 43.10 %, 59.45 % and 44.84 % respectively for  English ,  Hindi  and  Bengali . Team name: \n         Spyder ) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages – English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories – “Overtly Aggressive” (OAG), “Covertly Aggressive” (CAG) and “Non-Aggressive” (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.', 'ar': 'في السنوات القليلة الماضية ، غطى خطاب الكراهية والتعليقات العدوانية جميع منصات التواصل الاجتماعي تقريبًا مثل facebook و twitter وما إلى ذلك. ونتيجة لذلك ، تتزايد الكراهية. تصف هذه الورقة مشاركتنا (اسم الفريق: سبايدر) في المهمة المشتركة حول اكتشاف العدوان التي نظمتها TRAC-2 ، ورشة العمل الثانية حول التصيد والعدوان والتسلط عبر الإنترنت. قدم المنظمون مجموعات بيانات بثلاث لغات - الإنجليزية والهندية والبنغالية. كانت المهمة هي تصنيف كل حالة من مجموعات الاختبار إلى ثلاث فئات - "عدواني بشكل علني" (OAG) ، و "عدواني بشكل سري" (CAG) و "غير عدواني" (NAG). في هذه الورقة ، نقترح ثلاثة نماذج مختلفة باستخدام المصنفات القائمة على Tf-Idf وقطبية المشاعر والتعلم الآلي. حصلنا على درجة f1 بنسبة 43.10٪ و 59.45٪ و 44.84٪ على التوالي للغة الإنجليزية والهندية والبنغالية.', 'pt': 'Nos últimos anos, discursos de ódio e comentários agressivos cobriram quase todas as plataformas de mídia social como facebook, twitter etc. Como resultado, o ódio está aumentando. Este artigo descreve nossa participação (nome da equipe: Spyder) na Tarefa Compartilhada de Detecção de Agressão organizada pelo TRAC-2, Segundo Workshop sobre Trolling, Agressão e Cyberbullying. Os organizadores forneceram conjuntos de dados em três idiomas – inglês, hindi e bengali. A tarefa foi classificar cada instância dos conjuntos de testes em três categorias – “Abertamente Agressivo” (OAG), “Cobertamente Agressivo” (CAG) e “Não Agressivo” (NAG). Neste artigo, propomos três modelos diferentes usando Tf-Idf, polaridade de sentimento e classificadores baseados em aprendizado de máquina. Obtivemos pontuação f1 de 43,10%, 59,45% e 44,84% respectivamente para inglês, hindi e bengali.', 'es': 'En los últimos años, el discurso de odio y los comentarios agresivos han cubierto casi todas las plataformas de medios sociales como Facebook, Twitter, etc. Como resultado, el odio está aumentando. Este artículo describe nuestra participación (Nombre del equipo: Spyder) en la tarea compartida sobre detección de agresión organizada por TRAC-2, Segundo taller sobre trolling, agresión y ciberacoso. Los organizadores proporcionaron conjuntos de datos en tres idiomas: inglés, hindi y bengalí. La tarea consistía en clasificar cada instancia de los conjuntos de pruebas en tres categorías: «Agresiva manifiesta» (OAG), «Agresiva encubierta» (CAG) y «No agresiva» (NAG). En este artículo, proponemos tres modelos diferentes que utilizan clasificadores basados en Tf-Idf, polaridad de sentimiento y aprendizaje automático. Obtuvimos una puntuación f1 del 43,10%, 59,45% y 44,84% respectivamente para inglés, hindi y bengalí.', 'fr': "Au cours des dernières années, les discours haineux et les commentaires agressifs ont couvert presque toutes les plateformes de médias sociaux comme Facebook, Twitter, etc. Cet article décrit notre participation (nom de l'équipe\xa0: Spyder) à la tâche partagée sur la détection de l'agression organisée par TRAC-2, Second Workshop on Trolling, Agressivité and Cyberbullying. Les organisateurs ont fourni des ensembles de données en trois langues\xa0: anglais, hindi et bengali. La tâche consistait à classer chaque instance des ensembles de tests en trois catégories\xa0: «\xa0ouvertement agressif\xa0» (OAG), «\xa0secrètement agressif\xa0» (CAG) et «\xa0non agressif\xa0» (NAG). Dans cet article, nous proposons trois modèles différents utilisant Tf-Idf, la polarité des sentiments et des classificateurs basés sur l'apprentissage automatique. Nous avons obtenu un score f1 de 43,10\xa0%, 59,45\xa0% et 44,84\xa0% respectivement pour l'anglais, l'hindi et le bengali.", 'zh': '在昔数年,仇言攻击性论几覆社交媒体台,如Facebook,Twitter等。 仇方增。 本文引我(团队名:Spyder)与TRAC-2侵检之共同任务,再拖钓侵网络之研讨会。 组织者给三语数集 - 英语,印地语孟加拉语。 分试集为例为三 - "公攻击性"(OAG),"隐攻击性"(CAG)"非攻击性"(NAG)。 本文中,发用Tf-Idf,情极性与机器学分类器三者不同。 英语、印地语、孟加拉语f1得分为43.10%、59.45%、44.84%。', 'hi': 'पिछले कुछ वर्षों में, हेट स्पीच और आक्रामक टिप्पणियों ने फेसबुक, ट्विटर आदि जैसे लगभग सभी सोशल मीडिया प्लेटफार्मों को कवर किया है। नतीजतन नफरत बढ़ती जा रही है। यह पेपर TRAC-2, Trolling, आक्रामकता और Cyberbullying पर दूसरी कार्यशाला द्वारा आयोजित आक्रामकता का पता लगाने पर साझा कार्य में हमारी (टीम का नाम: Spyder) भागीदारी का वर्णन करता है। आयोजकों ने तीन भाषाओं - अंग्रेजी, हिंदी और बंगाली में डेटासेट प्रदान किए। कार्य परीक्षण सेट के प्रत्येक उदाहरण को तीन श्रेणियों में वर्गीकृत करना था - "अत्यधिक आक्रामक" (ओएजी), "गुप्त रूप से आक्रामक" (सीएजी) और "गैर-आक्रामक" (एनएजी)। इस पेपर में, हम Tf-Idf, भावना ध्रुवीयता और मशीन लर्निंग आधारित क्लासिफायरका उपयोग करके तीन अलग-अलग मॉडलों का प्रस्ताव करते हैं। हमने अंग्रेजी, हिंदी और बंगाली के लिए क्रमशः 43.10%, 59.45% और 44.84% का f1 स्कोर प्राप्त किया।', 'ru': 'За последние несколько лет ненавистнические высказывания и агрессивные комментарии охватили почти все социальные медиа-платформы, такие как facebook, Twitter и т. д. В результате ненависть усиливается. В этом документе описывается наше участие (название команды: Spyder) в Совместной задаче по обнаружению агрессии, организованной TRAC-2, Второй семинар по троллингу, агрессии и кибербуллингу. Организаторы представили наборы данных на трех языках – английском, хинди и бенгальском. Задача состояла в том, чтобы классифицировать каждый экземпляр тестовых наборов по трем категориям – «открыто агрессивные» (ОАГ), «скрыто агрессивные» (КАГ) и «неагрессивные» (НАГ). В этой статье мы предлагаем три различные модели с использованием Tf-Idf, полярности настроений и классификаторов на основе машинного обучения. Мы получили оценку f1 43,10%, 59,45% и 44,84% соответственно для английского, хинди и бенгальского языка.', 'ja': 'ここ数年、ヘイトスピーチや攻撃的なコメントは、facebook、twitterなどのソーシャルメディアプラットフォームのほぼすべてをカバーしています。そのため、憎悪が高まっている。この論文では、TRAC -2、トロール、アグレッション、ネットいじめに関する第2回ワークショップが主催する「侵略検出に関する共有タスク」への（チーム名： Spyder ）の参加について説明します。主催者は、英語、ヒンディー語、ベンガル語の3つの言語でデータセットを提供しました。このタスクは、テストセットの各インスタンスを、「露骨に攻撃的」（ OAG ）、「秘密裏に攻撃的」（ CAG ）、および「非攻撃的」（ NAG ）の3つのカテゴリに分類することでした。本稿では、Tf - Idf、センチメント極性、機械学習ベースの分類子を用いた3つの異なるモデルを提案する。英語、ヒンディー語、ベンガル語でそれぞれ43.10%、59.45%、44.84%のf 1スコアを得た。', 'ga': 'Le blianta beaga anuas, clúdaíodh fuathchaint agus tráchtaireacht ionsaitheach ar bheagnach gach ardán meán sóisialta ar nós facebook, twitter etc. Mar thoradh air sin tá an fuath ag méadú. Déanann an páipéar seo cur síos ar ár rannpháirtíocht (Ainm Foirne: Spyder) sa Tasc Comhroinnte ar Bhrath Ionsaitheach arna eagrú ag TRAC-2, an Dara Ceardlann ar Throláil, Ionsaí agus Cibearbhulaíocht. Chuir na hEagraithe tacair shonraí ar fáil i dtrí theanga – Béarla, Hiondúis agus Beangáilis. Ba é an tasc a bhí ann ná gach cás de na tacair tástála a rangú i dtrí chatagóir – “Go hOllmhargach Ionsaitheach” (OAG), “Covertly Ionsaitheach” (CAG) agus “Neamh- Ionsaitheach” (NAG). Sa pháipéar seo, molaimid trí mhúnla éagsúla a úsáideann Tf-Idf, polaraíocht meon agus aicmitheoirí atá bunaithe ar mheaisín-fhoghlaim. Fuaireamar scór f1 de 43.10%, 59.45% agus 44.84% faoi seach do Bhéarla, Hiondúis agus Beangáilis.', 'hu': 'Az elmúlt néhány évben a gyűlöletbeszéd és az agresszív megjegyzések szinte minden közösségi média platformra kiterjedtek, mint a facebook, a twitter stb. Ennek eredményeképpen növekszik a gyűlölet. Ez a tanulmány bemutatja (Csapatnév: Spyder) részvételünket a TRAC-2 által szervezett, a Trolling, Agresszió és Cyberbullying második workshopján. A Szervezők három nyelven – angol, hindi és bengáli nyelven – biztosítottak adatkészleteket. A feladat az volt, hogy a vizsgálati készletek minden egyes példányát három kategóriába sorolják: "Túlzottan agresszív" (OAG), "Túlzottan agresszív" (CAG) és "Nem agresszív" (NAG). Ebben a tanulmányban három különböző modellt javasolunk Tf-Idf, sentiment polarity és gépi tanulás alapú osztályozókat használva. Az angol, hindi és bengáli f1 pontszám 43,10%, 59,45%, illetve 44,84%.', 'el': 'Τα τελευταία χρόνια, η ρητορική μίσους και τα επιθετικά σχόλια έχουν καλύψει σχεδόν όλες τις πλατφόρμες κοινωνικής δικτύωσης όπως κλπ. Ως αποτέλεσμα το μίσος αυξάνεται. Η παρούσα εργασία περιγράφει τη συμμετοχή μας (όνομα ομάδας: κατάσκοπος) στην Κοινή Εργασία για την Ανίχνευση Επιπτώσεων που διοργανώθηκε από το Δεύτερο Εργαστήριο για το Τρόλινγκ, την Επίθεση και τον Κυβερνοβουλισμό. Οι διοργανωτές παρείχαν σύνολα δεδομένων σε τρεις γλώσσες: Αγγλικά, Χίντι και Βεγγαλικά. Το καθήκον ήταν να ταξινομηθεί κάθε περίπτωση των συνόλων δοκιμών σε τρεις κατηγορίες: "Υπερβολικά επιθετική" (OAG), "Κρυμμένα επιθετική" (CAG) και "Μη επιθετική" (NAG). Στην παρούσα εργασία, προτείνουμε τρία διαφορετικά μοντέλα χρησιμοποιώντας ταξινομητές που βασίζονται σε πολικότητα συναισθημάτων και μηχανική μάθηση. Πήραμε βαθμολογία f1 43.10%, 59.45% και 44.84% αντίστοιχα για τα Αγγλικά, τα Χίντι και τα Βεγγαλικά.', 'it': 'Negli ultimi anni, discorsi d\'odio e commenti aggressivi hanno coperto quasi tutte le piattaforme di social media come facebook, twitter ecc. Di conseguenza l\'odio è in aumento. Questo articolo descrive la nostra partecipazione (Team name: Spyder) al Compito Condiviso sulla Rilevazione dell\'Aggressione organizzato da TRAC-2, Secondo Workshop su Trolling, Aggressione e Cyberbullismo. Gli organizzatori hanno fornito set di dati in tre lingue - inglese, hindi e bengalese. Il compito era quello di classificare ogni istanza dei set di test in tre categorie - "Overtly Aggressive" (OAG), "Coverly Aggressive" (CAG) e "Non Aggressive" (NAG). In questo articolo, proponiamo tre diversi modelli che utilizzano Tf-Idf, polarità sentimentale e classificazione basata sull\'apprendimento automatico. Abbiamo ottenuto il punteggio f1 del 43,10%, 59,45% e 44,84% rispettivamente per inglese, hindi e bengalese.', 'kk': "Соңғы бірнеше жылда сөйлесу және агрессивні түсініктемелер жалғастырып, Facebook, twitter және т.б. секілді жалғастырып жатыр. Бұл қағаз TRAC-2, Trolling, Aggression және Cyberbullying бойынша екінші жұмыс шоғырында ортақ тапсырмаға қатынасызды (Топ атауы: Spyder) қатынасызды таңдайды. Организаторлар үш тілде деректер қорларын - ағылшын, хинди және бенгали тілде берді. Тапсырма тексеру баптауларының әрбір инстанциясын үш санатына - 'Үлкен сұрақтық' (OAG), 'Мұқаралық сұрақтық' (CAG) және 'Сұрақтық емес' (NAG) классификациялауы болды. Бұл қағазда Tf-Idf, сезімдік поляриялық және машинаның оқыту классификаторын қолданатын үш түрлі үлгі моделдерді таңдаймыз. Біз f1 нөмірі 43,10%, 59,45% және 44,84% ағылшын, хинди және бенгали үшін алдық.", 'mk': 'In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing.  Овој весник го опишува нашето учество (името на тимот: Шпијдер) во заедничката задача за детекција на агресија организирана од TRAC-2, вториот работилник за тролинг, агресија и киберболитирање. Организаторите обезбедија податоци на три јазици - англиски, хинди и бенгали. Задачата беше да се класификува секоја инстанција од тестовите во три категории - „Премногу агресивно“ (OAG), „Сокриено агресивно“ (CAG) и „Неагресивно“ (NAG). Во овој весник предложуваме три различни модели кои користат Тф-Идф, поларитет на чувствата и класификатори базирани на машинско учење. Добивме оценка f1 од 43,10 отсто, 59,45 отсто и 44,84 отсто за англиски, хинди и бенгали.', 'ka': "ოჲჟლვენთრვ ნწკჲლკჲ დჲეთნთ, მპაჱნთ დჲგჲპთ თ ადპვჟთგნთ კჲმვნრპთ ჟვ ჲბკპთგარ ოჲფრთ გჟთფკთ ჟჲუთალნთ მვეთწ ოლარტჲპმართ, კარჲ ტვიჟბსკ, რგთრვპ ეს დოკუნტი აღწერს ჩვენი (Team name: Spyder) დანაწილეობა საზოგადოებული დავალებაში TRAC-2, მეორე სამუშაო სამუშაო Trolling, Aggression და Cyberbullying-ზე. Organizers provided datasets in three languages - English, Hindi and Bengali. პარამეტრები იყო, რომ ტესტის სამი კატეგორიაში ყოველ ინსტანსის კლასიფიკაცია - 'ძალიან ადგრესიური' (OAG), 'სამხოლოდ ადგრესიური' (CAG) და 'არა ადგრესიური' (NAG). ამ დოკუნეში ჩვენ სამი განსხვავებული მოდელის გამოყენება Tf-Idf, სენტიმენტის პოლარიტი და მაქინის სწავლების კლასიფიკაციების გამოყენება. ჩვენ მივიღეთ f1 წერტილი 43,10%, 59,45% და 44,84% ანგლისურად, ჰინდი და ბენდალისთვის.", 'lt': 'Per pastaruosius kelerius metus neapykantos kalba ir agresyvios pastabos apimo beveik visas socialinės žiniasklaidos platformas, pvz., Facebook, Twitter ir t. t. Dėl to didėja neapykanta. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  Organizatoriai pateikė duomenų rinkinius trimis kalbomis - anglų, hindų ir bengalų kalbomis. Kiekvienas bandymų rinkinio atvejis buvo klasifikuojamas į tris kategorijas - "pernelyg agresyvus" (OAG), "apskritai agresyvus" (CAG) ir "nesuagresyvus" (NAG). Šiame dokumente siūlome tris skirtingus modelius, naudojančius Tf-Idf, jausmų poliarumą ir mašinų mokymosi klasifikatorius. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.', 'ms': "Dalam beberapa tahun terakhir, ucapan kebencian dan komentar agresif telah menutupi hampir semua platform media sosial seperti facebook, twitter dan sebagainya kebencian meningkat. Kertas ini menggambarkan (nama pasukan: Spyder) participasi kami dalam Tugas Berkongsi untuk pengesan Aggresi yang dirancang oleh TRAC-2, Workshop Kedua tentang Trolling, Aggression dan Cyberbullying. Pengurus menyediakan set data dalam tiga bahasa - Bahasa Inggeris, Hindi dan Bengali. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  Dalam kertas ini, kami cadangkan tiga model yang berbeza menggunakan Tf-Idf, polariti perasaan dan klasifikasi pembelajaran mesin. Kami mendapat skor f1 43.10%, 59.45% dan 44.84% respectively untuk bahasa Inggeris, Hindi dan Bengali.", 'ml': "കഴിഞ്ഞ കുറച്ചു വര്\u200dഷങ്ങളില്\u200d, വെറുപ്പുകളും അക്രമമായ വാക്കുകളും മുഴുവന്\u200d സാമൂഹ്യ മീഡിയ പ്ലാറ്റ്ഫോമുകളും മൂടിയിട്ടുണ്ട്. ഫെസ ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ (ടീം പേര്: സ്പൈഡര്\u200d) പങ്കെടുത്ത ജോലിയില്\u200d പങ്കുചേര്\u200dക്കുന്നു സംഘടനക്കാര്\u200d മൂന്നു ഭാഷകളില്\u200d ഡാറ്റാസറ്റുകള്\u200d നല്\u200dകിയിരിക്കുന്നു. ഇംഗ്ലീഷ്, ഹിന്ദി, ബെങ്കാ പരീക്ഷണ സജ്ജീകരണങ്ങളുടെ ഓരോ അവസ്ഥ മൂന്നു വിഭാഗങ്ങളായി - 'മുഴുവന്\u200d അഗ്രാഗ്രാസ്റ്റീവ്' (OAG), 'കോപ്റ്റ്ലി Aggressive' (CAG) അല്ലാത്ത വിഭാഗങ്ങള്\u200d' ( ഈ പത്രത്തില്\u200d ടിഫ്-ഐഡിഫിനെ ഉപയോഗിക്കുന്ന മൂന്നു വ്യത്യസ്ത മോഡലുകള്\u200d ഞങ്ങള്\u200d നിര്\u200dദ്ദേശിക്കുന്നു. വിചാരപൂര്\u200dണ്ണമ We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.", 'mt': "Fl-a ħħar ftit snin, id-diskors tal-mibegħda u l-kummenti aggressivi koprew kważi l-pjattaformi kollha tal-midja soċjali bħall-facebook, it-twitter eċċ. B’riżultat ta’ dan il-mibegħda qed tiżdied. Dan id-dokument jiddeskrivi l-parteċipazzjoni tagħna (Isem it-Tim: Spyder) fil-Kompitu Konġunt dwar id-Detezzjoni tal-Aggressjoni organizzat mit-TRAC-2, it-Tieni Workshop dwar it-Trolling, l-Aggressjoni u ċ-Ċiberbullying. L-Organizzaturi pprovdew settijiet ta’ dejta fi tliet lingwi - l-Ingliż, l-Indjan u l-Bengali. Il-kompitu kien li kull każ tas-settijiet tat-testijiet jiġi kklassifikat fi tliet kategoriji - 'Aggressivi żżejjed' (OAG), 'Aggressivi b'mod Kopert' (CAG) u 'Mhux Aggressivi' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers.  Kisbu punteġġ f1 ta’ 43.10%, 59.45% u 44.84% rispettivament għall-Ingliż, l-Indjan u l-Bengali.", 'pl': 'W ciągu ostatnich kilku lat mowa nienawiści i agresywne komentarze obejmowały prawie wszystkie platformy mediów społecznościowych, takie jak facebook, twitter itp. W rezultacie nienawiść wzrasta. Niniejszy artykuł opisuje nasz (nazwa zespołu: Spyder) udział w wspólnym zadaniu wykrywania agresji organizowanym przez TRAC-2, Drugie warsztaty na temat trollingu, agresji i cyberprzemocy. Organizatorzy dostarczyli zbiory danych w trzech językach: angielskim, hindi i bengalskim. Zadaniem było podzielenie każdej instancji zestawów testowych na trzy kategorie: nadmiernie agresywne (OAG), "tajne agresywne" (CAG) i "nieagresywne" (NAG). W niniejszym artykule proponujemy trzy różne modele wykorzystujące klasyfikatory Tf-Idf, polaryzację sentymentów oraz klasyfikatory oparte na uczeniu maszynowym. Uzyskaliśmy wynik f1 43,10%, 59,45% i 44,84% odpowiednio dla angielskiego, hindi i bengalskiego.', 'ro': 'În ultimii ani, discursul de ură și comentariile agresive au acoperit aproape toate platformele de social media precum facebook, twitter etc. Ca urmare ura este în creștere. Această lucrare descrie participarea noastră (numele echipei: Spyder) la activitatea comună privind detectarea agresiunii organizată de TRAC-2, al doilea atelier privind trolling, agresiune și cyberbullying. Organizatorii au furnizat seturi de date în trei limbi - engleză, hindi și bengală. Sarcina a fost de a clasifica fiecare instanță a seturilor de teste în trei categorii - "excesiv agresiv" (OAG), "excesiv agresiv" (CAG) și "non-agresiv" (NAG). În această lucrare, propunem trei modele diferite folosind Tf-Idf, polaritatea sentimentului și clasificarea bazată pe machine learning. Am obținut scorul f1 de 43,10%, 59,45% și respectiv 44,84% pentru engleză, hindi și bengali.', 'si': "අන්තිම අවුරුදු කීපයක් වලින්, වෛර කරනවා කියලා සමාජික මධ්\u200dයමාධ්\u200dයම ප්\u200dරවෘත්තියක් වගේ ප්\u200dරවෘත්තියක් වගේ පැත මේ පැත්තේ අපේ සම්බන්ධ නාමය (කණ්ඩායම්: ස්පායිඩර්) සම්බන්ධ වැඩක් තියෙනවා TRAC-2, දෙවෙනි වැඩකරුව ට්\u200dරෝලින්, සායිබර්බුලින් වල සංයෝජනකරුවන් දත්ත සැට් තුනක් භාෂාවට දුන්නා - ඉංග්\u200dරීසි, හින්දි සහ බෙන්ගාලි. වැඩය තමයි පරීක්ෂණා සැකසුම් හැම සැකසුම් තුනක් වලට පරීක්ෂණය කරගන්න - 'වැඩියෙන් වැඩියි' (OAG), 'කවර්ට්ලි වැඩියි' (CAG) සහ 'වැඩියෙන්  මේ පැත්තට, අපි Tf-Idb භාවිතා වෙනස් මොඩේල් තුනක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා, දැනුම් ප්\u200dරයෝජනය සහ ම අපිට අංග්\u200dරීසි, හින්දි සහ බෙන්ගාලි වලට f1 ප්\u200dරමාණයක් ලැබුනා.", 'mn': "Өнгөрсөн хэдэн жилийн дотор үзэн ядах яриа, хүчирхийллэг сэтгэл зүйл нь facebook, twitter гэх мэт бүх нийгмийн медиа платформуудыг харуулж байна. Үүний үр дүнд үзэн ядах нь нэмэгддэг. Энэ цаас бидний (Баг нэр: Спидер) TRAC-2, Тролинг, Агресс, Цибербулингийн хоёр дахь ажиллагааны тухай хуваалцах ажилд оролцож байна. Организагчид гурван хэл дээр өгөгдлийн сангууд - Англи, Хинди, Бенгали. Үүний шалгалтын давхар бүрийг 3 категорид хэлбэрээр хэлбэртэй (OAG), 'Мөн хэлбэртэй' (CAG) болон 'Мөн хэлбэргүй' (NAG) хэлбэрээр ангилах байсан. Энэ цаасан дээр бид Tf-Idf, сэтгэл хөдлөл, машины сургалтын үндсэн хэлбэрүүдийг ашиглан гурван өөр загварыг санал болгож байна. Бид f1 оноо 43,10%, 59,45% болон 44,84% Англи, Хинди болон Бенгали хүмүүст авсан.", 'sr': "U poslednjih nekoliko godina, govor mržnje i agresivni komentari su pokrili skoro sve platforme društvenih medija poput facebook, twitter itd. Ovaj papir opisuje naše (Tim name: Spyder) sudjelovanje u zajedničkom zadatku o detekciji agresije organizovanom TRAC-2, drugom radionicom o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio da klasifikišemo svaku instancu testova u tri kategorije - pretjerano agresivno (OAG), 'Prikriveno agresivno' (CAG) i 'ne-agresivno' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost sentimenta i klasifikatore osnovane na mašinama. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.", 'so': "Sannadihii ugu dambeeyey, hadalka nacayb iyo commentarada kibirka ah waxay ku qariyeen jardiinada shabakadda bulshada oo dhan sida facebook, twitter etc. sababtoo darteed nacaybku waa sii kordhayaa. Qoraalkan waxaa ku qoran (Team name: Spyder) qayb ka dhigista shaqada la sharciyey Aggression Detection organized by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. Waxay qabanqaabiyaan macluumaadyo ku qoran saddex luuqadood - Ingiriis, Hindi iyo Bengali. Shaqada waxaa lagu qoray inuu u kala sooco caymis kasta oo imtixaanka lagu sameeyo saddex categor - 'Overall Aggressive' (OAG), 'Covertly Aggressive' (CAG) iyo 'Non-Aggressive' (NAG). Qoraalkan waxaan ku soo jeedaynaa saddex tusaale oo kala duduwan oo isticmaalaya Tf-Idf, qasabka fikrada iyo waxbarashada machine-ka. Af Ingiriis, Hindi iyo Bengali ayaannu helnay boqolkiiba f1 boqolkiiba 43.10, 59.45 % iyo 44.84 boqolkiiba.", 'sv': 'Under de senaste åren har hatpropaganda och aggressiva kommentarer täckt nästan alla sociala medieplattformar som facebook, twitter etc. Som ett resultat av detta ökar hatet. Denna uppsats beskriver vårt (Team name: Spyder) deltagande i Shared Task on Aggression Detection organiserad av TRAC-2, Andra Workshop om Trolling, Aggression och Cybermobbning. Arrangörerna tillhandahöll datauppsättningar på tre språk - engelska, hindi och bengaliska. Uppgiften var att klassificera varje instans av testuppsättningarna i tre kategorier - "Övergripande" (OAG), "Coverly Aggressive" (CAG) och "Non-Aggressive" (NAG). I denna uppsats föreslår vi tre olika modeller med hjälp av Tf-Idf, sentimentpolaritet och maskininlärningsbaserade klassificerare. Vi fick f1 poäng på 43,10%, 59,45% respektive 44,84% för engelska, hindi och bengali.', 'ur': "پچھلے چند سال میں، ناپسند بات اور سختی کی کمانٹیاں تقریباً تمام سوسیل میڈیا پٹرومٹیاں جیسے facebook, twitter اور اگلوں پر پورے ہوئے ہیں. نتیجہ میں نفرت بڑھتی ہے. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organized by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. سازمان کرنے والوں نے تین زبانوں میں ڈاٹ سٹ دی - انگلیسی, ہندی اور بنگالی۔ اس کا کام یہ تھا کہ ہر امتحان سٹ کو تین کاٹیوں میں تقسیم کریں - 'زیادہ گریز' (OAG), 'Covertly Aggressive' (CAG) اور 'Non-Aggressive' (NAG)۔ اس کاغذ میں ہم Tf-Idf کے استعمال سے تین مختلف موڈل پیشنهاد کرتے ہیں، احساسات آلودگی اور ماشین سیکھنے کی بنیادی کلاسیٹر کے استعمال سے۔ ہم نے 43.10%, 59.45% اور 44.84% انگلیسی, ہندی اور بنگالی کے لئے f1 سکوٹ پائی۔", 'no': "I dei siste få år har hatt tale og aggressiv kommentarar dekka nesten alle sosiale mediaplattformene som facebook, twitter osv. Som resultatet er hatt økt. Denne papiret beskriver vårt (gruppenamn: Spyder) deltakast i delt oppgåve om Aggressingsoppdaging organisert av TRAC-2, andre arbeidsområde på Trolling, Aggressing og Cyberbullying. Organisatorene oppgav datasett i tre språk – engelsk, hindisk og Bengalisk. Oppgåva var å klassifisera kvar instans av testsettet inn i tre kategoriar – overAggresiv (OAG), 'Covertly Aggressive' (CAG) og 'Non-Aggressive' (NAG). I denne papiret foreslår vi tre ulike modeller med Tf-Idf, sentiment-polaritet og maskinelæring basert klassifiserar. Vi har f1 poeng med 43,10%, 59,45% og 44,84% for engelsk, hindisk og bengalisk.", 'ta': "கடந்த சில ஆண்டுகளில், வெறுப்பு பேச்சு மற்றும் அக்கிரமமான கருத்துக்கள் கிட்டத்தட்ட அனைத்து சமூக ஊடக முறைமைகளை மூடியிருக்கிறத இந்த காகிதத்தில் எங்கள் (குழு பெயர்: ஸ்பைட்டர்) TRAC- 2 ஆல் நிறுவப்பட்ட வேலையில் பங்கிடப்பட்டுள்ளது என்ற பணியில் பகிர்ந்து கொள்ளப்படுகிறது, ட்ரால் நிறுவனர்கள் மூன்று மொழிகளில் தகவல் அமைப்பு சோதனை அமைப்புகளின் ஒவ்வொரு நிகழ்வும் மூன்று வகுப்புகளாக வகுப்படுத்த வேண்டும் 'மேலும் Aggressive' (OAG), 'Covertly Aggressive' (CAG) மற்றும் 'Aggressive' (NAG). இந்த காகிதத்தில், Tf-Idf, உணர்வு தீவிரம் மற்றும் இயந்திரம் வகுப்பாளர் நாங்கள் ஆங்கிலத்து, ஹின்டி மற்றும் பெங்காலிக்கு நிதியாக 43.10%, 59.45% மற்றும் 44.84% கிடைத்தோம்.", 'vi': 'Trong những năm gần đây, lời nói căm ghét và những bình luận tích cực đã bao trùm hầu hết các nền tảng truyền thông xã hội như facebook, twitter, v.v. Kết quả là sự căm ghét đang tăng dần. Tờ giấy này mô tả sự tham gia của chúng ta (tên của nhóm: Spyder) vào "Việc Điều tra tấn công" được chia sẻ được tổ chức bởi TRAC-2, Thứ nhì "Xưởng làm việc" về tội phạm, rối loạn và nạn nhân ảo. Các tổ chức cung cấp dữ liệu bằng ba ngôn ngữ: Anh, Hindi và Bengali. Nhiệm vụ là phân loại mỗi trường hợp của các thử nghiệm thành ba loại "Tổng tấn công" khủng khiếp (OAS nhận nhận dạng A.G). và "không hung hãn" (NAG). Trong tờ giấy này, chúng tôi đề xuất ba mẫu khác nhau sử dụng các phân loại cảm xúc và các phân loại máy móc. Chúng tôi có kết quả F1 số lượng của 43.10=, 59.45=. và 44.84=. for English, Hindi và Bengali.', 'uz': "Keyingi necha yil ichida, kuch aytish va aggressiv izohlar faqat facebook, twitter etc. kabi hamma jamiyat medya platformlarini qaraydi. natijada hat ko'prodi. Бу саҳифа бизнинг (Team номи: Spyder) TRAC-2, Тўғрилик, Китоб ва Кипробляция Қуйидаги ўзгартириш вазифасига шерик бўлишимизни айтиб беради. Dasturlar uch tillarda maʼlumotlar tarkibini ingliz, Hindi va Bengalcha tilida yaratadi. Name Bu qogʻozda, biz Tf-Idf, hissiyot polariyat va mashinalar asosida o'rganishga uchta boshqa modellarni rivojlanamiz. Biz ingliz, Hindi va Bengalchaga har xizmat 43.10%, 59.45% va 44.84% foizdan foydalandik.", 'bg': 'През последните няколко години речта на омразата и агресивните коментари обхванаха почти всички социални медийни платформи като В резултат на това омразата нараства. Настоящата статия описва нашето (име на екипа: Спайдър) участие в споделената задача за откриване на агресия, организирана от Втора работна среща по тролинг, агресия и кибертормоз. Организаторите предоставиха набори от данни на три езика - английски, хинди и бенгалски. Задачата беше да се класифицират всеки пример от тестовите групи в три категории - "прекалено агресивен" (OAG), "скрит агресивен" (CAG) и "неагресивен" (NAG). В настоящата статия предлагаме три различни модела, използващи класификатори, базирани на сентиментална полярност и машинно обучение. Получихме резултат от 43,10%, 59,45% и 44,84% съответно за английски, хинди и бенгалски.', 'hr': "U posljednjih nekoliko godina, govor mržnje i agresivni komentari pokrivali su skoro sve platforme društvenih medija poput facebook, twitter itd. Ovaj papir opisuje naše sudjelovanje (Tim name: Spyder) u zajedničkom zadatku o detectivu agresije organiziranom TRAC-2, Drugi radnički rad o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio klasifikacija svake primjere testova u tri kategorije - pretjerano agresivne (OAG), 'Prikriveno agresivne' (CAG) i 'ne agresivne' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost osjećaja i klasifikatore na osnovu učenja strojeva. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.", 'da': 'I løbet af de sidste par år har had tale og aggressive kommentarer dækket næsten alle sociale medier platforme som facebook, twitter osv. Som følge heraf er hadet voksende. Denne artikel beskriver vores (Team name: Spyder) deltagelse i Delt Opgave om Aggression Detection organiseret af TRAC-2, Anden Workshop om Trolling, Aggression og Cybermobbing. Arrangørerne leverede datasæt på tre sprog - engelsk, hindi og bengali. Opgaven var at klassificere hver enkelt forekomst af testsættene i tre kategorier - "Over Aggressive" (OAG), "Coverly Aggressive" (CAG) og "Non-Aggressive" (NAG). I denne artikel foreslår vi tre forskellige modeller ved hjælp af Tf-Idf, sentiment polarity og machine learning baserede klassificeringer. Vi fik f1 score på 43,10%, 59,45% og 44,84% for henholdsvis engelsk, hindi og bengali.', 'de': 'In den letzten Jahren haben Hassrede und aggressive Kommentare fast alle Social-Media-Plattformen wie Facebook, Twitter etc. abgedeckt, wodurch Hass zunimmt. Dieses Papier beschreibt unsere (Teamname: Spyder) Teilnahme an der von TRAC-2 organisierten Shared Task on Aggression Detection, Second Workshop on Trolling, Aggression and Cybermobbing. Die Organisatoren stellten Datensätze in drei Sprachen zur Verfügung: Englisch, Hindi und Bengali. Die Aufgabe bestand darin, jede Instanz der Testsätze in drei Kategorien zu klassifizieren: Overtly Aggressive (OAG), "Covertly Aggressive" (CAG) und "Non-Aggressive" (NAG). In diesem Beitrag schlagen wir drei verschiedene Modelle vor, die Tf-Idf, Sentiment Polarity und Machine Learning basierte Klassifikatoren verwenden. Für Englisch, Hindi und Bengali erreichten wir f1 Score von 43,10%, 59,45% und 44,84% .', 'nl': "In de afgelopen jaren hebben hate speech en agressieve reacties bijna alle sociale media platforms zoals facebook, twitter etc. bestraald waardoor haat toeneemt. Dit artikel beschrijft onze (Teamnaam: Spyder) deelname aan de Shared Task on Aggression Detection georganiseerd door TRAC-2, Tweede Workshop over Trolling, Aggressie en Cyberpesten. De Organisatoren leverden datasets in drie talen: Engels, Hindi en Bengaals. De taak was om elke instantie van de testsets te classificeren in drie categorieën: Overtly Aggressive (OAG), 'Covertly Aggressive' (CAG) en 'Non-Aggressive' (NAG). In dit artikel stellen we drie verschillende modellen voor met behulp van Tf-Idf, sentimentpolariteit en machine learning gebaseerde classificatoren. We behaalden f1 score van respectievelijk 43,10%, 59,45% en 44,84% voor Engels, Hindi en Bengaals.", 'fa': "در چند سال گذشته، از سخنرانی متنفر و توضیح\u200cهای تجاوز تقریباً تمام platformهای رسانه\u200cهای اجتماعی مانند facebook, twitter و غیر از آن پوشیده شده است. به نتیجه نفرت افزایش می\u200cیابد. این کاغذ (نام تیم: Spyder) مشارکت ما را توصیف می\u200cکند در کار مشترک در مورد بازرسی گروهی که توسط TRAC-2 سازمان شده است، کارگاه دوم در مورد ترولینگ، گروهی و سایبر بولینگ است. Organizers provided data sets in three languages - English, Hindi and Bengali. وظیفه این بود که هر نمونه از مجموعه\u200cهای آزمایش را در سه گروه کلاس کنیم - 'زیادی گریز' (OAG), 'قابل گریز' (CAG) و 'ناگریز' (NAG). در این کاغذ، ما سه مدل متفاوتی را با استفاده از Tf-Idf پیشنهاد می کنیم، قطعیت احساسات و دستگاه یادگیری بر اساس مختلف راهنمایی. ما درصد f1 از 43.10%, 59.45% و 44.84% به عنوان انگلیسی, هندی و بنگالی دریافت کردیم.", 'sw': "Katika miaka michache iliyopita, hotuba ya chuki na maoni ya kibaguzi yamekuwa yakitangaza karibu majukwaa ya mitandao ya kijamii kama vile Facebook, twita etc. Matokeo yake yanaongezeka chuki. Gazeti hili linaelezea (jina la timu: Spyder) kushiriki katika kazi ya kushirikiana kwenye Utafiti wa Makubaliano ulioandaliwa na TRAC-2, Warsha ya pili kuhusu Uvunjifu, Matukio na Mtandao. Waandaaji walitoa taarifa kwa lugha tatu - Kiingereza, Kihindi na Bengali. Kazi hiyo ilikuwa ni kuwadhibiti kila aina ya jaribio hilo linatengeneza katika makundi matatu - 'Kwa ujumla Aggressive' (OAG), 'Maandamano makubwa' (CAG) na 'Sio Aggressive' (NAG). Katika karatasi hii, tunapendekeza mifano mitatu tofauti kwa kutumia Tf-Idf, unyanyasaji wa hisia na kujifunza mashine yenye msingi. Tumepata vipindi vya f1 kwa asilimia 43.10, 59.45% na 44.84 kwa ajili ya Kiingereza, Hindi na Bengali.", 'ko': "지난 몇 년 동안 페이스북, 트위터 등 모든 소셜미디어 플랫폼에 원한 발언과 공격적인 댓글이 덮여 있어 원한이 증가하고 있다.본고는 우리(팀명: Spyder)가TRAC-2조직의 공격검측공유임무에 참여하고 제2기 제어, 공격과 인터넷 괴롭힘에 관한 세미나를 묘사한다.조직자는 영어, 인디언, 방글라데시어 세 가지 언어의 데이터 집합을 제공했다.임무는 테스트 집합의 각 실례를'공개공격'(OAG),'은폐공격'(CAG),'비공격'(NAG) 세 종류로 나누는 것이다.본고에서 우리는 Tf-Idf, 감정의 극성과 기계 학습을 바탕으로 하는 분류기를 이용하여 세 가지 다른 모델을 제시했다.우리의 f1영어, 인디언, 방글라데시어 성적은 각각 43.10%, 59.45%와 44.84% 였다.", 'tr': "Soňky ýylda ýigrenýän çykyş we agresýji terjimeler diňe facebook, twitter we şeýle ýaly sosyal medialaryň platformlaryny üýtgedýär. netijeli ýigrenýän bolsa. Bu kagyz biziň (topar adymyzy: Spyder) TRAC-2, Ilkinji Trollin, Aggresiýa we Cyberbulliýa tarapyndan çykyşymyzyň (topar ady: Spyder) bölegimizi barlaýar. Gurganlar üç dilde maglumat setirini – Iňlisçe, Hindi we Bengali ýa dilde temin etdiler. Bu hat üç kategoriýa içine synanyşan her sahypany bejerilmek üçin. - 'Üzgün Aggresiýan' (OAG), 'Covertly Aggressive' (CAG) we 'Non-Aggressive' (NAG). Bu kagyzda Tf-Idf, duýgular polaritet we maşynyň öwrenmegi tabanly klassiflerden üç dürli nusgalary teklip edýäris. Biz f1 sany 43,10%, 59,45% we 44,84% iňlisçe, Hindiler we Bengaliler üçin aldyk.", 'am': "ባለፉት ጥቂት ዓመታት፣ ጥላቻን ንግግር እና ተቃውሞ አካባቢ ማኅበራዊ ሚዲያ ጦማሪያዎች እንደ ፊትቡክ፣ twitter እና ድምፅ ይጨምራሉ፡፡ This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  አጋራጆች በሦስት ቋንቋ - እንግሊዘኛ፣ ሄንዲ እና በንጋሊ ዳታተርቶችን ሰጥተዋል፡፡ ስራው ሁሉንም ምሳሌዎች በሦስት categories - 'አብዛኛውን Aggressive' (OAG), 'Covertly Aggressive' (CAG) እና 'nonAggressive' (NAG). በዚህ ካላት፣ Tf-Idf፣ የስሜት ፖርቲካ እና የመኪና ትምህርት መተማር የተለየ ሦስት የተለየ ዓይነቶች እና መደበቂያ እናደርጋለን፡፡ በእንግሊዝኛ፣ Hindi እና በጋንጋል ላይ የፊዲ ቁጥር 43.10 በመቶ፥ 59.45 በመቶ እና 44.84 በመቶ አግኝተናል።", 'af': "In die laaste paar jaar het haat spraak en aggressiewe kommentaar amper al die sosiale media platforme soos facebook, twitter ensfh. As 'n resultaat haat vergroei word. Hierdie papier beskrywe ons (Team name: Spyder) deelnadering in die Gedeelde Opdrag oor Aggresiedeteksie organiseer deur TRAC-2, tweede Werkshop op Trolling, Aggresie en Cyberbullying. Die Organiseerders het datastelle in drie tale verskaf - Engels, Hindi en Bengali. Die taak was om elke voorbeeld van die toets stel in drie kategorie te klassifiseer - 'Oorskynlik Aggressief' (OAG), 'Omdek Aggressive' (CAG) en 'Non- Aggressive' (NAG). In hierdie papier voorstel ons drie verskillende modele met gebruik van Tf-Idf, sentiment polariteit en masjien leer gebaseerde klassifiseerders. Ons het f1 telling van 43,10%, 59,45% en 44,84% respectively vir Engels, Hindi en Bengali ontvang.", 'sq': "Në vitet e fundit, fjalimi i urrejtjes dhe komentet agresive kanë mbuluar pothuajse të gjitha platformet e medias sociale si facebook, twitter etj. Si rezultat i urrejtjes po rritet. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  Organizuesit ofruan të dhëna në tre gjuhë - anglisht, hindisht dhe bengalisht. Detyra ishte të klasifikohej çdo rast i grupeve të testit në tre kategori - 'Shumë Aggresive' (OAG), 'Covertely Aggressive' (CAG) dhe 'Non-Aggressive' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers.  We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.", 'hy': 'Վերջին մի քանի տարիների ընթացքում ատելության խոսքը և ագրեսիվ մեկնաբանությունները ծածկել են գրեթե բոլոր սոցիալական լրատվամիջոցների պլատֆորմերը, ինչպիսիք են Ֆեյսբուքը, թվիթերը և այլն, ինչի արդյունքում ատելություն Այս հոդվածը նկարագրում է մեր (Թիմի անունը՝ Սպիդեր) մասնակցությունը Ագրեսիայի հայտնագործման ընդհանուր խնդրի մեջ, որը կազմակերպել է ԹրաԿ-2, Թրոլինգի, Ագրեսիայի և Կիբերբուլիգի երկրորդ աշխատասենյակում: The Organizers provided datasets in three languages - English, Hindi and Bengali.  Հարտադրությունն էր դասակարգել փորձարկումների յուրաքանչյուր օրինակ երեք կատեգորիաների՝ չափազանց ագրեսիվ, թաքնված ագրեսիվ և ոչ ագրեսիվ: Այս թղթի մեջ մենք առաջարկում ենք երեք տարբեր մոդել, որոնք օգտագործում են Tf-IDf-ը, զգացմունքների մոտավորությունը և մեքենային ուսումնասիրության հիմնված դասակարգերը: Մենք ստացանք 43.10 տոկոսը, 59.45 տոկոսը և 44.84 տոկոսը անգլերենի, հինդի և բենգալիի համար:', 'bn': "গত কয়েক বছরে ঘৃণা ভাষণ এবং অত্যাচারী মন্তব্য প্রায় সকল সামাজিক প্রচার মাধ্যমের প্লাটফর্ম ফেসবুক, টুইটার ইত্যাদি প্রকাশ করেছে, যার ফলে  এই পত্রিকাটি আমাদের (দলের নাম: স্পাইডার) অংশগ্রহণের অংশগ্রহণ করেছে ট্রাক্লিং এবং সাইবার্বালিং এর দ্বিতীয় ওয়ার্কশপের আয়োজন করেছে। সংগঠনগুলো তিনটি ভাষায় তথ্য সংগ্রহ করেছে- ইংরেজি, হিন্দি এবং বাংলায়। The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  এই কাগজটিতে আমরা টিএফ-আইডফ, আবেগের দূর্নীতি এবং মেশিন ভিত্তিক শিক্ষা ব্যবহার করে তিনটি ভিন্ন মডেল প্রস্তাব করি। আমরা ইংরেজি, হিন্দি এবং বাংলার জন্য ৪৪.", 'ca': "En els últims anys, el discurs d'odi i els comentaris agressius han cobert gairebé totes les plataformes dels mitjans socials com Facebook, Twitter, etc. Com a resultat, l'odi està creixent. Aquest article descriu la nostra participació (Nom de l'equip: Spyder) en la Task Shared on Aggression Detection organitzada per TRAC-2, Segona Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages - English, Hindi and Bengali.  The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  En aquest paper, proposem tres models diferents utilitzant Tf-Idf, polaritat sentimental i classificadors basats en l'aprenentatge màquina. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.", 'az': "Son bir neçə il içində nifrət sözləri və agresif şəhadətlər facebook, twitter və ya da bənzər sosyal media platformlarını bürüdülər. Sonuçta nifrət artırır. Bu kağıt TRAC-2, Trolling, Aggresyon və Cyberbullying ilə organizasyon edilmiş Aggresyon Detection işimizin paylaşılmış işimizi təsdiqləyir. Organizerlər üç dildə verilən qurğular – İngilizce, Hindi və Bengali. Gözəl hər bir sınama quruluğunu üç kategoriya ilə dəyişdirmək idi: 'Çox Agressive' (OAG), 'Cover Aggressive' (CAG) və 'Non-Aggressive' (NAG). Bu kağızda Tf-Idf, sentiment polaritāti və maşın öyrənməsi tabanlı klasifikatçıları ilə üç fərqli modeli təklif edirik. Biz f1 nöqtəsini 43,10%, 59,45% və 44,84% İngilizce, Hindi və Bengali üçün aldıq.", 'cs': 'V posledních několika letech se nenávistná řeč a agresivní komentáře pokryly téměř všechny platformy sociálních médií jako Facebook, Twitter atd. V důsledku toho se nenávist zvyšuje. Tento článek popisuje naši (název týmu: Spyder) účast na Sdíleném úkolu detekce agrese organizovaném TRAC-2, Druhém workshopu o trollingu, agresi a kyberšikaně. Organizátoři poskytli datové sady ve třech jazycích: angličtině, hindštině a bengálštině. Úkolem bylo rozdělit každou instanci testovacích sad do tří kategorií: příliš agresivní (OAG), utajené agresivní (CAG) a neagresivní (NAG). V tomto článku navrhujeme tři různé modely používající Tf-Idf, polaritu sentimentu a klasifikátory založené na strojovém učení. Získali jsme f1 skóre 43,10%, 59,45% a 44,84% pro angličtinu, hindštinu a bengálštinu.', 'bs': "U posljednjih nekoliko godina, govor mržnje i agresivni komentari su pokrili skoro sve platforme socijalnih medija poput facebook, twitter itd. Ovaj papir opisuje naše (Tim name: Spyder) sudjelovanje u zajedničkom zadatku o detekciji agresije organiziranom TRAC-2, Drugom radionicom o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio klasifikacija svakog instanca testova u tri kategorije - pretjerano agresivno (OAG), 'Prikriveno agresivno' (CAG) i 'ne-agresivno' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost sentimenta i klasifikatore na osnovu učenja strojeva. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.", 'et': 'Viimastel aastatel on vihakõne ja agressiivsed kommentaarid hõlmanud peaaegu kõiki sotsiaalmeedia platvorme nagu facebook, twitter jne, mille tulemusena vihkamine kasvab. Käesolevas dokumendis kirjeldatakse meie (meeskonna nimi: Spyder) osalemist TRAC-2 poolt korraldatud agressiooni tuvastamise jagatud ülesandes, mis käsitleb trollingut, agressiooni ja küberkiusamist. Korraldajad esitasid andmekogumeid kolmes keeles - inglise, hindi ja bengali keeles. Ülesanne oli klassifitseerida iga katsekogumi eksemplar kolme kategooriasse - "ülemääraselt agressiivne" (OAG), "varjatult agressiivne" (CAG) ja "mitteagressiivne" (NAG). Käesolevas töös pakume välja kolm erinevat mudelit, mis kasutavad Tf-Idf, sentimentaalse polaarsuse ja masinõppe alusel põhinevaid klassifitseerijaid. Inglise, hindi ja bengali puhul saime f1 skoori 43,10%, 59,45% ja 44,84%.', 'fi': 'Viime vuosina vihapuhe ja aggressiiviset kommentit ovat kattaneet lähes kaikki sosiaalisen median alustat, kuten Facebook, Twitter jne. Tämän seurauksena viha kasvaa. Tässä artikkelissa kuvataan (Team name: Spyder) osallistumistamme TRAC-2:n järjestämään aggression havaitsemista koskevaan yhteiseen tehtävään, joka on toinen Trolling-, Aggression- ja Cyberbullying-työpaja. Järjestäjät toimittivat aineistoja kolmella kielellä - englanti, hindi ja bengali. Tehtävänä oli luokitella testisarjat kolmeen luokkaan: "Yliaggressiivinen" (OAG), "Salaaggressiivinen" (CAG) ja "Ei aggressiivinen" (NAG). Tässä työssä ehdotamme kolmea eri mallia käyttäen Tf-Idf-, sentiment polarity- ja koneoppimispohjaisia luokittelijoita. Englannin, hindin ja bengalin f1-pisteet olivat 43,10%, 59,45% ja 44,84%.', 'id': "In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing.  This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  The Organizers provided datasets in three languages - English, Hindi and Bengali.  The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  Dalam kertas ini, kami mengusulkan tiga model yang berbeda menggunakan Tf-Idf, polaritas sentimen dan klasifikasi berbasis pembelajaran mesin. Kami mendapat skor f1 43,10%, 59,45% dan 44,84% respectively untuk Inggris, Hindi dan Bengali.", 'ha': 'Daga ƙidãyayyuta kaɗan, hoton ƙiyayya da mawaƙi sun rufe kowace platforms na mitanda na jamii kamar facebook, Twitter etc. Saboda haka, ƙiyayya ta ƙara. Wannan karatun yana bayyana mana (Team name: SPAYer) shirin ya zama a cikin aikin Shared on Aggression Dictionary organized by TRac-2, Shirin Sauq na Tõrlling, Aggression and cyberbullbullbullbullbullbulling. Shirin Ayuka na bãyar da data set cikin harshe uku - Ingiriya, Hindcha da Bangali. Kayan aikin ya zama mai rarraba ko wani halin na jarraba ta cikin nau\'i uku - \'Totally Aggressive\' (OAG), "Deptly Aggressive\' (CAG) da \'Non-Aggressive\' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers.  Mun sãmi f1 score na 43.10%, 59.45% da 44.84% na Ingiriya, Hinddi da Bangali.', 'sk': 'V zadnjih nekaj letih so sovražni govor in agresivni komentarji pokrivali skoraj vse platforme socialnih medijev, kot so facebook, twitter itd., zaradi česar sovraštvo narašča. Ta prispevek opisuje naše sodelovanje (ime ekipe: Spyder) v skupni nalogi za odkrivanje agresije, ki jo organizira TRAC-2, Druga delavnica o trollingu, agresiji in kibernetskem ustrahovanju. Organizatorji so zagotovili nabore podatkov v treh jezikih - angleščini, hindijščini in bengalščini. Naloga je bila razvrstiti vsak primer preskusnih nizov v tri kategorije - "preveč agresivni" (OAG), "skriti agresivni" (CAG) in "neagressivni" (NAG). V prispevku predlagamo tri različne modele, ki uporabljajo klasifikatorje Tf-Idf, sentimentalno polarnost in strojno učenje. Za angleščino, hindijščino in bengalščino smo dobili oceno f1 43,10%, 59,45% oziroma 44,84%.', 'jv': 'Nang acara sing ditambah dumadhi, cah-cah dumadhi lan komentar sing gak bener tentang karo hal-hal sing mengko kuwi padha kaé sistem media soti kowé karo netwisu, tuwitir, njl. sebelah kuwi mau kudu dunyane kuwi mau. Perintah iki dadi ono nggawe (Group name: spyrer) sumusunoi tanggal nggawe Tarjamahan kelas nggawe barang nggawe barang TROC-2, Second Workspace nang Trill, agegress lan Ciberbullying. Organiser politenessoffpolite"), and when there is a change ("assertivepoliteness Nang paper iki, kéné supoyo model sing sampeyan telu model sing gambar tf-Idf, polarity seneng karo sistem sing basa sak kelas. Awak dhéwé luwih tangané f1 puntuan sing katênêr, denganêr, limang-limang kanggo kalah-aman kanggo inggiles, barang-arang karo Bengal.', 'bo': "འདས་བའི་ལོ་ངོ་ཤས་ཀྱི་རིང་ལ་་་ ཕྱིར་ཉེན་དགའ་ཕྱོགས་དང་བསྡུར་བའི་མཆན་བཤད་ཀྱི་གྲོས་ཁྱེར་གྱི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ནང་དུ་ ཤོག་བྱང་འདིས་ང་ཚོའི་མཉམ་དུ་སྤྱི་ཚོགས་ཀྱི་མིང་། སྒྲིག་འཛུགས་པ་ཚོས་སྐད་རིགས་གསུམ་ནང་གི་གནད་སྡུད་གཞི་སྒྲིག་ཚོགས་གཅིག་གི་ནང་བྱིན་ཡོད། The task was to classify each instance of the test sets in three categories - 'Overly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་སྔོན་པ་ལ་མ་དབྱེ་བ་གསུམ་རྣམས་སྤྱོད་ཀྱི་ཐབས་ལམ་མ་འདུག Tf-Idf་དང་། སེམས་ཚོར ངེད་ཚོ་སྤྱི་ཚོགས་ཀྱི་ཨང་ཀི43.10%, 59.45% དང་། སྤྱི་ཚོགས་ཀྱི་ཨང་ཀིས་ཡིག་ཆ་གཅིག་ཙམ་གྱི་འབོར་ཡོད།", 'he': 'בשנים האחרונות, נאום שנאה והתגובות אגרסיביות כיסו כמעט את כל המתקנות של התקשורת החברתית כמו פייסבוק, טוויטר וכו"כ. כתוצאה מכך שנאה גדלה. העיתון הזה מתאר את השתתפות שלנו (שם צוות: ספיידר) במשימה המשותפת על גילוי התקפה מאורגנת על ידי TRAC-2, Workshop שני על טרולינג, התקפה וקייברבולינג. המארגנים סיפקו קבוצות נתונים בשלושה שפות - אנגלית, הינדית ובנגלית. The task was to classify each instance of the test sets into three categories - \'Overtly Aggressive\' (OAG), \'Covertly Aggressive\' (CAG) and \'Non-Aggressive\' (NAG).  בעיתון הזה, אנו מציעים שלושה דוגמנים שונים בשימוש ב-Tf-Idf, קוטביות רגשות ולמדות מכונות מסודרים. השגנו נקודת f1 של 43.10%, 59.45% ו-44.84% בהתאם לאנגלית, הינדית ובנגלית.'}
{'en': 'BERT of all trades, master of some BERT  of all trades, master of some', 'ar': 'بيرت من بين جميع المهن ، سيد البعض', 'fr': 'BERT de tous les métiers, maître de certains', 'es': 'BERT de todos los oficios, maestro de algunos', 'pt': 'BERT de todos os ofícios, mestre de alguns', 'ja': 'すべての取引のバート、いくつかのマスター', 'zh': 'µēĆµ£ēĶĪīõĖÜBERT,Ķ»ĖÕĖł', 'hi': 'सभी ट्रेडों के BERT, कुछ के मास्टर', 'ru': 'БЕРТ всех профессий, мастер некоторых', 'ga': 'BERT de gach ceird, máistir roinnt', 'ka': 'ბვპრ ჲრ გჟთფკთ რპადჲგთ, დჲჟოჲეაპ ნა ნწკჲთ.', 'hu': 'BERT minden szakmában, néhány mester', 'it': 'BERT di tutti i mestieri, maestro di alcuni', 'el': 'BERT όλων των επαγγελμάτων, κύριος κάποιων', 'mk': 'BERT на сите трговија, господар на некои', 'ms': 'BERT semua perdagangan, tuan beberapa', 'kk': 'Бүкіл салымдардың BERT-і, кейбір салымдардың мастері', 'mt': 'BERT tal-kummerċ kollu, kaptan ta’ xi wħud', 'ml': 'എല്ലാ ട്രേഡികളുടെയും ബെര്\u200dട്ട്, ചിലരുടെ മാസ്റ്റര്\u200d', 'lt': 'Visų prekių BERT, kai kurių prekių kapitonas', 'ro': 'BERT de toate meseriile, maestru de unele', 'sr': 'BERT od svih trgovina, gospodar nekih', 'mn': 'Бүх худалдааны БЕРТ, зарим нь', 'no': 'BERT av alle handelsar, heiter av noen', 'pl': 'BERT wszystkich zawodów, mistrz niektórych', 'sv': 'BERT av alla yrken, mästare på vissa', 'ur': 'تمام تجارت کے BERT، بعض کے مالک', 'so': 'BERT dhamaan ganacsiga, madaxa qaar', 'si': 'සියළුම ව්\u200dයාපාරයක්, සමහර දෙයක්', 'ta': 'அனைத்து வியாபாரத்தின் பெர்ட், சில முதலாளி', 'uz': 'BERT of all trades, master of some', 'vi': 'Tất cả các giao dịch, bậc thầy.', 'bg': 'BERT на всички занаяти, господар на някои', 'da': 'BERT af alle fag, mester af nogle', 'hr': 'BERT svih trgovina, gospodar nekih', 'nl': 'BERT van alle beroepen, meester van sommige', 'de': 'BERT aller Gewerke, Meister einiger', 'ko': '버트는 각 분야에 정통하고, 좀 정통하다', 'id': 'BERT dari semua perdagangan, master dari beberapa', 'fa': 'BERT از همه تجارت، ارباب بعضی', 'sw': 'BERT ya biashara zote, mkuu wa baadhi', 'tr': 'Bütin işleri, käbirleriniň maksady', 'af': 'BERT van alle handelinge, meester van sommige', 'sq': 'BERT e të gjitha tregtisë, mjeshtër e disa', 'am': 'የሁሉም ንግድ', 'hy': 'ԲԵՌԹ բոլոր առևտրի, որոշ', 'az': 'B칲t칲n ticar톛tl톛rin BERT, b톛zil톛rin sahibi', 'bn': 'সব ব্যবসা, কিছু মাস্টার', 'cs': 'BERT ze všech oborů, mistr některých', 'bs': 'BERT svih trgovina, gospodar nekih', 'ca': "BERT de tots els negocis, mestre d'alguns", 'et': 'BERT kõigis valdkondades, meister mõned', 'fi': 'BERT kaikkien alojen, mestari joidenkin', 'jv': 'BERT Panjenengan wong komeh-wong, paling-wong liyane', 'ha': 'QUnicodeControlCharacterMenu', 'sk': 'BERT vseh poslov, gospodar nekaterih', 'bo': 'BERT ཡི་ཚོང་མཛོད་ཁང་ཡོད་ཚད་ལྡན་ཞིག་གི་བདག་པོ་ཞིག་རེད།', 'he': 'BERT של כל הסחרות, אדון של כמה'}
{'en': 'This paper describes our results for TRAC 2020 competition held together with the conference LREC 2020. Our team name was Ms8qQxMbnjJMgYcw. The competition consisted of 2 subtasks in 3 languages (Bengali, English and Hindi) where the participants’ task was to classify aggression in short texts from  social media  and decide whether it is gendered or not. We used a single BERT-based system with two outputs for all tasks simultaneously. Our  model  placed first in  English  and second in Bengali gendered text classification competition tasks with 0.87 and 0.93 in F1-score respectively.', 'ar': 'تصف هذه الورقة نتائج مسابقة TRAC 2020 التي عقدت جنبًا إلى جنب مع مؤتمر LREC 2020. كان اسم فريقنا Ms8qQxMbnjJMgYcw. تكونت المسابقة من مهمتين فرعيتين بثلاث لغات (البنغالية والإنجليزية والهندية) حيث كانت مهمة المشاركين تصنيف العدوان في نصوص قصيرة من وسائل التواصل الاجتماعي وتحديد ما إذا كان جنسانيًا أم لا. استخدمنا نظامًا واحدًا قائمًا على BERT بمخرجين لجميع المهام في وقت واحد. احتل نموذجنا المرتبة الأولى في اللغة الإنجليزية والثاني في مهام مسابقة تصنيف النص حسب الجنس البنغالية مع 0.87 و 0.93 في درجة F1 على التوالي.', 'es': 'Este documento describe nuestros resultados para la competencia TRAC 2020 celebrada junto con la conferencia LREC 2020. El nombre de nuestro equipo era Ms8qqxmbnjjmgycw. El concurso consistió en 2 subtareas en 3 idiomas (bengalí, inglés e hindi) donde la tarea de los participantes era clasificar la agresión en textos cortos de las redes sociales y decidir si era de género o no. Utilizamos un único sistema basado en BERT con dos salidas para todas las tareas simultáneamente. Nuestro modelo ocupó el primer lugar en inglés y el segundo en las tareas de competencia de clasificación de texto de género bengalí con 0.87 y 0.93 en puntaje F1 respectivamente.', 'pt': 'Este artigo descreve nossos resultados para a competição TRAC 2020 realizada em conjunto com a conferência LREC 2020. O nome da nossa equipe era Ms8qQxMbnjJMgYcw. A competição consistiu em 2 subtarefas em 3 idiomas (Bengali, Inglês e Hindi) onde a tarefa dos participantes era classificar a agressão em textos curtos das mídias sociais e decidir se é de gênero ou não. Usamos um único sistema baseado em BERT com duas saídas para todas as tarefas simultaneamente. Nosso modelo ficou em primeiro lugar em inglês e em segundo em tarefas de competição de classificação de texto de gênero bengali com 0,87 e 0,93 na pontuação F1, respectivamente.', 'fr': "Cet article décrit nos résultats pour le concours TRAC 2020 organisé en marge de la conférence LREC 2020. Le nom de notre équipe était MS8QQxMbnJJMGYCW. Le concours comportait 2 sous-tâches en 3 langues (bengali, anglais et hindi) où la tâche des participants était de classer l'agression dans de courts textes provenant des médias sociaux et de décider si elle est sexospécifique ou non. Nous avons utilisé un seul système basé sur BERT avec deux sorties pour toutes les tâches simultanément. Notre modèle s'est classé premier dans les tâches de concours de classification de texte sexospécifique en anglais et deuxième en bengali avec respectivement 0,87 et 0,93 dans le score F1.", 'ja': '本稿では、LREC 2020会議とともに開催されたTRAC 2020コンペティションの結果について説明します。チーム名はMs 8 qQxMbnjJMgYcw。コンペティションは、3つの言語（ベンガル語、英語、ヒンディー語）の2つのサブタスクで構成されており、参加者の課題は、ソーシャルメディアからの短いテキストで攻撃性を分類し、それが性別化されているかどうかを決定することでした。すべてのタスクに2つの出力を持つ単一のBERTベースのシステムを同時に使用しました。私たちのモデルは、英語で1位、ベンガル語で2位のジェンダーテキスト分類のコンテストタスクで、F 1スコアではそれぞれ0.87と0.93でした。', 'hi': 'यह पेपर TRAC 2020 प्रतियोगिता के लिए हमारे परिणामों का वर्णन करता है जो सम्मेलन LREC 2020 के साथ एक साथ आयोजित किया गया था। हमारी टीम का नाम Ms8qQxMbnjJMgYcw था। प्रतियोगिता में 3 भाषाओं (बंगाली, अंग्रेजी और हिंदी) में 2 उप-कार्य शामिल थे, जहां प्रतिभागियों का कार्य सोशल मीडिया से छोटे ग्रंथों में आक्रामकता को वर्गीकृत करना था और यह तय करना था कि यह लिंग है या नहीं। हमने एक साथ सभी कार्यों के लिए दो आउटपुट के साथ एक एकल BERT-आधारित प्रणाली का उपयोग किया। हमारे मॉडल को अंग्रेजी में पहले और बंगाली लिंग वाले पाठ वर्गीकरण प्रतियोगिता कार्यों में क्रमशः F1-स्कोर में 0.87 और 0.93 के साथ रखा गया है।', 'zh': '本文引与LREC 2020会议TRAC 2020竞。 吾团队名Ms8qQxMbnjJMgYcw。 3种言(孟加拉语,英语印地语)之2成,参与者者,社交媒体短文本之攻击行为类也。 吾以单BERT之统,兼给二输。 英语中第一,孟加拉语中第一,F1得分中为0.870.93。', 'ru': 'В данной статье описываются результаты нашего конкурса по программе TRAC 2020, проведенного совместно с конференцией LREC 2020. Наша команда называлась Ms8qQxMbnjJMgYcw. Конкурс состоял из 2 подзадач на 3-х языках (бенгальском, английском и хинди), где задача участников состояла в том, чтобы классифицировать агрессию в коротких текстах из социальных сетей и решить, является ли она гендерной или нет. Мы использовали единую систему на основе BERT с двумя выходами для всех задач одновременно. Наша модель заняла первое место на английском языке и второе на бенгальском языке в конкурсе гендерной классификации текстов с 0,87 и 0,93 баллами F1 соответственно.', 'ga': "Déanann an páipéar seo cur síos ar ár dtorthaí do chomórtas TRAC 2020 a reáchtáladh in éineacht leis an gcomhdháil LREC 2020. Ba é ainm ár bhfoireann Ms8qQxMbnjJMgYcw. Bhí an comórtas comhdhéanta de 2 fhothasc i 3 theanga (Beangáilis, Béarla agus Hiondúis) áit a raibh sé de chúram ar na rannpháirtithe ionsaitheacht i mbeagán focal a rangú ó na meáin shóisialta agus cinneadh a dhéanamh an bhfuil sé inscne nó nach bhfuil. D'úsáideamar córas amháin bunaithe ar BERT le dhá aschur do gach tasc ag an am céanna. Chuir ár múnla an chéad áit i mBéarla agus sa dara háit i dtascanna comórtais rangaithe téacs inscne Beangáilis le 0.87 agus 0.93 sa scór F1 faoi seach.", 'ka': 'ეს დოკუნფიგურაცია ჩვენი შედეგი TRAC 2020 კონფიგურაციისთვის შემდეგ გააჩვენება. ჩვენი სახელი იყო Ms8qQxMbnjJMgYcw. კონკრენტები სამი ენაში (ბენდალიური, ანგლიური და ჰინდიური) იყო, სადაც მოთავსდებელების დავალება იყო, რომ სოციალური მედიაზე კლასიფიკაცია აგრესის კლასიფიკაცია და განსაზღვრება თუ არა. ჩვენ ვიყენებთ ერთი BERT-დაბათი სისტემა, რომელიც ორი გამოყენება ყველა დავალებისთვის. ჩვენი მოდელი პირველად ანგლისში და მეორე ბენდალიში გენგლისური ტექსტის კლასიფიკაციის კონტექსტიკური კონტექსტიკური კონტექსტიკური კონტექსტიკური დამუშავებული', 'el': 'Η παρούσα εργασία περιγράφει τα αποτελέσματά μας για τον διαγωνισμό που πραγματοποιήθηκε από κοινού με το συνέδριο LREC 2020. Το όνομα της ομάδας μας ήταν Ms8qQxMbnjJGYcw. Ο διαγωνισμός αποτελούνταν από δύο δευτερεύουσες εργασίες σε τρεις γλώσσες (Βεγγαλικά, Αγγλικά και Χίντι) όπου το καθήκον των συμμετεχόντων ήταν να ταξινομήσουν την επιθετικότητα σε σύντομα κείμενα από τα μέσα κοινωνικής δικτύωσης και να αποφασίσουν αν είναι φυλετική ή όχι. Χρησιμοποιήσαμε ένα ενιαίο σύστημα με δύο εξόδους για όλες τις εργασίες ταυτόχρονα. Το μοντέλο μας τοποθετήθηκε πρώτη στα αγγλικά και δεύτερη στις εργασίες του διαγωνισμού ταξινόμησης κειμένου με φύλο στη Βεγγάλη με 0.87 και 0.93 αντίστοιχα στο σκορ F1.', 'hu': 'Ez a tanulmány bemutatja az LREC 2020 konferenciával együtt megrendezett TRAC 2020 verseny eredményeit. Csapatunk neve Ms8qQxmbnjJMgYcw volt. A verseny 2 részfeladatból állt 3 nyelven (bengáli, angol és hindi), ahol a résztvevők feladata az agresszió rövid szövegekbe sorolása volt a közösségi médiából és eldöntése, hogy nemi-e vagy sem. Egyetlen BERT alapú rendszert használtunk két kimenettel minden feladathoz egyidejűleg. Modellünk az első helyezett angol nyelven, a második helyezett a bengáli nemi szövegosztályozási versenyen 0,87, illetve 0,93 F1 pontszámmal.', 'lt': 'Šiame dokumente apibūdinami mūsų TRAC 2020 konkurso rezultatai, surengti kartu su konferencija LREC 2020. Mūsų komanda buvo Ms8qQxMbnjJMgYcw. Konkursą sudarė du paklausimai trijose kalbose (bengalų, anglų ir hindų), kuriose dalyvių užduotis buvo klasifikuoti agresiją į trumpas social in ės žiniasklaidos tekstus ir nuspręsti, ar tai lytis ar ne. We used a single BERT-based system with two outputs for all tasks simultaneously.  Mūsų modelis buvo pirmasis anglų kalba ir antrasis bengalų lyčių teksto klasifikavimo konkurso užduotis, atitinkamai 0,87 ir 0,93 F1 balais.', 'it': "Questo articolo descrive i risultati del concorso TRAC 2020 organizzato insieme alla conferenza LREC 2020. Il nome del nostro team era Ms8qQxmbnjJMgYcw. Il concorso consisteva in 2 sottocompiti in 3 lingue (bengalese, inglese e hindi) in cui il compito dei partecipanti era quello di classificare l'aggressività in brevi testi dai social media e decidere se fosse di genere o meno. Abbiamo utilizzato un unico sistema basato su BERT con due uscite per tutte le attività contemporaneamente. Il nostro modello si è piazzato al primo posto in inglese e al secondo posto nelle gare di classificazione del testo di genere bengalese con 0,87 e 0,93 rispettivamente in F1.", 'mk': "Овој документ ги опишува нашите резултати за натпреварот TRAC 2020 одржан заедно со конференцијата LREC 2020. Нашиот тим се викаше Ms8qQxMbnjJMgYcw. The competition consisted of 2 subtasks in 3 languages (Bengali, English and Hindi) where the participants' task was to classify aggression in short texts from social media and decide whether it is gendered or not.  Користевме еден систем базиран на BERT со два излези за сите задачи истовремено. Нашиот модел беше ставен прв на англиски и втор на бенгалиски текстови класификации со конкурентни задачи со 0,87 и 0,93 во F1 оценка.", 'kk': 'Бұл қағаз TRAC 2020 конференциясының LREC 2020 конференциясының нәтижесімізді анықтайды. Біздің тобыздың аты Ms8qQxMbnjJMgYcw. Қатысушылардың тапсырмасы қысқа мәтіндерінде агрессияны бағыттау және әлеуметтік медиақтардың бөлігін шешу үшін, 3 тілде (бенгали, ағылшын және хинди) 2 суреттер болды. Біз барлық тапсырмалар үшін бір BERT негіздеген жүйені қолдандық. Біздің үлгіміз біріншіден ағылшын және екіншіден бенгалияның жалпы мәтін классификациялау тапсырмаларына 0,87 және 0,93 жылдамдығын F1 жылдамдығында орнатылды.', 'ml': 'ഈ പത്രത്തില്\u200d TRAC 2020 പ്രതിരോധികള്\u200dക്ക് നമ്മുടെ ഫലങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. LREC 2020 കോണ്\u200dഫറന്\u200dസിനോടൊപ് ഞങ്ങളുടെ ടീം പേര് മിസ്8qQxMbnjJMgYcw ആയിരുന്നു. പങ്കാളികളുടെ ജോലിയില്\u200d നിന്നും സോഷ്യല്\u200d മെഡിയയില്\u200d നിന്നും ചെറിയ ലേഖനങ്ങളില്\u200d നിന്നും ആക്രമണത്തെ വിവിധേയമാക്കുവാന്\u200d തീരുമാനിക്കുന്നത് മൂ ഞങ്ങള്\u200d ഒരു ബെര്\u200dട്ടി അടിസ്ഥാനമായ ഒരു സിസ്റ്റം ഉപയോഗിച്ചിരുന്നു. രണ്ട് പുറത്തുണ്ടായി ഞങ്ങളുടെ മോഡല്\u200d ആദ്യം ഇംഗ്ലീഷിലും രണ്ടാമത്തേയും ബാങ്കാലിയില്\u200d മാതൃകതയുള്ള ടെക്സ്റ്റ് ക്ലാസ്ഫിക്കല്\u200d പ്രതിയോഗിക്കുന്ന', 'ms': 'Kertas ini menjelaskan keputusan kita untuk pertandingan TRAC 2020 yang dilakukan bersama-sama dengan persidangan LREC 2020. Nama pasukan kami adalah Ms8qQxMbnjJMgYcw. Pertandingan terdiri dari 2 sub-tanya dalam 3 bahasa (Bengali, Inggeris dan Hindi) di mana tugas peserta adalah untuk mengklasifikasi agresi dalam teks pendek dari media sosial dan memutuskan sama ada ia adalah jenis atau tidak. Kami menggunakan satu sistem berdasarkan BERT dengan dua output untuk semua tugas secara bersamaan. Model kami ditempatkan pertama dalam bahasa Inggeris dan kedua dalam tugas teks klasifikasi jenis Bengali dengan 0.87 dan 0.93 dalam skor F1 berdasarkan.', 'mt': 'Dan id-dokument jiddeskrivi r-riżultati tagħna għall-kompetizzjoni TRAC 2020 li saret flimkien mal-konferenza LREC 2020. Isem it-tim tagħna kien Ms8qQxMbnjJMgYcw. Il-kompetizzjoni kienet tikkonsisti f’żewġ sottomistoqsijiet fi tliet lingwi (il-Bengali, l-Ingliż u l-Indjan) fejn il-kompitu tal-parteċipanti kien li jikklassifikaw l-aggressjoni f’testi qosra mill-midja soċjali u jiddeċiedu jekk huwiex sesswali jew le. Użajna sistema waħda bbażata fuq BERT b’żewġ outputs għall-kompiti kollha fl-istess ħin. Il-mudell tagħna tqiegħed l-ewwel fl-Ingliż u t-tieni fil-Bengali kompiti ta’ klassifikazzjoni tat-test tal-klassifikazzjoni tat-test b’0.87 u 0.93 fil-punteġġ F1 rispettivament.', 'ro': 'Această lucrare descrie rezultatele concursului TRAC 2020 organizat împreună cu conferința LREC 2020. Numele echipei noastre a fost Ms8qQxmbnjJMgYcw. Concursul a constat în 2 subactivități în 3 limbi (bengală, engleză și hindi) unde sarcina participanților a fost de a clasifica agresiunea în texte scurte de pe rețelele de socializare și de a decide dacă este gender sau nu. Am folosit un singur sistem bazat pe BERT cu două ieșiri pentru toate sarcinile simultan. Modelul nostru s-a plasat pe primul loc în limba engleză și pe al doilea loc în competițiile de clasificare a textelor de gen bengaleze cu 0,87 și respectiv 0,93 în punctajul F1.', 'mn': 'Энэ цаас бидний TRAC 2020 өрсөлдөөний үр дүнг LREC 2020-тэй хамтдаа байгуулсан. Манай багийн нэр нь Ms8qQxMbnjJMgYcw байсан. Энэ өрсөлдөөнд оролцогчдын ажил бол нийгмийн мэдээллээс богино хэсгүүдэд халдвар халдвар халдварыг хэлэхэд 3 хэл (Бенгали, Англи, Хинди) гэх мэт 2 сурагчид байлаа. Бид бүх ажил дээр хоёр үр дүнтэй нэг BERT-д суурилсан системийг ашигласан. Бидний загвар нь англи, хоёр дахь нь Бенгалид гендер хэлбэрийн өрсөлдөөнийг 0.87, 0.93-д F1-н хэлбэрт оруулсан.', 'no': 'Denne papiret beskriver resultatet våre for konkurransen TRAC 2020 som er held saman med konferansen LREC 2020. Gruppenamnet vårt var Ms8qQxMbnjJMgYcw. Konkursa inneheld 2 underspørsmål i 3 språk (Bengalisk, engelsk og hindisk) der deltakaranes oppgåve var å klassifisera aggressjon i korte tekstar frå sosiale medier og bestemme om det er generelt eller ikkje. Vi brukte ein enkel BERT-basert system med to utdata for alle oppgåver samtidig. Modellen vårt plassert først i engelsk og andre i Bengalisk seks-klassifikasjonsprogrammet med 0,87 og 0,93 i F1-poeng.', 'pl': 'Niniejszy artykuł opisuje nasze wyniki konkursu TRAC 2020 organizowanego wspólnie z konferencją LREC 2020. Nasz zespół nazywał się Ms8qQxMbnjJMGYCw. Konkurs składał się z dwóch podzadań w trzech językach (bengalski, angielski i hindi), w których zadaniem uczestników było klasyfikowanie agresji w krótkich tekstach z mediów społecznościowych i zdecydowanie, czy jest ona płciowa czy nie. Użyliśmy jednego systemu opartego na BERT z dwoma wyjściami do wszystkich zadań jednocześnie. Nasz model zajął się pierwszym miejscem w języku angielskim i drugim w zadaniach klasyfikacji tekstu bengalskiego z 0.87 i 0.93 w wynikach F1.', 'sr': 'Ovaj papir opisuje naše rezultate natjecanja TRAC 2020, održane zajedno sa konferencijom LREC 2020. Naše ime je bilo Ms8qQxMbnjJMgYcw. Konkurencija se sastojila od 2 podkaza na 3 jezika (Bengali, engleski i Hindi), gde je zadatak učesnika bio klasifikacija agresije u kratkim tekstima iz društvenih medija i odlučiti je li spol ili ne. Koristili smo jedini sistem na BERT-u sa dvije rezultate za sve zadatke istovremeno. Naš model je prvi stavio na engleski i drugo na Bengalski zadatak za konkurenciju klasifikacije teksta sa 0,87 i 0,93 u F1 rezultatu.', 'so': "Warqadan waxaa ku qoran resultiyadeena TRAC 2020 oo iskutallaabta la qabtay LREC 2020. Magaca kooxdayagu wuxuu ahaa Ms8qQxMbnjJMgYcw. The competition consisted of 2 subtasks in 3 languages (Bengali, English and Hindi) where the participants' task was to classify aggression in short texts from social media and decide whether it is gendered or not.  Isticmaalnay hal nidaam oo BERT ku saleysan, taas oo la mid ah labo dibadood ayaan u isticmaalnay shaqaalaha oo dhan. Tusaalkayagii wuxuu ugu horeeyey af Ingiriis iyo labaad oo ku qoray shaqooyin ku qoran qoraal-tababarida dadka galmada ah ee Bengali ku qoran ugu horeeya 0.87 iyo 0.93 kooxda F1.", 'sv': 'Denna uppsats beskriver våra resultat för TRAC 2020-tävlingen som hålls tillsammans med konferensen LREC 2020. Vårt teamnamn var Ms8qQxmbnjJMgYcw. Tävlingen bestod av 2 deluppgifter på 3 språk (bengali, engelska och hindi) där deltagarnas uppgift var att klassificera aggression i korta texter från sociala medier och avgöra om den är könsbunden eller inte. Vi använde ett enda BERT-baserat system med två utgångar för alla uppgifter samtidigt. Vår modell placerades först på engelska och tvåa i bengaliska könsklassificeringstävlingsuppgifter med 0,87 respektive 0,93 i F1-poäng.', 'ta': 'இந்த காகிதத்தில் TRAC 2020 போட்டியின் முடிவுகளை குறிப்பிடுகிறது LREC 2020 கூட்டத்துடன் சேர்ந்துள்ளது. எங்கள் அணி பெயர் மிஸ்8qQxMbnjJMgYcw. மூன்று மொழிகளில் (பெங்காலி, ஆங்கிலத்தில் மற்றும் ஹின்டியில்) இரண்டு துணை பணிகளில் இருந்தது. பங்காளிகளின் செயல் சிறிய உரைகளிலிருந்து குறைந்த ம நாங்கள் ஒரே BERT-அடிப்படையில் இரண்டு வெளியீடுகளை பயன்படுத்தினோம் அதே சமயமாக அனைத்து பணிகளுக்கும். எங்கள் மாதிரி முதலில் ஆங்கிலத்தில் மற்றும் இரண்டாவது பெங்காலியில் பெண்களில் இணங்குபட்ட உரை வகைப்பாட்டு போர்க்கும் பணிகளை மு', 'si': "මේ පැත්තේ අපේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් තියෙනවා TRAC 2020යි ප්\u200dරතිචාරයක් එක්ක සම්බන්ධ වෙලා තියෙ අපේ කණ්ඩායමේ නම Ms8qQxMbndJMgYq. The Competition comprised of 2 subtask in 3 language (Bengali, English and Hindi) where the particints' job is to classifie aggression in short texts from the local medias and choose if it is sex or not. අපි එකම BERT පද්ධතියක් භාවිතා කරලා හැම වැඩක්ම එකම වෙනුවෙන් ප්\u200dරතිකාර දෙකක් තියෙනවා. අපේ මොඩල් ඉංග්\u200dරීසියේ පළමු ඉංග්\u200dරීසියෙන් දෙවෙනි වර්ගයෙන් බෙන්ගාලී වලින් පරික්ෂණ පරික්ෂණ විශේෂණයේ ප", 'ur': 'یہ کاغذ ہے کہ TRAC 2020 رقابت کے لئے ہمارے نتیجے کی توصیف کرتا ہے کہ کائنفر LREC 2020 کے ساتھ ملے گئے۔ ہمارے ٹیم کا نام Ms8qQxMbnjJMgYcw تھا. مسابقه میں 3 زبانوں میں دو زیب سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ سٹ س ہم نے ایک BERT بنیادی سیسٹم کا استعمال کیا تھا جو سب کاموں کے لئے دو آئٹپوٹ کے ساتھ۔ ہمارا موڈل پہلے انگلیسی اور دوسرے میں بنگالی کی جنسی ٹیکسٹ کلاسیفوں کی مسابقات کے کاموں میں 0.87 اور 0.93 کو F1-score میں رکھا تھا۔', 'uz': "Бу саҳифа TRAC 2020 konferansa LREC 2020 bilan birlashtirilgan rivojlanuvchimizni anglatadi. Timizning ismi Ms8qQxMbnjJMgYcw edi. Мухолифатлар уч тил (Bengali, Ingliz ва Hindi) bilan ikkita sub-vazifalar (Bengali, Ingliz va Hindiston) ga ega bo'lgan vazifasi jamiyat media yordamchidan qisqa textlarni tarjima qilish va u jinsiyalarni ko'rsatishi mumkin. Biz bir bir BERT asosiy tizimdan bir xil vazifalar bilan ikkita natijalar bilan foydalanamiz. Bizning modelimiz birinchi ingliz va ikkinchi xil tilida Bengalcha jinsiya matn darajalashtirish vazifalarini boshqacha 0.87 va 0.93 bir xil F1 scorida qo'llangan.", 'vi': 'Tờ giấy này mô tả kết quả cuộc thi TRAC 2020 tổ chức cùng với hội nghị RMER 2020. Tên của chúng tôi là Ms8qQxmnggJMgYcw. Cuộc thi gồm có hai chữ phụ (Bengali, Anh và Hindi) trong đó nhiệm vụ của người tham gia là phân loại sự xâm lược theo cách viết ngắn từ các phương tiện xã hội và quyết định xem nó là giới tính hay không. Chúng tôi sử dụng một hệ thống duy nhất được dựa trên BERT với hai kết quả cho tất cả các công việc cùng lúc. Mẫu của chúng tôi được xếp hàng đầu bằng tiếng Anh và thứ hai ở Bengali đồi về các nhiệm vụ phân phối văn bản với hàng đầu 0.87 và 0.93, điểm số F1.', 'bg': 'В настоящата статия са описани резултатите от конкурса ТРАК 2020, проведен съвместно с конференцията ЛРЕС 2020. Името на екипа ни беше Ms8qQxMbnjJmgYcw. Състезанието се състояше от 2 подзадачи на 3 езика (бенгалски, английски и хинди), където задачата на участниците беше да класифицират агресията в кратки текстове от социалните медии и да решат дали е полова или не. Използвахме една система базирана на БРТ с два изхода за всички задачи едновременно. Нашият модел се класира на първо място в английския и второ място в бенгалските състезателни задачи по класиране на текста по полов език с 0,87 и 0,93 съответно във Формула 1.', 'da': 'Denne artikel beskriver vores resultater for TRAC 2020 konkurrence afholdt sammen med konferencen LREC 2020. Vores holdnavn var Ms8qQxmbnjJMgYcw. Konkurrencen bestod af 2 underopgaver på 3 sprog (bengali, engelsk og hindi), hvor deltagernes opgave var at klassificere aggression i korte tekster fra sociale medier og afgøre, om det er kønnet eller ej. Vi brugte et enkelt BERT-baseret system med to udgange til alle opgaver samtidigt. Vores model placerede først på engelsk og andenpladsen i bengaliske kønsbaserede tekstklassifikationsopgaver med henholdsvis 0,87 og 0,93 i F1-score.', 'nl': 'Deze paper beschrijft onze resultaten voor de TRAC 2020 competitie samen met de conferentie LREC 2020. Onze teamnaam was Ms8qQxMbnjJMGYCw. De wedstrijd bestond uit twee subtaken in drie talen (Bengaals, Engels en Hindi) waarbij de deelnemers de taak hadden om agressie te classificeren in korte teksten van sociale media en te beslissen of het gendergerelateerd is of niet. We gebruikten één BERT-gebaseerd systeem met twee uitgangen voor alle taken tegelijk. Ons model plaatste zich als eerste in het Engels en tweede in Bengaals geslachtsgestuurde tekstclassificatietaken met respectievelijk 0.87 en 0.93 in F1-score.', 'hr': 'Ovaj papir opisuje naše rezultate natjecanja TRAC 2020, održane zajedno s konferencijom LREC 2020. Naše ime je Ms8qQxMbnjJMgYcw. Takmičenje se sastojilo od 2 podkaza na 3 jezika (Bengalski, engleski i Hindi), gdje je zadatak učesnika bio klasifikirati agresiju u kratkom tekstu društvenih medija i odlučiti je li spol ili ne. Koristili smo jedan sistem na BERT-u s dvije rezultate za sve zadatke istovremeno. Naš model je prvi stavio na engleski i drugo na Bengalski zadatak za natjecanje klasifikacije teksta s 0,87 i 0,93 u rezultatu F1-a.', 'de': 'Dieser Beitrag beschreibt unsere Ergebnisse für den TRAC 2020 Wettbewerb zusammen mit der Konferenz LREC 2020. Unser Teamname war Ms8qQxMbnjJMGYCw. Der Wettbewerb bestand aus zwei Teilaufgaben in drei Sprachen (Bengali, Englisch und Hindi), bei denen die Teilnehmer Aggression in kurzen Texten aus sozialen Medien einordnen und entscheiden sollten, ob sie geschlechtsspezifisch ist oder nicht. Für alle Aufgaben nutzten wir ein einziges BERT-basiertes System mit zwei Ausgängen gleichzeitig. Unser Modell platzierte sich als Erster in Englisch und Zweiter in bengalischen Textklassifizierungsaufgaben mit 0.87 bzw. 0.93 in F1-Punktzahl.', 'id': 'Kertas ini menjelaskan hasil kita untuk kompetisi TRAC 2020 yang dilakukan bersama konferensi LREC 2020. Nama tim kami adalah Ms8qQxMbnjJMgYcw. Kompetisi terdiri dari 2 subtasks dalam 3 bahasa (Bengali, Inggris dan Hindi) di mana tugas peserta adalah untuk mengklasifikasi agresi dalam teks pendek dari media sosial dan memutuskan apakah itu adalah jenis atau tidak. Kami menggunakan satu sistem berdasarkan BERT dengan dua output untuk semua tugas secara bersamaan. Our model placed first in English and second in Bengali gendered text classification competition tasks with 0.87 and 0.93 in F1-score respectively.', 'fa': 'این کاغذ نتایج ما را برای رقابت TRAC 2020 با کنفرانس LREC 2020 توصیف می\u200cکند. اسم تیم ما خانم 8qQxMbnjJMgYcw بود. مسابقه\u200cای از ۲ زیر سؤال در ۳ زبان (بنگالی، انگلیسی و هندی) بود که وظیفه\u200cی مشترک\u200cکنندگان این بود که در متن\u200cهای کوتاه از رسانه\u200cهای اجتماعی حمله را تشکیل دهند و تصمیم بگیرند که آیا جنسی است یا نه. ما یک سیستم بر اساس BERT با دو نتیجه برای همه کارها همزمان استفاده کردیم. مدل ما اول در انگلیسی و دوم در بنگالی مسابقه\u200cهای مسابقه\u200cای با 0.87 و 0.93 در نقاط F1 قرار داد.', 'ko': '이 문서에서는 LREC 2020 회의와 함께 진행된 TRAC 2020 경연대회의 결과를 다룹니다.저희 팀 이름은 MS8QXMBNJMGYCW입니다.경기는 3개 언어(방글라데시, 영어, 인디언)의 2개 하위 임무로 구성됐으며, 참가자의 임무는 소셜미디어의 짧은 텍스트에서 공격 행위를 분류하고 성별 차이가 있는지 확인하는 것이다.우리는 모든 작업에 두 개의 출력이 동시에 있는 버트 기반 시스템을 사용한다.우리의 모델은 영어와 방글라데시어 성별 텍스트 분류 경연 미션에서 1위를 차지했고 F1의 성적은 각각 0.87과 0.93이었다.', 'sw': 'Gazeti hili linaelezea matokeo yetu ya ushindani wa TRAC 2020 uliofanyika pamoja na mkutano wa LREC 2020. Jina letu la timu lilikuwa Ms8qQxMbnjJMgYcw. Mashindano yalijumuisha kazi mbili kwa lugha tatu (Bengali, Kiingereza na Kihindi) ambapo kazi ya washiriki ilikuwa ya kutangaza ukatili katika maandishi fupi kutoka kwenye mitandao ya kijamii na kuamua ikiwa ni jinsia au la. Tulitumia mfumo mmoja wa BERT wenye matokeo mawili kwa kazi zote wakati huo. Mfano wetu uliweka kwanza katika lugha ya Kiingereza na pili katika mashindano ya kutangaza maandishi ya kijinsia nchini Bengali kwa kiwango cha 0.87 na 0.93 katika vipindi vya F1.', 'tr': 'Bu kagyz TRAC 2020 ýaryşy bilen konferensiýa LREC 2020 bilen geçirilen netijelerimizi tassyýar. Biziň toparymyzyň ady Ms8qQxMbnjJMgYcw idi. Rekabetçe 3 dilde 2 alt sorag bar (Bengali ýa, iňlisçe we hindiýa) iştirakçileriniň görevi sosial mediýanyň gysga metinlerinde agyry barlamakdyr we onuň jentilleýändigini çözmelidir ýa-da çözmelidir. Hemme iş üçin iki netijeli bar bir BERT tabanly sistemini ulandyk. Biziň nusgymyz ilkinji iňlisçe we ikinjisi Bengali ň derejesinde diňlisçe çykyşlyk bilen diňlisçe 0.87 we 0.93 derejesi bardyr.', 'sq': 'Ky dokument përshkruan rezultatet tona për konkurrencën TRAC 2020 të mbajtur së bashku me konferencën LREC 2020. Ekipi ynë quhej Ms8qQxMbnjJMgYcw. Konkurrenca përbëhej nga 2 nënpyetje në 3 gjuhë (bengale, angleze dhe Hindi) ku detyra e pjesëmarrësve ishte të klasifikonin agresionin në tekste të shkurtra nga media sociale dhe të vendosnin nëse është gjinore apo jo. Ne përdorëm një sistem të vetëm bazuar në BERT me dy dalje për të gjitha detyrat në të njëjtën kohë. Modeli ynë u vendos i pari në anglisht dhe i dyti në detyrat e klasifikimit të tekstit të gjinisë bengale me respektivisht 0.87 dhe 0.93 në rezultatin F1.', 'am': 'ይህ ገጽ ከ20020 ሰብዓዊ LREC 2020 ጋር የተሰበሰቡትን TRAC ውጤታችንን ይናገራል፡፡ የቡድን ስም ምስ8qQxMbnjJMgYcw ነው። ተቃዋሚዎቹን ማኅበራዊ አውታር ሚዲያ ላይ ግጭት በጥቂት ጽሑፎች ለመለየፍ እና ማኅበራዊ ሚዲያ እንደሆነ ወይም እንደሆነ በ3 ቋንቋዎች (በጋንጋሊ፣ እንግሊዘኛ እና ኪንዲ) የሚደረጉት ስራ በ2 ደብዳቤዎች ውስጥ ነው፡፡ አንድ BERT-based ስርዓት ሁለት ውጤቶች ለሁሉም ስራ በተሰራን ነበር፡፡ ሞዴሌያችን በመጀመሪያ በአንግሊዝኛ እና በሁለተኛው በቢንጋል የሥልጣኑ የጽሑፍ ክፍል ሥርዓቶችን በመለወጥ 0.87 እና 0.93 በF1-score ነው።', 'af': "Hierdie papier beskrywe ons resultate vir TRAC 2020 samekoms met die konferensie LREC 2020. Ons span naam was Ms8qQxMbnjJMgYcw. Die sameswerking het bestaan van 2 subtaske in 3 tale (Bengali, Engels en Hindi) waar die deelnaders se taak was om aggresie in kort teks van sosiale media te klassifiseer en besluit of dit geneem is of nie. Ons het 'n enkele BERT-gebaseerde stelsel gebruik met twee uitvoerdes vir alle werke simultaan. Ons model het eerste in Engels en tweede in Bengali geskende teks klassifiseerde kommunikasie opdragte met 0.87 en 0.93 in F1-telling respectively gesit.", 'hy': 'Այս հոդվածը նկարագրում է մեր արդյունքները ԹրաԿ 2020 մրցակցության համար, որը տեղի է ունեցել միասին LRE2020 կոնֆերանսի հետ: Մեր թիմի անունը Ms8QxMBnja JMgYc էր: Այս մրցակցությունը կազմված էր 2 ենթահարցերից 3 լեզուներում (բենգալացի, անգլերենի և հինդի), որտեղ մասնակիցների առաջադրանքն էր դասակարգել ագրեսիան սոցիալական լրատվամիջոցների կարճ տեքստներում և որոշել, թե դա սեռ է, թե ոչ Մենք օգտագործեցինք մեկ BER-ի հիմնված համակարգ, որը երկու արդյունք ունի բոլոր առաջադրանքների համար միաժամանակ: Մեր մոդելը առաջինն էր անգլերենում, իսկ երկրորդը՝ բենգալացի տեքստի դասակարգման մրցակցության առաջադրանքներում՝ 0.87-ով և 0.93-ով F1-ով:', 'az': 'Bu kağıt TRAC 2020 müharibəsində konferans LREC 2020 ilə birlikdə olan müharibələrimizin sonuçlarını təsbit edir. Ekibimiz adı Ms8qQxMbnjJMgYcw idi. Yarışmaq 3 dildə (Bengali, İngilizce və Hindi) 2 subtasklardır. İtirafçıların işi sosyal medya vasitələrindən küçük məlumatlarda agresiyanı dəyişdirmək və cins olub olmadığını karar vermək idi. Bütün işlər üçün bircə BERT tabanlı sistemi istifadə etdik. Bizim modelimiz ilk dəfə İngilizce və ikinci dəfə Bengali cinsli metin klasifikasyonu müqayisədə 0.87 və 0.93 ilə F1 dəfəsində yerləşdirdi.', 'bn': 'এই পত্রিকা আমাদের ফলাফল ট্রিএস ২০২০ এর জন্য বর্ণনা করেছে যা কনফারেন্স এলরিসি ২০২০ এর সাথে একত্রিত হয়েছে। আমাদের দলের নাম মিস৮qQxMbnjJMgYcw। এই প্রতিযোগিতার মধ্যে তিন ভাষায় দুটি সাবট্যাক্ট (বেঙ্গালী, ইংরেজী এবং হিন্দি ভাষা) রয়েছে যেখানে অংশগ্রহণকারীদের কাজ সামাজিক মিডিয়া থ আমরা একই সাথে সব কাজের জন্য দুটি আউটপুট ব্যবহার করেছিলাম এক বার্ট-ভিত্তিক সিস্টেম। আমাদের মডেল প্রথম ইংরেজি এবং দ্বিতীয় ভাষায় বাংলাদেশের লিঙ্গ লিঙ্গ লিখিত লেখা বিভিন্ন লিখিত প্রতিযোগিতায় প্রতিযোগিতা কর', 'bs': 'Ovaj papir opisuje naše rezultate natjecanja TRAC 2020, održane zajedno sa konferencijom LREC 2020. Naše ime je Ms8qQxMbnjJMgYcw. Konkurencija se sastojila od 2 podkaza na 3 jezika (Bengalski, engleski i Hindi), gdje je zadatak učesnika bio klasifikacija agresije u kratkim tekstima iz društvenih medija i odlučiti je li spol ili ne. Koristili smo jedan sistem na BERT-u sa dvije rezultate za sve zadatke istovremeno. Naš model je prvi stavio na engleski i drugi na Bengalski zadatak za konkurenciju klasifikacije teksta s 0,87 i 0,93 u dobitku F1.', 'ca': "Aquest paper descriu els nostres resultats de la competició TRAC 2020 celebrada juntament amb la conferència LREC 2020. El nostre equip es diu Ms8qQxMbnjJMgYcw. La competició consistia en 2 subtaskes en 3 llengües (bengalí, anglès i hindí) on la tasca dels participants era classificar l'agressió en textos curts dels mitjans socials i decidir si és sexe o no. Vam utilitzar un únic sistema basat en BERT amb dos productes per totes les tasques simultàneament. El nostre model va ser el primer en anglès i el segon en les tasques de classificació de textos bengalès amb 0,87 i 0,93 puntuacions F1 respectivament.", 'cs': 'Tento článek popisuje naše výsledky soutěže TRAC 2020 konané společně s konferencí LREC 2020. Náš tým se jmenoval Ms8qQxMbnjJMGYCw. Soutěž se skládala z dvou dílčích úkolů ve třech jazycích (bengálština, angličtina a hindština), kde účastníci měli klasifikovat agresi v krátkých textech ze sociálních médií a rozhodnout, zda je genderová nebo ne. Použili jsme jeden systém založený na BERT se dvěma výstupy pro všechny úkoly současně. Náš model se umístil jako první v angličtině a druhý v bengálském klasifikaci textů s 0.87 a 0.93 v F1 skóre.', 'et': 'Käesolevas dokumendis kirjeldatakse koos konverentsiga LREC 2020 toimunud TRAC 2020 konkursi tulemusi. Meie meeskonna nimi oli Ms8qQxMbnjJGYcw. Võistlus koosnes kahest alamülesandest kolmes keeles (bengali, inglise ja hindi), kus osalejate ülesanne oli klassifitseerida agressioon lühikestesse tekstidesse sotsiaalmeedias ja otsustada, kas see on sooline või mitte. Kasutasime ühte BERT-põhist süsteemi kahe väljundiga kõikide ülesannete jaoks korraga. Meie mudel oli esimene inglise keeles ja teine bengali soolise tekstiklassifikatsiooni ülesannetes vastavalt 0,87 ja 0,93 F1-skooriga.', 'fi': 'Tässä artikkelissa kuvataan tuloksia LREC 2020 -konferenssin yhteydessä järjestetyssä TRAC 2020 -kilpailussa. Tiimimme nimi oli Ms8qQxMbnjJGgYcw. Kilpailu koostui kahdesta alatehtävästä kolmella kielellä (bengali, englanti ja hindi), joissa osallistujien tehtävänä oli luokitella aggressio lyhytteksteihin sosiaalisesta mediasta ja päättää, onko se sukupuolitettu vai ei. Käytimme yhtä BERT-pohjaista järjestelmää, jossa oli kaksi ulostuloa kaikkiin tehtäviin samanaikaisesti. Mallimme sijoittui ensimmäiseksi englanniksi ja toiseksi bengalilaisessa sukupuoleen perustuvassa tekstiluokituksessa 0,87 pisteellä ja 0,93 pisteellä F1.', 'sk': 'V prispevku so opisani rezultati tekmovanja TRAC 2020, ki je potekala skupaj s konferenco LREC 2020. Ime naše ekipe je bilo Ms8qQxMbnjJGgYcw. Tekmovanje je bilo sestavljeno iz dveh podnalog v treh jezikih (bengalščini, angleščini in hindijščini), kjer je bila naloga udeležencev klasificirati agresijo v kratkih besedilih iz družbenih medijev in se odločiti, ali je agresivna ali ne. Uporabili smo en BERT sistem z dvema izhodoma za vsa opravila hkrati. Naš model se je uvrstil na prvo mesto v angleščini in na drugo mesto v bengalskem tekmovalnem tekmovanju za klasifikacijo besedila po spolu z 0,87 oziroma 0,93 oceno F1.', 'he': 'העיתון הזה מתאר את התוצאות שלנו לתחרות TRAC 2020 שנערכה יחד עם הישיבה LREC 2020. שם הקבוצה שלנו היה Ms8qQxMbnjJMgYcw. התחרות היתה מורכבת משני תושאות בשלושה שפות (בנגלי, אנגלי והינדי) שבו המשימה של השתתפים היתה להקליף אגרסיה בטקסטים קצרים ממדיה חברתית ולהחליט אם היא מינית או לא. השתמשנו במערכת אחת מבוססת על BERT עם שתי יציאות לכל המשימות באותו זמן. המודל שלנו הוצב ראשון באנגלית ושני באנגלית בתפקידים מסווגים טקסטים בנגאליים עם 0.87 ו-0.93 ב-F1-נקודה בהתאם.', 'jv': 'Perintah iki dadi tanggal perintah sing ditambah nggo metunggal TROC 2020 sing beraksi barêng ngêngêr LREC 2020 Jenengan kelompok nambah wis mr8 qqqMbnjijijijYq. Competisi wis rampung 2 kalih basa ning 3 luwih Awak dhéwé nggunakake sistem sing saben BERT-diangkat iki dadi ono nggawe barang sampeyan. modelo sing ngejarakne tualke kanggo inggiles karo segondi kanggo inggal gal kuwi suk kelas telas telas telas karo 0.', 'ha': 'Wannan karatun yana bayyana matsalayinmu wa TRac 2020, wanda aka haɗa da kongamai LTRC 2020. Sunan Team S8qQxMbnjJMgYcw. Daga jigon ta ƙunsa da task õki 2 cikin harshen 3 (Bangali, Ingiriya da Hindu) a inda aikin mãsu shirin da shi ya kasance a rarraba kibiyoyi cikin littafan rubutu masu ƙaranci daga mitandan jamii kuma ya hukunta, ko ba za a jine shi ba. We used a single BERT-based system with two outputs for all tasks simultaneously.  Misalinmu ya sanya farko a cikin Ingiriya da na sauniya a cikin matsayin sifilacin mutane na Bangali da henhold 0.87 da 0.93 a F1-score.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་རྐྱེན་འབྲས་འདིས་TRAC 2020་གི་ཕྱོགས་སུ་ཚོར་བ་དང་མཉམ་དུ་བསྡུར་དུས་ཡོད། ང་ཚོའི་མིང་མིང་ནི་Ms8qQxMbnjJMgYcw རེད། དཀའ་ངལ་འདིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་གྱི་དོན་ཚན་གསུམ་ལས་ཕན་ཕྲིན་གཉིས་ཀྱི་ནང་དུ་ཡོད། ང་ཚོས་བྱ་འགུལ་ཆ་ཚང་ལ་ཐོག་ལས་འགུལ་གཉིས་གཅིག་གི་BERT་རྟེན་གཞི་བྱས་པའི་མ་ལག་གཅིག་བེད་སྤྱོད་པ། Our model placed first in English and second in Bengali gendered text classification competition tasks with 0.87 and 0.93 in F1-score respectively.'}
{'en': 'FlorUniTo@TRAC-2 : Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection F lor U ni T o@ TRAC -2: Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection', 'es': 'FlorUnito @TRAC -2: Adaptación de incrustaciones de palabras en un léxico abusivo para la detección agresiva del lenguaje', 'ar': 'FlorUniTo @ TRAC-2: التعديل التحديثي لتضمينات الكلمات في معجم مسيء للكشف عن اللغة العدوانية', 'fr': "FlorUnito @TRAC -2\xa0: modification de l'intégration de mots sur un lexique abusif pour une détection agressive du langage", 'pt': 'FlorUniTo@TRAC-2: Adaptando Word Embeddings em um Lexicon Abusivo para Detecção de Linguagem Agressiva', 'ja': 'FlorUniTo @ TRAC -2:攻撃的な言語検出のための濫用的な辞書への単語埋め込みの改造', 'zh': 'FlorUniTo@TRAC-2:于滥用词典上修改词嵌攻击性语检测', 'ru': 'FlorUniTo@TRAC-2: Модернизация слов на оскорбительном лексиконе для агрессивного обнаружения языка', 'hi': 'FlorUniTo@TRAC-2: Retrofitting Word Embeddings आक्रामक भाषा का पता लगाने के लिए एक अपमानजनक शब्दकोश पर', 'ga': 'FlorUniTo@TRAC-2: Leabú Focal Iarfheistithe ar Foclóir maslach le haghaidh Teanga Ionsaitheach a Bhrath', 'ka': 'FlorUniTo@TRAC - 2: წარმოდგენებული სიტყვების შებეჭირება აბუციური ლექსიკონის შესაძლებელად წარმოდგენებაზე', 'hu': 'FlorUniTo@TRAC -2: Szóbeágyazások utólagos beépítése egy visszaélő lexikonra az agresszív nyelvészleléshez', 'el': 'FlorUniTo@TRAC -2: Αναβάθμιση ενσωμάτωσης λέξεων σε ένα καταχρηστικό λεξικό για επιθετική ανίχνευση γλώσσας', 'it': 'FlorUniTo@TRAC -2: Retrofit di incorporazioni di parole su un lessico abusivo per il rilevamento aggressivo del linguaggio', 'kk': 'FlorUniTo@TRAC - 2: Сөзді тілді анықтау үшін қайта келтірілген сөзді ендіру', 'lt': 'FlorUniTo@TRAC - 2: žodžių įterpimo į piktnaudžiaujantį leksikoną, skirtą agresyviai kalbai nustatyti, atgavimas', 'mk': 'FlorUniTo@TRAC - 2: Ретрофитирање на зборовите на злоупотребен лексикон за агресивно детекција на јазик', 'ms': 'FlorUniTo@TRAC -2: Mengembalikan Penciptaan Kata pada Lexikon Abusif untuk Pengesanan Bahasa Aggresif', 'ml': 'FlorUniTo@TRAC - 2: അബുസിവ് ലെക്സിക്സണില്\u200d വാക്കുകള്\u200d പുനരുത്ഥാപിക്കുന്നു', 'mt': 'FlorUniTo@TRAC -2: L-inkorporazzjoni mill-ġdid tal-kliem fuq Lexicon Abużiv għad-Detezzjoni tal-Lingwa Aggressiva', 'mn': 'FlorUniTo@TRAC -2: Хөгжим хэлний нээлттэй зориулалт дээр дахин нэвтрүүлэгч үг нэвтрүүлэгч', 'no': 'FlorUniTo@TRAC - 2: Retrofitting of Word Embedding on an Abusive Lexicon for Aggressive Language Detection', 'pl': 'FlorUniTo@TRAC -2: modernizacja osadzeń słowa w nadużywanym słowniku do agresywnego wykrywania języka', 'ro': 'FlorUniTo@TRAC -2: Retromontarea încorporărilor de cuvinte pe un Lexicon abuziv pentru detectarea agresivă a limbajului', 'sr': 'FlorUniTo@TRAC - 2: Uveštavanje reèi na nasilnu leksiju za agresivno detekcije jezika', 'si': 'FlorUniTo@TRAC - 2: ක්\u200dරියාත්මක භාෂාව හොයාගන්න පුළුවන් වචනය සම්පූර්ණයෙන් ආපහු සම්පූර්ණය කරන්න', 'so': 'FlorUniTo@TRAC -2: Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Detection of Language', 'sv': 'FlorUniTo@TRAC -2: Efteranpassning av Word Embeddings på en missbrukande Lexikon för aggressiv språkidentifiering', 'ta': 'FlorUniTo@TRAC - 2: முன்னேற்ற மொழி கண்டுபிடிப்புக்கான ஒரு ஆப்ஸிவ் லெக்சிக்சான் மீது பொருத்தமான வார்த்தை உட்பொத', 'ur': 'FlorUniTo@TRAC - 2: انگریسی زبان شناسایی کے لئے ابھاری لکسیسون پر کلام ایمبڈینگ دوبارہ پیدا کرنے والا ہے', 'uz': 'FlorUniTo@TRAC - 2: Aniqlik tilni aniqlash uchun Abusive Lekson tilidan qayta moslash', 'vi': 'FlorUniTo@TRAC -2: Nhúng lại từ vào một Lexicon lợi dụng để phát hiện ngôn ngữ hiếu chiến', 'bg': 'FlorUniTo@TRAC -2: Премонтиране на вграждания на думи в злоупотребяващ лексикон за агресивно откриване на езика', 'da': 'FlorUniTo@TRAC -2: Retrofit Word Embeddings på et misbrugskæsikon til aggressiv sprogregistrering', 'hr': 'FlorUniTo@TRAC - 2: uključujući uključenje riječi o abusivnoj leksiji za agresivno detekcije jezika', 'nl': 'FlorUniTo@TRAC -2: Het retrofitten van woordinsluitingen op een misbruikend lexicon voor agressieve taaldetectie', 'de': 'FlorUniTo@TRAC -2: Nachrüsten von Wort-Einbettungen auf einem missbräuchlichen Lexikon für aggressive Spracherkennung', 'id': 'FlorUniTo@TRAC -2: Mengembalikan Penampilan Kata pada Lexikon Abusif untuk Deteksi Bahasa Aggresif', 'ko': 'FlorUniTo@TRAC-2: 욕설성 어휘에 단어 삽입을 개선하여 공격성 언어 검사를 실시한다', 'fa': 'FlorUniTo@TRAC - ۲: انجمن کلمه\u200cهای تغییر\u200cاندازی بر روی یک تغییر تغییر\u200cاندازی برای کشف زبان\u200cهای بزرگی', 'sw': 'FlorUniTo@TRAC -2: Matukio yanayopaswa na maneno yanayohusu Lexico yenye asili ya kibaguzi kwa ajili ya Utafiti wa Lugha ya Kiingereza', 'tr': 'FlorUniTo@TRAC -2: Abusive Lexicon for Aggressive Language Detection', 'af': "FlorUniTo@TRAC - 2: Herstel Woord Inbetering op 'n Abusive Lexicon vir Aggressive Taal Opdekking", 'sq': 'FlorUniTo@TRAC -2: Ripërfitimi i përfshirjes së fjalëve në një leksikon abuziv për zbulimin agresiv të gjuhës', 'am': 'FlorUniTo@TRAC -2: በአቡስዊ ሊኬክሶን ላይ የቋንቋ አቀማመጥ ቃላት አቀማመጥ', 'hy': 'FlorUniTo@TRAC -2: Ագրեսիվ լեզվի հայտնաբերման բառերի ներգրավման վերաբերյալ', 'az': "FlorUniTo@TRAC - 2: Böyük dil keşfetməsi üçün Abusive Lexicon'da Sözlük İfadələri", 'bn': 'FlorUniTo@TRAC -2: Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection', 'bs': 'FlorUniTo@TRAC - 2: Učvršćenje riječi o nasilnoj leksiji za agresivno detekcije jezika', 'ca': "FlorUniTo@TRAC -2: Retrofitir l'incorporació de paraules en un Lexicó Abusive per a la detecció de llenguatges agressivs", 'cs': 'FlorUniTo@TRAC -2: Dodatečné vybavení vložení slov na zneužívající Lexikon pro agresivní detekci jazyka', 'et': 'FlorUniTo@TRAC -2: Sõna manustamine kuritarvitavale leksikonile agressiivse keele tuvastamiseks', 'fi': 'FlorUniTo@TRAC -2: Sanaupotusten jälkiasentaminen pahoinpitelevään leksikoniin aggressiivisen kielen havaitsemista varten', 'jv': 'FlorUniTo@TRAC -2', 'ha': 'FlorUniTo@TRAC -2: Match as Regular Expression', 'sk': 'FlorUniTo@TRAC -2: Posodobitev vdelav besed v zlorabljajoči leksikon za agresivno zaznavanje jezika', 'bo': 'FlorUniTo@TRAC -2: ཆ་རྐྱེན་ལ་མཚོན་པའི་སྐད་རིགས་བཙལ་བཤེར་ལ་Abusive Lexicon on an Abusive Lexicon for Aggressive Language Detection', 'he': 'FlorUniTo@TRAC -2: מחדש מקדמות מילים על לקסיקון מועלל לגלות שפות אגרסיבית'}
{'en': 'This paper describes our participation to the TRAC-2 Shared Tasks on Aggression Identification. Our team, FlorUniTo, investigated the applicability of using an abusive lexicon to enhance word embeddings towards improving detection of aggressive language. The embeddings used in our paper are word-aligned pre-trained vectors for  English ,  Hindi , and  Bengali , to reflect the languages in the shared task data sets. The embeddings are retrofitted to a multilingual abusive lexicon, HurtLex. We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations. Overall, our  systems  placed toward the middle of the  official rankings  based on  weighted F1 score . However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.', 'fr': "Cet article décrit notre participation aux tâches partagées TRAC-2 sur l'identification de l'agression. Notre équipe, FlorUnito, a étudié l'applicabilité de l'utilisation d'un lexique abusif pour améliorer l'intégration de mots afin d'améliorer la détection du langage agressif. Les intégrations utilisées dans notre article sont des vecteurs pré-entraînés alignés sur des mots pour l'anglais, l'hindi et le bengali, afin de refléter les langues dans les ensembles de données de tâches partagées. Les intégrations sont adaptées à un lexique abusif multilingue, HurtLex. Nous avons expérimenté un modèle LSTM en utilisant l'original ainsi que les intégrations transformées et différentes variations de langage et de paramètres. Dans l'ensemble, nos systèmes se sont classés au milieu du classement officiel en fonction du score pondéré en F1. Cependant, les résultats sur les ensembles de développement et de test montrent des améliorations prometteuses dans toutes les langues, en particulier en ce qui concerne la sous-tâche «\xa0agressivité misogyne\xa0».", 'ar': 'تصف هذه الورقة مشاركتنا في المهام المشتركة لـ TRAC-2 بشأن تحديد هوية العدوان. قام فريقنا ، FlorUniTo ، بالتحقيق في إمكانية تطبيق استخدام معجم مسيء لتعزيز عمليات دمج الكلمات من أجل تحسين اكتشاف اللغة العدوانية. إن الزخارف المستخدمة في ورقتنا عبارة عن نواقل مدربة مسبقًا محاذاة للكلمات للغة الإنجليزية والهندية والبنغالية ، لتعكس اللغات في مجموعات بيانات المهام المشتركة. تم تعديل حفلات الزفاف إلى معجم مسيء متعدد اللغات ، HurtLex. لقد جربنا نموذج LSTM باستخدام الزخارف الأصلية بالإضافة إلى الزخارف المحولة ولغة مختلفة واختلافات الإعداد. بشكل عام ، تم وضع أنظمتنا في منتصف التصنيفات الرسمية بناءً على درجة F1 المرجحة. ومع ذلك ، تظهر النتائج على مجموعات التطوير والاختبار تحسينات واعدة عبر اللغات ، لا سيما في المهمة الفرعية العدوانية الكارهة للنساء.', 'es': 'Este documento describe nuestra participación en las tareas compartidas de TRAC-2 sobre la identificación de la agresión. Nuestro equipo, FlorUnito, investigó la aplicabilidad del uso de un léxico abusivo para mejorar la incrustación de palabras con el fin de mejorar la detección del lenguaje agresivo. Las incrustaciones utilizadas en nuestro artículo son vectores preentrenados alineados con palabras para inglés, hindi y bengalí, para reflejar los idiomas en los conjuntos de datos de tareas compartidas. Las incorporaciones se han adaptado a un léxico abusivo multilingüe, HurtLex. Experimentamos con un modelo LSTM utilizando las incrustaciones originales y transformadas y diferentes variaciones de idioma y configuración. En general, nuestros sistemas se ubicaron en la mitad de la clasificación oficial en función de la puntuación ponderada de F1. Sin embargo, los resultados de los conjuntos de desarrollo y pruebas muestran mejoras prometedoras en todos los idiomas, especialmente en la subtarea de agresión misógina.', 'pt': 'Este artigo descreve nossa participação nas Tarefas Compartilhadas do TRAC-2 sobre Identificação de Agressões. Nossa equipe, FlorUniTo, investigou a aplicabilidade do uso de um léxico abusivo para aprimorar a incorporação de palavras para melhorar a detecção de linguagem agressiva. As incorporações usadas em nosso artigo são vetores pré-treinados alinhados por palavras para inglês, hindi e bengali, para refletir os idiomas nos conjuntos de dados de tarefas compartilhadas. As incorporações são adaptadas a um léxico abusivo multilíngue, HurtLex. Experimentamos um modelo LSTM usando o original, bem como os embeddings transformados e diferentes variações de idioma e configuração. No geral, nossos sistemas ficaram no meio do ranking oficial com base na pontuação ponderada da F1. No entanto, os resultados nos conjuntos de desenvolvimento e teste mostram melhorias promissoras em todos os idiomas, especialmente na subtarefa de agressão misógina.', 'ja': '本稿では、侵略行為識別に関するTRAC -2共有タスクへの参加について説明します。私たちのチーム、FlorUniToは、攻撃的な言葉の検出を改善するために、濫用的な辞書を使用して単語の埋め込みを強化することの適用性を調査しました。私たちの論文で使用されている埋め込みは、共有タスクデータセットに言語を反映するための英語、ヒンディー語、ベンガル語の単語整列された事前トレーニングベクトルです。埋め込みは、多言語濫用辞書HurtLexに改造されています。オリジナルと変換された埋め込み、異なる言語と設定のバリエーションを使用して、LSTMモデルを実験しました。総合的には、F 1の加重スコアに基づき、公式ランキングの中位に位置づけられています。しかし、開発とテストセットの結果は、言語全体、特にミソジニー的な攻撃サブタスクで有望な改善を示しています。', 'zh': '本条引我TRAC-2识事之共同任务。 臣等团队FlorUniTo研用滥词典以增词嵌适用性,以改攻击性语之检。 臣等论用嵌为英语,印地语与孟加拉语单词齐之预训练向量,以见共享之数集之言。 嵌改多言滥词典HurtLex。 用LSTM为实验,用原始与转换、言语、设变体。 总体而言者,加权F1之分也。 然开试之果,言语皆可喜,尤在恶女之攻击性子。', 'hi': 'यह पेपर आक्रामकता पहचान पर TRAC-2 साझा कार्यों के लिए हमारी भागीदारी का वर्णन करता है। हमारी टीम, FlorUniTo, आक्रामक भाषा का पता लगाने में सुधार की दिशा में शब्द embeddings बढ़ाने के लिए एक अपमानजनक शब्दकोश का उपयोग करने की प्रयोज्यता की जांच की। हमारे पेपर में उपयोग किए जाने वाले एम्बेडिंग अंग्रेजी, हिंदी और बंगाली के लिए शब्द-संरेखित पूर्व-प्रशिक्षित वैक्टर हैं, जो साझा कार्य डेटा सेट में भाषाओं को प्रतिबिंबित करते हैं। एम्बेडिंग एक बहुभाषी अपमानजनक शब्दकोश, HurtLex के लिए retrofitted हैं। हमने मूल के साथ-साथ रूपांतरित एम्बेडिंग और विभिन्न भाषाओं और सेटिंग विविधताओं का उपयोग करके एक एलएसटीएम मॉडल के साथ प्रयोग किया। कुल मिलाकर, हमारे सिस्टम भारित F1 स्कोर के आधार पर आधिकारिक रैंकिंग के बीच की ओर रखा। हालांकि, विकास और परीक्षण सेट पर परिणाम भाषाओं में आशाजनक सुधार दिखाते हैं, विशेष रूप से गलत आक्रामकता उप-कार्य पर।', 'ru': 'В настоящем документе описывается наше участие в совместных задачах ПРОФ-2 по выявлению агрессии. Наша команда, FlorUniTo, исследовала применимость оскорбительного лексикона для улучшения вложений слов в целях улучшения обнаружения агрессивного языка. Вложения, используемые в нашей работе, являются словесно-согласованными предварительно обученными векторами для английского, хинди и бенгальского языка, чтобы отразить языки в общих наборах данных задач. Вложения переоснащены многоязычным оскорбительным лексиконом HurtLex. Мы экспериментировали с моделью LSTM, используя как оригинальные, так и преобразованные вложения и различные языковые и установочные вариации. В целом, наши системы расположились в середине официального рейтинга на основе взвешенного балла F1. Однако результаты разработки и тестирования наборов показывают многообещающие улучшения в разных языках, особенно в подзадаче женоненавистнической агрессии.', 'ga': 'Déanann an páipéar seo cur síos ar ár rannpháirtíocht i Tascanna Comhroinnte TRAC-2 ar Aithint Ionsaithe. Rinne ár bhfoireann, FlorUniTo, imscrúdú ar an infheidhmeacht a bhaineann le foclóir maslach a úsáid chun leabú focal a fheabhsú chun teanga ionsaitheach a bhrath. Is veicteoirí réamhoilte focal-ailínithe iad na leabaithe a úsáidtear inár bpáipéar don Bhéarla, don Hiondúis agus don Bheangáilis, chun na teangacha sna tacair shonraí tasc roinnte a léiriú. Déantar na leabaithe a iarfheistiú ar fhoclóir maslach ilteangach, HurtLex. Rinneamar turgnamh le samhail LSTM ag baint úsáide as an mbunleagan chomh maith leis na leabaithe claochlaithe agus éagsúlachtaí éagsúla teanga agus suímh. Ar an iomlán, chuir ár gcórais i dtreo lár na rátálacha oifigiúla bunaithe ar scór ualaithe F1. Mar sin féin, léiríonn na torthaí ar na tacair forbartha agus trialacha feabhsuithe thar na teangacha, go háirithe ar an bhfo-thasc forránta míoginistíoch.', 'ka': 'ეს დოკუმენტი აღწერს ჩვენი დაწყვეტილებას TRAC-2 გაყოფილი დავალებების შესახებ ადგრესის იდენტიფიკაციის შესახებ. ჩვენი ჯგუფი, FlorUniTo, განსხვავებულია აპლექსიკონის გამოყენება სიტყვების შესაბამისათვის, რომ აგრესიური ენის განსხვავებას უფრო მეტივად გახსნა. ჩვენი გვერდიში გამოყენებული ინგლისური, ჰინდელი და ბენდალის წინაწერები არის სიტყვების წინაწერებული წინაწერებული გვექტორები, რომლებიც განსაზღვრებული მონაცემების საზოგადოებში ჩატვირთვა მრავალენგური ძალიან ძალიან ლექსიკონისთვის, HurtLex. ჩვენ LSTM მოდელის გამოყენებას გამოყენებული ორიგიალური მოდელის გამოყენებას და განსხვავებული სიტყვის და განსხვავებული გარიაციების გამოყენებას გამოყენებთ. ჩვენი სისტემები განსაზღვრებული F1 წერტილის საშუალოდ დაყენებულია. მაგრამ განვითარების და ტესტის შედეგების შედეგები ჩვენებენ საუკეთესო წლის შესაძლებლობა, განსაკუთრებით Misogynistic aggression sub-task.', 'hu': 'Ez a tanulmány bemutatja, hogy részt vettünk a TRAC-2 megosztott feladatokban az agresszióazonosítással kapcsolatban. Csapatunk, a FlorUniTo megvizsgálta, hogy egy visszaélő lexikon alkalmazható-e a szóbeágyazások javítására az agresszív nyelv felismerésének javítása érdekében. A tanulmányunkban használt beágyazások szóhoz igazított, előre képzett vektorok angol, hindi és bengáli nyelvekre, hogy tükrözzék a megosztott feladatok adatkészleteiben található nyelveket. A beágyazások egy többnyelvű bántalmazó lexikonra, a HurtLexre vannak beépítve. Kísérleteztünk egy LSTM modellel az eredeti, valamint az átalakított beágyazások és a különböző nyelvi és beállítási variációk felhasználásával. Összességében rendszereink a súlyozott F1 pontszám alapján a hivatalos ranglisták közepére kerültek. A fejlesztési és tesztkészletekkel kapcsolatos eredmények azonban ígéretes fejlődést mutatnak a nyelvek között, különösen a nőgyűlölő agresszió alfeladat tekintetében.', 'el': 'Η παρούσα εργασία περιγράφει τη συμμετοχή μας στις κοινές εργασίες για τον προσδιορισμό της επιθετικότητας. Η ομάδα μας διερεύνησε την εφαρμογή της χρήσης ενός καταχρηστικού λεξικού για την ενίσχυση της ενσωμάτωσης λέξεων προς τη βελτίωση της ανίχνευσης επιθετικής γλώσσας. Οι ενσωματώσεις που χρησιμοποιούνται στην εργασία μας είναι προ-εκπαιδευμένα διανύσματα ευθυγραμμισμένα με λέξεις για τα Αγγλικά, τα Χίντι και τα Βεγγαλικά, ώστε να αντικατοπτρίζουν τις γλώσσες στα κοινά σύνολα δεδομένων εργασιών. Οι ενσωματώσεις είναι αναβαθμισμένες σε ένα πολυγλωσσικό καταχρηστικό λεξικό, HurtLex. Πειραματιστήκαμε με ένα μοντέλο χρησιμοποιώντας το πρωτότυπο καθώς και τις μεταμορφωμένες ενσωματώσεις και διαφορετικές παραλλαγές γλώσσας και ρυθμίσεων. Συνολικά, τα συστήματά μας τοποθετήθηκαν στο μέσο της επίσημης κατάταξης με βάση τη σταθμισμένη βαθμολογία F1. Ωστόσο, τα αποτελέσματα των συνόλων ανάπτυξης και δοκιμών δείχνουν ελπιδοφόρες βελτιώσεις σε όλες τις γλώσσες, ειδικά στην υποεργασία μισογυνιστικής επιθετικότητας.', 'it': "Questo articolo descrive la nostra partecipazione ai compiti condivisi TRAC-2 sull'identificazione dell'aggressione. Il nostro team, FlorUniTo, ha indagato l'applicabilità dell'uso di un lessico abusivo per migliorare l'incorporazione di parole per migliorare la rilevazione di un linguaggio aggressivo. Le incorporazioni utilizzate nel nostro articolo sono vettori pre-addestrati allineati alle parole per inglese, hindi e bengalese, per riflettere le lingue nei set di dati delle attività condivise. Le incorporazioni sono adattate a un lessico abusivo multilingue, HurtLex. Abbiamo sperimentato un modello LSTM utilizzando l'originale e le incorporazioni trasformate e diverse variazioni di linguaggio e impostazione. Nel complesso, i nostri sistemi si posizionano verso la metà della classifica ufficiale basata sul punteggio F1 ponderato. Tuttavia, i risultati sui set di sviluppo e test mostrano miglioramenti promettenti tra le lingue, in particolare sul sottocompito dell'aggressione misogina.", 'lt': 'Šiame dokumente apibūdinamas mūsų dalyvavimas bendrame TRAC-2 agresijos identifikavimo uždaviniuose. Mūsų komanda, FlorUniTo, ištyrė, ar galima naudoti piktnaudžiaujantį leksikoną, kad sustiprintų žodžių įtraukimą siekiant pagerinti agresyvios kalbos aptikimą. Mūsų popieriuje naudojami įrašai yra anglų, hindų ir bengalų iš anksto parengti žodžių derinami vektoriai, kurie atspindi kalbas bendruose užduočių duomenų rinkiniuose. The embeddings are retrofitted to a multilingual abusive lexicon, HurtLex.  We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations.  Apskritai, mūsų sistemos padėtos į oficialių klasifikacijų vidurį, remiantis svertiniu F1 rezultatu. Tačiau rengimo ir bandymų rinkinių rezultatai rodo, kad kalbos gerėja, ypač misogynistinės agresijos subužduotis.', 'mk': 'Овој весник го опишува нашето учество во заедничките задачи на TRAC-2 за идентификација на агресијата. Нашиот тим, Флорунито, ја истражуваше апликабилноста на користењето на злоупотребен лексикон за подобрување на зборовите кон подобрување на детекцијата на агресивниот јазик. Вклучувањата кои се користат во нашата хартија се предобучени вектори на англиски, хиндиски и бенгалички јазици кои ги одразуваат јазиците во заедничките податоци за задачи. Вклучувањата се реактивирани на мултијазичен злоупотребен лексикон, HurtLex. Експериментиравме со LSTM модел користејќи го оригиналот, како и трансформираните вградувања и различни јазици и поставување варијации. Вкупно, нашите системи се поставени кон средината на официјалните рангирања базирани на тежираната оценка Ф1. Сепак, резултатите на развојот и тестовите покажуваат ветувачки подобрувања меѓу јазиците, особено во врска со мизогинистичката агресивна подзадача.', 'kk': 'Бұл қағаз біздің TRAC- 2 ортақтастырылған тапсырмаларды оқиға идентификациясына қатынасызды таңдайды. Біздің командамыз FlorUniTo, агрессивні тілді анықтау үшін сөздерді ендіру үшін жеңілдіру үшін қолданбаны зерттеді. Қағазда қолданылатын ендіру - тілдерді ортақтастырылған тапсырма деректерінің тілдерін көрсету үшін сөздердің алдын- оқылған векторлары. Ендіру көптілікті жеңілікті лексикалық HurtLex- ге қайта келтіріледі. Біз LSTM моделі бастапқы түрінде, түрлендірілген ендірулерді, басқа тілді және түрлендірулерді қолданып тұрдық. Жалпы жүйелеріміз F1 нүктесіне негізделген официальные жолдардың ортасына орналасқан. Бірақ, жасау және сынақтардың нәтижелері тілдердің арасындағы жақсартылығын көрсетеді, осымен қатар, бусогинистикалық агрессиялық ішкі тапсырмасында.', 'ms': 'Kertas ini menggambarkan ketertarikan kita pada Tugas Berkongsi TRAC-2 mengenai pengenalan Aggression. Pasukan kita, FlorUniTo, menyelidiki kemungkinan menggunakan leksikon yang mengganggu untuk meningkatkan penyembahan perkataan untuk meningkatkan pengesan bahasa agresif. Pencampuran yang digunakan dalam kertas kami adalah vektor pra-dilatih sepanjang perkataan untuk bahasa Inggeris, Hindi, dan Bengali, untuk mencerminkan bahasa dalam set data tugas terkongsi. Pencampuran ditetapkan semula ke leksikon yang menganiaya berbilang bahasa, HurtLex. We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations.  Secara keseluruhan, sistem kita ditempatkan ke tengah rangkaian rasmi berdasarkan skor F1 berat. Namun, hasil pembangunan dan set ujian menunjukkan peningkatan yang berjanji di seluruh bahasa, terutama pada sub-tugas agresi misogynistic.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ പങ്കെടുപ്പ് TRAC-2 പങ്കാളിയുള്ള ജോലികള്\u200dക്ക് വിവരിച്ചുകൊടുക്കുന്നു. ഞങ്ങളുടെ ടീം, ഫ്ലോര്\u200dയൂണിറ്റോ, അതിക്രമത്തിലുള്ള ഭാഷയുടെ കണ്ടുപിടിക്കുന്നതിന് വാക്കുകള്\u200d മെച്ചപ്പെടുത്താന്\u200d വേണ്ടി ഒര ഞങ്ങളുടെ പേപ്പറില്\u200d ഉപയോഗിക്കുന്ന അഭിപ്രായങ്ങള്\u200d ഇംഗ്ലീഷ്, ഹിന്ദി, ബെങ്കാലിക്ക് വേണ്ടി മുമ്പ് പരിശീലന വെക്റ്റര്\u200dമാര്\u200d വാക് അകത്തേക്കുള്ള അഭിപ്രായമായ ഒരു ലെക്സിക്കോണിലേക്ക് മാറ്റിയിട്ടുണ്ട്, ഹാര്\u200dട്ട്ലെക്സ്. നമ്മള്\u200d ഒരു LSTM മോഡല്\u200d ഉപയോഗിച്ച് പരീക്ഷിച്ചിരിക്കുന്നു. നമ്മുടെ ആദ്യഭാഷയും മാറ്റിയിരിക്കുന്ന ഭാഷകളും വ്യത്യസ മൊത്തം, നമ്മുടെ സിസ്റ്റം എഫ്\u200c1 സ്കോര്\u200d അടിസ്ഥാനമായി ഓഫീസല്\u200d റാങ്ങിന്\u200dറെ നടുവിലേക്ക് വെച്ചിരിക എന്നാലും വികസിക്കുന്നതിന്റെയും പരീക്ഷണത്തിന്റെയും ഫലങ്ങള്\u200d ഭാഷകളില്\u200d മുന്\u200dഗണന മുന്\u200dഗണന കാണിക്കുന്നു. പ്രത്യേകിച', 'mt': 'Dan id-dokument jiddeskrivi l-parteċipazzjoni tagħna fit-TRAC-2 Kompiti Konġunti dwar l-Identifikazzjoni tal-Aggressjoni. It-tim tagħna, FlorUniTo, investiga l-applikabbiltà tal-użu ta’ lexicon abbużiv biex itejjeb l-inkorporazzjoni tal-kliem lejn titjib fid-detezzjoni tal-lingwa aggressiva. L-inkorporazzjonijiet użati fid-dokument tagħna huma vetturi mħarrġa minn qabel allinjati bil-kliem għall-Ingliż, l-Indjan u l-Bengali, biex jirriflettu l-lingwi fis-settijiet ta’ dejta ta’ kompiti kondiviżi. L-inkorporazzjonijiet huma retrofitted għal lexicon abbużiv multilingwi, HurtLex. Esperimentajna b’mudell LSTM bl-użu tal-inkorporazzjonijiet oriġinali kif ukoll trasformati u varjazzjonijiet differenti fil-lingwa u fl-issettjar. B’mod ġenerali, is-sistemi tagħna mqiegħda lejn in-nofs tal-klassifikazzjonijiet uffiċjali bbażati fuq punteġġ P1. Madankollu, ir-riżultati dwar l-iżvilupp u s-settijiet tat-testijiet juru titjib promettenti fil-lingwi kollha, speċjalment dwar is-sottokompitu tal-aggressjoni misogynistika.', 'mn': 'Энэ цаас бидний TRAC-2 хуваалтын ажиллагаанд оролцоог тайлбарладаг. Бидний баг ФлорЮНИТО, хүчирхийллийн хэлний нээлтийг сайжруулахын тулд хүчирхийллийн хэлний хэрэглээ ашиглах талаар судалсан. Бидний цаасан дээр хэрэглэгдсэн орнууд нь Англи, Хинди, Бенгали хэлний хэл дээр хуваалцагдсан ажлын өгөгдлийн хэлбэрүүдийг илэрхийлэх үед илэрхийлэгдсэн векторууд юм. Үүнийг олон хэлний зөрчилдөг лексикон, HurtLex-д дахин давтагддаг. Бид LSTM загвартай өөр өөр хэл болон өөр өөрчлөлтийг ашиглаж туршилтыг хийсэн. Ихэнхдээ бидний систем F1 оноо дээр үндсэн официйн цэгийн дунд байрлуулсан. Гэхдээ хөгжлийн болон шалгалтын үр дүн нь хэл дээр амлалтай сайжруулалт харуулдаг, ялангуяа буруу согинист агрессийн суб-даалгаврыг харуулдаг.', 'no': 'Denne papiret beskriver vårt deltakast til TRAC- 2 delte oppgåver på Aggressidentifikasjonen. Gruppen vårt FlorUniTo undersøkte tilgjengeligheten til å bruka ein abusive leksikon for å forbetra ordinnbygging til å forbetra oppdaging av agresivt språk. Innbyggingane som vert brukte i papiret vårt er ordinnstillingane for føreøvinga vektorar for engelsk, hindisk og bengalisk, for å reflektere språka i delte oppgåvedatasett. Innbyggingane vert gjenoppretta til ein fleire språksbokstavar, HurtLex. Vi eksperimenterte med ein LSTM-modell ved å bruka originalen, og den transformerte innbygginga og ulike språk og innstillingar. Systemet våre plassert til midten av dei offisielle rangene basert på vekta F1- poeng. Resultatene for utviklinga og testen viser imidlertid promising forbedringar på språk, spesielt på underoppgåva for misogynistiske aggresjonar.', 'pl': 'Niniejszy artykuł opisuje nasz udział w TRAC-2 Shared Tasks on Aggression Identification. Nasz zespół FlorUniTo zbadał możliwość stosowania nadużywania leksykonu w celu poprawy osadzania słów w celu poprawy wykrywania agresywnego języka. Zastosowane w naszym artykule osadzenia są wstępnie wyszkolone wektory dla angielskiego, hindi i bengalskiego, aby odzwierciedlać języki we wspólnych zestawach danych zadań. Wkłady są modernizowane do wielojęzycznego nadużywającego leksykonu HurtLex. Eksperymentowaliśmy z modelem LSTM z wykorzystaniem oryginalnych i transformowanych osadzeń oraz różnych wariantów językowych i ustawień. Ogólnie rzecz biorąc, nasze systemy umieściły się w połowie oficjalnych rankingów opartych na ważonym wyniku F1. Jednak wyniki zestawów rozwojowych i testowych pokazują obiecujące ulepszenia w językach, zwłaszcza w podzadaniu agresji mizoginistycznej.', 'ro': 'Această lucrare descrie participarea noastră la activitățile partajate TRAC-2 privind identificarea agresiunii. Echipa noastră, FlorUniTo, a investigat aplicabilitatea utilizării unui lexicon abuziv pentru a îmbunătăți încorporarea cuvintelor în vederea îmbunătățirii detectării limbajului agresiv. Încorporările utilizate în lucrarea noastră sunt vectori pre-instruiți aliniați cu cuvinte pentru engleză, hindi și bengală, pentru a reflecta limbile din seturile de date de sarcini partajate. Încorporările sunt adaptate la un lexicon multilingv abuziv, HurtLex. Am experimentat cu un model LSTM folosind atât originalul, cât și încorporările transformate și diferite variante de limbaj și setare. În general, sistemele noastre sunt plasate spre mijlocul clasamentului oficial bazat pe scorul F1 ponderat. Cu toate acestea, rezultatele privind seturile de dezvoltare și teste arată îmbunătățiri promițătoare în toate limbile, în special în ceea ce privește subsarcina agresivă misogină.', 'sr': 'Ovaj papir opisuje naše sudjelovanje na delovanju TRAC-2 zajedničkih zadataka o identifikaciji agresije. Naš tim, FlorUniTo, istražio je primjenu upotrebe nasilnog leksikona kako bi poboljšao uključenje reči u poboljšanje otkrivanja agresivnog jezika. Uključeni u našim papirima su predobučeni vektori za engleski, Hindi i Bengali, koji odražavaju jezike u zajedničkim podacima. Uključenje se vratilo na multijezički nasilni leksikon, HurtLex. Eksperimentirali smo sa LSTM modelom korištenjem originala, kao i transformiranih integracija i različitih jezika i varijacija postavljanja. Naši sistemi su postavljeni usred zvaničnih redova na temelju težih rezultata F1. Međutim, rezultati razvoja i testova pokazuju obećavajuće poboljšanje na jezicima, posebno na podzadatku misoginističke agresije.', 'so': 'Warqaddan waxaa ku qoran qayb-ka wadashada shaqada lagu sharciyey TRAC-2 ee aqoonsiga Aggression. Kooxdayaga FlorUnito ayaa baarayay suurtagalka isticmaalka leksikan isticmaalaya si uu u kordhiyo hadal ku qoran si uu u hagaajiyo aqoonsiga afka xadgudubka ah. The embeddings used in our paper are word-aligned pre-trained vectors for English, Hindi, and Bengali, to reflect the languages in the shared task data sets.  Xafiiska waxaa loo soo celiyey lexico luuqado badan oo isticmaalaya, HurtLex. Waxaannu ku tijaabinay muusiko LSTM ah oo ku isticmaalaya asalka iyo sidoo kale habka beddelan iyo luuqadaha kala duwan iyo bedelka. Sida caadiga ah nidaamkayagii waxay u soo jeedeen meelaha rasmiga ah ee ay ku saleysan yihiin qiimaha F1. Si kastaba ha ahaatee, arimaha horumarinta iyo imtixaanka waxay muuqataa hagaajinta horumarinta luuqadaha oo dhan, khusuusan ku saabsan xeebta galmada galmada.', 'si': 'මේ පැත්තේ අපේ සම්බන්ධතාව TRAC-2 සම්බන්ධ වැඩකට සම්බන්ධ විශ්වාස කරනවා. අපේ කණ්ඩායම, FlorUniTo, පරීක්ෂණය කළා අපරාධකාරීය භාෂාවක් භාවිත කරන්න ප්\u200dරයෝජනයක් පරීක්ෂණය කරලා වචන සංවිධානය අපේ පත්තරයේ භාවිත කරලා තියෙන්නේ වචන ප්\u200dරධාන වෙක්ටර්ස්, ඉංග්\u200dරීසි, හින්දී, බෙන්ගාලී, භාෂාවල් සම්බන්ධ වැඩ මෙම්බෙන්ඩින්ග් එක ආපහු භාෂාවක් ප්\u200dරශ්නයක්, හර්ට්ලෙක්ස්. අපි LSTM මොඩේල් එක්ක පරීක්ෂණය කළා, මූලිකය සහ වෙනස් භාෂාව සහ වෙනස් භාෂාව සඳහා පරීක්ෂණය කරනවා. සම්පූර්ණයෙන්ම, අපේ පද්ධතිය F1 ස්කෝර් අධාරික පද්ධතියට තියෙන්නේ. නමුත්, විකාශය සහ පරීක්ෂණයේ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් භාෂාවල් වලට ප්\u200dරශ්නයක් වෙනවා, විශේෂයෙන්ම වැරද', 'sv': 'Denna uppsats beskriver vårt deltagande i TRAC-2 Shared Tasks on Aggression Identification. Vårt team, FlorUniTo, undersökte tillämpligheten av att använda ett grovt lexikon för att förbättra ordinbäddningar för att förbättra detekteringen av aggressivt språk. Inbäddningarna som används i vår uppsats är ordanpassade förklädda vektorer för engelska, hindi och bengali, för att återspegla språken i de delade uppgiftsuppgifterna. Inbäddningarna anpassas till ett flerspråkigt lexikon, HurtLex. Vi experimenterade med en LSTM-modell med både original och transformerade inbäddningar och olika språk- och inställningsvariationer. Sammantaget placerade våra system mot mitten av den officiella rankningen baserat på viktad F1 poäng. Resultaten av utvecklings- och testuppsättningarna visar dock lovande förbättringar över språk, särskilt på underuppgiften misogynistisk aggression.', 'ta': 'இந்த காகிதத்தில் TRAC-2 பகிர்ந்த பணிகளுக்கு எங்கள் பங்கீடு விவரிக்கிறது கூட்டு அடையாளத்தின் மீது. எங்கள் குழு, ஃப்ளார்யூனிட்டோ, ஒரு தீவிரமான லெக்சியன் பயன்படுத்தும் பயன்படுத்தப்படும் வார்த்தை மேம்படுத்துவதற்கு aggressive மொழியை கண எங்கள் தாளில் பயன்படுத்தப்பட்ட மொழிகள் முன் பயிற்சி முன்பு பயிற்சி வெக்டார்கள் ஆங்கிலம், ஹின்டி மற்றும் பெங்காலிக்கு, பகிர்ந்த உட்பொதிப்புகள் பல மொழிக்கு மீண்டும் செலுத்தப்பட்டுள்ளது, ஹார்ட்லெக்ஸ். நாங்கள் ஒரு LSTM மாதிரியால் பரிசோதனை செய்தோம் மூலம் மூலம் மற்றும் மாற்றப்பட்ட பொருள்கள் மற்றும் வேறு மொழி மற்றும்  மொத்த, எங்கள் அமைப்புகள் F1 மதிப்புக்கு அடிப்படையில் அரசியல் மாற்றங்களின் மத்தியில் அமைக்கப்பட்டது. ஆனால், முன்னேற்றத்தின் முடிவுகள் மற்றும் சோதனைகள் அமைப்புகளின் முடிவுகள், மொழிகள் முழுவதும் முன்னேற்றம் காட்டும', 'ur': 'This paper describes our participation in the TRAC-2 Shared Tasks on Aggression Identification. ہماری تیم، فلوریونیٹو، ایک زبان کا اثبات کرنے کے لئے استعمال کرنے کے قابلیت کی تحقیق کی ہے۔ ہمارے کاغذ میں استعمال کئے جاتے ہیں، انگلیسی، ہندی اور بنگالی کے لئے کلمات کی تعلیم سے پہلے تدریس کئے ہوئے ویکتوروں کے لئے، جو زبانیں مشترک ٹاکس ڈیٹ سٹ میں تفصیل کریں۔ انبوڈینگ ایک بہت سی زبان زبان زبان زبان کے ذریعے، HurtLex کی طرف پلٹی جاتی ہیں. ہم نے ایک LSTM موڈل کے ساتھ آزمائش کی تھی جو اصلی اور تبدیل شدہ ایمبڈینگ اور مختلف زبان اور تنظیم تغییرات کے مطابق ہے۔ بالکل، ہماری سیستموں کو وزن F1 اسکور پر بنیاد رسمی رینگوں کے وسط کی طرف رکھا گیا ہے. However, the results of the development and test set show promising improvements in languages, especially in misogynistic aggression sub-task.', 'uz': "Бу саҳифа TRAC-2 bilan birlashtirilgan vazifalarning qismlarimizni anglatadi. Bizning guruhimiz FlorUnito, kichkina tilni o'zgartirish uchun kuchli leksini ishlatish qobiliyatini o'rganish uchun so'zlarni oshirish mumkin. Qogʻozimizda ishlatilgan odamlar ingliz, Hindi va Bengalcha tillarini qayb boʻlgan vazifa maʼlumotlar tarkibidagi tillarni tashqi qilish uchun birinchi taʼminlovchi vektorlar. Ko'pchiliklarni ko'pchilik kuchli leksikaga olib tashlab, HurtLex. Biz asl asl va o'zgartirilgan qismlarni va boshqa tillar bilan o'zgartirish va o'zgarishlar bilan LSTM modelini sinab ko'rdik. Umumiy, bizning tizimmiz F1 scori asosida qo'llangan rasmlar orasidagi. Lekin, taʼminlovchi va sinov natijalari tillarda yaxshi yaxshi o'zgarishni ko'rsatadi, hususan misogistik harakat haqida o'zgarishni ko'rsatadi.", 'vi': 'Bài viết này mô tả sự tham gia của chúng ta vào Nhiệm vụ Phối Hợp MMA. Đội của chúng tôi, FloriUniTo, đã điều tra khả năng sử dụng ngôn ngữ lạm dụng để tăng sự tác dụng từ từ từ về việc phát triển việc phát hiện ngôn ngữ hung hăng. Những sự nhúng vào trong bài báo của chúng tôi là những cỗ máy sẵn sàng với các từ dành cho người Anh, người Hindi, và Bengali, để phản ánh ngôn ngữ trong các tập tin vụ chung. Những sự gia nhập được trang bị thêm cho ngôn ngữ đa dạng lạm dụng, Tổn nạn Lex. Chúng tôi đã thử nghiệm với một mô hình LSTM dùng bản gốc cũng như sự thay đổi sự nhúng vào và ngôn ngữ khác nhau và thay đổi sự biến đổi. Toàn bộ, hệ thống của chúng tôi được xếp vào giữa các loại chính thức dựa trên điểm F1 cân nặng. Tuy nhiên, kết quả của chương trình phát triển và thử nghiệm cho thấy có những cải tiến đầy hứa hẹn trên cả ngôn ngữ, đặc biệt là trong phân công tác hung hăng-cảm-phụ.', 'bg': 'Настоящата статия описва участието ни в Споделените задачи на ТРАК-2 за идентифициране на агресия. Нашият екип изследва приложимостта на използването на злоупотребяващ лексикон за подобряване на вграждането на думи за подобряване на откриването на агресивен език. Вградванията, използвани в нашата статия, са подравнени на думи предварително обучени вектори за английски, хинди и бенгалски, за да отразяват езиците в споделените набори от данни за задачи. Вградените елементи са модернизирани към многоезичен обиден лексикон, ХъртЛекс. Експериментирахме с модел използвайки оригинала, както и трансформираните вграждания и различни езикови и настройки вариации. Като цяло, нашите системи са поставени в средата на официалното класиране въз основа на претеглен резултат от Формула 1. Резултатите от разработката и тестовите комплекти обаче показват обещаващи подобрения в различните езици, особено в подзадачата за женомраза агресия.', 'nl': 'Dit artikel beschrijft onze deelname aan de TRAC-2 Shared Tasks on Aggression Identification. Ons team, FlorUniTo, onderzocht de toepasbaarheid van het gebruik van een misbruikend lexicon om woordinbeddingen te verbeteren om de detectie van agressieve taal te verbeteren. De embeddings die in ons document worden gebruikt, zijn vooraf getrainde vectoren voor het Engels, Hindi en Bengaals, om de talen in de gedeelde taakgegevens weer te geven. De embeddings zijn achteraf uitgerust met een meertalig misbruik lexicon, HurtLex. We experimenteerden met een LSTM model met zowel de originele als de getransformeerde embeddings en verschillende taal- en settingsvariaties. Over het algemeen plaatsten onze systemen zich in het midden van de officiële ranglijsten op basis van gewogen F1 score. Echter, de resultaten op de ontwikkeling en test sets tonen veelbelovende verbeteringen in alle talen, met name op de misogynistische agressie sub-taak.', 'da': 'Dette dokument beskriver vores deltagelse i TRAC-2 delte opgaver om identifikation af aggression. Vores team, FlorUniTo, undersøgte anvendeligheden af at bruge et krænkende leksikon til at forbedre ordindlejringer til at forbedre detekteringen af aggressivt sprog. De indlejringer, der anvendes i vores papir, er ordjusterede præ-trænede vektorer til engelsk, hindi og bengali, for at afspejle sprogene i de delte opgavedatasæt. Indlejringerne er eftermonteret til et flersproget krænkende leksikon, HurtLex. Vi eksperimenterede med en LSTM model ved hjælp af den originale såvel som de transformerede indlejringer og forskellige sprog- og indstillingsvariationer. Samlet set er vores systemer placeret mod midten af de officielle ranglister baseret på vægtet F1 score. Resultaterne af udviklings- og testsættet viser imidlertid lovende forbedringer på tværs af sprog, især på underopgaven misoginistisk aggression.', 'hr': 'Ovaj papir opisuje naše sudjelovanje na podijeljenim zadacima TRAC-2 o identifikaciji agresije. Naš tim, FlorUniTo, istražio je primjenu upotrebe nasilnog leksikona kako bi poboljšao uključenje riječi u poboljšanje otkrivanja agresivnog jezika. Uključeni u našim papirima su predodređeni vektori za engleski, Hindi i Bengali kako bi odrazili jezike u zajedničkim podacima o zadatku. Uključenje se vratilo na multijezički nasilni leksikon HurtLex. Eksperimentirali smo s LSTM modelom korištenjem originala, kao i transformiranih integracija i različitih jezika i varijacija postavljanja. Naši sustavi su postavljeni usred zvaničnih redova na temelju težih rezultata F1. Međutim, rezultati razvoja i testova pokazuju obećavajuće poboljšanje na jezicima, posebno na podzadatku misogynističke agresije.', 'de': 'Diese Arbeit beschreibt unsere Teilnahme an den TRAC-2 Shared Tasks on Aggression Identification. Unser Team, FlorUniTo, untersuchte die Anwendbarkeit der Verwendung eines missbräuchlichen Lexikons, um Worteinbettungen zu verbessern, um die Erkennung aggressiver Sprache zu verbessern. Die in unserem Papier verwendeten Einbettungen sind wortausgerichtete vortrainierte Vektoren für Englisch, Hindi und Bengali, um die Sprachen in den gemeinsamen Aufgabendatensätzen wiederzugeben. Die Einbettungen werden auf ein mehrsprachiges missbräuchliches Lexikon, HurtLex, nachgerüstet. Wir haben mit einem LSTM-Modell experimentiert, das sowohl das Original als auch die transformierten Einbettungen und verschiedene Sprach- und Setting-Variationen verwendet. Insgesamt platzierten sich unsere Systeme in der Mitte der offiziellen Rankings basierend auf gewichteter F1-Punktzahl. Die Ergebnisse der Entwicklungs- und Testsets zeigen jedoch vielversprechende Verbesserungen in allen Sprachen, insbesondere in der Teilaufgabe frauenfeindliche Aggression.', 'ko': '본고는 TRAC-2 공격 식별 공유 임무에 참여한 상황을 묘사한다.우리 팀은 폭언성 어휘를 사용하여 단어의 삽입을 강화하여 공격성 언어 검출의 적용성을 높이는 것을 조사했다.본고에서 사용한 삽입은 영어, 인디언, 방글라데시어의 단어와 일치하는 예비 훈련 벡터로 공유 임무 데이터가 집중된 언어를 반영한다.이 삽입물들은 다중 언어 남용 어휘인 HurtLex로 개조되었다.LSTM 모델은 원본 삽입, 변환 삽입, 다양한 언어와 설정 변형을 사용하여 실험했습니다.전반적으로 말하자면, 우리 시스템은 F1 가중점수를 바탕으로 하는 공식 랭킹에서 중간 위치에 있다.그러나 개발과 테스트 집합의 결과에 따르면 크로스 언어의 테스트는 특히 혐녀 공격 서브 임무에서 크게 개선되었다.', 'id': 'Kertas ini menjelaskan participasi kita pada Trac-2 Bagian Tugas Identifikasi Aggresi. Our team, FlorUniTo, investigated the applicability of using an abusive lexicon to enhance word embeddings towards improving detection of aggressive language.  Pencampuran yang digunakan dalam kertas kami adalah vektor pre-terlatih yang disesuaikan dengan kata-kata untuk bahasa Inggris, Hindi, dan Bengali, untuk merefleksikan bahasa dalam set data tugas yang sama. Penampilan ini dipasang kembali ke leksikon abusif berbagai bahasa, HurtLex. We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations.  Secara umum, sistem kita ditempatkan ke tengah rangkaian resmi berdasarkan skor F1 berat. Namun, hasil dari perkembangan dan set tes menunjukkan perkembangan yang berjanji di berbagai bahasa, terutama pada sub-tugas agresi misogynis.', 'fa': 'این کاغذ مشارکت ما را توصیف می\u200cکند که در کارهای مشترک TRAC-2 در مورد شناسایی گروهی مشترک باشیم. تیم ما، فلوریونیتو، کاربردی از استفاده از زبان زبان تجاوز تحقیق کرد تا افزایش کردن کلمات به سوی بهتر شناسایی زبان تجاوز کرد. در روزنامه\u200cهای ما استفاده می\u200cشود، ویکتورهای پیش آموزش برای انگلیسی، هندی و بنگالی، برای تفسیر زبانها در مجموعه داده\u200cهای کار مشترک است. افزایش\u200cها به زبان\u200cهای زیادی زبان، هارتلکس بازگردانده می\u200cشوند. ما با یک مدل LSTM آزمایش کردیم که از اصلی استفاده می\u200cکند، همچنین وسیله\u200cهای تغییر داده شده و زبان مختلف و تغییرات تنظیم می\u200cکند. در کل، سیستم\u200cهای ما به وسط صفحه\u200cهای رسمی بر اساس نقاط وزن F1 قرار داده اند. ولی نتیجه\u200cهای توسعه و آزمایش\u200cها بر روی توسعه و آزمایش\u200cها بهترین قول\u200cدهنده\u200cای در زبانها نشان می\u200cدهند، مخصوصا بر روی زیر وظیفه\u200cی حمله\u200cهای ناشناسی.', 'sw': 'Gazeti hili linaelezea ushiriki wetu kwenye kazi za TRAC-2 zilizoshirikishwa kwenye utambulisho wa Makubaliano. Timu yetu, FlorUnito, ilichunguza matumizi ya kutumia lexico yenye matumizi ya ukatili ili kuongeza maneno yanayoingizwa ili kuboresha kutambua lugha ya kibaguzi. Maandamano yaliyotumiwa katika gazeti letu ni vector zilizotengenezwa kwa maneno ya awali kwa ajili ya Kiingereza, Hindi na Bengali, kutafakari lugha katika seti za taarifa za kazi zilizoshirikishwa. Makumbusho hayo yanarudishwa kwenye lexico yenye matumizi ya lugha mbalimbali, HurtLex. Tulijaribu kwa mtindo wa LSTM kwa kutumia asili pamoja na mabadiliko yaliyobadilika na lugha tofauti na kutengeneza mabadiliko. Kwa ujumla, mifumo yetu iliweka katikati ya mataifa rasmi yenye vipimo vya F1. However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.', 'tr': "Bu kagyz biziň TRAC-2 bölüniş işimizi Aggresiýa Kimligi barada goşulşymyzy tassyklaýar. Biziň topamyz FlorUniTo, agresif dilini tapmaklygy üçin ýeterleşdirmek üçin boýunça bir lexikaň ulanmaklygyny soruşdy. Kagyzymyzda ulanylan ýerler sözlerimiz, Iňlisçe, Hindiler we Bengaliler üçin öň-bilim gelen vektörlerdir. Ködlemeler birnäçe dilli hasaplanýan bir leksiýa, HurtLex'e yzarlanýar. Biz LSTM nusgasy bilen orijinal nusgasyny we üýtgeden çykyşlary we üýtgeden çykyşlary ulanyp test etdik. Her zamanki sistemimize göre ölçülü F1 noktasına dayanan resmi satışların ortasına doğru koyuldu. Ýöne, gelişme we synagyň netijesi dillerde söz berýän gelişmeleri görkezýär, ýöne-de ýalňyşlyk agresiýasynyň alt zadynda.", 'sq': 'Ky dokument përshkruan pjesëmarrjen tonë në TRAC-2 Taskat e Përbashkëta për Identifikimin e Aggresionit. Ekipi ynë, FlorUniTo, hetoi aplikabilitetin e përdorimit të një lexikoni abuziv për të përmirësuar përfshirjen e fjalëve drejt përmirësimit të zbulimit të gjuhës agresive. Ndërtesat e përdorura në letrën tonë janë vektorë të paratrajnuar me fjalë për anglisht, Hindi dhe Bengali, për të pasqyruar gjuhët në grupet e të dhënave të përbashkëta të detyrave. Ndërtesat janë përsëritur në një lexikon shumëgjuhës abuziv, HurtLex. Eksperimentuam me një model LSTM duke përdorur origjinalet si dhe përfshirjet e transformuara dhe gjuhët e ndryshme dhe përcaktimin e variacioneve. Në përgjithësi, sistemet tona janë vendosur drejt mes të renditjeve zyrtare bazuar në rezultatin e peshuar F1. Megjithatë, rezultatet mbi zhvillimin dhe grupet e provave tregojnë përmirësime premtuese nëpërmjet gjuhëve, veçanërisht në nëndetyrën e agresionit misogynist.', 'af': "Hierdie papier beskrywe ons deelnimmering na die TRAC- 2 Gedeelde Opdragte op Aggresie Identifikasie. Ons span, FlorUniTo, het die toepassingbaarheid van die gebruik van 'n abusive leksikoon ondersoek om woord inbêding te verbeter tot die verbetering van opspoor van agresive taal. Die inbêding wat in ons papier gebruik word is woord- aligned voor- opgelei vektore vir Engels, Hindi en Bengali, om die tale in die gedeelde taak data stelle te reflekteer. Die inbêding word teruggevind na 'n veelvuldige abusive lexicon, HurtLex. Ons het eksperimenteer met 'n LSTM model met die oorspronklike gebruik en die transformeerde inbêdings en verskillende taal en instelling veranderinge. Ons stelsels het geplaas tot die middel van die offisiele rangings gebaseer op geweeg F1 telling. Maar die resultate van die ontwikkeling en toets stel beloftende verbeteringe oor tale, veral op die misogynistiese aggresie sub-taak.", 'am': 'ይህም ገጽ የTRAC-2 ስራዎችን በአጠቃላይ ማግኘት ላይ የተካፈለውን ትግባር ይናገራል፡፡ የጦማሪያችን የፎርዩንቲ ቋንቋን ለማሻሻል የሚችሉትን ቃላትን ለማድረግ የሚችሉትን አቀማመጥ በማድረግ መግለጫ መረመራል፡፡ በጋዜጠታችን የተጠቀም የቋንቋ ቋንቋዎች በተካፈሉት የስራ ዳታ ማዕከላዎች ውስጥ ለመመለስ የንግግሊዝኛ፣ ሄንዲ እና በናጋሊ ቃላት የተለየ ቀድሞ ተማሪ vectors ናቸው፡፡ አካባቢዎቹ በብዙ ቋንቋ ተጨማሪ ሊክሲን፣ ሐርትLex ወደሚመለሱ ነው፡፡ አዋቂውን እና የተለወጠውን የቋንቋ እና ልዩ ቋንቋ እና ልዩ ልዩነትን በመጠቀም የLSTM ሞዴል ፈተናል፡፡ በጠቅላላ፣ የሥርዓታችን ስርዓት F1 score በመሠረት ላይ ወደ ባለሥልጣናት መካከለኛ ነው፡፡ ነገር ግን የግንኙነት እና የመፈተኛ ውጤቶች በቋንቋዎች ሁሉ፣ ይልቁንም በተሳማሚ ግጭት የደብዳቤ ጉዳይ ላይ ያሳያል፡፡', 'hy': 'Այս հոդվածը նկարագրում է մեր մասնակցությունը համաձայնության հայտնաբերման հանձնարարություններում: Մեր թիմը, Ֆլորունիտոն, ուսումնասիրեց, թե արդյոք օգտագործելի է չարաշահույթ լեքսիկոն, որպեսզի բարելավենք բառերի ներդրումը ագրեսիվ լեզվի հայտնաբերման բարելավման համար: Մեր թղթի մեջ օգտագործվող ներդրումները անգլերենի, հնդինդի և բենգալիի համար բառերով համապատասխանված նախապատրաստված վեկտորներ են, որոնք արտացոլում են լեզուները ընդհանուր խնդիրների տվյալների համակարգերում: Այս ներդրումները վերականգնված են բազմալեզու չարաշահույթ լեքսիկոնին՝ Հարթլեքսին: Մենք փորձեցինք LSMT մոդելի միջոցով օգտագործելով նաև վերափոխված ներդրումները, տարբեր լեզուները և տարբերությունները: Ընդհանուր առմամբ, մեր համակարգերը տեղադրված են պաշտոնական դասակարգումների կենտրոնի վրա, հիմնված F1 դասակարգում: Այնուամենայնիվ, զարգացման և փորձարկումների արդյունքները ցույց են տալիս խոստացնող բարելավումներ լեզուների միջև, հատկապես ձախողվող ագրեսիայի ենթախնդիր:', 'az': "Bu kağıt bizim TRAC-2 şəkli işlərimizi Aggresiya Kimlikləri barəsində təklif edir. Ekibimiz FlorUniTo, agresif dilin keşfini yaxşılaşdırmaq məqsədilə sözləri inkişaf etmək üçün istifadə etmək üçün istifadə edilməsi üçün istifadə etdi. Kağıtlarımızda istifadə edilən in şallar, İngilizce, Hindi və Bengali dillərini paylaşdırılmış işlər verilənlərin dəstələrində təşkil etmək üçün sözlərlə təşkil edilmiş vektörlərdir. İndirmələr çoxlu dil təcavüzlü sözləri HurtLex'ə yenidən təcavüzlənir. Biz LSTM modeli ilə təcrübə etdik, həmçinin dəyişiklikləri və dəyişiklikləri istifadə etdik. Əlbəttə, sistemlərimiz F1 dərəcəsinin ortasına tərəf qoyuldu. Ancaq təhsil və sınamanın sonuçları dillərin arasında, özlərinə də misogynistik agresiyanın apa-görevi barəsində söz verilən yaxşılıqları göstərir.", 'bn': 'এই পত্রিকা আমাদের অংশগ্রহণের বিষয়টি ট্রিএস-২ শেয়ার করা কাজের কাছে বর্ণনা করেছে গ্রেজেশন পরিচয়ের ব্যাপারে। আমাদের দল ফ্লোর ইউনিটো, একটি অত্যাচারী লেক্সিকোন ব্যবহার করার প্রয়োজনীয়তা তদন্ত করেছেন যাতে তারা আক্রান্ত ভাষার আবিষ্কারের জন্য শ আমাদের পত্রিকায় ব্যবহার করা প্রথম প্রশিক্ষিত ভেক্টর ইংরেজি, হিন্দি এবং বাংলাদেশের ভাষাগুলো শেয়ার করা কাজের তথ্য সেটে প্রতিফলিত করা বিভিন্ন ভাষায় অত্যাচারী লেক্সিকোর কাছে ফিরে যাওয়া হয়েছে, হার্টলেক্স। আমরা একটি এলস্টিএম মডেল দ্বারা পরীক্ষা করেছিলাম মূল ভাষা এবং পরিবর্তিত ভাষা এবং ভিন্ন ভাষা এবং ভিন্ন ভিন্ন ভিন্ন ভিন সাধারণত, আমাদের সিস্টেম এফ১ স্কোরের ভিত্তিক ভিত্তিক করে আনুষ্ঠানিক রাঙ্কের মধ্যে দিকে রাখা হয়ে তবে উন্নয়ন এবং পরীক্ষার ফলাফল সারা ভাষায় প্রতিশ্রুতিশীল উন্নতি প্রদর্শন করে, বিশেষ করে ভাষায় ভাষায় বিভিন্ন ভাষায় আক', 'bs': 'Ovaj papir opisuje naše sudjelovanje na podijeljenim zadacima TRAC-2 o identifikaciji agresije. Naš tim, FlorUniTo, istražio je primjenu upotrebe nasilnog leksikona kako bi poboljšao uključenje riječi u poboljšanje otkrivanja agresivnog jezika. Uključeni u našim papirima su predobučeni vektori za engleski, Hindi i Bengali, koji odražavaju jezike u zajedničkim podacima. Uključenje se vratilo na multijezički nasilni leksikon HurtLex. Eksperimentirali smo s LSTM modelom koristeći originalno kao i transformirane integracije i različite jezike i variacije postavljanja. Naši sistemi su postavljeni usred zvaničnih redova na temelju težih rezultata F1. Međutim, rezultati razvoja i testova pokazuju obećavajuće poboljšanje na jezicima, posebno na podzadatku misogynističke agresije.', 'cs': 'Tento článek popisuje naši účast na TRAC-2 Shared Tasks on Aggression Identification. Náš tým FlorUniTo zkoumal použitelnost použití zneužívajícího slovníku ke zlepšení vložení slov směrem ke zlepšení detekce agresivního jazyka. Vložení použité v našem článku jsou slovně zarovnané předškolené vektory pro angličtinu, hindštinu a bengálštinu, aby odrážely jazyky ve sdílených datových sadách úkolů. Vložení jsou doplněny do vícejazyčného zneužívajícího slovníku HurtLex. Experimentovali jsme s LSTM modelem s využitím originálních i transformovaných vložení a různých jazykových a nastavení variant. Celkově se naše systémy umístily do středu oficiálního žebříčku založeného na váženém skóre F1. Nicméně výsledky vývojových a testovacích sad ukazují slibná zlepšení napříč jazyky, zejména v podúkolu misogynistické agrese.', 'ca': "Aquest article descriu la nostra participació a la TRAC-2 Tasks Shared on Aggression Identification. El nostre equip, FlorUniTo, va investigar l'aplicabilitat d'utilitzar un lexicó abusiv per millorar l'incorporació de paraules cap a millorar la detecció del llenguatge agressiu. Les integracions que s'utilitzen en el nostre paper són vectors pré-entrenats allinjats a paraules per anglès, hindí i bengalès, per reflexionar les llengües dels conjunts de dades compartits de tasques. The embeddings are retrofitted to a multilingual abusive lexicon, HurtLex.  Hem experimentat amb un model LSTM utilitzant l'original i les incorporacions transformades i diferents llengües i variacions de configuració. En general, els nostres sistemes es van posar cap al mig de les classificacions oficials basades en la puntuació P1. However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.", 'et': 'Käesolevas dokumendis kirjeldatakse meie osalemist TRAC-2 ühistes ülesannetes agressiooni tuvastamiseks. Meie meeskond FlorUniTo uuris kuritarvitava sõnavara kasutamise rakendatavust sõna manustamise parandamiseks agressiivse keele tuvastamise parandamiseks. Meie töös kasutatavad manustamised on inglise, hindi ja bengali keele jaoks sõnajoondatud eelõpetatud vektorid, mis kajastavad jagatud ülesannete andmekogumite keeli. Põimitud sõnastikud on uuendatud mitmekeelsele kuritarvitavale sõnastikule HurtLex. Eksperimenteerisime LSTM mudeliga, kasutades nii originaali kui ka muudetud manustamist ning erinevaid keele- ja seadistusvariatsioone. Kokkuvõttes asetasid meie süsteemid kaalutud F1 skoori alusel ametliku edetabeli keskele. Arendus- ja katsekomplektide tulemused näitavad aga paljulubavaid edusamme keeltes, eriti naisvihkamise allülesandes.', 'fi': 'Tässä artikkelissa kuvataan osallistumistamme TRAC-2:n aggression tunnistamista koskeviin yhteisiin tehtäviin. Tiimimme FlorUniTo tutki väärinkäyttävän sanaston käytön soveltuvuutta sanan upottamiseen aggressiivisen kielen havaitsemisen parantamiseksi. Paperissamme käytetyt upotukset ovat englannin, hindin ja bengalin sanalinjattuja esikoulutettuja vektoreita, jotka heijastavat jaettujen tehtävätietojoukkojen kieliä. Upotukset on jälkiasennettu monikieliseen loukkaavaan sanastoon HurtLex. Kokeilimme LSTM-mallia käyttäen alkuperäistä sekä muunneltuja upotuksia ja erilaisia kieli- ja asetusvaihtoehtoja. Kaiken kaikkiaan järjestelmämme sijoittuivat kohti virallisten rankingien keskiosaa painotettujen F1-pisteiden perusteella. Kehitys- ja testisarjojen tulokset osoittavat kuitenkin lupaavia parannuksia eri kielillä, erityisesti misogynistisen aggression osatehtävässä.', 'jv': 'tab Seung awak dhéwé, Flor UniTo, digawesi aplikasi kanggo nggambar leksi sing usul kanggo nglanggar aturan sing misirke sing bisa bantuan kanggo ngerasakno ujaran langah apik. embedding text-editor-action Awak dhéwé éneng perintain karo model LTT sing gambar urip tiku nggawe ngubah winih lan aturan sing paling nggawe Global Nanging, diputamong kapan akeh nggunaken lan ujian iki bakal mlebu nggawe luwih-luwih dumadhi kanggo langgar, sithik ngomongke sak segala apa-task perusahaan no karo hal-iki.', 'sk': 'Ta prispevek opisuje naše sodelovanje pri skupnih nalogah TRAC-2 za identifikacijo agresije. Naša ekipa, FlorUniTo, je raziskala uporabnost uporabe zlorabljajočega leksikona za izboljšanje vključevanja besed za izboljšanje odkrivanja agresivnega jezika. Vgradnje, ki se uporabljajo v našem članku, so besedno poravnani vnaprej usposobljeni vektorji za angleščino, hindijščino in bengalščino, ki odražajo jezike v skupnih naborih podatkov opravil. Vgradnje so naknadno opremljene z večjezičnim zlorabljajočim besedilom HurtLex. Z LSTM modelom smo eksperimentirali na podlagi originala in preoblikovanih vdelav ter različnih jezikovnih in nastavitvenih variacij. Na splošno so se naši sistemi uvrstili proti sredini uradne lestvice na podlagi tehtanega rezultata F1. Vendar pa rezultati razvojnih in testnih sklopov kažejo obetavne izboljšave v vseh jezikih, zlasti pri podnalogi ženske sovražnosti agresije.', 'ha': "Wannan takardan na bayyana ushurinmu zuwa the TRac-2 Shared Tayyinin Aggression. Teachenmu, FironUnito, ana tambayar the use of an abuse wani leksiko zuwa ya ƙara magana wanda ke cikin kashi zuwa ga improve ganin harshen na ƙetare. An yi amfani da cikin takardan mu, su zama shiryoyi masu daidaita ta gabã ɗaya wa masu shirya wa Ingiriya, Hindu da Bangali, dõmin su yi tunãni ga harshen cikin tsarin aiki da aka raba shi. Suna shige zuwa wani leksin mai abuse na bakwai, HurtLex. Mun jarraba da wani misali na LSM da aka yi amfani da asalin da aka canza da cikin shirin da aka canza da harshen daban-daban da aka daidaita variant. A jumla, na'uranmu suka saka a tsakanin ranki masu rasmi a kan karatun F1. However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.", 'he': 'This paper describes our participation to the TRAC-2 Shared Tasks on Aggression Identification.  הצוות שלנו, פלוריוניטו, חקר את אפשרות השימוש בלקסיקון מתעלל כדי לשפר את המילים לכיוון שיפור גילוי שפה אגרסיבית. המערכות שמשתמשות בעיתון שלנו הן ווקטורים מאומנים לפני מילים לאנגלית, הינדית ובנגאלית, כדי לשקף את השפות בתוכניות הנתונים המשותפות. התקפות מתקפות מחדש ללקסיקון מתעלל במספר שפות, הרטלקס. ניסינו עם מודל LSTM בשימוש במקורי, כמו גם את התכניות המשתנות ושפה שונה ומצבים שונים. באופן כללי, המערכות שלנו מוקמות לאמצע הדרגות הרשמיות בהתבסס על נקודת F1 משקלת. בכל אופן, התוצאות על התפתחות ומערכות הבדיקות מראות שיפורים מבטיחים ברחבי שפות, במיוחד על התפקיד האגרסיבי המוסוגיניסטי.', 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མཉམ་སྦྲེལ་མཐུད་དུ་འཇུག་སྣོད་ཀྱི་TRAC-2་དང་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་ལ་བཤད་པ ང་ཚོའི་མཁའ་དབུགས་FlorUniTo་ཡིས་བརྗོད་བྱས་པའི་འཇུག ང་ཚོའི་ཤོག་བུ་ནང་དུ་ཡིག་ཚན་གྱི་ནང་དུ་ཡིག་འཕྲིན་གྱི་སྔོན་གྲངས་སྒྲིག་ཟིན་བྲིས་པ་ཚིན་ཡིན། སྒྲིག་འཛུགས་འདི་དག་གི་སྐད་རིགས་སྤྱོད་པའི་གནད་དོན་རིགས་ལ་སླར་སྤྱོད་ཀྱི་ཡོད། ང་ཚོས་དུས་ཡོད་པའི་LSTM་རྣམ་གྲངས་ཀྱི་སྔོན་སྒྲིག་ཅིག་བེད་སྤྱོད་བཞིན་པའི་ནང ཡོངས་བསྡུར་ན། ང་ཚོའི་མ་ལག་གིས་གཞུང་ཕྱོགས་ཀྱི་ཚད་F1 རིམ་པ་ལྟར་གཞུང་ཕྱོགས་སྟེ། ཡིན་ནའང་། འཕེལ་རིམ་དང་བརྟག'}
{'en': 'Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020 TRAC  2020', 'ar': 'صقل مشترك متعدد اللغات لنماذج المحولات لتحديد التصيد والعدوان والتسلط عبر الإنترنت في TRAC 2020', 'fr': "Mise au point conjointe multilingue des modèles de transformateurs pour identifier la pêche à la traîne, l'agression et la cyberintimidation au TRAC 2020", 'es': 'Ajuste conjunto multilingüe de modelos Transformer para identificar el trolling, la agresión y el ciberacoso en TRAC 2020', 'pt': 'Ajuste fino conjunto multilíngue de modelos de transformadores para identificação de trollagem, agressão e cyberbullying no TRAC 2020', 'ja': 'TRAC 2020でのトロール、侵略、ネットいじめを識別するためのトランスフォーマーモデルの多言語共同微調整', 'zh': '于TRAC 2020多言变压器,以识拖钓,侵陵网络', 'ru': 'Многоязычная совместная тонкая настройка моделей трансформаторов для идентификации троллинга, агрессии и киберзапугивания на TRAC 2020', 'hi': 'TRAC 2020 में ट्रोलिंग, आक्रामकता और साइबरबुलिंग की पहचान करने के लिए ट्रांसफॉर्मर मॉडल की बहुभाषी संयुक्त फाइन-ट्यूनिंग', 'ga': 'Mionchoigeartú ilteangach ar shamhlacha Claochladáin chun Trolláil, Ionsaitheach agus Cibearbhulaíocht a shainaithint ag TRAC 2020', 'hu': 'Transzformátormodellek finomhangolása a trolling, agresszió és cyberbullying azonosítására a TRAC 2020-on', 'el': 'Πολυγλωσσικός κοινός συντονισμός μοντέλων μετασχηματιστών για τον προσδιορισμό του τρόλινγκ, της επιθετικότητας και του κυβερνο-εκφοβισμού στο TRAC 2020', 'ka': 'მრავალენგური ერთადერთი ტრანფორმეტრის მოდელების განსაზღვრება Trolling, Aggression და Cyberbullying TRAC 2020-ში', 'mk': 'Мултијазично заедничко финетизирање на трансформските модели за идентификување на тролинг, агресија и киберболитирање на TRAC 2020', 'lt': 'Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020', 'it': 'Perfezionamento congiunto multilingue dei modelli Transformer per identificare Trolling, Aggressione e Cyberbullismo a TRAC 2020', 'kk': 'TRAC 2020 жылы Trolling, Aggression және Cyberbullying тілдерін анықтау үшін көптеген тілдерді түрлендіруші үлгілерін біріктіру', 'ml': 'ട്രോള്\u200dലിങ്ങ്, ആഗ്രേഷന്\u200d, സൈബെര്\u200dബുളിങ്ങ് ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റര്\u200d മോഡലുകളെ തിരിച്ചറിയുന്നതിനായി പല ഭാഷകള്\u200d യൂണ', 'ms': 'Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020', 'mn': 'ТРАК 2020 оны Тролинг, Агресс болон Цибер булчинг тодорхойлох олон хэлний Трансфер загварын олон төрлийн хувьд', 'mt': 'Aġġustament Konġunt Multilingwi tal-mudelli tat-Trasformer għall-identifikazzjoni tat-Trolling, l-Aggressjoni u ċ-Ċiberbullying fit-TRAC 2020', 'no': 'Fleirspråk samanlig finnstilling av transformeringsmodeller for identifisering av Trolling, Aggression og Cyberbullying på TRAC 2020', 'pl': 'Wielojęzyczne wspólne dostosowanie modeli Transformera do identyfikacji trollingu, agresji i cyberprzemocy w TRAC 2020', 'ro': 'Ajustarea comună multilingvă a modelelor Transformer pentru identificarea trollingului, agresiunii și hărțuirii cibernetice la TRAC 2020', 'sr': 'Mnogjezički zajednički fino podešavanje modela transformera za identifikaciju trolling, agresije i kiberbullying na TRAC 2020.', 'si': 'ගොඩක් භාෂාවක් සම්පූර්ණය සම්පූර්ණය සඳහා TRAC 202 දී ත්\u200dරෝලින්, සම්පූර්ණය සහ සායිබර්බුලින් අඳුන්න', 'ur': 'TRAC 2020 میں ترولینگ, گریسی اور سایبر بولینگ کا پہچان کرنے کے لئے بہت سی زبان جوئن ٹرنفسر موڈل کے اچھی تنظیم', 'sv': 'Flerspråkig gemensam finjustering av transformatormodeller för identifiering av trolling, aggression och cybermobbning på TRAC 2020', 'so': 'Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020', 'ta': 'TRAC 2020-ல் மாற்றும் மாதிரி மாதிரிகளின் பல மொழி இணைப்பு முன்னோட்டங்களை கண்டுபிடிக்க முடியவில்லை', 'vi': 'Liên kết đa ngôn ngữ đồng âm bản biến hình cho việc xác định xem chó săn, tấn công và nạn nhân mạng tại TRAC 2020', 'uz': 'Name', 'bg': 'Многоезична съвместна фина настройка на трансформаторните модели за идентифициране на тролинг, агресия и кибертормоз в ТРАК 2020', 'da': 'Flersproget fælles finjustering af Transformer modeller til identifikation af Trolling, Aggression og Cybermobbing på TRAC 2020', 'hr': 'Mnogjezička zajednička fina prilagodba modela transformera za identifikaciju trolling, agresije i kiberbullying na TRAC 2020.', 'nl': 'Meertalige gezamenlijke fine-tuning van Transformer modellen voor het identificeren van Trolling, Aggressie en Cyberpesten op TRAC 2020', 'de': 'Mehrsprachige gemeinsame Feinabstimmung von Transformer-Modellen zur Identifizierung von Trolling, Aggression und Cybermobbing bei TRAC 2020', 'ko': 'TRAC 2020에서 사이버 괴롭힘, 공격, 사이버 괴롭힘을 식별하기 위해 변압기 모델에 대해 다국어 연합 마이크로스피커를 실시한다.', 'fa': 'برای شناسایی ترولینگ، گروهی و سایبر بولینگ در TRAC 2020', 'id': 'Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020', 'af': 'Veelvuldige Joint Fine-tuning van Transformer-modele vir die identifiseer van Trolling, Aggresie en Cyberbullying by TRAC 2020', 'sq': 'Përrregullimi i përbashkët shumëgjuhës i modeleve të Transformuesve për identifikimin e trollimit, agresionit dhe kibernetikut në TRAC 2020', 'sw': 'Kundi la lugha mbalimbali la mifano ya Transfer kwa kutambua Tatizo, Matukio na Mtandao katika TRAC 2020', 'am': 'በTRAC 2020 ውስጥ የTrolling፣ Aggression እና Cyberbullying ለማረጋገጥ የብዙ ቋንቋዎች ተጨማሪ ጥያቄ', 'hy': 'Տրոլինգի, Ագրեսիայի և Կիբերբուլիգի հայտնաբերման համար', 'tr': 'Trolling, Aggresiýa we Cyberbullying at TRAC 2020', 'az': 'TRAC 2020-də Trolling, Aggresyon və Cyberbullying təsdiqlənmək üçün çoxlu dil birləşdirilməsi', 'bn': 'ট্র্যাঙ্গেল, গ্রেগ্রেশন এবং সাইবার্বুলিং চিহ্নিত করার জন্য ট্রান্সফ্রেম মডেলের মাল্টিভাল ভাষায় যুক্তি প্রদ', 'ca': "Models multilingües d'ajustament conjunt de transformadors per identificar trolls, agressions i cibernòmics a TRAC 2020", 'cs': 'Vícejazyčné společné doladění modelů transformátoru pro identifikaci trollingu, agrese a kyberšikany na TRAC 2020', 'bs': 'Mnogjezički zajednički fino podešavanje modela transformera za identifikaciju trolling, agresije i kiberbullying na TRAC 2020.', 'fi': 'Transformer-mallien monikielinen hienosäätö trollingin, aggression ja kyberkiusaamisen tunnistamiseksi TRAC 2020 -messuilla', 'et': 'Transformerite mudelite mitmekeelne ühine täpsustamine trollingu, agressiooni ja küberkiusamise tuvastamiseks TRAC 2020 raames', 'sk': 'Večjezično skupno nastavitev transformatorskih modelov za prepoznavanje trolling, agresije in kibernetskega ustrahovanja na TRAC 2020', 'ha': 'KCharselect unicode block name', 'he': 'שינוי משותף רב-שפתי של דוגמנים טרנספוררים לזהות טרולינג, אגרסיה וקייברבולינג ב-TRAC 2020', 'jv': 'Multilanguage Joint Fine', 'bo': 'Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020'}
{'en': 'We present our team ‘3Idiots’ (referred as ‘sdhanshu’ in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks. Our approach relies on fine-tuning various Transformer models on the different  datasets . We also investigated the utility of task label marginalization, joint label classification, and joint training on multilingual datasets as possible improvements to our models. Our team came second in English sub-task A, a close fourth in the English sub-task B and third in the remaining 4 sub-tasks. We find the multilingual joint training approach to be the best trade-off between computational efficiency of model deployment and  model ’s evaluation performance. We open source our approach at https://github.com/socialmediaie/TRAC2020.', 'ar': 'نقدم لفريقنا نهج "3Idiots" (المشار إليه باسم "sdhanshu" في التصنيف الرسمي) للمهام المشتركة للصيد والعدوان والتسلط عبر الإنترنت (TRAC) لعام 2020. يعتمد نهجنا على ضبط نماذج المحولات المختلفة على مجموعات البيانات المختلفة. لقد بحثنا أيضًا في فائدة تهميش تسمية المهام ، وتصنيف الملصقات المشتركة ، والتدريب المشترك على مجموعات البيانات متعددة اللغات كتحسينات محتملة لنماذجنا. جاء فريقنا في المرتبة الثانية باللغة الإنجليزية في المهمة الفرعية A ، والرابع في المهمة الفرعية باللغة الإنجليزية B والثالث في المهام الفرعية الأربعة المتبقية. نجد أن نهج التدريب المشترك متعدد اللغات هو أفضل مفاضلة بين الكفاءة الحسابية لنشر النموذج وأداء تقييم النموذج. نحن نفتح المصدر نهجنا على https://github.com/socialmediaie/TRAC2020.', 'pt': "Apresentamos a abordagem da nossa equipe `3Idiots' (referido como `sdhanshu' nos rankings oficiais) para as tarefas compartilhadas de Trolling, Agressão e Cyberbullying (TRAC) 2020. Nossa abordagem se baseia no ajuste fino de vários modelos do Transformer nos diferentes conjuntos de dados. Também investigamos a utilidade da marginalização de rótulos de tarefas, classificação conjunta de rótulos e treinamento conjunto em conjuntos de dados multilíngues como possíveis melhorias em nossos modelos. Nossa equipe ficou em segundo lugar na subtarefa de inglês A, em quarto lugar na subtarefa de inglês B e em terceiro nas 4 subtarefas restantes. Achamos que a abordagem de treinamento conjunto multilíngue é o melhor compromisso entre a eficiência computacional da implantação do modelo e o desempenho da avaliação do modelo. Abrimos nossa abordagem em https://github.com/socialmediaie/TRAC2020.", 'fr': "Nous présentons l'approche de notre équipe «\xa03Idiots\xa0» (appelée «\xa0sdhanshu\xa0» dans le classement officiel) pour les tâches partagées de Trolling, Aggression and Cyberbullying (TRAC) 2020. Notre approche repose sur le réglage fin de différents modèles de transformateurs sur les différents ensembles de données. Nous avons également étudié l'utilité de la marginalisation des étiquettes de tâches, de la classification conjointe des étiquettes et de la formation conjointe sur les ensembles de données multilingues comme améliorations possibles de nos modèles. Notre équipe est arrivée deuxième dans la sous-tâche A en anglais, juste quatrième dans la sous-tâche anglaise B et troisième dans les 4 sous-tâches restantes. Nous estimons que l'approche de formation conjointe multilingue est le meilleur compromis entre l'efficacité informatique du déploiement du modèle et les performances d'évaluation du modèle. Notre approche est open source à l'adresse https://github.com/socialmediaie/TRAC2020.", 'es': "Presentamos el enfoque de nuestro equipo `3Idiots' (referido como `sdhanshu' en los rankings oficiales) para las tareas compartidas de Trolling, Aggression and Cyberbullying (TRAC) 2020. Nuestro enfoque se basa en ajustar varios modelos de Transformer en los diferentes conjuntos de datos. También investigamos la utilidad de la marginación de etiquetas de tareas, la clasificación conjunta de etiquetas y la capacitación conjunta sobre conjuntos de datos multilingües como posibles mejoras de nuestros modelos. Nuestro equipo ocupó el segundo lugar en la subtarea A en inglés, un cuarto cercano en la subtarea B en inglés y el tercero en las 4 subtareas restantes. Consideramos que el enfoque de capacitación conjunta multilingüe es la mejor compensación entre la eficiencia computacional de la implementación del modelo y el rendimiento de la evaluación del modelo. Abrimos nuestro enfoque en https://github.com/socialmediaie/TRAC2020.", 'zh': '吾言吾团队"3Idiots"(于官列名为"sdhanshu")法,施于拖钓,侵轶与网络陵(TRAC)2020年共之。 吾法依于异数集上微调诸变形金刚。 又考其任边缘化、合其类、多言数集训练之效,以为可改。 臣等团队在英语子A第二,在英语子B第四,在余4第三。 多言合训练方法者,模形之数也效率与质性之权衡也。 吾于 https://github.com/socialmediaie/TRAC2020 开源吾道也。', 'ja': '私たちは、トロール、侵略、ネットいじめ（ TRAC ） 2020の共有タスクのためのチームの「3 Idiots」（公式ランキングでは「sdhanshu」と呼ばれます）アプローチを提示します。私たちのアプローチは、さまざまなデータセット上のさまざまなトランスフォーマーモデルを微調整することに依存しています。また、モデルの改善として、タスクラベルの縁取り、合同ラベル分類、および多言語データセットに関する共同トレーニングの有用性を調査しました。私たちのチームは、英語のサブタスクAで2位になり、英語のサブタスクBでは4位になり、残りの4つのサブタスクでは3位になりました。多言語共同トレーニングアプローチは、モデル展開の計算効率とモデルの評価パフォーマンスの間の最良のトレードオフであることがわかります。https://github.com/socialmediaie/TRAC2020で私たちのアプローチをオープンソースにしています。', 'hi': "हम ट्रोलिंग, आक्रामकता और साइबरबुलिंग (TRAC) 2020 साझा कार्यों के लिए अपनी टीम '3Idiots' (आधिकारिक रैंकिंग में 'sdhanshu' के रूप में संदर्भित) दृष्टिकोण प्रस्तुत करते हैं। हमारा दृष्टिकोण विभिन्न डेटासेट पर विभिन्न ट्रांसफॉर्मर मॉडल को ठीक करने पर निर्भर करता है। हमने अपने मॉडल में संभावित सुधार के रूप में कार्य लेबल हाशिए, संयुक्त लेबल वर्गीकरण और बहुभाषी डेटासेट पर संयुक्त प्रशिक्षण की उपयोगिता की भी जांच की। हमारी टीम अंग्रेजी उप-कार्य ए में दूसरे स्थान पर रही, अंग्रेजी उप-कार्य बी में एक करीबी चौथा और शेष 4 उप-कार्यों में तीसरा। हम बहुभाषी संयुक्त प्रशिक्षण दृष्टिकोण को मॉडल तैनाती की कम्प्यूटेशनल दक्षता और मॉडल के मूल्यांकन प्रदर्शन के बीच सबसे अच्छा व्यापार-बंद पाते हैं। हम https://github.com/socialmediaie/TRAC2020 पर हमारे दृष्टिकोण को खोलते हैं।", 'ru': 'Мы представляем нашему коллективу подход «3Идиоты» (в официальных рейтингах именуемый «sdhanshu») для разделяемых задач «Троллинг, агрессия и кибербуллинг (TRAC) 2020». Наш подход основан на точной настройке различных моделей трансформаторов на различных наборах данных. Мы также исследовали полезность маргинализации меток задач, совместной классификации меток и совместного обучения многоязычным наборам данных в качестве возможных улучшений наших моделей. Наша команда заняла второе место в английской подзадаче А, четвертое место в английской подзадаче В и третье место в остальных 4 подзадачах. Мы считаем, что многоязычный подход к совместному обучению является наилучшим компромиссом между вычислительной эффективностью развертывания модели и эффективностью оценки модели. Мы открываем исходный текст нашего подхода по адресу https://github.com/socialmediaie/TRAC2020.', 'ga': "Cuirimid i láthair ár bhfoireann `3Idiots' (dá ngairtear `sdhanshu' sna rátálacha oifigiúla) le haghaidh tascanna comhroinnte Trolling, Ionsaithe agus Cibearbhulaíocht (TRAC) 2020. Braitheann ár gcur chuige ar mhionchoigeartú a dhéanamh ar mhúnlaí éagsúla Trasfhoirmeoirí ar na tacair shonraí éagsúla. Rinneamar imscrúdú freisin ar áirgiúlacht imeallú lipéad tasc, rangú lipéad comhpháirteach, agus oiliúint chomhpháirteach ar thacair sonraí ilteangacha mar fheabhsúcháin féideartha ar ár samhlacha. Tháinig ár bhfoireann sa dara háit i bhfothasc Béarla A, an ceathrú ceann is cóngaraí i bhfothasc Béarla B agus sa tríú háit sna 4 fhothasc eile. Is dóigh linn gurb é an cur chuige oiliúna comhpháirteach ilteangach an comhbhabhtáil is fearr idir éifeachtúlacht ríomh- imscartha na samhla agus feidhmíocht meastóireachta na samhla. Oscailtímid ár gcur chuige foinse ag https://github.com/socialmediaie/TRAC2020.", 'el': 'Παρουσιάζουμε την προσέγγιση της ομάδας μας για τα κοινά καθήκοντα Τρόλινγκ, Aggression και Cyberbulling (TRAC) 2020. Η προσέγγισή μας βασίζεται στη ρύθμιση διαφόρων μοντέλων μετασχηματιστών στα διαφορετικά σύνολα δεδομένων. Ερευνήσαμε επίσης τη χρησιμότητα της περιθωριοποίησης ετικετών εργασίας, της κοινής ταξινόμησης ετικετών και της κοινής κατάρτισης σε πολυγλωσσικά σύνολα δεδομένων ως πιθανές βελτιώσεις στα μοντέλα μας. Η ομάδα μας ήρθε δεύτερη στην αγγλική δευτερεύουσα εργασία Α, μια σχεδόν τέταρτη στην αγγλική δευτερεύουσα εργασία Β και τρίτη στις υπόλοιπες τέσσερις δευτερεύουσες εργασίες. Θεωρούμε ότι η πολύγλωσση κοινή προσέγγιση κατάρτισης είναι η καλύτερη ανταλλαγή μεταξύ υπολογιστικής αποδοτικότητας της ανάπτυξης του μοντέλου και της απόδοσης αξιολόγησης του μοντέλου. Ανοίγουμε την προσέγγισή μας στο https://github.com/socialmediaie/TRAC2020.', 'it': "Presentiamo il nostro team `3Idiots' (indicato come `sdhanshu' nelle classifiche ufficiali) approccio per i compiti condivisi Trolling, Aggression e Cyberbullismo (TRAC) 2020. Il nostro approccio si basa sulla messa a punto di vari modelli di Transformer sui diversi set di dati. Abbiamo anche esaminato l'utilità dell'emarginazione delle etichette di task, della classificazione congiunta delle etichette e della formazione congiunta su set di dati multilingue come possibili miglioramenti ai nostri modelli. Il nostro team è arrivato secondo nella sottomissione inglese A, un quarto vicino nella sottomissione inglese B e terzo nelle restanti 4 sottomissioni. Riteniamo che l'approccio di formazione congiunta multilingue sia il miglior compromesso tra l'efficienza computazionale della distribuzione del modello e le prestazioni di valutazione del modello. Il nostro approccio open source https://github.com/socialmediaie/TRAC2020.", 'ka': "ჩვენ ჩვენი ჯგუფი `3Idiots' (რომელიც `sdhanshu' უნდა იყოს პროლინდში) გავამხსენებთ Trolling, Aggression და Cyberbullying (TRAC) 2020-ის გაყოფილი საქმედებისთვის. ჩვენი პროგორმაცია განსხვავებული მონაცემების განსხვავებული მონაცემების განსხვავებული განსხვავებული ტრანფორმეტრის მოდელზე დარწმუნება. ჩვენ ასევე შევხედავთ მონაცემის მარტინალიზაციის სუტილიტება, ერთადერთი მარტინალიზაციის კლასიფიკაცია, და მრავალენგური მონაცემის შესაძლებელი მონაცემის შესაძლებელი მონაც ჩვენი ჯგუფი მეორე ანგლისური სამუშაო A-ში, მეორე მეორე ანგლისური სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო B და მეორე სამუშა ჩვენ მივიღებთ მრავალენგური ერთადერთი განსწავლების პროგრამი, რომ იყოს ყველაზე საუკეთესო შესაძლებლობა, რომელიც მოდელის გამოყენება და მოდელის განსწავლების მუშაობის მ ჩვენ გახსნა ჩვენი მიღება https://github.com/socialmediaie/TRAC2020.", 'hu': 'Bemutatjuk csapatunkat `3Idiots\' (a hivatalos ranglistákon `sdhanshu\' néven említve) a Trolling, Aggresszió és Cyberbullying (TRAC) 2020 megosztott feladatokhoz. Megközelítésünk a különböző Transformer modellek finomhangolásán alapul a különböző adatkészletekre. Vizsgáltuk továbbá a feladatcímkék marginalizációjának, a közös címke osztályozásának és a többnyelvű adatkészletek közös képzésének hasznosságát, mint modelleink lehetséges fejlesztését. Csapatunk második lett az angol "A" alcsoportban, közel negyedik az angol "B" alcsoportban és harmadik a fennmaradó 4 alcsoportban. Úgy véljük, hogy a többnyelvű közös képzési megközelítés a modell telepítésének számítási hatékonysága és a modell értékelési teljesítménye közötti legjobb megoldás. Nyílt forráskódú megközelítésünk https://github.com/socialmediaie/TRAC2020.', 'mk': "We present our team `3Idiots' (referred as `sdhanshu' in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks.  Нашиот пристап зависи од финетизирање на различни трансформски модели на различните податоци. Исто така, ја истражувавме корисноста на маргинализацијата на ознаките на задачите, заедничката класификација на ознаките и заедничката обука за многрачни податоци како можно подобрување на нашите модели. Нашиот тим дојде втор во англиската подзадача А, четврта во англиската подзадача Б и трета во преостанатите четири подзадачи. Најдовме дека мултијазичкиот заеднички пристап на обука е најдобрата разлика помеѓу пресметувачката ефикасност на распоредувањето на моделот и проценката на моделот. Го отвораме нашиот пристап на https://github.com/socialmediaie/TRAC2020.", 'kk': 'Троллинг, Aggression және Cyberbullying (TRAC) 2020 жылы ортақ тапсырмалар үшін біздің тобымызды «3Idiots» деп аталады. Біздің қасиетіміз түрлі деректер жиындарына түрлі түрлендіруші үлгілерін баптауға тәуелді. Сонымен қатар біз тапсырмалар жарлығының маргинализациясын, жарлық жарлығының классификациясын және бірнеше тілдік деректер жарлығының біріктіріміздің моделдеріміздің жақсарту үшін қо Біздің командамыз ағылшын тілінің A ішкі тапсырмасында екінші, ағылшын тілінің B ішкі тапсырмасында төртінші, үшінші қалды 4 ішкі тапсырмаларда. Біз бірнеше тілді біріктірілген оқыту тәсілімі үлгілерді және үлгілердің оқыту жұмысының есептеулердің ең жақсы тәртіпсіздігі болуы үшін табыламыз. Біз көзімізді ашып, https://github.com/socialmediaie/TRAC2020.', 'lt': 'Mes pristatome savo komandą „3Idiotai“ (vadinamą „sdhanshu“ oficialiuose ranguose) dėl bendros užduoties „Trolling, Aggression and Cyberbullying“ (TRAC) 2020 m. Mūsų požiūris grindžiamas įvairių Transformer modelių patobulinimu įvairiuose duomenų rinkiniuose. Taip pat ištyrėme užduočių ženklo marginalizacijos, bendro ženklo klasifikavimo ir bendro mokymo daugiakalbių duomenų rinkinių naudingumą, kaip įmanoma patobulinti mūsų modelius. Mūsų komanda buvo antroji anglų A subužduotyje, ketvirtoji anglų B subužduotyje ir trečioji likusiose 4 subužduotyse. Mūs ų nuomone, daugiakalbis bendras mokymo metodas yra geriausias kompromisas tarp modelio diegimo skaičiavimo veiksmingumo ir modelio vertinimo rezultatų. We open source our approach at  https://github.com/socialmediaie/TRAC2020.', 'mt': 'Aħna nippreżentaw l-approċċ tagħna tat-tim “3Idiots” (imsejjaħ “sdhanshu” fil-klassifikazzjonijiet uffiċjali) għall-kompiti kondiviżi tat-Trolling, l-Aggressjoni u ċ-Ċiberbullying (TRAC) 2020. L-approċċ tagħna jiddependi fuq l-irfinar ta’ mudelli differenti tat-Transformer fuq settijiet ta’ dejta differenti. Investigajna wkoll l-utilità tal-marġinalizzazzjoni tat-tikketta tal-kompiti, il-klassifikazzjoni konġunta tat-tikketta, u t-taħriġ konġunt dwar settijiet ta’ dejta multilingwi bħala titjib possibbli għall-mudelli tagħna. It-tim tagħna ħareġ it-tieni fis-sottokompitu Ingliż A, ir-raba’ mill-a ħħar fis-sottokompitu Ingliż B u t-tielet fl-erba’ sottokompiti li jifdal. Aħna nsibu li l-approċċ tat-taħriġ konġunt multilingwi huwa l-aħjar kompromess bejn l-effiċjenza tal-komputazzjoni tal-użu tal-mudell u l-prestazzjoni tal-evalwazzjoni tal-mudell. Aħna noftħu l-approċċ tagħna fuq https://github.com/socialmediaie/TRAC2020.', 'ms': "Kami memperkenalkan pasukan kami `3Idiots' (dinamakan `sdhanshu' dalam peringkat rasmi) pendekatan untuk tugas kongsi Trolling, Aggression and Cyberbullying (TRAC) 2020. pendekatan kita bergantung pada penyesuaian pelbagai model Transformer pada set data yang berbeza. Kami juga menyelidiki utiliti marginalisasi label tugas, kelasukan label kongsi, dan latihan kongsi pada set data berbilang bahasa sebagai kemungkinan peningkatan kepada model kami. Pasukan kami datang kedua dalam sub-tugas Inggeris A, keempat dekat dalam sub-tugas Inggeris B dan ketiga dalam 4 sub-tugas yang tersisa. Kami mendapati pendekatan latihan bersama berbilang bahasa untuk menjadi perdagangan terbaik antara efisiensi pengiraan penggunaan model dan prestasi penilaian model. Kita buka sumber pendekatan kita di https://github.com/socialmediaie/TRAC2020.", 'no': 'Vi presenterer gruppa vårt « 3Idiots » (som kalla « sdhanshu » i den offisielle rangeringa) for delte oppgåva for Trolling, Aggression og Cyberbullying (TRAC) 2020. Tilnærminga vårt dependerer på å finna ulike transformeringsmodeller på dei ulike datasetta. Vi har også undersøkt verktøyet for marginalisering av oppgåvemerkelappen, joint label classification, and joint training on multilingual datasets as possible improvements to our models. Gruppen vårt kom andre i engelsk underoppgåve A, ein lukk fjerde i engelsk underoppgåve B og tredje i dei reste 4 underoppgåva. Vi finn den fleire språksprøvingstilnærminga som er den beste utviklinga mellom dataeffektiviteten av utviklinga av modellen og evalueringseffekten av modellen. Vi opnar kjelde tilnærming vår på https://github.com/socialmediaie/TRAC2020.', 'ml': "ഞങ്ങള്\u200d ഞങ്ങളുടെ ടീമില്\u200d '3Idiots' (ഓഫീലിക്കല്\u200d റാങ്ങിങ്ങില്\u200d 'ദെഹന്\u200dഷൂ' എന്ന പേര് പറയുന്ന) ട്രോളിങ്ങ്, അഗ്രേഷന്\u200d, സൈബെര്\u200dബുളിങ്ങ് 2020 പങ്കിട്ടി വ്യത്യസ്ത ഡാറ്റാസറ്റുകളില്\u200d നമ്മുടെ അടുത്തുനിന്ന് വ്യത്യസ്തമായി ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d മോഡലു ഞങ്ങള്\u200d ജോലി ലേബിന്റെ മാര്\u200dഗ്ഗീകരണത്തിന്റെ ഉപയോഗം, യൂണ്ട് ലേബിലേറ്റ് ക്ലാസ്ഫികേഷനും, പല ഭാഷകങ്ങളുടെ ഡാറ്റാസറ്റുകളില്\u200d  ഞങ്ങളുടെ ടീം രണ്ടാമത്തേതായി ഇംഗ്ലീഷ് സബ് ജോലിയില്\u200d വന്നു. ഇംഗ്ലീഷിലെ അടുത്ത നാലാമത്തേത്, ബി-ലും മൂന്നാമത്തേതും ബ മോഡല്\u200d പ്രവർത്തിപ്പിക്കുന്നതിന്റെയും മോഡലിന്റെയും വിലാസപ്രകൃതിയുടെയും ഏറ്റവും നല്ല കച്ചവടത്തിന്റെയും പരിശീലനത്തിന്റെയ നമ്മള്\u200d നമ്മുടെ അടുത്തേക്ക് തുറന്നുകൊണ്ടിരിക്കുന്നു. https://github.com/socialmediaie/TRAC2020.", 'sr': 'Predstavljamo naš tim "3idioti" (nazvan kao "sdhanshu" u zvaničnim redovima) pristup za delove troljanja, agresije i kiberbullinga (TRAC) 2020. Naš pristup se oslanja na finaliziranje različitih modela transformera na različitim setima podataka. Istražili smo i korisnost marginalizacije etiketa zadataka, zajedničke klasifikacije etiketa i zajedničke obuke na multijezičkim setima podataka kao moguće poboljšanje naših modela. Naš tim je došao drugi na engleskom podzadatku A, blizu četvrtinu na engleskom podzadatku B i treću u ostalih 4 podzadatka. Nalazimo multijezički zajednički pristup obuke da bude najbolji trgovin između računalne efikasnosti razvoja modela i provedbe ocjene modela. Otvaramo izvor pristupa https://github.com/socialmediaie/TRAC2020.', 'pl': "Przedstawiamy nasz zespół `3Idiots' (określany w oficjalnych rankingach jako `sdhanshu') podejście do wspólnych zadań Trolling, Aggression i Cyberbulling (TRAC) 2020. Nasze podejście opiera się na dostrajaniu różnych modeli Transformera na różnych zbiorach danych. Zbadaliśmy również użyteczność marginalizacji etykiet zadań, wspólnej klasyfikacji etykiet i wspólnego szkolenia na temat wielojęzycznych zbiorów danych jako możliwości ulepszenia naszych modeli. Nasz zespół zajął drugie miejsce w angielskim podzadaniu A, blisko czwartym w angielskim podzadaniu B i trzecim w pozostałych czterech podzadaniach. Uważamy, że wielojęzyczne wspólne podejście szkoleniowe jest najlepszym kompromisem pomiędzy efektywnością obliczeniową wdrażania modelu a wydajnością oceny modelu. Nasze podejście open source https://github.com/socialmediaie/TRAC2020.", 'ro': "Vă prezentăm abordarea echipei noastre `3Idiots' (denumită `sdhanshu' în clasamentele oficiale) pentru sarcinile comune ale Trolling, Agresiune și Cyberbullying (TRAC) 2020. Abordarea noastră se bazează pe reglarea fină a diferitelor modele de Transformer pe diferitele seturi de date. De asemenea, am investigat utilitatea marginalizării etichetelor de sarcini, clasificării comune a etichetelor și instruirii comune privind seturile de date multilingve ca posibile îmbunătățiri ale modelelor noastre. Echipa noastră a ajuns pe locul doi în subsarcina engleză A, pe locul patru în subsarcina engleză B și pe locul trei în celelalte 4 subsarcini. Considerăm că abordarea comună de formare multilingvă reprezintă cel mai bun compromis între eficiența computațională a implementării modelului și performanța de evaluare a modelului. Abordarea noastră deschisă la https://github.com/socialmediaie/TRAC2020.", 'si': "අපි අපේ කණ්ඩායම `3idiots' (ප්\u200dරධානික රේජින් වලට `sdhansu' කියලා) ට්\u200dරෝලිංග්, සිබර්බුලින් සහ සායිබර්බුලින් (TRAC) 2020යි කාර්ය අපේ විදිහට වෙනස් දත්ත සේට් වලින් වෙනස් විදිහට ප්\u200dරවර්තනය කරනවා. අපි පරීක්ෂණය කළා වැඩක් ලේබල් මාර්ජියාලය, සම්බන්ධ ලේබල් විශේෂණය, සම්බන්ධ විශේෂණය, සම්බන්ධ විශේෂණය ග අපේ කණ්ඩායමයි ඉංග්\u200dරීසි සුබ-වැඩ A වල දෙවෙනි කණ්ඩායමයි, ඉංග්\u200dරීසි සුබ-වැඩ B වල වඩා හතරවෙනි කාර්යා අපි ගොඩක් භාෂාවක් සම්පූර්ණ ප්\u200dරශ්නයක් හොයාගන්නවා මොඩේල් විවෘත්තිය සහ මොඩේල්ගේ විවෘත්තියේ හොඳම ව්\u200dය අපි අපේ ප්\u200dරවේශය අරගෙන https://github.com/socialmediaie/TRAC2020.", 'so': "We present our team `3Idiots' (referred as `sdhanshu' in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks.  Dhaqdhaqaalkayagu waxay ku xiran tahay samooyin kala duduwan oo turjumista ah oo ku saabsan danbiyada kala duduwan. Waxaynu sidoo kale baaritaannay isticmaalka calaamada shaqada, fasaxa iskuulka wadajirka ah, iyo waxbarashada wadajirka ah oo ku saabsan sawirada macluumaadka luuqadaha kala duduwan sida suurtagal ah oo loo horumariyo tusaalayaashaada. Timaheena waxay ku yimaadeen labaad sub-task A, af dhow oo ku qoran afka ingiriiska sub-task B iyo saddexaad ee ka hadhay 4 sub-shaqooyinka. Waxaynu helnaa habka iskuulka iskuullada luuqadaha kala duduwan inay ahaato habka ugu wanaagsan ganacsiga ee u dhexeeya shaqaalaha sameynta modellka iyo sameynta qiimeynta sameynta. Waxaynu furan nahay qaabkeenna https://github.com/socialmediaie/TRAC2020.", 'sv': "Vi presenterar vårt team `3Idiots' (som kallas 'sdhanshu' i den officiella rankningen) strategi för Trolling, Aggression och Cybermobbning (TRAC) 2020 delade uppgifter. Vårt tillvägagångssätt bygger på att finjustera olika Transformermodeller på de olika datauppsättningarna. Vi undersökte också nyttan av marginalisering av uppgiftsmärken, gemensam märkningsklassificering och gemensam utbildning i flerspråkiga dataset som möjliga förbättringar av våra modeller. Vårt team kom tvåa i engelska underuppgift A, en nära fjärde i engelska underuppgift B och tredje i de återstående 4 underuppgifterna. Vi anser att den flerspråkiga gemensamma utbildningsmetoden är den bästa avvägningen mellan beräkningseffektivitet i modelldistribution och modellens utvärderingsprocess. Vi har öppen källkod för vårt tillvägagångssätt på https://github.com/socialmediaie/TRAC2020.", 'ur': 'ہم نے اپنے تیم „3Idiots” (رسمی رینگوں میں „sdhanshu”) کو ترولینگ, Aggression اور سایر بولینگ (TRAC) 2020 کے مشترک کام کے لئے پیش کیا ہے. ہمارا طریقہ مختلف ڈاٹ سٹ پر مختلف ٹرنفسر موڈلز کی تنظیم کرنے پر ہے ہم نے بھی تابع لیبل مارجینالیزی کے استعمال کی تحقیق کی، joint label classification، اور multilingual datasets کے ساتھ ملتی زبان کی آموزش کی تعلیم کو ہمارے مدلکوں کے امکانات کے ساتھ بہترین تربیت کی۔ ہماری تیم انگلیسی sub-task A میں دوسری آئی، انگلیسی sub-task B میں نزدیک چوتھی اور تیسری باقی 4 sub-tasks میں آئی۔ ہم نے بہت سی زبان کی تعلیم کی طریقہ پائی ہے کہ موڈل کی تعلیم اور موڈل کی ارزیابی کی عمدگی کے درمیان سب سے بہترین تجارت نافذ ہونے کے لئے۔ ہم اپنے طریقے کو کھولتے ہیں https://github.com/socialmediaie/TRAC2020.', 'ta': "நாங்கள் எங்கள் குழு '3Idiots' (அதிகாரிக்கையில் 'sdhanshu' என்று குறிப்பிட்ட) ட்ரோல்லிங், Aggression மற்றும் Cyberbullying (TRAC) 2020 பகிர்ந்த பணிகளுக்கு நெருங்க எங்கள் அணுக்கம் வேறு தரவு அமைப்புகளில் நன்றாக மாற்றும் மாதிரிகளை சார்ந்தது. நாங்கள் செயல் விளக்கச்சீட்டு சுருக்குதல், சேர் விளக்கச்சீட்டு வகுப்பு, மற்றும் பல மொழி தரவுத்தளங்களில் இணைய பயிற்சி மாதிர எங்கள் குழு இரண்டாவது ஆங்கிலம் துணை பணியில் வந்தது, ஆங்கிலத்தில் நான்காவது துணை பணி B மற்றும் மீதி 4 துணை பணிகளில். மாதிரி விடுதல் மற்றும் மாதிரியின் மதிப்பீடு செயல்பாட்டிற்கும் இடையே சிறந்த வணிக பயிற்சி முறையை நாம் கண்டுபிடிக்கிறோம நாங்கள் எங்கள் மூலம் திறந்த https://github.com/socialmediaie/TRAC2020.", 'mn': 'Бид "3Idiots" (нэртэй хэмжээнд "sdhanshu" гэдэг) багийг Тролинг, Агресс, Цибербулинг (TRAC) 2020 оны хуваалцааны арга замыг тайлбарлаж байна. Бидний арга зам нь өөр өгөгдлийн сангийн олон Трансфер загваруудыг тодорхойлох боломжтой. Мөн бид ажлын загварын загварын загварын загварын хэрэглээ, нийлбэр загварын хуваалтыг, олон хэл өгөгдлийн загварын нийлбэр сургалтыг бидний загварын сайжруулах боломжтой болгон судалсан. Бидний баг Англи хэлний A-н суб-задалгаанд хоёрдугаар ирсэн. Англи хэлний B-н суб-задалгаанд дөрвөн, үлдсэн 4 суб-задалгаанд гурав. Бид олон хэлний нийлбэр сургалтын арга зам нь загварын хөгжүүлэх болон загварын үнэлгээний үйлдвэрлэлийн хамгийн сайн худалдааны ажиллагаа юм. Бид өөрсдийн ойлголтыг нээж, https://github.com/socialmediaie/TRAC2020.', 'uz': "We present our team `3Idiots' (referred as `sdhanshu' in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks.  Bizning muvaffaqiyatlarimiz boshqa maʼlumotlar tarkibini ajratish modellariga ishonadi. Biz shunday qildik, vazifaning marginaliz, birlashtirish yorliq darajasining foydalanishini, va bir necha tillar maʼlumotlar tarkibida bir xil taʼminlovchini o'rganish mumkin modellarimizga bajarish mumkin. Bizning guruhimiz ingliz tilidagi sub-vazifani ikkinchi marta keldi, ingliz tilidagi tub vazifa B va uchinchi uchinchi vazifalarda. Biz bir necha tilda bir xil tibbiy o'rganishni o'rganamiz, modelning qiymati va modelning eng yaxshi qiymati darajasi bo'lishi mumkin. Biz shu yerda https://github.com/socialmediaie/TRAC2020.", 'vi': "Chúng tôi giới thiệu đội của chúng tôi: 3'Idiots (được gọi là'sdhanshu'trong các phong cách chính thức) tiếp cận với bọn Troll, cưỡng bức và bắt nạt mạng (TRAC) 2020 đã được chia sẻ công việc. Cách tiếp cận của chúng ta dựa vào độ chính xác các mô hình transformer. Chúng tôi cũng đã nghiên cứu về tiện ích của nhãn hiệu công tác ngoại giao, nhãn hạng chung, và giáo dục chung về các tập tin đa dạng có thể cải tiến các mô hình của chúng tôi. Đội của chúng tôi theo thứ hai trong phân công A tiếng Anh, một thứ tư trong phân công B tiếng Anh và thứ ba trong bốn nhiệm vụ phụ còn lại. Chúng tôi thấy phương pháp giáo dục chung đa dạng là giải pháp thỏa thuận tốt nhất giữa hiệu quả tính của triển khai mô hình và hiệu suất đánh giá của mô hình. Chúng ta mở nguồn tiếp cận tại https://github.com/socialmediaie/TRAC2020.", 'bg': 'Представяме подхода на екипа ни "3идиоти" (наричан "сданшу" в официалната класация) за споделените задачи на Тролинг, Агресия и Кибертормоз (ТРАК) 2020. Нашият подход разчита на фина настройка на различни модели трансформатори на различните набори от данни. Проучихме и ползата от маргинализацията на етикетите на задачите, съвместната класификация на етикетите и съвместното обучение по многоезични набори от данни като възможни подобрения в нашите модели. Екипът ни зае втори в английската подзадача А, близо четвърти в английската подзадача Б и трети в останалите 4 подзадачи. Смятаме, че многоезичният подход за съвместно обучение е най-добрият компромис между изчислителната ефективност на внедряването на модела и ефективността на оценяването на модела. Ние отваряме нашия подход в https://github.com/socialmediaie/TRAC2020.', 'nl': "We presenteren ons team `3Idiots' (aangeduid als `sdhanshu' in de officiële rankings) aanpak voor de gezamenlijke taken Trolling, Aggressie en Cyberpesten (TRAC) 2020. Onze aanpak berust op het finetunen van verschillende Transformer modellen op de verschillende datasets. We onderzochten ook het nut van marginalisering van taakliketten, gezamenlijke etikettenclassificatie en gezamenlijke training op meertalige datasets als mogelijke verbeteringen aan onze modellen. Ons team werd tweede in Engelse deeltaak A, een bijna vierde in de Engelse deeltaak B en derde in de resterende vier deeltaken. Wij vinden de meertalige gezamenlijke trainingsaanpak de beste afweging tussen de rekenefficiëntie van de implementatie van modellen en de evaluatieprestaties van het model. We open source onze aanpak op https://github.com/socialmediaie/TRAC2020.", 'da': "Vi præsenterer vores team `3Idiots' (omtalt som `sdhanshu' i de officielle ranglister) tilgang til Trolling, Aggression og Cybermobbing (TRAC) 2020 delte opgaver. Vores tilgang er afhængig af finjustering af forskellige Transformer modeller på de forskellige datasæt. Vi undersøgte også nytten af marginalisering af opgavemærker, fælles etiketklassificering og fælles træning i flersprogede datasæt som mulige forbedringer af vores modeller. Vores team kom andenplads i engelsk underopgave A, en tæt fjerde i den engelske underopgave B og tredje i de resterende 4 underopgaver. Vi finder, at den flersprogede fælles træningstilgang er den bedste afvejning mellem beregningseffektivitet af modelindrulning og modellens evalueringsydeevne. Vi åbner kildekode vores tilgang til https://github.com/socialmediaie/TRAC2020.", 'hr': 'Predstavljamo svoj tim "3idioti" (nazvan kao "sdhanshu" u službenim redovima) pristup za zajedničke zadatke Trolling, Agresije i Cyberbullying (TRAC) 2020. Naš pristup se oslanja na dobro određivanje različitih modela transformera na različitim podacima. Istražili smo i korisnost marginalizacije oznake zadataka, zajedničke klasifikacije oznake i zajedničke obuke na multijezičkim podacima kao moguće poboljšanje naših modela. Naš tim je došao drugi na engleskom podzadatku A, blizu četvrtinu na engleskom podzadatku B i treću u ostalih 4 podzadatka. Nalazimo multijezički zajednički pristup obuke da bude najbolji trgovin između računalne učinkovitosti razvoja modela i učinkovitosti ocjene modela. Otvaramo izvor pristupa https://github.com/socialmediaie/TRAC2020.', 'de': "Wir präsentieren unser Team `3Idiots' (in den offiziellen Rankings als `sdhanshu' bezeichnet) Ansatz für die gemeinsamen Aufgaben Trolling, Aggression und Cybermobbing (TRAC) 2020. Unser Ansatz basiert auf der Feinabstimmung verschiedener Transformer-Modelle auf den verschiedenen Datensätzen. Wir untersuchten auch den Nutzen von Task Label Marginalisierung, Joint Label Klassifizierung und gemeinsamem Training auf mehrsprachigen Datensätzen als mögliche Verbesserungen unserer Modelle. Unser Team wurde Zweiter in englischer Teilaufgabe A, knapp vierter in englischer Teilaufgabe B und dritter in den verbleibenden 4-Teilaufgaben. Wir finden, dass der mehrsprachige gemeinsame Trainingsansatz der beste Kompromiss zwischen der Recheneffizienz der Modellbereitstellung und der Evaluierungsleistung des Modells ist. Wir öffnen unseren Ansatz unter https://github.com/socialmediaie/TRAC2020.", 'id': "Kami memperkenalkan tim kami `3Idiots' (disebut `sdhanshu' dalam peringkat resmi) pendekatan untuk tugas kongsi Trolling, Aggression dan Cyberbullying (TRAC) 2020. pendekatan kita bergantung pada memperbaiki berbagai model Transformer pada set data yang berbeda. Kami juga menyelidiki utilitas marginalisasi label tugas, klasifikasi label kongsi, dan pelatihan kongsi pada set data multibahasa sebagai kemungkinan peningkatan pada model kami. Tim kami datang kedua dalam sub-tugas Inggris A, keempat dekat dalam sub-tugas Inggris B dan ketiga dalam 4 sub-tugas yang tersisa. Kami menemukan pendekatan pelatihan berbagai bahasa untuk menjadi perdagangan terbaik antara efisiensi komputasi penggunaan model dan prestasi evaluasi model. Kami membuka sumber pendekatan kami di https://github.com/socialmediaie/TRAC2020.", 'ko': "트위터, 공격, 사이버 괴롭힘(TRAC) 2020 공유 임무에 사용되는 우리 팀의'3Idiots'(공식 순위에서'sdhanshu') 방법을 보여줬다.우리의 방법은 서로 다른 데이터 집합의 각종 변압기 모델을 미세하게 조정하는 데 의존한다.우리는 또한 임무 라벨의 변두리화, 연합 라벨 분류와 다언어 데이터 집합의 연합 훈련의 효용을 연구하여 우리 모델에 대한 개선 가능성으로 삼았다.우리 팀은 영어 서브퀘스트 A에서 2위, 영어 서브퀘스트 B에서 4위, 나머지 4개 서브퀘스트 중 3위에 올랐다.우리는 모델 배치의 계산 효율과 모델의 평가 성능 사이에서 다언어 연합 훈련 방법이 가장 좋은 절충 방안이라는 것을 발견했다.우리https://github.com/socialmediaie/TRAC2020.", 'fa': 'ما تیممون را در صفحه رسمی به عنوان «sdhanshu» (به عنوان «sdhanshu» در صفحه رسمی) برای کار مشترک Trolling, Aggression and Cyberbullying (TRAC) 2020 پیشنهاد می\u200cکنیم. دستور ما بر مدل\u200cهای تغییر\u200cدهنده\u200cهای مختلف به مجموعه\u200cهای داده\u200cهای مختلف بستگی دارد. ما همچنین استفاده از ترکیب برچسب\u200cهای کار، ترکیب برچسب\u200cهای مشترک و آموزش مشترک در مجموعه\u200cهای داده\u200cهای زیادی زبان به عنوان بهترین\u200cهای ممکن برای مدل\u200cهای ما تحقیق کردیم. تیم ما دوم در زیر کار انگلیسی A آمد، چهارمین نزدیک در زیر کار انگلیسی B و سوم در چهار زیر کار باقی ماند. ما روش آموزش های متعدد زبان را پیدا می کنیم تا بهترین تجارت بین موثیت کامپیوتری محاسباتی از کاربرد مدل و کاربرد ارزیابی مدل باشد. ما روش خود را باز می کنیم https://github.com/socialmediaie/TRAC2020.', 'sw': 'Tunawasilisha timu yetu ya ‘Idiots 3’ (inayoitwa ‘sdhanshu’ katika maeneo rasmi) mbinu za kugombea, Mapinduzi na Mtandao (TRAC) 2020. Hatua yetu inategemea kutengeneza mifano mbalimbali ya Transfer katika seti tofauti za data. Pia tulichunguza matumizi ya vifaa vya kuharibiwa, usambazaji wa alama za pamoja, na mafunzo ya pamoja kwenye seti za takwimu za lugha mbalimbali kama inawezekana kuboreshwa kwa mifano yetu. Timu yetu ilifika kwa mara ya pili kwa kazi ya Uingereza A, nne ya karibu katika kazi za kituo cha Kiingereza B na tatu katika kazi zilizobaki 4. Tunapata mbinu ya mafunzo ya pamoja ya lugha mbalimbali ya kuwa ni njia bora ya biashara kati ya ufanisi wa kompyuta wa kutengeneza mifano na utendaji wa mifano. Tunafungua chanzo cha hatua yetu https://github.com/socialmediaie/TRAC2020.', 'tr': "Biz öz toparymyzy Trolling, Aggresiýa we Cyberbullying (TRAC) 2020-nji ýyllar üçin resmi sahypalarda `sdhanshu'-a gollaýarys. Biziň ýaryşymyz farklı veri setirlerine düzelenýän transformer modellerinden ybaratdyr. Biz hem täzim etiketleriň gabdalyklarynyň, birleşik etiketleriň klasifikasyýasynyň, we multidil veri setirleriniň modlarymyza mümkin gelişmeleri diýip soradyk. Biziň toparymyz iňlisçe sub-task A-de ikinji geldi, iňlisçe sub-task B-de ýakyn dördünji we galan 4 sub-tasklerde üçünji boldy. Birnäçe dilli birleşik bilim taýýarlamanyň nusgasy we nusgasynyň baýramçylygynyň iň gowy taýýarlanmagy üçin bilim taýýarlamanyň golaýyny tapdyk. Biz özümiziň golaýymyzy açýarys. https://github.com/socialmediaie/TRAC2020.", 'am': 'የጦማሪያችንን ‹3Idiots› (ባለሥልጣናዊ ክፍል› የተባለውን ‹ድሃንሹ› እና በ2020 የተካፈሉ ስራዎችን ለመግኘት እናቀርባለን፡፡ ልዩ ዳታተሮች ላይ የተለየ የTransformer models በመጠቀም ላይ ነው፡፡ የስራ ምልክት መቀናቀል፣ የኢትዮጵያ መግለጫ እና የብዙልዩ ቋንቋ ዳታዎችን ማቀናቀል እና በሞዴላዎቻችን ማሻሻሻል በሚችል እና የተጠቃሚ ትምህርት ጠቅመን ነበር፡፡ የእንግሊዝኛ ደብዳቤ B እና ሦስተኛውም የቀሩት 4 ደብዳቤ ስራ በንግግሊዝኛ አዳራሽ ስራ A በመጣ ሁለተኛ ደረሱ፡፡ የብዙልዩ ቋንቋዎች ተማሪዎች የሞዴል አካባቢ እና የሞዴል አካውንት እና የሞዴል አካውንት መሆኑን ከመልካም ንግድ መሆኑን እናገኛለን፡፡ መግቢያችንን ከፈትን https://github.com/socialmediaie/TRAC2020.', 'sq': "Ne paraqesim ekipin tonë `3Idiots' (të quajtur `sdhanshu' në renditjet zyrtare) për detyrat e përbashkëta të Trollit, Aggresionit dhe Kiberbollit (TRAC) 2020. Përqasja jonë mbështetet në rregullimin e modeleve të ndryshme të Transformuesve në të dhënat e ndryshme. Ne gjithashtu hetuam utilitetin e marginalizimit të etiketës së detyrave, klasifikimin e etiketës së përbashkët dhe trajnimin e përbashkët mbi të dhënat shumëgjuhëse si përmirësime të mundshme në modelet tona. Ekipi ynë erdhi i dyti në nëndetyrën angleze A, një i katërti i afërt në nëndetyrën angleze B dhe i treti në 4 nëndetyrat e mbetura. We find the multilingual joint training approach to be the best trade-off between computational efficiency of model deployment and model's evaluation performance.  We open source our approach at  https://github.com/socialmediaie/TRAC2020.", 'af': "Ons stel ons span `3Idiots' (verwys as `sdhanshu' in die offisiele rangings) toegang vir die Trolling, Aggresie en Cyberbullying (TRAC) 2020 gedeelde taak. Ons toegang verlig op fine- tuning van verskillende Transformer modele op die verskillende datastelle. Ons het ook die nutsprogram van taak etiket marginalisasie, joint label klasifikasie en joint training op multilingual datastelle as moontlike verbeteringe aan ons modele gevind. Ons span het tweede in Engels sub-taak A gekom, 'n toe vierde in die Engels sub-taak B en derde in die oorblywende 4 sub-taak. Ons vind die multitaalske koppelige onderwerp toegang om die beste verkoop-af te wees tussen rekenaasjonale effektiviteit van model verwydering en model se evalueringsprestasie. Ons open bron ons toegang op https://github.com/socialmediaie/TRAC2020.", 'hy': 'Մենք ներկայացնում ենք մեր թիմը «3հիմարներ» (որը կոչվում է «սդանշո» պաշտոնական դասակարգում) 2020 թվականի "Թրոլինգի, Ագրեսիայի և Կիբերբուլգի" հանձնարարությունների համար: Մեր մոտեցումը հիմնված է տարբեր տրանսֆերմերի մոդելների բարելավման վրա տարբեր տվյալների համակարգերի վրա: We also investigated the utility of task label marginalization, joint label classification, and joint training on multilingual datasets as possible improvements to our models.  Մեր թիմը սկսեց երկրորդ անգլերեն A-ի ենթախնդրի մեջ, չորրորդ անգլերեն B-ի ենթախնդրի մեջ և երրորդ մնացած 4 ենթախնդրի մեջ: Մենք գտնում ենք, որ բազմալեզու միասին ուսուցման մոտեցումը լավագույն հակամարտությունն է մոդելի օգտագործման հաշվարկների արդյունավետության և մոդելի գնահատման արդյունավետության միջև: We open source our approach at  https://github.com/socialmediaie/TRAC2020.', 'az': 'Biz "3idiots" ekibimizi "sdhanshu" olaraq "Trolling, Aggression and Cyberbullying (TRAC) 2020 şərikli işlər üçün tərəfindən göstəririk. Bizim yaxınlığımız müxtəlif veri qurularında müxtəlif Transformer modellərini düzəltməyə təvəkkül edir. Biz də modellərimizin mümkün düzəltməsi olaraq işləri etiketlərin marginalizasyonu, birlikdə etiketlərin klasifikasyonu və çoxlu dil veri setlərində birlikdə təhsil etdik. Bizim ekibimiz İngilizə A apa görevi ilə ikinci gəldi, İngilizə apa görevi B və üçüncü ilə qalan 4 apa görevi. Biz çoxlu dillərin birlikdə təhsil təhsil metodlarını, modelinin təhsil edilməsi və modelinin değerlendirməsi təhsil etməsi arasında ən yaxşı ticarət olaraq tapırıq. Biz yaxınlığımızı açıq https://github.com/socialmediaie/TRAC2020.', 'cs': "Představujeme náš tým `3Idiots' (označovaný jako `sdhanshu' v oficiálním žebříčku) přístup pro sdílené úkoly Trolling, Aggression a Kyberšikany (TRAC) 2020. Náš přístup se opírá o jemné ladění různých modelů Transformeru na různých datových sadách. Dále jsme zkoumali užitečnost marginalizace štítků úkolů, společné klasifikace štítků a společného školení na mnohojazyčných datových sadách jako možné zlepšení našich modelů. Náš tým byl druhý v anglickém podúkolu A, těsně čtvrtý v anglickém podúkolu B a třetí ve zbývajících čtyřech podúkolech. Vícejazyčný společný tréninkový přístup považujeme za nejlepší kompromis mezi výpočetní efektivitou nasazení modelu a výkonností hodnocení modelu. Open source náš přístup na https://github.com/socialmediaie/TRAC2020.", 'bs': 'Predstavljamo svoj tim "3idioti" (nazvan "sdhanshu" u zvaničnim redovima) pristup za zajedničke zadatke Trolling, Agresije i Cyberbullying (TRAC) 2020. Naš pristup se oslanja na dobro određivanje različitih modela Transformera na različitim podacima. Istražili smo i korisnost marginalizacije etikete zadataka, zajedničke klasifikacije etikete i zajedničke obuke na multijezičkim setima podataka kao moguće poboljšanje naših modela. Naš tim je došao drugi na engleskom podzadatku A, blizu četvrtinu na engleskom podzadatku B i treću u ostalih 4 podzadatka. Nalazimo multijezički zajednički pristup obuke da bude najbolji trgovin između računalne učinkovitosti razvoja modela i učinkovitosti ocjene modela. Otvaramo izvor pristupa https://github.com/socialmediaie/TRAC2020.', 'bn': "আমরা আমাদের দল '৩ নির্দোষ' (আনুষ্ঠানিক পর্যায়ে দেহানশু' নামে অভিহিত করেছি) ট্রোলিং, গ্রেগ্রেশন এবং সাইবার বুলিয়ান (ট্রিএসএ) ২০২০০ শেয়ার কর্মস আমাদের পদক্ষেপ বিভিন্ন তথ্য সংক্রান্ত বিভিন্ন ধরনের ট্রান্সফ্রান্স মডেলের উপর নির্ভর করে। আমাদের মডেলের সম্ভাব্য উন্নয়ন হিসেবে আমরা কাজের লেবেলের মার্মিগ্রেশন, যৌথ লেবেল বিভাগ এবং মাল্টিভাল ডাটাসেটে যৌথ প্রশি আমাদের দল ইংরেজী সাব-কাজ এ-এ দ্বিতীয় ভাষায় এসেছিল, যিনি ইংরেজী সাব-কাজ বি এবং বাকি ৪ সাব-কাজে একটি কাছাকাছি চার জন আমরা অনেক ভাষায় যৌথ প্রশিক্ষণ প্রশিক্ষণের উপায় খুঁজে বের করি যে মডেল প্রতিষ্ঠান এবং মডেলের মূল্য প্রদর্শনের মধ্যে সবচেয়ে ভালো ব্যবসা কর আমরা আমাদের প্রতিক্রিয়া খুলে দেই https://github.com/socialmediaie/TRAC2020.", 'ca': 'Presentam el nostre equip "3Idiots" (anomenat sdhanshu en les classificacions oficials) per a les tasques compartides de Trolling, Aggressió i Cyberbullying (TRAC) 2020. El nostre enfocament es basa en ajustar diversos models de Transformer en els diferents conjunts de dades. També vam investigar la utilitat de marginar l\'etiqueta de tasca, classificar l\'etiqueta conjunta i formar conjuntament els conjunts de dades multilingües com a millors possibles als nostres models. El nostre equip va arribar al segon en la subtasca anglesa A, un quart a la subtasca anglesa B i el tercer en les quatre subtasques restants. Trobem que l\'enfocament multilingüe de formació conjunta és el millor compromís entre l\'eficiència computacional de l\'implantació del model i el rendiment d\'evaluació del model. Ens aproximam de codi obert https://github.com/socialmediaie/TRAC2020.', 'et': "Tutvustame oma meeskonna `3Idiots' (ametlikus edetabelis nimetatakse `sdhanshu' lähenemisviisi Trolling, Aggression ja Cyberbullying (TRAC) 2020 jagatud ülesannete jaoks. Meie lähenemine tugineb erinevate Transformerite mudelite täpsustamisele erinevate andmekogumite põhjal. Samuti uurisime ülesannete märgistuse marginaliseerimise, ühise märgistuse klassifitseerimise ja mitmekeelsete andmekogumite ühise koolituse kasulikkust meie mudelite võimalikuks täiustamiseks. Meie meeskond oli inglise alamülesandes A teisel kohal, inglise alamülesandes B peaaegu neljandal kohal ja ülejäänud neljas alamülesandes kolmandal kohal. Leiame, et mitmekeelne ühine koolitus on parim kompromiss mudeli kasutuselevõtu arvutusliku tõhususe ja mudeli hindamise tulemuslikkuse vahel. Me avame lähtekoodiga oma lähenemisviisi https://github.com/socialmediaie/TRAC2020.", 'fi': "Esittelemme tiimimme `3Idiots' (jota kutsutaan virallisissa rankingissa `sdhanshu') lähestymistavan Trolling, Aggression ja Cyberbullying (TRAC) 2020 jaettuihin tehtäviin. Lähestymistapamme perustuu erilaisten Transformer-mallien hienosäätöön eri aineistojen pohjalta. Tutkimme myös tehtävälapun marginalisoinnin, yhteisen etiketin luokittelun ja monikielisten tietoaineistojen yhteiskoulutuksen hyödyllisyyttä malliemme mahdollisina parannuksina. Tiimimme sijoittui toiseksi englanninkielisessä osatehtävässä A, lähes neljänneksi englanninkielisessä osatehtävässä B ja kolmanneksi neljässä jäljellä olevassa osatehtävässä. Mielestämme monikielinen yhteinen koulutusmenetelmä on paras kompromissi mallin käyttöönoton laskennallisen tehokkuuden ja mallin arviointisuorituskyvyn välillä. Avoimen lähdekoodin lähestymistapamme https://github.com/socialmediaie/TRAC2020.", 'sk': "Predstavljamo našo ekipo `3Idiots' (v uradni lestvici imenovano `sdhanshu' pristop za skupne naloge Trolling, Agression and Cyberbullying (TRAC) 2020. Naš pristop temelji na natančnem nastavitvi različnih modelov transformatorjev na različnih naborih podatkov. Raziskovali smo tudi uporabnost marginalizacije nalepk, skupne klasifikacije nalepk in skupnega usposabljanja o večjezičnih naborih podatkov kot možne izboljšave naših modelov. Naša ekipa je bila druga v angleški podnalogi A, tesno četrta v angleški podnalogi B in tretja v preostalih štirih podnalogah. Večjezični skupni pristop usposabljanja je najboljši kompromis med računalniško učinkovitostjo uvajanja modela in učinkovitostjo ocenjevanja modela. Odprtokodni pristop pri https://github.com/socialmediaie/TRAC2020.", 'ha': "Tuna halatar da jama'ar tudunmu `3 Ididiots' (aka kallo `dan shu' a cikin sararin rasmi) zuwa aikin da aka samu taskõki na Tõrlling, Aggression da Kiberbullyin (TRac) 2020 da aka raba aiki. Mataimakinmu na dõgara a kan tunkuɗe misãlai mãsu yawa na Transformer kan danne-danne-daban. Haƙĩƙa, mun yi ƙidãya da amfani da alamar aikin marginalizing, classifori mai haɗi label, da kuma shirin haɗiya a kan danne-danne-dangane multilingu kamar an iya ƙara wa misalinmu. Team na zo na farko a cikin sub-aikin Ingiriya A, na rubu'in na Ingiriya sub-aikin B da na uku a cikin aikin na bakin 4. Munã s ãmu hanyoyin wa'aikin mulki-mulki zuwa ta kasance mafi kyaun fatauci a tsakanin misalin misalin da muhimmin misalin. Tuna buɗe mataimakanmu a https://github.com/socialmediaie/TRAC2020.", 'he': "אנחנו מציגים את הצוות שלנו '3Idiots' (שנקרא 'sdhanshu' בציונים רשמיים) גישה למשימות המשותפות של הטרולינג, האגרסיה וקייברבולינג (TRAC) 2020. הגישה שלנו סומכת על התאים מודלים טרנספורטרים שונים על קבוצות נתונים שונות. חקרנו גם את השימוש של השימוש בתווית המשימה, מסווג תווית משותף, ואימונים משותפים על קבוצות נתונים רבות שפות כשיפורים אפשריים לדוגמנים שלנו. הצוות שלנו הגיע השני בתפקיד אנגלי א, רביעי קרוב בתפקיד אנגלי ב ושלישי בארבע התפקידים האחרים. אנו מוצאים את גישת האימון המשותפת המרבית לשונות כהסחר הטוב ביותר בין יעילות מחשבית של השימוש מודל לביצוע הערכה של המודל. אנחנו פותחים את הגישה שלנו https://github.com/socialmediaie/TRAC2020.", 'jv': 'Awak dhéwé nambah kelompok "3 idiot" (oleh dika \'sdanshu\' ning resmi adalah) nggawe barang nggawe Tringgé, negoresi lan tambah bantayan karo Perusahaan (TROC) 2020 Ndoleh dhewe ngulinakake sistem sing paling-dibutuhke model Transformer sampeyan neng dataset sing dibutuhke Awakdhéwé éntuk nggunakaé sistem kanggo nggawe gerakan karo task label Awak dhéwé nambah tanggal segondi kanggo nyeneng Sub-task A, njuk sabanjuré wis mungkin inggiles Sub-task B lan tambah wis telat kanggo nambah 4 Sub-tasks Awak dhéwé nglanggar aturan tambah banter-sistem sing dibenakake nggawe gerakan luwih dumateng ingkang sampek kalem nggawe gerakan ingkang dianggap model lan ijol-ijolan model. Awak dhéwé mengakaké kelas telah https://github.com/socialmediaie/TRAC2020.', 'bo': 'ང་ཚོས་གཞུང་གི་གནས་སྟངས་ལ་དབྱིབས་གནད་དོན་གྱི་ཐབས་ལམ་གནང་"3Idiots"སྤྲོད་པ་ཡིན། ང་ཚོའི་གཟུགས་སྐོར་འདིས་གནད་སྡུད་ཚན་མ་འདྲ་བའི་བཟོ་བཅོས་ཆས་མིན་འདུག ང་ཚོས་དུས་ཡོད་ཚད་གླེང་མོལ་གསོག་སུ་འཇུག་པའི་བྱ་རིམ་གྱི་སྤྱོད་སྟངས་ལ་ཞིབ་དཔྱད་བྱས། ང་ཚོའི་དབང་ཆ་ཚོའི་དབྱིན་ཡིག་གཟུགས་ལས་ཀ་གཉིས་པ་དེ་ལས་དབྱིན་ཡིག་ཆ་ལྡན་པའི་ནང་ལས་ དབྱིན་ཡིག་གཟུགས་ལས་ཀ་ཆ་ ང་ཚོས་སྐད་ཡིག ང་ཚོས་རང་གི་གཟུགས་རིས་ཁུངས་ཀྱི་འབྲི་ཚོར་ https://github.com/socialmediaie/TRAC2020.'}
{'en': 'Aggression and Misogyny Detection using  BERT  : A Multi-Task Approach BERT : A Multi-Task Approach', 'ar': 'كشف العدوان وكراهية النساء باستخدام BERT: نهج متعدد المهام', 'es': 'Detección de agresión y misoginia mediante BERT: un enfoque multitarea', 'pt': 'Detecção de agressão e misoginia usando BERT: uma abordagem multitarefa', 'fr': "Détection de l'agressivité et de la misogynie à l'aide du BERT\xa0: une approche multitâche", 'ja': 'BERTを使用したアグレッションとミソジニー検出：マルチタスクアプローチ', 'zh': '用BERT侵厌女症检:多任务法', 'hi': 'आक्रामकता और Misogyny BERT का उपयोग कर पता लगाना: एक बहु कार्य दृष्टिकोण', 'ru': 'Обнаружение агрессии и мизогинии с использованием BERT: многозадачный подход', 'ga': 'Ionsaitheacht agus Brath Misogyny ag baint úsáide as BERT: Cur Chuige Ilthasc', 'ka': 'ბერტის გამოყენებაში ადგრესია და Misogyny განახლება', 'hu': 'Aggresszió és nőgyűlölet felismerése BERT segítségével: többfeladatos megközelítés', 'it': 'Rilevamento di aggressività e misoginia con BERT: un approccio multi-task', 'kk': 'BERT: Көптеген тапсырмалар қатынау', 'lt': 'Aggresijos ir mizogenijos nustatymas naudojant BERT: daugiafunkcinis metodas', 'ms': 'Pengesanan Aggression dan Misogyny menggunakan BERT: A Multi-Task Approach', 'ml': 'BERT ഉപയോഗിക്കുന്ന മുന്\u200dഗണനും വിഷയത്തിലുള്ള ഡിറ്റിക്റ്ററി', 'mk': 'Aggression and Misogyny Detection using BERT: A Multi-Task Approach', 'el': 'Ανίχνευση επιθετικότητας και μισογυνίας με τη χρήση του Μια προσέγγιση πολλαπλών εργασιών', 'mt': 'Aggression and Misogyny Detection using BERT: A Multi-Task Approach', 'mn': 'BERT: Олон үйл ажиллагааны ойлголт', 'no': 'Agrasjon og misogynsk oppdaging ved bruk av BERT: ein tilnærming av fleire oppgåver', 'pl': 'Wykrywanie agresji i misogynii przy użyciu BERT: podejście wielozadaniowe', 'sr': 'Agresija i Misogni detekcija koristeći BERT: Multi-Task Approach', 'ro': 'Detectarea agresiunii și a misoginiei utilizând BERT: o abordare multi-sarcină', 'si': 'BERT 喽脆穵鈥嵿痘喽亨窛喽⑧侗喽亨窓喽编穵 喾冟穭 喽膏窉喾冟窛喽溹窉喽编窉 喾勦窚喽亨窂喽溹侗喾娻侗', 'so': 'Horumarinta iyo baaritaanka shaqo badan', 'ur': 'BERT کے استعمال سے گریسی اور غلطی شناسایی', 'ta': 'பெர்ட் பயன்படுத்தி முன்னேற்றம் மற்றும் பிழை கண்டுபிடிப்பு', 'sv': 'Identifiering av aggression och misogini med BERT: En flerfunktionsmetod', 'uz': 'Comment', 'vi': 'Phát hiện sự tập kích và rối loạn do hỗn tạp sử dụng', 'da': 'Registrering af aggression og misogini ved hjælp af BERT: En multi-opgavetilgang', 'nl': 'Detectie van agressie en misogynie met behulp van BERT: een multitask aanpak', 'de': 'Aggression und Misogynie Detektion mit BERT: Ein Multi-Task Ansatz', 'ko': 'BERT의 공격과 혐오 검출을 활용한 다중 임무 방법', 'fa': 'با استفاده از BERT: یک نزدیک بسیاری از کار', 'hr': 'Agresija i misoginija otkrivanje koristeći BERT: Multi-Task Approach', 'bg': 'Установяване на агресия и омраза с помощта на подхода с множество задачи', 'id': 'Deteksi Aggression dan Misogyny menggunakan BERT: A Multi-Task Approach', 'sw': 'Utafiti wa Ushirikiano na Uelelezi kwa kutumia BERT: Utafiti wa Kazi nyingi', 'tr': 'BERT: A Multi-Task Approach', 'af': "Aggresie en Misogyny-beskrywing gebruik BERT: ' n Multi- Task Approach", 'am': 'Aggression and Misogyny Detection using BERT: A Multi-Task Approach', 'az': 'BERT vasitəsilə Agresiya və Misogyny Tanıma: Çoxlu Görüş Yaxınlığı', 'bn': 'বেরেট ব্যবহার করে অগ্রগতি এবং বিভিন্ন সনাক্তি: একটি বহুবিধ কাজের আগমন', 'bs': 'Agresija i kriminalna detekcija koristeći BERT: Multi-Task Approach', 'cs': 'Detekce agrese a misogynie pomocí BERT: víceúkolový přístup', 'et': 'Agressiooni ja misogünia tuvastamine BERT-i abil: mitme ülesandega lähenemisviis', 'hy': 'Ագրեսիայի և խաբեության հայտնաբերման միջոցով BER-ը՝ բազմախնդիրների մոտեցում', 'fi': 'Aggression and Misogyny Detection using BERT: A Multi-Task Approach', 'sq': 'Detektimi i agresionit dhe mizogjinisë duke përdorur BERT: një metodë shumë-detyrash', 'ca': "Detecció d'agressió i misogínia utilitzant BERT: Un enfocament multitascat", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Zaznavanje agresije in misogine z uporabo BERT: večopravilni pristop', 'he': 'גילוי התקף ומיסוגיניה באמצעות BERT: Approach Multi-Tasks', 'ha': 'KCharselect unicode block name', 'bo': 'BERT: A Multi-Task Approach'}
{'en': 'In recent times, the focus of the NLP community has increased towards offensive language, aggression, and hate-speech detection. This paper presents our system for TRAC-2 shared task on Aggression Identification (sub-task A) and Misogynistic Aggression Identification (sub-task B). The data for this shared  task  is provided in three different languages-English,  Hindi , and  Bengali . Each data instance is annotated into one of the three aggression classes-Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes-Gendered and Non-Gendered. We propose an end-to-end neural model using  attention  on top of BERT that incorporates a multi-task learning paradigm to address both the sub-tasks simultaneously. Our team, na14, scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task. The code and the model weights are publicly available at https://github.com/NiloofarSafi/TRAC-2. Keywords :  Aggression ,  Misogyny ,  Abusive Language , Hate-Speech Detection, BERT,  NLP ,  Neural Networks ,  Social Media', 'ar': 'في الآونة الأخيرة ، ازداد تركيز مجتمع البرمجة اللغوية العصبية نحو اللغة الهجومية والعدوانية واكتشاف الكلام الذي يحض على الكراهية. تقدم هذه الورقة نظامنا لمهمة TRAC-2 المشتركة حول "تحديد العدوان" (المهمة الفرعية أ) و "العدوان الكاره للنساء تحديد "(المهمة الفرعية ب). يتم توفير البيانات الخاصة بهذه المهمة المشتركة بثلاث لغات مختلفة - الإنجليزية والهندية والبنغالية. يتم شرح كل مثيل بيانات في واحدة من فئات العدوان الثلاث - غير عدواني ، عدواني في الخفاء ، عدواني بشكل علني ، بالإضافة إلى إحدى فئتي كره النساء - النوع الاجتماعي وغير الجنساني. نقترح نموذجًا عصبيًا شاملاً باستخدام الانتباه أعلى BERT الذي يشتمل على نموذج تعليمي متعدد المهام لمعالجة كل من المهام الفرعية في وقت واحد. سجل فريقنا "na14" 0.8579 بمقياس F1 مرجح في المهمة الفرعية باللغة الإنجليزية B وحصل على المركز الثالث من بين 15 فريقًا لهذه المهمة. الكود وأوزان النموذج متاحة للجمهور على https://github.com/NiloofarSafi/TRAC-2. الكلمات الرئيسية: العدوان ، كره النساء ، اللغة المسيئة ، كشف الكلام الذي يحض على الكراهية ، BERT ، البرمجة اللغوية العصبية ، الشبكات العصبية ، وسائل التواصل الاجتماعي', 'es': 'En los últimos tiempos, el enfoque de la comunidad de PNL ha aumentado hacia la detección del lenguaje ofensivo, la agresión y el discurso de odio. Este artículo presenta nuestro sistema para la tarea compartida del TRAC-2 sobre «Identificación de la agresión» (subtarea A) e «Identificación de la agresión misógina» (subtarea B). Los datos de esta tarea compartida se proporcionan en tres idiomas diferentes: inglés, hindi y bengalí. Cada instancia de datos se anota en una de las tres clases de agresión: no agresiva, encubiertamente agresiva, abiertamente agresiva, así como una de las dos clases de misoginia: con género y sin género. Proponemos un modelo neuronal de extremo a extremo que utiliza la atención por encima de BERT que incorpora un paradigma de aprendizaje multitarea para abordar ambas subtareas simultáneamente. Nuestro equipo, «na14», obtuvo 0.8579 medidas de F1 ponderadas en la subtarea B en inglés y se aseguró el tercer rango de 15 equipos para la tarea. El código y los pesos del modelo están disponibles públicamente en https://github.com/NiloofarSafi/TRAC-2. Palabras clave: Agresión, Misoginia, Lenguaje abusivo, Detección de incitación al odio, BERT, PNL, Redes neuronales, Redes sociales', 'pt': 'Nos últimos tempos, o foco da comunidade de PNL aumentou para linguagem ofensiva, agressão e detecção de discurso de ódio. Identificação” (subtarefa B). Os dados para esta tarefa compartilhada são fornecidos em três idiomas diferentes - inglês, hindi e bengali. Cada instância de dados é anotada em uma das três classes de agressão - Não Agressiva, Secretamente Agressiva, Claramente Agressiva, bem como uma das duas classes de misoginia - Gênero e Não Gênero. Propomos um modelo neural de ponta a ponta usando a atenção em cima do BERT que incorpora um paradigma de aprendizado multitarefa para abordar ambas as subtarefas simultaneamente. Nossa equipe, “na14”, marcou 0,8579 na medida F1 ponderada na subtarefa B de inglês e garantiu o 3º lugar entre 15 equipes para a tarefa. O código e os pesos do modelo estão disponíveis publicamente em https://github.com/NiloofarSafi/TRAC-2. Palavras-chave: Agressão, Misoginia, Linguagem Abusiva, Detecção de Discurso de Ódio, BERT, PNL, Redes Neurais, Mídias Sociais', 'fr': "Ces derniers temps, la communauté de la PNL s'est davantage concentrée sur la détection du langage offensant, de l'agressivité et des discours haineux. Cet article présente notre système pour la tâche partagée TRAC-2 sur «\xa0l'identification de l'agression\xa0» (sous-tâche A) et «\xa0l'identification de l'agression misogyne\xa0» (sous-tâche B). Les données de cette tâche partagée sont fournies en trois langues différentes\xa0: anglais, hindi et bengali. Chaque instance de données est annotée dans l'une des trois classes d'agressivité - Non agressif, Discrètement agressif, ouvertement agressif, ainsi que dans l'une des deux classes de misogynie - Gendered et Non-Gender. Nous proposons un modèle neuronal de bout en bout utilisant l'attention en plus du BERT qui intègre un paradigme d'apprentissage multitâche pour traiter les deux sous-tâches simultanément. Notre équipe, «\xa0na14\xa0», a obtenu 0,8579 mesures F1 pondérées sur la sous-tâche anglaise B et a obtenu le 3e rang sur 15 équipes pour cette tâche. Le code et les poids du modèle sont accessibles au public à l'adresse https://github.com/NiloofarSafi/TRAC-2. Mots-clés\xa0: Agressivité, Misogynie, Langage abusif, Détection de discours haineux, BERT, TALN, Réseaux de neurones, Réseaux sociaux", 'ja': '近年、NLPコミュニティの焦点は、攻撃的な言語、攻撃性、およびヘイトスピーチ検出に向かって増加しています。本稿では、「侵略識別」（サブタスクA ）および「ミソジニー的侵略識別」（サブタスクB ）に関するTRAC -2共有タスクのためのシステムを紹介します。 この共有タスクのデータは、英語、ヒンディー語、ベンガル語の3つの言語で提供されています。 各データインスタンスは、非攻撃的、秘密裏に攻撃的、露骨に攻撃的という3つの攻撃クラスと、ジェンダー化されたと非ジェンダー化された2つのミソジニークラスのいずれかに注釈が付けられています。 私たちは、両方のサブタスクに同時に対処するためのマルチタスク学習パラダイムを組み込んだ、BERTの上に注目を使用したエンドツーエンドのニューラルモデルを提案します。 私たちのチーム「na 14」は、英語のサブタスクBで重み付けされたF 1メジャーを0.8579得点し、タスクの15チーム中3位を確保しました。 コードとモデルの重みは、https://github.com/NiloofarSafi/TRAC-2で公開されています。 キーワード：アグレッション、ミソジニー、虐待言語、ヘイトスピーチ検出、BERT、NLP、ニューラルネットワークス、ソーシャルメディア', 'hi': 'हाल के दिनों में, एनएलपी समुदाय का ध्यान आक्रामक भाषा, आक्रामकता और नफरत-भाषण का पता लगाने की ओर बढ़ गया है। यह पेपर "आक्रामकता पहचान" (उप-कार्य ए) और "Misogynistic आक्रामकता पहचान" (उप-कार्य बी) पर TRAC-2 साझा कार्य के लिए हमारी प्रणाली प्रस्तुत करता है। इस साझा कार्य के लिए डेटा तीन अलग-अलग भाषाओं - अंग्रेजी, हिंदी और बंगाली में प्रदान किया गया है। प्रत्येक डेटा उदाहरण को तीन आक्रामकता वर्गों में से एक में एनोटेट किया जाता है - आक्रामक नहीं, गुप्त रूप से आक्रामक, अत्यधिक आक्रामक, साथ ही साथ दो misogyny वर्गों में से एक - लिंग और गैर-लिंग। हम BERT के शीर्ष पर ध्यान का उपयोग करके एक एंड-टू-एंड तंत्रिका मॉडल का प्रस्ताव करते हैं जिसमें दोनों उप-कार्यों को एक साथ संबोधित करने के लिए एक बहु-कार्य सीखने के प्रतिमान को शामिल किया गया है। हमारी टीम, "na14", ने अंग्रेजी उप-कार्य बी पर 0.8579 भारित F1-माप स्कोर किया और कार्य के लिए 15 टीमों में से तीसरा स्थान हासिल किया। कोड और मॉडल वजन सार्वजनिक रूप से https://github.com/NiloofarSafi/TRAC-2 पर उपलब्ध हैं। कीवर्ड: आक्रामकता, Misogyny, अपमानजनक भाषा, हेट स्पीच डिटेक्शन, BERT, NLP, तंत्रिका नेटवर्क, सामाजिक मीडिया', 'zh': '近者,NLP社区焦点益集攻击性语,侵怨检测。 本文引TRAC-2"侵识"(子职A)与"恶女侵识"(子职B)之共同任务统。 凡此三者, - 英语印地语孟加拉语。 每数例注为三攻击性之一 - 非攻击性,隐攻击性公攻击性,及二厌女症之一 - 性别与非性别。 建一端到之神经,注意于BERT之上,合多任务学式,以两决之。 吾团队"na14"B得0.8579加权F1于英语子,而第三于其15团队。 代码与模形权重于 https://github.com/NiloofarSafi/TRAC-2 公给。 关键词: 侵 , 厌女症, 诟言, 仇言检, BERT, NLP, 神经网络, 社交媒体', 'ru': 'В последнее время сообщество NLP стало уделять больше внимания оскорбительному языку, агрессии и обнаружению ненавистнических высказываний. В этом документе представлена наша система для общей задачи TRAC-2 «Идентификация агрессии» (подзадача A) и «Идентификация женоненавистнической агрессии» (подзадача B). Данные по этой общей задаче представлены на трех разных языках - английском, хинди и бенгальском. Каждый экземпляр данных аннотируется к одному из трех классов агрессии - не агрессивный, скрыто агрессивный, открыто агрессивный, а также к одному из двух классов женоненавистничества - гендерному и негендерному. Мы предлагаем сквозную нейронную модель с использованием внимания поверх BERT, которая включает парадигму многозадачного обучения для одновременного решения обеих подзадач. Наша команда, «na14», набрала 0,8579 взвешенной меры F1 в английской подзадаче B и заняла 3-е место из 15 команд по заданию. Код и вес модели находятся в открытом доступе по адресу https://github.com/NiloofarSafi/TRAC-2. Ключевые слова: агрессия, мизогиния, оскорбительный язык, обнаружение ненавистнической речи, БЕРТ, NLP, нейронные сети, социальные сети', 'ga': 'Le blianta beaga anuas, tá fócas an phobail NLP méadaithe i dtreo teanga maslach, ionsaí, agus braite fuath-urlabhra. Cuireann an páipéar seo i láthair ár gcóras do TRAC-2 tasc roinnte ar “Aggression Aitheantas” (fo-thasc A) agus “Misogynistic Ionsaí Aitheantas” (fothasc B). Cuirtear na sonraí don tasc roinnte seo ar fáil i dtrí theanga éagsúla - Béarla, Hiondúis agus Beangáilis. Déantar gach cás sonraí a anótáil i gceann amháin de na trí aicme ionsaitheachta - Neamh- Ionsaitheach, Fostaithe go Foiléir, Ró-Ionsaitheach, chomh maith le ceann amháin den dá rang misogyny - Inscne agus Neamhinscne. Molaimid samhail néarúil ceann go ceann ag baint úsáide as aird ar bharr CRET a ionchorpraíonn paradigm foghlama ilthascanna chun aghaidh a thabhairt ar an dá fhothasc ag an am céanna. Scóráil ár bhfoireann, “na14”, 0.8579 beart F1 ualaithe ar fhothasc Béarla B agus bhain siad an 3ú háit amach as 15 fhoireann don tasc. Tá an cód agus na meáchain mhúnla ar fáil go poiblí ag https://github.com/NiloofarSafi/TRAC-2. Eochairfhocail: Ionsaí, Misogyny, Teanga Mhí-úsáideach, Brath Fuath-Urlabhra, BERT, NLP, Líonraí Néaracha, Na Meáin Shóisialta', 'el': "Τον τελευταίο καιρό, η εστίαση της κοινότητας έχει αυξηθεί προς την προσβλητική γλώσσα, την επιθετικότητα και την ανίχνευση ρητορικών μίσους. Η παρούσα εργασία παρουσιάζει το σύστημά μας για την κοινή εργασία TRAC-2 σχετικά με τον προσδιορισμό της συγκέντρωσης (υποεργασία Α) και τον προσδιορισμό της μισογυνιστικής συγκέντρωσης (υποεργασία Β). Τα δεδομένα για αυτήν την κοινή εργασία παρέχονται σε τρεις διαφορετικές γλώσσες: Αγγλικά, Χίντι και Βεγγαλικά. Κάθε παρουσία δεδομένων σημειώνεται σε μία από τις τρεις κατηγορίες επιθετικότητας: Όχι επιθετική, Κρυμμένα επιθετική, Υπερβολικά επιθετική, καθώς και σε μία από τις δύο κατηγορίες μισογυνίας: Γεννημένη και Μη γενετική. Προτείνουμε ένα ολοκληρωμένο νευρωνικό μοντέλο που χρησιμοποιεί προσοχή πάνω από το το οποίο ενσωματώνει ένα μοντέλο εκμάθησης πολλαπλών εργασιών για να αντιμετωπίσει και τις δύο δευτερεύουσες εργασίες ταυτόχρονα. Η ομάδα μας, 'να14', πέτυχε 0.8579 σταθμισμένο μέτρο F1 στην αγγλική δευτερεύουσα εργασία Β και εξασφάλισε 3η θέση από τις 15 ομάδες για την αποστολή. Ο κώδικας και τα βάρη του υποδείγματος είναι δημόσια διαθέσιμα στη διεύθυνση: https://github.com/NiloofarSafi/TRAC-2. Λέξεις-κλειδιά: Aggression, Misogyny, καταχρηστική γλώσσα, ανίχνευση μίσους-ομιλίας, BERT, ΝLP, Νευρικά Δίκτυα, Κοινωνικά Μέσα", 'hu': 'Az utóbbi időkben az NLP közösség egyre inkább a sértő nyelv, az agresszió és a gyűlölet-beszéd felismerése iránt összpontosított. Ez a tanulmány bemutatja a TRAC-2 megosztott feladat rendszerét az "Aggressziós azonosítás" (A) és a "Misogin Aggressziós azonosítás" (B) alfeladat). A megosztott feladathoz kapcsolódó adatok három különböző nyelven - angolul, hindi és bengáli. Minden adatpéldány a három agressziós osztály egyikébe van jegyzetelve - Nem agresszív, Titkos agresszív, Túl agresszív, valamint a két nőgyűlölet osztály egyikébe - Gendered és Non-Gendered. Egy olyan end-to-end neurális modellt javasolunk, amely figyelmet nyújt a BERT tetejére, és amely magában foglalja a többfeladatos tanulási paradigmát, hogy egyidejűleg kezelje mindkét alfeladatot. Csapatunk, \'na14\', 0,8579 súlyozott F1-mérést szerzett az angol B alcsoportban, és 15 csapat közül harmadik helyet ért el a feladatra. A kód és a modellsúlyok nyilvánosan hozzáférhetők a következő oldalon: https://github.com/NiloofarSafi/TRAC-2. Kulcsszavak: Aggresszió, Misoginia, Abuzív nyelv, Gyűlölet-beszédfelismerés, BERT, NLP, Neurális hálózatok, Közösségi média', 'ka': 'ოჲჟლვენთრვ გპვმვნთ, კჲნუვკრსპაუთწრა ნა კჲმოსნთუთწრა ნა NLP ჟვ ოჲგყპქთ გ ჲტვნჟთგნთწ ენვჟ, ადპვჟთწრა თ ჲრკპთგანვრჲ ნა მპაჱნთ დჲგჲპთ. ეს გვერდის ჩვენი სისტემა TRAC-2 გაყოფილი დავალებისთვის \'Aggression Identification\' (sub-task A) და \'Misogynistic Aggression Identification\' (sub-task B)\'. ამ გაყოფილი დავალების მონაცემები სამი განსხვავებული ენებით - ანგლისური, ჰინდური და ბენდალიური. ყოველ მონაცემების ინსტანცია იყოს სამი ადგრესის კლასის ერთად - არა ადგრესიური, უფრო ადგრესიური, უფრო ადგრესიური, და ერთად ორი არგესიური კლასის ერთად - Gendered და Non-Gendered. ჩვენ გვეყველა ნეიროლური მოდელს, რომელიც BERT-ის მარცხენა გამოყენებს, რომელიც მრავალური დასწავლების პარადიგმა დავყენებს, რომელიც მრავალური დასწავლების პარადიგმა, რომელიც ჩვენი ჯგუფი "na14", 0.8579 წერტილი F1-ზომა ანგლისური სამუშაო B და დაახლოებით სამუშაო წერტილი 15 ჯგუფის განმავლობაში. კოდი და მოდელური მნიშვნელობა ადამიანებით ხელსაწყებელია https://github.com/NiloofarSafi/TRAC-2. Keywords: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media', 'it': "Negli ultimi tempi, l'attenzione della comunità NLP è aumentata verso il linguaggio offensivo, l'aggressività e la rilevazione del discorso d'odio. Questo articolo presenta il nostro sistema per il compito condiviso TRAC-2 su 'Aggression Identification' (sub-task A) e 'Misoginistic Aggression Identification' (sub-task B). I dati per questa attività condivisa sono forniti in tre lingue diverse: inglese, hindi e bengalese. Ogni istanza di dati è annotata in una delle tre classi di aggressività - Non aggressiva, Coverly Aggressiva, Troppo aggressiva, così come in una delle due classi di misoginia - Gendered e Non-Gendered. Proponiamo un modello neurale end-to-end utilizzando l'attenzione sopra BERT che incorpora un paradigma di apprendimento multi-task per affrontare entrambi i sub-task contemporaneamente. La nostra squadra, 'na14', ha segnato 0,8579 F1-misura ponderata nel sottocompito inglese B e si è assicurata il terzo posto su 15 squadre per il compito. Il codice e i pesi del modello sono disponibili al pubblico all'indirizzo https://github.com/NiloofarSafi/TRAC-2. Parole chiave: Aggressione, Misoginia, Linguaggio Abusivo, Rilevazione dell'odio, BERT, NLP, Reti Neurali, Social Media", 'kk': 'Соңғы уақытта NLP компаниясының көңіл түсінікті тіл, агрессия және қарсы сөйлерді табуға көтерді. Бұл қағаз TRAC- 2 ортақтастырылған тапсырманың жүйесін \'Aggression Identification\' (A ішкі тапсырма) және \'Misogynistic Aggression Identification\' (B ішкі тапсырма) жүйесінде көрсетеді. Бұл ортақ тапсырманың деректері үш түрлі тілде - ағылшын, хинди және бенгали. Әрбір деректер инстанциясы үш агрессиялық классының біріне белгіленіп тұрады - сәйкес емес, мәліметті сәйкес, үлкен сәйкес, сондай-ақ екі қайталау классының бірі - жалғастырылған және жалғастырылмаған. Біз BERT үстінде бірнеше тапсырмаларды оқыту парадигмін бір-бір ішкі тапсырмалардың екі ішкі тапсырмаларды біріктіру үшін соңындағы неврал үлгісін қолданамыз. Біздің командамыз "na14", 0,8579 өлшемі ағылшын ішкі тапсырмасында F1-өлшемі, бұл тапсырма үшін 15 топтардан 3-ші ретінде қауіпсіз. Код мен үлгі жиілігі жалпы https://github.com/NiloofarSafi/TRAC-2. Көздегі сөздер: Aggression, Misogyny, Abusive Language, Hate- Speech Detection, BERT, NLP, Neural Networks, Social Media', 'ml': "അടുത്ത സമയങ്ങളില്\u200d, NLP സമൂഹത്തിന്റെ ശ്രദ്ധ കൂടിക്കൊണ്ടിരിക്കുന്നത് ആക്രമണഭാഷയിലേക്കും, അക്രമത്തിലേക്കും, വെറു ഈ പത്രത്തില്\u200d 'ആഗ്രേഷന്\u200d തിരിച്ചറിയുന്നത്' (സബ്- ജോലി A) എന്നിട്ടും 'മിസോഗിനിസ്റ്റിക് അഗ്രേഷന്\u200d തിരിച്ചറിയുന്നതിനുള്ള സിസ്റ്റ ഈ പങ്കെടുത്ത ജോലിക്കുള്ള വിവരങ്ങള്\u200d മൂന്നു വ്യത്യസ്ത ഭാഷകളില്\u200d ലഭ്യമാക്കുന്നു. ഇംഗ്ലീഷ്, ഹിന്ദി,  എല്ലാ ഡേറ്റാ ഉദാഹരണങ്ങളും മൂന്ന് അക്രമത്തിന്റെ ക്ലാസില്\u200d ഒരാളിലേക്ക് വിഷമിക്കുന്നു - അഗ്രാഗ്രാസ്റ്റ് അല്ല, പ്രധാനപൂര്\u200dണ്ണമായ അഗ്രാസ്റ്റീവ്, മ ബെര്\u200dട്ടിയുടെ മുകളില്\u200d ശ്രദ്ധ പ്രയോഗിച്ച് അവസാനം അവസാനിക്കുന്ന ന്യൂറല്\u200d മോഡല്\u200d ഞങ്ങള്\u200d പ്രായശ്ചിത്തം ചെയ്യുന്നു. അത് ഒരു പല ജോലിയുടെ പ നമ്മുടെ ടീം നാ14, 0. 8579 ഇംഗ്ലീഷ് ഉപാധി ബിയില്\u200d തൂക്കം എഫ്1-അളവില്\u200d നിന്നും 15 ടീമില്\u200d നിന്നും മൂന്നാം പടി സുരക്ഷിച്ചു. കോഡും മോഡല്\u200d തൂക്കങ്ങളും പ്രസിദ്ധമായി ലഭ്യമാണ് https://github.com/NiloofarSafi/TRAC-2. കീവോര്\u200dഡുകള്\u200d: ഗ്രാഗ്രേഷന്\u200d, മിസോഗിനി, അബുസിവ് ഭാഷ, വെറുപ്പ്-സംസാരം ഡിറ്റീഷന്\u200d, ബെര്\u200dട്ടി, NLP, നെയുറല്\u200d നെറ്റോവര്\u200dക്കുകള്\u200d,", 'mt': "F’dawn l-aħħar żminijiet, il-fokus tal-komunità NLP żdied lejn lingwa offensiva, aggressjoni u detezzjoni ta’ diskors ta’ mibegħda. Dan id-dokument jippreżenta s-sistema tagħna għall-kompitu kondiviż TRAC-2 dwar 'Identifikazzjoni tal-Aggressjoni' (sottokompitu A) u 'Identifikazzjoni Misoġenistika tal-Aggressjoni' (sottokompitu B). Id-dejta għal dan il-kompitu kondiviż hija pprovduta fi tliet lingwi differenti - l-Ingliż, l-Indjan u l-Bengali. Kull każ ta’ dejta huwa annotat f’waħda mit-tliet klassijiet ta’ aggressjoni - Mhux Aggressiva, Aggressiva b’mod Kopert, Aggressiva b’mod Soprattiv, kif ukoll f’waħda miż-żewġ klassijiet ta’ misoġinja - Sess u Mhux Sess. Aħna nipproponu mudell newrali minn tarf sa tarf li juża l-attenzjoni fuq il-BERT li jinkorpora paradigma ta’ tagħlim multikompiti biex jindirizza ż-żewġ sottokompiti simultanjament. It-tim tagħna, 'na14', ikklassifika 0.8579 miżura F1 peżata fuq is-sottokompitu Ingliż B u assigurat it-tielet klassifika minn 15-il tim għall-kompitu. Il-kodiċi u l-piżijiet tal-mudell huma disponibbli pubblikament fuq https://github.com/NiloofarSafi/TRAC-2. Il-kliem ewlieni: Aggressjoni, Misoġinja, Lingwa Abużiva, Sejbien ta’ Ħoss tal-Mibegħda, BERT, NLP, Netwerks Newrali, Midja Soċjali", 'lt': 'Pastaruoju metu NLP bendruomenė daugiau dėmesio skyrė žiauriai kalbai, agresijai ir neapykantos kalbų aptikimui. Šiame dokumente pristatoma mūsų TRAC-2 bendros užduoties „Aggresijos identifikavimas“ (A subužduotis) ir „Misogininis agresijos identifikavimas“ (B subužduotis) sistema. Šios bendros užduoties duomenys pateikiami trimis skirtingomis kalbomis - anglų, hindų ir bengalų kalbomis. Kiekvienas duomenų pavyzdys yra įrašytas į vieną iš trijų agresijos klasių - Ne agresyvus, apskritai agresyvus, pernelyg agresyvus, taip pat į vieną iš dviejų nelygybės klasių - lytis ir nelygybė. Mes siūlome, kad būtų sukurtas visapusiškas neurologinis modelis, kuriame be BERT būtų skiriamas dėmesys, kuriame būtų numatyta daugiafunkcinio mokymosi paradigm a, siekiant vienu metu spręsti abi subužduotis. Mūsų komanda "na14" įgijo 0,8579 svertinio F1 matavimo Anglijos B papunktyje ir užtikrino trečią rangą iš 15 komandų. Kodas ir modelio svoriai viešai skelbiami https://github.com/NiloofarSafi/TRAC-2. Pagrindiniai žodžiai: agresija, mizoginija, piktnaudžiavimas kalba, neapykantos kalbos aptikimas, BERT, NLP, nerviniai tinklai, socialinė žiniasklaida', 'no': 'I tidlegare har fokuset på NLP-samfunnet økt mot offensivspråk, aggresjon og hatespråk. Denne papiret viser systemet vårt for delt oppgåve TRAC-2 på « Aggressidentifikasjon » (underoppgåve A) og « Misogynistisk Aggressidentifikasjon » (underoppgåve B). Data for denne delte oppgåva er tilgjengelege i tre ulike språk – engelsk, hindisk og Bengalisk. Kvar datainstans blir oppmerkt i ein av de tre agresasjonsklassene – Ikkje Aggresiv, Aggresiv, Overgrad Aggresiv, Og ein av dei to feogynske klassene – Gendered og Ikkje Gendered. Vi foreslår ein neuralmodell for slutt til slutt ved å bruka oppmerksomheten på toppen av BERT som inkluderer ein paradigm for å lære fleire oppgåver for å handtera begge underoppgåver samtidig. Gruppen vårt « na14 », rekna 0,8579 vekta F1-mål på engelsk underoppgåve B og sikker tredje rank ut av 15 grupper for oppgåva. Koden og modellevekten er tilgjengeleg offentlig på https://github.com/NiloofarSafi/TRAC-2. Nøkkelord: Aggress, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media', 'ms': "Dalam masa-masa terakhir, fokus komuniti NLP telah meningkat ke arah bahasa yang menyerang, agresi, dan pengesan ucapan benci. This paper presents our system for TRAC-2 shared task on 'Aggression Identification' (sub-task A) and 'Misogynistic Aggression Identification' (sub-task B).  The data for this shared task is provided in three different languages - English, Hindi, and Bengali.  Setiap contoh data dicatat ke salah satu dari tiga kelas agresi - Tidak Aggressive, Covertely Aggressive, Overly Aggressive, dan salah satu dari dua kelas misogyny - Gender dan Non-Gender. Kami cadangkan model saraf akhir-akhir menggunakan perhatian di atas BERT yang mengandungi paradigm a pembelajaran berbilang-tugas untuk mengatasi kedua-dua sub-tugas secara bersamaan. Pasukan kami, 'na14', mencetak 0.8579 F1-ukuran berat pada sub-tugas Inggeris B dan mendapat peringkat ketiga daripada 15 pasukan untuk tugas. The code and the model weights are publicly available at  https://github.com/NiloofarSafi/TRAC-2. Kata-kata kunci: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media", 'pl': 'W ostatnim czasie skupienie się społeczności NLP wzrosło na obraźliwym języku, agresji i wykrywaniu mowy nienawiści. W artykule przedstawiono nasz system wspólnego zadania TRAC-2 na temat identyfikacji agresji (podzadanie A) i misogynistycznej identyfikacji agresji (podzadanie B). Dane dotyczące tego wspólnego zadania są dostarczane w trzech różnych językach: angielskim, hindi i bengalskim. Każda instancja danych jest podana do jednej z trzech klas agresji: Nieagresywna, Ukryta agresywna, Nadmiernie agresywna, a także jednej z dwóch klas mizoginii: Gendered i Non-Gendered. Proponujemy kompleksowy model neuronowy wykorzystujący uwagę na szczycie BERT, który zawiera wielozadaniowy paradygmat uczenia się, aby rozwiązać oba podzadania jednocześnie. Nasz zespół, "na14", zdobył 0.8579 ważoną miarę F1 na angielskim podzadaniu B i zdobył trzecie miejsce spośród piętnastu drużyn do tego zadania. Kod i wagi modelu są publicznie dostępne pod adresem: https://github.com/NiloofarSafi/TRAC-2. Słowa kluczowe: agresja, misogynia, nadużywanie języka, wykrywanie mowy nienawiści, BERT, NLP, sieci neuronowe, media społecznościowe', 'mn': 'Сүүлийн үед NLP-ын нийгмийн төвлөрөл нь хүчирхийллэг хэл, хүчирхийллэл, үзэн ядах ярианы нээлт рүү нэмэгдсэн. Энэ цаас бидний TRAC-2 хуваалтын ажлын системийг \'Aggression Identification\' (sub-task A) болон \'Misogynistic Aggression Identification\' (sub-task B) дээр харуулдаг. Энэ хуваалцагдсан ажлын мэдээллийг 3 өөр хэл дээр өгсөн байна: Англи, Хинди, Бенгали. Бүх өгөгдлийн жишээ нь гурван агрессийн хичээлийн нэг хэсэгт анзаарагдаг. Гэтэл агрессийн, нийтлэг агрессийн, ихэвчлэн агрессийн, мөн хоёр буруу хичээлийн нэг хэсэгт анзаарагдаг. Бид BERT дээрх анхаарлыг ашиглаж, олон ажлын суралцах парадигм бүрдүүлдэг мэдрэлийн загварын төгсгөл загварыг санал болгож байна. Бидний баг "na14" нь Англи хэлний B суб-даалгаварын хэмжээнд 0.8579 хэмжээтэй бөгөөд ажлын 15 багийн 3 хэмжээнд хадгалагдсан. Код болон загварын жин олон нийтэд https://github.com/NiloofarSafi/TRAC-2. Товчтой үг: Агресс, Мизогини, Абсоцивны хэл, Харамсалтай яриаг олох, BERT, NLP, Цөмийн сүлжээг, Нийгмийн мэдээлэл', 'ro': 'În ultimul timp, accentul comunității PNL a crescut către limbajul ofensator, agresiunea și detectarea discursului de ură. Această lucrare prezintă sistemul nostru pentru activitatea comună TRAC-2 privind "Identificarea agresiunii" (sub-sarcina A) și "Identificarea agresiunii misogine" (sub-sarcina B). Datele pentru această sarcină partajată sunt furnizate în trei limbi diferite - engleză, hindi și bengală. Fiecare instanță de date este adnotată în una dintre cele trei clase de agresiune - Nu agresiv, Acoperit agresiv, Excesiv agresiv, precum și una dintre cele două clase de misoginie - Gendered și Non-Gendered. Propunem un model neural end-to-end folosind atenția deasupra BERT, care încorporează o paradigmă de învățare multi-task pentru a aborda simultan ambele subsarcini. Echipa noastră, "na14", a marcat 0,8579 măsură F1 ponderată pe subsarcina engleză B și a asigurat locul 3 din 15 echipe pentru sarcină. Codul și greutățile modelului sunt disponibile public la adresa https://github.com/NiloofarSafi/TRAC-2. Cuvinte cheie: agresiune, mizoginie, limbaj abuziv, detectarea vorbirii de ură, BERT, NLP, Rețele neurale, Social Media', 'sr': 'U poslednje vreme, fokus zajednice NLP povećao se ka ofanzivnom jeziku, agresiji i otkrivanju govora mržnje. Ovaj papir predstavlja naš sistem za zajednički zadatak TRAC-2 o "Identifikaciji agresije" (podzadatak A) i "Identifikaciji misoginističke agresije" (podzadatak B). Podaci o ovom zajedničkom zadatku pružaju se na tri različita jezika - engleski, Hindi i Bengali. Svaki primer podataka je annotiran u jednu od tri klase agresije - ne Aggresivno, Prikriveno Aggresivno, Previše Aggresivno, kao i jednu od dva klasa misoginije - Gendered i Non-Gendered. Predlažemo neuralni model kraja do kraja koristeći pažnju na vrhu BERT-a koja uključuje paradigmu učenja višezadataka kako bi se istovremeno obratila oba podzadataka. Naš tim, na14, rezultirao je 0,8579 težine F1-mjere na engleskom podzadatku B i osigurao treći red od 15 tima za zadatak. Kod i model težine su javno dostupne na https://github.com/NiloofarSafi/TRAC-2. Ključne reči: Agresija, Misognija, Abuzivna jezika, Detekcija mržnje-govora, BERT, NLP, Neuralne mreže, Socijalne medije', 'so': "Muddooyinkii ugu dambeeyey, Fokuska bulshada NLP ayaa ku kordhay luqada xadgudubka, xadgudubka iyo baahida hadalka nacayb. Warqaddan waxaa soo saara nidaamka TRAC-2 oo lagu qaybiyey shaqadeeda 'Aqoonsiga Aggression' (sub-task A) iyo 'Misogynistic Aggression Identification' (sub-task B). Macluumaadka shuqulkaas la wadaajiyey waxaa lagu bixiyaa saddex luuqadood oo kala duduwan Ingiriis, Hindi iyo Bengali. Tusaale kasta oo macluumaad ah waxay ku dhibaataysaa sadex fasalka xadgudubka - Not Aggressive, Covertly Aggressive, Overly Aggressive, as well as mid ka mid ah labadii fasalka xunxun - jinsiga iyo aan jinsiga ahayn. Tusaale neurada ugu dhammaadka ugu dambaysta ah waxaynu soo jeedaynaa booska BERT korkiisa, kaas oo ku qoraya qayb waxbarasho badan oo ah si uu ugu hadlo labada shaqo ee hoose. Kooxdayagii, na14, waxaa miisaamay 0.8579 oo miisaami jiray F1-miis ku saabsan sub-task B ingiriisiga, wuxuuna ka dhigay darajada 3aad oo ka mid ah 15 koox. Qorada iyo miisaanka muusikadu waxay furan yihiin https://github.com/NiloofarSafi/TRAC-2. Aqoonsheer: Aggression, Misogyny, Abusive language, Hate-Speech, BERT, NLP, Neural Network, Social Media", 'sv': 'På senare tid har NLP-gemenskapens fokus ökat mot stötande språk, aggression och hatpropaganda upptäckt. Denna uppsats presenterar vårt system för TRAC-2 delad uppgift om "Aggression Identification" (underuppgift A) och "Misogynistic Aggression Identification" (underuppgift B). Uppgifterna för denna delade uppgift tillhandahålls på tre olika språk - engelska, hindi och bengali. Varje datainstans är kommenterad i en av de tre aggressionsklasserna - Inte aggressiv, Täckt aggressiv, Överaggressiv, samt en av de två misogyny klasserna - Gendered och Icke-Gendered. Vi föreslår en end-to-end neural modell som använder uppmärksamhet ovanpå BERT som innehåller ett multi-task lärande paradigm för att hantera båda underuppgifterna samtidigt. Vårt team, \'na14\', fick 0,8579 viktade F1-mått på den engelska underuppgiften B och säkrade 3:e rankningen av 15 lag för uppgiften. Koden och modellvikterna är tillgängliga för allmänheten på https://github.com/NiloofarSafi/TRAC-2. Nyckelord: Aggression, Misogyni, Missbruk, Hate-Tal Detection, BERT, NLP, Neurala nätverk, Sociala medier', 'si': "අලුත් වෙලාවට, NLP සමාජයේ අවධානය විශ්වාස කරලා තියෙන්නේ අපරාධ භාෂාව, අපරාධානය සහ විරෝධ කතා මේ පැත්තේ අපේ පද්ධතිය TRAC-2 කොටස් එක්ක 'Aggression ID' (sub-job A) සහ 'Misoynistic Aggression ID' (sub-job B) ගැන භාවිත වැඩක් සඳහා තියෙනවා. මේ වෙනුවෙන් වෙනුවෙන් භාෂාව තුනක් තියෙන දත්ත - ඉංග්\u200dරීසි, හින්දි සහ බෙන්ගාලි. හැම දත්ත ස්ථානයක්ම සිද්ධ විශේෂ තුනක් වලින් එක්කෙනෙක් විශ්වාස කරලා තියෙනවා - සිද්ධ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ අපි අවසානයෙන් අවසානයෙන් ඉවරයි න්\u200dයූරාල් මොඩේලයක් ප්\u200dරයෝජනය කරනවා BERT වලින් අවස්ථාවක් ප්\u200dරයෝජනය කරනවා ඒකෙන් වඩා වැඩි  අපේ කණ්ඩායම 'na14', 0.8579 විශේෂයෙන් ඉංග්\u200dරීසි සුබ-වැඩ B වල F1-විශේෂයෙන් සුරක්ෂා කරලා තියෙන තුන්වෙනි ප්\u200dරමාණය 15 කෝඩ් සහ මොඩේල් බර ප්\u200dරතිකාරයෙන් ප්\u200dරතිකාරයෙන් පිළිබඳයි. https://github.com/NiloofarSafi/TRAC-2. යතුරු වචන්: සාමාජික භාෂාව, විරෝධ කතා පරීක්ෂණය, BERT, NLP, න්\u200dයූරල් ජාලය, සමාජික මිඩියාව", 'mk': "Во последните времиња, фокусот на заедницата на НЛП се зголеми кон навредливиот јазик, агресијата и детекцијата на говорот на омраза. This paper presents our system for TRAC-2 shared task on 'Aggression Identification' (sub-task A) and 'Misogynistic Aggression Identification' (sub-task B).  The data for this shared task is provided in three different languages - English, Hindi, and Bengali.  Each data instance is annotated into one of the three aggression classes - Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes - Gendered and Non-Gendered.  We propose an end-to-end neural model using attention on top of BERT that incorporates a multi-task learning paradigm to address both the sub-tasks simultaneously.  Our team, 'na14', scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task.  Кодот и теговите на моделот се јавно достапни на https://github.com/NiloofarSafi/TRAC-2. Клучни зборови: агресија, мизогина, злоупотребен јазик, детективност на омразен говор, БЕРТ, НЛП, неврални мрежи, социјални медиуми", 'ta': "சமீபத்தில், NLP சமுதாயத்தின் கவனத்தை மீறும் மொழி, aggression, மற்றும் வெறுப்பு பேச்சு கண்டுபிடிப்பதற்கு அதிகரித்துவிட இந்த தாள் TRAC- 2 பங்கிடப்பட்ட பணிக்கு எங்கள் அமைப்பை காட்டுகிறது 'Aggression Identification' (sub- task A) மற்றும் 'Misogynistic Aggression Identification' (sub- task B). இந்த பகிர்ந்த செயலுக்கான தகவல் மூன்று வித்தியாசமான மொழிகளில் வழங்கப்படுகிறது - ஆங்கிலம், ஹின்டி மற்றும ஒவ்வொரு தரவு நிகழ்வும் மூன்று எதிர்பார்ப்பு வகுப்புகளில் ஒருவனாக குறைக்கப்படுகிறது - முக்கியமாக அல்ல, கருத்து மிகுந்த, மேலும் மேலும் மேலும் மேலு BERT மேல் கவனத்தை பயன்படுத்தி முடிவு இறுதி முடிவு புதிய மாதிரி முறைமையை நாம் பரிந்துரைக்கிறோம். அது பல பணிகள் கற்றுக் கொள்ளும் அளபுருவை  எங்கள் குழு 'na14', 0. 8579 ஆங்கிலத்தின் துணை பணி B மீது F1-அளவை எடுத்து 15 குழுக்களில் மூன்றாவது வரிசை பாதுகாப்பாக்கப்பட்டது. குறியீடு மற்றும் மாதிரி எடைகள் பொதுவாக கிடைக்கும் https://github.com/NiloofarSafi/TRAC-2. விசைவார்த்தைகள்: Aggression, Misogyny, Abusive Language, Hate- Speech Detection, BERT, NLP, Neural Network, Social Media", 'ur': "اگلے وقت، NLP کمونٹی کی تمرکز بڑھی گئی ہے فساد کی زبان، فساد اور عداوت کی بات شناسایی کی طرف۔ This paper presents our system for TRAC-2 shared task on 'Aggression Identification' (sub-task A) and 'Misogynistic Aggression Identification' (sub-task B)'. اس مشترک کام کے لئے اطلاعات تین مختلف زبانوں میں پیش کیے جاتے ہیں - انگلیسی, ہندی اور بنگالی۔ ہر ڈاٹ کی مثال تین گریس کلاس میں سے ایک میں اظہار کی جاتی ہے - نہ گریز، پورٹی گریز، زیادہ گریز، اور دو گریز کلاس میں سے ایک - جنسی اور ناجنسی. ہم نے BERT کے اوپر توجه کے مطابق ایک نائرل موڈل کو پیشنهاد کرتا ہے جو ایک دوسرے ساب-ٹاکس کے بارے میں مشغول کرتا ہے۔ ہماری تیم، na14، 0.8579 انگلیسی sub-task B پر وزن F1-measure کیا گیا تھا اور 15 تیموں میں سے تیسرا رقم امن رکھا گیا تھا۔ کوڈ اور موڈل وزن ظاہر طور پر موجود ہیں https://github.com/NiloofarSafi/TRAC-2. Keywords: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media", 'vi': 'Trong những ngày gần đây, tiêu điểm của cộng đồng Njala đã càng tăng lên về việc phát hiện ngôn ngữ tấn công, hung hăng và ngôn ngữ căm ghét. Tờ giấy này giới thiệu hệ thống phân công cộng TRAC-2 tác vụ chung "Nhận diện xâm lược (dưới nhiệm vụ A) và"Nhận diện xâm lược yếu ớt (dưới nhiệm vụ B). Dữ liệu cho nhiệm vụ chia sẻ này được cung cấp bằng ba ngôn ngữ khác nhau (tiếng Anh, tiếng Hindi, và Bengali). Mỗi trường dữ liệu được ghi chú vào một trong ba lớp hung hăng\'Không phải hiếu khách, Dồn sắc, Quá mạnh, cũng như một trong hai lớp kém tham quan\'Tự do và không tự do. Chúng tôi đề nghị một mô hình thần kinh từ tới cuối cùng, sử dụng sự chú ý trên thực phẩm BERT, bao gồm cả một mô hình học đa nhiệm vụ để giải quyết cả hai nhiệm vụ cùng một lúc. Đội của chúng tôi,\'na14\', đã ghi điểm 0.8579 và nhận trọng lượng F1-thước đo bằng con tàu ngầm Anh-nhiệm vụ B và đảm bảo đội thứ ba cấp ngoài 15 cho nhiệm vụ. The code và the model tạ được công bố công khai tại https://github.com/NiloofarSafi/TRAC-2. Từ khóa: Sự xâm lược, Misogyny, lạm dụng ngôn ngữ, ghét-Ngôn ngữ trinh sát, BERT, NLP, Neural Networks, Social Media', 'uz': "Yaqinda, NLP jamiyatlarining fokusi kashqaruvchi tillarda, harakat qilish, va kuch aytishni aniqlashga oshadi. Бу саҳифа TRAC-2 bilan bogʻliq vazifa (sub- vazifa A) va 'Misogynistik Aggression ID' bilan bogʻliq vazifasini koʻrsatiladi. Ushbu bogʻliq vazifa uchun maʼlumot uch xil tilda - Inglizcha, Hindi va Bengalcha tilida koʻrsatiladi. Har bir maʼlumot misol uchta harakat sinfga aylanadi - Aggressiv emas, Hisobot Aggressiv, katta vulg'iz va ikkita misoglif sinfning biri - jinsiy va hech narsa emas. Biz bir xil vazifalarni bir xil o'rganish parametrini bir xil o'rganish uchun bir xil o'rganish imkoniyatini o'rganish mumkin. Bizning guruhimiz 'na14', 0. 8579 ingliz sub-vazifa B bilan F1 tilini qidirish va vazifa uchun 15 guruhdan 3 darajadagi 3 darajaga himoyalangan. Kodlash va model balandlari public https://github.com/NiloofarSafi/TRAC-2. Keyingi soʻzlar: Aggression, Misogyny, Abusiv tili, Hat-Speech Detection, BERT, NLP, Neural Network, Social Media", 'bg': 'В последно време фокусът на общността на НЛП се увеличи към офанзивен език, агресия и откриване на реч на омразата. Настоящата статия представя нашата система за споделена задача на TRAC-2 относно "Идентификация на агресията" (подзадача А) и "Идентификация на агресията на мизогинизма" (подзадача Б). Данните за тази споделена задача са предоставени на три различни езика - английски, хинди и бенгалски. Всеки пример на данни е анотиран в един от трите класа агресия - Не агресивен, Прикрити агресивен, Прекалено агресивен, както и един от двата класа на женомраза - Жандеризиран и Не-Жандеризиран. Предлагаме невронен модел от край до край, използващ вниманието върху БРТ, който включва парадигма за обучение с множество задачи, за да се справи едновременно с двете подзадачи. Екипът ни, "не 14", отбеляза 0.8579 претеглена мярка на английската подзадача Б и осигури 3-то място от 15 отбора за тази задача. Кодът и теглото на модела са публично достъпни на адрес: https://github.com/NiloofarSafi/TRAC-2. Ключови думи: Агресия, Мизоомраза, Злоупотребяващ език, Откриване на омраза и реч, НЛП, Неврални мрежи, Социални медии', 'nl': "De laatste tijd is de focus van de NLP gemeenschap toegenomen op aanstootgevende taal, agressie en haatspraakdetectie. Dit document presenteert ons systeem voor TRAC-2 gedeelde taak op 'Aggressie Identificatie' (sub-taak A) en 'Misogynistische Aggressie Identificatie' (sub-taak B). De gegevens voor deze gedeelde taak worden verstrekt in drie verschillende talen: Engels, Hindi en Bengaals. Elke gegevensinstantie is geannoteerd in een van de drie agressieve klassen, Niet agressief, Verborgen agressief, Overtly agressief, evenals een van de twee misogynieklassen Gendered en Non-Gendered. We stellen een end-to-end neuraal model voor met aandacht bovenop BERT dat een multi-task leerparadigma bevat om beide deeltaken tegelijkertijd aan te pakken. Ons team, 'na14', scoorde 0.8579 gewogen F1-maat op de Engelse deeltaak B en behaalde de 3e rang van 15 teams voor de taak. De code en de modelgewichten zijn openbaar beschikbaar op: https://github.com/NiloofarSafi/TRAC-2. Trefwoorden: Aggressie, Misogynie, Misusieve Taal, Hate-Speech Detection, BERT, NLP, Neurale Netwerken, Social Media", 'hr': 'U zadnje vrijeme, fokus zajednice NLP-a povećao se ka uvredljivom jeziku, agresiji i otkrivanju govora mržnje. Ovaj papir predstavlja naš sustav za zajednički zadatak TRAC-2 o identifikaciji agresije (podzadatak A) i Misogynističkoj identifikaciji agresije (podzadatak B). Podaci za ovaj zajednički zadatak pružaju se na tri različita jezika - engleski, hindi i Bengali. Svaki primjer podataka je annotiran u jednu od tri klase agresije - ne Agresivne, Prikriveno Agresivne, Previše Agresivne, kao i jednu od dvije misoginije klase - Gendered i Non-Gendered. Predlažemo neuralni model kraja do kraja koristeći pažnju na vrhu BERT-a koja uključuje paradigmu učenja višezadataka kako bi se istovremeno obratila oba podzadataka. Naš tim, na14, rezultirao je 0,8579 težine F1-mjere na engleskom podzadatku B i osigurao treći red od 15 tima za zadatak. Kod i model težine su javno dostupne na https://github.com/NiloofarSafi/TRAC-2. Ključne riječi: Agresija, Misogynija, Abuzivni jezik, Detekcija mržnje-govora, BERT, NLP, Neuralne mreže, Socijalne medije', 'de': "In letzter Zeit hat sich der Fokus der NLP-Community auf beleidigende Sprache, Aggression und Hassrede-Erkennung erhöht. Diese Arbeit stellt unser System für TRAC-2 Shared Task auf 'Aggression Identification' (Teilaufgabe A) und 'Misogynistische Aggression Identification' (Teilaufgabe B) vor. Die Daten für diese gemeinsame Aufgabe werden in drei verschiedenen Sprachen bereitgestellt: Englisch, Hindi und Bengali. Jede Dateninstanz wird in eine der drei Aggressionsklassen Not Aggressive, Coverly Aggressive, Overly Aggressive sowie eine der beiden Frauenfeindlichkeitsklassen Gendered und Non-Gendered kommentiert. Wir schlagen ein neuronales End-to-End-Modell vor, das Aufmerksamkeit auf BERT verwendet, das ein Multi-Task-Lernparadigma beinhaltet, um beide Teilaufgaben gleichzeitig anzugehen. Unser Team 'na14', erzielte 0.8579 gewichtete F1-Kennzahl für die englische Teilaufgabe B und sicherte sich den dritten Rang aus 15-Teams für diese Aufgabe. Der Code und die Modellgewichte sind öffentlich verfügbar unter https://github.com/NiloofarSafi/TRAC-2. Keywords: Aggression, Misogynie, Missbrauchssprache, Hate-Speech Detection, BERT, NLP, Neuronale Netzwerke, Social Media", 'id': "Pada saat-saat terakhir, fokus komunitas NLP telah meningkat menuju bahasa yang menyerang, agresi, dan deteksi pidato kebencian. Kertas ini memperkenalkan sistem kita untuk TRAC-2 tugas berbagi pada 'Identifikasi Aggresi' (sub-tugas A) dan 'Identifikasi Aggresi Misogynistic' (sub-tugas B). Data untuk tugas berbagi ini disediakan dalam tiga bahasa yang berbeda - Bahasa Inggris, Hindi, dan Bengali. Setiap contoh data dicatat ke salah satu dari tiga kelas agresi - Tidak Aggressive, Covertely Aggressive, Overly Aggressive, dan salah satu dari dua kelas misogyny - Gender dan Non-Gender. Kami mengusulkan model saraf akhir-akhir menggunakan perhatian di atas BERT yang mengandung paradigm a belajar multi-tugas untuk mengatasi kedua sub-tugas secara bersamaan. Tim kami, 'na14', mencetak 0,8579 berat F1-ukuran pada sub-tugas Inggris B dan mengamankan rangka ketiga dari 15 tim untuk tugas ini. Kode dan berat model tersedia publik di https://github.com/NiloofarSafi/TRAC-2. Kata kunci: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media", 'da': "I den seneste tid er NLP-fællesskabets fokus steget mod stødende sprog, aggression og had-tale detektering. Denne artikel præsenterer vores system for TRAC-2 delte opgave om 'Aggression Identification' (underopgave A) og 'Misogynistic Aggression Identification' (underopgave B). Dataene til denne delte opgave leveres på tre forskellige sprog - engelsk, hindi og bengali. Hver dataforekomst er noteret i en af de tre aggressionsklasser - Ikke aggressiv, Skjult aggressiv, Over aggressiv, samt en af de to misogini klasser - Gendered og Ikke-Gendered. Vi foreslår en end-to-end neural model ved hjælp af opmærksomhed oven på BERT, der indarbejder et multi-task læringsparadigme til at adressere begge underopgaver samtidigt. Vores hold, 'na14', scorede 0,8579 vægtet F1-mål på den engelske underopgave B og sikrede 3. rang ud af 15 hold til opgaven. Koden og modelvægtene er offentligt tilgængelige på https://github.com/NiloofarSafi/TRAC-2. Nøgleord: Aggression, Misogyni, misbrugssprog, Hade-Tale Detection, BERT, NLP, Neurale Netværk, Sociale Medier", 'sw': "Katika nyakati za hivi karibuni, lengo la jumuiya ya NLP umeongezeka kwenye lugha ya ukatili, uvunjifu na kutambua hotuba za chuki. Makala hii inaonyesha mfumo wetu wa kazi yetu ya TRAC-2 iliyoshirikiana kwenye ‘Utambulisho wa Umoja wa Matukio' (Utambulisho wa Uwekezi wa Utaguzi wa Uwekezaji wa Uwekezi wa Kigaidi” (kazi ya subira B). Takwimu za kazi hii zinatolewa kwa lugha tatu tofauti - Kiingereza, Kihindi na Bengali. Kila aina ya takwimu inakerushwa katika moja ya darasa tatu la ukatili - Sio Aggressive, Wengi Aggressive, na hata moja ya darasa hizo mbili za uonevu - Wanajinsia na wasio na jinsia. Tunazipendekeza muonekano wa mwisho wa neura kwa kutumia mtazamo juu ya BERT ambao unajumuisha mchanganyiko wa kujifunza kwa kazi nyingi ili kuzungumza kazi hizo mbili kwa wakati mmoja. Timu yetu, 'na14', ilibeba kipimo 0.8579 cha F1 kwenye jukumu la Kiingereza B na kuhakikisha daraja tatu kutoka timu 15 kwa ajili ya kazi hiyo. Kodi na mizani ya modeli zinapatikana kwa umma https://github.com/NiloofarSafi/TRAC-2. Kwa maneno muhimu: Utaguzi, Utaguzi, Lugha ya Ubaguzi, Utafiti wa Hotuba za Hati, BERT, NLP, Mtandao wa Kiurali, Mitandao ya kijamii", 'af': "In onlangse tyde het die fokus van die NLP-gemeenskap verhoog tot offensivele taal, aggresie en haatspraak-opdekking. Hierdie papier stel ons stelsel vir TRAC- 2 gedeelde taak op 'Aggresie Identifikasie' (sub- task A) en 'Misogynistiese Aggresie Identifikasie' (sub- task B). Die data vir hierdie gedeelde taak is verskaf in drie verskillende tale - Engels, Hindi en Bengali. Elke data voorbeeld is in een van die drie aggressie klasse aangetel - Nie Aggressief, Aggressief, Oorvloedig Aggressief, asook een van die twee misogynie klasse - Gendered en Nie-Gendered. Ons voorstel 'n einde-tot-einde neurale model met aandag op bo van BERT wat 'n multi-taak leer paradigme inkorpreer om beide die sub-taak simultaan te adres. Ons span, 'na14', het 0.8579 geweeg F1-maat op die Engels sub-taak B en seker 3de rank uit 15 teams vir die taak. Die kode en die model gewigte is openlik beskikbaar by https://github.com/NiloofarSafi/TRAC-2. Sleutelwoorde: Aggresie, Misogyny, Abusive Taal, Hate-Spraak Deteksie, BERT, NLP, Neurale Netwerke, Sosiale Media", 'fa': 'در اخیر زمان، تمرکز جامعه NLP به سمت زبان فساد، حمله و تشخیص سخنرانی متنفر افزایش یافت. این کاغذ سیستم ما را برای کار مشترک TRAC-2 در مورد شناسایی گروهی (زیر کار A) و شناسایی گروهی Misogynistic Aggression (زیر کار B) نشان می دهد. اطلاعات این کار مشترک در سه زبان متفاوت - انگلیسی، هندی و بنگالی ارائه می شود. هر نمونه داده\u200cای به یکی از سه کلاس\u200cهای تجاوز مشخص می\u200cشود - نه گروه\u200cگر، نه گروه\u200cگر، نه گروه\u200cگر، و همچنین یکی از دو کلاس ناشناس - جنسی و ناجنسی. ما پیشنهاد می کنیم یک مدل عصبی پایان و پایان با استفاده از توجه روی بالای BERT که یک پارادیگ یادگیری چندین کار را شامل می کند تا هر دو مدل زیر کار را به همراه حل کند. تیم ما "na14" 0.8579 اندازه F1 وزن روی زیر کار انگلیسی B و درجه سوم از 15 تیم برای این کار امن داشت. کد و وزن مدل عمومی در https://github.com/NiloofarSafi/TRAC-2. کلمات کلیدی: افزایش، میسوگنی، زبان ناپسند، کشف سخنرانی ناپسند، BERT, NLP, شبکه\u200cهای عصبی، رسانه\u200cهای اجتماعی', 'ko': "최근 몇 년 동안 NLP 커뮤니티의 관심사는 공격적인 언어, 공격적이고 증오적인 언어 검출로 증가했다.본고는 우리의 TRAC-2 공유 임무인'공격 식별'(하위 임무 A)과'염녀 공격 식별'(하위 임무 B) 시스템을 소개한다.이 공유 작업의 데이터는 영어, 인디언, 방글라데시어 세 가지 언어로 제공된다.모든 데이터 실례는 세 개의 공격류 중 하나인 비공격성, 은폐공격성, 공개공격성, 그리고 두 개의 염녀류 중 하나인 성별과 비성별로 표시된다.우리는 BERT 위에 주의를 기울이고 다중 임무 학습 모델을 결합시켜 이 두 개의 하위 임무를 동시에 처리하는 단도직입적인 신경 모델을 제시했다.우리 팀'na14'는 영어 하위 퀘스트 B의 F1 가중 점수가 0.8579로 15개 퀘스트를 완성한 팀 중 3위에 올랐다.코드 및 모델 가중치https://github.com/NiloofarSafi/TRAC-2.키워드: 공격적, 여성혐오, 욕설적 언어, 혐오 언어 검출, 버트, NLP, 신경 네트워크, 소셜 미디어", 'am': "በቅርብ ዘመን፣ የNLP ማኅበረሰብ ማዕከላዊ ቋንቋ፣ ግፍ እና ጥል ንግግር አግኝቷል፡፡ ይህ ፕሮግራም የTRAC-2 ስራችንን ‹መግለጫ ማውቀት› (sub-ስራ A) እና ‹Misogynistic Aggression Identification› (sub-task B) የሚያሳየው ስርዓታችንን ያቀርባል፡፡ ይህ የተካፈሉት ስራ ዳታ በሦስት ልዩ ቋንቋ - እንግሊዝኛ፣ ኬንዲ እና በንጋሊ ነው፡፡ Each data instance is annotated into one of the three aggression classes - Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes - Gendered and Non-Gendered.  በBERT ላይ ማስታወቂያውን የብዙ ትምህርት ተማሪ ተቃውሞ በተጨማሪው እና ሁለቱን ደብዳቤዎችን በመጠቀም የሚጨምረው የዳርቻ የኒጀር ሞዴል እናሳልቃለን፡፡ የቡድን 'na14', 0.8579 የኢንግሊዝኛ ደብዳቤ B ሚዛን የመዘን F1 መስፈሪያ ነው፡፡ ኮድ እና ሞዴል ሚዛን በህዝብ ላይ ይገናኛሉ https://github.com/NiloofarSafi/TRAC-2. ቃላት: Aggression, Misogyny, Abusive ቋንቋ, Hate-Speech Detection, BERT, NLP, Neural Network, ማኅበራዊ ሚዲያ", 'tr': "Soňky wagtlar NLP jemgyýetiniň fokusy höwesli dillere, agresiýa we ýigrenç sözlerine göz öňüne getirilýär. Bu kagyz biziň sistemimizi TRAC-2 beýleki zady 'Aggresiýa Kimligi' (sub-task A) we 'Misogynist Aggresiýa Kimligi' (sub-task B) üçin belleýär. Bu paylaşyk işiň maglumaty üçin üç dürli dilde – iňlisçe, Hindi çe we Bengali çe Her veri instansi üç agresiýa sınıflardan birine sözleştirildi - Aggresiýa däl, Covertly Aggresiýa, Çok Aggresiýa we iki hat sırasyndan birine de sözleştirildi - Çikgi we Çikgi bolmady. BERT'yň üstünde üns almak üçin bir näral nusgasyny soňunda taýýarlanan nusgasyny teklip edýäris. Bu ikisiniň sub-zadyny hem çykmak üçin bir multi-täbli öwrenmek paradigmanyň içini bar. Biziň toparymyz 'na14', Häzirki görkezilişinden hat we nusga üçin belli edip biler. https://github.com/NiloofarSafi/TRAC-2. Keywords: Aggresiýa, Misogyny, Abusive Dili, Hate-sözleri tanyş, BERT, NLP, Neural Networks, Social Media", 'bn': "সাম্প্রতিক সময়ে এনএলপি সম্প্রদায়ের মনোযোগ বাড়িয়ে দিয়েছে আক্রমণ ভাষা, আক্রমণ এবং ঘৃণা বাক্য সনাক্তির দিকে। এই পত্রিকাটি আমাদের TRAC-2 শেয়ার করা কাজের জন্য উপস্থাপন করেছে 'গ্রেগ্রেশন পরিচয়পত্র' (সাব-কাজ A) এবং 'মিসোজিনিস্টিক গ্রেগ্রেশন পরিচয়' (সাব এই শেয়ার কর্মের তথ্য তিনটি ভিন্ন ভাষায় প্রদান করা হয়েছে - ইংরেজি, হিন্দি এবং বাংলায়। প্রত্যেক তথ্যের উদাহরণ তিনটি আক্রান্ত শ্রেণীর মধ্যে একটিকে বিরক্তিত - গ্রেগ্রাস নয়, কোভার্টিভ গ্রাগ্রেসিভ, অত্যন্ত গ্রেগ্রাস্টিভ, এবং দুই ধরনের ভুল আমরা বিরেটের উপর মনোযোগ দিয়ে শেষ পর্যন্ত নিউরেল মডেলের প্রস্তাব করি যেটি একই সাথে সাব-কাজের কথা বলার জন্য একটি বহুকাজ শিক্ষা প্যারাডিমের মধ্যে  Our team, 'na14', scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task.  The code and the model weights are publicly available at  https://github.com/NiloofarSafi/TRAC-2. কীবোর্ড: গ্রেগ্রেশন, মিজোজিনি, আবুসিভ ভ ভাষা, ঘৃণা ভাষা ডিটেকটিশন, বের্ট, এনএলপি, নিউরাল নেটওয়ার্ক, সোশ্যাল মিডিয়া", 'bs': 'U nedavno vrijeme, fokus zajednice NLP povećao se ka ofanzivnom jeziku, agresiji i otkrivanju govora mržnje. Ovaj papir predstavlja naš sistem za zajednički zadatak TRAC-2 o "Identifikaciji agresije" (podzadatak A) i "Identifikaciji misoginističke agresije" (podzadatak B). Podaci o ovom zajedničkom zadatku pružaju se na tri različita jezika - engleski, Hindi i Bengali. Svaki primjer podataka je annotiran u jednu od tri klase agresije - ne Aggresivno, Prikriveno Aggresivno, Previše Aggresivno, kao i jednu od dvije klase misoginije - Gender i Non-Gendered. Predlažemo neuralni model kraja do kraja koristeći pažnju na vrhu BERT-a koja uključuje paradigmu učenja višezadataka kako bi se istovremeno obratila oba podzadataka. Naš tim \'na14\', rezultirao je 0,8579 težine F1-mjere na engleskom podzadatku B i osigurao treći red od 15 tima za zadatak. Kod i model težine su javno dostupne na https://github.com/NiloofarSafi/TRAC-2. Ključne riječi: Agresija, Misognija, Abuzivni jezik, Detekcija mržnje govora, BERT, NLP, Neuralne mreže, Socijalne medije', 'hy': "Վերջին ժամանակներում ՆԼՀ-ի համայնքի կենտրոնացումը աճեց դեպի գայթակղիչ լեզու, ագրեսիա և ատելության խոսքի հայտնաբերման: This paper presents our system for TRAC-2 shared task on 'Aggression Identification' (sub-task A) and 'Misogynistic Aggression Identification' (sub-task B).  The data for this shared task is provided in three different languages - English, Hindi, and Bengali.  Յուրաքանչյուր տվյալների օրինակ գրված է երեք ագրեսիայի դասարաններից մեկի մեջ՝ ոչ ագրեսիվ, ոչ ամբողջովին ագրեսիվ, չափազանց ագրեսիվ, ինչպես նաև երկու անհարմարության դասարաններից մեկի մեջ՝ գենդերային և ոչ գենդերային: Մենք առաջարկում ենք մի վերջ-վերջ նյարդային մոդել, որը օգտագործում է ուշադրությունը BER-ի վերևում, որը ներառում է բազմախնդիր ուսուցման պարադիգմ երկու ենթախնդիրներին միաժամանակ լուծելու համար: Մեր թիմը «na 14»-ը ստացավ 0,8579 կեշտրված F1-չափություն անգլերենի B ենթախնդրի վրա և ստացավ 15 թիմից 3-րդ դասակարգ: Կոդը և մոդելների կշիռը հասանելի են https://github.com/NiloofarSafi/TRAC-2. Հիմնական բառերը. Ագրեսիա, Միսոգենիա, Վաբյուզիվ լեզու, ատելության-ելույթի հայտնաբերություն, ԲԵՌԹ, ՆԵԼՊ, Նեյրալ ցանցեր, սոցիալական մեդիա", 'sq': "Në kohët e fundit, fokusi i komunitetit NLP është rritur drejt gjuhës ofensive, agresionit dhe zbulimit të fjalëve të urrejtjes. Ky dokument paraqet sistemin tonë për detyrën e përbashkët TRAC-2 mbi 'Identifikimin e Aggresionit' (nëndetyrë A) dhe 'Identifikimin Misogynist të Aggresionit' (nëndetyrë B). The data for this shared task is provided in three different languages - English, Hindi, and Bengali.  Each data instance is annotated into one of the three aggression classes - Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes - Gendered and Non-Gendered.  Ne propozojmë një model nervor nga fundi në fund duke përdorur vëmendjen mbi BERT që përfshin një paradigm ë mësimi shumë-detyrash për të trajtuar të dy nëndetyrat në të njëjtën kohë. Ekipi ynë, na14, shënoi 0.8579 masë F1 në nëndetyrën angleze B dhe siguroi rendin e tretë nga 15 ekipe për detyrën. Kodi dhe peshat e modelit janë në dispozicion publik në https://github.com/NiloofarSafi/TRAC-2.  Keywords: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media", 'cs': 'V poslední době se zaměření komunity NLP zvýšilo na urážlivý jazyk, agresi a detekci nenávistných řečí. Tento článek představuje náš systém pro TRAC-2 sdílený úkol na \'Identifikace agrese\' (sub-úkol A) a \'Misogynistická identifikace agrese\' (sub-úkol B). Údaje pro tento sdílený úkol jsou poskytovány ve třech různých jazycích: angličtině, hindštině a bengálštině. Každá datová instance je anotována do jedné ze tří agresivních tříd: Neagresivní, utajeně agresivní, příliš agresivní a jedné ze dvou misogynních tříd Gendered a Non-Gendered. Navrhujeme komplexní neuronový model využívající pozornost na vrcholu BERT, který obsahuje multi-tasking učení paradigma pro řešení obou dílčích úkolů současně. Náš tým "na14" skóroval 0.8579 váženou F1 míru na anglickém podúkolu B a zajistil třetí místo z patnácti týmů pro tento úkol. Kód a hmotnost modelu jsou veřejně dostupné na adrese: https://github.com/NiloofarSafi/TRAC-2. Klíčová slova: Agrese, Misogynie, Abusivní jazyk, Detekce nenávisti řeči, BERT, NLP, Neurální sítě, Sociální média', 'az': "Son zamanlarda NLP toplumunun fərqli dillərin, agresiyanın və nifrət sözlərinin keşfetməsinə təsiri artırdı. Bu kağıt TRAC-2 paylaşılmış işlərimizin sistemini 'Aggresiya Kimlik' (A sub-task) və 'Misogynistik Aggresiya Kimlik' (B sub-task) barəsində göstərir. Bu paylaşılan işin məlumatları üç cür dildə - İngilizce, Hindi və Bengali dildə təmin edilir. Hər məlumat məlumatı üç agresiya sınıfından birinə bildiriləcəkdir - Agressiv deyil, Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü-Özü Biz BERT'nin üstündə çoxlu işin öyrənməsi paradigmi ilə birlikdə hər ikisini də apa işlərinə çəkmək üçün çoxlu işin öyrənməsini istifadə edən neural modeli təklif edirik. Bizim ekibimiz, na14, İngilizci B apa görevi barəsində 0,8579 ölçülü F1 ölçülü və bu iş üçün üçüncü dərəcə təhlükəsiz oldu. Kod və modellərin ağırlığı açıq olaraq https://github.com/NiloofarSafi/TRAC-2. Anahtar sözləri: Aggresiya, Misogyny, Abusive Dil, Nefrət-Sözü Detection, BERT, NLP, Neural Networks, Social Media", 'fi': "Viime aikoina NLP-yhteisön painopiste on lisääntynyt loukkaavaan kieleen, aggressioon ja vihapuheen havaitsemiseen. Tässä artikkelissa esitellään TRAC-2:n yhteinen tehtävä Aggression Identification (alitehtävä A) ja Misogynistic Aggression Identification (alitehtävä B). Tämän yhteisen tehtävän tiedot toimitetaan kolmella eri kielellä - englanti, hindi ja bengali. Jokainen tietoesiintymä on merkitty yhteen kolmesta aggressiivisuusluokasta - Ei aggressiivinen, Peitetysti aggressiivinen, Yliaggressiivinen, sekä yhteen kahdesta misogyny luokasta - Gendered ja Non-Gendered. Ehdotamme end-to-end neuromallia, joka käyttää huomiota BERT:n päällä ja joka sisältää monitehtäväoppimisen paradigman, joka käsittelee molempia osatehtäviä samanaikaisesti. Joukkueemme 'na14', teki 0,8579 painotettua F1-mittaria Englannin alatehtävässä B ja varmisti kolmannen sijoituksen 15 joukkueesta tehtävässä. Koodi ja mallipainot ovat julkisesti saatavilla osoitteessa https://github.com/NiloofarSafi/TRAC-2. Avainsanat: Aggressio, Misogynia, Väkivaltainen kieli, Vihanpuheen tunnistus, BERT, NLP, Neuraaliset verkostot, Sosiaalinen media", 'et': 'Viimasel ajal on NLP kogukonna fookus suurenenud solvava keele, agressiooni ja vihakõne avastamise suunas. Käesolevas dokumendis tutvustatakse TRAC-2 jagatud ülesannete süsteemi "Aggression Identification" (alamülesanne A) ja "Misogynistic Aggression Identification" (alamülesanne B). Selle ühise ülesande andmed on esitatud kolmes erinevas keeles - inglise, hindi ja bengali. Iga andmete eksemplar on märgitud ühte kolmest agressiooniklassist - Mitte agressiivne, Salajaselt agressiivne, Liiga agressiivne, samuti ühte kahest naisvihkamise klassist - Gendered ja Non-Gendered. Pakume välja lõpp-otsa neuromudeli, mis kasutab tähelepanu BERT-ile, mis sisaldab mitme ülesandega õppimise paradigmat, et käsitleda mõlemat alamülesannet samaaegselt. Meie meeskond "na14" lõi Inglise alamülesandel B 0,8579 kaalutud F1-mõõdu ja saavutas ülesande 15 meeskonnast kolmanda koha. Kood ja mudeli kaalud on avalikult kättesaadavad aadressil https://github.com/NiloofarSafi/TRAC-2. Märksõnad: Aggressioon, misogünia, kuritarvitav keel, vihkamise-kõne tuvastamine, BERT, NLP, neurovõrgud, sotsiaalmeedia', 'ca': "In recent times, the focus of the NLP community has increased towards offensive language, aggression, and hate-speech detection. This paper presents our system for TRAC-2 shared task on 'Aggression Identification' (sub-task A) and 'Misogynistic Aggression Identification' (sub-task B).  The data for this shared task is provided in three different languages - English, Hindi, and Bengali.  Cada cas de dades està anotat en una de les tres classes d'agressió - No aggressiva, cobertament aggressiva, excessivament aggressiva, com també en una de les dues classes de misogínia - sexe i no sexe. Proposem un model neural de final a final utilitzant l'atenció a sobre del BERT que incorpora un paradigma d'aprenentatge multitasca per abordar ambdues subtasques simultàneament. Our team, 'na14', scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task.  El codi i el pes del model estan disponibles en https://github.com/NiloofarSafi/TRAC-2. Mots clau: Aggressió, Misogínia, Llingua abusiva, Detecció de Discursos Odiós, BERT, NLP, Redes Neurals, Mèdia Social", 'he': 'בזמנים האחרונים, התמקדות של קהילת NLP הגיעה לשפה פגיעה, אגרסיה, וגילוי נאום שנאה. העבודה הזו מציגה את מערכת המשימה המשותפת שלנו של TRAC-2 על "זיהוי התקף" (תחת משימה A) ו "זיהוי התקף מיזוגיניסטי" (תחת משימה B). הנתונים למשימה המשותפת הזו מוספקים בשלושה שפות שונות - אנגלית, הינדית ובנגלית. כל דוגמא של נתונים מוכתבת באחד משלושת שיעורי האגרסיה - לא אגרסיבית, אגרסיבית מוחלטת, אגרסיבית מוחלטת, וגם באחד משני שיעורי מיסוגיניה - גזע ולא גזע. אנו מציעים מודל עצבי סוף-סוף בשימוש תשומת לב מעל BERT שמכיל פרדיגמה ללמוד במשימות רבות Our team, \'na14\', scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task.  הקוד והמשקלים של המודל זמינים לציבור https://github.com/NiloofarSafi/TRAC-2. מילים מפתחות: אגרסיה, מיזוגיניה, שפה מועללת, גילוי נאום-שנאה, BERT, NLP, רשתות נוירוליות, מדיה חברתית', 'sk': 'V zadnjem času se je osredotočenost skupnosti NLP povečala na žaljiv jezik, agresijo in odkrivanje sovražnega govora. Ta prispevek predstavlja naš sistem za skupno nalogo TRAC-2 o identifikaciji agresije (podnaloga A) in identifikaciji misoginistične agresije (podnaloga B). Podatki za to skupno nalogo so na voljo v treh različnih jezikih - angleščini, hindijščini in bengališčini. Vsak primerek podatkov je označen v enega od treh agresivnih razredov - ne agresivno, skrito agresivno, pretirano agresivno, pa tudi v enega od dveh razredov sovražnosti žensk - Gendered in Non-Gendered. Predlagamo nevronski model od konca do konca, ki uporablja pozornost na vrhu BERT, ki vključuje paradigma učenja z več nalogami za hkratno obravnavo obeh podnalog. Naša ekipa "na14" je na angleški podnalogi B dosegla 0,8579 tehtanega merila F1 in zagotovila 3. mesto od 15 ekip. Koda in uteži modela so javno dostopni na spletni strani https://github.com/NiloofarSafi/TRAC-2. Ključne besede: agresija, misoginja, zlorabljajoči jezik, odkrivanje sovraštva in govora, BERT, NLP, nevralna omrežja, socialni mediji', 'jv': "mudhik sing njuk, kawula nggolaké komunitas NLP kuwi wis mudhik kanggo tukang langga, njuk, lan ujaran-ujaran. Bu peutel sistemi atubangsane TRA2-2 tahun ciptaaken 'Agresiyon ID' (Sub-task A) lan 'MisogYnst Agresiyon ID' (Sub-task B). Bilih kanggo didalahan nggo nggawe iki sampeyan ing sakjane telu luwih-luwih, Inggris, Bindhis, lan Bengal. Sampeyan akué data sing ditambahak tanggal sabên karo kelas telu populasyon - Gak dhéwé, Covertly agegressy, Orangri agegressy, tambah susahé sak sabên iki kelas misogyèni iki - Gender lan pakan-Gender. Awak dhéwé nggunakake model end-to-end Nyural nungsi aturan tapi BERT sing digambut karo multi-task öyenne gampang kanggo ngerasakno apa-tasks tambah. Awak dhéwé, 'na 14' sing paling 0.5875 uwèk nggawe F1 Genjer-genjer https://github.com/NiloofarSafi/TRAC-2. echoH e l l o space w o r l d periodHelloworldHello world", 'ha': 'Ga na farko, fokus na jamii na NLP ya ƙara zuwa harshen na ƙetare, da ƙetare da kuma za\'a gane magana na ƙeta. Wannan takardar na nuna aikin mu na TRac-2 wanda aka raba aikin da shi a kan \'Idonanin Aggression\' (sub-aikin A) da \'Idonanin Aggression\' da \'Misogistic Aggression\' (sub-aikin B). @ item Spelling dictionary Ana cũtar da kõwa misali ta cikin ɗayan ƙungiyõyi uku na gargaɗin - Don Aggressive, Aggressive, Haƙĩƙa Aggressive, da kuma ɗayan nau\'i biyu na misogi - aka jingina da kuma ba-jine. Tuna goyyar da wata motsi na ƙari zuwa-ƙari, ta yi amfani da aikin muhalli kan BERT wanda ke haɗa wani paradigm na sanar da aiki masu yawa dõmin ya yi magana ga duk aikin sub-aikin sami. Team mu, "na14", aka sami 0.8579 ma\'auni F1-balanci a kan English sub-aikin B kuma ya tsare daraja 3 daga 15 team dõmin aikin. Ana iya ƙayyade kodi da nauyin motel da bayani da https://github.com/NiloofarSafi/TRAC-2. KCharselect unicode block name', 'bo': 'ཉེ་ཆར་བར་དུ། NLP ཚོགས་སྡེའི་གནད་དོན་འདིས་སྐྱུར་བའི་སྐད་ཡིག་ཆ་དང་། གསལ་བཤད་རྣམས་ནད་ཡོད། ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་འདི་སྟོན་པ་ཞིག་ནི TRAC-2་དང་མཉམ་དུ་བསྡུར་བ་སྤྱོད་བཞིན་ཡོད། མཉམ་སྤྱོད་བྱས་པའི་བྱ་འགུལ་འདིའི་ནང་གི་ཆ་འཕྲིན་དེ་སྐད་རིགས་མི་འདྲ་བའི་ནང་དུ་བྱིན་ཡོད། ཨིན་ཇིའི་དང་ཧྲི དབྱེ་རིམ་གྱི་གནད་སྡུད་འདི་ཚོ་གསུམ་ནང་ལ་བཟོ་བཅོས་བ་ཡིན། ང་ཚོས་BERT ལྟ་བུའི་མཐོང་སྣེ་མང་ཆོས་ཤེས་སྐབས་བྱ་རིམ་གྱི་ཐབས་ལམ་ཞིག་འཇུག ང་ཚོའི་དབྱིན་གྱི་ཕྱོགས་སྡུད་མི་(na14)རྣམས་ལས་ ཨིན་རིའི་ནང་གི་ཚད་གཅིག་མཐུན་འགྲོ་བ་ཡིན། སྔོན་སྒྲིག་ཉེར་སྤྱོད་དང་མིག་ཆའི་ཚད་གཞི་དང་མང་ཙམ་མང་ཙམ་ཡོད་པ https://github.com/NiloofarSafi/TRAC-2. གཙོ་ཚིག: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media'}
{'en': 'Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language', 'es': 'Mejora del léxico de enfoques basados en la incrustación para la detección del lenguaje abusivo', 'ar': 'معجم - تعزيز النهج القائمة على التضمين نحو الكشف عن اللغة المسيئة', 'fr': "Lexicon-Enrichissement des approches basées sur l'intégration pour la détection du langage abusif", 'pt': 'Aprimoramento do léxico de abordagens baseadas em incorporação para a detecção de linguagem abusiva', 'ja': '虐待言語の検出に向けた埋め込みベースのアプローチの語彙強化', 'hi': 'शब्दकोश-एम्बेडिंग-आधारित दृष्टिकोण की वृद्धि अपमानजनक भाषा का पता लगाने की ओर', 'zh': '词典-于销辱语言检测之益强', 'ru': 'Лексикон-улучшение основанных на внедрении подходов к обнаружению оскорбительного языка', 'ga': 'Foclóir - Feabhsú Cur Chuige Bunaithe ar Leabú I dtreo Teanga Mhí-úsáideach a Bhrath', 'ka': 'ლექსიკონის განსაზღვრება დამატებული დაწყებების მიზეზების განსაზღვრებაზე', 'hu': 'Lexikon – Beágyazáson alapuló megközelítések fejlesztése a visszaélő nyelv felismerése felé', 'el': 'Λεξικό-Βελτίωση Προσεγγίσεων με βάση την ενσωμάτωση προς την ανίχνευση καταχρηστικής γλώσσας', 'it': 'Lexicon-Enhancement of Embedding Approach to the Detection of Abusive Language', 'kk': 'Ендіру негіздеген қасиеттерді жетілдіру үшін лексикалық- жетілдіру', 'lt': 'Įtraukimu pagrįstų požiūrių į piktnaudžiavimo kalba nustatymą tobulinimas', 'mk': 'Појачување на лексиконите на пристапите базирани на вградување кон откривањето на злоупотребен јазик', 'ms': 'Pengembangan-Lexicon pendekatan berdasarkan penyembelihan Ke arah Pengesanan Bahasa Mencegah', 'ml': 'അബൂസിവ് ഭാഷയുടെ കണ്ടുപിടിയ്ക്കുന്നതിന് മുകളിലേക്ക് ലെക്സിക്സണ്\u200d - മെച്ചപ്പെടുത്തുന്നത്', 'mt': 'Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language', 'mn': 'Хүчирхийлэлтэй хэл олж мэдэхэд сэтгэл хөгжүүлэх', 'no': 'Leksjon- forbetring av innbyggingsbaserte tilnærmingar mot oppdaging av abusive språk', 'pl': 'Leksykonowe ulepszenie podejść opartych na osadzeniu w kierunku wykrywania nadużyć języka', 'ro': 'Lexicon-îmbunătățirea abordărilor bazate pe încorporarea către detectarea limbajului abuziv', 'sr': 'Leksion-poboljšanje pristupa na osnovu uključenja prema otkrivanju zloupotrebnog jezika', 'si': 'ලෙක්සිකෝන්-විශාලනය සම්බන්ධ විදියට ආධාරිත විදියට ප්\u200dරවේශනය කරන්න', 'so': 'Lexicon-Advancement of deganaanshaha kor u qaadashada Finnishka Abusive', 'sv': 'Lexikon – Förbättring av inbäddade metoder mot upptäckt av missbruk av språk', 'ta': 'Name', 'ur': 'جسمانی زبان کی تلاش کی طرف پھیلانے کی آمیزش کی زیادتی', 'uz': 'Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language', 'vi': 'Cố gắng phát triển ngôn ngữ vi phạm', 'bg': 'Подобряване на подходите, базирани на вграждане, за откриване на злоупотребяващ език', 'hr': 'Leksički-poboljšanje pristupa na osnovu uključenja prema otkrivanju nasilnog jezika', 'nl': 'Lexicon-Verbetering van embedding-gebaseerde benaderingen naar de detectie van misbruikende taal', 'da': 'Lexikon-forbedring af indlejringsbaserede tilgange mod detektion af misbrug af sprog', 'de': 'Lexikon-Verbesserung eingebetteter Ansätze zur Erkennung missbräuchlicher Sprache', 'id': 'Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language', 'ko': '삽입된 욕 언어 검출 방법에 기반한 사전 강화', 'fa': 'تغییر\u200cپذیر دسترسی\u200cهای بنیادی بر روی کشف زبان مزخرف', 'sw': 'Kuboresha Lugha ya Kihisia', 'tr': 'Etrap Dilini Aňlamak üçin meksiýa-Aňlamak', 'af': 'Lexicon-Verbetering van Inbetering-gebaseerde toegang na die Opdekking van Abusive Taal', 'sq': 'Përmirësimi i lexikonëve të metodave të bazuara në përfshirje drejt zbulimit të gjuhës abuzive', 'am': 'አቢስ ቋንቋ ማግኘት ወደሚደርስበት ደረጃዎች ወደሚደርስበት የሊክሲኮን-ማድረግ', 'hy': 'Ներգրավման հիմնված մոտեցումների լեքսիկոնի բարելավումը', 'az': '쒰쎧楮擉餠楳瑩晡擉餠敤楬즙渠摩汬즙物渠步얟晥瑭즙獩滉餠瓉饲즙映楳瑩晡擉餠敤楬즙渠瓉饲즙晬즙爊', 'bn': 'Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language', 'bs': 'Leksičko-poboljšanje pristupa na osnovu uključenja prema otkrivanju nasilnog jezika', 'ca': "Mejor-Lexicon d'Approaches Based on Embedding Towards the Detection of Abusive Language", 'cs': 'Vylepšení přístupů založených na vložení k detekci zneužívaného jazyka', 'et': 'Lexikonipõhiste lähenemisviiside täiustamine kuritarvitava keele avastamiseks', 'fi': 'Käyttöönottoon perustuvien lähestymistapojen parantaminen väärinkäytöksen havaitsemiseksi', 'jv': 'Leksion-ENhancement of Inconclusi Rasara sing basa Perangkat Puntuan kanggo Ketokake Langan Abusuf', 'sk': 'Izboljšanje pristopov, ki temeljijo na vdelavi, k odkrivanju zlorabljenega jezika', 'he': 'שיפור לקסיקון של גישות מבוססות בהכניסה לכיוון גילוי שפת מועללת', 'ha': 'KCharselect unicode block name', 'bo': 'གཟུགས་རིས་ལ་འགྲོ་བཞིན་པའི་ནང་དུ་གཞི་རྟེན་ནས་བཟོ་བཅོས་ནི་འགྲོ་བཞིན་ཡོད།'}
{'en': 'Detecting abusive language is a significant research topic, which has received a lot of attention recently. Our work focuses on detecting personal attacks in  online conversations . As previous research on this task has largely used  deep learning  based on  embeddings , we explore the use of  lexicons  to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks. The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the  lexicons , in order to construct or to change embeddings that are ultimately fed into the learning model. The sentiment lexicon approaches focus on integrating  sentiment information  (in the form of sentiment embeddings) into the  learning model . The  semantic lexicon approaches  focus on transforming the original  word embeddings  so that they better represent relationships extracted from a  semantic lexicon . Based on our experimental results, semantic lexicon methods are superior to the rest of the  methods  in this paper, with at least 4 % macro-averaged F1 improvement over the baseline.', 'fr': "La détection du langage abusif est un sujet de recherche important qui a récemment fait l'objet d'une grande attention. Notre travail se concentre sur la détection des attaques personnelles dans les conversations en ligne. Comme les recherches précédentes sur cette tâche ont largement utilisé le deep learning basé sur les intégrations, nous explorons l'utilisation de lexiques pour améliorer les méthodes basées sur l'intégration afin de voir comment ces méthodes s'appliquent à la tâche particulière de détection des attaques personnelles. Les méthodes mises en œuvre et expérimentées dans cet article sont très différentes les unes des autres, non seulement par le type de lexiques qu'elles utilisent (sentiment ou sémantique), mais aussi par la façon dont elles utilisent les connaissances des lexiques, afin de construire ou de modifier les intégrations qui sont finalement intégrées à l'apprentissage. modèle. Les approches du lexique des sentiments se concentrent sur l'intégration d'informations sur les sentiments (sous la forme d'intégrations de sentiments) dans le modèle d'apprentissage. Les approches du lexique sémantique se concentrent sur la transformation des intégrations de mots d'origine afin qu'elles représentent mieux les relations extraites d'un lexique sémantique. D'après nos résultats expérimentaux, les méthodes du lexique sémantique sont supérieures aux autres méthodes décrites dans cet article, avec une amélioration F1 d'au moins 4\xa0% en moyenne macroéconomique par rapport à la base de référence.", 'ar': 'يعد الكشف عن اللغة المسيئة موضوع بحث مهم ، وقد حظي باهتمام كبير مؤخرًا. يركز عملنا على اكتشاف الهجمات الشخصية في المحادثات عبر الإنترنت. نظرًا لأن البحث السابق حول هذه المهمة قد استخدم إلى حد كبير التعلم العميق المستند إلى حفلات الزفاف ، فإننا نستكشف استخدام المعاجم لتحسين الأساليب القائمة على التضمين في محاولة لمعرفة كيفية تطبيق هذه الأساليب في المهمة الخاصة لاكتشاف الهجمات الشخصية. تختلف الطرق التي تم تنفيذها وتجربتها في هذه الورقة تمامًا عن بعضها البعض ، ليس فقط في نوع المعاجم التي يستخدمونها (المشاعر أو الدلالات) ، ولكن أيضًا في الطريقة التي يستخدمون بها المعرفة من المعاجم ، من أجل البناء أو تغيير حفلات الزفاف التي يتم تغذيتها في نهاية المطاف في نموذج التعلم. تركز مناهج معجم المشاعر على دمج معلومات المشاعر (في شكل زخارف المشاعر) في نموذج التعلم. تركز مناهج المعجم الدلالي على تحويل الكلمة الأصلية إلى حفلات الزفاف بحيث تمثل بشكل أفضل العلاقات المستخرجة من المعجم الدلالي. استنادًا إلى نتائجنا التجريبية ، تتفوق طرق المعجم الدلالي على بقية الطرق في هذه الورقة ، مع تحسين F1 متوسط الماكرو بنسبة 4 ٪ على الأقل على خط الأساس.', 'es': 'Detectar el lenguaje abusivo es un tema de investigación importante, que ha recibido mucha atención recientemente. Nuestro trabajo se centra en la detección de ataques personales en las conversaciones en línea. Como investigaciones anteriores sobre esta tarea han utilizado en gran medida el aprendizaje profundo basado en incrustaciones, exploramos el uso de léxicos para mejorar los métodos basados en incrustaciones en un esfuerzo por ver cómo se aplican estos métodos en la tarea particular de detectar ataques personales. Los métodos implementados y con los que se experimenta en este artículo son muy diferentes entre sí, no solo en el tipo de léxicos que utilizan (sentimental o semántica), sino también en la forma en que utilizan el conocimiento de los léxicos, para construir o cambiar las incrustaciones que, en última instancia, se introducen en el aprendizaje modelo. Los enfoques del léxico de los sentimientos se centran en integrar la información de los sentimientos (en forma de incrustaciones de sentimientos) en el modelo de aprendizaje. Los enfoques del léxico semántico se centran en transformar las incrustaciones de palabras originales para que representen mejor las relaciones extraídas de un léxico semántico. Según nuestros resultados experimentales, los métodos de léxico semántico son superiores al resto de los métodos de este artículo, con al menos un 4% de mejora de F1 macropromediada con respecto a la línea base.', 'pt': 'A detecção de linguagem abusiva é um tópico de pesquisa significativo, que recebeu muita atenção recentemente. Nosso trabalho se concentra na detecção de ataques pessoais em conversas online. Como pesquisas anteriores sobre essa tarefa usaram amplamente o aprendizado profundo baseado em embeddings, exploramos o uso de léxicos para aprimorar métodos baseados em embedding em um esforço para ver como esses métodos se aplicam à tarefa específica de detectar ataques pessoais. Os métodos implementados e experimentados neste artigo são bastante diferentes entre si, não só no tipo de léxicos que utilizam (sentimento ou semântico), mas também na forma como utilizam o conhecimento dos léxicos, para construir ou alterar os embeddings que, em última análise, são inseridos no modelo de aprendizagem. As abordagens do léxico de sentimento se concentram na integração de informações de sentimento (na forma de embutimentos de sentimento) no modelo de aprendizado. As abordagens do léxico semântico se concentram em transformar os embeddings de palavras originais para que representem melhor as relações extraídas de um léxico semântico. Com base em nossos resultados experimentais, os métodos de léxico semântico são superiores ao restante dos métodos neste artigo, com pelo menos 4% de melhoria na média macro de F1 em relação à linha de base.', 'ja': '虐待的な言葉を検出することは、最近多くの注目を浴びている重要な研究テーマです。 私たちの仕事は、オンライン会話での個人攻撃を検出することに焦点を当てています。 この課題に関する以前の研究では、埋め込みに基づくディープラーニングが主に使用されているため、個人攻撃を検出する特定の課題にこれらの方法がどのように適用されるかを確認するために、埋め込みベースの方法を強化するための辞書の使用を探求しています。 この論文で実装され実験された方法は、使用する辞書の種類（感情または意味論）だけでなく、学習モデルに最終的にフィードバックされる埋め込みを構築または変更するために、辞書からの知識を使用する方法においても、互いにかなり異なっている。 センチメント辞書のアプローチは、センチメント情報（センチメント埋め込みの形式）を学習モデルに統合することに焦点を当てている。 セマンティック辞書のアプローチは、元の単語の埋め込みを変換することに焦点を当て、セマンティック辞書から抽出された関係をよりよく表現するようにします。 我々の実験結果に基づいて、意味論的語彙法は、本論文の他の方法よりも優れており、ベースラインよりも少なくとも4%マクロ平均化されたF 1の改善がある。', 'zh': '检诟性言为重研究课题,近多所关注。 吾事重者,检在线言人身攻击也。 故求词典以益嵌之法,以知所以检人身攻击之特定。 文之成试,彼此殊异,非唯词典类(情语义),而于其用词典之道,以构改终馈送嵌于学。 情词典法侧重于将情信息(以情销)集成模样。 语义词典法侧重于转换原始单词嵌,以便语义词典取。 以吾实验之终,语义词典优于本文之他术,宏观均F1比基线少高4%。', 'hi': 'अपमानजनक भाषा का पता लगाना एक महत्वपूर्ण शोध विषय है, जिसे हाल ही में बहुत ध्यान दिया गया है। हमारा काम ऑनलाइन बातचीत में व्यक्तिगत हमलों का पता लगाने पर केंद्रित है। जैसा कि इस कार्य पर पिछले शोध ने काफी हद तक एम्बेडिंग के आधार पर गहरी शिक्षा का उपयोग किया है, हम यह देखने के प्रयास में एम्बेडिंग-आधारित तरीकों को बढ़ाने के लिए शब्दकोशों के उपयोग का पता लगाते हैं कि ये विधियां व्यक्तिगत हमलों का पता लगाने के विशेष कार्य में कैसे लागू होती हैं। इस पेपर में लागू और प्रयोग किए गए तरीके एक-दूसरे से काफी अलग हैं, न केवल उनके द्वारा उपयोग किए जाने वाले शब्दकोशों के प्रकार (भावना या शब्दार्थ) में, बल्कि जिस तरह से वे शब्दकोशों से ज्ञान का उपयोग करते हैं, उस तरह से भी निर्माण करने या एम्बेडिंग को बदलने के लिए जो अंततः सीखने के मॉडल में खिलाए जाते हैं। भावना शब्दकोश दृष्टिकोण सीखने के मॉडल में भावना जानकारी (भावना एम्बेडिंग के रूप में) को एकीकृत करने पर ध्यान केंद्रित करते हैं। शब्दार्थ शब्दकोश दृष्टिकोण मूल शब्द एम्बेडिंग को बदलने पर ध्यान केंद्रित करते हैं ताकि वे एक शब्दार्थ शब्दकोश से निकाले गए संबंधों का बेहतर प्रतिनिधित्व कर सकें। हमारे प्रयोगात्मक परिणामों के आधार पर, शब्दार्थ शब्दकोश विधियां इस पेपर में बाकी विधियों से बेहतर हैं, बेसलाइन पर कम से कम 4% मैक्रो-औसत F1 सुधार के साथ।', 'ru': 'Обнаружение оскорбительного языка является важной темой исследования, которой в последнее время уделяется много внимания. Наша работа сосредоточена на обнаружении личных атак в онлайн разговорах. Поскольку предыдущие исследования этой задачи в значительной степени использовали глубокое обучение на основе вложений, мы исследуем использование лексиконов для улучшения методов на основе вложений, чтобы увидеть, как эти методы применяются в конкретной задаче обнаружения личных атак. Методы, реализованные и экспериментируемые в этой работе, сильно отличаются друг от друга не только в типе используемых ими лексиконов (сентиментальных или семантических), но и в том, как они используют знания из лексиконов, для построения или изменения вложений, которые в конечном итоге подаются в модель обучения. Подходы сентиментального лексикона направлены на интеграцию информации о сентиментах (в виде вложений сентиментов) в модель обучения. Подходы семантического лексикона сосредоточены на преобразовании оригинальных вложений слов, чтобы они лучше представляли отношения, извлеченные из семантического лексикона. Основываясь на наших экспериментальных результатах, семантические методы лексики превосходят остальные методы в этой статье, с улучшением по меньшей мере на 4% макроусредненного F1 по сравнению с базовой линией.', 'ga': 'Is ábhar suntasach taighde é teanga mhaslach a bhrath, ar tugadh go leor airde air le déanaí. Díríonn ár gcuid oibre ar ionsaithe pearsanta a bhrath i gcomhráite ar líne. Toisc gur bhain taighde a rinneadh roimhe seo ar an tasc seo úsáid den chuid is mó as foghlaim dhomhain bunaithe ar leabú, déanaimid iniúchadh ar úsáid na bhfoclóirí chun modhanna bunaithe ar leabú a fheabhsú mar iarracht a fheiceáil conas a bhaineann na modhanna seo leis an tasc ar leith a bhaineann le hionsaithe pearsanta a bhrath. Tá na modhanna a chuirtear i bhfeidhm agus a ndearnadh tástáil orthu sa pháipéar seo an-difriúil óna chéile, ní hamháin sa chineál foclóireachta a úsáideann siad (seomantacht nó séimeantach), ach freisin sa chaoi a n-úsáideann siad an t-eolas ó na foclóirí, chun tógáil nó chun leabú a athrú a chuirtear isteach sa mhúnla foghlama ar deireadh. Díríonn an cur chuige foclóir meon ar eolas mothúcháin a chomhtháthú (i bhfoirm leabú mothúcháin) isteach sa mhúnla foghlama. Díríonn na cineálacha cur chuige foclóireachta séimeantach ar leabú na bhfocal bunaidh a athrú ionas gur fearr a léiríonn siad gaolmhaireachtaí a bhaintear as foclóir shéimeantach. Bunaithe ar ár dtorthaí turgnamhacha, tá modhanna foclóireachta séimeantacha níos fearr ná an chuid eile de na modhanna sa pháipéar seo, agus tá feabhas ar a laghad 4% ar mhacra-mheán F1 thar an mbunlíne.', 'el': 'Η ανίχνευση καταχρηστικής γλώσσας είναι ένα σημαντικό ερευνητικό θέμα, το οποίο έχει λάβει μεγάλη προσοχή πρόσφατα. Η εργασία μας επικεντρώνεται στην ανίχνευση προσωπικών επιθέσεων σε διαδικτυακές συνομιλίες. Καθώς η προηγούμενη έρευνα σε αυτό το έργο έχει χρησιμοποιηθεί σε μεγάλο βαθμό βαθιά μάθηση βασισμένη σε ενσωμάτωση, εξερευνούμε τη χρήση λεξικών για την ενίσχυση των μεθόδων ενσωμάτωσης σε μια προσπάθεια να δούμε πώς αυτές οι μέθοδοι εφαρμόζονται στο συγκεκριμένο έργο της ανίχνευσης προσωπικών επιθέσεων. Οι μέθοδοι που εφαρμόστηκαν και πειραματίστηκαν στην παρούσα εργασία είναι αρκετά διαφορετικές μεταξύ τους, όχι μόνο στο είδος των λεξικών που χρησιμοποιούν (συναισθηματικό ή σημασιολογικό), αλλά και στον τρόπο που χρησιμοποιούν τη γνώση από τα λεξικά, προκειμένου να κατασκευάσουν ή να αλλάξουν ενσωματώσεις που τελικά τροφοδοτούνται στο μαθησιακό μοντέλο. Οι προσεγγίσεις του λεξικού συναισθημάτων επικεντρώνονται στην ενσωμάτωση πληροφοριών συναισθημάτων (με τη μορφή ενσωμάτωσης συναισθημάτων) στο μαθησιακό μοντέλο. Οι προσεγγίσεις σημασιολογικού λεξικού εστιάζουν στη μετατροπή των αρχικών ενσωμάτωσης λέξεων έτσι ώστε να αντιπροσωπεύουν καλύτερα σχέσεις που εξάγονται από ένα σημασιολογικό λεξικό. Με βάση τα πειραματικά μας αποτελέσματα, οι μέθοδοι σημασιολογικού λεξικού είναι ανώτερες από τις υπόλοιπες μεθόδους αυτής της εργασίας, με τουλάχιστον 4% μακρομέση βελτίωση F1 έναντι της βάσης.', 'ka': 'ძალიან ძალიან ძალიან ძალიან მნიშვნელოვანი სურათი იყო, რომელიც მხოლოდ მნიშვნელოვანია. ჩვენი სამუშაო იქნება ინტერნეტიური პარამეტრებში პირადი ატაკების განახლებაზე. როგორც ამ დავალების წინა შესწავლობა ძალიან ძალიან გამოიყენება საშუალო სწავლობა, როგორც ჩვენ შევხედავთ ლექსიკონის გამოყენებას, როგორც ჩვენ შევხედავთ, როგორ ეს მეტოვები გამოყენება პირად ამ დომენტში გამოყენებული და ექსპერიმენტირებული მეტოვები ძალიან განსხვავებულია ერთმანეთისგან, არა მხოლოდ ლექსიკონის ტიპში, რომელიც გამოყენებენ (სინტემენტი ან სმენტიკური), მაგრამ ასევე როგორც ისინი ლექსიკონის მეცნიერებას გამ სენტიმენტური ლექსიკონი მოთავსდება სენტიმენტური ინფორმაციის ინტერგურაციას (სენტიმენტური ინფორმაციის ფორმაში) სწავლების მოდელში. სემონტიკური ლექსიკონის კონსტიკონის გარემოქმებაზე გარემოქმება, რომ ისინი უკეთესი გარემოქმება სემონტიკური ლექსიკონიდან გარემოქმება. ჩვენი ექსპერიმენტიური წარმოდგენებიდან, სემონტიკური ლექსიკონის მეტედისები უფრო მეტია ამ დონტში დასრულებული მეტედისებიდან, რომელიც მინუს 4% მაკრო განსაზღვრებული F1 დასრულ', 'hu': 'A visszaélő nyelv felismerése jelentős kutatási téma, amely az utóbbi időben nagy figyelmet kapott. Munkánk a személyes támadások felderítésére összpontosít az online beszélgetések során. Mivel az e feladatra vonatkozó korábbi kutatások nagyrészt beágyazáson alapuló mélytanulást használtak, feltárjuk a lexikonok használatát a beágyazáson alapuló módszerek javítására annak érdekében, hogy ezek a módszerek miként alkalmazhatók a személyes támadások felderítésére irányuló különleges feladatokban. A tanulmányban megvalósított és kísérletezett módszerek nagyon különböznek egymástól, nemcsak a lexikonok típusában (sentiment vagy szemantikai), hanem a lexikonok tudásának felhasználásában is, a tanulási modellbe végül táplált beágyazások kialakítására vagy megváltoztatására. Az érzelmi lexikon megközelítések az érzelmi információk (érzelmi beágyazások formájában) tanulási modellbe történő integrálására összpontosítanak. A szemantikai lexikon megközelítések az eredeti szóbeágyazások átalakítására összpontosítanak, hogy jobban reprezentálják a szemantikai lexikonból kivont kapcsolatokat. Kísérleti eredményeink alapján a szemantikai lexikon módszerek jobbak a jelen tanulmány többi módszeréhez képest, legalább 4%-os makro-átlagos F1 javulással az alaphelyzethez képest.', 'it': "Rilevare il linguaggio abusivo è un argomento di ricerca significativo, che ha ricevuto molta attenzione recentemente. Il nostro lavoro si concentra sul rilevamento di attacchi personali nelle conversazioni online. Poiché le ricerche precedenti su questo compito hanno ampiamente utilizzato il deep learning basato sull'embedding, esploriamo l'uso dei lessici per migliorare i metodi basati sull'embedding nel tentativo di vedere come questi metodi si applicano nel particolare compito di rilevare gli attacchi personali. I metodi implementati e sperimentati in questo articolo sono molto diversi l'uno dall'altro, non solo per il tipo di lessico che usano (sentiment o semantico), ma anche per il modo in cui utilizzano le conoscenze dei lessici, al fine di costruire o cambiare incorporazioni che vengono infine alimentate nel modello di apprendimento. Gli approcci del lessico sentimentale si concentrano sull'integrazione delle informazioni sentimentali (sotto forma di embedding sentiment) nel modello di apprendimento. Gli approcci lessicali semantici si concentrano sulla trasformazione delle incorporazioni di parole originali in modo da rappresentare meglio le relazioni estratte da un lessico semantico. Sulla base dei nostri risultati sperimentali, i metodi lessicali semantici sono superiori al resto dei metodi in questo articolo, con almeno il 4% di miglioramento F1 macro-medio rispetto al basale.", 'lt': 'Nustatyti piktnaudžiaujančią kalbą yra svarbi mokslinių tyrimų tema, kuri neseniai buvo daug dėmesio skiriama. Mūsų darbe daugiausia dėmesio skiriama asmeninių išpuolių aptikimui internetiniuose pokalbiuose. As previous research on this task has largely used deep learning based on embeddings, we explore the use of lexicons to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks.  Šiame dokumente taikomi ir eksperimentuojami metodai visiškai skiriasi vienas nuo kito ne tik jų naudojamų leksikonų tipu (jausmas arba semantinis), bet ir jų naudojimu iš leksikonų gaunamų žinių, kad būtų galima konstruoti arba pakeisti įdėjimus, kurie galiausiai patenka į mokymosi model į. Sentimento leksikono metoduose daugiausia dėmesio skiriama jautrumo informacijos (jautrumo įtraukimo formos) integravimui į mokymosi model į. Semantinis leksikonas daugiausia dėmesio skiria pradiniam žodžio įterpimui pakeisti, kad jie geriau atspindėtų santykius, ištrauktus iš semantinio leksikono. Remiantis mūsų eksperimentiniais rezultatais, semantiniai leksikono metodai yra geresni už likusius šiame dokumente pateiktus metodus, o F1 pagerėjimas yra ne mažesnis kaip 4 % makroekonominiu vidurkiu palyginti su pradiniu.', 'ms': 'Detecting abusive language is a significant research topic, which has received a lot of attention recently.  Our work focuses on detecting personal attacks in online conversations.  Sebagai kajian terdahulu mengenai tugas ini telah menggunakan kebanyakan belajar dalam berdasarkan penerbangan, kami mengeksplorasi penggunaan leksikon untuk meningkatkan kaedah berdasarkan penerbangan dalam usaha untuk melihat bagaimana kaedah ini berlaku dalam tugas tertentu untuk mengesan serangan peribadi. Kaedah yang dilaksanakan dan diuji dalam kertas ini agak berbeza antara satu sama lain, bukan sahaja dalam jenis leksikon yang mereka gunakan (perasaan atau semantik), tetapi juga dalam cara mereka menggunakan pengetahuan dari leksikon, untuk membina atau mengubah penerbangan yang akhirnya dimakan ke dalam model belajar. Leksikon sentimen mendekati fokus pada mengintegrasikan maklumat sentimen (dalam bentuk penyelesaian sentimen) ke dalam model belajar. Leksikon semantik mendekati fokus pada mengubah penyambungan perkataan asal sehingga ia lebih baik mewakili hubungan yang dikeluarkan dari leksikon semantik. Berdasarkan hasil percubaan kami, kaedah leksikon semantik lebih baik daripada kaedah yang lain dalam kertas ini, dengan sekurang-kurangnya 4% makro-rata F1 peningkatan atas asas.', 'kk': 'Қатысушылық тілді анықтау - ең жаңа тәртіпті зерттеу нақышы. Жұмыс істегеніміз онлайн сұрақтардағы жеке атқаруларды табуға көмектеседі. Бұл тапсырманың алдыңғы зерттеулері енгізуге негізделген терең оқытуды қолданғанда, біз лексикондың қолдануын зерттеп, осы әдістерді жеке жағдайларды анықтау тапсырмасында қалай қолданылатын әрекеттерді көру үшін кө Бұл қағазда іске асырылған және тәжірибе әдістері бір-бірінен әртүрлі емес, олар тек қолданылатын лексикондың түрінде емес, сондай-ақ олар лексикондың білімін қолдану үшін, ең соңында оқыту үлгісін құру не өзгерту үшін. Сөздік лексиконы оқыту үлгісіне көздеген мәліметті (сезімдік ендіру түрінде) ендіру үлгісіне көздейді. Семантикалық лексикон бастапқы сөздерді ендіру үшін көздеген көздеген, сондықтан олар semantic лексикондан шығарылған қатынастарды жақсы көрсетеді. Тәжірибелік нәтижелерімізге негізделген, семантикалық лексикалық әдістері осы қағаздың басқа әдістерінен артық, кемінде 4% макро орташа F1 дегенді негізгі жолда жақсарту үшін.', 'mk': 'Детектирањето на злоупотребен јазик е значајна истражувачка тема, која неодамна доби многу внимание. Нашата работа се фокусира на детектирање на лични напади во онлајн разговори. As previous research on this task has largely used deep learning based on embeddings, we explore the use of lexicons to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks.  Методите спроведени и експериментирани во оваа хартија се сосема различни меѓусебно, не само во типот на лексикони кои ги користат (чувства или семантични), туку и на начинот на кој ги користат знаењата од лексиконите, со цел да се конструираат или да се менуваат вградувањата кои на крајот се хранат во моделот на учење. Лексиконот на чувствата се приближува кон интеграцијата на информациите за чувствата (во форма на вградување на чувствата) во моделот на учење. Семантичкиот лексикон се приближува да се фокусира на трансформирањето на оригиналните зборови вградени за подобро да ги претставуваат односите извадени од семантичкиот лексикон. Според нашите експериментални резултати, семантичките лексиконски методи се супериорни од останатите методи во оваа вест, со најмалку 4 отсто макро-просечно подобрување на F1 во однос на основата.', 'ml': 'പീഡിപ്പിക്കുന്ന ഭാഷ കണ്ടുപിടിക്കുന്നത് ഒരു പ്രധാനപ്പെട്ട പഠിപ്പിക്കുന്ന കാര്യമാണ്. അതിന്റെ  ഞങ്ങളുടെ ജോലി ഓണ്\u200dലൈന്\u200d സംസാരിക്കുന്നതില്\u200d വ്യക്തിപരമായ ആക്രമണങ്ങള്\u200d കണ്ടെത്തുന്നതിന് ശ്രദ്ധ ഈ ജോലിയിലെ മുമ്പുള്ള പഠനത്തില്\u200d ആഴത്തില്\u200d പഠിക്കുന്നത് പോലെ ലെക്സിക്കന്\u200dമാരുടെ ഉപയോഗം നമ്മള്\u200d പരിശോധിക്കുന്നു. സ്വകാര്യ ആക്രമണങ്ങള്\u200d കണ്ടെത്തുന ഈ പത്രത്തില്\u200d പ്രവര്\u200dത്തിപ്പിക്കപ്പെടുകയും പരീക്ഷിക്കപ്പെടുകയും ചെയ്യുന്ന രീതികള്\u200d പരസ്പരം വ്യത്യസ്തമാകുന്നു. ലെക്സിക്ഷന്\u200dമാരില്\u200d നിന്നും അവര്\u200d ഉപയോഗിക്കുന്ന ലെക്സിക്കോണില്\u200d നി ലെക്സിക്കോണിന്റെ വികാരം ശിക്ഷ മാതൃകയിലേക്ക് ശ്രദ്ധിക്കുന്നതിന് ശ്രദ്ധിക്കുന്നതാണ്. സെമാന്റിക് ലെക്സിക്കോണ്\u200d ആദ്യ വാക്കുകള്\u200d മാറ്റുന്നതിന് ശ്രദ്ധിക്കുന്നു. അതുകൊണ്ട് അവര്\u200d സെമാന്റിക് ലെക്സിക്കോണില്\u200d  നമ്മുടെ പരീക്ഷണ ഫലങ്ങള്\u200d അടിസ്ഥാനമായി ഈ പത്രത്തിലെ മറ്റുള്ള രീതികളെക്കാള്\u200d സെമാന്റിക്ക് ലെക്സിക്കോണ്\u200d രീതികള്\u200d മെച്ചപ്പെടുത്തുന്നു.', 'no': 'Oppdaging av abusive språk er eit viktig forskningsemne, som har motteken mykje oppmerksomhet nyleg. Arbeidet vårt fokuserer på å finna personlege ataka i nettsamtaler. Som førre forskning på denne oppgåva har brukt stort dyp læring basert på innbygging, så utforskar vi bruken av leksikoner for å forbetra innbyggingsbaserte metodar i ein forsøk for å sjå korleis desse metodane brukar i den spesielle oppgåva om oppdaging av personlege ataka. Metodane som er implementerte og eksperimentert med i denne papiret er ganske forskjellige frå kvarandre, ikkje berre i typen leksikon dei brukar (sentiment eller semantisk), men også på måten dei brukar kunnskapen frå leksikonet, for å konstruere eller endra innbygging som er til slutt ført til læringsmodellen. Sensitingsleksikon nærmer fokus på å integrera sentimentsinformasjon (i form av sentimentinnbygging) i læringsmodellen. Semantisk leksikon nærmer fokus på å transformera originale ordinnbygging slik at dei bedre representerer forholdet ekstrahert frå eit semantisk leksikon. Basert på eksperimentelle resultater våre, er semantiske leksikonsmetodar over resten av metodane i denne papiret, med minst 4% makro-gjennomsnittlig forbedring av F1 over grunnlinja.', 'mt': 'Is-sejba ta’ lingwa abbużiva hija suġġett ta’ riċerka sinifikanti, li reċentement irċeviet ħafna attenzjoni. Il-ħidma tagħna tiffoka fuq l-identifikazzjoni ta’ attakki personali fi konverżjonijiet onlajn. Peress li r-riċerka preċedenti dwar dan il-kompitu fil-biċċa l-kbira użat tagħlim fil-fond ibbażat fuq l-inkorporazzjonijiet, aħna nesploraw l-użu tal-lexicons biex itejbu l-metodi bbażati fuq l-inkorporazzjoni fi sforz biex naraw kif dawn il-metodi japplikaw fil-kompitu partikolari li jinstabu attakki personali. The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the lexicons, in order to construct or to change embeddings that are ultimately fed into the learning model.  L-approċċi tal-lexicon tas-sentimenti jiffokaw fuq l-integrazzjoni tal-informazzjoni tas-sentimenti (fil-forma ta’ inkorporazzjonijiet tas-sentimenti) fil-mudell tat-tagħlim. L-approċċi tal-lexicon semantiku jiffokaw fuq it-trasformazzjoni tal-kliem inkorporati oriġinali sabiex jirrappreżentaw a ħjar ir-relazzjonijiet estratti minn lexicon semantiku. Abbażi tar-riżultati sperimentali tagħna, il-metodi semantiċi tal-lexicons huma superjuri għall-bqija tal-metodi f’dan id-dokument, b’mill-inqas 4% titjib makro-medju ta’ F1 fuq il-linja bażi.', 'sr': 'Otkrivanje nasilnog jezika je značajna tema istraživanja, koja je nedavno dobila mnogo pažnje. Naš rad se fokusira na otkrivanje osobnih napada u internetskim razgovorima. Kao što je prethodno istraživanje na ovom zadatku u velikoj meri koristilo duboko učenje na osnovu integracije, istražujemo korištenje leksikona kako bi poboljšali metode na osnovu integracije u pokušaju da vidimo kako se te metode primjenjuju u posebnom zadatku otkrivanja ličnih napada. Metode provedene i eksperimentirane sa ovim papirom su prilično različite jedni od drugih, ne samo u tipu leksiona koje koriste (osjećaj ili semantički), nego i na način na koji koriste znanje iz leksiona, kako bi se konstruirali ili promenili integracije koje su na kraju nahranjene u model učenja. Leksikon sentimenta približava se fokusiranju na integraciju informacija o sentimentu (u obliku integracije sentimenta) u model učenja. Semantički leksikon se približava koncentraciji na transformaciji originalne reči o integraciji tako da bolje predstavljaju odnose izvedene iz semantičkog leksikona. Na temelju naših eksperimentalnih rezultata, semantičke leksičke metode su nadmašile ostalim metodama u ovom papiru, sa najmanje 4% makro-srednje poboljšanje F1 iznad početne linije.', 'mn': 'Хүчирхийллэх хэл гэдэг нь саяхан маш их анхаарал авсан судалгааны сэдэв юм. Бидний ажил онлайн ярилцлаганд хувийн дайралтуудыг олж мэдэхэд анхаарна. Энэ ажлын өмнөх судалгааны тухай ихэнхдээ гүн гүнзгий суралцах сургалтыг ашиглаж байхад бид Лексиконуудын хэрэглээ хувийн дайралд хэрхэн хэрэглэгддэгийг харах зорилго дээр нэмэгдүүлэх зорилго ашиглаж байна. Энэ цаасан дээр хийгдсэн, туршилтын арга нь бие бие биенээ өөрчлөгдөж, зөвхөн хэрэглэдэг лексиконуудын төрөл биш, мөн лексиконуудын мэдлэгийг ашиглах, эцэст нь суралцах загвар руу шилжүүлэх эсвэл өөрчлөгдөх боломжтой. Сэтгэл хөдлөл нь мэдрэмжтэй мэдээллийг суралцах загвар руу нэгтгэх (мэдрэмжтэй байдлын хэлбэр) дээр анхаарлаа хандуулдаг. Земантик лексикон нь эхний үгийг өөрчлөх тулд анхаарлаа ойртож байна. Ингээд тэд semantic лексиконоос гарсан харилцаа илүү сайн илэрхийлдэг. Бидний туршилтын үр дүн дээр, семантик лексикон арга нь энэ цаасан дээрх бусад арга замаас илүү өндөр, хамгийн бага 4% макро дундаж F1 нь суурь шугам дээр сайжруулсан.', 'pl': 'Wykrywanie obraźliwego języka jest ważnym tematem badawczym, który ostatnio zyskał dużą uwagę. Nasza praca koncentruje się na wykrywaniu ataków osobistych w rozmowach online. Ponieważ poprzednie badania nad tym zadaniem w dużej mierze wykorzystywały głębokie uczenie się oparte na osadzeniach, badamy wykorzystanie leksykonów w celu ulepszenia metod osadzenia w celu sprawdzenia, jak te metody mają zastosowanie w konkretnym zadaniu wykrywania ataków osobistych. Metody wdrożone i eksperymentowane w niniejszym artykule różnią się od siebie zupełnie, nie tylko rodzajem stosowanych przez nich leksykonów (sentyment czy semantyczny), ale także sposobem wykorzystywania wiedzy z leksykonów w celu konstruowania lub zmiany osadzeń, które ostatecznie są wprowadzane do modelu uczenia się. Podejścia do leksykonu sentymentów koncentrują się na integracji informacji sentymentów (w postaci osadzeń sentymentów) w modelu uczenia się. Podejścia semantyczne koncentrują się na przekształceniu oryginalnych osadzeń słowa tak, aby lepiej reprezentowały relacje wyodrębnione z leksykonu semantycznego. Na podstawie naszych wyników eksperymentalnych metody semantyczne są lepsze od pozostałych metod zawartych w niniejszym artykule, z co najmniej 4% makroeśrednią poprawą F1 w stosunku do bazy wyjściowej.', 'ro': 'Detectarea limbajului abuziv este un subiect semnificativ de cercetare, care a primit o mulțime de atenție recent. Activitatea noastră se concentrează pe detectarea atacurilor personale în conversațiile online. Deoarece cercetările anterioare privind această sarcină au utilizat în mare măsură învățarea profundă bazată pe încorporări, explorăm utilizarea lexicoanelor pentru a îmbunătăți metodele bazate pe încorporare, într-un efort de a vedea cum se aplică aceste metode în sarcina particulară de detectare a atacurilor personale. Metodele implementate și experimentate în această lucrare sunt destul de diferite una de cealaltă, nu numai în tipul de lexicoane pe care le folosesc (sentiment sau semantic), ci și în modul în care folosesc cunoștințele din lexicoane, pentru a construi sau a schimba încorporări care sunt în cele din urmă alimentate în modelul de învățare. Abordările lexiconului sentimental se concentrează pe integrarea informațiilor sentimentale (sub formă de încorporări sentimentale) în modelul de învățare. Abordările lexiconului semantic se concentrează pe transformarea încorporărilor cuvintelor originale, astfel încât acestea să reprezinte mai bine relațiile extrase dintr-un lexicon semantic. Pe baza rezultatelor experimentale, metodele de lexicon semantic sunt superioare celorlalte metode din această lucrare, cu cel puțin 4% îmbunătățire macro-medie F1 față de bază.', 'ta': 'மொழியை கண்டுபிடிப்பது ஒரு முக்கியமான ஆராய்ச்சி தலைப்பு, அது சமீபத்தில் நிறைய கவனம் பெற்றது. எங்கள் வேலை தனிப்பட்ட தாக்கியங்களை கண்டுபிடிக்கும் பொழுது கவனம் செலுத்துகிறது. இந்த பணியின் முந்தைய ஆராய்ச்சி பெரும்பாலாக உள்ளீடுகளை அடிப்படையில் ஆழமான கற்றலை பயன்படுத்தியுள்ளது, நாம் லெக்சிக்ஸியன் பயன்படுத்தும் முறைகளை அதிகரிக்க இந்த காகிதத்தில் செயல்படுத்தப்பட்டுள்ள முறைகள் மற்றும் சோதிக்கப்பட்டது மிகவும் வேறுபாடு இருக்கிறது, அவர்கள் மட்டுமே பயன்படுத்துகிறார்கள் (உணர்வு அல்லது பாதிப்பு வகையில் மட்டும் அல்ல,  The sentiment lexicon approaches focus on integrating sentiment information (in the form of sentiment embeddings) into the learning model.  பெம்மான்டிக் லெக்சிகான் நெருங்குகிறது முதல் வார்த்தைகளை மாற்றும் போது கவனம் செலுத்துகிறது, அதனால் அவர்கள் ஒரு பெம்மான்ட எங்கள் சோதனையின் முடிவுகளை அடிப்படையில், இந்த காகிதத்தில் மற்ற முறைகளை விட பெரிய பாதிப்பு முறைகளாக இருக்கிறது, குறைந்தது 4% மேக்ரோ சராசரி F', 'so': 'Aqoonsashada luqada isticmaalka waa arin waxbarasho oo muhiim ah, taasoo ugu dhowaad aad aad u dhegaysatay. Shaqodayadu waxay ku focus yihiin in ay ogaato weerar shakhsiyeed oo ku qoran hadalka internetka. Sida baaritaankii hore ee shuqulkaas uu si badan u isticmaalay waxbarasho aad u dheer, waxaynu baaraynaa isticmaalka leksikanka si loo kordhiyo qaababka lagu kordhiyo, si aan u aragno sida qaababkan loo codsado gooni ah shaqo ku saabsan in lagu ogaado weerarka shakhsiga ah. Dhaqdooyinka lagu sameeyo iyo lagu tijaabiyey warqaddan qaarkood way ka duwan yihiin, ma aha nooca leksikada oo keliya ee ay isticmaalaan (fikrada ama semantika), laakiin sidoo kale sida ay aqoonta leksikanka uga isticmaalaan, si ay u dhisaan ama u beddelaan sawirada ugu dambeeya qaabka waxbarashada. Fikirada leksikanka ayaa ku soo dhowaanaya inuu ku kalsooneeyo macluumaadka xisaabta (foomka daryeelka xisaabta) sameynta waxbarashada. Leksikan ayaa soo dhowaadaa si ay u beddelaan hadalka asalka ah oo uu u beddelo si ay u hagaajiyaan xiriirka laga soo saaray leksikan. Inta lagu saleyn karo resultiyada imtixaanka, qaababka leksikaanka ah ayaa ka sarreeya qaababka kale ee warqadan ku qoran, waxayna ugu yaraan 4% macro-average F1 horumarinta hoose.', 'si': 'අපරාධ භාෂාව හොයාගන්න පුළුවන් විදියට පරීක්ෂණ ප්\u200dරශ්නයක්, ඒක අවස්ථානයේ ගොඩක් අවධ අපේ වැඩේ පෞද්ගලික ප්\u200dරහාරයක් අන්ලයාන් කතා කරන්නේ පරික්ෂා කරන්න. මේ ව්\u200dයාපෘතියේ පසුගිය පරීක්ෂණය සඳහා ගොඩක් ගොඩක් ඉගෙනගන්න පාවිච්චි කරලා තියෙනවා, අපි ලෙක්සිකන්ස් භාවිතාව පරීක්ෂණය කරනවා පුද්ගල මේ පත්තරේ පරීක්ෂණය සහ පරීක්ෂණය කරලා තියෙන විදිහට වෙනස් වෙන්නේ, ඔවුන් පාවිච්චි ලෙක්සිකෝන්ස් වර්ගයෙන් විතරක් නෙවෙයි (දේවල් සහ සෙමැන්ටික්), ඒත් ඔවුන් ප සංවේදනය ලෙක්සිකන් පිළිගන්නවා දැනුම් තොරතුරු සම්බන්ධ කරන්න (සංවේදනය සම්බන්ධ විදිහට) ඉගෙනීම් මොඩේල සෙමැන්ටික් ලෙක්සිකෝන් ප්\u200dරධාන වචනය සම්බන්ධ වෙනුවෙන් ප්\u200dරධාන වචනය සම්බන්ධ වෙනුවෙන් ප්\u200dරධානය කරනවා එතක අපේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාර විදිහට, සෙමැන්ටික් ලෙක්සිකෝන් විදිහට මේ පැත්තේ ඉතුරු විදිහට වඩා වඩා වඩා විශේෂයි, අ', 'sv': 'Att upptäcka kränkande språk är ett viktigt forskningsämne som har fått mycket uppmärksamhet på senare tid. Vårt arbete fokuserar på att upptäcka personliga attacker i onlinesamtal. Eftersom tidigare forskning kring denna uppgift till stor del har använt djupinlärning baserat på inbäddningar undersöker vi användningen av lexikon för att förbättra inbäddningsbaserade metoder i ett försök att se hur dessa metoder tillämpas i den särskilda uppgiften att upptäcka personliga attacker. De metoder som implementeras och experimenteras med i denna uppsats skiljer sig helt från varandra, inte bara i vilken typ av lexikon de använder (sentiment eller semantik), utan också i hur de använder kunskapen från lexikonerna, för att konstruera eller ändra inbäddningar som slutligen matas in i inlärningsmodellen. Sentimentlexikonen fokuserar på att integrera sentimentinformation (i form av sentimentinbäddningar) i inlärningsmodellen. Det semantiska lexikontillvägagångssättet fokuserar på att omvandla det ursprungliga ordet inbäddningar så att de bättre representerar relationer extraherade från ett semantiskt lexikon. Baserat på våra experimentella resultat är semantiska lexikonmetoder överlägsna de övriga metoderna i denna uppsats, med minst 4% makro-genomsnittlig F1 förbättring jämfört med baslinjen.', 'ur': 'زیادتی زبان کی تلاش کرنا ایک اہم تحقیق موضوع ہے جو اچھے وقت بہت اظہار کیا گیا ہے۔ ہمارا کام آنلاین کی باتوں میں شخصی حملہ کا مشاہدہ کرنا ہے۔ اس کام پر پہلے کی تحقیق بہت زیادہ عمیق تعلیم کا استعمال کیا گیا ہے جو انبوڈینگ پر بنیاد ہے، ہم لکسینز کے استعمال کی تحقیق کرتے ہیں کہ انبوڈینگ بنیاد طریقے کو زیادہ مضبوط بنانے کے لئے ایک کوشش میں دیکھیں کہ یہ طریقے کس طرح استعمال کرتے ہیں شخصی حملہ کا شناس اس کاغذ میں مطابق اور آزمائش کی طریقے ایک دوسرے سے بہت مختلف ہیں، نہ صرف لکسینز کی طرح میں جو وہ استعمال کرتے ہیں، بلکہ اسی طرح بھی لکسینز کے علم کا استعمال کرتے ہیں، تاکہ انڈینگ بنائیں یا تبدیل کریں جو بالاخره سیکھنے کی مدل میں کھائی جاتی ہیں. احساسات لکسون سیکھنے کے موڈل میں سیکھنے کے لئے احساسات معلومات (احساسات انڈیینگ کی شکل میں) تخلیق کرنے کے لئے تمرکز کرتا ہے۔ سیمنٹی لکسون کی طرف متوجہ ہو جاتی ہے کہ اصلی لکھ انڈینگ کی تبدیل کرنے پر سوچنے لگتا ہے تاکہ وہ بہتر معاملہ کریں جو ایک سیمنٹی لکسون سے نکالے گئے ہیں. ہمارے آزمائش نتائج پر بنیاد ہے، سیمنٹی لکسیون طریقے اس کاغذ میں بقیہ طریقے سے زیادہ ہیں، کم تر 4% مکرو متوسط F1 کی ابزار لین پر زیادہ.', 'uz': "Ularni aniqlash uchun juda muhim taʼminlovchi mavzu, u yaqinda ko'p paydo bo'lgan. Bizning ishimiz shaxsiy chaqaloqlarni aniqlash uchun foydalanadi. Bu vazifaning oldingi o'rganish asosida o'rganishda, biz leksikanlarning foydalanishini o'rganamiz, bu usullarni shaxsiy attacklarni aniqlashga qanday foydalanishini ko'rganish uchun foydalanamiz. Ushbu qogʻozda ishlatilgan usullar boshqa bir-birga o'xshash, balki faqat leksikanlar turida ishlatiladigan (hissiyot yoki semantik kabi), balki leksikanlarning ma'lumotlarini ishlatish uchun yoki oxirgi o'rganish modeliga o'zgartirish uchun. Leksikaning hissiyoti o'rganish modelidagi hissiyot haqida birlashtirishga foydalanadi. Semantik leksika orqali asl so'zlarini o'zgartirish uchun asl so'zlarini o'zgartirishga foydalanadi va ularning semantik leksisidan tashkilotgan munosabatlarni yaxshi ko'rsatish mumkin. Bizning tajriba natijalarimizga asosida, bu qogʻozdagi semantik leksikan metodalarning boshqa usullarda ko'proq, asosiy sohasida minimum 4% makro-o'rtacha F1 yaxshi darajada o'zgarishdir.", 'vi': 'Việc phát hiện ngôn ngữ lạm dụng là một chủ đề nghiên cứu quan trọng, và gần đây đã được chú ý rất nhiều. Công việc của chúng tôi tập trung vào việc phát hiện tấn công trực tuyến. Vì các nghiên cứu trước về nhiệm vụ này đã sử dụng hầu hết các nghiên cứu sâu học dựa trên sự nhúng tay, chúng tôi khám phá sử dụng ngôn ngữ từ ngữ để tăng cường phương pháp phù hợp để tìm hiểu cách sử dụng các phương pháp này trong nhiệm vụ đặc biệt là phát hiện các cuộc tấn công cá nhân. Những phương pháp được áp dụng và thí nghiệm với tờ giấy này hoàn to àn khác nhau, không chỉ trong dạng ngôn ngữ mà họ sử dụng (đa cảm hay ngữ pháp), mà còn trong cách họ sử dụng kiến thức từ ngôn ngữ, để xây dựng hay thay đổi sự tác động của sự nhúng tay vào các mô hình học vấn. Cách tiếp cận ngôn ngữ cảm xúc tập trung vào việc thấu hiểu thông tin tình cảm (dạng sự gắn bó tình cảm) trong mô hình học. Cách tiếp cận từ ngữ pháp tập trung vào việc thay đổi sự ghép nối từ nguyên bản để chúng đại diện tốt hơn các mối quan hệ chiết xuất từ ngữ pháp. Dựa trên kết quả thử nghiệm của chúng ta, các phương pháp văn hóa ngữ pháp vượt trội so với các phương pháp còn lại trong tờ giấy này, với ít nhất bốn phần vi tính cộng tổng số F1 cải tiến trên cơ sở.', 'da': 'At opdage misbrug af sprog er et vigtigt forskningsemne, som har fået stor opmærksomhed på det seneste. Vores arbejde fokuserer på at opdage personlige angreb i onlinesamtaler. Da tidligere forskning i denne opgave i vid udstrækning har brugt dyb læring baseret på indlejringer, undersøger vi brugen af leksikoner til at forbedre indlejringsbaserede metoder i et forsøg på at se, hvordan disse metoder anvendes i den særlige opgave med at detektere personlige angreb. De metoder, der implementeres og eksperimenteres med i denne artikel, er ganske forskellige fra hinanden, ikke kun i den type leksikoner de bruger (sentiment eller semantisk), men også i den måde de bruger viden fra leksikonerne til at konstruere eller ændre indlejringer, der i sidste ende bliver fodret ind i læringsmodellen. Sentiment leksikon tilgange fokuserer på at integrere sentiment information (i form af sentiment embeddings) i læringsmodellen. Den semantiske leksikon tilgange fokuserer på at transformere de oprindelige ord embeddings, så de bedre repræsenterer relationer udvundet fra et semantisk leksikon. Baseret på vores eksperimentelle resultater, semantiske leksikon metoder er bedre end resten af metoderne i denne artikel, med mindst 4% makro-gennemsnit F1 forbedring i forhold til baseline.', 'bg': 'Откриването на злоупотребяващ език е важна изследователска тема, която получи много внимание напоследък. Работата ни се фокусира върху откриването на лични атаки в онлайн разговори. Тъй като предишните изследвания на тази задача до голяма степен използват дълбоко обучение въз основа на вграждания, ние изследваме използването на лексикони за подобряване на базираните на вграждането методи в опит да видим как тези методи се прилагат в конкретната задача за откриване на лични атаки. Методите, прилагани и експериментирани в тази статия, са доста различни един от друг, не само по типа лексикони, които използват (сантиментални или семантични), но и по начина, по който използват знанията от лексиконите, за да изградят или променят вгражданията, които в крайна сметка се захранват с модела на учене. Сентименталният лексикон подходи се фокусира върху интегрирането на сентиментална информация (под формата на вграждане на сентимента) в модела на обучение. Сентическите лексиконови подходи се фокусират върху трансформирането на оригиналните вграждания на думи, така че да представят по-добре взаимоотношенията, извлечени от семантичен лексикон. Въз основа на нашите експериментални резултати, семантичните лексиконни методи са по-добри от останалите методи в тази статия, с най-малко 4% макросредно подобрение спрямо базовата база.', 'nl': 'Het opsporen van beledigende taal is een belangrijk onderzoeksonderwerp, dat de laatste tijd veel aandacht heeft gekregen. Ons werk richt zich op het detecteren van persoonlijke aanvallen in online gesprekken. Aangezien eerder onderzoek naar deze taak grotendeels deep learning heeft gebruikt op basis van embeddings, onderzoeken we het gebruik van lexicons om embedding-gebaseerde methoden te verbeteren in een poging om te zien hoe deze methoden van toepassing zijn op de specifieke taak van het detecteren van persoonlijke aanvallen. De methodes die in dit artikel worden geïmplementeerd en geëxperimenteerd zijn heel verschillend van elkaar, niet alleen in het type lexicons dat ze gebruiken (sentiment of semantisch), maar ook in de manier waarop ze de kennis uit de lexicons gebruiken om embeddings te construeren of te veranderen die uiteindelijk in het leermodel worden gevoed. De sentimentlexicon benaderingen richten zich op het integreren van sentimentinformatie (in de vorm van sentiment embeddings) in het leermodel. De semantische lexicon benaderingen richten zich op het transformeren van de oorspronkelijke woordinbeddingen zodat ze beter relaties weergeven die uit een semantisch lexicon zijn gehaald. Op basis van onze experimentele resultaten zijn semantische lexicon methoden superieur aan de rest van de methoden in dit document, met minstens 4% macro-gemiddelde F1 verbetering ten opzichte van de baseline.', 'hr': 'Otkrivanje nasilnog jezika je značajna tema istraživanja, koja je nedavno dobila mnogo pažnje. Naš rad se fokusira na otkrivanje osobnih napada u internetskim razgovorima. Kao što je prethodno istraživanje na ovom zadatku u velikoj mjeri koristilo duboko učenje na osnovu ugrađenja, istražujemo upotrebu leksikona kako bi poboljšali metode ugrađene na osnovu ugrađenja u pokušaju vidjeti kako se te metode primjenjuju u posebnom zadatku otkrivanja osobnih napada. Metode provedene i eksperimentirane s ovim papirom su prilično različite jedni od drugih, ne samo u vrsti leksiona koje koriste (osjećaj ili semantički), već i na način na koji koriste znanje iz leksiona, kako bi se konstruirali ili promijenili integracije koje su na kraju navedene u model učenja. Leksikon osjećaja približava se fokusiranju na integraciju informacija o osjećajima (u obliku integracije osjećaja) u model učenja. Semantički leksikon se približava usredotočiti na transformaciju originalne riječi ugrađenja tako da bolje predstavljaju odnose izvučene iz semantičkog leksikona. Na temelju naših eksperimentalnih rezultata, semantičke leksičke metode su nadmažene od ostalih metoda u ovom papiru, s najmanje 4% prosječnog poboljšanja F1 na početnoj liniji.', 'de': 'Die Erkennung missbräuchlicher Sprache ist ein wichtiges Forschungsthema, das in letzter Zeit viel Aufmerksamkeit erfahren hat. Unsere Arbeit konzentriert sich auf die Erkennung persönlicher Angriffe in Online-Konversationen. Da bisherige Forschung zu dieser Aufgabe weitgehend Deep Learning auf Basis von Einbettungen verwendet hat, untersuchen wir den Einsatz von Lexikonen zur Verbesserung von Einbettungsmethoden, um herauszufinden, wie diese Methoden in der speziellen Aufgabe der Erkennung persönlicher Angriffe angewendet werden. Die in dieser Arbeit implementierten und erprobten Methoden unterscheiden sich sehr voneinander, nicht nur in der Art der verwendeten Lexikone (Sentiment oder Semantik), sondern auch in der Art und Weise, wie sie das Wissen aus den Lexikonen nutzen, um Einbettungen zu konstruieren oder zu verändern, die letztlich in das Lernmodell eingespeist werden. Die Sentiment-Lexikon-Ansätze konzentrieren sich auf die Integration von Sentiment-Informationen (in Form von Sentiment-Einbettungen) in das Lernmodell. Die semantischen Lexikonansätze konzentrieren sich darauf, die ursprünglichen Worteinbettungen so zu transformieren, dass sie besser Beziehungen darstellen, die aus einem semantischen Lexikon extrahiert wurden. Basierend auf unseren experimentellen Ergebnissen sind semantische Lexikonmethoden den übrigen Methoden in dieser Arbeit überlegen, mit mindestens 4% makro-gemittelter F1 Verbesserung gegenüber der Baseline.', 'id': 'Mengeteksi bahasa yang kasar adalah topik penelitian yang signifikan, yang telah menerima banyak perhatian baru-baru ini. Pekerjaan kami fokus pada mendeteksi serangan pribadi dalam percakapan online. Sebagai penelitian sebelumnya tentang tugas ini telah banyak menggunakan belajar mendalam berdasarkan embedding, kami mengeksplorasi penggunaan leksikon untuk meningkatkan metode embedding berdasarkan upaya untuk melihat bagaimana metode ini berlaku dalam tugas tertentu untuk mendeteksi serangan pribadi. Metode yang dieksperimen dan diuji dalam kertas ini cukup berbeda satu sama lain, bukan hanya dalam jenis leksikon yang mereka gunakan (sentimen atau semantis), tetapi juga dalam cara mereka menggunakan pengetahuan dari leksikon, untuk membangun atau mengubah embedding yang akhirnya dimakan ke model belajar. The sentiment lexicon approaches focus on integrating sentiment information (in the form of sentiment embeddings) into the learning model.  Lexikon semantis mendekati fokus pada mengubah pembangunan kata asli sehingga mereka lebih baik mewakili hubungan yang dikeluarkan dari lexikon semantis. Berdasarkan hasil percobaan kami, metode lexikon semantis lebih baik dari sisa metode di kertas ini, dengan setidaknya 4% makro-rata F1 peningkatan dibanding dasar.', 'sw': 'Kugundua lugha ya unyanyasaji ni mada muhimu ya utafiti, ambayo imepokea hisia nyingi hivi karibuni. Kazi yetu inajikita katika kutambua mashambulizi binafsi katika mazungumzo ya mtandaoni. Kama utafiti uliopita juu ya kazi hii umetumia kujifunza kwa kiasi kikubwa kwa kuanzia mabango, tunachunguza matumizi ya watu wa lexico ya kuongeza mbinu za kuzuia katika jitihada za kuona namna mbinu hizi zinavyotumika katika kazi maalum ya kutambua mashambulizi binafsi. njia zilizotekelezwa na zilizojaribiwa katika karatasi hii ni tofauti tofauti na tofauti, siyo tu kwa aina ya lexico wanazotumia (hisia au semantic), bali pia kwa namna wanavyotumia maarifa kutoka kwa lexico, ili kujenga au kubadilisha vifaa vinavyofedheheshwa kwa mwisho katika modeli ya kujifunza. Kihisia cha lexico kinaingia lengo la kuunganisha taarifa za hisia (kwa namna ya hisia zinazoingia) katika mtindo wa kujifunza. Kilexico cha sekunde kinaingia lengo la kubadilisha neno la asili lililoingizwa ili waweze kuwakilisha mahusiano yaliyotolewa na lexico ya seksua. Kwa mujibu wa matokeo yetu ya majaribio, mbinu za lexico za kimapenzi ni bora zaidi kuliko njia nyingine nyingine katika gazeti hili, na kwa kiwango cha asilimia 4 yenye wastani wa F1 zaidi ya msingi.', 'ko': '욕설성 언어를 검출하는 것은 중요한 연구 과제로 최근 몇 년 동안 광범위한 관심을 받았다.우리의 업무 중점은 온라인 대화 중의 인신공격을 검측하는 것이다.이전에 이 임무에 대한 연구는 대부분이 삽입을 바탕으로 하는 깊이 있는 학습을 사용했기 때문에 우리는 어떻게 어휘를 사용하여 삽입을 바탕으로 하는 방법을 강화하고 이런 방법이 인신공격을 측정하는 특정한 임무에 어떻게 응용되는지 이해했다.본고에서 실현과 실험의 방법은 서로 크게 다르다. 그들이 사용하는 어휘 유형(감정이나 의미)뿐만 아니라 그들이 어휘에 있는 지식을 사용하는 방식에서도 삽입을 구축하거나 바꾸기 위해 이러한 삽입은 최종적으로 학습 모델에 입력된다.감정 사전 방법은 감정 정보(감정이 박힌 형식)를 학습 모델에 통합시키는 데 중심을 둔다.어의 사전 방법은 어의 사전에서 추출한 관계를 더욱 잘 나타내기 위해 원시 단어를 삽입하는 데 중심을 두었다.우리의 실험 결과에 따르면 의미 사전 방법은 본고의 다른 방법보다 우수하고 기선에 비해 매크로 평균 F1이 적어도 4% 높아졌다.', 'fa': 'کشف زبان تجاوز یک موضوع تحقیقات مهم است که اخیراً توجه زیادی را دریافت کرده است. کار ما روی کشف حمله شخصی در صحبت\u200cهای آنلاین تمرکز می\u200cکند. همانطور که تحقیقات قبلی در این وظیفه بسیار زیادی از یادگیری عمیق بر اساس ابتدایی استفاده کرده است، ما استفاده از لکسیون را برای افزایش روش\u200cهای ابتدایی در یک تلاش برای دیدن چگونه این روش\u200cها در وظیفه ویژه\u200cای از شناسایی حمله\u200cهای شخصی تأث روش\u200cهایی که در این کاغذ انجام می\u200cشود و آزمایش می\u200cکنند، کاملاً از یکدیگر متفاوت هستند، نه تنها در نوع لکسیون\u200cهایی که استفاده می\u200cکنند (احساسات یا semantic) بلکه همچنین در روش استفاده از دانش\u200cهایی از لکسیون، برای ساختن یا تغییر گیری\u200cهایی که بالاخره به مدل یادگیری می\u200cشوند. زبان احساسات به مدل یادگیری تمرکز می\u200cکند که اطلاعات احساسات (در شکل پیوند احساسات) به مدل یادگیری برسید. زبان شناسی به تغییر کلمه اصلی متصل می\u200cشود تا بهتر رابطه\u200cها را نشان دهند که از یک زبان شناسی خارج شده است. بر اساس نتیجه آزمایشی ما، روش\u200cهای لکسیون semantic are superior to the rest of the methods in this paper, with at least 4% macro-averaged F1 improvement over the baseline.', 'tr': 'Pikirli dili tapmak örän möhüm bir araştyrma temadyr. Soňra köp üns berilýär. Çalışmalarymyz internetde şahsy goşuşyklary tapmakda üns berýär. Bu zadyň öňki barlagynda gaty uly öwrenmeleri integralara daýan etmäge ulanýan öwrenmeler üçin biz esasy salganlary tanamak üçin lezikonslaryň ullanyşyny çözýäris. Bu kagyzda implementedilen we suratlandyran yöntemler birbirlerinden üýtgeşik däldir, diňe ullanýan leksiýanlar (duýgular ýa-da semantik) degişlidir, ýöne olar leksiýalardan bilimi ullanýarlar we soňunda öwrenmek nusgasyna üýtgetmek üçin däldir. duýgular sözleri duýgular maglumatyny öwrenmek nusgasyna golaýlaýar. Semantik tekizlikler başlangıç sözlerini üýtgetmek üçin fokusa yaklaýar we bu şekilde semantik tekizliklerden çykarmak üçin gowy görnüşler. Biziň experimental netijelerimize görä, semantik leksikon metodlarymyz bu kagyzdaki iň azyndaky döwletlerden has gowurak, iň azyndan 4% makro ortalyk F1 boýunçylygy üçin has gowurak.', 'am': 'ቋንቋን መግለጽ በጣም ትምህርት ጉዳይ ነው፡፡ ስራችን የግል ጦማሪያዎችን በመስመር ላይ በመግኘት ላይ ማሳየት ነው፡፡ ከዚህ ስራ ላይ ባለፈው ጥልቅ ትምህርት በመጠቀም፣ ለሌክሲኮን የሚጠቀሙትን የግንኙነት አካባቢ ሥርዓቶችን ለማድረግ እንፈልጋለን፡፡ The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the lexicons, in order to construct or to change embeddings that are ultimately fed into the learning model.  የሜክሲኮን ስሜት ማወቂያ (በተማሪው መልክ በመስመር) ወደ ትምህርት ሞዴል ለመቀላቀል ነው፡፡ የሴሜንቲካ ሌክሲኮን የመጀመሪያውን ቃላት አካባቢውን በመለወጥ እና ከሴሜንቲካ ሊክሲክ የተወለደውን ግንኙነትን በመለወጥ ያስችላል፡፡ ፈተና ውጤታችንን በመሠረት፣ የsemantic lexicon methods ከሌሎቹ ሥርዓቶች የበለጠ ናቸው፡፡', 'sq': 'Gjetja e gjuhës abuzive është një temë e rëndësishme kërkimi, e cila ka marrë shumë vëmendje kohët e fundit. Puna jonë përqëndrohet në zbulimin e sulmeve personale në bisedimet online. Ndërsa kërkimet e mëparshme në këtë detyrë kanë përdorur në mënyrë të madhe mësimin e thellë bazuar në përfshirje, ne eksplorojmë përdorimin e lexikonëve për të përmirësuar metodat e mbështetura në një përpjekje për të parë se si këto metoda aplikohen në detyrën e veçantë të zbulimit të sulmeve personale. The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the lexicons, in order to construct or to change embeddings that are ultimately fed into the learning model.  Lexikoni i ndjenjave afrohet përqëndrohet në integrimin e informacionit të ndjenjave (në form ën e përfshirjes së ndjenjave) në model in e mësimit. The semantic lexicon approaches focus on transforming the original word embeddings so that they better represent relationships extracted from a semantic lexicon.  Bazuar në rezultatet tona eksperimentale, metodat semantike të lexikonëve janë më të larta se pjesa tjetër e metodave në këtë letër, me të paktën 4% përmirësim makro-mesatar F1 mbi bazën.', 'af': "Ontdekking van abusive taal is 'n betekende onderwerp wat onlangs baie aandag ontvang het. Ons werk fokus op die ontdekking van persoonlike atake in online gesprekke. Soos vorige ondersoek op hierdie taak groot gewoonlik diep leer gebruik het gebruik gebruik gebruik op inbêding, ondersoek ons die gebruik van lexicons om inbêring-gebaseerde metodes in 'n versoek te verbeter om te sien hoe hierdie metodes in die bepaalde taak toewend word om persoonlike atake te beskry Die metodes wat in hierdie papier implementeer en eksperimenteer word, is heeltemal anders van mekaar, nie net in die tipe leksikone wat hulle gebruik word nie (sentiment of semantiek), maar ook in die manier waarop hulle die kennis van die leksikone gebruik het om inbêding te konstrukteer of te verander wat eindelik in die leermodel gevoer word. Die sentiment lexikon naby fokus op integrering van sentiment inligting (in die vorm van sentiment inbettings) in die leer model. Die semantiese leksikon naby fokus op die transformasie van die oorspronklike woord inbettings sodat hulle beter verbindings verteenwoordig wat uit 'n semantiese leksikoon uitgevoer is. Op ons eksperimentele resultate is semantiese leksikone metodes superior aan die res metodes in hierdie papier, met minste 4% makro-gemiddelde F1 verbetering oor die basisline.", 'hy': 'Խաղաղ լեզուների հայտնաբերումը կարևոր ուսումնասիրության թեմա է, որը վերջերս շատ ուշադրություն է ստացել: Our work focuses on detecting personal attacks in online conversations.  Քանի որ այս խնդրի վերաբերյալ նախորդ հետազոտությունները մեծամասամբ օգտագործել են խորը ուսումնասիրություն, որը հիմնված է ներգրավման վրա, մենք ուսումնասիրում ենք լեքսիկոնների օգտագործումը ներգրավման հիմնված մեթոդների բարելավման համար, փորձելով տեսնել, թե ինչպես են այս մեթոդները Այս թղթի մեթոդները իրականացված և փորձարկված են միմյանց բավականին տարբերվում, ոչ միայն այն լեքսիկոնների տեսակում, որոնք նրանք օգտագործում են (զգացմունքներ կամ սեմանտիկ), այլ նաև լեքսիկոնների գիտելիքների օգտագործման ձևով, որպեսզի կառուցեն կամ փոխեն ներդրումներ, որոնք վերջապես կերակրում են ուսուցման մոդելի Զգացմունքների լեքսիկոնը մոտենում է զգացմունքների տեղեկատվության ինտեգրման վրա (զգացմունքների ներգրավման ձևով) ուսուցման մոդելի մեջ: Սեմանտիկ լեքսիկոնը մոտենում է կենտրոնանալ սկզբնական բառի ներդրումների վերափոխման վրա, որպեսզի նրանք ավելի լավ ներկայացնեն սեմանտիկ լեքսիկոնից ստացված հարաբերությունները: Հաշվի առնելով մեր փորձարկման արդյունքները, սեմանտիկ լեքսիկոնի մեթոդները գերազանցում են այս թղթի մնացած մեթոդներին, որի արդյունքում F1-ի մակարոմիջին բարելավումը 4 տոկոսով է կազմում:', 'bn': 'অত্যাচারী ভাষা সনাক্ত করা হচ্ছে একটি গুরুত্বপূর্ণ গবেষণা বিষয়, যা সম্প্রতি অনেক মনোযোগ পেয়েছে। আমাদের কাজ অনলাইন আলোচনায় ব্যক্তিগত আক্রমণ খুঁজে বের করার প্রতি মনোযোগ দেয়। এই কাজের উপর আগের গবেষণা বেশীরভাগ ভিত্তিক গভীর শিক্ষা ব্যবহার করেছে, আমরা লেক্সিকোনদের ব্যবহার বিশেষ করে ব্যক্তিগত আক্রমণ খুঁজে বের করার প্রচেষ্টায় লেক্সিকোর ব্ এই পত্রিকায় ব্যবহার করা এবং পরীক্ষা করা পদ্ধতি একে অপরের কাছ থেকে অনেক ভিন্ন, শুধুমাত্র লেক্সিকোন ধরনের (অনুভূতি বা সেমেন্টিক) ব্যবহার করে না, কিন্তু তারা লেক্সিকোনদের জ্ঞান ব্যবহার করে  লেক্সিকোর অনুভূতিটি শিক্ষার মডেলে দৃষ্টিভঙ্গিত তথ্য যুক্ত করার প্রতি মনোযোগ প্রদান করে। The semantic lexicon approaches focus on transforming the original word embeddings so that they better represent relationships extracted from a semantic lexicon.  আমাদের পরীক্ষার ফলাফলের ভিত্তিতে এই কাগজের বাকি পদ্ধতিতে সেমেন্টিক লেক্সিকোর মাধ্যমের চেয়ে বেশী বেশী, যার মধ্যে অন্তত ৪% ম্যাক্রো গ', 'bs': 'Otkrivanje nasilnog jezika je značajna tema istraživanja, koja je nedavno dobila mnogo pažnje. Naš rad se fokusira na otkrivanje osobnih napada u internetskim razgovorima. Dok je prethodno istraživanje o ovom zadatku u velikoj meri koristilo duboko učenje na osnovu ugrađenja, istražujemo upotrebu leksikona kako bi poboljšali metode ugrađene na osnovu ugrađenja u naporima da vidimo kako se te metode primjenjuju u posebnom zadatku otkrivanja osobnih napada. Metode provedene i eksperimentirane s ovim papirom su prilično različite jedni od drugih, ne samo u tipu leksiona koje koriste (osjećaj ili semantički), već i na način na koji koriste znanje iz leksikona, kako bi se konstruirali ili promijenili integracije koje se na kraju hrane u model učenja. Leksikon osjećaja približava se fokusiranju na integraciju informacija o osjećajima (u obliku integracije osjećaja) u model učenja. Semantički leksikon se približava koncentraciji na transformaciji originalne riječi ugrađenja tako da bolje predstavljaju odnose izvučene iz semantičkog leksikona. Na temelju naših eksperimentalnih rezultata, semantičke leksičke metode su nadmažene od ostalih metoda u ovom papiru, s najmanje 4% prosječnog poboljšanja F1 na početnoj liniji.', 'ca': "Detectar un llenguatge abusiv és un tema de recerca significatiu, que ha rebut molta atenció fa poc. La nostra feina es centra en detectar atacs personals en converses en línia. Com la recerca anterior sobre aquesta tasca ha utilitzat en gran part l'aprenentatge profund basat en incorporacions, explorem l'ús de lexicòns per millorar els mètodes basats en incorporació en un esforç per veure com s'aplican aquests mètodes en la tasca particular de detectar atacs personals. Els mètodes implementats i experimentats en aquest paper són bastant diferents dels altres, no només en el tipus de llexicòns que utilitzen (sentiment o semàntic), sinó també en la manera en què utilitzen el coneixement dels llexicòns, per construir o canviar incorporacions que finalment s'alimentan al model d'aprenentatge. The sentiment lexicon approaches focus on integrating sentiment information (in the form of sentiment embeddings) into the learning model.  The semantic lexicon approaches focus on transforming the original word embeddings so that they better represent relationships extracted from a semantic lexicon.  Sobre la base dels nostres resultats experimentals, els mètodes de lexicó semàntica són superiors a la resta dels mètodes d'aquest paper, amb al menys un 4% de millora de F1 a la mitjana macrogràfica sobre la base.", 'az': 'Zövcə dilini təşkil etmək, son zamanlarda çox məlumat alınan möhkəm bir araştırma məsəlinədir. Çalışmalarımız online söhbətlərində kişisel saldıqları keşfetməyə odaqlanır. Bu iş barəsindəki əvvəlki araştırmaların çox yüksək öyrənməsini inbadinglərə dayanan kimi, biz bu metodların şəxsi saldıqların keşfetməsi üçün nəyə uyğun olduğunu görmək üçün leksiklərin istifadəsini keşfetmişik. Bu kağızda işlədilən və təcrübə edilən metodlar bir-birindən çox fərqli deyildir, ancaq istifadə etdikləri (hiss və semantik) leksiklərin türündə deyildir, lakin elmi leksiklərin istifadə etdikləri kimi, nihayət öyrənmək model in in in şallarını inşa etmək və dəyişdirmək üçün. Duyarlıq layihəsi öyrənmə modeli hisslərin məlumatlarını (duyarlıq məlumatlarının forması ilə) birləşdirməyə tərəf yaxınlaşır. Semantik sözləri semantik sözlərindən çıxarılan ilişkileri daha yaxşı göstərmək üçün orijinal sözləri dəyişdirməyə tərəf yaxınlaşır. Müxtəlif sonuçlarımıza görə, semantik leksikon metodları bu kağızdaki geri qalan metodların üstündür. En azından 4% makro-ortalamalı F1 dəyişdirilməsi altında.', 'cs': 'Odhalování zneužívajících jazyků je významným výzkumným tématem, kterému se v poslední době věnovalo velké pozornosti. Naše práce se zaměřuje na detekci osobních útoků v online konverzacích. Jelikož předchozí výzkum tohoto úkolu do značné míry využíval hluboké učení založené na vložení, zkoumáme využití lexikonů k vylepšení metod založených na vložení, abychom zjistili, jak tyto metody uplatňují v konkrétním úkolu detekce osobních útoků. Metody implementované a experimentované v tomto článku jsou od sebe zcela odlišné, a to nejen typem slovníků, které používají (sentiment nebo sémantika), ale také způsobem, jakým využívají znalosti z lexikonů k konstruování nebo změně vložení, které jsou nakonec vloženy do vzdělávacího modelu. Přístupy sentimentu se zaměřují na integraci sentimentových informací (ve formě sentimentových vložení) do vzdělávacího modelu. Sémantické lexikonové přístupy se zaměřují na transformaci původních slovních vložení tak, aby lépe reprezentovaly vztahy extrahované ze sémantického lexikonu. Na základě našich experimentálních výsledků jsou sémantické lexikonové metody lepší než ostatní metody v tomto článku, s minimálně 4% makro-průměrným zlepšením F1 ve srovnání s výchozí linií.', 'et': 'Kurvastava keele avastamine on oluline uurimisteema, mis on viimasel ajal palju tähelepanu pälvinud. Meie töö keskendub isiklike rünnakute tuvastamisele internetivestlustes. Kuna varasemad uuringud selle ülesande kohta on suures osas kasutanud sügavõpet, mis põhineb manustamisel, uurime sõnavara kasutamist manustamisel põhinevate meetodite täiustamiseks, et näha, kuidas neid meetodeid rakendatakse isiklike rünnakute tuvastamise konkreetsel ülesandel. Käesolevas töös rakendatud ja katsetatud meetodid erinevad üksteisest üsna erinevad, mitte ainult nende kasutatavate leksikonide tüübist (sentimentaalne või semantiline), vaid ka selles osas, kuidas nad kasutavad leksikonidest saadud teadmisi, et ehitada või muuta manustamist, mis lõppkokkuvõttes õppimismudelisse toidetakse. Sentimentaalse leksikoni lähenemine keskendub sentimentaalse informatsiooni integreerimisele (sentimentaalse manustamise vormis) õppemudelisse. Semantilise leksikoni lähenemine keskendub algsete sõnade manustamisele, et need paremini esindaksid semantilisest leksikonist eraldatud seoseid. Meie eksperimentaalsete tulemuste põhjal on semantilised leksikoni meetodid paremad kui ülejäänud käesolevas artiklis toodud meetodid, kusjuures vähemalt 4% makrokeskmine F1 paranemine võrreldes lähtetasemega.', 'fi': 'Väkivaltaisen kielen havaitseminen on merkittävä tutkimusaihe, joka on viime aikoina saanut paljon huomiota. Työssämme keskitytään henkilökohtaisten hyökkäysten havaitsemiseen verkkokeskusteluissa. Koska aiemmissa tutkimuksissa tähän tehtävään on hyödynnetty syväoppimista, tutkimme sanastojen käyttöä upottamiseen perustuvien menetelmien parantamiseksi ja pyrimme näkemään, miten nämä menetelmät soveltuvat henkilökohtaisen hyökkäyksen havaitsemiseen. Tässä työssä toteutetut ja kokeillut menetelmät eroavat toisistaan varsin toisistaan, ei ainoastaan niiden sanastojen tyypissä (sentimentti tai semanttinen), vaan myös siinä, miten ne käyttävät sanastojen tietoa rakentaakseen tai muuttaakseen sulautuksia, jotka lopulta syötetään oppimismalliin. Tunnesanaston lähestymistavat keskittyvät tunteiden tiedon integrointiin (tunteiden upottamisen muodossa) oppimismalliin. Semanttisessa sanastossa keskitytään muuttamaan alkuperäisiä sanaupotuksia siten, että ne edustavat paremmin semanttisesta sanastosta poimittuja suhteita. Kokeellisten tulosten perusteella semanttiset sanastomenetelmät ovat parempia kuin muut tässä artikkelissa esitetyt menetelmät, ja vähintään 4% makrokeskiarvoinen F1-parannus verrattuna lähtötilanteeseen.', 'jv': 'Mobiluhke tresno ing pancene kang dipunangke tema sing akeh nggunakake Workspace Awak dhéwé barêng langkung wigat nggawe akeh pengguna-pengguna luwih dumadhi sing nguasai winih, kéné isikno nggunakake sistem lekhikono nggunakake sistem sing dipunangé awak dhéwé nggawe ngubah cilik nggawe ngubah dhéwé kuwi kesempatan kanggo nggawe atak perbudhakan. Awak dhéwé sing beraksi lan ijol-ijol sing ngewehke nêmên ning acara iki dadi wis alih luwih apik dhéwé, ngéwé kuwi kesempatan kanggo kelompok layar (Sensitik lan sematik), maca ngomong nik arep awak dhéwé iso nggawe awak dhéwé ning awak dhéwé iso nggawe layar awak dhéwé, ngrebut awak dhéwé iso nggawe modèl Language sematik lexèk dadi ono nggawe perspek kanggo ngerwih akeh awak dhéwé sisané awak dhéwé sapa njaluk sing luwih apik dhéwé uga luwih apik sematik. Ngawe Perintah sing paling-perintah sing dadi, sematik layanan karo perusahaan kanggo mbala gampang kuwi maur, dadi 4% kebutuhan macro-median F1 kuwi diagonalan tambah iki diagonal.', 'ha': "Ina gane lugha mai zartar da shi, ma'anar matsayi mai muhimmi ne, wanda aka karɓi muhimmi. Kaimarmu yana muhimmin ka gane attacki masu shakka a cikin mazaɓa masu shagala ne. Kama da research na gabani a kan wannan aikin ya yi amfani da matsayi mafi ƙaranci a kan amfani da akwatin bayani, za mu yi amfani da amfani da leksikon dõmin ya ƙara hanyoyin-kibiyoyi, dõmin ka yi aikin ka gani yadda waɗannan hanyõyin suke amfani da shi a cikin aikin da za'a gane wa attacki masu shakka. Shiryoyin da aka samar da kuma aka jarraba da shi a cikin wannan takarda, yana sãɓã wa jũna guda, kuma bã da nau'in irin mutane da suke yi amfani da shi kawai (hisia'a ko semantic), kuma amma a kan hanyar su da ke amfani da sanin daga leksisiki, dõmin ya sami ko kuma ya musanya filin da aka ƙara shi zuwa misali mai karanta. Fikirin leksikon yana kusantar ta zura ido kan ka haɗa bayani na hisia (cikin fomat da ke fitarwa) zuwa misali da aka karanta. Ki sakanci na shige ta kafin a zura canza maganar farko da ke fitarwa, dõmin su fi zama mafi alhẽri ga mahusinsa da aka samu da shi daga mai shekara. Basan da matsalanmu na jarraba, hanyoyin leksisiki na semanti ne mafi alhẽri daga wasu hanyõyin na cikin wannan takarda, kuma da a ƙarami 4% macro-kawaici F1 za'a samar da shi a ƙarƙashin.", 'sk': 'Odkrivanje zlorabljajočega jezika je pomembna raziskovalna tema, ki je v zadnjem času prejela veliko pozornosti. Naše delo se osredotoča na odkrivanje osebnih napadov v spletnih pogovorih. Ker so predhodne raziskave o tej nalogi v veliki meri uporabljale globoko učenje, ki temelji na vdelavah, raziskujemo uporabo leksikonov za izboljšanje metod, ki temeljijo na vdelavi, v prizadevanju, da bi ugotovili, kako se te metode uporabljajo pri določeni nalogi odkrivanja osebnih napadov. Metode, ki jih izvajamo in s katerimi eksperimentiramo v tem prispevku, se med seboj precej razlikujejo, ne le v vrsti leksikonov, ki jih uporabljajo (sentimentalni ali semantični), temveč tudi v načinu, kako uporabljajo znanje leksikonov, da bi konstruirali ali spremenili vdelave, ki se na koncu vključujejo v model učenja. Pristopi sentimentalnega leksikona se osredotočajo na vključevanje sentimentalnih informacij (v obliki vključevanja sentimentalnih informacij) v model učenja. Pristopi semantičnega leksikona se osredotočajo na preoblikovanje izvirnih besednih vdelav tako, da bolje predstavljajo odnose, pridobljene iz semantičnega leksikona. Na podlagi naših eksperimentalnih rezultatov so semantične leksikonske metode boljše od ostalih metod v tem članku, z vsaj 4-odstotnim makropovprečnim izboljšanjem F1 v primerjavi z osnovno vrednostjo.', 'he': 'לגלות שפה מתעללת היא נושא מחקר משמעותי, אשר קיבל הרבה תשומת לב לאחרונה. העבודה שלנו מתמקדת בלגלות תקיפות אישיות בשיחות באינטרנט. כמחקר קודם על המשימה הזו השתמש בעיקר ללמוד עמוק מבוסס על קישומים, אנחנו חוקרים את השימוש של לקסיקונים כדי לשפר שיטות מבוססות על קישום במאמץ השיטות המופעלות והניסויים בהן בעיתון הזה שונות אחד מהשני, לא רק בסוג של לקסיקונים שהם משתמשים (רגשות או סמנטיות), אלא גם בדרך שהם משתמשים בידע מהלקסיקונים, כדי לבנות או לשנות תוכניות שהם בסופו של דבר מאכילים למודל הלימוד. הלקסיקון של הרגשות מתמקד באינטרגציה של מידע הרגשות (בצורה של תוכניות רגשות) למודל הלימוד. The semantic lexicon approaches focus on transforming the original word embeddings so that they better represent relationships extracted from a semantic lexicon.  בהתבסס על התוצאות הניסיוניים שלנו, שיטות הלקסיקון סמנטיות טובות יותר משאר השיטות בעיתון הזה, עם לפחות 4% שיפור F1 בממוצע מקרו מעל הבסיס.', 'bo': 'ལག་ལེན་འཐབ་བའི་སྐད་རིགས་རྟོགས་ནི་ལྟ་བུའི་གཏོང་གི་གཏོང་ཁག་ཅིག་རེད། ང་ཚོའི་ལས་ཀ་ནི་དྲ་ཐོག་གཏམ་གླེང་ཐོག་ལས་སྒེར་གྱི་གནོད་འགན་རྙེད་ཀྱི་ཕྱོགས་སྟོན As previous research on this task has largely used deep learning based on embeddings, we explore the use of lexicons to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks. ཤོག་བྱང་འདིའི་ནང་དུ་འཇུག་སྒྲིག་བྱས་པའི་ཐབས་ལམ་དེ་འདི་ཚོ་ནི་སོ་སོ་སོའི་ལྟ་བུའི་ནང་མིན་པར། སེམས་ཚོར་གྱི་གནད་དོན་དག་གིས་སློབ་པའི་མ་དབྱིབས་ཐད་ཚོར་བ་དང་མཐུན་སྣེ་མཐུན་གྱི་ཡོད། སྔོན་ལྟའི་གཟུགས་རིས་ལའང་གཟུགས་གཅིག་ནི་ཐོག་མའི་གཟུགས་རིས་ཡིག་ཆའི་ནང་དུ་དམིགས་གཏོང་བ་དང་མཐུན་རྐྱེན་ཚོར་མང་ཙམ ང་ཚོའི་བརྟག་ཞིབ་གྱི་གནད་སྡུད་མིན་ལག་ལེན་ཐབས་ལམ་དེ་ཚོ་ཤོག་བྱང་འདིའི་ནང་གི་ཐབས་ལམ་ལ་ལས་མཐོ་ཤོས་ཀྱི་ཡོད།'}
