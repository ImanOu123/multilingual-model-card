{'en': 'What is Multimodality?', 'ar': 'ما هو تعدد الوسائط؟', 'fr': "Qu'est-ce que la multimodalité\xa0?", 'es': '¿Qué es la multimodalidad?', 'pt': 'O que é Multimodalidade?', 'ja': 'マルチモーダリティとは何ですか？', 'hi': 'Multimodality क्या है?', 'zh': '何谓多式联运?', 'ru': 'Что такое мультимодальность?', 'ga': 'Cad is Ilmhódúlacht ann?', 'el': 'Τι είναι η Πολυmodality;', 'hu': 'Mi az a multimodalitás?', 'ka': 'კაკგჲ ვ მლთრმჲეთალნჲჟრ?', 'it': "Che cos'è la multimodalità?", 'kk': 'Көптеген көптеген қандай?', 'lt': 'Kas yra daugiarūšis režimas?', 'mk': 'Што е мултимодитетот?', 'ms': 'Apa itu Multimodaliti?', 'mn': 'Олон загвар нь юу вэ?', 'ml': 'What is Multimodality?', 'no': 'Kva er Multimodalitet?', 'ro': 'Ce este multimodalitatea?', 'pl': 'Co to jest multimodalność?', 'sr': 'Šta je Multimodalitet?', 'si': 'මොකක්ද ගොඩක් ප්\u200dරමාණය?', 'so': 'Waa maxay qaab badan?', 'sv': 'Vad är multimodalitet?', 'ta': 'பெரும்பாடு என்ன?', 'ur': 'Multimodality کیا ہے؟', 'mt': 'X’inhi l-Multimodalità?', 'vi': 'Nhân bản là gì?', 'uz': 'Koت»proq moduli nima?', 'bg': 'Какво представлява мултимодалност?', 'da': 'Hvad er multimodalitet?', 'nl': 'Wat is multimodaliteit?', 'hr': 'Što je Multimodalitet?', 'de': 'Was ist Multimodalität?', 'ko': '무엇이 다중모드입니까?', 'fa': 'Multimodality چیه؟', 'sw': 'Ni upi mkubwa?', 'id': 'Apa itu Multimodalitas?', 'tr': 'Multimodalitet näme?', 'af': 'Wat is Multimodaliteit?', 'hy': 'What is Multimodality?', 'sq': 'Çfarë është Multimodaliteti?', 'az': 'Multimodality n톛dir?', 'am': 'ብልሃት ምንድር ነው?', 'bn': 'মাল্টিমোডিয়ালি কি?', 'cs': 'Co je multimodalita?', 'bs': 'Šta je Multimodalitet?', 'ca': 'Què és la Multimodalitat?', 'et': 'Mis on multimodaalsus?', 'fi': 'Mitä multimodaalisuus on?', 'he': 'מה זה Multimodality?', 'ha': 'Mẽne ne Mulki?', 'sk': 'Kaj je multimodalnost?', 'bo': 'སྣ་མང་ཆེ་མཐོང་སྣང་ཅི་རེད།', 'jv': 'Apane Multimodalité?'}
{'en': 'The last years have shown rapid developments in the field of multimodal machine learning, combining e.g., ', 'ar': 'لقد أظهرت السنوات الماضية تطورات سريعة في مجال التعلم الآلي متعدد الوسائط ، والجمع بين الرؤية أو النص أو الكلام على سبيل المثال. في ورقة الموقف هذه ، نشرح كيف يستخدم المجال التعاريف القديمة للوسائط المتعددة التي ثبت أنها غير مناسبة لعصر التعلم الآلي. نقترح تعريفًا جديدًا نسبيًا للمهمة للطريقة (المتعددة) في سياق التعلم الآلي متعدد الوسائط الذي يركز على التمثيلات والمعلومات ذات الصلة بمهمة تعلم آلي معينة. من خلال تعريفنا الجديد للوسائط المتعددة ، نهدف إلى توفير أساس مفقود للبحث متعدد الوسائط ، ومكون مهم لتأسيس اللغة وعلامة بارزة نحو NLU.', 'es': 'Los últimos años han mostrado rápidos avances en el campo del aprendizaje automático multimodal, combinando, por ejemplo, la visión, el texto o el habla. En este documento de posición explicamos cómo el campo utiliza definiciones anticuadas de multimodalidad que no son aptas para la era del aprendizaje automático. Proponemos una nueva definición de (multi) modalidad relativa a la tarea en el contexto del aprendizaje automático multimodal que se centra en las representaciones y la información que son relevantes para una tarea de aprendizaje automático determinada. Con nuestra nueva definición de multimodalidad, nuestro objetivo es proporcionar una base que falta para la investigación multimodal, un componente importante de la base del lenguaje y un hito crucial hacia la NLU.', 'pt': 'Os últimos anos mostraram rápidos desenvolvimentos no campo do aprendizado de máquina multimodal, combinando, por exemplo, visão, texto ou fala. Neste documento de posicionamento, explicamos como o campo usa definições desatualizadas de multimodalidade que se mostram inadequadas para a era do aprendizado de máquina. Propomos uma nova definição de (multi)modalidade relativa à tarefa no contexto de aprendizado de máquina multimodal que se concentra em representações e informações relevantes para uma determinada tarefa de aprendizado de máquina. Com nossa nova definição de multimodalidade, pretendemos fornecer uma base que faltava para a pesquisa multimodal, um componente importante da base da linguagem e um marco crucial para a NLU.', 'fr': "Ces dernières années ont connu des développements rapides dans le domaine de l'apprentissage automatique multimodal, combinant par exemple la vision, le texte ou la parole. Dans ce document de position, nous expliquons comment le domaine utilise des définitions obsolètes de la multimodalité qui se révèlent inadaptées à l'ère de l'apprentissage automatique. Nous proposons une nouvelle définition de la (multi) modalité relative aux tâches dans le contexte de l'apprentissage automatique multimodal qui met l'accent sur les représentations et les informations pertinentes pour une tâche d'apprentissage automatique donnée. Avec notre nouvelle définition de la multimodalité, nous visons à fournir une base manquante pour la recherche multimodale, un élément important de l'ancrage linguistique et une étape cruciale vers la NLU.", 'hi': 'पिछले वर्षों ने मल्टीमॉडल मशीन लर्निंग के क्षेत्र में तेजी से विकास दिखाया है, उदाहरण के लिए, दृष्टि, पाठ या भाषण के संयोजन के लिए। इस स्थिति के पेपर में हम बताते हैं कि कैसे क्षेत्र बहुआयामीता की पुरानी परिभाषाओं का उपयोग करता है जो मशीन सीखने के युग के लिए अयोग्य साबित होते हैं। हम मल्टीमॉडल मशीन लर्निंग के संदर्भ में (मल्टी) मोडलिटी की एक नई कार्य-सापेक्ष परिभाषा का प्रस्ताव करते हैं जो किसी दिए गए मशीन लर्निंग कार्य के लिए प्रासंगिक प्रतिनिधित्व और जानकारी पर केंद्रित है। Multimodulity की हमारी नई परिभाषा के साथ हम बहुआयामी अनुसंधान के लिए एक लापता नींव, भाषा ग्राउंडिंग का एक महत्वपूर्ण घटक और एनएलयू की ओर एक महत्वपूर्ण मील का पत्थर प्रदान करने का लक्ष्य रखते हैं।', 'ja': 'ここ数年、視覚、テキスト、音声などを組み合わせたマルチモーダル機械学習の分野で急速な発展が見られた。このポジション論文では、機械学習の時代に適していないことが証明された時代遅れのマルチモーダリティの定義をどのように使用するかを説明します。私たちは、与えられた機械学習タスクに関連する表現と情報に焦点を当てた、マルチモーダル機械学習の文脈における（マルチ）モダリティの新しいタスク相対的定義を提案します。マルチモーダリティの新しい定義により、マルチモーダルリサーチの欠如した基盤、言語基盤の重要な構成要素、およびNLUへの重要なマイルストーンを提供することを目指しています。', 'zh': '往数年,多模态机器学域,合视听、文本、语音。 本立场之文,解域所以用时者多模态定义,其效不宜机器学时。 多模态机器学之背景(多)模态之新,定义侧重于给定机器学。 以吾模态性之新定义,吾之所以为多模态究其阙失,此言之大组成部分,亦NLU之要里程碑。', 'ru': 'Последние годы продемонстрировали быстрые изменения в области мультимодального машинного обучения, сочетающего, например, зрение, текст или речь. В этом позиционном документе мы объясняем, как в этой области используются устаревшие определения мультимодальности, которые оказываются непригодными для эпохи машинного обучения. Мы предлагаем новое относительное к задаче определение (мульти)модальности в контексте мультимодального машинного обучения, которое фокусируется на представлениях и информации, актуальных для данной задачи машинного обучения. С нашим новым определением мультимодальности мы стремимся обеспечить недостающую основу для мультимодальных исследований, важный компонент языкового обоснования и критическую веху на пути к НЛУ.', 'ga': 'Le blianta beaga anuas tá forbairtí tapa léirithe i réimse na meaisínfhoghlama ilmhódaigh, ag comhcheangal m.sh. fís, téacs nó urlabhra. Sa staidpháipéar seo mínímid conas a úsáideann an réimse sainmhínithe atá as dáta ar ilmhódúlacht nach bhfuil oiriúnach don ré meaisínfhoghlama. Molaimid sainmhíniú nua a bhaineann le tasc-choibhneas le (il)mhódúlacht i gcomhthéacs na foghlama meaisín ilmhódaigh a dhíríonn ar léiriúcháin agus ar fhaisnéis atá ábhartha do thasc meaisínfhoghlama ar leith. Leis an sainmhíniú nua atá againn ar ilmhódúlacht tá sé mar aidhm againn bunsraith in easnamh a sholáthar do thaighde ilmhódúil, gné thábhachtach de bhunús teanga agus cloch mhíle ríthábhachtach i dtreo NLU.', 'hu': 'Az elmúlt évek gyors fejlődést mutattak a multimodális gépi tanulás területén, például a látást, a szöveget vagy a beszédet kombinálva. Ebben a pozícióban elmagyarázzuk, hogy a terület hogyan használja a multimodalitás elavult definícióit, amelyek alkalmatlanok a gépi tanulás korszakára. Javasoljuk a multimodális gépi tanulás összefüggésében a (multimodális) módszerrel kapcsolatos új feladat-relatív definíciót, amely az adott gépi tanulási feladat szempontjából releváns reprezentációkra és információkra összpontosít. A multimodalitás új definíciójával arra törekszünk, hogy hiányzó alapot biztosítsunk a multimodális kutatáshoz, amely a nyelvi alapozás fontos eleme és kulcsfontosságú mérföldkő az NLU felé.', 'it': "Gli ultimi anni hanno mostrato rapidi sviluppi nel campo dell'apprendimento automatico multimodale, combinando ad esempio visione, testo o discorso. In questo articolo di posizione spieghiamo come il campo utilizza definizioni obsolete di multimodalità che si rivelano inadatte all'era del machine learning. Proponiamo una nuova definizione relativa al compito di (multi)modalità nel contesto del machine learning multimodale che si concentra sulle rappresentazioni e le informazioni rilevanti per un dato compito di machine learning. Con la nostra nuova definizione di multimodalità puntiamo a fornire una base mancante per la ricerca multimodale, una componente importante della formazione linguistica e una pietra miliare cruciale verso l'NLU.", 'ka': 'ბოლო წლის შემდეგ მულტიმოდიალური მაქანის სწავლების სამყაროში ძალიან განვითარება ჩვენებენ, მაგალითად, ხედი, ტექსტი ან სიტყვა. ამ პოზიციის დომენტში ჩვენ განვიხსნავთ, როგორ გამოყენება მულტიმოდიალობის განსაზღვრებები, რომლებიც მაქინის სწავლების ენერაში არ მუშაობს. ჩვენ შეგიძლიათ ახალი მოდენიფიკაცია (multimodal) მოდენიფიკაციის კონტექსტში, რომელიც მრავალმოდიალური მაქანის სწავლების კონტექსტში, რომელიც განსაკუთრებულებაზე და ინფორმაციისთვის გა ჩვენი ახალი განსაზღვრებით მულტიმოდიალურობის განსაზღვრებით ჩვენ მინდა გადავიტანოთ მულტიმოდიალური განსწავლებისთვის, მნიშვნელოვანი წინაწყისთვის, მნიშვნელოვანი წინაწყის', 'el': 'Τα τελευταία χρόνια έχουν δείξει ραγδαίες εξελίξεις στον τομέα της πολυμορφικής μηχανικής μάθησης, συνδυάζοντας π.χ. όραση, κείμενο ή ομιλία. Σε αυτό το έγγραφο θέσης εξηγούμε πώς ο τομέας χρησιμοποιεί ξεπερασμένους ορισμούς της πολυμορφίας που αποδεικνύονται ακατάλληλοι για την εποχή της μηχανικής μάθησης. Προτείνουμε έναν νέο ορισμό της (πολυ)τροπικότητας σε σχέση με την εργασία στο πλαίσιο της πολυτροπικής μηχανικής μάθησης που εστιάζει σε αναπαραστάσεις και πληροφορίες που είναι σχετικές με μια συγκεκριμένη εργασία μηχανικής μάθησης. Με τον νέο μας ορισμό της πολυμορφίας στοχεύουμε να παράσχουμε ένα χαμένο θεμέλιο για την πολυμορφική έρευνα, ένα σημαντικό συστατικό της γλωσσικής γείωσης και ένα κρίσιμο ορόσημο προς την κατεύθυνση της πολυμορφίας.', 'kk': 'Соңғы жылдар көптеген машиналық оқыту өрісінде жылдам өзгерістерді көрсетті, мысалы, көрініс, мәтін не сөйлеу өрісінде біріктірілген. Бұл орны қағазында өрістер машина оқыту үшін жарамсыз болатын көпкөпшілікті анықтамаларды қалай пайдаланып көрсетеді. Біз машина оқыту тапсырмасының (көп) көпшілік үйреніміздің жаңа тапсырманың (көпшілік) қасиетін анықтамасын ұсынамыз. Біздің жаңа көптеген мәліметтің анықтамасымен біз көптеген зерттеулердің негізгі, тілдердің негізгі компоненті және NLU-ге қарсы маңызды мәліметті жеткізу үшін жеткізген негізгі', 'ms': 'The last years have shown rapid developments in the field of multimodal machine learning, combining e.g., vision, text or speech.  Dalam kertas kedudukan ini kita jelaskan bagaimana medan menggunakan takrifan lama multimodaliti yang membuktikan tidak sesuai untuk era pembelajaran mesin. Kami cadangkan definisi relatif tugas baru bagi (multi)modaliti dalam konteks pembelajaran mesin multimodal yang fokus pada perwakilan dan maklumat yang relevan untuk tugas pembelajaran mesin yang diberi. Dengan definisi baru multimodaliti kami bertujuan untuk menyediakan dasar yang hilang untuk kajian multimodal, komponen penting dari dasar bahasa dan batu utama penting menuju NLU.', 'ml': 'കഴിഞ്ഞ വര്\u200dഷങ്ങള്\u200d മള്\u200dട്ടിമോഡാല്\u200d യന്ത്രത്തിന്റെ വയലില്\u200d വേഗം വികസിപ്പിക്കുന്നു ഈ സ്ഥാനത്തെ പത്രത്തില്\u200d നമ്മള്\u200d വിശദീകരിക്കുന്നു എങ്ങനെയാണ് ഫീല്\u200dഡ് ഉപയോഗിക്കുന്നത് മിഷിന്\u200d പഠിക്കുന്ന കാലത് കൊടുത്ത മെഷിന്\u200d പഠിപ്പിക്കുന്നതിന്റെ പ്രതിനിധികളിലും വിവരങ്ങളിലും പ്രധാനപ്പെട്ട ഒരു പുതിയ ജോലിയുടെ അടിസ്ഥാനത്തിലും (multi) മോഡിയലി നമ്മുടെ പുതിയ വിശദീകരണത്തിന്റെ പുതിയ വിശദീകരണത്തില്\u200d നമ്മുടെ ഉദ്ദേശിക്കുന്നത് പല്ലിമോഡല്\u200d പഠനത്തിന്റെ അടിസ്ഥാനത്തിനാണ്. ഭാഷ', 'mn': 'Сүүлийн жилүүд олон моделийн машины суралцах, жишээлбэл харагдах, текст эсвэл ярианы талбайд хурдан хөгжлийг харуулсан. Энэ байр сургалтын цаасан дээр бид салбар хэрхэн машины суралцах үеийн хугацааны олон төрлийн тодорхойлолтыг хэрхэн ашигладаг талаар тайлбарлаж байна. Бид машин суралцах үйлдлийн тухай төвлөрүүлэх болон мэдээллийн тухай төвлөрүүлэх олон моделийн машин суралцах нөхцөлд шинэ үйлдлийн харьцаатай тодорхойлолтыг санал болгож байна. Бидний олон загварын шинэ тодорхойлолтоор олон загварын судалгааны үндсэн байгууллага, хэлний сууриллагын чухал хэсэг болон НҮБ-д хамгийн чухал хамгийн чухал түвшинд хангах зорилго өгдөг.', 'no': 'Dei siste årene har vist raske utviklingar i feltet med multimodal maskinelæring, som kombinerer eksempel vising, tekst eller tale. I denne posisjonspapiret forklarer vi korleis feltet brukar noverande definisjonar av multimodalitet som viser ugyldig for maskinelæringsperioden. Vi foreslår ein ny oppgåveliste definisjon av (fleire) modulitet i konteksten av multimodal maskinelæring som fokuserer på representasjonar og informasjon som er relevant for ei oppgåve med maskinelæring. Med vår nye definisjon av multimodalitet må vi gjere ein manglende fundamentet for multimodal forskning, ein viktig komponent av språkkgrunnlegging og ein viktig milestone mot NLU.', 'mk': 'Последните години покажаа брзи развоји во областа на мултимодилното машинско учење, комбинирајќи на пример визија, текст или говор. In this position paper we explain how the field uses outdated definitions of multimodality that prove unfit for the machine learning era.  Ние предложуваме нова релативна дефиниција за (мултимодијалност) задачи во контекст на мултимодијално машинско учење кое се фокусира на претставувања и информации кои се релевантни за одредена задача за машинско учење. Со нашата нова дефиниција на мултимодијалност ние имаме за цел да обезбедиме недостасувачка основа за мултимодилно истражување, важен компонент на јазичното основање и клучен мизер кон НЛУ.', 'ro': 'Ultimii ani au arătat evoluții rapide în domeniul învățării automate multimodale, combinând, de exemplu, viziunea, textul sau vorbirea. În această lucrare de poziție explicăm modul în care domeniul utilizează definiții depășite ale multimodalității care se dovedesc inadecvate pentru era machine learning. Propunem o nouă definiție relativă la sarcini a (multi) modalității în contextul învățării automate multimodale, care se concentrează pe reprezentări și informații relevante pentru o anumită sarcină de învățare automată. Prin noua noastră definiție a multimodalității, ne propunem să oferim o bază lipsă pentru cercetarea multimodală, o componentă importantă a fundamentării limbajului și o etapă crucială spre NLU.', 'pl': 'Ostatnie lata wykazały szybki rozwój w dziedzinie multimodalnego uczenia maszynowego, łączącego np. wizję, tekst czy mowę. W niniejszym artykule wyjaśniamy, w jaki sposób dziedzina wykorzystuje przestarzałe definicje multimodalności, które okazują się nienadające się do ery uczenia maszynowego. Proponujemy nową definicję (multi)modalności w kontekście multimodalnego uczenia maszynowego, która koncentruje się na reprezentacjach i informacjach istotnych dla danego zadania uczenia maszynowego. Dzięki naszej nowej definicji multimodalności chcemy zapewnić brakujący fundament dla badań multimodalnych, ważny element uziemienia języka i kluczowy kamień milowy w kierunku NLU.', 'mt': 'L-aħħar snin urew żviluppi rapidi fil-qasam tat-tagħlim multimodali tal-magni, li jikkombinaw pereżempju viżjoni, test jew diskors. In this position paper we explain how the field uses outdated definitions of multimodality that prove unfit for the machine learning era.  We propose a new task-relative definition of (multi)modality in the context of multimodal machine learning that focuses on representations and information that are relevant for a given machine learning task.  With our new definition of multimodality we aim to provide a missing foundation for multimodal research, an important component of language grounding and a crucial milestone towards NLU.', 'sr': 'Posljednje godine pokazale su brzi razvoj u oblasti učenja multimodalnih strojeva, kombiniranja primjerice vizije, teksta ili govora. U ovom papiru za poziciju objašnjavamo kako polje koristi nove definicije multimodaliteta koja dokazuje nepristojnu za doba učenja mašine. Predlažemo novu definiciju (multimodalne) modalitate u kontekstu učenja multimodalnih mašin a koji se fokusira na predstavljanja i informacije koje su relevantne za određeni zadatak za učenje mašine. Sa našom novom definicijom multimodaliteta ciljamo pružiti nestalu temelj za multimodalno istraživanje, važnu komponentu temelja jezika i ključnu mjeru prema NLU.', 'si': 'අන්තිම අවුරුද්දු වලින් ගොඩක් මැෂින් ඉගෙනගන්න පුළුවන් වේගවත් විකාශය පෙන්වන්න පුළුවන් විදිහට පෙන මේ ස්ථාන පත්තියේ අපි පැහැදිලි කරනවා කොහොමද මෙහෙයුම් ඉගෙන ගන්නේ මෙහෙයුම් ඉගෙන ගන්නේ කොහොමද කියලා අපි අළුත් වැඩ සම්බන්ධ විශ්වාස කරන්න පුළුවන් විශ්වාස කරනවා (විශේෂ) විශ්වාස කිරීමේ විශ්වාස කිරීමේ විශ්වාස ක අපේ අලුත් විශ්ලේෂණය ගැන අලුත් විශ්ලේෂණය සමග අපි අල්ලගන්නවා විශේෂ විශ්ලේෂණය ගැන, භාෂාව භාවිතාවයේ වැදගත් අ', 'lt': 'Pastaraisiais metais paaiškėjo spartus daugiarūšio mašin ų mokymosi pokyčiai, pavyzdžiui, vizija, tekstas ar kalba. Šiame pozicijos dokumente paaiškiname, kaip lauke naudojamos pasenusios daugiarūšio režimo apibrėžtys, kurios pasirodo netinkamos mašinų mokymosi amžiui. Siūlome naują su užduotimis susijusią (daugiarūšio) būdo apibrėžimą daugiarūšio mašin ų mokymosi kontekste, kuriame dėmesys sutelkiamas į reprezentacijas ir informaciją, svarbias tam tikrai mašinų mokymosi užduotims. Naujoju daugiarūšio pobūdžio apibrėžimu siekiame sukurti trūkstamą daugiarūšio pobūdžio mokslinių tyrimų pagrindą, svarbų kalbų pagrindo komponentą ir esminį NLU etapą.', 'sv': 'De senaste åren har visat på en snabb utveckling inom området multimodalt maskininlärning som kombinerar t.ex. syn, text eller tal. I denna positionsuppsats förklarar vi hur fältet använder föråldrade definitioner av multimodalitet som visar sig olämpliga för maskininlärningen. Vi föreslår en ny uppgiftsrelaterad definition av (multi)modalitet inom ramen för multimodalt maskininlärning som fokuserar på representationer och information som är relevant för en viss maskininlärningsuppgift. Med vår nya definition av multimodalitet strävar vi efter att skapa en saknad grund för multimodal forskning, en viktig komponent i språkgrundning och en avgörande milstolpe mot NLU.', 'so': "Sannadihii ugu dambeeyey waxay tuseen horumarinta dhaqso ah e e lagu barto machadka kala duduwan, tusaale ahaan muuqashada, qoraalka ama hadalka. Warqadan booska ah waxaan ku caddaynayaa sida beeradu u isticmaalayo sawirro la'eg oo kala duduwan ah, kaas oo caddaynaya waqtiga waxbarashada machadka. Waxbarashada mashiinka kala duduwan waxaan soo jeedaynaa qoraal saameyn cusub oo ku saabsan shaqo la xiriirta (kala duduwan). Sida a an ku qorno sawir cusub oo kala duduwan, waxaynu ku talo galaynaa in aan la helo aasaaso waxbarasho kala duduwan, qayb muhiim ah oo ku qoran luqada iyo dhagax muhiim ah oo NLU u jeeda.", 'ta': 'கடந்த ஆண்டுகள் பல இயந்திரத்தில் விரைவான முன்னேற்றங்களை காண்பித்துள்ளார்கள், உதாரணமாக பார்வை, உரை அல்லது பேச்சு போன இந்த நிலைக்காகிதத்தில் நாம் புலத்தை எப்படி பயன்படுத்துகிறோம் புலத்திற்கு முன்னேற்றப்பட்ட விளக்கங்களின் மாதி பல்வேறு இயந்திரம் கற்றுக்கொள்ளும் பொருளில் நாம் ஒரு புதிய செயல் சார்ந்த வரையறை (பல) வகையை பரிந்துரைக்கிறோம். இது கொடுக்கப்பட்ட இயந்திரத்த புதிய விவரிப்புடன் நாம் காணவில்லை பல ஆராய்ச்சிக்கு ஒரு அடித்தளத்தை வழங்க வேண்டும், மொழி கூட்டுதல் முக்கியமான பொருள் மற்றும் NL', 'ur': 'پچھلے سالوں میں بہت سی ماشین کی تعلیم کی کھیتی میں تیز تغییرات دکھائی گئی ہیں، جیسے کہ نظر، متن یا کلام جمع کر رہے ہیں۔ ہم اس موقعیت کاغذ میں سفارش دیتے ہیں کہ کیونکر مصرف مصرف کے پہلے سے تعریف کے مطابق مصرف کے لئے غلط ہے۔ ہم ایک نئی تابع-رابطہ تعریف (multimodal) موڈلیٹ کی مختلف ماشین یادگاری کے بارے میں پیشنهاد کرتے ہیں جو دکھانے اور معلومات پر تمرکز کرتی ہے جو ایک دیے ہوئے ماشین یادگاری تابع کے لئے موجود ہیں. ہمارے بہت سی موڈلیٹ کی نوی تعریف کے ساتھ ہم ایک گھاٹی بنیاد دینے کا ارادہ رکھتے ہیں بہت سی موڈلیل تحقیق کے لئے، زبان کی بنیادی کے ایک اہم رقم اور NLU کی طرف بہت اہم مائلٹ۔', 'uz': "Oxirgi yil ko'pchilik mashina o'rganishda tez tajribalarni ko'rsatadi, masalan ko'rinishi, matn yoki gapirishni birlashtirish mumkin. Bu nafaqat sahifani biz maydonni qanday o'rganish uchun bir necha xil aniqlaridan foydalanishini anglatamiz. Ko'pchilik mashina o'rganishda yangi vazifa (ko'plab) modulini aniqlash imkoniyatini rivojlanamiz. Ko'rsatilgan mashina o'rganish vazifasi uchun muhim bo'lgan narsa va maʼlumot bilan bog'liq. With our new definition of multimodality we aim to provide a missing foundation for multimodal research, an important component of language grounding and a crucial milestone towards NLU.", 'vi': 'Những năm qua đã có dấu hiệu phát triển nhanh trong lĩnh vực học tập máy đa phương, kết hợp cả tầm nhìn, văn bản hay ngôn ngữ. Trong tình huống này, chúng tôi giải thích làm thế nào trường dùng những định nghĩa đa chiều lỗi thời cho việc học máy không phù hợp. Chúng tôi đề xuất một định nghĩa "tương đối nhiệm vụ" mới về "đa dạng" trong trường hợp học cỗ máy đa chiều, tập trung vào các biểu hiện và thông tin có liên quan đến một nhiệm vụ học máy cụ thể. Với định nghĩa đa chiều mới của chúng ta, chúng ta sẽ tạo ra một nền tảng thiếu hụt cho nghiên cứu đa phương, một yếu tố quan trọng trong việc khởi động ngôn ngữ và một mốc quan trọng đến Ntrường.', 'bg': 'Последните години показаха бързи развития в областта на мултимодалното машинно обучение, съчетавайки например зрение, текст или реч. В тази позиция обясняваме как в областта се използват остарели дефиниции за мултимодалност, които се оказват негодни за ерата на машинното обучение. Предлагаме ново определение за (мулти)модалност в контекста на мултимодалното машинно обучение, което се фокусира върху представянето и информацията, които са от значение за дадена задача за машинно обучение. С новата ни дефиниция за мултимодалност се стремим да осигурим липсваща основа за мултимодалното изследване, важен компонент на езиковото обосноване и ключов етап към НЛУ.', 'nl': 'De afgelopen jaren hebben snelle ontwikkelingen laten zien op het gebied van multimodaal machine learning, waarbij bijvoorbeeld visie, tekst of spraak worden gecombineerd. In dit positiedocument leggen we uit hoe het veld verouderde definities van multimodaliteit gebruikt die ongeschikt blijken te zijn voor het tijdperk van machine learning. We stellen een nieuwe task-relatieve definitie voor van (multi)modaliteit in de context van multimodaal machine learning die zich richt op representaties en informatie die relevant zijn voor een bepaalde machine learning taak. Met onze nieuwe definitie van multimodaliteit willen we een ontbrekende basis bieden voor multimodaal onderzoek, een belangrijk onderdeel van taalbasis en een cruciale mijlpaal naar NLU.', 'da': 'De seneste år har vist en hurtig udvikling inden for multimodal maskinlæring, der kombinerer f.eks. vision, tekst eller tale. I denne position paper forklarer vi, hvordan feltet bruger forældede definitioner af multimodalitet, der viser sig uegnede til maskinlæringsæraen. Vi foreslår en ny opgaverelateret definition af (multi)modalitet i forbindelse med multimodal maskinlæring, der fokuserer på repræsentationer og information, der er relevante for en given maskinlæringsopgave. Med vores nye definition af multimodalitet sigter vi mod at skabe et manglende fundament for multimodal forskning, en vigtig komponent i sproggrundlægning og en afgørende milepæl mod NLU.', 'hr': 'Posljednje godine pokazale su brzi razvoj u oblasti učenja multimodalnih strojeva, kombiniranja primjerice vizije, teksta ili govora. U ovom pozicijskom papiru objašnjavamo kako polje koristi nove definicije multimodalnosti koje dokazuju nepristojne za vrijeme učenja strojeva. Predlažemo novu definiciju (multimodalne) modalitate u kontekstu učenja multimodalnih strojeva koji se fokusira na predstavljanja i informacije koje su relevantne za određeni zadatak učenja strojeva. Sa našom novom definicijom multimodalnosti ciljamo pružiti nestalu temelj za multimodalno istraživanje, važnu komponentu temelja jezika i ključnu mjeru prema NLU.', 'de': 'In den letzten Jahren haben sich rasante Entwicklungen im Bereich des multimodalen maschinellen Lernens gezeigt, das z.B. Vision, Text oder Sprache kombiniert. In diesem Positionspapier erklären wir, wie das Feld veraltete Definitionen von Multimodalität verwendet, die sich als ungeeignet für das Zeitalter des maschinellen Lernens erweisen. Wir schlagen eine neue aufgabenbezogene Definition von (Multi)Modalität im Kontext von multimodalem maschinellem Lernen vor, die sich auf Repräsentationen und Informationen konzentriert, die für eine bestimmte Aufgabe des maschinellen Lernens relevant sind. Mit unserer neuen Definition von Multimodalität wollen wir eine fehlende Grundlage für multimodale Forschung schaffen, eine wichtige Komponente der Spracherdung und einen entscheidenden Meilenstein in Richtung NLU.', 'ko': '최근 몇 년 동안 다중모드기계 학습 분야는 신속한 발전을 이루었고 시각, 텍스트 또는 음성을 결합시켰다.본고에서 우리는 이 분야에서 유행이 지난 다중모드 정의를 어떻게 사용하는지 설명할 것이다. 이러한 정의는 기계 학습 시대에 적합하지 않다는 것이 증명되었다.다중모드적 기계 학습 배경에서 우리는 새로운(다중)모드적 임무와 관련된 정의를 제시했다. 이 정의는 주어진 기계 학습 임무와 관련된 표시와 정보를 주목한다.다중모드에 대한 우리의 새로운 정의를 통해 우리는 다중모드 연구에 부족한 기초를 제공하기 위한 것이다. 이것은 언어 기초의 중요한 구성 부분이자 NLU의 중요한 이정표이다.', 'fa': 'سال\u200cهای گذشته پیشرفت سریع در میدان یادگیری ماشین\u200cهای زیادی را نشان داده\u200cاند، مثال، دید، متن یا سخنرانی را ترکیب می\u200cکنند. در این کاغذ موقعیت ما توضیح می\u200cدهیم که چگونه میدان تعریف\u200cهای قدیمی از چندین موقعیت استفاده می\u200cکند که برای مدت یادگیری ماشین بی\u200cنیاز ثابت می\u200cکند. ما پیشنهاد می\u200cکنیم تعریف جدید نسبت به وضعیت (متعدد) موادی در محیط یادگیری ماشین متعدد که روی نمایش و اطلاعات تمرکز می\u200cکند که برای وضعیت یادگیری ماشین داده شده ارتباط دارند. با تعریف جدید ما از چندmodalities هدف داریم که یک بنیاد گم شده برای تحقیقات چندmodal، یک بخش مهم از بنیاد زبان و یک مسیر مهم به سمت NLU پیشنهاد کنیم.', 'sw': 'Miaka iliyopita imeonyesha maendeleo ya haraka katika uwanja wa kujifunza mashine ya viumbe, kuunganisha kwa mfano maono, maandishi au hotuba. Katika gazeti hili la nafasi tunaeleza jinsi bango linavyotumia ufafanuzi wa habari mpya wa utambulisho ambao unaonyesha ukosefu wa kipindi cha kujifunza mashine. Tunazipendekeza ufafanuzi mpya wa kazi inayohusiana na utaratibu wa (a in a nyingi) katika muktadha wa kujifunza mashine mbalimbali yanayolenga kuwakilisha na taarifa zinazohusiana na kazi ya kujifunza mashine. Kwa ufafanuzi wetu mpya wa utamaduni wa kidunia tunalenga kutoa msingi wa utafiti wa kidunia, sehemu muhimu ya makundi ya lugha na hatua muhimu kwa NLU.', 'tr': 'So흫ky 첵yllar multimodal ma힊yny 철wrenmek, 철r채n g 철rn체힊, metin 첵a 챌yky힊 bilen tiz 철s체mlikleri g철rkezildi. Bu 첵erde wagtda sahypa ma힊yny 철wrenmek wagty 체챌in n채hili 철흫ki modalitet kararynda ulan첵andygyny d체힊체ndir첵채ris. Biz multimodal ma힊yny흫 철wrenmegi 체챌in t채ze t채ze t채ze g철rn체힊-g철rn체힊li definisyony teklip ed첵채ris. Birn채챌e modalitet채mizi흫 t채ze definisyonymyz bilen, multimodal ylmy 체챌in 첵itilme첵채n fondasy sa첵lamaga ama챌landyr첵arys, dilleri흫 첵erle힊dirmegi we NLU 체챌in 철r채n m철h체m 첵erle힊dirim.', 'af': "Die laaste jaar het vinnige ontwikkeling vertoon in die veld van multimodal e masjien leer, bygelyks gesig, teks of spreek. In hierdie posisie papier verduidelik ons hoe die veld uiteindelike definisies van multimodaliteit gebruik word wat onregverdige bevestig vir die masjien leer era. Ons voorstel 'n nuwe taak-relatiewe definisie van (multi)modaliteit in die konteks van multimodale masjien leer wat fokus op voorstellings en inligting wat relevant is vir 'n gegewe masjien leer taak. Met ons nuwe definisie van multimodaliteit doen ons doel om 'n ontbrekende fondasie vir multimodale ondersoek te verskaf, 'n belangrike komponent van taal grond en 'n kruipende milestone teen NLU.", 'am': 'ባለፉት ዓመታት በብዙ የሞክራዊ መሣሪያዎች ትምህርት እርሻ ውስጥ ፈጥኖ ፍጥረት ያሳየዋል፤ ምሳሌ ራእይን፣ ጽሑፍ ወይም ንግግር ያሳያል፡፡ በዚህ ቦታ ካላት መሬት የመረጃ ትምህርት ዕድሜን እንዴት እንደሚጠቀም የብልሃት ግልጾችን እናብራራለን፡፡ አዲስ ስራ-ተሟጋቾች (multi)modality በማስተማርና በተሰጠው የመኪን ትምህርት ስራ ላይ የሚጠቃቀሙትን እና መረጃዎችን በማስተማርን እናሳውቃለን፡፡ አዲስ የብልሃት ግንኙነታችንን ለብዙ ጥያቄ ምርመራ የጠፋን መሠረት እና ወደ NLU የቋንቋ መፍጠር የሚያስፈልገውን የmuhimu ክፍል እና የተጠቃሚ ሚሊስ ድንጋይ እናደርጋለን፡፡', 'hy': 'Վերջին տարիները ցույց են տվել արագ զարգացումներ բազմամոդային մեքենայի ուսումնասիրության ոլորտում, օրինակ՝ տեսողության, տեքստի կամ խոսքի համադրման համար: Այս դիրքի թղթի մեջ մենք բացատրում ենք, թե ինչպես է դաշտը օգտագործում հնացած բազմակերպության սահմանումներ, որոնք պարզվում են անհամապատասխան մեքենային ուսուցման դարաշրջանի համար: Մենք առաջարկում ենք նոր (բազմա)մեթոդիալիության վերաբերյալ սահմանափակում բազմամոդալ մեքենայի ուսումնասիրության կոնտեքստում, որը կենտրոնանում է ներկայացումների և տեղեկատվության վրա, որոնք կարևոր են որոշ մեքենայի ուսում Մեր նոր բազմաձևակերպության սահմանման միջոցով մենք նպատակում ենք ապահովել բազմաձևակերպ հետազոտությունների բացակայող հիմք, լեզվի հիմնադրման կարևոր բաղադրիչ և ՆԼՄ-ի համար կարևոր քայլ:', 'sq': 'Vitet e fundit kanë treguar zhvillime të shpejtë në fushën e mësimit multimodal të makinave, duke kombinuar për shembull vizion, tekst apo fjalim. Në këtë letër pozicioni ne shpjegojmë se si fusha përdor përkufizime të vjetëruara të shumëmodalitetit që janë të papërshtatshme për epokën e mësimit të makinave. Ne propozojmë një përcaktim të ri relativ për detyrat e (shumë)modalitetit në kontekstin e mësimit multimodal të makinave që përqëndrohet në përfaqësimet dhe informacionin që janë të rëndësishëm për një detyrë të caktuar për mësimin e makinave. Me përcaktimin tonë të ri të multimodalitetit ne synojmë të sigurojmë një themel të humbur për kërkimin multimodal, një komponent të rëndësishëm të bazimit të gjuhës dhe një pikë kryesore drejt NLU.', 'az': 'Son il √ßoxlu modal maŇüńĪn √∂yr…ônm…ôsi sah…ôsind…ô hńĪzlńĪ geliŇüm…ôl…ôri g √∂st…ôrir, m…ôs…ôl…ôl…ôr, m…ôtnl…ôr v…ô danńĪŇümalar birl…ôŇüdirir. Bu pozisyon kańüńĪdńĪnda maŇüńĪn √∂yr…ônm…ô m√ľdd…ôtin…ô uyńüun g√∂st…ôr…ôn √ßoxlu modaliyy…ôtin …ôvv…ôlki tanńĪmlamalarńĪnńĪ nec…ô istifad…ô edir? Biz m√ľxt…ôlif maŇüńĪn √∂yr…ônm…ôsinin (√ßoxlu) modaliyy…ôtinin (√ßoxlu) m√ľ…ôyy…ôn edilm…ôsini t…ôklif edirik. Bu maŇüńĪn √∂yr…ônm…ôsi √ľ√ß√ľn m…ôlumatlara v…ô m…ôlumatlara m…ôxsusdur. Bizim √ßoxlu modaliyy…ôtimizin yeni tanńĪmlamasńĪyla √ßoxlu modal araŇütńĪrmalarńĪn, dill…ôrin yerl…ôŇüdirilm…ôsi v…ô NLU t…ôr…ôfind…ôn √ßoxlu m√∂h√ľm bir m…ôlumat verm…ôk ist…ôyirik.', 'bn': 'গত বছর মাল্টিমোডাল মেশিন শিক্ষা, যেমন দৃশ্য, টেক্সট অথবা বক্তৃতা সম্মিলন করা হয়েছে। এই অবস্থানের কাগজে আমরা ব্যাখ্যা করি কিভাবে ক্ষেত্রে মাল্টিমোডেলিয়ালিকার সংবাদ ব্যবহার করে যা মেশিন শিক্ষা যু মাল্টিমোডাল মেশিন শিক্ষার প্রেক্ষাপটে আমরা একটি নতুন কাজ-আত্মিক বিবরণের প্রস্তাব করছি যা প্রতিনিধিত্ব ও তথ্যের প্রতি মনোযোগ আকর্ষণ করে যা একট আমাদের নতুন সংজ্ঞার মাধ্যমে আমরা মাল্টিমোডাল গবেষণার জন্য একটি হারিয়ে যাওয়ার লক্ষ্য করছি, ভাষার গুরুত্বপূর্ণ অংশ এবং এনএলইউ-এর দিকে গুরু', 'bs': 'Posljednje godine pokazale su brzi razvoj u oblasti učenja multimodalnih strojeva, kombinacije primjerice vizije, teksta ili govora. U ovom papiru za poziciju objašnjavamo kako polje koristi nove definicije multimodaliteta koja dokazuje nepristojnu za vrijeme učenja mašine. Predlažemo novu definiciju (multimodalne) modalitate u kontekstu multimodalnog učenja mašine koji se fokusira na predstavljanja i informacije koje su relevantne za određeni zadatak za učenje mašine. Sa našom novom definicijom multimodaliteta ciljamo pružiti nestalu temelj za multimodalno istraživanje, važnu komponentu temelja jezika i ključnu mjeru prema NLU.', 'cs': 'Poslední roky ukázaly rychlý vývoj v oblasti multimodálního strojového učení, kombinující například vidění, text nebo řeč. V tomto příspěvku vysvětlíme, jak obor používá zastaralé definice multimodality, které se ukáží jako nevhodné pro éru strojového učení. Navrhujeme novou úlohově relativní definici (multi)modality v kontextu multimodálního strojového učení, která se zaměřuje na reprezentace a informace relevantní pro danou úlohu strojového učení. Cílem naší nové definice multimodality je poskytnout chybějící základ pro multimodální výzkum, důležitou součást jazykového uzemnění a klíčový milník směrem k NLU.', 'ca': "Els darrers anys han demostrat desenvolupaments ràpids en el camp de l'aprenentatge multimodal de màquines, combinant, per exemple, visió, text o discurs. In this position paper we explain how the field uses outdated definitions of multimodality that prove unfit for the machine learning era.  Proposem una nova definició relativa a la tasca de la (multimodalitat) en el context de l'aprenentatge multimodal de màquines que s'enfoca en representacions i informació pertinents per a una tasca d'aprenentatge de màquines. Amb la nostra nova definició de multimodalitat tenim l'objectiu de proporcionar una base que falta per a la recerca multimodal, un component important del fonament de la llengua i una etapa crucial cap a la NLU.", 'id': 'Tahun-tahun terakhir telah menunjukkan perkembangan cepat dalam bidang belajar mesin multimodal, menggabungkan contoh, penglihatan, teks atau pidato. In this position paper we explain how the field uses outdated definitions of multimodality that prove unfit for the machine learning era.  Kami mengusulkan definisi baru dari (multi)modalitas dalam konteks pembelajaran mesin multimodal yang fokus pada representation dan informasi yang relevan untuk tugas pembelajaran mesin tertentu. Dengan definisi baru multimodalitas kami bertujuan untuk menyediakan dasar yang hilang untuk penelitian multimodal, komponen penting dari dasar bahasa dan batu utama yang penting menuju NLU.', 'et': 'Viimased aastad on näidanud kiiret arengut mitmeliigilise masinõppe valdkonnas, mis ühendab näiteks nägemise, teksti või kõne. Selles seisukohas selgitame, kuidas valdkonnas kasutatakse aegunud multimodaalsuse definitsioone, mis osutuvad masinõppe ajastule sobimatuks. Pakume välja (multi)modaalsuse uue ülesandesuhtelise määratluse mitmeliigilise masinõppe kontekstis, mis keskendub esitustele ja teabele, mis on asjakohased konkreetse masinõppe ülesande jaoks. Meie uue mitmeliigilisuse määratlusega püüame luua puuduva aluse mitmeliigilistele teadusuuringutele, mis on keele aluse oluline komponent ja oluline verstapost NLU suunas.', 'fi': 'Viime vuosina multimodaalisen koneoppimisen alalla on tapahtunut nopeaa kehitystä, jossa yhdistyvät mm. visio, teksti tai puhe. Tässä kannanotossa selitämme, miten ala käyttää vanhentuneita multimodaalisuuden määritelmiä, jotka osoittautuvat sopimattomiksi koneoppimisen aikakaudelle. Ehdotamme uutta tehtäväsuhteista (multi)modaalisuuden määritelmää multimodaalisen koneoppimisen kontekstissa, jossa keskitytään tiettyä koneoppimistehtävää koskeviin esityksiin ja tietoihin. Uudella multimodaalisuuden määritelmällämme pyrimme tarjoamaan puuttuvan perustan multimodaaliselle tutkimukselle, joka on tärkeä osa kielen pohjautumista ja tärkeä virstanpylväs kohti NLU:ta.', 'he': 'השנים האחרונות הראו התפתחות מהירות בתחום הלימוד של מכונות רבות-מודליות, שילוב למשל חזון, טקסט או נאום. בנייר העמדה הזה אנחנו מסבירים איך השדה משתמש בהגדרות מוקדמות של המולטומודליות שמוכיחות לא מתאימות לעידן הלימוד המכונות. אנו מציעים הגדרה חדשה יחסית למשימה של (מוליטי) מודיאליות בקשר ללימודי מכונות מוליטי שמתמקדים על מייצגים ומידע שהם רלוונטיים למשימה של למידת מכונות מסוימת. עם הגדרה החדשה שלנו של המולטומודליות אנו מתכוונים לספק בסיס חסר למחקר מולטומודלית, רכיב חשוב של קרקע שפת ו-קילומטר קריטי לכיוון NLU.', 'ha': "The last years have shown rapid developments in the field of multimodal machine learning, combining e.g., vision, text or speech.  Ga wannan takardan wurin, Munã bayyana yadda field ke amfani da fassarar da aka tsohon da suka fi zama masu ƙaranci na multiodaliti da za'a gaskata wa zaman lafyutan ayuka. Tuna goyyar da wani rabon aikin-danganiyar (multi) modaliti cikin muhalli da za'a iya fahimta masu ƙarami masu da amfani da masu hushi ga mataimaki da information da ke da amfani da wa wani aikin da aka sanar da shi. Ga da rabon zanen multiodati, tuna kwatankani, za'a sami wani asalin da ba'a ɓace wa research masu multi-mutane, wani abu na muhimu na musamman lugha da sami na muhimu zuwa NLU.", 'sk': 'Zadnja leta so pokazala hiter razvoj na področju multimodalnega strojnega učenja, ki združuje npr. vizijo, besedilo ali govor. V prispevku razložimo, kako področje uporablja zastarele definicije multimodalnosti, ki se izkazujejo za neprimerne za obdobje strojnega učenja. Predlagamo novo opredelitev (multi)modalnosti glede na nalogo v kontekstu multimodalnega strojnega učenja, ki se osredotoča na predstavitve in informacije, ki so pomembne za določeno nalogo strojnega učenja. Z novo opredelitvijo multimodalnosti želimo zagotoviti manjkajočo osnovo za multimodalne raziskave, pomembno komponento jezikovnega osnovanja in ključni mejnik v smeri NLP.', 'bo': 'འདས་བའི་ལོ་ངོ་ཚོས་རྗེས་མ་དབྱིབས་སློབ་གླེང་བའི་སྒེར་གྱི་ནང་དུ་འཕྱུར་འགྲོས་འགྱུར་བ་མངོན་འཆར་བྱས་ཡོད། དཔེར་ན། མཐ གནས་སྟངས་འདིའི་ཤོག་བྱང་ནང་དུ་ང་ཚོས་རང་ཁུལ་གྱིས་དུས་ཡོད་པའི་ངོས་འཛིན་གྱི་ཐབས་ལམ་ལ་རང་ཉིད་མེད་པའི་ངོས་འཛི ང་ཚོས་ལག་ལེན་བྱ་བ་དང་མཐུན་འབྲེལ་བའི་སྣ་མང་མཐུན་གྱི་གནས་ཚུལ་གསརཔ་ཞིག་བསམ་བློ་གཏོང་བྱེད། ང་ཚོའི་གནད་དོན་ཐབས་ལམ་གསར་བ་དེ་ལ་དམིགས་ཡུལ་འདོད་པའི་རྨས་གཞི་ཞིག་བྱས་མིན་འདུག་ སྐད་ཡིག་རྒྱབ་སྐྱོར་གྱི་ཆ་ཤས་གལ་ཆེན', 'jv': 'Bandhung kaluwar neng sistem sing nêmên anyar tentang kanggo kalaha gambar mobil Multimodal Nang pisan iki dipunangé awak dhéwé ngerasakno ning acara dadi nggawe gerarané karo Multimodalité sing bakal nggawe barang nggawe barang manut. Awak dhéwé nggunakake nggawe task-ratio sistem sing bagian(multi)modalité nang kontèks multimodal karo sistem sing nyimpen nggawe basa gambar lan informasi sing dikareparahan kanggo kelompok nggawe sistem cilerahan. Awakdhéwé éné perusahaan anyar karo multimodalité, awak dhéwé iso nggawe basa sing perusahaan kanggo ranjut multimodal, sing kompon sing nggawe aturan kapulungan karo sistem sing apik tur angel karo NLU.'}
{'en': 'Seeing past words : Testing the cross-modal capabilities of pretrained V&L models on counting tasks', 'fr': 'Voir les mots du passé\xa0: tester les capacités intermodales des modèles V&L préentraînés sur les tâches de comptage', 'es': 'Ver palabras pasadas: probar las capacidades intermodales de los modelos de V&L previamente entrenados en tareas de conteo', 'ar': 'رؤية الكلمات السابقة: اختبار القدرات متعددة الوسائط لنماذج V&L سابقة التدريب على مهام العد', 'ja': '過去の単語を見る：カウントタスクで事前に訓練されたV&amp;Lモデルのクロスモーダル機能をテストする', 'zh': '检旧单词:试预训练 V&L 模跨模', 'ru': 'Просмотр прошлых слов: тестирование кросс-модальных возможностей предварительно подготовленных моделей V&amp;L на задачах подсчета', 'hi': 'पिछले शब्दों को देखना: गिनती कार्यों पर पूर्वप्रशिक्षित वी एंड एल मॉडल की क्रॉस-मोडल क्षमताओं का परीक्षण करना', 'ga': 'Seanfhocail a fheiceáil: Cumais thrasmhódúla na múnlaí V&L réamhoilte a thástáil maidir le tascanna comhairimh', 'pt': 'Vendo palavras passadas: testando os recursos multimodais de modelos V&L pré-treinados em tarefas de contagem', 'hu': 'Múltbeli szavak látása: Az előkészített V&L modellek transzmodális képességeinek tesztelése számlálási feladatokon', 'ka': 'წინა სიტყვების შენახვა: დავამწონოთ სამუშაო V&L მოდელების შესაძლებლობა შესაძლებლობა', 'lt': 'Ankstesnių žodžių matymas: išankstinio mokymo V&L modelių kompleksinių pajėgumų tikrinimas skaičiuojant užduotis', 'kk': 'Өткен сөздерді көру: тапсырмаларды есептеу үшін V&L моделдерінің көп модель мүмкіндіктерін тексеру', 'mk': 'Гледање на минатите зборови: Тестирање на крстомодалните способности на предобучените V&L модели на броењето задачи', 'el': 'Βλέποντας προηγούμενες λέξεις: Δοκιμή των διαστομειακών δυνατοτήτων των προκαθορισμένων μοντέλων σε εργασίες καταμέτρησης', 'ml': 'കഴിഞ്ഞ വാക്കുകള്\u200d കാണുന്നത്: ജോലികള്\u200d എണ്ണുന്നതിനെ പരീക്ഷിക്കുക', 'mt': 'Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks', 'ms': 'Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks', 'it': 'Vedere parole passate: testare le capacità cross-modali dei modelli V&L pre-addestrati sui compiti di conteggio', 'ro': 'Vederea cuvintelor trecute: Testarea capacităților cross-modale ale modelelor V&L pre-instruite pe sarcini de numărare', 'sr': 'Videći prošle reči: testiranje kroz modalnih mogućnosti pretvaranja modela V&L na brojanje zadataka', 'mn': 'Өнгөрсөн үгсийг харж байна: ажил тооцоолж V&L загваруудын олон загваруудыг шалгах', 'no': 'Sjå førre ord: Testar krysmodale kapasiteten for trekke V&L-modeller på teljing av oppgåver', 'pl': 'Zobaczenie przeszłych słów: Testowanie możliwości crossmodalnych wstępnie przeszkolonych modeli V&L na zadaniach liczenia', 'si': 'අතින් වචන දැක්කා: වැඩක් ගණන් කරන්න විසින් V&L මොඩල් වලට ප්\u200dරතිචාර විසින් විසින් ක්\u200dරියාත්මක විසින් ප', 'so': 'Sida aragtida hadallada hore: Imtixaanka awoodda iskuulka ah ee dabeecadda V&L oo ku saabsan xisaabta shaqada', 'sv': 'Att se tidigare ord: Testa de tvärmodala funktionerna hos förkränade V&L-modeller på räkningsuppgifter', 'ta': 'முந்தைய வார்த்தைகளை பார்த்துக் கொண்டிருக்கிறது: செயல்களை கணக்கிடும் போது மாதிரிகளின் குறியீட்டு ம', 'ur': 'گزشتہ کلمات کو دیکھتے ہیں: کاموں کی گنتی پر V&L موڈلوں کی مختلف موڈال کے قابلیت کا امتحان کرنا', 'uz': "Oldingi so'zlarni ko'rish: Testing the cross-modal capabilities of pretrained V&L models on counting task", 'vi': 'Thấy từ quá khứ: Thử nghiệm khả năng chiều chéo của các mẫu V/ L trước khi tính các công việc', 'da': 'At se tidligere ord: Test af tværmodale kapaciteter i forudtrænede V&L modeller på tællingsopgaver', 'hr': 'Gledajući prošle riječi: testiranje kroz modalnih sposobnosti preliječenih modela V&L na brojanje zadataka', 'de': 'Vergangene Worte sehen: Prüfung der crossmodalen Fähigkeiten von vortrainierten V&L-Modellen bei Zählaufgaben', 'id': 'Melihat kata-kata yang lalu: Mencoba kemampuan transmodal dari model V&L yang dilatih sebelumnya pada menghitung tugas', 'fa': 'دیدن کلمات گذشته: آزمایش توانایی\u200cهای متوسط مدل\u200cهای نمودار V&L را بر شماره کار', 'ko': '과거를 보면: 미리 훈련된 V&L 모형이 계수 임무에서의 크로스모드 능력을 테스트한다', 'bg': 'Виждане на минали думи: Тестване на мултимодалните възможности на предварително тренирани модели за броене на задачи', 'sw': 'Kuona maneno yaliyopita: Kujaribu uwezo wa kuvuka mifano ya vifaa vya vifaa vya vifaa vya vifaa vya V L kuhusu kuhesabu kazi', 'nl': 'Woorden uit het verleden zien: Het testen van de crossmodale mogelijkheden van vooraf getrainde V&L modellen op teltaken', 'tr': 'Geçen sözleri gören:Görevleri saymak üzere V&L modellerinin çoklu modal kapasitelerini dene', 'af': 'Sien verlede woorde: Toets die kruismodale kapasiteite van verlede V&L modele op teling van taak', 'sq': 'Duke parë fjalët e kaluara: Testimi i aftësive transmodale të modeleve të parastërvitura V&L mbi numërimin e detyrave', 'az': 'Geçmiş sözləri görmək: işləri saymaq haqqında V&L modellərinin çox modal qabiliyyətlərini sınamaq', 'bn': 'Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks', 'am': 'የቀድሞው ቃላት አይቶ: የcross-modal capabilities of pretrained V&L models on counting tasks', 'bs': 'Gledajući prošle riječi: testiranje kroz modalnih mogućnosti pretvaranja modela V&L na brojanje zadataka', 'et': 'Varasemate sõnade nägemine: Eeltreenitud V&L mudelite modaalsete võimaluste testimine lugemisülesannetel', 'ca': 'Veure les paraules passades: Probar les capacitats transmodals dels models de V&L preconformats en comptar tasques', 'cs': 'Sledování minulých slov: Testování crossmodálních schopností předem trénovaných V&L modelů při počítání úloh', 'fi': 'Aiempien sanojen näkeminen: Valmennettujen V&L-mallien multimodaalisten ominaisuuksien testaaminen laskentatehtävissä', 'hy': 'Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks', 'ha': 'An gane maganar ta riga: Test the kr-modal abiliti of late V/L modems on ƙidãyar aikin', 'sk': 'Videnje preteklih besed: Preizkušanje medmodalnih zmogljivosti predtreniranih modelov V&L pri opravilih štetja', 'he': 'Seeing past words: Testing the cross-modal capabilities of pretrained V&L models on counting tasks', 'bo': 'འདས་བའི་ཡིག་གེ་ལྟ་ཚུལ། བྱ་འགུལ་གྱིས་རྩིས་བརྗོད་བྱེད་པའི་ཐབས་ལམ་སྐོར་བརྟག་དཔྱད་བྱས།', 'jv': 'Genjer-genjer langgambar kelas kuwi: nyong bisa banter-modal kapasitekan karo model V&L sing ngawe saiki dadi wis ngawe'}
{'en': 'We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration : (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image. We evaluate three pretrained V&L models on these tasks : ViLBERT, ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings. Our results show that ', 'ar': 'نحن نحقق في القدرة المنطقية لنماذج الرؤية واللغة (V&L) المدربة مسبقًا في مهمتين تتطلبان تكاملًا متعدد الوسائط: (1) التمييز بين زوج جملة صورة صحيح من زوج غير صحيح ، و (2) عد الكيانات في صورة ما. نقوم بتقييم ثلاثة نماذج من طراز V&L مدربة مسبقًا في هذه المهام: ViLBERT و ViLBERT 12 في 1 و LXMERT ، في إعدادات دقيقة ومحددة. تظهر نتائجنا أن النماذج تحل المهمة (1) بشكل جيد جدًا ، كما هو متوقع ، نظرًا لأن جميع النماذج تم اختبارها مسبقًا في المهمة (1). ومع ذلك ، لا يمكن لأي من نماذج V&L المدربة مسبقًا حل المهمة (2) ، مسبار العد الخاص بنا ، ولا يمكنهم التعميم على الكميات خارج التوزيع. نقترح عددًا من التفسيرات لهذه النتائج: يُظهر LXMERT (وإلى حد ما ViLBERT 12 في 1) بعض الأدلة على النسيان الكارثي للمهمة (1). فيما يتعلق بالنتائج التي توصلنا إليها في مسبار العد ، نجد دليلًا على أن جميع النماذج تتأثر بتحيز مجموعة البيانات ، وتفشل أيضًا في تمييز الكيانات في المدخلات المرئية. في حين أن نقطة البيع لنماذج V&L المدربة مسبقًا هي قدرتها على حل المهام المعقدة ، تشير النتائج التي توصلنا إليها إلى أن فهم قدراتها المنطقية والتأسيسية يتطلب تحقيقات أكثر استهدافًا حول ظواهر معينة.', 'fr': "Nous étudions la capacité de raisonnement des modèles de vision et de langage préentraînés (V&L) dans le cadre de deux tâches qui nécessitent une intégration multimodale\xa0: (1) différencier une paire image-phrase correcte d'une paire incorrecte, et (2) compter les entités dans une image. Nous évaluons trois modèles V&L préentraînés sur ces tâches\xa0: VILbert, VILbert 12 en 1 et LXMERT, dans des réglages zéro et affinés. Nos résultats montrent que les modèles résolvent très bien la tâche (1), comme prévu, puisque tous les modèles sont préentraînés sur la tâche (1). Cependant, aucun des modèles V&L préentraînés n'est capable de résoudre correctement la tâche (2), notre sonde de comptage, et ils ne peuvent pas généraliser aux quantités hors distribution. Nous proposons un certain nombre d'explications à ces résultats\xa0: LXMERT (et dans une certaine mesure VilBert 12-en-1) montre certaines preuves d'oubli catastrophique sur la tâche (1). En ce qui concerne nos résultats sur la sonde de comptage, nous trouvons des preuves que tous les modèles sont affectés par le biais de l'ensemble de données et qu'ils ne parviennent pas à individualiser les entités dans l'entrée visuelle. Alors que l'un des arguments de vente des modèles V&L préentraînés est leur capacité à résoudre des tâches complexes, nos résultats suggèrent que la compréhension de leurs capacités de raisonnement et de mise à la terre nécessite des enquêtes plus ciblées sur des phénomènes spécifiques.", 'pt': 'Investigamos a capacidade de raciocínio de modelos pré-treinados de visão e linguagem (V&L) em duas tarefas que requerem integração multimodal: (1) discriminar um par imagem-frase correto de um incorreto e (2) contar entidades em uma imagem. Avaliamos três modelos de V&L pré-treinados nessas tarefas: ViLBERT, ViLBERT 12-em-1 e LXMERT, em configurações zero-shot e finetuned. Nossos resultados mostram que os modelos resolvem a tarefa (1) muito bem, como esperado, uma vez que todos os modelos são pré-treinados na tarefa (1). No entanto, nenhum dos modelos V&L pré-treinados é capaz de resolver adequadamente a tarefa (2), nossa sonda de contagem, e eles não podem generalizar para quantidades fora de distribuição. Propomos uma série de explicações para esses achados: LXMERT (e até certo ponto ViLBERT 12-em-1) mostra alguma evidência de esquecimento catastrófico na tarefa (1). Em relação aos nossos resultados na sonda de contagem, encontramos evidências de que todos os modelos são afetados pelo viés do conjunto de dados e também falham em individualizar entidades na entrada visual. Embora um ponto de venda de modelos de V&L pré-treinados seja sua capacidade de resolver tarefas complexas, nossas descobertas sugerem que entender seus recursos de raciocínio e fundamentação requer investigações mais direcionadas sobre fenômenos específicos.', 'ja': '私たちは、マルチモーダルインテグレーションを必要とする2つのタスクにおける事前訓練された視覚および言語（ V&amp;L ）モデルの推論能力を調査します。（ 1 ）正しい画像-文章のペアを間違ったものから識別し、（ 2 ）画像内のエンティティをカウントします。 ゼロショットと微調整設定で、ViLBERT、ViLBERT 12 - in -1、LXMERTの3つの事前に訓練されたV&amp;Lモデルを評価します。 私たちの結果は、すべてのモデルはタスク（ 1 ）で事前に訓練されているため、モデルは予想通りにタスク（ 1 ）を非常によく解決することを示しています。 ただし、事前に訓練されたV&amp;Lモデルは、タスク（ 2 ）、カウンティングプローブを適切に解決することができず、分布外の量に一般化することはできません。 これらの所見には、いくつかの説明が提案されています。LXMERT （そしてある程度ViLBERT 12 - in -1 ）は、タスク（ 1 ）を忘れるという破滅的な証拠を示しています。 カウントプローブの結果については、すべてのモデルがデータセットのバイアスの影響を受け、視覚入力のエンティティを個別化できないという証拠を発見しました。 事前に訓練されたV&amp;Lモデルのセールスポイントは、複雑なタスクを解決する能力ですが、私たちの調査結果は、推論と基礎付けの能力を理解するには、特定の現象についてよりターゲットを絞った調査が必要であることを示唆しています。', 'zh': '臣等考之视听语言(V&L)模形于两多模态成事推理:(1)分别正句是非之句对,及(2)算象之实体。 凡此三V&L:ViLBERT,ViLBERT 12-in-1LXMERT,设中于零。 吾之的结果表明也,如预期之善地解决(1),皆预练于(1)也。 然无先教者V&L足以尽事(2),吾计数探针,不能及布外之数。 发其说曰:LXMERT(某种程度者,ViLBERT 12-in-1)见灾难性遗忘之证(1)。 凡我等于计数探针上,见有证证,皆受数集偏差,亦未能于视觉输入中个性化实体也。 虽预V&L之一卖点,所以决烦务,究其结果表明,知其理接地,须有针对性于特定也。', 'es': 'Investigamos la capacidad de razonamiento de los modelos de visión y lenguaje (V&L) previamente entrenados en dos tareas que requieren integración multimodal: (1) discriminar un par correcto de imagen-frase de uno incorrecto y (2) contar entidades en una imagen. Evaluamos tres modelos de V&L previamente entrenados en estas tareas: VIlbert, VIlbert 12 en 1 y LXMERT, en entornos de tiro cero y ajustados. Nuestros resultados muestran que los modelos resuelven muy bien la tarea (1), como se esperaba, ya que todos los modelos están preentrenados en la tarea (1). Sin embargo, ninguno de los modelos V&L previamente entrenados es capaz de resolver adecuadamente la tarea (2), nuestra sonda de conteo, y no pueden generalizar a cantidades fuera de la distribución. Proponemos una serie de explicaciones para estos hallazgos: LXMERT (y hasta cierto punto VIlbert 12 en 1) muestran alguna evidencia de olvido catastrófico en la tarea (1). Con respecto a nuestros resultados en la sonda de conteo, encontramos evidencia de que todos los modelos se ven afectados por el sesgo del conjunto de datos y tampoco pueden individualizar entidades en la entrada visual. Si bien un punto de venta de los modelos de V&L previamente entrenados es su capacidad para resolver tareas complejas, nuestros hallazgos sugieren que comprender sus capacidades de razonamiento y fundamentación requiere investigaciones más específicas sobre fenómenos específicos.', 'hi': 'हम दो कार्यों में पूर्वप्रशिक्षित दृष्टि और भाषा (वी एंड एल) मॉडल की तर्क क्षमता की जांच करते हैं जिनके लिए बहुआयामी एकीकरण की आवश्यकता होती है: (1) एक गलत से सही छवि-वाक्य जोड़ी को भेदभाव करना, और (2) एक छवि में संस्थाओं की गिनती करना। हम इन कार्यों पर तीन पूर्वप्रशिक्षित वी एंड एल मॉडल का मूल्यांकन करते हैं: ViLBERT, ViLBERT 12-in-1 और LXMERT, शून्य-शॉट और महीन सेटिंग्स में। हमारे परिणाम बताते हैं कि मॉडल कार्य (1) को बहुत अच्छी तरह से हल करते हैं, जैसा कि अपेक्षित है, क्योंकि सभी मॉडल कार्य (1) पर पूर्वप्रशिक्षित हैं। हालांकि, प्रीट्रेन्ड वी एंड एल मॉडल में से कोई भी पर्याप्त रूप से कार्य (2) को हल करने में सक्षम नहीं है, हमारी गिनती की जांच, और वे आउट-ऑफ-डिस्ट्रीब्यूशन मात्राओं को सामान्यीकृत नहीं कर सकते हैं। हम इन निष्कर्षों के लिए कई स्पष्टीकरणों का प्रस्ताव करते हैं: LXMERT (और कुछ हद तक ViLBERT 12-in-1) कार्य (1) पर विनाशकारी भूलने के कुछ सबूत दिखाते हैं। गिनती जांच पर हमारे परिणामों के बारे में, हमें सबूत मिलते हैं कि सभी मॉडल डेटासेट पूर्वाग्रह से प्रभावित होते हैं, और दृश्य इनपुट में संस्थाओं को विभाजित करने में भी विफल रहते हैं। जबकि पूर्वप्रशिक्षित वी एंड एल मॉडल का एक बिक्री बिंदु जटिल कार्यों को हल करने की उनकी क्षमता है, हमारे निष्कर्ष बताते हैं कि उनके तर्क और ग्राउंडिंग क्षमताओं को समझने के लिए विशिष्ट घटनाओं पर अधिक लक्षित जांच की आवश्यकता होती है।', 'ru': 'Мы исследуем рассудительность предварительно обученных моделей зрения и языка (V&amp;L) в двух задачах, требующих мультимодальной интеграции: (1) различение правильной пары изображение-предложение от неправильной и (2) подсчет сущностей на изображении. Мы оцениваем три предварительно обученные модели V&amp;L по этим задачам: ViLBERT, ViLBERT 12-в-1 и LXMERT, в настройках с нулевым выстрелом и тонкой настройкой. Наши результаты показывают, что модели решают задачу (1) очень хорошо, как и ожидалось, так как все модели предварительно обучены заданию (1). Тем не менее, ни одна из предварительно подготовленных моделей V&amp;L не способна адекватно решить задачу (2), наш счетный зонд, и они не могут обобщать не распределяемые количества. Мы предлагаем ряд объяснений этим выводам: LXMERT (и в некоторой степени ViLBERT 12-в-1) показывают некоторые доказательства катастрофического забывания о задаче (1). Что касается наших результатов по счетному зонду, мы находим доказательства того, что все модели подвержены влиянию смещения набора данных, а также не могут выделить объекты в визуальном вводе. В то время как торговая точка предварительно подготовленных моделей V&amp;L - это их способность решать сложные задачи, наши выводы предполагают, что понимание их способностей к мышлению и обоснованию требует более целенаправленных исследований конкретных явлений.', 'ga': 'Déanaimid imscrúdú ar chumas réasúnaíochta na múnlaí réamhoilte radhairc agus teanga (V&L) in dhá thasc a éilíonn comhtháthú ilmhódach: (1) idirdhealú a dhéanamh idir péire ceart íomhá-abairt agus ceann mícheart, agus (2) aonáin in íomhá a chomhaireamh. Déanaimid measúnú ar thrí mhúnla V&L réamhoilte ar na tascanna seo: ViLBERT, ViLBERT 12-in-1 agus LXMERT, i suímh náid-shots agus miontiúnta. Léiríonn ár dtorthaí go réitíonn samhlacha tasc (1) go han-mhaith, mar a bheifí ag súil leis, ós rud é go ndéantar réamhoiliúint ar na samhlacha go léir ar an tasc (1). Mar sin féin, níl aon cheann de na samhlacha V&L réamhthraenáilte in ann tasc (2), ár dtóir comhairimh, a réiteach go sásúil, agus ní féidir leo ginearálú go dtí cainníochtaí as-dáilte. Molaimid roinnt mínithe ar na torthaí seo: Léiríonn LXMERT (agus go pointe áirithe ViLBERT 12-in-1) roinnt fianaise ar dearmad tubaisteach ar an tasc (1). Maidir lenár dtorthaí ar an taiscéalaí comhairimh, feicimid fianaise go bhfuil tionchar ag claonadh tacair sonraí ar gach samhail, agus go dteipeann orthu freisin aonáin aonair san ionchur amhairc. Cé gur pointe díola samhlacha V&L réamhoilte é an cumas atá acu tascanna casta a réiteach, tugann ár dtorthaí le fios go dteastaíonn imscrúduithe níos spriocdhírithe ar fheiniméin shonracha chun a gcumas réasúnaíochta agus bunús a thuiscint.', 'hu': 'Két olyan feladatban vizsgáljuk, amelyek multimodális integrációt igényelnek: (1) a helyes kép-mondat pár megkülönböztetése egy helytelen képtől, és (2) az entitások számolása egy képen. Három előképzett V&L modellt értékelünk ezekre a feladatokra: ViLBERT, ViLBERT 12 az 1-ben és LXMERT, nulla lövés és finomhangolt beállításokban. Eredményeink azt mutatják, hogy a modellek nagyon jól oldják meg a feladatot (1) a várakozásoknak megfelelően, mivel minden modellt előkészítettek a feladatra (1). Azonban az előkészített V&L modellek egyike sem képes megfelelően megoldani a feladatot (2), a számláló szondánkat, és nem tudnak általánosítani az elosztáson kívüli mennyiségekre. Ezekre a megállapításokra számos magyarázatot javasolunk: az LXMERT (és bizonyos mértékben a ViLBERT 12 az 1-ben) bizonyos bizonyítékokat mutat a feladat katasztrofális elfelejtésére (1). A számláló szondával kapcsolatos eredményeinket illetően bizonyítékot találunk arra, hogy minden modellt érint az adatkészlet elfogultsága, és nem tudjuk azonosítani a vizuális bemenetben lévő entitásokat. Míg az előkészített V&L modellek értékesítési pontja a komplex feladatok megoldására való képességük, eredményeink arra utalnak, hogy érvelésük és megalapozási képességeik megértése célzottabb vizsgálatokat igényel konkrét jelenségekre.', 'el': 'Ερευνούμε την ικανότητα συλλογισμού των προ-εκπαιδευμένων μοντέλων όρασης και γλώσσας σε δύο εργασίες που απαιτούν πολυμορφική ενσωμάτωση: (1) διάκριση ενός σωστού ζευγαριού εικόνας-πρότασης από ένα λανθασμένο και (2) καταμέτρηση οντοτήτων σε μια εικόνα. Αξιολογούμε τρία προ-εκπαιδευμένα μοντέλα σε αυτές τις εργασίες: ViLBERT, ViLBERT 12-σε-1 και LXMERT, σε μηδενικές και συντονισμένες ρυθμίσεις. Τα αποτελέσματά μας δείχνουν ότι τα μοντέλα λύνουν την εργασία (1) πολύ καλά, όπως αναμενόταν, καθώς όλα τα μοντέλα είναι προκαθορισμένα στην εργασία (1). Ωστόσο, κανένα από τα προ-εκπαιδευμένα μοντέλα δεν είναι σε θέση να λύσει επαρκώς το καθήκον (2), τον ανιχνευτή μέτρησης μας, και δεν μπορεί να γενικεύσει σε ποσότητες εκτός διανομής. Προτείνουμε μια σειρά εξηγήσεων για αυτά τα ευρήματα: Η LXMERT (και σε κάποιο βαθμό ViLBERT 12-σε-1) δείχνουν κάποια στοιχεία καταστροφικής λησμονής στο έργο (1). Όσον αφορά τα αποτελέσματά μας στον έλεγχο μέτρησης, βρίσκουμε στοιχεία ότι όλα τα μοντέλα επηρεάζονται από προκατάληψη συνόλου δεδομένων, και επίσης αποτυγχάνουν να ξεχωρίσουν οντότητες στην οπτική είσοδο. Ενώ ένα σημείο πώλησης των προκαθορισμένων μοντέλων είναι η ικανότητά τους να λύνουν πολύπλοκα καθήκοντα, τα ευρήματά μας δείχνουν ότι η κατανόηση των ικανοτήτων συλλογισμού και γείωσης τους απαιτεί πιο στοχευμένες έρευνες σε συγκεκριμένα φαινόμενα.', 'it': "Investighiamo la capacità di ragionamento dei modelli di visione e linguaggio pre-addestrati (V&L) in due compiti che richiedono integrazione multimodale: (1) discriminare una corretta coppia immagine-frase da una errata, e (2) contare entità in un'immagine. Valutiamo tre modelli V&L pre-addestrati su questi compiti: ViLBERT, ViLBERT 12-in-1 e LXMERT, in impostazioni a scatto zero e perfezionate. I nostri risultati mostrano che i modelli risolvono il compito (1) molto bene, come previsto, poiché tutti i modelli sono pre-addestrati sul compito (1). Tuttavia, nessuno dei modelli V&L pre-addestrati è in grado di risolvere adeguatamente il compito (2), la nostra sonda di conteggio, e non possono generalizzare a quantità fuori distribuzione. Proponiamo una serie di spiegazioni per questi risultati: LXMERT (e in una certa misura ViLBERT 12-in-1) mostrano alcune prove di abbandono catastrofico sul compito (1). Per quanto riguarda i nostri risultati sulla sonda di conteggio, troviamo prove che tutti i modelli sono influenzati da bias del set di dati, e anche non riescono a individuare entità nell'input visivo. Mentre un punto di forza dei modelli V&L pre-addestrati è la loro capacità di risolvere compiti complessi, i nostri risultati suggeriscono che la comprensione delle loro capacità di ragionamento e di messa a terra richiede indagini più mirate su fenomeni specifici.", 'ka': 'ჩვენ შევხედავთ მოდელების პარამენტის შესაძლებლობა, რომელიც მრავალმოდიალური ინტეგრაციის შესაძლებლობად მრავალური შესაძლებლობა (V&L) მოდელში, რომელიც მრავალური ინტეგრაციის შესაძლებლობად: 1) დისკრიმინაცია მსგავსი გამ ჩვენ გავამუშაოთ სამი მოდელი V&L მოდელი ამ დავალების შესახებ: ViLBERT, ViLBERT 12-in-1 და LXMERT, 0-shot და finetuned settings. ჩვენი წარმოდგენება ჩვენი მოდელების მოდელების გადაწყვეტილება (1) ძალიან კარგი, როგორც უნდა იყოს, რადგან ყველა მოდელები დააწყვეტილია (1). მაგრამ, არაფერი V&L მოდელში არაფერი შეუძლია საკმაოდ გადაწყენოთ რაოდენობა (2), ჩვენი მრიცხველის პონდის, და ისინი არ შეუძლიათ დავუწყენოთ გადაწყენებული მრავალზე. ჩვენ გვეძლევა რამდენიმე განახსნა ამ შესაძლებლობისთვის: ჩვენი წარმოდგენების შესახებ მრიცხველების პონდის შესახებ, ჩვენ აღმოჩნეთ წარმოდგენები, რომ ყველა მოდელეები დაახლოებით მონაცემების შესახებ, და ასევე ვერ შეუძლებელია თუმცა სამუშაო მოდელების გადაწყვეტილება არის ისინი შესაძლებლობა კომპლექსიკური საქმედების გადაწყვეტილება, ჩვენი შესაძლებლობები გვიძლია, რომ სამუშაო და გადაწყვეტილების შესაძლებლობა უფრო', 'ms': 'Kami menyelidiki kemampuan alasan bagi model penglihatan dan bahasa (V&L) terlatih dalam dua tugas yang memerlukan integrasi multimodal: (1) mendiskriminasi pasangan kalimat-imej yang betul dari salah satu yang salah, dan (2) menghitung entiti dalam imej. Kami menilai tiga model V&L yang dilatih dahulu pada tugas ini: ViLBERT, ViLBERT 12-in-1 dan LXMERT, dalam tetapan 0-shot dan finetuned. Hasil kita menunjukkan bahawa model menyelesaikan tugas (1) dengan baik, seperti yang dijangka, kerana semua model telah dilatih pada tugas (1). Namun, tiada model V&L yang dilatih dahulu mampu menyelesaikan tugas (2), sonda penghitungan kita, dan mereka tidak boleh menyebarkan kepada kuantiti diluar distribusi. Kami mengusulkan beberapa penjelasan untuk penemuan ini: LXMERT (dan dalam beberapa keadaan ViLBERT 12-in-1) menunjukkan beberapa bukti melupakan bencana tugas (1). Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input.  Sementara titik jualan model V&L yang dilatih dahulu adalah kemampuan mereka untuk menyelesaikan tugas kompleks, penemuan kami menunjukkan bahawa memahami kemampuan alasan dan mendasar mereka memerlukan penyelidikan yang lebih ditujukan pada fenomena tertentu.', 'kk': 'Біз көпModal интеграциясы керек екі тапсырмалардың (V&L) көрініс мен тіл үлгілерінің сезімділік мүмкіндігін зерттейміз: (1) дұрыс бірінен дұрыс кескінді сөйлейтін және (2) есептеу мүмкіндіктерін кескінде дискрим Бұл тапсырмалардың үш өзгертілген V&L үлгілерін бағаладық: ViLBERT, ViLBERT 12- in- 1 және LXMERT, нөл- шоу және дұрыс емес параметрлерінде. Біздің нәтижелеріміз үлгілер тапсырманы (1) жоспарлады, күтпеген сияқты, өйткені барлық үлгілер тапсырманың (1) арқылы өзгертіледі. Бірақ бұл V&L үлгілерінің бір тапсырманы (2) дұрыс шешуі мүмкін емес, есептеу тәртібімізді, олар үлестірілген сандарды жалпы түрде шешуге болмайды. Біз осы тапсырмалар үшін бірнеше түсініктемелерді ұсынамыз: LXMERT (және ViLBERT 12- in- 1 дегенде) тапсырманы ұмытып жатқан катастрофиялық тапсырмаларды көрсетеді (1). Санау пробсының нәтижелеріміз туралы, барлық үлгілер деректер қорларының өзгертілігіне әсер етеді деп ойлаймыз, сондай-ақ визуалдық енгізімізде бөліктерді бөліктеу мүмкін емес Олардың комплексті тапсырмаларды шешу мүмкіндігі болғанда, біздің тапсырмамыз олардың сезімділіктерін түсінуге және негіздеу мүмкіндіктерін түсінуге болады.', 'ml': 'ഒരു തെറ്റായ ഒന്നില്\u200d നിന്നും ഒരു ചിത്രത്തില്\u200d നിന്നും ഒരു ശരിയായ ഒരു ഇമേജ്-വാക്ക് രണ്ട് ജോലികള്\u200dക്ക് ആവശ്യമുള്ള രണ്ട് ജോലികളില്\u200d നിന്നും വീണ്ടെടുക്കപ്പെടുന്ന കാഴ ഈ പ്രവര്\u200dത്തനങ്ങളില്\u200d വില്\u200dബെര്\u200dട്ട്, വില്\u200dബെര്\u200dട്ട് 12-in-1, LXMERT, ശൂന്യമായ വെടിവെക്കപ്പെട്ടിരിക്കുന്നു വില്\u200dബെര്\u200dട്ട്. നമ്മുടെ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് പ്രതീക്ഷിച്ചത് പോലെ മോഡലുകള്\u200d തീരുമാനിക്കുന്ന പണിയാണെന്നാണ എന്നാലും വി &എല്\u200d മോഡലുകളില്\u200d ഒരാള്\u200dക്കും മതിയായ ജോലി പരിഹരിക്കാന്\u200d കഴിയില്ല (2), നമ്മുടെ എണ്ണിപ്പിടിപ്പിക്കുന്ന പ്രോബ്, വിതരണം കൂടാ ഈ കണ്ടുപിടികള്\u200dക്ക് വേണ്ടി നമ്മള്\u200d കുറച്ച് വിശദീകരിക്കുന്നു: LXMERT (വില്\u200dബെര്\u200dട്ട് 12-in-1) ജോലിയില്\u200d മറന്നുപോകുന്ന കാര്യങ്ങളുടെ  എണ്ണുന്നതിന്റെ ഫലങ്ങളെക്കുറിച്ച് ഞങ്ങള്\u200d തെളിവുകള്\u200d കണ്ടെത്തുന്നു, എല്ലാ മോഡലുകളും ഡാറ്റാസറ്റ് ബിയാസിന്റെ പ്രഭാവിക്കുന്നു.  വി &എല്\u200d മോഡലുകളുടെ വില്\u200dക്കുന്ന പോയിന്റ് വില്\u200dക്കുന്നത് അവരുടെ പ്രശ്നങ്ങള്\u200d പരിഹരിക്കാനുള്ള കഴിവാണെങ്കില്\u200d, നമ്മുടെ കണ്ടുപിടികള്\u200d പറയുന്നു അവരുടെ', 'lt': 'We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration: (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image.  Vertiname tris iš anksto apmokytus V&L modelius šiose užduotyse: ViLBERT, ViLBERT 12-in-1 ir LXMERT, nuliniu ir patobulintais būdais. Mūsų rezultatai rodo, kad modeliai labai gerai sprendžia užduotį (1), kaip tikėtasi, nes visi modeliai iš anksto mokomi užduotyje (1). Tačiau nė vienas iš išankstinio mokymo V&L modelių negali tinkamai išspręsti užduoties (2), mūsų skaičiavimo sondo, ir jie negali apskritai išplatinti į nepaskirstytus kiekius. Siūlome paaiškinti šiuos faktus: LXMERT (ir tam tikru mastu ViLBERT 12-in-1) rodo kai kuriuos katastrofinio užduoties pamiršimo įrodymus (1). Kalbant apie mūsų skaičiavimo zondo rezultatus, turime įrodymų, kad visiems modeliams įtakos daro duomenų rinkinio pusiausvyra, taip pat nesugebame atskirti subjektų vizualiniame įvedime. Nors iš anksto apmokytų V&L modelių pardavimo vieta yra jų gebėjimas išspręsti sudėtingas užduotis, mūsų išvados rodo, kad jų pagrįstumo ir pagrindimo gebėjimų supratimas reikalauja tikslingesnių konkrečių reiškinių tyrimų.', 'mt': 'Aħna ninvestigaw il-kapaċità ta’ raġunament ta’ mudelli ta’ viżjoni u lingwa (V&L) imħarrġa minn qabel f’żewġ kompiti li jeħtieġu integrazzjoni multimodali: (1) id-diskriminazzjoni ta’ par korrett ta’ sentenza ta’ immaġni minn wieħed inkorrett, u (2) l-għadd ta’ entitajiet f’immaġni. Aħna jevalwaw tliet mudelli ta’ V&L imħarrġa minn qabel dwar dawn il-kompiti: ViLBERT, ViLBERT 12-in-1 u LXMERT, f’ambjenti mingħajr skop u ffinalizzati. Ir-riżultati tagħna juru li l-mudelli jsolvu l-kompitu (1) tajjeb ħafna, kif mistenni, peress li l-mudelli kollha huma mħarrġa minn qabel fuq il-kompitu (1). However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they cannot generalise to out-of-distribution quantities.  We propose a number of explanations for these findings: LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of catastrophic forgetting on task (1).  Fir-rigward tar-riżultati tagħna dwar is-sonda tal-għadd, isibu evidenza li l-mudelli kollha huma affettwati minn preġudizzju għas-sett tad-dejta, u wkoll jonqsu milli jindividwaw entitajiet fl-input viżwali. Filwaqt li punt ta’ bejgħ ta’ mudelli V&L imħarrġa minn qabel huwa l-kapaċità tagħhom li jsolvu kompiti kumplessi, is-sejbiet tagħna jissuġġerixxu li l-fehim tal-kapaċitajiet ta’ raġunament u ta’ bażi tagħhom jeħtieġ investigazzjonijiet aktar immirati fuq fenomeni speċifiċi.', 'no': 'Vi undersøker grunnleggingskapasiteten for å bruke forskyvingsmodeller og språk (V&L) i to oppgåver som krev multimodal integrasjon: (1) diskriminerer eit rett biletstrykk par frå ein feil, og (2) teljar einingar i eit bilete. Vi evaluerer tre pretrained V&L-modeller på desse oppgåvene: ViLBERT, ViLBERT 12-in-1 og LXMERT, i null-shot og finetulerte innstillingar. Resultatet våra viser at modeller løyser oppgåve (1) svært godt, som venta, sidan alle modeller vert løyst på oppgåve (1). Men ingen av dei pretrende V&L-modellene kan tilpassa oppgåva (2), tellingsproben vårt, og dei kan ikkje generellisere til utfordelingskvantitetar. Vi foreslår mange forklaringar for desse finningane: LXMERT (og til nokre måte ViLBERT 12-in-1) viser nokre beviser om katastrofisk glemme på oppgåva (1). I tillegg til resultatet våre på taleproben finn vi beviser at alle modeller vert påvirka av datasett-forsiktighet, og ikkje kan også individualisere entiteter i det visuelle inndata. Selv om eit salgspunkt av pretrende V&L-modeller er deres kapasitet for å løysa komplekse oppgåver, er det våre oppgåver tyder på at forståelse deres grunnleggingskapasiteten krev meir målretta undersøking om spesifikke fenomen.', 'pl': 'Badamy zdolność rozumowania wstępnie przeszkolonych modeli widzenia i języka (V&L) w dwóch zadaniach wymagających integracji multimodalnej: (1) odróżnienia prawidłowej pary zdań od niepoprawnej oraz (2) liczenia jednostek w obrazie. Oceniamy trzy wstępnie przeszkolone modele V&L w tych zadaniach: ViLBERT, ViLBERT 12-w-1 i LXMERT, w ustawieniach zero-shot i precyzyjnie dostrojonych. Nasze wyniki pokazują, że modele rozwiązują zadanie (1) bardzo dobrze, zgodnie z oczekiwaniami, ponieważ wszystkie modele są wstępnie trenowane na zadanie (1). Jednak żaden z wstępnie przeszkolonych modeli V&L nie jest w stanie odpowiednio rozwiązać zadania (2), naszej sondy liczeniowej, i nie może uogólnić do ilości poza dystrybucją. Proponujemy szereg wyjaśnień dla tych ustaleń: LXMERT (i do pewnego stopnia ViLBERT 12-w-1) wykazują pewne dowody katastrofalnego zapomnienia o zadaniu (1). Jeśli chodzi o nasze wyniki badania liczeniowe, znaleźliśmy dowody na to, że wszystkie modele są wpływane biasowaniem zbiorów danych, a także nie są w stanie indywidualizować jednostek w wejściu wizualnym. Chociaż punktem sprzedaży wstępnie przeszkolonych modeli V&L jest ich zdolność do rozwiązywania złożonych zadań, nasze ustalenia sugerują, że zrozumienie ich rozumowania i uziemienia wymaga bardziej ukierunkowanych badań nad konkretnymi zjawiskami.', 'ro': 'Investigăm capacitatea de raționament a modelelor de viziune și limbaj (V&L) pre-instruite în două sarcini care necesită integrare multimodală: (1) discriminarea unei perechi imagine-propoziție corectă de una incorectă și (2) numărarea entităților într-o imagine. Evaluăm trei modele V&L pre-instruite pentru aceste sarcini: ViLBERT, ViLBERT 12-in-1 și LXMERT, în setări zero-shot și fin-tuned. Rezultatele noastre arată că modelele rezolvă sarcina (1) foarte bine, așa cum era de așteptat, deoarece toate modelele sunt pre-instruite pe sarcina (1). Cu toate acestea, niciunul dintre modelele V&L pre-instruite nu este capabil să rezolve în mod adecvat sarcina (2), sonda noastră de numărare, și nu pot generaliza la cantități în afara distribuției. Propunem o serie de explicații pentru aceste constatări: LXMERT (și într-o anumită măsură ViLBERT 12-în-1) prezintă unele dovezi de uitare catastrofală pe sarcină (1). În ceea ce privește rezultatele noastre asupra sondei de numărare, găsim dovezi că toate modelele sunt afectate de părtinirea setului de date și, de asemenea, nu reușim să identificăm entitățile în intrarea vizuală. În timp ce un punct de vânzare al modelelor V&L pre-instruite este capacitatea lor de a rezolva sarcini complexe, constatările noastre sugerează că înțelegerea raționamentului și capacităților lor de împământare necesită investigații mai specifice asupra fenomenelor specifice.', 'si': 'අපි පරීක්ෂා කරනවා ප්\u200dරතිරීක්ෂණය සහ භාෂාව (V&L) මොඩේල්ස් දෙකක් වලින් ප්\u200dරතිරීක්ෂණය සහ භාෂාව (V&L) මොඩේල්ස් වලින් අවශ්\u200dය වෙනුවෙන්: (1) විශ අපි මේ වැඩේ ප්\u200dරීට්\u200dරේන්ඩ් V&L මොඩේල් තුනක් විශ්වාස කරනවා: ViLBERT, ViLBERT 12-in-1 සහ LXMERT, සුන්ධ වෙඩි තියෙනවා සහ සුන්ධ වෙඩි තියෙන අපේ ප්\u200dරතිචාරය පෙන්වන්නේ මොඩේල් වැඩ කරන්න (1) ගොඩක් හොඳයි, බලාපොරොත්තු විදිහට, හැම මොඩේල් වැඩේ ප්\u200dරතිච නමුත්, ප්\u200dරීට්\u200dරේන්ඩ් V&L මොඩල් එක්කෙන් කිසිම වැඩ කරන්න පුළුවන් නැහැ (2), අපේ ගණන් ප්\u200dරශ්නයක්, ඒ වගේම ඔවුන්ට ප්\u200dරශ්නයක් න අපි මේ හොයාගන්න විස්තරයක් ගොඩක් ප්\u200dරශ්නයක් සැලසුම් කරනවා: LXMERT (සහ විස්තර ViLBERT 12-in-1) වැඩේ අමතක වෙලා තියෙන සාක්ෂියක් පෙන්ව අපේ ප්\u200dරතිචාර පරීක්ෂණය ගැන, අපි හොයාගන්න සාක්ෂියක් හොයාගන්නවා හැම මොඩේල් සැකසුම් ප්\u200dරතිචාර විදියට පරීක්ෂණය කරනවා ක ප්\u200dරීට්\u200dරේන්ස් V&L මොඩල් එකේ වික්ෂණ ප්\u200dරතිකාරයක් තමයි ඔවුන්ගේ ප්\u200dරතිකාර විශ්වාස කරන්න පුළුවන්, අපේ හොයාගන්න පුළුවන් විතරයි ඔ', 'so': 'We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration: (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image.  Shaqooyinkan waxaa lagu qiimeynayaa saddex qaabab oo V&L ka hor dhigay: ViLBERT, ViLBERT 12-in-1 iyo LXMERT, oo lagu qoray qoraal aan la qorin iyo aan la fududayn. Fashiyadayada waxay muuqataa in tusaalooyinku ay u xajisaan shaqada (1) si wanaagsan, sida loo rajaynayo, sababtoo ah tusaalooyin oo dhan waxaa lagu sharrajiyey shaqada (1). Si kastaba ha ahaatee, noocyada V&L-ka mid ahna ma awoodi karo inay ku xalliyaan shaqada si ku filan (2), cadayntayada xisaabta, mana ay sameyn karaan qiyaastii aan qaybsanayn. Waxaan soo jeedaynaa caddeyn kala duduwan tusaale ahaan arimahan: LXMERT (iyo ilaa waqti dheer ViLBERT 12-in-1) oo tusaya calaamado khatar ah oo ka halmaamay shaqada (1). Kuwii ku saabsan resultiyada imtixaanka tirada, waxaynu helaynaa caddeynta in tusaalaha oo dhan ay saameyn ku leedahay dabeecada taranka, sidoo kale ma baaqan inay ka shaqeeyaan alaabta aragga. Inta lagu jiro noocyada iibinta V&L waa awooddooda ay ku xalliyaan shuqullada adag, waxaa laga jeedaa in garashada sababtooda iyo awoodooda aasitaanka ay u baahan yihiin baaritaanka waxqabadka gaarka ah.', 'mk': 'Ние ја истражуваме размислувачката способност на предобучените визии и јазички (V&L) модели во две задачи кои бараат мултимодилна интеграција: (1) дискриминација на правилниот пар со слика-реченица од неправилна, и (2) бројачки ентитети на слика. We evaluate three pretrained V&L models on these tasks: ViLBERT, ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings.  Our results show that models solve task (1) very well, as expected, since all models are pretrained on task (1).  Сепак, ниту еден од предобучените V&L модели не е во можност да ја реши задачата (2), нашата бројачка сонда, и тие не можат да се генерализираат на количини надвор од дистрибуцијата. We propose a number of explanations for these findings: LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of catastrophic forgetting on task (1).  Во врска со нашите резултати на истрагата за броење, најдовме докази дека сите модели се влијаени од пристрасност на податоците и исто така не успеваат да индивидуираат ентитети во визуелниот внес. Иако точката на продажба на предобучените модели на В&Л е нивната способност да решат комплексни задачи, нашите откритија укажуваат на тоа дека разбирањето на нивните размислувачки и основни способности бара поцелосни истраги за специфични феномени.', 'mn': 'Бид олон загварын нэгтгэл хэрэгтэй хоёр даалгаврын үзэл, хэл (V&L) загварын тухай бодит байдлыг судалж байна: (1) буруу хэлбэрээс зөв зураг өгүүлэх хоёрыг буруу хэлбэрээс ялгаалж, мөн (2) хэлбэрээр тооцоолж байгаа загвар. Бид эдгээр ажил дээр 3 давтагдсан V&L загварыг үнэлдэг: ViLBERT, ViLBERT 12-in-1, LXMERT, 0-н шат болон цэвэрхэн тохиолдолд. Бидний үр дүнд загварууд ажлыг олох (1) нь маш сайн шийдвэрлэхийг харуулж байна. Яагаад гэвэл бүх загварууд ажил дээр (1) хураагдаж байгаа учраас (1). Гэхдээ бидний тооцоолох судалгаагаар V&L загваруудын хэн ч ажлыг сайн олох боломжгүй. Бид олон тодорхойлолтуудыг тайлбарлаж байна: LXMERT (мөн зарим хэмжээнд ViLBERT 12-in-1) ажил дээр алдсан гамшигтай зүйлсийг харуулж байна. Тооцоолох судалгааны үр дүний тухай бид бүх загваруудыг өгөгдлийн сангийн өрөөсгөлд нөлөөлдөг гэдгийг баталж байна. Мөн индивидуал өгөгдлийн оролцоонд индивидуал бүтээгдэхүүнд бүтэлгүйтсэн. Хэдийгээр тэдний комплекс даалгаваруудыг шийдэх чадварыг тэдний худалдаж буй V&L загваруудын худалдаж буй цэгүүд нь ойлгох боломжуудыг ойлгох нь тодорхой явдал дээр илүү зориулсан судалгаа хэрэгтэй.', 'sv': 'Vi undersöker resonemangsförmågan hos förtrränade vision- och språkmodeller i två uppgifter som kräver multimodal integration: (1) att skilja ett korrekt bild-meningspar från ett felaktigt och (2) att räkna entiteter i en bild. Vi utvärderar tre förkränade V&L-modeller på dessa uppgifter: ViLBERT, ViLBERT 12-i-1 och LXMERT, i noll- och finjusterade inställningar. Våra resultat visar att modeller löser uppgiften (1) mycket bra, som förväntat, eftersom alla modeller är förberedda på uppgiften (1). Men ingen av de förkränade V&L-modellerna kan tillfredsställande lösa uppgiften (2), vår räknare sond, och de kan inte generalisera till outdistributionsmängder. Vi föreslår ett antal förklaringar till dessa resultat: LXMERT (och i viss mån ViLBERT 12-in-1) visar några tecken på katastrofal glömska om uppgiften (1). När det gäller våra resultat på räkningssonden finner vi bevis för att alla modeller påverkas av dataset bias, och inte heller kan identifiera entiteter i den visuella ingången. Medan en försäljningspunkt för förtrränade V&L-modeller är deras förmåga att lösa komplexa uppgifter, tyder våra resultat på att förståelse av deras resonemang och jordningsförmåga kräver mer målinriktade undersökningar av specifika fenomen.', 'ta': 'நாம் பிம்பத்தில் இரண்டு பணிகளில் சேர்க்கப்பட்ட பார்வையும் மொழியும் (V&L) மாதிரிகளின் காரணத்தையும் ஆராய்ச்சி செய்கிறோம்: (1) ஒரு சரியான பிம்பத்தின் சுட்ட வில்பெர்ட், வில்பெர்ட் 12-in-1 மற்றும் LXMERT, பூஜ்ஜியம் மற்றும் முன்னோக்கப்பட்ட அமைப்புகளில் மூன்று மாதிரிகளை மதிப்பிடுகிறோம். நம்முடைய முடிவு ஆயினும், வழங்கப்பட்ட வி.எல் மாதிரிகளில் எதுவும் தீர்வு செய்ய முடியாது (2), எங்கள் எண்ணிக்கையை கண்டுபிடிக்க முடியாது, அவை வெளியே பங இந்த கண்டுபிடிப்புகளுக்கான சில விளக்கங்களை நாம் பரிந்துரைக்கிறோம்: LXMERT (மற்றும் சில அளவு வில்பெர்ட் 12-in-1) சில துன்பத்தை மறந்து  எண்ணிக்கையின் முடிவுகள் பற்றி நாம் கண்டுபிடிக்கிறோம் அனைத்து மாதிரிகளும் தகவல் அமைப்பு பியாஸ் பாதிக்கப்பட்டுள்ளது என்று, மற்று விற்பனை புள்ளி', 'ur': "ہم نے دوسرے کاموں میں پہلے نظر اور زبان کی (V&L) نمڈلوں کی منطقی قابلیت کی تحقیق کی ہے جو multimodal integration کی ضرورت رکھتے ہیں: (1) ایک غلط تصویر کے جوڑے سے درست تصویر کا جوڑا تقسیم کرتے ہیں، اور (2) ایک تصویر میں شمار کرنے والے entities. ہم نے ان کاموں پر تین پیشرین V&L موڈل کا ارزش کیا: ViLBERT, ViLBERT 12-in-1 اور LXMERT، صفر-شٹ اور پاکیزہ تنظیمات میں. ہمارے نتیجے دکھاتے ہیں کہ موڈل کام (1) کو بہت اچھا حل کرتا ہے، جیسے انتظار کیا گیا ہے، کیونکہ تمام موڈل کام (1) پر زیادہ زیادہ زیادہ تدبیر کئے جاتے ہیں۔ However, none of the pretrained V&L models can adequately solve task (2), our counting probe, and they can't generalise out of distribution quantities. ہم ان پاؤں کے لئے بہت سی توضیح پیشنهاد کرتے ہیں: LXMERT (اور کچھ اندازے سے ViLBERT 12-in-1) کام پر بھولے جانے والی مصیبت کی نشانیاں (1) دکھاتے ہیں۔ ہمارے نتیجے گنتی پرڈ کے بارے میں، ہم نے ثابت قدم لیا ہے کہ تمام نمڈلوں کو ڈاٹ سٹ کی بحث سے اثر دی جاتی ہے، اور وہاں بھی تصویر وروت میں ایک فرقہ کے اختیار میں ناکام ہوتے ہیں. اگرچہ ان کے پیچیدہ کاموں کو حل کرنے کی قابلیت ہے، ہمارے نتیجے یہ سمجھتے ہیں کہ ان کے دلیل اور بنیادی قابلیت سمجھنے کی زیادہ موجب تحقیق کی ضرورت ہے.", 'sr': 'Istražujemo razumnu sposobnost modela vida i jezika (V&L) u dva zadatka koji zahtevaju multimodalnu integraciju: (1) diskriminirajući pravi par rečenica slike iz pogrešne rečenice, i (2) brojanja entiteta na sliki. Procjenjujemo tri pretkinjena V&L modela na ovim zadatkima: ViLBERT, ViLBERT 12-in-1 i LXMERT, u nulom snimanju i finom određenom stanju. Naši rezultati pokazuju da se modeli rešavaju zadatak (1) vrlo dobro, kao što je očekivano, pošto se svi modeli pretvaraju na zadatak (1). Međutim, nijedan od pretkišenih modela V&L nije u stanju adekvatno rešiti zadatak (2), našu sondu za brojanje, i oni ne mogu generalizirati na iznad distribucije količine. Predlažemo broj objašnjenja za ove nalaze: LXMERT (i u neku mjeru ViLBERT 12-in-1) pokazuju neke dokaze o katastrofskom zaboravljanju na zadatak (1). Što se tiče naših rezultata na sondi brojanja, nalazimo dokaze da su svi modeli utjecani predrasudama podataka, a takođe ne uspevaju da pojedinačne entitete u vizualnom ulazu. Iako je tačka prodaje pretreniranih modela V&L njihova sposobnost da riješe kompleksne zadatke, naši nalazi sugeriraju da razumevanje njihovih mogućnosti razuma i osnova zahteva više ciljnih istraga o specifičnim fenomenima.', 'uz': "Biz ko'paytirish kerak bo'lgan ikkita vazifalarda ko'plab-birlashtirish kerak bo'lgan ko'plab ko'rinish va o'zgaruvchining haqiqida o'zgarishga ega bo'lishimiz mumkin: 1) rasm-soʻzni notoʻgʻri bir narsa va (2) rasmni hisoblash. Biz shu vazifalarda uchta taxminan V&L modellarini qiymatmiz: ViLBERT, ViLBERT 12- in-1 va LXMERT nuqta va ajratilgan moslamalarda. Bizning natijalarimiz esa modellar vazifani aniqlash imkoniyatini ko'rsatadi, chunki hamma modellar vazifa (1) da o'xshash keladi. Lekin, V&L modellaridan hech kim ishni yetarlicha o'tib kelmaydi (2), hisoblash muvaffaqiyatlarimiz mumkin, va ular ajratish qiymatiga yetarli emas. Bu natijalar uchun bir necha forklarini talab qilamiz: Ko'rib chiqarish natijalarimiz haqida, biz hamma modellar maʼlumotlar bir xizmatlar tomoniga ishlatiladi va ko'rinadigan narsalarni qo'shishga muvaffaqiyatsiz tugadi. Biz murakkab vazifalarni aniqlash imkoniyatini o'rganish mumkin, biz murakkab vazifalarni tushunishimiz mumkin, ularning g'oyalari va tuzilishi imkoniyatini tushunishi mumkin, ularning sabablarni va qo'shish imkoniyatlarini aniqlash kerak bo'ladi.", 'vi': 'Chúng tôi điều tra khả năng lập luận của các mô hình ngôn ngữ và hình ảnh trước khi chụp (V, L) trong hai nhiệm vụ cần thiết phải phối hợp đa phương: 1) phân biệt một cặp hình ảnh đúng từ một cái sai, và (2) thực thể đếm trong ảnh. Chúng tôi đánh giá ba mẫu V/ L trước khi làm nhiệm vụ này: ViLBERT, ViLBERT 12-in-1 và LXMENT, trong thiết lập không quay và tinh chỉnh. Kết quả của chúng tôi cho thấy các mẫu giải quyết nhiệm vụ(1) rất tốt, như dự kiến, vì mọi mẫu đều được xem trước nhiệm vụ (1). Tuy nhiên, không có mẫu V/ L được bình thường giải quyết thích thích thích thích thích thích thích thích thích hợp (2), hệ thống thăm dò đếm của chúng ta, và chúng không thể phát thường ra lượng ngoài phân phối. Chúng tôi đề xuất một số giải thích cho những phát hiện này: LXMENT (và cho một phần nào đó virus virus virus virus virus virus virus 12-in-1) cho thấy một số chứng cứ về sự lãng quên thảm họa trên nhiệm vụ (1). Đối với kết quả của chúng ta về máy dò đếm, chúng ta tìm thấy bằng chứng rằng mọi mô- đun đều bị ảnh hưởng bởi khuynh hướng của tập tin, và cũng không xác định được thực thể trong dữ liệu. Trong khi một điểm bán của các mô hình xoắn V/ L là khả năng giải quyết các nhiệm vụ phức tạp, những phát hiện của chúng tôi cho thấy việc hiểu lý lẽ của họ và khả năng cơ bản đòi hỏi điều tra mục tiêu hơn về các hiện tượng cụ thể.', 'bg': 'Проучваме способността за разсъждаване на предварително тренирани модели на зрение и език в две задачи, които изискват мултимодална интеграция: (1) разграничаване на правилна двойка изображение-изречение от неправилна и (2) преброяване на единици в изображение. Ние оценяваме три предварително обучени модела за тези задачи: в нулеви и фини настройки. Нашите резултати показват, че моделите решават задача (1) много добре, както се очаква, тъй като всички модели са предварително обучени по задача (1). Въпреки това, никой от предварително тренираните модели не е в състояние да реши адекватно задачата (2), нашата бройна сонда, и те не могат да генерализират до количества извън разпределение. Предлагаме редица обяснения за тези констатации: показва някои доказателства за катастрофално забравяне на задачата (1). Що се отнася до резултатите ни от бройната сонда, намираме доказателства, че всички модели са повлияни от пристрастия към набора от данни, а също така не успяват да индивидуализират единици във визуалния вход. Докато продаващата точка на предварително обучените модели е способността им да решават сложни задачи, нашите констатации предполагат, че разбирането на техните възможности за разсъждаване и заземяване изисква по-целенасочени изследвания на конкретни явления.', 'hr': 'Istražujemo razumnu sposobnost modela preglednih vida i jezika (V&L) u dva zadatka koji zahtijevaju multimodalnu integraciju: (1) diskriminirajući pravi par rečenica slike iz pogrešnog jednog i (2) entiteta brojanja na sliki. Procjenjujemo tri pretkišena V&L modela na ovim zadatkima: ViLBERT, ViLBERT 12-in-1 i LXMERT, u nulo-pucanju i finetne postavke. Naši rezultati pokazuju da su modeli riješili zadatak (1) vrlo dobro, kao što je očekivano, jer su svi modeli pretrenuti na zadatak (1). Međutim, nijedan od pretkišenih modela V&L nije u stanju adekvatno riješiti zadatak (2), našu sondu za brojanje, i oni ne mogu generalizirati na iznad distribucije količine. Predlažemo broj objašnjenja za te nalaze: LXMERT (i u neku mjeru ViLBERT 12-in-1) pokazuju neke dokaze o katastrofskom zaboravljanju na zadatak (1). Što se tiče naših rezultata na sondi brojanja, nalazimo dokaze da su svi modeli utjecani na predrasude podataka, a također nisu pojedinačni subjekti u vizualnom ulazu. Iako je tačka prodaje pretkišenih modela V&L njihova sposobnost rješavanja kompleksnih zadataka, naši nalazi sugeriraju da razumijevanje njihovih mogućnosti razuma i osnova zahtijevaju ciljnije istrage o specifičnim fenomenima.', 'da': 'Vi undersøger ræsonneringsevnen af forudtrænede vision- og sprogmodeller i to opgaver, der kræver multimodal integration: (1) at skelne et korrekt billede-sætning par fra et forkert par, og (2) at tælle enheder i et billede. Vi evaluerer tre forudtrænede V&L modeller på disse opgaver: ViLBERT, ViLBERT 12-i-1 og LXMERT, i nul-shot og finjusterede indstillinger. Vores resultater viser, at modeller løser opgave (1) meget godt, som forventet, da alle modeller er fortrænet på opgave (1). Men ingen af de forudtrænede V&L modeller er i stand til at løse opgaven (2), vores tællesonde tilstrækkeligt, og de kan ikke generalisere til mængder uden for distribution. Vi foreslår en række forklaringer på disse resultater: LXMERT (og til en vis grad ViLBERT 12-i-1) viser nogle tegn på katastrofal glemmelse af opgaven (1). Med hensyn til vores resultater på tællesonden finder vi beviser på, at alle modeller påvirkes af datasæt bias, og heller ikke identificerer enheder i det visuelle input. Mens et salgspunkt for forudtrænede V&L-modeller er deres evne til at løse komplekse opgaver, tyder vores resultater på, at forståelsen af deres ræsonnement og jordbundning kræver mere målrettede undersøgelser af specifikke fænomener.', 'nl': 'We onderzoeken het redeneervermogen van vooraf getrainde visie- en taalmodellen in twee taken die multimodale integratie vereisen: (1) het onderscheiden van een correct beeld-zinnenpaar van een onjuist, en (2) het tellen van entiteiten in een beeld. We evalueren drie vooraf getrainde V&L modellen voor deze taken: ViLBERT, ViLBERT 12-in-1 en LXMERT, in zero-shot en finetuned instellingen. Onze resultaten tonen aan dat modellen taak (1) zeer goed oplossen, zoals verwacht, aangezien alle modellen vooraf getraind zijn op taak (1). Echter, geen van de vooraf getrainde V&L modellen is in staat om taak (2), onze telsonde, adequaat op te lossen en ze kunnen niet generaliseren naar niet-distributiehoeveelheden. We stellen een aantal verklaringen voor deze bevindingen voor: LXMERT (en tot op zekere hoogte ViLBERT 12-in-1) tonen enig bewijs van catastrofale vergeten op taak (1). Met betrekking tot onze resultaten op de telsonde, vinden we bewijs dat alle modellen worden beïnvloed door dataset bias, en ook niet in staat zijn entiteiten te individueren in de visuele input. Hoewel een verkooppunt van vooraf getrainde V&L modellen hun vermogen is om complexe taken op te lossen, suggereren onze bevindingen dat het begrijpen van hun redenering en gronding capaciteiten gerichter onderzoek naar specifieke fenomenen vereist.', 'id': 'Kami menyelidiki kemampuan alasan dari model penglihatan dan bahasa (V&L) terlatih dalam dua tugas yang memerlukan integrasi multimodal: (1) diskriminasi pasangan gambar-kalimat yang benar dari salah satu, dan (2) menghitung entitas dalam gambar. Kami mengevaluasi tiga model V&L terlatih di tugas ini: ViLBERT, ViLBERT 12-in-1 dan LXMERT, dalam pengaturan nol-shot dan finetuned. Hasil kami menunjukkan bahwa model memecahkan tugas (1) dengan baik, seperti yang diharapkan, karena semua model dilatih di tugas (1). Namun, tidak satupun dari model V&L yang dilatih sebelumnya mampu menyelesaikan tugas (2), sonda penghitungan kita, dan mereka tidak dapat menyebarkan ke jumlah luar distribusi. Kami mengusulkan beberapa penjelasan untuk penemuan ini: LXMERT (dan seberapa besar ViLBERT 12-in-1) menunjukkan beberapa bukti bencana melupakan tugas (1). Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individualize entities in the visual input. While a selling point of pretrained V&L models is their ability to solve complex tasks, our findings suggest that understanding their reasoning and grounding capabilities requires more targeted investigations on specific phenomena.', 'de': 'Wir untersuchen die Argumentationsfähigkeit von vortrainierten Vision- und Sprachmodellen (V&L)-in zwei Aufgaben, die eine multimodale Integration erfordern: (1) Unterscheidung eines richtigen Bild-Satz-Paares von einem falschen und (2) Zählen von Entitäten in einem Bild. Wir evaluieren drei vortrainierte V&L Modelle für diese Aufgaben: ViLBERT, ViLBERT 12-in-1 und LXMERT, in Zero-Shot und Feinabstimmung. Unsere Ergebnisse zeigen, dass Modelle Aufgabe (1) wie erwartet sehr gut lösen, da alle Modelle auf Aufgabe (1) vortrainiert sind. Keines der vortrainierten V&L-Modelle ist jedoch in der Lage, Aufgabe (2), unsere Zählsonde, adäquat zu lösen und kann nicht auf nicht verteilte Mengen verallgemeinern. Wir schlagen eine Reihe von Erklärungen für diese Befunde vor: LXMERT (und teilweise ViLBERT 12-in-1) zeigen Hinweise auf katastrophales Vergessen der Aufgabe (1). In Bezug auf unsere Ergebnisse auf die Zählprobe finden wir Hinweise darauf, dass alle Modelle von Datensatzverzerrungen betroffen sind und auch keine Entitäten in der visuellen Eingabe individualisieren können. Während ein Verkaufsargument vortrainierter V&L-Modelle ihre Fähigkeit ist, komplexe Aufgaben zu lösen, deuten unsere Ergebnisse darauf hin, dass das Verständnis ihrer Argumentations- und Erdungsfähigkeiten gezieltere Untersuchungen spezifischer Phänomene erfordert.', 'ko': '우리는 시각과 언어(V&L)모델이 다중모드 통합이 필요한 두 가지 임무에서의 추리력을 미리 훈련시켰다. (1) 정확한 이미지 문장 쌍과 잘못된 이미지 문장 쌍을 구분하고 (2) 이미지의 실체를 계산하는 것이다.우리는 세 가지 예비훈련의 V&L모델이 이러한 임무에 나타난 것을 평가했다. 그것이 바로 윌버트, 윌버트 12합성1과 LXMERT이다. 영포와 마이크로스피드 설정에 있다.우리의 결과에 따르면 모든 모델이 임무(1)에 대해 예훈련을 했기 때문에 모델은 임무를 잘 해결할 수 있다(1).그러나 사전에 훈련된 손익모델이 우리의 계수 탐지 임무를 충분히 해결할 수 있을 뿐만 아니라 분포 밖의 수량까지 확대할 수 없다.우리는 이러한 발견에 대해 몇 가지 해석을 제시했다. LXMERT (그리고 어느 정도의 VilBERT 12-in-1) 는 임무 (1) 에서 재난적인 망각의 증거를 보여 주었다.계수 탐지기의 결과에 대해 우리는 모든 모델이 데이터 집합의 편차의 영향을 받고 시각적 입력에서 실체를 개성화할 수 없다는 증거를 발견했다.미리 훈련된 V&L모델의 장점 중 하나는 복잡한 임무를 해결하는 능력이지만, 이들의 추리와 기초 능력을 이해하려면 특정 현상에 대한 맞춤형 조사가 필요하다는 연구결과가 나왔다.', 'sw': 'Tunafanya uchunguzi wa uwezo wa maana wa mifano ya kuonyesha na lugha (V&L) katika kazi mbili zinazohitaji ushirikiano wa kidunia: (1) kuelezea viwili sahihi kutoka kwa moja isiyo sahihi, na (2) kuhesabu vitu katika picha. Tutathmini mifano mitatu iliyopigwa na V&L kwenye kazi hizi: ViLBERT, ViLBERT 12-in-1 na LXMERT, katika mazingira yasiyo na sifuri. Matokeo yetu yanaonyesha kuwa mifano inatua kazi (1) vizuri, kama ilivyotarajiwa, kwa sababu mifano yote inatangazwa kwenye kazi (1). Hata hivyo, hakuna moja ya mifano ya vifaa vya V&L inaweza kutatua kazi ya kutosha (2), jaribio letu la kuhesabu, na hawawezi kuzalisha kwa kiasi cha kutogawanya. Tunazipendekeza maelezo kadhaa kwa matokeo haya: LXMERT (na kwa kiasi fulani cha ViLBERT 12-in-1) kuonyesha ushahidi wa janga la kusahau kazi (1). Kuhusu matokeo yetu kuhusu jaribio la kuhesabu, tunagundua ushahidi kuwa mifano yote yamesababishwa na upendeleo wa taarifa, na pia kushindwa kupunguza vifaa vinavyoonekana. Wakati mtazamo wa ununuzi wa mifano ya V&L ni uwezo wao wa kutatua kazi tata, matokeo yetu yanapendekeza kwamba kuelewa sababu zao na uwezo wa msingi unahitaji uchunguzi wa kina lengo la hali fulani.', 'fa': 'ما توانایی منطقی دید و زبان (V&L) را در دو کار تحقیق می\u200cکنیم که نیاز به جمع\u200cآوری چندین مدل است: (۱) یک جفت جمله\u200cی تصویر درست از یک جمله غلط و (۲) محاسبه\u200cای در یک تصویر جدا می\u200cکنیم. ما سه مدل V&L را در این وظیفه ارزیابی می کنیم: ViLBERT, ViLBERT 12-in-1 و LXMERT در تنظیمات صفر و بی\u200cنیاز. نتیجه\u200cهای ما نشان می\u200cدهند که مدل\u200cها کار (۱) را بسیار خوب حل می\u200cکنند، همانطور که انتظار داشته\u200cاند، زیرا همه مدل\u200cها بر روی کار (۱) تغییر داده می\u200cشوند. ولی هیچ کدام از مدل\u200cهای پیش\u200cفرض V&L قادر نیست کاری را به اندازه کافی حل کند (۲)، امتحان شمارش ما، و آنها نمی\u200cتوانند به اندازه\u200cهای غیر تقسیم کنند. ما تعدادی توضیح برای این نتیجه\u200cها پیشنهاد می\u200cکنیم: LXMERT (و به اندازه\u200cای ViLBERT 12-in-1) برخی از مدرک\u200cهای فاجعه\u200cای که در کار فراموش می\u200cکند (۱) نشان می\u200cدهیم. در مورد نتیجه\u200cهای ما در مورد امتحان شماره، مدرک می\u200cیابیم که همه مدرک\u200cها توسط طبیعت\u200cهای مجموعه\u200cی داده\u200cها تأثیر داده می\u200cشوند، و همچنین شکست نمی\u200cدهند که متحد\u200cهای فردی در ورودی دیده\u200cای تأثیر در حالی که یک نقطه فروش از مدل\u200cهای V&L پیش\u200cگیری توانایی آنها برای حل کار پیچیده است، نتیجه\u200cهای ما پیشنهاد می\u200cدهند که درک توانایی\u200cهای منطقی و پایه\u200cگیری آنها نیاز به تحقیقات هدف\u200cگیری بیشتری بر روی پدیده\u200cهای خاص است.', 'tr': 'Biz öňki görnüş we dil (V&L) nusgalarynyň (multimodal integrasy) sistemasynda nädogry bir surat-sözlemde nädogry bir däldir we (2) sanat elementlerini bir suratda diskrimi edip görýäris. Bu görevlerde üç önündeki V&L modelleri değerlendiriyoruz: ViLBERT, ViLBERT 12-in-1 ve LXMERT, 0-shot ve sonsuz ayarlar içinde. Biziň netijelerimiz nusgalaryň täzisini çözmesini (1) örän gowy gözlenýän bolandygyny görkezýär, sebäbi hemme nusgalaryň täzisinde (1) öňünde döredilýändigini görkezýär. Yine de öňündeki V&L modellerinin hiçbiri görevi (2), saylama sanatımızdan uygun çözemedi ve dağıtılma sayılardan başka bir şekilde düzenleyemedi. Biz bu tapmalar için birçok a çıklama teklif ediyoruz: LXMERT (ve bir şekilde ViLBERT 12-in-1) görevi unutmayan katastrofi bir kanıt gösteriyoruz (1). Sanamak probasynda netijelerimiz bardygynda, hemme nusgalaryň dataset biasy tarapyndan täsirli bolandygyny we munuň görsel girişinde birbirleri üýtgedigini tapdyk. Öň önünlikli V&L modelleriniň satylyk nokady olaryň karmaşık zadalaryny çözmek ukypdyr. Çözgülerimiz olaryň razylygyny we ýeterlik ukyplaryny düşünmek üçin özleriniň spesifik fenomenlerde köp maksadaly soruşmalary gerek bolmagyny maslahat berýärler.', 'af': "Ons ondersoek die redekende moontlikheid van voorrekende visie en taal (V&L) modele in twee taak wat multimodaal integrasie nodig: (1) wat 'n korrekte beeld-seting paar van' n verkeerde een, en (2) tel entiteite in 'n beeld. Ons evalueer drie pretrained V&L modele op hierdie opdragte: ViLBERT, ViLBERT 12-in-1 en LXMERT, in nul-skoot en finetuned instellings. Ons resultate vertoon dat modele oplos opdrag (1) baie goed, as verwagte, omdat alle modele op opdrag (1) voorgetrek word. Maar niemand van die pretreënde V&L-modele kan adequate opdrag oplos (2), ons tel probe, en hulle kan nie genereliseer na uitverspreidingskvantities nie. Ons voorstel 'n aantal uitduidelings vir hierdie vindings: LXMERT (en na sommige uitbreiding ViLBERT 12- in- 1) vertoon sommige getuienis van katastrofiske vergeet op taak (1). Aangaande ons resultate op die tel probe, vind ons bevestigheid dat alle modele deur datastel voorskyning geïffekteer word, en ook misluk om individuele entiteite in die visuele invoer te individueer. Alhoewel 'n verkooppunt van voorskryfde V&L-modele is hul moontlik om komplekse taak te los, is ons gevinde aanduidelik dat hulle redening en grunnende kapasiteite verstaan het meer doelgemaakte ondersoek op spesifieke fenomene nodig.", 'sq': 'We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration: (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image.  We evaluate three pretrained V&L models on these tasks: ViLBERT, ViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings.  Rezultatet tona tregojnë se modelet zgjidhin detyrën (1) shumë mirë, siç pritej, pasi të gjitha modelet janë trajnuar në detyrë (1). However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they cannot generalise to out-of-distribution quantities.  Ne propozojmë një numër shpjegimesh për këto gjetje: LXMERT (dhe në një farë mënyre ViLBERT 12-in-1) tregon disa prova të harrimit katastrofik të detyrës (1). Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input.  While a selling point of pretrained V&L models is their ability to solve complex tasks, our findings suggest that understanding their reasoning and grounding capabilities requires more targeted investigations on specific phenomena.', 'am': 'የራእይ እና ቋንቋ (V&L) ምሳሌዎችን በሚያስፈልጋቸው ሁለት ስራ ውስጥ ያስተካክሉናል:(1) እውነተኛውን ምስል-የውይይት ሁለት ዓይነቶችን ከስህተት አንዱን እና (2) አካባቢዎችን ምስል እንዲቆጠር እናደርጋለን፡፡ እነዚህን ስርዓቶች ላይ ያሉትን ሦስት የV&L ምሳሌዎችን እናስተዋልታለን: ViLBERT፣ ViLBERT 12-in-1 እና LXMERT በzero-shot እና ፍጥረት ላይ ነው፡፡ ፍጥረታችን ሞዴሎችን አድራጊ (1) እንዲፈጸም እንደተስፋ ነው፤ ምሳሌዎች ሁሉ በሥራ (1) ላይ በመፍጠር ነው፡፡ ምንም እንኳን፣ የV&L ዓይነቶች ማንም ስራችንን (2)፣ ቁጥር ፈተናችን ሊፈጸም አይችልም፣ ከክፍለ ክፍል ውጪ ማድረግ አይችሉም፡፡ ለዚህ ፍላጎች ብዙ ማስረጃዎችን እናሳልቃለን፤ LXMERT (እና ወደ አንዳንድ ደረጃ ViLBERT 12-in-1) ስራ ላይ የተረሳውን የጥፋት ማስረጃ ማሳየትን (1). በቁጥጥር ፈተና ላይ ፍሬዎቻችን፣ ሙሉ ምሳሌዎች ሁሉ በዳታዊው ብያሽን እንዲያካክሉ እና አካባቢዎችን በዓይነቱ ውስጥ እንዲያስወግዱ የማይጎድል ማስረጃዎችን እናገኛለን፡፡ የV&L ዓይነቶች የሚሸጥ ስራዎችን ለመፍታት የሚችል ስልጣን ሲሆን ግንኙነታችን ማስታወቂያውን እና መፍታትን በአካባቢ ነገር ላይ የተመሳሳይ ምርመራ እንዲያስፈልጋል፡፡', 'hy': "We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration: (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image.  Մենք գնահատում ենք երեք նախապատրաստված V+L մոդելներ այս խնդիրների վրա' Վիլբերթը, Վիլբերթը 12-ի-1 և Լքսմերթը, զրոյի և փոփոխված միջոցներում: Մեր արդյունքները ցույց են տալիս, որ մոդելները լուծում են խնդիրը (1) շատ լավ, ինչպես ակնկալում էր, քանի որ բոլոր մոդելները նախապատրաստված են խնդիրը (1). However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they cannot generalise to out-of-distribution quantities.  Մենք առաջարկում ենք մի շարք բացատրություններ այս բացահայտումների համար. LXMerc (և որոշ չափով ViLBER 12-in-1) ցույց է տալիս որոշ ապացույցներ, որոնք ցույց են տալիս, որ խնդիրը կործանր է մոռացել (1). Ինչ վերաբերում է հաշվարկի հարցում գտնվող մեր արդյունքներին, մենք գտնում ենք ապացույցներ, որ բոլոր մոդելները ազդում են տվյալների համակարգի կողմնականության վրա, ինչպես նաև չենք կարողանում անհատականացնել տեսողական ներմուծքի մեջ գտն Մինչդեռ նախավարժված V+L մոդելների վաճառման կետը նրանց կարողությունն է լուծել բարդ խնդիրները, մեր հայտնաբերությունները ցույց են տալիս, որ նրանց մտածողական և հիմնական կարողությունների հասկանալը պահանջում է ավելի նպատակային հետազոտություններ որոշակի երևույթների", 'az': 'Biz çoxlu modal integrasiya ehtiyacı olan iki işdə gözəl görünüş və dil modellərinin razılaşma qabiliyyətini incidirik: (1) yanlış bir şəkildən düzgün görüntü cümlələrinin çiftlərini ayırmaq və (2) saymaq məqsədilində olan iki işdə. Biz bu işlərdə üç əvvəlki V&L modelləri değerləşdiririk: ViLBERT, ViLBERT 12-in-1 və LXMERT, sıfır-vuruş və gözəl tərzdə. Bizim sonuçlarımız modellərin (1) işlərini çox yaxşı çəkdiyini göstərir, çünki bütün modellərin (1) işləri təkrarlandırılır. Ancaq, əvvəlki V&L modellərin heç biri görevi (2), sayım sonumuza uyğun çəkə bilməz və onlar dağıtılmaz sayılara generalizə edə bilməzlər. Biz bu məlumatlar üçün bir neçə a çıq-aydın təbliğ edirik: LXMERT (və bir neçə dəfə ViLBERT 12-in-1) işləri unutduğu katastrofi dəlilləri göstərir (1). Seçmə sonuğumuz barəsində, bütün modellərin verilən qurbanlar təsirlərindən təsirləndirildiyi təsdiqləndirildiyi təsdiqləyici təsdiqləyici təsdiqləyici təsdiqləyici təsdiqləyici təsdiqləyici görünür. Əvvəlki V&L modellərin satış nöqtəsi onların kompleks işləri çəkmə bacarığı olduğu halda, bizim tapındıqlarımız onların razılıqlarını və yerləşdirmə bacarıqlarını anlamaq məqsədil fenomenlər barəsində daha çox məqsədil təşkil etmək lazımdır.', 'bs': 'Istražujemo razumnu sposobnost modela preglednih vida i jezika (V&L) u dva zadatka koji zahtijevaju multimodalnu integraciju: 1) diskriminirajući pravi par rečenica slike iz pogrešnog jednog, i 2) entiteta brojanja na sliki. Procjenjujemo tri pretrenirana V&L modela na ovim zadatkima: ViLBERT, ViLBERT 12-in-1 i LXMERT, u nulom snimanju i finom određenom stanju. Naši rezultati pokazuju da se modeli vrlo dobro rješavaju zadatak (1), kao što je očekivano, jer se svi modeli pretvaraju na zadatak (1). Međutim, nijedan od pretkišenih modela V&L nije u stanju adekvatno riješiti zadatak (2), našu sondu za brojanje, i oni ne mogu generalizirati na iznad distribucije količine. Predlažemo nekoliko objašnjenja za te nalaze: LXMERT (i u neku mjeru ViLBERT 12-in-1) pokazuju neke dokaze katastrofičkog zaboravljanja na zadatku (1). Što se tiče naših rezultata na sondi brojanja, nalazimo dokaze da su svi modeli utjecani na predrasude kompleta podataka, a također nisu pojedinačni entiteti u vizualnom ulazu. Iako je tačka prodaje pretreniranih modela V&L njihova sposobnost rješavanja kompleksnih zadataka, naši nalazi ukazuju na to da razumijevanje njihovih mogućnosti razuma i osnova zahtijevaju ciljnije istrage o specifičnim fenomenima.', 'bn': 'আমরা অনুসন্ধান করি দুই কাজের মধ্যে দৃষ্টি এবং ভাষা (ভি&এল) মডেলের যৌক্তিক ক্ষমতা, যা মাল্টিমোডাল একত্রিত হওয়ার প্রয়োজন: (১) একটি সঠিক ছবির কারাদণ্ডের জোড়া ভুল একটি ছবির এই কাজের উপর আমরা তিনটি প্রাপ্ত ভি&এল মডেলের মূল্য মূল্য দিচ্ছি: ভিলবের্ট, ভিলবের্ট ১২-ইন-১ এবং এলএক্সমের্টি। শুধুমাত্র গুলি এবং ফিন্স Our results show that models solve task (1) very well, as expected, since all models are pretrained on task (1).  However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they cannot generalise to out-of-distribution quantities.  আমরা এই আবিস্কারের জন্য বেশ কয়েকটি ব্যাখ্যা প্রস্তাব করেছি: এলএক্সমের্টি (এবং কিছু পর্যায়ে ভিলেবার্ট ১২-ইন-১) কিছু প্রমাণ প্রদর্শন করেছে ক গণনা পরীক্ষার ফলাফল সম্পর্কে আমরা প্রমাণ পেয়েছি যে ডাটাসেট বিয়াসের দ্বারা সকল মডেল প্রভাবিত হয়েছে এবং দৃষ্টিভঙ্গিতে বিভিন্ন বস্তুক যখন ভি&এল মডেলের একটি বিক্রি বিক্রি করা বিন্যাস হচ্ছে তাদের জটিল কাজ সমাধানের ক্ষমতা, তখন আমাদের আবিস্কার পরামর্শ দেয়া হচ্ছে যে তাদের কারণ এবং ভূমিকম্পের ক', 'ca': 'We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration: (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image.  Evaluam tres models de V&L pré-entrenats en aquestes tasques: ViLBERT, ViLBERT 12-in-1 i LXMERT, en configuracions de zero-shot i fins. Els nostres resultats demostren que els models resolen la tasca (1) molt bé, com es esperava, ja que tots els models estan pré-entrenats en la tasca (1). However, none of the pretrained V&L models is able to adequately solve task (2), our counting probe, and they cannot generalise to out-of-distribution quantities.  We propose a number of explanations for these findings: LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of catastrophic forgetting on task (1).  Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input.  While a selling point of pretrained V&L models is their ability to solve complex tasks, our findings suggest that understanding their reasoning and grounding capabilities requires more targeted investigations on specific phenomena.', 'cs': 'Zkoumáme uvažovací schopnost předtrénovaných modelů vidění a jazyka (V&L) ve dvou úkolech, které vyžadují multimodální integraci: (1) rozlišování správného páru obrazu-věty od nesprávného a (2) počítání entit v obrazu. Pro tyto úkoly hodnotíme tři předtrénované modely V&L: ViLBERT, ViLBERT 12-v-1 a LXMERT, v nulovém a jemném nastavení. Naše výsledky ukazují, že modely řeší úlohu (1) velmi dobře, jak se očekává, protože všechny modely jsou předtrénovány na úlohu (1). Nicméně žádný z předtrénovaných V&L modelů není schopen adekvátně řešit úlohu (2), naši počítačovou sondu, a nemohou zobecnit na mimo distribuci množství. Navrhujeme řadu vysvětlení těchto nálezů: LXMERT (a do určité míry i ViLBERT 12-in-1) ukazují nějaké důkazy katastrofického zapomenutí na úkol (1). Co se týče našich výsledků na počítačové sondě, našli jsme důkazy, že všechny modely jsou ovlivněny biasem datových sad a také nedokážou individualizovat entity ve vizuálním vstupu. Zatímco prodejním bodem předem trénovaných V&L modelů je jejich schopnost řešit složité úkoly, naše zjištění naznačují, že pochopení jejich uvažování a uzemnění schopností vyžaduje cílenější zkoumání konkrétních jevů.', 'fi': 'Tutkimme esikoulutettujen näkemys- ja kielimallien päättelykykyä kahdessa multimodaalista integraatiota edellyttävässä tehtävässä: (1) oikean kuva-lauseparin erottaminen väärästä ja (2) entiteettien laskeminen kuvassa. Arvioimme kolmea esikoulutettua V&L-mallia näissä tehtävissä: ViLBERT, ViLBERT 12-in-1 ja LXMERT nollakuvausasetuksissa ja hienosäätöissä. Tuloksemme osoittavat, että mallit ratkaisevat tehtävän (1) odotetulla tavalla, koska kaikki mallit on esikoulutettu tehtävään (1). Yksikään ennalta koulutetuista V&L-malleista ei kuitenkaan pysty ratkaisemaan riittävästi tehtävää (2), laskentaluotainta, eivätkä ne voi yleistyä jakelun ulkopuolella oleviin määriin. Ehdotamme useita selityksiä näihin löydöksiin: LXMERT (ja jossain määrin ViLBERT 12-in-1) osoittaa joitakin todisteita katastrofista unohtamisesta tehtävässä (1). Laskentaluotaimen tuloksista löydämme todisteita siitä, että datajoukon vääristymät vaikuttavat kaikkiin malleihin, eivätkä ne myöskään pysty yksilöimään kokonaisuuksia visuaalisessa syötteessä. Esikoulutettujen V&L-mallien myyntipisteenä on niiden kyky ratkaista monimutkaisia tehtäviä, mutta tutkimustuloksemme viittaavat siihen, että niiden päättelyn ja pohjautumiskyvyn ymmärtäminen edellyttää kohdennetumpaa tutkimusta tietyistä ilmiöistä.', 'et': 'Uurime eeltreenitud nägemis- ja keelemudelite (V&L) mõtlemisvõimet kahes ülesandes, mis nõuavad multimodaalset integratsiooni: (1) õige pildi-lausepaari eristamine ebaõigest ja (2) olemuste loendamine pildil. Nende ülesannete puhul hindame kolme eeltreenitud V&L mudelit: ViLBERT, ViLBERT 12-in-1 ja LXMERT null-shot ja peenestatud seadetes. Meie tulemused näitavad, et mudelid lahendavad ülesande (1) väga hästi, nagu oodati, kuna kõik mudelid on eeltreenitud ülesande (1) järgi. Kuid ükski eeltreenitud V&L mudel ei suuda piisavalt lahendada ülesannet (2), meie loendussõdurit, ja neid ei saa üldistada jaotusest väljas olevatele kogustele. Pakume välja mitmeid selgitusi nende tulemuste kohta: LXMERT (ja teatud määral ViLBERT 12-in-1) näitab mõningaid tõendeid katastroofilisest ülesande unustamisest (1). Mis puudutab meie tulemusi lugemissoodri kohta, siis leiame tõendeid, et kõiki mudeleid mõjutab andmekogumi kallutamine ja samuti ei suuda neid visuaalses sisendis individuaalselt eristada. Kuigi eeltreenitud V&L mudelite müügipunktiks on nende võime lahendada keerukaid ülesandeid, näitavad meie tulemused, et nende mõtlemise ja maandamise võimekuse mõistmine nõuab konkreetsete nähtuste sihipärasemat uurimist.', 'sk': 'Raziskovali smo sposobnost razmišljanja predvadljenih modelov vida in jezika (V&L) v dveh nalogah, ki zahtevata multimodalno integracijo: (1) razlikovanje pravilnega za sliko-stavek od napačnega in (2) štetje entitet na sliki. Pri teh nalogah smo ocenili tri predtrenirane modele V&L: ViLBERT, ViLBERT 12-v-1 in LXMERT, v nastavitvah brez strela in natančno nastavljenih. Naši rezultati kažejo, da modeli rešujejo nalogo (1) zelo dobro, kot je bilo pričakovano, saj so vsi modeli predvadljeni na nalogo (1). Vendar pa noben od predtreniranih modelov V&L ne more ustrezno rešiti naloge (2), naše štetje sonde, in ne more posplošiti na količine, ki niso porazdelitve. Predlagamo številne razlage za te ugotovitve: LXMERT (in do neke mere ViLBERT 12-v-1) kažejo nekaj dokazov katastrofalnega pozabljanja na nalogo (1). Glede na naše rezultate štetja najdemo dokaze, da na vse modele vpliva pristranskost nabora podatkov, prav tako pa v vizualnem vnosu ne moremo posameznikovati entitet. Medtem ko je prodajna točka predtreniranih modelov V&L njihova sposobnost reševanja kompleksnih nalog, naše ugotovitve kažejo, da razumevanje njihovih zmožnosti razumevanja in ozemljitve zahteva bolj ciljno usmerjene raziskave specifičnih pojavov.', 'jv': 'Awak dhéwé nyongguna perusahaan karo akeh Panjenengan lan luwih (V&L) model sing dibutuhke ditambah iki dadi dianggap multimodal: We assess 3 Laptop" and "Desktop politenessoffpolite, "), and when there is a change ("assertivepoliteness Awak dhéwé ngerasakno akeh akeh luwih akeh gawe nggawe barang iki: LXMerT (dan saben batasan VisLBERT 12-in-1) iso nggawe barang kelas karo caftarno kuwi mau (1). Genjer-genjer mbuganyu punika ingkang rawe kantor-punika hayag kita spike punika ingkang angkang dadi batakan Alpha', 'ha': "Tuna ƙidãya masu yinin gani da harshen (V_L) cikin aikin biyu wanda ke ƙayyade haɗiya da multi-multi: (1) suna rarraba nau'in sunan-surar da suka daidaita daga wani mai maras kuma (2) mai ƙidãya masu cikin zane. Mu ƙaddara misãlai uku wanda aka yi wa V/L a kan wannan aikin: WiLBERT, WiLBERT 12-in-1 da LXMERT, cikin sifo-shot da finfinfined. MatamayinMu na nuna cewa misãlai su sola aiki (1) mai kyau kamar yadda aka ƙayyade, don haka duk misãlai za'a bayyana a kan aikin (1). A lokacin da wani misalin V/L na daɗa ba zai iya iya yin raba aiki da hakki (2), ma'anar ƙidãyinmu, kuma ba za su iya cire kodi ba da rabo. Tuna goyyar da wasu fassarai wa waɗannan fassarar da aka samu: LXMERT (kuma zuwa wani gwargwadon da aka yi wa KilBERT 12-in-1) za'a nũna wani dalĩli na masĩfi wanda ya manta a kan aikin (1). Ga da matsalanmu a ƙidãyar jarrabai, Munã sãmu shaidar duk misãlai sun yi musamman da abinda na danne-danne, kuma an kasa canza masu cikin tsarin da ke gani. Waka da wani point ya sali misalin V/L za'a iya iya iya solar aikin masu husũma, misãlai masu shagala ne da cẽwa, an fahimta fahimcinsu da abincin bakwai sun ƙayyade kashfa masu ƙaranci a kan abu na ƙayyade.", 'he': 'We investigate the reasoning ability of pretrained vision and language (V&L) models in two tasks that require multimodal integration: (1) discriminating a correct image-sentence pair from an incorrect one, and (2) counting entities in an image.  אנו מעריכים שלושה דוגמנים V&L מאומנים מראש על המשימות הללו: ViLBERT, ViLBERT 12-in-1 ו LXMERT, במסדרות אפס-ירייה ומתאימות. התוצאות שלנו מראות שדוגמנים פותרים את המשימה (1) היטב, כפי שציפיתי, מכיוון שכל דוגמנים מתאמנים מראש על המשימה (1). בכל אופן, אף אחד מהדוגמנים V&L המאמנים מראש אינם מסוגלים לפתור במיוחד את המשימה (2), חוקר הספירה שלנו, והם לא יכולים לגנרליזציה לכמות מחוץ להפצה. אנחנו מציעים מספר הסברים לממצאים האלה: LXMERT (ולמעט ויLBERT 12-in-1) מראה כמה ראיות של שכחת קטסטרופית על המשימה (1). Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input.  בעוד נקודת מכירה של דוגמנים V&L מתאמנים מראש היא היכולת שלהם לפתור משימות מורכבות, הממצאים שלנו מציעים שהבינה של היגיון והיכולות הקרקעית שלהם דורשת חקירות ממוקדות יותר על תופעות ספציפיות.', 'bo': 'ང་ཚོས་བྱ་རིམ་གཉིས་ཀྱི་སྔོན་སྒྲིག་ལྟ་བ་དང་སྐད་རིགས་ཀྱི་ཐབས་ལམ་བཙལ་འདོད་དགོས་པའི་(V&L)རྣམ་པ་དང་མིའི་རྣམ་པ་གཉིས་ནང་གི་རྟོགས་བཤད་ཀྱི་ཆེད་དུ་བཙལ་ཞིབ ང་ཚོས་བྱ་ཚིག་ནང་གི་V&L མིག་གཟུགས་རིས་གསུམ་ཡིན་པའི་དཔེ་གཞི་འདི་ཚོར་ཞིབ་བྱེད་ཀྱི་ཡོད།ViLBERT, ViLBERT 12-in-1 དང་LXMERT ། བྱ་བ་རྣམ་གྲངས ང་ཚོའི་འབྲས་བྱ་ཚིག་མིག་གཟུགས་རྩལ་ལས་ཀ་ཆེན་པོ་༡(1)ཡིན་པ་མངོན་འཆར་ཡོད། ཡིན་ནའང་། V&L མིག་དཔེ་གཞི་ཚོའི་ནང་དུ་གྲངས་ཀྱི་ལས་འགན་བདེ་ཐམ་ཡོད་མིན་འདུག། ང་ཚོས་རྙེད་ཐུབ་འདི་དག་ལ་གསལ་བཤད་མང་པོ་ཞིག་སྤྲོད་ཀྱི་ཡོད། Concerning our results on the counting probe, we find evidence that all models are impacted by dataset bias, and also fail to individuate entities in the visual input. V&L མ་དཔེ་གཞི་ཚོགས་ཀྱི་སྤྲོད་ཐག་ཆེ་ནི་ཁོང་ཚོའི་ཆོས་ཉིད་ཅིག་གིས་མཐུན་རྐྱེན་གྱི་བྱ་རིམ་དང་།'}
{'en': 'How Vision Affects Language : Comparing Masked Self-Attention in Uni-Modal and Multi-Modal Transformer', 'ar': 'كيف تؤثر الرؤية على اللغة: مقارنة الانتباه الذاتي المقنع في المحولات أحادية الوسائط ومتعددة الوسائط', 'pt': 'Como a visão afeta a linguagem: comparando a autoatenção mascarada em transformadores unimodais e multimodais', 'es': 'Cómo afecta la visión al lenguaje: comparación de la autoatención enmascarada en el transformador unimodal y multimodal', 'ja': 'ビジョンが言語にどのように影響するか：ユニモーダルとマルチモーダルトランスフォーマーにおけるマスク付き自己注意力の比較', 'fr': "Comment la vision affecte le langage\xa0: comparaison de l'attention personnelle masquée dans les transformateurs unimodaux et multimodaux", 'hi': 'कैसे दृष्टि भाषा को प्रभावित करती है: यूनि-मोडल और मल्टी-मोडल ट्रांसफॉर्मर में नकाबपोश आत्म-ध्यान की तुलना करना', 'zh': '视何以动言:较单模态多模态变压器中蒙面自视', 'ru': 'Как зрение влияет на язык: сравнение маскированного самовосприятия в одномодальном и многомодальном трансформаторе', 'ga': 'An Dóigh a dtéann Fís i bhFeidhm ar Theanga: Comparáid a dhéanamh ar Fhéinaird Mhascaithe i gClaochladán Aonmhódach agus Ilmhódach', 'ka': 'Name', 'el': 'Πώς η όραση επηρεάζει τη γλώσσα: Σύγκριση της μασκαρισμένης αυτοπροσοχής στον μετασχηματιστή ενιαίου και πολλαπλών μορφών', 'hu': 'Hogyan befolyásolja a látás a nyelvet: maszkos önfigyelem összehasonlítása az unimodális és multimodális transzformátorban', 'it': "Come la visione influisce sul linguaggio: confrontare l'auto-attenzione mascherata nel trasformatore unimodale e multimodale", 'mk': 'Како визијата влијае врз јазикот: Споредување на маскирано себеси внимание во едномодален и мултимодален трансформер', 'ml': 'എങ്ങനെയാണ് കാണാനുള്ള ഭാഷ: മാസ്ക് ചെയ്ത സ്വയം ശ്രദ്ധിക്കുക', 'ms': 'Bagaimana Vision Affects Language: Comparing Masked Self-Attention in Uni-Modal and Multi-Modal Transformer', 'kk': 'Көрініс тілді қалай нәтижесі: Бір модалдық және көп модалдық түрлендірушісінде қалқан өзінің тәртібін салыстыру', 'mt': 'Kif il-Viżjoni taffettwa l-Lingwa: It-tqabbil tal-Attenzjoni Awto-Maskjata fi Trasferiment UniModali u MultiModali', 'lt': 'Kaip vizija daro poveikį kalbai: lyginti maskuotą savarankišką dėmesį vieno ir kelių modulių transformatoriuose', 'mn': 'Хэрхэн харагдах нөлөө үзүүлэлт нь хэл: Нэг-модал, олон-модал шилжүүлэгч дээр маскиг өөрөө анхаарлыг харьцуулах', 'pl': 'Jak wizja wpływa na język: Porównanie maskowanej uwagi w transformatorze unimodalnym i multimodalnym', 'ro': 'Cum viziunea afectează limbajul: Compararea atenției mascate în transformatorul unimodal și multimodal', 'no': 'Korleis synleg påvirkar språk: Samanliknar maskerte selvmerksomhet i unimodal og fleire modular', 'sv': 'Hur syn påverkar språk: Jämför maskerad självuppmärksamhet i unimodal och multimodal transformator', 'sr': 'Kako vizija utječe na jezik: uspoređivanje maskiranog samopouzdanja u jednomodalnom i multimodalnom transformatoru', 'ur': 'نظر کی زبان کس طرح اثر دیتی ہے: Uni-Modal اور Multi-Modal Transformer میں ماسک کی اثر برابری کرتی ہے', 'ta': 'எவ்வாறு பார்வை மொழி: ஒற்றை மோடல் மற்றும் பல- மாற்றி மாற்றியமைப்பில் ஒப்பிடும்', 'so': 'Sidee Vision affects Language: Comparinta Self-Attention in Uni-Modal and Transfer badan Modal', 'si': 'කොහොමද දර්ශනය භාෂාව ප්\u200dරශ්නය කරන්නේ: Uni- මොඩාල් හා ගොඩක්- මොඩාල් වෙනස් කරුණාකරුවේ මාස්ක් ස්වාම්ප', 'vi': 'Cách mà ngôn ngữ nhạy cảm: Đối chiếu với tự giác', 'uz': '@ info', 'bg': 'Как зрението влияе върху езика: Сравняване на маскираното самовнимание в унимодален и мултимодален трансформатор', 'nl': 'Hoe visie invloed heeft op taal: het vergelijken van gemaskerde zelfaandacht in Uni-Modal en Multi-Modal Transformer', 'de': 'Wie Vision Sprache beeinflusst: Vergleich maskierter Selbstaufmerksamkeit in Uni-Modal und Multi-Modal Transformer', 'id': 'Bagaimana Vision Affects Language: Comparing Masked Self-Attention in Uni-Modal and Multi-Modal Transformer', 'hr': 'Kako pogleda utječe na jezik: uspoređivanje maskiranog samopouzdanja u jednomodalnom i multimodalnom transformatoru', 'da': 'Hvordan vision påvirker sproget: Sammenlign maskeret selvopmærksomhed i unimodal og multi-modal transformator', 'sw': 'Namna Vision Inavyoathiri Lugha: Kulinganisha Tafsiri ya kujitegemea katika Modala ya Umoja na Tafsiri ya Kimulti', 'ko': '시각이 언어에 어떻게 영향을 미치는지: 단봉과 다봉 변형금강 중 복면 자기주의의 비교', 'fa': 'Name', 'sq': 'How Vision Affects Language: Comparing Masked Self-Attention in Uni-Modal and Multi-Modal Transformer', 'am': 'ቋንቋ እንዴት ይቻላል: Comparison Self-Attention in Uni-Modal and Multi-Modal Transfer', 'tr': 'Görnöşin Nähili Etkilendirler Dili: Uni-Modal we Multi-Modal Üýtgewçisinde Maskeldirilen Öz Unsurlygy Karşılaştyrmak', 'af': 'Hoe Besigtig Afteken Taal: Vergelyking Maskeerde Selfwaarskuwing in Uni- Modaal en MultiModaal Transformeerder', 'hy': 'Ինչպե՞ս է տեսողությունը ազդում լեզվին: Մաշված ինքնաուշադրության համեմատությունը միամոդալ և բազմամոդալ փոխակերպերով', 'bn': 'কিভাবে ভিশন ভাষা প্রভাবিত হয়েছে: ইউনি- মডেল এবং বহুমোডাল ট্রান্সফার্নার', 'az': "Görüş dili necə etkileyici: Uni-Modal və Multi-Modal Transformer'də Maskilə Öz-Attention", 'bs': 'Kako vizija utječe na jezik: uspoređivanje maskiranog samopouzdanja u jednomodalnom i multimodalnom transformatoru', 'ca': 'How Vision Affects Language: Comparing Masked Self-Attention in Uni-Modal and Multi-Modal Transformer', 'et': 'Kuidas nägemine mõjutab keelt: maskeeritud enesetähelepanu võrdlemine unimodaalses ja multimodaalses transformaatoris', 'cs': 'Jak vidění ovlivňuje jazyk: Porovnání maskované sebepozornosti v unimodálním a multimodálním transformátoru', 'fi': 'Miten näkö vaikuttaa kieleen: Maskitun itsetunnon vertailu unimodaalisessa ja monimodaalisessa muuntajassa', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': '@ action', 'he': 'איך חזון משפיע על שפת: השוואה של תשומת לב עצמית עם מסכה במעבר חד-מודלי ורב-מודלי', 'sk': 'Kako vizija vpliva na jezik: primerjava maskirane samopozornosti v enomodalnem in večmodalnem transformatorju', 'bo': 'མཐོང་ནུས་ཀྱི་སྐད་རིགས་ལ་གནོད་དོན་འདུག：སྤྱད་རུང་བའི་རང་ཉིད་ལ་རྣམ་པ་ཚོའི་ནང་དུ་མཉམ་བསྡུར་བ་ཡིན་པ'}
{'en': 'The problem of interpretation of knowledge learned by multi-head self-attention in transformers has been one of the central questions in ', 'ar': 'كانت مشكلة تفسير المعرفة المكتسبة من خلال الاهتمام الذاتي متعدد الرؤوس في المحولات أحد الأسئلة المركزية في البرمجة اللغوية العصبية. ومع ذلك ، ركز الكثير من العمل بشكل أساسي على النماذج المدربة على المهام أحادية الوسائط ، على سبيل المثال الترجمة الآلية. في هذه الورقة ، قمنا بفحص الانتباه الذاتي المقنع في محول متعدد الوسائط تم تدريبه على مهمة وضع تعليقات على الصورة. على وجه الخصوص ، نقوم باختبار ما إذا كانت الأساليب المتعددة لهدف المهمة تؤثر على أنماط الانتباه المكتسبة. تُظهر تصوراتنا للانتباه الذاتي المقنع أنه (1) يمكنه تعلم المعرفة اللغوية العامة للمدخلات النصية ، و (2) أنماط انتباهه تتضمن مصنوعات من الطريقة المرئية على الرغم من أنها لم تصلها بشكل مباشر مطلقًا. نقارن أنماط انتباه المحولات الخاصة بنا مع الانتباه المقنع في Distilgpt-2 الذي تم اختباره لتوليد نص أحادي الوسائط لتعليقات الصور. استنادًا إلى خرائط أوزان الانتباه المستخرجة ، نجادل بأن الاهتمام الذاتي المقنع في محول التعليق على الصور يبدو أنه يتعزز بالمعرفة الدلالية من الصور ، مما يمثل معلومات مشتركة عن اللغة والرؤية في أنماط الانتباه.', 'pt': 'O problema da interpretação do conhecimento aprendido pela autoatenção multicabeças em transformadores tem sido uma das questões centrais da PNL. No entanto, muito trabalho se concentrou principalmente em modelos treinados para tarefas unimodais, por exemplo. maquina de tradução. Neste artigo, examinamos a autoatenção mascarada em um transformador multimodal treinado para a tarefa de legendagem de imagens. Em particular, testamos se a multimodalidade do objetivo da tarefa afeta os padrões de atenção aprendidos. Nossas visualizações de autoatenção mascarada demonstram que (i) ela pode aprender o conhecimento linguístico geral da entrada textual, e (ii) seus padrões de atenção incorporam artefatos da modalidade visual mesmo que nunca a tenham acessado diretamente. Comparamos os padrões de atenção do nosso transformador com a atenção mascarada no distilgpt-2 testado para geração de texto unimodal de legendas de imagens. Com base nos mapas de pesos de atenção extraídos, argumentamos que a autoatenção mascarada no transformador de legendagem de imagens parece ser aprimorada com o conhecimento semântico das imagens, exemplificando informações conjuntas de linguagem e visão em seus padrões de atenção.', 'es': 'El problema de la interpretación del conocimiento aprendido por la autoatención multicabezal en los transformadores ha sido una de las cuestiones centrales en la PNL. Sin embargo, gran parte del trabajo se centró principalmente en modelos entrenados para tareas unimodales, por ejemplo, la traducción automática. En este artículo, examinamos la autoatención enmascarada en un transformador multimodal entrenado para la tarea de subtitulación de imágenes. En particular, probamos si la multimodalidad del objetivo de la tarea afecta los patrones de atención aprendidos. Nuestras visualizaciones de la autoatención enmascarada demuestran que (i) puede aprender el conocimiento lingüístico general de la entrada textual, y (ii) sus patrones de atención incorporan artefactos de la modalidad visual a pesar de que nunca ha accedido directamente a ellos. Comparamos los patrones de atención de nuestro transformador con la atención enmascarada en distilgpt-2 probados para la generación de texto unimodal de leyendas de imágenes. Basándonos en los mapas de pesos de atención extraídos, argumentamos que la autoatención enmascarada en el transformador de subtítulos de imágenes parece mejorarse con el conocimiento semántico de las imágenes, ejemplificando la información conjunta del lenguaje y la visión en sus patrones de atención.', 'ja': '変圧器における多頭自己注目から学んだ知識の解釈の問題は、NLPの中心的な質問の一つであった。 しかし、多くの作業は主に、機械翻訳などの単一モーダルタスクのために訓練されたモデルに焦点を当てていた。 本稿では、画像キャプション作成のために訓練されたマルチモーダルトランスフォーマーにおけるマスク付き自己注目について検討する。 特に、タスク目標のマルチモーダリティが学習された注意パターンに影響を与えるかどうかをテストします。 マスクされた自己注目の視覚化は、(i)テキスト入力の一般的な言語学的知識を学ぶことができ、(ii)その注目パターンは、直接アクセスしたことがないにもかかわらず、視覚的モダリティから人工物を取り入れていることを示しています。 当社は、画像キャプションの単一モーダルテキスト生成のためにテストされたdistilgpt -2で、変圧器の注目パターンとマスクされた注目パターンを比較します。 抽出された注意重みのマップに基づいて、画像キャプション変換器のマスク付き自己注意は、画像からのセマンティック知識で強化されているようであり、その注意パターンにおける共同言語と視覚の情報を例示していると主張する。', 'zh': '变压器之中,多头自注所学之说,NLP心之一也。 然众务归于单模态,如机器翻译。 本文,我们研究了图像字幕职务训练的多模态变压器中的蒙面自己关注。 试之多模态学之大体也。 吾于蒙面自可视化,(i)其可以学文本输之俗语,而(ii)其注意涵视之人工制品,虽未尝径访也。 变压器与distilgpt-2屏蔽相校,已成标单模态。 盖取意权重之射,以为字幕转换器中蒙面自意似因语义知识增强,于意模中见合语言视息。', 'ru': 'Проблема интерпретации знаний, усвоенных многоголовым самовниманием в трансформаторах, была одним из центральных вопросов в NLP. Однако большая работа была сосредоточена главным образом на моделях, подготовленных для одномодальных задач, например машинного перевода. В этой статье мы исследуем замаскированное самовнимание в мультимодальном трансформаторе, обученном заданию субтитров изображения. В частности, мы проверяем, влияет ли мультимодальность цели задачи на изученные закономерности внимания. Наши визуализации замаскированного самовнимания показывают, что (i) он может изучать общие лингвистические знания текстового ввода и (ii) его паттерны внимания включают артефакты из визуальной модальности, даже если он никогда не получал к ним прямого доступа. Мы сравниваем паттерны внимания нашего трансформатора с замаскированным вниманием в distilgpt-2, протестированном для создания одномодальных текстовых подписей к изображениям. Основываясь на картах извлеченных весов внимания, мы утверждаем, что маскированное самовнимание в трансформаторе субтитров изображения, кажется, усиливается семантическими знаниями из изображений, иллюстрирующими совместную информацию языка и зрения в его паттернах внимания.', 'ga': "Tá an fhadhb a bhaineann le léirmhíniú an eolais a d'fhoghlaim féin-aird ilcheann i gclaochladáin ar cheann de na ceisteanna lárnacha in NLP. Mar sin féin, dhírigh go leor oibre go príomha ar mhúnlaí atá oilte le haghaidh tascanna aonmhódúla, e.g. aistriúchán meaisín. Sa pháipéar seo, scrúdaímid féinaird fholctha i gclaochladán ilmhódach atá oilte le haghaidh fotheidealú íomhánna. Go háirithe, déanaimid tástáil an bhfuil tionchar ag ilmhódúlacht an taiscchuspóra ar na patrúin aire foghlamtha. Léiríonn ár n-amharcléirithe ar fhéinaird faoi cheilt (i) gur féidir leis eolas ginearálta teangeolaíoch a fhoghlaim ar an ionchur téacsúil, agus (ii) go n-ionchorpraíonn a phátrúin aird déantáin ó mhódúlacht amhairc cé nach bhfuair sé rochtain dhíreach riamh air. Déanaimid comparáid idir patrúin aird ár gclaochladáin agus aird chumhdaithe i distilgpt-2 a tástáladh chun téacs aonmhódúil a ghiniúint de fhotheidil íomhá. Bunaithe ar léarscáileanna na n-ualaí aird a bhaintear, áitímid gur cosúil go bhfeabhsaítear féinaird folaithe i gclaochladán fotheidealaithe íomhá le heolas shéimeantach ó íomhánna, ag léiriú comhfhaisnéis teanga-agus-físe ina phatrúin aird.", 'fr': "Le problème de l'interprétation des connaissances acquises par l'auto-attention multi-têtes dans les transformateurs a été l'une des questions centrales de la PNL. Cependant, de nombreux travaux ont principalement porté sur des modèles formés pour des tâches unimodales, par exemple la traduction automatique. Dans cet article, nous examinons l'attention personnelle masquée dans un transformateur multimodal entraîné pour la tâche de sous-titrage d'images. En particulier, nous testons si la multimodalité de l'objectif de la tâche affecte les modèles d'attention appris. Nos visualisations d'auto-attention masquée démontrent que (i) il peut acquérir une connaissance linguistique générale de l'entrée textuelle, et (ii) ses modèles d'attention incorporent des artefacts provenant de la modalité visuelle même s'il n'y a jamais accédé directement. Nous comparons les modèles d'attention de notre transformateur avec l'attention masquée dans distilgpt-2 testé pour la génération de texte unimodal de légendes d'images. Sur la base des cartes des poids d'attention extraits, nous soutenons que l'auto-attention masquée dans le transformateur de sous-titrage d'image semble être améliorée par la connaissance sémantique des images, illustrant les informations conjointes du langage et de la vision dans ses modèles d'attention.", 'hi': 'ट्रांसफॉर्मर में बहु-सिर आत्म-ध्यान द्वारा सीखे गए ज्ञान की व्याख्या की समस्या एनएलपी में केंद्रीय प्रश्नों में से एक रही है। हालांकि, बहुत सारे काम मुख्य रूप से यूनि-मोडल कार्यों के लिए प्रशिक्षित मॉडल पर केंद्रित हैं, उदाहरण के लिए मशीन अनुवाद। इस पेपर में, हम छवि कैप्शनिंग के कार्य के लिए प्रशिक्षित एक बहु-मोडल ट्रांसफार्मर में नकाबपोश आत्म-ध्यान की जांच करते हैं। विशेष रूप से, हम परीक्षण करते हैं कि क्या कार्य उद्देश्य की बहु-रूपरेखा सीखे गए ध्यान पैटर्न को प्रभावित करती है। नकाबपोश आत्म-ध्यान के हमारे विज़ुअलाइज़ेशन से पता चलता है कि (i) यह पाठ्य इनपुट के सामान्य भाषाई ज्ञान को सीख सकता है, और (ii) इसके ध्यान पैटर्न में दृश्य रूपरेखा से कलाकृतियों को शामिल किया गया है, भले ही यह कभी भी इसे सीधे एक्सेस नहीं किया गया हो। हम छवि कैप्शन के uni-modal पाठ पीढ़ी के लिए परीक्षण distilgpt-2 में नकाबपोश ध्यान के साथ हमारे ट्रांसफार्मर के ध्यान पैटर्न की तुलना करते हैं। निकाले गए ध्यान वजन के नक्शे के आधार पर, हम तर्क देते हैं कि छवि कैप्शनिंग ट्रांसफॉर्मर में नकाबपोश आत्म-ध्यान को छवियों से शब्दार्थ ज्ञान के साथ बढ़ाया जाता है, जो इसके ध्यान पैटर्न में संयुक्त भाषा-और-दृष्टि जानकारी का उदाहरण देता है।', 'hu': 'A transzformátorokban a többfejű önfigyelem által tanult tudás értelmezésének problémája volt az NLP egyik központi kérdése. Sok munka azonban elsősorban unimodális feladatokra képzett modellekre összpontosított, például gépi fordításra. Ebben a tanulmányban egy multimodális transzformátorban végzett maszkos önfigyelmet vizsgálunk, amelyet a kép feliratozására készítettek. Különösen azt vizsgáljuk, hogy a feladat célkitűzés multimodalitása befolyásolja-e a tanult figyelemmintákat. A maszkos önfigyelmet vizualizáló vizualizációink azt mutatják, hogy (i) a szövegbevitel általános nyelvtudását képes megtanulni, és (ii) figyelemmintái vizuális modalitásból származó tárgyakat foglalnak magukba, bár soha nem fért hozzá közvetlenül. Transzformátorunk figyelemmintáit összehasonlítjuk az unimodális szöveggenerálásra tesztelt distilgpt-2 álcázott figyelemmel. A kivont figyelemsúlyok térképei alapján azt állítjuk, hogy a feliratozó transzformátorban a maszkos önfigyelmet a képekből származó szemantikai ismeretekkel erősítik, például a közös nyelv-és-látási információkat figyelemmintáiban.', 'el': 'Το πρόβλημα της ερμηνείας της γνώσης που μαθαίνεται από την πολυκεφαλική αυτοπροσοχή στους μετασχηματιστές είναι ένα από τα κεντρικά ερωτήματα στο ΝΛΠ. Ωστόσο, πολλές εργασίες επικεντρώθηκαν κυρίως σε μοντέλα εκπαιδευμένα για εργασίες ενιαίας μορφής, π.χ. μηχανική μετάφραση. Σε αυτή την εργασία, εξετάζουμε την απόκρυφη αυτοπροσοχή σε έναν πολυμορφικό μετασχηματιστή εκπαιδευμένο για το έργο της λεζάντας εικόνας. Ειδικότερα, εξετάζουμε αν η πολυμορφία του στόχου εργασίας επηρεάζει τα μαθημένα πρότυπα προσοχής. Οι απεικονίσεις μας της συγκαλυμμένης αυτοπροσοχής καταδεικνύουν ότι (i) μπορεί να μάθει γενικές γλωσσικές γνώσεις της γραπτής εισόδου, και (ii) τα μοτίβα προσοχής του ενσωματώνουν αντικείμενα από την οπτική τροπολογία παρόλο που δεν έχει ποτέ πρόσβαση απευθείας σε αυτήν. Συγκρίνουμε τα μοτίβα προσοχής του μετασχηματιστή μας με τη συγκεκαλυμμένη προσοχή σε destilgpt-2 δοκιμασμένο για την παραγωγή μονοmodal κειμένου λεζάντες εικόνας. Με βάση τους χάρτες των εξαγόμενων βαρών προσοχής, υποστηρίζουμε ότι η συγκαλυμμένη αυτοπροσοχή στον μετασχηματιστή λεζάντας εικόνας φαίνεται να ενισχύεται με σημασιολογική γνώση από εικόνες, παραδειγματικά από κοινές πληροφορίες γλώσσας και όρασης στα μοτίβα προσοχής.', 'ka': 'უცნობის ინტერპექტირების პრობლემა, რომელიც მრავალთან თავიდარჩენებული განახლოებით განახლოებით განახლოებით განახლოებით განახლოების ერთი კითხვა NLP-ში. მაგრამ ბევრი სამუშაო სამუშაო მუშაოდ მოდელებზე, რომლებიც ერთ-მოდელური სამუშაო, მაგალითან გადაწყვანა. ამ დომენტში, ჩვენ მასკური თავიდარჩენება მრავალური მოდიალური ტრანფიგურაციაში, რომელსაც გამოსახულების საქმებისთვის გავაკეთებთ. განსაკუთრებულად, ჩვენ შევცვალოთ თუ რაოდენობის მიზეზი უმრავალური მოდიალურობა აღმოჩენა მოსწავლილი მონიშნულება. ჩვენი ვიზუალიზაციები, რომელიც მასკური თავიდან აღმოჩენა, დემოსტრაციენ, რომ i) ის შეუძლია აღმოჩენოთ ტექსტულის გეგნების საერთო ლუნგური ცნობიერება, და ii) მისი აღმოჩენების მონაცემების მონაც ჩვენ ჩვენი ტრანფერსტრისტრისტრისტრისტრის მონაცემების მონაცემების შემდეგ მაქსირებული მონაცემებით განსხვავებული-2 ტექსტრისტრისტრისტრისტრის შემდე ჩვენ აღწერეთ, რომ მაქსირებული თავიდარჩენება გამოსახულების ტრანფიგურაციის შესახებ სემონტიკური ცნობილებით გამოსახულებულია, რომელიც ჩვენ გამოსახულებული ენის და ხელსახულების ინფორმაციის შესახებ შესახებ.', 'it': "Il problema dell'interpretazione delle conoscenze apprese dall'auto-attenzione multi-testa nei trasformatori è stato uno dei problemi centrali nella PNL. Tuttavia, molto lavoro si è concentrato principalmente su modelli formati per compiti unimodali, ad esempio la traduzione automatica. In questo articolo esaminiamo l'auto-attenzione mascherata in un trasformatore multimodale addestrato per il compito di didascalia delle immagini. In particolare, verifichiamo se la multimodalità dell'obiettivo del compito influisce sui modelli di attenzione appresi. Le nostre visualizzazioni di auto-attenzione mascherata dimostrano che (i) può imparare la conoscenza linguistica generale dell'input testuale, e (ii) i suoi schemi di attenzione incorporano artefatti dalla modalità visiva, anche se non ha mai avuto accesso diretto ad esso. Confrontiamo i modelli di attenzione del nostro trasformatore con l'attenzione mascherata in distilgpt-2 testato per la generazione di testi unimodali di didascalie di immagini. Sulla base delle mappe dei pesi di attenzione estratti, sosteniamo che l'auto-attenzione mascherata nel trasformatore di didascalia delle immagini sembra essere migliorata con la conoscenza semantica dalle immagini, esemplificando le informazioni congiunte di linguaggio e visione nei suoi schemi di attenzione.", 'kk': 'Қосымшалардың білім түсініктемесінің мәселесі NLP-де бірнеше көпшілікті өзгертушілердің түсініктемесінің негізгі сұрақтарының бірі болды. Бірақ көптеген жұмыс көпшілігі бір модалдық тапсырмалар үшін оқылған моделдерге, мысалы, машинаның аудармасы. Бұл қағазда біз суреттің айдарының тапсырмасы үшін бірнеше модалдық түрлендірушісінде қалқан өзімізді тексереміз. Мысалы, біз тапсырманың көптеген мақсаттың көптеген қасиеттері үйренген нақышты үлгілеріне әсер етпегенін тексереміз. Біздің қалқан өзіміздің көзіміздің көрінісіміз, i) оның мәтіндік кіріс туралы жалпы лингвистикалық білімін үйрене алады. ii) оның қызығу үлгілері көрініс модельдігінен артефакттарды бірге қосылады.  Біз түрлендірушіміздің қызықтық үлгілерін кескіндердің айдарын құру үшін бөлек-2 мәтінді құру үшін қалқалаған қызықтығымен салыстырамыз. Кескінді айдарындағы өзіңіздің өзіңіздің қызықтығының карталарына негізделген кескіндердің айдарындағы өзіңіздің өзіңіздің қызықтығын кескіндерден семантикалық білімімен көтеріп, тіл мен көрініс мәліметін өз', 'ms': 'Masalah interpretasi pengetahuan yang dipelajari oleh perhatian diri berbilang-kepala dalam pengubah telah menjadi salah satu soalan pusat dalam NLP. Namun, banyak kerja terutama fokus pada model yang dilatih untuk tugas uni-modal, contohnya terjemahan mesin. In this paper, we examine masked self-attention in a multi-modal transformer trained for the task of image captioning.  Terutama, kita menguji sama ada multimodaliti objektif tugas mempengaruhi corak perhatian yang dipelajari. Visualisasi kita perhatian-diri bertopeng menunjukkan bahawa (i) ia boleh belajar pengetahuan bahasa umum tentang input teks, dan (ii) corak perhatiannya mengandungi artefakta dari modaliti visual walaupun ia tidak pernah mengaksesnya secara langsung. Kita membandingkan corak perhatian pengubah kita dengan perhatian tertutup dalam distilgpt-2 diuji untuk generasi teks uni modal bagi tajuk imej. Berdasarkan peta berat perhatian ekstrak, kami menyangka perhatian-diri bertutup dalam penukar captioning imej kelihatan diperbaiki dengan pengetahuan semantik dari imej, menggambarkan maklumat bahasa-dan-penglihatan kongsi dalam corak perhatiannya.', 'mk': "Проблемот на интерпретација на знаењето научено од самовниманието на мултиглавите во трансформаторите беше едно од централните прашања во НЛП. Сепак, многу работи се фокусираа главно на модели обучени за унимодални задачи, како што е машинскиот превод. Во овој документ, го испитуваме маскираното себеси внимание во мултимодален трансформатор трениран за задачата на снимање слики. Посебно, тестираме дали мултимодијалноста на целта на задачата влијае на научените образи на внимание. Our visualisations of masked self-attention demonstrate that (i) it can learn general linguistic knowledge of the textual input, and (ii) its attention patterns incorporate artefacts from visual modality even though it has never accessed it directly.  We compare our transformer's attention patterns with masked attention in distilgpt-2 tested for uni-modal text generation of image captions.  Со основа на мапите на извадени тегови на внимание, тврдиме дека маскираното себеси внимание во трансформерот за наслов на слики се чини дека е подобрено со семантично знаење од сликите, примерувајќи заеднички информации за јазик и визија во своите образи на внимание.", 'lt': 'Daugiagalvių savarankiškumo transformatorių žinių aiškinimo problema buvo vienas pagrindinių NLP klausimų. Vis dėlto daug darbo daugiausia buvo skirta modeliams, parengtiems vienmodalinėms užduotims atlikti, pvz., vertimui mašinomis. Šiame dokumente mes tiriame paslėptą savarankišką dėmesį daugiarūšio transformatoriaus, kuris mokomas paveikslėlio įrašymo uždaviniams atlikti. In particular, we test whether the multi-modality of the task objective affects the learned attention patterns.  Mūsų apslėpto savarankiško dėmesio vizualizavimas rodo, kad i) jis gali i šmokti bendrų kalbinių žinių apie tekstinį įvestį ir ii) jo dėmesio modeliai apima vizualinio režimo dirbinius, nors jis niekada tiesiogiai nepasiekė jo. Palyginame savo transformatoriaus dėmesio modelius su paslėptu dėmesiu distilgpt-2, išbandytu vienodo režimo teksto paveikslėlių kūrimui. Remiantis ištrauktų dėmesio svorių žemėlapiais, teigiame, kad paslėptas savęs dėmesys vaizdo pavadinimo transformatoriuje atrodo stiprinamas semantinėmis žiniomis iš vaizdų, pavyzdžiui, bendra kalbos ir regėjimo informacija savo dėmesio modeliuose.', 'no': 'Problemet med tolking av kunnskapen lært av fleire hovud selvmerksomhet i transformerande er ein av dei sentrale spørsmålene i NLP. Men mykje arbeid fokuserte hovudsakelig på modeller trengte for uni modal e oppgåver, f.eks. maskineoversettelse. I denne papira undersøker vi maskerte selvmerksomheten i ein fleire modal transformasjon som treng for oppgåva av biletet. I særskilt tester vi om fleire modaliteten av oppgåvemålet påvirkar dei lærte oppmerksmønstrene. Visualiseringane våre av maskerte selvmerksomhet viser at i) den kan lære generelle lingviske kunnskap om tekstinndata, og ii) oppmerksmønsteret sin inkluderer artefaktar frå visuell modus selv om det aldri har tilgang til den direkte. Vi sammenliknar transformeringsmønsteret med maskerte oppmerksomheten i distilgpt-2 testa for uni modal tekstgenerering av biletittel. Basert på karta med utpakka oppmerksvekt, så argumenterer vi at maskerte selvmerksomhet i biletet er forbetra med semantisk kunnskap frå bilete, som fører til å bruke felles informasjon om språk og vising i oppmerksmønsteret.', 'mt': 'Il-problema tal-interpretazzjoni tal-għarfien li jitgħallem mill-attenzjoni awtonoma b’diversi ras fit-trasformaturi kienet waħda mill-mistoqsijiet ċentrali fil-NLP. Madankollu, ħafna xogħol iffoka prinċipalment fuq mudelli mħarrġa g ħal kompiti unimodali, pereżempju t-traduzzjoni bil-magna. F’dan id-dokument, nagħmlu eżami tal-awtonomija maskrata fi trasformatur multimodali mħarreġ għall-kompitu tal-captioning tal-immaġni. B’mod partikolari, nistestjaw jekk il-multimodalità tal-objettiv tal-kompitu taffettwax ix-xejriet ta’ attenzjoni miksuba. Il-viżwalizzazzjonijiet tagħna ta’ awtonomija maskrata juru li (i) hija tista’ titgħallem l-għarfien lingwistiku ġenerali tal-input testwali, u (ii) ix-xejriet ta’ attenzjoni tagħha jinkorporaw artefatti mill-modalità viżwali anki jekk qatt ma aċċessawha direttament. Aħna nqabblu x-xejriet ta’ attenzjoni tat-trasformatur tagħna ma’ attenzjoni mħassra fid-distilgpt-2 ittestjata għall-ġenerazzjoni tat-test unimodali ta’ intestaturi tal-immaġni. Abbażi tal-mapep tal-piżijiet tal-attenzjoni estratti, aħna jargumentaw li l-awtonomija mxekkla fit-trasformatur tal-intestatura tal-immaġni tidher li tissaħħaħ bl-għarfien semantiku mill-immaġni, billi tiġi eżempjata informazzjoni konġunta dwar il-lingwa u l-viżjoni fix-xejriet tal-attenzjoni tagħha.', 'ml': 'പലതലയിലെ സ്വയം ശ്രദ്ധിച്ച് പഠിച്ച അറിവിന്റെ വിശദീകരിക്കുന്നതിന്റെ പ്രശ്നമാണ് NLP-ലെ സെന്റ്ററിലെ ചോദ്യങ എന്നാലും ഒരുപാട് ജോലി പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു, യൂണി-മോഡല്\u200d ജോലികള്\u200dക്ക് പരിശീലനം നല്\u200dകിയ മോഡലുകളില്\u200d  ഈ പത്രത്തില്\u200d, നമ്മള്\u200d മുഖം മൂടിയ സ്വയം ശ്രദ്ധിക്കുന്നത് ഒരു പല മോഡല്\u200d മാറ്റങ്ങളില്\u200d പരിശീലിക്കുന്നു. ചിത്രം പിടിച പ്രത്യേകിച്ച്, ജോലിയുടെ പല-മോഡിറ്റിയുടെ സ്ഥിതിയില്\u200d പഠിച്ച ശ്രദ്ധയുടെ രീതികളെ ബാധിക്കുമോ എന മുഖപ്പെട്ട സ്വയം ശ്രദ്ധിച്ചുകൊണ്ടിരിക്കുന്ന നമ്മുടെ ദൃഷ്ടാന്തങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു (I) ടെക്സ്കൂള്\u200d ഇന്\u200dപുട്ടിനെപ്പറ്റി സാധാരണ ഭാഷ അറ ഞങ്ങള്\u200d നമ്മുടെ മാറ്റങ്ങളുടെ ശ്രദ്ധ രൂപത്തിന്റെ മാതൃകങ്ങളെ തുല്യമാക്കുന്നു. ചിത്ര തലക്കെട്ടുകളുടെ ഇമേജിന്റെ തലമ പുറത്തെടുക്കപ്പെട്ട ശ്രദ്ധ തൂക്കങ്ങളുടെ മാപ്പുകള്\u200d അടിസ്ഥാനത്താണ് ഞങ്ങള്\u200d വാദിക്കുന്നത് ചിത്രത്തില്\u200d സ്വയം ശ്രദ്ധിച്ചിരിക്കുന്നത് ചിത്രങ്ങള്\u200d മൂ', 'mn': 'Мэдлэгийг олон толгой өөртөө анхаарлаа шилжүүлэгчид сурсан мэдлэгийг тодорхойлдох асуудал нь NLP-ийн төвөгтэй асуултуудын нэг юм. Гэвч маш олон ажлын тухай ихэнхдээ нэг загварын дасгал хөгжүүлэх загварууд дээр төвлөрсөн. Энэ цаасан дээр бид зураг дүрслэх үйл ажилд сургалтын олон моделийн шилжүүлэгч дээр өөрсдийгөө анхаарлаа дүрслэгдсэн. Ялангуяа бид ажлын зорилго дээрх олон загвар нь сурсан анхаарлын загварын нөлөөлдөг эсэхийг шалгаж байна. Бидний өөртөө анхаарлаа дүрслэгдсэн харагдаж байгаа зүйл нь (i) текстурын орлуулалтын ерөнхий хэлний мэдлэг сурах боломжтой. ii) түүний анхаарлаа төвлөрүүлэлт нь харагдаж байгаа артефактуудыг шууд хүргэж чадахгүй ч гэсэн харагдаж байна. Бид өөрчлөгчдийн анхаарлын загварыг харьцуулж байна. Дэлхийн загварын нэг хэлбэрээр шалгалтын анхаарлыг харьцуулж байна. Тайлбарласан анхаарлын жингийн газрын зураг дээр үндсэн, бид зураг зураг дээр анхаарлын төвлөрүүлэгч дээр өөртөө анхаарлын анхаарлыг дүрслэх нь зураг дээрх семантик мэдлэгтэй нэмэгдүүлдэг мэт санагдаж байна. Түүний анхаарлын хэл болон харагда', 'ro': 'Problema interpretării cunoștințelor învățate prin auto-atenția multi-cap în transformatoare a fost una dintre întrebările centrale în PNL. Cu toate acestea, multă muncă s-a concentrat în principal pe modele instruite pentru sarcini unimodale, de exemplu traducerea automată. În această lucrare, examinăm auto-atenția mascată într-un transformator multimodal instruit pentru sarcina de subtitrare a imaginilor. În special, verificăm dacă multimodalitatea obiectivului sarcinii afectează modelele de atenție învățate. Vizualizările noastre de auto-atenție mascată demonstrează că (i) poate învăța cunoștințe lingvistice generale despre intrarea textuală și (ii) modelele sale de atenție includ artefacte din modalitatea vizuală, chiar dacă nu a accesat-o direct. Comparăm modelele de atenție ale transformatorului nostru cu atenția mascată în distilgpt-2 testat pentru generarea de text unimodal de subtitrări de imagine. Pe baza hărților greutăților atenției extrase, susținem că auto-atenția mascată în transformatorul de subtitrare a imaginilor pare să fie îmbunătățită cu cunoștințe semantice din imagini, exemplificând informațiile comune de limbaj și viziune în modelele sale de atenție.', 'sr': 'Problem interpretacije znanja naučenog od višeglavnih samopouzdanja u transformatorima je jedan od centralnih pitanja NLP-a. Međutim, mnogo posla se uglavnom fokusiralo na modele obučene za jednomodne zadatke, npr. prevod mašine. U ovom papiru pregledamo maskiranu samopouzdanje u multimodalnom transformatoru obučenom za zadatak imidža. Posebno, testiramo da li multimodalitet cilja zadatka utječe na naučene obrasce pažnje. Naše vizualizacije maskirane samopouzdanje pokazuju da i) može naučiti opće lingvističko znanje tekstualnog ulaska, i ii) njegove pažnje obrasce uključuju artefakte iz vizuelne modalitate iako ga nikada nije direktno pristupila. Uspoređujemo pažnju našeg transformera sa maskiranom pažnjom u distilgpt-2 testovanom za jedinstvenu modelnu generaciju kapcija slika. Na temelju mape izvlačenih težina pažnje, tvrdimo da maskirana sama pažnja u transformatoru slika izgleda da je poboljšana semantičkim znanjem iz slika, primjenjujući zajedničke informacije o jeziku i viziji u svojim obrascima pažnje.', 'si': 'ගොඩක් හෙඩ් අවධානයෙන් ඉගෙන ගත්ත දැනගන්න ප්\u200dරශ්නය NLP වල ඉන්න ප්\u200dරශ්නයක් තියෙනවා. නමුත්, ගොඩක් වැඩක් විශාල විදිහට ප්\u200dරධාන විදිහට අවධානය කරලා තියෙන්නේ නිර්මාණය සඳහා ප්\u200dරධාන වැඩක්  මේ පත්තරේ අපි පරීක්ෂා කරලා තියෙන්නේ පින්තූර පින්තූර විශේෂණ වැඩක් වෙනුවෙන් ගොඩක් මොඩාල් ප්\u200dරවර්ත විශේෂයෙන්, අපි පරීක්ෂා කරනවා කාර්යාලයේ ගොඩක් ප්\u200dරමාණයක් පරීක්ෂා කරනවා නැද්ද කියලා. අපේ ප්\u200dරදේශ ස්වාම්ප්\u200dරදේශයේ ස්වාම්ප්\u200dරධාන අවධානය පෙන්වන්න පුළුවන් කියලා (i) ඒක පාළුවන්ගේ සාමාන්\u200dය භාෂාවික දැනගන්න පුළුවන් ක අපි පින්තූරයේ පින්තූරයේ පින්තූරයේ පින්තූරයේ පින්තූරයේ පින්තූරයේ අවස්ථාවක් සඳහා අපේ වෙනස් කරුණ පිළිඹින් අවධානය ගැන පිළිබඳින්න පිළිබඳින් ස්වයංග අවධානය කරනවා කියලා අපි පිළිබඳින් පිළිබඳින් පිළිබඳින් සැමැන්තික දන්', 'so': "Dhibaatada turjumidda aqoonta lagu barto iskuulka iskuulka iskuullada kala duduwan ee isbedelka waxaa ka mid ah su'aalaha ugu dhexeeya ee NLP. Si kastaba ha ahaatee shaqo badan ayaa ugu horeyn ku kalsoonaaday tusaalooyin lagu tababariyey shaqooyinka nooca ah, tusaale ahaan turjuma machine. Qoraalkan waxaynu ku baaraynaa iskuul-dhigista iskuulka u bedelka qaabka badan ee loo baray shaqada sawirka. Si gaar ah, waxaynu tijaabinaynaa in noocyada shaqadu ay saameyn ku leedahay noocyada caqliga lagu baray. Our visualisations of masked self-attention demonstrate that (i) it can learn general linguistic knowledge of the textual input, and (ii) its attention patterns incorporate artefacts from visual modality even though it has never accessed it directly.  Waxaynu isbarbardhignaa noocyada isbedelka, aragtideena maskax-2 oo loo tijaabiyey muuqashada qoraalka ee uni-modal ah. Sida lagu saleynayo kartooyinka miisaanka daruuraha la saaro, waxaynu ka sheekaynaa in iskuul-hoosaysiinta sawirka lagu qabto isbedelka is-beddelka looga kordhiyaa aqoonta sawirada, tusaale ahaan macluumaadka luuqada wadajirka ah iyo muuqashada aragtida ee uu ku qorayo qaababka aad u fiiriso.", 'sv': 'Problemet med tolkning av kunskap som lärts av multi-head självuppmärksamhet i transformatorer har varit en av de centrala frågorna i NLP. Mycket arbete fokuserade dock främst på modeller utbildade för unimodala uppgifter, t.ex. maskinöversättning. I denna uppsats undersöker vi maskerad självuppmärksamhet i en multimodal transformator utbildad för uppgiften att bildtexta. I synnerhet testar vi om uppgiftsmålets multimodalitet påverkar de lärda uppmärksamhetsmönstren. Vår visualisering av maskerad självuppmärksamhet visar att (i) den kan lära sig allmän språklig kunskap om textinmatningen, och (ii) dess uppmärksamhetsmönster innefattar artefakter från visuell modalitet trots att den aldrig har kommit åt den direkt. Vi jämför vår transformators uppmärksamhetsmönster med maskerad uppmärksamhet i distilgpt-2 testad för unimodal textgenerering av bildtexter. Baserat på kartor över extraherade uppmärksamhetsvikter hävdar vi att maskerad självuppmärksamhet i bildbildsformator verkar förstärkas med semantisk kunskap från bilder, vilket exemplifierar gemensam språk-och-vision information i sina uppmärksamhetsmönster.', 'ta': 'மாற்றங்களில் பல தலைவர் தன்னுடைய கவனத்தை கற்றுக் கொண்டுள்ள அறிவின் விளக்கம் பிரச்சினை ஆயினும், நிறைய வேலை முக்கியமாக உனக்கு மாதிரி பணிகளுக்கு பயிற்சி செய்யப்பட்ட மாதிரிகள் மீது கவனம் செலுத்தப்பட இந்த காகிதத்தில், நாம் முகத்தை தன்னாலே கவனத்தை பரிசோதிக்கிறோம் பல மாற்றம் பயிற்சிக்கப்பட்டுள்ளது பிம்பத்தை பெறு குறிப்பிட்டு, நாம் சோதிக்க வேண்டும் செயல்பாட்டின் பல-முறைமையில் கற்றப்பட்ட கவனத்தை மாதிரிகளை பாத மூடப்பட்டுள்ள தானே கவனத்தை காண்பிக்கும் பொதுவான மொழியின் அறிவு கற்றுக்கொள்ள முடியும் என்பதை காட்டுகிறது. இது நேரடியாக அணுகாமல் இருந்தாலும் பார்வையி நாங்கள் எங்கள் மாற்றங்களின் கவனத்தின் வடிவங்களை ஒப்பிடுகிறோம் பிம்பத்தின் தலைப்புகளின் மூலம் மூடப்பட்ட கவனத்தை பிரித வெளியேற்றப்பட்ட கவனம் எடைகளின் வரைப்படங்களை அடிப்படையில், நாம் விவாதம் செய்து கொண்டிருக்கிறோம் பிம்பத்தை எடுத்து மாற்றுதல் மூடப்பட்ட தன்னியக்கவனம் மூ', 'pl': 'Jednym z centralnych pytań NLP jest problem interpretacji wiedzy zdobytej przez wielogłowicową uwagę na siebie w transformatorach. Jednak dużo pracy skupiało się głównie na modelach przeszkolonych do zadań unimodalnych, np. tłumaczenia maszynowego. W artykule badamy zamaskowaną uwagę na siebie w transformatorze multimodalnym przeszkolonym do zadania podpisywania obrazów. W szczególności testujemy, czy multimodalność celu zadania wpływa na nauczone wzorce uwagi. Nasze wizualizacje zamaskowanej uwagi na siebie pokazują, że (i) może nauczyć się ogólnej wiedzy językowej o wejściu tekstowym, a (ii) jego wzorce uwagi zawierają artefakty z modalności wizualnej, chociaż nigdy nie uzyskały do niej bezpośredniego dostępu. Porównujemy wzorce uwagi naszego transformatora z zamaskowaną uwagą w destilgpt-2 testowanym do unimodalnego generowania tekstu napisów obrazów. Na podstawie map wyodrębnionych wag uwagi twierdzimy, że zamaskowana uwaga w transformatorze podpisów obrazu wydaje się być wzmocniona o wiedzę semantyczną z obrazów, przykładem wspólnych informacji językowo-wizyjnych w jej wzorcach uwagi.', 'ur': 'زیادہ سرداروں کی تعبیر کی مسئلہ NLP میں ایک مرکزی سوال ہے۔ However, a lot of work mainly focused on models trained for uni modal tasks, e.g. machine translation. اس کاغذ میں، ہم نے ایک مختلف موڈال تغییر کرنے والے میں ماسک کی اپنا توجه جانچ لیا ہے جو تصویر کاپٹینگ کے کام کے لئے آموزش کی گئی ہے. مخصوصا، ہم آزمائش کرتے ہیں کہ کوشش کی بہت سی موڈلیٹ کی تعلیم یاد رکھی ہوئی توجه نمونوں کو اثر دیتی ہے. ہماری تصویریزوں کی اپنی ذات کی تصویریزوں نے دکھائی کہ (i) اس نے textual input کی عمومی زبان علم سکھائی ہے، اور (ii) اس کی توجه النمائی کے مطابق تصویر کے مطابق اگرچہ وہ اسے مستقیم نہیں پہنچ سکے۔ ہم نے اپنے تغییر پھیلانے والے کی توجه پٹرنوں کو تصویر کے کپٹوں کے غیر موڈال ٹیکسٹ نسل کے لئے آزمائش میں ماسک کی توجه سے مقایسہ کیا ہے. اٹھائے جاتے ہیں توجه وزن کے نقشه پر، ہم جھگڑتے ہیں کہ تصاویر کاپٹینگ میں ماسک کی اپنا توجه کرتا ہے کہ تصاویر سے سیمنٹی علم سے زیادہ مزید ہو جاتی ہے، جو زبان اور دیدگی معلومات کے مطابق اس کی توجه کے نمونوں میں مثال کرتی ہے.', 'vi': 'Vấn đề giải thích kiến thức được tập trung bởi các chuyên gia cảm biến trong cơ thể biến đổi đã là một trong những vấn đề chính ở Njala. Tuy nhiên, rất nhiều việc tập trung chủ yếu vào các mẫu được đào tạo cho các công việc vu thời đại, ví dụ dịch vụ máy. Trong tờ giấy này, chúng tôi kiểm tra sự chú ý đeo mặt nạ trong một máy biến đổi đa phương được huấn luyện để tạo ảnh. Chúng tôi đặc biệt kiểm tra xem độ đa chiều của mục tiêu nhiệm vụ có ảnh hưởng tới các mô hình tập trung học. Những hình ảnh che giấu sự chú ý của chúng tôi chứng minh: i) nó có thể học kiến thức ngôn ngữ chung về kết cấu kết cấu, và cả sự chú ý của nó bao gồm các đồ vật từ chế độ hình ảnh mặc dù nó chưa bao giờ tiếp cận trực tiếp với nó. Chúng tôi so s ánh các mô hình chú ý của máy biến đổi với sự chú ý đeo mặt nạ trong phần chưng cất-2 được thử nghiệm để sản xuất văn bản dạng mô-đổi phương. Dựa trên bản đồ các trọng lượng chú ý được chiết xuất, chúng tôi cho rằng sự chú ý đeo mặt nạ trong bộ chuyển hóa hình ảnh có vẻ được tăng cường với kiến thức ngữ pháp từ ảnh, ví dụ thông tin ngôn ngữ và tầm nhìn chung trong mô hình chú ý.', 'uz': "Muallif o'zgarishlarda ko'pchilik o'zgarishlarda o'rganish o'rganish muammolari NLP'ning eng markaziy savollaridan biri. Lekin, ko'pchilik ishni uni modal vazifalar uchun o'rnatilgan modellarga foydalanadi, масалан machine tarjima qilish. Do not translate the keyword between brackets (e. g. ServerName, ServerAdmin, etc.) Bu qogʻozda, biz rasm tashkilotlari uchun bir necha modal o'zgarishni o'rganishga o'rganishni o'rganamiz. Hullas, biz vazifa maqsadining ko'plab usuli o'rganilgan foydalanuvchi modellariga qo'llanib beradi. Bizning o'zimizning o'zingizning ko'rinishimiz ko'rinishimizni ko'rsatishimiz mumkin. Bu ma'lumot matnning o'rganishi umumiy lugʻatni o'rganishi mumkin, va (i) ularning taqvimli shakllarini ko'rinish usulida o'rganish mumkin. Biz o'zgarishning taqdimotimizning shakllarini o'xshash ko'rinishimiz mumkin, uni modal matn tahrirlarining birinchi rasm sarlavhasini o'rganish uchun uning modal matn generalida o'xshash tuzilamiz. Biz tasavvur qiladigan qartasi qo'shilgan rasmlar asosida aytganimiz, o'zgarishni tasavvur qilish rasmlarni o'zgartirish shaklida o'zgarishni o'zgartirish o'zgarishda o'zgarishni o'zgartiradigan rasmlarning semantik ilimlarni oshirish mumkin, masalan bir bir necha tillar va ko'", 'hr': 'Problem interpretacije znanja naučenih od višeglavnih samopouzdanja u transformatorima je jedan od centralnih pitanja NLP-a. Međutim, puno posla se uglavnom fokusiralo na modele obučene za jednomodne zadatke, na primjer prevod strojeva. U ovom papiru pregledamo maskiranu samopouzdanje u multimodalnom transformatoru obučenom za zadatak navedenja slika. Posebno, testiramo da li multimodalitet cilja zadatka utječe na naučene obrasce pažnje. Naše vizualizacije maskirane samopouzdanje pokazuju da i) može naučiti opće lingvističko znanje tekstualnog ulaska, i ii) njegove obrasce pažnje uključuju artefakte iz vizuelne modalitate iako ga nikada nije pristupila direktno. Uspoređujemo obrazac pažnje transformatora maskiranom pažnjom u distilgpt-2 testovanom za unimodalnu generaciju tekstskih kapcija slika. Na temelju mape izvlačenih težina pažnje, tvrdimo da maskirana sama pažnja u transformatoru slika izgleda poboljšana semantičkim znanjem iz slika, primjenjujući zajedničke informacije o jeziku i viziji u svojim obrascima pažnje.', 'bg': 'Проблемът с интерпретацията на знанията, придобити от многоглавото самовнимание в трансформаторите, е един от централните въпроси в НЛП. Въпреки това, много работа се фокусира главно върху модели, обучени за едномодални задачи, например машинен превод. В настоящата статия изследваме маскираното самовнимание в мултимодален трансформатор, обучен за задачата на надпис на изображения. По-специално тестваме дали мултимодалността на целта на задачата засяга моделите на наученото внимание. Нашите визуализации на маскираното самовнимание демонстрират, че (i) той може да научи общи езикови познания за текстовия вход и (ii) неговите модели на внимание включват артефакти от визуалната модалност, въпреки че никога не е имал достъп директно до него. Сравняваме моделите на вниманието на трансформатора с маскираното внимание в дестилгпт-2, тествани за едномодално генериране на текст на надписи на изображения. Въз основа на картите на извлечените тежести на вниманието, ние твърдим, че маскираното самовнимание в трансформатора за надписване на изображения изглежда е подобрено със семантично познание от изображения, като пример за съвместна езикова и зрителна информация в моделите на вниманието му.', 'de': 'Das Problem der Interpretation von Wissen, das durch Mehrköpfige Selbstaufmerksamkeit in Transformatoren gelernt wird, ist eine der zentralen Fragen in NLP. Viel Arbeit konzentrierte sich jedoch hauptsächlich auf Modelle, die für unimodale Aufgaben trainiert wurden, z.B. maschinelle Übersetzung. In diesem Beitrag untersuchen wir maskierte Selbstaufmerksamkeit in einem multimodalen Transformator, der für die Aufgabe der Bildunterschriftung ausgebildet ist. Insbesondere testen wir, ob die Multimodalität des Aufgabenziels die erlernten Aufmerksamkeitsmuster beeinflusst. Unsere Visualisierungen maskierter Selbstaufmerksamkeit zeigen, dass (i) sie allgemeine sprachliche Kenntnisse des textlichen Inputs erlernen kann, und (ii) ihre Aufmerksamkeitsmuster Artefakte aus visueller Modalität enthalten, obwohl sie nie direkt darauf zugegriffen hat. Wir vergleichen die Aufmerksamkeitsmuster unseres Transformators mit maskierter Aufmerksamkeit in destilgpt-2 getestet für unimodale Textgenerierung von Bildunterschriften. Basierend auf den Karten extrahierter Aufmerksamkeitsgewichte argumentieren wir, dass maskierte Selbstaufmerksamkeit im Bildunterschriftstransformator durch semantisches Wissen aus Bildern erweitert wird, was gemeinsame Sprach- und Sehinformationen in ihren Aufmerksamkeitsmustern veranschaulicht.', 'ko': '자연 언어 처리에서 변압기 중의 다두자기주의를 통해 배운 지식의 해석 문제는 줄곧 중심 문제 중의 하나이다.그러나 많은 업무는 주로 단봉 임무를 위한 훈련 모델, 예를 들어 기계 번역에 집중된다.이 논문에서 우리는 다중모드 변환기의 복면 자기주의를 연구했는데 이 변환기는 이미지 자막 임무에 사용되도록 훈련되었다.특히 우리는 임무 목표의 다중모드가 학습의 주의 모드에 영향을 미치는지 테스트한다.우리가 복면 자기주의에 대한 가시화는 (i) 텍스트 입력의 일반 언어학 지식을 배울 수 있고, (ii) 그의 주의 모델은 시각적 형식의 인공 제품을 결합시켜 직접 방문한 적이 없어도 된다.우리는distilgpt-2에서 트랜스포머의 주의 모드와 복면 주의를 비교하여 이미지 제목의 단봉 텍스트 생성을 테스트했다.추출한 주의권중도를 토대로 우리는 이미지 자막 변환기의 복면 자기주의는 이미지의 의미 지식을 통해 강화된 것 같고 그 주의 모델에서 결합 언어와 시각 정보를 구현한 것 같다고 생각한다.', 'nl': 'Het probleem van interpretatie van kennis geleerd door meerkoppige zelfaandacht in transformatoren is een van de centrale vragen in NLP geweest. Veel werk richtte zich echter vooral op modellen die getraind zijn voor unimodale taken, zoals machinevertaling. In dit artikel onderzoeken we gemaskerde zelfaandacht in een multimodale transformator die getraind is voor de taak van beeldbijschriften. In het bijzonder testen we of de multimodaliteit van de taakdoelstelling invloed heeft op de geleerde aandachtspatronen. Onze visualisaties van gemaskerde zelfaandacht tonen aan dat (i) het algemene taalkennis van de tekstuele input kan leren, en (ii) zijn aandachtspatronen artefacten uit visuele modaliteit bevatten, hoewel het er nooit rechtstreeks toegang toe heeft. We vergelijken de aandachtspatronen van onze transformator met gemaskeerde aandacht in destilgpt-2 getest voor unimodale tekstgeneratie van beeldbijschriften. Gebaseerd op de kaarten van geëxtraheerde aandachtsgewichten, stellen we dat gemaskerde zelfaandacht in beeldbijschrifttransformator lijkt te worden verbeterd met semantische kennis uit beelden, wat gezamenlijke taal-en-visie informatie in zijn aandachtspatronen illustreert.', 'da': 'Problemet med fortolkning af viden lært af multi-head selvopmærksomhed i transformatorer har været et af de centrale spørgsmål i NLP. Imidlertid fokuserede meget arbejde hovedsageligt på modeller uddannet til unimodale opgaver, f.eks. maskinoversættelse. I denne artikel undersøger vi maskeret selvopmærksomhed i en multimodal transformer uddannet til opgaven med billedtekster. Især undersøger vi, om opgavemålets multimodalitet påvirker de lærte opmærksomhedsmønstre. Vores visualiseringer af maskeret selvopmærksomhed viser, at (i) den kan lære generel sproglig viden om det tekstlige input, og (ii) dens opmærksomhedsmønstre inkorporerer artefakter fra visuel modalitet, selvom den aldrig har fået adgang til det direkte. Vi sammenligner vores transformers opmærksomhedsmønstre med maskeret opmærksomhed i distilgpt-2 testet for unimodal tekstgenerering af billedtekster. Baseret på kortene over ekstraherede opmærksomhedsvægte hævder vi, at maskeret selvopmærksomhed i billedteksttransformer synes at være forbedret med semantisk viden fra billeder, der eksemplificerer fælles sprog-og-vision information i sine opmærksomhedsmønstre.', 'id': 'Masalah interpretasi pengetahuan yang dipelajari oleh perhatian diri multi-kepala dalam transformer telah menjadi salah satu pertanyaan pusat di NLP. However, a lot of work mainly focused on models trained for uni-modal tasks, e.g. machine translation.  Dalam kertas ini, kami memeriksa perhatian diri tertutup dalam transformator multi modal dilatih untuk tugas captioning gambar. Terutama, kita menguji apakah multimodalitas dari objek tugas mempengaruhi pola perhatian yang dipelajari. Visualisasi kita tentang perhatian-diri tertutup menunjukkan bahwa (i) ia dapat belajar pengetahuan bahasa umum tentang input tekstual, dan (ii) pola perhatiannya mengandung artefakta dari modalitas visual meskipun tidak pernah mengaksesnya secara langsung. Kami membandingkan pola perhatian transformer kami dengan perhatian tertutup dalam distilgpt-2 diuji untuk generasi teks uni modal dari captions gambar. Berdasarkan peta berat perhatian ekstraksi, kami berdebat bahwa perhatian diri tertutup dalam penjelmaan gambar transformator tampaknya diperbaiki dengan pengetahuan semantis dari gambar, mengutamakan informasi bahasa-dan-penglihatan bersama dalam pola perhatiannya.', 'fa': 'مشکل تعبیر علمی که توسط توجه خودسرهای زیادی در تغییردهندگان یاد گرفته است یکی از سوالات مرکزی در NLP است. با این حال، بسیاری از کارها در اصل روی مدلها آموزش داده شده برای وظیفه\u200cهای یک مدل، مثال ترجمه ماشین است. در این کاغذ، ما توجه خود ماسک را در یک تغییردهنده متعدد مدال آموزش داده\u200cایم که برای وظیفه عنوان تصویر آموزش داده شده است تحقیق می\u200cکنیم. مخصوصا، ما امتحان می کنیم که آیا مدل های زیادی هدف کار بر الگوهای توجه یافته تاثیر می دهد. تصویرهای ما از توجه خود ماسک نشان می\u200cدهند که (i) می\u200cتواند دانش زبان\u200cشناسی عمومی درباره ورودی متن یاد بگیرد، و (ii) الگوهای توجه اش هنری\u200cفاکت\u200cها را از حالت دیده\u200cای شامل می\u200cکند، هر چند هرگز مستقیم به آن دسترسی نداشته باشد. ما الگوهای توجه تغییر دهنده\u200cمان را با توجه ماسک\u200cشده در آزمایش\u200cهای مختلف-۲ برای نسل متن متن متناک از عنوان تصویر مقایسه می\u200cکنیم. بر اساس نقشه\u200cهای وزن توجه خارج شده، می\u200cگوییم که توجه خود را در انتقال عنوان تصاویر، به نظر می\u200cرسد با دانش semantic از تصاویر بیشتر شود، که اطلاعات زبان و دیده\u200cهای مشترک در الگوهای توجه خود را نمونه می\u200cدهد.', 'af': "Die probleem van uitlegging van kennis leer deur multikop self-aandag in transformeerders is een van die sentrale vrae in NLP. Maar baie werk het heeltemal gefokus op modele wat opgelei word vir uni modal e opdragte, bv. masjien vertaling. In hierdie papier, ons ondersoek maskeerde self-aandag in 'n multimodaal transformeerder wat opgelei is vir die taak van beeldkapsie. In besonderhede, ons probeer of die multimodaliteit van die taak doel die geleerde aandagpatrone beïnvloor. Ons visualisasies van maskeerde self-aandag vertoon dat (i) dit kan leer algemene lingwisiese kennis van die tekstuele invoer, en (ii) sy aandag patrone inkorpreer artefakte van visuele modaliteit selfs al het dit nooit direk toegang gekom nie. Ons vergelyk ons transformeerder se aandag patrone met maskeerde aandag in distilgpt-2 toets vir unimodaal teks generasie van beeldtitels. Basies op die kaarte van uitgepakte aandagsvegte, het ons gespreek dat self-aandag in beeldkapitering transformeerder verskyn is verbeter met semantiese kennis van beelde, voorbeeld van joint taal-en-visie inligting in sy aandag patrone.", 'sq': 'Problemi i interpretimit të njohurive të mësuara nga vetëvëmendja me shumë koka në transformuesit ka qenë një nga pyetjet qendrore në NLP. Megjithatë, shumë punë u përqëndrua kryesisht në modelet e trajnuara për detyra unimodale, për shembull përkthimi makinash. Në këtë letër, ne shqyrtojmë vetëvëmendjen e maskuar në një transformues multi modal të trajnuar për detyrën e titullimit të imazheve. Në veçanti, ne testojmë nëse shumëmodaliteti i objektivit të detyrës ndikon në modelet e vëmendjes së mësuar. Vizualizimet tona të vetëvëmendjes së maskuar demonstrojnë se (i) ajo mund të mësojë njohuri të përgjithshme gjuhësore të hyrjes tekstuale dhe (ii) modelet e vëmendjes së saj përfshijnë artefakte nga modaliteti vizual edhe pse nuk ka hyrë kurrë drejtpërdrejt në të. Ne krahasojmë modelet e vëmendjes s ë transformuesit tonë me vëmendjen e maskuar në distilgpt-2 testuar për gjenerimin e tekstit uni modal të titujve të imazhit. Bazuar në hartat e peshëve të vëmendjes së nxjerrë, argumentojmë se vetëvëmendja e maskuar në transformuesin e titullimit të imazheve duket të përmirësohet me njohuri semantike nga imazhet, duke shembulluar informacionin e përbashkët gjuhë-dhe-vizion në modelet e vëmendjes së saj.', 'am': 'በብዙ ራስ-ራሱ የራሱን ትኩረት የተማረ የእውቀትን ትርጓሜ ጉዳይ በNLP የመካከለኛ ጥያቄዎች አንዱ ነው፡፡ ነገር ግን ብዙ ስራ በኩል ለዩናዊ-ሞዴል ስራዎችን በሚያስተማሩበት ዓይነቶች ላይ ትኩረት ነው፡፡ በዚህ ፕሮግራም ለምስል ማሳየት ስርዓት የተማረከውን በብዙ-modal ለውጦች ላይ የራሳቸውን ትኩረት እንሞክራለን፡፡ በተለይም፣ የስራ አካባቢ ብዙዎችን የልማት ትኩረት ሥርዓት የሚያደርስባቸው እንደሆነ እንሞክራለን፡፡ የራሳችንን ራሳችንን አሳይ (እኔ) የጽሑፍ ውስጥ የቋንቋ ቋንቋን ማወቅ ይችላል (i) እና (i) ምሳሌዎቹን ከዓይነት መልክት ምንም እንኳ ቀጥተኛ ምንም እንኳ ሳይገኝ አካባቢዎችን እንዲያስተካክሉ ያሳያል፡፡ የምስል ትውልድ ለዩንዶል የጽሑፍ ትውልድ ምስል ትውልድ ለመፈተን እናሳያታለን፡፡ በጥያቄ ሚዛኖችን ላይ በሚያሳየው ካርታ ላይ፣ የራሱን ትኩረት በማሳየት ምስል ለውጦችን በማሳየት እውቀት ከምስሎች በኩል እውቀት ማድረግ ይመስላል፡፡', 'sw': 'Tatizo la tafsiri ya maarifa yanayojifunza na kujitegemea kwa watu wengi katika mabadiliko yamekuwa moja ya maswali ya msingi nchini NLP. Hata hivyo, kazi nyingi imejikita zaidi kwenye mifano inayofundishwa kwa ajili ya kazi za kiutamaduni, kwa mfano utafsiri wa mashine. Katika karatasi hii, tunachunguza kujitegemea katika mabadiliko ya namna mbalimbali yaliyofundishwa kwa kazi ya kuchukua picha. hasa, tunajaribu kama utaratibu wa aina mbalimbali wa malengo ya kazi yanaathiri mitindo ya kujifunza. Maonyesho yetu ya kujitegemea yanaonyesha kuwa (mimi) inaweza kujifunza maarifa ya lugha ya lugha ya ujumla wa input wa maandishi, na (i i) mitindo yake ya kusikiliza yanajumuisha viumbe kutoka kwa hali ya kuona ingawa haijawahi kuifikia moja kwa moja. Tunawalinganisha mitindo ya mabadiliko yetu yenye mwangalizi uliofanywa na macho yaliyotibiwa kwenye tofauti-2 iliyojaribiwa kwa ajili ya kizazi cha maandishi yasiyo na ujumbe wa picha. Based on the maps of extracted attention weights, we argue that masked self-attention in image captioning transformer seems to be enhanced with semantic knowledge from images, exemplifying joint language-and-vision information in its attention patterns.', 'tr': "Birnäçe kelläp özüne üns berýän bilim terjimesiniň meselesi NLP'da esasy soraglarynyň biridir. Ýöne köp işe adatça modal işi üçin bilinmeli nusgalar, meselâ maşynyň terjime edilmesi üçin bilinmeli nusgalara üns berildi. Bu kagyzda, surat käpşenleriniň görevi üçin bilinmeli bir multi modal transformatçyda maskara özüniň ünsüni bardyk. Aýratyn bolsa, biz zadyň birnäçe modalitet öwrenmegi nusgalaryna etmäge synanyşýarys. Bizim maskele özine dikkat eden görsellerimiz (i) tekst girişinin umumiy dilli bilgileri öwrenip biler ve (ii) üns örneklerini görsel modalitetden artefaktlary düzenleyebilir. Bu şekilde hiç haçan edilmedi. Biz transformatörümizin dikkatini daşkınlaştırıp, modal olmayan metin kelimeleri için test edilen maske dikkati ile karşılaştırıyoruz. Çaklanyş üns çekilýän pikirleriniň görkezilişinde, suratlarda özüne üns berýän pikirleri görkezilýän görkezilişi bilen semantik bilen gowylaşdyrylýar ýaly görünýär, bilen dil-we-aýdym maglumatyny diňleýän diýip pikir edýäris.", 'hy': 'Բազմագլխավոր ինքնաուշադրության միջոցով սովորված գիտելիքների ինտերպրենցիայի խնդիրը վերափոխողներում գլխավոր հարցերից մեկն էր ՆԼՊ-ում: Այնուամենայնիվ, շատ աշխատանք հիմնականում կենտրոնացել է միամոդալ խնդիրների համար վարժեցված մոդելների վրա, օրինակ մեքենայի թարգմանման համար: Այս թղթի մեջ մենք ուսումնասիրում ենք ծածկված ինքնաուշադրությունը մի բազմամոդալ վերափոխողի մեջ, ով պատրաստված է պատկերի վերնագրման խնդրի համար: Մենք հատկապես ստուգում ենք, թե արդյոք խնդրի բազմակերպությունը ազդում է ուսումնասիրելի ուշադրության կաղապարներին: Մեր ծածկված ինքնաուշադրության տեսողական պատկերացումները ցույց են տալիս, որ i) այն կարող է սովորել գլխավոր լեզվաբանական գիտելիքներ տեքստալ ինֆորմացիայի մասին, և 2) դրա ուշադրության կաղապարները ներառում են տեսողական մոդելներից արտեֆեկտներ, չնայած որ երբեք այն անմիջապես չի Մենք համեմատում ենք մեր վերափոխողի ուշադրության կաղապարները դիստիլգpt-2 մեջ ծածկված ուշադրության հետ, որոնք ստուգել են պատկերի վերնագրերի միամոդալ տեքստի ստեղծման համար: Հիմնված ուշադրության քարտեզների վրա, մենք փաստարկում ենք, որ պատկերի վերնագրման վերաբերյալ ձևափոխողի պատկերացման մեջ ծածկված ինքնաուշադրությունը կարծես բարելավված լինի պատկերներից սեմանտիկ գիտելիքներով, օրինակելով միասին լեզվի և տեսողության ինֆորմացիան իր ուշադրության կա', 'az': "NLP'deki çoxlu başlıq təsirlərindən öyrəndiyi bilgi təfsil etməsi problemi NLP'də mərkəzi suallardan biridir. Ancaq çox işlər çox modal işlər üçün təhsil edilmiş modellərə, məsələn maşın təhsil edilməsi üçün təhsil edilmişdir. Bu kağıtda, görüntü başlığı üçün təhsil edilən çoxlu modal transformatördə maski özünü təhsil edirik. Özellikle, biz işlərin çoxlu modaliyyətinin öyrəndiyi təsirlərin müxtəlif təsirlərinə müvafiq edirik. Bizim gizli özünün dikkatimizin vizualizasyonları göstərir ki, i) textual girişi barəsində ünvanlı dil bilgi öyrənə bilər, ii) onun dikkati örtükləri görsel modaliyyətindən artefaktları daxil edə bilər. Halbuki o, heç vaxt doğrudan əlavə edilməmişdir. Biz transformatörümüzün dikkati nöqtələrini bir modal mətn nöqtəsi üçün müxtəlif-2 məlumat nöqtəs in ə s ınamaq üçün maski dikkati ilə qarşılaşdırırıq. Gözlük ağırlığının haritalarına baxmayaraq, görüntü kapasiyası transformatöründə özünün dikkatini gizlətmiş görünür ki, görüntülərdən semantik bilgi ilə daha yaxınlaşdırılır, dil və görünür məlumatlarını öz dikkati örnəklərində örnərdik.", 'bs': 'Problem interpretacije znanja naučenog od višeglavnih samopouzdanja u transformatorima je jedan od centralnih pitanja NLP-a. Međutim, mnogo posla se uglavnom fokusiralo na modele obučene za unimodalne zadatke, npr. prevod mašine. U ovom papiru, pregledamo maskiranu samopouzdanje u multimodalnom transformatoru obučenom za zadatak navedenja slika. Posebno, testiramo da li multimodalitet cilja zadatka utječe na naučene obrasce pažnje. Naše vizualizacije maskirane samopouzdanje pokazuju da i) može naučiti opće lingvističko znanje tekstualnog ulaska, i ii) njegove pažnje obrasce uključuju artefakte iz vizuelne modalitate iako ga nikada nije direktno pristupila. Uspoređujemo obrazac pažnje transformera sa maskiranom pažnjom u distilgpt-2 testovanom za unimodalnu generaciju teksta kapcija slika. Na temelju mape izvlačenih težina pažnje, tvrdimo da maskirana sama pažnja u transformatoru slika izgleda da je poboljšana semantičkim znanjem iz slika, primjenjujući zajedničke informacije o jeziku i viziji u svojim obrascima pažnje.', 'ca': "El problema de l'interpretació del coneixement aprengut per l'autoatenció multicapa dels transformadors ha estat una de les preguntes centrals del NLP. Però molta feina es va centrar principalment en models entrenats per tasques unimodals, per exemple traducció màquina. En aquest paper examinem l'auto-atenció mascarada en un transformador multi modal entrenat per la tasca de capturació d'imatges. En particular, examinem si la multimodalitat de l'objectiu de la tasca afecta als patrons d'atenció aprenguts. Les nostres visualitzacions d'autoatenció mascarada demostren que (i) pot aprendre coneixement lingüístic general de la entrada textual, i (ii) els seus patrons d'atenció incorporan artefactes de la modalitat visual encara que mai l'ha accedit directament. Comparem els patrons d'atenció del nostre transformador amb l'atenció mascarada en distilgpt-2 testat per a la generació de textos uni modal s de títulos d'imatge. Sobre la base dels mapes de pes d'atenció extraïts, argumentem que l'autoatenció mascarada en el transformador de captionització d'imatges sembla ser millorada amb coneixement semàntic de les imatges, exemplificant la informació conjunta de llenguatge i visió en els patrons d'atenció.", 'et': 'Mitmepealise enesetähelepanu abil transformaatorites omandatud teadmiste tõlgendamise probleem on olnud NLP üks keskseid küsimusi. Kuid palju tööd keskenduti peamiselt mudelitele, mis on koolitatud ühe modaalse ülesande jaoks, nt masintõlke jaoks. Käesolevas töös uurime maskeeritud enesetähelepanu multimodaalses trafos, mis on koolitatud piltide pildistamise ülesandeks. Eelkõige testime, kas ülesande eesmärgi multimodaalsus mõjutab õppitud tähelepanu mustreid. Meie maskeeritud enesetähelepanu visualiseerimine näitab, et i) ta suudab õppida üldisi keelelisi teadmisi tekstisisendist ja ii) tema tähelepanumustrid sisaldavad visuaalse modaalsuse esemeid, kuigi ta ei ole sellele otse ligi pääsenud. Me võrdleme meie trafo tähelepanu mustreid maskeeritud tähelepanuga distilgpt-2-s, mida testitakse piltide pealdiste ühemoodaalse teksti genereerimiseks. Tuginedes väljatõmmatud tähelepanu kaalude kaartidele, väidame, et maskeeritud enesetähelepanu piltide pealdiste transformaatoris näib olevat täiustatud semantiliste teadmistega piltidest, näidates ühist keele- ja nägemisteavet tähelepanu mustrites.', 'cs': 'Problém interpretace poznatků získaných vícehlavovou sebepozorností v transformátorech je jednou z hlavních otázek NLP. Mnoho práce se však zaměřilo především na modely trénované pro unimodální úkoly, např. strojový překlad. V tomto článku zkoumáme maskovanou sebepozornost v multimodálním transformátoru vycvičeném pro úlohu popisků obrazu. Zejména testujeme, zda multimodalita cíle úkolu ovlivňuje naučené vzorce pozornosti. Naše vizualizace maskované sebepozornosti ukazují, že (i) se může naučit obecné jazykové znalosti textového vstupu a (ii) jeho vzorce pozornosti obsahují artefakty z vizuální modality, i když k němu nikdy přímo nepřistupovala. Porovnáváme vzory pozornosti transformátoru s maskovanou pozorností v destilgpt-2 testovaném pro unimodální generování textových titulků. Na základě map extrahovaných závaží pozornosti argumentujeme, že maskovaná sebepozornost v transformátoru popisků obrazu se zdá být rozšířena o sémantické znalosti z obrazů, což ukazuje společné jazykovo-vizní informace v jejich vzorcích pozornosti.', 'bn': 'বিনিময় পরিবর্তনের মধ্যে জ্ঞানের ব্যাখ্যা হচ্ছে এনএলপির কেন্দ্রীয় প্রশ্ন। তবে ইউনিমোডাল কাজের জন্য প্রশিক্ষিত মডেলের উপর অনেক কাজ, যেমন মেশিন অনুবাদ। এই কাগজটিতে আমরা মুখোশের আত্মমনোযোগ পরীক্ষা করি একটি বহুমোডাল পরিবর্তনের প্রশিক্ষণ প্রদান করা হয়েছে ছবির কাজের জন্য। বিশেষ করে, আমরা পরীক্ষা করি কাজের উদ্দেশ্যের বহুমাত্রার মাধ্যমে শিক্ষিত মনোযোগ প্রতিক্রিয়া কি প্রভাব ফে আমাদের মুখোশিত আত্মমনোযোগের দৃষ্টিভঙ্গি দেখাচ্ছে যে (আমি) এটি টেক্সটুয়াল ইনপুটের সাধারণ ভাষার জ্ঞান শিখতে পারে এবং (ই) এর মনোযোগ প্রদর্শনের মাধ্যমে দৃশ্যম আমরা আমাদের পরিবর্তনের মনোযোগ প্যাটারের তুলনা করি ছবির শিরোনামের প্রজন্ম ইউনিমোডাল টেক্সট প্রজন্মের জন্য মুখোশিত মনোযো বের করে আকর্ষণের মানচিত্রের ভিত্তিতে আমরা যুক্তি দিচ্ছি যে ছবির পরিবর্তনের ক্ষেত্রে আত্মমনোযোগ আকর্ষণের মুখোশ বাড়িয়ে দিয়েছে, ছবির সাথে সামান্যিক জ্', 'fi': 'Monipäisen itsehuomion avulla muuntajissa opitun tiedon tulkintaongelma on ollut yksi NLP:n keskeisistä kysymyksistä. Työssä keskityttiin kuitenkin pääasiassa multimodaalisiin tehtäviin koulutettuihin malleihin, kuten konekäännöksiin. Tässä työssä tarkastelemme naamioitua itsehuomiota multimodaalisessa muuntajassa, joka on koulutettu kuvatekstitykseen. Testaamme erityisesti, vaikuttaako tehtävätavoitteen multimodaalisuus opittuihin huomiomalleihin. Piilotetun itsetunnon visualisoinnit osoittavat, että (i) se voi oppia yleistä kielellistä tietoa tekstisyötteestä ja (ii) sen huomiokuviot sisältävät visuaalisen modaalisuuden esineitä, vaikka se ei ole koskaan käyttänyt sitä suoraan. Vertaamme muuntajan huomiokuvioita maskittuun huomioon distilgpt-2:ssa, joka on testattu kuvatekstitysten monomodaalista tuottamista varten. Väitämme poimittujen huomiopainojen karttojen perusteella, että kuvatekstityksen muuntajan naamioitua itsehuomiota tehostetaan kuvien semanttisella tiedolla, joka havainnollistaa yhteistä kieli- ja näkötietoa sen huomiomalleissa.', 'jv': 'Rasané kanggo mbukakipun ajeng-ajeng politenessoffpolite"), and when there is a change ("assertivepoliteness Nang mapir iki, kita isih bantuan sami-tenan neng bantuan multi modal transformer sing ditambah kanggo nggawe barang nggawe aturan ngomong Awakdhéwé éntuk karo pergambar sing sampeyan mraké nggambar ngono (i) iso nggambar barang langgambar barang nggambar ingkang teks, lan (i i) iso nggambar terakhi artiteks ning modalité sing bisa ngono kuwi ora bisa dianggo ndelok. Awak dhéwé nggawe transformer tentang kanggo barang sampek karo aturan gambar neng sampek diwujer-2 ujian kanggo kelangan uni-modal tekan kelangan surat Ngawe jenis mapaké karbot gampang pakan nggunaké aturan sing nggawe, awak dhéwé nyimpen winih karo nggawe surat pirsak neng mapaké surat, lak sematik dhéwé uga ngono larang sematik lan alam kuwi nggawe gerakan sampek tarjamahan lan alam-winih sing berarti.', 'sk': 'Eno izmed osrednjih vprašanj v NLP je problem interpretacije znanja, pridobljenega z večglavno samopozornostjo v transformatorjih. Vendar je bilo veliko dela osredotočenega predvsem na modele, usposobljene za enomodalne naloge, npr. strojno prevajanje. V prispevku preučujemo maskirano samopozornost v multimodalnem transformatorju, usposobljenem za nalogo napisovanja slik. Predvsem testiramo, ali multimodalnost cilja naloge vpliva na učene vzorce pozornosti. Naše vizualizacije maskirane samopozornosti kažejo, da (i) se lahko nauči splošnega jezikovnega znanja besedilnega vnosa in (ii) njegovi vzorci pozornosti vključujejo artefakte iz vizualne modalnosti, čeprav do nje nikoli ni neposredno dostopal. Primerjamo vzorce pozornosti našega transformatorja z maskirano pozornostjo v distilgpt-2, testiranem za enomodalno generiranje besedila podobnih napisov. Na podlagi zemljevidov izvlečenih uteži pozornosti trdimo, da se zdi, da je maskirana samopozornost v transformatorju podobnih napisov izboljšana s semantičnim znanjem iz slik, kar ponazarja skupne jezikovne in vizijske informacije v svojih vzorcih pozornosti.', 'ha': "Tayyar da fassarar fassarar ilmi wanda aka sanar da shi daga masu nau'in-jiɓintar mutane da ke cikin transformation sun kasance ɗayan maswali na tsakiya a NLP. Kayya, masu yawa na aikin aiki yana fokus a kan misãlai wanda aka sanar wa aikin uni-modal, misali fassarar mashine. Daga wannan takardan, Munã jarraba masu rufe kanka a cikin wata shifo mai yawa-modal wanda aka yi wa aikin tsarin zane. Kuma a cikin ƙayyade, Munã jarraba ko shirin-multi-nau'in aikin zai yi amfani da tsarin muhimman aikin da aka sani. FarayayinMu da aka rufe kansa na nuna (na iya iya sanar da littãfin da aka shigar littãfin, kuma (i i) misalin muhimmanci na shigar da masu tsari daga tsarin gani, kuma kõ dã ba ta isa bayani ba. Tuna samfan masu canza masu kallo da aka kiyaye zura cikin zane-2 wanda aka jarraba wa sunayen zane na uni-modal. Base a kan mapardan masu nau'i na saurari, Munã yi musu jãyayya cẽwa, an rufe fuskar rãyukansu cikin zanen da za'a fange transformer da surori, kamar an ƙara shi da sanin na semanti daga zane, kuma don ya sami tsarin zane-zane da zane-zane na haɗi cikin zane-zane-zane.", 'he': 'הבעיה של הפרשנות של הידע שנלמדה על ידי תשומת לב עצמית רבה-ראשים במעברים הייתה אחת השאלות המרכזיות של NLP. עם זאת, הרבה עבודה התמקדה בעיקר בדוגמנים מאומנים למשימות חד-מודאליות, למשל תרגום מכונות. בעיתון הזה, אנחנו בודקים תשומת לב עצמית מסוכנת במעבר מודיאלי רב מאומן למשימה של ציור תמונות. במיוחד, אנחנו בודקים אם המולטומודליות של מטרה המשימה משפיעה על דפוסי תשומת לב למדו. חיזויים שלנו של תשומת לב עצמית מסוכנת מראים כי (i) הוא יכול ללמוד ידע שפתי כללי של הכניסה הטקסטלית, ו (ii) דפוסי תשומת לבו מכילים עובדות ממודליות ויזואלית למרות שהוא מעולם לא הגיע אליה ישירות. אנחנו משוותים את דפוסי תשומת לבו של המעבר שלנו עם תשומת לב מסוכנת בדיסילגפט-2 שנבחנה לדור טקסט חד-מודאלי של תוארי תמונות. בהתבסס על המפות של משקלי תשומת לב מווצאים, אנו טוענים כי תשומת לב עצמית מסוכנת במעבר ציור תמונות נראית משותפת עם ידע סמנטי מהתמונות, להדגים מידע שפה וחזונה משותף בתבנות תשומת לבו.', 'bo': 'དབྱིབས་སྒྱུར་གྱི་གནས་ཚུལ་གྱི་གསལ་བཤད་ཀྱི་དཀའ་ངལ་ཞིག་ནི་དབྱིབས་ཡོད་པའི་སྒེར་གྱི་རང་ཉིད་ཀྱི་གནད་དོན་དག་ཚད་NLP ནང་ ཡིན་ནའང་། ལས་ཀ་ཆེ་ཤོས་རྣམས་ལ་སྨན་པའི་མིག་དཔེ་གཏོང་གི་ནང་དུ་བློ་གཏོང་བ་རེད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་གདོང་རིས་གཞུང་གི་རང་ཉིད་ཀྱི་གནད་དོན་ཡོད་པའི་ལྟ་བུ་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དམིགས་ཡུལ་གྱི་ཐབས་ལམ་སྣ་མང་ཆོས་ཡོད་པ་དེ་མཐོང་གི་གཟུགས་རིས་ལ་གདོང་བསྐྱོད་ཡོད་མིན་ནམ། ང་ཚོའི་མཐོང་སྣང་དང་རང་ཉིད་ཀྱི་གནད་དོན་ཡུལ་གྱི་མཐོང་སྣང་གསལ་བཤད་ནི། (i) ང་ཚོས་རང་གི་བཟོ་བཅོས་པའི་གཟུགས་རིས་ལ་གདོང་རིས་འདྲ་བ་དང་མི་འདྲ་བརྟན་པའི་བརྗོད་རྟགས་ལ་མཐུན་པ། Based on the maps of extracted attention weights, we argue that masked self-attention in image captioning transformer seems to be enhanced with semantic knowledge from images, exemplifying joint language-and-vision information in its attention patterns.'}
{'en': 'EMISSOR : A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References', 'pt': 'EMISSOR: Uma plataforma para capturar interações multimodais como memórias episódicas e interpretações com referências ontológicas baseadas em cenários situados', 'ar': 'EMISSOR: منصة لالتقاط التفاعلات متعددة الوسائط كذكريات عرضية وتفسيرات باستخدام المراجع الأنطولوجية القائمة على السيناريو', 'es': 'EMISSOR: Una plataforma para capturar interacciones multimodales como memorias e interpretaciones episódicas con referencias ontológicas basadas en escenarios situados', 'fr': "EMISSOR\xa0: Une plateforme pour capturer les interactions multimodales sous forme de mémoires épisodiques et d'interprétations avec des références ontologiques basées sur des scénarios situés", 'zh': 'EMISSOR曰:一台者,所以多获模态交以为记解,有定位之体论', 'hi': 'EMISSOR: स्थित परिदृश्य-आधारित Ontological संदर्भों के साथ एपिसोडिक यादें और व्याख्याओं के रूप में मल्टीमॉडल इंटरैक्शन को कैप्चर करने के लिए एक मंच', 'ja': 'EMISSOR ： Episodic Memories and Interpretations with Situated Scenario - based Ontological Referencesとしてマルチモーダルインタラクションをキャプチャするためのプラットフォーム', 'ru': 'ЭМИССОР: Платформа для сбора мультимодальных взаимодействий в виде эпизодических воспоминаний и интерпретаций с онтологическими ссылками на основе ситуационного сценария', 'ga': 'EMISSOR: Ardán chun idirghníomhaíochtaí ilmhódacha a ghabháil mar Chuimhneacháin Eipeasóideacha agus Léirmhínithe le Tagairtí Onteolaíocha Bunaithe ar Chásanna', 'hu': 'EMISSOR: A multimodális interakciók epizódikus emlékekként és értelmezésekként történő rögzítésére szolgáló platform helyezett forgatókönyv alapú ontológiai referenciákkal', 'el': 'Μια πλατφόρμα καταγραφής των πολυπροπικών αλληλεπιδράσεων ως Επισκοπικές Μνήμες και Ερμηνείες με Εντοπισμένες Οντολογικές Αναφορές', 'kk': 'EMISSOR: Бірнекmodal интерфейстерді эписодикалық жады және онтологикалық сілтемелер ретінде алу платформа', 'lt': 'EMISSOR: daugiarūšio pobūdžio sąveikos kaip epizodinių atmintinių ir aiškinimų su situacijomis grindžiamomis Ontologinėmis nuorodomis nustatymo platforma', 'ka': 'EMISSOR: მულტიმოდიალური ინტერფექციების შესახებ როგორც ეპიციოდიური მეხსიერები და ინტერფექციები სენარიოდან განტოლოგიური რეფერენციებით', 'it': 'EMISSOR: Una piattaforma per catturare interazioni multimodali come memorie episodiche e interpretazioni con riferimenti ontologici basati su scenari localizzati', 'ms': 'EMISSOR: Platform untuk menangkap interaksi multimodal sebagai Memori Episodi dan Interpretasi dengan Rujukan Ontologi Berasas Skenario', 'ml': 'EMISSOR: എപ്പിസോഡിക് മെമ്മറികളും പരിഭാഷണങ്ങളും പിടികൂടുന്നതിനുള്ള ഒരു പ്ലാറ്റ്ഫോമാണ് സ്കെയിനാറിയ സ്കേനാരിയയുടെ അടിസ്ഥാനമായ ഓണ്\u200d', 'mn': 'EMISSOR: Олон моделийн харилцааны аль нэг платформ эпиsodic Memory and interpretations with Situated Scenario-based Ontological References гэх мэт', 'mt': 'EMISSOR: Pjattaforma għall-qbid ta’ interazzjonijiet multimodali bħala Memorji Episodiċi u Interpretazzjonijiet b’Referenzi Ontoloġiċi Sitwati bbażati fuq ix-Xenarju', 'mk': 'ЕМИСОР: Платформа за заземање мултимодални интеракции како епизодички сеќавања и интерпретации со лоцирани онтологички референции базирани на сценарио', 'pl': 'EMISSOR: Platforma do rejestrowania interakcji multimodalnych jako wspomnień epizodycznych i interpretacji z odniesieniami ontologicznymi opartymi na scenariuszach lokalnych', 'no': 'EMISSOR: Eit plattform for å henta fleire modal interaksjonar som episodiske minne og interpretasjonar med sitert scenariobasert ontologiske referanser', 'ro': 'EMISSOR: O platformă pentru captarea interacțiunilor multimodale ca amintiri și interpretări episodice cu referințe ontologice situate bazate pe scenarii', 'sr': 'EMISSOR: Platforma za uhvativanje multimodalnih interakcija kao episodičke sjećanja i razmišljanja sa Situated scenarijskim ontološkim referencijama', 'so': 'EMISSOR: Qoraalka qabsashada Interactions badan sida Episodic Memoris and Interpretations with Situated Scenario-based Ontological References', 'sv': 'EMISSOR: En plattform för att fånga multimodala interaktioner som episodiska minnen och tolkningar med lokaliserade scenariebaserade ontologiska referenser', 'si': 'EMISSOR: ගොඩමෝඩාල් සම්බන්ධයක් අල්ලගන්න ප්\u200dලේටෆ්ටෝම් එකක් Episodic මතකය හා සිටුවේට් සීනාරියේ අධාරිත අන්තෝලෝගික', 'ur': 'EMISSOR: ایک پلٹورم ملتی موڈال تعاملات کا پکڑنے کے لئے اپیسوڈیک یادگار اور سٹیوٹ سناریو بنیادی اوٹولوژیکل تعاملات کے مطابق', 'ta': 'Constellation name (optional)', 'uz': 'EMISSOR: Koʻrsatilgan Scenario asosida, Ontological References kabi multimodal interfeysini qabul qilish uchun platform', 'vi': 'Mô hình nền chụp ảnh tương tác đa phương như kí ức và giải thích theo trường hợp, dựa trên nghiên cứu khoa học', 'nl': 'EMISSOR: Een platform voor het vastleggen van multimodale interacties als episodische herinneringen en interpretaties met gesitueerde scenario-gebaseerde ontologische referenties', 'bg': 'ЕМИСОР: Платформа за улавяне на мултимодални взаимодействия като епизодични спомени и интерпретации с базирани на сценарии онтологични референции', 'hr': 'EMISSOR: Platforma za uhvaćenje multimodalnih interakcija kao episodske sjećanja i razmjene s onitologičkim referencijama na Situated scenario', 'da': 'EMISSOR: En platform til at indfange multimodale interaktioner som episodiske minder og fortolkninger med lokaliserede scenariebaserede ontologiske referencer', 'ko': 'EMISSOR: 다중모드적 상호작용을 상황 기억과 해석으로 포획하는 플랫폼으로 상황의 본체론을 바탕으로 참고', 'de': 'EMISSOR: Eine Plattform zur Erfassung multimodaler Interaktionen als episodische Erinnerungen und Interpretationen mit situated szenario-basierten ontologischen Referenzen', 'fa': 'برنامه\u200cای برای گرفتن تعاملات چندmodal به عنوان حافظه\u200cهای Episodic and Interpretations با برنامه\u200cهای Ontological Based on Situated Scenario', 'id': 'EMISSOR: Sebuah platform untuk menangkap interaksi multimodal sebagai Memori Episodi dan Interpretasi dengan Referensi Ontologi Berdasarkan Situasi Skenario', 'tr': 'EMISSOR: Episodik Hatalar ve Situated Scenario tabanlı Ontologik Referanslar gibi çoklumodal etkileşimleri yakalamak için bir plataforma', 'sq': 'EMISSOR: Një platform ë për kapjen e ndërveprimeve multimodale si Kujtime dhe Interpretime Epizodike me Referencat Ontologjike të Situatuara në Skenar', 'sw': 'EMISSOR: Jukwaa la kuchukua mahusiano mengi kama kumbukumbu na Tafsiri za Kipinduzi na Matangazo ya Kimataifa yanayoendelea', 'af': 'Name', 'az': 'EMISSOR: Episodik Yad캼nlar v톛 캻nterpretasyon olaraq 칞oxlu modal 톛laq톛l톛ri tutmaq 칲칞칲n bir platforma', 'am': 'EMISSOR: በተጨማሪው Scenario-based Ontological References', 'hy': 'ԷՄԻՍՍՕՌ. Մոլիմոդալ փոխազդեցությունների որպես Էպիզոդիկ Հիշողություններ և Ինտերպրենցիաներ Սցենարիոն հիմնված Օնթոլոգիական Հետևանքների հետ', 'bs': 'EMISSOR: Platforma za uhvaćenje multimodalnih interakcija kao episodske sjećanja i razmjene s onitologičkim referencijama na Situated scenario', 'ca': 'EMISSOR: Una plataforma per capturar interaccions multimodals com Memories Episòdiques i Interpretacions amb Referències Ontògiques Situates basades en Scenaris', 'cs': 'EMISSOR: Platforma pro zachycení multimodálních interakcí jako epizodických vzpomínek a interpretací s lokalizovanými ontologickými referencemi založenými na scénářích', 'bn': 'EMISSOR: এক প্ল্যাটফর্ম মাল্টিমোডাল ইন্টারজেক্সের গ্রহণের জন্য এক প্ল্যাটফর্ম, যেখানে স্থানীয় স্কেনারিয়ার ভিত্তিক অনটোলোগিকা', 'et': 'EMISSOR: platvorm multimodaalsete interaktsioonide jäädvustamiseks episoodiliste mälestuste ja tõlgendustena paiknevate stsenaariumipõhiste ontoloogiliste viitetega', 'fi': 'EMISSOR: Alusta multimodaalisten vuorovaikutusten tallentamiseksi episodisina muistoina ja tulkintoina, joissa on asetettu skenaario-pohjainen ontologinen viite', 'ha': 'QUnicodeControlCharacter', 'sk': 'EMISSOR: Platforma za zajemanje multimodalnih interakcij kot episodičnih spominov in interpretacij z ontološkimi referencami na osnovi postavljenega scenarija', 'he': 'פלטפורמה לתפוס אינטראקציות multimodal כזיכרונות ופרשומות Episodic', 'bo': 'EMISSOR: A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References', 'jv': 'EMIsso: Perintah kanggo kelas multimodal'}
{'en': 'We present EMISSOR : a platform to capture multimodal interactions as recordings of episodic experiences with explicit referential interpretations that also yield an episodic Knowledge Graph (eKG). The ', 'fr': "Nous présentons EMISSOR\xa0: une plateforme pour capturer les interactions multimodales sous forme d'enregistrements d'expériences épisodiques avec des interprétations référentielles explicites qui produisent également un Knowledge Graph épisodique (eKG). La plateforme stocke des flux de multiples modalités sous forme de signaux parallèles. Chaque signal est segmenté et annoté indépendamment avec interprétation. Les annotations sont finalement mises en correspondance avec des identités et des relations explicites dans l'ECG. Lorsque nous mettons à la terre des segments de signal provenant de différentes modalités aux mêmes représentations d'instance, nous établissons également différentes modalités les unes sur les autres. La particularité de notre eKG est qu'il accepte différentes interprétations selon les modalités, les sources et les expériences et soutient le raisonnement sur des informations contradictoires et des incertitudes pouvant résulter d'expériences multimodales. EMISSOR peut enregistrer et annoter des expériences dans le monde virtuel et réel, combiner des données, évaluer le comportement du système et ses performances pour des objectifs prédéfinis, mais également modéliser l'accumulation de connaissances et d'interprétations dans le Knowledge Graph à la suite de ces expériences épisodiques.", 'es': 'Presentamos EMISSOR: una plataforma para capturar interacciones multimodales como grabaciones de experiencias episódicas con interpretaciones referenciales explícitas que también producen un Knowledge Graph (ECG) episódico. La plataforma almacena flujos de múltiples modalidades como señales paralelas. Cada señal se segmenta y se anota de forma independiente con interpretación. Las anotaciones eventualmente se asignan a identidades y relaciones explícitas en el eKG. A medida que conectamos a tierra segmentos de señales de diferentes modalidades a las mismas representaciones de instancia, también conectamos a tierra diferentes modalidades entre sí. Lo único de nuestro eKG es que acepta diferentes interpretaciones a través de modalidades, fuentes y experiencias y apoya el razonamiento sobre información contradictoria e incertidumbres que pueden resultar de experiencias multimodales. EMISSOR puede registrar y anotar experimentos en el mundo virtual y real, combinar datos, evaluar el comportamiento del sistema y su rendimiento para objetivos preestablecidos, pero también modelar la acumulación de conocimiento e interpretaciones en el Knowledge Graph como resultado de estas experiencias episódicas.', 'ar': 'نقدم EMISSOR: منصة لالتقاط التفاعلات متعددة الوسائط كتسجيلات للتجارب العرضية مع تفسيرات مرجعية صريحة تؤدي أيضًا إلى رسم بياني معرفي عرضي (eKG). تخزن المنصة تدفقات من طرائق متعددة كإشارات متوازية. يتم تجزئة كل إشارة وتعليقها بشكل مستقل مع التفسير. يتم في النهاية تعيين التعليقات التوضيحية للهويات والعلاقات الصريحة في مخطط كهربية القلب. نظرًا لأننا نؤرض مقاطع إشارة من طرائق مختلفة إلى تمثيلات الحالة نفسها ، فإننا نؤسس أيضًا طرائق مختلفة عبر بعضها البعض. فريد من نوعه في eKG هو أنه يقبل تفسيرات مختلفة عبر الطرائق والمصادر والخبرات ويدعم الاستدلال على المعلومات المتضاربة والشكوك التي قد تنجم عن التجارب متعددة الوسائط. يمكن لـ EMISSOR تسجيل التجارب والتعليق عليها في العالم الافتراضي والواقعي ، والجمع بين البيانات ، وتقييم سلوك النظام وأدائه للأهداف المحددة مسبقًا ، ولكن أيضًا نموذجًا لتراكم المعرفة والتفسيرات في الرسم البياني للمعرفة نتيجة لهذه التجارب العرضية.', 'hi': 'हम EMISSOR प्रस्तुत करते हैं: स्पष्ट संदर्भित व्याख्याओं के साथ एपिसोडिक अनुभवों की रिकॉर्डिंग के रूप में मल्टीमॉडल इंटरैक्शन को कैप्चर करने के लिए एक मंच जो एक एपिसोडिक नॉलेज ग्राफ (ईकेजी) भी उत्पन्न करता है। प्लेटफ़ॉर्म समानांतर संकेतों के रूप में कई तौर-तरीकों की धाराओं को संग्रहीत करता है। प्रत्येक संकेत को विभाजित किया जाता है और व्याख्या के साथ स्वतंत्र रूप से एनोटेट किया जाता है। एनोटेशन अंततः eKG में स्पष्ट पहचान और संबंधों के लिए मैप किए जाते हैं। जैसा कि हम एक ही उदाहरण प्रतिनिधित्व के लिए विभिन्न तौर-तरीकों से संकेत खंडों को जमीन देते हैं, हम एक-दूसरे में विभिन्न तरीकों को भी जमीन देते हैं। हमारे ईकेजी के लिए अद्वितीय यह है कि यह तौर-तरीकों, स्रोतों और अनुभवों में विभिन्न व्याख्याओं को स्वीकार करता है और परस्पर विरोधी जानकारी और अनिश्चितताओं पर तर्क का समर्थन करता है जो बहुआयामी अनुभवों के परिणामस्वरूप हो सकते हैं। EMISSOR आभासी और वास्तविक दुनिया में प्रयोगों को रिकॉर्ड और एनोटेट कर सकता है, डेटा को संयोजित कर सकता है, सिस्टम व्यवहार और पूर्व निर्धारित लक्ष्यों के लिए उनके प्रदर्शन का मूल्यांकन कर सकता है, लेकिन इन एपिसोडिक अनुभवों के परिणामस्वरूप नॉलेज ग्राफ़ में ज्ञान और व्याख्याओं के संचय को भी मॉडल कर सकता है।', 'pt': 'Apresentamos o EMISSOR: uma plataforma para capturar interações multimodais como gravações de experiências episódicas com interpretações referenciais explícitas que também produzem um Knowledge Graph episódico (eKG). A plataforma armazena fluxos de múltiplas modalidades como sinais paralelos. Cada sinal é segmentado e anotado independentemente com interpretação. As anotações são eventualmente mapeadas para identidades e relações explícitas no eKG. À medida que aterramos segmentos de sinal de diferentes modalidades para as mesmas representações de instância, também aterramos diferentes modalidades entre si. O exclusivo do nosso eKG é que ele aceita diferentes interpretações entre modalidades, fontes e experiências e suporta o raciocínio sobre informações conflitantes e incertezas que podem resultar de experiências multimodais. O EMISSOR pode registrar e anotar experimentos no mundo real e virtual, combinar dados, avaliar o comportamento do sistema e seu desempenho para metas predefinidas, mas também modelar o acúmulo de conhecimento e interpretações no Knowledge Graph como resultado dessas experiências episódicas.', 'ja': 'EMISSOR ：エピソード知識グラフ（ eKG ）をもたらす明示的な参照解釈を用いて、エピソード体験の記録としてマルチモーダルインタラクションをキャプチャするためのプラットフォームを提示します。 プラットフォームは、複数のモードのストリームを並列信号として格納します。 各信号は分割され、解釈とともに独立して注釈されます。 注釈は、最終的にeKG内の明示的なアイデンティティと関係にマッピングされます。 異なるモダリティから同じインスタンス表現への信号セグメントを接地するとき、互いに異なるモダリティを接地することもできます。 当社のeKGのユニークな点は、モダリティ、ソース、および経験にわたってさまざまな解釈を受け入れ、マルチモーダルエクスペリエンスから生じる可能性のある矛盾する情報と不確実性に関する推論をサポートすることです。 EMISSORは、仮想世界と現実世界での実験を記録および注釈付けし、データを組み合わせ、システムの動作と事前設定された目標のためのパフォーマンスを評価することができますが、これらのエピソード的な経験の結果としてナレッジグラフ内の知識と解釈の蓄積をモデル化することもできます。', 'zh': '臣等EMISSOR:一获多模态交互之台,以为情节经验之记,明参解释,亦生情节图谱(eKG)。 该平台以余模态流储为并行信号。 每信号皆因解释独立分段注。 注终射心电图中显式。 异模态者接地同实者,异模态相接地。 吾心电图之独在,其受跨式,其来异说,而支其冲突之信不确定性。 EMISSOR记注虚拟,与世实验合数,评统行能以成其趣,验图谱解之积建模。', 'ru': 'Мы представляем EMISSOR: платформу для захвата мультимодальных взаимодействий в виде записей эпизодического опыта с явными ссылочными интерпретациями, которые также дают эпизодический График знаний (eKG). Платформа хранит потоки нескольких модальностей в виде параллельных сигналов. Каждый сигнал сегментируется и аннотируется независимо с интерпретацией. Аннотации в конечном итоге сопоставляются с явными идентичностями и отношениями в eKG. Поскольку мы заземляем сегменты сигнала от разных способов к одному и тому же представлению экземпляра, мы также заземляем различные способы друг у друга. Уникальность нашей eKG заключается в том, что она принимает различные интерпретации различных способов, источников и опыта и поддерживает рассуждения о противоречивой информации и неопределенностях, которые могут возникнуть в результате мультимодального опыта. EMISSOR может записывать и аннотировать эксперименты в виртуальном и реальном мире, комбинировать данные, оценивать поведение системы и их производительность для заданных целей, а также моделировать накопление знаний и интерпретаций в графе знаний в результате этого эпизодического опыта.', 'ga': 'Cuirimid i láthair EMISSOR: ardán chun idirghníomhaíochtaí ilmhódacha a ghabháil mar thaifeadtaí ar eispéiris eipeasóideach le léirmhínithe tagartha follasacha a thugann Graf Eolais eipeasóideach (eKG) freisin. Stórálann an t-ardán sruthanna de mhódúlachtaí iolracha mar chomharthaí comhthreomhara. Déantar gach comhartha a dheighilt agus a anótáil go neamhspleách le léirmhíniú. Déantar nótaí a mhapáil ar deireadh chuig féiniúlachtaí agus caidreamh follasach san eKG. De réir mar a dhéanaimid míreanna comharthaí a shuí ó mhódúlachtaí difriúla go dtí na huiríll céanna, leagaimid módúlachtaí difriúla trasna a chéile freisin. Rud uathúil dár eKG is ea go nglacann sé le léirmhínithe éagsúla trasna módúlachtaí, foinsí agus eispéiris agus go dtacaíonn sé le réasúnaíocht faoi fhaisnéis chontrártha agus neamhchinnteachtaí a d’fhéadfadh teacht as eispéiris ilmhódacha. Is féidir le EMISSOR trialacha sa saol fíorúil agus sa saol fíor a thaifeadadh agus a anótáil, sonraí a chomhcheangal, iompraíocht an chórais agus a bhfeidhmíocht a mheas le haghaidh spriocanna réamhshocraithe ach freisin múnla a dhéanamh ar charnadh eolais agus léirmhínithe sa Ghraf Faisnéise mar thoradh ar na heispéiris eipeasóideach seo.', 'hu': 'Bemutatjuk az EMISSOR-t: a multimodális interakciók rögzítésére szolgáló platformot epizódikus tapasztalatok rögzítéseként, explicit referenciális értelmezésekkel, amelyek epizódikus Tudásgráfot (eKG) is eredményeznek. A platform párhuzamos jelként tárolja a többféle módszerek áramát. Minden jelet szegmentáltak és jegyzeteltek függetlenül értelmeznek. A jegyzékeket végül az eKG explicit identitásaihoz és kapcsolataihoz térképezik. Ahogy a különböző módszerekből ugyanazon példány reprezentációkig földeljük a jelszegmenseket, különböző módszereket is egymás között földeljük. Az eKG egyedülálló az, hogy elfogadja a módszerek, források és tapasztalatok közötti különböző értelmezéseket, és támogatja a multimodális tapasztalatokból eredő ellentmondó információk és bizonytalanságok érvelését. Az EMISSOR virtuális és valós világban rögzítheti és jegyzetelheti a kísérleteket, kombinálhatja az adatokat, értékelheti a rendszer viselkedését és teljesítményét előre beállított célok érdekében, de modellezheti a tudás és értelmezések felhalmozódását a Knowledge Graphban ezen epizódikus tapasztalatok eredményeként.', 'el': 'Παρουσιάζουμε μια πλατφόρμα για την καταγραφή των πολυπροπικών αλληλεπιδράσεων ως καταγραφές των επισοδικών εμπειριών με ρητές αναφορητικές ερμηνείες που παράγουν επίσης ένα επίσοδικό Γράφημα Γνώσης (eKG). Η πλατφόρμα αποθηκεύει ροές πολλαπλών μορφών ως παράλληλα σήματα. Κάθε σήμα διαιρείται και σχολιάζεται ανεξάρτητα με ερμηνεία. Οι σημειώσεις αντιστοιχίζονται τελικά σε ρητές ταυτότητες και σχέσεις στο eKG. Καθώς γειώνουμε τμήματα σήματος από διαφορετικές λεπτομέρειες στις ίδιες αναπαραστάσεις, γειώνουμε επίσης διαφορετικές λεπτομέρειες μεταξύ τους. Μοναδικό για το ηλεκτρονικό μας σύστημα είναι ότι αποδέχεται διαφορετικές ερμηνείες σε διάφορες μορφές, πηγές και εμπειρίες και υποστηρίζει τη συλλογιστική σχετικά με αντικρουόμενες πληροφορίες και αβεβαιότητες που μπορεί να προκύψουν από πολυμορφικές εμπειρίες. Η ΕΜΙΣΣΟR μπορεί να καταγράψει και να σχολιάσει πειράματα σε εικονικό και πραγματικό κόσμο, να συνδυάσει δεδομένα, να αξιολογήσει τη συμπεριφορά του συστήματος και την απόδοσή τους για προκαθορισμένους στόχους αλλά και να μοντελοποιήσει τη συσσώρευση γνώσεων και ερμηνείων στο Γράφημα Γνώσης ως αποτέλεσμα αυτών των επιδοτικών εμπειριών.', 'ka': 'EMISSOR: პლატატრამი, რომელიც მულტიმოდიალური ინტერფექციების შესახებ, როგორც ეპიციოდიური გამოცდილებების შესახებ, რომელიც ეპიციოდიური რეფერენციალური ინტერფექციების შესახებ, რომელიც Name ყოველ სიგნალის სიგნალის განსხვავება და განსხვავება განსხვავებულად განსხვავება. ანოტაციები საბოლოოდ eKG-ში გამოსახულებული იდენტიფიკაციების და შესახებების შესახებ. როგორც ჩვენ განსხვავებული მოდილების განსხვავებული მოდილების განსხვავებული მოდილების განსხვავებაში, ჩვენ ასევე განსხვავებული მოდილებების განსხვავებას ერთმანეთის განსხვავებთ. ჩვენი eKG-ის განსხვავებული ინტერპუქციები მოდილიტებით, გამოცდილებით და გამოცდილებით დაახლოების პარამეტრებით კონფლიქციური ინფორმაციას და განსხვავებას, რომელიც შეიძლება მრავალმედიალურ EMISSOR შეიძლება ვირტუალური და რეალური მსოფლიოში ექსპერიმენტების რეკონტურაციას და დააწერა, სისტემური ქცევის შესახებ და მათი სამუშაო მიზეზებისთვის შესახებ, მაგრამ მოდელური იცნობის და ინტერპუქ', 'it': "Presentiamo EMISSOR: una piattaforma per catturare le interazioni multimodali come registrazioni di esperienze episodiche con interpretazioni referenziali esplicite che producono anche un Knowledge Graph episodico (eKG). La piattaforma memorizza flussi di modalità multiple come segnali paralleli. Ogni segnale è segmentato e annotato in modo indipendente con interpretazione. Le annotazioni vengono infine mappate a identità e relazioni esplicite nell'eKG. Mentre misuriamo segmenti di segnale da modalità diverse a rappresentazioni della stessa istanza, misuriamo anche modalità diverse tra loro. Unico del nostro eKG è che accetta diverse interpretazioni tra modalità, fonti ed esperienze e supporta il ragionamento su informazioni contrastanti e incertezze che possono derivare da esperienze multimodali. EMISSOR può registrare e annotare esperimenti nel mondo virtuale e reale, combinare dati, valutare il comportamento del sistema e le loro prestazioni per obiettivi prestabiliti, ma anche modellare l'accumulo di conoscenze e interpretazioni nel Knowledge Graph come risultato di queste esperienze episodiche.", 'kk': 'EMISSOR: бірнеше мәліметті білім график (eKG) эписодикалық тәжірибесін жазып алу үшін көп модалық интернетацияларды қабылдау платформасы. Платформа бірнеше режімдерді параллел сигналдар ретінде сақтайды. Әрбір сигнал түрлендіріммен бірге бөліп, түрлендірілген. Аңдатпалар eKG- де көрсетілген идентификациялар мен қатынастарға сәйкес келтіріледі. Біз әртүрлі әдістерден бір инстанцияның түріне сәйкес сегменттерді бір-бірімізге әртүрлі әдістерді зерттейміз. Біздің eKG-мізге бірнеше түрлі түсініктерді көпшілік, көзі және тәжірибелердің арасындағы түрлі түсініктерді қабылдап, көпшілікті тәжірибелерден қайшылық мәліметтерді және EMISSOR виртуалды және шын әлемдегі эксперименттерді жазып жазып жазып, мәліметтерді біріктіре алады, жүйелік әрекеттерін және оның әдеттегі мақсаттарының әрекеттерін баптай алады, сондай-ақ бұл эписодикалық тәжірибелерінің себе', 'ml': 'ഞങ്ങള്\u200d EMISSOR: ഒരു പ്ലാറ്റ്\u200cഫോം എപ്പിസോഡിക്ക് അനുഭവങ്ങളുടെ റെക്കോര്\u200dഡ് ചെയ്യാനുള്ള ഒരു പ്ലാറ്റ്മോഡിക് പരിജ്ഞാനം കൊണ്ട് വരുന്നു പ്ലാറ്റ്ഫോമിലെ സൂക്ഷിക്കുന്ന പ്ലാറ്റ്ഫോമില്\u200d പല മോഡിയലുകളുടെ നദികള്\u200d പാരാമലില്\u200d സിഗ്നലുകളാ ഓരോ സിഗ്നലും പിരിച്ചു വിശദീകരിക്കപ്പെട്ടിരിക്കുന്നു. വ്യാഖ്യാനം കൊണ്ട് സ്വാതന്ത്ര്യമ അവസാനം എക്കെജിയിലെ ഐച്ഛികങ്ങളും ബന്ധങ്ങളും വ്യക്തമാക്കുവാന്\u200d മാപ്പ് ചെയ്യുന്നു. നമ്മള്\u200d വ്യത്യസ്ത രീതികളില്\u200d നിന്നും പ്രതിനിധികളിലേക്കും വ്യത്യസ്ത സിഗ്നല്\u200d ഭൂമിയില്\u200d നിന്നും സ്ഥാപിക്കുന്ന പ Unique to our eKG is that it accepts different interpretations across modalities, sources and experiences and supports reasoning over conflicting information and uncertainties that may result from multimodal experiences.  EMISSOR വാര്\u200dച്ചുവലിലും യഥാര്\u200dത്ഥ ലോകത്തും പരീക്ഷണങ്ങള്\u200d റെക്കോര്\u200dട്ട് ചെയ്യുകയും വിശദീകരിക്കുകയും ചെയ്യാം, വിവരങ്ങള്\u200d കൂട്ടുകയും, സിസ്റ്റം നടപടികളെയും പരിഗണിക്കുകയും, പ്രെ', 'lt': 'Mes pristatome EMISSOR: platform ą daugiarūšio pobūdžio sąveikai užfiksuoti kaip epizodinių patirčių įrašus su aiškiais referenciniais aiškinimais, kurie taip pat rodo epizodinį žinių grafiką (eKG). Platforma saugo įvairių režimų srautus kaip lygiagrečius signalus. Each signal is segmented and annotated independently with interpretation.  Pastabos galiausiai pateikiamos atsižvelgiant į aiškų eKG tapatybę ir santykius. Kadangi mes antžeminiai signal ų segmentai nuo skirtingų režimų iki vieno pavyzdys, mes taip pat skirtingas režimas vienas kitam. Unique to our eKG is that it accepts different interpretations across modalities, sources and experiences and supports reasoning over conflicting information and uncertainties that may result from multimodal experiences.  EMISSOR gali įrašyti ir anotuoti eksperimentus virtualiajame ir realiajame pasaulyje, derinti duomenis, įvertinti sistemų elgesį ir jų rezultatus pagal nustatytus tikslus, bet taip pat modeliuoti žinių ir aiškinimų kaupimą žinių grafikoje dėl šių epizodinių patirčių.', 'mk': 'Презентираме ЕМИССОР: платформа за снимање на мултимедални интеракции како снимки на епизодични искуства со експлицитни референцијални интерпретации кои исто така даваат епизодичен знање граф (eKG). Платформата складира потоци од повеќе моделности како паралелни сигнали. Секој сигнал е сегментиран и анотиран независно од интерпретацијата. Annotations are eventually mapped to explicit identities and relations in the eKG.  Како што ние ги приземјуваме сегментите од различни моделности до истите претставувања, ние исто така ги приземјуваме различните моделности меѓусебно. Единствено за нашиот eKG е тоа што прифаќа различни интерпретации меѓу моделностите, изворите и искуствата и го поддржува размислувањето околу конфликтните информации и несигурностите кои можат да резултираат од мултимодилните искуства. ЕМИСОР може да сними и анотира експерименти во виртуелниот и реалниот свет, да ги комбинира податоците, да го процени системското однесување и нивното однесување за предпоставени цели, но исто така да ја моделира акумулацијата на знаење и интерпретации во Графот на знаење како резултат на овие епизодичн', 'mt': 'Aħna nippreżentaw l-EMISSOR: pjattaforma biex inqabdu interazzjonijiet multimodali bħala reġistrazzjonijiet ta’ esperjenzi episodiċi b’interpretazzjonijiet referenzjali espliċiti li jagħtu wkoll Grafika episodika tal-Għarfien (eKG). Il-pjattaforma taħżen flussi ta’ modalitajiet multipli bħala sinjali paralleli. Kull sinjal huwa segmentat u annotat indipendentement bl-interpretazzjoni. L-annotazzjonijiet eventwalment jiġu mmappjati għal identitajiet u relazzjonijiet espliċiti fl-eKG. Minħabba li nagħmlu segmenti tas-sinjali terrestri minn modalitajiet differenti għal rappreżentazzjonijiet tal-istess istanza, aħna nagħmlu wkoll modalitajiet differenti lil xulxin. Uniku għall-eKG tagħna huwa li taċċetta interpretazzjonijiet differenti bejn il-modalitajiet, is-sorsi u l-esperjenzi u tappoġġja r-raġunament dwar informazzjoni u inċertezzi konfliġġenti li jistgħu jirriżultaw minn esperjenzi multimodali. EMISSOR jista’ jirreġistra u jinnota esperimenti f’dinja virtwali u reali, jikkombina dejta, jevalwa l-imġiba tas-sistema u l-prestazzjoni tagħhom għal għanijiet predefiniti iżda jimmudella wkoll l-akkumulazzjoni ta’ għarfien u interpretazzjonijiet fil-Grafika tal-Għarfien bħala riżultat ta’ dawn l-esperjenzi episodjali.', 'ms': 'Kami memperkenalkan EMISSOR: platform untuk menangkap interaksi multimodal sebagai rekaman pengalaman episodik dengan interpretasi referensi eksplisit yang juga memberikan Graf Pengetahuan episodik (eKG). Platform menyimpan aliran modaliti berbilang sebagai isyarat selari. Setiap isyarat disegmen dan dicatat secara independen dengan interpretasi. Annotasi akhirnya dipetakan ke identiti dan hubungan eksplisit dalam eKG. Sebagaimana kita mendarat segmen isyarat dari modaliti yang berbeza ke perwakilan contoh yang sama, kita juga mendarat modaliti yang berbeza antara satu sama lain. Unik bagi eKG kami adalah ia menerima interpretasi yang berbeza melalui modaliti, sumber dan pengalaman dan menyokong reasoning mengenai maklumat dan ketidakpastian yang berkonflik yang mungkin berasal dari pengalaman multimodal. EMISSOR boleh rekod dan anotasi eksperimen dalam dunia maya dan nyata, menggabungkan data, menilai perilaku sistem dan prestasi mereka untuk tujuan preset tetapi juga model akumulasi pengetahuan dan interpretasi dalam Graf Pengetahuan sebagai hasil pengalaman episodik ini.', 'pl': 'Prezentujemy EMISSOR: platformę służącą do rejestrowania interakcji multimodalnych jako nagrania doświadczeń epizodycznych z wyraźnymi interpretacjami referencyjnymi, które dają również epizodyczny wykres wiedzy (eKG). Platforma przechowuje strumienie wielu modalności jako sygnały równoległe. Każdy sygnał jest segmentowany i adnotacjonowany niezależnie z interpretacją. Annotacje są ostatecznie mapowane do wyraźnych tożsamości i relacji w eKG. Gdy uziemiamy segmenty sygnału z różnych modalności do tych samych reprezentacji instancji, uziemiamy również różne modalności wzajemnie. Unikalne dla naszego eKG jest to, że akceptuje różne interpretacje w różnych modalnościach, źródłach i doświadczeniach oraz wspiera rozumowanie sprzecznych informacji i niepewności, które mogą wynikać z multimodalnych doświadczeń. EMISSOR może rejestrować i adnotatować eksperymenty w świecie wirtualnym i rzeczywistym, łączyć dane, oceniać zachowanie systemu i ich wydajność dla ustalonych celów, ale także modelować gromadzenie wiedzy i interpretacji w Wykresie Wiedzy w wyniku tych epizodycznych doświadczeń.', 'mn': 'Бид EMISSOR-г илтгэдэг: олон моделийн харилцааны талаар эпиsodик туршлагын бичлэг болон тодорхой тодорхойлолтой тодорхойлолтой тодорхойлолтой, мөн эпиsodic Knowledge Graph (eKG) үүсгэдэг платформ юм. Платформ нь олон загварын урсгалыг параллел сигнал болгон хадгалдаг. Зөвлөгөө бүр хэлбэрээр хуваагдана, илэрхийлэлтэй тулгарсан. Эцэст нь eKG-ийн тодорхойлолт, харилцааны тодорхойлолтой газрын зураг зурагдсан. Бид өөр хэлбэрээс адилхан тодорхойлолтууд руу шилжүүлэхэд өөр өөр арга замыг бие бие бие бие бие бие бие бие бие бие бие бие бие бие бие бие бие бие бие бие биенээ Бидний eKG-д нэг л зүйл бол энэ нь олон төрлийн туршлагаас үр дүнтэй олон төрлийн мэдээлэл болон тодорхойлолтыг хүлээн зөвшөөрөх боломжтой мэдээлэл болон тодорхойлолтыг дэмжиж байна. EMISSOR виртуал болон жинхэнэ ертөнцийн туршилтуудыг бичлэглэж, анзаараж, мэдээллийг нийлүүлж, системийн үйл ажиллагааг үнэлгээж, зорилгооны төлөө зорилгоор ажиллаж чадна. Мөн эдгээр эпиsodик туршилтын үр дүнд мэдлэг графикийн мэдлэг болон түгээмэл д', 'ro': 'Vă prezentăm EMISSOR: o platformă pentru captarea interacțiunilor multimodale ca înregistrări ale experiențelor episodice cu interpretări referențiale explicite care generează și un grafic de cunoaștere episodic (eKG). Platforma stochează fluxuri de modalități multiple ca semnale paralele. Fiecare semnal este segmentat și adnotat independent cu interpretare. Adnotările sunt în cele din urmă mapate la identități explicite și relații în eKG. Pe măsură ce împărțim segmente de semnal de la diferite modalități la aceeași reprezentare instanță, de asemenea, împărțim modalități diferite unul pe celălalt. Unic pentru eKG-ul nostru este faptul că acceptă interpretări diferite în diferite modalități, surse și experiențe și sprijină raționamentul asupra informațiilor conflictuale și incertitudinilor care pot rezulta din experiențele multimodale. EMISSOR poate înregistra și adnota experimente în lumea virtuală și reală, combina date, evalua comportamentul sistemului și performanța acestora pentru obiective prestabilite, dar, de asemenea, modela acumularea de cunoștințe și interpretări în Knowledge Graph ca rezultat al acestor experiențe episodice.', 'no': 'Vi presenterer EMISSOR: ein plattform for å ta opp multimodal samarbeid som opptak av episodiske opplevelsar med eksplisitt referansielle tolking som også gjer ein episodisk kjennomsnittgraf (eKG). Plattformet lagrar strømmer med fleire modusar som parallelle signaler. Kvar signal er segmentert og merkt uavhengig med tolking. Notasjonar er eventuelt kartert til eksplisitt identitetar og forhold i eKG. Som vi bakgrunnsingssegmentar frå forskjellige modusar til samme instans representasjonar, vil vi også bakgrunnstille forskjellige modusar. Einskilt til eKG vårt er at den aksepterer ulike tolkingar over modaliteter, kjelder og opplevelsar og støttar rasjon over konfliktlige informasjon og usikkerhet som kan føre til fleire opplevelsar. EMISSOR kan registrere og annoterare eksperimenter i virtuelt og verkeleg, kombinere data, evaluere systemoppførsel og utviklinga for førehandsvising av mål, men også modellere akumulering av kunnskap og tolkingar i Kjenningsgrafen som resultat av desse episodiske opplevelsane.', 'so': "Waxaynu soo wadanaa EMISSOR: Qorshaha lagu qabto Interfaco kala duduwan oo ah qoraalka arimaha dhaqdhaqaaqa episodic iyo turjumaadyo cad oo ku qoran karta qoraalka aqoonta (eKG). Jardiinoku wuxuu ku wareejiyaa durdurro kala duduwan sida calaamada lambarka ah. Calaamad kasta waxaa loo qeybiyaa oo si xor ah loo dhibaa turjubaan. Ugu dambaysta waxaa lagu sawiraa aqoonsiga iyo xiriirka eKG. Sida aan qeybaha sawirada u dhulno noocyo kala duduwan iyo noocyo isku mid ah, waxaynu sameynaa qaabab kala duduwan. EKG waxaa u gaar ah in turjubaan kala duduwan qaababka kala duduwan, asagooyinka iyo khilaafka, waxayna kaalmeeyaa arrimaha ka dooda macluumaadka muran iyo garashada la'aanta, taas oo laga heli karo arimaha kala duduwan. EMISSOR wuxuu sameyn karaa jirrabaadka ku qoran karo iyo baaraandegista caalamiga ah, wuxuuna isku dari karaa macluumaadka, qiimeyn karaa tababarada nidaamka iyo tababarka ay ku shaqeeyaan goalada hore, laakiin wuxuu sidoo kale u sameyn karaa soo urursashada aqoonta iyo turjumidda aqoonta Graf aqoonta sababtoo ah arimahan baaritaanka ah.", 'sr': 'Predstavljamo EMISSOR: platformu za hvatanje multimodalnih interakcija kao snimanje episodijskih iskustava sa eksplicitim referencijskim interpretacijama koji takođe pružaju episodijski grafik znanja (eKG). Platforma čuva niz višestrukih modaliteta kao paralelne signale. Svaki signal je segmentiran i annotiran nezavisno sa interpretacijom. Anotacije su na kraju mapirane na pojasne identitete i odnose u eKG-u. Dok smo podmetnuli segmente signala iz različitih moda do iste primjere, takođe smo podmetnuli različite modalitete međusobno. Jednostavno za našu eKG je da prihvata različite interpretacije preko moda, izvora i iskustva i podržava razgovor o sukobnim informacijama i nesigurnostima koje mogu rezultirati od multimodalnih iskustava. EMISSOR može snimiti i annotirati eksperimente u virtualnom i realnom svijetu, kombinirati podatke, proceniti sistemsko ponašanje i njihovo izvođenje za predpostavljene ciljeve, ali takođe modelirati akumulaciju znanja i interpretacija u grafiku znanja kao rezultat ovih episodijskih iskustava.', 'sv': 'Vi presenterar EMISSOR: en plattform för att fånga multimodala interaktioner som inspelningar av episodiska upplevelser med explicita referenstolkningar som också ger en episodisk kunskapsgraf (eKG). Plattformen lagrar strömmar av flera modaliteter som parallella signaler. Varje signal segmenteras och kommenteras självständigt med tolkning. Annotationer mappas så småningom till explicita identiteter och relationer i eKG. När vi jordar signalsegment från olika modaliteter till samma instansrepresentationer, jordar vi också olika modaliteter över varandra. Unikt för vår eKG är att den accepterar olika tolkningar över modaliteter, källor och erfarenheter och stöder resonemang över motstridiga uppgifter och osäkerheter som kan uppstå av multimodala erfarenheter. EMISSOR kan registrera och kommentera experiment i virtuell och verklig värld, kombinera data, utvärdera systembeteende och deras prestanda för förinställda mål men också modellera ackumulering av kunskap och tolkningar i Knowledge Graph som ett resultat av dessa episodiska upplevelser.', 'si': 'අපි EMISSOR පෙනුම් කරනවා: ගොඩමෝඩාල් සම්බන්ධයක් අල්ලගන්න බොහොමෝඩාල් සම්බන්ධයක් වගේ ප්\u200dරකාශිත සම්බන්ධ අභ්\u200dයාගයක් වගේ ප්\u200dරකාශ Name හැම සංඥානයක්ම සැකසුම් කරලා තියෙනවා සහ ස්වයංක්\u200dරමයෙන් ස්වයංක්\u200dරමයෙන් ප්\u200dරතිකා අවස්ථාවෙන් අන්තිමේදී eKG වලින් පැහැදිලි අනතුරක් සහ සම්බන්ධතාවක් ලැබෙනවා. අපි වෙනස් සංඥාවක් සංඥාවක් වලින් වෙනස් සංඥාවක් වලින් එකම සංඥාවක් වලින්, අපි එක්කෙනෙක්ට වෙනස අපේ eKG එක්කෙනෙක් තමයි ඒක වෙනස් අභිවාදයක් පිළිගන්නවා කියලා, මුළුවන් සහ අභිවාදයක් වලින් වෙනස් අභිවාදයක් වලින් සහ සම්බ EMISSOR පුළුවන් අවස්ථාව සහ ඇත්ත ලෝකයේ පරීක්ෂණාවක් ලැබෙන්න, දත්ත එකතු කරන්න, පද්ධතිය අවස්ථාවක් සහ ඔවුන්ගේ ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය සඳහා මුළ', 'ta': 'நாங்கள் EMISSOR காண்பிக்கிறோம்: பல்வேறு இடைவெளிப்பாடுகளை பிடிக்கும் ஒரு பட்டியல் புதிய அறிவு வரைப்படத்தை கொடுக்கும் ஒரு வெளிப்படையான அனுபவங்களை பத தளம் பல வகைகளின் ஆறுகளை இணைய குறிகளாக சேமிக்கிறது. ஒவ்வொரு குறிகையும் பிரிக்கப்பட்டுள்ளது மற்றும் விளக்கத்துடன் தனியாக குறிக்கப்படுகிறது. Annotations are eventually mapped to explicit identities and relations in the eKG.  நாம் வேறு வகைகளிலிருந்து வேறு குறிக்குறியீட்டு பிரிவுகளை ஒரே நிகழ்வுக்கு முன்னால், நாம் ஒருவர் மற்றொருவருக எங்கள் eKG தனிப்பட்ட முறைகள், மூலங்கள் மற்றும் அனுபவங்கள் மூலம் வேறு விளக்கங்களை ஏற்றுக் கொள்கிறார் EMISSOR மெய்நிகர் மற்றும் உண்மையான உலகத்தில் உள்ள சோதனைகளை பதிவு மற்றும் வெளிப்படுத்த முடியும், தகவல்களை ஒன்று சேர்க்க, கணினி நடத்தையையும் பரிசோதிக்க முடியும், முன்ன', 'ur': 'ہم EMISSOR کو پیش کریں گے: ایک پلٹورم ہے کہ multimodal interactions capture as recordings of episodic experiences with explicit referential interpretations that also yield an episodic Knowledge Graph (eKG). پلٹورم تعداد موڈلیٹ کے سیگنالوں کی طرح سیگنالوں کو ذخیره کرتا ہے. Each signal is segmented and annotated independently with interpretation. اچھی طرح اچھی طرح اچھی پہچان اور رابطہ کے لئے مکاپیٹ کیے جاتے ہیں۔ جیسے ہم مختلف موڈلیٹوں سے مختلف سیگنال سگلوں کو ایک ہی مثال تک بناتے ہیں، ہم ایک دوسرے کے درمیان مختلف موڈلیٹوں کو بھی بناتے ہیں۔ ہمارے eKG کے لئے یونیک ہے کہ یہ مختلف تعبیروں کو modalities, sources and experiences کے ساتھ قبول کرتا ہے اور مختلف معلومات اور یقین کے بارے میں بحث کرنے کی مدد کرتا ہے جو بہت سی موڈال تجربے سے نتیجہ حاصل کرسکتی ہے. EMISSOR مجازی اور حقیقی دنیا میں آزمائش کا ریکورد کرسکتا ہے اور آزمائش کرسکتا ہے، ڈاٹا کو ترکیب کرسکتا ہے، سیستم رفتار اور ان کی عملیات کا ارزش کرسکتا ہے، لیکن اس کے نتیجہ میں علم اور تعلیمات کی جمع کرنا بھی مدل کرسکتا ہے، یہ اپیسوڈیک تجربے کے نتیجہ سے۔', 'uz': "Biz EMISSOR hozir qilamiz: Pisodik tajribalarini tahrirlash uchun multimodal interfektlarni tasavvur qilish platformi, bu esa episodic Known Graph (eKG) ga ega bo'ladi. Name @ info Annotations are eventually mapped to explicit identities and relations in the eKG.  Biz har xil signalning qismlarini boshqa usullardan bitta xususiyatlarni o'zgartirishimiz mumkin, biz bir bir bir bir xil usullarni boshqaramiz. Bizning eKG uchun uning bir xil tarjimalarni turadi, manba va tajribalar bilan boshqa tarjimalarni qabul qiladi va murojaat qilish haqida murakkab maʼlumot va haqiqiqatlarni qoʻllash mumkin, multimodal tajribadan foydalanishi mumkin. EMISSOR virtual va halik dunyodagi tajribalarni tahrirlash mumkin, maʼlumot, tizimning xususiyatlarini qiymatish va prezident maqolalari uchun bajarish imkoniyatini birlashtirish mumkin, balki bu maʼlumot va tarjima tajribalarni taʼminlovchi taʼminot darajada o'zgartirish mumkin.", 'vi': 'Chúng tôi giới thiệu EMSSOR: một dàn để ghi nhận các tương tác đa phương như các bản ghi chép của các kinh nghiệm động đất với các nhận dạng rõ ràng và cũng có biểu đồ tri thức. The platform stores streams of multiple Operations as parallel signs. Mỗi tín hiệu được chia ra và ghi chú độc lập bằng cách giải thích. Phụ chú được vẽ thành bản đồ và quan hệ rõ ràng trong eKG. Khi chúng ta bắt đầu tín hiệu phân khúc từ phương thức khác nhau đến các biểu tượng cùng trường hợp, chúng ta cũng đặt ra các phương thức khác nhau. Đặc biệt đối với ngKG là nó chấp nhận các cách giải thích khác nhau về phương thức, nguồn tin và kinh nghiệm và hỗ trợ lập luận về những thông tin và bất ngờ mâu thuẫn có thể là kết quả từ kinh nghiệm đa phương. EMSSOR có thể ghi lại và ghi chú các thí nghiệm trên vật thể ảo và thực tế, kết hợp dữ liệu, đánh giá hành vi của hệ thống và khả năng của chúng với mục tiêu đã định sẵn, nhưng cũng mô hình sự tích tập hợp kiến thức và cách giải thích trong cùng bộ đồ tri thức này.', 'bg': 'Представяме ЕМИСОР: платформа за улавяне на мултимодални взаимодействия като записи на епизодични преживявания с изрични референтни интерпретации, които също дават епизодична графика на знанието. Платформата съхранява потоци от множество модали като паралелни сигнали. Всеки сигнал е сегментиран и анотиран независимо с интерпретация. Анотациите в крайна сметка се картографират към изрични идентичности и връзки в електронната мрежа. Докато приземяваме сигнални сегменти от различни модификации към едни и същи примери, ние също така заземяваме различни модификации помежду си. Уникално за нашата електронна мрежа е, че приема различни интерпретации между модалите, източниците и опита и подкрепя разсъжденията за противоречива информация и несигурност, които могат да произтичат от мултимодалния опит. Емисор може да записва и анотира експерименти във виртуалния и реалния свят, да комбинира данни, да оценява системното поведение и тяхното представяне за предварително зададени цели, но също така да моделира натрупването на знания и интерпретации в Графиката на знанието в резултат на тези епизодични преживявания.', 'nl': 'We presenteren EMISSOR: een platform om multimodale interacties vast te leggen als opnames van episodische ervaringen met expliciete referentiele interpretaties die ook een episodische Kennisgrafiek (eKG) opleveren. Het platform slaat streams van meerdere modaliteiten op als parallelle signalen. Elk signaal wordt afzonderlijk gesegmenteerd en geannoteerd met interpretatie. Annotaties worden uiteindelijk in kaart gebracht aan expliciete identiteiten en relaties in de eKG. Als we signaalsegmenten van verschillende modaliteiten naar dezelfde instancerepresentaties aarden, aarden we ook verschillende modaliteiten over elkaar heen. Uniek aan onze eKG is dat het verschillende interpretaties accepteert tussen modaliteiten, bronnen en ervaringen en dat het redeneren ondersteunt over conflicterende informatie en onzekerheden die kunnen voortvloeien uit multimodale ervaringen. EMISSOR kan experimenten vastleggen en annoteren in virtuele en reale wereld, data combineren, systeemgedrag en prestaties evalueren voor vooraf ingestelde doelen, maar ook de accumulatie van kennis en interpretaties modelleren in de Knowledge Graph als resultaat van deze episodische ervaringen.', 'hr': 'Predstavljamo EMISSOR: platformu za uhvatiti multimodalne interakcije kao snimanje episodijskih iskustva s eksplicitim referencijskim interpretacijama koji također pružaju episodijski znanstveni grafik (eKG). Platforma čuva struje višestrukih modaliteta kao paralelne signale. Svaki signal je segmentiran i zabilježen nezavisno sa interpretacijom. Notacije su na kraju mapirane na pojasne identitete i odnose u eKG-u. Dok smo podmetnuli segmente signala iz različitih načina do istog primjera, također smo podmetnuli različite načine međusobno. Jedino od naših eKG-a je da prihvata različite interpretacije preko moda, izvora i iskustva i podržava razgovor o sukobnim informacijama i nesigurnosti koje mogu rezultirati iz multimodalnih iskustva. EMISSOR može snimiti i annotirati eksperimente u virtualnom i stvarnom svijetu, kombinirati podatke, procijeniti sustavno ponašanje i njihovo učinkovito za predpostavljene ciljeve, ali također modelirati akumulaciju znanja i interpretacija u grafiku znanja kao rezultat tih episodijskih iskustava.', 'da': 'Vi præsenterer EMISSOR: en platform til at fange multimodale interaktioner som optagelser af episodiske oplevelser med eksplicitte referentielle fortolkninger, der også giver en episodisk vidensgraf (eKG). Platformen gemmer strømme af flere modaliteter som parallelle signaler. Hvert signal er segmenteret og annoteret uafhængigt med fortolkning. Anmærkninger kortlægges i sidste ende til eksplicitte identiteter og relationer i eKG. Når vi jordsignalsegmenter fra forskellige modaliteter til samme instans repræsentationer, jordbaserer vi også forskellige modaliteter på tværs af hinanden. Unikt for vores eKG er, at det accepterer forskellige fortolkninger på tværs af modaliteter, kilder og erfaringer og understøtter ræsonnement over modstridende oplysninger og usikkerheder, der kan resultere i multimodale erfaringer. EMISSOR kan registrere og kommentere eksperimenter i virtuel og virkelig verden, kombinere data, evaluere systemadfærd og deres ydeevne til forudindstillede mål, men også modellere akkumuleringen af viden og fortolkninger i Knowledge Graph som et resultat af disse episodiske oplevelser.', 'de': 'Wir präsentieren EMISSOR: eine Plattform zur Erfassung multimodaler Interaktionen als Aufzeichnungen episodischer Erfahrungen mit expliziten referenziellen Interpretationen, die auch einen episodischen Knowledge Graph (eKG) ergeben. Die Plattform speichert Streams mehrerer Modalitäten als parallele Signale. Jedes Signal wird separat mit Interpretation segmentiert und kommentiert. Anmerkungen werden schließlich expliziten Identitäten und Beziehungen im eKG zugeordnet. Wenn wir Signalsegmente von verschiedenen Modalitäten zu denselben Instanzdarstellungen erden, erden wir auch verschiedene Modalitäten untereinander. Einzigartig an unserem eKG ist, dass es unterschiedliche Interpretationen über Modalitäten, Quellen und Erfahrungen hinweg akzeptiert und die Argumentation über widersprüchliche Informationen und Unsicherheiten unterstützt, die sich aus multimodalen Erfahrungen ergeben können. EMISSOR kann Experimente in der virtuellen und realen Welt aufzeichnen und kommentieren, Daten kombinieren, Systemverhalten und deren Leistung für voreingestellte Ziele bewerten, aber auch die Ansammlung von Wissen und Interpretationen im Knowledge Graph als Ergebnis dieser episodischen Erfahrungen modellieren.', 'id': 'Kami mempersembahkan EMISSOR: sebuah platform untuk menangkap interaksi multimodal sebagai rekaman pengalaman episodik dengan interpretasi referensi eksplisit yang juga memberikan sebuah Graf Pengetahuan episodik (eKG). Platform menyimpan aliran dari berbagai modalitas sebagai sinyal paralel. Setiap sinyal disegmen dan dicatat secara independen dengan interpretasi. Anotasi akhirnya dipetakan untuk identitas dan hubungan eksplisit di eKG. As we ground signal segments from different modalities to the same instance representations, we also ground different modalities across each other.  Unik bagi eKG kami adalah bahwa ia menerima interpretasi yang berbeda melalui modalitas, sumber dan pengalaman dan mendukung pemikiran tentang informasi dan ketidakpastian konflik yang mungkin berasal dari pengalaman multimodal. EMISSOR can record and annotate experiments in virtual and real-world, combine data, evaluate system behavior and their performance for preset goals but also model the accumulation of knowledge and interpretations in the Knowledge Graph as a result of these episodic experiences.', 'sw': 'Tunawasilisha EMISSOR: jukwaa la kuchukua mahusiano mengi kama rekodi ya uzoefu wa episodia na tafsiri za wazi za maoni ambayo pia inaleta Graph ya Ujuzi (eKG). Jukwaa hilo linabeba mito ya aina mbalimbali kama ishara za usambazaji. Kila ishara imetengwa na kusikitishwa huru kwa tafsiri. Matangazo hatimaye yameporodheshwa ili kuweka wazi utambulisho na mahusiano kwenye eKG. Kama tunavyotumia vipengele vya saini kutoka katika namna tofauti hadi uwakilishi ule, pia tunatengeneza namna tofauti. Kikipekee kwa eKG ni kwamba inapokea tafsiri tofauti katika namna mbalimbali za namna, vyanzo na uzoefu na inaunga mkono kujadili kuhusu taarifa za mgogoro na usio na uhakika ambao unaweza kutokana na uzoefu wa watu wengi. EMISSOR inaweza rekodi na kutangaza majaribio katika ulimwengu wa kiraia na halisi, kuunganisha data, kutathmini tabia za mfumo na utendaji wao kwa malengo ya uboreshaji lakini pia anaweka mfano wa mkusanyiko wa maarifa na tafsiri katika Graph ya Ujuzi kutokana na uzoefu huu wa tukio hilo.', 'fa': 'ما EMISSOR را پیشنهاد می\u200cکنیم: یک Platform برای گرفتن تعاملات چندین مدل به عنوان ثبت تجربه\u200cهای episodic with explicit referential interpretations that also produce an episodic Knowledge Graph (eKG). پلاتورم رودها از چند روش به عنوان سیگنال\u200cهای parallel ذخیره می\u200cکند. هر سیگنال به خصوصی با تعبیر جدا می شود و به خصوصی با تعبیر مشخص می شود. توضیح\u200cها بالاخره به هویت\u200cهای مشخص و ارتباط در eKG نقشه\u200cبندی می\u200cشوند. همانطور که ما بخش\u200cهای سیگنال را از روش\u200cهای متفاوت به نمایش\u200cهای همان مثال می\u200cگذاریم، همچنین روش\u200cهای متفاوت را در میان همدیگر می\u200cگذاریم. یکسان به eKG ما این است که تفسیر های مختلف را در موارد، منبع و تجربه ها پذیرفته می کند و دلیل درباره اطلاعات و uncertaintiات مختلف را پذیرفته می کند که ممکن است نتیجه از تجربه های مختلف. EMISSOR می\u200cتواند آزمایش\u200cهای مجازی و دنیای واقعی را ثبت کند و آگاهی کند، داده\u200cها را ترکیب کند، رفتار سیستم و عملکرد آنها را برای هدف پیش\u200cاندازه\u200cها ارزیابی کند، و همچنین مدل جمع علم و تعبیر\u200cها در گراف دانش به نتیجه این تجربه\u200cهای episodic است.', 'ko': '우리는 EMISSOR: 하나의 플랫폼으로 다중모드적 상호작용을 포착하고 줄거리 체험의 기록으로서 명확한 참조 해석을 가지며 줄거리 지식도(eKG)도 형성했다.이 플랫폼은 다양한 모델의 흐름을 병렬 신호로 저장한다.모든 신호는 독립적으로 분할되고 주석되어 해석된다.메모는 eKG의 명시적 ID 및 관계식에 최종적으로 매핑됩니다.우리가 서로 다른 모드의 신호 구간을 같은 실례 표시에 접지할 때, 우리는 서로 다른 모드를 서로 접지할 것이다.eKG의 독특한 점은 서로 다른 모델, 출처와 경험의 다른 해석을 받아들이고 다중 모델 경험이 초래할 수 있는 충돌 정보와 불확실성에 대한 추리를 지원한다는 점이다.EMISSOR는 가상과 현실 세계의 실험을 기록하고 주석하며 데이터를 결합시켜 시스템 행위와 미리 설정한 목표의 성능을 평가하고 이러한 상황 경험에 따라 지식도에서 모델링 지식의 축적과 해석을 할 수 있다.', 'af': "Ons stel EMISSOR voor 'n platform a om multimodale interaksies as opneem van episodiese erfarings met eksplisiese verwysing wat ook 'n episodiese kennis graf (eKG) gee. Die platform stoor strome van veelvuldige modaliteite as parallele signale. Elke sein is segmenteerd en onvolledig aangeteken met uitlegging. Opmerkinge is eindelik gekap na eksplisiese identiteite en relasies in die eKG. Soos ons grond sein segmente van verskillende modaliteite tot dieselfde voorbeeld verteenwoordings, grond ons ook verskillende modaliteite oor mekaar. Unieke aan ons eKG is dat dit aanvaar verskillende uitleggings oor modaliteite, bronne en erfarings en ondersteun redening oor konfliksiende inligting en onversekerheid wat kan resultaat van multimodale erfarings. EMISSOR kan eksperimente in virtuele en reële wêreld opneem en annoteer, data kombinasie, stelsel gedrag en hulle uitvoering vir voorafinstelling doels, maar ook model die akumulasie van kennis en interpretasies in die kennis Graf as gevolg van hierdie episodiese erfarings.", 'tr': "EMISSOR'yu tanıtıyoruz: episodik tecrübelerin kayıtları ve episodik Bilgi Grafi(eKG) ile ilgili çok modal etkileşimleri yakalamak için bir plataforma sunuyoruz. Plataforma köp modüller arasynda parallel signaller ýaly gaýd edýär. Her sinyal bir beýik edildi we täzelikde boýunça terjime edildi. Döwürmeler iň soňunda eKG'deki belli kimlikler we baglaýyşlar üçin mappe edildi. Farklı modalardan aynı örnek ifadelerine sinyal segmentlerini yerleştirdiğimizde, birbirimizin farklı modüllerini de yerleştirdik. Biziň eKG üçin munyň üýtgeşik modüllerimiz, çeşmelerimiz we deneyimleriň arasynda farklı terjimeleri kabul edýär we näçe modal tecrübeleriniň netijesinden çykyp biljek maglumatlary we ynamlyklaryň üstünde düşünüşini destekleýär. EMISSOR wirtual we hakyky dünýäde deneyleri ýazyp bilýär, maglumatlary birleşdirýär, sistem davranışyny we olaryň ön bellenen hedeflerde etkinleşmelerini çykyp bilýär we bilgi Grafdaky terjimeleriň birleşmesini bu episodik deneyleriň netijesi üçin örän çykyp bilýär.", 'am': 'የኢሜስኮር አካባቢ እውቀት ግራፍ (eKG) በሚያሳየው የአፍሪካዊ ትርጓሜዎችን ለማሳየት የብዙኃን ተግባር ማቀናቀል እናስገራለን፡፡ አዲስ ዶሴ ፍጠር ሁሉም ሲክሎ በተለየ እና በተለየ በተለየ ትርጓሜ ይታሰራል፡፡ አቀማመጥ ከልዩ ልዩ ዓይነቶች ወደ አንድ ምሳሌ እናደርጋለን፡፡ ለeKG የተለየ ልዩ ልዩ ትርጓሜዎችን በዓይነት፣ መልዕክቶች እና ፈቃድ የሚቀበል እና በተጨማሪው መረጃዎች እና በተጨማሪው ግንኙነት ላይ የሚወስደውን እና የማይታወቀውን መነጋገር ይረዳል፡፡ EMISSOR የውይይት እና እውነተኛ ዓለም ፈተናዎችን ማሰብሰብ ይችላል፣ ዳታዎችን፣ የስርዓቱን ሁኔታ እና የእውቀትን እና ትርጓሜዎችን ለማሳየት ይችላል፡፡ ግን በዚህ አካባቢ ክፍተት ምክንያት እውቀትን እና ትርጓሜዎችን ለመሰብሰብ ይችላል፡፡', 'az': "Biz EMISSOR: çoxlu modal müxtəlif müxtəlif müxtəlif müxtəlif təcrübələrin episodik təcrübələrinin yazılması üçün bir platformu göstəririk ki, bu da episodik Bilgi Grafi (eKG) olar. Platforma çoxlu modüllərin səviyyələrini paralel sinyallər kimi sakin edir. Hər sinyal təfsil ilə segment edilir və təfsil edilir. Qiyamət sonunda eKG'nin açıq-aydın kimlikləri və əlaqələri ilə xəritələnir. Biz fərqli modlərdən eyni nümunələrə qədər sinyal segmentlərini yerləşdirdikdə, bir-birimizin arasında fərqli modülləri də yerləşdiririk. Bizim eKG-lərimizə eyni ola bilər ki, o, modüllər, kaynaqlar və təcrübələr arasında fərqli təfsirləri qəbul edər və çoxlu modal təcrübələrdən sonrakı müxtəlif məlumatlar və məlumatlar barəsində mübahisə etməyi və təhlükəsizlikləri dəstəkləyir. EMISSOR Virtual və real dünyada təcrübələr kaydedir və annotate edər, məlumatları birləşdirir, sistem davranışlarını və təcrübələrini əvvəlcə hazırlanmış məqsədilər üçün təcrübə edər, lakin bu episodik təcrübələrin səbəbi olaraq Bilim Grafındakı elm və təcrübələrinin birliklənməsini modellendirir", 'sq': 'Ne paraqesim EMISSOR: një platform ë për të kapur ndërveprimet multimodale si regjistrime të përvojave episodike me interpretime të qarta referenciale që japin gjithashtu një grafik episodik të njohurive (eKG). The platform stores streams of multiple modalities as parallel signals.  Çdo sinjal është segmentuar dhe shënuar në mënyrë të pavarur me interpretim. Anotacionet përfundimisht janë hartuar për identitetet dhe marrëdhëniet eksplicite në eKG. Ndërsa ne i themi segmentet e sinjalit nga modalitetet e ndryshme në përfaqësimet e të njëjtit rast, ne gjithashtu themi modalitete të ndryshme mes vete. Unique to our eKG is that it accepts different interpretations across modalities, sources and experiences and supports reasoning over conflicting information and uncertainties that may result from multimodal experiences.  EMISSOR mund të regjistrojë dhe të anotojë eksperimentet në botën virtuale dhe reale, të kombinojë të dhënat, të vlerësojë sjelljen e sistemit dhe performancën e tyre për qëllimet e paracaktuara por gjithashtu të modelojë akumulimin e njohurive dhe interpretimeve në grafikun e njohurive si rezultat i këtyre përvojave episodike.', 'hy': 'Մենք ներկայացնում ենք ԷՄԻՍՍՕՌ՝ մի հարթակ, որն արտացոլում է բազմամոդալ փոխազդեցությունները որպես հաճախիկ փորձառությունների ձայնագրություններ բացատրական վերաբերյալ մեկնաբանություններով, որոնք նաև հանգեցնում են գիտելիքի հաճախ գրաֆի (eKG). Աշխարհային հարթակը բազմաթիվ միջոցների հոսքեր է պահպանում որպես զուգահեռ ազդանշաններ: Each signal is segmented and annotated independently with interpretation.  Անտորակները վերջապես քարտեզագրված են eKG-ում բացատրված ինքնությունների և հարաբերությունների համար: Երբ մենք տարբեր միջոցներից մինչև նույն օրինակի ներկայացումներ ենք կազմում, մենք նաև տարբեր միջոցներ ենք կազմում միմյանց միջև: Մեր eKG-ի համար միանգամայն այն է, որ այն ընդունում է տարբեր մեկնաբանություններ տարբեր միջոցներում, աղբյուրներում և փորձառություններում, և աջակցում է բանավեճը բախում տեղեկատվության և անորոշությունների մասին, որոնք կարող են առաջացնել բազմամոդային փոր ԷՄԻՍՍՕրը կարող է ձայնագրել և նշում վիրտուալ և իրական աշխարհում փորձարկումներ, համադրել տվյալներ, գնահատել համակարգի վարքագիծը և դրանց արտադրողությունը նախասահմանված նպատակների համար, բայց նաև մոդելներ կազմել գիտելիքների և մեկնաբանությունների հավաքածուն գիտելիքների և մեկնաբանությունների մասին գիտելիք', 'ca': "Presentam EMISSOR: una plataforma per capturar interaccions multimodals com gravacions d'experiències episòdiques amb interpretacions referencials explícites que també donen un gràfic episòdic del coneixement (eKG). La plataforma emmagatzema corrents de múltiples modalitats com senyals paralèls. Cada senyal es segmenta i s'anota independentment de l'interpretació. Les anotacions estan eventualment mapeades per identitats i relacions explícites a l'eKG. Mentre compartim segons terrestres de diferents modalitats fins a representacions de la mateixa instancia, també compartim diferents modalitats entre elles. L'únic per al nostre eKG és que accepta diferents interpretacions entre modalitats, fonts i experiències i suporta el raonament sobre informació i incertituds en conflicte que poden resultar d'experiències multimodals. EMISSOR pot gravar i anotar experiments en món virtual i real, combinar dades, evaluar el comportament del sistema i el seu rendiment per als objectius predefinits, però també modelar l'acumulació de coneixements i interpretacions a la Gràfica del Conèixement com a resultat d'aquestes experiències episodiques.", 'bs': 'Predstavljamo EMISSOR: platformu za hvatanje multimodalnih interakcija kao snimanje episodijskih iskustava sa eksplicitim referencijskim interpretacijama koji također donose episodijski grafik znanja (eKG). Platforma čuva struje višestrukih modaliteta kao paralelne signale. Svaki signal je segmentiran i annotiran nezavisno sa interpretacijom. Anotacije su na kraju mapirane na pojasne identitete i odnose u eKG-u. Dok smo podmetnuli segmente signala iz različitih modaliteta do istog primjera, također smo podmetnuli različite modalitete međusobno. Jedino od naših eKG-a je da prihvata različite interpretacije preko moda, izvora i iskustva i podržava razgovor o sukobnim informacijama i nesigurnostima koje mogu rezultirati iz multimodalnog iskustva. EMISSOR može snimiti i annotirati eksperimente u virtualnom i realnom svijetu, kombinirati podatke, procijeniti sistemsko ponašanje i njihovo učinkovito za predstavljene ciljeve, ali također modelirati akumulaciju znanja i interpretacija u grafiku znanja kao rezultat ovih episodijskih iskustava.', 'et': 'Esitleme EMISSOR: platvormi multimodaalsete interaktsioonide jäädvustamiseks episoodiliste kogemuste salvestustena selgete viitetõlgendustega, mis annavad ka episoodilise teadmisgraafiku (eKG). Platvorm salvestab paralleelsete signaalidena mitmesuguseid vooge. Iga signaal on segmenteeritud ja märgitud sõltumatult tõlgendamisega. Annotatsioonid kaardistatakse lõpuks eKG selgete identiteetide ja suhetega. Kui maandame erinevatest mudelitest erinevate signaalide segmendid samade eksemplaride esitamiseks, maandame ka erinevaid mudeleid üksteise vahel. Meie e-KG jaoks on ainulaadne see, et see aktsepteerib erinevaid tõlgendusi eri viiside, allikate ja kogemuste vahel ning toetab arutelusid vastuolulise teabe ja ebakindluse üle, mis võivad tuleneda multimodaalsetest kogemustest. EMISSOR suudab salvestada ja märkida virtuaalses ja reaalses maailmas eksperimente, kombineerida andmeid, hinnata süsteemi käitumist ja nende jõudlust eelnevalt seatud eesmärkide saavutamiseks, kuid samuti modelleerida teadmiste ja tõlgenduste kogumist teadmistegraafikus nende episoodiliste kogemuste tulemusena.', 'bn': 'আমরা EMISSOR উপস্থাপন করছি: একটি প্ল্যাটফর্ম যাতে বিভিন্ন অভিজ্ঞতার রেকর্ডিং হিসেবে মাল্টিমোডাল ইন্টারজেক্টেশন গ্রাফ (ইকেজি) প্রকাশ্য পরিস্থিতির ব প্ল্যাটফর্মের সংরক্ষণ করা হয়েছে প্যারালেল সিগন্যাল হিসেবে। প্রত্যেক সিগন্যাল বিভক্ত এবং ব্যাখ্যা দিয়ে স্বাধীনভাবে বিরক্তিকর। শেষ পর্যন্ত ইকেজিতে পরিচয় এবং সম্পর্ক ব্যাখ্যা করার জন্য ঘোষণা ম্যাপ করা হয়েছে। যেহেতু আমরা বিভিন্ন ধরনের থেকে একই ধরনের প্রতিনিধিত্ব থেকে সিগন্যাল অংশ ভূমিকম্প, আমরা একে অপরের সাথে বিভিন্ন ধরনে আমাদের ইকেজির প্রতি একান্ত হচ্ছে যে এটি বিভিন্ন ধরনের, সূত্র এবং অভিজ্ঞতার সাথে বিভিন্ন ভাবে ব্যাখ্যা গ্রহণ করে এবং সংঘর্ষের তথ্য এবং নিশ্চ এমআইএসএসোর ভার্চুয়াল আর আসল বিশ্বের পরীক্ষার সংক্রান্ত পরীক্ষাগুলোকে রেকর্ড ও বিস্তারিত করতে পারে, তথ্য সংযোগ, সিস্টেমের আচরণ এবং প্রেসেট গোলের জন্য তাদের প্রকাশ', 'cs': 'Představujeme EMISSOR: platformu pro zachycení multimodálních interakcí jako záznamů epizodických zkušeností s explicitními referenčními interpretacemi, které rovněž vytvářejí epizodický znalostní graf (eKG). Platforma ukládá toky více modalit jako paralelní signály. Každý signál je segmentován a anotován nezávisle s interpretací. Anotace jsou nakonec mapovány na explicitní identity a vztahy v eKG. Když uzemňujeme segmenty signálu z různých modalit ke stejným reprezentacím instance, uzemňujeme také různé modality napříč sebou. Jedinečné pro naše eKG je, že přijímá různé interpretace napříč modalitami, zdroji a zkušenostmi a podporuje uvažování o konfliktních informacích a nejistotách, které mohou vyplývat z multimodálních zkušeností. EMISSOR dokáže zaznamenávat a anotovat experimenty ve virtuálním i reálném světě, kombinovat data, vyhodnocovat chování systému a jejich výkonnost pro přednastavené cíle, ale také modelovat akumulaci znalostí a interpretací v Knowledge Graph jako výsledek těchto epizodických zkušeností.', 'fi': 'Esittelemme EMISSOR: alustan multimodaalisten vuorovaikutusten tallentamiseksi episodisten kokemusten tallennuksi eksplisiittisillä viitetulkinnoilla, jotka tuottavat myös episodisen tietokaavion (eKG). Alusta tallentaa useita modaalisia virtoja rinnakkaisina signaaleina. Jokainen signaali on segmentoitu ja merkitty itsenäisesti tulkinnan avulla. Huomautukset kartoitetaan lopulta eksplisiittisiin identiteetteihin ja suhteisiin eKG:ssä. Kun maadoitamme signaalisegmentit eri modaliteeteista samoihin instanssiesityksiin, maadoitamme myös eri modaliteetit toisiinsa. Ainutlaatuinen eKG:lle on se, että se hyväksyy erilaisia tulkintoja eri muodoista, lähteistä ja kokemuksista ja tukee päättelyä ristiriitaisista tiedoista ja epävarmuuksista, jotka voivat johtua multimodaalisista kokemuksista. EMISSOR voi tallentaa ja kommentoida kokeiluja virtuaali- ja reaalimaailmassa, yhdistää dataa, arvioida järjestelmän käyttäytymistä ja niiden suorituskykyä ennalta asetettuihin tavoitteisiin, mutta myös mallintaa tiedon ja tulkintojen kertymistä Knowledge Graphiin näiden episodisten kokemusten tuloksena.', 'sk': 'Predstavljamo EMISSOR: platformo za zajemanje multimodalnih interakcij kot posnetkov episodičnih izkušenj z eksplicitnimi referenčnimi interpretacijami, ki ustvarjajo tudi episodični graf znanja (eKG). Platforma shranjuje tokove več modalitet kot vzporedni signali. Vsak signal je segmentiran in označen neodvisno z interpretacijo. Opombe so sčasoma preslikane v eksplicitne identitete in relacije v eKG. Medtem ko označujemo segmente signalov iz različnih modalij do istih predstavitev primerov, prav tako označujemo različne modalije med seboj. Edinstveno za našo e-KG je, da sprejema različne interpretacije med načini, viri in izkušnjami ter podpira razmišljanje o nasprotujočih si informacijah in negotovostih, ki so lahko posledica multimodalnih izkušenj. EMISSOR lahko beleži in označuje eksperimente v virtualnem in realnem svetu, združuje podatke, ocenjuje vedenje sistema in njihovo uspešnost za vnaprej nastavljene cilje, hkrati pa tudi modelira kopičenje znanja in interpretacij v grafu znanja kot rezultat teh episodičnih izkušenj.', 'ha': "Tuna halatar da EMIS SOR: wata platform da za'a kãma multi-multi-interaction kamar rekodin masu farin agodi da fassarar fassarar da bayyane na fassarar fassarar da ke ƙara fassarar Sann Nan (eKG). @ info An raba kõwace alama kuma aka cũtar da shi kaɗai da fassarar. Ana sakan sunan zuwa ƙarshen aka saka wa bayani masu bayyani da tsaro cikin eKG. Kayya da Muke bakin rabon sigogi daga shirin ayuka daban-daban zuwa misali guda, ko kuma muna saka hanyõyi dabam-daban. Yana da amfani ga eKG ko kuwa, shi yana karɓi fassarar-fassarar dabam a cikin shirin taƙaitori, masu sourcen da erfari, kuma yana ƙarfafa masu yin husũma a cikin masu husũma da tsari masu motsi da masu yaƙĩni, masu yiwuwa tanã ƙara daga sharuɗe masu yawa. EMIS SOR yana iya rekogi da bayani cikin masu cikin duniya iya iya fara-rubutu, kuma yana samun data, yana iya ƙaddara aikin muhimmanci da aikin muhimmanci, kuma yana sami ƙaramako da ilmi da fassararsu a cikin Narrafi kamar shawarar waɗannan masu basĩra.", 'he': "אנחנו מציגים EMISSOR: פלטפורמה לכלוף אינטראקציות multimodal כהקלטות של ניסיונות אפרודיות עם פרשנות רפורנציאליות ברורות הפלטפורמה מחסנת זרמים של מודיאליות רבות כאותים מקבילים. כל אות מוחלק ומכתב באופן עצמאי עם הפרשנות. הערות מופיעות בסופו של דבר לזהויות ומערכות יחסים ברורות באי.קיי.ג. כפי שאנחנו חולקים אות קרקעיים ממונדיות שונות לאותם מייצגים במקרה, אנחנו גם חולקים מודיות שונות אחד לשני. היחיד לאי-קיי-ג'י שלנו הוא שהוא מקבל פרשנות שונות ברחבי מודיאליות, מקורות ונסיונות ותמוך בהיגיון על מידע ונוודות מתנגדים EMISSOR יכול להקליט ולציין ניסויים בעולם וירטואלי ואמיתי, לשלב נתונים, להעריך התנהגות מערכת והביצועים שלהם למטרות מראש, אבל גם לדוגמא את האספור של ידע והפרשנות בגרף הידע כתוצאה מהניסיונות הפרודיות האלה.", 'bo': 'We present EMISSOR: a platform to capture multimodal interactions as recordings of episodic experiences with explicit referential interpretations that also yield an episodic Knowledge Graph (eKG). གླེང་སྒྲོམ་ནང་དུ་ཐབས་ལམ་འདྲ་ཞིག་དང་མཐུན་མིན་པ་བཞིན་ཉར་འཇོག་བྱེད་པ Each signal is segmented and annotated independently with interpretation. མཇུག་བསྡུ་ནས་གནད་དོན་དག་གི་ངོས་འཛིན་དང་འབྲེལ་བ་ཚོ་ནི་eKG ནང་དུ་ཆགས་པ་རེད། As we ground signal segments from different modalities to the same instance representations, we also ground different modalities across each other. ང་ཚོའི་eKG ལ་གཅིག་མཚུངས་པ EMISSOR CAN Virtual and real-world experiments in recording and annotate data, combine data, evaluate system behavior and their performance for preset goals but also model the accumulation of knowledge and interpretations in the Knowledge Graph as a result of these episodic experiences.', 'jv': 'Awak dhéwé éntuk EMIsSo: nggawe sistem kanggo nêmên interaksi multimodal karo kayalamat éntuk karo perbudhakan sing nyurangké nggawe barang dhéwé ngerasakno sing nyimpen soko ngono nggawe "knowknowknowknowGraph" (eKG). Laptop" and "Desktop Setung structural navigation Taning Unique kanggo eKG nambah punika ingkang sampeyan akeh mbukakipun karo modalité, penjelajah lan alam lan nggunakake informasi sing nggawe gerakan karo pakeh-apa kanggo ngerasakno sing bisa pasakno sing podho kara sampeyan operasi sing mengko EMIKSOR isa ngawe dadi lan alat kanggo ngerasahan perintah lan alat-sangan berusahaan data, nggawe barang sistem lan saiki perusahaan kanggo ngilanggar tarjamahan kanggo ngerasahan kanggo ngerasahan kanggo ngerasahan kanggo ngerasahan kanggo ngerasahan kanggo ngerasahan punika dianggap iki.'}
{'en': 'Incremental Unit Networks for Multimodal, Fine-grained Information State Representation', 'es': 'Redes de unidades incrementales para la representación multimodal y detallada del estado de la información', 'ar': 'تزايدي وحدة شبكات لتمثيل دولة المعلومات متعدد الوسائط دقيق الحبيبات', 'fr': "Réseaux d'unités incrémentiels pour une représentation fine et multimodale de l'état de l'information", 'pt': 'Redes de Unidades Incrementais para Representação do Estado de Informação Multimodal e Refinada', 'zh': '以多模态、细粒度息为增量单元网络', 'ru': 'Инкрементальные единичные сети для мультимодального представления состояния мелкозернистой информации', 'ja': 'マルチモーダルで細かい情報状態表現のためのインクリメンタルユニットネットワーク', 'hi': 'मल्टीमॉडल के लिए वृद्धिशील इकाई नेटवर्क, ठीक दानेदार सूचना राज्य प्रतिनिधित्व', 'ga': 'Líonraí Aonaid Incriminteach le haghaidh Ionadaíocht Stáit Faisnéise Ilmhódúil', 'el': 'Δίκτυα πρόσθετων μονάδων για την Πολυmodale, λεπτόκοκκη εκπροσώπηση του κράτους πληροφοριών', 'hu': 'Multimodális, finomszemű információs állam képviseletének növekvő egységhálózatai', 'it': "Reti di unità incrementali per la rappresentanza dello Stato dell'informazione multimodale e a grana fine", 'lt': 'Daugiamodalių, smulkių grūdų informacinės valstybės tinklų didinimas', 'kk': 'Көптеген, көптеген мәлімет күйінің бірліктіру желілері', 'mk': 'Интернет за екстрементални единици за мултимодијална, фина информациска состојба', 'ml': 'Multimodal, Fine- grayed Info State Representation', 'mt': 'Netwerks ta’ Unitajiet inkrementali għar-Rappreżentanza ta’ l-Istat ta’ l-Informazzjoni Multimodali u b’Ħruġ Fin', 'mn': 'Олон-моделийн, сайн жингийн мэдээллийн улс төрийн төлөөлөлт', 'ka': 'Multimodal, Fine grained Information State Representation for Incremental Unit Networks for Multimodal, Fine grained Information State Representation', 'no': 'Einingsnettverk for fleirmodal, fynnkorna informasjonstilstand', 'pl': 'Sieci jednostek przyrostowych dla multimodalnej, drobnoziarnistej reprezentacji państwa informacyjnego', 'ro': 'Rețele de unități incrementale pentru reprezentarea statului informațional multimodal, cu granule fine', 'sr': 'Povećavajuće mreže jedinica za multimodalnu, dobru informaciju državnu predstavnicu', 'si': 'ගොඩක් මොඩාල්, හොඳක් තොරතුරු තොරතුරු ස්ථානය නිර්මාණය සඳහා විශාලනය යුතුව', 'so': 'Internetka qaybta badnaanta ee wadamada macluumaadka ee badan', 'ms': 'Name', 'sv': 'Inkrementella enhetsnät för multimodal, finkornig informationsstatsrepresentation', 'ta': 'Multimodal, நன்றாக கிடைக்கப்பட்ட தகவல் நாட்டின் பிரதிபலகையில் உள்ள அலகு வலைப்பின்னல்கள்', 'ur': 'Multimodal, Fine-grained Information State Representation for Incremental Unit Networks for Multimodal, Fine-grained Information State Representation', 'uz': 'Name', 'vi': 'Bộ xây dựng mạng lưới truyền thông, phong độ', 'bg': 'Ингрементални мрежи за мултимодално, фино-зърнесто информационно представителство на държавата', 'hr': 'Povećavajuće mreže jedinica za višemodalnu, finu informativnu državu predstavljanje', 'id': 'Jaringan Unit Incremental untuk Perwakilan Negara Informasi Multimodal, Tinggi Terbaik', 'de': 'Inkrementelle Einheitennetze für multimodale, feinkörnige Information State Representation', 'nl': 'Incrementele eenheidsnetwerken voor multimodale, fijnkorrelige informatiestaatsvertegenwoordiging', 'da': 'Inkrementelle enhedsnet for multimodal, finkornet informationsstatsrepræsentation', 'fa': 'شبکه های واحد افزایش برای نمایش وضعیت اطلاعات زیادی', 'sw': 'Mtandao wa Kiungo cha Kuongezeka kwa ajili ya Taifa ya Taarifa, Taifa lililozungumzwa vizuri', 'af': 'Inkrementeel Eenheidnetwerke vir Multimodaal, Fin-graad Informasie Staat Voorstelling', 'sq': 'Rrjetet e njësisë inkrementale për përfaqësimin e shtetit të informacionit multimodal, me drithëra të holla', 'hy': 'Comment', 'ko': '다중모드, 세립도 정보 상태 표시에 사용되는 증량 단위 네트워크', 'az': 'Multimodal, Fine-grained Information State Representation for Incremental Unit Networks for Multimodal, Fine-grained Information State Representation', 'tr': 'Çoklumodal, süýşikli Maglumat Durumy Görkezilişi', 'bn': 'বহুমোডালের জন্য বেশী ইউনিট নেটওয়ার্ক, ভালো গ্রেফতার তথ্য স্টেট প্রতিনিধি', 'bs': 'Povećavajuće mreže jedinice za Multimodalnu, Fine-grained Information State Representative', 'ca': 'Incremental Unit Networks for Multimodal, Fine-grained Information State Representation', 'am': 'ምርጫዎች', 'et': 'Mitmeliigilise, peenestrateralise teabega üksuste võrgud Riigi esinduse jaoks', 'fi': 'Lisäyksikköverkot multimodaalisia, hienojakoisia tietoja varten Valtion edustusto', 'cs': 'Sítě inkrementálních jednotek pro multimodální, jemnozrnné zastoupení informačního stavu', 'jv': 'unit-format', 'sk': 'Pogradbena omrežja enot za multimodalno, drobnozrnato informacijsko predstavništvo države', 'he': 'רשתות יחידות נוספות עבור מייצגת מדינת מידע רבות ומודלית', 'ha': 'KCharselect unicode block name', 'bo': 'ཡར་རྒྱས་ཀྱི་ཆ་འཕྲིན་དང་སྐུད་ཆེ་བའི་ཆ་འཕྲིན་གནས་ཚུལ་གྱི་རྩ་སྒྲིག་འབྲེལ་མཐུད་དྲ་བ'}
{'en': 'We offer a fine-grained information state annotation scheme that follows directly from the Incremental Unit abstract model of dialogue processing when used within a multimodal, co-located, interactive setting. We explain the Incremental Unit model and give an example application using the Localized Narratives dataset, then offer avenues for future research.', 'ar': 'نحن نقدم مخططًا توضيحيًا دقيقًا لحالة المعلومات يتبع مباشرة من النموذج المجرد للوحدة المتزايدة لمعالجة الحوار عند استخدامه ضمن إعداد تفاعلي متعدد الوسائط ومشترك في الموقع. نشرح نموذج الوحدة الإضافية ونعطي مثالاً للتطبيق باستخدام مجموعة بيانات السرد المترجم ، ثم نقدم طرقًا للبحث في المستقبل.', 'fr': "Nous proposons un schéma d'annotation d'état d'information précis qui découle directement du modèle abstrait Incremental Unit du traitement du dialogue lorsqu'il est utilisé dans un environnement interactif multimodal, colocalisé et. Nous expliquons le modèle d'unité incrémentielle et donnons un exemple d'application utilisant le jeu de données Narratives localisées, puis proposons des pistes pour de futures recherches.", 'pt': 'Oferecemos um esquema de anotação de estado de informação de granularidade fina que segue diretamente do modelo abstrato de unidade incremental de processamento de diálogo quando usado em um ambiente multimodal, co-localizado e interativo. Explicamos o modelo de Unidade Incremental e damos um exemplo de aplicação usando o conjunto de dados de Narrativas Localizadas e, em seguida, oferecemos caminhos para pesquisas futuras.', 'es': 'Ofrecemos un esquema detallado de anotación del estado de la información que sigue directamente del modelo abstracto de unidad incremental de procesamiento de diálogos cuando se usa dentro de un entorno multimodal, co-ubicado e interactivo. Explicamos el modelo de unidades incrementales y damos una aplicación de ejemplo que utiliza el conjunto de datos de narrativas localizadas, y luego ofrecemos vías para futuras investigaciones.', 'ja': '私たちは、マルチモーダル、コロケーション、インタラクティブな設定で使用される場合、ダイアログ処理のインクリメンタルユニット抽象モデルから直接従う細かい情報状態注釈スキームを提供します。インクリメンタルユニットモデルを説明し、ローカライズされたナラティブデータセットを使用してアプリケーションの例を示し、将来の研究のための手段を提供します。', 'ru': 'Мы предлагаем мелкозернистую схему аннотации состояния информации, которая следует непосредственно из абстрактной модели обработки диалога Incremental Unit при использовании в мультимодальной, совместной, интерактивной среде. Мы объясняем модель инкрементной единицы и приводим пример приложения, используя набор данных Localized Narratives, а затем предлагаем пути для будущих исследований.', 'ga': 'Cuirimid scéim mhionsonraithe anótála stáit faisnéise ar fáil a leanann go díreach ó mhúnla teibí an Aonaid Incrimintigh de phróiseáil an chomhphlé nuair a úsáidtear é laistigh de shuíomh ilmhódach, comhlonnaithe, idirghníomhach. Mínímid múnla an Aonaid Incrimintigh agus tugaimid feidhmchlár samplach ag baint úsáide as an tacar sonraí Narratives Logánta, ansin cuirimid bealaí ar fáil le haghaidh taighde amach anseo.', 'zh': '臣等供细粒度注方案,当于多模式、共存、交互式置中用之,其径循对语者增量单元抽象。 释增量单元模形,本地化叙事数以示例应用程序之,然后为未来之道也。', 'hi': 'हम एक ठीक-ठाक जानकारी राज्य एनोटेशन योजना प्रदान करते हैं जो संवाद प्रसंस्करण के वृद्धिशील इकाई अमूर्त मॉडल से सीधे अनुसरण करता है जब एक मल्टीमॉडल, सह-स्थित, इंटरैक्टिव सेटिंग के भीतर उपयोग किया जाता है। हम वृद्धिशील इकाई मॉडल की व्याख्या करते हैं और स्थानीयकृत कथा डेटासेट का उपयोग करके एक उदाहरण एप्लिकेशन देते हैं, फिर भविष्य के शोध के लिए रास्ते प्रदान करते हैं।', 'ka': 'ჩვენ მივიღეთ სურათი ინფორმაციის სურათი ანოტაციის სქემი, რომელიც მულტიმედიალური, ერთადერთადერთადერთი, ინტერრაქტიური პარამეტრების მოდულის აბსტრაქტური მოდელზე, როდესაც გამოყენ ჩვენ განვიხსნათ მოდელს მოდილის მოდელს და დავუყვანეთ მაგალითი პროგრამის მონაცემების შესახებ ლოკალიზებული ნარატიგების მონაცემების შესახებ, შემდეგ მომავალ', 'hu': 'Egy finomszemcsés információs állapotjegyzési sémát kínálunk, amely közvetlenül a párbeszédfeldolgozás inkrementális egységeinek absztrakt modelljéből következik, ha multimodális, közös helyezésű, interaktív környezetben használják. Elmagyarázzuk az Incremental Unit modellt, és példaalkalmazást adunk a Localized Narratives adatkészletet használva, majd lehetőségeket kínálunk a jövőbeli kutatásokhoz.', 'el': 'Προσφέρουμε ένα λεπτόκοκκο σύστημα σχολιασμού κατάστασης πληροφοριών που ακολουθεί απευθείας από το αφηρημένο μοντέλο επεξεργασίας διαλόγων κατά τη χρήση σε ένα πολυπροπικό, συν-τοποθετημένο, διαδραστικό περιβάλλον. Επεξηγούμε το μοντέλο Προσωρινής Μονάδας και δίνουμε μια παραδειγματική εφαρμογή χρησιμοποιώντας το σύνολο δεδομένων Τοπικές Αφηγήσεις, στη συνέχεια προσφέρουμε τρόπους για μελλοντική έρευνα.', 'it': "Offriamo uno schema di annotazione dello stato delle informazioni a grana fine che segue direttamente dal modello astratto dell'unità incrementale di elaborazione dei dialoghi se utilizzato all'interno di un'impostazione multimodale, co-localizzata e interattiva. Spieghiamo il modello dell'unità incrementale e diamo un esempio di applicazione utilizzando il set di dati Narrative localizzate, quindi offriamo strade per la ricerca futura.", 'lt': 'Mes siūlome nuodugnią informacinės būklės anotacijų sistemą, kuri tiesiogiai atsiranda iš Incremental Unit abstraktaus dialogo apdorojimo modelio, kai naudojama daugiarūšio, bendrai esančioje, interaktyvioje aplinkoje. We explain the Incremental Unit model and give an example application using the Localized Narratives dataset, then offer avenues for future research.', 'mk': 'Ние нудиме фина информациска шема за анотација на состојбата која директно следи од апстрактниот модел на екстременталната единица за обработување на дијалогот кога се користи во мултимедално, колоцирано, интерактивно поставување. Го објаснуваме моделот на Експерменталната единица и даваме пример апликација со користење на локализираните податоци за наративи, потоа нудиме патишта за идно истражување.', 'ms': 'Kami menawarkan skema annotasi keadaan maklumat yang bersinar yang diikuti secara langsung dari model abstrak Unit Incremental pemprosesan dialog bila digunakan dalam tetapan interaktif multimodal, ditempatkan bersama. Kami menjelaskan model Unit Incremental dan memberikan aplikasi contoh menggunakan set data Narratives Lokal, kemudian menawarkan jalan untuk kajian masa depan.', 'ml': 'നമ്മള്\u200d ഒരു നല്ല വിവരങ്ങളുടെ അവസ്ഥ വിശദീകരണ പദ്ധതിയില്\u200d നിന്നും നേരെയായി പിന്തുടരുന്നുള്ള സംവാദത്തിന്റെ പ്രവര്\u200dത്തനത്തിന്റെ മോഡലില്\u200d നി നമ്മള്\u200d കൂടുതല്\u200d യൂണിറ്റ് മാതൃകയെ വിശദീകരിക്കുന്നു. ഒരു ഉദാഹരണമായ പ്രയോഗത്തിന്റെ ലോക്കലാക്കിയ നാറാറാറേറ്റിവിന്റെ', 'mt': 'Aħna noffru skema ta’ annotazzjoni tal-istat tal-informazzjoni b’qamħ fin li ssegwi direttament mill-mudell astratt tal-Unit à inkrementali tal-ipproċessar tad-djalogu meta użat f’ambjent multimodali, lokalizzat flimkien, interattiv. Aħna nistpjegaw il-mudell tal-Unit à inkrementali u nagħtu eżempju tal-applikazzjoni bl-użu tas-sett tad-dejta dwar in-Narrativi Lokalizzati, u mbagħad joffru mezzi għar-riċerka futura.', 'no': 'Vi tilbyr eit uttrykk informasjonstilstandsskjema som følgjer direkte frå den abstrakte modellen for dialoghandsaming av aukande einingar når det vert brukt i ein multimodal, co- plassert, interaktiv innstilling. Vi forklarer modellen «Incremental Unit», og gir eit eksempel program med datasettet «Localized Narratives», og tilbyr så avener for framtidige forskning.', 'pl': 'Oferujemy precyzyjny schemat adnotacji stanu informacji, który wynika bezpośrednio z abstrakcyjnego modelu jednostki przyrostowej przetwarzania dialogu w ramach multimodalnego, współlokacyjnego, interaktywnego otoczenia. Wyjaśniamy model jednostki przyrostowej i podajemy przykładową aplikację wykorzystującą zbiór danych Localized Narratives, a następnie oferujemy możliwości przyszłych badań.', 'ro': 'Oferim o schemă fină de adnotare a stării informațiilor care urmează direct din modelul abstract al procesării dialogurilor în unitatea incrementală atunci când este utilizat într-un cadru multimodal, co-localizat, interactiv. Explicăm modelul Unității Incrementale și oferim un exemplu de aplicație folosind setul de date Narrative localizate, apoi oferim căi pentru cercetarea viitoare.', 'sr': 'Nudimo dobar informativni sistem za annotaciju države koja prati direktno iz abstrakta model a obrade dijaloga povećane jedinice kada se koristi unutar multimodalnog, spolokalnog, interaktivnog nastavka. Objašnjavamo model pojedinačne jedinice i dajemo primjernu aplikaciju koristeći lokalizovani set podataka o narkoticima, a onda nudimo avenije za buduće istraživanje.', 'si': 'අපි හොඳ තොරතුරු ස්ථානයක් ප්\u200dරවේශනය කරනවා ඒ වගේම ප්\u200dරවේශනයක් විශාල සංවාදය ප්\u200dරවේශනයක් වගේම ප්\u200dරවේශනය කරන්න පුළුවන් විත අපි පැහැදිලි විශාල යුනිට් මොඩේල් එක්ක පැහැදිලි කරනවා සහ ස්ථානික විශාල පරීක්ෂණය සඳහා ස්ථානික විශාල', 'kk': 'Біз көптеген мәліметтің күй- жайлы жазбалар сұлбасын таңдаймыз. Бұл көптеген, бірнеше, бірнеше, интерактивті параметрлерде қолданылатын Диалогты Абстракт бірлігінен тұрақтық тү Біз Кеңейту бірлігінің моделін түсіндіріп, жергілікті нарративтер деректер жиынын қолдану үшін мысал қолданбаны таңдап, келесі зерттеулердің жолдарын таңдаймыз.', 'so': 'Waxaannu siinaynaa qorshaha dhibaatada xaaladda ee macluumaadka oo wanaagsan oo toos ka soo socda noocyada baaraandegista qoraalka marka lagu isticmaalayo xarumaha kala duduwan oo kala duduwan. Tusaalada Midhaha badnaanta waxaan u caddaynayaa tusaale ahaan codsiga ku isticmaalaya taariikhda diiwaangelinta, kadibna waxaynu bixinaa macluumaad baaritaanka mustaqbalka ah.', 'sv': 'Vi erbjuder ett finkornigt informationstillstﾃ･ndsanmﾃ､ltningsschema som fﾃｶljer direkt frﾃ･n den abstrakta modellen Incremental Unit fﾃｶr dialogbehandling nﾃ､r den anvﾃ､nds inom en multimodal, samlokaliserad, interaktiv miljﾃｶ. Vi fﾃｶrklarar Incremental Unit modellen och ger ett exempelprogram med hjﾃ､lp av datauppsﾃ､ttningen Localized Narratives, och erbjuder sedan vﾃ､gar fﾃｶr framtida forskning.', 'ta': 'நாம் ஒரு நன்றாக்கப்பட்ட தகவல் நிலை அறிவிப்பு முறைமை நாம் அதிகமான அலகு மாதிரி விளக்குகிறோம் மற்றும் ஒரு உதாரணத்தை பயன்படுத்துகிறோம் உள்ளூர்ந்த நாள்வியல் தகவல் அமைப்பை பயன்பட', 'mn': 'Бид олон моделийн, хамтран, интерактив тохиолдолд хэрэглэгдсэн диалог боловсруулах загвараас шууд дагаж ирсэн мэдээллийн байр суурь загварын загвар өгдөг. Бид нэмэлт нэгж загварыг тайлбарлаж, Локализацийн Narratives өгөгдлийн санг ашиглаж, дараа нь ирээдүйн судалгааны арга зам өгдөг.', 'ur': 'ہم ایک پاکیزہ اندھیر کی اطلاعات سٹیٹ انٹوریٹ سیکھی پیش کرتے ہیں جو مستقیماً مطالعہ یونیٹ کے مطالعہ سے سیدھی پیروی کرتی ہے جب ایک multimodal, co-located, interactive setting میں استعمال کیا جاتا ہے. ہم اضافہ یونیٹ موڈل کو توضیح دیتے ہیں اور ایک مثال اضافہ دیتے ہیں لیکولایز ناراریٹ ڈیٹ سٹ کے استعمال سے، پھر آینده تحقیق کے لئے رسائل پیش کرتے ہیں.', 'vi': 'Chúng tôi cung cấp một chương trình ghi chú trạng thái thông tin hoàn hảo theo trực tiếp từ mô hình trừu tượng trừu tượng của bộ phận cấu tạo thoại khi được dùng trong một thiết lập đa phương, đồng vị, tương tác. Chúng tôi giải thích mô hình đơn vị phức tạp và đưa ra một ứng dụng ví dụ, sử dụng bộ dữ liệu thời kỳ cục bộ, rồi cung cấp phương pháp nghiên cứu tương lai.', 'uz': 'Biz bir necha multimodal, bir xil boshqaruv, interaktiv moslamada ishlatilganda muloqat boshqaruv modelini aniqlab qoladi. Biz Birlik modelini faqat qilamiz va masalan dasturni Lokal Narrativ maʼlumotlar satridan foydalanamiz va keyin kelajakdagi qidirish uchun qoʻllanmalar beramiz.', 'da': 'Vi tilbyder en finkornet informationstilstand annotationsordning, der følger direkte fra den Incremental Unit abstrakte model for dialogbehandling, når den bruges i en multimodal, co-placeret, interaktiv indstilling. Vi forklarer Incremental Unit modellen og giver et eksempel program ved hjælp af Localized Narratives datasæt, og tilbyder derefter muligheder for fremtidig forskning.', 'nl': 'We bieden een gedetailleerd annotatieschema voor informatiestatus dat rechtstreeks volgt op het abstracte incremental unit model van dialoogverwerking wanneer gebruikt binnen een multimodale, co-located, interactieve setting. We leggen het Incremental Unit model uit en geven een voorbeeldtoepassing met behulp van de Localized Narratives dataset en bieden vervolgens mogelijkheden voor toekomstig onderzoek.', 'id': 'Kami menawarkan skema anotasi negara informasi yang baik yang mengikuti langsung dari model abstrak Unit Incremental dari proses dialog ketika digunakan dalam seting multimodal, co-lokasi, interaktif. Kami menjelaskan model Unit Incremental dan memberikan contoh aplikasi menggunakan dataset Narratives Lokalisasi, kemudian menawarkan jalan untuk penelitian masa depan.', 'bg': 'Предлагаме фина схема за анотация на състоянието на информацията, която следва директно от абстрактния модел на обработка на диалога при използване в мултимодална, съвместна, интерактивна настройка. Обясняваме модела на Incremental Unit и даваме примерно приложение, използвайки набора от данни Локализирани разкази, след което предлагаме възможности за бъдещи изследвания.', 'hr': 'Nudimo dobar informativni sistem državne annotacije koji slijedi direktno iz abstrakta model a obrade dijaloga povećane jedinice kada se koristi unutar multimodalnog, spolokalnog, interaktivnog nastavka. Objašnjavamo model pojedinačne jedinice i dajemo primjernu aplikaciju koristeći lokalizirani set podataka o narkoticima, a onda nudimo avenije za buduće istraživanje.', 'de': 'Wir bieten ein detailliertes Informationszustandsannotationsschema an, das direkt aus dem abstrakten Inkremental Unit-Modell der Dialogverarbeitung folgt, wenn es in einer multimodalen, co-located, interaktiven Umgebung verwendet wird. Wir erläutern das Inkremental Unit Modell und geben eine Beispielanwendung anhand des Datensatzes Localized Narratives an und bieten dann Möglichkeiten für zukünftige Forschung.', 'fa': 'ما یک نقشه اظهار وضعیت اطلاعات قطعی را پیشنهاد می\u200cکنیم که مستقیما از مدل مطلق واحد افزایش از پرداخت محاورۀ محاورۀ محاورۀ چندین مدل، همکاری، پیروی می\u200cکند. ما مدل واحد افزایش را توضیح می\u200cدهیم و یک کاربرد مثال را با استفاده از مجموعه داده\u200cهای ناراحتی محلی می\u200cدهیم، سپس راه\u200cها برای تحقیقات آینده پیشنهاد می\u200cدهیم.', 'sw': 'Tunatoa mpango wa uchunguzi wa hali ya taarifa mzuri ambao unafuata moja kwa moja kutoka kwa mfumo wa kutetea mazungumzo wakati unatumiwa ndani ya mazingira ya watu wengi, yenye ushirikiano. Tunaelezea modeli ya Umoja wa Kiongezeko na kutoa mfano kwa kutumia seti ya taarifa za Kinarratives nchini humo, kisha kutoa misingi kwa ajili ya utafiti wa baadaye.', 'ko': '우리는 다중 모드, 공통 포지셔닝, 상호작용 설정에서 사용할 때 대화 처리의 증량 단원 추상 모델을 직접 따르는 세분도 정보 상태 주석 방안을 제공했다.우리는 증량 단원 모델을 설명하고 현지화 서사 데이터 집합을 사용하는 예시적인 응용을 제시한 다음에 미래의 연구에 경로를 제공했다.', 'af': "Ons gee 'n fyn- graan inligting staat annotasie skema wat direk volg van die Incremental Unit abstrak model van dialoog verwerking wanneer gebruik word binne 'n multimodaal, co- located, interaktief instelling. Ons verduidelik die Incremental Unit model en gee 'n voorbeeld aansoek wat gebruik die Lokaliseerde Narratiewe datastel, en dan offer aveniers vir toekomstige forsoek.", 'tr': 'Biz g체첵챌li maglumat t채blisasinden gelen bir m철h체m maglumat t채blisasinden teklip ed첵채ris Biz K철챌ekme Birim nusgasyny d체힊체ndir첵채ris we 첵erle힊dirilen Narrative흫 veri setirini ulanyp 철r채n bir uygulama bererik we so흫ra gelejek ara힊tyrmalar 체챌in 챌채releri teklip et.', 'am': 'We offer a fine-grained information state annotation scheme that follows directly from the Incremental Unit abstract model of dialogue processing when used within a multimodal, co-located, interactive setting.  እናሳውቃለን የአስታክል ብሔራዊ ምሳሌ እናስገልጣለን፣ እና የአገራዊ ናራይት ዳታተር ሲጠቀም ምሳሌ እናደርጋለን፡፡', 'az': 'Biz √ßoxlu modal, birl…ôŇüdirilmiŇü, interaktiv quruluŇü i√ßind…ô istifad…ô edil…ôn, √ßoxlu modal, birl…ôŇüdirilmiŇü, m√ľxt…ôlif bir birl…ôŇüdirilmiŇü m…ôlumatlardan dońürudan istifad…ô ed…ôn m√ľ…ôyy…ôn bir m…ôlumat m…ôlumatńĪ taslańüńĪ t…ôklif edirik. Biz Incremental Unit modelini a√ßńĪqlayńĪrńĪq v…ô Lokalized Narratives veril…ônl…ôri vasit…ôsil…ô m…ôs…ôl uygulayńĪrńĪq, sonra g…ôl…ôc…ôk araŇütńĪrma √ľ√ß√ľn yollar t…ôblińü edirik.', 'hy': 'Մենք առաջարկում ենք մի գեղեցիկ տեղեկատվական վիճակի նոտացիայի ծրագիր, որը ուղղակի հետևում է Աճեցող միավորի վերացական մոդելուց, երբ այն օգտագործվում է բազմամոդալ, համատեղված, ինտերակտիվ միջավայրում: Մենք բացատրում ենք Increment միավորի մոդելը և մի օրինակ ենք տալիս, օգտագործելով տեղական պատմությունների տվյալների համակարգը, ապա հնարավորություն ենք տալիս ապագա հետազոտության համար:', 'bn': 'আমরা একটি সুন্দর তথ্য রাষ্ট্রের বিজ্ঞাপন পরিকল্পনা প্রদান করি যা সরাসরি বৃদ্ধিমান ইউনিট থেকে ডায়ালগ প্রক্রেশনের মডেল থেকে নিচে যায়, যখন ব্যবহার করা হয়, স আমরা ব্যাখ্যা করি ইউনিটের মডেল এবং স্থানীয় ন্যারাটিভেট ডাটাসেট ব্যবহার করে একটি উদাহরণ প্রয়োগ করি, তারপর ভবিষ্যত গবেষণার জন্য ভেন', 'ca': "Oferem un esquema d'anotació d'estat d'informació fina que segueix directament del model abstract de processament de diàleg de l'Unitat Incremental quan es utilitza dins un entorn interactiu multimodal, co-localitzat. We explain the Incremental Unit model and give an example application using the Localized Narratives dataset, then offer avenues for future research.", 'cs': 'Nabízíme detailní schéma anotace stavu informací, které vychází přímo z abstraktního modelu Inkremental Unit zpracování dialogu při použití v multimodálním, společně umístěném interaktivním prostředí. Vysvětlíme model inkrementální jednotky a uvádíme příklad aplikace s využitím datové sady Localized Narratives, poté nabízíme možnosti pro budoucí výzkum.', 'sq': 'Ne ofrojmë një skemë të hollësishme të anotacionit të shtetit të informacionit që pason drejtpërdrejt nga modeli abstrakt i njësisë inkrementale të procesimit të dialogut kur përdoret brenda një vendosje multimodale, bashkëpunuese dhe interaktive. We explain the Incremental Unit model and give an example application using the Localized Narratives dataset, then offer avenues for future research.', 'bs': 'Nudimo dobar informativni sistem za annotaciju države koje prati direktno iz abstrakta model a obrade dijaloga povećane jedinice kada se koristi unutar multimodalnog, kolokacije, interaktivnog nastavka. Objašnjavamo model pojedinačne jedinice i dajemo primjernu aplikaciju koristeći lokalizovani set podataka o narkoticima, a onda nudimo avenije za buduće istraživanje.', 'et': 'Pakume täpset infooleku annotatsiooniskeemi, mis järgib otse dialoogi töötlemise Incremental Unit abstraktset mudelit, kui seda kasutatakse multimodaalses, ühisasukohas, interaktiivses seadmes. Selgitame Incremental Unit mudelit ja anname näiteks rakenduse lokaliseeritud narratiivide andmekogumi abil, seejärel pakume võimalusi edasiseks uurimiseks.', 'fi': 'Tarjoamme hienojakoisen informaatiotilan merkintäjärjestelmän, joka seuraa suoraan Incremental Unit abstraktia dialogin käsittelyn mallia multimodaalisessa, yhteisesti sijoitetussa, interaktiivisessa ympäristössä. Selitämme Incremental Unit -mallia ja annamme esimerkkisovelluksen Lokalisoidut narratiivit -aineiston avulla, minkä jälkeen tarjoamme mahdollisuuksia tulevaisuuden tutkimukseen.', 'jv': 'Speaking Awak dhéwé ngerasakno model Unit Incretal lan ngewehi aplikasi nggawe dataset Narrate lokalised, njuk ngewehi mbukak kanggo sabêng-sabên kanggo ngerasakno', 'sk': 'Ponujamo drobnozrnato shemo označevanja informacijskega stanja, ki sledi neposredno iz abstraktnega modela obdelave dialoga Incremental Unit, kadar se uporablja v multimodalni, soolocacijski, interaktivni nastavitvi. Razložimo model Incrementalne enote in podamo primer aplikacije z uporabo nabora podatkov Lokaliziranih pripovedi, nato pa ponujamo možnosti za prihodnje raziskave.', 'ha': "Tuna bãyar da wani shirin alama na halin bayani mai kyau, wanda ke biyar bayani na shirin ayuka na IncIncInc Unit da ake nuna wa zauren akwatin bayani idan an yi amfani da shi a cikin wani tsari na sami da ake haɗa. Munã bayyana misãlin Umarni na Incinci kuma Munã bãyar wani misali da shirin ayuka da ke amfani da tsarin database na Lokal Narrative, sa'an nan Mu sami masu motsi ga research masu ƙarai.", 'bo': 'We offer a fine-grained information state annotation scheme that follows directly from the Incremental Unit abstract model of dialog processing when used in a multimodal, co-located, interactive setting. ང་ཚོས་རྒྱ་ཆེ་མཐོང་ཆུང་གི་མ་དབྱིབས་གསལ་བཤད་བྱས་ནས་ཉེར་སྤྱོད་ཅིག་སྤྱོད་ནས་རང་ཁུལ་སྤྱོད་པའི་Narratives གནད་སྡུད་ཆ་སྒྲི', 'he': 'אנו מציעים מערכת ציונים של מדינת מידע מעולה שמוציאה ישירות מהדוגמא המתוספת של יחידת הדיולוגים של מעבדת דיאלוגים כאשר משתמשת בתוך סדרה multimodal, משותפת, אינטראקטיבית. אנחנו מסבירים את דוגמא היחידה האינדרמנטלית ולתת דוגמא שימוש בשימוש במערכת הנתונים המקומית, ואז מציעים דרכים למחקר עתיד.'}
{'en': 'Teaching Arm and Head Gestures to a Humanoid Robot through Interactive Demonstration and Spoken Instruction', 'fr': 'Enseignement des gestes du bras et de la tête à un robot humanoïde par le biais de démonstrations interactives et', 'es': 'Enseñar gestos de brazos y cabeza a un robot humanoide a través de una demostración interactiva y una instrucción oral', 'pt': 'Ensinando gestos de braço e cabeça para um robô humanóide por meio de demonstração interativa e instrução falada', 'ar': 'تعليم إيماءات الذراع والرأس لإنسان آلي من خلال العرض التفاعلي والتعليمات المنطوقة', 'zh': '交互式教人形机器人教臂头手势', 'ja': 'インタラクティブなデモンストレーションとスポークンインストラクションを通じて、人型ロボットに腕と頭のジェスチャーを教える', 'ru': 'Обучение жестикуляции рук и головы гуманоидного робота посредством интерактивной демонстрации и устной инструкции', 'hi': 'इंटरैक्टिव प्रदर्शन और बोले गए निर्देश के माध्यम से एक Humanoid रोबोट के लिए हाथ और सिर इशारों शिक्षण', 'ga': 'Lámh agus Gothaí Cinn a Mhúineadh do Róbat Humanoid trí Thaispeántas Idirghníomhach agus Teagasc Labhartha', 'ka': 'სწავლება სახელის და სახელის გესტურები ადამიანოდის პრობოტისთვის ინტერქექტური დემონსტრაციის და სახელის ინსტრუქტურაციაში', 'hu': 'Tanító kar és fej gesztusok egy humanoid robotnak interaktív demonstráció és beszélt oktatás segítségével', 'el': 'Διδασκαλία χειρονομίας και κεφαλιού σε ανθρώπινο ρομπότ μέσω διαδραστικής επίδειξης και προφορικής διδασκαλίας', 'it': "Insegnare il braccio e i gesti della testa a un robot umanoide attraverso la dimostrazione interattiva e l'istruzione parlata", 'kk': 'Интерактивті демонстрациялау және бақылау құрылымы арқылы гуманойдық роботтарға қолдану мен айдарының меңзерін оқыту', 'ml': 'സൈന്യങ്ങളും ഹെഡ് ഗെസ്റ്റുകളും ഹുമാനോയിഡ് റോബോട്ടിലേക്ക് പഠിപ്പിക്കുന്നു', 'ms': 'Mengajar Gerakan Senjata dan Kepala kepada Robot Manusia melalui Pertunjukan Interaktif dan Instruksi Bercakap', 'mn': 'Хүн төрөлхтний роботын арм болон удирдлага багшлах нь Interactive Demonstration, Spoken Instruction-аар', 'mt': 'It-tagħlim tal-Ġesti tal-Armi u tal-Kap lil Robot Umaninoid permezz ta’ Demonstrazzjoni Interattiva u Istruzzjoni Kkellma', 'no': 'Læring av Arm- og Head- gestar til ein Humanoid Robot gjennom Interaktiv Demonstrasjon og Spoken Instruksjon', 'mk': 'Учитување на жести со раце и глава на хуманоиден робот преку интерактивна демонстрација и говорни инструкции', 'pl': 'Nauczanie gestów ramienia i głowy do humanoidalnego robota poprzez interaktywną demonstrację i instrukcję mówiącą', 'ro': 'Predarea brațului și a gesturilor capului unui robot umanoid prin demonstrație interactivă și instrucțiuni vorbite', 'sr': 'Nauèivanje ruke i glavnih gesta za humanoidni robot kroz interaktivnu demonstraciju i govornu instrukciju', 'si': 'ආයුධ සහ හෙඩ් ජෙස්ටර්ස් ඉගෙනීම් මිනිහෝඩ් රොබෝට් එක්ක ඉන්තර්ජාතික ප්\u200dරදේශනය සහ ස්පූක් නිර්ද', 'lt': 'Rankų ir galvos judesių mokymas humanoidiniam robotui naudojant interaktyvią demonstraciją ir kalbėtąsias instrukcijas', 'so': 'Teaching Arm and Head Gestures to a Humanoid Robot through Interactive Demonstration and Talk', 'sv': 'Undervisningsarm och huvudgester till en humanoid robot genom interaktiv demonstration och talade instruktioner', 'ur': 'ہتھیار اور سر گوسٹر کی تعلیم انسانی رابوٹ کے ذریعہ اضافہ دکھانے اور اسپاک ایسترک کے ذریعہ سے', 'ta': 'கையையும் தலைப்புக்குறிகளையும் கற்றுக்கொடுக்கும் இடைவெளி செயல் மற்றும் பேச்சு கட்டுப்பாட்டு', 'uz': 'Name', 'vi': 'Vũ khí và lực lượng chính học cho con người máy qua trình bày bày tương tác và phát ngôn viên', 'nl': 'Het onderwijzen van arm- en hoofdgebaren aan een humanoïde robot door middel van interactieve demonstratie en gesproken instructie', 'bg': 'Преподаване на жестове на ръка и глава на хуманоиден робот чрез интерактивна демонстрация и говорени инструкции', 'da': 'Undervisningsarm og hovedgester til en humanoid robot gennem interaktiv demonstration og talt instruktion', 'hr': 'Naučavanje oružja i glavnog gesta za humanoidni robot kroz interaktivnu demonstraciju i govornu instrukciju', 'ko': '인터랙티브 프레젠테이션과 구어 교육을 통해 모방 로봇에게 팔과 머리 제스처를 가르치다', 'de': 'Zeigen von Arm- und Kopfgesten an einen humanoiden Roboter durch interaktive Demonstration und gesprochene Instruktion', 'fa': 'آموزش اسلحه و دستگاه سر به رابوت انسانی از طریق نمایش\u200cسازی و دستورالعمل حرف زدن', 'sw': 'Kufundisha Jeshi na Makuu kwa Robot ya Humanoid kupitia Utamaduni wa Maandamano na Mazungumzo', 'tr': 'Teaching Arm and Head Gestures to a Humanoid Robot through Interactive Demonstration and Spoken Instruction', 'id': 'Mengajar Gerakan Senjata dan Kepala kepada Robot Manusia melalui Demonstrasi Interaktif dan Instruksi Bicara', 'sq': 'Duke mësuar lëvizje armësh dhe kokash për një robot humanoid nëpërmjet demonstracionit interaktiv dhe udhëzimeve të folura', 'hy': 'Ինտերակտիվ ցուցադրության և խոսքի միջոցով մարդկային ռոբոտին ձեռքերի և գլխավոր շարժումներ սովորեցնելը', 'az': 'ńįnter–į–ļ—ā–ł–≤ Demonstraciya v…ô Spoken Instruksiya vasit…ôsil…ô Humanoid Robotuna Arm v…ô Head Gestures √∂yr…ôtm…ôk', 'af': "Onderleer Arm en Hoofgestuur na 'n Humanoid Robot deur Interaktiewe Demonstracie en Spoken Instruksie", 'am': 'Arm and head Gestures to a Humanoid Robot through Interactive Demonstration and Spoken Instructions', 'bs': 'Naučavanje oružja i glavnog gesta humanitarnom robotu kroz interaktivnu demonstraciju i govornu instrukciju', 'ca': 'Ensenyar gests de braç i cap a un robot humanoida mitjançant una demostració interactiva i una instrucció parlada', 'et': 'Humanoidrobotile käe- ja peažestide õpetamine interaktiivse demonstratsiooni ja rääkiva juhendamise kaudu', 'bn': 'ইন্টারেক্টিভ ডিমোন্টেশন এবং কথোপকথন নির্দেশনার মাধ্যমে হাম্যানোয়াইড রোবটের সাথে সশস্ত্র এবং মাথার গ্যাস', 'cs': 'Výuka gesta ruky a hlavy humanoidnímu robotovi prostřednictvím interaktivní demonstrace a mluvené instrukce', 'fi': 'Käsi- ja pään eleiden opettaminen humanoidirobotille interaktiivisen demonstroinnin ja puhuttujen ohjeiden avulla', 'jv': 'Learning Arm lan Head Gegestes to a Human oyd Jobot throng interactive Monstration and Speakken Instruction', 'ha': 'Teaching gun and Head Gestures to a humanoid Robot through interactive Demoning and Talk Instructi', 'sk': 'Učenje kretnj roke in glave humanioidnemu robotu z interaktivno demonstracijo in govorjenimi navodili', 'he': 'מלמד תנועות זרוע וראש לרובוט אנושי באמצעות הפגינה אינטראקטיבית וההוראה מדברת', 'bo': 'Teaching Arm and Head Gestures to a Humanoid Robot through Interactive Demonstration and Spoken Instruction'}
{'en': 'We describe work in progress for training a ', 'pt': "Descrevemos o trabalho em andamento para treinar um robô humanóide para produzir gestos icônicos de braço e cabeça como parte da interação de diálogo orientada a tarefas. Isso envolve o desenvolvimento e uso de um gerenciador de diálogo multimodal para não especialistas para 'programar' rapidamente o robô através de fala e visão. Usando este gerenciador de diálogo, vídeos de demonstrações de gestos são coletados. As posições motoras são extraídas desses vídeos para especificar trajetórias motoras onde coleções de trajetórias motoras são usadas para produzir gestos de robôs seguindo uma abordagem de misturas gaussianas. A discussão final considera como as representações aprendidas podem ser usadas para reconhecimento de gestos pelo robô e como a estrutura pode amadurecer em um sistema para abordar o fundamento da linguagem e a representação semântica.", 'es': 'Describimos el trabajo en curso para entrenar a un robot humanoide para que produzca gestos icónicos de brazos y cabeza como parte de una interacción de diálogo orientada a tareas. Esto implica el desarrollo y el uso de un administrador de diálogo multimodal para que los no expertos «programen» rápidamente el robot a través del habla y la visión. Con este administrador de diálogos, se recopilan vídeos de demostraciones de gestos. Las posiciones del motor se extraen de estos vídeos para especificar las trayectorias del motor en las que se utilizan colecciones de trayectorias del motor para producir gestos robóticos siguiendo un enfoque de mezclas gaussianas. La discusión final considera cómo el robot puede utilizar las representaciones aprendidas para el reconocimiento de gestos y cómo el marco puede convertirse en un sistema para abordar la base del lenguaje y la representación semántica.', 'ar': 'نصف العمل الجاري لتدريب إنسان آلي على إنتاج إيماءات ذراع ورأس أيقونية كجزء من تفاعل حوار موجه نحو المهام. يتضمن ذلك تطوير واستخدام مدير حوار متعدد الوسائط لغير الخبراء من أجل "برمجة" الروبوت بسرعة من خلال الكلام والرؤية. باستخدام مدير الحوار هذا ، يتم جمع مقاطع فيديو لتوضيحات الإيماءات. يتم استخراج أوضاع المحرك من مقاطع الفيديو هذه لتحديد مسارات المحرك حيث يتم استخدام مجموعات من مسارات المحرك لإنتاج إيماءات الروبوت باتباع نهج الخلطات الغاوسية. تنظر المناقشة الختامية في كيفية استخدام التمثيلات المكتسبة للتعرف على الإيماءات بواسطة الروبوت ، وكيف يمكن أن ينضج الإطار إلى نظام لمعالجة أسس اللغة والتمثيل الدلالي.', 'fr': "Nous décrivons le travail en cours pour entraîner un robot humanoïde à produire des gestes emblématiques du bras et de la tête dans le cadre d'une interaction de dialogue axée sur les tâches. Cela implique le développement et l'utilisation d'un gestionnaire de dialogue multimodal permettant aux non-experts de «\xa0programmer\xa0» rapidement le robot par la parole et la vision. À l'aide de ce gestionnaire de boîtes de dialogue, des vidéos de démonstration de gestes sont collectées Les positions motrices sont extraites de ces vidéos pour spécifier des trajectoires motrices où des ensembles de trajectoires motrices sont utilisés pour produire des gestes de robot suivant une approche de mélanges gaussiens. La discussion finale examine comment les représentations apprises peuvent être utilisées pour la reconnaissance gestuelle par le robot, et comment le cadre peut devenir un système qui traite de la base du langage et de la représentation sémantique.", 'ja': '私たちは、タスク指向の対話の一部として、象徴的な腕と頭のジェスチャーを生成するヒューマノイドロボットをトレーニングするための進行中の作業について説明します。これには、非専門家のためのマルチモーダルダイアログマネージャーの開発と使用が含まれ、スピーチとビジョンを通じてロボットをすばやく「プログラム」します。このダイアログマネージャーを使用して、ジェスチャーデモのビデオを収集します。これらのビデオからモーターの位置を抽出して、モーターの軌道の集合がガウス混合アプローチに従ってロボットのジェスチャーを生成するために使用されるモーターの軌道を指定します。最後の議論は、学習された表現がロボットによるジェスチャー認識にどのように使用され得るか、およびフレームワークがどのように言語の接地および意味的表現に対処するためのシステムに成熟し得るかを考察する。', 'zh': '述人形机器人事,以生标志性臂头势,为向任之交。 此开用多模对话管理器,供非专家语音视疾"编程"机器人。 用此对话框管理器,可以收势视频。 取视频电机位以定电机迹,其电机合于斯而后生机器人势。 最后之议思之机器人以学表为手势,及框架熟为解语语义表征之统。', 'hi': "हम कार्य-उन्मुख संवाद बातचीत के हिस्से के रूप में प्रतिष्ठित हाथ और सिर के इशारों का उत्पादन करने के लिए एक ह्यूमनॉइड रोबोट को प्रशिक्षित करने के लिए प्रगति पर काम का वर्णन करते हैं। इसमें भाषण और दृष्टि के माध्यम से रोबोट को जल्दी से 'प्रोग्राम' करने के लिए गैर-विशेषज्ञों के लिए एक बहुआयामी संवाद प्रबंधक का विकास और उपयोग शामिल है। इस संवाद प्रबंधक का उपयोग करके, इशारे प्रदर्शनों के वीडियो एकत्र किए जाते हैं। मोटर पदों को इन वीडियो से मोटर प्रक्षेपवक्र निर्दिष्ट करने के लिए निकाला जाता है जहां मोटर प्रक्षेपवक्रों के संग्रह का उपयोग गाऊसी मिश्रण दृष्टिकोण के बाद रोबोट इशारों का उत्पादन करने के लिए किया जाता है। समापन चर्चा इस बात पर विचार करती है कि रोबोट द्वारा इशारे की पहचान के लिए सीखे गए अभ्यावेदन का उपयोग कैसे किया जा सकता है, और कैसे ढांचा भाषा ग्राउंडिंग और शब्दार्थ प्रतिनिधित्व को संबोधित करने के लिए एक प्रणाली में परिपक्व हो सकता है।", 'ru': 'Мы описываем текущую работу по обучению гуманоидного робота производству знаковых жестов рук и головы в рамках ориентированного на решение задач диалога. Это включает в себя разработку и использование мультимодального менеджера диалогов для не-экспертов, чтобы быстро «запрограммировать» робота через речь и зрение. С помощью этого диспетчера диалоговых окон собираются видеозаписи демонстраций жестов. Позиции двигателей извлекаются из этих видеороликов, чтобы указать траектории двигателей, где коллекции траекторий двигателей используются для создания жестов робота после подхода на основе гауссовых смесей. В заключительном обсуждении рассматривается, как полученные представления могут быть использованы для распознавания жестов роботом, и как фреймворк может созревать в систему для решения языкового обоснования и семантического представления.', 'ga': "Déanaimid cur síos ar an obair atá ar siúl chun róbat daonna a thraenáil chun gothaí íocónacha lámh agus cinn a tháirgeadh mar chuid d'idirphlé tasc-dhírithe. Is éard atá i gceist leis seo ná bainisteoir dialóige ilmhódaigh a fhorbairt agus a úsáid do dhaoine nach saineolaithe iad chun an róbat a ‘ríomhchlárú’ go tapa trí chaint agus trí fhís. Ag baint úsáide as an mbainisteoir dialóige seo, bailítear físeáin de thaispeántais gothaí. Baintear suíomhanna mótair as na físeáin seo chun conairí mótair a shonrú ina n-úsáidtear bailiúcháin de ruthairí mótair chun gothaí róbat a tháirgeadh de réir cur chuige meascáin Gaussach. Ag deireadh an phlé, breithnítear conas is féidir le róbait léirithe foghlamtha a úsáid chun gothaí a aithint, agus conas is féidir leis an gcreat a aibíocht ina chóras chun dul i ngleic le bunús teanga agus léiriú shéimeantach.", 'hu': 'Leírjuk a folyamatban lévő munkát egy humanoid robot képzésére, hogy ikonikus kar- és fejmozdulatokat készítsen a feladatorientált párbeszéd interakció részeként. Ez magában foglalja egy multimodális párbeszédkezelő fejlesztését és használatát a nem szakértők számára, hogy gyorsan "programozzák" a robotot beszéden és látáson keresztül. Ezzel a párbeszédkezelővel a gesztusbemutatók videóit gyűjtjük össze. A motorpozíciókat ezekből a videókból kivonjuk, hogy meghatározzák azokat a motorpályákat, ahol a motorpályák gyűjteményeit használják robotmozdulatok előállítására Gauss keverékek megközelítését követően. A záró beszélgetés azt vizsgálja, hogy a robot hogyan használhatja a tanult reprezentációkat a gesztusfelismeréshez, és hogyan fejlődhet ki a keretrendszer a nyelvi alapozás és a szemantikai reprezentáció kezelésére.', 'el': 'Περιγράφουμε εργασίες σε εξέλιξη για την εκπαίδευση ενός ανθρωποειδούς ρομπότ για να παράγει εμβληματικές χειρονομίες χεριών και κεφαλιού ως μέρος της αλληλεπίδρασης διαλόγου προσανατολισμένης στην εργασία. Αυτό περιλαμβάνει την ανάπτυξη και χρήση ενός πολυτροπικού διαχειριστή διαλόγου για μη εμπειρογνώμονες για να "προγραμματίσει" γρήγορα το ρομπότ μέσω ομιλίας και όρασης. Χρησιμοποιώντας αυτόν τον διαχειριστή διαλόγου, συλλέγονται βίντεο από επιδείξεις χειρονομίας. Οι θέσεις μηχανών εξάγονται από αυτά τα βίντεο για να καθορίσει τις τροχιές μηχανών όπου οι συλλογές τροχιών μηχανών χρησιμοποιούνται για την παραγωγή χειρονομίας ρομπότ ακολουθώντας μια προσέγγιση Gaussian μείγματα. Η τελική συζήτηση εξετάζει πώς οι διδαγμένες αναπαραστάσεις μπορούν να χρησιμοποιηθούν για την αναγνώριση χειρονομίας από το ρομπότ, και πώς το πλαίσιο μπορεί να ωριμάσει σε ένα σύστημα για την αντιμετώπιση της γλωσσικής γείωσης και της σημασιολογικής αναπαράστασης.', 'ka': "ჩვენ პროგრამის სამუშაოდ სამუშაო პრობოტის განაკეთებაში ადამიანიური პრობოტი, რომელიც იკონონიური ხელი და დესტურები გამოიყენებს, რომელიც დავამუ ეს არის მულტიმოდიალური დიალოგის მენეჯერის განვითარება და გამოყენება, რომელიც არ არის ექსპერტისთვის `პროგრამი' პრობოტის სიტყვებით და ხედავთ. ამ დიალოგის მენეჯერის გამოყენება, გესტურის დემონსტრაციების ვიდეოები შექმნა. მოტორული პოზეციები ამ ვიდეოდან გამოყენებულია მოტორული ტრაექტორიების განსაზღვრებისთვის, სადაც მოტორული ტრაექტორიების კოლექციები გამოყენებულია პრობოტის გექსტების გამოყენება დაუს პრობოტის განაცნობისთვის, როგორ პარამეტრები შეიძლება სისტემაში წარმოდგენოს, როგორ იყენება ენის ფონტურაციისთვის და სენმანტიკური განაცნობისთვის.", 'it': 'Descriviamo il lavoro in corso per addestrare un robot umanoide a produrre gesti iconici del braccio e della testa come parte dell\'interazione di dialogo orientata al compito. Ciò comporta lo sviluppo e l\'utilizzo di un gestore di dialogo multimodale per non esperti per "programmare" rapidamente il robot attraverso la parola e la visione. Utilizzando questo gestore di dialogo, vengono raccolti video di dimostrazioni gestuali. Le posizioni dei motori sono estratte da questi video per specificare traiettorie motorie in cui raccolte di traiettorie motorie sono utilizzate per produrre gesti robot seguendo un approccio di miscele gaussiane. La discussione conclusiva considera come le rappresentazioni apprese possano essere utilizzate per il riconoscimento dei gesti da parte del robot, e come il framework possa maturare in un sistema per affrontare la messa a terra del linguaggio e la rappresentazione semantica.', 'lt': 'Mes apibūdiname vykdomą darbą, skirtą mokymui humanoidiniam robotui gaminti ikoninius rankos ir galvos gestus kaip uždaviniams orientuotos dialogo sąveikos dalį. Tai apima daugiarūšio dialogo valdytojo kūrimą ir naudojimą ne ekspertams, kad greitai "programuotų" robot ą per kalbą ir viziją. Naudojant šį dialogo valdytoją surenkami gestų demonstracijų vaizdo įrašai. Iš šių vaizdo įrašų ištraukiamos variklio vietos, kuriose nurodomos variklio trajektorijos, kuriose variklio trajektorijų kolekcijos naudojamos robotiniams gestams gaminti, artėjant prie Gausijos mišinių. Galutinėje diskusijoje svarstoma, kaip robotas gali naudoti įgytas atstovavimas gestų pripažinimui ir kaip sistema gali tapti sistema, skirta kalbų pagrindui ir semantiniam atstovavimui spręsti.', 'kk': "Біз гуманоид роботты бақылау үшін тапсырманың бағытталған диалог интерфейсінің бір бөлігі ретінде тапсырмалар жұмысын жасау үшін түсіндіреміз. Бұл роботты сөйлеу мен көрініс арқылы `бағдарлама' деген көптеген диалог менеджерін жасау және қолдануға болады. Бұл диалог менеджерін қолдану үшін жұмыс демонстрацияларының видео жинақталады. Бұл видеодан моторлық орналасуы, Гауссияның микшерлерінен кейін роботты жұмыс істеу үшін моторлық траекторияларды келтіру үшін, моторлық траекторияларды таңдау үшін қолданылады. Дискуссияның соңында, роботтың жұмыс белгілерін қалай оқылған түсініктер қолданылатын жүйесіне жұмыс істеу және семантикалық түсініктерді қалай өзгертуге болады деп ойлайды.", 'mk': 'Ние ја опишуваме работата во тек за обука на хуманоиден робот за производство иконички гести на рака и глава како дел од дијалогот ориентиран на задачи интеракција. Ова вклучува развој и употреба на мултимодилен менаџер на дијалози за неексперти за брзо „ програмирање “ на роботот преку говор и визија. Користејќи го овој менаџер на дијалози, се собираат видеа од демонстрации на гест. Позициите на моторите се извадени од овие видеа за да се спецификуваат моторните траектории каде колекциите на моторните траектории се користат за производство на роботски гести по пристапот на гаусските мешавини. Конечната дискусија разгледува како може да се користат научени претставувања за признавање на гестот од страна на роботот, и како рамката може да порасне во систем за решавање на основата на јазикот и семантичното претставување.', 'ms': "Kami menggambarkan kerja yang sedang berlangsung untuk melatih robot humanoid untuk menghasilkan gerakan tangan ikonik dan kepala sebagai sebahagian dari interaksi dialog oriented tugas. Ini melibatkan pembangunan dan penggunaan pengurus dialog multimodal untuk bukan-ahli untuk cepat `program' robot melalui ucapan dan penglihatan. Dengan pengurus dialog ini, video demonstrasi gerakan dikumpulkan. Posisi enjin diekstrak dari video ini untuk nyatakan laluan enjin di mana koleksi laluan enjin digunakan untuk menghasilkan gerakan robot mengikut pendekatan campuran Gaussian. Diskusi akhir mempertimbangkan bagaimana perwakilan belajar boleh digunakan untuk pengenalan gerak oleh robot, dan bagaimana kerangka boleh dewasa ke dalam sistem untuk mengatasi pendaftaran bahasa dan perwakilan semantik.", 'mn': "Бид хүн төрөлхтний робот сургалтын тулд ажлыг тайлбарлаж тайлбарлаж тайлбарлаж, тайлбарлаж, удирдах хөдөлгөөн бүтээх нь ажлын төвөгтэй диалогын харилцааны нэг хэсэг болно. Энэ нь олон моделийн диалог менеджерын хөгжлийн болон ашиглах нь мэргэжилтнүүдийн биш програмыг илтгэл болон харааны аргаар хурдан `програм' гэх мэт. Энэ диалог менеджер ашиглан, хөдөлгөөн үзүүлэлтийн видео цуглуулагддаг. Эдгээр бичлэгээс мотор зам цуглуулалт гаргаж, Гаусийн цуглуулалтын дараа робот хөдөлгөөн үйлдвэрлэхэд хэрэглэгддэг мотор зам замыг тодорхойлж өгдөг. Дэлхийн дараа нь роботын хэрхэн сурсан үзүүлэлтийг хэрхэн ашиглаж болох вэ гэдгийг ойлгохын тулд, хэлний суурь, semantic үзүүлэлтийг хэрхэн ашиглаж болох вэ гэдгийг ойлгосон.", 'ml': "ഒരു മനുഷ്യന്\u200d റോബോട്ടിനെ പരിശീലിപ്പിക്കാന്\u200d പ്രവർത്തിക്കുന്ന പണിയെക്കുറിച്ച് ഞങ്ങള്\u200d വിവരിച്ചുകൊടുക്കുന്നു. ചി വിശിഷ്ടന്മാര്\u200dക്ക് വേഗത്തില്\u200d 'പ്രോഗ്രാം ചെയ്യാന്\u200d' റോബോട്ടിന് വേഗം സംസാരിക്കുന്നതിനും കാഴ്ചകളിലൂടെയും ഒരു പല ഈ ഡയലോഗ് മാനേജര്\u200d ഉപയോഗിക്കുന്നു, ഗസ്റ്റര്\u200d പ്രദര്\u200dശനങ്ങളുടെ വീഡിയോ സംഘടിപ്പിക്കപ്പെടുന്നു. ഈ വീഡിയോകളില്\u200d നിന്നും മോട്ടോര്\u200d ട്രാക്ടോറികള്\u200d പ്രത്യേകിപ്പിക്കാന്\u200d മോട്ടോര്\u200d സ്ഥാനങ്ങള്\u200d പുറത്തെടുക്കപ്പെടുന്നു സംസാരം വിചാരിക്കുന്നത് റോബോട്ടിന്റെ ഗെസ്റ്റേര്\u200d തിരിച്ചറിയാന്\u200d പഠിച്ച പ്രതിനിധികള്\u200d എങ്ങനെയാണ് ഉപയോഗിക്കുന്നതെന്നും സംശയം", 'no': 'Vi beskriver arbeidet i framdriving for å trenja ein humanoid robot for å produsera ikonske arm og hovudgester som del av dialogvindauget med oppgåver. Dette involverer utviklinga og bruk av ein multimodal dialoghandsamar for ikkje-ekspertar for å raskt «program» roboten gjennom tale og vising. Bruk denne dialoghandsamaren vert videoar av gesturedemonstrasjonar samla. Motorplasseringar vert pakka ut frå desse videoane for å spesifisera motortrajektorar der samlingar av motortrajektorar vert bruka for å produsera robot-gestar etter ein Gaussisk tilnærming. I slutten av diskusjon ser ut korleis lærte representasjonar kan brukast for å gjenkjenne gestar av roboten, og korleis rammeverket kan forstørra i eit system for å handtera språkkgrunnlegging og semantisk representasjon.', 'pl': 'Opisujemy trwające prace nad szkoleniem humanoidalnego robota do wytwarzania ikonicznych gestów ramienia i głowy w ramach dialogu zorientowanego na zadania. Obejmuje to opracowanie i wykorzystanie multimodalnego menedżera dialogu dla nieekspertów, aby szybko "programować" robota poprzez mowę i wizję. Za pomocą tego menedżera dialogowego gromadzone są filmy demonstracji gestów. Pozycje silników są ekstraktowane z tych filmów, aby określić trajektorie motoryczne, w których zbiory trajektorii motorycznych są wykorzystywane do wytwarzania gestów robota zgodnie z podejściem Gaussa mieszanek. Podsumowująca dyskusja rozważa, w jaki sposób nauczone reprezentacje mogą być wykorzystywane do rozpoznawania gestów przez robota, oraz w jaki sposób framework może dojrzeć do systemu zajmującego się uziemieniem języka i reprezentacją semantyczną.', 'mt': "Aħna niddeskrivu x-xogħol li qed isir għat-taħriġ ta’ robot umanojde biex jipproduċi ġesti ikoniċi tad-driegħ u tar-ras bħala parti mill-interazzjoni ta’ djalogu orjentat lejn ix-xogħol. This involves the development and use of a multimodal dialog manager for non-experts to quickly `program' the robot through speech and vision.  Bl-użu ta’ dan il-maniġer tad-djalogu, jinġabru vidjows ta’ dimostrazzjonijiet tal-ġesti. Il-pożizzjonijiet tal-mutur jiġu estratti minn dawn il-vidjows biex jispeċifikaw it-trajettorji tal-mutur fejn il-kollezzjonijiet tat-trajettorji tal-mutur jintużaw biex jipproduċu ġesti robotiċi wara approċċ ta’ taħlitiet Gaussjani. Id-diskussjoni konklużiva tikkunsidra kif ir-rappreżentazzjonijiet miksuba jistgħu jintużaw għar-rikonoxximent tal-ġesti mir-robot, u kif il-qafas jista’ jimmatura f’sistema li tindirizza l-bażi tal-lingwi u r-rappreżentazzjoni semantika.", 'sr': "Opišemo napredak rad za obuku humanoičnog robot a kako bi proizveli ikonsku ruku i geste glave kao deo interakcije sa orijentacijom na zadatke. To uključuje razvoj i korištenje multimodalnog menadžera dijaloga za ne-stručnike da brzo `program' robot a kroz govor i viziju. Koristeći ovaj menadžer dijaloga, prikupljeni su video demonstracija gesta. Motorne pozicije su izvedene iz ovih video da bi specificirali motorne puteve gde se kolekcije motornih putnika koriste za proizvodnju robotnih gesta nakon pristupa Gausijskih mješavina. Uključujući raspravu, razmišlja o tome kako se naučene predstave mogu koristiti za prepoznavanje gesta od strane robot a, i kako okvir može odrastati u sistem za rješavanje jezičkog osnova i semantičkog predstavljanja.", 'so': 'Waxaynu u qornaa shaqo horumarinta u tababarinta robotiga humanoid si aan u sameyno gacanta sawir ah iyo qalabka madaxa sida qayb ka mid ah sameynta diyaarinta shaqada. Taas waxaa ku saabsan horumarinta iyo isticmaalka maamulaha dialog kala duduwan oo aan khabiir-aqoon ahayn si dhaqso ah looga sameeyo robotiga hadal iyo muuqasho. Isku isticmaalaya maamulka diyaarinta waxaa lagu soo ururiyaa fiidiyowyada muuqashada gestur. Fiidiyowyadan waxaa laga soo saaraa goobaha gaadiidka si ay u gaaraan wadooyinka gaadiidka lagu soo ururiyo gaadiidka lagu isticmaalo in lagu sameeyo qalabka robotiga goobaha lagu isku qasto Gaussian. Xukumidda dhamaadka ayaa ka fiirsanaya sida loo isticmaali karo in lagu aqoonsado robotiga iyo siduu dhaqdhaqaaqyo nidaamka si uu ugu hadlo kooxda luqada iyo wakiilka kooxaha ah.', 'si': 'අපි මිනිස්සු රෝබෝට්ටුවක් ප්\u200dරශ්නයක් වෙනුවෙන් වැඩක් විස්තර කරනවා අයිකෝනික අතුරු හා ඔළු හැස්සුවක් වි මේකෙන් විශාලනය සහ භාවිතා කරන්න පුළුවන් විශේෂක නොවිශ්වාසකයෙක් වෙනුවෙන් විශාලනය සහ භාවිතා කරන්න. මේ සංවාද ප්\u200dරධානකය පාවිච්චි කරනවා, වීඩියෝ සංවිධානයක් සංවිධානය කරනවා. මෝටර් ස්ථානයක් මේ වීඩියෝ වලින් පිටවෙන්නේ මෝටර් ස්ථානයක් නිර්දේශ කරන්න මෝටර් ස්ථානයක් කිරීමට රොබෝට් ස්ථානයක රොබෝට් වලින් ප්\u200dරතිචාර පද්ධතියෙන් කොහොමද ඉගෙන ගත්ත ප්\u200dරතිචාරය පාවිච්චි කරන්න පුළුවන් කියලා, සහ කොහොමද පද්ධතියේ', 'ro': "Descriem lucrările în curs de desfășurare pentru instruirea unui robot umanoid pentru a produce gesturi iconice ale brațului și capului ca parte a interacțiunii de dialog orientate spre sarcini. Acest lucru implică dezvoltarea și utilizarea unui manager de dialog multimodal pentru non-experți pentru a `programa' rapid robotul prin vorbire și viziune. Folosind acest manager de dialog, sunt colectate videoclipuri cu demonstrații gestuale. Pozițiile motoarelor sunt extrase din aceste videoclipuri pentru a specifica traiectoriile motoarelor în care colecțiile de traiectorii motoarelor sunt utilizate pentru a produce gesturi robot după o abordare a amestecurilor gaussiene. Discuția finală ia în considerare modul în care reprezentările învățate pot fi utilizate pentru recunoașterea gesturilor de către robot și modul în care cadrul poate maturiza într-un sistem pentru a aborda bazarea limbajului și reprezentarea semantică.", 'ta': "நாம் முன்னேற்றத்தில் ஒரு மனித ஒளியை பயிற்சி செய்ய முன்னேற்றத்திற்கு விவரிக்கிறோம். சின்னம் கையை மற்றும் தலைப்பு க இது விரைவாக 'நிரல்' ரோபோட்டை பேச்சு மற்றும் பார்வையின் மூலம் விரைவாக உரையாடல் மேலாளருக்கு உருவாக்கத்தை பயன்படுத்த Using this dialog manager, videos of gesture demonstrations are collected.  இயந்திரக் குறிப்பிட இந்த வீடியோவிலிருந்து பொறியோர் நிலைகள் பெறுக்கப்பட்டுள்ளது ஒரு காய்சியன் கலந்துகள் செயல்பாட்டின் சேகரிப்ப முடிவு விவாதத்தை பார்க்கும் ரோபோட்டின் அறிவிப்புக்கு எவ்வாறு கற்றுக் கொண்டிருக்கும் பாதிப்புக் குறிப்புகளை பயன்படுத்தும்", 'sv': 'Vi beskriver pågående arbete för att utbilda en humanoid robot att producera ikoniska arm- och huvudgester som en del av uppgiftsorienterad dialog interaktion. Detta innebär utveckling och användning av en multimodal dialoghanterare för icke-experter att snabbt "programmera" roboten genom tal och vision. Med hjälp av den här dialoghanteraren samlas videor med gestdemonstrationer in. Motorpositioner extraheras från dessa videor för att specificera motoriska banor där samlingar av motoriska banor används för att producera robotgester efter en Gaussisk blandning metod. Avslutningsvis diskuteras hur lärda representationer kan användas för gestigenkänning av roboten, och hur ramverket kan mogna till ett system för att hantera språkgrundning och semantisk representation.', 'ur': "ہم ایک انسانی روبوت کی آموزش کے لئے کام کی توصیف کرتے ہیں کہ اسکانیک ہاتھ اور سر جستجو کو کام کی طرف متوجہ ہونے کی تعلیم کے لئے۔ یہ ایک multimodal dialog manager کی توسعہ اور استعمال ہے جو غیر متخصص لوگوں کے لئے سریع بات اور بینا کے ذریعہ روبوت کو 'پروگرام' کے لئے ہے. اس ڈیلوگ منڈیر کے استعمال سے، جستر نمایش کے ویڈیوں کو جمع کیا جاتا ہے. موٹر موٹر موقعیت کو ان ویڈیوں سے نکال دیا گیا ہے کہ موٹر ٹراجٹریس کو مشخص کرنے کے لئے جہاں موٹر ٹراجٹریس کی جماعتیں گاوسی میکسٹریس طریقے کے پیچھے روبوٹ جستر پیدا کرنے کے لئے استعمال کی جاتی ہیں. بحث کے ساتھ مشورہ کرتا ہے کہ کس طرح سکھایا گیا نمونات رابوت کے ذریعے جستر کی شناخت کے لئے استعمال کئے جاسکتے ہیں اور کیسے فرمود ایک سیستم میں بڑھائے جاسکتا ہے زبان کی بنیادی اور سیمنٹی نمونات کے ذریعے.", 'uz': "Biz odamoid robot yordamida ishni tahrirlash uchun tajriba qilamiz. Nishoncha qo'l va boshqa qo'llanmalarni vazifa bilan boshqa muloqat boshqarish bir qismi deb o'ylaymiz. Name Name Motor joylari Gaussiya mikrog tartiblar qoidadan foydalanadigan motor traktorlarini aniqlash uchun ishlatiladi. Davom etish muvaffaqiyatlarini anglatadi, robot yordamida qanday o'rganish imkoniyatlarini foydalanishi mumkin, va freym tilni guruhlash va semantik representiyatlarini boshqarish uchun tizimga qarshi mumkin.", 'vi': 'Chúng tôi mô tả công việc đang tiến hành để huấn luyện một robot người để tạo ra biểu tượng cánh tay và đầu cử chỉ như một phần của cuộc đối thoại hướng nhiệm vụ. Việc này liên quan đến việc phát triển và sử dụng quản lý hộp thoại đa phương cho người không chuyên gia để nhanh chóng "lập trình" robot qua ngôn ngữ và tầm nhìn. Sử dụng hộp thoại quản lý này, hãy thu thập các đoạn video biểu tình. Các vị trí cơ động được lấy ra từ các video để xác định đường dẫn vận động nơi các bộ sưu tập xe vận động được dùng để sản xuất các cử chỉ robot theo một phương pháp hoà giải kiểu Gauss. Những cuộc thảo luận kết thúc xem xét cách sử dụng các biểu tượng đã học để nhận dạng cử chỉ của robot, và cách thức cơ quan có thể phát triển thành một hệ thống để đối phó với nền văn học và phân biệt ngữ pháp.', 'nl': "We beschrijven werk in uitvoering voor het trainen van een humanoïde robot om iconische arm- en hoofdgebaren te produceren als onderdeel van taakgerichte dialooginteractie. Dit omvat de ontwikkeling en het gebruik van een multimodale dialoogmanager voor niet-experts om de robot snel te 'programmeren' via spraak en visie. Met behulp van deze dialoogmanager worden video's van gebarendemonstraties verzameld. Motorposities worden geëxtraheerd uit deze video's om motortrajecten te specificeren waarbij verzamelingen motortrajecten worden gebruikt om robotgebaren te produceren volgens een Gaussiaanse mengsels benadering. Concluderende discussie onderzoekt hoe geleerde representaties kunnen worden gebruikt voor gebarenherkenning door de robot, en hoe het framework kan rijpen tot een systeem om taalgronding en semantische representatie aan te pakken.", 'bg': 'Описваме текущата работа за обучение на хуманоиден робот да произвежда емблематични жестове на ръка и глава като част от диалогово взаимодействие, ориентирано към задачите. Това включва разработването и използването на мултимодален мениджър на диалог за неексперти, който бързо "програмира" робота чрез говор и зрение. С помощта на този мениджър на диалоговия прозорец се събират видеоклипове с демонстрации с жестове. Моторните позиции са извлечени от тези видеоклипове, за да се определят траекториите на двигателя, при които колекции от траектории на двигателя се използват за производство на роботи жестове, следвайки подход на гаусите смеси. В заключителната дискусия се разглежда как научените изображения могат да бъдат използвани за разпознаване на жестове от робота и как рамката може да узрее в система за справяне с езиковото заземяване и семантичното представяне.', 'de': 'Wir beschreiben Arbeiten zur Ausbildung eines humanoiden Roboters zur Herstellung ikonischer Arm- und Kopfgesten im Rahmen einer aufgabenorientierten Dialoginteraktion. Dies beinhaltet die Entwicklung und Verwendung eines multimodalen Dialogmanagers für Nicht-Experten, um den Roboter schnell durch Sprache und Sehen zu "programmieren". Mit diesem Dialog-Manager werden Videos von Gesten-Demonstrationen gesammelt. Aus diesen Videos werden Motorpositionen extrahiert, um Motortrajektorien zu spezifizieren, bei denen Ansammlungen von Motortrajektorien verwendet werden, um Robotergesten nach einem Gaußschen Mischungsansatz zu erzeugen. Abschließend wird untersucht, wie erlernte Repräsentationen für die Gestenerkennung durch den Roboter genutzt werden können und wie das Framework zu einem System zur sprachlichen Erdung und semantischen Repräsentation heranreifen kann.', 'hr': "Opisujemo napredak rad za obuku humanoičnog robot a kako bi proizveli ikonske ruke i geste glave kao dio interakcije dijaloga orientiranog na zadatke. To uključuje razvoj i upotrebu multimodalnog menadžera dijaloga koji ne znaju stručnjake brzo `program' robot a kroz govor i viziju. Koristeći ovaj menadžer dijaloga, prikupljaju se snimke demonstracija gesta. Motorne pozicije su izvučene iz ovih snimaka kako bi specificirali motorne puteve gdje se kolekcije motornih putnika koriste za proizvodnju robotnih gesta nakon pristupa Gausijskih mješavina. Uključujući raspravu, razmišlja o tome kako se naučeni predstavnici mogu koristiti za prepoznavanje gesta od strane robot a i kako okvir može odrastati u sustav za rješavanje jezičkog temelja i semantičkog predstavljanja.", 'da': "Vi beskriver igangværende arbejde med at træne en humanoid robot til at producere ikoniske arm- og hovedbevægelser som en del af opgaveorienteret dialog interaktion. Dette indebærer udvikling og brug af en multimodal dialog manager for ikke-eksperter til hurtigt at 'programmere' robotten gennem tale og vision. Ved hjælp af denne dialoghåndtering indsamles videoer af bevægelsesdemonstrationer. Motorpositioner udtrækkes fra disse videoer for at angive motoriske baner, hvor samlinger af motoriske baner bruges til at producere robotbevægelser efter en Gaussisk blandingsmetode. Den afsluttende diskussion overvejer, hvordan lærte repræsentationer kan bruges til gestus genkendelse af robotten, og hvordan rammen kan modnes til et system til at adressere sprogbaseret og semantisk repræsentation.", 'id': "Kami menggambarkan pekerjaan yang sedang dilanjutkan untuk melatih robot humanoid untuk menghasilkan gerakan ikonik lengan dan kepala sebagai bagian dari interaksi dialog orientasi tugas. Ini melibatkan pembangunan dan penggunaan manajer dialog multimodal untuk non-ahli untuk cepat `program' robot melalui pidato dan penglihatan. Menggunakan manajer dialog ini, video demonstrasi gerakan dikumpulkan. Motor positions are extracted from these videos to specify motor trajectories where collections of motor trajectories are used to produce robot gestures following a Gaussian mixtures approach.  Diskusi akhir mempertimbangkan bagaimana representation belajar dapat digunakan untuk pengenalan gerak oleh robot, dan bagaimana rangkaian dapat dewasa menjadi sistem untuk mengatasi dasar bahasa dan representation semantis.", 'ko': '우리는 사람을 모방하는 로봇을 훈련시켜 상징적인 팔과 머리 자세를 만들어 임무를 향한 대화의 상호작용의 일부로 삼고 있는 작업을 묘사했다.이것은 비전문가를 위해 다중모드 대화 관리자를 개발하고 사용하며 음성과 시각을 통해 로봇을 신속하게 프로그래밍하는 것과 관련된다.이 대화상자 관리자를 사용하면 제스처 프레젠테이션의 영상을 수집할 수 있습니다.이 영상에서 운동 위치를 추출하여 운동 궤적을 지정하는데 그 중에서 운동 궤적 집합은 고스 혼합 방법에 따라 로봇 제스처를 생성하는 데 사용된다.마지막 토론은 학습된 표징이 로봇의 제스처 식별에 어떻게 사용되는지, 그리고 이 구조가 언어의 기초와 의미 표징을 처리하는 시스템으로 어떻게 성숙되었는지를 고려했다.', 'sw': "Tunaelezea kazi za kuendelea kwa mafunzo ya roboti ya kibinadamu ili kutengeneza mkono na gesi za kichwa kama sehemu ya mazungumzo yanayoelekezwa na kazi. Hii inahusisha maendeleo na matumizi ya mkurugenzi wa mazungumzo mengi kwa ajili ya wataalam wasio na utaalam wa 'programu' roboti kwa kutumia hotuba na maono. Kwa kutumia mjadala huu, video za maandamano yanakusanywa. Video hizi zinatengenezwa kwa ajili ya kutambua barabara za moto ambapo mikusanyiko ya magari yanatumiwa kutengeneza gesi za roboti kufuatia mbinu za mchanganyiko wa Gaussia. Concluding discussion considers how learned representations may be used for gesture recognition by the robot, and how the framework may mature into a system to address language grounding and semantic representation.", 'af': "Ons beskryf werk in vordering vir die onderwerp van 'n humanoid robot om ikoniese arm en kopgesture te produseer as deel van die taak-orienteerde dialoog interaksie. Hierdie insluit die ontwikkeling en gebruik van 'n multimodaal dialoog bestuurder vir nie-eksperte om vinnig `program' die robot deur spreek en gesig te gaan. Gebruik hierdie dialoog bestuurder, word videos van gestuur demonstrasies versamel. Motore posisies word uitgevoer van hierdie videos om motor trajektories te spesifiseer waar versameling van motor trajektories gebruik word om robot gesture te produseer volgens 'n Gaussian gemeenskappe toegang te maak. Besluit die diskusie betref hoe geleerde voorstellings kan gebruik word vir gestuur herken deur die robot, en hoe die raamwerk kan in 'n stelsel vergroot word om taal grond en semantiese voorstelling te adres.", 'fa': 'ما کار در حال پیشرفت برای آموزش روبات بشریت را توصیف می\u200cکنیم تا به عنوان بخشی از ارتباط گفتگوی مسئله\u200cی مشارکت به کار برساند. این شامل توسعه و استفاده از یک مدیر محاورۀ محاورۀ چندین مدل برای متخصص غیر متخصص است تا سریع «برنامه» روبات را از طریق سخنرانی و دید بگیرد. استفاده از این مدیر محاورۀ محاورۀ محاورۀ ، ویدئو از نمایش\u200cهای جستجو جمع می\u200cشوند. موقعیت\u200cهای موتور از این ویدئو خارج می\u200cشوند تا مسیرهای موتور را مشخص کند که جمع\u200cآوری مسیرهای موتور برای تولید جستجو\u200cهای روبات بعد از نزدیک گوسی\u200cها استفاده می\u200cشوند. در نهایت بحث به نظر می رسد که چگونه نمایش یاد گرفته می تواند برای شناسایی جستجو توسط روبات استفاده شود، و چگونه چهار چهار چهارچوب می تواند به یک سیستم بزرگ شود تا به پایه\u200cسازی زبان و نمایش\u200cسازی semantic.', 'hy': 'Մենք նկարագրում ենք մարդկային ռոբոտի ուսումնասիրելու ընթացքում գլխավոր և ձեռքերի խորհրդանիշ շարժումներ ստեղծելու համար աշխատանքը որպես աշխատանքի ուղղությամբ շփումների մի մաս: Սա ներառում է ոչ մասնագետների համար բազմամոդալ պատմության մենեջերի զարգացումը և օգտագործումը, որպեսզի արագ «ծրագրավորենք» ռոբոտին խոսքի և տեսողության միջոցով: Օգտագործելով այս մենեջերն, հավաքվում են ժեստերի ցուցադրությունների տեսահոլովակները: Motor positions are extracted from these videos to specify motor trajectories where collections of motor trajectories are used to produce robot gestures following a Gaussian mixtures approach.  Վերջնական քննարկությունը հաշվի առնում է, թե ինչպես կարող են սովորված ներկայացումները օգտագործվել ռոբոտի կողմից ժեստերի ճանաչելու համար, և թե ինչպես կարող է շրջանակը դառնալ համակարգ լեզվի հիմնադրման և սեմանտիկ ներկայացումների լուծման համար:', 'az': 'Biz insanoid robot təhsil etmək üçün işləri təhsil edirik ki, işin təhsil edilməsi üçün ikonik kol və baş gestlərini təhsil edir. Bu robot danışmaq və görünüş vasitəsilə "program" yazmaq üçün çoxlu modal dialoq müdürünün inkişafında və istifadəsindədir. Bu dialoq müdürünün istifadəsində, gestir göstərişlərinin videoları toplanılır. Motor pozisyonları bu videolardan çıxarılır, Gaussian karıştırıqların yaxınlığından sonra robot gestirlərini ürəkləmək üçün motor traktörlərini belirtmək üçün istifadə edilir. Müzakirə sonrasında, robot tarafından gestin tanımlaması üçün öyrəndiyi tərzlərin necə istifadə ediləcəyini və dil tərzlərini və semantik tərzlərini çəkmək üçün sistemə necə böyüklənəcəyini düşünür.', 'bn': "আমরা একটি মানবাধিকার রোবট প্রশিক্ষণের জন্য অগ্রগতির বর্ণনা করছি যাতে কাজের দিকে প্রতিষ্ঠান এবং মাথার গুলি তৈরি করা হয়েছে কাজের এটি বিশেষজ্ঞ বিশেষজ্ঞের জন্য একটি মাল্টিমোডাল ডায়ালগ ম্যানেজারের উন্নয়ন এবং ব্যবহার করে দ্রুত 'প্রোগ্রাম' রোবটের ভাষণ এই ডায়ালগ ম্যানেজার ব্যবহার করে প্রতিবাদের ভিডিও সংগ্রহ করা হয়েছে। এই ভিডিও থেকে মোটর ট্র্যাক্টরিগুলো উল্লেখ করা হয়েছে যেখানে মোটর ট্র্যাক্টরির সংগ্রহ করা হয়েছে গাউসিয়ার মিশ্রিত প্রতিক্রিয়ার পরে র Concluding discussion considers how learned representations may be used for gesture recognition by the robot, and how the framework may mature into a system to address language grounding and semantic representation.", 'tr': 'Biz insanoid robot okuwçysynyň ýerini we kellämizi işe görkezilýän dijalogyň bir parçasy şeklinde düşündirip ýöredik. Bu robot çykyş we görnüş görä örän ulymmodal dialog müdiriniň gelişmegi we ullanyşyny bar. Bu dialogy müdiri ullanýar, gesteler görkezilişi videolar ýygnalýar. Motor kalamlary bu wideodan çykylýar, Goş kargalaryň golaýyndan soňra motor trajektörleriniň toplamyny takyklamak üçin motor gatlaklary takyklamak üçin guruldylar. Diskusiýada nähili öwrenen temsiller robot tarapyndan gesteler tanamak üçin ullanylýandygyny düşünýär we çerädçi dil garaşylmagy we semantik temsillemesi üçin sistemada nähili ulaşabilir.', 'sq': "Ne përshkruajmë punën në përparim për trajnimin e një roboti humanoid për të prodhuar gjeste ikonike të krahut dhe kokës si pjesë e ndërveprimit të dialogut të orientuar ndaj detyrave. Kjo përfshin zhvillimin dhe përdorimin e një menaxheri dialogu multimodal për jo-ekspertët për të 'programuar' shpejt robotin nëpërmjet fjalimit dhe vizionit. Duke përdorur këtë menaxher dialogu, janë mbledhur videot e demonstratave të gjesteve. Pozicionet motorike nxirren nga këto video për të specifikuar trajektoret motorike ku koleksionet e trajektoreve motorike përdoren për të prodhuar gjeste robotike pas një qasje të përzierjeve gauziane. Diskutimi përfundimtar konsideron se si përfaqësimet e mësuara mund të përdoren për njohjen e gjesteve nga roboti dhe se si kuadri mund të rritet në një sistem për të trajtuar bazimin e gjuhës dhe përfaqësimin semantik.", 'am': 'አካባቢ ክንድ እና የራስ ግንኙነትን ለመፍጠር የሰማዊ ሮቦት የስራ አካባቢ ማኅበረሰብ ግንኙነት ለመፍጠር የሚችሉትን ሥራ እናሳውቃለን፡፡ ይህም ለባሕላዊ መክፈት እና ለመጠቀም ለባሕሮችና ለመጠቀም ለሮቦት በንግግር እና በራእይ ፈጥኖ ‘ፕሮግራም’ ለመጠቀም የሚያስፈልጋል፡፡ ይህ ጥያቄ መቆጣጠሪያ በመጠቀም የgesture ሰልፎች ቪዲዮዎች ይሰበስባሉ፡፡ የሜትሮር ቦታዎች ከዚህች ቪዲዮዎች የኮንቨርስ አካባቢዎች የሮቦት አካባቢዎች በጋውስሲ መቀናቀል ለመፍጠር የሚጠቅሙበት የኮንተር አካባቢዎችን ለመግለጥ ይወጣሉ፡፡ የግንኙነት ግንኙነት በሮቦት ማወቅ እንዴት እንደተማረ መልዕክቶችን እንዲጠቀሙ እና የፍሬም ፍሬማት እንዴት ቋንቋ መፍጠር እና የsemantic መልዕክት ለመጠቀም ሲችል እንደተደረገ እና እንዴት እንደተፈጸመ ይችላል፡፡', 'cs': 'Popisujeme probíhající práce na výcviku humanoidního robota k produkci ikonických gest paží a hlavy v rámci dialogové interakce orientované na úkoly. To zahrnuje vývoj a použití multimodálního dialogového manažera pro non-experty k rychlému "programování" robota prostřednictvím řeči a vidění. Pomocí tohoto správce dialogů jsou shromažďována videa ukázek gest. Z těchto videí jsou extrahovány pozice motoru pro specifikaci motorových trajektorií, kde se sbírky motorových trajektorií používají k produkci gest robota podle Gaussova směsi. Závěrečná diskuse se zabývá tím, jak mohou být naučené reprezentace využity pro rozpoznávání gest robotem a jak může rámec vyzrát do systému řešení jazykového uzemnění a sémantické reprezentace.', 'et': 'Kirjeldame käimasolevat tööd humanoidroboti koolitamiseks ikooniliste käe- ja peažestide tootmiseks ülesandepõhise dialoogi koostöö raames. See hõlmab mitteekspertide multimodaalse dialoogihalduri väljatöötamist ja kasutamist roboti kiireks programmeerimiseks kõne ja nägemise kaudu. Selle dialoogihalduri abil kogutakse žestide demonstratsioonide videoid. Nendest videotest on välja võetud mootori asukohad, et täpsustada mootori trajektoorid, kus mootori trajektooride kogumeid kasutatakse roboti žestide tootmiseks Gaussi segude lähenemisviisi järgi. Kokkuvõttes käsitletakse, kuidas õppitud representatsioone saab kasutada žestide tuvastamiseks roboti poolt ning kuidas raamistik võib areneda süsteemiks, mis käsitleb keele alust ja semantilist representatsiooni.', 'fi': 'Kuvaamme meneill채채n olevaa ty철t채 humanoidirobotin kouluttamiseksi tuottamaan ikonisia k채si- ja p채채-eleit채 osana teht채v채l채ht철ist채 vuoropuhelua. T채m채 edellytt채채 multimodaalisen vuoropuhelunhallinnan kehitt채mist채 ja k채ytt철채 muille kuin asiantuntijoille robotin nopeaan ohjelmointiin puheen ja n채철n avulla. T채m채n valintaikkunan avulla ker채t채채n videoita eleiden esittelyist채. N채ist채 videoista poimitaan moottoreiden asennot m채채ritt채m채채n moottoriradat, joissa moottoriradan kokoelmia k채ytet채채n tuottamaan robottien eleit채 gaussilaisen sekoituksen mukaisesti. Keskustelun p채채tteeksi pohditaan, miten opittuja representaatioita voidaan k채ytt채채 robotin eletunnistukseen ja miten viitekehys voi kypsy채 kielellisen pohjautumisen ja semanttisen representaation k채sittelyj채rjestelm채ksi.', 'bs': "Mi opisujemo napredak rad za obuku humanoičnog robot a kako bi proizvela ikonsku ruku i geste glave kao dio interakcije s orijentacijom na zadatke. To uključuje razvoj i korištenje multimodalnog menadžera dijaloga za ne-stručnike da brzo `program' robot a kroz govor i viziju. Koristeći ovaj menadžer dijaloga, prikupljeni su video demonstracija gesta. Motorne pozicije su izvučene iz ovih snimaka kako bi specificirali motorne puteve gdje se kolekcije motornih putnika koriste za proizvodnju robotnih gesta nakon pristupa Gausijskih mješavina. Uključujući raspravu, razmišlja o tome kako se naučene predstave mogu koristiti za prepoznavanje gesta od strane robot a i kako okvir može odrastati u sistem za rješavanje jezičkog osnova i semantičkog predstavljanja.", 'ca': "Descrevem el treball en progrés per formar un robot humanoide per produir gestos de braç i cap icònics com part de la interacció de diàleg orientat a les tasques. Això implica el desenvolupament i l'ús d'un gestor de diàleg multimodal per a no experts per a programar ràpidament el robot a través de la fala i la visió. Amb aquest gestor de diàleg es recollen vídeos de demostracions de gestos. Les posicions motores es extraeixen d'aquests vídeos per especificar trajectòries motores on es fan servir col·leccions de trajectòries motores per produir gests robots segons un enfocament de mistures gaussies. Concluding discussion considers how learned representations may be used for gesture recognition by the robot, and how the framework may mature into a system to address language grounding and semantic representation.", 'ha': "Munã bayyana aikin da za'a yi amfani da wani jeroho na mutane dõmin ya zaɓi hannuwan da shirin suna cikin shirin bayani na aikin da aka danne shi. Wannan yana da amfani da manajan zauren akwatin bayani na multi-multi don masu fitarwa ga haraka `shirin ayuka' don ka yi bayani da magana da gani. Yi amfani da wannan manajan zauren akwatin bayani, za'a samu video na nunayen gesture. An fiɗe masu motsi daga wannan video dõmin a ƙayyade wasu hanyõyi masu motsi da aka yi amfani da su a samun haɗuwa da shiryori masu motsi dõmin su zata gesture cikin jero idan an sami wata hanyoyi na gaussi. Daga jãyayya ta ƙayyade jinsi za'a yi amfani da shaidar da aka sanar da su dõmin a yi amfani da su ga ganin matofatin raɗabi'a, kuma yadda zai iya mature firam zuwa wani na'urar dõmin ka yi magana ga halartar da bakin harshe da kuma ma'anar mutane.", 'he': "אנחנו מתארים עבודה בתהליך לאימון רובוט אנונואיד כדי לייצר מחוות איקוניות של זרוע וראש כחלק מהאינטראקציה של דיאלוג ממוקד למשימות. זה מעורב בפיתוח ושימוש של מנהל דיאלוגים multimodal עבור לא מומחים כדי 'לתכנן' מהר את הרובוט דרך נאום וחזון. בשימוש במנהל הדיולוגים הזה, אוספים וידאו של הדגמות מחוות. עמדות אוטוריות מווצרות מהסרטונים האלה כדי לציין מסלולים אוטוריים שבו אוסף מסלולים אוטוריים משתמשים כדי לייצר מחווות רובוטים בעקבות גישה לערבובות גאוסיות. הדיון הסופי שוקל איך ניתן להשתמש באמצעות מייצגות ללמודות לזהות מחוות על ידי הרובוט, ואיך המסגרת יכולה להתבגר למערכת כדי להתייחס לאיסוף שפות וייצגות סמנטית.", 'sk': 'Opisujemo delo, ki poteka za usposabljanje humanoidnega robota za izdelavo ikoničnih kretnj roke in glave kot del dialoga, usmerjenega v nalogo. To vključuje razvoj in uporabo multimodalnega upravljalnika dialoga za nestrokovnjake za hitro programiranje robota skozi govor in vid. Z uporabo tega upravljalnika pogovornega okna se zbirajo videoposnetki demonstracij gest. Iz teh videoposnetkov so izvlečeni motorni položaji, ki določajo motorne poti, kjer se zbirke motornih poti uporabljajo za proizvodnjo robotskih gest po pristopu gaussijskih mešanic. Zaključna razprava obravnava, kako se lahko naučene reprezentacije uporabljajo za prepoznavanje gest s strani robota in kako lahko okvir zrel v sistem, ki obravnava jezikovno ozemljanje in semantično reprezentacijo.', 'jv': "Anyone Iki lak nglebok nggunakake lan gambar sistem sistem dialog kanggo ngilangno pi-pernik kanggo ngilangno pi-pernik kanggo tukang 'program' bot kanggo ngilangno sesorahan lan penjane Jejaring Kowe Moton Simulan negori sampeyan piye isakno piye isakno aken representasi sing isa nggawe nguasai gesture karo bot, lan piye isakno sing isa teka saben sistem kanggo ngerasai aturan kelangan bangsane lan sematik repréntasi.", 'bo': "ང་ཚོས་རྒྱལ་ཁབ་ཀྱི་ལས་འགན་འགྲོ་བཞིན་པའི་སྐྱེས་པའི་རྩོམ་པ་ཞིག་གིས This involves the development and use of a multimodal dialog manager for non-experts to quickly `program' the robot through speech and vision. སྒྲ་བརྙན་དོ་དམ་པ་འདིས་སྤྱོད་བཞིན་པའི་བརྙན་རིས་སྒྲིག་འགོད་ཀྱི་བརྙན་རིས་བསྡུ་ཚར་བ སྒུལ་འཁོར་གྱི་གནས་སྟངས་འདི་དག་གི་བརྙན་པར་ལས་ཕྱིར་འདུག་ནས་སྣ་འཁོར་གྱི་འགྲུལ་འཁོར་སྤྱོད་སའི་ནང་དུ་སྒུལ་འཁོར་གྱི་ནང་དུ་སྤྱད་ནས་བརྡ་རྩོལ་འཁ ཤེས་འཇུག་འདོད་མ་ཟད། ག་དུས་འཆར་བྱེད་པའི་རྣམ་གྲངས་སྟོན་རྩིས་ལག་ལེན་འཐབ་བཏུབ་ཡིན།"}
