{'en': 'AraBERT : Transformer-based Model for Arabic Language Understanding', 'ar': 'أرابرت: نموذج قائم على المحولات لفهم اللغة العربية', 'es': 'ARaBert: modelo basado en transformadores para la comprensión del idioma árabe', 'fr': 'ARaBert\xa0: modèle basé sur un transformateur pour la compréhension de la langue arabe', 'pt': 'AraBERT: modelo baseado em transformador para compreensão da língua árabe', 'ja': 'AraBERT ：アラビア語を理解するためのトランスフォーマーベースモデル', 'ru': 'AraBERT: Трансформаторная модель для понимания арабского языка', 'zh': 'AraBERT:变压器阿拉伯语解模', 'hi': 'Arabert: अरबी भाषा की समझ के लिए ट्रांसफॉर्मर-आधारित मॉडल', 'ga': 'AraBERT: Múnla Trasfhoirmeoir-bhunaithe le haghaidh Tuiscint na Teanga Araibise', 'ka': 'Arabic', 'hu': 'AraBERT: Transzformátor alapú modell az arab nyelv megértéséhez', 'el': 'Το μοντέλο που βασίζεται στον μετασχηματιστή για την κατανόηση της αραβικής γλώσσας', 'it': 'AraBERT: Modello basato su trasformatori per la comprensione della lingua araba', 'mk': 'АраБЕРТ: Модел за разбирање на арапскиот јазик базиран на трансформи', 'kk': 'AraBERT: Араб тілін түсініктіру үшін түрлендіруші негізделген модель', 'lt': 'AraBERT: Arabų kalbos supratimo transformatoriaus modelis', 'ms': 'AraBERT: Model berasaskan-Transformer untuk Pemahaman Bahasa Arab', 'mt': 'AraBERT: Transformer-based Model for Arabic Language Understanding', 'mn': 'Араберт: Араб хэл ойлголтын төлөвлөгч суурилсан загвар', 'ml': 'അരാബെര്\u200dട്ട്: അറബി ഭാഷയ്ക്കുള്ള മോഡല്\u200d പരിശോധിക്കുക', 'no': 'AraBERT: Transformeringsbasert modell for arabisk språk forståking', 'pl': 'AraBERT: oparty na transformatorze model rozumienia języka arabskiego', 'ro': 'AraBERT: Model bazat pe transformator pentru înțelegerea limbii arabe', 'si': 'AraBERT: අරාබි භාෂාව තේරුම්ගන්න සඳහා ප්\u200dරවර්තනයක් අධාරණය කරන්න ප්\u200dරමාණය', 'sr': 'AraBERT: Model na transformaciji za razumevanje arapskog jezika', 'so': 'AraBERT: Model ku saleysan afka Carabiga waxgarashada', 'sv': 'AraBERT: Transformatorbaserad modell för förståelse av arabiska språk', 'ta': 'AraBERT: மாற்று அடிப்படையான மாதிரி அரபி மொழி புரிந்து கொள்ளும்', 'ur': 'عربی زبان سمجھنے کے لئے ترفنٹر بنیادی موڈل', 'vi': 'AraBERT: Mô hình biến hình cho hiểu biết ngôn ngữ Ả rập', 'uz': 'AraBERT: Transformer- based Model for Arabic language understandingName', 'da': 'AraBERT: Transformer-baseret model til arabisk sprogforståelse', 'bg': 'Модел за разбиране на арабския език, базиран на трансформатори', 'nl': 'AraBERT: Transformer-gebaseerd model voor het begrijpen van Arabische taal', 'hr': 'AraBERT: Model na transformaciji za razumijevanje arapskog jezika', 'de': 'AraBERT: Transformatorbasiertes Modell für das Verständnis der arabischen Sprache', 'fa': 'آرابرت: مدل تغییر دهنده برای فهمیدن زبان عربی', 'ko': '아랍트: 변압기 기반의 아랍어 이해 모델', 'id': 'AraBERT: Model Berdasar Transformer untuk Pemahaman Bahasa Arab', 'sw': 'AraBERT: Mradi wa Kiarabu wa Kiarabu wa Kuelewa', 'tr': 'AraBERT: Arapça dilini düşünmek üçin terjime edilen nusgala', 'af': 'AraBERT: Transformer- gebaseerde Model vir Arabiese Taal Verstaan', 'sq': 'AraBERT: Model me bazë në transformim për kuptimin e gjuhës arabe', 'am': 'AraBERT: Transformer-based Model for Arabic Language Understanding', 'hy': 'Արաբերտ. Արաբերական լեզվի հասկանալու վերափոխման հիմնված մոդել', 'az': 'AraBERT: Arab dili anlama üçün Transformer-based Model', 'bn': 'AraBERT: আরবী ভাষার বুঝার জন্য পরিবর্তন ভিত্তিক মডেল', 'bs': 'AraBERT: Model na transformaciji za razumijevanje arapskog jezika', 'ca': 'AraBERT: Model de comprensió del llenguatge àrab basat en transformadors', 'et': 'AraBERT: Transformer-põhine mudel araabia keele mõistmiseks', 'cs': 'AraBERT: Model založený na transformátoru pro porozumění arabskému jazyku', 'fi': 'AraBERT: Muuntajapohjainen malli arabian kielen ymmärtämiseen', 'jv': 'araBERT: Transformer-basic model for Language', 'ha': 'KCharselect unicode block name', 'sk': 'AraBERT: transformatorski model za razumevanje arabskega jezika', 'he': 'AraBERT: Transformer-based Model for Arabic Language Understanding', 'bo': 'AraBERT: Transformer-based Model for Arabic Language Understanding'}
{'en': 'The ', 'ar': 'اللغة العربية هي لغة غنية من الناحية الشكلية مع موارد قليلة نسبيًا وبنية أقل استكشافًا مقارنة باللغة الإنجليزية. نظرًا لهذه القيود ، فإن مهام معالجة اللغة العربية الطبيعية (NLP) مثل تحليل المشاعر (SA) ، والتعرف على الكيانات المسماة (NER) ، والإجابة على الأسئلة (QA) ، أثبتت أنها صعبة للغاية في معالجتها. في الآونة الأخيرة ، مع زيادة النماذج القائمة على المحولات ، أثبتت النماذج القائمة على BERT الخاصة باللغة أنها فعالة للغاية في فهم اللغة ، بشرط أن يتم تدريبهم مسبقًا على مجموعة كبيرة جدًا. كانت هذه النماذج قادرة على وضع معايير جديدة وتحقيق أحدث النتائج لمعظم مهام البرمجة اللغوية العصبية. في هذه الورقة ، قمنا بتدريب BERT مسبقًا خصيصًا للغة العربية سعياً لتحقيق نفس النجاح الذي حققه BERT للغة الإنجليزية. تتم مقارنة أداء AraBERT بأداء BERT متعدد اللغات من Google وغيره من الأساليب الحديثة. أظهرت النتائج أن AraBERT الذي تم تطويره حديثًا حقق أداءً متطورًا في معظم مهام البرمجة اللغوية العصبية العربية التي تم اختبارها. نماذج araBERT سابقة التدريب متاحة للجمهور على https://github.com/aub-mind/araBERT على أمل تشجيع البحث والتطبيقات الخاصة بمعالجة اللغات الطبيعية العربية.', 'es': 'El idioma árabe es un idioma rico morfológicamente con relativamente pocos recursos y una sintaxis menos explorada en comparación con el inglés. Dadas estas limitaciones, las tareas de procesamiento del lenguaje natural (NLP) árabe, como el análisis de sentimientos (SA), el reconocimiento de entidades nombradas (NER) y la respuesta a preguntas (QA), han demostrado ser muy difíciles de abordar. Recientemente, con el aumento de los modelos basados en transformadores, los modelos basados en BERT específicos del idioma han demostrado ser muy eficientes en la comprensión del idioma, siempre que estén previamente entrenados en un corpus muy grande. Estos modelos fueron capaces de establecer nuevos estándares y lograr resultados de vanguardia para la mayoría de las tareas de PNL. En este artículo, entrenamos previamente a BERT específicamente para el idioma árabe con el fin de lograr el mismo éxito que el BERT obtuvo para el idioma inglés. El rendimiento de ARaBert se compara con el BERT multilingüe de Google y otros enfoques de última generación. Los resultados mostraron que el AraBert recientemente desarrollado logró un rendimiento de vanguardia en la mayoría de las tareas de PNL árabe probadas. Los modelos AraBert previamente entrenados están disponibles públicamente en https://github.com/aub-mind/araBERT con la esperanza de fomentar la investigación y las solicitudes de PNL árabe.', 'fr': "La langue arabe est une langue morphologiquement riche avec relativement peu de ressources et une syntaxe moins explorée que l'anglais. Compte tenu de ces limites, les tâches de traitement du langage naturel (NLP) en arabe, telles que l'analyse des sentiments (SA), la reconnaissance d'entités nommées (NER) et la réponse aux questions (AQ), se sont révélées très difficiles à gérer. Récemment, avec l'essor des modèles basés sur des transformateurs, les modèles BERT spécifiques au langage se sont révélés très efficaces pour la compréhension de la langue, à condition qu'ils soient pré-entraînés sur un très grand corpus. Ces modèles ont permis d'établir de nouvelles normes et d'obtenir des résultats de pointe pour la plupart des tâches de PNL. Dans cet article, nous avons pré-formé BERT spécifiquement à la langue arabe dans le but d'obtenir le même succès que BERT pour la langue anglaise. Les performances d'AraBert sont comparées à celles du BERT multilingue de Google et d'autres approches de pointe. Les résultats ont montré que le nouveau AraBert a atteint des performances de pointe sur la plupart des tâches de PNL en arabe testées. Les modèles AraBert préformés sont accessibles au public sur https://github.com/aub-mind/araBERT dans l'espoir d'encourager la recherche et les applications pour la PNL arabe.", 'pt': 'A língua árabe é uma língua morfologicamente rica com relativamente poucos recursos e uma sintaxe menos explorada em relação ao inglês. Dadas essas limitações, tarefas de Processamento de Linguagem Natural (PNL) em árabe, como Análise de Sentimento (SA), Reconhecimento de Entidade Nomeada (NER) e Resposta a Perguntas (QA), provaram ser muito desafiadoras. Recentemente, com o surgimento de modelos baseados em transformadores, os modelos baseados em BERT específicos de linguagem provaram ser muito eficientes na compreensão da linguagem, desde que sejam pré-treinados em um corpus muito grande. Esses modelos foram capazes de estabelecer novos padrões e alcançar resultados de última geração para a maioria das tarefas de PNL. Neste artigo, nós pré-treinamos o BERT especificamente para o idioma árabe na busca de alcançar o mesmo sucesso que o BERT fez para o idioma inglês. O desempenho do AraBERT é comparado ao BERT multilíngue do Google e outras abordagens de última geração. Os resultados mostraram que o recém-desenvolvido AraBERT alcançou desempenho de última geração na maioria das tarefas de PNL árabe testadas. Os modelos araBERT pré-treinados estão disponíveis publicamente em https://github.com/aub-mind/araBERT esperando encorajar pesquisas e aplicações para PNL árabe.', 'ja': 'アラビア語は形態論的に豊かな言語であり、英語と比較してリソースが比較的少なく、構文もあまり探求されていません。 これらの制限を考慮すると、センチメント分析（ SA ）、名前付きエンティティ認識（ NER ）、質問回答（ QA ）などのアラビア語自然言語処理（ NLP ）タスクは、非常に困難であることが証明されています。 最近、変圧器ベースのモデルの急増に伴い、言語固有のBERTベースのモデルは、非常に大きなコーパスで事前にトレーニングされている限り、言語理解において非常に効率的であることが証明されています。 このようなモデルは、ほとんどのNLPタスクで新しい基準を設定し、最先端の結果を達成することができました。 この論文では、BERTが英語で行ったのと同じ成功を目指して、アラビア語のためにBERTを事前に訓練しました。 AraBERTのパフォーマンスは、Googleの多言語BERTや他の最先端のアプローチと比較されます。 結果は、新しく開発されたAraBERTが、ほとんどのテスト済みアラビア語NLPタスクで最先端のパフォーマンスを達成したことを示しています。 事前に訓練されたaraBERTモデルは、https://github.com/aub-mind/araBERTで公開されており、アラビア語のNLPの研究と応用を奨励することを期待しています。', 'zh': '比之英语,阿拉伯语为富言,资源相薄,语法索为少。 鉴于此限,情析 (SA)、名实识 (NER) 与问答 (QA) 等阿拉伯语自然语言处 (NLP) 其效甚挑战性。 近者,随转换器之激增,BERT言之效,先言之语料库。 能为之多NLP设其制度而先进之。 本文者,专阿拉伯语预练BERT,以求BERT英语同功也。 AraBERT性与Google多言BERT较之最先进者。 结果表明,新发者AraBERT多试阿拉伯语NLP最先进之性。 豫教者araBERT明于 https://github.com/aub-mind/araBERT ,愿劝阿拉伯语NLP而用之。', 'hi': 'अरबी भाषा अपेक्षाकृत कम संसाधनों और अंग्रेजी की तुलना में कम खोजे गए वाक्यविन्यास के साथ एक रूपात्मक रूप से समृद्ध भाषा है। इन सीमाओं को देखते हुए, अरबी प्राकृतिक भाषा प्रसंस्करण (एनएलपी) जैसे भावना विश्लेषण (एसए), नामित इकाई मान्यता (एनईआर), और प्रश्न उत्तर (क्यूए) जैसे कार्य, निपटने के लिए बहुत चुनौतीपूर्ण साबित हुए हैं। हाल ही में, ट्रांसफॉर्मर आधारित मॉडल की वृद्धि के साथ, भाषा-विशिष्ट BERT आधारित मॉडल भाषा की समझ में बहुत कुशल साबित हुए हैं, बशर्ते वे एक बहुत बड़े कॉर्पस पर पूर्व-प्रशिक्षित हों। इस तरह के मॉडल नए मानकों को स्थापित करने और अधिकांश एनएलपी कार्यों के लिए अत्याधुनिक परिणाम प्राप्त करने में सक्षम थे। इस पेपर में, हमने विशेष रूप से अरबी भाषा के लिए BERT को उसी सफलता को प्राप्त करने की खोज में पूर्व-प्रशिक्षित किया जो BERT ने अंग्रेजी भाषा के लिए किया था। AraBERT के प्रदर्शन की तुलना Google से बहुभाषी BERT और अन्य अत्याधुनिक दृष्टिकोणों से की जाती है। परिणामों से पता चला है कि नव विकसित AraBERT ने अधिकांश परीक्षण किए गए अरबी एनएलपी कार्यों पर अत्याधुनिक प्रदर्शन हासिल किया। पूर्वप्रशिक्षित araBERT मॉडल सार्वजनिक रूप से https://github.com/aub-mind/araBERT पर उपलब्ध हैं जो अरबी एनएलपी के लिए अनुसंधान और अनुप्रयोगों को प्रोत्साहित करने की उम्मीद कर रहे हैं।', 'ru': 'Арабский язык является морфологически богатым языком с относительно небольшим количеством ресурсов и менее изученным синтаксисом по сравнению с английским. Учитывая эти ограничения, задачи обработки арабского естественного языка (NLP), такие как анализ настроений (SA), распознавание именованных сущностей (NER) и ответы на вопросы (QA), оказались очень сложными для решения. В последнее время, с всплеском трансформаторных моделей, языковые модели на основе BERT оказались очень эффективными в понимании языка, при условии, что они предварительно обучены на очень большом корпусе. Такие модели смогли установить новые стандарты и достичь самых современных результатов для большинства задач NLP. В этой статье мы предварительно обучили БЕРТА специально для арабского языка в стремлении достичь того же успеха, что и БЕРТА для английского языка. Производительность AraBERT сравнивается с многоязычным BERT от Google и других современных подходов. Результаты показали, что недавно разработанный AraBERT достиг самых современных показателей по большинству протестированных арабских задач NLP. Предварительно подготовленные модели araBERT находятся в открытом доступе на https://github.com/aub-mind/araBERT в надежде стимулировать исследования и приложения для арабского NLP.', 'ga': 'Is teanga saibhre moirfeolaíoch í an teanga Araibis le líon beag acmhainní agus comhréir nach bhfuil an oiread céanna iniúchta uirthi i gcomparáid leis an mBéarla. I bhfianaise na dteorainneacha seo, tá sé an-dúshlánach dul i ngleic le tascanna Próiseála Teanga Nádúrtha Araibis (NLP) mar Anailís Mothúchán (SA), Aitheantas Aonán Ainmnithe (NER), agus Freagra Ceist (QA). Le déanaí, le méadú ar mhúnlaí bunaithe ar chlaochladáin, tá múnlaí bunaithe ar BERT a bhaineann go sonrach le teanga an-éifeachtach maidir le tuiscint teanga, ar an gcoinníoll go bhfuil siad réamh-oilte ar chorpas an-mhór. Bhí samhlacha den sórt sin in ann caighdeáin nua a shocrú agus torthaí úrscothacha a bhaint amach i gcás fhormhór na dtascanna NLP. Sa pháipéar seo, rinneamar réamhoiliúint ar BERT go sonrach don Araibis chun an rath céanna a bhaint amach agus a rinne BERT don Bhéarla. Cuirtear feidhmíocht AraBERT i gcomparáid le BERT ilteangach ó Google agus cineálacha cur chuige úrscothacha eile. Léirigh na torthaí gur bhain an AraBERT nuafhorbartha feidhmíocht den scoth amach ar na tascanna NLP Araibis is mó a ndearnadh tástáil orthu. Tá na samhlacha araBERT réamhoilte ar fáil go poiblí ar https://github.com/aub-mind/araBERT ag súil le taighde agus iarratais ar NLP Araibis a spreagadh.', 'ka': 'აპაბური ენაა მორპოლოგიურად ღარილი ენაა, რომელიც პარამეტრებით რამდენიმე რესურსი და უფრო ცოტა განსხვავებული სინტაქსი ინგლისურად შედგ ამ ზომილებების განსაზღვრებით, აპაბიური თავისუფალური ენერგიის პროცესი (NLP) საქმედები, როგორც Sentiment Analysis (SA), სახელი ინტერტის განაცნობა (NER) და კითხვების განახლება (QA) იქნება ძალიან გართული. მხოლოდ, ტრანფორმენტების მოდელების გარეშე, ბერტის განსაზღვრებული მოდელები გამოიყენება მნიშვნელოვანია ენათვის განსხვავებაში, თუ ისინი მნიშვნელოვანია დიდი კორპუსზე. ასეთი მოდელები შეუძლია ახალი სტანდარტულებს დააყენოთ და გავაკეთოთ სტანდარტულების შედეგი NLP დავალებებისთვის. ამ დოკუნეში ჩვენ BERT-ს წინასწარმოადგენა განსაკუთრებით აპაბიური ენაზე იგივე წარმატების მიღება, რომელიც BERT-ს ანგლისური ენაზე გავაკეთე. არაბერტის გამოსახულება მრავალენგური BERT-თან და სხვა ხელსახულების დასახულება. წარმოდგენები გაჩვენეთ, რომ ახალი განვითარებული აპაბერტი განვითარებულია ახალგაზრულებული აპაბერტის ნამდვილეობით განვითარებულია ახალგაზრულებული აპაბური N პაბერტის მოდელები საშუალოდ აქვს https://github.com/aub-mind/araBERT იმედი, რომ აპაბიური NLP-ის განსხვავება და პროგრამების შესაძლებლობა.', 'el': 'Η αραβική γλώσσα είναι μια μορφολογικά πλούσια γλώσσα με σχετικά λίγους πόρους και λιγότερο διερευνημένη σύνταξη σε σύγκριση με τα αγγλικά. Δεδομένης αυτών των περιορισμών, οι εργασίες επεξεργασίας φυσικής γλώσσας αραβικής γλώσσας (όπως η ανάλυση συναισθημάτων (SA), η αναγνώριση ονομαστών οντοτήτων (NER) και η απάντηση ερωτήσεων (QA), έχουν αποδειχθεί ότι είναι πολύ δύσκολο να αντιμετωπιστούν. Πρόσφατα, με την αύξηση των μοντέλων που βασίζονται σε μετασχηματιστές, τα ειδικά γλωσσικά μοντέλα έχουν αποδειχθεί πολύ αποτελεσματικά στην κατανόηση της γλώσσας, υπό την προϋπόθεση ότι είναι προ-εκπαιδευμένα σε ένα πολύ μεγάλο σώμα. Τέτοια μοντέλα ήταν σε θέση να θέσουν νέα πρότυπα και να επιτύχουν αποτελέσματα τελευταίας τεχνολογίας για τις περισσότερες εργασίες NLP. Σε αυτή την εργασία, εκπαιδεύσαμε ειδικά για την αραβική γλώσσα με στόχο την επίτευξη της ίδιας επιτυχίας που έκανε και για την αγγλική γλώσσα. Η απόδοση του AraBERT συγκρίνεται με την πολύγλωσση BERT από την Google και άλλες σύγχρονες προσεγγίσεις. Τα αποτελέσματα έδειξαν ότι το πρόσφατα αναπτυγμένο AraBERT πέτυχε υπερσύγχρονες επιδόσεις στις περισσότερες δοκιμασμένες αραβικές εργασίες NLP. Τα προσχεδιασμένα μοντέλα είναι δημόσια διαθέσιμα στο https://github.com/aub-mind/araBERT ελπίζοντας να ενθαρρύνει την έρευνα και τις εφαρμογές για τα αραβικά NLP.', 'hu': 'Az arab nyelv morfológiailag gazdag nyelv viszonylag kevés erőforrással és kevésbé feltárt szintaxissal az angolhoz képest. Tekintettel ezekre a korlátozásokra, az arab természetes nyelvi feldolgozás (NLP) feladataira, mint az érzelmek elemzése (SA), a nevezett entitások felismerése (NER) és a kérdések megválaszolása (QA) nagyon kihívást jelentett. Az utóbbi időben a transzformátorok alapú modelleinek megnövekedésével a nyelvspecifikus BERT-alapú modellek nagyon hatékonynak bizonyultak a nyelv megértésében, feltéve, hogy egy nagyon nagy korpuszon előkészítették őket. Az ilyen modellek képesek voltak új szabványokat meghatározni és korszerű eredményeket elérni a legtöbb NLP-feladat tekintetében. Ebben a tanulmányban a BERT-t kifejezetten az arab nyelvre képeztük előre, hogy ugyanazt a sikert érjük el, mint a BERT az angol nyelvre. Az AraBERT teljesítményét a Google többnyelvű BERT és más korszerű megközelítések hasonlítják össze. Az eredmények azt mutatták, hogy az újonnan kifejlesztett AraBERT korszerű teljesítményt ért el a legtöbb tesztelt arab NLP feladatban. Az előkészített araBERT modellek nyilvánosan hozzáférhetők a következő oldalon: https://github.com/aub-mind/araBERT az arab nemzeti politika kutatásának és alkalmazásának ösztönzésében.', 'it': "La lingua araba è una lingua morfologicamente ricca con relativamente poche risorse e una sintassi meno esplorata rispetto all'inglese. Date queste limitazioni, le attività di elaborazione del linguaggio naturale arabo (NLP) come l'analisi dei sentimenti (SA), il riconoscimento delle entità denominate (NER) e la risposta alle domande (QA), si sono rivelate molto difficili da affrontare. Recentemente, con l'aumento di modelli basati su trasformatori, i modelli basati su BERT specifici per il linguaggio si sono dimostrati molto efficienti nella comprensione del linguaggio, a condizione che siano pre-formati su un corpus molto ampio. Tali modelli sono stati in grado di stabilire nuovi standard e raggiungere risultati all'avanguardia per la maggior parte delle attività PNL. In questo articolo, abbiamo pre-formato BERT specificamente per la lingua araba nella ricerca di ottenere lo stesso successo che BERT ha fatto per la lingua inglese. Le prestazioni di AraBERT sono paragonate al BERT multilingue di Google e ad altri approcci all'avanguardia. I risultati hanno mostrato che il nuovo AraBERT ha ottenuto prestazioni all'avanguardia nella maggior parte delle attività NLP arabe testate. I modelli araBERT pretrained sono disponibili al pubblico su https://github.com/aub-mind/araBERT sperando di incoraggiare la ricerca e le applicazioni per la PNL araba.", 'kk': 'Араб тілі - ағылшын тіліне салыстырылған морфологиялық баяны тіл, салыстырмалы көп ресурстар мен бірнеше зерттеулі синтаксисі. Бұл шектеулерге қарай, араб тіл процессі (NLP) Sentiment Analysis (SA), аталған нысандарды анықтау (NER) және сұрақтар жауап беру (QA) сияқты тапсырмалар өте қиын болды. Жуырда Түрлендірушілер негіздеген үлгілерді өзгерту үшін, тілді белгілі BERT негіздеген үлгілер тілді түсініктерге өте ең ең пайдалы болып көрсетілген, егер олар өте үлкен корпус арқылы Бұл үлгілер жаңа стандартты орнатуға болды және NLP тапсырмаларының көпшілігінің күйінің нәтижесін жеткізуға болды. Бұл қағазда БЕРТ тіліне әдетте Араб тіліне берттің ағылшын тіліне жеткізген сәтті жеткізу үшін алдын- ала оқыдық. AraBERT жылдамдығы Google және басқа әртүрлі көп тілді BERT-мен салыстырылады. Нәтижелер жаңа жасалған AraBERT- тың тексерілген Араб NLP тапсырмаларының көпшілігін жеткізгенін көрсетті. АраBERT үлгілері көпшілікті қолданылады https://github.com/aub-mind/araBERT Араб NLP зерттеулерін және қолданбаларын көмектесу үшін.', 'lt': 'Arabų kalba yra morfologiškai turtinga kalba, turinti palyginti nedaug išteklių ir mažiau ištirtą sintaksą, palyginti su anglų kalba. Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle.  Pastaruoju metu, kai daugėja transformatorių pagrįstų modelių, kalbos specifiniai BERT pagrįsti modeliai įrodė, kad yra labai veiksmingi kalbų supratimo srityje, jeigu jie yra iš anksto apmokyti labai dideliu korpusu. Tokie modeliai galėjo nustatyti naujus standartus ir pasiekti naujausius rezultatus daugeliui NLP užduočių. In this paper, we pre-trained BERT specifically for the Arabic language in the pursuit of achieving the same success that BERT did for the English language.  AraBERT veiksmingumas lyginamas su daugiakalbiu Google BERT ir kitais naujausiais metodais. Iš rezultatų matyti, kad naujai sukurtas AraBERT pasiekė pažangiausius rezultatus daugumoje išbandytų arabų NLP užduočių. Išankstinio mokymo araBERT modeliai yra viešai prieinami https://github.com/aub-mind/araBERT Tikimasi skatinti mokslinius tyrimus ir paraiškas arabų nacionalinei nacionalinei programai.', 'ms': 'Bahasa Arab adalah bahasa yang kaya secara morfologik dengan sumber relatif sedikit dan sintaks yang kurang dikeksplorasi dibandingkan dengan bahasa Inggeris. Mengingat keterangan-keterangan ini, tugas Pemprosesan Bahasa Alami Arab (NLP) seperti Analisi Sentiment (SA), Pengenalan Entiti bernama (NER), dan Jawapan soalan (QA), telah terbukti sangat mencabar untuk diselesaikan. Baru-baru ini, dengan tumbuhan model berasaskan pengubah, model berasaskan BERT bahasa-spesifik telah terbukti sangat efisien dalam pemahaman bahasa, dengan syarat mereka dilatih-dilatih pada korpus yang sangat besar. Such models were able to set new standards and achieve state-of-the-art results for most NLP tasks.  Dalam kertas ini, kami melatih BERT secara khusus untuk bahasa Arab dalam mengejar untuk mencapai kejayaan yang sama dengan BERT untuk bahasa Inggeris. Performasi AraBERT dibandingkan dengan BERT berbilang bahasa dari Google dan pendekatan-state-of-the-art lain. Hasilnya menunjukkan bahawa AraBERT yang baru dikembangkan mencapai prestasi terbaik pada kebanyakan tugas NLP Arab yang diuji. Model araBERT yang dilatih dahulu tersedia pada https://github.com/aub-mind/araBERT - berharap untuk mendorong penyelidikan dan aplikasi untuk NLP Arab.', 'mk': 'Арапскиот јазик е морфолошки богат јазик со релативно малку ресурси и помалку истражена синтакса во споредба со англискиот. Со оглед на овие ограничувања, задачите на арапскиот природен јазик процес (НЛП), како што се чувствителната анализа (СА), именуваното препознавање на ентитетите (НЕР) и одговорот на прашањата (QA), се покажаа дека се многу тешки за решавање. Неодамна, со зголемувањето на моделите базирани на трансформатори, моделите базирани на јазик БЕРТ се докажаа дека се многу ефикасни во разбирањето на јазикот, под услов дека се предобучени на многу голем корпус. Таквите модели успеаа да постават нови стандарди и да постигнат најдобри резултати за повеќето задачи на НЛП. In this paper, we pre-trained BERT specifically for the Arabic language in the pursuit of achieving the same success that BERT did for the English language.  Представноста на АраБЕРТ се споредува со мултијазичниот БЕРТ од Гугл и другите најнови пристапи. Резултатите покажаа дека новиот развиен АраБЕРТ постигна најсовремена резултат на најтестираните арапски НЛП задачи. The pretrained araBERT models are publicly available on  https://github.com/aub-mind/araBERT Се надевам дека ќе охрабри истражување и апликации за арапската НЛП.', 'mt': 'Il-lingwa Għarbija hija lingwa morfoloġikament rikka b’relattivament ftit riżorsi u sintaks anqas esplorat meta mqabbel mal-Ingliż. Minħabba dawn il-limitazzjonijiet, il-kompiti tal-Ipproċessar tal-Lingwi Naturali Għarab (NLP) bħall-Analiżi tas-Sentiment (SA), ir-Rikonoxximent tal-Entità bl-Isem (NER), u t-Tweġiba għall-Mistoqsijiet (QA), urew li huma sfida ħafna biex jiġu indirizzati. Dan l-a ħħar, biż-żieda ta’ mudelli bbażati fuq it-trasformaturi, mudelli bbażati fuq il-BERT speċifiċi għall-lingwa wrew li huma effiċjenti ħafna fil-fehim tal-lingwa, sakemm ikunu mħarrġa minn qabel fuq korpus kbir ħafna. Dawn il-mudelli setgħu jistabbilixxu standards ġodda u jiksbu riżultati l-aktar avvanzati għall-biċċa l-kbira tal-kompiti tal-NLP. F’dan id-dokument, aħna mħarrġin minn qabel lill-BERT speċifikament għall-lingwa Għarbija biex inkisbu l-istess suċċess li għamel il-BERT għall-lingwa Ingliża. Il-prestazzjoni ta’ AraBERT titqabbel ma’ BERT multilingwi minn Google u approċċi oħra l-aktar avvanzati. Ir-riżultati wrew li l-AraBERT li għadu kif ġie żviluppat kiseb prestazzjoni avvanzata fil-biċċa l-kbira tal-kompiti tal-NLP Għarab ittestjati. Il-mudelli araBERT mħarrġa minn qabel huma disponibbli pubblikament fuq https://github.com/aub-mind/araBERT • li jittama li jinkoraġġixxu r-riċerka u l-applikazzjonijiet għall-NLP Għarab.', 'ml': 'അറബി ഭാഷ ഒരു മോര്\u200dഫോളജിക്കല്\u200d സമ്പന്നമായ ഭാഷയാണ് ഇംഗ്ലീഷിനെക്കുറിച്ച് കുറച്ച് വിഭവങ്ങളുമുള്ള സിന്\u200dടാക Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle.  അടുത്തുതന്നെ, മാറ്റങ്ങളുടെ അടിസ്ഥാനത്തിലുള്ള മോഡലുകളുടെ തൂക്കത്തില്\u200d, ഭാഷ-പ്രത്യേക ബെര്\u200dട്ടി അടിസ്ഥാനമായ മോഡലുകള്\u200d ഭാഷ ബുദ്ധിയുടെ മനസ്സില ഇത്തരം മോഡലുകള്\u200dക്ക് പുതിയ സ്റ്റഡേറ്ററുകള്\u200d സജ്ജീകരിക്കാന്\u200d സാധിച്ചിരുന്നു. ഏറ്റവും പേരും NLP ജോലികള്\u200d ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d ബെര്\u200dട്ടിനെ പ്രത്യേകിച്ച് പരിശീലിപ്പിച്ചത് പ്രത്യേകിച്ച് അറബി ഭാഷയ്ക്ക് വേണ്ടിയാണ്. ബെര്\u200dട്ടിന്  ആരാബെര്\u200dട്ടിന്റെ പ്രദര്\u200dശനം ഗൂഗിളില്\u200d നിന്നും മറ്റു കലാകാര്\u200dട്ടില്\u200d നിന്നും അധിക ഭാഷ ബെര്\u200dട്ടിനോടും താല്\u200dപര്യമാണ പരീക്ഷിച്ചതില്\u200d ഏറ്റവും പരീക്ഷിക്കപ്പെട്ട അറബിര്\u200dട്ടി പുതിയ പരിശോധിച്ചിരിക്കുന്ന ആരാബെര്\u200dട്ടിയുടെ സ്ഥിതിയില അറബെര്\u200dട്ടി മോഡലുകള്\u200d പ്രത്യേകിച്ച് ലഭ്യമാണ് https://github.com/aub-mind/araBERT അറബി എംഎല്\u200dപിയ്ക്ക് വേണ്ടി പരിശോധനവും പ്രയോഗങ്ങളും ആശ്രയിക്കാന്\u200d പ്രതീക്ഷിക്കുന്നു.', 'no': 'Arabisk språk er eit morfologisk rikt språk med relativt få ressursar og mindre utforska syntaks sammenlignet med engelsk. Given desse grensene, har oppgåver som Sentiment Analysis (SA), Named Entity Recognition (NER) og Question Answering (QA) vist til at det er veldig vanskeleg å løyse. Nyleg har det vist å vera veldig effektiv ved språk forståking av transformatorbaserte modeller, dersom dei er først trent på ein veldig stor korpus. Desse modeller vart i stand til å setja nye standardar og oppnå tilstanden av kunsten for dei fleste NLP-oppgåver. I denne papiret har vi forelært BERT spesielt for den arabiske språket i følgje til å oppnå det samme suksess BERT gjorde for engelske språk. Utviklinga av AraBERT er samanlikna med fleire språk BERT frå Google og andre tilstand av kunsten. Resultatet viste at den nye utviklinga AraBERT har oppnådd status-of-the-art performance på dei mest testerte arabiske NLP-oppgåva. Den pretraine araBERT-modellen er tilgjengeleg offentlig på https://github.com/aub-mind/araBERT Håp om å oppretta forskning og program for arabisk NLP.', 'mn': 'Араб хэл нь англи хэлний харьцуулахад бага баялаг хэл, бага баялаг судалсан синтаксис юм. Эдгээр хязгаарлалууд нь Араб байгалийн хэл процесс (NLP) шиг Sentiment Analysis (SA), нэрлэгдсэн Entity Recognition (NER) болон асуулт хариулт (QA) үүсгэх нь маш хэцүү байдаг. Сүүлийн үед өөрчлөгчийн загваруудын суурилсан загваруудыг нэмэгдүүлснээр хэл дээр тодорхой BERT-ийн загварууд хэл ойлголтын тулд маш үр дүнтэй байдаг гэдгийг баталсан. Ийм загварууд шинэ стандарт гаргаж, ихэнх NLP даалгаварын төлөө урлагийн үр дүн гаргаж чадсан. Энэ цаасан дээр бид БЕРТ-г англи хэл дээр хийсэн амжилтыг хүртэхийн тулд ялангуяа Араб хэлний хувьд сургалтын тулд сургалтын төлөө хийсэн. ААБЕРТ-ын үйл ажиллагаа нь Google-ын олон хэлний БЕРТ болон бусад урлагийн тусламжтай харьцуулдаг. Үр дүнд шинэ хөгжсөн Араберт нь Араб НLP даалгаварын хамгийн шинжлэх ухааны үйл ажиллагааг гаргасан. Өнгөрсөн араберт загварууд олон нийтэд https://github.com/aub-mind/araBERT Араб NLP-ын судалгаа болон хэрэглээ дэмжих гэж найдаж байна.', 'ro': 'Limba arabă este o limbă bogată din punct de vedere morfologic, cu relativ puține resurse și o sintaxă mai puțin explorată în comparație cu limba engleză. Având în vedere aceste limitări, sarcini de procesare a limbii naturale arabe (PNL), cum ar fi analiza sentimentelor (SA), recunoașterea entităților denumite (NER) și răspunsul la întrebări (QA), s-au dovedit a fi foarte dificil de abordat. Recent, odată cu creșterea modelelor bazate pe transformatoare, modelele bazate pe limbă BERT specifice s-au dovedit a fi foarte eficiente în înțelegerea limbii, cu condiția ca acestea să fie pre-instruite pe un corpus foarte mare. Astfel de modele au fost capabile să stabilească noi standarde și să obțină rezultate de ultimă generație pentru majoritatea sarcinilor PNL. În această lucrare, am pregătit BERT special pentru limba arabă în căutarea de a obține același succes ca BERT pentru limba engleză. Performanța AraBERT este comparată cu BERT multilingv de la Google și cu alte abordări de ultimă generație. Rezultatele au arătat că noul AraBERT dezvoltat a obținut performanțe de ultimă oră în cele mai multe sarcini testate din PNL arabe. Modelele araBERT pretrainate sunt disponibile public pe https://github.com/aub-mind/araBERT sperând să încurajeze cercetarea și aplicațiile pentru PNL arab.', 'pl': 'Język arabski jest bogatym morfologicznie językiem o stosunkowo niewielkich zasobach i mniej zbadanej składni w porównaniu do angielskiego. Biorąc pod uwagę te ograniczenia, zadania przetwarzania języka naturalnego arabskiego (NLP), takie jak analiza sentymentów (SA), rozpoznawanie nazwanych podmiotów (NER) i odpowiedź na pytania (QA), okazały się bardzo trudne do rozwiązania. Ostatnio, wraz z napięciem modeli opartych na transformatorach, modele oparte na języku BERT okazały się bardzo skuteczne w rozumieniu języka, pod warunkiem że są wstępnie przeszkolone na bardzo dużym korpusie. Takie modele były w stanie wyznaczyć nowe standardy i osiągnąć najnowocześniejsze wyniki dla większości zadań NLP. W niniejszym artykule wstępnie szkoliliśmy BERT specjalnie dla języka arabskiego w dążeniu do osiągnięcia tego samego sukcesu, co BERT zrobił w języku angielskim. Wydajność AraBERT porównywana jest z wielojęzycznym BERT firmy Google i innymi najnowocześniejszymi podejściami. Wyniki pokazały, że nowo opracowany AraBERT osiągnął najnowocześniejszą wydajność w większości testowanych arabskich zadań NLP. Wstępnie trenowane modele araBERT są publicznie dostępne na stronie internetowej https://github.com/aub-mind/araBERT mając nadzieję zachęcić do badań i aplikacji dla arabskiego NLP.', 'si': 'අරාබි භාෂාව තමයි ප්\u200dරමාණ භාෂාවක් සම්බන්ධයෙන්ම සම්බන්ධයෙන් ප්\u200dරමාණ භාෂාවක් සහ අඩුවෙන අරාබික භාෂාව ප්\u200dරවේශනය (NLP) විශ්ලේෂණය (SA), නම් තියෙන ප්\u200dරශ්නයක් ප්\u200dරශ්නය (NER), සහ ප්\u200dරශ්නයක් ප්\u200dරතික්ෂණය (QA) විදිහට ප්\u200dරශ්නයක් විද අවසානයෙන්, වෙනස් කරණාකරණය අධාරිත මොඩේල් එක්ක, භාෂාව විශේෂ BERT අධාරිත මොඩේල් එක්ක බොහොම ප්\u200dරයෝජනය වෙන්න පුළුවන ඒ වගේ මොඩල් අලුත් ප්\u200dරමාණය සැකසුම් කරලා තියෙන්න පුළුවන් වුනා සහ NLP වැඩේ වැඩි වැඩි වැඩි වැඩි වැඩිය මේ පත්තරේ අපි BERT විශේෂයෙන් අරාබි භාෂාව සඳහා ප්\u200dරශ්නයක් කළා ඉංග්\u200dරීසි භාෂාව සඳහා BERT කරපු එකම සමහර විශේ අරාබෙර්ට්ගේ ප්\u200dරමාණය ගුගුල් වලින් බෙර්ට්ට් වලින් සහ අනිත් ස්ථානයක් සම්බන්ධ වෙනවා. ප්\u200dරතිචාරය පෙන්වන්නේ අළුත් විකාශ කරපු අරාබෙර්ට් එක්ක තත්වයේ ක්\u200dරියාත්මක වැඩි පරීක්ෂා කරපු අරාබි පුරුදු අරාබෙර්ට් මෝඩේල් සාමාන්\u200dයයෙන් ප්\u200dරවේශ වෙන්න පුළුවන් https://github.com/aub-mind/araBERT අරාබික් NLP සඳහා පරීක්ෂණය සහ අවශ්\u200dයාව සම්බන්ධ කරන්න බලාපොරොත්තු වෙනවා.', 'sv': 'Det arabiska språket är ett morfologiskt rikt språk med relativt få resurser och en mindre utforskad syntax jämfört med engelska. Med tanke på dessa begränsningar har uppgifter som Sentiment Analysis (SA), Named Entity Recognition (NER) och Question Answering (QA) visat sig vara mycket utmanande att hantera. Nyligen har språkspecifika BERT-baserade modeller visat sig vara mycket effektiva när det gäller språkförståelse, förutsatt att de är förberedda på en mycket stor korpus. Sådana modeller kunde sätta nya standarder och uppnå toppmoderna resultat för de flesta NLP-uppgifter. I denna uppsats förberedde vi BERT specifikt för det arabiska språket i strävan efter att uppnå samma framgång som BERT gjorde för det engelska språket. AraBERT:s prestanda jämförs med flerspråkig BERT från Google och andra toppmoderna metoder. Resultaten visade att den nyutvecklade AraBERT uppnådde toppmodern prestanda på de flesta testade arabiska NLP-uppgifter. De förkränade araBERT-modellerna är tillgängliga för allmänheten på https://github.com/aub-mind/araBERT hoppas kunna uppmuntra forskning och tillämpningar för arabisk NLP.', 'so': "Luqada Carabigu waa luqad hodan ah oo la xiriira rasmi yar iyo mid ka yar kaalmada la barto ingiriisiga. Xiriiriyadan waxaa lagu xaqiijiyey shaqooyin baaritaanka afka asalka ah (NLP) oo la mid ah fasaxa (SA), Aqoonsashada Entity (NER), iyo jawaabta su'aalaha (QA) inay aad u adag tahay inay tacliiyaan. Muddii ugu dhowaaday, marka qaababka beddelka lagu dhigay, tusaalooyin ku saleysan afka gaar ah BERT waxay caddeysay inay aad u faa’iido u tahay fahanka luuqada, haddii ay horay u tababartay korpus aad u weyn. Tusaaladan ayaa awoodi kara in ay sameyn karaan 标准yo cusub, waxayna heli karaan arimaha farshaxanka ee ugu badan shaqooyinka NLP. Warqadan, waxaynu horay ugu tababarinnay BERT si gaar ah ugu tababarinnay luqada Carabiga, markii aan dhamaadno liibaanka isku mid ah ee BERT u sameeyey afka Ingiriiska. Dhaqanka AraBERT waxaa la barbaranayaa BERT luuqadaha kala duduwan ee Google iyo habka kale ee farshaxanta. Abaalkii waxay muuqatay in waqtiga cusub ee soo hormariyey AraBERT gaadhay state-of-the-art performance in ugu badan la imtixaamay shaqada Carabiga NLP. Tusaalada araBERT ee la soo daabacay waxay si bayaan ah uga helaan https://github.com/aub-mind/araBERT waxaan rajaynayaa in la dhiirrigeliyo waxbarasho iyo codsiyada afka Carabiga NLP.", 'sr': 'Arapski jezik je morfološki bogat jezik sa relativno malo resursa i manje istražena sintaksa u usporedbi sa engleskim jezikom. S obzirom na te ograničenja, radovi Arapskog prirodnog jezika (NLP) poput Sentimentne analize (SA), priznanja podataka imenovanih podataka (NER) i odgovora na pitanja (QA), dokazali su da su veoma izazovni za rješavanje. Nedavno, s porastom modela na osnovu transformatora, modeli koji su temeljeni na jeziku BERT-u pokazali su veoma efikasni na razumijevanju jezika, ako su predobučeni na veoma velikom korpusu. Takvi modeli su uspjeli postaviti nove standarde i ostvariti rezultate umetnosti za većinu zadataka NLP-a. U ovom papiru smo predobučili BERT posebno za arapski jezik u potrazi za istim uspjehom koji je BERT uradio za engleski jezik. Izvrsnost AraBERT se uspoređuje sa multijezičkim BERT-om iz Google-a i drugim pristupima umetnosti. Rezultati su pokazali da je novi razvijen AraBERT postigao državni izvor umjetnosti na najtestiranijim arapskim NLP zadatkima. Preklinjeni araBERT modeli su javno dostupni na https://github.com/aub-mind/araBERT Nadajući se da će potaknuti istraživanje i prijave za arapski NLP.', 'ta': 'அரபி மொழி என்பது சொற்ப சிறிய வளர்ச்சிகளுடன் மொழியில் உள்ளது மற்றும் ஆங்கிலத்திற்கு ஒப்பிடும் குறைவான தேவை இந்த எல்லைகள் கொடுத்திருந்தால், அரபி இயற்கை மொழி செயல்பாடு (NLP) சென்டிமென்ட் Analysis (SA), பெயர் பெயர் உள்ளீட்டு அறிவிப்பு (NER) மற்றும் கேள்வி பதில் (QA) போன்ற ச சமீபத்தில், மாற்றங்கள் அடிப்படையில் உள்ள மாதிரிகளின் அளவிற்கு, மொழி- குறிப்பிட்ட BERT அடிப்படையில் உள்ள மாதிரிகள் மொழி புரிந்து கொள்ள முன்ப இவ்வாறு மாதிரிகள் புதிய நிலைகளை அமைக்க முடியவில்லை மற்றும் பெரும்பாலான NLP பணிகளுக்கான நிலையில் கலை முடி இந்த காகிதத்தில், நாம் பிரெட் குறிப்பாக அரபி மொழிக்கு பயிற்சியாக முன் பயிற்சி செய்தோம் பிரெட் ஆங்கிலத்திற்கு பி அராபெர்டின் செயல்கூறு பல மொழி பிரெட்டின் ஒப்பிடுவது கூகுலில் இருந்து மற்றும் கலை நிலையில் இருந்து மற்ற நிலைம முடிவு ஏர்பெர்ட் மாதிரிகள் பொதுவாக கிடைக்கும் https://github.com/aub-mind/araBERT - அரபி NLP க்கான ஆராய்ச்சி மற்றும் பயன்பாடுகளை உறுதிப்படுத்த நம்புகிறேன்.', 'ur': 'عربی زبان ایک مالک زبان ہے جو نسبت تھوڑے منابع اور اندھیری سینٹکس کے مقابلہ میں کم تحقیق کیا گیا ہے۔ یہ محدودیتوں کے باعث عربی طبیعی زبان پردازش (NLP) کے کاموں کی وجہ سے سنتیمنٹ تحلیل (SA), نام رکھا ہوا اینٹیٹی شناخت (NER) اور سوال جواب دینے (QA) کو ثابت ہو چکا ہے۔ اچھے سے، تبدیل کرنے والوں کی مدلکوں کے ذریعہ، زبان-خاص BERT بنیاد مدلکوں نے زبان سمجھنے کے لئے بہت اثبات کے ساتھ ثابت کی ہے، اگر یہ ایک بہت بڑے کورپوس پر پیش آموزش کی جاتی ہیں۔ ایسے موڈلے نئی استاندارڈ بنا سکتے تھے اور ان کے اکثر NLP کاموں کے لئے موقعیت کا نتیجہ پہنچا سکتے تھے. اس کاغذ میں ہم نے BERT کو مخصوصاً عربی زبان کے لئے آموزش دی ہے جس طرح BERT انگلیسی زبان کے لئے کیا تھا۔ آرابرٹ کی عملکرد گگل اور دوسری ایٹ آرت کے قریبوں سے بہت سی زبانی BERT کے مقابلہ میں ہے. نتیجے دکھائے گئے کہ نئی آرابرٹ نے بہترین آزمائش عربی NLP کے کاموں پر استعمال کی۔ آراBERT موڈلے ظاہر طور پر موجود ہیں https://github.com/aub-mind/araBERT اس کی امید ہے کہ عربی NLP کے لئے تحقیق اور کاروباروں کی تحقیق کریں۔', 'uz': "The Arabic language is a morphologically rich language with relatively few resources and a less explored syntax compared to English.  Bu chegaralar bilan, Sentiment Analysis (SA), nomli tizimni tanlash (NER) va savol javobi (QA) kabi arab tili tabiiy jarayonlariga (NLP) vazifalar bilan ishlatiladi. Bu savol juda murakkab bo'ladi. Yaqinda o'zgarishlar asosiy modellarning ko'payishi bilan, tilning asosiy BERT asosiy modellari tilni o'rganishga juda muhim ishlaydi, agar ular juda katta katta korpusda o'rganishdan oldin. Bu modellarni yangi standardlarni oʻrnatish mumkin va ko'pchilik NLP vazifalari uchun shaxsiy narsalar natijalarini bajaradi. Bu hujjatda biz ingliz tili uchun BERT ishga tushirilgan bir muvaffaqiyatli o'rganishga tayyorlamiz. AraBERT bajarishi Google bilan bir necha tildagi BERT kabi va boshqa holatning holatiga qarang. Natijalarni ko'rsatadi, yangi taʼminlovchi AraBERT haqida ko'paytirilgan arab NLP vazifalarining eng taʼminlov sohasini bajardi. Name https://github.com/aub-mind/araBERT Arab NLP uchun tahrirlash va dasturlarni ishlab chiqarishni himoyalash mumkin.", 'vi': 'Ngôn ngữ Ả Rập là một ngôn ngữ ngữ có lịch sử giàu có với một số nguồn tài nguyên tương đối ít được khám phá hơn so với tiếng Anh. Dựa trên những hạn chế này, các công việc xử lý ngôn ngữ tự nhiên của Ả Rập (NLP) như là một phiên bản phân tích cảm xúc (SA), Tênd Entity recognition (NER) và thẩm vấn đáp trả (QA) đã chứng tỏ là rất khó khăn để giải quyết. Gần đây, với sự tăng vọt các mô hình dựa trên máy biến đổi, các mô hình ngôn ngữ đặc trưng của BERT đã chứng minh được rất hiệu quả trong việc hiểu biết ngôn ngữ, miễn là chúng được rèn luyện sẵn trên một tập thể rất lớn. Những mẫu này đã xác định được những tiêu chuẩn mới và đạt được kết quả tối tân cho hầu hết các công việc. Trong tờ giấy này, chúng tôi đã rèn luyện thiếu sót cho ngôn ngữ Ả Rập nhằm đạt được thành công tương tự như BERT đã làm cho ngôn ngữ Anh. Các trình diễn của AraBERT được so sánh với hỗn tạp BERT của Google và các phương pháp hiện đại khác. Kết quả cho thấy rằng AraBERT mới được phát triển đã đạt được thành quả tuyệt vời trong các công việc được thử nghiệm cao nhất của Arab ngọt ngào. The prerained araBERT xảy ra công khai trên https://github.com/aub-mind/araBERT hy vọng sẽ khuyến khích nghiên cứu và ứng dụng ngôn ngữ Chọc tức tiếng Ả Rập.', 'nl': 'De Arabische taal is een morfologisch rijke taal met relatief weinig bronnen en een minder verkende syntaxis in vergelijking met het Engels. Gezien deze beperkingen zijn taken zoals Sentiment Analysis (SA), Named Entity Recognition (NER) en Question Respwering (QA) zeer uitdagend gebleken. Onlangs, met de toename van transformatorgebaseerde modellen, hebben taalspecifieke BERT-gebaseerde modellen bewezen zeer efficiënt te zijn in het begrijpen van taal, mits ze vooraf zijn getraind op een zeer groot corpus. Dergelijke modellen waren in staat om nieuwe normen te stellen en state-of-the-art resultaten te behalen voor de meeste NLP-taken. In dit artikel hebben we BERT speciaal voor de Arabische taal voorgetraind om hetzelfde succes te bereiken als BERT voor de Engelse taal. De prestaties van AraBERT worden vergeleken met meertalige BERT van Google en andere state-of-the-art benaderingen. De resultaten toonden aan dat de nieuw ontwikkelde AraBERT state-of-the-art prestaties behaalde bij de meeste geteste Arabische NLP-taken. De voorgetrainde araBERT modellen zijn publiekelijk beschikbaar op https://github.com/aub-mind/araBERT In de hoop onderzoek en toepassingen voor Arabische NLP te stimuleren.', 'bg': 'Арабският език е морфологично богат език със сравнително малко ресурси и по-малко изследван синтаксис в сравнение с английския. Предвид тези ограничения задачите за обработка на арабски естествен език (НЛП) като анализ на чувствата (SA), разпознаване на имена на субекти (NER) и отговор на въпроси (QA), се оказаха много трудни за справяне. Напоследък, с пренапрежението на трансформаторни модели, базирани на езика модели се доказаха като много ефективни при разбирането на езика, при условие че са предварително обучени върху много голям корпус. Тези модели са в състояние да определят нови стандарти и да постигнат най-съвременни резултати за повечето задачи на НЛП. В тази статия предварително обучихме BERT специално за арабския език в стремежа да постигнем същия успех, който BERT направи за английския език. Ефективността на AraBERT се сравнява с многоезичните BERT от Google и други съвременни подходи. Резултатите показват, че новоразработеният Араберт постига най-съвременни резултати при повечето тествани задачи по арабски НЛО. Предварително обучените модели са публично достъпни на https://github.com/aub-mind/araBERT Надявайки се да насърчи изследванията и приложенията за арабското НЛП.', 'hr': 'Arapski jezik je morfološki bogat jezik sa relativno malo resursa i manje istražena sintaksa u usporedbi s engleskim jezikom. S obzirom na te ograničenja, radovi Arapskog prirodnog jezika (NLP) poput Sentimentne analize (SA), priznanja podataka imenovanih podataka (NER) i odgovora na pitanja (QA) pokazali su veoma izazovni za rješavanje. Nedavno, s porastom modela na temelju transformatora, modeli koji su temeljeni na jeziku BERT-u pokazali su vrlo učinkoviti u razumijevanju jezika, ako su predobučeni na veoma velikom korpusu. Takvi modeli su uspjeli postaviti nove standarde i ostvariti rezultate stanja umjetnosti za većinu zadataka NLP-a. U ovom papiru smo predobučili BERT posebno za arapski jezik u potrazi za ostvarivanjem istog uspjeha koji je BERT učinio za engleski jezik. Izvrsnost AraBERT se uspoređuje s višejezičkim BERT-om iz Google-a i drugim pristupima umjetnosti. Rezultati su pokazali da je novi razvijen AraBERT postigao stanje umjetnosti na najtestiranijim arapskim NLP zadatkima. Preklinjeni araBERT modeli su javno dostupni na https://github.com/aub-mind/araBERT Nadam se da će poticati istraživanje i prijave za arapski NLP.', 'da': "Det arabiske sprog er et morfologisk rigt sprog med relativt få ressourcer og en mindre udforsket syntaks sammenlignet med engelsk. I betragtning af disse begrænsninger har Arabic Natural Language Processing (NLP) opgaver som Sentiment Analysis (SA), Named Entity Recognition (NER) og Spørgsmål Besvarelse (QA) vist sig at være meget udfordrende at tackle. I den seneste tid har sprogspecifikke BERT-baserede modeller med den stigning i transformatorbaserede modeller vist sig at være meget effektive til sprogforståelse, forudsat at de er foruddannet på et meget stort korpus. Sådanne modeller var i stand til at sætte nye standarder og opnå avancerede resultater for de fleste NLP-opgaver. I denne artikel forududdannede vi BERT specifikt til det arabiske sprog i stræben efter at opnå den samme succes, som BERT gjorde for det engelske sprog. AraBERT's ydeevne sammenlignes med flersprogede BERT fra Google og andre avancerede metoder. Resultaterne viste, at den nyudviklede AraBERT opnåede state-of-the-art præstation på de fleste testede arabiske NLP-opgaver. De prætrænede araBERT modeller er offentligt tilgængelige på https://github.com/aub-mind/araBERT i håb om at fremme forskning og anvendelse af arabisk NLP.", 'de': 'Die arabische Sprache ist eine morphologisch reiche Sprache mit relativ wenigen Ressourcen und einer weniger erforschten Syntax im Vergleich zu Englisch. Angesichts dieser Einschränkungen haben sich Aufgaben der Verarbeitung natürlicher arabischer Sprache (NLP) wie Sentiment Analysis (SA), Named Entity Recognition (NER) und Question Answering (QA) als sehr schwierig erwiesen. In letzter Zeit haben sich sprachspezifische BERT-basierte Modelle mit der Zunahme transformatorbasierter Modelle als sehr effizient im Sprachverständnis erwiesen, vorausgesetzt, sie sind auf einem sehr großen Korpus vortrainiert. Solche Modelle konnten für die meisten NLP-Aufgaben neue Standards setzen und State-of-the-Art Ergebnisse erzielen. In diesem Beitrag haben wir BERT speziell für die arabische Sprache vortrainiert, um den gleichen Erfolg zu erzielen, wie BERT auch für die englische Sprache. Die Leistung von AraBERT wird mit mehrsprachigem BERT von Google und anderen State-of-the-Art Ansätzen verglichen. Die Ergebnisse zeigten, dass der neu entwickelte AraBERT bei den meisten getesteten arabischen NLP-Aufgaben auf dem neuesten Stand der Technik ist. Die vortrainierten araBERT Modelle sind öffentlich verfügbar auf https://github.com/aub-mind/araBERT In der Hoffnung, Forschung und Anwendungen für arabische NLP zu fördern.', 'id': 'Bahasa Arab adalah bahasa yang murfologis kaya dengan relatif sedikit sumber daya dan sintaks yang kurang dikeksplorasi dibandingkan bahasa Inggris. Mengingat batas-batas ini, tugas Persiapan Bahasa Alami Arab (NLP) seperti Analisi Sentiment (SA), Pengenalan Entitas bernama (NER), dan Jawaban Pertanyaan (QA), telah terbukti sangat sulit untuk diselesaikan. Baru-baru ini, dengan tumbuhan model yang berdasarkan transformator, model berbasis bahasa-spesifik BERT telah terbukti sangat efisien dalam pemahaman bahasa, dengan syarat mereka dilatih-dilatih pada korpus yang sangat besar. Model tersebut mampu menetapkan standar baru dan mencapai hasil terbaik bagi kebanyakan tugas NLP. Dalam koran ini, kami melatih BERT secara khusus untuk bahasa Arab dalam pencarian untuk mencapai sukses yang sama dengan BERT untuk bahasa Inggris. Pertunjukan AraBERT dibandingkan dengan BERT berbagai bahasa dari Google dan pendekatan terbaik lainnya. Hasilnya menunjukkan bahwa AraBERT yang baru dikembangkan mencapai prestasi terbaik pada kebanyakan tugas NLP Arab yang diuji. Model araBERT yang dilatih dahulu tersedia publik di https://github.com/aub-mind/araBERT Berharap untuk mendorong penelitian dan aplikasi untuk NLP Arab.', 'ko': '아랍어는 형태가 풍부한 언어로 영어에 비해 자원이 상대적으로 적고 문법 탐색이 적다.이러한 한계를 감안하면 감정분석(SA), 명명실체식별(NER), 질의응답(QA) 등 아랍어자연언어처리(NLP) 임무가 매우 도전적이라는 것이 입증됐다.최근transformers 기반의 모델이 급증함에 따라 특정 언어를 바탕으로 하는 BERT 모델은 언어 이해에 매우 효과적이라는 것이 증명되었다. 전제는 그들이 매우 큰 어료 라이브러리에서 미리 훈련한 것이다.이 모델들은 대부분의 NLP 작업에 대해 새로운 기준을 설정하고 가장 선진적인 결과를 얻을 수 있다.본고에서 우리는 영어와 같은 성공을 얻기 위해 아랍어를 대상으로 BERT에 대한 예비 훈련을 실시했다.AraBERT의 성능은 구글과 다른 가장 선진적인 방법에서 나온 다국어 BERT와 비교했다.그 결과 새로 개발된 아라베트는 대부분의 테스트를 거친 아랍어 NLP 임무에서 가장 선진적인 성능을 얻었다.예비 훈련을 거친 아라비아 모형은https://github.com/aub-mind/araBERT아랍어 NLP의 연구와 응용을 장려하기를 바랍니다.', 'fa': 'زبان عربی یک زبان مورفولوژیکی پولدار با نسبتا کم منابع و یک سنتاکس کوچک در مقایسه با انگلیسی است. با توجه به این محدودیت، وظیفه\u200cهای پرداخت زبان طبیعی عربی (NLP) مانند تحلیل سنتیمتر (SA), شناسایی واحد نامیده (NER) و جواب سوال (QA) ثابت کردند که برای حل کردن بسیار سخت است. اخیرا، با افزایش مدل\u200cهای متغییر\u200cکننده\u200cها، مدل\u200cهای متغییر به زبان BERT ثابت شده\u200cاند که در درک زبانی بسیار موثر است، در صورتی که آنها پیش از این روی یک کورپوس بسیار بزرگ آموزش یافته\u200cاند. این مدلها توانستند استانداردهای جدید را تنظیم کنند و نتیجه\u200cهای وضعیت هنری را برای بیشتر کارهای NLP بررسی کنند. در این کاغذ، ما BERT را پیش آموزش دادیم، مخصوصا برای زبان عربی در دنبال رسیدن موفقیت همان که BERT برای زبان انگلیسی انجام داد. عملکرد آرابرت با BERT multilingual از گوگل و دیگر نزدیک\u200cهای موجود هنر مقایسه می\u200cشود. نتیجه\u200cها نشان داده\u200cاند که آرابرت تازه توسعه داده شده\u200cای در بیشترین کارهای NLP آزمایش عربی رسیده است. مدلهای آرابرت پیش\u200cفرض به طور عمومی دسترسی دارند https://github.com/aub-mind/araBERT امیدوارم تحقیقات و کاربردهای NLP عربی را تشویق دهم.', 'sw': 'Lugha ya Kiarabu ni lugha yenye utajiri wa kifolojia yenye rasilimali chache na michache yenye uchunguzi kidogo ukilinganishwa na Kiingereza. Kwa kuzingatia vizuizi hivi, kazi za Utarabu wa Utarabu (NLP) kama vile Uchambuzi wa Sentiment (SA), Utambuzi wa Ujumbe wa Jinsia (NER), na Jawabu la swali (QA), zimekwisha kuwa na changamoto kubwa ya kupambana na mkakati. Hivi karibuni, kwa kuongezeka kwa mifano ya mabadiliko yenye msingi wa lugha, mifano maalum ya BERT yenye lugha imethibitisha kuwa na ufanisi mkubwa kwa kuelewa lugha, ikiwa ni mafunzo ya awali kwa makundi makubwa. Mfano huu uliweza kuweka viwango vipya na kupata matokeo ya hali ya sanaa kwa kazi nyingi za NLP. Katika karatasi hii, tumefundisha BERT hasa kwa lugha ya Kiarabu kufuatia mafanikio yale yaliyofanya kwa lugha ya Kiingereza. Utendaji wa AraBERT unalinganishwa na BERT kwa lugha mbalimbali kutoka Google na njia nyingine za sanaa. Matokeo yalionyesha kuwa chama kipya kilichoendelea AraBERT kilifanikiwa na hali ya sanaa katika kazi za Kiarabu zilizojaribiwa zaidi. Mradi wa araBERT unapatikana kwa uwazi https://github.com/aub-mind/araBERT  hoping to encourage research and applications for Arabic NLP.', 'tr': "Arap챌a dil, i흫lis챌e g철r채 birn채챌e 챌e힊me bolan morfologik bagly dildir we az g철zle첵채n syntaks. Bu 챌yky힊lara g철r채, Sentiment Analysis (SA), Adlanan Entity Recognition (NER), we Soragy jogaplama (QA) 첵aly Arap챌a Dogaty Dil i힊lemleri (NLP) t채zelikleri 챌철zmek 철r채n kyn챌ylykly bolupdyr. So흫ky wagtlarda, BERT'a tabanly terjime edenler nusgalary bilen, dilleri흫 체st체nde t채sirli nusgalary dilleri흫 d체힊체nmesinde 철r채n t채sirli bolup kan캇tlandyryl첵ar. Olar 철r채n uly korpusda 철흫-철흫체nden 철흫체nden okuw챌yl첵arlar. B채rde nusgalar t채ze standartlary guryp bil첵채rdi we NLP t채zeliklerini흫 k철p nusgasyna 첵etip bil첵채rdi. Bu kagyzda, BERT dilini i흫lis dilinde 첵etirmek 체챌in adat챌a 철흫체nde BERT'y 철흫체nde bilim berdik. AraBERT'y흫 etkinlik Googladan we ba힊ga sanat ta첵첵arlaryna gola첵la힊첵ar. Netijeler AraBERT t채ze geli힊mi힊 t채ze kanunlary arap NLP i힊inde test edilen t채ze kanunlary흫 체st체ne 첵etip bardygyny g철rkezildi. 횦agyryl첵an araBERT nusgalary publikat i챌inde bar https://github.com/aub-mind/araBERT Arap챌a NLP 체챌in barlag we uygulamalaryny t채sirlemek 체챌in umyt ed첵채rler.", 'af': "Die Arabiese taal is 'n morfologiese ryk taal met relativief paar hulpbronne en 'n minder uitsoek sintaks vergelyk met Engels. Gien hierdie beperkinge, die Arabiese Natuurlike Taal-Prosessering (NLP) werke soos Sentiment Analysis (SA), Gegenoem Eenheidrekening (NER), en Fraag-Antwoord Onlangs, met die verhoeging van transformers gebaseerde modele, taal-spesifieke BERT-gebaseerde modele het bevestig om baie effektief te wees by taal verstaan, voorwaar dat hulle vooraf opgelei word op 'n baie groot korpus. Soos modele was in staat om nuwe standaarde te stel en die staat-van-kuns-resultate te bereik vir die meeste NLP-opdragte. In hierdie papier, ons het BERT voorafgeleer spesifieke vir die Arabiese taal in die volg van die selfde sukses wat BERT gedoen het vir die Engels taal. Die prestasie van AraBERT is vergelyk met multilinglike BERT van Google en ander staat-van-kuns toekoms. Die resultate het vertoon dat die nuwe ontwikkelde AraBERT staat-van-kuns-prestasie op die meeste toets van Arabiese NLP-opdragte bereik het. Die presreënde araBERT-modele is openlik beskikbaar op https://github.com/aub-mind/araBERT In die hoop om forsoeking en toepassings vir Arabiese NLP te bevestig.", 'sq': "Gjuha arabe është një gjuhë morfologikisht e pasur me relativisht pak burime dhe një sintaksë më pak të eksploruar krahasuar me anglishtin. Duke pasur parasysh këto kufizime, detyrat arabe të Procesimit të Gjuhave Natyrore (NLP) si Analiza e Sentimenteve (SA), njohja e emëruar e njësisë (NER) dhe përgjigja e pyetjeve (QA) kanë provuar të jenë shumë të vështira për t'u trajtuar. Recently, with the surge of transformers based models, language-specific BERT based models have proven to be very efficient in language understanding, provided they are pre-trained on a very large corpus. Modelet e tilla ishin në gjendje të vendosin standarde të reja dhe të arrinin rezultate më të larta për shumicën e detyrave të NLP. Në këtë letër, ne paratrajnuam BERT specifikisht për gjuhën arabe në përpjekje për të arritur të njëjtin sukses që BERT bëri për gjuhën angleze. Performanca e AraBERT krahasohet me BERT shumëgjuhës nga Google dhe metoda të tjera më të larta. Rezultatet treguan se AraBERT i sapo zhvilluar arriti shfaqjen më të lartë në detyrat më të testuara të NLP arabe. Modelet e paratrajnuara të araBERT janë në dispozicion publik në https://github.com/aub-mind/araBERT  hoping to encourage research and applications for Arabic NLP.", 'am': 'ዐረብኛ ቋንቋ ከመንግሊዝኛ ጋር ጥቂት ሀብት እና ትንሽ የተመረጠው ሲንካስብ ነው፡፡ እነዚህን ግንኙነት፣ አረቢኛ የፍጥረት ቋንቋ ፕሮጀክት (NLP) ሥርዓቶች እንደ ሳንተርናዊ Analysis (SA), የስሜት ውጤት ማውቀት (NER) እና ጥያቄ መልስ (QA) በመቃወም በጣም አቃውሎ ነው፡፡ Recently, with the surge of transformers based models, language-specific BERT based models have proven to be very efficient at language understanding, provided they are pre-trained on a very large corpus.  እንደዚህ ዓይነቶች አዲስ standard ማዘጋጀት ይችላሉ እና ለብዙዎቹ NLP ስራቶች የ-art ውጤቶችን ለማግኘት ይችላሉ፡፡ በዚህ ገጽ BERT በተለየን ለዐረብኛ ቋንቋ ብኤርቴን ለማግኘት የኢንግሊዝኛ ቋንቋ የተደረገውን ያን ድል ለማግኘት ለመፈለግ አስቀድመን ነበር፡፡ የAraBERT ድምፅ ከጎግል እና ከሌሎች የዓርት ግንኙነት ብሪቴን ለመተካከል ነው፡፡ ፍሬዎቹ አዲስ አረቢ አርቢ አርቢ የዓረብኛ አርቢ ስርዓት የ-የ-የ-አርእስት አግኝቷል፡፡ የተከፋፈሉት አረቢብERT ሞዴላዎች በህዝብ ላይ የተገኙ ናቸው https://github.com/aub-mind/araBERT በአረቢኛ NLP ላይ ትምህርት እና ፕሮግራሞች ለማጽናናት ተስፋ አደርጋለሁ፡፡', 'bn': 'আরবী ভাষা হচ্ছে একটি মরোফোলজিক ভাষায় সমৃদ্ধ ভাষা, যার সাথে সামান্য কিছু সম্পদ এবং ইংরেজীর তুলনায় কম অনুসন্ধান করা সিন এই সীমাবদ্ধতা দিয়ে আরবী প্রাকৃতিক ভাষার প্রক্রিয়া (এনএলপি) কাজগুলো সেন্টাইমেন্ট বিশ্লেষণ (এসএ), নামের ইনটিটি স্বীকৃতি এবং প্রশ্নের উত্তর (কিউ এ) যুক্ত সম্প্রতি পরিবর্তনের ভিত্তিক মডেলে ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক মডেল ভাষায় ভাষা বুঝতে বেশ কার্যকর, যদি তারা অনেক বড় কো এরকম মডেলগুলো নতুন ম্যান্ডার নির্ধারণ করতে পারে এবং বেশীরভাগ NLP কাজের রাষ্ট্র-শিল্পের ফলাফল অর্জন করতে পারে। এই কাগজটিতে আমরা বিরেট প্রশিক্ষণের পূর্বে প্রশিক্ষণ প্রদান করেছি বিশেষ করে বিরেটি ইংরেজি ভাষার জন্য একই সফল পৌঁছানোর জন্য। আরাবেরেটের প্রদর্শনীর তুলনায় গুগল থেকে বহুভাষার বিবেরেট এবং অন্যান্য রাষ্ট্র-অফ শিল্পের প্রতিক্রিয়ার তুলনায়। The results showed that the newly developed AraBERT achieved state-of-the-art performance on most tested Arabic NLP tasks.  প্রাপ্ত আরাবেরেট মডেল প্রকাশ্যে পাওয়া যাচ্ছে https://github.com/aub-mind/araBERT আরবী এনএলপির গবেষণা এবং অ্যাপ্লিকেশন উৎসাহিত করতে আশা করি।', 'az': "Arapçalıq dili çox az qüvvətli və az keşfedilmiş sintaks dilidir İngilizə qarşı. Bu limitlərə görə, ərəbcə təbiətli dil işləməsi (NLP) işləri Sentiment Analysis (SA), Adlı Entity Recognition (NER) və sual Cevapı (QA) kimi çəkilmək çox çətin olduqlarını kanıtladı. Son zamanlarda, transformatçıların modellərinin yüksəlişi ilə, dillərin BERT tabanlı modellərin dillərin anlaşılmasında çox faydalı olduğunu kanıtladı, əgər onlar çox böyük korpus üstündə öyrənmişlər. Bütün modellər yeni standartları təyin edə bilərdilər və NLP işlərinin əksəriyyəti üçün mövcuddur sonuçlarını başa düşə bilərdilər. Bu kağızda BERT dilini özlərinə ərəb dilini təhsil etdik və BERT dilini İngilizce dilinə təhsil etdiyi başarıya çatmaq üçün. AraBERT performansı Google'dan çoxlu dilli BERT və digər şəkildə sanat tərəfindən salınmışdır. Sonuçlar AraBERT'nin yeni təhsil edildiyini göstərdi ki, arab NLP işlərinin ən çox imtahana çəkilmiş səhifələrində təhsil edilmişdir. Yaxşı araBERT modelləri açıq-aşkar mövcuddur. https://github.com/aub-mind/araBERT Arapça NLP üçün araşdırma və uyğulamaları təşkil etmək istəyirlər.", 'bs': 'Arapski jezik je morfološki bogat jezik sa relativno malo resursa i manje istražena sintaksa u usporedbi s engleskim jezikom. S obzirom na te ograničenja, radovi Arapskog prirodnog jezika (NLP) poput Sentiment Analize (SA), priznanja imenovanih entiteta (NER) i odgovora na pitanja (QA), dokazali su da su vrlo izazovni za rješavanje. Nedavno, uz porast modela baziranih na transformacijama, modeli koji su temeljeni na jeziku BERT-u pokazali su veoma efikasni na razumijevanju jezika, ako su predobučeni na veoma velikom korpusu. Takvi modeli su uspjeli postaviti nove standarde i ostvariti rezultate stanja umjetnosti za većinu zadataka NLP-a. U ovom papiru smo predobučili BERT posebno za arapski jezik u potrazi za ostvarivanjem istog uspjeha koji je BERT učinio za engleski jezik. Izvrsnost AraBERT se uspoređuje sa multijezičkim BERT-om iz Google-a i drugim pristupima umjetnosti. Rezultati su pokazali da je novi razvijen AraBERT postigao state-of-the-art performance na najtestiranijim arapskim NLP zadatkima. Preklinjeni araBERT modeli su javno dostupni na https://github.com/aub-mind/araBERT Nadam se da će poticati istraživanje i prijave za arapski NLP.', 'ca': "La llengua àrab és una llengua rica morfològicament amb relativament pocs recursos i una sintaxi menys explorada en comparació amb l'anglès. Tenint en compte aquestes limitacions, tasques de processament de llenguatges naturals àrabs (NLP), com Anàlisi de Sentiments (SA), Recognició Nomada d'Entitat (NER) i Responses a Preguntes (QA), han demostrat ser molt difícils d'abordar. Recentment, amb l'augment de models basats en transformadors, els models basats en BERT per llenguatge han demostrat ser molt eficients en la comprensió del llenguatge, a condició que siguin pré-entrenats en un corpus molt gran. Aquests models van poder establir nous estàndards i aconseguir resultats més avançats per a la majoria de les tasques del NLP. En aquest article vam preparar BERT específicament per a la llengua àrab en busca d'aconseguir el mateix èxit que BERT va fer per a la llengua anglesa. El rendiment d'AraBERT es compara amb el BERT multilingüe de Google i d'altres enfocaments més avançats. Els resultats van demostrar que el AraBERT recientement desenvolupat va aconseguir un rendiment més avançat en la majoria de tasques de NLP àrabs testades. Els models araBERT pré-entrenats estan disponibles en https://github.com/aub-mind/araBERT  hoping to encourage research and applications for Arabic NLP.", 'cs': 'Arabský jazyk je morfologicky bohatý jazyk s relativně málo zdrojů a méně prozkoumanou syntaxi ve srovnání s angličtinou. Vzhledem k těmto omezením se ukázalo, že úkoly zpracování arabského přirozeného jazyka (NLP), jako je analýza sentimentů (SA), rozpoznávání jmenovaných entit (NER) a odpověď na otázky (QA), jsou velmi náročné na řešení. V poslední době se vzhledem k nárůstu modelů založených na transformátorech ukázaly, že jazykově specifické modely založené na BERT jsou velmi efektivní při porozumění jazyků, pokud jsou předškoleny na velmi velkém korpusu. Tyto modely byly schopny stanovit nové standardy a dosáhnout nejmodernějších výsledků pro většinu úkolů NLP. V tomto příspěvku jsme předškolili BERT speciálně pro arabský jazyk, abychom dosáhli stejného úspěchu jako BERT v angličtině. Výkon AraBERT je porovnáván s vícejazyčným BERT od Google a dalšími moderními přístupy. Výsledky ukázaly, že nově vyvinutý AraBERT dosáhl nejmodernějšího výkonu u většiny testovaných arabských NLP úloh. Předtrénované modely araBERT jsou veřejně dostupné na internetu https://github.com/aub-mind/araBERT Doufám, že podpoří výzkum a aplikace pro arabské NLP.', 'hy': 'The Arabic language is a morphologically rich language with relatively few resources and a less explored syntax compared to English.  Եթե հաշվի առնենք այս սահմանափակումները, արաբական բնական լեզվի վերլուծությունը (ՆԼՊ) այնպիսի խնդիրներ, ինչպիսիք են զգացմունքների վերլուծությունը (ՍԱ), անվանված անհատականության ճանաչելը (ՆԵՌ) և հարցերի պատասխանը (QA), ապացուցել են, որ շատ դժվար Վերջերս, վերափոխողների հիմնված մոդելների աճի դեպքում լեզվի մասնավոր BER-ի հիմնված մոդելները պարզվեցին շատ արդյունավետ լեզվի հասկացության մեջ, եթե նրանք նախապատրաստված են շատ մեծ մարմնի վրա: Այսպիսի մոդելները կարողացան նոր ստանդարտներ սահմանել և լավագույն արդյունքներ հասնել ՆԼՊ խնդիրների մեծ մասի համար: Այս թղթի մեջ մենք նախապատրաստում էինք BER-ը հատկապես արաբական լեզվի համար, որպեսզի հասնենք նույն հաջողությունը, ինչ BER-ը անգլերեն լեզվի համար: Արաբերթի արտադրությունը համեմատում է Google-ի և այլ ամենահետաքրքիր մոտեցումների բազլեզու Բերթին: Արդյունքները ցույց տվեցին, որ նորից զարգացած Արաբերթը հասավ ամենաբարձր արդյունքների ամենափորձարկված արաբական ՆԼՊ-ի խնդիրների վրա: The pretrained araBERT models are publicly available on  https://github.com/aub-mind/araBERT - հույս ունելով խրախուսել ուսումնասիրություններ և ծրագրեր արաբական ՆԼՊ-ի համար:', 'fi': 'Arabian kieli on morfologisesti rikas kieli, jolla on suhteellisen vähän resursseja ja vähemmän tutkittu syntaksi verrattuna englantiin. Näiden rajoitusten vuoksi arabian luonnollisen kielen käsittelyn (NLP) tehtävät, kuten Sentiment Analysis (SA), Nimetty entity Recognition (NER) ja Question Answering (QA), ovat osoittautuneet erittäin haastaviksi käsitellä. Muuntajapohjaisten mallien nousun myötä kielispesifiset BERT-pohjaiset mallit ovat osoittautuneet erittäin tehokkaiksi kielen ymmärtämisessä edellyttäen, että ne on koulutettu hyvin suurelle korpuselle. Näillä malleilla pystyttiin asettamaan uusia standardeja ja saavuttamaan huipputason tulokset useimmissa NLP-tehtävissä. Tässä artikkelissa esikoulutimme BERT:n erityisesti arabian kielellä pyrkiäksemme saavuttamaan saman menestyksen kuin BERT teki englannin kielellä. AraBERTin suorituskykyä verrataan Googlen monikieliseen BERT-järjestelmään ja muihin huippuluokan lähestymistapoihin. Tulokset osoittivat, että juuri kehitetty AraBERT saavutti huipputason suorituskyvyn useimmissa testatuissa arabiankielisissä NLP-tehtävissä. Esikoulutetut araBERT-mallit ovat julkisesti saatavilla osoitteessa https://github.com/aub-mind/araBERT toivoen rohkaista tutkimusta ja sovelluksia arabian NLP.', 'et': "Araabia keel on morfoloogiliselt rikas keel, millel on suhteliselt vähe ressursse ja vähem uuritud süntaks võrreldes inglise keelega. Neid piiranguid arvestades on araabia looduskeele töötlemise (NLP) ülesanded, nagu tunnete analüüs (SA), nimetatud üksuste tunnustamine (NER) ja küsimustele vastamine (QA), osutunud väga keeruliseks. Hiljuti on transformaatoritel põhinevate mudelite suurenemisega keelespetsiifilised BERT-põhised mudelid osutunud keele mõistmisel väga tõhusaks, tingimusel et nad on eelnevalt koolitatud väga suure korpusega. Sellised mudelid suutsid kehtestada uued standardid ja saavutada uusimaid tulemusi enamiku uue uue tööprogrammi ülesannete puhul. Käesolevas töös koolitasime BERT-i spetsiaalselt araabia keele jaoks, et saavutada sama edu, mida BERT tegi inglise keele puhul. AraBERTi tulemuslikkust võrreldakse Google'i mitmekeelse BERTi ja teiste kaasaegsete lähenemisviisidega. Tulemused näitasid, et äsja arendatud AraBERT saavutas tipptasemel jõudluse enamikus testitud Araabia uue õppekava ülesannetes. Eeltreenitud araBERT mudelid on avalikult kättesaadavad aadressil https://github.com/aub-mind/araBERT lootes julgustada Araabia uue õppekava teadusuuringuid ja rakendusi.", 'sk': 'Arabski jezik je morfološko bogat jezik z relativno malo virov in manj raziskano sintakso v primerjavi z angleščino. Glede na te omejitve se je izkazalo, da so naloge obdelave arabskega naravnega jezika (NLP), kot so analiza čustev (SA), prepoznavanje imenovanih subjektov (NER) in odgovarjanje na vprašanja (QA), zelo zahtevne. V zadnjem času so se z napetostjo transformatorskih modelov jezikovno specifični modeli BERT izkazali za zelo učinkovite pri razumevanju jezika, če so predhodno usposobljeni na zelo velikem korpusu. Takšni modeli so lahko določili nove standarde in dosegli najsodobnejše rezultate za večino nalog novega delovnega programa. V tem prispevku smo BERT predhodno usposabljali posebej za arabski jezik, da bi dosegli enak uspeh kot BERT za angleški jezik. Uspešnost AraBERT se primerja z večjezičnim BERT iz Googla in drugimi najsodobnejšimi pristopi. Rezultati so pokazali, da je novo razvit AraBERT dosegel najsodobnejše zmogljivosti pri večini preskušenih arabskih nalog NLP. Predtrenirani modeli araBERT so javno dostopni na spletni strani https://github.com/aub-mind/araBERT v upanju, da bo spodbudil raziskave in aplikacije za arabsko NLP.', 'ha': "Harabci na Larabci yana da wata harshe na morfologically matajiri da ma'auni kaɗan kuma da abu kaɗan da aka samu da suntakin da Ingiriya. Gida waɗannan tsaro, aka sami aikin Harabi na Fasarin Lugha Kiarabu (NLP) kamar Analyze na Saukar (SA), Ananin Entity Recognition (NER), da Jawabar QA, sun jarraba su zama mai tsananin hanyarwa zuwa takin. A yanzu, da surar misãlai masu shige masu basara a bakin ayuka, misãlai masu ƙayyade BERT masu jarraba ya zama mai amfani da fasalin harshen, ko kuma idan an yi amfani da su a kan wani umarni mai girma. Waɗannan misalin sun iya iya daidaita kima na yanzu kuma su sami matsalar-halin-art wa masu yawa na aikin NLP. Ga wannan takardan, mun yi wa tunkuɗawa da BERT na ƙayyade wa harshen Larabci, a lokacin da za'a sãmi babban rabo da BERT ya aikata sabõda harshen Ingirinsa. Sunan AraBERT kamar misalin multi-linguin BERT daga Google da wasu halin-of-the-art. Result nuna that the newly developed AraBERT achieved state-of-the-art performance on most jarrabi taskõkin NLP. Ana iya da misalin araBERT da ake ƙayyade https://github.com/aub-mind/araBERT Ina kwaɗayin su ƙara wa fitina da shiryoyin ayuka na arabu NLP.", 'bo': 'ཨ་རབ་ཀྱི་སྐད་ཡིག་ནི་དབྱིན་ཡིག་དང་བསྡུར་བའི་སྐད་ཡིག་ཆ་ནི་ཆ་རྐྱེན་ངལ་ཆེ་བའི་ཆ་རྐྱེན་ཡིན་པ་དང་ནང་འད Given these limits, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proved to be very challenging to tackle. འཕྲལ་ཁམས་དེ་ལྟ་བུའི་དཔེ་དབྱིབས་བཟོ་བྱེད་མཁན་གྱི་འགྱུར་བ་ལྟར་བྱས་པ་ཡིན། སྐད་ཡིག་དམིགས་བསལ་ནུས་ཀྱི་དཔེ་དབྱིབས་བྱ་རིམ་ལ་ཧ་ཅང་ཚང དཔེ་དབྱིབས་འདི་དག་གི་སྔོན་སྒྲིག་གསར་བ་སྒྲིག་ནས་གནས་སྟངས་གནས་སྟངས་དང་རྒྱས་ཁབ་ཀྱི་འབྲེལ་བ་ཡོད་པ་རྟོགས་ཐུབ་ཀྱི་ཡོད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ངེད་ཚོས་BERT སྔོན་སྒྲིག་འཛིན་གྱིས་ཨ་རིའི་སྐད་ཡིག AraBERT ཡི་སྒྲུབ་གྱི་བྱ་སྟངས་འདི་གུ་གལ་ཏུ་སྐད་ཡིག་ཆ་སྐྱེས་དང་འདྲ་བའི་མཐུན་སྣ་ཚོགས་དང་མཐུན་ཡོད། གྲུབ་འབྲས་གསར་བ་བཟོ་བྱས་ན། AraBERT་གིས་གསར་བ་སྔོན་སྒྲིག་གནས་སྟངས་གཤིས་ཀྱི་ལས་འགན་སྟངས་མང་ཤོས་བྱས་ཡོད། སྔོན་པ་ཡོད་པའི་ araBERT མིག་དཔེ་དབྱིབས་མང་ཆོས་སྤྱོད་ཐུབ་པ་ཡིན། https://github.com/aub-mind/araBERT ཨ་རབ་ཀྱི་NLP་ལ་འཚོལ་ཞིབ་དང་ཉེར་སྤྱོད་ཀྱི་རེ་བ་སྐོར་བྱེད་དགོས་པ་རེད།', 'he': 'השפה הערבית היא שפה עשירה באופן מורפולוגי עם מעט משאבים יחסית וסינטקס פחות חוקר בהשוואה לאנגלית. בהתחשב בהגבלות הללו, משימות מעבדת שפת טבעית ערבית (NLP) כמו ניתוח רגשות (SA), זיהוי איכות בשם (NER), ותשובה לשאלות (QA), הוכיחו להיות מאד מאתגרים להתמודד. לאחרונה, עם התפרצות של דוגמנים מבוססים על משתנים, דוגמנים מבוססים על BERT ספציפיים לשפה הוכיחו להיות יעילים מאוד בהבנת שפת, בהנחה שהם מאומנים מראש על קורפוס גדול מאוד. Such models were able to set new standards and achieve state-of-the-art results for most NLP tasks.  בעיתון הזה, אימנו את BERT במיוחד לשפה הערבית במטרה להשיג את אותו הצלחה שבה BERT עשה לשפה האנגלית. ההופעה של AraBERT שווה ל BERT רבולוגית מגוגל ומגישות חדשות אחרות. The results showed that the newly developed AraBERT achieved state-of-the-art performance on most tested Arabic NLP tasks.  דוגמני araBERT המאמנים מראש זמינים לציבור על https://github.com/aub-mind/araBERT בתקווה לעודד מחקר ויישומים עבור NLP ערבית.', 'jv': 'Ascening arap kuwi masalah punika dipunangka luwih karo ingkang dipunangka sing titimbang kelas karo ingkang. Ngomongke limiting iki, nggambar obang-obang Habang Daerapakan (NLP) sentiment Resolution (S), Ngatur EntityTaniksi (NeR), lan Sugeng-responsing (NLP), kang dipenangke Jaringan (question responsing) sing berartile nggawe ketahan ora apik. Sadurungé, nganggep nggunaké model sing paling transformer, sampek model sing saben nggawe BERT kuwi diangkat diangkat luwih apik jênêmêr, ngetoké dhéwé wis diangkat saben ngono akeh dumateng. Laptop" and "Desktop Nang peurén iki, awake dhewe luwih-luwih bantuan karo BERT ngono nganggo langgambar arap kanggo nggawe barang nggawe gerakan kanggo nggawe luwih apik BERT kanggo langgambar ingkang. Arep nggawe Rejalian sing ngomong nik araBERT mbutuhake nggawe barang kelas-karo iso nggawe barang kelas barang nggawe barang arap NLP. model araBERT padha biasane ono https://github.com/aub-mind/araBERT Awakdhéwé nglanggar aturan kanggo tukang karo aplikasi kanggo NLP arab.'}
{'en': 'From Arabic Sentiment Analysis to Sarcasm Detection : The ArSarcasm Dataset', 'es': 'Del análisis del sentimiento árabe a la detección del sarcasmo: el conjunto de datos ArSarcasm', 'pt': 'Da análise de sentimento árabe à detecção de sarcasmo: o conjunto de dados ArSarcasm', 'ar': 'من تحليل المشاعر العربية إلى اكتشاف السخرية: مجموعة بيانات ArSarcasm', 'fr': "De l'analyse des sentiments arabes à la détection du sarcasme\xa0: le jeu de données Arsarcasm", 'ja': 'アラビア語の感情分析から皮肉の検出まで： ArSarcasmデータセット', 'ru': 'От арабского анализа сентиментов к обнаружению сарказма: набор данных ArSarcasm', 'zh': '自阿拉伯语情析至刺检:ArSarcasm数据集', 'hi': 'अरबी भावना विश्लेषण से व्यंग्य का पता लगाने के लिए: ArSarcasm डेटासेट', 'ga': 'Ó Anailís Mothúchán Araibise go Brath Sarcasm: An Tacar Sonraí ArSarcasm', 'ka': 'აპაბური სენტიმენტის ანალიზიდან საპკასმის განახლებაზე: ArSarcasm მონაცემები', 'el': 'Από την αραβική ανάλυση συναισθημάτων στην ανίχνευση σαρκασμού: Το σύνολο δεδομένων Αρσαρκασμού', 'hu': 'Az arab érzelmek elemzésétől a szarkazmus felismeréséig: az arszarkazmus adatkészlet', 'it': "Dall'analisi dei sentimenti arabi alla rilevazione del sarcasmo: il dataset dell'arsarcasmo", 'lt': 'Nuo arabų jautrumo analizės iki sarkazmo aptikimo: ArSarkazmo duomenų rinkinys', 'mk': 'Од анализа на арапските чувства до детективација на сарказмот: Датотеката на арсарказмот', 'kk': 'Араб синтименттің анализациясынан Саркассм анықтау: ArSarcasm деректер қоры', 'ms': 'Dari Analisi Sentimen Arab ke Pengesanan Sarkasm: Dataset ArSarcasm', 'ml': 'അറബി സെന്റിമെന്റ് അന്വേഷിക്കുന്നതില്\u200d നിന്നും സര്\u200dക്കാസം ഡിറ്ററിറ്റീഷനിലേക്കു്: The ArSarcasm Dataset', 'mt': 'Mill-Analiżi tas-Sentiment Għarbi għad-Detezzjoni tas-Sarkazmu: Id-Dataset tal-ArSarkazmu', 'mn': 'Араб сэтгэл санааны шинжилгээс Саркассмын мэдээлэл: ArSarcasm өгөгдлийн сан', 'no': 'Fra arabisk sentimentanalyser til sarkasm- oppdaging: ArSarcasm- databasen', 'pl': 'Od arabskiej analizy sentymentów do wykrywania sarkazmu: zestaw danych arsarkazmu', 'ro': 'De la analiza sentimentelor arabe la detectarea sarcasmului: setul de date arSarcasm', 'sr': 'Od arapske analize sentimenta do detekcije sarkazma: Datata Arsarkazma', 'si': 'අරාබියාවෙන් සංවේදනය විශ්ලේෂණය සර්කාස්ම් හොයාගන්න: ArSarcasm දත්ත', 'so': 'Tan laga soo bilaabo baaritaanka fasaxa ee Carabiga iyo tan iyo Sarcasm: The ArSarcasm Dataset', 'sv': 'Från arabisk känsloanalys till Sarkasm Detection: ArSarkasm Dataset', 'ta': 'அரேபிய உணர்வு விளக்கம் வரை சார்காஸ் கண்டுபிடிப்பு: The ArSarcasm Dataset', 'ur': 'عربی سنٹیمنٹ تحلیل سے Sarcasm Detection: The ArSarcasm Dataset', 'uz': 'Arab Sentiment Analysis Sarkasm aniqlash: The ArSarcasm Dataset', 'vi': 'Từ phân tích tình cảm Ả rập đến trinh sát Sarcasm: the Arcasm dataset', 'bg': 'От арабски анализ на сентимента до откриване на сарказъм: набор от данни за арсарказма', 'hr': 'Od arapske analize sentimenta do detekcije sarkasma: Datacija ArSarcasma', 'nl': 'Van Arabische Sentiment Analyse tot Sarcasme Detectie: De ArSarcasme Dataset', 'da': 'Fra arabisk følelsesanalyse til opdagelse af sarkasme: ArSarkasm datasættet', 'de': 'Von der arabischen Stimmungsanalyse bis zur Sarkasmus-Erkennung: Der ArSarkasmus-Datensatz', 'id': 'Dari Analisi Sentimen Arab ke Deteksi Sarkasme: Dataset ArSarcasm', 'fa': 'از تحلیل احساسات عربی تا شناسایی سارکاسم: Databases ArSarcasm', 'sw': 'Kutoka Uchambuzi wa Seneti ya Kiarabu mpaka Kutambuliwa kwa Kisarcasm: Taarifa za ArSarcasm', 'ko': '아랍어 정서 분석부터 풍자 검출까지: ArSarcasm 데이터 세트', 'tr': 'Arapça Sentimental analizi Sarkasm Deteksi:The ArSarcasm Dataset', 'af': 'Van Arabiese Sentiment Analysis na Sarcasm Deteksie: Die ArSarcasm Dataset', 'am': 'ከዐረብኛ ሰንሰዓት መAnalysis to Sarcasm Detection: The ArSarcasm Dataset', 'az': '䅲慰쎧慤慮⁓敮瑩浥湴⁁湡汩穩湤즙渠卡牫慳洠䭥얟晩湩㨠䅲卡牫慳洠噥物泉饲椊', 'bs': 'Iz arapske analize sentimenta do detekcije sarkazma: Datata ArSarkazma', 'bn': 'From Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset', 'cs': 'Od analýzy arabských sentimentů k detekci sarkasmu: sada dat ArSarkasmu', 'ca': "Des de l'anàlisi del sentiment àrab a la detecció del sarcasme: el conjunt de dades d'ArSarcasme", 'et': 'Araabia sentimentide analüüsist sarkasmi tuvastamiseni: ArSarkasmi andmekogum', 'fi': 'Arabian tunteiden analyysistä sarkasmin havaitsemiseen: ArSarcasm Dataset', 'sq': 'Nga analiza e ndjenjave arabe deri në zbulimin e sarkazmit: Dataseti i ArSarkazmit', 'hy': 'Արաբական զգացմունքների վերլուծությունից մինչև Սարկազմի հայտնաբերումը.', 'ha': 'Analyze to Sarcasm Finding: The ArSarcasm Dataset', 'jv': 'Sentiment Resolution', 'bo': 'From Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset', 'he': 'מתוך ניתוח רגשות ערבית עד גילוי סרקזם:', 'sk': 'Od arabske analize sentimenta do zaznavanja sarkazma: nabor podatkov ArSarcasm'}
{'en': 'Sarcasm is one of the main challenges for sentiment analysis systems. Its ', 'ar': 'السخرية هي أحد التحديات الرئيسية لأنظمة تحليل المشاعر. يأتي تعقيدها من التعبير عن الرأي باستخدام الصياغة الضمنية غير المباشرة. في هذا البحث ، نقدم ArSarcasm ، وهي مجموعة بيانات عربية لاكتشاف السخرية ، والتي تم إنشاؤها من خلال إعادة صياغة مجموعات بيانات تحليل المشاعر العربية المتاحة. تحتوي مجموعة البيانات على 10547 تغريدة ، 16٪ منها ساخرة. بالإضافة إلى السخرية ، تم شرح البيانات الخاصة بالمشاعر واللهجات. يُظهر تحليلنا الطبيعة الذاتية للغاية لهذه المهام ، والتي يتضح من التحول في تسميات المشاعر بناءً على تحيزات المعلقين. تظهر التجارب تدهور أحدث أجهزة تحليل المشاعر عند مواجهة محتوى ساخر. أخيرًا ، نقوم بتدريب نموذج التعلم العميق للكشف عن السخرية باستخدام BiLSTM. يحقق النموذج درجة F1 تبلغ 0.46 ، مما يوضح الطبيعة الصعبة للمهمة ، ويجب أن يكون بمثابة الأساس الأساسي للبحث المستقبلي في مجموعة البيانات الخاصة بنا.', 'es': 'El sarcasmo es uno de los principales desafíos para los sistemas de análisis de sentimientos. Su complejidad proviene de la expresión de la opinión mediante fraseo indirecto implícito. En este artículo, presentamos ArSarcasm, un conjunto de datos de detección de sarcasmo árabe, que se creó mediante la reanotación de los conjuntos de datos de análisis de sentimientos árabes disponibles. El conjunto de datos contiene 10 547 tuits, el 16% de los cuales son sarcásticos. Además del sarcasmo, los datos se anotaron para el sentimiento y los dialectos. Nuestro análisis muestra la naturaleza altamente subjetiva de estas tareas, lo que se demuestra con el cambio en las etiquetas de opinión basadas en los sesgos de los anotadores. Los experimentos muestran la degradación de los analizadores de sentimientos de última generación cuando se enfrentan a contenido sarcástico. Finalmente, entrenamos un modelo de aprendizaje profundo para la detección de sarcasmo mediante BilsTM. El modelo logra una puntuación F1 de 0.46, lo que demuestra la naturaleza desafiante de la tarea, y debe actuar como una base de referencia básica para futuras investigaciones en nuestro conjunto de datos.', 'fr': "Le sarcasme est l'un des principaux défis des systèmes d'analyse des sentiments. Sa complexité vient de l'expression d'une opinion à l'aide d'un phrasé indirect implicite. Dans cet article, nous présentons ArSarcasm, un ensemble de données de détection du sarcasme arabe, créé par la réannotation des ensembles de données d'analyse des sentiments arabes disponibles. L'ensemble de données contient 10 547 tweets, dont 16\xa0% sont sarcastiques. En plus du sarcasme, les données ont été annotées pour le sentiment et les dialectes. Notre analyse montre la nature hautement subjective de ces tâches, comme en témoigne le changement des étiquettes d'opinion en fonction des biais des commentateurs. Les expériences montrent la dégradation des analyseurs de sentiments de pointe face à un contenu sarcastique. Enfin, nous formons un modèle d'apprentissage profond pour la détection des sarcasmes à l'aide de BilsTM. Le modèle obtient un score F1 de 0,46, ce qui montre la nature difficile de la tâche, et devrait servir de base pour les recherches futures sur notre ensemble de données.", 'pt': 'O sarcasmo é um dos principais desafios para os sistemas de análise de sentimentos. Sua complexidade vem da expressão de opinião usando frases indiretas implícitas. Neste artigo, apresentamos o ArSarcasm, um conjunto de dados de detecção de sarcasmo árabe, que foi criado por meio da reanotação de conjuntos de dados de análise de sentimentos árabes disponíveis. O conjunto de dados contém 10.547 tweets, 16% dos quais são sarcásticos. Além do sarcasmo, os dados foram anotados para sentimentos e dialetos. Nossa análise mostra a natureza altamente subjetiva dessas tarefas, o que é demonstrado pela mudança nos rótulos de sentimento com base nos vieses dos anotadores. Experimentos mostram a degradação de analisadores de sentimentos de última geração quando confrontados com conteúdo sarcástico. Por fim, treinamos um modelo de aprendizado profundo para detecção de sarcasmo usando BiLSTM. O modelo atinge uma pontuação F1 de 0,46, o que mostra a natureza desafiadora da tarefa e deve atuar como uma linha de base básica para futuras pesquisas em nosso conjunto de dados.', 'zh': '刺者,情之大体也。 其复杂性出于用隐间接辞表达意见。 本文引ArSarcasm,此阿拉伯语刺检数集,阿拉伯语情析数集而创之也。 该数集包10,547条推文,其16%为讽刺性。 自刺刺之外,数犹注情方言。 吾等分明此主观性,可以偏见标签之验也。 实验当临刺,最先情分析器退化。 最后,我们用 BiLSTM 练一个用刺检测的深度学习模样。 其F1分为0.46,明其挑战性,以为未来考数集之基线。', 'ru': 'Сарказм является одной из главных проблем для систем анализа настроений. Его сложность связана с выражением мнения с использованием неявной косвенной формулировки. В этой статье мы представляем ArSarcasm, арабский набор данных для обнаружения сарказма, который был создан путем повторной аннотации доступных наборов данных анализа арабских настроений. Набор данных содержит 10 547 твитов, 16% из которых саркастичны. В дополнение к сарказму данные были аннотированы для настроений и диалектов. Наш анализ показывает весьма субъективный характер этих задач, о чем свидетельствует сдвиг в метках настроений, основанный на предвзятости аннотаторов. Эксперименты показывают деградацию современных анализаторов настроений при столкновении с саркастическим контентом. Наконец, мы обучаем модель глубокого обучения для обнаружения сарказма с помощью BiLSTM. Модель достигает балла F1 0,46, что показывает сложный характер задачи, и должна выступать в качестве базовой линии для будущих исследований по нашему набору данных.', 'ja': '皮肉は感情分析システムの主な課題の1つです。その複雑さは、暗黙の間接的なフレーズを用いた意見表明から来ている。本稿では、利用可能なアラビア語センチメント分析データセットの再注釈を通じて作成されたアラビア語の皮肉検出データセットであるArSarcasmを紹介する。このデータセットには10,547件のツイートが含まれていますが、その16%は皮肉です。皮肉のほか、感情や方言についてもデータに注釈がつけられた。私たちの分析は、これらのタスクの非常に主観的な性質を示しています。これは、注釈者のバイアスに基づく感情ラベルの変化によって示されています。実験では、皮肉な内容物に直面したときの最先端の感情分析装置の劣化が示されている。最後に、BiLSTMを使用した皮肉検出のためのディープラーニングモデルをトレーニングします。このモデルは、課題の挑戦的な性質を示す0.46のF 1スコアを達成し、データセットに関する将来の研究の基本的なベースラインとして機能する必要があります。', 'hi': 'व्यंग्य भावना विश्लेषण प्रणालियों के लिए मुख्य चुनौतियों में से एक है। इसकी जटिलता अंतर्निहित अप्रत्यक्ष phrasing का उपयोग कर राय की अभिव्यक्ति से आता है। इस पेपर में, हम ArSarcasm, एक अरबी व्यंग्य का पता लगाने वाले डेटासेट को प्रस्तुत करते हैं, जिसे उपलब्ध अरबी भावना विश्लेषण डेटासेट के reannotation के माध्यम से बनाया गया था। डेटासेट में 10,547 ट्वीट शामिल हैं, जिनमें से 16% व्यंग्यात्मक हैं। व्यंग्य के अलावा डेटा को भावना और बोलियों के लिए एनोटेट किया गया था। हमारा विश्लेषण इन कार्यों की अत्यधिक व्यक्तिपरक प्रकृति को दर्शाता है, जो एनोटेटर के पूर्वाग्रहों के आधार पर भावना लेबल में बदलाव द्वारा प्रदर्शित किया जाता है। प्रयोगों से पता चलता है कि व्यंग्यात्मक सामग्री का सामना करते समय अत्याधुनिक भावना विश्लेषकों की गिरावट होती है। अंत में, हम BiLSTM का उपयोग करके व्यंग्य का पता लगाने के लिए एक गहरी सीखने के मॉडल को प्रशिक्षित करते हैं। मॉडल 0.46 का एक एफ 1 स्कोर प्राप्त करता है, जो कार्य की चुनौतीपूर्ण प्रकृति को दर्शाता है, और हमारे डेटासेट पर भविष्य के शोध के लिए एक बुनियादी आधार रेखा के रूप में कार्य करना चाहिए।', 'ga': 'Tá searbhas ar cheann de na príomhdhúshláin do chórais anailíse meon. Tagann a chasta is atá sé tuairim a chur in iúl agus frásaí intuigthe indíreacha á úsáid. Sa pháipéar seo, cuirimid ArSarcasm i láthair, tacar sonraí braite searbhas Araibise, a cruthaíodh trí thacair sonraí anailíse ar mheon na hAraibe a bhí ar fáil a athnótáil. Tá 10,547 tvuít sa tacar sonraí, agus tá 16% díobh searbhasach. Chomh maith le searbhas bhí anótáil ar na sonraí maidir le meon agus canúintí. Léiríonn ár n-anailís nádúr an-suibiachtúil na dtascanna seo, rud atá léirithe ag an athrú ar lipéid sentiment bunaithe ar laofachtaí na nótaíadóirí. Léiríonn turgnaimh díghrádú na n-anailíseoirí meon is nua-aimseartha agus iad ag tabhairt aghaidh ar ábhar searbhasach. Ar deireadh, cuirimid oiliúint ar mhúnla domhain foghlama le haghaidh braite searbhas ag baint úsáide as BiLSTM. Baineann an tsamhail scór F1 amach de 0.46 amach, a léiríonn nádúr dúshlánach an taisc, agus ba cheart go bhfeidhmeodh sé mar bhunlíne do thaighde amach anseo ar ár dtacar sonraí.', 'hu': 'A szarkazmus az egyik fő kihívás az érzelmek elemzésére. Bonyolultsága a véleménynyilvánítás implicit közvetett megfogalmazásából ered. Ebben a tanulmányban bemutatjuk az arszarkazmus, egy arab szarkazmus detektálási adatkészletet, amely a rendelkezésre álló arab szentimentális elemzési adatok újrannotálásával jött létre. Az adatkészlet 10 547 tweetet tartalmaz, amelyek 16%-a szarkasztikus. A szarkazmus mellett az adatokat érzelmekre és dialektusokra is jegyzetelték. Elemzésünk megmutatja e feladatok rendkívül szubjektív jellegét, amit a hangulatcímkék változása mutat a kommentátorok elfogultságai alapján. A kísérletek azt mutatják, hogy a legkorszerűbb hangulatelemzők lebomlanak a szarkasztikus tartalommal szemben. Végül egy mély tanulási modellt készítünk a szarkazmus felismerésére BiLSTM segítségével. A modell 0,46 F1 pontszámot ér el, ami mutatja a feladat kihívást jelentő jellegét, és alapvető alapként kell szolgálnia az adatkészletünkkel kapcsolatos jövőbeli kutatásokhoz.', 'el': 'Ο σαρκασμός είναι μια από τις κύριες προκλήσεις για τα συστήματα ανάλυσης συναισθημάτων. Η πολυπλοκότητά του προέρχεται από την έκφραση γνώμης χρησιμοποιώντας έμμεση διατύπωση. Σε αυτή την εργασία, παρουσιάζουμε τον Αρσαρκασμό, ένα σύνολο δεδομένων ανίχνευσης αραβικού σαρκασμού, το οποίο δημιουργήθηκε μέσω της επανεγγραφής διαθέσιμων αραβικών συνόλων δεδομένων ανάλυσης συναισθημάτων. Το σύνολο δεδομένων περιέχει 10,547 tweets, 16% εκ των οποίων είναι σαρκαστικά. Εκτός από τον σαρκασμό, τα δεδομένα σχολιάστηκαν για συναισθήματα και διαλέκτους. Η ανάλυσή μας δείχνει την άκρως υποκειμενική φύση αυτών των καθηκόντων, η οποία αποδεικνύεται από τη μετατόπιση των ετικετών συναισθημάτων που βασίζονται στις προκαταλήψεις των σχολιαστών. Τα πειράματα δείχνουν την υποβάθμιση των σύγχρονων αναλυτών συναισθημάτων όταν αντιμετωπίζουν σαρκαστικό περιεχόμενο. Τέλος, εκπαιδεύουμε ένα μοντέλο βαθιάς μάθησης για την ανίχνευση σαρκασμού χρησιμοποιώντας BiLSTM. Το μοντέλο επιτυγχάνει μια βαθμολογία F1 0.46, η οποία δείχνει την προκλητική φύση της εργασίας, και θα πρέπει να λειτουργήσει ως βασική βάση για μελλοντική έρευνα στο σύνολο δεδομένων μας.', 'ka': 'საპკაზმი არის ერთი საუკეთესო გამოცდილება სენტიმენტის ანალიზმის სისტემისთვის. მისი კომპლექსიტეტი იქნება მნიშვნელობის გამოსახულებიდან გამოყენებული ინფლიქტიური კომპლექტიური გამოსახულებიდან. ამ დომენტში ჩვენ აყერკასმა, აპაბური საპკასმის მონაცემების მონაცემები, რომელიც შექმნილი აპაბური სენტიმენტის ანალიზმის მონაცემების განაცემების გამოყენებაში. მონაცემების კონფიგურაციაში 10 547 tweets, 16% მათგანი საპაკატიურია. დამატებით საპკასმის დამატებით, მონაცემები იყო სენტიმენტების და დიალექტის დამატებით. ჩვენი ანალიზია ამ დავალების ძალიან სუბექტიური ნახევა, რომელიც განაჩვენებულია სენტიმენტური ლაბეტებში, რომელიც აღმოჩვენებულია ანტოტორორების წინასწორებების დაბაზ ექსპერიმენტები გამოჩვენებს სტატისტური ანალიზიმენტის განმავლობას, როდესაც საპკასტიური შემდგომარებით გამოყენებულია. საბოლოოდ, ჩვენ განვიყავით ძალიან სწავლებელი მოდელ საპკასმის განვიყენებაში BiLSTM გამოყენებული. მოდელის მონაცემები 0,46 წერტილის F1 წერტილია, რომელიც ჩვენი მონაცემების შესაძლებელი პირობა აჩვენებს, და უნდა იქნება როგორც უფრო ფესტური წერტილია მომავალეთ მონაცემე', 'it': "Il sarcasmo è una delle principali sfide per i sistemi di analisi del sentiment. La sua complessità deriva dall'espressione dell'opinione attraverso un fraseggio indiretto implicito. In questo articolo, presentiamo ArSarcasm, un dataset di rilevamento del sarcasmo arabo, creato attraverso la rianimazione dei dataset di analisi del sentimento arabo disponibili. Il dataset contiene 10.547 tweet, il 16% dei quali sarcastici. Oltre al sarcasmo i dati sono stati annotati per sentimenti e dialetti. La nostra analisi mostra la natura altamente soggettiva di questi compiti, che è dimostrata dal cambiamento nelle etichette sentimental basate sui pregiudizi degli annotatori. Gli esperimenti mostrano il degrado degli analizzatori di sentiment all'avanguardia di fronte a contenuti sarcastici. Infine, addestriamo un modello di deep learning per il rilevamento del sarcasmo utilizzando BiLSTM. Il modello raggiunge un punteggio F1 di 0,46, che mostra la natura impegnativa del compito, e dovrebbe fungere da base per la ricerca futura sul nostro set di dati.", 'kk': 'Сарказм - сезімдік анализ жүйелерінің негізгі маңыздылығындағы бірі. Оның тәжірибесі тәртіпсіздік сөздерді қолдану арқылы ойлардың сөздерінен келеді. Бұл қағазда ArSarcasm- тің араб сарказм анықтау деректер жиынын таңдадық. Бұл жеткізетін араб сезімдер анализ деректер жиындарын қайта анықтау арқылы құрылған. Деректер жиында 10 547 tweet бар, 16% саркастикалық. Саркассамға қосымша деректер сезім мен диалекттер үшін белгіледі. Біздің анализиямыз бұл тапсырмалардың көп мақсатты тапсырмаларды көрсетеді. Бұл жазбалардың белгілеріне негізделген символдық жарлықтарды өзгерту арқылы көрсетеді. Тәжірибелер саркастикалық мазмұнымен қарағанда суреттің күйінің анализаторларының деградациясын көрсетеді. Соңында біз BiLSTM арқылы саркассм анықтау үшін түсінікті оқыту үлгісін үйрендік. Бұл үлгі тапсырманың маңызды тапсырманы көрсетеді. Бұл тапсырманың негізгі негізгі жолы болашақ деректер жиынымызды зерттеу үшін жұмыс істеу керек.', 'lt': 'Sarkazmas yra vienas pagrindinių iššūkių jautrumo analizės sistemoms. Jos sudėtingumas kyla iš nuomonės išraiškos naudojant netiesioginę frazę. Šiame dokumente pristatome ArSarkazmą, arabų sarkazmo nustatymo duomenų rinkinį, kuris buvo sukurtas iš naujo atkreipiant dėmesį į turimus arabų sentiment ų analizės duomenų rinkinius. Duomenų rinkinyje yra 10 547 tweetai, iš kurių 16 proc. yra sarkastiniai. Be sarkazmo, duomenys buvo anotuoti dėl jautrumo ir dialektų. Mūsų analizė rodo labai subjektyvų šių užduočių pobūdį, kuris įrodomas keičiant jausmų etiketes, pagrįstas anotatorių sąlyčiais. Eksperimentai rodo pažangiausių jautrumo analizatorių skaidymą susidūrus su sarkastiniu kiekiu. Galiausiai rengiame gilaus mokymosi model į sarkazmo aptikimui naudojant BiLSTM. Modeliu pasiektas F1 rezultatas yra 0,46, kuris rodo sunkų užduoties pobūdį ir turėtų būti pagrindinis mūsų duomenų rinkinio mokslinių tyrimų pagrindas ateityje.', 'mk': 'Сарказмот е еден од главните предизвици за системите на анализа на чувствата. Неговата комплексност доаѓа од изразувањето на мислењето користејќи имплицитна индиректна фраза. Во овој весник го претставуваме АрСарказам, набор на податоци за детекција на арапскиот сарказам, кој беше создаден преку повторно забележување на достапните набори на податоци за анализа на арапските чувства. Податоците содржат 10.547 твитови, од кои 16% се саркастични. Покрај сарказмот податоците беа анотирани за чувства и дијалекти. Нашата анализа ја покажува високо субјективната природа на овие задачи, која се покажува со промената на етикетите на чувствата базирани на предрасудите на анотаторите. Експериментите покажуваат деградација на најсовремените анализатори на чувства кога се соочуваат со саркастична содржина. Конечно, тренираме модел за длабоко учење за детекција на сарказам користејќи БиЛСТМ. Моделот постигнува оценка F1 од 0,46, која ја покажува предизвикувачката природа на задачата и треба да функционира како основна основа за идното истражување на нашите податоци.', 'ms': "Sarkasme adalah salah satu cabaran utama untuk sistem analisis perasaan. Kekompleksikannya berasal dari ungkapan pendapat menggunakan frasa langsung implicit. Dalam kertas ini, kami memperkenalkan ArSarcasm, set data pengesan sarkasm Arab, yang dicipta melalui pengamatan semula set data analisis perasaan Arab yang tersedia. Set data mengandungi 10,547 tweet, 16% daripada itu sarkastik. Selain sarkasme data telah dicatat untuk perasaan dan dialekt. Our analysis shows the highly subjective nature of these tasks, which is demonstrated by the shift in sentiment labels based on annotators' biases.  Eksperimen menunjukkan kerosakan penganalisis perasaan yang terbaik apabila dihadapkan dengan kandungan sarkastik. Akhirnya, kita melatih model belajar dalam untuk pengesan sarkasma menggunakan BiLSTM. Model mencapai skor F1 0.46, yang menunjukkan sifat cabaran tugas, dan patut bertindak sebagai dasar as as untuk kajian masa depan pada set data kita.", 'mt': 'Sarcasm is one of the main challenges for sentiment analysis systems.  Its complexity comes from the expression of opinion using implicit indirect phrasing.  F’dan id-dokument, nippreżentaw ArSarkasm, sett ta’ dejta Għarbi dwar l-individwazzjoni tas-sarkasmu, li nħoloq permezz tan-notifika mill-ġdid ta’ settijiet ta’ dejta disponibbli dwar l-analiżi tas-sentimenti Għarab. Is-sett tad-dejta fih 10 547 tweet, li 16% minnhom huma sarkastiċi. Minbarra s-sarkazmu, id-dejta ġiet annotata għal sensazzjoni u dijaletti. L-analiżi tagħna turi n-natura soġġettiva ħafna ta’ dawn il-kompiti, li tintwera mill-bidla fit-tikketti tas-sentimenti bbażati fuq il-preġudizzji tal-annotaturi. L-esperimenti juru d-degradazzjoni tal-analizzaturi tas-sentimenti l-aktar avvanzati meta jiffaċċjaw kontenut sarkastiku. Fl-a ħħar nett, aħna nħarrġu mudell ta’ tagħlim profond għad-detezzjoni tas-sarkazmu bl-użu ta’ BiLSTM. Il-mudell jikseb punteġġ F1 ta’ 0.46, li juri n-natura sfidanti tal-kompitu, u għandu jaġixxi bħala linja bażi bażika għar-riċerka futura dwar is-sett tad-dejta tagħna.', 'ml': 'സാർക്കാസം വിചാരകങ്ങൾ സിസ്റ്റത്തിന്റെ പ്രധാനപ്പെട്ട വിലാസങ്ങളിലൊന്നാണ്. Its complexity comes from the expression of opinion using implicit indirect phrasing.  ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d അര്\u200dസര്\u200dക്കാസം, അറബി സാര്\u200dക്കാസം കണ്ടുപിടിക്കുന്ന ഡാറ്റാസെറ്റ് നിര്\u200dമ്മിക്കുന്നു. അത് ലഭ്യമായ അറബി അനു ഡാറ്റാസെറ്റില്\u200d 10,547 ടൂട്ടുകളുണ്ട്, 16% അതില്\u200d സർക്കാസിക്കാരാണ്. സര്\u200dക്കാസിന് കൂടാതെ വിവരങ്ങള്\u200d വിഷമമാക്കുകയും ചെയ്തു. നമ്മുടെ അന്വേഷണം ഈ ജോലികളുടെ ഏറ്റവും വിശ്വസ്തതയുള്ള സ്വഭാവം കാണിക്കുന്നു. വിചാരകന്\u200dമാരുടെ തെറ്റുകള്\u200d അടിസ്ഥാനത്തില്\u200d വെച പരീക്ഷണങ്ങള്\u200d പരീക്ഷിക്കുന്നത് സർക്കാസിക്ക് വിഭവങ്ങളുടെ സ്ഥാനത്തിന്റെ നിലനിര്\u200dദ്ദേശിക്കുന്നതാണ്. അവസാനം, ബിഎല്\u200dഎസ്റ്റം ഉപയോഗിച്ച് സാര്\u200dക്കാസം കണ്ടുപിടിക്കാനുള്ള ഒരു ആഴത്തെ പഠിപ്പിക്കുന്ന മോ പ്രവര്\u200dത്തിക്കുന്നതിന്റെ വിലപാടിന്റെ സ്വഭാവം കാണിക്കുന്ന F1 സ്കോര്\u200d എടുക്കുന്നു. നമ്മുടെ ഡാറ്റാസറ്റിന്റെ ഭാവിയുട', 'mn': 'Сарказм бол сэтгэл санааны шинжилгээний системийн гол асуудал юм. Үүний төвөгтэй байдал нь буруу хэлбэрийг ашиглан ойлголтын илэрхийллээс гарч ирдэг. Энэ цаасан дээр бид АрСаркассмыг, Араб саркассмын шинжилгээний өгөгдлийн санг дахин ойлгоход бүтээсэн Араб сэтгэл санааны шинжилгээний өгөгдлийн санг харуулж байна. Өгөгдлийн санд 10,547 tweets, 16% нь саркаст байдаг. Саркассмын дотор мэдээллийг мэдрэмж, диалект болон сэтгэл хөдлөлд анхаарсан. Бидний шинжилгээ нь эдгээр үйл ажиллагаануудын хамгийн сэтгэл хандлагатай байдлыг харуулж байна. Энэ нь сэтгэл хандлагын жагсаалтын тухай харагдаж байна. Түүх туршилтууд урлагийн сэтгэл хөдлөлийн шинжилгээчдийн хувьсгал хөдлөлтэй байдлыг харуулдаг. Эцэст нь бид BiLSTM-г ашиглаж суралцах загварыг суралцаж суралцах загвар өгдөг. Загварын загвар нь 0.46 тооны F1 оноо гарч ирээдүйн өгөгдлийн сангийн судалгааны үндсэн суурь шугам болно.', 'no': 'Sarkasm er ein av dei viktige utfordringane for følelsesystemet. Den kompleksiteten kommer frå uttrykket av meningsuttrykket med implisitt indirekt frasing. I denne papiret presenterer vi ArSarcasm, ein arabisk sarkasm-oppdagingsdataset, som ble oppretta gjennom gjennom gjennomføring av tilgjengelege datasett i arabiske sentimentanalyser. Datasettet inneheld 10 547 tweets, 16% av dei er sarkastiske. I tillegg til sarkasm vart data oppmerkte for sentiment og dialektar. Analysen vårt viser den høgssubjektive naturen av desse oppgåvene, som vert demonstrert av forskyvinga i sentimentetikettene basert på førehandsvising av annotatorar. Eksperimentar viser degradasjonen av kunstsentimentanalizatorar når det står med sarkastisk innhald. I slutt treng vi ein dyp læringsmodell for å oppdaga sarkasm med BiLSTM. Modellen oppnår eit F1- poeng med 0,46, som viser den vanskelege naturen av oppgåva, og bør handsama som grunnleggjande baseline for framtidige forskning på datasettet vårt.', 'ro': 'Sarcasmul este una dintre principalele provocări pentru sistemele de analiză a sentimentelor. Complexitatea sa provine din exprimarea opiniei folosind fraze indirecte implicite. În această lucrare, prezentăm ArSarcasm, un set de date de detectare a sarcasmului arab, creat prin reannoția seturilor de date disponibile pentru analiza sentimentului arab. Setul de date conține 10.547 tweet-uri, dintre care 16% sunt sarcastice. Pe lângă sarcasm, datele au fost adnotate pentru sentimente și dialecte. Analiza noastră arată natura extrem de subiectivă a acestor sarcini, ceea ce este demonstrat de schimbarea etichetelor sentimentale bazate pe prejudecățile adnotatorilor. Experimentele arată degradarea analizelor de sentiment de ultimă generaţie atunci când se confruntă cu conţinut sarcastic. În cele din urmă, pregătim un model de învățare profundă pentru detectarea sarcasmului folosind BiLSTM. Modelul atinge un scor F1 de 0,46, ceea ce arată natura provocatoare a sarcinii și ar trebui să acționeze ca o bază de bază pentru cercetarea viitoare a setului nostru de date.', 'pl': 'Sarkazm jest jednym z głównych wyzwań dla systemów analizy sentymentów. Jej złożoność wynika z wyrażania opinii za pomocą ukrytych pośrednich fraz. W niniejszym artykule przedstawiamy arsarkazm, arabski zestaw danych wykrywania sarkazmu, który został stworzony poprzez reanotację dostępnych arabskich zbiorów danych analizy sentymentów. Zestaw danych zawiera 10,547 tweety, z których 16% są sarkastyczne. Oprócz sarkazmu dane zostały poddane adnotacji dotyczących sentymentów i dialektów. Nasza analiza pokazuje wysoce subiektywny charakter tych zadań, o czym świadczy zmiana etykiet sentymentów opartych na uprzedzeniach adnotatorów. Eksperymenty pokazują degradację najnowocześniejszych analizatorów sentymentów w obliczu sarkastycznych treści. Wreszcie trenujemy model głębokiego uczenia do wykrywania sarkazmu przy użyciu BiLSTM. Model osiąga wynik F1 0,46, który pokazuje wymagający charakter zadania i powinien stanowić podstawową bazę podstawową dla przyszłych badań nad naszym zbiorem danych.', 'sr': 'Sarkazam je jedan od glavnih izazova za sisteme analize sentimenta. Njena kompleksnost dolazi iz izraza mišljenja koristeći implicitne indirektne rečenice. U ovom papiru predstavljamo ArSarkazam, kompletu podataka za detekciju arapskih sarkazama, koji je stvoren kroz ponovno otkrivanje dostupnih kompleta analize arapskih sentimenta. Podaci sadrže 10.547 tweets, 16% od kojih su sarkastični. Pored sarkazma, podaci su bili annotirani za sentiment i dijalekte. Naša analiza pokazuje vrlo subjektivnu prirodu ovih zadataka, koja se pokazuje smjena sentimentalnih etiketa na osnovu predrasuda annotatora. Eksperimenti pokazuju degradaciju analitičara stanja umjetnosti kada se suočavaju sa sarkastičnim sadržajem. Konačno treniramo model dubokog učenja za detekciju sarkazma koristeći BiLSTM. Model postiže rezultat F1 od 0,46, koji pokazuje izazovnu prirodu zadatka, i treba da se ponaša kao osnovna osnovna linija za buduće istraživanje našeg seta podataka.', 'si': 'සාර්කාස්ම් තමයි විශ්ලේෂණ පද්ධතියේ ප්\u200dරධාන අභ්\u200dයානයක්. ඒකේ සංශ්\u200dයාත්මක ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ නිර්දේශ ප්\u200dරශ්නයක් භාවිත කරන්න. මේ පත්තරේ අපි ArSarcasm විශ්ලේෂණ දත්ත සූදානයක්, අරාබි සර්කාස්ම් හොයාගන්න දත්ත සූදානයක්, ඒක පුළුවන් අරාබි දේවල දත්ත සැට 10,547 ට්විට් වලින් තියෙනවා, ඒ වගේම 16% සාර්කාසික් වලින්. සාර්කාස්ම් එක්ක තොරතුරු සංවේදනය සහ ඩායිලෙක්ට්ස් එක්ක ප්\u200dරතිචාර කරලා තියෙනවා. අපේ විශ්ලේෂණය පෙන්වන්නේ මේ වැඩේ ගොඩක් විශේෂ ස්වභාවිතාවක්, ඒක පෙන්වන්නේ හැඟීම් ලේබල් වලින් වෙනස් වෙන පරීක්ෂණය පෙන්වන්න පුළුවන් සාර්කාසික් සාමාන්\u200dය සමඟ සම්බන්ධ විශ්ලේෂකයන්ගේ ස්ථිතියේ වික්\u200dරමණය අන්තිමේදී, අපි බිල්ස්ටිම් භාවිතා කරන්නේ සාර්කාස්ම් හොයාගන්න හොයාගන්න ගොඩක් ඉගෙනගන්න ප්\u200d මොඩල් එකෙන් F1 ප්\u200dරමාණයක් 0.46 වෙනුවෙන්, ඒකෙන් වැඩේ ප්\u200dරශ්නයක් පෙන්වන්න පුළුවන්, ඒ වගේම අපේ දත්ත සැට විසින් අනාගත', 'so': 'Sarkasm waa mid ka mid ah dhibaatooyin ugu muhiimsan nidaamka kaleemeysiga. Dhibaatadu waxay ka timaadaa muuqashada aragtida iyagoo isticmaalaya hadalka si toos ah. Warqadan, waxaynu keenaynaa ArSarcasm, taas oo ah taarifka baaritaanka sarcasm ee Carabi ah, taas oo lagu sameeyay dib-u-abuurista sawirida danbiyada ah oo la heli karo kalluumeynta arimaha Carabiga. Rugta macluumaadku wuxuu ku jiraa 10,547 twiti, 16% oo ka mid ahna waa sarkisiin. Khatarka waxaa ka sokow macluumaadka lagu dhibaataystay fikrada iyo macluumaadka. Analyskayagu wuxuu muujiyaa dabiicadda shaqaalahaas oo aad u muhiimsan, taas oo lagu muujiyaa beddelka alaabta xisaabta ku saleysan tababarada dhibaatooyinka. Imtixaanka waxaa muujiya hoosaysiinta xaaladda-farshaxanta marka ay ka hor jeedaan waxyaabaha sarcastiga. Ugu dambaysta, waxaynu tababarinaynaa model aad u dheer oo waxbarasho ah oo lagu baaraandegayo sarcasm isticmaalka BiLSTM. Tusaale wuxuu gaadhaa koox F1 oo ku qoran 0.46, kaas oo muujiya dabiicadda dhibaatada shaqada, wuxuuna habboon yahay inuu u shaqeeyo sida shabakadda aasaasiga ah ee baaritaanka mustaqbalka ee sawiradayada.', 'sv': 'Sarkasm är en av de största utmaningarna för känsloanalyssystem. Dess komplexitet kommer från yttrandeuttrycket med implicit indirekt frasering. I denna uppsats presenterar vi ArSarkasm, en arabisk sarkasm detektionsdatauppsättning, som skapades genom att återuppliva tillgängliga arabiska sentimentalanalys datauppsättningar. Datauppsättningen innehåller 10 547 tweets, varav 16% är sarkastiska. Förutom sarkasm kommenterades data för sentiment och dialekter. Vår analys visar på den mycket subjektiva karaktären av dessa uppgifter, vilket framgår av skiftet i sentimentetiketter baserat på kommentatorernas fördomar. Experiment visar försämringen av de senaste känsloanalysatorerna när de ställs inför sarkastiskt innehåll. Slutligen tränar vi en djupinlärningsmodell för sarkasm detektering med hjälp av BiLSTM. Modellen uppnår en F1-poäng på 0,46, vilket visar uppgiftens utmanande karaktär, och bör fungera som en grundläggande bas för framtida forskning om vår datauppsättning.', 'ta': 'Sarcasm என்பது உணர்வு ஆய்வு அமைப்புகளின் முக்கிய சவால்களில் ஒன்று. அதில் சிக்கல் ஒரு சரியான சொற்றொடரை பயன்படுத்தி கருத்தின் கூற்றிலிருந்து வருகிறது. இந்த காகிதத்தில், நாங்கள் அர்சார்காஸ்ம், ஒரு அரபி சார்ந்த கண்டுபிடிப்பு தகவல் அமைப்பு, கிடைக்கும் அரபி உணர்வு ஆய்வு தரவு அமைப் இந்த தரவுத்தளத்தில் 10,547 டுவிட்டுக் கொண்டுள்ளது, அதில் 16% வெற்றிகரம். சுழற்சி கூடுதலாக தகவல்கள் உணர்வு மற்றும் விளக்கங்களுக்கு குறிக்கப்பட்டது. எங்கள் ஆராய்ச்சி இந்த பணிகளின் மிகவும் பொருள் செயல்பாட்டின் இயற்கையை காட்டுகிறது, அது உணர்வு சிட்டைகள் மாற்றுதல் குறிப்ப சூழ்ச்சிகள் சூழ்நிலையில் உள்ளடக்கத்தை பார்க்கும்போது அலங்காரத்தின் நிலையில் உள்ள உணர்வு ஆராய்வை குற கடைசியாக, நாம் பைஎல்எஸ்டிஎம் பயன்படுத்தி ஒரு ஆழமான கற்றுக்கொள்ள மாதிரி பயிற்சி செய்கிறோம். The model achieves a F1 score of 0.46, which shows the challenging nature of the task, and should act as a basic baseline for future research on our data set.', 'ur': 'سارکاسم احساسات تحلیل سیسٹم کے لئے سب سے زیادہ مشکلات میں سے ایک ہے۔ اس کی پیچیدگی منظور کے منظور سے آتی ہے کہ اسے غلط مفصل کے مطابق استعمال کرتی ہے. اس کاغذ میں ہم ArSarcasm کو ایک عربی سارکاسم ڈیٹ سٹ کے ذریعے پیدا کیا گیا تھا جو صاحبِ عربی احساسات تحلیل ڈیٹ سٹ کے ذریعے پیدا کیا گیا تھا. ڈاٹ سٹ میں 10,547 ٹویٹ ہیں، ان میں سے 16% سارکاسٹ ہیں۔ سارکاسم کے علاوہ ڈیٹا احساسات اور ڈیلکت کے لئے اظہار کیا گیا تھا۔ ہماری تحلیل یہ کاموں کی بہت زیادہ سرپرست طبیعت دکھاتی ہے، جو احساسات لیبلوں کی تغییر کے ذریعہ دکھائی جاتی ہے۔ آزمائش کی تدبیروں نے سارکاسٹی منصفات کے سامنے موجود ہونے کے موقع آزمائش کرنے والوں کی حالت کا ذلت دکھائی۔ بالآخر، ہم ایک عمیق سیکھنے کی موڈل کو BiLSTM کے استعمال سے سارکاسم شناسایی کے لئے تربیت کرتے ہیں. Model achieves an F1 score of 0.46, which shows the challenging nature of the task, and should act as a basic baseline for future research on our dataset.', 'uz': "Sarkasm - sentiment analyzer tizimlarining asosiy qiyin biri. Bu murakkablik fikrlarni noto'g'ri tildan foydalanishidan keladi. Bu hujjatda ArSarkasm, Arab sarkasm qidirish maʼlumotlarini aniqlashni hosil qilamiz. Bu arab foydalanuvchi taʼlumotlar tarkibini qaytadan yaratish mumkin. Maʼlumotlar soni 10,547 tweeti mavjud, ularning 16% sarkastik. sarkasm bilan maʼlumotlar hissiyotga va dialeklarga taqdim edi. Analytikiz shu vazifalarning eng muhim tarkibini ko'rsatadi, bu hissiyotlarning tablarida o'zgartirish imkoniyatini ko'rsatadi. Name Endi biz BiLSTM yordamida sarkasm aniqlash modelini o'rganamiz. Name", 'vi': 'Âm nhạc là một trong những thử thách chính trong hệ thống phân tích cảm xúc. Sự phức tạp của nó đến từ cách biểu lộ quan điểm bằng cách nói riêng. Trong tờ giấy này, chúng tôi giới thiệu lưu trữ dữ liệu về Ar-cass, một tập tin được tạo ra bằng cách khai thác lại các tập tin phân tích cảm xúc của Ả Rập. Bộ dữ liệu chứa tweet 10,57, 16.of which are Mỉa mai. Ngoài mỉa mai, dữ liệu còn được ghi chú cho cảm xúc và phương ngữ. Phân tích của chúng tôi cho thấy thực chất chủ quan của những nhiệm vụ này, được chứng minh bởi sự thay đổi các biểu tượng cảm xúc dựa trên sai lầm của nhà biên niên. Thí nghiệm cho thấy phân tích cảm xúc hiện đại khi đối mặt với nội dung châm biếm. Cuối cùng, chúng tôi đào tạo một mô hình học sâu để phát hiện mỉa mai bằng BiLSTM. Mô hình này đạt đến điểm số F1 của 0.46, hiển thị tính chất thách thức của nhiệm vụ, và cũng là cơ sở cơ bản cho nghiên cứu tương lai về bộ dữ liệu của chúng tôi.', 'da': 'Sarkasme er en af de største udfordringer for følelsesanalysesystemer. Dens kompleksitet stammer fra meningsudtrykket ved hjælp af implicit indirekte formulering. I denne artikel præsenterer vi ArSarkasm, et arabisk sarkasm detektion datasæt, som blev skabt gennem genoptagelse af tilgængelige arabiske sentiment analyse datasæt. Datasættet indeholder 10.547 tweets, hvoraf 16% er sarkastiske. Ud over sarkasme blev data noteret for sentiment og dialekter. Vores analyse viser, at disse opgaver er meget subjektive, hvilket fremgår af skiftet i sentiment labels baseret på kommentatorernes fordomme. Eksperimenter viser nedbrydningen af state-of-the-art sentiment analysatorer, når de står over for sarkastisk indhold. Endelig træner vi en deep learning model til sarkasme detektion ved hjælp af BiLSTM. Modellen opnår en F1 score på 0,46, hvilket viser opgavens udfordrende karakter, og bør fungere som grundlæggende udgangspunkt for fremtidig forskning i vores datasæt.', 'nl': 'Sarcasme is een van de belangrijkste uitdagingen voor sentimentanalysesystemen. De complexiteit ervan komt voort uit de expressie van mening met behulp van impliciete indirecte frasering. In dit artikel presenteren we ArSarcasme, een Arabische sarcasme detectie dataset, die is gecreëerd door de re-notatie van beschikbare Arabische sentiment analyse datasets. De dataset bevat 10,547 tweets waarvan 16% sarcastisch is. Naast sarcasme werden de gegevens geannoteerd voor sentiment en dialecten. Onze analyse toont het zeer subjectieve karakter van deze taken aan, wat blijkt uit de verschuiving van sentimentlabels op basis van de vooroordelen van annotatoren. Experimenten tonen de degradatie aan van state-of-the-art sentiment analyzers wanneer geconfronteerd wordt met sarcastische inhoud. Tot slot trainen we een deep learning model voor sarcasme detectie met behulp van BiLSTM. Het model behaalt een F1 score van 0.46, die het uitdagende karakter van de taak laat zien, en moet fungeren als basis voor toekomstig onderzoek naar onze dataset.', 'bg': 'Сарказмът е едно от основните предизвикателства за системите за анализ на сентимента. Нейната сложност идва от изразяването на мнение чрез имплицитно косвено формулиране. В настоящата статия представяме Арсарказъм, набор от данни за откриване на арабски сарказъм, създаден чрез повторно нотиране на наличните арабски сентиментални анализи. Наборът от данни съдържа 10 547 туита, 16% от които са саркастични. В допълнение към сарказма данните са анотирани за сантименталност и диалекти. Анализът ни показва силно субективния характер на тези задачи, което се демонстрира от промяната в сентименталните етикети въз основа на предразсъдъците на анотаторите. Експериментите показват разграждането на най-съвременните сентиментални анализатори, когато са изправени пред саркастично съдържание. Накрая, обучаваме модел за дълбоко учене за откриване на сарказъм с помощта на БиЛСТМ. Моделът постига оценка от 0,46, което показва предизвикателния характер на задачата и трябва да действа като основна база за бъдещи изследвания на нашия набор от данни.', 'hr': 'Sarkazam je jedan od glavnih izazova za sisteme analize osjećaja. Njezina kompleksnost dolazi iz izraza mišljenja koristeći implicitne indirektne rečenice. U ovom papiru predstavljamo ArSarcasm, kompletu datoteka za detekciju arapskih sarkazama, koji je stvoren kroz ponovno otkrivanje dostupnih datoteka za analizu arapskih osjećaja. Podaci sadrže 10 547 tweets, 16% od kojih su sarkastični. Osim sarkazma, podaci su bili annotirani za osjećaj i dijalekte. Naša analiza pokazuje vrlo subjektivnu prirodu tih zadataka, koja se pokazuje smjenom osjećajnih etiketa na temelju pristrasnosti annotatora. Eksperimenti pokazuju degradaciju analizatora stanja umjetnosti kada se suočavaju s sarkastičnim sadržajem. Konačno, treniramo model dubokog učenja za otkrivanje sarkazma koristeći BiLSTM. Model postiže rezultat F1 od 0,46, koji pokazuje izazovnu prirodu zadatka, i trebao bi se ponašati kao osnovnu početnu liniju za buduće istraživanje našeg podataka.', 'de': 'Sarkasmus ist eine der größten Herausforderungen für Stimmungsanalysesysteme. Seine Komplexität ergibt sich aus der Meinungsäußerung durch implizite indirekte Formulierungen. In diesem Beitrag stellen wir ArSarkasmus vor, einen Datensatz zur Erkennung arabischer Sarkasmen, der durch die Reannotation verfügbarer arabischer Sentiment-Analyse-Datensätze erstellt wurde. Der Datensatz enthält 10,547 Tweets, von denen 16% sarkastisch sind. Neben Sarkasmus wurden die Daten für Sentiment und Dialekte kommentiert. Unsere Analyse zeigt die höchst subjektive Natur dieser Aufgaben, was sich durch die Verschiebung der Sentiment Labels auf Basis von Annotatoren-Vorurteilen zeigt. Experimente zeigen den Abbau moderner Sentiment Analysatoren bei sarkastischen Inhalten. Abschließend trainieren wir ein Deep Learning Modell zur Sarkasmus-Erkennung mittels BiLSTM. Das Modell erreicht einen F1-Score von 0,46, der die Herausforderung der Aufgabe zeigt und als Basis für zukünftige Forschungen an unserem Datensatz dienen sollte.', 'ko': '풍자는 정서 분석 시스템이 직면한 주요 도전 중의 하나다.그것의 복잡성은 은근한 간접적 표현을 사용하여 관점을 표현하는 데서 나온다.본고에서 우리는 ArSarcasm, 아랍어 풍자 검측 데이터 집합을 소개했는데 이것은 사용 가능한 아랍어 정서 분석 데이터 집합을 다시 표시하여 만든 것이다.이 데이터 세트에는 10547개의 추문이 포함되어 있는데 그 중 16%는 풍자적이다.풍자 외에도 감정과 사투리가 표기돼 있다.우리의 분석은 이러한 임무의 높은 주관성을 나타냈고 주석자의 편견을 바탕으로 하는 감정 라벨의 변화가 이를 증명했다.실험에 따르면 풍자 내용에 직면할 때 가장 선진적인 정서 분석기는 퇴화된다.마지막으로 우리는 BilSTM을 이용하여 풍자를 감지하기 위해 깊이 있는 학습 모형을 훈련했다.이 모델의 F1은 0.46점으로 임무의 도전성을 보여 미래 데이터 집합 연구의 기본 기선이 되어야 한다.', 'sw': 'Sarcasm ni moja ya changamoto kuu kwa mfumo wa uchambuzi wa hisia. Tatizo hilo linatokana na hisia za maoni kwa kutumia maneno yasiyo ya moja kwa moja. Katika karatasi hii, tunawasilisha ArSarcasm, kituo cha taarifa cha uchunguzi wa kejeli cha Kiarabu, ambacho kiliundwa kwa njia ya upya wa taarifa za uchambuzi wa hisia za Kiarabu. Taarifa hiyo ina twiti 10,547, asilimia 16 ambayo ni kejeli. Zaidi ya kejeli takwimu hizo zilikuwa zimechangazwa kwa hisia na lugha. Uchambuzi wetu unaonyesha ubunifu wa kazi hizi, ambao unaonyeshwa na mabadiliko ya hisia kwa sababu ya upendeleo wa matatizo. Experiments show the degradation of state-of-the-art sentiment analysers when faced with sarcastic content.  Mwisho, tunafundisha modeli ya kujifunza kwa ajili ya kutambua kejeli kwa kutumia BiLSTM. Mfano huo unafanikiwa score ya F1 ya 0.46, ambayo inaonyesha aina ya changamoto ya kazi hiyo, na inapaswa kufanya kazi kama msingi wa utafiti wa baadaye kwenye seti yetu ya data.', 'tr': "Senköm duýgym analyzasy sistemalarynyň esasy kynçylygynyň biri. Onuň çykyşlygyny netijeli däl sözleri ulanan pikir edeniň ifadesinden çykar. Bu kagyzda biz Arkasymy, arapça sarkasm tanyşynyň veri setirini görkezip bilen meňzeş arpça duýgular analyzasynda döredildi. Maglumat setirinde 10,547 tweet, ondan 16% sarkastça bar. Sarkasm'a da bilim duyguları ve dialektler için uyandırıldı. Bizim analizimiz bu görevlerin en yüksek subjektif doğasını gösterir. Bu duyguların etiketlerine dayanan duygular etiketlerinde değişiklikleri tarafından gösterilir. Synaniýalar sarkastik maglumaty bilen görünýän wagtyň durumynyň azalyşygyny görkezýär. Soňunda BiLSTM ulanan sarkasm deteksiyony üçin derin öwrenmek nusgasyny öwredýäris. Bu nusga 0,46-njy bir F1 sany tapýar, bu işiň kynçylyk tebigatyny görkezýär we veri setegimizde gelejek araştyrmalar üçin esasy çyzgyr bolmaly.", 'fa': 'سارکاسم یکی از چالش های اصلی برای سیستم تحلیل احساسات است. پیچیدگی آن از توضیح نظر با استفاده از عبارت غیرمستقیم است. در این کاغذ، ما یک مجموعه اطلاعات شناسایی سارکاسم عربی را پیشنهاد می\u200cکنیم که از طریق بازشناسایی داده\u200cهای تحلیل احساسات عربی موجود شده است. مجموعه داده\u200cها ۱۰.۵۴۷ تویت دارند، ۱۶ درصد از آنها سارکاستیک هستند. در اضافه به سارکاسم، داده\u200cها برای احساسات و دیالکت\u200cها مشخص شده\u200cاند. تحلیل ما طبیعت بسیار مسئولیت این وظیفه ها را نشان می دهد که توسط تغییر تغییر توسط نقاشی احساسات بر اساس طبیعت های آشنا کنندگان نشان می دهد. تجربه\u200cها تحلیل\u200cکننده\u200cهای احساسات ایالت هنری را نشان می\u200cدهند وقتی با محتوای جالبی روبرو می\u200cشوند. بالاخره، ما یک مدل یادگیری عمیق برای کشف سارکاسم را با استفاده از BiLSTM آموزش می دهیم. این مدل یک امتیاز F1 از 0.46 به دست آورد، که طبیعت سخت کار را نشان می دهد، و باید به عنوان یک خط بنیادی برای تحقیقات آینده در مجموعه داده\u200cهای ما عمل کند.', 'af': "Sarkasm is een van die hoofde uitdagings vir sentimentanalisiesystemee. Sy kompleksiteit kom van die uitdrukking van besonderhede met inplisite indirekte frasing. In hierdie papier stel ons ArSarcasm voor 'n Arabiese sarkasm-opdekking dataset, wat gemaak is deur die herkenning van beskikbare Arabiese sentimentanaliseerdatasse. Die datastel bevat 10,547 tweets, 16% van wat sarkasies is. In addition to sarcasm the data was annotated for sentiment and dialects. Ons analisie vertoon die baie subjektiewe natuur van hierdie taak, wat deur die verskuif in sentiment etikette gebaseer word op annotators se voorskrifte. Eksperimente vertoon die afbreiding van staat-van-kunste sentiment-analiseerders wanneer gesig is met sarkasiese inhoud. Eindelik, ons trein 'n diep leer model vir sarkasme-opdekking deur BiLSTM te gebruik. Die model bereik 'n F1 telling van 0.46, wat vertoon die vanskende natuur van die taak, en moet werk as 'n basiese basisline vir toekomstige ondersoek op ons datastel.", 'am': 'ሳርካሲም የስሜት ትምህርት ምርጫዎች መሆኑን መፍታት አንዱ ነው፡፡ አካባቢው ከአስተያየት አካባቢ ንግግር የተጠቃሚ ነው፡፡ በዚህ ፕሮግራም አርስካሲምን፣ አርቢኛ የሳርካሲም ዳታዎችን አቀረብን፡፡ የዳታ ሰርቨሮች 10,547 ትዊተሮችን አግኝቷል፣ 16 በመቶ ሰርካሲ ናቸው፡፡ In addition to sarcasm the data was annotated for sentiment and dialects.  Analysያችን የእነዚህ ስራዎችን አካባቢ ሥርዓት ያሳያል፣ በተቃውሞው ተቃውሞ በመለወጥ የሚታየው የስሜት ምልክቶች ነው፡፡ ፈተናዎች በጣራሲካዊ ጥቅም በተገናኘ ጊዜ የሀገር-የ-አርእስት አስተያየት የሚያሳውቃቸውን አዋጅ ያሳያል፡፡ በመጨረሻም በቢልSTM ለመጠቀም የሳርካሲም ማስተማር model እናስተምራለን፡፡ ሞዴል 0.46 ነጥብ አግኝቷል፣ የስራውን ጥቃት የሚያሳየው፣ ለፊት ለዳታቤታችን የመጀመሪያ ጥያቄ መሠረት መሠረት አለበት፡፡', 'hy': 'Sarcasm is one of the main challenges for sentiment analysis systems.  Դրա բարդությունը գալիս է կարծիքի արտահայտումից, օգտագործելով ենթարկված միջին արտահայտությունը: Այս թղթի մեջ մենք ներկայացնում ենք Արսարկազմը, արաբական սարկազմի հայտնաբերման տվյալների համակարգը, որը ստեղծվել է արաբական զգացմունքների վերանայման հասանելի տվյալների համակարգերի միջոցով: Տեղեկատվական համակարգը պարունակում է 10.547 թվիթեր, որոնցից 16 տոկոսը սարկաստական է: Բացի սարկազմից, տվյալները գրված էին զգացմունքների և դիալեկտների համար: Մեր վերլուծությունը ցույց է տալիս այս խնդիրների շատ սուբյեկտիվ բնույթը, որը ցույց է տալիս զգացմունքների պիտակների փոփոխությունը, հիմնված նոտատորների կողմնականության վրա: Փորձարկումները ցույց են տալիս ամենաբարձր զգացմունքների վերլուծումների դեգրադացիան, երբ հանդիպում են սարկաստական պարունակության հետ: Վերջապես, մենք պատրաստում ենք սարկազմի հայտնաբերման խորը սովորելու մոդել, օգտագործելով ԲիLSԹՄ: Մոդելը հասնում է F1-ի 0.46 գնահատականի, որը ցույց է տալիս խնդրի դժվարին բնույթը, և պետք է գործի որպես հիմք մեր տվյալների ապագա հետազոտության համար:', 'az': "Sarkasm sentiment analizi sistemlərin ən böyük çətinliklərindən biridir. Onun qarışıqlığı müəyyən edilməz fərz vasitəsilə fikirlərin ifadesindən gəlir. Bu kağızda ArSarcasm'ı, ərəbcə sarkasm keşfetməsi verilən verilər qurulduğu ərəbcə hiss analizi verilər qurulduğu yerdən yaratdıq. Veri qurğuları 10.547 twet içərir, bunların 16% sarkastik. Sarkasma da məlumatlar hisslər və dialektlər üçün annotated edildi. Bizim analizimiz bu işlərin çox subjektiv təbiətini göstərir. Bu, duygusal etiketlərin dəyişikliklərindən göstərilən duygusal etiketlərin təsirlərinə dayanılır. Həqiqətən, təcrübələr sarkastik məzmunları ilə qarşılaşdığı zaman, sanatlı hisslər analizacıların əskilməsini göstərir. Sonunda, BiLSTM vasitəsilə sarkasm keşfetməsi üçün derin öyrənmə modeli təhsil edirik. Model 0,46 xərcləyici F1 nöqtəsinə nail olur, ki bu işin çətin təbiətini göstərər, və verilən qutumuzda gələcək təhsil barəsindəki araştırmalar üçün əsas səviyyə olar.", 'bn': 'সার্কাস্ম হচ্ছে আবেগ বিশ্লেষণ ব্যবস্থার প্রধান চ্যালেঞ্জ। তার কঠিন ব্যাখ্যা ব্যবহার করে মন্তব্যের প্রকাশ থেকে এসেছে। এই কাগজটিতে আমরা আরবী বিদ্রোহী তথ্য সনাক্তির তথ্য সংক্রান্ত আর্সার্কাস্ম উপস্থাপন করছি, যা আরবী অনুভূতি বিশ্লেষণের ডাটাসেটের ডাটাসেটের মধ্যে ১০,৫৪৭ টুইট রয়েছে, যাদের মধ্যে ১৬% বিদ্রোহী। In addition to sarcasm the data was annotated for sentiment and dialects.  আমাদের বিশ্লেষণ দেখাচ্ছে এই কাজের প্রকৃতি অত্যন্ত বিশেষ প্রকৃতি, যা মনোভাবের বিরোধীদের বিরুদ্ধে ভিত্তিক ভিত্তিতে অনুভূ বিদ্রোহীত বিষয়বস্তুর মুখোমুখি হওয়ার পর পরীক্ষার সাথে রাষ্ট্র-শিল্পীদের লাঞ্ছনা দেখায়। শেষ পর্যন্ত আমরা বিএলস্টিএম ব্যবহার করে বিদ্রাম সনাক্তের জন্য গভীর শিক্ষার মডেল প্রশিক্ষণ করি। এই মডেলটি ০. ৪৬ স্কোর অর্জন করে, যা কাজের চ্যালেঞ্জের প্রকৃতি দেখায় এবং ভবিষ্যতের গবেষণার মৌলিক কাজ হিসেবে কাজ করা উচিত।', 'id': 'Sarkasme adalah salah satu tantangan utama untuk sistem analisis sentimen. Kompleksitasnya berasal dari ekspresi pendapat menggunakan frasa indirekt implicit. Dalam kertas ini, kami mempersembahkan ArSarkasm, sebuah set data deteksi sarkasm Arab, yang diciptakan melalui reannotasi dari set data analisis sentimen Arab yang tersedia. Set data berisi 10.547 tweet, 16% dari yang sarkastik. In addition to sarcasm the data was annotated for sentiment and dialects.  Analisis kami menunjukkan sifat subyektif tugas-tugas ini, yang dipastikan oleh perubahan dalam label sentimen berdasarkan biases annotator. Experiments show the degradation of state-of-the-art sentiment analysers when faced with sarcastic content.  Akhirnya, kita melatih model belajar dalam untuk deteksi sarkasme menggunakan BiLSTM. Model ini mencapai skor F1 0,46, yang menunjukkan sifat tantangan tugas, dan harus bertindak sebagai dasar dasar untuk penelitian masa depan pada set data kita.', 'sq': 'Sarkazmi është një nga sfidat kryesore për sistemet e analizës së ndjenjave. Kompleksia e saj vjen nga shprehja e opinionit duke përdorur frazën implicite të indirekte. Në këtë letër, ne paraqesim ArSarkazmin, një grup të dhënash për zbulimin e sarkazmit arab, i cili u krijua nëpërmjet rishkrimit të grupeve të dhënash për analizën e ndjenjave arabe të disponueshme. Të dhënat përmbajnë 10,547 tweets, prej të cilave 16% janë sarkastikë. Përveç sarkazmit të dhënat u shënuan për ndjenja dhe dialekte. Analiza jonë tregon natyrën shumë subjektive të këtyre detyrave, e cila demonstrohet nga ndryshimi i etiketave të ndjenjave bazuar në paragjykimet e anotatorëve. Eksperimentet tregojnë degradimin e analizuesve të ndjenjave më të larta kur përballen me përmbajtjen sarkastike. Finally, we train a deep learning model for sarcasm detection using BiLSTM.  Modeli arrin një rezultat F1 prej 0.46, i cili tregon natyrën sfiduese të detyrës dhe duhet të veprojë si bazë bazë për kërkimet e ardhshme në grupin tonë të dhënash.', 'cs': 'Sarkasmus je jednou z hlavních výzev systémů analýzy sentimentů. Jeho složitost vychází z vyjádření názoru pomocí implicitních nepřímých frází. V tomto článku představujeme arsarkasmus, arabskou sadu detekce sarkasmu, která byla vytvořena reanotací dostupných arabských datových sad analýzy sentimentů. Datová sada obsahuje 10,547 tweety, z nichž 16% jsou sarkastické. Kromě sarkasmu byla data anotována pro sentiment a dialekty. Naše analýza ukazuje vysoce subjektivní povahu těchto úkolů, což dokládá posun sentimentu založený na zaujatostech anotátorů. Experimenty ukazují degradaci nejmodernějších analyzátorů sentimentu při tváření sarkastického obsahu. Nakonec trénujeme model hlubokého učení pro detekci sarkasmu pomocí BiLSTM. Model dosahuje F1 skóre 0,46, které ukazuje náročnou povahu úkolu, a měl by sloužit jako základní základní základní základní základ pro budoucí výzkum našeho datového souboru.', 'ca': "El sarcasme és un dels principals reptes per als sistemes d'anàlisi del sentiment. La seva complexitat prové de l'expressió de l'opinió utilitzant frases indirectes implícites. En aquest article presentem l'ArSarcasme, un conjunt de dades de detecció del sarcasme àrab, que va ser creat a través de la reannotació dels conjunts de dades disponibles d'an àlisi del sentiment àrab. El conjunt de dades conté 10.547 tweets, del qual 16% són sarcàstics. A més del sarcasme, les dades es van anotar per sentiment i dialectes. La nostra anàlisi mostra la naturalesa altament subjectiva d'aquestes tasques, que es demostra pel canvi d'etiquetes de sentiments basats en les tendències dels anotators. Els experiments demostren la degradació dels analitzadors de sentiments d'última edat quan s'enfronten amb continguts sarcàstics. Finalment, entrenem un model d'aprenentatge profund per la detecció del sarcasme utilitzant BiLSTM. El model aconsegueix una puntuació F1 de 0,46, que mostra la difícil naturalesa de la tasca, i hauria d'actuar com una base bàsica per a la futura recerca sobre el nostre conjunt de dades.", 'bs': 'Sarkazam je jedan od glavnih izazova za sisteme analize sentimenta. Njezina kompleksnost dolazi iz izraza mišljenja koristeći implicitne indirektne fraze. U ovom papiru predstavljamo ArSarkazam, kompletu datoteka za detekciju arapskih sarkazama, koji je stvoren kroz ponovno otkrivanje dostupnih datoteka za analizu arapskih osjećaja. Podaci sadrže 10.547 tweets, 16% od kojih su sarkastični. Osim sarkazma, podaci su bili annotirani za osjećaj i dijalekte. Naša analiza pokazuje vrlo subjektivnu prirodu ovih zadataka, koja se pokazuje smjenom osjećajnih etiketa na temelju predrasuda annotatora. Eksperimenti pokazuju degradaciju analizatora stanja umjetnosti kada se suočavaju sa sarkastičnim sadržajem. Konačno, treniramo model dubokog učenja za detekciju sarkazma koristeći BiLSTM. Model postiže rezultat F1 od 0,46, koji pokazuje izazovnu prirodu zadatka, i trebao bi se ponašati kao osnovnu osnovnu liniju za buduće istraživanje našeg seta podataka.', 'et': 'Sarkasm on sentimentaalüüsi süsteemide üks peamisi väljakutseid. Selle keerukus tuleneb arvamuse väljendamisest kaudse sõnastuse abil. Käesolevas töös tutvustame Araabia sarkasmi tuvastamise andmekogumit ArSarcasm, mis loodi olemasolevate araabia sentimentaalüüsi andmekogumite taasnimetamise teel. Andmekogum sisaldab 10 547 säutsu, millest 16% on sarkastilised. Lisaks sarkasmile märgiti andmeid sentimentaalsete ja dialektide kohta. Meie analüüs näitab nende ülesannete väga subjektiivset olemust, mida näitab muutus sentimentaalsete siltide osas, mis põhinevad annotatorite eelarvamustel. Katsed näitavad kaasaegsete sentimentaalüsaatorite lagunemist sarkastilise sisuga silmitsi seistes. Lõpuks treenime sügavõppe mudelit sarkasmi tuvastamiseks BiLSTM abil. Mudel saavutab F1 skoori 0,46, mis näitab ülesande keerulist olemust ja peaks olema aluseks tulevastele uuringutele meie andmekogumi kohta.', 'fi': 'Sarkasmi on yksi tunteiden analysointij瓣rjestelmien t瓣rkeimmist瓣 haasteista. Sen monimutkaisuus johtuu mielipiteen ilmaisemisesta ep瓣suorasti ep瓣suorasti. T瓣ss瓣 artikkelissa esittelemme ArSarcasmia, arabialaista sarkasmin tunnistustietoa, joka luotiin olemassaolevien arabialaisten tunteiden analyysiaineistojen uudelleenmerkitsemisen avulla. Aineisto sis瓣lt瓣瓣 10 547 twiitti瓣, joista 16% on sarkastisia. Sarkasmin lis瓣ksi aineistoon tehtiin huomautuksia tunteista ja murteista. Analyysimme osoittaa n瓣iden teht瓣vien eritt瓣in subjektiivisen luonteen, mik瓣 n瓣kyy kommentoijien ennakkoluuloihin perustuvien tunteiden muuttumisesta. Kokeet osoittavat viimeisimpien tunteiden analysaattoreiden hajoamisen sarkastisen sis瓣ll繹n edess瓣. Lopuksi harjoittelemme syv瓣oppimismallia sarkasmin havaitsemiseen BiLSTM:n avulla. Malli saavuttaa F1-pisteen 0,46, mik瓣 osoittaa teht瓣v瓣n haastavan luonteen, ja sen pit瓣isi toimia perusl瓣ht繹kohtana tulevalle tutkimukselle aineistossamme.', 'sk': 'Sarkazem je eden glavnih izzivov za sisteme analize sentimenta. Njegova kompleksnost izhaja iz izražanja mnenja z implicitnim posrednim besedilom. V prispevku predstavljamo ArSarcasm, arabski nabor podatkov za odkrivanje sarkazma, ki je bil ustvarjen s ponovno notacijo razpoložljivih arabskih naborov podatkov analize sentimenta. Zbirka podatkov vsebuje 10.547 tweetov, od katerih je 16% sarkastičnih. Poleg sarkazma so bili podatki označeni tudi za sentimentalne in narečja. Naša analiza kaže zelo subjektivno naravo teh nalog, kar dokazuje premik sentimentalnih oznak na podlagi pristranskosti opozorilcev. Eksperimenti kažejo razgradnjo najsodobnejših analizatorjev čustva, ko se soočajo s sarkastično vsebino. Na koncu smo usposobili model globokega učenja za odkrivanje sarkazma z BiLSTM. Model doseže rezultat F1 0,46, kar kaže zahtevno naravo naloge in mora delovati kot osnovno osnovo za prihodnje raziskave našega nabora podatkov.', 'bo': "སེམས་ཅན་དེ་ལྟ་བུའི་དབྱེ་ཞིབ་གི་རྩ་བའི་གདོང་ལེན་དག་གི་གཅིག་རེད། Its complexity comes from the expression of opinion using implicit indirect phrasing. འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་ཨ་ར་རབ་ཀྱི་སེམས་ཐག་གཙང་ཆེད་སྒྲིག་ཀྱི་ནང་དུ་ArSarcasm ཡི་སྒྲུང་ལ་རྙེད་ཀྱི་ནང་དུ་བྱུང་། སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆ་སྤྱད་ནས་གནད་དོན་འགྱུར་མཁན་འགྲོ་བ་༡༠,547དྲ་བ་ཞིག་ཡོད། སྤྱིར་བཏང་གི་ཐབས་ལམ་ནང་དུ་ཚོར་བ་སྣང་དང་སྒྲུང་ཐུང་སྙིང་ཡོད་པ་རེད། Our analysis shows the highly subjective nature of these tasks, which is demonstrated by the shift in sentiment labels based on annotators' biases. བརྟག་ཞིབ་ཀྱིས་སྒེར་གྱི་གནས་སྟངས་དང་སྣང་ཚུལ་ལྟ་བུ་ཚོར་བ་དང་མཉམ་དུ་འཕར་རིས་མངོན་འཆར་བྱེད་ཀྱི་ཡོད། མཐའ་མཇུག་དུ་འུ་ཅག་གིས་BiLSTM བེད་སྤྱོད་བཞིན་པའི་སྦྱོར་བའི་མ་དཔེ་གཏོང་གི་རེད། མ་དབུགས་འདིས་F1 རིམ་ཚད་0.46་ཡིན་པས་གནད་དོན་བཀོལ་བ་ཡིན་པའི་མིང་དཔྱད་ཡིན་པས། མ་འོངས་ལ་ཞིབ་འཚོལ་ཞིབ་འབད་དགོས", 'jv': 'Sarkasm kuwi wis ane karo perbudhakan sing dumadhi kanggo sistem dadi capan kelas. Rasane Nang pepul iki, awak dhéwé nggawe arSarkasm , dadi sing titik perusahaan sarkasm arap, sing nggawe ngupakan karo mulasah seneng dataset dadi sing beraksi perusahaan karo perangkat dhéwé. Sampeyan dataset nduwe 10.587 tuyte, 16% sampeyan karo sarkastik. tambah banter Ananali dhéwé menehi perbudhakan akeh apakno ning acara iki, sing bisa ngomong nik nggawe barang nggawe barang kelangan winih sing bisa basa oleh nyoatan. User: Nyong-ngobro, kita lagi ndherek sistem deep-Learn model kebutuhan sarkasm kuwi nggunakake BiLTT. model kuwi nggawe punika F1 sing paling 0,49, sing mau ning kapan kanggo ngilanggar sampeyan kanggo nggawe barang kanggo ngilanggar sampeyan kanggo ngilanggar sampek dadi.', 'he': 'סרקזם הוא אחד האתגרים העיקריים למערכות ניתוח רגשות. המורכבות שלה מגיעה מהביטוי של דעה באמצעות ביטוי אינדרי מילוי. בעיתון הזה, אנחנו מציגים את ארסארקזם, קבוצת נתונים לגילוי סרקזם ערבית, שנוצרה באמצעות הבחינה מחדש של קבוצות נתונים ניתוח רגשות ערביים זמינות. קבוצת המידע מכילה 10,547 טוויטים, 16% מהם סרקסטיים. In addition to sarcasm the data was annotated for sentiment and dialects.  הניתוח שלנו מראה את הטבע הסוביקטיבי ביותר של המשימות האלה, אשר מוצג על ידי השינוי בתוויות רגשות מבוססת על ההתמונות של המציאות. ניסויים מראים את השפלה של ניתוחי רגשות חדשים כשמתמודדים עם תוכן סרקסטי. סוף סוף, אנחנו מאמן מודל למידה עמוק לזהות סרקזם באמצעות BILSTM. המודל משיג נקודת F1 של 0.46, אשר מראה את הטבע המתאגר של המשימה, והוא צריך לפעול כבסיסי עבור מחקר עתיד על קבוצת הנתונים שלנו.', 'ha': "Sarkasm yana daga cikin muhimman hasara wa'anar-fasarin na'ura. Tammarsa na zo daga maganar ganin ta yi amfani da magana mai daidai. Ga wannan karatun, Munã halatar da ArSarcasm, a matsayin bayani na sarkasm na Larabci, wanda aka halicce shi daga redo na fassarar data na fassarar da za'a iya amfani da. Ana ƙunsa da 10,547 ɗin jumawa, kuma asiyen 16u sunan sarcasti. Babu sarsarki, aka cũtar da data wa matsayin da aka yi wa hisãbi. AnalyyinMu yana nũna halin masu muhimmi daga wannan aikin, wanda aka nuna shi da musanya cikin alama na hisani, a kan karatun matangazo. Experiments show the lower state-of-the-art Analysari idan facing sarcastic contents. Haƙari, za'a sanar da misãlin da za'a yi wa gano na sarki da amfani da BiLSM. @ info: whatsthis"}
{'en': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'ar': 'إرسال ALT لمهمة OSACT المشتركة حول اكتشاف اللغة الهجومية', 'es': 'Envío de ALT para la tarea compartida de OSACT sobre detección de lenguaje ofensivo', 'fr': 'Soumission ALT pour la tâche partagée OSACT sur la détection de langage offensant', 'pt': 'Envio de ALT para tarefa compartilhada OSACT na detecção de linguagem ofensiva', 'ja': '不快な言語検出時のOSACT共有タスクの代替送信', 'hi': 'OSACT के लिए ALT सबमिशन आपत्तिजनक भाषा का पता लगाने पर साझा कार्य', 'zh': '犯性检 OSACT 共事者 ALT 交', 'ru': 'Представление ALT для общей задачи OSACT по обнаружению оскорбительного языка', 'ga': 'Aighneacht ALT do Thasc Roinnte OSACT ar Bhrath Teanga Ionsaitheach', 'ka': 'OSACT გაყოფილი საქაღალდე საქაღალდე საქაღალდე სუფლიო ენის განახსნა', 'hu': 'ALT beküldés az OSACT megosztott feladatához a támadó nyelv felismerésével kapcsolatban', 'el': 'Υποβολή ALT για κοινή εργασία OSACT για την ανίχνευση προσβλητικών γλωσσών', 'lt': 'ALT pateikimas OSACT bendrai užduotims nustatyti pažeidžiamą kalbą', 'it': "Invio ALT per l'attività condivisa di OSACT sul rilevamento del linguaggio offensivo", 'mk': 'ALT поднесување за OSACT споделена задача за детекција на навредлив јазик', 'kk': 'OSACT ортақтастырылған тапсырмалар бойынша тілді анықтау үшін ALT жіберу', 'ms': 'Submission ALT untuk Tugas Berkongsi OSACT pada Pengesanan Bahasa Tersinggung', 'ml': 'ഓസാക്റ്റ് പങ്കാളിയാക്കിയ ജോലി', 'mt': 'Sottomissjoni tal-ALT għal Kompitu Konġunt tal-OSACT dwar id-Detezzjoni tal-Lingwa Offensiva', 'mn': 'ОСАКТ Хүмүүсийн хэл тогтоохын тулд ALT дамжуулалт', 'pl': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'ro': 'Trimiterea ALT pentru misiunea partajată OSACT privind detectarea limbajului ofensiv', 'no': 'ALT Submission for OSACT delt oppgåve ved forskyving av språk', 'sr': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'si': 'OSACT භාෂාව හොයාගන්න හොයාගන්න හොයාගන්න හැකියාව සම්බන්ධය', 'so': 'ALT Sameynta shaqada la sharciyey oo ku saabsan aqoonsiga luqada', 'sv': 'ALT-inlämning för OSACT delad uppgift om detektering av offensivt språk', 'ta': 'OSACT பகிர்ந்த பணி', 'ur': 'OSACT Shared Task for ALT Submission on Offensive Language Detection', 'uz': 'Name', 'vi': 'Hỗ trợ thương thuyết của Comment', 'bg': 'Подаване на ALT за споделена задача за откриване на офанзивен език', 'nl': 'ALT indiening voor OSACT Shared Task on Offensive Language Detection', 'da': 'ALT Indsendelse til OSACT delt opgave om detektering af offensivt sprog', 'hr': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'de': 'ALT-Einreichung für OSACT Shared Task zur Erkennung offensiver Sprachen', 'ko': 'OSACT 공유 작업에 대한 공격적인 언어 감지 Alt 제출', 'fa': 'Submission ALT for OSACT Shared Task on Offensive Language Detection', 'id': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'sq': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'am': 'አዲስ ዶሴ ፍጠር', 'hy': 'ALT-ի ներկայացումը', 'tr': 'OSACT Boýunça Dili Aňlamak üçin ALT Submission', 'sw': 'Ujumbe wa ALT kwa OSACT', 'az': 'OSACT paylaşılmış işləri Nöqsanlı Dil Tapılması barəsində ALT Submission for OSACT Shared Task on Offensive Language Detection', 'af': 'ALT Submission vir OSACT Gedeelde Opdrag op Offensive Taal Opdekking', 'bn': 'অফিসেন্ট ভাষা সনাক্ত করার জন্য OSACT শেয়ার করা কাজের ALT সাবমিশন', 'bs': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'ca': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'cs': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'et': 'ALT esitamine OSACTi jagatud ülesandele ründava keele tuvastamiseks', 'fi': 'ALT-lähetys OSACT Shared Task on Offensive Language Detection -ohjelmaan', 'he': 'שידור ALT עבור משימה משותפת OSACT על גילוי שפת פגיעה', 'ha': 'KCharselect unicode block name', 'bo': 'ALT Submission for OSACT Shared Task on Offensive Language Detection', 'sk': 'Oddaja ALT za OSACT skupno opravilo o zaznavanju napadalnega jezika', 'jv': 'AlT Submis kanggo OWALTI Kejaran task nang OWALTI Language detection'}
{'en': 'In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection. The shared ', 'ar': 'في هذه الورقة ، نصف جهودنا في OSACT Shared Task on Offensive Language Detection. تتكون المهمة المشتركة من مهمتين فرعيتين: اكتشاف اللغة الهجومية (المهمة الفرعية أ) واكتشاف الكلام الذي يحض على الكراهية (المهمة الفرعية ب). لاكتشاف اللغة الهجومية ، حقق مزيج نظام من آلات المتجهات الداعمة (SVMs) والشبكات العصبية العميقة (DNNs) أفضل النتائج في مجموعة التطوير ، والتي احتلت المرتبة الأولى في النتائج الرسمية لـ Subtask A بدرجة F1 بنسبة 90.51٪ في الاختبار جلس. بالنسبة لاكتشاف الكلام الذي يحض على الكراهية ، كانت DNNs أقل فاعلية وحققت مجموعة نظام من أجهزة SVM متعددة مع معلمات مختلفة أفضل النتائج في مجموعة التطوير ، والتي احتلت المرتبة الرابعة في النتائج الرسمية لـ Subtask B مع درجة F1- ماكرو 80.63٪ في مجموعة الاختبار.', 'fr': "Dans cet article, nous décrivons nos efforts dans le cadre de la tâche partagée OSACT sur la détection du langage offensant. La tâche partagée comprend deux sous-tâches\xa0: la détection du langage offensant (sous-tâche A) et la détection des discours haineux (sous-tâche B). Pour la détection de langage offensant, une combinaison système de machines à vecteurs de support (SVM) et de réseaux de neurones profonds (DNN) a obtenu les meilleurs résultats sur l'ensemble de développement, qui s'est classé 1er dans les résultats officiels de la sous-tâche A avec un score F1 de 90,51\xa0% sur l'ensemble de test. Pour la détection des discours haineux, les DNN étaient moins efficaces et une combinaison de plusieurs SVM avec différents paramètres a permis d'obtenir les meilleurs résultats sur l'ensemble de développement, qui se classait au 4e rang des résultats officiels pour la sous-tâche B avec un score F1-macro de 80,63\xa0% sur l'ensemble de test.", 'pt': 'Neste artigo, descrevemos nossos esforços na tarefa compartilhada OSACT na detecção de linguagem ofensiva. A tarefa compartilhada consiste em duas subtarefas: detecção de linguagem ofensiva (Subtarefa A) e detecção de discurso de ódio (Subtarefa B). Para detecção de linguagem ofensiva, uma combinação de sistema de Support Vector Machines (SVMs) e Deep Neural Networks (DNNs) alcançou os melhores resultados no conjunto de desenvolvimento, que ficou em 1º lugar nos resultados oficiais da Subtarefa A com pontuação F1 de 90,51% no teste definir. Para detecção de discurso de ódio, DNNs foram menos eficazes e uma combinação de sistema de vários SVMs com diferentes parâmetros alcançou os melhores resultados no conjunto de desenvolvimento, que ficou em 4º lugar nos resultados oficiais da Subtarefa B com pontuação F1-macro de 80,63% no conjunto de teste.', 'es': 'En este artículo, describimos nuestros esfuerzos en la tarea compartida de OSACT sobre detección de lenguaje ofensivo. La tarea compartida consta de dos subtareas: detección de lenguaje ofensivo (subtarea A) y detección de incitación al odio (subtarea B). Para la detección de lenguaje ofensivo, una combinación de sistemas de máquinas de vectores de soporte (SVM) y redes neuronales profundas (DNN) logró los mejores resultados en el conjunto de desarrollo, que ocupó el primer lugar en los resultados oficiales de la subtarea A con una puntuación de F1 del 90,51% en el conjunto de pruebas. Para la detección del discurso de odio, las DNN fueron menos efectivas y una combinación de sistemas de múltiples SVM con diferentes parámetros logró los mejores resultados en el conjunto de desarrollo, que ocupó el cuarto lugar en los resultados oficiales de la subtarea B con una puntuación macro F1 del 80,63% en el conjunto de pruebas.', 'ja': '本稿では、OSACT Shared Task on Offensive Language Detectionでの取り組みについて述べる。共有タスクは、不快な言語検出（サブタスクA ）とヘイトスピーチ検出（サブタスクB ）の2つのサブタスクで構成されています。不快な言語検出のために、Support Vector Machines （ SVM ）とDeep Neural Networks （ DNN ）のシステムの組み合わせは、開発セットで最高の結果を達成しました。これは、テストセットのF 1スコアが90.51 ％で、サブタスクAの公式結果で1位でした。ヘイトスピーチ検出では、DNNはあまり効果的ではなく、異なるパラメータを有する複数のSVMのシステム組み合わせは、開発セットで最高の結果を達成し、これは、テストセット上のF 1 -マクロスコアが80.63%であるサブタスクBの公式結果で4位にランクされた。', 'zh': '本文,我们述述了我们在OSACT犯性言语检测的共享事务。 共事二子:犯言检(子职 A)仇言检(子 B)。 犯性检言,赞向量机(SVM)深度神经网络(DNN)之统结于开发集上取其最善,于子职A官第一,于试集上之F1分为90.51%。 仇言相检,DNN之效差,异参数之SVM,合于开发集上取其最佳者,于子职B官第四,于试集上之F1-macro分为80.63%。', 'hi': 'इस पेपर में, हम आक्रामक भाषा का पता लगाने पर OSACT साझा कार्य में हमारे प्रयासों का वर्णन करते हैं। साझा कार्य में दो उप-कार्य होते हैं: आक्रामक भाषा का पता लगाना (सबटास्क ए) और हेट स्पीच डिटेक्शन (सबटास्क बी)। आक्रामक भाषा का पता लगाने के लिए, समर्थन वेक्टर मशीनों (एसवीएम) और डीप न्यूरल नेटवर्क (डीएनएन) के एक सिस्टम संयोजन ने विकास सेट पर सबसे अच्छे परिणाम प्राप्त किए, जो परीक्षण सेट पर 90.51% के एफ 1-स्कोर के साथ सबटास्क ए के लिए आधिकारिक परिणामों में पहले स्थान पर थे। हेट स्पीच डिटेक्शन के लिए, डीएनएन कम प्रभावी थे और विभिन्न मापदंडों के साथ कई एसवीएम के एक सिस्टम संयोजन ने विकास सेट पर सबसे अच्छे परिणाम प्राप्त किए, जो परीक्षण सेट पर 80.63% के एफ 1-मैक्रो स्कोर के साथ सबटास्क बी के लिए आधिकारिक परिणामों में 4 वें स्थान पर थे।', 'ru': 'В настоящем документе мы описываем наши усилия по совместной задаче ОСАКТ по обнаружению оскорбительных языков. Общая задача состоит из двух подзадач: обнаружение оскорбительного языка (Подзадача А) и обнаружение ненавистнической речи (Подзадача Б). Для обнаружения наступательного языка лучшие результаты на наборе разработок была достигнута системная комбинация из Support Vector Machines (SVMs) и Deep Neural Networks (DNNs), которая заняла 1-е место в официальных результатах по подзадаче А с показателем F1 90,51% на тестовом наборе. Для обнаружения ненавистнических высказываний DNN были менее эффективными, а системная комбинация из нескольких виртуальных машин защиты с разными параметрами достигла наилучших результатов на наборе разработок, который занял 4-е место по официальным результатам для Подзадачи B с F1-макро оценкой 80,63% на тестовом наборе.', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar ár n-iarrachtaí ar Thasc Roinnte OSACT ar Bhrath Teanga Ionsaitheach. Tá dhá fhothasc sa tasc comhroinnte: braite teanga maslach (Fothasc A) agus brath fuathchaint (Fothasc B). Maidir le braite teanga maslach, bhain meascán córais de Mheaisíní Veicteoir Tacaíochta (SVManna) agus Líonraí Neural Deep (DNNanna) na torthaí is fearr ar thacar forbartha, a bhí sa 1ú háit i dtorthaí oifigiúla Fothasc A le scór F1 de 90.51% ar an tástáil leagtha. Maidir le fuathchaint a bhrath, ní raibh DNNanna chomh héifeachtach agus bhain teaglaim córais d’il-SVManna le paraiméadair éagsúla na torthaí is fearr ar thacar forbartha, a bhí sa 4ú háit i dtorthaí oifigiúla Fothasc B le scór F1-macra de 80.63% ar an tacar tástála.', 'el': 'Σε αυτή την εργασία, περιγράφουμε τις προσπάθειές μας στην κοινή εργασία για την ανίχνευση προσβλητικών γλωσσών. Η κοινή εργασία αποτελείται από δύο δευτερεύουσες εργασίες: ανίχνευση προσβλητικής γλώσσας (δευτερεύουσα εργασία Α) και ανίχνευση ομιλίας μίσους (δευτερεύουσα εργασία Β). Για την ανίχνευση προσβλητικών γλωσσών, ένας συνδυασμός συστημάτων διανυσματικών μηχανών υποστήριξης (SVMs) και βαθέων νευρωνικών δικτύων (DNN) πέτυχε τα καλύτερα αποτελέσματα στο σύνολο ανάπτυξης, το οποίο κατατάχθηκε πρώτο στα επίσημα αποτελέσματα για την Υποεργασία Α με βαθμολογία F1 90,51% στο σετ δοκιμής. Για την ανίχνευση ρητορικής μίσους, τα DNN ήταν λιγότερο αποτελεσματικά και ένας συνδυασμός συστημάτων πολλαπλών SVM με διαφορετικές παραμέτρους πέτυχε τα καλύτερα αποτελέσματα στο σύνολο ανάπτυξης, το οποίο κατατάχθηκε 4η στα επίσημα αποτελέσματα για την Υποεργασία Β με βαθμολογία μακροεντολής F1 80,63% στο σύνολο δοκιμής.', 'hu': 'Ebben a tanulmányban bemutatjuk erőfeszítéseinket az OSACT Shared Task on Offensive Language Detection cégnél. A megosztott feladat két alcsoportból áll: sértő nyelvészlelés (A. alcsoport) és gyűlöletbeszédérzékelés (B. alcsoport). A támadó nyelvészlelés érdekében a Support Vector Machines (SVM) és a Deep Neural Networks (DNN) rendszerkombinációja érte el a legjobb eredményeket a fejlesztési készleten, amely az 1. helyezett az A. alfeladat hivatalos eredményei között 90,51%-os F1 pontszámmal a tesztkészleten. A gyűlöletbeszéd felismerésére a DNN-ek kevésbé hatékonyak voltak, és a különböző paraméterekkel rendelkező több SVM rendszerkombinációja érte el a legjobb eredményeket a fejlesztési készleten, amely a B. alfeladat hivatalos eredményei között a negyedik helyen állt, az F1-makró pontszáma 80,63%.', 'ka': 'ამ დოკუნეში ჩვენ აღწერეთ ჩვენი ძალადობას OSACT გაყოფილი რაოდენობაზე, რომელიც უფრო უფრო ძალიან ენაღწერებაზე. საზოგადოებული დავალება შექმნა ორი საზოგადოებების შეფარდება: საზოგადოებული ენის განახსნა (A საზოგადოება) და მპარებული ენის განახსნა (B საზოგადოება). საფუნქციური ენის განახლებისთვის სისტემის კომბიზაცია გვექტორის მაქანების (SVMs) და ძალიან ნეიროლური ქსელების (DNNs) სისტემის კომბიზაციაში მიღეთ ყველაზე საუკეთესო წარმოდგენება, რომელიც პირველი წარმოდგენა განვიხილებისთვის, DNN იყო უფრო ეფექტიური და სისტემის კომბიზაცია, რაც განსხვავებული პარამეტრებით მიიღეთ უკეთესი შედეგი შედეგი განვიხილებისთვის, რომელიც პროგრამის 4მე შედეგი Subtask B-ის პროგრამის პრო', 'lt': 'Šiame dokumente apibūdiname mūsų pastangas OSACT bendrame uždavinyje nustatyti pažeidžiamą kalbą. The shared task consists of two subtasks: offensive language detection (Subtask A) and hate speech detection (Subtask B).  Siekiant užpuolimo kalbų nustatymo, paramos vektorių mašin ų (SVM) ir giliųjų neurologinių tinklų (DNN) sistemos derinys pasiekė geriausius vystymosi rezultatus, kurie buvo pirmasis oficialių A poskirsnio rezultatų, o bandymų rinkinyje F1 rezultatas buvo 90,51 %. Kad būtų galima nustatyti neapykantos kalbą, DNN buvo mažiau veiksmingi, o daugelio SVM su skirtingais parametrais sisteminis derinys pasiekė geriausius vystymosi rezultatus, kurie buvo ketvirtasis oficialių B subužduoties rezultatų, o F1 makro balas buvo 80,63 % bandymų grupėje.', 'kk': 'Бұл қағазда, OSACT ортақтастырылған тапсырмаларымызды көмектесу тілді анықтау үшін тапсырмаларымызды таңдап көрдік. Ортақ тапсырма екі ішкі сұрақтардан тұрады: offensive language detection (Subtask A) and hate speech detection (Subtask B). Тілдерді анықтау үшін қолдау вектор механизмтері (SVMs) және түйінгі невралдық желілер (DNNs) жүйесі біріктірілген жасау жиынының ең жақсы нәтижелерін жеткізді. Бұл сынақтағы A Subtask үшін 1- нәтижелерінде, F1- нәтижелерінде 90 Жұмыс сөздерді анықтау үшін, DNN бағдарламалары көп эффективті емес және бірнеше параметрлермен бірнеше SVM бағдарламаларының жинақтауындағы ең жақсы нәтижелерін жеткізеді, бұл жетілдіру бағдарламаларының 4- ші нәтижелері', 'it': "In questo articolo, descriviamo i nostri sforzi in OSACT Shared Task on Offensive Language Detection. L'attività condivisa consiste in due sottoattività: rilevamento offensivo del linguaggio (sottoattività A) e rilevamento dell'odio vocale (sottoattività B). Per il rilevamento del linguaggio offensivo, una combinazione di sistemi di macchine vettoriali di supporto (SVM) e reti neurali profonde (DNN) ha ottenuto i migliori risultati sul set di sviluppo, che si è classificata al primo posto nei risultati ufficiali per la sottomissione A con un punteggio F1 del 90,51% sul set di test. Per il rilevamento del discorso d'odio, i DNN sono stati meno efficaci e una combinazione di sistema di più SVM con parametri diversi ha ottenuto i migliori risultati sul set di sviluppo, che si è classificato 4 ° nei risultati ufficiali per Subtask B con punteggio F1-macro dell'80,63% sul set di test.", 'mk': 'Во овој весник, ги опишуваме нашите напори во ОСАЦТ поделена задача за детекција на навредлив јазик. Соделената задача се состои од две подзадачи: детекција на навредлив јазик (подзадача А) и детекција на говор на омраза (подзадача Б). За детекција на навреден јазик, системската комбинација на векторни машини за поддршка (СВМ) и длабоките неврални мрежи (ДНН) ги постигна најдобрите резултати на сетот на развој, кој се рангираше на првиот во официјалните резултати за субзадача А со оценка F1 од 90,51 отсто на тесто За детекција на говорот на омраза, ДНН беа помалку ефикасни и системската комбинација на повеќе СВМ со различни параметри ги постигна најдобрите резултати на сетот на развој, кој се рангираше на четвртиот во официјалните резултати за Субзадача Б со F1-макро оценка од 80,63', 'ms': 'In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection.  Tugas berkongsi terdiri dari dua sub-tanya: pengesan bahasa yang menyerang (Sub-tugas A) dan pengesan ucapan kebencian (Sub-tugas B). Untuk pengesan bahasa yang menyerang, kombinasi sistem Mesin Vektor Sokongan (SVMs) dan Rangkaian Neural Dalam Dalam (DNN) mencapai keputusan terbaik pada set pembangunan, yang ditangkap pertama dalam keputusan rasmi untuk Subtugas A dengan skor-F1 90.51% pada set ujian. Untuk pengesan ucapan kebencian, DNN kurang berkesan dan kombinasi sistem SVM berbilang dengan parameter berbeza mencapai keputusan terbaik pada set pembangunan, yang ditangkap ke-4 dalam keputusan rasmi untuk Subtugas B dengan skor F1-makro 80.63% pada set ujian.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഓസാക്റ്റില്\u200d പങ്കാളിയുള്ള ജോലിയെ വിശദീകരിക്കുന്നു. പങ്കാളിയുള്ള ജോലിയില്\u200d രണ്ടു സബ്ജോട്ടുകളില്\u200d ഉണ്ട്: ആക്രമിക്കുന്ന ഭാഷ കണ്ടുപിടിപ്പിക്കുന്നു (സബ്ബ്ജ് A പിന്തുണയ്ക്കുന്ന ഭാഷ കണ്ടുപിടിക്കാന്\u200d ഒരു സിസ്റ്റമില്\u200d പിന്തുണയ്ക്കുന്ന വെക്റ്റര്\u200d മെഷിനുകളുടെയും ഡിപ്പ് നെയുറല്\u200d നെറ്റ്വര്\u200dക്കുകളുടെയും കൂട്ടത്തില്\u200d ഏറ്റവും നല്ല ഫലങ് വെറുപ്പുള്ള സംസാരം കണ്ടുപിടിക്കുന്നതിനായി ഡിഎന്\u200dഎന്\u200dഎന്\u200d സിസ്റ്റത്തിന്റെ സിസ്റ്റം കൂടുതല്\u200d പ്രാവര്\u200dത്തികമായിരുന്നു. വ്യത്യസ്ത പരാമീറ്ററുകളുമായി പല എസ്വിഎ', 'mt': 'F’dan id-dokument, aħna niddeskrivu l-isforzi tagħna fil-Kompitu Konġunt tal-OSACT dwar id-Detezzjoni tal-Lingwi Offensivi. Il-kompitu kondiviż jikkonsisti f’żewġ sottomistoqsijiet: l-iskoperta ta’ lingwi offensivi (Subkompitu A) u l-iskoperta ta’ diskors ta’ mibegħda (Subkompitu B). Għad-detezzjoni ta’ lingwi offensivi, kombinazzjoni tas-sistema ta’ Magni ta’ Vetturi ta’ Appoġġ (SVMs) u Netwerks Newrali Profondi (DNNs) kisbet l-a ħjar riżultati dwar is-sett ta’ żvilupp, li kklassifikat l-ewwel fir-riżultati uffiċjali għas-Subkompitu A b’punteġġ F1 ta’ 90.51% fuq is-sett tat-test. Għall-individwazzjoni tad-diskors ta’ mibegħda, id-DNNs kienu inqas effettivi u kombinazzjoni tas-sistema ta’ SVMs multipli b’parametri differenti kisbet l-a ħjar riżultati fis-sett tal-iżvilupp, li kklassifikat ir-raba’ fir-riżultati uffiċjali għas-Subkompitu B b’punteġġ F1-makro ta’ 80.63% fis-sett tat-test.', 'no': 'I denne papiret beskriver vi forsøkene våre på OSACT-delt oppgåve om forskyving av språk. Den delte oppgåva inneheld to underspørjingar: offensiv språk- oppdaging (Subtask A) og hatet taleoppdaging (Subtask B). For offensiv språk oppdaging, fikk eit systemkombinasjon av støtte vektormaskiner (SVMs) og dyppa neuralnettverk (DNN) det beste resultatet på utviklingssett, som rangerte 1 i den offisielle resultatet for Subtask A med F1- poeng 90,51% på testsettet. For å oppdaga hatespråk, var DNN mindre effektiv, og eit systemkombinasjon av fleire SVMs med ulike parametrar oppnådd dei beste resultatene på utviklingssett, som rangerte 4. i offisielle resultatene for Subtask B med F1- makro- poeng 80, 63% på testsettet.', 'ro': 'În această lucrare, descriem eforturile noastre la OSACT Shared Task on Offensive Language Detection. Activitatea partajată constă în două subactivități: detectarea limbajului ofensator (subactivitatea A) și detectarea vorbirii la ură (subactivitatea B). Pentru detectarea limbajului ofensator, o combinație de sistem de Suport Vector Machines (SVM) și Deep Neural Networks (DNN) a obținut cele mai bune rezultate pe setul de dezvoltare, care a ocupat locul 1 în rezultatele oficiale pentru Subsarcina A cu un scor F1 de 90,51% pe setul de test. Pentru detectarea discursului de ură, DNN-urile au fost mai puțin eficiente și o combinație de sistem de mai multe SVM cu parametri diferiți a obținut cele mai bune rezultate pe setul de dezvoltare, care s-a clasat pe locul 4 în rezultatele oficiale pentru Subsarcina B cu un scor F1-macro de 80,63% pe setul de test.', 'pl': 'W niniejszym artykule opisujemy nasze działania w ramach OSACT Shared Task on Offensive Language Detection. Wspólne zadanie składa się z dwóch podzadań: wykrywania obraźliwego języka (podzadanie A) i wykrywania mowy nienawiści (podzadanie B). Dla wykrywania obraźliwego języka kombinacja systemowa wsparcia wektorów (SVM) i głębokich sieci neuronowych (DNN) osiągnęła najlepsze wyniki w zestawie programistycznym, który zajął pierwszy miejsce w oficjalnych wynikach podzadania A z wynikiem F1 90,51% na zestawie testowym. W przypadku wykrywania mowy nienawiści DNN były mniej skuteczne, a połączenie systemowe wielu SVM o różnych parametrach osiągnęło najlepsze wyniki w zestawie programistycznym, który zajął czwartą pozycję oficjalnych wyników podzadania B z wynikiem makro F1 80,63% na zestawie testowym.', 'mn': 'Энэ цаасан дээр бид ОСАКТ-ын хуваалцаагүй хэлний мэдэх талаар хичээлийг тайлбарлаж байна. Холбоотой ажил нь хоёр суурь асуулт бий болгож байна: буруу хэл тогтоох (А суурь ажил) болон үзэн ядах ярианы тогтоох (B суурь ажил). Хүмүүсийн хэл мэдэхийн тулд тусламжтай вектор машинууд (SVMs) болон гүн сэтгэл мэдрэлийн сүлжээний хамгийн сайн үр дүнг гаргасан бөгөөд шалгалтын багтаагаар 1-р нь Subtask A-ын албан ёсны үр дүнд F1-score нь 90.51%. Харамсалтай яриаг олох үед ДНХ нь бага үр дүнтэй байсан бөгөөд олон SVMs-ын системийн нийлүүлэлт нь хөгжлийн багш дээр хамгийн сайн үр дүнг олсон. Энэ нь Subtask B-ын 4-р үр дүнд шалгалтанд F1-макро хэмжээтэй 80,63% байсан.', 'sr': 'U ovom papiru opisujemo naše napore na OSACT-u podeljenom zadatku o otkrivanju službenog jezika. Podijeljeni zadatak sastoji od dva podataka: detekcija ofanzivnog jezika (podzadatak A) i detekcija govora mržnje (podzadatak B). Za otkrivanje ofanzivnih jezika, sistemska kombinacija podrške vektorskih mašin a (SVMs) i dubokih neuronskih mreža (DNN) postigla je najbolji rezultat na setu razvoja, koji je prvi u službenim rezultatima subtask A sa 90,51% na testu. Za otkrivanje govora mržnje, DNN su bile manje efikasne, a sistemska kombinacija višestrukih SVM-ova sa različitim parametrama postigla je najbolji rezultat na setu razvoja, koji je četvrti u službenim rezultatima za Subtask B sa makrom od 80,63% na setu testova.', 'so': 'Qoraalkan waxaynu ku qoraynaa hawlahayaga ku saabsan OSACT oo lagu sharciyey shaqo ku saabsan baaritaanka luqada. Shaqada la qaybsado waxaa ka mid ah labo shaqo: aqoonsashada afka rasmiga ah (Subtask A) iyo caddeynta hadalka nebcaalka (Subtask B). For offensive language detection, a system combination of Support Vector Machines (SVMs) and Deep Neural Networks (DNNs) achieved the best results on development set, which ranked 1st in the official results for Subtask A with F1-score of 90.51% on the test set.  Qiimeynta hadalka nacayb aawadeed, DNNs waxay ahaayeen mid ka yar shaqeyn kara islamarkaasna waxaa gaadhay kooxaha SVMs oo kala duduwan oo ay leeyihiin midhaha ugu wanaagsan ee koritaanka, taasoo ka horraysa 4aad resultada rasmiga ah ee Subtask B with F1-macro score 80.63% oo lagu qoray imtixaanka.', 'sv': 'I denna uppsats beskriver vi våra insatser på OSACT Shared Task on Offensive Language Detection. Den delade uppgiften består av två underuppgifter: detektering av stötande språk (underuppgift A) och detektering av hattal (underuppgift B). För detektering av stötande språk uppnådde en systemkombination av Support Vector Machines (SVM) och Deep Neural Networks (DNN) de bästa resultaten på utvecklingsuppsättningen, som rankade 1:a i de officiella resultaten för Underuppgift A med F1-poäng på 90,51% på testuppsättningen. För hattalsdetektering var DNN mindre effektiva och en systemkombination av flera SVM med olika parametrar uppnådde de bästa resultaten på utvecklingsuppsättningen, som rankades 4:e i officiella resultat för deluppgift B med F1-makro poäng på 80,63% på testuppsättningen.', 'si': 'මේ පත්තරේ අපි අපේ උත්සාහ විස්තර කරනවා OSACT සමාගත වැඩක් අධික භාෂා හොයාගන්න. සම්බන්ධ වැඩේ සම්බන්ධ වැඩේ සම්බන්ධ වැඩ දෙකක් තියෙනවා: අපරාධ භාෂාව හොයාගන්න (සුබ් වැඩ A) සහ වෛර අපරාධ භාෂාව හොයාගන්න, වෙක්ටර් මැචින්ස් සහ ගොඩක් නිර්මාණ ජාලය (DNNs) වල පද්ධතිය සම්බන්ධතාවක් සම්බන්ධතාවක් සම්බන්ධතාවක් සඳහා පරීක්ෂණය සඳහා ස විශ්වාස කතා පරීක්ෂණය සඳහා, DNN නිසා පරීක්ෂණයක් අඩුවෙන් ප්\u200dරශ්නයක් තිබුනා, වෙනස් ප්\u200dරමාණයක් තිබුනා වෙනස් SVMs ගැන පද්ධතිය සම්බන්ධ විශ්වා', 'ta': 'இந்த தாளில், OSACT பகிர்ந்த பணி The shared task consists of two subtasks: offensive language detection (Subtask A) and hate speech detection (Subtask B).  முற்றிலும் மொழி கண்டுபிடிப்பதற்கு, ஆதரவு நெறி இயந்திரங்கள் (SVMs) மற்றும் ஆழமான நெருக்கிய வலைப்பின்னல்கள் (DNNs) சிறந்த முடிவுகளை பெற்றார்கள், அது சோதனைக்கு அமைப்பில் முதல் ம வெறுப்பு பேச்சு கண்டுபிடிப்பதற்காக DNNs செயல்பாடு குறைவாக இருந்தது மற்றும் வேறு அளபுருகளுடன் பல எஸ்விமிஸ்களுக்கு ஒரு அமைப்பு சேர்க்கப்பட்டது முன்னேற்றம் அமைப்பு', 'ur': 'ہم اس کاغذ میں اپنے کوشش کو OSACT شریک ٹاکس کے بارے میں نافذی زبان شناسی کے بارے میں بیان کرتے ہیں. مشترک کام میں دو سٹسٹسٹ ہیں: ناپسند زبان شناسایی (Subtask A) اور ناپسند بات شناسایی (Subtask B). فنسیف زبان شناسایی کے لئے، ایک سیستم ویکتور ماشین (SVMs) اور عمیق نیورال نیٹورک (DNNs) کی ترکیب پہنچائی گئی ہے، جس نے آزمائش سٹ پر F1-score 90.51% کے سب سے بہترین نتیجے پہنچ گئے۔ ناپسندیدہ بات شناسایی کے لئے DNN کم اثرات تھی اور مختلف پارامیٹروں کے ساتھ بہترین نتیجے پہنچ گئے ہیں جن کو تحقیق سٹے پر F1-macro score 80.63% کے ساتھ Subtask B کے رسمی نتیجے میں چوتھا تھا۔', 'vi': 'Trong tờ giấy này, chúng tôi mô tả nỗ lực của chúng tôi tại công tác chia sẻ của OSNACK về trinh sát ngôn ngữ tàn bạo. Nhiệm vụ chia sẻ gồm hai mặt: phát hiện ngôn ngữ tấn công (Tinh yêu A) và phát hiện ngôn ngữ ghét (Tinh cầu B). Để phát hiện ngôn ngữ tấn công, một tổ hợp hệ thống các cỗ máy phát xít (SVMs) và mạng thần kinh sâu (DNS) đã đạt được kết quả tốt nhất về bộ phát triển, thứ nhất được phân loại trong kết quả chính thức của giấu A với số F1 của 90.51=. trong bộ thử nghiệm. Đối với việc phát hiện ngôn ngữ ghét, DNS còn ít hiệu quả hơn và một hệ thống kết hợp nhiều SVMs với các tham số khác đã đạt được kết quả tốt nhất trên bộ phát triển, điểm thứ tư trong kết quả chính thức cho Subask B với số siêu âm F1 của 80.6T. trong bộ thử nghiệm.', 'uz': "Bu hujjatda biz OSACT bilan birlashtirilgan vazifani faqat qilamiz. Boʻlishilgan vazifalar ikkita subvazifalar: offensive language detection (Subtask A) va hate гап detection (Subtask B). Name Hat so'zni aniqlash uchun DNNS'ning ko'plab parametrlar bilan bir necha SVMs'ning bir tizimi birlashtirilgan va bir xil parametrlar o'zgarishning eng yaxshi natijalarini bajardi. Bu sinov tugmasining 80.63% bilan subtask B'ning 4 ta ta natijalariga o'zgartirdi.", 'bg': 'В тази статия ние описваме нашите усилия в Споделена задача за откриване на офанзивен език. Споделената задача се състои от две подзадачи: откриване на обиден език (подзадача А) и откриване на реч на омраза (подзадача Б). За откриване на офанзивен език системната комбинация от Поддържащи Векторни Машини (СВМ) и Дълбоки Неврални Мрежи (ДНН) постигна най-добри резултати в комплекта разработки, който се класира на първо място в официалните резултати за Подзадача А с резултат от 90.51% на теста. За откриване на реч от омраза ДНН са по-малко ефективни и системната комбинация от множество СММ с различни параметри постига най-добри резултати в комплекта разработки, който се класира на 4-то място в официалните резултати за Подзадача Б с оценка от 80,63% на теста.', 'da': "I denne artikel beskriver vi vores indsats hos OSACT Shared Task on Offensive Language Detection. Den delte opgave består af to underopgaver: detektering af stødende sprog (underopgave A) og detektering af hadefulde tale (underopgave B). Til stødende sprogregistrering opnåede en systemkombination af Support Vector Machines (SVM'er) og Deep Neural Networks (DNN'er) de bedste resultater på udviklingssættet, som rangerede første i de officielle resultater for Underopgave A med F1-score på 90,51% på testsættet. Til detektering af hadefulde taler var DNN'er mindre effektive, og en systemkombination af flere SVM'er med forskellige parametre opnåede de bedste resultater på udviklingssættet, som rangerede 4. i officielle resultater for Underopgave B med F1-makro score på 80,63% på testsættet.", 'nl': "In dit artikel beschrijven we onze inspanningen bij OSACT Shared Task on Offensive Language Detection. De gedeelde taak bestaat uit twee subtaken: aanstootgevende taaldetectie (Subtaak A) en haatspraakdetectie (Subtaak B). Voor aanstootgevende taaldetectie behaalde een systeemcombinatie van Support Vector Machines (SVM's) en Deep Neural Networks (DNN's) de beste resultaten op de ontwikkelingsset, die 1e in de officiële resultaten voor Subtask A met F1-score van 90,51% op de testset scoorde. Voor haatspraakdetectie waren DNN's minder effectief en een systeemcombinatie van meerdere SVM's met verschillende parameters behaalde de beste resultaten op de ontwikkelingsset, die 4e rangschikte in officiële resultaten voor Subtaak B met F1-macroscore van 80,63% op de testset.", 'hr': 'U ovom papiru opisujemo naše napore na OSACT-u zajedničkom zadatku o otkrivanju neposlušnog jezika. Podijeljeni zadatak sastoji se od dva podataka: otkrivanje ofanzivnog jezika (podzadatak A) i otkrivanje govora mržnje (podzadatak B). Za otkrivanje ofanzivnih jezika, kombinacija sustava podrške vektorskih strojeva (SVMs) i dubokih neuronskih mreža (DNN) postigla je najbolji rezultat na setu razvoja, koji je prvi u službenim rezultatima subtask A s rezultatima F1 od 90,51% na testu. Za otkrivanje govora mržnje, DNN-i su bili manje učinkoviti, a sustav kombinacije višestrukih SVM-a s različitim parametrama postigao je najbolji rezultat na setu razvoja, koji je četvrti u službenim rezultatima za Subtask B s ocjenom F1-makro od 80,63% na setu ispitivanja.', 'de': 'In diesem Beitrag beschreiben wir unsere Bemühungen bei OSACT Shared Task on Offensive Language Detection. Die gemeinsame Aufgabe besteht aus zwei Teilaufgaben: Offensive Spracherkennung (Teilaufgabe A) und Hassspracherkennung (Teilaufgabe B). Für die Erkennung offensiver Sprache erzielte eine Systemkombination aus Support Vector Machines (SVMs) und Deep Neural Networks (DNNs) die besten Ergebnisse auf dem Entwicklungsset, der Platz eins in den offiziellen Ergebnissen für Subtask A mit F1-Score von 90,51% auf dem Testset belegt. Für die Erkennung von Hassreden waren DNNs weniger effektiv und eine Systemkombination mehrerer SVMs mit unterschiedlichen Parametern erzielte die besten Ergebnisse im Entwicklungssatz, der in den offiziellen Ergebnissen für Subtask B mit F1-Makro-Score von 80,63% auf dem Testset Platz vier belegte.', 'ko': '본고에서 우리는 OSACT가 공격적인 언어 탐지 임무를 공유하는 데 대한 노력을 묘사했다.공유 임무는 두 개의 하위 임무로 구성되어 있는데 그것이 바로 공격성 언어 검측(하위 임무 A)과 증오 언어 검측(하위 임무 B)이다.공격적 언어 검출의 경우 벡터기(SVM)와 심층신경망(DNN)을 지원하는 시스템 조합이 개발집에서 가장 좋은 결과를 얻어 서브퀘스트 a의 공식 결과 1위, 테스트세트 F1에서 90.51%의 점수를 받았다.DNN은 혐오 음성 감지의 경우 효율성이 낮았고, 개발집에서는 다양한 매개변수를 가진 벡터기 지원 시스템 포트폴리오가 가장 좋은 결과를 얻어 서브퀘스트 B의 공식 결과 4위, 테스트집중 F1 매크로 점수는 80.63%였다.', 'fa': 'در این کاغذ، ما تلاش\u200cهایمان را توصیف می\u200cکنیم در کار مشترک OSACT در مورد شناسایی زبان ناتوانی. وظیفه مشترک از دو زیر سؤال است: شناسایی زبان نافرمانی (Subtask A) و شناسایی سخنرانی ناخوشایند (Subtask B). برای شناسایی زبان فساد، یک ترکیب سیستم دستگاه پشتیبانی ویکتور (SVMs) و شبکه\u200cهای عصبی عمیق (DNN) بهترین نتایج در مجموعه توسعه را به دست آورد، که در نتایج رسمی برای Subtask A درجه ۱ در پایان رسمی در مجموعه آزمایش ۱۹.۵۵ درجه رسید. برای شناسایی سخنرانی از نفرت، DNN ها کمتر موثر بودند و یک ترکیب سیستم چندین SVM با پارامتر مختلف به بهترین نتایج در مجموعه توسعه رسمی رسید که در نتایج رسمی برای Subtask B با امتیاز F1-macro از 80.63 درصد در مجموعه آزمایش رسید.', 'id': 'Dalam kertas ini, kami menjelaskan usaha kami di OSACT Shared Task on Offensive Language Detection. Tugas berbagi terdiri dari dua subtasks: deteksi bahasa offensive (Subtask A) dan deteksi pidato kebencian (Subtask B). Untuk deteksi bahasa yang menyedihkan, kombinasi sistem dari Pembantu Vektor Mesin (SVM) dan Jaringan Neural Dalam (DNN) mencapai hasil terbaik pada set pengembangan, yang ditandai pertama dalam hasil resmi untuk Subtask A dengan skor F1 90,51% pada set tes. Untuk deteksi pidato kebencian, DNN kurang efektif dan kombinasi sistem dari SVM berbilang dengan parameter yang berbeda mencapai hasil terbaik pada set perkembangan, yang ditandai ke-4 dalam hasil resmi untuk Subtask B dengan skor F1-macro 80,63% pada set tes.', 'sw': 'Katika gazeti hili, tunaelezea juhudi zetu katika OSACT Kushirikishwa na Kazi ya Utafiti wa Lugha. Kazi hiyo ya kushirikiana ni pamoja na kazi mbili: Ugunduzi wa lugha ya uchochezi (Ujumbe wa A) na utambuzi wa hotuba za chuki (Ujumbe wa B). Kwa kutambua lugha ya ghasia, mfumo wa muunganiko wa Mashindano ya Kuunga mkono (SVMs) na Mtandao wa Kikuu cha Neural (DNNs) ulifanikiwa matokeo bora zaidi kwenye seti ya maendeleo, ambayo yalikuwa na matokeo ya kwanza ya rasmi ya Ujumbe A yenye vipimo vya F1 asilimia 90.51 kwenye seti ya jaribio. Kwa kutambua hotuba ya chuki, DNN walikuwa na ufanisi mdogo na mfumo wa mfumo wa mfumo wa SVMs mbalimbali wenye parameter tofauti ulifanikiwa kupata matokeo bora ya maendeleo, ambayo yalikuwa na matokeo rasmi ya nne kwa ajili ya Ujumbe B yenye vipimo vya F1 kwa asilimia 80.63 kwenye seti ya jaribio.', 'af': "In hierdie papier beskryf ons versoekte by OSACT Gedeelde Opdrag op Offensive Taal Opdekking. Die gedeelde taak bestaan van twee subtaske: offensive language detection (Subtask A) and hate speech detection (Subtask B). Vir offensivele taal beskrywing, 'n stelsel kombinasie van ondersteun vektor masjiene (SVMs) en Deep Neurale Netwerke (DNN) het die beste resultate op ontwikkelingsstel bereik, wat 1st in die offisiele resultate vir Subtask A met F1- telling van 90. 51% op die toets stel rang. For hate speech detection, DNN was less effective and a system combination of multiple SVMs with different parameters achieved the best results on development set, which ranked 4th in official results for Subtask B with F1- macro score of 80. 63% on the test set.", 'sq': 'Në këtë letër, ne përshkruajmë përpjekjet tona në OSACT Task Shared on Offensive Language Detection. Detyra e përbashkët përbëhet nga dy nëndetyra: zbulimi ofensiv i gjuhës (Subdetyra A) dhe zbulimi i fjalimit të urrejtjes (Subdetyra B). Për zbulimin ofensiv të gjuhës, një kombinim i sistemit të Maquinave Vektorore të Mbështetjes (SVMs) dhe Rrjeteve Neurale të thella (DNNs) arriti rezultatet më të mira në ngritjen e zhvillimit, e cila u rendit e para në rezultatet zyrtare për Subtask A me rezultat F1 prej 90.51% në ngritjen e testit. Për zbulimin e fjalimit të urrejtjes, DNN-të ishin më pak efektive dhe një kombinim i sistemit të SVM-ve të shumta me parametra të ndryshëm arriti rezultatet më të mira në ngritjen e zhvillimit, i cili renditi i katërti në rezultatet zyrtare për Subtask B me rezultat F1-makro 80.63% në ngritjen e testit.', 'tr': "Bu kagyzda, OSACT'iň beýleki dil tapylmagy barada synanyşymyzy tassykladyk. Paýlanan buýrukda iki alt soragy bar: offensive language detection (Subtask A) and hate speech detection (Subtask B). Günahkar diller tapylmak üçin, vektör maşynlaryň (SVMs) we Deep Neural Networks (DNNs) testiň düzümlerinde 1-nji derejä gelen netijede tapyldy. Hat sözlerini tanyşdyrmak üçin, DNN köp sanlaryň etkinji ýok bolup bilen a ýratyn parametrolaryň birleşmesi üçin gelişmäge taýýarlanan düzümlerde iň gowy netijesi başarmady. Bu test düzümlerinde Subtask B üçin resmi netijesi 4-nji derejesi bar we F1-makro अ 80.63% degişli.", 'am': 'በዚህ ፕሮግራም፣ የOSACT የቋንቋ አካባቢ ስራዎችን እናሳውቃለን፡፡ የተካፈሉት ስራ ሁለት ደብዳቤዎች ነው፤ አሰቃፊ ቋንቋ ማግኘት (Subtask A) እና የንግግር ማግኘት ጥል (Subtask B). አሰናፊ ቋንቋ ለማግኘት፣ የድጋፍ መኮንን (SVMs) እና ጥልቅ የኔural መረብ (DNNs) የተጠቃሚ ፍሬዎችን አግኝቷል፡፡ ለጥላቻ ንግግር አግኝቷል፣ DNNs በተለየ ብዙዎች የSVMs እና በተለያዩ parameters የተጠቃሚ የሥርዓት ውጤቶች አግኝተዋል፡፡', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք մեր ջանքերը ՕՍԱԿԹ-ի հանցագործ լեզվի հայտնաբերման գործում: Այս ընդհանուր խնդիրը կազմված է երկու ենթահարցերից. խոսքի հայտնաբերման (ենթախնդիր Ա) և ատելության խոսքի հայտնաբերման (ենթախնդիր Բ): Անցածր լեզուների հայտնաբերման համար Վեկտորային մեքենաների (ՍՀՄ) և Deep Նյարդային ցանցերի (ԴՆՆ) համակարգը հասավ զարգացման լավագույն արդյունքներին, որոնք առաջին անգամ դասակարգվել էին A-ի ենթախնդրի պաշտոնական արդյունքներում, հետևյալ անգամ 90.51 տոկոսով: Վատելու խոսքի հայտնաբերման համար ԴՆԹ-ները ավելի քիչ արդյունավետ էին, և տարբեր պարամետրերով բազմաթիվ ՎԻՄ-ների համակարգը հասավ զարգացման լավագույն արդյունքներին, որոնք 4-րդ դասակարգում էին B-ի ենթախնդրի պաշտոնական արդյունքներում, թեստերի համակարգում F1-մակրո', 'az': 'Bu kağızda, OSACT paylaşılmış dil tapınması barəsində çalışmalarımızı tanımlıyıq. B ölüşdürülən işlər iki dəstədir: offensive language detection (Subtask A) and hate speech detection (Subtask B). Həddi dil keşfetməsi üçün, Sənin A Subtask üçün 1. dəfə səviyyədə F1-score ilə 90.51% dəfə verilmiş Sənin Üstü Vektör Makinelərinin (SVMs) və Deep Neural Networks (DNNs) sistemi birləşdirilməsi üçün ən yaxşı sonuçlarını başa çatdı. Nöqsanlıq sözlərini keşfetmək üçün DNN daha az effektiv idi və müxtəlif parametrlərlə birləşdirilmiş çoxlu SVMs sistemi birləşdirilməsi üçün təhsil quruğunda ən yaxşı sonuçları başa düşdü. Bu test quruğunda F1-makro score 80,63 % olan Subtask B üçün 4-ci dərəcə verilmiş.', 'bn': 'এই পত্রিকায় আমরা ওসাক্ট শেয়ার করা কাজের ব্যাখ্যা করছি অফিসেভ ভাষা ডিটেকশনের উপর। শেয়ার করা কাজের মধ্যে দুটি সাবটাকাজ রয়েছে: আক্রান্ত ভাষা আবিষ্কার (সাবকাজ A) এবং ঘৃণা ভাষণের আবিষ্কার (সাববাস For offensive language detection, a system combination of Support Vector Machines (SVMs) and Deep Neural Networks (DNNs) achieved the best results on development set, which ranked 1st in the official results for Subtask A with F1-score of 90.51% on the test set.  ঘৃণা ভাষণ আবিষ্কারের জন্য ডিএনএন-এর সিস্টেম কম কার্যকর ছিল এবং বিভিন্ন প্যারামিটারের সাথে বিভিন্ন এক সিস্টেম সংযুক্ত একটি সিস্টেমে উন্নয়নের সেরা ফলাফল অর্জন করেছিল, যা পর', 'ca': "In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection.  La tasca compartida consisteix en dues subterrànies: detecció ofensiva de llenguatges (Subtasca A) i detecció de discurs d'odi (Subtasca B). Per la detecció ofensiva de llenguatges, una combinació de sistemes de Suport Vector Machines (SVMs) i Deep Neural Networks (DNNs) va aconseguir els millors resultats en el conjunt de desenvolupament, que va ser la primera en els resultats oficials de la Subtasca A amb puntuació F1 del 90,51% en el conjunt de proves. Per la detecció del discurs d'odi, els DNN eren menys efectius i una combinació sistemàtica de múltiples SVM amb diferents paràmetres va aconseguir els millors resultats en el conjunt de desenvolupament, que es va classificar al quart en els resultats oficials de la Subtasca B amb una puntuació F1-macro del 80,63% en el conjunt de tests.", 'cs': 'V tomto článku popisujeme naše úsilí v OSACT Shared Task on Offensive Language Detection. Sdílený úkol se skládá ze dvou dílčích úkolů: detekce urážlivého jazyka (podúkol A) a detekce nenávistné řeči (podúkol B). Pro detekci útočného jazyka dosáhla systémová kombinace SVM (Support Vector Machines) a hlubokých neuronových sítí (DNN) nejlepších výsledků na vývojové sadě, která byla první v oficiálních výsledcích pro Subtask A s F1 skóre 90,51% na testovací sadě. Pro detekci nenávistné řeči byly DNN méně efektivní a systémová kombinace několika SVM s různými parametry dosáhla nejlepších výsledků na vývojové sadě, která byla čtvrtá na oficiálních výsledcích pro Subtask B s F1 makro skóre 80,63% na testovací sadě.', 'bs': 'U ovom papiru opisujemo naše napore na OSACT-u zajedničkom zadatku o otkrivanju neposlušnog jezika. Podijeljeni zadatak sastoji se od dva podataka: otkrivanje ofanzivnog jezika (podzadatak A) i otkrivanje govora mržnje (podzadatak B). Za otkrivanje ofanzivnih jezika, sistemska kombinacija podrške vektorskih mašin a (SVMs) i dubokih neuronskih mreža (DNN) postigla je najbolji rezultat na setu razvoja, koji je postavio prvi u službenim rezultatima subtask A sa rezultatima F1 od 90,51% na setu testa. Za otkrivanje govora mržnje, DNN su bile manje efikasne, a sistemska kombinacija višestrukih SVM-a sa različitim parametrama postigla je najbolji rezultat na setu razvoja, koji je četvrti u službenim rezultatima za Subtask B s ocjenom F1-makro od 80,63% na setu testova.', 'et': 'Käesolevas dokumendis kirjeldame oma jõupingutusi OSACTi ründava keele tuvastamise jagatud ülesandes. Ühisülesanne koosneb kahest alamülesandest: solvava keele tuvastamine (alamülesanne A) ja vihakõne tuvastamine (alamülesanne B). Ründava keele tuvastamiseks saavutas tugivektori masinate (SVM) ja sügavate närvivõrkude (DNN) süsteemikombinatsioon arenduskomplektis parimad tulemused, mis oli alaülesande A ametlikus tulemuses 1. kohal F1-skooriga 90,51%. Vihakõne tuvastamisel olid DNN-d vähem efektiivsed ja erinevate parameetritega mitme SVM-i süsteemi kombinatsioon saavutas parimad tulemused arenduskomplektis, mis oli alaülesande B ametlikes tulemustes 4. kohal F1-makroskooriga 80,63%.', 'fi': 'Tässä artikkelissa kuvailemme työtämme OSACT Shared Task on Offensive Language Detection -ohjelmassa. Jaettu tehtävä koostuu kahdesta alitehtävästä: loukkaavan kielen tunnistus (alitehtävä A) ja vihapuheen tunnistus (alitehtävä B). Hyökkäävän kielen havaitsemisessa järjestelmäyhdistelmä Support Vector Machines (SVM) ja Deep Neural Networks (DNN) saavutti parhaat tulokset kehitystyössä, joka sijoittui 1. sijalle osatehtävän A virallisissa tuloksissa F1-pisteellä 90,51%. Vihanpuheen havaitsemisessa DNN:t olivat vähemmän tehokkaita ja useiden eri parametrien SVM:ien järjestelmäyhdistelmä saavutti parhaat tulokset kehitystyössä, joka sijoittui neljänneksi osatehtävässä B:ssä F1-makropisteellä 80,63%.', 'jv': 'Nang pemilih iki, kita ngubah njaluk wigatining perkaraan ning SSAKT Kemerdekaan Panjenengan langgambar task politenessoffpolite"), and when there is a change ("assertivepoliteness DNNs', 'sk': 'V tem članku opisujemo naša prizadevanja pri OSACT skupni nalogi za odkrivanje napadalnih jezikov. Skupno opravilo sestavljata dve podnalogi: zaznavanje žaljivega jezika (podnaloga A) in zaznavanje sovražnega govora (podnaloga B). Za ugotavljanje žaljivega jezika je sistemska kombinacija podpornih vektorskih strojev (SVM) in globokih živčnih omrežij (DNN) dosegla najboljše rezultate na razvojnem nizu, ki se je uvrstila na 1. mesto v uradnih rezultatih podnaloge A z rezultatom F1 90,51% na testnem nizu. Pri odkrivanju sovražnega govora so bili DNN manj učinkoviti, sistemska kombinacija več SVM z različnimi parametri pa je dosegla najboljše rezultate na razvojnem nizu, ki se je v uradnih rezultatih za podnalogo B uvrstila na 4. mesto z oceno F1-makro 80,63% na testnem nizu.', 'bo': 'ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་OSACT་དང་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་ནང་དུ་འགྲེལ་བཤད་པ མཉམ་སྤྱོད་ཀྱི་ལས་འགུལ་དུ་བཏུབ་པའི་subtasks་གཉིས་ཡིན། For offensive language detection, a system combination of Support Vector Machines (SVMs) and Deep Neural Networks (DNNs) achieved the best results on development set, which ranked 1st in the official results for Subtask A with F1-score of 90.51% on the test set. For hate speech detection, DNNs were less effective and a system combination of multiple SVMs with different parameters achieved the best results on development set, which ranked 4th in official results for Subtask B with F1-macro score of 80.63% on the test set.', 'ha': "In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection.  Ana haɗa aikin da aka haɗa shi na cikin task õki biyu: zane gane harshen na ƙiyayya (Subaikin A) da kuma gane magana na ƙi (Subaikin B). To, dõmin ganin harshen na ƙiyayya, wata na'ura mai haɗiya na Mataimakin Support (SvM) da Deƙas Neural Networks (DNNs) ya sãmu mafi kyaun matsalari na daidaita na zamanjaji, wanda ya range ta kwance a cikin matsalar mai bayani na Subtash A da F1-score na 90.51% a kan jarraba. Ga ganin magana na ƙi, DNNS sun kasance mafi fasahan aiki kuma wata na'ura mai haɗi da wasu masu SvM da parameteri dabam suka sami mafi kyaun matsalar na ci-danganta, wanda ya ranked 4 na fassarar rasmi ga Subjob B da score F1-macro na 80.63% a kan jarraba.", 'he': 'In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection.  המשימה המשותפת מורכבת משני תת-שאלות: זיהוי שפת פגיעה (תת-משימה A) זיהוי נאום שנאה (תת-משימה B). עבור גילוי שפת פגיעה, שילוב מערכת של מכונות קטורים תמיכה (SVMs) ורשתות נוירוליות עמוקות (Deep Neural Networks - DNNs) השיג את התוצאות הטובות ביותר על קבוצת התפתחות, אשר הגיעה לראשונה בתוצאות הרשמיות של Subtask A עם נקודת F1 של 90.51% על קבוצת הבדיקות. בשביל זיהוי נאום שנאה, DNN היו פחות יעילים ושילוב מערכת של SVMs מרובים עם פרמטרים שונים השיג את התוצאות הטובות ביותר על קבוצת הפיתוח, אשר הצוות ארבע בתוצאות רשמיות עבור Subtask B עם נקודת F1-מקרו של 80.63% על קבוצת הבדיקות.'}
{'en': 'ASU_OPTO at OSACT4-Offensive Language Detection for Arabic text', 'es': 'ASU_OPTO en OSACT4 - Detección de lenguaje ofensivo para texto árabe', 'fr': 'ASU_OPTO at OSACT4 - Détection de langage offensant pour le texte arabe', 'ar': 'ASU_OPTO في OSACT4 - اكتشاف اللغة الهجومية للنص العربي', 'pt': 'ASU_OPTO em OSACT4 - Detecção de idioma ofensivo para texto em árabe', 'ja': 'ASU_OSACT 4のオプト-アラビア語テキストの不快な言語検出', 'zh': 'OSACT4 ASU_OPTO - 阿拉伯语文本犯性语检测', 'hi': 'OSACT4 पर ASU_OPTO - अरबी पाठ के लिए आपत्तिजनक भाषा का पता लगाना', 'ru': 'ASU_OPTO в OSACT4 - Обнаружение оскорбительного языка для арабского текста', 'ga': 'ASU_OPTO ag OSACT4 - Brath Teanga Ionsaitheach le haghaidh téacs Araibis', 'ka': 'Language', 'el': 'Ανίχνευση προσβλητικής γλώσσας για αραβικό κείμενο', 'hu': 'ASU_OPTO at OSACT4 - Támadó nyelv felismerése arab szövegekhez', 'kk': 'OSACT4- дегі ASU_ OPTO - Араб мәтінінің көп тілді анықтау', 'lt': 'ASU_OPTO at OSACT4 - Offensive Language Detection for Arabic text', 'mk': 'ASU_ OPTO на OSACT4 - Детектирање на навреден јазик за арапски текст', 'it': 'ASU_OPTO a OSACT4 - Rilevamento delle lingue offensive per il testo arabo', 'ms': 'ASU_OPTO di OSACT4 - Pengesanan Bahasa Offensif untuk teks Arab', 'mt': "ASU_OPTO f'OSACT4 - Detezzjoni Offensiva tal-Lingwa għat-test Arabu", 'mn': 'OSACT4 дээр ASU_OPTO - Араб текстийн оффицист хэл олж мэдэх', 'ml': 'ASU_OPTO at OSACT4 - Offensive Language Detection for Arabic text', 'pl': 'ASU_OPTO w OSACT4.Ofensywne wykrywanie języka dla tekstu arabskiego', 'no': 'ASU_ OPTO på OSACT4 – Offensive språk- oppdaging for arabisk tekst', 'ro': 'ASU_OPTO la OSACT4 - Detectarea limbii ofensive pentru textul arab', 'sr': 'ASU_ OPTO na OSACT4 - Offensive Language Detection for Arabic text', 'si': 'ASU_ OPTO at OSACT4 - Offensive language Detection for Arab text', 'so': 'ASU_OPTO ee OSACT4 - Gariirka afka Carabiga', 'sv': 'ASU_OPTO på OSACT4 - Offensiv språkupptäckt för arabisk text', 'ta': 'ASU_ OPTO at OSACT4 - அரபி உரைக்கான தனிப்பயன் மொழி கண்டுபிடிப்பு', 'ur': 'OSACT4 پر ASU_ OPTO - عربی پیغام کے لئے اوفنسیو زبان شناسایی', 'uz': 'ASU_ OPTO OSACT4 - Ereb matn uchun foydalanuvchi tilni aniqlash', 'vi': '(ASU OPTO tại OSACT4 - Phát hiện ngôn ngữ rộng cho văn bản Ả rập)', 'bg': 'АСУ_ОПТО в ОСАКТ4 - Откриване на офанзивен език за арабски текст', 'nl': 'ASU_OPTO op OSACT4.Offensieve Taaldetectie voor Arabische tekst', 'hr': 'ASU_ OPTO na OSACT4 - Offensive Language Detection for Arabic text', 'da': 'ASU_OPTO på OSACT4 - Offensiv sprogregistrering for arabisk tekst', 'de': 'ASU_OPTO auf OSACT4 – Offensive Spracherkennung für arabischen Text', 'id': 'ASU_OPTO di OSACT4 - Deteksi Bahasa Offensif untuk teks Arab', 'ko': 'OSACT4의 ASU OPTO - 아랍어 텍스트에 대한 공격적인 언어 감지', 'fa': 'ASU_ OPTO در OSACT4 - شناسایی زبان ناتوان برای متن عربی', 'sw': 'ASU_OPTO kwenye OSACT4 - Utafiti wa lugha kwa ajili ya maandishi ya Kiarabu', 'tr': 'ASU_OPTO OSACT4 -Arapça metin üçin ofisi dil keşif', 'af': 'ASU_ OPTO by OSACT4 - Offensive Language Detection for Arabic text', 'sq': 'ASU_OPTO në OSACT4 - Detektimi ofensiv i gjuhës për tekstin arab', 'am': 'ASU_OPTO በOSACT4 - ምርጫዎች', 'hy': 'Comment', 'az': "OSACT4'də ASU_OPTO - Arapça metinləri üçün çoxlu dil keşif", 'bn': 'OSACT4-এ ASU_OPTO - আরবি লেখার জন্য অফেনসেভ ভাষা সনাক্ত', 'ca': 'ASU_OPTO a OSACT4 - Detecció ofensiva de llenguatges per al text àrab', 'et': 'ASU_OPTO at OSACT4 - Ründav keele tuvastamine araabia tekstile', 'cs': 'ASU_OPTO na OSACT4.Ofensivní detekce jazyka pro arabský text', 'bs': 'ASU_OPTO na OSACT4 - Offensive Language Detection for Arabic text', 'fi': 'ASU_OPTO OSACT4: ssä - hyökkäävä kielen tunnistus arabialaiselle tekstille', 'jv': 'ASU', 'he': 'ASU_ OPTO ב OSACT4 - Detection of Offensive Language for Arabic text', 'sk': 'ASU_OPTO na OSACT4 - Ofenzivno zaznavanje jezika za arabsko besedilo', 'ha': 'KCharselect unicode block name', 'bo': 'ASU_OPTO at OSACT4 - Offensive Language Detection for Arabic text'}
{'en': 'In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage. Having a ', 'ar': 'في السنوات الماضية ، أدت التعليقات السامة والكلام المسيء إلى تلويث الإنترنت وأصبح الفحص اليدوي لهذه التعليقات مهمة مرهقة يجب إدارتها. يعد امتلاك نموذج قائم على التعلم الآلي قادرًا على تصفية المحتوى العربي المسيء أمرًا ضروريًا في الوقت الحاضر. في هذه الورقة ، نصف النموذج الذي تم تقديمه إلى المهمة المشتركة حول اكتشاف اللغة الهجومية التي نظمتها (ورشة العمل الرابعة حول المجلة العربية المفتوحة المصدر وأدوات المعالجة). يستخدم نموذجنا النموذج القائم على المحولات (BERT) لاكتشاف المحتوى المسيء. حصلنا على المركز الرابع في المهمة الفرعية أ (الكشف عن الكلام المسيء) والمركز الثالث في المهمة الفرعية ب (الكشف عن الكلام الذي يحض على الكراهية).', 'es': 'En los últimos años, los comentarios tóxicos y el discurso ofensivo están contaminando Internet y la inspección manual de estos comentarios se está convirtiendo en una tarea tediosa de gestionar. Hoy en día es muy necesario contar con un modelo basado en el aprendizaje automático que sea capaz de filtrar contenido árabe ofensivo. En este artículo, describimos el modelo que se presentó a la tarea compartida sobre detección de lenguaje ofensivo organizada por (The 4th Workshop on Open-Source Arabic Corpus and Processing Tools). Nuestro modelo utiliza el modelo basado en transformadores (BERT) para detectar contenido ofensivo. Quedamos en cuarto lugar en la subtarea A (detectar discurso ofensivo) y en tercer lugar en la subtarea B (detectar discurso de odio).', 'fr': "Au cours des dernières années, les commentaires toxiques et les discours offensants ont pollué Internet et l'inspection manuelle de ces commentaires est devenue une tâche fastidieuse à gérer. Disposer d'un modèle basé sur l'apprentissage automatique capable de filtrer le contenu arabe choquant est un besoin pressant de nos jours. Dans cet article, nous décrivons le modèle qui a été soumis à la tâche partagée sur la détection de langage offensant organisée par (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Notre modèle utilise un modèle basé sur un transformateur (BERT) pour détecter le contenu offensant. Nous sommes arrivés à la quatrième place dans la sous-tâche A (détecter les discours offensants) et à la troisième place dans la sous-tâche B (détecter les discours haineux).", 'pt': 'Nos últimos anos, comentários tóxicos e discursos ofensivos estão poluindo a internet e a inspeção manual desses comentários está se tornando uma tarefa cansativa de gerenciar. Ter um modelo baseado em aprendizado de máquina capaz de filtrar conteúdo árabe ofensivo é uma grande necessidade hoje em dia. Neste artigo, descrevemos o modelo que foi submetido à Tarefa Compartilhada de Detecção de Linguagem Ofensiva que é organizada por (4º Workshop sobre Corpora Árabe de Código Aberto e Ferramentas de Processamento). Nosso modelo faz uso do modelo baseado em transformador (BERT) para detectar conteúdo ofensivo. Ficamos em quarto lugar na subtarefa A (detecção de discurso ofensivo) e em terceiro lugar na subtarefa B (detecção de discurso de ódio).', 'ru': 'В последние годы токсичные комментарии и оскорбительные высказывания загрязняют интернет, и ручная проверка этих комментариев становится утомительной задачей для управления. Наличие модели, основанной на машинном обучении, которая способна фильтровать оскорбительный арабский контент, в настоящее время является острой потребностью. В этой статье мы описываем модель, которая была представлена Общей задаче по обнаружению оскорбительного языка, организованной (4-й семинар по арабским корпорациям с открытым исходным кодом и инструментам обработки). Наша модель использует модель на основе трансформатора (BERT) для обнаружения оскорбительного контента. Мы заняли четвертое место в подзадаче А (обнаружение оскорбительной речи) и третье место в подзадаче Б (обнаружение ненавистнической речи).', 'zh': '在昔数年,毒论冒犯之论方污互联网,其论者方为厌务。 今有可以过漉令人反感者阿拉伯语盖机器学之大体也。 本文,我们述述了提交给(第四届开源阿拉伯语语料库和处理器用研讨会)结的"进攻性言语检测共享"的模样。 吾法用变压器(BERT)以检犯性。 臣等在子职A(检冒犯性言)中第四,在子职B(检仇言)第三。', 'hi': 'पिछले वर्षों में, विषाक्त टिप्पणियां और आक्रामक भाषण इंटरनेट को प्रदूषित कर रहे हैं और इन टिप्पणियों का मैनुअल निरीक्षण प्रबंधन करने के लिए एक थकाऊ काम बन रहा है। एक मशीन लर्निंग आधारित मॉडल होने से जो आक्रामक अरबी सामग्री को फ़िल्टर करने में सक्षम है, आजकल उच्च आवश्यकता है। इस पेपर में, हम उस मॉडल का वर्णन करते हैं जिसे आक्रामक भाषा का पता लगाने पर साझा कार्य में प्रस्तुत किया गया था जो (ओपन-सोर्स अरबी कॉर्पोरेट और प्रोसेसिंग टूल पर 4 वीं कार्यशाला) द्वारा आयोजित किया गया है। हमारा मॉडल आक्रामक सामग्री का पता लगाने के लिए ट्रांसफॉर्मर आधारित मॉडल (BERT) का उपयोग करता है। हम सबटास्क ए (आक्रामक भाषण का पता लगाने) में चौथे स्थान पर और सबटास्क बी (हेट स्पीच का पता लगाने) में तीसरे स्थान पर आए।', 'ja': '過去数年間、有毒なコメントや不快なスピーチがインターネットを汚染しており、これらのコメントの手動検査は管理するのが面倒な作業になりつつあります。不快なアラビア語コンテンツをフィルタリングできる機械学習ベースのモデルを持つことは、今日では非常に必要です。本稿では，が主催するShared Task on Offensive Language Detection （第4回オープンソースのアラビア語コーラと処理ツールのワークショップ）に提出したモデルについて述べる。当社のモデルは、トランスベースのモデル（ BERT ）を使用して不快なコンテンツを検出します。サブタスクA （不快なスピーチの検出）では4位、サブタスクB （ヘイトスピーチの検出）では3位になりました。', 'ga': 'Le blianta beaga anuas, tá tráchtanna tocsaineacha agus cainte maslach ag truailliú an idirlín agus tá iniúchadh láimhe á dhéanamh ar na tuairimí sin ina thasc uafásach. Tá géarghá sa lá atá inniu ann le múnla meaisín-fhoghlaim atá in ann ábhar maslach Araibis a scagadh. Sa pháipéar seo, déanaimid cur síos ar an múnla a cuireadh isteach don Tasc Comhroinnte ar Bhrath Teanga Ionsaitheach atá eagraithe ag (An 4ú Ceardlann ar Chorpóra agus Uirlisí Próiseála Araibis Foinse Oscailte). Úsáideann ár múnla múnla atá bunaithe ar chlaochladán (BERT) chun ábhar maslach a bhrath. Tháinig muid sa cheathrú háit i bhfothasc A (Caint Iontach a bhrath) agus sa tríú háit i bhfothasc B (Fuathchainte a bhrath).', 'hu': 'Az elmúlt években a mérgező megjegyzések és a sértő beszédek szennyezik az internetet, és ezeknek a megjegyzéseknek a manuális ellenőrzése fárasztó feladattá válik. Napjainkban nagy szükség van egy olyan gépi tanuláson alapuló modell, amely képes szűrni a sértő arab tartalmakat. Ebben a tanulmányban bemutatjuk azt a modellt, amelyet a nyílt forráskódú arab korpora és feldolgozó eszközök által szervezett Shared Task on Offensive Language Detection (4. Workshop on Open-Source Arab Corpora and Processing Tools) című munkához nyújtottak be. Modellünk transzformátor alapú modellt (BERT) használ a sértő tartalom észlelésére. A negyedik helyezést értünk el az A (offenzív beszéd felismerése) és a harmadik helyet a B (gyűlölet beszéd felismerése) alfeladatban.', 'el': 'Τα τελευταία χρόνια, τοξικά σχόλια και προσβλητική ομιλία μολύνουν το διαδίκτυο και η χειρωνακτική επιθεώρηση αυτών των σχολίων γίνεται κουραστική εργασία για τη διαχείριση. Η ύπαρξη ενός μοντέλου βασισμένου στη μηχανική μάθηση που είναι σε θέση να φιλτράρει προσβλητικό αραβικό περιεχόμενο είναι υψηλής ανάγκης στις μέρες μας. Στην παρούσα εργασία, περιγράφουμε το μοντέλο που υποβλήθηκε στην Κοινή Εργασία για την Ανίχνευση προσβλητικών Γλωσσών που οργανώνεται από το 4ο Εργαστήριο Αραβικού Σώματος Ανοικτού Κώδικα και Εργαλεία Επεξεργασίας. Το μοντέλο μας χρησιμοποιεί μοντέλο βασισμένο σε μετασχηματιστή για να ανιχνεύσει προσβλητικό περιεχόμενο. Ήρθαμε στην τέταρτη θέση στην υποταγή Α (ανίχνευση προσβλητικής ομιλίας) και στην τρίτη θέση στην υποταγή Β (ανίχνευση της ρητορικής μίσους).', 'lt': 'Pastaraisiais metais toksinės pastabos ir priešiškos kalbos užteršia internet ą, o rankinis šių pastabų patikrinimas tampa nuobodu valdyti. Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays.  In this paper, we describe the model that was submitted to the Shared Task on Offensive Language Detection that is organized by (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools).  Mūsų modelis naudoja transformatoriumi pagrįstą model į (BERT), kad būtų galima nustatyti pažeidžiamąjį turinį. Atėjome ketvirtoje vietoje A poskyryje (nuobaudos kalbos aptikimas) ir trečioje vietoje B poskyryje (neapykantos kalbos aptikimas).', 'ka': 'ბოლო წლის შემდეგ ტოქსიკური კომენტრები და სატანციური სიტყვა ინტერნეტის და მანქანური ინსპექცია ამ კომენტრების შესახებ იქნება დარწმუნებელი რაოდენობა. მაქინის სწავლების მოდელი, რომელიც შეუძლია ფილტრუქტირება აპაბიური შემდგომარების შემდგომარება, ახლა უფრო მეტი უნდა იყოს. ამ დოკუნში ჩვენ აღწერეთ მოდელს, რომელიც აღწერა საზოგადომი ენის განსახულებაზე, რომელიც ორგანიზაციულია (4-ი სამუშაო სამუშაო აპაბიური კორპორაზე და პროცესი ხელსაწყო ჩვენი მოდელი გამოყენება ტრანფორმეტრის ბაზეული მოდელი (BERT) სხვადასხვა შესახებ. ჩვენ მეოთხედი ადგილი A-ში მოვიყენეთ (საუკეთესო საუკეთესო სიტყვა) და მესამე ადგილი B-ში (საუკეთესო საუკეთესო საუკეთესო საუკეთესო სიტ', 'it': "Negli ultimi anni, commenti tossici e discorsi offensivi stanno inquinando Internet e l'ispezione manuale di questi commenti sta diventando un compito faticoso da gestire. Avere un modello basato sull'apprendimento automatico in grado di filtrare contenuti arabi offensivi è oggi di grande bisogno. In questo articolo, descriviamo il modello che è stato presentato al Task Condiviso sul rilevamento del linguaggio offensivo organizzato da (Il 4 ° Workshop su Open Source Arabic Corpora e Strumenti di elaborazione). Il nostro modello utilizza il modello basato su trasformatori (BERT) per rilevare contenuti offensivi. Siamo arrivati al quarto posto nel sottotask A (detecting Offensive Speech) e al terzo posto nel sottotask B (detecting Hate Speech).", 'ms': 'Dalam tahun-tahun terakhir, ulasan beracun dan ucapan yang menyerang mencemarkan internet dan pemeriksaan manual ulasan ini menjadi tugas yang membosankan untuk mengendalikan. Memiliki model berasaskan pembelajaran mesin yang mampu menapis kandungan Arab yang menyerang diperlukan pada hari ini. Dalam kertas ini, kami menggambarkan model yang dihantar kepada Tugas Berkongsi untuk Pengesanan Bahasa Tersinggung yang diatur oleh (Workshop Keempat tentang Korpora Arab Sumber terbuka dan Alat Pemprosesan). Model kami menggunakan model berasaskan pengubah (BERT) untuk mengesan kandungan serangan. Kami datang ke tempat keempat dalam subtitle A dan di tempat ketiga dalam subtitle B.', 'mk': 'Во изминатите години, токсичните коментари и офанзивниот говор го загадуваат интернетот и рачната инспекција на овие коментари станува досадна задача за управување. Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays.  Во овој весник, го опишуваме моделот кој беше поднесен на Делената задача за детекција на навредлив јазик, организирана од (Четвртиот работилник за отворен извор арапска корпора и алатки за процес). Нашиот модел го користи моделот базиран на трансформатор (BERT) за да открие навредна содржина. Дојдовме на четвртото место во подпрашањето А и на трето место во подпрашањето Б.', 'kk': 'Соңғы жылдар бойынша, қарсы түсініктемелер мен қарсы сөйлемелер Интернет және қолмен бұл түсініктемелерді тексеру үшін қатты тапсырма болады. Араб мазмұнын сүзгілей алатын машинаның негізделген үлгісі бар, бұл күні үлкен керек. Бұл қағазда біз ортақтастырылған тапсырмасына ортақтастырылған тапсырманы (Араб-көзі корпора және процессорлау құралдарындағы 4- ші жұмыс істеу үшін) анықтадық. Біздің үлгіміз қарсы мазмұнын анықтау үшін түрлендіруші негізделген үлгісін (BERT) қолданады. Біз төртінші жерде A суретінде (официалдық сөйлі анықтау) және B суретінде үшінші жерде келдік.', 'ml': 'കഴിഞ്ഞ വര്\u200dഷങ്ങളില്\u200d, വിഷമവാക്കുകളും പ്രശ്നവാക്കുകളും ഇന്റര്\u200dനെറ്റില്\u200d അശുദ്ധമാക്കുകയാണ്. ഈ കണക്കുകളുടെ കൈകാര്യം പരിശോധിക മെഷീന്\u200d പഠിക്കുന്നതിന്റെ അടിസ്ഥാനമായ ഒരു മോഡല്\u200d ഉണ്ടായി ഈ പത്രത്തില്\u200d നമ്മള്\u200d പങ്കുചേര്\u200dത്ത ടാസ്കിന് കീഴ്പെടുത്തിയ മോഡല്\u200d വിശദീകരിക്കുന്നു (തുറന്ന സ്രോതസ്സോര്\u200dസ്സ് അറബി കോര്\u200dപ്പോരിയും പ്രൊ നമ്മുടെ മോഡല്\u200d മാറ്റുന്നതിന്റെ അടിസ്ഥാനമായ മോഡല്\u200d (BERT) ഉപയോഗിക്കുന്നത് ആക്രമിക്കുന്ന ഉള്ളടക്കം  We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).', 'mt': 'In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage.  Illum il-ġurnata jeħtieġ ħafna mudell ibbażat fuq it-tagħlim tal-magni li jkun jista’ jiffiltra l-kontenut arabu offensiv. F’dan id-dokument, aħna niddeskrivu l-mudell li ġie ppreżentat lill-Kompitu Konġunt dwar id-Detezzjoni tal-Lingwi Offensivi li huwa organizzat minn (Ir-Raba’ Workshop dwar il-Korpora Għarbija ta’ Sors Miftuħ u l-Għodod ta’ Proċessar). Il-mudell tagħna jagħmel użu minn mudell ibbażat fuq it-trasformatur (BERT) biex jinstab kontenut ofensiv. A ħna daħlu fir-raba’ post fis-sottomistoqsija A (detezzjoni ta’ Speech Offensive) u fit-tielet post fis-sottomistoqsija B (detezzjoni ta’ Speech ta’ mibegħda).', 'no': 'I løpet av dei siste årene er toksiske kommentarar og offensiv tale som forstørrar Internett og manuelt inspeksjon av desse kommentarane blir ein utrygt oppgåve å handtera. Å ha ein maskinelæringsbasert modell som kan filtrera offensiv arabisk innhald i dag har høg treng. I denne papiret beskriver vi modellen som er sendt til den delte oppgåva om offensive språk- oppdaging som er organisert av (4. arbeidsområdet på opne- kildekode arabiske korpora og handlingsverktøya). Modellen vårt gjer bruk av transformeringsbasert modell (BERT) for å finna offensivinnhald. Vi kom på den fjerde plassen i subtspørjinga A (oppdaging ofensive språk) og på den tredje plassen i subtspørjinga B (oppdaging av hatspråk).', 'pl': 'W ostatnich latach toksyczne komentarze i obraźliwe mowy zanieczyszczają internet, a ręczna kontrola tych komentarzy staje się męczącym zadaniem do zarządzania. Posiadanie modelu opartego na uczeniu maszynowym, który jest w stanie filtrować obraźliwe treści arabskie jest obecnie bardzo potrzebne. W niniejszym artykule opisujemy model, który został przesłany do wspólnego zadania dotyczącego wykrywania języków ofensywnych organizowanego przez (IV Warsztaty Open-Source Arabic Corpora and Processing Tools). Nasz model wykorzystuje model oparty na transformatorze (BERT) do wykrywania obraźliwych treści. Zajęliśmy czwartym miejscem w podzadaniu A (wykrywanie mowy obraźnej) i trzecim miejscu w podzadaniu B (wykrywanie mowy nienawiści).', 'ro': 'În ultimii ani, comentariile toxice și discursul ofensator poluează internetul, iar inspecția manuală a acestor comentarii devine o sarcină obositoare de gestionat. A avea un model bazat pe învățare automată care este capabil să filtreze conținutul arab ofensator este de mare nevoie în zilele noastre. În această lucrare, descriem modelul care a fost prezentat la Activitatea partajată privind detectarea limbajului ofensiv organizată de (Cel de-al patrulea Workshop privind corporele arabe open-source și instrumentele de procesare). Modelul nostru utilizează modelul bazat pe transformator (BERT) pentru a detecta conținutul ofensator. Am ajuns pe locul patru în subactivitatea A (detectarea discursului ofensiv) și pe locul trei în subactivitatea B (detectarea discursului de ură).', 'mn': 'Өнгөрсөн жилийн дотор хохиромжтой сэтгэл хөдлөл болон буруу илтгэл интернет болон эдгээр сэтгэл хөдлөлийн шалгалт нь удирдах зорилготой ажил болж байна. Машин суралцах сургалтын загвар байх нь өнөөдөр Араб хэмжээсүүдийг шинжилж чадна. Энэ цаасан дээр бид зохион байгуулагдсан Хүмүүсийн Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Холбооны Бидний загвар нь шилжүүлэгчийн суурь загварыг (BERT) ашигладаг. Бид 4 дахь талаар А-н дотор (нээлттэй яриаг олох) болон 3 дахь талаар B-н дотор ирсэн.', 'sr': 'U proteklih godina, toksični komentari i ofanzivni govor zagađuju internet i ručnu inspekciju ovih komentara postaje umorna zadatak za upravljanje. Imati model na osnovu učenja mašine koji može filtrirati ofanzivni arapski sadržaj danas ima visoke potrebe. U ovom papiru opisujemo model koji je podignut zajedničkom zadatku o otkrivanju službenog jezika koji je organizovan od strane (4. radionica na otvorenom izvoru arabske korpore i alata za procesiranje). Naš model koristi transformator-bazirani model (BERT) da bi otkrio uvredljiv sadržaj. Došli smo na četvrto mesto na podpitanju A (otkrivanje neposlušnog govora) i na trećem mestu na podpitanju B (otkrivanje govora mržnje).', 'si': 'අන්තිම අවුරුද්දු වලින්, වික්\u200dරීය කිරීමක් සහ වික්\u200dරීය කතා කරනවා අන්තර්ජාලය සහ මේ කිරීමක් පරීක්ෂණයක් ප්\u200dරධානය කරන්න මෙචින් ඉගෙන ඉගෙන ඉගෙන ඉගෙනීමේ මොඩල් එකක් තියෙන්න පුළුවන් අරාබික් සාමාන්ත්\u200dරයක් පරික්ෂා කරන මේ පත්තරේ අපි විස්තර කරනවා මොඩේල් එක, සාමාන්\u200dය භාෂාව හොයාගන්න පුළුවන් භාෂාව සඳහා සැකසුම් කරලා තියෙන්නේ මොඩේල් අපේ මදුල්ය ප්\u200dරවේශකය අධාරිත මදුල්ය (BERT) භාවිත කරන්න ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්න. අපි හතරවෙනි ස්ථානයෙන් ඇවිත් A සබ්ප්\u200dරශ්නයෙන් (ප්\u200dරශ්නයක් පරික්ෂා කරනවා) හා තුන්වෙනි ස්ථානයෙන් B සබ්ප්\u200d', 'so': 'Sannadihii soo dhaafay, kommentaha maandooriyaha iyo hadalka caafimaadka ah ayaa nijaasaynaya internetka iyo baaritaanka arrimahan manual ah waxay noqotaa shaqo dhib leh oo la maamulo. Maanta waxaa loo baahan yahay tusaale waxbarasho aasaasi ah, kaas oo awoodi kara inuu filtereeyo waxyaabaha afka Carabiga ah oo caadi ah. Kanu warqadan ayaannu ku qoraynaa modelkii loo dhiibay Shaqada la sharciyey oo la sameeyay Gargaarka afka Offensive ah (The 4th Workshop on Open Source Carabi Corpora iyo Processing Tools). Tusaalkayaga ayaa isticmaalaya qaababka bedelka (BERT) si uu u ogaado waxyaabaha dhibka ah. Meeshii afraadna waxaynu ku nimid subaxda A (aqoonsiga afka hore) iyo meeshii saddexaad oo ku taal subaxda B (cadowga hadalka nebcaada).', 'sv': 'Under de senaste åren har giftiga kommentarer och stötande tal förorenat internet och manuell inspektion av dessa kommentarer blivit en tröttsam uppgift att hantera. Att ha en maskininlärningsbaserad modell som kan filtrera stötande arabiskt innehåll är av stort behov nuförtiden. I denna uppsats beskriver vi den modell som lämnades in till Shared Task on Offensive Language Detection som organiseras av (The 4e Workshop on Open Source Arabic Corpora and Processing Tools). Vår modell använder transformatorbaserad modell (BERT) för att upptäcka stötande innehåll. Vi kom på fjärde plats i subaktivitet A (detektering av offensivt tal) och på tredje plats i subaktivitet B (detektering av hattal).', 'ta': 'கடந்த ஆண்டுகளில், பாதிப்பு குறிப்புகள் மற்றும் தீவிரமான பேச்சு இணையத்தைத் தூய்மையாக்குகிறது மற்றும் இந்த குறிப்புகள் கைம ஒரு இயந்திரம் கற்றல் மாதிரி இருக்கும் அது தற்போது உயர்ந்த தேவையான அரபி உள்ளடக்கங்களை வடிகட்டி செய்ய முடியும். இந்த காக்கியத்தில், நாம் பங்கிட்ட பணிக்கு கொடுக்கப்பட்ட மாதிரியை விவரிக்கிறோம். அது நிறுவப்பட்ட மொழி கண்டுபிடிப்பு மீது (திறந்த மூலத்தில்  எங்கள் மாதிரி மாற்றம் அடிப்படையில் உள்ள மாதிரியை கண்டறிய பயன்படுத்துகிறது. நாங்கள் நான்காவது இடத்தில் வந்தோம் A (பேச்சை கண்டுபிடிக்க) மற்றும் மூன்றாவது இடத்தில் B துணை பணியில் (வெறுப்பு பேச்சை', 'ur': 'گزشتہ سالوں میں، سم کی توضیح اور فساد کی باتیں اینٹرنیٹ اور ان توضیح کے مطابق مطابق مطابق کر رہی ہیں کہ ان کی مدد کرنے کے لئے ایک خستگی کا کام ہو جاتا ہے. ایک ماشین کی تعلیم کی بنیادی موڈل ہے جو آج کے دن فانسی عربی موتوں کو فیلٹر کر سکتا ہے۔ اس کاغذ میں ہم نے موڈل کی توصیح دی ہے جس کی شریعت کی زبان شناسایی کے ذریعہ شریعت کی تابع کی گئی تھی (اوپن-سورس عربی کورپور اور پرس\u200cرسینگ ابزار پر چوتھا کارشاپ ہے)۔ ہمارا موڈل تبدیل کرنے والے بنیادی موڈل (BERT) کو فساد منصفات کا شناسایا کرنے کے لئے استعمال کرتا ہے۔ ہم چوتھی جگہ پر آئے ہیں A اور تیسری جگہ B میں', 'uz': "Oldingi yillarda, toksisk izohlar va harakat fikrlar Internetni o'zgartiradi va bu izohlarni qoʻlbola'llab qo'lbola'ylab boshqarish uchun harakat qiladi. Bunday hozir o'rganish asosiy modeli bo'lgan bir ko'pchilik arab tarkibini filterlash mumkin. Bu hujjatda, biz tashkilotni tashkilotga qoʻllanilgan foydalanuvchi modelni ko'rinamiz (Oʻrnatilgan arab Korpora va jarayon vositalarning 4- chi ish stoli). Our model makes use transformer based model (BERT) to detect offensive content.  Biz 4 tomondan o'zida o'zida o'rganish va 3 marta boshqa B'ni o'rganish.", 'vi': 'Trong những năm qua, những nhận xét độc hại và những lời phát biểu khiêu khích đang làm ô nhiễm internet và việc kiểm tra bằng tay những nhận xét này đang trở thành một nhiệm vụ khó khăn. Bây giờ, có một mô hình dựa trên việc học máy có khả năng lọc nội dung tấn công của A Rập là rất cần thiết. Trong tờ giấy này, chúng tôi mô tả mô hình đã được gửi cho "Tập đoàn Điều tra Ngôn ngữ Hành động" được tổ chức bởi "Bài tập thứ tư về Tập đoàn A Rập Mở Nguồn và Công cụ Xử Lý." Mẫu này dùng phương pháp chuyển thế dựa (BERT) để phát hiện nội dung tấn công. Chúng tôi đến vị trí thứ tư theo mức A (phát hiện Hạ giá) và ở vị trí thứ ba trong phần B (phát hiện ngôn ngữ ghét).', 'bg': 'През последните години токсичните коментари и обидните речи замърсяват интернет и ръчната проверка на тези коментари се превръща в уморителна задача за управление. Имането на модел базиран на машинно обучение, който е в състояние да филтрира обидно арабско съдържание е от голяма нужда в днешно време. В настоящата статия описваме модела, който е представен на споделената задача за откриване на офанзивен език, организирана от (Четвъртата работна среща по арабски корпора с отворен код и инструменти за обработка). Нашият модел използва трансформаторен модел за откриване на обидно съдържание. Дойдохме на четвърто място в подзадача А (откриване на обидна реч) и на трето място в подзадача Б (откриване на реч на омраза).', 'nl': 'In de afgelopen jaren vervuilen giftige reacties en aanstootgevende uitspraken het internet en handmatige inspectie van deze opmerkingen wordt een vermoeiende taak om te beheren. Het hebben van een machine learning gebaseerd model dat aanstootgevende Arabische inhoud kan filteren is tegenwoordig van grote behoefte. In dit artikel beschrijven we het model dat is ingediend bij de Shared Task on Offensive Language Detection die wordt georganiseerd door (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Ons model maakt gebruik van transformator based model (BERT) om aanstootgevende inhoud te detecteren. We kwamen op de vierde plaats in subtaak A (detecteren van offensieve spraak) en op de derde plaats in subtaak B (detecteren van haatspraak).', 'da': 'I de seneste år forurener giftige kommentarer og stødende tale internettet, og manuel inspektion af disse kommentarer er blevet en trættende opgave at håndtere. At have en maskinlæringsbaseret model, der er i stand til at filtrere stødende arabisk indhold, er et stort behov i dag. I denne artikel beskriver vi den model, der blev indsendt til Shared Task on Offensive Language Detection, der er organiseret af (The 4th Workshop on Open Source Arabic Corpora and Processing Tools). Vores model bruger transformer baseret model (BERT) til at registrere stødende indhold. Vi kom på fjerdepladsen i underopgave A (detektering af offensiv tale) og på tredje pladsen i underopgave B (detektering af had tale).', 'hr': 'U proteklih godina, toksični komentari i ofanzivni govor zagađuju internet i ručnu inspekciju tih komentara postaje umoran zadatak za upravljanje. Imati model na osnovu učenja strojeva koji može filtrirati ofanzivni arapski sadržaj danas ima visoke potrebe. U ovom papiru opisujemo model koji je podignut zajedničkom zadatku o otkrivanju neposlušnog jezika koji je organiziran od strane (4. radionica na otvorenom izvoru arabske korpore i alata za obradu). Naš model koristi transformator-bazirani model (BERT) za otkrivanje ofanzivnog sadržaja. Došli smo na četvrto mjesto na podpitanju A (otkrivanje neposlušnog govora) i na trećem mjestu na podpitanju B (otkrivanje govora mržnje).', 'de': 'In den letzten Jahren verschmutzen giftige Kommentare und beleidigende Reden das Internet und die manuelle Überprüfung dieser Kommentare wird zu einer mühsamen Aufgabe. Ein auf maschinellem Lernen basierendes Modell, das anstößige arabische Inhalte filtern kann, ist heutzutage dringend erforderlich. In diesem Beitrag beschreiben wir das Modell, das der Shared Task on Offensive Language Detection (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools) vorgelegt wurde. Unser Modell nutzt Transformator Based Model (BERT), um anstößige Inhalte zu erkennen. Wir kamen auf den vierten Platz in Teilaufgabe A (Erkennung offensiver Sprache) und auf den dritten Platz in Teilaufgabe B (Erkennung von Hassrede).', 'ko': '지난 몇 년 동안 유독 평론과 공격적인 언론이 인터넷을 오염시키고 있으며 수동으로 이 평론을 검사하는 것은 번거로운 관리 임무가 되고 있다.오늘날 사람들은 공격적인 아랍어 내용을 필터하기 위해 기계 학습 모델을 기반으로 하는 것이 절실하다.본고에서 우리는 제4회 개원 아랍어 어료 라이브러리와 처리 도구 세미나에 제출된 공격적 언어 검측 공유 임무의 모델을 묘사했다.우리 모델은 변압기 기반 모델(BERT)을 사용하여 공격적인 내용을 감지합니다.우리는 서브퀘스트 A(공격성 발언 검출) 4위, 서브퀘스트 B(헤이트 스피치 검출) 3위에 올랐다.', 'id': 'Selama bertahun-tahun terakhir, komentar racun dan pidato yang menyerang mencemari internet dan inspeksi manual komentar ini menjadi tugas yang membosankan untuk mengelola. Memiliki model pembelajaran mesin yang mampu mengisi isi Arab yang menyerang adalah kebutuhan yang tinggi saat ini. Dalam kertas ini, kami menggambarkan model yang dikirim ke Tugas Bergabung untuk Deteksi Bahasa Tersinggung yang diatur oleh (Workshop Keempat tentang Korpora Arab Sumber terbuka dan Alat Proses). Model kami membuat menggunakan model berdasarkan transformer (BERT) untuk mendeteksi konten offensive. Kami datang ke tempat keempat dalam subtask A dan di tempat ketiga dalam subtask B.', 'fa': 'در سال های گذشته، توضیح سمی و سخنرانی ناراحتی دارند که اینترنت را آلوده می کنند و تحقیق دستی از این توضیح ها به یک کار خسته کننده برای مدیریت می شود. با مدل یادگیری از ماشین که می تواند محتوای عربی نافرمانی را فیلتر دهد، امروز نیازهای زیادی دارد. در این کاغذ، ما مدل مشخص می\u200cکنیم که به کارهای مشترک در مورد شناسایی زبان فزونی که توسط آن سازمان می\u200cشود (کارگاه چهارمین روزنامه\u200cی کاغذ\u200cهای باز-منبع عربی و برنامه\u200cهای پردازی) فرستاده شده است. مدل ما از مدل تغییر دهنده (BERT) استفاده می\u200cکند تا محتوای تجاوز را شناسایی کند. ما در چهارمین مکان در پاسپرس A و در سوم مکان در پاسپرس B آمدیم.', 'sw': 'Katika miaka iliyopita, maoni na hotuba ya kisaikolojia yanachafua mtandao wa intaneti na kuchunguza maoni haya kwa manufaa yanakuwa kazi yenye kuchoka kusimamia. Kuwa na mfumo wa kujifunza mashine ambao unaweza kuchuja maudhui yanayodhalilisha Kiarabu ni muhimu sana leo. Katika karatasi hii, tunaelezea modeli iliyotolewa kwenye kazi ya Kuchunguza Lugha zilizoshirikishwa (Warsha ya 4 kwenye makampuni ya Kiarabu na Vifaa vya Uchunguzi). Mfano wetu unatumia mifano ya mabadiliko yenye msingi wa mabadiliko (BERT) ili kutambua maudhui ya uchochezi. Tulikuja katika nafasi ya nne katika kazi ya A (Kugundua Hotuba ya Uhuru) na katika nafasi ya tatu katika kazi ya B (Kugundua Hotuba ya Hati).', 'tr': 'Geçen ýyllarda, toksyz terjimeler we alçak sözleri internetden bejerýär we bu terjimeleriň el barlagyny özüne gözlemek üçin gaty kynçylyk bir görevi bolýar. Makine öwrenmek nusgasy bar we bu günlerde häzirki arapça maglumaty filtrup biler. Bu kagyzda, biz daş dili tapylyşynyň (Aç-Kaynaklı Arapça Korpora we işleýän Esbaplar barada 4-nji Çalışma Mody) tarapynda bellenilýäris. Biziň nusgamyz hilli faýllary açmak üçin transformer nusgasyny ulanýar. Biz dördünji ýerde A subtitlerde geldik (Offensive Speech Detension) we 3-nji ýerde B subtitlerde geldik (nefret sözlerini detension).', 'af': "In die verlede jaar word toksiske kommentaar en offensivele spreek verontheilig die internette en handbokinspeksie van hierdie kommentaar word 'n verdambare taak om te bestuur. Het 'n masjien leer gebaseerde model wat vandag kan filtereer ofsinsiewe Arabiese inhoud is van hoë nodig. In hierdie papier, beskrywe ons die model wat aan die Gedeelde Opdrag op Offensive Taal Opdekking ingestuur is wat deur (die 4de Werkskerm op Open-Source Arabic Corpora en Processing Tools organiseer word). Ons model maak gebruik transformeerder gebaseerde model (BERT) om offensive inhoud te ontdek. Ons het in die vierde plek gekom in subvraag A (ondersoek Offensive Speech) en in die derde plek in subvraag B (ondersoek Hate Speech).", 'sq': 'Në vitet e fundit, komentet toksike dhe fjalimi ofensiv po ndotin internetin dhe inspektimi manual i këtyre komenteve po bëhet një detyrë e lodhshme për të menaxhuar. Të kesh një model të bazuar në mësimin e makinave që është në gjendje të filtrojë përmbajtjen ofensive arabe është me nevojë të lartë sot. Në këtë letër, ne përshkruajmë modelin që u paraqit në Detyrën e Përbashkët për Detektimin e Gjuhave Ofensive që është organizuar nga (Workshop i katërt mbi Korpora Arabe me burim të hapur dhe Mjet e Procesimit). Our model makes use transformer based model (BERT) to detect offensive content.  Erdhëm në vendin e katërt në nënpyetjen A dhe në vendin e tretë në nënpyetjen B.', 'am': 'ባለፉት ዓመታት፣ የስካር ትርጉም እና አሰናክሎ ንግግር የኢንተርኔት እና እነዚህን አስተያየት የመቆጣጠር ድካም ሆኖአል፡፡ በዓረብኛ አረቢያ ተቃውሞ የሚችል መሣሪያን የሚማር ምሳሌ አለበት፡፡ በዚህ ገጽ ላይ የተሰናከረውን የቋንቋ ስራ ላይ የተሰራጨውን ሞዴል እናሳውቃለን፡፡ ሞዴሌያችን የተቃወመ የውጤት ምሳሌ (BERT) ለማግኘት ነው፡፡ በአራተኛውም ስፍራ አ (የቋንቋ ቋንቋን አግኝተን) በሦስተኛውም ቦታ የጥል ንግግርን አግኝተን መጣን።', 'az': 'Geçmiş illərdə, zehirli şəkillər və təkəbbürlü sözlər interneti təmizləyir və bu şəkillərin əlində təşkil edilməsi üçün yorğun bir iş olar. İnşallah ərəb məlumatını filtrləyə bilən maşına öyrənmək modeli olaraq bu gün yüksək ihtiyacı var. Bu kağızda, açıq-Kaynak Arab Korpora və işləmə vasitələri barəsində müəyyən edilən paylaşılmış dil keşfetməsi üçün göndərilən modeli tarif edirik. Bizim modellərimiz həddi aşmaq üçün transformer tabanlı modelləri (BERT) istifadə edir. Biz dördüncü yerdə A subtask içində və üçüncü yerdə B subtask içində gəldik.', 'hy': 'Անցյալ տարիների ընթացքում թունավոր մեկնաբանությունները և գայթակղիչ խոսքերը աղտոտում են ինտերնետը, և այս մեկնաբանությունների ձեռքի վերահսկումը դառնում է հոգնեցնող առաջադրանք կառավարելու համար: Having a machine learning based model that is able to filter offensive Arabic content is of high need nowadays.  Այս թղթի մեջ մենք նկարագրում ենք մոդելը, որը ներկայացվել է Ավնասավոր լեզվի հայտնաբերման ընդհանուր առաջադրանքին, որը կազմակերպված է (Արաբական կորպորայի և գործիքների չորրորդ աշխատասենյակում): Մեր մոդելը օգտագործում է վերափոխողի հիմնված մոդելը (BER-ը), որպեսզի հայտնաբերի գայթակղիչ պարունակությունը: Մենք եկել ենք չորրորդ տեղում A-ի ենթահարցում և երրորդ տեղում B-ի ենթահարցում:', 'bn': 'বিগত বছরে ব্যস্ত মন্তব্য এবং আক্রমণের বাক্য ইন্টারনেট দূষণ করছে এবং এই মন্তব্যের নিয়ন্ত্রণের ক্লান্তিকর কাজ পরীক্ষা হচ্ছে। মেশিনের ভিত্তিক মডেল থাকতে পারে যা আক্রমণের আরবী বিষয়বস্তু ফিল্টার করতে পারে তা এখন উচ্চ প্রয়োজন। এই পত্রিকায় আমরা এই মডেলের বর্ণনা করি যে মডেল প্রদান করা হয়েছিল অফেন্সিভ ভাষা ডিটিটিউটিশনের কাজে (উন্মুক্ত সোর্স আরবী কর্পোরা এবং প্রক্রিয়া টুলের ৪ আমাদের মডেল ব্যবহার করে আক্রমণের বিষয়বস্তু সনাক্ত করতে ব্যবহার করে। আমরা চারটি স্থানে এসেছি সাবকাজ A (অফিসেন্টিভ ভ ভাষাকে খুঁজে পাচ্ছি) এবং তৃতীয় স্থানে (ঘৃণা ভাষণ খুঁজে পাচ্ছি)।', 'bs': 'U proteklih godina, toksični komentari i ofanzivni govor zagađuju internet i ručnu inspekciju tih komentara postaje umorna zadatak za upravljanje. Imati model na osnovu učenja strojeva koji može filtrirati ofanzivni arapski sadržaj danas ima visoke potrebe. U ovom papiru opisujemo model koji je podignut zajedničkom zadatku o otkrivanju neposlušnog jezika koji je organizovan od strane (4. radionica na otvorenom izvoru arabske korpore i alata za obradu). Naš model koristi transformator-bazirani model (BERT) za otkrivanje napadajućeg sadržaja. Došli smo na četvrto mjesto na podpitanju A (otkrivanje neposlušnog govora) i na trećem mjestu na podpitanju B (otkrivanje govora mržnje).', 'ca': "En els últims anys, comentaris tòxics i discurs ofensius estan contaminant internet i la inspecció manual d'aquests comentaris s'està convertint en una tasca cansativa de gestionar. Tenir un model basat en aprenentatge màquinari capaç de filtrar continguts àrabs ofensius és de gran necessitat avui en dia. En aquest article, descrivim el model que va ser submetit a la Task Shared on Offensive Language Detection organitzada per (La 4ª Workshop on Open-Source Arabic Corpora and Processing Tools). El nostre model fa servir un model basat en transformadors (BERT) per detectar continguts ofensius. Vam arribar al quart lloc a la subtanya A (detecció de discurs ofensius) i al tercer lloc a la subtanya B (detecció de discurs d'odi).", 'et': 'Viimastel aastatel saastavad mürgised kommentaarid ja solvav kõne interneti ning nende kommentaaride käsitsi kontrollimine on muutumas väsitavaks ülesandeks. Masinõppel põhinev mudel, mis suudab filtreerida solvavat araabia sisu, on tänapäeval väga vajalik. Käesolevas töös kirjeldame mudelit, mis esitati ründava keele tuvastamise jagatud ülesandele (4. avatud lähtekoodiga araabia korporatsiooni ja töötlemisvahendite seminar). Meie mudel kasutab trafopõhist mudelit (BERT) solvava sisu tuvastamiseks. Me jõudsime neljandale kohale alamülesandes A (ründava kõne tuvastamine) ja kolmandale kohale alamülesandes B (vihkamise kõne tuvastamine).', 'cs': 'V posledních letech toxické komentáře a urážlivé řeči znečišťují internet a manuální kontrola těchto komentářů se stává únavným úkolem, který je třeba zvládnout. Mít model založený na strojovém učení, který je schopen filtrovat urážlivý arabský obsah, je v dnešní době velmi potřebný. V tomto článku popisujeme model, který byl předložen do Shared Task on Offensive Language Detection, který organizuje (4th Workshop on Open-Source Arabic Corpora and Processing Tools). Náš model využívá transformátorový model (BERT) k detekci urážlivého obsahu. Na čtvrtém místě jsme se dostali v podúkolu A (detekce útočné řeči) a na třetím místě v podúkolu B (detekce nenávistné řeči).', 'fi': 'Viime vuosina myrkylliset kommentit ja loukkaava puhe ovat saastuttaneet internetiä, ja näiden kommenttien manuaalisesta tarkastuksesta on tulossa väsyttävä tehtävä hallita. Koneoppimiseen perustuva malli, joka pystyy suodattamaan loukkaavaa arabialaista sisältöä, on nykyään erittäin tarpeellinen. Tässä artikkelissa kuvailemme mallia, joka lähetettiin Shared Task on Offensive Language Detection -ohjelmaan (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Mallimme käyttää muuntajapohjaista mallia (BERT) loukkaavan sisällön havaitsemiseen. Olimme neljännellä sijalla alatehtävässä A (loukkaavan puheen havaitseminen) ja kolmannella sijalla alatehtävässä B (vihapuheen havaitseminen).', 'ha': "A cikin wasu shẽkar da aka shige, mawaɗin giya da magana mai zartar gaskiya yana niƙa ƙƙe Intanet kuma inspection da manual'ani na zama wani aikin bayani na shiryarwa. Aka da wani misali da aka sanar da shi a kan salon da za'a iya iya filterar da maɓallin arabu mai ƙiyayya, yana da amfani da mai yawa a yanzu. A cikin wannan takardan, Munã bayyana misãlai wanda aka aika zuwa Tafiyar da aka Shara zuwa Tafiyar da Fara Haske da Cikakken Farawa wanda aka organize (The Fourth workspace on Open-Source Carabi Corope da Cikakken aiki). Tuduniyarmu yana amfani da motel mai shida (BERT) zuwa a gane maɓallin abuni. Mun je wa na rubu a cikin aikin A da na uku a cikin aikin B.", 'he': 'בשנים האחרונות, תגובות רעילות ונאום מעליב מזעזעים את האינטרנט ובדיקות ידנית של ההערות האלה הופכות למשימה עייפה לנהל. יש מודל למידת מכונות שמבוסס שיכול לסנן תוכן ערבי פגיע הוא זקוק גבוה בימים אלה. בעיתון הזה, אנחנו מתארים את המודל שנשלח למשימה המשותפת על גילוי שפת פגיעה שאורגן ע"י (Workshop 4 on Open-Source Arabic Corpora and Processing Tools). המודל שלנו גורם להשתמש במודל מבוסס במעבר (BERT) כדי לגלות תוכן פגיע. We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).', 'jv': 'Nang gulang sing dumadhi, komentar tok lan kelangan anyar tentang kanggo nggunakake Internet lan nganggep manut kanggo nggunakake komentar iki kuwi mau iso nggawe ngupakan langgar. Genjer-genjer sistem sing paling-sistem sing bisa supoyo nggawe nyimpen percoffes barang arap kuwi kudu nggawe barang mangan kuwi mau. Nang pebuk iki, awak dhéwé ngerasakno model sing ngesélané Mesang Daftar Pasang Ofensive kanggo Kebebasan Language sing berarti (Sampeyan 4Wing Workspace na Open-Source model Awak dhéwé wis nambah sing nganggo urip ing panjenengan A (ditambah Kemerdekaan Ofensive) lan ning acara tualah sing dumateng B (ditambah Kemerdekaan Kasama).', 'sk': 'V zadnjih letih strupeni komentarji in žaljivi govori onesnažujejo internet, ročni pregled teh komentarjev pa postaja naporna naloga za upravljanje. Danes je zelo potreben model, ki temelji na strojnem učenju, ki lahko filtrira žaljive arabske vsebine. V tem prispevku opisujemo model, ki je bil predložen skupni nalogi o odkrivanju napadalnih jezikov, ki ga organizira (4. delavnica o odprtokodnih arabskih korpusih in orodjih za obdelavo). Naš model uporablja transformatorski model (BERT) za zaznavanje žaljive vsebine. Prišli smo na četrto mesto v podnalogi A (odkrivanje napadalnega govora) in na tretje mesto v podnalogi B (odkrivanje sovražnega govora).', 'bo': 'འདས་བའི་ལོ་ངོ་ཚོའི་ནང་དུ་བྱུང་བ་མཁན་འགྱུར་བའི་མཆན་བཤད་དང་བརྗོད་སྒྲུབ་ཀྱི་ནང་དུ་ཡིས་དྲ་རྒྱ་སྟངས་ལ་ལག་སྟར་ཞིབ ལག་ཆས་ལྟ་བུའི་མ་དབུགས་ཅིག་ཡོད་ཚད་ལྟ་བུ་ཞིག་ཡོད་པ་དེ་རིང་གི་སྔར་སྐྱོན་བརྗོད་པའི་ཨ་རིའི་ནང་དོ འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་རྣམ་པ་འདིའི་ནང་དུ་མཉམ་དུ་སྤྱོད་པའི་བྱ་རིམ་དང་Offensive Language Detection་ལ་འཇུག་སྤྱོད་ཀྱི་མིང་དཔེ་གཏན་བཤད་པ་ཡིན། ང་ཚོའི་མ་དབྱིབས་དབྱིབས་གཞི་བརྗོད་མཁན་གྱི་མ་དབྱིབས(BERT)སྙན་འཛུགས་བྱེད་ཀྱི་ནང་དོན ང་ཚོས་རང་ཉིད་ཀྱི་རྒྱ་ནག་ནང་དུ་subtask A(Offensive Speech)ནང་དུ་འཇུག་སར་བཞི་པ་དང་། subtask B(Hate Speech)ནང་དུ་འཇུག་སྣོད་ཐེངས་གསུམ་པ་འདུག'}
{'en': 'Multi-Task Learning using AraBert for Offensive Language Detection', 'ar': 'التعلم متعدد المهام باستخدام AraBert لاكتشاف اللغة الهجومية', 'es': 'Aprendizaje multitarea con AraBert para la detección de lenguaje ofensivo', 'pt': 'Aprendizado multitarefa usando AraBert para detecção de linguagem ofensiva', 'fr': "Apprentissage multitâche à l'aide d'AraBert pour la détection", 'ja': '攻撃的言語検出のためのAraBertを使用したマルチタスク学習', 'hi': 'मल्टी-टास्क सीखना आक्रामक भाषा का पता लगाने के लिए AraBert का उपयोग कर', 'zh': '用 AraBert 犯性语言检测者多任务学', 'ru': 'Многозадачное обучение с использованием AraBert для обнаружения оскорбительного языка', 'ga': 'Foghlaim Ilthasc ag baint úsáide as AraBert chun Teangacha Ionsaitheach a Bhrath', 'hu': 'Többfeladatos tanulás AraBert segítségével a támadó nyelv felismeréséhez', 'el': 'Μάθηση πολλαπλών εργασιών χρησιμοποιώντας το AraBert για την ανίχνευση προσβλητικών γλωσσών', 'ka': 'Multi- Task Learning using AraBert for Offensive Language Detection', 'lt': 'Daugiaužduočių mokymasis naudojant AraBert pažeidžiamoms kalboms nustatyti', 'kk': 'Тілді табу үшін AraBert қолданылатын көптеген тапсырмаларды оқыту', 'it': 'Apprendimento multi-task utilizzando AraBert per il rilevamento offensivo del linguaggio', 'mt': 'Tagħlim Multikompiti bl-użu ta’ AraBert għad-Detezzjoni ta’ Lingwi Offensivi', 'mk': 'Мултизадачно учење користејќи AraBert за детекција на навредлив јазик', 'ml': 'അറബെര്\u200dട്ട് ഉപയോഗിക്കുന്നതിനായി അധിക ജോലി പഠിക്കുന്നു', 'mn': 'Олон-үйл ажиллагааны суралцах нь АраБерт-г нээлттэй хэл олж мэдэхэд', 'no': 'Multioppgåver-læring med AraBert for forskyving av språk', 'ro': 'Învățare multi-task folosind AraBert pentru detectarea limbajului ofensiv', 'sr': 'Naučenje više zadataka koristeći AraBert za otkrivanje službenog jezika', 'so': 'Waxbarashada shaqo badan oo isticmaalaya Arabert si aad u hesho aqoonsiga luqada', 'si': 'අධික භාෂාව හොයාගන්න ආරාබර්ට් භාවිතාව භාවිත කරන්න බොහොම කාර්ය ඉගෙන ගන්න', 'sv': 'Multi-Task Learning med AraBert för Offensiv Language Detection', 'ur': 'نافنسی زبان شناسی کے لئے AraBert کے استعمال سے بہت سی ٹاکس سیکھنے', 'pl': 'Wielozadaniowe uczenie się przy użyciu AraBert do wykrywania języka obraźliwego', 'ms': 'Belajar-Tugas Berbilang menggunakan AraBert untuk Pengesanan Bahasa Tersinggung', 'ta': 'அறிவிப்பு மொழி கண்டுபிடிப்பதற்கான அராபெர்ட் பயன்படுத்தி பல- பணி', 'uz': 'Name', 'vi': 'Truyền thuyết đa tác dụng AraBert để phát hiện biện pháp chân tướng', 'bg': 'Обучение с множество задачи с помощта на AraBert за откриване на офанзивен език', 'hr': 'Naučenje više zadataka koristeći AraBert za otkrivanje neposlušnog jezika', 'nl': 'Multi-Task Leren met AraBert voor offensieve taaldetectie', 'da': 'Multi-Task Learning ved hjælp af AraBert til Offensive Language Detection', 'de': 'Multi-Task Lernen mit AraBert zur Erkennung offensiver Sprachen', 'fa': 'یادگیری زیادی از AraBert برای شناسایی زبان ناتوان', 'ko': 'AraBert 기반 공격적 언어 감지 멀티태스킹', 'tr': "AraBert'i Zolaky Dili Aňlamak üçin köp Taýgy Öwrenmek", 'sq': 'Mësimi me shumë detyra duke përdorur AraBert për zbulimin ofensiv të gjuhës', 'sw': 'Multi-Task Learning using AraBert for Offensive Language Detection', 'am': 'መግለጫ', 'id': 'Belajar Multi-Task menggunakan AraBert untuk Deteksi Bahasa Meninggal', 'bn': 'অফিসেন্টিভ ভাষা সনাক্ত করার জন্য আরাবার্ট ব্যবহার করে অনেক কাজ শিক্ষা শিক্ষা', 'af': 'Multi- Task Leer gebruik AraBert vir Offensive Language Detection', 'bs': 'Naučenje više zadataka koristeći AraBert za otkrivanje neposlušnog jezika', 'ca': 'Aprendiment multitascat utilitzant AraBert per detectar llengües ofensives', 'cs': 'Víceúlohové učení pomocí AraBert pro detekci urážlivého jazyka', 'az': 'AraBert dilini tapmaq 칲칞칲n 칞ox-Task 칐yr톛nm톛si', 'fi': 'Useiden tehtävien oppiminen AraBertin avulla hyökkäävän kielen havaitsemiseen', 'hy': 'Բազմախնդիրներ սովորելը օգտագործելով Արաբերթը', 'et': 'Mitme ülesandega õppimine AraBerti abil ründava keele tuvastamiseks', 'ha': 'KCharselect unicode block name', 'jv': 'Multi-tasks FindOK', 'bo': 'Offensive Language Detection', 'he': 'ללמוד במשימות רבות בשימוש באראברט לגלות שפות פגיעה', 'sk': 'Večopravilno učenje z uporabo AraBerta za napadalno zaznavanje jezika'}
{'en': 'The use of ', 'ar': 'أصبح استخدام منصات التواصل الاجتماعي أكثر انتشارًا ، مما أتاح فرصًا هائلة للأشخاص للتواصل ، ولكنه فتح أيضًا الباب لإساءة الاستخدام مع انتشار خطاب الكراهية واللغة المسيئة. تدفع هذه الظاهرة المزيد والمزيد من الناس إلى ردود أفعال أكثر تطرفًا وعدوانية عبر الإنترنت ، مما يتسبب أحيانًا في أذى جسدي للأفراد أو مجموعات من الناس. هناك حاجة للسيطرة على إساءة استخدام وسائل التواصل الاجتماعي عبر الإنترنت ومنعها من خلال الاكتشاف التلقائي للغة البذيئة. هدفت المهمة المشتركة الخاصة باكتشاف اللغة الهجومية في OSACT4 إلى تحقيق أحدث أساليب الكشف عن اللغة البذيئة لوسائل التواصل الاجتماعي العربية. عالج فريقنا "BERTologists" هذه المشكلة من خلال الاستفادة من نموذج اللغة العربية المدروس مسبقًا ، AraBERT ، الذي زدناه بإضافة التعلم متعدد المهام لتمكين نموذجنا من التعلم بكفاءة من البيانات القليلة. حقق نهج AraBERT متعدد المهام الخاص بنا المركز الثاني في كلتا المهمتين الفرعيتين A و B ، مما يدل على أن النموذج يؤدي باستمرار عبر المهام المختلفة.', 'fr': "L'utilisation des plateformes de médias sociaux est devenue plus répandue, ce qui a permis aux gens de se connecter, mais a également ouvert la porte à un usage abusif avec la diffusion de discours haineux et de langage offensant. Ce phénomène conduit de plus en plus de personnes à des réactions extrêmes et à des agressions en ligne, causant parfois des dommages physiques à des individus ou à des groupes de personnes. Il est nécessaire de contrôler et de prévenir une telle utilisation abusive des réseaux sociaux en ligne grâce à la détection automatique du langage profane. La tâche partagée sur la détection des langues offensantes à l'OSACT4 visait à mettre au point des méthodes de détection de langage profane de pointe pour les médias sociaux arabes. Notre équipe «\xa0BertOlogists\xa0» s'est attaquée à ce problème en utilisant le modèle de langue arabe pré-formé de pointe, AraBert, que nous complétons avec l'ajout de l'apprentissage multitâche pour permettre à notre modèle d'apprendre efficacement à partir de peu de données. Notre approche multitâche ARaBert a obtenu la deuxième place dans les sous-tâches A et B, ce qui montre que le modèle fonctionne de manière cohérente sur différentes tâches.", 'es': 'El uso de plataformas de redes sociales se ha vuelto más frecuente, lo que ha brindado enormes oportunidades para que las personas se conecten, pero también ha abierto la puerta al uso indebido con la difusión de discursos de odio y lenguaje ofensivo. Este fenómeno ha llevado a más y más personas a reacciones más extremas y agresiones en línea, a veces causando daños físicos a individuos o grupos de personas. Es necesario controlar y prevenir este uso indebido de las redes sociales en línea mediante la detección automática de lenguaje profano. La tarea compartida sobre la detección de lenguaje ofensivo en la OSACT4 tiene como objetivo lograr métodos de detección de lenguaje profano de última generación para las redes sociales árabes. Nuestro equipo «Bertologists» abordó este problema aprovechando el modelo avanzado del idioma árabe preentrenado, ARaBert, que ampliamos con la adición del aprendizaje multitarea para permitir que nuestro modelo aprenda de manera eficiente con pocos datos. Nuestro enfoque AraBert Multitask obtuvo el segundo lugar en ambas subtareas A y B, lo que demuestra que el modelo funciona de manera consistente en diferentes tareas.', 'pt': 'O uso de plataformas de mídia social tornou-se mais prevalente, o que proporcionou enormes oportunidades para as pessoas se conectarem, mas também abriu as portas para o uso indevido com a disseminação de discursos de ódio e linguagem ofensiva. Esse fenômeno tem levado cada vez mais pessoas a reações mais extremas e agressões online, às vezes causando danos físicos a indivíduos ou grupos de pessoas. Há uma necessidade de controlar e prevenir tal uso indevido das mídias sociais online por meio da detecção automática de linguagem profana. A tarefa compartilhada sobre Detecção de Linguagem Ofensiva no OSACT4 teve como objetivo alcançar métodos de detecção de linguagem profana de última geração para mídias sociais árabes. Nossa equipe “BERTologists” abordou esse problema aproveitando o modelo de idioma árabe pré-treinado de última geração, AraBERT, que aumentamos com a adição de aprendizado multitarefa para permitir que nosso modelo aprenda de forma eficiente com poucos dados. Nossa abordagem multitarefa AraBERT alcançou o segundo lugar em ambas as subtarefas A e B, o que mostra que o modelo funciona de forma consistente em diferentes tarefas.', 'ja': 'ソーシャルメディアプラットフォームの使用がより普及し、人々がつながる絶好の機会を提供しましたが、ヘイトスピーチや不快な言葉の広がりとともに誤用の扉を開きました。 この現象は、ますます多くの人々を過激な反応やオンライン攻撃に駆り立て、時には個人や人々のグループに身体的な損害を与えることがあります。 不適切な言葉を自動的に検出することにより、オンラインソーシャルメディアのそのような不正使用を制御および防止する必要があります。 OSACT 4の攻撃的言語検出に関する共有タスクは、アラビア語ソーシャルメディアのための最先端の不適切な言語検出方法を達成することを目的としています。 私たちのチーム「BERTologists」は、最先端の事前訓練されたアラビア語モデル「AraBERT」を活用してこの問題に取り組みました。これは、マルチタスク学習を追加して、私たちのモデルが小さなデータから効率的に学習できるようにすることで拡張されました。 当社のMultitask AraBERTアプローチは、サブタスクAとBの両方で2位を達成しました。これは、モデルがさまざまなタスクで一貫して実行されることを示しています。', 'hi': 'सोशल मीडिया प्लेटफॉर्म का उपयोग अधिक प्रचलित हो गया है, जिसने लोगों को जुड़ने के लिए जबरदस्त अवसर प्रदान किए हैं, लेकिन नफरत भरे भाषण और आक्रामक भाषा के प्रसार के साथ दुरुपयोग के लिए दरवाजा भी खोल दिया है। यह घटना अधिक से अधिक लोगों को अधिक चरम प्रतिक्रियाओं और ऑनलाइन आक्रामकता के लिए चला रही है, कभी-कभी व्यक्तियों या लोगों के समूहों को शारीरिक नुकसान पहुंचाती है। अपवित्र भाषा का स्वत: पता लगाने के माध्यम से ऑनलाइन सोशल मीडिया के इस तरह के दुरुपयोग को नियंत्रित करने और रोकने की आवश्यकता है। OSACT4 में आपत्तिजनक भाषा का पता लगाने पर साझा कार्य का उद्देश्य अरबी सोशल मीडिया के लिए अत्याधुनिक अपवित्र भाषा का पता लगाने के तरीकों को प्राप्त करना है। हमारी टीम "BERTologists" कला pretrained अरबी भाषा मॉडल, AraBERT की स्थिति का लाभ उठाकर इस समस्या से निपटने के लिए, कि हम मल्टी-टास्क सीखने के अलावा के साथ वृद्धि करने के लिए हमारे मॉडल को थोड़ा डेटा से कुशलतासे सीखने के लिए सक्षम करने के लिए। हमारे मल्टीटास्क अराबर्ट दृष्टिकोण ने दोनों उप-कार्यों ए और बी में दूसरा स्थान हासिल किया, जो दिखाता है कि मॉडल विभिन्न कार्यों में लगातार प्रदर्शन करता है।', 'ru': 'Использование платформ социальных сетей стало более распространенным, что предоставило огромные возможности для общения людей, но также открыло дверь для неправильного использования с распространением ненавистнических высказываний и оскорбительных выражений. Это явление заставляет все больше и больше людей к более экстремальным реакциям и онлайн-агрессии, иногда причиняя физический вред отдельным лицам или группам людей. Необходимо контролировать и предотвращать такое неправомерное использование социальных сетей посредством автоматического обнаружения ненормативной лексики. Совместная задача ОСАКТ4 по выявлению оскорбительного языка направлена на достижение современных методов обнаружения ненормативного языка в арабских социальных сетях. Наша команда «BERTologists» решила эту проблему, используя современную предварительно обученную модель арабского языка, AraBERT, которую мы дополняем многозадачным обучением, чтобы наша модель могла эффективно учиться на основе небольших данных. Наш многозадачный подход AraBERT занял второе место в обеих подзадачах A и B, что показывает, что модель последовательно выполняет различные задачи.', 'zh': '社交媒体台用转普,这为人巨络,然亦为仇言犯性之传开滥门。 常使益多者为极网络攻击,或为群伤。 有以自动检测亵渎性言制之,防其滥在线社交媒体。 OSACT4犯性言检者同旨在阿拉伯语社交媒体最先进亵渎语检测之法。 吾团队"BERTologists"因先进之教阿拉伯语AraBERT决之,吾益多任务学以益之,使吾少数有效。 吾多任务AraBERT之法,于子职A与B俱得二,是异务也。', 'ga': 'Tá úsáid na n-ardán meán sóisialta níos forleithne anois, rud a chuir deiseanna iontacha ar fáil do dhaoine chun nascadh ach a d’oscail an doras freisin do mhí-úsáid le scaipeadh fuathchaint agus teanga maslach. Tá an feiniméan seo ag tiomáint níos mó agus níos mó daoine chuig frithghníomhartha níos déine agus ionsaí ar líne, rud a dhéanann dochar fisiceach uaireanta do dhaoine aonair nó do ghrúpaí daoine. Is gá a leithéid de mhí-úsáid ar na meáin shóisialta ar líne a rialú agus a chosc trí bhrath uathoibríoch ar theanga thruailliú. Tá an tasc roinnte ar Bhrath Teanga Ionsaitheach ag an OSACT4 dírithe ar mhodhanna braite teanga truamhéalacha den scoth a bhaint amach do na meáin shóisialta Araibise. Chuaigh ár bhfoireann “BERTologists” i ngleic leis an bhfadhb seo trí leas a bhaint as samhail teanga Araibis réamhoilte den chéad scoth, AraBERT, a chuirfimid leis trí fhoghlaim ilthasc a chur leis chun cur ar chumas ár múnla foghlaim go héifeachtach ó bheagán sonraí. Bhain ár gcur chuige Multitask AraBERT an dara háit amach sa dá fhothasc A & B, a léiríonn go bhfeidhmíonn an tsamhail go comhsheasmhach thar thascanna éagsúla.', 'hu': 'A közösségi média platformok használata egyre elterjedtebbé vált, ami óriási lehetőségeket biztosított az emberek számára a kapcsolatra, de megnyitotta az ajtót a gyűlöletbeszéd és a sértő nyelv terjedésével a visszaélések előtt is. Ez a jelenség egyre több embert hajt szélsőséges reakciókra és online agresszióra, néha fizikai károkat okozva egyéneknek vagy embercsoportoknak. Ellenőrizni és megakadályozni kell az online közösségi médiával való visszaélést a profán nyelv automatikus felismerésével. Az OSACT4 Offensive Language Detection közös feladata az arab közösségi médiában a legkorszerűbb profán nyelvfelismerési módszerek kialakítása volt. A "BERTologists" csapatunk ezt a problémát a legkorszerűbb, előképzett arab nyelv modelljének, az AraBERT-nek a kihasználásával kezelte, amelyet többfeladatos tanulással bővítünk, hogy modellünk hatékonyan tanulhasson kevés adatból. Multitask AraBERT megközelítésünk a második helyet érte el mindkét A & B alcsoportban, ami azt mutatja, hogy a modell következetesen teljesíti a különböző feladatokat.', 'ka': 'სოციალური მედია პლატატურების გამოყენება უფრო გარჩეველია, რომელიც ადამიანებისთვის უფრო დიდი შესაძლებლობა დაკავშირება, მაგრამ უფრო გახსნა კითხვის გარეშე შეცდომის გამოყენებ ეს ფანომენი უფრო მეტი ადამიანებს უფრო მეტი ექსტრექტიური რეაქციები და ინტერნეტიური ადგრესი დაკავშირებულია, რომელსაც ადამიანებისთვის ან ჯგუფებისთვის ფიზ არსებობს მოჭირდება დაკონტროლისთვის და დაწყვეტის ასეთი შეცდომის გამოყენება ინტერნეული სოციალური მედიაზე, რომელიც ავტომატურად განახსენება OSACT4-ში განსაზღვრებული ენის განსაზღვრების დასაზღვრებელი რაოდენობა უფრო მიდგომარებულია, რომ აპაბული საზოგადო მედიათებისთვის ხელოვნების განსაზღვრების შესაძლებლობა ჩვენი ჯგუფი "BERTologists" ამ პრობლემას გადაწყვეტა, რომელიც ხელოვნების მოდელს აპაბური ენის მოდელს, რომელიც ჩვენ უფრო რაოდენობის სწავლების დამატებით, რომ ჩვენი მოდელს უფრო ეფექტიურად ვისწავლოთ ჩვენი Multitask AraBERT პროგრამის მიღება ორი ადგილი A & B-ში, რომელიც ჩვენი მოდელის მუშაობა განსხვავებული დავალებებით.', 'el': 'Η χρήση των πλατφορμών κοινωνικής δικτύωσης έχει γίνει πιο διαδεδομένη, η οποία έχει παράσχει τεράστιες ευκαιρίες στους ανθρώπους να συνδεθούν, αλλά έχει επίσης ανοίξει την πόρτα για κακή χρήση με την εξάπλωση της ρητορικής μίσους και της προσβλητικής γλώσσας. Αυτό το φαινόμενο έχει οδηγήσει όλο και περισσότερους ανθρώπους σε πιο ακραίες αντιδράσεις και διαδικτυακή επιθετικότητα, προκαλώντας μερικές φορές σωματική βλάβη σε άτομα ή ομάδες ανθρώπων. Υπάρχει ανάγκη να ελεγχθεί και να προληφθεί αυτή η κατάχρηση των διαδικτυακών μέσων κοινωνικής δικτύωσης μέσω αυτόματου εντοπισμού βλαβερής γλώσσας. Το κοινό έργο για την ανίχνευση προσβλητικών γλωσσών στο OSACT4 έχει ως στόχο την επίτευξη σύγχρονων μεθόδων ανίχνευσης βλαβερών γλωσσών για τα αραβικά μέσα κοινωνικής δικτύωσης. Η ομάδα μας "BERTolologs" αντιμετώπισε αυτό το πρόβλημα αξιοποιώντας το προηγμένο μοντέλο αραβικής γλώσσας, το οποίο εμπλουτίζουμε με την προσθήκη εκμάθησης πολλαπλών εργασιών για να επιτρέψουμε στο μοντέλο μας να μαθαίνει αποτελεσματικά από λίγα δεδομένα. Η προσέγγιση πολλαπλών εργασιών κατέληξε στη δεύτερη θέση και στις δύο δευτερεύουσες εργασίες Α.Β, γεγονός που δείχνει ότι το μοντέλο εκτελεί σταθερά σε διαφορετικές εργασίες.', 'kk': 'Социалдық медиа платформасының қолдануы көтерілген болды. Бұл адамдар қосылу үшін көп мүмкіндіктерді қолдану мүмкіндіктері болды, бірақ сондай-ақ қарамастан сөйлейтін және қарсылық тілді қайт Бұл панель көп адамдарды онлайн агрессиясына көп қарсы және онлайн агрессиясына көп жеткізеді. Кейбірде физикалық жеке не адамдардың топтарына қарсы жеткізеді. Профан тілді автоматты түрде анықтау арқылы онлайн социалдық медиақтардың қолдануын қате пайдалануын басқару және бұл қатесін басқару керек. OSACT4 дегенде официалдық тілді анықтау үшін ортақ тапсырмасы араб әлемдік медиаға арнайы тілді анықтау әдістерін жеткізу үшін мақсатты. Біздің "BERTologists" командамыз бұл мәселеді, әртүрлі араб тіл үлгісінің күйін өзгертуге арналған, АраBERT, біз көптеген тапсырмаларды оқыту үшін біздің моделімізді кішкентай деректерден оқытуға мүмкіндік беру Біздің көптеген тапсырмамыз АРБЕРТ бағдарламасының екінші жағдайда A & B алдындағы екінші жағдайды жеткізді. Бұл үлгі әртүрлі тапсырмалардың бірінде тұратын', 'mk': 'Користењето на платформите за социјални медиуми стана попошироко, што им овозможи огромни можности на луѓето да се поврзат, но исто така ја отвори вратата за злоупотреба со ширењето на говорот на омраза и навреден јазик. Овој феномен води сé повеќе луѓе кон екстремни реакции и онлајн агресија, понекогаш предизвикувајќи физичка штета на поединците или групите на луѓе. Постои потреба да се контролира и спречи ваква злоупотреба на онлајн социјалните медиуми преку автоматско откривање на непријатниот јазик. Соделената задача за детективирање на навредлив јазик во ОСАЦТ4 има за цел постигнување на најсовремени методи за детективирање на јазик за арапските социјални медиуми. Our team “BERTologists” tackled this problem by leveraging state of the art pretrained Arabic language model, AraBERT, that we augment with the addition of Multi-task learning to enable our model to learn efficiently from little data.  Нашиот пристап на Мултизадача АРАБЕРТ го постигна второто место во двете потпрашања А и Б, што покажува дека моделот постојано функционира во различни задачи.', 'it': 'L\'uso delle piattaforme di social media è diventato più diffuso, il che ha fornito enormi opportunità per le persone di connettersi, ma ha anche aperto le porte ad abusi con la diffusione di discorsi di odio e linguaggio offensivo. Questo fenomeno ha spinto sempre più persone a reazioni più estreme e aggressioni online, causando talvolta danni fisici a individui o gruppi di persone. È necessario controllare e prevenire tale abuso dei social media online attraverso il rilevamento automatico del linguaggio profano. Il compito condiviso su Offensive Language Detection presso l\'OSACT4 è stato quello di ottenere metodi di rilevamento delle lingue profane all\'avanguardia per i social media arabi. Il nostro team "BERTologists" ha affrontato questo problema sfruttando il modello di lingua araba pre-addestrato all\'avanguardia, AraBERT, che aggiungiamo all\'apprendimento multi-task per consentire al nostro modello di imparare efficacemente da pochi dati. Il nostro approccio Multitask AraBERT ha ottenuto il secondo posto in entrambe le sottoattività A & B, il che dimostra che il modello si comporta costantemente in diversi compiti.', 'lt': 'Socialinės žiniasklaidos platformų naudojimas tapo vis dažnesnis, o tai suteikė didžiules galimybes žmonėms prisijungti, tačiau taip pat atverė duris piktnaudžiavimui sprendžiant neapykantos kalbą ir įžeidžiančią kalbą. Šis reiškinys vis labiau privertė žmones į ekstremalias reakcijas ir internetinę agresiją, kartais sukeliančią fizinę žalą asmenims ar žmonių grupėms. Reikia kontroliuoti ir užkirsti kelią tokiam netinkamam internetinės socialinės žiniasklaidos naudojimui, automatiškai nustatant nesąžiningą kalbą. Bendra užduotis, susijusi su nusikalstamos kalbos nustatymu OSACT4, buvo siekiama sukurti pažangiausius arabų socialinės žiniasklaidos kalbų nustatymo metodus. Mūsų komanda „BERTologijai“ išspręsė šią problem ą, naudodami pažangiausią iš anksto mokomą arabų kalbos model į AraBERT, kurį papildome papildomu daugiašaliu mokymusi, kad mūsų modelis galėtų veiksmingai mokytis iš mažai duomenų. Mūsų daugiafunkcinis AraBERT metodas pasiekė antrą vietą abiejose A ir B paklausose, o tai rodo, kad modelis nuosekliai atliekamas įvairiose užduotyse.', 'ms': 'Penggunaan platform media sosial telah menjadi lebih terkenal, yang telah menyediakan peluang yang luar biasa bagi orang untuk menyambung tetapi juga telah membuka pintu untuk salah penggunaan dengan penyebaran ucapan kebencian dan bahasa yang menyerang. This phenomenon has been driving more and more people to more extreme reactions and online aggression, sometimes causing physical harm to individuals or groups of people.  Terdapat kebutuhan untuk mengawal dan mencegah salah penggunaan media sosial online melalui pengesan secara automatik bahasa yang menderita. Tugas berkongsi untuk Pengesanan Bahasa Tersinggung di OSACT4 telah bertujuan untuk mencapai kaedah pengesan bahasa mendalam seni untuk media sosial Arab. Pasukan kami "BERTologists" mengatasi masalah ini dengan menggunakan model bahasa Arab yang telah dilatih dahulu, AraBERT, yang kami tambahkan dengan pembelajaran Multi-Task untuk memungkinkan model kami untuk belajar secara efektif dari data sedikit. Pendekatan AraBERT Multi-tugas kami mencapai tempat kedua dalam kedua-dua sub-tanya A & B, yang menunjukkan bahawa model berfungsi secara konsisten melalui tugas yang berbeza.', 'ml': 'സാമൂഹ്യ മീഡിയ പ്ലാറ്റ്ഫോമുകള്\u200d ഉപയോഗിക്കുന്നത് കൂടുതല്\u200d മുന്\u200dഗണനായിത്തീര്\u200dന്നിരിക്കുന്നു. അത് ആളുകള്\u200dക്ക് ബന്ധപ്പെടാന്\u200d വളരെ സാധ ഈ സംഭവം കൂടുതല്\u200d ആള്\u200dക്കാരെ ഓടിക്കൊണ്ടിരിക്കുകയാണ്. അതിന്റെ പ്രതികരണങ്ങള്\u200dക്കും ഓണ്\u200dലൈന്\u200d ആക്രമണങ്ങള്\u200dക്കും കൂടുതല്\u200d കൂടുതല ഓണ്\u200dലൈന്\u200d സാമൂഹ്യ മാധ്യമങ്ങളുടെ ഉപയോഗം തെറ്റായി നിയന്ത്രിക്കണമെന്നും അതിനെ തടഞ്ഞുനിര്\u200dത്താനും ആവശ്യമ ഓസാക്ട്4-ല്\u200d പങ്കാളിയുള്ള ഭാഷയുടെ ഡിറ്റക്ടീഷനില്\u200d പങ്കെടുത്ത ജോലി അറബിക്ക് സോഷ്യല്\u200d മേഡിയയ്ക്കുള്ള കലാകാര്\u200d ഭാഷ ഞങ്ങളുടെ ടീം "ബെര്\u200dട്ടോളജിസ്റ്റ്" ഈ പ്രശ്നത്തെ നോക്കിയിരിക്കുന്നു. ആരാബെര്\u200dട്ടിയുടെ അറബി ഭാഷയുടെ മോഡല്\u200d നിയന്ത്രിക്കുന്നതിനാല്\u200d ഞങ്ങള്\u200d കൂട്ടിചേര്\u200d ഞങ്ങളുടെ മില്ട്ടിട്ടുള്ള അറബെര്\u200dട്ടിയുടെ അടുത്തേക്ക് രണ്ടാമത്തേത് സ്ഥലം എത്തി... ...A & B സബ്ജിസുകളില്\u200d, അതിന്റെ മോഡല്\u200d', 'mn': 'Нийгмийн мэдээллийн хэвлэлийн платформуудын хэрэглээ илүү хүндрэлтэй болсон. Энэ нь хүмүүст холбогдох маш олон боломж олгосон ч мөн хаалга буруу хэрэглэх боломжтой болсон. Энэ явдал хүмүүсийг илүү их урвалд, онлайн агшил, заримдаа хүмүүст физикийн хохиромжтой болгодог. Интернет нийгмийн мэдээллийн хэрэглээнийг автоматаар гүн гүнзгий хэлний мэдээллээр удирдлага, зогсоох хэрэгтэй. OSACT4-ын оффицист хэл мэдэх үйлдэл нь Араб нийгмийн мэдээллийн хувьд урлагийн гүнзгий хэл мэдэх арга замыг хүргэх зорилготой. Бидний баг "БЕРТОЛОГИЙ" энэ асуудлыг Араб хэл загварын түвшинд хүргэж, бид олон үйл ажиллагааны сургалтыг нэмэхэд багахан мэдээллээс үр дүнтэй суралцах боломжтой болгодог. Бидний олон үйл ажиллагааны AraBERT арга нь А & B доогуудын хоёр дахь орон хүртэл гарч ирсэн. Энэ нь загвар нь үргэлж өөр үйл ажиллагаанд ажилладаг.', 'ro': 'Utilizarea platformelor de social media a devenit din ce în ce mai răspândită, ceea ce a oferit oportunități extraordinare pentru oameni de a se conecta, dar a deschis, de asemenea, ușa pentru utilizarea abuzivă prin răspândirea discursului de ură și a limbajului ofensator. Acest fenomen a condus din ce în ce mai mulți oameni la reacții extreme și agresiune online, cauzând uneori daune fizice indivizilor sau grupurilor de oameni. Este necesar să se controleze și să se prevină o astfel de utilizare abuzivă a rețelelor sociale online prin detectarea automată a limbajului profan. Sarcina comună privind detectarea limbilor ofensive la OSACT4 a vizat realizarea metodelor de detectare a limbilor profane de ultimă oră pentru rețelele sociale arabe. Echipa noastră "BERTologiști" a abordat această problemă utilizând modelul de limbă arabă pre-instruit de ultimă oră, AraBERT, pe care îl extindem cu adăugarea de învățare Multi-task pentru a permite modelului nostru să învețe eficient din puține date. Abordarea noastră Multitask AraBERT a obținut locul doi în ambele subactivități A și B, ceea ce arată că modelul efectuează constant în diferite sarcini.', 'mt': 'L-użu ta’ pjattaformi tal-midja soċjali sar aktar prevalenti, li pprovda opportunitajiet enormi għan-nies biex jikkonnettjaw iżda fetaħ ukoll il-bieb għal użu ħażin mat-tixrid ta’ diskors ta’ mibegħda u lingwa ofensiva. Dan il-fenomenu kien qed iwassal dejjem aktar nies għal reazzjonijiet aktar estremi u aggressjoni onlajn, u xi kultant jikkawża ħsara fiżika lil individwi jew gruppi ta’ nies. Jeħtieġ li jiġi kkontrollat u evitat tali użu ħa żin tal-midja soċjali onlajn permezz ta’ individwazzjoni awtomatika ta’ lingwa profana. The shared task on Offensive Language Detection at the OSACT4 has aimed at achieving state of art profane language detection methods for Arabic social media.  It-tim tagħna “BERToloġi” indirizza din il-problema billi sfrutta l-mudell tal-lingwa Għarbija mħarreġ minn qabel, AraBERT, li aħna nżidu biż-żieda ta’ tagħlim multikompiti biex il-mudell tagħna jkun jista’ jitgħallem b’mod effiċjenti minn ftit dejta. L-approċċ tagħna ta’ AraBERT Multikompitu kiseb it-tieni post fiż-żewġ sottomistoqsijiet A & B, li juri li l-mudell iwettaq b’mod konsistenti f’kompiti differenti.', 'si': 'සාමාජික මාධ්\u200dයමාධ්\u200dයම ප්\u200dරවේශනය විශේෂ වෙලා තියෙනවා, ඒකෙන් මිනිස්සුන්ට සම්බන්ධ වෙන්න බොහොම අවස්ථාවක් ලැබුනා නමු මේ සිද්ධ වෙනුවෙන් වඩා වැඩි මිනිස්සුන්ට ප්\u200dරතික්\u200dරියාවක් සහ අන්තර්ජාවක් වෙනුවෙන්, සමහර වෙලාවට ප්\u200dරතිකාරි සාමාජික මාධාරණය පාලනය කරන්න සහ ප්\u200dරතික්\u200dරියා කරන්න අවශ්\u200dයයක් තියෙනවා. OSACT4 වලින් විශේෂ භාෂාව හොයාගන්න ක්\u200dරියාව සමාජික භාෂාව හොයාගන්න ප්\u200dරමාණය අරමුණ විදිහට කලාවක් නිර්භ අපේ කණ්ඩායම "BERTologists" මේ ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරලා ඉරාබි භාෂාව ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කරලා අරාබි භාෂාව ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් කර අපේ ගොඩක් කාර්ය AraBERT විදියට දෙවෙනි ස්ථානය A & B දෙන්නෙක් විදියට ලැබුනා, ඒකෙන් පෙන්වන්නේ මොඩේල් වෙනස් කාර්යා', 'sr': 'Koristenje platformi društvenih medija postalo je prevalentniji, što je pružilo ogromne mogućnosti da se ljudi povežu, ali je takođe otvorilo vrata za nepravdu korištenje širenjem govora mržnje i ofanzivnog jezika. Ovaj fenomen vozi sve više ljudi na ekstremne reakcije i online agresiju, ponekad uzrokujući fizičku štetu pojedincima ili grupama ljudi. Postoji potreba za kontrolom i sprečavanjem takvog pogrešnog korištenja internetskih društvenih medija automatskim otkrivanjem profanog jezika. Podijeljeni zadatak o otkrivanju službenog jezika na OSACT4 je cilj postizanja metoda otkrivanja umjetnosti profane jezika za arapske društvene medije. Naš tim „BERTologisti“ rešio je ovaj problem uspoređivajući stanje umjetnosti pretvaranog arapskog jezičkog modela AraBERT, da se povećamo sa dodavanjem učenja više zadataka kako bi omogućili naš model da uči efikasno od malih podataka. Naš pristup multitask AraBERT postigao je drugo mesto u obje podupire A & B, što pokazuje da model stalno izvodi u različitim zadacima.', 'pl': 'Korzystanie z platform mediów społecznościowych stało się coraz bardziej powszechne, co dało ludziom ogromne możliwości do nawiązania kontaktów, ale także otworzyło drzwi dla niewłaściwego nadużycia wraz z rozprzestrzenianiem się mowy nienawiści i obraźliwego języka. Zjawisko to doprowadza coraz więcej ludzi do bardziej ekstremalnych reakcji i agresji online, czasami powodując fizyczne szkody osobom lub grupom ludzi. Istnieje potrzeba kontroli i zapobiegania takiemu nadużyciu mediów społecznościowych online poprzez automatyczne wykrywanie języka profannego. Wspólne zadanie dotyczące wykrywania języka ofensywnego na OSACT4 ma na celu osiągnięcie najnowocześniejszych metod wykrywania języka profannego w arabskich mediach społecznościowych. Nasz zespół "BERTologów" rozwiązał ten problem, wykorzystując najnowocześniej przeszkolony model języka arabskiego AraBERT, który uzupełniamy o dodatek wielozadaniowego uczenia się, aby umożliwić naszemu modelowi efektywne uczenie się z małej ilości danych. Nasze podejście wielozadaniowe AraBERT osiągnęło drugie miejsce w obu podzadaniach A.B, co pokazuje, że model działa konsekwentnie w różnych zadaniach.', 'ta': 'சமூக ஊடகங்களின் பயன்பாடு மிகவும் முன்னோக்கமாகி விட்டது, அது மக்களுக்கு இணைக்க வேண்டிய வாய்ப்புகளை வழங்கியுள்ளது ஆனால் வெறுப்பு பேச்ச இந்த நிகழ்வு மேலும் அதிக மக்களை ஓட்டிக் கொண்டிருக்கிறது மேலும் மிகவும் கடுமையான பிரச்சினைகள் மற்றும் இணையத்தில் மீறி நட தானியங்கி தொழில்நுட்ப மொழியை கண்டுபிடிப்பதற்காக இணைய சமூக ஊடகங்களின் தவறான பயன்படுத்தலை தடுக்க வேண்டும். OSACT4 ல் பகிர்ந்த மொழி கண்டுபிடிப்பில் பகிர்ந்த பணி எங்கள் குழு "BERTologists" இந்த பிரச்சினையை நிர்ணயித்தது ஆர்பெர்ட் சிறிய தகவலிலிருந்து வெளிப்படையாக கற்றுக் கொள்ளும் கலை மாதிரி மாதிரியை அனுப்பி அர்பிரெட எங்கள் பல பணி அராபெர்ட் நெருக்கம் இரண்டாவது இடத்தை இரண்டாவது துணை பணிகளில் அடைந்தது, அது மாதிரி மாதிரி வேறு பணிகளில் முழுமையாக செய', 'so': 'Isticmaalka daryeelka shabakada bulshada waxay noqotay mid ka sii qaali ah, taas oo dadka la xiriira fursado badan, laakiin sidoo kale wuxuu albaabka u furay si kharriban loogu isticmaalo hadalka nebcaalka iyo afka cadaawayaasha. Hadalkan ayaa lagu wadi jiray dad badan oo ka mid ah inay u wareegaan jawaabo aad u daran iyo xadgudub aad u daran internetka, qaarkood qaarkood wuxuu dhibaato jimicsi ku yeelan jiray qof ama koox dad ah. Waxaa loo baahan yahay in la maamulo iyo ka hor maro isticmaalka shabakadda bulshada ee internetka si gaar ah loo ogaado luqada caafimaadka ah. Shaqo la qaybsan karo ku saabsan baaritaanka luqada ee OSACT4 wuxuu ku talo galay in lagu helo qaababka aqoonta afka farshaxanka ah ee loogu talagalay macluumaadka bulshada Carabiga. Kooxdayaga “BERTolog” ayaa dhibaatadan u xambaaray si ay u soo dhiibto xaaladda farshaxanka ah oo afka Carabiga lagu soo delayso, AraBERT, in aynu ku dari karno waxbarashada badan, si aan u awoodno modellkayaga si faa’iido leh uga barto macluumaadka yar. Dhaqdhaqaalahayaga AraBERT waxay gaadheen meeshii labaad ee labada shaqaalaha ah A & B, taasoo muuqata in modellka uu ku sameynayo shaqooyin kala duduwan.', 'ur': 'سوسیل میڈیا پٹروم کا استعمال زیادہ پھیلا گیا ہے، جس نے لوگوں کو اتصال کرنے کے لئے بہت بڑی فرصت دے دی ہے، لیکن اس نے بھی ناپسند بات اور ناپسند زبان کے مطابق برائی کے لئے دروازے کھول دیئے ہیں. یہ اتفاق زیادہ اور زیادہ لوگوں کو زیادہ اضطراری اور آنلاین کی اضطراری کی طرف چلاتا ہے، بعض وقت آدمیوں یا گروہوں پر فیزیکی نقصان پہنچاتا ہے. اس طرح آنلاین سوسیل میڈیا کا غلط استعمال کرنا اور غلط زبان کے ذریعہ اس طرح کنٹرول کرنے کی ضرورت ہے۔ OSACT4 کے اوفنسیو زبان شناسایی کے بارے میں مشترک کام کا ارتفاع کرتا ہے کہ آرابی سوسیل میڈیا کے لئے آهنت کی عملی زبان شناسایی طریقے پہنچ سکیں۔ ہماری تیم "BERTologists" نے اس مسئلہ کو حل کر دیا کہ آرت کی مثال عربی زبان کی مدل، AraBERT کے ذریعہ آرام کرتی ہے کہ ہم بہت سے ٹائک کی تعلیم کے ساتھ بڑھتے ہیں کہ ہمارے مدل کو چھوٹے دیٹے سے مفید طور پر سیکھ سکیں۔ ہمارے Multitask AraBERT تقریبا دوسری جگہ پہنچ گیا ہے ان دونوں A & B کے ساتھ جو دکھاتا ہے کہ مدل مختلف کاموں میں ثابت قدم رہتا ہے۔', 'sv': 'Användningen av sociala medieplattformar har blivit vanligare, vilket har gett enorma möjligheter för människor att ansluta, men också öppnat dörren för missbruk med spridningen av hatpropaganda och stötande språk. Detta fenomen har drivit fler och fler människor till mer extrema reaktioner och online aggression, ibland orsaka fysisk skada på individer eller grupper av människor. Det finns ett behov av att kontrollera och förhindra sådant missbruk av sociala medier online genom automatisk upptäckt av profan språk. Den gemensamma uppgiften om detektering av offensivt språk på OSACT4 har syftat till att uppnå toppmoderna metoder för detektering av profana språk för arabiska sociala medier. Vårt team "BERTologists" tog itu med detta problem genom att utnyttja den senaste förkränade arabiska språkmodellen AraBERT, som vi utökar med tillägg av Multi-Task Learning för att göra det möjligt för vår modell att lära sig effektivt av lite data. Vår Multitask AraBERT-strategi nådde andraplatsen i båda deluppgifterna A & B, vilket visar att modellen presterar konsekvent över olika uppgifter.', 'no': 'Bruken av sosiale media-plattformar har blitt meir utbredt, som har gjeve enorme muligheter for å kopla til mennesker, men har også opna døra for feil bruk med spredning av hatespråk og offensiv språk. Denne fenomenen har kjørt fleire og fleire mennesker til fleire ekstremne reaksjonar og nettaggresjonar, noen ganger som fører til fysiske skade til individuar eller grupper av mennesker. Det er ein måte å kontrollera og forebygge slike feil bruk av internett sosialmedia gjennom automatisk oppdaging av profanespråk. Den delte oppgåva på Offensive Language Detection på OSACT4 har målet å få tilstand til kunstprofane språk-deteksjonsmetodar for arabiske sosiale media. Gruppen vårt «BERTologist» løysa denne problemet ved å levera tilstanden til kunsten i arabisk språk-modellen, AraBERT, at vi øker med tillegg av fleire oppgåver-læring for å slå på modellen vårt å lære effektivt frå lite data. Den andre plassen i begge subtasker A & B, som viser at modellen utfører konsistent på ulike oppgåver.', 'uz': 'The use of social media platforms has become more prevalent, which has provided tremendous opportunities for people to connect but has also opened the door for misuse with the spread of hate speech and offensive language.  Bu narsa ko\'proq odamlarni ko\'proq qiziqroq va tarmoqga harakat qiladi. Ba\'zida odamlarga yoki guruhlarga qo\'shishga qo\'shish sababdi. Name Name Biz guruhimizning "BERTologistlarimiz" bu muammolarni o\'ylab beradi, araBERT asoslangan arab tilning holatini boshqarish mumkin. Biz bir necha maʼlumotdan foydalanish uchun muloqat vazifa o\'rganishni qo\'shish mumkin. Bizning ko\'plab vazifa AraBERT quyidagi ikkinchi joyga erishilgan edi. Bu model boshqa vazifalar bilan birinchi vazifalar bajaradi.', 'vi': 'Việc sử dụng các nền tảng truyền thông xã hội đã trở nên phổ biến hơn, đã tạo ra nhiều cơ hội lớn cho mọi người để kết nối, nhưng cũng đã mở cửa cho việc lạm dụng bằng cách phát tán ngôn ngữ thù ghét và ngôn ngữ tấn công. Hiện tượng này đang thúc đẩy ngày càng nhiều người tới các phản ứng cực đoan và tấn công trực tuyến, đôi khi gây ảnh hưởng đến thể xác cá nhân hay nhóm người. Cần phải kiểm soát và ngăn chặn việc lạm dụng các phương tiện xã hội trực tuyến bằng việc phát hiện ngôn ngữ báng bổ. Nhiệm vụ phát hiện ngôn ngữ rộng lớn của OSACT4 nhằm mục đích thực hiện những phương pháp phát hiện ngôn ngữ trụy lạc trên nền nghệ thuật của mạng xã hội Ả rập. Đội chúng tôi:  82;Giải phóng giải pháp: ¶ 892; xử lý vấn đề này bằng cách thao túng thời trang nghệ thuật được hình tiếng Ả Rập, AraBERT, chúng tôi tăng cường thêm những bài học đa nhiệm vụ để cho phép mô hình này học hỏi hiệu quả từ những dữ liệu nhỏ. Cách tiếp cận nhiều nhiệm vụ AraBERT của chúng ta đã đạt được vị trí thứ hai trong cả hai mặt phụ đề A. GHT, cho thấy mô hình này hoạt động liên tục trong các công việc khác nhau.', 'hr': "Korištenje platformi društvenih medija postalo je prevalentniji, što je pružilo ogromne mogućnosti da se ljudi povežu, ali je također otvorilo vrata za pogrešnu uporabu s širenjem govora mržnje i uvredljivog jezika. Ovaj fenomen vozi sve više ljudi na ekstremne reakcije i online agresiju, ponekad uzrokujući fizičku štetu pojedincima ili grupama ljudi. Postoji potreba za kontrolom i spriječavanjem takvog pogrešnog uporabe internetskih društvenih medija automatskim otkrivanjem profanog jezika. Podijeljeni zadatak o otkrivanju Offensive Language Detection na OSACT4 je cilj postići stanje umjetničkih metoda otkrivanja jezika za arapske društvene medije. Naš tim 'BERTologisti' riješio je ovaj problem, uključujući stanje umjetnosti pretvaranog arapskog jezičkog modela AraBERT, da se povećamo s dodavanjem učenja više zadataka kako bi omogućili naš model učiti efikasno iz malih podataka. Naš pristup multitask AraBERT postigao je drugo mjesto u obje podupire A & B, što pokazuje da model konsekventno izvodi na različitim zadatkima.", 'da': "Brugen af sociale medieplatforme er blevet mere udbredt, hvilket har givet enorme muligheder for mennesker til at forbinde sig, men også har åbnet døren for misbrug med spredning af hadefuld tale og krænkende sprog. Dette fænomen har drevet flere og flere mennesker til mere ekstreme reaktioner og online aggression, nogle gange forårsaget fysisk skade på enkeltpersoner eller grupper af mennesker. Der er behov for at kontrollere og forhindre sådan misbrug af sociale medier online gennem automatisk registrering af profane sprog. Den fælles opgave om Offensive Language Detection på OSACT4 har til formål at opnå avancerede profane sprogdetekteringsmetoder til arabiske sociale medier. Vores team 'BERTologists' tacklede dette problem ved at udnytte den nyeste prætrænede arabiske sprogmodel, AraBERT, som vi udvider med tilføjelsen af Multi-task learning for at gøre vores model i stand til at lære effektivt af få data. Vores Multitask AraBERT-tilgang opnåede andenpladsen i begge underopgaver A & B, hvilket viser, at modellen udfører konsekvent på tværs af forskellige opgaver.", 'nl': "Het gebruik van social media platforms is steeds vaker geworden, wat enorme mogelijkheden biedt voor mensen om verbinding te maken, maar ook de deur heeft geopend voor misbruik door de verspreiding van haatspraak en beledigende taal. Dit fenomeen heeft steeds meer mensen tot meer extreme reacties en online agressie gedreven, soms lichamelijke schade veroorzaakt aan individuen of groepen mensen. Het is noodzakelijk om dergelijk misbruik van online sociale media te beheersen en te voorkomen door automatische detectie van profane taal. De gezamenlijke taak op het OSACT4 op het gebied van offensieve taaldetectie is gericht op het bereiken van state of art profane taaldetectiemethoden voor Arabische sociale media. Ons team 'BERTologists' heeft dit probleem aangepakt door gebruik te maken van state-of-the-art voorgetraind Arabisch taalmodel, AraBERT, dat we aanvullen met de toevoeging van Multi-task learning om ons model in staat te stellen efficiënt te leren van weinig gegevens. Onze Multitask AraBERT aanpak behaalde de tweede plaats in beide subtaken A.B, wat aantoont dat het model consistent presteert over verschillende taken.", 'bg': 'Използването на социални медийни платформи стана все по-разпространено, което предостави огромни възможности на хората да се свържат, но също така отвори вратата за злоупотреба с разпространението на речта на омразата и обидните езици. Това явление кара все повече и повече хора към по-екстремни реакции и онлайн агресия, понякога причинявайки физическа вреда на индивиди или групи хора. Необходимо е да се контролира и предотврати подобна злоупотреба с онлайн социалните медии чрез автоматично откриване на нечестив език. Споделената задача за откриване на офанзивен език към ОСАКТ4 е насочена към постигане на най-съвременни методи за откриване на профан език в арабските социални медии. Екипът ни се справи с този проблем, използвайки най-съвременния модел на арабски език, който допълнихме с добавянето на многофункционално обучение, за да позволи на нашия модел да се учи ефективно от малки данни. Нашият многозадавен подход постигна второ място в двете подзадачи А и Б, което показва, че моделът изпълнява последователно различни задачи.', 'de': 'Die Nutzung von Social-Media-Plattformen ist immer häufiger geworden, was den Menschen enorme Möglichkeiten bietet, sich zu verbinden, aber auch die Tür für Missbrauch mit der Verbreitung von Hassreden und beleidigender Sprache geöffnet hat. Dieses Phänomen hat immer mehr Menschen zu extremeren Reaktionen und Online-Aggressionen getrieben, was manchmal körperlichen Schaden für Einzelpersonen oder Gruppen von Menschen verursacht. Es besteht die Notwendigkeit, diesen Missbrauch von Online-sozialen Medien durch automatische Erkennung profaner Sprache zu kontrollieren und zu verhindern. Die gemeinsame Aufgabe zum Thema Offensive Spracherkennung auf der OSACT4 zielt darauf ab, modernste Methoden zur Erkennung profaner Sprachen für arabische Social Media zu entwickeln. Unser Team "BERTologists" hat dieses Problem angegangen, indem wir das hochmoderne vortrainierte arabische Sprachmodell AraBERT nutzten, das wir um Multi-Task Learning ergänzen, damit unser Modell effizient aus wenig Daten lernen kann. Unser Multitask AraBERT Ansatz erreichte den zweiten Platz in beiden Teilaufgaben A.B, was zeigt, dass das Modell über verschiedene Aufgaben hinweg durchgängig funktioniert.', 'fa': 'استفاده از وسیله\u200cهای رسانه\u200cهای اجتماعی بیشتر گسترده شده است، که برای مردم فرصت\u200cهای بزرگی برای ارتباط به مردم داده است، ولی در برای اشتباهی استفاده با گسترده سخنرانی از نفرت و زبان فساد باز کرده است. این پدیده افراد بیشتر و بیشتر به واکنش های خارق العاده\u200cتر و حمله آنلاین رانندگی می\u200cکند، گاهی باعث آسیب فیزیکی به افراد یا گروه مردم می\u200cشود. نیازی برای کنترل و جلوگیری از این اشتباهی استفاده از رسانه های اجتماعی آنلاین از طریق کشف خودکار زبان profane وجود دارد. وظیفه مشترک در مورد شناسایی زبان ناتوانی در OSACT4 هدف گرفته است که به رسیدن وضعیت شناسایی زبان ناتوانی برای رسانه\u200cهای اجتماعی عربی رسیده شود. تیم ما «BERTologists» این مشکل را با استفاده کردن وضعیت مدل زبان عربی پیش گرفته است، آراBERT، که ما با اضافه یادگیری چندین کار را افزایش می\u200cدهیم تا مدل ما را توان تا از داده\u200cهای کوچک موثرت یاد بگیریم. دستور Multitask AraBERT ما به جای دوم در هر دو subtasks A & B رسیده است که نشان می دهد که مدل همیشه در کار مختلف انجام می دهد.', 'id': "Penggunaan platform media sosial telah menjadi lebih prevalent, yang telah menyediakan kesempatan yang luar biasa bagi orang untuk berhubungan tetapi juga telah membuka pintu untuk salah penggunaan dengan penyebaran pidato kebencian dan bahasa yang menyerang. This phenomenon has been driving more and more people to more extreme reactions and online aggression, sometimes causing physical harm to individuals or groups of people.  Ada kebutuhan untuk mengendalikan dan mencegah penyalahgunaan media sosial online melalui deteksi otomatis bahasa yang menderita. Tugas berbagi untuk Deteksi Bahasa Tersinggung di OSACT4 telah bertujuan untuk mencapai metode deteksi bahasa mendalam seni untuk media sosial Arab. Our team 'BERTologists' tackled this problem by leveraging state of the art pretrained Arabic language model, AraBERT, that we augment with the addition of Multi-task learning to enable our model to learn efficiently from little data.  Pendekatan Multitask AraBERT kami mencapai tempat kedua dalam kedua subtasks A & B, yang menunjukkan bahwa model melakukan secara konsisten melalui tugas yang berbeda.", 'ko': "소셜미디어 플랫폼의 사용이 점점 보편화되면서 사람들에게 커다란 연락 기회를 제공했지만 증오 언론과 무례한 언어의 전파에 남용의 문을 열었다.이 현상은 점점 더 많은 사람들로 하여금 극단적인 반응과 인터넷 공격을 일으키게 하고 때로는 개인이나 단체에 신체적 상처를 입힐 수도 있다.모독 언어를 자동으로 감지함으로써 이런 온라인 소셜미디어에 대한 남용을 통제하고 방지할 필요가 있다.OSACT4의 공격적 언어 검출에 관한 공동 임무는 아랍 소셜미디어를 위해 가장 선진적인 모독 언어 검출 방법을 실현하기 위한 것이다.우리의'BERTOlogists'팀은 가장 선진적인 예비훈련 아랍어 모델인 AraBERT를 이용하여 이 문제를 해결했다. 우리는 다중 임무 학습을 추가하여 이 모델을 강화하여 우리의 모델을 소량의 데이터에서 효율적으로 학습할 수 있도록 했다.우리의 다중 퀘스트 아라베트 방법은 두 개의 하위 퀘스트 A와 B에서 모두 2위를 차지했다. 이것은 이 모델이 서로 다른 퀘스트에서 일치함을 나타낸다.", 'af': "Die gebruik van sosiale media platforme het meer oorvloedig geword, wat baie moontlikhede vir mense verskaf het om te verbind maar ook die deur oopgemaak het vir misgebruik met die verspreiding van haat spreek en offensivele taal. Hierdie fenomen het meer en meer mense gedryf na meer ekstreme reaksies en online aggresie, soms veroorsaak fysiske skade aan individue of groepe van mense. Daar is 'n benodig om sodanige verkeerde gebruik van online sosiale media te beheer en voorkom deur outomaties opdekking van profane taal. Die gedeelde taak op Offensive Taal Opdekking by die OSACT4 het bedoel om staat van kuns profane taal opdekking metodes vir Arabiese sosiale media te bereik. Ons span 'BERTologists' het hierdie probleem opgesluit deur die toestand van die kuns wat die Arabiese taal model, AraBERT, voorspoedig is, dat ons met die byvoeg van Multi-taak leer het om ons model te aktiveer om effektief van klein data te leer. Ons Multitask AraBERT toegang het die tweede plek in beide subtaske A & B, wat wys dat die model konsistentlik uitvoer oor verskillende taak.", 'sw': "Utumiaji wa majukwaa ya mitandao ya kijamii umekuwa tofauti zaidi, ambayo imetoa fursa kubwa kwa watu kuwaunganisha lakini pia imefungua mlango wa matumizi ya uovu kwa kutangaza lugha ya chuki na matusi. Jambo hili limekuwa likiendesha watu zaidi kwenye miitikio mbaya zaidi na uvunjifu wa mtandaoni, wakati mwingine yanasababisha madhara ya kimwili kwa watu au makundi ya watu. Kuna haja ya kudhibiti na kuzuia matumizi yanayotokana na mitandao ya kijamii ya mtandaoni kwa njia ya kutambua lugha za kawaida. Kazi hiyo inayoshirikishwa kwenye Uthibitisho wa Lugha Huru katika OSACT4 imelenga kupata mbinu za kutambua lugha za sanaa kwa mitandao ya kijamii ya Kiarabu. Timu yetu ya 'BERTologists' walikabiliana na tatizo hili kwa kutumia hali ya sanaa iliyotangazwa na muundo wa lugha ya Kiarabu, AraBERT, kwamba tunaongeza kwa kuongeza kujifunza kazi nyingi ili kuwezesha mifano yetu kujifunza kwa ufanisi kutoka kwa takwimu ndogo. Mfumo wetu wa Multitask AraBERT ulifikia nafasi ya pili katika kazi hizo mbili za A & B, ambayo inaonyesha kuwa mtindo huu unafanya kazi mbalimbali.", 'am': 'የማኅበራዊ አውታር ሚዲያ ጦማሪያዎች ላይ የተጠቃሚ ደረጃ ሆኖአል፤ ይህም ሰዎቹን ለማግኘት ብዙ ስልጣናት ሰጥቶአል፤ ነገር ግን በጥል ንግግር እና በዓመፀኛ ቋንቋ ለመስጠት ደጁን ክፈታል፡፡ ይህ አካባቢ አካባቢ ጉዳይ የሆኑ ወይም የሕዝብ ጉዳይ አካባቢ ጉዳይ እያደረገ ይጨምሩታል፡፡ የኢንተርኔት ማኅበራዊ ሚዲያዎች በሽፋን መግለጫ እና በመግለጫ ያስፈልጋል፡፡ በOSACT4 ላይ የተካፈሉት የቋንቋ ግንኙነት የዓረብ ማኅበራዊ ሚዲያ የቋንቋ አካባቢ ቋንቋን ለማግኘት ሥርዓት አግኝቷል፡፡ የቡሬቶሎጂዎች የዐረብኛ ቋንቋ ሞዴል አርቢብERT በመስጠት የዚህን ጉዳይ አቀላቅሎታል፡፡ ብዙ ስራታችን አርቢERT ስራ በሁለቱ ስራቶች ውስጥ ሁለተኛ ስፍራን አግኝቷል፤ ምሳሌው በተለያዩ ስራዎችን እንዲያሳየው ነው፡፡', 'hy': 'Սոցիալական լրատվամիջոցների պլատֆորմների օգտագործումը դարձավ ավելի տարածված, ինչը մարդկանց համար հսկայական հնարավորություններ է տալիս կապել, բայց նաև բացել է դռները ատելության խոսքի և գրավիչ լեզուների սխալ օգտագործման համար: Այս երևույթը ավելի ու ավելի շատ մարդ է առաջացնում ավելի ծայրահեղ ռեակցիաների և առցանց ագրեսիայի վրա, երբեմն ֆիզիկական վնաս է առաջացնում անհատներին կամ մարդկանց խմբերին: There is a need to control and prevent such misuse of online social media through automatic detection of profane language.  ՕսԱԿՏ4-ի հանցագործ լեզուների հայտնաբերման հանձնարարությունը նպատակ է հասնել արաբական սոցիալական լրատվամիջոցների համար բարձր լեզուների հայտնաբերման մեթոդներին: Մեր թիմը «BERTOLOGs» լուծեց այս խնդիրը, օգտագործելով արվեստի նախավարժված արաբական լեզվի մոդելը, Արաբերթը, որը մենք ավելացնում ենք բազմախնդիրների ուսումնասիրությամբ, որպեսզի մեր մոդելը կարողանա արդյունավետ սովորել փոքր տվյալներից: Մեր բազմախնդիր Արաբերթ մոտեցումը հասավ երկրորդ տեղին երկու հարցերում A և B, ինչը ցույց է տալիս, որ մոդելը համընդհատ գործում է տարբեր խնդիրների ընթացքում:', 'sq': "Përdorimi i platformeve të medias sociale është bërë më i përhapur, e cila ka ofruar mundësi të mëdha për njerëzit për të lidhur, por ka hapur gjithashtu derën për keqpërdorim me përhapjen e fjalimit të urrejtjes dhe gjuhës ofensive. Ky fenomen ka qenë duke nxitur gjithnjë e më shumë njerëz në reagime më ekstreme dhe agresion online, ndonjëherë duke shkaktuar dëm fizik ndaj individëve apo grupeve të njerëzve. Ka nevojë të kontrollohet dhe të parandalohet një përdorim i tillë i keq i mediave sociale online nëpërmjet zbulimit automatik të gjuhës së poshtme. Detyra e përbashkët për zbulimin e gjuhës ofensive në OSACT4 ka për qëllim arritjen e metodave të zbulimit të gjuhës së poshtme për mediat sociale arabe. Ekipi ynë 'BERTologë' trajtoi këtë problem duke nxitur nga modeli i gjuhës arabe të stërvitur më parë, AraBERT, që ne shtojmë me shtimin e mësimit multidetyror për të mundësuar modelin tonë të mësojë me efektshmëri nga të dhënat e vogla. Përqasja jonë e shumëdetyrës AraBERT arriti vendin e dytë në të dy nëndetyrat A & B, që tregon se modeli kryen vazhdimisht nëpërmjet detyrave të ndryshme.", 'bs': "Koristenje platformi društvenih medija postalo je prevalentije, što je pružilo ogromne mogućnosti da se ljudi povežu, ali je također otvorilo vrata za nepravdu korištenje širenjem govora mržnje i ofanzivnog jezika. Ovaj fenomen vozi sve više ljudi na ekstremne reakcije i online agresiju, ponekad uzrokujući fizičku štetu pojedincima ili grupama ljudi. Postoji potreba za kontrolom i sprečavanjem takvog pogrešnog upotrebe internetskih društvenih medija automatskim otkrivanjem profanog jezika. Podijeljeni zadatak o otkrivanju Offensive jezika na OSACT4 je cilj ostvariti državu metoda otkrivanja umjetnosti profane jezika za arapske socijalne medije. Naš tim 'BERTologisti' je riješio ovaj problem, uključujući stanje umjetnosti, pretvarajući arapski jezički model, AraBERT, da se povećamo sa dodavanjem učenja mnogobrojnih zadataka kako bi omogućili naš model da uči efikasno od malih podataka. Naš pristup multitask AraBERT postigao je drugo mjesto u obje podupire A & B, što pokazuje da se model konsekventno izvršava u različitim zadacima.", 'bn': "সামাজিক মিডিয়া প্ল্যাটফর্ম ব্যবহারের ব্যবহার আরো বেশী ভালো হয়ে গেছে, যা মানুষের সাথে যোগাযোগ করার জন্য বিশাল সুযোগ প্রদান করেছে, কিন্ত এই ঘটনাটি আরো বেশী লোককে চালানো হচ্ছে অত্যন্ত কঠিন প্রতিক্রিয়া এবং অনলাইন আক্রমণের দিকে, মাঝে মাঝে মাঝে মাঝে মাঝে মানুষ বা দলে অনলাইন সোশ্যাল মিডিয়ার ভুল ব্যবহার এবং স্বয়ংক্রিয় ভাষার মাধ্যমে নিয়ন্ত্রণ ও নিয়ন্ত্রণের প্রয়োজন। ওসাক্ট৪-এর অফেন্সিভ ভাষা ডিটেক্টরেশনে শেয়ার করা কাজ আরবী সামাজিক মিডিয়ার জন্য শিল্পের প্রোফাইন ভাষা সনাক্তির পদ্ধতি  Our team 'BERTologists' tackled this problem by leveraging state of the art pretrained Arabic language model, AraBERT, that we augment with the addition of Multi-task learning to enable our model to learn efficiently from little data.  আমাদের মাল্টিকাজ আরাবেরেটি প্রতিযোগিতা এ এবং বি সাবটাকাজের দ্বিতীয় স্থান পৌঁছেছে, যা দেখাচ্ছে যে মডেল বিভিন্ন কা", 'cs': 'Využívání platformy sociálních médií se stalo rozšířenější, což poskytlo obrovské příležitosti pro spojení lidí, ale také otevřelo dveře pro zneužití s šířením nenávistných projevů a urážlivých jazyků. Tento jev dohání stále více a více lidí k extrémnějším reakcím a online agresi, někdy způsobuje fyzické újmy jednotlivcům nebo skupinám lidí. Takovému zneužívání on-line sociálních médií je třeba kontrolovat a předcházet prostřednictvím automatické detekce profanního jazyka. Společný úkol v oblasti detekce urážlivého jazyka na OSACT4 má za cíl dosáhnout nejmodernějších metod detekce profanních jazyků pro arabské sociální média. Náš tým BERTolologů tento problém řešil využitím nejmodernějšího předškoleného arabského jazykového modelu AraBERT, který jsme rozšířili o víceúkolové učení, aby se náš model efektivně učil z malého množství dat. Náš multitasking AraBERT přístup dosáhl druhého místa v obou dílčích úkolech A.B, což ukazuje, že model plní konzistentně napříč různými úkoly.', 'ca': "L'ús de plataformes de mitjans socials ha esdevingut més prevalent, que ha proporcionat tremendas oportunitats per a la gent de connectar-se, però també ha obrit la porta per mal-ús amb la difusió del discurs d'odi i del llenguatge ofensiu. Aquest fenomen ha estat portant cada cop més gent a reaccions més extremes i agressions en línia, a vegades causant dany físic a individus o grups de persones. Hi ha la necessitat de controlar i prevenir aquest abus dels mitjans socials en línia a través de la detecció automàtica de llenguatges profans. La tasca compartida sobre la detecció ofensiva de llenguatges a l'OSACT4 ha mirat a aconseguir mètodes de detecció profans de llenguatges d'última generació per als mitjans socials àrabs. El nostre equip 'BERTologists' va abordar aquest problema aprofitant el model de llenguatge àrab pré-treinad, AraBERT, que augmenta amb l'afecció d'aprenentatge multitascat per a que el nostre model aprenga eficientment amb poces dades. El nostre enfocament d'AraBERT Multitasca va aconseguir el segon lloc en les dues subtaskes A & B, que demostra que el model actua consistentment en diverses tasques.", 'az': "Sosyal mediya platformlarının istifadəsi daha genişdir. Bu insanların bağlanması üçün böyük fırsatlar sağladı, lakin həmçinin nifrət sözlərini və düşmənçilik dillərini yaymaq üçün qapıları də açdı. Bu fenomen daha çox insanları daha ekstrem reaksiya və onlayn agresiya sürükləyir, bəzən insanlara və insanların dəstələrinə fiziki zərər verir. İnternettə sosyal media istifadəsindən böyük yanlış istifadə etməyi və təhlükəsizlik etməyi tələb edir. OSACT4'deki Offensive Dil İşlənməsi haqqında paylaşılan işlər ərəb sosyal media üçün sanat çətin dillərini keşfetmə metodlarına nəticə etdi. Bizim ekibimiz 'BERTologists' bu problemi, sanatımızın əvvəlcə ərəb dil modelinin, AraBERT modelini təmin edib, çoxlu işlər öyrənməsini art ırmaq üçün modelimizi kiçik məlumatlardan faydalı öyrənmək üçün çoxlu işlər öyrənməsi ilə çəkildi. Bizim çoxlu işimiz AraBERT tərəfimiz hər ikisinin A & B subtasklarında ikinci yeri başa düşdü. Bu modellərin müxtəlif işlər arasında sürəkləndiyini göstərir.", 'fi': 'Sosiaalisen median alustojen käyttö on yleistynyt, mikä on tarjonnut ihmisille suunnattomia mahdollisuuksia yhteydenpitoon, mutta on myös avannut oven väärinkäytölle vihapuheen ja loukkaavan kielen leviämisen myötä. Tämä ilmiö on ajanut yhä useampia ihmisiä äärimmäisiin reaktioihin ja verkkoaggressioon, aiheuttaen joskus fyysistä haittaa yksilöille tai ihmisryhmille. Verkkososiaalisen median väärinkäyttöä on valvottava ja estettävä tunnistamalla epäpyhä kieli automaattisesti. OSACT4:n yhteinen tehtävä hyökkäävän kielen havaitsemisesta on pyrkinyt saavuttamaan arabialaiseen sosiaaliseen mediaan viimeisimpiä profaanien kielen havaitsemismenetelmiä. Tiimimme "BERTologist" tarttui tähän ongelmaan hyödyntämällä viimeisintä esiasennettua arabiankielimallia, AraBERT, jota lisäämme Multi-task learning -oppimiseen, jotta mallimme oppisi tehokkaasti pienestä datasta. Multitask AraBERT -lähestymistapamme saavutti toisen sijan molemmissa osatehtävissä A ja B, mikä osoittaa, että malli toimii johdonmukaisesti eri tehtävissä.', 'tr': "Sosialy mediýal platformlarynyň ulanmagy köp kän bolup geçdi. Bu adamlar bilen baglaşmak üçin örän mümkinçilik berdi ýöne ýigrenýän sözlerini we alçak dillerini ýalňyşlyk bilen gapyny açdyr. Bu äpişgär birnäçe adamlary ýokary ýigrenç reaksiýa we online agresiýa sürüp ýöredi. Käwagt adamlary ýa-da adamlaryň toparyna fizik bir urşa bolup ýöredi. Çaltylyk sosial medýýatlaryň şeýle ýalňyşlygyny otomatik dilini tanyşyp bilen kontrol etmeli we önlemeli bolmaly. OSACT4'de Offensive Dil Taýýarlamakynyň (offensive dil) meýdançasynda sungat täsirini tapmak üçin amaçlady. Biziň topamyz 'BERTologistler' sungat dili nusgasyny arap dilinden öňünden öwrenmek üçin bu meseleyi çözdi. Biziň köp işimiz AraBERT ýaryşymyz ikinji ýerini A & B subtesasynda ýetirdi. Bu nusga dürli işlerde hemişe ýetirýändigini görkez.", 'et': 'Sotsiaalmeedia platvormide kasutamine on muutunud levinumaks, mis on andnud inimestele tohutuid võimalusi suhelda, kuid on avanud ukse ka väärkasutamisele vihakõne ja solvava keele leviku tõttu. See nähtus on ajendanud üha rohkem inimesi äärmuslikumate reaktsioonide ja online-agressiooni, põhjustades mõnikord füüsilist kahju üksikisikutele või inimrühmadele. On vaja kontrollida ja ennetada sellist sotsiaalmeedia väärkasutamist internetis profaanse keele automaatse tuvastamise kaudu. OSACT4 ründava keele tuvastamise jagatud ülesande eesmärk on saavutada araabia sotsiaalmeedia jaoks kõrgetasemelised profaanse keele tuvastamise meetodid. Meie meeskond "BERTologists" lahendas selle probleemi, kasutades kaasaegset haritud araabia keele mudelit AraBERT, mida me täiendame mitme ülesandega õppimisega, et meie mudel saaks tõhusalt õppida vähestest andmetest. Meie Multitask AraBERT lähenemine saavutas teise koha mõlemas alamülesandes A ja B, mis näitab, et mudel toimib järjepidevalt erinevates ülesannetes.', 'ha': "Amfanin mitandai na jamii ya kasance mafi fassar, wannan da ya ba da fursa mai girma ga mutane su yi haɗi kuma ya buɗe ƙõfõfi dõmin misuse da gafi na faɗin haske da ƙyacẽwar. Wannan abu na tafiyar da wasu mutane da ke ƙara zuwa kashi mai sauri da bakin taraki da bakin tarakin Online, ko da yaushe yana kusa ya yi hasara ga mutane ko jama'a guda. Tilas ne aka buƙata domin su kange kuma ka kange misuse daga wannan, wa'anar mutane na mitandai na ƙarami tare da za'a gane lugha farat ɗaya. The share of the job on Ferrative Lugha Afghanistan at the OSAct4 aims to achieve state of art profane language for language profane wa media in Arabic. Team 'BERTologists' sun motsa wannan mataimaki da kutuma ma ma'aunin kunyar da aka fassara misalin harshen Larabci, AraBERT, cẽwa, za mu ƙara da ƙara wa masu aikin da za'a karanta mulki-aikin da za'a iya amfani da misalinmu da ya sanar da fasahan daki kaɗan. MataimakinMu na mulki AraBERT ya sãmu na biyu a cikin laban aikin A & B, wanda ke nũna ayukan misalin su da daidai a cikin aikin dabam-daban.", 'he': 'השימוש במתקנות התקשורת החברתית הופך לשתלטות יותר, אשר סיפק הזדמנויות עצומות לאנשים להתחבר, אך גם פתח את הדלת לשימוש לא נכון עם התפשטות של נאום שנאה ושפה מעליבה. התופעה הזאת גורמת יותר ויותר אנשים לתגובות קיצוניים ויותר אגרסיה באינטרנט, לפעמים גורמת לפגיעה פיזית לאדם או לקבוצות אנשים. יש צורך לשלוט ולמנע אי-השימוש כזה של תקשורת חברתית באינטרנט דרך גילוי אוטומטי של שפה עלובה. The shared task on Offensive Language Detection at the OSACT4 has aimed at achieving state of art profane language detection methods for Arabic social media.  הצוות שלנו "ברטולוגים" התמודד עם הבעיה הזאת על ידי השימוש במצב המיוחד של מודל השפה הערבית המואמן מראש, ארברט, שאנחנו מגדלים עם ההוספת של למידת משימות רבות כדי לאפשר למדל שלנו ללמוד בצורה יעילה ממידע קטן. הגישה שלנו לאראברט השיגה את המקום השני בשני השאלות A & B, מה שמראה שהמודל מבצע באופן קבוע בכל משימות שונות.', 'bo': "སྤྱི་ཚོགས་འབྲེལ་མཐུད་འབྲེལ་མཐུད་ལམ་གླེང་སྤྱི་ཚོགས་ཀྱི་གླེང་སྒྲོམ་གྱི་ལག་སྟར་མང་ཆེ་མཐུད་ཡོད། དེ་ནི་མི་མང་ཚོས་སྦྲེལ་མཐུད་དང་། འགྱུར་བརྗོད སྣང་ཚུལ་འདི་གིས་མི་མང་ཆེ་མཐོང་འགྱུར་བ་དང་དྲ་རྒྱའི་སྐྱུར་བརྗོད་ཀྱི་འགྱུར་བ་མང་ཙམ་སྐྱེས་བ་ཡིན། རེ་ཚན་ཡང་མི་མང་ཚོའི་མི་ས སྐད་རིགས་རང་འགུལ་གྱིས་དྲ་རྒྱའི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་བ་རང་འགུལ་གྱིས་དྲ་བ་རྟོགས་དགོས་པ OSACT4 ནང་དུ་Offensive Language Detection (Offensive Language Detection) ལ་དམིགས་ཡུལ་ནི་སྒྱུ་རྩལ་ཆེན་གཏོང་བའི་སྐད་རིགས་རྟོགས་ཐབས་ལམ་ལ་འཇུག་པ་དང་། Our team 'BERTologists' tackled this problem by leveraging state of the art pretrained Arabic language model, AraBERT, that we augment with the addition of Multi-task learning to enable our model to learn efficiently from little data. ང་ཚོའི་སྣ་མང་བྱ་ཚིག་AraBERT གཟུགས་སྐོར་གཉིས་པ་ནང་གི་ཕྱོགས་གཉིས་པ་དེ་གཉིས་ཀྱིས་ཐུབ་པ་ཡིན། བྱ་རིམ་འདི་མི་འདྲ་བའི་བྱ་", 'jv': "Ngawe nguwe sistem media sothik dumadhi iki, awak dhéwé éntuk akeh perusahaan kanggo wong liya sing dumadhi iki dadi bisa ngukaké aturan kapungot kanggo nguasai perusahaan kanggo kebebasan langkung ora tau. Awak-awak iki lak mudhik liya lan bantuan luwih dumadhi sak ngerasah luwih karo hal-hal supaya karo perusahaan online, sira lak ngelasai perusahaan bakal perusahaan karo perusahaan uwong karo perusahaan uwong. Kayané kudu nguasai karo akeh pengguna kuwi ora oleh nggawe media sotiki ngono kuwi jenis, ora ngerasai tanggal sapa-tanggal kuwi kudu. OPENDECKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKARKAR Awak dhéwé 'BERT logists' nambah perbudhakan iki dadi nggawe geranglangno karo hal basa sing dirangkat langgambar arab, araBERT, wong dhéwé uga ngono nambah Multi-task lan sampek multi-task sing iso dianggap modelu dhéwé iso nggawe barang penggunaké susahé data sithik. Ndheke Multitask araBERT nambah sing wis rampung neng sampeyan segondi apa banjur A lan B, sing ngomongke tindakan modèl kuwi sampeyan sak dadi bisa-sampeyan gawe nguasakno", 'sk': 'Uporaba platform socialnih omrežij je postala vse bolj prevladujoča, kar je ljudem zagotovilo ogromne priložnosti za povezovanje, vendar je odprlo tudi vrata zlorabam s širjenjem sovražnega govora in žaljivega jezika. Ta pojav vedno več ljudi vodi do skrajnejših reakcij in spletne agresije, kar včasih povzroča telesno škodo posameznikom ali skupinam ljudi. Takšno zlorabo spletnih družbenih medijev je treba nadzorovati in preprečiti s samodejnim zaznavanjem profanega jezika. Skupna naloga o odkrivanju ofenzivnih jezikov v OSACT4 je bila namenjena doseganju najsodobnejših metod odkrivanja profanskih jezikov za arabske družbene medije. Naša ekipa "BERTologists" se je težavo lotila z uporabo najsodobnejšega predvadljenega arabskega jezikovnega modela AraBERT, ki ga dopolnjujemo z dodatkom večopravilnega učenja, da bi naš model učinkovito učil iz majhnih podatkov. Naš Multitask AraBERT pristop je dosegel drugo mesto v obeh podnalogah A in B, kar kaže, da model dosledno deluje pri različnih nalogah.'}
