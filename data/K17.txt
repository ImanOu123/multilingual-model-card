{'en': 'Should Neural Network Architecture Reflect Linguistic Structure?', 'ar': 'هل يجب أن تعكس بنية الشبكة العصبية الهيكل اللغوي؟', 'fr': "L'architecture du réseau neuronal doit-elle refléter la structure linguistique\xa0?", 'pt': 'A arquitetura de rede neural deve refletir a estrutura linguística?', 'es': '¿Debería la arquitectura de red neuronal reflejar la estructura lingüística', 'ja': 'ニューラルネットワークアーキテクチャは言語構造を反映すべきか？', 'zh': '神经网络架构当言构乎?', 'hi': 'क्या तंत्रिका नेटवर्क आर्किटेक्चर भाषाई संरचना को प्रतिबिंबित करना चाहिए?', 'ru': 'Должна ли архитектура нейронной сети отражать лингвистическую структуру?', 'ga': "Ar cheart d'Ailtireacht Líonra Néarach Léiriú ar Struchtúr Teangeolaíoch?", 'el': 'Πρέπει η αρχιτεκτονική νευρωνικών δικτύων να αντανακλά τη γλωσσική δομή;', 'hu': 'A neurális hálózati architektúra tükrözze a nyelvi struktúrát?', 'ka': 'ნეირალური ქსელის აქტიქტურის რეფლექტიკური ლინგუტიკური სტრუქტურა?', 'it': "L'architettura di rete neurale dovrebbe riflettere la struttura linguistica?", 'lt': 'Ar neurologinio tinklo architektūra turėtų atspindėti kalbinę struktūrą?', 'kk': 'Нейрондық желінің архитектурасы лингвистикалық құрылымын рефлектеу керек пе?', 'mk': 'Дали неуралната мрежна архитектура треба да ја одрази јазичката структура?', 'ms': 'Haruskah Arkitektur Rangkaian Neural mencerminkan Struktur Bahasa?', 'mt': 'L-Arkitettura tan-Netwerk Newrali għandha tirrifletti l-Istruttura Lingwistika?', 'ml': 'നെയുറല്\u200d നെറ്റര്\u200dവര്\u200dക്ക് ആര്\u200dക്ടിക്കേച്ചര്\u200d ലിങ്ഗിസ്റ്റിക്ക് സ്ട്രാക്ട്രൂട്ടിക്ക് പ്രത', 'mn': 'Цөмийн сүлжээний архитектур хэлбэрийн бүтэц шийдвэрлэх хэрэгтэй юу?', 'no': 'Skal nøyrale nettverkstarkitektur reflektere lingsstruktur?', 'pl': 'Czy architektura sieci neuronowej powinna odzwierciedlać strukturę językową?', 'ro': 'Ar trebui arhitectura rețelei neurale să reflecte structura lingvistică?', 'sr': 'Da li bi trebala da reflektuje Lingističku strukturu neuronske mreže?', 'so': 'Shabakadda netka Neural Architecture miyey ka fikiraan dhismaha Linguistic?', 'si': 'න්\u200dයුරල් ජාලය සංවිධානය සංවිධානය ප්\u200dරතික්\u200dරමණය කරන්න ඕනේ?', 'sv': 'Bör neural nätverksarkitektur reflektera språklig struktur?', 'ta': 'புதிய வலைப்பின்னல் பிணைப்பு உருவாக்கத்தை பிரதிபலிக்கவேண்டுமா?', 'ur': 'نیورال نیٹ ورک آرکٹیکٹر لینگیسٹی ساختار کو دفع کرنا چاہیے؟', 'uz': 'Name', 'vi': 'Có nên phản xạ ngôn ngữ học không?', 'bg': 'Трябва ли архитектурата на невралната мрежа да отразява езиковата структура?', 'nl': 'Zou neuronale netwerkarchitectuur een weerspiegeling moeten zijn van taalkundige structuur?', 'hr': 'Da li bi trebala Reflektirati Lingističku strukturu neuronske mreže?', 'da': 'Skal neural netværksarkitektur afspejle sproglig struktur?', 'id': 'Haruskah Arkitektur Jaringan Neural mencerminkan Struktur Bahasa?', 'de': 'Sollte neuronale Netzwerkarchitektur sprachliche Strukturen widerspiegeln?', 'fa': 'باید معماری شبکه عصبی ساختار لینگیستیک را برگرداند؟', 'ko': '신경 네트워크 구조는 언어 구조를 반영해야 합니까?', 'sw': 'Je, Mtandao wa Kihistoria wa Neurali lazima tafakari Mradi wa Kilinguistic?', 'af': 'Moet Neural Network Architecture Reflect Linguistic Structure?', 'tr': 'Nural Network Architecture Reflect Linguistic Structure?', 'sq': 'A duhet arkitektura e rrjetit nervor të reflektojë strukturën gjuhësore?', 'hy': 'Արդյո՞ք նյարդային ցանցի արխեկտությունը արտացոլում է լեզվական կառուցվածքը:', 'am': 'የኔural መረብ መዝገብ መዝገብ ማሳየት ይችላልን?', 'az': 'Nöral Ağ Arhitektura Linguistik Structure Reflect?', 'bs': 'Da li bi trebala Reflektovati Lingističku strukturu neuronske mreže?', 'ca': "L'arquitectura de la xarxa neuronal hauria de reflexionar sobre l'estructura lingüística?", 'bn': 'নিউরেল নেটওয়ার্ক আর্কিটেক্টার লিঙ্গিস্টিক কাঠামো প্রতিফলিত করা উচিত?', 'cs': 'Měla by architektura neuronových sítí odrážet jazykovou strukturu?', 'et': 'Kas neurovõrgu arhitektuur peaks peegeldama keelelist struktuuri?', 'fi': 'Pitäisikö neuroverkkoarkkitehtuurin heijastaa kielellistä rakennetta?', 'jv': 'Arep akèh seneng Artiktur Neral Network Reflete Linguistik structural ?', 'ha': '@ action: button', 'sk': 'Ali mora arhitektura nevronskih omrežij odražati jezikovno strukturo?', 'he': 'האם ארכיטקטורת הרשת העצבית צריכה לחשוב על מבנה שפתי?', 'bo': 'སྒེར་གྱི་དྲ་དམངས་སྒྲིག་འགོད་ལ་ངོས་འཛིན་གྱི་སྒྲིག་འགོད་དགོས་སམ།'}
{'en': 'I explore the hypothesis that conventional neural network models (e.g., recurrent neural networks) are incorrectly biased for making linguistically sensible generalizations when learning, and that a better class of models is based on architectures that reflect hierarchical structures for which considerable behavioral evidence exists. I focus on the problem of modeling and representing the meanings of sentences. On the generation front, I introduce recurrent neural network grammars (RNNGs), a joint, generative model of phrase-structure trees and sentences. RNNGs operate via a recursive syntactic process reminiscent of probabilistic context-free grammar generation, but decisions are parameterized using RNNs that condition on the entire (top-down, left-to-right) syntactic derivation history, thus relaxing context-free independence assumptions, while retaining a bias toward explaining decisions via syntactically local conditioning contexts. Experiments show that RNNGs obtain better results in generating language than models that do n’t exploit linguistic structure. On the representation front, I explore unsupervised learning of syntactic structures based on distant semantic supervision using a reinforcement-learning algorithm. The learner seeks a syntactic structure that provides a compositional architecture that produces a good representation for a downstream semantic task. Although the inferred structures are quite different from traditional syntactic analyses, the performance on the downstream tasks surpasses that of systems that use sequential RNNs and tree-structured RNNs based on treebank dependencies. This is joint work with Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, and Noah A. Smith.', 'ar': 'أستكشف الفرضية القائلة بأن نماذج الشبكة العصبية التقليدية (على سبيل المثال ، الشبكات العصبية المتكررة) متحيزة بشكل غير صحيح لإصدار تعميمات منطقية لغويًا عند التعلم ، وأن فئة أفضل من النماذج تعتمد على البنى التي تعكس الهياكل الهرمية التي يوجد لها دليل سلوكي كبير. أركز على مشكلة النمذجة وتمثيل معاني الجمل. على صعيد التوليد ، أعرض القواعد النحوية للشبكة العصبية المتكررة (RNNGs) ، وهي نموذج مشترك وتوليدي لأشجار وجمل بنية العبارات. تعمل RNNGs عبر عملية نحوية متكررة تذكرنا بتوليد القواعد النحوية الخالية من السياق الاحتمالي ، ولكن يتم تحديد المعلمات باستخدام RNNs التي تشترط على كامل سجل الاشتقاق النحوي (من أعلى إلى أسفل ومن اليسار إلى اليمين) ، وبالتالي تخفيف افتراضات الاستقلال الخالية من السياق ، مع الاحتفاظ بالتحيز تجاه شرح القرارات عبر سياقات تكييف "محلية نحوية". تظهر التجارب أن RNNGs تحصل على نتائج أفضل في توليد اللغة من النماذج التي لا تستغل البنية اللغوية. على جبهة التمثيل ، أستكشف التعلم غير الخاضع للإشراف للهياكل النحوية بناءً على الإشراف الدلالي البعيد باستخدام خوارزمية التعلم المعزز. يسعى المتعلم إلى بنية نحوية توفر بنية تركيبية تنتج تمثيلًا جيدًا لمهمة دلالي المصب. على الرغم من اختلاف الهياكل المستنبطة تمامًا عن التحليلات النحوية التقليدية ، إلا أن\nيتجاوز الأداء في مهام المصب أداء الأنظمة التي تستخدم شبكات RNN المتسلسلة وشبكات RNN الهيكلية الشجرية استنادًا إلى تبعيات بنك الشجرة. هذا عمل مشترك مع Adhi Kuncoro و Dani Yogatama و Miguel Ballesteros و Phil Blunsom و Ed Grefenstette و Wang Ling و Noah A. Smith.', 'fr': "J'explore l'hypothèse selon laquelle les modèles de réseaux neuronaux conventionnels (par exemple, les réseaux neuronaux récurrents) sont faussement biaisés pour faire des généralisations linguistiquement sensibles lors de l'apprentissage, et qu'une meilleure classe de modèles est basée sur des architectures qui reflètent des structures hiérarchiques pour lesquelles il existe des preuves comportementales. Je me concentre sur le problème de la modélisation et de la représentation du sens des phrases. Sur le front des générations, j'introduis des grammaires de réseaux neuronaux récurrents (RNNG), un modèle génératif conjoint d'arbres de structure de phrases et de phrases. Les RNNG fonctionnent via un processus syntaxique récursif qui rappelle la génération de grammaire probabiliste sans contexte, mais les décisions sont paramétrées à l'aide de RNN qui conditionnent l'historique complet de dérivation syntaxique (de haut en bas, de gauche à droite), assouplissant ainsi les hypothèses d'indépendance sans contexte, tout en conservant un biais pour expliquer les décisions via des contextes de conditionnement «\xa0syntaxiquement locaux\xa0». Les expériences montrent que les RNNG obtiennent de meilleurs résultats en matière de génération de langage que les modèles qui n'exploitent pas la structure linguistique. Sur le plan de la représentation, j'explore l'apprentissage non supervisé de structures syntaxiques basé sur une supervision sémantique distante à l'aide d'un algorithme d'apprentissage par renforcement. L'apprenant recherche une structure syntaxique qui fournit une architecture compositionnelle qui produit une bonne représentation pour une tâche sémantique en aval. Bien que les structures déduites soient très différentes des analyses syntaxiques traditionnelles, les\nles performances sur les tâches en aval dépassent celles des systèmes qui utilisent des RNN séquentiels et des RNN structurés en arborescence basés sur des dépendances de banques d'arbres. Il s'agit d'une collaboration avec Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling et Noah A. Smith.", 'pt': 'Eu exploro a hipótese de que os modelos convencionais de redes neurais (por exemplo, redes neurais recorrentes) são incorretamente tendenciosos para fazer generalizações linguisticamente sensatas ao aprender, e que uma classe melhor de modelos é baseada em arquiteturas que refletem estruturas hierárquicas para as quais existem evidências comportamentais consideráveis. Concentro-me no problema de modelar e representar os significados das frases. Na frente de geração, apresento gramáticas de redes neurais recorrentes (RNNGs), um modelo conjunto e generativo de árvores e sentenças de estrutura de frase. As RNNGs operam por meio de um processo sintático recursivo que lembra a geração probabilística de gramática livre de contexto, mas as decisões são parametrizadas usando RNNs que condicionam todo o histórico de derivação sintática (de cima para baixo, da esquerda para a direita), relaxando assim as suposições de independência livre de contexto, enquanto mantém um viés para explicar as decisões através de contextos de condicionamento “sintaticamente locais”. Experimentos mostram que RNNGs obtêm melhores resultados na geração de linguagem do que modelos que não exploram a estrutura linguística. Na frente da representação, exploro o aprendizado não supervisionado de estruturas sintáticas com base na supervisão semântica à distância usando um algoritmo de aprendizado por reforço. O aprendiz procura uma estrutura sintática que forneça uma arquitetura composicional que produza uma boa representação para uma tarefa semântica posterior. Embora as estruturas inferidas sejam bastante diferentes das análises sintáticas tradicionais, a\no desempenho nas tarefas de downstream supera o de sistemas que usam RNNs sequenciais e RNNs estruturados em árvore com base em dependências de banco de árvores. Este é um trabalho conjunto com Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling e Noah A. Smith.', 'ja': '私は、従来のニューラルネットワークモデル（例えば、再発ニューラルネットワーク）は、学習するときに言語学的に合理的な一般化を行うために誤って偏っているという仮説を探求し、より良いクラスのモデルは、相当な行動の証拠が存在する階層構造を反映するアーキテクチャに基づいているという仮説を探求する。 文章の意味をモデリングし、表現する問題に焦点を当てています。 世代別では、語句構造木と文の共同生成モデルである再帰的ニューラルネットワーク文法（ RNNG ）を紹介する。 RNNGは、確率論的な文脈自由文法生成を想起させる再帰的な構文プロセスを介して動作するが、決定は、（トップダウン、左から右へ）構文導出履歴全体を条件とするRNNを使用してパラメータ化され、したがって、文脈自由独立性の仮定を緩和する一方で、「構文的にローカルな」条件付け文脈を介して決定を説明するためのバイアスを維持する。 実験によると、RNNGは、言語構造を利用しないモデルよりも、言語生成において優れた結果を得ることが示されている。 表現面では、強化学習アルゴリズムを使用して、遠隔の意味論的監視に基づく構文構造の無監督学習を探求する。 学習者は、下流の意味論的タスクの良い表現を生み出す構成的アーキテクチャを提供する構文構造を求める。 推測される構造は、従来の構文解析とはかなり異なりますが、\nダウンストリームタスクのパフォーマンスは、ツリーバンク依存性に基づくシーケンシャルRNNおよびツリー構造化RNNを使用するシステムのパフォーマンスを上回る。これはAdhi Kuncoro、Dani Yogatama、Miguel Ballesteros、Phil Blunsom、Ed Grefenstette、Wang Ling、Noah A. Smithとの共同作品です。', 'es': 'Exploro la hipótesis de que los modelos de redes neuronales convencionales (por ejemplo, las redes neuronales recurrentes) están incorrectamente sesgados para hacer generalizaciones lingüísticamente sensatas durante el aprendizaje, y que una mejor clase de modelos se basa en arquitecturas que reflejan estructuras jerárquicas para las que existe evidencia de comportamiento. Me centro en el problema de modelar y representar los significados de las oraciones. En el frente de la generación, introduzco gramáticas de redes neuronales recurrentes (RNNGs), un modelo generativo conjunto de oraciones y árboles de estructura de frases. Las RNNG operan a través de un proceso sintáctico recursivo que recuerda a la generación probabilística de gramática libre de contexto, pero las decisiones se parametrizan utilizando RNN que condicionan todo el historial de derivaciones sintácticas (de arriba hacia abajo, de izquierda a derecha), relajando así las suposiciones de independencia sin contexto, manteniendo un sesgo para explicar las decisiones a través de contextos de condicionamiento «sintácticamente locales». Los experimentos muestran que las RNNGs obtienen mejores resultados en la generación de lenguaje que los modelos que no explotan la estructura lingüística. En el frente de la representación, exploro el aprendizaje no supervisado de estructuras sintácticas basado en la supervisión semántica a distancia utilizando un algoritmo de aprendizaje por refuerzo. El alumno busca una estructura sintáctica que proporcione una arquitectura compositiva que produzca una buena representación para una tarea semántica posterior. Aunque las estructuras inferidas son muy diferentes de los análisis sintácticos tradicionales, el\nel rendimiento en las tareas descendentes supera al de los sistemas que utilizan RNN secuenciales y RNN estructurados en árbol basados en dependencias de bancos de árboles. Este es un trabajo conjunto con Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling y Noah A. Smith.', 'zh': '余求其伪设,即古之神经网络模(,递归神经网络)误于言理,而善者基于层次结构架构,有大征矣。 余专注于建模、示句之义。 吾言递归神经网络语法(RNNGs),短语结构树句也。 RNNG行于递归句法,使人思概率上下文无关于语法,而决策用RNN参数化,此RNN以全(自上而下,从左到右)句法使生为资,而宽上下文无关之独立性设,而存句法本地条件反射上下文以决其偏也。 实验明,比于不言之形,NNNG于语言之善者也。 吾以强化学算法探远语义监者句法无监督学也。 学者求一语法结构,合一体系结构,可以为下流语义务成文章。 虽推结与古句法异同,然亦异也\n下流过用次 RNN 基于树库恃树 RNN 之统。 此与Adhi Kuncoro,Dani Yogatama,Miguel Ballesteros,Phil Blunsom,Ed Grefenstette,Wang Ling与Noah A. Smith合事也。', 'hi': 'मैं इस परिकल्पना का पता लगाता हूं कि पारंपरिक तंत्रिका नेटवर्क मॉडल (उदाहरण के लिए, आवर्तक तंत्रिका नेटवर्क) सीखने के दौरान भाषाई रूप से समझदार सामान्यीकरण बनाने के लिए गलत तरीके से पक्षपाती हैं, और यह कि मॉडल का एक बेहतर वर्ग आर्किटेक्चर पर आधारित है जो पदानुक्रमित संरचनाओं को प्रतिबिंबित करता है जिसके लिए काफी व्यवहारिक साक्ष्य मौजूद हैं। मैं मॉडलिंग की समस्या पर ध्यान केंद्रित करता हूं और वाक्यों के अर्थों का प्रतिनिधित्व करता हूं। पीढ़ी के मोर्चे पर, मैं आवर्तक तंत्रिका नेटवर्क व्याकरण (आरएनएनजी) पेश करता हूं, जो वाक्यांश-संरचना के पेड़ों और वाक्यों का एक संयुक्त, उत्पादक मॉडल है। RNNGs एक पुनरावर्ती वाक्यात्मक प्रक्रिया के माध्यम से काम करते हैं जो संभाव्य संदर्भ-मुक्त व्याकरण पीढ़ी की याद दिलाता है, लेकिन निर्णय RNNs का उपयोग करके पैरामीटर किए जाते हैं जो पूरे (ऊपर-नीचे, बाएं-से-दाएं) वाक्यात्मक व्युत्पत्ति इतिहास पर स्थिति रखते हैं, इस प्रकार संदर्भ-मुक्त स्वतंत्रता मान्यताओं को आराम देते हैं, जबकि "वाक्यात्मक रूप से स्थानीय" कंडीशनिंग संदर्भों के माध्यम से निर्णयों को समझाने की दिशा में एक पूर्वाग्रह को बनाए रखते हैं। प्रयोगों से पता चलता है कि RNNGs उन मॉडलों की तुलना में भाषा उत्पन्न करने में बेहतर परिणाम प्राप्त करते हैं जो भाषाई संरचना का शोषण नहीं करते हैं। प्रतिनिधित्व के मोर्चे पर, मैं एक सुदृढीकरण-सीखने के एल्गोरिथ्म का उपयोग करके दूर के शब्दार्थ पर्यवेक्षण के आधार पर वाक्यात्मक संरचनाओं के असुरक्षित सीखने का पता लगाता हूं। शिक्षार्थी एक वाक्यात्मक संरचना की तलाश करता है जो एक रचनात्मक वास्तुकला प्रदान करता है जो एक डाउनस्ट्रीम शब्दार्थ कार्य के लिए एक अच्छा प्रतिनिधित्व पैदा करता है। यद्यपि अनुमानित संरचनाएं पारंपरिक वाक्यात्मक विश्लेषणों से काफी अलग हैं, लेकिन\nडाउनस्ट्रीम कार्यों पर प्रदर्शन उन प्रणालियों से अधिक है जो treebank निर्भरताओं के आधार पर अनुक्रमिक RNNs और ट्री-संरचित RNNs का उपयोग करते हैं। यह अधि Kuncoro, दानी Yogatama, मिगुएल Ballesteros, फिल Blunsom, एड Grefenstette, वांग लिंग, और नूह ए स्मिथ के साथ संयुक्त काम है.', 'ru': 'Я изучаю гипотезу о том, что традиционные модели нейронных сетей (например, рекуррентные нейронные сети) неверно предвзяты для создания лингвистически разумных обобщений при обучении и что лучший класс моделей основан на архитектурах, которые отражают иерархические структуры, для которых существуют значительные поведенческие доказательства. Я фокусируюсь на проблеме моделирования и представления значений предложений. На фронте генерации я представляю рекуррентные нейросетевые грамматики (РННГ), совместную, генеративную модель деревьев фраз-структур и предложений. RNNG работают через рекурсивный синтаксический процесс, напоминающий вероятностную генерацию грамматики без контекста, но решения параметризируются с использованием RNN, которые обуславливают всю (сверху вниз, слева направо) историю синтаксических производных, тем самым смягчая предположения о независимости без контекста, сохраняя при этом уклон к объяснению решений через «синтаксически локальные» контексты кондиционирования. Эксперименты показывают, что RNNG получают лучшие результаты в генерировании языка, чем модели, которые не используют лингвистическую структуру. На фронте представления я исследую неконтролируемое обучение синтаксических структур, основанных на дистанционном семантическом надзоре, используя алгоритм обучения подкреплению. Учащийся ищет синтаксическую структуру, которая обеспечивает композиционную архитектуру, которая дает хорошее представление для последующей семантической задачи. Хотя предполагаемые структуры сильно отличаются от традиционных синтаксических анализов,\nпроизводительность на последующих задачах превосходит производительность систем, использующих последовательные RNN и RNN с древовидной структурой на основе зависимостей от древостоя. Это совместная работа с Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling и Noah A. Smith.', 'ga': 'Déanaim iniúchadh ar an hipitéis go bhfuil gnáthmhúnlaí néarlíonra (m.sh., líonraí néaracha athfhillteacha) claonta go mícheart maidir le ginearáluithe ciallmhar ó thaobh teanga a dhéanamh agus iad ag foghlaim, agus go bhfuil aicme samhlacha níos fearr bunaithe ar ailtireachtaí a léiríonn struchtúir ordlathacha a bhfuil fianaise iompraíochta suntasach ann ina leith. Dírím ar an bhfadhb a bhaineann le samhaltú agus léiriú bríonna abairtí. Ó thaobh na glúine de, tugaim isteach gramadach líonra néarach athfhillteach (RNNGanna), samhail chomhpháirteach ghiniúna de chrainn agus abairtí struchtúr frása. Feidhmíonn RNNGanna trí phróiseas comhréire athfhillteach a mheabhraíonn giniúint na gramadaí dóchúla atá saor ó chomhthéacs, ach déantar cinntí trí úsáid a bhaint as RNNanna a dhéanann riocht ar stair an díorthaigh chomhréire (ó bharr anuas, ó chlé) ar fad, agus ar an gcaoi sin réitítear boinn tuisceana neamhspleáchais saor ó chomhthéacs, agus claonadh á choinneáil i dtreo cinntí a mhíniú trí chomhthéacsanna riochtaithe “go comhréir áitiúil”. Léiríonn turgnaimh go bhfaigheann RNNG torthaí níos fearr i nginiúint teanga ná múnlaí nach mbaineann leas as struchtúr teanga. Ó thaobh na hionadaíochta de, déanaim iniúchadh ar fhoghlaim gan mhaoirseacht ar struchtúir chomhréire bunaithe ar chianmhaoirseacht shéimeantach agus úsáid á baint as algartam atreisithe-fhoghlama. Féachann an foghlaimeoir le struchtúr comhréire a sholáthraíonn ailtireacht chomhdhéanaimh a tháirgeann léiriú maith do thasc shéimeantach iartheachtach. Cé go bhfuil na struchtúir tátal an-difriúil ó anailísí comhréire traidisiúnta, tá an\nsháraíonn feidhmíocht ar thascanna iartheachtacha feidhmíocht na gcóras a úsáideann RNNanna seicheamhacha agus RNNanna crann-struchtúrtha bunaithe ar spleáchais crannchuir. Is comhobair í seo le Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, agus Noah A. Smith.', 'it': 'Le prestazioni sui task downstream superano quelle dei sistemi che utilizzano RNN sequenziali e RNN strutturati ad albero basati sulle dipendenze di treebank. Questo è un lavoro congiunto con Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling e Noah A. Smith.', 'el': 'Η απόδοση στις μεταγενέστερες εργασίες υπερβαίνει αυτή των συστημάτων που χρησιμοποιούν διαδοχικά και δομημένα με δένδρα RNN με βάση εξαρτήσεις δέντρων. Αυτή είναι κοινή δουλειά με τους Άντι Κουνκέρο, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, και Noah A. Smith.', 'hu': 'A downstream feladatok teljesítménye meghaladja az olyan rendszerek teljesítményét, amelyek szekvenciális RNN-eket és fa-strukturált RNN-eket használnak, amelyek függőségeken alapulnak. Ez Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling és Noah A. Smith közös munkája.', 'ka': 'პროცექტირება ჩვენი საკუთარი პარამეტრების შესახებ, რომელიც პროცემების პროცემების და ხე-სტრუქტურაციული პროცემების გამოყენებაში გამოიყენებს. რჲგა ვ ჱავენჲ პაბჲრა ჟ აეთ კსნკჲპჲ, ეანთ იჲდარამა, მთდსვლ ბალვჟრვპჲჟ, ტთლ ბლსნჟჲმ, ვე დპვტვნჟრვრ, სან ლთნდ თ ნჲა ა. ჟმთრ.', 'lt': 'tolesnių užduočių rezultatai viršija sistemų, kuriose naudojami nuoseklūs RNN ir medžio struktūrizuoti RNN, grindžiami priklausomybe nuo medžio sąnario, rezultatus. Tai bendras darbas su Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling ir Noah A. Smith.', 'mk': 'резултатите на задачите на потекло ги надминуваат оние на системите кои користат секвенцијални РНН и структурирани РНН од дрвја базирани на зависностите од дрвјата. Ова е заедничка работа со Ади Кункоро, Дани Јогатама, Мигел Балестерос, Фил Блунсом, Ед Грефенстет, Ванг Линг и Ноа А. Смит.', 'ms': 'prestasi pada tugas turun melebihi sistem yang menggunakan RNN sunyi dan RNN struktur pokok berdasarkan dependensi batang pokok. Ini kerja bersama dengan Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, dan Noah A. Smith.', 'kk': 'Төменгі тапсырмалардың істеуі келесі RNN және ағаш құрылған RNN тәуелдіктеріне негізделген жүйелердің істеуіне ауысады. Бұл Адхи Кункоро, Дани Йогатама, Мигель Баллестрос, Фил Блунсом, Эд Грефенстетте, Ванг Линг және Ноа А. Смит жұмыс істейді.', 'ml': 'ട്രീബാങ്കിന്\u200dറെ ആശ്രയിക്കുന്നതിന്\u200dറെ അടിസ്ഥാനത്തില്\u200d RNNs ഉപയോഗിക്കുന്ന സിസ്റ്റത്തിന്\u200dറെയും വൃക്ഷത്തിലുള്ള RNNs ഉപയോഗി This is joint work with Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, and Noah A. Smith.', 'mt': 'il-prestazzjoni fuq il-kompiti downstream taqbeż dik tas-sistemi li jużaw RNNs sekwenzjali u RNNs strutturati mis-siġar ibbażati fuq id-dipendenzi fuq il-bank tas-siġar. Dan huwa xogħol konġunt ma’ Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, u Noah A. Smith.', 'mn': 'давхар үйл ажиллагааны үйл ажиллагаа дамжуулах нь дараагийн НХ болон модны бүтээгдэхүүнтэй НХ-г ашигладаг системээс илүү их бага. Энэ бол Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, Noah A. Smith-тэй хамтран ажиллагаа.', 'no': 'utviklinga på nedstremde oppgåver overpassar systemet som brukar sekvensielle RNN og trestrukturerte RNN basert på treebank-avhengighet. Dette er samanlig arbeid med Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling og Noah A. Smith.', 'pl': 'Wydajność w dalszych zadaniach przewyższa systemy wykorzystujące sekwencyjne RNN i strukturalne RNN oparte na zależnościach drzewa. Jest to wspólna praca z Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling i Noah A. Smith.', 'ro': 'Performanța pe sarcinile din aval depășește cea a sistemelor care utilizează RNN secvențiale și RNN-uri structurate în arbore bazate pe dependențe de treebank. Aceasta este o lucrare comună cu Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling și Noah A. Smith.', 'sr': 'performansija na sledećim zadacima prelazi od sustava koji koriste sekvenčne RNN-e i drvetske strukturerane RNN-e na temelju ovisnosti o treebanciji. Ovo je zajednički posao sa Adhi Kuncorom, Danim Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling i Noah A. Smith.', 'si': 'ප්\u200dරවෘත්තිය පටන් ගත්ත වැඩේ ප්\u200dරවෘත්තිය පද්ධතියෙන් ප්\u200dරවෘත්තියෙන් පද්ධතියෙන් ප්\u200dරවෘත්තිය RNN සහ ගස් සංස්ථ මේක ඇදී කුන්කෝරෝ, ඩැනී යෝගාතාමා, මිගුල් බැල්ලෙස්ටරෝ, ෆිල් බ්ලොන්සෝම්, එඩ් ග්\u200dරෙෆෙන්ස්ටෙට්, වැන්ග් ලින්ග්, නෝව', 'so': 'sameynta hawlaha hoose waxaa kor u qaadanaya nidaam isticmaalaya RNNs dabadeed iyo geed-dhisan RNNs oo ku saleysan waxyaabaha ay ku xiran tahay treebank. This is joint work with Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, and Noah A. Smith.', 'sv': 'Prestandan på efterföljande uppgifter överträffar den hos system som använder sekventiella RNN och trädstrukturerade RNN baserade på treebank beroenden. Detta är ett gemensamt arbete med Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling och Noah A. Smith.', 'ta': 'கீழ் தண்ணீர் செயல்பாடு இது Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, and Noah A. Smith.', 'ur': 'نیچے سطح کے کاموں پر کامیابی ان سیستموں سے زیادہ اضافہ ہوتی ہے جو سیستموں کے ذریعہ RNN اور درخت ساختہ RNN استعمال کر رہے ہیں جو تریب بانک اعتباری پر بنیاد رکھتے ہیں. یہ ادی کونکروں، دنی یوگاتاماں، میگوئل بالسٹروں، فیل بلونسوم، ایڈ گریفنسٹٹ، وانگ لینگ اور نوہ ا. س. میٹ کے ساتھ ملک ہے.', 'uz': 'Name Bu Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, Noah A. Smith bilan birlashtirish ish.', 'vi': 'Thành quả trong các công việc xuôi dòng vượt hơn các hệ thống sử dụng RNN theo tần số và RNN cấu trúc cây dựa trên các phụ thuộc treeback. Đây là văn phòng chung với Adhi Kuncoro, Dani yoga, Miguel Ballestero, Phil Blunsom, Ed Grefenstette, Vương Ling, và Noah A. Smith.', 'bg': 'изпълнението на задачите надолу по веригата надхвърля това на системите, които използват последователни RNN и дървесни структурирани RNN въз основа на зависимости от дървесни банки. Това е съвместна работа с Адхи Кункоро, Дани Йогатама, Мигел Балестерос, Фил Блунсом, Ед Грефенстет, Уанг Линг и Ноа А. Смит.', 'de': 'Die Leistung der nachgelagerten Aufgaben übertrifft die von Systemen, die sequentielle RNNs und baumstrukturierte RNNs basierend auf Baumbankabhängigkeiten verwenden. Dies ist eine gemeinsame Arbeit mit Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling und Noah A. Smith.', 'da': "ydeevnen på downstream opgaver overgår systemer, der bruger sekventielle RNN'er og træstrukturerede RNN'er baseret på treebank afhængigheder. Dette er fælles arbejde med Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling og Noah A. Smith.", 'nl': "De prestaties op de downstreamtaken overtreffen die van systemen die sequentiële RNN's en boomgestructureerde RNN's gebruiken op basis van boombankafhankelijkheden. Dit is gezamenlijk werk met Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling en Noah A. Smith.", 'id': 'performance on the downstream tasks surpasses that of systems that use sequential RNNs and tree-structured RNNs based on treebank dependencies.  Ini adalah kerja bersama dengan Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, dan Noah A. Smith.', 'fa': 'عملکرد روی کارهای پایین پایین از سیستم\u200cهای استفاده از RNN\u200cهای پایین و RNN\u200cهای ساخته شده از درخت بر اساس بستگی\u200cهای درخت\u200cبندی بیشتر است. این همکاری با ادی کونکورو، دنی یوگاتاما، میگوئل بالesteros، فیل بلونسوم، Ed Grefenstette، وانگ لینگ و نوا ا. اسمیت است.', 'hr': 'učinkovitost na donjem zadatku iznosi sustave koji koriste sekvencijalne RNN-e i drveće strukturirane RNN-e na temelju ovisnosti o treebancima. Ovo je zajednički posao sa Adhi Kuncorom, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling i Noah A. Smith.', 'sw': 'utendaji wa kazi za mito ya chini unapitisha mifumo inayotumia RNN za baadae na RNN zilizotengenezwa na miti inayotegemea mitaani. Hii ni kazi ya pamoja na Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, na Noah A. Smith.', 'tr': 'aşağıdaki zadlaryň eserini agaç baglançylara daýanýan RNN we agaç-düzümlenmiş RNN sistemleriniň üstine geçýär. Bu Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling we Noah A. Smith bilen bir işdir.', 'af': 'produksie op die onderstreem opdragte oorvloei wat van stelsels wat sekwensiele RNN gebruik en boom-struktureerde RNN gebaseer op treebank afhanklikhede. Dit is saamstig werk met Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling en Noah A. Smith.', 'sq': 'performanca në detyrat e poshtme kalon atë të sistemeve që përdorin RNN sekuenciale dhe RNN strukturuar nga pemët bazuar në varësitë në bazë të drurit. Kjo është punë e përbashkët me Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling dhe Noah A. Smith.', 'ko': '다운스트림 작업의 성능은 순차 RNN과 트리 라이브러리 종속성 기반 트리 구조 RNN을 사용하는 시스템을 능가합니다.Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, Noah A.Smith와의 연합 작업이다.', 'am': 'የውኃው ውጤት ስራዎችን በተመሳሳይ የRNs እና ዛፍ-ሠረት RNs በተመሳሳይ ሥርዓቶች ላይ የሚጠቀሙትን ሥርዓቶች ይጨምሩታል፡፡ ይህ ከአዲhi ኩንኮሮ፣ ዳን ዮጋጋታ፣ ሚጉኤል ባሌስታሮስ፣ ፊል ብሎንሶም፣ ኤድ ግሪፌንስቴት፣ Wang Ling እና ኖሄ አ. ስሜት ነው፡፡', 'hy': 'վերջնական գործողությունների արդյունքը գերազանցում է այն համակարգերի, որոնք օգտագործում են հաջորդական ՌՆԹ-ներ և ծառերի կառուցվածքներով ՌՆԹ-ներ, հիմնված ծառերի հիմնական կախվածությունների վրա: This is joint work with Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling, and Noah A. Smith.', 'az': 'Aşağıdakı işlər işləri sonrakı RNN və ağac-strukturlı RNN sistemlərinin bağlılıqlarına dayanan sistemlərin istifadəsindən üstün gəlir. Bu Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling və Noah A. Smith ilə birlikdə çalışır.', 'bn': 'নীচের নদীর কাজের উপর প্রদর্শনীরা যে সিস্টেম ব্যবহার করে ত্রিবাংকের নির্ভরের উপর ভিত্তিক RNs এবং গাছের কাঠামো RNs ব্যবহার করে। এটা আদি কুন্কোরো, ড্যানি ইয়োগাতামা, মিগুয়েল বেলেস্টেরোস, ফিল ব্লুনসম, এড গ্রেফেন্স্টেট, ওয়াং লিং এবং নোয়া এ. স্মিথের সাথে যোগাযোগ ক', 'bs': 'učinkovitost na donjim zadacima prelazi od sustava koji koriste sekvencijalne RNN-e i drveće strukturirane RNN-e na temelju ovisnosti o treebancima. Ovo je zajednički posao sa Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling i Noah A. Smith.', 'cs': 'Výkon na následných úlohách překonává systémy, které používají sekvenční RNN a stromově strukturované RNN založené na závislostech stromové břehy. Jedná se o společnou práci s Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling a Noah A. Smith.', 'et': 'Järgnevate ülesannete tulemuslikkus ületab süsteemide omadust, mis kasutavad järjestikuseid RNN-sid ja puustruktureeritud RNN-sid, mis põhinevad puupanga sõltuvustel. See on koostöö Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling ja Noah A. Smith.', 'fi': 'Loppupään tehtävissä suorituskyky ylittää sekvenssiaalisia RNN:itä ja puurakenteisia RNN:iä hyödyntävien järjestelmien suorituskyvyn. Tämä on yhteistyötä Adhi Kuncoron, Dani Yogataman, Miguel Ballesterosin, Phil Blunsomin, Ed Grefenstetten, Wang Lingin ja Noah A. Smithin kanssa.', 'ca': "el rendiment de les tasques avall supera el dels sistemes que utilitzen RNS seqüencials i RNS estructurats per arbres basats en les dependencies de la base d'arbres. Això és treball conjunt amb Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling i Noah A. Smith.", 'jv': 'Arep nggawe dadi downtream dadi mbukake mrobahan kanggo sistem sing gambar nggambar R-Ns karo sekondiki -structural R-Ns singular diandelah kanggo kalalangan gambar gawe barang banget Iki iki luwung jajal karo Adhi Kuncoro, Dani Yogatama, miwel Ballesters, File Flossom, ED Grayhenstettettet, Wang Ling lan Noh A. Smith.', 'he': 'ביצועים במשימות התחתונות מעליים את המערכות ששותמשות בארנ"א רצופיים ומבנים על עצים מבוססים על תלויות שבקצה עץ. זו עבודה משותפת עם אדי קונקורו, דני יוגטמה, מיגל בלסטרוס, פיל בלונסום, אד גרפנסטט, וונג לינג, ונאה א. סמית.', 'ha': 'Mai cikakken aikin durowa na ƙaranci yana surge da tsarin masu amfani da RNNs na dabam-daban da aka rubuta RNNs da aka danne a kan danne da Treebank. Wannan yana da shirin aiki na Adhi KunCoro, Dan Yoga, Miguel Ballesteres, Phil Blonsom, Ed Grafenstutte, Wang Ling, da Nuhu A. Smith.', 'sk': 'Učinkovitost pri nadaljnjih nalogah presega učinkovitost sistemov, ki uporabljajo zaporedne RNN in drevesno strukturirane RNN, ki temeljijo na odvisnostih od drevesnih baz. To je skupno delo z Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling in Noah A. Smith.', 'bo': 'མཇུག་མའི་བྱ་འགུལ་གྱི་ཐོག་ལས་སྒྲུབ་མང་ཙམ་བརླབས་ཡོད། འདི་ནི་Adhi Kuncoro, Dani Yogatama, Miguel Ballesteros, Phil Blunsom, Ed Grefenstette, Wang Ling དང་། Noah A. Smith དང་མཉམ་དུ་མཐུན་སྒྲིག་གི་ཡོད།'}
{'en': 'Rational Distortions of Learners’ Linguistic Input', 'ar': 'التشوهات العقلانية في المدخلات اللغوية للمتعلمين', 'pt': 'Distorções racionais da entrada linguística dos alunos', 'es': 'Distorsiones racionales de las aportaciones lingüísticas de los alumnos', 'fr': "Distorsions rationnelles de l'apport linguistique des apprenants", 'ja': '学習者の言語入力の合理的な歪み', 'hi': 'शिक्षार्थियों के भाषाई इनपुट की तर्कसंगत विकृतियां', 'zh': '学者语言输入理性扭曲', 'ru': 'Рациональные искажения лингвистического вклада учащихся', 'ga': 'Saobhadh Réasúnach ar Ionchur Teangeolaíochta na bhFoghlaimeoirí', 'ka': 'სწავლის ლინგუტიკური მონაცემების რეაციონალური განზღვრება', 'hu': 'A tanulók nyelvi adatainak racionális torzulásai', 'el': 'Λογικές στρεβλώσεις της γλωσσικής εισόδου των μαθητών', 'it': "Distorsioni razionali dell'input linguistico degli studenti", 'kk': 'Оқытушылардың лингвистикалық енгізуінің қатынасы', 'lt': 'Mokytojų kalbos įėjimo racionalūs sutrikimai', 'mk': 'Рационални растури на јазичниот внес на учениците', 'ms': 'Penggangguan Rasional Input Bahasa Pelajar', 'mt': 'Distorsjonijiet Razzjonali tal-Input Lingwistiku tal-Apprendituri', 'mn': 'Оюутнуудын хэл хөрөнгө оруулалт', 'ml': "Rational Distortions of Learners' Linguistic Input", 'no': 'Relationale forskjellingar på lingsinndata til lærarar', 'pl': 'Racjonalne zniekształcenia wejścia językowego uczących się', 'ro': 'Distorsiuni raționale ale intrării lingvistice a elevilor', 'sr': 'Rationalne poremećaje Lingističkog ulaza učitelja', 'si': 'Screen saver category', 'so': "Distorments of Rational Learners' Linguistic Input", 'sv': 'Rationella förvrängningar av elevernas språkliga input', 'ta': 'படிப்பாளரின் வரிசை உள்ளீடு', 'ur': 'یادگاروں کی لینگویسٹی اینپوٹ کی نسبتی تقسیم', 'uz': 'Name', 'vi': 'Xoay ngang của ngôn ngữ học', 'bg': 'Рационални изкривявания на езиковия принос на учениците', 'da': 'Rationelle forvridninger af lærernes sproglige input', 'nl': 'Rationele vervormingen van de taalkundige input van leerlingen', 'hr': 'Rationalne poremećaje Lingističkog ulaska učitelja', 'de': 'Rationale Verzerrungen des sprachlichen Inputs der Lernenden', 'id': "Rational Distortions of Learners' Language Input", 'fa': 'تغییرات منطقی از ورودی لینگ\u200cگیستیک دانش آموزان', 'sw': 'Udhibiti wa mazingira ya Wasomi', 'tr': 'KCharselect unicode block name', 'af': 'Relationale Verspreidings van Leerders se Linguistiese Invoer', 'sq': 'Ndryshimet racionale të hyrjes gjuhësore të mësuesve', 'am': 'ምርጫዎች', 'hy': 'Աշակերտների լեզվաբանական ներմուծի ռացիոնալ շեղումները', 'az': "√Ėyr…ôn…ôn…ônl…ôrin Linguistik GiriŇüinin Rational Distortions of Learners' Linguistic Input", 'bn': 'শিক্ষকদের লিঙ্গিস্টিক ইনপুটের মাত্রিক ডিস্টোরেশন', 'bs': 'Rationalne poremećaje Lingističkog ulaska učitelja', 'ca': "Les distorsions racionales de l'entrada lingüística dels alumnes", 'cs': 'Racionální narušení jazykového vstupu studentů', 'et': 'Õppijate keelelise sisendi ratsionaalsed moonutused', 'ko': '학습자 언어 입력의 이성적 왜곡', 'fi': 'Oppijoiden kielellisen syötön rationaaliset vääristymät', 'jv': 'tutorial_basic', 'he': 'הפרעות רציונליות של הכניסה הלנגולית של לומדים', 'ha': 'KCharselect unicode block name', 'sk': 'Racionalna izkrivljanja jezikovnega vnosa učencev', 'bo': 'སློབ་པའི་སྐད་ཡིག་གནས་ཚུལ་གྱི་རྒྱུ་རྐྱེན་ཚད'}
{'en': 'Language acquisition can be modeled as a statistical inference problem : children use sentences and sounds in their input to infer linguistic structure. However, in many cases, children learn from data whose statistical structure is distorted relative to the language they are learning. Such distortions can arise either in the input itself, or as a result of children’s immature strategies for encoding their input. This work examines several cases in which the statistical structure of children’s input differs from the language being learned. Analyses show that these distortions of the input can be accounted for with a statistical learning framework by carefully considering the inference problems that learners solve during language acquisition', 'es': 'La adquisición del lenguaje se puede modelar como un problema de inferencia estadística: los niños usan oraciones y sonidos en sus comentarios para inferir la estructura lingüística. Sin embargo, en muchos casos, los niños aprenden de datos cuya estructura estadística está distorsionada en relación con el idioma que están aprendiendo. Tales distorsiones pueden surgir ya sea en la entrada misma o como resultado de las estrategias inmaduras de los niños para codificar su entrada. Este trabajo examina varios casos en los que la estructura estadística de las aportaciones de los niños difiere del idioma que se aprende. Los análisis muestran que estas distorsiones de la entrada se pueden explicar con un marco de aprendizaje estadístico al considerar cuidadosamente los problemas de inferencia que los estudiantes resuelven durante la adquisición del idioma.', 'ar': 'يمكن نمذجة اكتساب اللغة كمشكلة استدلال إحصائي: يستخدم الأطفال الجمل والأصوات في مدخلاتهم لاستنتاج البنية اللغوية. ومع ذلك ، في كثير من الحالات ، يتعلم الأطفال من البيانات التي يكون هيكلها الإحصائي مشوهًا بالنسبة للغة التي يتعلمونها. يمكن أن تنشأ مثل هذه التشوهات إما في المدخلات نفسها ، أو نتيجة لاستراتيجيات الأطفال غير الناضجة لتشفير مدخلاتهم. يبحث هذا العمل في العديد من الحالات التي يختلف فيها الهيكل الإحصائي لمدخلات الأطفال عن اللغة التي يتم تعلمها. تظهر التحليلات أن هذه التشوهات في المدخلات يمكن حسابها من خلال إطار عمل تعليمي إحصائي من خلال التفكير بعناية في مشاكل الاستدلال التي يحلها المتعلمون أثناء اكتساب اللغة', 'fr': "L'acquisition du langage peut être modélisée comme un problème d'inférence statistique\xa0: les enfants utilisent des phrases et des sons dans leurs entrées pour déduire la structure linguistique. Cependant, dans de nombreux cas, les enfants apprennent à partir de données dont la structure statistique est déformée par rapport à la langue qu'ils apprennent. De telles distorsions peuvent survenir soit dans l'entrée elle-même, soit à la suite de stratégies immatures des enfants pour coder leur entrée. Ce travail examine plusieurs cas dans lesquels la structure statistique de l'entrée des enfants diffère de celle de la langue apprise. Les analyses montrent que ces distorsions de l'entrée peuvent être prises en compte dans un cadre d'apprentissage statistique en tenant compte des problèmes d'inférence que les apprenants résolvent lors de l'acquisition d'une langue.", 'pt': 'A aquisição da linguagem pode ser modelada como um problema de inferência estatística: as crianças usam frases e sons em sua entrada para inferir a estrutura linguística. No entanto, em muitos casos, as crianças aprendem a partir de dados cuja estrutura estatística é distorcida em relação à língua que estão aprendendo. Tais distorções podem surgir no próprio input ou como resultado de estratégias imaturas das crianças para codificar seu input. Este trabalho examina vários casos em que a estrutura estatística da entrada das crianças difere da língua que está sendo aprendida. As análises mostram que essas distorções da entrada podem ser explicadas com uma estrutura de aprendizagem estatística, considerando cuidadosamente os problemas de inferência que os alunos resolvem durante a aquisição da linguagem.', 'hi': 'भाषा अधिग्रहण को सांख्यिकीय अनुमान समस्या के रूप में मॉडलकिया जा सकता है: बच्चे भाषाई संरचना का अनुमान लगाने के लिए अपने इनपुट में वाक्यों और ध्वनियों का उपयोग करते हैं। हालांकि, कई मामलों में, बच्चे डेटा से सीखते हैं जिनकी सांख्यिकीय संरचना उस भाषा के सापेक्ष विकृत है जो वे सीख रहे हैं। इस तरह की विकृतियां या तो इनपुट में ही उत्पन्न हो सकती हैं, या उनके इनपुट को एन्कोडिंग करने के लिए बच्चों की अपरिपक्व रणनीतियों के परिणामस्वरूप। यह काम कई मामलों की जांच करता है जिसमें बच्चों के इनपुट की सांख्यिकीय संरचना सीखी जा रही भाषा से अलग होती है। विश्लेषण से पता चलता है कि इनपुट के इन विकृतियों को एक सांख्यिकीय सीखने के ढांचे के साथ जिम्मेदार ठहराया जा सकता है, जो भाषा अधिग्रहण के दौरान शिक्षार्थियों द्वारा हल की जाने वाली अनुमान समस्याओं पर ध्यान से विचार करके किया जा सकता है', 'ja': '言語習得は、統計的推論問題としてモデル化することができる。子供たちは、言語構造を推論するために入力に文章と音を使用する。しかし、多くの場合、子供は学習している言語に対して統計構造が歪んでいるデータから学習します。このような歪みは、入力自体に生じる場合もあれば、子どもの入力をエンコードするための未熟な戦略の結果として生じる場合もある。この研究では、子どものインプットの統計構造が学習されている言語と異なるいくつかのケースを検討します。分析は、言語習得中に学習者が解決する推論問題を慎重に検討することによって、統計的学習フレームワークで入力のこれらの歪みを説明できることを示している。', 'zh': '语言习得可建模为一计推理:童子于其输中用句声以推其结构。 然童子从数中学之,其数相对,其言曲也。 或出于身,或出于童编码其不成策也。 其治儿童输入者统计结构与所学语言不同者数事。 分析表明审学者言习得之理,可以计学框架解输之曲。', 'ru': 'Приобретение языка может быть смоделировано как задача статистического вывода: дети используют предложения и звуки в своем вводе, чтобы вывести лингвистическую структуру. Однако во многих случаях дети учатся на основе данных, статистическая структура которых искажена по отношению к языку, который они изучают. Такие искажения могут возникать либо в самом входе, либо в результате незрелых стратегий детей по кодированию их входов. В этой работе рассматривается несколько случаев, когда статистическая структура вклада детей отличается от изучаемого языка. Анализы показывают, что эти искажения входных данных могут быть учтены с помощью статистической системы обучения путем тщательного рассмотрения проблем вывода, которые учащиеся решают во время изучения языка', 'ga': 'Is féidir sealbhú teanga a mhúnlú mar fhadhb tátail staitistiúil: úsáideann páistí abairtí agus fuaimeanna ina n-ionchur chun struchtúr teanga a thuiscint. I go leor cásanna, áfach, foghlaimíonn leanaí ó shonraí a bhfuil a struchtúr staitistiúil saobhadh i gcoibhneas leis an teanga atá á foghlaim acu. Is féidir le saobhadh mar seo teacht chun cinn san ionchur féin, nó mar thoradh ar straitéisí neamhaibí leanaí chun a n-ionchur a ionchódú. Scrúdaíonn an obair seo roinnt cásanna ina bhfuil difríocht idir struchtúr staitistiúil ionchur na bpáistí agus an teanga atá á foghlaim. Léiríonn anailísí gur féidir cuntas a thabhairt ar na saobhadh seo ar an ionchur le creat staitistiúil foghlama trí na fadhbanna tátail a réitíonn foghlaimeoirí le linn sealbhaithe teanga a mheas go cúramach.', 'ka': 'ენის მიღება შეიძლება მოდელურება როგორც სტატისტიკური ინფრენციის პრობლემა: ბავშვები გამოყენება სიტყვებები და სიტყვებები, რომლებიც სიტყვების სტრ მაგრამ, რამდენიმე შემთხვევაში, ბავშვები მონასწავლის მონაცემებით, რომელიც სტატისტიკური სტრუქტურაციას განმავლობაა, რომელიც ისინი ს ასეთი განსხვავებები შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება თავიდან შეიყვანა, ან ბავშვების განსხვავებული სტრატიგიების შედეგი, როგორც შე ეს სამუშაო განსხვავება რამდენიმე შემთხვევაში, რომლებიც ბავშვების მონაცემის სტატისტიკური სტრუქტურა განსხვავებულია ენაზე. ანალიზები ჩვენებენ, რომ ეს გადაწყვეტილების განმავლობა შეიძლება იყოს სტატისტიკური სწავლების ფრამეტრებით, რომელიც ინფრენციის პრობლემები, რომლებიც სწავლებელი წარმოადგენს ენის', 'el': 'Η απόκτηση γλωσσών μπορεί να μοντελοποιηθεί ως στατιστικό πρόβλημα συμπερασμάτων: τα παιδιά χρησιμοποιούν προτάσεις και ήχους στην εισαγωγή τους για να συμπεράνουν τη γλωσσική δομή. Ωστόσο, σε πολλές περιπτώσεις, τα παιδιά μαθαίνουν από δεδομένα των οποίων η στατιστική δομή είναι παραμορφωμένη σε σχέση με τη γλώσσα που μαθαίνουν. Τέτοιες στρεβλώσεις μπορεί να προκύψουν είτε στην ίδια την εισαγωγή είτε ως αποτέλεσμα των ανώριμων στρατηγικών των παιδιών για την κωδικοποίηση της εισόδου τους. Η παρούσα εργασία εξετάζει αρκετές περιπτώσεις στις οποίες η στατιστική δομή της εισροής των παιδιών διαφέρει από τη γλώσσα που μαθαίνεται. Οι αναλύσεις δείχνουν ότι αυτές οι στρεβλώσεις της εισαγωγής μπορούν να υπολογιστούν με ένα στατιστικό μαθησιακό πλαίσιο εξετάζοντας προσεκτικά τα προβλήματα συμπερασμάτων που επιλύουν οι μαθητές κατά την απόκτηση γλωσσών', 'hu': 'A nyelvelsajátítás statisztikai következtetési problémaként modellezhető: a gyerekek mondatokat és hangokat használnak a bemenetükben a nyelvi struktúra következtetésére. Sok esetben azonban a gyermekek olyan adatokból tanulnak, amelyeknek statisztikai struktúrája eltorzult az általuk tanult nyelvhez képest. Ezek a torzulások akár magában a bemenetben, akár a gyermekek éretlen stratégiáinak eredményeként is felmerülhetnek a bemenet kódolására. A munka több olyan esetet vizsgál, amikor a gyermekek adatainak statisztikai struktúrája eltér a tanult nyelvtől. Az elemzések azt mutatják, hogy az input torzulásait statisztikai tanulási keretrendszerrel lehet elszámolni, gondosan figyelembe véve azokat a következtetési problémákat, amelyeket a tanulók a nyelvtanulás során megoldanak', 'it': "L'acquisizione linguistica può essere modellata come un problema di inferenza statistica: i bambini usano frasi e suoni nel loro input per inferire la struttura linguistica. Tuttavia, in molti casi, i bambini imparano da dati la cui struttura statistica è distorta rispetto alla lingua che stanno imparando. Tali distorsioni possono sorgere sia nell'input stesso, o come risultato delle strategie immature dei bambini per codificare il loro input. Questo lavoro esamina diversi casi in cui la struttura statistica dell'input dei bambini differisce dalla lingua appresa. Le analisi mostrano che queste distorsioni dell'input possono essere contabilizzate con un framework statistico di apprendimento considerando attentamente i problemi di inferenza che gli studenti risolvono durante l'acquisizione della lingua", 'lt': 'Kalbos įgijimas gali būti modeliuojamas kaip statistinės išvados problem a: vaikai savo įnašuose naudoja sakinius ir garsus, kad galėtų daryti išvadą apie kalbinę struktūrą. Tačiau daugeliu atvejų vaikai mokosi iš duomenų, kurių statistinė struktūra iškraipoma, palyginti su kalba, kurią jie mokosi. Tokie iškraipymai gali atsirasti arba pačiame įvedime, arba dėl nepilnamečių vaikų įvedimo kodavimo strategijų. Šiame darbe nagrinėjami keli atvejai, kai vaikų įnašų statistinė struktūra skiriasi nuo mokomos kalbos. Analizės rodo, kad į šiuos įnašų iškraipymus galima atsižvelgti taikant statistinio mokymosi sistemą atidžiai apsvarstant išvadų problemas, kurias mokiniai sprendžia kalbų įgijimo metu.', 'mk': 'Добивањето јазик може да се моделира како проблем со статистичката инференција: децата користат реченици и звуци во нивните внесувања за да ја инферираат јазичката структура. Сепак, во многу случаи, децата учат од податоци чија статистичка структура е искоренета во однос на јазикот кој го учат. Таквите distorsions може да се појават или во самиот внес или како резултат на незрелите стратегии на децата за кодирање на нивниот внес. Оваа работа ги испитува неколку случаи во кои статистичката структура на внесувањето на децата се разликува од јазикот што се научи. Анализите покажуваат дека овие distorsions на влогот може да се сметаат за со статистичка рамка за учење со внимателно разгледување на проблемите со конференцијата кои учениците ги решаваат за време на набавувањето јазик', 'kk': 'Тілді қабылдау мәселесі статистикалық инференциялық мәселесі ретінде модельді: балалар сөздерді және дыбыстарын тілдік құрылғысын бақылау үшін қолданылады. Бірақ көп жағдайда, балалар статистикалық құрылымынан, олардың үйренген тіліне сәйкес ауыстырылған деректерінен үйренеді. Бұл қиындықтар өзінің келтірімінде немесе балалардың келтірімін кодтамасыз стратегияларының нәтижесі болуы мүмкін. Бұл жұмыс балалардың кірісінің статистикалық құрылымы тілден бірнеше жағдайды тексереді. Анализациялар келтірілген кірістің бұл қиындықтарын статистикалық оқыту бағдарламасынан тәжірибелеу мәселелерін оқыту үшін', 'ms': "Peroleh bahasa boleh dipodelkan sebagai masalah kesimpulan statistik: kanak-kanak menggunakan kalimat dan bunyi dalam input mereka untuk menyimpulkan struktur bahasa. Bagaimanapun, dalam banyak kes, kanak-kanak belajar dari data yang struktur statistiknya terganggu relatif dengan bahasa yang mereka belajar. Pencerahan tersebut boleh muncul sama ada dalam input sendiri, atau sebagai hasil strategi kanak-kanak yang belum dewasa untuk mengekodkan input mereka. This work examines several cases in which the statistical structure of children's input differs from the language being learned.  Analisis menunjukkan bahawa penyelesaian input ini boleh dianggap dengan kerangka pembelajaran statistik dengan hati-hati mempertimbangkan masalah kesimpulan yang pelajar selesaikan semasa pengakuan bahasa", 'mt': 'Language acquisition can be modeled as a statistical inference problem: children use sentences and sounds in their input to infer linguistic structure.  Madankollu, f’ħafna każijiet, it-tfal jitgħallmu minn dejta li l-istruttura statistika tagħhom hija mfixkla meta mqabbla mal-lingwa li qed jitgħallmu. Dawn id-distorsjonijiet jistgħu jinħolqu jew fl-input innifsu, jew bħala riżultat ta’ strateġiji immaturi tat-tfal għall-kodifikazzjoni tal-input tagħhom. Dan ix-xogħol jeżamina diversi każijiet fejn l-istruttura statistika tal-kontribut tat-tfal hija differenti mil-lingwa li qed titgħallem. L-analiżi turi li dawn id-distorsjonijiet tal-input jistgħu jiġu kkunsidrati b’qafas ta’ tagħlim statistiku billi jiġu kkunsidrati bir-reqqa l-problemi ta’ inferenza li l-istudenti jsolvu matul l-akkwist tal-lingwa', 'ml': 'ഭാഷ കിട്ടാന്\u200d സാധ്യതയുള്ള പ്രശ്നമായി മോഡല്\u200d ചെയ്യുന്നതാണ്: കുട്ടികള്\u200dക്ക് വാക്കുകളും ശബ്ദങ്ങളും അവയുടെ ഇന്\u200dപുട്ടില്\u200d ന എന്നാലും പല കാര്യങ്ങളിലും കുട്ടികള്\u200d വിവരങ്ങളില്\u200d നിന്നും പഠിക്കുന്നു. അവരുടെ സ്ഥിതികസ്ഥാനം അവര്\u200d പഠിക്കുന്ന ഇങ്ങനെയുള്ള വ്യത്യാസങ്ങള്\u200d സ്വയം ഉള്\u200dപ്പെടുന്നതാണ്, അല്ലെങ്കില്\u200d കുട്ടികളുടെ അസാധാരണമായ യുദ്ധങ്ങള്\u200dക്ക് കാരണം അവരു ഈ ജോലി കുറച്ചു കേസുകളെ പരിശോധിക്കുന്നു. കുട്ടികളുടെ ഇന്\u200dപുട്ടിന്റെ സ്ഥിതികസ്ഥാനം വ്യത്യസ്തമായി പഠി അന്വേഷിക്കുന്നു', 'no': 'Språkopling kan modelerast som eit statistisk infeksjonssproblem: barn brukar setningar og lydar i inndata til å fjerna språkstuktur. Men i mange tilfeller lærer barna frå data der statistiske strukturen er forvrengt relativt til språket dei lærer. Desse forstørringane kan oppstå anten i inndataen sjølv, eller som resultatet av barneske ugyldige strategiar for koding av inndataen s in. Dette arbeidet undersøker fleire tilfeller der statistiske strukturen av barna inndata er ulike frå språket som vert lært. Analyser viser at desse forskjellingane av inndata kan reknast etter eit statistisk læringsrammeverk ved å forstørra forstørringsprogrammet som lærarar løysa under språkopling', 'pl': 'Nabywanie języka można modelować jako statystyczny problem wnioskowania: dzieci używają zdań i dźwięków w swoich wejściach do wnioskowania struktury językowej. Jednak w wielu przypadkach dzieci uczą się na podstawie danych, których struktura statystyczna jest zniekształcona w stosunku do języka, którego się uczą. Takie zakłócenia mogą pojawić się zarówno w samym wejściu, jak i w wyniku niedojrzałych strategii kodowania danych przez dzieci. W pracy badano kilka przypadków, w których struktura statystyczna wkładu dzieci różni się od uczonego języka. Analizy pokazują, że te zakłócenia wejścia można uwzględnić za pomocą statystycznych ram uczenia się, uważnie rozważając problemy wnioskowania, które uczący się rozwiązują podczas nabywania języka', 'ro': 'Dobândirea limbii poate fi modelată ca o problemă de inferență statistică: copiii folosesc propoziții și sunete în intrarea lor pentru a deduce structura lingvistică. Cu toate acestea, în multe cazuri, copiii învață din date a căror structură statistică este distorsionată în raport cu limba pe care o învață. Astfel de distorsiuni pot apărea fie în intrarea în sine, fie ca urmare a strategiilor imature ale copiilor pentru codificarea intrării lor. Această lucrare examinează mai multe cazuri în care structura statistică a contribuțiilor copiilor diferă de limba învățată. Analizele arată că aceste denaturări ale intrărilor pot fi contabilizate printr-un cadru statistic de învățare, luând în considerare cu atenție problemele de deducție pe care elevii le rezolvă în timpul dobândirii limbilor străine', 'mn': 'Хүмүүс хэл худалдан авах нь статистикийн халдварын асуудал гэж загварчлагддаг: хүүхдүүд хэл хэлний бүтцийг халдварлахад өгүүлбэрүүдийг ашигладаг. Гэхдээ ихэнх тохиолдолд хүүхдүүд статистикийн бүтэц нь хэл суралцаж байгаагаас харьцуулсан мэдээллээс суралцдаг. Хүүхдүүдийн амьдралын стратегийн үр дүнд орж ирэх боломжтой. Энэ ажил хүүхдүүдийн оролцооны статистикийн бүтэц хэл суралцсан хэлээс ялгаатай олон тохиолдолуудыг шалгаж байна. Шалгааныг харуулж байгаагаар эдгээр орнуудын өөрчлөлт нь хэлний худалдааны үед сурагчид шийдвэрлэх халдварын асуудлуудыг анхаарлын тулд статистикийн суралцах системээр тодорхойлж чадна.', 'si': 'භාෂාව අල්ලගන්න පුළුවන් විදිහට ස්ථාතික අන්තිමත් ප්\u200dරශ්නයක් විදිහට මොඩොල් කරලා තියෙන්නේ: ළමයි වච නමුත්, ගොඩක් විදිහට, ළමයින් දත්තෙන් ඉගෙන ගන්නවා එයාලා ඉගෙන ගන්නේ භාෂාව සම්බන්ධයෙන් තියෙන්නේ  එහෙම විරෝධ වෙන්න පුළුවන් ඔවුන්ගේ ඇතුළත් ඇතුළත් ඇතුළත් ඇතුළත් ඇතුළත්, නැත්තම් ඔවුන්ගේ ඇතුළත් ඇතුළ මේ වැඩේ පරීක්ෂා කරනවා කිසිම විදිහක් තියෙන්නේ කොල්ලාගේ ඇතුළුමේ සංඛ්යාත්මක සංවිධානය වෙ විශ්ලේෂණය පෙන්වන්න පුළුවන් විදිහට මේ ඇතුළුමේ අනතුරු අනතුරු විදිහට පරික්ෂා කරන්න පුළුවන් විදිහට පරික්ෂා කරලා', 'so': "Waxbarashada luqada waxaa looga sameyn karaa dhibaato la'aan oo statistical ah: Carruurtu waxay isticmaalaan hadal iyo codyo si ay u fekeraan dhismaha luuqadda. Si kastaba ha ahaatee xaaladaha badan carruurtu waxay ka baraan macluumaadkooda dhismaha statisticada lagu qalloociyaa oo la xiriira luqada ay baranayaan. Dagaalka caynkaas ah waxaa ka dhici kara gudaha ama qalabka carruurta oo aan qaangaarka aheyn ka soo jeedin kara qoraalka lagu qorayo injiilkooda. Shaqadaasu wuxuu ka baaraandegaa xaalado badan, kuwaas oo ku qoran dhismaha takhasuska ee cunugga ay ku kala duwan yihiin luuqada lagu baranayo. Baaritaanka waxaa muuqanaya in qalloocsiga soo gala lagu xisaabin karo qalabka waxbarashada takhasuska ah, si taxadar leh uga fikir karo dhibaatooyinka jirada ee barashada luqada", 'sv': 'Språkinlärning kan modelleras som ett statistiskt inferensproblem: barn använder meningar och ljud i sin inmatning för att härleda språklig struktur. I många fall lär sig dock barn av data vars statistiska struktur är snedvriden i förhållande till det språk de lär sig. Sådana snedvridningar kan uppstå antingen i själva inmatningen, eller som ett resultat av barns omogna strategier för att koda deras inmatning. Detta arbete undersöker flera fall där den statistiska strukturen för barns input skiljer sig från det språk som lärs sig. Analyser visar att dessa snedvridningar av indata kan redovisas med hjälp av ett statistiskt lärramverk genom att noggrant överväga de slutsatssproblem som eleverna löser vid språkinlärning', 'sr': 'Prikupljanje jezika se može modelirati kao problem statističke infekcije: djeca koriste rečenice i zvuke u svojim ulazima da bi zarazila jezičku strukturu. Međutim, u mnogim slučajevima, deca uče od podataka čija je statistička struktura iskrivljena u odnosu na jezik koji uče. Takve poremećaje mogu da se pojave ili u samom ulazu, ili kao rezultat dječjih nezadovoljih strategija za kodiranje njihovog ulaza. Ovaj rad pregledava nekoliko slučajeva u kojima se statistička struktura dječjeg ulaska razlikuje od učenog jezika. Analize pokazuju da se ovi poremećaji ulaza mogu računati s statističkim okvirom učenja pažljivo razmatrajući probleme infekcije koje učenici rešavaju tokom prikupljanja jezika', 'ta': 'மொழி பெறுதல் புள்ளிவிவரமான பிரச்சனையாக மாற்றலாம்: குழந்தைகள் வாக்கியங்களையும் ஒலிகளையும் பயன்படுத்தி மொழியில் உள் ஆயினும், பல நிகழ்ச்சிகளில் குழந்தைகள் தகவலிலிருந்து கற்று கொள்கிறார் இத்தகைய குழப்பங்கள் உள்ளீட்டில் அல்லது குறியீட்டை குறியீட்டிடுவதற்கு காரணமாக குழந்தைகளின் தற்போதைய திட்டங்கள். இந்த வேலை பல நிகழ்வுகளைச் சோதிக்கிறது, அதில் குழந்தைகளின் உள்ளீடுகள் வித்தியாசமான மொழியிலிருந்து கற்றுக்  ஆராய்ச்சி காட்டுகிறது இந்த உள்ளீட்டின் குழப்பத்தை புள்ளிவிவரமான கற்றல் சட்டத்துடன் கணக்கிட முடியும்', 'ur': 'زبان حاصل کی مدل کی جاتی ہے ایک ایسٹیسٹیسی ایفارنس مسئلہ کی طرح: بچے اپنے ایمپ میں جماعت اور آواز استعمال کرتے ہیں زبان ساختار کے لئے۔ However, in many cases, children learn from data whose statistical structure is distorted relative to the language they are learning. یہ اختلاف یا اپنا انپیٹ میں ہو سکتے ہیں، یا بچوں کی ناجور استراتژی کے نتیجے سے ان کے انپیٹ کو اکڈ کرنے کے لئے۔ یہ کام بہت سی مواقع کی تحقیق کرتا ہے جہاں بچوں کے سوال کی آمار سیاسی ساختار کی زبان سے مختلف ہے۔ تحقیقات دکھاتے ہیں کہ ان اینپیٹ کے اختلاف کو ایک ایسٹیسٹی سیکھنے کے فرم کے ذریعہ حساب کر سکتے ہیں کہ اسے مضطرب سمجھتے ہیں کہ سیکھنے والے زبان حاصل کے وقت حل کر رہے ہیں', 'uz': "Tilni olishni statistik qo'llash muammolari sifatida modellashi mumkin: bolalar tillarda so'zlar va tovushlarni qo'shish uchun tovushlarni ishlatish mumkin. Lekin ko'pchilik holatda bolalar o'rganish tilidagi statistik tuzilishidan o'rganadi. Bunday murakkab o'zgarishlar kiritishda yoki bolalar ichiga kodlash uchun umuman strategiya sababchi bo'lishi mumkin. Bu ishni bir necha holatni ko'rib chiqaradi. Bu tilda o'rganish uchun bolalarning statistical tuzuvlari o'zgarishga o'xshash o'xshash. Analysi ko'rsatish mumkin, bu tuzuvlar o'rganishda statistik o'rganish 框架ni o'rganish mumkin va o'rganishda o'rganish muammolarni taqlid qilish mumkin.", 'vi': 'Nhận dạng ngôn ngữ có thể được mô hình thành một vấn đề ngụ ý thống kê: trẻ em dùng câu và âm thanh trong nội dung của họ để luận ra cấu trúc ngôn ngữ. Tuy nhiên, trong nhiều trường hợp, trẻ em học được từ dữ liệu có cấu trúc thống kê bị méo mó tương tự với ngôn ngữ mà họ đang học. Sự xáo trộn này có thể xảy ra trong nội dung của nó, hoặc do những chiến lược thiếu niên của trẻ em cho việc mã hóa nội dung của chúng. Công việc này phân tích nhiều trường hợp phân biệt cấu trúc thống kê của giáo khoa trẻ em với ngôn ngữ được học. Phân tích cho thấy những sai lệch trong dữ liệu này có thể được tính toán với một bộ khung học thống kê qua việc cân nhắc cẩn thận các vấn đề nhận biết mà học sinh giải quyết trong khi học giả dùng ngôn ngữ.', 'bg': 'Придобиването на езика може да бъде моделирано като проблем със статистическото заключение: децата използват изречения и звуци в своите входове, за да извлекат лингвистичната структура. В много случаи обаче децата се учат от данни, чиято статистическа структура е изкривена спрямо езика, който учат. Такива изкривявания могат да възникнат или в самия вход, или в резултат на незрелите стратегии на децата за кодиране на входа им. Тази работа разглежда няколко случая, в които статистическата структура на приноса на децата се различава от езика, който се изучава. Анализите показват, че тези изкривявания на входящите данни могат да бъдат отчетени чрез статистическа учебна рамка чрез внимателно обмисляне на проблемите с изводите, които обучаемите решават по време на придобиването на език', 'hr': 'Prikupljanje jezika može se modelirati kao problem statističke infekcije: djeca koriste rečenice i zvuke u svojim ulazima kako bi zarazila jezičku strukturu. Međutim, u mnogim slučajevima djeca uče iz podataka čija je statistička struktura iskrivljena u odnosu na jezik koji uče. Takve poremećaje mogu se pojaviti ili u samom ulazu, ili kao rezultat dječjih nezadovoljnih strategija za kodiranje njihovog ulaza. Ovaj rad pregledava nekoliko slučajeva u kojima se statistička struktura dječjeg ulaska razlikuje od učenog jezika. Analiziranja pokazuju da se ovi poremećaji ulaza mogu računati s statističkim okvirom učenja pažljivo razmatrajući probleme infekcije koje učenici rješavaju tijekom prikupljanja jezika', 'nl': 'Taalverwerving kan worden gemodelleerd als een statistisch inferentieprobleem: kinderen gebruiken zinnen en geluiden in hun input om de taalstructuur af te leiden. In veel gevallen leren kinderen echter van gegevens waarvan de statistische structuur vervormd is ten opzichte van de taal die ze leren. Dergelijke vervormingen kunnen ontstaan in de input zelf, of als gevolg van onvolwassen strategieën van kinderen om hun input te coderen. Dit werk onderzoekt verschillende gevallen waarin de statistische structuur van de input van kinderen verschilt van de taal die wordt geleerd. Uit analyses blijkt dat deze verstoringen van de input kunnen worden verantwoord met een statistisch leerkader door zorgvuldig te kijken naar de inferentieproblemen die leerlingen oplossen tijdens taalverwerving', 'da': 'Sprogerhvervelse kan modelleres som et statistisk udledelsesproblem: børn bruger sætninger og lyde i deres input til at udlede sproglig struktur. Men i mange tilfælde lærer børn af data, hvis statistiske struktur er forvrænget i forhold til det sprog, de lærer. Sådanne forvrængninger kan opstå enten i selve input eller som følge af børns umodne strategier til kodning af deres input. Dette arbejde undersøger flere tilfælde, hvor den statistiske struktur af børns input adskiller sig fra det sprog, der læres. Analyser viser, at disse forvrængninger af input kan redegøres for med en statistisk læringsramme ved omhyggeligt at overveje de konklusionsproblemer, som eleverne løser under sprogtilegnelse', 'id': 'Akquisisisi bahasa dapat dipodelkan sebagai masalah kesimpulan statistik: anak-anak menggunakan kalimat dan suara dalam input mereka untuk menyimpulkan struktur bahasa. Namun, dalam banyak kasus, anak-anak belajar dari data yang struktur statistiknya distorsi relatif dengan bahasa yang mereka belajar. Disorsi seperti ini dapat muncul baik dalam input sendiri, atau sebagai hasil dari strategi anak-anak yang belum dewasa untuk mengekodikan input mereka. Pekerjaan ini memeriksa beberapa kasus di mana struktur statistik input anak-anak berbeda dari bahasa yang sedang belajar. Analisis menunjukkan bahwa distorsi ini dari input dapat dianggap dengan cadangan pembelajaran statistik dengan mempertimbangkan dengan hati-hati masalah kesimpulan yang pelajar memecahkan selama pengakuan bahasa', 'de': 'Der Spracherwerb kann als statistisches Inferenzproblem modelliert werden: Kinder verwenden Sätze und Töne in ihren Eingaben, um sprachliche Strukturen abzuleiten. In vielen Fällen lernen Kinder jedoch aus Daten, deren statistische Struktur im Verhältnis zur erlernten Sprache verzerrt ist. Solche Verzerrungen können entweder im Input selbst oder als Folge von unreifen Strategien der Kinder zur Kodierung ihrer Inputs auftreten. Diese Arbeit untersucht mehrere Fälle, in denen sich die statistische Struktur des kindlichen Inputs von der erlernten Sprache unterscheidet. Analysen zeigen, dass diese Verzerrungen des Inputs mit einem statistischen Lernframework berücksichtigt werden können, indem die Inferenzprobleme, die Lernende beim Spracherwerb lösen, sorgfältig berücksichtigt werden.', 'ko': '언어 습득은 통계적 추측 문제로 모델링될 수 있다. 어린이는 입력에서 문장과 소리를 사용하여 언어 구조를 추측한다.그러나 많은 상황에서 아이들은 데이터에서 배운다. 이러한 데이터의 통계 구조는 그들이 배운 언어에 비해 비뚤어진다.이런 왜곡은 입력 자체에서 발생할 수도 있고 어린이의 미성숙한 입력 인코딩 전략의 결과일 수도 있다.이 작업은 어린이 입력의 통계 구조와 배운 언어가 다른 몇 가지 사례를 고찰했다.분석에 의하면 학습자가 언어 습득 과정에서 해결한 추리 문제를 자세히 고려함으로써 통계 학습 구조로 입력의 이러한 왜곡을 해석할 수 있다', 'fa': 'دریافت زبان می\u200cتواند به عنوان یک مشکل آلودگی آمریکایی مدل شود: کودکان از جمله\u200cها و صداها در ورودشان برای آلودگی ساختار زبان استفاده می\u200cکنند. ولی در بسیاری موارد، کودکان از داده\u200cها یاد می\u200cگیرند که ساختار آمار آنها نسبت به زبانی که دارند یاد می\u200cگیرند تغییر داده می\u200cشود. این تغییرات می\u200cتوانند یا در خودش وارد شود، یا به نتیجه استراتژی\u200cهای غیر طبیعی کودکان برای کودکان کردن وارد شدن آنها رخ دهند. این کار چند پرونده را تحقیق می\u200cکند که ساختار آماری ورودی کودکان از زبان یاد گرفته می\u200cشود. تحلیل\u200cها نشان می\u200cدهند که این تغییرات ورودی می\u200cتوانند با یک چهارچوب آموزش آموزش آموزشی با دقت با توجه به مشکلات آلودگی که یادآوران در طول گرفتن زبان حل می\u200cکنند', 'sw': 'Upatikanaji wa lugha unaweza kuchukuliwa kama tatizo la maambukizi ya takwimu: Watoto wanatumia sentensi na sauti katika viwanja vyao ili kupunguza mfumo wa lugha. Hata hivyo, katika matukio mengi, watoto wanajifunza kutoka kwa taarifa ambazo muundo wa takwimu unavurugwa na lugha ambayo wanajifunza. Changamoto kama hizi zinaweza kutokea katika matokeo yake mwenyewe, au matokeo ya mikakati ya watoto wasio na umuhimu kwa ajili ya kuingia input wao. Kazi hii inachunguza kesi kadhaa ambapo mfumo wa takwimu wa kituo cha watoto unatofautiana na lugha inayojifunza. Uchambuzi unaonyesha kwamba mabadiliko haya ya input yanaweza kuchukuliwa na mfumo wa kujifunza takwimu kwa makini kuzingatia matatizo ya maambukizi yanayojifunza kutatua wakati wa kupata lugha', 'tr': 'Dil almak isleýän statistik hasaplanjak meselesi hökmünde örneklendirilebilir: çagalar sözleri we ses girişinde dil strukturyny azaltmak üçin ulanýarlar. Ýöne köp wagtlarda çagalar statistik strukturynyň diline görä çykyp bilýärler. Böyle çöplükler girdi-de ýa-da çagalaryň içeri kodlamak üçin ýagdaýynda bolup biler. Bu işe çagalaryň girişiniň statistik düzümleriniň dilinden tapawutlandygyny birnäçe gadyry barýar. Analyzalar bu girişiň çözgütlerini statistik öwrenmek çerçevesi bilen baglanyp bilýär öwrenmeklerin dil tapmaklarynyň çözmesini ünsli bilen çözerek', 'af': "Taal aanvang kan as 'n statistiese inferensie probleem modelleer word: kinders gebruik setnings en klanke in hul invoer om lingwisiese struktuur te verloor. Maar in baie gevalle leer kinders van data wie se statistiese struktuur versterk word relatief tot die taal wat hulle leer. sodanige distortione kan opstaan of in die invoer self, of a s 'n resultaat van kinders se ongelukkige strategies vir kodering van hulle invoer. Hierdie werk ondersoek verskeie gevalle waarin die statistiese struktuur van kinders se invoer verander van die taal wat leer word. Analiseerdes wys dat hierdie uitbreidings van die invoer kan bereken word vir met 'n statistiese leer raamwerk deur versigtig te onderwerp van die uitbreidingsprobleme wat leerners oplos tydens taal aanvanging", 'sq': 'Merrja e gjuhës mund të modelohet si një problem statistikor përfundimi: fëmijët përdorin fjalë dhe tinguj në hyrjen e tyre për të inferuar strukturën gjuhësore. Megjithatë, në shumë raste, fëmijët mësojnë nga të dhënat struktura statistike e të cilave është e shtrembëruar në krahasim me gjuhën që po mësojnë. Ndryshimet e tilla mund të shfaqen ose në vetë hyrjen, ose si rezultat i strategjive të papritura të fëmijëve për kodimin e hyrjes s ë tyre. Ky punë shqyrton disa raste në të cilat struktura statistike e hyrjes s ë fëmijëve ndryshon nga gjuha që mësohet. Analizat tregojnë se këto distorsione të hyrjes mund të llogariten me një kuadër mësimi statistik duke konsideruar me kujdes problemet e përfundimit që mësuesit zgjidhin gjatë blerjes së gjuhës', 'am': "ቋንቋ ማግኘት የstatistic ድካም መሆኑን እንደሚመስል ይችላል፤ ልጆች የቋንቋ ቋንቋ መሠረት እና ድምጾችን በመጠቀም ይናገራሉ፡፡ ምንም እንኳን በብዙ ጉዳዮች፣ ልጆች ከዳታ ተማራሉ፡፡ እንደዚህ ያሉ ሽብርታዎች ቢሆን ወይም የሕፃናቱ ፍላጎት የድምፅ ውጤታቸውን ለማክበር የሚችል ማሰናከል ይችላል፡፡ This work examines several cases in which the statistical structure of children's input differs from the language being learned.  Analysis shows that these ጥላቻዎች የደረጃ ውጤቶች በstatistical ትምህርት ፍሬም በመጠቀም በቋንቋ ማግኘት ጊዜ የሚተማሩትን የድካም መከራዎች በጥንቃቄ በመቆጣጠር ይችላል፡፡", 'hy': "Լեզու ձեռք բերումը կարելի է մոդելավորել որպես վիճակագրական հետևանքների խնդիր. երեխաները օգտագործում են նախադասություններ և ձայներ իրենց ներմուծքում լեզվաբանական կառուցվածքի հետևանքների համար: Այնուամենայնիվ, շատ դեպքերում երեխաները սովորում են տվյալներից, որոնց վիճակագրական կառուցվածքը խառնաշփոթված է իրենց սովորող լեզուների հետ: Այսպիսի շեղումները կարող են առաջացնել կամ ներմուծի մեջ, կամ երեխաների անչափահաս ռազմավարությունների արդյունքում իրենց ներմուծի կոդավորման համար: This work examines several cases in which the statistical structure of children's input differs from the language being learned.  Հետազոտությունները ցույց են տալիս, որ ներմուծի այս շեղումները կարելի է հաշվի առնել վիճակագրական ուսումնասիրության շրջանակներով, ուշադիր հաշվի առնելով այն խնդիրները, որոնք ուսանողները լուծում են լեզվի ձեռք բերման ժամանակ", 'az': 'Dil alınması Statistik infeksiya problemi olaraq modelləşdirilebilir: uşaqlar dil qurularını azaltmaq üçün sözləri və səsləri istifadə edirlər. Ancaq çoxlu məsələlərdə çoxlu uşaqlar statistik quruluğunun öyrəndiklərinin dilinə qovuşduğu məlumatlardan öyrənirlər. Bütün bu xəstəliklər, ya giriş içində olar, ya da çocukların kodlama münasibətlərinin s əbəbi olar. Bu işlər çocukların girişin in statistik quruluğunun dilindən fərqli olduğuna görə baxır. Analyzlər göstərir ki, bu girişin dəyişikliklərinin statistik öyrənmə qurğusu ilə hesab edilə bilər, öyrənənənlərin dil alması sırasında çəkilən dəyişiklik problemlərini çox gözəl baxırlar.', 'bn': 'ভাষা পেতে পারে পরিসংখ্যানের পরিসংখ্যানের অসুস্থ সমস্যা হিসেবে মডেল করা যাবে: শিশুরা ভাষাগত কাঠামোর আক্রান্ত কাঠামোর তবে অনেক ক্ষেত্রে শিশুরা তথ্য থেকে শিক্ষা পায় যাদের পরিসংখ্যানের কাঠামো তাদের শিক্ষা যে ভাষার সাথে তাদ এই ধরনের বিভ্রান্তিগুলো নিজের ইনপুটে উঠতে পারে, অথবা বাচ্চাদের অভিযুক্ত কৌশলের ফলে তাদের ইনপুট করার জন্য। এই কাজের বেশ কয়েকটি কেস পরীক্ষা করেছে যেখানে শিশুদের ইনপুটের পরিসংখ্যান কাঠামোটি ভাষা থেকে ভিন্ন ভাষা শ বিশ্লেষণ দেখা যাচ্ছে যে এই ইনপুটের বিভ্রান্তিগুলো পরিসংখ্যান শিক্ষা কার্যক্রমের সাথে হিসেবে গণ্য করা যাবে সাবধানে ভাষা পেতে শি', 'bs': 'Prikupljanje jezika se može modelirati kao problem statističke infekcije: djeca koriste rečenice i zvuke u svojim ulaznim ulogama da bi zarazila jezičku strukturu. Međutim, u mnogim slučajevima, djeca uče iz podataka čija je statistička struktura iskrivljena u odnosu na jezik koji uče. Takve poremećaje mogu se pojaviti ili u samom ulazu, ili kao rezultat dječjih nezadovoljih strategija za kodiranje njihovog ulaza. Ovaj rad pregledava nekoliko slučajeva u kojima se statistička struktura dječjeg ulaza razlikuje od učenog jezika. Analiziranja pokazuju da se ovi poremećaji ulaza mogu računati s statističkim okvirom učenja pažljivo razmatrajući probleme infekcije koje učenici rješavaju tijekom prikupljanja jezika', 'ca': "L'adquisició de llenguatges pot ser modelada com un problem a d'infer ència estadística: els nens utilitzen frases i sons en les seves entrades per inferir l'estructura lingüística. Tot i així, en molts casos, els nens aprenen de dades la estructura estadística de les quals està distorsionada en relació amb la llengua que aprenen. Aquestes distorsions poden aparèixer o en la pròpia entrada, o com a resultat de les estratègies immature s dels nens per codificar la seva entrada. Aquesta feina examina diversos casos en els quals l'estructura estadística de la informació infantil difere de la llengua que s'aprenen. Les anàlisis mostren que aquestes distorsions de la entrada es poden tenir en compte amb un marc d'aprenentatge estadística considerant atentament els problemes de inferència que els alumnes resolen durant l'adquisició de llenguatges", 'cs': 'Získávání jazyka lze modelovat jako statistický inferenční problém: děti používají ve svém vstupu věty a zvuky k odvození jazykové struktury. Nicméně v mnoha případech se děti učí z údajů, jejichž statistická struktura je zkreslena vzhledem k jazyku, který se učí. Takové zkreslení mohou vzniknout buď ve vstupu samotném, nebo v důsledku nezralých strategií dětí pro kódování jejich vstupu. Tato práce zkoumá několik případů, kdy se statistická struktura vstupu dětí liší od učeného jazyka. Analýzy ukazují, že tato narušení vstupu lze vypočítat pomocí statistického učebního rámce pečlivým zvážením problémů s inferencí, které žáci řeší během osvojování jazyka', 'et': 'Keele omandamist saab modelleerida statistilise järeldusprobleemina: lapsed kasutavad keelestruktuuri järeldamiseks lauseid ja helisid. Paljudel juhtudel õpivad lapsed aga andmetest, mille statistiline struktuur on võrreldes keelega moonutatud. Sellised moonutused võivad tekkida kas sisendis endas või laste ebaküpsete sisendite kodeerimise strateegiate tulemusena. Käesolevas töös uuritakse mitmeid juhtumeid, kus laste sisendite statistiline struktuur erineb õppitavast keelest. Analüüsid näitavad, et neid sisendi moonutusi saab arvestada statistilise õpperaamistiku abil, kaaludes hoolikalt järeldusprobleeme, mida õppijad lahendavad keele omandamise ajal', 'fi': 'Kielen hankkimista voidaan mallintaa tilastollisena päättelyongelmana: lapset käyttävät lauseita ja ääniä kielellisen rakenteen päättelyyn. Monissa tapauksissa lapset oppivat kuitenkin tiedoista, joiden tilastollinen rakenne on vääristynyt suhteessa oppimaansa kieleen. Tällaisia vääristymiä voi syntyä joko itse syötteessä tai lasten epäkypsien strategioiden seurauksena syötteensä koodaamiseksi. Tässä työssä tarkastellaan useita tapauksia, joissa lasten panoksen tilastollinen rakenne eroaa opitusta kielestä. Analyysit osoittavat, että nämä panoksen vääristymät voidaan selittää tilastollisella oppimiskehyksellä tarkastelemalla huolellisesti päättelyongelmia, joita oppijat ratkaisevat kielen hankinnan aikana.', 'jv': 'first Nanging, akeh-akeh durung, gambar-akeh luwih basa dadi, dadi sing isih dadi sak dadi nggawe barang pengguna sak kudu nggambar luwih apik. Dijejer-jejer mbukak iso dianggapkno nang daftar tentang, njuk dadi kaya pancen dumadhi winih kanggo koder tentang Workspace Tanalén menehi wong kuwi nggawe diolah iki ning kelas nang ingkang iso luwih nguasai patetik sing nggawe barang nggawe nguasai perbudhakan kanggo ngerasai perbudhakan kanggo layang-layang', 'he': 'השיגור של שפת יכול להיות מודל כבעיית התוצאה סטטיסטית: ילדים משתמשים במשפטים וקולות בתכנית שלהם כדי להעלות מבנה שפתי. However, in many cases, children learn from data whose statistical structure is distorted relative to the language they are learning.  דיווחים כאלה יכולים להתרחש או בתוך הכניסה עצמה, או כתוצאה של אסטרטגיות ילדים בלתי בוגרים לקוד הכניסה שלהם. העבודה הזו בוחנת מספר מקרים שבהם המבנה הסטטיסטי של הכניסה של ילדים שונה מהשפה שנלמדה. ניתוחים מראים שהעיוורים האלה של הכניסה יכולים להיחשב על ידי מסגרת לימוד סטטיסטי על ידי שיקול בזהירות בבעיות ההנחה שהלומדים פותרים במהלך רכישת שפה', 'sk': 'Pridobivanje jezika je mogoče modelirati kot problem statističnega sklepanja: otroci uporabljajo stavke in zvoke za sklepanje jezikovne strukture. Vendar se otroci v mnogih primerih učijo iz podatkov, katerih statistična struktura je izkrivljena glede na jezik, ki se ga učijo. Takšna izkrivljanja se lahko pojavijo bodisi v samem vnosu bodisi kot posledica otrokovih nezrelih strategij za kodiranje njihovih vnosov. V delu so obravnavani več primerov, v katerih se statistična struktura vnosov otrok razlikuje od jezika, ki se uči. Analize kažejo, da je to izkrivljanje vnosov mogoče upoštevati s statističnim učnim okvirom s skrbnim preučevanjem problemov sklepanja, ki jih učenci rešujejo med pridobivanjem jezika.', 'ha': "Ana iya motsa kunna harshe kamar wata mataimaki na ƙayyade: yãra sunã amfani da maganar da saurare cikin tsarin da ke ƙaranci cikin linguistic. Amma, a cikin masu yawa, masu haifi daga data, wanda ake ƙẽtare tsarin statistics na zuwa harshen da za'a karanta. Tsarin haka, za'a iya fito ko kuwa a cikin cikin shirin ka ko kuma a matsalar kayan zaren da ba'a zartar da su kodi injistan. This work examines several cases in which the statistical structure of children's input differs from the language being learned.  Ana yi anarrawa ya nuna cewa, wannan gauraya cikin ana iya lissafa shi da firam na karanta statistical ko kuma ana yi sauri game da muhimman zartar da za'a sanar da su solar a lokacin da za'a sami lugha", 'bo': "སྐད་ཡིག་ཆ་དང་ཐ་སྙད་འདི་རྩོལ་ནུས་ཀྱི་ཚད་རྩིས་བའི་དཀའ་ངལ་ཅིག ཡིན་ནའང་། ཕལ་ཆེར་མང་པོ་ཞིག་ལ་སྙན་པའི་ཆ་འཕྲིན་རིགས་དབྱིབས་ཆགས་པའི་ཆ་འཕྲིན་ཡིན་གྱི་ཆ་འཕྲིན་དང་། Such distortions can arise either in the input itself, or a s a result of children's immature strategies for encoding their input. ལས་ཀ་འདིས་སྒྲུབ་ནང་དུ་ཆ་ཚོའི་ཚད་རྩིས་ཀྱི་གནས་ཚུལ་མང་པོ་ཞིག་དཔྱད་བྱས་ནས་སྐད་རིགས་ཤེས་པའི་ཚད་རྩིས་གཞ Analyzes show that these distortions of the input can be accounted for with a statistical learning framework by carefully considering the inference problems that learners solve during language acquisition"}
{'en': 'Exploring the Syntactic Abilities of RNNs with Multi-task Learning', 'ar': 'استكشاف القدرات النحوية لـ RNNs مع التعلم متعدد المهام', 'pt': 'Explorando as habilidades sintáticas de RNNs com aprendizado multitarefa', 'es': 'Exploración de las habilidades sintácticas de las RNN con el aprendizaje multitarea', 'fr': "Explorer les capacités syntaxiques des RNN grâce à l'apprentissage multitâche", 'ja': 'マルチタスク学習でRNNの構文能力を探る', 'hi': 'मल्टी-टास्क लर्निंग के साथ आरएनएन की वाक्यात्मक क्षमताओं की खोज', 'zh': '以多任务学探RNN之句法能', 'ru': 'Изучение синтаксических способностей RNN с многозадачным обучением', 'ga': 'Iniúchadh ar Chumais Chomhréire RNNanna le Foghlaim Ilthasc', 'ka': 'ბევრი რაოდენობის სწავლებით RNN-ის სინტაქტიკური ბილიტის გამოყენება', 'el': 'Εξερεύνηση των συντακτικών ικανοτήτων των RNN με εκμάθηση πολλαπλών εργασιών', 'hu': 'Az RNN-ek szintaktikus képességeinek feltárása többfeladatos tanulással', 'kk': 'Көп тапсырмалар оқу арқылы RNN синтактикалық мүмкіндіктерін зерттеу', 'it': "Esplorare le abilità sintattiche degli RNN con l'apprendimento multi-task", 'lt': 'RNN sintaktinių gebėjimų tyrimas su daugiafunkciniu mokymusi', 'mk': 'Истражување на синтактичките способности на РНН со учење со повеќе задачи', 'ms': 'Exploring the Syntactic Abilities of RNNs with Multi-task Learning', 'ml': 'Exploring the Syntactic Abilities of RNNs with Multi-task Learning', 'mn': 'ДНХ-ын олон ажлын сургалтын синтактикийн чадварыг судлах', 'mt': 'L-esplorazzjoni tal-Abilitajiet Sintattiċi ta’ RNNs b’Tagħlim Multikompitu', 'no': 'Utforskar syntaktiske tilstand for RNN med fleire oppgåver', 'pl': 'Badanie zdolności syntaktycznych RNN za pomocą wielozadaniowego uczenia się', 'ro': 'Explorarea abilităților sintactice ale RNN-urilor cu învățare multi-sarcină', 'sr': 'Ispitivanje sintaktičkih sposobnosti RNN-a sa učenjem više zadataka', 'si': 'Multi-Job ඉගෙනීම සඳහා RNN ගේ සින්ටැක්ටික ඇබිලිටියිස් ප්\u200dරශ්නය කරනවා', 'so': 'Muujinta awoodda Syntactic of RNNs with multi-task Learning', 'sv': 'Att utforska de syntaktiska förmågorna hos RNN med Multi-Task Learning', 'ta': 'Name', 'ur': 'Multi-task Learning کے ساتھ RNN کے سینٹاکتیک آبلیٹیوں کا تحقیق کرتا ہے', 'uz': 'Name', 'vi': 'Khám phá khả năng pháp thuật của RNN với việc giáo dục đa nhiệm vụ', 'hr': 'Ispitivanje sintaktičkih sposobnosti RNN-a s učenjem višezadataka', 'nl': "Het verkennen van de syntactische vaardigheden van RNN's met multitask leren", 'da': "Udforsk de syntaktiske evner i RNN'er med multi-opgave læring", 'ko': '다중 임무로 RNN의 문법 능력을 탐색하는 것을 배우다', 'de': 'Erforschung der syntaktischen Fähigkeiten von RNNs mit Multi-Task Learning', 'bg': 'Изследване на синтактичните способности на RNN с многофункционално обучение', 'id': 'Menjelaskan Kemampuan Sintaktik RNN dengan Belajar Multi-Tugas', 'sw': 'Kueleza uwezo wa ushirikiano wa RNN kwa mafunzo mengi', 'fa': 'تحقیق توانایی سینتکتیک RNN با یادگیری چند کار', 'af': 'Ondersoek die Syntaktiese Abiliteite van RNN met Multi-Task Leer', 'sq': 'Shqyrtimi i aftësive sintaktike të RNN-ve me Mësimin Multi-Tash', 'tr': "Multi-task öwrenmek bilen RNN'iň Sintaktik Abilitetlerini barlaýar", 'az': 'Multi-task √∂yr…ônm…ôsi il…ô RNN sintaktik qabiliyy…ôtl…ôrini t…ôhsil edir', 'am': 'ምርጫዎች', 'bn': 'বহুক্ষেত্র শিক্ষা দিয়ে RNNs-এর সিন্ট্যাক্টিক বিষয়গুলো ব্যবহার করা হচ্ছে', 'hy': 'ՌՆԹ-ների սինտակտիկ ունակությունների ուսումնասիրելը բազմախնդիրների սովորելով', 'bs': 'Ispitivanje sintaktičkih sposobnosti RNN-a sa učenjem multitask', 'ca': 'Explorar les capacitats sintàtiques dels RNA amb aprenentatge multitascat', 'cs': 'Zkoumání syntaktických schopností RNN s víceúlohovým učením', 'et': 'RNN-ide süntaktiliste võimete uurimine mitmeülesandelise õppega', 'fi': 'Tutkitaan RNN:ien synteettisiä kykyjä monitehtäväoppimisen avulla', 'jv': 'Jejaring', 'he': 'לחקור את היכולות הסינטקטיות של RNN עם הלימוד של משימות רבות', 'ha': 'KCharselect unicode block name', 'sk': 'Raziskovanje sintaktičnih sposobnosti RNN z večopravilnim učenjem', 'bo': 'Multi-task Learning་ཅན་གྱིས་སྦྲེལ་མཐུད་སྤྱོད་ཀྱི་དབྱེ་སྟངས་ལ་རྒྱུད་སྤྱོད་ཀྱི་གནད་དོན་འདྲི་ཞིབ་བྱེད་པ'}
{'en': 'Recent work has explored the syntactic abilities of RNNs using the subject-verb agreement task, which diagnoses sensitivity to sentence structure. RNNs performed this task well in common cases, but faltered in complex sentences (Linzen et al., 2016). We test whether these errors are due to inherent limitations of the architecture or to the relatively indirect supervision provided by most agreement dependencies in a corpus. We trained a single RNN to perform both the agreement task and an additional task, either CCG supertagging or language modeling. Multi-task training led to significantly lower error rates, in particular on complex sentences, suggesting that RNNs have the ability to evolve more sophisticated syntactic representations than shown before. We also show that easily available agreement training data can improve performance on other syntactic tasks, in particular when only a limited amount of training data is available for those tasks. The multi-task paradigm can also be leveraged to inject grammatical knowledge into language models.', 'ar': 'استكشف العمل الأخير القدرات النحوية لـ RNNs باستخدام مهمة اتفاق الفاعل والفعل ، والتي تشخص الحساسية لتركيب الجملة. أدت RNNs هذه المهمة بشكل جيد في الحالات الشائعة ، لكنها تعثرت في الجمل المعقدة (Linzen et al. ، 2016). نحن نختبر ما إذا كانت هذه الأخطاء ناتجة عن قيود متأصلة في البنية أو إلى الإشراف غير المباشر نسبيًا الذي توفره معظم تبعيات الاتفاقية في مجموعة ما. قمنا بتدريب RNN واحد لأداء مهمة الاتفاقية ومهمة إضافية ، إما CCG supertagging أو نمذجة اللغة. أدى التدريب متعدد المهام إلى انخفاض معدلات الخطأ بشكل كبير ، لا سيما في الجمل المعقدة ، مما يشير إلى أن RNNs لديها القدرة على تطوير تمثيلات نحوية أكثر تعقيدًا مما هو موضح من قبل. نظهر أيضًا أن بيانات التدريب على الاتفاقية المتاحة بسهولة يمكن أن تحسن الأداء في المهام النحوية الأخرى ، لا سيما عندما يتوفر مقدار محدود فقط من بيانات التدريب لهذه المهام. يمكن أيضًا الاستفادة من نموذج المهام المتعددة لإدخال المعرفة النحوية في النماذج اللغوية.', 'pt': 'Trabalhos recentes exploraram as habilidades sintáticas de RNNs usando a tarefa de concordância sujeito-verbo, que diagnostica a sensibilidade à estrutura da frase. As RNNs desempenharam bem essa tarefa em casos comuns, mas falharam em sentenças complexas (Linzen et al., 2016). Testamos se esses erros são devidos a limitações inerentes da arquitetura ou à supervisão relativamente indireta fornecida pela maioria das dependências de acordo em um corpus. Treinamos um único RNN para realizar tanto a tarefa de concordância quanto uma tarefa adicional, seja supermarcação CCG ou modelagem de linguagem. O treinamento multitarefa levou a taxas de erro significativamente mais baixas, em particular em frases complexas, sugerindo que as RNNs têm a capacidade de desenvolver representações sintáticas mais sofisticadas do que as mostradas anteriormente. Também mostramos que dados de treinamento de acordo facilmente disponíveis podem melhorar o desempenho em outras tarefas sintáticas, em particular quando apenas uma quantidade limitada de dados de treinamento está disponível para essas tarefas. O paradigma multitarefa também pode ser aproveitado para injetar conhecimento gramatical em modelos de linguagem.', 'fr': "Des travaux récents ont exploré les capacités syntaxiques des RNN à l'aide de la tâche d'accord sujet-verbe, qui diagnostique la sensibilité à la structure de la phrase. Les RNN ont bien rempli cette tâche dans les cas courants, mais ont échoué dans les phrases complexes (Linzen et al., 2016). Nous testons si ces erreurs sont dues à des limitations inhérentes à l'architecture ou à la supervision relativement indirecte fournie par la plupart des dépendances d'accord dans un corpus. Nous avons formé un seul RNN pour effectuer à la fois la tâche d'accord et une tâche supplémentaire, soit le supermarquage CCG ou la modélisation linguistique. La formation multitâche a permis de réduire considérablement les taux d'erreur, en particulier sur les phrases complexes, ce qui suggère que les RNN ont la capacité de développer des représentations syntaxiques plus sophistiquées que celles montrées précédemment. Nous montrons également que des données de formation d'accord facilement disponibles peuvent améliorer les performances sur d'autres tâches syntaxiques, en particulier lorsque seule une quantité limitée de données d'entraînement est disponible pour ces tâches. Le paradigme multitâche peut également être utilisé pour injecter des connaissances grammaticales dans les modèles linguistiques.", 'es': 'Un trabajo reciente ha explorado las habilidades sintácticas de las RNN utilizando la tarea de concordancia sujeto-verbo, que diagnostica la sensibilidad a la estructura de la oración. Las RNN realizaron bien esta tarea en casos comunes, pero vacilaron en oraciones complejas (Linzen et al., 2016). Probamos si estos errores se deben a limitaciones inherentes de la arquitectura o a la supervisión relativamente indirecta proporcionada por la mayoría de las dependencias de acuerdo en un corpus. Entrenamos a un solo RNN para realizar tanto la tarea de acuerdo como una tarea adicional, ya sea superetiquetado CCG o modelado del lenguaje. El entrenamiento multitarea condujo a tasas de error significativamente más bajas, en particular en oraciones complejas, lo que sugiere que las RNN tienen la capacidad de desarrollar representaciones sintácticas más sofisticadas que las mostradas anteriormente. También mostramos que los datos de entrenamiento de acuerdo fácilmente disponibles pueden mejorar el rendimiento en otras tareas sintácticas, en particular cuando solo hay una cantidad limitada de datos de entrenamiento disponibles para esas tareas. El paradigma multitarea también se puede aprovechar para inyectar conocimientos gramaticales en los modelos lingüísticos.', 'ja': '最近の研究では、文章構造に対する感度を診断する主語-動詞合意タスクを使用して、RNNの構文能力を探求しています。 RNNは、一般的なケースではこのタスクをうまく実行しましたが、複雑な文章ではうまくいきませんでした（ Linzen et al., 2016 ）。 私たちは、これらのエラーがアーキテクチャの固有の制限によるものか、コーパス内のほとんどの合意依存関係によって提供される比較的間接的な監督によるものかをテストします。 合意タスクと追加タスクの両方を実行するために、単一のRNNをトレーニングしました。CCGスーパータグ付けまたは言語モデリングのいずれかです。 マルチタスクトレーニングは、特に複雑な文のエラー率を著しく低くし、RNNが以前に示されたよりも洗練された構文表現を進化させる能力を有することを示唆した。 また、容易に入手できる合意トレーニングデータは、特にこれらのタスクのトレーニングデータが限られている場合に、他の構文タスクのパフォーマンスを向上させることができることも示されています。 マルチタスクパラダイムを活用して、文法的知識を言語モデルに注入することもできる。', 'hi': 'हाल के काम ने विषय-क्रिया समझौते के कार्य का उपयोग करके आरएनएन की वाक्यात्मक क्षमताओं का पता लगाया है, जो वाक्य संरचना के प्रति संवेदनशीलता का निदान करता है। RNNs ने इस कार्य को आम मामलों में अच्छी तरह से किया, लेकिन जटिल वाक्यों में लड़खड़ा गया (Linzen et al., 2016)। हम परीक्षण करते हैं कि क्या ये त्रुटियां वास्तुकला की अंतर्निहित सीमाओं के कारण हैं या एक कॉर्पस में अधिकांश समझौते निर्भरताओं द्वारा प्रदान की गई अपेक्षाकृत अप्रत्यक्ष पर्यवेक्षण के कारण हैं। हमने समझौते के कार्य और एक अतिरिक्त कार्य, या तो सीसीजी सुपरटैगिंग या भाषा मॉडलिंग दोनों को करने के लिए एक एकल आरएनएन को प्रशिक्षित किया। बहु-कार्य प्रशिक्षण ने विशेष रूप से जटिल वाक्यों पर काफी कम त्रुटि दर का नेतृत्व किया, यह सुझाव देते हुए कि आरएनएन में पहले दिखाए गए की तुलना में अधिक परिष्कृत वाक्यात्मक प्रतिनिधित्व विकसित करने की क्षमता है। हम यह भी दिखाते हैं कि आसानी से उपलब्ध समझौता प्रशिक्षण डेटा अन्य वाक्यात्मक कार्यों पर प्रदर्शन में सुधार कर सकता है, विशेष रूप से जब उन कार्यों के लिए केवल सीमित मात्रा में प्रशिक्षण डेटा उपलब्ध होता है। बहु-कार्य प्रतिमान को भाषा मॉडल में व्याकरणिक ज्ञान को इंजेक्ट करने के लिए भी लाभ उठाया जा सकता है।', 'zh': '近事用主语 - 动词一致性求RNN句法能,当诊其敏感性。 RNN于众务甚善,而步履蹒跚(Linzen等于杂句,2016)。 臣等试此谬由体系结构之固有限,犹由语料库中多协议仰给之对间接监督。 练一RNN以行协议附加任务,CCG超级标记言建模。 多任务训练致错误率显降,特在杂句,明RNN有见于前句法之力也。 又明数可以益句法,特当有有限之数可以施之也。 又因多任务范式语法注语模中。', 'ru': 'Недавняя работа исследовала синтаксические способности RNNs используя задачу соглашения субъект-глагол, которая диагностирует чувствительность к структуре предложения. RNN хорошо выполняли эту задачу в распространенных случаях, но неустойчиво в сложных предложениях (Linzen et al., 2016). Мы проверяем, обусловлены ли эти ошибки внутренними ограничениями архитектуры или относительно косвенным надзором, обеспечиваемым большинством зависимостей соглашения в корпусе. Мы обучили одного RNN выполнять как задачу соглашения, так и дополнительную задачу, либо супертегирование CCG, либо языковое моделирование. Многозадачное обучение привело к значительному снижению частоты ошибок, в частности, по сложным предложениям, предполагая, что RNN имеют способность развивать более сложные синтаксические представления, чем показано ранее. Мы также показываем, что легкодоступные обучающие данные соглашения могут улучшить производительность по другим синтаксическим задачам, в частности, когда для этих задач доступно только ограниченное количество обучающих данных. Многозадачная парадигма также может быть использована для внедрения грамматических знаний в языковые модели.', 'ga': "In obair le déanaí tá iniúchadh déanta ar chumais chomhréire na RNNanna ag baint úsáide as an tasc comhaontú ábhair-briathar, a dhiagnóisíonn íogaireacht i leith struchtúr abairte. Rinne RNNanna an tasc seo go maith i gcásanna coitianta, ach tháinig meath orthu in abairtí casta (Linzen et al., 2016). Déanaimid tástáil ar cibé acu an bhfuil na hearráidí seo mar gheall ar theorainneacha dúchasacha na hailtireachta nó de bharr na maoirseachta réasúnta indírí a sholáthraíonn formhór na spleáchais ar chomhaontuithe i gcorpas. Chuireamar oiliúint ar RNN amháin chun tasc an chomhaontaithe agus tasc breise a dhéanamh, sárchlibeáil CCG nó samhaltú teanga. D'eascair rátaí earráide i bhfad níos ísle as oiliúint il-tasc, go háirithe maidir le habairtí casta, rud a thugann le tuiscint go bhfuil an cumas ag RNNanna léiriú comhréire níos sofaisticiúla a fhorbairt ná mar a léiríodh roimhe seo. Léirímid freisin gur féidir le sonraí oiliúna comhaontaithe atá ar fáil go héasca feabhas a chur ar fheidhmíocht ar thascanna comhréire eile, go háirithe nuair nach bhfuil ach méid teoranta sonraí oiliúna ar fáil le haghaidh na dtascanna sin. Is féidir an paraidím ilthasc a ghiaráil freisin chun eolas gramadaí a instealladh isteach i múnlaí teanga.", 'el': 'Πρόσφατες εργασίες έχουν διερευνήσει τις συντακτικές ικανότητες των RNN χρησιμοποιώντας την εργασία συμφωνίας υποκειμένου-ρήματος, η οποία διαγνώνει ευαισθησία στη δομή των προτάσεων. Τα RNN εκτέλεσαν αυτό το έργο καλά σε κοινές περιπτώσεις, αλλά παρέλειψαν σε σύνθετες προτάσεις (Linzen et al., 2016). Εξετάζουμε αν αυτά τα λάθη οφείλονται σε εγγενείς περιορισμούς της αρχιτεκτονικής ή στην σχετικά έμμεση εποπτεία που παρέχεται από τις περισσότερες εξαρτήσεις συμφωνίας σε ένα σώμα. Εκπαιδευτήκαμε ένα μόνο RNN για να εκτελέσει τόσο την εργασία συμφωνίας όσο και μια πρόσθετη εργασία, είτε υπερσήμανση CCG ή γλωσσική μοντελοποίηση. Η εκπαίδευση πολλαπλών εργασιών οδήγησε σε σημαντικά χαμηλότερα ποσοστά σφαλμάτων, ιδίως σε σύνθετες προτάσεις, υποδηλώνοντας ότι τα RNN έχουν την ικανότητα να αναπτύσσουν πιο εξελιγμένες συντακτικές αναπαραστάσεις από ό,τι φαίνεται πριν. Δείχνουμε επίσης ότι τα εύκολα διαθέσιμα δεδομένα κατάρτισης συμφωνιών μπορούν να βελτιώσουν την απόδοση σε άλλες συντακτικές εργασίες, ιδίως όταν είναι διαθέσιμα μόνο περιορισμένα δεδομένα κατάρτισης για αυτές τις εργασίες. Το παράδειγμα πολλαπλών εργασιών μπορεί επίσης να χρησιμοποιηθεί για την εισαγωγή γραμματικής γνώσης στα γλωσσικά μοντέλα.', 'kk': 'Жуырдағы жұмыс сұрақтар құрылымына сезімсіздігін диагностикациялау үшін тақырыпты келесі арқылы RNN синтактикалық мүмкіндіктерін зерттеді. RNN бұл тапсырманы жалпы жағдайда жұмыс істеді, бірақ комплекс сөздерде (Linzen et al., 2016). Біз бұл қателер архитектураның шектеулері немесе корпус тәуелдіктерінің көпшілігімен келтірілген салыстырмалы тәуелдіктерінің шектеулерінің себебін тексереміз. Біз бір RNN-ті келесімді тапсырманы және қосымша тапсырманы орындау үшін оқыдық. Бұл CCG супертегтегі не тілді моделлеу үшін. Көптеген тапсырмалар оқыту көптеген қатенің жылдамдығын, осылай-ақ комплексті сөйлемелер үшін, RNN-дердің алдында көрсетілгеннен артық синтактикалық тапсырмаларды өзгертуге мүмкіндік береді Мұндай-ақ біз қол жеткізетін келім беру деректері басқа синтактикалық тапсырмалар үшін, осы тапсырмалар үшін тек шектелген оқыту деректерін жақсартуға болады. Көп тапсырманың парадигмі де грамматикалық білімдерді тіл үлгілеріне инжектеу үшін қолданылады.', 'ka': 'შემდეგ სამუშაო სამუშაო მუშაო მუშაო დაკავშირება RNN-ის სინტაქტიკური შესაძლებლობა, რომელიც განაზღვრდება სინტაქტიური შესაძლებლობა სტრუქ RNN-ები ამ დავალების საერთო შემთხვევაში კარგი გავაკეთეთ, მაგრამ კომპლექსი სიტყვებში (Linzen et al., 2016). ჩვენ შევცვალობთ თუ ეს შეცდომები არქტიქტურის განსაკუთრებული ზომილებებისთვის, ან კოპუსში მრავალურად მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ განსაკუთრებული დასა ჩვენ ერთი RNN-ს შესწავლოთ, რომ დავაკეთოთ შესაძლებლობის რაოდენობა და დამატებული რაოდენობა, ან CCG supertagging ან ენის მოდელირება. მრავალ დავალების განსწავლება იქნება მნიშვნელოვანი შეცდომის სინტექტიკური გამოსახულება, განსაკუთრებით კომპლექსიკური სიტყვების განსწავლების შესაძლებლობა, რომლებიც წინ ჩვენებ ჩვენ ასევე გამოჩვენებთ, რომ ადვილურად ხელმისაწარმოდგენებული მონაცემები შეუძლიათ სხვა სინტაქტიკური დავალების გამოსახულება, განსაკუთრებით, როცა მხოლოდ დასახულებული მრავალ დავალების პარადიგმა შეიძლება ასევე იყენება, რომ გრამიკალური ცნობილებები ენის მოდელში ინექტირება.', 'hu': 'A közelmúltbeli munkák az RNN-ek szintaktikai képességeit vizsgálták a tárgy-ige megállapodás feladat segítségével, amely diagnosztizálja a mondatszerkezetre való érzékenységet. Az RNN-ek gyakori esetekben jól teljesítették ezt a feladatot, de bonyolult mondatokban zavartak (Linzen et al., 2016). Teszteljük, hogy ezek a hibák az architektúra eredendő korlátaiból vagy a korpusz legtöbb megállapodásfüggősége által biztosított viszonylag közvetett felügyeletből erednek-e. Egyetlen RNN-t képeztünk ki a megállapodási feladat elvégzésére és egy további feladat elvégzésére, akár CCG szupercímkézésre, akár nyelvi modellezésre. A többfeladatos képzés jelentősen alacsonyabb hibaarányt eredményezett, különösen a komplex mondatok esetében, ami arra utal, hogy az RNN-ek képesek kifinomultabb szintaktikus reprezentációkat fejleszteni, mint korábban bemutatták. Azt is megmutatjuk, hogy a könnyen elérhető megállapodási képzési adatok javíthatják más szintaktikus feladatok teljesítményét, különösen akkor, ha ezekhez a feladatokhoz csak korlátozott mennyiségű képzési adat áll rendelkezésre. A többfeladatos paradigma a nyelvtani ismeretek nyelvi modellekbe történő bejuttatására is kihasználható.', 'it': "Recenti lavori hanno esplorato le capacità sintattiche degli RNN utilizzando il compito di accordo soggetto-verbo, che diagnostica la sensibilità alla struttura della frase. Gli RNN hanno svolto bene questo compito nei casi comuni, ma hanno vacillato in frasi complesse (Linzen et al., 2016). Verifichiamo se questi errori sono dovuti a limitazioni intrinseche dell'architettura o alla supervisione relativamente indiretta fornita dalla maggior parte delle dipendenze degli accordi in un corpus. Abbiamo addestrato un singolo RNN per eseguire sia il compito di accordo che un compito aggiuntivo, sia il supertagging CCG o la modellazione del linguaggio. La formazione multi-task ha portato a tassi di errore significativamente più bassi, in particolare su frasi complesse, suggerendo che gli RNN hanno la capacità di sviluppare rappresentazioni sintattiche più sofisticate di quanto mostrato in precedenza. Mostriamo inoltre che i dati di formazione concordati facilmente disponibili possono migliorare le prestazioni su altre attività sintattiche, in particolare quando per tali attività è disponibile solo una quantità limitata di dati di formazione. Il paradigma multi-task può anche essere sfruttato per iniettare conoscenze grammaticali nei modelli linguistici.", 'lt': 'Recent work has explored the syntactic abilities of RNNs using the subject-verb agreement task, which diagnoses sensitivity to sentence structure.  Įprastais atvejais RNN atliko šią užduotį gerai, tačiau susilpnėjo sudėtingais sakiniais (Linzen et al., 2016). Bandome, ar šios klaidos yra susijusios su būdingais architektūros apribojimais arba santykinai netiesiogine priežiūra, kurią teikia dauguma susitarimų priklausomybės korpuse. Mes apmokėme vieną RNN, kad atliktume tiek susitarimo užduotį, tiek papildomą užduotį – CCG superženklinimą arba kalbų modeliavimą. Daugiaužduočių mokymas lėmė gerokai mažesnį klaidų lygį, ypač sudėtinguose sakiniuose, ir tai rodo, kad RNN gali plėtoti sudėtingesnius sintaksinius rodmenis nei anksčiau. Taip pat rodome, kad lengvai prieinami susitarimo mokymo duomenys gali pagerinti kitų sintaktinių užduočių rezultatus, ypač kai tik ribotas mokymo duomenų kiekis yra prieinamas šioms užduotims. Daugiaužduočių paradigm ą taip pat galima panaudoti, kad gramatinės žinios būtų įdiegtos į kalbų modelius.', 'mk': 'Неодамнешната работа ги истражува синтактичките способности на РНН користејќи ја задачата на субјект-гласник договор, која дијагнозира чувствителност кон структурата на речениците. РННС ја извршија оваа задача добро во обични случаи, но недостасуваа комплексни реченици (Linzen и ал., 2016). Ние тестираме дали овие грешки се резултат на природните ограничувања на архитектурата или релативно индиректниот надзор обезбеден од повеќето зависности од договорот во корпус. We trained a single RNN to perform both the agreement task and an additional task, either CCG supertagging or language modeling.  Повеќезадачна обука доведе до значително пониски стапки на грешки, особено за комплексни реченици, што сугерира дека РНН имаат способност да еволуираат пософистицирани синтактички претставувања отколку што се покажаа претходно. Исто така покажуваме дека лесно достапните податоци за обука на договорот можат да ја подобрат резултатот на другите синтактички задачи, особено кога само ограничена количина податоци за обука се достапни за овие задачи. Парадигмот со мултизадачи, исто така, може да се искористи за инјектирање граматичко знаење во јазичките модели.', 'ms': 'Kerja baru-baru ini telah mengeksplorasi kemampuan sintaktik RNN menggunakan tugas persetujuan subjek-verb, yang diagnosis sensitiviti kepada struktur kalimat. RNN melakukan tugas ini dengan baik dalam kes biasa, tetapi gagal dalam kalimat kompleks (Linzen et al., 2016). Kita uji sama ada ralat ini disebabkan terhadap arkitektur atau pengawasan relatif langsung yang disediakan oleh kebanyakan dependensi persetujuan dalam korpus. Kami melatih satu RNN tunggal untuk melakukan kedua-dua tugas perjanjian dan tugas tambahan, sama ada CCG supertag atau pemodelan bahasa. Latihan-tugas berbilang membawa kepada kadar ralat yang lebih rendah, terutama pada kalimat kompleks, menyarankan bahawa RNN mempunyai kemampuan untuk berevolusi perwakilan sintaktik yang lebih canggih daripada yang telah dipaparkan sebelumnya. Kami juga menunjukkan bahawa data latihan kesepakatan yang mudah tersedia boleh meningkatkan prestasi pada tugas sintaktik lain, terutama apabila hanya jumlah data latihan yang terbatas tersedia untuk tugas tersebut. Paradigma multi-tugas juga boleh digunakan untuk menyuntik pengetahuan grammatik ke dalam model bahasa.', 'ml': 'അടുത്ത പ്രവര്\u200dത്തിക്കുന്ന ജോലി RNNs സിനിട്ടിക്കാനുള്ള കഴിവുകള്\u200d പരിശോധിച്ചിരിക്കുന്നു. വാക്കുകളുടെ ഘടനയ്ക്ക് ശ്രദ്ധ RNNs ഈ ജോലി സാധാരണ കാര്യങ്ങളില്\u200d നന്നായി പ്രവര്\u200dത്തിച്ചു, പക്ഷെ കുഴപ്പമുള്ള വാക്കുകളില്\u200d വീഴുകയും ചെയ്തു. നമ്മള്\u200d പരീക്ഷിക്കുന്നു, ഈ തെറ്റുകള്\u200d സ്ഥാനത്തിന്റെ നിലനില്\u200dക്കുന്ന പരിധികളാണോ അല്ലെങ്കില്\u200d ഒരു കോര്\u200dപ്പുസില്\u200d ഏറ്റവും അധികം അധി കരാര്\u200d ജോലിയും കൂടുതല്\u200d ജോലിയും പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു RNN പരിശീലിപ്പിച്ചിട്ടുണ്ട്, സിസിജി സൂപ്രട്ട പല ജോലിയുടെ പരിശീലനത്തിന് പ്രധാനപ്പെട്ട പിശകുകള്\u200d കുറച്ച് കുറഞ്ഞു വരുന്നു. പ്രത്യേകിച്ച് കുഴപ്പമുള്ള വാക്കുകളില്\u200d പ്രധാനപ്പെട നമ്മളും കാണിച്ചുകൊടുക്കുന്നു വേറെ സിന്റാക്റ്റിക്ക് ജോലികളില്\u200d പ്രദര്\u200dശനത്തിന്റെ പ്രഭാവം മുന്\u200dകൂട്ടാന്\u200d സാധിക്കു ഗ്രാമാട്ടിക്കല്\u200d അറിവ് ഭാഷ മോഡലിലേക്ക് അകത്തുകൊടുക്കുന്നതിനായി പല്ലാ ജോലിയുടെ പാര്\u200dഡിഡിമിറ്റം', 'mt': 'Xogħol reċenti esplora l-abbiltajiet sinrattiċi ta’ RNNs bl-użu tal-kompitu ta’ ftehim suġġett-verb, li jiddijanjostika s-sensittività għall-istruttura tas-sentenza. RNNs wettqu dan il-kompitu tajjeb f’każijiet komuni, iżda naqsu f’sentenzi kumplessi (Linzen et al., 2016). Nittestjaw jekk dawn l-iżbalji humiex dovuti għal limitazzjonijiet inerenti tal-arkitettura jew għas-superviżjoni relattivament indiretta pprovduta mill-biċċa l-kbira tad-dipendenzi tal-ftehim f’korpus. Taħriġna RNN wieħed biex iwettaq kemm il-kompitu tal-ftehim kif ukoll kompitu addizzjonali, jew supertagging tas-CCG jew mudell tal-lingwi. Multi-task training led to significantly lower error rates, in particular on complex sentences, suggesting that RNNs have the ability to evolve more sophisticated syntactic representations than shown before.  We also show that easily available agreement training data can improve performance on other syntactic tasks, in particular when only a limited amount of training data is available for those tasks.  Il-paradigma ta’ diversi kompiti tista’ tiġi sfruttata wkoll biex l-għarfien grammatiku jiġi injettat fil-mudelli lingwistiċi.', 'no': 'Nyleg har arbeidet utforska syntaktiske funksjonar for RNN med oppgåva med temaverbverb-samtalen, som diagnoserer følsomhet til setningsstrukturen. RNN har utført denne oppgåva godt i felles tilfeller, men falt i komplekse setningar (Linzen et al., 2016). Vi testar om desse feilene er grunn av innhaldne grenser av arkitekturen eller relativt indirekte oversikt som er tilgjengeleg av dei fleste avhengigheta i eit korpus. Vi trenga ein enkel RNN for å utføra både samtaleoppgåva og ei ekstra oppgåve, anten CCG supertagging eller språk modellering. Fleiroppgåver-trening førte til å ha mykje mindre feilrate, særleg på komplekse setningar, som tyder på at RNN har kapasitet til å utvikla meir sofistikerte syntaktiske representasjonar enn viste før. Vi viser også at enkelt tilgjengelege undersøkingsdata kan forbetra utviklinga på andre syntaktiske oppgåver, spesielt når berre ei begrenset mengd undersøkingsdata er tilgjengelege for desse oppgåvene. Det fleire oppgåver kan også brukast for å injisera grammatiske kunnskap til språk-modeller.', 'pl': 'Ostatnie prace zbadały zdolności składni RNN wykorzystując zadanie porozumienia temat-czasownik, które diagnozuje wrażliwość na strukturę zdań. RNN wykonywały to zadanie dobrze w powszechnych przypadkach, ale zawahały w złożonych zdaniach (Linz et al., 2016). Testujemy, czy błędy te są spowodowane nieodłącznymi ograniczeniami architektury czy stosunkowo pośrednim nadzorem zapewnianym przez większość zależności porozumienia w korpusie. Szkoliliśmy pojedynczego RNN do wykonywania zarówno zadania umowy, jak i dodatkowego zadania, czyli supertagowania CCG lub modelowania językowego. Szkolenie wielozadaniowe doprowadziło do znacznie niższego wskaźnika błędów, w szczególności w przypadku złożonych zdań, co sugeruje, że RNN mają zdolność do ewolucji bardziej zaawansowanych reprezentacji składni niż pokazano wcześniej. Pokazujemy również, że łatwo dostępne dane szkoleniowe umowy mogą poprawić wydajność innych zadań składni, w szczególności gdy tylko ograniczona ilość danych szkoleniowych jest dostępna dla tych zadań. Paradygmat wielozadaniowy może być również wykorzystany do wprowadzania wiedzy gramatycznej do modeli językowych.', 'mn': 'Саяхан ажил нь дарааллын бүтцийг мэдрэмжүүлэх чадварыг ашиглан РНХ-ын синтактик чадварыг судалсан. РНХ үүнийг ерөнхий тохиолдолд сайн хийсэн, гэхдээ комплекс өгүүлбэр (Linzen et al., 2016). Бид эдгээр алдаа барилгуудын хамааралтай хязгаарлалтыг эсвэл корпусын ихэнх зөвлөгөөний хамааралтай байдлын харьцангуй буруу хязгаарлалтын шалтгааныг шалгана. Бид нэг RNN-г зөвшөөрөлтийн даалгавар болон нэмэлт даалгавар хийх боломжтой болгосон. CCG супер-тег эсвэл хэл загвар хийх боломжтой. Олон дасгал дасгал хөдөлгөөн нь алдааны хувьд маш бага болсон, ялангуяа комплекс өгүүлбэрүүдийн тухай, РНХ өмнө нь харагдахаас илүү нарийн синтактик үзүүлбэрүүдийг хөгжүүлэх чадвартай гэсэн үг. Мөн бид мөн хялбар боломжтой боловсруулах боломжтой багш өгөгдлийн мэдээллийг бусад синтактикийн даалгаврууд дээр ажиллагааг сайжруулж чадна гэдгийг харуулж байна. Ялангуяа эдгээр даалгаврууд Мөн олон ажлын парадигм нь хэлний загвар руу грамматикийн мэдлэг инжекцийг ашиглах боломжтой.', 'ro': 'Lucrările recente au explorat abilitățile sintactice ale RNN-urilor folosind sarcina de acord subiect-verb, care diagnosticează sensibilitatea la structura propozițiilor. RNN-urile au îndeplinit această sarcină bine în cazurile comune, dar au ezitat în propoziții complexe (Linzen et al., 2016). Testăm dacă aceste erori se datorează limitărilor inerente ale arhitecturii sau supravegherii relativ indirecte oferite de majoritatea dependențelor de acord dintr-un corpus. Am instruit un singur RNN pentru a efectua atât sarcina acordului, cât și o sarcină suplimentară, fie supertagging CCG sau modelare lingvistică. Instruirea multi-task a dus la rate de eroare semnificativ mai scăzute, în special în cazul propozițiilor complexe, sugerând că RNN-urile au capacitatea de a evolua reprezentări sintactice mai sofisticate decât cele arătate anterior. De asemenea, demonstrăm că datele privind instruirea acordurilor ușor disponibile pot îmbunătăți performanța altor sarcini sintactice, în special atunci când sunt disponibile doar o cantitate limitată de date privind instruirea pentru aceste sarcini. paradigma multi-sarcină poate fi, de asemenea, utilizată pentru a injecta cunoștințe gramaticale în modelele lingvistice.', 'sr': 'Nedavno je rad istraživao sintaktične sposobnosti RNN-a koristeći zadatak sporazuma o temi, koji dijagnostikuje osjetljivost na strukturu kazne. RNN je dobro obavljao ovaj zadatak u zajedničkim slučajevima, ali je falsirao u kompleksnim rečenicama (Linzen et al., 2016). Testiramo da li su te greške zbog inherentnih ograničenja arhitekture ili relativno indirektnog nadzora pruženog većinom zavisnosti sporazuma u korpusu. Uèinili smo jednog RNN kako bi izvršili zadatak sporazuma i dodatni zadatak, ili nadoznavanje CCG-a ili modeliranje jezika. Većina zadataka dovela je do značajno manje stope greške, posebno na kompleksnim rečenicama, sugerirajući da RNN ima sposobnost da razvije sofisticiranije sintaktičke predstave nego što je pokazalo ranije. Takođe pokazujemo da lako dostupni podaci o obuci sporazuma mogu poboljšati provedbu na drugim sintaktičkim zadacima, posebno kada je dostupna samo ograničena količin a podataka o obuci za te zadatke. Mnogo zadataka paradigma se takođe može uticati na injekciju gramatičkih znanja u jezičke modele.', 'sv': 'Nyligen undersökte RNN:s syntaktiska förmågor med hjälp av subject-verb agreement-uppgiften, som diagnostiserar känslighet för meningsstruktur. RNN utförde denna uppgift bra i vanliga fall, men vacklade i komplexa meningar (Linzen et al., 2016). Vi testar om dessa fel beror på inneboende begränsningar i arkitekturen eller på den relativt indirekta tillsynen som tillhandahålls av de flesta avtalsberoenden i en korpus. Vi utbildade en enda RNN för att utföra både avtalsuppgiften och en extra uppgift, antingen CCG supertagg eller språkmodellering. Multi-task utbildning ledde till betydligt lägre felfrekvens, särskilt på komplexa meningar, vilket tyder på att RNN har förmågan att utveckla mer sofistikerade syntaktiska representationer än tidigare. Vi visar också att lättillgängliga avtalsutbildningsdata kan förbättra prestationen på andra syntaktiska uppgifter, särskilt när endast en begränsad mängd träningsdata finns tillgängliga för dessa uppgifter. Multiuppgifts paradigm kan också utnyttjas för att injicera grammatisk kunskap i språkmodeller.', 'so': 'Shaqoda la soo dhowaaday waxaa baaraandegay awoodaha RNNs oo lagu isticmaalayo shuqulka heshiiska qoraalka ah, kaas oo ku diagno dhaqaalaha si uu u helo dhismaha ciqaabka. RNNs waxay si wanaagsan u sameeyeen shuqulkaas xaaladaha caadiga ah, laakiin waxay ku dhaceen hadallo adag (Linzen et al., 2016). Waxaan imtixaamaynaa in qaladyadanu ay sabab u leedahay xaduudaha dhismaha ama ilaalinta si toos ah ee heshiiska badanu ay ku xiran tahay sharciga. Waxaannu tababarinnay hal RNN si a an u sameyno shuqulka heshiiska iyo shaqo dheeraad ah, ama CCG supertagging ama tusaale ahaan luuqada. Waxbarashada shaqo badan waxaa sababtay in aad u hoosaystiro tirada qaladka, khusuusan ku saabsan hadallada adag, waxayna ka jeedinayaan in RNNs ay awood u leeyihiin inay horumariyaan wakiilada safistika ah oo ka horeeyay. Sidoo kale waxan sidoo kale tusnaynaa in macluumaadka waxbarashada heshiiska si fudud loo heli karo uu horumarin karo sameynta shaqaalaha kale, khusuusan marka lagu helo macluumaad waxbarasho oo gaar ah. Xittaa waxaa lagu soo bandhigi karaa qeybta shaqada badan si uu aqoonta grammatika ugu soo saxeeyo tusaale ahaan luuqada.', 'si': 'අලුත් වැඩේ විදියට RNN ගේ සම්බන්ධ ක්\u200dරියාත්මක ක්\u200dරියාත්මක විදියට පරීක්ෂා කරලා තියෙනවා, ඒකෙන් වාක්ෂාව සං RNN නිසා මේ වැඩේ සාමාන්\u200dය විදියට හොඳ වැඩ කරලා තියෙනවා, නමුත් සංශ්\u200dය වචන වචන වලින් (Linzen et al., 2016). අපි පරීක්ෂා කරනවා මේ වැරදිලි සිද්ධතාවේ සිද්ධතාවක් නිර්මාණයක් නැත්නම් නැත්නම්, නැත්නම් සාමාන්\u200dය නිර්මාණය නිර් අපි එකම RNN එකක් ප්\u200dරශ්නයක් කරලා තියෙන්නේ සම්පූර්ණ වැඩ සහ තවත් වැඩ කරන්න, CCG සුපිට්ටැග් කරනවා නැත්නම් භ ගොඩක් වැඩක් ප්\u200dරශ්නයක් විශේෂයෙන් විශේෂයෙන් ප්\u200dරශ්නයක් විශේෂයෙන් විශේෂයෙන් අඩු වැඩක් තියෙනවා, විශේෂයෙන් සංක අපිට පෙන්වන්න පුළුවන් පුළුවන් සම්පූර්ණයෙන් ප්\u200dරධාන දත්ත ප්\u200dරධානය කරන්න පුළුවන් වෙන විදිහට අනිත් සංකේත ව ගොඩක් වැඩක් වැඩක් පාර්ඩිග්ම් වගේම භාෂා මොඩල් වලට ග්\u200dරමාත්මක දැනගන්න පුළුවන්.', 'ta': 'Recent work has explored the syntactic abilities of RNNs using the subject-verb agreement task, which diagnoses sensitivity to sentence structure.  RNNs இந்த பணியை பொதுவான விஷயங்களில் நன்றாக செய்து, ஆனால் சிக்கலான வாக்கியங்களில் விழுந்தது (லின்சென் et al., 2016). நாம் சோதிக்கிறோம் இந்த பிழைகள் கட்டுக்கூடிய வரம்புகளின் உள்ளமைந்து இருக்கிறதா அல்லது பெரும்பாலான ஒப்பந்தம் வழங்கப்பட்டுள்ளது  நாங்கள் ஒப்பந்தம் பணி மற்றும் ஒரு கூடுதல் செயலை செய்ய ஒரு RNN பயிற்சி செய்தோம், அல்லது CCG மேற்குறி அல்லது மொழி மாத பல பணி பயிற்சி முன்னால் காட்டப்பட்டதை விட சிக்கல் வாக்கியங்களை குறைவாக குறைந்து விட்டது, குறிப்பாக சிக்கல் வாக்கியங்களில், RNNs முன்ன நாம் காண்பிக்கிறோம் எளிதாக கிடைக்கும் ஒப்பந்தம் பயிற்சி தகவல் மற்ற செயல்களில் செயல்பாட்டை மேம்படுத்த முடியும் என்பதை  பல பணி அளபுருவும் மொழி மாதிரிகளுக்கு வரைபடமான அறிவை உள்ளிட முடியும்.', 'ur': 'اگلے کام نے RNN کے سینٹکتیک قابلیت کو تحقیق کر دیا ہے، جس کے مطابق تحقیق کے مطابق تحقیق کرتا ہے. RNN نے اس کام کو اچھی طرح کام کیا تھا، لیکن پیچیدہ جماعت میں (Linzen et al., 2016). ہم آزماتے ہیں کہ ان خطاؤں کے باعث معماری کی محدودیت یا نسبتا غلطی نظر کی وجہ سے ہیں جو اکثر معاہدہ اعتباری کے ذریعہ ایک کورپوس میں دی گئی ہے. ہم نے ایک RNN کی تعلیم دی ہے کہ موافقت کا کام اور اضافہ کا کام کرے، یا CCG سوپرٹاگ یا زبان موڈلینگ. بہت سی دنیا کی تعلیم نے بہت سی خطائیں رات کو کم کر دیا، مخصوصاً پیچیدہ جماعت پر، یہ بات کرتا ہے کہ RNN کو پہلے دکھائی ہوئی زیادہ پیچیدہ سینٹکتیک نمایش کا اختیار رکھتا ہے۔ ہم بھی دکھاتے ہیں کہ آسان طور پر موافقت ترینس ڈیٹے دوسرے سینٹاکٹیک ٹاکس پر عملکرد بہتر کر سکتے ہیں، مخصوصا جب ان کاموں کے لئے صرف ایک مقدار ترینس ڈیٹے موجود ہوتے ہیں۔ بہت سی دنیا کی پارادیگ بھی زبان مدلکوں میں گراماتیکی علم کے ذریعے استعمال کر سکتی ہے.', 'uz': "Yaqinda ishni taʼminlovchi soʻzni qoʻllash uchun RNNs' tizimlarini boshlaydi. Bu soʻzning tuzuvlari uchun sensitivitligni aniqlaydi. @ info We test whether these errors are due to inherent limitations of the architecture or to the relatively indirect supervision provided by most agreement dependencies in a corpus.  Biz bir necha RNN'ni o'rganishni o'rganish va bir qanday vazifani bajarish, yoki CCG supertaging yoki tilning modeli. Koʻproq vazifa taʼminlovchisi oldin koʻrsatilganligidan ko'proq kompleks so'zlarda xatolik foydalanishga ega bo'ldi. Bu holatda, RNNs qo'shilgan sofistik tashkilotlarini rivojlantirish imkoniyatini o'zgartiradi. Шунингдек, биз ҳам кўрсатамиз, oddiy қонун тайёргарлик маълумотлар бошқа масъалаларда ўзгартириш масъалаларини bajarishi мумкин, махфий вақтда фақат бу вазифалар учун камбағал тайёр маълумотлар мавжуд бўлса ҳам. Bir necha vazifa paradigligi tillar modellariga grammatika ilmogani kiritish uchun qo'shiladi.", 'vi': 'Công việc gần đây đã khám phá các khả năng cấu trúc cấu trúc cấu trúc cấu trúc của RNN sử dụng công việc hợp đồng chủ đề, nó sẽ chẩn đoán độ nhạy cảm với cấu trúc án. RNN đã thực hiện nhiệm vụ này rất tốt trong các trường hợp phổ biến, nhưng không đúng với những câu phức tạp (Linzen et al., thậm chí thẩm giá). Chúng tôi kiểm tra những lỗi này là do những hạn chế nội bộ của kiến trúc hay do sự giám sát tương đối gián tiếp do hầu hết các mối quan hệ đồng thuận thuộc về tập thể. Chúng tôi đã đào tạo một RNN đơn để thực hiện cả nhiệm vụ hợp đồng và một nhiệm vụ bổ sung, hoặc là theo dõi CCG hoặc tạo mẫu ngôn ngữ. Việc đào tạo đa nhiệm vụ đã dẫn đến tỉ lệ lỗi còn thấp hơn nhiều, đặc biệt về các câu phức tạp, cho thấy RNN có khả năng phát triển các biểu hiện cú pháp phức tạp hơn những diễn xuất trước đây. Chúng tôi cũng cho thấy những dữ liệu dễ dàng có sẵn để đào tạo hợp đồng có thể cải thiện hiệu quả trong các nhiệm vụ cú pháp khác, đặc biệt khi chỉ có một lượng ít dữ liệu về huấn luyện cho những nhiệm vụ đó. Mô hình đa tác động cũng có thể tác động thêm vào các mô hình ngôn ngữ.', 'bg': 'Последна работа изследва синтактичните способности на РНН, използвайки задачата за съгласуване субект-глагол, която диагностицира чувствителността към структурата на изречението. РНН изпълняват тази задача добре в чести случаи, но се колебаят в сложни изречения (Линцен и др., 2016). Проверяваме дали тези грешки се дължат на присъщи ограничения на архитектурата или на относително косвения надзор, осигурен от повечето зависимости на споразумението в корпуса. Обучихме един единствен РНН за изпълнение както на задачата по споразумението, така и на допълнителна задача, или супертагинг или езиково моделиране. Многозадачичното обучение води до значително по-ниски проценти на грешки, особено при сложни изречения, което предполага, че RNN имат способността да развиват по-сложни синтактични изображения, отколкото е показано преди. Също така показваме, че лесно достъпни данни за обучение по споразумения могат да подобрят изпълнението на други синтактични задачи, особено когато за тези задачи има само ограничено количество данни за обучение. Параграмата за многозадачи може да бъде използвана и за инжектиране на граматически знания в езиковите модели.', 'hr': 'Nedavno je rad istražio sintaktične sposobnosti RNN-a koristeći zadatak sporazuma o temi, koji dijagnosticira osjetljivost na strukturu kazne. RNN-ovi su dobro izvršili ovaj zadatak u zajedničkim slučajevima, ali falsificirani u složenim rečenicama (Linzen et al., 2016). Testiramo da li su te greške zbog inherentnih ograničenja arhitekture ili relativno indirektnog nadzora pruženog većinom zavisnosti sporazuma u korpusu. Uvježbali smo jednog RNN kako bi obavili zadatak sporazuma i dodatni zadatak, ili nadoziranje CCG-a ili jezičke modele. Većina zadataka obuka dovela je do značajno niže stope greške, posebno na kompleksnim rečenicama, ukazujući na to da RNN ima sposobnost razvijati sofisticiranije sintaktičke predstave nego što je pokazala ranije. Također pokazujemo da podaci o obuci sporazuma lako dostupni mogu poboljšati učinkovitost na drugim sintaktičkim zadatkima, posebno kada je dostupna samo ograničena količin a podataka o obuci za te zadatke. Većina zadataka se također može utjecati na ubrizgavanje gramatičkih znanja u jezičke modele.', 'nl': "Recent werk heeft de syntactische vaardigheden van RNN's onderzocht met behulp van de subject-werkwoord overeenkomst taak, die gevoeligheid voor zinsstructuur diagnosticeert. RNN's voerden deze taak goed uit in veel voorkomende gevallen, maar wankelden in complexe zinnen (Linz et al., 2016). We testen of deze fouten te wijten zijn aan inherente beperkingen van de architectuur of aan het relatief indirecte toezicht van de meeste overeenkomsten afhankelijkheden in een corpus. We hebben één RNN getraind om zowel de overeenkomst taak als een aanvullende taak uit te voeren, ofwel CCG supertagging of taalmodellering. Multi-task training leidde tot significant lagere foutpercentages, met name op complexe zinnen, wat suggereert dat RNN's de mogelijkheid hebben om meer geavanceerde syntactische representaties te ontwikkelen dan eerder werd getoond. We laten ook zien dat gemakkelijk beschikbare contracttrainingsgegevens de prestaties van andere syntactische taken kunnen verbeteren, met name wanneer slechts een beperkte hoeveelheid trainingsgegevens beschikbaar is voor die taken. Het multi-task paradigma kan ook worden gebruikt om grammaticale kennis in taalmodellen te injecteren.", 'da': "Nyligt arbejde har undersøgt RNN'ers syntaktiske evner ved hjælp af emne-verb aftale opgaven, som diagnosticerer følsomhed over for sætningsstruktur. RNN'er udførte denne opgave godt i almindelige tilfælde, men svigtede i komplekse sætninger (Linzen et al., 2016). Vi tester, om disse fejl skyldes iboende begrænsninger i arkitekturen eller den relativt indirekte overvågning, der leveres af de fleste aftaleafhængigheder i et korpus. Vi trænede en enkelt RNN til at udføre både aftaleopgaven og en ekstra opgave, enten CCG supertagging eller sprogmodellering. Multi-task træning førte til betydeligt lavere fejlfrekvenser, især på komplekse sætninger, hvilket tyder på, at RNN'er har evnen til at udvikle mere sofistikerede syntaktiske repræsentationer end vist før. Vi viser også, at let tilgængelige aftaletræningsdata kan forbedre ydeevnen på andre syntaktiske opgaver, især når der kun er en begrænset mængde træningsdata til disse opgaver. Multitask paradigmet kan også udnyttes til at indsprøjte grammatisk viden i sprogmodeller.", 'id': 'Recent work has explored the syntactic abilities of RNNs using the subject-verb agreement task, which diagnoses sensitivity to sentence structure.  RNN melakukan tugas ini dengan baik dalam kasus umum, tetapi gagal dalam kalimat kompleks (Linzen et al., 2016). Kami menguji apakah kesalahan-kesalahan ini disebabkan batasan inherent dari arsitektur atau pengawasan relatif indirekt yang disediakan oleh kebanyakan dependensi kesepakatan dalam korpus. Kami melatih satu RNN untuk melakukan kedua tugas kesepakatan dan tugas tambahan, baik CCG supertagging atau model bahasa. Pelatihan multi-tugas menyebabkan tingkat kesalahan yang jauh lebih rendah, terutama pada kalimat kompleks, menyarankan bahwa RNN memiliki kemampuan untuk berevolusi represisi sintaksi yang lebih canggih dari yang terlihat sebelumnya. Kami juga menunjukkan bahwa data pelatihan kesepakatan yang mudah tersedia dapat meningkatkan prestasi pada tugas sintaksi lainnya, terutama ketika hanya jumlah data pelatihan yang terbatas tersedia untuk tugas tersebut. Paradigma multi-tugas juga dapat digunakan untuk menyuntik pengetahuan grammatik ke dalam model bahasa.', 'ko': '최근 연구에서는 주술어 일치 임무를 이용해 RNN의 문법 능력을 탐색했는데, 이 임무는 문장 구조에 대한 민감성을 진단했다.RNN은 흔한 상황에서는 양호했지만, 복잡한 문장에서는 좋지 않았다(린젠 등, 2016년).우리는 이러한 오류가 체계 구조의 고유한 제한 때문인지, 아니면 자료 라이브러리에서 대부분의 프로토콜 의존항이 제공하는 상대적인 간접적인 감독 때문인지 테스트했다.우리는 프로토콜 작업과 추가 작업, CCG 슈퍼 태그나 언어 모델링을 수행하기 위해 RNN을 훈련시켰다.다중 임무 훈련으로 인해 오류율이 현저히 낮아졌다. 특히 복잡한 문장에서 RNN은 이전보다 더 복잡한 문법 표징을 진화시킬 능력이 있음을 보여준다.쉽게 얻을 수 있는 프로토콜 트레이닝 데이터는 다른 문법 임무의 성능을 향상시킬 수 있으며, 특히 이러한 임무가 유한한 트레이닝 데이터만 사용할 수 있을 때 더욱 그렇다.다중 임무 모델도 문법 지식을 언어 모델에 주입하는 데 쓸 수 있다.', 'de': 'Jüngste Arbeiten haben die syntaktischen Fähigkeiten von RNNs unter Verwendung der Subjekt-Verb Agreement Task untersucht, die Sensibilität für Satzstruktur diagnostiziert. RNNs erfüllten diese Aufgabe in gängigen Fällen gut, blieben aber in komplexen Sätzen zurück (Linz et al., 2016). Wir testen, ob diese Fehler auf inhärente Einschränkungen der Architektur oder auf die relativ indirekte Überwachung der meisten Übereinstimmungsabhängigkeiten in einem Korpus zurückzuführen sind. Wir trainierten einen einzelnen RNN, um sowohl die Vereinbarung als auch eine zusätzliche Aufgabe auszuführen, entweder CCG Supertagging oder Sprachmodellierung. Multi-Task Training führte zu deutlich geringeren Fehlerraten, insbesondere bei komplexen Sätzen, was darauf hindeutet, dass RNNs in der Lage sind, komplexere syntaktische Darstellungen zu entwickeln als bisher gezeigt. Wir zeigen auch, dass leicht verfügbare Vertragstrainingsdaten die Leistung anderer syntaktischer Aufgaben verbessern können, insbesondere wenn nur eine begrenzte Menge an Trainingsdaten für diese Aufgaben verfügbar ist. Das Multi-Task-Paradigma kann auch genutzt werden, um grammatikalisches Wissen in Sprachmodelle zu injizieren.', 'sw': 'Kazi ya hivi karibuni imegundua uwezo wa ushirikiano wa RNN kwa kutumia kazi ya makubaliano yenye ujumbe wa maneno, ambayo inagundua uelewa wa hali ya kuhukumiwa kifungo. Wakuu wa RNN walifanya kazi hii vizuri katika matukio ya kawaida, lakini walianguka kwenye hukumu ngumu (Linzen et al., 2016). Tunajaribu ikiwa makosa haya yanatokana na vizuizi vya ujenzi au kwa ufuatiliaji wa moja kwa moja na makubaliano mengi yanategemea kwenye makampuni. Tulimfundisha RNN moja kwa ajili ya kufanya kazi ya makubaliano na kazi ya ziada, ama kupiga picha za CCG au mifano ya lugha. mafunzo ya kazi mbalimbali yalisababisha kiwango cha kupunguza makosa, hususani kwa sentensi tatu, ikipendekeza kuwa Wa-RNN wana uwezo wa kuendeleza uwakilishi wa kisiasa zaidi kuliko ilivyoonyesha kabla. Tunaonyesha pia kuwa takwimu za mafunzo ya makubaliano zinazopatikana kwa urahisi zinaweza kuboresha ufanisi wa kazi nyingine za ushirikiano, hususani wakati tu kiasi kikubwa cha taarifa za mafunzo yanapatikana kwa ajili ya kazi hizo. Mpambano wa kazi mbalimbali pia unaweza kutumika ili kuingiza maarifa ya takwimu katika mifano ya lugha.', 'fa': 'کارهای اخیراً توانایی\u200cهای سنتاکتیک RNN را با استفاده از وظیفه توافق کلمه\u200cهای موضوع تحقیق کرده است که احساساتی به ساختار مجازات تشخیص می\u200cدهد. RNN این کار را در موارد مشترک خوب انجام داد، ولی در جمله\u200cهای پیچیده (Linzen et al., 2016) افتاد. ما امتحان می\u200cکنیم که آیا این اشتباه\u200cها به دلیل محدودیت\u200cهای محدودیت معماری یا بررسی نسبتا غیرمستقیم که توسط بیشتر بستگی\u200cهای توافق توافق در یک کورپوس است. ما یک RNN را آموزش دادیم تا وظیفه موافقت و وظیفه اضافه را انجام دهیم، یا supertagging CCG یا modeling زبان. آموزش تعداد زیادی از کار به نرخ خطای بسیار کمتر شد، مخصوصاً بر جمله\u200cهای پیچیده، که پیشنهاد می\u200cدهد که RNN\u200cها توانایی برای توسعه نمایش\u200cهای سنتاکتیک بیشتر از قبل تکامل دهند. ما همچنین نشان می دهیم که اطلاعات آموزش آموزش موافقت به آسانی در دسترس موافقت می\u200cتوانند عملکرد بر روی دیگر وظیفه\u200cهای سنتاکتیک را بهتر کنند، مخصوصا وقتی فقط یک مقدار محدود داده آموزش برای این وظیفه پارادیگ چندین کار می\u200cتواند برای تزریق دانش گراماتیک به مدل زبان استفاده کند.', 'tr': "Ýakyndaky işlem RNN'iň sintaktik ukyplaryny sözleşme täblisasyny ulanyp çykdy. RNN bu zady orta ýagdaýda gowy ýetirdi, ýöne karmaşık sözler(Linzen et al., 2016). Biz bu hatalaryň arhitektura ýagdaýynyň esasy çykyşlarynyň sebäbi ýa-da köpüde ylalaşyk baglyklarynyň köpüsi tarapyndan berilen netijesi üçin ýöredip barýarys. Biz bir RNN-iň hem ylalaşyk täblisasyny hem bir zady etmäge, ya da CCG süper taglamagyny, ya da dil modellerini etmäge öwrendik. Birnäçe işgär eğitimi ýüze hata ýigrendigini, özellikle karmaşık sözleriň üstünde, RNN'iň öňki görkezilişinden has sofistikli sintaktik suratlaryny geliştirmegine mümkin edip bilýär. Mundan hem biz bar ylalaşyk barlag maglumatlarynyň beýleki syntaktik görerlerde eserleşmeleri gowylaşdyryp biljekdigini görkez, ýöne-de diňe bu görerler üçin diňe çykarylyk maglumatlary bar. Birnäçe-täbli paradigm gramatika bilim nusgalaryny dil nusgalaryna dahyl edip biler.", 'af': "Onlangse werk het die sintaktieke kunstansies van RNN uitgesoek deur die onderwerp-verbooreenkomstaak te gebruik wat sensitiviteit na setstruktuur diagnoseer. RNN het hierdie taak goed in gemeenskaplike gevalle uitgevoer, maar gefal in komplekse setinge (Linzen et al., 2016). Ons probeer of hierdie foute is vanweë inherende beperkinge van die arkitektuur of die relativies indirekte supervisie wat deur die meeste ooreenkomstige afhanklikhede in 'n korpus verskaf word. Ons het 'n enkele RNN opgelei om beide die ooreenkomstaak en 'n addisionele taak te doen, of CCG supertagging of taal modeling. Veelvuldige opvoering het gevolg na betekeurig minder fout tempo, in besonderhede op komplekse setinge, voorgestel dat RNN die moontlik het om meer sofistike sintaktike voorstellings te ontwikkel as voor te vertoon. Ons wys ook dat maklik beskikbaar ooreenkomstige onderwerp data op ander sintaktike opdragte kan verbeter, in besonderhede wanneer slegs 'n beperk hoeveelheid onderwerp data beskikbaar is vir dié opdragte. Die multi-taak paradigm kan ook uitgevoer word om grammatiese kennis in taal modelles te inprop.", 'hy': 'Վերջին աշխատանքը ուսումնասիրել է ՌՆԹ-ների սինտակտիկ կարողությունները օգտագործելով բայի-թեմայի համաձայնության խնդիրը, որը ախտորոշում է նախադասության կառուցվածքի զգացումը: ՌՆՆ-ները այս խնդիրը լավ կատարեցին ընդհանուր դեպքերում, բայց բացարձակվեցին բարդ նախադասություններով (Linsen et al., 2016). Մենք ստուգում ենք, արդյոք այս սխալները կապված են ճարտարապետության բնորոշ սահմանափակումների, թե հարաբերականում անմիջական վերահսկողության, որը տրամադրվում է մարմնի համաձայն կախվածությունների մեծ մասի կողմից: Մենք պատրաստեցինք մեկ ՌՆԹ-ը, որպեսզի կատարի նաև համաձայնության առաջադրանքը, նաև ավելացված առաջադրանքը, կամ համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային Բազմախնդիրների ուսումնասիրությունը հանգեցրեց նշանակաբար ավելի ցածր սխալների մակարդակին, հատկապես բարդ նախադասությունների դեպքում, և առաջարկում է, որ ՌՆԹ-ները ունեն հնարավորություն զարգացնել ավելի բարդ սինտակտիկ ներկայացումներ, քան առաջ Մենք նաև ցույց ենք տալիս, որ հեշտությամբ հասանելի համաձայնության ուսումնասիրության տվյալները կարող են բարելավել այլ սինտակտիկ խնդիրների արդյունքը, հատկապես երբ այդ խնդիրների համար հասանելի են միայն սահմանափակ տվյալներ: Բազմախնդիրների պարադիգման կարելի է օգտագործել նաև գրամատիկ գիտելիքը լեզվի մոդելների մեջ ներդրելու համար:', 'am': 'የአሁኑ ሥራ የRNNs ጉዳዩ-verb agreement ስራትን በመጠቀም የስህተት ግንኙነትን ለፍርድ ግንኙነት የሚያሳውቅ የስህተት ግንኙነትን ይፈልጋል፡፡ RNNs ይህን አድራጊ በመጠቀም ነገር ግን በተጨማሪው ፍርድ ላይ ወደቀች (Linzen et al., 2016). እነዚህ ስህተቶች የመሠረታዊው ግንኙነት ወይም በአካባቢው ውይይት የተሰኘው የአካባቢው ግንኙነት በቁጥጥር የሚታመሙ መሆኑን እንሞክራለን፡፡ አንድ RNN የስራ ስራ እና ጨማሪ ስራ፣ CCG supertagging ወይም ቋንቋ ምሳሌ ለማድረግ አስተማርነው ነበር፡፡ ብዙ ስራ ማህበረሰብ አስቀድሞ ካሳየው ይልቅ የስህተት ቁጥጥር ያነሳል፡፡ እናም ለሌሎቹ ስራ ላይ የተለየ የስህተት ማግኘት ማድረግ ማድረግ የሚችል የስህተት ዳታዎችን እንዲሻል እናሳያቸዋለን፡፡ የብዙ ስራ ተቃውሞ የቋንቋ ምሳሌዎች ለመግለጥ ይችላል፡፡', 'sq': 'Puna e fundit ka eksploruar aftësitë sintaktike të RNN duke përdorur detyrën e marrëveshjes subjekt-verb, e cila diagnostikon ndjeshmërinë ndaj strukturës së dënimeve. RNNs e kryen këtë detyrë mirë në raste të zakonshme, por u falimentuan në fjalime komplekse (Linzen et al., 2016). Ne testojmë nëse këto gabime janë për shkak të kufizimeve të natyrshme të arkitekturës apo mbikqyrjes relativisht indirekte të ofruar nga shumica e varësive të marrëveshjes në një korpus. Kemi trajnuar një RNN të vetme për të kryer si detyrën e marrëveshjes dhe një detyrë shtesë, ose supertagging CCG ose modelim gjuhësh. Multi-task training led to significantly lower error rates, in particular on complex sentences, suggesting that RNNs have the ability to evolve more sophisticated syntactic representations than shown before.  Ne gjithashtu tregojmë se të dhënat e trajnimit të marrëveshjeve të lehta në dispozicion mund të përmirësojnë performancën në detyra të tjera sintaktike, veçanërisht kur vetëm një sasi e kufizuar e të dhënave të trajnimit janë në dispozicion për ato detyra. Paradigma shumëdetyrore mund të përdoret gjithashtu për të injektuar njohurinë gramatike në modelet gjuhësore.', 'az': "Son işdə RNN sintaktik qabiliyyətlərini sözlər qurulmasına təsdiqləyici tərzi ilə istifadə edir. RNN bu işi ortaq olaraq yaxşı işlədi, amma kompleks sözlərdə iflas edildi (Linzen et al., 2016). Biz bu xətaların arhitektura müəyyən edilməsi və ya korpusda olan çox anlaşma bağlılıqları ilə müəyyən edilməsi üçün müəyyən edirik. Biz bir RNN təhsil etdik ki, anlaşma işləri və həmçinin başqa işləri, ya CCG supertagging, ya da dil modellərini yerinə yetirmək üçün. Çoxlu işin təhsilini, özlərinə də kompleks cümlələr barəsində, RNN'lərin daha çox sofistikli sintaktik göstərişlərini göstərməyə qadir olduğunu iddia edir. Biz də göstəririk ki, asanlıqla müəyyən edilən müəyyən məlumatların başqa sintaktik işlərdə müəyyən edilməsini daha asanlıqla yaxşılaşdıra bilər, özlərinə də bu işlərdə yalnız müəyyən edilmiş təhsil məlumatlarının müəyyən edilməsi üçün müəyyə Multi-task paradigmi də dil modellerinə gramatik elmi inşa edə bilər.", 'bs': 'Nedavno je rad istraživao sintaktične sposobnosti RNN-a koristeći zadatak sporazuma o temi, koji dijagnosticira osjetljivost na strukturu kazne. RNN je dobro obavljao ovaj zadatak u zajedničkim slučajevima, ali je falsifikovana u složenim rečenicama (Linzen et al., 2016). Testiramo da li su te greške zbog nasljednih ograničenja arhitekture ili relativno indirektnog nadzora pruženog većinom zavisnosti sporazuma u korpusu. Uvježbali smo jednog RNN kako bi obavili zadatak sporazuma i dodatni zadatak, ili nadoznake CCG ili jezičke modele. Većina zadataka je dovela do značajno niže stope greške, posebno na kompleksnim rečenicama, sugerirajući da RNN ima sposobnost razvijati sofisticiranije sintaktične predstave nego što je pokazala ranije. Također pokazujemo da podaci o obuci sporazuma lako dostupni mogu poboljšati učinkovitost na drugim sintaktičkim zadacima, posebno kada je dostupna samo ograničena količin a podataka o obuci za te zadatke. Mnogo zadataka paradigma se također može uticati na injekciju gramatičkih znanja u jezičke modele.', 'ca': "Un treball recent ha explorat les habilitats sinàctiques dels RNN fent servir la tasca d'acord subjecte-verb, que diagnostica la sensibilitat a l'estructura de frases. RNNs performed this task well in common cases, but faltered in complex sentences (Linzen et al., 2016).  Probem si aquests errors són deguts a limitacions inherents de l'arquitectura o a la supervisió relativament indirecta proporcionada per la majoria de les dependencies d'acord en un corpus. Vam formar un únic RNA per a fer tant la tasca d'acord com una tasca adicional, o superetiqueta CCG o modelar llenguatges. L'entrenament multitasca va portar a nivells d'error significativament més baixos, en particular en frases complexes, que suggereixen que els RNN tenen l'habilitat d'evolucionar representacions sinàctiques més sofisticades que abans. També demostram que les dades d'entrenament d'acord fàcilment disponibles poden millorar el rendiment d'altres tasques sinàctiques, en particular quan només hi ha una quantitat limitada de dades d'entrenament disponibles per aquestes tasques. El paradigma multitasca també pot ser utilitzat per injectar el coneixement gramàtic en models lingüístics.", 'cs': 'Nedávná práce se zabývá syntaktickými schopnostmi RNN pomocí úlohy subjekt-sloveso agreement, která diagnostikuje citlivost na strukturu vět. RNN tento úkol v běžných případech prováděly dobře, ale v složitých větách zaváhaly (Linz et al., 2016). Testujeme, zda jsou tyto chyby způsobeny inherentními omezeními architektury nebo relativně nepřímým dohledem poskytovaným většinou dohodových závislostí v korpusu. Trénovali jsme jednoho RNN, aby prováděl jak úkol dohody, tak další úkol, buď CCG supertagging nebo jazykové modelování. Víceúlohový trénink vedl k výrazně nižší míře chyb, zejména u složitých vět, což naznačuje, že RNN mají schopnost vyvíjet sofistikovanější syntaktické reprezentace, než bylo ukázáno předtím. Dále ukazujeme, že snadno dostupná data smluvního tréninku mohou zlepšit výkon u jiných syntaktických úkolů, zejména když je pro tyto úkoly k dispozici pouze omezené množství tréninkových dat. Paradigma více úkolů lze také využít k vkládání gramatických znalostí do jazykových modelů.', 'et': 'Hiljutises töös on uuritud RNN-de süntaktilisi võimeid, kasutades subjekti-verbi kokkuleppe ülesannet, mis diagnoosib tundlikkust lausestruktuuri suhtes. RNN-id täitsid seda ülesannet hästi tavalistel juhtudel, kuid keerukates lausetes kõhklesid (Linzen et al., 2016). Testime, kas need vead on tingitud arhitektuuri omapärastest piirangutest või suhteliselt kaudsest järelevalvest, mida pakub enamik korpuse kokkulepesõltuvustest. Koolitasime ühe RNN-i nii kokkuleppeülesande kui ka lisaülesande täitmiseks, kas CCG supermärgistamise või keele modelleerimise. Mitme ülesandega koolitus viis märkimisväärselt madalamale veamäärale, eriti keerukate lausete puhul, mis viitab sellele, et RNN-idel on võime arendada keerukamaid süntaktilisi esitusi kui varem näidatud. Samuti näitame, et hõlpsasti kättesaadavad kokkuleppe koolitusandmed võivad parandada teiste süntaktiliste ülesannete tulemuslikkust, eriti kui nende ülesannete jaoks on kättesaadavad ainult piiratud hulk koolitusandmeid. Mitme ülesandega paradigmat saab kasutada ka grammatiliste teadmiste süstimiseks keelemudelitesse.', 'fi': 'Viimeaikainen työ on tutkinut RNN:ien syntaktisia kykyjä käyttäen subjekti-verbi-sopivuustehtävää, joka diagnosoi herkkyyttä lauserakenteelle. RNN:t suorittivat tämän tehtävän hyvin tavallisissa tapauksissa, mutta horjuivat monimutkaisissa lauseissa (Linzen et al., 2016). Testaamme, johtuvatko nämä virheet arkkitehtuurin luontaisista rajoituksista vai suhteellisen epäsuorasta valvonnasta, jota useimmat sopimusriippuvuudet tarjoavat. Koulutimme yhden RNN:n suorittamaan sekä sopimustehtävän että lisätehtävän, joko CCG-supertaggingin tai kielimallinnuksen. Monitehtäväharjoittelu johti merkittävästi alhaisempiin virhemääriin erityisesti monimutkaisissa lauseissa, mikä viittaa siihen, että RNN:illä on kyky kehittää kehittyneempiä syntaktisia esityksiä kuin aiemmin. Osoitamme myös, että helposti saatavilla oleva sopimuskoulutustieto voi parantaa suoritusta muissa syntaktisissa tehtävissä, erityisesti kun näihin tehtäviin on saatavilla vain rajallinen määrä koulutustietoja. Monitehtäväparadigmaa voidaan hyödyntää myös kieliopillisen tiedon lisäämiseksi kielimalleihin.', 'bn': 'সাম্প্রতিক কাজ বিষয়-ভার্ব চুক্তির কাজ ব্যবহার করে আরএনএন-এর সিন্ট্যাকটিক ক্ষমতা খুঁজে বের করেছে, যা শাস্তি কাঠামোর জন্য সংবে আরএনএন-এরা সাধারণ ক্ষেত্রে এই কাজটি ভালো করেছে, কিন্তু জটিল কারাদণ্ডে ধ্বংস হয়েছে (লিঞ্জেন এন্ট আল, ২০১৬)। We test whether these errors are due to inherent limitations of the architecture or to the relatively indirect supervision provided by most agreement dependencies in a corpus.  চুক্তির কাজ এবং অতিরিক্ত কাজ, সিসিজি সুপার্ট্যাগিং অথবা ভাষা মডেলিং করার জন্য আমরা একটি RNN প্রশিক্ষণ দিয়েছি। বহুক্ষেত্রের প্রশিক্ষণ গুরুত্বপূর্ণ ভুল হার কমে গেছে, বিশেষ করে জটিল বাক্যের ব্যাপারে, পরামর্শ দেয়া হচ্ছে যে এনএনএন এর পূর্বে প্রদর্শনিত থ আমরা একই সাথে দেখাচ্ছি যে সহজে প্রযুক্ত চুক্তি প্রশিক্ষণের তথ্য অন্যান্য সিন্ট্যাক্টিক কাজের ব্যাপারে প্রভাব বৃদ্ধি করতে  এই বহুক্ষেত্রের প্যারাডিম ভাষার মডেলে গ্রাম্যাটিক্যাল জ্ঞান ইঞ্জিজ করার জন্য প্রাপ্ত করা যাবে।', 'jv': 'tab-style DNN saiki nggawe task iki dadi kapan sakjane, njuk kesempatan kanggo kelangan kelangan kelangan komplikasi (Linz et al, 2011). Awak dhéwé éntuk perusahaan iki dadi nggawe nguasai perusahaan architecture apa or a ono nggawe barang nggawe barang kelas kuwi nggawe nguasai perusahaan winih dhéwé. Awak dhéwé wis telungi 1DNN kanggo ngewehke nggawe gerangkamunyatan karo task enyarno, dadi, video nggawe Multi Awak dhéwé mungkin ngerasakno iki luwih akeh operasi tambah nggawe gerakan kanggo nggawe barang seneng nggawe barang seneng pisan-pakan, njuk kesempatan kanggo awak dhéwé mungkin kuwi kudu nggawe gerakan dhéwé. Aparampun multi-task gawe ngubah ndelok kanggo ngerasakno nggawe ngerasakno bahin ingkang model.', 'ha': "Yin aikin da na ƙari ya gane abincin syntactic na RNNs da ya yi amfani da aikin wa-mazaɓa-verb, wanda yana gane sensitive zuwa tsarin cire. @ info Munã jarraba, ko waɗannan ɓatattu ne da ke cikin tsari na tsari ko kuma da tsarin mai tsaye da ke samar da kuma mafi yawansa yarda masu kamfata da ke cikin wani nauyi. Mun sanar da wata RNN guda dõmin a cika aikin alkawarin da kuma wani aikin ƙaranci, ko CCG surtagning ko kuma misalin harshen. Tayyar da mulki-aikin suka ƙara matsayin ɓata mai girma, hususan masu hususan ga saurãre masu hususan, sunã fatan cẽwa RNN's ma'abũcin ya buɗe masu sofi da shiryoyin syntactic ko da aka nuna a a gabãnin. Tuna nũna cewa data masu iya sauƙi da ma'anar agreeci, za su iya improve performance a kan taskõkin wasu masu yin syntactic, hasa'a, idan ana iya ƙayyade kodi kaɗan na ƙidãya wa masu aikin waɗannan. The multi-task paradigm can also be leveraged to inject grammatical knowledge into language models.", 'sk': 'Nedavno delo je raziskovalo sintaktične sposobnosti RNN z uporabo naloge soglasja subjekt-glagol, ki diagnosticira občutljivost na strukturo stavka. RNN-ji so to nalogo dobro opravili v običajnih primerih, vendar so v kompleksnih stavkih spodleteli (Linzen et al., 2016). Preizkusimo, ali so te napake posledica neločljivih omejitev arhitekture ali relativno posrednega nadzora, ki ga zagotavlja večina sporazumnih odvisnosti v korpusu. Eno RNN smo usposobili za izvajanje dogovorjene naloge in dodatne naloge, bodisi CCG superoznačevanje ali jezikovno modeliranje. Večopravilno usposabljanje je privedlo do bistveno nižjih stopenj napak, zlasti pri kompleksnih stavkih, kar kaže, da imajo RNN sposobnost razviti bolj prefinjene sintaktične reprezentacije, kot je prikazano prej. Pokazali smo tudi, da lahko dostopni podatki o usposabljanju o dogovoru izboljšajo uspešnost pri drugih sintaktičnih nalogah, zlasti kadar je za te naloge na voljo le omejena količina podatkov o usposabljanju. Večopravilno paradigmo je mogoče uporabiti tudi za vbrizganje slovničnega znanja v jezikovne modele.', 'he': 'העבודה האחרונה חקרה את היכולות הסינטקטיות של RNN בשימוש במשימת הסכם הנושא-אובר, אשר מאבחן רגישות למבנה משפטי. RNN ביצעו את המשימה הזאת היטב במקרים משותפים, אך נעלמו במשפטים מורכבים (Linzen et al., 2016). אנחנו בודקים אם הטעויות האלה הן בגלל הגבלות הנכונות של הארכיטקטורה או בגלל הפיקוח הלא ישיר יחסית שנוסף על ידי רוב תלויות הסכם בקורפוס. אימנו RNN אחד כדי לבצע את משימת ההסכם וגם משימה נוספת, או סי.קי.ג. אימון במשימות רבות הוביל לשיעורי טעויות נמוכים יותר באופן משמעותי, במיוחד בנוגע למשפטים מורכבים, שמציע שלארנ"א יש את היכולת לפתח מייצגים סינטקטיים מתוחכמים יותר ממה שנראה קודם. אנחנו גם מראים כי נתוני אימון הסכם זמינים בקלות יכולים לשפר ביצועים על משימות סינטקטיות אחרות, במיוחד כאשר רק כמות מוגבלת של נתוני אימון זמינים למשימות אלה. פרדיגמה במשימות רבות ניתן גם להזריק ידע גרמטי לדוגמאות שפות.', 'bo': 'ད་ལྟ་བུའི་ནང་དུ་རྣམ་གྲངས་ཀྱི་སྐྱེས་ཚུལ་དང་བཅས་ཀྱི་ཚོར་བ RNN ལྟ་བུའི་ཚིག་རྣམས་མཐུན་གྱི་སྐབས་སུ་བཏོན་པ་ཡིན་ནའང་ཚོར་ཆུང་གི་ཐ་སྙད་ནང་དུ་faltered (Linzen et al., 2016) ང་ཚོས་འཛོལ་བ་འདི་དག་གི་སྒྲིག་འཛུགས་ཡུལ་གྱི་ཚད་མེད་པ་དང་མཐུན་པ་ཅིག་གི་ནང་དུ་མཐུན་རྟེན་དང་འབྲེལ་བ་མེད་དུ་མཐུན་བཟོ་ནོ ང་ཚོས་རྒྱལ་ཁབ་གཅིག་པུ་ཞིག་གིས་མཐུན་སྒྲིག Multi-task training led to a significantly lower error rate, in particular on complex sentences, suggesting that RNNs have the ability to develop more sophisticated syntactic representations than shown before. ང་ཚོས་ཀྱང་ཕལ་ཆེན་རྐྱེན་གྱིས་ལས་སྟབས་བདེ་སྦྱོར་བའི་ཆ་འཕྲིན་ཡིག་ཆ་ནི་བྱ་སྟངས་གཞན་ལས་སྒྲུབ་གཏོང་། སྣ་མང་ཙམ་བྱུང་བའི་paradigm་དེ་ནི་སྐད་ཡིག་ཐབས་ལམ་ནང་གི་བྱ་རིམ་གྱི་ཐབས་ལམ་ནང་དུ་འགྱུར་བ་བཏུབ།'}
{'en': 'The Effect of Different Writing Tasks on Linguistic Style : A Case Study of the ROC Story Cloze Task', 'ar': 'تأثير مهام الكتابة المختلفة على الأسلوب اللغوي: دراسة حالة مهمة إخفاء قصة ROC', 'pt': 'O efeito de diferentes tarefas de escrita no estilo linguístico: um estudo de caso da tarefa ROC Story Cloze', 'es': 'El efecto de diferentes tareas de escritura en el estilo lingüístico: un estudio de caso de la tarea Cloze de la historia de ROC', 'fr': "L'effet des différentes tâches d'écriture sur le style linguistique\xa0: une étude de cas de la tâche ROC Story Cloze", 'ja': 'さまざまな書き込みタスクが言語スタイルに及ぼす影響： ROCストーリークローズタスクのケーススタディ', 'zh': '异务风流——以中华民国事为例', 'hi': 'भाषाई शैली पर विभिन्न लेखन कार्यों का प्रभाव: आरओसी स्टोरी क्लोज़ टास्क का एक केस स्टडी', 'ru': 'Влияние различных письменных заданий на лингвистический стиль: тематическое исследование задачи ROC Story Cloze', 'ga': 'Tionchar Tascanna Scríbhneoireachta Éagsúla ar Stíl Theangeolaíoch: Cás-staidéar ar Thasc Cloze Scéalaíochta ROC', 'ka': 'Name', 'hu': 'A különböző írási feladatok hatása a nyelvi stílusra: A ROC Story Cloze feladat esettanulmánya', 'el': 'Η επίδραση διαφορετικών εργασιών γραφής στο γλωσσικό στυλ: Μια μελέτη περίπτωσης της εργασίας Cloze Story', 'kk': 'Лингистикалық стилінде әртүрлі жазу тапсырмаларының эффекті: ROC журналын жабу тапсырмасы', 'it': "L'effetto di diversi compiti di scrittura sullo stile linguistico: un caso di studio del compito ROC Story Cloze", 'mk': 'Ефектот на различни задачи за пишување на јазичкиот стил: Студија на случаи на задачата за завршување на приказната на ROC', 'lt': 'Skirtingų rašymo užduočių poveikis kalbos stiliui: ROC istorijos uždarymo užduočių atvejų tyrimas', 'mt': 'L-Effett ta’ Kompiti Differenti tal-kitba fuq l-Istil Lingwistiku: Studju ta’ Każ tal-Kompitu tal-Għeluq tal-Story ROC', 'ms': 'Kesan Tugas Tulis berbeza pada Gaya Bahasa: Penelitian Kes Tugas Tutup Cerita ROC', 'mn': 'The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task', 'ml': 'ലിങ്ഗിസ്റ്റിക്ക് ശൈലിയില്\u200d വ്യത്യസ്ത എഴുതുന്ന ജോലികളുടെ പ്രഭാവം: റോസി സ്റ്റോറി ക്ലോസ് ജോലിയുടെ ഒരു കേസ് സ്', 'no': 'Effekt på ulike skriveoppgåver på linguistisk stil: Eit tilfeldig undersøking av ROC Story Close oppgåve', 'pl': 'Wpływ różnych zadań pisania na styl językowy: studium przypadku ROC Story Cloze Task', 'ro': 'Efectul diferitelor sarcini de scriere asupra stilului lingvistic: un studiu de caz al activității ROC Story Cloze', 'sr': 'Efekt različitih napisanih zadataka na lingvistički stil: Istraživanje slučaja priče o zatvaranju zadataka ROC-a', 'si': 'Name', 'so': 'Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task', 'sv': 'Effekten av olika skrivuppgifter på språklig stil: En fallstudie av ROC Story Cloze-uppgiften', 'ta': 'வேறு எழுதும் பணிகளின் விளைவு', 'ur': 'The effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task', 'uz': 'Name', 'vi': 'Hiệu ứng của các công việc viết khác nhau trên Kiểu ngôn ngữ: Một nghiên cứu của tập tin các phiên bản giống hệt ROC', 'bg': 'Ефектът на различните задачи за писане върху лингвистичния стил: казус на задачата за клоузиране на история', 'hr': 'Učinak različitih napisanih zadataka na Linguističkom stilu: Istraživanje slučaja priče o zatvaranju zadataka ROC-a', 'nl': 'Het effect van verschillende schrijftaken op taalstijl: een casestudy van de ROC Story Cloze Task', 'da': 'Virkningen af forskellige skriveopgaver på sproglig stil: Et casestudie af ROC Story Cloze-opgaven', 'de': 'Der Einfluss verschiedener Schreibaufgaben auf den Sprachstil: Eine Fallstudie der ROC Story Cloze Task', 'ko': '서로 다른 창작 임무가 언어 풍격에 미치는 영향 - ROC 이야기 완형 빈칸 채우기 임무를 예로 들면', 'fa': 'اثر کارهای نوشتن متفاوت روی استیل لینگیست: یک مطالعه پرونده داستان ROC', 'id': 'Efek Tugas Penulisan Berbeda pada Gaya Bahasa: Sebuah Penelitian Kasus Tugas Tutup Cerita ROC', 'sw': 'Madhara ya kazi tofauti ya kuandika kwenye Mtandao wa Kilinguistic: Utafiti wa Kesi wa Kazi ya Story Cloze ya ROC', 'tr': 'The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task', 'sq': 'Efekti i detyrave të ndryshme të shkrimit në stilin gjuhësor: Një studim rasti i detyrës së mbylljes së historisë ROC', 'af': 'Name', 'hy': 'Լեզվաբանական ոճի վրա գրելու տարբեր խնդիրների ազդեցությունը. ROC պատմության ավարտելու խնդիրը', 'am': 'የልዩ ጽሑፍ ስራዎችን በLinguistic Style: A Case Study of the ROC Story Cloze Task', 'bn': 'লিঙ্গিস্টিক স্টাইলে বিভিন্ন লেখা কাজের প্রভাব: রোসি গল্প ক্লোজের একটি কেস স্টিডি', 'az': 'Linguistic St칲l칲 칲z톛rind톛 f톛rqli Yaz캼 G칬r칲nt칲l톛rinin Etkisi: A Case Study of the ROC Story Cloze Task', 'ca': "L'efecte de diferents tasques d'escriptura sobre l'estil lingüístic: Un estudi de cas de la tasca d'enclosura de històries ROC", 'fi': 'Eri kirjoitustehtävien vaikutus kielelliseen tyyliin: tapaustutkimus ROC Story Cloze -tehtävästä', 'bs': 'Efekt različitih napisanih zadataka na Linguističkom stilu: Istraživanje slučaja priče o zatvaranju zadataka ROC-a', 'et': 'Erinevate kirjutamisülesannete mõju keelelisele stiilile: ROC Story Cloze ülesande juhtumiuuring', 'cs': 'Vliv různých psacích úkolů na jazykový styl: Případová studie ROC Story Cloze Task', 'he': 'The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task', 'ha': '@ action', 'jv': 'Name', 'sk': 'Učinek različnih pisalnih nalog na jezikovni slog: študija primera naloge ROC Story Cloze', 'bo': 'The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task'}
{'en': 'A writer’s style depends not just on personal traits but also on her intent and mental state. In this paper, we show how variants of the same writing task can lead to measurable differences in writing style. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints : (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story. We show that a simple linear classifier informed by stylistic features is able to successfully distinguish among the three cases, without even looking at the story context. In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge. Our results demonstrate that different task framings can dramatically affect the way people write.', 'ar': 'لا يعتمد أسلوب الكاتب على السمات الشخصية فحسب ، بل يعتمد أيضًا على نواياها وحالتها العقلية. في هذه الورقة ، نوضح كيف يمكن أن تؤدي متغيرات مهمة الكتابة نفسها إلى اختلافات قابلة للقياس في أسلوب الكتابة. نقدم دراسة حالة بناءً على مهمة إخفاء القصة (Mostafazadeh et al.، 2016a) ، حيث تم تكليف المعلقين بمهام كتابة مماثلة مع قيود مختلفة: (1) كتابة قصة كاملة ، (2) إضافة قصة نهاية لقصة معينة السياق ، و (3) إضافة نهاية غير متماسكة للقصة. نظهر أن المصنف الخطي البسيط المستنير بسمات أسلوبية قادر على التمييز بنجاح بين الحالات الثلاث ، حتى دون النظر إلى سياق القصة. بالإضافة إلى ذلك ، فإن الجمع بين ميزاتنا الأسلوبية وتنبؤات نموذج اللغة يصل إلى مستوى الأداء الفني في تحدي اختفاء القصة. توضح نتائجنا أن إطارات المهام المختلفة يمكن أن تؤثر بشكل كبير على طريقة كتابة الأشخاص.', 'pt': 'O estilo de um escritor depende não apenas de traços pessoais, mas também de sua intenção e estado mental. Neste artigo, mostramos como variantes da mesma tarefa de escrita podem levar a diferenças mensuráveis no estilo de escrita. Apresentamos um estudo de caso baseado na tarefa cloze de histórias (Mostafazadeh et al., 2016a), onde os anotadores receberam tarefas de escrita semelhantes com diferentes restrições: (1) escrever uma história inteira, (2) adicionar um final de história para uma determinada história contexto e (3) adicionar um final incoerente a uma história. Mostramos que um classificador linear simples informado por características estilísticas é capaz de distinguir com sucesso entre os três casos, mesmo sem olhar para o contexto da história. Além disso, a combinação de nossos recursos estilísticos com previsões de modelos de linguagem alcança um desempenho de última geração no desafio story cloze. Nossos resultados demonstram que diferentes enquadramentos de tarefas podem afetar drasticamente a maneira como as pessoas escrevem.', 'fr': "Le style d'une écrivaine dépend non seulement de ses traits personnels, mais aussi de son intention et de son état mental. Dans cet article, nous montrons comment les variantes d'une même tâche d'écriture peuvent entraîner des différences mesurables dans le style d'écriture. Nous présentons une étude de cas basée sur la tâche de clôture de l'histoire (Mostafazadeh et al., 2016a), où les annotateurs se sont vu attribuer des tâches d'écriture similaires avec différentes contraintes\xa0: (1) écrire une histoire entière, (2) ajouter une fin d'histoire pour un contexte d'histoire donné, et (3) ajouter une fin incohérente à une histoire. Nous montrons qu'un simple classificateur linéaire basé sur des caractéristiques stylistiques est capable de distinguer avec succès les trois cas, sans même regarder le contexte de l'histoire. De plus, la combinaison de nos caractéristiques stylistiques avec des prédictions de modèles de langage permet d'atteindre des performances de pointe sur le défi de la clôture de l'histoire. Nos résultats montrent que différents cadres de tâches peuvent avoir une incidence considérable sur la façon dont les gens écrivent.", 'es': 'El estilo de una escritora depende no solo de sus rasgos personales, sino también de su intención y estado mental. En este artículo, mostramos cómo las variantes de la misma tarea de escritura pueden llevar a diferencias medibles en el estilo de escritura. Presentamos un estudio de caso basado en la tarea de cloze de la historia (Mostafazadeh et al., 2016a), donde a los anotadores se les asignaron tareas de escritura similares con diferentes restricciones: (1) escribir una historia completa, (2) agregar un final de historia para un contexto de historia dado y (3) agregar un final incoherente a una historia. Mostramos que un simple clasificador lineal basado en características estilísticas es capaz de distinguir con éxito entre los tres casos, sin siquiera mirar el contexto de la historia. Además, la combinación de nuestras características estilísticas con las predicciones de modelos lingüísticos alcanza un rendimiento de vanguardia en el desafío de cerrar la historia. Nuestros resultados demuestran que los diferentes marcos de tareas pueden afectar drásticamente la forma en que escriben las personas.', 'ja': '作家のスタイルは、個人の特性だけでなく、意図や精神状態にも依存します。この論文では、同じ執筆タスクのバリアントが、どのようにして執筆スタイルの測定可能な違いにつながるかを示します。私たちは、ストーリークローズタスクに基づいたケーススタディを提示します（ Mostafazadeh et al., 2016 a ）。注釈者には、異なる制約を伴う同様の書き込みタスクが割り当てられています。（ 1 ）ストーリー全体を書き、（ 2 ）特定のストーリーの文脈にストーリーの結末を追加し、（ 3 ）ストーリーに一貫性のない結末を追加します。文体的特徴に基づいた単純な線形分類器は、ストーリーの文脈を見なくても、3つのケースをうまく区別することができることを示しています。さらに、私たちのスタイル機能と言語モデル予測を組み合わせると、ストーリークローズチャレンジで最先端のパフォーマンスに到達します。私たちの結果は、さまざまなタスクフレームワークが人々の書き方に劇的に影響を与える可能性があることを示しています。', 'zh': '风格不独在,意气在精神。 于本文之中,展同文之务变体何以致风格之可量异? 臣等条上故事例究(Mostafazadeh et al.,2016a),其注释者分类作:(1)编次故事,(2)为给定故事上下文添故事结尾,及(3)添不连贯故事。 吾言文体之简线性分类器能成功分此三者,至不须观故事背景。 此外,以我文体特徵与言语模样测合,于故事闭幕挑战最先进。 臣等考结果表明异务框架大妨人作。', 'hi': 'एक लेखक की शैली न केवल व्यक्तिगत लक्षणों पर निर्भर करती है, बल्कि उसके इरादे और मानसिक स्थिति पर भी निर्भर करती है। इस पेपर में, हम दिखाते हैं कि एक ही लेखन कार्य के वेरिएंट लेखन शैली में औसत दर्जे के अंतर को कैसे जन्म दे सकते हैं। हम कहानी क्लोज़ कार्य (Mostafazadeh et al., 2016a) के आधार पर एक केस स्टडी प्रस्तुत करते हैं, जहां एनोटेटरों को विभिन्न बाधाओं के साथ समान लेखन कार्य सौंपा गया था: (1) एक पूरी कहानी लिखना, (2) किसी दिए गए कहानी संदर्भ के लिए समाप्त होने वाली कहानी जोड़ना, और (3) एक कहानी के लिए एक असंगत अंत जोड़ना। हम दिखाते हैं कि शैलीगत विशेषताओं द्वारा सूचित एक साधारण रैखिक क्लासिफायर तीन मामलों के बीच सफलतापूर्वक अंतर करने में सक्षम है, यहां तक कि कहानी के संदर्भ को देखे बिना भी। इसके अलावा, भाषा मॉडल भविष्यवाणियों के साथ हमारी शैलीगत विशेषताओं का संयोजन कहानी क्लोज़ चुनौती पर कला प्रदर्शन की स्थिति तक पहुंचता है। हमारे परिणाम दर्शाते हैं कि विभिन्न कार्य फ्रेमिंग नाटकीय रूप से लोगों के लिखने के तरीके को प्रभावित कर सकते हैं।', 'ru': 'Стиль писателя зависит не только от его личных качеств, но и от его намерений и психического состояния. В этой статье мы показываем, как варианты одной и той же письменной задачи могут привести к измеримым различиям в стиле письма. Мы представляем тематическое исследование, основанное на задаче закрытия истории (Mostafazadeh et al., 2016a), где аннотаторам были назначены одинаковые письменные задания с различными ограничениями: (1) написание всей истории, (2) добавление истории, заканчивающейся для данного контекста истории, и (3) добавление непоследовательного конца к истории. Показано, что простой линейный классификатор, основанный на стилистических особенностях, способен успешно различать три случая, даже не глядя на контекст истории. Кроме того, сочетание наших стилистических особенностей с предсказаниями языковой модели достигает современной производительности на задаче закрытия истории. Наши результаты показывают, что различные фреймы задач могут резко повлиять на то, как люди пишут.', 'ga': 'Braitheann stíl scríbhneora ní hamháin ar thréithe pearsanta ach freisin ar a hintinn agus a staid mheabhrach. Sa pháipéar seo, léirímid conas is féidir éagsúlachtaí intomhaiste i stíl scríbhneoireachta a bheith mar thoradh ar éagsúlachtaí ar an tasc scríbhneoireachta céanna. Cuirimid cás-staidéar i láthair bunaithe ar an tasc cloze story (Mostafazadeh et al., 2016a), áit ar sannadh tascanna scríbhneoireachta cosúla le srianta éagsúla do na nótaíadóirí: (1) scéal iomlán a scríobh, (2) scéal iomlán a chur leis dar críoch scéal ar leith. comhthéacs, agus (3) ag cur críoch neamhchomhleanúnach le scéal. Léirímid go bhfuil aicmitheoir líneach simplí bunaithe ar ghnéithe stíle in ann idirdhealú a dhéanamh go rathúil i measc na dtrí chás, gan fiú féachaint ar chomhthéacs an scéil. Ina theannta sin, trí ár ngnéithe stíle a chomhcheangal le tuar ar mhúnlaí teanga, baintear amach an fheidhmíocht úrscothach ar dhúshlán an scéil. Léiríonn ár dtorthaí gur féidir le frámaí tascanna éagsúla cur isteach go mór ar an mbealach a scríobhann daoine.', 'el': 'Το στυλ ενός συγγραφέα εξαρτάται όχι μόνο από τα προσωπικά χαρακτηριστικά αλλά και από την πρόθεση και την ψυχική της κατάσταση. Σε αυτή την εργασία, παρουσιάζουμε πώς οι παραλλαγές της ίδιας εργασίας γραφής μπορούν να οδηγήσουν σε μετρήσιμες διαφορές στο στυλ γραφής. Παρουσιάζουμε μια μελέτη περίπτωσης βασισμένη στην εργασία κλεισίματος ιστορίας (κ.α., 2016α), όπου οι σχολιαστές είχαν ανατεθεί παρόμοιες εργασίες γραφής με διαφορετικούς περιορισμούς: (1) συγγραφή ολόκληρης ιστορίας, (2) προσθήκη ενός τέλους ιστορίας για ένα δεδομένο πλαίσιο ιστορίας, και (3) προσθήκη ενός ασυνάρτητου τέλους σε μια ιστορία. Δείχνουμε ότι ένας απλός γραμμικός ταξινομητής πληροφορημένος από στυλιστικά χαρακτηριστικά είναι σε θέση να διακρίνει επιτυχώς μεταξύ των τριών περιπτώσεων, χωρίς καν να κοιτάξει το πλαίσιο της ιστορίας. Επιπλέον, ο συνδυασμός των στυλιστικών χαρακτηριστικών μας με τις προβλέψεις γλωσσικών μοντέλων επιτυγχάνει την τελευταία απόδοση στην πρόκληση κλονισμού της ιστορίας. Τα αποτελέσματά μας δείχνουν ότι διαφορετικά πλαίσια εργασιών μπορούν να επηρεάσουν δραματικά τον τρόπο που γράφουν οι άνθρωποι.', 'hu': 'Az író stílusa nemcsak a személyes vonásoktól függ, hanem a szándékától és mentális állapotától is. Ebben a tanulmányban bemutatjuk, hogy ugyanazon írási feladat változatai hogyan vezethetnek mérhető különbségekhez az írási stílusban. Bemutatunk egy esettanulmányt a történet lezárására (Mostafazadeh et al., 2016a) alapozva, ahol a kommentátorok hasonló írási feladatokat kaptak különböző korlátozásokkal: (1) egy egész történet megírása, (2) egy történet végződésének hozzáadása egy adott történeti kontextushoz, és (3) egy összefüggő befejezés hozzáadása egy történethez. Megmutatjuk, hogy egy egyszerű lineáris osztályozó, stilisztikai tulajdonságokkal támasztott, sikeresen megkülönbözteti a három eset közül, anélkül, hogy a történet kontextusát nézné. Ezenkívül stilisztikai tulajdonságaink és nyelvi modellek előrejelzéseinek kombinálása a legkorszerűbb teljesítményt eredményezi a történet homályos kihívásán. Eredményeink azt mutatják, hogy a különböző feladatkeretek drámaian befolyásolhatják az emberek írásmódját.', 'ka': 'ქაიტორის სტილი არა მხოლოდ პირადი განსაზღვრებით, მაგრამ მისი საზოგადოება და მეგონიური განსაზღვრებით. ჩვენ ჩვენ ჩვენ აჩვენებთ, როგორ იგივე წერილების განრავლები შეგვიძლია წერილების სტილის განსხვავებას შეგვიძლია გავამზადოთ. ჩვენ გავაკეთებთ ისტორიების კოლუზაციის რაოდენობას (Mostafazadeh et al., 2016a), სადაც ანტოტოტორიები განსხვავებული წერის რაოდენობები დააყენებულია: 1) ყველა ისტორია დაწერა, 2) განსხვავებული ისტორიის კონტექსტისთვის დამატება, და 3) ისტორიის დამატება,  ჩვენ ჩვენ აჩვენებთ, რომ სტილისტიკური განსაზღვრებით სუფლიოდ სტრიქტიკური განსაზღვრება შეუძლია სამი შემთხვევაში წარმატებით განსაზღვრება, ისტორიის კონტექსტი დამატებით, ჩვენი სტილისტიკური განსაზღვრებით ენის მოდელის განსაზღვრებით მიიღება ისტორიის კოლუზის განსაზღვრებით. ჩვენი წარმოდგენები გამოჩვენებენ, რომ განსხვავებული დავალების ფრამეტრები შეიძლება დირამატიკურად გააკეთება ადამიანები წერილი.', 'kk': 'Жазушының стилі тек жеке қасиеттеріне тәуелді емес, сондай-ақ оның мақсаты мен психикалық күйіне тәуелді. Бұл қағазда біз бір жазу тапсырмасының айнымалылығын жазу стилінде өлшемілікті айнымалылығын көрсетедік. Біз оқиғаны клоз тапсырмасына негізделген оқиға зерттеуді (Mostafazadeh et al., 2016a) көрсетедік. Бұл оқиға жазу тапсырмаларын түрлі шектеулермен ұқсас жазу тапсырмаларына ұқсас етілді: (1) толық оқиға жазу, (2) көрсетілген оқиғаның контекст Біз стилистикалық мүмкіндіктері бойынша бір қарапайым сызық классификациясы оқиға контексті қарамай, үш жағдайда сәтті айыру мүмкіндігін көрсетедік. Қосымша, тіл үлгілерімен стилистик мүмкіндіктерімізді біріктіру оқиғалардың күйіне келеді. Біздің нәтижелеріміз басқа тапсырмалардың фреймілері адамдардың жазуының көмегімен әсер етеді деп көрсетеді.', 'it': "Lo stile di una scrittrice dipende non solo dai tratti personali, ma anche dal suo intento e dallo stato mentale. In questo articolo, mostriamo come le varianti dello stesso compito di scrittura possono portare a differenze misurabili nello stile di scrittura. Presentiamo un caso di studio basato sul compito di cloze della storia (Mostafazadeh et al., 2016a), in cui agli annotatori sono stati assegnati compiti di scrittura simili con vincoli diversi: (1) scrivere un'intera storia, (2) aggiungere una storia finale per un dato contesto di storia, e (3) aggiungere un finale incoerente a una storia. Mostriamo che un semplice classificatore lineare informato da caratteristiche stilistiche è in grado di distinguere con successo tra i tre casi, senza nemmeno guardare al contesto della storia. Inoltre, combinare le nostre caratteristiche stilistiche con le previsioni del modello linguistico raggiunge lo stato dell'arte della sfida del cloze della storia. I nostri risultati dimostrano che diverse cornici di compiti possono influenzare drammaticamente il modo in cui le persone scrivono.", 'lt': 'Rašytojo stilius priklauso ne tik nuo asmeninių požymių, bet ir nuo jos ketinimo ir psichikos būklės. Šiame dokumente parodomi, kaip tos pačios rašymo užduoties variantai gali lemti išmatuojamus rašymo stiliaus skirtumus. Mes pristatome atvejų tyrimą, pagrįstą istorijos užduotimi (Mostafazadeh et al., 2016a), kur anotatoriams buvo paskirtos panašios rašymo užduotys su skirtingais apribojimais: 1) rašyti visą istoriją, 2) pridėti istorijos pabaigą tam tikram istorijos kontekstui ir 3) pridėti nesuderinamą istorijos pabaigą. Mes rodome, kad paprastas linijinis klasifikatorius, informuotas stilistinėmis savybėmis, gali sėkmingai atskirti tris atvejus, net neatsižvelgdamas į istorijos kontekstą. Be to, mūsų stilistinių savybių derinimas su kalbos modelio prognozėmis pasiekia pažangiausius istorijos uždavinius. Mūsų rezultatai rodo, kad skirtingos užduočių struktūros gali dramatiškai paveikti žmonių rašymą.', 'mk': "A writer's style depends not just on personal traits but also on her intent and mental state.  Во овој весник покажуваме како варијантите на истата задача за пишување можат да доведат до мерливи разлики во стилот на пишување. Презентираме случајна студија базирана на задачата за затворање на приказните (Мостафазаде и други, 2016а), каде на анотаторите им беа доделени слични задачи за пишување со различни ограничувања: (1) пишување на цела приказна, (2) додавање на приказна која завршува за одреден контекст на приказната, и (3) додавање на несогласен кра Ние покажуваме дека едноставен линијарен класификатор информиран од стилистички карактеристики е во можност успешно да се разликува меѓу трите случаи, без дури да се погледне контекстот на приказната. Покрај тоа, комбинирањето на нашите стилистички карактеристики со предвидувањата на јазичкиот модел достигнува најсовремена изведба на предизвикот за затворање на приказната. Нашите резултати покажуваат дека различните задачни рамки можат драматично да влијаат на начинот на кој луѓето пишуваат.", 'ms': 'Gaya penulis bergantung bukan hanya pada ciri-ciri peribadi tetapi juga pada niat dan keadaan mental. Dalam kertas ini, kita menunjukkan bagaimana varian tugas tulisan yang sama boleh membawa kepada perbezaan yang boleh diukur dalam gaya tulisan. Kami memperkenalkan kajian kes berdasarkan tugas penutup cerita (Mostafazadeh et al., 2016a), di mana penganotator diberikan tugas penulisan yang sama dengan kekurangan yang berbeza: (1) menulis seluruh cerita, (2) menambah cerita yang berakhir untuk konteks cerita tertentu, dan (3) menambah akhir yang tidak konsisten kepada cerita. Kami menunjukkan bahawa pengklasifikasi linear sederhana yang diberitahu oleh ciri-ciri stilistik mampu membezakan antara tiga kes, tanpa melihat konteks cerita. Selain itu, menggabungkan ciri-ciri stilistik kami dengan ramalan model bahasa mencapai prestasi seni pada cabaran penutup cerita. Hasil kami menunjukkan bahawa bingkai tugas yang berbeza boleh mempengaruhi secara dramatis cara orang menulis.', 'ml': 'ഒരു എഴുത്തുകാരന്റെ രീതിയില്\u200d വ്യക്തിപരമായ പ്രശ്നത്തില്\u200d മാത്രമല്ല, അവളുടെ ലക്ഷ്യത്തിലും മാനസിക സ്ഥി ഈ പത്രത്തില്\u200d, ഒരേ എഴുതുന്ന പണിയുടെ വ്യത്യാസങ്ങള്\u200d എഴുതുന്നതിന്റെ രീതിയില്\u200d എഴുതുന്നതില്\u200d എഴുതുന്ന വ് കഥ ക്ലോസ് ജോലിയുടെ അടിസ്ഥാനത്തില്\u200d ഞങ്ങള്\u200d ഒരു കേസ് പഠിപ്പിക്കുന്നു (മോസ്റ്റാഫാസാദെഹ് എറ്റ് അല്), അവിടെ വ്യത്യസ്തമായ എഴുതുന്ന ജോലികള്\u200d നിയമിക്കപ്പെട്ടിരുന്നു: (1) ഒരു ക നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് സ്റ്റൈലിക്ക് ഗുണഗണങ്ങള്\u200d അറിയിക്കുന്ന ഒരു ലളിതമായ രീതിയില്\u200d ക്ലാസ്ഫിക്കറ്റര്\u200d വിവരി In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge.  നമ്മുടെ ഫലങ്ങള്\u200d വ്യത്യസ്ത ജോലിയുടെ ഫ്രാമിങ്ങുകള്\u200d ആളുകള്\u200d എഴുതുന്നത് പോലെ സ്വഭാവികമായി പ്രയോഗിക്', 'mt': 'L-istil ta’ kittieb jiddependi mhux biss fuq karatteristiċi personali iżda wkoll fuq l-intenzjoni u l-istat mentali tagħha. F’dan id-dokument, aħna nuru kif varjanti tal-istess kompitu tal-kitba jistgħu jwasslu għal differenzi li jistgħu jitkejlu fl-istil tal-kitba. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints: (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story.  Aħna nuru li klassifikatur lineari sempliċi infurmat minn karatteristiċi stilistiċi jista’ jiddistingwi b’suċċess fost it-tliet każijiet, mingħajr ma jħares lejn il-kuntest tal-istorja. Barra minn hekk, il-kombinazzjoni tal-karatteristiċi stilistiċi tagħna mal-previżjonijiet tal-mudell lingwistiku tilħaq l-aqwa prestazzjoni fuq l-isfida tal-għeluq tal-istorja. Ir-riżultati tagħna juru li oqfsa differenti ta’ kompiti jistgħu jaffettwaw b’mod drammatiku l-mod kif in-nies jiktbu.', 'ro': 'Stilul unei scriitoare depinde nu doar de trăsăturile personale, ci și de intenția și starea ei mentală. În această lucrare, vom arăta cum variantele aceleiași sarcini de scriere pot duce la diferențe măsurabile în stilul de scriere. Prezentăm un studiu de caz bazat pe sarcina de închidere a poveștii (Mostafazadeh et al., 2016a), în care adnotatorilor li s-au atribuit sarcini similare de scriere cu constrângeri diferite: (1) scrierea unei întregi povești, (2) adăugarea unui final de poveste pentru un context dat de poveste și (3) adăugarea unui final incoerent unei povești. Noi arătăm că un clasificator liniar simplu, informat de caracteristici stilistice, este capabil să distingă cu succes între cele trei cazuri, fără să se uite măcar la contextul povestirii. În plus, combinarea caracteristicilor noastre stilistice cu predicțiile modelului lingvistic ajunge la performanța de ultimă generație a provocării cloze povești. Rezultatele noastre demonstrează că diferitele cadre de sarcini pot afecta dramatic modul în care oamenii scriu.', 'pl': 'Styl pisarza zależy nie tylko od cech osobistych, ale także od intencji i stanu psychicznego. W niniejszym artykule pokazujemy, w jaki sposób warianty tego samego zadania pisania mogą prowadzić do wymiernych różnic w stylu pisania. Przedstawiamy studium przypadku oparte na zadaniu cloze story (Mostafazadeh et al., 2016a), w którym adnotatorzy otrzymali podobne zadania pisania z różnymi ograniczeniami: (1) pisanie całej historii, (2) dodanie końcówki historii dla danego kontekstu historii oraz (3) dodanie niespójnego zakończenia do opowieści. Pokazujemy, że prosty liniowy klasyfikator oparty na cechach stylistycznych jest w stanie z powodzeniem rozróżnić trzy przypadki, nawet nie patrząc na kontekst opowieści. Ponadto połączenie naszych funkcji stylistycznych z prognozami modeli językowych osiąga najnowocześniejsze osiągnięcie wyzwania dotyczącego cloze historii. Nasze wyniki pokazują, że różne ramy zadań mogą dramatycznie wpływać na sposób pisania ludzi.', 'mn': 'Зөвхөн хувийн чадвар биш, мөн түүний зорилго, сэтгэл санааны байдалд хамааралтай. Энэ цаасан дээр бид ижил бичих үйлдлийн өөрчлөлт бичих хэлбэрээр хэмжигдэх ялгааг харуулж байна. Бид түүхийн цохилтын ажлын үндсэн судалгааг (Mostafazadeh et al., 2016a) тайлбарлаж өгсөн бөгөөд хүмүүс түүхийн төгсгөлд төгсгөл түүхийн төгсгөлд төгсгөл, түүхийн төгсгөлд төгсгөл, мөн (3) түүхийн төгсгөлд төгсгөл байдаг. Бид энгийн шугам хуваалцагч нь стилист хэлбэрээр мэдээлэл өгсөн гурван тохиолдолд амжилттай хуваалцах боломжтой гэдгийг харуулсан. Үүнээс гадна, хэл загварын таамаглалтай стилист чадварыг нэгтгэх нь түүхийн дараагийн урлагийн үйл ажиллагааны төвшинд хүрч чадна. Бидний үр дүн нь олон ажлын фреймментүүд хүмүүсийн бичиж буй зүйлсийг маш их нөлөөлж чадна гэдгийг харуулдаг.', 'no': 'Eit skrivarstil avhenger ikkje berre på personlege eigenskapar, men også på henne vilje og mentalnastar. I denne papiret viser vi korleis variantar av det same skriveoppgåva kan føre til målbare forskjeller i skrivestilen. Vi presenterer ein tilfeldige studie basert på historien klose oppgåva (Mostafazadeh et al., 2016a), der annotatorar vart tildelt liknande skriveoppgåver med ulike begrensningar: (1) skrive ei heil historie, (2) legg til ei historie som sluttar på eit gitt historiekontekst, og (3) legg til ei inkoherende slutt til ei historie. Vi viser at ein enkel lineær klassifiserer som er informert av stylistiske funksjonar kan vellykkeleg distisera mellom dei tre tilfellene, utan å sjå på historiekonteksten. I tillegg kombinerer stylistiske funksjonar våre med språk-modelleforegåver når det er tilstand til kunstendige utviklinga på historien for å klose utviklinga. Resultatet våre viser at ulike oppgåver kan dramatisk påvirke måten folk skriva.', 'sr': 'Styl pisaca zavisi ne samo od ličnih osobina, nego i od njene namjere i mentalnog stanja. U ovom papiru pokazujemo kako varianti iste pismene zadatke mogu dovesti do mjerenih razlika u stilu pisanja. Predstavljamo studiju slučajeva na temelju zadatka za kloziranje priče (Mostafazadeh et al., 2016a), gdje su annotatori dodali slične pismene zadatke sa različitim ograničenjima: 1) pisanje cele priče, 2) dodavanje priče koja završava za kontekst određene priče, i (3) dodavanje nepoštenog kraja priče. Pokazujemo da je jednostavan linearni klasifikator obavešten stilističkim karakteristikama uspešno razlikovan među tri slučaja, a da ne pogleda ni kontekst priče. Osim toga, kombinacija naših stilističkih karakteristika sa predviđanjem jezičkog modela postiže stanje predstave umjetnosti na izazovu za kloziranje priče. Naši rezultati pokazuju da različite okvire zadataka mogu dramatično utjecati na način na koji ljudi pišu.', 'si': 'ලේඛකයේ විදියට පුද්ගලික විදියට විශේෂයක් නෙවෙයි, ඒත් එයාගේ අදහස් සහ මන්ත්\u200dරික විදියට විශේෂය මේ පත්තරේ අපි පෙන්වන්නේ කොහොමද වෙනස් ලියපු වැඩක් ලියපු විදියට ලියපු විදියට වෙනස් කරන්න පුළුවන්  අපි පෙන්වන්න ප්\u200dරශ්නයක් කතාව ක්ලෝස් වැඩේ අධිකරණය (Mostafazedeh et al., 2016a), කොහෙන් අනතුරු වෙනස් වෙනස් කතාවක් ලියනවා වගේ වෙනස් කතාවක් තියෙනවා: (1) මුළු කතාවක් ලියනවා, (2) කත අපි පෙන්වන්නේ සාමාන්\u200dය ලේනියාර් විශේෂකයෙක් ස්ටයිලිස්ටික් විශේෂකයෙන් සමහර විශේෂ විශේෂකයෙක් සමහර විශ ඒ වගේම, භාෂාව ප්\u200dරමාණය සමග අපේ ස්ටයිලිස්ටික අවශ්\u200dයය සම්බන්ධ කරන්න, කතාව ක්ලෝස් අවශ්\u200dයයේ කිරීමේ ස් අපේ ප්\u200dරතිචාරය පෙන්වන්නේ වෙනස් වැඩක් වැඩක් ප්\u200dරතිචාරය ප්\u200dරතිචාර කරන්න පුළුවන් මිනිස්', 'so': "A writer's style depends not just on personal traits but also on her intent and mental state.  Warqadan waxan ka muujinaynaa sida kala duwanaanshaha shaqada isku mid ah ee qoraalka ay ugu socon karaan kala duduwan qoraalka. Taariikhda waxaynu soo bandhignaa waxbarasho ku saleysan shaqada kooxaha taariikhda (Mostafazadeh et al., 2016a), kaas oo lagu sharciyey shaqooyin la mid ah oo qorayo oo ku qoran qasabyo kala duduwan: (1) qoraya sheeko dhammaantiis, (2) ku daro sheeko uu ku dhamaado xilliga la siiyey, iyo (3) ku daro sheeko a an la dhamaado. Waxaynu tusnaynaa in fasax fudud oo qoraal ah oo loo soo sheegay tababar-isticmaal ah uu suurtagal u kala sooci karo sadexda xaaladood, oo aan xittaa fiirin qoraalka. Intaas waxaa dheer in la isku xiriiro tababarideena muuqashada luuqada lagu sii sheegayo uu gaadhaa xaaladda farshaxanka ee ku saabsan dhibaatada taariikhda qabsashada. Abaalkayaga waxay caddaysaa in qasnadaha shaqada kala duduwan ay si aad ah u saameyn karaan sida dadku u qoro.", 'sv': 'En författares stil beror inte bara på personliga drag utan också på hennes avsikt och mentala tillstånd. I denna uppsats visar vi hur varianter av samma skrivuppgift kan leda till mätbara skillnader i skrivstil. Vi presenterar en fallstudie baserad på story cloze-uppgiften (Mostafazadeh et al., 2016a), där kommentatorer tilldelades liknande skrivuppgifter med olika begränsningar: (1) skriva en hel berättelse, (2) lägga till ett berättelseslut för ett givet berättelsesammanhang, och (3) lägga till ett osammanhängande slut till en berättelse. Vi visar att en enkel linjär klassificerare med hjälp av stilistiska drag framgångsrikt kan skilja mellan de tre fallen, utan att ens titta på berättelsens kontext. Genom att kombinera våra stilistiska funktioner med språkmodellförutsägelser uppnår vi dessutom toppmodern prestanda på story cloze utmaningen. Våra resultat visar att olika arbetsramar dramatiskt kan påverka hur människor skriver.', 'ur': 'ایک لکھنے والے کا طریقہ صرف شخصی ویژگی پر نہیں ہے بلکہ اس کے قصد اور روانی حالت پر بھی مضبوط ہے. ہم اس کاغذ میں دکھاتے ہیں کہ کس طرح الفاظت لکھنے کی تابع کرسکتے ہیں لکھنے کی شکل میں اندازہ قابل تفاوت کی وجہ سے۔ ہم ایک ایسی مطالعہ کریں جو کہانیاں کلوز کی تابع پر (Mostafazadeh et al., 2016a) ہے جہاں مطالعہ کرنے والوں کو ایسی طرح لکھنے کی تابع مقرر کی گئی تھی: ایک کلام لکھنا، ایک ایسی کہانیاں اضافہ کرنا اور (3) ایک ایسی کہانیاں اضافہ کرنا، ہم نشان دیتے ہیں کہ ایک ساده linear classifier جو استیلیسٹی ویٹیوں کے ذریعہ بتایا گیا ہے اس میں تین کیسوں کے درمیان موفقیت کے ساتھ تفرق کرسکتا ہے، حالات کے متصلہ کو بھی نہیں دیکھتے۔ اور اس کے علاوہ، ہمارے استیلیسٹی ویژے کو زبان موڈل کی پیش بینی کے ساتھ ملا کر کہانیاں کے کلوز چال پر آتا ہے. ہمارے نتیجے دکھاتے ہیں کہ مختلف ٹاکس فرمینگ کس طرح لوگوں کو لکھنے کی تاثیر دیتی ہے۔', 'ta': 'ஒரு எழுத்தாளரின் பாணி இந்த காகிதத்தில், அதே எழுதும் பணியின் மாறுபாடுகள் எவ்வாறு எழுதும் பாணியில் அளவிற்கு மாறுபாடுகளை காட்டு நாங்கள் ஒரு செய்தி கட்டுப்பாட்டை கட்டுப்படுத்தி வரலாற்று செயலை அடிப்படையில் (மோஸ்டாபாஜாத் மற்றும் அல், 2016) ஒரு செய்தி படிக்கையை கொண்டுள்ளோம். அதில் அறிவிப்பார்கள் ஒத்த எழுது We show that a simple linear classifier informed by stylistic features is able to successfully distinguish among the three cases, without even looking at the story context.  மேலும், எங்கள் பாணியல் குணங்களை மொழி மாதிரி முன்னோட்டத்துடன் ஒன்று சேர்க்கும் போது கதையின் கடைசி சவால்வில் கலை ச முடிவு', 'uz': "Yozuvchi uslubi faqat shaxsiy shifokorga ishlatadi, balki o'z qanday va mental holatiga ishlatadi. Bu qogʻozda, biz bitta yozish vazifaning o'zgarishlarini yozish uslubining o'lchamini o'zgartirish mumkin. Biz har bir kashfa o'qituvchiga (Mostafazadeh et al., 2016a) asosida o'zgarishlar turli yozish vazifalarini o'rganish mumkin:(1) butun hikoyani yozish, (2) bir hikoyani yozib qoʻshish va (3) o'sha tarixi muzdalanini qoʻshish mumkin. We show that a simple linear classifier informed by stylistic features is able to successfully distinguish among the three cases, without even looking at the story context.  Ko'pchilik, bizning uslublarning misol modeli bilan birlashtirish mumkin, hikoyalarning qiymati murakkab qilish davomida sanam bajarish holatiga ega. Bizning natijalarimizni ko'rsatadi, har xil vazifalar qatlamlari odamlar yozishni o'zgartiradi.", 'vi': 'Văn phong của một nhà văn không chỉ phụ thuộc vào đặc điểm cá nhân mà còn phụ thuộc vào ý đồ và tinh thần của cô. Trong tờ giấy này, chúng tôi cho thấy các biến thể của cùng một nhiệm vụ viết có thể gây ra những khác biệt thể xác định về cách viết. Chúng tôi đưa ra một nghiên cứu về các trường hợp dựa trên nhiệm vụ đánh dấu câu chuyện (Mostafazadeh et al., phần 6a), nơi nhà thanh niên được giao nhiệm vụ viết tương tự với các giới hạn khác nhau: 1) viết một câu chuyện to àn diện, 2) thêm một câu chuyện kết thúc cho một câu chuyện cụ thể, và (3) thêm một kết thúc không liên quan tới một câu chuyện. Chúng tôi cho thấy một nhà phân loại đơn giản được thông báo theo phong cách có thể phân biệt thành công trong ba trường hợp mà không cần phải nhìn vào ngữ cảnh. Thêm vào đó, kết hợp các tính chất thiết kế với dự đoán của mô hình ngôn ngữ đạt đến trình độ nghệ thuật trong việc thi đấu. Kết quả chứng minh rằng sự khác biệt trong các cuộc chiến có thể ảnh hưởng đến cách người ta viết.', 'nl': 'De stijl van een schrijver hangt niet alleen af van persoonlijke eigenschappen, maar ook van haar intentie en mentale toestand. In dit artikel laten we zien hoe varianten van dezelfde schrijftaak kunnen leiden tot meetbare verschillen in schrijfstijl. We presenteren een casestudy gebaseerd op de story cloze taak (Mostafazadeh et al., 2016a), waarbij annotators vergelijkbare schrijftaken kregen toegewezen met verschillende beperkingen: (1) het schrijven van een heel verhaal, (2) het toevoegen van een verhaal einde voor een bepaalde story context, en (3) het toevoegen van een incoherent einde aan een verhaal. We laten zien dat een eenvoudige lineaire classificator gebaseerd op stilistische kenmerken succesvol onderscheid kan maken tussen de drie gevallen, zonder zelfs maar naar de verhaalscontext te kijken. Bovendien bereikt het combineren van onze stijlfuncties met taalmodel voorspellingen state-of-the-art prestaties op de story cloze uitdaging. Onze resultaten tonen aan dat verschillende taakverdelingen de manier waarop mensen schrijven dramatisch kunnen beïnvloeden.', 'da': 'En forfatters stil afhænger ikke kun af personlige træk, men også af hendes hensigt og mentale tilstand. I denne artikel viser vi, hvordan varianter af samme skriveopgave kan føre til målbare forskelle i skrivestil. Vi præsenterer et casestudie baseret på historien cloze opgaven (Mostafazadeh et al., 2016a), hvor kommentatorer fik tildelt lignende skriveopgaver med forskellige begrænsninger: (1) at skrive en hel historie, (2) at tilføje en historieslutning for en given historiekontekst, og (3) at tilføje en inkonsekvent slutning til en historie. Vi viser, at en simpel lineær klassificering baseret på stilistiske træk med succes er i stand til at skelne mellem de tre tilfælde uden engang at se på historiens kontekst. Hertil kommer, at kombinere vores stilistiske funktioner med sprogmodel forudsigelser når state of te art performance på historie cloze udfordringen. Vores resultater viser, at forskellige opgaverammenslutninger dramatisk kan påvirke den måde, folk skriver på.', 'hr': 'Stil pisaca ovisi ne samo o osobnim osobama, nego i o njenoj namjeri i mentalnoj stanji. U ovom papiru pokazujemo kako varianti istog pisaćeg zadatka mogu dovesti do mjerenih razlika u pisaćem stilu. Predstavljamo ispitivanje slučajeva temeljno na zadatku kloziranja priče (Mostafazadeh et al., 2016a), gdje su annotatori dodali slične pismene zadatke s različitim ograničenjima: 1) pisanje cijele priče, 2) dodavanje priče koja se završava za kontekst određene priče, i (3) dodavanje nepoštenog kraja priče. Pokazujemo da je jednostavan linearni klasifikator obaviješten stilističkim karakteristikama uspješno određen među tri slučaja, bez čak ni pogledanja konteksta priče. Osim toga, kombinacija naših stilističkih karakteristika sa predviđanjima jezičkog modela postiže stanje učinkovitosti umjetnosti na izazovu priče za kloziranje. Naši rezultati pokazuju da različiti okviri zadataka mogu dramatično utjecati na način na koji ljudi pišu.', 'bg': 'Стилът на писателя зависи не само от личните черти, но и от намерението и психическото й състояние. В тази статия показваме как вариантите на една и съща задача за писане могат да доведат до измерими различия в стила на писане. Представяме казус, базиран на задачата за затваряне на историята (където анотаторите са възложени подобни задачи за писане с различни ограничения: (1) писане на цяла история, (2) добавяне на край на история за даден контекст на историята и (3) добавяне на несвързан край към историята. Показваме, че прост линеен класификатор, информиран от стилистични особености, е в състояние успешно да разграничи между трите случая, без дори да погледне контекста на историята. В допълнение, съчетаването на стилистичните ни характеристики с прогнозите на езиковите модели достига до най-съвременното представяне на предизвикателството за клозе на историята. Нашите резултати показват, че различните рамки на задачите могат драстично да повлияят на начина, по който хората пишат.', 'de': 'Der Stil einer Schriftstellerin hängt nicht nur von persönlichen Eigenschaften ab, sondern auch von ihrer Absicht und ihrem mentalen Zustand. In diesem Beitrag zeigen wir, wie Varianten derselben Schreibaufgabe zu messbaren Unterschieden im Schreibstil führen können. Wir präsentieren eine Fallstudie basierend auf der Story Cloze Task (Mostafazadeh et al., 2016a), in der Annotatoren ähnliche Schreibaufgaben mit unterschiedlichen Einschränkungen zugewiesen wurden: (1) Schreiben einer ganzen Story, (2) Hinzufügen eines Story Endes für einen bestimmten Story Kontext und (3) Hinzufügen eines inkohärenten Endes zu einer Story. Wir zeigen, dass ein einfacher linearer Klassifikator, der durch stilistische Merkmale geprägt ist, in der Lage ist, die drei Fälle erfolgreich zu unterscheiden, ohne auch nur den Handlungskontext zu betrachten. Darüber hinaus erreicht die Kombination unserer stilistischen Merkmale mit Sprachmodellvorhersagen den neuesten Stand der Technik bei der Story Cloze Challenge. Unsere Ergebnisse zeigen, dass verschiedene Aufgabenrahmen die Art und Weise, wie Menschen schreiben, dramatisch beeinflussen können.', 'id': 'Gaya penulis tergantung bukan hanya pada sifat pribadi tapi juga pada niatnya dan keadaan mental. Dalam kertas ini, kita menunjukkan bagaimana varian dari tugas penulisan yang sama dapat menyebabkan perbedaan yang dapat diukur dalam gaya penulisan. Kami mempersembahkan sebuah studi kasus berdasarkan tugas penutup cerita (Mostafazadeh et al., 2016a), di mana annotator diberikan tugas penulisan yang sama dengan kebarangan yang berbeda: (1) menulis seluruh cerita, (2) menambah cerita yang berakhir untuk konteks cerita tertentu, dan (3) menambah akhir yang tidak konsisten untuk cerita. Kami menunjukkan bahwa klasifikasi linear sederhana yang diberitahu oleh ciri-ciri stilistik dapat membedakan dengan sukses antara tiga kasus, bahkan tanpa melihat konteks cerita. Selain itu, menggabungkan karakteristik stilistik kita dengan prediksi model bahasa mencapai prestasi seni terbaik pada tantangan penutup cerita. Hasil kami menunjukkan bahwa bingkai tugas yang berbeda dapat mempengaruhi secara dramatis cara orang menulis.', 'ko': '작가의 풍격은 개인의 특징에 달려 있을 뿐만 아니라 그녀의 의도와 정신 상태에도 달려 있다.본고에서 우리는 같은 창작 임무의 변체가 어떻게 창작 풍격의 측정 가능한 차이를 초래하는지 보여 주었다.우리는 이야기 완성형 빈칸 채우기 임무를 바탕으로 한 사례 연구(Mostafazadeh et al., 2016a)를 제시했다. 그 중에서 주석자는 서로 다른 제약 조건을 가진 유사한 글쓰기 임무를 배정받았다. (1) 완전한 이야기를 쓰고 (2) 주어진 이야기 상하문에 이야기의 결말을 추가하고 (3) 한 이야기에 일관되지 않은 결말을 추가한다.우리는 간단한 선형 분류기가 문체 특징에 따라 이 세 가지 상황을 성공적으로 구분할 수 있고 심지어 이야기의 배경을 보지 않는다는 것을 보여준다.그 밖에 우리의 스타일 특징과 언어 모델 예측을 결합시켜 이야기의 완형 빈칸 채우기 도전에서 가장 선진적인 수준에 이르렀다.우리의 연구 결과에 따르면 서로 다른 임무 구조는 사람들의 작문 방식에 현저한 영향을 줄 수 있다.', 'sw': 'Mtandao wa mwandishi unategemea siyo tu kwa matatizo ya kibinafsi bali pia kwa nia yake na hali ya akili. Katika karatasi hii, tunaonyesha jinsi tofauti za kazi hiyo ya uandishi unavyoweza kusababisha tofauti za kipimo katika mtindo wa kuandika. Tunajaribu utafiti wa kesi kwa msingi wa kazi ya kufungia hadithi (Mostafazadeh et al., 2016), ambapo wataalamu waliwekwa majukumu yanayofanana na vikwazo tofauti: (1) kuandika hadithi nzima, (2) kuongeza hadithi inayomalizika kwa muktadha wa habari, na (3) kuongeza mwisho wa hadithi isiyofanana. Tunaonyesha kuwa mwandishi wa simu rahisi aliyeelezwa na vipengele vya msingi anaweza kufanikiwa kufanikiwa kati ya kesi tatu, bila hata kuangalia muktadha wa habari hiyo. Zaidi ya hayo, kuunganisha vipengele vyetu vya mtindo wa lugha na utabiri wa mitindo ya lugha unafikia hali ya utendaji wa sanaa kuhusu changamoto za kufungia simulizi. Matokeo yetu yanaonyesha kuwa mgogoro tofauti wa kazi unaweza kuathiri kwa kiasi kikubwa namna watu wanavyoandika.', 'tr': 'Awtoryň stili diňe şahsy hasaplaryna bagly däl, ýöne onuň niýeti we zihinsel durumyna hem garaşýar. Bu kagyzda, biz bir ýazma işiniň wariantlarynyň ýazma tarzda üýtgeşiklerini nähili edip biljekdigini görkeýäris. Biz hekaýa kloz täbligine (Mostafazadeh et al., 2016a) tabanly bir sahyp öwrenmesine meñzeş syýahat täblikleri (1) doly bir hekaýa ýazmak üçin bir hekaýa ekleýäris, we (3) bir hekaýa soňlandyrmaz bir soňy ekleýäris. Biz stylistik özellikleri tarapyndan bilgili basit çyzgyly klasifikatçy üç hadysa arasynda hatda hekaýa kontekstüne garamazdan başaryp bilýäris. Hemmäçe, dil nusgalary bilen stylistik özelliklerimizi birleştirmek hekaýa çevrilemek kynçylygynda sungat eserleriniň durumyna ulaşýar. Biziň netijelerimiz farklı işiň framlarynyň adamlaryň ýazmagy ýaly nähili täsirini edip biljekdigini kanıtlaýar.', 'fa': 'طرح نویسنده فقط به ویژه های شخصی بستگی دارد، بلکه به هدف و وضعیت روانی او بستگی دارد. در این کاغذ، ما نشان می دهیم که چگونه تغییرات یک کار نوشتن می توانند به تغییرات قابل اندازه گیری در سبک نوشتن رخ دهند. ما یک مطالعه پرونده را بر اساس وضع تغییر داستان (Mostafazadeh et al., 2016a) پیشنهاد می\u200cکنیم، جایی که مطالعه\u200cکنندگان کار نوشتن مشابه با محدودیت مختلف قرار داده می\u200cشوند: (1) نوشتن یک داستان کامل (2) اضافه داستان پایان برای یک موضوع داستان معلوم می\u200cشود، و (3) اضافه کردن یک پایا ما نشان می دهیم که یک راهنمایی خط ساده که توسط ویژه\u200cهای استیلیستیک اطلاعات داده شده است قادر به موفقیت در میان سه پرونده تفاوت دهد، بدون حتی نگاه به موضوع داستان. علاوه بر این، جمع کردن ویژه\u200cهای استیلیستیک ما با پیش\u200cبینی\u200cهای مدل زبان به وضعیت فعالیت هنری روی چالش\u200cبندی داستان می\u200cرسد. نتیجه\u200cهای ما نشان می\u200cدهند که فرم\u200cهای کار متفاوتی می\u200cتوانند به طریق نوشتن مردم تحت تاثیر قرار دهند.', 'af': "'n Skrifter se styl afhang nie net op persoonlike eienskappe nie, maar ook op haar doel en menslike toestand. In hierdie papier, wys ons hoe variante van dieselfde skryftaak kan lei na gemeetbare verskille in skryfstyl. Ons stel 'n geval studie gebaseer op die storie klose taak (Mostafazadeh et al., 2016a), waar annotators gelyke skryftaak met verskillende beheinings toegelaat word: (1) skryf 'n hele storie, (2) byvoeg by 'n storie einde vir 'n gegewe storie konteks, en (3) byvoeg by 'n onheilige einde a an 'n storie. Ons wys dat 'n eenvoudige lineêre klassifiseerder wat deur stylistiese funksies inligtig is, kan suksesvol onder die drie gevalle bereik, sonder selfs na die storie konteks kyk. In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge. Ons resultate wys dat verskillende taak ramme dramatiese kan effekteer die manier wat mense skryf.", 'sq': 'Stili i shkrimtarit varet jo vetëm nga traditat personale por gjithashtu nga qëllimi i saj dhe gjendja mendore. In this paper, we show how variants of the same writing task can lead to measurable differences in writing style.  Ne paraqesim një studim rasti bazuar në detyrën e mbylljes së historisë (Mostafazadeh et al., 2016a), ku anotatorëve u caktuan detyra të ngjashme shkrimi me kufizime të ndryshme: (1) shkrimi i një historie të tërë, (2) shtimi i një historie që përfundon për një kontekst të caktuar historie dhe (3) shtimi i një përfundimi të pakoheshëm në një histori. Ne tregojmë se një klasifikues linear i thjeshtë i informuar nga karakteristikat stilistike është në gjendje të dallojë me sukses midis tre rasteve, pa shikuar as kontekstin e historisë. Përveç kësaj, kombinimi i karakteristikave tona stilistike me parashikimet e modelit gjuhësor arrin në shfaqjen më të lartë të artit në sfidën e mbylljes së historisë. Rezultatet tona tregojnë se kornizat e ndryshme të detyrave mund të ndikojnë dramatikisht në mënyrën sesi njerëzit shkruajnë.', 'am': 'የጸሐፊ ዘይት የራሱ ጉዳይ ብቻ አይደለም ነገር ግን በአስብ እና በአእምሮ ግዛት ላይ ነው፡፡ በዚህ ካላት፣ አንድ የጽሑፍ ሥራ ልዩ ልዩ ልዩነት በጽሑፍ ልዩነት እንዴት እንዲለይ ይችላል እናሳያቸዋለን፡፡ በ ታሪክ ክፍል አድራጊ (ሞስታፋzadeh et al., 2016a) በተለየ የጽሑፍ ሥርዓቶች በተለያዩ ግንኙነት የተሰናከሉ የጉዳይ ትምህርት አቀረብናል:(1) ሁሉንም ታሪክ ጽፏል (2) በተሰጠው ታሪክ ክፍል እና (3) ታሪክ የሚጨምር ታሪክ ነው፡፡ እናሳየዋለን በሥርዓት የተማረከ ቀላል የመስመር ክፍሎች በሦስቱ ጉዳዮች መካከል በሙሉ ሊለይ ይችላል፡፡ በተጨማሪም፣ የቋንቋ ምሳሌ የመፍጠርን የዐርድ ድምፅ በታሪክ ክፍል ላይ የድምፅ ጥያቄ ይደርሳል፡፡ ፍሬዎቻችን የተለያዩ የስራ ግንኙነት ሕዝቦች እንደሚጻፉት በብርቱ ያስጨንቃቸዋል፡፡', 'hy': 'Գործողի ոճը կախված է ոչ միայն անձնական հատկանիշներից, այլ նաև նրա մտադրության և մտավոր վիճակից: In this paper, we show how variants of the same writing task can lead to measurable differences in writing style.  Մենք ներկայացնում ենք մի դեպքի ուսումնասիրություն, որը հիմնված է պատմության ավարտական գործի վրա (Մոստաֆազադեհ և այլն, 2016a), որտեղ annoտատորներին նման գրողական գործեր էին տրված տարբեր սահմանափակումներով: (1) ամբողջ պատմություն գրելը, (2) պատմություն ավելացնելը, որը ավելացնում է որոշ պատմությունների կոն Մենք ցույց ենք տալիս, որ մի պարզ գծային դասակարգիչ, որը տեղեկացված է գծային հատկություններով, կարող է հաջողությամբ տարբերակել երեք դեպքերը առանց նայելու պատմության կոնտեքստին: Ավելին, մեր ոճիլիստական հատկությունները միավորելը լեզվի մոդելի կանխատեսումների հետ հասնում է պատմությունը փակցնելու մարտահրավերի ամենաբարձր արդյունքին: Մեր արդյունքները ցույց են տալիս, որ տարբեր խնդիրների կառուցվածքները կարող են դրամական ազդեցություն ունենալ մարդկանց գրելու ձևի վրա:', 'bn': 'একজন লেখকের ধরন শুধুমাত্র ব্যক্তিগত ক্ষতির উপর নির্ভর করে না, বরং তার ইচ্ছা এবং মানসিক অবস্থার উপর নির্ভর করে। এই কাগজটিতে আমরা দেখাচ্ছি একই লেখার কাজের ভিন্ন ভিন্ন ভিন্ন কিভাবে লেখার ধরনের মাপের পার্থক্যের কারণ আমরা একটি কেসের গবেষণা উপস্থাপন করছি গল্প ক্লোজ করার উপরে (মোস্টাফাজাদেহ এন্ট আল, ২০১৬), যেখানে বিভিন্ন ধরনের লেখা কাজের সাথে বিভিন্ন নিয়মিত করা হয়েছিল: (১) একটি পুরো গল্প লিখেছিল, (২)  আমরা দেখাচ্ছি যে স্টাইলিস্টিক বৈশিষ্ট্যাবলীর তথ্যে জানানো একটি সাধারণ লাইনিয়ার বিশ্লেষক এই তিনটি কেসের মধ্যে সফল ভাবে বিচ এছাড়াও, আমাদের স্টাইলিস্টিক বৈশিষ্ট্যাবলীর সাথে ভাষার মডেলের ভবিষ্যৎবাণীর সাথে সংযুক্ত করে গল্প ক্লোজের চ আমাদের ফলাফল দেখাচ্ছে যে বিভিন্ন কাজের ফ্র্যামিং মানুষ যেভাবে লিখেছে সেভাবে সেভাবে ন্যায়েকভ', 'bs': 'Stil pisaca ovisi ne samo o ličnim osobinama, nego i o njenoj namjeri i mentalnoj stanji. U ovom papiru pokazujemo kako varianti istog pisaćeg zadatka mogu dovesti do mjerenih razlika u pisaćem stilu. Predstavljamo studiju slučajeva na temelju zadatka za kloziranje priče (Mostafazadeh et al., 2016a), gdje su annotatori dodali slične pismene zadatke sa različitim ograničenjima: napisati cijelu priču, dodajući priču koja završava za kontekst određene priče, i (3) dodajući nepošteni kraj priče. Pokazujemo da je jednostavan linearni klasifikator obaviješten stilističkim karakteristikama uspješno određen među tri slučaja, bez čak ni pogledanja konteksta priče. Osim toga, kombinacija naših stilističkih karakteristika sa predviđanjima jezičkog modela postiže stanje učinkovitosti umjetnosti na izazovu za kloziranje priče. Naši rezultati pokazuju da različite okvire zadataka mogu dramatično utjecati na način na koji ljudi pišu.', 'az': 'Yazıcının stili yalnız kişisel xüsusiyyətlərə bağlı deyil, ancaq onun niyyəti və ruhsal durumuna bağlı. Bu kağızda, biz aynı yazma işin in variablarını yazma stilində ölçülü fərqli olaraq göstəririk. Biz hekayətin kloz işinə dayanan bir məsəl təhsil göstəririk (Mostafazadeh et al., 2016a). Biz göstəririk ki, stylistik xüsusiyyətləri ilə bildirilmiş basit linear klasifikatçısı, hekayə məsələlərini baxmadan üç məsələlər arasında müvəffəqiyyətlə ayırd edə bilər. Əksinə, bizim stylistik xüsusiyyətimizi dil modeli tədbirləri ilə birləşdirmək hekayətlərin kloz çətinliklərinin vəziyyətinə gəlir. Bizim sonuçlarımız insanların yazdığı kimi, fərqli işlər çerçimləri dəhşətli təsir edə biləcəyini göstərir.', 'ca': "L'estil d'una escriptora no només depèn dels trets personals, sinó també de la seva intenció i estat mental. En aquest article mostram com les variants de la mateixa tasca d'escriptura poden portar a diferències mesurables en l'estil d'escriptura. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints: (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story.  Mostrem que un simple classificador linear informat per característiques estilistiques pot distingir amb èxit entre els tres casos, sense ni mirar el context de la història. A més, combinar les nostres característiques estilistiques amb les prediccions del model de llenguatge arriba a l'actuació més avançada en el repte de cloze de la història. Els nostres resultats demostren que diferents marcs de tasques poden afectar dràsticament la manera en que la gent escriu.", 'cs': 'Styl spisovatelky závisí nejen na osobních rysech, ale také na jejím záměru a duševním stavu. V tomto článku ukazujeme, jak varianty stejného psacího úkolu mohou vést k měřitelným rozdílům ve stylu psaní. Představujeme případovou studii založenou na úkolu cloze příběhu (Mostafazadeh et al., 2016a), kde byly anotátorům přiděleny podobné úkoly psaní s různými omezeními: (1) psaní celého příběhu, (2) přidání konce příběhu pro daný kontext příběhu a (3) přidání nesouvisejícího konce příběhu. Ukazujeme, že jednoduchý lineární klasifikátor založený na stylistických rysech je schopen úspěšně rozlišit mezi třemi případy, aniž by se ani díval na kontext příběhu. Kromě toho kombinace našich stylistických vlastností s předpovědí jazykových modelů dosahuje nejmodernějších výkonů v příběhu cloze výzvy. Naše výsledky ukazují, že různé rámečky úkolů mohou dramaticky ovlivnit způsob psaní lidí.', 'fi': 'Kirjoittajan tyyli ei riipu vain henkilökohtaisista ominaisuuksista vaan myös hänen tarkoituksestaan ja henkisestä tilastaan. Tässä artikkelissa näytämme, miten saman kirjoitustehtävän variantit voivat johtaa mitattaviin kirjoitustyylieroihin. Esitämme tapaustutkimuksen, joka perustuu tarinan cloze -tehtävään (Mostafazadeh et al., 2016a), jossa annotattoreille annettiin samankaltaisia kirjoitustehtäviä erilaisin rajoituksin: (1) koko tarinan kirjoittaminen, (2) tarinan lopun lisääminen tiettyyn tarinakontekstiin ja (3) tarinan epäjohdonmukainen loppu. Osoitamme, että yksinkertainen lineaarinen luokittelija, joka perustuu tyylillisiin ominaisuuksiin, pystyy erottamaan onnistuneesti kolme tapausta katsomatta edes tarinan kontekstia. Lisäksi tyylillisten ominaisuuksiemme ja kielimalliennusteiden yhdistäminen saavuttaa huipputason esityksen tarinan cloze -haasteessa. Tuloksemme osoittavat, että erilaiset tehtäväkehykset voivat vaikuttaa dramaattisesti ihmisten kirjoittamiseen.', 'et': 'Kirjaniku stiil ei sõltu mitte ainult isiklikest omadustest, vaid ka tema kavatsusest ja vaimsest seisundist. Käesolevas töös näitame, kuidas sama kirjutamisülesande variandid võivad viia mõõdetavate erinevusteni kirjutamisstiilis. Esitame juhtumiuuringu, mis põhineb loo sulgemise ülesandel (Mostafazadeh et al., 2016a), kus annotatoritele määrati sarnased kirjutamisülesanded erinevate piirangutega: (1) terve loo kirjutamine, (2) loo lõpu lisamine antud lookonteksti jaoks ja (3) loole segase lõpu lisamine. Näitame, et lihtne lineaarne klassifitseerija, mida teavitatakse stiililistest omadustest, suudab edukalt eristada kolme juhtumi vahel, isegi lugu konteksti vaatamata. Lisaks jõuab meie stiilifunktsioonide ja keelemudeli ennustuste kombineerimine loo sulgemise väljakutse tipptasemel etenduseni. Meie tulemused näitavad, et erinevad ülesannete raamistikud võivad oluliselt mõjutada inimeste kirjutamist.', 'jv': 'Jeneng penalah pennulis kuwi ngregang pengguna-pengguna kuwi duluran ngerti apa sing apik lan ora seneng pisan banget. In this paper, we show variants of the same writing task can amount to measurement gaps in writing style Kita menehi durung kelas menehi nggawe barang-sistem dadi sabanjur (Mustapadadeh et al, 2011). Awak dhéwé ngerasakno sistem linear sing ditambah akeh dhéwé ngerasakno karo akeh stilistik, iso ngubah sing beraksi tigoro basa saboh sak telu, ora bisa nguasakno kapan dadi. politenessoffpolite"), and when there is a change ("assertivepoliteness Rejalaké awak dhéwé menehi ngomong nik wektu nggawe bener-bener tentang karo nganggo maneh sing nyelarané surat.', 'sk': 'Pisateljev slog ni odvisen samo od osebnih lastnosti, temveč tudi od njenega namena in duševnega stanja. V prispevku bomo pokazali, kako lahko različice iste pisalne naloge vodijo do merljivih razlik v slogu pisanja. Predstavljamo študijo primera, ki temelji na nalogi zaklopa zgodbe (Mostafazadeh et al., 2016a), kjer so označevalci dodelili podobne pisalne naloge z različnimi omejitvami: (1) pisanje celotne zgodbe, (2) dodajanje konca zgodbe za določen kontekst zgodbe in (3) dodajanje nepovezanega konca zgodbi. Pokazali smo, da preprost linearni klasifikator, ki ga obveščajo slogovne značilnosti, uspešno razlikuje med tremi primeri, ne da bi niti pogledal kontekst zgodbe. Poleg tega združevanje slogovnih značilnosti z napovedi jezikovnega modela doseže najsodobnejšo predstavo na izzivu zgodbe cloze. Naši rezultati kažejo, da lahko različni okvirji opravil dramatično vplivajo na način pisanja ljudi.', 'ha': "Salon wani marubuci bai ƙayyade ba fãce a kan wahalar mutane, kuma amma yana a kan halinta da ma'anarsa. Ga wannan takardan, Munã nũna jinsi variants na aikin rubũtun da ke iya ƙara wa rabo masu ƙayyade cikin salon da aka rubũta. Tuna halatar da wani matsayi a kan muhallin aikin kwanan rufe (Mostafazadah et al., 2016), a inda aka raba wa masu yin takarda wa littãfin da wasu wahalar daban-daban:(1) suna rubũtar wani lãbãri guda, (2) kuma Mu ƙara wani lãbãri mai ƙaranci ga muhallin da aka bã shi na lãbãri (3) kuma a ƙara wani littãfi na ƙara. Tuna nũna cewa wani mai fassari mai sauƙi na cikin linja da aka sanar da wasu misãlai na misãlai, yana iya iya ci nasara a tsakanin sakan uku, ko da kuma ba ka dũba mazaɓan lãbãrin ba. In addition, combining our stylistic features with language model predictions reaches state of the art performance on the story cloze challenge.  MatamayinMu sun nuna cewa misãlai na aiki dabam-dabam za ta yi amfani da haske kan hanyar mutane da ke rubũtãwa.", 'he': 'הסגנון של סופר תלוי לא רק על תכונות אישיות, אלא גם על כוונתה ומצבה הנפשי. בעיתון הזה, אנו מראים כיצד שונים של אותו משימה כתיבה יכולים להוביל להבדלים מדויקים בסגנון כתיבה. אנחנו מציגים מחקר תיקים מבוסס על משימת הסיפור סגור (Mostafazadeh et al., 2016a), שבו הצביעות קיבלו משימות כתיבה דומות עם מחסומים שונים: (1) לכתוב סיפור שלם, (2) להוסיף סיפור מסתיים לקונקסט סיפור מסוים, ו (3) להוסיף סוף לא תואם לסיפור. אנו מראים כי מסווג לינרי פשוט מודיע על ידי תכונות סטיליסטיות הוא מסוגל להבדיל בהצלחה בין שלושת המקרים, מבלי אפילו להסתכל על הקשר הסיפור. בנוסף, שילוב התחומים הסטיליסטיים שלנו עם ציפויים של דוגמני שפה מגיע למצב של ההופעה האמנותית באתגר הסיפורים. התוצאות שלנו מראות שמסגרות משימה שונות יכולות להשפיע דרמטית על הדרך בה אנשים כותבים.', 'bo': 'རྩོམ་པ་པོའི་བཟོ་རྣམ་གྲངས་དེ་མིན་ནི་སྒེར་གྱི་ཁྱད་ཆོས་དང་རྣམ་གནས་སྟངས་དང་གཅིག་པུ་མཐུད་མེད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་བྲིས་པའི་འཇུག་སྣོད་ཀྱི་བཟོ་རྣམ་པ་མཚུངས་ནི་ཇི་ལྟ ང་ཚོས་དུས་ཚོད་ལྟ་བུའི་གནད་དོན་གྱི་ལོ་རྒྱུས་ཀྱི་བྱ་ཚིག་རྟེན་ཏེ། ང་ཚོས་བཟོ་བྱེད་པའི་ཆེད་དུ་རྣམ་པ་ཞིག་གིས་དབྱེ་བ་ཅན་གྱི་སྟབས་བདེ་འཇགས་ངལ་ཆེན་པོ་ཞིག་ལ་གནད་འགན་གསུམ་ནང་དུ་གཏོ ད་དུང་བསྡད་ན། སྐད་རིགས་གཟུགས་རིས་དང་མིང་ཚོའི་བཟོ་རྣམ་གྲངས་ཀ་ཆ་མཉམ་མཉམ་དུ་གཏོང་བ་སྣང་གནས་སྟངས་གནས་ས ང་ཚོའི་འབྲས་བུ'}
{'en': 'Parsing for Grammatical Relations via Graph Merging', 'es': 'Análisis de relaciones gramaticales mediante la fusión de gráficos', 'pt': 'Análise de relações gramaticais por meio da mesclagem de gráficos', 'ar': 'الاعراب للعلاقات النحوية عن طريق دمج الرسم البياني', 'fr': 'Analyse des relations grammaticales via la fusion de graphes', 'zh': '图形并解析语法', 'ja': 'グラフマージによる文法関係の解析', 'hi': 'ग्राफ़ मर्जिंग के माध्यम से व्याकरणिक संबंधों के लिए पार्सिंग', 'ru': 'Синтаксический анализ грамматических отношений посредством слияния графиков', 'ga': 'Parsáil do Chaidreamh Gramadaí trí Chumasc Graif', 'ka': 'Name', 'el': 'Ανάλυση για γραμματικές σχέσεις μέσω συγχώνευσης γραφικών', 'hu': 'Nyelvtani kapcsolatok értelmezése grafikaösszevonással', 'it': 'Analisi delle relazioni grammaticali tramite fusione di grafici', 'kk': 'Графикалық біріктіру арқылы грамматикалық қатынастарын талдау', 'mk': 'Анализирање за граматски односи преку спојување на графици', 'lt': 'Gramatinių santykių analizavimas jungiant grafikus', 'ml': 'ഗ്രാഫ് കൂട്ടിചേര്\u200dക്കുന്നതിനായി ഗ്രാമാറ്റിക്കല്\u200d ബന്ധങ്ങള്\u200d', 'ms': 'Menghurai hubungan Grammatik melalui Gabungan Graf', 'mt': 'Analiżi għar-Relazzjonijiet Grammatiċi permezz tal-Għaqda tal-Grafiki', 'mn': 'График нэгтгэх аргаар грамматикийн харилцааны талдаа', 'ro': 'Analizarea relațiilor gramaticale prin fuzionarea graficilor', 'pl': 'Parsowanie relacji gramatycznych za pomocą łączenia wykresów', 'no': 'Tolking for Grammatiske relasjonar ved samlinga av grafikk', 'sr': 'Parsing for Grammatical Relations via Graph Merging', 'so': 'Parsing for xiriirka Grammatical via Graph', 'sv': 'Tolkning av grammatiska relationer via grafsammanfogning', 'si': 'Name', 'ta': 'Parsing for Grammatical Relations via Graph Merging', 'ur': 'گراف مرکزی کے ذریعہ گرامٹیکل رابطہ کے لئے پارس کیا جاتا ہے', 'vi': 'Chế độ phân tích các quan hệ biểu đồ qua bộ đồ', 'uz': 'Grafik ulanish uchun parsing', 'da': 'Tolkning af grammatiske relationer via graffletning', 'nl': 'Parsen voor grammaticale relaties via Grafiek samenvoegen', 'hr': 'Očitanje za Gramatične odnose preko priključenja grafika', 'bg': 'Анализиране на граматически отношения чрез сливане на графики', 'de': 'Analyse für grammatische Beziehungen mittels Graph Merging', 'fa': 'تحلیل رابطه\u200cهای گراماتیک از طریق مجموعه گراف', 'ko': '그림 통합에 기초한 문법 관계 분석', 'id': 'Menganalisis hubungan Grammatis melalui Gabungan Graf', 'tr': 'Grammatik baglaýyşlar', 'af': 'Name', 'sw': 'Unapambanua Uhusiano wa KiGrammatika kupitia Munganishaji wa Graph', 'sq': 'Duke analizuar marrëdhëniet Gramatike nëpërmjet bashkimit të grafikut', 'am': 'Parsing for Grammatical Relations via Graph Merging', 'hy': 'Գրամատիկ հարաբերությունների վերլուծությունը գրաֆիկի միավորման միջոցով', 'bn': 'গ্রাফ মার্গিং মাধ্যমে গ্রামাটিক্যাল সম্পর্কের জন্য পার্স করা হচ্ছে', 'ca': 'Analitzar les relacions gramàtiques mitjançant la fusió de gràfics', 'bs': 'Proglašavanje Gramatičnih odnosa preko sastanka grafika', 'cs': 'Analýza gramatických vztahů prostřednictvím sloučení grafů', 'et': 'Grammatiliste suhete parsimine graafikute ühendamise kaudu', 'fi': 'Kielioppisten suhteiden jäsentäminen graafien yhdistämisen kautta', 'az': 'Grafik birl…ôŇüdirm…ôsi vasit…ôsil…ô Gramatik ńįliŇükil…ôrin analizi', 'jv': 'structural navigation', 'sk': 'Razčlenitev slovničnih odnosov prek združevanja grafikov', 'he': 'מערכת יחסים גראמטיים באמצעות התמזגות Graph', 'ha': 'KCharselect unicode block name', 'bo': 'ཚད་རིས་བསྡོམས་པའི་ནང་དོན་འབྲེལ་བ་དང་བརྗོད་ནས་དབྱེ་སྟངས་བྱེད་པ'}
{'en': 'This paper is concerned with building deep grammatical relation (GR) analysis using data-driven approach. To deal with this problem, we propose graph merging, a new perspective, for building flexible dependency graphs : Constructing complex graphs via constructing simple subgraphs. We discuss two key problems in this perspective : (1) how to decompose a complex graph into simple subgraphs, and (2) how to combine subgraphs into a coherent complex graph. Experiments demonstrate the effectiveness of graph merging. Our parser reaches state-of-the-art performance and is significantly better than two transition-based parsers.', 'ar': 'تهتم هذه الورقة ببناء تحليل العلاقة النحوية العميقة (GR) باستخدام نهج يعتمد على البيانات. للتعامل مع هذه المشكلة ، نقترح دمج الرسم البياني ، منظور جديد ، لبناء الرسوم البيانية التبعية المرنة: إنشاء الرسوم البيانية المعقدة عن طريق إنشاء الرسوم البيانية الفرعية البسيطة. نناقش مشكلتين رئيسيتين في هذا المنظور: (1) كيفية تحليل الرسم البياني المعقد إلى رسوم بيانية فرعية بسيطة ، و (2) كيفية دمج الرسوم البيانية الفرعية في رسم بياني معقد متماسك. التجارب تثبت فعالية دمج الرسم البياني. يصل المحلل اللغوي الخاص بنا إلى أحدث أداء وأفضل بكثير من المحلل اللغوي القائم على الانتقال.', 'es': 'Este artículo se ocupa de construir un análisis profundo de relaciones gramaticales (GR) utilizando un enfoque basado en datos. Para hacer frente a este problema, proponemos la fusión de gráficos, una nueva perspectiva, para crear gráficos de dependencia flexibles: Construir gráficos complejos mediante la construcción de subgrafos simples. Discutimos dos problemas clave en esta perspectiva: (1) cómo descomponer un gráfico complejo en subgráficos simples y (2) cómo combinar subgráficos en un gráfico complejo coherente. Los experimentos demuestran la eficacia de la fusión de gráficos. Nuestro analizador alcanza un rendimiento de vanguardia y es significativamente mejor que dos analizadores basados en transiciones.', 'fr': "Cet article s'intéresse à la construction d'une analyse de relation grammaticale (GR) profonde à l'aide d'une approche axée sur les données. Pour résoudre ce problème, nous proposons la fusion de graphes, une nouvelle perspective, pour construire des graphes de dépendance flexibles\xa0: Construire des graphes complexes via la construction de sous-graphes simples. Dans cette perspective, nous discutons de deux problèmes clés\xa0: (1) comment décomposer un graphe complexe en sous-graphes simples, et (2) comment combiner des sous-graphes en un graphe complexe cohérent. Les expériences démontrent l'efficacité de la fusion de graphes. Notre analyseur atteint des performances de pointe et est nettement meilleur que deux analyseurs basés sur la transition.", 'pt': 'Este artigo está preocupado com a construção de uma análise profunda de relações gramaticais (GR) usando uma abordagem orientada a dados. Para lidar com este problema, propomos a fusão de grafos, uma nova perspectiva para a construção de grafos de dependência flexíveis: Construindo grafos complexos através da construção de subgrafos simples. Discutimos dois problemas principais nesta perspectiva: (1) como decompor um grafo complexo em subgrafos simples e (2) como combinar subgrafos em um grafo complexo coerente. Experimentos demonstram a eficácia da mesclagem de gráficos. Nosso analisador atinge desempenho de última geração e é significativamente melhor do que dois analisadores baseados em transição.', 'ja': '本論文は、データ駆動型アプローチを用いた深層文法関係（ GR ）分析の構築に関するものである。この問題に対処するために、柔軟な依存グラフを構築するための新しい視点であるグラフマージを提案します。単純なサブグラフを構築することで、複雑なグラフを構築します。この観点では、(1)複雑なグラフを単純なサブグラフに分解する方法と、(2)サブグラフを一貫した複雑なグラフに結合する方法の2つの重要な問題について説明します。実験は、グラフマージの有効性を示している。当社のパーサーは最先端のパフォーマンスに達し、2つのトランジションベースのパーサーよりも大幅に優れています。', 'zh': '本文关注者,用数驱之法立深度语法(GR)析也。 为此图并,一新视角,以构生灵之图,以结简子图以造杂图。 议二关键问题:(1)以杂图解为简子图,及(2)何以将子图组合成贯之复图。 实验验图并之有效性。 吾解析器至先进之性,而显优于两解析器。', 'hi': 'यह पेपर डेटा-संचालित दृष्टिकोण का उपयोग करके गहरे व्याकरणिक संबंध (जीआर) विश्लेषण के निर्माण से संबंधित है। इस समस्या से निपटने के लिए, हम ग्राफ विलय का प्रस्ताव करते हैं, लचीला निर्भरता रेखांकन बनाने के लिए एक नया परिप्रेक्ष्य: सरल सबग्राफ के निर्माण के माध्यम से जटिल ग्राफ का निर्माण। हम इस परिप्रेक्ष्य में दो प्रमुख समस्याओं पर चर्चा करते हैं: (1) एक जटिल ग्राफ को सरल उपलेखों में कैसे विघटित किया जाए, और (2) एक सुसंगत जटिल ग्राफ में सबग्राफ को कैसे संयोजित किया जाए। प्रयोग ग्राफ विलय की प्रभावशीलता को प्रदर्शित करते हैं। हमारा पार्सर अत्याधुनिक प्रदर्शन तक पहुंचता है और दो संक्रमण-आधारित पार्सर की तुलना में काफी बेहतर है।', 'ru': 'Настоящий документ посвящен построению глубокого грамматического анализа (ГР) с использованием подхода, основанного на данных. Для решения этой задачи мы предлагаем слияние графов, новую перспективу, для построения гибких графиков зависимостей: построение сложных графов посредством построения простых подграфов. Мы обсуждаем две ключевые проблемы в этой перспективе: (1) как разложить сложный граф на простые подграфы, и (2) как объединить подграфы в когерентный сложный граф. Эксперименты демонстрируют эффективность слияния графов. Наш синтаксический анализатор достигает самой высокой производительности и значительно лучше, чем два синтаксических анализатора на основе перехода.', 'ga': 'Baineann an páipéar seo le hanailís dhomhain-chaidrimh ghramadaí (GR) a fhorbairt trí úsáid a bhaint as cur chuige bunaithe ar shonraí. Chun déileáil leis an bhfadhb seo, molaimid cumasc graf, peirspictíocht nua, chun graif spleáchais sholúbtha a thógáil: Graif chasta a thógáil trí fhoghraif shimplí a thógáil. Pléimid dhá phríomhfhadhb sa pheirspictíocht seo: (1) conas graf casta a dhianscaoileadh ina fhoghraif shimplí, agus (2) conas fograif a chomhcheangal i ngraf coimpléascach comhleanúnach. Léiríonn turgnaimh éifeachtacht an chumaisc ghraif. Sroicheann ár parsálaí feidhmíocht úrscothach agus tá sé i bhfad níos fearr ná dhá pharsálaí tras-bhunaithe.', 'el': 'Η παρούσα εργασία ασχολείται με την ανάπτυξη ανάλυσης βαθιάς γραμματικής σχέσης (GR) χρησιμοποιώντας προσέγγιση βασισμένη σε δεδομένα. Για να αντιμετωπιστεί αυτό το πρόβλημα, προτείνουμε τη συγχώνευση γραφημάτων, μια νέα προοπτική, για την κατασκευή ευέλικτων γραφημάτων εξάρτησης: Κατασκευή σύνθετων γραφημάτων μέσω της κατασκευής απλών υπογραφημάτων. Σε αυτή την προοπτική συζητάμε δύο βασικά προβλήματα: (1) πώς να αποσυντίσουμε ένα σύνθετο γράφημα σε απλά υπογραφήματα, και (2) πώς να συνδυάσουμε υπογραφήματα σε ένα συνεκτικό σύνθετο γράφημα. Τα πειράματα καταδεικνύουν την αποτελεσματικότητα της συγχώνευσης γραφήματος. Ο αναλυτής μας επιτυγχάνει επιδόσεις τελευταίας τεχνολογίας και είναι σημαντικά καλύτερος από δύο αναλυτές με βάση τη μετάβαση.', 'hu': 'Ez a tanulmány adatközpontú megközelítéssel foglalkozik a mély nyelvtani kapcsolatok (GR) elemzésével. A probléma megoldásához egy új perspektívát javasoljuk a gráfok összevonására, amely rugalmas függőségi grafikonok építésére szolgál: komplex grafikonok építése egyszerű algráfok készítésével. Ebben a perspektívában két kulcsfontosságú problémát vitatunk meg: (1) hogyan bontsunk le egy komplex gráfot egyszerű részgráfiára, és (2) hogyan kombináljuk az algráfiákat egy koherens komplex gráfiára. A kísérletek bizonyítják a grafikonok egyesítésének hatékonyságát. Elemzőnk eléri a legmodernebb teljesítményt és jelentősen jobb, mint két átmeneti alapú elemző.', 'ka': 'ეს წიგნი დარწმუნდება, რომელიც განახლებული მონაცემების გამოყენებით გრამიმატური შესახებ (GR) ანალიზაციის შექმნა. ამ პრობლემას გადავუდგინოთ, ჩვენ ახალი პერსპექტიფიკაციის შესაძლებელად დავწყებთ: კომპლექციური გრაფიკების შესაქმნა საუკეთესო სპექტიკების შესაძლებელად და 1) როგორ კომპლექსიკური გრაფიკაში გამოყენება და (2) როგორ გამოყენება სპექსიკური გრაფიკაში. ექსპერიმენტები გამოჩვენებენ გრაფის ერთადერთობის ეფექტიურობა. ჩვენი პანუზერი მიიღება სახელსაწყისი კეთესტაციას და მნიშვნელოვანად უკეთესია, ვიდრე ორი პანუზიციის დაბათი პანუზერი.', 'it': "Questo articolo si occupa di costruire un'analisi approfondita delle relazioni grammaticali (GR) utilizzando un approccio basato sui dati. Per affrontare questo problema, proponiamo la fusione dei grafici, una nuova prospettiva, per costruire grafici di dipendenza flessibili: Costruire grafici complessi attraverso la costruzione di sottografie semplici. Discutiamo due problemi chiave in questa prospettiva: (1) come scomporre un grafico complesso in sottografie semplici, e (2) come combinare sottografie in un grafico complesso coerente. Gli esperimenti dimostrano l'efficacia della fusione dei grafici. Il nostro parser raggiunge prestazioni all'avanguardia ed è significativamente migliore di due parser basati sulla transizione.", 'kk': 'Бұл қағаз деректерді бағыттау көмегімен грамматикалық қатынасын (GR) анализ құру үшін байланысты. Бұл мәселеге шешу үшін, графиктерді біріктіру, жаңа перспектива, гибсиялық тәуелдік графиктерді құру үшін: қарапайым субграфиктерді құру арқылы комплексті графиктерді құру. Біз осы перспективде екі кілт мәселелерді талқылаймыз: (1) комплексті график қарапайым бөлшектерге қалай бөлшектеу, және (2) субграфиктерді координативті комплексті графикаға қалай бөлшект Тәжірибелер графиктерді біріктіру мүмкіндігін көрсетеді. Біздің парзеріміз өзгерту күйіне жеткізеді және екі ауыстыру күйіне негізделген парзерінен ең жақсы.', 'mk': 'Овој документ е загрижен за изградба на длабока граматичка однос (GR) анализа користејќи пристап врз основа на податоци. To deal with this problem, we propose graph merging, a new perspective, for building flexible dependency graphs: Constructing complex graphs via constructing simple subgraphs.  Разговараме за два клучни проблеми во оваа перспектива: (1) како да се раздели комплексен граф во едноставни подграфи, и (2) како да се комбинираат подграфите во кохерентен комплексен граф. Експериментите ја покажуваат ефикасноста на спојувањето на графикот. Нашиот анализатор достигнува најдобра изведба и е значително подобар од двата анализатори базирани на транзиција.', 'lt': 'Šis dokumentas susijęs su išsamių gramatinių santykių (GR) analizės kūrimu naudojant duomenimis pagrįstą metodą. Siekiant išspręsti šią problem ą, siūlome susijungti grafiką, naują perspektyvą, kuriant lanksčias priklausomybės grafikas: kurti sudėtingus grafikus, kuriant paprastus pografus. Šiuo požiūriu diskutuojame apie dvi pagrindines problemas: 1) kaip suskirstyti sudėtingą grafiką į paprastus pografus ir 2) kaip sujungti pografus į nuoseklų sudėtingą grafiką. Eksperimentai rodo grafikų susijungimo veiksmingumą. Mūsų analizatorius pasiekia pažangiausius rezultatus ir yra gerokai geresnis nei du pereinamojo laikotarpio analizatoriai.', 'ms': 'Kertas ini berkaitan dengan membina analisis hubungan grammatik (GR) dalam menggunakan pendekatan yang dipandu data. Untuk menangani masalah ini, kami cadangkan penggabungan graf, perspektif baru, untuk membina graf dependensi fleksibel: membina graf kompleks melalui membina subgraf sederhana. Kita membincangkan dua masalah utama dalam perspektif ini: (1) bagaimana untuk memusnahkan graf kompleks ke dalam subgraf sederhana, dan (2) bagaimana untuk menggabungkan subgraf ke dalam graf kompleks yang konsisten. Eksperimen menunjukkan kegunaan penggabungan graf. Penganalis kami mencapai prestasi terbaik dan jauh lebih baik daripada dua penganalis berasaskan transisi.', 'ml': 'ഡേറ്റാ ഓടിച്ചുകൊണ്ട് ആഴത്തെ ഗ്രാമാട്ടിക്കല്\u200d ബന്ധം (ജിആര്\u200d) വിശ്വാസം നിര്\u200dമ്മിക്കുന്നതിനെപ്പറ ഈ പ്രശ്നത്തെക്കുറിച്ച് കൈകാര്യം ചെയ്യാന്\u200d, നമ്മള്\u200d ഒരു പുതിയ കാഴ്ച, ഫ്ലാക്സിബിള്\u200d ആശ്രയിക്കുന്ന ഗ്രാഫുകള്\u200d പണിയുന്നതിനായി ഗ ഈ കാഴ്ചപ്പാടില്\u200d നമ്മള്\u200d രണ്ടു പ്രശ്നങ്ങളെക്കുറിച്ച് സംസാരിക്കുന്നു: (1) എങ്ങനെയാണ് ഒരു കുഴപ്പമുള്ള ഗ്രാഫ് സാധാരണ സബ്ഗ്രാഫിലേക്ക്  പരീക്ഷണങ്ങള്\u200d ഗ്രാഫ് കൂട്ടിചേര്\u200dക്കുന്നതിന്റെ ഫലം കാണിക്കുന്നു. നമ്മുടെ പരാജയപ്രകാരം കാര്യങ്ങളുടെ സ്ഥിതിയിലേക്ക് എത്തുന്നു. രണ്ട് ട്രാന്\u200dസിങ്ങ് അടിസ്ഥാനമായ പാര്\u200dസര്\u200dസിന', 'mt': "Dan id-dokument huwa kkonċernat bil-bini ta’ analiżi grammatika profonda (GR) bl-użu ta’ approċċ immexxi mid-dejta. Biex nindirizzaw din il-problem a, nipproponu l-amalgamazzjoni tal-graffi, perspettiva ġdida, għall-bini ta’ graffi flessibbli ta’ dipendenza: Il-bini ta’ graffi kumplessi permezz tal-bini ta’ subgraffi sempliċi. Aħna niddiskutu żewġ problemi ewlenin f'din il-perspettiva: (1) kif nistgħu niddekomponu graff kumpless f'sottografi sempliċi, u (2) kif nistgħu nikkombinaw sottografi f'graff kumpless koerenti. Experiments demonstrate the effectiveness of graph merging.  Il-parser tagħna jilħaq il-prestazzjoni l-aktar avvanzata u huwa ferm aħjar minn żewġ parser ibbażati fuq it-tranżizzjoni.", 'mn': 'Энэ цаас нь өгөгдлийн дамжуулагдсан аргыг ашиглан гүн грамматикийн харилцаа (GR) шинжилгээ бүтээж байгаа юм. Энэ асуудлыг бодохын тулд бид график цуглуулах, шинэ асуудлыг шинээр үзүүлэх, гишүүмжтэй хамааралтай график бүтээхэд: энгийн дүрсийг бүтээх аргаар комплекс график бүтээх. Бид энэ тохиолдолд хоёр чухал асуудлыг ярилцаж байна: (1) комплекс график хэрхэн энгийн дүрсийн зурагт хуваагдах бөгөөд (2) зурагтуудыг хоорондоо холбоотой комплекс график руу холбоотой. График цуглуулалтын үр дүнг харуулдаг. Бидний судлаач урлагийн үйл ажиллагаанд хүртэл хоёр шилжилт суурилсан судлаачидаас илүү сайн байна.', 'no': 'Denne papiret er bekymret på å bygge dyp grammatisk relasjon (GR) med datadrivt tilnærming. For å løyse denne problemen, foreslår vi å bygge fleksibel avhengighetsgrafen for å samlinga med grafen. Konstruere komplekse grafen ved å konstruere enkle undergrafen. Vi diskuterer to nøkkelproblemer i denne perspektiven: (1) korleis å dekomprimera eit kompleks graf i enkle undergraf, og (2) korleis undergraf skal kombinererast i eit kompleks graf. Eksperimentar viser effektiviteten for å samla grafen. Tolkaren vårt når kunsthandlinga og er betydelig bedre enn to overgangsbaserte tolkar.', 'ro': 'Această lucrare se ocupă de construirea unei analize profunde a relațiilor gramaticale (GR) utilizând o abordare bazată pe date. Pentru a rezolva această problemă, propunem fuzionarea graficului, o nouă perspectivă, pentru construirea graficelor flexibile de dependență: Construirea graficelor complexe prin construirea unor subgrafii simple. Discutăm două probleme cheie în această perspectivă: (1) cum să descompunem un grafic complex în subgrafii simple și (2) cum să combinăm subgrafiile într-un grafic complex coerent. Experimentele demonstrează eficacitatea fuzionării grafice. Parserul nostru atinge performanțe de ultimă generație și este semnificativ mai bun decât două parsere bazate pe tranziție.', 'pl': 'Niniejszy artykuł zajmuje się budowaniem analizy głębokich relacji gramatycznych (GR) z wykorzystaniem podejścia opartego na danych. Aby poradzić sobie z tym problemem, proponujemy łączenie wykresów, nową perspektywę budowy elastycznych wykresów zależności: Budowanie złożonych wykresów poprzez konstruowanie prostych podgrafów. Omówimy dwa kluczowe problemy w tej perspektywie: (1) jak rozkładać wykres złożony na proste podgrafy i (2) jak łączyć podgrafy w spójny wykres złożony. Eksperymenty pokazują skuteczność łączenia wykresów. Nasz parser osiąga najnowocześniejszą wydajność i jest znacznie lepszy niż dwa parsery oparte na przejściu.', 'sr': 'Ovaj papir se brine o izgradnji dubokog gramatičkog odnosa (GR) analize sa podacima. Za rješavanje ovog problem a predlažemo skupljanje grafika, novu perspektivu, za izgradnju fleksibilnih grafika ovisnosti: izgradnju kompleksnih grafika putem konstrukcije jednostavnih podgrafa. Razgovaramo o dva ključna problema u ovoj perspektivi: 1) kako da rasključimo kompleksan grafik u jednostavne podgrafne i 2) kako da kombiniramo podgrafne u sasvim kompleksnom grafiku. Eksperimenti pokazuju učinkovitost skupljanja grafika. Naš analitičar postiže predstavu umjetnosti i značajno je bolji od dva razmatrača na temelju tranzicije.', 'si': 'මේ පැත්තේ ගොඩක් ග්\u200dරමාත්මක සම්බන්ධය (GR) විශ්ලේෂණය සඳහා බලාපොරොත්තු වෙනවා දත්ත ප්\u200dරවේශනය ස මේ ප්\u200dරශ්නය සම්බන්ධ වෙනුවෙන්, අපි ග්\u200dරාෆ් එක්ගන්න, අලුත් ප්\u200dරශ්නයක්, විශේෂ විශේෂතාවක් නිර්මාණය කරනවා: සාම අපි මේ ප්\u200dරශ්නයේ යතුරු ප්\u200dරශ්නයක් දෙකක් කතා කරනවා: (1) කොහොමද ප්\u200dරශ්නයක් සාමාන්\u200dය සබ්ලාග්රාෆ් වලට සංවිධානය කරන්නේ, සබ පරීක්ෂණය පෙන්වන්නේ ග්\u200dරාෆ් එක්කම් කරන්නේ ප්\u200dරශ්නයක්. අපේ පරීක්ෂකයා ක්\u200dරියාත්මක විදිහට පැමිණි වෙනවා ඒ වගේම වාර්ථානය දෙකට වඩා හොඳයි.', 'so': 'Qoraalkan waxaa ku saabsan dhisidda xiriirka aad u dheer ee grammatika (GR) baaritaanka isticmaalka qaababka danaha lagu wado. To deal with this problem, we propose graph merging, a new perspective, for building flexible dependency graphs: Constructing complex graphs via constructing simple subgraphs.  Waxaannu ka sheekaynaynaa laba dhibaatooyin oo muhiim ah xaggan: (1) Sidaan u koobi karno sawir adag, sidoo kale (2) si aan subgrafyada ugu soo wadano sawir adag. Imtixaanka waxay muujiyaan waxyaabaha isugu xiriira xarunta. Pararkeenu wuxuu gaadhaa habka farshaxanka farshaxanka ah, waxaana aad uga wanaagsan labo baaritaano lagu beddelayo.', 'sv': 'Denna uppsats handlar om att bygga djupa grammatiska relationsanalys (GR) med hjälp av datadriven ansats. För att hantera detta problem föreslår vi graffusion, ett nytt perspektiv, för att bygga flexibla beroendegrafer: Konstruera komplexa grafer genom att bygga enkla undergrafer. Vi diskuterar två nyckelproblem i detta perspektiv: (1) hur man sönderdelar en komplex graf till enkla subgrafer, och (2) hur man kombinerar subgrafer till en sammanhängande komplex graf. Experiment visar hur effektiv grafsammanfogningen är. Vår parser uppnår state-of-the-art prestanda och är betydligt bättre än två övergångsbaserade parsers.', 'ta': 'இந்த தாள் தரவு இயக்கும் செயல்பாட்டை பயன்படுத்தி ஆழமான கிராமாட்டிக் உறவு (GR) ஆராய்ச்சியை உருவாக்குவத இந்த பிரச்சனையை நிர்வகிக்க, நாம் வரைப்படத்தை ஒன்றாகச் சேர்க்க, புதிய பார்வையில், புதிய சார்ந்த சார்ந்த சிறிய வரைபடங்களை உருவா இந்த காட்சியில் இரண்டு முக்கிய பிரச்சனைகளை விவாதம் செய்கிறோம்: (1) சிக்கலான வரைபடத்தை எளிய துணை வரைபடங்களாக குறைக்க வேண்டும், மற்றும் (2 வரைபடத்தை ஒன்றிணைப்பதின் விளைவை காட்டுகிறது. நம்முடைய பரிசுத்துவர் கலை செயல்பாட்டின் நிலையை அடையும் மற்றும் இரண்டு மாற்று அடிப்படையில் சார்ந்த பார்ச', 'ur': 'یہ کاغذ ڈیٹا چلنے والی طریقہ کے مطابق عمیق گراماتیکی ارتباط (GR) کا تحلیل بنانے کے بارے میں مشغول ہے. اس مشکل کے بارے میں ہم گراف جمع کرنے کے لئے نئی نظر سے پیش کریں گے، مضبوط اعتمادی گراف بنانے کے لئے: سادھے سپگراف بنانے کے ذریعہ پیچیدہ گراف بنانے کے لئے. ہم اس نظر میں دو کلید مسئلہ کی بحث کرتے ہیں: (1) کس طرح ایک پیچیدہ گراف کو ساده سپگراف میں ڈھونڈ کریں، اور (2) سپگراف کو کس طرح ایک پیچیدہ پیچیدہ گراف میں جمع کریں۔ آزمائش گراف جمع کرنے کی فعالیت دکھاتے ہیں۔ ہمارا پارچر آهنت کی عملکرد تک پہنچ جاتا ہے اور دو ٹرنج کی بنیادی پارچر سے بہتر ہے۔', 'vi': 'Bài báo này nhằm vào việc xây dựng quan hệ ngôn ngữ sâu rộng (GR) phân tích bằng phương pháp dựa trên dữ liệu. Để giải quyết vấn đề này, chúng tôi đề nghị nhập đồ thị, một viễn cảnh mới, để xây dựng biểu đồ phụ thuộc linh hoạt: xây dựng các biểu đồ phức tạp bằng cách tạo ra các rạp chiếu đơn giản. Chúng ta thảo luận hai vấn đề quan trọng trong quan điểm này: 1) cách phân hủy đồ thị phức tạp thành các rạp chiếu đơn giản, và (2) cách kết hợp điện tử thành đồ thị phức tạp. Thí nghiệm cho thấy hiệu quả của việc ghép đồ thị. Vị cha xứ của chúng ta đạt đến trình độ tối tân và tốt hơn nhiều so với hai nhà phân tách.', 'uz': "Ushbu qogʻoz maʼlumot drayveri usuli yordamida murakkab grammatikal aloqalarni (GR) aniqlashga ega. Bu muammo bilan boshqarish uchun, biz yangi shaklni birlashtirish, fleksiz ishlatuvchi grafiklarni yaratish uchun namoyish qilamiz: oddiy subgrafiklarni yaratish orqali murakkab grafikni yaratish. Biz bu ko'rinida ikkita muhim muammolar bilan javob beramiz: (1) oddiy subgrafga murakkab grafikni ajratish va (2) subgraflarga qanday birlashtirish mumkin murakkab grafikga. Experiments demonstrate the effectiveness of graph merging.  Bizning ajratishimiz haqida o'zgarishga ega bo'ladi va bu ikkita transition asosiy parserka juda juda yaxshi.", 'bg': 'Настоящата статия се занимава с изграждане на анализ на дълбоките граматически взаимоотношения (ГР), използвайки подход, ориентиран към данни. За да се справим с този проблем, предлагаме сливане на графики, нова перспектива, за изграждане на гъвкави графики на зависимост: Изграждане на сложни графики чрез изграждане на прости подграфи. Обсъждаме два основни проблема в тази перспектива: (1) как да разложим сложна графика на прости подграфи и (2) как да комбинираме подграфи в кохерентна сложна графика. Експериментите показват ефективността на сливането на графики. Нашият анализатор достига най-съвременно представяне и е значително по-добър от два анализатора, базирани на преход.', 'hr': 'Ovaj papir se brine o izgradnji dubokog gramatičkog odnosa (GR) analize s podacima. Za rješavanje ovog problem a predlažemo skupljanje grafika, novu perspektivu za izgradnju fleksibilnih grafika ovisnosti: izgradnju kompleksnih grafika putem konstrukcije jednostavnih podgrafa. Razgovaramo o dva ključna problema u ovoj perspektivi: (1) kako rasporediti kompleksni graf u jednostavne podgrafne i (2) kako kombinirati podgrafne u sasvim kompleksni graf. Eksperimenti pokazuju učinkovitost skupljanja grafika. Naš analitičar postiže predstavu umjetnosti i značajno je bolji od dva razmatrača na temelju prijenosa.', 'da': 'Denne artikel beskæftiger sig med at opbygge dyb grammatisk relation (GR) analyse ved hjælp af data-drevet tilgang. For at løse dette problem foreslår vi graffusion, et nyt perspektiv, til opbygning af fleksible afhængighedsgrafer: Konstruktion af komplekse grafer ved at konstruere enkle undergrafer. Vi diskuterer to centrale problemer i dette perspektiv: (1) hvordan man nedbryder en kompleks graf til enkle subgrafer, og (2) hvordan man kombinerer subgrafer til en sammenhængende kompleks graf. Eksperimenter viser effektiviteten af graffusion. Vores parser opnår state-of-the-art ydeevne og er betydeligt bedre end to overgangsbaserede parsere.', 'de': 'Diese Arbeit befasst sich mit dem Aufbau von Deep Grammatical Relations (GR)-Analysen mit datengetriebenem Ansatz. Um dieses Problem zu lösen, schlagen wir Graph Merging vor, eine neue Perspektive, für den Aufbau flexibler Abhängigkeitsdiagramme: Konstruieren komplexer Graphen durch Konstruieren einfacher Subgraphen. Wir diskutieren zwei Schlüsselprobleme in dieser Perspektive: (1) wie man einen komplexen Graphen in einfache Subgraphen zerlegt und (2) wie man Subgraphen zu einem kohärenten komplexen Graphen kombiniert. Experimente demonstrieren die Effektivität der Graph Merging. Unser Parser erreicht State-of-the-Art Performance und ist deutlich besser als zwei transition-basierte Parser.', 'nl': 'Deze paper gaat over het bouwen van diepe grammaticale relatie (GR) analyse met behulp van data-driven benadering. Om dit probleem aan te pakken, stellen we grafiekmerging voor, een nieuw perspectief, voor het bouwen van flexibele afhankelijkheidsgrafieken: complexe grafieken construeren via het construeren van eenvoudige subgrafieken. We bespreken twee belangrijke problemen in dit perspectief: (1) hoe een complexe grafiek in eenvoudige subgrafieken te ontbinden, en (2) hoe subgrafieken te combineren tot een coherente complexe grafiek. Experimenten tonen de effectiviteit van het samenvoegen van grafieken aan. Onze parser bereikt state-of-the-art prestaties en is aanzienlijk beter dan twee transitie-gebaseerde parsers.', 'ko': '본고는 데이터 구동 방법을 이용하여 심층 문법 관계(GR) 분석을 구축하는 데 목적을 두고 있다.이 문제를 해결하기 위해 우리는 새로운 시각인 도합병을 통해 유연한 의존도를 구축했다. 간단한 서브맵을 구성함으로써 복잡한 그림을 구성하는 것이다.우리는 이 각도에서 두 가지 관건적인 문제를 토론했다. (1) 복잡한 그림을 어떻게 간단한 자도로 분해하는가, (2) 어떻게 자도를 하나의 일관된 복잡한 그림으로 조합하는가.실험은 도합병의 유효성을 증명하였다.우리의 해석기는 가장 선진적인 성능에 이르렀으며 전환을 바탕으로 하는 두 개의 해석기보다 현저히 우수하다.', 'id': 'Kertas ini berkaitan dengan membangun hubungan grammatik dalam (GR) analisis menggunakan pendekatan yang didorong data. Untuk menghadapi masalah ini, kami mengusulkan bergabung grafik, perspektif baru, untuk membangun grafik ketergantungan fleksibel: membangun grafik kompleks melalui membangun subgrafik sederhana. Kita mendiskusikan dua masalah kunci dalam perspektif ini: (1) bagaimana untuk memutuskan graf kompleks menjadi subgraf sederhana, dan (2) bagaimana untuk menggabungkan subgraf menjadi graf kompleks yang konsisten. Eksperimen menunjukkan efektivitas bergabung grafik. Penganalis kami mencapai prestasi terbaik dan jauh lebih baik dari dua penganalis berdasarkan transisi.', 'sw': 'Gazeti hili linahusiana na kujenga uchambuzi wa kina wa mahusiano (GR) kwa kutumia mbinu za takwimu zinazoendeshwa. To deal with this problem, we propose graph merging, a new perspective, for building flexible dependency graphs: Constructing complex graphs via constructing simple subgraphs.  Tunajojiana na matatizo mawili ya msingi katika mtazamo huu: (1) jinsi ya kupunguza picha tatizo katika viwanja rahisi, na (2) jinsi ya kuunganisha viungo vya ubora katika picha ya tatizo. Majaribio yanaonyesha ufanisi wa ushirikiano wa picha. Wachambuzi wetu wanafikia hali ya mambo ya sanaa na ni bora zaidi kuliko mabunge mawili yanayotumika na michango.', 'sq': 'Ky dokument është i shqetësuar me ndërtimin e analizës së lidhjes gramatike të thellë (GR) duke përdorur metodën e drejtuar nga të dhënat. To deal with this problem, we propose graph merging, a new perspective, for building flexible dependency graphs: Constructing complex graphs via constructing simple subgraphs.  Ne diskutojmë dy probleme kyçe në këtë perspektivë: (1) si të shkëputemi një grafik kompleks në subgrafi të thjeshta, dhe (2) si të kombinojmë subgrafitë në një grafik kompleks koherent. Eksperimentet tregojnë efektshmërinë e bashkimit të grafikut. Analizatori ynë arrin shfaqjen më të lartë dhe është më i mirë se dy analizues me bazë tranzicioni.', 'am': 'ይህ ገጽ የዳታ-driven ሥርዓት በመጠቀም ጥልቅ የgrammatical ግንኙነት (GR) ማስታወቂያውን ለመሥራት ነው፡፡ ይህንን ጉዳይ ለመቀናቀል፣ አዲስ ጉዳይ፣ አዲስ የግንኙነት ግንኙነትን ለመሥራት እናስጀምራለን፡፡ ሁለትን የቁልፎች ጉዳዮች እናስነጋግረዋለን::1) የተቃውሞ ቀለም ወደ ቀላል ጥያቄ መስኮቶች እና (2) ደብዳቤዎችን እንዴት ለመቀላቀል እናስባለን፡፡ ፈተናዎች የgraph ማቀናቀል ጥቅማቸውን ያሳያል፡፡ ተሳታፊያችን የ-የ የዓላማ ሥርዓት ግንኙነት አግኝቷል፡፡', 'hy': "Այս աշխատանքը մտահոգված է խորը գրամատիկ հարաբերությունների (GR) վերլուծությամբ, օգտագործելով տվյալների հիմնված մոտեցումը: Այս խնդիրը լուծելու համար մենք առաջարկում ենք գրաֆիկների միավորումը, նոր տեսանկյուն, ճկուն կախվածության գրաֆիկների կառուցվածքը' բարդ գրաֆիկների կառուցվածքը պարզ ենթագրաֆիկների կառուցվածքով: Մենք քննարկում ենք երկու կարևոր խնդիր այս տեսանկյունից. 1) ինչպես բաժանել բարդ գծագրը պարզ ենթագծագրերի, և 2) ինչպես համադրել ենթագծագրերը համապատասխան բարդ գծագրի: Փորձերը ցույց են տալիս գծագրի միավորման արդյունավետությունը: Մեր խմբագրիչը հասնում է ամենաբարձր արդյունքներին և շատ ավելի լավ է, քան երկու հաղորդակցման հիմնված խմբագրիչները:", 'tr': 'Bu kagyz gramatik baglaýyşyň (GR) çykyşynyň (data-driven approach) çykyşyny ulanan çykyş bilen aladalanýar. Bu mesele çözmek üçin grafikiň birleşmesini, täze bir perspektiv, fleksibil baglanylyk grafiklerini gurmak üçin teklip edip otyrys: basit grafikler guralýar. Bu perspektivde iki esasy mesele çözýäris: (1) bir kompleks grafyny basit grafiklere nädip birleştirmelidigini we (2) suratlaryny kohereket kompleks grafyň içine nähili birleştirmelidigini. Denminatlar grafik bileleşiginiň etkinliýetini görkezýär. Biziň çykyşymyz sungatyň durumyna ýetişýär we iki geçişikden has gowydyr.', 'az': 'Bu kańüńĪt, m…ôlumatlar t…ôr…ôfind…ôn istifad…ô edil…ôn m…ôlumatlar vasit…ôsil…ô d…ôrin gramatik …ôlaq…ôl…ôri (GR) analizi inŇüa etm…ôkd…ôn endirilir. Bu probleml…ô √ß…ôkilm…ôk √ľ√ß√ľn grafik birl…ôŇüdirm…ôyi, yeni bir perspektiv, fleksibil bańüńĪmlńĪlńĪq grafikl…ôrini inŇüa etm…ôk √ľ√ß√ľn t…ôklif edirik: basit subgraflar inŇüa ed…ôr…ôk kompleks grafikl…ôri inŇüa edirik. Biz bu perspektivd…ô iki a √ßar problemi danńĪŇüńĪrńĪq: (1) kompleks grafńĪ basit subgraflara nec…ô √ß…ôkilm…ôyi v…ô (2) subgraflarńĪ birl…ôŇüdirm…ôki m√ľnasib…ôtli bir kompleks grafńĪna. √áalńĪŇüńĪmlar grafik birl…ôŇüdirilm…ôsinin etkinlińüini g√∂st…ôrir. Bizim par√ßacńĪmńĪz sanat performansńĪna √ßatdńĪ v…ô iki d…ôyiŇüiklik d…ôyiŇüiklikd…ôn daha yaxŇüńĪdńĪr.', 'fa': 'این کاغذ نگران ساختن ارتباط گراماتیک عمیق (GR) با استفاده از روش داده\u200cها است. برای حل این مشکل، ما پیشنهاد گراف جمع کردن، یک نگاه جدید برای ساختن گراف بستگی قابل flexible: ساختن گراف پیچیده از طریق ساختن زیرگراف ساده است. ما در این نگاه دو مشکل کلیدی در مورد بحث می\u200cکنیم: (۱) چگونه یک گراف پیچیده را به زیرگراف\u200cهای ساده جدا کنیم، و (۲) چگونه زیرگراف\u200cها را به یک گراف پیچیده\u200cای ترکیب کنیم. تجربه\u200cها فعالیت جمع گراف را نشان می\u200cدهند. بازیگر ما به اجرای وضعیت هنری رسیده و خیلی بهتر از دو بازیگر بر اساس تغییر است.', 'af': "Hierdie papier is bekommerd met die bou van diep grammatiese verhouding (GR) analiseer met die gebruik van data-driefde toegang. Om hierdie probleem te behandel, voorstel ons graaf versameling, 'n nuwe perspektief vir fleksibel afhanklikheidsgraf te bou: Konstrueer komplekse graafe deur eenvoudige subgraaf te konstrukteer. Ons bespreek twee sleutel probleme in hierdie perspektief: (1) hoe om 'n kompleks graaf in eenvoudige subgraaf te dekomprimeer en (2) hoe om subgraaf in 'n koerende kompleks graaf te kombinerer. Eksperimente vertoon die effektiviteit van graf saamgevlans. Ons ontleerder bereik status-of-the-art-prestasie en is beter as twee oordragsbaseerde verwerkers.", 'bn': 'এই পত্রিকাটি ডাটা চালানো পদ্ধতি ব্যবহার করে গভীর গ্রামাটিক্যাল সম্পর্ক (জিআর) বিশ্লেষণের ব্যাপারে উদ্ব এই সমস্যার মুখোমুখি হওয়ার জন্য আমরা একটি নতুন দৃষ্টিভঙ্গি গ্রাফ একত্রিত করতে প্রস্তাব করি, ফ্ল্যাক্সিবলের নির্ভরিত গ্রাফ তৈরি করার জন্য: সা আমরা এই দৃষ্টিভঙ্গিতে দুটি গুরুত্বপূর্ণ সমস্যা নিয়ে আলোচনা করি: (১) কিভাবে একটি জটিল গ্রাফ সাবগ্রাফে কম্পোজ করা যায়, আর (২) কিভাবে সাবগ্রা গ্রাফ একত্রিত হওয়ার কার্যক্রম প্রদর্শন করে। আমাদের প্রস্তুতি শিল্পের পরিস্থিতিতে পৌঁছে গেছে এবং দুটি পার্সারের চেয়ে গুরুত্বপূর্ণ ভিত্তিক।', 'cs': 'Tento článek se zabývá budováním analýzy hlubokých gramatických vztahů (GR) pomocí datově řízeného přístupu. Pro řešení tohoto problému navrhujeme sloučení grafů, novou perspektivu pro budování flexibilních závislostních grafů: Konstrukce složitých grafů pomocí konstrukce jednoduchých podgrafů. V této perspektivě diskutujeme dva klíčové problémy: (1) jak rozložit komplexní graf na jednoduché podgrafy a (2) jak kombinovat podgrafy do koherentního komplexního grafu. Experimenty demonstrují účinnost sloučení grafů. Náš parser dosahuje nejmodernějšího výkonu a je výrazně lepší než dva parsery založené na přechodu.', 'et': 'Käesolev töö on seotud sügava grammatilise seose (GR) analüüsiga, kasutades andmepõhist lähenemist. Selle probleemi lahendamiseks pakume välja graafikute ühendamise, uue perspektiivi, paindlike sõltuvusgraafide loomiseks: keerukate graafikute loomine lihtsate alamgraafide loomise kaudu. Selles perspektiivis arutleme kahte põhiprobleemi: (1) kuidas lagundada kompleksne graafik lihtsateks alamgraafideks ja (2) kuidas kombineerida alamgraafid sidusaks kompleksne graafikuks. Katsed näitavad graafikute ühendamise tõhusust. Meie parser saavutab tipptasemel jõudluse ja on oluliselt parem kui kaks üleminekupõhist parser.', 'ca': "Aquest paper està preocupat per construir una anàlisi profunda de relació gramàtica (GR) utilitzant un enfocament basat en dades. To deal with this problem, we propose graph merging, a new perspective, for building flexible dependency graphs: Constructing complex graphs via constructing simple subgraphs.  Discutem dos problemes clau en aquesta perspectiva: 1) com descompondre un gràfic complexe en subgràfics simples, i 2) com combinar subgràfics en un gràfic complexe coherent. Els experiments demostren l'efectivitat de la fusió de gràfics. Our parser reaches state-of-the-art performance and is significantly better than two transition-based parsers.", 'bs': 'Ovaj papir se brine o izgradnji dubokog gramatičkog odnosa (GR) analize s podacima. Za rješavanje ovog problem a predlažemo skupljanje grafika, novu perspektivu, za izgradnju fleksibilnih grafika ovisnosti: izgradnju kompleksnih grafika putem konstrukcije jednostavnih podgrafa. Razgovaramo o dva ključna problema u ovoj perspektivi: (1) kako rasporediti kompleksan grafik u jednostavne podgrafe i (2) kako kombinirati podgrafe u saslužen kompleksni grafik. Eksperimenti pokazuju učinkovitost skupljanja grafika. Naš analitičar postiže predstavu umjetnosti i značajno je bolji od dva razmatrača na temelju tranzicije.', 'fi': 'Tämä artikkeli käsittelee syvän kieliopillisen suhteen (GR) analyysin rakentamista datavetoisen lähestymistavan avulla. Tämän ongelman ratkaisemiseksi ehdotamme graafien yhdistämistä, uutta näkökulmaa joustavien riippuvuuskaavojen rakentamiseen: monimutkaisten graafien rakentamista yksinkertaisten alakaavioiden avulla. Keskustelemme kahdesta keskeisestä ongelmasta tässä perspektiivissä: (1) kuinka hajottaa kompleksinen kaavio yksinkertaisiksi alikaavioiksi, ja (2) miten yhdistää alikaaviot johdonmukaiseksi kompleksiksi kaavioksi. Kokeet osoittavat graafien yhdistämisen tehokkuuden. Analysoijamme saavuttaa huipputason suorituskyvyn ja on huomattavasti parempi kuin kaksi siirtymäpohjaista jäsentäjää.', 'jv': 'Awak iki diputasane nggawe barang nggawe barang nggawe barang nggawe gerang-barang data Gujaring (1) AllProgressBar Perintah sing dipontrolan nggambar efek barang nggawe text-tool-action', 'ha': "Wannan takardan yana da sha'anin yin ƙidãya ga masu hushi na grammati (GR) Analyze da amfani da shiryoyin data-run. Ko haɗi da wannan muammãni, Munã buɗa yin haɗi grafu, da wata watani na dabam, dõmin ka gina rafogi masu hushi da fleksibo: Ka sami grafyuta masu adadi da za'a gina subgrafyutan sauri. We discuss two key problems in this perspective: (1) how to decompose a complex graph into simple subgraphs, and (2) how to combine subgraphs into a coherent complex graph.  Tajarakin na nuna Effekt na haɗi graphi. Paramenmu ya kai ga halin-kungiya kuma yana mafi alhẽri daga parjari biyu wanda aka shige.", 'sk': 'Prispevek se ukvarja z izgradnjo analize globokih slovničnih relacij (GR) z uporabo podatkovno usmerjenega pristopa. Za reševanje tega problema predlagamo združevanje grafov, novo perspektivo, za gradnjo fleksibilnih grafov odvisnosti: Konstrukcija kompleksnih grafov preko konstrukcije preprostih podgrafov. V tej perspektivi razpravljamo o dveh ključnih problemih: (1) kako razgraditi kompleksni graf v preproste podgrafe in (2) kako združiti podgrafe v koherenten kompleksni graf. Poskusi kažejo učinkovitost združevanja grafov. Naš razčlenjevalnik doseže najsodobnejšo zmogljivost in je bistveno boljši od dveh prehodnih razčlenjevalnikov.', 'he': 'הנייר הזה מודאג בבניין ניתוח מערכת גרמטיקה עמוקה (GR) באמצעות גישה מונעת מידע. כדי להתמודד עם הבעיה הזאת, אנו מציעים מיזוג גרפים, פרספקטיבה חדשה, לבניין גרפים של תלויות גמישים: לבנות גרפים מורכבים דרך בניית תת גרפים פשוטים. אנחנו מדברים על שתי בעיות מפתחיות בפרספקטיבה הזאת: (1) איך לפרק גרף מורכב לתוך תת-גרפים פשוטים, ו (2) איך לשלב תת-גרפים לתוך גרף מורכב תואם. ניסויים מראים את היעילות של התמזגות הגרפים. המחקר שלנו מגיע למופע המיוחד והוא יותר טוב משני המחקרים המבוססים במעבר.', 'bo': 'This paper is concerned with building deep grammatical relation (GR) analysis using data-driven approach. འུ་ཅག་གིས་བྱ་ཚུལ་འདི་ལྟ་བུ་ཞིག་ལས་སྦྱོར་བའི་རྣམ་པ་གསརཔ་ཞིག་བཤད་ཀྱི་ཡིག་གཟུགས་རིས་བཙུགས་རྒྱུ་དང་། འུ་ཅག་གིས་མཐོང་ཚོང་དཀའ་ངལ་གཉིས་འདི་ལྟ་བུ་བཤད་ཀྱི་ཡོད། ལག་ལེན་བྱ་ཚིག་གིས་མཉམ་དུ་བསྡུས་ནུས་ཡོད་ཚད་ལྟ་རྟོགས་བྱེད། ང་ཚོའི་དབྱེ་སྟངས་ཀྱིས་སྔོན་སྒྲིག་གནས་སྟངས་དང་གནས་སྟངས་འདྲ་བཤུ་གཉིས་ལས་མཐོང་བ་རེད།'}
{'en': 'Collaborative Partitioning for Coreference Resolution', 'ar': 'التقسيم التعاوني لقرار Coreference', 'pt': 'Particionamento Colaborativo para Resolução de Correferência', 'fr': 'Partitionnement collaboratif pour la résolution de coréférence', 'es': 'Particionamiento colaborativo para la resolución de correferencias', 'ja': 'コアリファレンス解決のためのコラボレーションパーティショニング', 'zh': '所以协理解析之协区也', 'ru': 'Совместное разбиение на разделы для разрешения ядра', 'ga': 'Deighilt Chomhoibríoch le haghaidh Réiteach Croíthagartha', 'hi': 'Coreference संकल्प के लिए सहयोगी विभाजन', 'el': 'Συνεργατικός διαχωρισμός για την επίλυση της Coreference', 'hu': 'Együttműködő partícionálás a Coreferencia-feloldáshoz', 'kk': 'Құрылғының Айырымдылығының біріктіру бөлімі', 'lt': 'Collaborative Partitioning for Coreference Resolution', 'mk': 'Collaborative Partitioning for Coreference Resolution', 'ms': 'Collaborative Partitioning for Coreference Resolution', 'ka': 'კოლეფერენციის რეზოციონისთვის დამყარებელი პარატიცია', 'mt': 'Tqassim Kolaborattiv għar-Riżoluzzjoni tal-Koreferenza', 'mn': 'Хамтрагчийн шийдвэрлэлийн хамтрагч хэсэг', 'no': 'Samarbeidsomdeling for oppløysing av koreferanse', 'pl': 'Wspólne podziały na potrzeby rozwiązywania współpracy', 'it': 'Partizionamento collaborativo per la risoluzione di Coreferenza', 'si': 'ප්\u200dරමාණය විශේෂණය සඳහා සම්බන්ධ පාරක්ෂණය', 'so': 'Heshiiska shaqada', 'sv': 'Samarbetspartnering för Coreference Resolution', 'sr': 'Sposobnost particije za rezoluciju korisnosti', 'ml': 'കോര്\u200dഫെന്\u200dസിന്റെ റിസ്റ്റല്\u200d വേണ്ടി സഹകരിക്കുന്ന പാര്\u200dട്ടിഷന്\u200d', 'ur': 'Coreference Resolution کے لئے مشترک پارٹیونینگ', 'ta': 'திரைத்திறனுக்கான கூட்டுதல் பகிர்வு', 'ro': 'Partiționare colaborativă pentru rezoluția coreferenței', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'bg': 'Съвместно разделяне за резолюция на Coreference', 'da': 'Samarbejdsdistribution for Coreference Resolution', 'hr': 'Saradnje particije za rezoluciju korisnosti', 'nl': 'Samenwerkende partitionering voor Coreference Resolutie', 'de': 'Kollaborative Partitionierung für die Coreferenz Resolution', 'ko': '협동 구분', 'id': 'Partisi Kolaboratif untuk Resolusi Koreference', 'sw': 'Collaborative Partitioning for Coreference Resolution', 'fa': 'تقسیم همکاری برای حل پیشنهاد', 'af': 'Kolaboratiewe Partisiering vir Koreferensie Resolusie', 'tr': 'Ewir Görniş Opşenler üçin Ýabşyrma', 'am': 'ምርጫዎች', 'sq': 'Partizimi bashkëpunim për rezolutën e Koreferencës', 'bn': 'কোরেফেন্সের সিস্টেমের জন্য সহযোগিতা পার্টিশন', 'hy': 'Comment', 'cs': 'Spolupracovní oddělení pro řešení společnosti Coreference', 'et': "Coreference'i resolutsiooni jaoks koostöös osalemine", 'bs': 'Saradnje particije za rezoluciju korisnosti', 'fi': 'Coreference-ratkaisun yhteistyöjako', 'ca': 'Collaborative Partitioning for Coreference Resolution', 'az': 'İfadə Çözünürlüyü üçün İşbirlikli Bölüm', 'sk': 'Sodelovalno delitev za resolucijo Coreference', 'ha': 'KCharselect unicode block name', 'he': 'מחלקת שיתוף פעולה לפתרון קורפירנס', 'bo': 'མཐའ་དབྱིབས་གདོང་ཚད་ལ་མཉམ་དབྱེ་ཞིབ', 'jv': 'ProgressBarUpdateResolution'}
{'en': 'This paper presents a collaborative partitioning algorithma novel ensemble-based approach to coreference resolution. Starting from the all-singleton partition, we search for a solution close to the ensemble’s outputs in terms of a task-specific similarity measure. Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models. Our experiments on the CoNLL dataset show that collaborative partitioning yields results superior to those attained by the individual components, for ensembles of both strong and weak systems. Moreover, by applying the collaborative partitioning algorithm on top of three state-of-the-art resolvers, we obtain the best coreference performance reported so far in the literature (MELA v08 score of 64.47).', 'ar': 'تقدم هذه الورقة خوارزمية تقسيم تعاونية - نهج جديد قائم على مجموعة لتحليل المرجع. بدءًا من القسم الفردي بالكامل ، نبحث عن حل قريب من مخرجات المجموعة من حيث مقياس التشابه الخاص بالمهمة. يفترض نهجنا تكاملًا سائبًا للمكونات الفردية للمجموعة ، وبالتالي يمكنه الجمع بين محللات المرجعة التعسفية ، بغض النظر عن نماذجها. تُظهر تجاربنا على مجموعة بيانات CoNLL أن التقسيم التعاوني يعطي نتائج أفضل من تلك التي حققتها المكونات الفردية ، لمجموعات من الأنظمة القوية والضعيفة. علاوة على ذلك ، من خلال تطبيق خوارزمية التقسيم التعاوني على رأس ثلاثة محللات حديثة ، نحصل على أفضل أداء مرجعي تم الإبلاغ عنه حتى الآن في الأدبيات (MELA v08 درجة 64.47).', 'es': 'Este artículo presenta un algoritmo de particionamiento colaborativo, un enfoque novedoso basado en conjuntos para la resolución de correferencias. Partiendo de la partición de todos los singleton, buscamos una solución cercana a los resultados del conjunto en términos de una medida de similitud específica de la tarea. Nuestro enfoque supone una integración flexible de los componentes individuales del conjunto y, por lo tanto, puede combinar resoluciones arbitrarias de correferencias, independientemente de sus modelos. Nuestros experimentos en el conjunto de datos de CoNll muestran que la partición colaborativa produce resultados superiores a los obtenidos por los componentes individuales, para conjuntos de sistemas fuertes y débiles. Además, al aplicar el algoritmo de particionamiento colaborativo sobre tres resolutores de última generación, obtenemos el mejor rendimiento de correferencia reportado hasta ahora en la literatura (puntuación MELA v08 de 64,47).', 'fr': "Cet article présente un algorithme de partitionnement collaboratif, une nouvelle approche basée sur un ensemble pour la résolution de coréférence. À partir de la partition tout singleton, nous recherchons une solution proche des sorties de l'ensemble en termes de mesure de similarité spécifique à une tâche. Notre approche suppose une intégration lâche des composants individuels de l'ensemble et peut donc combiner des résolveurs de coréférence arbitraires, quels que soient leurs modèles. Nos expériences sur l'ensemble de données ConLL montrent que le partitionnement collaboratif donne des résultats supérieurs à ceux obtenus par les composants individuels, pour des ensembles de systèmes forts et faibles. De plus, en appliquant l'algorithme de partitionnement collaboratif sur trois résolveurs de pointe, nous obtenons les meilleures performances de coréférence rapportées jusqu'à présent dans la littérature (score MELA v08 de 64,47).", 'pt': 'Este artigo apresenta um algoritmo de particionamento colaborativo – uma nova abordagem baseada em ensemble para resolução de correferência. A partir da partição all-singleton, procuramos uma solução próxima às saídas do ensemble em termos de uma medida de similaridade específica da tarefa. Nossa abordagem assume uma integração frouxa de componentes individuais do conjunto e, portanto, pode combinar resolvedores de correferência arbitrários, independentemente de seus modelos. Nossos experimentos no conjunto de dados CoNLL mostram que o particionamento colaborativo produz resultados superiores aos obtidos pelos componentes individuais, para conjuntos de sistemas fortes e fracos. Além disso, aplicando o algoritmo de particionamento colaborativo em três resolvedores de última geração, obtemos o melhor desempenho de correferência relatado até agora na literatura (pontuação MELA v08 de 64,47).', 'ja': '本稿では，コアレファレンス分解能に対する新規のアンサンブルベースのアプローチである協働パーティショニングアルゴリズムを紹介する．オールシングルトンパーティションから始まり、タスク固有の類似性メジャーの観点から、アンサンブルの出力に近いソリューションを探します。当社のアプローチは、アンサンブルの個々のコンポーネントの緩い統合を前提としているため、モデルに関係なく、任意のコア参照リゾルバを組み合わせることができます。CoNLLデータセットの実験では、協働パーティショニングは、強い系と弱い系の両方のアンサンブルについて、個々のコンポーネントによって達成された結果よりも優れた結果をもたらすことが示されています。さらに、3つの最先端のリゾルバの上にコラボレーションパーティショニングアルゴリズムを適用することで、これまでに文献で報告された最高のコアリファレンス性能を得ることができます（ Mela v 08スコアは64.47 ）。', 'hi': 'यह पेपर एक सहयोगी विभाजन एल्गोरिथ्म प्रस्तुत करता है - एक उपन्यास पहनावा-आधारित दृष्टिकोण को कोरेफेरेंस रिज़ॉल्यूशन के लिए। ऑल-सिंगलटन विभाजन से शुरू करते हुए, हम एक कार्य-विशिष्ट समानता उपाय के संदर्भ में पहनावा के आउटपुट के करीब एक समाधान की खोज करते हैं। हमारा दृष्टिकोण पहनावा के व्यक्तिगत घटकों का एक ढीला एकीकरण मानता है और इसलिए उनके मॉडल की परवाह किए बिना मनमाने ढंग से सह-सम्मेलन रिज़ॉल्वर को जोड़ सकता है। CoNLL डेटासेट पर हमारे प्रयोगों से पता चलता है कि सहयोगी विभाजन परिणाम व्यक्तिगत घटकों द्वारा प्राप्त किए गए लोगों से बेहतर होता है, दोनों मजबूत और कमजोर प्रणालियों के ensembles के लिए। इसके अलावा, तीन अत्याधुनिक रिज़ॉल्वरों के शीर्ष पर सहयोगी विभाजन एल्गोरिथ्म को लागू करके, हम साहित्य में अब तक रिपोर्ट किए गए सर्वश्रेष्ठ सह-सम्मेलन प्रदर्शन प्राप्त करते हैं (64.47 का मेला v08 स्कोर)।', 'zh': '本文作协作分区算法,盖集成协理解析法也。 从全单例分区,以特定相似性度索近输之解决方案。 吾法设融合诸组件散集,故可合任情之共指解析器,而不顾其形势。 吾于CoNLL数集上之实验明,于强弱之集,协分区而优于单组件也。 此外因三最先进解析器上应用协作分区算法,我们获到迄今为止文献中报告的最佳协同推理性能(MELA v08得分为64.47)。', 'ru': 'Эта работа представляет совместный алгоритм разбиения - новый ансамбле-основанный подход к разрешению сердечника. Начиная со всего шлифовального раздела, мы ищем решение, близкое к выводам ансамбля, с точки зрения специфической для задачи меры подобия. Наш подход предполагает свободную интеграцию отдельных компонентов ансамбля и, следовательно, может объединять произвольные решатели ядра, независимо от их моделей. Наши эксперименты на наборе данных CoNLL показывают, что совместное разделение дает результаты, превосходящие результаты, достигнутые отдельными компонентами, для ансамблей как сильных, так и слабых систем. Кроме того, применяя алгоритм совместного секционирования поверх трех современных резольверов, мы получаем лучшую на сегодняшний день производительность ядра, о которой сообщалось в литературе (оценка MELA v08 64,47).', 'ga': 'Cuireann an páipéar seo i láthair algartam deighilte comhoibríoch - cur chuige nua-bhunaithe ensemble i réiteach croíchomhdhála. Ag tosú ón gcríochdheighilt uile-aonair, déanaimid cuardach ar réiteach atá gar d’aschuir an ensemble i dtéarmaí beart cosúlachta tasc-shonrach. Glacann ár gcur chuige le comhtháthú scaoilte na gcomhpháirteanna aonair den ensemble agus is féidir, mar sin, réitigh lárnacha treallacha a chomhcheangal, beag beann ar a gcuid samhlacha. Léiríonn ár dturgnaimh ar thacar sonraí CoNLL go bhfuil torthaí na críochdheighilte comhoibríoch níos fearr ná na torthaí a bhaineann na comhpháirteanna aonair amach, do ensembles a bhfuil córais láidre agus laga acu araon. Ina theannta sin, tríd an algartam deighilte comhoibríoch a chur i bhfeidhm ar thrí réiteoirí úrscothacha, bainimid amach an fheidhmíocht croíláir is fearr a tuairiscíodh go dtí seo sa litríocht (scór MELA v08 de 64.47).', 'el': 'Η παρούσα εργασία παρουσιάζει έναν αλγόριθμο συνεργατικής κατανομής – μια νέα προσέγγιση βασισμένη σε σύνολα στην επίλυση των διαφορών. Ξεκινώντας από το ενιαίο χώρισμα, αναζητούμε μια λύση κοντά στα αποτελέσματα του συνόλου από την άποψη ενός μέτρου ομοιότητας ειδικά για την εργασία. Η προσέγγισή μας προϋποθέτει μια χαλαρή ενσωμάτωση των επιμέρους στοιχείων του συνόλου και ως εκ τούτου μπορεί να συνδυάσει αυθαίρετες επιλυτές αλληλοδιαφοράς, ανεξάρτητα από τα μοντέλα τους. Τα πειράματά μας στο σύνολο δεδομένων δείχνουν ότι η συνεργατική κατανομή αποδίδει αποτελέσματα ανώτερα από αυτά που επιτυγχάνονται από τα μεμονωμένα συστατικά, για σύνολα τόσο ισχυρών όσο και αδύναμων συστημάτων. Επιπλέον, εφαρμόζοντας τον αλγόριθμο συνεργατικής κατάτμησης πάνω σε τρεις εξελιγμένους διαλύτες, επιτυγχάνουμε την καλύτερη απόδοση συναρτήσεων που αναφέρθηκε μέχρι στιγμής στη βιβλιογραφία (βαθμολογία 64.47).', 'ka': 'ეს დოკუნტი აჩვენებს კოლობორაციური გაყოფილი ალგორიტიმ-პრომენტის ანსტემბლის დაბათებული პროგრამის შესახებ კოლეფერენციის გარეშექმნა. დავიწყებთ ყველა ერთადერთი პერტიკონიდან, ჩვენ შევაძლიათ განსახულებას, რომელიც დავიწყებთ ინსტემბლის გამოსახულებების შესახებ, რაოდენობის განსახულებელობის ზომიდან. ჩვენი პროგორმაცია აღმოჩნდება ინდეგუფიკალური კომპონენტების გარეშე ინტეგრაცია და შეიძლება ამიტომ გარეშე არბრიტური კომპონენტების გარეშე მოდელების გარეშე. ჩვენი ექსპერიმენტები CoNLL მონაცემების კონპონტებში ჩვენი ექსპერიმენტები აჩვენებს, რომ კონპორაციური პერტიციაციაცია იქნება უფრო მეტი მონაცემების, რომლებიც ინდივე დამატებით, ჩვენ მივიღეთ უფრო მსგავსი კოლეფერექცია, რომელიც აღწერა ლიტეტურაში (MELA v08 წერტილი 64.47).', 'kk': 'Бұл қағаз сәйкестік айырмашылығына қатынау алгоритм- романдық ензембл негіздеген жағдай көрсетеді. Бүкіл бөлімдерден басталып, бұл бөлімдердің шешімін қалаймыз. Біздің тәсіліміз енсембульдің жеке компоненттерінің біріктірілігін ұстайды. Сондықтан олардың үлгілеріне қарамастан, арнайы мәселелерді шешушілерді біріктіре алады. CoNLL деректер қорларындағы тәжірибелеріміздің біріміздің бөліміміз жеке компоненттердің, күшті және бақытты жүйелердің символдары үшін жеке компоненттердің нәтижесіне көп нәтижесін көрсете Сонымен қатар, бөлімдердің алгоритмін үш күй-жайын шешушілердің үстінде қолдануға арналған, әдебиетке қазірше хабарлаған ең жақсы қатынау әрекеттері (MELA v08 нәтижесі 64,47).', 'lt': 'This paper presents a collaborative partitioning algorithm-a novel ensemble-based approach to coreference resolution.  Pradedant nuo kiekvieno atskiro skaidymo, ieškome sprendimo, kuris būtų artimas ensemblio rezultatams, atsižvelgiant į užduočių specifinį panašumą. Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models.  Mūsų eksperimentai CoNLL duomenų rinkinyje rodo, kad bendradarbiaujant suskirstymo rezultatai yra didesni už rezultatus, pasiektus atskiruose komponentuose, tiek stiprių, tiek silpnų sistemų rinkiniuose. Be to, taikant bendradarbiaviminį suskirstymo algoritmą virš trijų pažangiausių išsprendiklių, pasiektume geriausius iki šiol literatūroje nurodytus koreferencinius rezultatus (MELA v08 balas 64,47).', 'hu': 'Ez a tanulmány egy kollaboratív partíciós algoritmust mutat be – egy új, együttes alapú megközelítést a coreferencia felbontására. Az all-single partíciótól kiindulva egy feladatspecifikus hasonlósági mértékben keresünk egy olyan megoldást, amely az együttes kimeneteihez közel áll. Megközelítésünk az együttes egyes komponenseinek laza integrációját feltételezi, így modellektől függetlenül kombinálhatjuk az tetszőleges coreferencia-feloldókat. A CoNLL adatkészleten végzett kísérleteink azt mutatják, hogy a kollaboratív partíciós eredmények az egyes komponensek által elért eredményeknél nagyobb eredményeket eredményeznek erős és gyenge rendszerek együtteseiben. Ezenkívül a kollaboratív partíciós algoritmus három korszerű resolver mellett történő alkalmazásával a szakirodalomban eddig jelentett legjobb coreferencia teljesítményt érjük el (MELA v08 pontszám 64,47).', 'it': "Questo articolo presenta un algoritmo di partizionamento collaborativo, un nuovo approccio basato sull'insieme alla risoluzione della coreferenza. Partendo dalla partizione all-singleton, cerchiamo una soluzione vicina agli output dell'ensemble in termini di una misura di somiglianza specifica del task. Il nostro approccio presuppone una libera integrazione dei singoli componenti dell'ensemble e può quindi combinare resolver di coreferenza arbitrari, indipendentemente dai loro modelli. I nostri esperimenti sul set di dati CoNLL mostrano che il partizionamento collaborativo produce risultati superiori a quelli raggiunti dai singoli componenti, per insiemi di sistemi forti e deboli. Inoltre, applicando l'algoritmo di partizionamento collaborativo su tre resolver all'avanguardia, otteniamo le migliori prestazioni di coreferenza finora riportate in letteratura (punteggio MELA v08 di 64,47).", 'ml': 'ഈ പത്രത്തില്\u200d കോര്\u200dഫെന്\u200dസിന്\u200dറെ റിസ്റ്റലിന്റെ അടിസ്ഥാനത്തില്\u200d സഹകരിക്കുന്ന ആല്\u200dഗോരിതം- ഒരു നോവലിന്റെ പ്രാധാ എല്ലാ പ്രത്യേകിച്ചിരിക്കുന്ന വിഭാഗങ്ങളില്\u200d നിന്നും തുടങ്ങുന്നതില്\u200d നിന്നും നമ്മള്\u200d ഒരു തിരഞ്ഞെടുക്കുന്ന ഒരു പ്രത്യേകിച നമ്മുടെ സമ്പ്രദാനത്തിന്റെ സ്വതന്ത്രത്തിന്റെ വ്യക്തിപരമായി ഒരുമിച്ചുകൂട്ടുന്നതാണ്. അതുകൊണ്ട് അവരുടെ മാതൃകങ്ങളെപ്പറ്റിയും  കോണ്\u200dഎല്\u200d ഡാറ്റാസെറ്റിലെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു സഹകരിക്കുന്നത് സഹകരിക്കുന്നതിന്റെ ഫലങ്ങള്\u200d വ്യക്തിപരമായ സംഘങ്ങള Moreover, by applying the collaborative partitioning algorithm on top of three state-of-the-art resolvers, we obtain the best coreference performance reported so far in the literature (MELA v08 score of 64.47).', 'ms': 'Kertas ini memperkenalkan algoritma pemisahan kerjasama-pendekatan berasaskan ensemble baru kepada resolusi persamaan. Mula dari sekatan semua-singleton, kita mencari penyelesaian yang dekat dengan output ensemble dalam terma ukuran persamaan khusus tugas. Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models.  Eksperimen kami pada set data CoNLL menunjukkan bahawa pemisahan kerjasama menghasilkan keputusan yang lebih baik daripada yang dicapai oleh komponen individu, untuk ensembles kedua-dua sistem kuat dan lemah. Selain itu, dengan melaksanakan algoritma pemisahan kerjasama di atas tiga penyelesaian state-of-the-art, kami mendapat prestasi coreference terbaik yang dilaporkan sejauh ini dalam literatur (skor MELA v08 64.47).', 'mt': 'Dan id-dokument jippreżenta algoritmu kollaborattiv ta’ tqassim – approċċ ġdid ibbażat fuq ensemble għar-riżoluzzjoni tal-koreferenza. Mill-partizzjoni ta’ kull wieħed, a ħna qed ifittxu soluzzjoni qrib ir-riżultati tal-ensemble f’termini ta’ miżura ta’ similarità speċifika għall-kompitu. L-approċċ tagħna jassumi integrazzjoni ħielsa ta’ komponenti individwali tal-ensemble u għalhekk jista’ jikkombina soluturi arbitrarji ta’ koreferenza, irrispettivament mill-mudelli tagħhom. L-esperimenti tagħna fuq is-sett tad-dejta CoNLL juru li t-tqassim kollaborattiv jagħti riżultati superjuri għal dawk miksuba mill-komponenti individwali, għal ensembles ta’ sistemi kemm b’saħħithom kif ukoll dgħajfa. Barra minn hekk, bl-applikazzjoni tal-algoritmu kollaborattiv ta’ tqassim fuq tliet riżolturi l-aktar avvanzati, inkisbu l-aħjar prestazzjoni ta’ koreferenza rrappurtata s’issa fil-letteratura (punteġġ MELA v08 ta’ 64.47).', 'mn': 'Энэ цаас нь хамтран ажиллах алгоритм-шийдвэрлэлтийн шийдвэрлэлт дээр зориулсан зохиол юм. Бүх ганц хэсэгт эхлэхээс эхлээд бид энземблийн үр дүнтэй ойролцоогоор даалгавартай адилхан хэмжээний тулд шийдлийг хайж байна. Бидний арга хэмжээний хэсгүүдийг загвараас хамаагүй нэгтгэх боломжтой болно. CoNLL өгөгдлийн сангийн туршилтын туршилтууд хамтран хамтран ажиллах хуваариллагаа нь нэг компонентийн хүрээнд хүргэсэн хүмүүсээс илүү өндөр үр дүнг өгдөг. Мөн хамтран ажиллах алгоритмыг гурван урлагийн шийдвэрлэгчдийн дээд хэрэглэж, уран зохиолд харагдаж байгаа хамгийн сайн зөвшөөрөл үйлдвэрлэл гаргаж байна (MELA v08 64,47 оноо).', 'ro': 'Această lucrare prezintă un algoritm colaborativ de partiționare - o abordare nouă bazată pe ansamblu a rezoluției coreferenței. Pornind de la partiția all-singleton, căutăm o soluție aproape de ieșirile ansamblului în termeni de o măsură de similaritate specifică sarcinii. Abordarea noastră presupune o integrare liberă a componentelor individuale ale ansamblului și, prin urmare, poate combina rezolvătoare arbitrare de corefență, indiferent de modelele acestora. Experimentele noastre pe setul de date CoNLL arată că partiționarea colaborativă produce rezultate superioare celor obținute de componentele individuale, atât pentru ansamblurile de sisteme puternice, cât și cele slabe. Mai mult decât atât, aplicând algoritmul de partajare colaborativă pe partea de sus a trei rezolutoare de ultimă generație, obținem cea mai bună performanță de coreferență raportată până acum în literatură (scorul MELA v08 de 64,47).', 'mk': 'Овој документ претставува соработен алгоритм за поделба-нов пристап базиран на ансембл кон резолуцијата на кореференцијата. Почнувајќи од сите единствени поделби, бараме решение блиску до излезите на ансемблот во однос на мерка на сличност специфична за задачите. Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models.  Нашите експерименти на податоците на CoNLL покажуваат дека соработката поделба дава резултати супериорни од резултатите постигнати од индивидуалните компоненти, за ансембли од силни и слаби системи. Покрај тоа, применувајќи го соработниот алгоритм за поделба на врвот од три најсовремени решители, добиваме најдобра референтна изведба објавена досега во литературата (резултат MELA v08 од 64,47).', 'pl': 'W artykule przedstawiono algorytm partycji współpracy – nowatorskie podejście oparte na zespole do rozdzielczości koreferencji. Zaczynając od partycji all-singleton, poszukujemy rozwiązania bliskiego wyjściom zespołu pod względem konkretnego zadania miary podobieństwa. Nasze podejście zakłada luźną integrację poszczególnych komponentów zespołu i dlatego może łączyć dowolne rozwiązania współzależności, niezależnie od ich modelu. Nasze eksperymenty na zbiorze danych CoNLL pokazują, że współdzielne partycjonowanie daje wyniki lepsze od osiągniętych przez poszczególne komponenty, dla zespołów zarówno silnych, jak i słabych systemów. Ponadto, stosując algorytm partycjonowania współpracującego na trzech najnowocześniejszych resolverach, uzyskujemy najlepszą wydajność współpracy zgłaszaną do tej pory w literaturze (MELA v08 wynik 64.47).', 'so': "This paper presents a collaborative partitioning algorithm-a novel ensemble-based approach to coreference resolution.  Sida aan ka bilaabo qeybta dhamaanka oo kaliga ah, waxaynu raadinaynaa xal ka dhaw oo ka soo baxa shuruudaha shaqada si isku mid ah. Dhaqdhaheenna waxay leedahay isqabsasho xor ah oo ka mid ah qeybaha shakhsiga ah, sidaas darteed waxay isku dari karaan go'aanka cadaawayaasha, haba kastoo ay sameyn lahaayeen. Imtixaankayada kooNLL-dataset waxay muuqataa in qeybinta wadajirka ah ay resultiyaan ka sarreeyaan kuwa laga helay kooxaha gaarka ah, tusaale ahaan nidaamka xoogga leh iyo kuwa itaalka daran. Sidoo kale, marka aad ku dalbaneyso kooxaha iskaasha ah saddexda xaalad ee farshaxanka, waxaan helaynaa heerka ugu fiican ee la soo sheegay qoraalka (MELA v08 score 64.47).", 'si': 'මේ පත්තුව සම්බන්ධ විශේෂණ අල්ගෝරිතම් එකක් පෙන්වනවා කොතුරු පත්තුවක් පත්තුවක් සම්බන්ධ විශේෂණය සඳ සියළුම පාර්ටිකරණයෙන් පටන් ගන්න, අපි ප්\u200dරතිස්ථානයක් හොයාගන්නේ ප්\u200dරතිස්ථානයක් විශේෂයෙන් විශේෂයෙන් විශේ අපේ ප්\u200dරවේශනය අනුමාන කරනවා විශේෂ අංකයේ ප්\u200dරතිකෘත අංකයක් සම්බන්ධ කරනවා, ඒ නිසා ඔවුන්ගේ මොඩේල් එක්කම් කරන්න පු අපේ පරීක්ෂණය CoNLL දත්ත සැටේ පෙන්වන්න පුළුවන් කියලා සම්බන්ධ වෙන්න ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයක් විශේෂයෙ තවත්, සාමාජික වෙනුවෙන් අල්ගෝරිතම් එක්ක සම්බන්ධ වෙනුවෙන් ප්\u200dරතිචාරයක් තුන්දෙනුවෙන් ඉදිරිපත් තුන්දෙනුවෙන්, අපිට ලැබෙනවා හොඳම කෝ', 'no': 'Denne papiret viser ein samarbeidsgiver partisjonsalgoritme-ein novel ensembelbasert tilnærming til koreferanse oppløysing. På starten av alle enkelte partisjonane s øker vi etter løysing nær utgåva av ensemblen ved hjelp av ei tilsvarande mål for oppgåve. Tilnærminga vårt gjer eit låg integrering av individuelle komponentar av ensemblen og kan derfor kombinere tilfeldige koreferensesløysar uavhengig av dei modelane. Eksperimentane våre på CoNLL-dataset viser at samarbeidsgruppene gjer resultat over dei som er att av dei enkelte komponentane, for ensembler av både sterke og svake systemer. I tillegg, ved å bruka samarbeidsgiveringsalgoritmen på toppen av tre oppløysar av kunsten, får vi den beste innstillinga for koreferens som er rapportert så langt i litteraturen (MELA v08 poeng av 64,47).', 'sv': 'Denna uppsats presenterar en samarbetspartitioneringsalgoritm – ett nytt ensemblebaserat tillvägagångssätt för coreferencelopplösning. Med utgångspunkt från partitionen all-singleton söker vi efter en lösning nära ensemblens utgångar i termer av en uppgiftsspecifik likhetsmått. Vårt tillvägagångssätt förutsätter en lös integration av enskilda komponenter i ensemblen och kan därför kombinera godtyckliga coreferensresolvers, oavsett deras modeller. Våra experiment på CoNLL datauppsättningen visar att kollaborativ partitionering ger resultat som är överlägsna än de enskilda komponenterna, för ensembler av både starka och svaga system. Dessutom, genom att tillämpa samarbetspartitioneringsalgoritmen ovanpå tre state-of-the-art resolvers, får vi den bästa coreferenceproduktionen hittills rapporterad i litteraturen (MELA v08 poäng på 64,47).', 'sr': 'Ovaj papir predstavlja saradnji algoritam particije - novi pristup na osnovu ensemble na rješavanju pristojnosti. Počevši od jedinstvenog particije, tražimo rešenje blizu ishoda ensembla u smislu mjere sličnosti određenog zadatka. Naš pristup preduzima oslobođenu integraciju pojedinačnih komponenta ensembla i stoga može kombinirati proizvoljne rezolucije dobrote bez obzira na njihove modele. Naši eksperimenti na sastavu podataka CoNLL pokazuju da saradnja particija pruža rezultate iznad onih koji su dobili pojedinačne komponente, za ensemble jak i slabe sisteme. Osim toga, primjenjivanjem algoritma saradnje particije na vrhu tri državnog rezolutora umjetnosti dobijemo najbolje izvješće u literaturi (MELA v08 rezultat od 64,47).', 'ta': 'இந்த தாள் குறிப்பு தெளிவுத்திறனுக்கு ஒரு கூட்டுதல் பிரிப்பு ஆல்பரிட்டம்- ஒரு புதிய புத்தகத்தை குறிப்பிடு அனைத்து ஒற்றைப் பிரிவிலிருந்தும் துவங்குகிறது, நாம் ஒரு செயல் குறிப்பிட்ட ஒத்த அளவிற்கு அருகில் உள்ள வெளியீடுகளை தீர்வ நம்முடைய செயல்பாடு தனித்தொகுதியின் தனியார் ஒருங்கிணைப்பு என்று எடுத்துக் கொள்கிறது மற்றும் அதனால் அவர்களுடைய மாதிரிகள் வேற கோஎன்எல் தரவுத்தளத்தில் எங்கள் சோதனைகள் காட்டுகிறது தெரியும் கூட்டாளி பிரிவுப்பு முடிவுகள் தனிப்பட்ட பகுதிகள் அடைந்தவர்களை விட அதிகமாக,  Moreover, by applying the collaborative partitioning algorithm on top of three state-of-the-art resolvers, we obtain the best coreference performance reported so far in the literature (MELA v08 score of 64.47).', 'ur': 'This paper presents a collaborative partition algorithm-a novel ensemble-based approach to coreference resolution. ہم نے انسبل کے نتائج کے نزدیک ایک کام کے مطابق مشابہ کے مطابق ایک حل تلاش کی۔ ہمارا تقریبا انزامبل کے فرقے فرقے کا ایک آسان ترکیب کرتا ہے اور اسی وجہ سے ان کی مدل کے بغیر کسی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طر ہماری آزمائش CoNLL ڈیٹ سٹ کے ذریعے دکھاتی ہے کہ collaborative partitioning yields higher results than those achieved by individual components, for both strong and weak systems. اور اس کے علاوہ، تین ایست کے حل کرنے والوں کے اوپر مشارکت پارٹیونٹ الگوریٹم کو لازم کریں، ہم سب سے بہترین مہربانی عملکرد حاصل کریں گے جو اب تک ادبیات میں گزاری گئی ہے (MELA v08 score of 64.47).', 'uz': "Bu qogʻoz bog'liqning algorithini birlashtirish uchun qoʻllanmalar Hamma bitta qismni boshlashdan boshlab, biz vazifa bir xil xil vazifasi bilan boshlanadi. Bizning fikrimimiz bir odamning bir qismlarini biroz birlashtirish mumkin va shunday qilib, ularning modellarini ham birlashtirish mumkin. KoNLL maʼlumotlar tarkibida taʼminlovchimizmizni ko'rsatadi, bir necha komponentlarni ishga tushirish natijalariga o'xshash natijalaridan ham ko'proq, ko'proq va yaxshi tizimning misol. Ko'pchilik algoritni 3 holatning 3 holatning yuqorida qo'llashni qo'llash uchun biz haqida o'zgarishga qaramalgan eng yaxshi ko'plab o'zgarishga (64.47 darajada MELA v08 scori).", 'vi': 'Tờ giấy này có một thuật to án phân tách hợp tác. Một phương pháp kết hợp mới để giải quyết khả năng. Bắt đầu từ phân khúc All-single, chúng tôi tìm kiếm một giải pháp gần kết xuất của dàn nhạc bằng một thước đo tương tự quy định. Cách tiếp cận của chúng ta nắm bắt một sự hoà nhập nhỏ giữa các thành phần của dàn nhạc và có thể kết hợp các dự án ngẫu nhiên, bất chấp các mô hình. Những thí nghiệm trên tập tin CoNll cho thấy các bộ phân tách hợp có kết quả tốt hơn so với kết quả của các thành phần cá nhân, cho các kết hợp của cả hệ thống mạnh và yếu. Thêm vào đó, áp dụng thuật toán phân tách hợp trên đỉnh ba tài năng hiện đại nhất, chúng tôi có khả năng đạt hiệu quả cam kết tốt nhất được ghi trong văn học (MELA v08 ghi số 94 của 647).', 'hr': 'Ovaj papir predstavlja saradnji algoritam particije - nov pristup na osnovu ensemble na rješavanju pristojnosti. Počevši od jedinstvenog particije, tražimo rješenje blizu ishoda ensembla u smislu mjere sličnosti određenog zadatka. Naš pristup preduzima oslobođenu integraciju pojedinačnih komponenta ensembla i stoga može kombinirati proizvoljne rješavanje dobrote bez obzira na njihove modele. Naši eksperimenti na sastavu podataka CoNLL pokazuju da saradnja particija pruža rezultate iznad onih koji su dobili pojedinačne komponente, za ensemble snažnih i slabi sustava. Osim toga, primjenjivanjem algoritma saradnje particije na vrhu tri državnog rezolutora umjetnosti, dobijemo najbolju učinku pristojnosti prijavljenu do sada u književnosti (MELA v08 rezultat od 64,47).', 'nl': 'Dit artikel presenteert een collaboratief partitioneringsalgoritme – een nieuwe ensemble-gebaseerde benadering van coreference resolutie. Vanuit de all-singleton partitie zoeken we naar een oplossing dicht bij de outputs van het ensemble in termen van een taakspecifieke vergelijkingsmaatregel. Onze aanpak veronderstelt een losse integratie van afzonderlijke componenten van het ensemble en kan daarom willekeurige coreference resolvers combineren, ongeacht hun modellen. Onze experimenten op de CoNLL dataset tonen aan dat collaboratieve partitionering resultaten oplevert die superieur zijn aan die welke worden bereikt door de afzonderlijke componenten, voor ensembles van zowel sterke als zwakke systemen. Bovendien, door het collaboratieve partitioneringsalgoritme toe te passen op drie state-of-the-art resolvers, verkrijgen we de beste coreferentieprestaties die tot nu toe in de literatuur zijn gerapporteerd (MELA v08 score van 64.47).', 'bg': 'Тази статия представя алгоритъм за съвместно разделяне - нов ансамбъл-базиран подход към резолюцията на кореференцията. Започвайки от изцяло-единичния дял, ние търсим решение близо до изходите на ансамбъла по отношение на специфична задача мярка за сходство. Нашият подход предполага хлабава интеграция на отделните компоненти на ансамбъла и следователно може да комбинира произволни решатори на кореференцията, независимо от моделите им. Нашите експерименти с набора от данни показват, че съвместното разделяне дава резултати по-добри от тези, постигнати от отделните компоненти, за ансамбли от силни и слаби системи. Освен това, чрез прилагане на алгоритъма за съвместно разделяне върху три най-съвременни резолюции, получаваме най-доброто представяне на кореференцията, докладвано досега в литературата (резултат 64.47).', 'da': 'Denne artikel præsenterer en kollaborativ partitioneringsalgoritme – en ny ensemble-baseret tilgang til coreferenceopløsning. Med udgangspunkt i all-singleton partitionen søger vi efter en løsning tæt på ensemblets output i form af en opgavespecifik lighedsmåling. Vores tilgang forudsætter en løs integration af enkelte komponenter i ensemblet og kan derfor kombinere vilkårlige coreference resolvere, uanset deres modeller. Vores eksperimenter med CoNLL datasættet viser, at kollaborativ partitionering giver resultater bedre end de enkelte komponenter, for ensembler af både stærke og svage systemer. Desuden opnår vi ved at anvende den kollaborative partitioneringsalgoritme oven på tre state-of-the-art resolvere den bedste coreferenceevne rapporteret hidtil i litteraturen (MELA v08 score på 64,47).', 'de': 'Dieser Beitrag stellt einen kollaborativen Partitionierungsalgorithmus vor – einen neuartigen ensemblebasierten Ansatz zur Coreferenzauflösung. Ausgehend von der All-Singleton-Partition suchen wir nach einer Lösung, die den Outputs des Ensembles in Bezug auf ein aufgabenspezifisches Ähnlichkeitsmaß nahe kommt. Unser Ansatz setzt eine lose Integration einzelner Komponenten des Ensembles voraus und kann daher beliebige Coreferenzresolver unabhängig von deren Modellen kombinieren. Unsere Experimente am CoNLL-Datensatz zeigen, dass die kollaborative Partitionierung für Ensembles von starken und schwachen Systemen bessere Ergebnisse liefert als die einzelnen Komponenten. Durch die Anwendung des kollaborativen Partitionierungsalgorithmus auf drei State-of-the-Art Resolvern erhalten wir die bisher beste Coreferenz-Performance (MELA v08 Score von 64.47).', 'ko': '본고는 협동 구분 알고리즘인 통합을 바탕으로 하는 새로운 공지 해소 방법을 제시했다.모든 단일 구분부터, 우리는 특정한 작업의 유사성 도량에 따라 집합 출력에 가까운 해를 검색합니다.우리의 방법은 집적된 각 구성 요소가 느슨하다고 가정하기 때문에, 그것들의 모델이 어떻든지 간에 임의의 공지 해석기를 조합할 수 있다.CoNLL 데이터 세트에서의 실험은 강력한 시스템과 약한 시스템의 집합에 대해 협업 구역이 하나의 구성 요소보다 더 좋은 결과를 얻었다는 것을 보여 주었다.또한 세 가지 가장 선진적인 해석기에 협업 구역 구분 알고리즘을 응용함으로써 우리는 지금까지 문헌에서 보고된 최고의 공지 성능(MELA v08 득점 64.47)을 얻었다.', 'fa': 'این کاغذ یک الگوریتم جدا کردن همکاری را نشان می دهد، یک روش روزنامه\u200cای که بر پایه\u200cی نویس\u200cها بنیاد می\u200cگیرد به راه حل\u200cسازی\u200cهای ارزشمند. از پارتمان\u200cهای تک تک تک\u200cتک شروع می\u200cکنیم، ما برای راه حل نزدیک به نتیجه\u200cهای انجمن به اندازه اندازه\u200cای شبیه\u200cانجمن مشخصه\u200cای دنبال می\u200cکنیم. دسترسی ما یک ترکیب آزاد از بخش\u200cهای فردی از انجمن می\u200cگیرد و به این دلیل می\u200cتواند با وجود مدل\u200cهایشان ترکیب کننده\u200cها را ترکیب کند. آزمایش\u200cهای ما در مجموعه داده\u200cهای CoNLL نشان می\u200cدهند که بخش\u200cهای همکاری به نتیجه\u200cهای بیشتر از آن\u200cها که توسط بخش\u200cهای شخصی به دست آورده\u200cاند، برای نشانه\u200cهای سیستم\u200cهای قوی و ضعیف است. علاوه بر این، با استفاده از الگوریتم جدا کردن همکاری در بالای سه کشورهای دولتی هنر، بهترین عملکرد همکاری که تا حالا در ادبیات گزارش داده شده\u200cایم را دریافت می\u200cکنیم (نمونه MELA v08 از 64.47).', 'id': 'Kertas ini mempersembahkan algoritma partisi kollaboratif - pendekatan baru berdasarkan ensemble untuk resolusi koreferensi. Mulai dari partisi semua-singleton, kita mencari solusi dekat dengan keluaran ensemble dalam terma ukuran persamaan spesifik tugas. Pendekatan kita menganggap integrasi bebas dari komponen individu dari ensemble dan oleh itu dapat menggabungkan penyelesaian coreference arbitrary, tidak peduli model mereka. Eksperimen kami di dataset CoNLL menunjukkan bahwa partisi kolaboratif memberikan hasil yang lebih tinggi dari hasil yang dicapai oleh komponen individu, untuk ensembles dari sistem yang kuat dan lemah. Selain itu, dengan menerapkan algoritma partisi kollaboratif di atas tiga pemecah state-of-the-art, kami mendapatkan prestasi coreference terbaik yang dilaporkan sejauh ini dalam literatur (skor MELA v08 64,47).', 'sw': 'Gazeti hili linaleta utaratibu wa ushirikiano-utaratibu wa riwaya unaoandaliwa na msingi wa kutatua suluhisho la msingi. Kuanzia kwenye sehemu zote za upigaji kura, tunatafuta suluhisho karibu na matokeo ya bunge hiyo kwa mujibu wa kiwango fulani cha kufanya kazi. Hatua yetu inachukua ushirikiano huru wa vifaa vya watu binafsi katika mfumo huo na kwa hiyo inaweza kuunganisha suluhisho la kimaadili, bila kujali mifano yao. Our experiments on the CoNLL dataset show that collaborative partitioning yields results superior to those attained by the individual components, for ensembles of both strong and weak systems.  Zaidi ya hayo, kwa kutumia utaratibu wa ushirikiano juu ya hali tatu ya mambo ya sanaa, tunapata utendaji bora wa ushirikiano ulioandikwa hadi sasa katika fasihi (vipimo vya MELA v08 vya 64.47).', 'sq': "Ky dokument paraqet një algoritëm bashkëpunim ndarjeje-një metodë të re bazuar në ensemble për zgjidhjen e koreferencës. Starting from the all-singleton partition, we search for a solution close to the ensemble's outputs in terms of a task-specific similarity measure.  Përqasja jonë merr një integrim të lirë të komponenteve individuale të ansamblit dhe prandaj mund të kombinojë zgjidhësit arbitrarë të bashkëpunimit, pavarësisht nga modelet e tyre. Eksperimentet tona në grupin e të dhënave CoNLL tregojnë se ndarja bashkëpunimtare sjell rezultate më të larta se ato të arritura nga komponentet individuale, për ansamblet e sistemeve të forta dhe të dobëta. Përveç kësaj, duke aplikuar algoritmin e ndarjes së bashkëpunimit në krye të tre zgjidhësve më të avancuar, ne arrijmë performancën më të mirë koreference të raportuar deri tani në letërsinë (rezultati MELA v08 prej 64.47).", 'tr': 'Bu kagyz golaýy çekişmäne golaýy ýagdaýa golaýy ýagdaýyny görkezýär. Bütün-birek bölümden başlanýan, biz ensembleriň netijesine ýakyn bir çözüm gözləýäris we görkezilişimiz beýleki ölçüsi üçin bir çözüm gözləýäris. Bizim yaklaşymyz ensembliň birnäçe parçalarynyň üsgüren bir integrasy kabul edip, bu yüzden itrabir çekişim çözümlerini modellerine rağmen birleştirebilir. CoNLL veri setindeki deneylerimiz işbirleşik bölümleriniň ýerleşýän adamlaryň, güýçli we zayıf sistemalaryň köpüsi üçin üstüne bir netijede getirilýär. Munuň üç sanat çözgüçileriniň üstünde işbirliği bölümleme algoritmyny ulanyp edebiýatynda iň gowy hereket etmäni tapdyk (MELA v08 sanat 64.47).', 'af': "Hierdie papier stel 'n samarbeidende partisie algoritme-芒聙聶n novel ensembleem-gebaseerde toegang tot koreferensieresolusie. Beginne van die al-enkelte partisie, soek ons vir 'n oplossing naby die ensemble se uitvoerdes in terms van 'n taak-spesifieke gelykenis maat. Ons toegang aanvaar 'n losse integrasie van individuele komponente van die ensemble en kan daarom arbitr锚re koreferensie oplosserers kombinieer, ongeag van hulle modele. Ons eksperimente op die CoNLL-datastel vertoon dat samarbeidende partisiering oordeel die resultate superior aan die wat deur die individuele komponente ontvang is, vir ensembles van beide sterk en swak stelsels. Daarop, deur die samarbeidende partisiealgoritme op die bo van drie staat-van-kuns-oplosserers toepassing te doen, kry ons die beste koreferensie-prestasie wat tot in die literateit berig is (MELA v08 telling van 64.47).", 'am': 'This paper presents a collaborative partitioning algorithm-a novel ensemble-based approach to coreference resolution.  ከሁሉም ብሔራዊ ክፍል ጀምሮ የስራ ክፍል በተለያዩ መጠቀም የሚቀርበውን መፍትሄን እንፈልጋለን፡፡ አካባቢነታችን የብሔራዊ አካባቢ አካባቢ አካባቢ አካባቢ እና ምሳሌዎቻቸውን ምንም እንኳ ቢሆንም አርቢ የክፍለ ግንኙነቶችን ማጋጠም ይችላል፡፡ በኮንአሌል ዳታ ሳትሰር ፈተናዎቻችን የጥያቄ ክፍል ፍሬዎችን ከሁሉም ክፍሎች የበለጠ እና የደካማ ስርዓቶች ምሳሌ ያሳያል፡፡ በተጨማሪው የሦስት ሀገራት ክፍል ላይ ባለው የክፍለ ክፍል አሌgoritምን በመጠቀም፣ እስከ ዛሬ ድረስ በጽሕፈት የተመረጠውን የድምፅ ውጤት አግኝተናል (MELA v08 የ64.47 ክፍል)', 'bs': 'Ovaj papir predstavlja saradnji algoritam particije - novi pristup na osnovu ensemble na rješavanju pristojnosti. Počevši od jedinstvenog particije, tražimo rješenje blizu ishoda ensembla u smislu mjere sličnosti određenog zadatka. Naš pristup preduzima oslobođenu integraciju pojedinačnih komponenta ensembla i stoga može kombinirati proizvodnje rješavanje dobrote bez obzira na njihove modele. Naši eksperimenti na sastavu podataka CoNLL pokazuju da saradnja particija pruža rezultate iznad onih koji su dobili pojedinačne komponente, za ensemble snažnih i slabi sustava. Osim toga, primjenjivanjem algoritma saradnje particije na vrhu tri državnog rezolutora umjetnosti, dobijemo najbolju učinku pristojnosti prijavljenu do sada u literaturi (MELA v08 rezultat od 64,47).', 'hy': 'Այս աշխատանքը ներկայացնում է համագործակցական բաժանման ալգորիթմ, որը հիմնված է նոր համակարգչային լուծումների վրա: Սկսելով ամենաանհատական մասնիկից, մենք փնտրում ենք լուծում, որը մոտ է էնսեմբոլի արտադրանքներին, խնդիրների հատուկ նմանության չափով: Մեր մոտեցումը ենթադրում է էնսեմբոլի անհատական բաղադրիչների ազատ ինտեգրացիան և կարող է հետևաբար համադրել կամավոր կորեֆերանսի լուծողներ, անկախ իրենց մոդելներից: Our experiments on the CoNLL dataset show that collaborative partitioning yields results superior to those attained by the individual components, for ensembles of both strong and weak systems.  Ավելին, կիրառելով համագործակցության բաժանման ալգորիթմը ամենաբարձր երեք լուծողների վրա, մենք ստանում ենք գրականության մեջ հայտարարված լավագույն համեմատական արտադրողությունները (64.47 գնահատականը ՄեԼԱ v2008).', 'bn': 'এই পত্রিকাটি কোরিফেন্সের সিদ্ধান্তের প্রতি একটি সহযোগিতায় অ্যালগরিদম-একটি নোডেল ভিত্তিক উপায় উপস্থাপন করেছে। সকল সাধারণ বিভাগ থেকে শুরু করা শুরু করে, আমরা একটি কাজের নির্দিষ্ট সমতার মাধ্যমে একটি সমাধান অনুসন্ধান করি। আমাদের প্রতিযোগিতার মাধ্যমে ব্যক্তিগত বিভিন্ন অংশগুলোর একটি মুক্তির সাথে একত্রিত হয়েছে এবং তাই তাদের মডেলের ব্যাপারে তাদে কএনএল ডাটাসেটে আমাদের পরীক্ষা দেখা যাচ্ছে যে সহযোগিতা বিভক্তির ফলাফল ব্যক্তিগত কম্পোনেটগুলোর কাছে পৌঁছেছে, যারা শক্তিশালী এবং দুর্বল এছাড়াও, তিন রাষ্ট্র-শিল্পের সিদ্ধান্তের উপরে সহযোগিতা অ্যালগরিদম প্রয়োগ করার মাধ্যমে আমরা সাহিত্যে সংবাদ প্রদান করেছি (মেলা ভি০৮ স্কোর 64.47 সাহিত্', 'cs': 'Tento článek představuje algoritmus kolaborativního dělení – nový přístup k rozlišení koreferencí založený na souborech. Vycházející z celosvětového oddílu hledáme řešení blízké výstupům souboru z hlediska úlohového měřítka podobnosti. Náš přístup předpokládá volnou integraci jednotlivých komponent souboru, a proto může kombinovat libovolné koreferenční resolvery bez ohledu na jejich modely. Naše experimenty na datové sadě CoNLL ukazují, že kolaborativní dělení přináší výsledky lepší než dosažené jednotlivými komponenty pro soubory silných i slabých systémů. Navíc aplikací algoritmu kolaborativního rozdělování na vrchol tří nejmodernějších resolverů získáme nejlepší koreferenční výkon popsaný dosud v literatuře (MELA v08 skóre 64.47).', 'ca': "Aquest paper presenta un algoritme de divisió col·laborativ-un enfocament basat en un nou conjunt de resolució de coreferències. Starting from the all-singleton partition, we search for a solution close to the ensemble's outputs in terms of a task-specific similarity measure.  Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models.  Els nostres experiments del conjunt de dades CoNLL mostren que la divisió col·laborativa produeix resultats superiors a aquells obtinguts pels components individuals, per conjunts de sistemes forts i dèbils. Moreover, by applying the collaborative partitioning algorithm on top of three state-of-the-art resolvers, we obtain the best coreference performance reported so far in the literature (MELA v08 score of 64.47).", 'et': 'Käesolevas töös tutvustatakse ühise partitsioneerimise algoritmi – uudset ansamblil põhinevat lähenemisviisi koreferensi resolutsioonile. Alustades kõik-singleton partitsioonist otsime lahendust, mis läheneb ansambli väljunditele ülesandespetsiifilise sarnasuse mõõtmise osas. Meie lähenemisviis eeldab üksikute komponentide lahtist integreerimist ning seetõttu võib kombineerida meelevaldseid koreferensi lahendajaid olenemata nende mudelitest. Meie eksperimendid CoNLL andmekogumiga näitavad, et ühise partitsioneerimise tulemused on paremad kui üksikute komponentide saavutatud tulemused nii tugevate kui ka nõrkade süsteemide ansamblite jaoks. Lisaks sellele, rakendades koostöö partitsioneerimise algoritmi kolme kaasaegse lahendaja peale, saame parima koreferentsuse tulemuse kirjanduses seni kirjeldatud (MELA v08 skoor 64,47).', 'az': 'Bu kağıt bir işbirlikçi bölüm algoritmi-yeni ensemble-based approach to coreference resolution göstərir. Bütün-təkrar bölümündən başlayıb, ensemblin çıxışlarının yaxın bir çətinlik axtarırıq. Bizim yaxınlığımız ensemblin individual komponentlərin küçük bir integrasyonu qəbul edir və buna görə də onların modellərinə baxmayaraq arbitrary rəftar çəkənləri birləşdirir. CoNLL veri qutusundakı eksperimentlərimiz göstərir ki, işbirlikçi parçacılığı individu komponentlərin əldə edilənlərin, güclü və zəif sistemlərin ensembüllərinin nəticəsi üçün daha üstün nəticələri verir. Daha sonra, müxtəlif bölüm algoritmini üç mövcud çəkənlərin üstündə istifadə edərək, müəyyən olunmuş ən yaxşı mərhəmət performansını alırıq (MELA v08 qiyməti 64,47).', 'fi': 'Tämä artikkeli esittelee yhteistoiminnallisen osiointialgoritmin – uudenlaisen ensemblepohjaisen lähestymistavan koreferenssiresoluutioon. All-singleton-osiosta alkaen etsimme ratkaisua, joka on lähellä kokoonpanon tuotoksia tehtäväkohtaisen samankaltaisuusmittarin osalta. Lähestymistapamme edellyttää yksittäisten komponenttien löysää integrointia kokonaisuudessa ja voi siten yhdistää mielivaltaisia koreferenssiratkaisuja niiden malleista riippumatta. CoNLL-aineistolla tehdyt kokeet osoittavat, että yhteistoiminnallisen osioinnin tulokset ovat parempia kuin yksittäisten komponenttien tulokset sekä vahvojen että heikkojen järjestelmien kokoonpanoissa. Lisäksi soveltamalla yhteistoiminnallista osiointialgoritmia kolmen huippuluokan ratkaisijan päälle saamme parhaan kirjallisuudessa raportoidun koreferenssisuorituskyvyn (MELA v08 pistemäärä 64,47).', 'ha': "Wannan takardan na bãyar da wata shirin rabo-algoritm-a novelar ensemble-based hanyoyi zuwa rabo-sararin kure. Aka fara daga rabon shirin duk ɗaya, Munã nẽman suluɗi zuwa masu fitarwa na tsari da aka ƙayyade wani aikin da ke daidaita. TayiyinMu yana da wata haɗi mai rasa cikin birnin da ke cikin birane, kuma don haka sai yana iya haɗa masu fassarar arbitati, kuma kõ da misãlai. Kayan jarrabõnmu kan data na CoNLL na nũna cewa rabon shirin da ke ƙara matsayin su ne mafi alhẽri daga waɗanda suka samu da ƙanshi guda, kamar misãlai masu ƙarfi da kuma masu rauni. Za kuma, a lokacin da za'a amfani da algoritm na samar da duk-halin-sanar masu fassarawa uku, za'a sãmu mafi kyãwo ga fassarar mutane da aka sanar da shi a fassarar (MEMA v08 score 64.47).", 'he': 'העבודה הזו מציגה אלגוריתם שיתוף פעולה - גישה מבוססת על אנסמבל חדש לפתרון התאמה. בהתחלה מהמחלקה של כל היחידה, אנו מחפשים פתרון קרוב לתוצאות של האנסמבל במונחים של מדידת דמיון ספציפית למשימה. הגישה שלנו לוקחת אינטגרציה משוחררת של רכיבים בודדים של האנסמבל ולכן יכולה לשלב את פתרוני הצדקה הרצוניים, ללא קשר לדוגמאות שלהם. הניסויים שלנו על קבוצת הנתונים של CoNLL מראים שהמחלקת שיתוף פעולה מובילה תוצאות עדיפות על אלה שהגיעו על ידי המרכיבים הפרטיים, לאנסמלים של מערכות חזקות וחלשות. חוץ מזה, על ידי השימוש של האלגוריתם המשותף של מחלקה על מעל שלושה פתרונים מצוינים, אנחנו מקבלים את ההופעה הכי טובה של התאמה שנדווחה עד כה בספרות (נקודת MELA v08 של 64.47).', 'sk': 'V prispevku je predstavljen algoritem za skupno particiranje – nov pristop, ki temelji na ansamblih k ločljivosti koreference. Iz vseh enojnih particij iščemo rešitev, ki je blizu rezultatom ansambla v smislu merila podobnosti opravila. Naš pristop predpostavlja ohlapno integracijo posameznih komponent ansambla in tako lahko kombinira poljubne reševalce koreference, ne glede na njihove modele. Naši eksperimenti na naboru podatkov CoNLL kažejo, da sodelovalno particiranje prinaša boljše rezultate od tistih, ki jih dosežejo posamezne komponente, za ansamble močnih in šibkih sistemov. Poleg tega z uporabo algoritma za sodelovanje particiranja na vrhu treh najsodobnejših reševalcev dosežemo najboljšo koreferenčno zmogljivost, o kateri smo poročali doslej v literaturi (MELA v08 ocena 64,47).', 'jv': 'Perintah sing nduwe akeh partition-Algorithm sing ngendalikno nêmên basa gambar nggawe gerakan karo Resolusi Nêmên. Mulai ke partition yang saben-singleteon, kita ngubah perusahaan kanggo ngilangno nggawe barang seneng nggawe barang langgambar nggawe Rasané awak dhéwé éngatasai akeh akeh oné akeh sampeyan ingkang sampeyan karo akeh sampeyan ingkang dianggap karo hal-sampeyan karo akeh lanjut sampeyan karo model sing berarti Awak dhéwé éntuk barêng-barêng sing CoNLL nang dataset sing ngomong nik sesilé katêpakan karo partition sing beraksi yang dadi supoyo sing gawe nguasai perusahaan karo sapa-perusahaan, lan akeh nyong nggawe sistem sing gawe nguasah barêng-barêng. Dadine wis, nek aplikasi perusahaan Algoritmi sing beraksi karo perusahaan sugih liyane karo perusahaan-sugih sing luwih dumadhi, kita iso nggawe perusahaan coreferasi sing luwih apik terus atubang ning basa (MELA V2008 sing paling 64.7).', 'bo': 'ཤོག་བྱང་འདིས་མཐུན་སྣུམ་གྱི་སྒྲིག་ཆ་རྐྱེན་སྟངས་ལ་མཐུན་གྱི་ཐབས་ལམ་སྟོན་པ་ཡིན། འགོ་འཛུགས་པ་གཞན་ཞིག་གི་བསུབ་སྣེ་གཙང་ནས་ང་ཚོས་མཚོན་རྟགས་ཀྱི་ཚད་ལ་མཐོང་བའི་ཐབས་ཤེས་ཅིག་འཚོལ་ཞིབ་བྱེད། Our approach assumes a loose integration of individual components of the ensemble and can therefore combine arbitrary coreference resolvers, regardless of their models. ང་ཚོའི་བརྟག་ཞིབ་ཀྱི་CoNLL གནད་སྡུད་ཕྲ་རིང་གིས་མཉམ་འབྲེལ་གྱི་དབྱེ་ཞིབ་ཀྱིས་མཐུན་རྐྱེན་པའི་ཆ་ཤས་སོ་སོ་ལ་ཕན་ཐོན་བྱེད་པའི་རྣམ་ དེ་ལས། རྒྱལ་ཁབ་ཀྱི་དབྱེ་སྤྱོད་མཁན་གྱི་སྣ་ཚོགས་གསུམ་གྱི་མཐུན་སྒྲིག་གི་སྣ་ཚོགས་སྤྱོད་བཞིན་ཡོད། ང་ཚོས་གཞི་ཚོགས་གནས་སྟངས་རྫོགས་ཤིག་གི་རྐྱེན་སྤྱོད་མཁན་ད'}
{'en': 'Tell Me Why : Using Question Answering as Distant Supervision for Answer Justification', 'ar': 'أخبرني لماذا: استخدام الإجابة على الأسئلة كإشراف عن بعد لتبرير الإجابة', 'pt': 'Diga-me por quê: usando a resposta a perguntas como supervisão à distância para justificação de respostas', 'es': 'Dime por qué: Usar la respuesta a preguntas como supervisión a distancia para la justificación de la respuesta', 'fr': 'Dites-moi pourquoi\xa0: Utilisation de la réponse aux questions comme supervision à distance pour justifier une réponse', 'ja': '理由を教えてください：質問への回答を回答の正当性のための遠隔監督として使用する', 'zh': '告我何故:以问答为远程监', 'hi': 'मुझे बताएं कि क्यों: उत्तर औचित्य के लिए दूर के पर्यवेक्षण के रूप में प्रश्न उत्तर का उपयोग करना', 'ru': 'Объясните, почему: использование ответов на вопросы в качестве дистанционного надзора для обоснования ответов', 'ga': 'Inis Liom Cén Fáth: Ag Úsáid Freagra Ceist mar Mhaoirseacht i gCéin chun Fírinniú Freagraí', 'hu': 'Mondd el miért: A kérdések megválaszolása távoli felügyelet a válasz igazolásához', 'ka': 'კაზთ მთ ჱაღჲ: პაჱოჲლჱგაირვ გყოპჲჟთ ჱა ჲრდჲგჲპ ჱა ჲრდჲგჲპ', 'el': 'Πείτε μου γιατί: Χρησιμοποιώντας την απάντηση σε ερωτήσεις ως απομακρυσμένη εποπτεία για την αιτιολόγηση απαντήσεων', 'kk': 'Неге десеңіз: Сұрақ жауап беруді жауап қашықтағы қашықтағы бақылау үшін қолдану', 'lt': 'Pasakykite, kodėl: atsakymo į klausimus naudojimas kaip nuotolinė priežiūra atsakymui pagrįsti', 'it': 'Spiegami perché: Usare la risposta alle domande come supervisione a distanza per giustificare la risposta', 'mt': 'Għid lili Għaliex: L-użu tat-tweġiba għall-mistoqsijiet bħala superviżjoni mill-bogħod għall-ġustifikazzjoni tat-tweġiba', 'ms': 'Beritahu saya kenapa: menggunakan jawapan soalan sebagai pengawasan jauh untuk pembalasan jawapan', 'mk': 'Кажи ми зошто: користењето на одговорот на прашањата како оддалечена надзора за оправдување на одговорот', 'ml': 'എന്നോട് പറയൂ: എന്തിനാണ് ചോദ്യത്തിന്റെ ഉത്തരം ഉത്തരം നീതിപ്പെടുത്തുന്നതിനായി ഉപയോഗിക്കുന്നത്.', 'no': 'Fortel meg hvorfor: Bruk spørsmålssvar som avstand oversikt for svarjustering', 'ro': 'Spune-mi de ce: Utilizarea răspunsurilor la întrebări ca supraveghere la distanță pentru justificarea răspunsurilor', 'pl': 'Powiedz mi dlaczego: Używanie odpowiedzi na pytania jako nadzoru na odległość do uzasadnienia odpowiedzi', 'mn': 'Яагаад гэдгийг надад хэлье: Хариулт зөвшөөрүүлэх шаардлагатай асуулт хариултыг ашиглан', 'sr': 'Reci mi zašto: koristeći odgovor na pitanje kao daljinski nadzor odgovora', 'si': 'මට කියන්න ඇයි කියලා: ප්\u200dරශ්න ප්\u200dරතිච්චාරය ප්\u200dරතිචාරය ප්\u200dරතිචාර කරන්න ප්\u200dරතිචාරය සඳහා දුර', 'so': "Ka dheh: Maxaa u isticmaalaya jawaabta su'aalaha sida Suurka maqnaada garsoorida", 'sv': 'Berätta varför: Använda frågesvar som fjärrövervakning för att motivera svar', 'ur': 'آپ کہہ دیجئے کہ سؤال کے استعمال سے جواب دینے کے لئے دور کی نظر ہے', 'ta': 'கேள்விக்கு பதில் தீர்ப்பு நிலைக்கான வழிகாட்சியை பயன்படுத்து', 'vi': 'Nói cho tôi biết tại sao: sử dụng câu trả lời hỏi như sự xác minh trả lời', 'uz': 'Айтинг: «Нима учун саволлар жавоб бериш учун саволлар жавоб беришдан фойдаланиш', 'da': 'Fortæl mig hvorfor: Brug af spørgsmål besvarelse som fjernsyn til svar retfærdiggørelse', 'nl': 'Vertel me waarom: Vragen beantwoorden gebruiken als toezicht op afstand voor antwoordrechtvaardiging', 'hr': 'Recite mi zašto: koristeći odgovor na pitanje kao daljinski nadzor odgovora', 'de': 'Sagen Sie mir warum: Verwenden von Fragebeantworter als Fernüberwachung zur Begründung von Antworten', 'fa': 'بگو چرا: با استفاده از سوال جواب دادن به عنوان مراقبت دور برای جواب دادن', 'id': 'Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification', 'ko': '이유를 알려주세요. 퀴즈를 답변 이유로 하는 원격 감독.', 'bg': 'Кажете ми защо: Използване на отговор на въпроси като отдалечен надзор за обосновка на отговорите', 'sw': 'Mwambie: Kwa nini: kutumia swali la kujibu kama kituo cha kutosha kwa ajili ya jibu la Haki', 'sq': 'Tell Me Why: Using Question Answering as Distant Supervision for Answer Justification', 'hy': 'Ինչու՞: Պատասխանի պատասխանը որպես պատասխանի արդարացման հեռավոր վերահսկողություն օգտագործելը', 'tr': 'Ma흫a n채me 체챌in a첵t: sorag jogaplary janla힊mak 체챌in uzak bir g철zlem챌i h철km체nde', 'af': 'Vertel My Waarom: Gebruik vraag Antwoord as afstand Supervisie vir Antwoord Justifikaasie', 'bn': 'আমাকে বলো কেন: উত্তর বিচারের জন্য প্রশ্নের উত্তর ব্যবহার করা হচ্ছে', 'bs': 'Reci mi zašto: koristeći odgovor na pitanje kao daljinski nadzor za opravdanje odgovora', 'cs': 'Řekněte mi proč: Použití odpovědi na otázky jako vzdáleného dohledu pro odůvodnění odpovědi', 'et': 'Ütle mulle miks: Küsimustele vastamise kasutamine kaugse järelevalvena vastuste põhjendamiseks', 'am': 'ለምንድር ነው: የጥያቄ መልስ ለመልስ ፍርድ መሆኑን በመጠቀም', 'az': 'Sən nə üçün soruşma cavab verməklə cavab vermək üçün uzaq Supervision kimi', 'fi': 'Kerro minulle miksi: Kysymyksiin vastaaminen etävalvonnan avulla vastausten perustelemiseksi', 'ca': 'Digueu-me Per què: Utilitzar la resposta a preguntes com a supervisió remota per a justificar la resposta', 'jv': 'Laopo aku perkaran: Ngawe Perintah Pangunian Bali', 'he': 'תגיד לי למה: להשתמש בתשובה לשאלות כפיקוח מרוחק עבור הצדקה בתשובה', 'ha': 'Ka ce: "Don me kuke karɓa wa tambayi a kan yin ãdalci?"', 'sk': 'Povej mi zakaj: Uporaba odgovarjanja na vprašanja kot daljni nadzor za utemeljitev odgovorov', 'bo': 'ཅིའི་ཕྱིར་ཞིག་ལ་ངེད་ལ། གཟུགས་རིས་ལྟ་བུའི་མཐོང་སྣང་ཚུལ་ངོས་འཛིན་པ་ལ་ཐོབ་པ།'}
{'en': 'For many applications of question answering (QA), being able to explain why a given model chose an answer is critical. However, the lack of labeled data for answer justifications makes learning this difficult and expensive. Here we propose an approach that uses answer ranking as distant supervision for learning how to select informative justifications, where justifications serve as inferential connections between the question and the correct answer while often containing little lexical overlap with either. We propose a neural network architecture for QA that reranks answer justifications as an intermediate (and human-interpretable) step in answer selection. Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications. We show that with this end-to-end approach we are able to significantly improve upon a strong IR baseline in both justification ranking (+9 % rated highly relevant) and answer selection (+6 % P@1).', 'ar': 'بالنسبة للعديد من تطبيقات الإجابة على الأسئلة (QA) ، فإن القدرة على شرح سبب اختيار نموذج معين للإجابة أمر بالغ الأهمية. ومع ذلك ، فإن الافتقار إلى البيانات المصنفة لتبريرات الإجابة يجعل تعلم ذلك صعبًا ومكلفًا. نقترح هنا نهجًا يستخدم ترتيب الإجابات كإشراف بعيد لتعلم كيفية اختيار المبررات الإعلامية ، حيث تعمل المبررات كصلات استنتاجية بين السؤال والإجابة الصحيحة بينما تحتوي غالبًا على القليل من التداخل المعجمي مع أي منهما. نقترح بنية شبكة عصبية لضمان الجودة تعيد تصنيف مبررات الإجابة كخطوة وسيطة (وقابلة للتفسير البشري) في اختيار الإجابة. يعتمد نهجنا على مجموعة من الميزات المصممة للجمع بين كل من التمثيلات المكتسبة والميزات الصريحة لالتقاط الاتصال بين الأسئلة والإجابات ومبررات الإجابة. نظهر أنه من خلال هذا النهج الشامل ، يمكننا تحسين خط الأساس القوي للأشعة تحت الحمراء بشكل كبير في كل من تصنيف التبرير (+ 9٪ تم تقييمه على درجة عالية من الأهمية) واختيار الإجابة (+ 6٪ P @ 1).', 'es': 'Para muchas aplicaciones de respuesta a preguntas (QA), es fundamental poder explicar por qué un modelo determinado eligió una respuesta. Sin embargo, la falta de datos etiquetados para justificar las respuestas hace que aprender esto sea difícil y costoso. Aquí proponemos un enfoque que utiliza la clasificación de respuestas como supervisión a distancia para aprender a seleccionar justificaciones informativas, donde las justificaciones sirven como conexiones inferenciales entre la pregunta y la respuesta correcta, mientras que a menudo contienen poca superposición léxica con cualquiera de las dos. Proponemos una arquitectura de red neuronal para el control de calidad que reclasifica las justificaciones de las respuestas como un paso intermedio (e interpretable por humanos) en la selección de respuestas. Nuestro enfoque se basa en un conjunto de características diseñadas para combinar tanto representaciones aprendidas como características explícitas para capturar la conexión entre preguntas, respuestas y justificaciones de respuestas. Demostramos que con este enfoque integral podemos mejorar significativamente una sólida base de RI tanto en la clasificación de la justificación (+9% calificado como altamente relevante) como en la selección de respuestas (+6% P @1).', 'pt': 'Para muitas aplicações de resposta a perguntas (QA), ser capaz de explicar por que um determinado modelo escolheu uma resposta é fundamental. No entanto, a falta de dados rotulados para justificativas de resposta torna o aprendizado difícil e caro. Aqui propomos uma abordagem que usa a classificação de respostas como supervisão distante para aprender a selecionar justificativas informativas, onde as justificativas servem como conexões inferenciais entre a pergunta e a resposta correta, embora muitas vezes contenham pouca sobreposição lexical com ambas. Propomos uma arquitetura de rede neural para QA que reclassifica as justificativas de resposta como uma etapa intermediária (e interpretável por humanos) na seleção de respostas. Nossa abordagem é informada por um conjunto de recursos projetados para combinar representações aprendidas e recursos explícitos para capturar a conexão entre perguntas, respostas e justificativas de respostas. Mostramos que, com essa abordagem de ponta a ponta, somos capazes de melhorar significativamente uma linha de base de RI forte tanto na classificação de justificativa (+9% classificada como altamente relevante) quanto na seleção de resposta (+6% P@1).', 'fr': "Pour de nombreuses applications de réponse aux questions (AQ), il est essentiel de pouvoir expliquer pourquoi un modèle donné a choisi une réponse. Cependant, l'absence de données étiquetées pour justifier les réponses rend l'apprentissage de cette question difficile et coûteux. Nous proposons ici une approche qui utilise le classement des réponses comme supervision à distance pour apprendre à sélectionner des justifications informatives, où les justifications servent de liens inférentiels entre la question et la bonne réponse tout en contenant souvent peu de chevauchement lexical avec l'une ou l'autre. Nous proposons une architecture de réseau neuronal pour l'assurance qualité qui reclasse les justifications des réponses comme une étape intermédiaire (et interprétable par l'homme) dans la sélection des réponses. Notre approche repose sur un ensemble de fonctionnalités conçues pour combiner à la fois des représentations apprises et des caractéristiques explicites afin de saisir le lien entre les questions, les réponses et les justifications de réponses. Nous montrons qu'avec cette approche de bout en bout, nous sommes en mesure d'améliorer de manière significative une base de référence IR solide à la fois dans le classement de la justification (+9\xa0% jugé très pertinent) et dans la sélection des réponses (+6\xa0% P @1).", 'ru': 'Для многих приложений, отвечающих на вопросы (QA), решающее значение имеет способность объяснить, почему данная модель выбрала ответ. Однако отсутствие маркированных данных для обоснования ответов затрудняет и обходится дорого. Здесь мы предлагаем подход, который использует ранжирование ответов в качестве удаленного надзора для обучения тому, как выбирать информативные обоснования, где обоснования служат в качестве входных связей между вопросом и правильным ответом, при этом часто содержащих мало лексического перекрытия с либо. Мы предлагаем архитектуру нейронной сети для QA, которая перераспределяет обоснования ответов в качестве промежуточного (и интерпретируемого человеком) шага в выборе ответов. Наш подход основан на наборе признаков, предназначенных для объединения как изученных представлений, так и явных признаков, чтобы зафиксировать связь между вопросами, ответами и обоснованиями ответов. Мы показываем, что с помощью этого сквозного подхода мы можем значительно улучшить сильный базовый уровень IR как в рейтинге обоснований (+9% с высокой оценкой), так и в выборе ответов (+6% P@1).', 'zh': '多所问(QA),解释何给定,择对至重。 然乏于对案之标数,使学难而贵。 于是条上一法,以对案排名为远程监督以学信息性,其理为理,而常含少词汇重叠。 为QA发一神经网络架构,更列其中(与人解)步骤。 吾法以群特徵为信息,其旨在合学显式,以获其问,对案相连。 所以然者,因其端到端,得以名(+ 9%之高评级)与对案择(+6%P@1)显改强之IR基线。', 'hi': 'प्रश्न उत्तर (क्यूए) के कई अनुप्रयोगों के लिए, यह समझाने में सक्षम होने के नाते कि किसी दिए गए मॉडल ने उत्तर क्यों चुना, महत्वपूर्ण है। हालांकि, उत्तर औचित्य के लिए लेबल किए गए डेटा की कमी इस कठिन और महंगी सीखना बनाती है। यहां हम एक दृष्टिकोण का प्रस्ताव करते हैं जो जानकारीपूर्ण औचित्य का चयन करने के तरीके सीखने के लिए दूर के पर्यवेक्षण के रूप में उत्तर रैंकिंग का उपयोग करता है, जहां औचित्य प्रश्न और सही उत्तर के बीच अनुमानित कनेक्शन के रूप में काम करते हैं, जबकि अक्सर या तो के साथ थोड़ा लेक्सिकल ओवरलैप होता है। हम क्यूए के लिए एक तंत्रिका नेटवर्क आर्किटेक्चर का प्रस्ताव करते हैं जो उत्तर चयन में एक मध्यवर्ती (और मानव-व्याख्यायोग्य) चरण के रूप में उत्तर औचित्य को फिर से प्रस्तुत करता है। हमारे दृष्टिकोण को प्रश्नों, उत्तरों और उत्तर औचित्य के बीच संबंध को कैप्चर करने के लिए दोनों सीखे गए अभ्यावेदन और स्पष्ट सुविधाओं को संयोजित करने के लिए डिज़ाइन की गई सुविधाओं के एक सेट द्वारा सूचित किया जाता है। हम दिखाते हैं कि इस एंड-टू-एंड दृष्टिकोण के साथ हम औचित्य रैंकिंग (+ 9% अत्यधिक प्रासंगिक रेटेड) और उत्तर चयन (+ 6% P@1) दोनों में एक मजबूत आईआर बेसलाइन पर काफी सुधार करने में सक्षम हैं।', 'ja': '質問応答（ QA ）の多くのアプリケーションでは、特定のモデルが答えを選択した理由を説明できることが重要です。 しかし、回答の正当化のためのラベル付けされたデータが欠如しているため、この学習は困難で費用がかかります。 ここでは、情報的な正当性を選択する方法を学習するための遠隔監督として回答ランキングを使用するアプローチを提案します。ここでは、正当性は質問と正解との間の推論的なつながりとして機能しますが、しばしばどちらともほとんど語彙的に重複しません。 QAのためのニューラルネットワークアーキテクチャを提案し、回答の正当性を回答選択の中間（および人間が解釈可能な）ステップとして再ランク付けします。 私たちのアプローチは、学習された表現と明示的な機能の両方を組み合わせて、質問、回答、および回答の正当性の間のつながりを捉えるように設計された一連の機能に基づいています。 このエンドツーエンドのアプローチでは、妥当性ランキング（関連性が高いと評価された+9 ％ ）と回答選択（ P @ 1 +6 ％ ）の両方において、強力なIRベースラインで大幅に改善することができることが示されています。', 'ga': 'I gcás go leor feidhmeanna a bhaineann le freagra ceisteanna (QA), tá sé ríthábhachtach a bheith in ann a mhíniú cén fáth ar roghnaigh samhail áirithe freagra. Mar sin féin, is deacair agus costasach é seo a fhoghlaim mar gheall ar an easpa sonraí lipéadaithe le haghaidh fírinniú freagraí. Molaimid anseo cur chuige a úsáideann rangú freagraí mar chianmhaoirseacht chun foghlaim conas fírinniú faisnéiseach a roghnú, áit a mbíonn fírinnithe mar naisc tátail idir an cheist agus an freagra ceart agus nach mbíonn mórán forluí foclóireachta ann go minic le ceachtar acu. Molaimid ailtireacht líonra néaraigh do QA a athrangaítear fírinniú freagraí mar chéim idirmheánach (agus daonna-léirmhínithe) i roghnú freagraí. Tá ár gcur chuige bunaithe ar thacar gnéithe atá deartha chun léirithe foghlamtha agus gnéithe soiléire araon a chomhcheangal leis an gceangal idir ceisteanna, freagraí agus fírinniú freagraí a léiriú. Léirímid leis an gcur chuige ceann-go-deireadh seo gur féidir linn feabhas suntasach a chur ar bhonnlíne láidir IR maidir le rangú fírinnithe (+9% rátáil an-ábhartha) agus roghnú freagraí (+6% P@1).', 'hu': 'Számos kérdésválasztási alkalmazás esetében kritikus, hogy meg tudjuk magyarázni, hogy egy adott modell miért választott választ. A válaszok indokolására szolgáló címkézett adatok hiánya azonban megnehezíti és költségessé teszi a tanulást. Itt egy olyan megközelítést javasolunk, amely a válaszok rangsorolását távoli felügyeletként használja az információs indokolások kiválasztásának megtanulására, ahol az indokolások következtetési kapcsolatként szolgálnak a kérdés és a helyes válasz között, miközben gyakran kevés lexikális átfedést tartalmaznak egyikkel. Egy neurális hálózati architektúrát javasolunk a QA számára, amely a válaszok indokolását közbenső (és ember-értelmezhető) lépésként átrendezi. Megközelítésünket olyan funkciók támasztják alá, amelyek mind a tanult reprezentációkat, mind a kifejezett funkciókat kombinálják, hogy megragadják a kapcsolatot a kérdések, a válaszok és a válaszok indokolásai között. Megmutatjuk, hogy ezzel a end-to-end megközelítéssel jelentősen javulni tudunk egy erős IR kiindulási értéken mind az igazolási rangsorban (+9% nagyon releváns) mind a válaszok kiválasztásában (+6% P@1 ).', 'it': "Per molte applicazioni di risposta alle domande (QA), essere in grado di spiegare perché un dato modello ha scelto una risposta è fondamentale. Tuttavia, la mancanza di dati etichettati per giustificare le risposte rende l'apprendimento difficile e costoso. Qui proponiamo un approccio che utilizza il ranking delle risposte come supervisione a distanza per imparare a selezionare le giustificazioni informative, dove le giustificazioni servono da connessioni inferenziali tra la domanda e la risposta corretta mentre spesso contengono poca sovrapposizione lessicale con entrambe. Proponiamo un'architettura di rete neurale per il QA che ricalcola le giustificazioni delle risposte come passo intermedio (e umano-interpretabile) nella selezione delle risposte. Il nostro approccio è basato su una serie di funzionalità progettate per combinare sia rappresentazioni apprese che funzioni esplicite per catturare la connessione tra domande, risposte e giustificazioni di risposta. Dimostriamo che con questo approccio end-to-end siamo in grado di migliorare significativamente su una solida base IR sia nella classifica di giustificazione (+9% valutato altamente rilevante) che nella selezione delle risposte (+6% P@1 ).", 'ka': 'ბევრი კითხვის პასუხისთვის (QA) პროგრამებისთვის, რომელიც შეუძლებელია გაახსნა, რატომ მინდა მონიშნული მოდელი გადაიყენეთ პასუხი კრიტიკ მაგრამ, მარტივი მონაცემების არსებობა განსახულებისთვის განსახულებისთვის გასწავლება ეს ძალიან და ძალიან ძალიან. აქ ჩვენ გვეძლევა გავაკეთებთ წარმოდგენა, რომელიც გამოიყენება წარმოდგენის რენექტირებას, რომელიც განსხვავება ინფორმატიური განსხვავებების განსხვავებას, რომელიც განსხვავება კითხვის და მართლა პასუხის შ ჩვენ მინდა QA-ს ნეიროლური ქსელის აქტიქტიქტიკური, რომელიც განახლება განსაზღვრებას, როგორც განახლება საშუალებელი (და ადამიანის განახლებელი) მონიშნულებაში. ჩვენი პროგრამა ინფორმაცია შექმნილი ფუნქციების ნაწილი, რომლებიც დასწავლებული გამოსახულებების და გამოსახულებული ფუნქციების შესახებ კითხვების, პასუხების და განსახულებების შესა ჩვენ ჩვენ გამოჩვენებთ, რომ ამ ბოლო ბოლო ბოლო პროგრამით ჩვენ შეგვიძლია მნიშვნელოვანად გავაკეთოთ ძალიან IR ფესური ხაზი ორივე განსაზღვრება პროგრამის (+9% უფრო მნიშვნელ P@1 )', 'el': 'Για πολλές εφαρμογές απάντησης ερωτήσεων (QA), είναι κρίσιμη η δυνατότητα να εξηγήσουμε γιατί ένα συγκεκριμένο μοντέλο επέλεξε μια απάντηση. Ωστόσο, η έλλειψη επισημασμένων δεδομένων για αιτιολόγηση απαντήσεων καθιστά τη μάθηση αυτή δύσκολη και δαπανηρή. Εδώ προτείνουμε μια προσέγγιση που χρησιμοποιεί την κατάταξη απαντήσεων ως μακρινή επίβλεψη για την εκμάθηση του τρόπου επιλογής πληροφοριακών δικαιολογιών, όπου οι δικαιολογίες χρησιμεύουν ως συμπερασματικές συνδέσεις μεταξύ της ερώτησης και της σωστής απάντησης ενώ συχνά περιέχουν μικρή λεξική επικάλυψη με τα δύο. Προτείνουμε μια αρχιτεκτονική νευρωνικού δικτύου για την QA που επαναταξινομεί τις αιτιολογήσεις απαντήσεων ως ενδιάμεσο (και ερμηνευτό από άνθρωπο) βήμα στην επιλογή απαντήσεων. Η προσέγγισή μας βασίζεται σε ένα σύνολο χαρακτηριστικών που έχουν σχεδιαστεί για να συνδυάζουν τόσο τις διδαγμένες αναπαραστάσεις όσο και τα ρητά χαρακτηριστικά για να αποτυπώσουν τη σύνδεση μεταξύ ερωτήσεων, απαντήσεων και αιτιολόγησης απαντήσεων. Αποδεικνύουμε ότι με αυτή την ολοκληρωμένη προσέγγιση είμαστε σε θέση να βελτιώσουμε σημαντικά σε σχέση με μια ισχυρή βάση IR τόσο στην κατάταξη αιτιολόγησης (+9% βαθμολογήθηκε ιδιαίτερα σχετική) όσο και στην επιλογή απαντήσεων (+6% P@1 ).', 'lt': 'Daugeliui klausimų atsakymo programų (QA) galima paaiškinti, kodėl pasirinktas konkretus model is yra kritiškas. However, the lack of labeled data for answer justifications makes learning this difficult and expensive.  Čia mes siūlome metodą, pagal kurį atsakymų klasifikavimas naudojamas kaip nuotolinė priežiūra mokymuisi, kaip pasirinkti informacinius pagrindimus, kai pagrindimai naudojami kaip neišvengiami ryšiai tarp klausimo ir teisingo atsakymo, tačiau dažnai juose yra nedidelis leksinis sutapimas. Siūlome QA neurologinio tinklo architektūrą, kuri pakartotinai sieja atsakymų pateisinimą kaip tarpinį (ir žmogaus aiškinamą) atsakymų atrankos žingsnį. Mūsų požiūris informuojamas įvairiais požymiais, kuriais siekiama sujungti mokomus atstovavimus ir aiškius požymius, kad būtų galima nustatyti klausimų, atsakymų ir atsakymų pagrindimo ryšį. Mes rodome, kad taikant šį metodą nuo vieno iki kito galime gerokai pagerinti tvirtą IR bazę tiek pateisinimo rangu (+9 proc. įvertinta labai svarbia) tiek atsakymų atranka (+6 proc. P@1 ).', 'mk': 'For many applications of question answering (QA), being able to explain why a given model chose an answer is critical.  Сепак, недостатокот на означени податоци за оправдување на одговорот го прави ова учење тешко и скапо. Овде предложуваме пристап кој користи рангирање на одговорот како далечен надзор за учење како да избере информативни оправдувања, каде оправдувањата служат како инференцијални врски помеѓу прашањето и правилниот одговор, а честопати содржи мала лексикална прекривка со или. Предложуваме нервна мрежна архитектура за QA која повторно ги поврзува оправдувањата како меѓувреме (и човечки-интерпретабилен) чекор во изборот на одговори. Нашиот пристап е информиран од множина карактеристики дизајнирани за комбинација на научени претставувања и експлицитни карактеристики за зафатување на врската помеѓу прашањата, одговорите и оправдувањата за одговорот. We show that with this end-to-end approach we are able to significantly improve upon a strong IR baseline in both justification ranking (+9% rated highly relevant) and answer selection (+6%  P@1 ).', 'ml': 'ചോദ്യത്തിന്റെ ഉത്തരം മറുപടിയുടെ പല പ്രയോഗങ്ങള്\u200dക്കും, കൊടുത്ത ഒരു മോഡല്\u200d എന്തിനാണ് ഉത്തരം തെരഞ്ഞെടുത്തതെന However, the lack of labeled data for answer justifications makes learning this difficult and expensive.  ഇവിടെ വെച്ച് വിവരങ്ങള്\u200d എങ്ങനെ തെരഞ്ഞെടുക്കേണ്ടതെന്ന് പഠിക്കുന്നതിന് വേണ്ടി വിവരങ്ങളുടെ നിയമങ്ങള്\u200d ഉപയോഗിക്കുന്ന ഉത്തരം റെങ്കിങ്ങ് ഉപയോഗിക് ക്യൂഎയ്ക്ക് വേണ്ടി ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റ്\u200cവര്\u200dക്കെറ്റിക്കേറ്റര്\u200d പ്രായശ്ചിത്രം ചെയ്യുന്നു. അത് മറുപടി തെരഞ്ഞെ പഠിച്ച പ്രതിനിധികളെയും കൂട്ടിചേര്\u200dക്കാനുള്ള വ്യക്തമായ വിഭാഗങ്ങളെയും ചോദ്യങ്ങള്\u200d, ഉത്തരങ്ങള്\u200dക്കിടയിലുള്ള ബന്ധം പിടികൂടാന്\u200d നമ ഈ അവസാനത്തിന്റെ അവസാനത്തേക്കുള്ള അടിസ്ഥാനത്തില്\u200d നമ്മള്\u200dക്ക് ശക്തിയുള്ള ഐആര്\u200d ബേസ്ലൈനില്\u200d മെച്ചപ്പെടുത്താന്\u200d കഴിയുന്നു (+9% വിധിയു P@1 .', 'mt': "Għal ħafna applikazzjonijiet ta’ tweġiba għall-mistoqsijiet (QA), li jkunu jistgħu jispjegaw għaliex mudell partikolari jagħżel tweġiba hija kritika. Madankollu, in-nuqqas ta’ dejta ttikkettata għall-ġustifikazzjonijiet tat-tweġibiet jagħmel it-tagħlim diffiċli u għali. Hawnhekk nipproponu approċċ li juża l-klassifikazzjoni tat-tweġibiet bħala superviżjoni distanti għat-tagħlim kif jintgħażlu ġustifikazzjonijiet informativi, fejn il-ġustifikazzjonijiet iservu bħala konnessjonijiet inferenzjali bejn il-mistoqsija u t-tweġiba korretta filwaqt li spiss ikun fihom ftit li xejn duplikazzjoni lexikali ma’ xulxin. Aħna qed nipproponu arkitettura tan-netwerk newrali għall-QA li tirrikorri l-ġustifikazzjonijiet tat-tweġibiet bħala pass intermedju (u interpretabbli mill-bniedem) fl-għa żla tat-tweġibiet. Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications.  Aħna nuru li b'dan l-approċċ minn tarf sa tarf nistgħu ntejbu b'mod sinifikanti fuq linja bażi qawwija tar-RI kemm fil-klassifikazzjoni tal-ġustifikazzjoni (+9% klassifikata bħala rilevanti ħafna) kif ukoll fl-għa żla tar-risposti (+6% klassifikata bħala rilevanti ħafna) P@1 ).", 'mn': 'Олон асуултын хариулт (QA) хэрэглээний тулд, яагаад өгөгдсөн загварын хариултыг сонгосон нь чухал. Гэхдээ хариултын шалтгааныг харуулахын тулд тэмдэглэгдсэн өгөгдлийн алдаагүй нь ийм хэцүү, үнэтэй суралцах болно. Энд бид хариулт цэгийг хэрхэн сонгохыг суралцах хол зэрэг хариултыг хэрэглэдэг арга замыг суралцах хэрэгтэй гэдгийг санал дэвшүүлнэ. Баталгаа нь асуулт болон зөв хариултын хоорондын холбоотой холбоотой байдаг. Бид QA-ын мэдрэлийн сүлжээний архитектурыг санал болгож байна. Хариулт сонголтын дундаж (мөн хүн төрөлхтний тухай) алхам гэж хариултыг дахин баталдаг. Бидний арга хэмжээ нь суралцсан үзүүлэлт болон тодорхой хариултуудын хоорондын холбоотой холбоотой холбоотой болон хариултын зөвшөөрөл холбоотой боломжтой хэлбэрээр зориулагдсан өөрчлөлт болон мэдээ Бид энэ төгсгөлд хүрэх арга замыг харуулж байна. Бид хоёр нь зөвхөн шударга ёстой (+9% нь маш холбогдолтой) болон хариултын сонголтыг (+6% нь) маш чухал хөгжүүлж чадна. P@1 )', 'ms': 'Untuk banyak aplikasi jawapan soalan (QA), dapat menjelaskan mengapa model yang diberi memilih jawapan adalah kritikal. However, the lack of labeled data for answer justifications makes learning this difficult and expensive.  Di sini kita cadangkan pendekatan yang menggunakan rangkaian jawapan sebagai pengawasan jauh untuk belajar bagaimana untuk memilih alasan maklumat, di mana alasan berkhidmat sebagai sambungan inferential antara soalan dan jawapan yang betul sementara sering mengandungi sedikit meliputi lexik dengan keduanya. We propose a neural network architecture for QA that reranks answer justifications as an intermediate (and human-interpretable) step in answer selection.  Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications.  Kami menunjukkan bahawa dengan pendekatan akhir-akhir ini kita boleh meningkatkan secara signifikan pada dasar IR yang kuat dalam kedua-dua rangkaian keadilan (+9% rangkaian sangat relevan) dan pemilihan jawapan (+6% P@1 ).', 'ro': 'Pentru multe aplicații de răspuns la întrebări (QA), este esențial să puteți explica de ce un anumit model a ales un răspuns. Cu toate acestea, lipsa datelor etichetate pentru justificarea răspunsurilor face ca învățarea să fie dificilă și costisitoare. Aici propunem o abordare care utilizează clasificarea răspunsurilor ca supraveghere la distanță pentru a învăța cum se selectează justificările informative, în cazul în care justificările servesc ca legături inferențiale între întrebare și răspunsul corect, în timp ce adesea conțin puține suprapuneri lexicale cu oricare dintre ele. Propunem o arhitectură de rețea neurală pentru QA care re-rankează justificările răspunsurilor ca un pas intermediar (și uman-interpretabil) în selecția răspunsurilor. Abordarea noastră este informată de un set de caracteristici concepute pentru a combina atât reprezentările învățate, cât și caracteristicile explicite pentru a capta legătura dintre întrebări, răspunsuri și justificări ale răspunsurilor. Aratăm că prin această abordare end-to-end suntem capabili să îmbunătățim semnificativ o bază de referință puternică IR atât în clasamentul de justificare (+9% evaluat extrem de relevant) cât și în selecția răspunsurilor (+6% P@1 ).', 'no': 'For mange spørsmålprogrammer som svarar (QA) kan forklare korleis ein oppgjeven model valt eit svar er kritisk. Manglansen av merkelige data for svarjusteringar gjer imidlertid å lære denne vanskeleg og dykka. Her foreslår vi ein tilnærming som brukar svarrankinga som distant oversikt for å læra korleis å velja informativ justeringar, der justeringar gjeld som mindre tilkopling mellom spørsmålet og det rette svaret mens ofte inneheld lite leksiske overlapping med anten. Vi foreslår eit neuralnettverksarkitektur for QA som gjenoppretter svarjusteringar som ein middels (og menneskelig tolkbar) steg i utvalet av svar. Tilnærminga vårt er informert av eit sett av funksjonar designert for å kombinere både lærte representasjonar og eksplisitt funksjonar for å henta tilkoplinga mellom spørsmål, svar og svarjusteringar. Vi viser at med denne tilnærminga til slutten kan vi betydelig forbedra på ein sterk IR-baseline i begge justeringsrekningar (+9% ratert svært relevant) og svarutvalet (+6%) P@1 )', 'sr': 'Za mnoge aplikacije odgovora na pitanje (QA), u mogućnosti objašnjavanja zašto je dao model izabrao odgovor kritičan. Međutim, nedostatak označenih podataka za opravdanje odgovora čini to teškom i skupom učenju. Ovde predlažemo pristup koji koristi reakciju odgovora kao daljinski nadzor za učenje kako odabrati informativne opravdanje, gdje opravdanja služe kao nedovoljne veze između pitanja i ispravnog odgovora, dok često sadrži malo leksičkog prelapanja s njima. Predlažemo neuralnu mrežu arhitekturu za QA koja ponovo reagira odgovore na opravdanje kao prosječni (i ljudski interpretabilni) korak u odabiru odgovora. Naš pristup je obavijestio skup karakteristika koji su dizajnirani za kombinaciju naučenih predstavljanja i pojasnih karakteristika da uhvatimo vezu između pitanja, odgovora i odgovora na opravdanje. Pokazujemo da s ovim pristupom do kraja možemo značajno poboljšati snažnu početnu liniju IR-a u obje redove opravdanja (+9% procenata jako relevantna) i izboru odgovora (+6%. P@1 )', 'pl': 'W przypadku wielu zastosowań odpowiedzi na pytania (QA) kluczowa jest możliwość wyjaśnienia, dlaczego dany model wybrał odpowiedź. Jednakże brak etykietowanych danych dla uzasadnienia odpowiedzi sprawia, że nauka jest trudna i kosztowna. Proponujemy tutaj podejście, które wykorzystuje ranking odpowiedzi jako odległy nadzór do nauki wyboru uzasadnień informacyjnych, gdzie uzasadnienia służą jako wnioskowe związki między pytaniem a prawidłową odpowiedzią, a często zawierają niewielkie nakładanie się leksykaliczne z jednym z nich. Proponujemy architekturę sieci neuronowej dla QA, która przestawia usprawiedliwienia odpowiedzi jako pośredni (i interpretowalny dla człowieka) krok w wyborze odpowiedzi. Nasze podejście opiera się na zestawie funkcji zaprojektowanych w celu połączenia zarówno nauczonych reprezentacji, jak i wyraźnych cech, aby uchwycić związek między pytaniami, odpowiedziami i uzasadnieniami odpowiedzi. Pokazujemy, że dzięki takiemu kompleksowemu podejściu jesteśmy w stanie znacząco poprawić silną bazę podczerwieni zarówno w rankingu uzasadnienia (+9% ocenianym wysoce istotnym) jak i wyborze odpowiedzi (+6% P@1 ).', 'si': 'ප්\u200dරශ්න ප්\u200dරතිච්චාරය (QA) ගොඩක් විදිහට ප්\u200dරශ්නයක් තියෙන්න පුළුවන් විස්තර කරන්න, ඇයි දෙන්න ප නමුත්, ප්\u200dරතිචාරය සඳහා ලේබල් තොරතුරු අවශ්\u200dයයෙන් ප්\u200dරතිචාරය සඳහා ප්\u200dරතිචාරය සඳහා මේක අ මෙතන අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් සහ වැරදි උත්තර ප්\u200dරශ්නයක් පාවිච්චි කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් අතර ප්\u200dරශ්නයක් සමඟ අපි QA වෙනුවෙන් න්\u200dයූරාල ජාලය ස්ථාපනයක් ප්\u200dරයෝජනය කරන්න පුළුවන් වෙනවා, ඒකෙන් උත්තර තෝරගන්න පුළුවන් වෙනු අපේ ප්\u200dරවේශනය සහ ප්\u200dරශ්නයක්, උත්තර, සහ උත්තර ප්\u200dරතිචාරයක් අතර සම්බන්ධ වෙනුවෙන් සම්බන්ධ වෙනුවෙන් සැකසුම් සඳහ අපි පෙන්වන්නේ මේ අවසානයෙන් අවසානයෙන් අපිට පුළුවන් විශ්වාස කරන්න බැරි IR මූලිකයෙන් වැඩියි (+9% අවසානය වැඩියි) සහ උත්තර තෝ P@1 )', 'sv': 'För många tillämpningar av frågesvar är det viktigt att kunna förklara varför en viss modell valde ett svar. Bristen på märkta data för att motivera svar gör det dock svårt och dyrt att lära sig. Här föreslår vi ett tillvägagångssätt som använder svarsrapportering som avlägsen handledning för att lära sig att välja informativa motiveringar, där motiveringar fungerar som inferentiella kopplingar mellan frågan och rätt svar samtidigt som de ofta innehåller liten lexikal överlappning med endera. Vi föreslår en neural nätverksarkitektur för QA som omräknar svarsbenägenheter som ett mellanliggande (och mänskligt-tolkningsbart) steg i svarsvalet. Vårt tillvägagångssätt styrs av en uppsättning funktioner som är utformade för att kombinera både lärda representationer och explicita funktioner för att fånga kopplingen mellan frågor, svar och svarsbehov. Vi visar att vi med detta end-to-end-tillvägagångssätt kan förbättra oss avsevärt mot en stark IR baseline i både motiveringsranking (+9% betygsatt högt relevant) och svarsval (+6% P@1 ).', 'ta': 'கேள்வி பதில் கேட்கையின் பல பயன்பாடுகளுக்கு, கொடுக்கப்பட்ட மாதிரி ஏன் விடை தேர்ந்தெடு ஆனால், விடையின் குறிப்பிட்ட தகவல் குறிப்பிடப்பட்டது, விடையின் குறிப்புகளுக்கு இந்த கடினமான மற்றும் வி இங்கே நாம் விடையை தொலைதூர கண்காணிப்பாக பயன்படுத்தி தகவல் நிலைமைகளை தேர்ந்தெடுப்பதற்காக பயன்படுத்தும் ஒரு செயல்பாட்டை பரிந்துரைக்கிறோம். அதில் வித நாம் QA க்கான புதிய வலைப்பின்னல் உருவாக்கத்தை பரிந்துரைக்கிறோம் அது மீண்டும் திரும்பி விடையின் விடை தேர்வில் செல் Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications.  இந்த முடிவில் இருந்து முடிவு செயல்பாட்டில் நாம் ஒரு வலுவான IR அடிப்படையில் மேம்படுத்த முடியும் என்று காட்டுகிறோம் (+9% விகிதம் மிகவு P@1 )', 'ur': 'بہت سے سوال کے جواب دینے کے لئے (QA) پوچھنے کے قابل ہیں، کیونکہ ایک مدل نے ایک جواب کیوں انتخاب کیا ہے وہ ضروری ہے۔ However, the lack of labeled data for answer justifications makes this learning difficult and expensive. یہاں ہم ایک طریقہ پیشنهاد کرتے ہیں جو جواب رینگ کو دور نظر کے طور پر استعمال کرتا ہے اس طریقے سے کہ معلومات کی تعریف کو کس طرح انتخاب کرنا چاہیے، جہاں تعریف سوال اور سچی جواب کے درمیان کم اتصال کے طور پر ہے اور بہت سے وقت بھی بہت کم زبان کا اتصال ہوتا ہے۔ ہم نے QA کے لئے ایک نئورل نیٹ ورک معماری پیشنهاد کرتا ہے جو جواب کے انتخاب میں متوسط (اور انسان کی تعبیر قابل) سطح کے طور پر جواب دینے کی جواب دیتا ہے۔ ہمارا طریقہ ایک مجموعہ سے بتایا گیا ہے جو تعلیم کی تعلیم اور واضح تعلیمات کو جمع کرنے کے لئے طریقہ کیا گیا ہے کہ سوال، جواب اور اصلاح کے درمیان اتصال حاصل کریں۔ ہم دکھاتے ہیں کہ اس پایان پایان کے مطابق ہم ایک مضبوط IR بنیس لین پر زیادہ اضافہ کر سکتے ہیں دونوں اصلاح رینگ میں (+9% مطابق اضافہ) اور انتخاب کے مطابق (+6%) P@1 )', 'so': "Codsiyada jawaabta su'aalaha badan (QA) oo aad u awoodi kartid inaad caddayso sababta model la doortay jawaab muhiim ah. Si kastaba ha ahaatee, baahida macluumaadka la xiriiray sababaha jawaabta ayaa barashadan adag iyo qaali ah. Halkan waxaynu soo jeedaynaa qaab lagu isticmaalo jawaabta aad ka leedahay ilaalinta meel fog si aad u doorato xuquuqda macluumaadka, taasoo ay xaq u leedahay sida xiriir aan kiro lahayn u dhexeeya su'aalaha iyo jawaabta saxda ah, inta badan oo ay ku jiraan isku xiriir yar oo leksikal ah. Waxaynu soo jeedaynaa dhismaha internetka ee neurada ee QA, kaas oo dib u soo celinaya inay ugu jawaabaan xaqa sida mid u dhexeeya (iyo turjubaan dadka) si loo doorto jawaabta. Dhaqdooyinkayada waxaa loo soo sheegaa noocyo badan oo loo qoray in la isku xiriiro noocyada bartay iyo faa’iido cad si ay u qabsadaan xiriirka su'aalaha, jawaabaha iyo jawaabta xaqa ah. Waxaynu muujinnaa in marka uu dhammaadka ugu dhammaado, waxaynu awoodi karnaa in aad si weyn u hagaajinno qoraal caadiga ah ee IR ku qoran labada heer oo caddaalad ah (+9% si aad u saabsan) iyo in aan jawaabo doorasho (+6%) P@1 ).", 'kk': 'Көптеген сұрақ жауап беру (QA) қолданбалары үшін келтірілген моделінің неге жауап таңдағанын түсіндіре алады. Бірақ жауапты түзету үшін жарлық деректер жоқ бұл қиын және бағатты оқытуға болады. Мұнда біз жауаптарды бақылау үшін, мәліметті түзетуді қалай таңдау үшін қашықтық бақылау ретінде қолданатын жауаптарды қашықтық бақылау ретінде қолданатын тәртібін таңдап береміз. Тәртіптері сұрақ мен дұрыс Біз QA үшін невралдық желінің архитектурасын таңдау үшін жауапты түзетуге қайта жауап береді. Біздің қасиетіміз сұрақтар, жауаптар мен жауаптарды түзету үшін біріктірілген қасиеттерді біріктіру үшін құрылған қасиеттерді біріктіреді. Бұл соңғы жағдайда біз күшті IR негізгі жолын түзету жолында (+9% бағалау үшін) және жауап таңдау жолында күшті жақсы көмектесуге болады. P@1 )', 'uz': "Name Lekin, javob tashkilotlari uchun hech qanday maʼlumot yoʻq bu juda qiyin va qiymatdir. Here we propose an approach that uses answer ranking as distant supervision for learning how to select informative justifications, where justifications serve as inferential connections between the question and the correct answer while often containing little lexical overlap with either.  @ info Bizning fikrimiz esa o'rganilgan tashkilotlar va savol, javoblar va javoblarni qabul qilish uchun aniqlangan xususiyatlarni birlashtirish mumkin. Biz shu oxiriga ko'rsatganimiz, biz chegara (+9% eng muhim bogʻ'liq) va javob tanlash (+6% yordamida katta IR asosida ko'paytirish mumkin. P@1 Албатта, У зот ўта эшитгувчи ва ўта билгувчи зотдир.", 'vi': 'Đối với nhiều ứng dụng trả lời câu hỏi (QA) có thể giải thích tại sao một mô hình đã chọn một câu trả lời là rất quan trọng. Tuy nhiên, sự thiếu dữ liệu có tựa để xác định đáp án khiến việc học khó khăn và tốn kém. Ở đây chúng tôi đề nghị một phương pháp dùng xếp hạng các câu trả lời như một sự giám sát xa xôi để học cách chọn các lí do thông tin, nơi lý lẽ phục vụ là sự liên kết có hạn giữa câu hỏi và câu trả lời chính xác, trong khi thường chứa hầu hết các chữ viết đè lên nhau. Chúng tôi đề xuất một kiến trúc mạng thần kinh cho QA để trả lời lí lẽ trở thành một bước trung gian (và được phân tích con người) trong việc chọn câu trả lời. Cách tiếp cận của chúng tôi được thông báo bởi một loạt các chi tiết nhằm kết hợp các diễn văn đã học và các chi tiết rõ ràng để nắm bắt sự liên kết giữa câu hỏi, câu trả lời và các lí do. Chúng tôi cho thấy rằng với phương pháp kết thúc này, chúng tôi có thể cải thiện đáng kể trên một cơ sở IR mạnh mẽ cả hai thứ được đánh giá đáng giá là đáng giá cộng cộng cộng cộng cộng cộng cộng-9=. được đánh giá cao) và chọn câu trả lời (+6% P@1 "', 'bg': 'За много приложения за отговор на въпроси (Отговор на въпроси) е критично да можеш да обясниш защо даден модел е избрал отговор. Липсата на етикетирани данни за обосновка на отговорите обаче прави ученето толкова трудно и скъпо. Тук предлагаме подход, който използва класирането на отговорите като дистанционен надзор за учене как да се избере информативна обосновка, където обосновките служат като изводни връзки между въпроса и правилния отговор, като често съдържат малко лексикално припокриване с нито един от тях. Предлагаме архитектура на невронната мрежа за контрол на качеството, която пренарежда оправданията на отговорите като междинна (и интерпретируема от човека) стъпка в избора на отговори. Нашият подход е информиран от набор от функции, предназначени да комбинират както научени представи, така и изрични функции, за да уловят връзката между въпроси, отговори и обяснения на отговорите. Показваме, че с този подход от край до край сме в състояние значително да подобрим силната база на инфраструктурата както в класирането на обосновките (+9% с висока оценка) така и в избора на отговори (+6%). P@1 ).', 'da': 'For mange anvendelser af spørgsmål besvarelse (QA) er det afgørende at kunne forklare, hvorfor en given model valgte et svar. Manglen på mærkede data til begrundelse af svar gør det dog vanskeligt og dyrt at lære. Her foreslår vi en tilgang, der bruger svarrangering som fjernvejledning til at lære, hvordan man vælger informative begrundelser, hvor begrundelser tjener som inferentielle forbindelser mellem spørgsmålet og det korrekte svar, mens de ofte indeholder lidt leksikalsk overlapning med begge dele. Vi foreslår en neural netværksarkitektur til QA, der omarrangerer svar begrundelser som et mellemliggende (og menneskeligt-fortolkbart) trin i svarvalg. Vores tilgang er baseret på et sæt funktioner designet til at kombinere både lærte repræsentationer og eksplicitte funktioner for at fange forbindelsen mellem spørgsmål, svar og svar begrundelser. Vi viser, at vi med denne end-to-end tilgang er i stand til at forbedre os betydeligt med en stærk IR baseline i både retfærdiggørelsesranking (+9% vurderet meget relevant) og svarudvælgelse (+6% P@1 ).', 'nl': 'Voor veel toepassingen van het beantwoorden van vragen (QA) is het cruciaal om uit te leggen waarom een bepaald model voor een antwoord heeft gekozen. Het ontbreken van gelabelde gegevens voor antwoordrechtvaardigingen maakt het leren hiervan echter moeilijk en duur. Hier stellen we een benadering voor die gebruik maakt van antwoorden rangschikking als toezicht op afstand om te leren hoe informatieve rechtvaardigingen te selecteren, waarbij rechtvaardigingen dienen als inferentiële verbanden tussen de vraag en het juiste antwoord, terwijl ze vaak weinig lexicale overlapping met beide bevatten. We stellen een neurale netwerkarchitectuur voor QA voor die antwoordrechtvaardigingen opnieuw rangschikt als een tussenstap in antwoordselectie. Onze aanpak is gebaseerd op een reeks functies die ontworpen zijn om zowel aangeleerde representaties als expliciete functies te combineren om de verbinding tussen vragen, antwoorden en antwoordrechtvaardigingen vast te leggen. We laten zien dat we met deze end-to-end aanpak significant kunnen verbeteren ten opzichte van een sterke IR baseline in zowel rechtvaardigingsrangschikking (+9% hoog relevant beoordeeld) als antwoordselectie (+6% P@1 ).', 'de': 'Für viele Anwendungen der Fragebeantwortung (QA) ist es entscheidend zu erklären, warum ein bestimmtes Modell eine Antwort gewählt hat. Der Mangel an markierten Daten für Antwortbegründungen macht das Lernen jedoch schwierig und teuer. Hier schlagen wir einen Ansatz vor, der das Antwortranking als Fernüberwachung nutzt, um zu lernen, wie man informative Begründungen auswählt, wobei Begründungen als Schlussfolgerungen zwischen der Frage und der richtigen Antwort dienen, während sie oft wenig lexikalische Überschneidungen mit beiden enthalten. Wir schlagen eine neuronale Netzwerkarchitektur für QA vor, die Antwortbegründungen als Zwischenschritt (und menschlich interpretierbar) in der Antwortauswahl neu rangiert. Unser Ansatz basiert auf einer Reihe von Funktionen, die sowohl erlernte Darstellungen als auch explizite Funktionen kombinieren, um die Verbindung zwischen Fragen, Antworten und Antwortbegründungen zu erfassen. Wir zeigen, dass wir mit diesem End-to-End-Ansatz eine starke IR-Baseline sowohl im Rechtfertigungs-Ranking (+9% hoch relevant bewertet) als auch in der Antwortauswahl (+6% P@1 ).', 'id': 'Untuk banyak aplikasi menjawab pertanyaan (QA), dapat menjelaskan mengapa model tertentu memilih jawaban adalah kritis. Namun, kekurangan data labeled untuk alasan jawaban membuat belajar ini sulit dan mahal. Di sini kami mengusulkan pendekatan yang menggunakan rangkaian jawaban sebagai pengawasan jauh untuk belajar bagaimana memilih alasan informatif, di mana alasan berguna sebagai koneksi inferensi antara pertanyaan dan jawaban yang benar sementara sering mengandung sedikit saling bertindak dengan keduanya. Kami mengusulkan arsitektur jaringan saraf untuk QA yang mengubah jawaban justifikasi sebagai langkah intermedium (dan dapat diterjemahkan oleh manusia) dalam seleksi jawaban. Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications.  We show that with this end-to-end approach we are able to significantly improve upon a strong IR baseline in both justification ranking (+9% rated highly relevant) and answer selection (+6%  P@1 ).', 'ko': '퀴즈(QA)의 많은 응용 프로그램에서 왜 주어진 모델이 답을 선택했는지 설명할 수 있는 것이 중요하다.그러나 이유를 대답하는 데 쓰이는 표기 데이터가 부족하기 때문에 학습은 어렵고 비싸다.여기서 우리는 답안 정렬을 원격 감독의 방법으로 삼아 정보성을 선택하는 이유를 배우는 데 사용했다. 그 중에서 이유는 문제와 정답 간의 추리적 연계이고 이 두 문제와 어휘가 거의 중첩되지 않는다.우리는 답안 논증을 다시 정렬하여 답안 선택의 중간 단계(그리고 인류가 해석할 수 있는 절차)로 QA에 사용되는 신경 네트워크 체계 구조를 제시했다.우리의 방법은 하나의 특징으로 구성된 것이다. 이러한 특징은 습득한 표징과 명확한 특징을 결합시켜 문제, 답안과 답안 논증 간의 관계를 포착한다.이러한 포괄적인 접근 방식을 통해 우리는 이유 순위(+9% 높은 상관관계)와 답안 선택(+6%)에서 강력한 IR 기준을 현저하게 개선할 수 있음을 보여줍니다.P@1).', 'tr': '(QA) jogap bermegi 체챌in k철p soraglar 체챌in berilen nusga n채me 체챌in jogap sa첵landygyny d체힊체n체p bil첵채rler. 횦철ne jogaba d체zeltmek 체챌in etiket edilen maglumatlary 첵ok bolsa 철wrenmek 체챌in kyn we gymmatlyk edip bil첵채r. Bu 첵erde biz jogaby d체z체mlerini da힊yrak g철zlem채ge n채dip informati첵a d체z체mlerni sa첵lamak 체챌in ullan첵an bir golla힊dyrma teklip ed첵채ris. Hakykatlamalar soragy흫 we dogry jogabyny흫 arasynda al챌ak bagla힊dyrma h철km체nde hem ki챌i bir le힊ik d체z체mlerni bar. Biz QA 체챌in n채yral 힊ebek arhitektegi teklip edip, jogaby sa첵lamak 체챌in 첵ene-de jogaby 챌철zmesini teklip edip bil첵채ris. Bizi흫 첵ary힊ymyz hem 철wrenmeli temsilleri hem a 챌캇k m철h체mlerimizi soraglary, jogabalary we dogra힊lyklary arasynda bir bagla힊mak 체챌in d체zenlenen 철zellikler tarapyndan haberdar edildi. Biz bu so흫ra so흫ra 첵ala첵y힊y흫 bilen hem g체첵챌li IR baselini hem de흫le첵i힊 derejesinde (+9% m철h체m derejesi 첵ok bolan) we jogap sa첵lamagyna m체mkin edip biljegimizi g철rke첵채ris. P@1 )', 'af': "Vir baie toepassings van vraag antwoord (QA), wat kan verduidelik waarom 'n gegewe model 'n antwoord gekies het, is kritiese. Maar die mislukking van gemerkte data vir antwoord opregtings maak die leer hierdie moeilik en koste. Hier stel ons 'n toegang wat antwoord rangering gebruik as afgeleë supervisie vir leer hoe om inligtige oprigting te kies, waar oprigting dien as onbekende verbindings tussen die vraag en die korrekte antwoord terwyl dikwels klein leksiese oorvloei met enige. Ons voorstel 'n neurale netwerk arkitektuur vir QA wat herank antwoord regverdigings as 'n intermediate (en menslike-interpreterbare) stap in antwoordekeuse. Ons toegang is inligtig deur 'n stel van funksies ontwerp om beide geleerde voorstellings en eksplisiese funksies te kombinereer om die verbinding tussen vrae, antwoorde en antwoord opregtheidinge te vang. Ons wys dat met hierdie einde-tot-einde toegang ons kan betekenlik verbeter op 'n sterk IR basislien in beide opregtheidingsregging (+9% gerateer baie relevante) en antwoord keuse (+6% P@1 )", 'sw': 'Kwa matumizi mengi ya majibu ya maswali (QA), kuweza kueleza kwa nini muundo uliotumiwa umechagua jibu ni muhimu. Hata hivyo, ukosefu wa taarifa zinazoonyesha kwa sababu za kujibu inafanya kujifunza hili ngumu na gharama. Hapa tunapendekeza mbinu ambazo hutumia jibu lenye rangi kama ufuatiliaji wa mbali kwa kujifunza namna ya kuchagua ufanisi wa taarifa, ambapo ukweli unafanya kazi kama muungano usio na msingi kati ya swali na jibu sahihi wakati ambapo mara nyingi hubeba upande mdogo wa lexico na pia. Tunazipendekeza ujenzi wa mtandao wa neura kwa ajili ya QA ambapo watangazaji wanajibu ukweli wa haki kama hatua ya kati (na tafsiri ya binadamu) katika uchaguzi wa majibu. Hatua yetu inaelezwa na baadhi ya vipengele vinavyolengwa kuunganisha wawili wanaojifunza na vipengele vya wazi ili kupata uhusiano kati ya maswali, majibu na jibu. Tunaonyesha kwamba kwa njia hii ya mwisho ya mwisho tunaweza kuboresha kwa kiasi kikubwa kwenye misingi ya IR yenye nguvu katika vyeo vya uhalali (+9% yenye umuhimu mkubwa) na jibu la uchaguzi (+6%) P@1 Na wakasema: Enyi watu wangu!', 'fa': 'برای بسیاری از کاربردهای جواب سوال (QA) قادر بودند که توضیح دهند که چرا یک مدل داده شده پاسخی را انتخاب کردند مهم است. ولی کمبود داده\u200cهای برچسب برای تعریف جواب این کار را سخت و گرون می\u200cکند. ما در اینجا یک روش پیشنهاد می کنیم که از رشته پاسخ به عنوان بررسی دور برای یادگیری از چگونه تعریف دادن اطلاعات را انتخاب کنیم، جایی که تعریف ها به عنوان ارتباطات کمی بین سؤال و پاسخ درست استفاده می کنند، در حالی که اغلب با هم دارای تغییر کوچک ما یک معماری شبکه عصبی برای QA پیشنهاد می\u200cکنیم که به عنوان یک قدم متوسط (و قابل تعبیر انسان) در انتخاب جواب جواب داده است. دستور ما توسط مجموعه از ویژه\u200cهایی که طراحی شده\u200cاند برای ترکیب نمایش\u200cهای یاد گرفته\u200cاند و ویژه\u200cهای خاصی برای گرفتن ارتباط بین سوال، جواب\u200cها و پاسخ\u200cدادن\u200cها اطلاع می\u200cشود. ما نشان می دهیم که با این روش پایان و پایان می توانیم به طور کلی بر یک خط بنیادی IR قوی در هر دو سطح تعریف (+9% با ارزش بسیار ارزش) و انتخاب پاسخ (+6% P@1 )', 'hy': 'Շատ հարցերի պատասխանի (QA) ծրագրերի համար կարելի է բացատրել, թե ինչու է տվյալ մոդելը ընտրել պատասխանը կարևոր է: Այնուամենայնիվ, պատասխանի արդարացումների համար պիտակ տվյալների բացակայությունը դժվարանում է և թանկ է դարձնում սովորելը: Այստեղ մենք առաջարկում ենք մի մոտեցում, որը օգտագործում է պատասխանների դասավորումը որպես հեռավոր վերահսկողություն սովորելու համար, թե ինչպես ընտրել ինֆորմատիվ արդարացումներ, որտեղ արդարացումները ծառայում են որպես անհավասար կապեր հարցի և ճիշտ պատասխանի միջև, բայց հաճախ էլ Մենք առաջարկում ենք QA-ի նյարդային ցանցի ճարտարապետություն, որը վերամշակում է պատասխանների արդարացումները որպես միջին (և մարդկային մեկնաբանելի) քայլ պատասխանների ընտրության մեջ: Մեր մոտեցումը տեղեկացված է մի շարք առանձնահատկությունների միջոցով, որոնք ձևավորված են համադրելու ուսանված ներկայացումները և բացատրական առանձնահատկությունները, որպեսզի ընկալեն հարցերի, պատասխանների և պատասխանների արդարա Մենք ցույց ենք տալիս, որ այս վերջ-վերջ մոտեցումն օգտագործելով մենք կարողանում ենք նշանակալի բարելավել ԱԲ-ի հզոր հիմքի վրա արդարացման դասավորման (+9 տոկոսը գնահատված շատ կարևոր) և պատասխանների ընտրության (+6 տոկոսը) P@1 ).', 'sq': 'Për shumë aplikime të përgjigjes për pyetje (QA), të jesh në gjendje të shpjegosh pse një model i caktuar zgjodhi një përgjigje është kritike. However, the lack of labeled data for answer justifications makes learning this difficult and expensive.  Këtu propozojmë një qasje që përdor renditjen e përgjigjeve si mbikqyrje të largët për të mësuar si të zgjedhin justifikimet informative, ku justifikimet shërbejnë si lidhje inferenciale midis pyetjes dhe përgjigjes së saktë ndërsa shpesh përmbajnë pak mbikqyrje lexike me të dy. Ne propozojmë një arkitekturë rrjeti neural për QA që përsërit përgjigjen e justifikimit si një hap ndërmjetës (dhe i interpretueshëm nga njerëzit) në zgjedhjen e përgjigjeve. Përqasja jonë është e informuar nga një sërë elementesh të dizajnuara për të kombinuar si përfaqësimet e mësuara dhe elemente të qarta për të kapur lidhjen midis pyetjeve, përgjigjeve dhe justifikimit të përgjigjeve. Ne tregojmë se me këtë qasje nga fundi në fund ne jemi në gjendje të përmirësojmë ndjeshëm mbi një bazë të fortë IR në të dy renditjen e justifikimit (+9% vlerësuar mjaft relevante) dhe zgjedhjen e përgjigjeve (+6% vlerësuar mjaft relevante) P@1 ).', 'am': 'ለብዙ ጥያቄ መልስ በመስጠት ፕሮግራሞች (QA)፣ የተሰጠ ሞዴል ለምን መልስ አስቸጋሪ ነው ለመግለጥ ይችላል፡፡ ነገር ግን የመልስ ማስታወቂያውን ለማስተማርና የከበረ መሆኑን የሚያስፈልግ የድምፅ መረጃዎች ጉዳይ ነው፡፡ ወደዚህ፣ የመረጃ ማስታወቂያውን እንዴት እንዲመረጥ ለማስተማር የሩቅ ጉዳይ የመስመር መልስ እንዲያቀበል እና በጥሩ መልስ እና በመጠቀም ጥቂት ሌክሲካዊ ክፍል ሲያይዙ በአካባቢው ግንኙነት እንዲያገለግሉ እና የመልካም መልስ እንዲያጋራለን፡፡ የውይይት መረብ መሠረታዊውን ለመቀበል እና የመካከለኛ (እና የሰው ትርጓሜ) ለመምረጥ ጥያቄዎችን ለመቀበል እናስጀምራለን፡፡ ጥያቄዎች፣ መልስ እና መልስ ክፍተቶችን ለመያሰብ በተማሩት የግንኙነት እና ግንኙነትን ለመያሰብ በተለየ ጥያቄዎች እና በተለየ ጥያቄዎች እና ግንኙነታችንን ለመያሰብ የሚታወቀው፡፡ ወደዚህ መጨረሻ መጨረሻ ልናሳየው እናሳየዋለን፡፡ P@1 .', 'bs': 'Za mnoge aplikacije odgovora na pitanje (QA), u mogućnosti objašnjavanja zašto je određeni model odabrao odgovor kritičan. Međutim, nedostatak označenih podataka za opravdanje odgovora čini to teškom i skupom učenju. Ovdje predlažemo pristup koji koristi reakciju odgovora kao daljinski nadzor za učenje kako odabrati informativne opravdanje, gdje opravdanja služe kao nedovoljne veze između pitanja i ispravnog odgovora, dok često sadrži malo leksičkog preklapanja. Predlažemo arhitekturu neuralne mreže za QA koja ponovo reagira odgovore na opravdanje kao prosječni (i ljudski interpretabilni) korak u odabiru odgovora. Naš pristup je obavijestio skup karakteristika koji su dizajnirani za kombinaciju naučenih predstavljanja i pojasnih karakteristika da uhvatimo vezu između pitanja, odgovora i odgovora na opravdanje. Pokazujemo da s ovim pristupom do kraja možemo značajno poboljšati na snažnoj početnoj liniji IR-a u obje redovite opravdanja (+9% procjene visoko relevantno) i izboru odgovora (+6%. P@1 )', 'az': 'Bir çox sual cavab verən (QA) proqramları üçün, verilən modeli niyə cevap seçdiyini a çıqlayabilir. Lakin, cavab tərzlərinin etiketli məlumatların yox olması bu çox çətin və mal öyrənməsini dəyişdirir. Burada biz cavab səviyyəsini uzaq gözləmə kimi istifadə edən bir metod təklif edirik ki, informativ tərzlərin seçilməsini öyrənmək üçün, haqq tərzlərin sual və doğru cevap arasındakı zəif bağlantılar kimi istifadə edir. Həmçinin çox çox küçük sözləri ilə istifadə edir. Biz QA üçün nöral a ğ arhitektarını təbliğ edirik ki, cevap seçməsi üçün orta (və insan-yorumlayıcı) adım olaraq dəyişdirir. Bizim yaxınlığımız suallar, cavablar və təsdiqlənmələr arasındakı bağlantıları almaq üçün öyrənmiş təsdiqlənmələr və a çıq-aydın təsdiqlənmələr birləşdirmək üçün müəyyən edilmiş bir qrup təsəvvür ilə xəbər verilir. Biz bu sona qədər yaxınlaşdırmaq üçün hər ikimizin təsdiqlənmək səviyyəsində (+9% yüksək dərəcəli) və cevap seçmək üçün möhkəm bir IR səviyyəsini daha yaxınlaşdıra bilərik (+6%) P@1 )', 'ca': "Per a moltes aplicacions de resposta a preguntes, ser capaç d'explicar per què un model determinat ha triat una resposta és crítica. Però la manca de dades etiquetades per justificar respostes fa que l'aprenentatge sigui difícil i cara. Aquí proposem un enfocament que utilitza la classificació de resposta com supervisió remota per aprendre a seleccionar justificacions informatives, on les justificacions serveixen de connexions inferencials entre la pregunta i la resposta correcta mentre sovint contenen poca sobreposió lexical amb tampoc. Proposem una arquitectura de xarxa neural per a QA que reenvolupi les justificacions de la resposta com un pas intermedi (i interpretable per humans) en la selecció de respostes. Our approach is informed by a set of features designed to combine both learned representations and explicit features to capture the connection between questions, answers, and answer justifications.  Mostrem que amb aquest enfocament de final a final podem millorar significativament en una línia de referència forta de IR tant en la classificació de justificació (+9% classificat altament rellevant) com en la selecció de respostes (+6% P@1 ).", 'bn': 'প্রশ্নের উত্তরের অনেক অ্যাপ্লিকেশনের জন্য ব্যাখ্যা করতে পারে কেন একটি মডেল বেছে নিয়েছে কেন একটি উত্তর সমালোচনা। তবে উত্তরের বৈধতার অভাব এই কঠিন এবং দাম শিখতে পারে। এখানে আমরা একটি পদক্ষেপ প্রস্তাব করি যা দূরবর্তী পর্যবেক্ষণ হিসেবে উত্তর ব্যবহার করে তথ্যের যুক্তি নির্বাচন করার জন্য ব্যবহার করে, যেখানে যুক্তি প্রশ্নের মধ্যে অন আমরা কিয়ার জন্য নিউরেল নেটওয়ার্ক কাঠামোর প্রস্তাব করছি যে পুনরায় উত্তর নির্বাচনের জন্য উত্তর প্রদান করা হয়েছে। প্রশ্ন, উত্তর এবং উত্তরের যুক্তিতে যোগাযোগ গ গ্রহণ করার জন্য আমাদের প্রযুক্তির কিছু বিশেষ বৈশিষ্ট্য দ্বারা জানানো হয়েছে। আমরা দেখাচ্ছি যে এই শেষ পর্যন্ত প্রতিক্রিয়ার মাধ্যমে আমরা একটি শক্তিশালী আইআর বেসেলাইনে গুরুত্বপূর্ণ উন্নত করতে পারি (+9% অত্যন্ত সংশ্লিষ্ট) এবং উত্তর P@1 ...', 'cs': 'Pro mnoho aplikací odpovědi na otázky (QA) je klíčové vysvětlit, proč daný model zvolil odpověď. Nedostatek označených dat pro odůvodnění odpovědí však činí učení obtížné a nákladné. Zde navrhujeme přístup, který používá hodnocení odpovědí jako vzdálený dohled pro výběr informačních odůvodnění, kde odůvodnění slouží jako odvodnění mezi otázkou a správnou odpovědí, přičemž často obsahuje malé lexikální překrývání obou otázek. Navrhujeme architekturu neuronové sítě pro QA, která znovu řadí odůvodnění odpovědí jako mezipřední (a lidsky interpretovatelný) krok ve výběru odpovědi. Náš přístup je informován sadou funkcí navržených tak, aby kombinovaly jak učené reprezentace, tak explicitní funkce, aby zachytily souvislost mezi otázkami, odpověďmi a odůvodněním odpovědí. Ukazujeme, že s tímto end-to-end přístupem jsme schopni výrazně zlepšit vůči silné IR základně jak v hodnocení zdůvodnění (+9% hodnocené vysoce relevantní) tak ve výběru odpovědi (+6% P@1 ).', 'hr': 'Za mnoge primjene odgovora na pitanje (QA), u mogućnosti objašnjavanja zašto je odabran model odgovor kritičan. Međutim, nedostatak označenih podataka za opravdanje odgovora čini to teškom i skupom učenju. Ovdje predlažemo pristup koji koristi reakciju odgovora kao daljinski nadzor za učenje kako odabrati informativne opravdanje, gdje opravdanja služe kao nedovoljne veze između pitanja i ispravnog odgovora, dok često sadrži mali leksički preklapanje. Predlažemo arhitekturu neuralne mreže za QA koja ponovno reagira odgovore na opravdanje kao prosječni (i ljudski interpretabilni) korak u odabiru odgovora. Naš pristup je obavijestio skup karakteristika dizajniranih za kombinaciju učenih predstavljanja i pojasnih karakteristika kako bi uhvatio vezu između pitanja, odgovora i odgovora na opravdanje. Pokazujemo da s ovim pristupom do kraja možemo značajno poboljšati na snažnoj početnoj liniji IR-a u obje redovite opravdanja (+9% procjene visoko relevantne) i izboru odgovora (+6%. P@1 )', 'et': 'Paljude küsimustele vastamise rakenduste puhul on kriitiline oskus selgitada, miks antud mudel valis vastuse. Kuid märgistatud andmete puudumine vastuste põhjendamiseks muudab õppimise raskeks ja kulukaks. Siin pakume välja lähenemisviisi, mis kasutab vastuste järjestamist kaugjuhendina informatiivsete põhjenduste valimise õppimiseks, kus põhjendused on järelduslikud seosed küsimuse ja õige vastuse vahel, kuid sageli sisaldavad vähe leksikaalset kattumist kumbagi. Pakume välja neuraalvõrgu arhitektuuri kvaliteedi tagamiseks, mis panustab vastuse põhjendused ümber vahepealse (ja inimese tõlgendatava) sammuna vastuse valimisel. Meie lähenemisviisi toetavad funktsioonid, mille eesmärk on kombineerida nii õppinud esitusi kui ka selgesõnalisi funktsioone, et jäädvustada seos küsimuste, vastuste ja vastuste põhjenduste vahel. Näitame, et selle lõikest-otsa lähenemisviisi abil suudame oluliselt parandada tugevat IR baasi nii põhjenduste järjekorras (+9% hinnatud väga asjakohaseks) kui ka vastuste valikus (+6%). P@1 ).', 'fi': 'Monissa kysymyksiin vastaamisen sovelluksissa on kriittistä selittää, miksi tietty malli valitsi vastauksen. Vastausten perustelemiseksi ei kuitenkaan ole merkittyjä tietoja, joten oppiminen on vaikeaa ja kallista. Tässä työssä ehdotamme lähestymistapaa, jossa vastausten luokittelua etäohjauksena opetellaan valitsemaan informatiivisia perusteluja, joissa perustelut toimivat inferentiaalisina yhteyksinä kysymyksen ja oikean vastauksen välillä, mutta usein ne sisältävät vain vähän sanastollista päällekkäisyyttä kummankaan kanssa. Ehdotamme laadunvarmistukseen neuroverkkoarkkitehtuuria, joka asettaa vastausperustelut uudelleen välivaiheeksi (ja ihmisen tulkittavaksi) vastausvalinnassa. Lähestymistapamme perustuu ominaisuuksiin, jotka on suunniteltu yhdistämään sekä opitut esitykset että eksplisiittiset ominaisuudet, jotka kuvaavat kysymysten, vastausten ja vastausperustelujen välistä yhteyttä. Osoitamme, että tällä kokonaisvaltaisella lähestymistavalla pystymme merkittävästi parantamaan vahvaa IR-lähtötasoa sekä perustelujen luokittelussa (+9% arvioitiin erittäin merkityksellisiksi) että vastausten valinnassa (+6%). P@1 ).', 'jv': 'Anggal akèh aplikasi sing mbubati cejane (KA), iso dianggawe lom apa sing apik modèl sing apik dhéwé tanggal. politenessoffpolite"), and when there is a change ("assertive Awak dhéwé ngerasai pergambar sing gambar nggawe ngubah gambar aturan tapi Awak dhéwé Awak dhéwé nggunakake architecture ngéuralan tambah kanggo KA kuwi nggawe justification iki dadi intermediate (lan ijol-ijol-ijol-ijol) kuwi diagonalan tambah bantuan. Awakdhéwé akses mengko perusahaan karo akeh operasi sing dibutuhke ditambah gambarang gambaran karo perusahaan sing nyimpen mruput, gambarang lan tambah apik dhéwé Awak dhéwé ngerasakno ngono ngono dianggap iki, kita iso nglanggar bantuan IR luwih dumadhi kanggo mbalke nggawe barang nggawe P@1 )', 'sk': 'Za številne aplikacije odgovarjanja na vprašanja (QA) je ključnega pomena razložiti, zakaj je določen model izbral odgovor. Vendar pa pomanjkanje označenih podatkov za utemeljitev odgovorov otežuje in drago učenje. Predlagamo pristop, ki uporablja razvrščanje odgovorov kot daljni nadzor za učenje izbire informativnih utemeljitev, kjer utemeljitve služijo kot inferencialne povezave med vprašanjem in pravilnim odgovorom, medtem ko pogosto vsebujejo malo leksikalnega prekrivanja z obema. Predlagamo arhitekturo nevronskega omrežja za zagotavljanje kakovosti, ki ponovno obravnava utemeljitve odgovorov kot vmesni (in človeško razložljiv) korak pri izbiri odgovorov. Naš pristop temelji na nizu funkcij, ki združujejo tako učene predstavitve kot eksplicitne značilnosti, da zajamejo povezavo med vprašanji, odgovori in obrazložitvami odgovorov. Pokazali smo, da lahko s tem celovitim pristopom znatno izboljšamo močno osnovno osnovo IR tako pri razvrščanju utemeljitve (+9% ocenjeno zelo relevantno) kot pri izbiri odgovorov (+6%). P@1 ).', 'ha': 'Ga masu yawa shiryoyin ayuka da aka karɓa wa tambaya (QA), za\'a iya bayyana bayani don me wani misali ya zaɓi wani jibar ya ƙayyade. Hata haka, bã da kamid data za\'a rubutu wa masu inganci wa jibar, sai ya sanar da wannan masu nauyi da gharama. Hali, Munã bukãta wani matsayi wanda ke amfani da jibar ranka kamar surowa mai nĩsa dõmin ka sani yadda za a zãɓe masu inganci, a inda justification ke aiki kamar linki masu rauni a tsakanin tambaya da jibar da inganci ko da yawa sunã ƙunsa da dukkan dukkan nauyi na leksi. Munã goyyade wani matsayin akwatin tarakin neural wa QA wanda ke samun mutane da ke karɓa wa justification kamar an tsakanin (da fassarar-fassarar) ta cikin zaɓen ajiya. Ana gaya mataimakanmu da wasu na\'umci wanda aka yi nufin su haɗa shaidar da masu lũra da wasu masu bayyani dõmin su kãma haɗi tsakãnin su na tambayar, da jibar da masu daidaita. Tuna nũna cewa, da wannan hanyarwa zuwa ƙari, za mu iya iya ƙari mai girma a kan wani sali mai ƙarfi na IR a cikin ranar justification biyu (+9% ya yi girgije mai girma) da zaɓen ajiya (+6%) P@1 Ya ce: "Yã ku mutãne!', 'he': 'For many applications of question answering (QA), being able to explain why a given model chose an answer is critical.  בכל אופן, חוסר נתונים מסוימים להצדקות תשובה גורם ללמוד את זה קשה ויקר. כאן אנו מציעים גישה שמשתמשת בשורה של תשובות כפיקוח מרוחק ללמוד איך לבחור הצדקות מידעיות, איפה הצדקות משמשות כקשרים אינפורנציאליים בין השאלה והתשובה הנכונה אנו מציעים ארכיטקטורת רשת עצבית עבור QA אשר מחדש רקע תשובה ההצדקות כצעד בינוני (ואנושי-אפשרי) בבחירת תשובה. הגישה שלנו מודיעה על ידי קבוצה של תכונות שנועדו לשלב בין מייצגות למדות ומתכונות ברורות כדי לתפוס את הקשר בין שאלות, תשובות, ותצדקות תשובה. אנו מראים שבגישה מסוף-לסוף זו אנחנו מסוגלים לשפר באופן משמעותי על בסיס IR חזק בשני הצדקות P@1 ).', 'bo': 'ཉེར་སྤྱོད་མང་པོ་ཞིག་ལ་ལན་གསལ་མཁན་གྱི་ཉེར་སྤྱོད་མང་པོ་ཞིག་གདམ་སའི་རྣམ་གྲངས་འདེམས་རྒྱུ་མཚན་ནི། ཡིན་ནའང་། རྒྱ་ནག འོན་ཀྱང་། ང་ཚོས་གནད་དོན་དག་གི་ལྟ་བུའི་རིམ་པ་ཞིག་སྤྱད་ནས་གནད་དོན་རྟོགས་པའི་ཉེན་རིས་ཇུས་ལྟར་གདམ་རྒྱུ་དང་། ང་ཚོས་QA(neural network architecture)ལ་ཡིག ང་ཚོའི་གཟུགས We show that with this end-to-end approach we are able to significantly improve on a strong IR baseline in both justification ranking (+9% rated highly relevant) and answer selection (+6% P@1 )'}
{'en': 'Learning What is Essential in Questions', 'ar': 'تعلم ما هو أساسي في الأسئلة', 'fr': 'Apprendre ce qui est essentiel dans les questions', 'pt': 'Aprendendo o que é essencial nas perguntas', 'es': 'Aprender lo que es esencial en las preguntas', 'ja': '質問に必要不可欠なことを学ぶ', 'zh': '学者必不可少也', 'hi': 'प्रश्नों में आवश्यक क्या है सीखना', 'ru': 'Изучение того, что важно в вопросах', 'ga': 'Ag Foghlaim Cad atá Riachtanach i gCeisteanna', 'hu': 'Tanulás Mi a lényeges a kérdésekben', 'ka': 'კითხვების შესწავლობა', 'el': 'Μάθετε τι είναι ουσιαστικό σε ερωτήσεις', 'it': 'Imparare ciò che è essenziale nelle domande', 'kk': 'Сұрақтарда негізгі нәрсені үйрену', 'mk': 'Научи што е основно во прашањата', 'ms': 'Belajar apa yang penting dalam soalan', 'lt': 'Mokytis, kas yra esminis klausimuose', 'mt': 'Tagħlim X’inhu Essenzjali fil-Mistoqsijiet', 'ml': 'ചോദ്യങ്ങളില്\u200d എസെന്റിയല്\u200d എന്താണെന്ന് പഠിക്കുന്നു', 'mn': 'Оюутнуудын үндсэн зүйлийг сурах нь', 'no': 'Læring kva er grunnleggjande i spørsmål', 'ro': 'Învățarea ce este esențial în întrebări', 'pl': 'Uczenie się, co jest niezbędne w pytaniach', 'sr': 'Naučenje što je osnovno u pitanjima', 'si': 'ප්\u200dරශ්නේ මොකක්ද විශ්වාසයි කියලා ඉගෙන ගන්න', 'so': 'Waxbarashada waxa ay tahay dhibaatooyinka', 'sv': 'Att lära sig vad som är viktigt i frågor', 'ta': 'கேள்விகளில் எஸ்சென்டில் என்ன கற்றுக்கொள்வது', 'ur': 'سؤال میں کیا بنیادی ہے', 'uz': 'Name', 'vi': 'Học về điều cần thiết trong câu hỏi', 'bg': 'Научете какво е съществено във въпросите', 'da': 'Læring Hvad er essentielt i spørgsmål', 'nl': 'Leren wat essentieel is in vragen', 'hr': 'Naučenje što je osnovno u pitanjima', 'de': 'Lernen, was in Fragen essentiell ist', 'ko': '무엇이 문제의 관건인지 배우다', 'id': 'Belajar apa yang penting dalam pertanyaan', 'fa': 'یاد گرفتن چیزی که در سوالات بنیادی است', 'sw': 'Kujifunza Kitu Kipi katika maswali', 'tr': 'Soraglarda esasy zady öwrenmek', 'af': 'Leer wat is essensieal in vrae', 'am': 'Learning What is Essential in Questions', 'sq': 'Mësimi i asaj që është thelbësore në pyetje', 'bn': 'প্রশ্নের মধ্যে কি সেন্টেল শিখা যাচ্ছে', 'hy': 'Սովորեցնել, թե ինչ է կարևոր հարցերում', 'bs': 'Naučenje što je osnovno u pitanjima', 'ca': 'Aprendre què és essencial en preguntes', 'cs': 'Učit se, co je nezbytné v otázkách', 'az': 'Sorularda 톛sas olan캼 칬yr톛nm톛k', 'fi': 'Oppiminen, mikä on olennaista kysymyksissä', 'et': 'Õppimine, mis on oluline küsimustes', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Učenje, kaj je bistvenega v vprašanjih', 'he': 'ללמוד מה חשוב בשאלות', 'ha': 'QDialogButtonBox', 'bo': 'དྲི་ཚིག་ནང་དུ་རྨན་ཅི་ཞིག་གི་སློབ་སྟངས་ལ།'}
{'en': 'Question answering (QA) systems are easily distracted by irrelevant or redundant words in questions, especially when faced with long or multi-sentence questions in difficult domains. This paper introduces and studies the notion of essential question terms with the goal of improving such QA solvers. We illustrate the importance of essential question terms by showing that humans’ ability to answer questions drops significantly when essential terms are eliminated from questions. We then develop a classifier that reliably (90 % mean average precision) identifies and ranks essential terms in questions. Finally, we use the classifier to demonstrate that the notion of question term essentiality allows state-of-the-art QA solver for elementary-level science questions to make better and more informed decisions, improving performance by up to 5%.We also introduce a new dataset of over 2,200 crowd-sourced essential terms annotated science questions.', 'ar': 'يسهل تشتيت انتباه أنظمة الإجابة على الأسئلة (QA) بالكلمات غير الملائمة أو الزائدة عن الحاجة في الأسئلة ، خاصةً عند مواجهة أسئلة طويلة أو متعددة الجمل في المجالات الصعبة. تقدم هذه الورقة وتدرس مفهوم مصطلحات الأسئلة الأساسية بهدف تحسين أدوات حل ضمان الجودة. نوضح أهمية مصطلحات الأسئلة الأساسية من خلال إظهار أن قدرة البشر على الإجابة عن الأسئلة تنخفض بشكل كبير عندما يتم حذف المصطلحات الأساسية من الأسئلة ، ثم نطور مصنفًا يحدد بشكل موثوق (90٪ متوسط الدقة) المصطلحات الأساسية في الأسئلة ويصنفها. أخيرًا ، نستخدم المصنف لإثبات أن فكرة ضرورة مصطلح السؤال تسمح بأحدث الحلول لضمان الجودة للأسئلة العلمية في المرحلة الابتدائية لاتخاذ قرارات أفضل وأكثر استنارة ، وتحسين الأداء بنسبة تصل إلى 5٪. مجموعة بيانات جديدة تضم أكثر من 2200 من المصطلحات الأساسية المُجمَّعة من مصادر جماهيرية والتي تم شرحها في الأسئلة العلمية.', 'fr': "Les systèmes de réponse aux questions (AQ) sont facilement distraits par des mots non pertinents ou redondants dans les questions, en particulier lorsqu'ils sont confrontés à des questions longues ou à plusieurs phrases dans des domaines difficiles. Cet article introduit et étudie la notion de termes de questions essentiels dans le but d'améliorer ces résolveurs d'assurance qualité. Nous illustrons l'importance des termes essentiels des questions en montrant que la capacité des humains à répondre aux questions diminue considérablement lorsque les termes essentiels sont éliminés des questions.Nous développons ensuite un classificateur qui identifie et classe de manière fiable (précision moyenne de 90\xa0%) de manière fiable (précision moyenne de 90\xa0%) et classe les termes essentiels dans les questions. Enfin, nous utilisons le classificateur pour démontrer que la notion d'essentialité d'un terme de question permet à un solveur d'assurance qualité de pointe pour les questions scientifiques de niveau élémentaire de prendre des décisions meilleures et plus éclairées, améliorant ainsi les performances jusqu'à 5\xa0%. Nous introduisons également un nouvel ensemble de données de plus de 2 200 éléments essentiels termes questions scientifiques annotées.", 'es': 'Los sistemas de respuesta a preguntas (QA) se distraen fácilmente con palabras irrelevantes o redundantes en las preguntas, especialmente cuando se enfrentan a preguntas largas o de varias frases en dominios difíciles. Este artículo presenta y estudia la noción de términos de preguntas esenciales con el objetivo de mejorar dichos solucionadores de control de calidad. Ilustramos la importancia de los términos de preguntas esenciales al mostrar que la capacidad de los seres humanos para responder preguntas disminuye significativamente cuando se eliminan los términos esenciales de las preguntas. A continuación, desarrollamos un clasificador que identifica y clasifica de manera confiable los términos esenciales en las preguntas (90% de precisión media). Por último, utilizamos el clasificador para demostrar que la noción de esencialidad del término de pregunta permite que un solucionador de control de calidad de última generación para preguntas científicas de nivel elemental tome decisiones mejores y más informadas, mejorando el rendimiento hasta en un 5%. También presentamos un nuevo conjunto de datos de más de 2,200 elementos esenciales de colaboración colectiva términos de preguntas científicas anotadas.', 'pt': 'Os sistemas de resposta a perguntas (QA) são facilmente distraídos por palavras irrelevantes ou redundantes em perguntas, especialmente quando confrontadas com perguntas longas ou com várias frases em domínios difíceis. Este artigo apresenta e estuda a noção de termos de questões essenciais com o objetivo de melhorar esses solucionadores de QA. Ilustramos a importância dos termos essenciais das perguntas mostrando que a capacidade dos humanos de responder às perguntas diminui significativamente quando os termos essenciais são eliminados das perguntas. Em seguida, desenvolvemos um classificador que identifica e classifica de forma confiável (90% de precisão média média) os termos essenciais nas perguntas. Finalmente, usamos o classificador para demonstrar que a noção de essencialidade do termo de questão permite que o solucionador de QA de última geração para questões de ciências de nível elementar tome decisões melhores e mais informadas, melhorando o desempenho em até 5%. um novo conjunto de dados de mais de 2.200 termos essenciais de crowdsourcing anotou questões científicas.', 'ja': '質問への回答（ QA ）システムは、特に難しいドメインで長いまたは複数文の質問に直面したときに、質問の中で無関係または冗長な単語によって気を散らされやすい。このようなQAソルバーを改善することを目標に、本質的な質問用語の概念を紹介し、研究する。私たちは、質問から必須用語が削除されると、人間の質問への回答能力が著しく低下することを示すことで、必須用語の重要性を示します。次に、質問で必須用語を確実に識別し、ランク付けする分類器を開発します（ 90 ％の平均精度）。最後に、私たちは分類子を使用して、質問用語の本質の概念が、初等科学レベルの質問のための最先端のQAソルバーがより良い、より情報に基づいた決定を行い、パフォーマンスを最大5%向上させることを実証します。また、2,200以上のクラウドソーシングされた本質的な用語の注釈付き科学の質問の新しいデータセットを導入します。', 'zh': '问答(QA)系统甚易,不关余单词,特当临难领多句时。 本末术语名,改进此QA求解器。 吾以明术语本末,人应会显降,以明术语要。 然后开一器,以地(90%之均)别名术语。 最后,以类器来证术语本之大概许于初级科学先进之QA求解器为愈善,愈明之策,而性能至5%。 引入一新数据集,其中含2,200数众包本术语,术语注科学问。', 'hi': 'प्रश्न उत्तर (क्यूए) सिस्टम प्रश्नों में अप्रासंगिक या अनावश्यक शब्दों से आसानी से विचलित हो जाते हैं, खासकर जब कठिन डोमेन में लंबे या बहु-वाक्य प्रश्नों का सामना करना पड़ता है। यह पेपर इस तरह के क्यूए सॉल्वरों में सुधार के लक्ष्य के साथ आवश्यक प्रश्न शब्दों की धारणा का परिचय और अध्ययन करता है। हम यह दिखाते हुए आवश्यक प्रश्न शब्दों के महत्व को स्पष्ट करते हैं कि प्रश्नों के उत्तर देने की मनुष्यों की क्षमता काफी कम हो जाती है जब आवश्यक शब्दों को प्रश्नों से समाप्त कर दिया जाता है। फिर हम एक क्लासिफायर विकसित करते हैं जो मज़बूती से (90% औसत परिशुद्धता का मतलब है) प्रश्नों में आवश्यक शब्दों की पहचान करता है और रैंक करता है। अंत में, हम क्लासिफायर का उपयोग यह प्रदर्शित करने के लिए करते हैं कि प्रश्न शब्द अनिवार्यता की धारणा प्राथमिक स्तर के विज्ञान प्रश्नों के लिए अत्याधुनिक क्यूए सॉल्वर को बेहतर और अधिक सूचित निर्णय लेने की अनुमति देती है, 5% तक प्रदर्शन में सुधार करती है। हम 2,200 से अधिक भीड़-स्रोत वाले आवश्यक शब्दों का एक नया डेटासेट भी पेश करते हैं जो एनोटेटेड विज्ञान प्रश्नों को एनोटेट करते हैं।', 'ru': 'Системы ответов на вопросы (QA) легко отвлекаются на ненужные или избыточные слова в вопросах, особенно когда сталкиваются с длинными или многословными вопросами в сложных областях. В настоящем документе вводится и изучается понятие существенных терминов вопросов с целью улучшения таких решателей QA. Мы иллюстрируем важность существенных терминов вопросов, показывая, что способность людей отвечать на вопросы значительно снижается, когда существенные термины исключаются из вопросов. Затем мы разрабатываем классификатор, который достоверно (90% средней точности) идентифицирует и ранжирует существенные термины в вопросах. Наконец, мы используем классификатор, чтобы продемонстрировать, что понятие существенности термина вопроса позволяет современному QA-решителю для вопросов науки элементарного уровня принимать лучшие и более обоснованные решения,улучшая производительность до 5%. Мы также вводим новый набор данных, состоящий из более чем 2200 аннотированных научных вопросов о существе краудсорсинга.', 'ga': 'Is furasta aird a tharraingt ar chórais freagartha ceisteanna (QA) ag focail neamhábhartha nó iomarcacha i gceisteanna, go háirithe nuair a bhíonn ceisteanna fada nó il-abairtí os comhair fearainn dheacra. Tugann an páipéar seo isteach agus déanann staidéar ar an nóisean de théarmaí riachtanacha ceiste agus é mar sprioc feabhas a chur ar a leithéid de réitigh QA. Léirímid an tábhacht a bhaineann le téarmaí riachtanacha ceisteanna trína thaispeáint go dtagann laghdú suntasach ar chumas daoine ceisteanna a fhreagairt nuair a bhaintear téarmaí riachtanacha amach as ceisteanna. Ansin forbróimid aicmitheoir a shainaithníonn agus a rangú go hiontaofa (meánchruinneas 90%) téarmaí riachtanacha i gceisteanna. Mar fhocal scoir, bainimid úsáid as an aicmitheoir chun a léiriú go gceadaíonn coincheap bunúsacht téarma ceiste an réiteoir QA úrscothach do cheisteanna eolaíochta bunrang chun cinntí níos fearr agus níos eolasaí a dhéanamh, ag feabhsú feidhmíochta suas le 5%. tacar sonraí nua de bhreis is 2,200 téarma bunriachtanach sluafhoinsithe ina raibh ceisteanna eolaíochta anótáilte.', 'ka': 'კითხვების პასუხი (QA) სისტემები ადვილად გადარწმუნებიან უფრო მნიშვნელოვანი ან უფრო მნიშვნელოვანი სიტყვებით, განსაკუთრებით, როცა ძალიან ან მრავალ სიტყვებით გა ეს წიგნის შესახებ და შესწავლობს მნიშვნელოვანი კითხვის სიტყვების შესახებ მიზეზით, რომელიც საკუთარი QA გაუკეთებელება. ჩვენ ახალგაზრდებით მნიშვნელოვანი კითხვის სიტყვების გასანიშვნელოვანობა, როცა ადამიანების შესაძლებლობა გაუკეთოთ კითხვების შესაძლებლობა მნიშვნელოვანია, რო შემდეგ ჩვენ კლასიფიკაციური განვითარებთ, რომელიც დარწმუნელად (90% ცოტა განსაზღვრება) იდენტიფიკაცის და წერებს მნიშვნელოვანი სიტყვებში. საბოლოოდ, ჩვენ კლასიფიკაციას გამოყენებთ, რომ კითხვის ტემისთვის წარმოდგენა, რომ QA წარმოდგენელი მეცნიერო კითხვებისთვის უფრო მეტი და უფრო ინფორმაციული გადაწყვება,შესაძლებლობას 5%. ჩვენ ასევე შევაჩვენეთ ახალი მონაცემების კონფიგურაცია, რომელიც უფრო მეტი 200-ზე მეტი მსოფლიო მუშაობელი კონფიგურაციები, რომელიც ამ', 'hu': 'A kérdésre válaszoló rendszereket könnyen elvonják a lényegtelen vagy redundáns szavak a kérdésekben, különösen, ha nehéz területeken hosszú vagy többmondatos kérdésekkel kell szembenézni. Ez a tanulmány bemutatja és tanulmányozza az alapvető kérdéses kifejezések fogalmát azzal a céllal, hogy fejlessze ezeket a minőségi megoldókat. Az alapvető kérdési kifejezések fontosságát illusztráljuk azzal, hogy megmutatjuk, hogy az emberek képessége jelentősen csökken a kérdések megválaszolására, ha az alapvető kifejezések kikerülnek a kérdésekből. Ezután kifejlesztünk egy osztályozót, amely megbízhatóan (90% átlagos pontosság) azonosítja és rangsorolja a lényeges kifejezéseket a kérdésekben. Végezetül az osztályozót használjuk annak bizonyítására, hogy a kérdéses kifejezés esszenciális fogalma lehetővé teszi a legkorszerűbb minőségi megoldó elemi szintű tudományos kérdések számára, hogy jobb és tájékozottabb döntéseket hozzon, és akár 5%-kal javítsa a teljesítményt. Bemutatunk egy új adatkészletet is, amely több mint 2200 közösségi forrásból származik, lényeges kifejezésekből áll, megjegyzett tudományos kérdésekkel.', 'el': 'Τα συστήματα απάντησης ερωτήσεων (QA) αποσπώνται εύκολα από άσχετες ή περιττές λέξεις σε ερωτήσεις, ειδικά όταν αντιμετωπίζουν ερωτήσεις μακράς διάρκειας ή πολλών προτάσεων σε δύσκολους τομείς. Η παρούσα εργασία εισάγει και μελετά την έννοια των βασικών όρων ερωτήσεων με στόχο τη βελτίωση αυτών των λύσεων QA. Επιδεικνύουμε τη σημασία των βασικών όρων ερωτήσεων δείχνοντας ότι η ικανότητα των ανθρώπων να απαντούν σε ερωτήσεις μειώνεται σημαντικά όταν οι βασικοί όροι εξαλείφονται από τις ερωτήσεις. Στη συνέχεια, αναπτύσσουμε έναν ταξινομητή που με αξιοπιστία (90% μέση ακρίβεια) προσδιορίζει και ταξινομεί τους βασικούς όρους σε ερωτήσεις. Τέλος, χρησιμοποιούμε τον κατηγοριοποιητή για να αποδείξουμε ότι η έννοια του όρου ουσιαστικότητα των ερωτήσεων επιτρέπει στον σύγχρονο λύτη QA για επιστημονικά ερωτήματα στοιχειώδους επιπέδου να λαμβάνει καλύτερες και πιο ενημερωμένες αποφάσεις, βελτιώνοντας την απόδοση μέχρι και 5%. Παρουσιάζουμε επίσης ένα νέο σύνολο δεδομένων πάνω από 2.200 βασικών όρων που σχολιάζουν επιστημονικά ερωτήματα.', 'lt': 'Question answering (QA) systems are easily distracted by irrelevant or redundant words in questions, especially when faced with long or multi-sentence questions in difficult domains.  This paper introduces and studies the notion of essential question terms with the goal of improving such QA solvers.  Mes iliustruojame esminių klausimų terminų svarbą įrodydami, kad žmogaus gebėjimas atsakyti į klausimus žymiai mažėja, kai iš klausimų pašalinamos esminės sąlygos. Tada parengiame klasifikatorių, kuris patikimai (vidutinis 90 proc. tikslumas) nustato ir klasifikuoja esminius klausimus. Galiausiai mes naudojame klasifikatorių, kad įrodytume, jog klausimų esmės sąvoka leidžia geriausiai pažangiam QA sprendžiamajam elementarinių mokslo klausimų klausimui priimti geresnius ir labiau informuotus sprendimus, pagerinti rezultatus iki 5 %. Taip pat įvedame naują duomenų rinkinį, kuriame yra daugiau kaip 2 200 iš visuomenės gautų esminių terminų, užfiksuotų mokslo klausimais.', 'it': "I sistemi di risposta alle domande (QA) sono facilmente distratti da parole irrilevanti o ridondanti nelle domande, specialmente quando si affrontano domande lunghe o multi-frase in domini difficili. Questo articolo introduce e studia la nozione di termini interrogativi essenziali con l'obiettivo di migliorare tali soluzioni di QA. Illustriamo l'importanza dei termini essenziali delle domande mostrando che la capacità degli esseri umani di rispondere alle domande diminuisce significativamente quando i termini essenziali vengono eliminati dalle domande. Sviluppiamo quindi un classificatore che identifica e classifica in modo affidabile (90% media precisione) i termini essenziali nelle domande. Infine, utilizziamo il classificatore per dimostrare che la nozione di essenzialità dei termini interrogativi consente a un risolutore di QA all'avanguardia per le domande scientifiche di livello elementare di prendere decisioni migliori e più informate, migliorando le prestazioni fino al 5%. Introducemo anche un nuovo set di dati di oltre 2.200 termini essenziali crowdsourcing annotati domande scientifiche.", 'ms': 'Question answering (QA) systems are easily distracted by irrelevant or redundant words in questions, especially when faced with long or multi-sentence questions in difficult domains.  Kertas ini memperkenalkan dan mempelajari idea terma soalan penting dengan tujuan untuk memperbaiki penyelesaian QA tersebut. Kami memperlihatkan kepentingan terma soalan penting dengan menunjukkan bahawa kemampuan manusia untuk menjawab soalan turun secara signifikan apabila terma penting dibuang daripada soalan. Kemudian kita mengembangkan pengklasifikasi yang boleh dipercayai (90% rata-rata ketepatan) mengenalpasti dan mengatur terma penting dalam soalan. Akhirnya, kami menggunakan pengukur untuk menunjukkan bahawa konsep istilah soalan penting membolehkan penyelesaian QA terbaik untuk soalan sains aras asas untuk membuat keputusan yang lebih baik dan lebih maklumat,meningkatkan prestasi sehingga 5%. We also introduce a new dataset of over 2,200 crowd-sourced essential terms annotated science questions.', 'kk': 'Сұрақ жауап беру (QA) жүйелері сұрақтардың күш не күш сөздерінің сұрақтарымен оңай айналдырылады, осымен қажетті домендерде ұзын немесе көп сөздер сұрақтарымен сұрақтарымен қатысты. Бұл қағаз QA шешімдерін жақсарту мақсатымен негізгі сұрақ терминдерінің ойын көрсетеді және зерттейді. Мынау сұрақтардың маңыздылығын көрсету үшін адамдардың сұрақтардың жауап беру мүмкіндігін сұрақтардан алып тастағанда маңызды сұрақтардың маңыздығын көрсетеді. Содан кейін сенімді (90% орташа дәл дәл дәл дәл) сұрақтардың негізгі тәртібін анықтайтын классификаторын құрамыз. Соңында, біз классификаторын қолданып, сұрақ терминінің негізгі тәсілдігі QA жасаушысының элементтік деңгейіндегі ғылым сұрақтарын жақсы және ақпаратты шешімдерді жасау үшін, әрекетті 5% деп жақсарту үшін Сонымен қатар, біз 2,200 көпшілік көпшілік көпшілікті негізгі терминдерді жаңа деректер жиынын таңдап береміз.', 'mk': "Системите за одговори на прашања (QA) лесно се одвлекуваат од нерелевантните или надлишните зборови во прашањата, особено кога се соочуваат со долги или мултиреченици прашања во тешки домени. This paper introduces and studies the notion of essential question terms with the goal of improving such QA solvers.  We illustrate the importance of essential question terms by showing that humans' ability to answer questions drops significantly when essential terms are eliminated from questions. Потоа развиваме класификатор кој веројатно (90 отсто просечна прецизност) идентификува и рангира основни термини во прашањата. Конечно, го користиме класификаторот за да демонстрираме дека идејата за суштински термин на прашање овозможува најсовремениот решител на QA за прашањата на основно ниво на науката да донесе подобри и поинформирани одлуки, подобрувајќи ја перформансата за до 5 отсто. Ние, исто така, воведуваме нови податоци од повеќе од 2.200 основни термини од публика кои ги анотираа научните прашања.", 'ml': 'ചോദ്യങ്ങളുടെ ഉത്തരം (ക്യൂഎ) സിസ്റ്റത്തിന്റെ ഉത്തരം ചോദ്യങ്ങള്\u200d എളുപ്പമുള്ള വാക്കുകള്\u200d വിവരങ്ങളില്\u200d വിവരങ്ങളാക്കുന്നു. പ്രത്യേക ഈ പേപ്പറില്\u200d പ്രധാനപ്പെട്ട ചോദ്യത്തിന്റെ ആവശ്യമുള്ള വാക്കുകളെ പരിചയപ്പെടുത്തുകയും ചെയ്യുന്നു പ്രധാനപ്പെട്ട ചോദ്യങ്ങളുടെ പ്രധാനപ്പെട്ടത് നമ്മള്\u200d വ്യക്തമാക്കുന്നു. മനുഷ്യരുടെ ഉത്തരം ചോദ്യങ്ങള്\u200dക്ക് ഉത്തരം നല്\u200dകാനുള പിന്നീട് നമ്മള്\u200d വിശ്വസ്തനായ ഒരു ക്ലാസ്ഫിഫറിനെ നിര്\u200dമ്മിക്കുന്നു. അതിന്റെ (90% അര്\u200dത്ഥം ശരാശരിയായ പരിഗണനം) ചോ അവസാനം, ചോദ്യത്തിന്റെ വാക്ക് പ്രധാനപ്പെട്ടതാണെന്ന് നമ്മള്\u200d ക്ലാസ്ഫിക്കര്\u200d ഉപയോഗിക്കുന്നത് ചോദ്യത്തിന്റെ അധികാരം ക്യൂഎ സ്റ്റേറ്റ് സ്റ്റേറ്റ 2,200 കൂടുതല്\u200d പ്രധാനപ്പെട്ട വാക്കുകളുടെ ഒരു പുതിയ വിവരങ്ങളും പരിചയപ്പെടുത്തുന്നു.', 'mt': "Is-sistemi tat-tweġiba għall-mistoqsijiet (QA) huma faċilment distratti minn kliem irrelevanti jew żejjed f’mistoqsijiet, speċjalment meta jiġu ffaċċjati mistoqsijiet twal jew b’ħafna sentenzi f’oqsma diffiċli. Dan id-dokument jintroduċi u jistudja l-kunċett ta’ termini essenzjali ta’ mistoqsijiet bil-għan li jittejbu dawn is-solventi tal-QA. Aħna nuru l-importanza tat-termini essenzjali tal-mistoqsijiet billi nuru li l-kapaċità tal-bnedmin li jwieġbu għall-mistoqsijiet tonqos b'mod sinifikanti meta t-termini essenzjali jiġu eliminati mill-mistoqsijiet. Imbagħad niżviluppaw klassifikatur li b’mod affidabbli (medja ta’ 90 % ta’ preċiżjoni medja) jidentifika u jikklassifika termini essenzjali f’mistoqsijiet. Fl-aħħar nett, aħna nużaw il-klassifikatur biex nippruvaw li l-kunċett ta’ terminu ta’ mistoqsija essenzjali jippermetti li s-soluzzjoni tal-QA l-aktar avvanzata għal kwistjonijiet xjentifiċi fuq livell elementari tieħu deċiżjonijiet aħjar u aktar infurmati, u ttejjeb il-prestazzjoni sa 5%. Aħna nintroduċu wkoll sett ġdid ta’ dejta ta’ aktar minn 2,200 terminu essenzjali minn sorsi ta’ nies annotati mistoqsijiet xjentifiċi.", 'mn': 'асуулт хариулт (QA) системүүд асуултуудад хамааралтгүй, дутагдалгүй үгүүд, ялангуяа хэцүү хэсэгт урт эсвэл олон өгүүлбэртэй асуултуудтай харьцуулахад амархан сэтгэгддэг. Энэ цаас QA шийдвэрлэгчдийг сайжруулах зорилго дээр үндсэн асуулт хэмжээний ойлголтыг илэрхийлж, судалдаг. Бид асуулт асуултын чухал чухал чухал зүйлийг харуулж, хүмүүсийн асуултаас хариулт өгөх чадварыг асуултаас хадгалагдах үед чухал зүйл бууруулж байна. Дараа нь бид итгэлтэй (дундаж дундаж тодорхойлолт 90% нь) асуулт дээр үндсэн тодорхойлолтыг тодорхойлж, хэлбэрийг тодорхойлж чадна. Эцэст нь бид асуултын үндсэн хэлбэрийг ашиглаж буй ангилалын шинжлэх ухааны асуулт дээр, илүү мэдээлэлтэй шийдвэр гаргах, үйл ажиллагааг 5% хүртэл сайжруулах боломжтой гэдгийг харуулахын тулд Мөн бид 2,200 гаруй олон хүмүүсийн үндсэн хэлбэрээр шинэ өгөгдлийн сангуудыг тайлбарлаж өгдөг.', 'no': 'Spørsmålsystemet (QA) er enkelt distraktert av uavhengige eller redundant ord i spørsmål, spesielt når det oppstod med lange eller fleire setningsspørsmål i vanskelege domene. Denne papiret introduserer og studerer ideen om nødvendige spørsmål med målet for å forbetra slike QA-løysar. Vi illustrerer viktigheten på grunnleggjande spørsmålsvilkår ved å visa at menneske kan svara på spørsmål slepp betydelig når grunnleggjande vilkår vert eliminert frå spørsmål. Vi utviklar så ein klassifiserer som tiltrukkeleg (90% gjennomsnittlig nøyaktig) identifiserer og rankerer viktige uttrykk i spørsmål. Til slutt bruker vi klassifiseringen for å demonstrere at noen av spørsmålstrykket er essentialitet tillet QA-løysar for elementær nivå vitenskapspunkt for å gjera betre og meir informerte beslutningar,forbedra utviklinga til 5%. Vi introduserer også ein ny dataset med over 2,200 nødvendige grunnleggjande uttrykk med vitenskapsførsmål.', 'pl': 'Systemy odpowiadania na pytania (QA) są łatwo rozpraszane przez nieistotne lub zbędne słowa w pytaniach, zwłaszcza w obliczu długich lub wielozadaniowych pytań w trudnych dziedzinach. Niniejszy artykuł wprowadza i bada pojęcie istotnych terminów pytań w celu poprawy takich rozwiązań jakości. Ilustrujemy znaczenie istotnych terminów pytania, pokazując, że zdolność ludzi do odpowiedzi na pytania znacznie spada, gdy istotne terminy są wyeliminowane z pytań. Następnie opracowujemy klasyfikator, który niezawodnie (90% średnia średnia precyzja) identyfikuje i klasyfikuje istotne terminy w pytaniach. Na koniec używamy klasyfikatora, aby wykazać, że pojęcie terminu istotność pytań pozwala najnowocześniejszym rozwiązywaczom jakości dla podstawowych pytań naukowych na podejmowanie lepszych i bardziej świadomych decyzji, poprawiając wydajność o nawet 5%. Wprowadzamy również nowy zestaw danych dotyczący ponad 2.200 zasadniczych terminów opartych na adnotacjach naukowych.', 'ro': 'Sistemele de răspuns la întrebări (QA) sunt ușor distrase de cuvinte irelevante sau redundante în întrebări, în special atunci când se confruntă cu întrebări lungi sau cu mai multe propoziții în domenii dificile. Această lucrare introduce și studiază noțiunea de termeni esențiali de întrebare cu scopul de a îmbunătăți astfel de soluționare a calității. Ilustrăm importanța termenilor esențiali de întrebare arătând că capacitatea oamenilor de a răspunde la întrebări scade semnificativ atunci când termenii esențiali sunt eliminați din întrebări. Apoi dezvoltăm un clasificator care identifică și clasifică în mod fiabil termenii esențiali în întrebări (90% medie de precizie). În cele din urmă, folosim clasificatorul pentru a demonstra că noțiunea de esențialitate a termenului de întrebare permite soluționarului de calitate de ultimă generație pentru întrebările științifice de nivel elementar să ia decizii mai bune și mai informate, îmbunătățind performanța cu până la 5%. Introducem, de asemenea, un nou set de date de peste 2.200 de termeni esențiali adnotați de întrebări științifice.', 'sr': 'Sistemi odgovora na pitanja (QA) se lako ometaju neophodnim ili redundantnim rečima na pitanjima, posebno kada se suočavaju sa dugim ili višerečenim pitanjima u teškim domenama. Ovaj papir predstavlja i proučava pojam temeljnih uslova pitanja sa ciljem poboljšanja takvih rješavača QA-a. Ilustriramo važnost osnovnih uslova pitanja pokazujući da sposobnost ljudi odgovora na pitanja značajno pada kada se osnovni uslovi eliminišu od pitanja. Zatim razvijamo klasifikatora koji vjerojatno (90% srednja prosječna preciznost) identifikuje i postavlja ključne uslove u pitanjima. Na kraju, koristimo klasifikatora kako bi pokazali da pojam rešenja QA-a iz pitanja omogućava rešenje države umjetnosti za pitanja nauke na osnovnoj nivou da donese bolje i informiranije odluke,poboljšavanje provedbe do 5%. Takoðe predstavljamo novi set podataka sa preko 2.200 temeljnih uslova koje su poduzele masovnim podacima annotirane nauène pitanja.', 'si': 'ප්\u200dරශ්න උත්තර (QA) පද්ධතිය ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක් විශේෂ වෙනුවෙන් ලේසියෙන් වි මේ පත්තුව ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ගැන අදහස් කරනවා සහ අධ්\u200dයාපනය කරනවා ඒ වගේ QA විස්තර කරණාකරුවන් අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ගැන අවශ්\u200dයය ප්\u200dරශ්නයක් පෙන්වන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ අපි පස්සේ විශ්වාසයෙන් විශ්වාසයෙන් විශ්වාසයෙක් විශ්වාස කරනවා (90% අමාර්\u200dයය අමාර්\u200dයය අමාර්\u200dයය) ප අන්තිමට, අපි ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විශ්වාස කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විශ්වාස කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් පට අපි අළුත් දත්ත සූදානයක් ප්\u200dරදේශ කරන්නේ අලුත් දේවල් සූදානම් 2,200 විතරයි මිනිස්සුන්ගේ අවශ්\u200dය වර', 'so': "Isticmaalka jawaabta su'aalaha (QA) waxaa si fudud looga wareejiyaa su'aalo aan suurtogal ahayn ama wax gaaban, khusuusan marka ay ka hor timaado su'aalo dheer ama ka badan goobaha dowlada adag. Kanu wuxuu soo bandhigayaa oo baranayaa fikrada su'aalaha muhiimka ah ee la jeedo hagaajinta qalabka QA. Waxaynu muujinnaa muhiimka ugu muhiimsan qoraalka su'aalaha ee muhiimka ah, marka lagu soo dejiyo su'aalaha in awoodda dadku uu jawaabo su'aalaha ay si muhiim ah u yaraadaan. Markaas waxaan horumarinaa fasax si aamin ah (90 boqolkiiba qiimaha wastaadka) oo u yaqaan si ay u hesho su'aalaha ugu muhiimsan. Ugu dambaysta, waxaynu isticmaalnaa fasaxa si aan u muujinno in fikrada su'aalaha muhiimka ah ay u fasaxaan xafiiska shaqada QA in ay sameeyaan go'aanka saxda iyo go'aanka la ogeysiiyo, in uu horumariyo tababarka ugu badnaanta 5 boqolkiiba. Sidoo kale waxaynu soo bandhignaa sawir cusub oo ay ka badan tahay 2,200 oo ka badan ee noocyada guud ee asalka cilmiga.", 'sv': 'Frågeställningssystem distraheras lätt av irrelevanta eller överflödiga ord i frågor, särskilt när de ställs inför långa eller flermeningsfrågor i svåra områden. Denna uppsats introducerar och studerar begreppet väsentliga frågetermer med målet att förbättra sådana QA-lösare. Vi illustrerar betydelsen av viktiga frågetermer genom att visa att människans förmåga att svara på frågor minskar avsevärt när väsentliga termer elimineras från frågor. Vi utvecklar sedan en klassificerare som tillförlitligt (90% genomsnittlig precision) identifierar och rankar viktiga termer i frågor. Slutligen använder vi klassificeraren för att visa att begreppet frågeterm essentialitet tillåter state-of-the-art QA-lösare för grundläggande vetenskapliga frågor att fatta bättre och mer informerade beslut, förbättra prestanda med upp till 5%. Vi introducerar också en ny datauppsättning med över 2 200 crowd-sourcing väsentliga termer kommenterade vetenskapliga frågor.', 'ur': 'سوال جواب دینے کی (QA) سیسٹم آسان ہے کہ سوال میں غیر اہم یا غیر اضافہ کلمات کے ذریعہ مشکل دومین میں درازی یا بہت سی کلمات کے سوال سے مشکل ہوتے ہیں۔ یہ کاغذ ایسے QA حل کرنے والوں کو بہتر کرنے کا موقع کے ذریعے ضروری سوال قوموں کی نظر پیش کرتا ہے اور پڑھتا ہے۔ ہم ضروری سوال قوموں کی اہم تعریف کو دکھاتے ہیں کہ انسانوں کی سؤال کا جواب دینے کی قابلیت ضروری سے دھوپ جاتی ہے جب ضروری قوموں کو سوال سے ٹال دیا جاتا ہے۔ پھر ہم ایک کلاسیٹر کو ایجاد کریں جو یقین رکھتا ہے (90% میانہ میانہ دقیق) سوال میں ضروری شرایطوں کو پہچان کرتا ہے اور درجے کرتا ہے۔ بالآخر، ہم کلاسیٹر کو استعمال کرتے ہیں کہ سوال کی اصلی قول کی نظریہ ہے کہ اصلی سطح سائنس سؤال کے لئے اچھی اور زیادہ اطلاعات کے فیصلہ کرنے کے لئے اجازت دیتا ہے، اور ہم نے 2,200 سے زیادہ اچھے ڈیٹ سٹ کو معرفی کر دیا ہے جن کی ضروری شرایطیں سائنس سؤال کرنے والی ہیں۔', 'ta': 'கேள்வி பதில் (QA) அமைப்புகள் சுலபமாக கேள்விகளில் இல்லாத அல்லது குறைவான வார்த்தைகளால் பிரச்சனைக்கப்படுகிறது, குறிப்பாக கடினமான கள இந்த காகிதத்தில் முக்கியமான கேள்வி விளக்கங்களின் கருத்துப் பொருளை அறிவிக்கும் மற்றும் முக்கியமான கேள்வி  முக்கியமான கேள்விகளின் முக்கியத்தை நாம் விளக்குகிறோம் கேள்விகளுக்கு பதில் கேட்கைகளின் ஆற்றல் முக்கியமாக குறைகிறத நம்பிக்கை கொள்ளும் வகுப்பாளரை நாம் உருவாக்குவோம் (90% என்றால் சராசரி துல்லியம்) கேள்விகளில் முக்கியமான விளக் இறுதியில், நாம் வகுப்பாளரை பயன்படுத்தி காண்பிக்கிறோம் கேள்வி சொல்லின் முக்கியமானது என்பதை குறிப்பிட வேண்டும் என்று காண்பிக்கும் பொழுது கேள்வி மு 2,200 க்கு மேற்பட்ட முக்கியமான விளக்கங்களை குறிப்பிட்ட அறிவியல் கேள்வி', 'uz': "Name Bu qogʻoz QA jadvallarini o'zgartirish maqsadida muhim savol so'zlarini o'rganish va o'rganadi. We illustrate the importance of essential question terms by showing that humans' ability to answer questions drops significantly when essential terms are eliminated from questions. Keyin biz muammiy darajaga (90% dan oddiy darajaga) aniqlanadi va savollar muhim darajada darajaga ega bo'ladi. Endi, biz muammolarni ko'rsatishimiz mumkin, savol so'zlarining muhimligi g'oyasi muhim QA sohasini o'zgartirish imkoniyatini asosiy darajada yaxshi va ko'proq haqida o'zgartirish imkoniyatlarini bajarishiga imkoniyat beradi va 5%-ga oshirish imkoniyatini oshirish mumkin. Biz esa 2,200 dan ortiq ma'lumotlar maʼlumotlar tarkibini o'rganamiz, ilmiy savollarni anglatadi.", 'vi': 'Câu trả lời câu hỏi (QA) dễ dàng bị phân tâm bởi những câu hỏi không liên quan hoặc những từ dư thừa, đặc biệt khi phải đối mặt với những câu hỏi dài hoặc nhiều câu trong những khu vực khó. Tờ giấy này đưa ra và nghiên cứu khái niệm về những điều khoản cần thiết với mục đích cải thiện chất giải quyết QA. Chúng tôi minh họa tầm quan trọng của những câu hỏi quan trọng bằng cách cho thấy khả năng trả lời của con người giảm đáng kể khi những điều khoản quan trọng bị loại khỏi câu hỏi. Sau đó chúng tôi phát triển một người phân loại có thể xác định được giá trị trung bình đáng tin cậy Cuối cùng, chúng tôi sử dụng người phân loại để chứng minh rằng khái niệm về tính thiết yếu nghi vấn cho phép giải quyết QA hiện đại cho những câu hỏi khoa học cấp thấp để đưa ra những quyết định tốt hơn và thông tin hơn, Chúng tôi cũng giới thiệu một bộ dữ liệu mới đầy hơn 2,200 từ nguồn tối thiểu, ghi chú các câu hỏi khoa học.', 'da': 'Spørgsmål besvarelsessystemer distraheres let af irrelevante eller overflødige ord i spørgsmål, især når de står over for lange eller flere sætninger spørgsmål i vanskelige områder. Denne artikel introducerer og undersøger begrebet væsentlige spørgsmålstegn med det formål at forbedre sådanne QA-løsere. Vi illustrerer vigtigheden af væsentlige spørgsmålstegn ved at vise, at menneskers evne til at besvare spørgsmål falder betydeligt, når væsentlige termer fjernes fra spørgsmål. Vi udvikler derefter en klassificering, der pålideligt (90% gennemsnitlig præcision) identificerer og rangerer væsentlige termer i spørgsmål. Endelig bruger vi klassificeringen til at demonstrere, at begrebet spørgsmålstegn væsentlighed gør det muligt for state-of-the-art QA-løser til elementære videnskabelige spørgsmål at træffe bedre og mere informerede beslutninger og forbedre ydeevnen med op til 5%. Vi introducerer også et nyt datasæt med over 2.200 crowd-sourcerede væsentlige termer kommenterede videnskabelige spørgsmål.', 'hr': 'Sistemi odgovora na pitanja (QA) se lako ometaju nepoznatim ili redundantnim riječima na pitanjima, posebno kada se suočavaju s dugim ili višerečenim pitanjima u teškim područjima. Ovaj papir predstavlja i proučava pojam temeljnih uvjeta pitanja s ciljem poboljšanja takvih rješavača QA-a. Ilustriramo važnost temeljnih uvjeta pitanja pokazujući da sposobnost ljudi odgovora na pitanja značajno pada kada se temeljni uvjeti eliminiraju iz pitanja. Zatim razvijamo klasifikatora koji vjerojatno (90% srednja prosječna preciznost) identificira i postavlja ključne uvjete na pitanja. Na kraju, koristimo klasifikatora kako bi pokazali da pojam temeljnosti pitanja omogućava rješavač stanja umjetnosti QA-a za pitanja znanosti na osnovnoj razini da donese bolje i informiranije odluke,poboljšavanje učinka do 5%. Također predstavljamo novi sastanak podataka s preko 2.200 temeljnih uslova koje su dobile masovne podatke annotirane naučne pitanja.', 'nl': 'Vragenantwoordsystemen (QA) worden gemakkelijk afgeleid door irrelevante of overbodige woorden in vragen, vooral wanneer ze worden geconfronteerd met lange of meerzinnige vragen in moeilijke domeinen. Dit artikel introduceert en bestudeert het begrip essentiële vraagtermen met als doel het verbeteren van dergelijke QA-oplossers. We illustreren het belang van essentiële vraagtermen door aan te tonen dat het vermogen van mensen om vragen te beantwoorden aanzienlijk afneemt wanneer essentiële termen uit vragen worden geëlimineerd. Vervolgens ontwikkelen we een classificator die op betrouwbare wijze (90% gemiddelde precisie) essentiële termen in vragen identificeert en rangschikt. Ten slotte gebruiken we de classificator om aan te tonen dat het begrip vraagterm essentiality state-of-the-art QA solver voor elementaire wetenschappelijke vragen toestaat betere en meer geïnformeerde beslissingen te nemen, waardoor de prestaties met maximaal 5%. We introduceren ook een nieuwe dataset van meer dan 2.200 crowdsourced essentiële termen geannoteerde wetenschappelijke vragen.', 'bg': 'Системите за отговор на въпроси лесно се разсейват от незначими или излишни думи във въпросите, особено когато са изправени пред въпроси с дълги или многоизречения в трудни области. Настоящата статия представя и изучава понятието за основни термини на въпросите с цел подобряване на такива решаващи въпроси. Ние илюстрираме важността на основните въпросителни термини, като показваме, че способността на хората да отговарят на въпроси намалява значително, когато съществените термини са елиминирани от въпросите. След това разработваме класификатор, който надеждно (90% средна точност) идентифицира и подрежда основните термини във въпросите. Накрая, използваме класификатора, за да демонстрираме, че понятието за същност на въпросния термин позволява на най-съвременните решаващи въпроси за оценка на качеството на елементарно ниво научни въпроси да вземат по-добри и по-информирани решения, подобрявайки ефективността с до 5%. Също така въвеждаме нов набор от данни от над 2200 основни термини с анотирани научни въпроси.', 'de': 'Fragebeantworter (QA)-Systeme werden leicht durch irrelevante oder redundante Wörter in Fragen abgelenkt, insbesondere wenn sie mit langen oder mehrsätzigen Fragen in schwierigen Bereichen konfrontiert werden. In diesem Beitrag wird der Begriff essentieller Fragebegriffe vorgestellt und untersucht, mit dem Ziel, solche QA-Löser zu verbessern. Wir verdeutlichen die Bedeutung essentieller Fragebegriffe, indem wir zeigen, dass die Fähigkeit des Menschen, Fragen zu beantworten, deutlich sinkt, wenn essentielle Begriffe aus Fragen eliminiert werden. Anschließend entwickeln wir einen Klassifikator, der zuverlässig (90% mittlere Präzision) wesentliche Begriffe in Fragen identifiziert und rangiert. Abschließend verwenden wir den Klassifikator, um zu demonstrieren, dass der Begriff der Fragenbegriffenheit es einem hochmodernen QA-Solver ermöglicht, bessere und fundiertere Entscheidungen zu treffen und die Leistung um bis zu 5%. Wir stellen auch einen neuen Datensatz von über 2.200 crowdsourcing essenziellen Begriffen mit Anmerkungen zu wissenschaftlichen Fragen vor.', 'id': 'Question answering (QA) systems are easily distracted by irrelevant or redundant words in questions, especially when faced with long or multi-sentence questions in difficult domains.  Kertas ini memperkenalkan dan mempelajari gagasan dari istilah pertanyaan penting dengan tujuan untuk memperbaiki penyelesaian QA tersebut. Kami memperlihatkan penting istilah pertanyaan penting dengan menunjukkan bahwa kemampuan manusia menjawab pertanyaan turun secara signifikan ketika istilah penting dihapus dari pertanyaan. Kemudian kita mengembangkan sebuah klasifikasi yang dapat dipercaya (90% rata-rata presisi) mengidentifikasi dan mengatur istilah penting dalam pertanyaan. Akhirnya, kami menggunakan klasifikasi untuk menunjukkan bahwa konsep istilah pertanyaan esensi memungkinkan penyelesaian QA terbaik untuk pertanyaan ilmu dasar untuk membuat keputusan yang lebih baik dan lebih informasi,meningkatkan prestasi hingga 5%. Kami juga memperkenalkan dataset baru dari lebih dari 2.200 terma penting sumber kerumunan yang menyatakan pertanyaan ilmu pengetahuan.', 'ko': '퀴즈 시스템은 문제에서 상관없거나 불필요한 단어에 의해 주의력을 분산시키기 쉽다. 특히 어려운 분야에서 긴 문장이나 여러 문장의 문제를 만날 때다.본고는 이러한 QA 해결자의 능력을 향상시키기 위해 기본적인 문제 용어의 개념을 소개하고 연구했다.우리는 기본 용어가 문제에서 삭제될 때 인류가 문제에 대답하는 능력이 현저히 떨어진다는 것을 보여줌으로써 기본 용어의 중요성을 설명한다.그리고 우리는 문제의 관건적인 용어를 신뢰할 수 있는(90%의 평균 정밀도) 식별하고 정렬할 수 있는 분류기를 개발했다.마지막으로 우리는 분류기를 사용하여 문제 용어의 중요성을 증명하는 개념을 사용하여 가장 선진적인 초급 과학 문제인 QA 해산기가 더욱 좋고 현명한 결정을 할 수 있도록 하고 성능을 5%까지 향상시켰다.우리는 2200여 개의 패키지 기본 용어 주석 과학 문제를 포함하는 새로운 데이터 집합도 소개했다.', 'fa': 'سیستم\u200cهای پاسخ سوال (QA) به آسانی توسط کلمات بی\u200cاثر یا بی\u200cاثر در سوالات، مخصوصا وقتی با سوالات طولانی یا زیادی از جمله\u200cها در دامنهای سخت روبرو می\u200cشوند. این کاغذ مفهوم اصلی از شرایط سوال با هدف بهتر کردن این حلگران QA را معرفی می کند و مطالعه می کند. ما اهمیت اصلی از شرایط سوال را نشان می دهیم با نشان دادن که توانایی انسان به جواب سوال ها در زمانی که شرایط اصلی از سوال حذف می شوند، به طور معنی می افتد. سپس ما یک راهنمایی را توسعه می\u200cکنیم که به یقین (۹۰ درصد دقیق متوسط) شرایط اصلی را در سوال شناسایی می\u200cکند و درجات می\u200cدهد. بالاخره، ما از محرمانه استفاده می\u200cکنیم تا نشان دهیم که نظر اصلی از اصطلاح سوال اجازه می\u200cدهد حلگر ایالت هنری QA برای سوالات علمی طبقه اصلی تا تصمیم\u200cهای بهتر و اطلاعات بیشتری انجام دهند، ما همچنین یک مجموعه اطلاعات جدید را معرفی می کنیم که بیش از ۲۰۰۰ شرایط اصلی از جمعیت به سوالات علمی مشخص شده است.', 'sw': 'Mfumo wa maswali ya kujibu (QA) unachanganywa kirahisi na maneno yasiyo na maana yanayopungua katika maswali, hususani pale wanapokutana na maswali mengi au ya hukumu mbalimbali katika maeneo ngumu. Papa hii inaonyesha na kutafiti dhana ya maana ya swali muhimu kwa lengo la kuboresha ufumbuzi wa aina hiyo wa QA. Tunaelezea umuhimu wa maneno muhimu ya swali kwa kuonyesha kuwa uwezo wa kujibu maswali yanapungua kwa kiasi kikubwa pale muhimu huondolewa kutoka maswali. Kisha tunaendelea kundi linaloaminika (asilimia 90 yenye wastani wa wastani) linaonyesha na kuweka rangi muhimu katika maswali. Mwisho, tunatumia mwangazaji kuonyesha kwamba dhana ya neno la maswali muhimu inaruhusu tatizo la utatuzi wa hali ya sanaa la QA kwa maswali ya msingi ya sayansi ili kufanya maamuzi bora na zaidi ya taarifa, kuboresha utendaji kwa asilimia 5. Pia tunaonyesha seti mpya ya taarifa za zaidi ya maneno ya msingi ya watu 2,200 yanayoibua maswali ya sayansi.', 'am': "የጥያቄ መልስ (QA) ስርዓቶች በተጨማሪው ግንኙነቶች ውስጥ ብዙ ወይም በብዙ ድረ ገጽ ጥያቄዎችን በመቀበል በቀላል እና በጥያቄ ቃላት ይታወሳሉ፡፡ ይህ ገጽ የጠያቂው ጥያቄ ግንኙነት የዚህን የQA ተቃውሞ በማሻሻል ጉዳይ ያስተምራል፡፡ We illustrate the importance of essential question terms by showing that humans' ability to answer questions drops significantly when essential terms are eliminated from questions. በኋላም የሚታመን (90 በመቶ የሚያህል ጥያቄ) የሚያሳውቃትን እናሳውቃለን፡፡ በመጨረሻው፣ የጥያቄ ቃላት ግንኙነት ግንኙነት የ-አዲስ የዩኤን ጉዳይ ለጥያቄ ጥያቄ ትክክለኛ እና የበለጠ ማስታወቂያ ውይይቶችን ለማድረግ እና ማሳየት የሚችሉትን ጥያቄዎችን ለማስታወቅ እና ለማሳየት እና ለማስታወቂያ ውይይቶችን ለማድረግ እንችላለን፡፡ ከ2,200 በላይ የሕዝብ አዳዲስ የውጤት ጥያቄዎችን እናስታውቃለን፡፡", 'tr': 'Sorag jogaplary (QA) sistemalary soraglaryň ýüzünde hiç hili möhüm ýa-da ýok sözleri bilen aňsatlyk bilen täsirlenýär, ýöne uzak ýa-da köp sözleşik soraglary bilen kynlaşdyrylyp durýandyr. Bu kagyz şu ýaly QA çözümlerini geliştirmek maksady bilen esasy soraglaryň düşünmesini tanaýar we öwredýär. Biz insanların sorulara cevap vermek için önemli soru terimlerinin önemini gösterip, önemli terimlerin sorulardan yok edildiğini gösteriyoruz. Sonra güvenilir bir klasifikatör geliştirdik (90% orta derece dikkati) sorular içinde önemli dereceleri tanıtır ve sıraylaştırır. Soňunda, biz klasifikatçyny ulanýarys soragy termynyň esasy ugurlaryna görkezmek üçin soraglaryň durumynyň üstüne degişli we daha bilgili kararlaryny gowurak etmek üçin 2%-a çevrilýäris. Biz hem 2,200-den gowy adam hasaplanýan hasaplary bilen tanyşdyrýarys.', 'af': "Vraog antwoord (QA) stelsels word maklik deur onbelangrik of rooi woorde in vrae afgewys, veral wanneer met lank of multi-seting vrae in moeilike domeine aangesig is. Hierdie papier introduseer en ondersoek die nodige vraagterme met die doel om sodanige QA oplosserers te verbeter. Ons illustreer die belangrikheid van nuwe vraagterme deur te wys dat mense se moontlikheid om vraagte te te antwoord val betekenlik wanneer nuwe terme van vraagte verwyder word. Ons ontwikkel dan 'n klassifiseerder wat vertroulik (90% gemiddelde gemiddelde presisie) identifiseer en rang behoorlike terme in vrae. Eindelik gebruik ons die klassifiseerder om te wys dat die noisie van vraagterme esensiealiteit toelaat staat van die kunstenaar QA-oplosser vir elementeerde vlak wetenskappye vrae om beter en meer inligte besluite te maak,beter presisie tot by 5%. Ons introduseer ook 'n nuwe datastel van meer 2,200 skare-geboorte nuwe bedrywe wat wetenskappyvrae aangetrek het.", 'az': 'sual cavab vermək sistemləri suallarda çox vaxtlı və çox cümləli suallar üzərində çox çətin sahələrdə üz tutduqları zaman asanlaşdırılmışdır. Bu kağıt böyük QA çözücülərini yaxşılaşdırmaq məqsədilə əsas sual şəkillərinin fikrini təşkil edir və təhsil edir. İnsanların suallarına cavab vermək bacarığı sualların məqsədilə məqsədilə məqsədil şəkillərin məqsədilə çəkilməsini göstərdik. Sonra güvenilir olaraq (90% orta dəqiqliyi) suallarda mövcud şəkilləri tanıyır və dərəcələr çəkir. Sonunda, biz seçənçisini istifadə edirik ki, sual teriminin əslində QA çözücüsü ilk səviyyə elmi suallarına daha yaxşı və daha bilgili kararlar vermək üçün, performansını 5%-ə qədər yaxşılaşdırmağa imkan verir. Biz həmçinin 2.200-dən artıq qövmünün məxluqatı olan yeni verilən qutusunu təşkil edirik.', 'sq': "Sistemet që përgjigjen pyetjeve (QA) janë lehtë të shpërngulur nga fjalët e papërshtatshme apo të tepruara në pyetje, veçanërisht kur ndeshen me pyetje të gjata apo me shumë fjalë në fusha të vështira. Ky dokument fut dhe studion konceptin e termave thelbësore të pyetjeve me qëllim përmirësimin e zgjidhjeve të tilla QA. Ne ilustrojmë rëndësinë e termave thelbësore të pyetjeve duke treguar se aftësia e njerëzve për t'u përgjigjur pyetjeve bie ndjeshëm kur termat thelbësore eliminohen nga pyetjet. Pastaj zhvillojmë një klasifikues që në mënyrë të besueshme (90% mesatare presion) identifikon dhe rendit termat thelbësore në pyetje. Më në fund, ne përdorim klasifikuesin për të demonstruar se koncepti i termit të pyetjeve thelbësore lejon zgjidhësin e QA më të lartë për pyetjet e nivelit elementar shkencor për të marrë vendime më të mira dhe më të informuara, duke përmirësuar performancën me deri në 5%. Ne gjithashtu paraqesim një grup të ri të dhënash prej mbi 2,200 termash thelbësorë të burimeve të turmës që anotojnë pyetje shkencore.", 'bn': 'প্রশ্নের উত্তর (কিউএ) সিস্টেম সহজে বিভ্রান্ত হয় প্রশ্নের ব্যাপারে প্রশ্নের ব্যাপারে বিভ্রান্ত হয়, বিশেষ করে যখন কঠিন ডোমেনে দীর্ এই কাগজটি প্রশ্নের গুরুত্বপূর্ণ শর্তের ধারণা উপস্থাপন করে এবং গবেষণা করে যাচ্ছে কিউএ সমাধানকে উন্নত করার লক্ষ্যে। আমরা প্রশ্নের মূল শর্তের গুরুত্বপূর্ণ বিষয়টি ব্যাখ্যা করি যে মানুষের প্রশ্নের উত্তর দেয়ার ক্ষমতা গুরুত্বপূর্ণ যখন প্রশ্ন থ তারপর আমরা একটি শ্রেণীবিষয়ক উন্নয়ন করি যা বিশ্বাস করে (৯০% মানে গড় পসিসিট) চিহ্নিত করে এবং প্রশ্নের মূল্যবান শর্তে  Finally, we use the classifier to demonstrate that the notion of question term essentiality allows state-of-the-art QA solver for elementary-level science questions to make better and more informed decisions,improving performance by up to 5%. আমরা একই সাথে ২,২০০০ জনসংখ্যার প্রধান বিজ্ঞানের প্রশ্নের একটি নতুন তথ্য সংক্রান্ত প্রদান করেছি।', 'hy': 'Հարցերին պատասխանելու համակարգերը հեշտությամբ շեղվում են անկարևոր կամ անհրաժեշտ բառերով հարցերում, հատկապես երբ հանդիպում են երկար կամ բազմապատասխանական հարցերին դժվար ոլորտներում: Այս հոդվածը ներկայացնում է և ուսումնասիրում է հիմնական հարցահանգամանքների գաղափարը, որպեսզի բարելավեն այդ QA լուծողները: Մենք ներկայացնում ենք հիմնական հարցի տերմինների կարևորությունը ցույց տալով, որ մարդկանց հարցերին պատասխանելու ունակությունը նշանակալիորեն նվազում է, երբ հիմնական տերմիները հեռացվում են հարցերից: We then develop a classifier that reliably (90% mean average precision) identifies and ranks essential terms in questions.  Վերջապես, մենք օգտագործում ենք դասակարգիչը, որպեսզի ապացուցենք, որ հարցահանդեպ տերմինի էության գաղափարը թույլ է տալիս լավագույն QA լուծողին տարրական մակարդակի գիտական հարցերի համար ավելի լավ և ավելի տեղեկացված որոշումներ կայացնել, բարելավելով արդյունքը մինչև 5 We also introduce a new dataset of over 2,200 crowd-sourced essential terms annotated science questions.', 'ca': "Els sistemes de resposta a preguntes (QA) es distraen fàcilment per paraules irrelevants o redundants en preguntes, especialment quan s'enfronten a preguntes llargues o multifrases en dominis difícils. Aquest paper introdueix i estudia la noció de termes essencials de preguntes amb l'objectiu de millorar aquests solucions de QA. Illustrem l'importància dels termes essencials de preguntes mostrant que la capacitat de resposta a preguntes dels humans disminueix significativament quan els termes essencials s'eliminen de les preguntes. Després desenvolupem un classificador que identifica i classifica de manera fiable (mitjana de precisió) termes essencials en preguntes. Finalment, utilitzem el classificador per demostrar que la noció de terme de qüestió essencial permet que el solucionador de QA més avançat per a qüestions científices a nivell elementar prengui decisions millors i més informades,millorant el rendiment fins al 5%. També introduïm un nou conjunt de dades de més de 2.200 termes essencials d'una multitud anotats preguntes científices.", 'bs': 'Sistemi odgovora na pitanja (QA) se lako ometaju nevažnim ili redundantnim riječima na pitanjima, posebno kada se suočavaju sa dugim ili višerečenim pitanjima u teškim oblastima. Ovaj papir predstavlja i proučava pojam temeljnih uslova pitanja sa ciljem poboljšanja takvih rješavača QA-a. Ilustriramo važnost ključnih uvjeta pitanja pokazujući da sposobnost ljudi odgovora na pitanja značajno pada kada se ključni uvjeti eliminiraju iz pitanja. Zatim razvijamo klasifikatora koji vjerojatno (90% srednja prosječna preciznost) identificira i postavlja ključne uvjete u pitanjima. Na kraju, koristimo klasifikatora kako bi pokazali da pojam temeljnosti pitanja omogućava rješavač države umjetnosti QA-a za pitanja znanosti na osnovnoj nivou da donese bolje i informiranije odluke,poboljšavanje učinka do 5%. Također predstavljamo novi set podataka sa preko 2.200 temeljnih uslova koje su dobile masovne podatke annotirane naučne pitanja.', 'cs': 'Systémy odpovědí na otázky (QA) jsou snadno rozptýleny irelevantními nebo nadbytečnými slovy v otázkách, zejména když čelí dlouhým nebo vícevětovým otázkám v obtížných oblastech. Tento článek představuje a studuje pojem základních otázek s cílem zlepšit tyto řešitele QA. Dokazujeme význam základních otázek tím, že schopnost lidí odpovědět na otázky výrazně klesá, když jsou základní pojmy z otázek eliminovány. Následně vyvineme klasifikátor, který spolehlivě (90% průměrná přesnost) identifikuje a řadí základní termíny v otázkách. Na závěr používáme klasifikátor k prokázání, že pojem esenciality otázek umožňuje nejmodernějším řešitelům QA pro základní vědecké otázky učinit lepší a informovanější rozhodnutí, což zlepšuje výkon až o 5%. Představujeme také novou datovou sadu více než 2.200 crowdsourcingových základních termínů anotovaných vědeckých otázek.', 'et': 'Küsimustele vastamise süsteeme häirivad kergesti ebaolulised või liigsed sõnad küsimustes, eriti kui tegemist on rasketes valdkondades pikkade või mitme lausega küsimustega. Käesolevas dokumendis tutvustatakse ja uuritakse oluliste küsimuste mõistet eesmärgiga parandada selliseid kvaliteedi tagamise lahendajaid. Me illustreerime oluliste küsimusmõistete tähtsust, näidates, et inimeste võime vastata küsimustele väheneb oluliselt, kui olulised terminid küsimustest eemaldatakse. Seejärel töötame välja klassifitseerija, mis usaldusväärselt (90% keskmine täpsus) tuvastab ja järjestab olulised terminid küsimustes. Lõpuks kasutame klassifitseerijat, et näidata, et küsimusmõiste essentsiaalsus võimaldab algtaseme küsimuste kvaliteedi tagamise lahendajal teha paremaid ja teadlikumaid otsuseid, parandades tulemuslikkust kuni 5%. Lisaks tutvustame uut andmekogumit, mis sisaldab enam kui 2200 ühisallikaga seotud olulisi termineid, märgitud teadusküsimusi.', 'fi': 'Kysymyksiin vastaaminen (QA) -järjestelmät häiriintyvät helposti epäolennaisilla tai tarpeettomilla sanoilla kysymyksissä, erityisesti kun on kyse pitkistä tai monilauseisista kysymyksistä vaikeilla aloilla. Tässä työssä esitellään ja tutkitaan keskeisten kysymystermin käsitettä tavoitteena parantaa laadunvarmistuksen ratkaisijoita. Esitämme olennaisten kysymysterminien merkitystä osoittamalla, että ihmisten kyky vastata kysymyksiin laskee merkittävästi, kun olennaisia termejä poistetaan kysymyksistä. Tämän jälkeen kehitämme luokittelijan, joka luotettavasti (90% keskiarvotarkkuus) tunnistaa ja sijoittaa keskeiset termit kysymyksissä. Lopuksi käytämme luokittelijaa osoittaaksemme, että kysymystermin olennaisuuden käsite mahdollistaa nykyaikaisen laadunvarmistuksen ratkaisijan perustekniikan kysymyksissä tehdä parempia ja tietoisempia päätöksiä parantaen suorituskykyä jopa 5%. Esittelemme myös uuden aineiston, jossa on yli 2 200 joukkolähdettä sisältävää olennaista termiä, joissa on selityksiä tiedekysymyksiin.', 'jv': 'Sugeng-responseng (KA) sistem sing di akeh veasa nek akeh basa sing ora nggawe pergunakake awak dhéwé kuwi mau, sithik iso nguasai kapan langgar o akeh-juwisan sing apik lan akeh-juwisan sing apik dhéwé. Perusahaan iki dadi nggunakaé karo dipunangé perusahaan kuwi mau sing bisa nggawe gerakan kanggo nggawe barang iki luwih apik. Awak dhéwé éntuk cara sing dikarepaké pergunakan anyar sing dikarepaké awak dhéwé, nik awak dhéwé nggambar barang maning. Awak dhéwé éntuk kelas sing ditambah saben nggawe layang-saben (60% kuwi kesempatan)nggawe lan basa sing ditambah layang lan singular-saben Tulung, awak dhéwé menehi kelas telu kanggo bisa ngomong nik, ngerasahan perusahaan kelas barang kelas barang nggawe barang kelas-layang Awak dhéwé éntuk nggawe datasing sing sing luwih kanggo langgar 2.200 sing tukang sing dibutuhke sing nyimpen tur angel.', 'ha': "Sura'ar tambaya (QA) na shawarar su da sauƙi ko kuma masu sauna cikin su masu tambayar, hasa'a, idan an haɗa maswali masu tsawo ko masu sauri cikin wurãren kwanan. Wannan takardan na ƙara shi kuma yana karanta fikon maganar masĩfa na muhimu da goan ya gyãra wa wannan QA-solver. Tuna bayyana muhimmin maganar tambayi masu muhimu da za'a nũna awon mutane su karɓa wa tambayar za'a ƙara da muhimu idan an goge muhimu daga tambayar. Sa'an nan kuma za Mu ƙãga wani mai fassara wanda yana iya aminci (ma'anar tsakanin tsakanin 90%) na gane kuma yana da daraja muhimu a cikin masu tambayar. Haƙĩƙa, Munã amfani da mai fassarwa dõmin Mu nuna kafin kalma na tambaya cewa muhimmi na yarda da mai sola halin-na-QA wa masu tambayar masu sakan da ƙanƙanci ya sami-matsayin yaƙin ya sami mafiya da masu sani, kuma yana ƙara fasalin da up to 5%. Kayya, Munã ƙara wani dangani na jumla da takwai 2,200 ga mutane da aka halatar da su masu sakin da aka sani.", 'sk': 'Sistemi za odgovarjanje na vprašanja (QA) zlahka odvrnejo nepomembne ali odvečne besede v vprašanjih, zlasti če se soočajo z dolgimi ali večstavkovnimi vprašanji na težkih področjih. Ta prispevek uvaja in proučuje pojem bistvenih vprašanj z namenom izboljšanja takšnih reševalcev kakovosti. Pomembnost bistvenih vprašanj ponazarjamo tako, da pokažemo, da se sposobnost človeka odgovarjanja na vprašanja znatno zmanjša, ko se bistveni izrazi izločijo iz vprašanj. Nato razvijamo klasifikator, ki zanesljivo (90% povprečna natančnost) identificira in razvrsti bistvene izraze v vprašanjih. Nazadnje uporabljamo klasifikator za dokazovanje, da pojem ključnosti izraza vprašanja omogoča najsodobnejšemu reševalcu kakovosti za znanstvena vprašanja osnovne ravni sprejemanje boljših in bolj informiranih odločitev, s čimer izboljšamo uspešnost do 5%. Predstavljamo tudi nov nabor podatkov, ki vsebuje več kot 2.200 bistvenih izrazov množičnega vira z oznakami znanstvenih vprašanj.', 'he': 'מערכות תשובות לשאלות (QA) מוסיקות בקלות על ידי מילים לא רלוונטיות או מוגזמות בשאלות, במיוחד כאשר מתמודדות עם שאלות ארוכות או רבות משפטים בתחומים קשים. העבודה הזו מציגה ומחקרת את הרעיון של תנאי שאלות חיוניות עם המטרה לשפר פתרוני QA כאלה. אנחנו מציגים את חשיבות תנאי שאלות חיוניות על ידי להראות שיכולת האדם לענות על שאלות נופלת באופן משמעותי כאשר תנאי חיוניים מוסרים משאלות. ואז אנחנו מפתחים מסווג שבאמון (90% מדויק ממוצע ממוצע) מזהה ומורג תנאים חיוניים בשאלות. סוף סוף, אנו משתמשים במקלאסיטור כדי להוכיח שהרעיון של מונח שאלה חיוניות מאפשר לפתור QA מצוין ביותר עבור שאלות מדעיות ברמה יסודית אנחנו גם מציגים קבוצת נתונים חדשה של יותר מ-2,200 מונחים חיוניים ממקור קהל שמכתבים שאלות מדעיות.', 'bo': 'ཡིག་གཟུགས་ལན་གསལ་བ(QA)མ་ལག་གི་དྲི་ཚིག་འདྲི་ཚིག་ནང་དུ་ཕན་མེད་པ་ཡང་ན་མང་པོ་ཞིག་གིས་བསམ་བློ་གཏོང་མ་ཐུབ་པ་ཡིན། ཤོག ང་ཚོས་རྒྱ་ནག་གི་ཆེད་དུ་གལ་ཆེ་བའི་དྲི་ཚིག་དག་གི་གལ་ཆེན་ངོ་སྟོན་བྱེད་ན། མིའི་རྒྱུ་མཚན་གྱི་ཐབས་ཤེས་ལན འོན་ཀྱང་། ང་ཚོའི་དྲི་ཚིག་ནང་དུ་བློ་གཏོང་རྩིས་གཏོང་མཁན་ཞིག་ཆགས་བྱེད་ཀྱི་ཡོད། མཐའ་མར་ང་ཚོས་དབྱེ་བ་འདི་ལག་ལེན་འཐབ་པའི་བརྗོད་རིམ་གྱི་གནད་སྡུད་མིན་པའི་དོན་དག་གཙོ་རིམ་གནས་སྟངས་དང་གནད་སྡུད་མིན་པའི་ཚན་རིག་གནད་དོན་དག་ ང་ཚོས་ཀྱང་དམངས་གཙོ་ཅན་གྱི་གནད་སྡུད་མིག་༢༠༠་ཙམ་གྱི་ནང་དུ་ཡོད་པའི་རྣམ་གྲངས་འབྲེལ་བ་ཞིག'}
{'en': 'Top-Rank Enhanced Listwise Optimization for Statistical Machine Translation', 'ar': 'تحسين قائمة محسّن من الدرجة الأولى للترجمة الآلية الإحصائية', 'pt': 'Otimização de lista aprimorada de alto nível para tradução automática estatística', 'es': 'Optimización de listas mejorada de primer nivel para la traducción automática estadística', 'fr': 'Optimisation améliorée au niveau de la liste pour la traduction automatique statistique', 'hi': 'सांख्यिकीय मशीन अनुवाद के लिए शीर्ष रैंक एन्हांस्ड सूचीवार अनुकूलन', 'ja': '統計的機械翻訳のためのトップランクの拡張リスト型最適化', 'zh': '计机器翻译之顶级增强型列优化', 'ru': 'Улучшенная по списку оптимизация верхнего ранга для статистического машинного перевода', 'ga': 'Barr-rangú Barrfheabhsaithe Listwise Optamaithe le haghaidh Aistriúcháin Meaisín Staidrimh', 'ka': 'Name', 'hu': 'Legjobb rangú továbbfejlesztett Listwise optimalizálás statisztikai gépi fordításhoz', 'el': 'Βελτιστοποίηση κορυφαίας κατηγορίας για τη στατιστική μηχανική μετάφραση', 'it': 'Ottimizzazione avanzata di Listwise per la traduzione automatica statistica', 'kk': 'Статистикалық машинаны аудару үшін жоғарғы түрлі тізімдегі жақсы оптимизация', 'lt': 'Aukščiausios rangos pagerintas statistinių mašinų vertimo sąrašu optimizavimas', 'mk': 'Највисока оптимизација за преведување на статистички машини', 'ms': 'Optimisasi Tingkat Atas Dengan Senarai Diperkembangkan untuk Terjemahan Mesin Statistik', 'ml': 'മുകളിലുള്ള റാങ്ക് മെച്ചപ്പെടുത്തിയ പട്ടികയിലുള്ള ഐച്ഛികങ്ങള്\u200d', 'mt': 'Titjib fl-Optimizzazzjoni tal-ogħla Livell fil-Lista għat-Traduzzjoni tal-Magni Statistiċi', 'mn': 'Статистикийн машины хөрөнгө оруулалтын дээд хэмжээний нэмэгдсэн жагсаалт', 'no': 'Optimalisering for statistisk maskinsomsetjing på øvre grad forbetra listeliste', 'pl': 'Najwyższej klasy ulepszona optymalizacja listowa dla statystycznego tłumaczenia maszynowego', 'ro': 'Optimizare îmbunătățită a listei de top pentru traducerea statistică automată', 'sr': 'Povećana optimizacija na listovima za prevod statističkih mašina', 'si': 'ස්ථිතික මැෂින් පරිවර්තනය සඳහා උපරිම ප්\u200dරමාණය වැඩි ලැයිස්තුවක් හොඳයි.', 'so': 'Top-Rank enhanced Listwise Optimization for Statistical Machine Translation', 'sv': 'Topprankad förbättrad Listwiseoptimering för statistisk maskinöversättning', 'ta': 'புள்ளிவிவரமான இயந்திரத்தின் மொழிபெயர்ப்புக்கான மேல்- வரிசையில் மேம்படுத்தப்பட்ட பட்டியல் விர', 'ur': 'اوپر Rank Enhanced Listwise Optimization for Statistical Machine Translation', 'uz': 'Boshqa shaklga almashtirish', 'vi': 'Tăng cường danh sách cho phép dịch cơ bản thống', 'bg': 'Подобрена оптимизация на списъците за статистически машинен превод', 'hr': 'Povećana optimizacija na listu najvišeg razreda za prevod statističkih strojeva', 'nl': 'Geavanceerde Listwise Optimalisatie voor Statistische Machine Translation', 'da': 'Top-rang forbedret Listwise optimering til statistisk maskinoversættelse', 'id': 'Optimisasi Listwise Tingkat Atas untuk Translation Mesin Statistik', 'de': 'Verbesserte Listwise-Optimierung für statistische maschinelle Übersetzung', 'ko': '통계 번역의 Top-Rank 개선 목록 최적화', 'fa': 'تغییرات فهرست بالایی بیشتر برای ترجمه ماشین آمار', 'sw': 'Utafiti wa Kifaa cha Kitakwimu', 'af': 'Boonste Rank Verbeter Lys Optimaliseering vir Statistiese Masjien Vertaling', 'tr': 'Statistik Maşynyň terjimesine üçin üst derejesi Bejer', 'sq': 'Optimizimi i lartë në mënyrë të përmirësuar në mënyrë të dëgjueshme për përkthimin statistik të makinave', 'am': 'ምርጫዎች', 'hy': 'Առաջին շարժումը բարելավված վիճակագրական մեքենայի թարգմանման համար', 'az': 'Statistik Makina Çevirməsi üçün ən yüksək dərəcə Yükselmiş Listə Optimizasyonu', 'bn': 'পরিসংখ্যান মেশিন অনুবাদের জন্য উপর- র\u200d্যাঙ্ক উন্নত তালিকা', 'bs': 'Povećana optimizacija na listovima najvišeg položaja za prevod statističkih strojeva', 'ca': 'Optimització millorada per a la traducció de màquines estadístiques', 'cs': 'Špičková vylepšená optimalizace Listwise pro statistický strojový překlad', 'et': 'Top-Rank täiustatud nimekirja optimeerimine statistilise masintõlke jaoks', 'fi': 'Huippuluokan parannettu luettelooptimointi tilastolliseen konekäännökseen', 'jv': "Menu item to Open 'Search for Open Files' dialog", 'he': 'אופטימיזציה רשימה משותפת בשורה העליונה לתרגום מכונות סטטיסטיות', 'ha': 'Optimisation for Translate', 'sk': 'Najboljša optimizacija seznama za statistično strojno prevajanje', 'bo': 'རིམ་པ་ལྟར་རྒྱ་བསྐྱེད་པའི་ཐོ་འགོད་ལ་ཚད་རྩིས་འཁོར་གཞུང་གི་འགྲེལ་སྤྲོད་ཀྱི་ཆ་རྐྱེན་བཟོ་བ'}
{'en': 'Pairwise ranking methods are the most widely used discriminative training approaches for structure prediction problems in natural language processing (NLP). Decomposing the problem of ranking hypotheses into pairwise comparisons enables simple and efficient solutions. However, neglecting the global ordering of the hypothesis list may hinder learning. We propose a listwise learning framework for structure prediction problems such as machine translation. Our framework directly models the entire translation list’s ordering to learn parameters which may better fit the given listwise samples. Furthermore, we propose top-rank enhanced loss functions, which are more sensitive to ranking errors at higher positions. Experiments on a large-scale Chinese-English translation task show that both our listwise learning framework and top-rank enhanced listwise losses lead to significant improvements in translation quality.', 'ar': 'تعد طرق الترتيب الزوجي أكثر مناهج التدريب التمييزية استخدامًا لمشاكل التنبؤ بالبنية في معالجة اللغة الطبيعية (NLP). يتيح تحليل مشكلة تصنيف الفرضيات إلى مقارنات زوجية حلولًا بسيطة وفعالة. ومع ذلك ، فإن إهمال الترتيب العالمي لقائمة الفرضيات قد يعيق التعلم. نقترح إطار عمل تعليمي قائم على القوائم لمشاكل التنبؤ بالبنية مثل الترجمة الآلية. يصمم إطار العمل الخاص بنا مباشرة ترتيب قائمة الترجمة بأكملها لمعرفة المعلمات التي قد تناسب عينات القائمة المحددة بشكل أفضل. علاوة على ذلك ، نقترح وظائف خسارة محسّنة من الدرجة الأولى ، والتي تكون أكثر حساسية لأخطاء الترتيب في المناصب العليا. تُظهر التجارب التي أجريت على مهمة ترجمة صينية-إنجليزية واسعة النطاق أن كلاً من إطار عمل التعلم القائم على القوائم وخسائر القائمة المحسّنة ذات التصنيف الأعلى تؤدي إلى تحسينات كبيرة في جودة الترجمة.', 'fr': "Les méthodes de classement par paires sont les approches d'entraînement discriminantes les plus utilisées pour les problèmes de prédiction de structure dans le traitement du langage naturel (NLP). La décomposition du problème du classement des hypothèses en comparaisons deux à deux permet de trouver des solutions simples et efficaces. Toutefois, le fait de négliger l'ordre global de la liste d'hypothèses peut entraver l'apprentissage. Nous proposons un cadre d'apprentissage par liste pour les problèmes de prédiction de structure tels que la traduction automatique. Notre framework modélise directement l'ordre de l'ensemble de la liste de traduction afin d'apprendre les paramètres qui peuvent mieux correspondre aux exemples de liste donnés. En outre, nous proposons des fonctions de perte améliorées de premier rang, qui sont plus sensibles aux erreurs de classement aux positions les plus élevées. Des expériences sur une tâche de traduction chinois-anglais à grande échelle montrent que notre cadre d'apprentissage au niveau de la liste et les pertes de premier ordre au niveau de la liste entraînent des améliorations significatives de la qualité de la traduction.", 'es': 'Los métodos de clasificación por parejas son los enfoques de entrenamiento discriminatorio más utilizados para los problemas de predicción de estructuras en el procesamiento del lenguaje natural (NLP). Descomponer el problema de clasificar las hipótesis en comparaciones por pares permite soluciones simples y eficientes. Sin embargo, descuidar el orden global de la lista de hipótesis puede dificultar el aprendizaje. Proponemos un marco de aprendizaje por listas para problemas de predicción de estructuras, como la traducción automática. Nuestro marco modela directamente el orden de toda la lista de traducción para aprender los parámetros que pueden ajustarse mejor a las muestras de listas dadas. Además, proponemos funciones de pérdida mejoradas de rango superior, que son más sensibles a los errores de clasificación en las posiciones más altas. Los experimentos realizados en una tarea de traducción chino-inglés a gran escala muestran que tanto nuestro marco de aprendizaje por listas como las pérdidas por listas mejoradas de primer nivel conducen a mejoras significativas en la calidad de la traducción.', 'pt': 'Os métodos de classificação de pares são as abordagens de treinamento discriminativo mais amplamente usadas para problemas de previsão de estrutura em processamento de linguagem natural (PLN). Decompor o problema de classificação de hipóteses em comparações de pares permite soluções simples e eficientes. No entanto, negligenciar a ordenação global da lista de hipóteses pode dificultar o aprendizado. Propomos uma estrutura de aprendizado de lista para problemas de previsão de estrutura, como tradução automática. Nossa estrutura modela diretamente a ordenação de toda a lista de tradução para aprender os parâmetros que podem se adequar melhor às amostras de listas fornecidas. Além disso, propomos funções de perda aprimoradas de alto nível, que são mais sensíveis a erros de classificação em posições mais altas. Experimentos em uma tarefa de tradução chinês-inglês em larga escala mostram que tanto nossa estrutura de aprendizado de listas quanto as perdas de listas aprimoradas de alto nível levam a melhorias significativas na qualidade da tradução.', 'ja': 'ペアワイズランキング法は、自然言語処理（ NLP ）における構造予測問題のために最も広く使用されている差別化トレーニングアプローチである。仮説のランク付けの問題を対比較に分解することで、単純で効率的な解決を可能にする。しかし、仮説リストのグローバルな順序付けを無視すると、学習が妨げられる可能性がある。機械翻訳などの構造予測問題のためのリスト型学習フレームワークを提案します。当社のフレームワークは、翻訳リスト全体の順序付けを直接モデル化して、与えられたリスト型サンプルに適合するパラメータを学習します。さらに、より高い位置でのランキングエラーに対してより敏感なトップランクの強化損失関数を提案します。大規模な中国語-英語翻訳タスクの実験では、当社のリスト型学習フレームワークとトップランクの強化されたリスト型損失の両方が翻訳品質の大幅な向上につながることが示されています。', 'zh': '成对序者,自然语言理(NLP)中结构预测用至博之判训练方法。 以假设排名之问分解为成对较可以成简效之解决方案。 然忽于设表之全局排序或碍于学。 建一列表学框架,以结占候,如机器翻译。 臣等框架直建模译次第,以学为宜给定列示参数。 此外顶级增强型亏函数,函数高第更敏。 大中英译职之实验明,列表学框架与顶级增损皆著译质。', 'ru': 'Методы парного ранжирования являются наиболее широко используемыми дискриминирующими подходами к обучению задачам прогнозирования структуры в обработке естественного языка (NLP). Декомпозиция задачи ранжирования гипотез на попарные сравнения позволяет найти простые и эффективные решения. Однако пренебрежение глобальным порядком списка гипотез может препятствовать обучению. Мы предлагаем систему пошагового обучения для задач предсказания структуры, таких как машинный перевод. Наша структура напрямую моделирует порядок перевода всего списка, чтобы узнать параметры, которые могут лучше соответствовать заданным образцам по списку. Кроме того, мы предлагаем расширенные функции убытков высшего ранга, которые более чувствительны к ошибкам ранжирования на более высоких позициях. Эксперименты по масштабной задаче китайско-английского перевода показывают, что как наша структура обучения по списку, так и расширенные потери по списку высшего ранга приводят к значительному улучшению качества перевода.', 'hi': 'Pairwise रैंकिंग विधियाँ प्राकृतिक भाषा प्रसंस्करण (NLP) में संरचना भविष्यवाणी समस्याओं के लिए सबसे व्यापक रूप से उपयोग किए जाने वाले भेदभावपूर्ण प्रशिक्षण दृष्टिकोण हैं। रैंकिंग परिकल्पनाओं की समस्या को युग्मवार तुलना में विघटित करना सरल और कुशल समाधानों को सक्षम बनाता है। हालांकि, परिकल्पना सूची के वैश्विक आदेश की उपेक्षा सीखने में बाधा डाल सकती है। हम मशीन अनुवाद जैसे संरचना भविष्यवाणी समस्याओं के लिए एक सूचीवार सीखने के ढांचे का प्रस्ताव करते हैं। हमारा ढांचा सीधे पूरी अनुवाद सूची के आदेश को पैरामीटर सीखने के लिए मॉडल करता है जो दिए गए सूचीवार नमूनों को बेहतर ढंग से फिट कर सकता है। इसके अलावा, हम शीर्ष-रैंक एन्हांस्ड लॉस फ़ंक्शंस का प्रस्ताव करते हैं, जो उच्च पदों पर रैंकिंग त्रुटियों के प्रति अधिक संवेदनशील हैं। एक बड़े पैमाने पर चीनी-अंग्रेजी अनुवाद कार्य पर प्रयोगों से पता चलता है कि हमारे सूचीवार सीखने के ढांचे और शीर्ष-रैंक संवर्धित सूचीवार नुकसान दोनों अनुवाद की गुणवत्ता में महत्वपूर्ण सुधार करते हैं।', 'ga': 'Is iad modhanna rangú Pairwise na cineálacha cur chuige idirdhealaitheacha oiliúna is mó a úsáidtear maidir le fadhbanna tuartha struchtúir i bpróiseáil teanga nádúrtha (NLP). Trí fhadhb na hipitéisí a rangú go comparáidí péireáilte is féidir réitigh shimplí agus éifeachtúla a dhéanamh. Mar sin féin, d’fhéadfadh sé bac a chur ar an bhfoghlaim má dhéantar faillí ar ordú domhanda an liosta hipitéise. Molaimid creat foghlama liostach le haghaidh fadhbanna a thuar struchtúir ar nós aistriúchán meaisín. Múnlaíonn ár gcreat go díreach ord an liosta aistriúcháin iomlán chun paraiméadair a fhoghlaim a d’fhéadfadh teacht níos fearr ar na samplaí liosta a thugtar. Ina theannta sin, molaimid feidhmeanna feabhsaithe caillteanais den scoth, atá níos íogaire i leith earráidí a rangú ag poist níos airde. Léiríonn turgnaimh ar thasc mórscála aistriúcháin Síneach-Béarla go dtagann feabhsuithe suntasacha ar cháilíocht an aistriúcháin as ár gcreat foghlama listwise agus ár gcreat feabhsaithe listwise araon.', 'hu': 'A páros rangsorolási módszerek a legszélesebb körben használt diszkriminatív képzési megközelítések a természetes nyelv feldolgozásában (NLP) a struktúra-előrejelzési problémákra. A hipotézisek páros összehasonlításra történő rangsorolásának problémájának bontása egyszerű és hatékony megoldásokat tesz lehetővé. A hipotézislista globális rendezésének elhanyagolása azonban akadályozhatja a tanulást. Javasolunk egy listás tanulási keretrendszert a strukturális előrejelzési problémákhoz, mint például a gépi fordítás. Keretrendszerünk közvetlenül modellezi a teljes fordítási lista rendelését, hogy olyan paramétereket tanuljon meg, amelyek jobban illeszkednek az adott listás mintákhoz. Továbbá javasoljuk a legmagasabb rangú fokozott veszteség funkciókat, amelyek érzékenyebbek a magasabb pozíciókban lévő rangsorolási hibákra. Egy nagyszabású kínai-angol fordítási feladaton végzett kísérletek azt mutatják, hogy mind a listás tanulási keretrendszerünk, mind a legmagasabb rangú, listás növekvő veszteségek jelentős javulást eredményeznek a fordítási minőségben.', 'el': 'Οι μέθοδοι ταξινόμησης ζευγαριών είναι οι πιο ευρέως χρησιμοποιούμενες διακριτικές προσεγγίσεις εκπαίδευσης για προβλήματα πρόβλεψης δομής στην επεξεργασία φυσικής γλώσσας (NLP). Η αποσύνθεση του προβλήματος της κατάταξης υποθέσεων σε συγκρίσεις ζεύγους επιτρέπει απλές και αποτελεσματικές λύσεις. Ωστόσο, παραμελώντας την παγκόσμια τάξη του καταλόγου υποθέσεων μπορεί να εμποδίσει τη μάθηση. Προτείνουμε ένα αναλυτικό μαθησιακό πλαίσιο για προβλήματα πρόβλεψης δομών όπως η μηχανική μετάφραση. Το πλαίσιο μας μοντελοποιεί άμεσα ολόκληρη τη σειρά του μεταφραστικού καταλόγου για να μάθει παραμέτρους που μπορεί να ταιριάζουν καλύτερα στα δοσμένα δείγματα λίστας. Επιπλέον, προτείνουμε κορυφαία ενισχυμένες λειτουργίες απώλειας, οι οποίες είναι πιο ευαίσθητες σε σφάλματα κατάταξης σε υψηλότερες θέσεις. Τα πειράματα σε μια μεγάλης κλίμακας εργασία μετάφρασης κινέζικων-αγγλικών δείχνουν ότι τόσο το πλαίσιο εκμάθησης βάσει λίστας όσο και οι αυξημένες απώλειες κορυφαίας κατηγορίας οδηγούν σε σημαντικές βελτιώσεις στην ποιότητα της μετάφρασης.', 'ka': 'პროგრამის პროგრამის პროგრამის მეტი არის ყველაზე широкого გამოყენებული დისკრიმინატიური განსწავლების პრობლემების სტრუქტურაციის პრობლემებისთვის (NLP). პრობლემების რენექტირების პრობლემების გადასრულება პრობლემები პრობლემების გადასრულებაში გამოიყენება ძალიან და ეფექტიური გარეშე. მაგრამ, ჰიპოტეზების სიის დოლობალური დაწყვეტილება შესაძლებელია შეუძლებელია გასწავლას. ჩვენ შეგიძლიათ სტრუქტურის წარმოდგენის პრობლემებისთვის, როგორც მაქსინური წარმოგენისთვის. ჩვენი პარამეტრები ექსტურად მოდელურია, რომელიც შეიძლება უფრო უფრო მეტი მოდელურია, რომელიც შეიძლება გავისწავლა პრამეტრები, რომელიც შეი დამატებით, ჩვენ უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფ ჩინეთი-ანგლისური თავისუფალური დაწყვეტილების გამოცდილებები აჩვენებს, რომ ჩვენი სიტყველური სწავლების ფრამეტრი და ყველაზე მეტი სიტყველური დასუფალი დასუფალი სიტყველური', 'it': "I metodi di classificazione a coppie sono gli approcci di formazione discriminatori più utilizzati per i problemi di previsione della struttura nell'elaborazione del linguaggio naturale (PNL). Decomponendo il problema della classificazione delle ipotesi in confronti a coppie consente soluzioni semplici ed efficienti. Tuttavia, trascurare l'ordinamento globale della lista delle ipotesi può ostacolare l'apprendimento. Proponiamo un framework di apprendimento liswise per problemi di previsione della struttura come la traduzione automatica. Il nostro framework modella direttamente l'ordine dell'intera lista di traduzione per imparare i parametri che possono meglio adattarsi ai campioni elencati. Inoltre, proponiamo funzioni di perdita potenziate di alto livello, che sono più sensibili agli errori di classifica nelle posizioni più alte. Esperimenti su un compito di traduzione cinese-inglese su larga scala dimostrano che sia il nostro framework di apprendimento listwise che le perdite listwise migliorate di alto livello portano a miglioramenti significativi nella qualità della traduzione.", 'kk': 'Жетілікті реттеу әдістері - табиғи тілдерді өңдеу (NLP) құрылымына қарау мәселелері үшін ең көптеген дискриминациялық оқыту әдістері. Гипотезаларды екі жүйелік салыстыру мәселесін шектеу қарапайым және эффективні шешімдерді мүмкіндік береді. Бірақ гипотеза тізімінің жалпы реттеуді шешуі оқытуға болады. Біз компьютердің аудару мәселелері секілді құрылғылардың оқыту бағдарламасын тізімдегі оқыту бағдарламасын ұсынамыз. Барлық аудармалар тізімінің бағытты параметрлерді оқыту үшін қоршау үлгілеріміз тізімінен келтірілген мәліметтерге жақсы келеді. Қосымша, жоғарғы жоғарғы жоғарғы жоғарғы жоғарғы жұмыс істеу функцияларын ұсынамыз. Бұл жоғарғы орындарда қателерге көбірек болады. Үлкен масштабтағы қытайша-ағылшын аудармалардың тәжірибелері тізімдегі оқыту және жоғары тізімдегі жоғары жоғарылып, аудармалардың сапасында маңызды жақсартылығын көр', 'lt': 'Pairwise ranking methods are the most widely used discriminative training approaches for structure prediction problems in natural language processing (NLP).  Išskaidant hipotezių klasifikavimo į poros lyginimus problem ą, galima rasti paprastus ir veiksmingus sprendimus. Tačiau nepaisydamas bendro hipotezės sąrašo tvarkymo gali trukdyti mokytis. Siūlome sąrašu pagrįstą mokymosi sistemą struktūros prognozavimo problemoms, pvz., vertimui mašinomis. Mūs ų sistema tiesiogiai modeliuoja visą vertimo sąrašo nurodymą išmokti parametrus, kurie gali geriau atitikti nurodytus sąrašo pavyzdžius. Be to, siūlome aukščiausio lygio didesnių nuostolių funkcijas, kurios yra jautresnės aukštesnėse pozicijose esančioms klasifikavimo klaidoms. Experiments on a large-scale Chinese-English translation task show that both our listwise learning framework and top-rank enhanced listwise losses lead to significant improvements in translation quality.', 'mk': 'Методите за рангирање на парови се најшироко употребените дискриминативни пристапи за обука за проблемите со структурата на предвидување во природното обработување јазик (НЛП). Декомпозирањето на проблемот со рангирањето на хипотезите во парови споредби овозможува едноставни и ефикасни решенија. Сепак, заборавањето на глобалното наредување на листата со хипотези може да го попречи учењето. Ние предложуваме листово учење рамка за проблеми со структурното предвидување како што е машинскиот превод. Нашата рамка директно ја моделира целата листа на превод наредува да научи параметри кои може подобро да се совпаѓаат со дадените примероци на листата. Furthermore, we propose top-rank enhanced loss functions, which are more sensitive to ranking errors at higher positions.  Експериментите на голема кинеско-англиска преведувачка задача покажуваат дека нашата рамка за листово учење и најдобрата зголемена загуба од листово учење водат до значителни подобрувања во квалитетот на преведувањето.', 'ms': "Kaedah rangkaian pasangan adalah pendekatan latihan diskriminatif yang paling digunakan untuk masalah ramalan struktur dalam proses bahasa semulajadi (NLP). Membongkar masalah mengatur hipotesis ke dalam perbandingan pasangan membolehkan penyelesaian sederhana dan efisien. Namun, mengabaikan perintah global senarai hipotesis mungkin menghalangi pembelajaran. Kami cadangan pembelajaran secara senarai untuk masalah ramalan struktur seperti terjemahan mesin. Our framework directly models the entire translation list's ordering to learn parameters which may better fit the given listwise samples.  Lagipun, kami cadangkan fungsi kehilangan bertambah tinggi, yang lebih sensitif kepada ralat rangkaian di posisi yang lebih tinggi. Eksperimen dalam tugas terjemahan bahasa Cina-Inggeris skala besar menunjukkan bahawa kerangka belajar senarai kita dan kerugian senarai tertinggi meningkat membawa kepada peningkatan yang signifikan dalam kualiti terjemahan.", 'mt': "Pairwise ranking methods are the most widely used discriminative training approaches for structure prediction problems in natural language processing (NLP).  Id-dekompożizzjoni tal-problema tal-klassifikazzjoni tal-ipotesi f’paraguni bejn il-pari tippermetti soluzzjonijiet sempliċi u effiċjenti. Madankollu, in-nuqqas ta’ ordni globali tal-lista ta’ ipotesi jista’ jfixkel it-tagħlim. Aħna nipproponu qafas ta’ tagħlim bl-istess mod għall-problemi ta’ tbassir tal-istruttura bħat-traduzzjoni tal-magni. Il-qafas tagħna jimmudella direttament l-ordni kollha tal-lista tat-traduzzjoni biex jitgħallmu parametri li jistgħu jaqblu aħjar mal-kampjuni tal-lista mogħtija. Barra minn hekk, qed nipproponu funzjonijiet ta' telf imsaħħaħ ta' livell għoli, li huma aktar sensittivi għall-klassifikazzjoni ta' żbalji f'pożizzjonijiet ogħla. L-esperimenti fuq kompitu ta’ traduzzjoni fuq skala kbira Ċiniża-Ingliż juru li kemm il-qafas tagħna ta’ tagħlim fuq il-lista kif ukoll it-telf imsaħħa ħ fuq il-lista jwasslu għal titjib sinifikanti fil-kwalità tat-traduzzjoni.", 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പ്രചോദനത്തിലെ പ്രവചന പ്രശ്നങ്ങള്\u200dക്ക് വേണ്ടി ഏറ്റവും വ്യത്യസ്തമായ പരിശീലനത്തില്\u200d ഉപയോഗിക്കുന്ന പരി റെഞ്ചിങ്ങ് ഹൈപ്പിയറ്റുകളുടെ പ്രശ്നം രണ്ട് വിജ്ഞാനമായ തുല്യത്തിലേക്ക് കുറിച്ച് ചെയ്യുന്നതിന് ലളിതമ എന്നാലും, ഹൈപ്പിറ്റസിസ് ലിസ്റ്റിന്റെ ഗ്ലോക കല്\u200dപനകള്\u200d അവഗണിക്കാന്\u200d കഴിയുമെങ്കിലും പഠനം തടഞ്ഞു നമ്മള്\u200d ഒരു ലിസ്റ്റ്\u200cലിസ്സ് പഠിക്കുന്ന ഫ്രെയിമെക്ക് പ്രഖ്യാപന പ്രശ്നങ്ങള്\u200dക്ക് പ്രായശ്ചിത നമ്മുടെ ഫ്രെയിമേര്\u200dക്ക് നേരിട്ട് ട്രെയിസ്റ്റര്\u200d ലിസ്റ്റില്\u200d പഠിക്കുന്ന പാരാമീറ്റര്\u200d പഠിക്കാനുള്ള അതിനുശേഷം, നമ്മള്\u200d മുകളില്\u200d നില്\u200dക്കുന്ന സ്ഥാനങ്ങളില്\u200d തെറ്റുകള്\u200d പരിശോധിക്കുന്നതാണ്. ചൈനീസ്- ഇംഗ്ലീഷ് പരിഭാഷണത്തിന്റെ ഒരു വലിയ പരീക്ഷണങ്ങള്\u200d കാണിച്ചുകൊണ്ടിരിക്കുന്നു നമ്മുടെ ലിസ്റ്റ്ലിക്ക് പഠിക്കുന്ന ഫ്', 'mn': 'Байгалийн хэлний үйлдвэрлэлт (NLP) дахь бүтээлийн асуудлуудын тухай хамгийн өргөн тархалтын дасгал хөгжүүлэх арга зам юм. Хоёр талаар харьцуулахын асуудал нь энгийн, үр дүнтэй шийдэл болох юм. Гэхдээ дэлхийн төлөвлөгөөний төлөвлөгөө нь суралцахыг зогсоож чадна. Бид машин хөгжүүлэх асуудлуудын төлөвлөгөөний системийн суралцах хэлбэрийг санал болгож байна. Бидний хэлбэрээр шууд загвар өгөгдсөн жагсаалтын жишээн дээр байж болох параметрлүүдийг сурах ёстой бүх хэлбэрүүдийг загварладаг. Үүнээс гадна бид өндөр байрлалд алдаа гаргахад илүү чухал, өндөр байрлалд дээд дээд хэмжээний халдвар гаргах функцийг санал болгож байна. Хятад-Англи хэлний хэмжээний хэмжээний туршилтын туршилт нь бидний жагсаалттай суралцах үйл ажиллагаа болон хамгийн өндөр хэмжээний алдагдлыг нь хөгжүүлэх чадварын чухал сайжруулах боломжтой бол', 'ro': 'Metodele de clasificare pereche sunt cele mai utilizate abordări discriminatorii de formare pentru problemele de predicție a structurii în procesarea limbajului natural (PNL). Descompunerea problemei clasificării ipotezelor în comparații perechi permite soluții simple și eficiente. Cu toate acestea, neglijarea ordinii globale a listei de ipoteze poate împiedica învățarea. Propunem un cadru de învățare listwise pentru probleme de predicție a structurii, cum ar fi traducerea automată. Cadrul nostru modelează direct ordinea întregii liste de traduceri pentru a învăța parametrii care se pot potrivi mai bine eșantioanelor listate date. Mai mult decât atât, propunem funcții de pierdere îmbunătățite de rang superior, care sunt mai sensibile la erorile de clasare pe poziții superioare. Experimentele asupra unei sarcini de traducere chineză-engleză la scară largă arată că atât cadrul nostru de învățare listwise, cât și pierderile de top îmbunătățite listwise duc la îmbunătățiri semnificative ale calității traducerii.', 'pl': 'Metody rankingu parowego są najczęściej stosowanymi dyskryminacyjnymi metodami szkoleniowymi dla problemów przewidywania struktury w przetwarzaniu języka naturalnego (NLP). Rozkładanie problemu rankingu hipotez na porównania parowe umożliwia proste i skuteczne rozwiązania. Jednak zaniedbanie globalnego porządku listy hipotez może utrudniać naukę. Proponujemy listowe ramy uczenia się problemów prognozowania struktury, takich jak tłumaczenie maszynowe. Nasz framework bezpośrednio modeluje kolejność całej listy tłumaczeń, aby poznać parametry, które mogą lepiej pasować do podanych listowych próbek. Ponadto proponujemy najwyższej rangi ulepszone funkcje strat, które są bardziej wrażliwe na błędy rankingowe na wyższych pozycjach. Eksperymenty na dużej skali zadania tłumaczeniowego chińsko-angielskiego pokazują, że zarówno nasze ramy uczenia się listowego, jak i najwyższej rangi zwiększone straty listowe prowadzą do znaczącej poprawy jakości tłumaczenia.', 'sr': 'Najširom korištenijim diskriminacijskim pristupima obuke za probleme predviđanja strukture u procesu prirodnog jezika (NLP). Dekompromitiranje problema rankinga hipoteze u par usporedba omogućava jednostavne i efikasne rešenja. Međutim, zanemarenje globalnog naređenja popisa hipoteze može spriječiti učenje. Predlažemo listički okvir učenja za probleme sa predviđanjem strukture kao što je prevod mašine. Naš okvir direktno modelira cijelu listu prevođenja naređenja da nauči parametre koje bi mogle bolje da uklapaju određene listovne uzorke. Osim toga, predlažemo najvišeg reda poboljšane funkcije gubitka, koje su osjetljivije na ranking greške na višim pozicijama. Eksperimenti na velikoj kineskoj-engleskoj prevodnoj zadatki pokazuju da naš listički okvir učenja i najviši redovi poboljšani listički gubitak vode do značajnih poboljšanja kvalitete prevodenja.', 'no': 'Pairwise-rekningsmetodar er dei mest brukte diskriminasjonsbehandlingane for strukturforebyggingsproblema i naturspråkshandsaming (NLP). Dekomprimerer problemet med å rankera hypotesar i samanlikningar på pare tilgjengeleg enkle og effektive løysing. Dette kan imidlertid hindra å lære på den globale rekkjefølgja i hypotesislista. Vi foreslår ei listevist læringsrammeverk for strukturforhåndsvising som maskinsomsetjing. Rammeverket vårt direkte modeller heile omsetjingslista rekkefølgja til å lære parametrar som kan bedre passa til dei oppgjevne listeprøver. I tillegg foreslår vi øvre rekke forbetra tapsfunksjonar, som er meir sensitiv til rekningsfeilar på høgare plasseringar. Eksperimentar på ein stor kinesisk-engelsk omsetjingsprogram viser at både våre listeliste læringsrammeverket og toppen rekkede tap i lista fører til signifikante forbedringar i omsetjingskvalitet.', 'so': 'Dhaqdooyinka jardiinada saqafka ah waa qaababka lagu isticmaalay takoorista takoorista ee ugu badan ee loo isticmaalo dhibaatooyin la hor-dhigo oo ku saabsan baaritaanka afka dabiicadda ah (NLP). Ka baaraandegista dhibaatada ku saabsan labada is-barbaro, waxay awoodaa xalal fudud oo faa’iido leh. Si kastaba ha ahaatee inaad ka tagto amar caalami ah ee liiska labawejiilka ayaa ka hor mari kara barashada. Waxaynu soo jeedaynaa qalabka waxbarashada ee lagu baro qoraal ah oo loo qorayo dhibaatooyin la sii sheego sida turjumista machine. Shaqoolkayaga si toos ah ayaa u sameynaya liiska turjumista oo dhan in lagu barto parameters oo ku habboon samooyinka la qoray. Furthermore, waxaynu horumarinaynaa shaqooyin la kordhiyey heerka sare, kuwaas oo aad u xiisaysan karta qaladyada meelaha sareeya. Imtixaanka shaqada turjumaadda ee Shiino-Ingiriis oo aad u weyn waxay muujiyaan in labadeeda qasnada waxbarashada lagu barto iyo lumbarka sare ee lagu kordhiyey qoraalka lagu kordhiyey waxay sababtaa horumarinta qiimaha turjumaadda.', 'si': 'සම්පූර්ණ ප්\u200dරශ්නයක් තමයි ස්වාභාවික භාෂාව ප්\u200dරශ්නයක් සඳහා සංස්ථාවිත භාෂාව ප්\u200dරශ්නයක් සඳහ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් නිර්මාණය කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක නමුත්, සාමාන්\u200dය විශ්වාස ලැයිස්තුවේ ජාතික විධානය අවධානය කරන්න පුළුවන්. අපි ලැයිස්තුවෙන් ඉගෙන ගන්න ප්\u200dරශ්නයක් ප්\u200dරයෝජනය කරනවා මැෂින් වාර්තාවක් වගේ. අපේ පරීක්ෂණය ප්\u200dරතික්\u200dරමාණය ප්\u200dරතික්\u200dරමාණය සම්පූර්ණ පරීක්ෂණය ලැයිස්තුවේ පරීක්ෂණය ඉගෙන ගන්න සිද තවත්, අපි උපරිම ප්\u200dරමාණයක් වැඩි වැඩි වැඩි වැඩි වැඩි වැඩක් ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරනවා, ඒ වගේම උපරිම ත ලොකු ප්\u200dරමාණයක් චීනි-ඉංග්\u200dරීසි භාෂාව ක්\u200dරියාවේ පරීක්ෂණය පෙන්වන්නේ අපේ ලැයිස්තුවේ ඉගෙන ගන්න ප්\u200dරමාණය සහ උපස', 'sv': 'Parvisa rankningsmetoder 채r de mest anv채nda diskriminerande utbildningsmetoderna f철r strukturf철ruts채gelseproblem i Natural Language Processing (NLP). Att nedmontera problemet med att rangordna hypoteser i parvisa j채mf철relser m철jligg철r enkla och effektiva l철sningar. Att f철rsumma den globala ordningen av hypoteslistan kan dock hindra inl채rningen. Vi f철resl책r ett listvigt l채rramverk f철r strukturf철ruts채gelseproblem som maskin철vers채ttning. V책rt ramverk modellerar direkt hela 철vers채ttningslistans best채llning f철r att l채ra sig parametrar som b채ttre passar de givna listvida exemplen. Dessutom f철resl책r vi topprankade f철rb채ttrade f철rlustfunktioner, som 채r mer k채nsliga f철r rankningsfel p책 h철gre positioner. Experiment p책 en storskalig kinesisk-engelsk 철vers채ttningsuppgift visar att b책de v책rt listvista l채rramverk och topprankade listvista f철rluster leder till betydande f철rb채ttringar i 철vers채ttningskvaliteten.', 'ta': 'பார்வைஸ் முறைமைகள் தான் இயல்பான மொழி செயல்பாட்டில் முன்னடிப்பு பிரச்சனைகளுக்கு மிகவும் விரிவாக பயன்படுத்தப்பட் சுலபமான மற்றும் தீர்வுகள் செயல்படுத்தலாம். ஆயினும், துப்புணர்வு பட்டியலின் உலக வரிசையை தவிர்த்து விட்டாலும் கற்றலை தடுக்கலாம். கணினி மொழிபெயர்ப்பு போன்ற பிரச்சனைகளுக்கு நாம் பட்டியலில் பட்டியலில் கற்றுக்கொள்ளும் சட்டத்தை  எங்கள் சட்டத்தை நேரடியாக மாதிரியும் மொழிபெயர்ப்பு பட்டியலின் கட்டளையை கற்றுக் கொள்ள முடியும் அளபுருக்களை மு Furthermore, we propose top-rank enhanced loss functions, which are more sensitive to ranking errors at higher positions.  ஒரு பெரிய அளவில் சீனா- ஆங்கிலம் மொழிபெயர்ப்பு செயல்பாட்டில் சோதனைகள் காட்டுகிறது நாம் பட்டியலில் பட்டியலில் பட்டியலில் பட்டியலில் இர', 'ur': 'جوڑ رینگ طریقے سب سے زیادہ استعمال کئے جاتے ہیں کہ ساختاری پیش بینی مسئلہ کے لئے (NLP) طبیعی زبان پردازی میں۔ رئنڈ ہيٹس کے مسئلہ کو دو طرح مقایسات میں کمزور کرنا سادھے اور قابل حل کرنے کے قابل ہے اگرچہ، فرضیات لکھ کی گلوبی سفارش کو غفلت کرنا ممکن ہے کہ تعلیم کو روک سکے۔ ہم ایک لکھی سمجھ سکھانے والی فرموک کی پیش بینی مشکلات کے لئے پیشنهاد کرتے ہیں جیسے ماشین ترجمہ۔ ہمارے فرمومیٹ مستقیماً الگو لکھنے کے لئے تمام ترجمہ لکھنے کے اورڈر بناتے ہیں کہ پارامیٹروں کو سیکھنا چاہیں جو اچھی طرح دیے جاتے ہیں لکھنے والی نمونڈوں پر۔ اور اس کے علاوہ، ہم بالا رینگ زیادہ زیادہ خسارہ فعالیتوں کو پیشنهاد کرتے ہیں، جو بلندی موقعیت پر رینگ گناہوں کے بارے میں زیادہ حساس ہیں. ایک بڑے اندازے سے چینی-انگلیسی ترجمہ کا کام پر آزمائش دکھاتی ہے کہ ہمارے لیستیوں کی تعلیم فرم اور اوپر رقم کی ترجمہ لیستیوں کی خسارہ ان کی ترجمہ کیفیت میں بہت اضافہ ہوتی ہے۔', 'uz': "Pairwise ranking methods are the most widely used discriminative training approaches for structure prediction problems in natural language processing (NLP).  Ko'pchilik munosabatlarni ko'pchilikga o'zgartirish muammolari oddiy va effektiv usullarni oshirish mumkin. Lekin, hypothesis roʻyxatining dunyo tartibizni o'rganishni o'rganishga yordam beradi. Biz mashina tarjima qilish kabi murakkablarini tasdiqlash muammolari uchun roʻyxat orqali o'rganishni tahlil qilamiz. Freymmiz to ʻgʻri tarjima roʻyxati orqali o'rganish amalni o'rganish uchun hamma parametrlarni o'rganish mumkin. Koʻrsatilgan roʻyxat misollariga qulay boʻlishi mumkin. Ko'rsatganda, biz yuqori darajada qo'shish funksiyalarini oshirish talab qilamiz. Bu eng yuqori joylarda xatolarni ko'paytirish uchun juda qiziqarli. Xitoycha- Inglizcha tarjima vazifani katta taʼminlovchi tajribalar ko'rsatadi, bizning roʻyxat o'rganish qatlamlarimiz va eng yuqori darajada ko'paytirilgan yozuvlar tarjima sifatida juda katta yaxshi o'zgarishlar sababchi.", 'vi': 'Phương pháp đánh giá bằng đồng là phương pháp đào tạo độc lập phổ biến nhất cho các vấn đề dự đoán cấu trúc trong việc xử lý ngôn ngữ tự nhiên. Việc phân phối các giả thuyết làm đôi để so sánh cho phép giải pháp đơn giản và hiệu quả. Tuy nhiên, bỏ qua mệnh lệnh toàn cầu của danh sách giả thuyết có thể cản trở học hỏi. Chúng tôi đề nghị một cơ sở học chính thức cho các vấn đề dự đoán cấu trúc như dịch vụ máy. Cơ chế của chúng tôi làm mẫu trực tiếp theo lệnh của danh s ách dịch để học các thông số có thể phù hợp với các mẫu đơn này. Hơn nữa, chúng tôi đề xuất chức năng giảm tổn thất cấp cao hơn, nhạy cảm hơn với việc xếp hạng lỗi ở vị trí cao hơn. Thí nghiệm trong một nhiệm vụ dịch dịch tiếng Trung-Anh quy mô lớn cho thấy, cả hệ thống học tập theo danh sách của chúng ta và tổn thất danh sách cao cấp đều dẫn đến cải thiện chất lượng dịch.', 'bg': 'Двойните методи за класиране са най-широко използваните дискриминационни тренировъчни подходи за проблеми с прогнозирането на структурата в обработката на естествения език (НЛП). Разлагането на проблема с класирането на хипотезите в двойки сравнения позволява прости и ефективни решения. Въпреки това, пренебрегването на глобалното подреждане на списъка с хипотези може да възпрепятства ученето. Предлагаме списък на учебна рамка за проблеми с прогнозирането на структурата като машинен превод. Нашата рамка директно моделира подреждането на целия списък за преводи, за да научи параметри, които могат да отговарят по-добре на дадените списъци образци. Освен това предлагаме подобрени функции за загуба от най-висок ранг, които са по-чувствителни към грешки в класирането на по-високи позиции. Експериментите по мащабна задача за превод на китайско-английски език показват, че както нашата учебна рамка, така и подобрените загуби в списъка водят до значителни подобрения в качеството на превода.', 'nl': 'Pairwise ranking methodes zijn de meest gebruikte discriminatieve trainingsbenaderingen voor structuurvoorspellingsproblemen in natuurlijke taalverwerking (NLP). Het ontleden van het probleem van het rangschikken van hypothesen in pairwise vergelijkingen maakt eenvoudige en efficiënte oplossingen mogelijk. Het verwaarlozen van de globale ordening van de hypotheselijst kan het leren echter belemmeren. We stellen een listwise learning framework voor structuurvoorspellingsproblemen zoals machinevertaling voor. Ons framework modelleert direct de volgorde van de volledige vertaallijst om parameters te leren die beter passen bij de opgegeven lijst voorbeelden. Bovendien stellen we geavanceerde verliesfuncties voor, die gevoeliger zijn voor rankingfouten op hogere posities. Experimenten met een grootschalige Chinees-Engels vertaaltaak tonen aan dat zowel ons listwise leerframework als de hoogste rang verbeterde listwise verliezen leiden tot aanzienlijke verbeteringen in de vertaalkwaliteit.', 'hr': 'Najširom korištenijim diskriminacijskim pristupima obuke za probleme predviđanja strukture u procesu prirodnog jezika (NLP). Dekompromiziranje problema raspoređivanja hipoteze u pairwise usporedbe omogućava jednostavne i učinkovite rješenja. Međutim, zanemarivanje globalnog naređenja popisa hipoteze može spriječiti učenje. Predlažemo listički okvir učenja za probleme predviđanja strukture poput prevoda strojeva. Naš okvir izravno modelira cijelu listu prevođenja naređenja da nauči parametre koji mogu bolje uključiti određene listovne uzorke. Nadalje, predlažemo najvišem redom poboljšane funkcije gubitka, koje su osjetljivije na redovne greške na višim položajima. Eksperimenti na velikoj kineskoj-engleskoj prevodnoj zadatki pokazuju da i naš listički okvir učenja i najviši redoviti poboljšani gubitak na lističkom položaju značajne poboljšanje kvalitete prevodenja.', 'da': 'Pairwise ranking metoder er de mest udbredte diskriminerende træningsmetoder til strukturforudsigelsesproblemer i naturlig sprogbehandling (NLP). Ved at nedbryde problemet med at rangere hypoteser i parvise sammenligninger muliggør enkle og effektive løsninger. Men at forsømme den globale rækkefølge af hypoteslisten kan hindre læring. Vi foreslår en listevis læringsramme for strukturforudsigelsesproblemer såsom maskinoversættelse. Vores ramme modellerer direkte hele oversættelseslistens rækkefølge for at lære parametre, der bedre passer til de givne listevise prøver. Desuden foreslår vi toprang forbedrede tabsfunktioner, som er mere følsomme over for rangeringsfejl på højere positioner. Eksperimenter med en omfattende kinesisk-engelsk oversættelsesopgave viser, at både vores listevise læringsramme og top-rang forbedrede listevise tab fører til betydelige forbedringer i oversættelseskvaliteten.', 'de': 'Pairwise Ranking Methoden sind die am weitesten verbreiteten diskriminierenden Trainingsansätze für Strukturvorhersageprobleme in der Verarbeitung natürlicher Sprache (NLP). Die Dekomposition des Problems der Rangfolge von Hypothesen in paarweise Vergleiche ermöglicht einfache und effiziente Lösungen. Die Vernachlässigung der globalen Ordnung der Hypothesenliste kann jedoch das Lernen behindern. Wir schlagen ein listenweise Lernframework für Strukturvorhersageprobleme wie maschinelle Übersetzung vor. Unser Framework modelliert direkt die Reihenfolge der gesamten Übersetzungsliste, um Parameter zu lernen, die besser zu den angegebenen listweisen Beispielen passen. Darüber hinaus bieten wir erweiterte Verlustfunktionen an, die empfindlicher auf Rankingfehler an höheren Positionen reagieren. Experimente an einer groß angelegten chinesisch-englischen Übersetzungsaufgabe zeigen, dass sowohl unser listweises Lernframework als auch die hochrangigen verbesserten listweisen Verluste zu signifikanten Verbesserungen der Übersetzungsqualität führen.', 'id': 'Metode ranking pasangan adalah pendekatan latihan diskriminatif yang paling digunakan untuk masalah prediksi struktur dalam proses bahasa alam (NLP). Decomposing the problem of ranking hypotheses into pairwise comparisons enables simple and efficient solutions.  Namun, mengabaikan perintah global daftar hipotesis mungkin menghalangi belajar. Kami mengusulkan cadangan belajar listwise untuk masalah prediksi struktur seperti terjemahan mesin. Framework kami secara langsung model seluruh daftar terjemahan perintah untuk belajar parameter yang mungkin lebih cocok dengan sampel daftar yang diberikan. Selain itu, kami mengusulkan fungsi kehilangan tingkat atas yang lebih sensitif kepada kesalahan rangkaian di posisi yang lebih tinggi. Eksperimen dalam tugas terjemahan bahasa Cina-Inggris skala besar menunjukkan bahwa both our listwise learning framework and top-rank enhanced listwise losses lead to significant improvements in translation quality.', 'ko': '쌍으로 정렬하는 방법은 자연언어처리(NLP)에서 구조 예측 문제 중 가장 광범위하게 응용되는 판별 훈련 방법이다.정렬 가설의 문제를 두 개의 비교로 나누면 간단하고 효과적인 해결 방안을 제공할 수 있다.그러나 가설 목록의 전체 정렬을 무시하면 학습을 방해할 수 있다.기계 번역 등 구조 예측 문제에 대해 우리는 목록식 학습 구조를 제시했다.우리의 프레임워크는 전체 번역 목록의 순서를 직접 모델링하여 목록 견본에 대한 매개 변수를 학습하는 데 더욱 적합할 수 있습니다.그 밖에 우리는 top-rank 증강 손실 함수를 제기했는데 더 높은 위치의 순위 오류에 대해 더욱 민감하다.대규모 한영 번역 임무에서의 실험에 의하면 우리의 리스트 학습 프레임워크와 top-rank가 강화한 리스트 손실은 번역의 질을 현저히 높일 수 있다.', 'fa': 'روش\u200cهای رشته\u200cبندی جفت\u200cها بزرگترین روش\u200cهای آموزش\u200cبندی جدایی برای مشکلات پیش\u200cبینی ساختار در پردازش زبان طبیعی (NLP) استفاده می\u200cشود. مشکل تنظیم کردن فرضیه\u200cها به مقایسه\u200cهای جفتی توان حل ساده و موثر باشد. با این حال، تغییر دادن سفارش جهانی لیست فرضیه ممکن است از یادگیری متوقف کند. ما پیشنهاد می\u200cکنیم چهارچوب یادگیری در فهرست برای مشکلات پیش بینی ساختار مثل ترجمه ماشین. چهارچوب ما مستقیما مدل\u200cهای کل فهرست ترجمه\u200cها را برای یاد گرفتن پارامتر می\u200cگیرد که ممکن است بهتر از نمونه\u200cها به طریق فهرست داده باشد. علاوه بر این، ما پیشنهاد می کنیم که عملکرد زیادی بیشتر از دست دادن، که به خطاهای درجات بالاتر حساس ترند. تجربه\u200cهایی روی یک کار ترجمه چینی و انگلیسی بزرگ نشان می\u200cدهند که هر دو چهارچوب یادگیری در فهرست ما و از دست دادن بالاترین درجه\u200cی فهرست به سوی بهترین کیفیت ترجمه\u200cها به پیشرفت بزرگی می\u200cرسد.', 'sw': 'Utawala wa uchimbaji wa rangi ni mbinu zilizotumiwa zaidi za mafunzo ya kibaguzi kwa ajili ya kutabiri matatizo ya utabiri katika upasuaji wa lugha asili (NLP). Kupambana na tatizo la wanafiki wa rangi katika kulinganisha viwili viwili vinaweza ufumbuzi rahisi na ufanisi. Hata hivyo, kupuuza amri ya kidunia ya orodha ya nadhani inaweza kuzuia kujifunza. Tunazipendekeza mfumo wa kujifunza kwa ajili ya matatizo ya kutabiri kama vile tafsiri ya mashine. Miundombi yetu inaonyesha moja kwa moja orodha ya tafsiri yote ya amri ya kujifunza parameters ambayo inaweza kuwa bora zaidi kupata sampuli zilizopewa listwise. Zaidi ya hayo, tunapendekeza shughuli za kupoteza kwa kiwango kikubwa, ambazo ni vizuri zaidi kwa kutangaza makosa katika nafasi za juu. Majaribio katika kazi ya tafsiri ya Kichina na Kiingereza yenye kiwango kikubwa inaonyesha kwamba miundombi yetu ya kujifunza vizuri na hasara ya juu zilizoongezeka kwenye orodha hiyo yanasababisha maboresho makubwa katika kiwango cha tafsiri.', 'tr': 'NLP hipotezlerin çift karşılaştırmalarına çözmesini basit ve etkili çözümler yaratabilir. Ýöne, hipotez listiniň küresel sıralamasyny boýunça öwrenmegi engellemek mümkin. Biz makina terjime edilýän kynçylyklar üçin düzümlenme öwrenme sistemasyny teklip edip görýäris. Biziň çerçewçimiz direkt nusgalary tüm terjime listleriniň aralygyny görkez. Bu nusgalar berilen listlerde has gowy örnekler bolup biler. Mundan beýle bir şekilde, üst depler iň gowylaşyrylan ýitirmek funksiýalary teklip edip görýäris. Bu iň üst deplerde ýitirmek üçin hatalaryň üstine hasaplanýar. Ullakan Çin çe-Iňlisçe terjime täbliginde örän jalyklaryň hem biziň listlerimizde öwrenmek çarpaklarymyz hem iň üst derejesimizde ýüzerli ýüzerli ýüzerleşmelerimiz terjime täbliginde örän gowurak bolup ýöredigin', 'sq': 'Metodat e renditjes së çifteve janë metodat më të përdorura diskriminuese të trajnimit për problemet e parashikimit të strukturës në procesimin natyror të gjuhës (NLP). Zhvendosja e problemit të renditjes së hipotezave në krahasime të palëvizshme lejon zgjidhje të thjeshta dhe të efektshme. Megjithatë, harrimi i renditjes globale të list ës së hipotezave mund të pengojë mësimin. Ne propozojmë një kuadër mësimi në mënyrë listike për problemet e parashikimit të strukturës, të tilla si përkthimi i makinave. Korniza jonë modelon drejtpërdrejt të gjithë list ën e përkthimit për të mësuar parametrat që mund të përshtaten më mirë me mostrat e dhëna në listë. Përveç kësaj, ne propozojmë funksione të larta të rritura të humbjes, të cilat janë më të ndjeshme ndaj gabimeve të renditjes në pozita më të larta. Eksperimentet në një detyrë përkthimi në shkallë të madhe kinez-anglisht tregojnë se si kuadri ynë i mësimit në mënyrë listore, ashtu edhe humbjet e larta në mënyrë listore çojnë në përmirësime të rëndësishme në cilësinë e përkthimit.', 'af': "Pairwise ranking metodes is die mees vaste gebruikte diskriminasiewe onderwerp toegang vir strukturevoorskou probleme in natuurlike taal verwerking (NLP). Om die probleem van rangering van hipotees in paar wyse vergelyking te maak eenvoudige en effektiewe oplossing toe. Maar, verwerking van die globale ordening van die hipotesis lys kan hinder die leer. Ons voorstel 'n lysswyse leer raamwerk vir struktuur voorskou probleme soos masjien vertaling. Ons raamwerk direk modeller die hele vertaling lys se ordening om parameters te leer wat dalk beter pas die gegewe lyswerk voorbeelde. Ons voorstel ook bo-rank verbeterde verlies funksies, wat meer sensitief is na ranking foute op hoëre posisies. Eksperimente op 'n groot-skaal Sjinese-Engelse vertaling taak wys dat beide ons lyswerk leer raamwerk en bo-rank verbeterde lyswerk verlore lei na betekende verbeteringe in vertaling kwaliteit.", 'am': 'የፍጥረት ቋንቋ ማቀናቀሚያ ጉዳዮች (NLP) የፍጥረት ቋንቋ ማቀናቀፍ ጉዳዮች ለመግለጽ የሚጠቀሙት ትልቅ ተማሪዎች ናቸው፡፡ በሁለት ዓይነት ምሳሌ ላይ የንፍቅና ውጤት መቆጣጠር የሚችል ቀላል እና ጥሩ መፍትሄቶችን ያስችላል፡፡ ነገር ግን የዓለምአቀፍ ትእዛዝ የንፍቅና ዝርዝር ማወቅ ይችላል፡፡ የመሳዊ ትርጓሜዎችን እንደሚመስል የመረጃ ትርጓሜዎችን ለመፍጠር የመረጃ ትምህርት ሥርዓት እናስፈልጋለን፡፡ የሥርዓታችን ሥርዓት የትርጉም ዝርዝር ሙሉ ማስተማር የሚያስፈልገውን በተሰጠው ዝርዝር ምሳሌዎችን የሚሻል ነው፡፡ በተጨማሪም፣ ከፍተኛ ስህተቶችን በመስመር ላይ የሚጨምሩ የክፋት ስህተቶችን እናሳውቃለን፡፡ በቻይና-እንግሊዘኛ ትርጉም ሥራ ላይ በተለየ ትርጉም ትርጉም የሚደረግ ፈተናዎች፣ የረጅም ደረጃዎች እና የደረጃ ክፍተቶችን በመተርጓሜ ጥሩ ትርጓሜ ጥሩ ትክክል ማድረግ እንዲያሳየው ነው፡፡', 'hy': 'Երկու դասակարգման մեթոդներն են ամենալայն օգտագործված խտրականությունը կրթության մոտեցումները կառուցվածքի կանխատեսման խնդիրների համար բնական լեզվի վերամշակում (ՆԼՊ). Հիպոթեզների դասավորման խնդիրը զույգչային համեմատություններով բաժանելը հնարավորություն է տալիս պարզ և արդյունավետ լուծումներ: Այնուամենայնիվ, հիպոթեզի ցուցակի գլոբալ կարգավորումը անտեսելը կարող է դժվարացնել սովորելը: Մենք առաջարկում ենք կառուցվածքի կանխատեսման խնդիրների, ինչպիսիք են մեքենայի թարգմանումը, ցանկացած սովորելու համակարգ: Մեր կառուցվածքը անմիջապես մոդելավորում է ամբողջ թարգմանման ցուցակի կարգավորումը սովորելու պարամետրեր, որոնք կարող են ավելի լավ համապատասխանել տվյալ ցուցակի տեսքով նմուշներին: Ավելին, մենք առաջարկում ենք բարձրացված կորստի ֆունկցիաներ, որոնք ավելի զգայուն են ավելի բարձր դիրքերում գտնվող սխալների դասավորման համար: Չինաստանի-անգլերենի թարգմանման մեծ խնդիրների փորձարկումները ցույց են տալիս, որ մեր ցանցաթարգմանական ուսումնասիրության շրջանակը և բարձրացված ցանցաթարգմանական կորստը հանգեցնում են թարգմանման որակի կարևոր բարելավում', 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ার (এনএলপি) প্রতিষ্ঠানের ভবিষ্যৎ সমস্যার জন্য বৈষম্য প্রশিক্ষণের চেয়ে সবচেয়ে ব্যবহার করা প্রয দুই জানুয়ালী তুলনায় রেঞ্জিং হিসাবের সমস্যা কমিয়ে দেওয়া যায় সাধারণ এবং কার্যকর সমাধান। তবে বিশ্ববিদ্যালয়ের তালিকার নির্দেশ প্রত্যাখ্যান করা সম্ভবত শিক্ষা থেকে বিরত রাখতে পারে। আমরা একটি তালিকাভাবে শিক্ষা কার্যক্রমের প্রস্তাব করছি যেমন মেশিন অনুবাদের মতো ভবিষ্যদ্বাণী সমস্যার জন্য। আমাদের ফ্রেমের কাঠামো সরাসরি মডেল করে পুরো অনুবাদের তালিকার নির্দেশ শ শিখতে পারে যা তালিকায় প্রাপ্ত নমুনালের এছাড়াও, আমরা উচ্চমর্যাদা বৃদ্ধি করার প্রস্তাব প্রস্তাব করছি, যা উচ্চপদস্থানে ভুল পরিচালনা করার জন্য আরো সুবিধাজনক। চীনা-ইংরেজী অনুবাদ কর্মসূচিতে বিশাল পরীক্ষা দেখা যাচ্ছে যে আমাদের তালিকাভাবে শিক্ষা কার্যক্রম এবং তালিকার তালিকায় বৃদ্ধির ক্', 'az': 'Təbiətli dil işləməsi (NLP) məqsədildə struktur tədbir problemləri üçün ən geniş istifadə edilən diskriminasiya təhsil metodları. İki dəyişdirilmiş hipotezlərin problemini çift dəyişdirilməsi basit və etkili çözümləri mümkün edər. Halbuki, hipotez listesinin küresel sıralaması öyrənməyə mane olar. Biz maşın tercüməsi kimi quruluş öyrənməsi üçün quruluş tədbir problemlərini təklif edirik. Bizim qurğumuz təkrarlama listesinin öyrənmək əmrini düzgün modellərlə çəkir ki, bu qurğulu təkrarlama nümunələrinə daha yaxşı uyğun ola bilər. Daha sonra, yüksək məqamlarda yerləşdirilmək xətalarına daha hassaslı olan yüksək səf yüksək səf-səf yüksək funksiyaları təklif edirik. Büyük ölçüdə Çin-İngilizce tercümə işləri ilə təcrübələr göstərir ki, listemizdə öyrənən öyrənmə framework ımız və ən yüksək dərəcələrimizin qurbanlıq kalitetində möhkəm düzəltməyə yol a çar.', 'bs': 'Najširom korištenijim diskriminacijskim pristupima obuke za probleme predviđanja strukture u procesu prirodnog jezika (NLP). Deompromitiranje problema raspoređivanja hipoteza u par usporedba omogućava jednostavne i efikasne rješenja. Međutim, zanemarivanje globalnog naređenja popisa hipoteze može spriječiti učenje. Predlažemo listički okvir učenja za probleme predviđanja strukture kao što je prevod strojeva. Naš okvir izravno modelira cijelu listu prevođenja naređenja da nauči parametre koji bi mogli bolje uklopiti određene listovne uzorke. Nadalje, predlažemo najvišem redom poboljšane funkcije gubitka, koje su osjetljivije na redovne greške na višim položajima. Eksperimenti na velikoj kineskoj-engleskoj prevodnoj zadatki pokazuju da i naš listički okvir učenja i najviši redoviti poboljšani listički gubitak vode do značajnih poboljšanja kvalitete prevodenja.', 'ca': "Els mètodes de classificació de parelles són els enfocaments discriminatoris més utilitzats per a les prediccions estructurals en el processament natural de llenguatges (NLP). Descomposir el problema de classificar hipòtesis en comparacions parelles permet solucions simples i eficients. Però ignorar l'ordre global de la llista d'hipòtesis pot dificultar l'aprenentatge. Proposem un marc d'aprenentatge listàtic per a problemes de predicció de l'estructura, com la traducció automàtica. Our framework directly models the entire translation list's ordering to learn parameters which may better fit the given listwise samples.  A més, proposem funcions de pèrdua millorada de alt rangque són més sensibles als errors de classificació en posicions més altes. Els experiments d'una tasca de traducció de gran escala xinès-anglès demostren que tant el nostre marc d'aprenentatge en termes de llista com les pèrdues millorades en termes de llista porten a millores significatives en la qualitat de traducció.", 'cs': 'Párové hodnocení jsou nejrozšířenějšími diskriminačními tréninkovými přístupy pro problémy predikce struktury v zpracování přirozeného jazyka (NLP). Rozložení problému hodnocení hypotéz do párových srovnání umožňuje jednoduchá a efektivní řešení. Nicméně zanedbání globálního uspořádání seznamu hypotéz může bránit učení. Navrhujeme seznamový učební rámec pro problémy s predikcí struktury, jako je strojový překlad. Náš framework přímo modeluje pořadí celého seznamu překladů, aby se naučil parametry, které by mohly lépe odpovídat daným seznamovým vzorkům. Navíc navrhujeme špičkové rozšířené ztrátové funkce, které jsou citlivější na chyby v hodnocení na vyšších pozicích. Experimenty na rozsáhlém čínsko-anglickém překladu ukazují, že jak náš rámec učení se seznamem, tak špičkové zvýšené ztráty se seznamem vedou k výraznému zlepšení kvality překladu.', 'et': 'Pairwise järjestuse meetodid on kõige laiemalt kasutatavamad diskrimineerivad koolitusmeetodid struktuuri ennustamise probleemide jaoks looduskeele töötlemisel (NLP). Hüpoteeside järjestamise probleemi lahendamine paarivõrdluseks võimaldab lihtsaid ja tõhusaid lahendusi. Hüpoteeside nimekirja ülemaailmse järjestuse tähelepanuta jätmine võib õppimist takistada. Pakume välja nimekirja õpperaamistiku struktuuri prognoosimise probleemidele, näiteks masintõlkele. Meie raamistik modelleerib otseselt kogu tõlke nimekirja järjestust, et õppida parameetreid, mis võivad paremini sobida antud nimekirja näidistega. Lisaks pakume välja kõrgema astme täiustatud kahjumifunktsioone, mis on tundlikumad kõrgemate positsioonide järjestamisvigade suhtes. Suuremahulise hiina-inglise tõlkeülesande eksperimendid näitavad, et nii meie nimekirja õppimise raamistik kui ka kõrgeima astme täiustatud nimekirja kaotused toovad kaasa tõlkekvaliteedi olulise paranemise.', 'fi': 'Pairwise ranking -menetelmät ovat yleisimmin käytettyjä syrjiviä koulutusmenetelmiä rakenteen ennustamisongelmiin luonnollisen kielen prosessoinnissa (NLP). Hypoteesien luokitteluongelman purkaminen parivertailuihin mahdollistaa yksinkertaiset ja tehokkaat ratkaisut. Hypoteesiluettelon maailmanlaajuisen järjestyksen laiminlyönti voi kuitenkin vaikeuttaa oppimista. Ehdotamme listallista oppimiskehystä rakenteen ennustamiseen liittyville ongelmille, kuten konekäännökselle. Kehyksemme mallintaa suoraan koko käännöslistan järjestystä oppiakseen parametreja, jotka sopivat paremmin annettuihin listanäytteisiin. Lisäksi ehdotamme top-rank parannettuja tappiofunktioita, jotka ovat herkempiä sijoitusvirheille korkeammassa asemassa. Laajamittaisessa kiina-englanti-käännöstyössä tehdyt kokeet osoittavat, että sekä listwise-oppimiskehyksemme että huippuluokan listahäviöt johtavat merkittäviin parannuksiin käännöksen laadussa.', 'ha': "Shiryoyin yin sayarwa na Pairway, sũ ne mafiya amfani da kowanka masu yin wa'azi da takwara masu yin gaura wa matsayin basĩri a cikin aikin harshe na natura (NLP). Decomposing the problem of ranking hypotheses into pairwise comparisons enables simple and efficient solutions.  A'aha, kuma kada ka manta da umarnin duniya ga jerin teyyaki, kan ya kange learning. Munã goyyar da wani firam mai sanarwa na jerin da aka yi wa matsayin basĩri kamar fassarar birnin mashine. Salon firam masu motsa dira kowace jerin fassarar da aka umurce su dõmin a karanta parameteri da za'a fi daidai da misãlai da aka ƙayyade. Furan haka, Munã ƙayyade mafiya ƙaranci functionin hasara a sarki, waɗanda ke da saurãre zuwa matsayin sarrafiya. Tajararin da aka cika wani aikin fassarar na China-Ingiriya mai girma yana nuna cewa duk masu shirya firam da aka sanar da su jerin-jerin da aka ƙara tsakanin sarrafa, suna ƙara mafiya kyau cikin tsarin fassarar.", 'sk': 'Metode pare razvrščanja so najpogosteje uporabljeni diskriminativni pristopi usposabljanja za probleme napovedovanja strukture v obdelavi naravnega jezika (NLP). Razdelitev problema razvrščanja hipotez v pare primerjave omogoča enostavne in učinkovite rešitve. Vendar pa lahko zanemarjanje globalnega urejanja seznama hipotez ovira učenje. Predlagamo seznam učnega okvira za težave s predvidevanjem strukture, kot je strojno prevajanje. Naš okvir neposredno modelira naročanje celotnega seznama prevodov, da se nauči parametrov, ki bi lahko bolje ustrezali danim seznamom. Poleg tega predlagamo najvišje izboljšane funkcije izgube, ki so bolj občutljive na napake razvrščanja na višjih položajih. Eksperimenti obsežne prevajalske naloge kitajsko-angleščine kažejo, da tako naš učni okvir po seznamu kot najboljše izgube po seznamu vodijo do znatnega izboljšanja kakovosti prevodov.', 'he': "שיטות הדרגה של זוגות הן הגישות האימוניות הבחירות ביותר השתמשות ביותר לבעיות חיזוי מבנה בעבודת שפת טבעית (NLP). לפרק את הבעיה של הדרגה של היפותזיות לשוואות בין זוגות מאפשר פתרונות פשוטות ויכולות. עם זאת, להשכח את ההזמנה הגלובלית של רשימת ההיפתוזיה יכולה להפריע ללמוד. אנחנו מציעים מסגרת לימוד רשימה לבעיות צפוי מבנה כמו תרגום מכונות. Our framework directly models the entire translation list's ordering to learn parameters which may better fit the given listwise samples.  חוץ מזה, אנו מציעים פעילות אובדן משותפות במדרגות העליונה, שהן רגישות יותר לטעויות בהדרגות בעמדות גבוהות יותר. ניסויים על משימת תרגום סינית-אנגלית ברמה גדולה מראים שגם המסגרת הלימודים שלנו ברשימה וגם הפסדים ברשימה גבוהה משותפים מובילים לשיפורים משמעותיים באיכות תרגום.", 'jv': 'Genjer AllProgressBarUpdates Nanging, nglanggar-langgar nganggo urip maneh sing pasablet kanggo ngerasar Awak dhéwé nggunakake sistem listWis kanggo ngerasakno perbudhakan kanggo ngerasakno MTR. Kernel Laha luwih, kita suggerusan kelas perusahaan langkung sampeyan Name', 'bo': "Pairwise ranking methods are the most widely used discriminative training approaches for structure prediction problems in natural language processing (NLP). དབྱེ་རིམ་གྱི་ཆ་ཚོད་ལྟར་མཉམ་དུ་བསྡོམས་པའི་ཆ་ཚོད་དེ་སྟབས་བདེ་བ་དང་ປະສ ན་བཟོས་ཐབས་ཤེས་ཡོད། ཡིན་ནའང་། སྤྱི་ཚོགས་ཀྱི་གྲངས་རྩིས་ཐོ་ཡིག་གི་གོ་རྣམ་པ་དེ་གིས་ཤེས་འཇུག་དགོས་པ་དང་། ང་ཚོས་རྒྱལ་ཁབ་ཀྱི་སྔོན་སྒྲིག་ཆ་ལྟ་བུའི་གྲངས་རིམ་གྱི་མཛོད་གཞུང་ཞིག་བསམ་བྱེད། Our framework directly models the entire translation list's ordering to learn parameters which may better fit the given listwise samples. འོན་ཀྱང་། ང་ཚོས་མཐོ་རིམ་པ་དེ་ལས་མཐོ་རྐྱེན་པའི་ལས་འགན་འགྱུར་བ་སྐྱེན་ཚུལ་མང་ཆེ་བས། རྒྱ་ནག་མིའི་སྤྱི་ཚོགས་ཀྱི་ལས་འཚོལ་ཞིབ་ཚད་ཆེན་པོ་ཞིག་གིས་བཀྲམ་སྟོན་ན།"}
{'en': 'Embedding Words and Senses Together via Joint Knowledge-Enhanced Training', 'ar': 'تضمين الكلمات والحواس معًا من خلال التدريب المعزز بالمعرفة المشتركة', 'fr': 'Intégrer les mots et les sens ensemble grâce à une formation conjointe renforcée par les connaissances', 'pt': 'Incorporando palavras e sentidos juntos por meio de treinamento conjunto aprimorado de conhecimento', 'es': 'Incorporación de palabras y sentidos a través de una capacitación conjunta mejorada con conocimientos', 'ja': '共同知識強化トレーニングを通じて言葉と感覚を共に埋め込む', 'zh': '因合知识培训销单词与感官', 'ru': 'Объединение слов и чувств посредством совместного обучения, основанного на знаниях', 'hi': 'संयुक्त ज्ञान-संवर्धित प्रशिक्षण के माध्यम से शब्दों और इंद्रियों को एक साथ एम्बेड करना', 'ga': 'Focail agus céadfaí a Leabú le Chéile trí Chomhoiliúint Feabhsaithe an Eolais', 'el': 'Ενσωματώνοντας λέξεις και αισθήσεις μαζί μέσω κοινής κατάρτισης ενισχυμένης γνώσης', 'hu': 'Szavak és érzékek együttes beágyazása közös tudásfejlesztett képzéssel', 'ka': 'Name', 'lt': 'Embedding Words and Senses Together via Joint Knowledge-Enhanced Training', 'mk': 'Embedding Words and Senses Together via Joint Knowledge-Enhanced Training', 'it': 'Incorporare parole e sensi insieme attraverso una formazione congiunta potenziata della conoscenza', 'ml': 'യൂണ്ട് അറിവ്- മെച്ചപ്പെടുത്തിയ പരിശീലനം മുഖാനുപയോഗിച്ച് എംബെഡിങ് വാക്കുകളും സെന്\u200dസുകളും', 'kk': 'Сөздер мен сезімдер біріктірілген білім- жетілдірілген оқыту арқылы біріктіру', 'mt': 'L-inkorporazzjoni tal-kliem u s-sensi Flimkien permezz ta’ Taħriġ Konġunt imtejjeb bl-Għarfien', 'mn': 'Холбоотой мэдлэг нэмэгдүүлсэн дасгал хөгжүүлэхээр', 'no': 'Innebygd ord og førsel saman via Joint Knowledge- Enhanced Training', 'ro': 'Încorporarea cuvintelor și simțurilor împreună prin instruire comună îmbunătățită a cunoștințelor', 'pl': 'Włączanie słów i zmysłów razem poprzez wspólne szkolenia zwiększone wiedzą', 'ms': 'Membenarkan Kata dan Sensa Bersama-sama melalui Latihan Bersama-sama Pengetahuan-Diperkembangkan', 'so': 'Adeegga wadajirka ah', 'sv': 'Bädda in ord och sinnen tillsammans genom gemensam kunskapsförbättrad utbildning', 'ta': 'இணைய அறிவு மேம்படுத்தப்பட்ட பயிற்சியால் உட்பொதிந்த சொற்கள் மற்றும் அனுப்பப்படுகிறது', 'sr': 'Uklapanje reèi i oseæanja zajedno putem zajedničkog znanja-poveæanja obuke', 'ur': 'Name', 'si': 'Name', 'uz': 'Name', 'vi': 'Nhúng chỉ thức và cảm xúc qua luyện trí tuệ phối hợp', 'bg': 'Включване на думи и усещания заедно чрез съвместно обучение с подобрено знание', 'nl': 'Woorden en zintuigen samenvoegen via gezamenlijke kennisversterkte training', 'da': 'Indlejring af ord og sanser sammen via fælles vidensforbedret træning', 'hr': 'Uključujući riječi i osjećaje zajedno putem zajedničkog znanja-poboljšanog treninga', 'de': 'Wörter und Sinne miteinander verbinden durch gemeinsame wissensbasierte Schulungen', 'id': 'Memembed Words and Senses Together via Joint Knowledge-Enhanced Training', 'ko': '연합지식 강화 훈련을 통해 단어와 감각을 한데 끼워넣다', 'fa': 'جمع کردن کلمات و احساسات با وجود آموزش دانش\u200cهای بیشتر', 'sw': 'Matambo na Sensi kwa pamoja kupitia mafunzo ya Ujuzi Mkuu', 'af': 'Name', 'tr': 'Sözler we Senedleri Birleşik Bilim-Yüklenen Ewez bilen birleştirilýär', 'sq': 'Futja e fjalëve dhe ndjenjave së bashku nëpërmjet trajnimit të përbashkët të përmirësuar nga njohuritë', 'am': 'የመጠቀሚያ ምርጫዎች', 'hy': 'Բառեր և զգացմունքներ միասին ներգրավելը գիտելիքով բարելավված համագործակցության միջոցով', 'az': 'Bütün bilik-genişlənmiş təhsil vasitəsilə sözləri və Senses birlikdə daxil edilir', 'bn': 'যুক্ত জ্ঞান-উন্নত প্রশিক্ষণের মাধ্যমে আমদেশিক শব্দ এবং প্রেরণ', 'bs': 'Uključujući riječi i osjećaje zajedno putem zajedničkog znanja povećanog treninga', 'ca': "Incorporar paraules i sentits junts a través d'una formació conjunta millorada en el coneixement", 'cs': 'Vkládání slov a smyslů dohromady prostřednictvím společného školení vylepšeného znalostmi', 'et': 'Sõnade ja meelte ühendamine ühise teadmistepõhise koolituse kaudu', 'fi': 'Sanojen ja aistien yhdistäminen yhteisellä osaamisella tehostetulla koulutuksella', 'jv': 'Tatanan Wurung lan Senses Tulung Jejaring', 'he': 'מכניס מילים ומחושים יחד באמצעות אימונים משותפים למידע', 'ha': '@ action', 'sk': 'Združevanje besed in čutov prek skupnega usposabljanja za izboljšanje znanja', 'bo': 'ནང་འདྲེན་པའི་ཡི་གེའང་དང་Senses མཉམ་དུ་བསྡུས་ནས་དབྱིབས་ཤེས་པའི་རིགས་ལ་ཡར་རྒྱས་སྤྲོད་ཀྱི་དཔེ་རིགས'}
{'en': 'Word embeddings are widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora. However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector. We address this issue by proposing a new model which learns word and sense embeddings jointly. Our model exploits large corpora and knowledge from semantic networks in order to produce a unified vector space of word and sense embeddings. We evaluate the main features of our approach both qualitatively and quantitatively in a variety of tasks, highlighting the advantages of the proposed method in comparison to state-of-the-art word- and sense-based models.', 'ar': 'تُستخدم عمليات دمج الكلمات على نطاق واسع في معالجة اللغة الطبيعية ، ويرجع ذلك أساسًا إلى نجاحها في التقاط المعلومات الدلالية من مجموعات ضخمة. ومع ذلك ، فإن عملية إنشائها لا تسمح بفصل المعاني المختلفة للكلمة تلقائيًا ، لأنها تدمجها في متجه واحد. نعالج هذه القضية من خلال اقتراح نموذج جديد يتعلم الكلمات والمعنى بشكل مشترك. يستغل نموذجنا المجموعات الكبيرة والمعرفة المستمدة من الشبكات الدلالية من أجل إنتاج فضاء متجه موحد لحفلات الزفاف بالمعنى والكلمة. نقوم بتقييم السمات الرئيسية لنهجنا من حيث النوعية والكمية في مجموعة متنوعة من المهام ، مع إبراز مزايا الطريقة المقترحة مقارنة بأحدث النماذج القائمة على الكلمة والمعنى.', 'pt': 'Embeddings de palavras são amplamente utilizados em Processamento de Linguagem Natural, principalmente devido ao seu sucesso na captura de informações semânticas de corpora massivos. No entanto, seu processo de criação não permite que os diferentes significados de uma palavra sejam separados automaticamente, pois os une em um único vetor. Abordamos essa questão propondo um novo modelo que aprende a incorporação de palavras e sentidos em conjunto. Nosso modelo explora grandes corpora e conhecimento de redes semânticas para produzir um espaço vetorial unificado de embeddings de palavras e sentidos. Avaliamos as principais características de nossa abordagem qualitativa e quantitativamente em uma variedade de tarefas, destacando as vantagens do método proposto em comparação com modelos baseados em palavras e sentidos de última geração.', 'es': 'Las incrustaciones de palabras se utilizan ampliamente en el procesamiento del lenguaje natural, principalmente debido a su éxito en la captura de información semántica de cuerpos masivos. Sin embargo, su proceso de creación no permite que los diferentes significados de una palabra se separen automáticamente, ya que los combina en un solo vector. Abordamos este tema proponiendo un nuevo modelo que aprenda la incorporación de palabras y sentidos de forma conjunta. Nuestro modelo aprovecha los grandes corpus y el conocimiento de las redes semánticas para producir un espacio vectorial unificado de incrustaciones de palabras y sentidos. Evaluamos las principales características de nuestro enfoque tanto cualitativa como cuantitativamente en una variedad de tareas, destacando las ventajas del método propuesto en comparación con los modelos de vanguardia basados en palabras y sentidos.', 'fr': "Les intégrations de mots sont largement utilisées dans le traitement du langage naturel, principalement en raison de leur capacité à capturer des informations sémantiques à partir de corpus massifs. Cependant, leur processus de création ne permet pas de séparer automatiquement les différentes significations d'un mot, car il les confond en un seul vecteur. Nous abordons ce problème en proposant un nouveau modèle qui apprend conjointement les intégrations de mots et de sens. Notre modèle exploite de grands corpus et des connaissances issues de réseaux sémantiques afin de produire un espace vectoriel unifié d'intégrations de mots et de sens. Nous évaluons les principales caractéristiques de notre approche tant qualitativement que quantitativement dans diverses tâches, en soulignant les avantages de la méthode proposée par rapport aux modèles de pointe basés sur les mots et les sens.", 'ja': 'ワード埋め込みは、主に大規模なコーラから意味情報を取り込むことに成功したため、自然言語処理で広く使用されています。しかし、それらの作成プロセスは、単一のベクトルにそれらを混同するため、単語の異なる意味を自動的に分離することを可能にしません。私たちは、単語とセンスの組み込みを共同で学ぶ新しいモデルを提案して、この問題に取り組んでいます。私たちのモデルは、単語とセンスの埋め込みの統一されたベクトル空間を生成するために、セマンティックネットワークからの大きなコーラと知識を利用します。私たちは、さまざまなタスクにおけるアプローチの主な特徴を定性的および定量的に評価し、最先端の単語ベースおよびセンスベースのモデルと比較して提案された方法の利点を強調します。', 'hi': 'शब्द एम्बेडिंग का व्यापक रूप से प्राकृतिक भाषा प्रसंस्करण में उपयोग किया जाता है, मुख्य रूप से बड़े पैमाने पर कॉर्पोरेट से शब्दार्थ जानकारी पर कब्जा करने में उनकी सफलता के कारण। हालांकि, उनकी निर्माण प्रक्रिया किसी शब्द के विभिन्न अर्थों को स्वचालित रूप से अलग करने की अनुमति नहीं देती है, क्योंकि यह उन्हें एक एकल वेक्टर में जोड़ती है। हम एक नए मॉडल का प्रस्ताव करके इस मुद्दे को संबोधित करते हैं जो संयुक्त रूप से शब्द और अर्थ एम्बेडिंग सीखता है। हमारा मॉडल शब्द और भावना एम्बेडिंग के एक एकीकृत वेक्टर स्थान का उत्पादन करने के लिए शब्दार्थ नेटवर्क से बड़े कॉर्पोरेट और ज्ञान का शोषण करता है। हम विभिन्न प्रकार के कार्यों में गुणात्मक और मात्रात्मक रूप से हमारे दृष्टिकोण की मुख्य विशेषताओं का मूल्यांकन करते हैं, जो अत्याधुनिक शब्द- और अर्थ-आधारित मॉडल की तुलना में प्रस्तावित विधि के फायदों को उजागर करते हैं।', 'zh': '词嵌于自然语言而博用之,盖其成功于大语料库语义。 然其创制不许自离单词异义,以其并为单向量也。 共学单词义销新模。 用自语义网络大语料库知,以生单词义向量空。 论定性量之要,标先进之单词,与感官之势。', 'ru': 'Вложения в слова широко используются в обработке естественного языка, в основном благодаря их успеху в захвате семантической информации из массивных корпусов. Однако процесс их создания не позволяет автоматически разделять различные значения слова, поскольку он объединяет их в один вектор. Мы решаем эту проблему, предлагая новую модель, которая изучает слова и смысловые вложения совместно. Наша модель использует большие корпуса и знания из семантических сетей, чтобы создать единое векторное пространство слов и смысловых вложений. Мы оцениваем основные особенности нашего подхода как качественно, так и количественно в различных задачах, подчеркивая преимущества предлагаемого метода по сравнению с современными моделями, основанными на словах и смыслах.', 'ga': 'Úsáidtear leabaithe focal go forleathan i bPróiseáil Teanga Nádúrtha, go príomha toisc go n-éiríonn leo faisnéis shéimeantach a ghabháil ó chorpra ollmhór. Mar sin féin, ní cheadaíonn a bpróiseas cruthaithe na bríonna éagsúla a bhaineann le focal a dheighilt go huathoibríoch, toisc go ndéanann sé iad a chomhdhlúthú ina veicteoir amháin. Tugaimid aghaidh ar an gceist seo trí mhúnla nua a mholadh a fhoghlaimíonn leabú focal agus ciall le chéile. Baineann ár múnla leas as corpas mór agus eolas ó líonraí séimeantacha chun spás veicteoir aontaithe de leabú focal agus ciall a tháirgeadh. Déanaimid meastóireacht cháilíochtúil agus chainníochtúil ar phríomhghnéithe ár gcur chuige i dtascanna éagsúla, ag cur béime ar bhuntáistí an mhodha atá molta i gcomparáid le samhlacha úrscothacha atá bunaithe ar fhocail agus ar chiall.', 'ka': 'სიტყვების შებრუნებები ძალიან გამოყენებულია ჩემი ენერგიის პროცესისში, რომელიც ძალიან წარმატებით იქნება სიმენტიკური ინფორმაციას მასიური კორპორაზე. მაგრამ, მათი შექმნა პროცესი არ უნდა ავტომატურად განყოფილი სიტყვის განსხვავებული ნიშნავები, როგორც მათ ერთი გვქტორიში კონფილურებს. ჩვენ ამ პრობლემას გადაწყენებთ ახალი მოდელს, რომელიც სიტყვის და სიტყვის გადასწავლის ერთად. ჩვენი მოდელი გამოვიყენება დიდი კოპორა და ცნობილება სემონტიკური ქსელებიდან, რომ გამოვიყენოთ ერთადერთი გვეკტორის სიტყვების და სიტყვების შემდეგ. ჩვენ კვალტატიურად და კვალტატიურად განსაზღვრებულად განსაზღვრებულად გავამუშავებთ ჩვენი პროგრამის უფრო მნიშვნელობები, რომლებიც განსაზღვრებულია პროგრამის უფრო მნიშვნელობების გასაზღვრება', 'hu': 'A szóbeágyazásokat széles körben használják a természetes nyelv feldolgozásában, elsősorban azért, mert sikeresen rögzítették a szemantikai információkat masszív corporákból. A létrehozási folyamat azonban nem teszi lehetővé, hogy egy szó különböző jelentéseit automatikusan elválasszák, mivel egyetlen vektorrá alakítja. Ezt a kérdést olyan új modellt javasolunk, amely közösen tanulja meg a szó- és érzékbeágyazásokat. Modellünk a szemantikai hálózatokból származó nagy korpuszokat és ismereteket használja ki annak érdekében, hogy a szó- és érzékbeágyazások egységes vektortérét hozzon létre. Megközelítésünk főbb jellemzőit minőségi és mennyiségi szempontból egyaránt értékeljük különböző feladatokban, kiemelve a javasolt módszer előnyeit a korszerű szó- és érzékalapú modellekhez képest.', 'el': 'Οι ενσωματώσεις λέξεων χρησιμοποιούνται ευρέως στην επεξεργασία φυσικής γλώσσας, κυρίως λόγω της επιτυχίας τους στην καταγραφή σημασιολογικών πληροφοριών από μαζικά σώματα. Ωστόσο, η διαδικασία δημιουργίας τους δεν επιτρέπει να διαχωρίζονται αυτόματα οι διαφορετικές έννοιες μιας λέξης, καθώς τις συγχέει σε ένα μόνο διάνυσμα. Αντιμετωπίζουμε αυτό το ζήτημα προτείνοντας ένα νέο μοντέλο το οποίο μαθαίνει από κοινού την ενσωμάτωση λέξεων και αισθήσεων. Το μοντέλο μας εκμεταλλεύεται μεγάλα σώματα και γνώσεις από σημασιολογικά δίκτυα προκειμένου να παράγει έναν ενοποιημένο διανυσματικό χώρο ενσωμάτωσης λέξεων και αισθήσεων. Αξιολογούμε τα κύρια χαρακτηριστικά της προσέγγισής μας τόσο ποιοτικά όσο και ποσοτικά σε ποικίλες εργασίες, αναδεικνύοντας τα πλεονεκτήματα της προτεινόμενης μεθόδου σε σύγκριση με σύγχρονα μοντέλα βασισμένα σε λέξεις και αισθήσεις.', 'mk': 'Вклучувањата на зборовите се широко употребени во процесот на природен јазик, главно поради нивниот успех во заземањето семантични информации од масовни корпора. However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector.  Ние го решаваме ова прашање предлагајќи нов модел кој научи зборови и чувства вградени заедно. Нашиот модел ги искористува големите корпора и знаење од семантичките мрежи со цел да создаде унифициран векторен простор на зборови и чувства. Ги проценуваме главните карактеристики на нашиот пристап квалитетно и квантитивно во различни задачи, истакнувајќи ги предностите на предложениот метод во споредба со најсовремените модели на зборови и смисла.', 'ms': 'Word embeddings are widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora.  Namun, proses ciptaan mereka tidak membenarkan makna berbeza perkataan untuk dipisahkan secara automatik, kerana ia mengkonflikasikan mereka kepada vektor tunggal. Kami mengatasi isu ini dengan melamar model baru yang mempelajari perkataan dan perasaan terbenaman bersama-sama. Model kami mengeksploitasi korpra besar dan pengetahuan dari rangkaian semantik untuk menghasilkan ruang vektor bersatu dari penyambungan perkataan dan perasaan. Kami menilai ciri-ciri utama pendekatan kita secara kualitatif dan kuantitatif dalam berbagai tugas, menyatakan keuntungan kaedah yang diusulkan dalam perbandingan dengan model yang terbaik perkataan dan berasaskan.', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയയില്\u200d വാക്കുകള്\u200d വിശാലമായി ഉപയോഗിക്കുന്നു എങ്കിലും അവയുടെ സൃഷ്ടിപ്പിന്റെ പ്രക്രിയയില്\u200d വ്യത്യസ്ത വാക്കുകളുടെ അര്\u200dത്ഥങ്ങള്\u200d സ്വയം വേര്\u200dപെടുത്തുവാന്\u200d അനുവദിക നമ്മള്\u200d ഈ പ്രശ്നത്തെക്കുറിച്ച് ഒരു പുതിയ മോഡല്\u200d പ്രാദേശിപ്പിക്കുന്നു. വാക്കും മനസ്സും പഠിക്കുന് നമ്മുടെ മോഡല്\u200d സെമാന്റിക് നെറ്റര്\u200dക്കുകളില്\u200d നിന്നും വലിയ കോര്\u200dപ്പോര്\u200dക്കും അറിവും പ്രയോഗിക്കുന്നു. വാക്കുകളുടെയും വ നമ്മുടെ നടപടിയുടെ പ്രധാനപ്പെട്ട പ്രധാനപ്പെട്ട വിഭവങ്ങള്\u200d വിലയിച്ചുകൊടുക്കുന്നു. പല ജോലികളിലും വ്യത്യസ്തമായിക്കൊണ്ടും, പ്രോദിപ്പിക്കപ്പെട്ട ര', 'it': "Le incorporazioni di parole sono ampiamente utilizzate nell'elaborazione del linguaggio naturale, principalmente a causa del loro successo nell'acquisizione di informazioni semantiche da corpora massicci. Tuttavia, il loro processo di creazione non permette che i diversi significati di una parola siano separati automaticamente, in quanto li confonde in un unico vettore. Affrontiamo questo problema proponendo un nuovo modello che impari insieme le incorporazioni di parole e sensi. Il nostro modello sfrutta grandi corpora e conoscenze provenienti da reti semantiche al fine di produrre uno spazio vettoriale unificato di incorporazioni di parole e sensi. Valutiamo le principali caratteristiche del nostro approccio sia qualitativamente che quantitativamente in una varietà di compiti, evidenziando i vantaggi del metodo proposto rispetto a modelli basati su parole e senso all'avanguardia.", 'mt': 'L-inkorporazzjoni tal-kliem tintuża b’mod wiesa’ fil-Proċessar tal-Lingwa Naturali, l-aktar minħabba s-suċċess tagħhom fil-kisba ta’ informazzjoni semantika minn korpra massiva. Madankollu, il-proċess ta’ ħolqien tagħhom ma jippermettix li t-tifsiriet differenti ta’ kelma jiġu separati awtomatikament, peress li jikkonflittahom f’vettur wieħed. Aħna nindirizzaw din il-kwistjoni billi nipproponu mudell ġdid li jitgħallem il-kliem u s-sens inkorporati flimkien. Il-mudell tagħna jisfrutta korpora kbira u għarfien minn netwerks semantiċi sabiex jipproduċi spazju unifikat ta’ vetturi ta’ inkorporazzjonijiet tal-kelma u tas-sens. Aħna jivvalutaw il-karatteristiċi ewlenin tal-approċċ tagħna kemm kwalitattivament kif ukoll kwantitattivament f’varjetà ta’ kompiti, filwaqt li jenfasizzaw il-vantaġġi tal-metodu propost meta mqabbel mal-mudelli l-aktar avvanzati bbażati fuq il-kliem u s-sens.', 'lt': 'žodžių įterpimas plačiai naudojamas gamtinės kalbos apdorojimo procese, daugiausia dėl to, kad jie sėkmingai gauna semantinę informaciją iš masinės korpros. Tačiau jų kūrimo procesas neleidžia automatiškai atskirti skirtingų žodžio reikšmių, nes juos sujungia į vieną vektorių. Mes sprendžiame šį klausimą pasiūlydami naują model į, kuriame bendrai mokomi žodžiai ir jausmas. Mūsų modelis naudoja didelę korprą ir žinias iš semantinių tinklų, kad sukurtume vieningą vektorių erdvę žodžių ir jutimo įdėjimų. Svarbiausius mūsų požiūrio aspektus vertiname kokybiškai ir kiekybiškai įvairiose užduotyse, pabrėždami siūlomo metodo pranašumus, palyginti su naujausiais žodžių ir proto modeliais.', 'pl': 'Osadzania tekstów są szeroko stosowane w przetwarzaniu języka naturalnego, głównie ze względu na ich sukces w przechwytywaniu informacji semantycznych z masywnych korpusów. Jednak proces ich tworzenia nie pozwala na automatyczne oddzielenie różnych znaczeń słowa, ponieważ łączy je w jeden wektor. Rozwiązujemy tę kwestię proponując nowy model, który wspólnie uczy się osadzeń słowa i sensu. Nasz model wykorzystuje duże korpory i wiedzę z sieci semantycznych w celu stworzenia jednolitej przestrzeni wektorowej osadzeń słowa i zmysłów. Oceniamy główne cechy naszego podejścia zarówno jakościowo, jak i ilościowo w różnych zadaniach, podkreślając zalety proponowanej metody w porównaniu z najnowocześniejszymi modelami opartymi na słowach i zmysłach.', 'ro': 'Încorporările de cuvinte sunt utilizate pe scară largă în procesarea limbajului natural, în principal datorită succesului lor în captarea informațiilor semantice din corpore masive. Cu toate acestea, procesul lor de creare nu permite diferitelor semnificații ale unui cuvânt să fie separate automat, deoarece le confundă într-un singur vector. Abordăm această problemă propunând un nou model care învață în comun încorporarea cuvintelor și sensurilor. Modelul nostru exploatează corpuri mari și cunoștințe din rețele semantice pentru a produce un spațiu vectorial unificat de încorporări de cuvinte și simțuri. Evaluăm principalele caracteristici ale abordării noastre atât calitativ, cât și cantitativ într-o varietate de sarcini, evidențiind avantajele metodei propuse în comparație cu modelele de ultimă generație bazate pe cuvinte și sensuri.', 'mn': 'Байгалийн хэл процесс дээр үг нэвтрүүлэлт ихэвчлэн хэрэглэгддэг, ихэвчлэн тэдний амжилтын шалтгаан нь маш олон корпоратаас семантик мэдээллийг авах боломжтой. Гэхдээ тэдний бүтээлтийн процесс үгийн өөр утгыг автоматаар хуваагдах боломжгүй. Яагаад гэвэл энэ нь тэднийг нэг вектор руу холбоотой. Бид энэ асуудлыг нэгтгэх үг болон мэдрэмжтэй холбоотой шинэ загвар суралцаж суралцдаг. Бидний загвар нь семантик сүлжээгээс том корпора болон мэдлэг ашигладаг. Үүний нэгдсэн векторын орон зай болон мэдрэмжтэй холбоотой. Бид өөр төрлийн ажил дээр шинжлэх ухааны гол чадварыг үнэлдэг. Бид өөр төрлийн ажил дээр шинжлэх ухаан, урлагийн үг болон мэдрэлийн үндсэн загвартай харьцуулахад санал өгсөн арга загварын давуу талуудыг тодорхойлдог.', 'no': 'Ordinnbygging vert breidd brukt i naturspråk- prosessering, hovudsakelig på grunn av sine suksess i å henta semantiske informasjon frå massivt korpora. Dette opprettingasprosessen kan imidlertid ikkje gjera at dei ulike betydningane av eit ord automatisk skal separerast, sidan han konflaterer dei til eit enkelt vektor. Vi handterar dette problemet ved å foreslå eit ny modell som lærer ordet og følelse innbygging saman. Modellen vårt ekspluaterer stor korpora og kunnskap frå semantiske nettverk for å produsere eit einaste vektorrom med ord og følelsesinnbygging. Vi evaluerer hovudfunksjonane til tilnærminga vårt både kvalitativ og kvantitativ i mange oppgåver, og markerer fordelene til den foreslåtte metoden i sammenligning med ordet i kunsten og følelsesbasert modeller.', 'sr': 'U procesu prirodnog jezika, uglavnom zbog uspeha u prihvatanju semantičkih informacija iz masovnog korpora, se široko koriste u prirodnom jeziku. Međutim, njihov proces stvaranja ne dozvoljava da se različiti znaci riječi automatski odvoje, jer ih povezuje u jednog vektora. Razgovaramo o ovom pitanju predloženjem novog model a koji zajedno uči reč i osjećaj. Naš model iskoristi veliku korporaciju i znanja iz semantičkih mreža kako bi proizveli ujedinjeni vektorski prostor riječi i smisla. Procjenjujemo glavne karakteristike našeg pristupa kvalitativno i kvantitativno u raznim zadacima, naglašavajući prednost predložene metode u usporedbi sa modelima na stanju umjetnosti i umjetnosti.', 'so': "Qoraalka afka asalka ah waxaa si badan loogu isticmaalaa macluumaadka qeybta ah ee xafiiska shirkadda badan ka soo qaadashada. Si kastaba ha ahaatee xiliga abuuriddu uma oggola in micneheeda kala duduwan ay si iskaa ah u kala soocaan, sababtoo ah waxay u bedeshaa wado kaliya. Waxaannu arrintan ku sheekeynaynaa tusaale cusub oo ku barta hadal iyo waxyaabaha la barta islamarkaasna. Our model exploits large corpora and knowledge from semantic networks in order to produce a unified vector space of word and sense embeddings.  Waxaynu qiimeynaynaa heerka ugu horeeya qaababkayaga, si qiimo ah iyo si qiyaas ah oo shaqaalaha kala duduwan, waxaana tusinaynaa faa'iidada qaababka la soo jeeday oo u barbarbardhiga noocyada farshaxanka iyo saxda.", 'ta': 'சொல் உள்ளடக்கங்கள் இயல்பான மொழி செயல்பாட்டில் விரிவாக பயன்படுத்தப்படுகிறது, முக்கியமாக அவர்கள் பெரிய நிறுவனத்திலிருந்து பெ ஆனால், அவர்களுடைய உருவாக்கும் செயல்பாடு வார்த்தையின் மாறுபாடுகளை தானாகவே பிரிக்க அனுமதிக்காது, அது ஒரு நெறியில் அவர்கள ஒரு புதிய மாதிரியை நாம் இந்த பிரச்சினையை விளக்குகிறோம். அது சொல்லை மற்றும் உணர்வு ஒன்றாக உள்ளிடும எங்கள் மாதிரி பெரிய நிறுவனம் மற்றும் அறிவு பெரிய பிணையங்களிலிருந்து வெக்டர் இடைவெளியை உருவாக்குவதற்காக தொடர்ந்து சொ நாம் எங்கள் செயல்பாட்டின் முக்கிய தன்மைகளை மதிப்பீடு செய்கிறோம் பல்வேறு பணிகளிலும் குறிப்பாக மற்றும் அளவிலும், முன்னோக்கப்பட்ட முறையின் விதிமுறைகள', 'si': 'වචන සම්බන්ධයක් ස්වභාවික භාෂාව ප්\u200dරක්\u200dරියාසයෙන් භාවිත කරනවා, විශේෂයෙන් ඔවුන්ගේ සාර්ථක විශේෂ ත නමුත්, ඔවුන්ගේ නිර්මාණය ප්\u200dරක්\u200dරියාව ස්වයංක්\u200dරමයෙන් වචනයක් වෙනස් අදහස් කරන්නේ නැහැ, ඒක ඔවුන්ව එක වෙක්ටර අපි මේ ප්\u200dරශ්නය සම්බන්ධ වෙනුවෙන් අලුත් මොඩේල් එකක් ඉගෙන ගන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා. අපේ මොඩල් එක්ක වෙක්ටර් කාර්පෝරා සහ දන්නවය ප්\u200dරයෝජනය කරනවා වචනය සහ අනුවිශ්වාස කරන්න. අපි අපේ ප්\u200dරධාන විශේෂයේ ප්\u200dරධාන විශේෂතාවක් හා ප්\u200dරධාන විශේෂතාවක් වගේම විවිධ වැඩක් වගේම අවශ්\u200dය කරනවා, ප්\u200dරධාන විධානයේ ප්\u200dරධාන', 'sv': 'Ordinbäddningar används ofta i Natural Language Processing, främst på grund av deras framgång med att fånga semantisk information från massiva korpora. Deras skapandeprocess tillåter dock inte att de olika betydelserna av ett ord automatiskt separeras, eftersom det sammanfaller dem till en enda vektor. Vi tar itu med denna fråga genom att föreslå en ny modell som tillsammans lär sig ord och sinnen inbäddade. Vår modell utnyttjar stora korpora och kunskap från semantiska nätverk för att producera ett enhetligt vektorutrymme av ord och sinnen inbäddningar. Vi utvärderar huvuddragen i vårt tillvägagångssätt både kvalitativt och kvantitativt i en mängd olika uppgifter, och belyser fördelarna med den föreslagna metoden jämfört med de senaste ord- och sinnesbaserade modellerna.', 'kk': 'Табиғи тіл процессінде сөздерді ендіру көбірек қолданылады, әдетте олардың көпшілікті корпорадан семантикалық мәліметін алу үшін. Бірақ олардың құру процесі сөздің әртүрлі мазмұнын автоматты түрде бөлу мүмкін емес, себебі оларды бір векторға сәйкес келеді. Біз осы мәселеге бірге сөз мен сезімді бірге үйренетін жаңа үлгісін таңдап береміз. Біздің үлгіміз симантикалық желінен үлкен корпора және білім беру үшін сөздер мен сезімдердің біріктірілген вектордың орын жасау үшін қолданады. Біз қасиеттеріміздің негізгі мүмкіндіктерін квалификациялық және көптеген тапсырмалардың негізгі мүмкіндіктерін бағалап, ұсынылған әдістердің күйіне және оқиға негізгі үлгілеріне салыстыру үшін таңда', 'ur': 'Word embedding is widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora. لیکن ان کی پیدائش کسی کلمہ کی مختلف معنی کو اپنے ساتھ جدا کرنا اجازت نہیں دیتی جیسے وہ ان کو ایک ویکتور میں ملتا ہے ہم اس مسئلہ کو مشورہ کر رہے ہیں ایک نئی موڈل کی پیشنهاد سے جو کلمات اور حس کے ساتھ سمجھتا ہے۔ ہماری مدل بڑی کمپورا اور علم کو سیمنٹی نیٹورک سے استعمال کرتا ہے تاکہ کلمات اور احساس انڈینگ کے ایک واحد ویکتور فضا پیدا کرے۔ ہم اپنے طریقے کی اصلی خصوصیات کا ارزش کررہے ہیں، ہر طریقے کے کاموں میں گوناگون اور گوناگون طور پر، پیشنهاد کی طریقے کے فائدے کی تدبیر کررہے ہیں، آرتی کلمات کے مقابلہ میں اور احساس کی بنیادی مدل کے مقابلہ میں.', 'uz': "Word embeddings are widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora.  Lekin ularning yaratish jarayonini avtomatik ajratish imkoniyatini ruxsat bermaydi, chunki u ularni bir vectorga aylantirish mumkin. Biz bu muammani birlashtirilgan so'z va ma'lumotni o'rganadigan yangi modelni rivojlanish bilan boshqaramiz. Bizning modelimiz semantik tarmoqlaridan katta kompaniya va bilimni ishlab chiqaradi, so'z va ma'lumotning bir birlashtirilgan vektorning joyini yaratish uchun. Biz har xil vazifalarda ko'plab o'zgarishning asosiy xususiyatlarimizni qiymatimiz, so'zlar soʻzning so'zlari va ma'lum asosiy modellariga o'xshasha beradigan foydalanishni anglatamiz.", 'vi': 'Từ ngữ được sử dụng rộng rãi trong Quá trình hóa ngôn ngữ tự nhiên, chủ yếu nhờ thành công của họ trong việc thu thập thông tin cơ bản. Tuy nhiên, quá trình tạo của họ không cho phép phân tách các ý nghĩa khác nhau của một từ tự động, vì nó nhầm họ thành một véc- tơ duy nhất. Chúng ta giải quyết vấn đề này bằng cách đề xuất một kiểu mẫu mới học về sự ghép nối từ và cảm xúc. Người mẫu của chúng ta sử dụng cơ thể lớn và kiến thức từ các mạng lưới ngữ pháp để tạo ra một không gian vector thống nhất của chữ và cảm xúc. Chúng tôi đánh giá các yếu tố chính trong phương pháp của chúng tôi về mặt chất lượng và về chất lượng trong các công việc khác nhau, nhấn mạnh lợi ích của phương pháp được đề nghị so với các mô hình từ và cảm xúc tiên tiến nhất.', 'bg': 'Вградените думи са широко използвани в обработката на естествени езици, главно поради успеха им в улавянето на семантична информация от масивни корпуси. Техният процес на създаване обаче не позволява различните значения на дадена дума да бъдат автоматично разделени, тъй като тя ги смесва в един вектор. Ние решаваме този въпрос, като предложим нов модел, който изучава съвместно вграждането на думи и смисъли. Нашият модел използва големи корпуси и знания от семантични мрежи, за да създаде единно векторно пространство от вграждания на думи и смисъли. Ние оценяваме основните характеристики на нашия подход както качествено, така и количествено в различни задачи, като подчертаваме предимствата на предложения метод в сравнение с най-съвременните модели, базирани на думи и смисъли.', 'nl': "Word embeddings worden veel gebruikt in Natural Language Processing, voornamelijk vanwege hun succes in het vastleggen van semantische informatie uit enorme corpora. Hun creatieproces laat echter niet toe dat de verschillende betekenissen van een woord automatisch worden gescheiden, omdat het ze samenvoegt tot een enkele vector. We pakken dit probleem aan door een nieuw model voor te stellen dat samen woord- en zintuiginbeddingen leert. Ons model maakt gebruik van grote corpora's en kennis van semantische netwerken om een uniforme vectorruimte van woord- en zintuigembeddingen te produceren. We evalueren de belangrijkste kenmerken van onze aanpak zowel kwalitatief als kwantitatief in een verscheidenheid van taken en benadrukken de voordelen van de voorgestelde methode ten opzichte van state-of-the-art woord- en zintuiggebaseerde modellen.", 'hr': 'Uključenje riječi široko se koristi u procesu prirodnog jezika, uglavnom zbog njihovog uspjeha u prihvatanju semantičkih informacija iz masovnog tijela. Međutim, njihov proces stvaranja ne dopušta da se različite znači riječi automatski odvoje, jer ih povezuje u jednog vektora. Razgovaramo s tim pitanjem predloženjem novog model a koji zajedno uči riječ i osjećaj. Naš model iskoristi veliku korporaciju i znanja iz semantičkih mreža kako bi proizveli ujedinjeni vektorski prostor riječi i smisla. Procjenjujemo glavne karakteristike našeg pristupa kvalitativno i kvantitativno u raznim zadacima, naglašavajući prednosti predložene metode u usporedbi s modelima na temelju stanja umjetnosti i smisla.', 'da': 'Ordindlejringer er meget udbredt i Natural Language Processing, primært på grund af deres succes med at fange semantisk information fra massive korpora. Men deres skabelsesproces tillader ikke, at de forskellige betydninger af et ord automatisk adskilles, da det samler dem til en enkelt vektor. Vi løser dette spørgsmål ved at foreslå en ny model, der lærer ord og sanse indlejringer i fællesskab. Vores model udnytter store korpora og viden fra semantiske netværk for at producere et samlet vektorrum af ord og sanse indlejringer. Vi evaluerer hovedtræk ved vores tilgang både kvalitativt og kvantitativt i en række opgaver og fremhæver fordelene ved den foreslåede metode i forhold til state-of-the-art ord- og sansebaserede modeller.', 'de': 'Word-Einbettungen sind in der Natural Language Processing weit verbreitet, vor allem aufgrund ihres Erfolgs bei der Erfassung semantischer Informationen aus massiven Korpora. Ihr Entstehungsprozess erlaubt es jedoch nicht, die verschiedenen Bedeutungen eines Wortes automatisch zu trennen, da es sie zu einem einzigen Vektor zusammenführt. Wir gehen dieses Problem an, indem wir ein neues Modell vorschlagen, das Wort- und Sinneseinbettungen gemeinsam lernt. Unser Modell nutzt große Korpora und Wissen aus semantischen Netzwerken, um einen einheitlichen Vektorraum von Wort- und Sinneseinbettungen zu erzeugen. Wir bewerten die Hauptmerkmale unseres Ansatzes sowohl qualitativ als auch quantitativ in einer Vielzahl von Aufgaben und heben die Vorteile der vorgeschlagenen Methode im Vergleich zu modernen Wort- und Sinnesmodellen hervor.', 'fa': 'استفاده از استفاده کردن کلمات در پردازش زبان طبیعی است، در اصل به خاطر موفقیت آنها در دستگیر اطلاعات semantic از شرکت بزرگی. ولی فرایند آفرینش آنها اجازه نمی دهد که معنی مختلف یک کلمه خود جدا شود، همانطور که آنها را به یک vektor متصل می کند. ما این مسئله را با پیشنهاد یک مدل جدید که کلمه و احساس را به همدیگر یاد می گیرد درباره اش حل می کنیم. مدل ما از شرکت های بزرگ و دانش های شبکه های semantic استفاده می کند تا فضای واحد ویکتور متحده از کلمات و احساسات استفاده کند. ما ویژگی های اصلی از دستور خودمان را با کیفیت و اندازه\u200cای در کارهای مختلف ارزیابی می\u200cکنیم، و سودهایی روش پیشنهاد را در مقایسه با کلمه\u200cهای هنری و مدل\u200cهای بنیادی به حس تخمین می\u200cدهیم.', 'id': 'Pencampuran kata-kata sering digunakan dalam Proses Bahasa Alami, terutama karena sukses mereka dalam menangkap informasi semantis dari corpora besar. Namun, proses penciptaan mereka tidak memungkinkan makna yang berbeda dari satu kata untuk dipisahkan secara otomatis, karena itu mengkonflikasikan mereka ke dalam satu vektor. Kami mengatasi masalah ini dengan mengusulkan model baru yang mempelajari kata-kata dan rasa embedding bersama-sama. Model kami mengeksploitasi corpora besar dan pengetahuan dari jaringan semantis untuk menghasilkan ruang vektor bersatu dari kata dan perasaan embedding. Kami mengevaluasi karakteristik utama pendekatan kita baik kualitatif maupun kuantitatif dalam berbagai tugas, menandakan keuntungan dari metode yang diusulkan dibandingkan dengan model yang terbaik dari kata-kata dan berasaskan.', 'tr': 'Dogaty dil işleýişinde söz integrasy köplenç ulanylýar, iň bellenen köpürden semantik maglumatlaryny yakalamak üçin. Bununla birlikte, oluşturma işlemleri sözlerin farklı anlamlarını otomatik olarak ayırmasına izin vermez çünkü bu, tek vektöre çarpıyor. Biz bu meseleyi täze bir nusga öwrenip söz we duýgulanmagy bilen öwrenip kabul eden nusga çykarýarys. Modelimiz semantik a ğlardan büyük korpora ve bilgimizi kullanır ki, tek vektör kelime ve mantıklı integrler oluşturmak için kullanır. Biz öz yaklaşımyzdaki özelliklerimizi qualitatif we quantitatif şeklinde farklı görevlerde değerlendirip, teklif edilen yöntemin önlemlerini sungat kelimelere karşılaştırmak için teklif edilen çözümleri çözeriz.', 'sw': 'Word embeddings are widely used in Natural Language Processing, mainly due to their success in capturing semantic information from massive corpora.  Hata hivyo, mchakato wao wa kutengeneza hauruhusu maana tofauti ya neno la kutengwa kwa wenyewe, kwa sababu inawafanya kuwa vector moja. Tunajadili suala hili kwa kupendekeza muundo mpya ambao unajifunza maneno na hisia zinazoingia pamoja. Mfano wetu unatumia makampuni makubwa na maarifa kutoka kwenye mitandao ya sekondari ili kutengeneza nafasi ya kutengenezwa kwa maneno na hisia. Tunatathmini vipengele muhimu vya mbinu zetu kwa kiwango na kwa kiasi kikubwa katika kazi mbalimbali, tunaonyesha faida za mbinu zilizopendekezwa kulinganisha na mifano ya maneno ya sanaa na yenye akili.', 'af': "Woord inbettings word heeltemal gebruik in Natuurlike Taal Prosessering, hoofsaaklik vanweë hulle sukses in die opvang van semantiese inligting van groot korpora. Maar hulle skep proses laat nie toe die verskillende betekenings van 'n woord outomaties skei word nie, omdat dit hulle in 'n enkele vektor verskil word nie. Ons adres hierdie probleem deur 'n nuwe model te voorstel wat die woord en sens inbêding saamstig leer. Ons model uitbreek groot korpora en kennis van semantiese netwerke om 'n eenvoudige vektorruimte van woord en sens inbettings te produseer. Ons evalueer die hooffunksies van ons toegang beide kwaliteit en kvantitatiewe in 'n verskillende opdragte, verligting van die voordekende van die voorgestelde metode in vergelyking met staat-van-die-kunstenwoord- en sens-gebaseerde modele.", 'sq': 'Përmbajtja e fjalëve përdoret gjerësisht në procesimin e gjuhës natyrore, kryesisht për shkak të suksesit të tyre në kapjen e informacionit semantik nga korpra masive. However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector.  Ne e trajtojmë këtë çështje duke propozuar një model të ri që mëson fjalë dhe ndjenjë të përfshirjes së bashku. Modeli ynë shfrytëzon korpra të mëdha dhe njohuri nga rrjetet semantike me qëllim që të prodhojë një hapësirë të unifikuar vektori me fjalë dhe kuptim. Ne vlerësojmë karakteristikat kryesore të qasjes sonë si kualitativisht ashtu edhe kuantitativisht në një shumëllojshmëri detyrash, duke theksuar avantazhet e metodës së propozuar në krahasim me modelet më të larta të fjalës dhe të kuptimit.', 'am': 'የቃላት ግንኙነት በተለየ በአዳራዊ ቋንቋ ማቀናቀል በተጠቃሚ ተጠቃሚ ነው፡፡ ምንም እንኳን፣ የፍጥረት ፕሮጀክት የቃላትን የተለየ ቃላት በራስነት እንዲለይ አይፈቅድላቸውም፡፡ ይህንን ጉዳይ አዲስ ሞዴል በመፍጠር እና ቃልን እና ማስታወቂያውን በመጠቀም እናስረዳለን፡፡ Our model exploits large corpora and knowledge from semantic networks in order to produce a unified vector space of word and sense embeddings.  የሥርዓታችንን የዋነኛ ምርጫዎች በተለያዩ ስራ እና በተለየ ቁጥጥር እናሳውቃለን፡፡', 'hy': "Բառերի ներգրավումները լայնորեն օգտագործվում են բնական լեզվի մշակում, հիմնականում նրանց հաջողության պատճառով սեմանտիկ տեղեկատվությունը հսկայական մարմնից վերցնելու համար: However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector.  Մենք լուծում ենք այս խնդիրը առաջարկելով նոր մոդել, որը միասին սովորում է բառեր և զգացմունքներ: Մեր մոդելը օգտագործում է մեծ կառուցվածք և գիտելիքներ սեմանտիկ ցանցերից, որպեսզի ստեղծի բառերի և զգացմունքների միավոր տարածք: Մենք գնահատում ենք մեր մոտեցության հիմնական հատկությունները, որականորեն և քանակականորեն, բազմաթիվ առաջադրանքներում, ներկայացնելով առաջարկած մեթոդի առավելությունները' համեմատելով ամենաբարձր բառերի և իմաստային մոդելների հետ:", 'az': 'Təbiətli dil işləməsində söz in şalları genişliyi ilə istifadə edilir, çox böyük korporadan semantik məlumatlarını almaq üçün onların başarısızlığına görədir. Lakin, onların yaratma prosesi bir sözün fərqli anlamını öz-özünə ayrılmasına izin verməz, çünki bu onları bir vektörə qovuşdurur. Biz bu meseleyi birlikdə sözləri və hissləri öyrənən yeni modeli təbliğ edirik. Modelimiz büyük korpora və bilgi semantik a ğlardan istifadə edir ki, bir vektor alanı sözlərin və hisslərin istifadə etmək üçün. Biz özümüzün tərəfimizin ən böyük xüsusiyyətlərini, həmçin in kvantitatlı və müxtəlif işlərdə değerləşdiririk, təklif edilmiş metodun mənfəətlərini, sanat sözləri və hiss modelləri ilə qarşılaşdırır.', 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়ায় শব্দ ব্যবহার করা হয়েছে, বিশাল কোর্পোরা থেকে সেমেন্টিক তথ্য গ্রহণ করার কারণে। However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector.  নতুন মডেল প্রস্তাব করে আমরা এই বিষয়টিকে আলোচনা করি যেটা একত্রে শব্দ এবং অনুভূতি শিখতে পারে। আমাদের মডেল সেমেন্টিক নেটওয়ার্ক থেকে বিশাল কোর্পোরা এবং জ্ঞান বিস্ফোরণ করেছে যাতে একটি একত্রিত ভেক্টরের স্থান তৈরি  আমরা বিভিন্ন কাজের মধ্যে প্রস্তাবিত পদ্ধতির প্রধান বৈশিষ্ট্যের বৈশিষ্ট্য এবং পরিমাণ মূল্যের মূল্য মূল্যায়ন করি, প্রস্তাবিত পদ্ধতির সুবিধা তুলে ধরি শি', 'ca': "Les integracions de paraules s'utilitzen ampliament en el processament de llenguatges naturals, principalment degut al seu èxit en capturar informació semàntica de corpora massiva. Però el seu procés de creació no permet que els diferents significats d'una paraula siguin separats automàticament, perquè els conflitza en un únic vector. We address this issue by proposing a new model which learns word and sense embeddings jointly.  El nostre model explota grans corpores i coneixements de xarxes semàntiques per a produir un espai de vectors unificat d'incorporacions de paraules i sentits. Evaluam les característiques principals del nostre enfocament tant qualitativament com quantitativament en una varietat de tasques, destacant les avantatges del mètode proposat en comparació amb models basats en paraules i sentits d'última generació.", 'ko': '단어가 자연 언어 처리에 삽입되어 광범위하게 응용되었는데, 주로 대량의 어료 라이브러리에서 의미 정보를 얻는 데 성공했기 때문이다.그러나, 그것들의 창설 과정은 한 단어의 다른 의미가 자동으로 분리되는 것을 허용하지 않는다. 왜냐하면 그것들을 하나의 벡터로 통합하기 때문이다.우리는 새로운 모델을 제시함으로써 이 문제를 해결할 수 있다. 이 모델은 단어와 의미를 연합하여 학습할 수 있다.우리의 모델은 대형 어료 라이브러리와 의미 네트워크의 지식을 이용하여 통일된 단어와 의미를 벡터 공간에 삽입하는 것을 생성한다.우리는 각종 임무에서 정성과 정량 두 가지 측면에서 우리의 방법의 주요 특징을 평가하고 가장 선진적인 단어와 의미를 바탕으로 하는 모델에 비해 제시한 방법의 장점을 강조했다.', 'cs': 'Vložení slov jsou široce používány při zpracování přirozeného jazyka, hlavně díky jejich úspěchu při zachytávání sémantických informací z masivních korpusů. Jejich proces tvorby však neumožňuje automaticky oddělit různé významy slova, protože je sloučí do jediného vektoru. Tuto problematiku řešíme navržením nového modelu, který se společně učí slovo a smysl vložení. Náš model využívá velkých korpusů a znalostí ze sémantických sítí, aby vytvořil sjednocený vektorový prostor slova a smyslu vložení. Hlavní rysy našeho přístupu hodnotíme jak kvalitativně, tak kvantitativně v různých úkolech a zdůrazňujeme výhody navrhované metody ve srovnání s nejmodernějšími modely založenými na slovech a smyslech.', 'bs': 'Uključenje riječi se široko koristi u procesu prirodnog jezika, uglavnom zbog njihovog uspjeha u prihvatanju semantičkih informacija iz masovnog korpora. Međutim, njihov proces stvaranja ne dopušta da se različiti znaci riječi automatski odvoje, jer ih povezuje u jednog vektora. Razgovaramo s tim pitanjem, predložimo novi model koji uči riječ i osjećaj zajedno. Naš model iskoristi veliku korporaciju i znanja iz semantičkih mreža kako bi proizveli ujedinjeni vektorski prostor riječi i smisla. Procjenjujemo glavne karakteristike našeg pristupa kvalitativno i kvantitativno u raznim zadacima, naglašavajući prednosti predložene metode u usporedbi sa modelima na državnoj umjetnosti i na osnovu smisla.', 'et': 'Sõnade manustamist kasutatakse laialdaselt looduskeelte töötlemisel, peamiselt tänu nende edule semantilise teabe kogumisel massiivsetest korpustest. Kuid nende loomisprotsess ei võimalda sõna erinevaid tähendusi automaatselt eraldada, sest see ühendab need üheks vektoriks. Me tegeleme selle küsimusega, pakkudes välja uue mudeli, mis õpib ühiselt sõna- ja tähendusühendusi. Meie mudel kasutab ära suured korpused ja semantilistest võrkudest saadud teadmised, et luua ühtne vektoriruum sõna- ja tähendusruumidest. Hindame oma lähenemisviisi põhijooni nii kvalitatiivselt kui kvantitatiivselt erinevates ülesannetes, rõhutades väljapakutud meetodi eeliseid võrreldes kaasaegsete sõna- ja tähenduspõhiste mudelitega.', 'fi': 'Sanaupotuksia käytetään laajasti luonnollisessa kielenkäsittelyssä, lähinnä siksi, että ne onnistuvat keräämään semanttista tietoa massiivisista korpusista. Niiden luontiprosessi ei kuitenkaan salli sanan eri merkitysten automaattista erottamista toisistaan, koska se yhdistää ne yhdeksi vektoriksi. Käsittelemme tätä kysymystä ehdottamalla uutta mallia, joka oppii sanan ja merkityksen yhdistämisen yhdessä. Mallimme hyödyntää suuria korporaatioita ja tietoa semanttisista verkoista luodakseen yhtenäisen vektoritilan sanan ja merkityksen upotuksista. Arvioimme lähestymistapamme pääpiirteitä sekä laadullisesti että määrällisesti erilaisissa tehtävissä korostaen ehdotetun menetelmän etuja verrattuna uusimpiin sana- ja aistipohjaisiin malleihin.', 'jv': 'Aspect ratio politenessoffpolite"), and when there is a change ("assertivepoliteness @title: window Awak dhéwé model nambah kebebasané perusahaan lan alam-alam kuwi semantar tentang kanggo ngelaran perusahaan vector sing beraksi sing larang awak dhéwé lan sampeyan ngerasakno Awak dhéwé éntuk ngéwé cara-cara sing nggawe akeh podho kalitatif lan anggawe lan ijol-ijolan winih kanggo kalagayut nggawe nguasai perusahaan karo perusahaan langgar sampek karo state-of-the-arts word- lan model sing wis dianggawe barang sistem.', 'sk': 'Vgradnje besedil se pogosto uporabljajo v obdelavi naravnega jezika, predvsem zaradi njihovega uspeha pri zajemanju semantičnih informacij iz masivnih korpusov. Vendar njihov proces ustvarjanja ne omogoča samodejnega ločevanja različnih pomenov besede, saj jih združuje v en sam vektor. To vprašanje obravnavamo s predlogom novega modela, ki skupaj uči vključevanje besed in smisla. Naš model izkorišča velike korpuse in znanje iz semantičnih omrežij, da bi ustvaril enoten vektorski prostor vključevanja besed in smisla. Glavne značilnosti našega pristopa ocenjujemo tako kvalitativno kot kvantitativno v različnih nalogah, pri čemer poudarjamo prednosti predlagane metode v primerjavi z najsodobnejšimi besednimi in smiselnimi modeli.', 'ha': "@ item: inmenu Text Completion However, their creation process does not allow the different meanings of a word to be automatically separated, as it conflates them into a single vector.  Munã jãyayya wannan masu al'amarin da za'a buɗe wani misali na daban, wanda yana sanar da magana da fahimci wanda ya haɗa shi. Misalinmu yana samun makampuni mai girma da ilmi daga mitandaki na semantiki dõmin ya zaɓe wani fili na haɗi da maganar da ma'abũta. Tuna ƙaddara masu muhimmin hanyoyinmu a cikin aikin nan masu iya lissafa da gwargwadon, ko kuma masu ƙayyade abũbuwan amfani na hanyor da aka buƙata a sami da misãlai-na-maganar-sanar da masu hankali.", 'he': 'תוספת מילים משתמשות באופן רחב בתהליך שפת טבעית, בעיקר בגלל הצלחתם בכניסה לתפוס מידע סמנטי מקבורה מסיבית. עם זאת, תהליך יצירתם לא מאפשר את המשמעות השוניות של מילה להיפרד באופן אוטומטי, כיוון שהיא מפריעה אותם לוקטור אחד. We address this issue by proposing a new model which learns word and sense embeddings jointly.  המודל שלנו מנצל גופורה גדולה וידע מרשתות סמנטיות כדי לייצר מרחב וקטור מאוחד של מילים ומחשים. אנו מעריכים את האופיינים העיקריים של הגישה שלנו באופן איכותי וכוונטיבי במגוון של משימות, ומדגישים את היתרונות של השיטה המוצעת בהשוואה למודלים המפורסמים ומבוססים בהיגיון.', 'bo': 'སྐད་ཡིག་གནས་སྟངས་ཀྱི་ཆ་རྐྱེན་དུ་རང་བཞིན་པའི་སྐད་ཡིག་ལས་སྦྱོར་བའི་ནང་དུ་སྤྱོད་ཡོད། ཡིན་ནའང་། ཁོང་ཚོའི་གསར་འཛུགས་ཀྱི་ལས་སྦྱོར་གྱིས་ཐ་སྙད་ཅིག་རང་འགུལ་གྱིས་དབྱེ་བ་རེད་མི་ཆོག་ཐང་། ང་ཚོས་བྱ་ཚིག་དང་མཐུན་སྒྲིག་གི་མ་དཔེ་གསར་པ་ཞིག་གིས་བསམ་བློ་གཏོང་བ་དེ་ལ། ང་ཚོའི་མ་དབྱིབས་འདིས་སྔར་འབྲེལ་གྱི་མཐུད་རིམ་དང་སྦྲེལ་མཐུད་ཆེན་པོ་ཞིག་ལག་ལེན་འཐབ་པའི་བར་སྟོང་དང་མཐུད་སྒྲིག་ ང་ཚོས་རང་གི་གཟུགས་སྐོར་གྱི་རྩ་བའི་ཁྱད་ཆོས་ཡོད་ཚད་དང་གྲངས་སུ་འབྲེལ་བ་མ་འདྲ་ཡིན་པ་ལས་སྔོན་སྒྲིག་གི་ཐབས་ལམ་ལ་མཉམ་འབྱུང་བ'}
{'en': 'An Artificial Language Evaluation of Distributional Semantic Models', 'ar': 'تقييم لغة اصطناعية للنماذج الدلالية التوزيعية', 'pt': 'Uma Avaliação de Linguagem Artificial de Modelos Semânticos Distribucionais', 'fr': 'Évaluation du langage artificiel des modèles sémantiques distributionnels', 'es': 'Una evaluación del lenguaje artificial de los modelos semánticos distribucionales', 'ru': 'Искусственная языковая оценка семантических моделей распределения', 'hi': 'वितरण शब्दार्थ मॉडल का एक कृत्रिम भाषा मूल्यांकन', 'ja': '分布セマンティックモデルの人工言語評価', 'zh': '一种布语义模形的人工语言评价', 'ga': 'Measúnú Teanga Saorga ar Mhúnlaí Séimeantacha Dáilte', 'ka': 'Name', 'el': 'Μια Τεχνητή Γλωσσική Αξιολόγηση Κατανεμητικών Σημαντικών Μοντέλων', 'hu': 'Az eloszlási szemantikus modellek mesterséges nyelvi értékelése', 'it': 'Valutazione del linguaggio artificiale dei modelli semantici distributivi', 'lt': 'Dirbtinis paskirstymo Semantinių modelių kalbų vertinimas', 'kk': 'Үлестірілген семантикалық үлгілердің мақсатты тілді оқу', 'ml': 'Name', 'mk': 'Уметна евалуација на јазикот на дистрибуционалните семантични модели', 'ms': 'Evaluasi Bahasa Artificial bagi Model Semantik Pembahagian', 'mt': 'Evalwazzjoni tal-Lingwa Artifikali tal-Mudelli Semantiċi Distribuzzjonali', 'no': 'Name', 'pl': 'Sztuczna ocena języka dystrybucyjnego modeli semantycznych', 'mn': 'Хувьсгалтын Semantic Загварын уран бүтээлийн хэл үнэлгээ', 'ro': 'Evaluarea limbajului artificial al modelelor semantice distribuționale', 'sr': 'Umetna procjena jezika distribucijskih semantičkih modela', 'si': 'Name', 'so': 'Qiimeynta luqada farshaxanka', 'sv': 'Ett artificiellt språk Utvärdering av distribuerade semantiska modeller', 'ta': 'Name', 'ur': 'Name', 'uz': 'An Artificial Language Evaluation of Distributional Semantic Models', 'vi': 'Bài đánh giá ngôn ngữ nhân tạo của các mô- đun bầu dục', 'hr': 'Umjetna procjena jezika distribucijskih semantičkih modela', 'bg': 'Изкуствена езикова оценка на дистрибуционните семантични модели', 'da': 'Et kunstigt sprog evaluering af fordelingssemantiske modeller', 'nl': 'Een Artificial Language Evaluation van Distributionele Semantische Modellen', 'de': 'Eine künstliche sprachliche Evaluation verteilter semantischer Modelle', 'id': 'Evaluasi Bahasa Sendiri Model Semantik Distributional', 'ko': '분포식 의미 모델의 인공 언어 평가', 'sw': 'Uthibitisho wa Lugha ya Kisanaa wa Modeli za Kimataifa', 'af': 'Name', 'sq': 'Një vlerësim i gjuhës artificiale të modeleve semantike shpërndarëse', 'fa': 'Name', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'tr': 'Çaplanjak Semantik nusgalaryň Ýabşyrymy', 'az': 'Bölüşdürülən Semantik Modellərin Yaxşı Dil Qıymeti', 'bn': 'Name', 'ca': 'Una Evaluació Artificial de Llingua de Models Semàtics Distributius', 'hy': 'Արվեստական լեզվի գնահատում տարածական սեմատիկ մոդելների', 'cs': 'Umělé jazykové hodnocení distribučních sémantických modelů', 'bs': 'Umjetna procjena jezika distribucijskih semantičkih modela', 'et': 'Jaotussemantiliste mudelite kunstliku keele hindamine', 'fi': 'Jakelun semanttisten mallien keinotekoinen kieliarviointi', 'jv': 'Language', 'he': 'עריכת שפת מלאכותית של דוגמנים סמנטיים פיצועיים', 'ha': 'KCharselect unicode block name', 'sk': 'Vrednotenje umetnega jezika distribucijskih semantičnih modelov', 'bo': 'རྩིས་པ་ཅན་གྱི་སྐད་ཡིག་གཟུགས་རིས་དབྱེ་རིགས་ཀྱི་ཚད་ལྟར་ཞིབ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Recent studies of distributional semantic models have set up a competition between word embeddings obtained from predictive neural networks and word vectors obtained from abstractive count-based models. This paper is an attempt to reveal the underlying contribution of additional training data and post-processing steps on each type of model in word similarity and relatedness inference tasks. We do so by designing an artificial language framework, training a predictive and a count-based model on data sampled from this grammar, and evaluating the resulting word vectors in paradigmatic and syntagmatic tasks defined with respect to the grammar.', 'pt': 'Estudos recentes de modelos semânticos distribucionais estabeleceram uma competição entre embeddings de palavras obtidos de redes neurais preditivas e vetores de palavras obtidos de modelos baseados em contagem abstrativos. Este artigo é uma tentativa de revelar a contribuição subjacente de dados de treinamento adicionais e etapas de pós-processamento em cada tipo de modelo em tarefas de inferência de similaridade e parentesco de palavras. Fazemos isso projetando uma estrutura de linguagem artificial, treinando um modelo preditivo e baseado em contagem em dados amostrados dessa gramática e avaliando os vetores de palavras resultantes em tarefas paradigmáticas e sintagmáticas definidas com relação à gramática.', 'es': 'Estudios recientes de modelos semánticos distribucionales han establecido una competencia entre las incrustaciones de palabras obtenidas de redes neuronales predictivas y los vectores de palabras obtenidos de modelos abstractivos basados en recuentos. Este artículo es un intento de revelar la contribución subyacente de los datos de entrenamiento adicionales y los pasos posteriores al procesamiento en cada tipo de modelo en las tareas de inferencia de similitud de palabras y relación. Lo hacemos diseñando un marco de lenguaje artificial, entrenando un modelo predictivo y basado en recuentos con datos muestreados de esta gramática y evaluando los vectores de palabras resultantes en tareas paradigmáticas y sintagmáticas definidas con respecto a la gramática.', 'fr': "Des études récentes de modèles sémantiques distributionnels ont mis en place une compétition entre les intégrations de mots obtenues à partir de réseaux neuronaux prédictifs et les vecteurs de mots obtenus à partir de modèles abstraits basés sur le comptage. Cet article tente de révéler la contribution sous-jacente des données de formation supplémentaires et des étapes de post-traitement sur chaque type de modèle dans les tâches de similarité de mots et d'inférence de parenté. Pour ce faire, nous concevons un cadre de langage artificiel, formons un modèle prédictif et un modèle basé sur le nombre à partir de données échantillonnées à partir de cette grammaire, et évaluons les vecteurs de mots résultants dans des tâches paradigmatiques et syntagmatiques définies par rapport à la grammaire.", 'ar': 'أقامت الدراسات الحديثة للنماذج الدلالية التوزيعية منافسة بين زخارف الكلمات التي تم الحصول عليها من الشبكات العصبية التنبؤية ونواقل الكلمات التي تم الحصول عليها من النماذج المستندة إلى العد التجريدي. هذه الورقة هي محاولة للكشف عن المساهمة الأساسية لبيانات التدريب الإضافية وخطوات المعالجة اللاحقة لكل نوع من أنواع النماذج في مهام تشابه الكلمات واستدلال الصلة. نقوم بذلك من خلال تصميم إطار عمل لغوي اصطناعي ، وتدريب نموذج تنبؤي وقائم على العد على البيانات المأخوذة من هذه القواعد ، وتقييم متجهات الكلمات الناتجة في المهام النموذجية والنحوية المحددة فيما يتعلق بالقواعد.', 'zh': '近者分布语义模形之论神经网络得词嵌与抽象之数争于词向量之间。 本文欲揭在词相似性及相关性推理,每形额外训练数后处理步骤者潜于贡献。 设一工之言框架,取语法之数以训占之,系语法之范语法之辞向量以成之。', 'ja': '最近の分布意味モデルの研究は、予測ニューラルネットワークから得られた単語埋め込みと、抽象的なカウントベースのモデルから得られた単語ベクトルとの間の競合を設定している。この論文は、単語の類似性と関連性の推論タスクにおける各タイプのモデルにおける追加のトレーニングデータと後処理ステップの基礎的な貢献を明らかにしようとする試みである。人工言語フレームワークを設計し、この文法からサンプリングされたデータに基づいた予測モデルとカウントモデルをトレーニングし、文法に関して定義されたパラダイム的および構文的タスクの結果として得られるワードベクトルを評価することによって行われます。', 'hi': 'वितरणात्मक शब्दार्थ मॉडल के हाल के अध्ययनों ने भविष्यवाणी तंत्रिका नेटवर्क से प्राप्त शब्द एम्बेडिंग और अमूर्त गिनती-आधारित मॉडल से प्राप्त शब्द वैक्टर के बीच एक प्रतियोगिता स्थापित की है। यह पेपर शब्द समानता और संबंधितता अनुमान कार्यों में प्रत्येक प्रकार के मॉडल पर अतिरिक्त प्रशिक्षण डेटा और पोस्ट-प्रोसेसिंग चरणों के अंतर्निहित योगदान को प्रकट करने का एक प्रयास है। हम एक कृत्रिम भाषा ढांचे को डिजाइन करके, इस व्याकरण से नमूने वाले डेटा पर एक भविष्यवाणी और गणना-आधारित मॉडल को प्रशिक्षित करके, और व्याकरण के संबंध में परिभाषित किए गए रूपात्मक और सिंटाग्मैटिक कार्यों में परिणामी शब्द वैक्टर का मूल्यांकन करके ऐसा करते हैं।', 'ru': 'Недавние исследования семантических моделей распределения создали конкуренцию между вложениями слов, полученными из прогностических нейронных сетей, и векторами слов, полученными из абстрактных основанных на подсчете моделей. Настоящий документ представляет собой попытку раскрыть основной вклад дополнительных данных обучения и этапов последующей обработки для каждого типа модели в задачах сходства слов и вывода о взаимосвязанности. Мы делаем это путем разработки структуры искусственного языка, обучения прогностической и основанной на подсчете модели на данных, выбранных из этой грамматики, и оценки результирующих векторов слов в парадигматических и синтагматических задачах, определенных в отношении грамматики.', 'ga': 'Tá comórtas curtha ar bun ag staidéir le déanaí ar shamhlacha dáilte shéimeantacha idir leabaithe focal a fhaightear ó líonraí néaracha thuarthacha agus veicteoirí focal a fhaightear ó shamhlacha bunaithe ar chomhaireamh teibí. Iarracht atá sa pháipéar seo chun an méid a chuireann sonraí oiliúna breise agus na céimeanna iar-phróiseála ar gach cineál múnla i dtascanna tátail cosúlachta agus gaolta le chéile a nochtadh. Déanaimid é sin trí chreat teanga shaorga a dhearadh, samhail thuarthach agus bunaithe ar chomhaireamh a oiliúint ar shonraí a samplaíodh as an ngramadach seo, agus trí na veicteoirí focal a thagann as a mheas i dtascanna paradigmatacha agus síntagmatacha a shainítear maidir leis an ngramadach.', 'ka': 'აბსტრაქტიური სიმენტიკური მოდელების ახალი კვლევების შესაბამისი სიტყვების შესაბამისი სიტყვების შესაბამისი სიტყვების შესაბამისი ნეიროლური ქსელებიდან და სიტყვების გვექტორებ ეს დოკუმენტი არის მოცდილობა, რომ აღმოჩვენოთ დამატებული მონაცემების დამატებული მონაცემების და პოსპროცესის მონაცემების განმავლობაში ყველა ტიპის მოდელეში სიტყვების სიმბოლობა ჩვენ ამას ვაკეთებთ კულტური ენის ფრამეტრის განაზღვრებით, პროგრამეტური და მნიშვნელოვანი მოდელის მონაცემებზე, რომელიც ამ გრამეტრიდან გამოიყენებული მონაცემებზე, და გავაკეთებთ შემდეგ სიტყვების გვეკტერების', 'el': 'Πρόσφατες μελέτες σημασιολογικών μοντέλων κατανομής έχουν δημιουργήσει έναν ανταγωνισμό μεταξύ ενσωμάτωσης λέξεων που λαμβάνονται από προγνωστικά νευρωνικά δίκτυα και διανύσματα λέξεων που λαμβάνονται από αφηρημένα μοντέλα μέτρησης. Η παρούσα εργασία είναι μια προσπάθεια να αποκαλύψει την υποκείμενη συμβολή των πρόσθετων δεδομένων κατάρτισης και των βημάτων μετεπεξεργασίας σε κάθε τύπο μοντέλου σε εργασίες συμπερασμάτων ομοιότητας λέξεων και συγγένειας. Το κάνουμε αυτό σχεδιάζοντας ένα τεχνητό γλωσσικό πλαίσιο, εκπαιδεύοντας ένα προβλέψιμο και ένα μοντέλο βασισμένο στον αριθμό δεδομένων που λαμβάνονται από αυτή τη γραμματική, και αξιολογώντας τα προκύπτουσα διανύσματα λέξεων σε παραδειγματικές και συντακτικές εργασίες που ορίζονται σε σχέση με τη γραμματική.', 'hu': 'A disztribúciós szemantikai modellek közelmúltbeli tanulmányai versenyt teremtettek a prediktív neurális hálózatokból nyert szóbeágyazások és az absztraktív számláló modellekből nyert szóvektorok között. Ez a tanulmány arra törekszik, hogy feltárja a további képzési adatok és utófeldolgozási lépések alapjául szolgáló hozzájárulását minden modelltípushoz a szóhasonlóság és a kapcsolódó következtetések feladataiban. Ezt mesterséges nyelvi keretrendszer kialakításával, prediktív és számláláson alapuló modellt készítünk az ebből a nyelvtani adatokból mintázott adatokra, valamint a nyelvtani vonatkozásában meghatározott paradigmatikus és szintagmatikus feladatokban értékeljük.', 'it': 'Recenti studi di modelli semantici distributivi hanno creato una competizione tra incorporazioni di parole ottenute da reti neurali predittive e vettori di parole ottenuti da modelli astratti basati sul conteggio. Questo articolo è un tentativo di rivelare il contributo sottostante di ulteriori dati di formazione e fasi di post-elaborazione su ogni tipo di modello in attività di inferenza di somiglianza delle parole e relatedness. Lo facciamo progettando un framework linguistico artificiale, addestrando un modello predittivo e basato sul conteggio su dati campionati da questa grammatica e valutando i vettori di parola risultanti in attività paradigmatiche e sintagmatiche definite rispetto alla grammatica.', 'lt': 'Recent studies of distributional semantic models have set up a competition between word embeddings obtained from predictive neural networks and word vectors obtained from abstractive count-based models.  Šis dokumentas yra bandymas atskleisti papildomų mokymo duomenų ir po apdorojimo etapų, susijusių su kiekvienu modelio tipu, įnašą žodžių panašumo ir susijusių išvadų užduotyse. We do so by designing an artificial language framework, training a predictive and a count-based model on data sampled from this grammar, and evaluating the resulting word vectors in paradigmatic and syntagmatic tasks defined with respect to the grammar.', 'mk': 'Неодамнешните студии на дистрибуционалните семантични модели воспоставија конкуренција помеѓу зборовите внесени од предвидливите нервни мрежи и зборовите вектори добиени од апстрактивните модели базирани на број. Овој документ е обид да го открие основниот придонес на дополнителните податоци за обука и постобработувањето на секој вид на модел во задачите на сличност на зборовите и конференција на врските. We do so by designing an artificial language framework, training a predictive and a count-based model on data sampled from this grammar, and evaluating the resulting word vectors in paradigmatic and syntagmatic tasks defined with respect to the grammar.', 'kk': 'Жуырдағы дистрибуциялық семантикалық моделдердің зерттеулері абстрактивтік санды негіздеген үлгерден алған невралдық желілерден және сөздер векторларынан алған сөздерді ендіру арасындағы конкурс орнатылды Бұл қағаз сөздердің ұқсас пен қатынастық тапсырмалардың әрбір түрінде қосымша оқыту деректерінің негізгі қатынасын көрсету әрекеті. Біз оны грамматикадан үлгілеген деректерді бақылап, бақылайтын тілдер қоршауын құрастырып, грамматиканың парадигматикалық және синтагматикалық тапсырмаларында анықталған сөз векторларын оқу үшін жасаймыз.', 'mt': 'Studji reċenti ta’ mudelli semantiċi distributtivi stabbilixxew kompetizzjoni bejn l-inkorporazzjonijiet tal-kliem miksuba minn netwerks newrali prevedibbli u vetturi tal-kliem miksuba minn mudelli astratti bbażati fuq l-għadd. Dan id-dokument huwa tentattiv li jiżvela l-kontribut sottostanti ta’ dejta addizzjonali ta’ taħriġ u passi ta’ wara l-ipproċessar fuq kull tip ta’ mudell f’kompiti ta’ inferenza ta’ similarità tal-kliem u relatati. Aħna nagħmlu dan billi niddisinjaw qafas lingwistiku artifiċjali, in ħarrġu mudell prevedibbli u bbażat fuq l-għadd tad-dejta meħuda mill-kampjun minn din il-gramma, u jivvalutaw il-vetturi tal-kliem li jirriżultaw f’kompiti paradigmatiċi u sintagmatiċi definiti fir-rigward tal-gramma.', 'ml': 'വിതരണ മോഡലുകളുടെ അടുത്തുള്ള പഠനങ്ങള്\u200d പ്രവചിക്കപ്പെട്ട ന്യൂറല്\u200d നെറുല്\u200d നെറുല്\u200d നെറുല്\u200d നെറ്ററില്\u200d നിന്നും വാക്ക് വെക്റ്ററുകളില്\u200d ന ഈ പത്രത്തില്\u200d കൂടുതല്\u200d പരിശീലന വിവരങ്ങളും പിന്നീട് പ്രവര്\u200dത്തിപ്പിക്കുന്ന എല്ലാ തരത്തിലുള്ള മോഡലിന്റെയും അടിസ്ഥാനത്തിലുള്ള പങ്കും  ഈ ഗ്രാമാരില്\u200d നിന്ന് ഉപയോഗിക്കപ്പെട്ട ഡാറ്റാമോഡലിനെയും പരിശീലിപ്പിക്കുന്നതും ഈ ഗ്രാമാറില്\u200d നിന്നും വിശദീകരിക്കുന്ന വാക്ക് വെക്റ്റോര്\u200dക്കുകളെ പരിഗണിക', 'mn': 'Шинэ хуваарилалтын семантик загварын судалгаанууд шинэ сэтгэл зүйн сүлжээ болон хэлбэрийн векторуудыг abstractive number-based загвараас авсан үгний хоорондын өрсөлдөөн байгуулсан. Энэ цаас бол нэмэлт сургалтын өгөгдлийн үндсэн нөлөө, дараа үйлдвэрлэлийн алхам бүр хэлбэрийн загварын нэг төрлийн адилхан, харилцааны хамааралтай үйл ажиллагааг илтгэх зорилго юм. Бид үүнийг уран бүтээлч хэл хэлний хэлбэрийг бүтээж, грамматаас гарсан өгөгдлийн зураг дээр таамаглах болон тооны загварыг суралцаж, грамматаар тодорхойлогдсон парадигматик болон синтагматик даалгаварын үр дүнг нь үнэлж үздэг.', 'ms': 'kajian baru-baru ini mengenai model semantik distribusi telah menetapkan persaingan antara pembenaman perkataan yang diperoleh dari rangkaian saraf ramalan dan vektor perkataan yang diperoleh dari model berasaskan kiraan abstraktif. This paper is an attempt to reveal the underlying contribution of additional training data and post-processing steps on each type of model in word similarity and relatedness inference tasks.  Kami melakukannya dengan merancang kerangka bahasa buatan, melatih model ramalan dan berdasarkan kiraan pada data yang dicampur dari grammar ini, dan menilai vektor perkataan yang berasal dalam tugas paradigmatik dan sintagmatik yang ditakrif berkaitan dengan grammar.', 'pl': 'Ostatnie badania dystrybucyjnych modeli semantycznych ustanowiły konkurencję między osadzeniami słów uzyskanymi z predykcyjnych sieci neuronowych a wektorami słowa uzyskanymi z abstrakcyjnych modeli liczeniowych. Niniejszy artykuł stanowi próbę ujawnienia podstawowego wkładu dodatkowych danych szkoleniowych i etapów postprocesowych dla każdego typu modelu w zadaniach związanych z podobieństwem słów i wnioskowaniem związków. Robimy to poprzez projektowanie sztucznego frameworku językowego, szkolenie modelu predykcyjnego i opartego na liczeniu na danych pobranych z tej gramatyki oraz ocenę powstałych wektorów słowa w zadaniach paradygmatycznych i syntagmatycznych zdefiniowanych w odniesieniu do gramatyki.', 'ro': 'Studiile recente ale modelelor semantice distributionale au creat o competitie intre incorporarile de cuvinte obtinute din retele neuronale predictive si vectorii de cuvinte obtinuti din modele abstractive bazate pe numar. Această lucrare este o încercare de a dezvălui contribuția de bază a datelor suplimentare de instruire și a etapelor post-procesare pe fiecare tip de model în sarcinile de inferență a similitudinii cuvintelor și relației. Facem acest lucru prin proiectarea unui cadru de limbaj artificial, instruirea unui model predictiv și bazat pe numărătoare pe datele eșantionate din această gramatică și evaluarea vectorilor de cuvânt rezultați în sarcini paradigmatice și sintagmatice definite în raport cu gramatica.', 'si': 'අලුත් විදුලිය සෙමාන්ටික් මොඩේල්ස් ගැන ප්\u200dරශ්නයක් ස්ථාපනය කරලා තියෙන්නේ වචන ඇම්බෙන්ඩින්ග් අතර ප්\u200dරශ්නයක් තියෙන මේ පත්තුව තමයි වචන සමාන්\u200dයතාවක් සහ සම්බන්ධතාවක් වෙනුවෙන් හැම ප්\u200dරමාණ වර්ගයක්ම වචන සහ සම්බන්ධතාවක් පරීක්ෂණය කරපු ව අපි ඒක කරන්නේ කිරීම භාෂාවක් සංයෝජනය කරන්න, ප්\u200dරශ්නයක් හා ගණන් සංයෝජනයක් සංයෝජනය කරන්න, මේ ග්\u200dරාමාර්කයෙන් සංයෝජනය කරලා තියෙන දත්ත ස', 'sr': 'Nedavno ispitivanje distribucijskih semantičkih modela uspostavili su konkurenciju između uključenih riječi iz predviđavajućih neuralnih mreža i vektori riječi koji su dobili od modela na apstraktivnom broju. Ovaj papir je pokušaj otkrivanja temeljnog doprinosa dodatnih podataka o obuci i koraka nakon obrade na svakom vrstu modela u rečima sličnosti i zadataka o infekciji povezanosti. To radimo izrađivanjem umjetničkog jezičkog okvira, obučavanjem predviđenog i brojnog model a na podacima uzorke iz ove gramatike, i procjenjivanjem rezultatnih vektora riječi u paradigmatskim i sintakmatskim zadacima definisanim u vezi gramatike.', 'so': 'Waxbarashada noocyada qaybsiga ee qaybsiga ayaa ka dhigay khilaaf ku saabsan hadal-ka mid ah oo laga helay shabakado neurada iyo qalabka ereyga oo laga helay tusaalooyin tiro ah oo aan waxtar lahayn. Qoraalkan wuxuu isku dayaa in uu muujiyo kharashka hoose ee macluumaadka waxbarashada dheeraad ah iyo tallaabooyin ka baaraandegista dabaraad tusaale kasta oo hadal u eg iyo shaqooyin la xiriira. Waxaynu sameynaa si a an u sameynno qorshaha afka farsamada ah, baaritaanno qaab wax la sii sheego iyo tusaale ku saabsan tijaabada oo lagu sameynayo takoorkan, waxaana qiimeynaynaa wadooyinka ereyga ka soo baxay oo ku qoran shaqooyinka sawirada iyo sawirada lagu qoray xarunta.', 'sv': 'Nyligen genomförda studier av distributionsmässiga semantiska modeller har skapat en konkurrens mellan ordinbäddningar erhållna från prediktiva neurala nätverk och ordvektorer erhållna från abstrakta räknebaserade modeller. Denna uppsats är ett försök att avslöja det underliggande bidraget av ytterligare utbildningsdata och efterbehandlingssteg för varje typ av modell i ordlikhets- och relatedness inference uppgifter. Det gör vi genom att utforma ett artificiellt språkramverk, träna en prediktiv och räknebaserad modell på data som hämtats från denna grammatik, och utvärdera de resulterande ordvektorerna i paradigmatiska och syntagmatiska uppgifter definierade med avseende på grammatiken.', 'ta': 'சமீபத்தில் பங்கீட்டு பாதிப்பு மாதிரிகளின் ஆராய்ச்சிகள் எதிர்பார்க்கப்பட்ட புதிய புதிய வலைப்பின்னல் மற்றும் வார்த்து நெறிகளில இந்த தாள் கூடுதல் பயிற்சி தரவுகள் மற்றும் பின்செயல்படுத்தல் படிகள் ஒவ்வொரு வகையான மாதிரியில் உள்ள அடிப்படையான பங்கை வெளிப்படுத்த மு நாம் இதை வடிவமைக்கிறோம் ஒரு சார்ந்த மொழி சட்டத்தை வடிவமைத்து, இந்த வரைப்படத்திலிருந்து முயற்சிக்கப்பட்ட தகவல் மாதிரியை பயிற்சி செய்கிறோம் மற்றும் முடிவு வார்', 'no': 'Nyleg studier av distribusjonssemantiske modeller har sett opp ein konkurrans mellom ordinnbygging som er henta frå foregåande neiralnettverk og ordvektorar som er henta frå abstraktive tal baserte modeller. Denne papiret er ein prøv å oppdaga undergrunnleggjande bidrag på fleire opplæringsdata og posthandlingsteg på kvar type modell i ordsimilaritet og tilsvaringsoppgåver. Vi gjer det ved å utforme eit kunstige språk-rammeverk, opplæring av eit foregåve og eit tal-basert modell på datautvalet frå denne grammatikken, og evaluering av resultatet ordvektorane i paradigmatiske og syntagmatiske oppgåver som er definert med hensyn til grammatikken.', 'ur': 'تقسیم سیمنٹی موڈل کے اخیر تحقیقات میں ایک مقابلہ مقرر کیا گیا ہے کلمات کے اندر جو پیش بینی نیورل نیٹورک سے حاصل ہوئی ہیں اور کلمات ویکتروں کے ذریعہ سے حاصل ہوئے ہیں۔ یہ کاغذ ایک کوشش ہے کہ کلمات کے مطابق اور رابطہ داری کے ذریعے اضافہ تطابق ڈاٹے اور پوسٹ پرسس کرنے کے بعد ہر قسم کے مدل پر اضافہ کرے۔ ہم ایسا کر رہے ہیں کہ ایک قابل زبان فرمیک طراحی کریں، ایک پیش بینی اور گنتی کی مدل کی تعلیم کریں، اس گرامماری سے نمونہ لکھی ہوئی ڈاٹے پر، اور اس کے نتیجۂ کلمات ویکتروں کو نمونہ لیتے ہیں جو گراماری کے معاملہ میں مقرر کئے گئے ہیں۔', 'uz': "Yaqinda taʼminlovchi semantik modellarini taʼminlovchi so'zlar tarmoqlaridan olingan so'zlar tarmoq va so'zlar vektoridan tashkilotga ega so'zlar tarkibini o'zgartiradi. Ushbu qogʻoz qoʻshish taʼminlovchi maʼlumot va keyingi boshqarish tugmalarining eng asosiy foydalanuvchi soʻzning bir turdagi modeldagi o'xshash va murakkablik vazifalari bilan bogʻliq. Biz shunday qilamiz, bu grammadan misol qilingan maʼlumot va hisoblash modelini aniqlash va natijasida so ʻzlar vectorlarini paradigmatik va syntagmatik vazifalar bilan aniqlangan vazifalarni qiymatmiz.", 'vi': 'Những nghiên cứu gần đây về mô hình phân phối ngữ pháp đã tạo ra một cuộc cạnh tranh giữa sự nhúng vào từ các mạng thần kinh dự đoán và các cỗ máy từ được lấy từ các mô hình con số trừu tượng. Tờ giấy này là một nỗ lực tiết lộ sự đóng góp tiềm ẩn của những dữ liệu huấn luyện bổ sung và những bước xử lý sau mỗi kiểu mô hình trong các công việc nhận dạng từ giống nhau và liên quan. Chúng ta sẽ làm thế bằng cách thiết kế một bộ dạng ngôn ngữ nhân tạo, đào tạo một mô hình dự đoán và dựa trên các dữ liệu lấy từ ngữ pháp này, và đánh giá các từ trung gian truyền hình và theo ngữ pháp được xác định với ngữ pháp.', 'bg': 'Последните проучвания на дистрибуционните семантични модели създават конкуренция между вграждането на думи, получени от предсказуеми невронни мрежи, и векторите на думи, получени от абстрактни модели, базирани на броене. Настоящата статия е опит да се разкрие основният принос на допълнителните данни за обучение и стъпките за последваща обработка на всеки тип модел в задачите за сходство на думите и изводи за свързаност. Ние правим това чрез проектиране на изкуствена езикова рамка, обучение на предсказуем и базиран на броя модел на данни, взети от тази граматика, и оценка на получените вектори на думи в парадигматични и синтагматични задачи, дефинирани по отношение на граматиката.', 'hr': 'Nedavno ispitivanje distribucijskih semantičkih modela uspostavili su konkurenciju između uključenih riječi iz predvidnih neuralnih mreža i vektori riječi koje su dobili od modela na apstraktivnom broju. Ovaj papir je pokušaj otkrivanja temeljnog doprinosa dodatnih podataka o obuci i koraka nakon obrade na svakom vrstu modela u zadatku sličnosti riječima i infekcije povezanosti. To radimo izrađivanjem umjetnog jezičkog okvira, obučavanjem predviđenog i brojnog model a na podacima uzorke iz ove gramatike i procjenjivanjem rezultatnih vektora riječi u paradigmatskim i sintakmatskim zadacima definiranim u vezi gramatike.', 'de': 'Jüngste Studien zu distributionalen semantischen Modellen haben einen Wettbewerb zwischen Worteinbettungen aus prädiktiven neuronalen Netzen und Wortvektoren aus abstraktiven Zählmodellen aufgebaut. In diesem Beitrag wird versucht, den zugrunde liegenden Beitrag zusätzlicher Trainingsdaten und Nachbearbeitungsschritte für jede Art von Modell in Textähnlichkeits- und Relatedness-Inferenz-Aufgaben aufzuzeigen. Dazu entwerfen wir ein künstliches Sprachframework, trainieren ein prädiktives und zählbasiertes Modell auf Daten aus dieser Grammatik und evaluieren die resultierenden Wortvektoren in paradigmatischen und syntagmatischen Aufgaben, die in Bezug auf die Grammatik definiert sind.', 'da': 'Nylige undersøgelser af distributionsmæssige semantiske modeller har sat en konkurrence mellem ordindlejringer opnået fra forudsigende neurale netværk og ordvektorer opnået fra abstraktive tællingsbaserede modeller. Dette dokument er et forsøg på at afsløre det underliggende bidrag fra yderligere uddannelsesdata og efterbehandlingstrin på hver type model i ordlighed og relateret inference opgaver. Det gør vi ved at designe en kunstig sprogramme, træne en forudsigende og tællebaseret model på data udtaget fra denne grammatik, og evaluere de resulterende ordvektorer i paradigmatiske og syntagmatiske opgaver defineret med hensyn til grammatiken.', 'nl': 'Recente studies van distributionele semantische modellen hebben een competitie opgezet tussen woordembeddingen verkregen uit voorspellende neurale netwerken en woordvectoren verkregen uit abstractieve telmodellen. Dit artikel is een poging om de onderliggende bijdrage van aanvullende trainingsgegevens en nabewerkingsstappen op elk type model in woordgelijkenis- en relatedness-inferentietaken te onthullen. Dit doen we door het ontwerpen van een kunstmatig taalframework, het trainen van een voorspellend en op telling gebaseerd model op gegevens uit deze grammatica, en het evalueren van de resulterende woordvectoren in paradigmatische en syntagmatische taken gedefinieerd met betrekking tot de grammatica.', 'id': 'Studi baru-baru ini tentang model semantis distribusi telah mengatur kompetisi antara pembangunan kata yang diperoleh dari jaringan saraf prediksif dan vektor kata yang diperoleh dari model abstraktif berdasarkan hitungan. Kertas ini adalah percobaan untuk mengungkapkan kontribusi dasar dari data pelatihan tambahan dan langkah-langkah post-proses pada setiap jenis model dalam tugas persamaan kata dan keterlibatan inferensi. Kita melakukannya dengan merencanakan rangkaian bahasa buatan, melatih model prediksif dan berdasarkan hitungan pada data yang diambil sampel dari grammar ini, dan mengevaluasi vektor kata yang berasal dari tugas paradigmatis dan sintagmatis yang didefinisikan berkaitan dengan grammar.', 'ko': '최근 분포식 의미 모델에 대한 연구는 신경 네트워크에서 얻은 단어의 삽입과 추상적인 계수 모델을 바탕으로 얻어진 단어의 양을 예측하는 데 경쟁을 벌였다.본고는 어휘의 유사성과 관련성 추리 임무에서 추가 훈련 데이터와 후처리 절차가 각 모델에 대한 잠재적인 기여를 제시하고자 한다.이를 위해 우리는 인공 언어 구조를 설계하여 이 문법에서 수집한 데이터 훈련 예측 모델과 계수를 바탕으로 하는 모델을 바탕으로 이 문법이 정의한 집합과 조합 임무에 따라 생성된 어향량을 평가한다.', 'sw': 'Tafiti za hivi karibuni za mifano ya usambazaji imetengeneza ushindani kati ya mabango ya maneno yaliyopatikana kutoka kwenye mitandao ya kutabiri ya neura na vectors za maneno yaliyopatikana kutoka kwa mifano yasiyo ya kuhesabu. Gazeti hili ni jaribio la kuonyesha mchango wa msingi wa taarifa za mafunzo na hatua za baada ya upasuaji katika kila aina ya mifano kwa maneno yanayofanana na kazi za maambukizi. Tunafanya hivyo kwa kutengeneza mfumo wa lugha bandia, tukifundisha utabiri na modeli inayohusiana na takwimu zilizosambazwa kutoka kwenye grammati hii, na kutathmini matokeo ya vectors za neno katika kazi za kibiashara na bandia zinazoelezwa kwa kuheshimu grammati.', 'fa': 'مطالعات اخیر از مدل\u200cهای semantic تقسیم\u200cکننده یک رقابت بین جمع\u200cآوری\u200cهای کلمه\u200cای که از شبکه\u200cهای عصبی پیش\u200cبینی و ویکتورهای کلمه\u200cای از مدل\u200cهای حساب\u200cکننده\u200cای دریافت شده\u200cاند ایجاد کرده\u200cاند. این کاغذ یک تلاش برای نشان دادن پایه\u200cای از داده\u200cهای تمرین اضافه\u200cای و قدم\u200cهای بعد از پردازش بر هر نوع مدل در کلمات شبیه\u200cانگیز و کار\u200cهای آلودگی ارتباطی است. ما این کار را با طراحی یک چهارچوب زبان مصنوعی انجام می دهیم، آموزش یک مدل پیش بینی و بر شماره بر روی نمونه\u200cهای داده\u200cای که از این گراماتر گرفته شده\u200cاند، و ارزیابی واژه\u200cهای نتیجه\u200cای از ویکتورهای کلمه\u200cهای پارادیگماتیکی و سنتاگراتیکی که در مورد گرام', 'tr': 'Ýakyndaky paýlaşma semantik modelleriň öňki öňki näyral şebekelerden we abstraktiv hasaplanyň tabanly modellerinden alan sözler arasynda ýaryşy guruldy. Bu kagyz sözlerin meňzeşlikli we ilat taýýarlama maglumatyň esasy nusgalarynda esasy hili nusgalarynda alyp barmak synanyşdyr. Biz muny öz gramatikadan örneklendirilen hatlaryň üstünde bir sanal dil framyny tasarlap, öngörümli we hasaplamada tabanly bir nusga düzenleyerek we netijäki söz vektörlerini gramatika barada tanyşdyrylýan paradigmatik we sintakmatik zadynda deňleýäris.', 'af': "Onlangse studie van verspreidingse semantiese modele het 'n mededing opstel tussen woord inbettings wat van voorskounde neuralnetwerke en woord vektore wat van abstraktiewe tel gebaseerde modele ontvang word. Hierdie papier is 'n probeer om die ondersteunde bydraag van addisionele onderwerp data en post-prosessering stappe op elke tipe model in woord gelykenis en verpligtigheid onderwerp opdragte te vertoon. Ons doen so deur 'n kunstenaar taal raamwerk te ontwerp, 'n voorskou en 'n tel-gebaseerde model op data uitgelaai van hierdie grammatiek en die resulteerde woord vektore in paradigmatiese en sintakmatiese taak gedefinieer met betrekking tot die grammatiek.", 'am': 'የቀድሞው የአካባቢ የsemantic ዓይነቶች ትምህርት ከቀድሞው የኔural network እና የቃላት vectors በተለየ ቁጥጥር የተመሳሳይ ምሳሌዎች በሚያገኙት ቃላት ውስጥ መከራን አቆመዋል፡፡ ይህ ገጽ በአጥላዊ ትምህርት ዳታዎችን እና የፖስተር ደረጃዎችን በማንኛውም ዓይነት ዓይነት በንግግር በተስማማማና ግንኙነት ስራዎችን ለማሳየት ለመፈለግ ነው፡፡ እንደዚህ እናደርጋለን፡፡', 'bn': 'সম্প্রতি বিতরণের সেমেন্টিক মডেলের গবেষণা বিতরণের মধ্যে একটি প্রতিযোগিতা সৃষ্টি করেছে যা ভবিষ্যত নিউরেল নেটওয়ার্ক এবং শব্দ ভেক্টর থেকে অ এই পত্রিকাটি একটি প্রচেষ্টা হচ্ছে যে প্রশিক্ষণের তথ্য এবং প্রক্রিয়ার প্রত্যেকটি ধরনের মডেলের প্রতি প্রশিক্ষণের মূল অবদান প্রকাশ করার প্রচেষ আমরা এটা করি একটি শৈল্পিক ভাষার ফ্রেক্কার গঠনের মাধ্যমে, একটি ভবিষ্যৎকার এবং এই গ্রামার থেকে তথ্য নির্ধারিত মডেলের প্রশিক্ষণ এবং এই গ্রামের সম্পর্কে নির্ধারিত ভাষায় শ', 'bs': 'Nedavno ispitivanje distribucijskih semantičkih modela uspostavili su konkurenciju između uključenih riječi iz predvidnih neuralnih mreža i vektori riječi koji su dobili od modela na apstraktivnom broju. Ovaj papir je pokušaj otkrivanja temeljnog doprinosa dodatnih podataka o obuci i koraka nakon obrade na svakom vrstu modela u zadatku sličnosti riječima i infekcije povezanosti. To radimo izrađivanjem umjetnog jezičkog okvira, obučavanjem predviđenog i brojnog model a na podacima uzorke iz ove gramatike, i procjenjivanjem rezultatnih vektora riječi u paradigmatskim i sintakmatskim zadacima definiranim u vezi gramatike.', 'sq': 'Studimet e fundit të modeleve semantike shpërndarëse kanë ngritur një konkurrencë midis përfshirjeve të fjalëve të përfshira nga rrjetet nervore parashikuese dhe vektorët e fjalëve të përfshira nga modelet abstraktive bazuar në numërim. This paper is an attempt to reveal the underlying contribution of additional training data and post-processing steps on each type of model in word similarity and relatedness inference tasks.  Ne e bëjmë këtë duke dizajnuar një kuadër gjuhësh artificiale, duke trajnuar një model parashikues dhe bazuar në numërim të të dhënave të marrë nga kjo gramatikë, dhe duke vlerësuar vektorët e fjalës që rezultojnë në detyrat paradigmatike dhe sintagmatike të përcaktuara lidhur me gramatikën.', 'hy': 'Սեմանտիկ մոդելների տարածման վերջին ուսումնասիրությունները ստեղծել են մրցակցություն բառերի ներդրումների միջև, որոնք ստացվում են նախատեսող նյարդային ցանցերից և բառերի վեկտորներից, որոնք ստացվում են վերացական հաշվարկի հիմնված մոդե Այս հոդվածը փորձում է բացահայտել ավելացյալ ուսումնասիրության տվյալների և վեր-վերամշակման քայլերի հիմնական ներդրումը բառերի նմանության և կապվածության եզրակացությունների յուրաքանչյուր տեսակի մոդելի վրա: Մենք դա անում ենք ստեղծելով արհեստական լեզվի շրջանակ, ուսումնասիրելով կանխատեսողական և հաշվով հիմնված մոդել այս գրաֆիկայից ստացված տվյալների վրա, և գնահատելով արտադրված բառերի վեկտորները գրաֆիկայի վերաբերյալ սահմանված պարադիգմատիկ և սինտագմատի', 'az': 'Dağıtılma semantik modellərin son öyrəndikləri tədbirli nöral a ğlardan alınan sözlərin və sözlərin vektörlərinin abstraktiv sayı tabanlı modellərdən alınan sözlərin arasında müqayisədə yaratdı. Bu kağıt, sözlərin bənzəriliyi və bağlantılıq təhsil işləri ilə hər modellərin başqa təhsil məlumatının və post-processing adımlarının əsas səbəbi göstərməyə çalışır. Biz bunu bir sanatlı dil framework ünü dizayn edirik, bu grammatik nümunələrindən çəkilmiş məlumatlar üzərində predictiv və saylı modeli təhsil edirik, və növbəti söz vektörlərinin paradigmatik və sintakmatik işləri grammatik barəsində tanımlanan paradigmatik və sintakmatik işlərdə təhsil edirik.', 'et': 'Hiljutised distributsioonilise semantilise mudeli uuringud on tekitanud konkurentsi ennustavatest närvivõrkudest saadud sõnade manustamise ja abstraktsetest loenduspõhistest mudelitest saadud sõnade vektorite vahel. Käesolevas töös püütakse välja selgitada täiendavate koolitusandmete ja järeltöötluse etappide panus iga mudeli tüüpi sõnade sarnasuse ja seose järelduste ülesannetes. Teeme seda tehiskeelse raamistiku kujundamisega, sellest grammatikast võetud andmetel prognoosiva ja loenduspõhise mudeli koolitamisega ning grammatikast lähtuvate paradigmaatiliste ja süntagmaatiliste ülesannete hindamisega.', 'ca': "Estudios recents de models semàntics de distribució han creat una competició entre les integracions de paraules obtingudes de xarxes neurals preditives i els vectors de paraules obtinguts de models abstracts basats en el nombre. Aquest paper és un intent de revelar la contribució subjacente de dades adicionals de formació i pas post-processament en cada tipus de model en tasques de inferència de paraules similars i relacionats. Ho fem dissenyant un marc de llenguatge artificial, treinant un model predictiu i basat en el nombre de dades mostrades d'aquesta gramàtica, i evaluant els vectors de paraules resultants en tasques paradigmàtiques i sintagmàtiques definides en relació a la gramàtica.", 'cs': 'Nedávné studie distribučních sémantických modelů vytvořily konkurenci mezi vkládáním slov získanými z prediktivních neuronových sítí a slovními vektory získanými z abstraktivních modelů založených na počtu. Tento článek se snaží odhalit základní přínos dalších tréninkových dat a postprocesních kroků na jednotlivých typech modelu v úlohách inference slovní podobnosti a souvislosti. Činíme tak navržením umělého jazykového frameworku, školením prediktivního a počítačového modelu na základě vzorků z této gramatiky a vyhodnocováním výsledných slovních vektorů v paradigmatických a syntagmatických úlohách definovaných s ohledem na gramatiku.', 'fi': 'Viimeaikaiset jakelusemanttisten mallien tutkimukset ovat luoneet kilpailun ennustavista neuroverkoista saatujen sanaupotusten ja abstraktiivisista laskentamalleista saatujen sanavektorien välille. Tässä artikkelissa pyritään paljastamaan kunkin mallin täydennystietojen ja jälkikäsittelyvaiheiden taustalla oleva vaikutus sanojen samankaltaisuus- ja suhdepäättelytehtävissä. Teemme sen suunnittelemalla keinotekoisen kielikehyksen, kouluttamalla ennakoivaa ja laskennallista mallia tästä kielioppiaineistosta otetuista tiedoista ja arvioimalla tuloksena olevia sanavektoreita kielioppiin liittyvissä paradigmaattisissa ja syntagmaattisissa tehtävissä.', 'jv': 'logic.org Perintah iki dadi saiki nggambar obah-obahan kelompok nggawe datayang tambah karo pakem-obahan sing perusahaan ning saben Tipe model karo perangkat kuwi tindakan alih lan kelompok nggawe operasi layar. Rasané awak dhéwé', 'he': 'מחקרים אחרונים של דוגמנים סמנטיים פיצועים הקימו תחרות בין התקפות מילים שנקבלו מרשתות עצביות צפויות וקטורים מילים שנקבלו מדוגמנים מבוססים בספירה אסטרקטיביים. הנייר הזה הוא ניסיון לחשוף את התרומה המרכזית של נתוני אימון נוספים ובצעדים לאחר העבודה על כל סוג של דוגמא בתפקידים של דוגמאות מילים וקשר. אנחנו עושים את זה על ידי עיצוב מסגרת שפה מלאכותית, אימון מודל צפוי ומבוסס בספירה על נתונים שנדגימו מהגרמטיקה הזו, ולעריך את הוקטורי המילים הנוצאים במשימות פרדיגמטיות וסינטגמטיות שמגדרות בנוגע לרמטיקה.', 'sk': 'Nedavne študije distribucijskih semantičnih modelov so vzpostavile konkurenco med vgradnjo besed iz napovednih nevronskih omrežij in besednimi vektorji iz abstraktivnih modelov, ki temeljijo na štetju. Ta prispevek je poskus razkritja osnovnega prispevka dodatnih podatkov o usposabljanju in korakov po obdelavi pri vsaki vrsti modela v nalogah podobnosti besed in sklepanja povezanosti. To naredimo z oblikovanjem umetnega jezikovnega okvira, usposabljanjem napovednega in številčnega modela na podlagi podatkov, vzorčenih iz te slovnice, ter ocenjevanjem nastalih besednih vektorjev v paradigmatičnih in sintagmatičnih opravilih, opredeljenih glede na slovnico.', 'ha': "Ana ƙidãya masu motsi na semantiki na farko, sun ƙidido wani competiti a tsakanin maganar filayen da aka samu daga zanen tarakin neural da shiryoyi masu basĩra daga misãlai na ƙidãya. This paper is an attempt to reveal the underlying contribution of additional training data and post-processing steps on each type of model in word similarity and relatedness inference tasks.  Kana aikata shi game da za'a ƙayyade wani firam na lugha wanda ba'a sani ba, ko kuma mu yi amfani da wani misali na ƙidãya a kan data masu sami'a daga wannan grammar, kuma Mu ƙaddara masu matsayi masu matsayi a cikin masu yin paradigati da kuma da suntagmati wanda aka ƙayyade game da grammar.", 'bo': 'Recent studies of distributional semantic models have set up a competition between word embeddings obtained from predictive neural networks and word vectors obtained from abstractive count-based models. ཤོག འུ་ཅག་གིས་རྩལ་ཆེ་བའི་སྐད་ཡིག་གཞུང་ཞིག་བཟོ་བ་ལས་སྔོན་འཚོལ་ཅན་དང་རྩིས་གཞི་རྩོལ་བའི་མིག་ཆས་གཞི་བཞག་ཡོད་པ་ལས་གཟུགས་རིས་བཅས་ཀྱི་ཆ་འཕྲིན་ཡི'}
{'en': 'Learning Word Representations with Regularization from Prior Knowledge', 'ar': 'تعلم تمثيلات الكلمات مع التنظيم من المعرفة السابقة', 'fr': 'Apprentissage des représentations de mots avec régularisation à partir de connaissances antérieures', 'es': 'Aprendizaje de representaciones de palabras con regularización a partir de conocimientos previos', 'pt': 'Aprendendo Representações de Palavras com Regularização de Conhecimento Prévio', 'zh': '学有正则化于先验者单词', 'hi': 'पूर्व ज्ञान से नियमितीकरण के साथ शब्द प्रतिनिधित्व सीखना', 'ja': '既存の知識から規則化された単語表現を学ぶ', 'ru': 'Представления учебных слов с упорядочением на основе предшествующих знаний', 'ga': 'Ag Foghlaim Léiriúcháin Focal le Rialáil ón Réamheolas', 'el': 'Μάθηση των Αντιπροσωπειών λέξεων με Ρυθμοποίηση από προηγούμενες γνώσεις', 'ka': 'წინ ვიცნობიდან რეგილარიზაციის სიტყვების გამოსწავლება', 'hu': 'Szóreprezentációk tanulása korábbi ismeretekből történő szabályozással', 'it': 'Imparare le rappresentazioni di parole con regolarizzazione da conoscenze precedenti', 'kk': 'Алдыңғы білім мәліметінен регулярлау үшін сөздерді таңдау', 'lt': 'Mokymasis žodžių atstovavimais reguliarizuojant iš ankstesnių žinių', 'mk': 'Научи претставувања на зборови со регуларизација од претходно знаење', 'ml': 'പ്രധാനപരിജ്ഞാനത്തില്\u200d നിന്നുള്ള വാക്കിന്റെ പ്രതിനിധികള്\u200d പഠിക്കുന്നു', 'ms': 'Learning Word Representations with Regularization from Prior Knowledge', 'mt': 'Tagħlim Rappreżentazzjonijiet tal-kliem b’Regolarizzazzjoni minn Għarfien minn Qabel', 'mn': 'Өмнөх мэдлэгийнхээ хэмжээний үг төлөөлөлт суралцах', 'no': 'Læring av ordreprezentasjonar med regulering frå førre kjenning', 'ro': 'Învățarea reprezentărilor Word cu regularizare din cunoștințe anterioare', 'pl': 'Nauka reprezentacji słowa z regularyzacją z wcześniejszej wiedzy', 'sr': 'Naučenje predstavljanja riječi sa regularizacijom iz priornog znanja', 'so': 'Barista hadal Representations with Regularization from Prior Knowledge', 'sv': 'Lär dig Word Representationer med regularisering från tidigare kunskap', 'si': 'ප්\u200dරධාන දන්නවයෙන් ප්\u200dරතිස්ථානය සමග වචන ප්\u200dරතිස්ථානය ඉගෙන ගන්න', 'ta': 'முன்னால் அறிவியிலிருந்து வார்த்தையின் பிரதிநிதியுடன் விதிமுறையாக்கம் கற்று', 'ur': 'پہلے علم سے روزنامہ کے ساتھ کلمات روزنامہ کی تعلیم کی جاتی ہے', 'uz': 'Learning Word Representations with Regularization from Prior Knowledge', 'vi': 'Học từ miễn trước khi phục hồi từ kiến thức', 'nl': 'Woordvertegenwoordigingen leren met regulering vanuit voorkennis', 'hr': 'Naučenje predstavljanja riječi s regularizacijom iz prije znanja', 'da': 'Læring af ordrepræsentationer med regulering fra tidligere viden', 'bg': 'Учене на думи с регуляризация от предишни знания', 'id': 'Belajar Perwakilan Kata dengan Regularisasi dari Pengetahuan Sebelumnya', 'de': 'Lernen von Wortdarstellungen mit Regularisierung aus Vorkenntnissen', 'ko': '선험지식에 기초한 규칙화 어휘 표징 학습', 'sw': 'Kujifunza maoni ya neno kwa Utawala kutoka Ujuzi Mkuu', 'tr': 'Öňki Bilim bilen düzenlemek bilen söz temsilleri öwrenmek', 'af': 'Leer woord voorstellings met Regulisering van Vorige kennis', 'fa': 'یاد گرفتن نمایش\u200cهای کلمه با تعیین قانونی از دانش قبلی', 'sq': 'Mëso përfaqësime fjalësh me rregullim nga njohuritë e mëparshme', 'hy': 'Learning Word Representations with Regularization from Prior Knowledge', 'bn': 'প্রাথমিক জ্ঞান থেকে নিয়মিতকরণের সাথে শব্দ প্রতিনিধি শিখা', 'az': '쿮vv톛lki Bilim t톛rzind톛n d칲zg칲n t톛rzd톛 S칬zl칲kl톛ri 칬yr톛nm톛k', 'am': 'ምርጫዎች', 'bs': 'Naučenje predstavljanja riječi sa regularizacijom iz prije znanja', 'ca': 'Aprendre representacions de paraules amb regularizació des del coneixement anterior', 'cs': 'Učení se slovních reprezentací s regularizací z předchozích znalostí', 'et': 'Õppida sõna esindusi regulariseerimisega varasematest teadmistest', 'fi': 'Sanaedustuksen oppiminen ja säännöstely aiemmasta tiedosta', 'jv': 'Ngubah Keterangkang Pak-Keterangkang karo Regularasyon nang Kelungan Prilikar', 'sk': 'Učenje besednih predstavitev z regularizacijo iz predhodnega znanja', 'he': 'Learning Word Representations with Regularization from Prior Knowledge', 'ha': 'KCharselect unicode block name', 'bo': 'སྔོན་མ་ཤེས་པའི་ལྟ་བུའི་ཡིག་གི་རྣམ་པ་དང་མཉམ་དུ་བསླབས་པའི་ཡིག་གཟུགས་སྟོན་དགོས་པ'}
{'en': 'Conventional word embeddings are trained with specific criteria (e.g., based on language modeling or co-occurrence) inside a single information source, disregarding the opportunity for further calibration using external knowledge. This paper presents a unified framework that leverages pre-learned or external priors, in the form of a regularizer, for enhancing conventional language model-based embedding learning. We consider two types of regularizers. The first type is derived from topic distribution by running LDA on unlabeled data. The second type is based on dictionaries that are created with human annotation efforts. To effectively learn with the regularizers, we propose a novel data structure, trajectory softmax, in this paper. The resulting embeddings are evaluated by word similarity and sentiment classification. Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality across multiple datasets, compared to a diverse collection of baseline methods.', 'ar': 'يتم تدريب عمليات تضمين الكلمات التقليدية وفقًا لمعايير محددة (على سبيل المثال ، استنادًا إلى نمذجة اللغة أو التواجد المشترك) داخل مصدر معلومات واحد ، مع تجاهل الفرصة لمزيد من المعايرة باستخدام المعرفة الخارجية. تقدم هذه الورقة إطارًا موحدًا يستفيد من مقدمات سابقة التعلم أو خارجية ، في شكل منظم ، لتعزيز تعلم التضمين المستند إلى نموذج اللغة التقليدية. نحن نعتبر نوعين من المنظمين. النوع الأول مشتق من توزيع الموضوع عن طريق تشغيل LDA على البيانات غير المسماة. النوع الثاني يعتمد على القواميس التي تم إنشاؤها بجهود التعليقات التوضيحية البشرية. للتعلم بشكل فعال مع المنظمين ، نقترح في هذه الورقة بنية بيانات جديدة ، مسار softmax. يتم تقييم حفلات الزفاف الناتجة عن طريق تشابه الكلمات وتصنيف المشاعر. تُظهر النتائج التجريبية أن إطار التعلم الخاص بنا مع التنظيم من المعرفة السابقة يحسن جودة التضمين عبر مجموعات بيانات متعددة ، مقارنة بمجموعة متنوعة من أساليب خط الأساس.', 'es': 'Las incrustaciones de palabras convencionales se entrenan con criterios específicos (por ejemplo, basados en el modelado del lenguaje o la coexistencia) dentro de una única fuente de información, sin tener en cuenta la oportunidad de una mayor calibración mediante el uso de conocimientos externos. Este documento presenta un marco unificado que aprovecha los antecedentes preaprendidos o externos, en forma de un regularizador, para mejorar el aprendizaje de incrustación basado en modelos de lenguaje convencional. Consideramos dos tipos de regularizadores. El primer tipo se deriva de la distribución de temas mediante la ejecución de LDA en datos sin etiqueta. El segundo tipo se basa en diccionarios que se crean con esfuerzos de anotación humanos. Para aprender eficazmente con los regularizadores, proponemos en este artículo una estructura de datos novedosa, trayectoria softmax. Las incrustaciones resultantes se evalúan mediante la similitud de palabras y la clasificación de sentimientos. Los resultados experimentales muestran que nuestro marco de aprendizaje con regularización de conocimientos previos mejora la calidad de la integración en múltiples conjuntos de datos, en comparación con una colección diversa de métodos de referencia.', 'fr': "Les intégrations de mots classiques sont formées avec des critères spécifiques (par exemple, basés sur la modélisation du langage ou la co-occurrence) au sein d'une source d'information unique, sans tenir compte de la possibilité d'un étalonnage supplémentaire à l'aide de connaissances externes. Cet article présente un cadre unifié qui tire parti des antécédents pré-appris ou externes, sous la forme d'un régularisateur, pour améliorer l'apprentissage par intégration basé sur un modèle de langage conventionnel. Nous considérons deux types de régularisateurs. Le premier type est dérivé de la distribution de sujets en exécutant LDA sur des données non étiquetées. Le second type est basé sur des dictionnaires créés avec des efforts d'annotation humaine. Pour apprendre efficacement avec les régularisateurs, nous proposons dans cet article une nouvelle structure de données, la trajectoire softmax. Les intégrations obtenues sont évaluées en fonction de la similitude des mots et de la classification des sentiments. Les résultats expérimentaux montrent que notre cadre d'apprentissage avec régularisation à partir de connaissances antérieures améliore la qualité de l'intégration dans de multiples ensembles de données, par rapport à un ensemble diversifié de méthodes de base.", 'pt': 'Embeddings de palavras convencionais são treinados com critérios específicos (por exemplo, com base em modelagem de linguagem ou co-ocorrência) dentro de uma única fonte de informação, desconsiderando a oportunidade de calibração adicional usando conhecimento externo. Este artigo apresenta uma estrutura unificada que utiliza prioris pré-aprendidos ou externos, na forma de um regularizador, para aprimorar o aprendizado de incorporação baseado em modelo de linguagem convencional. Consideramos dois tipos de regularizadores. O primeiro tipo é derivado da distribuição de tópicos executando LDA em dados não rotulados. O segundo tipo é baseado em dicionários que são criados com esforços humanos de anotação. Para aprender efetivamente com os regularizadores, propomos uma nova estrutura de dados, trajetória softmax, neste artigo. Os embeddings resultantes são avaliados por similaridade de palavras e classificação de sentimento. Os resultados experimentais mostram que nossa estrutura de aprendizado com regularização de conhecimento prévio melhora a qualidade da incorporação em vários conjuntos de dados, em comparação com uma coleção diversificada de métodos de linha de base.', 'ja': '従来の単語埋め込みは、外部知識を使用してさらなる較正を行う機会を無視して、単一の情報源内の特定の基準（例えば、言語モデリングまたは同時発生に基づく）で訓練される。 本稿では，従来の言語モデルに基づく埋め込み学習を強化するための規則化の形で，事前に学習されたまたは外部の前歴を活用する統一されたフレームワークを提示する． 2種類のレギュラー化を検討しています。 最初のタイプは、ラベル付けされていないデータ上でLDAを実行することによってトピック分布から導出されます。 2つ目のタイプは、人間の注釈の努力で作成された辞書に基づいています。 レギュレータで効果的に学習するために、本稿では新規のデータ構造である軌道ソフトマックスを提案する。 結果として生じる埋め込みは、単語の類似性と感情の分類によって評価されます。 実験結果は、既存の知識から規則化された学習フレームワークが、ベースライン法の多様なコレクションと比較して、複数のデータセットにわたる埋め込み品質を向上させることを示しています。', 'zh': '古词嵌信息源以特定准(,盖言语建模共现)练,忽于外校准也。 本立一框架,当框架以正则化器用预习外先验以强言语模样之旧。 吾思二正则化器。 一曰行未标之数 LDA 从题分生。 二曰人工注字典。 为学正则化器,立新数据结构于本文,即轨迹softmax。 以单词相似性情分质之。 实验结果表明与多样化之基线合,吾之学框架比前知之正则化,增数集之嵌质。', 'hi': 'पारंपरिक शब्द एम्बेडिंग को एक ही सूचना स्रोत के अंदर विशिष्ट मानदंडों (उदाहरण के लिए, भाषा मॉडलिंग या सह-घटना के आधार पर) के साथ प्रशिक्षित किया जाता है, बाहरी ज्ञान का उपयोग करके आगे के अंशांकन के अवसर की अनदेखी की जाती है। यह पेपर एक एकीकृत रूपरेखा प्रस्तुत करता है जो पारंपरिक भाषा मॉडल-आधारित एम्बेडिंग सीखने को बढ़ाने के लिए, एक नियमितकर्ता के रूप में पूर्व-सीखा या बाहरी प्राथमिकताओं का लाभ उठाता है। हम दो प्रकार के रेगुलराइज़र पर विचार करते हैं। पहला प्रकार बिना लेबल वाले डेटा पर LDA चलाकर विषय वितरण से व्युत्पन्न है. दूसरा प्रकार शब्दकोशों पर आधारित है जो मानव एनोटेशन प्रयासों के साथ बनाए जाते हैं। नियमितकरने वालों के साथ प्रभावी ढंग से जानने के लिए, हम इस पेपर में एक उपन्यास डेटा संरचना, प्रक्षेपवक्र सॉफ्टमैक्स का प्रस्ताव करते हैं। परिणामी एम्बेडिंग का मूल्यांकन शब्द समानता और भावना वर्गीकरण द्वारा किया जाता है। प्रयोगात्मक परिणामों से पता चलता है कि पूर्व ज्ञान से नियमितीकरण के साथ हमारा सीखने का ढांचा बेसलाइन विधियों के विविध संग्रह की तुलना में कई डेटासेट में एम्बेडिंग गुणवत्ता में सुधार करता है।', 'ga': 'Cuirtear oiliúint ar ghnáthchaibidlí focal le critéir shonracha (m.sh., bunaithe ar shamhaltú teanga nó comhtharlú) laistigh d’fhoinse amháin faisnéise, agus neamhaird á tabhairt ar an deis le haghaidh calabrú breise ag baint úsáide as eolas seachtrach. Cuireann an páipéar seo i láthair creat aontaithe a ghiaráil tosaíochtaí réamhfhoghlaim nó seachtracha, i bhfoirm rialtatóir, chun feabhas a chur ar ghnáthfhoghlaim teanga bunaithe ar leabú teanga. Breithnímid dhá chineál rialtaitheoirí. Díorthaítear an chéad chineál ó dháileadh topaicí trí LDA a rith ar shonraí neamhlipéadaithe. Tá an dara cineál bunaithe ar fhoclóirí a chruthaítear le hiarrachtaí anótála daonna. Chun foghlaim go héifeachtach leis na rialtaitheoirí, molaimid struchtúr sonraí nua, trajectory softmax, sa pháipéar seo. Déantar na leabú mar thoradh air a mheas trí chosúlacht focal agus aicmiú meon. Léiríonn torthaí turgnamhacha go bhfeabhsaítear ár gcreat foghlama le rialtacht ó réamheolas ar cháilíocht leabú thar il-thacair sonraí, i gcomparáid le bailiúchán éagsúil de mhodhanna bonnlíne.', 'ru': 'Традиционные вставки слов обучаются с помощью конкретных критериев (например, на основе языкового моделирования или совместного возникновения) внутри одного источника информации, игнорируя возможность дальнейшей калибровки с использованием внешних знаний. В этой статье представлена унифицированная структура, которая использует заранее изученные или внешние притязания в форме регуляризатора для улучшения обучения внедрению на основе моделей обычного языка. Мы рассматриваем два типа регуляризаторов. Первый тип получается из распределения топиков путем запуска LDA на немеченных данных. Второй тип основан на словарях, которые создаются с помощью человеческих аннотаций. Чтобы эффективно учиться с регуляризаторами, мы предлагаем новую структуру данных, траекторию softmax, в этой работе. Полученные вложения оцениваются по сходству слов и классификации настроений. Экспериментальные результаты показывают, что наша система обучения с регуляризацией на основе предшествующих знаний улучшает качество встраивания множества наборов данных по сравнению с разнообразным набором базовых методов.', 'hu': 'A hagyományos szóbeágyazásokat konkrét kritériumokkal (például nyelvi modellezés vagy együttes előfordulás alapján) képezik egyetlen információforráson belül, figyelmen kívül hagyva a további kalibrálás lehetőségét külső ismeretek felhasználásával. Ez a tanulmány egy olyan egységes keretrendszert mutat be, amely a hagyományos nyelvmodelleken alapuló beágyazási tanulás javításához használja az előre megtanult vagy külső priuszokat, szabályozó formájában. Kétféle szabályozót veszünk figyelembe. Az első típus a témalelosztásból származik, úgy, hogy LDA futtatása címke nélküli adatokon történik. A második típus olyan szótárakra épül, amelyeket emberi jegyzetelési erőfeszítésekkel hoztak létre. A szabályozókkal való hatékony tanulás érdekében ebben a tanulmányban egy új adatszerkezetet, pálya softmax-ot javasolunk. A kapott beágyazásokat szóhasonlóság és hangulatosztályozás alapján értékeljük. Kísérleti eredmények azt mutatják, hogy a korábbi ismeretekből származó szabályozással rendelkező tanulási keretrendszerünk javítja a beágyazás minőségét több adatkészletben, összehasonlítva az alapvető módszerek sokféle gyűjteményével.', 'el': 'Οι συμβατικές ενσωματώσεις λέξεων εκπαιδεύονται με συγκεκριμένα κριτήρια (π.χ. βασισμένα στη γλωσσική μοντελοποίηση ή συνύπαρξη) μέσα σε μια ενιαία πηγή πληροφοριών, αγνοώντας την ευκαιρία για περαιτέρω βαθμονόμηση χρησιμοποιώντας εξωτερικές γνώσεις. Η παρούσα εργασία παρουσιάζει ένα ενοποιημένο πλαίσιο που αξιοποιεί προ-μαθημένα ή εξωτερικά προηγούμενα, με τη μορφή ενός κανονικοποιητή, για την ενίσχυση της συμβατικής εκμάθησης βασισμένης στο μοντέλο γλώσσας. Εξετάζουμε δύο τύπους τακτικών. Ο πρώτος τύπος προέρχεται από τη διανομή θεμάτων με την εκτέλεση σε δεδομένα χωρίς ετικέτα. Ο δεύτερος τύπος βασίζεται σε λεξικά που δημιουργούνται με ανθρώπινες προσπάθειες σχολιασμού. Για να μάθουμε αποτελεσματικά με τους ρυθμιστές, προτείνουμε μια νέα δομή δεδομένων, τροχιά στην παρούσα εργασία. Οι προκύπτουσες ενσωματώσεις αξιολογούνται με βάση την ομοιότητα λέξεων και την ταξινόμηση συναισθημάτων. Τα πειραματικά αποτελέσματα δείχνουν ότι το μαθησιακό μας πλαίσιο με ρύθμιση από προηγούμενες γνώσεις βελτιώνει την ποιότητα ενσωμάτωσης σε πολλαπλά σύνολα δεδομένων, σε σύγκριση με μια ποικιλία μεθόδων βάσης.', 'ka': 'განსაკუთრებული სიტყვები კრიტირებით (მაგალითად, ენის მოდელირება ან ერთადერთი მოხდება) ერთადერთი ინფორმაციის გამოსახულებაში შემდეგ კალიბრაციის შესაძლებლობა გარეშე გამოიყენება. ეს დაახლოები ახლა ერთადერთი ფრამეტრი, რომელიც წინასწავლის ან გარეშე წინასწავლის ფორმაში, რეგილარიზერის ფორმაში, რომელიც კონტრაციონალური ენის მოდელური მოდელური გარეშე სწ ჩვენ ვფიქრობთ ორი ტიპი რეგილარიზაციელი. პირველი ტიპი ტემების გაყოფილებიდან დაიწყება LDA- ს გადაწყებით, რომელიც არაწერილი მონაცემებზე. მეორე ტიპი ადამიანის წარმოდგენებით შექმნილი სიტყვების დაბაზია. ეფექტიურად დავისწავლოთ რეგილარიზერებთან, ჩვენ პრომენტის მონაცემების სტრუქტურაციას, ტრაექტური softmax, ამ დონეში. შემდეგ შემდეგ სიტყვების სხვადასხვა და სენტიმენტის კლასიფიკაციაზე გაუმუშავება. ექსპერიმენტიური შედეგები ჩვენი სწავლების ფრამეტრის რეგილარიზაციაზე წინასწორედ ცნობილიდან უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ', 'it': "Le incorporazioni convenzionali di parole vengono addestrate con criteri specifici (ad esempio, basati sulla modellazione linguistica o sulla co-occorrenza) all'interno di una singola fonte di informazioni, trascurando l'opportunità di ulteriore calibrazione utilizzando conoscenze esterne. Questo articolo presenta un framework unificato che sfrutta precedenti pre-appresi o esterni, sotto forma di regolarizzazione, per migliorare l'apprendimento basato su modelli linguistici convenzionali. Consideriamo due tipi di regolarizzatori. Il primo tipo deriva dalla distribuzione degli argomenti eseguendo LDA su dati non etichettati. Il secondo tipo si basa su dizionari creati con sforzi umani di annotazione. Per imparare efficacemente con i regolarizzatori, proponiamo una nuova struttura dati, traiectory softmax, in questo articolo. Le incorporazioni risultanti sono valutate per somiglianza di parole e classificazione sentiment. I risultati sperimentali mostrano che il nostro framework di apprendimento con regolarizzazione da conoscenze precedenti migliora la qualità di incorporamento in più set di dati, rispetto a una raccolta diversificata di metodi di base.", 'kk': 'Кәдімгі сөздерді ендіру бір мәлімет көзінде бір түрлі мәлімет көзінде (мысалы, тілдерді моделдеу немесе бір түрлі көзінде негізделген) арнаулы критериялармен ұқытылады, сыртқы білім Бұл қағаз алдын- үйренген немесе сыртқы алдын- ала үйренген бірлікті фреймді, әдетті тіл үлгіні негізінде ендірген оқыту үшін үлгілікті көтеру үшін қолданылады. Біз екі түрлі қадамдастырушылар деп ойлаймыз. Бірінші түрі нақышты үлестіруден LDA- ды келтірілмеген деректерге жегіп шығарылады. Екінші түрі адамдардың жазбалармен құрылған сөздіктеріне негізделген. Үлгілі түрлермен үйрену үшін, бұл қағаздың романдық деректер құрылымын, траекториялық бағдарламалық максимумын таңдаймыз. Сондағы ендірулерді сөздердің ұқсас пен сезімдердің классификациясы бойынша бағалады. Эксперименталдық нәтижелері білім алдындағы мәліметтерден өзгертілген оқыту бағдарламасы бірнеше деректер бағдарламасының салыстыру сапасына салыстырады.', 'lt': 'Įprasti žodžių įterpimai rengiami taikant konkrečius kriterijus (pvz., remiantis kalbų modeliavimu arba bendra pasikartojimu) vieno informacijos šaltinio viduje, neatsižvelgiant į galimybę toliau kalibruoti naudojant išorines žinias. Šiame dokumente pateikiama bendra sistema, kuria reguliarizuojamas iš anksto išmokytas ar išorinis ankstesnis mokymasis, siekiant pagerinti tradiciniu kalbų modeliu pagrįstą įterpiamąjį mokymąsi. Mes svarstome dviejų rūšių reguliatorius. Pirmasis tipas gaunamas iš teminio paskirstymo naudojant LDA be žymės duomenis. The second type is based on dictionaries that are created with human annotation efforts.  Siekiant veiksmingai mokytis su reguliarizatoriais, šiame dokumente siūlome naują duomenų struktūrą, trajektorijos softmax. Atitinkamos įterptos vertinamos pagal žodžių panašumą ir jausmų klasifikaciją. Eksperimentiniai rezultatai rodo, kad mūsų mokymosi sistema, reguliuojama iš ankstesnių žinių, gerina kokybę įvairiuose duomenų rinkiniuose, palyginti su įvairiais baziniais metodais.', 'mk': 'Конвенционалните зборови се обучуваат со специфични критериуми (на пример, базирани на јазичното моделирање или соопштено појавување) во еден извор на информации, отфрлајќи ја можноста за понатамошна калибрација користејќи надворешно знаење. Овој документ претставува унифицирана рамка која влијае на преднаучените или надворешните предходни случаи, во форма на регуларизација, за подобрување на учењето базирано на конвенционалниот јазик модел. Размислуваме за два вида регуларизачи. The first type is derived from topic distribution by running LDA on unlabeled data.  Вториот тип се базира на речници кои се создадени со напори за човечка анотација. За ефикасно да научиме со регулаторизаторите, предложуваме нова структура на податоци, траекторија софтмакс, во овој весник. Резултатите на вградувањата се проценуваат со сличност на зборовите и класификација на чувствата. Експерименталните резултати покажуваат дека нашата рамка за учење со регуларизација од претходното знаење го подобрува вклопувањето на квалитетот во повеќе податоци, во споредба со различна колекција на основни методи.', 'ms': 'Pencampuran perkataan konvensional dilatih dengan kriteria khusus (cth., berdasarkan pemodelan bahasa atau kejadian sama) di dalam sumber maklumat tunggal, mengabaikan peluang untuk kalibrasi lanjut menggunakan pengetahuan luaran. Kertas ini memperkenalkan kerangka bersatu yang menggunakan latar belajar awal atau luaran, dalam bentuk pengaturan, untuk meningkatkan pembelajaran berbasis model bahasa konvensional. Kami mempertimbangkan dua jenis pengaturan. Jenis pertama dihimpunkan dari distribusi topik dengan menjalankan LDA pada data tidak ditabel. Jenis kedua berdasarkan kamus yang dicipta dengan usaha anotasi manusia. To effectively learn with the regularizers, we propose a novel data structure, trajectory softmax, in this paper.  Pencampuran yang menghasilkan diteliti dengan persamaan perkataan dan klasifikasi perasaan. Hasil percubaan menunjukkan bahawa kerangka pembelajaran kami dengan pengaturan dari pengetahuan terdahulu meningkatkan kualiti penyampaian dalam set data berbilang, dibandingkan dengan koleksi berbeza kaedah dasar.', 'ml': 'സാധാരണ വാക്കുകള്\u200d പ്രത്യേക പരിശീലിക്കപ്പെടുന്നു This paper presents a unified framework that leverages pre-learned or external priors, in the form of a regularizer, for enhancing conventional language model-based embedding learning.  നമ്മള്\u200d രണ്ടു തരം നിയന്ത്രണക്കാരെ വിചാരിക്കുന്നു. ലേബല്\u200d ചെയ്യാത്ത വിവരങ്ങളില്\u200d LDA പ്രവര്\u200dത്തിപ്പിക്കുന്നതില്\u200d നിന്ന് ആദ്യ തരം ലഭ്യമാക്കുന്നു. രണ്ടാമത്തെ തരം മനുഷ്യരുടെ പ്രശ്നം കൊണ്ട് സൃഷ്ടിക്കപ്പെട്ട നിഘണ്ടികൾ അടിസ്ഥാനമാണ്. നിയന്ത്രണക്കാരുടെ കൂടെ പഠിക്കാന്\u200d ഞങ്ങള്\u200d ഒരു നോവല്\u200d ഡേറ്റാ ഘടനയില്\u200d, ട്രാക്ടോക്ടറിന്റെ സോഫ്റ്റ്മാക്സ് ഈ പത് അതിന്റെ ഫലങ്ങള്\u200d വാക്കിന്റെ തുല്യമാക്കുന്നതിന്റെയും വാക്കിന്റെയും തീരുമാനത്തിന്റെയും ക്ലാസ്ഫി പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ പഠിക്കുന്ന ഫ്രെയിമ്പില്\u200d നിന്നും മുമ്പുള്ള വിജ്ഞാനത്തിന്റെ നിയന്ത്രണ', 'mt': 'L-inkorporazzjonijiet konvenzjonali tal-kliem huma mħarrġa b’kriterji speċifiċi (pereżempju, ibbażati fuq mudell tal-lingwa jew kookkorrenza) ġewwa sors wieħed ta’ informazzjoni, filwaqt li tiġi injorata l-opportunità g ħal aktar kalibrazzjoni bl-użu ta’ għarfien estern. Dan id-dokument jippreżenta qafas unifikat li jagħti spinta lill-prijoritajiet ta’ qabel it-tagħlim jew dawk esterni, fil-form a ta’ regolarizzatur, għat-titjib tat-tagħlim inkorporat ibbażat fuq mudell ta’ lingwa konvenzjonali. Aħna nqisu żewġ tipi ta’ regolaturi. L-ewwel tip huwa derivat mid-distribuzzjoni suġġetta billi jitħaddem l-LDA fuq dejta mingħajr tikketta. It-tieni tip huwa bbażat fuq dikjaraturi li jinħolqu bl-isforzi ta’ annotazzjoni umana. Biex nitgħallmu b’mod effettiv mar-regolarizzaturi, qed nipproponu struttura ġdida ta’ dejta, trajettorja softmax, f’dan id-dokument. L-inkorporazzjonijiet li jirriżultaw huma evalwati skont is-similarità tal-kelma u l-klassifikazzjoni tas-sentimenti. Riżultati esperimentali juru li l-qafas tagħna ta’ tagħlim bir-regolarizzazzjoni minn għarfien minn qabel itejjeb l-inkorporazzjoni tal-kwalità f’settijiet ta’ dejta multipli, meta mqabbel ma’ ġbir diversifikat ta’ metodi ta’ bażi.', 'mn': 'Нэг мэдээллийн эх үүсвэр дотор тодорхой хэл загвар (жишээ нь хэл загвар болон хамтран үйлдвэрлэх) тодорхой шаардлагатай үг бий болгож, гадаад мэдээллийг ашиглаж дахиад калибр хийх боломжтой боломжтой боломжтой Энэ цаас урьд суралцах эсвэл гадаад суралцагчийн хэлбэрийн загварын сургалтыг улам сайжруулахын тулд нэгтгэлтэй хэлбэрийг харуулдаг. Бид хоёр төрлийн жинхэнэ хэлбэрийг боддог. Эхний төрлийн нь сэдвийн хуваарилалт гаргасан мэдээллээр LDA-г ашиглаж ирсэн юм. Хоёр дахь төрлийн нь хүн төрөлхтний сэтгэл хөдлөл дээр бий болгосон үгсэлтүүд дээр суурилсан. Эцэст нь энгийн хүмүүстэй суралцахын тулд бид энэ цаасан дээр шинэ өгөгдлийн бүтэц, салбарын салбарын максимум гэдгийг санал дэвшүүлнэ. Үүний үр дүнг нь үг төстэй болон сэтгэл хөдлөлийн хуваалцаанд үнэлдэг. Эмчилгээний үр дүнд бидний суралцах үйл ажиллагааны үйл ажиллагааг өмнөх мэдлэгийнхээ хувьд олон өгөгдлийн сангийн хэлбэрээс харьцуулахын тулд бидний суралцах үйл ажиллагааны үйл ажиллагаа', 'no': 'Innbygging av vanleg ord er utlært med spesifikke kriterier (f.eks. basert på språk modellering eller samtidig oppgåve) i ein enkelt informasjonskjelde, utan hending av muligheten for meir kalibrering ved å bruka eksterne kunnskap. Denne papiret viser eit einaste rammeverk som leverer førelærte eller eksterne førehandsvisingar, i form av eit regulært, for å forbetra konvensjonell språk-modell basert innbygging. Vi ser på to typar regulærar. Den første typen er henta frå temafordelinga ved å køyra LDA på ukjende data. Den andre typen er basert på ordbokar som er oppretta med menneske merknader. For å lære effektivt med regulære, foreslår vi eit nytt datastruktur, trajectory softmax i denne papiret. Dette resultatet innbygginga er evaluert etter ordsimilaritet og sentimentklassifikasjon. Eksperimentale resultat viser at læringsrammeverket vår med reguleringa frå førre kunnskap forbetrar innbyggingskvalitet over fleire datasett, sammenlignet med ein ulike samling av baselinjesmetodar.', 'pl': 'Konwencjonalne osadzenia słów są szkolone według określonych kryteriów (np. w oparciu o modelowanie językowe lub współwystępowanie) wewnątrz jednego źródła informacji, pomijając możliwość dalszej kalibracji z wykorzystaniem wiedzy zewnętrznej. Niniejszy artykuł przedstawia ujednolicone ramy, które wykorzystują wcześniej nauczone lub zewnętrzne priorytety, w postaci regularyzatora, do poprawy konwencjonalnego modelu językowego nauczania się osadzania. Rozważamy dwa rodzaje regulatorów. Pierwszy typ pochodzi z dystrybucji tematów poprzez uruchomienie LDA na danych nieoznakowanych. Drugi typ opiera się na słownikach tworzonych przy użyciu człowieka adnotacji. Aby skutecznie uczyć się z regulatorami, proponujemy w niniejszym artykule nową strukturę danych, trajektorię softmax. Wynikające z nich osadzenia oceniane są według klasyfikacji podobieństwa słów i sentymentów. Wyniki eksperymentalne pokazują, że nasze ramy uczenia się z regularyzacją z wcześniejszej wiedzy poprawiają jakość osadzenia w wielu zbiorach danych, w porównaniu do zróżnicowanego zbioru metod bazowych.', 'so': 'Hadalka ku soo socota waxaa lagu baraa kaarar gaar ah (tusaale ahaan tusaale ahaan muuqashada luuqada ama iskaasha ah) marka laga eego fursadda kalibsashada aqoonta dibadda lagu isticmaalo. Qoraalkan waxaa soo saara qoraal isku darsami ah oo horay u sii kordhiya barashada qoraalka afka caadiga ah oo ku qoran horay ama dibadda. Waxaynu ka fiirsanaynaa laba nooc oo xeerarka ah. Nooca ugu horreeya waxaa laga soo saaraa qaybinta madaxa lagu soo dirayo LDA oo ku qoran macluumaad aan la labeyn. Nooca labaad waxaa ku saleysan luqadaha lagu abuuray dhibaatooyinka dadka. Si aad u faa’iido ah u barto xeerarka, waxan warqadan uga soo jeedaynaa dhismo macluumaadka saxda ah, saqafka wadiiqooyinka dhaqdhaqaaqa. Xiriirka sababta ah waxaa lagu qiimeeyaa si siman u eg iyo kalsooni. Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality across multiple datasets, compared to a diverse collection of baseline methods.', 'ro': 'Încorporările convenționale de cuvinte sunt instruite cu criterii specifice (de exemplu, pe baza modelării limbajului sau a co-apariției) într-o singură sursă de informații, ignorând posibilitatea de calibrare ulterioară utilizând cunoștințe externe. Această lucrare prezintă un cadru unificat care valorifică antecedentele pre-învățate sau externe, sub forma unui regularizator, pentru îmbunătățirea învățării bazate pe modele lingvistice convenționale. Considerăm două tipuri de regularizatori. Primul tip este derivat din distribuția subiectului prin rularea LDA pe date fără etichete. Al doilea tip se bazează pe dicționare care sunt create cu eforturi umane de adnotare. Pentru a învăța eficient cu regularizatorii, propunem o nouă structură de date, traiectoria softmax, în această lucrare. Încorporările rezultate sunt evaluate prin similitudinea cuvintelor și clasificarea sentimentului. Rezultatele experimentale arată că cadrul nostru de învățare cu regularizare din cunoștințe anterioare îmbunătățește calitatea încorporării în mai multe seturi de date, comparativ cu o colecție diversă de metode de bază.', 'sr': 'Konvencionalni integraciji reči obučeni su sa specifičnim kriterijama (na primjer na temelju modela jezika ili saradnje) unutar jednog izvora informacija, bez obzira na mogućnost daljnje kalibracije koristeći spoljno znanje. Ovaj papir predstavlja jedinstven okvir koji utiče na pre-naučene ili vanjske prethodne, u obliku regularizatora, za unapređenje konvencionalnog jezičkog model a osnovanog učenja. Smatramo dva vrsta regularizatora. Prvi tip je proizveden iz distribucije teme pokrenući LDA na neizbiljnim podacima. Drugi tip je baziran na rečnicima koje su stvorene naporima ljudskih annotacija. Da bi se efikasno naučili sa regularizatorima, predlažemo novu strukturu podataka, trajektoriju softmax, u ovom papiru. Rezultativne integracije procjenjuju sliènost rijeèi i klasifikacija sentimenta. Eksperimentalni rezultati pokazuju da naš okvir učenja sa regularizacijom iz prethodnog znanja poboljšava integraciju kvalitete na višestrukim podacima u usporedbi sa različitim kolekcijom početnih metoda.', 'si': 'සාමාන්\u200dය වචන සම්බන්ධ වචන සිද්ධ විශේෂ අවශ්\u200dය (උදාහරණය, භාෂාව මොඩේලන් හෝ සම්බන්ධ වෙනුවෙන්) එක්ක තොරතුරු මූල්\u200dයයක මේ පත්තුව පෙන්වන්නේ සාමාන්\u200dය භාෂාව ප්\u200dරධානය සඳහා ප්\u200dරධානයක් හෝ ප්\u200dරධානයක් ප්\u200dරධානය කරනවා. අපි හිතන්නේ සාමාන්\u200dය වැඩකරු දෙකක් වගේ. පළවෙනි වර්ගයක් තේරුම් විතරයෙන් ලිපින්න බැරි දත්තේ LDA දාලා යනවා. දෙවෙනි වර්ගයක් මිනිස්සු ප්\u200dරශ්නයක් සඳහා නිර්මාණය කරලා තියෙන වචන වචන වලට අධාරිත වෙනව සාමාන්\u200dය විදියට ඉගෙන ගන්න, අපි නියම දත්ත සංවිධානයක් ප්\u200dරයෝජනය කරනවා, මේ පත්තියේ ප්\u200dරයෝජනයක්. ප්\u200dරතිචාරය සම්බන්ධතාවක් වචනය සහ විශේෂතාවක් වලින් විශේෂය කරනවා. පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වනවා අපේ ඉගෙන ගන්න ප්\u200dරතිචාරය ප්\u200dරතිචාරයක් ප්\u200dරතිචාරයෙන් ප්\u200dරතිචාරයෙන්', 'ta': 'வழக்கமான வார்த்தை உள்ளிடுதல் குறிப்பிட்ட குறிப்பிட்ட நிறுவனங்களுடன் (உதாரணமாக மொழி மாதிரி வடிவமைப்பு அல்லது ஒரு சேர்ந்த நிகழ்வு) ஒரே தகவல் மூலமு இந்த தாள் ஒரு unified சட்டத்தை குறிப்பிடுகிறது அது முன்னர் கற்றப்பட்டது அல்லது வெளிப்புற முன்னுரிமைகளை வெளியேற்றுகிறது, ஒரு வழக்கமான மொழி மாதி இரண்டு வகையான கட்டுப்பாட்டாளர்களை நாம் கருதுகிறோம். முதல் வகை குறிப்பிடப்படாத தகவலில் LDA இயக்கி தலைப்பு பங்கீட்டிலிருந்து வந்துள்ளது. இரண்டாவது வகை மனித அறிவிப்பு முயற்சிகளுடன் உருவாக்கப்பட்ட அகராதிகளை அடிப்படையாகும். விதிமுறையாளர்களுடன் கற்றுக் கொள்வதற்கு, நாம் இந்த தாளில் ஒரு புதிய தகவல் அமைப்பு, பாதையில் மென்பெரிதாக்கம் பரிந் @ info: whatsthis பரிசோதனை முடிவுகள் காண்பிக்கப்படுகிறது முன்னால் கல்வி சட்டத்திலிருந்து விதிமுறையாக்கத்திலிருந்து கற்றுக்கொள்ளும் அறிவு ம', 'sv': 'Konventionella ordinbäddningar utbildas med specifika kriterier (t.ex. baserat på språkmodellering eller samtidig förekomst) inuti en enda informationskälla, bortsett från möjligheten till ytterligare kalibrering med hjälp av extern kunskap. Denna uppsats presenterar ett enhetligt ramverk som utnyttjar förkunna eller externa prioriteringar, i form av en regularizer, för att förbättra konventionellt språkmodellbaserat inbäddande lärande. Vi betraktar två typer av regularisers. Den första typen härleds från ämnesdistribution genom att köra LDA på omärkta data. Den andra typen är baserad på ordböcker som skapas med mänskliga anteckningar ansträngningar. För att effektivt lära sig med regularisers föreslår vi en ny datastruktur, traiectory softmax, i denna uppsats. De resulterande inbäddningarna utvärderas genom ordlikhet och sentimentklassificering. Experimentella resultat visar att vårt lärramverk med regularisering från tidigare kunskap förbättrar inbäddningskvaliteten över flera datauppsättningar, jämfört med en mängd olika baslinjemetoder.', 'ur': 'ایک اطلاعات سورج کے درمیان (جیسے زبان موڈلینگ یا اتفاق) کے مطابق مخصوص مقداروں کے ساتھ استعمال کئے جاتے ہیں، اور باہر علم کے مطابق اضافہ کلیبرینگ کے فرصت کے ذریعے بغیر منع کئے جاتے ہیں. یہ کاغذ ایک متحدہ فریمیٹ ہے جو پہلے سکھایا جاتا ہے یا خارج سے پہلے، ایک قانون ترکیب کرنے والے کی شکل میں، ایک متحدہ زبان کی مدل پر بنیاد رکھنے کی تعلیم کے لئے استعمال کرتا ہے. ہم نے دو قسم کے معاملہ کرنے والوں کو سمجھ لیا ہے۔ پہلی ٹیپ ٹیپ ڈیٹ پریزینڈر سے لکھا گیا ہے جو LDA کو بغیر پڑھی ہوئی ڈیٹ پر چلتی ہے. دوسری طرح انسان کی اظہار کی کوشش کے ساتھ بنائے ہوئے لکھائی پر بنیاد ہے. ہم نے اس کاغذ میں ایک نئی ڈیٹا ساختار، تراژیکٹری نرم ماکس کی پیشنهاد کرتا ہے۔ نتیجۂ ایمبڈینگ لفظ کے مطابق اور احساسات کلاسیفوں کے ذریعہ ارزش کیا جاتا ہے. Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality in multiple datasets, compared to a diverse collection of baseline methods.', 'uz': "Davom etilgan so'zlar tashqi maʼlumot manbasiga (m. g. tilning modeli yoki bir nechta hodisa asosida) foydalanadi. Bu qogʻoz bir birlashtirilgan freymni koʻrsatiladi. Bu qogʻoz boshqaruvchidan oldin o'rganish yoki tashqi oldin oldin o'rganish yoki tashqi oldin oldin ishlatiladi. Biz ikki tur boshqaruvchilarga o'ylaymiz. @ info: whatsthis Ikkinchi tur inson taʼminlovchi harakat bilan yaratilgan lugʻatlar asosida. Boshqaruvchilar bilan o'rganish uchun, biz bu qogʻozdagi novel maʼlumot tizimi, sakkizning soʻrov dasturi. @ info: whatsthis Tajriba natijalari shunday ko'rsatadi, biz o'rganish frameiyatlarimiz bir necha maʼlumotlar tarkibidagi sonlarning qiymatini ko'paytirish imkoniyatini oshirish mumkin, bir necha maʼlumotlar sonlariga ko'paytirish imkoniyatini ko'rsatadi.", 'vi': 'Những từ ngữ thông thường được đào tạo với những tiêu chuẩn đặc biệt (v.d., dựa trên cách phát minh ngôn ngữ hay nhập nhau) bên trong một nguồn thông tin đơn lẻ, không để ý cơ hội điều chỉnh thêm dựa trên kiến thức bên ngoài. Tờ giấy này đưa ra một cơ sở thống nhất dùng để thúc đẩy sự hiểu biết trước hay ra ngoài, bằng cách làm chính thức, để phát triển khả năng học thêm ngôn ngữ truyền thống. Chúng tôi xem xét hai loại đều đặn. Loại thứ nhất bắt nguồn từ việc phân phối chủ đề bằng cách chạy LDAP với dữ liệu không tải. Kiểu thứ hai dựa trên các từ điển được tạo ra với các nỗ lực ghi chú con người. Để có hiệu quả học với các nhà hoá học, chúng tôi đề xuất một cấu trúc mới về dữ liệu, đường chuyền bóng đèn, trong tờ giấy này. Kết quả của sự ghép nối được đánh giá bằng cách phân loại từ giống nhau và cảm xúc. Kết quả thí nghiệm cho thấy cơ sở học dựa trên việc theo quy tắc dựa trên kiến thức trước cải thiện việc trộn chất lượng trên nhiều bộ dữ liệu hơn so với một loạt các phương pháp cơ bản khác nhau.', 'bg': 'Конвенционалните вграждания на думи се обучават със специфични критерии (например въз основа на езиково моделиране или съвместно появяване) в рамките на един информационен източник, пренебрегвайки възможността за по-нататъшно калибриране с помощта на външни знания. Тази статия представя единна рамка, която използва предварително научени или външни приоритети под формата на регуляризатор, за подобряване на конвенционалното езиково обучение, базирано на вграждане, базирано на модели. Ние разглеждаме два вида регуляризатори. Първият тип се извлича от тематично разпределение чрез стартиране на LDA върху немаркирани данни. Вторият тип се основава на речници, които са създадени с човешки усилия за анотация. За да се научим ефективно с регуляризаторите, ние предлагаме нова структура на данните, траектория софтмакс, в тази статия. Получените вграждания се оценяват по сходство на думите и класификация на сантименталността. Експерименталните резултати показват, че нашата учебна рамка с регламентиране от предишни знания подобрява качеството на вграждането в множество набори от данни в сравнение с разнообразната колекция от базови методи.', 'hr': 'Uvježbanje konvencionalnih riječi obučeno je s specifičnim kriterijama (na primjer na temelju modeliranja jezika ili saradnje) unutar jednog izvora informacija, bez obzira na mogućnost daljnje kalibracije koristeći vanjske znanje. Ovaj papir predstavlja ujedinjeni okvir koji utječe na predučenje ili vanjske prije, u obliku regularizatora, za poboljšanje konvencionalnog jezičkog model a osnovanog učenja. Smatramo dva vrsta regularizatora. Prvi tip je proizveden iz distribucije teme pokrenući LDA na neizbiljnim podacima. Drugi tip se temelji na riječi koje su stvorene naporima ljudskih annotacija. Da bi se učili s regularizatorima, predlažemo novu strukturu podataka, trajektoriju softmax, u ovom papiru. Rezultativne integracije procjenjuju sličnost riječima i klasifikacija osjećaja. Eksperimentalni rezultati pokazuju da naš okvir učenja s regularizacijom prije znanja poboljšava uključenje kvalitete u više podataka u usporedbi s različitim kolekcijom početnih metoda.', 'nl': 'Conventionele woordinsluitingen worden getraind met specifieke criteria (bijvoorbeeld op basis van taalmodellering of co-voorkomen) binnen één enkele informatiebron, waarbij de mogelijkheid tot verdere kalibratie met behulp van externe kennis buiten beschouwing wordt gelaten. Dit document presenteert een uniform raamwerk dat gebruik maakt van vooraf geleerde of externe priors, in de vorm van een regularizer, voor het verbeteren van conventioneel taalmodel gebaseerd embedded learning. We beschouwen twee soorten regularisers. Het eerste type is afgeleid van topic distributie door LDA uit te voeren op gegevens zonder label. Het tweede type is gebaseerd op woordenboeken die zijn gemaakt met menselijke annotatie inspanningen. Om effectief te leren met de regularizers, stellen we in dit artikel een nieuwe datastructuur voor, trajectory softmax. De resulterende embeddings worden geëvalueerd op basis van woordgelijkenis en sentimentclassificatie. Experimentele resultaten tonen aan dat ons leerframework met regularisatie van voorkennis de kwaliteit van het inbedden in meerdere datasets verbetert, in vergelijking met een diverse verzameling basismethoden.', 'da': 'Konventionelle ordindlejringer trænes med specifikke kriterier (f.eks. baseret på sprogmodellering eller samtidig forekomst) inde i en enkelt informationskilde, uden at der tages hensyn til muligheden for yderligere kalibrering ved hjælp af ekstern viden. Dette dokument præsenterer en samlet ramme, der udnytter præ-lærte eller eksterne forudsætninger, i form af en regularizer, til at forbedre konventionel sprogmodel baseret indlejring. Vi overvejer to typer regulatorisatorer. Den første type stammer fra emnefordeling ved at køre LDA på ikke-mærkede data. Den anden type er baseret på ordbøger, der er oprettet med menneskelige annoteringsindsatser. For effektivt at lære med regulariserne, foreslår vi en ny datastruktur, traiectory softmax, i denne artikel. De resulterende indlejringer evalueres ved ordlighed og sentiment klassificering. Eksperimentelle resultater viser, at vores læringsramme med regulering fra tidligere viden forbedrer indlejringskvaliteten på tværs af flere datasæt sammenlignet med en varieret samling af basismetoder.', 'de': 'Herkömmliche Worteinbettungen werden mit spezifischen Kriterien (z.B. basierend auf Sprachmodellierung oder Co-Vorkommen) innerhalb einer einzigen Informationsquelle trainiert, wobei die Möglichkeit einer weiteren Kalibrierung mit externem Wissen vernachlässigt wird. Dieser Beitrag stellt ein einheitliches Framework vor, das vorgelernte oder externe Priors in Form eines Regularizers nutzt, um konventionelles sprachmodellbasiertes Einbettungslernen zu verbessern. Wir betrachten zwei Arten von Regularizern. Der erste Typ wird von der Themenverteilung abgeleitet, indem LDA auf nicht beschrifteten Daten ausgeführt wird. Der zweite Typ basiert auf Wörterbüchern, die mit menschlichen Anmerkungen erstellt werden. Um effektiv mit den Regularizern zu lernen, schlagen wir in diesem Beitrag eine neuartige Datenstruktur vor, Trajektorie softmax. Die resultierenden Einbettungen werden nach Wortähnlichkeit und Stimmungsklassifikation bewertet. Experimentelle Ergebnisse zeigen, dass unser Lernframework mit Regularisierung aus Vorkenntnissen die Einbettungsqualität über mehrere Datensätze hinweg verbessert, im Vergleich zu einer Vielzahl von Basismethoden.', 'id': 'Pencampuran kata konvensional dilatih dengan kriteria spesifik (contohnya, berdasarkan model bahasa atau korespondensi) di dalam sumber informasi tunggal, mengabaikan kesempatan untuk kalibrasi lanjut menggunakan pengetahuan luar. Kertas ini mempersembahkan rangkaian yang bersatu yang mempengaruhi masa depan pre-belajar atau eksternal, dalam bentuk regulariser, untuk meningkatkan pembelajaran berbasis model bahasa konvensional. Kami mempertimbangkan dua jenis regulariser. Tipe pertama didirikan dari distribusi topik dengan menjalankan LDA pada data tidak ditabel. Jenis kedua berdasarkan kamus yang diciptakan dengan usaha anotasi manusia. Untuk mempelajari secara efektif dengan regularisers, kami mengusulkan struktur data baru, trajektori softmax, di kertas ini. Pencampuran hasilnya diuji dengan persamaan kata dan klasifikasi sentimen. Hasil eksperimen menunjukkan bahwa kerangka belajar kita dengan regularisasi dari pengetahuan sebelumnya meningkatkan kualitas penerbangan di berbagai set data, dibandingkan dengan koleksi berbagai metode dasar.', 'ko': '특정 정보원을 바탕으로 하는 모델링(예를 들어 외부 정보원을 바탕으로 하는 모델링)이나 특정 정보원을 바탕으로 하는 모델링(예를 들어 외부 정보원을 바탕으로 하는 모델링).본고는 통일된 틀을 제시했다. 이 틀은 정규화기의 형식으로 사전 학습이나 외부 선험 지식을 이용하여 전통적인 언어 모델을 바탕으로 하는 삽입 학습을 강화한다.우리는 두 가지 정규화자를 고려한다.첫 번째 유형은 표시되지 않은 데이터에서 LDA를 실행함으로써 테마 분포에서 파생됩니다.두 번째는 인공 주석을 바탕으로 만든 사전이다.정규화기를 효과적으로 사용하여 학습을 하기 위해 본고는 새로운 데이터 구조인 궤적softmax를 제시했다.단어의 싱크로율과 감정 분류를 통해 삽입 결과를 평가한다.실험 결과에 따르면 여러 가지 기선 방법에 비해 선험지식을 바탕으로 하는 정규화 학습 구조는 여러 데이터 집합의 삽입 품질을 향상시켰다.', 'sw': 'Matambo ya kawaida yanafundishwa na vigezo maalum (kwa mfano, kwa kutumia mifano ya lugha au tukio la pamoja) ndani ya chanzo moja cha habari, wakipuuza fursa ya kupatikana kwa kutumia maarifa ya nje. Gazeti hili linaleta mfumo wa muungano unaoendelea kipaumbele cha kujifunza kabla au nje, kwa namna ya mtaalamu, kwa ajili ya kuongeza mfumo wa lugha ya kawaida wa kujifunza. Tunaona aina mbili ya watengenezaji. Aina ya kwanza inatokana na usambazaji wa mada kwa kufanya LDA kwenye taarifa zisizoeleweka. aina ya pili ni ya lugha ambazo zinatengenezwa na jitihada za kutoa taarifa za binadamu. To effectively learn with the regularizers, we propose a novel data structure, trajectory softmax, in this paper.  Matokeo hayo yanavutiwa kwa maneno yanayofanana na hisia. Matokeo ya majaribio yanaonyesha kuwa mfumo wetu wa kujifunza na kudhibiti utaratibu wa maarifa ya kabla huboresha ubora wa kuzalisha katika seti za data mbalimbali, ukilinganisha na mkusanyiko wa njia mbalimbali za msingi.', 'tr': 'Adatça söz integrasy (meselâ, dil modelleýäniň ýa-da bir meňzeşlik çe şmesine daýanýar) bir maglumat çeşmesinde täze bir kalibreleme mümkinçiligi ýok edip bilmeýär. Bu kagyz öňden öňden öwrenmeden ýa daşarydaky öňki öňki döwletlerini düzgün täsirleştirmek üçin birleştirilen bir çerçew görkezýär. Biz düzgün düzgünçiler diýip pikir edýäris. Ilkinji hili ýazmayan maglumaty üzerinde LDA tarapyndan tem daýratyndan çykar. Ikinji hili adam duýdurma çabalary bilen döredilen sözlerne daýanýar. Düzenli adamlar bilen öwrenmek üçin, biz bu kagyzda roman maglumat strukturuny, traktöriň ýokary maksimum teklip edip görýäris. Sonuçta içeri kelime meňzeşlik we duýgular klasifikasyna görä deňlendirilýär. Durmançylyk netijelerimiz öwrenmek framlarymyzyň öňki bilgi bilen düzenli taýýarlanmagy bilen daşary taýýarlanmagynyň köpürleýändigini görkezýär.', 'af': "Konvensionale woord inbettings word opgelei met spesifieke kriteriërs (bv. gebaseer op taal modellering of saamvoorkoms) binne 'n enkele inligting bron, onthou die geleentheid vir verdere kalibrering deur eksterne kennis te gebruik. Hierdie papier beveel 'n eenvoudige raamwerk wat voorafleer of eksterne voorafwoordes, in die vorm van 'n regulariseerder, verhoog vir die verbetering van konvensionale taal model gebaseerde inbetering leer. Ons beskou twee tipe regulariseerders. Die eerste tipe is afgeleide van onderwerp verspreiding deur loop LDA op ongeabelde data. Die tweede tipe is gebaseer op woordeboeke wat gemaak word met menslike annotasie versoekte. Om effektief te leer met die regulariseerders, voorstel ons 'n nuwe data struktuur, trajectory softmax in hierdie papier. Die resultateerde inbêdings word deur woord gelykbaarheid en sentiment klasifikasie evalueer. Eksperimentale resultate wys dat ons leer raamwerk met regularisasie van voorheede kennis verbeter inbetering kwaliteit oor veelvuldige datastelle, vergelyk met 'n verskillende versameling van basisline metodes.", 'fa': 'درون یک منبع اطلاعات معمولی استفاده می\u200cکنند که فرصت برای کالیبران بیشتری با استفاده از دانش خارجی استفاده می\u200cکنند. این کاغذ یک چهارچوب متحده را نشان می دهد که پیش از آموزش یافته یا خارجی را به شکل یک قانونی\u200cکننده، برای افزایش یادگیری\u200cهای متحده به مدل زبان معمولی تحت تاثیر قرار می\u200cدهد. ما دو نوع معمولی را در نظر می گیریم. اولین نوع از توزیع موضوع با اجرای LDA در داده\u200cهای نامزدی به دست آورده می\u200cشود. نوع دوم بر اساس واژه\u200cهایی است که با تلاش\u200cهای اظهار انسان آفریده می\u200cشوند. برای موفقیت با معمولی یاد گرفتن با معمولی، ما یک ساختار داده های رمانی را پیشنهاد می کنیم، مسیر نرم ماکس، در این کاغذ. پیوند\u200cهای نتیجه\u200cای به عنوان کلمه شبیه\u200cای و کلمه\u200cهای احساسات ارزیابی می\u200cشوند. نتیجه\u200cهای تجربه\u200cی ما نشان می\u200cدهد که چهارچوب یادگیری ما با ساده\u200cسازی از دانش\u200cهای قبلی در مجموعه\u200cهای داده\u200cهای متعدد، در مقایسه با مجموعه\u200cهای متفاوتی از روش\u200cهای بنیادی بهتر می\u200cشود.', 'sq': 'Përmbajtja e fjalëve konvencionale është trajnuar me kritere të posaçme (për shembull, bazuar në modelimin gjuhësor apo bashkëndodhjen) brenda një burimi të vetëm informacioni, duke harruar mundësinë për kalibrim të mëtejshëm duke përdorur njohuritë e jashtme. Ky dokument paraqet një kuadër të unifikuar që nxjerr përparësi të mësuara ose të jashtme, në form ën e një rregullatori, për përmirësimin e mësimit të ndërtimit të gjuhës konvencionale bazuar në model in e gjuhës. Ne konsiderojmë dy lloje rregullatorësh. Tipi i parë derivohet nga shpërndarja e temës duke ecur LDA në të dhëna pa etiketë. The second type is based on dictionaries that are created with human annotation efforts.  Për të mësuar efektivisht me rregullatorët, ne propozojmë një strukturë të re të të dhënave, trajektori softmax, në këtë letër. Ndërtesat që rezultojnë vlerësohen nga ngjashmëria e fjalës dhe klasifikimi i ndjenjave. Rezultatet eksperimentale tregojnë se kuadri ynë i mësimit me rregullalizim nga njohuritë e mëparshme përmirëson përfshirjen e cilësisë nëpërmjet grupeve të të dhënave të shumta, krahasuar me një koleksion të ndryshëm të metodave bazë.', 'am': 'Conventional word embeddings are trained with specific criteria (e.g., based on language modeling or co-occurrence) inside a single information source, disregarding the opportunity for further calibration using external knowledge.  ይህ ገጽ አስቀድሞ የተማረ ወይም ውጭ የውጭ ቀዳሚዎችን ያሳርፋል፡፡ ሁለት ዓይነቶች አስተዳዳሪዎች እናስባለን ። የመጀመሪያው ዓይነት አዲስ ዶሴ ፍጠር ሁለተኛይቱ ዓይነት በሰው ብሔራዊ ጉዳይ የተፈጠሩ መዝገብ ነው፡፡ በሥርዓት አስተዳሪዎች ጋር ለመማር፣ በዚህ ገጽ የመረጃ ዳታ አካባቢ፣ የግንኙነት ስፍትሕት እናሳውቃለን፡፡ የውጤቱ አካባቢዎች ቃላት በሚመስል እና በሚስማት መግለጫ ያስተካክላሉ፡፡ ፈተና ፍሬዎች ከቀድሞ እውቀታችን ጋር መማር ፍሬማችን በብዛት ዳታተር ጥያቄን እንዲያሳድጋል፣ በተለየ ብዙዎች የጥያቄ ሥርዓት እንዲያሳድግ ያሳያል፡፡', 'hy': 'Հավանդական բառերի ներդրումը սովորեցվում է հատուկ չափումներով (օրինակ, հիմնված լեզվի մոդելավորման կամ համապատասխանատվության վրա) մեկ տեղեկատվական աղբյուրի մեջ, անտեսելով այն հնարավորությունը, որ ապագայում կալիբրացվի արտաքին գիտելիքների Այս թղթին ներկայացնում է միասնական շրջանակ, որը ազդում է նախկին սովորված կամ արտաքին նախաձեռնություններին, օրինադրողի ձևով, ավանդական լեզվի մոդել հիմնված ուսումնասիրության բարելավման համար: Մենք դիտարկում ենք երկու տեսակի կանոնավորողներ: Առաջին տեսակը ստացվում է թեմայի բաշխման միջոցով, երբ սկսում է աշխատել ԼԴԱ-ն աննշան տվյալների վրա: Երկրորդ տեսակը հիմնված է բառարանների վրա, որոնք ստեղծվում են մարդկային նշումների միջոցով: Այս թղթի մեջ արդյունավետ սովորելու համար մենք առաջարկում ենք նոր տվյալների կառուցվածք, շարժման ծրագիր: Արդյունքում ստացված ներդրումները գնահատվում են բառի նմանության և զգացմունքների դասակարգման միջոցով: Փորձարկվող արդյունքները ցույց են տալիս, որ մեր ուսումնական շրջանակը նախկին գիտելիքներից վերահսկվող կարգավորման հետ բարելավում է բազմաթիվ տվյալների համակարգերի որակը, համեմատած հիմնական մեթոդների բազմաթիվ հավաքածուի', 'ca': "Les integracions de paraules convencionals s'entrenen amb criteris específics (per exemple, basats en modelar llengües o coincidència) dins d'una sola font d'informació, ignorant l'oportunitat de seguir calibrant fent servir coneixements externs. Aquest paper presenta un marc unificat que aprofita priors pré-aprenguts o externs, en form a de regularització, per millorar l'aprenentatge integral basat en models de llenguatge convencional. Considerem dos tipus de regularitzadors. El primer tipus es deriva de la distribució temàtica executant LDA en dades sense etiqueta. The second type is based on dictionaries that are created with human annotation efforts.  Per aprendre efectivament amb els regularitzadors, proposem una nova estructura de dades, trajectòria softmax, en aquest article. Les integracions resultants s'evaluen segons la similitud de paraules i la classificació del sentiment. Els resultats experimentals mostren que el nostre marc d'aprenentatge amb regularització a partir del coneixement anterior millora l'incorporació de la qualitat a múltiples conjunts de dades, comparat amb una diversa col·lecció de mètodes de base.", 'az': 'Yalnız bir məlumat kaynağı içində müəyyən edilən sözlər içərisində müəyyən qiymətlərlə təhsil edilir, daxili bilgi ilə daha çox kalibrləmə fərqli olaraq təhsil edilir. Bu kağıt, əvvəlcə öyrənmiş və ya dış əvvəlkilərin öyrənməsini, düzgün dil modelini yüksəltmək üçün, müxtəlif dil modelini yüksəltən öyrənmək üçün birləşdirilmiş bir framework göstərir. Biz iki növlü düzgün tərzi düşünürük. İlk növ məsələlər dağıtılışından LDA vasitəsilə yazılmış məlumatlardan alındı. İkinci növ insan işarələri ilə yaratdığı sözlərə dayanılır. Bu kağızda yeni məlumat quruluşu, trajectory softmax təklif edirik. Növbəti inşallar sözlərin bənzəriliyi və hisslərin klasifikasiyası ilə değerlənir. Müxtəlif sonuçları, əvvəlki bilgi ilə müəyyən edilən öyrənmə qurğusu ilə, çoxlu veri qurğuları ilə müxtəlif dəyişiklik metodlarının müqayisədə, müxtəlif təhsil qurğusu ilə birləşdirilir.', 'bs': 'Konvencionalni integraciji riječi obučeni su s specifičnim kriterijama (na primjer na temelju modela jezika ili saradnje) unutar jednog izvora informacija, bez obzira na mogućnost daljnje kalibracije koristeći vanjske znanje. Ovaj papir predstavlja ujedinjeni okvir koji utiče na predučenje ili vanjske prethodne, u obliku regularizatora, za unapređenje konvencionalnog jezičkog model a osnovanog učenja ugrađenja. Smatramo dva vrsta regularizatora. Prvi tip je proizveden iz distribucije teme pokrenući LDA na neizbiljnim podacima. Drugi tip je baziran na rečnicima koje su stvorene naporima ljudskih annotacija. Da bi se efikasno naučili sa regularizatorima, predlažemo novu strukturu podataka, trajektoriju softmax, u ovom papiru. Rezultatni integraciji procjenjuju sličnost riječima i klasifikacija osjećaja. Eksperimentalni rezultati pokazuju da naš okvir učenja s regularizacijom iz prethodnog znanja poboljšava integraciju kvalitete na višestrukim podacima u usporedbi s različitim kolekcijom početnih metoda.', 'cs': 'Konvenční vkládání slov jsou trénovány podle specifických kritérií (např. založených na jazykovém modelování nebo společném výskytu) uvnitř jednoho informačního zdroje, přičemž se ignoruje možnost další kalibrace pomocí externích znalostí. Tento článek představuje jednotný rámec, který využívá předučené nebo externí předchozí záznamy, ve formě regularizátoru, pro zlepšení konvenčního jazykového modelu založeného na embeddedování. Zvažujeme dva typy regularizátorů. První typ je odvozen z distribuce tématu spuštěním LDA na neoznačených datech. Druhý typ je založen na slovnících, které jsou vytvořeny s lidskými anotacemi. Abychom se efektivně učili s regularizátory, navrhujeme v tomto článku novou datovou strukturu, trajektorii softmax. Výsledné vložení jsou hodnoceny podobností slov a klasifikací sentimentů. Experimentální výsledky ukazují, že náš učební rámec s regularizací z předchozích znalostí zlepšuje kvalitu vložení do více datových sad ve srovnání s různorodou sbírkou základních metod.', 'et': 'Tavapäraseid sõnade manustamist koolitatakse konkreetsete kriteeriumidega (nt keele modelleerimisel või koosesinemisel) ühes teabeallikas, jättes arvesse võimalust edasiseks kalibreerimiseks välisteadmiste abil. Käesolevas dokumendis esitatakse ühtne raamistik, mis võimendab eelõppenud või väliseid prioriteete regulariseerija kujul tavapärase keelemudelil põhineva manustamisõppe parandamiseks. Me kaalume kahte tüüpi regulaatoreid. Esimene tüüp tuletatakse teemajaotusest, käivitades LDA märgistamata andmetel. Teine tüüp põhineb sõnaraamatutel, mis on loodud inimese annoteerimise jõupingutustega. Regulariseerijatega tõhusaks õppimiseks pakume selles töös välja uudse andmestruktuuri, trajektoor softmax. Tulenevaid manustamisi hinnatakse sõna sarnasuse ja sentimentaalse klassifikatsiooni alusel. Eksperimentaalsed tulemused näitavad, et meie õppimisraamistik, mis reguleerib varasemaid teadmisi, parandab mitme andmekogumi manustamise kvaliteeti võrreldes erinevate lähtemeetodite kogumiga.', 'bn': 'এক তথ্য উৎসের ভিতরে বিশেষ ক্যালাবেশনের সুযোগ প্রশিক্ষণ প্রদান করা হয় (যেমন ভাষার মডেলিং অথবা একই সাথে সংঘটিত ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক)  এই পত্রিকাটি একটি একত্রিত ফ্রেম উপস্থাপন করেছে যা পূর্বে শিক্ষা বা বাইরে শিক্ষা প্রাপ্ত বা বিদেশী শিক্ষা প্রদান করা হয়েছে, একটি নিয়মিত শিক্ষা  আমরা দুটি ধরনের নিয়মিত বিবেচনা করি। এলডিএ চালিয়ে যাওয়ার মাধ্যমে প্রথম ধরনের বিষয় বিতরণ থেকে উদ্ধার করা হয়েছে অল্প তথ্য চালানোর মাধ্যমে। দ্বিতীয় ধরনের ভিত্তিতে রয়েছে মানুষের প্রচেষ্টার মাধ্যমে যা সৃষ্টি করা হয়েছে। কার্যকরভাবে নিয়ন্ত্রণকারীদের সাথে শিখার জন্য আমরা এই কাগজটিতে একটি উপন্যাস তথ্য কাঠামো প্রস্তাব করি, ট্রাক্টরিক এর ফলে বিভিন্ন বিভিন্ন শব্দের সমতা এবং অনুভূতি বিভাগের মাধ্যমে মূল্যায়ন করা হয়। পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের শিক্ষার কাঠামো পূর্বের জ্ঞান নিয়ন্ত্রণের সাথে বিভিন্ন ধরনের বেসাইলাইন পদ্ধতির তুলনায় বেশ কিছ', 'fi': 'Tavanomaisia sanaupotuksia koulutetaan erityisillä kriteereillä (esim. kielimallinnukseen tai rinnakkaisesiintymiseen) yhden tietolähteen sisällä ottamatta huomioon mahdollisuutta kalibroida edelleen ulkoisen tiedon avulla. Tässä artikkelissa esitellään yhtenäinen viitekehys, joka hyödyntää ennalta opittuja tai ulkoisia prioriteetteja säännöstelijän muodossa perinteisen kielimallipohjaisen upotusoppimisen parantamiseksi. Meillä on kahdenlaisia laillistajia. Ensimmäinen tyyppi johdetaan aihejakaumasta ajamalla LDA:ta merkitsemättömille tiedoille. Toinen tyyppi perustuu sanakirjoihin, jotka on luotu inhimillisillä huomautuksilla. Jotta säännöstelijöiden kanssa voitaisiin oppia tehokkaasti, ehdotamme tässä artikkelissa uutta datarakennetta, trajectory softmax. Tuloksena olevia upotuksia arvioidaan sanojen samankaltaisuuden ja tunteiden luokittelun perusteella. Kokeelliset tulokset osoittavat, että oppimiskehyksemme, jossa on säännönmukainen aikaisemmasta tiedosta, parantaa useiden tietokokonaisuuksien upottamisen laatua verrattuna moniin perusaikataulumenetelmien kokoelmaan.', 'sk': 'Običajne vgradnje besed se usposabljajo s posebnimi merili (npr. na podlagi jezikovnega modeliranja ali sočasnega pojava) znotraj enega samega vira informacij, pri čemer se ne upošteva možnost nadaljnje kalibracije z uporabo zunanjega znanja. Ta prispevek predstavlja enoten okvir, ki izkorišča vnaprej učene ali zunanje predhodne predhodne naloge v obliki urejevalnika za izboljšanje vključevanja učenja, ki temelji na običajnih jezikovnih modelih. Razmišljamo o dveh vrstah regulatorjev. Prva vrsta je izpeljana iz porazdelitve teme z zagonom LDA na neoznačenih podatkih. Druga vrsta temelji na slovarjih, ki so ustvarjeni s človeškimi pripombami. Za učinkovito učenje z regulatorji v tem prispevku predlagamo novo strukturo podatkov, trajectory softmax. Nastale vdelave so ocenjene s podobnostjo besed in klasifikacijo sentimenta. Eksperimentalni rezultati kažejo, da naš učni okvir z ureditvijo iz predhodnega znanja izboljšuje kakovost vključevanja v več naborov podatkov v primerjavi z raznoliko zbirko osnovnih metod.', 'jv': 'embedding Perintah iki nggawe akeh nesaturan sing paling-nesaturan sing rumangsa akeh banter, ngono nggawe barang langkung sampek kudu nggawe gerakan ingkang. Awak dhéwé sawetara duwé Tipe tualke kang tanggal Distribusi Tema nang data Gak Bukak Tipe wis digawe sing basa ning diktualisar sing dumadhi karo dolanan sing dadi populer. Awak dhéwé nggambar aturan biasane gagal, kéné ngerasakno dadi nggawe datadir, trajector software, ning basa iki. gambar Reulti sing paling-peringatan nganggep kuwi awak dhéwé sisané awak dhéwé karo sistem sing beraksi kanggo awak dhéwé kuwi tindakan akeh perusahaan karo dataset sing butawak dhéwé, ngrebut karo akeh sampek akeh perusahaan sistem sing sus', 'ha': "An sanar da maganar da ke ƙunsa da kayan ƙayyade masu ƙayyade (misali, a kan motsi da misalin harshe ko da tsohon da ke koma) cikin wani sourcen maɓalli guda, kuma ana ƙyale fursa wa kalarin da ke amfani da ilmi na ƙarƙasan. Wannan takardar na bãyar da wani firam wanda ya haɗu da shi wanda ke ƙara gaba-da-baro ko bakin-gaba, cikin the form of a Rurizor, dõmin ya ƙara wa zane-zane-da-bakin ayuka na ɗabi'a. Tuna ganin wasu nau'i biyu. @ action: button Nau'in na biyu, yana kan karatun dictionaries wanda aka halitta da aikin zartar mutane. To, dõmin a sanar da masu inganci, sai mu buƙata wani matsayin data na yanzu, matsayin hanya, cikin wannan takarda. Ana ƙaddara masu ƙaranci da aka daidaita magana da sifilawa. Matarin da aka jarraba, ya nuna firam masu karanta da jurisdictori daga gabãnin wani ilmi ya improve tsarin faɗi a kowace data-set-daban, kuma a sammeniyar da misãlai masu haɗi ko-jama'a-biyu.", 'he': 'תוספת מילים מסורתיות מאומנות עם קריטורים ספציפיים (למשל, מבוססים על דוגמנית שפה או התרחשות משותפת) בתוך מקור מידע אחד, מתעלמים מההזדמנות לקליברציה נוספת באמצעות ידע חיצוני. המסמך הזה מציג מסגרת מאוחדת שמשתמשת על קודמות קודמות מלמדות או חיצוניים, בצורה של חוקית, כדי לשפר את הלימוד המבוסס על מודל שפה קונבנציונציאלי. אנחנו שוקלים שני סוגים של חוקים. הטיפוס הראשון מושג מהפיצוץ הנושא על ידי הפעלת LDA על נתונים ללא סימנים. The second type is based on dictionaries that are created with human annotation efforts.  כדי ללמוד באופן יעיל עם המפקדים, אנו מציעים מבנה נתונים חדש, מסלול softmax, בעיתון הזה. המערכות הנוצאות מוערכות על ידי דמיון מילים וסימון רגשות. תוצאות ניסויים מראות שמסגרת הלימודים שלנו עם התקנה מידע קודם משפר את הכניסה של איכות בין קבוצות נתונים רבות, בהשוואה לאספת מיוחדת של שיטות בסיסיות.', 'bo': 'Conventional word embeddings are trained with specific criteria (e.g., based on language modeling or co-occurrence) inside a single information source, disregarding the opportunity for further calibration using external knowledge. ཤོག ང་ཚོས་མི་འདྲ་བ་བཟོས་མཁན་གྱི་རྩིས་པ་གཉིས་བསམ་བྱེད་ཀྱི་ཡོད། རིགས་དང་པོ་དེ་ནི་ཁོང་ཡིག་ཆ་མེད་པའི་གནད་དོན་བཤད་ནས་སྤྱོད་པའི་LDA་ནས་ཕན་འབྲས་བ་རེད། དབྱེ་རིགས་གཉིས་པ་དེ་ནི་མིའི་བསྐུལ་ལུགས་ཀྱི་བཟོ་བརྗོད་པའི་འཇིག་རྟེན་དང་མཉམ་དུ་གཞི་རྟེན་ཡོད། དེ་ལྟར་འགྱུར་བ་དང་མཉམ་དུ་གྲངས་སུ་བཏང་ན། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་གི་གསར་འགུལ་གྱི་ཆ་འཕྲིན་དང་། དབྱིབས་ཤུགས་ཀྱི་གནས་ཚུལ་དེ་ཚོར་བ་དང་སྒྲིག་ཚིག་གི་དབྱེ་རིགས་ལ་བསྟུན་ནས་དབྱེ་བ་བཟོས་ཡོད། Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality across multiple datasets, compared with a diverse collection of baseline methods.'}
{'en': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'ar': 'شبكة عصبية تلافيفية متكررة قائمة على الانتباه لتسجيل النقاط تلقائيًا للمقال', 'fr': "Réseau neuronal convolutif récurrent basé sur l'attention pour la notation automatique des dissertations", 'pt': 'Rede Neural Convolucional Recorrente Baseada na Atenção para Pontuação Automática de Ensaios', 'es': 'Red neuronal convolucional recurrente basada en la atención para la puntuación automática de ensayos', 'ja': '自動小論文スコアリングのためのアテンションベースの再発畳み込みニューラルネットワーク', 'zh': '注意自论文评分循环卷积神经网络', 'ru': 'Внимание на основе рекуррентной сверточной нейронной сети для автоматической оценки эссе', 'hi': 'स्वत: निबंध स्कोरिंग के लिए ध्यान-आधारित आवर्तक Convolutional तंत्रिका नेटवर्क', 'ga': 'Líonra Néarrach Comhtháite Athfhillteach atá bunaithe ar aird le haghaidh Scóráil Uathoibríoch Aiste', 'ka': 'ავტომატიკური Essay მონიშნეებისთვის დაახლოებით შემდეგ კონტუალური ნეიროლური ქსელი', 'hu': 'Figyelem-alapú ismétlődő konvolúciós neurális hálózat az automatikus esszék pontozásához', 'el': 'Με βάση την προσοχή επαναλαμβανόμενο νευρωνικό δίκτυο για αυτόματη βαθμολογία δοκίμων', 'lt': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'it': "Rete neurale convoluzionale ricorrente basata sull'attenzione per il punteggio automatico del saggio", 'mk': 'Рекурентна конволуционална неврална мрежа базирана на внимание за автоматско оценување на тестот', 'kk': 'Автоматты Essay Scoring үшін қайталанатын қайталанатын невралдық желі', 'ms': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'mt': 'Netwerk newrali konvoluzzjonali rikorrenti bbażat fuq l-attenzjoni għall-punteġġi tal-ittestjar awtomatiku', 'no': 'Attention-basert gjentakelig konvolusjonell neuralnettverk for automatisk Essay Scoring', 'ml': 'സ്വയം എസ്സി സ്കോറിങ്ങിനുള്ള ശേഖരം', 'mn': 'Автоматикийн Essay Scoring-ийн сэтгэл зүйн сэтгэл хөдөлгөөн', 'si': 'ස්වයංක්\u200dරීය එසේය ස්කෝරින්ග් සඳහා අවධානය සම්බන්ධයෙන් ප්\u200dරතික්\u200dරියාත්මක ජාලය', 'pl': 'Oparta na uwagę Recurrent Convolutional Neuroral Network dla automatycznego wyniku esejów', 'so': 'Shabakadda Neural Neural ee ku soo deganaanshaha ee loogu talagalay Automatic Essay Scoring', 'ro': 'Rețeaua Neurală Convoluțională Recurentă Recurentă bazată pe atenție pentru punctarea automată a eseului', 'ta': 'தானியங்கி எஸ்சி வருடுதல்', 'ur': 'Automatic Essay Scoring کے لئے اپنا حوادث بنیاد دوبارہ کنورل نیورل نیورل نیٹورک', 'sr': 'Na pažnji se osnovala ponovna konvolucionalna nervna mreža za automatski rezultat eseja', 'sv': 'Uppmärksamhet baserat återkommande konvulutivt neuralt nätverk för automatisk essäpoäng', 'uz': 'Name', 'vi': 'Chú ý Liên tục ôn hoà thần kinh cho Automatic Essay Scoring', 'bg': 'Базирана на вниманието повтаряща се конвелуционна неврална мрежа за автоматично оценяване на есета', 'nl': 'Aandacht-gebaseerd Recurrent Convolutional Neural Network voor Automatische Essay Scoring', 'da': 'Opmærksomhedsbaseret tilbagevendende konvulutivt neural netværk til automatisk Essay scoring', 'hr': 'Na temelju pažnje ponovna konvolucionalna nervna mreža za automatski rezultat Essay', 'de': 'Aufmerksamkeitsbasiertes Recurrent Convolutional Neural Network für automatische Essay Scoring', 'id': 'Jaringan Neural Konvelusional Berikut Berdasarkan Perhatian untuk Puncakan Ujian Otomatis', 'sw': 'Mtandao wa Neural wa Kujitolea kwa Kifaragha wa Essay', 'fa': 'شبکه عصبی بازگشت بر پایه توجه برای امتیاز اساسی خودکار', 'af': 'Aangaande- gebaseerde herhaling Konvolusionele Neuralnetwerk vir Outomatiese Essay Telling', 'tr': 'Otomatik Essay Görkezilişi', 'sq': 'Rrjeti neural i përsëritur konvolutiv i bazuar në vëmendje për pikëpamjen automatike të provave', 'am': 'ምርጫዎች', 'hy': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'az': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'ko': '주의에 기초한 귀속 권적 신경 네트워크 자동 작문 평점', 'bn': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'bs': 'Na temelju pažnje ponovna konvolucionalna nervna mreža za automatski rezultat Essay', 'ca': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'et': 'Tähelepõhine korduv konvolutsiooniline neurovõrk automaatse essee skoorimise jaoks', 'cs': 'Recyklující konveluční neuronová síť založená na pozornosti pro automatické hodnocení esejí', 'fi': 'Huomioon perustuva toistuva konvolutionaalinen hermoverkosto automaattiseen esseen pisteytykseen', 'jv': 'Attension-basa recurrecurent convolution Neral Network for Automatically essay Escring', 'ha': 'KCharselect unicode block name', 'sk': 'Pozornost temelječa ponavljajoča konvolucijska živčna mreža za samodejno ocenjevanje esejev', 'he': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring', 'bo': 'Attention-based Recurrent Convolutional Neural Network for Automatic Essay Scoring'}
{'en': 'Neural network models have recently been applied to the task of automatic essay scoring, giving promising results. Existing work used recurrent neural networks and convolutional neural networks to model input essays, giving grades based on a single vector representation of the essay. On the other hand, the relative advantages of RNNs and CNNs have not been compared. In addition, different parts of the essay can contribute differently for scoring, which is not captured by existing models. We address these issues by building a hierarchical sentence-document model to represent essays, using the attention mechanism to automatically decide the relative weights of words and sentences. Results show that our model outperforms the previous state-of-the-art methods, demonstrating the effectiveness of the attention mechanism.', 'ar': 'تم تطبيق نماذج الشبكة العصبية مؤخرًا على مهمة تسجيل المقالات تلقائيًا ، مما أعطى نتائج واعدة. استخدم العمل الحالي الشبكات العصبية المتكررة والشبكات العصبية التلافيفية لنمذجة مقالات الإدخال ، وإعطاء الدرجات بناءً على تمثيل متجه واحد للمقال. من ناحية أخرى ، لم تتم مقارنة المزايا النسبية لشبكات RNN و CNN. بالإضافة إلى ذلك ، يمكن لأجزاء مختلفة من المقال أن تساهم بشكل مختلف في وضع النقاط ، وهو ما لم يتم التقاطه بواسطة النماذج الحالية. نعالج هذه القضايا من خلال بناء نموذج هرمي لوثيقة الجملة لتمثيل المقالات ، باستخدام آلية الانتباه لتحديد الأوزان النسبية للكلمات والجمل تلقائيًا. تظهر النتائج أن نموذجنا يتفوق في الأداء على أحدث الأساليب السابقة ، مما يدل على فعالية آلية الانتباه.', 'es': 'Recientemente se han aplicado modelos de redes neuronales a la tarea de puntuación automática de ensayos, dando resultados prometedores. El trabajo existente utilizó redes neuronales recurrentes y redes neuronales convolucionales para modelar ensayos de entrada, dando calificaciones basadas en una representación vectorial única del ensayo. Por otro lado, no se han comparado las ventajas relativas de las RNN y las CNN. Además, diferentes partes del ensayo pueden contribuir de manera diferente a la puntuación, lo que no se refleja en los modelos existentes. Abordamos estas cuestiones mediante la creación de un modelo jerárquico de documentos de oraciones para representar ensayos, utilizando el mecanismo de atención para decidir automáticamente los pesos relativos de las palabras y las oraciones. Los resultados muestran que nuestro modelo supera a los métodos de última generación anteriores, lo que demuestra la eficacia del mecanismo de atención.', 'pt': 'Modelos de redes neurais foram recentemente aplicados à tarefa de pontuação automática de ensaios, apresentando resultados promissores. O trabalho existente usou redes neurais recorrentes e redes neurais convolucionais para modelar ensaios de entrada, dando notas com base em uma única representação vetorial do ensaio. Por outro lado, as vantagens relativas de RNNs e CNNs não foram comparadas. Além disso, diferentes partes do ensaio podem contribuir de forma diferente para a pontuação, o que não é capturado pelos modelos existentes. Abordamos essas questões construindo um modelo hierárquico de documento de sentença para representar redações, usando o mecanismo de atenção para decidir automaticamente os pesos relativos de palavras e sentenças. Os resultados mostram que nosso modelo supera os métodos anteriores do estado da arte, demonstrando a eficácia do mecanismo de atenção.', 'fr': "Des modèles de réseaux neuronaux ont récemment été appliqués à la notation automatique des dissertations, donnant des résultats prometteurs. Les travaux existants utilisaient des réseaux de neurones récurrents et des réseaux de neurones convolutifs pour modéliser des essais d'entrée, donnant des notes basées sur une représentation vectorielle unique de l'essai. En revanche, les avantages relatifs des RNN et des CNN n'ont pas été comparés. En outre, différentes parties de l'essai peuvent contribuer différemment à la notation, ce qui n'est pas saisi par les modèles existants. Nous abordons ces questions en construisant un modèle hiérarchique de document de phrase pour représenter les dissertations, en utilisant le mécanisme d'attention pour décider automatiquement du poids relatif des mots et des phrases. Les résultats montrent que notre modèle surpasse les méthodes de pointe précédentes, démontrant l'efficacité du mécanisme de l'attention.", 'ja': 'ニューラルネットワークモデルは、最近、エッセイの自動スコアリングのタスクに適用され、有望な結果をもたらしています。既存の研究は、再帰ニューラルネットワークと畳み込みニューラルネットワークを使用して入力エッセイをモデル化し、エッセイの単一のベクトル表現に基づいて成績を与えた。一方、ＲＮＮ及びＣＮＮの相対的な利点は比較されていない。さらに、エッセイの異なる部分は、既存のモデルでは取り込まれていないスコアリングに異なる貢献をすることができます。エッセイを表現するための階層的な文章ドキュメントモデルを構築し、注意メカニズムを使用して、単語と文章の相対的な重みを自動的に決定することによって、これらの問題に対処します。結果は、当社のモデルが以前の最先端の方法を上回っていることを示しており、注意メカニズムの有効性を示しています。', 'zh': '神经网络模形近用自论评分之任,与之有期。 今事用递归神经网络、卷积神经网络建模输论,以论文单向量示评分。 其一,RNN与CNN相对未校也。 此外,文章异类,可异于评分,此见模形不可得也。 因构一句文档以表论文,用意机自决单词与句权重以决之。 结果表明者,吾之先入也,明其有效性也。', 'hi': 'तंत्रिका नेटवर्क मॉडल को हाल ही में स्वचालित निबंध स्कोरिंग के कार्य पर लागू किया गया है, जिससे आशाजनक परिणाम मिलते हैं। मौजूदा काम ने इनपुट निबंधों को मॉडल करने के लिए आवर्तक तंत्रिका नेटवर्क और कनवल्शनल न्यूरल नेटवर्क का उपयोग किया, जो निबंध के एकल वेक्टर प्रतिनिधित्व के आधार पर ग्रेड दे रहा था। दूसरी ओर, RNNs और CNN के सापेक्ष लाभों की तुलना नहीं की गई है। इसके अलावा, निबंध के विभिन्न हिस्से स्कोरिंग के लिए अलग-अलग योगदान कर सकते हैं, जो मौजूदा मॉडलों द्वारा कब्जा नहीं किया गया है। हम निबंधों का प्रतिनिधित्व करने के लिए एक पदानुक्रमित वाक्य-दस्तावेज़ मॉडल का निर्माण करके इन मुद्दों को संबोधित करते हैं, ध्यान तंत्र का उपयोग करके स्वचालित रूप से शब्दों और वाक्यों के सापेक्ष वजन तय करते हैं। परिणाम बताते हैं कि हमारा मॉडल पिछले अत्याधुनिक तरीकों से बेहतर प्रदर्शन करता है, जो ध्यान तंत्र की प्रभावशीलता का प्रदर्शन करता है।', 'ru': 'Нейросетевые модели недавно были применены к задаче автоматической оценки эссе, давая многообещающие результаты. Существующие работы использовали рекуррентные нейронные сети и сверточные нейронные сети для моделирования входных эссе, давая оценки на основе единого векторного представления эссе. С другой стороны, сравнение относительных преимуществ РНН и ХНН не проводилось. Кроме того, различные части эссе могут по-разному способствовать оценке, которая не отражена в существующих моделях. Мы решаем эти вопросы, создавая иерархическую модель «предложение-документ» для представления эссе, используя механизм внимания для автоматического определения относительных весов слов и предложений. Результаты показывают, что наша модель превосходит предыдущие современные методы, демонстрируя эффективность механизма внимания.', 'ga': 'Cuireadh samhlacha líonra néaraíoch i bhfeidhm le déanaí maidir le scóráil uathoibríoch aistí, rud a thugann torthaí gealltanais. D’úsáid obair reatha líonraí néaracha athfhillteacha agus líonraí néaracha comhraonta chun aistí ionchuir a shamhaltú, ag tabhairt gráid bunaithe ar léiriú veicteoireach amháin ar an aiste. Ar an láimh eile, ní dhearnadh comparáid idir na buntáistí coibhneasta a bhaineann le RNNanna agus CNNanna. Ina theannta sin, is féidir le codanna éagsúla den aiste rannchuidiú go difriúil le haghaidh scórála, rud nach bhfuil gafa ag samhlacha atá ann cheana féin. Tugaimid aghaidh ar na saincheisteanna seo trí mhúnla ordlathach de dhoiciméid abairte a thógáil chun aistí a léiriú, ag baint úsáide as an meicníocht aird chun meáchan coibhneasta na bhfocal agus na n-abairtí a chinneadh go huathoibríoch. Léiríonn torthaí go sáraíonn ár múnla na modhanna úrscothacha a bhí ann roimhe seo, rud a léiríonn éifeachtacht an mheicníocht aird.', 'hu': 'A közelmúltban ideghálózati modelleket alkalmaztak az automatikus esszék pontozás feladatára, ígéretes eredményeket adva. A már meglévő munkák visszatérő neurális hálózatokat és konvuluális neurális hálózatokat használtak a bemeneti esszék modellezésére, amelyek az esszé egyetlen vektoros ábrázolásán alapulnak. Másrészt az RNN-ek és CNN-ek relatív előnyeit nem hasonlították össze. Ezenkívül az esszé különböző részei eltérően járulhatnak hozzá a pontszámozáshoz, amelyet a meglévő modellek nem rögzítenek. Ezeket a kérdéseket úgy kezeljük, hogy hierarchikus mondat-dokumentum modellt építünk az esszék ábrázolására, a figyelem mechanizmus segítségével automatikusan meghatározzuk a szavak és mondatok relatív súlyát. Az eredmények azt mutatják, hogy modellünk felülmúlja a korábbi korszerű módszereket, bizonyítva a figyelem mechanizmus hatékonyságát.', 'el': 'Πρόσφατα έχουν εφαρμοστεί μοντέλα νευρωνικών δικτύων στο έργο της αυτόματης βαθμολογίας δοκίμων, δίνοντας ελπιδοφόρα αποτελέσματα. Η υπάρχουσα εργασία χρησιμοποίησε επαναλαμβανόμενα νευρωνικά δίκτυα και πολύπλοκα νευρωνικά δίκτυα για να μοντελοποιήσει δοκίμια εισόδου, δίνοντας βαθμούς με βάση μια ενιαία διανυσματική αναπαράσταση της εργασίας. Από την άλλη πλευρά, τα σχετικά πλεονεκτήματα των RNN και των CNN δεν έχουν συγκριθεί. Επιπλέον, διαφορετικά μέρη της έκθεσης μπορούν να συμβάλουν διαφορετικά στη βαθμολογία, η οποία δεν αποτυπώνεται από υπάρχοντα μοντέλα. Αντιμετωπίζουμε αυτά τα ζητήματα δημιουργώντας ένα ιεραρχικό μοντέλο πρότασης-εγγράφου για να αναπαραστήσουμε τα δοκίμια, χρησιμοποιώντας τον μηχανισμό προσοχής για να αποφασίσουμε αυτόματα το σχετικό βάρος λέξεων και προτάσεων. Τα αποτελέσματα δείχνουν ότι το μοντέλο μας ξεπερνά τις προηγούμενες μεθόδους τελευταίας τεχνολογίας, αποδεικνύοντας την αποτελεσματικότητα του μηχανισμού προσοχής.', 'it': "Modelli di rete neurale sono stati recentemente applicati al compito di punteggio automatico del saggio, dando risultati promettenti. Il lavoro esistente ha utilizzato reti neurali ricorrenti e reti neurali convoluzionali per modellare saggi di input, dando voti basati su una rappresentazione vettoriale singola del saggio. D'altra parte, i vantaggi relativi di RNN e CNN non sono stati confrontati. Inoltre, diverse parti del saggio possono contribuire in modo diverso per il punteggio, che non è catturato dai modelli esistenti. Affrontiamo questi problemi costruendo un modello gerarchico frase-documento per rappresentare i saggi, utilizzando il meccanismo di attenzione per decidere automaticamente il peso relativo di parole e frasi. I risultati mostrano che il nostro modello supera i precedenti metodi all'avanguardia, dimostrando l'efficacia del meccanismo di attenzione.", 'ka': 'ნეიროლური ქსელის მოდელები მხოლოდ აკეთებულია ავტომატური ესეის სკონტირების დავალებისთვის, რომლებიც გვეუბნებული შედეგების შესახებ. მსგავსი სამუშაო გამოყენებული რეკურენტური ნეიროლური ქსელები და კონგუროლური ნეიროლური ქსელები, რომლებიც მოდელურად შეტყობინებული ესეების მოდელედ, რომლებ მეორე მხოლოდ, RNN და CNN-ის პირობილური გამოსახულებები არ შემდგომარებულია. დამატებით, სესიის განსხვავებული ნაწილები შეიძლება განსხვავებულად დამატებოთ სკორეციისთვის, რომელიც არ არის ჩატვირთებული მოდელებით. ჩვენ ამ პრობლემების შესახებ იერაქტიკური კომენტაქტის მოდელის შესახებ ესეების გამოყენება, დაახლოების მექანსის გამოყენება სიტყვების და სიტყვების შესახებ ავტომატურ შემდეგ ჩვენი მოდელი უფრო გავაკეთებს წინა სურათების მეტები, რომელიც გამოჩვენება აფექტიურება მაქსინემის მექსინემის ეფექტიურობას.', 'kk': 'Нейрондық желі үлгілері автоматты есеп сұрауының тапсырмасына қолданылды, әлемді нәтижелерді беру үшін. Бар жұмыс қайталанатын невралды желі және қайталанатын невралды желілерді есеяның бір векторына негізделген сыныптарды үлгілеу үшін қолданылады. Біріншіден, RNN және CNN қатынастық артықшылықтар салыстырылмаған. Қосымша, есеяның әртүрлі бөлігі сұрау үшін әртүрлі көмектесе алады, бұл үлгілер бар болмайды. Біз бұл мәселелерді иерархиялық құжат үлгісін құру үшін ессейлерді көрсету үшін, сөздер мен сөздердің қатынастығын автоматты түрде шешу үшін қатынастыру механизмін қолданамыз. Нәтижелер біздің үлгіміздің алдыңғы суреттің әдістерін өзгерту әдістерін көрсетеді.', 'ms': 'Model rangkaian saraf baru-baru ini telah dilaksanakan untuk tugas penilaian esai automatik, memberikan keputusan yang berjanji. Kerja yang wujud digunakan rangkaian saraf berulang dan rangkaian saraf konvolusi untuk model esai input, memberikan grad berdasarkan perwakilan vektor tunggal esai. On the other hand, the relative advantages of RNNs and CNNs have not been compared.  Selain itu, bahagian-bahagian yang berbeza dari esei boleh menyumbangkan dengan berbeza untuk penilaian, yang tidak ditangkap oleh model yang wujud. Kami mengatasi isu-isu ini dengan membina model kalimat-dokumen hierarkis untuk mewakili esei, menggunakan mekanisme perhatian untuk automatik memutuskan berat relatif perkataan dan kalimat. Results show that our model outperforms the previous state-of-the-art methods, demonstrating the effectiveness of the attention mechanism.', 'ml': 'അടുത്തുതന്നെ സ്വയം എസ്സേ സ്കോര്\u200d ചെയ്യുന്നതിന്റെ ജോലിയില്\u200d പ്രയോഗിക്കപ്പെട്ടിരിക്കുന്ന നെയുറല്\u200d നെറ്റ നിലവിലുള്ള ജോലി ആവര്\u200dത്തിക്കുന്ന ന്യൂറല്\u200d നെറുല്\u200d നെറുല്\u200d നെറുല്\u200d നെറുല്\u200d നെറുല്\u200d നെറുല്\u200d വര്\u200dക്കുകള്\u200d ഉപയോഗിക്കുന്നു. എസ്സേയിലെ  മറുവശത്ത് RNNs-കളുടെയും CNNNകളുടെയും അടുത്ത സുഖാനുഭവങ്ങള്\u200d തുല്യമാക്കിയിട്ടില്ല. കൂടാതെ, നിലവിലുള്ള മോഡലുകളാല്\u200d പിടികൂടാത്ത ചില ഭാഗങ്ങള്\u200dക്ക് വ്യത്യസ്തമായി സ്കോര്\u200d ചെയ്യാന്\u200d സാധിക്ക വാക്കുകളുടെയും വാക്കുകളുടെയും തൂക്കങ്ങളുടെയും വാക്കുകളുടെയും തീരുമാനിക്കുന്നതിന്റെയും ഉത്തമമായ വാക്കുകളുടെയും തീരുമാനി ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ മോഡല്\u200d മുമ്പ് മാതൃകയുടെ കലാകാര്യത്തിന്റെ രീതികള്\u200d പ്രവര്\u200dത്തിപ്പിക്ക', 'mt': 'Dan l-aħħar ġew applikati mudelli ta’ netwerk newrali għall-kompitu ta’ punteġġ awtomatiku ta’ testijiet, li jagħtu riżultati promettenti. Xogħol eżistenti uża netwerks newrali rikorrenti u netwerks newrali konvoluzzjonali biex jimmudellaw essays ta’ input, li jagħtu gradi bbażati fuq rappreżentazzjoni ta’ vettur wieħed tal-essay. Min-naħa l-oħra, il-vantaġġi relattivi ta’ RNNs u CNNs ma tqabblux. Barra minn hekk, partijiet differenti tas-sess jistgħu jikkontribwixxu b’mod differenti għall-punteġġ, li mhuwiex maqbud minn mudelli eżistenti. Aħna nindirizzaw dawn il-kwistjonijiet billi nibnu mudell ġerarkiku ta’ sentenza-dokument biex nirrappreżentaw l-esejs, billi nużaw il-mekkaniżmu ta’ attenzjoni biex jiddeċiedu awtomatikament il-piżijiet relattivi tal-kliem u s-sentenzi. Ir-riżultati juru li l-mudell tagħna huwa ogħla mill-metodi l-aktar avvanzati preċedenti, li juri l-effettività tal-mekkaniżmu ta’ attenzjoni.', 'no': 'Nøyrale nettverksmodeller er nyleg brukte på oppgåva for automatisk forsøkskoring, og gjev forsøkingsresultat. Det eksisterande arbeidet brukt gjentakelige neuralnettverk og konvolusjonelle neuralnettverk for å modellere inndataessar, og gir grader basert på ein enkelt vektorrepresentasjon av essasen. Den relative fordelene av RNN og CNN er ikkje samanlikna. I tillegg kan forskjellige deler av essasen bidra til ein annan måte for scoring, som ikkje er henta av eksisterande modeller. Vi handterar desse problemene ved å bygge eit hierarkisk setningsdokumentmodell for å representera essay, ved å bruka oppmerksmekanismen for å avgjøre automatisk relative vekt av ord og setningar. Resultater viser at modellen vårt utfører dei førre metodane for kunsten, som viser effektiviteten til oppmerksmekanismen.', 'lt': 'Neseniai buvo taikomi neurologinių tinklų modeliai automatiniam egzaminų vertinimui, duodant pažadus rezultatus. Esamas darbas naudojo pakartotinius nervinius tinklus ir konvoliucinius nervinius tinklus įėjimo egzaminui modeliuoti, suteikiant klases, grindžiamas vieno egzamino vektoriaus atstovavimu. Kita vertus, santykinis RNN ir CNN pranašumas nebuvo lyginamas. Be to, skirtingos egzamino dalys gali skirtingai prisidėti prie vertinimo, kuris nėra įtrauktas į esamus modelius. Mes sprendžiame šiuos klausimus kuriant hierarchinį sakinių ir dokumentų model į, kuriame būtų atstovaujami esejai, naudojant dėmesio mechanizmą automatiškai nuspręsdami santykinius žodžių ir sakinių svorius. Rezultatai rodo, kad mūsų modelis atitinka ankstesnius moderniausius metodus ir rodo dėmesio mechanizmo veiksmingumą.', 'mk': 'Neural network models have recently been applied to the task of automatic essay scoring, giving promising results.  Existing work used recurrent neural networks and convolutional neural networks to model input essays, giving grades based on a single vector representation of the essay.  On the other hand, the relative advantages of RNNs and CNNs have not been compared.  Покрај тоа, различни делови од есејот можат да придонесат различно за оценката, која не е зафатена од постоечките модели. Ние ги решаваме овие прашања со изградба на хиерархички модел на реченици-документи за претставување на есеи, користејќи го механизмот на внимание за автоматски одлучување на релативната тежина на зборовите и речениците. Резултатите покажуваат дека нашиот модел ги надминува претходните најдобри методи, покажувајќи ја ефикасноста на механизмот на внимание.', 'mn': 'Саяхан мэдрэлийн сүлжээний загварууд автоматик эссийн сүлжээний ажил дээр ашиглан амлалтай үр дүнг өгсөн. Ингээд байгаа ажил дахин дахин сэтгэл зүйн сүлжээ болон сэтгэл зүйн сүлжээг ашиглаж, эсийн нэг векторын үзүүлэлт дээр дүн гаргаж ирсэн. Нөгөө талаар, RNN болон CNN-ийн харьцангуй талаар харьцуулагдаагүй. Үүнээс гадна эссийн өөр хэсгүүд нь суурь загвараар баригдаагүй сүлжээнд өөр өөрчлөлт хийж чадна. Бид эдгээр асуудлуудыг илэрхийлдэг үг болон өгүүлбэрүүдийн харьцаа хэмжээг автоматаар шийдвэрлэх боломжтой анхаарлын механизмийг ашиглаж байдаг. Үүний үр дүнд бидний загвар өмнөх урлагийн үйл ажиллагааны үйл ажиллагааг гаргаж, анхаарлын механизмийн үр дүнг үзүүлдэг.', 'ro': 'Modelele de rețea neurală au fost recent aplicate sarcinii de punctare automată a eseurilor, oferind rezultate promițătoare. Lucrările existente au folosit rețele neurale recurente și rețele neurale convoluționale pentru a modela eseurile de intrare, oferind note bazate pe o reprezentare vectorială unică a eseului. Pe de altă parte, avantajele relative ale RNN și CNN nu au fost comparate. În plus, diferite părți ale eseului pot contribui diferit la punctaj, care nu este capturat de modelele existente. Rezolvăm aceste probleme prin construirea unui model ierarhic de propoziție-document pentru a reprezenta eseurile, folosind mecanismul atenției pentru a decide automat greutatea relativă a cuvintelor și propozițiilor. Rezultatele arată că modelul nostru depășește metodele anterioare de ultimă generație, demonstrând eficiența mecanismului de atenție.', 'pl': 'Modele sieci neuronowych zostały ostatnio zastosowane do zadania automatycznego punktowania esejów, dając obiecujące rezultaty. Dotychczasowe prace wykorzystywały powtarzające się sieci neuronowe i konwolucyjne sieci neuronowe do modelowania esejów wejściowych, nadając oceny oparte na pojedynczej reprezentacji wektorowej eseju. Z drugiej strony nie porównano względnych zalet RNN i CNN. Ponadto różne części eseju mogą różnie przyczynić się do punktowania, co nie jest uchwycone przez istniejące modele. Rozwiązujemy te problemy, budując hierarchiczny model zdań-dokumentów reprezentujący eseje, wykorzystując mechanizm uwagi do automatycznego decydowania o względnej wadze słów i zdań. Wyniki pokazują, że nasz model przewyższa poprzednie najnowocześniejsze metody, co pokazuje skuteczność mechanizmu uwagi.', 'so': "Tusaalada shabakadda naadiga ah ee ugu dhowaad waxaa loo codsaday shaqo jimicsiga iskuulka ah oo lagu siinayo resulto ballan leh. Shaqada joogtada ah waxaa lagu isticmaalay shabakado neurada oo soo socda iyo shabakada neurada oo si qasab ah u sameynta fasalka input, wuxuuna fasalka ku saleysan yahay qaab keliya oo ku qoran qorshaha. Hada kale, faa'iidada qaraabada ah ee RNNs iyo CNNNs lama simin. Intaas waxaa dheer in qeybo kala duduwan oo jimicsiga lagu qaban karo, kaas oo aan lagu qabsan samooyin heysta. Waxaannu arrimahan ku sheekeynaynaa dhisidda muusikada qoraalka hierarkiisa si aan u represento fasaxyada, waxaynu isticmaalnaa meymisyo booqashada si aan u go’aanno miisaanka hadalka iyo erayada qaraabada. Results show that our model outperforms the previous state-of-the-art methods, demonstrating the effectiveness of the attention mechanism.", 'sv': 'Neurala nätverksmodeller har nyligen tillämpats på uppgiften med automatisk uppsatspoäng, vilket ger lovande resultat. Befintligt arbete använde sig av återkommande neurala nätverk och konvulutionella neurala nätverk för att modellera inputuppsatser, vilket gav betyg baserat på en enda vektor representation av uppsatsen. Å andra sidan har de relativa fördelarna med RNN och CNN inte jämförts. Dessutom kan olika delar av uppsatsen bidra olika till poängsättning, vilket inte fångas upp av befintliga modeller. Vi tar itu med dessa frågor genom att bygga en hierarkisk mening-dokumentmodell för att representera uppsatser, använda uppmärksamhetsmekanismen för att automatiskt bestämma den relativa vikten av ord och meningar. Resultaten visar att vår modell överträffar de tidigare toppmoderna metoderna, vilket visar effektiviteten hos uppmärksamhetsmekanismen.', 'sr': 'Neuralne mrežne modele nedavno su primjenjene na zadatak automatskog izvlačenja eseja, dajući obećavajuće rezultate. Postojeći rad koristi rekonstruirane neuralne mreže i konvolucionalne neuralne mreže za modele ulaznih eseja, dajući ocene na temelju jednog vektora zastupanja eseja. S druge strane, relativne prednosti RNN i CNN nisu uspoređene. Osim toga, različiti dijelovi eseja mogu doprinijeti drugačije za izvlačenje, koje ne uhvate postojeći modeli. Mi rješavamo te probleme izgradnjem hijerarhijskog model a rečenica za predstavljanje eseja, koristeći mehanizam pažnje da automatski odlučimo relativne težine riječi i rečenica. Rezultati pokazuju da naš model iznosi prethodne metode umjetnosti, pokazujući učinkovitost mehanizma pažnje.', 'ta': 'புதிய வலைப்பின்னல் மாதிரிகள் சமீபத்தில் தானியங்கி வாய்ப்பு மதிப்பு செய்யும் பணிக்கு பயன்படுத்தப்பட்டுள்ளது,  தற்போதைய வேலை திரும்ப நெருக்கிய வலைப்பின்னல்கள் மற்றும் சாதாரண புதிய பிணையத்தின் வலைப்பின்னல்களை மாதிரி உள்ளீட்டு விளிம்பு மற்றொரு பக்கத்தில், RNNs மற்றும் CNNNகளின் சார்ந்த பயன்பாடுகள் ஒப்பிடுவதில்லை. கூடுதலாக, வித்தியாசமான பாகங்கள் மதிப்பெண்களுக்கு வேறு பகுதிகள் பங்கு செய்யலாம், அது ஏற்கனவே இருக்கும் மாதிர நாம் இந்த பிரச்சனைகளை தேர்ந்தெடுத்து வாக்கியங்களை குறிப்பிட வேண்டிய வாக்கு- ஆவண மாதிரி உருவாக்குவதற்கு, தானாகவே வார்த்தைகள முடிவுகள் எங்கள் மாதிரி முந்தைய நிலையில் கலை முறைகளை வெளியேற்றுகிறது, கவனத்தின் முறைமையின் விளைவை காட்டுகிறது.', 'si': 'ස්වයංක්\u200dරිය ස්කෝරින්ග් වැඩේ ස්වයංක්\u200dරියාවක් නිර්මාණ ජාලය මොඩේල් අවස්ථාවක් වෙලා තියෙ ඉතින් ඉතින් වැඩේ ප්\u200dරතික්\u200dරියාත්මක න්\u200dයුරෝල ජාලය සහ සම්පූර්ණ න්\u200dයුරෝල ජාලය සඳහා ප්\u200dරතික්\u200dරියාත්මක විදියට ප අනිත් පැත්තෙන්, RNN සහ CNN ගැන සම්බන්ධ ප්\u200dරයෝජනයක් තියෙන්නේ නෑ. ඒ වගේම, වෙනස් කොටස් වලින් ස්කෝරින්ගේ වෙනස් ක්\u200dරමයක් වෙනස් වෙනස් වෙනුවෙන් සදහන් කරන්න පුළුවන්, ඒ අපි මේ ප්\u200dරශ්නයක් විශ්වාස කරනවා වචන සහ වාක්ෂාවක් නිර්මාණය කරන්න, ස්වයංක්\u200dරීය විශ්වාස කරන්න, ස්වයංක්\u200dරීය විශ්වා ප්\u200dරතිචාරය පෙන්වන්නේ අපේ මොඩල් ප්\u200dරතිචාරය ප්\u200dරතිචාරයක් ප්\u200dරතිචාරය කරන්න පුරාවන් විදිහට ප්\u200dරතිචාරය', 'ur': 'نیورال نیٹ ورک موڈل اچھے وقت اپنا سس سکونگ کے کام پر لازم کیا گیا ہے، وعدہ دینے والے نتائج دینے کے لئے۔ موجود عمل کے لئے دوبارہ نیورل نیٹورل نیٹورک اور کنویروشن نیورل نیٹورک استعمال کئے گئے ہیں، اسے ایک ویکتور کی نمایش پر گرڈ دیتے ہیں. دوسری طرف، RNN اور CNN کے مقابلہ فائدے مقابلہ نہیں کیے گئے۔ اور اس کے مختلف ٹکڑے اسکینگ کے لئے مختلف طریقے سے اضافہ کر سکتے ہیں، جو موجود مدل کے ذریعہ نہیں پکڑے جاتے۔ ہم اس مسئلہ کو اپنا معاملہ بناتے ہیں کہ اسے دکھانے کے لئے ایک حکومت سند مدل بناتے ہیں، لفظوں اور جماعتوں کی نسبت وزن کا فیصلہ کرنا چاہتے ہیں. نتیجے دکھاتے ہیں کہ ہمارا موڈل پہلے کی حالت آرتی کی طریقے سے کام لیتا ہے، جس سے توجه کی مکانیسم کی تابعداری دکھاتا ہے.', 'uz': "Yaqinda yangi tarmoq modellari avtomatik essay qiymatiga qoʻllanilgan va kutilgan natijalarni koʻrsatish. Name Boshqa bir tomonda, qo'shimcha RNNs va CNNNs uchun foydalanuvchiga tenglanmagan. Koʻrsatgich, sahifa boshqa qismlarini boshqa qiymatga qoʻllash mumkin. Bu mavjud modellar tomonidan qabul qilmagan. Biz bu muammolarni o'xshash tilini represent qilish uchun hierarchical sentence-ҳужжат modeli yaratish bilan boshqaramiz, va o'z soʻzlar va maxfiy soʻzlarni avtomatik avtomatik avtomatik o'zgartirish imkoniyatlaridan foydalanamiz. Natijalar esa, bizning modelimiz oldingi holatning sohasi usullarini ko'rsatadi, foydalanish mechanisining effektligini ko'rsatadi.", 'vi': 'Các mô hình thần kinh mạng gần đây được áp dụng cho nhiệm vụ đánh giá bằng văn bản tự động, cung cấp kết quả hứa hẹn. Việc tồn tại đã sử dụng các mạng thần kinh liên tục và kết nối dây thần kinh để mô hình các bài luận nhập, đưa ra các điểm dựa trên một trình tự duy nhất của bài luận. Mặt khác, các ưu điểm tương đối của RNN và CNN không được so sánh. Thêm vào đó, các phần khác nhau của bài luận có thể đóng góp khác nhau để ghi điểm, mà không được ghi bởi các mô hình đã có. Chúng ta giải quyết các vấn đề này bằng cách tạo ra một mô hình văn bản phân cấp để đại diện các bài văn, sử dụng cơ chế chú ý để tự động quyết định các trọng lượng của từ và câu. Kết quả cho thấy mẫu của chúng ta hoàn thiện phương pháp hiện đại trước đây, minh chứng hiệu quả của cơ chế tập trung.', 'bg': 'Моделите на невралната мрежа наскоро бяха приложени към задачата за автоматично оценяване на есе, давайки обещаващи резултати. Съществуващата работа използва повтарящи се невронни мрежи и конволюционни невронни мрежи за моделиране на входни есета, давайки оценки въз основа на едно векторно представяне на есето. От друга страна, относителните предимства на RNN и CNN не са сравнени. Освен това различните части от есето могат да допринесат различно за оценката, която не е уловена от съществуващите модели. Ние решаваме тези въпроси чрез изграждане на йерархичен модел изречение-документ за представяне на есета, използвайки механизма на вниманието за автоматично определяне на относителното тегло на думите и изреченията. Резултатите показват, че нашият модел превъзхожда предишните съвременни методи, демонстрирайки ефективността на механизма за внимание.', 'hr': 'Neuralne mrežne modele nedavno su primjenjene na zadatak automatskog izvlačenja eseja, dajući obećavajuće rezultate. Postojeći rad koristi rekonstruirane neuralne mreže i konvolucionalne neuralne mreže za model ulaznih eseja, dajući ocjene na temelju jednog vektora zastupanja eseja. S druge strane, relativne prednosti RNN-a i CNN-a nisu uspoređene. Osim toga, različiti dijelovi eseja mogu doprinijeti drugačije za izvlačenje, koje ne uhvate postojeći modeli. Mi rješavamo te probleme izgradnjem hijerarhičkog model a kazne za predstavljanje eseja, koristeći mehanizam pažnje za automatski odlučivanje relativne težine riječi i kazne. Rezultati pokazuju da naš model iznosi prethodne metode umjetnosti, pokazujući učinkovitost mehanizma pažnje.', 'nl': "Neurale netwerkmodellen zijn onlangs toegepast op de taak van automatische essay scoren, wat veelbelovende resultaten oplevert. Bestaand werk gebruikte terugkerende neurale netwerken en convolutionele neurale netwerken om input essays te modelleren, waarbij cijfers werden gegeven op basis van een enkele vectorrepresentatie van het essay. Aan de andere kant zijn de relatieve voordelen van RNN's en CNN's niet vergeleken. Daarnaast kunnen verschillende delen van het essay verschillend bijdragen aan scoren, wat niet wordt vastgelegd door bestaande modellen. We pakken deze problemen aan door een hiërarchisch zin-document model te bouwen om essays weer te geven, waarbij we het aandachtsmechanisme gebruiken om automatisch de relatieve gewichten van woorden en zinnen te bepalen. De resultaten tonen aan dat ons model de vorige state-of-the-art methoden overtreft, wat de effectiviteit van het aandachtsmechanisme aantoont.", 'da': "Neurale netværksmodeller er for nylig blevet anvendt til opgaven med automatisk essay scoring, hvilket giver lovende resultater. Eksisterende arbejde brugte tilbagevendende neurale netværk og konvulutionelle neurale netværk til at modellere input essays, der gav karakterer baseret på en enkelt vektor repræsentation af essayen. På den anden side er de relative fordele ved RNN'er og CNN'er ikke blevet sammenlignet. Derudover kan forskellige dele af essayen bidrage forskelligt til scoring, som ikke er fanget af eksisterende modeller. Vi løser disse problemer ved at opbygge en hierarkisk sætning-dokumentmodel til at repræsentere essays, ved hjælp af opmærksomhedsmekanismen til automatisk at bestemme den relative vægt af ord og sætninger. Resultaterne viser, at vores model overgår de tidligere state-of-the-art metoder, hvilket viser effektiviteten af opmærksomhedsmekanismen.", 'de': 'Neurale Netzwerkmodelle wurden kürzlich auf die Aufgabe der automatischen Aufsatzbewertung angewendet und liefern vielversprechende Ergebnisse. Bestehende Arbeiten nutzten wiederkehrende neuronale Netze und convolutionale neuronale Netze, um Eingabeessays zu modellieren, wobei Noten basierend auf einer einzigen Vektorrepräsentation des Aufsatzes gegeben wurden. Andererseits wurden die relativen Vorteile von RNNs und CNNs nicht verglichen. Darüber hinaus können verschiedene Teile des Aufsatzes unterschiedlich zum Scoring beitragen, was von bestehenden Modellen nicht erfasst wird. Wir adressieren diese Probleme, indem wir ein hierarchisches Satz-Dokument-Modell zur Darstellung von Essays aufbauen und den Aufmerksamkeitsmechanismus verwenden, um automatisch die relativen Gewichte von Wörtern und Sätzen zu bestimmen. Die Ergebnisse zeigen, dass unser Modell die bisherigen State-of-the-Art Methoden übertrifft und die Wirksamkeit des Aufmerksamkeitsmechanismus demonstriert.', 'ko': '최근 신경 네트워크 모델이 자동 논문 채점 임무에 활용돼 고무적인 결과를 얻었다.기존의 작업은 귀속신경망과 권적신경망을 이용하여 입력문장을 모델링하고 문장의 단일 벡터에 따라 점수를 표시한다.한편, RNN과 CNN의 상대적 우위는 아직 비교되지 않았다.이 밖에 문장의 각 부분이 평점에 기여하는 것도 다르기 때문에 기존 모델에서는 포착할 수 없다.우리는 차원화된 문장 문서 모델을 구축하여 문장을 나타내고 주의 메커니즘을 이용하여 단어와 문장의 상대적인 중요성을 자동으로 확정하여 이런 문제들을 해결한다.결과에 의하면 우리의 모델은 이전의 가장 선진적인 방법보다 우수하고 주의 메커니즘의 유효성을 증명했다.', 'id': 'Neural network models have recently been applied to the task of automatic essay scoring, giving promising results.  Pekerjaan yang ada digunakan jaringan saraf berkurang dan jaringan saraf konvolusi untuk model esai masukan, memberikan nilai berdasarkan representation vektor tunggal dari esai. Di sisi lain, keuntungan relatif RNN dan CNN belum dibandingkan. Selain itu, bagian-bagian yang berbeda dari esei dapat berkontribusi berbeda untuk skor, yang tidak ditangkap oleh model yang ada. Kami mengatasi masalah ini dengan membangun model kalimat-dokumen hierarkis untuk mewakili esei, menggunakan mekanisme perhatian untuk secara otomatis memutuskan berat relatif kalimat dan kalimat. Hasil menunjukkan bahwa model kita melampaui metode terbaik sebelumnya, menunjukkan efektivitas mekanisme perhatian.', 'fa': 'مدلهای شبکه عصبی اخیراً به وظیفه\u200cی آزمایش آزمایش\u200cبندی خودکار، به عنوان نتیجه\u200cهای قول\u200cدهنده کاربرد شده\u200cاند. کار موجود از شبکه\u200cهای عصبی تکرار و شبکه\u200cهای عصبی متعادلانه برای مدل رسی\u200cهای وارد شدن استفاده می\u200cشود، که درجه\u200cها بر اساس نمایش یک واکتور از رسی است. از طرف دیگر، منافع نسبت به RNN و CNN مقایسه نشده است. علاوه بر این، قسمت های مختلف از صحنه می توانند به طور مختلف برای جستجویی که توسط مدل های موجود حاضر نیستند کمک کنند. ما این مسائل را با ساختن یک مدل سند جمله\u200cهای طبیعی برای نمایش رسی\u200cها با استفاده از مکانیسم توجه برای تصمیم گرفتن وزن نسبت به کلمات و جمله\u200cها به خودکار حل می\u200cکنیم. نتیجه\u200cها نشان می\u200cدهند که مدل ما روش\u200cهای اولین هنری را انجام می\u200cدهد، که نشان می\u200cدهد موثیت مکانیسم توجه را نشان می\u200cدهد.', 'tr': "Näyral şebeke nusgalary otomatik eser ýazmasynyň täblisasine uygulanýar, söz berýän netijesi berilýär. Eskiden çalışma tekrarlı nöral a ğları ve konvolusyonal nöral ağları giriş eserlerini modellemek için kullanıldı ve sıralar tek vektöre dayanan ders verildi. Diňe görä, RNN we CNN'yň relative ösümlikleri deňleşdirilmedi. Ynsada, esesiň dürli bölekleri scoring üçin başga bir şekilde kömekleyebilir. Ol bar modeller tarapyndan alyp bilmeýär. Biz bu meseleleri yerarşiw sened modelini eserleri temsil etmek üçin çözerek, üns meýdançasyny otomatik olarak sözlerin we sözlerin miňlap netijesini çözmek üçin çözerek çözeriz. Netijenler biziň nusgamyzyň öňki möhüm taýýarlaryň üstüne çykyp bardygyny görkezýär.", 'sw': 'Mradi wa mitandao ya kijamii hivi karibuni umetumiwa katika kazi ya kuchukua kurasa za fasihi za kujitegemea, na kutoa matokeo yanayoahidi. Kazi ya sasa imetumia mitandao ya neura yanayoendelea na mitandao ya taratibu ya taratibu ya kitaalamu ili kutengeneza masomo ya maandishi, na kutoa darasa kwa msingi wa uwakilishaji wa mswada huo mmoja. On the other hand, the relative advantages of RNNs and CNNs have not been compared.  Zaidi ya hayo, sehemu mbalimbali za maandiko yanaweza kuchangia tofauti kwa kuchukua michezo, ambayo haijakamatwa na mifano iliyopo. Tunaongelea masuala haya kwa kutengeneza muundo wa hukumu-nyaraka wa kiuchunguzi ili kuwakilisha masomo, kwa kutumia mfumo wa ufuatiliaji kuamua kwa uhuru wa mizani ya maneno na hukumu. Matokeo yanaonyesha kwamba mifano yetu inaonyesha njia za awali za sanaa, inayoonyesha ufanisi wa mfumo wa ufuatiliaji.', 'af': "Nurale netwerk modele is onlangs toegewend na die taak van outomatiese essay skoring, gegee beloftende resultate. Bestaande werk gebruik word herhaalde neuralnetwerke en konvolusionele neuralnetwerke na model invoer essye, gegee grade gebaseer op 'n enkele vektor voorstelling van die essay. Op die ander hand, die relatiewe voordeel van RNN en CNN is nie vergelyk nie. In addition, different parts of the essay can contribute differently for scoring, which is not captured by existing models. Ons adreseer hierdie probleme deur 'n hierarkies setdokument-model te bou om essays te verteenwoordig, gebruik die aandagmekanisme om outomaties die relatiewe weegte van woorde en setnings te besluit. Resultate wys dat ons model die vorige state-of-the-art metodes uitvoer, wat die effektiviteit van die aandagmekanisme vertoon.", 'hy': 'Նյարդային ցանցի մոդելները վերջերս կիրառվել են ավտոմատիկ էսսերի գնահատման խնդրի վրա, որն առաջարկում է խոստացող արդյունքներ: Գոյություն ունեցող աշխատանքը օգտագործում էր կրկնօրինակ նյարդային ցանցեր և կոնվոլյուցիոն նյարդային ցանցեր մուտքագրման էսսերի մոդելավորման համար, տալով գնահատականներ, հիմնված էսսերի մեկ վեկտորի ներկայացման Մյուս կողմից, ՌՆԹ-ների և ՍՆԹ-ների հարաբերական առավելությունները չեն համեմատել: Ավելին, էսեյի տարբեր մասերը կարող են այլ կերպ ներդրվել գնահատման համար, ինչը գոյություն ունի մոդելներ: Մենք լուծում ենք այս խնդիրները ստեղծելով հիերարխիկ նախադասություն-փաստաթղթի մոդել, որը ներկայացնում է էսսերը, օգտագործելով ուշադրության մեխանիզմը, որպեսզի ինքնաբերաբար որոշենք բառերի և նախադասությունների Արդյունքները ցույց են տալիս, որ մեր մոդելը գերազանցում է նախորդ բարձրագույն մեթոդները, ցույց տալով ուշադրության մեխանիզմի արդյունավետությունը:', 'am': 'የውጤት መረብ ሞዴላዎች በቅርብ ጊዜ የተስፋ ውጤቶች ሲሰጡ በራሱ የሲሳይ ጉዳይ ላይ ተጠቃሚ ናቸው፡፡ Existing work used recurrent neural networks and convolutional neural networks to model input essays, giving grades based on a single vector representation of the essay.  በሌላው ወገን የRNN እና CNN ጥቅማቸው አልተተካከሉም፡፡ በተጨማሪም፣ የጉዳዩ ክፍሎች በተለየ ለመቆጣጠር ይችላል፡፡ እነዚህንም ጉዳዮች የቅርብ ቃላት እና የቃላት ሚዛኖችን በራስነት ለመፍጠር እናስረዳለን፡፡ ፍጥረቶቹ ሞዴሌያችን የቀድሞውን የዓላማ ሥርዓት እና የጥያቄውን አካባቢ ማሳየት ነው፡፡', 'sq': 'Modelet e rrjetit nervor janë aplikuar kohët e fundit në detyrën e shënimit automatik të eseve, duke dhënë rezultate premtuese. Puna ekzistuese përdori rrjete neurale të përsëritura dhe rrjete neurale konvolutive për të modeluar esej të hyrjes, duke dhënë grada bazuar në një përfaqësim vektor të vetëm të esejës. Nga ana tjetër, avantazhet relative të RNN dhe CNN nuk janë krahasuar. Përveç kësaj, pjesë të ndryshme të esejës mund të kontribuojnë ndryshe për pikëpamjen, e cila nuk kapet nga modelet ekzistuese. Ne i trajtojmë këto çështje duke ndërtuar një model hierarkik fjalë-dokument për të përfaqësuar esejat, duke përdorur mekanizmin e vëmendjes për të vendosur automatikisht peshat relative të fjalëve dhe fjalëve. Rezultatet tregojnë se modeli ynë përmirëson metodat e mëparshme të state-of-the-art, duke demonstruar efektshmërinë e mekanizmit të vëmendjes.', 'bn': 'সম্প্রতি নিউরেল নেটওয়ার্ক মডেল স্বয়ংক্রিয়ভাবে প্রতিশ্রুত ফলাফল প্রদান করা হয়েছে। বর্তমান কাজ ব্যবহার করা হয়েছে পুনরায় নিউরেল নেটওয়ার্ক এবং নির্ভরিত নিউরেল নেটওয়ার্ক, যারা এই প্রবন্ধের এক ভেক্টরের প্রতিনিধিত্বে ভিত্ অন্যদিকে আরএনএন এবং সিএনএন-এর আত্মিক সুবিধা তুলনা করা হয়নি। এছাড়াও এই প্রবন্ধের বিভিন্ন অংশ স্কোরের জন্য ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন অংশ যোগ দিতে পারে, যা বর্তমান ম আমরা এই বিষয়গুলোকে নিয়ে আলোচনা করি শিরোনামের প্রতিনিধিত্বের জন্য একটি হিয়ারারাক্তিক শাস্তি-নথি মডেল নির্মাণের মাধ্যমে। ফলাফল দেখা যাচ্ছে যে আমাদের মডেল পূর্ববর্তী শিল্পের রাষ্ট্রের পদ্ধতিতে প্রকাশ করে, যেখানে মনোযোগ মেক্সিমের কার্যকর', 'az': 'Nöral ağ modelləri yenidən avtomatik essay scoring işinə uyğunlaşdırılmışdır, söz verici sonuçlar verir. Əvvəlki işlər yenidən nöral a ğları və konvolucional nöral ağları, hesabın tək vektorun göstərilməsinə dayanan sıralar modellərə istifadə edir. Digər tərəfindən, RNN və CNN qohum mənfəətləri ilə müqayisədə edilməmişdir. Əvvəlcə, essay ın müxtəlif parçaları, həmin modellərdən alınmadığı scoring üçün fərqli olaraq kömək edə bilər. Biz bu məsələləri hiyerarşik cümlələr modeli inşa edirik ki, essayları göstərmək üçün, məlumat mehanizmisini avtomatik olaraq sözlərin və cümlələrin relatif a ğırlığını qərar etmək üçün istifadə edirik. Sonuçlarımız modellərimizin əvvəlki sanat metodlarını göstərməsini göstərər, məlumat mehanizmisinin etkinliğini göstərər.', 'ca': "Recentment s'han aplicat models de xarxa neuronal a la tasca de puntuació automàtica d'essays, donant resultats prometedors. Els treballs existents van utilitzar xarxes neurals recurrents i xarxes neurals convolucionals per modelar essais d'entrada, donant notes basades en una representació per un únic vector de l'essai. D'altra banda, no s'han comparat les avantatges relativas dels RN i dels CNN. A més, diferents parts de l'assaig poden contribuir de manera diferent a la puntuació, que no es captura pels models existents. Ens ocupem d'aquestes qüestions construint un model jeràrquic de frases-documents per representar els assaig, utilitzant el mecanisme d'atenció per decidir automàticament els pes relativs de paraules i frases. Els resultats mostren que el nostre model supera els mètodes més avançats anteriors, demostrant l'eficacia del mecanisme d'atenció.", 'cs': 'Neurální síťové modely byly v poslední době aplikovány na úkol automatického bodování esejů, které poskytují slibné výsledky. Stávající práce využívala recidivující neuronové sítě a konvoluční neuronové sítě k modelování vstupních esejí a poskytovala známky založené na jediném vektorovém reprezentaci eseje. Na druhou stranu nebyly srovnány relativní výhody RNN a CNN. Kromě toho mohou různé části eseje přispět různě k bodování, které není zachyceno existujícími modely. Tyto problémy řešíme vytvořením hierarchického modelu vět-dokumentů, který reprezentuje eseje, pomocí mechanismu pozornosti automaticky rozhoduje relativní hmotnost slov a vět. Výsledky ukazují, že náš model překonává předchozí nejmodernější metody, což dokazuje účinnost mechanismu pozornosti.', 'bs': 'Neuralne mreže modele nedavno su primjenjene na zadatak automatskog izvlačenja eseja, dajući obećavajuće rezultate. Postojeći rad koristi rekonstruirane neuralne mreže i konvolucione neuralne mreže za modele eseja ulaska, dajući ocjene na temelju jednog vektora zastupanja eseja. S druge strane, relativne prednosti RNN-a i CNN-a nisu uspoređene. Osim toga, različiti dijelovi eseja mogu doprinijeti drugačije za izvlačenje, koje ne uhvate postojeći modeli. Mi rješavamo te probleme izgradnjem hijerarhijskog model a kazne za predstavljanje eseja, koristeći mehanizam pažnje da automatski odlučimo relativne težine riječi i kazne. Rezultati pokazuju da naš model iznosi prethodne metode umjetnosti, pokazujući učinkovitost mehanizma pažnje.', 'et': 'Hiljuti on neurovõrgu mudeleid rakendatud automaatse essee skoorimise ülesandeks, andes paljulubavaid tulemusi. Olemasolevad tööd kasutasid sisendesseede modelleerimiseks korduvaid närvivõrke ja konvolutsioonivõrke, andes essee ühe vektori esituse alusel hindeid. Teisest küljest ei ole RNN ja CNN suhtelisi eeliseid võrreldatud. Lisaks võivad essee erinevad osad hindamisele erinevalt kaasa aidata, mida olemasolevad mudelid ei hõlma. Nende probleemide lahendamiseks ehitame esseede esindamiseks hierarhilise lause-dokumendi mudeli, kasutades tähelepanumehhanismi sõnade ja lausete suhtelise kaalu automaatseks otsustamiseks. Tulemused näitavad, et meie mudel ületab varasemaid kaasaegseid meetodeid, näidates tähelepanumehhanismi efektiivsust.', 'fi': 'Neuroverkostomalleja on hiljattain sovellettu automaattiseen esseen pisteytykseen, mikä antaa lupaavia tuloksia. Olemassa olevassa työssä käytettiin toistuvia neuroverkkoja ja konvolutionaalisia neuroverkkoja syöttöesseiden mallintamiseen ja annettiin arvosanoja yhden vektorin esitykseen perustuen. Toisaalta RNN:ien ja CNN:ien suhteellisia etuja ei ole verrattu. Lisäksi esseen eri osat voivat vaikuttaa eri tavoin pisteytykseen, jota ei oteta huomioon olemassa olevissa malleissa. Käsittelemme näitä kysymyksiä rakentamalla esseitä edustavan hierarkkisen lause-dokumenttimallin, jossa huomiomekanismin avulla päätetään automaattisesti sanojen ja lauseiden suhteellinen paino. Tulokset osoittavat, että mallimme suoriutuu edellisistä uusimmista menetelmistä ja osoittaa huomiomekanismin tehokkuuden.', 'jv': 'Sample rate Sayensi Bilih pangrung liya, dibutuhé perusahaan ning DNN karo KNN ora bisa digawe. Nambah, pating sampeyan essay sing bisa kontribusi panggon sampeyan kanggo nguasar Awak dhéwé éntuk perbudhakan iki dadi nggawe model kuwi nggawe gerakan karo tentang, nambah aturan awak dhéwé nggawe ngubah dhéwé kuwi nggawe ngubah aturan awak dhéwé lan kelangan kuwi mau. Mehola sing ngomong nambah modellu kuwi nggawe barang kelas nang sampek parat-karat sing ngendalikno ngono nggawe barang seneng pisan neng sistem sing nggawe gerarané.', 'sk': 'Modeli živčnih omrežij so bili pred kratkim uporabljeni za nalogo avtomatskega ocenjevanja esejev, kar daje obetavne rezultate. Obstoječe delo je uporabljalo ponavljajoče se nevronske mreže in konvolucijske nevronske mreže za modeliranje vhodnih esejev, pri čemer so ocene podali na podlagi ene same vektorske reprezentacije eseja. Po drugi strani pa relativne prednosti RNN in CNN niso primerjali. Poleg tega lahko različni deli eseja drugače prispevajo k ocenjevanju, ki ga obstoječi modeli ne zajemajo. Ta vprašanja rešujemo z oblikovanjem hierarhičnega modela stavkov-dokumenta, ki predstavlja eseje, s pomočjo mehanizma pozornosti pa samodejno določamo relativno težo besed in stavkov. Rezultati kažejo, da naš model presega prejšnje najsodobnejše metode, kar dokazuje učinkovitost mehanizma pozornosti.', 'he': 'דוגמני רשת נוירולית הופעו לאחרונה למשימה של ציוני מבחן אוטומטי, נותנים תוצאות מבטיחות. עבודה קיימת משתמשת ברשתות עצביות חוזרות ורשתות עצביות משתנות כדי לדוגמא מאמרים כניסה, נותנת ציונים מבוססים על ייצוג ווקטור אחד של המאמר. מצד שני, היתרונות יחסיות של RNN ו CNN לא שוואות. בנוסף, חלקים שונים של המאמר יכולים לתרום בצורה שונה לנקודת הציוד, אשר לא נתפס על ידי דוגמנים קיימים. אנחנו מתמודדים עם הנושאים האלה על ידי בניית דוגמנית משפט-מסמך היררכית כדי לייצג מאמרים, בשימוש במנגנון תשומת לב כדי להחליט באופן אוטומטי את משקלי המילים והמשפטים יחסיים. התוצאות מראות שהמודל שלנו מוביל את השיטות הקודמות של המצב האמנותי, להוכיח את היעילות של מנגנון תשומת לב.', 'ha': "@ action: button Yi amfani da aikin da ke iya lissafa tsarin neural da tsarin neural da wanda ya mutu ya samu'a cikin tsarin ayuka, yana bãyar da darajõji a kan karatun guda mai nuna wa littafin. Ga da wani, ma'anar danganiya na amfani da RNNs da CNNNs ba a daidaita. Da wannan, rabo dabam-daban littafi na iya ƙara yin wani daban wa kwanan matsayi, wanda ba a kãma shi ba na da misãlai da ke gaba. Munã jãyayya masu wannan da ke samun ka gina wani misali na takardar-rubutu na hierrarci dõmin ya wakilishi littãfi, da amfani da alama na kiyaye masu nauyi na maganar da muhimmanci. Matarin ya nuna cewa misalinmu yana samar da metoden-halin na-sanar ta gaba, kuma yana nuna tayari na muhimmin muhimmanci.", 'bo': 'རང་འགུལ་གྱིས་ཞིབ་བཤེར་གྱི་ལས་འགུལ་ལ་ཉེ་ཆར་སུ་འཇུག་ཡོད་པ་ལས་སྦྱོར་བརྟན་དགོས་པ Existing work used recurrent neural networks and convolutional neural networks to model input essays, giving grades based on a vector representation of the essay. ཕྱོགས་གཞན་ཞིག་ནས་RNNs དང་CNNs་ཚོའི་མཐུན་རྐྱེན་གྱི་སྲོལ་ཚུལ་འདྲ་ཡིན་མེད། ཞིབ་བཤེར་གྱི་ཆ་ཤས་མ་འདྲ་བ་དེ་ཁྱད་དུ་སྙིགས་སྣོད་ནང་སྤྱོད་པར་གཞན་དང་མི་འདུག ང་ཚོས་དབྱིབས་ཡུལ་གྱི་ཚིག གྲུབ་འབྲས་བྱིས་ང་ཚོའི་མ་དབྱིབས་སྔོན་གྱི་གནས་སྟངས་གཙོ་བྱེད་ཀྱི་ཐབས་ལམ་ལ་ཕན་ཐོན་བྱེད་མི་འདུག་པས།'}
{'en': 'Feature Selection as Causal Inference : Experiments with Text Classification', 'ar': 'اختيار الميزة كاستدلال سببي: تجارب مع تصنيف النص', 'pt': 'Seleção de recursos como inferência causal: experimentos com classificação de texto', 'es': 'Selección de características como inferencia causal: experimentos con clasificación de texto', 'fr': 'Sélection de caractéristiques comme inférence causale\xa0: expériences avec classification de texte', 'ja': '原因推論としての特徴選択：テキスト分類の実験', 'zh': '为因果推理特征选择:文本分类实验', 'hi': 'कारण अनुमान के रूप में सुविधा चयन: पाठ वर्गीकरण के साथ प्रयोग', 'ru': 'Выбор признаков в качестве причинно-следственной связи: эксперименты с классификацией текста', 'ga': 'Roghnú Gné mar Thástáil Chúis: Turgnaimh le hAicmiú Téacs', 'ka': 'ფექტურის არჩევა, როგორც შესაძლებლობის განსხვავება: ტექსტის კლასიფიკაციის экспеპერიმენტები', 'el': 'Επιλογή χαρακτηριστικών ως αιτιολογικό συμπέρασμα: Πειράματα με την ταξινόμηση κειμένου', 'it': 'Selezione delle caratteristiche come inferenza causale: esperimenti con classificazione del testo', 'hu': 'Jellemzők kiválasztása okozati mellékhatásként: kísérletek szövegosztályozással', 'kk': 'Қасиеттерді таңдау үшін таңдау: Мәтін классификациясындағы тәжірибелер', 'mk': 'Форматичен избор како причинна инференција: Експерименти со текстова класификација', 'ml': 'വിശേഷത്തിന്റെ തെരഞ്ഞെടുക്കുന്നതിന്റെ വിശേഷം: പദാവലി ക്ലാസിഷനുമായി പരീക്ഷണങ്ങള്\u200d', 'ms': 'Pilihan Feature sebagai Penyuruh Sebab: Eksperimen dengan Klasifikasi Teks', 'lt': 'Atranka kaip priežastinis nuokrypis: eksperimentai su teksto klasifikacija', 'mt': 'Għażla tal-Karatteristika bħala Inferenza Kawżali: Esperimenti bil-Klassifikazzjoni tat-Test', 'mn': 'Хэрэглэгч сонголт нь шалтгаан шалтгаан: Текст классификацийн туршилт', 'no': 'Utval av funksjonar som avbryting: Eksperimentar med tekstklassifikasjon', 'pl': 'Wybór cech jako wniosek przyczynowy: Eksperymenty z klasyfikacją tekstu', 'ro': 'Selectarea caracteristicilor ca inferență cauzală: Experimente cu clasificarea textului', 'si': 'විශේෂතා තෝරාගන්න ප්\u200dරමාණයක් විශේෂතාවක් වගේ: පාළ ප්\u200dරමාණය සඳහා පරීක්ෂණය', 'sv': 'Funktionsval som orsaksinferens: Experiment med textklassificering', 'ta': 'பயனர் முன்னேற்றமாக தேர்ந்தெடுப்பு: உரை வகைப்படுத்தலுடன் சோதனைகள்', 'so': 'Dalbashada xuquuqda iskuulka ah: Imtixaanka qoraalka', 'sr': 'Izaber karakteristike kao ometanje: eksperimenti sa klasifikacijom teksta', 'ur': 'خصوصی انتخاب کے طور پر قابل تحقیق کے طور پر: تفصیل کلاسیفی کے ساتھ تجربے', 'uz': 'Parametrlar', 'vi': 'Chọn đặc trưng như Liên Minh Nguyên nhân: Thử nghiệm với mức độ Văn bản', 'bg': 'Избор на характеристика като причинно заключение: експерименти с класификация на текста', 'da': 'Valg af egenskaber som årsagssygdom: Eksperimenter med tekstklassifikation', 'nl': 'Selectie van kenmerken als oorzakelijke conclusie: Experimenten met tekstclassificatie', 'hr': 'Izaber karakteristike kao nepoštovanje optužnice: eksperimenti sa klasifikacijom teksta', 'de': 'Feature Selection als kausale Schlussfolgerung: Experimente mit Textklassifikation', 'id': 'Feature Selection as Causal Inference: Experiments with Text Classification', 'ko': '인과 추리의 특징으로 선택: 텍스트 분류 실험', 'fa': 'انتخاب ویژه به عنوان تفاوت بازداشت: تجربه\u200cها با کلاس متن', 'sw': 'Uchaguzi wa Tamko kama Uzuizi wa Usalama: Tatizo na Makala', 'tr': 'Görniş Opşenler Aýratma Saýlaw:', 'sq': 'Zgjidhja e funksionit si Inferencë Kazuale: Eksperimentet me Klasifikimin e Tekstit', 'af': 'Featurekeuse as Causal Inference: Experiments with Text Classification', 'am': 'ምርጫዎች', 'hy': 'Փաստակարգ ընտրությունը որպես պատճառային ինֆերանսներ: Տեքստի դասակարգման փորձեր', 'bn': 'Feature Selection as Causal Inference: Experiments with Text Classification', 'az': '칐zellik Se칞iml톛ri K칬t칲l칲y칲 olaraq: Metin Klasifikasiyy톛si il톛 s캼naqlar', 'bs': 'Izaber karakteristike kao ometanje: eksperimenti sa klasifikacijom teksta', 'ca': 'La selecció de característiques com a inferència causal: experiments amb classificació de text', 'et': 'Funktsioonide valik kui põhjuslik järeldus: eksperimendid teksti klassifitseerimisega', 'cs': 'Výběr prvků jako příčinný závěr: Experimenty s klasifikací textu', 'fi': 'Feature Selection as Causal Inference: Kokeet tekstin luokittelulla', 'jv': 'spoken punctuation', 'he': 'בוחר תכונות כחוסר סיבה: ניסויים עם קליфікаציה טקסטית', 'sk': 'Izbira funkcij kot vzročni sklep: eksperimenti z razvrščanjem besedila', 'ha': 'KCharselect unicode block name', 'bo': 'ཡིག་ཆ་སྒྲིག་འཛུགས་ལ་རང་ཆས་བྱེད་སྟངས་ལ་གདམ་པ། ཡི་གེའི་སྡེར་རིམ་དང་བརྟན་པའི་བརྟག་ཞིབ'}
{'en': 'This paper proposes a matching technique for learning causal associations between word features and class labels in document classification. The goal is to identify more meaningful and generalizable features than with only correlational approaches. Experiments with sentiment classification show that the proposed method identifies interpretable word associations with sentiment and improves classification performance in a majority of cases. The proposed feature selection method is particularly effective when applied to out-of-domain data.', 'es': 'Este artículo propone una técnica de correspondencia para aprender las asociaciones causales entre las características de las palabras y las etiquetas de clase en la clasificación de documentos. El objetivo es identificar características más significativas y generalizables que solo con enfoques correlacionales. Los experimentos con la clasificación de sentimientos muestran que el método propuesto identifica asociaciones de palabras interpretables con sentimiento y mejora el rendimiento de la clasificación en la mayoría de los casos. El método de selección de características propuesto es particularmente eficaz cuando se aplica a datos fuera del dominio.', 'ar': 'تقترح هذه الورقة تقنية مطابقة لتعلم الارتباطات السببية بين سمات الكلمات وتسميات الفئات في تصنيف المستندات. الهدف هو تحديد ميزات أكثر جدوى وقابلة للتعميم من الأساليب الارتباطية فقط. تظهر التجارب مع تصنيف المشاعر أن الطريقة المقترحة تحدد ارتباطات الكلمات القابلة للتفسير مع المشاعر وتحسن أداء التصنيف في غالبية الحالات. طريقة اختيار الميزة المقترحة فعالة بشكل خاص عند تطبيقها على البيانات خارج المجال.', 'fr': "Cet article propose une technique d'appariement pour apprendre les associations causales entre les caractéristiques des mots et les étiquettes de classe dans la classification des documents. L'objectif est d'identifier des caractéristiques plus significatives et généralisables qu'avec des approches uniquement corrélationnelles. Les expériences de classification des sentiments montrent que la méthode proposée identifie les associations de mots interprétables avec le sentiment et améliore les performances de classification dans la majorité des cas. La méthode de sélection de caractéristiques proposée est particulièrement efficace lorsqu'elle est appliquée à des données hors domaine.", 'ja': '本稿では，文書分類における言葉の特徴とクラスラベルとの因果関係を学習するためのマッチング手法を提案する．目標は、相関的アプローチのみを使用するよりも、より有意義で一般化可能な特徴を特定することです。センチメント分類の実験では、提案された方法は、センチメントとの解釈可能な単語の関連性を特定し、大部分のケースで分類のパフォーマンスを向上させることが示されています。提案された特徴選択法は、ドメイン外データに適用する場合に特に有効である。', 'hi': 'यह पेपर दस्तावेज़ वर्गीकरण में शब्द सुविधाओं और वर्ग लेबल के बीच कारण संघों को सीखने के लिए एक मिलान तकनीक का प्रस्ताव करता है। लक्ष्य केवल सहसंबंध दृष्टिकोण की तुलना में अधिक सार्थक और सामान्यीकृत विशेषताओं की पहचान करना है। भावना वर्गीकरण के साथ प्रयोगों से पता चलता है कि प्रस्तावित विधि भावना के साथ व्याख्यायोग्य शब्द संघों की पहचान करती है और अधिकांश मामलों में वर्गीकरण प्रदर्शन में सुधार करती है। प्रस्तावित सुविधा चयन विधि विशेष रूप से प्रभावी है जब आउट-ऑफ-डोमेन डेटा पर लागू किया जाता है।', 'zh': '本文设文档类学单词特徵类标之间,因果关联之术。 所以识别比仅用相关之法更有意义与可推广者也。 情类实验明, 所出法别单词与情连, 多能. 所上特征择法于域外数特效。', 'ga': 'Molann an páipéar seo teicníocht mheaitseála chun naisc chúise a fhoghlaim idir gnéithe focal agus lipéid ranga i rangú doiciméad. Is é an sprioc gnéithe níos bríonna agus níos ginearálaithe a aithint ná le cur chuige comhghaolaithe amháin. Léiríonn turgnaimh le haicmiú sentiment go n-aithníonn an modh atá beartaithe naisc fhocail inmhínithe le meon agus go gcuirtear feabhas ar fheidhmíocht aicmithe i dtromlach na gcásanna. Tá an modh roghnaithe gnéithe atá beartaithe éifeachtach go háirithe nuair a chuirtear i bhfeidhm é ar shonraí lasmuigh den fhearann.', 'ru': 'В настоящей работе предлагается метод сопоставления для изучения причинно-следственных связей между характеристиками слов и метками классов в классификации документов. Цель состоит в том, чтобы выявить более значимые и обобщаемые признаки, чем с помощью только корреляционных подходов. Эксперименты с классификацией сентиментов показывают, что предлагаемый метод идентифицирует интерпретируемые ассоциации слов с сентиментами и улучшает эффективность классификации в большинстве случаев. Предложенный способ выбора признаков особенно эффективен при применении к внедоменным данным.', 'pt': 'Este artigo propõe uma técnica de correspondência para aprender associações causais entre características de palavras e rótulos de classe na classificação de documentos. O objetivo é identificar características mais significativas e generalizáveis do que apenas com abordagens correlacionais. Experimentos com classificação de sentimento mostram que o método proposto identifica associações de palavras interpretáveis com sentimento e melhora o desempenho da classificação na maioria dos casos. O método de seleção de características proposto é particularmente eficaz quando aplicado a dados fora do domínio.', 'ka': 'ეს დოკუმენტის კლასიფიკაციაში სიტყვების ფუნქციები და კლასის ნიშანების შორის შესაბამისი ტექნექტიკის შესაბამისი ტექნექტიკა. მიზეზი არის უფრო მნიშვნელოვანი და გენერალური ფუნქციების განსაზღვრება, ვიდრე მხოლოდ კორელაციური მიზეზებით. სენტიმენტის კლასიფიკაციის ექსპერიმენტები გამოჩვენება, რომ საზოგადომის მეტი განსხვავებელი სიტყვების შესახებ სენტიმენტის შესახებ და კლასიფიკაციის შესახებ უფ პროგრამეტრების გამოყენება სხვადასხვა მეტი იქნება განსაკუთრებული ეფექტიური, როცა ეფექტიური გარეშე მონაცემებისთვის გამოყენ', 'el': 'Η παρούσα εργασία προτείνει μια τεχνική αντιστοίχισης για την εκμάθηση αιτιώδους συσχετισμών μεταξύ χαρακτηριστικών λέξεων και ετικετών τάξης στην ταξινόμηση εγγράφων. Στόχος είναι να εντοπιστούν πιο σημαντικά και γενικευμένα χαρακτηριστικά από ό,τι με μόνο συσχετιστικές προσεγγίσεις. Τα πειράματα με την ταξινόμηση συναισθημάτων δείχνουν ότι η προτεινόμενη μέθοδος εντοπίζει ερμηνευτές συσχετίσεις λέξεων με το συναίσθημα και βελτιώνει την απόδοση ταξινόμησης στις περισσότερες περιπτώσεις. Η προτεινόμενη μέθοδος επιλογής χαρακτηριστικών είναι ιδιαίτερα αποτελεσματική όταν εφαρμόζεται σε δεδομένα εκτός πεδίου.', 'it': "Questo articolo propone una tecnica di matching per imparare le associazioni causali tra caratteristiche delle parole e etichette di classe nella classificazione dei documenti. L'obiettivo è quello di identificare caratteristiche più significative e generalizzabili che con approcci correlazionali. Esperimenti di classificazione sentimentale mostrano che il metodo proposto identifica associazioni di parole interpretabili con sentiment e migliora le prestazioni di classificazione nella maggior parte dei casi. Il metodo proposto di selezione delle funzionalità è particolarmente efficace se applicato ai dati fuori dominio.", 'hu': 'Ez a tanulmány egy megfelelő technikát javasol a szó jellemzői és osztálycímkék okozati összefüggéseinek tanulására a dokumentumok osztályozásában. A cél a korrelációs megközelítéseknél jelentősebb és általánosítható jellemzők azonosítása. Az érzelmek osztályozásával végzett kísérletek azt mutatják, hogy a javasolt módszer értelmezhető szóasszociációkat azonosít az érzelmekkel és javítja az osztályozási teljesítményt az esetek többségében. A javasolt funkciókiválasztási módszer különösen hatékony, ha a domainen kívüli adatokra alkalmazzák.', 'mk': 'Овој документ предлага техника за одговарање за учење причински асоцијации помеѓу зборните карактеристики и класичните етикети во класификацијата на документите. Целта е да се идентификуваат позначајни и генерализирани карактеристики отколку само со корелационални пристапи. Експериментите со класификација на чувства покажуваат дека предложениот метод идентификува интерпретабилни зборни здруженија со чувства и ја подобрува класификацијата во повеќето случаи. Предложениот метод за избор на карактеристики е особено ефикасен кога се применуваат на податоци надвор од доменот.', 'kk': 'Бұл қағаз құжаттардың салыстыруындағы сөз қасиеттері мен клас жарлықтары арасындағы сәйкес келетін техниканы үйрену үшін қолданылады. Мақсат - тек корелациялық жағдайлармен артық және жалпы мүмкіндіктерді анықтау. Сөздерді шектеу тәжірибелері келтірілген тәжірибелердің көпшілігінде сөздерді түсініктеу мүмкіндігін анықтайды. Келтірілген мүмкіндіктерді таңдау әдісі доменге шығыс деректерге қолданғанда әсер етеді.', 'ms': 'Kertas ini mencadangkan teknik yang sepadan untuk mempelajari hubungan penyebab antara ciri perkataan dan label kelas dalam klasifikasi dokumen. Tujuan adalah untuk mengenalpasti ciri-ciri yang lebih bermakna dan boleh diseluruhkan daripada hanya dengan pendekatan korelasi. Experiments with sentiment classification show that the proposed method identifies interpretable word associations with sentiment and improves classification performance in a majority of cases.  Kaedah pemilihan fitur yang diusulkan adalah terutama berkesan bila dilaksanakan pada data diluar domain.', 'ml': 'ഈ പത്രത്തില്\u200d രേഖയുടെ വിഭവങ്ങള്\u200dക്കും ക്ലാസിന്റെ ലേബ്ലുകള്\u200dക്കും ഇടയിലുള്ള കാരണങ്ങള്\u200d പഠിപ്പിക്കുന്നതിനും ഒരു  ലക്ഷ്യത്തിന്റെ ലക്ഷ്യം കൂടുതല്\u200d അര്\u200dത്ഥതയുള്ളതും സാധാരണ പ്രധാനപ്പെട്ട വിഭാഗങ്ങളും നിരീക്ഷിക്കാനാണ്. Experiments with sentiment classification show that the proposed method identifies interpretable word associations with sentiment and improves classification performance in a majority of cases.  പ്രൊദ്ദേശിക്കപ്പെട്ട ഗുണപൂര്\u200dണ്ണമായ തെരഞ്ഞെടുക്കുന്ന രീതിയില്\u200d പ്രധാനപ്പെടുത്തുന്നത് ഡോമെയ', 'lt': 'Šiame dokumente siūloma suderinti mokymosi priežastines sąsajas tarp žodžių charakteristikų ir klasės etiketės dokumentų klasifikacijoje. The goal is to identify more meaningful and generalizable features than with only correlational approaches.  Eksperimentai su jautrumo klasifikacija rodo, kad siūlomas metodas nustato aiškinamąsias žodžių asociacijas su jautrumu ir daugeliu atvejų pagerina klasifikacijos veiksmingumą. Siūlomas savybių atrankos metodas yra ypač veiksmingas, kai jis taikomas ne srities duomenims.', 'mt': 'Dan id-dokument jipproponi teknika ta’ tqabbil għat-tagħlim ta’ assoċjazzjonijiet kawżali bejn karatteristiċi tal-kliem u tikketti tal-klassi fil-klassifikazzjoni tad-dokumenti. L-għan huwa li jiġu identifikati karatteristiċi aktar sinifikanti u ġeneralizzabbli milli biss b’approċċi korrelazzjonali. L-esperimenti bil-klassifikazzjoni tas-sentimenti juru li l-metodu propost jidentifika assoċjazzjonijiet interpretabbli tal-kliem bis-sentiment u jtejjeb il-prestazzjoni tal-klassifikazzjoni fil-maġġoranza tal-każijiet. Il-metodu propost għall-għażla tal-karatteristiċi huwa partikolarment effettiv meta applikat għal dejta barra d-dominju.', 'mn': 'Энэ цаас баримт хуваалцааны үг болон ангийнхаа загварын хоорондох шалтгааныг сурах боломжтой техник юм. Цаг нь зөвхөн холбоотой ойлголтын тулд илүү утгатай, ерөнхийлөгч чанарыг олж мэдэх юм. Боловсролын хуваалтын туршилтууд санал өгсөн арга нь сэтгэл хөдлөлтэй үг холбоотой байдлыг тодорхойлж, ихэнх тохиолдолд хуваалцах үйл ажиллагааг сайжруулдаг гэдгийг харуулдаг. Өөрчлөлтийн сонголтын арга нь ялангуяа холбоотой мэдээлэл дээр хэрэглэгддэг үед үр дүнтэй.', 'pl': 'W artykule zaproponowano technikę dopasowania do nauki związków przyczynowych między cechami słowa a etykietami klas w klasyfikacji dokumentów. Celem jest zidentyfikowanie bardziej znaczących i uogólnionych cech niż w przypadku tylko podejść korelacyjnych. Eksperymenty z klasyfikacją sentymentów pokazują, że proponowana metoda identyfikuje interpretowalne skojarzenia słów ze sentymentem i w większości przypadków poprawia wydajność klasyfikacji. Proponowana metoda selekcji cech jest szczególnie skuteczna w przypadku zastosowania do danych poza domeną.', 'no': 'Denne papiret foreslår eit tilsvarande teknikk for å læra grunnleggjande tilknytingar mellom ord- funksjonar og klassemerkelapp i dokumentklassifikasjon. Målet er å identifisera meir betydelige og generelle funksjonar enn berre med korrelasjonelle tilnærmingar. Eksperimentar med sentimentklassifikasjon viser at den foreslåde metoden identifiserer tolkbare ord- forbundingar med sentiment og forbetrar klassifikasjonen i fleire tilfeller. Dette første metoden for utvalet av funksjonar er særleg effektivt når det er brukt til utviklingsdata.', 'ro': 'Această lucrare propune o tehnică de potrivire pentru învățarea asociațiilor cauzale între caracteristicile cuvântului și etichetele clasei în clasificarea documentelor. Scopul este de a identifica caracteristici mai semnificative și generalizabile decât cu abordări corelationale. Experimentele cu clasificarea sentimentului arată că metoda propusă identifică asocierile cuvintelor interpretabile cu sentimentul și îmbunătățește performanța clasificării în majoritatea cazurilor. Metoda propusă de selectare a caracteristicilor este deosebit de eficientă atunci când este aplicată datelor din afara domeniului.', 'sr': 'Ovaj papir predlaže odgovarajuću tehniku za učenje uzrokovanih asocijacija između karakteristika riječi i etiketa klase u klasifikaciji dokumenta. Цел је да идентифицирамо још смислије и обичајеме особе од само корелационних подхода. Eksperimenti sa klasifikacijom sentiment a pokazuju da predložena metoda identifikuje interpretabilne veze sa osjećanjem i poboljšava klasifikaciju u većini slučajeva. Predložena metoda selekcije funkcija je posebno efikasna kada se primjenjuje na podaci izvan domena.', 'so': 'Kanu wuxuu soo jeedaa iskuul u eg barashada ururada sababta ah oo u dhexeeya aqoonta hadalka iyo calaamadaha fasalka ee wargeyska. Ujeedadu waa in la ogaado tayooyin faa’iido badan oo la faa’iido leh oo la caadi karo oo kaliya qaabab xiriir ah. Imtixaanka kalluumeysiga waxay muuqataa in qaababka la soo jeeday ay aqoonsadaan ururo hadal turjuman oo ay ku leeyihiin fikrad turjuman, wuxuuna beddeliyaa fasaxa fasaxa marka ay badan yihiin xaaladaha badan. Midabka doorashada ee la soo jeedo waxaa si gaar ah u faa’iido leh marka lagu codsaday macluumaad aan dalbanin.', 'sv': 'Denna uppsats föreslår en matchande teknik för att lära sig orsakssamband mellan ordfunktioner och klassetiketter i dokumentklassificering. Målet är att identifiera mer meningsfulla och generaliserbara egenskaper än med enbart korrelationsansatser. Experiment med sentimentklassificering visar att den föreslagna metoden identifierar tolkningsbara ordassociationer med sentiment och förbättrar klassificeringsprestandan i de flesta fall. Den föreslagna metoden för val av funktioner är särskilt effektiv när den tillämpas på data utanför domänen.', 'si': 'Name අරමුණය තමයි විශේෂයෙන් සම්බන්ධ විදියට වඩා සම්බන්ධ විදියට සම්බන්ධ විදියට වඩා විශේෂය සහ ස ප්\u200dරශ්න විධානය පෙන්වන්න පුළුවන් විධානය පෙන්වන්නේ ප්\u200dරශ්න විධානය සම්බන්ධ වචන සම්බන්ධය සමඟ සම්බන් ප්\u200dරයෝජනය විශේෂය තෝරාගන්න ප්\u200dරවේශය විශේෂයෙන් ප්\u200dරයෝජනය විශේෂයි.', 'ta': 'இந்த தாள் ஆவண வகைப்படுத்தலில் வார்த்தை குணங்கள் மற்றும் வகுப்பு சிட்டைகளுக்கு இடையே கற்றுக் கொள்ள ஒரு பொருத்தமா இலக்கு மட்டும் தொடர்புடைய முறைமைகளை விட அதிக மதிப்புள்ள மற்றும் பொதுவான குணங்களை கண்டறியும். உணர்வு வகைப்படுத்தலுடன் சோதனைகள் தெரியும் முறைமையில் பெரும்பாலான விஷயங்களில் மொழிபெரும்பாலான வார்த்தை இணைப்புகளை காட்ட திருத்தப்பட்ட குணங்கள் தேர்வு முறைமையாக குறிப்பாக பயன்படுத்தப்படும் போது.', 'ur': 'This paper proposes a matching technique for learning causal associations between words features and class labels in document classification. مقصد یہ ہے کہ صرف مرتبہ طریقے سے زیادہ مطلوب اور عمومی خصوصے پہچان سکیں۔ احساسات کلاسیفوں کے تجربے دکھاتے ہیں کہ پیشنهاد کی طریقہ احساسات کے ساتھ تفصیل قابل کلاسیفوں کی تعریف کرتی ہے اور بہت سی موارد میں کلاسیفوں کی عملکرد کو بہت زیادہ سے زیادہ زیادہ سے زیادہ کرتی ہے پیشنهاد فرصت انتخاب طریقہ مخصوصاً اثرات ہے جبکہ ڈومین خارج سے ڈاٹ پر لازم کیا جاتا ہے.', 'uz': "Бу қонун ҳужжат тафсилотида сўз хусусиятлари ва синфдаги маълумотлар ўрнатиш учун мувофиқ тахмини кўрсатади. Maqola shunday, faqat bog'liq usullardan ko'proq va umumiy xususiyatlarni aniqlash. Foydalanuvchi darajasida taʼminlovchi imtiyozlar qo'shiladi. Bu tilda ilova qilingan usul hisob bilan bog'langan so'zlar bogʻlanishini aniqlaydi va ko'pchilik holatlarda darajalashtirishni bajaradi. The proposed feature selection method is particularly effective when applied to out-of-domain data.", 'vi': 'Tờ giấy này đề xuất một phương pháp phù hợp để học các liên quan hệ hệ hệ hệ hệ hệ hệ hệ hệ hệ hệ hệ nguyên tử giữa các chữ và nhãn lớp trong phân loại tài liệu. Mục tiêu là xác định các tính năng có ý nghĩa và rộng rãi hơn chỉ với các phương pháp tương quan. Thử nghiệm phân loại cảm xúc cho thấy rằng phương pháp đã đề nghị xác định các liên hệ ngôn ngữ có cảm xúc và cải thiện hiệu suất phân loại trong hầu hết các trường hợp. Cách chọn đặc trưng đã đề nghị đặc biệt hiệu quả khi được áp dụng cho dữ liệu ngoài miền.', 'bg': 'Настоящата статия предлага съвпадение техника за изучаване на причинно-следствени асоциации между черти на думи и етикети на класове в класификацията на документи. Целта е да се идентифицират по-смислени и обобщени характеристики, отколкото само с корелационни подходи. Експерименти с класификация на сантимента показват, че предложеният метод идентифицира интерпретируеми думи асоциации със сантимента и подобрява класификацията в повечето случаи. Предложеният метод за избор на характеристика е особено ефективен, когато се прилага за данни извън домейна.', 'da': 'Denne artikel foreslår en matchende teknik til at lære årsagssammenhænge mellem ordfunktioner og klasseetiketter i dokumentklassificering. Målet er at identificere mere meningsfulde og generaliserede træk end med kun korrelationelle tilgange. Eksperimenter med sentimentklassificering viser, at den foreslåede metode identificerer fortolkningsbare ordassociationer med sentiment og forbedrer klassifikationens ydeevne i de fleste tilfælde. Den foreslåede metode til valg af funktioner er særlig effektiv, når den anvendes på data uden for domænet.', 'nl': 'Deze paper stelt een matching techniek voor voor het leren van causale associaties tussen woordkenmerken en klassenlabels in documentclassificatie. Het doel is om meer betekenisvolle en generaliseerbare kenmerken te identificeren dan met alleen correlationele benaderingen. Experimenten met sentimentclassificatie tonen aan dat de voorgestelde methode interpreteerbare woordassociaties met sentiment identificeert en in de meeste gevallen de classificatieprestaties verbetert. De voorgestelde methode voor de selectie van functies is bijzonder effectief wanneer toegepast op gegevens buiten het domein.', 'hr': 'Ovaj papir predlaže odgovarajuću tehniku za učenje uzročnih udruženja između karakteristika riječi i etiketa klase u klasifikaciji dokumenta. Cilj je identificiranje značajnijih i generalnih karakteristika nego samo korelacionih pristupa. Eksperimenti sa klasifikacijom osjećaja pokazuju da je predložena metoda identificirana interpretabilne veze riječi s osjećanjem i poboljšava učinkovitost klasifikacije u većini slučajeva. Predloženi metod izbora funkcija posebno je učinkovit kada se primjenjuje na podaci izvan domena.', 'de': 'Diese Arbeit schlägt eine Matching-Technik vor, um kausale Assoziationen zwischen Wortmerkmalen und Klassenbezeichnungen in der Dokumentenklassifizierung zu lernen. Ziel ist es, aussagekräftigere und generalisierbare Merkmale zu identifizieren als mit nur korrelationalen Ansätzen. Experimente mit Sentiment-Klassifizierung zeigen, dass die vorgeschlagene Methode interpretierbare Wortassoziationen mit Sentiment identifiziert und in den meisten Fällen die Klassifikationsleistung verbessert. Die vorgeschlagene Feature Selection Methode ist besonders effektiv, wenn sie auf Out-of-Domain Daten angewendet wird.', 'id': 'Kertas ini mengusulkan teknik yang cocok untuk belajar asosiasi penyebab antara fitur kata dan label kelas dalam klasifikasi dokumen. Tujuannya adalah untuk mengidentifikasi ciri-ciri yang lebih bermakna dan dapat diseluruhkan daripada hanya dengan pendekatan korelasi. Experiments with sentiment classification show that the proposed method identifies interpretable word associations with sentiment and improves classification performance in a majority of cases.  Metode seleksi fitur yang diusulkan sangat efektif ketika diterapkan pada data luar domain.', 'fa': 'این کاغذ یک تکنیک متفاوت برای یادگیری اتصال باعث اتصال بین ویژگی\u200cهای کلاس و برچسب\u200cهای کلاس در برچسب سند پیشنهاد می\u200cکند. هدف این است که ویژگی\u200cهای معنی\u200cتر و قابل توجه\u200cتر از تنها نزدیک\u200cهای ارتباطی شناسایی کنیم. تجربه\u200cهایی با classification احساسات نشان می\u200cدهند که روش پیشنهاد ارتباط قابل تعبیر کلمات با احساسات شناسایی می\u200cکند و عملکرد کلمات را در بیشتر پرونده\u200cها بهتر می\u200cکند. روش انتخاب خصوصی پیشنهاد مخصوصاً موثر است وقتی برای داده های خارج از دامنه استفاده می شود.', 'ko': '본고는 문서 분류에서 단어의 특징과 분류 라벨 간의 인과 관계를 학습하는 일치 기술을 제시했다.관련 방법만 사용하는 것보다 더 의미있고 보편적인 특징을 식별하는 것이 목표다.감정 분류에 대한 실험에 따르면 이 방법은 감정과 관련된 해석 가능한 단어를 식별할 수 있고 대다수 상황에서 분류 성능을 향상시켰다.역외 데이터에 응용할 때 제시된 특징 선택 방법은 특히 효과적이다.', 'sw': 'Makala hii inapendekeza teknolojia inayofanana kwa ajili ya kujifunza mashirika yanayosababishwa kati ya utambulisho wa maneno na alama za darasa katika usambazaji wa nyaraka. Lengo ni kutambua tabia zenye maana na zenye umuhimu kuliko tu kwa njia za mahusiano. Majaribio yenye kutafsiri hisia zinaonyesha kuwa mbinu zilizopendekezwa inaonyesha mashirika yanayotafsiri ya neno yenye hisia na kuboresha utendaji wa usambazaji katika kesi nyingi. The proposed feature selection method is particularly effective when applied to out-of-domain data.', 'tr': 'Bu kagyz sened klasifikasynda söz karakterleriň we klas etiketleriň arasynda eşleşen teknikleri teklip edir. Maksady diňe correlatyýan golaýlary bilen has möhüm we umumy üpjün tanyşdyrmak. Duýgular klasifikasyyla experimentalar öngörülen yöntemiň duýgular bilen terjime edilebilir sözleri tanap edýändigini görkezýär we olaryň köpüsi ýagdaýda klasifikasyon etkinleşigini gowuraýar. Sahypa edilen özellikler saýlamak yöntemi belli-da domain maglumaty üçin etkinleýär.', 'af': "Hierdie papier stel 'n ooreenstemmende tekniks voor te leer oorsaaklike assosiasies tussen woord funksies en klas etikette in dokumentklasifikasie. Die doel is om meer betekenlike en generaliseerbare funksies te identifiseer as met slegs korelasiese toegange. Eksperimente met sentiment klasifikasie wys dat die voorgestelde metode uitleggbare woord toesluitings met sentiment identifiseer en verbeter klasifikasie-prestasie in 'n meeste van gevalle. Die voorgestelde funksie kies metode is spesifieke effektief wanneer gebruik word na outdomein data.", 'sq': 'Ky dokument propozon një teknikë të përshtatshme për mësimin e shoqatave shkakuese midis karakteristikave të fjalëve dhe etiketave të klasës në klasifikimin e dokumenteve. Qëllimi është të identifikojmë karakteristika më të kuptueshme dhe të gjeneralizueshme sesa me vetëm qasje korrelacionale. Experiments with sentiment classification show that the proposed method identifies interpretable word associations with sentiment and improves classification performance in a majority of cases.  Metoda e propozuar e zgjedhjes së funksioneve është veçanërisht e efektshme kur aplikohet në të dhënat jashtë domenit.', 'am': "ይህ ገጽ በሰነድ ግንኙነት እና በቋንቋው ምልክቶች መካከል ለየረኀብ ማህበረሰብን ለመማር የሚተካከለውን የሥልጣን ጥያቄ ያሳያል፡፡ ጉዳዩ ግን ከግንኙነት ግንኙነት ብቻ ይልቅ የሚያስፈልገው እና ማወያየት የሚችሉትን ምርጫዎች ማረጋገጥ ነው፡፡ በአስማዊ መግለጫ ላይ ፈተናዎች በተፈጸመ ሥርዓት፣ በተመሳሳይ ማግኘት የሚችሉትን ቃላት ማኅበረሰቦችን የሚያሳውቅ እና በብዙዎቹ በጉዳዮች ላይ የተለያዩትን ትርጉም ማድረግ ያበጃል፡፡ ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Այս աշխատանքը առաջարկում է համապատասխանող տեխնիկա ուսումնասիրելու պատճառային կապվածություններ բառերի առանձնահատկությունների և դասի պիտակների միջև փաստաթղթերի դասակարգում: The goal is to identify more meaningful and generalizable features than with only correlational approaches.  Զգացմունքների դասակարգման փորձարկումները ցույց են տալիս, որ առաջարկված մեթոդը հայտնաբերում է թարգմանելի բառերի կապեր զգացմունքների հետ և բարելավում է դասակարգման արդյունքը շատ դեպքերում: Առաջարկված հատկանիշների ընտրության մեթոդը հատկապես արդյունավետ է, երբ կիրառվում է ոչ տիեզերական տվյալների վրա:', 'az': 'Bu kağıt, belədir klasifikasiyada söz özellikləri və sınıf etiketlərinin arasındakı causal bağlantıları öyrənmək üçün uyğun bir tekniki təklif edir. Məqsəd yalnız korrelasyon tərzlərindən daha anlamlı və genel tərzlərini tanımmaqdır. Duyarlıq klasifikasiyası ilə təcrübə edilən təcrübə metodun duyarlığı ilə yorumlu söz bağlantılarını tanıyır və klasifikasiya performansını çoxluğunda yaxşılaşdırır. Önülləşdirilmiş xüsusiyyətlər seçmə metodu, domena dışı verilənlərə istifadə edilərkən müəyyən edilir.', 'bn': 'এই পত্রিকাটি নথি বিভাগে শব্দের বৈশিষ্ট্য এবং ক্লাসের লেবেলের মধ্যে কারণের সংস্থা শিক্ষা শিখতে একটি মিলিয়ার প্ লক্ষ্য হচ্ছে শুধুমাত্র সম্পর্কিত উপায়ের চেয়ে বেশী অর্থহীন এবং সাধারণ বৈশিষ্ট্য চিহ্নিত করা। অনুভূতি বিভাগের পরীক্ষা দেখাচ্ছে যে প্রস্তাবিত পদ্ধতি অনুভূতির সাথে ব্যাখ্যাত শব্দ সম্প্রদায়কে চিহ্নিত করে এবং বেশীরভাগ কেস প্রস্তাবিত বৈশিষ্ট্য নির্বাচন পদ্ধতি বিশেষ কার্যকর যখন ডোমেইনের তথ্য প্রয়োগ করা হয়।', 'bs': 'Ovaj papir predlaže odgovarajuću tehniku za učenje uzročnih asocijacija između karakteristika riječi i etiketa klase u klasifikaciji dokumenta. Cilj je identificiranje značajnijih i generalnih karakteristika nego samo korelacionih pristupa. Eksperimenti sa klasifikacijom osjećanja pokazuju da je predložena metoda identificirana interpretabilne veze riječi sa osjećanjem i poboljšava učinkovitost klasifikacije u većini slučajeva. Predložena metoda izbora funkcija je posebno efikasna kada se primjenjuje na podaci izvan domena.', 'ca': "Aquest article proposa una tècnica d'ajustament per aprendre associacions causals entre les característiques de paraules i les etiquetes de classe en la classificació de documents. L'objectiu és identificar característiques més significatives i generalitzables que només amb enfocaments correlacionals. Els experiments amb classificació del sentiment mostren que el mètode proposat identifica associacions de paraules interpretables amb el sentiment i millora el rendiment de la classificació en la majoria de casos. El mètode proposat de selecció de característiques és particularment efectiu quan s'aplica a dades fora de domini.", 'cs': 'Tento článek navrhuje metodu shodování příčinných asociací mezi slovními rysy a popisky tříd v klasifikaci dokumentů. Cílem je identifikovat smysluplnější a zobecňovatelnější rysy než u pouze korelačních přístupů. Experimenty s klasifikací sentimentů ukazují, že navržená metoda identifikuje interpretovatelné slovní asociace se sentimentem a zlepšuje klasifikační výkon ve většině případů. Navržená metoda výběru funkcí je obzvláště efektivní, pokud je aplikována na data mimo doménu.', 'et': 'Käesolevas töös pakutakse välja sobitamismeetodi, et õppida põhjuslikke seoseid sõna omaduste ja klassimärgiste vahel dokumendi klassifitseerimisel. Eesmärk on tuvastada tähenduslikumad ja üldistatavad tunnused kui ainult korrelatsioonilised lähenemisviisid. Eksperimentid sentimentaalse klassifikatsiooniga näitavad, et kavandatud meetod tuvastab tõlgendatavaid sõnasuhteid sentimentaalsusega ja parandab klassifikatsiooni tulemuslikkust enamikul juhtudel. Kavandatud funktsioonide valimise meetod on eriti tõhus, kui seda rakendatakse valdkonnaväliste andmete puhul.', 'fi': 'Tässä työssä ehdotetaan vastaavuustekniikkaa sanaominaisuuksien ja luokkamerkintöjen kausaalisten yhteyksien oppimiseen dokumenttieluokituksessa. Tavoitteena on tunnistaa merkityksellisempiä ja yleistettäviä piirteitä kuin pelkillä korrelaatiomenetelmillä. Tunteluokittelukokeet osoittavat, että ehdotettu menetelmä tunnistaa tulkittavissa olevat sanasuhteet tunteeseen ja parantaa luokitusta useimmissa tapauksissa. Ehdotettu ominaisuusvalintamenetelmä on erityisen tehokas, kun sitä sovelletaan toimialueen ulkopuolisiin tietoihin.', 'jv': 'Perintah iki supoyata sak teknik sing dadi nggawe pawaran kelas karo perusahaan kelas karo etiket sing koyo barang token Punika kanggo nambah sing luwih dumadhi lan kabeh-luwih apik sing luwih apik karo perusahaan sampeyan. User The proposal option method is special effectwhen used to out-of-domain data.', 'he': 'העבודה הזו מציעה טכניקה מתאימה ללמוד איגודות סיבות בין תכונות מילים ותוויות שיעורים בהסכם המסמכים. המטרה היא לזהות תכונות משמעותיות ויותר כלליות מאשר עם גישות יחסיות בלבד. ניסויים עם מסווג רגשות מראים שהשיטה המוצעת מזהה איגודים מילים אפשריים לפרש עם רגשות ומשתפר ביצועים מסווגים ברוב המקרים. שיטת הבחירה המוצעת של תכונות היא יעילה במיוחד כשהופעה למידע מחוץ לתחום.', 'ha': "Wannan takardar da ke ƙayyade wani technci mai daidaita wa karanta associations masu shawara tsakanin haske da alama mai daraja cikin fasalin takardar. The goal is to identify more meaningful and generalizable features than with only correlational approaches.  Saurin da sifori na aikin hisia na nuna cewa metoden da aka buƙata yana gane masu fassarawa da maganar da ke da hisani'a kuma yana ƙari da fasalar fassarar cikin masu yawa. @ info: whatsthis", 'sk': 'V prispevku je predlagana tehnika ujemanja za učenje vzročnih povezav med besednimi značilnostmi in oznakami razredov pri klasifikaciji dokumentov. Cilj je prepoznati pomembnejše in splošljive značilnosti kot le s korelacijskimi pristopi. Eksperimenti s klasifikacijo sentimenta kažejo, da predlagana metoda identificira razložljive besedne povezave s sentimentalnostjo in v večini primerov izboljša klasifikacijsko uspešnost. Predlagana metoda izbire značilnosti je še posebej učinkovita, kadar se uporablja za zunajdomenske podatke.', 'bo': 'This paper proposes a matching technique for learning causal associations between word features and class labels in document classification. དམིགས་ཡུལ་ནི་ཕན་ཚུན་མཐུན་དང་བསྡུར་ན་ཡོད་པའི་ཆོས་ཉིད་དང་ཁྱད་ཆོས་ཉིད་དག་རྟོགས་འདོད་ཡོད། སྟོན་རྟགས་དབྱེ་རིགས་དང་མཉམ་དུ་གྲུབ་པའི་ལག་ལེན་གྱིས་དམིགས་འཛུགས་པའི་ཐབས་ལམ་དེ་སྟོན་རུང་བའི་ཐ་སྙད་དང་སྦྲེལ་མཐུད་དང་ཡང་ The proposed feature selection method is particularly effective when applied to out-of-domain data.'}
{'en': 'A Supervised Approach to Extractive Summarisation of Scientific Papers', 'pt': 'Uma abordagem supervisionada para sumarização extrativa de artigos científicos', 'es': 'Un enfoque supervisado para el resumen extractivo de artículos científicos', 'ar': 'نهج خاضع للإشراف للتلخيص الاستخراجي للأوراق العلمية', 'fr': "Une approche supervisée de la synthèse extractive d'articles scientifiques", 'ja': '科学論文を抽出的に要約するための監督されたアプローチ', 'zh': '科学论文摘摘要监督之法', 'hi': 'वैज्ञानिक पत्रों के निष्कर्षण सारांशीकरण के लिए एक पर्यवेक्षित दृष्टिकोण', 'ru': 'Контролируемый подход к экстрактивному обобщению научных работ', 'ga': 'Cur Chuige Maoirsithe maidir le hAchoimriú Eastóscach ar Pháipéir Eolaíoch', 'el': 'Μια εποπτευόμενη προσέγγιση στην αποσπαστική περίληψη επιστημονικών εγγράφων', 'ka': 'მეცნიერო კომეტრების ექსტრაქტიური კომპანიზაციის დანახვა', 'hu': 'A tudományos tanulmányok extraktív összefoglalásának felügyeleti megközelítése', 'it': 'Un approccio supervisionato alla sintesi estrattiva dei documenti scientifici', 'lt': 'Stebimas metodas ekstraktyviam mokslinių dokumentų santraukų apibendrinimui', 'kk': 'Ғылыми құжаттардың тарқату тұжырымдамасының басқару жағдайыName', 'mk': 'Набљудуван пристап до екстрактивна резултата на научните документи', 'ms': 'Name', 'ml': 'ശാസ്ത്ര പത്രങ്ങളുടെ ശാസ്ത്ര പത്രത്തിലേക്ക് പുറത്തെടുക്കുന്നതിലേക്കു് പ്രത്യേകിച്ചുകൊണ്ടിരി', 'mn': 'Шинжлэх ухааны баримтуудын нэмэгдүүлэх нэмэгдүүлэлт', 'no': 'Name', 'pl': 'Nadzorowane podejście do ekstrakcyjnego podsumowania prac naukowych', 'mt': 'Approċċ Sorveljat għas-Sommarju Estrattiv tad-Dokumenti Xjentifiċi', 'ro': 'O abordare supravegheată a rezumatului extractiv al lucrărilor științifice', 'sv': 'En övervakad metod för extraktiv sammanfattning av vetenskapliga artiklar', 'so': 'A Supervised Approach to Extract Summary of Scientific Papers', 'ta': 'அறிவியல் தாள்களின் சுருக்கம்', 'sr': 'Nadzorni pristup ekstraktivnoj rezervaciji naučnih papira', 'si': 'Name', 'ur': 'سائنس کاغذوں کے اضافہ کرنے کے لئے ایک تحت نظر کی تقرب ہے', 'uz': 'Name', 'vi': 'Kế hoạch giám sát Tóm tắt các giấy tờ khoa học', 'da': 'En overvåget metode til ekstraktiv sammenfatning af videnskabelige papirer', 'bg': 'Надзорен подход към извличане на научни статии', 'nl': 'Een begeleide benadering van extractieve samenvatting van wetenschappelijke documenten', 'hr': 'Nadzorni pristup ekstraktivnoj rezervaciji znanstvenih papira', 'de': 'A Supervised Approach to Extractive Summarisation of Scientific Papers', 'id': 'A Supervised Approach to Extractive Summarisation of Scientific Papers', 'ko': '과학 논문 적록의 감독 방법', 'sw': 'Makala ya Sayansi', 'fa': 'یک دستیابی تحت نظر به جمع\u200cآوری استخراج از روزنامه\u200cهای علمی', 'af': 'Name', 'am': 'ወደ ውጭ ማውጣት ማጠቃለያ የሳይንስ ወረቀቶች', 'tr': 'Ilmi Kagytlaryň A ýry Gaýşartma golaýy', 'sq': 'Një metodë e mbikqyrur për përmbledhjen ekstraktive të dokumenteve shkencore', 'hy': 'Գիտական փաստաթղթերի արտադրողական համառոտագրման վերահսկված մոտեցումը', 'bn': 'বৈজ্ঞানিক পত্রিকাগুলোর সামারসংক্রান্ত সংক্রান্ত সম্পর্কে সার্পার্ভিস করা হয়েছে', 'az': 'İlmi Kağıtların Extractive Summarisation üçün Gözlənmiş Yaxınlıq', 'ca': 'Un enfocament supervisat a la somària extractiva dels documents científics', 'bs': 'Nadzorni pristup ekstraktivnoj rezervaciji znanstvenih papira', 'cs': 'Dohledovaný přístup k extraktivnímu shrnutí vědeckých článků', 'et': 'Järelevalve all olev lähenemisviis teaduslike dokumentide ekstraktivsele kokkuvõttele', 'fi': 'Valvottu lähestymistapa tieteellisten julkaisujen tiivistämiseen', 'jv': 'Subtitles', 'ha': 'KCharselect unicode block name', 'sk': 'Nadzorovan pristop k ekstraktivnemu povzetku znanstvenih člankov', 'he': 'גישה מושגת לסיוריזציה אקסטרקטיבית של מסמכים מדעיים', 'bo': 'ཚན་རིག་གི་ཤོག་བུ་ཚོའི་ཁྱད་དུ་འཕགས་རིས་ཐུབ་པའི་ལྟ་བུའི་གཟུགས་སྐོར་དང་།'}
{'en': 'Automatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.', 'ar': 'التلخيص التلقائي هو نهج شائع لاختزال المستند إلى حججه الرئيسية. ركزت الأبحاث الحديثة في المنطقة على الأساليب العصبية للتلخيص ، والتي يمكن أن تكون متعطشة للغاية للبيانات. ومع ذلك ، يوجد عدد قليل من مجموعات البيانات الكبيرة ولا يوجد أي منها للمجال الشائع تقليديًا للمنشورات العلمية ، مما يفتح طرقًا بحثية صعبة تركز على ترميز المستندات الكبيرة والمعقدة. في هذه الورقة ، نقدم مجموعة بيانات جديدة لتلخيص منشورات علوم الكمبيوتر من خلال استغلال مصدر كبير من الملخصات المقدمة من المؤلفين وإظهار طرق مباشرة لتوسيعها أكثر. نقوم بتطوير نماذج على مجموعة البيانات باستخدام كل من ترميز الجملة العصبية وميزات التلخيص المستخدمة تقليديًا وإظهار أن النماذج التي تشفر الجمل بالإضافة إلى سياقها المحلي والعالمي تؤدي بشكل أفضل ، وتتفوق بشكل كبير على أساليب خط الأساس الراسخة.', 'es': 'El resumen automático es un enfoque popular para reducir un documento a sus argumentos principales. Las investigaciones recientes en el área se han centrado en los enfoques neuronales de la síntesis, que pueden consumir muchos datos. Sin embargo, existen pocos conjuntos de datos grandes y ninguno para el dominio tradicionalmente popular de las publicaciones científicas, lo que abre vías de investigación desafiantes centradas en la codificación de documentos grandes y complejos. En este artículo, presentamos un nuevo conjunto de datos para resumir publicaciones informáticas aprovechando un gran recurso de resúmenes proporcionados por los autores y mostramos formas sencillas de ampliarlo aún más. Desarrollamos modelos sobre el conjunto de datos utilizando tanto la codificación de oraciones neuronales como las funciones de resumen utilizadas tradicionalmente y demostramos que los modelos que codifican oraciones, así como su contexto local y global, tienen un mejor rendimiento, superando significativamente los métodos de referencia bien establecidos.', 'fr': "La synthèse automatique est une approche populaire qui permet de réduire un document à ses principaux arguments. Des recherches récentes dans ce domaine se sont concentrées sur les approches neuronales de la synthèse, qui peuvent être très gourmandes en données. Cependant, il existe peu de grands ensembles de données et aucun pour le domaine traditionnellement populaire des publications scientifiques, ce qui ouvre des pistes de recherche complexes centrées sur l'encodage de documents complexes et volumineux. Dans cet article, nous introduisons un nouvel ensemble de données pour la synthèse des publications informatiques en exploitant une grande quantité de résumés fournis par les auteurs et montrons des moyens simples de l'étendre davantage. Nous développons des modèles sur le jeu de données en utilisant à la fois le codage neuronal des phrases et les fonctions de synthèse utilisées traditionnellement. Nous montrons que les modèles qui encodent des phrases ainsi que leur contexte local et global sont les meilleurs, surpassant de manière significative les méthodes de base bien établies.", 'pt': 'A sumarização automática é uma abordagem popular para reduzir um documento aos seus principais argumentos. Pesquisas recentes na área se concentraram em abordagens neurais para sumarização, que podem ser muito famintas por dados. No entanto, existem poucos grandes conjuntos de dados e nenhum para o domínio tradicionalmente popular de publicações científicas, o que abre caminhos de pesquisa desafiadores centrados na codificação de documentos grandes e complexos. Neste artigo, apresentamos um novo conjunto de dados para resumo de publicações de ciência da computação, explorando um grande recurso de resumos fornecidos pelo autor e mostramos maneiras diretas de estendê-lo ainda mais. Desenvolvemos modelos no conjunto de dados usando recursos de codificação de sentença neural e recursos de sumarização tradicionalmente usados e mostramos que os modelos que codificam sentenças, bem como seu contexto local e global, apresentam melhor desempenho, superando significativamente os métodos de linha de base bem estabelecidos.', 'ja': '自動要約は、ドキュメントを主な引数に縮小するための一般的なアプローチです。この分野の最近の研究は、非常にデータに飢えている可能性のある要約へのニューラルアプローチに焦点を当てています。しかし、大規模なデータセットはほとんど存在せず、大規模で複雑な文書をエンコードすることを中心とした挑戦的な研究の道筋を開く、従来人気のあった科学出版物の分野については何も存在しない。本稿では、著者が提供した要約の大量のリソースを活用して、コンピュータサイエンスの出版物を要約するための新しいデータセットを紹介し、それをさらに拡張する簡単な方法を示す。私たちは、ニューラル文章エンコードと従来使用されてきた要約機能の両方を使用して、データセット上でモデルを開発し、文章をエンコードするモデルと、そのローカルおよびグローバルなコンテキストが最高のパフォーマンスを発揮し、確立されたベースライン法を大幅に上回ることを示します。', 'zh': '自摘要者,将文档简化为主要参数之常用也。 其领域近究集总结神经法,甚须数据。 然少有大数,亦无施于流科学出版物之域,开以编码杂文档为心挑战性之道也。 于本文中,引一新数集,以资作者之多摘要资源以总计算机科学出版物,而展其径术。 数集上发用神经句编码旧摘要,明于句上下文之上,明于已立之基线。', 'hi': 'स्वचालित सारांशीकरण एक लोकप्रिय दृष्टिकोण है जो किसी दस्तावेज़ को उसके मुख्य तर्कों तक कम करता है। इस क्षेत्र में हाल के शोध ने संक्षेप में तंत्रिका दृष्टिकोण पर ध्यान केंद्रित किया है, जो बहुत डेटा-भूखा हो सकता है। हालांकि, कुछ बड़े डेटासेट मौजूद हैं और वैज्ञानिक प्रकाशनों के पारंपरिक रूप से लोकप्रिय डोमेन के लिए कोई भी नहीं है, जो बड़े, जटिल दस्तावेजों को एन्कोडिंग पर केंद्रित चुनौतीपूर्ण अनुसंधान मार्ग खोलता है। इस पेपर में, हम लेखक के एक बड़े संसाधन का शोषण करके कंप्यूटर विज्ञान प्रकाशनों के सारांशीकरण के लिए एक नया डेटासेट पेश करते हैं और इसे आगे बढ़ाने के सीधे तरीके दिखाते हैं। हम डेटासेट पर मॉडल विकसित करते हैं जो तंत्रिका वाक्य एन्कोडिंग और पारंपरिक रूप से उपयोग की जाने वाली सारांश सुविधाओं दोनों का उपयोग करते हैं और दिखाते हैं कि मॉडल जो वाक्यों को एन्कोड करते हैं और साथ ही साथ उनके स्थानीय और वैश्विक संदर्भ को एन्कोड करते हैं, वे सबसे अच्छा प्रदर्शन करते हैं, जो अच्छी तरह से स्थापित बेसलाइन विधियों को काफी हद तक बेहतर प्रदर्शन करते हैं।', 'ru': 'Автоматическое обобщение - это популярный подход к сведению документа к его основным аргументам. Недавние исследования в этой области были сосредоточены на нейронных подходах к обобщению, которые могут быть очень голодными по данным. Тем не менее, больших наборов данных существует мало, и они отсутствуют для традиционно популярной области научных публикаций, что открывает сложные исследовательские пути, сосредоточенные на кодировании больших, сложных документов. В этой статье мы вводим новый набор данных для обобщения публикаций в области компьютерных наук, используя большой ресурс, предоставленный автором резюме, и показываем простые способы его дальнейшего расширения. Мы разрабатываем модели на наборе данных, используя как нейронное кодирование предложений, так и традиционно используемые обобщающие признаки, и показываем, что модели, которые кодируют предложения, а также их локальный и глобальный контекст, работают лучше, значительно превосходят хорошо зарекомендовавшие себя базовые методы.', 'ga': 'Is cur chuige coitianta é achoimriú uathoibríoch chun doiciméad a laghdú go dtí na príomh-argóintí a bhaineann leis. Dhírigh taighde le déanaí sa réimse seo ar chuir chuige néaracha maidir le hachoimriú, a bhféadfadh an-ocras sonraí a bheith air. Mar sin féin, is beag tacar sonraí móra atá ann agus níl aon cheann acu don réimse foilseachán eolaíoch a mbíonn an-tóir air go traidisiúnta, a osclaíonn bealaí dúshlánacha taighde atá dírithe ar dhoiciméid mhóra chasta a ionchódú. Sa pháipéar seo, tugaimid isteach tacar sonraí nua chun foilseacháin ríomheolaíochta a achoimriú trí leas a bhaint as acmhainn mhór achoimrí a cuireadh ar fáil ó údair agus a léiríonn bealaí simplí chun é a leathnú tuilleadh. Forbróimid samhlacha ar an tacar sonraí ag baint úsáide as ionchódú néar-abairtí agus gnéithe achoimriúcháin a úsáidtear go traidisiúnta agus taispeánann muid go bhfeidhmíonn múnlaí a ionchódaíonn abairtí chomh maith lena gcomhthéacs áitiúil agus domhanda is fearr, a fheidhmíonn go suntasach níos fearr ná modhanna bonnlíne seanbhunaithe.', 'ka': 'ავტომატიკური კოსუმენტიზაცია არის პოლიპური პროგრამი, რომ დოკუმენტი მისი მნიშვნელოვანი არგორმენტებში გადასრულება. მიმდინარე განსხვავებაში ნეიროლური გახსნა, რომელიც შეიძლება იყოს ძალიან მონაცემები. მაგრამ, რამდენიმე დიდი მონაცემების კომპუტაციები არსებობს და არსებობს მეცნიერო პუბლიური პუბლიუციების დემონი, რომელიც გახსნა შესაძლებელი სწავლებელი გასწავლებელი ამ დოკუმენში ჩვენ ახალი მონაცემების კომპუტერის მეცნიერების რესურსის გამოყენებით, რომელიც ავტორის დიდი რესურსის გამოყენებული რესურსის გავაკეთებთ და უფრო უფრო გავაკეთება ჩვენ განვითარებთ მოდელები მონაცემებზე, რომლებიც ნეიროლური სიტყვების კონექციაციის გამოყენებას და ტრადიციურად გამოყენებული სიტყვების ფუნქციების გამოყენებას და გამოყენება, რომ მოდელები, რომლებიც', 'hu': 'Az automatikus összefoglalás népszerű megközelítés a dokumentumok fő érveire való csökkentésére. A területen végzett közelmúltbeli kutatások az összefoglaló neurális megközelítésekre összpontosítottak, amelyek nagyon adatéhesek lehetnek. A tudományos publikációk hagyományosan népszerű területén azonban kevés nagyméretű adatkészlet létezik, ami nagy, komplex dokumentumok kódolására összpontosító kutatási utakat nyit meg. Ebben a tanulmányban egy új adatkészletet mutatunk be a számítástechnikai publikációk összefoglalására a szerzői összefoglalók nagy forrásának kiaknázásával, és egyértelmű módokat mutatunk be annak további kiterjesztésére. Az adatkészletre vonatkozó modelleket fejlesztünk ki mind az idegi mondatkódolás, mind a hagyományosan használt összefoglaló funkciók felhasználásával, és bemutatjuk, hogy a mondatokat kódoló modellek, valamint a helyi és globális kontextusok teljesítenek a legjobban, jelentősen felülmúlják a jól bevált alapmódszereket.', 'el': 'Η αυτόματη σύνοψη είναι μια δημοφιλής προσέγγιση για τη μείωση ενός εγγράφου στα κύρια επιχειρήματά του. Πρόσφατες έρευνες στην περιοχή έχουν επικεντρωθεί σε νευρωνικές προσεγγίσεις συνοψίας, οι οποίες μπορεί να είναι πολύ πεινασμένες για δεδομένα. Ωστόσο, λίγα μεγάλα σύνολα δεδομένων υπάρχουν και κανένα για τον παραδοσιακά δημοφιλή τομέα των επιστημονικών εκδόσεων, γεγονός που ανοίγει δύσκολες ερευνητικές οδούς που επικεντρώνονται στην κωδικοποίηση μεγάλων, σύνθετων εγγράφων. Σε αυτή την εργασία, εισάγουμε ένα νέο σύνολο δεδομένων για την περίληψη των εκδόσεων της επιστήμης των υπολογιστών αξιοποιώντας έναν μεγάλο πόρο περιλήψεων που παρείχαν οι συντάκτες και παρουσιάζουμε απλούς τρόπους για την περαιτέρω επέκταση του. Αναπτύσσουμε μοντέλα για το σύνολο δεδομένων χρησιμοποιώντας τόσο νευρωνική κωδικοποίηση προτάσεων όσο και παραδοσιακά χρησιμοποιούμενα χαρακτηριστικά σύνοψης και δείχνουν ότι μοντέλα που κωδικοποιούν προτάσεις καθώς και το τοπικό και παγκόσμιο τους πλαίσιο αποδίδουν καλύτερα, αποδίδοντας σημαντικά καλύτερα αποτελέσματα από τις καθιερωμένες μεθόδους βάσης.', 'it': "La sintesi automatica è un approccio popolare per ridurre un documento ai suoi argomenti principali. Recenti ricerche nell'area si sono concentrate sugli approcci neurali alla sintesi, che possono essere molto affamati di dati. Tuttavia, esistono pochi grandi set di dati e nessuno per il dominio tradizionalmente popolare delle pubblicazioni scientifiche, che apre strade di ricerca impegnative incentrate sulla codifica di documenti di grandi dimensioni e complessi. In questo articolo, introduciamo un nuovo set di dati per la sintesi delle pubblicazioni informatiche sfruttando una grande risorsa di sintesi fornite dagli autori e mostriamo modi semplici per estenderlo ulteriormente. Sviluppiamo modelli sul set di dati utilizzando sia la codifica neurale delle frasi che le funzionalità di riepilogo tradizionalmente utilizzate e mostriamo che i modelli che codificano le frasi così come il loro contesto locale e globale funzionano meglio, superando significativamente i metodi di base ben consolidati.", 'kk': 'Құжатты негізгі аргументтеріне көшірмелеу үшін автоматты түрде тұжырымдамасы. Жуырдағы зерттеулері күнтізбелгілеу үшін невралдық жағдайларына назар аударды. Бұл деректерді өткізу мүмкін. Бірақ бірнеше үлкен деректер жинақтары жоқ және әдімгі көптеген ғылыми жазулардың домені жоқ. Бұл үлкен, комплексті құжаттарды кодтамасына орналастыратын зерттеу жолдарын ашады. Бұл қағазда компьютер ғылымды жазуларды жаңа деректер жинақтарын келтіріп, автордың үлкен ресурсын қолданып, оны жалғастыру үшін жаңа деректер жинақтарын көрсетеді. Біз деректер қорларының үлгілерін жасап, невралдық сөздер кодтамасын және әдетте қолданылатын тұжырымдамасын қолдану үлгілерін жасап, сөздерді кодтамасын және жергілікті және әлемдік контексті жақсы жұмыс істейт', 'ms': 'Penapisan automatik adalah pendekatan popular untuk mengurangkan dokumen ke argumen utamanya. Penelitian baru-baru ini di kawasan ini telah fokus pada pendekatan saraf untuk ringkasan, yang boleh menjadi sangat lapar data. Bagaimanapun, beberapa set data besar wujud dan tiada untuk domain tradisional populer penerbitan saintifik, yang membuka jalan penyelidikan yang mencabar ditengatkan pada pengekodan dokumen besar dan kompleks. Dalam kertas ini, kami memperkenalkan set data baru untuk ringkasan penerbitan sains komputer dengan mengeksploitasi sumber besar penulis menyediakan ringkasan dan menunjukkan cara yang mudah untuk memperluasnya lebih jauh. Kami mengembangkan model pada set data yang menggunakan kedua-dua pengekodan kalimat saraf dan ciri-ciri ringkasan tradisional yang digunakan dan menunjukkan bahawa model yang mengekodkan kalimat serta konteks setempat dan global mereka melakukan yang terbaik, melampaui cara dasar yang ditetapkan dengan baik.', 'mk': 'Автоматска резимулација е популарен пристап за намалување на документот на неговите главни аргументи. Неодамнешното истражување во областа се фокусираше на нервните пристапи до резултатирањето, што може да биде многу гладно од податоци. Сепак, постојат неколку големи податоци и ниту еден за традиционално популарниот домен на научни публикации, кој отвора предизвикни истражувачки патишта центрирани на кодирање на големи, комплексни документи. Во овој весник, ние воведуваме нови податоци за резултат на компјутерските научни публикации со искористување на голем ресурс на авторот, обезбедувајќи резултати и покажувајќи едноставни начини за продолжување. Развиваме модели на податоците кои ги користат кодирањето на нервните реченици и традиционално употребените карактеристики за резултатирање и покажуваме дека моделите кои ги кодираат речениците, како и нивниот локален и глобален контекст, вршат најдобри, значително надминуваат добро воспостав', 'ml': 'ഒരു രേഖയെ പ്രധാനപ്പെട്ട ആര്\u200dഗ്യുമെന്\u200dറിലേക്ക് കുറയ്ക്കുവാന്\u200d സ്വയം ചുരുക്കം പ്രധാനപ്പെട്ട ഈ പ്രദേശത്തിലെ അടുത്തുള്ള പരിശോധന നടത്തിയിരിക്കുന്നു, ചുരുക്കത്തിന്റെ അടുത്തുള്ള പ്രാദേശങ്ങളിലേക്ക് ശ എന്നാലും കുറച്ച് വലിയ ഡാറ്റാസറ്റുകള്\u200d നിലനില്\u200dക്കുന്നു. പാരാധാരണ ശാസ്ത്ര പ്രകടന പ്രസ്താപങ്ങളുടെ പ്രധാനപ്പെട്ട ഡൊമെയിനുമി ഈ പത്രത്തില്\u200d, കമ്പ്യൂട്ടറിന്റെ ശാസ്ത്ര പ്രചരണങ്ങള്\u200dക്ക് വേണ്ടി ഒരു പുതിയ ഡാറ്റാസേറ്റ് പരിചയപ്പെടുത്തുന്നു. ഒരു വലിയ വിഭവങ്ങള്\u200d ചെയ്ത ന്യൂറല്\u200d വാക്കിന്റെ കോഡിങ് കോഡിങ് ഉപയോഗിക്കുന്നതും ചരിത്രമായി ഉപയോഗിക്കുന്നതും ഉപയോഗിക്കുന്നതുമായ ഡാറ്റാസസെറ്റില്\u200d നാം മോഡലുകള്\u200d നിര്\u200dമ്മിക്കുന്നു.', 'mt': 'Is-sommarju awtomatiku huwa approċċ popolari biex jitnaqqas dokument għall-argumenti ewlenin tiegħu. Ir-riċerka reċenti fil-qasam iffokat fuq approċċi newrali għas-sommarju, li jista’ jkollhom ħafna nuqqas ta’ dejta. Madankollu, jeżistu ftit settijiet ta’ dejta kbar u l-ebda sett ma huwa għall-qasam tradizzjonalment popolari ta’ pubblikazzjonijiet xjentifiċi, li jiftaħ toroq ta’ riċerka sfidanti li jiffukaw fuq il-kodifikazzjoni ta’ dokumenti kbar u kumplessi. F’dan id-dokument, a ħna nintroduċu sett ġdid ta’ dejta għas-sommarju tal-pubblikazzjonijiet tax-xjenza tal-kompjuter billi nisfruttaw riżorsa kbira ta’ awtur ipprovda sommarji u nuru modi sempliċi kif tiġi estiża aktar. Aħna niżviluppaw mudelli dwar is-sett tad-dejta li jużaw kemm il-kodifikazzjoni tas-sentenzi newrali kif ukoll il-karatteristiċi ta’ sommarju tradizzjonalment użati u nuru li mudelli li jikkodifikaw is-sentenzi kif ukoll il-kuntest lokali u globali tagħhom iwettqu l-aħjar metodi ta’ bażi stabbiliti sew u b’mod sinifikanti.', 'mn': 'Хэрэв автоматтын тодорхойлолт бол баримтыг түүний гол аргумент руу багасгах олон хүмүүсийн арга зам юм. Үүний сүүлийн судалгаагаар мэдээллийн өлсгөлөн байж болно. Гэхдээ хэдэн том өгөгдлийн сангууд байдаг бөгөөд уламжлалтай шинжлэх ухааны нийтлэл дээр хэн ч байхгүй. Энэ нь том, төвөгтэй баримтуудыг кодлох гол шаардлагатай судалгааны шаардлагатай арга замыг нээж өгдө Энэ цаасан дээр бид компьютер шинжлэх ухааны хэвлэлүүдийг нэмэгдүүлэх шинэ өгөгдлийн компьютерийн шинжлэх ухааны хэвлэлүүдийг ашиглаж, маш их баялаг зохиолчдыг ашиглаж, үүнийг илүү өргөн арга за Бид мэдээллийн хэлбэрийн шинжлэх ухаан болон уламжлалтаар хэрэглэгдсэн жинхэнэ хэлбэрүүдийг ашиглаж байгаа өгөгдлийн хэлбэрийн загваруудыг хөгжүүлж, тэдний орон нутгийн болон ертөнцийн байдлаар шинжлэх ухаан гаргадаг загварууд нь сайн', 'lt': 'Automatinė santrauka yra populiarus požiūris, kad dokumentą būtų galima sumažinti atsižvelgiant į pagrindinius argumentus. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry.  Tačiau yra nedaug didelių duomenų rinkinių ir jų nėra tradiciškai populiarios mokslinių leidinių srities, kuri atveria sudėtingus mokslinių tyrimų būdus, centruotus didelių ir sudėtingų dokumentų kodavimu. Šiame dokumente įvedame naują duomenų rinkinį kompiuterinių mokslo leidinių santraukai, naudojant didelį autorių išteklių, pateiktų santraukas, ir parodysime paprastus būdus ją toliau plėsti. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.', 'no': 'Automatisk samandringa er ein populært tilnærming for å redusera eit dokument til hovudargumentet sin. Nyleg forskning i området har fokusert på neiraltilnærmingar til sammendraging, som kan vera veldig data-hunger. Det finst imidlertid mange store datasett og ingen for den tradisjonelle populære domenet av vitenskapelige publikasjonar, som opnar opp vanskeleg forskningsavener sentrert på koding av store, komplekse dokument. I denne papiret introduserer vi ei ny dataset for samansering av datavitenskap ved å bruka eit stor ressurs av autoren som har tilgjengelege samanseringar og vise enkelt måtar å utvide det framover. Vi utviklar modeller på datasettet som brukar både neuralteiknkodingar og tradisjonell bruka samanseringsfunksjonar og viser at modeller som kodar setningar og lokale og globale kontekstar utfører best, som utfører godt fastleggte baselinjesmetodar.', 'pl': 'Automatyczne podsumowanie to popularne podejście do zredukowania dokumentu do jego głównych argumentów. Ostatnie badania w tym obszarze koncentrowały się na neuronowym podejściu do podsumowania, które może być bardzo głodne danych. Istnieje jednak niewiele dużych zbiorów danych i żaden nie jest dla tradycyjnie popularnej domeny publikacji naukowych, co otwiera wymagające ścieżki badawcze skupione na kodowaniu dużych, złożonych dokumentów. W niniejszym artykule przedstawiamy nowy zestaw danych służący do podsumowania publikacji informatycznych poprzez wykorzystanie dużego zasobu podsumowań autorskich i pokazujemy proste sposoby jego dalszego rozszerzenia. Opracowujemy modele na zbiorze danych wykorzystujące zarówno kodowanie zdań neuronowych, jak i tradycyjnie stosowane funkcje podsumowania i pokazujemy, że modele kodujące zdania, jak i ich lokalny i globalny kontekst działają najlepiej, znacząco przewyższające ugruntowane metody bazowe.', 'sr': 'Automatski sažetak je popularan pristup smanjivanju dokumenta do glavnih argumenata. Nedavno istraživanje u području fokusiralo se na neuralne pristupe sažetaciji, što može biti gladno podacima. Međutim, nekoliko velikih podataka postoji i nijedna za tradicionalno popularnu domenu naučnih publikacija, koja otvara izazovne istraživačke avente usredotočene na kodiranje velikih, kompleksnih dokumenta. U ovom papiru predstavljamo novi set podataka za sažetak publikacija kompjuterske nauke koristeći veliki resurs autora koji je pružio sažetke i pokazujemo jednostavne načine da ga produže dalje. Razvijamo modele na setu podataka koji koriste i kodiranje neuralne rečenice i tradicionalno korištenje sažetke i pokazujemo da modeli koji kodiraju rečenice, kao i njihov lokalni i globalni kontekst najbolje izvršavaju, značajno iznosi dobro uspostavljene metode početne linije.', 'ro': 'Rezumatul automat este o abordare populară pentru a reduce un document la argumentele sale principale. Cercetările recente din acest domeniu s-au concentrat pe abordările neurale ale rezumatului, care pot fi foarte consumatoare de date. Cu toate acestea, există puține seturi de date mari și niciuna pentru domeniul tradițional popular al publicațiilor științifice, ceea ce deschide căi de cercetare provocatoare centrate pe codificarea documentelor mari și complexe. În această lucrare, introducem un nou set de date pentru rezumarea publicațiilor informatice prin exploatarea unei resurse mari de rezumate furnizate de autor și prezentăm modalități simple de extindere a acestuia în continuare. Dezvoltăm modele pe setul de date utilizând atât codarea frazelor neurale, cât și caracteristicile de rezumare utilizate în mod tradițional și arătăm că modelele care codează frazele, precum și contextul lor local și global performează cel mai bine, depășind semnificativ metodele de bază bine stabilite.', 'si': 'ස්වයංක්\u200dරීය සංවේදනය තමයි ලොකුණු ප්\u200dරධාන ප්\u200dරතිචාරයක් අඩංගුවන්න ලොකුණු ප්\u200dරති මේ ප්\u200dරදේශයේ අලුත් පරීක්ෂණය ප්\u200dරවේශනය කරලා තියෙන්නේ න්\u200dයූරාල් ප්\u200dරවේශනය සඳහා, ඒක ගොඩක් දත්ත බඩග නමුත්, ලොකු දත්ත සේට් ටිකක් තියෙන්නේ නැහැ ඒ වගේම විද්\u200dයාත්මක ප්\u200dරකෘතිපත්තියේ සාමාන්\u200dය ප්\u200dරකෘතිපත්තිය සඳහා ප්\u200d මේ පත්තරේ අපි අළුත් දත්ත සූදානයක් පරිගණක විද්\u200dයාව ප්\u200dරකාශනය සඳහා අළුත් දත්ත සූදානයක් ප්\u200dරවේශනය කරනවා, ලේඛකයේ ලොකු  අපි දත්ත සූදානයේ මොඩේල් විස්තර කරනවා නියරල් වාක්ය සංකේතනය සහ ප්\u200dරමාණයෙන් භාවිත කරනවා සංකේතනය සමග ස්ථානික සහ ජාතික සංකේතය හොඳම ව', 'so': 'Si gaar ah loo soo bandhigayo waa qaab maamuus ah in dukumenti uu ku hoosaysiiyo arrimaha ugu muhiimsan. Baaritaanka ugu dambeeyay ee magaalada waxay focus ugu leedahay soo dhowaanshada naafada, kaas oo aad u gaajaysan kara macluumaadka. Si kastaba ha ahaatee waxaa jira dhawr kooban macluumaad oo waaweyn, mana jiraan meelaha caadiga ah ee baaritaanka cilmi-qaadashada, taas oo furan qaabilsan baaritaanka waxbarashada oo ku qoran qoraalka warqadaha waaweyn oo adag. Qoraalkan waxaynu ku soo bandhignaa sawir cusub oo lagu soo qorayo baaritaanka cilmiga kombiyuutarka, si aan ugu isticmaalno macluumaad aad u badan oo qoraal ah oo uu soo diro xagaas, si toos ah ayaannu u tusno wadooyin aad u sii wado. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.', 'sv': 'Automatisk sammanfattning är ett populärt tillvägagångssätt för att reducera ett dokument till dess huvudsakliga argument. Ny forskning inom området har fokuserat på neurala metoder för sammanfattning, som kan vara mycket datahungriga. Det finns dock få stora datamängder och inga för den traditionellt populära domänen vetenskapliga publikationer, vilket öppnar upp utmanande forskningsvägar centrerade om kodning av stora, komplexa dokument. I denna uppsats introducerar vi en ny datauppsättning för sammanfattning av datavetenskapliga publikationer genom att utnyttja en stor resurs författartillhandahållna sammanfattningar och visa enkla sätt att utöka den ytterligare. Vi utvecklar modeller på datauppsättningen med hjälp av både neural meningskodning och traditionellt använda sammanfattningsfunktioner och visar att modeller som kodar meningar samt deras lokala och globala sammanhang presterar bäst, betydligt bättre än väl etablerade baslinjemetoder.', 'ta': 'தானியங்கி சுருக்கம் ஒரு பிரபலமான வழியாகும் ஆவணத்தை அதன் முக்கிய தருமதிப்புகளுக்கு குறைக்க. சமீபத்தில் உள்ள ஆராய்ச்சி சுருக்கத்திற்கு புதிய அணுகுகளை கவனம் செலுத்தியுள்ளது, அது மிகவும் தரவு பசிக்கும். ஆயினும், சில பெரிய தகவல் அமைப்பு இந்த காகிதத்தில், நாம் கணிப்பொறி அறிவியல் வெளியீடுகளை சுருக்க ஒரு புதிய தகவல் அமைப்பை அறிவிக்கிறோம். ஆசிரியரின் பெரிய மூலங்களை பயன்படுத்த நாம் தரவுத்தளத்தின் மாதிரிகளை உருவாக்குகிறோம் புதிய வாக்கியத்தின் குறியீட்டு மற்றும் மரபாரியமாக பயன்படுத்தப்பட்ட சுருக்கு தன்மைகளை பயன்படுத்துகிறது மற்று', 'ur': 'سٹوکیٹ کرنا ایک محبوب طریقہ ہے کہ ایک دفتر کو اس کی اصلی ارجментوں میں کم کرے۔ اس منطقه میں اچھی تحقیقات کا ذریعہ ذخیره کرنے کے لئے نورول کی طریقے پر ہے، جو بہت بھوک ہے۔ لیکن تھوڑے بڑے ڈاٹ سٹ موجود ہیں اور سائنس پوسٹ کے سائنس ڈومین کے لئے کوئی نہیں ہے جو بڑے، پیچیدہ ڈوکینٹ کے ذریعہ منزل کے مطابق مشکل تحقیق رستوں کو کھولتا ہے۔ اس کاغذ میں ہم نے کمپیوٹر سائنس پیغامات کے ذریعے ایک نئی ڈیٹ سٹ کو معرفی کر دیا ہے کہ ایک بڑے سرمایہ کا استعمال کریں اور اسے اضافہ کرنے کے لئے سیدھے طریقے دکھائیں۔ ہم نے ڈیٹ سٹ پر موڈل ڈھیلاتے ہیں جو نئورل جماعت اکنوڈینگ اور سنتی طور پر استعمال کئے جاتے ہیں اور ان کی موڈل کو دکھاتے ہیں جو جماعت اور ان کی محلی اور جہالت کنٹنسٹ سب سے بہتر کرتی ہیں، بہت اچھی طریقہ سے استعمال کئے جاتے ہیں.', 'uz': "Hujjatni asosiy argumentlarga kamaytirish uchun avtomatik hisoblash. Yaqinda taʼminlovchi taʼminotlar esa tahrirlash uchun neyural murakkablariga foydalanadi. Bu ma'lumot juda ko'proq yurak bo'lishi mumkin. Шундай қилиб, жумладан кўп катта маълумотлар маълумотлар мавжуд ва одатда маълумот тааллуқли маълумотларнинг доментлари мавжуд эмас. Бу маълумот маълумотлари катта, complex ҳужжатларни рамз қилишга мажбур қилинади. Bu hujjatda biz kompyuterning ilmiy nashriyotlarni qisqarish uchun yangi maʼlumot satrini ishlatamiz. Mualliflar juda katta qisqartmalar yordamida ko'paytirish va uni tezlashtirish uchun yaxshi usullarni koʻrsatish. Biz bir nechta maxfiy soʻz kodlash imkoniyatlaridan foydalanish uchun maʼlumot set modellarini yaratishmiz va oddiy hisoblanish imkoniyatlaridan foydalanish mumkin va maxfiy soʻzlarni kodlash va lokal va dunyo muhimkoniyatlarini bajarish modellarini koʻrsatish mumkin, juda ham yaxshi oʻrnatilgan baseline usullarini bajarish mumkin.", 'vi': 'Bản tóm tắt tự động là một phương pháp phổ biến để đưa tài liệu vào các lý luận chính. Nghiên cứu gần đây đã tập trung vào các phương pháp thần kinh để tóm tắt, có thể rất đói dữ liệu. Tuy nhiên, có rất ít dữ liệu lớn tồn tại và không có gì cho lĩnh vực thường được phổ biến trong các tạp chí khoa học, mở ra những tuyến đường nghiên cứu đầy thử thách được tập trung vào việc mã hóa các tài liệu lớn phức tạp. Trong tờ giấy này, chúng tôi sẽ đưa ra một tập tin mới để tóm tắt các tạp chí khoa học máy tính bằng cách sử dụng một nguồn đầy đủ tác giả cung cấp các bản tóm tắt và chỉ ra các cách đơn giản để mở rộng nó hơn. Chúng tôi phát triển các mô hình trên bộ dữ liệu, sử dụng cả những tính năng cấu hình dây thần kinh và sử dụng các tính năng tổng hợp truyền thống, và cho thấy những mẫu mã hóa câu, cũng như ngữ cảnh địa phương và toàn cầu của chúng làm việc tốt nhất, khả năng đạt được các phương pháp cơ bản đã được.', 'nl': 'Automatische samenvatting is een populaire benadering om een document te reduceren tot zijn belangrijkste argumenten. Recent onderzoek op dit gebied heeft zich gericht op neurale benaderingen van samenvatting, die zeer datahongerig kunnen zijn. Er bestaan echter weinig grote datasets en geen voor het traditioneel populaire domein van wetenschappelijke publicaties, wat uitdagende onderzoekswegen opent gericht op het coderen van grote, complexe documenten. In dit artikel introduceren we een nieuwe dataset voor het samenvatten van computerwetenschappelijke publicaties door gebruik te maken van een grote bron van door de auteur verstrekte samenvattingen en tonen we eenvoudige manieren om deze verder uit te breiden. We ontwikkelen modellen op de dataset die gebruik maken van zowel neurale zinscodering als traditioneel gebruikte samenvattingsfuncties en laten zien dat modellen die zinnen coderen evenals hun lokale en globale context het beste presteren en aanzienlijk beter presteren dan gevestigde basismethoden.', 'bg': 'Автоматичното обобщаване е популярен подход за намаляване на документа до основните му аргументи. Последните изследвания в областта са фокусирани върху невронните подходи към обобщаване, което може да бъде много жадно за данни. Въпреки това съществуват малко големи набори от данни и нито един за традиционно популярната област на научните публикации, което отваря предизвикателни изследователски пътища, съсредоточени върху кодирането на големи, сложни документи. В тази статия ние въвеждаме нов набор от данни за обобщаване на публикациите по компютърни науки чрез използване на голям ресурс от авторски предоставени резюмета и показваме лесни начини за неговото разширяване. Разработваме модели на набора от данни, използващи както невронно кодиране на изречения, така и традиционно използвани функции за обобщаване, и показваме, че моделите, които кодират изречения, както и техният местен и глобален контекст, се представят най-добре, значително по-добре от добре установените базови методи.', 'da': 'Automatisk opsummering er en populær tilgang til at reducere et dokument til dets vigtigste argumenter. Nylig forskning på området har fokuseret på neurale tilgange til opsummering, som kan være meget datahungrende. Der findes imidlertid få store datasæt og ingen for det traditionelt populære domæne af videnskabelige publikationer, hvilket åbner op for udfordrende forskningsmuligheder centreret om kodning af store, komplekse dokumenter. I denne artikel introducerer vi et nyt datasæt til sammenfatning af edb-videnskabelige publikationer ved at udnytte en stor ressource af forfatter leverede resuméer og vise enkle måder at udvide det yderligere. Vi udvikler modeller på datasættet ved hjælp af både neural sætningskodning og traditionelt anvendte opsummeringsfunktioner og viser, at modeller, der koder sætninger såvel som deres lokale og globale kontekst, klarer sig bedst og overgår væsentligt veletablerede basismetoder.', 'hr': 'Automatski sažetak je popularan pristup smanjivanju dokumenta do glavnih argumenata. Nedavno istraživanje u području usredotočilo se na neurološke pristupe sažetaciji, što može biti gladno podacima. Međutim, postoje nekoliko velikih podataka i nijedna za tradicionalno popularnu domenu znanstvenih publikacija, koja otvara izazovne istraživačke avente usmjerene na kodiranje velikih, složenih dokumenta. U ovom papiru predstavljamo novi set podataka za sažetak publikacija računalnih nauka iskorištavajući veliki izvor autora pružajući sažetke i pokazujemo jednostavne načine da ga produže dalje. Mi razvijamo modele na setu podataka koji koriste i kodiranje neuralnih rečenica i tradicionalno korištenje sažetka i pokazujemo da modeli koji kodiraju rečenice, kao i njihov lokalni i globalni kontekst najbolje izvršavaju, značajno iznosi dobro uspostavljene osnovne metode.', 'de': 'Automatische Zusammenfassung ist ein beliebter Ansatz, um ein Dokument auf seine Hauptargumente zu reduzieren. Jüngste Forschungen auf diesem Gebiet konzentrieren sich auf neuronale Zusammenfassungsansätze, die sehr datenhungrig sein können. Allerdings existieren nur wenige große Datensätze und keine für den traditionell populären Bereich wissenschaftlicher Publikationen, was herausfordernde Forschungsansätze eröffnet, die sich auf die Kodierung großer, komplexer Dokumente konzentrieren. In diesem Beitrag stellen wir einen neuen Datensatz für die Zusammenfassung von informatischen Publikationen vor, indem wir eine große Ressource von autorengestellten Zusammenfassungen nutzen und zeigen einfache Wege auf, diesen weiter zu erweitern. Wir entwickeln Modelle auf dem Datensatz, die sowohl neuronale Satzkodierung als auch traditionell verwendete Zusammenfassungsfunktionen verwenden und zeigen, dass Modelle, die Sätze sowie ihren lokalen und globalen Kontext kodieren, am besten abschneiden und etablierte Basismethoden deutlich übertreffen.', 'id': 'Persingkatan otomatis adalah pendekatan populer untuk mengurangi dokumen ke argumen utamanya. Penelitian baru-baru ini di daerah ini telah fokus pada pendekatan saraf untuk ringkasan, yang bisa sangat lapar data. Namun, beberapa set data besar ada dan tidak ada untuk bidang tradisional populer publikasi ilmiah, yang membuka tantangan jalur penelitian yang fokus pada pengekodan dokumen besar, kompleks. Dalam kertas ini, kami memperkenalkan set data baru untuk mempersingkatkan publikasi ilmu pengetahuan komputer dengan mengeksploitasi sumber daya besar penulis yang memberikan ringkasan dan menunjukkan cara sederhana untuk memperluasnya lebih lanjut. Kami mengembangkan model pada dataset yang menggunakan kedua pengkodisan kalimat saraf dan karakteristik pengsingkatan tradisional yang digunakan dan menunjukkan bahwa model yang mengekodisan kalimat serta konteks lokal dan global mereka melakukan yang terbaik, yang jauh melebihi metode dasar yang ditetapkan dengan baik.', 'sw': 'Ujumbe wa moja kwa moja ni njia maarufu ya kupunguza nyaraka kwa hoja zake za msingi. Utafiti wa hivi karibuni katika eneo hilo umejikita kwenye mbinu za uraia za muhtasari, ambazo zinaweza kuwa na njaa sana. Hata hivyo, seti chache kubwa za taarifa zinapo na hakuna kwa ajili ya maeneo maarufu ya kitamaduni ya chapisho za kisayansi, ambayo inafungua vipengele vya utafiti vinavyohusiana na kupunguza nyaraka kubwa, magumu. Katika karatasi hii, tunaonyesha seti mpya ya taarifa za muhtasari wa kuchapishwa kwa masuala ya sayansi za kompyuta kwa kutumia rasilimali kubwa ya mwandishi wa kipindi cha muhtasari na kuonyesha njia moja kwa moja ya kupanua zaidi. Tunaweza kutengeneza mifano kwenye seti ya taarifa inayotengeneza matumizi ya kodi ya hukumu ya kijamii na kutumika vipengele vya muhtasari vya kawaida na kuonyesha mifano ambayo hujumuisha hukumu pamoja na mazingira yao ya kimataifa yanafanya vizuri zaidi, kwa kiasi kikubwa kufanya mbinu za msingi zilizotengenezwa vizuri.', 'ko': '자동 요약은 문서를 주요 논점으로 간소화하는 데 자주 사용하는 방법이다.이 분야의 최신 연구는 총괄적인 신경 방법에 집중되어 있어 데이터가 필요할 수도 있다.그러나 대형 데이터 집합은 거의 존재하지 않고 전통적으로 유행하는 과학 출판물 분야에도 대형 데이터 집합이 없기 때문에 대형 복잡한 문서를 인코딩하는 것을 중심으로 하는 연구에 도전적인 경로를 열었다.본고에서 우리는 대량의 저자가 제공한 요약 자원을 이용하여 새로운 컴퓨터 과학 출판물 요약 데이터 집합을 소개하고 이를 더욱 확장하는 간단한 방법을 보여 주었다.우리는 신경 문장 인코딩과 전통적으로 사용된 정리 기능을 이용하여 데이터 집합에서 모델을 개발했고 문장과 그 국부와 전역의 상하문을 인코딩하는 모델이 성숙한 기선 방법보다 현저히 우수하다는 것을 나타냈다.', 'sq': 'Përshkrimi automatik është një qasje popullore për të reduktuar një dokument në argumentet kryesore të tij. Kërkimet e fundit në këtë fushë janë përqëndruar në qasjet nervore të përmbledhjes, e cila mund të jetë shumë e uritur nga të dhënat. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents.  Në këtë letër, ne paraqesim një grup të ri të dhënash për përmbledhjen e publikimeve të shkencës kompjuterike duke shfrytëzuar një burim të madh të autorëve të dhëna përmbledhje dhe tregojmë mënyra të thjeshta për të zgjeruar atë më tej. Ne zhvillojmë modele në grupin e të dhënave duke përdorur si kodimin e fjalëve nervore ashtu edhe karakteristikat e përmbledhjes së përdorura tradicionalisht dhe tregojmë se modelet që kodojnë fjalët si dhe kontekstin lokal dhe global të tyre bëjnë më të mira, duke kaluar ndjeshëm metodat bazë të vendosura mirë.', 'af': "Outomatiese opsomming is 'n populêre toegang om 'n dokument na sy hoof argumente te verminder. Onlangste verondersoek in die area het gefokus op neurale toegang tot opsomming, wat baie data-honger kan wees. Maar sommige groot datastelle bestaan en geen vir die tradisioneel populêre domein van wetenskaplike publikasies nie, wat oopgemaak die pragtige ondersoek avenue wat op die enkodering van groot, komplekse dokumente gesentreer is nie. In hierdie papier, introduseer ons 'n nuwe datastel vir opsomming van rekenaar wetenskaplike publikasies deur 'n groot hulpbron van outeur verskaf opsommings te gebruik en eenvoudige maniere om dit verder te verleng. Ons ontwikkel modele op die datastel wat gebruik word van beide neurale setkodering en tradisioneel gebruik is opsomming funksies en wys dat modele wat teikens enkodeer en hul plaaslike en globale konteks beste uitvoer, betekenlik uitvoer goed-geïnstalleerde basisline metodes.", 'tr': 'Senediň esasy argümlerine azaltmak üçin awtomatik duşurmekdir. Ýakyndaky araştyrmalar, jemgyýetleşme üçin när ýagdaýlary üçin üns berildi. Bu ýagdaýda örän aç bolup biler. Ýagna görä birnäçe uly maglumat setirleri bar we däpli uly, karmaşık senediň ködlemeleri üçin hiç hili meňzeşli bilim publikalaryň domaýynda däl däldir. Bu kagyzda, kompýuter bilimi publikasynyň hulatyny çaplanmak üçin täze bir dataseti girdirip, täze bir awtor jemgyýetlerini ulanarak we muny daal äpli uzatmak üçin ullanýarys. Munuň üçin data setirinde örnekler gelişýäris. Näyral sözlerin kodlemesini hem däpli işleýän jemgyýetleme karakterlerden ullanýar we sözlerin, ýerli we dünýädäki kontekstleriniň gowydygyny çykarýan nusgalaryň gowydygyny görkez.', 'hy': 'Ավտոմատիկ համառոտագրությունը հայտնի մոտեցում է փաստաթղթի հիմնական բանավեճերի կրճատման համար: Այս ոլորտում վերջին հետազոտությունները կենտրոնացել են համառոտագրման նյարդային մոտեցումների վրա, որոնք կարող են շատ քաղցած լինել տվյալներով: Այնուամենայնիվ, կան մի քանի մեծ տվյալների համակարգեր և ոչ մի համակարգ գիտական հրատարակությունների ավանդական հայտնի ոլորտում, որը բացում է դժվար հետազոտության ուղիներ, որոնք կենտրոնացված են մեծ, բարդ փաստաթղթերի կոդավորման վրա: Այս աշխատանքում մենք ներկայացնում ենք համակարգչային գիտության հրատարակությունների համառոտագրման նոր տվյալների համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային ռեսուրսը օգտագործելով հեղինակի մեծ ռեսուրսը, որը տրամա Մենք զարգանում ենք տվյալների համակարգի մոդելներ, որոնք օգտագործում են նաև նյարդային նախադասությունների կոդավորումը, ինչպես նաև ավանդական օգտագործված համառոտագրման հատկությունները, և ցույց են տալիս, որ մոդելները, որոնք կոդավորում են նախադասությունները, ինչպես նաև նրանց տեղական և գլոբալ կո', 'fa': 'تعداد خودکار یک روش محبوب برای کاهش یک سند به دلیل اصلی آن است. تحقیقات اخیرا در این منطقه روی دسترسی عصبی برای جمع کردن تمرکز شده است که می تواند خیلی گرسنه اطلاعات باشد. با این حال، چند مجموعه داده\u200cهای بزرگ وجود دارد و هیچ یک از مجموعه\u200cهای منتشر علمی را برای منتشر کردن مدارک بزرگ و پیچیده\u200cای ندارد. در این کاغذ، ما یک مجموعه اطلاعات جدید برای جمع کردن آهنگ علم کامپیوتر با استفاده از یک منبع بزرگ نویسنده\u200cای که جمع\u200cآوری\u200cها را پیشنهاد کرده\u200cاند، معرفی می\u200cکنیم و راه\u200cهای ساده\u200cای برای آن بیشتر گسترش دادن را ما مدل\u200cهایی را روی مجموعه\u200cهای داده\u200cها توسعه می\u200cکنیم که با استفاده از رمزبندی کردن جمله\u200cهای عصبی و به طور سنتی از ویژه\u200cهای جمع\u200cآوری استفاده می\u200cکنند و نشان می\u200cدهیم که مدل\u200cهایی که جمله\u200cها و محیط محلی و جهانی\u200cشان بهترین عمل می\u200cکنند، به طور', 'az': 'Vəsanı ana argumentlərinə azaltmaq üçün avtomatik təmizləmə məşhur bir tərzidir. Bu bölgedəki son araştırmalar təmizlənmək üçün nöral yaxınlıqlarına odaqlanmışdır, bu çox verilər aç olar. Ancaq çox böyük verilən qurğular mövcud deyildir və elmi yayınlıqların nəticə edilməsi üçün heç kəs yoxdur ki, böyük, kompleks xətaların kodlaması üzərində çətin araştırma yollarını açar. Bu kağızda, kompjuter elmi yayınlıqlarının qeyd edilməsi üçün yeni verilən qurğunu təşkil edirik, yazarın böyük çoxluğunu istifadə edərək və onu daha çox uzatmaq üçün düzgün yolları göstəririk. Biz məlumatların qovluğunda modelləri təhsil edirik ki, nöral cümlələr kodlamasını və nəticə olaraq istifadə edir və cümlələri kodlayan modellərin və yerli və küresel məlumatlarının ən yaxşı işlədiklərini göstərir, çox yaxşı təhsil çəkilən təhsil metodlarının istifadəsindən daha yaxşı.', 'bs': 'Automatski sažetak je popularan pristup smanjivanju dokumenta do glavnih argumenata. Nedavno istraživanje u području usredotočilo se na neuralne pristupe sažetaciji, što može biti gladno podacima. Međutim, postoje nekoliko velikih podataka i nijedna za tradicionalno popularnu domenu naučnih publikacija, koja otvara izazovne istraživačke avente usmjerene na kodiranje velikih, kompleksnih dokumenta. U ovom papiru predstavljamo novi set podataka za sažetak publikacija kompjuterske nauke koristeći veliki resurs autora koji je pružio sažetke i pokazujemo jednostavne načine da ga produže dalje. Razvijamo modele na setu podataka koji koriste i kodiranje neuralnih rečenica i tradicionalno korištenje rezimetriranih karakteristika i pokazujemo da modeli koji kodiraju rečenice, kao i njihov lokalni i globalni kontekst najbolje izvode, značajno iznosi dobro uspostavljene osnovne metode.', 'ca': "El resum automàtic és un enfocament popular per reduir un document als seus arguments principals. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry.  No obstant això, hi ha pocs grans conjunts de dades i cap del domini tradicionalment popular de publicacions científices, que obre avenyes de recerca desafiables centrades en codificar grans i complexes documents. En aquest article introduim un nou conjunt de dades per a resumir publicacions de ciències informàtiques explotant un gran recurso d'autors proporcionant resumes i mostrant maneres senzilles d'estendre-la més endavant. Desenvolvem models en el conjunt de dades que utilitzen tant la codificació de frases neurals com les característiques de resum tradicionalment utilitzades i mostren que els models que codifiquen frases com el seu contexte local i mundial actuen millor, superant significativament els mètodes de base ben estables.", 'cs': 'Automatické shrnutí je oblíbeným přístupem k redukci dokumentu na jeho hlavní argumenty. Nedávný výzkum v této oblasti se zaměřil na neuronové přístupy k shrnutí, které mohou být velmi hladové na data. Nicméně existuje málo velkých datových souborů a žádný pro tradičně populární doménu vědeckých publikací, což otevírá náročné výzkumné cesty zaměřené na kódování velkých a složitých dokumentů. V tomto článku představujeme nový datový soubor pro shrnutí informatických publikací s využitím velkého zdroje autorských souhrnů a ukazujeme jednoduché způsoby jeho dalšího rozšíření. Vyvíjíme modely na datové sadě s využitím neuronového kódování vět i tradičně používaných souhrnných funkcí a ukazujeme, že modely, které kódují věty, stejně jako jejich lokální a globální kontext, významně překonávají zavedené základní metody.', 'et': 'Automaatne kokkuvõte on populaarne lähenemisviis dokumendi peamiste argumentideni vähendamiseks. Hiljutised uuringud selles valdkonnas on keskendunud neuronaalsetele lähenemisviisidele kokkuvõtlikuks tegemiseks, mis võib olla väga andmevajalik. Siiski on olemas vähe suuri andmekogumeid ja mitte ühtegi traditsiooniliselt populaarse teadusväljaannete valdkonna jaoks, mis avab keerulisi uurimisvõimalusi, mis keskenduvad suurte ja keerukate dokumentide kodeerimisele. Käesolevas töös tutvustame uut andmekogumit arvutiteaduse väljaannete kokkuvõtlikuks kokkuvõtteks, kasutades suurt ressurssi autori esitatud kokkuvõtteid ja näitame lihtsaid viise seda edasi laiendada. Töötame välja andmekogumi mudelid, mis kasutavad nii neuraalset lausekodeerimist kui ka traditsiooniliselt kasutatavaid kokkuvõtlusfunktsioone, ning näitame, et lauseid kodeerivad mudelid ning nende kohalik ja globaalne kontekst on parimad, ületades märkimisväärselt väljakujunenud lähtemeetodeid.', 'bn': 'স্বয়ংক্রিয়ভাবে সংক্রান্ত সংক্রান্ত সংক্রান্ত একটি জনপ্রিয় পদ্ধতি তার প্রধান যুক্তির মধ্যে একটি  এই এলাকার সম্প্রতি গবেষণা সংক্ষেপের প্রতি নিউরেল কাছে মনোযোগ দিয়েছে, যা খুব তথ্য-ক্ষুধার্ত। However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents.  এই কাগজটিতে আমরা কম্পিউটার বিজ্ঞান প্রকাশনার সারসংক্ষেপের জন্য একটি নতুন ডাটাসেট পরিচয় করিয়ে দেখাচ্ছি লেখকের একটি বিশাল সম্পদ ব্যবহার করে সারসারিক আমরা ডাটাসেটের মডেল তৈরি করি নিউরেল বাক্য এনকোডিং ব্যবহার করে এবং ঐতিহ্যবাহীতভাবে সংক্ষিপ্ত বৈশিষ্ট্য ব্যবহার করে এবং দেখাচ্ছি যে মডেল যে কোন বাক্য এনকোডের বি', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s በአካባቢው ውስጥ የቀድሞው ምርጫዎች የደዌብ መቃወሚያ ላይ አሰብቷል፡፡ ነገር ግን ጥቂት ትልቁ ዳታተሮች አሉ፣ ለባሕላዊ የሳይንቀሳዊ ፕሬጀክቶች የፍትሕት ግንኙነት ማንም የለም፤ ይህ ትልቅ፣ ትክክለኛ ሰነድ ማቀናጃ ማቀናቀል የተደረገ የጥናት ተቃውሞ የሚከፍት ነው፡፡ በዚህ ካላት አዲስ የኮምፒዩተር የሳይንስ ፕሬጀክቶችን ለማሳየት አዲስ ዳታተር ማሳየትን እናሳየዋለን፡፡ የናውሬው የሥርዓት ቃላት የኮድ ክፍተት እና ባሕላዊ ማሳሰል የተጠቀም እና ቃላትን እና የአገራዊ እና የዓለማዊ ግንኙነታቸውን በመጠቀም እናሳያቸዋለን፡፡", 'fi': 'Automaattinen yhteenveto on suosittu tapa vähentää asiakirja sen pääasiallisiin argumentteihin. Viimeaikaiset tutkimukset alueella ovat keskittyneet hermostollisiin lähestymistapoihin yhteenvetoon, joka voi olla hyvin datanälkäinen. Suuria aineistoja on kuitenkin vain vähän, eikä niitä ole perinteisesti suositulle tieteelliselle julkaisualueelle, mikä avaa haastavia tutkimusväyliä suurten ja monimutkaisten asiakirjojen koodaamiseen. Tässä artikkelissa esittelemme uuden tietoaineiston tietojenkäsittelytieteellisten julkaisujen yhteenvetoon hyödyntämällä suurta resurssia tekijän toimittamia yhteenvetoja ja näyttää yksinkertaisia tapoja laajentaa sitä edelleen. Kehitämme aineistoon malleja, joissa hyödynnetään sekä neurolausekoodausta että perinteisesti käytettyjä yhteenvetoominaisuuksia ja osoitetaan, että lauseita koodaavat mallit sekä niiden paikallinen ja maailmanlaajuinen konteksti suoriutuvat parhaiten, merkittävästi paremmin kuin vakiintuneet perusmenetelmät.', 'jv': 'Cumulate Fine politenessoffpolite"), and when there is a change ("assertivepoliteness and punctuation Nang pepulan iki, kita mulai data set nggawe tarjamahan kanggo resumen siéntasi komputer Awak dhéwé nggunakake model ning dataset kuwi nggawe sistem dadi nggawe winih dhéwé kuwi nggawe winih dhéwé kuwi perintahaan empahan lan nambah dhéwé modèl sing kodahan ceduluran lan akeh dumadhi tanggal gawe nguasal dhéwé, akeh dumadhi dianggawe barang-sistem sing isin akeh dum', 'sk': 'Samodejno povzemanje je priljubljen pristop k zmanjšanju dokumenta na glavne argumente. Nedavne raziskave na tem področju so se osredotočile na nevralne pristope k povzetku, ki so lahko zelo potrebni podatkov. Vendar pa obstaja le malo velikih naborov podatkov in nobenih za tradicionalno priljubljeno področje znanstvenih publikacij, kar odpira zahtevne raziskovalne poti, osredotočene na kodiranje velikih, kompleksnih dokumentov. V prispevku predstavljamo nov nabor podatkov za povzetek publikacij računalništva z izkoriščanjem velikega vira avtorskih povzetkov in prikazujemo enostavne načine za njegovo nadaljnjo razširitev. Na naboru podatkov razvijamo modele, ki uporabljajo tako nevronsko kodiranje stavkov kot tradicionalno uporabljene funkcije povzetka, in pokažemo, da modeli, ki kodirajo stavke, kot tudi njihov lokalni in globalni kontekst, delujejo najbolje, saj znatno presegajo dobro uveljavljene osnovne metode.', 'he': 'הסכם אוטומטי הוא גישה פופולרית כדי להפחית מסמך לטיעונים העיקריים שלו. מחקר לאחרונה באזור התמקד על גישות עצביות לסיוריזציה, אשר יכול להיות רעב מאוד בנתונים. בכל אופן, מעט קבוצות מידע גדולות קיימות ואף אחד מהם לתחום המפורסם המסורתי של פרסומות מדעיות, אשר פותח דרכים מחקרים מאתגרים המרכזים על הקוד מסמכים גדולים וממורכבים. בעיתון הזה, אנחנו מציגים קבוצת נתונים חדשה לסיוריזציה של פרסומות מדע המחשב על ידי ניצל משאב גדול של סופר סיפק סדרות ותראה דרכים פשוטות להאריך אותו יותר. אנחנו מפתחים דוגמנים על קבוצת הנתונים שמשתמשים גם בקוד משפטים עצביים ושימושים במסורתית בתאמות ומראים שדוגמנים שמקודים משפטים כמו גם הקשר המקומי והגלובלי שלהם מבצעים את שיטות הבסיס המבוססות ביותר, שיוצאות יותר משמעותיות.', 'ha': "@ action: button Tafiti na nan a yanzu, yana zura makiyar hanyõyin neura zuwa ga kurarin, wanda za'a iya zama masu hasara da data-yunwa. A lokacin da, akwai kodi kaɗan na takardar data masu girma kuma bãbu wani wa'yan damisar da aka sani, wanda ke buɗe masu buɗaɗãwa na fassarar research masu ƙaranci a tsakanin kodi babban, takardar murakku. Ga wannan takardan, Munã ƙara wani sabo na takardar da aka ƙayyade fassarar masu da aka sani na kwamfyuta don mu yi amfani da amfani mai girma na marubuci wanda ya samar da shi na ƙari kuma mu nuna hanya madaidaiciya ta ƙara. Tuna buɗe masu motsi a kan daidaita danne da za'a yi amfani da kodi na cewa kodi na ruburar da kuma a nuna misãlai masu amfani da shiryoyin ƙararrawa da ke amfani da shi a ƙidãya, kuma masu nuna misãlai da ke kode saurãren kwanan da ke sami muhimmanci a lokacin da ke cikin mazaɓa, kuma masu cika hanyoyin rubutun da aka daidaita.", 'bo': 'རང་འགུལ་གྱི་བཅུད་སྡུད་དེ་ཡིག་ཆ་རང་ཉིད་ཀྱི་རྩ་བའི་སྒྲུབ་རྟགས་ལ་ཉེན་ཁ་གཏོང་བ་ཞིག་རེད། དབུལ་ཁུལ་ནང་གི་ལྟ་ཞིབ་འདིས་མཐུན་སྣེ་ཚོར་བ་སྐྱེན་པའི་མཐུན་རྐྱེན་དུ་དམིགས་བསལ་བྱས། ཡིན་ནའང་མི་ཆེས་ཀྱི་གནད་སྡུད་ཆེ་བའི་ཆ་འཕྲིན་གྲངས་ཀ་ལས་རྒྱུན་ལྡན་ཡོད་མེད་པར། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་རྩིས་འཁོར་གྱི་ཆ་རྩལ་བ་མང་ཆེ་བའི་རྩོམ་པ་པོ་ཞིག་གི་མཛུབ་སྐྱེས་ཚོགས་གསར་བ་ཞིག་སྟོན་ ང་ཚོས་རང་ཉིད་ཀྱི་ཡིག་ཆ་སྒྲིག་ཆ་ལག་ལེན་འཐབ་པའི་མིག་གཟུགས་རིས་ལག་ལེན་འཐབ'}
{'en': 'An Automatic Approach for Document-level Topic Model Evaluation', 'ar': 'نهج تلقائي لتقييم نموذج موضوع على مستوى المستند', 'pt': 'Uma abordagem automática para avaliação de modelo de tópico em nível de documento', 'es': 'Un enfoque automático para la evaluación de modelos de temas a nivel de documento', 'fr': "Une approche automatique pour l'évaluation de modèles de sujets au niveau du document", 'ja': '文書レベルのトピックモデル評価のための自動アプローチ', 'ru': 'Автоматический подход к оценке тематической модели на уровне документа', 'zh': '一以文档主题模评自法', 'hi': 'दस्तावेज़-स्तर विषय मॉडल मूल्यांकन के लिए एक स्वचालित दृष्टिकोण', 'ga': 'Cur Chuige Uathoibríoch maidir le Meastóireacht ar Shamhaltú Topaicí ar leibhéal an Doiciméid', 'ka': 'Name', 'el': 'Μια αυτόματη προσέγγιση για την αξιολόγηση θεματικών μοντέλων σε επίπεδο εγγράφου', 'hu': 'Automatikus megközelítés a dokumentumszintű témakimodell értékeléséhez', 'it': 'Un approccio automatico per la valutazione dei modelli tematici a livello di documento', 'kk': 'Құжат деңгейіндегі нақыштар үлгісінің автоматты түрде қатынау', 'lt': 'Automatinis metodas dokumentų lygmens teminio modelio vertinimui', 'mk': 'An Automatic Approach for Document-level Topic Model Evaluation', 'ms': 'Name', 'ml': 'രേഖയുടെ നിലവിലുള്ള പ്രമേയ മോഡല്\u200d പരിശോധിക്കുന്നതിനുള്ള സ്വയമായി സമീപിക്കുക', 'mn': 'Документын түвшинд сэдвийн загварын үнэлэх автоматтын арга барилга', 'mt': 'Approċċ Awtomatiku għall-Evalwazzjoni tal-Mudell Topiku fil-livell tad-Dokument', 'no': 'Name', 'pl': 'Automatyczne podejście do oceny modelu tematycznego na poziomie dokumentu', 'sr': 'Automatski pristup ocjene modela na nivou dokumenta', 'ro': 'O abordare automată pentru evaluarea modelului tematic la nivel de document', 'si': 'Comment', 'so': 'Kaartaynta muuqashada dukumentiyada-level', 'sv': 'En automatisk metod för utvärdering av ämnesmodeller på dokumentnivå', 'ta': 'Comment', 'ur': 'Name', 'uz': 'Comment', 'vi': 'Định hướng tự động cho giá trị kiểu mẫu tài liệu', 'nl': 'Een automatische aanpak voor de evaluatie van onderwerpen op documentniveau', 'hr': 'Automatski pristup ocjene modela na razini dokumenta', 'bg': 'Автоматичен подход за оценка на тематичния модел на ниво документ', 'da': 'En automatisk tilgang til evaluering af emnemodel på dokumentniveau', 'fa': 'Name', 'de': 'Ein automatischer Ansatz für die Bewertung von Themenmodellen auf Dokumentenebene', 'sw': 'Upatikanaji wa Huduma kwa ajili ya Uthibitisho wa Modeli ya Madaktari', 'id': 'Pendekatan Otomatis untuk Evaluasi Model Topik Tingkat Dokumen', 'tr': 'Sened derejesi Mazmunlar', 'ko': '문서급 테마 모델 자동 평가 방법', 'af': 'Name', 'sq': 'Një metodë automatike për vlerësimin e modelit të temës në nivelin e dokumentit', 'am': 'አዲስ ዶሴ ፍጠር', 'bn': 'Comment', 'az': 'Dökümət səviyyəsi Məsələni Vəziyyətlərinin Avtomatik Yaxınlığı', 'bs': 'Automatski pristup ocjene modela na nivou dokumenta', 'et': 'Automaatne lähenemisviis dokumenditasemel teemamudeli hindamiseks', 'hy': 'Comment', 'fi': 'Automaattinen lähestymistapa asiakirjatason aihemallin arviointiin', 'ca': "Un enfocament automàtic per a l'evaluació del model de tema a nivell de document", 'cs': 'Automatický přístup k hodnocení tématických modelů na úrovni dokumentů', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Avtomatski pristop za vrednotenje tematskega modela na ravni dokumentov', 'ha': '@ action', 'he': 'An Automatic Approach for Document-level Topic Model Evaluation', 'bo': 'ཡིག་གེའི་གནས་རིམ་གྱི་གནད་དོན་དཔེ་དབྱིབས་དཔྱད་ཚད་ལ་རང་འགུལ་གྱིས་འདྲི་ཞིབ'}
{'en': 'Topic models jointly learn topics and document-level topic distribution. Extrinsic evaluation of topic models tends to focus exclusively on topic-level evaluation, e.g. by assessing the coherence of topics. We demonstrate that there can be large discrepancies between topic- and document-level model quality, and that basing model evaluation on topic-level analysis can be highly misleading. We propose a method for automatically predicting topic model quality based on analysis of document-level topic allocations, and provide empirical evidence for its robustness.', 'ar': 'تتعلم نماذج الموضوعات بشكل مشترك الموضوعات وتوزيع الموضوعات على مستوى المستند. يميل التقييم الخارجي لنماذج الموضوعات إلى التركيز حصريًا على التقييم على مستوى الموضوع ، على سبيل المثال. من خلال تقييم تناسق الموضوعات. نوضح أنه يمكن أن يكون هناك اختلافات كبيرة بين جودة النموذج على مستوى الموضوع والوثيقة ، وأن تقييم النموذج الأساسي على تحليل مستوى الموضوع يمكن أن يكون مضللاً للغاية. نقترح طريقة للتنبؤ تلقائيًا بجودة نموذج الموضوع بناءً على تحليل تخصيصات الموضوع على مستوى المستند ، ونقدم دليلًا تجريبيًا على متانته.', 'pt': 'Os modelos de tópicos aprendem tópicos em conjunto e a distribuição de tópicos em nível de documento. A avaliação extrínseca de modelos de tópicos tende a se concentrar exclusivamente na avaliação em nível de tópico, por exemplo. avaliando a coerência dos tópicos. Demonstramos que pode haver grandes discrepâncias entre a qualidade do modelo em nível de tópico e de documento, e que basear a avaliação do modelo na análise de nível de tópico pode ser altamente enganosa. Propomos um método para prever automaticamente a qualidade do modelo de tópicos com base na análise de alocações de tópicos em nível de documento e fornecemos evidências empíricas de sua robustez.', 'es': 'Los modelos de temas aprenden conjuntamente los temas y la distribución de temas a nivel de documento. La evaluación extrínseca de los modelos de temas tiende a centrarse exclusivamente en la evaluación a nivel de tema, por ejemplo, mediante la evaluación de la coherencia de los temas. Demostramos que puede haber grandes discrepancias entre la calidad del modelo a nivel de tema y de documento, y que basar la evaluación del modelo en el análisis a nivel de tema puede resultar muy engañoso. Proponemos un método para predecir automáticamente la calidad del modelo de tema basado en el análisis de las asignaciones de temas a nivel de documento, y proporcionamos evidencia empírica de su solidez.', 'fr': "Les modèles de sujets apprennent conjointement les sujets et la distribution des sujets au niveau du document. L'évaluation extrinsèque des modèles thématiques tend à se concentrer exclusivement sur l'évaluation au niveau du sujet, par exemple en évaluant la cohérence des sujets. Nous démontrons qu'il peut y avoir de grandes différences entre la qualité du modèle au niveau du sujet et du document, et que baser l'évaluation du modèle sur une analyse au niveau du sujet peut être très trompeur. Nous proposons une méthode pour prédire automatiquement la qualité du modèle de sujet sur la base de l'analyse des attributions de sujets au niveau du document, et fournissons des preuves empiriques de sa robustesse.", 'ja': 'トピックモデルは、共同でトピックとドキュメントレベルのトピック配布を学習します。トピックモデルの外因的評価は、トピックの一貫性を評価するなどして、トピックレベルの評価にのみ焦点を当てる傾向がある。トピックレベルとドキュメントレベルのモデルの品質には大きな相違があり、トピックレベルの分析に基づいたモデル評価は非常に誤解を招く可能性があることを示しています。文書レベルのトピック割り当ての分析に基づいてトピックモデルの品質を自動的に予測する方法を提案し、その堅牢性について実証的な証拠を提供します。', 'hi': 'विषय मॉडल संयुक्त रूप से विषयों और दस्तावेज़-स्तर के विषय वितरण को सीखते हैं। विषय मॉडल का बाह्य मूल्यांकन विशेष रूप से विषय-स्तर के मूल्यांकन पर ध्यान केंद्रित करता है, उदाहरण के लिए विषयों की सुसंगतता का आकलन करके। हम प्रदर्शित करते हैं कि विषय- और दस्तावेज़-स्तर मॉडल गुणवत्ता के बीच बड़ी विसंगतियां हो सकती हैं, और विषय-स्तर के विश्लेषण पर मॉडल मूल्यांकन को आधार बनाना अत्यधिक भ्रामक हो सकता है। हम दस्तावेज़-स्तर के विषय आवंटन के विश्लेषण के आधार पर विषय मॉडल गुणवत्ता की स्वचालित रूप से भविष्यवाणी करने के लिए एक विधि का प्रस्ताव करते हैं, और इसकी मजबूती के लिए अनुभवजन्य साक्ष्य प्रदान करते हैं।', 'ru': 'Тематические модели совместно изучают темы и распределяют темы на уровне документов. Внешняя оценка тематических моделей, как правило, сосредоточена исключительно на оценке на уровне тем, например, путем оценки согласованности тем. Мы демонстрируем, что могут существовать значительные расхождения между качеством модели на уровне темы и документа, и что оценка модели на основе анализа на уровне темы может вводить в заблуждение. Мы предлагаем метод автоматического прогнозирования качества тематической модели на основе анализа распределения тем на уровне документов и предоставляем эмпирические доказательства ее надежности.', 'zh': '模形共学主题与文档级主题分发。 其模形之外,往往关注题级,如估题之一致性。 吾证题级与文档质有大异,而原其高下。 立文档分题自料之法,为稳健性经验。', 'ga': 'Comhfhoghlaimíonn samhlacha topaice topaicí agus dáileadh topaicí ar leibhéal na doiciméid. Is gnách go ndírítear meastóireacht eistreach ar shamhlacha topaicí go heisiach ar mheastóireacht ar leibhéal topaice, e.g. trí chomhleanúnachas na dtopaicí a mheas. Léirímid gur féidir le neamhréireachtaí móra a bheith ann idir cáilíocht na samhla ar leibhéal topaice agus doiciméad, agus gur féidir leis an measúnú samhla a bhunú ar anailís ar leibhéal topaice a bheith an-mhíthreorach. Molaimid modh chun cáilíocht mhúnla topaice a thuar go huathoibríoch bunaithe ar anailís ar leithdháiltí topaicí ar leibhéal doiciméad, agus cuirimid fianaise eimpíreach ar fáil dá stóinseacht.', 'el': 'Τα μοντέλα θεμάτων μαθαίνουν από κοινού θέματα και τη διανομή θεμάτων σε επίπεδο εγγράφων. Η εξωτερική αξιολόγηση των μοντέλων θεμάτων τείνει να επικεντρώνεται αποκλειστικά στην αξιολόγηση σε επίπεδο θεμάτων, π.χ. με την αξιολόγηση της συνοχής των θεμάτων. Αποδεικνύουμε ότι μπορεί να υπάρχουν μεγάλες αποκλίσεις μεταξύ της ποιότητας μοντέλων σε επίπεδο θεμάτων και εγγράφων και ότι η βάση της αξιολόγησης μοντέλων σε ανάλυση σε επίπεδο θεμάτων μπορεί να είναι ιδιαίτερα παραπλανητική. Προτείνουμε μια μέθοδο αυτόματης πρόβλεψης της ποιότητας του μοντέλου θεμάτων με βάση την ανάλυση των κατανεμήσεων θεμάτων σε επίπεδο εγγράφων και παρέχουν εμπειρικά στοιχεία για την αξιοπιστία του.', 'hu': 'A téma modellek közösen tanulnak témákat és dokumentum szintű tématerjesztést. A témamodellek külső értékelése általában kizárólag a témaszintű értékelésre összpontosít, például a témák koherenciájának értékelésével. Bemutatjuk, hogy nagy eltérések lehetnek a téma- és dokumentumszintű modellminőség között, és hogy a modellértékelés témaszintű elemzésre alapozása rendkívül félrevezető lehet. Javasoljuk a dokumentum szintű témaolokációk elemzésén alapuló automatikus témamodellek minőségének előrejelzésére szolgáló módszert, és empirikus bizonyítékokat adunk annak robusztusságára.', 'ka': 'ტემიკური მოდელები ერთად ვისწავლოთ ტემიკური და დოკუმენტის დოკუმენტის ტემიკური გაყოფილი. ტემების მოდელების ექსტრინსიკური განსაზღვრება უფრო მხოლოდ ტემების განსაზღვრებისათვის, მაგალითად ტემების შესაძლებლობაზე. ჩვენ გამოჩვენებთ, რომ ტემების და დოკუმენტის მოდელის კაalitეტის შორის დიდი განგანსხვავება შეიძლება და რომ მოდელის განსხვავება ტემების განსხვავებაში შეიძლება ძალიან შეცდომა. ჩვენ აჩვენებთ მეტი, რომელიც ავტომატურად განსაზღვრება ტემების მოდელის კაalitეტის განსაზღვრება, რომელიც დოკუმენტის დოკუმენტის განსაზღვრების ანალიზაციისთვის დაბა', 'kk': 'Нақыштар үлгілері нақыштарды және құжат деңгейіндегі нақыштарды үлестіруді біріктіреді. Нақыштар үлгілерінің экстринзикалық оқиғасы тақырыптар деңгейіндегі оқиғаларға ғана көздейді, мысалы, нақыштардың тегіздігін оқиғанда. Біз нақыштар мен құжат деңгейінің сапасы арасындағы үлкен айырмашылығын көрсету мүмкіндігін көрсету мүмкіндігін көрсетедік. Нақыштар деңгейіндегі анализ үлгісін негіздеу үлгісі Құжат деңгейіндегі нақыштардың бөлімінің анализиясына негізделген нақыштар үлгісін автоматты түрде бақылау әдісін жұмыс істеп, оның дәрежесіне империялық дәліктерді бер', 'it': "I modelli tematici imparano congiuntamente gli argomenti e la distribuzione degli argomenti a livello di documento. La valutazione esterna dei modelli tematici tende a concentrarsi esclusivamente sulla valutazione a livello tematico, ad esempio valutando la coerenza degli argomenti. Dimostriamo che possono esserci grandi discrepanze tra la qualità del modello a livello di argomento e di documento, e che basare la valutazione del modello su analisi a livello di argomento può essere altamente fuorviante. Proponiamo un metodo per predire automaticamente la qualità del modello tematico basato sull'analisi delle allocazioni tematiche a livello di documento e fornire prove empiriche per la sua robustezza.", 'lt': 'Teminiai modeliai bendrai mokosi temų ir dokumentų lygmens temų platinimo. Ekstreninis teminių modelių vertinimas paprastai sutelkiamas tik į teminio lygio vertinimą, pvz., vertinant temų nuoseklumą. Mes įrodome, kad gali būti didelių skirtumų tarp teminio ir dokumentų modelio kokybės ir kad modelio vertinimo pagrindas teminio lygio analizei gali būti labai klaidinantis. Siūlome automatiškai numatyti teminio modelio kokybę, pagrįstą dokumentų lygmens teminių paskirstymų analize, ir pateikti empirinius jo patikimumo įrodymus.', 'ms': 'Model topik belajar topik bersama-sama dan distribusi topik-aras dokumen. Pengesahan ekstrinik model topik cenderung untuk fokus eksklusif pada penilaian aras topik, cth. dengan penilaian kesesuaian topik. Kami menunjukkan bahawa ada perbezaan besar antara kualiti model topik dan aras dokumen, dan bahawa penilaian model berdasarkan analisis aras topik boleh sangat menyesatkan. Kami cadangkan kaedah untuk memprediksi kualiti model topik secara automatik berdasarkan analisis alokasi topik aras dokumen, dan menyediakan bukti empirik untuk kepekatannya.', 'ml': 'പ്രമേയത്തിന്റെ മോഡലുകള്\u200d ഒരുമിച്ച് വിതരണ പഠിക്കുന്നു പ്രമേയത്തിന്റെ മാതൃകങ്ങളുടെ കൂടുതല്\u200d വിശേഷിപ്പിക്കുന്നതിനാല്\u200d പ്രമേയത്തിന്റെ നില വിശ്വാസത്തില്\u200d മാത്രം ശ്രദ്ധിക്കുന്ന നമ്മള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു വിഭാഗത്തിനും രേഖനില മോഡലിന്റെയും തമ്മിലുള്ള വലിയ വ്യത്യാസങ്ങള്\u200d ഉണ്ടാകുമെന്നും, പ്രമേയത്തിന്റ പ്രധാനപ്പെടുത്താനുള്ള പ്രമേയത്തിന്റെ മാതൃകയുടെ ഗുണത്തിന്റെ അടിസ്ഥാനത്ത് പ്രവചിപ്പിക്കാനുള്ള ഒരു രീതിയാണ് ഞങ്ങള്\u200d പ്', 'mk': 'Моделите на теми заедно учат теми и дистрибуција на теми на ниво на документи. Екстринската проценка на темските модели има тенденција да се фокусира исклучително на проценка на темско ниво, на пример со проценка на кохеренцијата на темите. Демонстрираме дека може да има големи разлики помеѓу квалитетот на моделот на темата и на документот, и дека основата на проценката на моделот на анализата на темата може да биде многу збунувачка. Предложуваме метод за автоматско предвидување на квалитетот на темскиот модел врз основа на анализата на распределувањата на темата на ниво на документи, и обезбедуваме емпириски докази за неговата robustness.', 'mt': 'Il-mudelli tematiċi jitgħallmu b’mod konġunt is-suġġetti u d-distribuzzjoni tas-suġġetti fil-livell tad-dokumenti. L-evalwazzjoni ekstrinika tal-mudelli tematiċi g ħandha t-tendenza li tiffoka esklussivament fuq evalwazzjoni fil-livell tematiku, pereżempju billi tivvaluta l-koerenza tas-suġġetti. Aħna nuru li jista’ jkun hemm diskrepanzi kbar bejn il-kwalità tal-mudell fil-livell tas-suġġett u dak tad-dokument, u li l-valutazzjoni tal-mudell ibbażata fuq analiżi fil-livell tas-suġġett tista’ tkun qarrieqa ħafna. Aħna nipproponu metodu għat-tbassir awtomatiku tal-kwalità tal-mudell tematiku bbażat fuq analiżi tal-allokazzjonijiet tematiċi fil-livell tad-dokument, u nipprovdu evidenza empirika għar-robustezza tiegħu.', 'mn': 'Сүүлийн загварын загварууд нийлбэр сэдвийг, баримт-түвшин сэдвийг хуваалцуулдаг. Судалгааны загварын үнэлгээ нь сэдвийн түвшинд зөвхөн анхаарлаа төвлөрүүлдэг.Жишээ нь, сэдвийн нийгмийн нийгмийг тодорхойлж байдаг. Бид сэдэв болон баримтын түвшин загварын чанарын хоорондох том ялгаатай байж болно гэдгийг харуулж байна. Загварын түвшин шинжилгээний үндсэн загварын үндсэн үнэлгээ нь маш буруу болж чадна. Бид сэдвийн загварыг автоматаар таамаглах арга загварын сайн талаар баримт-түвшин сэдвийн талаар шалгаж, хүчтэй байдлын талаар эзэмшигтэй баталгаа өгдөг.', 'no': 'Emne- modeller lærer saman emne og temafordeling i dokumentnivå. Ekstransisk evaluering av temamodeller har tendens til å fokusera eksklusivt på emnivåevaluering, f.eks. ved å vurdere konsekvensen av emner. Vi viser at det kan vera store forskjeller mellom emne- og dokumentnivåmodellkvalitet, og at basert modellevaluering på emnivåanalysen kan vera veldig misleading. Vi foreslår ein metode for å automatisk foreslå emnemodulkvalitet basert på analysen av dokumentnivåemål, og tilbyr empiriske beviser for kraftigheten.', 'pl': 'Modele tematyczne wspólnie uczą się tematów i dystrybucji tematów na poziomie dokumentów. Zewnętrzna ocena modeli tematów koncentruje się wyłącznie na ocenie poziomu tematów, np. poprzez ocenę spójności tematów. Wykazujemy, że mogą występować duże rozbieżności między jakością modelu na poziomie tematu i dokumentu, a opieranie oceny modelu na analizie tematu może być bardzo mylące. Proponujemy metodę automatycznego przewidywania jakości modelu tematycznego opartego na analizie alokacji tematów na poziomie dokumentów oraz dostarczamy empirycznych dowodów na jego solidność.', 'ro': 'Modelele tematice învață împreună subiecte și distribuția subiectelor la nivel de document. Evaluarea extrinsă a modelelor tematice tinde să se concentreze exclusiv pe evaluarea la nivel tematic, de exemplu prin evaluarea coerenței subiectelor. Demonstrăm că pot exista discrepanțe mari între calitatea modelului la nivel de subiect și document și că bazarea evaluării modelului pe analiza la nivel de subiect poate fi extrem de înșelătoare. Propunem o metodă de predicție automată a calității modelului subiectelor bazată pe analiza alocărilor subiectelor la nivel de document și furnizăm dovezi empirice pentru robustețea acestuia.', 'sr': 'Temski modeli zajedno uče teme i distribuciju teme na nivou dokumenta. Ekstransička procjena modela teme tendencija se fokusira samo na procjenu nivoa teme, na primjer procjenom saskaņonosti teme. Pokazujemo da postoje velika razlika između kvalitete modela teme i nivoa dokumenta, i da osnovna procena modela na analizi nivoa teme može biti veoma pogrešna. Predlažemo metodu za automatski predviđanje kvalitete teme na osnovu analize sadržaja teme na nivou dokumenta i pružanje empiričkih dokaza za njegovu robustnost.', 'si': 'විශේෂ මොඩල් එක්කම විදේශ සහ විදේශ සඳහා විදේශ විතරය ඉගෙන ගන්න. ප්\u200dරශ්න විද්\u200dයාපයක් ප්\u200dරශ්න විද්\u200dයාපයක් ප්\u200dරශ්න විද්\u200dයාපයක් ප්\u200dරශ්න විද්\u200dයාපයක් ප්\u200dරශ්න විද්\u200dයාපයක් විතරයි, උදා අපි පෙන්වන්නම් විදිහට විදිහට විශේෂය සහ විදිහට ප්\u200dරතිශේෂයෙන් විශේෂයෙන් ලොකු විකල්පයක් තියෙන්න පුළුවන් කියලා අපි ප්\u200dරශ්නයක් ස්වයංක්\u200dරමයෙන් ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා විදිහට විස්ත', 'so': 'Tusaalada maamulka waxaad si wadajir ah u bartaan maadooyinka iyo kala qaybinta mada dukumentiga. Extrinsic evaluation of topic models tends to focus exclusively on topic-level evaluation, e.g. by assessing the coherence of topics.  Waxaynu muujinnaa in kala duwanaanshaha badan oo u dhexeeya tijaabada- iyo sawirada muuqashada, qiimeynta muusikada basaasiga ee sawirka sawirada ah waxaa laga yaabaa mid aad u khiyaaneeya. Waxaynu horumarinaynaa qaab aan si automatic ah u sii sheegno tusaale-tijaabadeed, taasoo lagu saleyn karo baaritaanka saqafka dhamaadka ee warqada qoraalka, waxaana u siinaynaa caddeynta waxqabadka.', 'sv': 'Ämnesmodeller lär sig gemensamt ämnen och ämnesfördelning på dokumentnivå. Yttre utvärderingar av ämnesmodeller tenderar att uteslutande inriktas på utvärdering på ämnesnivå, t.ex. genom att bedöma ämnenas samstämmighet. Vi visar att det kan finnas stora skillnader mellan ämnes- och dokumentnivå modellkvalitet och att det kan vara mycket vilseledande att basera modellutvärdering på ämnesnivå analys. Vi föreslår en metod för att automatiskt förutsäga ämnesmodellkvalitet baserat på analys av ämnesallokeringar på dokumentnivå, och ger empiriska belägg för dess robusthet.', 'ta': 'தலைப்பு மாதிரிகள் தலைப்புகள் மற்றும் ஆவண- நிலை தலைப்பு பகிர்ந்தளிப்புகளை ஒன்றாக கற்றுக்கொள்ளவு தலைப்பு மாதிரிகளின் விரிவாக evaluation தனிப்பட்ட தலைப்பு மட்டத்தின் மதிப்பில் மட்டும் தனிப்படுத்தப்படும், உதாரணமாக, தலைப்புகளின் கூட்ட தலைப்புகள் மற்றும் ஆவண- நிலை மாதிரி தரம் இடையே பெரிய வேறுபாடுகள் இருக்க முடியும் என்பதை நாம் காட்டுகிறோம், மற்றும் அந்த பேஸ்ட் மாதிர ஆவண- மட்டத்தின் தலைப்பு ஒதுக்கீட்டை அடிப்படையில் நாம் தானாகவே மாதிரி மாதிரி தரம் முறையை பரிந்துரைக்கிறோம் மற்றும் அதன் ஆட்ட', 'ur': 'موضوع موڈلز موضوع اور دفتر سطح توسط تقسیم کے ساتھ سیکھتے ہیں. ٹوپ موڈل کے مطابق تحقیق صرف ٹوپ سطح تحقیق پر تمرکز کرتی ہے، جیسے ٹوپ کے مطابق مطابق. ہم نشان دیتے ہیں کہ موضوع اور دفتر-سطح موڈل کی کیفیت کے درمیان بہت بڑی مختلف ہوسکتی ہے، اور یہ کہ موڈل کا ارزش ٹوپ-سطح تحلیل پر زیادہ غلط ہو سکتا ہے۔ ہم نے ایک طریقہ پیش کرتا ہے تابع موڈل کی کیفیت کی تحلیل پر بنیاد رکھی ہے، اور اس کی طاقت کے لئے مضبوط دلیلیں پیش کرتی ہیں.', 'vi': 'Các mẫu chính học về các chủ đề và công cụ tài liệu. Việc đánh giá tuyệt đối về mô hình chủ đề thường tập trung vào việc đánh giá cấp chuyên nghiệp, ví dụ bằng việc đánh giá sự đồng nhất của các chủ đề. Chúng tôi chứng minh có thể có nhiều sự khác biệt lớn giữa chất lượng mô hình về chủ đề và tài liệu, và việc dựa trên mô hình đánh giá về mức độ chuyên môn có thể là rất sai lầm. Chúng tôi đề xuất một phương pháp dự đoán tự động chất lượng của mô hình chủ đề dựa trên phân tích về các giai đoạn về tài liệu, và cung cấp bằng chứng về sự vững chắc của nó.', 'uz': "Mavzu modellari mavzular va hujjat darajasi mavzu tarqatishni birlashtiradi. Name Biz mavzu va hujjat darajasi modeli sifatida katta ajoylik mavjud boʻlishi mumkin, va mavzu- darajadagi analyzer modelini qiymatish juda yomon qilishi mumkin. Biz ҳужжат darajadagi mavzu ajratishga asosida avtomatik kutilmagan mavzu sifatini avtomatik kutilmagan usulni tahlil qilamiz va uning quvvatligi uchun muvaffaqiyatli imkoniyatlarni qo'shishimiz mumkin.", 'nl': 'Topic modellen leren gezamenlijk onderwerpen en onderwerpen distributie op documentniveau. Extrinsieke evaluatie van topic modellen richt zich meestal uitsluitend op topic level evaluatie, bijvoorbeeld door de coherentie van onderwerpen te beoordelen. We tonen aan dat er grote verschillen kunnen zijn tussen de kwaliteit van het model op onderwerp- en documentniveau, en dat het baseren van de evaluatie van het model op analyse op onderwerp-niveau zeer misleidend kan zijn. We stellen een methode voor om de kwaliteit van het topic model automatisch te voorspellen op basis van analyse van de topic allocaties op documentniveau, en leveren empirisch bewijs voor de robuustheid ervan.', 'de': 'Themenmodelle lernen gemeinsam Themen und Themenverteilung auf Dokumentenebene kennen. Die extrinsische Evaluation von Themenmodellen konzentriert sich tendenziell ausschließlich auf die Bewertung auf Themenebene, z.B. durch Bewertung der Kohärenz von Themen. Wir zeigen, dass es große Diskrepanzen zwischen der Modellqualität auf Themen- und Dokumentenebene geben kann und dass eine Modellbewertung auf Themenebene sehr irreführend sein kann. Wir schlagen eine Methode zur automatischen Vorhersage der Qualität von Themenmodellen vor, die auf der Analyse von Themenallokationen auf Dokumentenebene basiert, und liefern empirische Beweise für deren Robustheit.', 'bg': 'Тематичните модели съвместно научават теми и разпространение на теми на ниво документ. Екстринната оценка на тематичните модели обикновено се фокусира изключително върху оценка на тематично ниво, например чрез оценка на съгласуваността на темите. Ние демонстрираме, че може да има големи несъответствия между качеството на модела на тематично и документално ниво и че базирането на оценката на модела на тематично ниво може да бъде силно подвеждащо. Предлагаме метод за автоматично прогнозиране на качеството на тематичния модел въз основа на анализ на разпределението на темите на ниво документ и предоставяме емпирични доказателства за неговата устойчивост.', 'id': 'Model topik bersama belajar topik dan distribusi topik tingkat dokumen. Evaluasi ekstrinis dari model topik cenderung untuk fokus eksklusif pada evaluasi tingkat topik, misalnya dengan menilai koherensi topik. Kami menunjukkan bahwa ada perbedaan besar antara kualitas model topik dan tingkat dokumen, dan bahwa penghargaan model berdasarkan analisis tingkat topik dapat sangat menyesatkan. Kami mengusulkan metode untuk memprediksi secara otomatis kualitas model topik berdasarkan analisis dari alokasi topik tingkat dokumen, dan menyediakan bukti empiris untuk kepekatannya.', 'hr': 'Temski modeli zajedno uče teme i distribuciju teme na razini dokumenta. Ekstranzička procjena modela teme tendencija se fokusira samo na procjenu razine teme, na primjer procjenom saskaņonosti teme. Pokazujemo da postoje velika neslaganja između kvalitete modela teme i razine dokumenta i da temeljna procjena modela na analizi razine teme može biti vrlo pogrešna. Predlažemo metodu za automatski predviđanje kvalitete teme na temi analize sadržaja teme na razini dokumenta i pružamo empiričke dokaze za njegovu robustnost.', 'da': 'Emnemodeller lærer i fællesskab emner og emnefordeling på dokumentniveau. Ekstern evaluering af emneodeller har tendens til udelukkende at fokusere på emneområdeevaluering, f.eks. ved at vurdere sammenhængen mellem emner. Vi påviser, at der kan være store uoverensstemmelser mellem emne- og dokumentniveau model kvalitet, og at det kan være meget vildledende at basere modelvurdering på emne-niveau analyse. Vi foreslår en metode til automatisk forudsigelse af emneodellekvalitet baseret på analyse af emneområdeallokeringer på dokumentniveau og giver empirisk dokumentation for dens robusthed.', 'sw': 'Mradi wa mada kwa pamoja unajifunza mada na usambazaji wa mada ya nyaraka. Utafiti wa ziada wa mifano ya mada huwa unajikita pekee kwenye tathmini za kiwango cha mada, kwa mfano kwa kutathmini umoja wa mada. Tunaonyesha kuwa kuna utofauti mkubwa kati ya ubora wa kiwango cha mada- na kiwango cha nyaraka, na utafiti wa mifano ya michezo kwenye uchambuzi wa ngazi za mada unaweza kuwa wa kudanganya sana. Tunazipendekeza njia ya kutabiri ubora wa muundo wa mada kwa automatic kutabiri ubora wa maudhui kwa kutumia uchambuzi wa utofauti wa mada ya nyaraka, na kutoa ushahidi wa msisimko wa uchumi wake.', 'fa': 'مدل موضوع با همدیگر موضوع و توزیع موضوع سطح سند یاد می\u200cگیرند. ارزیابی استرینی از مدل\u200cهای موضوع معمولاً به جز بر ارزیابی سطح\u200cهای موضوع تمرکز می\u200cکند، مثال با ارزیابی هماهنگی موضوع. ما نشان می دهیم که می تواند اختلاف بزرگی بین عنوان و کیفیت مدل سطح سند وجود داشته باشد، و بنیاد ارزیابی مدل در تحلیل سطح موضوع می تواند بسیار اشتباه کنند. ما یک روش پیشنهاد می کنیم برای پیش بینی کردن کیفیت مدل موضوع به طور خودکار بر اساس تحلیل تقسیم موضوع سطح سند، و مدرک امپراتیک برای استعداد آن را پیشنهاد می کنیم.', 'af': "Onderwerp modelles leer saamstig onderwerpe en dokumentvlak onderwerp verspreiding. Ekstransiese evaluasie van onderwerp-modelles tendeer eksklusief te fokus op onderwerp-vlak evaluasie, bv. deur die koherens van onderwerpe te vurk. Ons wys dat daar groot verskilligheid kan wees tussen onderwerp- en dokument-vlak-model kwaliteit, en dat die basis van model evaluasie op onderwerp-vlak analisie baie misleiding kan wees. Ons voorstel 'n metode vir outomaties voorskou onderwerp model kwaliteit gebaseer op analisie van dokumentvlak onderwerp toewysings, en verskaf empiriese bevestigheid vir sy kragtigheid.", 'tr': 'Me첵dan챌a nusgalary me첵dan챌alary we desktap derejesi me첵dan챌alary 철wren첵채r. Topat nusgalaryny흫 챌yky힊yny di흫e tema-derejesi 챌yky힊ynda fokus ed첵채n 첵aly, mesel창 temalary흫 birle힊igini 챌aklap 첵철ren. Biz tema we sened derejesi arasynda 철r채n d철w체rlen힊ik bolup biljekdigini g철rke첵채ris we nusga derejesinde 챌철z체mlenme 철r채n 첵al흫y힊lyk 첵ok bolup biler. Biz tema nusgasyny 철z-철z체nden t채ze ta첵첵arlamak 체챌in bir nusga teklip edip g철r첵채ris we g체첵챌li mesele ta첵첵arlamasynda empirik kanlag bererik.', 'sq': 'Modelet tematike mësojnë së bashku temat dhe shpërndarjen e temave në nivel të dokumentit. Vlerësimi ekstrem i modeleve tematike ka tendencë të përqëndrohet vetëm në vlerësimin e nivelit tematik, për shembull duke vlerësuar përkatësinë e temave. Ne demonstrojmë se mund të ketë mospërputhje të mëdha midis kualitetit të modelit të nivelit tematik dhe të dokumentit dhe se bazimi i vlerësimit të modelit në analizën e nivelit tematik mund të jetë shumë mashtrues. Ne propozojmë një metodë për parashikimin automatik të cilësisë së modelit të temës bazuar në analizën e caktimit të temës në nivel të dokumentit dhe furnizojmë prova empirike për fuqinë e saj.', 'am': 'Topic models jointly learn topics and document-level topic distribution.  የውይይት አካባቢ ምርጫዎች የጭብጥ ምርጫዎች የጉዳዩ ደረጃን ማስታወቂያ በተለየ ነው፡፡ እናሳየዋለን፡፡ ሰነድ-ደረጃ የደረጃ አካላትን በማስተካከል እና ለልብስ ማስረጃዎችን እናሳውቃለን፡፡', 'az': 'Mevzu modell…ôri m…ôs…ôl…ôl…ôri v…ô m…ôs…ôl…ôl…ôr s…ôviyy…ôsi dańüńĪtńĪmńĪ birlikd…ô √∂yr…ônir. Mevzu modell…ôrin ekstrinsik deńüerlendirm…ôsi t…ôkc…ô m…ôs…ôl…ôl…ôrin t…ôr…ôfind…ôn t…ôkc…ô m…ôs…ôl…ôl…ôrin t…ôr…ôfind…ôn t…ôr…ôfind…ôn t…ôr…ôfind…ôn t…ôr…ôfind…ôn t…ôr…ôfind…ôn t…ôr…ôfind…ôn danńĪŇüńĪr. Biz t…ôs…ôvv√ľr-s…ôviyy…ô modeli keyfiyy…ôti arasńĪnda b√∂y√ľk m√ľxt…ôliflik olaraq g√∂st…ôririk v…ô m…ôs…ôl…ôn-s…ôviyy…ô analizi √ľz…ôrind…ô modeli deńüerl…ôŇüdirm…ôk √ßox azdńĪrńĪcńĪ olar. Biz m…ôs…ôl…ôl…ôrin m…ôs…ôl…ôl…ôrinin d…ôyiŇüiklikl…ôrinin analizi √ľz…ôrind…ô t…ôkrar-t…ôkrar m…ôs…ôl…ôl…ôrini t…ôkrar-t…ôkrar t…ôdbir etm…ôk √ľ√ß√ľn bir metodu t…ôklif edirik v…ô onun s…ôrtliyi √ľ√ß√ľn empirik d…ôlill…ôr t…ôklif edirik.', 'hy': 'Մոդելները միասին սովորում են թեմաներ և փաստաթղթերի մակարդակի տարածումներ: Թեմային մոդելների արտաքին գնահատումը հակված է կենտրոնանալ միայն թեմային մակարդակի գնահատման վրա, օրինակ՝ թեմայի համապատասխանությունը գնահատելով: Մենք ցույց ենք տալիս, որ կարող են լինել մեծ տարբերություններ թեմային և փաստաթղթի մակարդակի մոդելի որակի միջև, և որ թեմային մակարդակի վերլուծության վրա հիմնված մոդելի գնահատման հիմքը կարող է շատ մոլորեցնող լինել: Մենք առաջարկում ենք թեմային մոդելի որակի ավտոմատ կանխատեսելու մեթոդ, որը հիմնված է փաստաթղթի մակարդակի թեմային բաժանման վերլուծության վրա և ապահովում է էմպիրիկ ապացույցներ նրա կայունության համար:', 'bn': 'বিষয়বস্তু মডেল একত্রে বিষয়বস্তু এবং নথি- স্তর বিতরণ শিখুন। বিষয় মডেলের এক্সট্রিন্সিক মূল্য বিষয়টি বিষয়বস্তু মূল্যের মাধ্যমে শুধুমাত্র বিষয়-স্তরের মূল্যের উপর মনোযোগ প্রদান করে। আমরা দেখাচ্ছি যে বিষয়বস্তু এবং নথি স্তরের মডেলের মানের মধ্যে বিশাল বৈষম্য থাকতে পারে এবং বিষয়বস্তু বিশ্লেষণের ব্যাসিং মডেলের মাধ্যমে ব আমরা স্বয়ংক্রিয়ভাবে বিষয়বস্তুর বিশ্লেষণের ভিত্তিতে বিষয়বস্তু মোডেলের মানের জন্য একটি পদ্ধতি প্রস্তাব করি এবং তার রোবস্টের জন্য', 'bs': 'Temski modeli zajedno uče teme i distribuciju teme na nivou dokumenta. Ekstransička procjena modela teme tendencija se fokusira samo na procjenu nivoa teme, na primjer procjenom saskaņonosti teme. Pokazujemo da postoje velika neslaganja između kvalitete modela teme i nivoa dokumenta, i da temeljna procjena modela na analizi nivoa teme može biti vrlo pogrešna. Predlažemo metodu za automatski predviđanje kvalitete model a teme na temelju analize sadržaja teme na nivou dokumenta i pružamo empiričke dokaze za njegovu robustnost.', 'ca': "Els models de tema aprenen conjuntament temes i distribució de temes a nivell documental. L'evaluació extraínsica dels models temàtics tendeix a centrar-se exclusivament en l'evaluació a nivell temàtic, per exemple evaluant la coherencia dels temàtics. We demonstrate that there can be large discrepancies between topic- and document-level model quality, and that basing model evaluation on topic-level analysis can be highly misleading.  Proposem un mètode per predir automàticament la qualitat del model temàtic basat en l'anàlisi de les asignacions temàtiques a nivell de documents, i proporcionem evidències empíriques de la seva robusteat.", 'ko': '주제 모델은 주제와 문서급 주제의 분포를 함께 학습한다.주제 모델의 외부 평가는 종종 주제 차원의 평가, 예를 들어 주제의 일치성을 평가하는 데만 주목한다.우리는 주제급과 문서급 모델의 품질 사이에 커다란 차이가 존재할 수 있음을 증명했고 주제급 분석을 바탕으로 하는 모델 평가는 심각한 오도를 초래할 수 있다.우리는 문서급 주제 분배 분석을 바탕으로 주제 모델의 질을 자동으로 예측하는 방법을 제시했고 그 노봉성에 실증적 증거를 제공했다.', 'et': 'Teemamudelid õpivad ühiselt teemasid ja dokumentide tasemel teemade levitamist. Teemamudelite väljastpoolne hindamine keskendub tavaliselt ainult teematasandi hindamisele, näiteks teemade sidususe hindamise kaudu. Näitame, et teema- ja dokumenditasandi mudeli kvaliteedi vahel võib esineda suuri erinevusi ning et mudeli hindamine teematasandi analüüsil võib olla väga eksitav. Pakume välja meetodi teemamudeli kvaliteedi automaatseks prognoosimiseks, mis põhineb dokumenditasemel teemajaotuste analüüsil, ning pakume empiirilisi tõendeid selle tugevuse kohta.', 'cs': 'Tématické modely se společně učí témata a distribuci témat na úrovni dokumentů. Extrinzní hodnocení tématických modelů se zaměřuje výhradně na hodnocení tématické úrovně, např. posouzením soudržnosti témat. Dokazujeme, že mohou existovat velké rozdíly mezi kvalitou modelu na úrovni tématu a dokumentů a že založení hodnocení modelu na analýze tématu může být velmi zavádějící. Navrhujeme metodu automatické predikce kvality tématického modelu založenou na analýze alokací témat na úrovni dokumentů a poskytujeme empirické důkazy o jeho robustnosti.', 'fi': 'Aihemallit oppivat yhdessä aiheita ja dokumenttitason aihejakaumaa. Aihemallien ulkoisessa arvioinnissa keskitytään yleensä yksinomaan aihekohtaiseen arviointiin esimerkiksi arvioimalla aiheiden johdonmukaisuutta. Osoitamme, että aihe- ja asiakirjatason mallilaadun välillä voi olla suuria eroja ja että malliarvioinnin pohjautuminen aihetason analyysiin voi olla erittäin harhaanjohtavaa. Esitämme menetelmän, jolla aihemallin laatua voidaan ennustaa automaattisesti dokumenttitason aihealueiden allokoinnin analyysiin perustuen, ja annamme empiiristä näyttöä sen kestävyydestä.', 'jv': 'Tema model joint to cile tématik lan sdokment-pak Distribution Tulung Awak dhéwé éntuk ngono kuwi akeh nesalahan luwih dumadhi kamu kudu nggawe gerakan ingkang tema- lan model-kaliwat dokumen, lan nambah model kuwi wis dipatensi cara-seneng dipatensi temu iso akeh akeh ora bisa pasar. Awak dhéwé nggunakake sistem kanggo ngerasakno modèl itédagaké ora bisa nguasakno cara-kudu nggawe barang nggawe barang nggawe barang seneng pisan empir nggawe barang nggawe gerakan.', 'ha': "@ action: button Ana ƙaddara wa misãlai madaidaici na ɗabi'a, yana da fokus a kan ƙayyade-daraja madaidaici, misali, idan an ƙaddara koɗaicin maɓalli. Tuna nuna cewa there za'a sami gaɓanci mai girma a tsakanin tsarin misãlai-daraja na madaidaici da takardar-dokuman, kuma kan muhallin motsi mai basketa kan anayyar-daraja mai girma za'a iya ɓatar da mai girma. We propose a method for automatically predicting topic model quality based on analysis of document-level topic allocations, and provide empirical evidence for its robustness.", 'sk': 'Tematski modeli skupaj učijo teme in distribucijo teme na ravni dokumentov. Ekstranzično vrednotenje tematskih modelov se običajno osredotoča izključno na vrednotenje tematske ravni, npr. z ocenjevanjem skladnosti tem. Dokazujemo, da lahko obstajajo velike razlike med kakovostjo modela na tematski in dokumentski ravni in da je lahko ocenjevanje modela na tematski ravni zelo zavajajoče. Predlagamo metodo za avtomatsko napovedovanje kakovosti tematskega modela, ki temelji na analizi dodeljevanja tematskih podatkov na ravni dokumenta, in zagotavljamo empirične dokaze o njegovi robustnosti.', 'he': 'מודלים נושאים ללמוד יחד נושאים ולפיצול נושאים ברמה מסמכים. הערכה קיצונית של דוגמנים נושאים נוטה להתמקד בלבד בהערכה ברמה נושאית, למשל על ידי הערכה של התקבלות הנושאים. אנו מוכיחים שיכולים להיות אי-שווים גדולים בין איכות מודל נושאי לרמה מסמכים, ושהערכה מודל מבוססת על ניתוח רמה נושאית יכולה להיות משוגעת מאוד. We propose a method for automatically predicting topic model quality based on analysis of document-level topic allocations, and provide empirical evidence for its robustness.', 'bo': 'གནད་དོན་མིག་ཆས་འདྲ་བ་དང་ཡིག་གེ་གནས་ཁོངས་དང་ཡིག་གེ་གོང་གི་གནད་དོན་བགོ་སྤྲོད་བྱེད། དཔེར་ན། གནད་དོན་མིག་གཟུགས་རིས་འདིའི་ནང་གི་མི་དཔེ་གཏན་ནང་གི་མཉམ་དུ་མཐོང་ནུས་མེད་པར། ང་ཚོས་གནད་དོན་དང་ཡིག་ཆའི་མ་དཔེ་དབྱིབས་གྱི་མཐོང་ཚད་དང་མིང་དཔེ་དབྱིབས་རྟགས་ལ་མཐོང་ནུས་མེད་པ་དང་། ང་ཚོས་རང་འགུལ་གྱིས་གནད་དོན་དག་གི་མ་གཟུགས་རིས་གནས་ཚུལ་གྱི་དབྱེ་བ་ཞིག་དང་། ཡིག'}
{'en': 'Cross-language Learning with Adversarial Neural Networks', 'ar': 'التعلم عبر اللغات مع الشبكات العصبية العدائية', 'fr': 'Apprentissage interlinguistique avec les réseaux de neurones antagonistes', 'pt': 'Aprendizado de vários idiomas com redes neurais adversas', 'es': 'Aprendizaje multilenguaje con redes neuronales adversarias', 'ja': '対立ニューラルネットワークによるクロスリンガル学習', 'zh': '抗神经网络跨语学', 'hi': 'प्रतिकूल तंत्रिका नेटवर्क के साथ क्रॉस-भाषा सीखना', 'ru': 'Кросс-языковое обучение с соперничающими нейронными сетями', 'ga': 'Foghlaim Trasteanga le Líonraí Néaracha Sárscéimhe', 'hu': 'Nyelvek közötti tanulás negatív ideghálózatokkal', 'el': 'Διγλωσσική μάθηση με τα εχθρικά Νευρικά Δίκτυα', 'it': 'Apprendimento cross-language con reti neurali avverse', 'kk': 'Тілдердің көпшілік невралдық желілерімен үйрену', 'lt': 'Mokymasis įvairiomis kalbomis su prieštaringais nerviniais tinklais', 'mk': 'Cross-language Learning with Adversarial Neural Networks', 'ms': 'Name', 'ka': 'Name', 'ml': 'അഡ്രസറിയല്\u200d നെയുറല്\u200d നെറ്റ്വര്\u200dക്കുകളുമായി ക്രോസ്സ് ഭാഷ പഠിക്കുന്നു', 'mn': 'Дөрвөн хэл суралцах нь сэтгэл мэдрэлийн сүлжээ', 'no': 'Krysspråk læring med rekursariale neuralnettverk', 'pl': 'Nauka między językami z przeciwnymi sieciami neuronowymi', 'ro': 'Învățarea interlingvistică cu rețelele neurale adverse', 'sr': 'Prejezično učenje sa naprednim nervnim mrežama', 'mt': 'Tagħlim translingwistiku ma’ Netwerks Newrali Adversarjali', 'si': 'Name', 'so': 'Cross-language Learning with Adversarial Neural Networks', 'sv': 'Språköverskridande lärande med negativa neurala nätverk', 'ur': 'Cross-language Learning with Adversarial Neural Networks', 'ta': 'Name', 'uz': 'Cross-language Learning with Adversarial Neural Networks', 'vi': 'Học xuyên ngôn ngữ với mạng thần kinh trở lại', 'bg': 'Обучение на междуезици с нежелани неврални мрежи', 'hr': 'Prejezično učenje s naprednim nervnim mrežama', 'nl': 'Taaloverschrijdend leren met nadelige neuronale netwerken', 'da': 'Læring på tværs af sprog med negative neurale netværk', 'de': 'Sprachübergreifendes Lernen mit negativen neuronalen Netzwerken', 'id': 'Belajar Bahasa Salib dengan Rangkaian Neural Adversarial', 'fa': 'یادگیری از زبانهای متفاوت با شبکه های عصبی مخالف', 'ko': '대항성 신경 네트워크 기반의 다중 언어 학습', 'sw': 'Kufundisha lugha ya Cross with Adversal Neural Network', 'tr': 'Gerçekli Näralar Aýtlary bilen Çapraz diller öwrenmek', 'sq': 'Mësimi ndërgjuhësor me rrjetet neuronale kundërshtare', 'af': 'Name', 'hy': 'Խաղելեզվի սովորելը հակառակ նյարդային ցանցերով', 'am': 'ምርጫዎች', 'bn': 'অ্যাডভারেরিয়াল নেউরাল নেটওয়ার্ক দিয়ে ক্রস ভাষা শিক্ষা', 'az': '칖nversarial N칬ral Netikl톛ri il톛 칞ox dil 칬yr톛nm톛si', 'cs': 'Mezijazyčné učení s nepříznivými neuronovými sítěmi', 'et': 'Keeleülene õppimine kõrvaltoimete neuraalsete võrkudega', 'bs': 'Prejezično učenje s naprednim nervnim mrežama', 'ca': 'Aprendiment de llenguatges transversals amb xarxes neuronals adversaries', 'fi': 'Kieltenvälinen oppiminen haitallisten hermoverkkojen avulla', 'jv': 'ProgressBarUpdates', 'ha': 'KCharselect unicode block name', 'he': 'ללמוד שפת צלב עם רשתות נוירוליות נוגדיות', 'sk': 'Medjezikovno učenje z neželenimi živčnimi mrežami', 'bo': 'Cross-language Learning with Adversarial Neural Networks'}
{'en': 'We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language. In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages. The evaluation results show sizable improvements for our cross-language adversarial neural network (CLANN) model over a strong non-adversarial system.', 'ar': 'نعالج مشكلة التكيف عبر اللغات لإعادة طرح تشابه الأسئلة والسؤال في الإجابة على أسئلة المجتمع ، بهدف نقل نظام مدرب على لغة إدخال واحدة إلى لغة إدخال أخرى مع إعطاء بيانات تدريب مصنفة للغة الأولى والبيانات غير المصنفة فقط للغة الأولى. اللغة الثانية. على وجه الخصوص ، نقترح استخدام التدريب العدائي للشبكات العصبية لتعلم الميزات عالية المستوى التي تعتبر تمييزية لمهمة التعلم الرئيسية ، وفي نفس الوقت تكون ثابتة عبر لغات الإدخال. تُظهر نتائج التقييم تحسينات كبيرة لنموذج الشبكة العصبية المناوئة متعددة اللغات (CLANN) على نظام قوي غير عدائي.', 'es': 'Abordamos el problema de la adaptación entre idiomas para la reclasificación de la similitud entre preguntas y preguntas en la respuesta a preguntas de la comunidad, con el objetivo de trasladar un sistema entrenado en un idioma de entrada a otro idioma de entrada, dados datos de entrenamiento etiquetados para el primer idioma y solo datos sin etiqueta para el segundo idioma. En particular, proponemos utilizar el entrenamiento contradictorio de las redes neuronales para aprender características de alto nivel que son discriminatorias para la tarea de aprendizaje principal y, al mismo tiempo, son invariables en todos los idiomas de entrada. Los resultados de la evaluación muestran mejoras considerables para nuestro modelo de red neuronal contradictoria (CLANN) en comparación con un sólido sistema no contradictorio.', 'pt': 'Abordamos o problema de adaptação entre idiomas para reclassificação de similaridade pergunta-pergunta na resposta de perguntas da comunidade, com o objetivo de portar um sistema treinado em um idioma de entrada para outro idioma de entrada, com dados de treinamento rotulados para o primeiro idioma e apenas dados não rotulados para o idioma de entrada. segunda língua. Em particular, propomos usar o treinamento adversário de redes neurais para aprender recursos de alto nível que são discriminativos para a tarefa principal de aprendizado e, ao mesmo tempo, são invariantes nas linguagens de entrada. Os resultados da avaliação mostram melhorias consideráveis para nosso modelo de rede neural adversária de vários idiomas (CLANN) em um sistema não adversário forte.', 'fr': "Nous abordons le problème de l'adaptation interlinguistique pour le reclassement de similarité question-question dans la réponse aux questions de la communauté, dans le but de transférer un système formé sur une langue d'entrée vers une autre langue d'entrée à partir de données de formation étiquetées pour la première langue et uniquement des données non étiquetées pour la seconde langue langue. En particulier, nous proposons d'utiliser l'entraînement contradictoire des réseaux de neurones pour apprendre des fonctionnalités de haut niveau qui sont discriminantes pour la tâche d'apprentissage principale, tout en étant invariantes entre les langues d'entrée. Les résultats de l'évaluation montrent des améliorations considérables pour notre modèle de réseau neuronal antagoniste interlinguistique (CLANN) par rapport à un système non contradictoire solide.", 'ja': '私たちは、コミュニティの質問回答における質問類似性の再ランク付けのためのクロスランゲージ適応の問題に取り組み、1つの入力言語でトレーニングされたシステムを、第1言語のラベル付きトレーニングデータと、第2言語のラベルなしデータのみを与えられた別の入力言語に移植することを目的としています。特に、ニューラルネットワークの対位法トレーニングを使用して、主な学習課題に対して識別可能であると同時に、入力言語全体で不変である高レベルの特徴を学習することを提案します。評価結果は、強力な非対抗システムに比べて、クロスランゲージ対抗ニューラルネットワーク（ CLANN ）モデルの大幅な改善を示しています。', 'ru': 'Мы рассматриваем проблему межъязыковой адаптации для повторного ранжирования подобия вопросов-вопросов в ответах на вопросы сообщества с целью перенести систему, обученную на одном языке ввода, на другой язык ввода, учитывая помеченные данные обучения для первого языка и только немеченные данные для второго языка. В частности, мы предлагаем использовать состязательное обучение нейронных сетей для изучения высокоуровневых признаков, которые являются дискриминационными для основной учебной задачи, и в то же время являются инвариантными для языков ввода. Результаты оценки показывают значительные улучшения для нашей модели межязыковой состязательной нейронной сети (CLANN) по сравнению с сильной несостязательной системой.', 'hi': 'हम प्रश्न-प्रश्न समानता के लिए क्रॉस-लैंग्वेज अनुकूलन की समस्या को संबोधित करते हैं, जिसका उद्देश्य एक इनपुट भाषा पर प्रशिक्षित सिस्टम को दूसरी इनपुट भाषा में पोर्ट करना है, जो पहली भाषा के लिए लेबल प्रशिक्षण डेटा दिया गया है और दूसरी भाषा के लिए केवल लेबल रहित डेटा दिया गया है। विशेष रूप से, हम उच्च-स्तरीय विशेषताओं को सीखने के लिए तंत्रिका नेटवर्क के प्रतिकूल प्रशिक्षण का उपयोग करने का प्रस्ताव करते हैं जो मुख्य सीखने के कार्य के लिए भेदभावपूर्ण हैं, और एक ही समय में इनपुट भाषाओं में अपरिवर्तनीय हैं। मूल्यांकन परिणाम एक मजबूत गैर-प्रतिकूल प्रणाली पर हमारे क्रॉस-लैंग्वेज प्रतिकूल तंत्रिका नेटवर्क (CLANN) मॉडल के लिए बड़े सुधार दिखाते हैं।', 'zh': '解社区问答相似性重列名,以一输语,给定第一语言标数,第二语言未记数。 臣等请用神经网络对抗性训练以习大判别性,而言语不变。 评估结果表明,比强非抗统,跨言相抗神经网络(CLANN)模形显著。', 'ga': 'Tugaimid aghaidh ar an bhfadhb a bhaineann le hoiriúnú tras-teanga d’athrangú cosúlachtaí ceist-cheiste i bhfreagraí pobail ceisteanna, agus é mar chuspóir córas atá oilte ar theanga ionchuir amháin a phortáil go teanga ionchuir eile nuair a thugtar sonraí oiliúna lipéadaithe don chéad teanga agus gan ach sonraí neamhlipéadaithe don dara teanga. Molaimid go háirithe úsáid a bhaint as traenáil sháraíochta ar líonraí néaracha chun gnéithe ardleibhéil a fhoghlaim atá idirdhealaitheach don phríomhthasc foghlama, agus atá ag an am céanna athróg trasna na dteangacha ionchuir. Léiríonn torthaí na meastóireachta feabhsuithe móra ar ár samhail líonra néar-chomhraic sáraíochta tras-teanga (CLANN) thar chóras láidir neamhsháraíochta.', 'ka': 'ჩვენ სამუშაო კითხვების მისამართებელობისთვის კითხვების შესაბამისათვის კითხვების შესაბამისათვის კითხვების შესაბამისათვის პრობლემების პრობლემების შესაბამისათვის, მისამართვის, რომ ერთი შესაბამისათვის სისტემის შე განსაკუთრებით, ჩვენ მინდა გამოყენოთ ნეიროლური ქსელების განათლებას, რომელიც დისკრიმინატიურია მნიშვნელოვანი სამუშაო სამუშაო სამუშაო დასწავლებისთვის, და ერთადერთი დრო წარმოდგენების შედეგები ჩვენი მრავალური ნეიროლური ქსელის (CLANN) მოდელზე ძალიან არ-განატებრიალური სისტემის შესაძლებლობად უფრო დიდი წარმოქმედება.', 'hu': 'A közösségi kérdések megválaszolásában a kérdések és kérdések hasonlóságának átsorolására irányuló nyelvközi adaptáció problémájával foglalkozunk azzal a céllal, hogy az egyik bemeneti nyelven képzett rendszert egy másik bemeneti nyelvre helyezzük át, amelynek címkézett képzési adatait az első nyelvre és csak a második nyelvre vonatkozóan jelöletlen adatokat adjunk. Különösen azt javasoljuk, hogy a neurális hálózatok ellentétes képzését használjuk olyan magas szintű jellemzők elsajátítására, amelyek diszkriminatívak a fő tanulási feladathoz, és ugyanakkor invariánsak a bemeneti nyelveken. Az értékelési eredmények jelentős javulást mutatnak a cross-language adversary neural network (CLANN) modellünk számára egy erős, nem-adversary rendszerrel szemben.', 'el': 'Αντιμετωπίζουμε το πρόβλημα της γλωσσικής προσαρμογής για την επανακατάταξη ομοιότητας ερωτήσεων-ερωτήσεων στην απάντηση κοινοτικών ερωτήσεων, με στόχο τη μεταφορά ενός συστήματος εκπαιδευμένου σε μια γλώσσα εισαγωγής σε άλλη γλώσσα εισόδου με επισήμανση δεδομένων κατάρτισης για την πρώτη γλώσσα και μόνο χωρίς επισήμανση δεδομένων για τη δεύτερη γλώσσα. Ειδικότερα, προτείνουμε να χρησιμοποιήσουμε την αντίθετη εκπαίδευση των νευρωνικών δικτύων για να μάθουμε χαρακτηριστικά υψηλού επιπέδου που είναι διακριτικά για το κύριο μαθησιακό έργο και ταυτόχρονα είναι αμετάβλητα στις γλώσσες εισαγωγής. Τα αποτελέσματα της αξιολόγησης δείχνουν σημαντικές βελτιώσεις για το μοντέλο του διγλωσσικού αντικρουνικού νευρωνικού δικτύου (CLANN) σε σχέση με ένα ισχυρό μη αντικρουνικό σύστημα.', 'it': "Affrontiamo il problema dell'adattamento cross-language per la ricalcolazione della somiglianza domanda-domanda nella risposta alle domande comunitarie, con l'obiettivo di trasferire un sistema addestrato su una lingua di input ad un'altra lingua di input fornendo dati di formazione etichettati per la prima lingua e solo dati non etichettati per la seconda lingua. In particolare, proponiamo di utilizzare la formazione avversaria delle reti neurali per imparare caratteristiche di alto livello che sono discriminatorie per il compito principale di apprendimento, e allo stesso tempo sono invarianti attraverso le lingue di input. I risultati della valutazione mostrano notevoli miglioramenti per il nostro modello cross-language adversarial neural network (CLANN) rispetto a un sistema non adversarial forte.", 'kk': 'Біз сұрақтар сұрақтарының жауаптарына қайта жауап беру үшін бір тілден бір кіріс тіліне оқылған жүйелік тіліне бірінші тіл үшін жазылған оқыту деректерінің бірінші тіліне жазылған, тек екінші тіліне жазылмаған деректеріне Әрине біз негізгі оқыту тапсырмасына дискриминациялық деңгейіндегі жоғары деңгейіндегі қарсы оқыту үшін невралдық желілердің қарсы оқытуын қолданатын жұмыс істейміз, бірақ бір уақытта Бағалау нәтижелері біздің тілдеріміздің негізгі невралдық желіміздің (CLANN) моделіміздің өлшемі жақсартылығын көрсетеді.', 'mk': 'We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language.  Посебно, предложуваме да се користи противна обука на невровните мрежи за да се научат високо ниво карактеристики кои се дискриминативни за главната задача за учење, а истовремено се инваријантни низ влезните јазици. Резултатите од евалуацијата покажуваат значителни подобрувања за нашиот модел на противјазичката нервна мрежа (КЛАН) преку силен непротивјазички систем.', 'ms': 'Kami mengatasi masalah penyesuaian bahasa-saling untuk persamaan soalan-soalan sambungan semula dalam jawapan soalan komuniti, dengan tujuan untuk port sistem dilatih pada satu bahasa input ke bahasa input lain diberi data latihan yang ditabel untuk bahasa pertama dan hanya data tidak ditabel untuk bahasa kedua. Secara khususnya, kami cadangkan untuk menggunakan latihan musuh rangkaian saraf untuk belajar ciri-ciri tahap tinggi yang diskriminatif untuk tugas pembelajaran utama, dan pada masa yang sama adalah invarian di seluruh bahasa input. Hasil penilaian menunjukkan peningkatan yang besar untuk model rangkaian saraf musuh saling bahasa (CLANN) melalui sistem bukan musuh yang kuat.', 'ml': 'സമൂഹത്തിന്റെ ചോദ്യത്തിന്റെ മറുപടിയില്\u200d ചോദ്യത്തിന്റെ ചോദ്യത്തിന്റെ പുനരുത്ഥാനത്തിനുള്ള ക്രിസ്റ്റ് ഭാഷ പ്രശ്നം നമ്മള്\u200d വിശദീകരിക്കുന്നു. ഒരു സിസ്റ്റം  പ്രത്യേകിച്ച്, പ്രധാനപഠിക്കുന്ന ജോലിക്ക് വ്യത്യസ്ത വിഭാഗങ്ങള്\u200d പഠിപ്പിക്കാന്\u200d ന്യൂറല്\u200d നെറുല്\u200d നെറുല്\u200d നെറ്റുകളുടെ പരിശീലനത്തിന വിലാസങ്ങളുടെ ഫലങ്ങള്\u200d നമ്മുടെ ക്രിസ്റ്റ് ഭാഷ വിരോധമായ നെറുറല്\u200d നെറ്റര്\u200d നെറ്റ്\u200cവര്\u200dക്കിന് വലിയ മെച്ചപ്പെടുത്തുന്നത് ക', 'lt': 'Mes sprendžiame klausimų panašumo tarpkalbinio pritaikymo problem ą atsakant į bendruomenės klausimus klausimų panašumo atžvilgiu, siekdami perkelti sistemą, mokomą viena įėjimo kalba, į kitą įėjimo kalbą, kurioje pateikiami paženklinti mokymo duomenys pirmajai kalbai ir tik antrajai kalbai neskelbti duomenys. Visų pirma siūlome pasinaudoti priešingu nervų tinklų mokymu, kad būtų mokomi aukšto lygio ypatumai, kurie diskriminuoja pagrindinę mokymosi užduotį ir tuo pačiu metu yra nevienodi visomis įeinančiomis kalbomis. Vertinimo rezultatai rodo, kad mūsų tarpkalbinio priešiško nervinio tinklo (CLANN) modelio pagerėjimas yra didelis, palyginti su stipria ne priešiška sistema.', 'mt': 'Aħna nindirizzaw il-problem a tal-adattament translingwistiku għas-similarità bejn mistoqsijiet u mistoqsijiet li jerġgħu jintrabtu fit-tweġiba għall-mistoqsijiet tal-komunità, bl-għan li tiġi portata sistema mħarrġa b’lingwa waħda ta’ input għal lingwa oħra ta’ input mogħtija dejta ta’ taħriġ ittikkettata għall-ewwel lingwa u dejta mhux ittikkettata biss għat-tieni lingwa. B’mod partikolari, qed nipproponu li jintużaw taħriġ avversarju tan-netwerks newrali biex jitgħallmu karatteristiċi ta’ livell għoli li huma diskriminatorji għall-kompitu ewlieni ta’ tagħlim, u fl-istess ħin huma invarjanti fil-lingwi kollha tal-input. Ir-riżultati tal-evalwazzjoni juru titjib konsiderevoli għall-mudell tagħna tan-netwerk newrali avversarju translingwistiku (CLANN) fuq sistema qawwija mhux avversarja.', 'mn': 'Бид асуулт асуултуудын хариултын тулд асуулт асуудлын төстэй адилтгалын асуудлыг олон хэлний адилтгалын асуудлын тухай асуудлыг харуулж, нэг оролцоо хэл дээр сургалтын зорилго нь нэг оролцоо хэл дээр нэг оролцоо хэл дээр нэг хэл дээ Ялангуяа бид мэдрэлийн сүлжээний эсрэг дасгал хөдөлгөөнийг ашиглаж, үндсэн суралцах үйл ажиллагаанд ялгаатай боломжтой өндөр түвшинд суралцах чадварыг суралцах гэсэн санал өгдөг. Үүний шалгалтын үр дүнд бидний олон хэл эсрэг мэдрэлийн сүлжээний (CLANN) загварын тулд хүчтэй эсрэг систем дээр хэмжээний сайжруулалт гаргадаг.', 'no': 'Vi adresserer problemet med krysspråk-adaptasjon for tilsvaring av spørsmål-spørsmål på nytt, med målet å portera eit systemet trent på eitt innskriftsspråk til ein annan innskriftsspråk som er gitt merkelig opplæringsdata for den første språket og berre ubeligge data for den andre språket. I særskilt foreslår vi å bruka negativ trening av neuralnettverk for å lære høg nivå funksjonar som er diskriminasjonale for hovudlæringsoppgåva, og samtidig er ikkje viktig på inndata språka. Evalueringsresultatet viser stor forbedringar for vår krysspråk adversarial neuralnettverk (CLANN) over ein sterk ikkje-adversarial system.', 'pl': 'Zajmujemy się problemem adaptacji wielojęzycznej dla zmiany rankingu podobieństwa pytań-pytań w odpowiedzi na pytania społeczne, w celu przeniesienia systemu przeszkolonego na jednym języku wejściowym do innego języka wejściowego podającego oznakowane dane szkoleniowe dla pierwszego języka i tylko nieoznakowane dane dla drugiego języka. W szczególności proponujemy wykorzystanie przeciwnego treningu sieci neuronowych do nauki cech wysokiego poziomu, które są dyskryminacyjne dla głównego zadania uczenia się, a jednocześnie są niezmienne we wszystkich językach wejściowych. Wyniki oceny pokazują znaczące ulepszenia dla naszego modelu wielojęzycznej sieci neuronowej (CLANN) w porównaniu z silnym systemem nieprzeciwnym.', 'sr': 'Mi rješavamo problem prejezičke adaptacije za sličnost ispitivanja i pitanja koje se ponovo vraćaju na odgovor na zajedničko pitanje, sa ciljem da priključimo sistem obučen na jednom jeziku unutarnjeg jezika na drugi jezik koji je određen etiketirani podaci o obuci za prvi jezik i samo nepoznati podaci za drugi jezik. Posebno, predlažemo da koristimo adversarnu obuku neuralnih mreža kako bi naučili karakteristike na visokom nivou koje su diskriminacije za glavni učenje zadatak, a istovremeno su invariantni na ulaznim jezicima. Rezultati procjene pokazuju velike poboljšanje za našu neprijateljsku neuralnu mrežu (CLANN) preko jakog neprijateljskog sistema.', 'ro': 'Rezolvăm problema adaptării între limbi pentru compararea întrebărilor și întrebărilor în răspunsul la întrebări comunitare, cu obiectivul de a transfera un sistem instruit pe o limbă de intrare într-o altă limbă de intrare, oferind date de formare etichetate pentru prima limbă și numai date nelimitate pentru a doua limbă. În special, propunem utilizarea instruirii adversare a rețelelor neuronale pentru a învăța caracteristici de nivel înalt care sunt discriminatorii pentru sarcina principală de învățare și, în același timp, sunt invariante în toate limbile de intrare. Rezultatele evaluării arată îmbunătățiri semnificative pentru modelul nostru cross-language adversarial neural network (CLANN) în raport cu un sistem non-adversarial puternic.', 'si': 'අපි ප්\u200dරශ්නය-ප්\u200dරශ්නය ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ විශේෂයෙන්, අපි ප්\u200dරධාන විදියට ඉගෙන ගන්න ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් ඉගෙන ගන්න ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200d විශ්ලේෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ විශිෂ්ට භාෂාව විරෝද්ධ භාෂාවේ විරෝද්ධ නියුත', 'ta': 'கேள்வி கேள்வி கேள்வி திரும்ப திரும்பச் சிக்கலைப் பிரச்சனையை நாம் விளக்குகிறோம், ஒரு உள்ளீட்டு மொழியில் பயிற்சிக்கப்பட்ட கணினியை ஒரு உள்ளீட்டு மொழிக குறிப்பிட்டு, நாம் புதிய வலைப்பின்னல் பயிற்சியை பயன்படுத்த உயர்நிலை பண்புகளை கற்றுக் கொள்ள உயர்நிலையில் குணங்கள் முக்கிய கற்றலுக்கு வே மதிப்பிடும் முடிவுகள் மிகப்பெரிய முன்னேற்றங்களை காட்டுகிறது எங்கள் கிரும்ப மொழியில் இருந்து எதிர்பார்த்த நரம்பு வலைப்', 'sv': 'Vi tar itu med problemet med tvärspråklig anpassning för likhet mellan frågor och frågor i gemenskapsfrågor, med målet att överföra ett system som tränats på ett inmatningsspråk till ett annat inmatningsspråk med märkta utbildningsdata för det första språket och endast omärkta data för det andra språket. Framför allt föreslår vi att man använder kontradiktorisk träning av neurala nätverk för att lära sig högnivåfunktioner som är diskriminerande för huvuduppgiften och samtidigt är invarianta över inmatningsspråken. Utvärderingsresultaten visar på betydande förbättringar för vår cross-language adversarial neural network (CLANN) modell jämfört med ett starkt icke-adversarial system.', 'ur': 'ہم سوال-سوال کے مطابق دوبارہ جواب دینے کے لئے مختلف زبان کے اضافہ کے مسئلہ میں مشکل کریں گے، ایک ایسے سیستم کے ذریعہ سے ایک ایسے اینٹ زبان میں دوسری اینٹ زبان کی تعلیم کی جگہ سے پہلی زبان کے لئے لابل کیا گیا ہے اور صرف دوسری زبان کے لئے ناپذیر دی مخصوصا، ہم نے نئورل نیٹورک کی مخالف ترکینس کا استعمال کرنا پیشنهاد کرتا ہے کہ اچھی سطح کے فائولوں کو سیکھیں جو اصلی تعلیم کے کام کے لئے مختلف ہیں، اور اسی طرح انٹورل زبانوں میں غیر مشکل ہیں. ارزیابی نتیجے ہمارے کرس زبان مخالف نیورل نیورل (CLANN) موڈل کے لئے بہت زیادہ اضافہ دکھاتے ہیں۔', 'so': "Dhibaatada u beddelashada isbedelka luuqada iskuulka ah ee u soo celinta su'aalaha arrimaha bulshada, waxaynu ka sheekaynaa jawaabta su'aalaha la xiriira in lagu baro nidaam af mid laga soo qoro oo lagu qoro luqad kale oo lagu qoray macluumaad waxbarasho oo lagu qoray luuqada ugu horraysa iyo macluumaad aan la aqoon karin oo kaliya luqada labaad. In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages.  Qiimeynta waxaa ka muuqda hagaajinta aad u weyn ee shabakadda neurada ka geesta ah ee luuqadaha kala duduwan (CLANN) model ka sareeya nidaam xoog badan oo aan ka gees ahayn.", 'uz': "Biz jamiyat savollarida o'zgarishni boshqa tillarni o'zgartirish muammolarini boshqa tillarni o'rganish uchun muammolarni boshqa tillarni o'rganish uchun tizimni birinchi tillarda o'rganish uchun o'zgartirish mumkin va faqat ikkinchi tillar uchun hech qanday taʼminlovchi maʼlumot. Shunday qilib, biz neyrolik tarmoqlaridan foydalanishni boshqa o'rganish vazifani o'rganish uchun yuqori darajadagi xususiyatlarni o'rganamiz, va shu paytda o'sha paytda kiritish tillariga yetarli bo'lsa. Ko'rib chiqish natijalari qo'llangan bir necha tildagi foydalanuvchi tarmoqning (CLANN) modelini ko'rsatadi.", 'vi': 'Chúng tôi giải quyết vấn đề bắt đầu bằng ngôn ngữ khác nhau về việc thích ứng giống câu hỏi trong câu hỏi của cộng đồng để trả lời, với mục đích gắn kết một hệ thống được đào tạo trên một ngôn ngữ nhập vào một ngôn ngữ khác được đưa ra các dữ liệu về huấn luyện trong ngôn ngữ đầu tiên và chỉ dữ liệu chưa được tô hoá cho ngôn ngữ thứ hai. Chúng tôi đề nghị sử dụng huấn luyện trái ngược của các mạng thần kinh để học các tính năng cấp cao phân biệt đối với công việc học chính, và đồng thời luôn xâm chiếm các ngôn ngữ nhập. Những kết quả đánh giá cho thấy những cải tiến đáng kể cho mô hình thần kinh đối nghịch của chúng ta trên một hệ thống không phải đối thủ mạnh.', 'bg': 'Ние разглеждаме проблема с междуезичната адаптация за повторно подреждане на сходството въпрос-въпрос при общностното отговаряне на въпроси, с цел да се пренесе система, обучена на един входен език към друг входен език, като се предоставят етикетирани данни за обучение за първия език и само незабелязани данни за втория език. По-специално, ние предлагаме да се използва съперническо обучение на невронни мрежи, за да се научат функции на високо ниво, които са дискриминиращи за основната учебна задача и в същото време са инвариращи в различните входни езици. Резултатите от оценката показват значителни подобрения за нашия модел на междуезична конферентна невронна мрежа (CLANN) спрямо силна неконферентна система.', 'nl': 'We behandelen het probleem van taaloverschrijdende aanpassing voor het opnieuw rangschikken van vraag-vraag-overeenkomst bij het beantwoorden van gemeenschapsvragen, met als doel een systeem dat getraind is op de ene invoertaal naar een andere invoertaal te porteren met gelabelde trainingsgegevens voor de eerste taal en alleen niet-gelabelde gegevens voor de tweede taal. In het bijzonder stellen we voor om adversariale training van neurale netwerken te gebruiken om functies op hoog niveau te leren die discriminerend zijn voor de belangrijkste leertaak, en tegelijkertijd invariant zijn in de invoertalen. De evaluatieresultaten tonen aanzienlijke verbeteringen aan voor ons cross-language adversarian neural network (CLANN) model ten opzichte van een sterk niet-adversarian systeem.', 'da': 'Vi tager fat på problemet med tilpasning på tværs af sprog til lighed mellem spørgsmål og spørgsmål i forbindelse med besvarelse af fællesskabsspørgsmål med det formål at overføre et system, der er trænet på ét inputsprog, til et andet inputsprog med mærkede uddannelsesdata for det første sprog og kun uskilte data for det andet sprog. Især foreslår vi at bruge adversiel træning af neurale netværk til at lære højt niveau funktioner, der er diskriminerende for den vigtigste læringsopgave, og samtidig er invariant på tværs af input sprog. Evalueringsresultaterne viser betydelige forbedringer for vores cross-language adversarial neural network (CLANN) model over et stærkt ikke-adversarial system.', 'hr': 'Mi rješavamo problem prejezičke adaptacije za sličnost ispitivanja na odgovoru na pitanje zajednice, s ciljem priključiti sustav obučen na jednom jeziku unutarnjeg jezika na drugi jezik koji je određen etiketirani podaci o obuci za prvi jezik i samo neoznačeni podaci za drugi jezik. Posebno, predlažemo koristiti adversarnu obuku neuralnih mreža kako bi naučili karakteristike visokog nivoa koje su diskriminirane za glavni učenje zadatak, a istovremeno su invariantne na ulaznim jezicima. Rezultati procjene pokazuju velike poboljšanje za našu neprijateljsku neuralnu mrežu (CLANN) preko jakog neprijateljskog sustava.', 'de': 'Wir befassen uns mit dem Problem der sprachübergreifenden Anpassung für die Frage-Frage-Ähnlichkeits-Rangierung bei der Beantwortung von Community-Fragen, mit dem Ziel, ein System, das auf einer Eingabesprache trainiert wurde, in eine andere Eingabesprache zu portieren, wobei markierte Trainingsdaten für die erste Sprache und nur unbesiegelte Daten für die zweite Sprache angegeben wurden. Insbesondere schlagen wir vor, das adversariale Training neuronaler Netze zu nutzen, um hochrangige Merkmale zu erlernen, die für die Hauptlernarbeit diskriminierend sind und gleichzeitig über die Eingabesprachen hinweg invariant sind. Die Auswertungsergebnisse zeigen deutliche Verbesserungen für unser cross-language adversarial neural network (CLANN) Modell gegenüber einem starken nicht-adversarialen System.', 'id': 'Kami mengatasi masalah adaptasi saling bahasa untuk persamaan pertanyaan-pertanyaan mengatasi ulang pertanyaan komunitas menjawab pertanyaan, dengan tujuan untuk port sistem dilatih pada satu bahasa masukan ke bahasa masukan lain yang diberikan data pelatihan berlabel untuk bahasa pertama dan hanya data tidak berlabel untuk bahasa kedua. Terutama, kami mengusulkan untuk menggunakan pelatihan musuh jaringan saraf untuk belajar fitur tingkat tinggi yang diskriminatif untuk tugas belajar utama, dan pada saat yang sama invarian di dalam bahasa input. Hasil evaluasi menunjukkan perbaikan yang besar untuk jaringan saraf musuh saling bahasa (CLANN) model melalui sistem non-musuh yang kuat.', 'fa': 'ما مشکل تغییر دادن زبانهای متفاوتی برای تغییر دادن شبیه سوال و سوال سوال در جواب سوال جامعه با هدف برای تغییر دادن یک سیستم در یک زبان ورودی به زبان دیگر ورودی آموزش داده شده که داده های آموزش نامیده شده برای زبان اول و فقط داده های نامیده شده برای زبان دوم را دریافت مخصوصا، ما پیشنهاد می\u200cکنیم از آموزش مخالف شبکه\u200cهای عصبی استفاده کنیم تا ویژگی\u200cهای سطح بالا را یاد بگیریم که برای کار یادگیری اصلی تفریح می\u200cکنند، و در همین زمان در زبان ورودی بی\u200cنیاز هستند. نتایج ارزیابی برای شبکه عصبی مخالف زبان (CLANN) بر روی یک سیستم غیر دشمنی قوی نشان می دهد.', 'ko': '우리는 지역사회 문답에서 문제의 유사성을 재배열하는 다중 언어 적응 문제를 해결했다. 목적은 첫 번째 언어에 대한 표기 훈련 데이터와 두 번째 언어에 대한 표기 데이터가 없는 상황에서 입력 언어 훈련 시스템을 다른 입력 언어로 이식하는 것이다.특히 우리는 신경 네트워크의 대항적인 훈련을 이용하여 고급 특징을 배우는 것을 권장한다. 이런 특징은 주요 학습 임무에 차이가 있고 입력 언어에서 변하지 않는다.평가 결과에 따르면 우리의 다중 언어 대항성 신경망(CLANN) 모델은 강력한 비대항성 시스템에서 상당히 크게 개선되었다.', 'tr': 'Biz jemgyýet soraglarynyň ýene-de durmuş dil adaptasiýasynyň meselesini çykaryp barýarys, jemgyýet soraglarynyň ýene-de durmuş dilinde sistemany bir girdi dilinden başga bir dile gollanýan we diňe ikinji dilinden a ýlanmaýan maglumatlary üçin beýleki girdi diline gollanýan we bellenilýän Aýratyn bolsa, biz neural şebekeleriň ýokary derejesini öwrenmek üçin düýbünden aýratyn çykyşlygyny ulanmagy teklip edýäris we şol wagt içinde giriş dillerinde döwürmeýäris. Ýardamçylyk netijesi çapda dillerimiziň teňkil netijesi (CLANN) nusgasymyz üçin golaýlaşykly düzeldileri görkezýär.', 'sw': 'Tunaongelea tatizo la kubadilishwa kwa lugha mbalimbali kwa maswali yanayofanana na kujibu swali la jumuiya, kwa lengo la kuweza mfumo wa kufundishwa kwa lugha moja ya input kwa lugha nyingine inayotolewa na taarifa za mafunzo kwa lugha ya kwanza na takwimu zisizoeleweka tu kwa lugha ya pili. Kwa hakika, tunapendekeza kutumia mafunzo ya upinzani ya mitandao ya kijamii ili kujifunza vipengele vya juu ambavyo vinatofautisha kwa kazi kuu ya kujifunza, na kwa wakati huo huo huvamia lugha za ndani. Matokeo ya uchunguzi yanaonyesha maendeleo makubwa kwa mtandao wetu wa upinzani wa neura wa lugha tofauti (CLANN) juu ya mfumo mzuri usio na upinzani.', 'hy': 'Մենք լուծում ենք հարցերի և հարցերի նմանության միջլեզվի ադապտացիայի խնդիրը համայնքի հարցերի պատասխանների մեջ, որի նպատակն է տեղափոխել մի համակարգ, որն ուսուցանված է մեկ մուտքային լեզվով, մեկ այլ մուտքային լեզվով, որը տալիս է առաջին լեզվի և միայն երկրորդ լեզվի համար բացահայտվ In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages.  Ագնահատման արդյունքները ցույց են տալիս մեր լեզվի միջև եղած հակառակ նյարդային ցանցի (ԿԼԱՆ) մոդելի մեծ բարելավումներ ուժեղ ոչ հակառակորդային համակարգի փոխարեն:', 'am': 'የቋንቋ-ቋንቋን አቀማመጥ ለመጠያየር ጥያቄን ለመቀበል እናስቀራለን፡፡ በተለይም፣ ለዋነኛው ትምህርት ትምህርት ትምህርት የሚለዩትን ከፍተኛ ደረጃዎች ለማስተማር በተቃዋሚ መረብ ማስተማርን እናዘጋጅታለን፡፡ ውጤቶች በተቃዋሚ የቋንቋችን ተቃዋሚ የኔሩኤል መረብ (CLANN) ሞዴል በጠነከረ ተቃዋሚ ስርዓት ላይ የበለጠ ክፍተቶችን ያሳያል፡፡', 'af': "Ons adres die probleem van kruistaal aanpassing vir vraag-vraag vergelykbaarheid wat in gemeenskapsvraag antwoord word, met die doel om 'n stelsel op een invoer taal te poort, aan 'n ander invoer taal gegee etiketeerde onderwerp data vir die eerste taal en slegs ongeabelde data vir die tweede taal. In spesifieke voorstel ons om teenstandaarde onderwerking van neurale netwerke te gebruik om hoë vlak funksies te leer wat diskrimineer is vir die hoof leer taak, en op dieselfde tyd is ongelukkig oor die invoer tale. Die evalueringsresultate vertoon groottebaar verbeteringe vir ons kruistale teenstandaarde neuralnetwerk (CLANN) model oor 'n sterk nie-teenstandaarde stelsel.", 'sq': 'Ne trajtojmë problem in e përshtatjes ndërgjuhësore për ngjashmërinë e pyetjeve-pyetjeve të rishikimit në përgjigjen e pyetjeve të komunitetit, me qëllim të portojmë një sistem të trajnuar në një gjuhë të hyrjes në një gjuhë tjetër të hyrjes të dhëna me etiketë të dhëna trainimi për gjuhën e parë dhe vetëm të dhëna pa etiketë për gjuhën e Në veçanti, ne propozojmë të përdorim trajnimin kundërshtar të rrjeteve nervore për të mësuar karakteristika të nivelit të lartë që janë diskriminuese për detyrën kryesore të mësimit dhe në të njëjtën kohë janë invariante nëpër gjuhët e hyrjes. Rezultatet e vlerësimit tregojnë përmirësime të mëdha për modelin tonë të rrjetit neural kundërshtar ndërgjuhësor (CLANN) lidhur me një sistem të fortë jo kundërshtar.', 'bn': 'সম্প্রদায়ের প্রশ্নের উত্তরে পুনরায় প্রশ্নের প্রশ্নের প্রশ্নের প্রশ্নের ক্ষেত্রে প্রশ্নের ক্ষেত্রে প্রশিক্ষণের সমস্যা আমরা আয়োজন করি, যার উদ্দেশ্য হচ্ছে যে একটি সিস্টেম In particular, we propose to use adversarial training of neural networks to learn high-level features that are discriminative for the main learning task, and at the same time are invariant across the input languages.  এই মূল্যের ফলাফল আমাদের ক্রস-ভাষার বিরোধী নিউরেল নেটওয়ার্ক (CLANN) মডেল দেখাচ্ছে শক্তিশালী বিরোধী ব্যবস্থার উপর।', 'az': 'Biz sual-sual istifadə etmək üçün çox dil adaptasiyasının problemini çəkirik, ümmətlərin sual cavabında yenidən çəkilməsi üçün, birinci dil üçün etiketli təhsil verilmiş sistemin bir girdi dilində təhsil edilmiş başqa bir girdi dilinə təhsil edilməsi və ancaq ikinci dil üçün etiketli təhsil verilmiş verilər. Özellikle, biz nöral ağların təhsilini istifadə etməyi təklif edirik ki, ən yüksək seviyyətli öyrənmə işi üçün dəyişiklik təhsilini öyrənmək üçün, həmçinin də giriş dillərində istifadə edirik. Qıymet sonuçları çoxlu dillərimizin düşmənçilik nöral a ğımızın (CLANN) modelinin çoxlu düşmənçilik sistemində göstərir.', 'bs': 'Mi rješavamo problem prejezičke adaptacije za sličnost ispitivanja na odgovoru na pitanje zajednice, s ciljem priključiti sistem obučen na jednom jeziku unutrašnjih jezika na drugi jezik koji je određen etiketirani podaci o obuci za prvi jezik i samo neoznačeni podaci za drugi jezik. Posebno, predlažemo da koristimo adversarnu obuku neuronskih mreža kako bi naučili karakteristike visokog nivoa koje su diskriminacije za glavni učenje zadatak, a istovremeno su invariantni na ulaznim jezicima. Rezultati procjene pokazuju velike poboljšanje za našu neprijateljsku neuralnu mrežu (CLANN) preko jakog neprijateljskog sistema.', 'cs': 'Řešíme problém mezijazyčné adaptace pro změnu řazení podobnosti otázek-otázek v komunitním odpovědi na otázky s cílem přenést systém trénovaný na jednom vstupním jazyce do jiného vstupního jazyka s označením výcvikových dat pro první jazyk a pouze neoznačených dat pro druhý jazyk. Konkrétně navrhujeme využít adversariální trénink neuronových sítí k učení se vysoce úrovňových rysů, které jsou diskriminační pro hlavní učební úlohu a zároveň jsou invariantní napříč vstupními jazyky. Výsledky hodnocení ukazují značná zlepšení našeho cross-jazykového modelu adversariální neuronové sítě (CLANN) ve srovnání se silným non-adversariálním systémem.', 'ca': "We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language.  En particular, proposem fer servir la formació adversaria de les xarxes neurals per aprendre característiques d'alt nivell que són discriminatives per a la tasca principal d'aprenentatge, i al mateix temps són invariants a través de les llengües d'entrada. Els resultats de l'evaluació mostran millores significatives en el nostre model de xarxa neural adversaria (CLANN) a través d'un sistema no adversari fort.", 'fi': 'Käsittelemme ongelmaa, joka liittyy kysymys-kysymys-samankaltaisuuden uudelleenjärjestelyyn yhteisön kysymyksiin vastaamisessa. Tavoitteena on siirtää yhdestä syöttökielestä koulutettu järjestelmä toiselle syöttökielelle, jossa on merkitty ensimmäisen kielen koulutustiedot ja vain merkitsemätön tieto toisen kielen osalta. Erityisesti ehdotamme, että neuroverkkojen vastakkainasettelukoulutusta käytettäisiin oppimaan korkean tason ominaisuuksia, jotka ovat syrjiviä pääasiallinen oppimistehtävä ja samalla invariantteja kaikilla syöttökielillä. Arviointitulokset osoittavat, että CLANN (cross-language adversarial neural network) -mallimme on parantunut merkittävästi verrattuna vahvaan ei-adversariaaliseen järjestelmään.', 'et': 'Tegeleme keeleülese kohandamise probleemiga küsimuste-küsimuste sarnasuse ümberarvestamiseks kogukonna küsimustele vastamisel, eesmärgiga transportida ühel sisendkeelel koolitatud süsteem teise sisendkeelde, millel on esimese keele koolitusandmed märgistatud ja teise keele puhul ainult märgistamata andmed. Eelkõige teeme ettepaneku kasutada närvivõrkude vastastikust koolitust, et õppida kõrgetasemelisi funktsioone, mis on diskrimineerivad peamise õppeülesande jaoks ja samal ajal invariandid sisendkeeltes. Hindamistulemused näitavad märkimisväärset paranemist meie keeleülese konkurentsivõrgu (CLANN) mudelis võrreldes tugeva mittekurentsivõrgu mudeliga.', 'jv': 'Awak dhéwé mengko perbudhakan langkung karo kesalahan kanggo langa-suaraning ing nggawe gerakan ning cebo komunitas, karo bukal kanggo ngubah sistem sing tukang sistem sing sembol karo perusahaan langa sing dadi ingkang alih sing apik dhéwé. Awak dhéwé éntuk data nggawe perusahaan langa sambanjur kuwi wis dumateng dhéwé. Genjer-Genjer Wulangan menehi perusahaan langgar sampeyan kanggo mbalkurin kanggo nyebute nggawe langgar-langgar netwisan (CLANN) seneng sistem sing gak bener, ora jewisan tambahan.', 'he': 'אנו מתמודדים עם הבעיה של התאמה לשפה צלבית לשאלה-שאלות דומות הקשר מחדש בתשובה לשאלה הקהילתית, עם המטרה לשלוח מערכת מאומנת בשפת כניסה אחת לשפת כניסה אחרת שנתנה נתוני אימון על תווית לשפה הראשונה ורק נתונים ללא תווית לשפה השנייה. במיוחד, אנו מציעים להשתמש באימונים נוגדיים של רשתות עצביות כדי ללמוד תכונות ברמה גבוהה שמחלוקות למשימת הלימוד העיקרית, ובאותו הזמן הם תמידים בכל שפות הכניסה. The evaluation results show sizable improvements for our cross-language adversarial neural network (CLANN) model over a strong non-adversarial system.', 'sk': 'Obravnavamo problem medjezikovne prilagoditve za prerazporejanje podobnosti vprašanj-vprašanj pri odgovarjanju na vprašanja skupnosti, s ciljem prenesti sistem, usposobljen za en vhodni jezik, v drug vhodni jezik z označenimi podatki o usposabljanju za prvi jezik in samo neoznačenimi podatki za drugi jezik. Zlasti predlagamo uporabo kontradikcijskega usposabljanja nevronskih omrežij za učenje značilnosti visoke ravni, ki so diskriminativne za glavno učno nalogo, hkrati pa invariantne v vseh vhodnih jezikih. Rezultati vrednotenja kažejo precejšnje izboljšave našega modela cross-language adversarial nevronomrežja (CLANN) v primerjavi z močnim ne-adversarialnim sistemom.', 'ha': "Munã wajen zama masu husũma ga adapta lugha-ɗabi'a wa masu tambaya na sami da za'a samu'a samu'in da za'a karɓa wa tambayar jamii, tare da shirin ya ƙõna wata na'ura wa'ura wanda aka yi wa wa tsari a kan harshen guda cikin harshen inputwa zuwa wani harshe wanda aka bai wa tsari da data na tsari wa lugha na farkon, kuma da data wanda ba'a yi amf Kayyai, Munã kwaɗayin mu yi amfani da tsarin masu motsi wa zanen neura dõmin su sanar da masu tsari masu sarrafi waɗanda ke yin gaura wa aikin muhimman karantawa, kuma a lokacin da za'a shiga cikin harshen ayuka. Ana ƙidãya matsalari na nũna mafiya girma wa shirin jerin na tsohon neural mai maras-nau'i (CLENN) kan wata na'ura mai ƙarfi ba-motsi.", 'bo': 'We address the problem of cross-language adaptation for question-question similarity reranking in community question answering, with the objective to port a system trained on one input language to another input language given labeled training data for the first language and only unlabeled data for the second language. ང་ཚོས་རང་ཉིད་ཀྱི་རྒྱུ་དངོས་འབྲེལ་མཐུད་དྲ་རྒྱའི་གྲངས་སྒྲིག་ཐད་ནས་མཐུན་རྒྱུ་དངོས་མང་པོ་ཞིག་ཡོད་པའི་ཁྱད་ཆོས་རྩ་བའི་བྱ་འགུལ་ལ་གསལ་རྒྱས་ དབྱེ་ཞིབ་གི་རྐྱེན་འབྲས་འདིས་ང་ཚོའི་སྐད་ཡིག་ཆ་མཐོང་བའི་མཐོ་རིམ་མཐོང་ཚད་ཆེ་རུ་གཏོང་བསྐྱེད་པ་དང་མཐོང་སྣང་མེད་ལག་'}
{'en': 'A Probabilistic Generative Grammar for Semantic Parsing', 'ar': 'القواعد التوليدية الاحتمالية للتحليل الدلالي', 'es': 'Una gramática generativa probabilística para el análisis semántico', 'fr': "Une grammaire générative probabiliste pour l'analyse sémantique", 'pt': 'Uma gramática generativa probabilística para análise semântica', 'ja': 'セマンティック構文解析のための確率的生成文法', 'zh': '语义解析之概率生语法', 'hi': 'सिमेंटिक पार्सिंग के लिए एक संभाव्य जननात्मक व्याकरण', 'ru': 'Вероятностная генеративная грамматика для семантического анализа', 'ga': 'Gramadach Ghiniteach Dóchúil le haghaidh Parsála Séimeantach', 'hu': 'Valószínűleg generációs nyelvtan a szemantikus értelmezéshez', 'ka': 'Name', 'kk': 'Semantic талдау үшін мүмкіндік жасау грамматикасы', 'lt': 'Semantinio analizavimo tikimybės generacinė grama', 'it': "Una grammatica generativa probabile per l'analisi semantica", 'ms': 'Name', 'mk': 'Веројатна генеративна грама за семантично анализирање', 'el': 'Μια πιθανή γενετική γραμματική για τη σημειακή ανάλυση', 'mt': 'Grammar Ġenerattiv Probabilistiku għall-Analiżi Semantika', 'no': 'Name', 'pl': 'Prawdopodobna gramatyka generacyjna dla parsowania semantycznego', 'ro': 'O Grammatică Generativă Probabilistică pentru Parsing Semantic', 'sr': 'Verovatno generativni Grammar za semantičko razmatranje', 'ml': 'സെമാന്റിക് പാര്\u200dസിങ്ങിനുള്ള ഒരു സാധ്യതയുള്ള ജനററിവ് ഗ്രാമാര്\u200d', 'mn': 'Semantic Parsing-ын магадлалын төрөлхтөн эмч', 'ta': 'Name', 'so': 'Heshiiska Semantic', 'si': 'Name', 'sv': 'En sannolik generativ grammatik för semantisk tolkning', 'ur': 'سیمنٹی پارسینگ کے لئے ایک شانس نسل گرم', 'uz': 'Name', 'vi': 'A Probabilistic Grammar for Semantic Parsons.', 'bg': 'Вероятна генеративна граматика за семантичен анализ', 'da': 'A Probabilistic Generative Grammar for Semantic Parsing', 'hr': 'Vjerojatno generativni Grammar za semantičko razmatranje', 'nl': 'Een Probabilistische Generatieve Grammatica voor Semantische Parsing', 'de': 'Eine probabilistische Generative Grammatik für Semantische Parsing', 'ko': '어의 분석에 사용되는 확률 생성 문법', 'id': 'A Probabilistic Generative Grammar for Semantic Parsing', 'fa': 'یک گرم نسل احتمالات نسل برای بازجویی سیمانتیک', 'tr': 'Semantik analyzasy üçin muhtemelen döredici Grammat', 'af': 'Name', 'sw': 'Kiratibu cha Kizalendo cha Kizalendo cha Uchaguzi wa Semantic', 'sq': 'Një grafik gjenerativ i mundshëm për analizimin Semantik', 'am': 'ምርጫዎች', 'hy': 'Սեմանտիկ վերլուծության հավանական գեներատիվ գրամաման', 'az': 'Semantik analizi üçün mümkün olaraq nəsli Grammar', 'bn': 'সেম্যান্টিক পার্সিং এর জন্য সম্ভবত জেনারেটিভ গ্রামার', 'bs': 'Vjerojatno generativni Grammar za semantičko razmatranje', 'ca': "Un grama generatiu probable per a l'analització semàtica", 'cs': 'Pravděpodobná generativní gramatika pro sémantické analýzy', 'et': 'Semantilise parsimise tõenäoline generatiivne grammatika', 'fi': 'Semanttisen analysoinnin todennäköistä generoivaa kielioppia', 'jv': 'A likely Generative Gramm for semanti-parenting', 'he': 'Grammar גנרטיבי סביר עבור בדיקת סמנטית', 'ha': 'KCharselect unicode block name', 'sk': 'Verjetna generativna slovnica za semantično razčlenitev', 'bo': 'semantic Parsing for Probabilistic Generative Grammar'}
{'en': 'We present a generative model of natural language sentences and demonstrate its application to semantic parsing. In the generative process, a logical form sampled from a prior, and conditioned on this logical form, a grammar probabilistically generates the output sentence. Grammar induction using MCMC is applied to learn the grammar given a set of labeled sentences with corresponding logical forms. We develop a semantic parser that finds the logical form with the highest posterior probability exactly. We obtain strong results on the GeoQuery dataset and achieve state-of-the-art F1 on Jobs.', 'ar': 'نقدم نموذجًا توليديًا لجمل اللغة الطبيعية ونوضح تطبيقه على الاعراب الدلالي. في عملية التوليد ، شكل منطقي مأخوذ من نموذج سابق ، وشرط على هذا الشكل المنطقي ، تقوم القواعد الاحتمالية بإنشاء الجملة الناتجة. يتم تطبيق الاستقراء النحوي باستخدام MCMC لتعلم القواعد المعطاة لمجموعة من الجمل المصنفة مع الأشكال المنطقية المقابلة. نقوم بتطوير محلل دلالي يجد الشكل المنطقي بأعلى احتمالية لاحقة بالضبط. نحصل على نتائج قوية على مجموعة بيانات GeoQuery ونحقق F1 على أحدث طراز على الوظائف.', 'pt': 'Apresentamos um modelo generativo de sentenças em linguagem natural e demonstramos sua aplicação à análise semântica. No processo gerativo, uma forma lógica amostrada de uma anterior e condicionada a essa forma lógica, uma gramática gera probabilisticamente a sentença de saída. A indução gramatical usando MCMC é aplicada para aprender a gramática a partir de um conjunto de frases rotuladas com formas lógicas correspondentes. Desenvolvemos um analisador semântico que encontra exatamente a forma lógica com a maior probabilidade posterior. Obtemos fortes resultados no conjunto de dados GeoQuery e alcançamos F1 on Jobs de última geração.', 'es': 'Presentamos un modelo generativo de oraciones en lenguaje natural y demostramos su aplicación al análisis semántico. En el proceso generativo, una forma lógica muestreada de una anterior y condicionada a esta forma lógica, una gramática genera probabilísticamente la oración de salida. La inducción gramatical mediante MCMC se aplica para aprender la gramática dado un conjunto de oraciones etiquetadas con las formas lógicas correspondientes. Desarrollamos un analizador semántico que encuentra exactamente la forma lógica con la probabilidad posterior más alta. Obtenemos resultados sólidos en el conjunto de datos de GeoQuery y logramos una F1 de vanguardia en Jobs.', 'fr': "Nous présentons un modèle génératif de phrases en langage naturel et démontrons son application à l'analyse sémantique. Dans le processus génératif, une forme logique échantillonnée à partir d'une forme antérieure et conditionnée par cette forme logique, une grammaire génère de façon probabiliste la phrase de sortie. L'induction grammaticale à l'aide de MCMC est appliquée pour apprendre la grammaire avec un ensemble de phrases étiquetées avec des formes logiques correspondantes. Nous développons un analyseur sémantique qui trouve exactement la forme logique ayant la probabilité postérieure la plus élevée. Nous obtenons des résultats solides sur le jeu de données GeoQuery et obtenons une F1 de pointe sur les tâches.", 'ja': '自然言語文の生成モデルを提示し、セマンティック構文解析への適用を実証します。生成プロセスでは、以前の論理フォームからサンプリングされ、この論理フォームで条件付けられた論理フォームでは、文法が確率的に出力文を生成する。MCMCを使用した文法帰納法は、対応する論理形式を持つラベル付き文のセットを与えられた文法を学習するために適用される。事後確率が最も高い論理形を正確に求めるセマンティック構文解析器を開発していますGeoQueryデータセットで強力な結果を得て、ジョブで最先端のF 1を達成します。', 'zh': '发一自然语言句成模样,演示语义解析中用。 先验抽样之,以为语法概率性地。 用MCMC者语法归于学给定组有相应者语法。 开一语义解析器,得至后验概率之逻辑。 GeoQuery数集上强大,Jobs得先进F1。', 'ru': 'Представляем генеративную модель предложений на естественном языке и демонстрируем ее применение к семантическому синтаксическому разбору. В генеративном процессе логическая форма, выбранная из предшествующей и обусловленная этой логической формой, грамматика вероятностно генерирует выходное предложение. Грамматическая индукция с использованием MCMC применяется для изучения грамматики при заданном наборе обозначенных предложений с соответствующими логическими формами. Мы разрабатываем семантический парсер, который находит логическую форму с наибольшей апостериорной вероятностью точно. Мы получаем сильные результаты по набору данных GeoQuery и достигаем самого современного F1 по заданиям.', 'hi': 'हम प्राकृतिक भाषा वाक्यों का एक उत्पादक मॉडल प्रस्तुत करते हैं और शब्दार्थ पार्सिंग के लिए इसके आवेदन का प्रदर्शन करते हैं। उत्पादक प्रक्रिया में, एक तार्किक रूप को एक पूर्व से नमूना लिया जाता है, और इस तार्किक रूप पर वातानुकूलित होता है, एक व्याकरण संभावित रूप से आउटपुट वाक्य उत्पन्न करता है। MCMC का उपयोग करके व्याकरण प्रेरण को संबंधित तार्किक रूपों के साथ लेबल किए गए वाक्यों के एक सेट को दिए गए व्याकरण को सीखने के लिए लागू किया जाता है। हम एक शब्दार्थ पार्सर विकसित करते हैं जो उच्चतम पश्चसंभाव्यता के साथ तार्किक रूप पाता है। हम GeoQuery डेटासेट पर मजबूत परिणाम प्राप्त करते हैं और नौकरियों पर अत्याधुनिक F1 प्राप्त करते हैं।', 'ga': 'Cuirimid múnla ginideach d’abairtí teanga nádúrtha i láthair agus léirímid a bhfeidhmiú ar pharsáil shéimeantach. Sa phróiseas giniúna, foirm loighciúil arna sampláil ó réamhfhocal, agus arna coinníollú ar an bhfoirm loighciúil seo, gineann gramadach an abairt aschuir go dóchúlacht. Cuirtear ionduchtú gramadaí ag baint úsáide as MCMC i bhfeidhm chun an ghramadach a fhoghlaim tugtar sraith abairtí lipéadaithe le foirmeacha loighciúla comhfhreagracha. Forbróimid parsálaí shéimeantach a aimsíonn an fhoirm loighciúil leis an dóchúlacht is airde ina dhiaidh sin go díreach. Faighimid torthaí láidre ar thacar sonraí GeoQuery agus bainimid amach F1 ar Jabanna den scoth.', 'ka': 'ჩვენ ჩვენ ჩვენ მოვაჩვენეთ ჩემი წარმოდგენტიური მოდელი თავისი წარმოდგენების მოდელს და გამოჩვენეთ მისი პროგრამის სემონტიკური პარასტი გენერაციური პროცესში ლოგიკური ფორმა, რომელიც წინაღმდენიდან გამოიყენებულია და ამ ლოგიკური ფორმაზე, გრამიმა წინაღმდენობითად გამოყენებული სიტყვების შექმნა. MCMC- ის გამოყენება დამატებული სიტყვების ნაწილად დამატებული სიტყვების ნაწილად გამოყენება. ჩვენ ვაკეთებთ სემონტიკური პანსერერერი, რომელიც ლოგიკური ფორმა, რომელიც ყველაზე უფრო მარტივია შესაძლებლობა. ჩვენ მივიღეთ ძალიან შედეგი მონაცემების შესახებ GeoQuery მონაცემების შესახებ და მივიღეთ სამუშაო შესახებ F1.', 'el': 'Παρουσιάζουμε ένα παραγωγικό μοντέλο φράσεων φυσικής γλώσσας και καταδεικνύουμε την εφαρμογή του στη σημασιολογική ανάλυση. Στην παραγωγική διαδικασία, μια λογική μορφή που λαμβάνεται από ένα προηγούμενο, και εξαρτάται από αυτή τη λογική μορφή, μια γραμματική παράγει πιθανά την πρόταση εξόδου. Η γραμματική επαγωγή με τη χρήση εφαρμόζεται για να μάθει τη γραμματική που δίνεται ένα σύνολο επισήμαντων προτάσεων με αντίστοιχες λογικές μορφές. Αναπτύσσουμε έναν σημασιολογικό αναλυτή που βρίσκει ακριβώς τη λογική μορφή με την υψηλότερη οπίσθια πιθανότητα. Λαμβάνουμε ισχυρά αποτελέσματα στο σύνολο δεδομένων και επιτυγχάνουμε την υπερσύγχρονη F1 στις θέσεις εργασίας.', 'hu': 'Bemutatjuk a természetes nyelvi mondatok generációs modelljét és bemutatjuk annak alkalmazását a szemantikai elemzésre. A generációs folyamatban egy korábbi logikai formából mintázott, és ezen logikai formától függően a nyelvtan valószínűleg generálja a kimeneti mondatot. Nyelvtani indukciót alkalmaznak az MCMC segítségével, hogy megtanulják a nyelvtani nyelvtani adott, megfelelő logikai formákkal ellátott címkézett mondatok sorozatát. Kifejlesztünk egy szemantikai elemzőt, amely pontosan megtalálja a logikai formát a legnagyobb hátsó valószínűséggel. Erős eredményeket érünk el a GeoQuery adatkészleten, és a legkorszerűbb F1-t érjük el Jobs-on.', 'it': "Presentiamo un modello generativo di frasi di linguaggio naturale e dimostriamo la sua applicazione al parsing semantico. Nel processo generativo, una forma logica campionata da un precedente, e condizionata da questa forma logica, una grammatica genera probabilisticamente la frase di output. L'induzione grammaticale utilizzando MCMC viene applicata per imparare la grammatica data da un insieme di frasi etichettate con forme logiche corrispondenti. Sviluppiamo un parser semantico che trova esattamente la forma logica con la più alta probabilità posteriore. Otteniamo ottimi risultati sul set di dati GeoQuery e otteniamo F1 all'avanguardia su Jobs.", 'kk': 'Біз табиғи тіл сөздерінің құрамындағы үлгісін келтіріп, оның қолданбасын semantic талдау үшін көрсетедік. Жасау процесінде, алдындағы логикалық пішімі, және логикалық пішіміне шарт берілген, грамматика шығыс сөзді құрады. MCMC қолданатын грамматикалық тізбектерді оқыту үшін грамматикалық индукциясы сәйкес логикалық пішімдермен келтірілген сөздер жиынын үйрену үшін қолданылады. Біз логикалық пішімді ең жоғары кейінгі маңыздылығымен табу симантикалық талдаушы құрамыз. Біз GeoQuery деректер жиынында күшті нәтижелерді жеткіземіз жұмыс істеу үшін F1 күйін жеткіземіз.', 'lt': 'Pateikiame gamtinių kalbų sakinių model į ir įrodome jo taikymą semantiniam analizavimui. Generaciniame procese, logiška form a, paimta iš ankstesnio ir su sąlyga, kad ši logiška forma, gramatika greičiausiai sukuria išėjimo sakinį. Gramos indukcija naudojant MCMC naudojama gramatikai išmokti, nurodant žymėtų sakinių rinkinį su atitinkamomis loginėmis formomis. Mes sukuriame semantinį analizatorių, kuris randa logišką form ą su didžiausia galine tikimybe tiksliai. Gavome tvirtų GeoQuery duomenų rinkinio rezultatų ir pasiekiame naujausią darbo vietų F1.', 'ml': 'നമ്മള്\u200d സ്വാഭാവിക വാക്കുകളുടെ ജനറല്\u200d മോഡല്\u200d കൊണ്ടുവരുന്നു. അതിന്റെ പ്രയോഗങ്ങള്\u200d സെമാന്റിക് പാര്\u200dസിങ് ജെനററിവ് പ്രക്രിയയില്\u200d, മുമ്പുള്ള ഒരു ലോഗിക്കല്\u200d രീതിയില്\u200d നിന്നും ഈ ലോഗിക്കല്\u200d രീതിയില്\u200d നിര്\u200dബന്ധമാക്കിയിരിക്കുന്ന ഒരു ഗ് എംസിഎംസി ഉപയോഗിച്ച് ഗ്രാമാര്\u200d ആന്\u200dഡന്\u200d പ്രയോഗിക്കുന്നു നമ്മള്\u200d ഒരു സെമാന്റിക്ക് പരിഗണിക്കുന്നുണ്ടാക്കുന്നു. അതിന്റെ ലോഗിക്കല്\u200d രൂപം കണ്ടെത്തുന്നു. അതിന്റ ജിയോക്ക് ഡാറ്റാസെറ്റിന്\u200dറെ ശക്തിയുള്ള ഫലങ്ങള്\u200d ഞങ്ങള്\u200dക്ക് ലഭിക്കുന്നു. ജോലികളില്\u200d ജോലികളില്\u200d നിന്നും സ്', 'mn': 'Бид байгалийн хэл өгүүлбэрүүдийн жинхэнэ загварыг илэрхийлэж, тэдний хэрэглээ semantic parsing-д үзүүлдэг. Эдгээр үйл явцдаа аль хэдийн логикийн хэлбэрээс шалгаж, энэ логикийн хэлбэрээр нөлөөлдөг, граммат магадлал үржүүлэх өгүүлбэрийг бий болгодог. MCMC-г ашиглан грамматикийг суралцахын тулд грамматик өгүүлбэрүүдийг логикийн хэлбэртэй тэмдэглэгдсэн үг суралцах хэрэгтэй. Бид логикийн хэлбэрийг хамгийн өндөр дараагийн магадлалыг олж мэддэг семантик хуваарч үүсгэдэг. Бид GeoQuery өгөгдлийн сангийн хүчтэй үр дүнг гаргаж, ажлын төлөө-урлагийн F1-г хүртэх болно.', 'mk': 'We present a generative model of natural language sentences and demonstrate its application to semantic parsing.  Во генеративниот процес, логична форма примерена од претходната и условена на оваа логична форма, граматиката веројатно ја генерира излезната реченица. Грамарска индукција користејќи MCMC е аплицирана за да се научи граматиката дадена со сет означени реченици со соодветни логични форми. Развиваме семантичен анализатор кој ја најде логичната форма со највисока позадина веројатност точно. Добиваме силни резултати од податоците на GeoQuery и постигнуваме најсовремени F1 за работни места.', 'ms': 'Kami memperkenalkan model generatif kalimat bahasa semulajadi dan menunjukkan aplikasinya untuk penghuraian semantik. In the generative process, a logical form sampled from a prior, and conditioned on this logical form, a grammar probabilistically generates the output sentence.  Induksi gram menggunakan MCMC dilaksanakan untuk belajar grammar diberi set kalimat yang ditabel dengan bentuk logik yang sepadan. Kami mengembangkan penghurai semantik yang mencari bentuk logik dengan kebarangkalian posterior yang paling tinggi tepatnya. Kami mendapat keputusan yang kuat pada set data GeoQuery dan mencapai kemudahan-state-of-the-art F1 pada Jobs.', 'mt': 'Aħna nippreżentaw mudell ġenerattiv ta’ sentenzi lingwistiċi naturali u nippruvaw l-applikazzjoni tiegħu għall-analiżi semantika. In the generative process, a logical form sampled from a prior, and conditioned on this logical form, a grammar probabilistically generates the output sentence.  L-induzzjoni tal-gramma bl-użu ta’ MCMC hija applikata biex titgħallem il-gramma mogħtija sett ta’ sentenzi ttikkettati b’forom loġiċi korrispondenti. Aħna niżviluppaw analizzatur semantiku li jsib il-form a loġika bl-ogħla probabbiltà posterjuri eżattament. Aħna nkisbu riżultati b’saħħithom dwar is-sett ta’ dejta GeoQuery u niksbu l-aħħar F1 dwar l-Impjiegi.', 'no': 'Vi presenterer eit generert modell av naturspråkssetningar og demonstrerer programmet til semantisk tolking. I den genererige prosessen generert eit logisk form som utvalet frå eit førre, og med betingelse på denne logiske skjemaen, vil eit grammatisk sannsynlegvis laga utdatasetninga. Grammarkinduksjon med MCMC er brukt for å lære grammatikken gjeven eit sett med merkelige setningar med tilsvarande logiske formar. Vi utviklar eit semantisk tolkar som finn den logiske skjemaen med den høgste sannsynligheten etter nøyaktig. Vi får sterke resultat på GeoQuery- dataset og oppnår tilstanden av kunsten F1 på jobber.', 'pl': 'Przedstawiamy generatywny model zdań językowych naturalnych i demonstrujemy jego zastosowanie do parsowania semantycznego. W procesie generacyjnym, forma logiczna pobrana z poprzedniego i uwarunkowana tą formą logiczną, gramatyka prawdopodobnie generuje zdanie wyjściowe. Indukcja gramatyki przy użyciu MCMC stosuje się do nauki gramatyki podanej zestawu oznaczonych zdań z odpowiednimi formami logicznymi. Opracowujemy semantyczny parser, który dokładnie znajduje logiczną formę z największym prawdopodobieństwem tylnym. Uzyskujemy silne wyniki na zbiorze danych GeoQuery i osiągamy najnowocześniejszy F1 on Jobs.', 'ro': 'Prezentăm un model generativ de propoziții de limbaj natural și demonstrăm aplicarea acestuia la analizarea semantică. În procesul generativ, o formă logică eșantionată dintr-un anterior și condiționată de această formă logică, o gramatică generează probabil propoziția de ieșire. Inducția gramaticală folosind MCMC este aplicată pentru a învăța gramatica dată un set de propoziții etichetate cu forme logice corespunzătoare. Dezvoltăm un parser semantic care găsește forma logică cu cea mai mare probabilitate posterioară exact. Obținem rezultate puternice pe setul de date GeoQuery și obținem F1 de ultimă generație pe locuri de muncă.', 'sr': 'Predstavljamo generični model prirodnih rečenica jezika i pokazujemo njegovu aplikaciju za semantičko analiziranje. U generativnom procesu, logički oblik uzorak iz ranije, i uvođen na ovaj logički oblik, gramatika verovatno stvara izlaznu rečenicu. Gramatična indukcija koristeći MCMC se primjenjuje kako bi naučila gramatiku s obzirom na setu označenih rečenica sa odgovarajućim logičkim oblicima. Razvijamo semantički analizator koji pronađe logički oblik sa najvećim poslednjim verovatnošću. Dobili smo jake rezultate na setu podataka GeoQuery i postigli stanje umjetnosti F1 o poslovima.', 'so': "Waxaan keenaynaa qaab muuqasho ah oo ku qoran hadalka afka dabiiciga ah, waxaana tusinaynaa codsigiisa baarlamaanka semantika ah. Xarunta geneeral, foomka logical ah oo hore lagu sameynayo, foomkan logical ahna lagu sharciyey, waxaa laga yaabaa in grammar uu soo saaraa go'aanka. Waxbarashada maareynta waxaa lagu codsadaa in lagu barto qoraalka lagu qoray noocyo xirfadeed oo la mid ah. Waxaynu korinnaa baaritaanka semantika ah oo hela foomka jimicsiga ee ugu sareeya suurtagalka ugu sarreeya. Waxaannu heli karnaa resultooyin xoog badan oo ku saabsan shabakada GeoQuery kadibna waxaynu heli karnaa xaalad-state-art F1 ee shaqada.", 'sv': 'Vi presenterar en generativ modell av naturliga språkmeningar och demonstrerar dess tillämpning på semantisk tolkning. I den generativa processen, en logisk form som samples från en tidigare, och betingas av denna logiska form, genererar en grammatik troligen utmatningsmeningen. Grammatik induktion med MCMC används för att lära sig grammatiken som ges en uppsättning märkta meningar med motsvarande logiska former. Vi utvecklar en semantisk parser som hittar den logiska formen med den högsta bakre sannolikheten exakt. Vi får starka resultat på GeoQuery datauppsättningen och uppnår toppmodern F1 på jobb.', 'ta': 'நாம் இயல்பான மொழி வாக்கியங்களின் பொதுவான மாதிரியை காண்பிக்கிறோம் மற்றும் அதன் பயன்பாட்டை பாடலுக்க பொதுவான செயல்பாட்டில், முன்னிருந்து மாதிரியும் ஒரு புரிவான வடிவம், மற்றும் இந்த த தொழில்நுட்பமான வடிவத்தில் நிலைமையில், ஒரு  MCMC பயன்படுத்தி வரைப்படம் கொடுக்கப்பட்ட குறிப்பிட்ட வாக்கியங்களை படிக்க பயன்படுத்தப்படும் நாம் ஒரு பெமான்டிக் பரிசோதனை உருவாக்குகிறோம். அது அதிக பின்னணி சாத்தியமான முறையை கண்டுபிடிக்கும். நாம் ஜியோ தகவல் அமைப்பில் உறுதியான முடிவுகள் பெறுகிறோம் மற்றும் வேலைகளில் உள்ள - கலை F1 நிலையை பெறுகிறது.', 'ur': 'ہم نے طبیعی زبان جماعت کے پیدا کرنے والی موڈل کو پیش کیا ہے اور اس کے کاروبار کو سیمنٹی پارسینگ کے لئے دکھا دیتے ہیں۔ پیدا کرنے والی پروسس میں، ایک منطقی فرم پہلے سے نمونہ لیا گیا ہے، اور اس منطقی فرم پر کنڈیسی کیا گیا ہے، ایک گراماری احتمالاً اپوٹ ویٹ ویٹ پیدا کرتا ہے. Name ہم ایک سیمنٹی پارچر کو تولید کرتے ہیں جو لاجیک فرم کو بالاترین پوسٹریور احتمال کے ساتھ پاتا ہے۔ ہم جئوکوئر ڈاٹ سٹ پر مضبوط نتیجے حاصل کرتے ہیں اور جو کام پر استیٹ آرت F1 حاصل کرتے ہیں۔', 'si': 'අපි ස්වාභාවික භාෂාව ප්\u200dරතිචාරයක් පෙන්වන්න සහ සෙමැන්ටික් විශ්ලේෂණය කරනවා. ප්\u200dරභාවිත ප්\u200dරක්\u200dරියාසයෙන්, ප්\u200dරභාවිත ප්\u200dරකෘතියක්, ප්\u200dරභාවිත ප්\u200dරකෘතියක්, සහ මේ ලොකික ප්\u200dරකෘතියේ සාම්ප්\u200d Name අපි සෙමැන්ටික් විශේෂකයෙක් විස්තර කරනවා ඒ වගේම ලෝකික ප්\u200dරමාණයක් හොයාගන්න පුළුවන් විශේෂක අපි ජෝක්වේරි දත්ත සෙට් එකේ ශක්තිමත් ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරත', 'uz': "Biz tabiiy tilning bir generativ modelini hozir qilamiz va uni semantik parsing uchun dasturni koʻrsatish. @ info: whatsthis Grammar induction using MCMC is applied to learn the grammar given a set of labeled sentences with corresponding logical forms.  Biz semantik parametrlarini yaratishimiz, bu eng eng eng eng eng yaxshi holatda logical shaklni topishi mumkin. Biz Geo maʼlumotlar bazasini ko'proq natijalar olib kelamiz va vazifalar bilan barcha F1'ning holatini bajaramiz.", 'vi': 'Chúng tôi đưa ra một mô hình tác động của câu ngôn ngữ tự nhiên và chứng minh cách sử dụng nó theo ngữ pháp. Trong quá trình tạo ra, một hình thức logic được lấy từ một hình thức trước đó, và được điều chỉnh bằng hình dạng logic này, ngữ pháp sẽ phát ra các câu. Dùng MCMC để học ngữ pháp cho các câu ghi chú với các dạng logic tương ứng. Chúng tôi phát triển một vị cha vấn ngữ nghĩa tìm thấy hình hài logic với khả năng cao nhất sau lưng chính xác. Chúng tôi đạt được kết quả tích cực trên tập tin GeoQuery và đạt được con số F1 tuyệt vời về Việc làm.', 'bg': 'Представяме генеративен модел на изречения с естествен език и демонстрираме приложението му към семантичен анализ. В генеративния процес логическа форма, извадена от предишна и обусловена от тази логическа форма, граматиката вероятно генерира изходното изречение. Граматичната индукция с помощта на MCMC се прилага за изучаване на граматиката, даден набор от етикетирани изречения със съответните логически форми. Разработваме семантичен анализатор, който намира логическата форма с най-голяма задна вероятност точно. Получаваме силни резултати за набора от данни и постигаме най-съвременни резултати за работни места.', 'nl': 'We presenteren een generatief model van natuurlijke taalzinnen en demonstreren de toepassing ervan op semantische parsing. In het generatieve proces, een logische vorm uit een voorafgaande, en geconditioneerd op deze logische vorm, genereert een grammatica waarschijnlijk de uitvoerzin. Grammatica inductie met behulp van MCMC wordt toegepast om de grammatica te leren gegeven een reeks gelabelde zinnen met overeenkomstige logische vormen. We ontwikkelen een semantische parser die de logische vorm met de hoogste posterior waarschijnlijkheid precies vindt. We behalen sterke resultaten op de GeoQuery dataset en bereiken state-of-the-art F1 on Jobs.', 'da': 'Vi præsenterer en generativ model af naturlige sprogsætninger og demonstrerer dens anvendelse til semantisk parsing. I den generative proces, en logisk form udtaget fra en forudgående, og betinget af denne logiske form, en grammatik sandsynligvis genererer output sætningen. Grammatik induktion ved hjælp af MCMC anvendes til at lære grammatik givet et sæt mærkede sætninger med tilsvarende logiske former. Vi udvikler en semantisk fortolker, der finder den logiske form med den højeste bagerste sandsynlighed præcist. Vi opnår stærke resultater på GeoQuery datasættet og opnår state-of-the-art F1 på Jobs.', 'id': 'Kami mempersembahkan model generatif kalimat bahasa alam dan menunjukkan aplikasinya untuk penghuraian semantis. In the generative process, a logical form sampled from a prior, and conditioned on this logical form, a grammar probabilistically generates the output sentence.  Induksi grammar menggunakan MCMC diaplikasikan untuk mempelajari grammar diberikan set kalimat yang ditabel dengan bentuk logis yang cocok. Kami mengembangkan parser semantis yang menemukan bentuk logis dengan kemungkinan posterior tertinggi tepatnya. We obtain strong results on the GeoQuery dataset and achieve state-of-the-art F1 on Jobs.', 'de': 'Wir präsentieren ein generatives Modell natürlicher Sprachsätze und demonstrieren dessen Anwendung auf semantisches Parsing. Im generativen Prozess, einer logischen Form, die von einer vorherigen abgetastet und von dieser logischen Form konditioniert wird, erzeugt eine Grammatik wahrscheinlich den Ausgabesatz. Grammatik Induktion mit MCMC wird angewendet, um die Grammatik zu lernen, wenn eine Reihe von beschrifteten Sätzen mit entsprechenden logischen Formen gegeben ist. Wir entwickeln einen semantischen Parser, der die logische Form mit der höchsten posterioren Wahrscheinlichkeit genau findet. Wir erzielen starke Ergebnisse auf dem GeoQuery-Datensatz und erzielen den neuesten F1 on Jobs.', 'hr': 'Predstavljamo generični model prirodnih jezičkih rečenica i pokazujemo njegovu primjenu za semantičko analiziranje. U generativnom procesu, logički oblik koji je uzorak uzorak iz ranije i uvjetan na ovaj logički oblik, gramatika vjerojatno stvara izlaznu rečenicu. Gramatična indukcija s primjenom MCMC-a primjenjuje se kako bi naučila gramatiku s obzirom na skup označenih rečenica s odgovarajućim logičkim oblicima. Razvijamo semantički analizator koji nalazi logički oblik s najvećom posljednjom vjerojatnošću. Dobili smo jake rezultate na setu podataka GeoQuery i postigli stanje umjetnosti F1 o poslovima.', 'ko': '우리는 자연 언어 문장의 생성 모델을 제시했고 의미 분석에서의 응용을 보여 주었다.생성 과정에서 하나의 선행어에서 추출한 논리 형식을 조건으로 하여 문법은 출력 문장을 생성할 수 있다.MCMC를 사용하여 문법적 귀납을 하고 해당 논리적 형식을 가진 표기문 그룹을 정하는 문법을 배운다.우리는 백업 확률이 가장 높은 논리 형식을 정확하게 찾을 수 있는 의미 해석기를 개발했다.GeoQuery 데이터 세트에서 강력한 결과를 얻었고 작업에서 가장 선진적인 F1을 실현했습니다.', 'fa': 'ما یک مدل ژنترافی از جمله\u200cهای زبان طبیعی را پیشنهاد می\u200cکنیم و کاربردهای آن را به پراکندن سیمانتیک نشان می\u200cدهیم. در فرایند تولید، یک فرم منطقی که از یک فرم قبل نمونه گرفته شده و بر این فرم منطقی وضعیت شده، یک فرم احتمالاً به طور احتمالاً جمله خروج را تولید می\u200cکند. تولید گرامی با استفاده از MCMC برای یاد گرفتن گرامی که یک مجموعه از جمله\u200cهای برچسب\u200cشده با فرم\u200cهای منطقی متفاوت است، کاربرد می\u200cشود. ما یک بازیگر semantic را توسعه می\u200cکنیم که فرم منطقی را با بالاترین احتمال پشتیبانی دقیقا پیدا می\u200cکند. ما نتایج قوی در مجموعه داده های GeoQuery دریافت می\u200cکنیم و به موقعیت هنر F1 در کار می\u200cرسیم.', 'sw': 'Tunaonyesha mtindo wa kizalendo wa hukumu za lugha za asili na kuonyesha matumizi yake kwa ajili ya kuimba kimapenzi. Katika mchakato wa jenerali, mtindo wa kisayansi uliofanana kutokea awali, na hali iliyopo katika mtindo huu wa kisiasa, gramma inawezekana inatengeneza hukumu ya matokeo. Utengenezaji wa maarufu kwa kutumia MCMC unatumiwa kujifunza maarufu uliofanywa na seti zenye maneno yanayofanana na mfumo wa kijiolojia. We develop a semantic parser that finds the logical form with the highest posterior probability exactly.  Tunapata matokeo makubwa kwenye seti ya takwimu za Geo na kupata hali ya sanaa ya F1 kwenye kazi.', 'tr': "Biz tebigy dil sözleriniň döredijilik nusgasyny görkeýäris we uygulamasyny semantik a ýlamaga görkeýäris. Janlaşdyrýan prosesde, öňünden örän namaýylan logik biçim we bu logik biçiminde duşulan bir gramatik çizgi sözlemi döreýär. MCMC'i ulanan küştürme alçaklary grammatik üçin edilen sözleriň nähili biçimleri bilen öwrenmek üçin uygulandyrylýar. Biz semantik çözümleyici şeklinde logik biçiminde en yüksek poster mümkinçiligi takyklaýarys. GeoQuery veri setinde güýçli netijeleri aldyk we iş üstünde bolup ýetirdik.", 'am': 'የፍጥረት ቋንቋ ቃላትን አቀናቅላለን እናሳየዋለን፡፡ በአውራጅ ፕሮጀክት፣ ከአሁን በፊት የተመሳሳይ እና በተገኘ የግንኙነት ፎርማት፣ grammar የውጤት ፍርድ ፍጥረት ያስጀላል፡፡ የግራማር ማቀናጃ በተጠቃሚ MCMC ማስተማር ይጠቅማል፡፡ የሌሎጂ ፎርማት እናገኛለን፡፡ የግዮQuery Dataset ላይ ብርቱ ፍሬዎችን እናገኛለን በሥራም የ-art F1 ግዛት እናደርጋለን፡፡', 'af': "Ons stel 'n genereerde model van natuurlike taal setings en wys sy toepassing na semantiese verwerking. In die genereereerbare proses, 'n logiese vorm wat van 'n voorheede voorbeeld is, en voorbeeld op hierdie logiese vorm, 'n grammatiek waarskynlik genereer die uitset setsing. Grammar induksie wat MCMC gebruik word, word toegewend om die grammatiek te leer wat gegee is 'n stel van etiketeerde setinge met ooreenstemmende logiese vorms. Ons ontwikkel 'n semantiese ontwerker wat die logiese vorm vind met die hoogste posteriore waarskynlik presies. Ons kry sterke resultate op die GeoQuery datastel en bereik status-of-the-art F1 op werke.", 'sq': 'We present a generative model of natural language sentences and demonstrate its application to semantic parsing.  Në procesin gjenerativ, një form ë logjike e marrë nga një formë e mëparshme dhe e kushtëzuar në këtë formë logjike, një gramatikë probabilisht gjeneron fjalën e daljes. Induktimi i gramave duke përdorur MCMC është aplikuar për të mësuar gramatikën e dhënë një sërë fjalësh të etiketuara me forma llogjike korrespondente. Ne zhvillojmë një analizues semantik që gjen form ën logjike me probabilitetin më të lartë posterior saktësisht. Ne arrijmë rezultate të forta në grupin e të dhënave GeoQuery dhe arrijmë më të lartën F1 në punë.', 'hy': 'We present a generative model of natural language sentences and demonstrate its application to semantic parsing.  Սկզբնական գործընթացի ընթացքում, նախկինում նմուշված տրամաբանական ձև, որը պայմանավորված է այս տրամաբանական ձևի վրա, գրամագրությունը հավանականորեն ստեղծում է արտադրյալ նախադասությունը: Գրամամային ինդուկցիան, օգտագործելով MCC, կիրառվում է գրամագրությունը սովորելու համար, որը տրվում է մի շարք պիտակուցված նախադասություններ համապատասխան տրամաբանական ձևերով: Մենք զարգանում ենք սեմանտիկ վերլուծում, որը գտնում է լավագույն հետևի հավանականությունը: Մենք ստանում ենք ուժեղ արդյունքներ geo-հետաքրքիր տվյալների համակարգի վրա և հասնում ենք աշխատանքների վերջին տեխնոլոգիական F1-ին:', 'az': "Biz təbiətli dil cümlələrinin generativ modelini göstəririk və onun uygulamasını semantik ayırmağa göstəririk. Generativ prosesində, əvvəlkilərin nümunələrindən alınan logik formu və bu logik formasında müəyyən edilmiş, bir grammatik mümkün olaraq çıxış cümləsini yaradır. MCMC vasitəsilə Grammar induksyonu gramatika öyrənmək üçün uyğunlaşdırılır, müqayisədə logik formları ilə etiket edilmiş cümlələri öyrənir. Ən yüksək sonrakı mümkünlüyü ilə logik formu tapmış bir semantik parçacını təhsil edirik. Biz GeoQuery veri qutusunda möhkəm sonuçlar alırıq və işlər barəsində möhkəm F1'i başa çatdırırıq.", 'bs': 'Predstavljamo generični model prirodnih rečenica jezika i pokazujemo njegovu primjenu za semantičko analiziranje. U generativnom procesu, logički oblik uzorak iz ranije i uvjetljen na ovaj logički oblik, gramatika vjerojatno stvara izlaznu rečenicu. Gramatična indukcija koristeći MCMC se primjenjuje kako bi naučila gramatiku s obzirom na setu označenih rečenica sa odgovarajućim logičkim oblicima. Razvijamo semantički analizator koji nalazi logički oblik sa najvećom poslednjom verovatnošću. Dobili smo jake rezultate na setu podataka GeoQuery i postigli stanje umjetnosti F1 o poslovima.', 'bn': 'We present a generative model of natural language sentences and demonstrate its application to semantic parsing.  জেনারেটিভ প্রক্রিয়ায় একটি পূর্ব থেকে একটি লজিক্যাল ফর্মের উদাহরণ এবং এই লোগিক্যাল ফর্মে অবস্থিত, একটি গ্রামার সম্ভবত আউটপুটের বাক্ এমসিএমসি ব্যবহার করে গ্রামার শিক্ষা প্রয়োগ করা হয়েছে যে গ্রামারের সাথে সংশ্লিষ্ট লেবেল বাক্য দিয়েছে তা শিখতে পারে। আমরা একটি সেমেন্টিক প্যালেজার তৈরি করি যা সর্বোচ্চ পোস্টারিয়ার সম্ভাবনার সাথে লজিক ফর্ম খুঁজে পায়। আমরা গিওর তথ্য সেটে শক্তিশালী ফলাফল পেয়েছি এবং কাজের ব্যাপারে শিল্পের রাষ্ট্র-অফ-আর্ট এফ১ পেয়েছি।', 'ca': "Presentam un model generador de frases de llenguatge natural i demostrem la seva aplicació a l'analització semàntica. En el procés generador, una form a lògica mostrada d'una forma lògica anterior i condicionada amb aquesta forma lògica, una gramàtica probabilitàticament genera la frase de sortida. L'inducció gramàtica utilitzant MCMC es aplica per aprendre la gramàtica dada un conjunt de frases etiquetades amb formes lògiques correspondents. Desenvolvem un analitzador semàntic que troba la form a lògica amb la probabilitat posterior més alta exactament. Obtenim resultats forts en el conjunt de dades GeoQuery i aconseguem F1 de l'última generació sobre treball.", 'cs': 'Představujeme generativní model vět přirozeného jazyka a demonstrujeme jeho aplikaci pro sémantickou parsování. V generativním procesu, logická forma vzorkovaná z předchozí, a podmíněná touto logickou formou, gramatika pravděpodobně generuje výstupní větu. Gramatická indukce pomocí MCMC se používá k učení gramatiky při souboru označených vět s odpovídajícími logickými formami. Vyvíjíme sémantický parser, který přesně najde logickou formu s nejvyšší pravděpodobností posterioru. Dosahujeme silných výsledků na datové sadě GeoQuery a dosahujeme nejmodernějších F1 on Jobs.', 'et': 'Esitleme looduskeelsete lausete generatiivset mudelit ja demonstreerime selle rakendamist semantilisele parsimisele. Generatiivses protsessis genereerib grammatika tõenäoliselt väljundlause eelnevast loogilisest vormist võetud loogiline vorm, mis on tingitud sellest loogilisest vormist. Grammatika induktsiooni kasutades MCMC kasutatakse grammatika õppimiseks, mis on antud märgistatud lausete komplekti vastavate loogiliste vormidega. Me töötame välja semantilise parser, mis leiab loogilise vormi, millel on täpselt kõige suurem tagumine tõenäosus. Saame GeoQuery andmekogumil tugevaid tulemusi ja saavutame töökohtadel tipptasemel F1.', 'fi': 'Esittelemme luonnollisen kielen lauseiden generatiivisen mallin ja esittelemme sen soveltamisen semanttiseen jäsentämiseen. Generatiivisessa prosessissa kielioppi todennäköisesti tuottaa lähtölauseen, joka on otettu näytteeksi aikaisemmasta ja ehdollistettu tähän loogiseen muotoon. Kieliopin induktiota käyttäen MCMC:tä käytetään oppimaan kielioppi, joka annetaan joukko merkittyjä lauseita vastaavilla loogisilla muodoilla. Kehitämme semanttisen jäsentäjän, joka löytää loogisen muodon, jolla on suurin myöhempi todennäköisyys. Saamme vahvoja tuloksia GeoQuery-aineistosta ja saavutamme huippuluokan F1-tulokset Jobs-palvelussa.', 'jv': 'Awak dhéwé éntuk sistem sing kelompok ing rakyat gagal nggambar aturan karo aplikasi semantar Genjer-Genjer Language Awakdhéwé éntuk semanti karo akeh dumadhi sing luwih nggawe nguasat seneng dipoler, sing paling nggawe barang seneng bongkar bongkar nggo Ketokan Awak dhéwé éntuk dadi sing nggunakake ing dataset GEquery karo iso nggawe stad-o-the-arts F1 karo Jobs.', 'ha': "Tuna gabatar da wani misali na'anar maganar harshe na natsuwa kuma Muke nuna shirin ayukansa zuwa parse na semantic. In tafiyar da shirin ɗabi'a, wani fomat na logical wanda aka samu daga gaba, da kuma wanda aka ƙayyade shi kan wannan fomat, grammar yana ƙara cewa na fitarwa. Grammar induction using MCMC is applied to learn the grammar given a set of labeled sentences with corresponding logical forms.  Tuna buɗe wani parameteri na semantic wanda ke sami tsarin lojiki da mafi sauri na sauri. Tuna sami matsala masu ƙarfi kan danne-Geo kuma mu sami halin-the-art F1 kan aikin.", 'sk': 'Predstavljamo generativni model stavkov naravnega jezika in prikazujemo njegovo uporabo v semantičnem razčlenjevanju. V generativnem procesu, logična oblika, vzorčena iz prejšnje in pogojena s to logično obliko, slovnica verjetno ustvari izhodni stavek. Slovnična indukcija z uporabo MCMC se uporablja za učenje slovnice, ki je podan niz označenih stavkov z ustreznimi logičnimi oblikami. Razvijamo semantični razčlenjevalec, ki najde logično obliko z največjo posteriorno verjetnostjo. Dobivamo močne rezultate na naboru podatkov GeoQuery in dosegamo najsodobnejše F1 na delovnih mestih.', 'he': 'אנחנו מציגים מודל דולר של משפטי שפת טבעיים ומוכיחים את היישום שלה לאבחן סמנטי. בתהליך הדורתי, צורה הגיונית שנלקחה מדגימה מקודמת, ומתאימה בצורה הגיונית הזו, גרמטיקה בוודאי יוצרת את משפט ההוצאה. השימוש של הגרמה באמצעות MCMC מופעל כדי ללמוד את הגרמטיקה שנתנה קבוצה של משפטים מסומנים עם צורות הגיוניות מתאימות. אנחנו מפתחים מעבד סמנטי שממצא את הצורה הגיונית עם הסבירות האחורית הגבוהה ביותר בדיוק. אנחנו מקבלים תוצאות חזקות על קבוצת מידע GeoQuery ולהשיג את המדינה המאוחרת F1 על עבודות.', 'bo': 'ང་ཚོས་རང་རྒྱུན་ལྡན་སྐད་ཡིག་ཆ་ཚིག་ཀྱི་དཔེ་བརྗོད་རྐྱེན་བྱས་མིན་འདུག In the generative process, a logical form sampled from a prior, and conditioned on this logical form, a grammar probabilistically generates the output sentence. Grammar induction using MCMC is applied to learn the grammar given a set of labeled sentences with corresponding logical forms. ང་ཚོས་རང་ཉིད་ཀྱི་རྣམ་འགྱུར་བ་ཅིག་ལྟ་བུའི་ནང་དུ་ཡོད་པའི་མིང་རྩིས་ཀྱི་དཔེ་དབྱེ་བ་ཞིག་གིས་མཐོང་ཐུ We obtain strong results on the GeoQuery dataset and achieve state-of-the-art F1 on Jobs.'}
{'en': 'Learning Contextual Embeddings for Structural Semantic Similarity using Categorical Information', 'ar': 'تعلم الضمانات السياقية للتشابه الدلالي الهيكلي باستخدام المعلومات الفئوية', 'fr': "Apprentissage des intégrations contextuelles pour la similarité sémantique structurelle à l'aide d'informations catégorielles", 'pt': 'Aprendendo incorporações contextuais para similaridade semântica estrutural usando informações categóricas', 'es': 'Aprendizaje de incrustaciones contextuales para la similitud semántica estructural mediante información categórica', 'ja': 'カテゴリ情報を使用した構造的セマンティック類似性のための文脈埋め込みの学習', 'zh': '以类信学构语义相似性者上下文嵌之', 'hi': 'संरचनात्मक शब्दार्थ समानता के लिए प्रासंगिक एम्बेडिंग सीखना श्रेणीगत जानकारी का उपयोग करके', 'ru': 'Обучение контекстуальным вложениям для структурного семантического сходства с использованием категорийной информации', 'ga': 'Leabú Comhthéacsúla a Fhoghlaim do Chosúlacht Shéimeantach Struchtúrtha ag baint úsáide as Faisnéis Chatagóireach', 'ka': 'სტრუქტურული სემანტიკის გამოსახულებლად კონტექსტურული ჩვენება', 'el': 'Ενσωματώσεις στο πλαίσιο μάθησης για τη δομική σημαντική ομοιότητα χρησιμοποιώντας κατηγορηματικές πληροφορίες', 'hu': 'Kontextuális beágyazások a strukturális szemantikus hasonlósághoz Kategorikus információk segítségével', 'it': 'Incorporazioni contestuali di apprendimento per la somiglianza semantica strutturale utilizzando le informazioni categoriche', 'mk': 'Научи контекстни вградувања за структурна семантична сличност користејќи категориска информација', 'kk': 'Структуралық семантикалық ұқсас үшін контексттік ендіру', 'lt': 'Naudojant kategorijinę informaciją mokymasis struktūriniam sementiniam panašumui skirtų kontekstinių įdėjimų', 'ms': 'Mempelajari Penjelmaan Konteksual untuk Persamaan Semantik Struktur menggunakan Maklumat Kategori', 'ml': 'ക്യാറ്റഗറിക്കല്\u200d വിവരങ്ങള്\u200d ഉപയോഗിച്ചുകൊണ്ട് സ്ട്രാക്ട്രൂറല്\u200d സെമാന്റിക് സമമാക്കുന്നതിനുള്ള ഉള', 'mt': 'Tagħlim tal-Inġenji Kontekswali għal Similarità Semantika Strutturali bl-użu ta’ Informazzjoni Kategorika', 'mn': 'Структураллын семантик тэнцүү байдлыг суралцаж Категорийн мэдээллийг ашиглан', 'pl': 'Uczenie się kontekstowych osadzeń dla strukturalnego podobieństwa semantycznego przy użyciu informacji kategoricznych', 'ro': 'Încorporarea contextuală a învățării pentru similitudinea semantică structurală folosind informațiile categorice', 'sr': 'Učenje kontekstualnih integracija za strukturnu semantičku sličnost koristeći kategorijsku informaciju', 'no': 'Læring av kontekst innbygging for strukturelle semantiske likningar ved hjelp av kategoriinformasjon', 'si': 'සංවිධානය සැමැන්තිය සඳහා සංවිධානය සැමැන්තිය සම්බන්ධතාවක් ඉගෙනගන්න', 'sv': 'Inlärning av kontextuella inbäddningar för strukturell semantisk likhet med hjälp av kategorisk information', 'ta': 'கட்டமைப்பு ஒற்றைப் போன்ற அமைப்புகளுக்கான உள்ளடக்கம் கற்றுக் கொண்டுள்ளது வகைப்படி தகவல்களை பயன்படுத்தி', 'ur': 'کاٹیوریک معلومات کے مطابق ساختاری سیمنٹی سیمالیاتی کے لئے کنٹکسٹیول ایمبڈینگ سیکھ رہی ہے', 'so': 'Waxbarashada gudaha ah ee dhismaha Semantic Similarity using Categorical Information', 'uz': 'Name', 'vi': 'Học Tham vọng tương xứng với cấu trúc tinh trùng kỳ diệu', 'bg': 'Учебни контекстни вграждания за структурна семантична прилика с помощта на категорична информация', 'nl': 'Leren contextuele embeddings voor structurele semantische gelijkenis met behulp van categorische informatie', 'da': 'Læringskontekstuelle indlejringer for strukturel semantisk lighed ved hjælp af kategorisk information', 'de': 'Lernkontextuelle Einbettungen für strukturelle semantische Ähnlichkeit mithilfe kategorischer Informationen', 'hr': 'Učenje kontekstualnih integracija za strukturnu semantičnu sličnost koristeći kategorijske informacije', 'id': 'Learning Contextual Embeddings for Structural Semantic Similarity using Categorical Information', 'sw': 'Kujifunza Mipango ya Nchini kwa ajili ya Miundombinu Similani kwa kutumia Habari za Kikategoria', 'tr': 'struktural semantik meňzeşliki üçin metini öwrenmek Kategoriýal Maglumaty ullanýar', 'fa': 'یاد گرفتن پیوندهای متوسط برای شبیه ساختاری شبیه ساختاری با استفاده از اطلاعات کلاسیک', 'sq': 'Mësimi i përfshirjeve kontekstuale për ngjashmërinë strukturore Semantike duke përdorur informacionin kategorik', 'af': 'Leer Konteksual Inbêdings vir strukturele semantiese gelykenis met gebruik van Kategoriese Informasie', 'hy': 'Սովորեցնել կառուցվածքային սեմատիկ նման կոնտեքստային ներգրավումներ օգտագործելով կատեգորիկական տեղեկատվություն', 'ko': '범주 정보 기반의 구조적 의미 유사성 상하문 삽입 학습', 'az': 'Kategoriya Mal칲mat캼n캼 istifad톛 edir톛k strukturlu semantik simantik istifad톛si 칲칞칲n m칲xt톛lif 쿮lav톛l톛ri 칬yr톛nm톛k', 'am': 'Categorical Information', 'bs': 'Učenje kontekstualnih integracija za strukturnu semantičku sličnost koristeći kategorijsku informaciju', 'ca': 'Aprendre integracions contextuals per a la similitud Semàtica Estructural fent servir informació Categorical', 'cs': 'Učební kontextové vložení pro strukturální sémantickou podobnost pomocí kategorických informací', 'bn': 'ক্যাটাগরিক তথ্য ব্যবহার করে কৌশল সেম্যান্টিক সংক্রান্ত তথ্যের জন্য বিদ্যমান বিষয়বস্তু শিখানো', 'et': 'Õppimise kontekstilised põimimised struktuurse semantilise sarnasuse jaoks kategoorialise teabe abil', 'fi': 'Learning Contextual Embeddings for Structural Semantic Similarity using Categorical Information', 'he': 'ללמוד קישורים קונטקסטיים עבור דמיון סמנטי מבנה באמצעות מידע קטגוריי', 'sk': 'Učne kontekstualne vdelave za strukturno semantično podobnost z uporabo kategorijskih informacij', 'ha': 'KCharselect unicode block name', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'རྩིས་གཞུང་དང་བསྡུས་རྟགས་ལ་སྒྲིག་ནང་གི་ཁྱད་ཚད་གཞུང་སྒྲིག་འཛུགས་ཀྱི་དབྱེ་རིགས་སྤྱོད་བཞིན་པ'}
{'en': 'Tree kernels (TKs) and neural networks are two effective approaches for automatic feature engineering. In this paper, we combine them by modeling context word similarity in semantic TKs. This way, the latter can operate subtree matching by applying neural-based similarity on tree lexical nodes. We study how to learn representations for the words in context such that TKs can exploit more focused information. We found that neural embeddings produced by current methods do not provide a suitable contextual similarity. Thus, we define a new approach based on a Siamese Network, which produces word representations while learning a binary text similarity. We set the latter considering examples in the same category as similar. The experiments on question and sentiment classification show that our semantic TK highly improves previous results.', 'ar': 'تعد نواة الشجرة (TKs) والشبكات العصبية طريقتين فعالتين لهندسة الميزات التلقائية. في هذه الورقة ، قمنا بدمجها عن طريق نمذجة تشابه كلمات السياق في المعارف التقليدية الدلالية. بهذه الطريقة ، يمكن للأخير تشغيل مطابقة الشجرة الفرعية عن طريق تطبيق التشابه القائم على العصبية على العقد المعجمية للأشجار. ندرس كيفية تعلم تمثيل الكلمات في السياق بحيث يمكن للمعارف التقليدية استغلال معلومات أكثر تركيزًا. وجدنا أن الزخارف العصبية التي تنتجها الأساليب الحالية لا توفر تشابهًا سياقيًا مناسبًا. وبالتالي ، فإننا نحدد نهجًا جديدًا يعتمد على شبكة سيامي ، والتي تنتج تمثيلات للكلمات أثناء تعلم تشابه نص ثنائي. وضعنا الأمثلة الأخيرة في الاعتبار في نفس الفئة مثل مماثلة. تُظهر التجارب على تصنيف الأسئلة والمشاعر أن معارفنا التقليدية الدلالية تُحسِّن النتائج السابقة بدرجة كبيرة.', 'pt': 'Os kernels de árvore (TKs) e as redes neurais são duas abordagens eficazes para a engenharia automática de recursos. Neste artigo, nós os combinamos modelando a similaridade de palavras de contexto em TKs semânticos. Desta forma, o último pode operar o casamento de subárvores aplicando similaridade baseada em neurônios em nós léxicos de árvores. Estudamos como aprender representações para as palavras em contexto, de modo que os TKs possam explorar informações mais focadas. Descobrimos que os embeddings neurais produzidos pelos métodos atuais não fornecem uma similaridade contextual adequada. Assim, definimos uma nova abordagem baseada em uma rede siamesa, que produz representações de palavras enquanto aprende uma semelhança de texto binário. Definimos o último considerando exemplos na mesma categoria que similares. Os experimentos de classificação de perguntas e sentimentos mostram que nosso TK semântico melhora muito os resultados anteriores.', 'es': 'Los núcleos de árbol (TKs) y las redes neuronales son dos enfoques eficaces para la ingeniería automática de funciones. En este artículo, los combinamos modelando la similitud de palabras de contexto en los TK semánticos. De esta manera, este último puede operar la coincidencia de subárboles mediante la aplicación de similitud basada en neuronas en los nodos léxicos de los árboles. Estudiamos cómo aprender representaciones de las palabras en contexto de modo que los TK puedan aprovechar información más enfocada. Se encontró que las incrustaciones neuronales producidas por los métodos actuales no proporcionan una similitud contextual adecuada. Por lo tanto, definimos un nuevo enfoque basado en una red siamesa, que produce representaciones de palabras mientras aprende una similitud de texto binario. Fijamos este último considerando ejemplos de la misma categoría como similares. Los experimentos sobre la clasificación de preguntas y sentimientos muestran que nuestro CT semántico mejora en gran medida los resultados anteriores.', 'fr': "Les noyaux d'arbre (TK) et les réseaux de neurones sont deux approches efficaces pour l'ingénierie automatique des caractéristiques. Dans cet article, nous les combinons en modélisant la similitude des mots contextuels dans les CT sémantiques. De cette façon, ce dernier peut opérer une correspondance de sous-arborescence en appliquant une similitude basée sur les neurones sur les nœuds lexicaux de l'arbre. Nous étudions comment apprendre les représentations des mots dans leur contexte afin que les connaissances traditionnelles puissent exploiter des informations plus ciblées. Nous avons constaté que les intégrations neuronales produites par les méthodes actuelles ne fournissent pas une similitude contextuelle appropriée. Ainsi, nous définissons une nouvelle approche basée sur un réseau siamois, qui produit des représentations de mots tout en apprenant une similitude textuelle binaire. Nous définissons ce dernier en tenant compte des exemples de la même catégorie que similaires. Les expériences sur la classification des questions et des sentiments montrent que nos savoirs traditionnels sémantiques améliorent considérablement les résultats précédents.", 'ja': 'ツリーカーネル（ ＴＫ ）及びニューラルネットワークは、自動機能工学のための２つの効果的なアプローチである。本稿では、意味論的TKにおけるコンテキストワードの類似性をモデル化することでそれらを組み合わせる。このようにして、後者は、ニューラルベースの類似性を木の語彙ノードに適用することによって、サブツリーマッチングを操作することができる。私たちは、TKがより焦点を当てた情報を活用できるように、文脈内の単語の表現を学ぶ方法を研究しています。我々は、現在の方法によって生成されたニューラル埋め込みは、適切な文脈上の類似性を提供しないことを発見した。したがって、バイナリテキストの類似性を学習しながら単語表現を生成するSiamese Networkに基づいた新しいアプローチを定義します。同様のカテゴリの例を考慮して後者を設定しました。疑問と感情の分類に関する実験は、私たちの意味論的TKが以前の結果を非常に改善することを示しています。', 'zh': '树核(TK)、神经网络者,自效之道也。 本文者,因语义TK之上下文词相似性而建模合之。 然后可以树词法节点用神经之相似性以操子树配。 何以上下文学单词,以古知可集。 今法所生神经嵌不可上下文相似性。 故义在暹罗网络新法,其法在学二进制文本相似性同时生单词。 吾置后者虑同类之示例。 情类实验明,语义知大改。', 'hi': 'ट्री कर्नेल (टीके) और तंत्रिका नेटवर्क स्वचालित सुविधा इंजीनियरिंग के लिए दो प्रभावी दृष्टिकोण हैं। इस पेपर में, हम उन्हें शब्दार्थ टीके में संदर्भ शब्द समानता मॉडलिंग द्वारा संयोजित करते हैं। इस तरह, उत्तरार्द्ध पेड़ लेक्सिकल नोड्स पर तंत्रिका-आधारित समानता लागू करके सबट्री मिलान का संचालन कर सकता है। हम अध्ययन करते हैं कि संदर्भ में शब्दों के लिए प्रतिनिधित्व कैसे सीखें जैसे कि टीके अधिक केंद्रित जानकारी का शोषण कर सकते हैं। हमने पाया कि वर्तमान विधियों द्वारा उत्पादित तंत्रिका एम्बेडिंग एक उपयुक्त प्रासंगिक समानता प्रदान नहीं करते हैं। इस प्रकार, हम एक सियामी नेटवर्क के आधार पर एक नए दृष्टिकोण को परिभाषित करते हैं, जो बाइनरी टेक्स्ट समानता सीखते समय शब्द प्रतिनिधित्व का उत्पादन करता है। हमने समान के रूप में एक ही श्रेणी में उदाहरणों पर विचार करते हुए उत्तरार्द्ध सेट किया। प्रश्न और भावना वर्गीकरण पर प्रयोगों से पता चलता है कि हमारे शब्दार्थ टीके पिछले परिणामों में अत्यधिक सुधार करते हैं।', 'ru': 'Ядра деревьев (TK) и нейронные сети являются двумя эффективными подходами для автоматической разработки функций. В этой статье мы объединяем их, моделируя сходство контекстного слова в семантических ТЗ. Таким образом, последний может работать с поддеревом путем применения нейронного сходства к лексическим узлам дерева. Мы изучаем, как выучить представления для слов в контексте, чтобы ТЗ могли использовать более сфокусированную информацию. Мы обнаружили, что нейронные вставки, созданные современными методами, не обеспечивают подходящего контекстного сходства. Таким образом, мы определяем новый подход, основанный на сиамской сети, которая производит представления слов, изучая сходство двоичного текста. Мы ставим последние, рассматривая примеры в той же категории, что и аналогичные. Эксперименты по классификации вопросов и настроений показывают, что наши семантические ТЗ значительно улучшают предыдущие результаты.', 'ga': 'Dhá chur chuige éifeachtacha iad eithne crann (TKanna) agus líonraí néaracha maidir le hinnealtóireacht uathghnéitheach. Sa pháipéar seo, cuirimid le chéile iad trí chosúlacht focal comhthéacs a shamhaltú i TKanna shéimeantacha. Ar an mbealach seo, is féidir leis an dara ceann meaitseáil fochrainn a oibriú trí chosúlacht néarbhunaithe a chur i bhfeidhm ar nóid léacsacha crann. Déanaimid staidéar ar conas léirithe do na focail a fhoghlaim i gcomhthéacs ionas gur féidir le TKanna leas a bhaint as faisnéis níos dírithe. Fuaireamar amach nach soláthraíonn leabaithe néaracha a tháirgtear trí mhodhanna reatha cosúlacht chomhthéacsúil oiriúnach. Mar sin, sainmhínímid cur chuige nua bunaithe ar Líonra Siamese, a tháirgeann uiríll focal agus ag foghlaim cosúlacht téacs dénártha. Shocraigh muid an dara ceann ag smaoineamh ar shamplaí sa chatagóir chéanna le samplaí comhchosúla. Léiríonn na turgnaimh ar cheist agus aicmiú meon go bhfeabhsaíonn ár TK shéimeantach torthaí roimhe seo go mór.', 'el': 'Οι πυρήνας δέντρων και τα νευρωνικά δίκτυα είναι δύο αποτελεσματικές προσεγγίσεις για την αυτόματη μηχανική χαρακτηριστικών. Σε αυτή την εργασία, τις συνδυάζουμε μοντελοποιώντας ομοιότητα λέξεων περιβάλλοντος σε σημασιολογικές TK. Με αυτόν τον τρόπο, οι τελευταίοι μπορούν να λειτουργήσουν αντιστοίχιση υποτίτων εφαρμόζοντας ομοιότητα βασισμένη σε νευρώνες σε λεξικούς κόμβους δέντρων. Μελετάμε πώς να μάθουμε αναπαραστάσεις των λέξεων στο πλαίσιο έτσι ώστε οι ΤΚ να μπορούν να εκμεταλλευτούν πιο εστιασμένες πληροφορίες. Διαπιστώσαμε ότι οι νευρωνικές ενσωματώσεις που παράγονται με τις τρέχουσες μεθόδους δεν παρέχουν κατάλληλη ομοιότητα στο πλαίσιο. Έτσι, καθορίζουμε μια νέα προσέγγιση βασισμένη σε ένα Σιαμέζικο Δίκτυο, το οποίο παράγει αναπαραστάσεις λέξεων ενώ μαθαίνει μια δυαδική ομοιότητα κειμένου. Τα τελευταία θέτουμε λαμβάνοντας υπόψη παραδείγματα στην ίδια κατηγορία με παρόμοια. Τα πειράματα σχετικά με την ταξινόμηση ερωτήσεων και συναισθημάτων δείχνουν ότι η σημασιολογική μας ΤΚ βελτιώνει σημαντικά τα προηγούμενα αποτελέσματα.', 'ka': 'სახელის კენელი (TKs) და ნეიროლური ქსელები ორი ეფექტიური პროგრამები ავტომატიკური ფუნქციების ინეზინერიციისთვის. ამ დოკუნტში ჩვენ ისინი კონტექსტური სიტყვების სხვადასხვა სიტყვებით სემონტიკური TKs-ში გამოყენებთ. ასე, შემდეგ შეუძლია აკეთება სტრიქტური თანამდგომარების გამოყენებით ნეიროლური დაბათებული სინამდგომარეობაზე. ჩვენ ვისწავლობთ როგორ გავისწავლობთ სიტყვებისთვის კონტექსტში, როგორც TKs შეუძლია გამოიყენოთ უფრო ფოკუნური ინფორმაცია. ჩვენ აღმოჩნეთ, რომ მიმდინარე მეტოვებით წარმოიქმნილი ნეიროლური ინბიდნეციები არ მოხდება საჭირო კონტექსტური განსხვავება. ამიტომ, ჩვენ ახალი პროგრამის განსაზღვრება Siamese ქსელის ბაზაზე, რომელიც გამოვიყენებს სიტყვების განსაზღვრება, რომელიც ბინარი ტექსტის განსხვავება იყოს. ჩვენ შემდეგი მაგალითების შესახებ იგივე კატეგორიაში, როგორც მსგავსი. ექსპერიმენტები კითხვის და სენტიმენტების კლასიფიკაციის შესახებ, რომ ჩვენი სენტიკური TK ძალიან უფრო უფრო უფრო უფრო უფრო უფრო მე', 'hu': 'A fa magok (TK) és az idegi hálózatok két hatékony megközelítést jelentenek az automatikus funkciótervezéshez. Ebben a tanulmányban kombináljuk őket a kontextusszó hasonlóságának modellezésével a szemantikus TK-kben. Ez utóbbi így tudja működtetni a szubsztrátumok egyeztetését neurális alapú hasonlóság alkalmazásával a fa lexikális csomópontokon. Tanulmányozzuk, hogyan tanulhatjuk meg a szavak reprezentációit kontextusban, hogy a TK-k kihasználhassák a koncentráltabb információkat. Megállapítottuk, hogy a jelenlegi módszerekkel előállított neurális beágyazások nem biztosítanak megfelelő kontextuális hasonlóságot. Így új megközelítést határozunk meg egy sziámi hálózaton alapuló új megközelítésre, amely szóreprezentációkat hoz létre, miközben megtanuljuk a bináris szöveghasonlóságot. Az utóbbit ugyanabban a kategóriában mutatjuk be, mint hasonló példákat. A kérdéses és érzelmi osztályozással kapcsolatos kísérletek azt mutatják, hogy a szemantikai TK jelentősen javítja a korábbi eredményeket.', 'it': "I kernel ad albero (TK) e le reti neurali sono due approcci efficaci per l'ingegneria automatica delle funzionalità. In questo articolo, li combiniamo modellando la somiglianza delle parole di contesto in TK semantici. In questo modo, quest'ultimo può operare la corrispondenza dei subtrei applicando la somiglianza neurale sui nodi lessicali degli alberi. Studiamo come imparare le rappresentazioni delle parole nel contesto in modo che TK possa sfruttare informazioni più mirate. Abbiamo scoperto che le incorporazioni neurali prodotte con i metodi attuali non forniscono una somiglianza contestuale adeguata. Quindi definiamo un nuovo approccio basato su una Rete Siamese, che produce rappresentazioni di parole mentre apprende una somiglianza di testo binario. Abbiamo impostato quest'ultimo considerando esempi nella stessa categoria come simili. Gli esperimenti sulla classificazione delle domande e dei sentimenti mostrano che il nostro TK semantico migliora notevolmente i risultati precedenti.", 'lt': 'Medžių branduoliai ir nerviniai tinklai yra du veiksmingi automatinės savybių inžinerijos metodai. Šiame dokumente mes juos deriname modeliuodami kontekstinį žodį panašumą semantiniais TK. Tokiu būdu pastaroji gali veikti subtrinį derinimą, taikant nervinius panašumus medžio leksiniams mazgams. Mes tiriame, kaip mokytis atstovauti žodžiams tokiomis aplinkybėmis, kad TK galėtų panaudoti tikslesnę informaciją. Nustatėme, kad dabartiniais metodais pagaminti nervų įterpimai nesuteikia tinkamo kontekstinio panašumo. Thus, we define a new approach based on a Siamese Network, which produces word representations while learning a binary text similarity.  Pastaruosius pateikėme svarstant pavyzdžius toje pačioje ir panašioje kategorijose. Eksperimentai dėl klausimų ir jausmų klasifikacijos rodo, kad mūsų semantinė savybė labai pagerina ankstesnius rezultatus.', 'mk': 'Дрвените јадри (ТК) и нервните мрежи се два ефикасни пристапи за автоматско инженерство на карактеристики. Во овој весник, ги комбинираме со моделирање на контекстна сличност на зборот во семантични ТК. На овој начин, вториот може да функционира подтри спојувања со апликација на неурална сличност на лексикалните јазли на дрвјата. Студираме како да научиме претставувања за зборовите во контекст како што ТК може да искористи пофокусирани информации. Најдовме дека нервните вградувања произведени со тековните методи не обезбедуваат соодветна контекстуална сличност. Thus, we define a new approach based on a Siamese Network, which produces word representations while learning a binary text similarity.  Ги поставуваме последните со оглед на примерите во истата категорија како слични. Експериментите на прашањето и класификацијата на чувствата покажуваат дека нашата семантична технологија многу ги подобрува претходните резултати.', 'ms': 'Kernel pokok (TK) dan rangkaian saraf adalah dua pendekatan yang efektif untuk teknik ciri automatik. Dalam kertas ini, kita menggabungkannya dengan memmodelkan perkataan konteks persamaan dalam TK semantik. Dengan cara ini, yang terakhir boleh operasikan persamaan subtree dengan melaksanakan persamaan berasaskan saraf pada nod leksikal pokok. Kami belajar bagaimana untuk belajar mewakili perkataan dalam konteks sehingga TK boleh mengeksploitasi maklumat yang lebih fokus. We found that neural embeddings produced by current methods do not provide a suitable contextual similarity.  Oleh itu, kita menentukan pendekatan baru berdasarkan Rangkaian Siama, yang menghasilkan perwakilan perkataan semasa mempelajari kesamaan teks binari. Kami tetapkan contoh yang terakhir dalam kategori yang sama dengan yang sama. Eksperimen mengenai pertanyaan dan klasifikasi perasaan menunjukkan bahawa TK semantik kita meningkatkan keputusan sebelumnya.', 'kk': 'Бұтақ тұтақтары (ТК) мен невралдық желі автоматты мүмкіндіктердің инженериясының екі әсер етікті арқылы. Бұл қағазда, біз оларды semantic TKs үшін контексті сөздердің ұқсастығын моделдеп жинақтаймыз. Бұл үшін, соңғылар неврал негіздеген лексикалық түрлеріне ұқсас түрлерді қолдануға болады. Біз сөздер үшін мәліметтерді қалай оқытуды үйренеміз, бұл үшін ТК-лер көңіл көздеген мәліметті қолдануға болады. Біз назардағы әдістер бойынша жасалған невралдық ендіруді жақсы контексті ұқсас етпейді. Біз Siamese желіне негізделген жаңа тәсілді анықтаймыз. Бұл бинарлық мәтіннің ұқсастығын үйрену кезінде сөздерді көрсетеді. Біз соңғы мысалдарды бір санаттағы ұқсас деп ойладық. Сұрақ және сезімдердің классификациясының тәжірибелері біздің semantic TK-міздің алдыңғы нәтижелерін өте жақсарту дегенді көрсетеді.', 'ml': 'വൃക്ഷത്തിലെ കെര്\u200dണലുകള്\u200d (TKs) പിന്നെ ന്യൂറല്\u200d ശൃംഖലകളും സ്വയം പ്രത്യേക പ്രധാനപ്പെടുത്തി എഞ്ചിനീജിനീയറി ഈ പത്രത്തില്\u200d, നമ്മള്\u200d അതിനെ മോഡല്\u200d ചെയ്യുന്നതിന്റെ വാക്ക് സെമാന്റിക് ടിക്കികളില്\u200d ഒരുപോലെയാണ്. ഈ വഴിയില്\u200d, അവസാനം സബ്ട്രീവിനോട് പൊരുത്തുന്ന സ്വഭാവം പ്രവര്\u200dത്തിപ്പിക്കാന്\u200d സാധിക്കുന്നു. മരത്തിലെ ലെക് ടിക്കികള്\u200dക്ക് കൂടുതല്\u200d ശ്രദ്ധിക്കുന്ന വിവരങ്ങള്\u200d ഉപയോഗിക്കാന്\u200d കഴിയുന്ന വാക്കുകള്\u200dക്ക് എങ്ങനെയാണ് പഠ ഇപ്പോഴത്തെ രീതികളില്\u200d നിന്നും ഉണ്ടാക്കിയ ന്യൂറല്\u200d എപ്പോഡിങ്ങുകള്\u200d ഒരുപോലെയല്ല എന്ന് ഞങ്ങള്\u200d കണ്ടെത്തി. അതുകൊണ്ട്, ഒരു സിയാമീസ് നെറ്റ്\u200cവര്\u200dക്ക് അടിസ്ഥാനമായ ഒരു പുതിയ പ്രായോഗ്യം നാം നിര്\u200dണയിക്കുന്നു. അത് ഒരു ബൈനരി ടെക് പിന്\u200dഗാമികളെ നാം ഒരേ വിഭാഗത്തില്\u200d ഉദാഹരണങ്ങളാക്കിയിരിക്കുന്നു. ചോദ്യം ചെയ്യുന്നതിന്\u200dറെയും വികാരങ്ങളുടെയും പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ സെമാന്റിക് ടികെയിന്\u200dറെ', 'mt': 'Il-qalba tas-siġar (TKs) u n-netwerks newrali huma żewġ approċċi effettivi għall-inġinerija awtomatika tal-karatteristiċi. F’dan id-dokument, aħna ngħaqduhom billi nimmudellaw il-kelma tal-kuntest similarità fit-TKs semantiċi. B’dan il-mod, dan tal-aħħar jista’ jopera tqabbil subtri billi japplika similarità bbażata fuq in-newrali fuq in-nodi lexiċi tas-siġar. Aħna nistudjaw kif jitgħallmu r-rappreżentazzjonijiet għall-kliem f’kuntest b’tali mod li t-TKs jistgħu jisfruttaw informazzjoni aktar iffukata. We found that neural embeddings produced by current methods do not provide a suitable contextual similarity.  Għalhekk, niddefinixxu approċċ ġdid ibbażat fuq Netwerk Siamese, li jipproduċi rappreżentazzjonijiet tal-kliem waqt li jitgħallmu similarità tat-test binarju. Aħna nistabbilixxu dawn tal-aħħar billi nqisu eżempji fl-istess kategorija bħal simili. L-esperimenti dwar il-kwistjoni u l-klassifikazzjoni tas-sentimenti juru li t-TK semantika tagħna ttejjeb ħafna r-riżultati preċedenti.', 'pl': 'Jądra drzew (TK) i sieci neuronowe to dwa skuteczne podejścia do automatycznej inżynierii funkcji. W artykule łączymy je poprzez modelowanie kontekstowego podobieństwa słów w semantycznych TK. W ten sposób te ostatnie mogą obsługiwać dopasowanie podliczek poprzez zastosowanie podobieństwa opartego na neuronie na węzłach leksykalnych drzew. Badamy, jak uczyć się reprezentacji słów w kontekście, tak aby TK mogły wykorzystywać bardziej skoncentrowane informacje. Stwierdziliśmy, że osadzenia neuronowe produkowane obecnymi metodami nie zapewniają odpowiedniego kontekstowego podobieństwa. W ten sposób definiujemy nowe podejście oparte na sieci syjamskiej, która produkuje reprezentacje słów podczas uczenia się podobieństwa tekstu binarnego. Te ostatnie ustawiamy biorąc pod uwagę przykłady w tej samej kategorii jak podobne. Eksperymenty dotyczące klasyfikacji pytań i sentymentów pokazują, że nasza semantyczna TK znacznie poprawia poprzednie wyniki.', 'mn': 'Модны цэцэг (TKs) болон мэдрэлийн сүлжээг автоматжуулалтын инженерийн хоёр үр дүнтэй арга юм. Энэ цаасан дээр бид тэднийг зэрэгцээ үг төстэй хэлбэрээр нэгтгэдэг. Үүний дараагийн нь модны лексикийн цогцууд дээр мэдрэлийн үндсэн төстэй адилхан байдлыг ашиглаж болно. Бид хэрхэн тодорхой мэдээлэл ашиглаж чадна гэдгийг судалж байна. Бид одоогийн арга хэмжээгээр бүтээгдэхүүний сэтгэл хөдлөл нь тохиромжтой төстэй адилхан байдлаар хангадаггүй гэдгийг олж мэдсэн. Тиймээс бид Siamese Network-ын үндсэн шинэ арга замыг тодорхойлдог. Энэ нь хоёр дахь текст төстэй байдлыг сурах үед үг илэрхийллийг гаргадаг. Бид дараагийн жишээг ижил хэлбэртэй адилхан хэлбэрээр тайлбарласан. Суулт болон сэтгэл хөдлөлийн хуваалтын туршилтууд бидний өмнөх үр дүнг сайжруулдаг гэдгийг харуулдаг.', 'no': 'Trekjerner (TKs) og neuralnettverk er to effektive tilnærmingar for automatisk funksjonsengineering. I denne papiret kombinerer vi dei med modellering av kontekstordlikhet i semantiske TKs. Denne måten kan den siste operasjonen med understreka samsvar ved å bruka neuralbasert liknande på tre- leksiske noder. Vi studerer korleis å lære representasjonar for ord i konteksten slik at TKs kan bruka meir fokusert informasjon. Vi fann at neuralinnbyggingar som er produsert av gjeldande metodar ikkje gjev nokon passande kontekstlikt. Dette definerer vi eit ny tilnærming basert på eit Siamese nettverk, som produserer ordrepresentasjonar medan lærer ein binær tekstlikning. Vi sett dei siste eksemplane i same kategori som liknande. Eksperimentane om spørsmål og sentimentklassifikasjon viser at vår semantisk TK forbetrar tidlegare resultat.', 'ro': 'Nucleele arborelor (TK) și rețelele neurale sunt două abordări eficiente pentru ingineria automată a caracteristicilor. În această lucrare, le combinăm prin modelarea similitudinii cuvintelor contextuale în TK-uri semantice. În acest fel, acesta din urmă poate opera potrivirea subtrei prin aplicarea similarității neurale pe nodurile lexicale arborești. Studiem cum să învățăm reprezentări pentru cuvinte în context astfel încât TK-urile să poată exploata informații mai concentrate. Am constatat că încorporările neuronale produse prin metodele actuale nu oferă o asemănare contextuală adecvată. Astfel, definim o nouă abordare bazată pe o rețea siameză, care produce reprezentări de cuvinte în timp ce învățăm o similitudine de text binar. Am stabilit acest din urmă luând în considerare exemple din aceeași categorie ca similare. Experimentele privind clasificarea întrebărilor și sentimentelor arată că TK semantic îmbunătățește foarte mult rezultatele anterioare.', 'sv': 'Träkärnor (TK) och neurala nätverk är två effektiva metoder för automatisk funktionsteknik. I denna uppsats kombinerar vi dem genom att modellera kontextordlikhet i semantiska TK. På så sätt kan den senare använda subtree matchning genom att tillämpa neuralbaserad likhet på trädlexikala noder. Vi studerar hur man lär sig representationer för orden i ett sammanhang så att TK kan utnyttja mer fokuserad information. Vi fann att neurala inbäddningar producerade med nuvarande metoder inte ger en lämplig kontextuell likhet. Således definierar vi ett nytt tillvägagångssätt baserat på ett siamesiskt nätverk, som producerar ordrepresentationer samtidigt som vi lär oss en binär textlikhet. Vi sätter det senare med tanke på exempel i samma kategori som liknande. Experimenten med fråga- och sentimentklassificering visar att vår semantiska TK avsevärt förbättrar tidigare resultat.', 'sr': 'Drvi kerneli (TKs) i nervne mreže su dva efikasna pristupa za automatski inženjering funkcija. U ovom papiru, kombiniramo ih modeliranjem kontekstske reči sličnosti u semantičkim TK-ima. Na ovaj naèin, poslednji može da funkcioniše podstresne odgovarajuće primjenom neurološke sliènosti na leksičkim čvorovima drveta. Proučavamo kako naučiti predstave za reči u kontekstu tako da TKs može iskoristiti fokusiranije informacije. Pronašli smo da neuralne integracije proizvode trenutnim metodama ne pružaju odgovarajuću kontekstualnu sličnost. Dakle, definišemo novi pristup baziran na Siamejskoj mreži, koja proizvodi riječi predstavljanja dok učimo sličnost binarnog teksta. Posljednji smo postavili s obzirom na primjere u istoj kategoriji kao slične. Eksperimenti o pitanju i klasifikaciji sentimenta pokazuju da naš semantički TK veoma poboljšava prethodne rezultate.', 'so': 'Geedka kernels (TKs) iyo shabakada neurada waa laba qaab oo faa’iido leh oo ka shaqeeya injiilka maamulka ah. Qoraalkan waxaynu ku dari karnaa qoraal sameynaya si siman oo u eg TKs. This way, the latter can operate subtree matching by applying neural-based similarity on tree lexical nodes.  Waxaynu baranaynaa sida aad u barto noocyo-wakiilada hadallada, taas oo ah sida TKs ay macluumaad dheeraad ah u isticmaali karto. Waxaynu ogaannay in qalabka naafada ah oo ay soo saaraan qaababka haatan aysan wax u eg isku mid ah. Sidaas darteed waxaynu qoraynaa qaab cusub oo ku saleysan shabakadda Siamese, kaas oo soo saara macluumaad u eg marka la barto qoraal labaad oo isku mid ah. Waxaana kayeelay tusaalayaal kuwii dambe oo kale. Imtixaanka ku saabsan fasaxa arimaha iyo fikrada waxay muuqataa in TK-kanu uu si weyn u beddelo resultiyada hore.', 'si': 'Tree kernells (TKs) සහ න්\u200dයූරල් ජාලය දෙකයි ස්වයංක්\u200dරියාත්මක විශේෂතාවක් ඉන්ජිනයින් වෙනුවෙන් ප්\u200dර මේ පැත්තේ, අපි ඔවුන්ව සම්බන්ධ වචන සමාන්\u200dය TKs වලින් සමාන්\u200dය විදියට සමාන්ය කරනවා. මෙහෙම විදියට, අන්තිම විදියට පුළුවන් විදියට පුළුවන් පුළුවන් පුළුවන් විදියට පුළුවන් න්\u200dයූරා අපි අධ්\u200dයානය කරනවා කොහොමද ප්\u200dරතිචාරයක් ඉගෙන ගන්නේ කියලා, ඒ වගේම TKs ට තව ප්\u200dරතිචාරයක් ප්\u200dරතිච අපි හොයාගෙන හිටියා මේ විදියට ප්\u200dරතිචාර විදියට නිර්මාණික සංවිධානයක් ප්\u200dරතිචාර විදියට සමා ඉතින්, අපි සියාමිස් ජාලයේ ආධාරිත අළුත් ප්\u200dරවේශයක් විශ්වාස කරනවා, ඒකෙන් බායිනාරි පාළුවක් වගේ සාමා අපි අන්තිම වර්ගයක් වගේ උදාහරණ සැකසුම් කරනවා. ප්\u200dරශ්නය සහ විශේෂ විශේෂණයේ පරීක්ෂණය පෙන්වන්නේ අපේ සැමැන්තික TK ප්\u200dරශ්නයක් ප්\u200dරශ්නය කරනවා', 'ta': 'Tree kernels (TKs) and neural networks are two effective approaches for automatically feature engineering. இந்த காகிதத்தில், நாம் அவர்களை மாதிரியும் சூழ்ச்சி சொல்லை ஒப்பிடும் மூலம் இணைக்கிறோம். இந்த வழியில், பின்வரும் துணை மரத்தின் லெக்சிகிள் புள்ளிகளில் பொருந்தும் துணை மரத்தை செயல்படுத்தலாம். TKகள் மேலும் கவனமான தகவலை பயன்படுத்த முடியும் என்ற வார்த்தைகளுக்கு எவ்வாறு பிரதிநிதிகளை கற்றுக் கொள்கிற தற்போதைய முறைமைகளால் உருவாக்கப்பட்ட புதிய உள்ளடக்கங்கள் ஒரு பொருத்தமான தற்காலிக நிலையில் ஒத்திசையை கொடு எனவே, நாம் ஒரு புதிய செயலை வரையறுக்கிறோம் ஒரு சையமேசி வலைப்பின்னல் அடிப்படையில், அது ஒரு இருமுறை உரை ஒத்திசைப்படுத்தும்  பின்னுள்ளவர்களுக்கும் அதைப் போன்ற உதாரணங்களை நாம் ஏற்படுத்தினோம். கேள்வி மற்றும் உணர்வு வகுப்புகள் பற்றிய சோதனைகள் நமது பாதிப்பு TK முந்தைய விளைவுகளை மிக மேம்படுத்துகிறது', 'ur': 'Tree kernels (TKs) اور neural networks are two effective approaches for automatic feature engineering. اس کاغذ میں ہم ان کو سیمنٹی ٹی کیس میں سیمانٹی کلمات کی مثالی کے ذریعہ ترکیب کرتے ہیں۔ اسی طرح، پچھلے لوگ نیورال بنیادی برابری کو درخت لکسیکل نوڈ پر لازم کریں گے. ہم پڑھتے ہیں کہ کلمات کی تعلیم کس طرح سکھائیں اس طرح کہ TKs اس سے زیادہ منظور معلومات کا استعمال کر سکتے ہیں۔ ہم نے پایا کہ موجود طریقے سے پیدا ہوئے نیورال ایمبڈینگ ایک مناسب متصلہ برابر نہیں کرتی۔ اسی طرح، ہم ایک سیامی نیٹ ورک پر بنیاد ایک نوی طریقہ کی تعریف کرتے ہیں، جو ایک دوسری ٹیکسٹ برابری کی تعلیم میں کلمات کی نمایش پیدا کرتا ہے۔ اور ہم نے پچھلوں کو ایک طریقہ میں مثالیں بنائیں سوال اور sentiment classification کی آزمائش دکھاتی ہے کہ ہماری سیمانٹی ٹی کی پہلے نتائج بہت زیادہ بہتر ہوتی ہے.', 'uz': "Name Bu qogʻozda biz ularni semantik TKlarda birlashtiramiz. Bu yerda keyingi daraxt toʻgʻri tugmalar birikmasini qoʻllash mumkin. Biz qanday so'zlarning tajribalarini o'rganishni o'rganamiz. TKlar qo'shimcha foydalanish mumkin. Biz shunday topdikki, joriy usullar yaratilgan neyron embedded to'g'ri xil tili emas. Shunday qilib, biz Siamese tarmoq asosida yangi usulni aniqlaysiz. Bu bir ikkita matn bir xil tilni o'rganishda so'zni tashkilotga chiqaradi. Ва кейингиларга мисоллар қилиб қўйдик. savol va sentiment classifikasining tajribalari esa bizning semantik TK natijalarimiz oldingi natijalarni juda yaxshi ko'paydi.", 'vi': 'Các hạt nhân cây (TK) và mạng thần kinh là hai phương pháp hiệu quả cho việc chế tạo tính năng tự động. Trong tờ giấy này, chúng ta kết hợp chúng bằng cách tạo mẫu từ tương tự theo ngữ cảnh. Cách này, bộ này có thể vận hành trừ bằng cách áp dụng khả năng kết hợp thần kinh với các lõi tiếp xúc. Chúng tôi nghiên cứu cách tìm hiểu các biểu hiện của các từ trong ngữ cảnh để nhờ đó người máy có thể khai thác thông tin chuyên nghiệp hơn. Chúng tôi phát hiện rằng sự cấy ghép thần kinh do các phương pháp hiện thời không mang lại kết quả phù hợp giống nhau. Do đó, chúng tôi xác định một phương pháp mới dựa trên một mạng lưới Siamese, nó sản xuất các biểu tượng từ trong khi học một kết cấu nhị phân. Chúng tôi phân tích những ví dụ giống nhau. Thử nghiệm về phân loại nghi vấn và cảm xúc cho thấy rằng ngữ pháp của chúng ta cải thiện tối đa kết quả trước.', 'nl': "Tree kernels (TK's) en neurale netwerken zijn twee effectieve benaderingen voor automatische feature engineering. In dit artikel combineren we ze door context woordgelijkenis in semantische TK's te modelleren. Op deze manier kan de laatste subtree matching uitvoeren door neurale gelijkenis toe te passen op boomlexicale knooppunten. We bestuderen hoe we representaties voor de woorden leren in context, zodat TK's meer gerichte informatie kunnen benutten. We ontdekten dat neurale embeddings geproduceerd door huidige methoden geen geschikte contextuele gelijkenis bieden. Zo definiëren we een nieuwe aanpak gebaseerd op een Siamese Netwerk, dat woordrepresentaties produceert terwijl we een binaire tekstgelijkenis leren. We zetten deze laatste rekening met voorbeelden in dezelfde categorie als vergelijkbaar. Uit de experimenten op vraag- en sentimentclassificatie blijkt dat onze semantische TK eerdere resultaten sterk verbetert.", 'da': "Trækerner (TK'er) og neurale netværk er to effektive tilgange til automatisk feature engineering. I denne artikel kombinerer vi dem ved at modellere sammenhængende ordlighed i semantiske TK'er. På denne måde kan sidstnævnte betjene subtree matching ved at anvende neural-baseret lighed på træ leksikalske knuder. Vi studerer, hvordan man lærer repræsentationer for ordene i sammenhæng, så TK'er kan udnytte mere fokuseret information. Vi fandt ud af, at neurale indlejringer produceret ved nuværende metoder ikke giver en passende kontekstuel lighed. Således definerer vi en ny tilgang baseret på et siamesisk netværk, som producerer ordrepræsentationer, mens vi lærer en binær tekst lighed. Vi sætter sidstnævnte i betragtning af eksempler i samme kategori som lignende. Eksperimenterne med spørgsmål og sentimentklassificering viser, at vores semantiske TK i høj grad forbedrer tidligere resultater.", 'bg': 'Дървесните ядра (ТК) и невронните мрежи са два ефективни подхода за автоматичното инженерство на функциите. В тази статия ги комбинираме чрез моделиране на сходството на контекстните думи в семантични ТК. По този начин последният може да оперира съвпадение на субтрии чрез прилагане на невронно базирано сходство върху дървесни лексикални възли. Изучаваме как да научим представяне на думите в контекст, така че ТК да могат да използват по-фокусирана информация. Установихме, че невронните вграждания, произведени по настоящите методи, не осигуряват подходяща контекстуална прилика. По този начин ние дефинираме нов подход, базиран на сиамска мрежа, която произвежда думи представящи, докато изучава двойна текстова сходство. Задаваме последния като разглеждаме примери в същата категория като подобни. Експериментите по въпросите и сантименталната класификация показват, че семантичната ни ТК подобрява значително предишните резултати.', 'de': 'Baumkerne (TKs) und neuronale Netze sind zwei effektive Ansätze für das automatische Feature Engineering. In diesem Beitrag kombinieren wir sie, indem wir Kontextwörterähnlichkeit in semantischen TKs modellieren. Auf diese Weise kann letztere Subree Matching betreiben, indem neuronale Ähnlichkeit auf lexikalischen Knoten angewendet wird. Wir untersuchen, wie man Darstellungen für Wörter im Kontext lernt, so dass TKs fokussiertere Informationen nutzen können. Wir fanden heraus, dass neuronale Einbettungen, die mit aktuellen Methoden erzeugt werden, keine geeignete kontextbezogene Ähnlichkeit bieten. Daher definieren wir einen neuen Ansatz basierend auf einem Siamesischen Netzwerk, das Wortrepräsentationen erzeugt und dabei eine binäre Textähnlichkeit lernt. Letztere setzen wir unter Berücksichtigung von Beispielen in der gleichen Kategorie als ähnlich ein. Die Experimente zur Frage- und Sentiment-Klassifizierung zeigen, dass unsere semantische TK bisherige Ergebnisse stark verbessert.', 'hr': 'Drvački kerneli (TKs) i nervne mreže su dvije učinkovite pristupe za automatski inženjering funkcija. U ovom papiru, kombiniramo ih modeliranjem kontekstske riječi sličnosti u semantičkim TK-ima. Na taj način, posljednja može funkcionirati supstražno odgovarajuće primjenom neurološke sličnosti na leksičkim čvorovima drveta. Proučavamo kako naučiti zastupanje riječi u kontekstu tako da TKs može iskoristiti fokusiranije informacije. Pronašli smo da neuralne integracije proizvođene trenutnim metodama ne pružaju odgovarajuću kontekstualnu sličnost. Stoga definiramo novi pristup na temelju Siamese mreže, koji proizvodi riječi predstavljanja dok učimo sličnost binarnog teksta. Posljednji smo postavili s obzirom na primjere u istoj kategoriji kao slične. Eksperimenti o pitanju i klasifikaciji osjećaja pokazuju da naš semantički TK veoma poboljšava prethodne rezultate.', 'ko': '나무 핵과 신경 네트워크는 자동 특징 공정의 두 가지 효과적인 방법이다.본문에서 우리는 의미 TKs에서 모델링 상하문 단어의 유사성을 통해 그것들을 결합시켰다.이런 방식을 통해 후자는 나무 어휘 노드에 신경 네트워크를 바탕으로 하는 유사성을 응용하여 서브 트리 매칭을 할 수 있다.우리는 TKs가 더욱 집중된 정보를 이용할 수 있도록 상하문에서 단어의 표현을 어떻게 배우는지 연구했다.우리는 현재의 방법으로 발생하는 신경 삽입이 적당한 상하문 유사성을 제공할 수 없다는 것을 발견했다.따라서 우리는 샴로 네트워크를 바탕으로 하는 새로운 방법을 정의했다. 이 방법은 2진 텍스트의 유사성을 학습하는 동시에 단어 표시를 생성한다.우리는 후자를 동류 중의 예로 본다.문제와 감정의 분류에 대한 실험은 우리의 의미 지식이 이전의 결과를 크게 개선시켰다는 것을 보여준다.', 'fa': 'کرنه\u200cهای درخت (TKs) و شبکه\u200cهای عصبی دو دستور موثر برای مهندسی ویژه\u200cهای خودکار هستند. در این کاغذ، آنها را با نمونه\u200cسازی کلمه\u200cهای متصل در TKs semantic ترکیب می\u200cکنیم. از این طریق، آخرین می\u200cتواند با استفاده از شبیه\u200cهای عصبی بر روی گره\u200cهای لکسیکی درخت\u200cها تفاوت\u200cکننده\u200cهای زیر پایه\u200cای انجام دهد. ما مطالعه می کنیم که چگونه نمایش\u200cهایی برای کلمات در محیط یاد بگیریم که TKs می\u200cتواند اطلاعات تمرکز بیشتری را استفاده کند. ما فهمیدیم که داخل عصبی که توسط روش\u200cهای فعلی تولید می\u200cشود شبیه\u200cهای موضوع مناسب نیست. بنابراین، ما روش جدید را بر اساس شبکه سیامی تعریف می\u200cکنیم که در زمان یادگیری شبیه\u200cای از متن دویینی کلمه\u200cها را تولید می\u200cکند. ما آخرین را با توجه به مثالها در یک گروه مشابه قرار دادیم. آزمايشات در مورد سوال و تشخيص احساسات نشون ميده که نتيجه هاي قبليمون رو بهتر ميکنه', 'id': 'Kernel pohon (TK) dan jaringan saraf adalah dua pendekatan efektif untuk teknik karakteristik otomatis. Dalam kertas ini, kita menggabungkan mereka dengan memmodelir kata konteks persamaan dalam TK semantis. Dengan cara ini, yang terakhir dapat beroperasi persamaan subtree dengan menggunakan kesamaan berasaskan saraf pada node leksikal pohon. Kami mempelajari bagaimana untuk belajar representation untuk kata-kata dalam konteks sehingga TK dapat mengeksploitasi informasi yang lebih fokus. Kami menemukan bahwa penyambungan saraf yang diproduksi oleh metode saat ini tidak menyediakan persamaan kontekstual yang tepat. Jadi, kita mendefinisikan pendekatan baru berdasarkan Jaringan Siamese, yang memproduksi representation kata sementara mempelajari kesamaan teks binari. Kami mempertimbangkan contoh-contoh di kategori yang sama dengan yang sama. Eksperimen tentang pertanyaan dan klasifikasi sentimen menunjukkan bahwa TK semantis kita meningkatkan hasil sebelumnya.', 'tr': 'Gujer kerneleri (TKs) we näyral şebekeleri awtomatik özellikler enjiniýasy üçin iki etkinlik yaklaşykdyr. Bu kagyzda olary semantik TKlarda daýarlyk sözlerini modelleýän bilen birleşýäris Bu şekilde, soňky näyral tabanly lukmanyň tekizliklerine uygulamak üçin asty reňkleri işleyebilir. Biz sözleriň nädip üns berişi öwrenip bilmegimizi öwrenýäris. Şonuň ýaly TK-yň köp üns berişi bilýän maglumatlary ulanyp bilýäris. Häzirki täzelikler tarapyndan üretilen neural ködlemeler üçin uygun bir contextual meňzeşliki saýlamaýarlar. Bu şekilde, Siamese Ağına dayanan yeni bir yaklaşmayı tanımlarız. Bu, ikili metin benzerini öğrenrken kelime ifadelerini sağlar. Biz soňky örnekleri bir kategoriýada meňzeş ýaly düşünýän ýaly düzenledik. Sorag we duýgular klasifikasynda synaglaryň biziň semantik TK-miziň öňki netijelerimizi has gowy gelip getirilýär.', 'sw': 'Kerneli za mti (TKs) na mitandao ya kisasa ni mbili yenye ufanisi kwa ajili ya uhandikishaji binafsi. Katika gazeti hili, tunaunganisha kwa kutengeneza maneno ya muktadha kama yanavyofanana na TKs. Kwa njia hii, mwingine wanaweza kufanya kazi ya mti wa chini unaohusiana na kutumia ulimwengu wa uraia katika viwanja vya mti wa lexico. Tunajifunza jinsi ya kujifunza uwakilishi kwa maneno katika muktadha wa aina hiyo kwamba TKs wanaweza kutumia taarifa zilizo makini zaidi. Tumegundua kuwa vifaa vya neura vilivyotengenezwa na mbinu za sasa havina usawa wa kimataifa sahihi. Kwa hiyo, tunaelezea mbinu mpya inayohusiana na Mtandao wa Siamese, ambao unaleta uwakilishi wa maneno wakati wa kujifunza ujumbe wa twita unaofanana. Na tukawaweka mfano wa walio kuja baadaye kwa namna hiyo. Majaribio yanayohusu suala hilo na kutangazwa kwa hisia zinaonyesha kuwa TK yetu ya sekunde inabadilisha matokeo yaliyopita.', 'af': "Boom kernels (TK) en neuralnetwerke is twee effektief toegang vir outomatiese funksie inženiering. In hierdie papier, ons kombinieer hulle deur die modellering van kontekswoord gelykbaarheid in semantiese TK. Hierdie manier kan die laaste onderstreek ooreenstemmende operasieer deur die toepassing van neurale gebaseerde gelykenis op boom leksiese nodes. Ons leer hoe om voorstellings te leer vir die woorde in konteks sodat TK meer fokuseerde inligting kan gebruik. Ons het gevind dat neurale inbêdings wat deur huidige metodes geproduseer word nie 'n geskikte contextual gelykenis verskaf nie. Daarom definieer ons 'n nuwe toegang gebaseer op 'n Siamese Netwerk, wat word voorstellings produseer terwyl 'n binêre teks gelykenis leer. Ons stel die laaste voorbeelde in dieselfde kategorie as gelykbaar onderwerp. Die eksperimente op vraag en sentiment klasifikasie wys dat ons semantiese TK baie verbeter vorige resultate.", 'sq': 'Tree kernels (TKs) and neural networks are two effective approaches for automatic feature engineering.  Në këtë letër, ne i kombinojmë ato duke modeluar fjalën e kontekstit ngjashmëri në TK semantike. Kështu, kjo e fundit mund të funksionojë përputhje subtre duke aplikuar ngjashmëri me bazë neurone në nyjet lexike të pemës. Ne studiojmë si të mësojmë përfaqësime për fjalët në kontekst të tillë që TK mund të shfrytëzojnë informacion më të fokusuar. Gjetëm se përfshirjet nervore të prodhuara nga metodat aktuale nuk ofrojnë një ngjashmëri kontekstuale të përshtatshme. Kështu, ne përcaktojmë një qasje të re bazuar në një rrjet Siamese, i cili prodhon përfaqësime fjalësh ndërsa mëson një ngjashmëri teksti binar. Ne i vendosim të fundit duke konsideruar shembuj në të njëjtën kategori si të ngjashme. Eksperimentet në çështje dhe klasifikimin e ndjenjave tregojnë se TK-ja jonë semantike përmirëson shumë rezultatet e mëparshme.', 'az': 'Ağaç çubuqları (TKs) və nöral ağları otomatik özelliklərin inženjeri üçün iki faydalı yoldur. Bu kağızda onları semantik TKlərdə məlumatların məlumatlarını modelləşdirməklə birləşdiririk. Bu yolla, sonuncusu, ağac leksik düyünün üstündə nöral tabanlığını uygulamaq vasitəsilə istifadə edə bilər. TKlər daha çox fokuslı məlumatları istifadə edə biləcək sözlərin necə öyrənməsini öyrənirik. Şimdiki metodlar vasitəsilə ürəklənən nöral inşalları uyğun müxtəlif bir bənzər olmadığını gördük. Beləliklə, biz Siamlı Şebeyə dayanan yeni bir tərzi belə tanımlıyıq ki, iki mətn bənzərisini öyrənərkən sözləri göstərir. Biz sonuncu misalları eyni kategoriyada belə çəkdik. Suğul və sentiment klasifikasiyasındakı eksperimentlər semantik TK-mizin əvvəlki sonuçlarını çox yaxşılaşdırır.', 'hy': "Փայրի միջուկները և նյարդային ցանցերը ավտոմատիկ հատկանիշների ճարտարագիտության երկու արդյունավետ մոտեցում են: Այս թղթի մեջ մենք դրանք համադրում ենք մոդելավորելով սեմանտիկ տեխնոլոգիաներում կոնտեքստի բառի նմանությունը: Այսպես, վերջինը կարող է աշխատել աննշան համապատասխանման միջոցով, օգտագործելով նյարդային հիմնված նմանությունը ծառի լեքսիկական հանգույցների վրա: Մենք ուսումնասիրում ենք, թե ինչպես սովորել բառերի ներկայացումներ այնպիսի կոնտեքստում, որ տեխնոլոգիաները կարող են օգտագործել ավելի կենտրոնացված ինֆորմացիա: Մենք հայտնաբերեցինք, որ ներկայիս մեթոդների միջոցով արտադրված նյարդային ներգրավումները համապատասխան կոնտեքստային նմանություն չեն տալիս: Այսպիսով, մենք սահմանում ենք մի նոր մոտեցում, որը հիմնված է Սիամական ցանցի վրա, որը ստեղծում է բառերի ներկայացումներ' երկարագույն տեքստի նմանությունը սովորելով: Մենք վերջիններին հաշվի առնելով օրինակներ նույն կատեգորիայի մեջ, ինչպիսիք են նման: The experiments on question and sentiment classification show that our semantic TK highly improves previous results.", 'bn': 'ট্রি কার্নেল এবং নিউরেল নেটওয়ার্ক স্বয়ংক্রিয় বৈশিষ্ট্যাবলী ইঞ্জিনিয়ারের জন্য দুটি কার্যকর উপায়। এই কাগজটিতে আমরা তাদের মোডেলিং কন্টেক্সটেক্ট শব্দের সমতুল্যের মাধ্যমে একত্রিত করি। এইভাবে নিউরেল ভিত্তিক সাবট্রীর মিলে কাজ করতে পারে গাছের লেক্সিক্যাল নোডের মাধ্যমে। আমরা শিক্ষা করছি কিভাবে এই শব্দের প্রতিনিধিত্ব শিখতে পারি যেমন টিকিকে আরো মনোযোগ দিতে পারে। আমরা পেয়েছি যে বর্তমান পদ্ধতি দ্বারা তৈরি নিউরেল বিভিন্ন বিভিন্ন প্রতিযোগিতার সমতা প্রদান করে না। তাই আমরা একটি সিয়ামের নেটওয়ার্কের উপর ভিত্তিক একটি নতুন পদ্ধতি নির্ধারণ করি, যা বাইনারি টেক্সটের একই ধরনের শিক্ষা শিখার সময় শব আমরা পরবর্তীদের একই ধরনের উদাহরণ বিবেচনা করেছি। প্রশ্ন এবং অনুভূতি বিভাগের পরীক্ষাগুলো দেখাচ্ছে যে আমাদের পূর্ববর্তী ফলাফল অত্যন্ত উন্নতি দেয়া হয়েছে।', 'ca': "Els núcles d'arbre (TK) i les xarxes neurals són dos enfocaments efectius per a l'enginyeria automàtica de característiques. En aquest article, els combinam modelant la paraula contextual de similitud en TK semàntiques. D'aquesta manera, aquesta última pot operar l'ajustament subtri aplicant la similitud neuronal als nodos lèxics d'arbre. Estudem com aprendre representacions per a les paraules en un context de tal manera que les tecnològiques puguin explotar informació més centrada. Vam descobrir que les integracions neuronals produïdes pels mètodes actuals no proporcionen una similitud contextual adequada. Així, definim un nou enfocament basat en una xarxa siamese, que produeix representacions de paraules mentre aprenem una similitud de text binari. En vam posar aquests exemples considerant exemples de la mateixa categoria que semblants. Els experiments en qüestió i la classificació del sentiment mostren que la nostra tècnica semàntica millora molt els resultats anteriors.", 'am': 'የዛፍ አቀማመጥ (TKs) እና የደዌብ መረብ ለራሱ የተግባር የፊደል ኢንጂንጂንግር ሁለት ጥያቄዎች ናቸው፡፡ በዚህ ፕሮግራም፣ እናሳብቃቸዋለን በጽሑፍ ቃላት በsemantic TKs ውስጥ This way, the latter can operate subtree matching by applying neural-based similarity on tree lexical nodes.  እናስተማርካለን፣ የቴክስ ተሟጋቾች መረጃዎችን ለመጠቀም የሚችሉትን ቃላትን እንዴት ለመማር እናስተምራለን፡፡ የአሁኑ ሥርዓት የሚደረገውን የነጥብ አካባቢዎች በቁጥጥር የሚመስል እንደሌላቸው አግኝተናል፡፡ እንዲሁም በሁለት ጽሑፎች በተስተማሩ ጊዜ ቃልን የሚያሳልፍ አዲስ ሥርዓት መፍጠርን እናሳውቃለን፡፡ የኋለኞቹንም ምሳሌዎች ብጤያቸው አደረግናቸው ፡ ፡ የጥያቄ እና የስሜት መግለጫ ፈተናዎች የጤናዊው TK ፍሬዎቻችን የቀድሞውን ውጤቶች እጅግ ያበጅላቸዋል፡፡', 'bs': 'Drvo kernela (TKs) i nervne mreže su dva efikasna pristupa za automatski inženjering funkcija. U ovom papiru, kombiniramo ih modeliranjem kontekstskih riječi sličnosti u semantičkim TK-ima. Na ovaj način, posljednja može funkcionisati supstražno odgovaranje primjenjivanjem neuralne sličnosti na leksičkim čvorovima drveta. Proučavamo kako naučiti predstave za riječi u kontekstu tako da TKs može iskoristiti fokusiranije informacije. Pronašli smo da neuralne integracije proizvode trenutnim metodama ne pružaju odgovarajuću kontekstualnu sličnost. Tako definišemo novi pristup na temelju Siamejske mreže, koji proizvodi riječi predstavljanja dok učimo sličnost binarnog teksta. Posljednji smo postavili s obzirom na primjere u istoj kategoriji kao slične. Eksperimenti o pitanju i klasifikaciji sentimenta pokazuju da naš semantički TK veoma poboljšava prethodne rezultate.', 'cs': 'Stromová jádra (TK) a neuronové sítě jsou dva efektivní přístupy pro automatické inženýrství funkcí. V tomto článku je kombinujeme modelováním kontextové podobnosti slov v sémantických TK. Tento druhý způsob může operovat porovnávání podčísel aplikací neuronové podobnosti na lexikálních uzlech stromů. Studujeme, jak se naučit reprezentace slov v kontextu tak, aby TK mohli využívat více zaměřených informací. Zjistili jsme, že neuronové vložení produkované současnými metodami neposkytují vhodnou kontextovou podobnost. Proto definujeme nový přístup založený na siamské síti, která produkuje slovní reprezentace při učení binární podobnosti textu. Ty druhé jsme nastavili s ohledem na příklady ve stejné kategorii jako podobné. Experimenty na klasifikaci otázek a sentimentů ukazují, že náš sémantický TK výrazně zlepšuje předchozí výsledky.', 'et': 'Puutuumad (TKs) ja närvivõrgud on kaks tõhusat lähenemisviisi automaatse funktsioonide projekteerimiseks. Käesolevas töös kombineerime neid, modelleerides kontekstisõnade sarnasust semantilistes TK-des. Nii saab viimane töötada lahtrite sobitamisega, rakendades neuraalpõhist sarnasust puude leksikaalsetele sõlmedele. Me uurime, kuidas õppida sõnade esitusi kontekstis nii, et TK saaks kasutada rohkem keskendunud teavet. Leidsime, et praeguste meetoditega toodetud neuraalsed manustamised ei paku sobivat kontekstilist sarnasust. Seega määratleme uue lähenemisviisi, mis põhineb siaami võrgustikul, mis toodab sõnarepresentatsioone, õppides samal ajal binaarset teksti sarnasust. Me seadsime viimase, arvestades näiteid samas kategoorias nagu sarnased. Küsimuste ja sentimentaalsete klassifikatsioonide katsed näitavad, et meie semantiline TK parandab oluliselt varasemaid tulemusi.', 'fi': 'Puuytimet (TKs) ja hermoverkot ovat kaksi tehokasta lähestymistapaa automaattiseen ominaisuuksien suunnitteluun. Tässä työssä yhdistämme ne mallintamalla kontekstin sanasamankaltaisuutta semanttisissa TK:issä. Tällä tavoin jälkimmäinen voi toimia subtree matching soveltamalla neuropohjaista samankaltaisuutta puiden leksikaalisissa solmukkeissa. Tutkimme, miten sanoja voidaan esittää kontekstissa siten, että TK voi hyödyntää kohdennettua tietoa. Havaitsimme, että nykyisillä menetelmillä tuotetut neuroupotukset eivät tarjoa sopivaa kontekstuaalista samankaltaisuutta. Määrittelemme uuden lähestymistavan, joka perustuu siamilaiseen verkostoon, joka tuottaa sanaesityksiä oppiessaan binaarisen tekstin samankaltaisuutta. Asetamme jälkimmäisen ottaen huomioon esimerkit samassa luokassa kuin samankaltaiset. Kysymys- ja tunteiden luokittelukokeet osoittavat, että semanttinen TK parantaa huomattavasti aiempia tuloksia.', 'he': 'גרעיני עץ (TKs) ורשתות עצביות הן שתי גישות יעילות להנדסה אוטומטית של תכונות. בעיתון הזה, אנחנו משלבים אותם על ידי הדוגמה של מילה קונטקסט דומות בטקס סמנטי. בדרך זו, האחרונה יכולה לפעול התאמה מתחת לשטח על ידי השימוש של דמיון מבוסס על עצים קסמיים. אנו לומדים איך ללמוד מייצגים למילים בקשר כזה שטקי-קיי יכולים לנצל מידע ממוקד יותר. מצאנו שמערכות עצביות שנוצרות בשיטות הנוכחיות לא מספקות דמיון קונטקטואלי מתאים. כך, אנחנו מגדירים גישה חדשה מבוססת על רשת סיאמית, אשר מייצרת מילים מייצרות בזמן ללמוד דמיון טקסט בינרי. קבענו את האחרונים בהתחשב בדוגמאות באותה קטגוריה כמו דומות. הניסויים על שאלות וסימונים מראים שהטכנולוגיה הסמנטית שלנו משפר את התוצאות הקודמות.', 'sk': 'Drevesna jedra (TK) in nevronska omrežja sta dva učinkovita pristopa za avtomatsko inženiring funkcij. V tem prispevku jih združujemo z modeliranjem podobnosti kontekstnih besed v semantičnih TK. Na ta način lahko slednji deluje ujemanje podatkov z uporabo podobnosti na živčni osnovi na drevesnih leksikalnih vozliščih. Preučujemo, kako se naučiti reprezentacij besed v kontekstu, tako da lahko TK izkoristijo bolj osredotočene informacije. Ugotovili smo, da nevronske vdelave, izdelane s trenutnimi metodami, ne zagotavljajo ustrezne kontekstualne podobnosti. Tako opredelimo nov pristop, ki temelji na siamski mreži, ki ustvarja besedne reprezentacije ob učenju podobnosti binarnega besedila. Slednje smo postavili glede na primere v isti kategoriji kot podobne. Poskusi o klasifikaciji vprašanj in sentimenta kažejo, da naša semantična TK močno izboljšuje prejšnje rezultate.', 'jv': 'Jaringan Kernels (T Ks) lan Neral netek didasai iki layang apik kanggo ngono otomatik kanggo jenis maneh. Nan pempet iki, kita digowisih karo model karo sampeyan kelas nang semanti-T Ks . Node Awak dhéwé ngerti ngerti repréntasi kanggo kelas kuwi nglarani ning kontèks seneng pisan, tèk iso nggawe informasi tambah bantuan. text-editor-action Simulate Awak dhéwé éntuk sistem sing paling-tolerané, nungsak kelompok ngono koyok Genjer-ingkang angkang karo kesempatan lan kelangan kelangan kelangan kuwi sematik dhéwé nggawe barang langgar tarjamahan kanggo mbalke disempatan kanggo ngerasai winih dhéwé.', 'bo': 'Tree kernels (TKs) and neural networks are two effective approaches for automatic feature engineering. ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ཚོར་མཐུན་སྣང་ཚོགས་ཀྱི་ཚིག་དང་འདྲ་བར་མཉམ་དུ་བསྡད་བྱེད་ཀྱི་ཡོད། འདི་ལྟ་བུའི་རྗེས་མའི་རྣམ་པ་དེ་དབྱིབས་ཡུལ་དང་མཐུན་སྒྲིག་ཡོད་པའི་subtree་སྒྲུབ་བྱེད་ཐུབ་པ། ང་ཚོས་གནས་ཚུལ་ནང་གི་ཡི་གེ་ཅིག་ལ་གསལ་བཤད་པ་དང་མི་ཤེས་པས་TKs ཡིས་གནས་ཚུལ་མང་ཙམ་སྟོན་ཐུབ་པ་དང་། ང་ཚོས་ད་ལྟོའི་ལམ་ལུགས་ཀྱིས་མཐུན་སྐྱེས་པའི་རྣམ་པ་ནང་དུ་འདྲ་རྒྱ་སྟངས་དང་མཐུན་སྒྲིག་ཡོད་པ་མ་རེད། དེར་བརྟེན། ང་ཚོས་སྔོན་སྒྲིག་འབྱོར་གསར་བ་ཞིག་ངེས་པར་འཛིན་བྱེད་ཀྱི་ཡོད་འབྲེལ་མཐུན་དང་། ང་ཚོས་ཤེས་མའི་དཔེར་བརྗོད་འདི་དག་གི་དབྱེ་བ་གཅིག་མཚུངས་ཡིན་པ་ལ་བསམ་བློ་བཏང་བ་ཡིན། དྲི་ཚིག་དང་སེམས་ཚོར་གྱི་བརྟག་བཤད་ཀྱི་གྲུབ་རྩལ་བ་དག་གིས་ང་ཚོའི་semantic TK་གི་གྲུབ་འབྲས་མཐོ་དཔག་ཏུ་འགྱུ', 'ha': "Tree kernel (TKs) da zanen tarakin neura, sun kasance biyu masu amfani da shiryoyin ayuka masu amfani da masu inganci na farat ɗaya. Ina cikin wannan takardan, Munã haɗa su da magana mai motsi da ke daidaita cikin TKs. Kamar wannan, ƙarshen na iya yi amfani da sub-itãce mai daidai da ta yi amfani da kwamfyutan neural a kan node na leksi. We study how to learn representations for the words in context such that TKs can exploit more focused information.  Mun gane cewa da ke samar da hanyõyin yanzu ba su bãyar da wani daidai da ke daidai. Kamar haka, Munã bayyana wani hanyoyi na daban a kan Shiamese, ta sami magana masu tsari a lokacin da za'a sanar da littãfin da ke daidaita. Kuma Muka sanya misãlai ga mutãnen ƙarshe. The experiments on question and sentiment classification show that our semantic TK highly improves previous results."}
{'en': 'Neural Domain Adaptation for Biomedical Question Answering', 'es': 'Adaptación del dominio neuronal para respuestas a preguntas biomédicas', 'fr': 'Adaptation du domaine neuronal pour répondre aux questions biomédicales', 'ar': 'تكييف المجال العصبي للإجابة على الأسئلة الطبية الحيوية', 'pt': 'Adaptação de Domínio Neural para Resposta a Perguntas Biomédicas', 'ja': '生物医学的質問の回答のためのニューラルドメインアダプテーション', 'ru': 'Адаптация нейронной области для ответа на биомедицинский вопрос', 'zh': '生物医学问答神经域应', 'hi': 'बायोमेडिकल प्रश्न उत्तर देने के लिए तंत्रिका डोमेन अनुकूलन', 'ga': 'Oiriúnú Fearainn Néaraigh le haghaidh Freagra ar Cheisteanna Bithleighis', 'hu': 'Neural Domain adaptáció bioorvosi kérdések megválaszolására', 'ka': 'ნეიროლური დომენის აეპტიფიკაცია ბიომედიციური კითხვების გარეშე', 'el': 'Προσαρμογή Νευρικού Τομέα για την απάντηση βιοιατρικών ερωτήσεων', 'it': 'Adattamento del dominio neurale per la risposta alle domande biomedicali', 'kk': 'Биомедицина сұрақ жауап беру үшін нейрондық домен адаптациясы', 'lt': 'Neuralinio domeno pritaikymas atsakymui į biologinę mediciną', 'mk': 'Адаптација на нервниот домен за одговор на биомедицински прашања', 'ms': 'Penyesuaian Domain Neural untuk Jawapan soalan Biomedis', 'ml': 'ബിയോമിഡിക്കല്\u200d ചോദ്യം ഉത്തരം നല്\u200dകുന്നതിനുള്ള നെയുറല്\u200d ഡൊമെയിന്\u200d ആഡാപ്റ്റേഷന്\u200d', 'mt': 'Adattament tad-Domain Newrali għat-tweġiba għall-mistoqsijiet bijomediċi', 'no': 'Neuraldomeneadaptasjon for biomedisk svar', 'mn': 'Биоэмнэлгийн асуулт хариултын тулд мэдрэлийн домаар дамжуулалт', 'ro': 'Adaptarea domeniului neural pentru răspunsul la întrebări biomedicale', 'pl': 'Adaptacja domeny neuronowej dla odpowiedzi na pytania biomedyczne', 'si': 'ජීවිත වෛද්\u200dය ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරතිච්චාරයක් වෙනුවෙන් න්\u200dයූරාල් ඩොමේන් අනු', 'so': 'Neural Domain Adaptation for Biomedical Question Answering', 'sr': 'Neuralna domena adaptacija za odgovor na biomedicinsko pitanje', 'sv': 'Neural Domain Anpassning för biomedicinsk frågeställning', 'ta': 'பையோமிடிக்கல் கேள்வி', 'ur': 'Biomedical سوال جواب کے لئے نیورال ڈومین اڈپٹیٹ', 'uz': 'Name', 'vi': 'Sửa thuộc thần kinh cho câu hỏi sinh học', 'da': 'Tilpasning af neural domæne til besvarelse af biomedicinske spørgsmål', 'bg': 'Адаптация на невралния домейн за отговор на биомедицински въпроси', 'hr': 'Adaptacija neurodomena za odgovor na biomedicinsko pitanje', 'nl': 'Neurale Domeinaanpassing voor het beantwoorden van biomedische vragen', 'de': 'Neurale Domänenanpassung für biomedizinische Fragestellungen', 'ko': '생물의학 문답 중의 신경역 자체 적응', 'id': 'Adaptasi Domain Neural untuk Jawaban Pertanyaan Biomedis', 'fa': 'Adaptation of Neural Domain for Biomedical Question Answering', 'sw': 'Toleo la Neural Domain kwa ajili ya swali la Biomedical', 'af': 'Neurale domein aanpassing vir biomediese vraag antwoord', 'tr': 'Biomedical soragy jogap üçin näsaz ýerleşdirim', 'sq': 'Adaptimi i Domenit Neural për Përgjigjen e Pyetjeve Biomjekësore', 'az': 'Biomedical sual cavab vermək üçün nöral Domain Adaptation', 'hy': 'Բիոբիոբժշկական հարցերի պատասխանների համար', 'bn': 'বিয়োমিকাল প্রশ্নের উত্তরের জন্য নিউরেল ডোমেইন অ্যাডাপ্টেশন', 'am': 'የውይይት ዶሜን አቀማመጥ', 'bs': 'Adaptacija neurodomena za odgovor na biomedicinsko pitanje', 'cs': 'Adaptace neuronové domény pro zodpovězení biomedicínských otázek', 'ca': 'Adaptació neuronal al domini per respondre a preguntes biomèdiques', 'et': 'Neuraalse domeeni kohandamine biomeditsiinilistele küsimustele vastamiseks', 'fi': 'Neural Domain Adaptation for Biomedical Question Answering', 'jv': 'structural navigation', 'he': 'Neural Domain Adaptation for Biomedical Question Answering', 'ha': 'Adafatas na Domen na Neural wa Jafi na Biomedical', 'sk': 'Prilagajanje nevralne domene za odgovore na biomedicinska vprašanja', 'bo': 'སྒེར་གྱི་གནས་སྟངས་ལ་མཐུད་སྒྲིག་མཐུན་སྒྲིག་གི་བྱ་ཚིག་དང་མཐུན་སྒྲིག'}
{'en': 'Factoid question answering (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch. For example, the BioASQ dataset for biomedical QA comprises less then 900 factoid (single answer) and list (multiple answers) QA instances. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. Our network architecture is based on a state-of-the-art QA system, extended with biomedical word embeddings and a novel mechanism to answer list questions. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.', 'es': 'La respuesta factoide a preguntas (QA) se ha beneficiado recientemente del desarrollo de sistemas de aprendizaje profundo (DL). Los modelos de redes neuronales superan a los enfoques tradicionales en dominios donde existen grandes conjuntos de datos, como sQuad (alrededor de 100.000 preguntas) para los artículos de Wikipedia. Sin embargo, estos sistemas aún no se han aplicado al control de calidad en dominios más específicos, como la biomedicina, porque los conjuntos de datos son generalmente demasiado pequeños para entrenar un sistema de DL desde cero. Por ejemplo, el conjunto de datos BioAsq para el control de calidad biomédico comprende menos de 900 instancias de control de calidad factoide (respuesta única) y lista (respuestas múltiples). En este trabajo, adaptamos un sistema de control de calidad neuronal entrenado en un gran conjunto de datos de dominio abierto (sQuad, fuente) a un conjunto de datos biomédicos (BioAsq, objetivo) mediante el empleo de varias técnicas de aprendizaje por transferencia. Nuestra arquitectura de red se basa en un sistema de control de calidad de vanguardia, ampliado con incrustaciones de palabras biomédicas y un mecanismo novedoso para responder a las preguntas de la lista. A diferencia de los sistemas biomédicos de control de calidad existentes, nuestro sistema no se basa en ontologías, analizadores o etiquetadores de entidades específicos del dominio, que son costosos de crear. A pesar de este hecho, nuestros sistemas logran resultados de vanguardia en las preguntas de los hechos y resultados competitivos en las preguntas de la lista.', 'ar': 'استفادت ميزة Factoid الإجابة على الأسئلة (QA) مؤخرًا من تطوير أنظمة التعلم العميق (DL). تتفوق نماذج الشبكة العصبية على الأساليب التقليدية في المجالات التي توجد بها مجموعات بيانات كبيرة ، مثل SQuAD (حوالي 100000 سؤال) لمقالات ويكيبيديا. ومع ذلك ، لم يتم تطبيق هذه الأنظمة حتى الآن على ضمان الجودة في مجالات أكثر تحديدًا ، مثل الطب الحيوي ، لأن مجموعات البيانات بشكل عام صغيرة جدًا لتدريب نظام DL من نقطة الصفر. على سبيل المثال ، تشتمل مجموعة بيانات BioASQ الخاصة بضمان الجودة الطبي الحيوي على أقل من 900 (إجابة واحدة) وقائمة (إجابات متعددة). في هذا العمل ، نقوم بتكييف نظام ضمان الجودة العصبي المُدرَّب على مجموعة كبيرة من البيانات ذات المجال المفتوح (SQuAD ، المصدر) لمجموعة بيانات طبية حيوية (BioASQ ، الهدف) من خلال استخدام تقنيات نقل التعلم المختلفة. تعتمد بنية شبكتنا على نظام ضمان الجودة المتطور ، والممتد مع تضمين الكلمات الطبية الحيوية وآلية جديدة للإجابة على أسئلة القائمة. على عكس أنظمة ضمان الجودة الطبية الحيوية الحالية ، لا يعتمد نظامنا على الأنطولوجيا الخاصة بالمجال أو المحللات أو أدوات تحديد الكيانات ، والتي تكون مكلفة في إنشائها. على الرغم من هذه الحقيقة ، تحقق أنظمتنا أحدث النتائج في الأسئلة الواقعية والنتائج التنافسية في قائمة الأسئلة.', 'pt': 'A resposta a perguntas factóides (QA) recentemente se beneficiou do desenvolvimento de sistemas de aprendizado profundo (DL). Os modelos de rede neural superam as abordagens tradicionais em domínios onde existem grandes conjuntos de dados, como SQuAD (cerca de 100.000 perguntas) para artigos da Wikipedia. No entanto, esses sistemas ainda não foram aplicados ao QA em domínios mais específicos, como biomedicina, porque os conjuntos de dados são geralmente muito pequenos para treinar um sistema DL do zero. Por exemplo, o conjunto de dados BioASQ para QA biomédico compreende menos de 900 instâncias de QA factóides (resposta única) e lista (respostas múltiplas). Neste trabalho, adaptamos um sistema de QA neural treinado em um grande conjunto de dados de domínio aberto (SQuAD, source) para um conjunto de dados biomédicos (BioASQ, target) empregando várias técnicas de aprendizado de transferência. Nossa arquitetura de rede é baseada em um sistema de controle de qualidade de última geração, ampliado com incorporações de palavras biomédicas e um novo mecanismo para responder a perguntas de listas. Em contraste com os sistemas de controle de qualidade biomédicos existentes, nosso sistema não depende de ontologias específicas de domínio, analisadores ou tags de entidade, que são caros para criar. Apesar disso, nossos sistemas alcançam resultados de última geração em questões factóides e resultados competitivos em questões de lista.', 'fr': "La réponse aux questions (QA) factoid a récemment bénéficié du développement de systèmes d'apprentissage profond (DL). Les modèles de réseaux neuronaux surpassent les approches traditionnelles dans les domaines où il existe de grands ensembles de données, tels que SQuAD (environ 100 000 questions) pour les articles Wikipédia. Cependant, ces systèmes n'ont pas encore été appliqués à l'assurance qualité dans des domaines plus spécifiques, tels que la biomédecine, car les ensembles de données sont généralement trop petits pour former un système DL à partir de zéro. Par exemple, l'ensemble de données BioASQ pour l'assurance qualité biomédicale comprend moins de 900 instances d'AQ factoïdes (réponse unique) et liste (réponses multiples). Dans ce travail, nous adaptons un système d'assurance qualité neuronale formé sur un vaste ensemble de données de domaine ouvert (SQuad, source) à un ensemble de données biomédicales (BioASQ, cible) en utilisant diverses techniques d'apprentissage par transfert. Notre architecture réseau est basée sur un système d'assurance qualité de pointe, complété par des intégrations de mots biomédicaux et un nouveau mécanisme pour répondre aux questions des listes. Contrairement aux systèmes d'assurance qualité biomédicaux existants, notre système ne repose pas sur des ontologies, des analyseurs ou des marqueurs d'entités spécifiques au domaine, dont la création est coûteuse. Malgré cela, nos systèmes obtiennent des résultats de pointe sur les questions factuelles et des résultats compétitifs sur les questions de liste.", 'ja': 'ファクトイド・クエスチョン・アンサー（ QA ）は、ディープ・ラーニング（ DL ）システムの開発によって最近恩恵を受けています。 ニューラルネットワークモデルは、Wikipedia記事のSQuAD （約100,000の質問）など、大規模なデータセットが存在するドメインで従来のアプローチを上回ります。 しかしながら、これらのシステムは、一般的にデータセットが小さすぎてDLシステムを一から訓練することができないため、バイオメディシンなどのより特定のドメインのQAにはまだ適用されていません。 例えば、生物医学的Ｑ ＡのためのＢｉｏＡＳＱデータセットは、９ ０ ０未満のファクトイド（単一回答）及びリスト（複数回答） Ｑ Ａインスタンスを含む。 本研究では、大規模なオープンドメインデータセット（ SQuAD、ソース）で訓練されたニューラルQAシステムを、様々な転送学習技術を用いてバイオメディカルデータセット（ BioASQ、ターゲット）に適応させます。 当社のネットワークアーキテクチャは、最先端のQAシステムに基づいており、バイオメディカルワード埋め込みとリストの質問に答えるための新規メカニズムが拡張されています。 既存のバイオメディカルQAシステムとは対照的に、当社のシステムは、作成に高価なドメイン固有のオントロジー、パーサー、またはエンティティタガーに依存していません。 この事実にもかかわらず、当社のシステムは、事実に基づく質問で最先端の結果を達成し、リストの質問で競争的な結果を達成します。', 'hi': 'Factoid प्रश्न उत्तर (QA) ने हाल ही में गहरी शिक्षा (डीएल) प्रणालियों के विकास से लाभ उठाया है। तंत्रिका नेटवर्क मॉडल डोमेन में पारंपरिक दृष्टिकोणों को मात देते हैं जहां बड़े डेटासेट मौजूद हैं, जैसे कि विकिपीडिया लेखों के लिए SQuAD (ca. 100,000 प्रश्न)। हालांकि, इन प्रणालियों को अभी तक अधिक विशिष्ट डोमेन, जैसे बायोमेडिसिन में क्यूए पर लागू नहीं किया गया है, क्योंकि डेटासेट आमतौर पर खरोंच से डीएल सिस्टम को प्रशिक्षित करने के लिए बहुत छोटे होते हैं। उदाहरण के लिए, बायोमेडिकल क्यूए के लिए BioASQ डेटासेट में 900 फैक्टोइड (एकल उत्तर) और सूची (एकाधिक उत्तर) क्यूए उदाहरण शामिल हैं। इस काम में, हम एक बड़े ओपन-डोमेन डेटासेट (SQuAD, स्रोत) पर प्रशिक्षित एक तंत्रिका क्यूए सिस्टम को विभिन्न स्थानांतरण सीखने की तकनीकों को नियोजित करके एक बायोमेडिकल डेटासेट (BioASQ, लक्ष्य) के लिए अनुकूलित करते हैं। हमारा नेटवर्क आर्किटेक्चर एक अत्याधुनिक क्यूए सिस्टम पर आधारित है, जो बायोमेडिकल शब्द एम्बेडिंग और सूची के सवालों के जवाब देने के लिए एक उपन्यास तंत्र के साथ विस्तारित है। मौजूदा बायोमेडिकल क्यूए सिस्टम के विपरीत, हमारा सिस्टम डोमेन-विशिष्ट ontologies, पार्सर या एंटिटी टैगर्स पर भरोसा नहीं करता है, जो बनाने के लिए महंगे हैं। इस तथ्य के बावजूद, हमारे सिस्टम सूची प्रश्नों पर तथ्यात्मक प्रश्नों और प्रतिस्पर्धी परिणामों पर अत्याधुनिक परिणाम प्राप्त करते हैं।', 'zh': 'Factoid问答(QA)近受益于深学(DL)系统之发。 神经网络在集域优于旧法,如维基百科条目SQuAD(约100,000问)。 然未用于更领之QA,如生物医学,盖数集常小而不可从头始DL系统也。 如用于生物医学 QA 者 BioASQ 数集包少于 900 事(单对)列表(多)QA 例。 于此之事,吾因迁徙学术,将大开域数集(SQuAD,源)训练之神经QA系统应用于生物医学数集(BioASQ,以趋)。 吾网络架构基于先进之QA统,因生物医学词嵌新之机以答列表。 比之生物医学QA统,不依特定域之本,解析器或实体标器,创立本高。 虽然,吾统取先进,表取竞争力。', 'ru': 'Ответы на фактоидные вопросы (QA) в последнее время выиграли от разработки систем глубокого обучения (DL). Нейросетевые модели превосходят традиционные подходы в тех областях, где существуют большие наборы данных, таких как SQuAD (около 100 000 вопросов) для статей Википедии. Однако эти системы еще не применялись к ОК в более конкретных областях, таких как биомедицина, поскольку наборы данных, как правило, слишком малы, чтобы обучать систему DL с нуля. Например, набор данных BioASQ для биомедицинского QA содержит менее 900 фактических (один ответ) и список (несколько ответов) экземпляров QA. В этой работе мы адаптируем нейронную систему QA, обученную на большом наборе данных открытого домена (SQuAD, источник), к набору биомедицинских данных (BioASQ, цель), используя различные методы обучения переносу. Наша сетевая архитектура основана на современной системе обеспечения качества, дополненной биомедицинскими вложениями слов и новым механизмом ответов на вопросы из списка. В отличие от существующих биомедицинских систем обеспечения качества, наша система не полагается на специфические для домена онтологии, парсеры или теггеры сущностей, создание которых обходится дорого. Несмотря на это, наши системы достигают самых современных результатов по фактическим вопросам и конкурентных результатов по списку вопросов.', 'ga': 'Bhain freagra ceiste factoideach (QA) tairbhe le déanaí as forbairt na gcóras domhainfhoghlama (DL). Is fearr le samhlacha líonra néaraigh cur chuige traidisiúnta i bhfearainn ina bhfuil tacair shonraí móra, mar SQuAD (thart ar 100,000 ceist) le haghaidh alt Vicipéid. Mar sin féin, níor cuireadh na córais seo i bhfeidhm go fóill ar QA i réimsí níos sainiúla, mar bhithleighis, toisc go mbíonn tacair shonraí róbheag go hiondúil chun córas DL a oiliúint ón tús. Mar shampla, cuimsíonn tacar sonraí BioASQ do QA bithleighis níos lú ná 900 cás QA factoid (freagra aonair) agus liosta (ilfhreagraí). San obair seo, cuirimid in oiriúint do thacar sonraí bithleighis (BioASQ, sprioc) córas néarach QA atá oilte ar thacar sonraí mór fearainn oscailte (SQuAD, foinse) trí theicnící éagsúla foghlama aistrithe a úsáid. Tá ár n-ailtireacht líonra bunaithe ar chóras QA úrscothach, leathnaithe le leabaithe focal bithleighis agus meicníocht nua chun ceisteanna liosta a fhreagairt. I gcodarsnacht leis na córais QA bithleighis atá ann cheana féin, níl ár gcóras ag brath ar ontologies a bhaineann go sonrach leis an bhfearann, ar pharsálaithe nó ar chlibeálaithe aonáin, atá costasach le cruthú. In ainneoin na fírice seo, baineann ár gcórais torthaí den scoth amach ar cheisteanna factoid agus torthaí iomaíocha ar cheisteanna liostaí.', 'ka': 'ფექტიოდის კითხვის პასუხი (QA) უკვე აღმოჩენა სისტემის განვითარებადან. Name მაგრამ, ეს სისტემები უფრო კონფიგურად QA-ში არ აყენებულია, როგორც ბიომედიცია, რადგან დეტატისტები უფრო მცირე ხალხი, რომ DL სისტემის გასწავლად შემდეგ გას მაგალითად, BioASQ მონაცემები QA-ს შესახებ 900 ფაქტოიდის (ერთი პასუხი) და სია (მრავალ პასუხი) QA მონაცემები. ამ სამუშაოში, ჩვენ ნეიროლური QA სისტემის აეპორტირება, რომელიც დიდი გახსნა დემომინის მონაცემების კონფიგურაციაში (SQuAD, Source) ბიომედიციური მონაცემების კონფიგურაციაში (BioASQ,  ჩვენი ქსელის არქტიქტურაცია QA სისტემაზე ბაზიან, რომელიც ბიომედიციური სიტყვებით გადატანა და პრომენტიური მექანსი სიტყვებით გადასრულება. ჩვენი სისტემა კონტაქტიური ბიომედიციური QA სისტემაზე არ დარწმუნდება დიომინის განსაკუთრებული ონტოლოგიების, პარასერების ან ინტერტიკური ტეგერების განმავლობაზე, რომლებ მაგრამ ამ ფაქტის განმავლობაში, ჩვენი სისტემები გავაკეთებთ წარმოდგენების წარმოდგენების ფაქტოიდის კითხვების და კონკონტებური წარმოდგენების შესახებ.', 'el': 'Πρόσφατα επωφελήθηκε από την ανάπτυξη συστημάτων βαθιάς μάθησης. Τα μοντέλα νευρωνικών δικτύων ξεπερνούν τις παραδοσιακές προσεγγίσεις σε τομείς όπου υπάρχουν μεγάλα σύνολα δεδομένων, όπως το SQuAD (περίπου 100.000 ερωτήσεις) για άρθρα της Βικιπαίδειας. Ωστόσο, αυτά τα συστήματα δεν έχουν ακόμη εφαρμοστεί για τη διασφάλιση της ποιότητας σε πιο συγκεκριμένους τομείς, όπως η βιοϊατρική, επειδή τα σύνολα δεδομένων είναι γενικά πολύ μικρά για να εκπαιδεύσουν ένα σύστημα DL από την αρχή. Για παράδειγμα, το σύνολο δεδομένων για τη βιοϊατρική QA περιλαμβάνει λιγότερο από 900 πραγματικές (ενιαία απάντηση) και λίστες (πολλαπλές απαντήσεις) περιπτώσεων QA. Στην εργασία αυτή, προσαρμόζουμε ένα νευρικό σύστημα QA εκπαιδευμένο σε ένα μεγάλο σύνολο δεδομένων ανοιχτού τομέα (πηγή) σε ένα βιοϊατρικό σύνολο δεδομένων (στόχος) χρησιμοποιώντας διάφορες τεχνικές μάθησης μεταφοράς. Η αρχιτεκτονική του δικτύου μας βασίζεται σε ένα υπερσύγχρονο σύστημα QS, που επεκτείνεται με βιοϊατρικές ενσωματώσεις λέξεων και έναν νέο μηχανισμό για την απάντηση σε ερωτήσεις λίστας. Σε αντίθεση με τα υπάρχοντα βιοϊατρικά συστήματα QA, το σύστημά μας δεν βασίζεται σε οντολογίες ειδικού τομέα, αναλυτές ή ετικέτες οντότητας, οι οποίες είναι ακριβές στη δημιουργία. Παρά το γεγονός αυτό, τα συστήματά μας επιτυγχάνουν αποτελέσματα τελευταίας τεχνολογίας σε πραγματικά ερωτήματα και ανταγωνιστικά αποτελέσματα σε ερωτήματα καταλόγου.', 'hu': 'A tényálló kérdések megválaszolása (QA) a közelmúltban előnyös volt a mélytanulási (DL) rendszerek fejlesztéséből. A neurális hálózati modellek felülmúlják a hagyományos megközelítéseket azokban a tartományokban, ahol nagy adathalmazok léteznek, mint például az SQUAD (kb. 100 000 kérdés) a Wikipédia cikkekhez. Ezeket a rendszereket azonban még nem alkalmazták a minőségbiztosításra konkrétabb területeken, például a biomedicinában, mivel az adatkészletek általában túl kicsik ahhoz, hogy egy DL rendszert a semmiből képezzék. Például az orvosbiológiai minőségválasztásra vonatkozó BioASQ adatkészlet kevesebb mint 900 tényleges (egyszeri válasz) és lista (többszörös válasz) minőségválasztási példányt tartalmaz. Ebben a munkában különböző transzfer tanulási technikák alkalmazásával adaptálunk egy nagyméretű, nyílt tartományú adatkészletre (SQUAD, forrás) képzett neurális minőségbiztosítási rendszert egy orvosbiológiai adatkészlethez (BioASQ, cél). Hálózati architektúránk egy korszerű minőségbiztosítási rendszeren alapul, amelyet orvosbiológiai szóbeágyazásokkal és egy új mechanizmussal bővítettünk ki a lista kérdéseire. A meglévő orvosbiológiai minősítési rendszerekkel ellentétben rendszerünk nem támaszkodik domain-specifikus ontológiákra, elemzőkre vagy entitásjelzőkre, amelyek létrehozása drága. Ennek ellenére rendszereink korszerű eredményeket érnek el tényleges kérdésekben, versenyképes eredményeket pedig listás kérdésekben.', 'it': "La risposta alle domande fattuali (QA) ha recentemente beneficiato dello sviluppo di sistemi di deep learning (DL). I modelli di rete neurale superano gli approcci tradizionali in domini dove esistono grandi set di dati, come SQUAD (circa 100.000 domande) per gli articoli di Wikipedia. Tuttavia, questi sistemi non sono ancora stati applicati al QA in domini più specifici, come la biomedicina, perché i set di dati sono generalmente troppo piccoli per addestrare un sistema DL da zero. Ad esempio, il set di dati BioASQ per la QA biomedica comprende meno di 900 istanze di QA factoid (risposta singola) e elenco (risposte multiple). In questo lavoro, adattiamo un sistema di QA neurale addestrato su un grande dataset open-domain (SQUAD, fonte) a un dataset biomedico (BioASQ, target) utilizzando varie tecniche di transfer learning. La nostra architettura di rete si basa su un sistema di QA all'avanguardia, esteso con incorporazioni biomediche di parole e un nuovo meccanismo per rispondere alle domande degli elenchi. A differenza dei sistemi di QA biomedici esistenti, il nostro sistema non si basa su ontologie specifiche del dominio, parser o tag di entità, che sono costosi da creare. Nonostante questo, i nostri sistemi raggiungono risultati all'avanguardia sulle domande di fatto e risultati competitivi sulle domande di elenco.", 'mk': 'Одговорите на фактоидните прашања (QA) неодамна имаа корист од развојот на системите за длабоко учење (DL). Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles.  Сепак, овие системи сé уште не се применети на QA во посебни домени, како што е биомедицината, бидејќи податоците генерално се премногу мали за да се обучува DL систем од почеток. На пример, наборот на податоци BioASQ за биомедицински QA сочинува помалку од 900 фактоиди (еден одговор) и листа (повеќе одговори) инстанции QA. Во оваа работа, прилагодуваме нервен QA систем трениран на голем набор на отворени податоци (SQuAD, извор) на биомедицински податоци (BioASQ, мета) со употреба на различни техники на трансферентно учење. Нашата мрежна архитектура е базирана на најсовремениот систем на QA, проширен со биомедицински зборови и нов механизам за одговори на прашањата на листата. За разлика од постојните биомедициски системи на QA, нашиот систем не се потпира на онтологии, анализатори или означувачи на ентитети, кои се скапи за создавање. И покрај овој факт, нашите системи постигнуваат најсовремени резултати на фактоидните прашања и конкурентните резултати на листите прашања.', 'lt': 'Atsakymai į faktinius klausimus (QA) neseniai buvo naudingi plėtojant gilaus mokymosi sistemas. Neuralinių tinklų modeliai viršija tradicinius metodus srityse, kuriose yra didelių duomenų rinkinių, pvz., SQuAD (apie 100 000 klausimų) Wikipedia straipsniams. Tačiau šios sistemos dar nebuvo taikomos QA specifinėse srityse, pavyzdžiui, biomedicinoje, nes duomenų rinkiniai paprastai yra per maži, kad iš pradžių būtų mokoma DL sistema. Pavyzdžiui, BioASQ biomedicinės QA duomenų rinkinyje yra mažiau nei 900 faktoidų (vienintelis atsakymas) ir sąrašas (keli atsakymai) QA atvejų. Šiame darbe, naudojant įvairius perdavimo mokymosi metodus, prisidedame prie biomedicinos duomenų rinkinio (BioASQ, tikslo) naudodami didelį atviro domeno duomenų rinkinį (SQuAD, šaltinis). Mūsų tinklo architektūra grindžiama naujausia QA sistema, išplėsta biomediciniais žodžiais ir nauju mechanizmu atsakyti į sąrašo klausimus. Priešingai nei esamos biomedicinės QA sistemos, mūsų sistema nesikliauja konkrečioms sritims skirtomis ontologijomis, analizatoriais ar subjektų žymekliais, kurie yra brangūs sukurti. Nepaisant to, mūsų sistemos pasiekia naujausius faktinių klausimų rezultatus ir konkurencinius klausimų sąraše rezultatus.', 'kk': 'Фактоид сұрақтарын жауап беру (QA) жүйелердің қалыпты оқыту (DL) жүйелерінен жасау мүмкіндігін жасады. Нейрондық желі үлгілері Википедия мақалаларының үлкен деректер жиындарында әдеттегі арқылы көмектеседі. Мысалы SQuAD (100 000 сұрақ) секілді. Бірақ бұл жүйелер әлі көптеген домендерде QA- ге қолданбаған жоқ, мысалы биомедицина, себебі деректер жиындары DL жүйесін жүктеу үшін әдетте кішкентай болып тұрады. Мысалы, BioASQ бағдарламасының биомедикалық QA деректер жиыны 900 фактоид (бір жауап) және QA мәселелері (бірнеше жауап) тізімі болады. Бұл жұмыс ішінде біз көптеген аудару технологияларын қолдану арқылы көп ашық домендық деректер жинағында (SQuAD, көзі) невралдық QA жүйесін биомедикалық деректер жинағына (BioASQ, мақсат) адаптациялады Желі архитектурамыз QA күйіне негізделген, биомедикалық сөздерді ендіру және тізім сұрақтарына жауап беру үшін романдық механизмі. Бар биомедикалық QA жүйелеріне қарсы, біздің жүйеміз доменге арнаулы онтологиялар, талдаушылар немесе нысандар тегжерлеріне сенбейді. Бұл құру үшін бағатты. Бұл шындықтан қарамастан, жүйелеріміз тізімдегі сұрақтардың фактоид сұрақтарына және конкурсивті нәтижелеріне жеткізеді.', 'ms': 'Penjawapan soalan fakta (QA) baru-baru ini telah berguna dari pembangunan sistem belajar dalam (DL). Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles.  Namun, sistem ini belum dilaksanakan pada QA dalam domain yang lebih spesifik, seperti biomedicin, kerana set data biasanya terlalu kecil untuk melatih sistem DL dari awal. Contohnya, set data BioASQ untuk QA biomedikal mengandungi kurang daripada 900 faktoid (jawapan tunggal) dan senarai (jawapan berbilang) kejadian QA. Dalam kerja ini, kita menyesuaikan sistem QA saraf dilatih pada set data domain terbuka besar (SQuAD, sumber) kepada set data biomedikal (BioASQ, sasaran) dengan menggunakan teknik pembelajaran pemindahan berbeza. Arkitektur rangkaian kami berdasarkan sistem QA yang terbaik, dilambangkan dengan penyambungan perkataan biomedis dan mekanisme baru untuk menjawab soalan senarai. Sebaliknya dengan sistem QA biomedikal yang wujud, sistem kita tidak bergantung pada ontologi-domain-spesifik, penghurai atau tag entiti, yang mahal untuk dicipta. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.', 'mt': 'Ir-risposta għall-mistoqsijiet fattwali (QA) reċentement ibbenefikat mill-iżvilupp ta’ sistemi ta’ tagħlim profond (DL). Il-mudelli tan-netwerk newrali jaqbżu l-approċċi tradizzjonali f’oqsma fejn jeżistu settijiet ta’ dejta kbar, bħal SQuAD (madwar 100,000 mistoqsija) għall-artikoli tal-Wikipedia. Madankollu, dawn is-sistemi għadhom ma ġewx applikati għall-QA f’oqsma aktar speċifiċi, bħall-bijomediċin a, minħabba li s-settijiet tad-dejta huma ġeneralment żgħar wisq biex iħarrġu sistema DL mill-bidu. Pereżempju, is-sett tad-dejta BioASQ għal QA bijomedika jinkludi inqas minn 900 fattojde (risposta waħda) u lista (risposti multipli) ta’ każijiet QA. F’dan ix-xogħol, a ħna nadattaw sistema ta’ QA newrali mħarrġa fuq sett kbir ta’ dejta open-domain (SQuAD, sors) għal sett ta’ dejta bijomedika (BioASQ, mira) billi nużaw diversi tekniki ta’ tagħlim ta’ trasferiment. L-arkitettura tan-netwerk tagħna hija bbażata fuq sistema ta’ QA l-aktar avvanzata, estiża b’inkorporazzjoni bijomedika ta’ kliem u mekkaniżmu ġdid biex iwieġeb mistoqsijiet dwar il-lista. B’kuntrast mas-sistemi bijomediċi eżistenti ta’ QA, is-sistema tagħna ma tiddependix fuq ontoloġiji speċifiċi għad-dominju, analizzaturi jew tikketti tal-entitajiet, li huma għaljin biex jinħolqu. Minkejja dan il-fatt, is-sistemi tagħna jiksbu riżultati l-aktar avvanzati dwar mistoqsijiet fattojdi u riżultati kompetittivi dwar mistoqsijiet tal-lista.', 'ml': 'ഫാക്റ്റോയിഡ് ചോദ്യം ഉത്തരം (ക്യൂഎ) അടുത്തുതന്നെ ആഴത്തെ പഠിക്കുന്നതില്\u200d നിന്നും ഉപകരിച്ചിരിക്കുന് വിക്കിപിഡിയയുടെ ലേഖനങ്ങള്\u200dക്കുള്ള എസ്ക്വാഡിലെ വലിയ ഡാറ്റാസറ്റുകള്\u200d നിലനില്\u200dക്കുന്ന ഡോമീനുകളില്\u200d ന്യൂറല്\u200d നെറ്റര്\u200d നെറ് എന്നാലും ഈ സിസ്റ്റമുകള്\u200d ക്യൂഎയിലേക്ക് പ്രയോഗിച്ചിട്ടില്ല കൂടുതല്\u200d പ്രത്യേകിച്ച ഡോമെഡിയില്\u200d പ്രയോഗിച്ചിട്ടുണ്ട്, ജീവിയ മെ ഉദാഹരണത്തിനായി, ബൈയോഎസ്ക്ക് ഡാറ്റാസെറ്റ് ജീവിതഡിക്കല്\u200d ക്യൂഎ (ഒരു ഉത്തരം) കുറച്ച് പിന്നീട് 900 ഫാക്ടോയിഡ് കൂടിയിരിക് ഈ ജോലിയില്\u200d, ഞങ്ങള്\u200d ഒരു വലിയ തുറന്ന ഡൊമെയിന്\u200d ഡാറ്റാസെറ്റില്\u200d പഠിപ്പിക്കുന്ന ന്യൂറല്\u200d ക്യൂറല്\u200d സിസ്റ്റം സജ്ജീകരിക്കുന്നു. വ്യത്യസ്ത വിവരങ്ങള്\u200d ഉപയോ നമ്മുടെ നെറ്റര്\u200dക്ക് ആര്\u200dട്ട് സിസ്റ്റേറ്റ് സംവിധാനത്തിന്റെ അടിസ്ഥാനത്താണ്, ജീവിയ മെഡിക്കല്\u200d വാക്കുകള്\u200d ഉള്\u200dപ്പെടുത്തുന്നത നിലവിലുള്ള ബൈവിക മെഡിക്കല്\u200d ക്യൂഎ സിസ്റ്റമുകള്\u200dക്ക് വിരോധമാണ്, നമ്മുടെ സിസ്റ്റത്തില്\u200d ഡൊമെയിന്\u200d പ്രത്യേകിച്ച ഓണ്\u200dടോളജികള്\u200d,  ഈ സത്യത്തിന് ശേഷം, നമ്മുടെ സിസ്റ്റമുകള്\u200d ഫാക്ടോയിഡ് ചോദ്യങ്ങള്\u200dക്ക് സ്റ്റേറ്റ് സ്റ്റേറ്റ് ഫാക്ടോയിഡ് ചോദ്യങ്', 'no': 'Faktoidspørsmålssvar (QA) har nyleg brukt frå utviklinga av dype læringssystemar (DL). Nyral nettverksmodeller utfører tradisjonelle tilnærmingar i domene der store datasett finst, slik som SQuAD (omtrent 100 000 spørsmål) for Wikipedia- artiklar. Desse system a har imidlertid ikkje noko brukt til QA i meir spesifikke domene, slik som biomedikamen, fordi dataseta er vanlegvis for lite for å trena ein DL-system frå skrått. For eksempel, bioASQ-datasettet for biomedisk QA inneheld mindre enn 900 faktoid (enkelt svar) og liste (fleire svar) QA-instansar. I denne arbeida tilpassar vi eit neiralt QA-system som treng på ein stor dataset for opna domenet (SQuAD, kjelde) til ein biomedisk dataset (BioASQ, mål) ved å bruka forskjellige underlæringsteknikk for overføring. Nettverkarkitekturen vårt er basert på eit QA-systemet for kunsten, utvida med biomedisinske ordinnbygging og ein roman mekanisme for å svara på list a-spørsmål. I contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Til tross av denne faktoren, systemet våre oppnår tilstanden av kunsten på faktoidspørsmål og konkurentiv resultat på spørsmål i lista.', 'mn': 'Фактоид асуултын хариулт (QA) саяхан гүн гүнзгий суралцах (DL) системийн хөгжлийн ашигтай. Цөмийн сүлжээний загварууд Укипедиа баримтуудын хувьд том өгөгдлийн сангууд байдаг уламжлалтын арга загваруудыг ашигладаг. Гэвч эдгээр системүүд QA-д илүү тодорхой хэсэгт хэрэглэгддэггүй. Яагаад гэвэл биологийн эмчилгээ. Учир нь өгөгдлийн санд ихэвчлэн DL системийг гүйцэтгэхэд хэтэрхий жижиг. Жишээлбэл, BioASQ өгөгдлийн сангууд биологийн QA-ын хувьд 900 фактоид (ганц хариулт) болон QA тохиолдолд бага байдаг. Энэ ажил дээр бид олон шилжүүлэх технологийг ашиглаж сургалтын том нээлттэй мэдээллийн компонент (SQuAD, эх үүсвэр) биологийн эмнэлгийн өгөгдлийн компонент (BioASQ, зорилго) дээр сургалтын мэдрэлийн QA системийг адаптирч байна. Бидний сүлжээний архитектур нь биологийн эмнэлгийн үгийг нэмэгдүүлж, жагсаалтын асуултыг хариулах шинэ механизм дээр суурилсан. Биологийн эмчилгээний QA системийн эсрэг бидний систем бүтээх үнэ цэнэтэй онтологууд, ажиллаачид эсвэл бүтээгдэхүүнээс хамаарч байгаагүй. Гэвч энэ үнэндээ бидний систем жагсаалт дээрх фактоид асуулт болон өрсөлдөөний үр дүн гаргадаг.', 'pl': 'Faktoidalne odpowiedzi na pytania (QA) skorzystały ostatnio z rozwoju systemów głębokiego uczenia (DL). Modele sieci neuronowych przewyższają tradycyjne podejścia w domenach, w których istnieją duże zbiory danych, takie jak SQuAD (ok. 100.000 pytania) dla artykułów Wikipedii. Jednak systemy te nie zostały jeszcze zastosowane w odniesieniu do jakości w bardziej konkretnych dziedzinach, takich jak biomedycyna, ponieważ zbiory danych są zazwyczaj zbyt małe, aby szkolić system DL od podstaw. Na przykład zbiór danych BioASQ dla biomedycznej jakości obejmuje mniej niż 900 faktoidalne (pojedyncza odpowiedź) i listę (wiele odpowiedzi) instancje QA. W niniejszej pracy dostosowujemy neuronowy system QA przeszkolony na dużym zbiorze danych otwartych (SQuAD, źródło) do zbioru danych biomedycznych (BioASQ, target) przy użyciu różnych technik uczenia się transferu. Nasza architektura sieci opiera się na najnowocześniejszym systemie QA, rozszerzonym o biomedyczne osadzenia słów i nowatorski mechanizm odpowiedzi na pytania listowe. W przeciwieństwie do istniejących biomedycznych systemów QA, nasz system nie opiera się na ontologiach specyficznych dla domeny, parserach czy tagerów entity, które są kosztowne w tworzeniu. Mimo to nasze systemy osiągają najnowocześniejsze wyniki w kwestiach faktycznych oraz konkurencyjne wyniki w kwestiach listowych.', 'ro': 'Răspunsul la întrebări factoide (QA) a beneficiat recent de dezvoltarea sistemelor de învățare profundă (DL). Modelele de rețea neurală depășesc abordările tradiționale în domenii în care există seturi de date mari, cum ar fi SQUAD (aproximativ 100.000 de întrebări) pentru articolele Wikipedia. Cu toate acestea, aceste sisteme nu au fost încă aplicate calității în domenii mai specifice, cum ar fi biomedicina, deoarece seturile de date sunt, în general, prea mici pentru a instrui un sistem DL de la zero. De exemplu, setul de date BioASQ pentru QA biomedicală cuprinde mai puțin de 900 de instanțe de QA factoid (răspuns unic) și liste (răspunsuri multiple). În această lucrare, adaptăm un sistem de calitate neurală instruit pe un set mare de date open-domain (SQUAD, sursă) la un set de date biomedicale (BioASQ, țintă) prin utilizarea diferitelor tehnici de transfer de învățare. Arhitectura noastră de rețea se bazează pe un sistem de calitate de ultimă generație, extins cu încorporări biomedicale de cuvinte și un mecanism nou pentru a răspunde la întrebările de listă. Spre deosebire de sistemele de calitate biomedicală existente, sistemul nostru nu se bazează pe ontologii specifice domeniului, parsere sau etichete de entitate, care sunt costisitoare de creat. În ciuda acestui fapt, sistemele noastre obțin rezultate de ultimă generație în ceea ce privește întrebările de fapt și rezultate competitive în ceea ce privește întrebările de listă.', 'sr': 'Odgovor na fakultet pitanja (QA) nedavno je koristio od razvoja dubokih sustava učenja (DL). Neuralne mrežne modele iznose tradicionalne pristupe u domenama gde postoje veliki podaci, poput SQuAD (oko 100.000 pitanja) za Wikipedijske članake. Međutim, ove sisteme još nisu primjenjene na QA u specifičnijim domenama, poput biomedicina, jer su podaci uglavnom previše male da bi obučili sistem DL od ogrebotine. Na primer, bioASQ podaci za biomedicinsku QA sadrže manje od 900 faktoida (jedini odgovor) i popis (višestruki odgovori) QA instancija. U ovom poslu, prilagodimo neuralni QA sistem obučen na velikom setu podataka otvorenog domena (SQuAD, izvor) biomedicinskom setu podataka (BioASQ, meta) koristeći različite tehnike učenja prijenosa. Naša mrežna arhitektura je bazirana na stanju umjetnog QA sistema, proširena sa biomedicinskim rečima i novim mehanizam za odgovor na pitanja popisa. U suprotnost postojećim biomedicinskim QA sistemima, naš sistem se ne oslanja na konkretne ontologije, parsere ili etikete entitata, koje su skupe za stvaranje. Uprkos ovoj činjenici, naši sistemi postižu rezultate umetnosti na faktoidskim pitanjima i konkurentnim rezultatima na pitanjima popisa.', 'si': 'ඇත්තටම ප්\u200dරශ්න උත්තර (QA) ගොඩක් ඉගෙනීම (DL) පද්ධතියේ විකාශයෙන් ප්\u200dරයෝජනය කරලා තියෙනවා. විකිපිඩියා පිළිපත්තුවට ප්\u200dරශ්නයක් විදියට SQuAD (ca. 100,000 ප්\u200dරශ්නයක්) ප්\u200dරශ්නයක් නිර්මාණික ජාතික ජාතික ජාත නමුත්, මේ පද්ධතිය තාමත් QA විශේෂ විශේෂ දේමින් වලින් ප්\u200dරයෝජනය කරලා නැහැ, ජීවිත වෛද්\u200dයාවය වගේ, මොකද දත්ත සේට උදාහරණයෙන්, BioASQ දත්ත සූදානම් ජීවිත වෛද්\u200dය QA වෙනුවෙන් ප්\u200dරතිචාරයක් 900 විතරයි (එක ප්\u200dරතිචාරයක්) සහ (විතරක්  මේ වැඩේ අපි නියරුල් QA පද්ධතියක් ප්\u200dරශ්නය කරනවා ලොකු විශාල ප්\u200dරධාන දත්ත සැට (SQuAD, මුළුවක්) ජීවිත්\u200dයාත්මක දත්ත සැට (BioASQ, ඉලක් අපේ ජාල විද්\u200dයාපෘතිය විද්\u200dයාපෘතිය අධාරිත QA පද්ධතියෙන් අධාරිත වෙනවා, ජීවිත විද්\u200dයාපෘතිය වචන සංවේදනය සහ අපේ පද්ධතිය බියෝවිඩික්සිය QA පද්ධතියට විරුද්ධයෙන්, අපේ පද්ධතිය නිර්දේශ විශේෂ පද්ධතිය, පරීක්ෂකය හා පද්ධත මේ ඇත්ත නමුත්, අපේ පද්ධතිය ප්\u200dරශ්නයක් ලැයිස්තුවේ ප්\u200dරශ්නයක් සහ ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ්නයක් විද', 'so': "jawaabta su'aalaha suuqa ah (QA) ugu dhowaad waxey faa'iido u leedahay horumarinta nidaamka waxbarashada deegaan (DL). Tusaalada shabakada naadiga ah waxay ka samaysaa qaabab caadi ah oo ku qoran meelaha macluumaadka waaweyn, sida SQuAD (qiyaas 100,000 su'aalo) ee warqadaha Wikipedia. Si kastaba ha ahaatee, nidaamkan weli QA laguma codsan meelo gaar ah, tusaale ahaan dawo dhakhaatiir ah, sababtoo ah tartanka macluumaadku waxay u yaraan yihiin in lagu tababaro nidaamka DL-ka. Tusaale ahaan qoraalka macluumaadka BioASQ ee QA waxaa kamid ah in ka yar 900 faktoid (jawaabta kaliya) iyo liiska (jawaabaha kala duduwan) QA. Shuqulkaas waxaynu ku habboonaynaa nidaamka neurada QA oo lagu tababariyey sawir aad u weyn oo xafiiska domain oo furan (SQuAD, source) si loo sameeyo sawirada dawooyinka (BioASQ, goal) si aan u isticmaalno qalabka waxbarasho kala duduwan. Arkitirka shabakaddeena waxaa ku saleysan habka QA-da-farshaxanka, waxaana lagu fidiyay hadalka biomedical ah oo la soo dirayo iyo mekaniisa warqada ah si ay ugu jawaabaan su'aalaha liiska. Iska duwan nidaamka dawooyinka QA ee ay jiraan, nidaamkayagu wuxuu ku xiran maayo xirfadaha gaarka ah ee gudaha, jardiinada ama jardiinada waxyaabaha ay ku qaali yihiin in la abuuro. Inta kastoo ay runtii tahay, nidaamkayagu wuxuu soo gaadhaa arimaha xaaladda farshaxanka ee su'aalaha farsamada iyo arimaha iskaashatada ku saabsan su'aalaha lista.", 'sv': 'Fakta frågesvar (QA) har nyligen gynnats av utvecklingen av system för djupinlärning (DL). Neurala nätverksmodeller överträffar traditionella tillvägagångssätt i domäner där stora datamängder finns, till exempel SQUAD (ca 100 000 frågor) för Wikipediaartiklar. Dessa system har dock ännu inte tillämpats på kvalitetssäkring inom mer specifika områden, till exempel biomedicin, eftersom datauppsättningar i allmänhet är för små för att träna ett DL-system från grunden. BioASQ-datauppsättningen för biomedicinsk kvalitetssäkring omfattar till exempel mindre än 900 faktainstanser (ett enda svar) och listor (flera svar). I detta arbete anpassar vi ett neuralt QA-system tränat på ett stort open-domain dataset (SQUAD, källa) till ett biomedicinskt dataset (BioASQ, mål) genom att använda olika överföringstekniker. Vår nätverksarkitektur bygger på ett toppmodernt QA-system, utökat med biomedicinska ordinbäddningar och en ny mekanism för att besvara listfrågor. Till skillnad från befintliga biomedicinska kvalitetssystem förlitar sig vårt system inte på domänspecifika ontologier, tolkare eller entitetstaggare, som är dyra att skapa. Trots detta uppnår våra system toppmoderna resultat i faktafrågor och konkurrenskraftiga resultat i listfrågor.', 'ta': 'உண்மையான கேள்வி பதில் (QA) சமீபத்தில் ஆழமான கல்வி அமைப்புகளின் உருவாக்கத்திலிருந்து பயனுள்ளது. Name ஆனால், இந்த அமைப்புகள் இன்னும் குறிப்பிட்ட குறிப்பிட்ட களங்களில் குறிப்பிட்ட குறிப்பிட்ட களங்களில் பயன்படுத்தப்படவில்லை, ஜியோ எடுத்துக்காட்டாக, biomedical QA தகவல் அமைப்பு QA நிகழ்வுகளில் 900 காரணி( ஒரு விடை) மற்றும் பட்டியல் (பல விடைகள்) குறைந்தது. இந்த வேலையில், நாம் ஒரு பெரிய திறந்த டோமைன் தகவல் அமைப்பு (SQuAD, மூலம்) பயிற்சி செய்யப்பட்ட புதிய கியூஏ அமைப்பை பொருத்துகிறோம் பல மாற்று கற்றல் தொழில்ந எங்கள் பிணையமைப்பு உருவாக்கம் ஒரு நிலையில்-கலை கியூஏ அமைப்பின் அடிப்படையில் உள்ளது, உயிரியல் மருத்துவ வ வார்த்தைகள் பொருத்தப்பட்டத இருக்கும் உயிரியல் கியூஏ முறைமைகளுக்கு எதிராக, எங்கள் கணினியில் குறிப்பிட்ட தொடர்புகள், பார்சர்கள் அல்லது பொருள் ஒட்டுக்களை நம்பு இந்த உண்மையை விட்டாலும், எங்கள் அமைப்புகள் பட்டியல் கேள்விகளுக்கு நிலையில் கலை முடிவுகள் பெறுகிறது.', 'ur': 'فاکتوئیڈ سؤال جواب (QA) اچھے وقت عمیق تعلیم (DL) سیستموں کی توسعہ سے فائدہ اٹھایا گیا ہے۔ نیورال نیٹ ورک موڈل ویکیپیڈیا لکھوں کے لئے بہت بڑے ڈاٹ سٹ موجود ہوتے ہیں۔ لیکن ان سیستموں کو QA کے ذریعے بھی زیادہ مشخص ڈومین میں لازم نہیں کیا گیا ہے، جیسے بیولڈیکس، کیونکہ ڈاٹ سٹ بہت ہی چھوٹے ہیں کہ DL سیستموں کو اسکرے سے تربیت کریں۔ مثال، BioASQ ڈاٹ سٹ بیوڈیسٹ کی QA کے لئے کم ہے پھر 900 فاکتوئڈ (واحد جواب) اور (بہت سی جواب) QA اثباتوں میں لکھا جاتا ہے. اس کام میں ہم نے ایک نورول QA سیستم کو ایک بڑے اوپن ڈومین ڈیٹسٹ (SQuAD, سورست) پر آمادہ کیا ہے جو ایک بیویڈیسٹ ڈیٹسٹ (BioASQ, target) کے ذریعہ مختلف ترنسیٹ سیکھنے کی تکنیک استعمال کرتی ہے۔ ہماری نیٹ ورک معماری ایک ایستی QA سیسٹم پر بنیاد ہے جو بیویڈیسی لفظ کے ساتھ پھیلائی گئی ہے اور ایک نئی مکانیسی لیست سؤال کے جواب دینے کے لئے۔ موجود biomedical QA سیستموں کے مقابلہ میں، ہمارا سیستم ڈومین خاص آنٹلوژ، پارس یا انٹیٹ ٹاگر پر اعتماد نہیں کرتا، جو ایجاد کرنے کے لئے بہت گران ہیں. اس حقیقت کے بغیر، ہماری سیستموں نے لکھ سؤال پر فکتوئیڈ سؤال اور رقابت نتائج پہنچ لیا ہے.', 'vi': 'Sự trả lời các câu hỏi bằng chứng (QA) gần đây đã có lợi từ việc phát triển hệ thống học sâu (DL). Các mô hình thần kinh mạng vượt trội các phương pháp truyền thống trong mỗi miền có các bộ dữ liệu lớn, như SQurad (ca. 100,000 câu hỏi) cho các bài báo Wikipedia. Tuy nhiên, những hệ thống này vẫn chưa được áp dụng với QA trong những lĩnh vực đặc biệt hơn, như môn sinh học, vì các bộ dữ liệu thông thường quá nhỏ để đào tạo hệ thống DL từ đầu. Ví dụ, bộ nhớ dữ liệu của BioASQ dành cho QA sinh học bao gồm ít hơn 900 factoid (một câu trả lời) và danh sách (nhiều câu trả lời) các trường hợp QA. Trong công trình này, chúng tôi thích nghi hệ thần kinh QA được đào tạo trên một bộ dữ liệu rộng mở (SCOAD, nguồn) thành một bộ dữ liệu sinh học (BioASQ, mục tiêu) bằng cách sử dụng các kỹ thuật học chuyển nhượng khác nhau. Kiến trúc mạng của chúng tôi dựa trên một hệ thống QA hiện đại, được mở rộng với sự nhúng vào các từ sinh học và một cơ chế mới để trả lời các câu hỏi. Trái với hệ thống QA sinh học hiện tại, hệ thống của chúng ta không dựa trên các loài có thể điểu chỉnh, phân tích hay kích thước thực thể riêng, mà rất tốn kém để tạo ra. Mặc dù vậy, hệ thống của chúng ta đạt được kết quả tối tân về các vấn đề nhân tố và kết quả cạnh tranh trong các câu hỏi danh sách.', 'uz': "Yaqinda ko'pchilik savol javob beradi DL tizimlarini o'rganishdan foydalanadi. Name Lekin, bu tizimlar QA'ga ko'proq foydalanmagan, biomediya kabi, chunki maʼlumot tizimlari umuman bunday DL tizimdan foydalanish uchun juda qisqa. Masalan, biomedical QA uchun BioASQ maʼlumot seti keyin 900 faktoid (bitta javob) va roʻyxat (bir nechta javoblar) QA dasturlarida yaratiladi. Bu vazida biz juda katta ochiq domen maʼlumot tizimi (SQuAD, манбаъ) bilan bir necha ta'lim o'rganish tugmasini ishlatish uchun biomediya maʼlumotlar tizimga (BioASQ, ലക. BioASQ). Tarmoq arxituvchisi roʻyxat savollariga javob beradigan biomediya soʻzlari va novel mechanisiyasi. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create.  Bu haqida, bizning tizimimiz faqoid savollari va roʻyxat savollariga rivojlanish natijalarini bajaradi.", 'da': 'Faktisk spørgsmålsbesvarelse (QA) har for nylig nydt godt af udviklingen af deep learning (DL)-systemer. Neurale netværksmodeller overgår traditionelle tilgange i domæner, hvor der findes store datasæt, såsom SQUAD (ca. 100.000 spørgsmål) til Wikipedia-artikler. Disse systemer er imidlertid endnu ikke blevet anvendt på QA på mere specifikke områder, såsom biomedicin, fordi datasæt generelt er for små til at træne et DL-system fra bunden. BioASQ-datasættet for biomedicinsk QA omfatter f.eks. mindre end 900 faktiske (enkelt svar) og liste (flere svar) QA-instanser. I dette arbejde tilpasser vi et neuralt QA-system uddannet på et stort open-domain datasæt (SQUAD, kilde) til et biomedicinsk datasæt (BioASQ, mål) ved at anvende forskellige transfer learning teknikker. Vores netværksarkitektur er baseret på et topmoderne QA-system, udvidet med biomedicinske ordindlejringer og en ny mekanisme til at besvare listespørgsmål. I modsætning til eksisterende biomedicinske kvalitetssystemer er vores system ikke afhængig af domænespecifikke ontologier, fortolkere eller entitetstaggere, som er dyre at oprette. På trods af dette opnår vores systemer topmoderne resultater på faktiske spørgsmål og konkurrencedygtige resultater på listespørgsmål.', 'bg': 'Напоследък фактоидният отговор на въпроси се възползва от развитието на системи за дълбоко обучение. Моделите на невронните мрежи превъзхождат традиционните подходи в области, където съществуват големи набори от данни, като например за статии в Уикипедия (около 100 000 въпроса). Тези системи обаче все още не са били приложени към оценката на качеството в по-специфични области, като биомедицината, тъй като наборите от данни обикновено са твърде малки, за да се обучава система от самото начало. Например наборът от данни за биомедицинско Отговорност на качеството включва по-малко от 900 фактоидни (единичен отговор) и списък (множество отговори) инстанции за Отговор на качеството. В тази работа адаптираме невронна система за контрол на качеството, обучена върху голям отворен домейн набор от данни (източник) към биомедицински набор от данни (целева) чрез използване на различни техники за трансферно обучение. Нашата мрежова архитектура се основава на най-съвременна система за контрол на качеството, разширена с биомедицински слова вградени и нов механизъм за отговор на списъчни въпроси. За разлика от съществуващите биомедицински системи за контрол на качеството, нашата система не разчита на специфични за домейн онтологии, анализатори или етикети на обекти, които са скъпи за създаване. Въпреки този факт, нашите системи постигат най-съвременни резултати по фактоидни въпроси и конкурентни резултати по списъчни въпроси.', 'de': 'Factoid Question Responsing (QA) hat kürzlich von der Entwicklung von Deep Learning (DL)-Systemen profitiert. Neuronale Netzwerkmodelle übertreffen traditionelle Ansätze in Domänen, in denen große Datensätze existieren, wie SQuAD (ca. 100.000 Fragen) für Wikipedia-Artikel. Allerdings wurden diese Systeme noch nicht auf die Qualitätssicherung in spezifischeren Bereichen wie der Biomedizin angewendet, da Datensätze im Allgemeinen zu klein sind, um ein DL-System von Grund auf neu zu trainieren. Beispielsweise umfasst der BioASQ-Datensatz für biomedizinische Qualitätssicherung weniger als 900 factoide (Einzelantwort) und Listen (Mehrantwort) QS-Instanzen. In dieser Arbeit adaptieren wir ein neuronales QA-System, das auf einem großen Open-Domain-Datensatz (SQuAD, Quelle) trainiert wurde, auf einen biomedizinischen Datensatz (BioASQ, Target) durch den Einsatz verschiedener Transfer-Lerntechniken. Unsere Netzwerkarchitektur basiert auf einem hochmodernen QA-System, erweitert um biomedizinische Worteinbettungen und einen neuartigen Mechanismus zur Beantwortung von Listenfragen. Im Gegensatz zu bestehenden biomedizinischen Qualitätssicherungssystemen setzt unser System nicht auf domänenspezifische Ontologien, Parser oder Entity Tagger, die teuer zu erstellen sind. Trotzdem erzielen unsere Systeme aktuelle Ergebnisse bei Faktenfragen und wettbewerbsfähige Ergebnisse bei Listenfragen.', 'nl': 'Factoïde vragenbeantwoording (QA) heeft onlangs geprofiteerd van de ontwikkeling van deep learning (DL) systemen. Neurale netwerkmodellen presteren beter dan traditionele benaderingen in domeinen waar grote datasets bestaan, zoals SQuAD (ca. 100.000 vragen) voor Wikipedia-artikelen. Deze systemen zijn echter nog niet toegepast op QA in meer specifieke domeinen, zoals de biogeneeskunde, omdat datasets over het algemeen te klein zijn om een DL-systeem vanaf nul te trainen. De BioASQ dataset voor biomedische QA omvat bijvoorbeeld minder dan 900 factoïde (enkel antwoord) en lijst (meerdere antwoorden) QA instanties. In dit werk passen we een neuraal QA systeem getraind op een grote open-domein dataset (SQuAD, bron) aan op een biomedische dataset (BioASQ, target) door gebruik te maken van verschillende transferleertechnieken. Onze netwerkarchitectuur is gebaseerd op een state-of-the-art QA systeem, uitgebreid met biomedische woord embeddings en een nieuw mechanisme om lijstvragen te beantwoorden. In tegenstelling tot bestaande biomedische QA systemen, is ons systeem niet afhankelijk van domeinspecifieke ontologieën, parsers of entity taggers, die duur zijn om te maken. Desondanks bereiken onze systemen state-of-the-art resultaten op feitelijke vragen en concurrerende resultaten op lijstvragen.', 'id': 'Jawaban pertanyaan fakta (QA) baru-baru ini telah berguna dari pengembangan sistem belajar dalam (DL). Model jaringan saraf melampaui pendekatan tradisional di domain di mana dataset besar ada, seperti SQuAD (ca. 100.000 pertanyaan) untuk artikel Wikipedia. Namun, sistem-sistem ini belum diterapkan untuk QA dalam domain yang lebih spesifik, seperti biomedisina, karena dataset umumnya terlalu kecil untuk melatih sistem DL dari awal. Contohnya, set data BioASQ untuk QA biomedis terdiri kurang dari 900 faktoid (jawaban tunggal) dan daftar (jawaban berbilang) instansi QA. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques.  Arkitektur jaringan kami berdasarkan sistem QA yang terbaik, diperluaskan dengan pembangunan kata biomedis dan mekanisme baru untuk menjawab pertanyaan daftar. Sebaliknya dengan sistem QA biomedis yang ada, sistem kita tidak bergantung pada ontologi spesifik domain, parser atau tag entitas, yang mahal untuk dibuat. Meskipun fakta ini, sistem kita mencapai hasil terbaik pada pertanyaan faktoid dan hasil kompetitif pada pertanyaan daftar.', 'hr': 'Odgovor na fakultet pitanja (QA) nedavno je iskoristio razvoj sustava dubokog učenja (DL). Modeli neuronske mreže iznose tradicionalne pristupe u domenama gdje postoje veliki podaci, poput SQuAD (oko 100.000 pitanja) za članke Wikipedije. Međutim, ovi sustavi još nisu primjenjeni na QA u specifičnijim domenama, poput biomedicina, jer su podaci obično previše male da bi obučili sustav DL iz ogrebotine. Na primjer, podaci BioASQ za biomedicinsku QA sadrže manje od 900 faktoida (jedini odgovor) i popis (višestruke odgovore) QA-a. U ovom poslu, prilagodimo neuronski QA sustav obučen na velikom setu podataka otvorenog domena (SQuAD, izvor) biomedicinskom setu podataka (BioASQ, cilj) koristeći različite tehnike učenja prijenosa. Naša mrežna arhitektura je temeljena na stanju umjetnog QA sustava, proširenoj sa biomedicinskim riječima ugrađenim i novom mehanizam za odgovor na pitanja popisa. Za suprotnost postojećim biomedicinskim QA sustavima, naš sustav se ne oslanja na ontologije, parsere ili etikete entitata, koje su skupe za stvaranje. Uprkos ovoj činjenici, naši sustavi postignu rezultate umjetnosti na faktoidskim pitanjima i konkurentnim rezultatima na pitanjima popisa.', 'ko': '팩토id Q&amp;A(QA)는 최근 딥러닝(DL) 시스템의 발전으로 이득을 봤다.대형 데이터 집합이 존재하는 분야에서 신경 네트워크 모델의 표현은 전통적인 방법보다 우수하다. 예를 들어 위키백과 문장의 단체(약 100000개의 문제).그러나 데이터 세트가 너무 작아서 DL 시스템을 처음부터 훈련할 수 없기 때문에 이런 시스템은 아직 더 구체적인 분야(예를 들어 생물의학)의 QA에 응용되지 않았다.예를 들어 생물의학 QA에 사용되는 바이오ASQ 데이터 세트에는 900개 미만의factoid(단일 답안)와list(여러 답안)의QA 실례가 포함돼 있다.이 작업에서 우리는 다양한 전이 학습 기술을 사용해 대형 개방 분야 데이터 세트(팀, 출처)에서 훈련된 신경 QA 시스템을 바이오메디컬 데이터 세트(BioASQ, 목표)에 맞춘다.우리의 네트워크 구조는 가장 선진적인 QA 시스템을 바탕으로 생물의학 단어 삽입과 새로운 메커니즘을 통해 목록 문제에 대답한다.기존의 생물의학 품질보증시스템에 비해 우리 시스템은 특정 분야의 본체, 해석기 또는 실체 표기기에 의존하지 않기 때문에 이런 창설 원가가 매우 높다.그럼에도 불구하고 우리 시스템은 인자 문제에서 가장 선진적인 결과를 얻었고 리스트 문제에서 경쟁적인 결과를 얻었다.', 'sw': 'Majibu ya maswali ya kweli (QA) hivi karibuni yametumika na maendeleo ya mfumo wa kujifunza kina (DL). Mradi wa mitandao ya kijamii unaonyesha mbinu za kitamaduni katika maeneo ambapo takwimu kubwa zinapo, kama vile SQuAD (maswali 100,000) kwa makala za Wikipedia. Hata hivyo, mifumo hii bado haijatumiwa kwa QA katika maeneo maalum zaidi kama vile dawa za viumbe, kwa sababu seti za taarifa kwa ujumla ni ndogo sana kufundisha mfumo wa DL kutoka kwenye vifaa vya vifaa. Kwa mfano, kituo cha data cha BioASQ cha kitabibu cha QA kinajumuisha kiwango kidogo cha 900 (jibu moja) na orodha (majibu kadhaa) matukio ya QA. Katika kazi hii, tunaweka mfumo wa kiserikali wa QA uliojifundishwa kwenye seti kubwa ya taarifa za ndani (SQuAD, chanzo) kwenye seti ya taarifa za kitabibu (BioASQ, lengo) kwa kutumia mbinu mbalimbali za kujifunza. Ujengo wetu wa mtandao umejikita na mfumo wa hali ya sanaa wa QA, umepandishwa na neno la kitabibu na mfumo wa riwaya wa kujibu maswali ya orodha. Tofauti na mifumo ya kitabibu cha QA, mfumo wetu hautegemea maeneo maalum ya ndani, mabunge au mabango ya viwanda, ambayo ni ghali kwa kutengeneza. Pamoja na ukweli huu, mifumo yetu hupata matokeo ya hali ya sanaa kuhusu maswali ya kiukweli na matokeo ya ushindani katika maswali ya listi.', 'fa': 'پاسخ سؤال faktoid (QA) اخیرا از توسعه سیستم یادگیری عمیق (DL) سود گرفته است. مدل شبکه عصبی از طریق\u200cهای سنتی در دامنه\u200cهای جایی که مجموعه\u200cهای داده\u200cهای بزرگ وجود دارد، مثل SQuAD (حدود ۱۰۰ هزار سوال) برای مقاله\u200cهای ویکیپدیا انجام می\u200cدهد. ولی این سیستم\u200cها هنوز به QA در دامنه\u200cهای خاص\u200cتر، مانند بیولوژیک، کاربرد نشده\u200cاند، زیرا مجموعه\u200cهای داده\u200cها معمولا خیلی کوچک هستند تا سیستم DL را از خرچ آموزش دهند. برای مثال، مجموعه داده های BioASQ برای QA زیست پزشکی کمتر از 900 فاکتوئید (پاسخ تنها) و لیست (پاسخ های چند) QA است. در این کار، ما سیستم عصبی QA را با استفاده از تکنیک یادگیری های متفاوت مختلف آموزش داده شده در یک مجموعه داده های بیولوژیکی (BioASQ، هدف) به یک مجموعه داده های بیولوژیکی آموزش داده می کنیم. معماری شبکه ما بر اساس یک سیستم QA هنری است که با کلمات زیست پزشکی و یک مکانیسم رمانی برای پاسخ دادن سوالات لیست است. در مقابل سیستم های زیست پزشکی QA موجود، سیستم ما بر روی ontologies, parsers or entities taggers خاص دامنه اعتماد ندارد که برای ایجاد کردن گرون هستند. با وجود این حقیقت، سیستم\u200cهای ما نتیجه\u200cهای وضعیت هنری بر سوال\u200cهای فاکتوئید و نتیجه\u200cهای رقابتی در سوال\u200cهای لیست به دست می\u200cآورند.', 'tr': "Factoid soragy jogap (QA) soňra derin öwrenmek sistemleriniň gelişmesinden fayda ýetirdi. Nöral şebek modelleri Wikipedia makalary üçin däpli hatlaryň içinde däpli nokatlary çykýar. Ýöne bu sistemler hem kä birhili takyk sahalarda QA'a uygulanmadylar, sebäbi bil-dermançylyklar hem kiçi bolar çünki ol sistemalar depesinden DL sistemini öwretmek üçin örän kiçi. mysal bolsa, biomedical QA üçin BioASQ veri setirinde 900 faktoidler (ýeke jogaba) we QA örnekleri az döwürýär. Bu işde, beýleki transfers öwrenmek tekniklerini ulanarak öwrenmeli nuýral QA sistemini (SQuAD, çeşme) bir biyomedical dataset (BioASQ, hedef) bilen üýtgedik. Biziň şebek arhitekterimiz QA sistemasyna daýanýar, biomedical söz integrasy we listleriň soraglaryna jogap bermek üçin bir roman mehanizmidir. Öň bar biyomedical QA sistemleriň garşynda, biziň sistemimiz bu domeny beýleki ontologiýa, parsarlar ýa etiketçilere ynanmaýar. Olar bejermek üçin mal. Bu hakykatdan hem sistemamyz faktoid soraglary we ýakynlaşyk netijeleri listde ýetip barýar.", 'sq': 'Përgjigja e pyetjeve faktike (QA) ka përfituar kohët e fundit nga zhvillimi i sistemeve të mësimit të thellë (DL). Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles.  Megjithatë, këto sisteme nuk janë aplikuar ende në QA në fusha më specifike, të tilla si biomedicine, sepse të dhënat janë përgjithësisht shumë të vogla për të trajnuar një sistem DL nga zero. Për shembull, kompleti i të dhënave BioASQ për QA biomedikale përfshin më pak se 900 raste faktoide (përgjigje e vetme) dhe list ë (përgjigje të shumta) QA. Në këtë punë, ne përshtatemi një sistem QA neural të stërvitur në një set të madh të të dhënave të dominiu të hapur (SQuAD, burim) në një set të të dhënave biomedikale (BioASQ, objektiv) duke përdorur teknika të ndryshme të mësimit të transferimit. Arkitektura jonë e rrjetit është bazuar në një sistem QA më të lartë, të zgjeruar me përfshirje fjalësh biomedike dhe një mekanizëm të ri për të përgjigjur pyetjeve të list ës. Në kontrast me sistemet biomedikale QA ekzistuese, sistemi ynë nuk mbështetet në ontologjitë specifike për domenin, analizuesit apo etiketat e njësive, të cilat janë të shtrenjta për të krijuar. Pavarësisht nga ky fakt, sistemet tona arrijnë rezultate moderne mbi pyetjet faktike dhe rezultatet konkurruese mbi pyetjet e list ës.', 'am': 'የውጤት ጥያቄ መልስ (QA) በቅርብ ጊዜ ጥልቅ ትምህርት (DL) ሲስተማርን መግለጫ ጠቅሟል፡፡ የኔural network models to Wikipedia articles such as SQuAD (ca. 100,000 ጥያቄዎች) በታላቅ ዳታዎችን በሚኖሩበት ድረቦች ውስጥ የባሕላዊ ጥያቄዎችን ያሳያል። ምንም እንኳን፣ እነዚህ ስብስቶች ገና ወደ QA በተለያዩ አካባቢዎች፣ እንደbiomedics፣ ምክንያቱም ዳታተሮችን ከክፈት ጀምሮ DL ሲስተማር በጣም ትንሽ ናቸው፡፡ ለምሳሌ፣ የቢዮASQ ዳታ ለbiomedical QA ማሰናጃዎች ከዚያ በኋላ 900 ፋክቶዲ (አንዲት መልስ) እና ዝርዝር (ብዙዎች መልስ) ጥያቄ ነው፡፡ በዚህ ሥራ፣ በተለየ ትልቅ ትምህርት ትምህርት ለመጠቀም በተከፈተ ድሜን ዳታ ማሰሪያ (SQuAD, ምንጭ) የተጠቃሚ የኩነቶች የኩነቶች የQA ስርዓት ስርዓት (BioASQ, ዕቅድ) እናስጠጋለን፡፡ የመርከቢቱ መረብ መሠረት መሠረት የ-የ የ.አ-የ.አ. ስርዓት፣ የbiomedical ቃላት መግለጫ እና የዘላለም መዝገብ የዝርዝር ጥያቄዎችን ለመመልስ አካሄድ ነው፡፡ በተቃውሞው የbiomedical QA ስርዓቶች፣ ስርዓታችን ለድሜን የተለየ ኢኖኖሎጂ፣ ፓርስር ወይም አካባቢ ተጋርማዎች አይደገፍም፡፡ ከዚህም ነገር ምንም እንኳ፣ ስርዓቶቻችን የ-የ-የ-አርእስት ውጤቶችን በጥያቄ ጥያቄዎች እና በጥያቄ ውጤቶችን በዝርዝር ጥያቄዎች ላይ ያገኛሉ፡፡', 'af': "Name Neurale netwerk modele uitvoer tradisionele toegang in domeine waar groot datastelle bestaan, soos SQuAD (ca. 100. 000 vrae) vir Wikipedia-artikels. Maar hierdie stelsels is nog nie toegewend na QA in meer spesifieke domeine, soos biomediese, omdat datastelle gewoonlik te klein is om 'n DL stelsel te trein vanaf die skrewe. Byvoorbeeld, die BioASQ datastel vir biomediese QA is minder dan 900 faktoide (enkele antwoord) en lys (veelvuldige antwoorde) QA voorbeelde. In hierdie werk, ons adapteer 'n neurale QA stelsel wat op 'n groot oop- domein datastel (SQuAD, bron) opgelei is na' n biomediese datastel (BioASQ, doel) deur verskillende oordrag onderwerp teknike te gebruik. Ons netwerk arkitektuur is gebaseer op 'n state-of-the-art QA stelsel, uitgebrei met biomediese woord inbettings en 'n roman mekanisme om lys vrae te antwoord. In contrast to existing biomedical QA systems, our system rely not on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Ons stelsels bereik staat van die kunsten resultate op faktoide vrae en mededingsresultate op lys vrae.", 'hy': 'Ֆատոյդի հարցերին պատասխանելը վերջերս օգտվել է խորը ուսումնասիրության համակարգերի զարգացմանից: Նյարդային ցանցի մոդելները գերազանցում են ավանդական մոտեցումները այնպիսի ոլորտներում, որտեղ կան մեծ տվյալների համակարգեր, ինչպիսիք են օրինակ Վիքիփեդիայի հոդվածների SQUADը (մոտ 100,000 հարց): However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch.  Օրինակ, կենսաբժշկական QA-ի ԲիոASQ տվյալների համակարգը կազմում է ավելի քիչ քան 900 ֆակտոիդ (մեկ պատասխան) և ցուցակ (բազմաթիվ պատասխաններ) QA-ի օրինակներ: Այս աշխատանքի ընթացքում մենք հարմարեցնում ենք նյարդային QA համակարգը, որը պատրաստված է մեծ բաց բնագավառի տվյալների համակարգի վրա (SQUADը, աղբյուրը) կենսաբժշկական տվյալների համակարգին (ԲիոԱՍQ, նպատակը) օգտագործելով տարբեր փոխանցման ուս Մեր ցանցի ճարտարապետությունը հիմնված է ամենաբարձր QA համակարգի վրա, որը ընդլայնված է կենսաբժշկական բառերի ներդրման և նոր մեխանիզմի վրա, որպեսզի պատասխանի ցանկի հարցերին: Ի հակադրություն գոյություն ունեցող կենսաբժշկական QA համակարգերին, մեր համակարգը չի հիմնված բնագավառի կոնկրետ օնտոլոգիաների, վերլուծումների կամ անհատականության նշանների վրա, որոնք թանկ են ստեղծելու համար: Չնայած այս փաստին, մեր համակարգերը հասնում են ամենաբարձր արդյունքներին ֆակտոիդ հարցերի և մրցակցության արդյունքների ցուցակի հարցերի վրա:', 'bs': 'Odgovor na fakultet pitanja (QA) nedavno je koristio od razvoja dubokih sustava učenja (DL). Neuralne mrežne modele iznose tradicionalne pristupe u domenama gdje postoje veliki podaci, poput SQuAD (oko 100.000 pitanja) za Wikipedijske članake. Međutim, te sisteme još nisu primjenjene na QA u specifičnijim domenama, poput biomedicina, jer su podaci uglavnom previše male da bi obučili sistem DL iz ogrebotine. Na primjer, bioASQ podaci za biomedicinsku QA sadrže manje od 900 faktoida (jedini odgovor) i popis (višestruke odgovore) QA instanca. U ovom poslu, prilagodimo neuralni QA sistem obučen na velikom setu podataka otvorenog domena (SQuAD, izvor) biomedicinskom setu podataka (BioASQ, meta) koristeći različite tehnike učenja prijenosa. Naša mrežna arhitektura je temeljena na stanju umjetnog QA sistema, proširena sa biomedicinskim riječima, i novom mehanizam za odgovor na pitanja popisa. U suprotnost postojećim biomedicinskim QA sistemima, naš sistem se ne oslanja na konkretne ontologije, parsere ili etikete entitata, koje su skupe za stvaranje. Uprkos ovoj činjenici, naši sistemi postignu rezultate umjetnosti na faktoidnim pitanjima i konkurentnim rezultatima na pitanjima popisa.', 'bn': 'ফ্যাক্টোয়াড প্রশ্নের উত্তর (কিউএ) সম্প্রতি গভীর শিক্ষা ব্যবস্থা উন্নয়ন থেকে সুবিধা প্রদান করেছে। উইকিপিডিয়া প্রবন্ধের জন্য স্কুয়াড (প্রায় ১০০০০,০০০ প্রশ্ন) নিউরেল নেটওয়ার্ক মডেলের ঐতিহ্যবাহী প্রযুক্তি প্রদর্শন করেছে। তবে এই সিস্টেমগুলো এখনো কিউ এ-এর কাছে প্রয়োগ করা হয়নি, যেমন বায়োমেডিয়ান, কারণ ডাটাসেটগুলো সাধারণত ডিএলসিস্টেম থেকে প্রশিক্ষণ করার জন্য উদাহরণস্বরূপ, বায়োয়ামেডিকেল কিউএ এর জন্য বায়োআসিকার ডাটাসেট কম তারপর ৯০০ ফ্যাক্টোয়িড (একক উত্তর) এবং তালিকা (বেশ কয়েকটি উত্তর) কিউ এ এই কাজে আমরা বিভিন্ন পরিবর্তন শিক্ষা প্রযুক্তি ব্যবহার করে একটি বিশাল খোলা ডোমেইন ডাটাসেট (SQuAD, সোর্স) প্রশিক্ষিত একটি নিউরেল কিউএ সিস্টেম প্রশিক্ষণ করি। আমাদের নেটওয়ার্ক কাঠামো একটি কিউএ সিস্টেমের উপর ভিত্তিক, বায়োমেডিকেল শব্দ বিস্তৃত হয়েছে এবং তালিকার প্রশ্নের উত্তর দেয়ার জন্য একটি  বিদ্যমান বায়োমেডিকেল কিউএ সিস্টেমের বিপরীতে, আমাদের সিস্টেম ডোমেইন-নির্দিষ্ট অনলোগিয়া, পার্সার অথবা বস্তুর ট্যাগারের উপর নির্ এই বাস্তবতা সত্ত্বেও, আমাদের সিস্টেম ফ্যাক্টোইড প্রশ্ন এবং তালিকা প্রশ্নের উপর প্রতিযোগিতার ফলাফল অর্জন করে।', 'az': "Faktoid sual cavab vermək (QA) son zamanlarda dərin öyrənmə sistemlərindən faydalandı. Nöral ağ modelləri Wikipedia məktulları üçün böyük veri qurğuları olduğu domenlərdə yayınlaşdırır. Ancaq bu sistemlər hələ də QA'ya daha müəyyən bir domenlərdə uyğunlanmamışlar, biomedicin kimi, çünki verilən qurğular genellikle DL sistemini çəkmək üçün çox kiçik idilər. Misal olaraq, biomedical QA üçün BioASQ verilənlərin qurğusu daha az, sonra 900 faktoid (tək cavab) və QA məsələlərini qurtar. Bu işdə, çox a çıq-domen veri seti (SQuAD, kaynağı) ilə müxtəlif transfer öyrənmə tekniklərini istifadə edərək bir nöral QA sistemini biomedical veri setinə uyğunlaşdırırıq. Ağ arhitektarımız QA sisteminin eyaletində dayanılır, biomedical sözlərlə birlikdə genişlənmiş və liste sorularına cavab vermək üçün yeni bir mehanizmidir. Bütün biomedical QA sistemlərinə qarşı, sistemimiz domain-specific ontologies, parsers və entity taggers üzərində təvəkkül etmirik ki, yaratmaq üçün mal. Bu həqiqətə baxmayaraq, sistemlərimiz məsələlər haqqında faktoid sualların və müəllif sonuçlarına gəlir.", 'ca': "La resposta a preguntes de fets (QA) ha beneficiat recentment del desenvolupament de sistemes d'aprenentatge profund (DL). Els models de xarxa neuronal superen els enfocaments tradicionals en dominis on existeixen grans conjunts de dades, com SQuAD (uns 100.000 preguntes) per articles de Wikipedia. No obstant això, aquests sistemes encara no s'han aplicat a la QA en dominis més específics, com la biomèdica, perquè els conjunts de dades són generalment massa petits per treinar un sistema DL des de zero. Per exemple, el conjunt de dades BioASQ per a QA biomèdic comprend menys de 900 instances de QA de factoide (resposta única) i llista (múltiples respostes). En aquesta feina, adaptem un sistema QA neural entrenat en un gran conjunt de dades de domini obert (SQuAD, font) a un conjunt de dades biomèdics (BioASQ, objectiu) utilitzant diverses tècniques d'aprenentatge de transfer ències. La nostra arquitectura de xarxa està basada en un sistema QA d'última generació, estensit amb integració de paraules biomèdiques i un mecanisme nou per respondre a preguntes de llista. Al contrari dels sistemes existents de QA biomèdics, el nostre sistema no es basa en ontologies específices per domini, analitzadors o etiquetadors d'entitats, que són costosos de crear. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.", 'cs': 'Faktoidní odpověď na otázky (QA) v poslední době využívá vývoj systémů hlubokého učení (DL). Modely neuronálních sítí překonávají tradiční přístupy v doménách, kde existují velké datové sady, jako je SQuAD (cca 100.000 otázky) pro články Wikipedie. Tyto systémy však dosud nebyly aplikovány na QA ve specifických oblastech, jako je biomedicína, protože datové sady jsou obecně příliš malé na to, aby DL systém trénoval od začátku. Například datová sada BioASQ pro biomedicínské QA obsahuje méně než 900 faktoidní (jedna odpověď) a seznam (více odpovědí) QA instancí. V této práci adaptujeme neuronový QA systém trénovaný na velkém open-domain datovém souboru (SQuAD, zdroj) na biomedicínský datový soubor (BioASQ, cíl) pomocí různých technik transferového učení. Naše síťová architektura je založena na nejmodernějším systému QA, rozšířeném o biomedicínské vložení slov a nový mechanismus pro odpověď na otázky seznamu. Na rozdíl od stávajících biomedicínských systémů QA se náš systém nespoléhá na doménově specifické ontologie, parsery nebo entity tagery, které jsou nákladné na vytvoření. Navzdory tomu dosahují naše systémy nejmodernějších výsledků na faktické otázky a konkurenčních výsledků na seznamových otázkách.', 'fi': 'Factoid question answer (QA) on viime aikoina hyﾃｶtynyt syvﾃ､oppimisjﾃ､rjestelmien kehittﾃ､misestﾃ､. Neuroverkkomallit ylittﾃ､vﾃ､t perinteiset lﾃ､hestymistavat aloilla, joilla on suuria tietoaineistoja, kuten Wikipedia-artikkeleissa SQuAD (noin 100 000 kysymystﾃ､). Nﾃ､itﾃ､ jﾃ､rjestelmiﾃ､ ei kuitenkaan ole vielﾃ､ sovellettu laadunvarmistukseen tarkemmin mﾃ､ﾃ､ritellyillﾃ､ aloilla, kuten biolﾃ､ﾃ､ketieteessﾃ､, koska tietoaineistot ovat yleensﾃ､ liian pieniﾃ､ kouluttaakseen DL-jﾃ､rjestelmﾃ､ﾃ､ alusta alkaen. Esimerkiksi biolﾃ､ﾃ､ketieteellisen laadunvarmistuksen BioASQ-tietokokonaisuus sisﾃ､ltﾃ､ﾃ､ alle 900 faktoidia (yksi vastaus) ja luetteloa (useita vastauksia) laadunvarmistuksen. Tﾃ､ssﾃ､ tyﾃｶssﾃ､ sovitamme suurella avoimen verkkotunnuksen tietoaineistolla (SQuAD, lﾃ､hde) koulutetun neuraalisen laadunvarmistusjﾃ､rjestelmﾃ､n biolﾃ､ﾃ､ketieteelliseen tietoaineistoon (BioASQ, kohde) kﾃ､yttﾃ､mﾃ､llﾃ､ erilaisia siirtooppimistekniikoita. Verkkoarkkitehtuurimme perustuu huipputekniikkaan perustuvaan laadunvarmistusjﾃ､rjestelmﾃ､ﾃ､n, jota laajennetaan biolﾃ､ﾃ､ketieteellisillﾃ､ sanaupotuksilla ja uudella mekanismilla listan kysymyksiin vastaamiseksi. Toisin kuin olemassa olevat biolﾃ､ﾃ､ketieteelliset laadunvarmistusjﾃ､rjestelyt, jﾃ､rjestelmﾃ､mme ei perustu toimialueekohtaisiin ontologioihin, jﾃ､sentﾃ､jiin tai entiteettitagereihin, joiden luominen on kallista. Tﾃ､stﾃ､ huolimatta jﾃ､rjestelmﾃ､mme saavuttavat huipputason tuloksia faktoiduissa kysymyksissﾃ､ ja kilpailukykyisiﾃ､ tuloksia listakysymyksissﾃ､.', 'et': 'Küsimustele vastamise faktoid on hiljuti saanud kasu sügavõppe süsteemide arendamisest. Närvivõrgu mudelid ületavad traditsioonilisi lähenemisviise valdkondades, kus on olemas suured andmekogumid, näiteks SQuAD (umbes 100 000 küsimust) Wikipedia artiklite jaoks. Neid süsteeme ei ole siiski veel rakendatud kvaliteedi tagamise suhtes konkreetsemates valdkondades, nagu biomeditsiini, sest andmekogumid on üldiselt liiga väikesed, et koolitada üldiselt laiaulatuslikku süsteemi nullist. Näiteks BioASQ andmekogum biomeditsiinilise kvaliteedi tagamiseks hõlmab vähem kui 900 faktilist (üks vastus) ja loendit (mitu vastust) kvaliteedi tagamise eksemplari. Selles töös kohandame suurel avatud domeenil (SQuAD, allikas) koolitatud neuraalset kvaliteedi tagamise süsteemi biomeditsiiniliste andmekogumitega (BioASQ, sihtmärk), kasutades erinevaid siirdeõppe tehnikaid. Meie võrguarhitektuur põhineb kaasaegsel kvaliteedi tagamise süsteemil, mida laiendatakse biomeditsiiniliste sõnade manustamisega ja uudse mehhanismiga nimekirjade küsimustele vastamiseks. Erinevalt olemasolevatest biomeditsiinilistest kvaliteedi tagamise süsteemidest ei toetu meie süsteem domeenispetsiifilistele ontoloogiatele, parseritele või olemi sildistajatele, mille loomine on kallis. Sellest hoolimata saavutavad meie süsteemid kaasaegseid tulemusi faktilistes küsimustes ja konkurentsivõimelisi tulemusi nimekirja küsimustes.', 'jv': 'logic Name Nanging, sistem iki durung pangkat ono arep aplikasi kanggo KA dengan pangkat pangkat lunak, kaya bisa biyoton, soalé dataset duwé isih basa kanggo ngelarang sistem DL kapan kanggo ngilanggar. Sampeyan, nggambar Daftar BiASq kanggo Ketok Biyuan sing sampeyan mralah mungkin liyane, sampeyan mungkin 9 nek batar manut (singular responsa) lan lisar (akeh mbubaturan) qA sing sampeyan. In this job, we Adjusted a Neral qA System tracted on a big open-domain dataset Arkirektur sing paling dhéwé basa ning sistem stad-ning-kuwi-arêt qA, ndêmlaku karo pergambar barang biyo-dhéwé lan nganggo sistem sing nyimpen kanggo ngubah dhéwé. In contrast to current Biwotherapist Ingon ngomong, sistem namung gawe barang langkung tarjamah-perusahaan lan gambarang langkung rawut karo perusahaan sing paling-perusahaan kanggo ndelok', 'sk': 'Dektoidno odgovarjanje na vprašanja (QA) je nedavno koristilo razvoj sistemov globokega učenja (DL). Modeli živčnih omrežij presegajo tradicionalne pristope v domenah, kjer obstajajo veliki nabori podatkov, kot je SQuAD (približno 100.000 vprašanj) za Wikipedijske članke. Vendar pa ti sistemi še niso bili uporabljeni za zagotavljanje kakovosti na bolj specifičnih področjih, kot je biomedicina, saj so podatkovni nabori na splošno premajhni, da bi lahko sistem DL usposabljali iz nič. Zbirka podatkov BioASQ za biomedicinsko preverjanje kakovosti na primer obsega manj kot 900 dejanskih (en odgovor) in seznamov (več odgovorov) primerov kakovosti. V tem delu smo z uporabo različnih tehnik transfernega učenja prilagodili nevronski sistem kakovosti, usposobljen na velikem naboru podatkov odprte domene (SQuAD, vir) biomedicinskemu naboru podatkov (BioASQ, tarča). Naša omrežna arhitektura temelji na najsodobnejšem sistemu kakovosti, razširjenem z biomedicinskimi vgradnjami besed in novim mehanizmom za odgovore na vprašanja seznama. V nasprotju z obstoječimi biomedicinskimi sistemi za zagotavljanje kakovosti se naš sistem ne zanaša na domenske ontologije, razčlenjevalnike ali označevalce entitet, ki so dragi za ustvarjanje. Kljub temu naši sistemi dosegajo najsodobnejše rezultate pri dejanskih vprašanjih in konkurenčne rezultate pri vprašanjih seznama.', 'he': 'עניין על שאלות פקטוידיות (QA) הרוויח לאחרונה מהפיתוח של מערכות למידה עמוקה (DL). דוגמני רשת נוירולית עולים על גישות מסורתיות בתחומים שבו קבוצות נתונים גדולות קיימות, כמו SQuAD (בערך 100,000 שאלות) עבור מאמרים ויקיפדיה. בכל אופן, המערכות הללו עדיין לא הופעו על QA בתחומים יותר ספציפיים, כמו ביורפואה, כי קבוצות נתונים בדרך כלל קטנות מדי כדי לאמן מערכת DL מאפס. לדוגמה, קבוצת מידע BioASQ עבור QA ביורפואית מכילה פחות מ 900 מקרים QA (תשובה אחת) ורשימה (תשובות רבות). בעבודה הזו, אנו מתאימים מערכת QA עצבית מאומנת על קבוצת נתונים גדולה של שטח פתוח (SQuAD, מקור) לקבוצת נתונים ביורפואיים (BioASQ, מטרה) על ידי שימוש טכניקות לימוד העברה שונות. הארכיטקטורה הרשתית שלנו מבוססת על מערכת QA מצוינת ביותר, מורחבת עם מילים ביומדיקאיות והמנגנון חדש לענות על שאלות רשימת. בניגוד למערכות QA ביורפואית קיימות, המערכת שלנו לא סומכת על אונטולוגיות ספציפיות לתחום, מחקרים או תגרים של ישויות, שהיו יקרים ליצור. למרות העובדה הזאת, המערכות שלנו משיגות תוצאות חדשות על שאלות עובדות ותוצאות תחרותיות על שאלות רשימה.', 'ha': "QA na iya karɓa wa tambayi mai faso (QA) na ƙarshen ya da amfani daga the Development of Systems of learning Depth (DL). Shiryoyin taruwar neural sun nuna hanyoyin zaman hanyõyin da ke cikin daidai da tsari masu girma, kamar SQuAD (daidai 100,000 tambayar) wa makampuni na Wikimedia. A lokacin da, ba za a iya amfani da waɗannan na'ura ba zuwa QA cikin wasu kayan dabam-daban, kamar dawwamar da za'a yi amfani da shi ba, kwani, tsarin bayani masu ƙaranci don a yi amfani da wani na'urar DL daga shawarar. Misali, tsarin database na BioAsQ na samar da aka kashe QA na ƙara lokaci 9000 faktoid (jibar guda) da jerin (masu yawa) masu motsi na QA. Daga wannan aikin, za mu daidaita wani na'urar QA wanda aka sanar da shi a kan tsarin danne-danne mai buɗe (SQuAD, source) zuwa tsarin bayayyakinsi na'asa (BioAsQ, goan) don mu yi amfani da masu motsi daban-daban. An samar da bakin tarakinmu an baka a kan halin-na-sanar QA, an shimfiɗa shi da magana mai baƙanci da kuma an sami wani matsayin wara ga karya masu tambayar. Tsarin da ke gaba ga tsarin QA da aka kashe shi, na'urarmu ba ta dõgara a kan wasu shiryoyin ayuka na guda ba, parser ko matsayin ayuka da maɓallin gaske, masu kyauta ne a ƙidida su ƙiƙiro. Babu da gaskiyar wannan, na'asarmu za'a sami matsalar-halin-sanata a kan masu tambayar faktoid da matsala masu yin jihãdi a kan tambayar jerin.", 'bo': 'Factoid question answer (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. ཡིན་ནའང་། མ་ལག་འདི་དག་དུས་ཁྱབ་པར་དམིགས་བསལ་གྱི་དོན་ཁྲོད་ཀྱི་ནང་དུ་QA་ལ་སྤྱོད་མ་ཐུབ། དཔེར་ན། BioASQ སྒྲིག་ཆ་འཕྲིན་གྱི་ཆ་འཕྲིན་ཡིག་གཟུགས་ཀྱི་QA དེ་ལས་ཀྱང་ཉུང་བའི་faktoid 900(single answer)དང་ཐོ་འགོད་ཀྱི་དཔེ་བརྗོད།QA དཔེ་བརྗོད་དང་། In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. ང་ཚོའི་དྲ་དམངས་སྒྲིག་གནས་སྟངས་ལ་རྒྱལ་ཁབ་ཀྱི་གནས་སྟངས་དང་གནས་སྟངས་ཀྱི་QA་རིམ་ལ་གཞི་རྟེན་ཡོད་པ་ལས་སྐྱེན་བཟོས་པའི་གནད་ཆ་འཕྲིན In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. དེ་བཞིན་ཡང་། ང་ཚོའི་མ་ལག་གིས་སྔོན་སྒྲིག་གི་གནས་སྟངས་གནས་སྟངས་དང་ཐོ་འགོད་གི་གནད་དོན་རྐྱེན་བྱེད་ཀྱི་ཡོད།'}
{'en': 'A phoneme clustering algorithm based on the obligatory contour principle', 'ar': 'خوارزمية التجميع الصوتي على أساس مبدأ الكنتور الإلزامي', 'fr': 'Un algorithme de clustering de phonèmes basé sur le principe du contour obligatoire', 'pt': 'Um algoritmo de agrupamento de fonemas baseado no princípio de contorno obrigatório', 'es': 'Un algoritmo de agrupamiento de fonemas basado en el principio obligatorio de contorno', 'ja': '必須輪郭原理に基づく音素クラスタリングアルゴリズム', 'zh': '一基于强轮廓原理音素聚类算法', 'ru': 'Алгоритм кластеризации фонем, основанный на принципе обязательного контура', 'hi': 'अनिवार्य समोच्च सिद्धांत के आधार पर एक फोनेम क्लस्टरिंग एल्गोरिथ्म', 'ga': 'Algartam cnuasaithe fóinéime bunaithe ar phrionsabal an chomhrianta éigeantach', 'ka': 'ტონემის კლასტერის ალგორიტიმი, რომელიც დაბაზეულია საჭირო კონტურის პრინციპზე', 'hu': 'A kötelező kontúr elven alapuló fonema klaszterezési algoritmus', 'el': 'Ένας αλγόριθμος ομαδοποίησης φωνωμάτων βασισμένος στην υποχρεωτική αρχή περιγράμματος', 'it': 'Un algoritmo di clustering del fonema basato sul principio del contorno obbligatorio', 'lt': 'Phoneme clustering algorithm based on the mandatory contour principle', 'mk': 'Алгоритм за групирање на телефони базиран на принципот на обврзан контур', 'kk': 'Фонемді кластерингі алгоритм, көмекші контрол принципіне негізделген', 'ms': 'Algoritma pengkumpulan fonem berdasarkan prinsip contur yang wajib', 'ml': 'ഒരു ഫോണിമെന്\u200d ആല്\u200dഗോരിതം അടിസ്ഥാനമാക്കിയിരിക്കുന്നു.', 'mn': 'Фонемын кластерингийн алгоритм нь', 'mt': 'Algoritmu ta’ raggruppament telefoniku bbażat fuq il-prinċipju tal-kontorn obbligatorju', 'no': 'Name', 'pl': 'Algorytm klastrowania fonemów oparty na zasadzie obowiązkowego konturu', 'ro': 'Un algoritm de clusterizare a fonemului bazat pe principiul conturului obligatoriu', 'sr': 'Telefonski algoritam skupljanja baziran na obligatornom principu kontura', 'si': 'Name', 'so': 'Qoraalka telefoonka oo ku saleysan sharciga qasabka ah', 'sv': 'En fonemklubreringsalgoritm baserad på den obligatoriska konturprincipen', 'ta': 'கட்டுப்படுத்தப்பட்ட தொடர்பு விதிமுறையை அடிப்படையில் ஒரு புகைப்பெட்டி உறுப்பிடும் ஆல்பரிடம்', 'ur': 'ایک فونیم کلسٹر الگوریتم مجبور کنٹور پرنسیٹ پر بنیاد ہے', 'uz': 'Name', 'vi': 'Một thuật gia gốc điện điện đã được chấp nhận', 'bg': 'Алгоритъм за групиране на фонеми въз основа на задължителния принцип на контура', 'da': 'En fonemklosteringsalgoritme baseret på det obligatoriske konturprincip', 'nl': 'Een foneemclustering algoritme gebaseerd op het verplichte contourprincipe', 'hr': 'Telefonski algoritam skupljanja baziran na obligatornom principu kontura', 'ko': '강제 윤곽 원리를 바탕으로 한 음소 집합 알고리즘', 'de': 'Ein Phonem-Clustering-Algorithmus basierend auf dem obligatorischen Konturprinzip', 'id': 'Algoritma pengumpulan fonem berdasarkan prinsip kontur obligatif', 'fa': 'الگوریتم گروه\u200cگری تلفن بر اساس قانون مجبوری', 'sw': 'Ualgorithi wa simu unaoonyesha msingi wa kanuni ya utaratibu', 'tr': 'Özgür Kontour prinsipine daýanýan telefon görkezilişi algoritmi', 'af': 'Name', 'sq': 'Algoritmi i grupimit telefonik bazuar në parimin e detyrueshëm të konturimit', 'am': 'የፎቶ አሌጎርቲም በሥርዓት ግንኙነት ላይ', 'hy': 'Ֆոնեմի խմբավորող ալգորիթմ, որը հիմնված է պարտադիր հատվածի սկզբունքի վրա,', 'az': 'Nöqsanlı kontur prinsipinə dayanan bir fonema clustering algoritmi', 'bs': 'Telefonski algoritam skupljanja baziran na obligatornom principu kontura', 'bn': 'বৈধ পরিচিতি নীতির উপর ভিত্তিক একটি ফোনেম বিস্তৃত অ্যালগরিদম', 'et': 'Kohustuslikul kontuuripõhimõttel põhinev foneemide klastrite algoritm', 'fi': 'Pakolliseen ääriviivaperiaatteeseen perustuva foneemiklusterointialgoritmi', 'ca': 'Un algoritme de agrupació fonèmica basat en el principi obligatori del contorn', 'cs': 'Algoritmus shlukování fonémů založený na principu povinné kontury', 'jv': 'Algorithm', 'ha': "Wani algoritm na samu'a da algoritm na lazimta", 'he': 'אלגוריתם מגדל טלפונים מבוסס על עקרון הקונטור המחוייב', 'sk': 'Algoritem združevanja fonema, ki temelji na obveznem principu konture', 'bo': 'སྤྱིར་བཏང་བ་དང་མཉམ་སྦྲགས་ཀྱི་སྔོན་ལྟར་གཞུང་བཟོས་ཀྱི་སྣེ་གཟུགས་རྣམ་པ།'}
{'en': 'This paper explores a divisive hierarchical clustering algorithm based on the well-known Obligatory Contour Principle in phonology. The purpose is twofold : to see if such an algorithm could be used for unsupervised classification of phonemes or graphemes in corpora, and to investigate whether this purported universal constraint really holds for several classes of phonological distinctive features. The algorithm achieves very high accuracies in an unsupervised setting of inferring a consonant-vowel distinction, and also has a strong tendency to detect coronal phonemes in an unsupervised fashion. Remaining classes, however, do not correspond as neatly to phonological distinctive feature splits. While the results offer only mixed support for a universal Obligatory Contour Principle, the algorithm can be very useful for many NLP tasks due to the high accuracy in revealing consonant / vowel / coronal distinctions.', 'es': 'Este artículo explora un algoritmo de agrupamiento jerárquico divisivo basado en el conocido Principio de Contorno Obligatorio en fonología. El propósito es doble: ver si tal algoritmo podría usarse para la clasificación no supervisada de fonemas o grafemas en cuerpos, e investigar si esta supuesta restricción universal realmente se aplica a varias clases de características distintivas fonológicas. El algoritmo logra precisiones muy altas en un entorno no supervisado de inferir una distinción entre consonantes y vocales, y también tiene una fuerte tendencia a detectar fonemas coronales de manera no supervisada. Sin embargo, las clases restantes no se corresponden tan claramente con las divisiones de características distintivas fonológicas. Si bien los resultados solo ofrecen un apoyo mixto para un principio de contorno obligatorio universal, el algoritmo puede ser muy útil para muchas tareas de PNL debido a la alta precisión en la revelación de distinciones consonantes/vocales/coronales.', 'ar': 'تستكشف هذه الورقة خوارزمية المجموعات الهرمية الانقسامية بناءً على مبدأ الكفاف الإجباري المعروف في علم الأصوات. والغرض من ذلك ذو شقين: لمعرفة ما إذا كان يمكن استخدام مثل هذه الخوارزمية للتصنيف غير الخاضع للإشراف للفونيمات أو الحروف الرسومية في corpora ، والتحقيق فيما إذا كان هذا القيد العام المزعوم ينطبق بالفعل على عدة فئات من السمات المميزة الصوتية. تحقق الخوارزمية دقة عالية جدًا في إعداد غير خاضع للإشراف لاستنتاج تمييز بين حرف ساكن وحرف متحرك ، ولديها أيضًا ميل قوي لاكتشاف الصوتيات الإكليلية بطريقة غير خاضعة للإشراف. ومع ذلك ، فإن الفئات المتبقية لا تتوافق بدقة مع انشقاقات السمات المميزة الصوتية. بينما تقدم النتائج دعمًا مختلطًا فقط لمبدأ محيط إلزامي عالمي ، يمكن أن تكون الخوارزمية مفيدة جدًا للعديد من مهام البرمجة اللغوية العصبية نظرًا للدقة العالية في الكشف عن الفروق الساكنة / حرف العلة / الإكليل.', 'fr': "Cet article explore un algorithme de regroupement hiérarchique divisif basé sur le célèbre principe de contour obligatoire en phonologie. L'objectif est double\xa0: voir si un tel algorithme peut être utilisé pour la classification non supervisée de phonèmes ou de graphèmes dans des corpus, et étudier si cette prétendue contrainte universelle vaut vraiment pour plusieurs classes de caractéristiques phonologiques distinctives. L'algorithme atteint des précisions très élevées dans un environnement non supervisé consistant à déduire une distinction consonne-voyelle, et a également une forte tendance à détecter les phonèmes coronaux de manière non supervisée. Les classes restantes, cependant, ne correspondent pas aussi clairement aux divisions des traits distinctifs phonologiques. Bien que les résultats n'offrent qu'un support mitigé pour un principe universel de contour obligatoire, l'algorithme peut être très utile pour de nombreuses tâches de PNL en raison de la grande précision de la révélation des distinctions consonne/voyelle/coronale.", 'pt': 'Este artigo explora um algoritmo de agrupamento hierárquico divisivo baseado no conhecido Princípio de Contorno Obrigatório em fonologia. O objetivo é duplo: ver se tal algoritmo poderia ser usado para classificação não supervisionada de fonemas ou grafemas em corpora e investigar se essa suposta restrição universal realmente vale para várias classes de traços distintivos fonológicos. O algoritmo atinge acurácias muito altas em uma configuração não supervisionada de inferir uma distinção consoante-vogal, e também tem uma forte tendência a detectar fonemas coronais de maneira não supervisionada. As classes restantes, no entanto, não correspondem tão claramente às divisões de traços distintivos fonológicos. Embora os resultados ofereçam apenas suporte misto para um Princípio de Contorno Obrigatório universal, o algoritmo pode ser muito útil para muitas tarefas de PNL devido à alta precisão em revelar distinções consoante/vogal/coronal.', 'ja': '本論文では、音声学におけるよく知られた義務的等高線原理に基づいた分裂階層クラスタリングアルゴリズムを探求する。目的は2つあります。そのようなアルゴリズムがコーパス内の音素または文法の無制限の分類に使用できるかどうかを調べることと、この意図された普遍的制約が音声学的特徴のいくつかのクラスに本当に適合しているかどうかを調べることです。このアルゴリズムは、子音-母音の区別を推論する無監督の設定で非常に高い精度を達成し、また、無監督の方法で冠状音素を検出する強い傾向を有する。しかし、残りのクラスは、音声学的に特徴的な特徴の分割にきちんと対応していません。結果は、普遍的な義務的等高線原理のための混合されたサポートのみを提供するが、このアルゴリズムは、子音/母音/冠状の区別を明らかにする高精度のため、多くのNLPタスクに非常に有用であり得る。', 'zh': '本文探讨了一种语音学中众所周知的强制等值线原理的分裂聚类算法。 其目重:视其可用于语料库音素若字素之不监分,而论其所谓周制者几类语音也。 其算法于推辅音-元音分无监督之中致其精,而犹有以无监检冠状音素之强。 然其余类与语音独异者,不尽应也。 虽资之以强轮郭,示辅音/元音/冠状以高准确性,其算法有用于众NLP。', 'hi': 'यह पेपर एक विभाजनकारी पदानुक्रमित क्लस्टरिंग एल्गोरिथ्म की पड़ताल करता है जो फोनोलॉजी में प्रसिद्ध अनिवार्य समोच्च सिद्धांत पर आधारित है। उद्देश्य दोगुना है: यह देखने के लिए कि क्या इस तरह के एल्गोरिथ्म का उपयोग कॉर्पोरेट में फोनमेस या ग्राफेम्स के असुरक्षित वर्गीकरण के लिए किया जा सकता है, और यह जांचने के लिए कि क्या यह कथित सार्वभौमिक बाधा वास्तव में ध्वन्यात्मक विशिष्ट विशेषताओं के कई वर्गों के लिए रखती है। एल्गोरिथ्म एक व्यंजन-स्वर भेद का अनुमान लगाने की एक असुरक्षित सेटिंग में बहुत उच्च सटीकता प्राप्त करता है, और एक असुरक्षित फैशन में कोरोनल फोनेम का पता लगाने की एक मजबूत प्रवृत्ति भी है। शेष कक्षाएं, हालांकि, ध्वन्यात्मक विशिष्ट विशेषता विभाजन के लिए बड़े करीने से मेल नहीं खाती हैं। जबकि परिणाम एक सार्वभौमिक अनिवार्य समोच्च सिद्धांत के लिए केवल मिश्रित समर्थन प्रदान करते हैं, एल्गोरिथ्म व्यंजन / स्वर / कोरोनल भेद का खुलासा करने में उच्च सटीकता के कारण कई एनएलपी कार्यों के लिए बहुत उपयोगी हो सकता है।', 'ru': 'В данной статье рассматривается алгоритм иерархической кластеризации, основанный на известном в фонологии принципе обязательного контура. Цель двоякая: посмотреть, может ли такой алгоритм быть использован для неконтролируемой классификации фонем или графем в корпусах, и исследовать, действительно ли это предполагаемое универсальное ограничение имеет несколько классов фонологических отличительных признаков. Алгоритм достигает очень высокой точности в неконтролируемой настройке отличия согласных голосов, а также имеет сильную тенденцию обнаруживать корональные фонемы неконтролируемым образом. Оставшиеся классы, однако, не так аккуратно соответствуют фонологическим отличительным признакам. Хотя результаты предлагают только смешанную поддержку универсального обязательного принципа контура, алгоритм может быть очень полезен для многих задач NLP из-за высокой точности в выявлении согласных/гласных/корональных различий.', 'ga': 'Scrúdaíonn an páipéar seo algartam cnuasaithe ordlathach deighilte atá bunaithe ar an bPrionsabal Comhrian Oibleagáide a bhfuil aithne air sa fhóineolaíocht. Tá dhá chuspóir leis: féachaint an bhféadfaí algartam dá leithéid a úsáid chun fóinéimí nó graiféimí a aicmiú i gcorpora gan mhaoirseacht, agus imscrúdú a dhéanamh an bhfuil an srian uilíoch airbheartaithe seo i ndáiríre do roinnt cineálacha sainghnéithe fóineolaíochta. Baineann an t-algartam beachtas an-ard amach i suíomh gan mhaoirseacht a bhaineann le hidirdhealú guta consain a bhaint amach, agus tá claonadh láidir aige freisin fóinéimí corónacha a bhrath ar bhealach gan mhaoirseacht. Ní fhreagraíonn na haicmí atá fágtha, áfach, chomh néata do scoilteanna sainiúla fóineolaíochta. Cé nach dtugann na torthaí ach tacaíocht mheasctha do Phrionsabal Comhrianta Oibleagáide uilíoch, is féidir leis an algartam a bheith an-úsáideach le haghaidh go leor tascanna NLP mar gheall ar a ardchruinneas maidir le hidirdhealú comhrianta/guta/coróineach a nochtadh.', 'el': 'Η παρούσα εργασία διερευνά έναν διχαστικό ιεραρχικό αλγόριθμο ομαδοποίησης βασισμένο στην γνωστή Αρχή Υποχρεωτικού Περιγράμματος στη φωνολογία. Ο σκοπός είναι διττός: να δούμε αν ένας τέτοιος αλγόριθμος θα μπορούσε να χρησιμοποιηθεί για την χωρίς επίβλεψη ταξινόμηση φωνημάτων ή γραφημάτων σε σώματα, και να διερευνήσουμε αν αυτός ο υποτιθέμενος καθολικός περιορισμός ισχύει πραγματικά για διάφορες κατηγορίες φωνολογικών χαρακτηριστικών. Ο αλγόριθμος επιτυγχάνει πολύ υψηλές ακρίβειες σε ένα περιβάλλον χωρίς επίβλεψη για την εξαγωγή μιας διάκρισης συνήχων-φωνήθων, και έχει επίσης ισχυρή τάση να ανιχνεύει στεφανιαία φωνηματικά χωρίς επίβλεψη. Οι υπόλοιπες τάξεις, ωστόσο, δεν αντιστοιχούν τόσο καθαρά σε διαχωρισμούς φωνολογικών χαρακτηριστικών. Ενώ τα αποτελέσματα προσφέρουν μόνο μικτή υποστήριξη για μια καθολική Υποχρεωτική Αρχή Περιγράμματος, ο αλγόριθμος μπορεί να είναι πολύ χρήσιμος για πολλές εργασίες λόγω της υψηλής ακρίβειας στην αποκάλυψη των συνοφών/φωνήθων/στεφανιαίων διακρίσεων.', 'hu': 'A tanulmány a fonológia jól ismert kötelező kontúr elvén alapuló osztó hierarchikus klaszterezési algoritmust vizsgál. A cél kettős: annak megvizsgálása, hogy egy ilyen algoritmus alkalmazható-e a fonémák vagy grafémák felügyelet nélküli osztályozására corporákban, és annak vizsgálata, hogy ez az állítólagos univerzális korlátozás valóban érvényes-e a fonológiai megkülönböztető jellemzők több osztályára. Az algoritmus nagyon nagy pontosságot ér el egy felügyelet nélküli környezetben a mássalhangzó-magánhangzó megkülönböztetés következtetésére, valamint erős hajlamos arra, hogy felügyelet nélkül felismerje a koronafonémákat. A fennmaradó osztályok azonban nem felelnek meg olyan szépen a fonológiai megkülönböztető jellemzők felosztásának. Míg az eredmények csak vegyes támogatást nyújtanak az univerzális kötelező kontúr elvhez, az algoritmus nagyon hasznos lehet számos NLP feladatnál, mivel nagy pontossággal fedi fel a mássalhangzó/magánhangzó/korona megkülönböztetéseket.', 'ka': 'ეს დოკუმენტი განსხვავებს გაყოფილი იერაქტიკალური კლასტერის ალგორტიმს, რომელიც ფონოლოგიაში უცნობიერი კონტური კონტური პრინციპლის დაბაზიან. მიზეზი ორჯერ იქნება: დავხედოთ თუ ასეთი ალგორიტიმ შეიძლება გამოიყენება ფონოლოგიური განსხვავებული ფონოლოგიური განსხვავებული ფონოლოგიური განსხვავებების განსხვავებულ კლასიფიკაციისთვის თუ არა ეს უნიველური განსხვავ ალგორიტიმა ძალიან დიდი კონონტური განსხვავებაში, რომელიც არ განსხვავებული კონტონტური ფონტურების განსხვავებაში მიიღება, და ასევე აქვს ძალიან რენდენტი, რომელიც კონტურული ფონტურების განსხვავებ მაგრამ დასრულებული კლასები არ კონფოლოგიური განსხვავებული ფონოლოგიური განსხვავებული ფონოლოგიური განსხვავებას. წარმოდგენების შესაძლებლობა მხოლოდ სამყარო მხოლოდ სამყარო სამყარო კონტური პრინციპლისთვის, ალგორიტიმ შეიძლება ძალიან გამოიყენებელია მრავალი NLP დავალებისთვის, რადგან უფრო მართლად', 'it': "Questo articolo esplora un algoritmo di clustering gerarchico divisivo basato sul noto Principio Obbligatorio del Contoro in fonologia. Lo scopo è duplice: vedere se un tale algoritmo potrebbe essere utilizzato per la classificazione non supervisionata di fonemi o grafemi nei corpora, e indagare se questo presunto vincolo universale sia realmente valido per diverse classi di caratteristiche distintive fonologiche. L'algoritmo raggiunge precisione molto elevate in un ambiente non supervisionato di dedurre una distinzione consonante-vocale, e ha anche una forte tendenza a rilevare fonemi coronali in modo non supervisionato. Le classi rimanenti, tuttavia, non corrispondono altrettanto chiaramente alle suddivisioni fonologiche delle caratteristiche distintive. Mentre i risultati offrono solo supporto misto per un principio universale del contorno obbligatorio, l'algoritmo può essere molto utile per molte attività NLP grazie all'elevata precisione nel rivelare distinzioni consonanti/vocali/coronali.", 'lt': 'Šiame dokumente nagrinėjamas dalijamasis hierarchinis klasifikavimo algoritmas, pagrįstas gerai žinomu fonologijos privalomojo apskritimo principu. Tikslas yra dvigubas: patikrinti, ar toks algoritmas galėtų būti naudojamas nekontroliuojamam fonemų ar grafemų klasifikavimui korporoje ir ištirti, ar šis tariamas universalus apribojimas iš tikrųjų taikomas kelioms fonologinių savybių klasėms. Algoritmas pasiekia labai aukštą tikslumą nepastebimoje aplinkoje, nustatant konsonantinį ir vokalinį skirtumą, ir taip pat turi didelę tendenciją nepastebimu būdu nustatyti koroninius fonemes. Remaining classes, however, do not correspond as neatly to phonological distinctive feature splits.  Nors rezultatai teikia tik mišrią paramą universaliam privalomam apskritimo principui, algoritmas gali būti labai naudingas daugeliui NLP užduočių, nes atskleidžiami aukštas tikslumas atskleidžiant konsonantų/vokalų/koroninius skirtumus.', 'kk': 'Бұл қағаз фонологиядағы бөлек иерархиялық кластерлік алгоритмін зерттейді. Мақсатты екі рет: бұл алгоритм корпорадағы телефон не графимдердің шектеу үшін қолданылатын ба, және бұл әлемдік шектеулердің қаншалық фонологиялық қасиеттердің бірнеше классының шектеулерін тексеру үшін қолданылады. Алгоритм консонкт-дыбыс түрлендірімін таңдау үшін өте жоғары дұрыстығын жеткізеді, сондай-ақ короналдық фономдарды таңдау үшін күшті тенденциясы бар. Бірақ қалдырған класстар фонологиялық бөліктерге сәйкес келмейді. Нәтижелер тек жалпы көпшілікті көпшілікті көпшілікті көпшілікті көпшілікті көпшілікті көпшілікті көпшілікті NLP тапсырмаларының алгоритмі өте пайдалы болады.', 'ml': 'ഈ പേപ്പറില്\u200d ഫോണോളജിയിലെ പ്രിന്\u200dസിപ്പിള്\u200d അടിസ്ഥാനത്തില്\u200d വിഭാഗിക്കുന്ന ഹിയറാര്\u200dക്കിക് ആല്\u200dഗോരിതം കണ്ടെത്തുന്ന അതിന്റെ ലക്ഷ്യം രണ്ടായിരിക്കുന്നു: ഇതുപോലുള്ള ഒരു ആല്\u200dഗോരിതം സംരക്ഷിക്കാത്ത ഫോണികളോ ഗ്രാഫീമോ ഉപയോഗിക്കാന്\u200d സാധിക്കുമോ എന്ന് നോക്കാന്\u200d സാധിക്കുന്നതിനായി  സൂക്ഷിച്ചില്ലാത്ത വേര്\u200dപെടുത്തുന്ന ഒരു സ്ഥാനത്തില്\u200d ആല്\u200dഗോരിതം വളരെ കൂടുതല്\u200d ശ്രദ്ധ പ്രാപിക്കുന്നുണ്ട്. കോര്\u200dണോണ്\u200d ഫോണികള്\u200d കണ്ടുപിടിക്കാന്\u200d ശ ശേഷിച്ചിരിക്കുന്ന ക്ലാസുകള്\u200d, ഫോളോളജിക്കല്\u200d വ്യത്യസ്തമായ വിഭാഗങ്ങള്\u200dക്കുള്ള പ്രത്യേകങ്ങള്\u200dക്ക് മാത് ഒരു പൊതുവായ ബബ്ലിറ്ററി കോണ്\u200dട്ടോര്\u200d പ്രിന്\u200dസിപ്പിളിന് മാത്രമേ ഇതിന്\u200dറെ ഫലങ്ങള്\u200d മികച്ച പിന്തുണയ്ക്കുന്നുള്ളൂ, എന്\u200dഎല്\u200dപി ജോലികള്\u200dക്ക് വളരെ ഉപയോഗമുള', 'mk': 'This paper explores a divisive hierarchical clustering algorithm based on the well-known Obligatory Contour Principle in phonology.  The purpose is twofold: to see if such an algorithm could be used for unsupervised classification of phonemes or graphemes in corpora, and to investigate whether this purported universal constraint really holds for several classes of phonological distinctive features.  Алгоритмот постигнува многу високи точности во ненадгледувано поставување на инференција на разлика консорентно-гласна, и исто така има силна тенденција да детектира коронални телефони на ненадгледуван начин. Останатите класи, сепак, не одговараат толку добро на фонолошките дискриптивни делови на карактеристиките. И покрај тоа што резултатите нудат само мешана поддршка за универзалниот обврзан принцип на контур, алгоритмот може да биде многу корисен за многу НЛП задачи поради високата прецизност во откривањето на разликите на конзонантот/главата/короната.', 'mt': 'Dan id-dokument jesplora algoritmu ta’ raggruppament ġerarkiku diviżiv ibbażat fuq il-Prinċipju Obbligatorju ta’ Kontour magħruf sew fil-fonoloġija. L-għan huwa doppju: li wieħed jara jekk algoritmu bħal dan jistax jintuża għal klassifikazzjoni mhux sorveljata ta’ fonemijiet jew grafemijiet fil-korpra, u li jiġi investigat jekk din ir-restrizzjoni universali supposta tassew tapplikax għal diversi klassijiet ta’ karatteristiċi distintivi fonoloġiċi. The algorithm achieves very high accuracies in an unsupervised setting of inferring a consonant-vowel distinction, and also has a strong tendency to detect coronal phonemes in an unsupervised fashion.  Il-klassijiet li jifdal, madankollu, ma jikkorrispondux b’mod tajjeb għall-qsim tal-karatteristiċi distintivi fonoloġiċi. Filwaqt li r-riżultati joffru biss appoġġ imħallat għal Prinċipju Universali Obbligatorju ta’ Kontorn, l-algoritmu jista’ jkun utli ħafna għal ħafna kompiti NLP minħabba l-preċiżjoni għolja fl-iżvelar ta’ distinzjonijiet konsonanti/vowel/koronali.', 'ms': 'This paper explores a divisive hierarchical clustering algorithm based on the well-known Obligatory Contour Principle in phonology.  Tujuan adalah dua kali: untuk melihat sama ada algoritma tersebut boleh digunakan untuk klasifikasi fonem atau grafem tidak diawasi dalam corpora, dan untuk menyelidiki sama ada kewajiban universal yang diduga ini benar-benar memegang untuk beberapa kelas ciri-ciri fonologi yang berbeza. Algoritma mencapai ketepatan yang sangat tinggi dalam tetapan tidak diawasi untuk menyimpulkan perbezaan konsonan-vowel, dan juga mempunyai kecenderungan kuat untuk mengesan fonem koronal dalam cara tidak diawasi. Kelas yang tersisa, bagaimanapun, tidak sepadan dengan pemisahan ciri-ciri berbeza fonologi. Walaupun keputusan hanya menawarkan sokongan campuran untuk Prinsip Contour Obligator universal, algoritma boleh sangat berguna untuk banyak tugas NLP disebabkan keputusan tinggi dalam mengungkap perbezaan consonant/vowel/coronal.', 'mn': 'Энэ цаас фонологи дээр нэрлэж байгаа хамааралтын алгоритмыг судалдаг. Хоёр дахь зорилго нь: ийм алгоритм нь корпоратын телефон эсвэл графикийн хуваалцааны тулд хэрэглэгдэж болох эсэхийг харах, мөн энэ цэвэрлэгдсэн ертөнцийн хязгаар фонологикийн өөр өөр хэлбэрүүдийн хуваалцааны тулд байдаг эсэхийг судалж болно. Алгоритм нь үнэхээр өндөр тохиромжтой байдлыг баталгаагүй хэмжээнд хүргэдэг. Мөн мөн дамжуулагүй хэлбэрээр корон утаснуудыг олж мэдэх хүчтэй байдаг. Гэхдээ үлдсэн хичээл фонологикийн ялгаатай хуваагдмалтай адилхан байхгүй. Үүний үр дүнд зөвхөн универсал төлөөлөгчийн төлөөлөгчийн тусламжтай тусламжтай тусламжтай байдаг ч, алгоритм нь олон NLP даалгавруудын тулд маш ашигтай байж болно.', 'no': 'Denne papiret utforskar ein delvis hierarkisk klasseringsalgoritme basert på den godt kjente tilfeldige kontinueringsprinsiplen i fonologikk. Målet er to gamle: å sjå om denne algoritmen kan brukast for ikkje-spesifisert klassifikasjon av telefoner eller grafen i korpora, og for å undersøke om denne ønskte universelle begrensningen verkeleg inneheld for fleire klasser med fonologiske spesifiserte funksjonar. Algoritmen oppnår svært høg nøyaktighet i eit usikkerte innstillinga for å få ein konsonart-tålsdistikasjon, og også har ein sterk tendens for å finna koronale foner på ein usikkerte måte. Gjennomslag klasser er imidlertid ikkje tilsvarande så nødvendig til fonologiske spesifiserte funksjonar. Mens resultatet gjev berre blandet støtte for ein universelt tilsvarende kontinueringsprinsipl, kan algoritmen vera veldig nyttig for mange NLP-oppgåver på grunn av høy nøyaktighet i å opna konsonent/vowel/koronale forskjeller.', 'ro': 'Această lucrare explorează un algoritm de clusterizare ierarhică divizivă bazat pe binecunoscutul Principiu Obligatoriu al Contorului în fonologie. Scopul este dublu: să vedem dacă un astfel de algoritm ar putea fi folosit pentru clasificarea nesupravegheată a fonemelor sau grafemelor în corpore și să investigăm dacă această presupusă constrângere universală este într-adevăr valabilă pentru mai multe clase de caracteristici fonologice distinctive. Algoritmul atinge acurateți foarte mari într-un cadru nesupravegheat de deducere a unei distincții consonante-vocale și are, de asemenea, o tendință puternică de a detecta fonemele coronale într-un mod nesupravegheat. Cu toate acestea, clasele rămase nu corespund la fel de bine divizărilor caracteristicilor distinctive fonologice. În timp ce rezultatele oferă doar suport mixt pentru un principiu universal de contor obligatoriu, algoritmul poate fi foarte util pentru multe sarcini PNL datorită acurateții ridicate în dezvăluirea distincțiilor consonante/vocale/coronale.', 'pl': 'Niniejszy artykuł bada podziałowy hierarchiczny algorytm klastrowania oparty na dobrze znanej zasadzie obowiązkowego konturu w fonologii. Cel jest dwojaki: sprawdzenie, czy taki algorytm może być wykorzystywany do klasyfikacji fonemów lub grafemów w korpusach bez nadzoru, oraz zbadanie, czy to rzekome uniwersalne ograniczenie rzeczywiście obowiązuje dla kilku klas fonologicznych cech charakterystycznych. Algorytm osiąga bardzo wysoką dokładność w nienadzorowanym ustawieniu wnioskowania rozróżnienia spółgłoski-samogłoski, a także ma silną tendencję do wykrywania fonemów koronalnych w sposób bez nadzoru. Pozostałe klasy jednak nie odpowiadają tak dokładnie fonologicznym podziałom cech charakterystycznych. Podczas gdy wyniki oferują jedynie mieszane wsparcie dla uniwersalnej zasady obowiązkowego konturu, algorytm ten może być bardzo przydatny dla wielu zadań NLP ze względu na wysoką dokładność w ujawnianiu różnic spółgłoskowych/koronalnych.', 'sr': 'Ovaj papir istražuje podijeljeni hijerarhijski algoritam skupljanja na osnovu poznatog prinsipa obaveznog kontora u fonologiji. Svrha je dvostruka: da vidim da li se takav algoritam može koristiti za neodređenu klasifikaciju telefona ili grafeja u korpori, i da istražuje da li ova potvrđena univerzalna ograničenja stvarno drži za nekoliko klasa fonoloških različitih karakteristika. Алгоритм постига веома висока точност у неподкрепљеним постављеним постављањем разлика консонсента-повука, а также има јаку тенденцију за откривање короналних телефонова на неподкрепљеном моду. Međutim, ostale klase ne odgovaraju kao čisto fonološkim različitim delovima. Iako rezultati nude samo pomešanu podršku univerzalnog obligatornog kontura principa, algoritam može biti vrlo korisan za mnoge NLP zadatke zbog visoke tačnosti u otkrivanju konsonentnih/povraćanja/koronalnih razlika.', 'si': 'මේ පත්තර පරීක්ෂණය කරනවා විශේෂ අයිරිකාශික අයිරිකාශික අල්ගෝරිතම් එක්ක හොඳට දන්න පුළුවන් ප්\u200dරධාන ප්\u200dර අරමුණ දෙකක් තියෙන්නේ: මේ අල්ගෝරිතම් එකක් පාවිච්චි කරන්න පුළුවන් නැත්නම් කොර්පෝරාවේ ෆෝන්මියෝ නැත්නම් ග්\u200dරාෆීම් වලින් විශේෂ කරණය ඇල්ගෝරිතම් ගොඩක් උත්සහ සිද්ධ විශේෂයක් ලැබෙනවා, සම්පූර්ණ විශේෂ විශේෂ විශේෂයක් අවස්ථානයක් නැති විශේෂ කරලා තියෙනවා. නමුත්, ඉන්න විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විශ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරධානයක් විතරයි සාමාන්\u200dය සම්බන්ධතාවක් විතරයි, ඇල්ගෝරිතම් ප්\u200dරතිප්\u200dරධානයක් විතරයි NLP වැඩේ ගොඩක් වැඩේ වැ', 'so': 'Qoraalkan wuxuu ka baaraandegaa algorithm kala qaybsan oo ku saleysan qofka la yaqaan waajibaadka ku qoran qoraalka qofka nolojiga. Ujeedadu waa laba jibbaar: si aan u arko in qoraal caynkaas ah looga isticmaali karo fasalka telefoonka ama sawiraadka aan la sawirin karo iyo in aan baarito in qasabkaas caalamiga ah uu ku haysto kooxo kala duwan oo kala duduwan. Algoritku wuxuu gaadhaa saxda aad u sarreeya, si a an hagaagsanayn oo uu u dhibo kala duwan nidaamka, sidoo kale waxay leedahay qaab aad u adag in uu sawiro sawirro ah oo aan la ilaalin. Si kastaba ha ahaatee fasalka hadhay uma dhigin inay si fiican u kala duwan yihiin farsamada. Intii ay resultadu u fidiyaan kaalmo isku qasan oo kaliya oo ay u fidiyaan qasabka madaxda caalamiga ah, algoritmka ayaa aad u faa’iido u leh shaqaalaha NLP, sababtoo ah saxda aad u sareeya si ay u muuqato consoconsole/vowel/koox kala duwan.', 'sv': 'Denna uppsats undersöker en splittrande hierarkisk klustringsalgoritm baserad på den välkända Obligatoriska konturprincipen inom fonologi. Syftet är dubbelt: att se om en sådan algoritm kan användas för obevakad klassificering av fonem eller grafem i corpora, och att undersöka om denna påstådda universella begränsning verkligen gäller för flera klasser av fonologiska särdrag. Algoritmen uppnår mycket hög noggrannhet i en oövervakad miljö för att härleda en konsonant-vokal skillnad, och har också en stark tendens att upptäcka koronala fonemer på ett oövervakat sätt. Resterande klasser motsvarar emellertid inte lika tydligt splittringar av fonologiska särdrag. Medan resultaten endast erbjuder blandat stöd för en universell Obligatorisk konturprincip, kan algoritmen vara mycket användbar för många NLP-uppgifter på grund av den höga noggrannheten när det gäller att avslöja konsonant/vokal/koronal distinktion.', 'ta': 'இந்த காகிதத்தில் போனியோஜியில் தெரியும் அடிப்படையில் ஒரு பிரிவாக்கப்பட்ட hierarchical clustering algorithm அடிப்படையில் தேடுகிறது. இலக்கு இருமடங்காகும்: இது போன்ற அல்லது வரைப்படங்களை பாதுகாப்பாக்கப்படாத வகுப்பாட்டிற்கு பயன்படுத்தப்பட்டுள்ளதா என்பதை பார்க்கவும், மற்றும் இந்த வரையறுக்கப்பட்ட பொதுவான பாதுகாப்பாக்கப்படாத அமைப்பில் மிகவும் உயர்ந்த சரிவுகள் பெறுகிறது, ஒரு கூட்டுப்பொருள் வேறுபாட்டை பாதுகாப்பாக்கப்படாத அமைப்பில், மற்றும் கோர்க மீதிய வகுப்பு முடிவுகள் ஒரு பொதுவான ஒப்புக்கொள்ளும் பொருளுக்கு மட்டும் கலப்பு ஆதரவு வழங்கும் போது, பல NLP பணிகளுக்கு மிகவும் பயனுள்ளது, ஏனென்றால் அதிக சரிபார்வையா', 'ur': 'This paper explores a divisive hierarchical clustering algorithm based on the well known Obligatory Contour Principle in phonology. مطابق دو بار ہے: دیکھنے کے لئے یہ الگوریتم کو کورپورا میں فونیوں یا گرافیموں کے غیرقابل تشکیل کے لئے استعمال کر سکتا ہے یا نہیں، اور تحقیق کرنے کے لئے کہ کیا یہ پاک ارومیل محدودیت واقعی چند کلاس فونیولوژیکوں کے متفاوتوں کے لئے ہے. الگوریتم بہت بالا دقیق پہنچ رہا ہے ایک غیر قابل تفریق کے ذریعہ سے، اور اس طرح ایک غیر قابل تفریق کے ذریعہ کورونل فونیموں کو پہچان سکتا ہے۔ لیکن باقی کلاس کے ساتھ فانولوژیکی مختلف فرقش کے مطابق پاکیزہ نہیں ہیں۔ اگرچہ نتائج صرف ایک عمومی قابل تعلق کے قابل تعلق کے لئے مختلف پشتیبانی پیش کرتی ہیں، الگوریتم بہت سے NLP کاموں کے لئے بہت فائدہ اٹھائے جاتے ہیں، اس کے باعث بالائی دقیق بات کی وجہ سے کہ مشرکین/ووئل/کرونٹی اختلاف ظاہر کرتی ہے.', 'uz': "Bu qogʻoz fonologiyani aniqlangan obʼektlarning asosida ajratilgan hierarchik algoritni aniqlaydi. Masalan ikki marta ko'p: Bunday algoritni ko'rsatish uchun qo'llanmagan foydalanuvchi yoki grammatika sifatida foydalanishini ko'rsatish mumkin, va bu ko'paytirilgan umumiy qandaydir fonologik bir necha sinfni boshqarish imkoniyatlariga ega bo'lishi mumkin. Algoritga qo'llanilmaydigan xavfsizlik darajada, konsoliy vowlarni ajratishda juda juda katta haqiqiqatga ega bo'ladi, va bu holatda qo'llanmagan foydalanuvchilarni ko'rsatish juda katta tartib bor. Keyingi sinfga oʻtish mumkin, fonologik alohida foydalanish imkoniyatlariga mos kelmaydi. @ info: whatsthis", 'vi': 'Tờ giấy này nghiên cứu một thuật toán phân cấp lập lập lập dựa trên công thức ràng buộc nổi tiếng trong ngôn ngữ. Mục đích là kép: để xem liệu thuật to án này có thể được dùng để phân loại các niên ngữ điện hay các hình nhân không được giám sát trong cơ thể, và để tìm hiểu xem liệu điều đó có thực sự phù hợp với các loại đặc biệt ngôn ngữ hay nghệ không. Thuật to án đạt đến độ chính xác rất cao trong một điều kiện không được giám sát nhằm nhận ra sự phân biệt âm âm đảo âm phụ, và cũng có một xu hướng mạnh mẽ để phát hiện âm âm âm câm theo một cách không được giám sát. Tuy nhiên, các lớp còn lại không tương ứng rõ ràng với các khớp đặc trưng từ âm. Mặc dù kết quả chỉ hỗ trợ cho một Công ty Luôn-Sát-hoá phổ biến, nhưng thuật to án có thể rất hữu dụng cho nhiều công việc Nchọc (NLP) vì độ chính xác cao trong việc vạch rõ ràng phụ-vohàn/coronal.', 'hr': 'Ovaj papir istražuje dijeljiv hijerarhički algoritam skupljanja na temelju poznatog prinsipa obaveznog kontura u fonologiji. Svrha je dvostruka: vidjeti da li se takav algoritam može koristiti za neodređenu klasifikaciju telefona ili grafeja u tijelu i istražiti da li se ova potvrđena univerzalna ograničenja stvarno drži za nekoliko klasa fonoloških različitih karakteristika. Algoritam postiže vrlo visoke preciznosti u neodređenom stanju uvođenja određenog izraza, a također ima jaku tendenciju otkriti koronalne telefone na neodređenom načinu. Međutim, ostale klase ne odgovaraju kao čisto fonološkim različitim dijelovima. Iako rezultati nude samo pomiješanu podršku univerzalnog obveznog kontura principa, algoritam može biti vrlo korisan za mnoge zadatke NLP-a zbog visoke preciznosti u otkrivanju konsonentnih/povraćanja/koronalnih razlika.', 'nl': 'Dit artikel onderzoekt een divisief hiërarchisch clustering algoritme gebaseerd op het bekende Obligatory Contour Principe in de fonologie. Het doel is tweeledig: te kijken of een dergelijk algoritme kan worden gebruikt voor onbeheerde classificatie van fonemen of grafemen in corpora, en te onderzoeken of deze vermeende universele beperking werkelijk geldt voor verschillende klassen fonologische onderscheidende kenmerken. Het algoritme bereikt zeer hoge nauwkeurigheiden in een niet-begeleide setting van het afleiden van een consonant-klinker onderscheid, en heeft ook een sterke neiging om coronale fonemen op een niet-begeleide manier te detecteren. Resterende klassen komen echter niet zo netjes overeen met fonologische onderscheidende kenmerken splitsen. Hoewel de resultaten slechts gemengde ondersteuning bieden voor een universeel Obligatory Contour Principe, kan het algoritme zeer nuttig zijn voor veel NLP taken vanwege de hoge nauwkeurigheid bij het onthullen van consonant/klinker/coronale onderscheidingen.', 'da': 'Denne artikel udforsker en splittende hierarkisk klyngealgoritme baseret på det velkendte Obligatoriske Konturprincip i fonologi. Formålet er dobbelt: at se, om en sådan algoritme kunne bruges til ukontrolleret klassificering af fonemer eller grafer i corpora, og at undersøge, om denne påståede universelle begrænsning virkelig gælder for flere klasser af fonologiske karakteristika. Algoritmen opnår meget høje nøjagtigheder i en ikke-overvåget indstilling af at udlede en konsonant-vokal skelnen, og har også en stærk tendens til at opdage koronale fonemer på en ikke-overvåget måde. De resterende klasser svarer imidlertid ikke så godt til fonologiske særpræg. Selvom resultaterne kun giver blandet understøttelse af et universelt Obligatorisk Konturprincip, kan algoritmen være meget nyttig til mange NLP-opgaver på grund af den høje nøjagtighed i afsløring af konsonant/vokal/koronal skelninger.', 'bg': 'Настоящата статия изследва разделителен йерархичен алгоритъм за клъстериране, базиран на добре познатия принцип на задължителен контур в фонологията. Целта е две: да се види дали такъв алгоритъм може да се използва за ненадзорно класифициране на фонеми или графеми в корпуси и да се проучи дали това предполагаемо универсално ограничение действително важи за няколко класа фонологични отличителни черти. Алгоритъмът постига много високи точности в ненаблюдавана обстановка за извеждане на съгласно-гласно разграничение, а също така има силна тенденция да открива коронални фонеми по ненаблюдаван начин. Останалите класове обаче не съответстват толкова ясно на разделянето на фонологичните отличителни черти. Въпреки че резултатите предлагат само смесена подкрепа за универсален принцип на задължителен контур, алгоритъмът може да бъде много полезен за много задачи на НЛП поради високата точност при разкриване на съгласни/гласни/коронални различия.', 'de': 'Diese Arbeit untersucht einen divisiven hierarchischen Clustering-Algorithmus basierend auf dem bekannten Obligatory Contour Principle in der Phonologie. Der Zweck ist zweierlei: zu sehen, ob ein solcher Algorithmus für die unbeaufsichtigte Klassifizierung von Phonemen oder Graphen in Korpora verwendet werden könnte, und zu untersuchen, ob diese angebliche universelle Bedingung tatsächlich für mehrere Klassen phonologischer Unterscheidungsmerkmale gilt. Der Algorithmus erreicht sehr hohe Genauigkeiten in einer unbeaufsichtigten Umgebung der Ableitung einer Konsonant-Vokal-Unterscheidung und hat auch eine starke Tendenz, koronale Phoneme unbeaufsichtigt zu erkennen. Die verbleibenden Klassen entsprechen jedoch nicht so sauber phonologischen Unterscheidungsmerkmalen. Während die Ergebnisse nur gemischte Unterstützung für ein universelles Obligatory Contour Principle bieten, kann der Algorithmus aufgrund der hohen Genauigkeit bei der Aufdeckung von Konsonant/Vokal/Koronal Unterscheidungen für viele NLP-Aufgaben sehr nützlich sein.', 'id': 'Kertas ini mengeksplorasi algoritma berkumpul hierarkis divisif berdasarkan Prinsip Obligatory Contour yang terkenal dalam fonologi. Tujuan adalah dua kali: untuk melihat apakah algoritma seperti itu dapat digunakan untuk klasifikasi tidak diawasi dari fonem atau grafem dalam corpora, dan untuk menyelidiki apakah batasan universal yang diduga ini benar-benar memegang untuk beberapa kelas karakteristik fonologi yang berbeda. Algoritma mencapai akurasi yang sangat tinggi dalam pengaturan yang tidak diawasi menyimpulkan perbedaan konsonan-vowel, dan juga memiliki kecenderungan yang kuat untuk mendeteksi fonem koronal dalam cara yang tidak diawasi. Kelas yang tersisa, bagaimanapun, tidak sesuai dengan pemisahan karakteristik fonologis. Sementara hasilnya hanya menawarkan dukungan campuran untuk Prinsip Contour Obligator universal, algoritma dapat sangat berguna untuk banyak tugas NLP karena akurasi tinggi dalam mengungkap perbedaan konsonan/vowel/koronal.', 'sw': 'Makala hii inagundua algorithi inayotengeneza mifano inayotumika kwa kutumia msingi maarufu wa Ubeba Mkuu katika simu za mkononi. The purpose is twofold: to see if such an algorithm could be used for unsupervised classification of phonemes or graphemes in corpora, and to investigate whether this purported universal constraint really holds for several classes of phonological distinctive features.  Ualgorithi huo unafanikiwa ukweli mkubwa katika mazingira yasiyo na uhakika wa kuathiri utofauti wa kiasi kikubwa, na pia in a tendo kubwa la kutambua simu za kiungo kwa namna isiyo na uhakika. Kubaki darasa, hata hivyo, hawalinganishwi kama mapambano ya utaalamu wa kifolojia. Wakati matokeo hayo yanatoa msaada mchanganyiko tu kwa Mkuu wa Mbunge wa Umoja wa Ulinzani, utaratibu huu unaweza kuwa na ufanisi mkubwa kwa kazi nyingi za NLP kutokana na ukweli mkubwa wa kuonyesha muungano wa kondoome/ahali/tofauti za kiungo.', 'ko': '본고는 음운학에서 유명한 강제 윤곽 원리를 바탕으로 하는 분열 차원 분류 알고리즘을 탐구했다.그 목적은 두 가지가 있다. 첫째, 이런 알고리즘이 어료 라이브러리에서 음소나 자소의 무감독 분류에 사용될 수 있는지, 둘째, 이른바 보편적인 제약이 몇 가지 음성 특징에 실제로 적용되는지 연구하는 것이다.이 알고리즘은 자음-모음의 차이를 추정하는 무감독 환경에서 매우 높은 정확도를 실현했고 무감독 방식으로 관상음소를 검출하는 강렬한 경향을 가지고 있다.그러나 나머지 유형은 음성 특징 분열처럼 가지런히 대응하지 않는다.결과는 통용되는 강제 윤곽 원칙에 대해 혼합 지원을 제공했지만 이 알고리즘은 자음/모음/관상어의 차이를 밝히는 데 비교적 높은 정확성을 가지기 때문에 많은 NLP 임무에 매우 유용하다.', 'tr': 'Bu kagyz faýllaryň üstünde bilinen Jaňry Gaýragçylyk prinsipinden daýanýan bir iýerarhiýa goýragçylyk algoritmini keşfetýär. Mazmuny ikinji gezek: şu ýaly algoritmus corporadaky telefonlaryň ýa-da grafikleriň klasifikasyny üçin ullanyp bilmeýändigini we bu süýtgetmek üçin ullanyp bilmeýändigini soramak üçin. Algoritmus konson-sesi üýtgetmek üçin gaty ýokary taýýarlançylyga ýetip bilýär we munuň üçin koronal fonomolary tassyklanmayan şekilde ýokary ýokary bar. Ýöne kalan synplar fonolojik aýratynyň aýratyny ýaly täb etmeýär. netijeler sadece uniwersaly halkara gatnaşma prinsiple üçin karışyk destekleri teklip edýän bolsa, algoritmus NLP işleri üçin ýokary dogrylygyna görkezilýän/ýuwaş/korunlyk üýtgeşmeleri üçin örän faydaly bolup biler.', 'fa': 'این کاغذ یک الگوریتم تقسیم گروه گروه گروه تقسیم را بر اساس پرینسپول قانونی معروف در فونولوژی تحقیق می کند. هدف دو برابر است: تا ببینیم آیا این الگوریتم می\u200cتواند برای برنامه\u200cگذاری تلفن\u200cها یا گراف\u200cها در شرکت استفاده شود، و تا تحقیق کند که آیا این محدودیت جهانی\u200cشناسی واقعا برای چندین کلاس ویژه\u200cهای متفاوت فون\u200cشناسی دارد. الگوریتم دقیقات بسیار بالا در یک تنظیمات غیرقابل تحریک از تفاوت صوتی که مشترک می باشد رسیده است، و همچنین یک تنظیمات قوی برای شناسایی تلفن\u200cهای کورنولی در یک حالت غیرقابل تحریک شده است. ولی کلاس\u200cهای باقی مانده، به اندازه پاکیزه\u200cای با ویژه\u200cهای متفاوت فونیولوژیکی مرتبط نمی\u200cشوند. در حالی که نتیجه\u200cها تنها پشتیبانی مختلف برای یک پرنسیپل قانونی جهانی پیشنهاد می\u200cدهند، الگوریتم می\u200cتواند برای بسیاری از کارهای NLP مفید باشد، به دلیل دقیق بالا در آشکار تفاوت\u200cهای مشترک/راهنمایی/کورونی.', 'hy': 'Այս հոդվածը ուսումնասիրում է բաժանող հիերարխիկ խմբավորումների ալգորիթմ, որը հիմնված է ֆոնոլոգիայի մեջ հայտնի պարտադիր կոնտուրի սկզբունքի վրա: Նպատակն երկու է. տեսնել, թե արդյոք այդպիսի ալգորիթմ կարող է օգտագործվել կոպորայի ֆոնեմների կամ գրաֆեմների անվերահսկված դասակարգման համար, և ուսումնասիրել, արդյոք այս ենթադրված համընդհանուր սահմանափակումները իրականում պահպանվում են ֆոնոլոգիական առանձնահատկությունների մի քանի The algorithm achieves very high accuracies in an unsupervised setting of inferring a consonant-vowel distinction, and also has a strong tendency to detect coronal phonemes in an unsupervised fashion.  Այնուամենայնիվ, մնացած դասերը չեն համապատասխանում ֆոնոլոգիական առանձնահատկությունների բաժանմաններին: Մինչդեռ արդյունքները միայն խառնված աջակցություն են առաջարկում համընդհանուր պարտադիր հատվածաշրջանի սկզբունքի համար, ալգորիթմը կարող է շատ օգտակար լինել շատ ՆԼՊ-ի առաջադրանքների համար, քանի որ բարձր ճշգրտությունը բացահայտում է կոնսոնտ, խոսք և', 'af': "Hierdie papier ondersoek 'n deelde hierarkies klasteringsalgoritme gebaseer op die wel bekende ondersoekte kontinuersprinsipel in fonologie. Die doel is twee maal: om te sien of sodanige 'n algoritme kan gebruik word vir ononderwerpende klasifikasie van fonemes of grafies in korpora, en om te ondersoek of hierdie uitgevoerde universele beperking regtig hou vir verskeie klasse van fonologiese eienskaplike funksies. Die algoritme bereik baie hoë akkurasies in 'n onverondersteunde instelling van 'n konsonant-voel-uitdeling te verkondig, en ook het 'n sterk tendensie om koronale fonemes in 'n onverondersteunde manier te vind. Maar oorblywende klasse, moet nie so goed ooreenstem na fonologiese eienskaplike funksie splitting nie. Alhoewel die resultate slegs gemengde ondersteuning vir 'n universele verpligtige kontinuerlike prinsipel aanbied, kan die algoritme baie nuttig wees vir baie NLP-opdragte vanweë die hoë presisie in die openbaar van konsonent/voel/koronale verskilte.", 'az': 'Bu kağıt fonologiyada bilinmiş müəyyən bir hiyerarşik clustering algoritmi təşkil edir. Məqsəd ikiqatdır: bu algoritm korporada telefon və grafümlərin müəyyən edilməmiş klasifikasyonun istifadə edilməsi və bu təsdiqlənmiş üniversal müəyyən edilməsi həqiqətən də fonolojik müəyyən qismətlərin çoxluğu üçün istifadə edilməsi mümkündür. Algoritimin çox yüksək düzgünlükləri, konsantlı-səslə fərqlənmək üçün çox yüksək düzgünlükləri başa düşər, həmçin in də koronal fonomeləri gözləmək üçün çox qüvvətli bir təsiri var. Ancaq qalan sınıflar fonolojik müxtəlif fərqli parçalara uyğun olmaz. Sonuçlar yalnız üniversal müvəffəqiyyətli Contour Principli üçün karışıq dəstək təklif edərkən, algoritm çox NLP işlərinə çox faydalı olar ki, konsonent/vowel/coronal ayrılıqlarını göstərmək üçün yüksək doğruluğu üzündən.', 'sq': 'Ky artikull eksploron një algoritëm ndarës hierarkik të grupimit bazuar në Principin e Obligatory Contour të njohur në fonologji. Qëllimi është i dyfishtë: të shohim nëse një algoritëm i tillë mund të përdoret për klasifikimin e pa mbikqyrur të fonemeve apo grafimeve në corpora dhe të hetojmë nëse kjo kufizim universal e pretenduar vërtet mban për disa klasa të karakteristikave fonologjike të veçanta. Algoritmi arrin saktësi shumë të larta në një ambient të pazgjidhur për të përfshirë një dallim konsonant-vowel, dhe gjithashtu ka një tendencë të fortë për të zbuluar telefonema koronale në një mënyrë të pazgjidhur. Klasat e mbetura, megjithatë, nuk korrespondojnë si të rregullta me ndarjet fonologjike të veçanta. Ndërsa rezultatet ofrojnë vetëm mbështetje të përzier për një Princip Universal Obligator Contour, algoritmi mund të jetë shumë i dobishëm për shumë detyra NLP për shkak të saktësisë së lartë në zbulimin e dallimeve konsonante/vowel/koronal.', 'am': 'ይህ ገጽ በፎሎጂ በሚታወቀው የባሕላዊ ግንኙነት የፊንሎጂ ጉዳይ ላይ የተለየ አፍሪካዊ አሌጎርቲን ይፈልጋል፡፡ ጉዳዩ ሁለት እጥፍ ነው፤ እንደዚህ ያለ አልጎሪም የፎፎፎች ወይም የግራሜቶችን መግለጫ ለመጠቀም የሚችል እንደ ሆነ ማየት፣ ይህም አቀማሚ ግንኙነት የፎሎጂ ግንኙነት ለብዙዎቹ የፊሎጂ ግንኙነት መቆጣጠር እንደሆነ እና ለመጠይቅ ነው፡፡ አሌጎሪም በተጠበቀው የስእላቱን መለያየት በመቀነስ እጅግ የበረታች እርግጠኛ አግኝቷል፤ ደግሞም የስልክ ፎፎችን ለማግኘት ኃይለኛ ነው፡፡ ምንም እንኳን በግራ ያሉ ክፍሎች ግን ለፎሎጂ የተለየ የፊሎጂ ጥያቄ ጥያቄ አይተካከሉም፡፡ ፍጥረቶቹ ለዓለምአቀፍ ባለስብሰባዊ ኮንትሮር ፕሪንቨር ብቻ የተቀላቀሉ ድጋፍ ሲያቀርቡ፣ አሌጎርቲም ለብዙ NLP ስርዓቶች ከፍተኛ ትርክት ምክንያት የቆንጆኒው/vowel/koronal ልዩነት በማሳየት በጣም ይጠቅማል፡፡', 'cs': 'Tento článek zkoumá algoritmus dělitelného hierarchického shlukování založený na známém principu povinného konturu ve fonologii. Účel je dvojí: zjistit, zda by takový algoritmus mohl být použit pro klasifikaci fonémů nebo grafemů v korpusech bez dohledu, a zjistit, zda toto údajné univerzální omezení skutečně platí pro několik tříd fonologických charakteristických rysů. Algoritmus dosahuje velmi vysokých přesností v bez dozoru nastavení odvození rozlišení souhlásky a samohlásky a má také silnou tendenci detekovat koronální fonémy bez dozoru. Zbývající třídy však tak úhledně neodpovídají fonologickým rozdělením charakteristických rysů. Zatímco výsledky nabízejí pouze smíšenou podporu univerzálního principu Obligatory Contour, algoritmus může být velmi užitečný pro mnoho NLP úloh díky vysoké přesnosti při odhalování souhlásek/samohlásek/koronálních rozlišení.', 'ca': "Aquest article explora un algoritme divisiu d'agrupament jeràrquic basat en el conegut Principi de Contorn Obligatori en fonologia. El propòsit és doble: veure si un algoritme així podria ser utilitzat per la classificació no supervisada de fonemes o gràfems a la corpora, i investigar si aquesta suposada restricció universal realment es manté per diverses classes de característiques fonològices distintives. L'algoritme aconsegueix moltes precisions en un entorn sense supervisió de deduir una distinció consonant-vowel, i també té una forta tendència a detectar fonemes coronals d'una manera sense supervisió. Remaining classes, however, do not correspond as neatly to phonological distinctive feature splits.  Mentre que els resultats només ofereixen suport mixte a un Principi Universal de Contorn Obligatori, l'algoritme pot ser molt útil per moltes tasques de NLP, degut a la gran precisió en revelar distincions consonant/vowel/coronal.", 'bn': 'এই পত্রিকাটি ফোনোজিয়ার ভিত্তিতে পরিচিত অস্বীকারের প্রধানমন্ত্রীর ভিত্তিতে একটি বিভক্ত হিয়ারারাক্কিল ক্লোরিদম ব উদ্দেশ্য হচ্ছে দুইবার: দেখতে পারার জন্য এই ধরনের অ্যালগরিদম কি কোর্পোরায় অরক্ষিত ফোন বা গ্রাফিম ব্যবহার করা যাবে না, আর তদন্ত করতে পারে যে এই উদ্দেশ্য বিশ্ববিদ্যালয়ের নিয় The algorithm achieves very high accuracies in an unsupervised setting of inferring a consonant-vowel distinction, and also has a strong tendency to detect coronal phonemes in an unsupervised fashion.  তবে শ্রেণীর মধ্যে থাকা ক্লাসের সাথে ফোনোলজিক্যাল বৈচিত্র্যময় বিভিন্ন বৈশিষ্ট্যের সাথে সাথে যোগ দ যদিও ফলাফল শুধুমাত্র একটি বিশ্ববিদ্যালয়ী কন্টোর প্রিন্সিপেলের জন্য মিশ্রিত সমর্থন প্রদান করে, তবে অনেক এনএলপি কাজের জন্য এই অ্যালগরিদম বেশ কাজে প্রয়োজনীয়', 'bs': 'Ovaj papir istražuje dijelovni hijerarhijski algoritam skupljanja baziran na poznatom prinsipu obveznog kontura u fonologiji. Svrha je dvostruka: da vidim da li se takav algoritam može koristiti za neodređenu klasifikaciju telefona ili grafeja u korpori i da istraži da li ova potvrđena univerzalna ograničenja stvarno drži za nekoliko klasa fonoloških različitih karakteristika. Algoritam postiže veoma visoke preciznosti u neodređenom stanju uvođenja određenog glasnog razlika, a također ima jaku tendenciju da otkrije koronalne telefone na neodređenom načinu. Međutim, ostale klase ne odgovaraju kao čisto fonološkim različitim dijelovima. Iako rezultati nude samo pomiješanu podršku univerzalnog obveznog kontura principa, algoritam može biti vrlo korisan za mnoge zadatke NLP zbog visoke tačnosti u otkrivanju konsonentnih/povraćanja/koronalnih razlika.', 'et': 'Käesolevas töös uuritakse lõhestavat hierarhilist klastrite algoritmi, mis põhineb tuntud fonoloogia kohustusliku kontuuri põhimõttel. Eesmärk on kaks: uurida, kas sellist algoritmi saaks kasutada foneemide või grafeemide järelevalveta klassifitseerimiseks korpustes, ning uurida, kas see väidetav universaalne piirang kehtib tõepoolest mitme fonoloogilise eristusvõime klassi kohta. Algoritm saavutab väga kõrge täpsuse konsonant-vokaalide eristamise järelevalveta seadmes ning samuti on tal tugev kalduvus tuvastada koroonaalfoneeme järelevalveta viisil. Ülejäänud klassid ei vasta siiski nii hästi fonoloogiliste eristustunnuste jaotustele. Kuigi tulemused pakuvad ainult segatud toetust universaalsele kohustuslikule kontuuri põhimõttele, võib algoritm olla väga kasulik paljude NLP ülesannete jaoks, kuna konsonant/vokaal/koroonaalsed eristused on kõrge täpsusega.', 'fi': 'Tässä artikkelissa tarkastellaan jakohierarkkista klusterointialgoritmia, joka perustuu fonologian tunnettuun pakollisen kontour-periaatteeseen. Tarkoituksena on kaksi: selvittää, voidaanko tällaista algoritmia käyttää foneemien tai grafeemien valvomattomaan luokitteluun korpusissa, ja tutkia, onko tämä väitetty yleinen rajoitus todella voimassa useiden fonologisten erotteluominaisuuksien luokkien osalta. Algoritmi saavuttaa erittäin korkeat tarkkuudet valvomattomassa konsonantti-vokaalierottelun päättelyssä, ja sillä on myös vahva taipumus havaita koronaaliset foneemit valvomattomasti. Jäljelle jäävät luokat eivät kuitenkaan vastaa yhtä hyvin fonologisia erottelupiirteitä. Vaikka tulokset tarjoavat vain sekatukea yleismaailmalliselle pakolliselle Contour Principle -periaatteelle, algoritmi voi olla erittäin hyödyllinen monissa NLP-tehtävissä konsonantti-/vokaali-/koronaalisen erottelun korkean tarkkuuden vuoksi.', 'jv': 'Perintah iki dhéwé énjedagaké un Algorithm podho akeh basa nang ngerasakno sawar. Heh iki dadi apik: iso dianggo nek segala Algorithm sing bisa diungubah kanggo kelas telegram o graphing kanggo didasakno nggo Kemerdekaan kanggo nguasakno Algorithm mbuh diunting akeh tanggal sing gak bênêr, mengko iso nggawe nguasah dumadhi kaé diunting nggawe gerapakan kuwi, lan tambah kuwi susahe awak dhéwé kuwi diangkat dhéwé, kuwi iso nggawe nguasah perusahaan sistêm kuwi dianggap. politenessoffpolite"), and when there is a change ("assertivepoliteness Nombo', 'sk': 'Ta prispevek raziskuje razdelitveni hierarhični algoritem grozdenja, ki temelji na znanem načelu obveznega kontorja v fonologiji. Namen je dvojni: ugotoviti, ali bi se tak algoritem lahko uporabil za nenadzorovano klasifikacijo fonemov ali grafemov v korpusih, in raziskati, ali ta domnevna univerzalna omejitev resnično velja za več razredov fonoloških razlikovalnih značilnosti. Algoritem doseže zelo visoko natančnost v nenadzorovanem nastavitvi sklepanja razlike med soglasniki in samoglasniki, prav tako pa ima močno nagnjenost k odkrivanju koronalnih foneme na nenadzorovan način. Preostali razredi pa ne ustrezajo tako lepo razdelitvi fonoloških razlikovalnih značilnosti. Čeprav rezultati nudijo le mešano podporo univerzalnemu načelu obveznega kontura, je algoritem lahko zelo uporaben za številne naloge NLP zaradi visoke natančnosti pri razkrivanju soglasnikov/samoglasnikov/koronalnih razlik.', 'ha': "Wannan karatun yana karatun wata taƙaita ta dabam-dabar hierrrchical clusta algoritm a kan the known obbtariy Contor Principe in fologi. Gani na sau biyu: domin ka dũba idan an iya amfani da wannan algoritm don a sami tsare wa siffafi ko grammati cikin makampuni, kuma a yi ƙidãya, ko lalle wannan ƙudura da aka rubutu da shi na cikin wasu fasafa na folojiki. Algoritm yana sãmu gaskiyar gaskiyar a cikin tsarin da ba'a tsare shi ba, kuma yana da sauri mai ƙarfi ga gane fofomfonin nan da ba'a tsare shi ba. Dama da aka baka, kada ku daidaita matsala zuwa rabin siffarwa na folojiki. Algoritm zai iya amfani da wa masu yawa na NLP kwanan da gaskiyar tabbatarwa ya nuna tsakanin kafin/rantsuwel/koronal.", 'he': 'העיתון הזה חוקר אלגוריתם היררכי מחלק שמבוסס על עיקרון הקונטור המחוייב הידוע בפונולוגיה. המטרה היא שתיים: לראות אם אלגוריתם כזה יכול להשתמש בכיתוי לא מעוקב של טלפונים או גראפים בקופורה, ולחקור אם ההגבלה האוניברסלית המנועדת הזו באמת מחזיקה בכמה כיסויים של תכונות פונולוגיות מיוחדות. האלגוריתם משיג מדויקות גבוהות ביותר במסגרת ללא השגחה של למצוא הבדל קונסונט-קולוויל, וגם יש נטייה חזקה לגלות טלפונים קורונאלים באופן בלתי השגחה. למרות זאת, השיעורים הנשארים לא מתאימים באופן נקי לחלקות תכונות פונולוגיות מיוחדות. בעוד התוצאות מציעות רק תמיכה מעורבת לעיקוד קונטור חובה אוניברסלי, האלגוריתם יכול להיות מאוד שימושי עבור משימות רבות של NLP בגלל מדויקת גבוהה בחשף הבדיקות קונסונטית/קולוויל/קורונית.', 'bo': 'ཤོག་བྱང་འདིས་འདིར་སྐྱེས་པའི་ལྟ་བུའི་གྲངས་སུ་འབྲེལ་པའི་རྣམ་པ་གཙོ་རིམ་དང་མཉམ་དུ་གཏོང་བ་དང་། དམིགས་ཡུལ་འདི་གཉིས་པ་དང་། སྒྲིག་སྟངས་དེ་ལྟ་བུའི་ནང་གི་སྐྱེས་ཚད་ཆེན་པོ་ཞིག་ཡོད་པའི་སྒྲིག་འཛུགས་ཀྱིས་ཕན་ཚུན་སྐྱེས་པའི་ཁྱད་པར་མཐོང་མེད་པའི་སྒྲིག་འགོད་ནང་ལྟར་བདེ་ཤོས་ཡོད། ཡིན་ནའང་དུ་འཛམ་གླིང་ལ་འཛིན་གྲྭར་གཟུགས་འགྱུར་བ་ཀྱི་ཁྱད་ཆོས་སྟངས་དང་མཐུན་མི་མཚུངས་པ། རྒྱབ'}
{'en': 'Learning Stock Market Sentiment Lexicon and Sentiment-Oriented Word Vector from StockTwits', 'ar': 'تعلم معجم المشاعر في سوق الأسهم ومتجه الكلمات الموجهة نحو المشاعر من StockTwits', 'pt': 'Aprendendo o Léxico do Sentimento do Mercado de Ações e o Vetor de Palavras Orientado ao Sentimento da StockTwits', 'fr': 'Apprendre le lexique du sentiment boursier et le vecteur de mot orienté sentiment de StockTwits', 'es': 'Aprendiendo el léxico de sentimiento del mercado de valores y el vector de palabras orientado al sentimiento de StockTwits', 'ja': 'StockTwitsから株式市場センチメント辞書とセンチメント指向のワードベクトルを学ぶ', 'hi': 'स्टॉकट्विट्स से शेयर बाजार भावना शब्दकोश और भावना-उन्मुख वर्ड वेक्टर सीखना', 'zh': '学于StockTwits股市情词汇向情词向量', 'ru': 'Лексика сентиментов и ориентированный на сентименты вектор слов на фондовом рынке от StockTwits', 'ga': 'Saor in Aisce íoslódáil Féach ar Twitter Focloir Meon an Mhargaidh Stoc Foghlama agus Veicteoir Focal atá Dírithe ar Mheinteán ó StockTwits', 'ka': 'სტაკონის მარკეტის გასწავლება სტაკონისტური ლექსიკონისტური და სტაკონისტური სიტყვების ვეკტორი StockTwits- დან', 'hu': 'Tanulás Stock Market Sentiment Lexikon és Sentiment-orientált Word Vector a StockTwits', 'el': 'Μαθαίνοντας λεξικό συναισθημάτων αγοράς μετοχών και διανύσμα λέξεων προσανατολισμένο στο συναίσθημα από το StockTwits', 'kk': 'StockTwits- ден Сызық маркеттерді оқыту сезімдік лексикон және Sentiment- Oriented Word Vector ы', 'it': 'Lexicon del sentimento del mercato azionario e vettore di parole orientato al sentimento da StockTwits', 'mk': 'Научи лексикон за чувство на берзата и вектор на зборови ориентиран на чувство од StockTwits', 'lt': 'Mokymasis vertybinių popierių rinkos jautrumo leksikonu ir jautrumui orientuotu žodžių vektoriumi iš StockTwits', 'ms': 'Mempelajari Lexicon Sentiment Pasar saham dan Vektor Perkataan Orientasi Sentiment dari StockTwits', 'ml': 'സ്റ്റോക്ക് ടൌക്ക് മാര്\u200dക്കറ്റ് സെന്റിമെന്\u200dറ് ലെക്സിക്ഷനും സെനിമെന്\u200dറ് മൂല്യമായ വാക്ക് വെക്റ്റര്\u200d', 'mt': 'Learning Stock Market Sentiment Lexicon and Sentiment-Oriented Word Vector from StockTwits', 'mn': 'Сургуулийн зах зээл мэдрэгч Лексикон болон Sentiment-Oriented Word Vector StockTwits-ээс суралцах', 'no': 'Læring av følgjande leksjon og følgjande ordvektor frå StockTwits', 'pl': 'Uczenie się słów rynku giełdowego i wektor słowa zorientowanego na sentymenty od StockTwits', 'ro': 'Lexicon de învățare a sentimentelor pieței de bursă și vector de cuvânt orientat spre sentimente de la StockTwits', 'sr': 'Naučenje tržišta fonda Sentiment Lexicon i Sentiment-Oriented Word Vector iz StockTwits', 'si': 'ඉගෙනීම් ස්ටෝක් මාර්ක්ට් සෙන්ටිමන්ට් ලෙක්සිකෝන් සහ Sentiment-orient Word Vector from StockTwits', 'so': 'Lexicon iyo Sentiment-oriented Word Vector from StockTwits', 'sv': 'Lärande Stock Market Sentiment Lexikon och Sentiment-Oriented Word Vector från StockTwits', 'ta': 'கடைசி விளையாட்டு வெற்றியை கற்றுக்கொள்கிறது', 'ur': 'سٹوک مارکیٹ سنٹیمنٹ لکسیسون اور سنٹیمنٹ اوریٹ ورڈ ویکتور سے سیکھا رہا ہے', 'uz': 'Name', 'vi': 'Học về thị trường chứng khoán... Công ty Y học... và tình cảm về từ cổ phiếu...', 'bg': 'Учене на фондовия пазар Сентимент Лексикон и Сентимент-ориентиран Слово Вектор от Сентимент Лексикон и Сентимент-ориентиран Слово', 'nl': 'Leren Stock Market Sentiment Lexicon en Sentiment-Oriented Word Vector van StockTwits', 'de': 'Lernen Aktienmarkt Sentiment Lexikon und Sentiment-Oriented Word Vektor von StockTwits', 'da': 'Læring Stock Market Sentiment Lexikon og Sentiment-orienteret Word Vector fra StockTwits', 'hr': 'Naučenje tržišta stokova Sentiment Lexicon i Sentiment-Oriented Word Vector iz StockTwits', 'fa': 'یادگیری بازار اسناد مجموعه Lexicon و ویکتور کلمه اصلی از StockTwits', 'sw': 'Sentiment Lexicon and Sentiment-oriented Word Vector from StockTwits', 'tr': 'StockTwits-den Sentral Sentral Leksik we Sentral Sentral söz Vektory öwrenmek', 'id': 'Mempelajari Sentiment Pasar saham Lexicon dan Sentiment-Oriented Word Vector dari StockTwits', 'af': 'Leer voorkommerk Sentiment Lexicon en Sentiment- Orienteerde Woord Vektor van StockTwits', 'hy': 'Comment', 'ko': 'StockTwits에서 주식시장 정서 어휘와 정서 가이드 어휘의 방향을 배우다', 'am': 'timent-Oriented Word Vector from StockTwits', 'sq': 'Mëso lexikonin e ndjenjave të tregut të aksioneve dhe vektorin e fjalëve të orientuar në ndjenja nga StockTwits', 'bs': 'Naučenje tržišta fonda Sentiment Lexicon i Sentiment-Oriented Word Vector iz StockTwits', 'ca': "Aprendre Lexicon del Sentiment del Mercat d'Actes i Vector de paraules orientats al Sentiment a StockTwits", 'bn': 'সেন্টিমেন্ট লেক্সিকোন এবং সেন্টিমেন্ট- অর্থিত শব্দ ভেক্টর', 'cs': 'Učení se akciového trhu Sentiment Lexikon a Sentiment orientovaný slovní vektor ze StockTwits', 'et': 'Õppimine Stock Market Sentiment Lexicon ja Sentiment-orienteeritud sõna vektor StockTwits', 'fi': 'Oppiminen Stock Market Sentiment Lexicon ja Sentiment-Oriented Word Vector alkaen StockTwits', 'az': 'StockTwits t톛r톛find톛n StockTwits pazar캼ndan 칬yr톛n톛n Sentiment Lexicon v톛 Sentiment-Oriented Word Vector', 'jv': 'text-editor-action', 'ha': 'Media controller element', 'he': 'ללמוד רגשות שוק המניות לקסיקון וקטור מילים ממוקד רגשות מStockTwits', 'sk': 'Učenje borznega trga Sentiment Lexikon in Sentiment-Oriented Beseda Vector iz StockTwits', 'bo': 'སློབ་སྦྱོར་བའི་གནས་ཚུལ་གྱི་དྲ་རྒྱ་ཆེས་མཚམས་སུ་གཏོང་དང་དུས་ཚོད་འདྲ་བྱེད་ཀྱི་ཐབས་ལམ།'}
{'en': 'Previous studies have shown that investor sentiment indicators can predict stock market change. A domain-specific sentiment lexicon and sentiment-oriented word embedding model would help the sentiment analysis in financial domain and stock market. In this paper, we present a new approach to learning stock market lexicon from StockTwits, a popular financial social network for investors to share ideas. It learns word polarity by predicting message sentiment, using a neural net-work. The sentiment-oriented word embeddings are learned from tens of millions of StockTwits posts, and this is the first study presenting sentiment-oriented word embeddings for stock market. The experiments of predicting investor sentiment show that our lexicon outperformed other lexicons built by the state-of-the-art methods, and the sentiment-oriented word vector was much better than the general word embeddings.', 'ar': 'أظهرت الدراسات السابقة أن مؤشرات ثقة المستثمرين يمكن أن تتنبأ بتغير سوق الأسهم. من شأن معجم المشاعر الخاصة بالمجال ونموذج تضمين الكلمات الموجه نحو المشاعر أن يساعدا في تحليل المشاعر في المجال المالي وسوق الأوراق المالية. في هذه الورقة ، نقدم نهجًا جديدًا لتعلم معجم سوق الأوراق المالية من StockTwits ، وهي شبكة اجتماعية مالية شهيرة للمستثمرين لمشاركة الأفكار. يتعلم قطبية الكلمات من خلال التنبؤ بمشاعر الرسالة ، باستخدام شبكة عمل عصبية. يتم تعلُّم الكلمة المزخرفة الموجهة نحو المشاعر من عشرات الملايين من منشورات StockTwits ، وهذه هي الدراسة الأولى التي تقدم حفلات الزفاف الموجهة نحو المشاعر لسوق الأوراق المالية. تُظهر تجارب التنبؤ بمشاعر المستثمرين أن معجمنا تفوق في الأداء على المعاجم الأخرى التي تم إنشاؤها بواسطة أحدث الأساليب ، وكان متجه الكلمات الموجه نحو المشاعر أفضل بكثير من الكلمات العامة المزخرفة.', 'fr': "Des études antérieures ont montré que les indicateurs de sentiment des investisseurs peuvent prédire l'évolution du marché boursier. Un lexique des sentiments propre à un domaine et un modèle d'intégration de mots axé sur les sentiments faciliteraient l'analyse des sentiments dans le domaine financier et le marché boursier. Dans cet article, nous présentons une nouvelle approche d'apprentissage du lexique boursier de StockTwits, un réseau social financier populaire permettant aux investisseurs de partager des idées. Il apprend la polarité des mots en prédisant le sentiment d'un message, à l'aide d'un réseau neuronal. Les intégrations de mots axées sur le sentiment sont apprises à partir de dizaines de millions de publications de StockTwits, et il s'agit de la première étude présentant des intégrations de mots axées sur le sentiment pour le marché boursier. Les expériences de prédiction du sentiment des investisseurs montrent que notre lexique a surpassé les autres lexiques créés par les méthodes de pointe, et que le vecteur de mots axé sur les sentiments était bien meilleur que le mot embeddings général.", 'es': 'Estudios anteriores han demostrado que los indicadores de confianza de los inversores pueden predecir el cambio en el mercado de valores. Un léxico de sentimiento específico del dominio y un modelo de inserción de palabras orientado al sentimiento ayudarían al análisis de sentimientos en el dominio financiero y el mercado de valores. En este artículo, presentamos un nuevo enfoque para aprender el léxico bursátil de StockTwits, una popular red social financiera para que los inversores compartan ideas. Aprende la polaridad de las palabras mediante la predicción del sentimiento del mensaje mediante una red neuronal. Las incrustaciones de palabras orientadas al sentimiento se aprenden de decenas de millones de publicaciones de StockTwits, y este es el primer estudio que presenta incrustaciones de palabras orientadas al sentimiento para el mercado de valores. Los experimentos de predicción del sentimiento de los inversores muestran que nuestro léxico superó a otros léxicos creados por los métodos más avanzados, y el vector de palabras orientado al sentimiento fue mucho mejor que las incrustaciones de palabras generales.', 'pt': 'Estudos anteriores mostraram que os indicadores de sentimento dos investidores podem prever mudanças no mercado de ações. Um léxico de sentimento específico de domínio e um modelo de incorporação de palavras orientado a sentimento ajudariam a análise de sentimento no domínio financeiro e no mercado de ações. Neste artigo, apresentamos uma nova abordagem para aprender o léxico do mercado de ações da StockTwits, uma rede social financeira popular para investidores compartilharem ideias. Ele aprende a polaridade da palavra prevendo o sentimento da mensagem, usando uma rede neural. As incorporações de palavras orientadas para o sentimento são aprendidas em dezenas de milhões de postagens do StockTwits, e este é o primeiro estudo que apresenta incorporações de palavras orientadas para o sentimento para o mercado de ações. Os experimentos de previsão do sentimento do investidor mostram que nosso léxico superou outros léxicos construídos pelos métodos de última geração, e o vetor de palavras orientado ao sentimento foi muito melhor do que os embeddings gerais de palavras.', 'ja': 'これまでの研究では、投資家センチメント指標は株式市場の変化を予測できることが示されています。ドメイン固有のセンチメント辞書とセンチメント指向の単語埋め込みモデルは、金融ドメインと株式市場におけるセンチメント分析に役立ちます。この論文では、投資家がアイデアを共有するための人気のある金融ソーシャルネットワークであるStockTwitsから株式市場の辞書を学ぶための新しいアプローチを提示します。ニューラルネットワークを使用して、メッセージ感情を予測することで、単語の極性を学習します。センチメント指向の単語埋め込みは、数千万のStockTwitsの投稿から学びました。これは、株式市場のためにセンチメント指向の単語埋め込みを提示する最初の研究です。投資家の感情を予測する実験では、私たちの辞書は最先端の方法で構築された他の辞書よりも優れており、感情指向の単語ベクトルは一般的な単語埋め込みよりもはるかに優れていました。', 'zh': '前论明白,投资者情指标可测股市变。 特定领域之情词典与向情之词嵌模将有助于金融领股票市场之情析。 本文中,发StockTwits学股票市场词汇新法,StockTwits是流行之金融社交网络,供投资者分享之意。 以神经网络事占消息,以学单词极性。 以情为向者嵌数千万StockTwits帖中学者,此第一项为股市供以情为向者也。 测投资者情之实验明,词典优于先进之词典,而以情词向量胜于众词。', 'hi': 'पिछले अध्ययनों से पता चला है कि निवेशक भावना संकेतक शेयर बाजार में बदलाव की भविष्यवाणी कर सकते हैं। एक डोमेन-विशिष्ट भावना शब्दकोश और भावना-उन्मुख शब्द एम्बेडिंग मॉडल वित्तीय डोमेन और शेयर बाजार में भावना विश्लेषण में मदद करेगा। इस पेपर में, हम स्टॉकट्विट्स से शेयर बाजार शब्दकोश सीखने के लिए एक नया दृष्टिकोण प्रस्तुत करते हैं, जो निवेशकों के लिए विचारों को साझा करने के लिए एक लोकप्रिय वित्तीय सामाजिक नेटवर्क है। यह संदेश भावना की भविष्यवाणी करके शब्द ध्रुवीयता सीखता है, एक तंत्रिका नेट-वर्क का उपयोग करके। भावना-उन्मुख शब्द एम्बेडिंग को लाखों स्टॉकट्वाइट्स पोस्ट से सीखा जाता है, और यह शेयर बाजार के लिए भावना-उन्मुख शब्द एम्बेडिंग प्रस्तुत करने वाला पहला अध्ययन है। निवेशक भावना की भविष्यवाणी करने के प्रयोगों से पता चलता है कि हमारे शब्दकोश ने अत्याधुनिक तरीकों द्वारा निर्मित अन्य शब्दकोशों को पछाड़ दिया, और भावना-उन्मुख शब्द वेक्टर सामान्य शब्द एम्बेडिंग की तुलना में बहुत बेहतर था।', 'ru': 'Предыдущие исследования показали, что индикаторы настроений инвесторов могут предсказывать изменения на фондовом рынке. В анализе настроений в финансовой сфере и на фондовом рынке помогли бы лексикон настроений и модель встраивания слов, ориентированная на настроения. В этой статье мы представляем новый подход к изучению лексикона фондового рынка от StockTwits, популярной финансовой социальной сети для обмена идеями между инвесторами. Он изучает полярность слов, предсказывая настроения сообщений, используя нейронную сеть. Ориентированные на настроения вложения слов выучены из десятков миллионов сообщений StockTwits, и это первое исследование, представляющее ориентированные на настроения вложения слов для фондового рынка. Эксперименты по прогнозированию настроений инвесторов показывают, что наш лексикон превосходил другие лексиконы, построенные современными методами, а ориентированный на настроения вектор слов был намного лучше, чем общие вложения слов.', 'ga': 'Léiríodh i staidéir roimhe seo gur féidir le táscairí meon infheisteoirí athrú ar an stocmhargadh a thuar. Chuideodh foclóir meon fearainn-shonrach agus samhail um leabú focal atá dírithe ar dhearcadh leis an anailís sentiment san fhearann airgeadais agus sa stocmhargadh. Sa pháipéar seo, cuirimid i láthair cur chuige nua maidir le foghlaim foclóra stocmhargadh ó StockTwits, líonra sóisialta airgeadais a bhfuil tóir ag infheisteoirí air chun smaointe a roinnt. Foghlaimíonn sé polaraíocht na bhfocal trí mheon na teachtaireachta a thuar, ag baint úsáide as líonra néareolaíoch. Foghlaimítear an leabú focal atá dírithe ar mheon ó na mílte post de chuid StockTwits, agus is é seo an chéad staidéar a chuireann i láthair leabaithe focal atá dírithe ar mheon don stocmhargadh. Léiríonn na turgnaimh maidir le meon na n-infheisteoirí a thuar gur sháraigh ár bhfoclóir foclóirí eile a tógadh leis na modhanna úrscothacha, agus bhí an veicteoir focal atá dírithe ar mheon i bhfad níos fearr ná an leabú focal ginearálta.', 'hu': 'Korábbi tanulmányok kimutatták, hogy a befektetői hangulatmutatók megjósolhatják a tőzsdei változásokat. Egy domain-specifikus hangulatlexikon és hangulatorientált szóbeágyazási modell segítené a hangulatelemzést a pénzügyi területen és a tőzsdén. Ebben a tanulmányban egy új megközelítést mutatunk be a tőzsdei lexikon tanulására a StockTwits, egy népszerű pénzügyi közösségi hálózat a befektetők számára, hogy megosszák ötleteiket. Megtanulja a szó polaritását az üzenet érzelmeinek előrejelzésével, neurális hálózat segítségével. Az érzelmi orientált szóbeágyazásokat több tízmillió StockTwits posztból tanulják, és ez az első tanulmány, amely érzelmi orientált szóbeágyazásokat mutat be a tőzsdén. A befektetői hangulat előrejelzésének kísérletei azt mutatják, hogy lexikonunk a legkorszerűbb módszerekkel épített lexikonokat felülmúlta, és az érzelmi orientált szóvektor sokkal jobb volt, mint az általános szóbeágyazások.', 'el': 'Προηγούμενες μελέτες έχουν δείξει ότι οι δείκτες συναισθημάτων των επενδυτών μπορούν να προβλέψουν αλλαγή στο χρηματιστήριο. Ένα συγκεκριμένο λεξικό συναισθημάτων και μοντέλο ενσωμάτωσης λέξεων προσανατολισμένο στο συναίσθημα θα βοηθούσε την ανάλυση συναισθημάτων στον οικονομικό τομέα και στο χρηματιστήριο. Σε αυτή την εργασία, παρουσιάζουμε μια νέα προσέγγιση στην εκμάθηση λεξικού χρηματιστηρίου από το ένα δημοφιλές οικονομικό κοινωνικό δίκτυο για επενδυτές για να μοιραστούν ιδέες. Μαθαίνει πολικότητα λέξεων προβλέποντας το συναίσθημα μηνυμάτων, χρησιμοποιώντας ένα νευρικό δίκτυο. Οι ενσωματωμένες λέξεις προσανατολισμένες στο συναίσθημα μαθαίνονται από δεκάδες εκατομμύρια δημοσιεύσεις και αυτή είναι η πρώτη μελέτη που παρουσιάζει ενσωματωμένες λέξεις προσανατολισμένες στο συναίσθημα για το χρηματιστήριο. Τα πειράματα πρόβλεψης του συναισθήματος των επενδυτών δείχνουν ότι το λεξικό μας ξεπερνούσε τα άλλα λεξικά που χτίστηκαν με τις προηγμένες μεθόδους, και το διανύσμα λέξεων προσανατολισμένο στο συναίσθημα ήταν πολύ καλύτερο από τις γενικές ενσωματώσεις λέξεων.', 'ka': 'წინა კვლევები გამოჩვენეთ, რომ ინსტერსტორის სენტიმენტის ინდექტორიები შეუძლიათ წინასწარმოდგინოთ stock market changes. დიომინის განსაკუთრებული სენტიმენტის ლექსიკონი და სენტიმენტის განსაკუთრებული სიტყვების მოდელია დახმარება სენტიმენტის ანალიზაციას ფინანსურ დიომინი და stock market ამ დოკუმენტში ჩვენ ახალი პროგრამა StockTwits-ის სტაკუმენტური საზოგადო სოციალური ქსელექტის სტაკუმენტური ქსელექტის სტაკუმენტური მეტ ის სწავლის სიტყვის პოლარიტი, შეტყობინებული სიტყვის სენტიმენტის გამოყენებით, ნეიროლური მუშაობის გამოყენებით. სენტიმენტიური სიტყვების შემდეგ ათი მილიონის StockTwits პოსტიდან მოსწავლია, და ეს არის პირველი სწავლა, რომელიც სენტიმენტიური სიტყვების შემდეგ სენტიმენტიური სიტყვების შემდეგება. ექსპერიმენტები, რომელიც ინსტერესტორის სენტიმენტიმენტის წარმოდგენა, ჩვენი ლექსიკონი უფრო მეტი ლექსიკონის შექმნა, რომელიც სენტიმენტიმენტიური სიტყვების გვექტორი უფრო მეტი იყო', 'it': "Studi precedenti hanno dimostrato che gli indicatori del sentiment degli investitori possono prevedere il cambiamento del mercato azionario. Un lessico del sentiment specifico per il dominio e un modello di incorporazione delle parole orientato al sentiment aiuterebbe l'analisi del sentiment nel dominio finanziario e nel mercato azionario. In questo articolo, presentiamo un nuovo approccio all'apprendimento del lessico del mercato azionario da StockTwits, un popolare social network finanziario per gli investitori per condividere idee. Impara la polarità delle parole predicendo il sentimento del messaggio, usando una rete neurale. Gli embedding di parole orientati al sentiment sono appresi da decine di milioni di post StockTwits, e questo è il primo studio che presenta embedding di parole orientati al sentiment per il mercato azionario. Gli esperimenti di predire il sentiment degli investitori mostrano che il nostro lessico ha superato altri lessici costruiti con metodi all'avanguardia, e il vettore di parole orientato al sentiment era molto migliore delle incorporazioni di parole generali.", 'lt': 'Previous studies have shown that investor sentiment indicators can predict stock market change.  Su konkrečia sritimi susijęs sentimento leksikonas ir su sentimentais susijęs žodžių įtraukimo modelis padėtų analizuoti sentimentus finansų srityje ir akcijų rinkoje. Šiame dokumente pristatome naują požiūrį į vertybinių popierių rinkos leksikono mokymąsi iš StockTwits, populiaraus finansinio socialinio tinklo investuotojams dalytis idėjomis. Jis mokosi žodžių poliarumo prognozuodamas pranešimo jausmą, naudojant nervinį tinklą. The sentiment-oriented word embeddings are learned from tens of millions of StockTwits posts, and this is the first study presenting sentiment-oriented word embeddings for stock market.  Investitorių jausmų prognozavimo eksperimentai rodo, kad mūsų leksikonas viršijo kitus leksikonus, sukurtus moderniausiais metodais, ir jausmų orientuotas žodžių vektorius buvo daug geresnis nei bendrieji žodžių įterpimai.', 'kk': 'Алдыңғы зерттеулері инвеститордың сезімдік индикаторлары бағат рынкының өзгерістерін алдын ала алады. Доменге ерекше сезімдік лекциясы және сезімдік сөздерді ендіру үлгісі финансовы доменде және акциялық рынкта сезімдік талдауына көмектеседі. Бұл қағазда, StockTwits-тың stock market лексикасын оқыту үшін, инвеститорлардың идеяларын ортақтастыру үшін мәліметті финансовы жалпы желінде жаңа тәртібін таңдаймыз. Бұл сөздердің поляриялығын хаттар сезімін алдын ала алады, невралдық желі жұмыс істеп. Сөздерге бағытталған сөздердің ендіру оның арасындағы миллион StockTwits поштасынан үйреніледі. Бұл бірінші зерттеу көздерге сәтсіздік сөздерді ендіру үшін көрсетеді. Инвеститордың сезімдігін бақылау тәжірибелері біздің лексиканың басқа лексиканың әдістері бойынша құрылған лексиканың өте жақсы екенін көрсетеді. Сезімдік сөздердің векторы жалпы сөздердің ендіруіне артық бол', 'ms': 'kajian terdahulu menunjukkan bahawa indikator perasaan pelabur boleh meramalkan perubahan pasar saham. Sebuah leksikon perasaan khusus-domain dan model penyambungan perkataan orient-sentimen akan membantu analisis perasaan dalam domain keuangan dan pasar saham. Dalam kertas ini, kami memperkenalkan pendekatan baru untuk mempelajari leksikon pasar saham dari StockTwits, rangkaian sosial kewangan populer bagi pelabur untuk berkongsi idea. Ia belajar polariti perkataan dengan meramalkan perasaan mesej, menggunakan jaringan saraf. Pencampuran perkataan sentimen-oriented belajar dari puluhan juta pos StockTwits, dan ini adalah kajian pertama yang memperkenalkan pencampuran perkataan sentimen-oriented untuk pasar saham. Eksperimen meramalkan perasaan pelabur menunjukkan bahawa leksikon kita melampaui leksikon lain yang dibina oleh kaedah-kaedah-state-of-the-art, dan vektor perkataan-sentiment-oriented jauh lebih baik daripada penyembedding perkataan umum.', 'ml': 'മുമ്പുള്ള പഠനങ്ങള്\u200d കാണിച്ചിരിക്കുന്നുവെങ്കില്\u200d സ്റ്റോക്കറ്റ് മാറ്റങ്ങള്\u200d പ്രത്യേകിക്കാന A domain-specific sentiment lexicon and sentiment-oriented word embedding model would help the sentiment analysis in financial domain and stock market.  ഈ പത്രത്തില്\u200d, സ്റ്റോക്ക് ട്വിറ്റില്\u200d നിന്നും സ്റ്റോക്ക് മാര്\u200dക്കറ്റ് ലെക്സിക്കോണിനെ പഠിപ്പിക്കാന്\u200d പുതിയ ഒരു വഴി കൊ ന്യൂറല്\u200d നെറ്റ്\u200cവര്\u200dക്ക് ഉപയോഗിച്ച് സന്ദേശം പ്രവചിപ്പിക്കുന്നതിനാല്\u200d വാക്ക് അശുദ്ധീകരണം പഠിക സ്റ്റോക്ക്ട്വിറ്റ് പോസ്റ്റുകളില്\u200d നിന്നും പത്ത് ലക്ഷത്തോളം വാക്കുകള്\u200d പഠിച്ചിരിക്കുന്നു. ഇതാണ് ആദ്യ പഠിക്കുന്നത് സ്റ്റോക്ക് മാ ഇന്\u200dസ്റ്റര്\u200dട്ടെന്\u200dറിന്\u200dറെ വികാരങ്ങള്\u200d പ്രതീക്ഷിക്കുന്ന പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ ലെക്സിക്കോണ്\u200d രാജ്യത്തിലെ രീതിയിലെ മറ്റ', 'mk': 'Претходните студии покажаа дека инвеститорите можат да предвидат промени на берзата. Лексикон за чувства специфичен на домен и модел за вградба на зборови ориентиран на чувства би помогнал во анализата на чувствата во финансискиот домен и берзата. Во овој весник, претставуваме нов пристап до учењето на лексиконот на берзата од СтокТвитс, популарна финансиска социјална мрежа за инвеститорите да споделат идеи. It learns word polarity by predicting message sentiment, using a neural net-work.  Сентиментално ориентираните зборови се научија од десетици милиони постови на СтокТвитс, а ова е првата студија која претставува сентиментално ориентирани зборови за берзата. Експериментите за предвидување на чувството на инвеститорите покажуваат дека нашиот лексикон ги надмина другите лексикони изградени со најсовремените методи, а сентиментално ориентираниот вектор на зборовите беше многу подобар од општите вградувања на зборовите.', 'mt': 'Studji preċedenti wrew li l-indikaturi tas-sensazzjoni tal-investitur jistgħu jipprevedu l-bidla fis-suq tal-ishma. A domain-specific sentiment lexicon and sentiment-oriented word embedding model would help the sentiment analysis in financial domain and stock market.  F’dan id-dokument, qed nippreżentaw approċċ ġdid għat-tagħlim tal-lexicon tas-suq tal-ishma minn StockTwits, netwerk soċjali finanzjarju popolari għall-investituri biex jaqsmu ideat. Huwa jitgħallem il-polarità tal-kelma billi jipprevedi s-sentiment tal-messaġġ, bl-użu ta’ netwerk newrali. L-inkorporazzjonijiet tal-kliem orjentati lejn is-sentimenti jitgħallmu minn għexieren ta’ miljuni ta’ postijiet ta’ StockTwits, u dan huwa l-ewwel studju li jippreżenta inkorporazzjonijiet tal-kliem orjentati lejn is-sentimenti għas-suq tal-ishma. L-esperimenti tat-tbassir tas-sentiment tal-investitur juru li l-lexicon tagħna wettaq lexicons oħra mibnija mill-metodi l-aktar avvanzati, u l-vettur tal-kelma orjentat lejn is-sentiment kien ħafna aħjar mill-inkorporazzjonijiet ġenerali tal-kelma.', 'mn': 'Өмнөх судалгаагаар хөрөнгө оруулагчдын сэтгэл хөдлөлийн зах зээлийн өөрчлөлтийг тодорхойлж чадна гэдгийг харуулсан. Холбооны тодорхой мэдрэмжтэй сэтгэл хөдлөл, сэтгэл хөдлөлтэй үг бий болгох загвар санхүүгийн сүлжээ болон хөрөнгийн зах зээлийн мэдрэмжүүдийн шинжилгээнд туслах болно. Энэ цаасан дээр бид StockTwits-ээс хөрөнгө оруулагчдын санхүүгийн нийгмийн сүлжээний суралцах шинэ арга зам өгсөн. Энэ нь мэдээллийн сэтгэл хөдлөлийг таамаглаж, мэдрэлийн сүлжээг ашиглаж хэлбэрээр зайлсхийг сурдаг. Үүнийг мэдрэмжтэй хэлбэрээр бий болгох үгийг арван сая StockTwits хуудас суралцаж байна. Энэ бол хөрөнгө зах зээл дээр мэдрэмжтэй үг бий болгох анхны судалгаа. хөрөнгө оруулагч сэтгэл хөдлөлийг таамаглах туршилтууд бидний лексикон нь урлагийн төвшин аргаар бүтээсэн бусад лексиконуудыг илүү сайн хийж чаддаг гэдгийг харуулж байна.', 'no': 'Førre studiar har vist at investoresentimentindikatorer kan foregå endringar på stokkmarkedet. Eit domenespesifikk sentiment lexicon og sentimentorientert ordinnbyggingsmodell vil hjelpa til sentimentanalysen i finansielle domene og stock-markedet. I denne papiret presenterer vi ein ny tilnærming til å lære stokkmarkedsleksikon frå StockTwits, eit populært finansielt sosialt nettverk for investorer for å dele idear. Det lærer ordpolaritet ved å foregå meldingsfeil med eit neuralt nettverk. Den følsemninga orienterte ordinnbygginga er lært frå tiere millioner av StockTwits-postar, og dette er den første studien som viser sentimentorientert ordinnbygging for stokkmarkedet. Eksperimentane for å foregå investoresentiment viser at vår leksikon utførte andre leksikon som bygd av kunstmetodane, og sentimentorientert ordvektoren var mykje bedre enn det generelle ordinnbygginga.', 'pl': 'Wcześniejsze badania wykazały, że wskaźniki sentymentu inwestorów mogą przewidywać zmiany na giełdzie. Specyficzny dla domeny leksykon sentymentów i model osadzania słów zorientowany na sentymenty pomogłby w analizie sentymentów w domenie finansowej i giełdzie. W artykule przedstawiamy nowe podejście do nauki leksykonu giełdowego z StockTwits, popularnej finansowej sieci społecznościowej dla inwestorów do dzielenia się pomysłami. Uczy się polaryzacji słów przewidując sentyment wiadomości, używając sieci neuronowej. Wkłady słów zorientowanych na sentyment nauczyły się z dziesiątek milionów postów StockTwits i jest to pierwsze badanie prezentujące osadzenia słów zorientowanych na sentyment dla giełdy. Eksperymenty przewidywania sentymentu inwestorów pokazują, że nasz leksykon przewyższał inne leksykony zbudowane przy użyciu najnowocześniejszych metod, a wektor słowa zorientowany na sentyment był znacznie lepszy niż ogólne osadzenia słów.', 'ro': 'Studiile anterioare au arătat că indicatorii sentimentului investitorilor pot prezice schimbările pieței bursiere. Un lexicon al sentimentului specific domeniului și un model de încorporare a cuvintelor orientat spre sentiment ar ajuta analiza sentimentului în domeniul financiar și pe piața bursieră. În această lucrare, prezentăm o nouă abordare a învățării lexiconului bursier de la StockTwits, o rețea socială financiară populară pentru investitori pentru a împărtăși idei. Învaţă polaritatea cuvintelor predicând sentimentul mesajelor, folosind o reţea neurală. Incorporarea cuvintelor orientate spre sentiment este învățată din zeci de milioane de postări StockTwits, iar acesta este primul studiu care prezintă încorporarea cuvintelor orientate spre sentiment pentru piața de valori. Experimentele de predicție a sentimentului investitorilor arată că lexiconul nostru a depășit alte lexicoane construite prin metode de ultimă generație, iar vectorul de cuvânt orientat spre sentiment a fost mult mai bun decât încorporarea cuvântului general.', 'sr': 'Prethodne studije pokazale su da indikatori osjećanja ulagača mogu predvidjeti promjenu tržišta dionica. Leksikon za posebnu domenu sentimenta i model uključenih reèi na sentiment-orientirani bi pomogao analizi sentimenta na financijskom domenu i tržištu dionica. U ovom papiru predstavljamo novi pristup učenju leksiona tržišta dionica iz StockTwita, popularne finansijske socijalne mreže za ulagače da podijele ideje. Nauèi reè polarnost predviðajuæi osjeæaj poruke, koristeći neuralnu mrežu. Oseæanje izraženih reèi se nauèi od desetine miliona stockTwits postova, a ovo je prva studija koja predstavlja sentimentalne reèi ugražavanja dionica. Eksperimenti predviđanja sentimenta investitora pokazuju da je naš leksikon nadmašio druge leksikone izgrađene državnim metodama umjetnosti, a vektor reèi orijentirani na sentiment bio mnogo bolji od općeg uključenja reèi.', 'si': 'මුලින් පරීක්ෂණාව පෙන්වන්න පුළුවන් විදිහට ස්ටෝක් මාර්ක්ටර් වෙනස් විදිහට අනුවෙන්  ඩොමේන් එක්ක විශේෂ විශේෂ ලෙක්සිකෝන් සහ හිතුවක් ප්\u200dරමාණය සම්බන්ධ වචන පද්ධතියක් සඳහා විශේෂ විශේ මේ පත්තරේ අපි අළුත් ප්\u200dරවේශයක් ස්ටොක්ට්විට් වලින් ස්ටොක් මාර්කේට් ලෙක්සිකෝන් ඉගෙන ගන්න, ප්\u200dරජාතික අ ඒක පණිවිඩය සම්බන්ධ විදියට පණිවිඩය ප්\u200dරශ්නයක් ඉගෙන ගන්නවා. ස්ටොක්ට්විට්ස් මිලියන දහස් පොස්ට්ස් වලින් ඉගෙනගන්න පුළුවන් අධ්\u200dයානය විදියට ප්\u200dරධානයක් පෙන්වන්න පුළුවන් අධ්\u200dයානය. සාමාන්\u200dය වෙක්ටර් වලින් අපේ ලෙක්සිකෝන් අනිත් ලෙක්සිකෝන්ස් වලින් නිර්මාණය කරලා තියෙනවා කියලා ප්\u200dරයෝජනය කරනවා කියලා ප්\u200dරයෝජනය කරනවා ක', 'so': 'Waxbarashada hore waxay tuseen in tusaale ahaan waxyaabaha laga soo jeedin karo beddelka suuqa ganacsiga. Tusaale ku qoran hadal ku saabsan dareenka leksikan iyo midowga kaleemeyska ayaa caawinaya baaritaanka maandooriyaha guriga dhaqaalaha iyo suuqa xoolaha. Qoraalkan waxaynu ku soo bandhignaa qaab cusub oo aan ka barano suuqa firaaqada, kaas oo ah shabakadda bulshada dhaqaalaha ee ganacsadaha oo dhan si ay u qaybsadaan fikrada. Waxey ku barataa habka hadalka, iyadoo isticmaalaya isticmaalka shabakadda cawinaad. Hadalka la soo jeedo waxaa laga bartaa toban kun oo milyan oo warqadood oo StockTwits ah, taasina waa waxbarashada ugu horraysay ee soo jeeda hadal ku qoran suuqa firaaqada. Imtixaanka ka hor dhigashada fikrada qofka wax bedela waxay muuqataa in leksikankeenu ay sameeyeen leksikan kale oo ay sameeyeen qaababka dowladda farshaxanka ah, oo qofka xisaabta u jeeday ay ay ka wanaagsan tahay hadalka caadiga ah.', 'sv': 'Tidigare studier har visat att investerarnas sentimentindikatorer kan förutsäga förändringar på aktiemarknaden. En domänspecifik sentimentlexikon och sentimentorienterad ordbäddningsmodell skulle hjälpa sentimentanalysen inom finansiell domän och börs. I denna uppsats presenterar vi ett nytt sätt att lära sig aktiemarknadslexikon från StockTwits, ett populärt finansiellt socialt nätverk för investerare att dela idéer. Den lär sig ordpolaritet genom att förutsäga meddelandesentiment, med hjälp av ett neuralt nätverk. De sentimentorienterade ordinbäddningarna lär sig från tiotals miljoner StockTwits inlägg, och detta är den första studien som presenterar sentimentorienterade ordinbäddningar för aktiemarknaden. Experimenten med att förutsäga investerarens sentiment visar att vårt lexikon presterade bättre än andra lexikon byggda med de senaste metoderna, och den sentimentorienterade ordvektorn var mycket bättre än de allmänna ordinbäddningarna.', 'ta': 'முந்தைய ஆய்வுகள் முதலீட்டாளர் உணர்வு குறிக்குறியீடுகள் சாலை சந்தையின் மாற்றத்தை முன்னோக்கி  ஒரு டோமைன் குறிப்பிட்ட உணர்வு லெக்சிகோன் மற்றும் உணர்வு திசையாக்கப்பட்ட வார்த்தை உள்ளிடும் மாதிரி பொருள் களம் மற்றும் பங இந்த காகிதத்தில், நாம் ஸ்டாக்ட்டுவிட்டில் இருந்து ஸ்காக் சந்தை லெக்சியானை கற்றுக்கொள்ள ஒரு புதிய வழியை கொண்டு வருகிற அது செய்தி உணர்வை முன்வாக்கி வார்த்தை தீவிரமாக கற்றுக் கொள்கிறது, ஒரு புதிய நெட் வேலையை பயன்படுத்தி The sentiment-oriented word embeddings are learned from tens of millions of StockTwits posts, and this is the first study presenting sentiment-oriented word embeddings for stock market.  முதலீட்டாளர் உணர்வு முன்னோக்கி சோதனைகள் காண்பிக்கப்பட்டுள்ளது என்றால் எங்கள் லெக்சிகோன் மற்ற லெக்சியன் முறைமைகளால் உருவாக்கப்பட்டுள்ளது என்று தெரியு', 'ur': 'پہلے کی تحقیقات دکھائی گئی ہے کہ سرمایہ کرنے والے احساسات نشانیاں سٹاک مارکیٹ بدلنے کی پیش بینی کر سکتے ہیں۔ ایک ڈومین کے مطابق احساسات لکسون اور احساسات-oriented word embedding model کی مدد کرتا ہے کہ فنانسی ڈومین اور سٹاک مارک میں احساسات تحلیل کی مدد کرے۔ اس کاغذ میں ہم نے StockTwits سے استاکٹ مارک لکسون کی تعلیم کے لئے ایک نئی طریقہ پیش کیا ہے، ایک مشهور مالی سوسیل نیٹورک ہے جو سرمایہ کرنے والوں کے لئے ایڈیوں کا شریک کرنا ہے۔ یہ بات نصیحت کی بات سکھاتا ہے پیغام احساس کی پیش بینی کے ذریعہ، ایک نیورل نیٹ کارک کے استعمال سے۔ اور یہ سب سے پہلی تحقیق ہے کہ اسٹاکٹ مارکیٹ کے لئے احساس کی طرف متوجہ ہوئی لفظ انڈینگ سے سیکھا جاتا ہے۔ استعمال کرنے والے احساسات کی پیش بینی کی آزمائش دکھاتی ہے کہ ہماری لکسیون نے دوسری لکسیون سے زیادہ اضافہ کیا تھا جو ایالت کے مطابق بنائے گئے تھے، اور احساسات کے مطابق لکھنے والی لکھنے والی ویکتور عمومی لکھنے سے بہت بہتر تھا۔', 'vi': 'Những nghiên cứu trước đã cho thấy rằng tỉ lệ tình cảm của nhà đầu tư có thể dự đoán thị trường. Một ngôn ngữ đa cảm cụ thể miền và một mô hình cài ghép từ ủy mị có thể giúp phân tích cảm xúc trong lĩnh vực tài chính và thị trường cổ phiếu. Trong bài báo này, chúng tôi đưa ra một phương pháp mới để học văn hóa thị trường cổ phiếu từ StockTwits, một mạng xã hội tài chính phổ biến cho các nhà đầu tư chia sẻ ý tưởng. Nó học cực từ bằng cách dự đoán tình cảm thông điệp, sử dụng mạng lưới thần kinh. Những từ ngữ có ý nghĩa được học hỏi từ hàng chục triệu chứng khoán chứng khoán,...và đây là nghiên cứu đầu tiên có những từ ngữ tình cảm gắn kết cho thị trường chứng khoán. Các thí nghiệm dự đoán cảm xúc của nhà đầu tư cho thấy ngôn ngữ của chúng ta có thể sử dụng các ngôn ngữ khác được xây dựng bởi các phương pháp hiện đại, và véc- tơ từ ngữ có tính cảm xúc tốt hơn nhiều so với những từ ngữ chung.', 'uz': "Oldingi taʼminotlar esa, investering hissiyotlari imkoniyatlarini o'zgartirish mumkin. Name Bu qogʻozda, biz StockTwittdan aks suhbatning leksini o'rganish uchun yangi yo'l o'rganish imkoniyatlarining fikrlarini qaytarish uchun jamiyat tarmoqda. Bu xabar hissiyotini oldinga so'zlarni o'rganadi, neyural nett ish orqali foydalanish. Bu birinchi taʼminlovchi so'zlar o'zgarishga teng millionlab millionlab StockTwitt postlaridan o'rganadi. Bu birinchi o'qituvchi so'zlar quyidagi so'zlarni o'zgartiradi. Bizning elektr hissiyotning tajribalari esa Leksonimiz boshqa leksikalarni davlat usullari bilan ishga tushirilgan, va hissiyotga ega bo'lgan so'zlar vektori umumiy so'zlardan ham yaxshi edi.", 'nl': 'Eerdere studies hebben aangetoond dat indicatoren voor beleggerssentiment veranderingen in de aandelenmarkt kunnen voorspellen. Een domein-specifiek sentimentlexicon en sentiment-georiënteerd woordinbeddingsmodel zouden de sentimentanalyse in financieel domein en aandelenmarkt helpen. In dit artikel presenteren we een nieuwe benadering van het leren van aandelenlexicon van StockTwits, een populair financieel sociaal netwerk voor beleggers om ideeën te delen. Het leert woordpolariteit door het voorspellen van berichtsentiment, met behulp van een neuraal netwerk. De sentiment-georiënteerde woord embeddings zijn geleerd van tientallen miljoenen StockTwits berichten, en dit is de eerste studie die sentiment-georiënteerde woord embeddings voor de beurs presenteert. De experimenten met het voorspellen van beleggerssentiment tonen aan dat ons lexicon beter presteerde dan andere lexicons gebouwd met de state-of-the-art methoden, en dat de sentiment-georiënteerde woordvector veel beter was dan de algemene woordinbeddingen.', 'bg': 'Предишни проучвания показват, че инвеститорските сентиментални показатели могат да предвидят промените на фондовия пазар. Специфичен за домейна сентиментален лексикон и ориентиран към сентиментални думи модел за вграждане би помогнал при анализа на сентимента във финансовия домейн и фондовия пазар. В настоящата статия представяме нов подход към изучаване на лексикона на фондовия пазар от популярна финансова социална мрежа за инвеститорите да споделят идеи. Научава полярността на думите чрез предсказване на сентимента на съобщението, използвайки невронна мрежа. Сантиментално ориентираните думи се научават от десетки милиони публикации и това е първото проучване, което представя сантиментално ориентирани думи за фондовия пазар. Експериментите за прогнозиране на сентимента на инвеститорите показват, че нашият лексикон надминава други лексикони, изградени по най-съвременните методи, а ориентираният към сентимента словесен вектор е много по-добър от общите вграждания на думи.', 'da': 'Tidligere undersøgelser har vist, at investor sentiment indikatorer kan forudsige aktiemarkedsændringer. En domænespecifik sentiment leksikon og sentiment-orienteret ordindlejringsmodel vil hjælpe sentiment analyse på det finansielle område og aktiemarkedet. I denne artikel præsenterer vi en ny tilgang til at lære aktiemarkedet leksikon fra StockTwits, et populært finansielt socialt netværk for investorer at dele ideer. Den lærer ordpolaritet ved at forudsige budskabsfølelse ved hjælp af et neuralt netværk. De følelsesorienterede ord embeddings er lært fra titusinder af millioner af StockTwits indlæg, og dette er den første undersøgelse, der præsenterer følelsesorienterede ord embeddings for aktiemarkedet. Eksperimenterne med at forudsige investor sentiment viser, at vores leksikon bedre end andre lexikoner bygget af state-of-the-art metoder, og den sentiment-orienterede ordvektor var meget bedre end den generelle ordindlejring.', 'de': 'Fr羹here Studien haben gezeigt, dass Indikatoren der Anlegerstimmung Aktienmarktver瓣nderungen vorhersagen k繹nnen. Ein dom瓣nenspezifisches Sentiment-Lexikon und ein sentimentorientiertes Wort-Einbettungsmodell w羹rden die Sentiment-Analyse im Finanzbereich und am Aktienmarkt unterst羹tzen. In diesem Beitrag stellen wir einen neuen Ansatz vor, Aktienlexikon von StockTwits zu lernen, einem beliebten finanziellen sozialen Netzwerk f羹r Investoren, um Ideen auszutauschen. Es lernt Wortpolarit瓣t, indem es Nachrichtensentiment vorhersagt, indem es ein neuronales Netz verwendet. Die sentimentorientierten Wort-Einbettungen wurden aus Dutzenden Millionen von StockTwits-Beitr瓣gen gelernt, und dies ist die erste Studie, die sentimentorientierte Wort-Einbettungen f羹r den Aktienmarkt pr瓣sentiert. Die Experimente zur Vorhersage der Anlegerstimmung zeigen, dass unser Lexikon andere Lexikone 羹bertraf, die mit den modernsten Methoden erstellt wurden, und dass der sentimentorientierte Wortvektor viel besser war als die allgemeinen Worteinbettungen.', 'id': 'Previous studies have shown that investor sentiment indicators can predict stock market change.  Sebuah leksikon sentimen-spesifik domain dan model penerbangan kata sentimen-oriented akan membantu analisis sentimen di domain keuangan dan pasar saham. Dalam kertas ini, kami mempersembahkan pendekatan baru untuk belajar lexikon pasar saham dari StockTwits, jaringan sosial keuangan populer bagi investor untuk berbagi ide. Ini mempelajari polaritas kata dengan memprediksi perasaan pesan, menggunakan jaringan saraf. Pencampuran kata yang orient sentimen dipelajari dari puluhan juta pos StockTwits, dan ini adalah studi pertama yang memperkenalkan pencampuran kata yang orient sentimen untuk pasar saham. Eksperimen memprediksi perasaan investor menunjukkan bahwa leksikon kita melampaui leksikon lain yang dibangun oleh metode state-of-the-art, dan vektor kata sentiment-oriented jauh lebih baik dari pembangunan kata umum.', 'ko': '이전 연구에 따르면 투자자의 정서 지표는 주식시장의 변화를 예측할 수 있다.특정 분야의 정서 사전과 정서를 향한 단어 삽입 모델은 금융 분야와 주식시장의 정서 분석에 도움이 될 것이다.본고에서 우리는 StockTwits에서 주식시장의 어휘를 배우는 새로운 방법을 제시했다. StockTwits는 유행하는 금융 소셜네트워크서비스로 투자자들이 아이디어를 공유할 수 있다.그것은 신경 네트워크를 통해 정보 정서를 예측하여 단어의 극성을 배운다.정서지향어 삽입은 수천만 개의 StockTwits 게시물에서 배운 것으로 주식시장에 대한 정서지향어 삽입 연구는 이번이 처음이다.투자자의 정서를 예측하는 실험에 의하면 우리의 사전은 최신 방법으로 구축된 다른 사전보다 낫고 정서 가이드의 어향량은 일반적인 단어보다 훨씬 좋다.', 'hr': 'Prije ispitivanja pokazala su da indikatori osjećanja ulagača mogu predvidjeti promjenu tržišta dionica. Leksikon za posebne osjećaje domena i model uključujući riječi na osjećaj pomoći bi analizi osjećaja u financijskom domenu i tržištu dionica. U ovom papiru predstavljamo novi pristup učenju leksiona tržišta dionica iz StockTwits, popularne financijske socijalne mreže za ulagače da podijele ideje. Nauči riječ polarnost predviđajući osjećaj poruke, koristeći neuralnu mrežu. Osjećanja orijentirane riječi uče se od desetine milijuna stockTwits postova, a ovo je prva ispitivanja koja predstavlja osjećaj orijentirane riječi ugrađene za tržište dionica. Eksperimenti predviđanja osjećanja ulagača pokazuju da je naš leksikon nadmašio druge leksikone izgrađene državnim metodama umjetnosti, a vektor riječi, orijentirane na osjećaj, bio je mnogo bolji od običnih riječi.', 'af': "Vorige studie het vertoon dat investor sentimente-indikators kan voorskou staatsmarkveranderinge. 'n Domein-spesifieke sentiment lexicon en sentiment-orienteerde woord inbetering model sal help die sentiment-analisie in finansiële domein en stokkmarkte. In hierdie papier stel ons 'n nuwe toegang voor die leer van StockTwits-staatsmarkleksie van StockTwits, 'n populêre finansiële sosiale netwerk vir investorers om idees te deel. Dit leer woord polêrisiteit deur die voorskou van boodskapsentiment deur 'n neurale netwerk te gebruik. Die sentiment-orienteerde woord inbettings word geleer van tiendes van miljoene StockTwits-pos, en dit is die eerste studie wat sentiment-orienteerde woord inbettings voorsien vir stokkmarkte. Die eksperimente van die voorskou van investoreerde sentiment vertoon dat ons leksikon ander leksikone uitgevoer het deur die state-of-the-art metodes gebou, en die sentiment-orienteerde woord vektor was baie beter as die algemene woord inbettings.", 'fa': 'تحقیقات قبلی نشان داده اند که نشان\u200cدهندگان احساسات سرمایه گذاری می\u200cتوانند تغییرات بازار سرمایه گذاری را پیش بینی کنند. یک مدل تحلیل احساسات ویژه\u200cای در دومین مالی و بازار سهام کمک می\u200cکند. در این کاغذ، ما یک روش جدید برای یاد گرفتن لکسیون بازاری سهام از استوک توئیت، یک شبکه اجتماعی معروف برای سرمایه گذارندگان برای شریک ایده ها پیشنهاد می کنیم. این کلمه قطعیت را با پیش بینی کردن احساسات پیام، با استفاده از شبکه عصبی یاد می\u200cگیرد. این اولین مطالعه\u200cای است که کلمه\u200cای که به احساسات ارائه می\u200cدهند از دهها میلیون\u200cها پوست\u200cهای StockTwits یاد می\u200cگیرند، و این اولین مطالعه\u200cای است که کلمه\u200cای که به احساسات ارائه می\u200cدهند برای بازار سهام ارائه می\u200cدهند. آزمایش\u200cهای پیش\u200cبینی احساسات سرمایه\u200cگذاران نشان می\u200cدهند که زبان\u200cگذاری ما با روش\u200cهای هنر ساخته شده\u200cاند، زبان\u200cگذاری دیگر را بیشتر از کلمه\u200cهای عمومی بهتر است.', 'sq': 'Studimet e mëparshme kanë treguar se treguesit e ndjenjave të investitorit mund të parashikojnë ndryshimin e tregut të aksioneve. Një leksikon i ndjenjave specifike në domeni dhe modeli i përfshirjes së fjalëve të orientuar në ndjenja do të ndihmonte analizën e ndjenjave në domenin financiar dhe tregun e aksioneve. Në këtë letër, ne paraqesim një qasje të re për mësimin e lexikonit të tregut të aksioneve nga StockTwits, një rrjet financiar social popullor për investitorët për të ndarë ide. Mëson polaritetin e fjalës duke parashikuar ndjesinë e mesazhit, duke përdorur një rrjet nervor. Ndërtesat e fjalëve të orientuara ndaj ndjenjave mësohen nga dhjetra miliona postime të StockTwits-it dhe ky është studimi i parë që paraqet përfshirjet e fjalëve të orientuara ndaj ndjenjave për tregun e aksioneve. Eksperimentet e parashikimit të ndjenjave të investitorëve tregojnë se lexikoni ynë kaloi lexikonet e tjera të ndërtuara nga metodat më të larta, dhe vektori i fjalës me orientim ndaj ndjenjave ishte shumë më i mirë se përfshirja e fjalës së përgjithshme.', 'sw': 'Tafiti zilizopita zimeonyesha kuwa ishara za wawekezaji zinaweza kutabiri mabadiliko ya soko la misoko. Kihisia maalum cha lexico na neno linaloongozwa na hisia litasaidia uchambuzi wa hisia katika soko la kifedha na maduka. Katika karatasi hii, tunaweka mbinu mpya ya kujifunza soko la misimamo kutoka StockTwits, mtandao maarufu wa kijamii wa kifedha kwa wawekezaji kushirikiana mawazo. Inajifunza uvunjifu wa maneno kwa kutabiri hisia za ujumbe, kwa kutumia mtandao wa kijeshi. The sentiment-oriented word embeddings are learned from tens of millions of StockTwits posts, and this is the first study presenting sentiment-oriented word embeddings for stock market.  Majaribio ya kutabiri hisia za wawekezaji zinaonyesha kuwa lexico letu lilifanya vibaya vya lexico vingine vilivyojengwa na mbinu za serikali za sanaa, na vector wa neno lililoelekezwa lilikuwa bora zaidi kuliko neno la jumla lililoingizwa.', 'hy': 'Անցյալ ուսումնասիրությունները ցույց են տվել, որ ներդրողների զգացմունքների ցուցանիշները կարող են կանխատեսել արժեքների շուկայի փոփոխությունները: Բոլոր բնագավառների կոնկրետ զգացմունքների լեքսիոնը և զգացմունքների կոնկրետ բառերի ներգրավման մոդելը կօգնեն ֆինանսական բնագավառների և արժեքների զգացմունքների վերլուծությունը: Այս թղթի մեջ մենք ներկայացնում ենք մի նոր մոտեցում Ստոքթվիթսի ֆինանսական սոցիալական ցանց, որը ներդրողների համար կարող է կիսվել գաղափարներով: It learns word polarity by predicting message sentiment, using a neural net-work.  Զգացմունքներով հիմնված բառերը սովորվում են Ստոքթվիթսի տասնյակ միլիոնավոր տեղադրություններից, և սա առաջին ուսումնասիրությունն է, որը ներկայացնում է զգացմունքներով հիմնված բառեր արժեքի համար: Ներդրողների զգացմունքների կանխատեսման փորձարկումները ցույց են տալիս, որ մեր լեքսիկոնը գերազանցել է այլ լեքսիկոններ, որոնք կառուցվել են նորագույն մեթոդների միջոցով, և զգացմունքներով ուղղված բառերի վեկտորը շատ ավելի լավ էր, քան ընդհանուր բառերը:', 'tr': "Öňki araştyrmalar maňa ulagançy duýgym görkezilişi stock bazarynyň üýtgewlerini öňünden aýdyp biljekdigini görkezildi. Bir domena spesifik duygulama leksiyonu ve duygulama yönelik kelime içeri modeli mali domenin ve stok pazarında duygulama analizine yardım eder. Bu kagyzda StockTwit'dan stock bazarynyň leksiýasyny öwrenmek üçin täze bir nusga görkeýäris, ideýalary paylaşmak üçin meýhur mali sosyaly neteja. Bu mesaj duýgularyny önlemek bilen sözleriň polaritlygyny öwrenýär, näyral net işi ullanýar. Duýgun görkezilýän söz integrasy on milyonlaryň StockTwit postundan öwrenilýär. Bu ilkinji gezek stock bazarynda duýgular üçin söz integrasyny görkezýär. investor duýgularyny tahmin etmek deneylerinde biziň leksiýamyz sungat yöntemlerinden beýleki leksiýalary çykardygyny görkezýär. Şüphesiz görkezilýän sözlerimiz umumy sözlerimizden has gowydygyny görkezýär.", 'bn': 'পূর্ববর্তী গবেষণা প্রদর্শন করেছে যে বিনিয়োগকারীদের অনুভূতি নির্দেশক স্টক বাজারের পরিবর্তন ভবিষ্যত করত একটি ডোমেইন-নির্দিষ্ট অনুভূতি লেক্সিকোন এবং আবেগ-অনুভূতিপূর্ণ শব্দের মোডেল বিশ্লেষণের সাহায্য করবে অর্থনৈতিক ডোমেইন এবং স্টক এই কাগজটিতে আমরা স্টক টুইটের স্টক বাজারের লেক্সিকোন শিক্ষা শিখার একটি নতুন পদ্ধতি উপস্থাপন করেছি, যা বিনিয়োগকারীদের জন্য একটি জনপ এটা বার্তা অনুভূতি প্রত্যাখ্যান করে শব্দ দূরীতি শিখে, নিউরেল নেট-কাজ ব্যবহার করে। স্টক টুইটের পোস্ট থেকে হাজার হাজার লক্ষ লক্ষ লক্ষ শব্দের দৃষ্টিভঙ্গি শিক্ষা প্রদান করা হয়েছে এবং এটি হচ্ছে প্রথম গবেষণা যা স্টক বাজারের জন্য অনু বিনিয়োগী অনুভূতির প্রতি ভবিষ্যদ্বাণী করার পরীক্ষা দেখা যাচ্ছে যে আমাদের লেক্সিকোন রাষ্ট্র-অফ-শিল্প পদ্ধতি দ্বারা অন্যান্য লেক্সিকোন ব্যবহার করেছ', 'ca': "Els estudis anteriors han demostrat que els indicadors de sentiment dels inversors poden predir el canvi del mercat d'acció. A domain-specific sentiment lexicon and sentiment-oriented word embedding model would help the sentiment analysis in financial domain and stock market.  En aquest article, presentem un nou enfocament a l'aprenentatge del lexicó del mercat d'accions de StockTwits, una xarxa social financera popular per als inversors per compartir idees. Aprèn la paraula polaritat predint el sentiment dels missatges, utilitzant una xarxa neural. Les integracions de paraules orientades al sentiment s'aprenen de desenes de milions de posts de StockTwits, i aquest és el primer estudi que presenta integracions de paraules orientades al sentiment per al mercat d'accions. Els experiments de predir el sentiment dels inversors mostren que el nostre lexicòn va superar altres lexicòns construïts pels mètodes més avançats, i el vector de paraules orientats al sentiment era molt millor que l'incorporació de paraules generals.", 'am': 'Previous studies have shown that investor sentiment indicators can predict stock market change.  የዶሜን አካባቢ ስሜት ሊክሲን እና የስሜት አካባቢ ቃላት ሞዴል በሀብት ውይይት እና የገንዘብ ገበያ ውስጥ የሚያስተምር ይረዳል፡፡ በዚህ ፕሮግራም፣ የኢንጀራዎች አሳብ ለማጋራት የሀብት ማኅበራዊ መረብ ከስቴክTwits ለመማር አዲስ የግንኙነት ግንኙነት እናቀርባለን፡፡ የመልእክትን ስሜት በመቀበል በመጠየቅ የነጥብ መረብ በመጠቀም ቃላትን ንጹሕነት ትማራለች፡፡ የስሜት ቃላት አሥር ሚሊዮን የሚቆጠሩ StockTwitters ጽሑፎች ተማርተዋል፤ ይህም የመጀመሪያ ትምህርት የስሜት ገበያ የግንኙነት ገበያ የሚያሳየው የመጀመሪያ ትምህርት ነው፡፡ የኢንተርኔት ስሜት መሞከሪያ፣ ሌክሲኮን በአገሪካ-የ-አርጤት ሥርዓት የተሠራ ሌሎችን ሌሎችን ሊክሲኮን እንዳደረገ እና የመስማት ቃላት vector ከጠቅላላ ቃላት የሚሻል ነው፡፡', 'az': "∆Źvv…ôlki t…ôhsil g√∂st…ôrmiŇüdir ki, investor sentiment indikat√∂rl…ôrinin stock marketi d…ôyiŇüiklikl…ôrini t…ôsbit ed…ô bil…ôr. domain-specific sentiment lexicon v…ô sentiment-oriented word embedding model financial domain v…ô stock marketd…ô sentiment analizin…ô k√∂m…ôk ed…ôr. Bu kańüńĪzda StockTwits'd…ôn StockTwits'in stok pazarńĪnńĪn leksikl…ôrini √∂yr…ônm…ôk √ľ√ß√ľn yeni bir yol g√∂st…ôririk. ńįddialarńĪ paylaŇümaq √ľ√ß√ľn m…ôŇühur malik sosyal Ňü…ôb…ôk…ô. ńįsmarńĪŇü duygularńĪnńĪ t…ômin edib, n√∂ral a ńü iŇül…ôri istifad…ô edir. DuygularńĪna y√∂n…ôlmiŇü s√∂zl…ôr i√ß…ôrisind…ô on milyonlarca StockTwits m…ôlumatńĪndan √∂yr…ônirl…ôr, v…ô bu ilk √∂yr…ônm…ôkdir ki, hissl…ôr…ô y√∂n…ôlmiŇü s√∂zl…ôr stok bazarńĪna inŇüa edilir. Investor sentimentl…ôrini t…ômin etm…ôk t…ôcr√ľb…ôl…ôrind…ô g√∂st…ôr…ôn t…ôcr√ľb…ôl…ôr bizim leksiyonumuz, sanat metodlarńĪ il…ô inŇüa edilmiŇü baŇüqa leksikl…ôrd…ôn daha yaxŇüńĪ idi v…ô sentiment-oriented s√∂z vekt√∂r√ľ genel s√∂z inŇüa edilm…ôsind…ôn daha yaxŇüńĪ idi.", 'et': "Varasemad uuringud on näidanud, et investorite sentimentaalsed näitajad suudavad ennustada aktsiaturu muutusi. Domeenipõhine sentimentaalsõnavara ja sentimentaalsõnale orienteeritud sõnade manustamise mudel aitaks analüüsida sentimentaalsust finantsvaldkonnas ja aktsiaturul. Käesolevas töös tutvustame uut lähenemisviisi aktsiaturu leksikoni õppimiseks StockTwits'ist, populaarsest finantssektorilisest sotsiaalsest võrgustikust investoritele ideede jagamiseks. See õpib sõna polaarsust ennustades sõnumi tundeid, kasutades närvivõrku. Sentimentaalsed sõnade manustamised on õppinud kümnetest miljonitest StockTwitsi postitustest ja see on esimene uuring, mis tutvustab sentimentaalsed sõnade manustamist börsil. Investorite sentimentaalsuse prognoosimiseks tehtud eksperimendid näitavad, et meie sõnavara suutis ületada teisi kaasaegsete meetodite abil ehitatud leksikone ning sentimentaalne sõnavaktor oli palju parem kui üldised sõnavahedused.", 'fi': 'Aiemmat tutkimukset ovat osoittaneet, että sijoittajan tunteen indikaattorit voivat ennustaa osakemarkkinoiden muutosta. Domain-kohtainen tunnesanasto ja tunnelähtöinen sanaupotusmalli auttaisivat tunneanalyysissä rahoitusalalla ja osakemarkkinoilla. Tässä artikkelissa esittelemme uuden lähestymistavan osakemarkkinoiden sanaston oppimiseen StockTwitsistä, joka on suosittu taloudellinen sosiaalinen verkosto sijoittajille ideoiden jakamiseen. Se oppii sanan polariteetin ennustamalla viestin tunteita neuroverkon avulla. Tunteelähtöiset sanaupotukset on opittu kymmenistä miljoonista StockTwits-postauksista, ja tämä on ensimmäinen tutkimus, joka esittelee tunnelähtöisiä sanaupotuksia osakemarkkinoille. Sijoittajien tunteiden ennustamiskokeet osoittavat, että sanastomme suoriutui paremmin kuin muut nykyaikaisilla menetelmillä rakennetut sanastot, ja tunnesuuntautunut sanavektori oli paljon parempi kuin yleiset sanaupotukset.', 'bs': 'Prije studija pokazala su da indikatori osjećanja ulagača mogu predvidjeti promjenu tržišta dionica. Leksikon za posebnu domenu osjećanja i model uključenja riječi na osjećaj bi pomogao analizi osjećaja na financijskom domenu i tržištu dionica. U ovom papiru predstavljamo novi pristup učenju leksiona tržišta dionica iz StockTwita, popularne financijske socijalne mreže za ulagače da podijele ideje. Nauči riječ polarnosti predviđajući osjećaj poruke, koristeći neuralnu mrežu. Osjećanja orijentirane riječi uče se od desetine milijuna stockTwits postova, a ovo je prva studija koja predstavlja osjećaj orijentirane riječi ugrađenja na tržište dionica. Eksperimenti predviđanja osjećanja investitora pokazuju da je naš leksikon nadmašio druge leksikone izgrađene od strane nacionalnih metoda umjetnosti, a vektor riječi orijentirani na osjećaj bio mnogo bolji od općeg uključenja riječi.', 'cs': 'Předchozí studie ukázaly, že ukazatele sentimentu investorů mohou předvídat změnu akciového trhu. Doménově specifický slovník sentimentu a model vkládání slov orientovaných na sentimenty by pomohl analýze sentimentu ve finanční doméně a na akciovém trhu. V tomto příspěvku představujeme nový přístup k učení se akciového slovníku od StockTwits, populární finanční sociální sítě pro sdílení nápadů investorů. Učí se polaritu slov předpovídáním sentimentu zpráv pomocí neuronové sítě. Vložení slov orientovaných na sentimenty se naučí z desítek milionů příspěvků StockTwits, a to je první studie prezentující vkládání slov orientovaných na sentimenty pro akciový trh. Experimenty předpovědi sentimentu investorů ukazují, že náš slovník předčil ostatní slovníky vytvořené nejmodernějšími metodami a slovní vektor orientovaný na sentiment byl mnohem lepší než obecné vložení slov.', 'sk': 'Prejšnje študije so pokazale, da lahko kazalniki sentimenta vlagateljev napovedujejo spremembe borznega trga. Domensko specifičen sentimentalni leksikon in sentimentalno usmerjen model vključevanja besed bi pomagal pri analizi sentimenta na finančnem področju in borznem trgu. V tem prispevku predstavljamo nov pristop k učenju besedika borznega trga iz StockTwits, priljubljenega finančnega socialnega omrežja za vlagatelje, da delijo ideje. Z nevronsko mrežo se nauči polarnosti besed. Sentimentalno usmerjene besede se naučijo iz več deset milijonov objav StockTwits in to je prva študija, ki predstavlja sentimentalno usmerjene besede za borzni trg. Poskusi napovedovanja vlagateljskega sentimenta kažejo, da je naš leksikon presegel druge leksikone, zgrajene z najsodobnejšimi metodami, sentimentalno usmerjen besedni vektor pa je bil veliko boljši od splošnih vgradnj besed.', 'he': 'מחקרים קודמים הראו כי אינדיקטורי רגשות משקיעים יכולים לחזות שינוי בשוק המניות. למקסיקון רגשות ספציפי לתחום ומודל מילים ממוקף רגשות יעזור לניתוח הרגשות בתחום פיננסי ושוק המניות. בעיתון הזה, אנחנו מציגים גישה חדשה ללמוד לקסיקון שוק המניות מ StockTwits, רשת חברתית פיננסית פופולרית למשקעים כדי לחלוק רעיונות. הוא לומד מילה קוטביות על ידי חיזוי רגשות הודעות, באמצעות רשת עצבית. המילים המיוחדות מהרגשות נלמדות מעשרות מיליוני פרסומות של סטוקטוויטס, וזו המחקר הראשון שמציג מילים ממיוחדות מהרגשות לשוק המניות. הניסויים של חיזוי רגשות משקיעים מראים שהלקסיקון שלנו ביצע לקסיקונים אחרים שנבנו על ידי השיטות המאומנות המאומנות', 'ha': "Tayyar da zaman, sun nuna cewa indikatori masu jiɓinta ta sun iya iya gabani musanyi ga musanya na'uran shugaban. Wata sauran da aka ƙayyade domin-zaɓen leksikon da misãlin da aka zura da shi, zai taimake anayyar kalma a cikin wurãren dũkiya da kuma ma'abũta salon. Ga wannan takardan, Munã zo da wani hanyoyi na karanta leksikon a kan sokar shugabanni daga StackTuits, zuwa wurãren jamii masu jami da mataimaki wa mataimaki dõmin su share idãnun. Yana sanar da kalmar zaranci da ya yi bayani ga wani hisani da ake faɗa, yana amfani da wani shirin intake na ƙarura. Ana sanar da maganar da aka zura daga dubu dubu millionnin na matsayin StackTwitter, kuma wannan na farko da ke nuna maganar da aka origina na maganar da ke cikin buƙata. jarrabar da ke gabatar da hisia na ɗaitar ta shekara cewa leksikonmu ta samar wasu leksiya da aka samar da shi na-hanyor-na-sanar, kuma masu jiyya da maganar-na-hanyor, shi ne mafi alhẽri daga maganar ta guda.", 'jv': 'Laptop" and "Desktop A domain Nang kuwi iki, awak dhéwé ngewehi sistem anyar kanggo lemaring lewat gerejahan kanggo nggawe lanjut sabên nggo stockTwo, tambah sing popular tambah komunitas kanggo kebebasan perangkat lunak nggawe ide nggo kebebasan FindOK gambar Where\'s the reference box?', 'bo': 'སྔོན་གྱི་བརྗོད་ནས་བྱ་ཚིག་གིས་རྐྱེན་སྐྱེས་བ་དང་སྐྱེས་པའི་བརྗོད་རྗེས་སྟོན་ཡོད། A domain-specific sentiment lexicon and sentiment-oriented word embedding model would help the sentiment analysis in financial domain and stock market. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་StockTwits་ནས་གནས་སྟངས་དང་ཆ་རྐྱེན་འབྲེལ་གྱི་ཐབས་ལམ་གསར་བ་ཞིག་སྟོན་པ་ཡིན། མི་མང་གི་དང དེ་ནི་འཕྲིན་དོན་རྟོགས་པའི་སྐོར་བ་དང་སྔོན་ཚུལ་གྱི་ཐབས་ལམ་སྤྱོད་ནས་མཐུན་རྐྱེན་པ་ཤེས་ཀྱི་ཡོད། sentiment-oriented word embeddings are learned from tens of millions of StockTwits posts, and this is the first study presenting sentiment-oriented word embeddings for stock market. སྒྲུབ་གཏོང་མཁན་གྱི་སྔོན་སྒྲིག་གི་ཐབས་ལམ་དེ་ང་ཚོའི་གཟུགས་རིས་ལབ་ཀྱི་གཟུགས་རིས་གཞན་ལས་ཕན་ཐོགས་བྱས་མྱོང་བ་ཡིན་པས།'}
{'en': 'Idea density for predicting Alzheimer’s disease from transcribed speech', 'ar': 'كثافة الفكرة للتنبؤ بمرض الزهايمر من الكلام المنسوخ', 'es': 'Densidad de ideas para predecir la enfermedad de Alzheimer a partir del habla transcrita', 'pt': 'Densidade de ideias para prever a doença de Alzheimer a partir da transcrição da fala', 'fr': "Densité d'idées pour prédire la maladie d'Alzheimer à partir d'un discours transcrit", 'ja': '転写音声からアルツハイマー病を予測するためのアイデア密度', 'zh': '以转录言占阿尔茨海默病之心密度', 'hi': 'लिखित भाषण से अल्जाइमर रोग की भविष्यवाणी करने के लिए विचार घनत्व', 'ru': 'Плотность идей для прогнозирования болезни Альцгеймера по транскрибируемой речи', 'ga': 'Dlús smaointe chun galar Alzheimer a thuar ó chaint thras-scríofa', 'ka': 'იდეა სიგრძნობა, რომელიც ალცჰეიმერის სიგრძნობას ტრანსკრიბული საუბრიდან წინასწორებლად', 'hu': 'Az Alzheimer-kór előrejelzésére szolgáló ötletsűrűség az átírt beszédből', 'el': 'Πυκνότητα ιδεών για την πρόβλεψη της νόσου Αλτσχάιμερ από την μεταγραφή ομιλίας', 'it': "Densità dell'idea per predire la malattia di Alzheimer dal discorso trascritto", 'mk': 'Густината на идејата за предвидување на Алцхајмеровата болест од транскриптираниот говор', 'lt': 'Alzheimerio ligos prognozavimo iš transkriptos kalbos tankis', 'kk': 'Альцхаймердің ауруының ауруының ауруынан алдындағы идеяның жиілігі', 'mt': 'Densità ta’ ideat għat-tbassir tal-marda ta’ Alzheimer mid-diskors trasskritt', 'ml': 'അലസ്ഹീമെരിന്റെ രോഗം പ്രവചിക്കുന്നതിനുള്ള ആശയം', 'ms': 'Kepadatan idea untuk meramalkan penyakit Alzheimer dari ucapan yang ditulis', 'no': 'Idedensitet for å foregå Alzheimer s sykdom frå transkripte tale', 'mn': 'Альцхаймерийн өвчнийг бичсэн яриагаас таамаглах', 'ro': 'Densitatea ideilor pentru predicția bolii Alzheimer din discursul transcris', 'pl': 'Gęstość pomysłu do przewidywania choroby Alzheimera z transkrypcji mowy', 'sr': 'Gubitnost ideje za predviđanje Alzheimerove bolesti od prepisanog govora', 'si': 'අල්ස්හායිමර්ගේ රෝගය ප්\u200dරශ්නය කරලා තියෙන්නේ අදහස් ගැන', 'sv': 'Idédensitet för att förutsäga Alzheimers sjukdom från transkriberat tal', 'so': 'Fiidka culus ee la sii sheegayo cudurka Alzheimer oo ka soo qoray hadal qoran', 'ta': 'அல்சைமரின் நோயை முன்வாக்குவதற்கான எண்ணிக்கையின் கடினம் எழுதப்பட்ட பேச்சிலிருந்து', 'ur': 'الزجیمر کی بیماری کی پیش آنے کے لئے ایڈیو گھاٹی ہے لکھی ہوئی بات سے', 'uz': "Alzheimer kasalligini ko'rib chiqish uchun qiyin", 'vi': 'Mật độ ý tưởng để dự đoán bệnh Alzheimer từ tiếng nói được ghi lại', 'da': 'Idétæthed til at forudsige Alzheimers sygdom fra transkriberat tale', 'hr': 'gustina ideje za predviđanje Alzheimerove bolesti iz prepisanog govora', 'bg': 'Плътност на идеите за предсказване на болестта на Алцхаймер от транскриптирана реч', 'de': 'Ideendichte zur Vorhersage der Alzheimer-Krankheit aus transkribierter Sprache', 'id': 'Kepadatan ide untuk memprediksikan penyakit Alzheimer dari pidato transkrip', 'ko': '녹음 음성으로 알츠하이머병의 이상 밀도를 예측하다', 'nl': 'Ideumdichtheid voor het voorspellen van de ziekte van Alzheimer op basis van getranscribeerde spraak', 'tr': 'Alzheimeryň hastalanyny ýazylýan çykyşyndan öňündirmek üçin ideýa ýigrenlik', 'fa': 'تفاوت ایده برای پیش بینی بیماری الزایمر از سخنرانی نوشته شده', 'sw': 'Uzungumzo wa mawazo kwa kutabiri ugonjwa wa Alzheimer kutokana na hotuba iliyoandikwa', 'af': 'Idee densiteit vir voorskou van Alzheimer se siekte van transkripteerde spreek', 'sq': 'Densiteti i ideve për parashikimin e s ëmundjes së Alzheimerit nga fjalimi i transkriptuar', 'hy': 'Ալցհեյմերի հիվանդության կանխատեսման գաղափարի խտությունը', 'bn': 'আলজেমারের রোগের ভবিষ্যদ্বাণী করার চিন্তার গভীর গভীর', 'am': 'የአልዝheimer ድምፅ ከጽሑፍ ንግግር ለመቀበል የአሳብ ድካም', 'cs': 'Hustota myšlenek pro predikci Alzheimerovy choroby z přepisované řeči', 'bs': 'Gubitnost ideje za predviđanje Alzheimerove bolesti iz prepisanog govora', 'ca': "La densitat d'idees per predir la malaltia d'Alzheimer a partir del discurs transcrit", 'et': 'Idee tihedus Alzheimeri tõve prognoosimiseks transkribeeritud kõnest', 'fi': 'Ideatiheys Alzheimerin taudin ennustamiseen kirjoitetusta puheesta', 'az': '䅬穨敩浥爠桡獴慬쒱쒟쒱滄넠祡竄녬淄뇅鼠猠쎶穬즙牤즙渠쎶祲즙湭즙欠쎼쎧쎼渠楤敹愠祯硬畱污狄넊', 'ha': 'Gaskiya wa idãnun ya yi bayani ga aikin Alzheimar daga magana wanda aka rubũta', 'he': "Idea density for predicting Alzheimer's disease from transcribed speech", 'sk': 'Gostota idej za napovedovanje Alzheimerjeve bolezni iz prepisanega govora', 'jv': 'Denlhe sampeyan kanggo ngerasai usul Aldhejer', 'bo': "འབྲིས་བཀོད་པའི་སྐད་བརྗོད་ནང་གི་Alzheimer's disease་རྒྱུན་ལྡན་གྱི་གསལ་བཤད་ཆེན་པོ་ཞིག་དང་།"}
{'en': 'Idea Density (ID) measures the rate at which ideas or elementary predications are expressed in an utterance or in a text. Lower ID is found to be associated with an increased risk of developing Alzheimer’s disease (AD) (Snowdon et al., 1996 ; Engelman et al., 2010). ID has been used in two different versions : propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideasa feature characteristic to AD speech. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8.', 'ar': 'تقيس كثافة الفكرة (ID) معدل التعبير عن الأفكار أو التنبؤات الأولية في كلام أو في نص. تم العثور على معرفات أقل مرتبطة بزيادة مخاطر الإصابة بمرض الزهايمر (سنودون وآخرون ، 1996 ؛ إنجلمان وآخرون ، 2010). تم استخدام المعرف في نسختين مختلفتين: كثافة الفكرة المقترحة (PID) تحسب الأفكار المعبر عنها ويمكن تطبيقها على أي نص بينما تحسب كثافة الفكرة الدلالية (SID) وحدات محتوى المعلومات المحددة مسبقًا وهي قابلة للتطبيق بشكل طبيعي على المجالات المعيارية ، مثل كمهام وصف الصورة. في هذه الورقة ، قمنا بتطوير DEPID ، وهي طريقة جديدة تعتمد على التبعية لحساب PID ، ونسختها DEPID-R التي تمكن من استبعاد الأفكار المتكررة - وهي خاصية مميزة للكلام AD. نجري المقارنة الأولى بين PID و SID المستخرجين تلقائيًا في مهمة التصنيف التشخيصي على مجموعتي بيانات AD مختلفتين تغطي كل من مجالات الموضوع المغلق والاستدعاء المجاني. بينما يعمل SID بشكل أفضل على مجموعة البيانات المعيارية ، تؤدي إضافة PID إلى تحسن صغير ولكنه مهم (+1.7 درجة F). في مجموعة البيانات ذات الموضوع المجاني ، يعمل PID بشكل أفضل من SID كما هو متوقع (77.6 مقابل 72.3 في درجة F) ولكن إضافة الميزات المشتقة من كلمة التضمين العنقودية الكامنة وراء SID التلقائي يزيد النتائج بشكل كبير ، مما يؤدي إلى درجة F تبلغ 84.8 .', 'pt': 'A Densidade de Ideia (ID) mede a taxa na qual ideias ou predicações elementares são expressas em um enunciado ou em um texto. A DI mais baixa está associada a um risco aumentado de desenvolver a doença de Alzheimer (DA) (Snowdon et al., 1996; Engelman et al., 2010). O ID tem sido usado em duas versões diferentes: a densidade de ideia proposicional (PID) conta as ideias expressas e pode ser aplicada a qualquer texto enquanto a densidade de ideia semântica (SID) conta unidades de conteúdo de informação pré-definidas e é naturalmente mais aplicável a domínios normativos, como como tarefas de descrição de imagem. Neste artigo, desenvolvemos o DEPID, um novo método baseado em dependência para calcular o PID, e sua versão DEPID-R que permite excluir ideias repetidas – um recurso característico da fala do AD. Conduzimos a primeira comparação de PID e SID extraídos automaticamente na tarefa de classificação de diagnóstico em dois conjuntos de dados AD diferentes, abrangendo domínios de tópico fechado e de recall livre. Embora o SID tenha um desempenho melhor no conjunto de dados normativo, a adição de PID leva a uma melhoria pequena, mas significativa (+1,7 F-score). No conjunto de dados de tópico livre, o PID tem um desempenho melhor do que o SID como esperado (77,6 vs 72,3 no F-score), mas adicionar os recursos derivados do agrupamento de incorporação de palavras subjacente ao SID automático aumenta consideravelmente os resultados, levando a um F-score de 84,8 .', 'es': 'La densidad de ideas (ID) mide la velocidad a la que las ideas o las predicaciones elementales se expresan en un enunciado o en un texto. Se ha descubierto que una menor ID está asociada con un mayor riesgo de desarrollar la enfermedad de Alzheimer (EA) (Snowdon et al., 1996; Engelman et al., 2010). La identificación se ha utilizado en dos versiones diferentes: la densidad de ideas proposicionales (PID) cuenta las ideas expresadas y se puede aplicar a cualquier texto, mientras que la densidad de ideas semánticas (SID) cuenta las unidades de contenido de información predefinidas y, naturalmente, es más aplicable a los dominios normativos, como las tareas de descripción de imágenes. En este artículo, desarrollamos DEPID, un novedoso método basado en dependencias para calcular PID, y su versión DEPID-R que permite excluir ideas repetidas, una característica característica del habla de AD. Llevamos a cabo la primera comparación de PID y SID extraídos automáticamente en la tarea de clasificación de diagnóstico en dos conjuntos de datos de AD diferentes que cubren tanto dominios de tema cerrado como de recuperación libre. Si bien el SID funciona mejor en el conjunto de datos normativos, agregar PID conduce a una mejora pequeña pero significativa (+1.7 F score). En el conjunto de datos de tema libre, el PID funciona mejor que el SID como se esperaba (77,6 frente a 72,3 en la puntuación F), pero la adición de las características derivadas de la agrupación de incrustación de palabras subyacente al SID automático aumenta los resultados considerablemente, lo que lleva a una puntuación F de 84,8.', 'fr': "La densité des idées (ID) mesure la vitesse à laquelle les idées ou les prédications élémentaires sont exprimées dans un énoncé ou dans un texte. Une diminution de la DI est associée à un risque accru de développer la maladie d'Alzheimer (MA) (Snowdon et al., 1996\xa0; Engelman et al., 2010). L'ID a été utilisé dans deux versions différentes\xa0: la densité des idées propositionnelles (PID) compte les idées exprimées et peut être appliquée à n'importe quel texte tandis que la densité des idées sémantiques (SID) compte les unités de contenu d'information prédéfinies et est naturellement plus applicable aux domaines normatifs, tels que les tâches de description d'images. Dans cet article, nous développons DEPID, une nouvelle méthode basée sur la dépendance pour calculer le PID, et sa version DEPID-R qui permet d'exclure les idées répétitives, une caractéristique caractéristique de la parole AD. Nous effectuons la première comparaison du PID et du SID extraits automatiquement dans la tâche de classification diagnostique sur deux ensembles de données AD différents couvrant à la fois les domaines de sujet fermé et de rappel libre. Alors que SID fonctionne mieux sur l'ensemble de données normatives, l'ajout de PID entraîne une amélioration faible mais significative (score F +1,7). Sur l'ensemble de données gratuit, PID fonctionne mieux que SID comme prévu (77,6 contre 72,3 dans le score F) mais l'ajout des caractéristiques dérivées du clustering d'intégration de mots sous-jacent au SID automatique augmente considérablement les résultats, ce qui conduit à un score F de 84,8.", 'ja': 'アイデア密度（ ID ）は、アイデアまたは基本的な述語が発話またはテキストで表現される速度を測定します。 下方ＩＤは、アルツハイマー病（ ＡＤ ）を発症するリスクの増加と関連付けられることが見出される（ Ｓｎｏｗｄｏｎ ｅ ｔ ａ ｌ ． ， １ ９ ９ ６ ； Ｅｎｇｅｌｍａｎ ｅ ｔ ａ ｌ ． ， ２ ０ １ ０ ）。 IDは、２つの異なるバージョンで使用されている：命題アイデア密度（ PID ）は、表現されたアイデアをカウントし、任意のテキストに適用することができ、セマンティックアイデア密度（ SID ）は、事前定義された情報コンテンツ単位をカウントし、画像記述タスクなどの規範的ドメインに自然により適用可能である。 本稿では、PIDを計算するための新規の依存性ベースの方法であるDEPIDと、ADスピーチの特徴である繰り返しアイデアを除外できるDEPID - Rのバージョンを開発した。 クローズドトピックドメインとフリーリコールドメインの両方をカバーする2つの異なるADデータセットの診断分類タスクで、自動抽出されたPIDとSIDの最初の比較を行います。 SIDは規範的データセットでより優れたパフォーマンスを発揮するが、PIDを追加すると、小さいが有意な改善につながる（+1.7 Fスコア）。 フリートピックのデータセットでは、PIDは予想されるようにSIDよりも優れたパフォーマンスを発揮します（ Fスコアでは77.6対72.3 ）が、自動SIDの基礎となる単語埋め込みクラスタリングに由来する機能を追加すると、結果が大幅に増加し、Fスコアは84.8になります。', 'zh': '意密度(ID)量心本谓词语本之速率也。 视其下ID与患阿尔茨海默病(AD)风险增(Snowdon等,1996。 Engelman等,2010)。 ID已施于二本:命题心密度(PID)计心,可施于文本,而语义心密度(SID)计预定义之信息内容单元,自适于规模领域,如图片述事。 本文开DEPID,一本新型PID算,版本DEPID-R能排复意 - 此AD语音之征也。 余于诊分之中AD两端自取PID与SID首较,涵盖封闭主题及自由召回域。 虽 SID 于规数集上者尤善,而加 PID 则小而著者改(+1.7 F 分数)。 其自由主题数集上,PID优于期SID(F分为77.6,F分为72.3),而从自SID后词销聚之类大加,F分为84.8。', 'hi': 'Idea Density (ID) उस दर को मापता है जिस पर विचारों या प्राथमिक predications को एक उच्चारण में या एक पाठ में व्यक्त किया जाता है। लोअर आईडी को अल्जाइमर रोग (एडी) (स्नोडन एट अल। एंगेलमैन एट अल., 2010)। आईडी का उपयोग दो अलग-अलग संस्करणों में किया गया है: प्रस्तावात्मक विचार घनत्व (पीआईडी) व्यक्त विचारों की गणना करता है और इसे किसी भी पाठ पर लागू किया जा सकता है जबकि शब्दार्थ विचार घनत्व (एसआईडी) पूर्व-परिभाषित जानकारी सामग्री इकाइयों की गणना करता है और स्वाभाविक रूप से मानक डोमेन पर अधिक लागू होता है, जैसे कि चित्र विवरण कार्य। इस पेपर में, हम DEPID, पीआईडी कंप्यूटिंग के लिए एक उपन्यास निर्भरता-आधारित विधि विकसित करते हैं, और इसका संस्करण DEPID-R जो दोहराए जाने वाले विचारों को बाहर करने में सक्षम बनाता है- एडी भाषण के लिए एक विशेषता विशेषता। हम दो अलग-अलग एडी डेटासेट पर नैदानिक वर्गीकरण कार्य में स्वचालित रूप से निकाले गए पीआईडी और एसआईडी की पहली तुलना करते हैं जो बंद-विषय और फ्री-रिकॉल डोमेन दोनों को कवर करते हैं। जबकि SID मानक डेटासेट पर बेहतर प्रदर्शन करता है, पीआईडी जोड़ने से एक छोटे लेकिन महत्वपूर्ण सुधार (+ 1.7 एफ-स्कोर) की ओर जाता है। फ्री-टॉपिक डेटासेट पर, पीआईडी अपेक्षित रूप से SID से बेहतर प्रदर्शन करता है (F-स्कोर में 77.6 बनाम 72.3) लेकिन स्वचालित SID के अंतर्निहित एम्बेडिंग क्लस्टरिंग शब्द से व्युत्पन्न सुविधाओं को जोड़ने से परिणाम काफी बढ़ जाते हैं, जिससे 84.8 का एफ-स्कोर होता है।', 'ru': 'Idea Density (ID) измеряет скорость, с которой идеи или элементарные предсказания выражаются в высказывании или тексте. Установлено, что более низкий ИД связан с повышенным риском развития болезни Альцгеймера (АД) (Snowdon et al., 1996; Engelman et al., 2010). Идентификатор был использован в двух различных версиях: предлагаемая плотность идеи (PID) подсчитывает выраженные идеи и может быть применена к любому тексту, в то время как семантическая плотность идеи (SID) подсчитывает предопределенные единицы информационного содержания и, естественно, более применима к нормативным доменам, таким как задачи описания изображения. В данной работе мы разрабатываем DEPID, новый метод вычисления PID на основе зависимостей, и его версию DEPID-R, которая позволяет исключить повторяющиеся идеи - особенность, характерная для речи AD. Мы проводим первое сравнение автоматически извлеченных PID и SID в задаче диагностической классификации на двух разных наборах данных AD, охватывающих как закрытые тематические, так и свободные области повторного вызова. В то время как SID работает лучше на нормативном наборе данных, добавление PID приводит к небольшому, но значительному улучшению (+1,7 F-балла). На наборе данных произвольной тематики PID работает лучше, чем SID, как и ожидалось (77,6 против 72,3 в F-оценке), но добавление признаков, полученных из кластеризации встраивания слов, лежащей в основе автоматического SID, значительно увеличивает результаты, что приводит к F-оценке 84,8.', 'ga': 'Tomhaiseann Dlús Smaointe (ID) an ráta ag a gcuirtear smaointe nó buntuartha in iúl i bhfocail nó i dtéacs. Faightear amach go bhfuil baint ag ID níos ísle le baol méadaithe galar Alzheimer (AD) a fhorbairt (Snowdon et al., 1996; Engelman et al., 2010). Baineadh úsáid as an ID in dhá leagan éagsúla: comhaireamh dlús smaointe tairgí (PID) na smaointe a cuireadh in iúl agus is féidir é a chur i bhfeidhm ar aon téacs agus comhaireamh dlús smaointe shéimeantach (SID) aonaid ábhair faisnéise réamhshainithe agus go nádúrtha tá sé níos infheidhme maidir le fearainn normatacha, mar sin mar thascanna cur síos pictiúr. Sa pháipéar seo, forbróimid DEPID, modh spleáchais úrnua chun PID a ríomh, agus a leagan DEPID-R a chuireann ar ár gcumas smaointe athfhillteacha a eisiamh — gné atá saintréith de chuid cainte AD. Déanaimid an chéad chomparáid idir PID agus SID a bhaintear go huathoibríoch sa tasc aicmithe diagnóiseach ar dhá thacar sonraí AD éagsúla a chlúdaíonn réimsí ábhar dúnta agus réimsí saorghlao araon. Cé go bhfeidhmíonn SID níos fearr ar an tacar sonraí normatacha, má chuirtear PID leis an bhfeabhas beag ach suntasach (+1.7-scór F). Ar an tacar sonraí saor in aisce, feidhmíonn PID níos fearr ná SID mar a bhíothas ag súil leis (77.6 vs 72.3 i scór F) ach má chuirtear na gnéithe a dhíorthaítear ón gcnuasach leabú focal atá mar bhunús leis an uathoibríoch SID méadaítear na torthaí go mór, rud a fhágann go bhfuil F-scór 84.8 ann. .', 'hu': 'Az ötletsűrűség (ID) azt a sebességet méri, amelyen az ötletek vagy elemi jóslatok kifejeződnek egy kimondásban vagy egy szövegben. Az alacsonyabb azonosítószám az Alzheimer-kór (AD) kialakulásának fokozott kockázatával jár (Snowdon et al., 1996; Engelman et al., 2010). Az azonosítót két különböző változatban használták: a propozicionális ötletsűrűség (PID) számolja a kifejezett ötleteket és bármilyen szövegre alkalmazható, míg a szemantikus ötletsűrűség (SID) számolja az előre definiált információtartalmi egységeket és természetesen inkább alkalmazható normatív tartományokra, mint például a kép leírási feladatokra. Ebben a tanulmányban fejlesztjük ki a PID számítására szolgáló új, függőségi alapú módszert, a DEPID-R verziót, amely lehetővé teszi az ismétlődő ötletek kizárását, amelyek az AD beszéd jellemzői. A diagnosztikai osztályozási feladat során az automatikusan kivont PID és SID első összehasonlítását két különböző AD adatkészleten végezzük, amelyek mind a zárt témakörű, mind a szabad visszahívású tartományokat lefedik. Míg a SID jobban teljesít a normatív adatkészleten, a PID hozzáadása kis, de jelentős javulást eredményez (+1,7 F pontszám). A szabad témakörű adatkészleten a PID a vártnál jobban teljesít, mint a SID (77,6 vs 72,3 F pontszámban), de az automatikus SID mögötti fürtözésből származó funkciók hozzáadása jelentősen növeli az eredményeket, ami 84,8 F pontszámot eredményez.', 'el': 'Η πυκνότητα ιδεών (ID) μετρά τον ρυθμό με τον οποίο οι ιδέες ή οι στοιχειώδεις προβλέψεις εκφράζονται σε μια ομιλία ή σε ένα κείμενο. Η χαμηλότερη αναγνωριστική ικανότητα φαίνεται να σχετίζεται με αυξημένο κίνδυνο ανάπτυξης νόσου Αλτσχάιμερ (AD) (Σνόουντον et al., 1996; Engelman et al., 2010). Το ID έχει χρησιμοποιηθεί σε δύο διαφορετικές εκδόσεις: η πυκνότητα προτάσεων (PID) μετρά τις εκφρασμένες ιδέες και μπορεί να εφαρμοστεί σε οποιοδήποτε κείμενο, ενώ η σημασιολογική πυκνότητα ιδεών (SID) μετρά προκαθορισμένες μονάδες περιεχομένου πληροφοριών και είναι φυσικά πιο εφαρμόσιμη σε κανονιστικούς τομείς, όπως εργασίες περιγραφής εικόνων. Σε αυτή την εργασία, αναπτύσσουμε μια νέα μέθοδο για τον υπολογισμό του και την έκδοση του που επιτρέπει να αποκλείεται η επανάληψη ιδεών – χαρακτηριστικό χαρακτηριστικό της ομιλίας του. Πραγματοποιούμε την πρώτη σύγκριση των αυτόματα εξαγόμενων PID και SID στην εργασία διαγνωστικής ταξινόμησης σε δύο διαφορετικά σύνολα δεδομένων που καλύπτουν τόσο τους τομείς κλειστού θέματος όσο και τους τομείς ελεύθερης ανάκλησης. Ενώ η SID αποδίδει καλύτερα στο κανονιστικό σύνολο δεδομένων, η προσθήκη PID οδηγεί σε μια μικρή αλλά σημαντική βελτίωση (+1.7 Φ-βαθμολογία). Στο σύνολο δεδομένων ελεύθερου θέματος, το PID αποδίδει καλύτερα από το SID όπως αναμενόταν (77.6 vs 72.3 σε βαθμολογία F), αλλά η προσθήκη των χαρακτηριστικών που προέρχονται από τη λέξη ενσωμάτωση ομαδοποίησης που υποκείμει στην αυτόματη SID αυξάνει σημαντικά τα αποτελέσματα, οδηγώντας σε μια βαθμολογία Φ 84.8.', 'ka': 'Idea Density (ID) მოზემის სიმაღლე, რომელიც იდეები ან ელემენტური პრედიციები გამოსახულებულია სიტყვაში ან ტექსტიში. ჩვენ აღმოჩნდება, რომ საკუთარი ინდენტიფიკაცია ალცჰეიმერის დაავადება (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID გამოყენებულია ორი განსხვავებული ვერსიებში: პროგრამეტური იდეების ცნობიერება (PID) გამოყენებული იდეების ცნობიერებაში და შეიძლება გამოყენება ყველა ტექსტისთვის, როცა სემონტიკური იდეების ცნობიერება (SID) წინ განსაზღვრებული ინ ამ დომენტში, ჩვენ DEPID-ს განვითარებთ, პრომენტის დასადარებულება PID-ს კომპიუტერებისთვის და მისი ვერსია DEPID-R, რომელიც შეუძლია ახლა ახლა განვითარებას იდეების განსაკუთრების პ ჩვენ ავტომატურად გამოყენებული PID და SID-ის პირველი შემდგომარება დიაგონტიკური კლასიფიკაციის რაოდენობაში ორი განსხვავებული AD მონაცემების კონფიკაციის ორივე დახურებული ტემების და თავის SID ნორმატიგური მონაცემების კონფიგურაციაში უკეთესი გავაკეთება, PID დამატება იქნება პატარა, მაგრამ მნიშვნელოვანი გაუკეთება (+1. 7 F- score). თავისუფალი ტემენტის მონაცემების კონფიგურაციაში PID უფრო მეტი გავაკეთება SID-ზე (77.6 vs 72.3 F-score-ში) მაგრამ დამატება სიტყვებით დამატებული სიტყვებით დამატებული სიტყვებით, რომელიც ავტომატიკური SID-ზე დამატებული, გავაკ', 'lt': 'Idėjų tankis (ID) matuoja idėjų ar elementinių predikacijų išraiškos išraiškoje arba tekste greitį. Nustatyta, kad mažesnis identifikavimo rodiklis yra susijęs su padidėjusia Alzheimerio ligos (AD) išsivystymo rizika (Snowdon et al., 1996; Engelman et al., 2010). ID buvo naudojamas dviem skirtingomis versijomis: siūlomas idėjų tankis (PID) skaičiuoja išreikštas idėjas ir gali būti taikomas bet kuriam tekstui, o semantinis idėjų tankis (SID) skaičiuoja iš anksto apibrėžtus informacijos turinio vienetus ir yra natūraliai labiau taikomas normatyvioms sritims, pvz., vaizdo aprašymo užduotims. Šiame dokumente mes parengiame DEPID, naują priklausomybės grindžiamą PID apskaičiavimo metodą, ir jo versiją DEPID-R, kuri leidžia atmesti kartotines idėjas – AD kalbos ypatybę. Pirmą kartą atliekame automatiškai ištrauktų PID ir SID palyginimą atliekant diagnostinės klasifikacijos užduotį dviejuose skirtinguose AD duomenų rinkiniuose, apimančiuose tiek uždarą temą, tiek nemokamą atšaukimą. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score).  Be temos duomenų rinkinyje PID veikia geriau nei tikėtasi SID (77,6 palyginti su 72,3 F balais), tačiau papildant savybes, gautas iš žodžio įterpimo klasterizavimo, kuriame grindžiamas automatinis SID, rezultatai gerokai padidėja, todėl F balas yra 84,8.', 'kk': 'Идея жиілігі (ID) идеялар немесе элементтерлік предикациялардың сөздерде немесе мәтінде көрсетілетін жылдамдығын есептеп береді. Төменгі идентификаторы Альцгеймер ауруының (AD) (Snowdon et al., 1996; Engelman et al., 2010) көбірек қауіпсіздігімен байланысты. Идентификатор екі түрлі нұсқанда қолданылды: келтірілген идеяның жиілігі (PID) келтірілген идеяны есептеп, семантикалық идеяның жиілігі (SID) алдында анықталған мәліметтің мазмұнының бірлігін есептеп, нормативті домендерге қолданыла Бұл қағазда, біз DEPID, PID есептеу үшін романдық тәуелдік негізінде тәуелдік тәсілді және оның DEPID-R нұсқасы, ол AD сөйлесу үшін идеяларды қайталау мүмкіндігін өзгертуге мүмкіндік Біз автоматты түрде PID және SID тарқатын алғашқы салыстырып, диагностикалық салыстыру тапсырмасында, жабылған нақышты және бос қайталану домендерінің екі түрлі AD деректер жиындарында болады. SID нормативтік деректер жинағында жақсы жұмыс істегенде, PID қосу үшін кішкентай, бірақ маңызды жақсарту (+1, 7 F- нөмірі) болады. Бос нақышты деректер жиында PID күтпеген SID- ден жақсы жұмыс істейді (77, 6 және 72, 3 және F- нөмірінде) бірақ автоматты SID- нәтижелерін автоматты түрде ендіру керек сөздерді қосу үшін, F- нөміріне 84, 8 деп өтеді.', 'it': "La densità dell'idea (ID) misura la velocità con cui le idee o le predizioni elementari sono espresse in un'espressione o in un testo. L'ID inferiore è stato trovato per essere associato ad un aumentato rischio di sviluppare la malattia di Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). L'ID è stato utilizzato in due versioni diverse: la densità proposizionale dell'idea (PID) conta le idee espresse e può essere applicata a qualsiasi testo mentre la densità semantica dell'idea (SID) conta le unità di contenuto delle informazioni predefinite ed è naturalmente più applicabile a domini normativi, come le attività di descrizione delle immagini. In questo articolo, sviluppiamo DEPID, un nuovo metodo basato sulle dipendenze per il calcolo del PID, e la sua versione DEPID-R che consente di escludere idee ripetute, una caratteristica caratteristica del discorso AD. Eseguiamo il primo confronto tra PID e SID estratti automaticamente nell'attività di classificazione diagnostica su due diversi set di dati AD che coprono sia domini a tema chiuso che a richiamo libero. Mentre SID si comporta meglio sul set di dati normativi, l'aggiunta di PID porta ad un piccolo ma significativo miglioramento (+1,7 F-score). Sul set di dati free-topic, PID funziona meglio del SID come previsto (77,6 vs 72,3 in F-score), ma aggiungendo le caratteristiche derivate dalla parola embedding clustering sottostante il SID automatico aumenta notevolmente i risultati, portando a un F-score di 84,8.", 'mk': 'Гензитетот на идеите (ИД) ја мери стапката со која идеите или елементарните предикации се изразени во израз или текст. Пониската идентификација е поврзана со зголемениот ризик за развој на Алцхајмеровата болест (АД) (Snowdon et al., 1996; Engelman et al., 2010). ИД е употребен во две различни верзии: густината на предложните идеи (PID) ги брои изразените идеи и може да се примени на било кој текст додека густината на семантичните идеи (SID) ги брои преддефинираните информации и е природно поприменлива за нормативните домени, како што се задачите за опис на сликата. Во овој весник развиваме ДЕПИД, нов метод заснован на зависност за компјутерирање на ПИД, и нејзината верзија ДЕПИД-Р што овозможува да се исклучи повторувањето на идеите - карактеристика на говорот на АД. Правиме прва споредба на автоматски извадени ПИД и СИД во дијагностичката класификација задача на две различни податоци на АД кои покриваат и затворени теми, и слободни домени за повлекување. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score).  Во групата на податоци со слободна тема, ПИД изведува подобри резултати од СИД како што се очекува (77,6 во однос на 72,3 во Ф-оценка), но додавањето на карактеристиките изведени од зборот вклопување групирање под автоматски СИД значително ги зголемува резултатите, што води до Ф-оценка од 84', 'mn': 'Idea Density (ID) Хамгийн бага ID нь Alzheimer өвчнийг хөгжүүлэх эрсдэлтэй холбогдож байна (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID хоёр өөр хувилбарт хэрэглэгдсэн: санааны жинтэй (PID) нь илэрхийлэгдсэн санаануудыг тооцоолж чадна. Симпатик санааны жинтэй (SID) нь илэрхийлэгдсэн мэдээллийн хэмжээний нэгжүүдийг тооцоолж чадна. Харин зураг тайлбарлах үйл ажиллагаатай адилхан байдаг. Энэ цаасан дээр бид DEPID, PID тооцоолох шинэ хамаарал хамааралтай арга болон DEPID-R хувилбарыг хөгжүүлнэ. Энэ нь AD илтгэлийг давтах боломжтой. Бид хоёр өөр AD өгөгдлийн сангийн хоёр төрлийн ДОХ болон ДОХ-ыг автоматаар автоматжуулсан PID болон SID-г автоматжуулах анхны харьцуулалт хийдэг. SID нь норматив өгөгдлийн сан дээр илүү сайн ажилладаг ч PID нэмэх нь жижиг, гэхдээ чухал сайжруулах боломжтой (+1.7 F-score) юм. Хэрэггүй сэдвийн өгөгдлийн сан дээр PID нь хүлээн зөвхөн SID-ээс илүү сайн үйлдвэрлэж байна (77.6 vs 72.3 F-score дээр) гэхдээ автоматжуулагч SID-ын доор автоматжуулагч хэлбэрээс автоматжуулагч хэлбэрээс гарсан зүйлсийг нэмэх нь үр дүнг маш их нэмэгдүүлнэ. F', 'ml': 'ഐഡിയ (ഐഡി) വാക്കിലോ വാക്കിലോ പദാവലിയിലോ ആശയങ്ങളോ മൂലപ്രഖ്യാപനങ്ങളോ പ്രസ്താവിക്കുന്ന വ്യത്യാസങ്ങള്\u200d അളവി അല്\u200dസ്ഹീമെരിന്\u200dറെ രോഗം വളര്\u200dന്നുപോകുന്നതിന്\u200dറെ അപകടത്തോട് കൂടുതല്\u200d കൂടുതല്\u200d അപകടത്തോട് താഴെ ഐഡിയില്\u200d ബന്ധപ്പെടുന്നതായി കണ്ടെത രണ്ടു വ്യത്യസ്ത വിഭാഗങ്ങളില്\u200d ഐഡി ഉപയോഗിച്ചിരിക്കുന്നു: പ്രൊച്ചഷന്\u200d ഐഡിയ ആശയങ്ങളുടെ തെളിവ് എണ്ണിയിരിക്കുന്നു. ഏതെങ്കിലും ടെക്സ്റ്റില്\u200d പ്രയോഗിക്കുന്നു. സെമാന്റ ഈ പത്രത്തില്\u200d, നമ്മള്\u200d DEPID, പിഐഡി കണക്ട് ചെയ്യുന്നതിനുള്ള നോവല്\u200d ആശ്രയിക്കുന്ന ഒരു രീതിയാണ്, അതിന്റെ പതിപ്പ് DEPID-R, ആഡി സംസാരത്തിലേക്ക് തിരിച്ചു പിഐഡിയും ഐഡിയും സ്വയമായി പുറത്തെടുക്കപ്പെടുന്നതിന്റെ ആദ്യ തുല്യമാണ് ഞങ്ങള്\u200d പ്രവര്\u200dത്തിക്കുന്നത്. ഡാറ്റാസറ്റുകള്\u200d രണ്ട് വ്യത്യസ്ത വ സാധാരണ ഡാറ്റാസറ്റ് സെറ്റില്\u200d SID പ്രവര്\u200dത്തിക്കുമ്പോള്\u200d പിഐഡി ചേര്\u200dക്കുന്നത് ചെറിയ പക്ഷെ വളരെ പ്രധാനപ്പെട്ട മെച്ച On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8.', 'pl': 'Idea Density (ID) mierzy tempo, w jakim idea lub elementarne predykcje są wyrażane w wypowiedzi lub w tekście. Stwierdzono, że niższy identyfikator jest związany ze zwiększonym ryzykiem rozwoju choroby Alzheimera (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID został wykorzystany w dwóch różnych wersjach: gęstość idei propozycyjnej (PID) liczy wyrażone pomysły i może być stosowana do dowolnego tekstu, natomiast gęstość idei semantycznej (SID) liczy wstępnie zdefiniowane jednostki treści informacyjnej i jest naturalnie bardziej stosowana do domen normatywnych, takich jak zadania opisu obrazu. W artykule opracowujemy DEPID, nową metodę obliczania PID opartą na zależności, oraz jego wersję DEPID-R, która pozwala wykluczyć powtarzające się pomysły – cechę charakterystyczną dla mowy AD. Przeprowadzamy pierwsze porównanie automatycznie wyodrębnionych PID i SID w zadaniu klasyfikacji diagnostycznej na dwóch różnych zestawach danych AD obejmujących zarówno domeny zamkniętego tematu, jak i swobodnego wycofania. Podczas gdy SID działa lepiej na normatywnym zbiorze danych, dodanie PID prowadzi do niewielkiej, ale znaczącej poprawy (+1.7 F-score). W zbiorze danych o wolnym temacie PID działa lepiej niż oczekiwano SID (77.6 vs 72.3 w wyniku F), ale dodanie funkcji pochodzących z klastrowania słowa osadzenia leżącego u podstaw automatycznego SID znacznie zwiększa wyniki, prowadząc do wyniku F 84.8.', 'no': 'Idea- tettleiken (ID) målar farten på at idear eller elementære predikasjonar vert uttrykt i eit uttrykk eller i tekst. Finn at nedre ID er tilknyttet med ein økt risiko for å utvikla Alzheimer-sykdom (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID er brukt i to forskjellige versjonar: foreslåande idedensitet (PID) teller uttrykket ideane og kan brukast på alle tekstane mens semantiske idedensitet (SID) teller foredefinerte innhaldseiningar for informasjon og er naturleg meir tilgjengelege for normative domene, slik som oppgåver for skildring av biletet. I denne papiret utviklar vi DEPID, ein roman avhengighetsbasert metode for å rekna ut PID, og den versjonen DEPID-R, som kan unngå gjentakingar av idear-ein funksjon for AD-tale. Vi gjer den første sammenligninga av automatisk pakka ut PID og SID i diagnostiske klassifikasjonsprogrammet på to ulike AD-datasett som dekkar både lukka tema og fri-rekkalla domene. Mens SID utfører bedre på den normative datasettet, fører PID til ein liten, men signifikant forbedring (+1, 7 F- poeng). På datasettet frå fri tema utfører PID bedre enn SID som forventa (77,6 vs 72,3 i F-poeng) men legg til funksjonane som er deriverte frå ordet innebyggende grupperen under automatisk SID øker resultatet mykje, som fører til ein F-poeng av 84,8.', 'ms': 'Densiti Idea (ID) mengukur kadar pada mana idea atau predikasi unsur diekspresikan dalam ungkapan atau dalam teks. ID rendah ditemukan berkaitan dengan risiko yang meningkat untuk mengembangkan penyakit Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID telah digunakan dalam dua versi berbeza: Densitas idea proposisional (PID) menghitung idea yang diungkap dan boleh dilaksanakan kepada mana-mana teks sementara Densitas idea semantik (SID) menghitung unit kandungan maklumat yang terdefinisikan dan secara alami lebih berlaku kepada domain normatif, seperti tugas penerangan gambar. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas-a feature characteristic to AD speech.  Kami melakukan perbandingan pertama PID dan SID yang secara automatik dikekstrak dalam tugas klasifikasi diagnostik pada dua set data AD yang berbeza meliputi kedua-dua domain topik tertutup dan free-recall. Sementara SID berjalan lebih baik pada set data normatif, menambah PID membawa kepada peningkatan kecil tetapi signifikan (+1.7 skor F). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8.', 'mt': 'Id-Densità tal-Ideat (ID) tkejjel ir-rata li biha l-ideat jew il-predikazzjonijiet elementari huma espressi f’dikjarazzjoni jew f’test. Identità aktar baxxa nstabet li hija assoċjata ma’ riskju akbar ta’ żvilupp tal-marda ta’ Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). L-ID intuża f’żewġ verżjonijiet differenti: id-densità ta’ ideat propozzjonali (PID) tgħodd l-ideat espressi u tista’ tiġi applikata għal kwalunkwe test filwaqt li d-densità ta’ ideat semantika (SID) tgħodd unitajiet ta’ kontenut ta’ informazzjoni ddefiniti minn qabel u hija naturalment aktar applikabbli għal dominji normattivi, bħal kompiti ta’ deskrizzjoni tal-istampa. F’dan id-dokument, qed niżviluppaw id-DEPID, metodu ġdid ibbażat fuq id-dipendenza għall-kalkolu tal-PID, u l-verżjoni tiegħu DEPID-R li tippermetti li jiġu esklużi ideat ripetuti bħala karatteristika għad-diskors AD. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains.  Filwaqt li s-SID tagħmel prestazzjoni a ħjar fuq is-sett ta’ dejta normattiva, iż-żieda tal-PID twassal għal titjib żgħir iżda sinifikanti (+1.7 punteġġ F). Fuq is-sett ta’ dejta free-topic, il-PID iwettaq prestazzjoni aħjar mis-SID kif mistenni (77.6 vs 72.3 fil-punteġġ F) iżda ż-żieda tal-karatteristiċi derivati mill-kliem inkorporazzjoni raggruppament sottostanti għas-SID awtomatiku żżid ir-riżultati konsiderevolment, u twassal għal punteġġ F ta’ 84.8.', 'sr': 'Idejska gustina (ID) mjera stopu po kojoj se ideje ili elementarne predikacije izražavaju u govoru ili u tekstu. Smatra se da je niža identifikacija povezana sa povećanom rizikom razvoja Alzheimerove bolesti (AD) (Snowdon et al., 1996; Engelman et al., 2010). Identifikacija je korišćena u dve različite verzije: predložena gustina ideje (PID) broji izražene ideje i može se primjenjivati na bilo koji tekst, dok semantička gustina ideje (SID) broji preddefinirane jedinice sadržaja informacija i prirodno je primjenjiva na normativne domene, poput zadataka opisa slika. U ovom papiru razvijamo DEPID, novu metodu na osnovu zavisnosti za raèunanje PID-a, i njegovu verziju DEPID-R koja omoguæava da iskljuèi ponavljanje ideja-karakteristiku AD govora. Provodimo prvu usporedbu automatski izvlačenog PID i SID u zadatku dijagnostičke klasifikacije na dva različita serija podataka AD-a koji pokrivaju zatvorene teme i slobodne domene. Iako SID bolji izvodi na normativnom setu podataka, dodanje PID vodi do malog, ali značajnog poboljšanja (+1,7 F-rezultata). Na slobodnom setu podataka, PID je bolji od SID kao što je očekivano (77,6 protiv 72,3 u F-rezultatu), ali dodajući karakteristike iz reči uključujući skupljanje na temelju automatske SID povećava rezultate značajno, što je dovelo do F-rezultata 84,8.', 'si': 'අදහස් සංකීර්ණතාවය (ID) ක්\u200dරමාණය කරනවා අදහස් නැත්තම් ප්\u200dරමාණය සඳහා ප්\u200dරමාණික ප්\u200dරමාණයක් කිරීමක් විදිහට Lower ID is seen to be linked to an grew Hazard of development (AD) (Snow et al., 1996; Engelman et al., 2010). ID වෙනස් සංවිධානයක් දෙකක් භාවිත කරලා තියෙනවා: ප්\u200dරශ්නය අදහස් සංවිධානය (PID) ප්\u200dරශ්ණ අදහස් සංවිධානය සම්බන්ධතාවක් ගණනය කරලා තියෙන්න පුළුවන් ප මේ පත්තරයේදී, අපි DEPID විස්තර කරනවා, PID ගණනාකරණය සඳහා නියම විශේෂතාවක් අධික විධානයක්, ඒ වගේම එයාගේ සංවිධානය DEPID-R විස්තර අපි ස්වයංක්\u200dරියාවිතයෙන් අරගෙන PID සහ SID ගැන පළමු ප්\u200dරමාණය කරනවා AD දත්ත සෙට් දෙන්නා වෙනස් විදිහට පරික්ෂා කරලා තියෙන්නේ වහ SID සාමාන්\u200dය දත්ත සූදානයේ හොඳයි කරන්න, PID එකතු කරන්න පුංචි නමුත් වැඩ කරන්න (+1.7 F- score) වලට ප්\u200dරමාණයක් තියෙනවා. නිදහස් විදේශ දත්ත සූදානයෙන්, PID ස්වයංක්\u200dරීය SID වලින් හොඳයි (77.6 vs 72.3 in F-score) නමුත් ස්වයංක්\u200dරීය SID වලින් ස්වයංක්\u200dරීය විදිහට පිළිපිළිපිළිපිළිප', 'so': 'Aqoonsiga fikrada (ID) ayaa qiyaasa qiimaha lagu qoro fikrada ama bandhigyada asalka ah oo ku qoran hadal ama qoraal. IDC hoose waxaa laga helaa in la xiriiro khatar kordhiya cudurka Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). IDD waxaa lagu isticmaalay laba kooxood oo kala duduwan: qiimeynta fikrada (PID) waxaa lagu tirinayaa fikrada la muujiyey, waxaana lagu codsan karaa macluumaad kasta, marka ay kooxda fikrada (SID) ku tirsataa kooxaha macluumaadka ee horay loo qoray, waxaana si dabiiqada ah ugu habboon meelaha caadiga ah, tusaale ahaan goobaha warqada sawir. Warqadan waxaan ku qoraynaa DEPID, qaab warqad ku xiran oo ku saabsan PID, iyo warqadiisa DEPID-R oo awoodi kara inuu iska gooyo fikrada oo dib u celinayo waxyaabaha ku saabsan hadalka AD. Waxaannu sameynaa isbardhigga ugu horreeya oo ah PID iyo SID oo ku qoran macluumaadka kala duduwan ee ku qoran labada sawirada ee ku qoran dhamaan mada iyo meelaha aan xor lahayn. Inta uu SID si fiican ugu sameeyo kooxda danbiyada caadiga ah, ku daro PID wuxuu keenaa mid yar laakiin aad u hagaajiya (+1.7 F-score). Bogga macluumaadka ee xor la’aanta ah PID wuxuu ka shaqeeyaa SID wax ka wanaagsan sida loo rajeeyey (77.6 vs 72.3 score F-score) laakiin wuxuu ku daraa aqoonta uu ka soo baxay hadalka ku qoran kooxaha SID ee hoosta hoose u dhiga, wuxuuna kordhiyaa midhihiisa si aad u badan, wuxuuna keenaa kooxda F-score 84.8.', 'sv': 'Idédensitet (ID) mäter hur snabbt idéer eller elementära predikningar uttrycks i ett yttrande eller i en text. Lägre ID har visat sig vara förknippad med en ökad risk för att utveckla Alzheimers sjukdom (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID har använts i två olika versioner: Propositional Idea density (PID) räknar de uttryckta idéerna och kan tillämpas på vilken text som helst medan semantisk Idea density (SID) räknar fördefinierade informationsinnehållsenheter och är naturligtvis mer tillämplig på normativa domäner, såsom bildbeskrivningsuppgifter. I denna uppsats utvecklar vi DEPID, en ny beroendebaserad metod för att beräkna PID, och dess version DEPID-R som gör det möjligt att utesluta upprepade idéer – en funktion som kännetecknar AD-tal. Vi genomför den första jämförelsen av automatiskt extraherad PID och SID i den diagnostiska klassificeringsuppgiften på två olika AD-datauppsättningar som täcker både slutna ämnen och fria återkallande domäner. Medan SID presterar bättre på den normativa datauppsättningen leder tillägg av PID till en liten men betydande förbättring (+1,7 F-poäng). På den fria ämnesdatauppsättningen presterar PID bättre än SID som förväntat (77,6 mot 72,3 i F-poäng), men om man lägger till de funktioner som härrör från ordet inbäddning klustring bakom den automatiska SID ökar resultaten avsevärt, vilket leder till en F-poäng på 84,8.', 'ro': 'Densitatea ideii (ID) măsoară rata la care ideile sau predicțiile elementare sunt exprimate într-o cuvântare sau într-un text. Identificarea inferioară este asociată cu un risc crescut de dezvoltare a bolii Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID-ul a fost folosit în două versiuni diferite: densitatea ideilor propoziționale (PID) numără ideile exprimate și poate fi aplicată oricărui text, în timp ce densitatea ideilor semantice (SID) numără unități de conținut al informațiilor predefinite și este, în mod natural, mai aplicabilă domeniilor normative, cum ar fi sarcinile de descriere a imaginii. În această lucrare, dezvoltăm DEPID, o metodă nouă bazată pe dependență pentru calcularea PID, și versiunea sa DEPID-R care permite excluderea ideilor repetate – o caracteristică caracteristică vorbirii AD. Realizăm prima comparație a PID și SID extrase automat în sarcina de clasificare a diagnosticului pe două seturi de date AD diferite care acoperă atât domeniile cu subiect închis, cât și cele cu rechemare liberă. În timp ce SID performează mai bine pe setul de date normative, adăugarea PID duce la o îmbunătățire mică, dar semnificativă (+1,7 F-scor). Pe setul de date free-topic, PID performează mai bine decât SID așa cum era de așteptat (77,6 vs 72,3 în F-scor), dar adăugarea caracteristicilor derivate din cuvântul încorporare clustering care stau la baza SID automat crește considerabil rezultatele, ducând la un F-scor de 84,8.', 'ta': 'Idea Density (ID) எந்த எண்ணங்கள் அல்லது தனிமங்கள் முன்னிருப்புகளின் விகிதத்தை ஒரு வார்த்தையில் அல்லது உரையில் தெரியும். குறைந்த அடையாளம் அல்சைமர் நோயை உருவாக்குவதற்கு ஒரு அதிக ஆபத்துடன் இணைக்கப்பட்டது கண்டுபிடிக்கப்படுகிறது (சுவோடான் மற்றும் அல், 1996; எங இரண்டு வேறு வித்தியாசமான பதிப்பில் ID பயன்படுத்தப்பட்டுள்ளது: முன்னிருப்பு யோசனை தெளிவாக்கப்பட்ட யோசனைகள் (PID) எண்ணிக் கொண்டுள்ளது மற்றும் எந்த உரையிலும் பயன்படுத்தலாம் பெரு இந்த காக்கியத்தில், நாம் DEPID, PID கணக்கிட ஒரு புதிய சார்ந்த சார்பு முறையை உருவாக்குகிறோம், அதன் பதிப்பு DEPID-R, அது AD பேச்சிற்கு திரும்ப வேண்டிய ய நாம் தன்னியக்கமாக வெளியேற்றப்பட்ட PID மற்றும் SID ஐ ஒப்பிடுதலை செய்கிறோம் இரண்டு வேறு வித்தியாசமான AD தரவுத்தளங்களில் மூடிய தலைப்பு SID இயல்பான தரவுத்தளத்தில் சிறந்த செயல்படுத்தும் போது, PID சேர்க்கும் போது சிறிய ஆனால் முக்கியமான மேம்படுத்தல் (+1. 7 இலவச- தலைப்பு தகவல் அமைப்பில் PID எதிர்பார்க்கப்பட்டதை விட SID சிறப்பாக செயல்படுத்துகிறது (F- score 77. 6 vs 72. 3 ல்) ஆனால் தானியங்கி SID கீழே உள்ள வார்த்தை கொண்டு உள்ளிடும் குறிப்பிட்ட', 'ur': 'ایڈیو ڈنسیٹی (ID) اس رات کا اندازہ مقرر کرتا ہے جس سے ایڈیوں یا ابتدائی پیشگونیاں ایک کلام یا ایک پیغام میں بیان کیے جاتے ہیں. نیچے ID کو آلزحمیر بیماری (AD) کی بڑھائی ہوئی خطر کے ساتھ مرتبہ کیا گیا ہے (Snowdon et al., 1996; Engelman et al., 2010). ID دو مختلف نسخہ میں استعمال کیا گیا ہے: پیشنهادی ایڈیوں کی گھمنٹی (PID) صریح ایڈیوں کو شمار کرتا ہے اور کسی متکس پر لازم کر سکتا ہے حالانکہ سیمانٹی ایڈیوں کی گھمنٹی (SID) پہلے منظور معلومات کے منظور یونیٹوں کو شمار کرتا ہے اور طبیعی طور پر عام ڈومین کے لئے زیادہ لازم اس کاغذ میں ہم DEPID کو تخلیق کریں گے، ایک نو اعتمادی طریقہ کی کمپیوٹر PID کے لئے، اور اس کی نسخہ DEPID-R کو جو AD کلام کے لئے ایک دوبارہ فکرت کا اختیار نہیں کرسکتا۔ ہم دوسرے مختلف AD ڈاٹ سٹ پر ڈیٹ سٹ کے بارے میں ڈیٹ ڈیٹ سٹ کے بارے میں ڈیٹ ڈیٹ ڈیٹ اور آزاد-ریکال ڈومین کے بارے میں اپنے آپ کو پیدا کیا گیا PID اور SID کی پہلی مقایسہ کررہے ہیں. While SID performs better on the normative data set, adding PID leads to a small but significant improvement (+1.7 F- score). فائر-ٹوپ ڈیٹسٹ پر PID اس طرح بہتر عمل کرتا ہے جیسے انتظار کی گئی ہے (F-score میں 77.6 vs 72.3) لیکن کلاستر کے نیچے لکھنے والی کلسٹر سے فائدے اضافہ کرتا ہے جو آٹوٹی SID کے نیچے آئی ہے، نتائج اضافہ کرتا ہے، یہاں تک کہ 84.8 کی F-score کی مدد کرتا ہے.', 'vi': 'Vị độ cao của ý tưởng (ID) đo mức độ độ các ý tưởng hay tình trạng căn bản được diễn tả bằng lời nói hay trong văn bản. Hạ chỉ được xác định là có khả năng tăng rủi ro phát triển bệnh Alzheimer (AD) (Snowdon et al., 196; Engelman et al., 2009). lD đã được sử dụng trong hai phiên bản khác nhau: tỷ lệ ý tưởng truyền thống (PID) tính các ý tưởng được phát biểu và có thể áp dụng cho bất kỳ văn bản trong khi mật độ lớn ý tưởng (SID) tính trước các đơn vị nội dung được xác định và có thể được áp dụng nhiều hơn cho lĩnh vực quy định, như các công việc mô tả ảnh. Trong tờ giấy này, chúng tôi phát triển một chế độ phụ thuộc mới cho việc tính to án PID, và phiên bản của nó, hâ tiện-R, cho phép loại bỏ những ý tưởng lặp lại một tính đặc trưng của lời diễn văn AD. Chúng tôi tiến hành cuộc so sánh đầu tiên với PID và SID tự động được chiết xuất trong nhiệm vụ phân tích chẩn đoán về hai tập tin AD khác nhau bao gồm cả khu vực chủ đề đóng và miền lại tự do. Trong khi SID làm tốt hơn trong bộ dữ liệu tiêu chuẩn, việc thêm PID lại dẫn tới một tiến bộ nhỏ nhưng đáng kể (+1.7 F-điểm). Trên tập tin chủ đề tự do, PID làm tốt hơn SID như dự kiến (77.6 vs 72.3 trong điểm F) nhưng việc thêm các tính năng thừa hưởng từ cụm từ bên dưới lớp SID tự động tăng đáng kể kết quả, dẫn đến điểm F của 84.8.', 'uz': "Shaxsiyat (ID) gapirish yoki matnning fikrlari yoki element predefinito koʻrsatiladigan chegarani moslash. Quyidagi ID Alzheimer kasalligini yaxshi shaklga oshirishga (AD) (Snowdon et al., 1996; Engleman et al., 2010) bilan bog'liq topildi. IDD ikkita boshqa versiyalarga ishlatilgan: аввалги фикр чеклиги (PID) кўрсатилган фикрларни ҳисоблашади ва ҳар бир matnlarda qoʻllaniladi, аммо semantik g'oya uzunligi (SID) oldin aniqlangan maʼlumot tarkibini ҳисоблашади ва одатда фойдаланадиган доментларга, masalan rasm taʼrif vazifalari kabi. Bu hujjatda biz PID'ni kompyuter qilish uchun novel ishlatuvchi usuli va унинг DEPID-R versiyasi AD axborotiga takrorlash imkoniyatini ajratish mumkin. We conduct the first comparison of automatically extracted PID and SID in the diagnostic classification task on two different AD datasets covering both closed-topic and free-recall domains.  SID oddiy maʼlumotlar tarkibida yaxshi bajarayotganda, PID'ni qoʻshishda kichik lekin muhim bajarishga ega boʻladi (+1. 7 F- score). Xossalar", 'bg': 'Плътността на идеите (ИД) измерва скоростта, с която идеите или елементарните предсказания се изразяват в изказване или текст. По-ниската ID е свързана с повишен риск от развитие на болестта на Алцхаймер (Сноудън и др., 1996; Engelman и др., 2010). ИД се използва в две различни версии: плътността на идеята (ПИД) брои изразените идеи и може да се приложи към всеки текст, докато семантичната плътност на идеята (ПИД) брои предварително дефинирани единици информационно съдържание и естествено е по-приложима за нормативни области, като задачи за описание на картината. В тази статия разработваме нов метод, базиран на зависимости, за изчисляване на ПИД, и неговата версия която позволява изключване на повтарящи се идеи - характеристика, характерна за речта на AD. Провеждаме първото сравнение на автоматично извлечените ПИД и СИД при диагностичната класификация на два различни набора от данни от АД, обхващащи както закрити теми, така и свободни домейни. Докато се представя по-добре на нормативния набор от данни, добавянето на ПИД води до малко, но значително подобрение (+1.7 F-score). На съвкупността от данни със свободни теми се представя по-добре от очакваното (77.6 срещу 72.3 в F-score), но добавянето на характеристиките, получени от думата вграждане на клъстери в основата на автоматичния СИД увеличава значително резултатите, което води до F-score от 84.8.', 'nl': 'Idea Density (ID) meet de snelheid waarmee ideeën of elementaire voorspellingen worden uitgedrukt in een uiting of in een tekst. Lower ID blijkt geassocieerd te zijn met een verhoogd risico op het ontwikkelen van de ziekte van Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID is gebruikt in twee verschillende versies: propositional idea density (PID) telt de uitgebrachte ideeën en kan worden toegepast op elke tekst, terwijl semantische idea density (SID) vooraf gedefinieerde informatie content eenheden telt en van nature meer toepasbaar is op normatieve domeinen, zoals beeldbeschrijvingstaken. In dit artikel ontwikkelen we DEPID, een nieuwe afhankelijkheidsgebaseerde methode voor het berekenen van PID, en de versie DEPID-R die het mogelijk maakt om herhalende ideeën uit te sluiten – een kenmerk voor AD spraak. We voeren de eerste vergelijking uit van automatisch geëxtraheerde PID en SID in de diagnostische classificatietaak op twee verschillende AD-datasets die zowel gesloten-topic als vrij-recall domeinen bestrijken. Terwijl SID beter presteert op de normatieve dataset, leidt het toevoegen van PID tot een kleine maar significante verbetering (+1.7 F-score). Op de free-topic dataset presteert PID beter dan SID zoals verwacht (77.6 vs 72.3 in F-score), maar het toevoegen van de functies afgeleid van het woord embedding clustering onderliggende de automatische SID verhoogt de resultaten aanzienlijk, wat leidt tot een F-score van 84.8.', 'hr': 'Glavnost ideje (ID) mjera stopu po kojoj se ideje ili elementarne predikacije izražavaju u govoru ili u tekstu. Smatra se da je niži ID povezan s povećanim rizikom razvoja Alzheimerove bolesti (AD) (Snowdon et al., 1996; Engelman et al., 2010). Identifikacija se koristila u dvije različite verzije: predložena gustina ideje (PID) broji izražene ideje i može se primjenjivati na bilo koji tekst, dok semantička gustina ideje (SID) broji predodređene jedinice sadržaja informacija i prirodno je primjenjiva na normativne domene, poput zadataka opisa slika. U ovom papiru razvijamo DEPID, novu metodu zavisnosti za računalo PID, i njegovu verziju DEPID-R koja omogućava isključiti ponavljanje ideja-karakteristiku AD govora. Provodimo prvo usporedbu automatski izvlačenog PID i SID u zadatku dijagnostičke klasifikacije na dva različita serija podataka AD koji pokrivaju zatvorene teme i slobodne domene. Iako SID bolji izvodi na normativnom setu podataka, dodanje PID vodi do malog, ali značajnog poboljšanja (+1,7 F-rezultata). Na slobodnoj skupini podataka PID djeluje bolje od SID kako je očekivano (77,6 protiv 72,3 u F-rezultatu), ali dodajući karakteristike iz riječi uključujući skupinu pod automatskim SID-om, značajno povećava rezultate, što je dovelo do F-rezultata 84,8.', 'de': 'Ideendichte (ID) misst die Geschwindigkeit, mit der Ideen oder elementare Vorhersagen in einer Äußerung oder in einem Text ausgedrückt werden. Die niedrigere ID wird mit einem erhöhten Risiko für die Entwicklung der Alzheimer-Krankheit (AD) assoziiert (Snowdon et al., 1996; Engelman et al., 2010). ID wurde in zwei verschiedenen Versionen verwendet: Die propositionale Ideendichte (PID) zählt die ausgedrückten Ideen und kann auf jeden Text angewendet werden, während die semantische Ideendichte (SID) vordefinierte Informationsinhaltseinheiten zählt und natürlich besser auf normative Bereiche, wie Bildbeschreibungsaufgaben, anwendbar ist. In diesem Beitrag entwickeln wir DEPID, eine neuartige abhängigkeitsbasierte Methode zur Berechnung von PID, und seine Version DEPID-R, die es ermöglicht, sich wiederholende Ideen auszuschließen – ein Merkmal der AD-Sprache. Wir führen den ersten Vergleich von automatisch extrahierten PID und SID in der diagnostischen Klassifikationsaufgabe auf zwei verschiedenen AD-Datensätzen durch, die sowohl geschlossene Themen als auch freie Rückrufdomänen abdecken. Während SID im normativen Datensatz besser abschneidet, führt das Hinzufügen von PID zu einer kleinen, aber signifikanten Verbesserung (+1.7 F-Score). Auf dem freien Themendatensatz schneidet PID wie erwartet besser ab als SID (77.6 vs 72.3 im F-Score), aber das Hinzufügen der Funktionen, die aus dem Wort Einbettung Clustering abgeleitet sind, die der automatischen SID zugrunde liegen, erhöht die Ergebnisse erheblich, was zu einem F-Score von 84.8 führt.', 'ko': '사상밀도(ID)는 사상이나 기본 술어가 말이나 텍스트에서 표현하는 속도를 측정한다.연구에 따르면 낮은 ID는 알츠하이머병(AD)의 발병 위험 증가와 관련이 있다(Snowdon 등, 1996년, 엔젤맨 등, 2010년).ID는 두 가지 다른 버전에 사용된다. 명제 사상밀도(PID) 계산 표현의 사상은 모든 텍스트에 응용할 수 있고 의미 사상밀도(SID)는 미리 정의된 정보 내용 단원을 계산하면 규범 분야, 예를 들어 그림 묘사 임무에 더욱 적합하다.본고에서 우리는 의존 관계를 바탕으로 하는 새로운 PID 계산 방법인 DEPID와 그의 DEPID-R 버전을 개발했다. 이 버전은 중복된 생각을 배제할 수 있는데 이것은 AD 음성의 특징이다.닫힌 주제와 자유 회상 영역을 덮어쓰는 두 개의 서로 다른 AD 데이터 세트에서 진단 분류 작업에서 자동으로 추출된 PID와 SID를 처음으로 비교했습니다.SID는 표준 데이터 세트에서 더 나은 모습을 보이지만 PID를 추가하면 작고 현저한 개선(+1.7F 점수)을 가져올 수 있다.자유 주제 데이터 세트에서 PID는 SID보다 더 잘 표현된다(F점수는 각각 77.6과 72.3). 그러나 자동 SID에서 나온 단어가 집합에 삽입되는 특징을 추가하면 F점수가 84.8로 현저히 높아진다.', 'da': 'Idétæthed (ID) måler den hastighed, hvormed ideer eller elementære prædikationer udtrykkes i en udtalelse eller i en tekst. Lavere ID vises at være forbundet med en øget risiko for at udvikle Alzheimers sygdom (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID er blevet brugt i to forskellige versioner: Propositional Idea density (PID) tæller de udtrykte ideer og kan anvendes på enhver tekst, mens semantisk Idea density (SID) tæller prædefinerede informationsindholdsenheder og er naturligvis mere anvendelig på normative domæner, såsom billedbeskrivelsesopgaver. I denne artikel udvikler vi DEPID, en ny afhængighedsbaseret metode til beregning af PID, og dens version DEPID-R, der gør det muligt at udelukke gentagne ideer – en funktion karakteristisk for AD tale. Vi foretager den første sammenligning af automatisk ekstraheret PID og SID i den diagnostiske klassifikationsopgave på to forskellige AD datasæt, der dækker både lukkede emner og fri tilbagekaldelse domæner. Mens SID klarer sig bedre på det normative datasæt, fører tilføjelse af PID til en lille, men betydelig forbedring (+1,7 F-score). På det frie emne datasæt, PID fungerer bedre end SID som forventet (77,6 vs 72,3 i F-score), men tilføjelse af de funktioner, der stammer fra ordet integrering clustering underliggende den automatiske SID øger resultaterne betydeligt, hvilket fører til en F-score på 84,8.', 'sw': 'Kukanusha Idia (ID) hupima kiwango ambacho wazo au utabiri wa msingi huonyeshwa kwa lugha au kwa ujumbe wa maandishi. UID wa chini unaonekana kuwa unahusiana na hatari kubwa ya kuendeleza ugonjwa wa Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks.  In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas-a feature characteristic to AD speech.  Tunafanya ulinganisho wa kwanza wa PID na SID katika jukumu la kutambua maambukizi katika seti mbili tofauti za AD zinazohusu mada zilizofungwa na mada za bure. Wakati SID inafanya vizuri katika seti ya taarifa za kawaida, kuongeza PID inapelekea maboresho kidogo lakini muhimu (+1.7 F-score). Katika seti ya taarifa huru za mada, PID inafanya vizuri zaidi ya SID kama ilivyotarajiwa (77.6 vs 72.3 kwenye vipindi vya F) lakini kuongeza vipengele vilivyotokana na neno ambalo linajumuisha viungo vya SID kinaongeza matokeo yake kwa kiasi kikubwa, na kusababisha vipindi vya F-score 84.8.', 'id': 'Densitas Ide (ID) mengukur kadar pada mana ide atau predikasi dasar diungkap dalam sebuah ucapan atau dalam teks. ID lebih rendah ditemukan terkait dengan risiko yang meningkat untuk mengembangkan penyakit Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID telah digunakan dalam dua versi yang berbeda: ketepatan ide proposisional (PID) menghitung ide-ide yang diungkap dan dapat diaplikasikan pada setiap teks sementara ketepatan ide semantis (SID) menghitung unit konten informasi yang terdefinisikan sebelumnya dan secara alami lebih diaplikasikan untuk domain normatif, seperti tugas deskripsi gambar. Dalam kertas ini, kami mengembangkan DEPID, metode baru berdasarkan dependensi untuk menghitung PID, dan versi DEPID-R yang memungkinkan untuk mengeluarkan ulang ide-karakteristik pada pidato AD. Kami melakukan perbandingan pertama dari PID dan SID yang secara otomatis diekstraksi dalam tugas klasifikasi diagnostik pada dua set data AD yang berbeda meliputi kedua topik tertutup dan domain free-recall. Sementara SID berhasil lebih baik pada set data normatif, menambahkan PID menyebabkan peningkatan kecil tapi signifikan (+1,7 skor F). Pada set data topik bebas, PID berhasil lebih baik dari SID seperti yang diharapkan (77,6 vs 72,3 dalam skor F) tetapi menambahkan fitur yang berasal dari kata embedding clustering di bawah SID otomatis meningkatkan hasilnya dengan konsideratif, menyebabkan skor F 84,8.', 'fa': 'تنظیم ایده\u200cها (هویت شناسایی) میزان را اندازه می\u200cدهد که ایده\u200cها یا پیشنهاد اصلی در یک کلمه یا در یک متن بیان می\u200cشوند. شناسایی پایین به عنوان خطر افزایش بیماری الزهیمر (AD) (Snowdon et al., 1996; Engelman et al., 2010) ارتباط دارد. شناسایی در دو نسخه متفاوت استفاده می\u200cشود: density of ideas proposed (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as images description tasks. در این کاغذ، ما DEPID را توسعه می\u200cکنیم، یک روش بستگی بستگی تازه برای محاسبه PID، و نسخه DEPID-R آن که می\u200cتواند از تکرار ایده\u200cها و ویژگی\u200cهای ویژه\u200cای برای سخنرانی AD خارج کند. ما اولین مقایسه\u200cای از PID و SID\u200cهای خودکار را در کار شناسایی شناسایی در دو مجموعه داده\u200cهای AD متفاوت انجام می\u200cدهیم که هر یک از مجموعه\u200cهای بسته و آزاد یادآوری است. در حالی که SID در مجموعه داده\u200cهای معمولی بهتر انجام می\u200cدهد، اضافه کردن PID به یک بهترین کوچک ولی مهمتر (+1.7 فوت). در مجموعه داده\u200cهای آزاد موضوع، PID بهتر از SID انجام می\u200cدهد همانطور که انتظار داشته باشد (77.6 vs 72.3 در امتیاز F) ولی اضافه کردن ویژگی\u200cهایی که از کلمه\u200cای که جمع می\u200cشود در زیر SID اتوماتیک پایان می\u200cدهد، نتایج\u200cها را بسیار زیادی افزایش می\u200cدهد، که به عنوان امتیا', 'sq': 'Idea Density (ID) measures the rate at which ideas or elementary predications are expressed in an utterance or in a text.  ID më e ulët gjendet të lidhet me një rrezik të rritur të zhvillimit të s ëmundjes së Alzheimerit (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID është përdorur në dy versione të ndryshme: densiteti propozitiv i ideve (PID) numëron idetë e shprehura dhe mund të aplikohet në çdo tekst ndërsa densiteti semantik i ideve (SID) numëron njësitë e përmbajtjes së informacionit të përcaktuar para dhe është natyralisht më i aplikueshëm për domenat normative, të tilla si detyrat e përshkrimit të fotove. Në këtë letër, ne zhvillojmë DEPID, një metodë të re bazuar në varësi për llogaritjen e PID, dhe versionin e saj DEPID-R që lejon të përjashtojë përsëritjen e ideve-një karakteristikë të fjalimit AD. Ne kryejmë krahasimin e parë të PID dhe SID të nxjerrur automatikisht në detyrën e klasifikimit diagnostik në dy grupe të dhënash të ndryshme AD që mbulojnë si temat e mbyllura ashtu edhe domenat e mbledhjes së lirë. Ndërsa SID funksionon më mirë në sistemin normativ të të dhënave, shtimi i PID shpie në një përmirësim të vogël por të rëndësishëm (+1.7 F-score). Në grupin e të dhënave të temave të lira, PID performon më mirë se SID siç pritej (77.6 krahasuar me 72.3 në F-score) por shtimi i elementeve të nxjerra nga fjala përfshirje grupimi nën bazën e SID automatik rrit konsiderueshëm rezultatet, duke shpjerë në një F-score prej 84.8.', 'am': 'የአዲስ ጥያቄ (ID) በአሳብ ወይም አቀማሚ ጉዳይ በንግግር ወይም በጽሑፍ በሚገልጹበት ቁጥጥር ይለካል፡፡ ታችኛይቱ ID በአልዚሃሜር ደዌ መፍታት (AD) (Snowdon et al., 1996; Engelman et al., 2010) በተጨማሪው መከራ ጋር ተገኝቷል፡፡ ID በተለየ ሁለት መልዕክቶች ውስጥ ተጠቃሚ ሆኖአል: የፊደል አዲስ ጥቁር (PID) የተገኘውን አሳብ ይቆጥራል እና በምንም ነገር ላይ ይደረጋል፡፡ በዚህ ገጽ DEPID፣ የኖም የአደባባይ የPID-መቆጣጠር ሥርዓት እና የድምጽ DEPID-R መክፈቻን ለAD ንግግር ማሳየት የሚችል የአሳብን-አካባቢ ስርዓት ማቀናቀል እናደርጋለን፡፡ PID እና SID በመጀመሪያው ተሳያየት በሁለት ሌሎች የAD ዳታተሮች ላይ በተዘጋጀ ትክክል እና ነፃ አዳራሾችን ላይ እናደርጋለን፡፡ SID በተለመደ ዳታዊ ሰርቨር ሲደረግ፣ PID መጨመር ታናሽ ነገር ግን ታናሽ ነገር ግን ታናሽ ማሻሻሻል (+1.7 F-score). በነጻ-ጉዳዩ ዳታተር ላይ PID ከSID የተሻለ ይሠራል (77.6 vs 72.3 በF-score) ነገር ግን በሠሌዳዊ SID ውይይት ውስጥ ካለው ከቃላት የተገኘውን ምርጫዎች ይጨምርበታል፡፡', 'hy': 'Գաղափարի խտությունը (ID) չափում է այն արագությունը, որի վրա գաղափարները կամ տարրական դիտակումները արտահայտվում են արտահայտության կամ տեքստի մեջ: Պարզվում է, որ ցածր ID-ը կապված է Ալցհեյմերի հիվանդության (ԱԴ) զարգացման աճող ռիսկի հետ (Սնոուդոն և այլն., 1996, Էնգելման և այլն., 2010 թ): ID-ն օգտագործվել է երկու տարբեր տարբերակներում. առաջարկական գաղափարի խտությունը հաշվարկում է արտահայտված գաղափարները և կարող է կիրառվել ցանկացած տեքստի վրա, մինչդեռ սեմանտիկ գաղափարի խտությունը (SID) հաշվարկում է նախասահմանված տեղեկատվական պարունակության միավորները և բնական ավելի կիրառվում է նոր Այս թղթի մեջ մենք զարգանում ենք DEPiD-ը, մի նոր կախվածության հիմնված մեթոդ, որը օգտագործում է համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգչային համակարգ Մենք կատարում ենք ախտորոշման դասակարգման առաջին համեմատությունը երկու տարբեր ԱԴ տվյալների համակարգերի հետ, որոնք ներառում են փակ թեմային և անվճար հիշելու ոլորտներ: While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score).  Անվճար թեմայի տվյալների համակարգում, ՊիԴ-ն ավելի լավ է աշխատում, քան սպասում էր SID-ը (77.6 համեմատած 72.3 F-գնահատականի դեպքում), բայց ավելացնելով այն հատկանիշները, որոնք առաջացել են ավտոմատիկ SID-ի հիմքում գտնվող բառի ներառման խմբավորումներից, ապա արդյունքները շատ', 'az': "Ideya Hizməti (ID) ideyaların və ilk prediksyonların sözlərdə və ya metinlərdə ifadə ediləcəyi dərəsini ölçüdə saxlayır. Aşağıdaki kimlik Alzheimer hastalığı (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID iki müxtəlif versiyada istifadə edildi: təklif ideya yoğunluğu (PID) ifadə edilən fikirləri sayır və semantik ideya yoğunluğu (SID) ön təyin edilmiş məlumat ünvanlarını sayır və təbiətli olaraq normativ domenalara uyğunlaşdırılabilir, çünki fotoğraf tanımlaması işləri kimi. Bu kağızda DEPID, PID hesaplamaq üçün yeni bağımlılıq tabanlı bir yöntem və onun DEPID-R versiyonu təkrarlayır ki, ideyalarını AD sözlərinə təkrarlayır. Biz öz-özündən çıxarılan PID və SID'nin ilk karşılaşdırmasını iki müxtəlif AD veri quruları ilə bağlı-mevzu və serbest-recall domeinlərini örtürdük. SID normativ veri quruluğunda daha yaxşı işlədirsə də, PID əlavə etmək kiçik, amma möhkəm düzəltməyə yol göstərir (+1.7 F-score). Özgür məsələlər qutusunda, PID gözlədiyi kimi SID-dən daha yaxşı performans edər (77.6 vs 72.3 F-score içində) ancaq avtomatik SID-nin altındakı clustering sözdən gələn fəaliyyətləri artırar, F-score 84.8 dəyişdirir.", 'bn': 'আইডিয়া সংশ্লিষ্ট (আই. ডি.) যে হারের মাধ্যমে ধারণা বা মৌলিক ভবিষ্যৎবাণী বা লেখায় প্রকাশ করা হয় তা ব্যবহার করে। নিম্নলিখিত পরিচয়পত্র আল্জহেমারের রোগের বৃদ্ধির ঝুঁকির সাথে যোগাযোগ পাওয়া যাচ্ছে (এডি) (স্নোডন এন্ট আল, ১৯৬; ইংল্যান এন দুই ভিন্ন ভিন্ন সংস্করণে ID ব্যবহার করা হয়েছে: প্রস্তাবিত আইডিয়ার গঠন (পিআইডি) প্রকাশিত চিন্তা গণনা করে এবং যে কোন টেক্সটে প্রয়োগ করা যাবে যখন সেম্যান্টিক আইডিয়ার গঠন (SID) পূর্ব এই কাগজটিতে আমরা ডেপিআইডি তৈরি করি, পিআইডি কমিউনিটিং এর নির্ভর করার একটি উপন্যাস-ভিত্তিক পদ্ধতি এবং এর সংস্করণ DEPID-R যা AD ভাষণের বৈশিষ্ট্যের বৈশিষ্ট্যাবলী আমরা স্বয়ংক্রিয়ভাবে পিআইডি এবং SID-এর প্রথম তুলনা করি ডিজিনোগ্রাফিকেশন কাজের মধ্যে দুটি বিভিন্ন AD ডাটাসেটের উপর, যা দুটি বিষয় বন্ধ করে দ যখন SID স্বাভাবিক ডাটাসেটে ভালো কাজ করে, তখন পিআইডি যোগ করা একটি ছোট কিন্তু গুরুত্বপূর্ণ উন্নয়ন (+1. 7 F- স্কোর)। On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8.', 'af': "Idee Densiteit (ID) maak die tempo waar idees of elementeerde voorskrifte in 'n uitdrukking of in 'n teks uitgevoer word. Sagter ID is gevind om geassosieer te word met 'n vergroot risiko van die ontwikkeling van Alzheimer se sykdom (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID is gebruik in twee verskillende weergawes: voorstellings idee densiteit (PID) tel die uitgevoerde idee en kan wees aangepas na enige teks terwyl semantiese idee densiteit (SID) tel voor- gedefinieerde inligting inhoud eenhede en is natuurlik meer toewenbaar vir normatiewe domeine, soos prent beskrywing opdragte. In hierdie papier, ontwikkel ons DEPID, 'n novel afhanklikheid-gebaseerde metode vir bereken PID, en sy weergawe DEPID-R wat toelaat om herhaalde idee-a funksie karakteristiek te uitsluit aan AD spreek. Ons doen die eerste vergelyking van outomaties uitgepak PID en SID in die diagnosiese klasifikasie taak op twee verskillende AD datastelle wat beide gesluit-onderwerp en vry-rekal domeine oordek. Terwyl SID beter uitvoer op die normatiewe datastel, byvoeg PID lei na 'n klein maar beter verbetering (+1. 7 F- telling). Op die vry-onderwerp datastel, PID uitvoer beter as SID as verwagte (77.6 teen 72.3 in F- telling) maar by voeg by die funksies afgeleide van die woord ingesluit clustering onder die outomatiese SID die resultate oorvloedig vergroot, wat na 'n F- telling van 84.8 lei.", 'bs': 'Glavnost ideje (ID) mjera stopu po kojoj se ideje ili elementarne predikacije izražavaju u govoru ili u tekstu. Smatra se da je niži ID povezan s povećanim rizikom razvoja Alzheimerove bolesti (AD) (Snowdon et al., 1996; Engelman et al., 2010). Identifikacija se koristila u dvije različite verzije: predložena gustina ideje (PID) broji izražene ideje i može se primjenjivati na bilo koji tekst, dok semantička gustina ideje (SID) broji preddefinirane jedinice sadržaja informacija i prirodno je primjenjiva na normativne domene, poput zadataka opisa slika. U ovom papiru razvijamo DEPID, novu metodu zavisnosti za računalo PID, i njegovu verziju DEPID-R koja omogućava isključiti ponavljanje ideja-karakteristiku AD govora. Provodimo prvu usporedbu automatski izvlačenog PID i SID u zadatku dijagnostičke klasifikacije na dva različita seta podataka AD-a koja pokrivaju i zatvorene teme i slobodne domene. Iako SID bolji izvodi na normativnom setu podataka, dodanje PID vodi do malog, ali značajnog poboljšanja (+1,7 F-rezultata). Na slobodnom setu podataka, PID čini bolje od SID kao što je očekivano (77,6 protiv 72,3 u F-rezultatu), ali dodajući karakteristike iz riječi uključujući skupljanje pod automatskim SID povećava rezultate značajno, što je dovelo do F-rezultata 84,8.', 'cs': 'Idea Density (ID) měří rychlost vyjádření myšlenek nebo elementárních predikcí v projevu nebo textu. Dolní ID je zjištěno, že je spojeno se zvýšeným rizikem vzniku Alzheimerovy choroby (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID se používá ve dvou různých verzích: výroková hustota myšlenek (PID) počítá vyjádřené myšlenky a může být aplikována na libovolný text, zatímco sémantická hustota myšlenek (SID) počítá předem definované jednotky obsahu informací a je přirozeně více aplikovatelná pro normativní domény, jako jsou úlohy popisu obrázků. V tomto článku vyvíjíme DEPID, novou metodu založenou na závislostech pro výpočet PID, a její verzi DEPID-R, která umožňuje vyloučit opakující se myšlenky, což je charakteristické pro AD řeč. První porovnání automaticky extrahovaných PID a SID v diagnostické klasifikaci provádíme na dvou různých AD datových sadách pokrývajících jak uzavřené tématické, tak volné vyvolání domény. Zatímco SID funguje lépe na normativní datové sadě, přidání PID vede k malému, ale výraznému zlepšení (+1.7 F-skóre). Na volném tématu datové sadě PID funguje lépe než SID podle očekávání (77.6 vs 72.3 v F-skóre), ale přidání funkcí odvozených ze slovního vkládání clusterů podkladového automatického SID zvyšuje výsledky výrazně, což vede k F-skóre 84.8.', 'et': 'Ideede tihedus (ID) mõõdab kiirust, millega ideed või elementaarsed ennustused väljendatakse väljenduses või tekstis. Madalam ID on seotud suurenenud riskiga Alzheimeri tõve (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID-d on kasutatud kahes erinevas versioonis: propositsionaalne ideede tihedus (PID) loeb väljendatud ideed ja seda saab rakendada igale tekstile, semantiline ideede tihedus (SID) loeb eelnevalt määratletud infosisuühikuid ja on loomulikult rohkem kohaldatav normatiivsetele valdkondadele, näiteks pildi kirjeldamise ülesannetele. Käesolevas töös töötame välja DEPID, uudse sõltuvuspõhise meetodi PID arvutamiseks, ja selle versiooni DEPID-R, mis võimaldab välistada korduvaid ideid, mis on AD kõnele iseloomulik omadus. Automaatselt ekstraheeritud PID ja SID esimese võrdluse teostame diagnostilise klassifitseerimise ülesandes kahe erineva AD andmekogumiga, mis hõlmavad nii suletud teema kui ka vaba tagasikutsumise domeeni. Kuigi SID toimib normatiivses andmekogumis paremini, toob PID lisamine kaasa väikese, kuid märkimisväärse paranemise (+1,7 F-skoor). Vaba teema andmekogumi puhul on PID oodatust parem kui SID (77,6 vs 72,3 F-skoori puhul), kuid automaatse SID aluseks olevast sõnast tulenevate funktsioonide lisamine suurendab tulemusi märkimisväärselt, viies F-skoori 84,8.', 'tr': "ideýa Densitet (ID) pikirler ýa elementer öňünde bir sözle ýa-da metin içinde ifade edilen hatlary öleýär. Iň aşak ID-iň Alzheimer hastalıklarynyň gelişmegi (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID iki dürli wersiýada ullanylýar: teklip ideýa çykyşyklygyny (PID) surat alan ideýalary hasaplaýar we semantik ideýa çykyşyklygyny (SID) öň-belirlenýän maglumat meýdançasyny hasaplaýar we bellenen ýagdaýda, surat waspy görerleri ýaly adalatyr. Bu kagyzda, DEPID'i, PID'i hesaplamak üçin romanlaryň daşarylygyny we DEPID-R wersiýasynda ideýalaryny AD sözleri üçin gaýtalamak mümkin edýäris. Biz diagnostik klasifikasynda PID we SID'i ilkinji gezek baglanyşyp edýäris. Diňe bir AD veri setirleri hem ýapylan meselede hem boş-gaýşart sahypalarynda. SID normativ veri setinde has gowurak işleýän bolsa, PID ekleýän kiçijek we möhüm gelişmege sebep edýär (+1.7 f-esli). Özgür tema maglumaty takmynda, PID gözlenen ýaly SID-den has gowurar (77.6 we 72.3 we F-score içinde) ýöne awtomatik SID-iň altyndaky sözden düzülen özellikleri ekleýär we F-score 84.8-dir.", 'fi': 'Ideatiheys (ID) mittaa sitä nopeutta, jolla ideat tai alkeelliset predikaatiot ilmaistaan lauseessa tai tekstissä. Alemman ID:n on todettu liittyvän lisääntyneeseen riskiin sairastua Alzheimerin tautiin (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID:tä on käytetty kahdessa eri versiossa: propositional idea density (PID) laskee ilmaistut ideat ja sitä voidaan soveltaa mihin tahansa tekstiin, kun taas semanttinen ideadensity (SID) laskee ennalta määritellyt tietosisältöyksiköt ja soveltuu luonnollisesti paremmin normatiivisiin toimialoihin, kuten kuvankuvaustehtäviin. Tässä artikkelissa kehitämme DEPID-menetelmän, joka on uusi riippuvuuteen perustuva menetelmä PID-laskentaan, ja sen version DEPID-R, jonka avulla toistuvia ideoita voidaan sulkea pois – ominaisuus, joka on ominaista AD-puheelle. Vertailemme automaattisesti poimittuja PID- ja SID-tietoja diagnostisessa luokittelutehtävässä ensimmäistä kertaa kahdella eri AD-aineistolla, jotka kattavat sekä suljetun aiheen että vapaan palautuksen toimialueen. Vaikka SID suoriutuu paremmin normatiivisessa aineistossa, PID:n lisääminen johtaa pieneen mutta merkittävään parannukseen (+1,7 F-score). Vapaan aiheen aineistossa PID suoriutuu odotettua paremmin kuin SID (77,6 vs 72,3 F-score), mutta automaattisen SID:n taustalla olevasta klusteroinnista johdettujen ominaisuuksien lisääminen lisää tuloksia huomattavasti, jolloin F-score on 84,8.', 'ca': "La densitat d'idees (ID) mesura la velocitat a la que les idees o predicacions elementars s'expressen en una expressió o en un text. Es troba que la menor identificació està associada a un risc augmentat de desenvolupament de la malaltia d'Alzheimer (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks.  En aquest article, desenvolupem DEPID, un nou mètode basat en la dependència per calcular PID, i la seva versió DEPID-R que permet excluir les idees repetidas, una característica característica del discurs AD. Fem la primera comparació de PID i SID automàticament extraïts en la tasca de classificació diagnòstica en dos conjunts de dades AD diferents que cobreixen tant dominys de tema tancat com de recuperació gratuita. Mentre que la SID funciona millor en el conjunt normatiu de dades, afegir PID condueix a una petita però significativa millora (+1,7 puntuació F). En el conjunt de dades de tema lliure, el PID funciona millor que el SID tal com es esperava (77,6 vs 72,3 en puntuació F), però afegint les característiques derivades de la paraula incorporació agrupació subjacente al SID automàtic augmenta considerablement els resultats, portant a una puntuació F de 84,8.", 'ha': "Tsarin Aiki (ID) yana ƙayyade iyakar da za'a nuna ko kuma ba'a cikin wani matsayi. Ana gane ID ya ƙarƙashin a haɗi da wata risiko mai ƙaranci wa ya develope jiran Alzheiter (AD) (Sũdon et al., 1996; Engel man et al., 2010). An amfani da ID cikin sigogi biyu daban-daban: nau'in idãnun na fasahan (PID) yana ƙidãya wa idãnun da aka bayyana su kuma ana iya amfani da duk matsayi idan nau'in fikan na semantic (AID) na ƙidãya sunayen tsarin da aka bayyana shi a gaba-bayan-bayan, kuma ana fi zama na amfani da cikin duk masu na daidaita, kamar aikin zane-zane. Daga wannan takardan, Munã buɗe DAPID, wata hanyor da ke samar da kuma a kan lissafar da sabon da aka ƙayyade ga lissafar PID, da kuma tsohon DAPID-R wanda ke iya amfani da yin cire-dubu na'ura da zato-wata na'urar-zafi zuwa hotel na AD. Kana tafiyar da farkon samfani na PID da AID farat ɗaya cikin aikin classified na zaman shawarar da aka goyi a kan danne biyu masu daban-daban AD waɗanda ke rufe-topogi da sauran da aka sake koma-komai. Waka da SSD ya gyara mafi alhẽri a kan daidaita database na normal, za'a ƙara PID zuwa wani ƙari amma mai kyau (+1.7 F- score). Ga tsarin bayani-madaidaita, PID na aikata mafi alhẽri daga shirin SD kamar an ƙayyade (77.6 vers 197.3 cikin F-score) kuma yana ƙara wasu fikofati waɗanda aka ƙara daga maganar da ke ƙaranci da shirin da aka ƙara ƙaramata farat-inganci, yana ƙara fassaran an girma, kuma yana ƙara wata F-score na 84.8.", 'sk': 'Gostota idej (ID) meri hitrost, s katero so ideje ali elementarne napovedi izražene v izgovoru ali besedilu. Ugotovljeno je, da je nižja ID povezana s povečanim tveganjem za razvoj Alzheimerjeve bolezni (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID je bil uporabljen v dveh različnih različicah: proposicionalna gostota idej (PID) šteje izražene ideje in se lahko uporablja za katero koli besedilo, medtem ko semantična gostota idej (SID) šteje vnaprej določene enote informacijske vsebine in je seveda bolj primerna za normativne domene, kot so opravila opisa slike. V tem prispevku smo razvili DEPID, novo metodo, ki temelji na odvisnosti za računalništvo PID, in njeno različico DEPID-R, ki omogoča izključitev ponavljajočih se idej – značilnosti govora AD. Prvo primerjavo avtomatično ekstrahiranih PID in SID v diagnostični opravili klasifikacije na dveh različnih naborih podatkov AD, ki pokrivajo tako domeno zaprte teme kot domeno prostega odpoklica. Medtem ko je SID boljši na normativnem naboru podatkov, dodajanje PID vodi do majhnega, vendar znatnega izboljšanja (+1,7 F-score). Na naboru podatkov o prostih temah je PID boljši od SID, kot je bilo pričakovano (77,6 v primerjavi s 72,3 v F-rezultatih), vendar dodajanje funkcij, ki izhajajo iz besede vključevanje grozdov, ki temelji na samodejnem SID, znatno poveča rezultate, kar vodi do F-rezultata 84,8.', 'he': 'צפיפות הרעיון (ID) מדדים את הקצב שבו רעיונות או מחויבות אלמנטריות מוביעים בבטא או בטקסט. מצא שזהות נמוכה יותר קשורה לסיכון גבוה לפיתוח מחלת אלצהיימר (AD) (Snowdon et al., 1996; Engelman et al., 2010). ID השתמש בשני גרסאות שונות: צפיפות רעיונות הצעה (PID) סופרת את הרעיונות המוביעים והיא יכולה להיות משמשת לכל טקסט בזמן שצפיפות רעיונות סמנטיות (SID) סופרת יחידות מידע מוגדרות מראש והיא יותר משתמשת באופן טבעי לתחומים נורמטיים, כמו משימות תיאור תמונות. בעיתון הזה, אנחנו מפתחים DEPID, שיטה חדשה מבוססת על תלויות לחישוב PID, וגרסה שלו DEPID-R שמאפשרת להוציא מחדש רעיונות-תכונה אופיינית לנאום AD. אנו מבצעים את השוואה הראשונה של PID מווצא באופן אוטומטי ו SID במשימת ההסגרה האבחנה על שני קבוצות נתונים AD שונים מכילים גם חוקים סגורים וגם חופשיים חזרה. While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score).  על קבוצת הנתונים חופשית, PID מבצע טוב יותר משSID כפי שציפיתי (77.6 נגד 72.3 בתוצאה F) אך להוסיף את המאפיינים שנוצרו מהמילה "קיבלת מקבוצת" בסיס SID האוטומטי מגבירה את התוצאות באופן משמעותי, מה שמוביל לתוצאה F של 84.8.', 'jv': 'drawable-action string" in "context_BAR_stringLink Display boxes Nang pepulan iki, kita diwehhi DEPID, basa gambar dipunangé perusahaan PID lan nganggo DEPID-R versi sing perusahaan kanggo ngilanggar nggawe ide-perusahaan langgar tanggal singular PID. We konduto the first alignment of automatically extract PID and PID in the diagram category task on the second separated ED dataset section section', 'bo': "idea Density(ID)ནང་དུ་བསམ་ཚུལ་དང་རྣམ་གྲངས་སྔོན་སྒྲིག་ཀྱི་ཚད་གང་འདྲ་ཡིན་པ་སྐད་བཤད་པའམ་ཡི་གེ བསམ་གཞུང་ནི་Alzheimer's disease་དང་མཐུན་རྐྱེན་བའི་ཉེན་ཁ་ཡུལ་དང་འབྲེལ་བ་ཡིན། ID has been used in two different versions: propositional idea density (PID) counts the expressed ideas and can be applied to any text while semantic idea density (SID) counts pre-defined information content units and is naturally more applicable to normative domains, such as picture description tasks. In this paper, we develop DEPID, a novel dependency-based method for computing PID, and its version DEPID-R that enables to exclude repeating ideas-a feature characteristic to AD speech. ང་ཚོས་AD་གནད་དོན་ཚན་གཉིས་ཀྱིས་རང་འགུལ་གྱིས་PID དང་SID་ཚོ་རང་འགུལ་གྱིས་ངལ་འདེབས་པའི་མཉམ་དང་ལྡན་གྱི་གནད་སྡུད་ཚན་གཉིས་མ་འདྲ་ While SID performs better on the normative dataset, adding PID leads to a small but significant improvement (+1.7 F-score). On the free-topic dataset, PID performs better than SID as expected (77.6 vs 72.3 in F-score) but adding the features derived from the word embedding clustering underlying the automatic SID increases the results considerably, leading to an F-score of 84.8."}
{'en': 'Zero-Shot Relation Extraction via Reading Comprehension', 'ar': 'استخلاص العلاقة الصفرية عن طريق الفهم القرائي', 'es': 'Extracción de relaciones de tiro cero a través de la comprensión lectora', 'pt': 'Extração de Relação Zero-Shot via Compreensão de Leitura', 'fr': 'Extraction de la relation Zero-Shot via la compréhension de lecture', 'ja': '読解によるゼロショット関係抽出', 'zh': '读解提取零次性', 'ru': 'Извлечение отношений нулевого выстрела через понимание чтения', 'hi': 'पढ़ने की समझ के माध्यम से शून्य-शॉट संबंध निष्कर्षण', 'ga': 'Eastóscadh Caidreamh Zero-Shot trí Léamhthuiscint', 'ka': 'Name', 'hu': 'Zéró lövéses kapcsolat kivonása olvasási értéken keresztül', 'el': 'Εξαγωγή σχέσης μηδενικού πυροβολισμού μέσω κατανόησης ανάγνωσης', 'kk': 'Оқу құрылымы арқылы 0- Shot қатынасын тарқату', 'it': 'Estrazione della relazione Zero-Shot tramite comprensione della lettura', 'lt': 'Nuotraukų santykio ekstrakcija skaitant kompresiją', 'mk': 'Екстракција на врска со нула- пукање преку читање на разбирање', 'mt': 'Estrazzjoni ta’ Relazzjoni Żro-Shot permezz ta’ Komprensjoni tal-qari', 'ms': 'Ekstraksi Hubungan Semula-Tembak melalui Pemahaman Pembacaan', 'ml': 'വായിക്കുന്നതിനാല്\u200d പൂര്\u200dണ്ണമായി വെടിവെക്കുന്നതിന്റെ വിലാസപുറപ്പെടുത്തുക', 'mn': 'Нэг-Shot холбоотой хамаарал гаргах', 'no': 'Utpakking av null- Shot- relasjon via lesing av komprehension', 'pl': 'Ekstrakcja relacji zerowych poprzez zrozumienie odczytu', 'ro': 'Extragerea relației zero-shot prin înțelegerea citirii', 'sr': 'Ekstrakcija odnosa nula-pucnjave putem èitanja kompresije', 'si': 'Name', 'so': 'Ka soo saarista iskudarka', 'ta': 'படித்தல் முடிப்பு வழியாக வெளியேறுதல்', 'ur': 'Zero-Shot رابطہ اخراج', 'sv': 'Extraktion av nollskottsrelation via läsförståelse', 'uz': 'Name', 'vi': 'Rút giảm ảnh lượng bằng phim', 'da': 'Zero-Shot Relation Extraction via læseforståelse', 'hr': 'Ekstrakcija odnosa nula-pucnjave preko komprehenzije čitanja', 'nl': 'Zero-Shot Relatie Extractie via Reading Comprehension', 'id': 'Ekstraksi Hubungan Zero-Shot melalui Pembacaan Kompresi', 'bg': 'Извличане на връзка с нулев изстрел чрез разбиране за четене', 'fa': 'اخراج رابطه\u200cهای صفر-Shot via Reading Comprehension', 'sw': 'Kutengeneza Kuhusiana na Kizuizi cha Shot', 'de': 'Zero-Shot Relation Extraction mittels Leseverständnis', 'ko': '읽기와 이해를 바탕으로 하는 제로 포 관련 추출', 'af': 'Name', 'am': 'አዲስ ዶሴ ፍጠር', 'az': 'QÄ±sqa-Shot Ä°liÅŸkilÉ™ri AĂ§Ä±rmaq', 'tr': 'Derjesi okamak üçin 0-täk ilişki açmak', 'bn': 'পাঠ করার মাধ্যমে জিরো- শুট সম্পর্ক এক্সট্র্যাক্ট্র্যাকশন', 'sq': 'Ekstraktimi i marrëdhënies zero-Shot nëpërmjet leximit të kompresionit', 'bs': 'Ekstrakcija odnosa iz nule-pucnjave putem pročitanja kompresije', 'et': 'Zero-Shot seose ekstraheerimine lugemise arusaamise kaudu', 'hy': 'Comment', 'ca': 'Extracció de la relació zero-Shot a través de la comprensió de llegir', 'cs': 'Extrakce vztahů nulovým výstřelem prostřednictvím porozumění čtení', 'fi': 'Zero-Shot Relation Extraction by Reading Comprehension', 'jv': '0-shot Relation extract', 'he': 'מחלקת יחסים אפס-יריות באמצעות ביטוי קריאה', 'ha': 'KCharselect unicode block name', 'sk': 'Izvleček odnosa z ničelnim posnetkom prek razumevanja branja', 'bo': 'Zero-Shot Relation Extraction via Reading Comprehension'}
{'en': 'We show that relation extraction can be reduced to answering simple reading comprehension questions, by associating one or more natural-language questions with each relation slot. This reduction has several advantages : we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, for which we have no labeled training examples. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.', 'ar': 'نظهر أن استخراج العلاقة يمكن اختزاله في الإجابة على أسئلة الفهم القرائي البسيطة ، من خلال ربط سؤال أو أكثر من أسئلة اللغة الطبيعية مع كل خانة علاقة. هذا التخفيض له العديد من المزايا: يمكننا (1) تعلم نماذج استخلاص العلاقة من خلال توسيع تقنيات فهم القراءة العصبية الحديثة ، (2) بناء مجموعات تدريب كبيرة جدًا لتلك النماذج من خلال الجمع بين الأسئلة الخاصة بالعلاقة الخاصة بمصادر الحشد مع الإشراف عن بعد ، و حتى (3) قم بالتعلم عن طريق استخلاص أنواع علاقات جديدة يتم تحديدها فقط في وقت الاختبار ، والتي ليس لدينا أمثلة تدريبية عليها. توضح التجارب على مهمة ملء الفتحات في ويكيبيديا أن النهج يمكن أن يعمم على أسئلة جديدة لأنواع العلاقات المعروفة بدقة عالية ، وأن التعميم الصفري لأنواع العلاقات غير المرئية ممكن ، بمستويات دقة أقل ، مما يضع شريطًا للعمل المستقبلي على هذه المهمة.', 'pt': 'Mostramos que a extração de relações pode ser reduzida a responder a perguntas simples de compreensão de leitura, associando uma ou mais perguntas de linguagem natural a cada slot de relação. Essa redução tem várias vantagens: podemos (1) aprender modelos de extração de relação estendendo técnicas recentes de leitura e compreensão neural, (2) construir conjuntos de treinamento muito grandes para esses modelos combinando perguntas de crowdsourcing específicas de relação com supervisão distante e mesmo (3) fazer aprendizado de tiro zero extraindo novos tipos de relação que são especificados apenas no tempo de teste, para os quais não temos exemplos de treinamento rotulados. Experimentos em uma tarefa de preenchimento de slots da Wikipedia demonstram que a abordagem pode generalizar para novas perguntas para tipos de relações conhecidos com alta precisão, e que a generalização de tiro zero para tipos de relações invisíveis é possível, em níveis de precisão mais baixos, definindo o padrão para trabalhos futuros em esta tarefa.', 'es': 'Mostramos que la extracción de relaciones se puede reducir a responder preguntas simples de comprensión lectora, asociando una o más preguntas de lenguaje natural con cada espacio de relación. Esta reducción tiene varias ventajas: podemos (1) aprender modelos de extracción de relaciones mediante la ampliación de las técnicas recientes de comprensión de lectura neuronal, (2) crear conjuntos de entrenamiento muy grandes para esos modelos combinando preguntas multitudinarias específicas de la relación con supervisión a distancia, e incluso (3) realizar un aprendizaje de tiro cero mediante extraer nuevos tipos de relación que solo se especifican en el momento de la prueba, para los que no tenemos ejemplos de entrenamiento etiquetados. Los experimentos en una tarea de llenado de espacios de Wikipedia demuestran que el enfoque puede generalizar a nuevas preguntas para tipos de relación conocidos con alta precisión, y que la generalización cero a tipos de relación invisibles es posible, con niveles de precisión más bajos, lo que establece el listón para el trabajo futuro en esta tarea.', 'fr': "Nous montrons que l'extraction de relation peut être réduite à la réponse à de simples questions de compréhension de lecture, en associant une ou plusieurs questions en langage naturel à chaque case de relation. Cette réduction présente plusieurs avantages\xa0: nous pouvons (1) apprendre des modèles d'extraction de relations en étendant les techniques récentes de compréhension et de lecture neuronale, (2) construire de très grands ensembles d'entraînement pour ces modèles en combinant des questions participatives spécifiques à la relation avec une supervision à distance, et même (3) faire un apprentissage zero-shot en extraction de nouveaux types de relations qui ne sont spécifiés qu'au moment du test, pour lesquels nous n'avons aucun exemple de formation étiqueté. Des expériences sur une tâche de remplissage de créneaux Wikipédia démontrent que l'approche peut généraliser à de nouvelles questions pour des types de relations connus avec une grande précision, et qu'une généralisation zéro à des types de relations invisibles est possible, à des niveaux de précision inférieurs, ce qui place la barre pour les travaux futurs sur cette tâche.", 'ja': '関係抽出は、1つ以上の自然言語の質問を各関係スロットに関連付けることにより、単純な読解の理解の質問に答えることに減らすことができることを示しています。この削減には、いくつかの利点があります。（ 1 ）最近のニューラル読解技術を拡張することによって関係抽出モデルを学ぶことができます。（ 2 ）関係固有のクラウドソースの質問と遠隔監督を組み合わせることによって、それらのモデルの非常に大きなトレーニングセットを構築します。（ 3 ）テストタイムでのみ指定された新しい関係タイプを抽出することによっても、ゼロショット学習を行うことができます。これについては、ラベル付けされたトレーニング例がありません。ウィキペディアのスロット充填タスクの実験では、このアプローチが既知のリレーションタイプの新しい質問を高精度で一般化することができ、見えないリレーションタイプへのゼロショットの一般化は、より低い精度レベルで可能であり、このタスクに関する将来の作業のためのバーを設定することができることが示されている。', 'zh': '明以一自然语言相关,取可简答。 减有数善:可(1)广近神经读解以学取模,(2)因特定于众包,与远程督合,为之大集,至(3)取新零镜头学,吾无表示例。 维基百科插槽充任之实验,可以高精度及知,可以零次泛化不见,为将来之准。', 'hi': 'हम दिखाते हैं कि संबंध निष्कर्षण को प्रत्येक संबंध स्लॉट के साथ एक या अधिक प्राकृतिक भाषा के प्रश्नों को जोड़कर, सरल पढ़ने की समझ के सवालों का जवाब देने के लिए कम किया जा सकता है। इस कमी के कई फायदे हैं: हम (1) हाल ही में तंत्रिका पढ़ने-समझ तकनीकों का विस्तार करके संबंध-निष्कर्षण मॉडल सीख सकते हैं, (2) दूर के पर्यवेक्षण के साथ संबंध-विशिष्ट भीड़-स्रोत वाले प्रश्नों के संयोजन से उन मॉडलों के लिए बहुत बड़े प्रशिक्षण सेट का निर्माण कर सकते हैं, और यहां तक कि (3) नए संबंध प्रकारों को निकालकर शून्य-शॉट सीखने का काम करते हैं जो केवल परीक्षण-समय पर निर्दिष्ट होते हैं, जिसके लिए हमारे पास कोई लेबल प्रशिक्षण उदाहरण नहीं है। एक विकिपीडिया स्लॉट-भरने के कार्य पर प्रयोगों से पता चलता है कि दृष्टिकोण उच्च सटीकता के साथ ज्ञात संबंध प्रकारों के लिए नए प्रश्नों को सामान्यीकृत कर सकता है, और यह कि अनदेखी संबंध प्रकारों के लिए शून्य-शॉट सामान्यीकरण संभव है, कम सटीकता स्तरों पर, इस कार्य पर भविष्य के काम के लिए बार सेट करना।', 'ru': 'Мы показываем, что извлечение отношения может быть сведено к ответам на простые вопросы понимания чтения, путем связывания одного или нескольких естественноязычных вопросов с каждым слотом отношения. Это сокращение имеет несколько преимуществ: мы можем (1) изучать модели отношения-экстракции, расширяя последние нейронные методы понимания чтения, (2) строить очень большие обучающие наборы для этих моделей, комбинируя вопросы, связанные с отношениями, из краудсорсинговых источников с дистанционным надзором, и даже (3) делать обучение с нулевым выстрелом, извлекая новые типы отношений, которые указаны только во время тестирования, для которых у нас нет помеченных обучающих примеров. Эксперименты над задачей заполнения слотов Википедии показывают, что подход может обобщать новые вопросы для известных типов отношений с высокой точностью, и что обобщение с нулевым выстрелом для невидимых типов отношений возможно при более низких уровнях точности, устанавливая планку для будущей работы над этой задачей.', 'ga': 'Léirímid gur féidir eastóscadh caidrimh a laghdú go dtí ceisteanna simplí léamhthuisceana a fhreagairt, trí cheist i dteanga nádúrtha amháin nó níos mó a cheangal le gach sliotán caidrimh. Tá buntáistí éagsúla ag baint leis an laghdú seo: is féidir linn (1) múnlaí gaol-astarraingthe a fhoghlaim trí theicnící néar-thuisceana le déanaí a leathnú, (2) tacair oiliúna an-mhóra a thógáil do na samhlacha sin trí cheisteanna a bhaineann go sonrach le slua-fhoinsithe a chomhcheangal le maoirsiú i bhfad i gcéin, agus fiú (3) foghlaim gan lámhaigh a dhéanamh trí chineálacha nua caidrimh a bhaint nach bhfuil sonraithe ach ag am tástála, nach bhfuil aon samplaí oiliúna lipéadaithe againn ina leith. Léiríonn turgnaimh ar thasc líonadh sliotán Vicipéid gur féidir leis an gcur chuige ginearálú chuig ceisteanna nua maidir le cineálacha caidrimh aitheanta le cruinneas ard, agus gur féidir ginearálú nialasach do chineálacha caidrimh neamhfheicthe, ag leibhéil chruinneas níos ísle, chun an barra a shocrú le haghaidh obair amach anseo ar. an tasc seo.', 'hu': 'Megmutatjuk, hogy a kapcsolat extrakció egyszerű olvasásértési kérdések megválaszolására korlátozható, ha egy vagy több természetes nyelvű kérdést kapcsolnak minden kapcsolattartóhoz. Ennek a csökkentésnek számos előnye van: 1) megtanulhatjuk a kapcsolat-extrakciós modelleket a legújabb neurális olvasási-értési technikák kiterjesztésével, (2) ezekhez a modellekhez nagyon nagy képzési készleteket építhetünk a kapcsolatspecifikus tömegspecifikus kérdések távoli felügyelettel való kombinációjával, sőt (3) null-shot tanulást végezhetünk új kapcsolattípusok kivonásával, amelyeket csak a tesztidőben határoztak meg, amelyekre nincsenek címkézett képzési példáink. Egy Wikipédia slot-töltő feladaton végzett kísérletek azt mutatják, hogy a megközelítés nagy pontossággal általánosítható az ismert kapcsolattípusok új kérdéseire, és hogy a nulla lövés általánosítása láthatatlan kapcsolattípusokra alacsonyabb pontossági szinten lehetséges, így beállítva a jövőbeli munkához.', 'el': 'Δείχνουμε ότι η εξαγωγή σχέσεων μπορεί να μειωθεί στην απάντηση απλών ερωτήσεων κατανόησης ανάγνωσης, συσχετίζοντας μία ή περισσότερες ερωτήσεις φυσικής γλώσσας με κάθε υποδοχή σχέσης. Αυτή η μείωση έχει αρκετά πλεονεκτήματα: μπορούμε (1) να μάθουμε μοντέλα εξαγωγής σχέσεων επεκτείνοντας τις πρόσφατες τεχνικές νευρωνικής ανάγνωσης-κατανόησης, (2) να χτίσουμε πολύ μεγάλα εκπαιδευτικά σύνολα για αυτά τα μοντέλα συνδυάζοντας συγκεκριμένες ερωτήσεις από το πλήθος με μακρινή επίβλεψη, ακόμη και (3) να κάνουμε μηδενική μάθηση εξάγοντας νέους τύπους σχέσεων που καθορίζονται μόνο κατά τη διάρκεια της δοκιμής, για τα οποία δεν έχουμε επισημασμένα παραδείγματα κατάρτισης. Τα πειράματα σε μια εργασία πλήρωσης αυλακώσεων της Βικιπαίδειας δείχνουν ότι η προσέγγιση μπορεί να γενικεύσει σε νέες ερωτήσεις για γνωστούς τύπους σχέσεων με υψηλή ακρίβεια, και ότι η μηδενική γενίκευση σε αόρατους τύπους σχέσεων είναι δυνατή, σε χαμηλότερα επίπεδα ακρίβειας, θέτοντας τον πήχη για μελλοντική εργασία σε αυτήν την εργασία.', 'it': "Mostriamo che l'estrazione delle relazioni può essere ridotta a rispondere a semplici domande di comprensione della lettura, associando una o più domande di linguaggio naturale ad ogni slot di relazione. Questa riduzione ha diversi vantaggi: possiamo (1) imparare modelli di estrazione-relazione estendendo le recenti tecniche di lettura-comprensione neurale, (2) costruire set di formazione molto grandi per quei modelli combinando domande crowd-sourced specifiche di relazione con supervisione a distanza, e persino (3) fare apprendimento zero-shot estraendo nuovi tipi di relazione che sono specificati solo al momento del test, per i quali non abbiamo esempi di formazione etichettati. Esperimenti su un'attività di riempimento slot di Wikipedia dimostrano che l'approccio può generalizzare a nuove domande per tipi di relazioni noti con alta precisione, e che la generalizzazione zero-shot a tipi di relazioni invisibili è possibile, a livelli di precisione più bassi, impostando la barra per il lavoro futuro su questo compito.", 'kk': 'Біз қатынасы тарқатуға қарапайым оқу сұрақтарына жауап беруге болады. Бір немесе бірнеше табиғи тіл сұрақтарын әрбір қатынасы сұрақтарымен байланыстыруға болады. Бұл қиындығында бірнеше артықшылықтар бар: біз (1) жаңа невралдық оқу түсініктерінің түсініктерін өзгертуге болады, (2) бұл үлгілер үшін өте үлкен оқыту бағдарламаларын құруға болады. Көпшіліктердің қатынасы артық қатынас артық сұрақтарды қашықтағы қатынас арқылы Бұл үшін жарлық оқыту мысалдары жоқ. Википедия слотты толтыру тапсырмасының тәжірибелері, тәжірибесі білетін қатынас түрлерінің жаңа сұрақтарына көбірек болады дегенді көрсетеді, және қатынас түрлеріне нөл- шарт жалпы түрлеріне қатынау мүмкін, төмен дұрыс деңгейін', 'lt': 'Mes rodome, kad santykių išgavimas gali būti sumažintas atsakant į paprastus skaitymo supratimo klausimus, sujungiant vieną ar daugiau klausimų natūraliomis kalbomis su kiekvienu santykių laiko tarpsniu. This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, - kuriam nėra pažymėtų mokymo pavyzdžių. Eksperimentai dėl Wikipedia laiko tarpsnių užpildymo užduoties rodo, kad metodas gali apskritai išspręsti naujus klausimus, susijusius su žinomais ryšių tipais su dideliu tikslumu, ir kad nulinio nuotolio generalizavimas su nematomis ryšių tipais yra įmanomas mažesniu tikslumo lygiu, nustatant būsimo darbo šiame uždavinyje ribas.', 'mk': 'Ние покажуваме дека извлекувањето на односите може да се намали на одговор на едноставни прашања за разбирање на читањето, со поврзување на едно или повеќе прашања на природен јазик со секое место за врска. Оваа намалување има неколку предности: можеме (1) да научиме модели за извлекување односи со проширување на неодамнешните техники за читање-разбирање на нервите, (2) да изградиме многу големи набори за овие модели со комбинација на прашања специфични за односите од публика со далечен надзор, а дури и (3) да научиме нула-стрела со извлекување нови ти За кои немаме примери за обука. Експериментите на задачата на Википедија за исполнување на слотови покажуваат дека пристапот може да се генерализира на новите прашања за познати типови на односи со висока прецизност, и дека генерализацијата со нула на невидени типови на односи е можна, на пониски нивоа на прецизност, поставувајќи го барот за идната работа на оваа зад', 'ms': 'Kami menunjukkan bahawa ekstraksi hubungan boleh dikurangkan kepada menjawab soalan pemahaman bacaan sederhana, dengan menghubungkan satu atau lebih soalan bahasa alam dengan setiap slot hubungan. Pengurangan ini mempunyai beberapa keuntungan: kita boleh (1) belajar model ekstraksi-hubungan dengan memperluas teknik pembacaan-pemahaman saraf yang baru-baru ini, (2) membina set latihan yang sangat besar untuk model-model itu dengan menggabungkan soalan-soalan khusus hubungan ramai dengan pengawasan jauh, dan bahkan (3) belajar-menembak sifar dengan ekstraksi jenis hubungan baru yang hanya dinyatakan pada masa ujian, - yang mana kita tiada contoh latihan yang ditabel. Eksperimen pada tugas penuhian slot Wikipedia menunjukkan bahawa pendekatan boleh menyebarkan kepada soalan baru untuk jenis hubungan yang diketahui dengan ketepatan tinggi, dan bahawa keseluruhan tembakan sifar kepada jenis hubungan yang tidak terlihat adalah mungkin, pada tahap ketepatan yang lebih rendah, menetapkan bar untuk kerja masa depan pada tugas ini.', 'mt': 'Aħna nuru li l-estrazzjoni tar-relazzjoni tista’ titnaqqas għal tweġiba għal mistoqsijiet sempliċi ta’ fehim tal-qari, billi tiġi assoċjata mistoqsija waħda jew aktar b’lingwa naturali ma’ kull slot ta’ relazzjoni. Dan it-tnaqqis għandu bosta vantaġġi: nistgħu (1) nitgħallmu mudelli ta’ estrazzjoni tar-relazzjonijiet billi jestendu t-tekniki reċenti ta’ qari u komprensjoni newrali, (2) nibnu settijiet ta’ taħriġ kbar ħafna għal dawk il-mudelli billi nikkombinaw mistoqsijiet speċifiċi għall-popolazzjoni b’sorveljanza mill-bogħod, u saħansitra (3) nagħmlu tagħlim mingħajr skop billi nistruttaw tipi ġodda ta’ relazzjonijiet li huma speċifikati biss fil-ħin tat-test • li għalihom m’għandna l-ebda eżempju ta’ taħriġ ittikkettat. L-esperimenti fuq kompitu ta’ mili ta’ slots tal-Wikipedia juru li l-approċċ jista’ jiġġeneralizza għal mistoqsijiet ġodda għal tipi ta’ relazzjonijiet magħrufa b’preċiżjoni għolja, u li ġeneralizzazzjoni b’zero-shot għal tipi ta’ relazzjonijiet mhux osservati hija possibbli, f’livelli ta’ preċiżjoni aktar baxxi, li tistabbilixxi l-ostaklu għal xogħol futur fuq dan il-kompitu.', 'ml': 'നമ്മള്\u200d കാണിച്ചുകൊടുക്കുന്നത് എല്ലാ ബന്ധങ്ങളുടെയും സ്ലോട്ടുകൊണ്ടും ഒന്നോ കൂടുതല്\u200d സ്വാഭാവികമായ ഭാഷ ചോദ്യങ്ങള്\u200d ചേര്\u200dത ഈ കുറയ്ക്ക് കുറച്ച് ഉപകാരങ്ങളുണ്ട്: നമുക്ക് ബന്ധപ്പെടുത്താനുള്ള മോഡലുകള്\u200d പഠിക്കാം (1) അടുത്ത പുതിയ ന്യൂറല്\u200d വായിക്കുന്ന വിവരങ്ങള്\u200d വികസിപ്പിക്കുന്നതിനാല്\u200d, (2) പരീക്ഷ സമയത്ത് മാത്രമേ വ്യക്തമാക അതിനാല്\u200d നമുക്കൊരു ലേബിള്\u200d ട്രെയിനിങ്ങളുടെ ഉദാഹരണങ്ങളുമില്ല. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.', 'ka': 'ჩვენ ჩვენ აჩვენებთ, რომ კონტაქციის ექსტრაქცია შეიძლება გადასრულებული ყოველ კონტაქციის კითხვების შესახებ, ერთი ან უფრო მეტი ნაირადი ენის კითხვების შესახებ ყოველ ეს შემცირება აქვს რამდენიმე მოსახლეობები: ჩვენ შეგვიძლია (1) გავისწავლოთ პრობლექციის ექსტრექციის მოდელების შესახებ ახალი ნეიროლური კითხვის შესახებ ტექნექციების გაზრუნდეთ, (2) ახალი პრობლექციის ტიპების გაზრუნდეთ ძალიან დიდი შემცირება ამ მოდელები რომელსაც ჩვენ არ გვაქვს მაგალითების მაგალითები. ვიკიპედიაში სოტიპედიაში სოტის დანარჩენის რაოდენობაში გამოცნობა, რომ პროგრამა შეუძლია განვიცნობით ახალი კითხვებისთვის, რომელიც უფრო მარტივია, და რომ ნულ სოტის გენერალიზაცია შესაძლებელია არაცნობით კითხვების ტი', 'no': 'Vi viser at utpakking av relasjonar kan reduserast til å svara på enkle lesingsforståelse, ved å tilknyta ein eller fleire naturspråksspørsmål med kvar relasjonsplass. Denne reduksjonen har fleire fordeler: vi kan (1) lære relasjonsekstraksjonsmodeller ved å utvide nyleg nøyralforståking av teknikkar, (2) bygge veldig stor opplæring for desse modelane ved å kombinere sammenhenga spesifikke spørsmål med fleire opplæringar med distant oversikt, og til og med (3) læring av nullsatt ved å ekstrahera nye relasjonstypar som berre er spesifisert på testtid, Eksempel på trening som vi ikkje har merkelig. Eksperimentar på eit Wikipedia-plass-fylleringsoppgåve viser at tilnærminga kan generellisere til nye spørsmål for kjente relasjonstypar med høg nøyaktig, og at generalisering av nullsett til ukjende relasjonstypar er mogleg, på lågare nøyaktighetsnivå, sett linja for framtidige arbeid på denne oppgåva.', 'mn': 'Бид харилцааны хамаарал гаргах нь энгийн унших ойлголтын асуултуудыг хариулах боломжтой байгалийн хэлний асуултуудыг харуулж болно. Энэ багасгал нь олон ашигтай: бид (1) саяхан мэдрэлийн унших болон ойлголтын технологийг нэмэгдүүлж харилцаа авах загваруудыг сурах боломжтой болно, (2) эдгээр загваруудын тулд маш том сургалтын багц бүтээж болно. Харин (3) хоорондоо холбоотой асуултуудыг холын зөвхөн шалгах үед зөвхөн тодорхойло Үүний тулд бидэнд сургалтын жишээ биш. Википедийн слотын дүүргэх үйл ажиллагааны туршилт нь ойлголт нь маш өндөр тодорхой харилцааны төрлийн шинэ асуулт болон харилцааны харилцааны төрлийн 0-шууд ерөнхийлөгч боломжтой гэдгийг харуулж байна. Дараагийн ажил дээр ажиллах барыг бага зөв хэмжээнд нь тодорхойлж', 'ro': 'Noi arătăm că extragerea relației poate fi redusă la răspunsul la întrebări simple de înțelegere a lecturii, asociend una sau mai multe întrebări de limbaj natural cu fiecare slot de relație. Această reducere are mai multe avantaje: putem (1) să învățăm modele de extracție a relației prin extinderea tehnicilor recente de citire-înțelegere neurală, (2) să construim seturi de instruire foarte mari pentru aceste modele prin combinarea întrebărilor specifice relației publice cu supravegherea la distanță și chiar (3) să facem învățare zero-shot prin extragerea de noi tipuri de relații care sunt specificate numai în timpul testului, pentru care nu avem exemple de formare etichetate. Experimentele pe o sarcină de umplere a sloturilor Wikipedia demonstrează că abordarea se poate generaliza la noi întrebări pentru tipurile de relații cunoscute cu mare precizie și că generalizarea zero-shot la tipurile de relații nevăzute este posibilă, la niveluri mai mici de precizie, setarea barei pentru lucrările viitoare la această sarcină.', 'sr': 'Pokazujemo da se izvlačenje odnosa može smanjiti na odgovor na jednostavna pitanja o razumijevanju čitanja, povezujući jedno ili više pitanja prirodnog jezika sa svakim mjestom veze. Ova smanjenja ima nekoliko prednosti: možemo (1) naučiti modele izvlačenja odnosa proširenjem nedavnih tehnika razumijevanja neuroloških čitanja, (2) izgraditi veoma velike obuke za te modele kombinacijom pitanja koje su specifične veze sa mnogim izvorima sa dalekim nadzorom, a čak i (3) učiti nulo-pucanjem izvlačenjem novih vrsta odnosa koji su samo određeni u testu, Nemamo primjere obuke. Eksperimenti na zadatku ispunjavanja slot a na Wikipediji pokazuju da pristup može generalizirati na nove pitanja za poznate vrste odnosa sa visokom preciznošću, i da je moguće generalizacija nula snimaka na nevidljive vrste odnosa na nižim nivoima tačnosti, postavljajući bar za budući rad na ovom zadatku.', 'pl': 'Pokazujemy, że ekstrakcja relacji może zostać zredukowana do odpowiedzi na proste pytania dotyczące zrozumienia czytania poprzez skojarzenie jednego lub więcej pytań naturalnych z każdym slotem relacji. Redukcja ta ma kilka zalet: możemy (1) nauczyć się modeli relacji-ekstrakcji poprzez rozszerzenie najnowszych technik czytania neuronowego, (2) zbudować bardzo duże zestawy treningowe dla tych modeli poprzez łączenie relacji specyficznych pytań crowdsourced z odległym nadzorem, a nawet (3) uczyć się zero-shot poprzez ekstrakcję nowych typów relacji, które są określone tylko w czasie testu, dla których nie mamy oznaczonych przykładów szkoleń. Eksperymenty na zadaniu wypełniającym szczelinę Wikipedii pokazują, że podejście to może uogólniać do nowych pytań dla znanych typów relacji z dużą dokładnością i że uogólnienie zerowe do niewidocznych typów relacji jest możliwe, przy niższych poziomach dokładności, ustawiając poprzeczkę dla przyszłych prac nad tym zadaniem.', 'so': "Waxaynu tusnaynaa in la soo bixinayo xiriirka looga jawaabi karo su'aalo fudud oo akhriska, in lagu wadaago su'aalo af kasta oo la xiriira hal ama ka badan oo af dabiiciga ah. Qashinkaasi waxay leedahay faa'iido badan: waxan ku baran karnaa tusaalaha iskudarka ee la soo saaro noocyada neurada ee la soo dhowaaday, (2) u dhisi karo koorasyo aad u weyn tusaalahaas, si aad u qabsato su'aalo kala duduwan oo aad u leedahay ilaalinta qaranka, xittaa (3) waxan ku sameyn karnaa wax aan wax lagu baran karno noocyo cusub oo lagu qorayo marka la tijaabiyo oo kaliya, oo aanan u lahayn tusaalooyin tababar ah. Imtixaan ku saabsan shaqada Wikipedia oo ku buuxinaya waxey muujiyaan in qaababka cusub uu u soo saari karo su'aalaha la yaqaan noocyada xiriirka oo aad u sahlan, waxaana suurtowda in zero-shot laga soo saaro noocyada qarsoon ee xiriirka, si hoos u saxda, uu u sameynayo dariiska shaqada mustaqbalka ah ee shaqadaas.", 'sv': 'Vi visar att relationsextraktion kan reduceras till att besvara enkla läsförståelsefrågor, genom att associera en eller flera naturspråksfrågor med varje relation slot. Denna minskning har flera fördelar: vi kan (1) lära oss relationsextraktionsmodeller genom att utöka de senaste neurala läs-förståelseteknikerna, (2) bygga mycket stora träningsuppsättningar för dessa modeller genom att kombinera relationsspecifika crowdsourced frågor med fjärrövervakning, och även (3) göra noll-shot lärande genom att extrahera nya relationstyper som bara specificeras vid testtid, för vilka vi inte har några märkta utbildningsexempel. Experiment på en Wikipedia slot-fyllning uppgift visar att tillvägagångssättet kan generalisera till nya frågor för kända relationstyper med hög noggrannhet, och att noll-skott generalisering till osynliga relationstyper är möjlig, vid lägre noggrannhetsnivåer, att ställa in ribban för framtida arbete med denna uppgift.', 'si': 'අපි පෙන්වන්නේ සම්බන්ධ ප්\u200dරශ්නයක් පිළිගන්න පුළුවන් සාමාන්\u200dය කියනවට ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පිළිගන්න, එකක්  මේ පරීක්ෂණය සමහර ප්\u200dරශ්නයක් තියෙනවා: අපිට (1) පුළුවන් සම්බන්ධ-ප්\u200dරශ්නයක් ඉගෙන ගන්න පුළුවන් අලුත් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් සම්බන්ධ කරන්න, සහ (3) සුරුද ඒ වගේම අපිට ලේබල් කිරීම් උදාහරණයක් නෑ. විකිපිඩියා ස්ලෝට් පුරවන්න වැඩේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට අනුව ප්\u200dරශ්නයක් පුළුවන් කියලා ප්\u200dරශ්නයක් විශ්වාස කරන්න පුළුවන් විදිහට, සම', 'ta': 'நாம் காண்பிக்கிறோம் ஒவ்வொரு தொடர்பு செருகுவாக்கத்துடனும் ஒன்று அல்லது அதிகமாக இயற்கையான மொழி கேள்விகளை இணைக்கும் மூ இந்த குறைப்பு பல பயன்பாடுகள் உள்ளது: நாம் (1) சமீபத்தில் புதிய தொடர்பு பிரிப்பு மாதிரிகளை படிக்க முடியும் - சூழ்நிலை தொகுதி தொகுதிகளை விரிவாக்கும் மூலம் இந்த மாதிரிகளுக்கு மிகவும் பெரிய பயிற்சி அமை குறிப்பிட்ட பயிற்சி உதாரணங்கள் இல்லை. விக்கிபிடியா செருகுவாய் நிரப்பும் பணியின் முயற்சிகள் அதிக சரியாக தெரியும் தொடர்பு வகைகளுக்கு புதிய கேள்விகளை உருவாக்க முடியும் என்பதை காட்டுகிறது, மறையாத உறவு வகைகள', 'ur': 'ہم دکھاتے ہیں کہ نسبت اٹھانے کے لئے ساده پڑھنے کے سوال کی جواب دینے کے لئے کم کر دی جاتی ہے، ایک یا زیادہ طبیعی زبان سوال کے ساتھ ہر نسبت کے سطح کے ساتھ شریک کرتی ہے. یہ کمزور کے لئے بہت سے فائدہ ہیں: ہم (1) اٹھانے کی مدل سکتے ہیں اچھی نئورل پڑھنے کی سمجھنے کی تکنیک کے مطابق اضافہ کریں، جن کے لئے ہمارے لئے کوئی مثال نہیں ہے۔ ایک ویکیپیڈیا اسلوٹ-بھولنے کے کام میں تجربے دکھاتے ہیں کہ اس طریقہ کو نئی سوالوں کے لئے بلند دقیق کے ساتھ معلوم ہونے والی نسبتوں کے لئے آگاہ کر سکتا ہے، اور یہ کہ صفر-شٹ آگاہ ہونے والی نسبتوں کے اندر غیر معلوم ہونے والی نسبتوں کے اندر غیر معلوم ہو سکتا ہے، نیچے دقیق س', 'vi': 'Chúng tôi cho rằng kiểm tra vệ lý quan trọng có thể chỉ bằng câu trả lời hiểu đơn giản, bằng cách đặt vào một vài câu hỏi ngôn ngữ tự chất của tự nhiên và Sự giảm bớt này có nhiều ưu điểm: chúng ta có thể học về các mô hình cách hấp thụ quan hệ bằng cách mở rộng các kỹ thuật đọc não (2) xây dựng các tập đoàn huấn luyện rất lớn cho các mô hình đó bằng cách kết hợp các câu hỏi có nguồn dân chủ quan hệ với sự giám sát xa xôi, và thậm chí (3) học bắn không bằng cách khai thác các dạng quan hệ mới chỉ được xác định vào giờ thử, mà chúng tôi không có tấm hình đề cập huấn luyện. Thí nghiệm trên một nhiệm vụ lấp đầy thời gian Wikipedia cho thấy phương pháp có thể tổng kết cho những câu hỏi mới về các kiểu liên quan đã biết với độ chính xác cao cao, và sự tổng hợp bằng không vào các kiểu liên quan vô hình có thể xảy ra, ở mức độ chính xác thấp hơn, để đặt thanh cho những việc làm tương lai trong nhiệm vụ này.', 'uz': "Biz ko'rayapmiz, murakkab ajratishni bir yoki ko'proq murakkab soʻzlari bilan bir maslahatlarni ajratish imkoniyatini kamaytirish mumkin. Bu kamaytirish bir necha foydalanuvchilar bor: Yaqinda neyrolik o'qish usullarini o'rganish mumkin, (2) o'sha modellarni ajratish uchun juda katta taʼminlovchi moslamalar yaratish mumkin. Masofadan boshqarish uchun boshqaruvchi jamoatlar suhbatlarini birlashtirish va (3) faqat bir xil vaqtda yangi aloqa turlarini ajratish uchun hech narsa o'rganish mumkin, shuning uchun bizda yozilgan taʼminlovchi misollar yo'q. Name", 'bg': 'Показваме, че извличането на релации може да бъде сведено до отговор на прости въпроси за разбиране на четенето чрез свързване на един или повече въпроси с естествен език с всеки релационен слот. Това намаление има няколко предимства: можем (1) да научим модели за извличане на взаимоотношения чрез разширяване на последните невронни техники за четене-разбиране, (2) да изградим много големи групи обучения за тези модели чрез комбиниране на специфични за взаимоотношенията въпроси, свързани с тълпата, с дистанционен надзор, и дори (3) да направим нулево обучение чрез извличане на нови типове взаимоотношения, които са определени само по време на теста, за които нямаме обозначени примери за обучение. Експерименти по задача за запълване на слотове в Уикипедия показват, че подходът може да се обобщи към нови въпроси за известни типове релации с висока точност и че нулево обобщаване към невидими типове релации е възможно при по-ниски нива на точност, задавайки лентата за бъдеща работа по тази задача.', 'nl': 'We laten zien dat relatienextractie kan worden teruggebracht tot het beantwoorden van eenvoudige leesbegripsvragen, door één of meer natuurlijke taalvragen aan elk relatieslot te koppelen. Deze reductie heeft verschillende voordelen: we kunnen (1) relatieontwikkelingsmodellen leren door recente neurale leesbegripstechnieken uit te breiden, (2) zeer grote trainingssets voor die modellen bouwen door relatiespecifieke crowdsourcing vragen te combineren met toezicht op afstand, en zelfs (3) zero-shot leren door nieuwe relatietypen te extraheren die alleen tijdens de test worden gespecificeerd, waarvoor we geen gelabelde trainingsvoorbeelden hebben. Experimenten met een Wikipedia slot-vullende taak tonen aan dat de aanpak kan generaliseren naar nieuwe vragen voor bekende relatietypen met hoge nauwkeurigheid, en dat zero-shot generalisatie naar onzichtbare relatietypen mogelijk is, met lagere nauwkeurigheidsniveaus, waardoor de lat wordt gelegd voor toekomstige werkzaamheden aan deze taak.', 'da': 'Vi viser, at relation ekstraktion kan reduceres til at besvare simple læseforståelsesspørgsmål ved at tilknytte et eller flere natursprogede spørgsmål til hver relation slot. Denne reduktion har flere fordele: Vi kan (1) lære relationsudvindingsmodeller ved at udvide de seneste neurale læseforståelsesteknikker, (2) bygge meget store træningssæt for disse modeller ved at kombinere relationsspecifikke crowdsourcerede spørgsmål med fjernsyn, og endda (3) gøre nul-shot læring ved at udtrække nye relationstyper, der kun er specificeret på testtid, hvor vi ikke har nogen mærkede uddannelseseksempler. Eksperimenter med en Wikipedia slot-fyldning opgave viser, at tilgangen kan generalisere til nye spørgsmål for kendte relationstyper med høj nøjagtighed, og at nulskud generalisering til usete relationstyper er mulig, ved lavere nøjagtighedsniveauer, at sætte baren for fremtidigt arbejde med denne opgave.', 'hr': 'Pokazujemo da se izvlačenje odnosa može smanjiti na odgovor na jednostavna pitanja razumijevanja čitanja, povezujući jedno ili više pitanja prirodnog jezika sa svakim mjestom odnosa. Ova smanjenja ima nekoliko prednosti: možemo (1) naučiti modele izvlačenja odnosa proširenjem nedavnih tehnika razumijevanja neuroloških čitanja, (2) izgraditi veoma velike obuke za te modele kombiniranjem pitanja s dalekim nadzorom na odnosima specifičnih prometnih pitanja s udaljenim nadzorom, a čak i (3) učiti nula snimka izvlačenjem novih vrsta odnosa koji su samo određeni u testu vrijeme, Nemamo primjere obuke. Eksperimenti na zadatku ispunjavanja slot a na Wikipediji pokazuju da pristup može generalizirati na nove pitanja za poznate vrste odnosa sa visokom preciznošću, a da je moguće generalizacija nula snimaka na nevidljive vrste odnosa na nižoj razini preciznosti, postavljajući bar za budući rad na ovom zadatku.', 'de': 'Wir zeigen, dass die Beziehungsextraktion auf die Beantwortung einfacher Leseverständnisfragen reduziert werden kann, indem jedem Beziehungsslot eine oder mehrere natursprachliche Fragen zugeordnet werden. Diese Reduktion hat mehrere Vorteile: Wir können (1) Beziehungsextraktionsmodelle erlernen, indem wir neue neuronale Leseverständnistechniken erweitern, (2) sehr große Trainingssets für diese Modelle erstellen, indem wir relationsspezifische Crowdsourcing-Fragen mit Fernüberwachung kombinieren, und sogar (3) Null-Schuss-Lernen durch Extrahieren neuer Beziehungstypen, die nur zum Testzeitpunkt spezifiziert werden, Für die wir keine gekennzeichneten Trainingsbeispiele haben. Experimente an einer Wikipedia-Slot-Füllaufgabe zeigen, dass der Ansatz auf neue Fragen für bekannte Relationstypen mit hoher Genauigkeit verallgemeinern kann und dass eine Null-Schuss-Verallgemeinerung auf unsichtbare Relationstypen bei geringerer Genauigkeit möglich ist, was die Messlatte für zukünftige Arbeiten an dieser Aufgabe setzt.', 'id': 'Kami menunjukkan bahwa ekstraksi hubungan dapat dikurangi untuk menjawab pertanyaan pemahaman bacaan sederhana, dengan mengassokasikan satu atau lebih pertanyaan bahasa alam dengan setiap slot hubungan. Pengurangan ini memiliki beberapa keuntungan: kita dapat (1) belajar model ekstraksi-hubungan dengan memperluas teknik pembacaan-pemahaman saraf baru-baru ini, (2) membangun set pelatihan yang sangat besar untuk model-model tersebut dengan menggabungkan pertanyaan-pertanyaan yang spesifik hubungan keramaian dengan pengawasan jauh, dan bahkan (3) melakukan pelatihan zero-shot dengan ekstraksi jenis hubungan baru yang hanya spesifik pada waktu ujian, Yang mana kita tidak punya contoh pelatihan yang ditabel. Eksperimen dalam tugas penuhian slot Wikipedia menunjukkan bahwa pendekatan dapat menyebarkan kepada pertanyaan baru untuk tipe hubungan yang dikenal dengan akurasi tinggi, dan bahwa generalisasi 0-shot untuk tipe hubungan yang tidak terlihat mungkin, pada tingkat akurasi lebih rendah, menetapkan bar untuk kerja masa depan pada tugas ini.', 'ko': '우리는 하나 이상의 자연 언어 문제를 모든 관계 슬롯과 연결함으로써 관계 추출을 간단한 읽기와 이해 문제에 대한 대답으로 간소화할 수 있음을 증명했다.이러한 간소화는 몇 가지 장점이 있다. 우리는 (1) 최근의 신경 읽기 이해 기술을 확장하여 관계 추출 모델을 배울 수 있다. (2) 특정 관계의 하도급 문제와 원격 감독을 결합시켜 이런 모델에 매우 큰 훈련집을 만들 수 있다. 심지어 (3) 추출을 테스트할 때 지정한 새로운 관계 유형으로만 0회 학습을 할 수 있다.우리는 표시된 교육 예시가 없다.위키백과 플러그인 충전 작업의 실험에 따르면 이 방법은 이미 알고 있는 관계 유형의 새로운 문제에까지 높은 정밀도로 보급할 수 있고, 낮은 정밀도 수준에서 보이지 않는 관계 유형에까지 제로 포를 보급할 수 있어 향후 이 작업에 대한 기준을 설정할 수 있다.', 'sw': 'Tunaonyesha kwamba uteuzi wa uhusiano unaweza kupunguzwa na kujibu maswali rahisi ya kusoma, kwa kuunganisha maswali ya lugha moja au zaidi ya asili na kila mswada wa mahusiano. Upunguzo huu una faida kadhaa: tunaweza kujifunza muundo wa utoaji wa mahusiano kwa kuongeza mbinu za hivi karibuni za kusoma ubongo, (2) kujenga seti kubwa za mafunzo kwa ajili ya mifano hiyo kwa kuunganisha maswali yanayohusiana na vyanzo vya umma na kufuatiliwa mbali, na hata (3) hufanya kujifunza sifuri kwa kutengeneza aina mpya za mahusiano ambazo pekee zinawekwa kwenye wakati wa jaribio, ambazo hatuna mifano ya mafunzo yenye maarufu. Majaribio kwenye kazi inayojaza vifaa vya Wikipedia yanaonyesha kuwa mbinu hizo zinaweza kuleta maswali mapya kwa aina mpya ya mahusiano yenye uhakika mkubwa, na kwamba uzalishaji wa aina zisizo za siri unawezekana, katika kiwango cha chini cha sahihi, na kuweka barua kwa ajili ya kazi za baadaye katika kazi hii.', 'fa': 'ما نشان می دهیم که اخراج رابطه می تواند به پاسخ خواندن سوال ساده\u200cای که درک می\u200cکنند کاهش داده شود، با ارتباط یک یا بیشتر سوال زبان طبیعی با هر نقطه رابطه. این کاهش چندین سودهایی دارد: ما می توانیم (۱) مدلهای استخراج رابطه را با افزایش فناوری\u200cهای درک\u200cشناسی عصبی اخیر یاد بگیریم، (۲) مجموعه\u200cهای آموزش بسیار بزرگ برای این مدلها بسازیم با ترکیب سوالات\u200cهای مخصوص نسبت به جامعه\u200cهای مخصوص با بررسی دور، و حتی (۳) با استخراج نوع رابطه\u200cهای جدید که تنه برای آن نمونه\u200cهای آموزش نامه\u200cای نداریم. تجربه\u200cهای روی یک کار پر کردن نقطه\u200cهای ویکیپیدیا نشان می\u200cدهند که این دستور می\u200cتواند به سوال\u200cهای جدید برای نوع\u200cهای رابطه\u200cهای معلوم با دقیق بالا تغییر دهد، و اینکه عمومی\u200cسازی\u200cهای صفر برای نوع\u200cهای رابطه\u200cای غیر معلوم است، در سطح دقیق پایین، بار برای کار آین', 'am': 'የግንኙነት ውጤት ማቀናቀል ጥያቄዎችን ለመመልስ እናሳየዋለን፡፡ ይህ አካሄድ ብዙ ጥቅሞች አለበት:(1) የአሁኑን የነዌብ አካባቢ-ትምህርት ዘዴዎችን በመዘረጋ ይችላል:(2) ለዚህ ዓይነቶች ትልቅ ትምህርት ማሳየት ይችላል፡፡ ለዚህም ተማሪዎች ምሳሌ የለንም ። Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.', 'tr': 'Biz baglaýyşyň gaýşartmaky basit okama soraglaryna jogap berip, bir ýa-da tebigy dil soraglaryny her baglaýyşyň bilen baglaýyşyp düşürip biler görkezip bileris. Bu düşürmek birnäçe üstünlikler bar: biz (1) ýakyn nuýral okama tekniklerini uzaklaşdyryp nuýral okama tekniklerini öwrenip bilen baglanyşyk nuýral okama tekniklerini öwrenip bileris, (2) bu modeller üçin gaty uly okuwçylyk toparlaryny guryp bileris, Ýöne bu ýagdaýda hiç hili etiket edilen okuw mysal ýok. Wikipediýa ýeri doldurulýan täze soraglaryň bardygyny görkezýär.', 'af': "Ons wys dat verwanting uittrekking kan verminder word na antwoord van eenvoudige lees verstanding vrae deur een of meer natuurlike taal vrae te assosieer met elke verwanting slot. Hierdie reduksie het verskeie voordeel: ons kan (1) leer relatie-uittrekking modele deur die uitbreiding van onlangse neurale lees-verstaan teknike, (2) bou baie groot onderwerking stelle vir dié modele deur verwanting-spesifieke skare-uitgesoekte vrae met afgeleë onderwerp te kombinerer, en selfs (3) doen nul-skoot leer deur nuwe verwanting tipes uittrek wat slegs gespesifiseer word op toets-ty waarvan ons geen etiketeerde onderwerp voorbeelde het nie. Eksperimente op 'n Wikipedia slot-opvulling opdrag bevestig dat die toegang kan generelliseer na nuwe vrae vir bekende verwanting tipes met hoë presisie, en dat nul-skoot generellisering na ongesien verwanting tipes is moontlik, op minder presisie vlakke, stel die balk vir toekomstige werk op hierdie taak.", 'hy': 'Մենք ցույց ենք տալիս, որ հարաբերությունների վերացումը կարող է նվազեցնել պարզ ընթերցման ընկալումների հարցերին պատասխանելու, միացնելով մեկ կամ ավելի բնական լեզվով հարցեր յուրաքանչյուր հարաբերության վայրի հետ: Այս նվազեցումը ունի մի քանի առավելություններ. մենք կարող ենք (1) սովորել հարաբերությունների վերացման-վերացման մոդելներ՝ ընդլայնելով վերջին նյարդային ընթերցման-ընկալության տեխնիկաները, (2) կառուցել շատ մեծ վարժեցման համակարգեր այդ մոդելների համար՝ համադրելով հարաբերությունների հատուկ ժողովրդի աղբյուրների հարցեր հեռավոր վերահսկողության հետ,  որոնց համար մենք չունենք նշանակված ուսուցման օրինակներ: Վիքիփեդիայի պահերի լրացման խնդիրների փորձերը ցույց են տալիս, որ մոտեցումը կարող է ընդհանուր հասցնել նոր հարցերին, որոնք վերաբերվում են բարձր ճշգրտությամբ հայտնի հարաբերությունների տեսակներին, և որ զրոյի ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ըն', 'sq': 'Ne tregojmë se nxjerrja e marrëdhënieve mund të reduktohet në përgjigjen e pyetjeve të thjeshta të kuptimit të leximit, duke shoqëruar një apo më shumë pyetje gjuhësh natyrore me çdo slot marrëdhënie. Ky zvogëlim ka disa avantazhe: ne mund (1) të mësojmë modele marrëdhënie-nxjerrje duke zgjeruar teknikat e fundit të leximit-kuptimit neuronal, (2) të ndërtojmë grupe shumë të mëdha trajnimi për këto modele duke kombinuar çështje të caktuara për marrëdhënie me popullin me mbikqyrje të largët, dhe madje (3) të mësojmë zero-shot duke nxjerrë tipe të reja marrëdhënie që janë specifikuar vetëm në kohën e testit,  for which we have no labeled training examples.  Eksperimentet në një detyrë të plotësimit të vendit të Wikipedias demonstrojnë se qasja mund të gjeneralizohet ndaj pyetjeve të reja për llojet e njohura të marrëdhënieve me saktësi të lartë dhe se gjeneralizimi zero-shot ndaj llojeve të marrëdhënieve të padukshme është i mundur, në nivele më të ulët të saktësisë, duke vendosur barin për punën e ardhshme në këtë detyr', 'az': 'Biz göstəririk ki, əlaqə çıxarılması hər bir əlaqə yerinə bir ya da bir çox təbiətli dil suallarını birləşdirərək basit okuma suallarına cavab verə bilər. Bu küçüyün bir neçə faydası var: biz (1) yeni nöral oxumaq-anlama tekniklərini uzaqlaşdırmaq üçün bağlantı-extraction modellerini öyrənə bilərik, (2) bu modellərə çox böyük təhsil qururuq, qüvvət-məşğul soruları uzaq təhsil ilə birləşdirib, hətta (3) sıfır-shot öyrənməsi ilə yeni bağlantı türünü istifadə edərək, ancaq test-zamanda belə belə belə Bizim üçün heç bir məsəllərimiz yoxdur. Wikipedia slot-filling işlərində təcrübələr göstərir ki, bu metod yüksək doğruluqla tanınmış ilişkilər üçün yeni suallara generalize edə bilər, və bu işin gələcək işlərin bar ını təyin edə bilər.', 'bn': 'আমরা দেখাচ্ছি যে প্রত্যেক সম্পর্কের স্লোটের সাথে প্রাকৃতিক ভাষার প্রশ্নের জবাব দিয়ে সম্পর্ক বের করা যায় সাধারণ পাঠকের প এই হ্রাসের বেশ কয়েকটি সুবিধা রয়েছে: আমরা (১) সম্পর্ক বের করার মডেল শিখতে পারি সাম্প্রতিক নিউরাল পাঠক-সম্পূর্ণ প্রযুক্তি বৃদ্ধির মাধ্যমে (২) এই মডেলের জন্য বিশাল প্রশিক্ষণ নির্মাণ করতে পারি দূরবর্তী পরী যার জন্য আমাদের কোন লেবেল প্রশিক্ষণের উদাহরণ নেই। উইকিপিডিয়া স্লোট ফেলার কাজে একটি পরীক্ষার পরীক্ষা প্রদর্শন করেছে যে এই পদ্ধতিটি উচ্চপরিস্থিতির সাথে পরিচিত সম্পর্কের নতুন প্রশ্নের জন্য সৃষ্টি করতে পারে এবং অদৃশ্য সম্পর্কের ধর', 'bs': 'Pokazujemo da se izvlačenje odnosa može smanjiti na odgovor na jednostavna pitanja o razumijevanju čitanja, povezujući jedno ili više pitanja prirodnog jezika sa svakim mjestom veze. Ova smanjenja ima nekoliko prednosti: možemo (1) naučiti modele izvlačenja odnosa proširenjem nedavnih tehnika razumijevanja neuroloških čitanja, (2) izgraditi veoma velike obuke za te modele kombinacijom pitanja koje su specifične veze s udaljenim nadzorom, a čak i (3) učiti nula snimka izvlačenjem novih vrsta odnosa koji su samo određeni u testu, Nemamo primjere obuke. Eksperimenti na zadatku ispunjavanja slot a na Wikipediji pokazuju da pristup može generalizirati na nove pitanja za poznate vrste odnosa sa visokom preciznošću, a da je moguće generalizacija nula snimaka na nevidljive vrste odnosa na nižim nivoima preciznosti, postavljanje bara za budući rad na ovom zadatku.', 'ca': "Mostrem que l'extracció de relació pot ser reduïda a respondre preguntes simples de comprensió de lectura, associant una o més preguntes de llenguatge natural a cada slot de relació. Aquesta reducció té molts avantatges: podem (1) aprendre models d'extracció de relació ampliant les tècniques recents de lectura-comprensió neural, (2) construir conjunts de capacitació molt grans per a aquests models combinant preguntes específices de la multitud amb supervisió remota, i fins i tot (3) fer aprenentatge zero extraint nous tipus de relació que només s'especifiquen en temps de prova, per a la qual no tenim exemples de formació etiquetats. Els experiments d'una tasca de rempliment de slots de Wikipedia demostren que l'enfocament pot generalitzar-se a noves preguntes per tipus coneguts de relacions amb alta precisió, i que la generalització de zero a tipus de relacions invisibles és possible, a nivells de més baixa precisió, posant la barra per a la futura feina en aquesta tasca.", 'et': 'Näitame, et suhete ekstraheerimist saab vähendada lihtsate lugemise mõistmise küsimuste vastuseni, sidudes iga suhete pesaga ühe või mitu looduskeelset küsimust. Sellel vähendamisel on mitmeid eeliseid: me saame (1) õppida suhete ekstraheerimise mudeleid, laiendades hiljutisi neuraalseid lugemise-mõistmise meetodeid, (2) ehitada nende mudelite jaoks väga suuri koolituskomplekte, kombineerides suhetespetsiifilisi rahvamassiga seotud küsimusi kaugjärelevalvega, ja isegi (3) teha null-shot õppimist uute suhete tüüpide ekstraheerimisega, mis on määratletud ainult katseajal, mille kohta meil puuduvad märgistatud koolitusnäited. Vikipeedia teenindusaegade täitmise ülesande eksperimendid näitavad, et lähenemisviis võib üldistada uutele küsimustele teadaolevate seostüüpide jaoks suure täpsusega ning et null-shot üldistamine nähtamatutele seostüüpidele on võimalik madalama täpsustasemega, seades riba selle ülesande edasiseks tööks.', 'cs': 'Ukazujeme, že extrakce vztahů může být redukována na zodpovězení jednoduchých otázek porozumění čtení tím, že s každým vztahovým slotem přidružíme jednu nebo více otázek v přirozeném jazyce. Toto snížení má několik výhod: můžeme (1) naučit se modely relace-extrakce rozšířením nejnovějších neuronových technik porozumění čtení, (2) vytvořit velmi rozsáhlé tréninkové sady pro tyto modely kombinací vztahově specifických crowdsourcingových otázek se vzdáleným dohledem, a dokonce (3) provádět nulové učení extrakcí nových typů vztahů, které jsou specifikovány pouze v době testu, pro které nemáme žádné označené příklady školení. Experimenty na úkolu Wikipedie s vyplňováním slotů ukazují, že tento přístup může zobecňovat nové otázky pro známé typy vztahů s vysokou přesností a že nulová zobecnění na neviditelné typy vztahů je možné při nižších úrovních přesnosti, což nastavuje laťku pro budoucí práci na tomto úkolu.', 'fi': 'Osoitamme, että suhdeuuttaminen voidaan vähentää yksinkertaisiin lukemisen ymmärtämiseen liittyviin kysymyksiin liittämällä yhden tai useamman luonnollisen kielen kysymyksen kuhunkin suhdepaikkaan. Tällä vähennyksellä on useita etuja: voimme (1) oppia suhdeuuttamismalleja laajentamalla viimeisimpiä neuron lukuymmärtämisen tekniikoita, (2) rakentaa hyvin suuria koulutussarjoja näille malleille yhdistämällä suhdekohtaisia joukkolähtöisiä kysymyksiä etäohjaukseen ja jopa (3) tehdä nolla-shot-oppimista uuttamalla uusia suhdetyyppejä, jotka määritellään vain testiaikana, joista meillä ei ole merkittyjä koulutusesimerkkejä. Wikipedian slot-täyttötehtävässä tehdyt kokeet osoittavat, että lähestymistapa voi yleistyä uusiin kysymyksiin tunnetuille suhdetyypeille suurella tarkkuudella, ja että nollalaukaus yleistää näkymättömiä suhdetyyppejä pienemmällä tarkkuudella, asettaen palkkia tulevalle työlle tässä tehtävässä.', 'ha': 'Tuna nũna cewa, za\'a iya ƙara masu husũma zuwa a karɓa wa maswalin karãtun littafi masu sauƙi, da kuma a haɗa masu tambayar cikin harshen guda ko da mafi sauti da takarda zuwa duk bango. Ga wannan ƙarami yana da amfani masu yawa: za mu iya iya fahimtar masu husũma (1) da za\'a ƙarfafa misãlai masu tsari na karatun-karatun na neural a yanzu, (2) ka sami shiryoyin muhimmi mai girma wa waɗannan misãlai da za\'a haɗi masu husũma-masu-danganta da cẽranta-masu basĩri da tsari mai nĩsa, kuma kõ da (3) za\'a yi amfani da yin nufi da su sami-zane-zane-zane-zane-zane-zane- "Ba mu da misãlai da aka sanar da shi ba. Experiments on a Wikipedia slot-filling task demonstrate that the approach can generalize to new questions for known relation types with high accuracy, and that zero-shot generalization to unseen relation types is possible, at lower accuracy levels, setting the bar for future work on this task.', 'jv': 'Awak dhéwé ngerasah akeh tanggal dipungot kanggo sabanjuré basa luwih basa sak perusahaan, lan akeh sabanjuré-luwih akeh sabanjuré-luwih sabanjuré sak bengoh. Ukuran iki dipumuhayo karo akeh bener: we can (1) ulih basa gambar n\' extract model sing bisa nggawe sistem sing isinculo nggawe biyaran sistem pentru nggawe sistem dhéwé (2) nggawe sistem luar aturan sing dibutuhke nggawe model sing dibutuhke tarjamahan karo perusahaan-perusahaan langgar-perusahaan lan sampek (3) nggawe sistem dhéwé iso nggawe perusahaan anyar mên karo test-time, politenessoffpolite"), and when there is a change ("assertive Perintah Panjenengan langkung slot-filling task Wakipedia nggawe sapa ngono diangkat kuwi nggawe cegak dhéwé nggawe aturan anyar nggawe aturan sing wis nggawe aturan tapi nyimpen, lan kene-nggawe 0 iso nggawe aturan sing wis nggawe aturan tambahan, akeh nggawe aturan sing beraksi, akeh nggawe bar a kanggo tinguha nggo dianggap iki', 'sk': 'Pokazali smo, da je mogoče ekstrakcijo relacij zmanjšati na odgovore na preprosta vprašanja razumevanja branja, tako da z vsako relacijsko režo povežemo eno ali več vprašanj naravnega jezika. To zmanjšanje ima več prednosti: 1) se lahko učimo modelov odnosov-ekstrakcije z razširitvijo novih tehnik nevronskega branja-razumevanja, (2) zgradimo zelo velike nabore usposabljanj za te modele s kombinacijo vprašanj množice, specifičnih za odnose, z daljnim nadzorom in celo (3) izvajamo učenje brez strela z izvlečevanjem novih tipov odnosov, ki so določeni le v času preskusa, za katere nimamo označenih primerov usposabljanja. Eksperimenti na opravilu zapolnjevanja rež v Wikipediji kažejo, da se lahko pristop z visoko natančnostjo posploši na nova vprašanja za znane vrste relacij in da je mogoče ničelno posplošiti na nevidne vrste relacij, pri nižjih stopnjah natančnosti, in nastaviti vrstico za prihodnje delo na tem opravilu.', 'he': 'אנו מראים שהחולץ מערכת יחסים יכול להיקטל לענות על שאלות פשוטות של בינה קריאה, על ידי הקשר שאלה אחת או יותר בשפה טבעית עם כל מקום מערכת יחסים. להפחית הזו יש כמה יתרונות: אנחנו יכולים (1) ללמוד דוגמנים יחסים-חיתוך על ידי הרחבת טכניקות קריאה-הבנה עצבית לאחרונה, (2) לבנות קבוצות אימונים גדולות מאוד לדוגמנים האלה על ידי שילוב שאלות מסוימות לקהל יחסים עם פיקוח רחוק, ואפילו שאין לנו דוגמאות אימונים. ניסויים על משימת מילוי קופסאות ויקיפדיה מראים שהגישה יכולה להתפשט לשאלות חדשות לטיפוסי יחסים ידועים עם מדויקת גבוהה, ושהגנרליזציה אפס לטיפוסי יחסים בלתי נראים היא אפשרית, ברמה מדויקת נמוכה יותר, להגדיר את הבר לעבודה העתידית על המשימה הזאת.', 'bo': 'ང་ཚོས་ཕྱིར་བཤེར་བ་དང་འབྲེལ་བ་ནི་སྤྱི་ཚོགས་ཀྱི་གནས་ཚུལ་འདྲི་ཚིག་ལས་མཐུན This reduction has several advantages: we can (1) learn relation-extraction models by extending recent neural reading-comprehension techniques, (2) build very large training sets for those models by combining relation-specific crowd-sourced questions with distant supervision, and even (3) do zero-shot learning by extracting new relation types that are only specified at test-time, དཔེར་ན། འུ་ཅག་ལ་ཤོག་བྱས་ཟིན་བྲིས་ཀྱི་དཔེར་བརྗོད་མ་ཡོད། Wikipedia་ཡི་སྒེར་གྱི་ནང་དུ་འཇུག་སྡུད་ལས་བརྟན་དཔྱད་ན་ཕྱོགས་ཀྱི་གཟུགས་རིས་གསར་པ་ལ་སྤྱིར་བཏང་བ་དང་། བྱ་ཚུལ་འདི་དག་བྱུང་བའི་རིགས'}
{'en': 'The Covert Helps Parse the Overt', 'ar': 'السر يساعد في تحليل الصراحة', 'fr': "Le secret aide à analyser l'overt", 'es': 'The Covert ayuda a analizar lo hostil', 'pt': 'O oculto ajuda a analisar o aberto', 'ja': '隠蔽は露骨な解析に役立つ', 'zh': '隐有助于解析显性', 'ru': 'Секрет помогает разобраться с откровенностью', 'hi': 'गुप्त ओवरट को पार्स करने में मदद करता है', 'ga': 'Cuidíonn The Covert le Parsáil a Dhéanamh', 'ka': 'Name', 'el': 'Το μυστικό βοηθά να αναλύσει το Overt', 'kk': 'Мұқабаттың көмегімен жоғарын талдау', 'lt': 'Apsauga padeda analizuoti viršutinę vertę', 'mk': 'Коривата помага во анализирањето на надворешноста', 'ms': 'Penutup Bantu Menghurai Penutup', 'hu': 'A titkos segít feldolgozni az átlagot', 'mn': 'Хавтас давхаргыг судлах тулд', 'it': "La copertina aiuta a interpretare l'overt", 'no': 'Omslaget hjelper å tolka overstyrken', 'pl': 'Tajnica pomaga analizować Overt', 'ro': 'The Covert helps Parse the Overt', 'mt': 'Il-Kopertura tgħin fl-analiżi tal-kopertura', 'ml': 'കോപ്പറ്റ് സഹായിക്കുന്നു', 'so': 'Kaalmada daboolku wuxuu kaalmeeyaa jardiinada', 'si': 'ආවරණය උදව් කරනවා විසින් විශ්ලේෂණය කරන්න', 'sv': 'Täckt hjälper till att tolka övertaget', 'ta': 'மேல்மேற்கூடிய உதவிகளை பார்க்கவும்', 'sr': 'Pokrivanje pomaže da analizira prekršaj', 'ur': 'پورٹ کی مدد کرتا ہے کہ اوپر کو پھیر لیتا ہے', 'uz': 'Name', 'vi': 'Những trợ giúp Che đậy phân tích bề ngoài', 'bg': 'Прикритието помага да се анализира Overt', 'da': 'Den dækkede hjælper med at fortolke overskriften', 'nl': 'The Covert helpt bij het Parsen van de Overt', 'hr': 'Pokrivač pomaže analizirati prekršaj', 'fa': 'پوشش کمک می\u200cکند در بررسی پایین', 'ko': '은폐된 도움말 해석 공개된', 'de': 'The Covert hilft beim Parsen des Overts', 'sw': 'The Cover helps Parse the overall', 'tr': '_Ýagtylamak modi', 'id': 'The Covert Helps Parse the Overt', 'sq': 'Mbuloja ndihmon analizimin e përmbytjes', 'af': 'Die Omslag Hulp Onderwerp die Oortjie', 'am': 'plug-in-action', 'az': 'Dərgənin daşınmasını çəkməyə kömək edir', 'hy': 'Comment', 'bn': 'কভার্টের সাহায্য করে ওপর পার্স করে', 'bs': 'Pokrivač pomaže analizirati prekršaj', 'et': 'Varjatud aitavad Overti lõpetada', 'cs': 'Tajný pomáhá analyzovat převrat', 'ca': 'La cobertura ajuda a analitzar la superfície', 'fi': 'The Covert Auts Parse the Overt', 'jv': 'Covert', 'sk': 'Skrivnost pomaga razčleniti Overt', 'he': 'הכיסוי עוזר לפרסם את האוברט', 'ha': 'KCharselect unicode block name', 'bo': 'ཁེབས་ཡུལ་གྱིས་བསུབ་ཀྱིས་དཔྱད་ཞིབ་བྱེད་རོགས'}
{'en': 'This paper is concerned with whether deep syntactic information can help surface parsing, with a particular focus on empty categories. We design new algorithms to produce dependency trees in which empty elements are allowed, and evaluate the impact of information about empty category on parsing overt elements. Such information is helpful to reduce the approximation error in a structured parsing model, but increases the search space for inference and accordingly the estimation error. To deal with structure-based overfitting, we propose to integrate disambiguation models with and without empty elements, and perform structure regularization via joint decoding. Experiments on English and Chinese TreeBanks with different parsing models indicate that incorporating empty elements consistently improves surface parsing.', 'ar': 'تهتم هذه الورقة بما إذا كانت المعلومات النحوية العميقة يمكن أن تساعد في التحليل السطحي ، مع التركيز بشكل خاص على الفئات الفارغة. نصمم خوارزميات جديدة لإنتاج أشجار تبعية يُسمح فيها بالعناصر الفارغة ، وتقييم تأثير المعلومات حول الفئة الفارغة على تحليل العناصر العلنية. هذه المعلومات مفيدة لتقليل خطأ التقريب في نموذج التحليل المنظم ، ولكنها تزيد من مساحة البحث للاستدلال وبالتالي خطأ التقدير. للتعامل مع فرط التجهيز المبني على الهيكل ، نقترح دمج نماذج إزالة الغموض مع العناصر الفارغة وبدونها ، وإجراء تنظيم للهيكل عبر فك تشفير المفصل. تشير التجارب التي أجريت على TreeBanks باللغتين الإنجليزية والصينية مع نماذج تحليل مختلفة إلى أن دمج العناصر الفارغة يؤدي باستمرار إلى تحسين تحليل السطح.', 'es': 'Este documento se ocupa de si la información sintáctica profunda puede ayudar al análisis de superficie, con un enfoque particular en las categorías vacías. Diseñamos nuevos algoritmos para producir árboles de dependencias en los que se permiten elementos vacíos y evaluamos el impacto de la información sobre la categoría vacía en el análisis de elementos manifiestos. Esta información es útil para reducir el error de aproximación en un modelo de análisis estructurado, pero aumenta el espacio de búsqueda para la inferencia y, en consecuencia, el error de estimación. Para hacer frente al sobreajuste basado en la estructura, proponemos integrar modelos de desambiguación con y sin elementos vacíos, y realizar la regularización de la estructura mediante decodificación conjunta. Los experimentos en TreeBank en inglés y chino con diferentes modelos de análisis indican que la incorporación de elementos vacíos mejora constantemente el análisis de la superficie.', 'pt': 'Este artigo está preocupado se informações sintáticas profundas podem ajudar na análise da superfície, com um foco particular em categorias vazias. Projetamos novos algoritmos para produzir árvores de dependência nas quais elementos vazios são permitidos e avaliamos o impacto das informações sobre a categoria vazia na análise de elementos evidentes. Tais informações são úteis para reduzir o erro de aproximação em um modelo estruturado de análise sintática, mas aumenta o espaço de busca para inferência e, consequentemente, o erro de estimativa. Para lidar com o overfitting baseado em estrutura, propomos integrar modelos de desambiguação com e sem elementos vazios e realizar a regularização da estrutura via decodificação conjunta. Experimentos em TreeBanks em inglês e chinês com diferentes modelos de análise indicam que a incorporação de elementos vazios melhora consistentemente a análise de superfície.', 'fr': "Cet article s'intéresse à la question de savoir si des informations syntaxiques approfondies peuvent aider à l'analyse de surface, avec un accent particulier sur les catégories vides. Nous concevons de nouveaux algorithmes pour produire des arbres de dépendance dans lesquels les éléments vides sont autorisés, et évaluons l'impact des informations sur les catégories vides sur l'analyse des éléments ouverts. Ces informations sont utiles pour réduire l'erreur d'approximation dans un modèle d'analyse structuré, mais augmentent l'espace de recherche pour l'inférence et, par conséquent, l'erreur d'estimation. Pour traiter le surajustement basé sur la structure, nous proposons d'intégrer des modèles de désambiguïsation avec et sans éléments vides, et d'effectuer une régularisation de structure via un décodage conjoint. Des expériences sur des TreeBanks anglais et chinois avec différents modèles d'analyse indiquent que l'incorporation d'éléments vides améliore constamment l'analyse de surface.", 'ja': 'この論文は、特に空のカテゴリに焦点を当てて、深い構文情報が表面解析に役立つかどうかを懸念している。空の要素が許可されている依存関係ツリーを生成し、空のカテゴリに関する情報が明白な要素を解析する際の影響を評価するために、新しいアルゴリズムを設計します。このような情報は、構造化された構文解析モデルにおける近似誤差を低減するのに役立つが、推論のための探索空間を増加させ、それに応じて推定誤差を増加させる。構造ベースのオーバーフィッティングに対処するために、空要素の有無にかかわらず曖昧さ解消モデルを統合し、ジョイントデコードを介して構造正規化を行うことを提案する。さまざまな構文解析モデルを使用した英語と中国のツリーバンクの実験では、空の要素を組み込むことで一貫して表面構文解析が改善されることが示されています。', 'zh': '本文关注者,深句法信息有助于外解析,特关空类。 设新算法以成许空元素之赖,并评空类别之信解析显性元素。 有助于减结构化解析模形之近差,但会增理之搜索空间,以应加度差。 为理基于结构之过拟合,议将消歧义模形与空元素、无空元素集成,因合解码行结构正则化。 用解析英文、中文树库之实验,合空元素可以持改外解析。', 'hi': 'यह पेपर इस बात से संबंधित है कि क्या गहरी वाक्यात्मक जानकारी खाली श्रेणियों पर विशेष ध्यान देने के साथ सतह पार्सिंग में मदद कर सकती है। हम निर्भरता पेड़ों का उत्पादन करने के लिए नए एल्गोरिदम डिजाइन करते हैं जिसमें खाली तत्वों की अनुमति है, और ओवरट तत्वों को पार्स करने पर खाली श्रेणी के बारे में जानकारी के प्रभाव का मूल्यांकन करते हैं। ऐसी जानकारी एक संरचित पार्सिंग मॉडल में सन्निकटन त्रुटि को कम करने में सहायक होती है, लेकिन अनुमान के लिए खोज स्थान और तदनुसार अनुमान त्रुटि को बढ़ाती है। संरचना-आधारित ओवरफिटिंग से निपटने के लिए, हम खाली तत्वों के साथ और बिना बहुविकल्पी मॉडल को एकीकृत करने का प्रस्ताव करते हैं, और संयुक्त डिकोडिंग के माध्यम से संरचना नियमितीकरण करते हैं। विभिन्न पार्सिंग मॉडल के साथ अंग्रेजी और चीनी ट्रीबैंक्स पर प्रयोगों से संकेत मिलता है कि खाली तत्वों को शामिल करने से लगातार सतह पार्सिंग में सुधार होता है।', 'ru': 'Настоящий документ посвящен вопросу о том, может ли глубокая синтаксическая информация способствовать поверхностному анализу с уделением особого внимания пустым категориям. Мы разрабатываем новые алгоритмы для создания деревьев зависимостей, в которых разрешены пустые элементы, и оцениваем влияние информации о пустой категории на синтаксический анализ открытых элементов. Такая информация полезна для уменьшения ошибки аппроксимации в структурированной модели синтаксического анализа, но увеличивает пространство поиска для вывода и, соответственно, ошибки оценки. Для решения структурной перестройки мы предлагаем интегрировать модели расплывчатости с пустыми элементами и без них, а также выполнить регуляризацию структуры посредством совместного декодирования. Эксперименты на английском и китайском TreeBank с различными моделями синтаксического анализа показывают, что включение пустых элементов постоянно улучшает синтаксический анализ поверхности.', 'ga': 'Baineann an páipéar seo le cé acu an féidir le faisnéis chomhréire domhain cabhrú le parsáil dromchla, le fócas ar leith ar chatagóirí folmha. Dearaimid halgartaim nua chun crainn spleáchais a tháirgeadh ina gceadaítear eilimintí folamh, agus meastóireacht a dhéanamh ar an tionchar atá ag faisnéis faoi chatagóir folamh ar pharsáil eilimintí follasach. Cuidíonn faisnéis den sórt sin chun an earráid mheastacháin i múnla parsála struchtúrtha a laghdú, ach méadaítear an spás cuardaigh le haghaidh tátail agus dá réir sin an earráid mheastacháin. Chun déileáil le rófheisteas struchtúr-bhunaithe, tá sé beartaithe againn samhlacha dí-athbhrí a chomhtháthú le heilimintí folamh agus gan iad, agus rialáil struchtúr a dhéanamh trí chomh-dhíchódú. Léiríonn turgnaimh ar TreeBank Béarla agus Síneach le samhlacha parsála éagsúla go bhfeabhsaíonn ionchorprú eilimintí folamh go comhsheasmhach parsáil dromchla.', 'el': 'Η παρούσα εργασία ασχολείται με το αν οι βαθιές συντακτικές πληροφορίες μπορούν να βοηθήσουν στην ανάλυση επιφάνειας, με ιδιαίτερη έμφαση στις κενές κατηγορίες. Σχεδιάζουμε νέους αλγόριθμους για την παραγωγή δέντρων εξάρτησης στα οποία επιτρέπονται άδεια στοιχεία και αξιολογούμε την επίδραση των πληροφοριών σχετικά με την κενή κατηγορία στην ανάλυση των φανερών στοιχείων. Αυτές οι πληροφορίες είναι χρήσιμες για τη μείωση του σφάλματος προσέγγισης σε ένα δομημένο μοντέλο ανάλυσης, αλλά αυξάνουν τον χώρο αναζήτησης για συμπέρασμα και ανάλογα το σφάλμα εκτίμησης. Για την αντιμετώπιση της υπερπροσαρμογής που βασίζεται στη δομή, προτείνουμε να ενσωματώσουμε μοντέλα διασφάλισης με και χωρίς κενά στοιχεία και να εκτελέσουμε την τακτοποίηση δομών μέσω κοινής αποκωδικοποίησης. Πειράματα σε αγγλικές και κινεζικές τράπεζες δέντρων με διαφορετικά μοντέλα ανάλυσης δείχνουν ότι η ενσωμάτωση κενών στοιχείων βελτιώνει σταθερά την ανάλυση επιφάνειας.', 'hu': 'Ez a tanulmány azzal foglalkozik, hogy a mély szintaktikus információk segíthetnek-e a felületi elemzésben, különös tekintettel az üres kategóriákra. Új algoritmusokat tervezünk, amelyekben üres elemek engedélyezettek, függőségfákat hozunk létre, és értékeljük az üres kategóriával kapcsolatos információk hatását a nyílt elemek elemzésére. Ezek az információk hasznosak a strukturált elemzési modellek közelítési hibájának csökkentésére, de növelik a következtetési területet és ennek megfelelően a becslési hibát. A struktúraalapú túlfeszítés kezeléséhez az üres elemekkel és anélkül való egyértelműsítési modellek integrálását javasoljuk, valamint a struktúra szabályozását közös dekódolással. Az angol és kínai fábankokon végzett kísérletek különböző elemezési modellekkel azt mutatják, hogy az üres elemek beépítése következetesen javítja a felületi elemezést.', 'ka': 'ეს დაახლობა დარწმუნება თუ არა ძალიან სინტაქტიული ინფორმაცია შეუძლია დახმარება სამუშაო პარალიზაციას, განსაკუთრებული ფონსკური კატეგორ ჩვენ ახალი ალგორიტიმები დავყენებთ, რომლებიც უნდა გავამუშავოთ გადაუშავებელი ელემენტები, და გავამუშავოთ ცარიელი კატეგორიის შესახებ ინფორმაციის შესახებ ასეთი ინფორმაცია მხოლოდ შეცდომა სტრუქტურული პარასტირებული მოდელში დაახლოების შეცდომას, მაგრამ შეიძლება ინფრენციის შესაძლებლობის სივრცე და შემდეგ შეცდომა. სტრუქტურის უფრო დამატებული სტრუქტურაციის შესახებ, ჩვენ მინდომარებით განამბიგუაციის მოდელების ინტერგურაციას და ცარიელი ელემენტებით და სტრუქტურის რეგ ექსპერიმენტები ინგლისური და ჩინეთიური TreeBanks-ზე განსხვავებული პარაზიციის მოდელებით იცის, რომ გადაყენება ცარიელი ელემენტები მუშაობით უფრო უფრო მე', 'lt': 'Šis dokumentas yra susijęs su tuo, ar gili sintaktinė informacija gali padėti analizuoti paviršius, ypatingą dėmesį skiriant tuščioms kategorijoms. We design new algorithms to produce dependency trees in which empty elements are allowed, and evaluate the impact of information about empty category on parsing overt elements.  Tokia informacija padeda sumažinti suderinimo klaidą struktūrizuotame analizavimo modelyje, tačiau padidina paieškos erdvę išvadoms ir atitinkamai vertinimo klaidą. Siekiant išspręsti struktūrinius perteklius, siūlome integruoti nedviprasmiškumo modelius su tuščiais elementais ir be jų ir atlikti struktūros reguliavimą jungtiniu dekodifikavimu. Eksperimentai su anglų ir Kinijos medžių bankais su skirtingais analizavimo modeliais rodo, kad su tuščiais elementais nuolat gerinamas paviršiaus analizavimas.', 'it': "Questo articolo si occupa se informazioni sintattiche profonde possono aiutare l'analisi superficiale, con particolare attenzione alle categorie vuote. Progettiamo nuovi algoritmi per produrre alberi di dipendenza in cui sono consentiti elementi vuoti e valutiamo l'impatto delle informazioni sulla categoria vuota sull'analisi degli elementi aperti. Tali informazioni sono utili per ridurre l'errore di approssimazione in un modello di analisi strutturato, ma aumentano lo spazio di ricerca per l'inferenza e di conseguenza l'errore di stima. Per affrontare il sovrafitting basato sulla struttura, proponiamo di integrare modelli di disambiguazione con e senza elementi vuoti ed eseguire regolarizzazione della struttura tramite decodifica congiunta. Esperimenti su TreeBanks inglesi e cinesi con diversi modelli di analisi indicano che incorporando elementi vuoti migliora costantemente l'analisi superficiale.", 'mk': 'Оваа хартија е загрижена за тоа дали длабоката синтактичка информација може да помогне во анализирањето на површината, со посебен фокус на празните категории. Ние дизајнираме нови алгоритми за да произведуваме дрва на зависност во кои се дозволени празни елементи, и да го процениме влијанието на информациите за празна категорија на анализирањето на очигледни елементи. Таквите информации се корисни за намалување на грешката во приближувањето во структурираниот модел на анализирање, но го зголемува просторот за пребарување за конференција и, во согласност, проценката на грешка. За да се справи со прекувременоста на структура, предложуваме интегрирање на моделите за раздвојување со и без празни елементи и спроведување на регуларизација на структурата преку заедничко декодирање. Експериментите на англиските и кинеските дрвја банки со различни модели за анализирање покажуваат дека вклучувањето на празните елементи константно го подобрува анализирањето на површината.', 'kk': 'Бұл қағаз терең синтактикалық мәліметі бос санаттарды талдауға көмектесе алады. Біз жаңа алгоритмдерді құрамыз, оларда бос элементтер рұқсат етілген тәуелсіздік ағаштарды құру үшін, және оларды талдау үшін бос санаттар туралы мәліметтердің нә Бұл мәлімет құрылған талдау үлгісінде жақындау қатесін азайту үшін көмектеседі, бірақ іздеу кеңістігін көмектеседі, сондықтан бағалау қатесін көмектеседі. Структура негіздеген үлгіліктер үшін біз бұл үлгілерді бос элементтермен және бос элементтермен біріктіру үшін, құрылымызды баптау үлгіліктерін біріктіру үшін қолданамыз. Ағылшын және Қытай TreeBanks- тың тәжірибелері түрлі талдау үлгілері бос элементтерді ендіру үшін көздерді талдау үшін жақсартылады.', 'ms': 'Kertas ini bimbang sama ada maklumat sintaktik dalam boleh membantu penghuraian permukaan, dengan fokus tertentu pada kategori kosong. Kami merancang algoritma baru untuk menghasilkan pokok dependensi di mana elemen kosong dibenarkan, dan menilai kesan maklumat mengenai kategori kosong pada hurai elemen yang jelas. Maklumat seperti ini berguna untuk mengurangkan ralat persamaan dalam model huraian struktur, tetapi meningkatkan ruang gelintar untuk kesimpulan dan sebagainya ralat perhitungan. To deal with structure-based overfitting, we propose to integrate disambiguation models with and without empty elements, and perform structure regularization via joint decoding.  Eksperimen pada English and Chinese TreeBanks dengan model penghuraian yang berbeza menunjukkan bahawa memasukkan unsur kosong secara konsisten meningkatkan penghuraian permukaan.', 'mt': 'Dan id-dokument huwa kkonċernat dwar jekk informazzjoni sinrattika profonda tistax tgħin fl-analiżi tal-wiċċ, b’enfasi partikolari fuq kategoriji vojta. Aħna niddisinjaw algoritmi ġodda biex jipproduċu siġar tad-dipendenza li fihom huma permessi elementi vojta, u jivvalutaw l-impatt tal-informazzjoni dwar kategorija vojta fuq l-analiżi tal-elementi overti. Informazzjoni bħal din hija utli biex jitnaqqas l-iżball ta’ approssimazzjoni f’mudell ta’ analiżi strutturata, iżda żżid l-ispazju ta’ tiftix għall-inferenza u għalhekk l-iżball ta’ stima. Biex nindirizzaw it-tagħmir żejjed ibbażat fuq l-istruttura, nipproponu li nintegraw mudelli ta’ diżambiguazzjoni b’elementi vojta u mingħajr elementi vojta, u nirregolarizzaw l-istruttura permezz ta’ diżakkodifikazzjoni konġunta. Experiments on English and Chinese TreeBanks with different parsing models indicate that incorporating empty elements consistently improves surface parsing.', 'ml': 'ഈ പത്രത്തില്\u200d ആഴത്തെ സിനിട്ടാക്കിക്ക് വിവരങ്ങള്\u200d ശൂന്യമായ വിഭാഗങ്ങള്\u200dക്ക് ഉപയോഗിക്കാന്\u200d സഹായിക്കുമോ എന്ന കാലിയായ മൂലകങ്ങള്\u200dക്ക് അനുവദിക്കുന്ന വിവരങ്ങള്\u200d വെറുതെ വിഭവങ്ങളുടെ പ്രഭാവം പുതിയ ആല്\u200dഗോരിത്മുകള്\u200d നാം സൃഷ്ടിക്കുന്നു. മാ ഇത്തരം വിവരങ്ങള്\u200d സ്ഥാപിച്ച പാര്\u200dസിങ്ങ് മോഡലില്\u200d അടുത്ത പിശക് കുറയ്ക്കുവാന്\u200d സഹായിക്കുന്നു, പക്ഷെ അപകടത്തിനുള്ള തെരച്ചില അടിസ്ഥാനത്തിലുള്ള അടിസ്ഥാനമായി മാറ്റുന്നതിനെക്കുറിച്ച് നമ്മള്\u200d പ്രാര്\u200dത്ഥിക്കുന്നു, വെറുതെയില്ലാത്ത മോഡലുകള്\u200d ഒന്നിച് വ്യത്യസ്ത പാര്\u200dസിംഗ് മോഡലുകളുമായി ഇംഗ്ലീഷിലും ചൈനീസ് ട്രീബാങ്കുകളിലും പരീക്ഷണങ്ങള്\u200d വെളിപ്പെടുത്തുന്നു വെറുത', 'ro': 'Această lucrare se preocupă dacă informațiile sintactice profunde pot ajuta la analizarea suprafețelor, cu un accent deosebit pe categoriile goale. Proiectăm noi algoritmi pentru a produce arbori de dependență în care sunt permise elementele goale și evaluăm impactul informațiilor despre categoria goală asupra analizării elementelor evidente. Aceste informații sunt utile pentru a reduce eroarea de aproximare într-un model structurat de analizare, dar crește spațiul de căutare pentru inferență și, în consecință, eroarea de estimare. Pentru a face față supraamendării bazate pe structură, propunem integrarea modelelor de dezambiguizare cu și fără elemente goale și efectuarea regularizării structurii prin decodare comună. Experimentele efectuate pe băncile de copaci engleze și chinezești cu diferite modele de analizare indică faptul că încorporarea elementelor goale îmbunătățește în mod constant analizarea suprafeței.', 'sr': 'Ovaj papir je zabrinut da li duboke sintaktičke informacije mogu pomoći u analiziranju površine, sa posebnim fokusom na prazne kategorije. Mi dizajniramo nove algoritme za proizvodnju drveća zavisnosti u kojima se dozvoljavaju prazni elementi i procjenjujemo uticaj informacija o praznoj kategoriji na analizu prekovremenih elementa. Takve informacije su korisne za smanjenje pogreške približavanja u strukturiranom modelu analize, ali povećava prostor potražnje za infekcijom i odmah pogrešku procjene. Da bismo se suočili sa preuređenjem na strukturi, predlažemo da integrišemo modele disambiguacije sa i bez praznih elementa, i da izvedemo regularizaciju strukture putem zajedničkog dekodiranja. Eksperimenti na engleskom i kineskom TreeBanku sa različitim modelima analize ukazuju na to da uključivanje praznih elementa konsekventno poboljšava analizu površine.', 'pl': 'Niniejszy artykuł zajmuje się tym, czy głębokie informacje składniowe mogą pomóc w analizie powierzchni, ze szczególnym uwzględnieniem pustych kategorii. Projektujemy nowe algorytmy do tworzenia drzew zależności, w których dozwolone są puste elementy, oraz oceniamy wpływ informacji o pustej kategorii na parsowanie elementów jawnych. Takie informacje są pomocne w zmniejszeniu błędu aproximacyjnego w ustrukturyzowanym modelu parsowania, ale zwiększają przestrzeń wyszukiwania wniosków i odpowiednio błąd szacowania. Aby poradzić sobie z nadmiernym dopasowaniem struktury, proponujemy zintegrowanie modeli rozjednoznaczności z i bez pustych elementów oraz przeprowadzenie regulacji struktury poprzez wspólne dekodowanie. Eksperymenty na angielskich i chińskich bankach drzew z różnymi modelami parsowania wskazują, że włączenie pustych elementów konsekwentnie poprawia parsowanie powierzchni.', 'so': 'Warqaddan waxaa ka welwelsan in macluumaad aad u dheer oo la xiriiri karo baaritaanka dhulka, gooni gaar ah oo ku kalsoonaan karo kooxo madhan. Waxaynu qoraynaa algoreemo cusub si aan u soo bixino geedo ku xiran, kuwaas oo ay ku jiraan alaabta madhan, waxaana qiimeynaynaa saamaynta macluumaadka ku saabsan kooxo madhan oo ku saabsan baaritaanka alaabta badan. Macluumaadkaas waxey caawinaysaa in uu hoos u dhigo qalabka baaritaanka oo ku dhow, laakiin wuxuu kordhiyaa goobta raadinta oo ku qoran baaritaanka, sababtoo ah qalabka qiimeynta. Si aan u kala macaamiloono dib u dhaafitaanka dhismaha, waxaynu soo jeedaynaa in noocyada kala duwanaanshaha la qabsado iyo aan la’aan element madhan, waxaana sameynaa qaab dhismaha la xeeray si aad u samaysid deynta wadajirka ah. Imtixaanka ku saabsan Ingiriis iyo Shiino TreeBanks oo ku qoran model baaritaanka kala duduwan waxay muuqataa in lagu soo geliyo alaabta madhan si joogto ah loo beddelo baaritaanka surface.', 'sv': 'Denna uppsats handlar om huruvida djup syntaktisk information kan hjälpa yttolkning, med särskilt fokus på tomma kategorier. Vi designar nya algoritmer för att producera beroendeträd där tomma element tillåts, och utvärderar effekten av information om tom kategori på tolkningen av öppna element. Sådan information är till hjälp för att minska approximationsfelet i en strukturerad tolkningsmodell, men ökar sökutrymmet för inferens och därmed skattningsfelet. För att hantera strukturbaserad överbyggnad föreslår vi att man integrerar olika modeller med och utan tomma element och utför strukturregularisering via gemensam avkodning. Experiment på engelska och kinesiska trädbanker med olika tolkningsmodeller indikerar att inkorporering av tomma element konsekvent förbättrar yttolkningen.', 'no': 'Denne papiret er bekymret om dype syntaktiske informasjon kan hjelpa for å tolka overflata, med ein spesielt fokus på tomme kategoriar. Vi design nye algoritme for å produsera avhengighetstrår der tomme elementer er tillatt, og evaluera effekten av informasjon om tomt kategori på tolking av overelement. Denne informasjonen er nyttig for å redusera nærmingsfeilen i ein strukturert tolkingsmodul, men aukar søkjemoden for infeksjon og derfor estimeringsfeilen. For å handtera strukturbasert overfitting, foreslår vi å integrere disambiguasjonsmodeller med og utan tomme elementer, og utføra strukturreguleringa ved hjelp av kopla dekoding. Eksperimentar på engelsk og kinesisk TreeBanks med ulike analyseringsmodeller tyder på at inkludering av tomme elementer er konsistent forbetra overflatingstolking.', 'si': 'මේ පැත්තේ ගොඩක් සංකේතික තොරතුරු විශේෂණය කරන්න උදව් කරන්න පුළුවන් කියලා බලාපොරොත්තු වෙනවා, හිස්  අපි අළුත් ඇල්ගෝරිතම් සැලසුම් කරනවා විශේෂතාවක් ගස් නිර්මාණය කරන්න, ඒ වගේම හිස්සු අවශ්\u200dය අවශ්\u200dය වෙනුවෙන් අ මෙම තොරතුරු ප්\u200dරශ්නයක් සම්බන්ධ විශාලනය විශාලනයක් තියෙන්න පුළුවන් වෙයි, නමුත් පරීක්ෂණය සඳහා පරීක්ෂණය විශා සංවිධානය අධාරිත ප්\u200dරමාණය කරන්න, අපි ප්\u200dරයෝජනය කරනවා අසාම්බන්ගුයේෂ් මොඩේල්ස් එක්ක හොඳ අයිතික අයිතික අයිතික අ ඉංග්\u200dරීසි සහ චීනි ට්\u200dරී බැන්ක්ස් ගැන වෙනස් විශේෂ විශේෂ මොඩේල් එක්ක පරීක්ෂණය පෙන්වන්න පුළුවන', 'ta': 'இந்த காகிதத்தில் ஆழமான ஒத்திசைவு தகவல் வெற்று வகைகளின் மீது குறிப்பிட்ட குறிப்பிட்ட பாடலை உதவுமா என்பதை பற் சார்பு மரங்களை உருவாக்க புதிய ஆல்பரிமாணங்களை வடிவமைக்கிறோம். அதில் காலியான உறுப்புகள் அனுமதிக்கப்பட்டுள்ளது, வெற்று வகுப்பின் வ இவ்வாறு தகவல் வடிவமைக்கப்பட்ட பாடல் மாதிரியில் சுருக்கமான பிழையை குறைக்க உதவும், ஆனால் தேடும் இடைவெளியை அதிகரிக்கும் அதனால் மதிப அமைப்பு அடிப்படையில் உள்ள மாற்றுதலை தீர்க்க நாம் பிரிந்துகொள்ள வேண்டும் பிரிவுப்பு மாதிரிகளை காலியான உறுப்புகளுடன் ஒன்றா வேறு பாடல் மாதிரிகளுடன் ஆங்கிலம் மற்றும் சீனா மரப்பாங்குகளில் உள்ள சோதனை', 'mn': 'Энэ цаас нь гүн гүнзгий синтактик мэдээлэл гадаргуу хуваалцахдаа туслах боломжтой эсэхийг хамааралтай. Бид шинэ алгоритмыг зохион байгуулахын тулд хамааралтай мод бүтээх, хоосон элементүүд боломжтой, хоосон хэлбэрийн талаарх мэдээллийн нөлөөг шалгаж өгдөг. Ийм мэдээлэл бүтээгдэхүүний шинжилгээний загварын ойролцоогоор алдаа багасгах тулд тусалдаг, гэхдээ хайртай орон зайг нэмэгдүүлнэ, тэгэхээр тооцоолох алдаа. Бид бүтцийн үндсэн хэмжээний загварыг хоосон элементүүдтэй, хоосон элементүүдтэй холбоотой, бүтцийн загварыг бүтээмжүүлэхийг зөвшөөрөх гэсэн санал байна. Англи болон Хятадын TreeBanks-ын туршилтууд өөр өөр хуваалцах загварууд нь хоосон элементүүдийг нэгтгэх нь гадаргуу хуваалцах нь үргэлж сайжруулдаг гэдгийг харуулдаг.', 'ur': 'یہ کاغذ کا اندیشہ ہے کہ کیا عمیق سینٹاکتیک معلومات سطح پارس کرنے کی مدد کرتی ہے، کھلی کاٹیوں پر ایک خاص فوकस کرتی ہے۔ ہم نے نو الگوریتم ڈیزائن کر رکھے ہیں کہ ان کے درختوں میں اعتمادی درخت پیدا کریں جن میں خالی عنصر اجازت دی جاتی ہیں اور کھلی قطار کے بارے میں معلومات کی تأثیر مقرر کریں یہ معلومات ایک ساخترائی پارسینگ موڈل میں تقرب کی خطا کم کرنے کے لئے مددگار ہے، لیکن ضرورت کے لئے تلاش کی جگہ اضافہ کرتا ہے اور اس کے مطابق اندازہ کی خطا ہے. ساختاری بنیادی اورفیٹنگ کے ساتھ استعمال کرنے کے لئے، ہم ڈازمبیوٹ موڈل کے ساتھ اور خالی عنصروں کے بغیر اور ساختاری قانونی کے ذریعہ مشترک ڈیکوڈ کے ذریعہ استعمال کریں گے. انگلیسی اور چینی تری بنکس کے آزمائش مختلف پارسینگ موڈل کے ساتھ نشان دیتے ہیں کہ کھلی طالبوں میں شامل ہونا سطح پارسینگ کو ثابت ہوتا ہے.', 'uz': "Ushbu qog\xa0ªoz bo\xa0ªsh turlariga bog'liq bo\xa0ªlgan so\xa0ªzni ajratishga yordam beradi. Biz ishlatadigan daraxtlarni yaratish uchun yangi algoritlarga yaratishmiz. Bu yerda bo\xa0ªsh elementlar bo\xa0ªlishi mumkin. Bo\xa0ªsh turdagi tarjima haqida qidirish mumkin. @ info Name Name", 'vi': 'Bài này đề cập đến liệu thông tin cú pháp sâu có thể giúp phân tích bề mặt, đặc biệt là các loại rỗng không. Chúng tôi thiết kế những thuật to án mới để sản xuất những cây độ phụ thuộc trong đó những nguyên tố rỗng, và đánh giá tác động của thông tin về các loại trống để phân tích các yếu tố hở. Thông tin này có ích để giảm lỗi ước lượng trong một mô hình phân tích được cấu trúc, nhưng tăng vùng tìm kiếm để nhận ra và do đó lỗi ước tính. Để giải quyết việc bay trên các cấu trúc, chúng tôi đề nghị hợp nhất các mô hình biến dạng với và không có các nguyên tố rỗng, và thực hiện quy tắc cấu trúc qua giải mã chung. Các thí nghiệm trên cây Anh và Trung Quốc với các mô hình phân tách khác nhau cho thấy rằng trộn các nguyên tố rỗng luôn cải thiện phân tách bề mặt.', 'hr': 'Ovaj papir se brine o tome da li duboke sintaktičke informacije mogu pomoći analiziranju površine, s posebnim fokusom na prazne kategorije. Mi dizajniramo nove algoritme za proizvodnju drveća zavisnosti u kojima se dozvoljavaju prazni elementi i procjenjujemo učinak informacija o praznoj kategoriji na analizu prekovremenih elementa. Takve informacije su korisne za smanjenje pogreške približnosti u strukturiranom modelu analize, ali povećava prostor potražnje za infekcijom i odmah pogrešku procjene. Za rješavanje prema strukturom predlažemo integrirati modele disambiguacije s praznim elementima i bez praznih elementa i provoditi regularizaciju strukture putem zajedničkog dekodiranja. Eksperimenti o engleskom i kineskom TreeBanku s različitim analizacijskim modelima ukazuju na to da uključivanje praznih elementa konsekventno poboljšava analizaciju površine.', 'da': 'Dette arbejde handler om, hvorvidt dyb syntaktisk information kan hjælpe overflade parsing, med særligt fokus på tomme kategorier. Vi designer nye algoritmer til at producere afhængighedstræer, hvor tomme elementer er tilladt, og evaluerer effekten af oplysninger om tom kategori på fortolkningen af åbne elementer. Sådanne oplysninger er nyttige til at reducere tilnærmelsesfejlen i en struktureret fortolkningsmodel, men øger søgepladsen for inferens og dermed estimeringsfejlen. For at håndtere strukturbaseret overfitting foreslår vi at integrere adskillelsesmodeller med og uden tomme elementer og udføre strukturregulering via fælles afkodning. Eksperimenter på engelske og kinesiske træbanker med forskellige parsingsmodeller indikerer, at indarbejdelse af tomme elementer konsekvent forbedrer overflade parsing.', 'nl': 'Dit artikel gaat in op de vraag of diepe syntactische informatie kan helpen oppervlakteparsen, met een bijzondere focus op lege categorieën. We ontwerpen nieuwe algoritmen om afhankelijkheidsbomen te produceren waarin lege elementen zijn toegestaan, en evalueren de impact van informatie over lege categorieën op het parsen van overte elementen. Dergelijke informatie is nuttig om de approximatiefout in een gestructureerd parsing model te verminderen, maar vergroot de zoekruimte voor inferentie en daarmee de schattingsfout. Om structurele overfitting aan te pakken, stellen we voor om onderscheidingsmodellen met en zonder lege elementen te integreren en structurele regularisatie uit te voeren via gezamenlijke decodering. Experimenten op Engelse en Chinese TreeBanks met verschillende parsing modellen geven aan dat het integreren van lege elementen consistent de oppervlakteparsing verbetert.', 'id': 'Kertas ini mengkhawatirkan apakah informasi sintaks dalam dapat membantu penghuraian permukaan, dengan fokus tertentu pada kategori kosong. Kami merancang algoritma baru untuk menghasilkan pohon dependensi di mana elemen kosong diizinkan, dan mengevaluasi dampak informasi tentang kategori kosong pada penghuraian elemen yang jelas. Informasi seperti ini berguna untuk mengurangi kesalahan pendekatan dalam model penghuraian struktur, tetapi meningkatkan ruang pencarian untuk kesimpulan dan sebagainya kesalahan perkiraan. Untuk menghadapi overfitting berdasarkan struktur, kami mengusulkan untuk mengintegrasi model desambiguasi dengan dan tanpa elemen kosong, dan melakukan regularisasi struktur melalui dekodasi kongsi. Eksperimen di TreeBanks Inggris dan Cina dengan model penghuraian yang berbeda menunjukkan bahwa memasukkan elemen kosong secara konsisten meningkatkan penghuraian permukaan.', 'de': 'Diese Arbeit beschäftigt sich mit der Frage, ob tiefe syntaktische Informationen beim Oberflächenparsen helfen können, mit besonderem Fokus auf leere Kategorien. Wir entwerfen neue Algorithmen, um Abhängigkeitsbäume zu erzeugen, in denen leere Elemente erlaubt sind, und bewerten den Einfluss von Informationen über leere Kategorien auf das Parsen offener Elemente. Solche Informationen sind hilfreich, um den Approximationsfehler in einem strukturierten Parsing-Modell zu reduzieren, erhöhen aber den Suchraum für Inferenz und damit den Schätzfehler. Um strukturbasiertes Overfitting zu bewältigen, schlagen wir vor, Begriffsmodelle mit und ohne leere Elemente zu integrieren und Strukturregularisierung mittels Joint Decoding durchzuführen. Experimente an englischen und chinesischen Baumbanken mit verschiedenen Parsing-Modellen zeigen, dass die Integration leerer Elemente die Oberflächenparsing-Funktion konsequent verbessert.', 'bg': 'Тази статия се занимава с това дали дълбоката синтактична информация може да помогне за анализ на повърхността, с особен фокус върху празните категории. Проектираме нови алгоритми за създаване на дървета за зависимост, в които са разрешени празни елементи, и оценяваме въздействието на информацията за празна категория върху анализирането на открити елементи. Тази информация е полезна за намаляване на приблизителната грешка в структуриран модел на анализиране, но увеличава пространството за търсене за заключение и съответно грешката при оценката. За да се справим със структурно-базираното свръхмонтиране, предлагаме интегриране на модели за разграничаване с и без празни елементи и извършване на регулиране на структурата чрез съвместно декодиране. Експерименти на английски и китайски дървесни банки с различни модели за анализ показват, че включването на празни елементи последователно подобрява повърхностното анализиране.', 'ko': '본고는 심층 문법 정보가 표층 문법 분석에 도움이 되는지 주목하고 특히 빈 유형을 주목한다.우리는 새로운 알고리즘을 설계하여 빈 원소를 허용하는 의존 트리를 생성하고 빈 유형 정보가 공개 원소 해석에 미치는 영향을 평가했다.이러한 정보는 구조화 해석 모델에서의 근사 오차를 줄이는 데 도움이 되지만 추리의 검색 공간을 늘려 추정 오차를 증가시킨다.구조를 바탕으로 하는 과의합 문제를 해결하기 위해 우리는 유공과 무공 원소의 소차 모델을 결합시키고 연합 디코딩을 통해 구조를 정규화하는 것을 제기했다.서로 다른 문법 분석 모델을 가진 영어와 중국어 트리 라이브러리에서의 실험에 의하면 빈 요소를 넣으면 표면 문법 분석을 지속적으로 개선할 수 있다.', 'sw': 'Gazeti hili lina wasiwasi ikiwa taarifa za kina za ushirikiano inaweza kusaidia kujenga eneo hilo, yenye lengo maalum kwenye makundi madogo. Tunaweza kutengeneza mialgorithi mpya ili kutengeneza miti yenye kutegemea na ambapo vifaa vinavyoruhusiwa, na kutathmini madhara ya taarifa kuhusu makundi yasiyo na mengi yanayohusiana na kutengeneza vipengele vya juu. Taarifa hizi zinasaidia kupunguza kosa la karibu katika modeli ya parge lililojengwa, lakini inaongeza nafasi ya kutafuta ugonjwa na hivyo kupunguza kosa la kadiria. Ili kukabiliana na kusafirishwa kwa miundombinu, tunapendekeza kuunganisha miundo ya ubaguzi na bila vifaa vya kutosha, na kutekeleza udhibiti wa miundombinu kwa kupitia decodi kwa pamoja. Majaribio kwenye Benki ya Kiingereza na TreeBanks ya China yenye mifano mbalimbali ya wimbo huo yanaonyesha kuwa kuingiza vifaa vinavyoweza kuboresha wimbo wa surfe.', 'tr': 'Bu kagyz gaty sintaktik maglumatlary ýüzüniň ayırmagyna kömek edip biler, beýleki kategoriýalary boş üçin fokus biler aladalanýar. Biz täze algoritmalar baglary ýüklemek üçin boş elementlere rugsat berilýar we üstünde boş kategoriýa barada maglumatlaryň täsirini çykarýarys. Häzirki maglumat strukturly tanyş nusgasynda, yaklaýyş hatasyny azaltmak üçin kömek edip biler, ýöne tanyş ýerini azaltýar we munuň üçin hasaplamak hatasyny artýar. Başga düzgünlerden daşary çykmak üçin, köçülemek nusgalaryny boş elementlerle birleştirmek we strukturyň düzgünlerini birleştirmek üçin teklip edýäris. Iňlisçe we Çinçe agaç Banklarynyň örän farklı ahtarma nusgalary bilen boş elementleriň içine girişinde ýüz analyzasyny gowy görýär diýip görkezýär.', 'sq': 'Kjo letër është e shqetësuar në se informacioni i thellë sintaktik mund të ndihmojë analizimin e sipërfaqeve, me një fokus të veçantë në kategori bosh. Ne dizajnojmë algoritme të reja për të prodhuar pemë varësie në të cilat janë lejuar elemente bosh dhe vlerësojmë ndikimin e informacionit rreth kategorisë bosh në analizimin e elementeve të qarta. Informacioni i tillë është i dobishëm për të reduktuar gabimin e përafërsisë në një model të strukturuar analizimi, por rrit hapësirën e kërkimit për përfundimin dhe në këtë mënyrë gabimin e vlerësimit. Për të trajtuar mbipajtimin bazuar në strukturë, ne propozojmë të integrojmë modelet e çambiguacionit me dhe pa elemente bosh dhe të kryejmë rregullalizimin e strukturës nëpërmjet dekodimit të përbashkët. Eksperimentet në TreeBanks angleze dhe kineze me modele të ndryshme analizimi tregojnë se përfshirja e elementeve bosh përmirëson vazhdimisht analizimin e sipërfaqeve.', 'fa': 'این کاغذ نگرانی است که آیا اطلاعات سنتاکتیک عمیق می\u200cتواند به تقسیم سطح کمک کند، با یک تمرکز خاصی روی کاغذهای خالی. ما الگوریتم\u200cهای جدید را طراحی می\u200cکنیم تا درختان بستگی را تولید کنیم که در آن عناصر خالی اجازه داده می\u200cشود، و تاثیر اطلاعات درباره عناصر خالی بر بررسی عناصر خالی را ارزیابی می\u200cکنیم. این اطلاعات برای کاهش خطای نزدیک شدن در یک مدل تقسیم ساخته کمک می\u200cکند، ولی فضای جستجو برای آلودگی افزایش می\u200cدهد و به همین دلیل خطای ارزیابی را افزایش می\u200cدهد. برای استفاده از زیادی ساختار، ما پیشنهاد می\u200cدهیم که مدل\u200cهای نامبوگیری را با و بدون عناصر خالی جمع کنیم، و از طریق دکوندن مشترک ساختار را ادامه دهیم. تجربه\u200cهای انگلیسی و درخت چینی با مدل\u200cهای پردازی متفاوت نشان می\u200cدهند که شامل عناصر خالی همیشه پردازی سطح را بهتر می\u200cکند.', 'af': "Hierdie papier is bekommerd met of diep sintaktieke inligting kan hulp oor die oortjie verwerking, met 'n bepaalde fokus op leë kategorie. Ons ontwerp nuwe algoritme om afhanklikheid bome te produseer waarin leë elemente toegelaat word, en evalueer die effek van inligting oor leë kategorie op verwerking van overt elemente. Hierdie inligting is hulp om die aankomstige fout in 'n struktureerde verwerking model te verminder, maar verhoog die soektog spasie vir inferensie en dus die estimatiese fout. Om te behandel met struktuur-gebaseerde oorvloediging, voorstel ons om disambiguasie-modelles met en sonder leë elemente te integreer en struktuur regularisasie te doen deur joint dekodering. Eksperimente op Engels en Sjinese TreeBanks met verskillende verwerking modele wys dat die inkorporering van leë elemente konsistentlik die oortjie verwerking verbeter.", 'am': 'ይህ ገጽ የጥልቅ የሲንተርካዊ መረጃ የደረጃ ማዘጋጀት ማግኘት ይችላል፡፡ የአዲስ መግለጫ አካል አዲስ መፍጠር የሚታደገ ዛፎችን ለመፍጠር እናደርጋለን፣ የባዶ አካላት ፍላጎቶችን ለመፍጠር እናስተውላለን፡፡ ይህ መረጃ በተሠረተ ማዘጋጀት ሞዴል ውስጥ የአቅራቢያ ስህተት ማሳሳየት ይጠቅማል፥ ነገር ግን ለመፈለግ ስፋትን ማሳየት ይጨምርበታል፡፡ የመሠረተ አካባቢ ጉዳይ ለመቀበል እና ባዶ አካላትን ለመቀናቀል እናደርጋለን፡፡ በንግግሊዝና በቻይና TreeBanks ላይ በተለየ ፓርቲው ሞዴላዎችን በመግጠም የባዶ አካላትን በመጠቀም የsurface ማዘጋጃውን በመጠቀም የሚያሳየው ነው፡፡', 'hy': 'Այս թղթին անհանգստանում է այն մասին, թե արդյոք խորը սինտակտիկ ինֆորմացիան կարող է օգնել մակերևույթի վերլուծումը, առանձնահատուկ կենտրոնացում դատարկ կատեգորիաների վրա: Մենք նախագծում ենք նոր ալգորիթմներ կախվածության ծառերի արտադրման համար, որտեղ թույլ են տալիս դատարկ տարրեր, և գնահատում ենք դատարկ կատեգորիթմի մասին տեղեկատվության ազդեցությունը բացահայտված տարրերի վերլուծության վրա: Այս տեղեկատվությունը օգտակար է նվազեցնելու հարաբերակցման սխալը կառուցվածքային վերլուծության մոդելի մեջ, սակայն աճում է հետևանքների որոնման տարածքը և հետևաբար գնահատման սխալը: Որպեսզի գործ ունենանք կառուցվածքի հիմնված գերապատրաստման հետ, մենք առաջարկում ենք ինտեգրել անբացատրական մոդելները դատարկ տարրերով և առանց դրանց, և կատարել կառուցվածքի վերականգնումը միասին վերականգնելով: Անգլերենի և չինական ծառերի բանկերի փորձարկումները տարբեր վերլուծության մոդելներով ցույց են տալիս, որ դատարկ տարրերի ներառումը մշտապես բարելավում է մակերևույթի վերլուծությունը:', 'az': 'Bu kağıt çökmüş sintaktik məlumatların, boş kategoriyalar üzərində müəyyən bir tərzi ilə üzərini ayırmağa kömək edə biləcəyini düşünürlər. Biz yeni algoritmi, bağımlılıq ağaclarını ürəkləmək üçün hazırlamışıq ki, orada boş elementlər izin verilir, və boş kategoriya haqqındakı məlumatların səbəbi çəkiririk. Bütün bu məlumat strukturlu ayırma modelində yaxınlaşma xətasını azaltmaq üçün faydalıdır, amma xəstəlik üçün arama alanını artırar və buna görə də hesablama xətasını artırar. Struktura tabanlı aşırı uyğunlaşdırmaq üçün, birlikdə kodlama vasitəsilə və boş elementlərlə disambiguasyon modellərini birləşdirmək və struktur düzgünlüyünü müəyyən edirik. İngilizce və Çin ağac Bankları təcrübələri ilə müxtəlif ayırma modelləri ilə təcrübə edirlər ki, boş elementlərin içində yer ayırmasını daimi daha yaxşılaşdırır.', 'bs': 'Ovaj papir se brine o tome da li duboke sintaktičke informacije mogu pomoći u analizu površine, s posebnim fokusom na prazne kategorije. Mi dizajniramo nove algoritme za proizvodnju drveća zavisnosti u kojima se dozvoljavaju prazni elementi i procjenjujemo utjecaj informacija o praznoj kategoriji na analizu prekovremenih elementa. Takve informacije su korisne za smanjenje pogreške približnosti u strukturiranom modelu analize, ali povećava prostor pretraživanja za infekciju i odmah pogrešku procjene. Za rješavanje prema strukturom predlažemo integrirati modele disambiguacije s praznim elementima i bez praznih elementa i izvršiti regularizaciju strukture putem zajedničkog dekodiranja. Eksperimenti o engleskom i kineskom TreeBanku s različitim analizacijskim modelima ukazuju na to da uključenje praznih elementa konsekventno poboljšava analizaciju površine.', 'ca': "Aquest paper es preocupa si la informació sinàctica profunda pot ajudar a analitzar la superfície, centrant-se en categories buides. dissenyem nous algoritmes per produir arbres de dependencia en els quals s'permeten elements buits, i evaluem l'impacte de la informació sobre la categoria buida en l'analització d'elements overts. Aquesta informació és útil per reduir l'error d'aproximació en un model d'analització estructurat, però augmenta l'espai de cerca de inferència i, en conseqüència, l'error d'estimació. Per tractar l'equipament excessiv basat en l'estructura, proposem integrar models de desambiguació amb i sense elements buits i realitzar la regularizació de l'estructura a través de la decodificació articular. Experiments on English and Chinese TreeBanks with different parsing models indicate that incorporating empty elements consistently improves surface parsing.", 'cs': 'Tento článek se zabývá tím, zda hluboké syntaktické informace mohou pomoci povrchové analýze, se zvláštním zaměřením na prázdné kategorie. Navrhujeme nové algoritmy pro tvorbu stromů závislostí, ve kterých jsou povoleny prázdné prvky, a vyhodnocujeme vliv informací o prázdné kategorii na analýzu otevřených prvků. Tyto informace jsou užitečné pro snížení aproximace chyby ve strukturovaném parsovacím modelu, ale zvyšují prostor pro vyhledávání inference a následně i chybu odhadu. Pro řešení strukturově založeného přesahu navrhujeme integrovat diambiguační modely s prázdnými prvky i bez nich a provést regularizaci struktury pomocí společného dekódování. Experimenty na anglických a čínských stromových bankách s různými parsovacími modely ukazují, že začlenění prázdných prvků důsledně zlepšuje parsování povrchu.', 'bn': 'এই পত্রিকাটি চিন্তিত যে গভীর সিন্ট্যাক্টিক তথ্য ফাঁকা বিভাগের পার্সিং পার্সিং সাহায্য করতে পারে কি না। আমরা নতুন অ্যালগরিদম নির্ভরশীল গাছ উৎপাদনের জন্য ডিজাইন করি যেখানে ফাঁকা উপাদানের অনুমতি দেয়া হয় এবং ফাঁকা বিভাগের তথ্যের প্রভাব সম্পর্ক এই তথ্য একটি কাঠামোক্ত পার্সিং মডেলে প্রায় সংক্রান্ত ত্রুটি কমাতে সাহায্য করে, কিন্তু সংক্রান্ত সংক্রান্ত স্থান বৃদ্ধ কাঠামোর ভিত্তিক প্রবাহের সাথে মিলিত হওয়ার জন্য আমরা প্রস্তাব করছি বিভ্রান্ত মডেলের সাথে এবং ফাঁকা উপাদান ছাড়াই একত্রিত করতে এবং যৌথ ডি বিভিন্ন পার্সিং মডেলের সাথে ইংরেজি এবং চীনা ট্রীব্যাংকের পরীক্ষা নির্দেশ করেছে যে ফাঁকা উপাদানের মধ্যে যোগাযোগ করা হয়', 'et': 'Käesolevas dokumendis käsitletakse, kas sügav süntaktiline teave võib aidata pinna parsimist, keskendudes eelkõige tühjadele kategooriatele. Projekteerime uusi algoritme sõltuvuspuude, milles on lubatud tühjad elemendid, ning hindame tühja kategooria info mõju avatud elementide parsimisele. Selline teave aitab vähendada struktureeritud parsimismudeli lähenemisviga, kuid suurendab järelduste otsimisruumi ja vastavalt hindamisviga. Struktuuripõhise ülepaigutusega tegelemiseks teeme ettepaneku integreerida tühjade elementidega ja ilma selleta eristusmudelid ning teostada struktuuri reguleerimist ühisdekodeerimise abil. Erinevate parsimismudelitega inglise ja hiina puupankade eksperimendid näitavad, et tühjade elementide kasutamine parandab pidevalt pinnaparsimist.', 'fi': 'Tämä artikkeli käsittelee sitä, voiko syvä syntaktinen tieto auttaa pinnan jäsentämistä, keskittyen erityisesti tyhjiin luokkiin. Suunnittelemme uusia algoritmeja tuottamaan riippuvuuspuita, joissa tyhjiä elementtejä sallitaan, ja arvioimme tyhjiä luokkia koskevan tiedon vaikutusta avointen elementtien jäsentämiseen. Tällaiset tiedot auttavat vähentämään strukturoidun jäsennysmallin lähentämisvirhettä, mutta lisäävät hakutilaa päättelylle ja vastaavasti estimointivirheelle. Rakennepohjaisen ylikuormituksen käsittelemiseksi ehdotamme, että integroidaan erottelumallit tyhjillä elementeillä ja ilman niitä sekä tehdään rakenteen säännöstely yhteisdekoodaamalla. Englanninkielisillä ja kiinalaisilla puupankeilla tehdyt kokeet eri parsausmalleilla osoittavat, että tyhjien elementtien sisällyttäminen parantaa pintaparsausta johdonmukaisesti.', 'jv': 'string" in "context_BAR_stringLink Awak dhéwé sistem Anyar Algorithm sing dibutuhke Keterangkang dipunangé perusahaan karo perusahaan karo perusahaan karo perusahaan karo perusahaan karo perusahaan karo perusahaan karo perusahaan informasi tambah bantuan kanggo ngakses ndelok kelangan kelangan kelangan kelangan Rasané kayané sistem-diangkat akses, kita supoyo nggawe model di dismbiguation karo lan karo alaman sing perusahaan, lan ngakus ngupakan ndelok sampek Jung-dino. Gejer-jejer mbut Inggris lan Tarik Banks sing wis dipun model urip nggawe sapa pernik nik ingkang eleman sing takon nggawe layang limo urip nggawe', 'sk': 'Ta prispevek obravnava, ali lahko globoke sintaktične informacije pomagajo pri razčlenitvi površin, s posebnim poudarkom na praznih kategorijah. Oblikujemo nove algoritme za izdelavo dreves odvisnosti, v katerih so dovoljeni prazni elementi, in ocenjujemo vpliv informacij o prazni kategoriji na razčlenjevanje prevzetih elementov. Takšne informacije so koristne za zmanjšanje napake približevanja v strukturiranem modelu razčlenjanja, vendar povečujejo iskalni prostor za sklepanje in s tem tudi napako ocenjevanja. Za obravnavo preoblikovanja na podlagi strukture predlagamo integracijo razločevalnih modelov s praznimi elementi in brez njih ter izvedbo regulacije strukture preko skupnega dekodiranja. Eksperimenti na angleških in kitajskih drevesnih bankah z različnimi modeli razčlenitve kažejo, da vključevanje praznih elementov dosledno izboljšuje razčlenitev površine.', 'he': 'הנייר הזה מודאג אם מידע סינטקטי עמוק יכול לעזור לאבחן פנים, עם מרכז מסוים בקטגוריות ריקות. אנו מעצבים אלגוריתמים חדשים כדי לייצר עצי תלויות שבהם אפשרים אלמנטים ריקים, ולעריך את ההשפעה של מידע על קטגוריה ריקה על מעבדת אלמנטים ברורים. מידע כזה מועיל כדי להפחית את טעות התקרבות במודל מעבדה מבוסס, אך מגביר את מרחב החיפוש למסקנה ולכן את טעות הערכה. כדי להתמודד עם התקנה המבוססת על מבנה יתר, אנו מציעים להשתלב מודלים של ניתוח בין אלמנטים ריקים ובין אלמנטים ריקים, ולבצע ניתוח מבנה דרך פיתוח משותף. ניסויים על אנגלית ועץ בנקס סינית עם דוגמנים בדיקות שונים מצביעים על כך שמכיל אלמנטים ריקים משפר באופן קבוע את בדיקות השטח.', 'ha': 'This paper is concerned with whether deep syntactic information can help surface parsing, with a particular focus on empty categories.  Kana ƙayyade algoritori na new don mu fitar da itãce masu da inganci, a cikinsa don an yarda ƙanshi masu buƙata, kuma Mu ƙaddara matsayin abun information about category mai amfani da kan parse ƙanshi na ƙasƙanci. @ info Dõmin ka yi haɗi da surori wanda aka baka shi na rubutu, sai Mu buƙata in haɗa misãlai masu yin gaugãwa da kuma bã da ƙanshi ba, kuma Mu cika jurisori na bakin rubutu da kwamfyuta. Tajararin da ke cikin Ingiriya da TreeBanks na China da misãlai masu yin parse-daban, yana nũna cewa, a shigar da abubuwa masu koma mafi kyau ga parse ga fuskar.', 'bo': 'This paper is concerned with whether deep syntactic information can help surface parsing, with a particular focus on empty categories. We design new algorithms to produce dependency trees in which empty elements are allowed, and evaluate the impact of information about empty category on parsing overt elements. གཟུགས་རིས་དབྱེ་ཞིབ་ཀྱི་མིག་དཔྱད་ནང་ལ་ཕན་ཚུན་འབྲས་བའི་ནོར་འཁྲུལ་འདི་དམའ་རུ་གཏོང To deal with structure-based overfitting, we propose to integrate disambiguation models with and without empty elements, and perform structure regularization via joint decoding. དབྱིན་ཡིག་དང་རྒྱ་ནག་གི་དབྱིན་བཟོ་བྱེད་ཀྱི་སྒེར་གྱི་ཚད་མི་འདྲ་བར་མཐུན་པས། དབྱེ་སྟངས་མི་འདྲ་བར་ན་ནང་བཙུགས་ཀྱི་ནང་ཚན་སྟོང'}
{'en': 'German in Flux : Detecting Metaphoric Change via Word Entropy', 'ar': 'الألمانية في التدفق: اكتشاف التغيير المجازي عبر كلمة إنتروبيا', 'fr': "German in Flux\xa0: Détecter le changement métaphorique via l'entropie des mots", 'es': 'Alemán en flujo: detección del cambio metafórico a través de la entropía de palabras', 'pt': 'Alemão em fluxo: detectando mudanças metafóricas via entropia de palavras', 'ja': 'フラックスのドイツ語:単語エントロピーを介した比喩的変化の検出', 'ru': 'Немецкий в потоке: обнаружение метафорических изменений через энтропию слов', 'zh': '变化之德语:因词熵检隐喻变', 'hi': 'फ्लक्स में जर्मन: वर्ड एन्ट्रॉपी के माध्यम से रूपक परिवर्तन का पता लगाना', 'ga': 'Gearmáinis i bhFlosc: Athrú Metaphoric a Bhrath trí Focal Eantrópachta', 'el': 'Γερμανικά σε ροή: Ανίχνευση μεταφορικής αλλαγής μέσω της εισόδου λέξεων', 'ka': 'Name', 'hu': 'Német folyamatban: Metafórikus változások felismerése Word Entrópia segítségével', 'mk': 'Германски во текст: Детектирање метафорска промена преку зборна ентропија', 'it': "Tedesco in flusso: rilevare cambiamenti metaforici tramite l'entropia di parole", 'kk': 'Флукс тіліндегі неміс: Word Entropy арқылы метафориялық өзгерістерді анықтау', 'ms': 'Jerman dalam Fluks: Mengesan Perubahan Metaforik melalui Entropi Perkataan', 'ml': 'Name', 'lt': 'Vokietijos kalba: metaforinių pokyčių nustatymas per žodžių entropiją', 'mn': 'Флукст Герман: Word Entropy-ээр метафорик өөрчлөлтийг олж мэдэх', 'no': 'Tysk i Flux: Finn metaforisk endring via Word Entropy', 'mt': 'Ġermaniż bi Fluss: Jinstab Bidla Metaforika permezz tal-Entropija tal-kliem', 'ro': 'Germană în flux: detectarea schimbărilor metaforice prin intermediul intropiei cuvintelor', 'pl': 'Niemiecki w przepływie: Wykrywanie zmian metaforycznych za pomocą entropii słowa', 'si': 'Name', 'sr': 'Njemaèki u fluksi: Pronaðenje metaforske promene preko reèi entropije', 'so': 'Jarmal in Flux: Detecting Metaphoric Change via Word Entropy', 'sv': 'Tyska i flöde: upptäcka metaforisk förändring via Word Entropi', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Đức trong Flux: Phát hiện biến đổi siêu hình bằng từ ảnh vào trong', 'bg': 'Немски в поток: откриване на метафорична промяна чрез ентропия на думи', 'nl': 'Duits in flux: Metaforische verandering detecteren via woordentropie', 'hr': 'Njemački u fluxu: otkrivanje metaforske promjene putem riječne entropije', 'de': 'Deutsch im Fluss: Metaphorische Veränderungen mittels Wortentropie erkennen', 'da': 'Tysk i flux: detektering af metaforisk ændring via Word Entropi', 'id': 'Jerman dalam Flux: Mengeteksi Perubahan Metaforik melalui Entropi Kata', 'sw': 'Ujerumani huko Flux: Kugundua Mabadiliko ya Kituo kupitia Neno', 'fa': 'Name', 'af': 'Name', 'sq': 'German in Flux: Detecting Metaphoric Change via Word Entropy', 'ko': '《변천 중인 독일어》: 엔트로피를 통해 은유 변화를 검출한다.', 'hy': 'Գերմաներեն ֆլուքսի մեջ. Բառերի էնտրոպիայի միջոցով հայտնաբերում է մետաֆորական փոփոխություն', 'tr': 'Fluks dilinde Almança', 'am': 'ጀርመን በFlux: Metaphoric Change via Word Entropy', 'bn': 'German in Flux: Detecting Metaphoric Change via Word Entropy', 'bs': 'Njemački u Fluxu: Otkrivanje metaforske promjene putem riječne entropije', 'cs': 'Němčina v toku: Detekce metaforických změn pomocí slovní entropie', 'ca': "Alemanès en flux: Detectar el canvi metafòric mitjançant l'entropia de paraules", 'fi': 'German in Flux: Metaforisen muutoksen havaitseminen Word Entropyn avulla', 'az': 'Flux olaraq Almanca: Kelimi Entropy vasit…ôsil…ô metaforik d…ôyiŇüiklikl…ôri keŇüif edir', 'et': 'Saksa keel voolus: metafoorsete muutuste tuvastamine sõna entroopia abil', 'jv': 'Actual Name', 'ha': '@ item Spelling dictionary', 'he': 'גרמנית בשפעה: גילוי שינוי מטאפורי באמצעות אנטרופיה מילים', 'sk': 'Nemščina v toku: Zaznavanje metaforičnih sprememb prek Wordove entropije', 'bo': 'German in Flux: Detecting Metaphoric Change via Word Entropy'}
{'en': 'This paper explores the information-theoretic measure entropy to detect metaphoric change, transferring ideas from hypernym detection to research on language change. We build the first diachronic test set for German as a standard for metaphoric change annotation. Our model is unsupervised, language-independent and generalizable to other processes of semantic change.', 'ar': 'تستكشف هذه الورقة مقياس إنتروبيا المعلوماتية للكشف عن التغيير المجازي ، ونقل الأفكار من اكتشاف التشعبات إلى البحث في تغيير اللغة. قمنا ببناء أول اختبار رقمي تم تعيينه للغة الألمانية كمعيار للتعليق التوضيحي المجازي للتغيير. نموذجنا غير خاضع للإشراف ومستقل عن اللغة وقابل للتعميم على عمليات التغيير الدلالي الأخرى.', 'pt': 'Este artigo explora a entropia da medida da teoria da informação para detectar mudanças metafóricas, transferindo ideias da detecção de hiperônimos para pesquisas sobre mudanças na linguagem. Construímos o primeiro conjunto de testes diacrônicos para alemão como padrão para anotação de mudança metafórica. Nosso modelo é não supervisionado, independente de linguagem e generalizável para outros processos de mudança semântica.', 'fr': "Cet article explore l'entropie de mesure de la théorie de l'information pour détecter les changements métaphoriques, en transférant des idées de la détection des hypernymes à la recherche sur le changement de langue. Nous construisons le premier jeu de tests diachroniques pour l'allemand en tant que norme pour l'annotation métaphorique des changements. Notre modèle est non supervisé, indépendant de la langue et généralisable à d'autres processus de changement sémantique.", 'es': 'Este artículo explora la entropía de medidas teóricas de la información para detectar cambios metafóricos, transfiriendo ideas de la detección de hipernimos a la investigación sobre el cambio de lenguaje. Creamos el primer conjunto de pruebas diacrónicas para alemán como estándar para la anotación de cambios metafóricos. Nuestro modelo no está supervisado, es independiente del idioma y se puede generalizar a otros procesos de cambio semántico.', 'ja': 'この論文では、比喩的変化を検出するための情報理論的測定エントロピーを探求し、超越論的変化の検出から言語変化の研究にアイデアを転移します。私たちは、比喩的な変化の注釈の標準として、ドイツ語のための最初のダイアクロニック試験セットを構築します。私たちのモデルは、監督されておらず、言語に依存せず、意味変化の他のプロセスに一般化することができます。', 'zh': '本文讨检隐喻变化之信熵,移心于超名词。 余为德语构首历试集,以为隐喻变注之准。 吾法无监督,非关语言,且可及语义变化之余。', 'hi': 'यह पेपर रूपक परिवर्तन का पता लगाने के लिए सूचना-सैद्धांतिक उपाय एन्ट्रॉपी की पड़ताल करता है, हाइपरनिम डिटेक्शन से विचारों को भाषा परिवर्तन पर शोध में स्थानांतरित करता है। हम रूपक परिवर्तन एनोटेशन के लिए एक मानक के रूप में जर्मन के लिए पहले डायक्रोनिक परीक्षण सेट का निर्माण करते हैं। हमारा मॉडल असुरक्षित, भाषा-स्वतंत्र और शब्दार्थ परिवर्तन की अन्य प्रक्रियाओं के लिए सामान्यीकृत है।', 'ru': 'В этой статье исследуется информационно-теоретическая мера энтропии для обнаружения метафорических изменений, перенося идеи от обнаружения гипернима к исследованиям по изменению языка. Мы создаем первый набор диахронических тестов для немецкого языка в качестве стандарта для аннотации метафорических изменений. Наша модель является неконтролируемой, языково-независимой и обобщаемой к другим процессам семантических изменений.', 'ga': 'Scrúdaíonn an páipéar seo an eantrópacht beart faisnéise-teoiriceach chun athrú meafarach a bhrath, ag aistriú smaointe ó bhrath hipirinim go taighde ar athrú teanga. Tógaimid an chéad tacar tástála déachrónach don Ghearmáinis mar chaighdeán le haghaidh anótáil athraithe mheafarach. Tá ár múnla gan mhaoirseacht, neamhspleách ar theanga agus inchurtha i leith próisis eile athraithe shéimeantaigh.', 'hu': 'Ez a tanulmány az információelméleti entrópia mérését vizsgálja a metaforikus változások észlelésére, ötletek átadását a hiperním detektálástól a nyelvváltozások kutatására. Megépítjük az első diakrónikus tesztkészletet német számára, mint a metaforikus változásjegyzékek szabványa. Modellünk felügyelet nélkül, nyelvfüggetlen és általánosítható a szemantikai változás más folyamataira.', 'el': 'Η παρούσα εργασία διερευνά το πληροφοριακό-θεωρητικό μέτρο εντροπίας για την ανίχνευση μεταφορικής αλλαγής, μεταφέροντας ιδέες από την ανίχνευση υπερνύμων στην έρευνα για την αλλαγή της γλώσσας. Κατασκευάζουμε το πρώτο διαχρονικό σετ δοκιμών για τα γερμανικά ως πρότυπο για μεταφορικές σχολιασμούς αλλαγής. Το μοντέλο μας είναι ανεξέλεγκτο, γλωσσικό ανεξάρτητο και γενικευμένο σε άλλες διαδικασίες σημασιολογικής αλλαγής.', 'ka': 'ეს დოკუმენტი ინფორმაცია-ტეორეტიკური ზომის ენტროპია, რომელიც მეტაფორიკური ცვლილების განახსნა, იდეები ჰიპერნიმური განახსნა იდეებიდან ენტაფორიკური ც ჩვენ გერმანეთისთვის პირველი დიაპრონიკური ტესტის შევქმნით, როგორც მეტაფორიკური ცვლილების ანოტაციისთვის. ჩვენი მოდელი არ განსხვავებულია, ენერგიის განსაზღვრებულია და გენერალურია სხვა ცვლილების პროცესებისთვის.', 'kk': 'Бұл қағаз метафориялық өзгерістерді анықтау үшін мәлімет- теориялық өлшемінің ентропиясын зерттеп, идеяларды гипернимді анықтау үшін тіл өзгерістерін зерттеу үшін аударып,  Біз неміс үшін бірінші диагроникалық сынақтарды метафориялық өзгерту жазбаларының стандартты ретінде құрамыз. Біздің үлгіміз өзгертілмеген, тілден тәуелсіз және басқа семантикалық өзгерту процестеріне жалпы болады.', 'lt': 'Šiame dokumente nagrinėjama informacijos ir teorinės priemonės entropija metaforiniams pokyčiams aptikti, perduodamos idėjas nuo hiperinimo aptikimo prie kalbos pokyčių mokslinių tyrimų. Mes sukuriame pirmąjį diachroninį bandymą vokiečiams kaip metaforinių pokyčių anotacijos standartą. Mūsų model is yra nepastebimas, nepriklausomas nuo kalbos ir gali būti plačiai paplitęs kitiems semantinių pokyčių procesams.', 'it': "Questo articolo esplora l'entropia di misura teoretica dell'informazione per rilevare il cambiamento metaforico, trasferendo idee dalla rilevazione degli ipernimi alla ricerca sul cambiamento del linguaggio. Costruiamo il primo set di test diacronici per il tedesco come standard per l'annotazione metaforica del cambiamento. Il nostro modello non è supervisionato, indipendente dal linguaggio e generalizzabile ad altri processi di cambiamento semantico.", 'mk': 'Овој весник ја истражува информативната теоретска мерка ентропија за детектирање метафорски промени, пренесувајќи идеи од детектирање хиперними на истражување за промена на јазикот. Го изградуваме првиот дијахроничен тест за германски како стандард за анатација на метафорска промена. Нашиот модел е ненадгледуван, независен од јазикот и генерализиран за други процеси на семантична промена.', 'ml': 'ഈ പത്രത്തില്\u200d വിവരങ്ങള്\u200d തിയോറിക്ക് എന്റ്രോപ്പിയെ കണ്ടുപിടിക്കുന്നത് മാറ്റിമാറ്റങ്ങള്\u200d കണ്ടുപിടിക്കാനും, ഹൈപ്പെനിമി ജര്\u200dമ്മനിലെ ആദ്യത്തെ ഡൈക്രോണിക് പരീക്ഷണത്തിന്റെ സെറ്റ് നമ്മള്\u200d നിര്\u200dമ്മിക്കുന്നു. മെറ്റോഫിക്ക്  നമ്മുടെ മോഡല്\u200d സൂക്ഷിക്കപ്പെടുന്നില്ല, ഭാഷ സ്വാതന്ത്ര്യതയില്ലാത്ത, മറ്റു സെമാന്റിക് മാറ്റങ്ങളുടെ', 'ms': 'Kertas ini mengeksplorasi entropi ukuran maklumat-teori untuk mengesan perubahan metaforik, memindahkan idea dari pengesan hipernim ke kajian perubahan bahasa. Kami membina ujian diakronik pertama ditetapkan untuk Jerman sebagai piawai untuk anotasi perubahan metaforik. Model kita tidak diawasi, bebas dari bahasa dan boleh diseluruhkan kepada proses lain perubahan semantik.', 'mn': 'Энэ цаас нь метафорын өөрчлөлтийг олоход мэдээллийн теоретикийн хэмжээг судалж, санаануудыг гиперним нээлттэйгээс хэлний өөрчлөлтийн судалгаанд шилжүүлж байна. Бид Германы анхны шинжлэх ухааны шинжлэх ухааны стандарт болгоно. Бидний загвар нь зэрэгцээ өөрчлөлт хийх боломжгүй, хэл хамааралтай, ерөнхийлөгч байдаг.', 'mt': 'Dan id-dokument jesplora l-entropija tal-miżura teoretika-informazzjoni biex tinstab bidla metaforika, billi jittrasferixxi ideat mill-individwazzjoni tal-iperinimi għar-riċerka dwar il-bidla fil-lingwa. Aħna nibnu l-ewwel sett ta’ test dijakroniku għall-Ġermaniż bħala standard għall-annotazzjoni tal-bidla metaforika. Il-mudell tagħna mhuwiex sorveljat, indipendenti mil-lingwa u ġeneralizzabbli għal proċessi oħra ta’ bidla semantika.', 'no': 'Denne papiret utforskar entropien med informasjon- teoretisk mål for å finna metaforiske endringar, overføra ideane frå hypernymoppdaging til forskning om språk- endringar. Vi bygger den første diakroniske testen for tysk som standard for metaforiske endringsinnstillingar. Modellen vårt er ikkje oppretta, språk-uavhengig og generelt for andre prosesser med semantiske endringar.', 'pl': 'W artykule badano teoretyczną miarę entropii informacyjno-teoretyczną w celu wykrycia zmian metaforycznych, przenosząc ideę z wykrywania hipernimów do badań nad zmianami językowymi. Budujemy pierwszy zestaw diachronicznych testów dla niemieckiego jako standard metaforycznej adnotacji zmian. Nasz model jest nienadzorowany, niezależny od języka i uogólniony dla innych procesów zmiany semantycznej.', 'ro': 'Această lucrare explorează entropia teoretică a informației pentru a detecta schimbarea metaforică, transferând idei de la detectarea hipernimului la cercetarea schimbării limbajului. Construim primul set de teste diacronice pentru germană ca standard pentru adnotarea metaforică a schimbărilor. Modelul nostru este nesupravegheat, independent de limbaj și generalizabil la alte procese de schimbare semantică.', 'sr': 'Ovaj papir istražuje entropiju informacija-teoretičke mjere za otkrivanje metaforskih promjena, prebacivanje ideja iz hipernimskog otkrivanja na istraživanje o promjeni jezika. Napravili smo prvi diahronički test za njemačke kao standard za metaforske oznake za promjene. Naš model je neodređen, nezavisan jezik i generalizan za druge procese semantičke promjene.', 'so': 'Warqaddaas wuxuu baaraandegaa tartanka macluumaadka la xiriira si uu u ogaado isbedelka midowga, wuxuuna beddelinayaa fikrada lagaga beddeliyo bedelka luqada. Waxaynu dhisaynaa imtixaanka ugu horeeya ee dhakhtarka ee Jarmalka sida calaamad u ah kalajarka beddelka. Tusaalkayaga waa mid aan la ilaalinayn, mid aan luqadu ku xoreen, waxaana loo barwaaqayaa habab kale oo isbedelka midabka ah.', 'sv': 'Denna uppsats undersöker det informationsteoretiska måttet entropi för att upptäcka metaforisk förändring, överföra idéer från hypernymdetektering till forskning om språkförändring. Vi bygger den första diakroniska testuppsättningen för tyska som standard för metaforiska förändringsannoteringar. Vår modell är oövervakad, språkoberoende och generaliserad för andra processer av semantisk förändring.', 'ta': 'இந்த தாள் தகவல்-தியூரிக் அளவு நுழைவை கண்டுபிடிக்க முடியும், மொழி மாற்றத்தைப் பற்றி ஆராய்ச்சிக்கு மாற்றும் கருத்துகளை ம நாங்கள் ஜெர்மன் மாற்றத்திற்கு ஒரு நிலையாக முதல் நோய் சோதனையை உருவாக்குகிறோம். எங்கள் மாதிரி பாதுகாப்பாக்கப்படாது, மொழி சுதந்தி மற்றும் பொதுவான மாற்றம் மற்ற செயல்பாடுகளுக்கு.', 'si': 'මේ පත්තර පරීක්ෂණය සඳහා තොරතුරු සාධාරණික වෙනස් හොයාගන්න, භාෂාව වෙනස් ගැන පරීක්ෂණය සඳහා අදහස් පරීක්ෂණය අපි ජර්මන් වෙනුවෙන් පලවෙනි ප්\u200dරධාන පරීක්ෂණ සෙට් වෙනුවෙන් මෙටාෆෝරික් වෙනස් වෙනුවෙන් ස අපේ නිර්මාණය නිර්මාණය කරන්නේ නැහැ, භාෂාව නිර්මාණය සහ සාමාන්\u200dය වෙනස් කරන්න පුළුවන්.', 'ur': 'This paper explores the information-theoretical measure entropy to detect metaphoric change, transferring ideas from hypernym detection to research on language change. ہم نے جرمن کے لئے پہلی دیاگرنیک امتحان سٹ بنایا ہے کہ metaphoric change annotation کے لئے استاندارد ہو۔ ہمارا مدل غیر قابل تحقیق ہے، زبان غیر قابل اور غیر قابل تحقیق کے بغیر طریقے پر قابل تحقیق ہے.', 'uz': "Bu qog\xa0Ľoz ma\xa0ľlumot teoretik o'zgarishni aniqlash uchun metaphorik o'zgarishni aniqlash uchun o'ylab topadi, o'ylarini hypernymdan aniqlash uchun o'ylarini o'zgartirish uchun o'zgartiradi. Biz Olmoniyaga birinchi diakronisk sinov tizimini metaphorik o'zgartirishning andoza deb yaramiz. Bizning modelmiz saqlanmagan, tilning xovfsiz va boshqa semantik o'zgarishlar jarayonlariga umumiy bo'ladi.", 'vi': 'Tờ giấy này nghiên cứu về phương trình đo định lí thông tin để phát hiện sự thay đổi ẩn dụ, chuyển ý tưởng từ phát hiện siêu rung động sang nghiên cứu về sự thay đổi ngôn ngữ. Chúng tôi xây dựng một bộ thử nghiệm muối đầu tiên cho tiếng Đức như một tiêu chuẩn cho ghi chú thay đổi trừu tượng. Mẫu của chúng tôi không giám sát, độc lập ngôn ngữ và rộng rãi với các thủ tục biến đổi ngữ pháp khác.', 'bg': 'Тази статия изследва информационно-теоретичната мярка ентропия за откриване на метафорична промяна, прехвърляйки идеи от откриване на хиперними към изследване на езиковата промяна. Изграждаме първия диахроничен тест за немски език като стандарт за метафорична анотация на промяна. Нашият модел е без надзор, независим от езика и обобщаващ се за други процеси на семантична промяна.', 'hr': 'Ovaj papir istražuje entropiju informacija-teoretičke mjere za otkrivanje metaforskih promjena, prenošenje ideja iz detekcije hipernima na istraživanje o promjeni jezika. Napravili smo prvi diahronički test za njemačke kao standard za metaforske oznake za promjene. Naš model je neovisan, nezavisan jezik i generalizan na druge procese semantičke promjene.', 'nl': 'Dit artikel onderzoekt de informatie-theoretische meetentropie om metaforische veranderingen te detecteren, waarbij ideeën worden overgedragen van hyperniemdetectie naar onderzoek naar taalverandering. We bouwen de eerste diachrone testset voor Duits als standaard voor metaforische verandering annotatie. Ons model is zonder toezicht, taalonafhankelijk en veralgemeenschappelijk voor andere processen van semantische verandering.', 'da': 'Denne artikel udforsker informationsteoretisk entropi til at detektere metaforisk forandring, overføre ideer fra hypernymdetektion til forskning i sprogforandring. Vi bygger det første diakroniske testsæt for tysk som standard for metaforisk ændringsannotation. Vores model er uafhængig, sproguafhængig og generaliserbar til andre processer af semantisk forandring.', 'de': 'Dieser Beitrag untersucht das informationstheoretische Maß Entropie zur Erkennung metaphorischer Veränderungen und überträgt Ideen von der Hypernymdetektion auf die Erforschung von Sprachveränderungen. Wir bauen das erste diachrone Testset für Deutsch als Standard für metaphorische Änderungsannotierungen. Unser Modell ist unbeaufsichtigt, sprachunabhängig und verallgemeinerbar für andere Prozesse des semantischen Wandels.', 'id': 'Kertas ini mengeksplorasi entropi ukuran informasi-teori untuk mendeteksi perubahan metafora, memindahkan ide dari deteksi hipernim ke penelitian perubahan bahasa. Kami membangun tes diakronis pertama set untuk Jerman sebagai standar untuk anotasi perubahan metaforik. Model kita tidak diawasi, bebas dari bahasa dan dapat diseluruhkan ke proses lain perubahan semantis.', 'fa': 'این کاغذ انتروپی اندازه\u200cهای اطلاعات و نظریه\u200cای را برای شناسایی تغییرات متفافریک تحقیق می\u200cکند، و ایده\u200cها را از شناسایی hypernym به تحقیق در مورد تغییرات زبان انتقال می\u200cدهد. ما اولین امتحان دیاکرونیک برای آلمان را به عنوان استاندارد برای نشان دادن تغییر متفافریک ساختیم. مدل ما غیرقابل تحقیق، غیرقابل توجه به زبان و قابل توجه به فرایند دیگر تغییرات semantic است.', 'tr': 'Bu kagyz metaforik 체첵tgewini tanamak 체챌in informasi첵a-teori첵a 철l챌체si entropi첵any ke힊fet첵채r, hipernimi흫 deteksi첵asyndan dil 체첵tgewleri barada barlamak 체챌in pikirleri ge챌ir첵채r. Biz ilkinji diachronik testi nemes챌e 체챌in metaforik 체첵tgetmek 체챌in standartdyr. Bizi챰 nusgymyz semantik 체첵tgewlerde gar힊ymyz, dillerden gorpu힊syz we umumy d철wletlerde.', 'sq': 'Ky artikull eksploron entropinë e masës informacion-teorike për të zbuluar ndryshimin metaforik, duke transferuar idetë nga zbulimi i hipernimeve në kërkim mbi ndryshimin e gjuhës. Ne ndërtojmë testin e parë diakronik për gjermanin si një standard për anotacionin e ndryshimit metaforik. Modeli ynë nuk është i mbikqyrur, i pavarur nga gjuha dhe i gjeneralizuar ndaj proceseve të tjera të ndryshimeve semantike.', 'af': "Hierdie papier ondersoek die inligting- teorieese maat entropie om metaforiese veranderinge te vind, oordra idees van hypernyme-opdekking na ondersoek op taal verander. Ons bou die eerste diakronise toets stel vir Duits as 'n standaard vir metaforiese verander notasie. Ons model is ononderwerp, taal-onafhanklik en genereerbaar vir ander prosesse van semantiese verandering.", 'am': 'ይህ ፕሮግራም የመረጃ-theoretical measure ኤንተሮፕን ለመግለጽ የፎቶ ለውጥ ለማግኘት ይፈልጋል፤ አእምሮዎችን ከhypernym ግንኙነት ወደ ቋንቋ ለውጥ ለመፍጠር ይለውጣል፡፡ የጀርመን የመጀመሪያውን ዳሮክሮክ ፈተና ለመለወጥ ጥያቄ መሆኑን እናደርጋለን፡፡ Our model is unsupervised, language-independent and generalizable to other processes of semantic change.', 'hy': 'This paper explores the information-theoretic measure entropy to detect metaphoric change, transferring ideas from hypernym detection to research on language change.  Մենք կառուցում ենք գերմանացի համար առաջին դիաքրոնիկ փորձը որպես ստանդարտ փոխաբերական փոփոխության նկարագրման համար: Մեր մոդելը անվերահսկված է, անկախ լեզվից և ընդհանուր է սեմանտիկ փոփոխության այլ գործընթացների համար:', 'ko': '본고는 정보론의 엔트로피로 은유의 변화를 검출하고 초어 검출의 사상을 언어 변화에 대한 연구로 옮겼다.우리는 독일어를 위해 첫 번째 역대 시험집을 세워 은유 변화 주석의 표준으로 삼았다.우리의 모델은 감독이 없고 언어에 독립되며 다른 의미 변화 과정으로 확대될 수 있다.', 'bn': 'এই পত্রিকা তথ্য-থিওরিক পরিমাপ এন্ট্রোপি খুঁজে বের করে মেটোফোরিক পরিবর্তন সনাক্ত করার জন্য, হাইপারেনিম সনাক্তি থেকে চিন্তাগু আমরা জার্মানের জন্য প্রথম ডায়রোনিক পরীক্ষা বানাই মেটোফ্রিক পরিবর্তনের জন্য স্ট্যান্ডার হিসেবে। আমাদের মডেল সংরক্ষিত, ভাষা স্বাধীন এবং অন্যান্য সেমেন্টিক পরিবর্তনের প্রক্রিয়ায় সাধারণ।', 'az': 'Bu kağıt metaforik dəyişiklikləri keşfetmək üçün məlumat-teoriki ölçü entropisini keşfetir, fikirləri hipernim keşfetməsindən dil dəyişiklikləri barəsində araştırmağa göndərir. Biz Almanca üçün ilk diakronisk sınamayı metaforik dəyişiklik notlaması üçün standart olaraq inşa edirik. Bizim modellərimiz semantik dəyişikliklərin başqa proseslərə istifadə edilməz, dildən bağımsız və genel olaraq istifadə edilməz.', 'cs': 'Tento článek zkoumá informačně-teoretickou entropii pro detekci metaforických změn a přenáší myšlenky z detekce hypernymů na výzkum jazykové změny. Vytváříme první diachronický testovací set pro němčinu jako standard pro metaforickou anotaci změn. Náš model je bez dozoru, jazykově nezávislý a zobecňovatelný pro další procesy sémantické změny.', 'sw': 'Gazeti hili linagundua ujasiri wa upatikanaji wa taarifa kwa ajili ya kutambua mabadiliko ya mitazamo, na kuhamisha mawazo kutoka kwa utafiti wa lugha za upeo ili kutafiti mabadiliko ya lugha. Tunajenga jaribio la kwanza la kidiakronisa la Ujerumani kama kiwango cha mabadiliko ya mitazamo. Mfano wetu haujahifadhiwa, huru kwa lugha na unawezekana kwa mchakato mwingine wa mabadiliko ya kimapenzi.', 'bs': 'Ovaj papir istražuje entropiju informacija-teoretičke mjere kako bi se otkrila metaforska promjena, prebacila ideje iz detekcije hipernima na istraživanje o promjeni jezika. Napravili smo prvi diahronički test za njemačke kao standard za metaforske oznake za promjene. Naš model je neovisan, nezavisan jezik i generalizan za druge procese semantičke promjene.', 'et': 'Käesolevas töös uuritakse infoteoreetilist entroopiat metafoorsete muutuste tuvastamiseks, edastades ideed hüpernüümide tuvastamisest keele muutuse uurimisele. Me ehitame esimese saksa keele diakroonilise testikomplekti metafoorse muutuse annotatsiooni standardiks. Meie mudel on järelevalveta, keelesõltumatu ja muude semantiliste muutuste protsesside jaoks üldistatav.', 'fi': 'Tässä artikkelissa tarkastellaan informaatioteoreettista mittausentropiaa metaforisen muutoksen havaitsemiseksi, siirtämällä ideoita hypernyymien havaitsemisesta kielenmuutoksen tutkimukseen. Rakennamme ensimmäisen diakroonisen testisarjan saksalle metaforisen muutosmerkinnän standardiksi. Mallimme on valvomaton, kieliriippumaton ja yleistettävissä muille semanttisten muutosten prosesseille.', 'ca': "This paper explores the information-theoretic measure entropy to detect metaphoric change, transferring ideas from hypernym detection to research on language change.  Construim el primer conjunt de tests diacrònics per a l'alemany com a estàndard per anotar el canvi metàforic. El nostre model no és supervisat, independent del llenguatge i generalitzable a altres processos de canvi semàntic.", 'jv': 'Bino Awak dhéwé nggawe perusahaan diahron seneng nggawe alam kuwi padha padha kanggo ngerintakno metaphor. model sing gak nggawe ora bisa perusahaan, akeh-tenan lan gewujer-tenan kanggo ngerasai perusahaan sematik maneh.', 'ha': "Wannan karatun yana yin amfani da shirin haske-teoretisk ketopi dõmin ya gane musanyi na metaforiki, kuma ya motsar idãnun daga gane surori daga hisernym zuwa fitina kan canza harshe. Tunã samar da ta farkon jarrabo na diaron da aka daidaita wa Jamanya kamar wata kalma wa musanyawa na metaforiki. Ana tsare misalinmu, da ba'a cikin harshe ba kuma yana mai kyau zuwa wasu aikin mutane na mutane.", 'sk': 'Prispevek raziskuje entropijo informacijsko-teoretične meritve za odkrivanje metaforičnih sprememb in prenaša ideje iz zaznavanja hipernimov v raziskave sprememb jezika. Prvi diakronični testni komplet za nemščino zgradimo kot standard metaforičnega označevanja sprememb. Naš model je nenadzorovan, jezikovno neodvisen in posplošen za druge procese semantičnih sprememb.', 'he': 'העיתון הזה חוקר את אנטרופיה המידע-תיאורטי כדי לגלות שינוי מטאפורי, להעביר רעיונות מגילוי היפרנימים למחקר על שינוי שפה. אנחנו בונים את המבחן הדיאכרוני הראשון לגרמני כסטנדרט לשינוי מטאפורי. המודל שלנו הוא לא משגיח, עצמאי לשפה ולהגולל לתהליכים אחרים של שינוי סמנטי.', 'bo': 'This paper explores the information-theoretic measure entropy to detect metaphoric change, transferring ideas from hypernym detection to research on language change. ང་ཚོས་དབྱིན་ཡུལ་གྱི་བརྟག་ཞིབ་ལ་འཛུགས་བྱས་པའི་སྒེར་གྱི་རྣམ་པ་དང་མཉམ་དུ་བཏང་ཡོད། ང་ཚོའི་མ་དབྱིབས་ཕན་རིས་སྔོན་བསྡུར་མི་བྱེད་པར་མཐུན་པ་དང་སྐད་རིགས་སྟོན་པར་མེད་པར་མཐུན་གྱི་ལས་སྦྱོ'}
{'en': 'Multilingual Semantic Parsing And Code-Switching', 'ar': 'الاعراب الدلالي متعدد اللغات وتبديل الكود', 'pt': 'Análise semântica multilíngue e comutação de código', 'fr': 'Analyse sémantique multilingue et changement de code', 'es': 'Análisis semántico multilingüe y cambio de código', 'ja': '多言語セマンティック解析とコード切り替え', 'hi': 'बहुभाषी सिमेंटिक पार्सिंग और कोड-स्विचिंग', 'zh': '多语言义解析代码切换', 'ru': 'Многоязычный семантический синтаксический анализ и переключение кода', 'ga': 'Parsáil Shéimeantach Ilteangach agus Athrú Cóid', 'ka': 'მრავალენგიური Semantic Parsing & Code- Switching', 'hu': 'Többnyelvű szemantikus értelmezés és kódváltás', 'el': 'Πολυγλωσσική σημειακή ανάλυση και αλλαγή κώδικα', 'it': 'Analisi semantica multilingue e scambio di codici', 'lt': 'Daugiakalbis Semantinis analizavimas ir kodų keitimas', 'mk': 'Повеќејазично семантично анализирање и менување на кодови', 'kk': 'Көп тілді семантикалық талдау мен код ауыстыру', 'ms': 'Penghuraian Semantik Berbahasa dan Penukaran-Kod', 'ml': 'പല ഭാഷ സെമാന്റിക് പാര്\u200dസിങ്ങും കോഡ്- മാറ്റുന്നതും', 'mt': 'Il-Analiżi Semantika Multilingwi u l-Iskambju tal-Kodiċi', 'mn': 'Олон хэлний Semantic Parsing, Code-Switching', 'no': 'Fleirspråk semantisk tolking og kodbyting', 'pl': 'Wielojęzyczne parowanie semantyczne i przełączanie kodu', 'sr': 'Višejezički semantički razmatranje i prebacivanje kodova', 'ro': 'Interpretarea semantică multilingvă și schimbarea codurilor', 'si': 'ගොඩක් භාෂාවක් සාමාන්තික විශ්ලේෂණය සහ කෝඩ- ස්විච්චනය', 'so': 'Parsing and Code-Switching luuqado badan', 'sv': 'Flerspråkig semantisk tolkning och kodväxling', 'ta': 'பல மொழி பாடல் மற்றும் குறியீடு மாற்றுதல்', 'ur': 'Multilingual Semantic Parsing and Code-Switching', 'vi': 'Phát xít và chuyển hóa mã', 'uz': 'Name', 'bg': 'Многоезична семантична обработка и превключване на кодове', 'hr': 'Većina jezičkih semantičkih analiza i prebacivanja kodova', 'nl': 'Meertalige semantische parsing en code-switching', 'da': 'Flersproget semantisk fortolkning og kodeskift', 'de': 'Mehrsprachiges semantisches Parsing und Code-Switching', 'id': 'Pemindahan dan Penukaran Kode Semantik Berbahasa', 'ko': '다중 언어 의미 분석과 코드 변환', 'fa': 'بازجویی و تغییر رمز\u200cهای متعدد زبان', 'sw': 'Hifadhi ya lugha nyingi na kubadilishana kwa sheria', 'tr': 'Çoklu Diller Parlamak we Ködleme', 'sq': 'Analizimi dhe ndryshimi i kodeve me shumëgjuhë Semantike', 'af': 'Veelvuldige semantiese verwerking en kode- wisseling', 'am': 'Multilingual Semantic Parsing and Code-Switching', 'hy': 'Բազլեզու սեմատիկ վերլուծություն և կոդի փոխարեն', 'az': 'Çoxlu dil Semantik Parsing və Kod-Switching', 'bn': 'বহুভাষায় সেমান্টিক পার্সিং এবং কোড- পরিবর্তন', 'bs': 'Većina jezičkih semantičkih analiza i prebacivanja kodova', 'ca': 'Multilingual Semantic Parsing And Code-Switching', 'cs': 'Vícejazyčné sémantické parsování a přepínání kódu', 'et': 'Mitmekeelne semantiline parsimine ja koodivahetus', 'fi': 'Monikielinen semanttinen jäsentely ja koodinvaihto', 'jv': 'sematik sematik Tarjamahan lan kode-Ngubah', 'he': 'מערכת בדיקת סמנטית רבות ושינוי קודים', 'sk': 'Večjezično semantično razčlenjevanje in preklapljanje kod', 'ha': 'Multilingual Semantic Parsing And Code-Switching', 'bo': 'སྐད་རིགས་སྣ་མང་ཆེ་ཆུང་ལ་ཞིབ་བཤེར་དང་ཨང་རྟགས་བསྒྱུར་བཅོས་བྱེད་ཀྱི་ཡོད'}
{'en': 'Extending semantic parsing systems to new domains and languages is a highly expensive, time-consuming process, so making effective use of existing resources is critical. In this paper, we describe a transfer learning method using crosslingual word embeddings in a sequence-to-sequence model. On the NLmaps corpus, our approach achieves state-of-the-art accuracy of 85.7 % for English. Most importantly, we observed a consistent improvement for German compared with several baseline domain adaptation techniques. As a by-product of this approach, our models that are trained on a combination of English and German utterances perform reasonably well on code-switching utterances which contain a mixture of English and German, even though the training data does not contain any such. As far as we know, this is the first study of code-switching in semantic parsing. We manually constructed the set of code-switching test utterances for the NLmaps corpus and achieve 78.3 % accuracy on this dataset.', 'ar': 'يعد توسيع أنظمة التحليل الدلالي إلى مجالات ولغات جديدة عملية مكلفة للغاية وتستغرق وقتًا طويلاً ، لذا فإن الاستخدام الفعال للموارد الحالية أمر بالغ الأهمية. في هذا البحث ، نصف طريقة تعلم التحويل باستخدام تطعيمات الكلمات المتقاطعة في نموذج التسلسل إلى التسلسل. في مجموعة NLmaps ، يحقق نهجنا دقة متطورة تبلغ 85.7٪ للغة الإنجليزية. الأهم من ذلك ، لاحظنا تحسنًا ثابتًا في اللغة الألمانية مقارنة بالعديد من تقنيات تكييف المجال الأساسي. كنتيجة ثانوية لهذا النهج ، فإن نماذجنا التي تم تدريبها على مزيج من النطق باللغة الإنجليزية والألمانية تؤدي أداءً جيدًا بشكل معقول في نطق تبديل الشفرة التي تحتوي على مزيج من الإنجليزية والألمانية ، على الرغم من أن بيانات التدريب لا تحتوي على أي من هذه الكلمات. بقدر ما نعلم ، هذه هي الدراسة الأولى لتبديل الشفرة في التحليل الدلالي. أنشأنا يدويًا مجموعة كلمات اختبار تبديل الكود لمجموعة NLmaps وحققنا دقة بنسبة 78.3٪ في مجموعة البيانات هذه.', 'pt': 'Estender os sistemas de análise semântica para novos domínios e linguagens é um processo muito caro e demorado, portanto, fazer uso eficaz dos recursos existentes é fundamental. Neste artigo, descrevemos um método de aprendizagem por transferência usando embeddings de palavras em vários idiomas em um modelo de sequência a sequência. No corpus NLmaps, nossa abordagem atinge precisão de última geração de 85,7% para inglês. Mais importante ainda, observamos uma melhoria consistente para o alemão em comparação com várias técnicas de adaptação de domínio de linha de base. Como um subproduto dessa abordagem, nossos modelos que são treinados em uma combinação de enunciados em inglês e alemão funcionam razoavelmente bem em enunciados de troca de código que contêm uma mistura de inglês e alemão, mesmo que os dados de treinamento não contenham nenhum. Até onde sabemos, este é o primeiro estudo de troca de código na análise semântica. Construímos manualmente o conjunto de enunciados de teste de troca de código para o corpus NLmaps e alcançamos 78,3% de precisão neste conjunto de dados.', 'es': 'Extender los sistemas de análisis semántico a nuevos dominios e idiomas es un proceso muy costoso y lento, por lo que es fundamental hacer un uso eficaz de los recursos existentes. En este artículo, describimos un método de aprendizaje por transferencia que utiliza incrustaciones de palabras en varios idiomas en un modelo de secuencia a secuencia. En el corpus de NLMaps, nuestro enfoque logra una precisión de vanguardia del 85,7% para el inglés. Lo que es más importante, observamos una mejora constante para el alemán en comparación con varias técnicas de adaptación de dominios de referencia. Como subproducto de este enfoque, nuestros modelos que se entrenan en una combinación de enunciados en inglés y alemán funcionan razonablemente bien en enunciados de cambio de código que contienen una mezcla de inglés y alemán, aunque los datos de capacitación no contengan ninguno de ellos. Por lo que sabemos, este es el primer estudio de cambio de código en el análisis semántico. Construimos manualmente el conjunto de enunciados de prueba de cambio de código para el corpus de NLMAP y logramos una precisión del 78,3% en este conjunto de datos.', 'fr': "L'extension des systèmes d'analyse sémantique à de nouveaux domaines et langages est un processus très coûteux et fastidieux. Il est donc essentiel d'utiliser efficacement les ressources existantes. Dans cet article, nous décrivons une méthode d'apprentissage par transfert utilisant l'intégration de mots multilingues dans un modèle séquence à séquence. Sur le corpus NLMaps, notre approche atteint une précision de pointe de 85,7\xa0% pour l'anglais. Plus important encore, nous avons observé une amélioration constante pour l'allemand par rapport à plusieurs techniques d'adaptation de domaines de référence. Comme sous-produit de cette approche, nos modèles formés sur une combinaison d'énoncés en anglais et en allemand fonctionnent assez bien avec des énoncés à changement de code contenant un mélange d'anglais et d'allemand, même si les données de formation n'en contiennent pas. Pour autant que nous le sachions, il s'agit de la première étude sur la commutation de code dans l'analyse sémantique. Nous avons construit manuellement l'ensemble d'énoncés de test de commutation de code pour le corpus NLMaps et avons atteint une précision de 78,3\xa0% sur cet ensemble de données.", 'ja': 'セマンティック解析システムを新しいドメインや言語に拡張することは、非常に高価で時間がかかるプロセスであるため、既存のリソースを有効に活用することが重要です。本稿では，シーケンスツーシーケンスモデルにおけるクロスリンガルワード埋め込みを用いた転送学習法について述べる。NLmapsコーパスでは、私たちのアプローチは英語で85.7 ％の最先端の精度を達成します。最も重要なことに、我々は、いくつかのベースラインドメイン適応技術と比較して、ドイツ語の一貫した改善を観察した。このアプローチの副産物として、英語とドイツ語の発話の組み合わせでトレーニングされたモデルは、トレーニングデータにはそのようなものが含まれていないにもかかわらず、英語とドイツ語の混合物を含むコードスイッチング発話でかなり優れたパフォーマンスを発揮します。これはセマンティック構文解析におけるコードスイッチングの最初の研究ですNLmapsコーパスのコードスイッチングテスト発話のセットを手動で構築し、このデータセットで78.3 ％の精度を達成しました。', 'zh': '将语义解析系统扩到新的领域和语言是一个很昂贵且耗时的事情,因此有效用现在资源至重。 在本文中,我们述述了一种序列到序列模样中用跨语言词嵌入的迁学法。 在NLmaps语料库上,吾道至85.7%英语准确性。 最要者,与数基线应术相比,观德语之改进。 副产品者,英语德语之言也,英语德语之代码切换也,虽练数不包。 以吾所知,此语义解析之代码切换第一项也。 为 NLmaps 语料库手动构代码切换试语,于此数集上得 78.3% 准确率。', 'hi': 'नए डोमेन और भाषाओं के लिए शब्दार्थ पार्सिंग सिस्टम का विस्तार करना एक अत्यधिक महंगी, समय लेने वाली प्रक्रिया है, इसलिए मौजूदा संसाधनों का प्रभावी उपयोग करना महत्वपूर्ण है। इस पेपर में, हम एक अनुक्रम-से-अनुक्रम मॉडल में क्रॉसलिंगुअल शब्द एम्बेडिंग का उपयोग करके एक स्थानांतरण सीखने की विधि का वर्णन करते हैं। NLmaps कॉर्पस पर, हमारा दृष्टिकोण अंग्रेजी के लिए 85.7% की अत्याधुनिक सटीकता प्राप्त करता है। सबसे महत्वपूर्ण बात, हमने कई बेसलाइन डोमेन अनुकूलन तकनीकों की तुलना में जर्मन के लिए एक सुसंगत सुधार देखा। इस दृष्टिकोण के उप-उत्पाद के रूप में, अंग्रेजी और जर्मन उच्चारण के संयोजन पर प्रशिक्षित हमारे मॉडल कोड-स्विचिंग उच्चारण पर यथोचित रूप से अच्छी तरह से प्रदर्शन करते हैं जिसमें अंग्रेजी और जर्मन का मिश्रण होता है, भले ही प्रशिक्षण डेटा में ऐसा कोई भी शामिल न हो। जहां तक हम जानते हैं, यह शब्दार्थ पार्सिंग में कोड-स्विचिंग का पहला अध्ययन है। हमने मैन्युअल रूप से एनएलमैप्स कॉर्पस के लिए कोड-स्विचिंग परीक्षण उच्चारण के सेट का निर्माण किया और इस डेटासेट पर 78.3% सटीकता प्राप्त की।', 'ru': 'Распространение семантических систем синтаксического анализа на новые домены и языки является весьма дорогостоящим и трудоемким процессом, поэтому эффективное использование существующих ресурсов имеет решающее значение. В этой статье мы описываем метод обучения переносу с использованием вложений перекрестных слов в модели последовательность-последовательность. На корпусе NLmaps наш подход достигает самой современной точности 85,7% для английского языка. Самое главное, мы наблюдали постоянное улучшение для немецкого языка по сравнению с несколькими методами адаптации базовой области. В качестве побочного результата этого подхода наши модели, которые обучены комбинации английских и немецких высказываний, достаточно хорошо работают с кодовыми высказываниями, которые содержат смесь английского и немецкого языков, даже несмотря на то, что учебные данные не содержат таких. Насколько нам известно, это первое исследование переключения кода в семантическом синтаксическом разборе. Мы вручную построили набор тестовых фраз переключения кода для корпуса NLmaps и достигли 78,3% точности на этом наборе данных.', 'ga': 'Is próiseas an-chostasach, a thógann am, é córais parsála shéimeantacha a leathnú chuig fearainn agus teangacha nua, agus mar sin tá sé ríthábhachtach úsáid éifeachtach a bhaint as acmhainní atá ann cheana féin. Sa pháipéar seo, déanaimid cur síos ar mhodh foghlama aistrithe ag baint úsáide as leabaithe focal trasteangacha i múnla seicheamh go seicheamh. Ar chorpas NLmaps, baineann ár gcur chuige cruinneas den scoth 85.7% amach don Bhéarla. Níos tábhachtaí fós, thugamar faoi deara feabhas comhsheasmhach don Ghearmáinis i gcomparáid le roinnt teicníochtaí bonnlíne oiriúnaithe fearainn. Mar fhotháirge den chur chuige seo, feidhmíonn ár múnlaí atá oilte ar mheascán de chainteanna Béarla agus Gearmáinise go réasúnta maith ar chaint aistrithe cód ina bhfuil meascán de Bhéarla agus Gearmáinis, cé nach bhfuil a leithéid sna sonraí oiliúna. Chomh fada agus is eol dúinn, is é seo an chéad staidéar ar chómhalartú i bparsáil shéimeantach. Thógamar de láimh an tacar de chainteanna tástála um chóid-mhalartú don chorpas NLmaps agus bhaineamar amach cruinneas 78.3% ar an tacar sonraí seo.', 'el': 'Η επέκταση των συστημάτων σημασιολογικής ανάλυσης σε νέους τομείς και γλώσσες είναι μια εξαιρετικά δαπανηρή, χρονοβόρα διαδικασία, οπότε η αποτελεσματική χρήση των υφιστάμενων πόρων είναι κρίσιμη. Στην παρούσα εργασία, περιγράφουμε μια μέθοδο εκμάθησης μεταφοράς χρησιμοποιώντας εγκάρσια ενσωμάτωση λέξεων σε ένα μοντέλο ακολουθίας-ακολουθίας. Στο σώμα, η προσέγγισή μας επιτυγχάνει ακρίβεια αιχμής 85,7% για τα αγγλικά. Το πιο σημαντικό, παρατηρήσαμε μια συνεπή βελτίωση για τα γερμανικά σε σύγκριση με αρκετές τεχνικές προσαρμογής του τομέα βάσης. Ως υποπροϊόν αυτής της προσέγγισης, τα μοντέλα μας που εκπαιδεύονται σε συνδυασμό Αγγλικών και Γερμανικών προφορών αποδίδουν αρκετά καλά σε εκφράσεις αλλαγής κώδικα που περιέχουν μείγμα Αγγλικών και Γερμανικών, παρόλο που τα δεδομένα εκπαίδευσης δεν περιέχουν τέτοια. Από όσο γνωρίζουμε, αυτή είναι η πρώτη μελέτη αλλαγής κώδικα στη σημασιολογική ανάλυση. Κατασκευάσαμε χειροκίνητα το σύνολο των προφορών δοκιμής αλλαγής κώδικα για το σώμα και επιτυγχάνουμε 78,3% ακρίβεια σε αυτό το σύνολο δεδομένων.', 'hu': 'A szemantikai elemzési rendszerek új domainekre és nyelvekre történő kiterjesztése rendkívül drága és időigényes folyamat, így a meglévő erőforrások hatékony kihasználása kritikus. Ebben a tanulmányban egy transzfer tanulási módszert írunk le, amely keresztnyelvű szóbeágyazásokat használ egy szekvencia-szekvencia modellben. Az NLMaps korpuszon megközelítésünk 85,7%-os pontosságot ér el angol nyelven. A legfontosabb, hogy a német területen következetes javulást figyeltünk meg számos alapterület adaptációs technikával összehasonlítva. Ennek a megközelítésnek a mellékterméként az angol és német nyelvű kifejezések kombinációjára képzett modelleink ésszerűen jól teljesítenek az angol és német nyelvű kódváltó kifejezéseken, még akkor is, ha a képzési adatok nem tartalmaznak ilyet. Amennyire tudjuk, ez az első tanulmány a kódváltásról a szemantikai elemzésben. Kézzel készítettük el az NLMaps korpusz kódkapcsoló tesztkimondásainak készletét, és 78,3%-os pontosságot értünk el ezen adatkészleten.', 'ka': 'Semantic parsing systems to new domains and languages is a highly expensive, time-consuming process, so making effective use of existing resources is critical. ამ გვერდიში, ჩვენ განახსენებთ გასწავლების მეტი, რომელიც კრისილუგიური სიტყვების გამოყენება შემდეგ მოდელში. NLmaps corpus-ში, ჩვენი პროგრამის მიღება 85,7% ინგლისურად. უფრო მნიშვნელოვანია, ჩვენ დავხედავთ გერმანეთისთვის მუშაობელი კონფიგურაცია, რომელიც რამდენიმე ფექციური დემონის აკაპტიფიკაციის ჩვენი მოდელები, რომლებიც ინგლისური და გერმანური სიტყვების კომბიზაციის კომბიზაციისთვის გამოყენებულია, რომლებიც ინგლისური და გერმანური სიტყვების შემთხვევაში წარმოადგენებული კომბიზაციის შე ჩვენ ვიცით, ეს არის პირველი კოდის შეცვლის კოდენტიკური პარასტი. ჩვენ პირდაპირად შევქმნით კოდის შეცვლის ტესტის სიტყვა NLmaps corpus და მივიღეთ 78.3% მართლა ამ მონაცვლის კოდის.', 'it': "Estendere i sistemi di analisi semantica a nuovi domini e linguaggi è un processo molto costoso e richiede tempo, quindi utilizzare efficacemente le risorse esistenti è fondamentale. In questo articolo, descriviamo un metodo di apprendimento del trasferimento utilizzando incorporazioni di parole cross-lingual in un modello sequenza-sequenza. Sul corpus Nlmaps, il nostro approccio raggiunge una precisione all'avanguardia dell'85,7% per l'inglese. Soprattutto, abbiamo osservato un miglioramento costante per il tedesco rispetto a diverse tecniche di adattamento del dominio di base. Come sottoprodotto di questo approccio, i nostri modelli formati su una combinazione di parole inglesi e tedesche funzionano ragionevolmente bene su parole di scambio di codice che contengono una miscela di inglese e tedesco, anche se i dati di formazione non contengono tali. Per quanto ne sappiamo, questo è il primo studio del code-switching nell'analisi semantica. Abbiamo costruito manualmente l'insieme delle dichiarazioni di test di commutazione del codice per il corpus Nlmaps e ottenuto un'accuratezza del 78,3% su questo set di dati.", 'lt': 'Semantinių analizės sistemų išplėtimas naujoms sritims ir kalboms yra labai brangus ir ilgai trunkantis procesas, todėl labai svarbu veiksmingai panaudoti esamus išteklius. Šiame dokumente apibūdiname perkėlimo mokymosi metodą naudojant tarpkalbinius žodžių įtraukimus į sekos model į. Pagal NLmaps corpus mūsų požiūris anglų kalbos tikslumui siekia 85,7 %. Svarbiausia, kad pastebėjome nuoseklų Vokietijos pagerėjimą, palyginti su keliais pradiniais srities prisitaikymo metodais. Kaip šio metodo šalutinis produktas, mūsų modeliai, mokomi anglų ir vokiečių kalbų deriniu, veikia pakankamai gerai kodų keitimo išraiškose, kuriose yra anglų ir vokiečių mišinys, nors mokymo duomenys tokių nėra. Kiek žinome, tai pirmasis semantinio analizavimo kodų keitimo tyrimas. Mes rankiniu būdu sukūrėme NLmaps corpus kodų keitimo bandymų išraiškų rinkinį ir pasiekėme 78,3 % tikslumą šiame duomenų rinkinyje.', 'kk': 'Semantic parsing systems to new domains and languages is a very expensive, time consuming process, so making effective use of existing resources is critical. Бұл қағазда біз тілді тілді тілді ендіру үлгісімен аудару әдісін таңдаймыз. NLmaps корпусында біздің тәсіліміз ағылшын тілінде 85,7% деп тұрады. Ең маңызды, біз неміс үшін бірнеше негізгі домендің адаптациялау техникаларымен салыстырып тұратын жақсартылығын көрдік. Бұл жағдайдың түрінде ағылшын және неміс сөздерді біріктіру үлгілеріміз ағылшын және неміс сөздерінің біріктіру үлгілері ағылшын және неміс тіліктерінің арасындағы код ауысу сөздерінде дұрыс жақсы Біз білеміз, бұл semantic талдау үшін код ауыстыру алғашқы зерттеу. Біз NLmaps корпус үшін код ауыстыру сынақтарын қолмен құрып, бұл деректер жиынында 78,3% дұрыс жеткіздік.', 'mk': 'Проширувањето на семантичните системи за анализирање на новите домени и јазици е многу скап, временски процес, така што ефикасната употреба на постоечките ресурси е критична. Во оваа хартија, опишуваме метод на трансферентно учење користејќи крстојазични зборови вклучени во модел од секвенца до секвенца. На корпусот на НЛ-мапите, нашиот пристап постигнува најсовремена точност од 85,7 отсто за англиски. Најважно е дека набљудувавме константно подобрување за германците во споредба со неколку основни техники за адаптација на доменот. Како посебен производ од овој пристап, нашите модели кои се обучени на комбинација на англиски и германски изрази реално добро функционираат на изразите за промена на кодови кои содржат мешавина на англиски и германски, иако податоците за обука не содржат такви. Колку што знаеме, ова е првата студија за промена на кодови во семантичното анализирање. Ручно го изградивме сетот на тестови за промена на кодови за корпусот на NLmaps и постигнавме 78,3% точност на овој сет податоци.', 'ml': 'പുതിയ ഡോമെന്\u200dസിലേയ്ക്കും ഭാഷകളിലേക്കും സെമാന്റിക് പാര്\u200dസിങ്ങ് സിസ്റ്റമുകള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നത് വളരെ വിലപ്പെട്ടതും,  ഈ പത്രത്തില്\u200d, ക്രോസ്ലിങ്കുള്ള വാക്ക് ഉപയോഗിക്കുന്ന ഒരു മാറ്റം പഠിക്കുന്ന രീതിയില്\u200d ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. എംഎല്\u200dമാപ്പ് കോര്\u200dപ്പാസില്\u200d ഞങ്ങളുടെ സമ്പാദ്യം ഇംഗ്ലീഷില്\u200d 85. 7 ശതമാനത്തിന്റെ സ്ഥിതിയില്\u200d എത്തുന്നു. ഏറ്റവും പ്രധാനപ്പെട്ടതാണ്, ഞങ്ങള്\u200d ജര്\u200dമ്മനിന് ഒരു സ്ഥിരമായ മെച്ചപ്പെടുത്തിയിരുന്നു. കുറച്ച് ബേസ്ലൈന്\u200d ഡൊമെ ഈ പ്രവര്\u200dത്തനത്തിന്റെ ഉല്\u200dപാദിത്വത്താല്\u200d, ഇംഗ്ലീഷും ജര്\u200dമ്മന്\u200d വാക്കുകളുമായി പഠിപ്പിക്കപ്പെട്ട നമ്മുടെ മോഡലുകള്\u200d കോഡ് മാറ്റുന്ന വാക്കുകളില്\u200d നിര്\u200dണ്ണ നമുക്കറിയാം, ഇതാണ് സെമാന്റിക് പാര്\u200dജിങ്ങില്\u200d കോഡ് മാറ്റുന്നതിന്റെ ആദ്യ പഠനം. നമ്മള്\u200d കൈയ്യില്\u200d നിര്\u200dമ്മിക്കുന്ന കോഡ് മാറ്റുന്ന ടെസ്റ്റ് വാക്കുകള്\u200d നിര്\u200dമ്മിക്കുകയും ഈ ഡാറ്റാസെറ്റില്\u200d 78.3% കൃത്', 'ms': 'Meluaskan sistem penghuraian semantik ke domain dan bahasa baru adalah proses yang sangat mahal, memakan masa, jadi membuat penggunaan efektif sumber yang wujud adalah kritik. In this paper, we describe a transfer learning method using crosslingual word embeddings in a sequence-to-sequence model.  Pada korpus NLmaps, pendekatan kita mencapai ketepatan state-of-the-art 85.7% untuk bahasa Inggeris. Yang paling penting, kami memperhatikan peningkatan konsisten untuk Jerman dibandingkan dengan beberapa teknik penyesuaian domain asas. Sebagai produk sampingan pendekatan ini, model kita yang dilatih dalam kombinasi ungkapan bahasa Inggeris dan Jerman berjalan dengan baik pada ungkapan-tukar kod yang mengandungi campuran bahasa Inggeris dan Jerman, walaupun data latihan tidak mengandungi apa-apa seperti itu. Sejauh yang kita tahu, ini adalah kajian pertama untuk menukar kod dalam penghuraian semantik. Kami membangun secara manual set ucapan ujian pengtukaran kod untuk korpus NLmaps dan mencapai ketepatan 78.3% pada set data ini.', 'mt': 'L-estensjoni tas-sistemi tal-analiżijiet semantiċi għal dominji u lingwi ġodda hija proċess li jieħu ħafna ħin, u għalhekk huwa kruċjali li jsir użu effettiv tar-riżorsi eżistenti. F’dan id-dokument, a ħna niddeskrivu metodu ta’ tagħlim ta’ trasferiment bl-użu ta’ inkorporazzjonijiet ta’ kliem translingwi f’mudell ta’ sekwenza għal sekwenza. Fir-rigward tal-NLmaps corpus, l-approċċ tagħna jikseb preċiżjoni avvanzata ta’ 85.7% għall-Ingliż. L-aktar importanti, osservajna titjib konsistenti għall-Ġermaniż meta mqabbel ma’ diversi tekniki ta’ adattament tad-dominju fil-linja bażi. Bħala prodott sekondarju ta’ dan l-approċċ, il-mudelli tagħna li huma mħarrġa fuq kombinazzjoni ta’ dikjarazzjonijiet Ingliżi u Ġermaniżi jwettqu raġonevolment tajjeb fuq dikjarazzjonijiet ta’ skambju ta’ kodiċijiet li fihom taħlita ta’ Ingliż u Ġermaniż, anki jekk id-dejta ta’ taħriġ ma fiha l-ebda tali dikjarazzjoni. Sa fejn nafu, dan huwa l-ewwel studju dwar il-bidla tal-kodiċi fl-analiżi semantika. Inbnejna manwalment is-sett ta’ testijiet ta’ qlib tal-kodiċi għall-NLmaps corpus u kisbu preċiżjoni ta’ 78.3% fuq dan is-sett ta’ dejta.', 'pl': 'Rozszerzenie systemów parsowania semantycznego na nowe domeny i języki jest bardzo kosztownym, czasochłonnym procesem, dlatego skuteczne wykorzystanie istniejących zasobów ma kluczowe znaczenie. W niniejszym artykule opisano metodę uczenia się transferowego wykorzystującą osadzenia słów krzyżowych w modelu sekwencji-sekwencji. W korpusie NLMaps nasze podejście osiąga najnowocześniejszą dokładność 85,7% dla języka angielskiego. Co najważniejsze, obserwowaliśmy konsekwentną poprawę dla niemieckiego w porównaniu z kilkoma technikami adaptacji domen bazowych. Jako produkt uboczny tego podejścia nasze modele, które są przeszkolone na połączeniu wypowiedzi angielskiej i niemieckiej, sprawdzają się raczej dobrze w przypadku wypowiedzi przełączających kod, które zawierają mieszankę angielskiego i niemieckiego, nawet jeśli dane treningowe nie zawierają takich wypowiedzi. Z tego co wiemy, jest to pierwsze badanie przełączania kodu w parsowaniu semantycznym. Ręcznie skonstruowaliśmy zestaw wypowiedzi testowych przełączania kodu dla korpusu NLMaps i osiągnęliśmy dokładność 78,3% na tym zbiorze danych.', 'no': 'Utviding av semantiske tolkingssystemer til nye domene og språk er ein veldig dyppa, tidsforbrukingsprosess, slik at det gjer effektivt bruk av eksisterande ressursar er kritisk. I denne papiret beskriver vi ein læringsmetode for overføring ved å bruka krysspråk ordinnbygging i ein sekvens- til- sekvensmodell. På NLmaps-korpusen er tilnærminga vårt nådd nokså nøyaktighet på kunsten 85,7 % for engelsk. Det viktigste er at vi observerte ein konsistent forbedring for tysk sammenlignet med fleire baseline domeneadaptasjonssteknikk. Som eit etterprodukt av denne tilnærminga, våre modeller som er trengte på ein kombinasjon av engelsk og tysk uttaler utfører riktig godt ved å bytte ut tekstar som inneheld ein mixture av engelsk og tysk, selv om opplæringsdata inneheld ingen slik. Som vi vet, er dette den første studien for å byta kode i semantisk tolking. Vi konstruerte oppsettet av testbyteringsuttrykk for NLmaps corpus manuelt og oppnå 78,3% nøyaktighet på denne datasettet.', 'mn': 'Шинэ хэл болон хэл хүмүүст семантик хуваалцах системүүдийг нэмэгдүүлэх нь маш үнэтэй, цаг хугацааны хэрэглэх процесс юм. Тиймээс суурь нөөцийг ашиглах нь чухал. Энэ цаасан дээр бид хэлний хэлний нэвтрүүлэх үгийг дарааллаас дарааллаар дамжуулан суралцах аргыг тайлбарлаж байна. НЛ-газрын корпус дээр бидний арга хэмжээний хувьд Англи хэлний хувьд 85.7% тохиромжтой байдаг. Хамгийн чухал нь бид Германы хувьд хэдэн суурь шугамын адилтгалын технологийг харьцуулахад зөвхөн сайжруулагдсан. Энэ арга хэмжээний үр дүнд Англи болон Германы хэлэлцээнд сургалтын загварууд Англи болон Германы холбоотой холбоотой холбоотой код-шилжүүлэх хэлэлцээнд сайн ажилладаг. Бидний мэдэхээр, энэ бол семантийн хуваалцааны эхний судалгаа. Бид NLmaps корпус-ын код-өөрчлөлтийн шалгалтын хэлбэрүүдийг гараар бүтээсэн ба энэ өгөгдлийн хэлбэрээс 78.3% зөв байдал гаргасан.', 'ro': 'Extinderea sistemelor de analizare semantică la domenii și limbi noi este un proces foarte scump și consumator de timp, astfel încât utilizarea eficientă a resurselor existente este esențială. În această lucrare, descriem o metodă de învățare a transferului folosind încorporări de cuvinte încrucișate într-un model secvență-la-secvență. Pe corpul NLMaps, abordarea noastră atinge o acuratețe de ultimă oră de 85,7% pentru limba engleză. Cel mai important, am observat o îmbunătățire constantă pentru germană comparativ cu mai multe tehnici de adaptare a domeniului de bază. Ca rezultat secundar al acestei abordări, modelele noastre instruite pe o combinație de expresii în limba engleză și germană performează rezonabil de bine la expresiile de schimbare a codului care conțin un amestec de limba engleză și germană, chiar dacă datele de formare nu conțin astfel de expresii. Din câte știm, acesta este primul studiu al schimbării codurilor în analizarea semantică. Am construit manual setul de declarații de testare de comutare a codului pentru corpul NLMaps și am obținut o precizie de 78,3% pe acest set de date.', 'sr': 'Proširenje semantičkih analiza na nove domene i jezike je jako skup proces potrošenja vremena, tako da je važno upotrebu postojećih resursa. U ovom papiru opisujemo metodu učenja prijenosa korištenjem krstojezičkih rečenica u modelu sekvence do sekvence. Na korpusu NLmapa, naš pristup postiže tačnost države umjetnosti 85,7% za engleski. Najvažnije, posmatrali smo konsekventno poboljšanje za njemački u usporedbi sa nekoliko tehnika adaptacije područja domena. Kao proizvod ovog pristupa, naši modeli koji su obučeni na kombinaciji engleskih i njemačkih govora razumno dobro izvode na rečenicama prebacivanja koda koji sadrže mješavinu engleskog i njemačkog, iako podaci obuke ne sadrže takve. Koliko znamo, ovo je prva studija prebacivanja koda u semantičkom analizu. Ručno smo izgradili set testova za zamjenu koda za NLmaps korpus i ostvarili preciznost 78,3% na ovom setu podataka.', 'si': 'සෙමැන්ටික් විශ්ලේෂණ පද්ධතිය අළුත් ඩෝමේන් සහ භාෂාවට විශාලනය කරන්න බොහොම ගොඩක් විශාල, වෙලාව භාවිත ව මේ පත්තරේ අපි ප්\u200dරවේශනයක් විස්තර කරනවා ක්\u200dරියාභාෂික වචනය සම්බන්ධ කරනවා ක්\u200dරියාභාෂාත්මක වචනය සඳහා  NLmap කොර්පුස් වල, අපේ ප්\u200dරමාණය ඉංග්\u200dරීසි වලට 85.7% තියෙනවා. ගොඩක් වැදගත්, අපි ජර්මන් වලට සාමාන්\u200dය විස්තරයක් බලලා තියෙනවා ජර්මන් වලට පරීක්ෂණය විස්තර විස්ත මේ ප්\u200dරදේශයේ ප්\u200dරදේශයක් විදිහට, අපේ මොඩල් ඉංග්\u200dරීසි සහ ජර්මන් කියන්නේ සම්බන්ධ වෙනුවෙන් ඉංග්\u200dරීසි සහ ජර්මන් වලින් සම්බන්ධ වෙනුවෙන අපි දන්නවා වගේම, මේක තමයි පලවෙනි කෝඩ් වෙනස් කරන්නේ පළවෙනි අධ්\u200dයය. අපි අයිතියෙන් නිල්මැප්ස් කොර්පුස් වලින් කෝඩ් වෙනස් කරන්න පරීක්ෂණ කිරීමේ සූදානම් සැකසුම් කරලා මේ දත්ත සූදා', 'so': 'Sidaa darteed isticmaalka faa’iido leh ee isticmaalka rasmiga ah ee degmooyinka cusub iyo afafka cusub waa jardiino qaali ah oo aad u qaali ah, waqtiga la isticmaalayo waa muhiim. Qoraalkan waxaynu ku qornaa qaabka waxbarashada bedelka ah oo lagu isticmaalayo hadalka luqada ah oo ku qoran sameynta dib-u-xigta. Qoraxda NLmap, dhaqdhaqaalahayagu wuxuu gaadhaa saxda xaaladda farshaxanka ee afka Ingiriiska ku qoran 85.7 % oo saxda farshaxanka ah. Inta ugu muhiimsan, waxaynu aragnay hagaajinta Jarmalka oo la barbaro qalabka beddelinta ee gudaha hoose. Sida midowga qaababkan lagu soo bandhigi karo, modelalkayaga lagu baro luqadaha Ingiriis iyo Jarmalka ayaa si wanaagsan ugu sameeya hadallada beddelinta ee ku qoran isku xiran Ingiriis iyo Jarmalka, xataa xitaa macluumaadka waxbarashadu ma jirto wax la mid ah. Marka aynu ognahay, kanu waa waxbarashada ugu horeysa ee ku beddelaya baaritaanka semantiga. We manually constructed the set of code-switching test utterances for the NLmaps corpus and achieve 78.3% accuracy on this dataset.', 'sv': 'Utvidgning av semantiska tolkningssystem till nya domäner och språk är en mycket dyr och tidskrävande process, så att effektivt utnyttja befintliga resurser är avgörande. I denna uppsats beskriver vi en överföringsinlärningsmetod med hjälp av korspråkiga ordinbäddningar i en sekvens-till-sekvensmodell. På Nlmaps korpus uppnår vårt tillvägagångssätt toppmodern noggrannhet på 85,7% för engelska. Viktigast av allt observerade vi en konsekvent förbättring för tyska jämfört med flera baslinjedomänanpassningstekniker. Som en biprodukt av detta tillvägagångssätt presterar våra modeller som är utbildade på en kombination av engelska och tyska yttranden rimligt bra på kodväxling yttranden som innehåller en blandning av engelska och tyska, även om utbildningsdata inte innehåller något sådant. Såvitt vi vet är detta den första studien av kodväxling i semantisk tolkning. Vi konstruerade manuellt uppsättningen kodväxlande testyttranden för Nlmaps korpus och uppnådde 78,3% noggrannhet på denna dataset.', 'ur': 'سیمنٹی پارسینگ سیستموں کو نو ڈومین اور زبانوں میں پھیلانا بہت خرد ہے، زمان مصرف کرنے کی پروسس، تو موجود موجود منبعوں کا مصرف کرنا ضروری ہے. اس کاغذ میں ہم ایک ترنسفور سیکھنے کا طریقہ توصیف کرتے ہیں کرسٹ زبان کلمات کے مطابق مختلف سیکھنے کی مدل میں۔ NLmaps کورپوس پر، ہماری تقریبا انگلیسی کے لئے 85.7% کی سیدھی سیدھی موجود ہوتی ہے۔ ہم نے جرمن کے لئے بہت اہم باتیں دیکھی ہیں کہ بہت سی بنیس لین ڈومین ادامه تکنیک کے مقابلہ میں جرمن کے لئے ایک ثابت ترقی ہے۔ اس طریقے کی ایک بغیر تولید کے طور پر، ہمارے مدل جو انگلیسی اور جرمانی کلمات کی تعلیم پر آموزش کی جاتی ہیں، کوڈ-سوچینگ کلمات پر قابل اچھی طرح عمل کرتے ہیں جو انگلیسی اور جرمانی کی ملکیت میں ہے، اگرچہ تربینگ ڈیٹے ایسے نہیں ہیں۔ ہم جانتے ہیں کہ یہ سب سے پہلے کی مطالعہ ہے کہ سیمنٹی پارسینگ میں کوڈ-سوچ کرنے کی۔ ہم نے NLmaps کورپوس کے لئے کوڈ-سوچینگ ٹیسٹ کی سٹ بنائی اور اس ڈیٹ سٹ پر 78.3% دقیق حاصل کیا۔', 'ta': 'புதிய களங்களுக்கும் மொழிகளுக்கும் அரைப்பெண்டிக் பாசிங் அமைப்புகளை நீட்டுதல் மிகவும் விலையானது, நேரம் பயன்படுத்தும் செயல்கள இந்த காகிதத்தில், நாம் ஒரு மாற்று கற்றல் முறையை விவரிக்கிறோம் முறைமையை குறுக்கும் மொழியில் உள்ள மாற்று வரிசையில் இரு NLவரைப்படங்கள் கார்ப்ஸ் மீது, எங்கள் அணுகும் செயல்பாடு ஆங்கிலத்திற்கு 85.7% சரியான நிலையை பெறுகிறது. மிகவும் முக்கியமாக, நாங்கள் ஜெர்மனின் முன்னேற்றத்தை பார்த்தோம் பல அடிப்படைக்கோடு டோமைன் ஒப்பீட்டு தொழி இந்த செயல்பாட்டின் பொருளால் பயிற்சி செய்யப்பட்ட எங்கள் மாதிரிகள், ஆங்கிலத்தில் மற்றும் ஜெர்மன் வார்த்தைகள் ஒன்றில் பயிற்சி செய்யப்பட்டுள்ளது குறிமுறை நாங்கள் தெரியும் வரை, இது பெம்மான்டிக் பாசிங்கில் குறிமுறைமாற்றம் முதல் படிப்பாகும். நாங்கள் NLவரிப்படங்களுக்கான குறிமுறை மாற்றும் சோதனை சொல்லை அமைப்பை கைமுறைமுறைமையாக உருவாக்கி இந்த தரவுத்தளத்தின் சரிய', 'uz': "Name In this paper, we describe a transfer learning method using crosslingual word embeddings in a sequence-to-sequence model.  NLmaplar corpusida, bizning qismimiz ingliz tilida 85.7% haqida ishlab chiqaradi. Ko'pchilik muhim, biz ko'pchilik bir necha baseline domen adaptation techniquesi ko'paytirish uchun Olmoniyaga davomida muvaffaqiyatlarni ko'rdik. Bu usulning natijasi sifatida o'rganish modellarimiz Ingliz va Olmon so'zlari birlashtirish uchun o'rganilgan so'zlarni o'rganadi. Ingliz va Olmonchaga bir qanday taʼminlovchi maʼlumot mavjud emas. Biz bilsangiz, bu semantik parsing uchun kodlash orqali birinchi o'qituvchi. Biz NLmap corpuslari uchun kodlash tugmalarini qoʻlbola aytdik va bu maʼlumotlar sohasida 78.3% tasdiqlanishni yetdik.", 'vi': 'Việc mở rộng hệ thống phân tích theo ngữ pháp cho những miền và ngôn ngữ mới là một quá trình tốn thời gian rất đắt tiền, vì vậy việc sử dụng nguồn lực đã có là rất quan trọng. Trong tờ giấy này, chúng tôi mô tả phương pháp học chuyển nhượng sử dụng việc ghép chữ chéo trong mô hình dãy-tới-dãy. Trên tập đoàn NLmaps, trình độ chính xác cao nhất của 85.7.7. đối với tiếng Anh. Quan trọng nhất, chúng tôi thấy một tiến bộ nhất đối với Đức so với nhiều kỹ thuật sửa chữa miền cơ sở. Theo cách tiếp cận này, các mẫu được đào tạo dựa trên một sự kết hợp giữa tiếng Anh và Đức hoàn thành tốt với những từ ngữ chuyển đổi mã mà chứa một hỗn hợp giữa Anh và Đức, mặc dù các dữ liệu về huấn luyện không chứa những từ đó. Theo như chúng ta biết, đây là nghiên cứu đầu tiên về việc chuyển đổi mã theo ngữ pháp. Chúng tôi tự ráp các giọng kiểm tra chuyển đổi mã cho tập đoàn NILmaps và đạt độ chính xác 78.3. trên tập tin này.', 'bg': 'Разширяването на системите за семантичен анализ до нови домейни и езици е много скъп и отнемащ време процес, така че ефективното използване на съществуващите ресурси е от решаващо значение. В настоящата статия е описан метод на трансферно обучение, използващ многоезични вграждания на думи в модел последователност към последователност. В корпуса нашият подход постига най-съвременна точност от 85,7% за английски език. Най-важното е, че наблюдаваме последователно подобрение при немски език в сравнение с няколко базови техники за адаптация на домейна. Като страничен продукт на този подход нашите модели, обучени по комбинация от английски и немски изказвания, се представят сравнително добре при изказвания за превключване на код, които съдържат смесица от английски и немски, въпреки че данните за обучение не съдържат такива. Доколкото знаем, това е първото изследване на кодовото превключване в семантичен анализ. Ръчно конструирахме набор от тестови изказвания за превключване на кода за корпуса и постигнахме 78,3% точност на този набор от данни.', 'da': 'Udvidelse af semantiske analysesystemer til nye domæner og sprog er en meget dyr og tidskrævende proces, så det er afgørende at gøre effektiv brug af eksisterende ressourcer. I denne artikel beskriver vi en transfer learning metode ved hjælp af tværsprogede ordindlejringer i en sekvens-til-sekvens model. På NLMaps korpus opnår vores tilgang topmoderne nøjagtighed på 85,7% for engelsk. Vigtigst af alt observerede vi en konsekvent forbedring for tysk sammenlignet med flere basisdomæneteknikker. Som et biprodukt af denne fremgangsmåde fungerer vores modeller, der er trænet i en kombination af engelsk og tysk udtalelser, rimeligt godt på kodeskift udtalelser, der indeholder en blanding af engelsk og tysk, selv om træningsdataene ikke indeholder noget sådant. Så vidt vi ved, er dette den første undersøgelse af kodeskift i semantisk parsing. Vi konstruerede manuelt sættet af kodeskift testudtalelser til Nlmaps korpus og opnår 78,3% nøjagtighed på dette datasæt.', 'nl': 'Het uitbreiden van semantische parsing systemen naar nieuwe domeinen en talen is een zeer duur en tijdrovend proces, dus effectief gebruik maken van bestaande bronnen is cruciaal. In dit artikel beschrijven we een transfer learning methode met behulp van crosslingual word embeddings in een sequence-to-sequence model. Op het NLmaps corpus bereikt onze aanpak state-of-the-art nauwkeurigheid van 85,7% voor Engels. Het belangrijkste is dat we een consistente verbetering waargenomen hebben voor Duits in vergelijking met verschillende basislijndomeinadaptatietechnieken. Als bijproduct van deze aanpak presteren onze modellen die zijn getraind op een combinatie van Engelse en Duitse uitingen redelijk goed op code-switching uitingen die een mix van Engels en Duits bevatten, hoewel de trainingsgegevens geen dergelijke bevatten. Voor zover we weten is dit de eerste studie van code-switching in semantische parsing. We hebben handmatig de set code-switching testuitingen voor het NLmaps corpus geconstrueerd en bereikt 78,3% nauwkeurigheid op deze dataset.', 'id': 'Meluaskan sistem penghuraian semantis ke domain dan bahasa baru adalah proses yang sangat mahal, memakan waktu, sehingga membuat penggunaan efektif sumber daya yang ada adalah kritis. Dalam kertas ini, kami menggambarkan metode belajar transfer menggunakan pembangunan kata saling bahasa dalam model urutan-ke-urutan. Pada NLmaps corpus, pendekatan kita mencapai akurasi state-of-the-art 85,7% untuk bahasa Inggris. Yang paling penting, kami memperhatikan peningkatan konsisten untuk Jerman dibandingkan dengan beberapa teknik pengadaptasi domain dasar. Sebagai produk sampingan pendekatan ini, model kami yang dilatih dalam kombinasi dari ucapan Inggris dan Jerman berjalan cukup baik pada ucapan-mengubah kode yang mengandung campuran bahasa Inggris dan Jerman, meskipun data pelatihan tidak mengandung apapun seperti itu. Sejauh yang kita ketahui, ini adalah penelitian pertama untuk mengubah kode dalam pemeriksaan semantis. Kami membangun secara manual set ujian penggantian kode untuk NLmaps corpus dan mencapai akurasi 78,3% pada dataset ini.', 'de': 'Die Erweiterung von semantischen Parsing-Systemen auf neue Domänen und Sprachen ist ein sehr kostspieliger und zeitaufwändiger Prozess, daher ist die effektive Nutzung vorhandener Ressourcen entscheidend. In diesem Beitrag beschreiben wir eine Transferlernmethode mit Hilfe von crosslingualen Worteinbettungen in einem Sequenz-zu-Sequenz-Modell. Auf dem NLmaps-Korpus erreicht unser Ansatz eine Genauigkeit von 85,7% auf dem neuesten Stand der Technik für Englisch. Am wichtigsten ist, dass wir eine konsistente Verbesserung für Deutsch im Vergleich zu mehreren Basisdomänenanpassungstechniken beobachten konnten. Als Nebenprodukt dieses Ansatzes sind unsere Modelle, die auf einer Kombination von englischen und deutschen Äußerungen trainiert sind, bei Code-Switching-Äußerungen, die eine Mischung aus Englisch und Deutsch enthalten, relativ gut, obwohl die Trainingsdaten keine solche enthalten. Soweit wir wissen, ist dies die erste Studie über Code-Switching im semantischen Parsing. Wir haben den Satz von Code-Switching Test Äußerungen für das NLmaps Korpus manuell konstruiert und erreichen 78,3% Genauigkeit auf diesem Datensatz.', 'hr': 'Proširenje semantičkih analiza na nove domene i jezike je jako skup proces potrošenja vremena, tako da je kritično učinkovito iskoristiti postojeće resurse. U ovom papiru opisujemo metodu učenja prijenosa koristeći krstojezičke riječi ugrađenje u modelu sekvence do sekvence. Na korpusu NLmapa, naš pristup postiže tačnost države umjetnosti 85,7% za engleski. Najvažnije, primijetili smo konsekventno poboljšanje za njemački u usporedbi s nekoliko tehnika prilagodbe područja. Kao proizvod ovog pristupa, naši modeli koji su obučeni na kombinaciji engleskih i njemačkih govora razumno dobro izvršavaju govore koje sadrže mješavinu engleskog i njemačkog, iako podaci obuke ne sadrže takve. Koliko znamo, ovo je prvo ispitivanje zamjene kod u semantičkom analizu. Ručno smo izgradili setu testova za promjenu koda za NLmaps corpus i ostvarili preciznost 78,3% na ovom setu podataka.', 'sw': 'Extending semantic parsing systems to new domains and languages is a highly expensive, time-consuming process, so making effective use of existing resources is critical.  Katika karatasi hii, tunaelezea njia ya kujifunza kwa kutumia maneno ya lugha yanayoingia katika mfumo wa mfululizo. Katika mashindano ya NLmap, mbinu yetu inafikia hali ya sahihi ya sanaa kwa asilimia 85.7 kwa Kiingereza. Kimuhimu zaidi, tulishuhudia kuboreshwa kwa Ujerumani ukilinganishwa na mbinu kadhaa za kubadilisha ndani ya msingi. Kama uzalishaji wa mbinu hii, mifano yetu ambayo inafundishwa kwa muunganiko wa lugha za Kiingereza na Ujerumani hufanya kazi vizuri kwa maneno ya kubadilisha kodi ambayo ina mchanganyiko wa Kiingereza na Kijerumani, ingawa taarifa za mafunzo hazina taarifa yoyote kama hayo. Kwa kadri tunavyojua, hii ni utafiti wa kwanza wa kubadilisha kodi katika mabadiliko ya mabadiliko ya kimapenzi. Tumejenga seti ya maneno ya kupiga kuratibu jaribio kwa ajili ya mashindano ya NLmap na kupata asilimia 78.3 sahihi katika seti hii ya taarifa.', 'fa': 'گسترش سیستم\u200cهای تقسیم semantic به دامنهای جدید و زبان\u200cها یک فرایند بسیار گرون و مصرف زمان است، بنابراین استفاده از منابع موجود موجود موجود به عنوان ضروری است. در این کاغذ، ما روش یادگیری انتقال را با استفاده از عبارت کلمه\u200cهای متوسط زبان توصیف می\u200cکنیم. روی کورپوس NLmaps، دستور ما دقیقات هنری 85.7 درصد برای انگلیسی به دست می آید. مهمترین است که ما یک بهترین توسعه برای آلمان را در مقایسه با چند تکنیک تغییر سازی دومین بنیادی مشاهده کردیم. به عنوان یک تولید از این روش، مدلهای ما که در ترکیب زبان انگلیسی و آلمانی آموزش یافته\u200cاند، به طور منطقی در کلمات تغییر قانونی که شامل ترکیب انگلیسی و آلمانی است، انجام می\u200cدهند، با وجود اینکه داده\u200cهای آموزش هیچ\u200cگونه\u200cای ندارد. تا جایی که ما می دانیم، این اولین مطالعه تغییر کد در تجزیه شناسایی است. ما مجموعه کلمات تغییر کد تغییر آزمایش برای کورپوس NLmaps را به دست ساختیم و دقیق 78.3% در این مجموعه داده را به دست آوردیم.', 'tr': 'Semantik analyz sistemlerini täze sahypa we dillere eklemek üçin örän gymmat, wagt tüketmeli prosesdir. Bu üçin meýdançalaryň ullanyşyny täsirli däldir. Bu kagyzda, biz çatlaş dillerden at sany nusgasynda terjime etmek üçin bir terjime öwrenmek yöntemi tassyýarys NLmaplar korpusynda, biziň ýaryşymyz iňlisçe 85.7% degişligi ýetip barýar. Iň wajyp bolsa, biz nemes üçin birnäçe baseline domeniň adaptasy teknikleri bilen görä düzgün gelişmeleri gözledik. Bu ýagdaýyň köpüsi bolan nusgalarymyz iňlisçe we Alman dilinde bilim alýan nusgalarymyz beýleki şekilde gowy çykarýar. Bilýänimiz şu ýagdaýda, semantik aýlamanyň ilkinji köd üýtgetmeginiň öwrenmesi. Biz NLmaps korpusu üçin köd almak çözümlerini elimizden inşa etdik we bu veri setinde 78.3% dogry tapdyk.', 'ko': '의미 분석 시스템을 새로운 분야와 언어로 확장하는 것은 매우 비싸고 시간이 소모되는 과정이기 때문에 기존 자원을 효과적으로 이용하는 것이 중요하다.본고에서 우리는 서열에서 서열 모델까지 다중 언어 단어를 삽입하는 이동 학습 방법을 묘사했다.NLmaps 자료 라이브러리에서 우리의 방법은 영어의 85.7%의 최신 정확도를 실현하였다.가장 중요한 것은 기선 기술과 일치하는 몇 가지 개선을 관찰했다는 것이다.이런 방법의 부산물로서 우리의 모델은 영어와 독일어가 결합된 상황에서 훈련을 하는데 영어와 독일어 혼합어를 포함하는 코드 변환 언어에서 상당히 잘 나타난다. 비록 훈련 데이터에 이런 정보가 포함되지 않지만.의미 분석에서의 코드 변환을 연구한 것은 이번이 처음인 것으로 알려졌다.우리는 NLmaps 자료 라이브러리를 위해 코드 변환 테스트 문장을 수동으로 구축했고 이 데이터 집합에서 78.3%의 정확도를 실현했다.', 'sq': 'Extending semantic parsing systems to new domains and languages is a highly expensive, time-consuming process, so making effective use of existing resources is critical.  Në këtë letër, ne përshkruajmë një metodë mësimi transferimi duke përdorur përmbajtje fjalësh ndërgjuhësore në një model sekuencë-në-sekuencë. Në NLmaps corpus, metoda jonë arrin saktësinë e lartë të 85.7% për anglishtin. Më e rëndësishmja, kemi vëzhguar një përmirësim konsistent për gjermanin krahasuar me disa teknika bazë të përshtatjes në domeni. Si një produkt i këtij qasje, modelet tona që janë trajnuar në një kombinim të shprehjeve angleze dhe gjermane funksionojnë mjaft mirë në shprehjet e ndërrimit të kodeve që përmbajnë një përzierje angleze dhe gjermane, edhe pse të dhënat e trajnimit nuk përmbajnë asnjë të tillë. Për sa e dimë, ky është studimi i parë i ndërrimit të kodeve në analizimin semantik. Ne ndërtuam manualisht settin e testimeve të ndërtimit të kodeve për NLmaps corpus dhe arritëm 78.3% saktësi në këtë set të dhënash.', 'am': 'የአዲስ ውይይቶች እና ቋንቋዎች ላይ የsemantic ማዘጋጀት ስርዓት መጨመር እጅግ የከበረ፣ የጊዜው መጠቀሚያ ፕሮግራም ነው፡፡ በዚህ ፕሮግራም፣ የድምፅ ቋንቋ ቃላትን በመጠቀም የስርዓት-ወደ-ስርዓት ሞዴል እናሳውቃለን፡፡ በNLmap ካርፓስ፣ የግንኙነታችን ግንኙነት የዓላማ ግንኙነት 85.7 በመቶ እንግሊዘኛ ነው፡፡ አብዛኛውም አስፈላጊ፣ የጀርመን አካባቢ የዶሜን አካባቢ ቴክኖጂ በተደረገ የውይይት አካባቢ ማድረግ አየን፡፡ እንደዚህ ሥርዓት አካባቢ፣ እንግሊዘኛ እና የጀርመን ቃላት በተጠቃሚ እና በኮድ-ለውጥ ቃላት በሚያስተምሩ ሞዴላዎቻችን በአስተናክል እና የኢንዝርመን እና የጀርመን ቋንቋ በተለወጠው እና የኢንዝርመን እና የግንኙነት ቋንቋ እንዲያካክሉ ይደረጋሉ፡፡ As far as we know, this is the first study of code-switching in semantic parsing.  የNLmap ካርፓስ የኮድ ቃላትን አካባቢ እና በዚህ ዳታ ላይ 78.3 በመቶ እርግጠኛ አግኝተናል፡፡', 'hy': 'Սեմանտիկ վերլուծության համակարգերի տարածումը նոր բնագավառների և լեզուների համար շատ թանկ, ժամանակ պահանջող գործընթաց է, ուստի գոյություն ունեցող ռեսուրսների արդյունավետ օգտագործումը կարևոր է: Այս թղթի մեջ մենք նկարագրում ենք փոխանցման ուսումնական մեթոդը, օգտագործելով փոխլեզվով բառերի ներառումներ հաջորդականության մոդելի մեջ: ՆԼԿ-ի քարտեզի կորպոսի վրա մեր մոտեցումը հասնում է անգլերենի 85.7 տոկոսի ամենաբարձր ճշգրտության: Ամենակարևորը, մենք նկատեցինք գերմանացիների համար համեմատական զարգացում, համեմատած որոշ հիմնական բնագավառի ադապտացիոն տեխնիկաների հետ: Որպես այս մոտեցության կողմնակի արդյունք, մեր մոդելները, որոնք վարժեցված են անգլերեն և գերմանացի արտահայտությունների համադրման վրա, բավականին լավ են աշխատում կոդի փոխելու արտահայտությունների վրա, որոնք պարունակում են անգլերեն և գերմանացի խառնուրդ, չնայած որ վարժեց Ինչքան գիտենք, սա կոդի փոխման առաջին ուսումնասիրությունն է սեմանտիկ վերլուծության մեջ: Մենք ձեռքով կառուցեցինք կոդի փոխման փորձարկման արտահայտությունները ՆԼԿ քարտեզի կորպոսի համար և ստացանք 78.3 տոկոսի ճշգրտություն այս տվյալների համակարգում:', 'bn': 'নতুন ডোমেন এবং ভাষায় সেমেন্টিক পার্সিং সিস্টেম বাড়ানো হচ্ছে একটি বেশ দামী, সময়-ভক্তি প্রক্রিয়া, তাই বিদ্যমান সম্পদের কার্যকর ব্ এই কাগজটিতে আমরা একটি ট্রান্সফার্নারের শিক্ষার পদ্ধতি বর্ণনা করি যা ক্রস্লিঙ্গুয়াল শব্দ ব্যবহার করে একটি সেকেন্স-থেকে সেকে এনএলম্যাপের কোর্পাসে আমাদের প্রতিযোগিতা ইংরেজীর জন্য ৮৫. ৭% রাষ্ট্রের সঠিকভাবে পৌঁছায়। সবচেয়ে গুরুত্বপূর্ণ, আমরা জার্মানের জন্য এক স্থায়ী উন্নতি দেখেছি বেশ কয়েকটি বেসাইলাইন ডোমেইন আপেটশন কৌশলের তুলনা এই পদক্ষেপের একটি প্রযুক্তি হিসেবে আমাদের মডেল যা ইংরেজী এবং জার্মান ভাষার সাথে একত্রিত ভাষায় প্রশিক্ষণ প্রদান করা হয়েছে তারা কোড পরিবর্তনের কথাগুলোর ব্যাপার আমাদের জানা যায়, এটাই সেমেন্টিক পার্গিং-এ কোড পরিবর্তনের প্রথম গবেষণা। এনএলম্যাপ কোর্পাসের জন্য কোড পরীক্ষা বাক্যের সেট নির্মাণ করেছি এবং এই ডাটাসেটে ৭৮.৩% সঠিকভাবে পৌঁছেছি।', 'bs': 'Proširenje semantičkih analiza na nove domene i jezike je vrlo skup proces potrošenja vremena, tako da je kritično učinkovito iskoristiti postojeće resurse. U ovom papiru opisujemo metodu učenja prijenosa korištenjem krstojezičkih rečenica u modelu sekvence do sekvence. Na korpusu NLmapa, naš pristup postiže tačnost države umjetnosti 85,7% za engleski. Najvažnije, posmatrali smo konsekventno poboljšanje za njemački u usporedbi s nekoliko tehnika adaptacije područja domena. Kao proizvod ovog pristupa, naši modeli koji su obučeni na kombinaciji engleskih i njemačkih govora razumno dobro obavljaju govore o prebacivanju koda koji sadrže mješavinu engleskog i njemačkog, iako podaci o obuci ne sadrže takve. Koliko znamo, ovo je prva studija prebacivanja koda u semantičkom analizu. Ručno smo izgradili set testova za promjenu koda za NLmaps corpus i ostvarili preciznost 78,3% na ovom setu podataka.', 'az': 'Semantik ayırma sistemlərini yeni domenalara və dillərə genişləndirmək çox pahalı, vaxtlı istifadə etmə prosesidir, bu yüzden mövcud resursların istifadəsi mövcuddur. Bu kağızda, bir transfer öyrənmə metodlarını seçmə-seçmə modeli ilə çox dilli sözləri ilə istifadə edirik. NLmaps corpusunda, bizim tərəfimiz İngilizce üçün 85,7%-in müəyyən edilməsi üçün istifadə edər. Ən çox mövcuddur, biz Almanca üçün çoxlu baseline domenin uyğunlaşdırma teknikləri ilə müəyyən edilən düzəltməyi gördük. Bu tərzimin təhsil olaraq, İngilis və Alman sözlərinin birləşdirilməsində təhsil edilən modellərimiz İngilis və Alman dillərinin karışığı barəsində çox yaxşı işlər görür, çünki təhsil məlumatların heç bir şey yoxdur. Bildiyimiz kadarıyla, bu, semantik ayırışında kodu değiştirmək ilk təhsil idi. Biz NLmaps korpusu üçün kodu-dəyişiklik test sözlərinin qurulduğu və bu veri qutusunda 78.3%-in doğruluğuna nail olduq.', 'ca': "L'ampliació dels sistemes d'analització semàntica a nous dominis i llengües és un procés molt costós i costant temps, així que utilitzar eficaçment els recursos existents és crític. En aquest paper, descrivim un mètode d'aprenentatge de transfer ència utilitzant integracions de paraules translingües en un model de seqüència a seqüència. En el corpus de NLmaps, el nostre enfocament aconsegueix una precisió d'última generació del 85,7% en anglès. El més important és que vam observar una millora consistent en alemanya comparada amb diverses tècniques basales d'adaptació al domini. Com a subproducte d'aquest enfocament, els nostres models entrenats en una combinació d'expressions anglesa i alemanya actuen raonablement bé en expressions de canvi de codi que contenen una combinació d'anglès i alemany, encara que les dades d'entrenament no contenen cap d'aquestes. Per tant que sabem, aquest és el primer estudi de canvi de codi en l'analització semàntica. Vam construir manualment el conjunt de proves de canvi de codi per al corpus NLmaps i aconseguir una precisió del 78,3% en aquest conjunt de dades.", 'cs': 'Rozšíření sémantických parsovacích systémů na nové domény a jazyky je velmi nákladný a časově náročný proces, takže efektivní využití stávajících zdrojů je důležité. V tomto článku popisujeme metodu transferového učení využívající vkládání křížových slov do sekvenčního modelu. V korpusu NLMaps dosahuje náš přístup nejmodernější přesnosti 85,7% pro angličtinu. Nejdůležitější je, že jsme pozorovali konzistentní zlepšení u německé společnosti ve srovnání s několika metodami adaptace domény. Jako vedlejší produkt tohoto přístupu fungují naše modely, které jsou trénovány na kombinaci anglických a německých výroků, přiměřeně dobře u výroků přepínajících kód, které obsahují směs angličtiny a němčiny, i když tréninková data žádné takové neobsahují. Pokud víme, je to první studie přepínání kódu v sémantickém parsování. Ručně jsme sestavili sadu testovacích výroků pro korpus NLMaps a dosáhli přesnosti 78,3% na této datové sadě.', 'et': 'Semantiliste parsimissüsteemide laiendamine uutele domeenidele ja keeltele on väga kallis ja aeganõudev protsess, mistõttu on olemasolevate ressursside tõhus kasutamine kriitilise tähtsusega. Käesolevas töös kirjeldame siirdeõppe meetodit, kasutades ristkeelseid sõnade manustamist jadast järjestusse mudelis. NLMaps korpuse puhul saavutab meie lähenemine inglise keele puhul kaasaegse täpsuse 85,7%. Kõige olulisem on see, et saksa keele puhul täheldati järjepidevat paranemist võrreldes mitmete algvaldkonna kohandamise meetoditega. Selle lähenemisviisi kõrvalsaadusena toimivad meie inglise- ja saksakeelsete väljendite kombinatsioonil koolitatud mudelid üsna hästi koodi vahetamisel, mis sisaldavad inglise ja saksa keele segu, isegi kui koolitusandmed sellist ei sisalda. Niipalju kui me teame, on see esimene uuring koodi vahetamisest semantilises parsimises. Konstrueerisime käsitsi NLMaps korpuse jaoks koodi vahetamise testilausete komplekti ja saavutasime selle andmekogumi 78,3% täpsuse.', 'fi': 'Semanttisten jäsennysjärjestelmien laajentaminen uusille toimialueille ja kielille on erittäin kallis ja aikaa vievä prosessi, joten olemassa olevien resurssien tehokas hyödyntäminen on ratkaisevan tärkeää. Tässä työssä kuvaillaan siirtooppimismenetelmää käyttäen monikielisiä sanaupotuksia sekvenssimallissa. NLMaps-korpusessa lähestymistapamme saavuttaa 85,7 prosentin tarkkuuden englanniksi. Tärkeintä oli, että saksan kielen kohdalla havaittiin johdonmukaista parannusta verrattuna useisiin perusdomeenin sopeutustekniikoihin. Tämän lähestymistavan sivutuotteena englannin- ja saksankielisten sanontojen yhdistelmään koulutetut mallit toimivat kohtuullisen hyvin koodinvaihtolauseissa, jotka sisältävät sekoitusta englantia ja saksaa, vaikka koulutustiedot eivät sisällä tällaisia. Tietääksemme tämä on ensimmäinen tutkimus koodin vaihtamisesta semanttisessa jäsentämisessä. Rakensimme käsin NLMaps-korpuselle koodinvaihtotestilausekkeet ja saavutimme 78,3% tarkkuuden tässä aineistossa.', 'af': "Die uitbreiding van semantiese verwerking stelsels na nuwe domeine en tale is 'n baie koste, tydproosing proses, sodat effektief gebruik van bestaande hulpbronne is kritiese. In hierdie papier beskrywe ons 'n oordrag leer metode deur te gebruik kruistale woord inbêring in 'n sekvens-na-sekvens model. On the NLmaps corpus, our approach achieves state-of-the-art accuracy of 85.7% for English. Mees belangriks het ons 'n konsistente verbetering vir Duits aangesien met verskeie basisline domein aanpassing tekniks. As 'n by-product van hierdie toegang, ons modele wat op 'n kombinasie van Engels en Duitse uitspraak uitvoer redelik goed op kode-wissel uitspraak wat bevat 'n gemeng van Engels en Duitse, selfs al het die onderwerp data nie so nie bevat nie. Soos ons weet, dit is die eerste studie van kode-wisseling in semantiese verwerking. Ons het die stel van kode-wisseling toets uitspraak vir die NLmaps corpus gemaak en 78.3% waarskynlik op hierdie datastel bereik.", 'jv': "System Nang pember iki, kita rambarang pengguna nggawe layaraning wis ngubah gambar kelangan langgar sampeyan ning model sekondir-sampeyan. Nang bantayan NLmaps, dadi nyong nggawe barang-barêng kuwi diangkamunyatan kanggo kowé urip nggawe gerakan ceng egal-karang kanggo kowé 75.7% kebutuhan Inggris. mesthi wacki, we've beholder a sistem tau luwih akeh nggawe ning alam nggawe karo nesaturan bazline domain modification teknik. Sampeyan kelalah sing dibutuhke iki, model sing ditambahak dhéwé ngerasah karo ingkang karo akeh barang alam kuwi masakno sing bisa ngono nggambar kelangan sing sampeyan ingkang sampeyan ingkang sampeyan sampeyan ingkang sampeyan ingkang sampeyan Jarambah, lha kedahki awak dhéwé kuwi alam sing ora bisa ngono kuwi. Inga awak dhéwé ngerti, iki ulih kanggo ngerwih akeh barang sematik. Awak dhéwé nggawe manut sing beraksi perusahaan kode kanggo ngilangno cara-cara NLmaps lan nganggo barang bangsane nang konoh barang 75.3%.", 'sk': 'Razširitev semantičnih sistemov razčlenitve na nove domene in jezike je zelo drag in dolgotrajen proces, zato je učinkovita uporaba obstoječih virov ključnega pomena. V prispevku opisujemo metodo transfernega učenja z uporabo večjezičnih besednih vdelav v modelu zaporedja v zaporedje. Na korpusu NLMaps naš pristop dosega najsodobnejšo natančnost 85,7% za angleščino. Najpomembnejše je, da smo opazili dosledno izboljšanje pri nemščini v primerjavi z več tehnikami prilagajanja osnovnih domen. Kot stranski produkt tega pristopa so naši modeli, ki so usposobljeni za kombinacijo angleških in nemških izgovorov, razumno dobro uspešni pri izgovorih s preklapljanjem kode, ki vsebujejo mešanico angleščine in nemščine, čeprav podatki o usposabljanju tega ne vsebujejo. Kolikor vemo, je to prva študija preklapljanja kode v semantičnem razčlenjevanju. Ročno smo sestavili nabor testnih izjav za preklop kod za korpus NLMaps in dosegli 78,3% natančnost na tem naboru podatkov.', 'he': 'הרחבת מערכות בדיקת סמנטית לתחומים חדשים ושפות היא תהליך יקר מאוד, שמשתמש בזמן, כך שימוש יעיל משאבים קיימים הוא קריטי. בעיתון הזה, אנו מתארים שיטת לימוד העברה באמצעות תוספות מילים חצות במודל רצף לרצף. על הקורפוס של NLmaps, הגישה שלנו משיגה מדויקת מוקדמת של 85.7% לאנגלית. הכי חשוב, שמנו לב לשיפור קבוע לגרמני בהשוואה לכמה טכניקות התאמה בתחום בסיסי. בתור תוצר לוואי של הגישה הזאת, הדוגמנים שלנו שאומנים על שילוב של מילים אנגליים וגרמניים מבצעים היטב בהסביר על מילים מחליפים קודים שמכילים שילוב של אנגליים וגרמנים, למרות שמידע האימונים לא מכיל מילים כאלה. עד כמה שאנחנו יודעים, זה המחקר הראשון של החלפת קודים באבחן סמנטי. בנינו באופן ידני את קבוצת מבחני החלפת קודים לקורפוס NLmaps ולהשיג מדויקת 78.3% על קבוצת הנתונים הזאת.', 'ha': "Akwai mai shimfiɗawa na'urar parsingi na semantic zuwa wurãre da harsunan na zama jarraba mai girma, mai amfani da lokaci, don haka kuma yin amfani da amfani da maɓallin wanda ke jira na muhimu ne. Daga wannan takardan, muna bayyana wata metode mai motsi da za'a yi amfani da maganar gudu wanda za'a shiga cikin wani misali-zuwa-sequence. Ga shirin NLmaps, hanyoyinmu yana sãmun halin-sanannin da 85.7% wa Ingiriya. Ga mafi muhimu, mun ga mafiya kyauta na Jarman a sami da wasu masu adapto na danna-layin. As a by-product of this approach, our models that are trained on a combination of English and German utterances perform reasonably well on code-switching utterances which contain a mixture of English and German, even though the training data does not contain any such.  Ina sani, wannan ne farkon karatun na musanya kodi a cikin parishin semantic. Mun samar da tsarin ayuka na canza kodi-mai musanya wa nau'in NLmaps da kuma muka isa tsarin 78.3 a kan wannan tsari.", 'bo': 'Extending semantic parsing systems to new domains and languages is a highly expensive, time-consuming process, so making effective use of existing resources is critical. འོག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་སྐད་ཡིག་གེ་གནས་ཚུལ་གྱི་ཐབས་ལམ་ཞིག་བེད་སྤྱོད་བཞིན་པའི་གྲལ་སྒྲིག ང་ཚོའི་གཟུགས་འབྲེལ་དབུས་གཞུང་གི་ཐོག་ལས་ང་ཚོའི་ཐབས་ལམ་ལ་ཡོད་ཚད་ལྡན་སྔོན་ཡོད། ཆེས་ཤོས་གལ་ཆེ་ཤོས་ཡིན། ང་ཚོས་Aleman་དང་རྨང་གཞིའི་གྲངས་སྒྲིག་འགོད་ཐབས་ལམ་གཞན་དང་མཉམ་ལས་ཕར་རྒྱས་གཏ As a by-product of this approach, our models that are trained on a combination of English and German utterances perform reasonably well on code-switching utterances which contain a mixture of English and German, even though the training data does not contain any such. ང་ཚོས་ཤེས་ཐབས་ཤེས་དུ་འདི་ནི་semantic དབྱེ་ཞིབ་ནང་གི་ཨང་ཀིའི་ནང་དུ་བསྒྱུར་ཐབས་དང་པོ་རེད། ང་ཚོས་རང་ལག་ནས་སྒྲིག་འཛུགས་པའི་ཡིག་ཆ་ལྟ་ཞིབ་བཟོ་བྱེད་པའི་འཛུལ་སྒྲིག'}
{'en': 'Optimizing Differentiable Relaxations of Coreference Evaluation Metrics', 'ar': 'تحسين عمليات الاسترخاء المتمايزة لمقاييس تقييم Coreference', 'pt': 'Otimizando Relaxamentos Diferenciáveis de Métricas de Avaliação de Correferência', 'fr': "Optimisation des relaxations différentiables des mesures d'évaluation de coréférence", 'es': 'Optimización de relajaciones diferenciables de las métricas de evaluación de correferencias', 'ja': 'コアレファレンス評価指標の微分可能な緩和の最適化', 'zh': '优化共验评估指标者可微弛', 'hi': 'Coreference मूल्यांकन मैट्रिक्स के differentiable छूट का अनुकूलन', 'ru': 'Оптимизация дифференцированных релаксаций метрик оценки Coreference', 'ga': 'Suaimhneas Difreálach a Bharrfheabhsú ar Mhéadracht Measúnaithe Croítheachta', 'it': 'Ottimizzare i rilassamenti differenziati delle metriche di valutazione della coreferenza', 'ka': 'სხვა განსხვავებული განსხვავებული განსხვავებული განსხვავებების განსხვავება', 'el': 'Βελτιστοποίηση των διαφοροποιημένων χαλαρώσεων των μετρήσεων αξιολόγησης της συνάφειας', 'hu': 'A Coreferencia értékelési mérések differenciálható relaxációinak optimalizálása', 'lt': 'Optimizuoti diferencijuotus koreferencijos vertinimo metrikų atsparumus', 'kk': 'Қайшылық оқу метрикаларының айырмашылық қатынасын оқиғалау', 'ml': 'മെറ്റിക്സിന്റെ വ്യത്യസ്തമായ വ്യത്യസ്ത ബന്ധങ്ങള്\u200d ഉപയോഗിക്കുന്നു', 'mn': 'Өөр төрлийн харилцааны тооцоололтын тооцоололтын тооцоололт', 'mt': 'L-ottimizzazzjoni tar-Rilassazzjonijiet Differenzjabbli tal-Metriċi tal-Evalwazzjoni tal-Koreferenza', 'no': 'Optimaliserar forskjellige relaksjonar av hjelpevalueringsmetrar', 'mk': 'Оптимизирање на различни олеснувања на метриките за оценка на кореференцијата', 'pl': 'Optymalizacja różnicowalnych relaksacji wskaźników oceny Coreference', 'ms': 'Optimumkan Perubahan Pemeriksaan Metrik Evaluasi Kesuaian', 'sr': 'Optimaliziranje različitih relaksija metrika za procjenu korisnosti', 'si': 'වෙනස් සම්බන්ධ විශේෂ මීට්\u200dරික්ස් විශේෂ විශේෂණය', 'so': 'Horumarinta xiriirka kala duwan ee qiimeynta kaartaynta', 'ro': 'Optimizarea relaxărilor diferențiate ale parametrilor de evaluare a coreferenței', 'ur': 'سرپرستی ارزیابی متریک کے متفرق متفرق تفریق کرنے والی', 'ta': 'முன்னிருப்பு மதிப்பீட்டு மெட்ரிக்களின் வேறுபாடு தொடர்புகளை தேர்வு செய்கிறது', 'sv': 'Optimera differentierbara avslappningar av mätvärden för Coreference-utvärdering', 'uz': 'Name', 'vi': 'Tỷ lệ khác nhau tối đa của Cảm ứng lõi', 'hr': 'Optimaliziranje različitih relaksija mjera procjene korisnosti', 'bg': 'Оптимизиране на диференцираните релаксации на мерките за оценка на кореференцията', 'da': 'Optimering af differentierbare afslapning af målinger for Coreference evaluering', 'nl': 'Optimaliseren van differentieerbare relaxaties van Coreference Evaluatie Metrics', 'id': 'Optimisasi Relaksi Berbeda Metrik Evaluasi Koreferensi', 'de': 'Optimierung differenzierbarer Relaxationen von Coreferenz Evaluations Metriken', 'fa': 'بهترین رابطه\u200cهای متفاوتی از متریک ارزیابی قابلیت', 'ko': '공지 평가 지표의 미완 최적화', 'sw': 'Kuchagua Mazungumzo tofauti ya Uthibitisho wa Maendeleo', 'tr': 'Döwürler Taýýarlama Metricleriniň üýtgeşikleri', 'af': 'Optimaliseer Verskillende Relaksies van Hoeferensieevalueringsmetries', 'sq': 'Optimizimi i lehtësimeve të ndryshme të Metrikës së vlerësimit të Koreferencës', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Օպտիմացնում է կորեֆերենսի գնահատման մետրիկների տարբերակային հանգստությունները', 'az': 'M√ºf…ôss…ôl Qƒ±ymet Metricl…ôrinin Farklƒ± Relaxsiyalarƒ±nƒ± Optimizl…ôndirir', 'bn': 'করফেন্সের মেট্রিকেশনের বিভিন্ন রিলেক্সেশন অপশন করা হচ্ছে', 'bs': 'Optimaliziranje različitih relaksija mjera procjene korisnosti', 'ca': 'Optimizing Differentiable Relaxations of Coreference Evaluation Metrics', 'cs': 'Optimalizace diferenciálních relaxací hodnotících metrik Coreference', 'et': 'Koreferensi hindamismeetrite diferentseeritavate lõdvestuste optimeerimine', 'fi': 'Coreference-arviointimetrien eriytettävien rentoutusten optimointi', 'jv': 'Optimisation', 'ha': 'KCharselect unicode block name', 'sk': 'Optimizacija različnih sprostitev meril vrednotenja Coreference', 'he': 'אופטימיזציה שינויים אפשריים של מטריקת הערכה של קומפרנס', 'bo': 'མཐའ་དབྱིབས་དཔག་འཛུགས་ཀྱི་ཚད་རིམ་གྲངས་ཀྱི་ཁྱད་པར་འགྱུར་རྒྱུན་ལྡན་འགྲོ་བ་རེད།'}
{'en': 'Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions. Consequently, most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance. Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy. We show that by modifying the training objective of a competitive neural coreference system, we obtain a substantial gain in performance. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.', 'ar': 'يصعب تحسين مقاييس تقييم Coreference بشكل مباشر لأنها وظائف غير قابلة للتفاضل ، ولا يمكن تحليلها بسهولة إلى قرارات أولية. وبالتالي ، فإن معظم الأساليب تعمل على تحسين الأهداف المرتبطة بشكل غير مباشر فقط بالهدف النهائي ، مما يؤدي إلى أداء دون المستوى الأمثل. بدلاً من ذلك ، نقترح استرخاءً مختلفًا يفسح المجال للتحسين القائم على التدرج ، وبالتالي تجاوز الحاجة إلى التعلم المعزز أو التعديل الإرشادي للانتروبيا المتقاطعة. نظهر أنه من خلال تعديل هدف التدريب لنظام مرجعي عصبي تنافسي ، نحصل على مكاسب كبيرة في الأداء. يشير هذا إلى أنه يمكن اعتبار نهجنا بديلاً قابلاً للتطبيق لاستخدام التعلم المعزز أو تعلم المحاكاة الأكثر تكلفة من الناحية الحسابية.', 'pt': 'As métricas de avaliação de correferência são difíceis de otimizar diretamente, pois são funções não diferenciáveis, não facilmente decomponíveis em decisões elementares. Consequentemente, a maioria das abordagens otimiza os objetivos apenas indiretamente relacionados ao objetivo final, resultando em desempenho abaixo do ideal. Em vez disso, propomos um relaxamento diferenciável que se presta à otimização baseada em gradiente, ignorando assim a necessidade de aprendizado por reforço ou modificação heurística de entropia cruzada. Mostramos que modificando o objetivo de treinamento de um sistema de correferência neural competitivo, obtemos um ganho substancial no desempenho. Isso sugere que nossa abordagem pode ser considerada uma alternativa viável ao uso de aprendizado por reforço ou aprendizado por imitação mais caro computacionalmente.', 'es': 'Las métricas de evaluación de correferencias son difíciles de optimizar directamente, ya que son funciones no diferenciables y no se pueden descomponer fácilmente en decisiones elementales. En consecuencia, la mayoría de los enfoques optimizan los objetivos solo indirectamente relacionados con el objetivo final, lo que resulta en un rendimiento subóptimo. En cambio, proponemos una relajación diferenciable que se presta a la optimización basada en gradientes, evitando así la necesidad de aprendizaje por refuerzo o modificación heurística de la entropía cruzada. Demostramos que al modificar el objetivo de entrenamiento de un sistema de correferencia neuronal competitivo, obtenemos una ganancia sustancial en el rendimiento. Esto sugiere que nuestro enfoque puede considerarse una alternativa viable al uso del aprendizaje por refuerzo o el aprendizaje de imitación más caro desde el punto de vista computacional.', 'fr': "Les métriques d'évaluation de coréférence sont difficiles à optimiser directement car ce sont des fonctions non différentiables, difficilement décomposables en décisions élémentaires. Par conséquent, la plupart des approches optimisent les objectifs uniquement indirectement liés à l'objectif final, ce qui entraîne des performances sous-optimales. Au lieu de cela, nous proposons une relaxation différentiable qui se prête à une optimisation basée sur le gradient, évitant ainsi la nécessité d'un apprentissage par renforcement ou d'une modification heuristique de l'entropie croisée. Nous montrons qu'en modifiant l'objectif d'entraînement d'un système de coréférence neuronale compétitif, nous obtenons un gain de performance substantiel. Cela suggère que notre approche peut être considérée comme une alternative viable à l'utilisation de l'apprentissage par renforcement ou de l'apprentissage par imitation plus coûteux en informatique.", 'ja': 'コアレファレンス評価指標は、非微分可能な関数であるため、直接最適化することは困難であり、基本的な意思決定に分解することは容易ではありません。したがって、ほとんどのアプローチは、最終目標に間接的に関連する目標のみを最適化し、最適以下のパフォーマンスをもたらします。代わりに、勾配ベースの最適化に適した微分可能な緩和を提案し、したがって、クロスエントロピーの強化学習またはヒューリスティックな修正の必要性を回避する。競合的なニューラルコアファレンスシステムのトレーニング目標を変更することで、パフォーマンスの実質的な向上が得られることを示しています。このことから、我々のアプローチは、強化学習または計算上より高価な模倣学習を使用する代わりの実行可能な代替手段と見なすことができることが示唆される。', 'ru': 'Метрики оценки Coreference трудно оптимизировать напрямую, поскольку они являются недифференцируемыми функциями, не поддающимися легкой декомпозиции в элементарные решения. Следовательно, большинство подходов оптимизируют цели, только косвенно связанные с конечной целью, что приводит к неоптимальной производительности. Вместо этого мы предлагаем дифференцируемую релаксацию, которая поддается оптимизации на основе градиента, таким образом, минуя необходимость обучения подкреплению или эвристической модификации перекрестной энтропии. Мы показываем, что, изменяя цель обучения конкурентоспособной нейронной базовой системы, мы получаем существенное увеличение производительности. Это говорит о том, что наш подход можно рассматривать как жизнеспособную альтернативу использованию обучения с подкреплением или более дорогостоящего с вычислительной точки зрения обучения с имитацией.', 'zh': 'Coreference评估指标难直优化,以其不可微分之函数,未易分解为本。 故大抵优化与最终目标间接相关者,性能不佳。 反此者,可微之弛也,宜梯度之优化,以绕交熵之学,启发式改之求也。 吾明改竞争性神经共推理系统之教,可得而升也。 此明吾法可以为用强计算成本高者可以为代方也。', 'hi': 'Coreference मूल्यांकन मैट्रिक्स सीधे अनुकूलित करने के लिए कठिन हैं क्योंकि वे गैर-विभेद्य कार्य हैं, प्राथमिक निर्णयों में आसानी से विघटित नहीं होते हैं। नतीजतन, अधिकांश दृष्टिकोण उद्देश्यों को केवल अप्रत्यक्ष रूप से अंतिम लक्ष्य से संबंधित अनुकूलित करते हैं, जिसके परिणामस्वरूप सब-ऑप्टिमल प्रदर्शन होता है। इसके बजाय, हम एक अलग छूट का प्रस्ताव करते हैं जो खुद को ग्रेडिएंट-आधारित ऑप्टिमाइज़ेशन के लिए उधार देता है, इस प्रकार सुदृढीकरण सीखने या क्रॉस-एंट्रॉपी के हेरिस्टिक संशोधन की आवश्यकता को दरकिनार करता है। हम दिखाते हैं कि एक प्रतिस्पर्धी तंत्रिका कोरेफेरेंस सिस्टम के प्रशिक्षण उद्देश्य को संशोधित करके, हम प्रदर्शन में पर्याप्त लाभ प्राप्त करते हैं। इससे पता चलता है कि हमारे दृष्टिकोण को सुदृढीकरण सीखने या अधिक कम्प्यूटेशनल रूप से महंगी नकल सीखने का उपयोग करने के लिए एक व्यवहार्य विकल्प के रूप में माना जा सकता है।', 'ga': 'Is deacair méadracht mheastóireachta croí-chomhdhála a bharrfheabhsú go díreach toisc gur feidhmeanna neamh-idirdhealaithe iad, nach féidir a dhianscaoileadh go héasca i gcinntí bunúsacha. Dá bhrí sin, ní bhaineann an chuid is mó de na cineálacha cur chuige leas as cuspóirí ach amháin a bhaineann go hindíreach leis an sprioc deiridh, agus bíonn feidhmíocht fho-optamach mar thoradh air. Ina áit sin, molaimid maolú difreálach a oireann do bharrfheabhsú atá bunaithe ar ghrádán, rud a sheachnaíonn an gá atá le foghlaim atreisithe nó le modhnú heoraíoch tras-eantrópachta. Léirímid go bhfaighimid gnóthachan suntasach san fheidhmíocht trí chuspóir oiliúna córas croí-chomhdhála iomaíoch néarúil a mhodhnú. Tugann sé seo le tuiscint gur féidir breathnú ar ár gcur chuige mar mhalairt inmharthana ar fhoghlaim athneartaithe nó foghlaim aithrise atá níos costasaí a úsáid.', 'ka': 'მარტირების განსაზღვრება მეტრიკები ძალიან ძალიან აპტიმიზება, რადგან ისინი არ განსაზღვრებელი ფუნქციებია, არც ადვილად განსაზღვრებელია ელემენტრიული განსაზღვრებში. შემდეგ უფრო მეტი დახმარებები უფრო მხოლოდ საკუთარი მისამართლად დაკავშირებულია მისამართლად, რომელიც შემდეგ სუპოტიმალური გამოყენება. მაშინ, ჩვენ განსხვავებული განსხვავებელი განსხვავებელი განსხვავება, რომელიც თავისთან განსხვავებს განსხვავებელი განსხვავებას, რომელიც განსხვავებულია განსხვავებელი განსხვავებას, რომელიც განსხვავებულია ჩვენ ჩვენ აჩვენებთ, რომ კონტეპექტიური ნეიროლური კორეფერენციის სისტემის შეცვლის მიღებით, ჩვენ მივიღეთ მნიშვნელოვანი კონფიგურაციის მიღება. ეს იტყვის, რომ ჩვენი პროგრამა შეიძლება იყოს ცხოვრებელი ალტენტიფიკაცია, რომელიც გამოყენება სწავლების სწავლებას, ან უფრო კომპუტაციურად კომპუტა', 'hu': 'A coreferencia értékelési mutatókat nehéz közvetlenül optimalizálni, mivel nem megkülönböztethető függvények, nem könnyen bonthatók elemi döntésekre. Következésképpen a legtöbb megközelítés csak közvetett módon optimalizálja a célkitűzéseket, ami szuboptimális teljesítményt eredményez. Ehelyett olyan megkülönböztethető relaxációt javasolunk, amely gradiens alapú optimalizálásra alkalmas, így kikerülve a megerősítő tanulás vagy a keresztentrópia heurisztikus módosításának igényét. Megmutatjuk, hogy egy versenyképes neurális coreferencia rendszer edzési céljának módosításával jelentős teljesítménynövekedést érünk el. Ez azt sugallja, hogy megközelítésünk életképes alternatívának tekinthető a megerősítő tanulás vagy a számítástechnikailag drágább utánzó tanulás használatával szemben.', 'el': 'Οι μετρήσεις αξιολόγησης της συνάφειας είναι δύσκολο να βελτιστοποιηθούν άμεσα καθώς είναι μη διαφοροποιημένες λειτουργίες, δεν μπορούν εύκολα να αποσυναρμολογηθούν σε στοιχειώδεις αποφάσεις. Κατά συνέπεια, οι περισσότερες προσεγγίσεις βελτιστοποιούν τους στόχους μόνο έμμεσα που σχετίζονται με τον τελικό στόχο, με αποτέλεσμα την υποβέλτιστη απόδοση. Αντίθετα, προτείνουμε μια διαφοροποιημένη χαλάρωση που προσφέρεται για βελτιστοποίηση βάσει κλίσης, παρακάμπτοντας έτσι την ανάγκη για ενισχυτική μάθηση ή heuristική τροποποίηση της διασταυρούμενης εντροπίας. Αποδεικνύουμε ότι τροποποιώντας τον εκπαιδευτικό στόχο ενός ανταγωνιστικού νευρικού συστήματος συγχορήγησης, επιτυγχάνουμε ένα σημαντικό κέρδος στην απόδοση. Αυτό υποδηλώνει ότι η προσέγγισή μας μπορεί να θεωρηθεί ως μια βιώσιμη εναλλακτική λύση στη χρήση ενισχυτικής μάθησης ή πιο δαπανηρή υπολογιστικά απομίμηση μάθησης.', 'kk': 'Метрикалық қасиеттерді бағалау көмегімен, оны түрлендірмейтін функциялар болғанда, негізгі шешімдерге оңай бөлмейді. Сондықтан көпшілігі мақсаттарды тек соңғы мақсаттың арасындағы көпшілігін оптимизациялау мүмкіндігі болады. Осының орнына, біз өзімізді градиенттік оптимизациялауға көмектесетін түрлендірімізді ұсынамыз, сондықтан білімізді көмектесетін немесе көпшілікті ентропиялық өзгерту қажеттігін өзгертіп Біз әрекетті невралдық оқыту мақсатын өзгертуге болады. Біз оқыту мақсатын өзгертуге болады. Бұл біздің тәсіліміздің көмектесуді көмектесу немесе компьютерлік үлкен көмектесу үйренуді қолдануға арналған альтернатив деп ойлайды.', 'lt': 'Suderinimo vertinimo rodiklius sunku tiesiogiai optimizuoti, nes tai yra nediferencijuojamos funkcijos, nesudėtingos į elementinius sprendimus. Todėl dauguma metodų optimizuoja tikslus tik netiesiogiai, susijusius su galutiniu tikslu, todėl rezultatai nėra optimalūs. Vietoj to mes siūlome diferencijuotą atpalaidavimą, kuris leistų optimizuoti gradientais ir taip išvengti būtinybės stiprinti mokymąsi arba heuristiškai pakeisti kryžminę entropiją. Mes parodome, kad keičiant konkurencingos nervų koreferencijos sistemos mokymo tikslą, pasiekiame didelį rezultatų pasiekimą. Tai rodo, kad mūsų požiūris gali būti laikomas gyvybinga alternatyva pasitelkiant stipresnį mokymąsi arba skaičiavimo požiūriu brangesnį imitacinį mokymąsi.', 'ms': 'Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions.  Oleh itu, kebanyakan pendekatan optimize sasaran hanya secara tidak langsung berkaitan dengan sasaran akhir, menghasilkan prestasi tidak optimal. Sebaliknya, kami melamar penenang yang boleh berbeza yang meminjamkan diri kepada optimisasi berdasarkan gradien, dengan itu melepasi keperluan untuk pembelajaran kuasa atau perubahan heuristik saling entropi. Kami menunjukkan bahawa dengan mengubah tujuan latihan sistem bersamaan saraf kompetitif, kita mendapat keuntungan yang besar dalam prestasi. Ini menunjukkan bahawa pendekatan kita boleh dianggap sebagai alternatif yang mudah untuk menggunakan pembelajaran kuasa atau pembelajaran imitasi yang lebih mahal secara komputasi.', 'mt': 'Il-metriċi tal-evalwazzjoni tal-koerenza huma diffiċli biex jiġu ottimizzati direttament peress li huma funzjonijiet mhux differenzjabbli, mhux faċilment dekomponibbli f’deċiżjonijiet elementari. Konsegwentement, il-biċċa l-kbira tal-approċċi ottimizzaw l-għanijiet biss b’mod indirett relatati mal-għan finali, li jirriżultaw fi prestazzjoni subottimali. Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy.  Aħna nuru li billi nimmodifikaw l-għan tat-taħriġ ta’ sistema kompetittiva ta’ koreferenza newrali, inkisbu qligħ sostanzjali fil-prestazzjoni. Dan jissuġġerixxi li l-approċċ tagħna jista’ jitqies bħala alternattiva vijabbli għall-użu ta’ tagħlim rinfurzat jew tagħlim ta’ imitazzjoni aktar għali b’mod komputattiv.', 'it': "Le metriche di valutazione della coreferenza sono difficili da ottimizzare direttamente in quanto sono funzioni non differenziabili, non facilmente scomponibili in decisioni elementari. Di conseguenza, la maggior parte degli approcci ottimizza gli obiettivi solo indirettamente legati all'obiettivo finale, con conseguente performance subottimali. Proponiamo invece un rilassamento differenziato che si presta all'ottimizzazione gradiente, aggirando così la necessità di apprendimento di rinforzo o modifica euristica della cross-entropia. Dimostriamo che modificando l'obiettivo di allenamento di un sistema di coreferenza neurale competitivo, otteniamo un notevole guadagno di prestazioni. Questo suggerisce che il nostro approccio può essere considerato come una valida alternativa all'uso dell'apprendimento di rinforzo o dell'apprendimento di imitazione più costoso dal punto di vista computazionale.", 'mk': 'Метриките за проценка на кореференцијата се тешки да се оптимизираат директно бидејќи се неразликувачки функции, не лесно да се разделат во основни одлуки. Поради тоа, повеќето пристапи оптимизираат цели само индиректно поврзани со крајната цел, што резултира со субоптимална перформанса. Наместо тоа, предложуваме различен релаксација која се позајмува на оптимизација базирана на градиенти, со што ќе ја избегнеме потребата за зајакнување на учењето или хеористичка модификација на крстоентропијата. Ние покажуваме дека со модификација на обуката на конкурентниот систем на нервна кореференција, добиваме значителен профит во изведувањето. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.', 'mn': 'Хамгийн чухал оюун шалгалтын метрик нь шууд ялгаагүй функцүүдийг багасгах нь хэцүү. Энгийн шийдвэрлэлд амархан хуваагдахгүй. Үүнээс ихэнх арга барилга нь зорилгоонуудыг төгсгөлийн зорилгоос буруу холбоотой болгоно. Үүнээс эцсийн давхар үйл ажиллагаа болдог. Үүний оронд, бид өөрсдийгөө градиент дээр суурилуулан суралцах, эсвэл хямрал энтропийн өөрчлөлтийг нэмэгдүүлэх шаардлагатай өөрчлөлтийг санал болгож байна. Бид тэмцээний сэтгэл хөдлөлийн системийн дасгал хөдлөлийн зорилго өөрчлөхөд бид үйл ажиллагаанд маш их ашиг авдаг. Энэ нь бидний арга замыг дэмжих сургалтыг эсвэл маш их тооцоолон үнэтэй дүрслэлийн сургалтыг ашиглан амьдралын альтернатив гэж үздэг гэсэн үг.', 'no': 'Det er vanskeleg å optimalisera direkte fordi dei ikkje er forskjellige funksjonar, ikkje lett å dekomponera i elementære beslutningar. Derfor er dei fleste tilnærmingane optimalisere målane berre indirekte relaterte til sluttmålet, som fører til underoptimal utvikling. I staden foreslår vi ein forskjellig relaksjon som låner seg til optimizasjon på fargeovergangen, slik at vi gjer nødvendighet for å styrke læring eller heuristisk endring av kryss-entropi. Vi viser at ved å endra opplæringsmålet på eit konkurrentivt neuralkoreferens systemet, får vi ein betydelig innvikling i utviklingane. Dette tyder på at tilnærminga vårt kan verta kalla til å bruka styrkelæring eller meir kalkulasjonslykkeleg imitasjonlæring.', 'ml': 'കോര്\u200dഫെന്\u200dസ് വിലാസങ്ങള്\u200d നേരിട്ട് മെറ്റിക്ക് മെറ്റിക്കാന്\u200d ബുദ്ധിമുട്ടുകളാണ്. അവയൊക്കെ വ്യത്യസ്തമാക്കാത്ത ഫങ്ഷനുകള അതുകൊണ്ട് മിക്കവാറും അവസാനത്തിന്റെ ലക്ഷ്യത്തോടൊപ്പം നേരെയായി ബന്ധപ്പെട്ടിരിക്കുന്ന ലക്ഷ്യങ്ങള്\u200d മാത്രമേ ഉള് പകരം, നമ്മള്\u200d ഒരു വ്യത്യസ്തമായ വിശ്വാസം പ്രായശ്ചിത്തമാക്കുന്നു. അത് സ്വയം ഗ്രാഡേന്\u200dഡ് അടിസ്ഥാനത്തിലുള്ള പ്രതീക്ഷയ്ക്ക് സമ്മാനിക്കുന്നു.  നമ്മള്\u200d കാണിച്ചു കൊടുക്കുന്നത് പ്രകടനത്തില്\u200d ഒരു പ്രധാനപ്പെടുത്തുന്ന നെയൂറല്\u200d കോര്\u200dഫെന്\u200dസ് സിസ്റ്റത്തിന്\u200dറെ പര ഇത് നമ്മുടെ പ്രായോഗ്യം വിലപിക്കാന്\u200d കഴിയുന്ന ഒരു വിലാസമായി വിചാരിക്കാന്\u200d കഴിയുന്നു എന്ന് നിര്\u200dദേശിക്കുന്നു. കൂടുതല്\u200d', 'pl': 'Wskaźniki oceny Coreference są trudne do optymalizacji bezpośrednio, ponieważ są to nieróżnicowalne funkcje, niełatwo rozkładane na podstawowe decyzje. W konsekwencji większość podejść optymalizuje cele tylko pośrednio związane z celem końcowym, co powoduje nieoptymalną wydajność. Zamiast tego proponujemy zróżnicowalną relaksację, która nadaje się do optymalizacji opartej na gradientach, omijając tym samym potrzebę wzmocnienia uczenia się lub heurystycznej modyfikacji entropii krzyżowej. Pokazujemy, że modyfikując cel treningowy konkurencyjnego układu rdzeniowego, uzyskujemy znaczny wzrost wydajności. Sugeruje to, że nasze podejście można uznać za realną alternatywę dla wykorzystania uczenia się wzmacniającego lub bardziej kosztownych obliczeniowych imitacji.', 'ro': 'Metricile de evaluare a coreferenței sunt greu de optimizat direct, deoarece sunt funcții non-diferențiabile, nu ușor de descompus în decizii elementare. În consecință, majoritatea abordărilor optimizează obiectivele doar indirect legate de obiectivul final, rezultând performanțe suboptime. În schimb, propunem o relaxare diferențiabilă care se potrivește optimizării bazate pe gradient, ocolind astfel nevoia de învățare de consolidare sau modificare euristică a intropiei încrucișate. Arătăm că prin modificarea obiectivului de formare al unui sistem competitiv de corefență neurală, obținem un câștig substanțial în performanță. Acest lucru sugerează că abordarea noastră poate fi considerată o alternativă viabilă la utilizarea învățării de armare sau a învățării de imitație mai costisitoare din punct de vedere computațional.', 'sr': 'Metrike za procjenu korisnosti su teško optimizirati direktno jer su ne diferencijalne funkcije, ne lako se rasklopiti u osnovne odluke. Stoga većina pristupa optimizira ciljeve samo indirektno povezane sa ciljem kraja, što je rezultiralo podoptimalnim izvedbama. Umjesto toga, predlažemo diferencijalnu opuštenost koja se posudi optimizaciji na osnovu gradient a, tako da prelazimo potrebu za pojačanjem učenja ili heurističkim modifikacijama krstoentropije. Pokazujemo da, modificiranjem cilja obuke konkurentnog nervnog koreferencijskog sistema, dobijamo značajan dobitak u izvedbi. To predlaže da naš pristup može biti smatran rezultatnom alternativom za upotrebu učenja pojačanja ili računalno skupljeg učenja imitacije.', 'si': 'ප්\u200dරධාන විශ්ලේෂණ මෙට්\u200dරික්ස් ප්\u200dරධාන විශ්ලේෂණයක් අමාරුයි, ඔවුන් ප්\u200dරධාන විශ්ලේෂණයක් නොවෙන්න ප්\u200dරධා ඉතින්, ගොඩක් අවස්ථාවක් අවස්ථාවක් අවස්ථාවක් විතරයි අවස්ථාවක් සම්බන්ධ වෙන්නේ, අවස්ථාවක් අව ඒ වෙනුවෙන්, අපි වෙනස් වෙන්න පුළුවන් විස්තර විස්තාරයක් ප්\u200dරයෝජනය කරන්න පුළුවන් වෙනවා, ඒ වගේම ප්\u200dරයෝජනය විස්තර විස්තර විස් අපි පෙන්වන්නේ අපි ප්\u200dරශ්නයක් වෙනස් කරලා තියෙන්නේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක මේක ප්\u200dරශ්නයක් තියෙනවා අපේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් කියලා අපේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විදිහට', 'so': "Qiimeynta kaartayntu waa ku adag tahay in si toos ah loo tijaabiyo, sababtoo ah waa shaqooyin aan kala duwanaanayn, oo aan si fudud u gelin go'aanka aasaasiga ah. Consequently, most approaches optimize objectives only indirectly related to the end goal, resulting in suboptimal performance.  Waxan badalkeeda ka bixinaynaa dib u dhigid oo kala duwan, taas oo iska siineysa faa'iidada ku saabsan shahaadada, taas darteed baahida kordhiska barashada ama beddelinta iskuulka. Waxaynu muujinnaa in marka lagu beddelo goal-waxbarashada nidaamka kooxaha adag, waxaynu helaynaa faa'iido badan oo sameynta. Tan waxaa loola jeedaa in dhaqdhaqaalahayaga looga tirin karo fursad ah oo lagu isticmaali karo barashada kordhiska ama waxbarashada qiimo qaali ah oo qiimo ah.", 'ta': 'காரணி மதிப்பு மெட்ரிக்கள் நேரடியாக மாற்றுவதற்கு கடுமையானது, ஏனெனில் அவை மாறுபடாத செயல்பாடுகள், முதன்மை தீர்மானியங்களுக்கு மு அதனால், பெரும்பாலான நெருங்கும் பொருள்களை முடிவில் மட்டும் நேரடியாக தொடர்புடன் மட்டும் முடிவில் மட்டும் முடி அதற்கு பதிலாக, நாம் ஒரு வேறுபாட்டு குளிர் நுழைந்த மாற்றியமைப்பை தேர்வு செய்கிறோம். அது தன்னை சார்ந்து சார்ந்த நம்பிக்கைக்கு கடமையாக நாங்கள் ஒரு போராட்டியான புதிய முறைமையின் பயிற்சி பொருளை மாற்றுவதற்கு காட்டுகிறோம், நாம் செயல்பாட்டில் ஒரு ம இது நம்முடைய முறைமையை பார்க்க முடியும் என்று பரிந்துரைக்கிறது மேலும் கல்வி வலுப்படுத்தல் அல்லது கணக்கில் விலையான பின்பற்', 'sv': 'Koreferenceutvecklingsmetoder är svåra att optimera direkt eftersom de är icke-differentierbara funktioner, inte lätt nedbrytbara till elementära beslut. Följaktligen optimerar de flesta tillvägagångssätt endast indirekt relaterade till slutmålet, vilket resulterar i suboptimal prestanda. Istället föreslår vi en differentierbar avslappning som lämpar sig för gradientbaserad optimering och därmed kringgår behovet av förstärkt lärande eller heuristisk modifiering av korsentropi. Vi visar att genom att ändra träningsmålet för ett konkurrenskraftigt neuralt coreferencesystem får vi en betydande prestationsförbättring. Detta tyder på att vårt tillvägagångssätt kan ses som ett livskraftigt alternativ till att använda förstärkt lärande eller mer beräkningsmässigt dyrt imitationslärande.', 'ur': 'اچھی ارزیابی منٹریک مستقیماً اچھی طرح کرنا مشکل ہے جس طرح وہ بغیر متفاوت کام ہیں، آسانی طرح اصلی فیصلے میں تغییر نہیں کر سکتے۔ لہٰذا بہت سی تقریبیں موجودات کو صرف فائدہ مقصد کے ساتھ غلط طور پر متصل کر رہی ہیں، اور اس کے نتیجہ میں زیادی اچھی عملکرد کی وجہ سے ہوتی ہے. اس عوض، ہم ایک متفاوت آرامش کی پیشنهاد کرتے ہیں جو اپنے آپ کو گراڈیٹ بنیاد کی آرامش پر قرض دیتا ہے، اس طرح کرس انتروپی کی مضبوط تعلیم یا مضبوط تغییر کے لئے ضرورت سے گزرتے ہیں. ہم دکھاتے ہیں کہ ایک مقابلہ نظام کی تعلیم کا موضوع بدلنے کے ذریعہ، ہم عملہ میں بہت بڑا فائدہ حاصل کرتے ہیں. یہ اس بات سے پیش کرتا ہے کہ ہماری طریقہ کو مضبوط تعلیم یا زیادہ کمپیوٹر کے مطابق بہت گران تعلیم کی تعلیم کی استعمال کرنے کے لئے قابل قابل اختیار بنا سکتا ہے.', 'uz': "Eksport qilish metriklari to ʻgʻri aniqlash qiymati juda qiyin, chunki ular o'zgarib boʻlmagan funksiyalar emas, aslida tub xususiyatlarni o'zgartirib boʻlmaydi. Bu sababda, ko'pchilik obʼektlarni faqat oxiriga murakkab bog'liq boʻlgan narsalarni moslash mumkin. Bu sababda suboptimal bajarish natijasida bajaradi. Biz o'zgarishni tasavvur qilamiz, biz o'ziga gradient asosiy optimizga ega bo'ladi, shunday qilib, cross-entropni o'rganish yoki heuristik o'zgarishni oshirish kerak. Biz shunday ko'rsatganimiz, rivojlanadigan neyron coreference tizimini o'zgartirishimiz mumkin, biz bajarishga juda muhim muvaffaqiyatli topamiz. Bu shunday qiladi, bizning fikrimizni o'rganishni qo'shish yoki o'rganishni ko'proq qiymatni o'rganishdan foydalanish mumkin.", 'vi': 'Cấu hình đo cảm quang rất khó tối ưu trực tiếp vì nó là các chức năng không phân biệt, không dễ phân hủy thành các quyết định cơ bản. Hầu hết các phương pháp tối ưu các mục tiêu chỉ gián tiếp liên quan đến mục tiêu cuối, dẫn đến hiệu suất tối ưu. Thay vào đó, chúng tôi đề nghị một sự thư giãn khác biệt được cho phép tăng trưởng độ tối ưu, bỏ qua nhu cầu học tập củng cố hay thay đổi thần kinh của vận động chéo. Chúng tôi cho thấy bằng cách sửa đổi mục tiêu huấn luyện của một hệ thống hồng cầu thần kinh cạnh tranh, chúng tôi đạt được một lợi ích lớn trong khả năng đạt được. Điều này cho thấy phương pháp của chúng ta có thể được xem là một phương pháp có khả năng thay đổi sử dụng việc học củng cố hay học giả đắt tiền hơn.', 'bg': 'Метриците за оценка на кореференцията са трудни за оптимизиране директно, тъй като те са недиференцируеми функции, които не могат лесно да се разграждат в елементарни решения. Следователно повечето подходи оптимизират целите само косвено свързани с крайната цел, което води до недостатъчно представяне. Вместо това предлагаме диференцируема релаксация, която се отдава на градиентна оптимизация, като по този начин заобикаля необходимостта от усилване на обучението или евристична модификация на кръстосаната ентропия. Показваме, че чрез модифициране на тренировъчната цел на конкурентна невронна кореферентна система, получаваме значителна печалба в производителността. Това предполага, че нашият подход може да се разглежда като жизнеспособна алтернатива на използването на подсилващо обучение или по-скъпо изчислително имитиращо обучение.', 'hr': 'Metrike za procjenu korisnosti teško je optimizirati direktno jer su ne razlikujuće funkcije, ne lako se rasključiti u osnovne odluke. Stoga većina pristupa optimizira ciljeve samo indirektno povezane s ciljem kraja, što je rezultiralo podoptimalnim funkcijama. Umjesto toga, predlažemo diferencijalnu opuštenost koja se posudi optimizaciji na osnovu gradient a, tako što prelazimo potrebu za pojačanje učenja ili heurističkim modifikacijama krsno entropije. Pokazujemo da, promijenivši cilj obuke konkurentnog sustava neuralne pristojnosti, dobijamo značajnu dobit u učinkovitosti. To ukazuje na to da se naš pristup može smatrati održivim alternativom za upotrebu učenja pojačanja ili računalno skupljeg učenja imitacije.', 'da': 'Coreference evalueringsmålinger er svære at optimere direkte, da de er ikke-differentierbare funktioner, der ikke let kan nedbrydes i elementære beslutninger. De fleste tilgange optimerer derfor kun indirekte mål relateret til slutmålet, hvilket resulterer i suboptimal præstation. I stedet foreslår vi en differentierelig afslapning, der egner sig til gradient-baseret optimering og dermed omgå behovet for forstærkning af læring eller heuristisk modifikation af cross-entropi. Vi viser, at ved at ændre træningsmålet for et konkurrencedygtigt neural coreferencesystem opnår vi en betydelig præstationsgevinst. Dette tyder på, at vores tilgang kan betragtes som et levedygtigt alternativ til at bruge forstærkningslæring eller mere beregningsmæssigt dyrt efterligningslæring.', 'nl': 'Coreference evaluatiestatistieken zijn moeilijk direct te optimaliseren omdat het niet-differentieerbare functies zijn, niet gemakkelijk te decomponeren in elementaire beslissingen. Bijgevolg optimaliseren de meeste benaderingen doelstellingen slechts indirect gerelateerd aan het einddoel, wat resulteert in suboptimale prestaties. In plaats daarvan stellen we een differentieerbare ontspanning voor die zich leent voor gradiënt-gebaseerde optimalisatie, waardoor de noodzaak van versterking van leren of heuristische modificatie van cross-entropie wordt omzeild. We laten zien dat door het aanpassen van de trainingsdoelstelling van een competitief neuraal coreferentiesysteem, we een aanzienlijke verbetering in prestaties behalen. Dit suggereert dat onze aanpak kan worden beschouwd als een levensvatbaar alternatief voor het gebruik van versterking learning of meer computerdure imitatie learning.', 'fa': 'متریک ارزیابی پیشنهاد مستقیماً برای بهترین کردن عملیات غیر متفاوتی سخت است، نه به آسانی که در تصمیمات اصلی تغییر دهند. بنابراین، بیشتر دسترسی\u200cها هدف\u200cها را فقط به طور غیرمستقیم ارتباط به هدف پایان می\u200cدهند و به نتیجه عملکرد زیر optimal می\u200cرسد. به جای این، ما پیشنهاد می\u200cکنیم آرامش قابل تفاوتی که خودش را به optimization based on gradients قرض می\u200cدهد، بدین\u200cسان با تغییر نیازی برای یادگیری افزایش یا تغییر قابل توجه از متوسط انتروپی. ما نشان می دهیم که با تغییر هدف آموزش یک سیستم رقابت عصبی رقابت، ما به انجام یک سود زیادی دریافت می کنیم. این پیشنهاد می\u200cدهد که دستور ما می\u200cتواند به عنوان جایگزینی قابل قابل توجه به استفاده از یادگیری پشتیبانی یا یادگیری از طریق محاسبه\u200cهای گران\u200cتری محاسبه شود.', 'de': 'Coreferenz-Bewertungsmetriken sind schwer direkt zu optimieren, da es sich um nicht differenzierbare Funktionen handelt, die sich nicht leicht in elementare Entscheidungen zerlegen lassen. Folglich optimieren die meisten Ansätze Ziele nur indirekt, die mit dem Endziel zusammenhängen, was zu suboptimaler Leistung führt. Stattdessen schlagen wir eine differenzierbare Relaxation vor, die sich für gradientenbasierte Optimierung eignet und so die Notwendigkeit des Verstärkungslernens oder heuristischen Modifizierens der Cross-Entropie umgehen lässt. Wir zeigen, dass wir durch Modifikation des Trainingsziels eines kompetitiven neuronalen Coreferenzsystems einen erheblichen Leistungszuwachs erzielen. Dies deutet darauf hin, dass unser Ansatz als eine praktikable Alternative zum Reinforcement Learning oder dem computeraufwendigeren Nachahmenlernen angesehen werden kann.', 'ko': '공지 평가 지표는 직접적으로 최적화하기 어렵다. 왜냐하면 그들은 미함수이기 때문에 기본적인 결정으로 분해되기 어렵다.따라서 대부분의 방법은 최종 목표와 관련된 목표를 간접적으로 최적화하여 차등 성능을 초래할 뿐이다.반대로 우리는 미세한 이완 방법을 제시했는데 사다리를 바탕으로 최적화하는 데 도움이 되고 학습을 강화하거나 교차 엔트로피의 계발식 수정을 피할 수 있다.우리는 경쟁성 신경공지시스템의 훈련 목표를 수정함으로써 성능이 실질적으로 향상되었다는 것을 증명했다.이것은 우리의 방법이 학습을 강화하거나 계산 원가가 높은 모방 학습을 사용하는 실행 가능한 대체 방법으로 간주될 수 있음을 나타낸다.', 'sw': 'Utafiti wa uchunguzi wa mafanikio ni vigumu kuboresha moja kwa moja kwa sababu ni kazi zisizo tofauti, na si rahisi kuzipungua katika maamuzi ya msingi. Matokeo yake, mambo mengi yanaweza kuboresha malengo yanayohusiana moja kwa moja na lengo la mwisho, na yanasababisha utendaji wa ubora. Badala yake, tunapendekeza mapumziko yasiyo tofauti yanayojitenga na matumaini yenye msingi, kwa hiyo kupitia mahitaji ya kuuza elimu au mabadiliko ya kimapenzi ya kuingia kati. Tunaonyesha kwamba kwa kubadilisha malengo ya mafunzo ya mfumo wa ushindani wa neura, tunapata faida kubwa katika utendaji. Hii inapendekeza kwamba mbinu yetu inaweza kuchukuliwa kama mbadala yenye uwezekano wa kutumia kujifunza au kujifunza kwa gharama za uchumi.', 'sq': 'Metrikat e vlerësimit të korreferencës janë të vështira për të optimizuar drejtpërdrejt pasi ato janë funksione jo-diferenciale, jo lehtë të dekompozueshme në vendime elementare. Për shkak të kësaj, shumica e qasjeve optimizojnë objektivat vetëm në mënyrë indirekte lidhur me qëllimin përfundimtar, duke rezultuar në performancë jo optimale. Në vend të kësaj, ne propozojmë një relaksion të ndryshueshëm që i jep vetes optimizacionit bazuar në gradiente, duke shmangur kështu nevojën për forcimin e mësimit apo modifikimin heuristik të ndërentropisë. Ne tregojmë se duke modifikuar objektivin e trajnimit të një sistemi konkurrues korreference nervore, ne arrijmë një fitim thelbësor në performancë. Kjo sugjeron se qasja jonë mund të konsiderohet si një alternativë e jetueshme për përdorimin e mësimit të forcimit apo mësimit imitues më të shtrenjtë në llogari.', 'am': 'የኮርፌንስ ማስታወቂያው ማተሚያዎች በአዲስ መጀመሪያ ውይይቶች ሳይሆን በአካባቢው ውይይቶች ላይ ለማሻሻል በጣም ከባድ ነው፡፡ ስለዚህም ብዙዎቹ አቃውንቶችን በተለየ የመጨረሻው አቃውሞ ብቻ ሲያሳርፍ ይደረጋሉ፡፡ በፋንታ፣ ራሳውን ለቀዳዳሚ ምናልባት ያሳድጋል፡፡ ተግባራዊ የነዌብ የኮርፌንስ ስርዓት በማሻሻል እናሳየዋለን፡፡ ይሄ መግለጫችን ትምህርት ወይም ትምህርት በማድረግ በቁጥር የከበረ ትምህርት ለመጠቀም የሚችል መመለስ እንዲመስለው ይችላል፡፡', 'id': 'Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions.  Oleh karena itu, kebanyakan pendekatan optimisasi tujuan hanya secara indirekt berhubungan dengan tujuan akhir, yang menyebabkan prestasi suboptimal. Sebaliknya, kami mengusulkan relaxasi yang dapat dipercaya yang meminjamkan dirinya untuk optimisasi berdasarkan gradien, sehingga melewati kebutuhan untuk memperkuat belajar atau modifikasi heuristik interentropi. Kami menunjukkan bahwa dengan mengubah tujuan pelatihan sistem koreferensi saraf kompetitif, kita mendapatkan keuntungan besar dalam prestasi. Hal ini menunjukkan bahwa pendekatan kita dapat dianggap sebagai alternatif yang rentan untuk menggunakan pelajaran pemerintahan atau belajar imitasi yang lebih mahal secara komputasi.', 'hy': 'Կորեֆերենսի գնահատման մետրիկները դժվար է օպտիմացնել անմիջապես, քանի որ դրանք ոչ տարբերակելի ֆունկցիաներ են, ոչ հեշտությամբ բաժանելի են տարրական որոշումների մեջ: Հետևաբար, մոտեցումների մեծ մասը օպտիմացնում է նպատակները միայն անուղղակիորեն կապված վերջնական նպատակի հետ, ինչը հանգեցնում է ենթաօպտիմալ արդյունքների: Փոխարենը, մենք առաջարկում ենք տարբերակավոր հանգստացման, որը տալիս է ինքն իրեն աստիճանաբար հիմնված լավատեսության, այնպես խուսափելով ուսումնասիրության ուժեղացման կամ խաչը-էնտրոպիայի հորիստիկ փոփոխության կարիքը: Մենք ցույց ենք տալիս, որ փոփոխելով նյարդային համակարգի մրցակցության նպատակը, մենք նշանակալի շահույթ ենք ստանում արդյունքում: This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.', 'af': "Hoofheidsevalueringsmetries is moeilik om direk te optimaliseer as hulle nie-diferensiebaar funksies is nie, nie maklik in elementeerde besluitings te ontkoppel nie. Daarom, die meeste toegange optimaliseer die doels slegs indirekte verwante met die einde doel, wat resulteer in suboptimale prestasie. In plaas, ons voorstel 'n verskillende verlossing wat homself lê na gradient-gebaseerde optimalisasie, sodat ons die behoefte vir versterking van leer of heuristiese verandering van kruisentropie verbeter. Ons wys dat deur die oefening-doel van 'n konkurrente neurale koreferensie-stelsel te verander, ons kry 'n betekende verkry in uitvoeging. Hierdie stel voorstel dat ons toegang as 'n bepaalde alternatief kan aangesien word om versterking leer te gebruik of meer rekenasielik koste imitasie leer te gebruik.", 'bn': 'Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions.  এর ফলে বেশীরভাগ লক্ষ্য শেষ লক্ষ্যের সাথে সংশ্লিষ্ট উদ্দেশ্য সম্পর্কে সুবিচ্ছিন্ন প্রদর্শনের কারণে কাজ করে। তার পরিবর্তে আমরা একটি বিচ্ছিন্ন শান্তি প্রস্তাব করি যা নিজেকে গ্রেডিয়েন্ড ভিত্তিক আশাবাদের জন্য নিজেকে দেয়, যার ফলে ক্রস-এন্ট্রোপির শিক্ষ আমরা দেখাচ্ছি যে প্রতিযোগিতামূলক নিউরেল কোরেফেন্স সিস্টেমের প্রশিক্ষণের লক্ষ্য পরিবর্তন করার মাধ্যমে আমরা প্রদর্শন করি প্ এটি পরামর্শ দেয় যে আমাদের পদক্ষেপ বিশ্বাসযোগ্য বিকল্প হিসেবে বিবেচনা করা যায় যে শিক্ষা ব্যবহার করা বা গণতান্ত্রিক ভাবে বেশ', 'bs': 'Metrike za procjenu korisnosti su teško optimizirati direktno jer su ne razlikujuće funkcije, ne lako se rasključiti u osnovne odluke. Stoga većina pristupa optimizira ciljeve samo indirektno povezane sa ciljem kraja, što je rezultiralo podoptimalnim izvedbama. Umjesto toga, predlažemo diferencijalnu opuštenost koja se posudi optimizaciji na osnovu gradient a, tako da prelazimo potrebu za pojačanjem učenja ili heurističkim modifikacijama krsno entropije. Pokazujemo da, modificiranjem cilja obuke konkurentnog sustava neuralne koreferencije, dobijamo značajnu dobit u izvedbi. To predlaže da naš pristup može biti smatran rezultatnom alternativom za upotrebu učenja pojačanja ili računalno skupljeg učenja imitacije.', 'ca': "Les mètriques d'evaluació de la coreferència són difícils d'optimitzar directament perquè són funcions no diferenciables, no fàcilment descomposables en decisions elementars. En conseqüència, la majoria d'abords optimizen objectius només indiretament relacionats amb l'objectiu final, resultant en un rendiment subotimal. En canvi, proposem una relaxació diferenciable que es presta a l'optimisació basada en gradients, evitant així la necessitat d'aprenentatge reforçat o modificació heurística de la transentropia. Mostrem que modificant l'objectiu de formació d'un sistema competitiu de coreferència neuronal, obtenim un guany substancial en el rendiment. This suggests that our approach can be regarded as a viable alternative to using reinforcement learning or more computationally expensive imitation learning.", 'tr': 'Ýaraglar çykarmak metrikleri direkt üýtgeşik bolmadykça, birnäçe kararlara aýrylmak aňsat däl. Şol sebäpli köp golaýlar diňe soňky maksadyň üstünde gabdaly maksady optimize edýär, däl-de optimiz ukyplary bolar. Yýene-de, biz özüni farklı bir rahatlama teklip edip, Gradyýan tabanly optimizasyna kömekleýän bir rahatlama teklip edip, bu sebäpli öwrenmek üçin ýokarylyk ýöne we cross-entropiýanyň heuristik üýtgetmesi gerekli. Biz ýaryşykly näus keselleşme sistemasynyň eğitim maksadyny üýtgeden, başarylykda örän baýramyz bar. Bu biziň golaýymyzy güçlendirmek öwrenmegi ýöne ýa-da kalkular ýaly wagt imitaýýarlyk öwrenmegi ulanmak üçin täsirli bir alternatiw diýip kabul edilebilir.', 'az': 'Mərhəmət değerlendirməsi metriklərinin doğrudan fərqli olmayan funksiyalar olduğu kimi optimizlənmək çətin deyildir, əsas kararlara çəkilməyən deyildir. Buna görə də çox yaxınlıqlar məqsədiləri ancaq sonun məqsədilə haqq-hesab olaraq optimizləndirir, bu da alt optimal performans olaraq. Bunun yerinə, biz özünü gradient-based optimizasiya borc edən fərqli rahatlama təklif edirik, böylece öyrənmək və ya cross-entropiya dəyişdirmək üçün ehtiyacı yoxdur. Biz göstəririk ki, müəllif nöral rəftar sisteminin təhsil məqsədini dəyişdirərək böyük bir xeyir artırırıq. Bu, bizim metodumuzun çoxluğu öyrənmək və ya daha çox kompjuterlə çoxlu imitasyon öyrənmək üçün müvəffəqiyyətli alternatifi olaraq təmin edir.', 'cs': 'Metriky hodnocení Coreference jsou obtížné optimalizovat přímo, protože se jedná o nelišitelné funkce, které neliší snadno rozložit do základních rozhodnutí. V důsledku toho většina přístupů optimalizuje cíle pouze nepřímo související s konečným cílem, což vede k suboptimálnímu výkonu. Místo toho navrhujeme diferencovatelnou relaxaci, která se vhodně hodí k optimalizaci založené na gradientech, čímž se obejde potřeba zesílení učení nebo heuristické modifikace křížové entropie. Ukazujeme, že modifikací cíle tréninku konkurenčního neuronového coreferenčního systému dosahujeme výrazného zvýšení výkonu. To naznačuje, že náš přístup lze považovat za životaschopnou alternativu k použití zesíleného učení nebo výpočetně nákladnějšího imitačního učení.', 'et': "Coreference'i hindamismeetodeid on raske otseselt optimeerida, sest need on mittediferentseeritavad funktsioonid, mida ei ole lihtne lagundada elementaarseteks otsusteks. Sellest tulenevalt optimeerib enamik lähenemisviise eesmärke ainult kaudselt, mis on seotud lõppeesmärgiga, mille tulemuseks on ebaoptimaalne tulemus. Selle asemel pakume välja diferentseeritava lõdvestuse, mis võimaldab gradientil põhinevat optimeerimist, vältides seega vajadust tugevdada õppimist või heuristilist muutmist ristentroopia. Näitame, et konkurentsivõimelise neuraalse koreferentsussüsteemi treeningu eesmärgi muutmisega saavutame olulise tulemuslikkuse. See näitab, et meie lähenemisviisi võib pidada elujõuliseks alternatiiviks tugevdusõppe või arvutuslikult kallima imitatsiooniõppe kasutamisele.", 'fi': 'Coreference-arviointimetriikkaa on vaikea optimoida suoraan, koska ne ovat ei-eroteltavia funktioita, joita ei ole helppo hajottaa alkeellisiin päätöksiin. Näin ollen useimmat lähestymistavat optimoivat tavoitteita vain epäsuorasti, mikä johtaa epäoptimaaliseen suorituskykyyn. Sen sijaan ehdotamme eriytettävää rentoutumista, joka mahdollistaa gradienttipohjaisen optimoinnin, ohittaen siten tarpeen vahvistaa oppimista tai heuristista muuntamista ristientropiassa. Osoitamme, että muokkaamalla kilpailevan neurokoreferenssijärjestelmän koulutustavoitetta saavutamme huomattavan suorituskyvyn. Tämä viittaa siihen, että lähestymistapaamme voidaan pitää elinkelpoisena vaihtoehtona vahvistuksen oppimiselle tai laskennallisesti kalliimmalle jäljitelmäoppimiselle.', 'jv': 'iku Awak dhéwé, nggo diandelah kanggo ngerasai bukun nggawe bukun nggawe tarjamahan kanggo ngwala saiki, dadi sing wis ngerasai bukun. layers-action Awak dhéwé ngomong nik nggawe nggawe aksi iki luwih apik ning acara sistem coreferén, nik awak dhéwé kuwi nggawe barang apik dhéwé. Iki suggeruju kanggo ngerti persilangan awak dhéwé iki dadi Alternate sing beraksi nguasai sistêm nggawe layar ampuhi, lan ijol-ijolan surat sing komputer.', 'ha': "Metric evaluation na kasa nau'i dõmin a yi amfani da su dira ko da ba su zama masu yin gaɓanci ba, kuma bã da sauri na komai cikin masu saka. Saboda haka, masu yawa sunã fatan mafiya amfani da abubuwa kawai idan yana da shirin gabatar ƙarshen gabani, kuma yana ƙara da baƙaƙƙe masu kanana. Bayyan, muna goyya da wata kallafa mai rarraba ta kasancẽwa ta ƙara kansa zuwa mataimaki mai daraja, don haka kuma za mu tafi da muhimmin ƙaranci wa karantawa ko gyare-gyare na-entropy. Tuna nũna cewa, ana canza muhimmin muhimmada da ke cikin tsarin neuran da za'a sami mafiya girma a cikin aikin. Wannan yana madaidaici cewa an riya hanyarmu kamar wata matsayi mai iya amfani da amfani da zanen ƙara ko kuwa yana da mafiya kyauci na ƙidãya.", 'sk': 'Meritve vrednotenja Coreference je težko neposredno optimizirati, saj so funkcije, ki jih ni mogoče razlikovati in jih ni zlahka razgraditi v osnovne odločitve. Posledično večina pristopov optimizira cilje le posredno povezane s končnim ciljem, kar ima za posledico suboptimalno zmogljivost. Namesto tega predlagamo različljivo sprostitev, ki omogoča optimizacijo na podlagi gradienta, s čimer se izognemo potrebi po učenju ojačanja ali heuristični modifikaciji navzkrižne entropije. Pokazali smo, da s spreminjanjem cilja usposabljanja konkurenčnega nevronskega koreferenčnega sistema dosežemo znatno povečanje zmogljivosti. To kaže, da lahko naš pristop obravnavamo kot izvedljivo alternativo uporabi ojačitvenega učenja ali računalniško dražjega imitacijskega učenja.', 'he': 'קשה לאופטימליזם את מטריות הערכה של קומפרנס באופן ישיר, כיוון שהן פונקציות בלתי דיפרנציאליות, ולא בקלות להתפרק להחלטות יסודיות. כתוצאה מכך, רוב הגישויים אופטימים מטרות רק באופן לא ישיר בקשר למטרה הסופית, מה שמוביל ביצועים לא אופטימיים. במקום זה, אנו מציעים ריגוע אפשרי שילווה את עצמו לאופטימיזציה מבוססת על תדרגות, ולכן מתעלם מהצורך ללמוד חיבורי או שינוי היוריסטי של קרב אנטרופיה. אנו מראים כי על ידי שינוי מטרה האימונים של מערכת התאמה עצבית תחרותית, אנחנו מקבלים רווח משמעותי בהופעה. זה מציע שהגישה שלנו יכולה להיחשב כאלטרנטיבה חיונית לשימוש ללמוד חיבורי או ללמוד חיפוש יקר יותר.', 'bo': 'Coreference evaluation metrics are hard to optimize directly as they are non-differentiable functions, not easily decomposable into elementary decisions. དེར་བརྟེན། ཐབས་ལམ་ཆེ་ཤོས་ནི་དམིགས་ཡུལ་ནི་མི་ཐག་ཀར་འབྲེལ་བ་ཡིན་པ་ལས་ཕན་རྐྱེན་ཚད་ལྟར་སྐྱེལ། Instead, we propose a differentiable relaxation that lends itself to gradient-based optimisation, thus bypassing the need for reinforcement learning or heuristic modification of cross-entropy. འུ་ཅག་གིས་སྐྱེས་བ་སྐྱེས་པའི་གཞུང་གི་དམིགས་ཡུལ་བཟོ་བཅོས་བྱས་པ་ཡིན་ན། འུ་ཅག་གིས་རྐྱེན་སྐྱེས་ཚད་ལ་ཉེན་སྐྱེས འདིས་ང་ཚོའི་ཐབས་ལམ་ལ་ཕན་རྒྱལ་ཁབ་ཅིག་ཡིན་པར་སྤྲོད་རྒྱུ་དང་།'}
{'en': 'Neural Structural Correspondence Learning for Domain Adaptation', 'fr': "Apprentissage par correspondance structurelle neuronale pour l'adaptation", 'ar': 'التعلم بالمراسلة الهيكلية العصبية لتكييف المجال', 'pt': 'Aprendizado de correspondência estrutural neural para adaptação de domínio', 'es': 'Aprendizaje por correspondencia estructural neuronal para la adaptación de dominios', 'ja': 'ドメイン適応のための神経構造対応学習', 'zh': '应域者神经学也', 'hi': 'डोमेन अनुकूलन के लिए तंत्रिका संरचनात्मक पत्राचार सीखना', 'ru': 'Обучение нейроструктурному соответствию для адаптации домена', 'ga': 'Comhfhreagras Struchtúrtha Néarach Ag Foghlaim le hAghaidh Oiriúnú Fearainn', 'ka': 'ნეირალური სტრუქტურული კოსპონენციის სწავლება დომენის ადაპტაციისთვის', 'hu': 'Neural Structural Correspondence Learning for Domain adaptation', 'el': 'Μάθηση Νευρικής Δομικής Ανταποκρίσεως για την Προσαρμογή του Τομέα', 'it': "Imparare la corrispondenza strutturale neurale per l'adattamento del dominio", 'kk': 'Домен адаптациясы үшін нейрондық структуралық корреспонденциялық оқыту', 'lt': 'Neural Structural Correspondence Learning for Domain Adaptation', 'mk': 'Учење на нервната структурна кореспонденција за адаптација на доменот', 'ms': 'Korespondensi Struktur Neural Belajar untuk Penyesuaian Domain', 'ml': 'ഡൊമെയിന്\u200d അഡാപ്റ്റേഷന്\u200dറെ പഠനം പഠിപ്പിക്കുന്ന നെയുറല്\u200d സ്ട്രാക്ട്രൂറല്\u200d കോര്\u200dറര്\u200dസെ', 'mt': 'Tagħlim ta’ Korrispondenza Strutturali Newrali għall-Adattament tad-Dominju', 'mn': 'Цөмийн давхарлалтын мэдрэлийн бүтэц зөвшөөрөл суралцах', 'no': 'Læring av nøyrale strukturelle korespondence for domenetilpassing', 'ro': 'Învățarea corespondenței structurale neurale pentru adaptarea domeniului', 'pl': 'Nauka korespondencji strukturalnej neuronalnej dla adaptacji domen', 'si': 'ඩොමේන් අනුමාණය සඳහා නිර්මාණික සංවිධානය සම්බන්ධතාවක් ඉගෙන ගන්න', 'sr': 'Neuralna strukturna korespondencija učenje za adaptaciju domena', 'sv': 'Neural Structural Correspondence Learning for Domain Adaption', 'ur': 'ڈومین اڈپٹیٹ کے لئے نئورال ساخترال سٹرکٹورل سٹرپینڈنس سیکھنے', 'so': 'Neural Structural Correspondence Learning for Domain Adaptation', 'ta': 'டோமைன் அடிப்படைக்கு கற்றுக் கொண்டிருக்கும் நரம்பு கட்டுப்பாட்டு தொடர்பு', 'uz': 'Name', 'vi': 'Về cấu trúc thần kinh học sửa chữa miền', 'bg': 'Неврозна структурна кореспонденция за адаптация на домейна', 'da': 'Neural Structural Correspondence Learning for Domain Adaption', 'hr': 'Naučenje Neuralne strukturalne korespondence za adaptaciju domena', 'nl': 'Neuronale Structurele Correspondentie Leren voor Domeinaanpassing', 'de': 'Neuronale Strukturkorrespondenz Lernen für die Domänenanpassung', 'id': 'Korespondensi Struktur Neural Belajar untuk Adaptasi Domain', 'ko': '영역 적응에 사용되는 신경 구조 대응 학습', 'fa': 'یادگیری هماهنگی ساختار عصبی برای تغییرات دامنی', 'sw': 'Mafunzo ya Miundombinu ya Njerumani kwa ajili ya Kupitia Domain', 'af': 'Neurale strukturele korespondence leer vir domein aanpassing', 'tr': 'Etrap adaptasy üçin näsaz strukturaly gabdalyk öwrenmesi', 'sq': 'Mësimi i Korespondencës Strukturale Neurale për Adaptimin e Domenit', 'am': 'የውይይት ደረጃዎች', 'hy': 'Նյարդային կառուցվածքային համապատասխանությունը Դիպտենցիայի հարմարեցման համար սովորելը', 'az': 'Domain Adjustasyonu 칲칞칲n n칬ral Struktural 캻dar톛ti 칐yr톛nm톛si', 'bn': 'ডোমেইন অ্যাডাপ্টেশনের জন্য নিউরেল কৌশল সংস্কার শিক্ষা', 'bs': 'Naučenje Neuralne strukturalne korespondence za adaptaciju domena', 'ca': 'Neural Structural Correspondence Learning for Domain Adaptation', 'cs': 'Neurální strukturální korespondenční učení pro adaptaci domén', 'et': 'Neural Structural Correspondence Learning for Domain Adaptation', 'fi': 'Neuraalisten rakenteellisten vastaavuuksien oppiminen verkkotunnuksen mukauttamista varten', 'jv': 'structural', 'ha': 'KCharselect unicode block name', 'sk': 'Učenje nevronske strukturne korespondence za prilagajanje domeni', 'he': 'התאמה המבנית העצבית ללמוד להתאים לתחום', 'bo': 'སྲོང་ཁྱེར་གྱི་དབུས་གཞུང་དང་མཉམ་སྦྱོར་ལ།'}
{'en': 'We introduce a neural network model that marries together ideas from two prominent strands of research on domain adaptation through representation learning : structural correspondence learning (SCL, (Blitzer et al., 2006)) and autoencoder neural networks (NNs). Our model is a three-layer NN that learns to encode the non-pivot features of an input example into a low dimensional representation, so that the existence of pivot features (features that are prominent in both domains and convey useful information for the NLP task) in the example can be decoded from that representation. The low-dimensional representation is then employed in a learning algorithm for the task. Moreover, we show how to inject pre-trained word embeddings into our model in order to improve generalization across examples with similar pivot features. We experiment with the task of cross-domain sentiment classification on 16 domain pairs and show substantial improvements over strong baselines.', 'ar': 'نقدم نموذج الشبكة العصبية الذي يجمع بين الأفكار من خيطين بارزين من البحث حول التكيف مع المجال من خلال التعلم التمثيلي: التعلم بالمراسلة الهيكلية (SCL ، (Blitzer et al. ، 2006)) والشبكات العصبية للتشفير التلقائي (NNs). نموذجنا عبارة عن NN ثلاثي الطبقات يتعلم ترميز الميزات غير المحورية لمثال الإدخال إلى تمثيل منخفض الأبعاد ، بحيث يكون وجود ميزات محورية (ميزات بارزة في كلا المجالين وتنقل معلومات مفيدة لمهمة البرمجة اللغوية العصبية ) في المثال يمكن فك شفرته من هذا التمثيل. ثم يتم استخدام التمثيل منخفض الأبعاد في خوارزمية التعلم للمهمة. علاوة على ذلك ، نعرض كيفية إدخال تضمين كلمات مدربة مسبقًا في نموذجنا من أجل تحسين التعميم عبر الأمثلة ذات الميزات المحورية المماثلة. نجرب مهمة تصنيف المشاعر عبر المجالات على 16 زوجًا من المجالات ونظهر تحسينات كبيرة على خطوط الأساس القوية.', 'fr': "Nous présentons un modèle de réseau neuronal qui combine des idées issues de deux axes de recherche importants sur l'adaptation de domaines par l'apprentissage des représentations\xa0: l'apprentissage par correspondance structurelle (SCL, (Blitzer et al., 2006)) et les réseaux de neurones auto-encodeurs (NN). Notre modèle est un NN à trois couches qui apprend à coder les entités non pivot d'un exemple en entrée dans une représentation de faible dimension, de sorte que l'existence d'entités pivot (caractéristiques qui sont prédominantes dans les deux domaines et transmettent des informations utiles pour la tâche de PNL) dans l'exemple puisse être décodée à partir de cela représentation. La représentation de faible dimension est ensuite utilisée dans un algorithme d'apprentissage pour la tâche. De plus, nous montrons comment injecter des intégrations de mots préentraînées dans notre modèle afin d'améliorer la généralisation à travers des exemples présentant des caractéristiques de pivot similaires. Nous expérimentons la tâche de classification des sentiments entre domaines sur 16 paires de domaines et nous montrons des améliorations substantielles par rapport aux bases de référence solides.", 'pt': 'Apresentamos um modelo de rede neural que une ideias de duas vertentes proeminentes de pesquisa sobre adaptação de domínio por meio do aprendizado de representação: aprendizado de correspondência estrutural (SCL, (Blitzer et al., 2006)) e redes neurais autoencoder (NNs). Nosso modelo é um NN de três camadas que aprende a codificar os recursos não pivô de um exemplo de entrada em uma representação de baixa dimensão, de modo que a existência de recursos pivô (características que são proeminentes em ambos os domínios e transmitem informações úteis para a tarefa de NLP ) no exemplo pode ser decodificado a partir dessa representação. A representação de baixa dimensão é então empregada em um algoritmo de aprendizado para a tarefa. Além disso, mostramos como injetar embeddings de palavras pré-treinadas em nosso modelo para melhorar a generalização entre exemplos com recursos de pivô semelhantes. Experimentamos a tarefa de classificação de sentimento entre domínios em 16 pares de domínios e mostramos melhorias substanciais em relação a linhas de base fortes.', 'es': 'Presentamos un modelo de red neuronal que combina ideas de dos líneas prominentes de investigación sobre la adaptación de dominios a través del aprendizaje de la representación: el aprendizaje por correspondencia estructural (SCL, (Blitzer et al., 2006)) y las redes neuronales de autocodificador (NNs). Nuestro modelo es un NN de tres capas que aprende a codificar las entidades que no son de pivote de un ejemplo de entrada en una representación de baja dimensión, de modo que la existencia de entidades de pivote (características que son prominentes en ambos dominios y que transmiten información útil para la tarea de PNL) en el ejemplo se puede decodificar a partir de eso representación. La representación de baja dimensión se emplea luego en un algoritmo de aprendizaje para la tarea. Además, mostramos cómo inyectar incrustaciones de palabras previamente entrenadas en nuestro modelo para mejorar la generalización en los ejemplos con características de pivote similares. Experimentamos con la tarea de la clasificación de sentimientos entre dominios en 16 pares de dominios y mostramos mejoras sustanciales con respecto a líneas de base sólidas.', 'ja': '表現学習を通じた領域適応に関する2つの著名な研究分野：構造的対応学習（ SCL、（ Blitzer et al., 2006 ） ）とオートエンコーダーニューラルネットワーク（ NNs ）のアイデアを組み合わせたニューラルネットワークモデルを紹介する。我々のモデルは、入力例の非ピボット特徴を低次元表現に符号化することを学習する3層NNであり、そのため、例におけるピボット特徴（両方のドメインで顕著であり、NLPタスクの有用な情報を伝達する特徴）の存在をその表現から復号することができる。次いで、低次元表現は、タスクのための学習アルゴリズムで用いられる。さらに、同様のピボット機能を持つ例全体の一般化を改善するために、事前にトレーニングされた単語埋め込みをモデルにインジェクションする方法を示します。我々は、16個のドメイン対でのクロスドメインセンチメント分類のタスクを実験し、強力なベースラインにわたって実質的な改善を示した。', 'hi': 'हम एक तंत्रिका नेटवर्क मॉडल पेश करते हैं जो प्रतिनिधित्व सीखने के माध्यम से डोमेन अनुकूलन पर अनुसंधान के दो प्रमुख किस्में से एक साथ विचारों से शादी करता है: संरचनात्मक पत्राचार सीखने (एससीएल, (ब्लिट्जर एट अल। हमारा मॉडल एक तीन-परत एनएन है जो इनपुट उदाहरण की गैर-धुरी विशेषताओं को कम आयामी प्रतिनिधित्व में एन्कोड करना सीखता है, ताकि पिवट सुविधाओं (विशेषताएं जो दोनों डोमेन में प्रमुख हैं और एनएलपी कार्य के लिए उपयोगी जानकारी प्रदान करती हैं) के अस्तित्व को उस प्रतिनिधित्व से डिकोड किया जा सकता है। निम्न-आयामी प्रतिनिधित्व तब कार्य के लिए एक सीखने के एल्गोरिथ्म में नियोजित किया जाता है। इसके अलावा, हम दिखाते हैं कि समान धुरी सुविधाओं के साथ उदाहरणों में सामान्यीकरण में सुधार करने के लिए हमारे मॉडल में पूर्व-प्रशिक्षित शब्द एम्बेडिंग को कैसे इंजेक्ट किया जाए। हम 16 डोमेन जोड़े पर क्रॉस-डोमेन भावना वर्गीकरण के कार्य के साथ प्रयोग करते हैं और मजबूत बेसलाइन पर पर्याप्त सुधार दिखाते हैं।', 'zh': '引入一神经网络,以表征学,将合于二异之域:曰学(SCL,曰(Blitzer,曰2006)),曰编码器神经网络(NN)。 吾模一三层 NN,其学将输示例者非透视特徵编码为低维,以从其中解码出数透视(于两域中皆特徵为 NLP 传信)存焉。 然后示低维以学算法。 何以明其先训之词,以善类透视之示例泛化。 试 16 个域跨域情类,示出比强基线实质性改。', 'ru': 'Мы вводим модель нейронной сети, которая объединяет идеи из двух известных направлений исследований по адаптации домена посредством репрезентативного обучения: структурного обучения соответствию (SCL, (Blitzer et al., 2006)) и нейронных сетей автокодера (NNs). Наша модель представляет собой трехслойную NN, которая учится кодировать несравнительные признаки входного примера в низкомерное представление, так что существование поворотных признаков (признаков, которые видны в обеих областях и передают полезную информацию для задачи NLP) в примере может быть декодировано из этого представления. Низкоразмерное представление затем используется в алгоритме обучения для задачи. Кроме того, мы показываем, как вводить предварительно обученные вложения слов в нашу модель, чтобы улучшить обобщение между примерами с аналогичными функциями поворота. Мы экспериментируем с задачей междоменной классификации настроений на 16 парах доменов и демонстрируем существенные улучшения по сравнению с сильными базовыми линиями.', 'ga': 'Tugaimid isteach samhail líonra néarúil a nascann smaointe le chéile ó dhá shraith shuntasacha taighde ar oiriúnú fearainn trí fhoghlaim ionadaíochta: foghlaim struchtúrach comhfhreagrais (SCL, (Blitzer et al., 2006)) agus líonraí néaracha uath-ionchódóra (NNs). Is é ár múnla ná NN trí chiseal a fhoghlaimíonn conas gnéithe neamh-mhaighde sampla ionchuir a ionchódú i léiriú ísealthoiseach, ionas go mbeidh gnéithe maighdeog ann (gnéithe atá feiceálach sa dá fhearann agus a thugann faisnéis úsáideach don tasc NLP ) sa sampla is féidir é a dhíchódú ón léiriú sin. Úsáidtear an léiriú ísealtoiseach ansin in algartam foghlama don tasc. Ina theannta sin, léirímid conas leabaithe focal réamhoilte a instealladh isteach inár múnla chun ginearálú a fheabhsú ar fud samplaí le gnéithe maighdeogacha comhchosúla. Déanaimid turgnaimh leis an tasc a bhaineann le haicmiú tuairimí tras-fearainn ar 16 phéire fearainn agus léirímid feabhsuithe suntasacha thar bhunlínte láidre.', 'ka': 'ჩვენ შევცვალოთ ნეიროლური ქსელის მოდელი, რომელიც ორი მნიშვნელოვანი კონფიგურაციის შესახებ დემომინის ადაპექტირების კონფიგურაციის ორივე მნიშვნელოვანი კონფიგურაციის შესახებ განსწავლა: სტრუქ ჩვენი მოდელი არის სამი წერტილის NN, რომელიც ვისწავლის, რომ გავაკეთოთ მინუს განზომილებული გამოსახულებაში ჩვენი გამოსახულებელი ფუნქციების კოდირება, რადგან pivot ფუნქციების არსებობა (ფუნქციები, რომელიც ორივე დიომენში მნიშვნელოვანია და NLP დაბალი განზომილებული გამოსახულება შემდეგ იყენება სწავლების ალგორიტიმში. დამატებით, ჩვენ ჩვენ ჩვენი მოდელში როგორ დავიწყებთ საწყისო სიტყვები, როგორ დავიწყებთ ჩვენი მოდელში, როგორ დავიწყებთ გენერალიზაციას მაგალითად, როგ ჩვენ ექსპერიმენტებით გავაკეთებთ საკუთარი სენტიმენტების კლასიფიკაციაზე 16 დომინის კომპორტებით და გამოჩვენებთ მნიშვნელოვანი უფრო მეტადება ძალიან', 'hu': 'Bemutatunk egy neurális hálózati modellt, amely összekapcsolja a domain adaptációval kapcsolatos két kiemelkedő kutatási szál ötleteit a reprezentációs tanuláson keresztül: strukturális korrespondancia tanulás (SCL, (Blitzer et al., 2006)) és autoencoder neurális hálózatok (NNs). Modellünk egy három rétegű NN, amely megtanulja egy bemeneti példa nem pivot jellemzőit alacsony dimenziós ábrázolásba kódolni, így a pivot jellemzők létezése (amelyek mindkét tartományban kiemelkedőek és hasznos információkat közvetítenek az NLP feladathoz) a példában dekódolható abból a ábrázolásból. Az alacsony dimenziós ábrázolást ezután egy tanulási algoritmusban alkalmazzák a feladathoz. Ezenkívül megmutatjuk, hogyan fecskendezhetünk be előre képzett szóbeágyazásokat modellünkbe, hogy javítsuk a hasonló pivot funkciókkal rendelkező példák általánosítását. 16 domain páron kísérletezünk a cross-domain sentiment osztályozás feladatával, és jelentős javulást mutatunk az erős alapokhoz képest.', 'el': 'Παρουσιάζουμε ένα μοντέλο νευρωνικού δικτύου που συνδυάζει ιδέες από δύο εξέχουσες πτυχές της έρευνας σχετικά με την προσαρμογή του τομέα μέσω της εκμάθησης αναπαράστασης: τη μάθηση δομικής αλληλογραφίας (και τα νευρωνικά δίκτυα αυτοκωδικοποιητών). Το μοντέλο μας είναι ένα τριστρωματικό NN που μαθαίνει να κωδικοποιεί τα χαρακτηριστικά μη περιστροφής ενός παραδείγματος εισόδου σε μια αναπαράσταση χαμηλής διαστάσεων, έτσι ώστε η ύπαρξη χαρακτηριστικών περιστροφής (χαρακτηριστικά που είναι εμφανή και στους δύο τομείς και μεταφέρουν χρήσιμες πληροφορίες για την εργασία στο παράδειγμα μπορεί να αποκωδικοποιηθεί από αυτή την αναπαράσταση. Η χαμηλής διαστάσεων αναπαράσταση χρησιμοποιείται στη συνέχεια σε έναν αλγόριθμο μάθησης για την εργασία. Επιπλέον, δείχνουμε πώς να εισάγουμε προ-εκπαιδευμένες ενσωματώσεις λέξεων στο μοντέλο μας προκειμένου να βελτιωθεί η γενίκευση σε παραδείγματα με παρόμοια χαρακτηριστικά περιστροφής. Πειραματιζόμαστε με το καθήκον της ταξινόμησης συναισθημάτων μεταξύ των τομέων σε 16 ζεύγη τομέων και εμφανίζουμε σημαντικές βελτιώσεις σε σχέση με ισχυρές γραμμές βάσης.', 'it': "Introducemo un modello di rete neurale che unisce idee provenienti da due filoni importanti di ricerca sull'adattamento del dominio attraverso l'apprendimento della rappresentazione: l'apprendimento della corrispondenza strutturale (SCL, (Blitzer et al., 2006)) e le reti neurali autocodificatrici (NNs). Il nostro modello è un NN a tre livelli che impara a codificare le caratteristiche non pivot di un esempio di input in una rappresentazione a bassa dimensione, in modo che l'esistenza di caratteristiche pivot (caratteristiche che sono prominenti in entrambi i domini e trasmettono informazioni utili per l'attività NLP) nell'esempio possa essere decodificata da tale rappresentazione. La rappresentazione a bassa dimensione viene quindi impiegata in un algoritmo di apprendimento per il compito. Inoltre, mostriamo come iniettare incorporazioni di parole pre-addestrate nel nostro modello al fine di migliorare la generalizzazione tra esempi con caratteristiche pivot simili. Sperimentiamo il compito di classificazione dei sentiment cross-domain su 16 coppie di domini e mostriamo miglioramenti sostanziali rispetto a linee di base forti.", 'mk': 'Ние воведуваме модел на нервната мрежа кој се венча со идеи од две истражувања за адаптација на доменот преку учење на претставништво: структурно учење на кореспонденција (СКЛ, (Блицер и ал., 2006)) и автокодерски нервни мрежи (ННС). Нашиот модел е трислоевен НН кој научи да ги кодира невртените карактеристики на примерот на внесување во ниска димензионална претстава, така што постоењето на вртените карактеристики (карактеристики кои се истакнати во двата домени и пренесуваат корисни информации за задачата НЛП) во примерот може да биде декодирано од таа претстава. Нискодимензионалната претстава потоа се користи во алгоритм за учење за задачата. Покрај тоа, покажуваме како да инјектираме предобучени зборови во нашиот модел со цел да ја подобриме генерализацијата на примерите со слични обратни карактеристики. Експериментираме со задачата на крстодоменска класификација на чувства на 16 домени парови и покажуваме значителни подобрувања во однос на силните бази.', 'lt': 'Įdiegiame nervų tinklo model į, kuris sujungia idėjas iš dviejų svarbių srities prisitaikymo mokslinių tyrimų, pasitelkiant atstovavimo mokymąsi: struktūrinį korespondencijos mokymąsi (SCL, (Blitzer et al., 2006)) ir savikodifikatorių nervų tinklus (NNs). Mūsų model is yra trijų sluoksnių NN, kuris išmoko koduoti ne apsisukančius įvedimo pavyzdžio požymius į mažo matmens pavyzdį, kad pavyzdyje būtų galima dekoderuoti apsisukančių požymių (požymių, kurie yra akivaizdūs abiejose srityse ir perduoda naudingą informaciją NLP užduotims) egzistavimą. Tuomet mažo matmens atstovavimas naudojamas mokymosi algoritme užduočiai atlikti. Moreover, we show how to inject pre-trained word embeddings into our model in order to improve generalization across examples with similar pivot features.  Eksperimentuojame su 16 domenų poros tarpdomeninio jautrumo klasifikavimo užduotimi ir parodome esminius patobulinimus, palyginti su stipriomis bazinėmis linijomis.', 'ms': 'Kami memperkenalkan model rangkaian saraf yang berkahwin dengan idea-idea dari dua garis penelitian terkenal mengenai penyesuaian domain melalui pembelajaran perwakilan: pembelajaran korespondenci struktur (SCL, (Blitzer et al., 2006)) dan rangkaian saraf auto-pengekod (NNs). Model kami adalah NN bertiga lapisan yang belajar untuk mengekod ciri-ciri bukan-pivot contoh input ke dalam mewakili dimensi rendah, sehingga wujud ciri-ciri pivot (ciri-ciri yang terkenal dalam kedua-dua domain dan menyebarkan maklumat berguna untuk tugas NLP) dalam contoh boleh disekod dari mewakili itu. Perwakilan dimensi rendah kemudian digunakan dalam algoritma pembelajaran untuk tugas. Selain itu, kita menunjukkan bagaimana untuk menyuntik penyelesaian kata-kata terlatih-terlatih ke dalam model kita untuk meningkatkan keseluruhan melalui contoh-contoh dengan ciri-ciri pivot yang sama. Kami eksperimen dengan tugas klasifikasi sentimen cross-domain pada 16 pasangan domain dan menunjukkan peningkatan yang besar atas garis dasar yang kuat.', 'mt': 'Aħna nintroduċu mudell tan-netwerk newrali li jgħaqqad ideat minn żewġ oqsma prominenti ta’ riċerka dwar l-adattament tad-dominju permezz tat-tagħlim tar-rappreżentanza: tagħlim tal-korrispondenza strutturali (SCL, (Blitzer et al., 2006)) u netwerks newrali awtokoders (NNs). Il-mudell tagħna huwa NN bi tliet saffi li jitgħallem jikkodifika l-karatteristiċi mhux pivoti ta’ eżempju ta’ input f’rappreżentanza dimensjonali baxxa, sabiex l-eżistenza ta’ karatteristiċi pivoti (karatteristiċi li huma prominenti fiż-żewġ oqsma u li jgħaddu informazzjoni utli għall-kompitu NLP) fl-eżempju tkun tista’ tiġi dekodifikata minn dik ir-rappreżentanza. Ir-rappreżentanza dimensjonali baxxa mbagħad tintuża f’algoritmu ta’ tagħlim għall-kompitu. Barra minn hekk, aħna nuru kif ninjettaw inkorporazzjonijiet ta’ kliem imħarrġa minn qabel fil-mudell tagħna sabiex tittejjeb il-ġeneralizzazzjoni fost eżempji b’karatteristiċi pivoti simili. Aħna ninsperimentaw bil-kompitu tal-klassifikazzjoni tas-sentimenti bejn id-dominji fuq 16-il par ta’ dominji u nuru titjib sostanzjali fuq linji bażi b’saħħithom.', 'mn': 'Бид мэдрэлийн сүлжээний загварыг танилцуулж, холбоотой адилтгал судалгааны хоёр чухал хэлбэрээс холбогдсон санаануудыг үзүүлэх сургалтын аргаар, бүтэц харилцааны суралцах сургалт (SCL, (Blitzer et al., 2006)) болон автокодлогч мэдрэли Бидний загвар бол гурван давхар NN юм. Бидний оролцох жишээ нь бага хэмжээст үзүүлэлт рүү шилжүүлэхийг сурсан. Тиймээс жишээ нь pivot боломжуудын байр суурь (хоёр дотор чухал бөгөөд NLP ажил дээр хэрэгтэй мэдээлэл өгөх боломжтой) юм. Бага хэмжээст үзүүлэлт нь ажлын тулд суралцах алгоритмд ажилладаг. Мөн бид өөрсдийн загвар руу сургалтын өмнө сургалтын үгийг хэрхэн инжекци хийх вэ гэдгийг харуулж байна. Бид 16 холбоотой холбоотой мэдрэмжтэй хуваалцааны ажил дээр туршилт хийж, хүчтэй суурь шугам дээр маш их сайжруулалтыг харуулж байна.', 'no': 'Vi introduserer eit neuralnettverksmodell som møtar idear sammen frå to viktige strekar av forskning om domeneadaptasjon gjennom læring av representasjon: strukturelle tilsvarande læring (SCL, (Blitzer et al., 2006)) og autokoding av neuralnettverk (NNs). Modellen vårt er eit trelag NN som lærer å koda ikkje-pivot-funksjonane til eit låg dimensjonal representasjon, slik at eksisterende av pivot-funksjonane (funksjonane som er viktige i både domene og gjere nyttig informasjon for NLP-oppgåva) i eksemplet kan dekode frå denne representasjonen. Det lavdimensjonale representasjonen er derfor arbeida i ein læringsalgoritme for oppgåva. I tillegg viser vi korleis det skal injiserast først trengte ordinnbygging i modellen vårt for å forbetra generellisering i eksemplar med liknande pivotfunksjonar. Vi eksperimenterer med oppgåva til å klassifisera krysdomenesentimentar på 16 domenepar og vise substantielle forbedringar over sterke baselinjer.', 'pl': 'Wprowadzamy model sieci neuronowej, który łączy pomysły z dwóch ważnych kierunków badań nad adaptacją domen poprzez uczenie się reprezentacji: uczenie się korespondencji strukturalnej (SCL, (Blitzer et al., 2006)) i sieci neuronowe autokoderów (NN). Nasz model jest trójwarstwowym NN, który uczy się kodować cechy nieobrotowe przykładu wejściowego do reprezentacji niskowymiarowej, dzięki czemu istnienie cech obrotowych (cech, które są widoczne w obu domenach i przekazują przydatne informacje dla zadania NLP) w przykładzie można dekodować z tej reprezentacji. Reprezentacja niskowymiarowa jest następnie wykorzystywana w algorytmie uczenia się do zadania. Ponadto pokazujemy, jak wstrzykiwać wstępnie przeszkolone osadzenia słów w naszym modelu w celu poprawy uogólnienia wśród przykładów o podobnych funkcjach pivot. Eksperymentujemy z zadaniem klasyfikacji sentymentów między domenami na 16-tych parach domen i pokazujemy znaczne poprawy nad silnymi liniami bazowymi.', 'ro': 'Introducem un model de rețea neurală care combină idei din două fire proeminente de cercetare privind adaptarea domeniului prin învățarea reprezentării: învățarea corespondenței structurale (SCL, (Blitzer et al., 2006)) și rețelele neurale autoencoder (NNs). Modelul nostru este un NN cu trei straturi care învață să codeze caracteristicile non-pivot ale unui exemplu de intrare într-o reprezentare dimensională joasă, astfel încât existența caracteristicilor pivot (caracteristici care sunt proeminente în ambele domenii și transmit informații utile pentru sarcina NLP) în exemplu să poată fi decodată din acea reprezentare. Reprezentarea dimensională joasă este apoi folosită într-un algoritm de învățare pentru sarcină. Mai mult decât atât, arătăm cum să injectăm încorporări de cuvinte pre-instruite în modelul nostru pentru a îmbunătăți generalizarea în exemple cu caracteristici pivot similare. Experimentăm sarcina clasificării sentimentului cross-domain pe 16 perechi de domenii și prezentăm îmbunătățiri substanțiale față de liniile de bază puternice.', 'kk': 'Біз домен адаптациясының екі көмегімен зерттеу үшін идеяларды біріктіретін невралдық желінің моделін келтіреміз: структуралық корреспонденттердің оқытуы (SCL, (Blitzer et al., 2006)) және автокодер невралдық желілері (NNs). Біздің үш қабатты NN деген үш қабатты. Мысалы, келтірілген мәселелердің pivot емес қасиеттерін төмен өлшемі деңгейіне кодтау үшін үйренеді, сондықтан pivot мүмкіндіктері (екі доменде мәліметтер болып, NLP тапсырмасының пайдалы мәліметін беру үшін)  Төмен өлшемді тапсырманың алгоритмінде қолданылады. Осымен қатар, біз өзіміздің моделімізге алдын- ала оқылған сөздерді ендіру үшін жалпы мәселелерді жақсарту үшін көрсетедік. Біз 16 доменге көпшілік көпшілік көпшілік көпшілікті шектеу тапсырмасын тәжірибеп, күшті негізгі сызықтардың көпшілікті жақсартуларын көр', 'si': 'අපි ප්\u200dරධානය කරන්නේ නියරුල් ජාල ප්\u200dරමාණයක් සම්බන්ධ විදිහට අදහස් දෙකක් ප්\u200dරධානයක් පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා අදහස් කරනවා: ස්ථානය සම්බ අපේ මොඩේලය තමයි ප්\u200dරතිශාල NN තුනක් ස්ථානයක් ඉගෙන ගන්නේ නොපිවෝට් වර්ගයක් නොපිවෝට් වර්ගයක් නොපිවෝට් වර්ගයක් ප්\u200dරතිශේෂණයෙන්, ඉදිරියට පිවෝට් වර්ගයක් තිය අඩුම අභ්\u200dයාගයක් ප්\u200dරතිනිධානය වෙනුවෙන් ඉගෙන ගන්න ඇල්ගෝරිතම් වලින් වැඩ කරන්නේ. තවත්, අපි පෙන්වන්නේ කොහොමද ප්\u200dරධානය කරලා තියෙන්නේ ප්\u200dරධානය කරලා තියෙන්නේ කියලා අපේ මොඩේල් එක්ක සාමාන්\u200dය විශ අපි පරීක්ෂණය කරන්නේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්නයක් වෙනුවෙන් ප්\u200dරශ්න', 'sr': 'Predstavljamo model neuralne mreže koji se udaje zajedno za ideje iz dve značajne strane istraživanja o adaptaciji domena putem učenja predstavljanja: učenje strukturnih dopisnika (SCL, (Blitzer et al., 2006)) i autokodiranja neuralnih mreža (NNs). Naš model je trosloj NN koji nauèi da kodira neopivotne karakteristike unutarnjeg primjera u nisku dimenzionalnu predstavu, tako da postojanje pivotskih karakteristika (karakteristika koje su poznati u oba domena i prenose korisne informacije za zadatak NLP) na primjer može biti dekodirana iz te predstave. Niska dimenzionalna predstavljanja je onda zaposlena u algoritmu učenja za zadatak. Osim toga, pokazujemo kako da ubacimo predobučene reči u naš model kako bi poboljšali generalizaciju na primjere sa sličnim karakteristikama pivota. Eksperimentiramo sa zadatkom klasifikacije krstodomena sentimenta na 16 domena pare i pokazujemo značajne poboljšanje nad jakim osnovnim linijama.', 'ml': 'We introduce a neural network model that marries together ideas from two prominent strands of research on domain adaptation through representation learning: structural correspondence learning (SCL, (Blitzer et al., 2006)) and autoencoder neural networks (NNs).  നമ്മുടെ മോഡല്\u200d ഒരു മൂന്ന് ലേഡ് NN എന്നാണ്. അതിന്റെ ഉദാഹരണത്തിന്റെ ഇന്\u200dപുട്ടിന്റെ പ്രതിനിധികള്\u200d കുറഞ്ഞ ഡിമിനഷന്\u200d പ്രതിനിധിയിലാക്കാന്\u200d പഠിക്കുന്നു. അതുകൊണ്ട് പിവോട്ട് പ്രധാനപ്പെട The low-dimensional representation is then employed in a learning algorithm for the task.  പിന്നെയും നമ്മുടെ മോഡലിലേക്ക് മുന്\u200dപരിശീലന വാക്കുകള്\u200d പ്രവേശിപ്പിക്കുന്നത് എങ്ങനെയാണെന്ന് ഞങ്ങള്\u200d കാണിച്ചു തരുന്നു. ഇതുപ 16 ഡൊമെയിന്\u200d ജോടികളില്\u200d ക്ലാസ്ഫിക്ഷന്\u200d ചെയ്യുന്ന ജോലിയുടെ ജോലിയാല്\u200d ഞങ്ങള്\u200d പരീക്ഷിക്കുകയും, ശക്തിയുള്ള ബെസ്റ്റ', 'ta': 'நாம் ஒரு புதிய வலைப்பின்னல் மாதிரி முறைமையை குறிப்பிட்டுக் கொண்டு திருமணம் செய்து கொள்ளும் இரண்டு பிரகாசமான துண்டுகளிலிருந்து உள்ள ஆராய்ச்சிகளை திருமணம் ச எங்கள் மாதிரி என்பது ஒரு மூன்று அடுக்கு என்ன். உதாரணத்திற்கு ஒரு உள்ளீட்டு குறைந்த பரிமாற்றத்தை குறியீடாக்க கற்றுக் கொள்ள கற்றுக் கொண்டுள்ளது, அதனால் பைவோட் குணங்கள் இருக்கும் (இரு களங்களி குறைந்த பரிமாற்றத்திற்கு பின்னர் பணிக்கான கற்றுக்கொள்ளும் கல்வியலில் வேலை செய்யப்படுகிறது. மேலும், முன் பயிற்சி செய்யப்பட்ட வார்த்தைகளை எங்கள் மாதிரியில் சுருக்குவது எப்படி செய்ய வேண்டும் என்பதை காட்டுகிறோம் ப நாம் 16 டொமைன் ஜோடிகள் மீது சிறப்பு உணர்வு வகைப்படுத்தல் செயல்களை பரிசோதிக்கிறோம் மற்றும் வலிமை அடிப்படைக்கோடுகளில்', 'sv': 'Vi introducerar en neural nätverksmodell som förenar idéer från två framstående forskningsområden kring domänanpassning genom representationslärande: strukturell korrespondensinlärning (SCL, (Blitzer et al., 2006)) och autoencoder neurala nätverk (NNs). Vår modell är en trelagers NN som lär sig koda icke-pivot-funktionerna i ett inmatningsexempel till en lågdimensionell representation, så att förekomsten av pivot-funktioner (funktioner som är framträdande i båda domänerna och förmedlar användbar information för NLP-uppgiften) i exemplet kan avkodas från den representationen. Den lågdimensionella representationen används sedan i en inlärningsalgoritm för uppgiften. Dessutom visar vi hur man injicerar pre-utbildade ordinbäddningar i vår modell för att förbättra generaliseringen över exempel med liknande pivotfunktioner. Vi experimenterar med uppgiften att klassificera sentiment över domäner på 16 domänpar och visar betydande förbättringar jämfört med starka baslinjer.', 'so': 'Tusaale shabakadda neurada ah oo isku guurinaya fikrada labada xadhig oo caadiga ah oo ku saabsan bedelka deegaanka, waxaynu ku soo bandhignaa waxbarashada sharciga: barashada dhismaha iskuulka ah (SCL, (Blitzer et al., 2006)) iyo shabakadaha neurada ah (NNs). Tusaale ahaan waa qoraal sadex-layer NN oo ku barta in lagu koobo tusaale ahaan wax lagu qorayo tusaale ahaan mid hoos u eg, si ay u jirto muuqashada hiwaayadaha pivot (xuquuqda muuqata labada meelood ku jirta iyo in lagu sheego macluumaad faa’iido leh ee shaqada NLP) tusaale ahaan looga koobi karo wakiilkaas. The low-dimensional representation is then employed in a learning algorithm for the task.  Sidoo kale waxaynu tusnaynaa sidoo kale ku sawiraa hadalka horay loo tababaray, si aan u beddelno dhalashada tusaalooyin la mid ah oo la mid ah pivot. Waxaynu ku tijaabinaynaa shaqada fasaxa dareemaha ee gudaha ku yaala 16 labo, waxaana tusaynaa horumarinta ugu badnaanta aasaaska xoogga leh.', 'ur': 'ہم ایک نئورل نیٹورک موڈل کو معلوم کرتے ہیں جو دومین کی تعلیم کے معاملہ میں دو معرفی طریقے سے آزمائش کی نظریوں سے ملتے ہیں: ساخترکی تعلیم کی تعلیم (SCL, (Blitzer et al., 2006)) اور اتوکوڈر نیٹورل نیٹورک (NN) کے ذریعہ۔ ہمارا مدل ایک تین لائر NN ہے جو ایک اینپیوٹ مثال کے غیر پیوٹ ویٹی ویٹیوں کو کم اندازے کی نمونش میں کوڈ کرنا سکھاتا ہے تاکہ پیوٹ ویٹیوں کی موجود ہوتی ہے (جو دونوں ڈمین میں اظہار ہیں اور NLP تابع کے لئے فائدہ معلومات پہنچا سکتی ہے) مثال میں اس نمونش سے دکوڈ کر دیا جائے۔ نیچے اندازے کی تعلیم اس کے بعد کام کے لئے ایک تعلیم الگوریتم میں استعمال کیا جاتا ہے. اور ہم دکھاتے ہیں کہ ہمارے مدل میں پہلے تدریس کی لفظ کیسے انڈینگ کریں تاکہ اس طرح جیسے پیوٹ ویٹ ویٹیوں کے ساتھ عمومی تدریج کے ساتھ اضافہ کریں۔ ہم 16 ڈومین جوڑوں پر cross-domain sentiment classification کے کام کے ذریعے آزمائش کرتے ہیں اور مضبوط بنسس لینوں پر بہت اچھے سوداگری دکھاتے ہیں.', 'uz': "Biz bir neyrol tarmoq modelini anglatamiz, bu dodomen adapterini tahrirlash orqali ikkita murakkab o'rganishni o'rganish orqali o'ylab beradi: struktural qismi o'rganish (SCL, (Blitzer et, 2006)) va avtomatik neyrol tarmoqlari (NNs). Bizning modelimizning 3 daraja NN, bir misol, o'sha tashkilotni kichkina cheksiz namoyishga kodlash imkoniyatlarini o'rganadi, shunday qilib pivot xossalarining mavjudligi (xossalari buyruq va NLP vazifasi uchun foydali maʼlumot yozib olish mumkin) masalan, bu tashkilotdan kodlash mumkin. Keyin bu vazifa uchun o'rganish algoritga ishlaydi. Ko'rib, biz birinchi o'rganilgan so'zlarni modelimizga kiritishni ko'rsatdik. Bu misollarni o'xshash pivot xususiyatlariga o'zgartirish mumkin. Biz 16 domen qo'llarini o'rganish vazifasini o'rganamiz va ko'proq asboblarga katta yaxshi o'zgarishni ko'rsamiz.", 'vi': 'Chúng tôi giới thiệu một mô hình mạng thần kinh kết hợp các ý tưởng từ hai bộ phận quan trọng của nghiên cứu về thích ứng miền qua sự phân biệt: học về kết quả cấu trúc tương ứng (SCL (Blitzer et al., 2001) và mạng thần kinh tự mã (NNs). Mẫu của chúng tôi là một NNn ba lớp học cách mã hóa các tính năng không pivot của một ví dụ nhập vào một mô tả không gian thấp, để sự tồn tại các tính năng pivot (tính năng nổi bật trong cả hai miền và truyền tải thông tin hữu ích cho nhiệm vụ NLP) trong ví dụ có thể được giải mã từ đại diện đó. Việc diễn tả chiều thấp được sử dụng trong thuật toán học cho nhiệm vụ. Hơn nữa, chúng tôi chỉ ra cách tiêm những từ được đào tạo vào mẫu của chúng tôi để cải thiện sự tổng hợp các ví dụ với các tính năng xoay chuyển tương tự. Chúng tôi thử nghiệm với nhiệm vụ phân loại cảm xúc xuyên lục địa trên các cặp miền 16 và hiển thị những cải tiến đáng kể trên các nền tảng vững chắc.', 'bg': 'Въвеждаме модел на невронна мрежа, който съчетава идеи от две видни направления на изследванията за адаптация на домейна чрез изучаване на репрезентацията: структурно кореспондентно обучение (Блицер и др., 2006) и автокодиращи невронни мрежи (НН). Нашият модел е трислоен НН, който се научава да кодира характеристиките без пивот на входен пример в нискоизмерно представяне, така че съществуването на пивот функции (функции, които са видни и в двете области и предават полезна информация за задачата) в примера може да бъде декодирано от това представяне. След това нискоизмерното представяне се използва в алгоритъм за обучение за задачата. Освен това показваме как да инжектираме предварително обучени вграждания на думи в нашия модел, за да подобрим обобщението в примери с подобни функции на въртене. Експериментираме със задачата за междудомейнна класификация на сентименти върху 16 двойки домейни и показваме значителни подобрения спрямо силните базови линии.', 'nl': "We introduceren een neuraal netwerkmodel dat ideeën combineert uit twee prominente onderzoekslijnen over domeinadaptatie door representatie learning: structurele correspondentie learning (SCL, (Blitzer et al., 2006)) en autoencoder neurale netwerken (NN's). Ons model is een drielaagse NN die leert om de niet-pivot kenmerken van een invoervoorbeeld te coderen in een laagdimensionale weergave, zodat het bestaan van pivot kenmerken (kenmerken die prominent zijn in beide domeinen en nuttige informatie overbrengen voor de NLP taak) in het voorbeeld kan worden gedecodeerd van die weergave. De laagdimensionale weergave wordt vervolgens gebruikt in een leeralgoritme voor de taak. Bovendien laten we zien hoe je vooraf getrainde woord embeddings in ons model kunt injecteren om de generalisatie in voorbeelden met vergelijkbare pivot functies te verbeteren. We experimenteren met de taak van domeinoverschrijdende sentimentclassificatie op 16-domeinparen en laten substantiële verbeteringen zien ten opzichte van sterke baselines.", 'da': 'Vi introducerer en neural netværksmodel, der forener ideer fra to fremtrædende strenge af forskning om domænetilpasning gennem repræsentation learning: strukturel korrespondance learning (SCL, (Blitzer et al., 2006)) og autoencoder neurale netværk (NNs). Vores model er en tre-lags NN, der lærer at kode ikke-pivot funktioner i et input eksempel til en lav dimensionel repræsentation, så eksistensen af pivot funktioner (funktioner, der er fremtrædende i begge domæner og formidler nyttige oplysninger til NLP-opgaven) i eksemplet kan afkodes fra denne repræsentation. Den lavdimensionelle repræsentation anvendes derefter i en læringsalgoritme til opgaven. Desuden viser vi, hvordan man injicerer præ-trænede ord indlejringer i vores model for at forbedre generaliseringen på tværs af eksempler med lignende pivot funktioner. Vi eksperimenterer med opgaven med cross-domain sentiment klassificering på 16 domænepar og viser betydelige forbedringer i forhold til stærke basislinjer.', 'de': 'Wir stellen ein neuronales Netzwerkmodell vor, das Ideen aus zwei prominenten Forschungssträngen zur Domänenanpassung durch Repräsentationslernen zusammenführt: Strukturelles Korrespondenzlernen (SCL, (Blitzer et al., 2006)) und Autoencoder Neuronale Netze (NNs). Unser Modell ist ein dreischichtiges NN, das lernt, die Nicht-Pivot-Merkmale eines Eingabebeispiels in eine niederdimensionale Darstellung zu kodieren, so dass die Existenz von Pivot-Features (Features, die in beiden Domänen prominent sind und nützliche Informationen für die NLP-Aufgabe übermitteln) im Beispiel aus dieser Darstellung dekodiert werden kann. Die niederdimensionale Darstellung wird dann in einem Lernalgorithmus für die Aufgabe verwendet. Darüber hinaus zeigen wir, wie man vortrainierte Worteinbettungen in unser Modell injiziert, um die Generalisierung über Beispiele mit ähnlichen Pivot-Funktionen hinweg zu verbessern. Wir experimentieren mit der Aufgabe der domänenübergreifenden Sentiment-Klassifizierung an 16-Domänenpaaren und zeigen deutliche Verbesserungen gegenüber starken Baselines.', 'ko': '우리는 표징 학습을 통해 분야 적응 연구를 하는 두 가지 중요한 측면의 사상을 결합한 신경 네트워크 모델을 소개했다. 그것이 바로 구조적 대응 학습(SCL, (Blitzer et al., 2006)과 자동 코딩 신경 네트워크(NNS)이다.우리의 모델은 입력 예제의 비경첩 피쳐를 저차원 표현으로 인코딩하는 것을 배워서 예제의 경첩 피쳐의 존재를 이 표현에서 디코딩할 수 있습니다(두 도메인 모두 NLP 임무에 유용한 정보를 전달하는 피쳐).그리고 임무의 학습 알고리즘에 저차원 표시를 사용한다.그 밖에 미리 훈련된 단어를 우리 모델에 삽입하여 유사한 축심 특징을 가진 예시적인 범화 능력을 향상시키는 방법도 보여 주었다.우리는 16개 구역에서 크로스 감정 분류에 대한 실험을 실시한 결과 강한 기선에 비해 크로스 감정 분류가 실질적으로 개선되었다.', 'id': 'Kami memperkenalkan model jaringan saraf yang menikah dengan ide-ide dari dua garis penelitian terkenal tentang adaptasi domain melalui penelitian representation: pembelajaran korespondensi struktural (SCL, (Blitzer et al., 2006)) dan jaringan saraf autoencoder (NNs). Model kami adalah NN tiga lapisan yang belajar untuk mengkode fitur non-pivot contoh input ke dalam representation dimensi rendah, sehingga keberadaan fitur pivot (fitur yang prominenti dalam kedua domain dan menyampaikan informasi berguna untuk tugas NLP) dalam contoh dapat dikodeksi dari representation tersebut. Perwakilan dimensi rendah kemudian digunakan dalam algoritma belajar untuk tugas. Selain itu, kita menunjukkan bagaimana menyuntik kata-kata terlatih di model kita untuk meningkatkan generalisasi di samping contoh dengan ciri-ciri pivot yang sama. Kami bereksperimen dengan tugas klasifikasi sentimen cross-domain pada 16 pasangan domain dan menunjukkan peningkatan yang besar atas garis dasar yang kuat.', 'sw': 'Tunawasilisha muundo wa mtandao wa neura unaoea mawazo yanayotokana na viwanja viwili vikuu vya utafiti kuhusiana na mabadiliko ya ndani kwa njia ya kujifunza kwa uwakilishi: kujifunza mawasiliano ya muundo (SCL, (Blitzer et, 2006)) na mitandao ya neura (NN). Mfano wetu ni a in a tatu ya NN ambayo inajifunza kuingia vipengele vya upigaji kura vya upigaji kura kama uwakilishi wa kidini kidogo, kwa hiyo kuwepo kwa vipengele vya pivot (vipengele ambavyo vinatokea maarufu katika maeneo yote na kusambaza taarifa yenye manufaa kwa kazi ya NLP) kwa mfano, inaweza kupunguzwa kutoka kwa uwakilishi huo. The low-dimensional representation is then employed in a learning algorithm for the task.  Zaidi ya hayo, tunaonyesha jinsi ya kuingiza maneno yanayotumiwa kabla ya mafunzo katika mtindo wetu ili kuboresha uzalishaji katika mifano yenye vipengele kama vya pivo. Tunafanya majaribio kwa jukumu la kutangazwa kwa hisia za ndani kwa wanaume 16 ndani na kuonyesha maboresho makubwa zaidi ya misingi yenye nguvu.', 'hr': 'Predstavljamo model neuralne mreže koji se udaje zajedno za ideje iz dva značajna strana istraživanja o adaptaciji domena putem učenja predstavljanja: učenje strukturnih dopisnika (SCL, (Blitzer et al., 2006)) i autokodiranja neuralnih mreža (NNs). Naš model je troslojni NN koji uči kodirati neopivotne karakteristike primjera ulaska u nisku dimenzionalnu predstavu, tako da postojanje pivotskih karakteristika (karakteristika koje su poznati u oba domena i prenošenje korisne informacije za zadatak NLP-a) na primjer može biti dekodirana iz te predstave. Niska dimenzionalna predstavljanja je onda zaposlena u algoritmu učenja za zadatak. Osim toga, pokazujemo kako ubrizgati predobučene riječi u naš model kako bi poboljšali generalizaciju na primjere s sličnim pivotskim karakteristikama. Eksperimentiramo sa zadatkom klasifikacije krstodomena sentimenta na 16 domena pare i pokazujemo značajne poboljšanje nad jakim osnovnim linijama.', 'sq': 'Ne paraqesim një model rrjeti neural që martohet së bashku me idetë nga dy fusha të shquara të kërkimit mbi përshtatjen e fushës nëpërmjet mësimit të përfaqësimit: mësimi i korrespondencës strukturore (SCL, (Blitzer et al., 2006)) dhe rrjetet neurale autokodues (NNs). Modeli ynë është një NN me tre nivele që mëson të kodojë karakteristikat jo-pikë të një shembulli të hyrjes në një përfaqësim dimensional të ulët, në mënyrë që ekzistenca e karakteristikave të pikës (karakteristikat që janë të shquara në të dy fushat dhe transmetojnë informacion të dobishëm për detyrën NLP) në shembull mund të dekodizohet nga ajo përfaqësim. Përfaqësuesi i dimensionit të ulët përdoret në një algoritëm mësimi për detyrën. Përveç kësaj, ne tregojmë se si të injektojmë përfshirje fjalësh të paratrajnuara në model in tonë me qëllim që të përmirësojmë gjeneralizimin nëpër shembuj me karakteristika të ngjashme kthese. We experiment with the task of cross-domain sentiment classification on 16 domain pairs and show substantial improvements over strong baselines.', 'fa': 'ما یک مدل شبکه عصبی را معرفی می\u200cکنیم که با هم ایده\u200cهایی از دو قسمت تحقیقات معرفی در مورد تغییرات دومین با هم ازدواج می\u200cکند: یادگیری ساختاری مربوط به تغییرات (SCL, (Blitzer et al., 2006)) و شبکه\u200cهای عصبی (NNs) خودکورد می\u200cکند مدل ما یک NN سه طبقه است که یاد می\u200cگیرد که ویژه\u200cهای غیر پریوت از یک مثال ورودی را به نمایش اندازه پایین اندازه کند، تا وجود ویژه\u200cهای پریوت (ویژه\u200cهای معرفی در هر دو دامنه و اطلاعات مفید برای وظیفه NLP) در مثال می\u200cتواند از این نمایش دکورد شود. نمایش کم بعدی در الگوریتم یادگیری برای این کار کار می\u200cشود. علاوه بر این، ما نشان می دهیم که چگونه برای تزریق کردن کلمات پیش آموزش به مدل خودمان تزریق کنیم تا توسط مثالها با ویژه های مشابه پیوت بهتر شود. ما با وظیفه\u200cی تجربه کردن احساسات مختلف دامنی در ۱۶ جفت دامنی آزمایش می\u200cکنیم و بهترین زیادی را بر خط\u200cهای پایگاه\u200cهای قوی نشان می\u200cدهیم.', 'am': 'አካባቢ ትምህርት በማስተማር ከሁለት ታላላቅ ድረ ገበቦች አካባቢዎችን እናገባለን፡፡ የመሠረታዊ ግንኙነት ትምህርት ትምህርት (SCL፣ ብሊዝር እና አል፣ 2006)) እና የራሳቸውን የኔትራዊ መረብ (NNs) እና አካባቢ ትምህርት እናገባለን፡፡ ሞዴሌያችን የነጥብ ምርጫዎችን ለማቀናቀል የሚማር የጥምቀት ምርጫዎች አነስተኛ ነው፡፡ ስለዚህም ምሳሌ ከዚህ አካባቢ መልዕክት የተለየ ፕዮፎት ምርጫዎች (በሁለቱም ውይይይቶች ውስጥ ታዋቂዎች እና ለNLP ስራ የሚጠቅሙ መረጃዎች ማሳየት ይችላል፡፡ የዋነቱ መልዕክት ለስራ ትምህርት መምህርት ማድረግ ነው፡፡ እንደዚህም በተመሳሳይ የፎቶ ምርጫዎችን ለማድረግ እናሳየዋለን፡፡ የዳሜን ስሜት ክፍለ ሥርዓት በ16 ዶሜን ሁለት ላይ እና በብርቱ መደገፊያዎችን እናሳየዋለን፡፡', 'tr': 'Biz nüwarel şebeke modelini domeny adaptasyonuň iki belge diýip çarpan pikirleri birleştirip, temsil öwrenmesi üzerinden tanyşdyrýarys: strukturel korespondentlik öwrenmesi (SCL, (Blitzer et al., 2006)) we awtomatik kodlayıcı näralar şebekeleri (NNs). Biziň modelimiz pivot däldigini üýtgetmek üçin gatlak NN kodlamagyny öwrenen, eserdeki pivot özellikleri (her iki alanda möhüm bolan we NLP görevi üçin ullanyş maglumaty) eserden kodlanabiler. Aç boyutlu temsil mesele üçin öwrenme algoritmi içinde işlenýär. Mundan soňra, biz öňündeki bilim taýýarlanan sözler içine nähili nusgasyny örneklerimize üýtgetmek üçin örneklerimizi bejermek üçin görkezdik. Biz 16 domenin çift çift ve güçlü baz çizgilerinde çok önemli gelişmeleri denedik.', 'hy': 'Մենք ներկայացնում ենք նյարդային ցանցի մոդել, որը միավորում է իմաստներ բնագավառի ադապտացիայի մասին հետազոտության երկու հայտնի շրջաններից՝ ներկայացման ուսումնասիրության միջոցով: կառուցվածքային համաձայնության ուսումնասիրությունը (ՍԿL, (Բլիցսեր և այլն., 2006) և ինք Մեր մոդելը երեք շերտերով ՆՆ է, որը սովորում է կոդավորել ներդրված օրինակի ոչ պտտվող հատկությունները ցածր չափերի ներկայացման մեջ, որպեսզի օրինակի ընթացքում գոյությունը պտտվող հատկություններ (հատկություններ, որոնք արտահայտվում են երկու բնագավառներում և փոխանցում են օգտակար տեղեկատվություն ՆԼՊ-ի համար) կարող Այնուհետև ցածր չափերի ներկայացումը օգտագործվում է ուսուցման ալգորիթմի մեջ: Ավելին, մենք ցույց ենք տալիս, թե ինչպես ներդրել նախապատրաստված բառերի ներդրումներ մեր մոդելի մեջ, որպեսզի բարելավենք ընդհանուր տարածումը նմանատիպ շրջանակներով օրինակների միջև: Մենք փորձում ենք 16 տիեզերքի զույգերի միջբնագավառ զգացմունքների դասակարգման խնդրի հետ և ցույց ենք տալիս մեծ բարելավումներ ուժեղ հիմնական գծերի նկատմամբ:', 'af': "Ons introduseer 'n neuralnetwerk model wat saam met idees getrou word van twee prominente ondersoek op domein aanpassing deur voorstelling leer: strukturele ooreenstemmende ooreenstemmingsleer (SCL, (Blitzer et al., 2006)) en outokoder neuralnetwerke (NNs). Ons model is 'n drie-laag NN wat leer om die non-pivot funksies van' n invoer voorbeeld te kodeer in' n lae dimensie voorstelling, sodat die bestaande van pivot funksies (funksies wat is prominente in beide domeine en gebruiklike inligting vir die NLP taak) in die voorbeeld kan deur daardie voorstelling dekodeer word. Die lae-dimensie verteenwoording is dan gebruik in 'n leer algoritme vir die taak. Ook, ons wys hoe om vooraf-onderwerp woord inbêding in ons model te inbêer om generalisering te verbeter oor voorbeelde met gelyke pivot funksies. Ons eksperimenteer met die taak van kruisdomein sentiment klasifikasie op 16 domein paar en wys substantiele verbeteringe oor sterke basisline.", 'az': 'Biz nürol a ğ modelini təşkil edirik ki, nümunəlik öyrənməsi ilə domain adaptasiyasından iki ünlü təşkil təşkil edilən təşkil fikirlərlə birlikdə evlənir: strukturlu kompleksitə öyrənməsi (SCL, (Blitzer et al., 2006)) və autokodlayıcı nöral ağları (NNs). Bizim modelimiz üç katlı NN-dir ki, giriş məsəlinə pivot olmayan məsələlərini a şağı ölçülük göstəricisinə kodlamaq öyrənir, böylece pivot fəaliyyətlərinin (hər iki domeində möhkəm olan və NLP işin in faydalı məlumatlarını təbliğ etmək üçün) məsələdə bu göstəricisindən kodlana bilər. Daha düşük ölçülük göstəricisi bu işin öyrənmə algoritmi içində istifadə edilir. Daha sonra, modellərimizə əvvəl təhsil edilmiş sözlər in şa edilməsini göstəririk ki, bənzər pivot özellikləri ilə generalizasyonu daha yaxşı göstərək. Biz 16 domenin çift hissləri ilə qarşılıq domenin hisslərinin səviyyəsi ilə imtahana çəkirik və güclü səhifələrin üstündə çox yaxşılıqları göstəririk.', 'bn': 'আমরা একটি নিউরেল নেটওয়ার্ক মডেল পরিচয় করিয়ে দিচ্ছি যা দুটি বিশাল স্ট্রীনের গবেষণার মাধ্যমে দুটি বিশেষ চিন্তা বিয়ে করেছে: প্রতিনিধিত্ব শিক্ষার মাধ্যমে: কাঠামোর সংস্ আমাদের মডেল হচ্ছে একটি তিনটি স্তর যা একটি ইনপুটের বৈশিষ্ট্যের বৈশিষ্ট্য নির্ধারণ করার শিক্ষা দেয়া হয়েছে, যাতে পিভোটের বৈশিষ্ট্য (উভয় ডোমেইনে বিশেষ বৈশিষ্ট্য এবং এনএলপি কাজের জন্য কার্যকর তারপর কাজের জন্য শিক্ষার অ্যালগরিদমে নীচে প্রতিনিধিত্ব করা হয়। এছাড়াও, আমরা প্রশিক্ষিত পূর্ব প্রশিক্ষিত শব্দের প্রবেশ করার কিভাবে আমাদের মডেলে প্রবেশ করার জন্য পিভোটের বৈশিষ্ট্যের সাথ আমরা ১৬ ডোমেইন জোড়ায় বিভিন্ন ভিন্ন ভিন্ন ভিত্তিক উন্নতি দেখাচ্ছি।', 'bs': 'Predstavljamo model neuralne mreže koji se udaje zajedno za ideje iz dva značajna strana istraživanja o adaptaciji domena putem učenja predstavljanja: učenje strukturnih dopisnika (SCL, (Blitzer et al., 2006)) i autokodiranja neuralnih mreža (NNs). Naš model je trosloj NN koji nauči da kodira neopivotne karakteristike primjera ulaska u nisku dimenzionalnu predstavu, tako da postojanje pivotskih karakteristika (karakteristika koje su poznati u oba domena i prenose korisne informacije za zadatak NLP) na primjer može biti dekodirana iz te predstave. Niska dimenzionalna predstavljanja je onda zaposlena u algoritmu učenja za zadatak. Osim toga, pokazujemo kako da ubacimo predobučene riječi u naš model kako bi poboljšali generalizaciju na primjere sa sličnim karakteristikama pivota. Mi eksperimentiramo sa zadatkom klasifikacije krstodomena sentimenta na 16 domena pare i pokazujemo značajne poboljšanje nad jakim osnovnim linijama.', 'cs': 'Představujeme model neuronové sítě, který spojuje myšlenky ze dvou významných pramenů výzkumu adaptace domén prostřednictvím učení reprezentace: strukturální korespondenční učení (SCL, (Blitzer et al., 2006)) a autokodérové neuronové sítě (NN). Náš model je třívrstvý NN, který se naučí kódovat nepřipojovací prvky vstupního příkladu do nízkorozměrné reprezentace, takže existence pivotových prvků (prvků, které jsou prominentní v obou doménách a poskytují užitečné informace pro úlohu NLP) v příkladu lze dekódovat z této reprezentace. Nízkorozměrná reprezentace je pak použita v učebním algoritmu pro daný úkol. Navíc ukazujeme, jak do našeho modelu vložit předškolené vložení slov, abychom zlepšili zobecnění napříč příklady s podobnými pivotovými funkcemi. Experimentujeme s úkolem klasifikace sentimentů mezi doménami na 16.doménových párech a ukazujeme výrazná zlepšení oproti silným základním liniím.', 'et': 'Tutvustame närvivõrgu mudelit, mis ühendab mõtted kahest silmapaistvast valdkonna kohanemise uurimissuunast läbi representatsiooniõppe: struktuurse kirjavahetusõppe (SCL, (Blitzer et al., 2006)) ja autokodeerijate närvivõrgud (NNs). Meie mudel on kolmekihiline NN, mis õpib kodeerima sisendnäite mittepöördepunktsioone madalamõõtmeliseks esituseks, nii et näites on pöördepunktsioonide olemasolu (funktsioonid, mis on silmapaistvad mõlemas valdkonnas ja edastavad kasulikku teavet NLP ülesande jaoks) saab sellest esitusest dekodeerida. Seejärel kasutatakse ülesande õppealgoritmis madalamõõtmelist esitust. Lisaks näitame, kuidas süstida eelõpetatud sõnade manustamist meie mudelisse, et parandada sarnaste pöördepunktsioonidega näidete üldistamist. Eksperimenteerime domeenidevahelise sentimentaalse klassifitseerimise ülesandega 16 domeenipaari puhul ja näitame olulisi edusamme tugevate lähtejoontega võrreldes.', 'fi': 'Esittelemme neuroverkkomallin, joka yhdistää yhteen ideoita kahdesta merkittävästä tutkimuslohkosta, jotka käsittelevät domeenin sopeutumista representaatiooppimisen kautta: rakenteellisen kirjeenvaihdon oppimista (SCL, (Blitzer et al., 2006)) ja automaattisia neuroverkkoja (NN). Mallimme on kolmikerroksinen NN, joka oppii koodaamaan syöttöesimerkin ei-pivot-ominaisuudet matalaulotteiseksi esitykseksi, jotta esimerkin pivot-ominaisuudet (ominaisuudet, jotka ovat näkyvissä molemmilla toimialoilla ja välittävät hyödyllistä tietoa NLP-tehtävään) voidaan purkaa tästä esityksestä. Matalan ulottuvuuden esitystä käytetään tehtävän oppimisalgoritmissa. Lisäksi näytämme, miten malliimme lisätään ennalta koulutettuja sanaupotuksia, jotta voidaan parantaa yleistämistä esimerkeissä, joissa on samanlaisia pivot-ominaisuuksia. Kokeilemme verkkotunnusten välistä tunneluokitusta 16 verkkotunnusparilla ja osoitamme merkittäviä parannuksia vahvoihin lähtölinjoihin verrattuna.', 'ca': "We introduce a neural network model that marries together ideas from two prominent strands of research on domain adaptation through representation learning: structural correspondence learning (SCL, (Blitzer et al., 2006)) and autoencoder neural networks (NNs).  El nostre model és un NN de tres capes que aprene a codificar les característiques no pivots d'un exemple d'entrada en una representació baixa dimensional, de manera que l'existència de característiques pivots (característiques que són prominents en ambdós dominis i que transmetren informació útil per a la tasca NLP) en l'exemple pugui ser descodificada d'aquesta representació. La representació de baixa dimensió s'emplega en un algoritme d'aprenentatge per a la tasca. A més, ensenyem com injectar les paraules entrenades al nostre model per millorar la generalització entre exemples amb característiques pivots similars. Experimentem amb la tasca de classificació de sentiments transdomínics en 16 parelles de dominis i demostram millors substàntiques sobre línies de base fortes.", 'jv': 'Awak dhéwé nglanggar modèl netwisik sing gawe nggawe ide sing dumadhi iki luwih dumadhi sak perusahaan winih nggawe gerakan kelaleng cara-nyeleh: structural corester Learning (scL (Blitter et al. 2007) lan autokoder Neral netwisik (NNs). Kita model iki telu-layer NN liyane dadi ngkode pawangan lagi piVot kanggo nguasai perusahaan anyar, dadi piVot karjana piVot (karjana ono sing diputaan sampeyan iki dadi domain lan kelas informasi nggawe NLP task) iso dianggo oleh dumadhi iki Display rounding politenessoffpolite"), and when there is a change ("assertive We pilot with the task of inter-domain Sensitive CLASCIPATI on 16 domain paras and show supanti advancements about strength basic lines.', 'ha': "Tuna fara wani misali na'urar kwamfyutan, wanda ke auri marãyi da ke koma daga wurãre biyu mai girma wa research na adaptation ɗin Domen, a bayan ilimi na sharĩ'a: Shirin mutane da ake karanta rubutu (SCL, (blizzer et, 2006)) da zangaron neura na farat kode (NN). Misalinmu na zama wani na-daraja uku wanda yake iya karanta kodi masu tsari na-pivot na cikin shirin ayuka ya zama misali mai ƙaranci, dõmin a iya ƙididdige masu tsari na pivot (masu tsari waɗanda ke cikin duk biyu na girma kuma a gaya lãbãri mai amfani ga aikin NLP) kamar misali, za'a iya kode daga wannan uwar. An yi aiki a kan karatun karatun karatun wa aikin. Za kuma, Muna nũna jinin ka shiga maganar da aka shigar da shi a cikin misalinmu da ya yi amfani da shi gaba ɗaya, dõmin ya ƙara wa mai sami da misãlai masu daidaita na pivot. We experiment with the task of cross-domain sentiment classification on 16 domain pairs and show substantial improvements over strong baselines.", 'sk': 'Predstavljamo model nevronskega omrežja, ki združuje ideje iz dveh vidnih sklopov raziskav o prilagajanju domenskih področij prek reprezentacijskega učenja: strukturno korespondencijsko učenje (SCL, (Blitzer et al., 2006)) in avtonodirnih nevronskih omrežij (NNs). Naš model je trislojni NN, ki se nauči kodirati nepivotne funkcije vhodnega primera v nizkodimenzionalno reprezentacijo, tako da lahko obstoj pivotnih funkcij (funkcij, ki so vidne na obeh področjih in prenašajo koristne informacije za nalogo NLP) v primeru dekodiramo iz te reprezentacije. Nizkodimenzionalna reprezentacija se nato uporabi v algoritmu učenja za nalogo. Poleg tega vam pokažemo, kako vbrizgati vnaprej usposobljene besedne vdelave v naš model, da bi izboljšali posploševanje med primeri s podobnimi vrtilnimi funkcijami. Eksperimentiramo z nalogo meddomenske klasifikacije sentimentalnih občutkov na 16 parov domen in kažemo bistvene izboljšave v primerjavi z močnimi osnovnimi linijami.', 'he': 'אנחנו מציגים מודל רשת עצבית שמתחתן עם רעיונות משני חלקים מוכרים של מחקר על התאמה לתחום דרך לימוד מייצג: לימוד התכתבות מבנה (SCL, (Blitzer et al., 2006)) ורשתות עצביות קודמות אוטומטית (NNs). הדוגמא שלנו היא NN בשלוש שכבות שלמדה לקוד את תכונות הלא-פיוט של דוגמא כניסה לתוך ייצוג מימדי נמוך, כך שקיום של תכונות פיוט ההצגה המימדית הנמוכה משתמשת באלגוריתם ללמוד למשימה. חוץ מזה, אנחנו מראים איך להזריק מילים מאומנות מראש לתוך הדוגמא שלנו כדי לשפר את הגנרליזציה ברחבי דוגמאות עם תכונות פנויות דומות. אנו מנסים עם המשימה של קליפורת רגשות בין שטח על 16 זוגות שטח ומראים שיפורים משמעותיים מעל קווי בסיס חזקים.', 'bo': 'We introduce a neural network model that marries together ideas from two prominent strands of research on domain adaptation through representation learning: structural correspondence learning (SCL, (Blitzer et al., 2006)) and autoencoder neural networks (NNs). Our model is a three-layer NN that learns to encode the non-pivot features of an input example into a low dimensional representation, so that the existence of pivot features (features that are prominent in both domains and convey useful information for the NLP task) in the example can be decoded from that representation. འོན་ཀྱང་ཆེ་ཆུང་བའི་རྣམ་པ་དེ་ལས་ཀྱང་སློབ་པའི་སྒྲུབ་གྲངས་སྒྲིག་སྟངས་ཤིག་བྱེད་སོང་། འོན་ཀྱང་། ང་ཚོས་རང་གི་རྣམ་པ་ལ་སྔོན་གྲངས་སྒྲིག་པའི་ཐ་སྙད་ཅིག་གསལ་བཙུགས་ན་ང་ཚོའི་མིག་དཔེ་བས། ང་ཚོས་དུས་མཐུན་གྱི་རང་འགུལ་སྡུད་གྲྭར་ཞིབ་འཇུག་བྱེད་པའི་ལས་འགན་སྟངས་ལྡན་གྱི་རྩོམ་པ་༡༦་དང་།'}
{'en': 'A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling', 'es': 'Un modelo neuronal simple y preciso e independiente de la sintaxis para el etiquetado semántico de roles basado en dependencias', 'pt': 'Um modelo neural agnóstico de sintaxe simples e preciso para rotulagem de função semântica baseada em dependência', 'fr': "Un modèle neuronal agnostique simple et précis pour l'étiquetage sémantique des rôles basé sur la dépendance", 'ar': 'نموذج عصبي بسيط ودقيق لغوي لاأدري لتسمية الأدوار الدلالية القائمة على التبعية', 'ja': '依存関係に基づくセマンティックロールラベリングのためのシンプルで正確な構文認識ニューラルモデル', 'zh': '简而正者,语法之神经也,所以语义角也', 'ru': 'Простая и точная синтаксис-агностическая нейронная модель для семантической маркировки ролей на основе зависимостей', 'hi': 'निर्भरता-आधारित शब्दार्थ भूमिका लेबलिंग के लिए एक सरल और सटीक वाक्यविन्यास-अज्ञेयवादी तंत्रिका मॉडल', 'ga': 'Samhail Néaránach Comhréire-Agnóiseach Simplí agus Chruinn le haghaidh Lipéadú Róil Shéimeantach atá Bunaithe ar Spleáchas', 'ka': 'Name', 'el': 'Ένα απλό και ακριβές συντακτικό-αγνωστικό νευρωνικό μοντέλο για τη σημασιολογική σήμανση ρόλων βασισμένη στην εξάρτηση', 'hu': 'Egyszerű és pontos szintaxis-agnosztikai neurális modell a függőség alapú szemantikus szerepkörcímkézéshez', 'it': "Un modello neurale sintassi-agnostico semplice e preciso per l'etichettatura semantica basata sulla dipendenza", 'lt': 'A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling', 'kk': 'Қарапайым және нақты синтаксис- агностикалық невраллық модель тәуелдік негізделген семантикалық роль жарлығы', 'mk': 'Name', 'ms': 'Name', 'ml': 'സെമാന്റിക് അടിസ്ഥാനത്തിലുള്ള സെമാന്റിക് റോള്\u200d ലാബില്\u200dങ്ങിനുള്ള ഒരു എളുപ്പമായ സിന്റാക്സ്- ആഗ്നോസ്റ്റി', 'mn': 'Харилцааны үндсэн Semantic Role Labeling энгийн, тодорхой синтаксис-агностик мэдрэлийн загвар', 'mt': 'Mudell Newrali Sintetiku-Agnostiku Simpli u Akkwat għat-Tikkettar tar-Rwol Semantiku bbażat fuq id-Dipendenza', 'pl': 'Prosty i dokładny zespół-Agnostyczny model neuronowy dla oznaczania ról semantycznych opartych na zależności', 'ro': 'Un model neural simplu și precis sintaxial-agnostic pentru etichetarea rolurilor semantice bazate pe dependență', 'sr': 'Jednostavni i precizan sintaks-agnostički neiralni model za etiketiranje semantičkih uloga na osnovu ovisnosti', 'no': 'Ein enkel og akkurat syntaks- agnostisk neiralmodell for avhengighetsbasert semiantisk rolletiketting', 'si': 'Name', 'so': 'Model of Neural Neural-Agnostic Syntax-Agnostic Model of Dependence-based Semantic Role Labeling', 'sv': 'En enkel och korrekt syntax-agnostisk neural modell för beroendebaserad semantisk rollmärkning', 'ta': 'சார்பு அடிப்படையில் செமாண்டிக் சுழற்சி லாப்லிங்குக்கான எளிய மற்றும் சரியான ஒத்திசை', 'ur': 'ایک ساده اور دقیق سینٹکس-اگنیٹیک نیورال موڈل ڈیفاندنسی-بنیادی سیمنٹی رول لابلینگ کے لئے', 'uz': 'Name', 'vi': 'Một mô hình thần kinh Syntax-Agnosic đơn giản và chính thức cho người đặt nhãn đồng hồ Semantic', 'bg': 'Прост и точен синтаксисно-агностичен неврален модел за етикетиране на семантични роли въз основа на зависимост', 'hr': 'Jednostavni i precizan sintaks-agnostički neuronski model za označavanje semantičkih uloga na osnovu ovisnosti', 'nl': 'Een eenvoudig en nauwkeurig syntaxisch-agnostisch neuraal model voor afhankelijkheidsgebaseerde semantische rollabeling', 'da': 'En enkel og præcis syntaks-agnostisk neural model til afhængighedsbaseret semantisk rollemærkning', 'de': 'Ein einfaches und genaues syntax-agnostisches neuronales Modell zur abhängigkeitsbasierten semantischen Rollenbeschriftung', 'ko': '의존 관계의 의미 역할 표시를 바탕으로 하는 간단하고 정확한 문법 불가지 신경 모델', 'id': 'Model Neural Sintaks-Agnostik Sederhana dan Tepat untuk Label Rol Semantik Berdasarkan Dependensi', 'fa': 'Name', 'tr': 'Basit we Dyggat Sentaks-Agnostik Näral Modeli Dependensiýa tabanly Semantik Rol Etiketleme', 'sw': 'Mradi wa Kitendo cha Kitendo cha Kitendo cha Kitendo cha Kitendo cha Kujitegemea', 'af': 'Name', 'sq': 'Një model i thjeshtë dhe i saktë sintaks-agnostik neurol për etiketën e rolit Semantik bazuar në varësi', 'am': 'A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling', 'hy': 'Պարզ և ճշգրիտ սինտաքսի-ագնոստիկ նյարդային մոդել կախվածության հիմնված սեմանտիկ դերի պիտակ', 'az': 'Bağlamlıq-tabanlı Semantik Rol Labelini üçün basit və düzgün Sintaks-Agnostik Nöral Modeli', 'bn': 'নির্ভরিত সেম্যান্ডিক ভিত্তিক রোল লেবেলিং-এর জন্য একটি সহজ এবং সহজ সিন্যাক্স- আগনোস্টিক নিউরেল মডেল', 'ca': 'Un model neuronal sintàstic-agnòstic senzill i exact per etiquetar el paper Semàtic basat en dependencies', 'cs': 'Jednoduchý a přesný syntax-agnostický neuronový model pro označování sémantických rolí založených na závislosti', 'bs': 'Jednostavni i precizan sintaks-agnostički neuronski model za označavanje semantičkih uloga na osnovu ovisnosti', 'et': 'Lihtne ja täpne süntaksi-agnostiline neuromudel sõltuvuspõhise semantilise rolli märgistamiseks', 'fi': 'Yksinkertainen ja tarkka syntaksiagnostinen hermomalli riippuvuuspohjaiseen semanttiseen roolimerkintään', 'he': 'A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling', 'ha': '@ item Text character set', 'sk': 'Preprost in natančen sintakso-agnostični nevronski model za označevanje semantičnih vlog na podlagi odvisnosti', 'jv': 'Mungkin Normal karo Akuras Senaksi-agetik Njuarel model kanggo Ngawe Dijehensik Batal', 'bo': 'A Simple and Accurate Syntax-Agnostic Neural Model for Dependency-based Semantic Role Labeling'}
{'en': 'We introduce a simple and accurate neural model for dependency-based semantic role labeling. Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder. The semantic role labeler achieves competitive performance on English, even without any kind of syntactic information and only using local inference. However, when automatically predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the English CoNLL-2009 dataset. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e., syntactically-informed) SRL models are hindered when tested in this setting. Our syntax-agnostic model appears more robust, resulting in the best reported results on standard out-of-domain test sets.', 'ar': 'نقدم نموذجًا عصبيًا بسيطًا ودقيقًا لتصنيف الأدوار الدلالية القائم على التبعية. يتنبأ نموذجنا بالاعتماد على الحجة الأصلية التي تعتمد على حالات مشفر LSTM ثنائي الاتجاه. تحقق أداة تمييز الأدوار الدلالية أداءً تنافسيًا في اللغة الإنجليزية ، حتى بدون أي نوع من المعلومات النحوية وباستخدام الاستدلال المحلي فقط. ومع ذلك ، عندما يتم توفير علامات جزء من الكلام المتوقعة تلقائيًا كمدخلات ، فإنها تتفوق بشكل كبير على جميع النماذج المحلية السابقة وتقترب من أفضل النتائج التي تم الإبلاغ عنها في مجموعة بيانات CoNLL-2009 باللغة الإنجليزية. نأخذ في الاعتبار أيضًا اللغات الصينية والتشيكية والإسبانية حيث يحقق نهجنا أيضًا نتائج تنافسية. لا يمكن الاعتماد على المحلل اللغوي النحوي في البيانات خارج المجال ، لذلك يتم إعاقة نماذج SRL القياسية (أي المستنيرة نحويًا) عند اختبارها في هذا الإعداد. يبدو نموذجنا الحيادي في بناء الجملة أكثر قوة ، مما أدى إلى الحصول على أفضل النتائج المبلغ عنها في مجموعات الاختبار القياسية خارج المجال.', 'pt': 'Apresentamos um modelo neural simples e preciso para rotulagem de função semântica baseada em dependência. Nosso modelo prevê dependências predicado-argumento com base nos estados de um codificador LSTM bidirecional. O rotulador de função semântica alcança desempenho competitivo em inglês, mesmo sem nenhum tipo de informação sintática e usando apenas inferência local. No entanto, quando as tags de parte da fala previstas automaticamente são fornecidas como entrada, ele supera substancialmente todos os modelos locais anteriores e se aproxima dos melhores resultados relatados no conjunto de dados CoNLL-2009 em inglês. Também consideramos chinês, tcheco e espanhol, onde nossa abordagem também alcança resultados competitivos. Os analisadores sintáticos não são confiáveis em dados fora do domínio, portanto, os modelos SRL padrão (ou seja, informados sintaticamente) são prejudicados quando testados nessa configuração. Nosso modelo agnóstico de sintaxe parece mais robusto, resultando nos melhores resultados relatados em conjuntos de teste padrão fora do domínio.', 'fr': "Nous introduisons un modèle neuronal simple et précis pour l'étiquetage sémantique des rôles basé sur la dépendance. Notre modèle prédit les dépendances entre prédicats et arguments en fonction des états d'un codeur LSTM bidirectionnel. L'étiqueteuse de rôle sémantique atteint des performances compétitives en anglais, même sans aucune information syntaxique et en utilisant uniquement l'inférence locale. Toutefois, lorsque des balises de partie du discours prédites automatiquement sont fournies en entrée, elles surpassent largement tous les modèles locaux précédents et se rapprochent des meilleurs résultats rapportés sur l'ensemble de données anglais ConLL-2009. Nous prenons également en compte le chinois, le tchèque et l'espagnol, où notre approche permet également d'obtenir des résultats compétitifs. Les analyseurs syntaxiques ne sont pas fiables sur les données hors domaine, de sorte que les modèles SRL standard (c'est-à-dire informés syntaxiquement) sont gênés lorsqu'ils sont testés dans ce paramètre. Notre modèle indépendant de la syntaxe semble plus robuste, ce qui donne les meilleurs résultats rapportés sur des ensembles de tests hors domaine standard.", 'es': 'Presentamos un modelo neuronal simple y preciso para el etiquetado semántico de roles basado en dependencias. Nuestro modelo predice dependencias de argumentos predicados basándose en los estados de un codificador LSTM bidireccional. El etiquetador de roles semánticos logra un rendimiento competitivo en inglés, incluso sin ningún tipo de información sintáctica y solo utilizando inferencia local. Sin embargo, cuando se proporcionan etiquetas de parte del habla predichas automáticamente como entrada, supera sustancialmente a todos los modelos locales anteriores y se acerca a los mejores resultados informados en el conjunto de datos inglés ConLL-2009. También tenemos en cuenta el chino, el checo y el español, donde nuestro enfoque también logra resultados competitivos. Los analizadores sintácticos no son confiables en los datos fuera del dominio, por lo que los modelos SRL estándar (es decir, con información sintáctica) se ven obstaculizados cuando se prueban en este entorno. Nuestro modelo independiente de la sintaxis parece más sólido, lo que da como resultado los mejores resultados informados en conjuntos de pruebas estándar fuera del dominio.', 'ja': '依存性に基づく意味役割ラベリングのためのシンプルで正確なニューラルモデルを紹介します。我々のモデルは、双方向LSTMエンコーダの状態に依存して述語-引数依存性を予測する。セマンティックロールラベラーは、さまざまな構文情報がなく、ローカル推論のみを使用しても、英語で競争力のあるパフォーマンスを達成します。しかし、自動予測された発話部分タグが入力として提供される場合、それは以前のすべてのローカルモデルを実質的に上回り、英語のCoNLL -2009データセットで報告された最高の結果に近づきます。また、当社のアプローチが競争力のある結果をもたらす中国、チェコ、スペインについても考慮しています。構文解析器はドメイン外データでは信頼性が低いため、この設定でテストされると、標準的な（すなわち、構文情報に基づいた） SRLモデルが妨げられます。当社の構文非推論モデルは、より堅牢に見え、標準的なドメイン外テストセットで報告された最高の結果をもたらします。', 'zh': '引入一简确神经模形,以基语义角。 吾道赖于双向 LSTM 编码器者谓词-参数恃也。 语义角色标注器虽无一语法信而推理者,亦能争于英语。 然自占词性标输,其性大优于诸故,近英语CoNLL-2009数集上告之最也。 犹思中文,捷克语西班牙语,吾道有竞争力。 语法解析器域外数不足恃,故置中试之,(即语法通)SRL 模则阻。 吾语法无关模样健,试于域外集上获得最佳报。', 'hi': 'हम निर्भरता-आधारित शब्दार्थ भूमिका लेबलिंग के लिए एक सरल और सटीक तंत्रिका मॉडल पेश करते हैं। हमारा मॉडल एक द्विदिश एलएसटीएम एनकोडर के राज्यों पर निर्भर करते हुए विधेय-तर्क निर्भरताओं की भविष्यवाणी करता है। शब्दार्थ भूमिका लेबलर अंग्रेजी पर प्रतिस्पर्धी प्रदर्शन प्राप्त करता है, यहां तक कि किसी भी प्रकार की वाक्यात्मक जानकारी के बिना और केवल स्थानीय अनुमान का उपयोग करके। हालांकि, जब स्वचालित रूप से भविष्यवाणी की गई पार्ट-ऑफ-स्पीच टैग इनपुट के रूप में प्रदान की जाती है, तो यह पिछले सभी स्थानीय मॉडलों को काफी हद तक बेहतर बनाता है और अंग्रेजी CoNLL-2009 डेटासेट पर सर्वोत्तम रिपोर्ट किए गए परिणामों तक पहुंचता है। हम चीनी, चेक और स्पेनिश पर भी विचार करते हैं जहां हमारा दृष्टिकोण भी प्रतिस्पर्धी परिणाम प्राप्त करता है। सिंटैक्टिक पार्सर आउट-ऑफ-डोमेन डेटा पर अविश्वसनीय हैं, इसलिए इस सेटिंग में परीक्षण किए जाने पर मानक (यानी, वाक्यात्मक रूप से सूचित) एसआरएल मॉडल बाधित होते हैं। हमारा वाक्यविन्यास-अज्ञेयवादी मॉडल अधिक मजबूत दिखाई देता है, जिसके परिणामस्वरूप मानक आउट-ऑफ-डोमेन परीक्षण सेट पर सर्वोत्तम रिपोर्ट किए गए परिणाम होते हैं।', 'ru': 'Введем простую и точную нейронную модель для обозначения семантических ролей на основе зависимостей. Наша модель предсказывает зависимости предикат-аргумент, опираясь на состояния двунаправленного кодера LSTM. Метка семантической роли достигает конкурентной производительности на английском языке, даже без какой-либо синтаксической информации и только с использованием локального вывода. Однако, когда автоматически предсказанные теги части речи предоставляются в качестве входных данных, они значительно превосходят все предыдущие локальные модели и приближаются к наилучшим результатам, сообщенным в наборе данных CoNLL-2009 на английском языке. Мы также рассматриваем китайский, чешский и испанский, где наш подход также достигает конкурентных результатов. Синтаксические парсеры ненадежны на внедоменные данные, поэтому стандартные (т.е. синтаксически информированные) модели SRL при тестировании в этой настройке затруднены. Наша синтаксис-диагностическая модель выглядит более надежной, что приводит к лучшим результатам для стандартных наборов тестов вне домена.', 'ga': 'Tugaimid isteach samhail néarúil shimplí agus chruinn le haghaidh lipéadú ról shéimeantach atá bunaithe ar spleáchas. Déanann ár múnla spleáchais réamh-argóine a thuar ag brath ar stáit ionchódóra LSTM déthreoch. Baineann an lipéadóir ról shéimeantach amach feidhmíocht iomaíoch ar an mBéarla, fiú gan aon chineál faisnéise comhréire agus gan ach tátal áitiúil a úsáid. Mar sin féin, nuair a chuirtear clibeanna cuid cainte réamh-mheasta ar fáil go huathoibríoch mar ionchur, sáraíonn sé go suntasach na samhlacha áitiúla go léir roimhe seo agus téann sé i dtreo na dtorthaí tuairiscithe is fearr ar thacar sonraí Béarla CoNLL-2009. Breithnímid freisin ar an tSínis, ar an tSeicis agus ar an Spáinnis áit a mbaineann ár gcur chuige torthaí iomaíocha amach freisin. Tá parsálaithe comhréire neamhiontaofa ar shonraí lasmuigh den fhearann, mar sin cuirtear bac ar shamhlacha caighdeánacha (i.e., ar an eolas go comhréir) nuair a dhéantar tástáil orthu sa socrú seo. Is cosúil go bhfuil ár múnla agnostic comhréire níos láidre, agus mar thoradh air sin tá na torthaí is fearr tuairiscithe ar thacair chaighdeánacha tástála lasmuigh den fhearann.', 'ka': 'ჩვენ ჩვენ დავიყენებთ უკეთესი და მარტივი ნეიროლური მოდელი განსაკუთრებულობისთვის სემონტიკური პროლის მარტიკაციისთვის. ჩვენი მოდელი წარმოიდგინეთ წარმოდგინული არგუმენტის დასახლოები, რომლებიც ორიდერექციონალური LSTM კოდერების სტატუსების შესახებ. სიმენტიკური პროლის ლაბლიერი ინგლისური კონპექტიური გამოსახულებას მიიღებს, თუმცა არაფერი სინტაქტიური ინფორმაციას და მხოლოდ ლოკალური ინფრენცი მაგრამ, როდესაც ავტომატურად დაწყვეტილი სიტყვების ნაწილი ჭდეები იქნება როგორც შეტყობინებულია, ის ძალიან უფრო გავაკეთებს ყველა მხოლოდ ლოკალური მოდელები და მიღებს ყველაზე უფრო მ ჩვენ ასევე ვფიქრობთ ჩინეთი, ფექი და სპანელი, სადაც ჩვენი პროგრამა კონკენტებური შედეგების მიღება. სინტაქტიკური პარასერები დიომინის გარეშე მონაცემებში არ შეუძლებელია, ამიტომ სტანდარტული (სინტაქტიკურად ინფორმაციული) SRL მოდელები შეცდომარებულია, როცა ეს პარამეტრებში შე ჩვენი სინტაქსი-ადნოსტიკი მოდელი უფრო ძალიან ძალიან გამოიყურება, რომელიც შეიძლება უფრო ძალიან გამოცდილობული შედეგების შესახებ სტანდარტური გამ', 'hu': 'Bevezetünk egy egyszerű és pontos neurális modellt a függőség alapú szemantikai szerepjelöléshez. Modellünk egy kétirányú LSTM kódoló állapotán alapuló predikát-argumentum függőségeket jósol meg. A szemantikus szerepkörcímkéző versenyképes teljesítményt ér el angolul, még mindenféle szintaktikus információ nélkül is, és csak helyi következtetést használva. Ha azonban bemenetként automatikusan előrejelzett beszédrész-címkéket adnak meg, lényegesen felülmúlja az összes korábbi helyi modellt, és megközelíti az angol CoNLL-2009 adatkészletben szereplő legjobb eredményeket. A kínai, cseh és spanyol megközelítésünk során versenyképes eredményeket is érünk el. A szintaktikus elemzők nem megbízhatóak a tartományon kívüli adatokon, így a szabványos (azaz szintaktikusan tájékoztatott) SRL modellek akadályoznak ebben a beállításban történő teszteléskor. A szintaxis-agnosztikus modellünk robusztusabbnak tűnik, ami a legjobb eredményt eredményezi a standard, domain kívüli tesztkészleteknél.', 'el': 'Παρουσιάζουμε ένα απλό και ακριβές νευρωνικό μοντέλο για σημασιολογική σήμανση ρόλων βασισμένη στην εξάρτηση. Το μοντέλο μας προβλέπει εξαρτήσεις προβλέψεων-ορίων βασιζόμενοι σε καταστάσεις ενός αμφίδρομου κωδικοποιητή LSTM. Η σημασιολογική σήμανση ρόλων επιτυγχάνει ανταγωνιστική απόδοση στα αγγλικά, ακόμη και χωρίς οποιοδήποτε είδος συντακτικών πληροφοριών και χρησιμοποιώντας μόνο τοπικά συμπεράσματα. Ωστόσο, όταν παρέχονται αυτόματα προβλεπόμενες ετικέτες τμήματος ομιλίας ως εισαγωγή, ξεπερνά σημαντικά όλα τα προηγούμενα τοπικά μοντέλα και προσεγγίζει τα καλύτερα αναφερόμενα αποτελέσματα στο αγγλικό σύνολο δεδομένων. Εξετάζουμε επίσης κινέζικα, τσεχικά και ισπανικά όπου η προσέγγισή μας επιτυγχάνει επίσης ανταγωνιστικά αποτελέσματα. Οι συντακτικοί αναλυτές είναι αναξιόπιστοι σε δεδομένα εκτός πεδίου, οπότε τα τυποποιημένα (δηλ. συντακτικά ενημερωμένα) μοντέλα εμποδίζονται όταν δοκιμάζονται σε αυτή τη ρύθμιση. Το συντακτικό-agnostic μοντέλο μας φαίνεται πιο ισχυρό, με αποτέλεσμα τα καλύτερα αποτελέσματα που αναφέρονται σε τυποποιημένα σύνολα δοκιμών εκτός τομέα.', 'it': "Introduciamo un modello neurale semplice e preciso per l'etichettatura semantica dei ruoli basata sulla dipendenza. Il nostro modello predice dipendenze predicate-argument basate sugli stati di un codificatore LSTM bidirezionale. L'etichettatore di ruolo semantico raggiunge prestazioni competitive in inglese, anche senza alcun tipo di informazione sintattica e utilizzando solo inferenze locali. Tuttavia, quando vengono forniti i tag part-of-speech previsti automaticamente come input, supera sostanzialmente tutti i modelli locali precedenti e si avvicina ai migliori risultati riportati sul set di dati inglese CoNLL-2009. Consideriamo anche cinese, ceco e spagnolo dove il nostro approccio raggiunge anche risultati competitivi. I parser sintattici sono inaffidabili su dati fuori dominio, quindi i modelli standard (cioè sintatticamente informati) SRL sono ostacolati quando testati in questa impostazione. Il nostro modello agnostico della sintassi appare più robusto, con conseguente risultato dei migliori risultati riportati sui set di test standard fuori dominio.", 'lt': 'Įdiegiame paprastą ir tikslų priklausomybe pagrįstą semantinio vaidmens ženklinimo model į. Mūsų modelis prognozuoja, kad priklausomybė nuo dvikrypčio LSTM kodavimo būklės yra pagrįsta argumentais. Semantinis vaidmuo žymėtojas įgyja konkurencinius rezultatus anglų kalba net be jokios sintaksinės informacijos ir naudoja tik vietos išvadas. Vis dėlto, kai automatiškai numatytos kalbos dalys pateikiamos kaip įvestis, jos gerokai viršija visus ankstesnius vietinius modelius ir artėja prie geriausių pranešimų apie anglų CoNLL-2009 duomenų rinkinį rezultatų. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results.  Sintaktiniai analizatoriai nepatikimi ne domeniniais duomenimis, taigi šioje aplinkoje bandomi standartiniai (t. y. sintetiškai informuoti) SRL modeliai yra kliudžiami. Mūsų sintaksinės agnostikos modelis atrodo patikimesnis, todėl geriausiai gaunami standartinių išorinių bandymų rinkinių rezultatai.', 'mk': 'We introduce a simple and accurate neural model for dependency-based semantic role labeling.  Нашиот модел предвидува зависности од предикативни аргументи кои се зависат од состојбите на дворечниот кодер на ЛСТМ. Семантичкиот означувач на улога постигнува конкурентна резултат на англискиот јазик, дури и без било каква синтактичка информација и само користејќи локална конференција. Сепак, кога се обезбедуваат автоматски предвидени делови од говорот како влез, истиот значително ги надминува сите претходни локални модели и се приближува до најдобрите известени резултати на англискиот датотек CoNLL-2009. Ние, исто така, сметаме за кинески, чески и шпански, каде нашиот пристап, исто така, постигнува конкурентни резултати. Синтактичките анализатори не се доверливи на податоци надвор од доменот, така што стандардните (т.е., синтактички информирани) SRL модели се попречени кога се тестираат во ова поставување. Нашиот синтаксиско-агностички модел изгледа посилен, резултирајќи со најдобрите известени резултати на стандардните надворешни тестови.', 'ms': 'Kami memperkenalkan model saraf sederhana dan tepat untuk label peranan semantik berdasarkan dependensi. Model kami meramalkan dependensi argumen-predicate bergantung pada keadaan pengekod LSTM bidireksi. Label peranan semantik mencapai prestasi kompetitif dalam bahasa Inggeris, walaupun tanpa sebarang jenis maklumat sintaktik dan hanya menggunakan kesimpulan setempat. Namun, apabila tag-bahagian-ucapan yang dijangka secara automatik disediakan sebagai input, ia secara berasasan melebihi semua model setempat terdahulu dan mendekati keputusan terbaik yang dilaporkan pada set data CoNLL-2009 Inggeris. Kami juga mempertimbangkan bahasa Cina, Czech dan Spanyol di mana pendekatan kami juga mencapai keputusan kompetitif. Penghurai sintaktik tidak dipercayai pada data diluar domain, jadi model SRL piawai (iaitu maklumat sintaktik) dihalangi bila diuji dalam tetapan in i. Model sintaks-agnostik kami kelihatan lebih kuat, menghasilkan keputusan terbaik yang dilaporkan pada set ujian luar domain piawai.', 'mt': 'Aħna nintroduċu mudell newrali sempliċi u preċiż għat-tikkettar tar-rwol semantiku bbażat fuq id-dipendenza. Il-mudell tagħna jipprevedi dipendenzi predikati-argumenti li jiddependu fuq stati ta’ kodifikatur LSTM bidirezzjonali. It-tikkettatur tar-rwol semantiku jikseb prestazzjoni kompetittiva bl-Ingliż, anki mingħajr kwalunkwe tip ta’ informazzjoni sintetika u biss bl-użu ta’ inferenza lokali. Madankollu, meta jiġu pprovduti tikketti awtomatikament imbassra tal-parti tad-diskors bħala input, dan ikun sostanzjalment ogħla mill-mudelli lokali preċedenti kollha u joqrob lejn l-aħjar riżultati rrappurtati fuq is-sett tad-dejta Ingliż CoNLL-2009. Aħna nqisu wkoll iċ-Ċiniżi, iċ-Ċeki u Spanjoli fejn l-approċċ tagħna jikseb ukoll riżultati kompetittivi. Il-analizzaturi sintattiċi mhumiex affidabbli fuq dejta barra d-dominju, għalhekk mudelli SRL standard (jiġifieri infurmati b’mod sintattiku) huma mxekkla meta jiġu ttestjati f’dan l-ambjent. Il-mudell sintaks-agnostiku tagħna jidher aktar robust, li jirriżulta fl-aħjar riżultati rrappurtati fuq settijiet ta’ testijiet standard barra d-dominju.', 'ml': 'ആശ്രയിച്ചിരിക്കുന്ന സെമാന്റിക് റോള്\u200d ലേബിള്\u200d ചെയ്യുന്നതിന് ഞങ്ങള്\u200d ഒരു സാധാരണ പ്രധാനപ്പെടുത്തുന്നു. നമ്മുടെ മോഡല്\u200d പ്രവചിക്കുന്നു ഒരു ബിഡിയര്\u200dഷന്\u200d എല്\u200dസ്റ്റിംഗ് കോഡെര്\u200dഡില്\u200d ആശ്രയിക്കുന്നത് എന്ന്. സെമാന്റിക് റോള്\u200d ലേബെല്ലര്\u200d ഇംഗ്ലീഷില്\u200d മത്സരത്തിലുള്ള പ്രദര്\u200dശിദ്ധ പ്രവര്\u200dത്തനങ്ങള്\u200d എത്തുന്നു. ഒരു തരം സിനിട്ടാക്ക എന്നാലും, സ്വയം പ്രത്യേകിച്ചിരിക്കുന്ന വാക്കുകളുടെ ഭാഗം ഇന്\u200dപുട്ടായി നല്\u200dകുമ്പോള്\u200d അത് മുമ്പുള്ള എല്ലാ ലോക്കല്\u200d മോഡലുകളും പ്രവര്\u200dത്തിപ്പിക് നമ്മളും ചൈനീസ്, ചെക്കും സ്പാനിഷും പരിഗണിക്കുന്നു. നമ്മുടെ അടുത്തുള്ള പരിഗണന ഫലങ്ങളും എത്തുന്നു. സിന്റാക്റ്റിക്ക് പാര്\u200dസറുകള്\u200d ഡൊമെയിന്\u200d വിവരങ്ങളില്\u200d നിന്നും പുറത്തുകടക്കാന്\u200d സാധ്യമല്ല, അതുകൊണ്ട് സാധ്യതയുള്ള (അതായത്, സിന്റാക് നമ്മുടെ സിന്റാക്സ്-ആഗ്നോസ്റ്റിക് മോഡല്\u200d കൂടുതല്\u200d റോബ്സ്റ്റ് കാണുന്നു. അതിനാല്\u200d സാധാരണ ഡോമെന്\u200d പരീക്ഷണത്തിന്റ', 'pl': 'Wprowadzamy prosty i dokładny model neuronowy oparty na zależności semantycznego oznaczania roli. Nasz model przewiduje zależności predykat-argument opierając się na stanach dwukierunkowego kodera LSTM. Semantyczny oznaczacz roli osiąga konkurencyjną wydajność w języku angielskim, nawet bez jakichkolwiek informacji składniczych i wykorzystując tylko lokalne wnioski. Jednak gdy automatycznie przewidywane tagi części mowy są dostarczane jako wejście, znacznie przewyższa wszystkie poprzednie modele lokalne i podejmuje najlepsze raportowane wyniki w angielskim zbiorze danych CoNLL-2009. Rozważamy również chiński, czeski i hiszpański, gdzie nasze podejście osiąga również konkurencyjne wyniki. Parsery syntaktyczne są niewiarygodne na danych poza domeną, więc standardowe (tj. poinformowane składnią) modele SRL są utrudnione podczas testowania w tym ustawieniu. Nasz model agnostyczny składni wydaje się bardziej solidny, co skutkuje najlepszymi raportowanymi wynikami w standardowych zestawach testów poza domeną.', 'mn': 'Бид хамааралтай байдал дээр суурилсан semantic role labeling гэх энгийн, шууд мэдрэлийн загварыг танилцуулдаг. Бидний загвар нь хоёр дахь загварын LSTM кодлогчийн байр суурь дээр байрлах аргументын хамааралтай байдлыг таамагладаг. Зөвхөн англи хэл дээр өрсөлдөг үйл ажиллагаа хийдэг. Ямар ч синтактик мэдээлэл байхгүй, зөвхөн орон нутгийн халдвар хэрэглэдэггүй. Гэхдээ автоматаар ярианы нэг хэсэг тайлбаруудыг оруулах үед энэ нь өмнөх орны загваруудын бүх загваруудыг нэмэгдүүлж, Англи хэлний CoNLL-2009 өгөгдлийн сангийн хамгийн сайн мэдээллийн үр дүнд хүрэх болно. Бид мөн Хятад, Чех, Испан улсын арга зам нь өрсөлдөөний үр дүнг хүртэх газар бодож байна. Синтактикийн парсартууд дотоод бус мэдээллээр итгэлтэй байдаг. Тиймээс стандарт (синтактик мэдээллээр) SRL загварууд энэ тохиолдолд шалгахад зогсогддог. Бидний синтаксис-агностик загвар илүү хүчтэй харагдаж байна. Үүний үр дүнд стандарт бус домены шалгалтын хамгийн сайн мэдээллийн үр дүнг гаргаж байна.', 'no': 'Vi introduserer ein enkel og nøyaktig neuralmodell for merkelapp på semantiske roller basert på avhengighet. Modellen vårt foregår avhengighet av predikat argument som tilhøyrer tilstandane til ein bidireksjonal LSTM-kodar. Det semantiske rolletiketten oppnår konkurrentivt utvikling på engelsk, sjølv utan nokon type syntaksisk informasjon og berre brukar lokal infeksjon. Men når det vert automatisk foregått deltaletaggar som inndata, vil det utføra alle førre lokale modeller og nærma dei beste rapporterte resultatene på datasettet CoNLL- 2009. Vi ser også synleg kinesisk, tsjekkisk og spansk der tilnærminga vårt finn også konkurentære resultat. Syntaktiske tolkar er ikkje tillit på uten domenedata, så standard (t.d. syntaktisk informert) SRL- modeller blir hindra når testar i denne innstillinga. Vårt syntaks-agnostisk modell ser meir sterkt, som fører til dei beste rapporterte resultatene på standardverstatt av domenet.', 'ro': 'Introducem un model neural simplu și precis pentru etichetarea rolurilor semantice bazate pe dependență. Modelul nostru prezice dependențele predice-argument bazându-se pe stările unui codificator LSTM bidirecțional. Etichetatorul de roluri semantice obține performanțe competitive în limba engleză, chiar și fără nici un fel de informație sintactică și folosind doar deducția locală. Cu toate acestea, atunci când etichetele parțial de vorbire prevăzute automat sunt furnizate ca intrare, aceasta depășește substanțial toate modelele locale anterioare și abordează cele mai bune rezultate raportate pe setul de date CoNLL-2009 în limba engleză. Considerăm, de asemenea, chineză, cehă și spaniolă unde abordarea noastră obține, de asemenea, rezultate competitive. Analizoarele sintactice nu sunt fiabile pe datele din afara domeniului, astfel incat modelele standard (adica, informate sintactic) SRL sunt impiedicate atunci cand sunt testate in aceasta setare. Modelul nostru agnostic de sintaxă pare mai robust, rezultând cele mai bune rezultate raportate pe seturile standard de testare din afara domeniului.', 'sr': 'Predstavljamo jednostavan i tačan neuralni model za etiketiranje semantičkih uloga na osnovu zavisnosti. Naš model predviđa zavisnost predikata argumenata koja se oslanja na države dvodirektivnog kodera LSTM-a. Semantički etiketer uloge postiže konkurentnu predstavu na engleskom, čak i bez bilo kakvih sintaktičkih informacija i samo koristi lokalnu infekciju. Međutim, kada se automatski predviđaju oznake dijela govora kao ulaz, to značajno iznosi sve prethodne lokalne modele i približava najboljem izveštajnom rezultatu na engleskom sastavu podataka CoNLL-2009. Takođe razmišljamo o kineskom, češkom i španjolskom mestu gde naš pristup takođe postiže konkurentni rezultati. Синтактични парзери не могу да се доверују у данима о недомени, тако што се стандартни (т.е. синтактично информирани) модели SRL препятствују при испытанији у овом наставке. Naš sintaks-agnostički model izgleda jak, što je rezultat najboljih izveštaja na standardnim testovima izvan domena.', 'si': 'අපි සාධාරණ සහ සිද්ධ න්\u200dයූරල් මොඩල් එකක් පෙනුම් කරනවා විශේෂතාවක් අධාරණය වෙනුවෙන් සිමාන් අපේ මන්ද්\u200dරය ප්\u200dරතිස්ථානයක් ප්\u200dරතිස්ථානය කරන්නේ ප්\u200dරතිස්ථානයක් විශ්වාස කරනවා දෙන්න ප්\u200dරතිස්ථාන සෙමැන්ටික් ප්\u200dරධානය ලේබලර් ඉංග්\u200dරීසියේ ප්\u200dරධානය ප්\u200dරධානයක් ලැබෙනවා, කිසිම වගේ සංකේතික තොරතුරු  නමුත්, ස්වයංක්\u200dරියාවිතයෙන් ස්වයංක්\u200dරියාත්මක විශ්වාස කරන්න පුළුවන් කොටස් කිරීමක් ඇතුළත් විදියට, ඒක ප්\u200dරශ්ණයෙන් පිළ අපි චීනි, චෙක් සහ ස්පැනිස් වලින් හිතනවා අපේ ප්\u200dරවේශනය ප්\u200dරතිචාරයක් ලැබෙනවා. සංකේතික පරීක්ෂකයන්ට මෙම සැකසුමේ පරීක්ෂණය කරන්න පුළුවන් නැහැ ඩොමේන් දත්තේ, ඉතින් ස්ථානය (ඉතින්, සංකේතිකිරීම සඳහ අපේ සංවේදනය-අග්නොස්ටික් මොඩල් තරම් ශක්තිමත් වෙනවා, ප්\u200dරමාණයක් නැතිවෙන්න පුළුවන් පරීක්ෂණ සැටිම්', 'kk': 'Тәуелсіздік негіздеген семантикалық рольді жарлықтау үшін қарапайым және дұрыс невраллық моделін келтірік. Біздің үлгіміздің алдын- ала аргументтің тәуелдігін екі- директивалы LSTM кодерінің күйіне қалдырып тұрады. Семантикалық роль жарлығы ағылшын тілінде әрекетті әрекеттерді жеткізеді, сондай-ақ синтактикалық мәліметтер жоқ және тек жергілікті қалдыруды қолданады. Бірақ, автоматты түрде сөйлеу тегтерінің бір бөлігін келтірілген кезде, ол барлық алдыңғы жергілікті үлгілерді жасап, ағылшын CoNLL- 2009 деректер жиынының ең жақсы хабарлаған нәтижелеріне қатына Қытайша, Чех және Испан тілдеріміздің жағдайларымыздың сол жағдайда жақсы нәтижелерін жеткізеді. Синтактикалық талдаушылар доменге тыс деректерде сенімді болмайды, сондықтан стандартты (мәлімет синтактикалық) SRL үлгілері осы параметрде сынау үшін сақталмайды. Синтаксис- агностикалық моделіміз көбірек синтаксис үлгісін көрсетеді, сондықтан стандартты доменге шығыс сынақтардың ең жақсы нәтижелері бар.', 'so': "Tusaale sahlan oo sahlan oo neurada ah waxaynu soo bandhignaynaa qoraalka qayb ah oo ku xiran tahay. Tusaale'yadeenu wuxuu horay u sheegaa inay ku xiran tahay dowlada qoraalka LSTM oo ku qoran. Calaamada qaybta semantiki wuxuu ku gaadhaa bandhig ku saabsan Ingiriiska, xitaa macluumaad la’aan ah iyo isticmaalka cudurada degmada oo keliya. Si kastaba ha ahaatee, marka lagu soo bandhigayo qeyb ka mid ah warqadaha hadalka, wuxuu si weyn u sameeyaa modelalka hore ee deegaanka, wuxuuna u soo dhowaadaa resultiyada ugu fiican ee lagu soo sheegay qoraalka aqoonsiga Ingiriiska CoNLL-2009. Sidoo kale waxaynu ka fiirsanaynaa Shiino, Czech iyo Isbanish meesha aan soo galno arimaha iskutallaabta ah. Syntactic parsers are unreliable on out-of-domain data, so standard (i.e., syntactically-informed) SRL models are hindered when tested in this setting.  Tusaalkayaga sintada-agnostika ayaa ka muuqata mid ka badan, waxaana sababtay resultiyada ugu wanaagsan ee lagu soo sheegay marka lagu jiro sameynta imtixaanka gudaha.", 'sv': 'Vi introducerar en enkel och korrekt neural modell för beroendebaserad semantisk rollmärkning. Vår modell förutspår beroenden av predikat-argument beroende på tillstånd för en dubbelriktad LSTM-kodare. Den semantiska rollmärkningen uppnår konkurrenskraftig prestanda på engelska, även utan någon form av syntaktisk information och endast med hjälp av lokala slutsatser. Men när automatiskt förutspådda deltal-taggar tillhandahålls som inmatning överträffar den betydligt alla tidigare lokala modeller och närmar sig de bäst rapporterade resultaten från den engelska CoNLL-2009-datauppsättningen. Vi tar även hänsyn till kinesiska, tjeckiska och spanska där vårt tillvägagångssätt också ger konkurrenskraftiga resultat. Syntaktiska tolkare är opålitliga på data utanför domänen, så standard (dvs. syntaktiskt informerade) SRL-modeller hindras när de testas i den här inställningen. Vår syntaxagnostiska modell verkar mer robust, vilket resulterar i de bästa rapporterade resultaten på standardtestuppsättningar utanför domänen.', 'ta': 'நம்பிக்கை அடிப்படையில் சார்ந்த semantic பங்கை குறிப்பிடுவதற்கான எளிய மற்றும் சரியான புதிய மாதிரி முறைமையை  நம்முடைய மாதிரி முன்னிருப்பு வார்த்தைகளை முன்விரும்புகிறது ஒரு முறை LSTM குறியீட்டில் நம்பிக்கை உள்ளது. பெமான்டிக் பங்கு குறியீட்டு ஆங்கிலத்தில் போராட்டி செயல்பாட்டை பெறுகிறது, எந்த வகையான ஒத்திசைவு தகவலும் இல்லாமல ஆயினும், தானாகவே முன்னோக்கப்பட்ட பேச்சின் பகுதி குறிகள் உள்ளீடாக கொடுக்கப்படும் போது, அது முந்தைய உள்ளூர் மாதிரிகளையும் வெளியேற்றுகிறத நாம் சீன, செக் மற்றும் ஸ்பானிஷ் மற்றும் கருதுகிறோம் எங்கள் அணுகும் போதுமான முடிவுகளை பெறுகிறது. தொடர்புடைய பார்சர்கள் டொமைன் வெளியேறும் தகவலில் புரியாது, அதனால் நிலையான (அதாவது, ஒத்திசைவாக அறிவிக்கப்பட்ட) SRL மாதிரிகள் இந்த அமைப எங்கள் ஒத்திசைநெக்ஸ்டிக் மாதிரி மிகவும் தெரியும், சிறந்த அறிக்கப்பட்ட முடிவு', 'ur': 'ہم ایک ساده اور دقیق نئورل موڈل کو معلوم کریں گے۔ ہمارا مدل پیش بینی کرتا ہے کہ ایک دوسری مستقل LSTM کوڈر کی حالت پر اعتماد رکھتے ہیں. سیمنٹی رول لیبلر انگلیسی پر مسابقات کی فعالیت حاصل کرتا ہے، اگرچہ کسی طرح کی سینٹکتیک معلومات کے بغیر اور صرف محلی نازل کی استعمال کرتا ہے. However, when automatic predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the English CoNLL-2009 data set. ہم بھی چینی, چک اور اسپانیایی کی فکر کرتے ہیں جہاں ہمارا تقریبا بھی مسابقات نتائج پہنچتا ہے۔ سینٹاکتیک پارس ڈومین کے بیرون سے ڈاٹ پر یقین نہیں رکھتے، لہٰذا استاندارڈ (یعنی سینٹاکتیک-اطلاع) SRL موڈل اس تنظیمات میں آزمائش کی حالت میں روکا جاتا ہے. ہماری سینٹکس-اگنیسی موڈل زیادہ طاقتور بن رہی ہے، اس کے نتیجہ میں استاندارڈ آئٹ-ڈومین تست سٹ کے بہترین گزارے نتیجے ہیں.', 'uz': "Biz tashkilotga ishlatadigan semantik roli lab chiqarish uchun oddiy va aniqlangan neyrol modelini anglatamiz. Bizning modelimiz bir qanday LSTM kodlash davomida ishlatayotganimizga ishonch qo'shiladi. Seymantik role labeleri ingliz tilida rivojlanish natijalarini bajaradi, xato hech qachon qanday syntactik maʼlumot yoʻq va faqat lokal infeksiyatlarni ishlatish mumkin. Lekin, avtomatik koʻrsatilgan suhbatning qismlari kiritilganda, u oldingi lokal modellarni bajaradi va ingliz tilidagi CoNLL-2009 maʼlumotlar tarkibidagi eng yaxshi taʼminlovchi natijalarni bajaradi. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results.  Name Bizning syntax-agnostik modelimiz ko'proq robot ko'rinadi, bu sohalarning andoza tizimdan chiqishni bajaradi.", 'vi': 'Chúng tôi giới thiệu một mô hình thần kinh đơn giản và chính xác cho mô tả các vai khác nhau. Mẫu của chúng tôi dự đoán các phụ thuộc vào tình trạng của bộ mã hóa LSD di động. The semantics role labler results competition on English, even without any kind of sync Information and only using local infectionce. Tuy nhiên, khi tự động dự đoán các thẻ phần phát biểu được cung cấp như nhập, nó hoàn toàn vượt trội tất cả các mẫu địa phương trước và tiếp cận kết quả thông báo tốt nhất trên bộ dữ liệu Coyl-2009. Chúng tôi cũng xem xét Trung Quốc, Séc và Tây Ban Nha nơi cách tiếp cận của chúng tôi đạt được kết quả cạnh tranh. Người phân tích cú pháp không đáng tin trên dữ liệu ngoài miền, nên mô- đun S.L. bị cản trở khi thử nghiệm trong thiết lập này. Cơ chế cú pháp-chẩn của chúng ta có vẻ vững chắc hơn, dẫn đến kết quả báo cáo tốt nhất trên các bộ thử loại ngoài miền tiêu chuẩn.', 'hr': 'Upoznajemo jednostavan i precizan neuralni model za označavanje semantičkih uloga na osnovu ovisnosti. Naš model predviđa predikatne ovisnosti o argument koji se oslanjaju na države bidirektivnog kodera LSTM-a. Etiketar semantičke uloge postiže konkurentnu učinku na engleskom jeziku čak i bez bilo kakvih sintaktičkih informacija i samo koristi lokalnu infekciju. Međutim, kada se automatski predviđaju oznake dio govora kao ulaz, to značajno iznosi sve prethodne lokalne modele i pristupi najboljem izvješćenim rezultatima na setu podataka engleskog CoNLL-2009. Također smatramo kineskim, češkim i španjolskim, gdje naš pristup također postigne konkurentne rezultate. Sintaktički analizatori su neuvjerljivi na podacima izvan domena, tako da se standardni (tj. sintaktički informirani) modeli SRL sprječavaju kada su testirani u ovom nastavku. Naš sintaks-agnostički model izgleda jači, što je rezultat najboljih izvještaja na standardnim testovima izvan domena.', 'nl': 'We introduceren een eenvoudig en nauwkeurig neuraal model voor afhankelijkheidsgebaseerde semantische rollabeling. Ons model voorspelt predicate-argument afhankelijkheden gebaseerd op de toestanden van een bidirectionele LSTM encoder. De semantische rollabeler bereikt concurrerende prestaties op het Engels, zelfs zonder enige vorm van syntactische informatie en alleen met behulp van lokale inferentie. Wanneer echter automatisch voorspelde part-of-speech tags als input worden verstrekt, presteert het aanzienlijk beter dan alle eerdere lokale modellen en benadert het de best gerapporteerde resultaten op de Engelse CoNLL-2009 dataset. We denken ook aan Chinees, Tsjechisch en Spaans waar onze aanpak ook concurrerende resultaten oplevert. Syntactische parsers zijn onbetrouwbaar op out-of-domain data, dus standaard (d.w.z. syntactisch geïnformeerde) SRL modellen worden gehinderd wanneer getest in deze instelling. Ons syntaxis-agnostisch model lijkt robuuster, wat resulteert in de best gerapporteerde resultaten op standaard out-of-domain testsets.', 'da': 'Vi introducerer en enkel og præcis neural model for afhængighedsbaseret semantisk rollemærkning. Vores model forudsiger forudsigelige argumentafhængigheder afhængige af tilstande i en tovejet LSTM-koder. Den semantiske rollemærkning opnår konkurrencedygtige resultater på engelsk, selv uden nogen form for syntaktisk information og kun ved hjælp af lokal konklusion. Men når automatisk forudsigede dele af tale-tags leveres som input, overgår det væsentligt alle tidligere lokale modeller og nærmer sig de bedst rapporterede resultater på det engelske CoNLL-2009 datasæt. Vi overvejer også kinesisk, tjekkisk og spansk, hvor vores tilgang også giver konkurrencedygtige resultater. Syntaktiske fortolkere er upålidelige på data uden for domænet, så standard (dvs. syntaktisk informerede) SRL-modeller forhindres, når de testes i denne indstilling. Vores syntaksagnostiske model fremstår mere robust, hvilket resulterer i de bedste rapporterede resultater på standard testsæt uden for domænet.', 'id': 'Kami memperkenalkan model saraf sederhana dan akurat untuk label peran semantis berdasarkan dependensi. Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder.  Label peran semantis mencapai prestasi kompetitif dalam bahasa Inggris, bahkan tanpa informasi sintaks apapun dan hanya menggunakan kesimpulan lokal. Namun, ketika secara otomatis diprediksi bagian-dari-pidato tags disediakan sebagai input, itu secara substansial melebihi semua model lokal sebelumnya dan mendekati hasil terbaik yang dilaporkan pada set data CoNLL-2009 Inggris. Kami juga mempertimbangkan Cina, Ceko dan Spanyol di mana pendekatan kita juga mencapai hasil kompetitif. Penganalis sintaktik tidak dipercaya pada data luar domain, jadi standar (i.e., secara sintaksi-informasi) model SRL dihalangi ketika diuji dalam seting ini. Model sintaks-agnostik kami tampak lebih kuat, menghasilkan hasil terbaik yang dilaporkan pada set tes standar luar domain.', 'de': 'Wir führen ein einfaches und genaues neuronales Modell für abhängigkeitsbasierte semantische Rollenbeschriftung ein. Unser Modell prognostiziert Vorhersage-Argument-Abhängigkeiten basierend auf Zuständen eines bidirektionalen LSTM-Encoders. Der semantische Rollenbeschrifter erzielt wettbewerbsfähige Leistungen auf Englisch, auch ohne syntaktische Informationen und nur mit lokaler Inferenz. Wenn jedoch automatisch vorhergesagte Teile-der-Sprache-Tags als Eingabe bereitgestellt werden, übertrifft sie alle vorherigen lokalen Modelle erheblich und nähert sich den besten gemeldeten Ergebnissen im englischen CoNLL-2009-Datensatz an. Wir berücksichtigen auch Chinesisch, Tschechisch und Spanisch, wo unser Ansatz auch wettbewerbsfähige Ergebnisse erzielt. Syntaktische Parser sind auf Daten außerhalb der Domäne unzuverlässig, so dass Standard (d. h. syntaktisch informierte) SRL-Modelle behindert werden, wenn sie in dieser Einstellung getestet werden. Unser syntax-agnostisches Modell erscheint robuster, was zu den besten Ergebnissen für Standard-Out-of-Domain-Testsets führt.', 'ko': '우리는 간단하고 정확한 의존 관계를 바탕으로 하는 의미 역할 표기 신경 모델을 소개했다.우리의 모델은 쌍방향 LSTM 인코더의 상태에 따라 술어 파라미터의 의존 관계를 예측한다.의미 역할 labeler는 영어에서 경쟁력이 있고 문법 정보가 없어도 국부 추리만 사용한다.그러나 자동 예측된 어성 라벨이 입력으로 제공될 때, 그 성능은 이전의 모든 로컬 모델보다 훨씬 우수하고, 영어 CoNLL-2009 데이터 집합의 가장 좋은 보고 결과에 가깝다.중국, 체코, 스페인도 고려했고 이들 국가에서 우리의 방법도 경쟁력 있는 결과를 얻었다.구문 분석기는 도메인 밖 데이터에서 신뢰할 수 없으므로 이러한 환경에서 표준(즉 구문 정보)인 SRL 모델을 테스트할 때 장애가 발생합니다.우리의 문법 불가지 모델은 더욱 건장해 보이며 표준 역외 테스트 집합에서 가장 좋은 보고 결과를 얻었다.', 'sw': 'Tunaonyesha muundo rahisi na sahihi wa neura wa jukumu la kishindani linalotegemea. Mfano wetu unatabiri kuwa hoja zinategemea kwenye majimbo ya mfumo wa LSTM. Mchoro wa jukumu la kimapenzi unafanikiwa kufanya ushindani katika lugha ya Kiingereza, hata bila taarifa yoyote ya ushirikiano na kutumia maambukizi ya ndani tu. Hata hivyo, pale ambapo baadhi ya alama za hotuba zinazotabiriwa kwa manufaa ya kujieleza kama input, inafanya vibaya mifano yote ya zamani ya maeneo ya kijamii na kuingilia matokeo bora yanayoripotiwa kwenye seti ya data ya Kiingereza ya CoNLL-2009. Pia tunafikiria pia China, Czech na Kihispania ambapo hatua yetu pia inafanikiwa matokeo ya ushindani. Wabunge wa kitendo hicho hawana uwezekano wa kutoa taarifa za ndani, kwa hiyo miundo mbinu ya SRL yanazuiwa wakati wa jaribio hili. Mfano wetu wa usambazaji wa kodi unaonekana kuwa unavurugwa zaidi, na unasababisha matokeo bora yaliyoripotiwa juu ya matokeo ya viwango vinavyotokea nje ya majaribio ya ndani.', 'tr': 'Biz daşarylygyna dayanan semantik rol etiketlemesi üçin basit we dogry bir näral nusgasyny tanyşdyrýarys. Biziň modelimiz öň bellenen-argüm baglançylyklary bidireksiyonal LSTM kodçysynyň durumlara baglanýandygyny çaklaýar. Semantik näme etiketçisi Iňlis dilinde ýaryşykly ukyp başarýar, hatda hiç hili bir şekilde syntaktik maglumatlary ýok we diňe ýerli hasaplanjak ullanýar. Ýöne, haçanda otomatik olar çykyş tägleriň bir parçasyny giriş hökmünde üýtgedilýän bolsa, ol ýerli nusgalaryň hemmesini gowy görkez we iňlisçe CoNLL-2009 veri setirinde en gowy rapor eden netijesine golaýar. Biz hem Çinçe, Çehiýa we Ispaniýaly pikir edýäris, munuň ýaryşymyzyň ýaryşykly netijelerini ýetip bilýäris. Sintaktik analyzçylar öz-domain maglumatynda ynamly däl, şonuň üçin bu düzümlerde testi edilýän zaman standart (modal-informed) SRL modelleri barlanmaýar. Sintaks-agnostik modelimiz daha güçlü görünýär. Sonuçta standart out-of-domain testi düzenlerinde iñ gowy rapor edilen netijelerimize netije gelýär.', 'fa': 'ما یک مدل عصبی ساده و دقیق برای برچسب نقش semantic based dependency را معرفی می کنیم. مدل ما پیش\u200cبینی می\u200cکند که بستگی\u200cهای پیش\u200cبینی\u200cهای اردوмент بر وضعیت\u200cهای یک رمز\u200cدهنده LSTM دوباره بستگی دارد. برچسب نقش semantic به اجرای مسابقه در انگلیسی رسیده است، حتی بدون هیچ نوع اطلاعات سنتاکتیک و تنها با استفاده از آلودگی محلی. ولی هنگامی که برچسب\u200cهای پاره\u200cای از سخنرانی را به طور خودکار پیش\u200cبینی می\u200cکنند به عنوان ورودی داده می\u200cشوند، آن بسیار بیشتر از همه مدل\u200cهای محلی پیش\u200cبینی می\u200cکند و به بهترین نتایج گزارش داده شده در مجموعه داده\u200cهای انگلیسی CoNLL ما همچنین چینی، چک و اسپانیایی را در نظر می گیریم که دسترسی ما به نتایج رقابت رسیده است. بررسی\u200cکننده\u200cهای سنتاکتیک در داده\u200cهای خارج از دومین قابل اعتماد نیستند، بنابراین مدل\u200cهای SRL استاندارد (یعنی با اطلاعات سنتاکتی) زمانی که در این تنظیمات آزمایش می\u200cشود بازداشت می\u200cشوند. مدل سنتاکس-agnostic ما قوی تر به نظر می رسد، به نتیجه بهترین نتیجه گزارش داده شده در مجموعه آزمایش استاندارد خارج از دومین.', 'sq': 'Ne prezantojmë një model nervor të thjeshtë dhe të saktë për etiketën semantike të rolit bazuar në varësi. Modeli ynë parashikon varësitë e predikatës-argumentit mbështetur në shtetet e një koduesi LSTM dy-drejtues. Etiketari semantik arrin performancë konkurruese në anglisht, edhe pa ndonjë lloj informacioni sintaktik dhe vetëm duke përdorur përfundimet lokale. Megjithatë, kur shënimet e parashikuara automatikisht të pjesës së fjalimit janë dhënë si hyrje, ajo tejkalon në mënyrë të konsiderueshme të gjitha modelet e mëparshme lokale dhe afrohet rezultateve më të njoftuara më të mira në grupin e të dhënave angleze CoNLL-2009. Ne gjithashtu konsiderojmë kinezë, çeke dhe spanjollë ku metoda jonë arrin gjithashtu rezultate konkurruese. Analizatorët sintaktikë nuk janë të besueshëm në të dhënat jashtë domenisë, kështu që modelet standard e (i cili është informuar sintaktikisht) SRL pengohen kur testohen në këtë rregullim. Modeli ynë sintaks-agnostik duket më i fortë, duke rezultuar në rezultatet më të njoftuara më të mira në grupet standarde testesh jashtë domenisë.', 'bg': 'Въвеждаме прост и точен невронен модел за базирано на зависимост семантично етикетиране на роли. Нашият модел прогнозира зависимости между прогнозите и аргументите, разчитайки на състоянията на двупосочен кодер. Етикетът за семантична роля постига конкурентни резултати на английски език, дори без никаква синтактична информация и само използвайки локални изводи. Въпреки това, когато автоматично прогнозираните маркери за част от речта са предоставени като вход, то значително превъзхожда всички предишни местни модели и подхожда към най-добрите докладвани резултати в английския набор от данни CoNLL-2009. Също така разглеждаме китайски, чешки и испански, където нашият подход също постига конкурентни резултати. Синтактичните анализатори са ненадеждни на данни извън домейна, така че стандартните (т.е. синтактично информирани) модели са възпрепятствани при тестване в тази настройка. Нашият синтаксис-агностичен модел изглежда по-здрав, което води до най-добрите докладвани резултати при стандартни тестови набори извън домейна.', 'am': 'በተደጋገመች የsemantic role ማሳየት ቀላል እናስፈልጋለን፡፡ ሞዴሌያችን የግንኙነታችንን አካባቢ የLSTM የኮድ አካላት በመደገፍ ላይ የሚደገፍ ነው ይናገራል፡፡ የsemantic role labeler በንግግሊዝኛ ላይ የሚዋጋውን ድምፅ አግኝቷል፤ ምንም ዓይነት የሲንተርታዊ መረጃ ባይኖር እና የአገራዊ ድምፅ ብቻ በመጠቀም ይችላል፡፡ ምንም እንኳን፣ የንግግር ማዕከላዊ ክፍል እንደ ውስጥ በተቀረበ ጊዜ፣ የቀድሞውን የአገሪክ ኮንLL-2009 ዳታዎችን በመስጠት የተመረጠውን ውጤቶች ይደርሳል፡፡ የቻይና፣ ቻክክ እና ስፓኒሽ አካሄዳችን የሥልጣን ፍሬዎችን ደግሞ የሚያገኙ እንደሆነ እናስታውቃለን፡፡ Syntactic Parsers out of domain data so standard (i.e. syntactically-informed) models are hindered when they are tested. Syntax-agnostic ሞዴሌዎቻችን የበለጠ ልብስ ይመስላል፡፡ ከዶሜን ውጭ-ውጭ የሞክራዊ ፍሬዎችን በመፍጠር ይደረጋል፡፡', 'af': "Ons introduseer 'n eenvoudige en presies neurale model vir afhanklikheid-gebaseerde semantiese roletiketting. Ons model voorskou predikaat- argument afhanklikhede wat op staatste van 'n bidireksjonale LSTM-enkoder vertrou. Die semantiese rol etiketeerder bereik mededingstekens op Engels, selfs sonder enige soort sintaktika inligting en slegs plaaslike inferensie te gebruik. Maar wanneer automaties voorskou deel- van- spreek etikette as invoer verskaf word, word dit betekens uitgevoer alle vorige plaaslike modele en naby die beste verkondige resultate op die Engels CoNLL- 2009 datastel. Ons beskou ook Sjinese, Tschese en Spaanse waar ons toegang ook mededingsresultate bereik word. Sintaksiese verwerkers is onvertroubaar op buite- van- domein data, sodat standaard (bv. sintaksies- inligtig) SRL modelle word verhinder wanneer in hierdie opstelling toets word. Ons sintaks-agnostiese model verskyn meer kragtige, wat resultaat in die beste berigte resultate op standaard uit-domein toets stel.", 'hy': 'Մենք ներկայացնում ենք մի պարզ և ճշգրիտ նյարդային մոդել կախվածությամբ հիմնված սեմանտիկ դերի պիտակում: Մեր մոդելը կանխատեսում է, որ կախվածությունը կախված է երկու ուղղությամբ LSMT-ի կոդերի վիճակից: Սեմանտիկ դերի պիտակ հասնում է անգլերենում մրցակցության արդյունք, նույնիսկ առանց որևէ սինտակտիկ տեղեկատվության և միայն տեղական հետևանքների օգտագործման: Այնուամենայնիվ, երբ ավտոմատ կանխատեսված խոսքի մասերը տրամադրվում են որպես ներմուծք, այն նշանակաբար գերազանցում է նախորդ տեղական մոդելները և մոտենում է Անգլերենի CONSL-2009 տվյալների համակարգի լավագույն հայտարարված արդյունքներին: We also consider Chinese, Czech and Spanish where our approach also achieves competitive results.  Սինտակտիկ վերլուծումները անվստահելի են ոչ տիեզերքի տվյալների վրա, ուստի ստանդարտ (այսինքն, սինտակտիկ տեղեկացված) SSL մոդելները խոչընդոտում են, երբ փորձարկում են այս միջոցով: Our syntax-agnostic model appears more robust, resulting in the best reported results on standard out-of-domain test sets.', 'bs': 'Predstavljamo jednostavan i tačan neuralni model za merging semantičke uloge na osnovu zavisnosti. Naš model predviđa predikatne ovisnosti o argumentima koji se oslanjaju na države dvodirektivnog kodera LSTM-a. Etiketar semantičke uloge postiže konkurentne učinke na engleskom jeziku, čak i bez bilo kakvih sintaktičkih informacija i samo koristeći lokalnu infekciju. Međutim, kada se automatski predviđaju oznake dio govora kao ulaz, to značajno iznosi sve prethodne lokalne modele i približava najboljem izvještajnom rezultatu na setu podataka engleskog CoNLL-2009. Također razmišljamo o kineskom, češkom i španjolskom mjestu gdje naš pristup također postigne konkurentne rezultate. Sintaktični parseri su nepouzdani na podacima izvan domena, tako da se standardni (tj. sintaktički informirani) modeli SRL sprječavaju kada su testirani u ovom nastavku. Naš sintaks-agnostički model izgleda jači, što je rezultat najboljih izvještaja na standardnim testovima izvan domena.', 'az': 'Biz sadəcə və doğru bir nöral modeli bağımlılıq tabanlı semantik rol etiketi üçün təşkil edirik. Bizim modellərimiz öyrəndi-arqümet bağlılıqlarını, ikidiktiraqlı LSTM kodlayıcısına təvəkkül edir. Semantik rol etiketçisi İngilizce barəsində münafiqli performans tapır, heç bir sintaktik məlumatı olmadan və yalnız yerli infeksiya istifadə edir. Lakin, öz-özündən tədbir edilən söz etiketlərinin bir parças ını daxil olaraq təmin edildiyi zaman, o, əvvəlki yerli modellərin bütün modellərini çox üstün edər və İngilis CoNLL-2009 veri qutusundakı ən gözəl xəbərdar sonuçlarına yaxınlaşır. Biz də Çinli, Çehir və İspanyol tərəfimizin münafiqli sonuçlarını başa çatdığı yerə düşünürük. Sintaktik ayırıcılar dış domena verilənlərdə güvenilir, böylece standart (sintaktik bilgili) SRL modelləri bu ayarlarda sınamağa mane edilərlər. Sintaks-agnostik modellərimiz daha qüvvətli görünür, standart dış domeini sınamaq qurularında ən gözəl xəbərdar sonuçlarımız olar.', 'ca': "Introduïm un model neural simple i precis per etiquetar el paper semàntic basat en la dependència. El nostre model predica les dependencies de predicat-argument basant-se en estats d'un codificador LSTM bidireccional. L'etiquetador de paper semàntic aconsegueix un rendiment competitiu en anglès, fins i tot sense cap tipus de informació sinàctica i només utilitzant la inferència local. Tot i així, quan s'aporten etiquetes predites automàticament com entrada, supera substancialment tots els models locals anteriors i aproxima els millors resultats reportats del conjunt de dades anglès CoNLL-2009. We also consider Chinese, Czech and Spanish where our approach also achieves competitive results.  Els analitzadors sintàtics no són fiables en dades fora de domini, així que els models SRL estàndard (és a dir, sintàticament informats) són obstaculitzats quan es testen en aquest entorn. El nostre model sintaxi-agnòstic sembla més robust, i resulta en els millors resultats de les proves estandards fora de domini.", 'bn': 'আমরা নির্ভরিত সেমেন্টিক ভূমিকা লেবেলের জন্য একটি সহজ এবং সঠিক নিউরেল মডেল চিহ্নিত করি। আমাদের মডেল ভবিষ্যদ্বাণী করেছে যে বিদ্যমান এলস্টিএম এনকোডারের রাষ্ট্রে নির্ভর করছে। সেম্বান্টিক ভূমিকা লেবেলার ইংরেজীতে প্রতিযোগিতায় প্রতিযোগিতা প্রদর্শন করে, এমনকি কোন ধরনের সাথে সিন্ট্যাকটিক তথ্ তবে যখন স্বয়ংক্রিয়ভাবে প্রত্যাশিত ভাষণের অংশের ট্যাগ ইনপুট হিসেবে প্রদান করা হয়, তখন এটি পূর্ববর্তী স্থানীয় মডেলগুলো প্রদর্শন করে ইংরেজি কনএল-২০০ We also consider Chinese, Czech and Spanish where our approach also achieves competitive results.  এই বৈশিষ্ট্যাবলীতে পরীক্ষা করা হলে সিন্ট্যাক্টিক পার্সার বাইরে ডাটা বিশ্বাস করা যাচ্ছে না, তাই স্ট্যান্ডার্ড (যেমন সিন্ট্রাক্ট আমাদের সিন্ট্যাক্স-অ্যাগনোস্টিক মডেলের চেয়ে বেশী রোবট দেখা যাচ্ছে, যার ফলে ডোমেইন পরীক্ষার স্ট্যান্ডার্ডা', 'cs': 'Představujeme jednoduchý a přesný neuronový model pro značení rolí založené na závislosti. Náš model předpovídá závislosti predicate-argument spoléhající na stavy obousměrného LSTM kodéru. Sémantický označovač rolí dosahuje konkurenčního výkonu v angličtině, a to i bez jakéhokoliv druhu syntaktických informací a pouze pomocí lokální inference. Nicméně, když jsou jako vstup poskytnuty automaticky predikované značky části řeči, podstatně předčí všechny předchozí lokální modely a přibližuje se k nejlepším hlášeným výsledkům v anglickém datovém sadě CoNLL-2009. Zvažujeme také čínštinu, češtinu a španělštinu, kde náš přístup také dosahuje konkurenčních výsledků. Syntaktické parsery jsou nespolehlivé u dat mimo doménu, takže standardní (tj. syntakticky informované) SRL modely jsou při testování v tomto nastavení bráněny. Náš syntax-agnostický model se jeví robustnější, což vede k nejlepším hlášeným výsledkům u standardních mimo doménu testovacích sad.', 'et': 'Tutvustame lihtsat ja täpset närvimudelit sõltuvuspõhise semantilise rolli märgistamiseks. Meie mudel ennustab prognoosi-argumendi sõltuvusi, tuginedes kahesuunalise LSTM kodeerija olekutele. Semantiline rolli märgistaja saavutab inglise keeles konkurentsivõimelise tulemuse isegi ilma mingisuguse süntaktilise informatsioonita ja kasutades ainult kohalikku järeldust. Kui aga sisendina esitatakse automaatselt prognoositavad kõneosamärgid, ületab see oluliselt kõiki varasemaid kohalikke mudeleid ja läheneb inglise CoNLL-2009 andmekogumi parimatele esitatud tulemustele. Peame silmas ka hiina, tšehhi ja hispaania keelt, kus meie lähenemisviis saavutab ka konkurentsivõimelisi tulemusi. Süntaktilised parserid ei ole domeeniväliste andmete puhul usaldusväärsed, nii et standardsed (st süntaktiliselt informeeritud) SRL mudelid on selles sätetes testimisel takistatud. Meie süntaksiagnostiline mudel tundub tugevam, mille tulemuseks on parimad andmed standardsete domeeniväliste testide puhul.', 'fi': 'Esittelemme yksinkertaisen ja tarkan neuromallin riippuvuusperusteiseen semanttiseen roolimerkintään. Mallimme ennustaa ennuste-argumenttien riippuvuuksia kaksisuuntaisen LSTM-kooderin tiloihin perustuen. Semanttinen roolitunniste saavuttaa kilpailukykyisen suorituskyvyn englanniksi jopa ilman minkäänlaista syntaktista tietoa ja käyttämällä vain paikallista päättelyä. Kun syötteenä annetaan automaattisesti ennustetut puheen osatunnisteet, se kuitenkin ylittää huomattavasti kaikki aiemmat paikalliset mallit ja lähestyy parhaita raportoituja tuloksia englanninkielisessä CoNLL-2009 -aineistossa. Tarkastelemme myös kiinalaista, tšekkiä ja espanjaa, joissa lähestymistapamme saavuttaa myös kilpailukykyisiä tuloksia. Syntaktiset parserit eivät ole luotettavia verkkotunnuksen ulkopuolisissa tiedoissa, joten standardit (eli syntaktisesti informoidut) SRL-mallit ovat estyneet testattaessa tässä asetuksessa. Syntaksiagnostinen mallimme näyttää vankemmalta, mikä johtaa parhaisiin raportoituihin tuloksiin standardittomissa toimialueen ulkopuolisissa testisarjoissa.', 'jv': 'Awak dhéwé nggawe sistem sing sampeyan ngono kuwi model nêrung kuwi wis ana karo semanti kuwi nggawe barang seneng pisan. Monday Nambah semanti kuwi nggawe gerakan kang sampeyan ingkang sampeyan ingkang, lho ngono kuwi cah-cah penting sinaksi lan ijol-ijol kuwi wis dipun ajeng lokal sing apik. politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé ngerasakno Panjenengan Chinese, Chek lan Spanyol iki dadi, nik awak dhéwé iso ngejaraké barang sing paling maneh. String Kita sistem-agestik model sing paling kelas gak soalé, dadi piyambak ngono cah akeh barang nggawe barang dumadhan out-of-domain test seten.', 'he': "אנחנו מציגים מודל עצבי פשוט ודויק לתווית תפקידים סמנטיים מבוססת על תלויות. הדוגמא שלנו חוששת תלויות של טיעונים מתייחסים למדינות של קודד LSTM bidirectional. תווית התפקיד הסמנטי משיגה ביצועים תחרותיים באנגלית, אפילו בלי מידע סינטקטי כלשהו ורק בשימוש במסקנה מקומית. עם זאת, כאשר תוויות חלק מהנאום צפויות באופן אוטומטי מוספקות כתוצאה, זה משפיע בצורה משמעותית על כל הדוגמנים המקומיים הקודמים ומגיע לתוצאות הדווחות הטובות ביותר על קבוצת הנתונים אנגלית CoNLL-2009. אנחנו גם שוקלים סיני, צ'צ'י וספרדית היכן שהגישה שלנו גם משיגה תוצאות תחרותיות. מחקרי סינטקטיקה אינם אמינים על נתונים מחוץ לתחום, אז מודלים SRL סטנדרטיים (כלומר, מודיעים סינטקטיים) מוגבלים כאשר נבחנים במצב הזה. המודל הסינטקסי-אגנוסטי שלנו נראה חזק יותר, מה שהוביל בתוצאות הדווחות הטובות ביותר על קבוצות מבחנים מחוץ לתחום סטנדרטיים.", 'ha': "Tuna fara wani misali mai sauƙi da lissafa na neural da ke lissafa rubutun da ke dõgara. Tuduniyarmu na gabatar da baka-argument, yana dõgara a kan halin kode na LSSM. The semantic role player yana sãmun babban rabon da ke cikin Ingiriya, kõ da kuma bã da wani irin mutane na haɗatiki kuma yana amfani da kwamfyutan lokaci kawai. However, when automatically predicted part-of-speech tags are provided as input, it substantially outperforms all previous local models and approaches the best reported results on the English CoNLL-2009 dataset.  Kayya, Munã ƙaddara China, Czech da Isbanish a inda hanyõyinmu ke sami matsala masu bastarwa. Parser ɗin syntactic ba'a iya sami da data masu fitarwa ba, don haka an hana masallatan SRL na daidaita (misali da aka sanar da shi syntactic) idan an jarraba cikin wannan tsari. Misalinmu na sami-agnostic ya tsohon sigar, ta ƙara matsalan da aka faɗa mafi kyãwo a matsalar da za'a fito-fitarwa daga-Domin.", 'sk': 'Predstavljamo preprost in natančen nevronski model za označevanje semantičnih vlog na osnovi odvisnosti. Naš model napoveduje odvisnosti napovedi-argumentov na podlagi stanj dvosmernega kodirnika LSTM. Semantični označevalec vlog dosega konkurenčno učinkovitost v angleščini, tudi brez kakršnih koli sintaktičnih informacij in samo z uporabo lokalnih sklepov. Ko pa so kot vhodne oznake samodejno predvidene dele govora zagotovljene, bistveno presega vse prejšnje lokalne modele in pristopi k najboljšim poročanim rezultatom v angleškem naboru podatkov CoNLL-2009. Upoštevamo tudi kitajsko, češko in špansko, kjer naš pristop dosega tudi konkurenčne rezultate. Sintaktični razčlenjevalniki niso zanesljivi na zunajdomenskih podatkih, zato so standardni (tj. sintaktično informirani) modeli SRL ovirani pri testiranju v tej nastavitvi. Naš sintaksa-agnostični model se zdi bolj robusten, kar ima za posledico najboljše poročane rezultate pri standardnih zunajdomenskih testnih sklopih.', 'bo': 'ང་ཚོས་རྟེན་དང་མཐུན་པོ་ཞིག་གི་སྔོན་སྒྲིག་དང་བདེན་བདེ་ནི་མིའུ་རྣམ་པ་ཞིག་བཤད་ཀྱི་རེད། Our model predicts predicate-argument dependencies relying on states of a bidirectional LSTM encoder. The semantic role labeler achieves competitive performance on English, even without any kind of syntactic information and only using local inference. ཡིན་ནའང་། རང་འགུལ་གྱིས་སྔོན་ལྟ་ཀློག་པའི་རྣམ་གྲངས་ཀྱི་ཤོག་བྱང་ཆ་རང་འགུལ་གྱིས་འཇུག་པ་དང་སྔོན་ལྟ་ཀློག་པའི་མ་དཔེ་གཟུགས་རྣམ་པ་ཡོད་པའ ང་ཚོས་རྒྱ་ནག་དང་ཅེ་ཤེས་དང་སྐད་ཡིག་གི་ཐབས་ལམ་ལ་ཡང་རྒྱལ་ཁབ་འབྱུང་བ་རེད། Syntactic parsers are unreliable on out-of-domain data, so standard (i.e., syntactically-informed) SRL models are hindered when tested in this setting. Our syntax-agnostic model appears more robust, resulting in the best reported results on standard out-of-domain test sets.'}
{'en': 'Joint Prediction of Morphosyntactic Categories for Fine-Grained Arabic Part-of-Speech Tagging Exploiting Tag Dictionary Information', 'ar': 'التنبؤ المشترك للفئات الشكلية للنطق العربي ذي الحبيبات الدقيقة لوضع علامات على أجزاء من الكلام تستغل معلومات قاموس العلامات', 'fr': 'Prédiction conjointe de catégories morphosyntaxiques pour le balisage de parties de discours arabes à grain fin exploitant les informations du dictionnaire de balises', 'es': 'Predicción conjunta de categorías morfosintácticas para el etiquetado detallado de partes del habla en árabe aprovechando la información del diccionario de etiquetas', 'pt': 'Previsão conjunta de categorias morfossintáticas para marcação de parte da fala árabe de granulação fina Explorando informações do dicionário de tags', 'ja': '細かいアラビア語の音声タグ付けタグ辞書情報のための形態構文カテゴリの共同予測', 'zh': '细粒度阿拉伯语词性表用标签字典信息之形句法类合占之', 'hi': 'ठीक दानेदार अरबी भाग के लिए Morphosyntactic श्रेणियों की संयुक्त भविष्यवाणी के भाषण टैग टैग टैग शब्दकोश जानकारी शोषण टैग', 'ru': 'Совместное прогнозирование морфосинтаксических категорий для мелкозернистой арабской части речи', 'ga': 'Comhthuar na gCatagóirí Morphosyntactic le haghaidh Araibis Mhínghráthaithe Clibeáil Pháirt-de-Cainteanna Ag baint leasa as Clib an Fhoclóra', 'ka': 'Morphosyntactic Categories for Fine-Grained Arabic Part of- Speech Tagging Exploiting Tag Dictionary Information', 'hu': 'A finomszemű arab beszédrész morfoszintatikus kategóriáinak közös előrejelzése Tagging Kihasználási címke szótár információk', 'el': 'Κοινή πρόβλεψη μορφοσυντακτικών κατηγοριών για λεπτόκοκκο αραβικό τμήμα ομιλίας Εκμετάλλευση πληροφοριών λεξικού ετικετών', 'it': 'Predizione congiunta delle categorie morfosintattiche per la parte di discorso araba a grana fine Tagging Sfruttare le informazioni sul dizionario dei tag', 'lt': 'Bendras nuodugniai grūdintų arabų kalbos dalies žymėjimo žodynu naudojamų žymėjimų morfosintaktinių kategorijų numatymas', 'mk': 'Заедничка прогноза за морфосинтактички категории за фино-граничен арапски дел од говорот со ознака за искористување на речни информации за ознаките', 'kk': 'Тұтас түрлі араб тілінің бір бөлігін тегтерді эксплоатациялау тегтерінің мәліметі үшін Morphosyntactic санаттарының біріктірілген таңбалары', 'ms': 'Pengiraan Bersama-sama Kategori Morfosintaktik bagi Bahagian-Perkataan-Perkataan-Perkataan-Perkataan-Perkataan-Perkataan-Perkataan-Perkataan-Penggunaan Maklumat Kamus Tag', 'ml': 'നിര്\u200dണ്ണയിക്കപ്പെട്ട അറബി ഭാഗം- ഓഫ്- സംസാരിക്കുന്ന ടാഗ്ലോട്ട് വിവരങ്ങള്\u200d', 'mt': 'Tbassir Konġunt ta’ Kategoriji Morfosintattiċi għal Tagging ta’ Tag ta’ Tag bl-Isfruttar ta’ Parti Għarbija ta’ Biċċiet Fini', 'mn': 'Joint Prediction of Morphosyntactic Categories for Fine-Grained Arabic Part-of-Speech Tagging Exploiting Tag Dictionary Information', 'no': 'Slått saman forhåndsvising av morfosynaktiske kategoriar for informasjon om filgrensert arabisk del av språk- merkelapp- utforsking av merkelordbok', 'pl': 'Wspólne przewidywanie kategorii morfosyntaktycznych dla drobnoziarnistego arabskiego tagowania części mowy Wykorzystanie informacji o słowniku tagów', 'ro': 'Predicția comună a categoriilor morfosintactice pentru partea de vorbire arabă cu granule fine Etichetare Exploatarea etichetelor dicționar informații', 'sr': 'Zajednička predviđanja morfosintaktičnih kategorija za informacije o svemu izraženom arapskom dijelu govora', 'si': 'Name', 'so': 'Dictionary information', 'sv': 'Gemensam förutsägelse av morfosyntaktiska kategorier för finkornig arabisk del-av-tal Taggning Utnyttjande av tagg ordbok Information', 'ta': 'Joint Prediction of Morphosyntactic Categories for Fine-Grained Arabic Part-of-Speech Tagging Exploiting Tag Dictionary Information', 'ur': 'Name', 'vi': 'Định trước hỗn hợp các phân loại Morpheus dành cho máy chữ A ít được ăn cắp', 'uz': 'Comment', 'bg': 'Съвместно прогнозиране на морфосинтактични категории за фино зърнесто арабско етикетиране на част от речта', 'nl': 'Gezamenlijke voorspelling van morfosyntactische categorieën voor fijnkorrelig Arabisch deel-van-spraak tagging exploiteren Tag woordenboek informatie', 'da': 'Fælles forudsigelse af morfosyntaktiske kategorier for finkornet arabisk del af tale Tagging Udnyttelse af tagordbog Information', 'de': 'Gemeinsame Vorhersage morphosyntaktischer Kategorien für feinkörniges arabisches Part-of-Speech-Tagging Ausnutzung von Tag-Dictionary-Informationen', 'ko': '표기 사전 정보를 바탕으로 하는 세립도 아랍어 어성 표기 형태 문법 유형 연합 예측', 'fa': 'پیش\u200cبینی مشترک گونه\u200cهای مورف\u200cسنتاکتیک برای اطلاعات ویژه\u200cنامه\u200cی جعبه\u200cنامه\u200cی جعبه\u200cنامه\u200cهای تبدیل\u200cکننده\u200cی قول\u200cنامه\u200cهای عربی', 'hr': 'Zajednička predviđanja morfosintaktičkih kategorija za informacije o slobodnom arapskom dijelu govora o eksplozivanju znakova', 'tr': 'Fin-Graňkli Arapça Parça-of-Speech Taýýarlama Tägler Maglumaty üçin Morfosyntaktik Kalamlaryň ýerleşdirişi', 'id': 'Perkiraan Konġunt dari Kategori Morfosintaksi untuk Bahagian-dari-Perkataan Bahagian-dari-Perkataan Arab-Grained Fine Tagging Exploiting Tag Dictionary Information', 'sq': 'Parashikimi i Përbashkët i Kategorive Morfosintaktike për Tagging-in-Speech-Part-of-Speech', 'sw': 'Udhibiti wa Kiarabu wa Kuzungumza Uzungumzo wa Kiarabu', 'am': 'Joint Prediction of Morphosyntactic Categories for Fine-Grained Arabic Part-of-Speech Tagging Exploiting Tag Dictionary Information', 'az': 'Sözlük Sözlük Sözlük Məlumatı üçün Morphosyntactic Categories for Fine-Grained Arabic Part of-of-Speech Tagging Exploiting Tag Dictionary Information', 'hy': 'Խոսքի ընդհանուր կանխատեսումը ֆինանսավորված արաբական մասի մարտկոցների օգտագործման բառարանային տեղեկատվության մորֆոսինտակտիկ կատեգորիաների համար', 'ca': "Predicció conjunta de categories morfosintatsiques per a etiquetar l'etiqueta d'etiquetes de frases fins a grains àrabs", 'af': 'Gesamelende voorskrif van Morphosyntactic Kategories vir Fine- Grained Arabiese Deel- of- Speech Tagging Exploiting Etiket Woordeboek Informasie', 'et': 'Morfosüntaktiliste kategooriate ühine prognoosimine peeneteraliste araabia keeleosa sildistamiseks Sildi sõnaraamatu teabe kasutamine', 'cs': 'Společná predikce morfosyntaktických kategorií pro jemnozrnné značení arabské části řeči', 'bn': 'ভালো গ্রেফতার করা আরবী পার্ট- অফ-ভাষা ট্যাগ বিশেষ ট্যাগ বিশেষ তথ্য', 'bs': 'Zajednička predviđanja morfosintaktičkih kategorija za informacije o svemu izraženom arapskom dijelu govora', 'fi': 'Yhteinen ennuste morfosyntaktisista kategorioista hienojyväiselle arabialle Osa-puheelle Tagin hyödyntäminen sanakirjan tiedot', 'jv': 'Joint', 'ha': 'KCharselect unicode block name', 'sk': 'Skupna napoved morfosintaktičnih kategorij za finozrnato arabsko označevanje dela govora Izkoriščanje oznak slovar Informacije', 'he': 'צפייה משותפת של קטגוריות מורפוסינטקטיות עבור מידע מילון מילון של תאגים בערבית צמחונית', 'bo': 'Joint Prediction of Morphosyntactic Categories for Fine-Grained Arabic Part-of-Speech Tagging Exploiting Tag Dictionary Information'}
{'en': 'Part-of-speech (POS) tagging for morphologically rich languages such as Arabic is a challenging problem because of their enormous tag sets. One reason for this is that in the tagging scheme for such languages, a complete POS tag is formed by combining tags from multiple tag sets defined for each morphosyntactic category. Previous approaches in Arabic POS tagging applied one model for each morphosyntactic tagging task, without utilizing shared information between the tasks. In this paper, we propose an approach that utilizes this information by jointly modeling multiple morphosyntactic tagging tasks with a multi-task learning framework. We also propose a method of incorporating tag dictionary information into our neural models by combining word representations with representations of the sets of possible tags. Our experiments showed that the joint model with tag dictionary information results in an accuracy of 91.38 % on the Penn Arabic Treebank data set, with an absolute improvement of 2.11 % over the current state-of-the-art tagger.', 'ar': 'تعتبر علامات جزء من الكلام (POS) للغات الغنية شكليًا مثل العربية مشكلة صعبة بسبب مجموعات العلامات الهائلة الخاصة بها. أحد أسباب ذلك هو أنه في مخطط وضع العلامات لمثل هذه اللغات ، يتم تكوين علامة POS كاملة من خلال دمج العلامات من مجموعات العلامات المتعددة المحددة لكل فئة مورفوسينتيكتيك. طبقت المناهج السابقة في تعليم نقاط البيع العربية نموذجًا واحدًا لكل مهمة ترميز مورفوسينتيكتيك ، دون استخدام المعلومات المشتركة بين المهام. في هذه الورقة ، نقترح نهجًا يستخدم هذه المعلومات من خلال النمذجة المشتركة لمهام علامات مورفوسينتيكتيك متعددة مع إطار عمل تعليمي متعدد المهام. نقترح أيضًا طريقة لدمج معلومات قاموس العلامات في نماذجنا العصبية من خلال دمج تمثيلات الكلمات مع تمثيلات مجموعات العلامات الممكنة. أظهرت تجاربنا أن النموذج المشترك مع معلومات قاموس العلامات ينتج عنه دقة بنسبة 91.38٪ على مجموعة بيانات Penn Arabic Treebank ، مع تحسن مطلق بنسبة 2.11٪ مقارنة بأحدث العلامات الحالية.', 'fr': "Le balisage des parties du discours (POS) pour les langues morphologiquement riches telles que l'arabe est un problème difficile en raison de leur énorme jeu de balises. Cela s'explique notamment par le fait que, dans le schéma de marquage de ces langues, une étiquette POS complète est formée en combinant des étiquettes provenant de plusieurs ensembles d'étiquettes définis pour chaque catégorie morphosyntaxique. Les approches précédentes du balisage POS en arabe appliquaient un modèle pour chaque tâche de marquage morphosyntaxique, sans utiliser d'informations partagées entre les tâches. Dans cet article, nous proposons une approche qui utilise ces informations en modélisant conjointement plusieurs tâches de marquage morphosyntaxique avec un cadre d'apprentissage multitâche. Nous proposons également une méthode d'intégration d'informations de dictionnaire de balises dans nos modèles neuronaux en combinant des représentations de mots avec des représentations des ensembles d'étiquettes possibles. Nos expériences ont montré que le modèle conjoint avec les informations du dictionnaire d'étiquettes donne une précision de 91,38\xa0% sur l'ensemble de données Penn Arabic Treebank, avec une amélioration absolue de 2,11\xa0% par rapport au tagger de pointe actuel.", 'es': 'El etiquetado de parte del habla (POS) para idiomas con gran riqueza morfológica, como el árabe, es un problema difícil debido a sus enormes conjuntos de etiquetas. Una razón para esto es que en el esquema de etiquetado para tales idiomas, se forma una etiqueta POS completa combinando etiquetas de múltiples conjuntos de etiquetas definidos para cada categoría morfosintáctica. Los enfoques anteriores en el etiquetado de PDV árabe aplicaban un modelo para cada tarea de etiquetado morfosintáctico, sin utilizar información compartida entre las tareas. En este artículo, proponemos un enfoque que utiliza esta información mediante el modelado conjunto de múltiples tareas de etiquetado morfosintáctico con un marco de aprendizaje multitarea. También proponemos un método para incorporar información de diccionario de etiquetas en nuestros modelos neuronales mediante la combinación de representaciones de palabras con representaciones de los conjuntos de posibles etiquetas. Nuestros experimentos mostraron que el modelo conjunto con la información del diccionario de etiquetas da como resultado una precisión del 91,38% en el conjunto de datos de Penn Arabic Treebank, con una mejora absoluta del 2,11% con respecto al etiquetador actual de última generación.', 'pt': 'A marcação de parte da fala (POS) para idiomas morfologicamente ricos, como o árabe, é um problema desafiador por causa de seus enormes conjuntos de tags. Uma razão para isso é que no esquema de marcação para essas linguagens, uma tag POS completa é formada pela combinação de tags de vários conjuntos de tags definidos para cada categoria morfossintática. As abordagens anteriores na marcação POS árabe aplicavam um modelo para cada tarefa de marcação morfossintática, sem utilizar informações compartilhadas entre as tarefas. Neste artigo, propomos uma abordagem que utiliza essas informações modelando conjuntamente várias tarefas de marcação morfossintática com uma estrutura de aprendizado multitarefa. Também propomos um método de incorporar informações do dicionário de tags em nossos modelos neurais, combinando representações de palavras com representações dos conjuntos de tags possíveis. Nossos experimentos mostraram que o modelo conjunto com informações do dicionário de tags resulta em uma precisão de 91,38% no conjunto de dados Penn Arabic Treebank, com uma melhoria absoluta de 2,11% em relação ao atual tagger de última geração.', 'ja': 'アラビア語などの形態学的に豊富な言語の部分音声（ POS ）タグ付けは、その膨大なタグセットのため、困難な問題です。 その理由の1つは、そのような言語のタグ付けスキームでは、モルホシンタクティックカテゴリごとに定義された複数のタグセットからのタグを組み合わせることによって、完全なPOSタグが形成されることである。 アラビア語のPOSタグ付けにおける以前のアプローチでは、タスク間で共有された情報を利用することなく、形態素タグ付けタスクごとに1つのモデルが適用されました。 本稿では，マルチタスク学習フレームワークを用いて複数の形態素説的タグ付けタスクを共同でモデル化することにより，この情報を利用するアプローチを提案する． また、可能なタグのセットの表現と単語表現を組み合わせることにより、タグ辞書情報をニューラルモデルに組み込む方法も提案しています。 私たちの実験では、タグ辞書情報との共同モデルは、Penn Arabic Treebankデータセットで91.38 ％の精度をもたらし、現在の最先端のタグ付けよりも2.11 ％の絶対的な改善をもたらすことが示されました。', 'zh': '多言(阿拉伯语),词性 (POS) 表一挑战性,以其有大集也。 其一者,于此语之中,各为形态句法类定义者多标集,以成全 POS 。 前阿拉伯语 POS 标法句法各用一形,而不因事之间者共之。 于本文中,建此一法,用多任务学框架合建模数形句法标记。 立书字典并吾神经之法,以单词合集也。 臣等实验者,书字典合式Penn Arabic Treebank数集上之准确率为91.38%,先进之器绝于2.11%矣。', 'hi': 'अरबी जैसी रूपात्मक रूप से समृद्ध भाषाओं के लिए पार्ट-ऑफ-स्पीच (पीओएस) टैगिंग उनके विशाल टैग सेट के कारण एक चुनौतीपूर्ण समस्या है। इसका एक कारण यह है कि ऐसी भाषाओं के लिए टैगिंग योजना में, प्रत्येक मोर्फोसिंटैक्टिक श्रेणी के लिए परिभाषित कई टैग सेटों से टैग के संयोजन से एक पूर्ण पीओएस टैग बनता है। अरबी पीओएस टैगिंग में पिछले दृष्टिकोण ने कार्यों के बीच साझा जानकारी का उपयोग किए बिना, प्रत्येक मोरफोसिंटैक्टिक टैगिंग कार्य के लिए एक मॉडल लागू किया। इस पेपर में, हम एक दृष्टिकोण का प्रस्ताव करते हैं जो संयुक्त रूप से बहु-कार्य सीखने के ढांचे के साथ कई मोर्फोसिंटैक्टिक टैगिंग कार्यों को मॉडलिंग करके इस जानकारी का उपयोग करता है। हम संभावित टैग के सेट के प्रतिनिधित्व के साथ शब्द प्रतिनिधित्व के संयोजन से हमारे तंत्रिका मॉडल में टैग शब्दकोश जानकारी को शामिल करने की एक विधि का भी प्रस्ताव करते हैं। हमारे प्रयोगों से पता चला है कि टैग शब्दकोश जानकारी के साथ संयुक्त मॉडल के परिणामस्वरूप पेन अरबी ट्रीबैंक डेटा सेट पर 91.38% की सटीकता होती है, जिसमें वर्तमान अत्याधुनिक टैगर पर 2.11% का पूर्ण सुधार होता है।', 'ru': 'Тегирование части речи (POS) для морфологически богатых языков, таких как арабский, является сложной проблемой из-за их огромных наборов тегов. Одной из причин этого является то, что в схеме тегирования для таких языков полный тег POS формируется путем объединения тегов из множества наборов тегов, определенных для каждой морфосинтаксической категории. Предыдущие подходы в арабской POS-метке применяли одну модель для каждой задачи морфосинтаксической метки, без использования общей информации между задачами. В этой статье мы предлагаем подход, который использует эту информацию, совместно моделируя несколько задач морфосинтаксического тегирования с помощью многозадачного обучающего фреймворка. Предложен также способ включения информации словаря тегов в наши нейронные модели путем объединения словопредставлений с представлениями множеств возможных тегов. Наши эксперименты показали, что совместная модель с информацией словаря меток дает точность 91,38% на наборе данных Penn Arabic Treebank, с абсолютным улучшением на 2,11% по сравнению с современным тегером.', 'ga': 'Is fadhb dhúshlánach í clibeáil pháirteach cainte (POS) do theangacha atá saibhir ó thaobh moirfeolaíochta de mar an Araibis mar gheall ar a gcuid tacair ollmhóra clibeanna. Cúis amháin leis seo is ea go ndéantar clib iomlán POS sa scéim chlibeála do theangacha dá leithéid trí chlibeanna a chomhcheangal ó shraitheanna iolracha clibeanna sainithe do gach catagóir morphosyntactic. Chuir cur chuige roimhe seo i gclibeáil POS Araibis múnla amháin i bhfeidhm do gach tasc clibeála morfosyntactic, gan úsáid a bhaint as faisnéis roinnte idir na tascanna. Sa pháipéar seo, molaimid cur chuige a bhaineann úsáid as an bhfaisnéis seo trí thascanna éagsúla clibeála moirfosyntachta a chomhshamhaltú le creat foghlama ilthasc. Molaimid freisin modh chun faisnéis fhoclóra clibeanna a ionchorprú isteach inár múnlaí néarúla trí uiríll focal a chomhcheangal le léirithe ar thacair na gclibeanna féideartha. Léirigh ár dturgnaimh go bhfuil cruinneas 91.38% ar thacar sonraí Penn Arabic Treebank mar thoradh ar an gcomhshamhail le faisnéis foclóir clibeanna, le feabhas iomlán de 2.11% ar an gclibálaí úrscothach reatha.', 'hu': 'A morfológiailag gazdag nyelvek, például az arab nyelvek beszédrészleges címkézése kihívást jelent a hatalmas címkészletek miatt. Ennek egyik oka az, hogy az ilyen nyelvek címkézési sémájában egy teljes POS címke jön létre az egyes morfoszintatikus kategóriákhoz definiált több címkészletből származó címkék kombinálásával. Az arab POS-címkézés korábbi megközelítései minden morfoszintatikus címkézési feladathoz egy modellt alkalmaztak, anélkül, hogy a feladatok közötti megosztott információkat használnának. Ebben a tanulmányban egy olyan megközelítést javasolunk, amely ezeket az információkat felhasználja több morfoszintatikus címkézési feladatot együttesen modellezve egy többfeladatos tanulási keretrendszerrel. Javasoljuk továbbá a címkeszótár információinak beépítésének módszerét neurális modelleinkbe azáltal, hogy kombináljuk a szóreprezentációkat a lehetséges címkék készleteinek reprezentációival. Kísérleteink kimutatták, hogy a címkeszótár információkkal rendelkező közös modell 91,38%-os pontosságot eredményez a Penn Arabic Treebank adatkészleten, abszolút 2,11%-os javulást jelent a jelenlegi korszerű címkeszótárhoz képest.', 'ka': 'სიტყვების ნაწილი (POS) მარფოლოგიურად ღარილი ენებისთვის, როგორც აპაბიური, უფრო შესაძლებელი პრობლემა იქნება, რადგან მათი დიდი მარფების ნაწილზე. ერთი მიზეზი იყო, რომ ასეთი ენებისთვის ჭდეების სქემაში, ყველა მოპოსინტაქტიკური კატეგორიისთვის განსაზღვრებული POS ჭდეების შესაძლებელად შექმნილია. ყველა მოპოფსინტაქტიკური მონაცემებისთვის ერთი მოდელი აპაბიური POS-ში გამოყენებულია, ყველა მოპოფსინტაქტიკური მონაცემებისთვის, დავალების შორის გაყოფი ამ წიგნაში, ჩვენ მინდომარებით მინდომარება, რომელიც ამ ინფორმაციას გამოყენებს მრავალ მოპოფსინტაქტიური მონაცემებით მრავალ დასწავლების ფრამეტრებით. ჩვენ შეგიძლიათ ჩვენი ნეიროლური მოდელში ტექსტის სიტყვების ინფორმაციის შეყვანის მეტი, რომელიც შესაძლებელი ტექსტის კონფიგურაციებით სიტყვების გამოსახულებებით შემ ჩვენი ექსპერიმენტები გაჩვენეთ, რომ ერთადერთი მოდელი სიტყვანის ინფორმაციის შესახებ 91,38% მონაცემების შესახებ პენ აპაბური ბრიბანკის მონაცემების შესახებ, რომელიც აბსოლუტური შესახებ 2,11% მო', 'el': 'Η σήμανση μέρους ομιλίας (POS) για μορφολογικά πλούσιες γλώσσες όπως τα αραβικά είναι ένα δύσκολο πρόβλημα λόγω των τεράστιων συνόλων ετικετών τους. Ένας λόγος για αυτό είναι ότι στο σχήμα ετικετών για τέτοιες γλώσσες, μια πλήρης ετικέτα δημιουργείται συνδυάζοντας ετικέτες από πολλαπλά σύνολα ετικετών που ορίζονται για κάθε μορφοσυντακτική κατηγορία. Οι προηγούμενες προσεγγίσεις στην αραβική σήμανση εφαρμόστηκαν ένα μοντέλο για κάθε εργασία μορφοσυντακτικής σήμανσης, χωρίς να χρησιμοποιούνται κοινόχρηστες πληροφορίες μεταξύ των εργασιών. Στην παρούσα εργασία, προτείνουμε μια προσέγγιση που χρησιμοποιεί αυτές τις πληροφορίες μοντελοποιώντας από κοινού πολλαπλές μορφοσυντακτικές εργασίες σήμανσης με ένα μαθησιακό πλαίσιο πολλαπλών εργασιών. Προτείνουμε επίσης μια μέθοδο ενσωμάτωσης πληροφοριών λεξικού ετικετών στα νευρωνικά μοντέλα μας συνδυάζοντας αναπαραστάσεις λέξεων με αναπαραστάσεις των συνόλων πιθανών ετικετών. Τα πειράματά μας έδειξαν ότι το κοινό μοντέλο με πληροφορίες λεξικού ετικετών οδηγεί σε ακρίβεια 91.38% στο σύνολο δεδομένων της αραβικής τράπεζας δέντρων Penn, με απόλυτη βελτίωση 2.11% σε σχέση με την τρέχουσα υπερσύγχρονη συσκευή ετικετών.', 'it': "Il tag part-of-speech (POS) per lingue morfologicamente ricche come l'arabo è un problema impegnativo a causa dei loro enormi set di tag. Una ragione di ciò è che nello schema di tagging per tali lingue, un tag POS completo è formato combinando tag da più set di tag definiti per ogni categoria morfosintattica. Gli approcci precedenti nel tagging POS arabo applicavano un modello per ogni attività di tagging morfosintattico, senza utilizzare informazioni condivise tra le attività. In questo articolo, proponiamo un approccio che utilizza queste informazioni modellando congiuntamente più attività di tagging morfosintattico con un framework di apprendimento multi-task. Proponiamo anche un metodo per incorporare informazioni sul dizionario dei tag nei nostri modelli neurali combinando rappresentazioni di parole con rappresentazioni degli insiemi di possibili tag. I nostri esperimenti hanno dimostrato che il modello congiunto con informazioni sul dizionario dei tag si traduce in una precisione del 91,38% sul set di dati Penn Arabic Treebank, con un miglioramento assoluto del 2,11% rispetto all'attuale tagger stato dell'arte.", 'kk': 'Араб тілдерінің морфологиялық баяны тілдерінің (POS) бөлігі үлкен тегтер жиындарының себебі бұл көп мәселе. Бұл үшін бір себебі, осы тілдер үшін тегтерді сұлбанда, барлық POS тегтерін бірнеше морфосинтактикалық санатына анықталған тегтерді біріктіру үшін құрылады. Араб POS тегтерінде алдыңғы келесі бір морфосинтактикалық тапсырмалар үшін бір үлгі қолданылады, тапсырмалар арасындағы ортақтастырылған мәліметті қолданбады. Бұл қағазда біз бұл мәліметті бірнеше морфосинтактикалық тапсырмаларды көп тапсырмаларды оқыту фреймімен бірге моделдеп қолданатын тәртібін ұсынамыз. Мұндай-ақ біз тегтердің сөздік мәліметін біздің невралдық модельдерімізге ендіру әдісін таңдаймыз. Мүмкін тегтердің келтірімдерін біріктіріп, сөздердің мәлі Біздің тәжірибеміз тегтердің сөздік мәліметінің біріктірілген моделі Penn Arabic Treebank деректер жиынындағы 91,38% дегенді көрсету үшін, қазіргі тегтердің күйінде 2,11% дегенді абсолютті жақсарту үшін.', 'lt': 'Kalbos dalis (POS) žymėjimas morfologiškai turtingomis kalbomis, pavyzdžiui, arabų kalba, yra sudėtinga problem a dėl jų didžiulių žymėjimų rinkinių. Viena iš priežasčių yra tai, kad tokioms kalboms skirtoje žymėjimo sistemoje susidaro visas POS žymėjimas derinant žymėjimus iš įvairių žymėjimų rinkinių, apibrėžtų kiekvienai morfosintaktinei kategorijai. Ankstesni metodai arabų POS žymėjime taikė vieną model į kiekvienai morfosintaktinei žymėjimo užduotims, nenaudojant dalijamosios informacijos tarp užduočių. Šiame dokumente siūlome metodą, kuris naudoja šią informaciją kartu modeliuojant daugelį morfosintaksinių ženklinimo užduočių su daugelio užduočių mokymosi sistema. Mes taip pat siūlome metodą, kaip į mūsų nervinius modelius įtraukti etiketės žodyno informaciją, derinant žodžių atstovavimus su galimų etiketės rinkinių atstovavimais. Mūsų eksperimentai parodė, kad bendras modelis su žodyno etiketėmis suteikia 91,38 % tikslumo Penn Arabic Treebank duomenų rinkinyje, o absoliutus pagerėjimas – 2,11 % palyginti su dabartiniu pažymėtoju.', 'mk': 'Дел од говорот (POS) означување на морфолошки богати јазици како што е арапскиот е предизвикувачки проблем поради нивните огромни означувања. Една причина за ова е тоа што во шемата за означување на вакви јазици, целосна POS означка се формира со комбинација на означувања од многуте набори на означувања дефинирани за секоја морфосинтактичка категорија. Претходните пристапи во арапското POS означување применија еден модел за секоја морфосинтактичка задача за означување, без користење на споделени информации помеѓу задачите. Во овој документ, предложуваме пристап кој ги користи овие информации заеднички моделирајќи повеќе морфосинтактички задачи за означување со рамка за учење на мултизадачи. Ние, исто така, предложуваме метод за вклучување на информации за речникот на ознаките во нашите нервни модели со комбинација на репрезентации на зборовите со репрезентации на сетите на можни ознаки. Нашите експерименти покажаа дека заедничкиот модел со информации за речникот со ознаки резултира со точност од 91,38 отсто на податоците од Penn Arabic Treebank, со апсолутно подобрување од 2,11 отсто во однос на сегашниот најсовремен ознака.', 'ms': 'Bahagian-dari-ucapan (POS) tag untuk bahasa yang kaya secara morfologik seperti Arab adalah masalah yang mencabar kerana set tag yang besar mereka. Salah satu alasan untuk ini ialah bahawa dalam skema penandaan untuk bahasa tersebut, tag POS lengkap dicipta dengan menggabungkan tag dari set tag berbilang yang ditakrif untuk setiap kategori morfosintaktik. pendekatan terdahulu dalam tag POS Arab dilaksanakan satu model untuk setiap tugas tag morfosintaktik, tanpa menggunakan maklumat berkongsi antara tugas. Dalam kertas ini, kami cadangkan pendekatan yang menggunakan maklumat ini dengan menggunakan model bersama-sama tugas tag morfosintaktik berbilang dengan kerangka pembelajaran berbilang-tugas. Kami juga mengusulkan kaedah untuk memasukkan maklumat kamus tag ke dalam model saraf kami dengan menggabungkan perwakilan perkataan dengan perwakilan set tag yang mungkin. Eksperimen kami menunjukkan bahawa model kongsi dengan maklumat kamus tag mengakibatkan keperluan 91.38% pada set data Pangkalan Pokok Arab Penn, dengan peningkatan mutlak 2.11% daripada tag-state-of-the-art semasa.', 'ml': 'അറബിക്ക് പോലെ സംസാരിക്കുന്ന ഭാഷകള്\u200dക്കായി മോര്\u200dഫോളജിക്കല്\u200d സമ്പന്നരായ ഭാഷകള്\u200d ടാഗിങ്ങ് ചെയ്യുന്നത് അവരുടെ വലിയ ടാഗ്  ഇത്തരം ഭാഷകള്\u200dക്കുള്ള ടാഗ്ഗിംഗ് സ്ക്രീമില്\u200d ഓരോ മോര്\u200dഫോസിനിറ്റിക് വിഭാഗത്തിനുവേണ്ടി വ്യക്തമാക്കിയ പല ടാഗുകളില്\u200d നിന്നും ഒരു പൂര പങ്കെടുത്ത വിവരങ്ങള്\u200d ഉപയോഗിക്കാതെ എല്ലാ മോര്\u200dഫോസിന്റിക് ടാഗിങ്ക് ജോലിക്കും മുമ്പുള്ള അറബി പോസ് ടാഗിങ്ങില്\u200d ഒരു  ഈ പത്രത്തില്\u200d, ഈ വിവരങ്ങള്\u200d ഉപയോഗിക്കുന്ന ഒരു വഴിയാണ് ഞങ്ങള്\u200d നിര്\u200dദ്ദേശിക്കുന്നത്, ഒരു പല ജോലി പഠിക്കുന്ന ഫ്രെയിമോള്\u200dട്ടിക് മ ടാഗ് നിഘണ്ട വിവരങ്ങള്\u200d നമ്മുടെ ന്യൂറല്\u200d മോഡലില്\u200d ചേര്\u200dക്കുന്നതിനുള്ള ഒരു രീതിയും ഞങ്ങള്\u200d പ്രൊദ്ദേശിക്കുന്നു. വാക്കുകള്\u200d പ്രത നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ട് ടാഗ് നിഘണ്ട വിവരങ്ങളുടെ യൂട്ട് മോഡല്\u200d പെന്\u200d അറബി ട്രീബാങ്ക് ഡേറ്റാ സജ്ജീകരണത്തില്\u200d 91. 38% കാണിക്കുന്നു. ഇപ്പോഴ', 'mt': 'It-tikkettar ta’ parti mid-diskors (POS) għal lingwi morfoloġikament rikki bħall-Għarab huwa problem a ta’ sfida minħabba s-settijiet enormi tag ħhom ta’ tikketti. One reason for this is that in the tagging scheme for such languages, a complete POS tag is formed by combining tags from multiple tag sets defined for each morphosyntactic category.  L-approċċi preċedenti fit-tikkettar tal-POS Għarab applikaw mudell wieħed għal kull kompitu tat-tikkettar morfosintattiku, mingħajr l-użu ta’ informazzjoni kondiviża bejn il-kompiti. F’dan id-dokument, qed nipproponu approċċ li juża din l-informazzjoni billi nimmudellaw b’mod konġunt kompiti multipli ta’ tikkettar morfosintattiku ma’ qafas ta’ tagħlim multikompiti. Aħna nipproponu wkoll metodu għall-inkorporazzjoni tal-informazzjoni tad-dikjaratorju tat-tikketti fil-mudelli newrali tag ħna billi nikkombinaw ir-rappreżentazzjonijiet tal-kliem mar-rappreżentazzjonijiet tas-settijiet ta’ tikketti possibbli. L-esperimenti tag ħna wrew li l-mudell konġunt b’informazzjoni dwar id-dikjaratorju bit-tikketti jirriżulta f’preċiżjoni ta’ 91.38% fuq is-sett ta’ dejta tal-Punt Għarbi tal-Pinna, b’titjib assolut ta’ 2.11% fuq l-aħħar tikketta attwali.', 'no': 'Delt av tale (POS) som merkar for morfologisk rike språk, som arabisk, er eit vanskeleg problem på grunn av dei store merkelappene. Ein grunn for dette er at i merkelapparatet for slike språk er eit fullstendig POS- merkelapp formatert ved å kombinere merkelappar frå fleire merkelappar definert for kvar morfosyntaktisk kategori. Førre tilnærmingar i arabiske POS-merking har brukt ein model for kvar morphosyntaktisk merking-oppgåve utan å bruka delt informasjon mellom oppgåva. I denne papiret foreslår vi ein tilnærming som brukar denne informasjonen ved å modelera fleire morfosyntaktiske merking av oppgåver med eit fleire oppgåver-læringsrammeverk. Vi foreslår også ein metode for å inkludere merkelordbokinformasjon i våre neuralmodeller ved å kombinerera ordrepresentasjonar med representasjonar av settet av moglege merkelappar. Eksperimentane våre viste at den samanlige modellen med merkelordbokinformasjonen resulterer i en nøyaktig 91,38% på den oppsettet av Penn Arabic Treebank, med ein absolutt forbedring av 2,11% over den gjeldande tilstanden av kunsten.', 'mn': 'Араб зэрэг морфологик баян хэлнүүдийн нэг хэсэг нь маш их тэмдэгтийн хэлбэрээс шаардлагатай асуудал юм. Үүний нэг шалтгаан нь ийм хэлний тэмдэглэгдэх схемд морфосинтактик хэлбэрээр тодорхойлогдсон олон тэмдэглэгдсэн тэмдэгүүдийг цуглуулж бүрэн POS тэмдэглэгддэг. Өмнөх арга баримтууд Араб POS-ийн тэгшитгэлээр морфосинтактик тэгшитгэлийн ажлын тухай нэг загварыг ашиглаж, ажлын хоорондын хуваалцаагүй мэдээллийг ашиглаж байсан. Энэ цаасан дээр бид энэ мэдээллийг олон ажлын суралцах үйл ажиллагаатай олон морфосинтактикийн загваруудыг нийлүүлж ашиглах арга зам зааж байна. Мөн бид тэмдэгтийн үг өгүүлбэр мэдээллийг бидний мэдрэлийн загвар руу нэгтгэх арга зааж өгдөг. Бидний туршилтууд тэмдэглэгчийн мэдээллийн нийлбэр загвар нь Пенн Араб мод банкны мэдээллийн нийлбэр 91.38%-ын тодорхойлолтой болж байна гэдгийг харуулсан. Одоо байгаа урлагийн тэмдэглэгчийн хувьд 2.11%-ын тодорхойлолтой сайжруулсан.', 'pl': 'Tagowanie części mowy (POS) dla języków bogatych morfologicznie, takich jak arabski, jest trudnym problemem ze względu na ogromne zestawy tagów. Jednym z powodów jest to, że w schemacie tagowania dla takich języków kompletny tag POS tworzony jest poprzez łączenie tagów z wielu zestawów tagów zdefiniowanych dla każdej kategorii morfosyntaktycznej. Poprzednie podejścia w arabskim tagowaniu POS stosowały jeden model dla każdego zadania tagowania morfosyntaktycznego, bez wykorzystywania współdzielonych informacji między zadaniami. W niniejszym artykule proponujemy podejście wykorzystujące te informacje poprzez wspólne modelowanie wielu morfosyntaktycznych zadań tagowania z wielozadaniowym frameworkiem uczenia się. Proponujemy również metodę włączania informacji o słowniku tagów do naszych modeli neuronowych poprzez łączenie reprezentacji słów z reprezentacjami zbiorów możliwych tagów. Nasze eksperymenty wykazały, że wspólny model z informacjami o słowniku tagów powoduje dokładność 91,38% na zbiorze danych Penn Arabic Treebank, z absolutną poprawą o 2,11% w porównaniu z aktualnym najnowocześniejszym tagerem.', 'si': 'මොර්ෆෝලෝජික විශේෂ භාෂාවක් සඳහා ප්\u200dරශ්නයක් (POS) ටැග් කරන්න අරාබික වගේ ප්\u200dරශ්නයක් තමයි ඔවුන්ගේ ගොඩ මේක සඳහා එක හේතුවක් තමයි මේ භාෂාවට ටැග් ස්කම් වලින්, සම්පූර්ණ POS ටැග් ස්ථාපනයක් හැම මොර්ෆෝසින්ටක් වර්ගයෙ මොර්ෆෝසින්ටාක්ටික් ටැග් වැඩකට පසුගින් අරාබික POS ටැග් එක්ක මොඩේල් එකක් භාවිත කරලා තියෙන්නේ, වැඩකට අත මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා මේ තොරතුරු සම්බන්ධ වෙනුවෙන් මාර්ෆෝසින්ටාක්ටික් ටැග් කරනවා මාර්ෆෝසින්ටා අපි තමයි ටැග් වචනය තොරතුරු සම්බන්ධ කරන්න ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරන්න පුළුවන් ටැග් වචනය තොරතුරු සම්බන්ධ කරනවා  අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට ටැග් වචනය තොරතුරු එක්ක සම්බන්ධ මොඩල් එක්ක 91.38% පෙන්න් අරාබික් ට්\u200dරීබැන්ක් තොරතුරු සම්බන්ධතා', 'so': 'Part-of-speech (POS) tagging for morphologically rich languages such as Arabic is a challenging problem because of their enormous tag sets.  Sababtaas darteed waxaa loola sameeyaa qorshaha tagging ee luqadaha oo kale, boostada POS waxaa lagu sameeyaa si uu uga soo ururiyo tag badan oo loo qoray kooxo kasta oo morphosyntactic ah. Dhaqdooyinkii hore ee lagu soo bandhigay afka Carabiga POS waxay codsadeen qaab u eg shaqo kasta oo morphosyntactic ah, iyadoon isticmaalin macluumaad la xiriira shaqada dhexdooda. Qoraalkan waxaynu ka soo jeedaynaa qaabab lagu isticmaalo macluumaadkan si wadajir ah u sameynayo shaqooyin la xiriira marxalado badan oo la barto shaqo badan. Sidoo kale waxaynu soo bandhignaynaa qaab ku qoran macluumaadka warqadda ku qoran tusaalaha neurada ee noogu soo bandhigi karo noocyada hadalka oo la soo bandhigi karo qeybaha alaabta suurtagalka ah. Imtixaanadeena waxay muuqatay in tilmaamaha wadajirka ah ee macluumaadka warqadda ku qoran yahay saxda 91.38% oo ku saabsan taariikhda Treebank ee Penn Carabi, kaas oo hagaajiyey 2.11% oo ka kordhiya xaaladda-sanadda.', 'sr': 'Dio govora (POS) označavanje morfološki bogatih jezika poput Arapskog je izazovni problem zbog njihovih ogromnih seta oznake. Jedan razlog za to je da u šemi oznake za takve jezike kompletna oznake POS formira kombiniranjem oznake iz višestrukih oznake definisanih za svaku morfosintaktičku kategoriju. Prethodni pristupi na arapskom označavanju POS-a primjenjivali su jedan model za svaki morfosintaktički zadatak označavanja, bez korištenja zajedničkih informacija između zadataka. U ovom papiru predlažemo pristup koji koristi ovu informaciju zajedno modelirajući više morfosintaktičkih zadataka sa multi task učenjem okvira. Takođe predlažemo metodu uključivanja informacija o rečniku oznake u naše neuralne modele kombinirajući predstave riječi sa predstavljanjem seta mogućih oznake. Naši eksperimenti pokazali su da zajednički model sa informacijama o rečniku rezultira tačnosti od 91,38% na kompletu podataka o Treebank-u Penn Arapske, sa apsolutnom poboljšanjem od 2,11% iznad trenutnog stanja umjetnika.', 'sv': 'Part-of-speech (POS) märkning för morfologiskt rika språk som arabiska är ett utmanande problem på grund av deras enorma taggar uppsättningar. En anledning till detta är att i taggschemat för sådana språk bildas en komplett POS-tagg genom att kombinera taggar från flera taggsuppsättningar definierade för varje morfosyntaktisk kategori. Tidigare metoder i arabisk POS-märkning tillämpade en modell för varje morfosyntaktisk märkningsuppgift, utan att använda delad information mellan uppgifterna. I denna uppsats föreslår vi ett tillvägagångssätt som utnyttjar denna information genom att gemensamt modellera flera morfosyntaktiska taggande uppgifter med ett multi-task learning ramverk. Vi föreslår också en metod för att införliva tagglexikoninformation i våra neurala modeller genom att kombinera ordrepresentationer med representationer av uppsättningar av möjliga taggar. Våra experiment visade att den gemensamma modellen med tagglexikoninformation resulterar i en noggrannhet på 91,38% på Penn Arabic Treebank datauppsättningen, med en absolut förbättring på 2,11% jämfört med nuvarande state-of-the-art taggare.', 'ta': 'Part-of-speech (POS) tagging for morphologically rich languages such as Arabic is a challenging problem because of their enormous tag sets.  இந்த மொழிகளுக்கான ஒட்டும் முறைமையில், ஒவ்வொரு மொத்த ஒட்டு வகைக்கும் வரையறுக்கப்பட்ட பல ஒட்டு அமைப்பிலிருந்தும் ஒரு முழு POS ஒட்டு  @ info: status இந்த காகிதத்தில், நாம் இந்த தகவலை பயன்படுத்தும் ஒரு முறையீட்டை பரிந்துரைக்கிறோம். பல பணி கற்றுக் கொள்ளும் சட்டத்தில் பல மாதிரி ஒ மேலும் நாம் ஒட்டு அகராதி தகவலை எங்கள் புதிய மாதிரிகளில் சேர்க்கும் வார்த்தை குறிப்பிட்ட குறிப்பிட்ட குறிப்புகளின் க எங்கள் சோதனைகள் குறியீடு தகவலுடன் இணைய மாதிரி வெளிப்படுத்தப்பட்டது பென் அரபி ட்ரீபாங் தகவல் அமைப்பில் 91.38% சரியான முறையை காண்பிக்கிறது, தற்போதைய நிலையில் உள', 'ur': 'زبان کا ایک حصہ (POS) ٹاگ ہے جو ان کے بڑے ٹاگ سٹ کے سبب ایک مشکل ہے۔ اس کے لئے ایک دلیل یہ ہے کہ اس طرح کی زبانوں کے ٹاگنگ سیکٹ میں ایک کامل POS ٹاگ پیدا کی جاتی ہے کہ ہر مورفوسینٹک کاٹ کے لئے تعریف کی تعریف کی تعریف کے مطابق مختلف ٹاگ سے ٹاگ جمع کرتی ہے. عربی پوس میں پہلے طریقے ٹاگ کرنے کے لئے ہر مورفوسینٹاکٹیک ٹاگ ٹاگ ٹاگ ٹاگ کے لئے ایک موڈل لازم کیا گیا ہے، بغیر کسی کام کے درمیان شریک معلومات کا استعمال نہ کرنا۔ ہم اس کاغذ میں ایک طریقہ پیشنهاد کرتے ہیں جو اس معلومات کو مشترک طریقے سے مزید مورپوسینٹاکٹیک ٹاگ کرنے کے ذریعے مزید-ٹاکٹ سکونٹ فرم کے ساتھ استعمال کرتا ہے. ہم نے بھی ایک طریقہ پیشنهاد کرتا ہے کہ ٹاگ ڈیکلوری معلومات کو ہمارے نیورال موڈل میں شامل کریں، کلمات کی نمونات کو ممکن ٹاگ کے سیٹوں کی نمونات کے ساتھ جمع کریں۔ ہماری آزمائش نے دکھائی کہ ٹاگ لکھنے والے معلومات کے ساتھ ملک موڈل پین عربی تری بینک ڈاٹ سٹ پر 91.38% کی دقیقیقیت کا نتیجہ ہوتا ہے، اس کے ذریعہ 2.11% کی مطلوب تغییر کے ذریعہ سے ہے.', 'ro': 'Etichetarea "Part-of-speech" (POS) pentru limbi bogate din punct de vedere morfologic, cum ar fi arabă, reprezintă o problemă provocatoare datorită seturilor enorme de etichete. Un motiv pentru acest lucru este că în schema de etichetare pentru astfel de limbi, o etichetă POS completă este formată prin combinarea etichetelor din mai multe seturi de etichete definite pentru fiecare categorie morfosintactică. Abordările anterioare în etichetarea POS arabă au aplicat un model pentru fiecare sarcină de etichetare morfosintactică, fără a utiliza informații partajate între sarcini. În această lucrare, propunem o abordare care utilizează aceste informații prin modelarea în comun a mai multor sarcini de etichetare morfosintactică cu un cadru de învățare multi-task. De asemenea, propunem o metodă de încorporare a informațiilor dicționarului de etichete în modelele noastre neurale prin combinarea reprezentărilor cuvintelor cu reprezentări ale seturilor de etichete posibile. Experimentele noastre au arătat că modelul comun cu informații despre dicționarul de etichete rezultă într-o precizie de 91,38% pe setul de date Penn Arabic Treebank, cu o îmbunătățire absolută de 2,11% față de taggerul actual de ultimă generație.', 'uz': "Name @ info Name Bu qogʻozda, biz bu maʼlumotni bir nechta morphosyntactic teglash vazifalarini bir nechta ko'plab vazifalar bilan o'rganish muvaffaqiyatlarini foydalanishini anglatamiz. Шунингдек, биз теги маълумотларни neyrol modellariимизга қўшилиш усулини тақдим этамиз ва имконият теглар таркибидаги маълумотлар билан сўз кўрсатмаларини жамлаш. Bizning imtiyozlarimizni ko'rsatdik, tag maʼlumoti bilan birga birlashtirish modeli Joriy holatning Joriy sarlavhasidagi arab Treebank maʼlumotlariga 91.38% yaxshi darajaga ega beradi.", 'vi': 'Một phần của bài phát biểu (POS) để tìm các ngôn ngữ giàu lịch sự như tiếng Ả Rập là một vấn đề khó khăn vì những tập mác lớn của họ. Một lý do cho việc này là trong bộ định vị của các ngôn ngữ này, một thẻ hoàn chỉnh của POS được hình thành bằng cách kết hợp các thẻ từ nhiều bộ đánh dấu được xác định cho mỗi loại morphine. Các phương pháp trước trong việc biên tập vị trí A Rập áp dụng một mô hình cho mỗi nhiệm vụ in dấu morphine, mà không tận dụng thông tin chia sẻ giữa các nhiệm vụ. Trong bài báo này, chúng tôi đề xuất một phương pháp sử dụng thông tin này bằng cách thiết lập các công việc in dấu vết nhiều kiểu morphine với một cơ sở học đa nhiệm vụ. Chúng tôi cũng đề xuất một phương pháp để thêm thông tin từ điển nhãn vào các mô hình thần kinh của chúng tôi bằng cách kết hợp các biểu hiện từ ngữ với các bộ nhớ các thẻ có thể. Những thí nghiệm của chúng tôi đã cho thấy rằng mô hình chung với từ điển nhãn hiệu quả là độ chính xác của 97.38. trên tập tin dữ liệu Penn Arab Treebank, với một tiến triển tuyệt đối cao hơn khẩu 2.11=-the-first tagger.', 'bg': 'Маркирането на част от речта (ПОС) за морфологично богати езици като арабски е предизвикателен проблем поради огромните им набори маркери. Една от причините за това е, че в схемата за етикетиране на такива езици, пълен ПОС таг се формира чрез комбиниране на тагове от множество тагове, определени за всяка морфосинтактична категория. Предишните подходи в арабското етикетиране на ПОС приложиха по един модел за всяка задача за морфосинтактично етикетиране, без да се използва споделена информация между задачите. В настоящата статия предлагаме подход, който използва тази информация чрез съвместно моделиране на множество задачи за морфосинтактично маркиране с рамка за обучение с множество задачи. Предлагаме и метод за включване на информация за таг речник в нашите невронни модели чрез комбиниране на думи с представяне на наборите от възможни тагове. Нашите експерименти показаха, че съвместен модел с информация за таг речник води до точност от 91.38% върху набора от данни Пен Арабски Трейбанк, с абсолютно подобрение от 2.11% спрямо сегашния модерен тагер.', 'da': 'Part-of-speech (POS) mærkning for morfologisk rige sprog som arabisk er et udfordrende problem på grund af deres enorme tagsæt. En årsag til dette er, at i taggeskemaet for sådanne sprog dannes et komplet POS-tag ved at kombinere tags fra flere tagsæt defineret for hver morfosyntaktisk kategori. Tidligere tilgange i arabisk POS tagging anvendte en model for hver morfosyntaktisk tagging opgave uden at bruge delte oplysninger mellem opgaverne. I denne artikel foreslår vi en tilgang, der udnytter disse oplysninger ved i fællesskab at modellere flere morfosyntaktiske tagging opgaver med en multi-task learning framework. Vi foreslår også en metode til at indarbejde tag ordordbog information i vores neurale modeller ved at kombinere ord repræsentationer med repræsentationer af sæt af mulige tags. Vores eksperimenter viste, at den fælles model med tag ordbog information resulterer i en nøjagtighed på 91,38% på Penn Arabic Treebank datasæt, med en absolut forbedring på 2,11% i forhold til den nuværende state-of-the-art tagger.', 'nl': 'Part-of-speech (POS) tagging voor morfologisch rijke talen zoals Arabisch is een uitdagend probleem vanwege hun enorme tag sets. Een reden hiervoor is dat in het taggingschema voor dergelijke talen, een volledige POS-tag wordt gevormd door het combineren van tags uit meerdere tagsets gedefinieerd voor elke morfosyntactische categorie. Eerdere benaderingen in Arabische POS-tagging pasten één model toe voor elke morfosyntactische tagging taak, zonder gebruik te maken van gedeelde informatie tussen de taken. In dit artikel stellen we een aanpak voor die deze informatie gebruikt door gezamenlijk meerdere morfosyntactische tagging taken te modelleren met een multi-task leerframework. We stellen ook een methode voor om tag woordenboek informatie in onze neurale modellen te integreren door woordrepresentaties te combineren met representaties van de sets van mogelijke tags. Onze experimenten toonden aan dat het gezamenlijke model met tag woordenboek informatie resulteert in een nauwkeurigheid van 91,38% op de Penn Arabic Treebank dataset, met een absolute verbetering van 2,11% ten opzichte van de huidige state-of-the-art tagger.', 'de': 'Part-of-Speech (POS) Tagging für morphologisch reiche Sprachen wie Arabisch ist aufgrund ihrer enormen Tag-Sets ein herausforderndes Problem. Ein Grund dafür ist, dass im Tagging-Schema für solche Sprachen ein komplettes POS-Tag gebildet wird, indem Tags aus mehreren Tag-Sets kombiniert werden, die für jede morphosyntaktische Kategorie definiert sind. Frühere Ansätze im arabischen POS-Tagging verwendeten ein Modell für jede morphosyntaktische Tagging-Aufgabe, ohne gemeinsame Informationen zwischen den Aufgaben zu verwenden. In diesem Beitrag schlagen wir einen Ansatz vor, der diese Informationen nutzt, indem wir gemeinsam mehrere morphosyntaktische Tagging-Aufgaben mit einem Multi-Task-Lernframework modellieren. Wir schlagen auch eine Methode vor, Tag Wörterbuch Informationen in unsere neuronalen Modelle zu integrieren, indem Wortdarstellungen mit Darstellungen der Sätze möglicher Tags kombiniert werden. Unsere Experimente zeigten, dass das gemeinsame Modell mit Tags-Wörterbuchinformationen zu einer Genauigkeit von 91,38% auf dem Penn Arabic Treebank Datensatz führt, mit einer absoluten Verbesserung von 2,11% gegenüber dem aktuellen Stand der Technik Tagger.', 'id': 'Bagian-dari-pidato (POS) tagging untuk bahasa morfologis kaya seperti Arab adalah masalah yang menantang karena set tag besar mereka. Salah satu alasan untuk hal ini adalah bahwa dalam skema tagging untuk bahasa-bahasa seperti itu, sebuah tag POS lengkap terbentuk dengan menggabungkan tag dari beberapa set tag yang didefinisikan untuk setiap kategori morfosintaksi. Pendekatan sebelumnya dalam tagging POS Arab menerapkan satu model untuk setiap tugas tagging morfosintaksi, tanpa menggunakan informasi berbagi antara tugas. Dalam kertas ini, kami mengusulkan pendekatan yang menggunakan informasi ini dengan bersama-sama memmodelir beberapa tugas tagging morfosintaksi dengan rangka belajar multi-tugas. We also propose a method of incorporating tag dictionary information into our neural models by combining word representations with representations of the sets of possible tags.  Eksperimen kami menunjukkan bahwa model kongsi dengan informasi tag kamus menghasilkan akurasi 91,38% pada set data Penn Arabic Treebank, dengan peningkatan mutlak 2,11% atas tag state-of-the-art saat ini.', 'sw': 'Sehemu ya hotuba (POS) ikipiga alama kwa lugha zenye utajiri wa kifo kama vile Kiarabu ni tatizo la changamoto kwa sababu ya seti zao kubwa. Sababu moja kwa hilo ni kwamba katika mpango wa kupiga kurasa kwa lugha kama hizi, alama kamili ya POS imetengenezwa kwa kuunganisha alama kutoka kwenye seti mbalimbali zinazoelezwa kwa kila kundi la morphosync. Matokeo yaliyopita kwa lugha ya POS ya Kiarabu yalitumia muundo mmoja kwa kila kazi ya michezo ya kifo, bila kutumia taarifa zilizoshirikishwa kati ya kazi hizo. Katika karatasi hii, tunapendekeza mbinu inayotumia taarifa hizi kwa kuonyesha kazi mbalimbali za viungo vya simu za mkononi kwa mfumo wa kujifunza kazi nyingi. Pia tunapendekeza mbinu ya kuingiza taarifa za kiimla katika mifano yetu ya neurali kwa kuwaunganisha uwakilishi wa neno na wawakilishi wa seti za tag zinazowezekana. Our experiments showed that the joint model with tag dictionary information results in an accuracy of 91.38% on the Penn Arabic Treebank data set, with an absolute improvement of 2.11% over the current state-of-the-art tagger.', 'hr': 'Dio govora (POS) označavanje morfološki bogatih jezika poput Arapskog je izazovni problem zbog njihovih ogromnih seta oznake. Jedan razlog za to je da se u šemu oznake za takve jezike kompletna oznake POS formira kombiniranjem oznake iz višestrukih oznake definiranih za svaku morfosintaktičku kategoriju. Prethodni pristupi na arapskom označavanju POS-a primjenjivali su jedan model za svaki morfosintaktički zadatak označavanja bez korištenja zajedničkih informacija između zadataka. U ovom papiru predlažemo pristup koji koristi ovu informaciju zajedno modelirajući više morfosintaktičkih zadataka označavanja s višestrukim učenim okvirom. Također predlažemo metodu uključivanja informacija o rečniku oznake u naše nervne modele kombiniranjem riječi predstavljanja predstavljanjem seta mogućih oznake. Naši eksperimenti pokazali su da zajednički model sa informacijama o rečniku rezultira točnosti od 91,38% na kompletu podataka o Treebank-u Penn Arapske, s apsolutnom poboljšanjem od 2,11% iznad trenutnog stavljača umjetnosti.', 'tr': 'Ýagtyň bir bölümi (POS) morfologik baý diller üçin etiketleýän arapça örän kynçylyk meseledir. Bu üçin bir sebäbi bolmaly däl diller üçin etiketleýän etiketlerde, her morphosyntaktik kategoriýa üçin tanplary birleşdirmek üçin biýillenýar. Arapça POS taglamasynda öňki golaýlary her morphosyntaktik taglama täblisasi üçin bir nusga uygulady, işleriň arasynda paylaşyk maglumaty ulanmazdan. Bu kağıtda, bu bilgileri birden çoklu morphosyntaktik öğrenme çerçevesi ile birleştirerek kullanan bir metodu teklif ediyoruz. Biz de tägler sözlüğü bilgilerini nöral modellerimize birleştirerek kelime ifadelerini mümkün tägler toplamlarıyla birleştirmek için bir yöntem teklif ediyoruz. Biziň deneylerimiz Penn Arapça agaç howlaryndaky etiket maglumaty bilen bir nusga bilen meňzeşlik nusga görkezilýändigini görkezilýär. Şu wagt tägleriň durumynda 2.11% gowurak bar.', 'ko': '어성 표기는 아랍어 등 형태가 풍부한 언어에 있어 도전적인 문제이다. 왜냐하면 그들은 대량의 표기집을 가지고 있기 때문이다.이렇게 하는 이유 중 하나는 이런 언어의 표기 방안에서 하나의 완전한 어성 표기는 각 형태의 문법 유형에 정의된 여러 개의 표기 집합의 표기를 조합한 것이다.이전의 아랍어 어성 표기 방법은 모든 형태 문법 표기 임무에 하나의 모델을 적용하고 임무 간의 공유 정보를 이용하지 않았다.본고에서 우리는 이러한 정보를 활용하는 방법을 제시했고 다중 임무 학습 구조를 통해 여러 형태의 문법 표기 임무를 연합하여 모델링했다.우리는 또한 단어 표시와 가능한 표기집 표시를 결합시켜 표기 사전 정보를 우리의 신경 모델에 포함시키는 방법을 제시했다.우리의 실험에 의하면 사전 정보를 표시하는 연합 모델이 펜실베이니아대학 아랍 트리 데이터베이스 데이터 집합에서의 정확도는 91.38%로 현재 가장 선진적인 표기기에 비해 2.11% 높아졌다.', 'fa': 'بخشی از سخنرانی (POS) که برای زبانهای پولدار مورفولوژیکی مثل عربی یک مشکل سخت\u200cکننده است به دلیل مجموعه\u200cهای بسیار بزرگ آنها. یک دلیل برای این اینه که در برنامه نقاشی برای چنین زبانها، یک نقاشی کامل POS با ترکیب نقاشی از مجموعه\u200cهای متعدد نقاشی که برای هر گروه مورفوسینکتی تعریف شده\u200cاند صورت می\u200cگیرد. دسترسی قبلی در نقاشی POS عربی یک مدل برای هر کار نقاشی مورفوسینکتی استفاده کرد، بدون استفاده از اطلاعات مشترک بین کارها. در این کاغذ، ما یک روش پیشنهاد می کنیم که این اطلاعات را با مدل کردن کار های متعدد مورفوسینتیک با یک چهارچوب یادگیری multi task ی استفاده می کند. ما همچنین یک روش پیشنهاد می\u200cکنیم که اطلاعات الکترونیک را در مدل\u200cهای عصبی ما با ترکیب نمایش\u200cدهندگان کلمات با نمایش\u200cدهندگان مجموعه\u200cهای برچسب\u200cهای ممکن ترکیب کنیم. آزمایشات ما نشان دادند که مدل مشترک با اطلاعات یادآوری یادآوری به نتیجه دقیق 91.38 درصد در مجموعه داده های درخت درخت عربی پن است، با توسعه کامل ۲.۱۱ درصد در حالت یادآوری فعلی.', 'sq': 'Pjesë e fjalimit (POS) etiketat për gjuhë morfologjikisht të pasura si arabisht është një problem sfidues për shkak të grupeve të tyre të mëdha të etiketave. Një arsye për këtë është se në skemën e etiketave për gjuhë të tilla, një etiketë e plotë POS formohet duke kombinuar etiketat nga grupe të shumta etiketash të përcaktuara për çdo kategori morfosintaktike. Përqasjet e mëparshme në etiketat arabe POS aplikojnë një model për çdo detyrë morfosintaktike etiketash, pa përdorur informacion të përbashkët midis detyrave. In this paper, we propose an approach that utilizes this information by jointly modeling multiple morphosyntactic tagging tasks with a multi-task learning framework.  Ne propozojmë gjithashtu një metodë për përfshirjen e informacionit të fjalorit të etiketave në modelet tona neurale duke kombinuar përfaqësimet e fjalëve me përfaqësimet e grupeve të etiketave të mundshme. Eksperimentet tona treguan se modeli i përbashkët me informacionin e fjalorit të etiketave rezulton në një saktësi prej 91.38% në grupin e të dhënave të Bankës së Treve Arabe Penn, me një përmirësim absolut prej 2.11% mbi gjeneralën aktuale më të mirë.', 'az': 'Böyük etiket setlərinin səbəbi ərəb dillərinin morfolojik zengin dillərinin etiketlərinin bir parças ı çətin problemidir. Bunun bir səbəbi belə dillər üçün etiketləmə taslağında, hər bir morfosintaktik kategoriya üçün müxtəlif etiketlərdən etiketləri birləşdirən tamamlanmış POS etiketi yaradılır. Arapça POS etiketində əvvəlki tərzlərin hər morphosyntaktik etiketçi işi üçün bir modeli uyguladı, işlər arasında paylaşılan məlumatları istifadə etmədən. Bu kağızda, bu məlumatı çoxlu çoxlu iş öyrənmə framework ü ilə birlikdə modelləşdirən çoxlu morfosintaktik işarələri etiketləmək üçün istifadə edən bir yol təklif edirik. Biz də etiket sözlük məlumatlarını neural modellərimizə qatmaq üçün bir yolu təklif edirik ki, sözləri mümkün etiketlərin nümunələrini birləşdirib. Bizim təcrübələrimiz göstərdi ki, etiket sözlük məlumatları ilə birləşdirilmiş modellərin Penn Arapçası ağacı bankası məlumatları qutusunda 91,38%-in doğruluğuna bənzəyir. Şimdiki məlumatların etiketçisi üzərində 2,11%-in tamamilə yaxşılaşdırılır.', 'hy': 'Խոսքի մասը (POS) նշանները, որոնք նշանակում են մորֆոլոգիապես հարուստ լեզուներ, ինչպիսիք են արաբերենը, դժվար խնդիր է նրանց հսկայական նշանների պատճառով: Սրա պատճառը նրանում է, որ այս լեզուների նշանների համակարգում ամբողջական POS նշաններ կազմված են միավորելով բազմաթիվ նշանների համակարգերից, որոնք սահմանվում են յուրաքանչյուր մորֆոսինտակտիկ կատեգորիայի համար: Արաբական POS-ի նշաններում նախորդ մոտեցումները կիրառեցին մեկ մոդել յուրաքանչյուր մորֆոսինտակտիկ նշանների համար, առանց կիրառելու աշխատանքների միջև ընդհանուր տեղեկատվություն: Այս թղթի մեջ մենք առաջարկում ենք մի մոտեցում, որը օգտագործում է այս տեղեկատվությունը միասին մոդելավորելով բազմաթիվ մորֆոսինտակտիկ նշանակման խնդիրներ բազմաթիվ խնդիրների ուսումնասիրության շրջանակներով: Մենք նաև առաջարկում ենք թեգ բառարանի ինֆորմացիայի ներառման մեթոդ մեր նյարդային մոդելների մեջ, միավորելով բառարանի ներկայացումները հնարավոր թեգների ներկայացումների հետ: Մեր փորձարկումները ցույց տվեցին, որ միավոր մոդելը, որն ունի բառարանի տեղեկատվություն, հանգեցնում է Պենն Արաբական ծառի տվյալների համակարգի 91.38 տոկոսի ճշգրտությանը, ինչը բացարձակ բարելավում է 2.11 տոկոսին ներկայիս բարձրագույն բառարանի հետ:', 'bn': 'ভাষণের অংশ (পোএস) নৈতিক ভাষায় সমৃদ্ধ ভাষার জন্য ট্যাগিং যেমন আরবী ভাষায়, তাদের বিশাল ট্যাগ সেটের কারণে একটি চ্যালেঞ্জা এর জন্য একটি কারণ হচ্ছে এই ধরনের ভাষার ট্যাগিং বিন্যাসে পুরোপুরি পোস ট্যাগ গঠন করা হয়েছে প্রত্যেক মোর্ফোসিক্যাটিক বিভাগের জন্য নির্ধা আরবী পোস ট্যাগিং এর পূর্ববর্তী প্রতিটি মরোফোসিক্যাটিক ট্যাগিং কাজের জন্য একটি মডেল প্রয়োগ করা হয়েছে, কাজের মধ্যে শেয়ার করা ত এই কাগজটিতে আমরা একটি পদক্ষেপ প্রস্তাব করি যা এই তথ্য ব্যবহার করে একাত্মতায় বহুক্ষেত্রের শিক্ষা ফ্রেমের মাধ্যমে বেশ কিছু মডেলিং কর আমরা ট্যাগের অভিধান তথ্য আমাদের নিউরেল মডেলে যোগাযোগ করার একটি পদ্ধতি প্রস্তাব করি সম্ভাব্য ট্যাগের প্রতিনিধিত্বের সাথে শব্দ আমাদের পরীক্ষা দেখা যাচ্ছে যে ট্যাগের অভিধান তথ্যের সাথে যৌথ মডেলের ফলে পেন আরবী ট্রেবাঙ্কের তথ্য সেটে ৯১. ৩৮ শতাংশের সঠিকভাবে প্রতিফলিত হয়েছে, যার ফলে বর', 'ca': "L'etiqueta part-of-speech (POS) de llengües morfològicament rics com l'àrab és un problem a desafiant a causa dels seus enormes conjunts d'etiquetes. Una raó per això és que en l'esquema d'etiquetage d'aquestes llengües es forma una etiqueta POS completa combinant etiquetes de múltiples conjunts d'etiquetes definits per cada categoria morfosinàctica. Els enfocaments anteriors de la etiqueta POS àrab van aplicar un model per cada tasca de etiqueta morfosinàctica, sense utilitzar informació compartida entre les tasques. En aquest paper, proposem un enfocament que utilitza aquesta informació modelant conjuntament múltiples tasques d'etiquetage morfosinàctic amb un marc d'aprenentatge multitasca. També proposem un mètode d'incorporar la informació del diccionari d'etiquetes als nostres models neurals combinant representacions de paraules amb representacions dels conjunts d'etiquetes possibles. Els nostres experiments van demostrar que el model conjunt amb informació de diccionari etiquetat dóna lloc a una precisió del 91,38% en el conjunt de dades del Penn Arabic Treebank, amb una millora absoluta del 2,11% en comparació amb l'etiquetador actual d'última generació.", 'af': "Deel- van- spreek (POS) merking vir morfologiese ryk tale soos Arabiese is 'n pragtige probleem vanweë hul groot etiket stel. Een rede vir hierdie is dat in die etiket skema vir sodanige tale, 'n volledige POS etiket is formeer deur die kombinasie van etikette van veelvuldige etiket stel gedefinieerd vir elke morfosyntaktike kategorie. Vorige toegang in Arabiese Pos merking het een model aangepas vir elke morfosyntaktike merking taak, sonder om gedeelde inligting tussen die taak te gebruik. In hierdie papier, voorstel ons 'n toegang wat hierdie inligting gebruik deur bymekaar modelleer veelvuldige morfosyntaktike merking opdragte met 'n multi-taak leer raamwerk. Ons het ook 'n metode voorgestel om etiket woordeboek inligting in ons neurale modele te inkorporeer deur woord verteenwoordes met verteenwoordes van die stelle van moontlike etikette te kombinereer. Ons eksperimente het vertoon dat die joint model met etiket woordeboek inligting resultaat in 'n presisie van 91.38% op die Penn Arabiese Boom bank data stel, met 'n absoluut verbetering van 2.11% oor die huidige staat-van-kuns-etiket.", 'am': 'አረቢብ እንደሆነ የቋንቋ-ቋንቋ (POS) ማቀላቀል በብዛት ተርጓሚዎች መቆጣጠር ነው፡፡ አንድ ምክንያት ለዚህ ቋንቋዎች በtagging scheme ውስጥ ሙሉ POS tag በመለጠፍ ለሁሉም morphosyntactic ክፍተት በተለያዩ ምልክት ማሰናከል ነው፡፡ የቀድሞው ደረጃዎች በዐረብኛ POS ማተሚያ አንድ ሞዴል ለሁሉም ሞሮፎsyntactic ማሰሪያ ስራ ሳይጠቀም በስራዎቹ መካከል የተካፈለ መረጃ ተጠቀም፡፡ በዚህ ፕሮግራም፣ ይህንን መረጃዎች በመጠቀም በብዙ ትምህርት ትምህርት ፕሮግራም የተለየ ብዙ ዶፎስSyntactic ስራዎችን በመጠቀም እናስባለን፡፡ የመዝገብ መዝገብ የመዝገበኛ መረጃዎችን በናውራዊ ሞዴላዎች ውስጥ እናስገባለን፡፡ ፈተናዎቻችን የመዝገበ የመዝገበ የመዝገብ መረጃዎች የጣቢያ መተላለፊያ አረብኛ ትርጓሜ 91.38 በመቶ አረቢያ የTreebank ዳታ ማድረግ ነው፡፡', 'cs': 'Tagování části řeči (POS) pro morfologicky bohaté jazyky, jako je arabština, je náročným problémem kvůli jejich obrovským sadám tagů. Jedním z důvodů je, že v tagovacím schématu těchto jazyků vzniká kompletní POS tag kombinací tagů z více sad tagů definovaných pro každou morfosyntaktickou kategorii. Předchozí přístupy v arabském tagování POS aplikovaly jeden model pro každou morfosyntaktickou tagovací úlohu, aniž by byly použity sdílené informace mezi úkoly. V tomto článku navrhujeme přístup, který využívá těchto informací společným modelováním více morfosyntaktických tagovacích úloh s víceúlohovým učebním frameworkem. Navrhujeme také metodu začlenění slovníkových informací do našich neuronových modelů kombinací slovních reprezentací s reprezentacemi množin možných značek. Naše experimenty ukázaly, že společný model s informacemi o slovníku značek vede k přesnosti 91,38% na datové sadě Penn Arabic Treebank, s absolutním zlepšením o 2,11% oproti současnému špičkovému tageru.', 'et': 'Kõneosa (POS) märgistamine morfoloogiliselt rikkalike keelte, nagu araabia keel, on keeruline probleem nende tohutute siltikomplektide tõttu. Üks põhjus selleks on see, et selliste keelte sildistamisskeemis moodustatakse täielik POS-silt, kombineerides silte mitmest sildist, mis on määratletud iga morfosüntaktilise kategooria kohta. Varasemad lähenemised araabia POS sildistamisel rakendasid iga morfosüntaktilise sildistamisülesande jaoks ühe mudeli, kasutamata ülesannete vahelist jagatud teavet. Käesolevas töös pakume välja lähenemisviisi, mis kasutab seda teavet, modelleerides ühiselt mitmeid morfosüntaktilisi sildistamisülesandeid mitme ülesandega õpperaamistiku abil. Samuti pakume välja meetodi, kuidas lisada sildisõnaraamatu informatsioon meie närvimudelitesse, kombineerides sõnaesindusi võimalike sildide kogumitega. Meie eksperimendid näitasid, et siltide sõnastiku infoga ühine mudel annab Penn Arabic Treebanki andmekogumi täpsuse 91,38%, absoluutse paranemise 2,11% võrreldes praeguse kaasaegse siltidega.', 'bs': 'Dio govora (POS) označavanje morfološki bogatih jezika poput Arapskog je izazovni problem zbog njihovih ogromnih seta oznake. Jedan razlog za to je da se u šemi označavanja takvih jezika kompletna oznaka POS formira kombinacijom oznake iz višestrukih oznake definiranih za svaku morfosintaktičku kategoriju. Prethodni pristupi na arapskom označavanju POS-a primjenjivali su jedan model za svaki morfosintaktički zadatak označavanja, bez korištenja zajedničkih informacija između zadataka. U ovom papiru predlažemo pristup koji koristi ovu informaciju zajedno modelirajući više morfosintaktičkih zadataka označavanja sa multi task učenjem okvira. Također predlažemo metodu uključivanja informacija o rečniku oznake u naše neuralne modele kombiniranjem predstavljanja riječi sa predstavljanjem seta mogućih oznake. Naši eksperimenti pokazali su da zajednički model sa informacijama o rečniku rezultira tačnosti od 91,38% na kompletu podataka o Treebank-u Penn Arapske, s apsolutnom poboljšanjem od 2,11% iznad trenutnog stavljača umjetnosti.', 'fi': 'Muotologisesti rikkaiden kielten, kuten arabian, puheen osatunnistus (POS) on haastava ongelma valtavien tagien vuoksi. Yksi syy tähän on se, että tällaisten kielten tagausjärjestelmässä täydellinen POS-tagi muodostuu yhdistämällä tunnisteita useista tunnistejoukoista, jotka on määritelty kullekin morfosyntaktiselle luokalle. Aiemmat lähestymistavat arabialaisessa POS-tagauksessa sovelsivat yhtä mallia kuhunkin morfosyntaktiseen tagaukseen hyödyntämättä jaettua tietoa tehtävien välillä. Tässä työssä ehdotamme lähestymistapaa, joka hyödyntää tätä tietoa mallintamalla yhdessä useita morfosyntaktisia tagging tehtäviä monitehtävän oppimiskehyksellä. Ehdotamme myös menetelmää, jolla tunnistesanakirja voidaan sisällyttää neuromalleihimme yhdistämällä sanaesityksiä mahdollisten tunnisteiden esityksiin. Kokeet osoittivat, että yhteinen malli tunnistesanakirjan informaation kanssa tuottaa 91,38% tarkkuuden Penn Arabic Treebankin aineistossa, ja absoluuttinen parannus 2,11% verrattuna nykyiseen huipputekniikkaan.', 'ha': "@ info: whatsthis One reason for this is that in the tagging scheme for such languages, a complete POS tag is formed by combining tags from multiple tag sets defined for each morphosyntactic category.  @ info: whatsthis Ga wannan takardan, Munã buɗa wani hanyoyi wanda ke yin amfani da wannan information da ke sami-motsi masu shirya task õkin tagogi masu yawa da firam masu sanar da multi-aikin. Kayya, Munã buɗa wani hanyoyi wa ka shigar da information za'urar tagogi cikin misalinmu na neura da za'a haɗa maganar macalli da masu tsarin tagogi masu yiwuwa. CiraryinMu ya nuna cewa, shirin shirin haɗi da information na tag on dictionary na ƙara matsayin tsari na 91.38% na daidaita data na Treebank na Larabci, da mai ƙari da 2.11% a kan halin-halin-sanar.", 'he': 'החלק של הנאום (POS) תווים לשפות עשירות מורפולוגית כמו ערבית היא בעיה מאתגרת בגלל קבוצות תווים עצומות שלהם. סיבה אחת לכך היא שבמערכת התגיות לשפות כאלה, תווית POS מושלמת נוצרת על ידי שילוב תוויות ממספר תוויות מוגדרות לכל קטגוריה מורפוסינטקטית. גישות קודמות בתג POS ערבית שימשו מודל אחד לכל משימה תג מורפוסינטאקטית, בלי להשתמש במידע משותף בין המשימות. בעיתון הזה, אנו מציעים גישה שמשתמשת במידע הזה על ידי דוגמנים משותפים מורפוסינטאקטיים מרובים עם מסגרת לימוד מרובה משימות. אנחנו גם מציעים שיטה להכניס מידע מילון תגים לדוגמנים העצביים שלנו על ידי שילוב מייצגים מילים עם מייצגים של קבוצות של תגים אפשריים. Our experiments showed that the joint model with tag dictionary information results in an accuracy of 91.38% on the Penn Arabic Treebank data set, with an absolute improvement of 2.11% over the current state-of-the-art tagger.', 'sk': 'Označevanje dela govora (POS) za morfološko bogate jezike, kot je arabščina, je zahteven problem zaradi njihovih ogromnih naborov oznak. Eden od razlogov za to je, da se v shemi označevanja za take jezike celotna oznaka POS oblikuje z združevanjem oznak iz več naborov oznak, določenih za vsako morfosintaktično kategorijo. Prejšnji pristopi v arabskem označevanju POS so uporabili en model za vsako opravilo morfosintaktičnega označevanja, ne da bi uporabili skupne informacije med opravili. V prispevku predlagamo pristop, ki uporablja te informacije s skupnim modeliranjem več morfosintaktičnih nalog označevanja z večopravilnim učnim okvirom. Predlagamo tudi metodo vključevanja informacij o slovarju oznak v naše nevronske modele z združevanjem besednih reprezentacij s predstavitvami naborov možnih oznak. Naši eksperimenti so pokazali, da je skupni model z informacijami slovarja oznak 91,38% natančnost podatkovnega nabora Penn Arabic Treebank, z absolutnim izboljšanjem za 2,11% v primerjavi s trenutnim najsodobnejšim označevalnikom.', 'jv': 'MBR-Ngerawat (po S) One error message politenessoffpolite"), and when there is a change ("assertivepoliteness Nang pepulan iki, kita supoyo nggunakake tarjamahan kanggo nggawe informasi iki dadi model dadi multi-task nyimpen Awak dhéwé éngawe sistem sing arep nggawe informasi etiket karo model sing nêrung kuwi nggawe gerakan kelangan representasi karo gambar teka sing bisa nêmên. Awakdhéwé éntuk dhéwé ngertuk sistem sing nggawe nêmên karo informasi sing diketeksi kuwi sawetara welasakno sing wis ana sakjane kanggo wong dhéwé, dadi nyong penyuh, stabok punika ingkang 2.11% sing apik dhéwé', 'bo': 'Part-of-speech (POS) tagging for morphologically rich languages such as Arabic is a challenging problem because of their enormous tag sets. One reason for this is that in the tagging scheme for such languages, a complete POS tag is formed by combining tags from multiple tag sets defined for each morphosyntactic category. གཟུགས་བརྙན་གྱི་གནད་སྡུད་འདྲི་ཞིབ་བྱས་པའི་སྔོན་གྱི་གནད In this paper, we propose a approach that uses this information by jointly modeling multiple morphosyntactic tagging tasks with a multi-task learning framework. ང་ཚོས་ཀྱང་ལག་ཁྱེར་གྱི་ཤོག་བྱང་ཆ་འཕྲིན་ཡིག་གི་གསལ་བཤད་ཀྱི་ལམ་ལུགས་གཅིག་གི་ནང་དུ་འཇུག ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་ཁ་ཡིག་ཆ་དང་མཉམ་གྱི་མིག་དཔེ་དབྱིབས་འདུག'}
{'en': 'Learning from Relatives : Unified Dialectal Arabic Segmentation', 'ar': 'التعلم من الأقارب: التجزئة العربية اللهجة الموحدة', 'fr': 'Apprendre de la famille\xa0: segmentation arabe dialectale unifiée', 'pt': 'Aprendendo com parentes: segmentação árabe dialetal unificada', 'es': 'Aprendiendo de los familiares: segmentación unificada del árabe dialectal', 'ja': '親族から学ぶ：統一方言アラビア語セグメンテーション', 'zh': '学于亲戚,一阿拉伯语方言细分', 'hi': 'रिश्तेदारों से सीखना: एकीकृत बोलचाल अरबी विभाजन', 'ru': 'Учимся у родственников: унифицированная диалектальная арабская сегментация', 'ga': 'Ag Foghlaim ó Ghaolta: Deighleog Araibis Chanúnach Aontaithe', 'ka': 'Relatives', 'el': 'Μάθηση από συγγενείς: Ενοποιημένη διαλεκτική αραβική τμηματοποίηση', 'it': 'Imparare dai parenti: Segmentazione dialettale araba unificata', 'hu': 'Tanulás rokonoktól: Egységes dialektikus arab szegmentáció', 'kk': 'Сәйкестіктерден оқыту: біріктірілген араб сегментациясы', 'lt': 'Susijusių asmenų mokymasis: suvienodinta dialektinė arabų segmentacija', 'mk': 'Learning from Relatives: Unified Dialectal Arabic Segmentation', 'ms': 'Belajar dari Perhubungan: Segmentasi Arab Dialektik Bersatu', 'mn': 'Хэрэглэгчдийн суралцах: Нэгдсэн Араб хэсэг', 'ml': 'Learning from Relatives: Unified Dialectal Arabic Segmentation', 'mt': 'Tagħlim minn Relativi: Segmentazzjoni Għarbija Dijalettwali Unifikata', 'sr': 'Naučenje od Relativa: jedinstvena dijalektna arapska segmentacija', 'ro': 'Învățarea de la rude: Segmentarea dialectală arabă unificată', 'no': 'Læring frå Relativ: Unified Dialectal Arabic Segmentation', 'pl': 'Uczenie się od krewnych: ujednolicona dialektalna segmentacja arabska', 'ta': 'குடும்பங்களிலிருந்து கற்றுக் கொண்டிருக்கிறது: Unified Dialectal Arabic Segmentation', 'so': 'Waxbarashada Relatives: Unified Dialectal Arabic Segmentation', 'si': 'සම්බන්ධතාවක් වලින් ඉගෙනගන්න: එක්කත් අරාබික් සෙග්මැන්ටමන්ට', 'sv': 'Lära av släktingar: Enhetlig dialektisk arabisk segmentering', 'ur': 'Relatives سے سیکھنا: یونیفڈ ڈائیلٹیل عربی سیگنٹمنٹ', 'uz': 'Name', 'vi': 'Học hỏi từ Bà con: KCharselect unicode block name', 'bg': 'Учене от роднини: Унифицирана диалектална арабска сегментация', 'da': 'Læring af slægtninge: Unified dialektisk arabisk segmentering', 'de': 'Lernen von Verwandten: Einheitliche dialektale arabische Segmentierung', 'nl': 'Leren van familieleden: Unified Dialectal Arabic Segmentation', 'hr': 'Naučenje od Relativa: jedinstvena dijalektna arapska segmentacija', 'fa': 'آموزش از ارتباطات: جداگاهی عربی متحده', 'ko': '친척에게 배우기: 사투리 통일 아랍어 절분', 'id': 'Belajar dari Relatives: Segmentasi Arab Dialektik Bersatu', 'tr': 'Relativlardan öwrenmek: Birleýiş Dialektik Arapça Segmentasiýasy', 'af': 'Leer van Relatives: Unified Dialectal Arabic Segmentation', 'am': 'Unified Dialectal Arabic Segmentation', 'sw': 'Kujifunza kutoka kwa Kuhusiana: Kutengenezwa kwa Kiarabu', 'sq': 'Mësimi nga të afërmit: Segmentacioni i Unifikuar Dialektik Arab', 'bn': 'পরিবারের শিক্ষা: একত্রিত ডায়ালেক্টাল আরবী বিভাগ', 'hy': 'Համախորդներից սովորելը՝ միավորված դիալեկտալ արաբական սեգմենցիա', 'ca': 'Learning from Relatives: Unified Dialectal Arabic Segmentation', 'cs': 'Učení se od příbuzných: Jednotná dialektální arabská segmentace', 'et': 'Õppimine sugulastelt: ühtne dialektiline araabia segmentatsioon', 'fi': 'Oppiminen sukulaisilta: Yhdistetty dialektinen arabian segmentointi', 'az': 'Relativlardan √∂yr…ônm…ôk: Unified Dialectal Arabic Segmentation', 'bs': 'Naučenje od Relativa: jedinstvena dijalektna arapska segmentacija', 'sk': 'Učenje od sorodnikov: enotna dialektična arabska segmentacija', 'he': 'ללמוד משפחות משפחה: מחלקה ערבית דיאלקטית מאוחדת', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'Learning from Relatives: Unified Dialectal Arabic Segmentation', 'ha': 'KCharselect unicode block name'}
{'en': 'Arabic dialects do not just share a common koin, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other. In this paper we build a unified segmentation model where the training data for different dialects are combined and a single model is trained. The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation. We also measure the degree of relatedness between four major Arabic dialects by testing how a segmentation model trained on one dialect performs on the other dialects. We found that linguistic relatedness is contingent with geographical proximity. In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling.', 'ar': 'لا تشترك اللهجات العربية فقط في لغة كوينو مشتركة ، ولكن هناك ظواهر لغوية مشتركة بين اللهجات تسمح للنماذج الحسابية لللهجات بالتعلم من بعضها البعض. في هذا البحث قمنا ببناء نموذج تجزئة موحد حيث يتم دمج بيانات التدريب لهجات مختلفة ويتم تدريب نموذج واحد. ينتج النموذج دقة أعلى من النماذج الخاصة باللهجة ، مما يلغي الحاجة إلى تحديد اللهجة قبل التجزئة. نقيس أيضًا درجة الارتباط بين أربع لهجات عربية رئيسية من خلال اختبار كيفية أداء نموذج التقسيم المدرَّب على لهجة واحدة في اللهجات الأخرى. وجدنا أن الترابط اللغوي يتوقف على القرب الجغرافي. في تجاربنا ، نستخدم التصنيف المستند إلى SVM ووضع العلامات على تسلسل ثنائي LSTM-CRF.', 'fr': "Les dialectes arabes ne partagent pas seulement un koinë commun, mais il existe des phénomènes linguistiques pandialectaux communs qui permettent aux modèles informatiques d'apprendre les uns des autres. Dans cet article, nous élaborons un modèle de segmentation unifié dans lequel les données de formation pour différents dialectes sont combinées et un seul modèle est formé. Le modèle produit des précisions plus élevées que les modèles spécifiques à un dialecte, ce qui élimine la nécessité de l'identification du dialecte avant la segmentation. Nous mesurons également le degré de parenté entre quatre principaux dialectes arabes en testant la performance d'un modèle de segmentation formé sur un dialecte sur les autres dialectes. Nous avons constaté que la parenté linguistique dépend de la proximité géographique. Dans nos expériences, nous utilisons le classement basé sur la SVM et le marquage de séquence Bi-LSTM-CRF.", 'es': 'Los dialectos árabes no solo comparten una koinë común, sino que hay fenómenos lingüísticos pandialectales compartidos que permiten que los modelos computacionales de los dialectos aprendan unos de otros. En este artículo construimos un modelo de segmentación unificado en el que se combinan los datos de entrenamiento para diferentes dialectos y se entrena un solo modelo. El modelo produce mayor precisión que los modelos específicos de dialectos, lo que elimina la necesidad de identificación de dialectos antes de la segmentación. También medimos el grado de relación entre cuatro dialectos árabes principales probando cómo funciona un modelo de segmentación entrenado en un dialecto en los otros dialectos. Descubrimos que la relación lingüística depende de la proximidad geográfica. En nuestros experimentos utilizamos clasificación basada en SVM y marcaje de secuencias bi-LSTM-CRF.', 'pt': 'Os dialetos árabes não compartilham apenas um koinë comum, mas há fenômenos linguísticos pan-dialetais compartilhados que permitem que modelos computacionais para dialetos aprendam uns com os outros. Neste artigo, construímos um modelo de segmentação unificado onde os dados de treinamento para diferentes dialetos são combinados e um único modelo é treinado. O modelo produz precisões mais altas do que os modelos específicos de dialeto, eliminando a necessidade de identificação de dialeto antes da segmentação. Também medimos o grau de parentesco entre os quatro principais dialetos árabes testando como um modelo de segmentação treinado em um dialeto funciona nos outros dialetos. Descobrimos que a relação linguística é contingente com a proximidade geográfica. Em nossos experimentos, usamos classificação baseada em SVM e rotulagem de sequência bi-LSTM-CRF.', 'ja': 'アラビア語の方言は単に共通のkoinëを共有するだけでなく、方言のための計算モデルが互いに学ぶことを可能にする共有された汎方言言語現象があります。本稿では、異なる方言のトレーニングデータを組み合わせ、単一のモデルをトレーニングする統一セグメンテーションモデルを構築する。このモデルは、方言固有のモデルよりも高い精度をもたらし、セグメンテーションの前に方言を識別する必要がなくなります。また、一方の方言でトレーニングされたセグメンテーションモデルが他方の方言でどのように機能するかをテストすることによって、4つの主要なアラビア方言間の関連性の程度を測定します。言語の関連性は地理的な近さに依存することを発見した。我々の実験では、ＳＶＭベースのランキング及びバイＬＳＴＭ － ＣＲＦ配列標識を使用する。', 'hi': 'अरबी बोलियां न केवल एक आम कोइन को साझा करती हैं, बल्कि साझा पैन-बोलचाल भाषाई घटनाएं हैं जो बोलियों के लिए कम्प्यूटेशनल मॉडल को एक-दूसरे से सीखने की अनुमति देती हैं। इस पेपर में हम एक एकीकृत विभाजन मॉडल का निर्माण करते हैं जहां विभिन्न बोलियों के लिए प्रशिक्षण डेटा संयुक्त होते हैं और एक एकल मॉडल को प्रशिक्षित किया जाता है। मॉडल बोली-विशिष्ट मॉडल की तुलना में उच्च सटीकता पैदा करता है, विभाजन से पहले बोली पहचान की आवश्यकता को समाप्त करता है। हम चार प्रमुख अरबी बोलियों के बीच संबंध की डिग्री को भी मापते हैं कि एक बोली पर प्रशिक्षित विभाजन मॉडल अन्य बोलियों पर कैसे प्रदर्शन करता है। हमने पाया कि भाषाई संबंध भौगोलिक निकटता के साथ आकस्मिक है। हमारे प्रयोगों में हम एसवीएम-आधारित रैंकिंग और द्वि-एलएसटीएम-सीआरएफ अनुक्रम लेबलिंग का उपयोग करते हैं।', 'ru': 'Арабские диалекты не просто имеют общую коину, но существуют общие пан-диалектные лингвистические явления, которые позволяют вычислительным моделям для диалектов учиться друг у друга. В этой статье мы строим унифицированную модель сегментации, где данные обучения для различных диалектов объединяются и обучается одна модель. Модель обеспечивает более высокую точность, чем модели, специфичные для диалекта, что устраняет необходимость идентификации диалекта перед сегментацией. Мы также измеряем степень взаимосвязи между четырьмя основными арабскими диалектами, проверяя, как модель сегментации, обученная на одном диалекте, действует на других диалектах. Мы обнаружили, что лингвистическая связь обусловлена географической близостью. В наших экспериментах мы используем ранжирование на основе виртуальной машины защиты и маркировку последовательности bi-LSTM-CRF.', 'zh': '阿拉伯语方言不惟共一同koinë,亦有共享泛方言语言之象,许方言计模相学。 于本文中,构一统之分模,合方言之数,而练一模形。 其形高于特定言,消于割割之前。 试于一言之中,量四体阿拉伯语方言之关联也。 见言语相关性在地理近性。 在我实验中,用SVM名双LSTM-CRF。', 'ga': 'Ní hamháin go bhfuil koinë comónta ag canúintí Arabacha, ach tá feiniméin chomhroinnte teangeolaíochta pan-chanúinteacha ann a ligeann do mhúnlaí ríomhaireachtúla na gcanúintí foghlaim óna chéile. Sa pháipéar seo tógaimid múnla deighilte aontaithe ina gcuirtear na sonraí oiliúna le haghaidh canúintí éagsúla le chéile agus ina gcuirtear oiliúint ar mhúnla amháin. Cruthaíonn an tsamhail beachtas níos airde ná samhlacha a bhaineann go sonrach le canúintí, rud a chuireann deireadh leis an ngá atá le sainaithint canúintí roimh dheighilt. Tomhaisimid chomh maith an gaol atá idir ceithre mhórchanúint Araibise trí thástáil a dhéanamh ar an gcaoi a bhfeidhmíonn samhail deighilte atá oilte ar chanúint amháin ar na canúintí eile. Fuaireamar amach go bhfuil gaolmhaireacht teanga ag brath ar ghaireacht thíreolaíoch. Inár dturgnaimh úsáidimid rangú bunaithe ar SVM agus lipéadú seicheamh dé-LSTM-CRF.', 'el': 'Οι αραβικές διαλέκτες δεν μοιράζονται μόνο ένα κοινό κοίν, αλλά υπάρχουν κοινά πανδιαλεκτικά γλωσσικά φαινόμενα που επιτρέπουν στα υπολογιστικά μοντέλα των διαλέκτων να μάθουν ο ένας από τον άλλο. Σε αυτή την εργασία χτίζουμε ένα ενοποιημένο μοντέλο τμηματοποίησης όπου τα δεδομένα εκπαίδευσης για διαφορετικές διαλέκτες συνδυάζονται και εκπαιδεύεται ένα μόνο μοντέλο. Το μοντέλο αποδίδει υψηλότερες ακρίβειες από τα ειδικά μοντέλα διαλέκτου, εξαλείφοντας την ανάγκη αναγνώρισης διαλέκτου πριν από την τμηματοποίηση. Επίσης, μετράμε το βαθμό συσχέτισης μεταξύ τεσσάρων μεγάλων αραβικών διαλέκτων δοκιμάζοντας πώς ένα μοντέλο τμηματοποίησης εκπαιδευμένο σε μια διάλεκτο αποδίδει στις άλλες διαλέκτες. Διαπιστώσαμε ότι η γλωσσική συγγένεια εξαρτάται από τη γεωγραφική εγγύτητα. Στα πειράματά μας χρησιμοποιούμε ταξινόμηση βασισμένη σε SVM και σήμανση ακολουθίας bi-LSTM-CRF.', 'hu': 'Az arab dialektusok nem csak közös koine, hanem vannak közös pándialektális nyelvi jelenségek, amelyek lehetővé teszik, hogy a dialektusok számítástechnikai modellei tanuljanak egymástól. Ebben a tanulmányban egy egységes szegmentációs modellt építünk, ahol a különböző dialektusok képzési adatait kombináljuk és egyetlen modell képzésre kerül. A modell nagyobb pontosságot eredményez, mint a dialektus-specifikus modellek, így nincs szükség a dialektus azonosítására a szegmentáció előtt. Mérjük a négy fő arab dialektus közötti kapcsolattartás mértékét azáltal, hogy teszteljük, hogy egy szegmentációs modell hogyan teljesít az egyik dialektusra képzett másik dialektusban. Megállapítottuk, hogy a nyelvi kapcsolat függ a földrajzi közelséggel. Kísérleteinkben SVM alapú rangsorolást és bi-LSTM-CRF szekvencia címkézést használunk.', 'ka': 'არაბული დიალეკტები არა მხოლოდ საერთო კოინს გაყოფილი, მაგრამ არსებობს საერთო დიალექტალური ენალექტიკური ფენომენები, რომლებიც კომპუტაციალური მოდელები დიალეკტების განმა ამ დომენტში ჩვენ შევქმნით ერთადერთი სეგმენტაციის მოდელი, სადაც განსხვავებული დიალეკტებისთვის მონაცემები კომბიზიან და ერთადერთი მოდელი განსწავლია. მოდელი უფრო დიალექტიკური მოდელზე უფრო დიალექტიკური მოდელეებისთვის, რომელიც დიალექტიკური იდენტიფიკაციის უნდა წაშლა, სექმენტიკური მოდელ ჩვენ ასევე განზომილებით 4 დიალექტის მეტი არაბული დიალექტის განზომილების დონე, როგორ სექმენტირებული მოდელი ერთი დიალექტის განზომილებაში ექნება. ჩვენ აღმოჩნეთ, რომ ლენგოგური შესახებ გეგოგური დაბრუნებისთვის შესახებ. ჩვენი ექსპერიმენტებში ჩვენ გამოყენებთ SVM-based ranking და bi-LSTM-CRF-sequence labelling.', 'kk': 'Араб диалекттері тек жалпы койнды бөліскен емес, бірақ бөліскен пан диалекталық лингвистикалық панелдері бар, бұл диалекттердің компьютерлік моделдері бір-бірінен үйренуге мүмкіндік береді. Бұл қағазда біріктірілген сегментация үлгісін құрамыз. Бірнеше диалекттердің оқыту деректері біріктірілген және бір үлгісі оқылған. Бұл үлгі диалекттің ерекше үлгілерінен артық дұрыстығын өзгертеді. Сегментацияның алдында диалекттің идентификациясын өшіру қажет. Біз сондай-ақ төрт негізгі араб диалекттерінің арасындағы сәйкестік деңгейін бір диалект үлгісін тексеріп, бір диалект үлгісін қалай жұмыс істейді. Біз лингвистикалық қатынас географиялық жақындағы қатынас бар деп ойладық. Сіздің тәжірибемдерімізде SVM негіздеген жолдарды және bi-LSTM-CRF ретінің жарлығын қолданамыз.', 'lt': 'Arabų dialektai ne tik dalijasi bendrais koinais, bet ir yra bendrų dialektinių kalbinių reiškinių, leidžiančių dialektų skaičiavimo modeliams pasimokyti vienas iš kito. Šiame dokumente sukuriame vieningą segmentacijos model į, kuriame derinami skirtingų dialektų mokymo duomenys ir mokomas vienas model is. Modeliu gaunamas didesnis tikslumas nei dialektui būdingi modeliai, pašalinant dialekto identifikavimo poreikį prieš segmentavimą. Taip pat matuojame ryšio tarp keturių pagrindinių arabų dialektų laipsnį bandydami, kaip viename dialekte parengtas segmentacijos modelis veikia kituose dialektuose. Nustatėme, kad kalbinis ryšys priklauso nuo geografinio artumo. Mūsų eksperimentuose naudojame SVM pagrįstą klasifikavimą ir dviejų LSTM-CRF sekos ženklinimą.', 'mk': 'Арапските дијалекти не само што споделуваат заеднички коин, туку постојат заеднички пандијалектални јазички феномени кои овозможуваат компјутативните модели за дијалектите да учат еден од друг. Во овој документ градиме унифициран модел на сегментација каде што податоците за обука за различни дијалекти се комбинирани и еден модел е обучен. Моделот дава поголеми точности од моделите специфични за дијалект, елиминирајќи ја потребата за идентификација на дијалектот пред сегментацијата. Исто така го мериме степенот на поврзаност помеѓу четирите големи арапски дијалекти со тестирање на тоа како сегментацискиот модел обучен на еден дијалект функционира на другите дијалекти. We found that linguistic relatedness is contingent with geographical proximity.  Во нашите експерименти користиме рангирање базирано на СВМ и биЛСТМ-КрФ секвенциска етикета.', 'ms': 'Dialekt Arab tidak hanya berkongsi koine umum, tetapi terdapat fenomena bahasa pan-dialektal berkongsi yang membolehkan model komputasi untuk dialekt belajar dari satu sama lain. Dalam kertas ini kami membina model segmen bersatu dimana data latihan untuk dialekt berbeza digabung dan satu model dilatih. Model memberikan ketepatan yang lebih tinggi daripada model khusus-dialekt, menghapuskan keperluan pengenalan dialekt sebelum segmen. Kami juga mengukur darjah hubungan antara empat dialekt Arab utama dengan menguji bagaimana model segmen dilatih pada satu dialekt melaksanakan pada dialekt yang lain. We found that linguistic relatedness is contingent with geographical proximity.  Dalam eksperimen kami kami menggunakan penataran berdasarkan SVM dan label urutan bi-LSTM-CRF.', 'mn': 'Араб диалектууд зөвхөн ерөнхий коиныг хуваалцахгүй, гэхдээ хэл хэлний диалектикийн үзэгдэл нь тооцоололтын загварууд бие биенээс суралцах боломжтой болдог. Энэ цаасан дээр бид өөр диалектуудын сургалтын өгөгдлийг нийлүүлж, нэг загвар сургалтын нэгтгэл загвар бүтээж байна. Загвар нь диалектын тодорхой загвараас илүү өндөр тодорхойлолт өгч, загварын өмнө диалектын тодорхойлолтын хэрэгцээг устгах болно. Мөн бид 4 том Араб диалектын хоорондын харилцааны хэмжээг хэмжээгээр нэг диалект дээр хэрхэн сургалтын загварын загварыг шалгаж байна. Бид хэл хэлний холбоотой байдал газрын ойролцоогоор хамааралтай гэдгийг олж мэдсэн. Бидний туршилтуудад бид SVM-ийн үндсэн цэг, хоёр-LSTM-CRF дарааллын маркинг ашигладаг.', 'mt': 'Arabic dialects do not just share a common koine, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other.  F’dan id-dokument nibnu mudell ta’ segmentazzjoni unifikat fejn id-dejta tat-taħriġ għal dijaletti differenti tiġi kkombinata u jiġi mħarreġ mudell wieħed. Il-mudell jagħti preċiżjonijiet ogħla minn mudelli speċifiċi għad-dijalekt, u jelimina l-ħtieġa għall-identifikazzjoni tad-dijalekt qabel is-segmentazzjoni. Nikejlu wkoll il-grad ta’ rabta bejn erba’ dijaletti Għarab maġġuri billi nistestjaw kif mudell ta’ segmentazzjoni mħarreġ fuq dijaletti waħda jwettaq fuq id-dijaletti l-oħra. Instabna li r-relazzjoni lingwistika hija kontinġenti mal-prossimità ġeografika. Fl-esperimenti tagħna nużaw klassifikazzjoni bbażata fuq SVM u tikkettar tas-sekwenza bi-LSTM-CRF.', 'ml': 'അറബിക്ക് ഭാഷണങ്ങള്\u200d ഒരു സാധാരണ കോയിന്\u200d മാത്രമല്ല പങ്കുചേര്\u200dക്കുന്നത്, പക്ഷെ പങ്കുചേര്\u200dക്കുന്ന പാന്\u200d ഡയലക്ട്രിക്കല്\u200d ഭാഷകങ്ങളുടെ സ്വ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഒരു യൂണിക്കപ്പെട്ട സെഗ്മെന്റേഷന്\u200d മോഡല്\u200d ഉണ്ടാക്കുന്നു. വ്യത്യസ്ത ഡയലക്ടറുകള്\u200dക്കുള്ള പരിശീലന പ്രത്യേകിച്ച മോഡലുകളെക്കാള്\u200d ഉയര്\u200dത്തുന്ന മാതൃകങ്ങള്\u200d മാത്രം മോഡലിന്റെ തിരിച്ചറിയാനുള്ള ആവശ്യം നീക്കം ചെയ് നാല് പ്രധാനപ്പെട്ട അറബി ഡയലക്ടറുകള്\u200dക്കിടയിലുള്ള ബന്ധങ്ങളുടെ ഡിഗ്രി നമ്മള്\u200d അളന്നുകൊടുക്കുന്നു. ഒരു ഡയലക്ട്രിക്കിന്\u200dറെ  ഭാഷകക്കാരുടെ ബന്ധം ഭൂഗ്രാഫിക സമീപത്തില്\u200d ബന്ധമാണെന്ന് ഞങ്ങള്\u200d കണ്ടെത്തി. നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d ഞങ്ങള്\u200d SVM-അടിസ്ഥാനമായ റെഞ്ചിങ്ങും ബി-LSTM-CRF സെക്കന്\u200dസ് ലേബിള്\u200d ഉപയോഗിക്കുന്നു.', 'it': "I dialetti arabi non solo condividono una koine comune, ma esistono fenomeni linguistici pan-dialettali condivisi che consentono ai dialetti di imparare l'uno dall'altro modelli computazionali. In questo articolo costruiamo un modello unificato di segmentazione in cui i dati di allenamento per i diversi dialetti sono combinati e un unico modello è formato. Il modello produce precisione più elevate rispetto ai modelli dialettali specifici, eliminando la necessità di identificazione dialettale prima della segmentazione. Misuriamo anche il grado di relazione tra quattro grandi dialetti arabi testando come un modello di segmentazione addestrato su un dialetto si comporta sugli altri dialetti. Abbiamo scoperto che la relazione linguistica è condizionata dalla vicinanza geografica. Nei nostri esperimenti utilizziamo il ranking basato su SVM e l'etichettatura di sequenza bi-LSTM-CRF.", 'pl': 'Dialekty arabskie nie mają tylko wspólnego koine, ale istnieją wspólne panedialektalne zjawiska językowe, które pozwalają na uczenie się od siebie modeli obliczeniowych dialektów. W niniejszym artykule budujemy ujednolicony model segmentacji, w którym dane treningowe dla różnych dialektów są łączone i trenowane jest jeden model. Model daje większą dokładność niż modele specyficzne dla dialektu, eliminując potrzebę identyfikacji dialektu przed segmentacją. Mierzymy również stopień powiązania między czterema głównymi dialektami arabskimi, testując, jak model segmentacji trenowany na jednym dialektze działa na innych dialektach. Odkryliśmy, że związek językowy zależy od bliskości geograficznej. W naszych eksperymentach używamy rankingu opartego na SVM oraz znakowania sekwencji bi-LSTM-CRF.', 'no': 'Arabiske dialektar deler ikkje berre ei felles koine, men det er delt pan-dialektiske språk som tillater datamaskinemodeller for dialektar å lære frå kvarandre. I denne papiret bygger vi ein eine segmentasjonsmodul der opplæringsdata for ulike dialektar er kombinerte og ein enkel modell er trent. Modellen gjev høgare nøyaktighet enn dialektspesifikke modeller, og eliminerer nødvendighet for dialektidentifikasjon før segmentasjon. Vi måler også avhengighet mellom fire store arabiske dialektar ved å teste korleis ein segmentasjonsmodul treng på ein dialekt utfører på dei andre dialektane. Vi fann at lingviske relateten er avhengig med geografiske nærmingar. I våre eksperimenter bruker vi SVM-basert ranking og bi-LSTM-CRF-sekvensetiketting.', 'sr': 'Arapske dijalekte ne dijele samo zajednički koin, već postoje zajednički pan-dijalektski jezički fenomeni koji omogućavaju računalne modele za dijalekte da uče jedni od drugih. U ovom papiru izgradimo ujedinjeni model segmentacije gde su podaci obuke za različite dijalekte kombinirani i trenirani su jedan model. Model daje veće preciznosti od modela specifičnih dijalekata, eliminišući potrebu za identifikacijom dijalekata prije segmentacije. Takođe mjerimo stepenicu odnosa između četiri glavne arapske dijalekte testiranjem kako model segmentacije obučen na jednom dijalektu izvodi na drugim dijalektima. Pronašli smo da je jezička veza povezana sa geografskim blizinom. U našim eksperimentima koristimo označavanje rasporeda na SVM-baziranom i etiketiranje bi-LSTM-CRF sekvence.', 'so': 'Afka Carabiyadu ma qeybeeyaan oo kaliya koin caadi ah, laakiin waxaa jira wax la mid ah oo luuqadaha ku qoran afka pan-dialect, taasoo u sawiraa qaabab xisaab ah oo isbarta midba midka kale. Qoraalkan waxaan ku dhisaynaa model kooxaha kala duwan, meesha lagu baro macluumaadka waxbarashada ee luuqadaha kala duduwan iyo qaab keliya lagu baro. Tusaalada waxaa ka soo baxa saxda sare oo ka sii saxda tilmaamaha cayiman, wuxuuna dhameeyaa baahida aqoonsiga sawir ka hor inta aan la qeybin. Sidoo kale waxaynu qiyaasaynaa shahaadada xiriirka afarta afka ugu weyn ee Carabiga, si aan u imtixaano sidoo kale qaababka lagu baray mid af ka mid ah oo ku qoran xarafka kale. Waxaynu ogaanay in xiriirka luuqadda la xiriiro ay ku dhow tahay geographical. Imtixaanadeena waxaynu isticmaalnaa imtixaanka ku saleysan SVM iyo imtixaanka ku qoran BLSTM-CRF.', 'sv': 'Arabiska dialekter delar inte bara en gemensam koine, utan det finns gemensamma pan-dialektiska språkliga fenomen som tillåter beräkningsmodeller för dialekter att lära av varandra. I denna uppsats bygger vi en enhetlig segmenteringsmodell där träningsdata för olika dialekter kombineras och en enda modell tränas. Modellen ger högre noggrannhet än dialektsspecifika modeller, vilket eliminerar behovet av dialektidentifiering före segmentering. Vi mäter också graden av samband mellan fyra stora arabiska dialekter genom att testa hur en segmenteringsmodell tränad på en dialekt presterar på de andra dialekterna. Vi fann att språklig anknytning är beroende av geografisk närhet. I våra experiment använder vi SVM-baserad ranking och bi-LSTM-CRF sekvensmärkning.', 'ro': 'Dialectele arabe nu doar împărtășesc o koine comună, dar există fenomene lingvistice pan-dialectale comune care permit modelelor computaționale pentru dialecte să învețe unul de la celălalt. În această lucrare construim un model unificat de segmentare în care datele de formare pentru diferite dialecte sunt combinate și un singur model este instruit. Modelul oferă precizii mai mari decât modelele specifice dialectelor, eliminând necesitatea identificării dialectelor înainte de segmentare. De asemenea, măsurăm gradul de relație între patru dialecte arabe majore prin testarea modului în care un model de segmentare instruit pe un dialect performează pe celelalte dialecte. Am descoperit că relația lingvistică este condiționată de proximitatea geografică. În experimentele noastre folosim clasificarea bazată pe SVM și etichetarea secvenței bi-LSTM-CRF.', 'si': 'අරාබික් ඩායාලෙක්ට්ස් සාමාන්\u200dය කෝයින් එක්කෙන් ඉගෙනගන්න පැන් ඩායාලෙක්ටල් භාෂාවික ප්\u200dරදේශයක් නෙවෙයි. මේ පත්තරේ අපි එක්ක සැකස්මක් මොඩල් හදන්නේ කියලා වෙනස් ඩායිලක්ට් වලට පුහුණු දත්ත සම්බන්ධ කරලා තියෙන් මොඩේල් විශේෂ විශේෂ විශේෂ විදියට වඩා විශේෂ විශේෂ විදියට වඩා විශේෂ විදියට අවශ්\u200dයය නැති  අපි පරීක්ෂණය කරන්නේ ප්\u200dරධාන අරාබි දායිලෙක්ට් 4ක් අතර සම්බන්ධතාවක් අතර සම්බන්ධතාවක් අතර සම්බන්ධතාවක් ප්\u200dරධානය අපිට හොයාගත්තා කියලා භාෂාවික සම්බන්ධතාවක් සිද්ධ වෙන්න පුළුවන්. අපේ පරීක්ෂණයේ අපි SVM-ආධාරිත පරීක්ෂණය සහ Bi-LSTM-CRF පරීක්ෂණය ලේබිල් කරන්න පාවිච්චි කරනවා.', 'ta': 'அரபி விளக்கங்கள் ஒரு பொதுவான கோன் மட்டும் பகிர்ந்து கொள்ளவில்லை, ஆனால் பங்கிடப்பட்ட பான்-டையல் மொழிமொழிகள் பொருள் இருக்கிறது, இது ஒருவர்  இந்த காகிதத்தில் நாம் ஒரு ஒன்றிணைக்கப்பட்ட துண்டு மாதிரி உருவாக்குகிறோம் அதில் வேறு வரிசைகளுக்கான பயிற்சி தகவல் ஒன இந்த மாதிரி துண்டு பிரிப்பு முன் வரையறையின் தேவையை விட அதிக சரிவுகளை கொடுக்கும். நாம் நான்கு முக்கிய அரபி விளக்கங்களுக்கிடையே தொடர்புடைய degree அளவை சரிபார்ப்போம் ஒரு துண்டு மாதிரி மற்றொரு விளக்கச்சீட்டில்  நாங்கள் கண்டுபிடித்தோம் மொழியில் தொடர்புகள் பூமியியல் நெருங்கியிருக்கும். எங்கள் சோதனைகளில் நாம் SVM-அடிப்படையில் வரிசையை பயன்படுத்துகிறோம் மற்றும் பி-LSTM-CRF தொடர்ந்து சிட்டியை பயன', 'ur': 'عربی دیالکت صرف ایک مشترک کوئن کے ساتھ شریک نہیں ہیں لیکن ان میں ایک دوسرے سے سیکھنے کے لئے کامپیوتر کی نمونڈل ہیں۔ اس کاغذ میں ہم ایک متحدہ سیگنٹ موڈل بناتے ہیں جہاں مختلف ڈیلکتوں کے لئے ترینس ڈیٹے جمع کئے جاتے ہیں اور ایک موڈل ترینس کئے جاتے ہیں. موڈل ڈائیلکسٹ کے مطابق موڈل سے زیادہ مطابق اچھی دقیق حاصل کرتا ہے، جہاں سے پہلے ڈائیلکسٹ شناسیٹ کی ضرورت ہٹاتی ہے. ہم نے بھی چار بڑے عربی دیالکتوں کے درمیان رابطہ کے درجے کا اندازہ اندازہ کیا ہے کہ ایک دیالکت پر تعلیم کیا گیا ہے اور دوسرے دیالکتوں پر چلتا ہے ہم نے پایا کہ زبان کی تعلق جغرافی قریبی سے مشکل ہے۔ ہمارے آزمائش میں ہم SVM بنیاد رینگ اور دوسری LSTM-CRF رینگ لیبلینگ استعمال کرتے ہیں.', 'uz': "Арабча dialeklar faqat umumiy koine bilan bog'liq emas, balki pan-dialektikal tillarini birлари bilan o'rganishga ruxsat beradi. Bu hujjatda biz birlashtirilgan segmentning modelini yaramiz, bu yerda boshqa dialeklar uchun taʼminlovchi maʼlumot birlashtirilgan va bitta model o'rganadi. Name Biz esa to'rtta asosiy arab dialeklarga bog'liqning darajasini o'ylaymiz va bir dialeklarga o'rganish modeli boshqa dialeklarga qanday ishlashini o'rganamiz. Biz o'rganishni anglatdikki, tillar munosabati geografisk taqdimligi bilan bog'liq. Bizning tajribalarimizda SVM asosida saqlash va Bi-LSTM-CRF seksiyati imkoniyatlaridan foydalanamiz.", 'vi': 'Tiếng địa phương Ả Rập không chỉ chia sẻ một phần Koine phổ biến, mà còn có các hiện tượng ngôn ngữ chung, để cho phép các phương ngữ học hỏi từ nhau. Trong tờ giấy này chúng ta xây dựng một mô hình phân chia thống nhất nơi kết hợp dữ liệu đào tạo phương ngữ khác nhau và một mô hình duy nhất được đào tạo. Mô hình này mang lại độ chính xác cao hơn các mô hình đặc biệt với ngôn ngữ, loại trừ nhu cầu nhận diện ngôn ngữ trước khi phân chia. Chúng ta cũng đo được mức độ liên quan giữa bốn phương ngữ Á Rập lớn bằng cách thử nghiệm cách mô hình phân chia được rèn luyện trên một phương ngữ tiến hành trên các phương ngữ khác. Chúng tôi thấy quan hệ ngôn ngữ phụ thuộc vào khoảng cách địa lý. Trong các thí nghiệm, chúng tôi dùng nhãn hiệu phân loại giống SVM và I-LSTM-CRF.', 'bg': 'Арабските диалекти не само споделят общ коин, но съществуват общи пандиалектални лингвистични явления, които позволяват изчислителните модели на диалектите да се учат един от друг. В настоящата статия се изгражда унифициран модел на сегментация, при който се комбинират данните за обучение за различни диалекти и се обучава един модел. Моделът дава по-висока точност от диалектно-специфичните модели, елиминирайки необходимостта от идентификация на диалекта преди сегментацията. Също така измерваме степента на свързаност между четири основни арабски диалекта, като тестваме как моделът на сегментация, обучен на един диалект, се представя на другите диалекти. Установихме, че лингвистичната връзка зависи от географската близост. В нашите експерименти използваме базирано класиране и обозначаване на последователността.', 'nl': 'Arabische dialecten delen niet alleen een gemeenschappelijke koine, maar er zijn gedeelde pan-dialectische linguïstische fenomenen die rekenmodellen voor dialecten toelaten om van elkaar te leren. In dit artikel bouwen we een uniform segmentatiemodel waarbij de trainingsgegevens voor verschillende dialecten worden gecombineerd en een enkel model wordt getraind. Het model levert hogere nauwkeurigheiden op dan dialectspecifieke modellen, waardoor dialectidentificatie vóór segmentatie overbodig is. We meten ook de mate van verwantschap tussen vier grote Arabische dialecten door te testen hoe een segmentatiemodel getraind op het ene dialect presteert op de andere dialecten. We ontdekten dat taalverwantschap afhankelijk is van geografische nabijheid. In onze experimenten gebruiken we SVM-based ranking en bi-LSTM-CRF sequence labeling.', 'hr': 'Arapske dijalekte ne dijele samo zajednički koin, već postoje zajednički pan-dijalektski jezički fenomeni koji omogućavaju računalne modele za dijalekte učiti jedni od drugih. U ovom papiru izgradimo ujedinjeni model segmentacije gdje se kombiniraju podaci obuke za različite dijalekte i trenira se jedan model. Model daje veće preciznosti od specifičnih modela dijalekta, eliminirajući potrebu za identifikacijom dijalekta prije segmentacije. Također mjerimo stepenicu odnosa između četiri glavne arapske dijalekte testiranjem kako se model segmentacije obučen na jednom dijalektu izvršava na drugim dijalektima. Pronašli smo da je jezička veza povezana s geografskim blizinom. U našim eksperimentima koristimo označavanje rasporeda na SVM-u i označavanje bi-LSTM-CRF sekvence.', 'da': 'Arabiske dialekter deler ikke bare en fælles koine, men der er fælles pan-dialektiske sproglige fænomener, der tillader beregningsmodeller for dialekter at lære af hinanden. I denne artikel opbygger vi en samlet segmenteringsmodel, hvor træningsdata for forskellige dialekter kombineres og en enkelt model trænes. Modellen giver højere nøjagtigheder end dialektsspecifikke modeller, hvilket eliminerer behovet for dialektidentifikation før segmentering. Vi måler også graden af relaterethed mellem fire store arabiske dialekter ved at teste, hvordan en segmenteringsmodel trænet på en dialekt fungerer på de andre dialekter. Vi fandt ud af, at sproglig sammenhæng er betinget af geografisk nærhed. I vores eksperimenter bruger vi SVM-baseret ranking og bi-LSTM-CRF sekvensmærkning.', 'de': 'Arabische Dialekte teilen nicht nur eine gemeinsame Koine, sondern es gibt gemeinsame pan-dialektale linguistische Phänomene, die es ermöglichen, computergestützte Modelle für Dialekte voneinander zu lernen. In diesem Beitrag erstellen wir ein einheitliches Segmentierungsmodell, bei dem die Trainingsdaten für verschiedene Dialekte kombiniert und ein einziges Modell trainiert wird. Das Modell liefert höhere Genauigkeiten als dialektspezifische Modelle, wodurch die Notwendigkeit einer Dialektidentifikation vor der Segmentierung entfällt. Wir messen auch den Grad der Verwandtschaft zwischen vier großen arabischen Dialekten, indem wir testen, wie ein Segmentierungsmodell, das auf einem Dialekt trainiert wurde, auf den anderen Dialekten funktioniert. Wir fanden heraus, dass sprachliche Verwandtschaft mit geografischer Nähe bedingt ist. In unseren Experimenten verwenden wir SVM-basiertes Ranking und bi-LSTM-CRF Sequenzmarkierung.', 'id': 'Dialekt Arab tidak hanya berbagi koine umum, tetapi ada fenomena bahasa pan-dialektal yang berbagi yang memungkinkan model komputasi untuk dialekt belajar dari satu sama lain. Dalam kertas ini kami membangun model segmentasi bersatu di mana data latihan untuk dialekt berbeda digabung dan model tunggal dilatih. Model memberikan akurasi yang lebih tinggi dari model spesifik dialekt, menghapuskan kebutuhan untuk identifikasi dialekt sebelum segmen. Kami juga mengukur tingkat hubungan antara empat dialekt utama Arab dengan menguji bagaimana model segmen dilatih pada satu dialekt melaksanakan pada dialekt lain. Kami menemukan bahwa hubungan bahasa tergantung dengan kedekatan geografi. Dalam eksperimen kami kami menggunakan rangkaian berdasarkan SVM dan label urutan bi-LSTM-CRF.', 'ko': '아랍 방언은 공통된 코인어뿐만 아니라 공통된 범방언 언어 현상도 있어 방언의 계산 모델을 서로 배울 수 있다.본고에서 우리는 통일된 절분 모델을 구축하여 서로 다른 사투리의 훈련 데이터를 결합시켜 단일한 모델을 훈련한다.특정 사투리 모델에 비해 정확도가 높기 때문에 분할하기 전에 사투리 식별을 할 필요가 없다.우리는 또 한 가지 사투리에서 훈련된 절분모델이 다른 사투리에서의 표현을 시험하여 네 가지 주요 아랍어 사투리 간의 관련 정도를 평가한다.우리는 언어의 연관성이 지리적 인접성에 달려 있다는 것을 발견했다.실험에서 SVM 기반 정렬 및 bi-LSTM CRF 시퀀스 태그를 사용했습니다.', 'sw': 'Arabic dialects do not just share a common koine, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other.  Katika gazeti hili tunajenga muundo wa ushirikiano ambao taarifa za mafunzo kwa lugha tofauti zinaunganishwa na modeli moja inafundishwa. Mfano huu unatoa ukweli wa juu kuliko mifano maalum ya dialect, kuondoa haja ya kutambua utambulisho kabla ya kujitenga. Kadhalika tunapima kiwango cha mahusiano kati ya lugha nne kubwa za Kiarabu kwa kujaribu jinsi modeli ya kutenganisha kwa lugha moja inavyofanya katika lugha nyingine. Tumegundua kuwa uhusiano wa lugha unahusiana na ukaribu wa kijiografia. Katika majaribio yetu tunatumia michoro yenye msingi wa SVM na michoro ya mfululizo wa LSTM-CRF.', 'tr': 'Arapça dialektler diňe orta koýny paýlaşmaýarlar, ýöne bir-birinden öwrenmäge rugsat beren pan-dialektal lingwistiki parçalar bar. Biz bu kagyzda farklı dialektler üçin okuw maglumaty birleştirilýän bir segmentasyň modelini inşa edýäris we ýeke bir nusga okuw edilýäris. Bu nusga dialektiň takyk nusgalaryndan has ýokaryny çykar, segmentasiýanyň öňünde dialektiň kimligini çykar. Biz hem 4 esasy arap dialektalaryň arasynda segmentasiýa nusgasyny bir dialektde nähili edip barýandygyny barlap çözýäris. Biz dil baglanyşygy geografiki ýakynlaşdyr. Biziň deneylerimizde SVM daýanýan depler we bi-LSTM-CRF sanlaryny etiketlemek üçin ullanýarys.', 'sq': 'Arabic dialects do not just share a common koine, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other.  In this paper we build a unified segmentation model where the training data for different dialects are combined and a single model is trained.  Modeli jep saktësi më të larta se modelet specifike për dialekt, duke eleminuar nevojën për identifikimin e dialektit përpara segmentimit. Ne masojmë gjithashtu gradën e lidhjes midis katër dialekteve të mëdha arabe duke testuar se si një model segmentimi i trajnuar në një dialekt funksionon në dialektet e tjera. Gjetëm se lidhjet gjuhësore janë të varura me afërsinë gjeografike. Në eksperimentet tona ne përdorim renditjen bazuar në SVM dhe etiketën e sekuencës bi-LSTM-CRF.', 'af': "Arabiese dialekte deel nie net 'n gemeenskaplike koin nie, maar daar is gedeelde pan-dialektaal lingwisiese fenomene wat rekenaarse modele toelaat vir dialekte om van mekaar te leer. In hierdie papier bou ons 'n eenvoudige segmentasie model waar die onderwerp data vir verskillende dialekte is gekombineer en 'n enkele model is onderwerp. Die model gee hoëre presies as dialekte-spesifieke modele, verwyder die behoefte vir dialekte identifikasie voor segmentasie. Ons maat ook die grad van verwantigheid tussen vier groot arabese dialekte deur te teste hoe 'n segmentasie model op een dialekte opgelei is op die ander dialekte uitvoer. Ons het gevind dat lingwisiese verwantigheid met geografiese nabytigheid is. In ons eksperimente gebruik ons SVM-gebaseerde ranking en bi-LSTM-CRF-sekvens etiketting.", 'fa': 'دیالکت عربی تنها یک کوئین مشترک را شریک نمی\u200cکنند، بلکه نشانه\u200cهای ژانویی ژانویی مشترک هستند که اجازه می\u200cدهند مدل\u200cهای محاسباتی برای دیالکت\u200cها از همدیگر یاد بگیرند. در این کاغذ ما یک مدل جدایی متحد ساخته می\u200cکنیم که داده\u200cهای آموزش برای دیالکت\u200cهای متفاوت ترکیب می\u200cشوند و یک مدل تک آموزش می\u200cشود. این مدل دقیقات بالاتر از مدل\u200cهای مخصوص دیالکت را می\u200cدهد، که نیاز برای شناسایی دیالکت قبل از جدایی حذف می\u200cکند. ما همچنین درجه رابطه بین چهار دیالکت بزرگ عربی را اندازه می\u200cگیریم با امتحان کردن چگونه یک مدل جدایی که روی یک دیالکت آموزش داده می\u200cشود روی دیگر دیالکت انجام می\u200cدهد. ما پیدا کردیم که ارتباط زبان\u200cشناسی با نزدیکترین جغرافیایی است. در آزمایشات ما از نقاشی\u200cهای مرتبط به SVM و نقاشی\u200cهای دوگانه LSTM-CRF استفاده می\u200cکنیم.', 'am': 'አረቢያ ቋንቋዎች የተሰበሰቡ ኮইন ብቻ አይደሉም ነገር ግን እርስ በርሳቸው የሚማሩ የቁጥጥር ሞዴላዎችን ለመማር የሚፈቅዱ ናቸው፡፡ In this paper we build a unified segmentation model where the training data for different dialects are combined and a single model is trained.  The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation.  በአራቱ ታላላቆች አረቢያ ቋንቋዎች መካከል የግንኙነት ግንኙነት እናስቀምጣለን፡፡ የቋንቋው ግንኙነት የgeographical ቅርብ መሆኑን አግኝተናል፡፡ በሞከራችንን SVM-based ደረጃዎችን እና በ-LSTM-CRF-sequence ማተሚያ እናስቀምጣለን፡፡', 'hy': 'Arabic dialects do not just share a common koine, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other.  Այս թղթի մեջ մենք կառուցում ենք միավորված սեգմետրացիայի մոդել, որտեղ տարբեր դիալեկտների ուսուցման տվյալները միավորվում են և մեկ մոդել ուսուցվում է: Մոդելը ավելի ճշգրիտ է, քան դիալեկտի կոնկրետ մոդելները, վերացնելով անհրաժեշտությունը դիալեկտի հայտնաբերելու համար մինչև սեգմետրացիան: Մենք նաև չափում ենք կապը չորս կարևոր արաբական դիալեկտների միջև՝ ստուգելով, թե ինչպես է մեկ դիալեկտի վրա վարժեցված սեգմետրացիայի մոդելը գործում մյուս դիալեկտների վրա: Մենք հայտնաբերեցինք, որ լեզվաբանական կապը կախված է գերագրական մոտավորության հետ: Մեր փորձարկումների ընթացքում մենք օգտագործում ենք ՁԻԱՄ-ի հիմնված դասակարգման և երկու-ԼՍՏՄ-ԿՌՖ հաջորդականության պիտակ:', 'az': 'Arapça dialektlər yalnızca ortaq bir koin paylaşırlar, lakin bir-birindən öyrənməyə imkan verirlər. Bu kağızda, müxtəlif dialektlər üçün təhsil məlumatları birləşdirilmiş bir segmentasiya modeli inşa edirik və bir modeli təhsil edilir. Model dijalektə məxluqatından daha yüksək nöqtələri təşkil edir, segmentasiyasından əvvəl dialekt kimliğinin ehtiyacını silər. Biz də dörd böyük ərəb dialektlərinin arasındakı bağlılıq dərəcəsini ölçürük, digər dialektlərdə təhsil edilən segmentasiya modeli necə edər. Biz dil bağlılığı ģeogrāfiski yaxınlıqla bağlıdır. Bizim təcrübələrimizdə SVM tabanlı sıralama və bi-LSTM-CRF sıralama etiketlərini istifadə edirik.', 'bn': 'আরবী ভাষাগুলো শুধুমাত্র সাধারণ কোইন শেয়ার করে না, কিন্তু প্যান-ডায়ালেক্টিক ভাষায় ভাষায় শেয়ার করা হয়েছে যারা একে অপরের কাছ থেকে শিখতে  এই কাগজটিতে আমরা একটি একত্রিত বৈশিষ্ট্য মডেল তৈরি করি যেখানে বিভিন্ন ডায়ালেক্টরের জন্য প্রশিক্ষণের তথ্য একত্রিত হয় এবং  মডেলটি বৈশিষ্ট্য মডেলের চেয়ে বেশী সঠিকভাবে উৎপাদন করে, বিভিন্ন সংখ্যার পূর্বে ডায়ালেক্টের পরিচিতির প্রয়োজনীয় এছাড়াও আমরা চারটি প্রধান আরবী ভাষার মধ্যে যুক্তির পরিমাপ পরীক্ষা করি যে কিভাবে একটি বিভিন্ন ডায়ালেক্টরে প্রশিক্ষিত একটি মডেল কিভ আমরা পেয়েছি যে ভাষার সম্পর্ক ভূমিকার ক্ষেত্রে যুক্ত। আমাদের পরীক্ষায় আমরা এসভিএম ভিত্তিক র\u200d্যাঙ্কিং এবং বি-এলস্টিএম-CRF সেকেন্স ল্যাবেল ব্যবহার করি।', 'bs': 'Arapski dijalekti ne samo dijele zajednički koin, već postoje zajednički pan-dijalektski jezički fenomeni koji omogućavaju računalne modele za dijalekte da uče jedni od drugih. U ovom papiru izgradimo ujedinjeni model segmentacije gdje su podaci obuke za različite dijalekte kombinirani i trenirani su jedan model. Model daje veće preciznosti od modela specifičnih dijalekata, eliminirajući potrebu za identifikacijom dijalekata prije segmentacije. Također mjerimo stepenicu odnosa između četiri glavne arapske dijalekte testiranjem kako model segmentacije obučen na jednom dijalektu izvodi na drugim dijalektima. Pronašli smo da je jezička veza povezana sa geografskim blizinom. U našim eksperimentima koristimo označavanje redova na SVM-baziranom i označavanje redova bi-LSTM-CRF-a.', 'ca': "Arabic dialects do not just share a common koine, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other.  En aquest paper construïm un model de segmentació unificat on es combinan les dades d'entrenament de diferents dialectes i s'entrena un únic model. El model produeix més precisions que els models específics de dialecte, eliminant la necessitat d'identificar el dialecte abans de la segmentació. També mesurem el grau de relació entre quatre dialectes àrabs principals testant com un model de segmentació entrenat en un dialecte funciona en els altres dialectes. Vam descobrir que la relació lingüística està continguda amb la proximitat geogràfica. En els nostres experiments utilitzem la classificació basada en SVM i la etiqueta de seqüències bi-LSTM-CRF.", 'cs': 'Arabské dialekty nemají jen společnou koine, ale existují sdílené panedialektální jazykové jevy, které umožňují výpočetní modely dialektů učit se od sebe navzájem. V tomto článku vytvoříme jednotný segmentační model, kde jsou kombinována tréninková data pro různé dialekty a trénována jeden model. Model poskytuje vyšší přesnost než modely specifické pro dialekt, což eliminuje potřebu identifikace dialektu před segmentací. Měříme také stupeň souvislosti mezi čtyřmi hlavními arabskými dialekty testováním, jak segmentační model trénovaný na jednom dialektu funguje na ostatních dialektech. Zjistili jsme, že jazyková souvislost je podmíněna geografickou blízkostí. V našich experimentech používáme SVM hodnocení a bi-LSTM-CRF sekvenční značení.', 'et': 'Araabia murded ei jaga mitte ainult ühist koine, vaid on olemas ühiseid dialektilisi keelelisi nähtusi, mis võimaldavad dialektide arvutusmudelitel üksteiselt õppida. Käesolevas töös ehitame ühtse segmenteerimismudeli, kus koolitatakse erinevate murrete koolitusandmed ja koolitatakse üks mudel. Mudel annab suurema täpsuse kui dialektispetsiifilised mudelid, välistades vajaduse dialektide identifitseerimiseks enne segmenteerimist. Samuti mõõdame nelja peamise araabia dialekti vahelist seost, testides, kuidas ühel dialektil koolitatud segmenteerimismudel toimib teiste dialektide puhul. Leidsime, et keeleline seos sõltub geograafilisest lähedusest. Oma katsetes kasutame SVM-põhist järjestust ja bi-LSTM-CRF-järjestuse märgistust.', 'fi': 'Arabian murteet eivät vain jaa yhteistä koinea, vaan on olemassa yhteisiä pan-dialektisia kielellisiä ilmiöitä, jotka mahdollistavat murteiden laskennallisten mallien oppia toisiltaan. Tässä työssä rakennamme yhtenäisen segmentointimallin, jossa eri murteiden koulutustiedot yhdistetään ja yksi malli koulutetaan. Malli tuottaa murrekohtaisia malleja suuremmat tarkkuudet, jolloin murretunnistusta ei tarvita ennen segmentointia. Mittaamme myös neljän arabialaisen murteen välistä suhdetta testaamalla, miten yhteen murteeseen koulutettu segmentointimalli toimii muihin murteisiin. Havaitsimme, että kielellinen yhteys riippuu maantieteellisestä läheisyydestä. Kokeissamme käytämme SVM-pohjaista ranking- ja bi-LSTM-CRF-sekvenssimerkintää.', 'he': 'Arabic dialects do not just share a common koine, but there are shared pan-dialectal linguistic phenomena that allow computational models for dialects to learn from each other.  In this paper we build a unified segmentation model where the training data for different dialects are combined and a single model is trained.  The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation.  We also measure the degree of relatedness between four major Arabic dialects by testing how a segmentation model trained on one dialect performs on the other dialects.  מצאנו שקשר לשוני תלוי בקרבות גיאוגרפית. In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling.', 'sk': 'Arabska narečja ne delijo le skupnega koina, temveč obstajajo skupni pan-dialektni jezikovni pojavi, ki omogočajo računalniškim modelom narečij, da se učijo drug od drugega. V prispevku zgradimo enoten model segmentacije, kjer združujemo podatke o usposabljanju za različna narečja in usposabljamo en model. Model prinaša večjo natančnost kot modeli narečja, kar odpravlja potrebo po identifikaciji narečja pred segmentacijo. Merimo tudi stopnjo povezanosti med štirimi večjimi arabskimi narečji s preizkušanjem, kako deluje model segmentacije, usposobljen na enem narečju, na drugih narečjih. Ugotovili smo, da je jezikovna povezanost pogojena z geografsko bližino. V naših eksperimentih uporabljamo SVM-osnovno razvrščanje in bi-LSTM-CRF zaporedje označevanja.', 'ha': "Kurajan arabu ba su raba koin da ɗayan jama'a ba, kuma amma ana sami abu da ake yi wa raba cikin linguin fan-dialakatin, wanda yana yarda da misãlai na lissafar da za'a sanar da shi daga ɗayan. Daga wannan takardan, muna samar da wata misali da aka haɗa wa data na shirin diƙatan daban-daban kuma an sanar da wani motel guda. Modelen ya bãyar da tsari mafi girma daga motel-mai ƙayyade-ƙayyade, yana tafiyar da hitakin akwatin bayani na yi kiƙayyade gabãnin shirin sigar. Kayya, Munã ƙayyade darajõji masu yin husũma a tsakanin huɗu masu Larabci, ko kuma Muke jarraba yadda a sanar da wani misalin segmentation a kan gudan diƙatan. Mun gane cewa da mazaunin harshe na sami'a ga geografi. Ga jarrabõyinmu, munã amfani da mai rubutu na SV M-asansa da bi-LSSM-CRF.", 'bo': 'ཨ་རབ་ཀྱི་སྒྲ་ཚིགས་ཆ་རྣམས་གཅིག་མཐུན་གྱི་koine་གཅིག་ཡང་མཉམ་སྤྱོད་མིན་པར། ཡིན་ནའང་དེ་འདྲ་བར་གྱི་pan-dialectal linguistic phenomena་དག་གི་རྩིས་འཁོར་གྱི་མི ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་གྲངས་སྒྲིག་ཀྱི་ཆ་གྲངས་སྒྲིག་གི་མིག་ཆས་གཅིག་མཐུན་གྱི་རྣམ་པ་ཞིག་བྱེད་ཀྱི་ཡོད། The model yields higher accuracies than dialect-specific models, eliminating the need for dialect identification before segmentation. We also measure the degree of relatedness between four major Arabic dialects by testing how a segmentation model trained on one dialect performs on the other dialects. ངེད་གཉིས་ཀྱིས་སྐད་ཡིག་གཟུགས་འབྲེལ་འདི་སྤྱིར་བཏང་བ་དང་མཉམ་དུ་མཐུན་ཡོད། In our experiments we use SVM-based ranking and bi-LSTM-CRF sequence labeling.', 'jv': 'dialects arab sing ora deweke tek un koin nggawe liyane karo panelok dialectal maneh sing dumaten, nik sampeyan ingkang sampeyan pakan dialectal Awak dhéwé nggawe sistem sing beraksi dadi nggawe gerakan karo sistem sing dibenakake karo dialects sing sampeyan karo model sing beraksi. model Genjer-Genjer Awak dhéwé éntuk resmi ingkang dipun dadi kapan kelas nang jeogras. Anyone'}
{'en': 'Natural Language Generation for Spoken Dialogue System using RNN Encoder-Decoder Networks', 'ar': 'توليد اللغة الطبيعية لنظام الحوار المنطوق باستخدام شبكات فك التشفير RNN', 'fr': 'Génération de langage naturel pour système de dialogue vocal utilisant des réseaux encodeur-décodeur RNN', 'pt': 'Geração de linguagem natural para sistema de diálogo falado usando redes de codificador-decodificador RNN', 'es': 'Generación de lenguaje natural para el sistema de diálogo oral mediante redes codificador-descodificadoras RNN', 'ja': 'RNNエンコーダデコーダネットワークを使用したスポークンダイアログシステムのための自然言語生成', 'hi': 'RNN एन्कोडर-डिकोडर नेटवर्क का उपयोग कर बोली जाने वाली संवाद प्रणाली के लिए प्राकृतिक भाषा पीढ़ी', 'zh': '用RNN编码器-解码器网络口语自然语言成', 'ru': 'Генерация естественного языка для системы разговорного диалога с использованием сетей RNN Encoder-Decoder', 'ga': 'Giniúint Teanga Nádúrtha le haghaidh Córas Comhphlé Labhartha ag úsáid Líonraí Ionchódóra-Díchódóra RNN', 'el': 'Δημιουργία φυσικής γλώσσας για σύστημα ομιλούμενων διαλόγων χρησιμοποιώντας δίκτυα κωδικοποιητών-αποκωδικοποιητών RNN', 'hu': 'Természetes nyelv generálása beszélő párbeszédrendszerekhez RNN kódoló-dekódoló hálózatok használatával', 'ka': 'Name', 'kk': 'RNN кодер- декодер желілерін қолдану диалог жүйесінің табиғи тілді құру', 'it': 'Generazione del linguaggio naturale per il sistema di dialogo parlato utilizzando reti RNN Encoder-Decoder', 'ms': 'Jenerasi Bahasa Alami untuk Sistem Dialog Bercakap menggunakan Rangkaian Pengekod-Pengekod RNN', 'mt': 'Ġenerazzjoni ta’ Lingwa Naturali għal Sistema ta’ Djalogu Spoken bl-użu ta’ Netwerks ta’ Kodifikaturi-Dekodifikaturi RNN', 'lt': 'Gamtinės kalbos kūrimas kalbos dialogo sistemai naudojant RNN kodavimo ir dekoderių tinklus', 'mk': 'Генерација на природен јазик за разговорен дијалог систем користејќи мрежи за кодирање на RNN', 'ml': 'Name', 'no': 'Name', 'mn': 'RNN Encoder-Decoder Networks-г ашиглан Spoken Dialog System-ийн байгалийн хэл үүсгэх', 'pl': 'Generowanie języka naturalnego dla systemu dialogu mówionego przy użyciu sieci kodera-dekodera RNN', 'sr': 'Generacija prirodnog jezika za sistem govornog dijaloga koristeći RNN koder-dekoder mreže', 'ro': 'Generarea limbajului natural pentru sistemul de dialog vorbit folosind rețelele RNN Encoder-Decoder', 'si': 'Name', 'so': 'Isticmaalka RNN Encoder-Decoder Network', 'sv': 'Naturligt språk Generation för Talt Dialogue System med RNN Encoder-Decoder Networks', 'ta': 'Name', 'ur': 'Name', 'uz': 'Name', 'vi': 'Hệ thống nói chuyện ngôn ngữ tự nhiên dùng mạng mã hóa bảo vệ RNN', 'bg': 'Генериране на естествен език за говорена диалогова система с помощта на RNN кодер-декодерни мрежи', 'hr': 'Generacija prirodnog jezika za sustav govornog dijaloga koristeći RNN koder-dekoderske mreže', 'nl': 'Natuurlijke Taalgeneratie voor Gesproken Dialoog Systeem met behulp van RNN Encoder-Decoder Netwerken', 'da': 'Naturligt sprog generering til taledialog system ved hjælp af RNN Encoder-Decoder netværk', 'id': 'Generasi Bahasa Alami untuk Sistem Dialog Berbicara menggunakan Rangkaian Pengkode-Pengkode RNN', 'ko': 'RNN 코딩 네트워크 기반의 구어 대화 시스템 자연 언어 생성', 'fa': 'تولید زبان طبیعی برای سیستم محاورۀ گفتگو با استفاده از شبکه\u200cهای رمز\u200cدهنده RNN', 'de': 'Generierung natürlicher Sprache für gesprochenes Dialogsystem mit RNN Encoder-Decoder-Netzwerken', 'tr': 'RNN Ködleme-Açmak üçin Natal Dil Bejer', 'sq': 'Gjenerimi natyror i gjuhës për sistemin e dialogut të folur duke përdorur rrjetet e kodifikuesve RNN', 'af': 'Natuurlike taal genereering vir spoken dialoog stelsel gebruik RNN enkoder- dekoder Netwerke', 'am': 'የመድረክ ስም', 'sw': 'Uzalishaji wa lugha ya asili kwa ajili ya Mfumo wa Dialogu wa Mazungumzo kwa kutumia Mtandao wa RNN Encoder-Decoder', 'hy': 'Բնական լեզվի ստեղծման համար խոսում հաղորդագրական համակարգի համար, օգտագործելով ՌՆՆ-ի կոդեր-կոդեր ցանցեր', 'az': 'RNN Kodlayıcı-Dekodlayıcı Ağlarını istifadə edərək sözlü Dialoog Sistemi üçün təbiətli Dil Yaratılması', 'bn': 'RNN এনকোডার- ডেকোডার নেটওয়ার্ক ব্যবহার করে স্বাভাবিক ভাষা প্রজন্ম', 'ca': 'Generació natural de llenguatges per a un sistema de diàleg parlat utilitzant xarxes de codificadors RNN', 'bs': 'Generacija prirodnog jezika za sustav govornog dijaloga koristeći RNN koder-dekoder mreže', 'cs': 'Generování přirozeného jazyka pro systém mluveného dialogu pomocí sítí RNN Encoder-Decoder', 'et': 'Loomuliku keele loomine räägitud dialoogisüsteemi jaoks RNN kodeerija- dekoodrivõrkude abil', 'fi': 'Luonnollisen kielen luominen puhuttuun dialogijärjestelmään käyttäen RNN-kooderi-dekooderiverkkoja', 'he': 'יצירת שפות טבעית למערכת דיאלוגים מדברת באמצעות רשתות קודד RNN', 'jv': 'Jenengan langgambar Daftar kanggo Sistem Pangan Daftar dialog Ngawe gambar R.N koder-Dekoder netwark', 'ha': 'KCharselect unicode block name', 'sk': 'Ustvarjanje naravnega jezika za govorjeni dialogni sistem z uporabo RNN kodirnih in dekodirnih omrežij', 'bo': 'RNN སྤྱོད་བཞིན་པའི་སྐད་རིགས་ཀྱི་ཁ་འབྱེད་ཀྱི་ཌའི་ལོག་གླེང་སྒྲོམ་ལ་རང་བཞིན་གྱི་སྐད་རིགས་གསར་བསྐྲུན་པ'}
{'en': 'Natural language generation (NLG) is a critical component in a spoken dialogue system. This paper presents a Recurrent Neural Network based Encoder-Decoder architecture, in which an LSTM-based decoder is introduced to select, aggregate semantic elements produced by an attention mechanism over the input elements, and to produce the required utterances. The proposed generator can be jointly trained both sentence planning and surface realization to produce natural language sentences. The proposed model was extensively evaluated on four different NLG datasets. The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets.', 'ar': 'يعد توليد اللغة الطبيعية (NLG) مكونًا مهمًا في نظام الحوار المنطوق. تقدم هذه الورقة بنية مفكك التشفير القائمة على الشبكة العصبية المتكررة ، حيث يتم تقديم وحدة فك ترميز قائمة على LSTM لتحديد العناصر الدلالية المجمعة التي تنتجها آلية الانتباه على عناصر الإدخال ، ولإنتاج الكلام المطلوب. يمكن تدريب المولد المقترح بشكل مشترك على كل من تخطيط الجملة وإدراك السطح لإنتاج جمل لغة طبيعية. تم تقييم النموذج المقترح على نطاق واسع على أربع مجموعات بيانات NLG مختلفة. أظهرت النتائج التجريبية أن المولدات المقترحة لا تتفوق باستمرار على الأساليب السابقة في جميع مجالات NLG فحسب ، بل تُظهر أيضًا القدرة على التعميم من مجال جديد غير مرئي والتعلم من مجموعات البيانات متعددة المجالات.', 'pt': 'A geração de linguagem natural (NLG) é um componente crítico em um sistema de diálogo falado. Este artigo apresenta uma arquitetura Encoder-Decoder baseada em Rede Neural Recorrente, na qual um decodificador baseado em LSTM é introduzido para selecionar, agregar elementos semânticos produzidos por um mecanismo de atenção sobre os elementos de entrada e produzir os enunciados necessários. O gerador proposto pode ser treinado em conjunto tanto no planejamento de sentenças quanto na realização de superfície para produzir sentenças em linguagem natural. O modelo proposto foi amplamente avaliado em quatro conjuntos de dados NLG diferentes. Os resultados experimentais mostraram que os geradores propostos não apenas superam consistentemente os métodos anteriores em todos os domínios NLG, mas também mostram a capacidade de generalizar a partir de um domínio novo e não visto e aprender com conjuntos de dados de vários domínios.', 'fr': "La génération du langage naturel (GNL) est un élément essentiel d'un système de dialogue oral. Cet article présente une architecture encodeur-décodeur basée sur un réseau neuronal récurrent, dans laquelle un décodeur basé sur LSTM est introduit pour sélectionner, agréger des éléments sémantiques produits par un mécanisme d'attention sur les éléments d'entrée, et pour produire les énoncés requis. Le générateur proposé peut être formé conjointement à la fois à la planification de phrases et à la réalisation de surface pour produire des phrases en langage naturel. Le modèle proposé a fait l'objet d'une évaluation approfondie sur quatre ensembles de données de GNL différents. Les résultats expérimentaux ont montré que les générateurs proposés non seulement surpassent systématiquement les méthodes précédentes dans tous les domaines de GNL, mais montrent également une capacité à généraliser à partir d'un nouveau domaine non vu et à apprendre à partir d'ensembles de données multidomaines.", 'es': 'La generación de lenguaje natural (NLG) es un componente fundamental en un sistema de diálogo oral. Este artículo presenta una arquitectura de codificador-decodificador basada en redes neuronales recurrentes, en la que se introduce un decodificador basado en LSTM para seleccionar y agregar elementos semánticos producidos por un mecanismo de atención sobre los elementos de entrada, y para producir las expresiones requeridas. El generador propuesto puede capacitarse conjuntamente tanto en la planificación de oraciones como en la realización de la superficie para producir oraciones en lenguaje natural. El modelo propuesto se evaluó extensamente en cuatro conjuntos de datos de NLG diferentes. Los resultados experimentales mostraron que los generadores propuestos no solo superan sistemáticamente a los métodos anteriores en todos los dominios de NLG, sino que también muestran la capacidad de generalizar desde un dominio nuevo e invisible y aprender de conjuntos de datos multidominio.', 'ja': '自然言語生成（ NLG ）は、口語対話システムにおける重要な構成要素である。本論文では， LSTMベースのデコーダを導入し，入力要素に対して注意メカニズムによって生成されたセマンティック要素を選択して集約し，必要な発話を生成する， Recurrent Neural Networkベースのエンコーダデコーダアーキテクチャを提示した。提案されたジェネレータは、文章計画と表面実現の両方を共同で訓練して、自然言語の文章を作成することができます。提案されたモデルは、４つの異なるＮＬＧデータセット上で広範囲に評価された。実験結果は、提案されたジェネレータが、すべてのNLGドメインにわたって従来の方法を一貫して上回るだけでなく、新しい未知のドメインから一般化し、マルチドメインデータセットから学習する能力を示すことを示した。', 'zh': '自然语言成(NLG)者,口语之要组成部分。 本文立一基于递归神经网络之编码器-解码器架构,引入于LSTM之解码器,合意机于输入元素上生语义元素,并生所需之语。 议之生成器可以合训句规画,以成自然语言句。 四不同者NLG数集上博质之。 实验结果表明,所陈生成器非徒NLG域中始终优于前,而示从新,不见之域泛化从多域数集中学习之能也。', 'hi': 'प्राकृतिक भाषा पीढ़ी (एनएलजी) एक बोली जाने वाली संवाद प्रणाली में एक महत्वपूर्ण घटक है। यह पेपर एक आवर्तक तंत्रिका नेटवर्क आधारित एन्कोडर-डिकोडर आर्किटेक्चर प्रस्तुत करता है, जिसमें एक एलएसटीएम-आधारित डिकोडर को इनपुट तत्वों पर एक ध्यान तंत्र द्वारा उत्पादित समग्र शब्दार्थ तत्वों का चयन करने और आवश्यक उच्चारण का उत्पादन करने के लिए पेश किया जाता है। प्रस्तावित जनरेटर को प्राकृतिक भाषा वाक्यों का उत्पादन करने के लिए संयुक्त रूप से वाक्य योजना और सतह प्राप्ति दोनों को प्रशिक्षित किया जा सकता है। प्रस्तावित मॉडल का चार अलग-अलग एनएलजी डेटासेट पर बड़े पैमाने पर मूल्यांकन किया गया था। प्रयोगात्मक परिणामों से पता चला है कि प्रस्तावित जनरेटर न केवल सभी एनएलजी डोमेन में पिछले तरीकों से लगातार बेहतर प्रदर्शन करते हैं, बल्कि एक नए, अनदेखी डोमेन से सामान्यीकरण करने और बहु-डोमेन डेटासेट से सीखने की क्षमता भी दिखाते हैं।', 'ru': 'Генерация естественного языка (NLG) является критическим компонентом системы разговорного диалога. В данной работе представлена архитектура кодера-декодера на основе рекуррентной нейронной сети, в которой декодер на основе LSTM вводится для выбора, агрегирования семантических элементов, создаваемых механизмом внимания над входными элементами, и для получения необходимых фраз. Предлагаемый генератор может быть совместно обучен как планированию предложений, так и поверхностной реализации для получения предложений на естественном языке. Предлагаемая модель была тщательно оценена на основе четырех различных наборов данных NLG. Экспериментальные результаты показали, что предлагаемые генераторы не только последовательно превосходят предыдущие методы во всех доменах NLG, но и демонстрируют способность обобщать из нового, невидимого домена и учиться на многодоменных наборах данных.', 'ga': 'Comhpháirt ríthábhachtach de chóras comhphlé labhartha is ea giniúint nádúrtha teanga (NLG). Cuireann an páipéar seo i láthair ailtireacht Ionchódóra Ionchódóra Athfhillteach Líonra Néarach-bhunaithe, ina dtugtar isteach díchódóir LSTM-bhunaithe chun eilimintí shéimeantacha comhiomlána a tháirgtear trí mheicníocht aird ar na heilimintí ionchuir a roghnú, agus chun na cainteanna riachtanacha a tháirgeadh. Is féidir an gineadóir atá beartaithe a chomhthraenáil maidir le pleanáil pianbhreithe agus réadú dromchla araon chun abairtí nádúrtha teanga a tháirgeadh. Rinneadh measúnú cuimsitheach ar an tsamhail bheartaithe ar cheithre thacar sonraí NLG éagsúla. Léiríodh sna torthaí turgnamhacha go sáraíonn na gineadóirí molta na modhanna a bhí ann roimhe seo ar fud réimsí uile an NLG ach go léiríonn siad go bhfuil siad in ann ginearálú ó fhearann nua nach bhfacthas riamh cheana agus foghlaim ó thacair sonraí ilfhearainn.', 'el': 'Η παραγωγή φυσικής γλώσσας είναι ένα κρίσιμο στοιχείο σε ένα σύστημα προφορικού διαλόγου. Η παρούσα εργασία παρουσιάζει μια αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή βασισμένη σε επαναλαμβανόμενα νευρωνικά δίκτυα, στην οποία εισάγεται ένας αποκωδικοποιητής βασισμένος στο LSTM για να επιλέγει, να συγκεντρώνει σημασιολογικά στοιχεία που παράγονται από έναν μηχανισμό προσοχής πάνω από τα στοιχεία εισόδου, και να παράγει τις απαιτούμενες εκφράσεις. Η προτεινόμενη γεννήτρια μπορεί να εκπαιδευτεί από κοινού τόσο στο σχεδιασμό προτάσεων όσο και στην υλοποίηση επιφάνειας για να παράγει προτάσεις φυσικής γλώσσας. Το προτεινόμενο μοντέλο αξιολογήθηκε εκτενώς σε τέσσερα διαφορετικά σύνολα δεδομένων NLG. Τα πειραματικά αποτελέσματα έδειξαν ότι οι προτεινόμενες γεννήτριες όχι μόνο ξεπερνούν σταθερά τις προηγούμενες μεθόδους σε όλους τους τομείς αλλά επίσης δείχνουν την ικανότητα να γενικεύουν από ένα νέο, αόρατο τομέα και να μαθαίνουν από σύνολα δεδομένων πολλαπλών τομέων.', 'hu': 'A természetes nyelv generálása (NLG) kritikus eleme a beszélt párbeszédrendszernek. A tanulmány ismétlődő neurális hálózat alapú Encoder-Decoder architektúrát mutat be, amelyben egy LSTM alapú dekódolót vezetünk be a bemeneti elemek feletti figyelemmechanizmus által létrehozott szemantikai elemek kiválasztására, összesítésére, valamint a szükséges kimondások előállítására. A javasolt generátor közösen képezhető a mondattervezés és a felületi megvalósítás természetes nyelvű mondatok előállítására. A javasolt modellt négy különböző NLG adatkészleten alaposan értékelték. A kísérleti eredmények azt mutatták, hogy a javasolt generátorok nemcsak a korábbi módszereket következetesen felülmúlják az összes NLG tartományban, hanem azt is mutatják, hogy képesek általánosítani egy új, láthatatlan tartományból és tanulni a több tartományból álló adatkészletekből.', 'it': "La generazione del linguaggio naturale (NLG) è una componente critica in un sistema di dialogo parlato. Questo articolo presenta un'architettura Encoder-Decoder basata sulla rete neurale ricorrente, in cui viene introdotto un decoder basato su LSTM per selezionare, aggregare elementi semantici prodotti da un meccanismo di attenzione sugli elementi di input, e per produrre le espressioni richieste. Il generatore proposto può essere formato congiuntamente sia pianificazione delle frasi che realizzazione superficiale per produrre frasi in linguaggio naturale. Il modello proposto è stato ampiamente valutato su quattro diversi set di dati NLG. I risultati sperimentali hanno mostrato che i generatori proposti non solo superano costantemente i metodi precedenti in tutti i domini NLG, ma mostrano anche la capacità di generalizzare da un nuovo dominio invisibile e imparare da set di dati multi-dominio.", 'lt': 'Gamtinės kalbos kūrimas (NLG) yra svarbiausias kalbos dialogo sistemos elementas. Šiame dokumente pateikiama pakartotinio neurologinio tinklo kodavimo architektūra, kurioje įvedamas LSTM pagrindu pagrįstas dekoderis, kad būtų atrinkti, suvestiniai semantiniai elementai, pagaminti dėmesio mechanizmu, o ne įvedami elementai, ir gaunami reikalingi žodžiai. Siūlomas generatorius gali būti bendrai apmokytas ir sakinių planavimas, ir paviršiaus realizavimas, kad būtų parengti natūralūs kalbiniai sakiniai. Siūlomas modelis buvo išsamiai įvertintas pagal keturis skirtingus NLG duomenų rinkinius. The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets.', 'kk': 'Түзіндік тілді құру (NLG) сөйлейтін диалог жүйесінде маңызды компонент. Бұл қағаз қайталанатын нейралық желінің кодер- декодер архитектурасын көрсетеді. LSTM- негіздеген декодер таңдау үшін қолданылады. Кіріс элементтерінің механизмі бойынша өзгертілген семантикалық элементтерді және қажетті сөздерді жасау Бұл генератор табиғи тілді сөйлемелерді жасау үшін сөйлемелерді планировау мен поверхностық түсініктемелерді біріктіруге болады. Бұл үлгі төрт түрлі NLG деректер қорларында кеңейтілген. Тәжірибелі нәтижелер көрсетілген генераторлар тек', 'mk': 'Генерацијата на природен јазик (НЛГ) е критичен компонент во системот на разговорен дијалог. Овој документ претставува архитектура на рекурентна неурална мрежа базирана на кодер-декодер, во која се воведува декодер базиран на LSTM за избор, агресирање семантични елементи произведени од механизам на внимание над вводните елементи, и за производство на потребните израз Предложениот генератор може заеднички да биде обучен како планирање на речениците, така и објавување на површината за производство на природни реченици на јазикот. Предложениот модел беше екстремно проценет на четири различни податоци на НЛГ. Експерименталните резултати покажаа дека предложените генератори не само што постојано ги надминуваат претходните методи низ сите домени на НЛГ, туку и покажуваат способност да се генерализираат од нов, невиден домен и да учат од мултидомени податоци.', 'ms': 'Generasi bahasa semulajadi (NLG) adalah komponen kritik dalam sistem dialog bercakap. Kertas ini memperkenalkan arkitektur Pengekod-Pengekod Jaringan Neural Berulang, di mana pengekod berdasarkan LSTM diperkenalkan untuk memilih, aggregat unsur semantik yang dihasilkan oleh mekanisme perhatian atas unsur input, dan untuk menghasilkan ungkapan yang diperlukan. Generator yang diusulkan boleh dilatih bersama-sama merancang kalimat dan penyelesaian permukaan untuk menghasilkan kalimat bahasa semulajadi. The proposed model was extensively evaluated on four different NLG datasets.  Hasil percubaan menunjukkan bahawa generator yang direncanakan tidak hanya secara konsisten melampaui kaedah terdahulu di seluruh domain NLG tetapi juga menunjukkan kemampuan untuk menyebarkan dari domain baru, tidak terlihat dan belajar dari set data berbilang-domain.', 'ml': 'സ്വാഭാവിക ഭാഷ തലമുറയാണു് (NLG) സംസാരിക്കുന്ന ഡയലോഗ് സിസ്റ്റത്തില്\u200d ഒരു ഗുരുതരമായ ഘടകം. ഈ പത്രത്തില്\u200d നിലനില്\u200dക്കുന്ന നെയുറല്\u200d നെറ്റോര്\u200d നെറ്റോവര്\u200dക്ക് അടിസ്ഥാനത്തുള്ള എക്കോഡെര്\u200d ഡെക്കോഡെര്\u200d ആര്\u200dക്കിക്കേറ്റര്\u200d കാണിക്കുന്നു. അതില്\u200d ഒരു LSTM അടിസ്ഥാനമായ ഡ പ്രൊദ്ദേശിക്കപ്പെട്ട ജെനററേറ്റര്\u200d സ്വാഭാവിക ഭാഷയുടെ വാക്കുകള്\u200d ഉല്\u200dപാദിപ്പിക്കാനും വാക്കുകള്\u200d പ്ല പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്\u200d നാലു വ്യത്യസ്തമായ NLG ഡാറ്റാസറ്റുകളില്\u200d വിശാലമായി പരിഗണിച്ചു. പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നത് പ്രൊദ്ദേശിച്ച ജനറല്\u200dമാര്\u200d മുമ്പുള്ള എല്ലാ എംഎല്\u200dജി ഡോമെന്\u200dമെനുകളിലും മാത്രമല്ല, പുതിയ, അദൃശ്യമാ', 'mt': 'Il-ġenerazzjoni tal-lingwi naturali (NLG) hija komponent kritiku f’sistema ta’ djalogu mitkellem. Dan id-dokument jippreżenta arkitettura rikorrenti ta’ Kodifikatur-Dekodifikatur ibbażata fuq in-Netwerk Newrali, li fiha jiġi introdott dekodifikatur ibbażat fuq LSTM biex jintgħa żlu, jiġu aggregati elementi semantiċi prodotti minn mekkaniżmu ta’ attenzjoni fuq l-elementi ta’ input, u biex jiġu prodotti l-espressjonijiet meħtieġa. Il-ġeneratur propost jista’ jitħarreġ b’mod konġunt kemm fl-ippjanar tas-sentenzi kif ukoll fir-realizzazzjoni tas-superfiċje biex jipproduċi sentenzi lingwistiċi naturali. Il-mudell propost ġie evalwat b’mod estensiv fuq erba’ settijiet differenti ta’ dejta tal-NLG. Ir-riżultati sperimentali wrew li l-ġeneraturi proposti mhux biss b’mod konsistenti jwettqu l-metodi preċedenti fid-dominji kollha tal-NLG iżda wkoll juru l-kapaċità li jiġġeneralizzaw minn dominju ġdid, mhux osservat u jitgħallmu minn settijiet ta’ dejta multidominji.', 'ka': 'ნაირთოლური ენის განვითარება (NLG) არის კრიტიკური კომპონენტი სისტემაში. ეს დოკუმენტი განახლება განახლებელი ნეიროლური ქსელი, რომელიც LSTM-დაბათი განახლებელი განახლებელია, აგგრეგურაცია სიმენტიკური ელემენტები, რომელიც მოწყობინებული ელემენტების შესახებ დაახლოებით, და მოსახ პროგრამეტრების გენერატორი შეიძლება იყოს ერთადერთად განსწავლა, რომელიც წესების პლანეზაცია და სამუშაო რეალიზაცია, რომელიც მიიღებ პროგრამეტული მოდელი 4 განსხვავებული NLG მონაცემების შესახებ ძალიან განსაზღვრებული იყო. ექსპერიმენტიური წარმოდგენები გამოჩვენეთ, რომ პროგენტირებები არა მხოლოდ მხოლოდ წინასწარმოდგენებული მეტოვები ყველა NLG დიომენზე, მაგრამ ასევე გამოჩვენეთ შესაძლებლობა დავიწყებთ ახალი, არ', 'no': 'Natural language generation (NLG) er ein kritisk komponent i eit talet dialogsystem. Denne papiret viser eit gjentaande neuralnettverk basert koder- dekoderarkitektur, der ein LSTM-basert dekoder vert introdusert til å velja, aggregar semantiske elementar som er produsert av ein oppmerksmekanisme over inndataelementa, og for å produsera dei nødvendige uttalene. Dette første generatoren kan kopla opplærast både setningsplanning og overflate for å produsera naturspråk setningar. Foreslått modellen vart utvida på fire ulike NLG-datasett. Eksperimentale resultatene viste at foreslåde generatorene ikkje bare utfører dei førre metodane over alle NLG- domenene, men også viser ein kapasitet å generalisere frå ein ny, ukjend domene og lære frå fleire domenedatasett.', 'mn': 'Байгалийн хэл төрөлхтөн (NLG) бол ярианы диалог системийн чухал компонент юм. Энэ цаас дахин дахин шинэ мэдрэлийн сүлжээний Encoder-Decoder архитектурыг тайлбарладаг. LSTM-д суурилсан загвар сонгох, анхаарал төвлөрүүлэх механизмээр бүтээгдэхүүний тулд бүтээгдэхүүний тулд бүтээгдэхүүний тулд анхаарал төвлөрүүлэх, хэрэг Хэрэв санал өгсөн генератор нь байгалийн хэл өгүүлбэрийг бүтээхэд өгүүлбэрийн төлөвлөгөө болон гадаргуу ойлголтыг нийлүүлж болох юм. Өөрчлөгдсөн загвар нь 4 өөр NLG өгөгдлийн сангийн хэмжээнд маш их үнэлгээ өгсөн. Үүний туршилтын үр дүнд санал өгсөн генератор зөвхөн өмнөх арга зэрэг NLG зохион байгуулагдахгүй, мөн шинэ, харагдахгүй зохион байгуулагч, олон зохион өгөгдлийн санаас суралцах чадварыг харуулсан.', 'pl': 'Generowanie języka naturalnego (NLG) jest kluczowym elementem systemu dialogu mówionego. W artykule przedstawiono architekturę Encoder-Decoder opartą na sieci recurrent neuronal Network, w której wprowadzono dekoder oparty na LSTM do selekcji, agregowania elementów semantycznych wytwarzanych przez mechanizm uwagi nad elementami wejściowymi oraz do wytwarzania wymaganych wypowiedzi. Proponowany generator może być wspólnie przeszkolony zarówno planowanie zdań, jak i realizacja powierzchni w celu wytwarzania zdań językowych naturalnych. Proponowany model został szeroko oceniony na czterech różnych zbiorach danych NLG. Wyniki eksperymentalne wykazały, że proponowane generatory nie tylko konsekwentnie przewyższają poprzednie metody we wszystkich domenach NLG, ale również wykazują zdolność do uogólniania z nowej, niewidzialnej domeny i uczenia się z wielodzeninowych zbiorów danych.', 'ro': 'Generarea limbajului natural (NLG) este o componentă critică într-un sistem de dialog vorbit. Această lucrare prezintă o arhitectură Encoder-Decoder bazată pe rețea neurală recurentă, în care este introdus un decoder bazat pe LSTM pentru a selecta, agrega elementele semantice produse printr-un mecanism de atenție asupra elementelor de intrare și pentru a produce cuvintele necesare. Generatorul propus poate fi instruit în comun atât planificarea propozițiilor, cât și realizarea suprafeței pentru a produce propoziții de limbaj natural. Modelul propus a fost evaluat pe scară largă pe patru seturi diferite de date NLG. Rezultatele experimentale au arătat că generatorii propuși nu numai că depășesc în mod constant metodele anterioare în toate domeniile NLG, dar și capacitatea de a generaliza dintr-un domeniu nou, nevăzut și de a învăța din seturi de date multi-domeniu.', 'sr': 'Prirodna generacija jezika (NLG) je kritična komponenta u rečenom dijalogu. Ovaj papir predstavlja ponovnu neuronsku mrežu baziranu arhitekturu kodera-dekodera, u kojoj se predstavlja osnovana na LSTM dekoder kako bi izabrao, okupljao semantičke elemente proizvedene od mehanizma pažnje na ulaznim elementima i proizvela potrebne reči. Predloženi generator može biti zajedno obučen i planiranjem rečenica i realizacijom površine kako bi proizvela prirodne rečenice jezika. Predloženi model je prošireno procjenjivan na četiri različite podatke NLG. Eksperimentalni rezultati pokazali su da predloženi generatori ne samo konsekventno iznose prethodne metode u svim domenima NLG, nego takođe pokazuju sposobnost generalizacije iz novog, nevidjenog domena i naučiti iz višedomenih podataka.', 'so': 'Muujinta afka asalka ah (NLG) waa qayb muhiim ah oo ku qoran nidaamka dialogka. Kanu wuxuu keenaa taariikhda Qooder-Decoder ee ku saleysan Neural Network, kaas oo lagu soo bandhigay qoraal-coder-based LSTM, si uu u doorto, soo kordhiyo elements semantic oo ay u soo bandhigtay mekanisme ka kordhisan elementada input, iyo in uu soo saaro hadallo loo baahan yahay. Dhaqaalaha la soo jeeday waxaa si wadajir ah loo baran karaa qorshaha qorshaha iyo garashada dhulka si uu u soo koriyo qorshaha luqada asalka ah. Tusaale la soo jeeday waxaa si ballan ah lagu qiimeeyay afar koox oo kala duduwan oo ALG ah. Imtixaanka waxaa ka muuqday in dhaliyayaasha la soo jeeday ay ay ku dhamaadaan qaababka hore oo dhan ee gudaha NLG, laakiin waxay sidoo kale muujiyaan awood uu ka dhalayo gudaha cusub oo qarsoon iyo ka barto kooxda macluumaadka kala duduwan.', 'sv': 'Naturligt språk generation (NLG) är en kritisk komponent i ett talat dialogsystem. Denna uppsats presenterar en återkommande neural nätverksbaserad Encoder-Decoder arkitektur, där en LSTM-baserad avkodare introduceras för att välja, aggregera semantiska element producerade av en uppmärksamhetsmekanism över indata element, och för att producera de nödvändiga yttrandena. Den föreslagna generatorn kan gemensamt utbildas både meningsplanering och ytförverkligande för att producera naturliga språkmeningar. Den föreslagna modellen utvärderades ingående på fyra olika NLG-datauppsättningar. De experimentella resultaten visade att de föreslagna generatorerna inte bara konsekvent överträffar de tidigare metoderna inom alla NLG-domäner utan också visar en förmåga att generalisera från en ny, osedd domän och lära av flerdomänsdata.', 'si': 'ස්වභාවික භාෂාව ප්\u200dරමාණය (NLG) භාවිත සංවාදය පද්ධතියෙන් විශේෂ භාවිතාවක්. මේ පැත්ත පෙනුම් පෙනුම් වෙනුවෙන් නිර්මාණ ජාලයේ අධාරිත සංකේතනය සංකේතය, LSTM- අධාරිත සංකේතනයක් තෝරාගන්න, සම්පූර්ණ සංකේතනයක් ඇ ප්\u200dරශ්නය කරපු ජෙනරේටර් එක්කම ප්\u200dරශ්නයක් වෙන්න පුළුවන් වාක්ය සැලසුම් සහ පුළුවන් ප්\u200dරශ් ප්\u200dරශ්නය කරපු මෝඩේල් එක වෙනස් NLG දත්ත සෙට් හතරයි විශේෂයෙන් විශේෂයෙන් අවශ්\u200dයය කර පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ ප්\u200dරතිචාරකයන් ප්\u200dරතිචාරකයන්ට ප්\u200dරතිචාරකය NLG ඩෝමේන් වලින් ප්\u200dරතිචාරකය විතරක් නෙ', 'ta': 'இயல்பான மொழி உருவாக்கம் (NLG) பேசும் உரையாடல் முறைமையில் ஒரு முக்கியமான பொருள். இந்த paper presents a Recurrent Neural Network based Encoder- Decoder architecture, in which an LSTM-based decoder is introduced to select, aggregate semantic elements produced by an attention mechanism over the input elements, and to produce the required words. பரிந்துரைக்கப்பட்ட உருவாக்கி இயல்பான மொழியின் வாக்கியங்களை உருவாக்குவதற்கான வாக்கியை திட்டமைக்கும் த திருத்தப்பட்ட மாதிரி நான்கு வித்தியாசமான NLG தரவுத்தளங்களில் மதிப்பிடப்பட்டது. The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets.', 'ur': 'طبیعی زبان کی پیدائش (NLG) ایک بات کی گفتگو سیسٹم میں ایک ضروری رقم ہے۔ یہ کاغذ ایک دوبارہ نیورل نیورل نیٹ ورک بنیاد Encoder-Decoder معماری پیش کرتا ہے جہاں ایک LSTM بنیاد ڈیکوڈر کو انتخاب کرنے کے لئے پیش کیا جاتا ہے، ایک سیمانٹیک اتمام کو جمع کرتا ہے جو ایک توجه مکانیسم کے ذریعے اینٹ اتمام کے ذریعے توجه کی مکانیسم پیغمبر کی جنرائٹر ایک دوسرے سے جماعت کی تدبیر کی جاتی ہے اور سطح کی تصویر کی جاتی ہے کہ طبیعی زبان جماعت پیدا کرے۔ پیشنهاد کی موڈل چار مختلف NLG ڈیٹ سٹ پر پھیلائی گئی تھی۔ آزمائش نتیجے دکھائے گئے کہ پیشنهاد جنرائٹر صرف پہلے طریقے کو تمام NLG ڈومین کے ذریعہ سے زیادہ برتر نہیں کرسکتے بلکہ نیا، غیب دکھائی ڈومین سے اور بہت سی ڈیٹسٹ سے سیکھنے کی قابلیت بھی دکھائے جاتے ہیں.', 'uz': "Name Name Talab qilingan generator birlashtirilgan so'zni boshqarish va jadvalni aniqlash mumkin. Name Tekshirish natijalari shunday koʻrsatilgan taʼminlovchi generatorlar faqat avval NLG domenening hamma tarkibi usullarini ishga tushirish mumkin, balki yangi, nomaʼlum domen tarkibidan yaratish va bir necha domen maʼlumot tizimidan o'rganish imkoniyatini koʻrsatish mumkin.", 'vi': 'Thế hệ ngôn ngữ tự nhiên (NLG) là một thành phần quan trọng trong hệ thống đối thoại ngôn ngữ. Tờ giấy này đề xuất một kiến trúc Encoder-Decder phục phục (tiếp tế thần kinh) dựa vào các cấu trúc Encoder-Decder, trong đó có một bộ giải mã dựa trên LSD được nhập vào để chọn, tổng hợp các yếu tố ngữ pháp được sản xuất bởi một cơ chế tập trung các nguyên tố nhập, và sản xuất ra những lời nhắn yêu cầu. Máy phát điện có thể được huấn luyện cùng nhau, cả về kế hoạch án và thực hiện bề mặt để tạo ra các câu ngôn ngữ tự nhiên. Kiểu mẫu đã được đánh giá rộng trên bốn tập tin thuộc về LG khác nhau. Các kết quả thử nghiệm cho thấy rằng các máy phát điện đề xuất không chỉ hoàn to àn vượt trội các phương pháp trước trên tất cả các miền thuộc địa NLG, mà còn cho thấy khả năng tổng kết từ một miền mới, không ai thấy và học từ các tập tin đa miền.', 'nl': 'Natuurlijke taalgeneratie (NLG) is een cruciaal onderdeel in een gesproken dialoogsysteem. Dit artikel presenteert een Recurrent Neural Network gebaseerde Encoder-Decoder architectuur, waarin een LSTM-gebaseerde decoder wordt geïntroduceerd om semantische elementen geproduceerd door een aandachtsmechanisme over de invoerelementen te selecteren, te aggregeren en de vereiste uitspraken te produceren. De voorgestelde generator kan gezamenlijk getraind worden zowel zinnenplanning als oppervlakterealisatie om zinnen in natuurlijke taal te produceren. Het voorgestelde model werd uitgebreid geëvalueerd op vier verschillende NLG datasets. De experimentele resultaten toonden aan dat de voorgestelde generatoren niet alleen consistent de vorige methoden overtreffen in alle NLG domeinen, maar ook een vermogen tonen om te generaliseren vanuit een nieuw, onzichtbaar domein en te leren van multi-domein datasets.', 'bg': 'Генерирането на естествен език (НЛГ) е критичен компонент в системата за говорен диалог. Настоящата статия представя архитектура на кодер-декодер, базирана на повтаряща се неврална мрежа, в която се въвежда декодер, базиран на ЛСТМ, за да се изберат, обединят семантични елементи, произведени от механизъм за внимание върху входните елементи, и да се произведат необходимите изказвания. Предложеният генератор може да бъде съвместно обучен както планиране на изреченията, така и реализация на повърхността, за да се произвеждат изречения с естествен език. Предложеният модел беше обширно оценен върху четири различни НЛГ набора данни. Експерименталните резултати показват, че предложените генератори не само постоянно превъзхождат предишните методи във всички области на НЛГ, но и показват способност да генерират от нов, невидим домейн и да се учат от множество домейни данни.', 'hr': 'Prirodna generacija jezika (NLG) je kritična komponenta u govornom dijalogu. Ovaj papir predstavlja ponovnu arhitekturu osnovanu na Neuralnoj mreži kodera-dekodera, u kojoj se uvodi dekoder osnovan na LSTM-u kako bi se odabrao, okupljao semantičke elemente proizvođene od mehanizma pažnje na ulaznim elementima i proizvodio potrebne izraze. Predloženi generator može biti zajedno obučen planiranjem rečenica i realizacijom površine kako bi proizvela prirodne rečenice za jezik. Predloženi model je prošireno procijenjen na četiri različite podatke NLG-a. Eksperimentalni rezultati pokazali su da predloženi generatori ne samo konsekventno iznose prethodne metode u svim domenima NLG, nego također pokazuju sposobnost generalizacije iz novog, nevidjenog domena i naučiti iz višedomenih podataka.', 'ko': '자연 언어의 생성은 구어 대화 시스템의 중요한 구성 부분이다.본고는 귀속신경 네트워크를 바탕으로 하는 디코더 구조를 제시했는데 그 중에서 LSTM을 바탕으로 하는 디코더를 도입하여 주의 메커니즘에 의해 발생하는 의미 요소를 선택하고 집합하며 필요한 말을 만들었다.이 생성기는 문장 기획과 표면적인 연합 훈련을 통해 자연 언어 문장을 생성할 수 있다.네 개의 서로 다른 NLG 데이터 세트에서 제시된 모델에 대해 광범위한 평가를 실시했다.실험 결과에 따르면 제시된 생성기는 모든 NLG역에서 이전의 방법보다 우수할 뿐만 아니라 새로운, 보이지 않는 역에서 범화되고 다역 데이터로부터 집중적으로 학습할 수 있다.', 'id': 'Generasi bahasa alam (NLG) adalah komponen kritis dalam sistem dialog yang dibicarakan. Kertas ini mempersembahkan arsitektur Koder-Dekoder Jaringan Neural Berdasarkan Sekali-kali, di mana koder berdasarkan LSTM diperkenalkan untuk memilih, agregasi elemen semantis yang diproduksi oleh mekanisme perhatian atas elemen masukan, dan untuk menghasilkan ungkapan yang diperlukan. Generator yang diusulkan dapat dilatih bersama-sama untuk merencanakan kalimat dan menyadari permukaan untuk menghasilkan kalimat bahasa alami. Model yang diusulkan diteliti secara ekstensif pada empat set data NLG yang berbeda. Hasil eksperimen menunjukkan bahwa generator yang diusulkan tidak hanya secara konsisten melampaui metode sebelumnya di seluruh domain NLG tetapi juga menunjukkan kemampuan untuk menyegeralkan dari domain baru, tidak terlihat dan belajar dari set data multi-domain.', 'fa': 'نسل زبان طبیعی (NLG) یک بخش مهمی در سیستم گفتگو است. این کاغذ یک معماری که بر اساس شبکه عصبی بر اساس Encoder-Decoder بنیاد می\u200cآید را نشان می\u200cدهد، که در آن یک dekoder بنیاد LSTM برای انتخاب، عناصر semantic را جمع می\u200cکند که توسط یک مکانیسم توجه بر روی عناصر وارد می\u200cشود، و برای تولید کلمات لازم را معرفی ژنراتور پیشنهاد می\u200cتواند با هم برنامه\u200cریزی جمله و تعلیم سطح برای تولید جمله\u200cهای زبان طبیعی آموزش داده شود. مدل پیشنهاد در چهار مجموعه داده\u200cهای NLG بسیار ارزیابی شد. نتایج آزمایشی نشان داد که ژنراتورهای پیشنهاد نه تنها روش های قبلی را در تمام دامنهای NLG انجام می دهند، بلکه همچنین توانایی را نشان می دهد که از یک دامنی جدید، غیب و غیب و از مجموعه داده های چندین دامنی یاد بگیرند.', 'sw': 'Kizazi cha lugha ya asili (NLG) ni sehemu muhimu katika mfumo wa mazungumzo yanayozungumzwa. Gazeti hili linaonyesha ujenzi wa Mtandao wa Neural unaoendelea kwa msingi wa Kukodi-Decoder, ambapo kodi la LSTM linaanzishwa kuchaguliwa, kuongeza vipengele vya sekunde vilivyotengenezwa na mfumo wa kusikiliza juu ya vipengele vya habari, na kutengeneza hotuba zinazohitajika. Mtengenezaji huyo alipendekezwa anaweza kufundishwa kwa pamoja na mipango ya hukumu na kuelewa ukweli wa surfe ili kutengeneza hukumu za lugha asili. Mradi huo ulipendekezwa ulivutiwa kwa kiasi kikubwa kwenye seti nne tofauti za data za NLG. Matokeo ya majaribio yalionyesha kuwa vizazi wanaopendekezwa siyo tu kutekeleza mbinu zilizopita katika maeneo yote ya NLG bali pia zinaonyesha uwezo wa kutengeneza kutoka ndani mpya, isiyo na kujua na kujifunza kutoka kwenye seti za data za ndani mbalimbali.', 'da': 'Naturligt sprog generation (NLG) er en kritisk komponent i et talesystem. Denne artikel præsenterer en tilbagevendende neural netværksbaseret Encoder-Decoder arkitektur, hvor en LSTM-baseret dekoder introduceres til at udvælge, aggregere semantiske elementer produceret af en opmærksomhedsmekanisme over inputelementerne, og til at producere de nødvendige udtalelser. Den foreslåede generator kan trænes i fællesskab både sætningsplanlægning og overfladebehandling til at producere naturlige sprogsætninger. Den foreslåede model blev grundigt evalueret på fire forskellige NLG datasæt. De eksperimentelle resultater viste, at de foreslåede generatorer ikke kun konsekvent overperformer de tidligere metoder på tværs af alle NLG domæner, men også viser en evne til at generalisere fra et nyt, uset domæne og lære af multi-domæne datasæt.', 'tr': 'Natal dil döredilişi (NLG) gürleýän dijal sisteminde wajyp komponentdir. Bu kagyz faýlyň gaýd edilen Neural Network tabanly Koder-Dekoder arhitektegi ýazylýar. Bu ýerde LSTM tabanly bir dekoder saýlamak üçin guruldy, gyzyklanýan semantik elementler girdi elementlerden tarapyndan üretilen, we gerekli sözleri üretmek üçin birleşdirdi. Maksadat generatöri tebigy dil sözlerini täze etmek üçin sözler planlaýan we ýeri tassyklama bilen birleştirilebilir. Taýýarlanan nusga dört dürli NLG sanatynda golaýlaşdy. Deneysel netijeler teklip eden jeneratörler diňe öňki döwletlerden öňki döwletlerden döwürmekten däl, ýöne täze döwletlerden döwürmek başarjagyny görkez we köp-domain veri setirlerinden öwrenmek başarjagyny görkez.', 'af': "Natuurlike taal generasie (NLG) is 'n kritiese komponent in' n praat dialoog stelsel. Hierdie papier voorstel 'n Herhaalde Neurale Netwerk gebaseerde Enkoder-Dekoder-Arkitektuur, waarin 'n LSTM-gebaseerde dekoder is ingevoer om te kies, te groep semantiese elemente wat deur 'n aandag mekanisme uitgevoer word oor die invoer elemente en om die benodige uitdrukkings te produseer. Die voorgestelde genereerder kan saamstig opgelei word beide setplanning en oorspronklike realisasie om natuurlike taal setinge te produseer. Die voorgestelde model was uitbreidig op vier verskillende NLG datastelle. Die eksperimentale resultate het vertoon dat die voorgestelde genereerders nie slegs konsistentlik die vorige metodes oortvoer oor alle NLG domeine nie, maar ook 'n moontlik vertoon om van' n nuwe, ongesiende domein te genereer en te leer van multidomein datastelle.", 'de': 'Die Generierung natürlicher Sprache (NLG) ist ein wichtiger Bestandteil eines gesprochenen Dialogsystems. In diesem Beitrag wird eine Recurrent Neural Network basierte Encoder-Decoder-Architektur vorgestellt, in der ein LSTM-basierter Decoder eingeführt wird, um semantische Elemente auszuwählen, zu aggregieren, die durch einen Aufmerksamkeitsmechanismus über die Eingabeelemente erzeugt werden, und die erforderlichen Äußerungen zu erzeugen. Der vorgeschlagene Generator kann sowohl Satzplanung als auch Flächenrealisierung gemeinsam trainiert werden, um natürliche Sätze zu erzeugen. Das vorgeschlagene Modell wurde auf vier verschiedenen NLG-Datensätzen umfassend ausgewertet. Die experimentellen Ergebnisse zeigten, dass die vorgeschlagenen Generatoren nicht nur konsistent die bisherigen Methoden in allen NLG-Domänen übertreffen, sondern auch eine Fähigkeit zeigen, aus einer neuen, unsichtbaren Domäne zu verallgemeinern und aus Multi-Domänen-Datensätzen zu lernen.', 'sq': 'Gjenerimi natyror i gjuhës (NLG) është një komponent kritik në një sistem dialog të folur. Ky artikull paraqet një arkitekturë të kodifikuesit me bazë në rrjetin e përsëritur nervor, në të cilën futet një kodifikues me bazë në LSTM për të zgjedhur, aggreguar elementet semantike prodhuar nga një mekanizëm vëmendjeje mbi elementet e hyrjes dhe për të prodhuar shprehjet e kërkuara. The proposed generator can be jointly trained both sentence planning and surface realization to produce natural language sentences.  Modeli i propozuar u vlerësua gjerësisht në katër grupe të dhënash të ndryshme NLG. Rezultatet eksperimentale treguan se gjeneratorët e propozuar jo vetëm vazhdimisht tejkalojnë metodat e mëparshme anembanë të gjitha domeneve të NLG por tregojnë gjithashtu një aftësi për të gjeneralizuar nga një domen i ri, i padukshëm dhe për të mësuar nga grupet e të dhënave multidomenale.', 'hy': 'Բնական լեզվի ստեղծման (ՆԼԳ) կարևոր բաղադրիչ է խոսվող երկխոսության համակարգում: Այս հոդվածը ներկայացնում է կրկնվող նյարդային ցանցի հիմնված կոդեր-կոդեր ճարտարապետություն, որտեղ ներկայացվում է LSMT հիմնված կոդեր, որպեսզի ընտրեն, համախմբեն սեմանտիկ տարրերը, որոնք արտադրվում են ուշադրության մեխանիզմի միջոցով ներմուծման տարրերի վրա և ստեղծ Առաջարկված գեներատորը կարող է միասին ուսուցանվել նախադասությունների պլանավորման և մակերևույթի իրականացման համար, որպեսզի ստեղծի բնական լեզվի նախադասություններ: Առաջարկված մոդելը մեծամասնությամբ գնահատվել է չորս տարբեր ՆԼԳ տվյալների համակարգերի վրա: Փորձարկվող արդյունքները ցույց տվեցին, որ առաջարկած գեներատորները ոչ միայն համեմատաբար գեներկայացնում են նախորդ մեթոդները բոլոր ՆԼԳ-ի բնագավառներում, այլ նաև ցույց են տալիս ընդհանուր ընդունակությունը նորից, անտեսված բնագավառներից և սովորելու բազմա', 'az': 'Təbiətli dil nəzəriyyəti (NLG) danışılan dijalog sistemində kritik bir komponentdir. Bu kağıt, LSTM tabanlı dekoder arhitektarını seçmək üçün yenidən nöral a ğ tabanlı bir nöral ağ təşkil edir. Bu kağıt seçmək üçün LSTM tabanlı dekoder təşkil edilir, girdi elementlərin üstündə təşkil etmək üçün bir semantik elementi təşkil edir və lazım sözləri təşkil edir. Təbiətli dil cümlələri ürəkləmək üçün təklif edən generator də cümlələr planlaması və üzərində təhsil edilə bilər. Önülləşdirilmiş model dörd müxtəlif NLG veri qurularında geniş değerlendirildi. Müxtəlif sonuçlar göstərdi ki, təbliğ edilmiş generatorlar yalnızca əvvəlki metodları NLG domeinlərin içində istifadə edir, ancaq yeni, görmədiyin domeindən və çoxlu domenin veri setlərindən öyrənməyə qadirlik göstərər.', 'ca': "La generació de llenguatges naturals (NLG) és un component crític en un sistema de diàleg parlat. Aquest article presenta una arquitectura de codificador basada en la xarxa neural recurrent, en la qual s'introdueix un codificador basat en LSTM per seleccionar, agregar elements semàntics produïts per un mecanisme d'atenció sobre els elements d'entrada, i per produir les expressions requerides. El generador proposat pot ser entrenat conjuntament tant a la planificació de frases com a la realizació de la superfície per produir frases de llenguatge natural. El model proposat es va evaluar ampliament en quatre conjunts de dades de NLG. The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets.", 'am': 'የተለመደው ቋንቋ ትውልድ (NLG) በተናገረ ጥያቄ ሲስተም አካባቢ ክፍል ነው። ይህ ገጽ የሆኑት የነዌብ መረብ የኮድ-ዴድድ አካባቢ መሠረት ያቀርባል፡፡ የተዘጋጀው አወራጅ የፊደል ቋንቋ ቃላትን ለመፍጠር እና የመsurface ማስታወቂያውን በመጠቀም ይችላል፡፡ የአራቱ ልዩ የNLG ዳታተሮች ላይ ተዘጋጅቷል፡፡ The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets.', 'et': 'Looduskeele genereerimine (NLG) on kõneleva dialoogi süsteemi kriitiline komponent. Käesolevas töös tutvustatakse korduva neurovõrgu kodeerija-dekooderi arhitektuuri, kus LSTM-põhine dekooder tutvustatakse, et valida, koondada tähelepanumehhanismi abil toodetud semantilisi elemente sisendelementidele ja toota vajalikke väljendeid. Kavandatud generaatorit saab ühiselt koolitada nii lauseplaneerimist kui ka pinnarealiseerimist looduskeelsete lausete loomiseks. Kavandatud mudelit hinnati põhjalikult nelja erineva NLG andmekogumi põhjal. Eksperimentaalsed tulemused näitasid, et kavandatud generaatorid mitte ainult ei suuda järjekindlalt ületada varasemaid meetodeid kõigis NLG domeenides, vaid näitavad ka võimet üldistada uuest, nähtamatust domeenist ja õppida mitme domeeni andmekogumitest.', 'cs': 'Generace přirozeného jazyka (NLG) je klíčovou součástí mluveného dialogového systému. Tento článek představuje architekturu Encoder-Decoder založenou na recidivní neuronové síti, ve které je představen dekodér založený na LSTM pro výběr, agregování sémantických prvků vytvořených mechanismem pozornosti nad vstupními prvky a pro produkci požadovaných výroků. Navržený generátor může být společně trénován jak plánování vět, tak i povrchovou realizaci k produkci vět přirozeného jazyka. Navržený model byl důkladně zhodnocen na čtyřech různých datových sadách NLG. Experimentální výsledky ukázaly, že navržené generátory nejen konzistentně překonávají předchozí metody napříč všemi NLG doménami, ale také ukazují schopnost zobecňovat z nové, neviditelné domény a učit se z multi-doménových datových sad.', 'bs': 'Prirodna generacija jezika (NLG) je kritična komponenta u govorenom dijalogu. Ovaj papir predstavlja rekonstruiranu arhitekturu na osnovu kodera-dekodera Neuralne mreže, u kojoj se uvodi dekoder na osnovu LSTM-a kako bi odabrao, okupljao semantičke elemente proizvođene mehanizam pažnje na ulaznim elementima i proizvodio potrebne izraze. Predloženi generator može biti zajedno obučen planiranjem rečenica i realizacijom površine kako bi proizvela prirodne rečenice jezika. Predloženi model je prošireno procijenjen na četiri različite podatke NLG-a. Eksperimentalni rezultati pokazali su da predloženi generatori ne samo konsekventno iznose prethodne metode u svim domenima NLG, nego također pokazuju sposobnost generalizacije iz novog, nevidjenog domena i naučiti iz višedomenih podataka.', 'fi': 'Luonnonkielen luominen (NLG) on tärkeä osa puhuttua vuoropuhelua. Tässä artikkelissa esitellään toistuvaan hermoverkkoon perustuva kooderi-dekooderiarkkitehtuuri, jossa LSTM-pohjainen dekooderi esitellään huomiomekanismin tuottamien semanttisten elementtien valitsemiseksi, yhdistämiseksi syöttöelementtien päälle ja tarvittavien lausumien tuottamiseksi. Ehdotettu generaattori voidaan yhdessä kouluttaa sekä lausesuunnittelu että pintatoteutus luonnollisen kielen lauseiden tuottamiseksi. Ehdotettua mallia arvioitiin laajasti neljällä eri NLG-aineistolla. Kokeelliset tulokset osoittivat, että ehdotetut generaattorit eivät ainoastaan suoriudu johdonmukaisesti aikaisemmista menetelmistä kaikilla NLG-toimialueilla, vaan myös osoittavat kyvyn yleistyä uudesta näkymättömästä toimialueesta ja oppia monitoimialueisista tietokokonaisuuksista.', 'bn': 'স্বাভাবিক ভাষা প্রজন্ম (NLG) একটি কথোপকথন ডায়ালগ সিস্টেমে একটি গুরুত্বপূর্ণ অংশ। এই পত্রিকাটি পুনরায় নিউরাল নেটওয়ার্কের একটি এনকোডার-ডেকোডারের ভিত্তিক কাঠামো উপস্থাপন করেছে, যেখানে একটি LSTM ভিত্তিক ক কোডার চিহ্নিত করা হয়েছে নির্বাচনের জন্য, যা ইনপুট প্রস্তাবিত জেনারেটর প্রাকৃতিক ভাষার বাক্য তৈরি করার জন্য বাক্য পরিকল্পনা এবং প্রাকৃতিক বাক্য বুঝতে পার প্রস্তাবিত মডেল চারটি ভিন্ন এনএলজি ডাটাসেটে ব্যাপক মূল্যায়ন করা হয়েছে। পরীক্ষার ফলাফল দেখা যাচ্ছে যে প্রস্তাবিত জেনারেটরা শুধুমাত্র পূর্ববর্তী এনএলজি ডোমেনের সারা জুড়ে পূর্ববর্তী পদ্ধতি প্রদর্শন করে না কিন্তু তার', 'jv': "Peringatan kanggo kelas (NLG) iku kompon sing dibenakno ning sistem conversasi. Perintah iki nambah akeh arêtatik yang semanti sing is in é akéwé, sampeyan nambah Unutaan Néural Network sing basan koder-Dekoder, sing isiné diputara basa gambar n' olêter lanjut kanggo mulai, kuwi jenis êteré semanti kuwi nggawe nguasakno perusahaan langgar sampeyan ingkang dilané, lan nggawe sawêt terus nggawe Genjer-Genjer sing paling kelas Jejaring Sayensi Reset to DefaultsShow hidden files", 'he': 'יוצר שפת טבעית (NLG) הוא רכיב קריטי במערכת דיאלוג מדברת. העבודה הזו מציגה ארכיטקטורת קודד-דקודר מבוססת רשת נוירולית מתחזרת, שבה מוצגת קודד מבוסס על LSTM כדי לבחור, לאסוף אלמנטים סמנטיים שנוצרים ע"י מנגנון תשומת לב מעל אלמנטים הכניסה, וליצור את המילים הנדרשים. הגנרטור המוצע יכול להיות מאומן ביחד בתכנית משפטים וגם ביצוע השטח כדי ליצור משפטים שפות טבעיים. המודל המוצע הוערך באופן רחב על ארבעה קבוצות נתונים שונות של NLG. התוצאות הניסיוניים הראו שהגנרטורים המוצעים לא רק עולים באופן קבוע על השיטות הקודמות בכל השטחים של NLG, אלא גם מראים יכולת לגנרליזציה ממשטח חדש, בלתי נראה וללמד ממערכות נתונים רבות תרומות.', 'sk': 'Generacija naravnega jezika (NLG) je ključna komponenta govorjenega dialoga. V prispevku je predstavljena arhitektura Encoder-Dekoder na podlagi ponavljajočega se živčnega omrežja, v kateri je predstavljen sprejemnik na podlagi LSTM za izbiro, združevanje semantičnih elementov, ki jih proizvaja mehanizem pozornosti nad vhodnimi elementi, in za izdelavo zahtevanih izgovorov. Predlagani generator lahko skupaj usposabljamo tako načrtovanje stavkov kot uresničevanje površine za izdelavo stavkov v naravnem jeziku. Predlagani model je bil obsežno ocenjen na štirih različnih naborih podatkov NLG. Eksperimentalni rezultati so pokazali, da predlagani generatorji ne le dosledno presegajo prejšnjih metod v vseh domenah NLG, temveč kažejo tudi sposobnost posploševanja iz nove, nevidne domene in učenja iz večdomenskih podatkovnih nizov.', 'ha': "Kijan harshe na asali (NLG) wani abu ne mai muhimmi cikin tsarin zauren akwatin bayani. Wannan takardar na bãyar da wani ¦akin tsarin Encoder-Deoder na Naural wanda aka Motsa na Naural, a ciki, an introduce wani `kodkoder-Deoder', dõmin a zãɓe, kuma ya kiyaye ƙanshi na semantic wanda aka samar da wani mekaninsa na muhalli kan ƙanshi na inputan, kuma dõmin ya ƙãga maganar da ake ƙayyade. Ana iya ƙidãya wa mai gabatar da shi a haɗa tunkuɗe su ga shirin ayukan da za'a yi mãkirci da kuma ma'anar bakwai dõmin ya zaɓi maganar harshen masu natsuwa. An ƙaddara shirin da aka faɗaɗa shi a kan tsari huɗu daban-daban na NLG. Matarinta na jarrabi ya nuna cewa, zakata masu bukãtawa ba ta iya samar da shiryoyin gaba kawai koda ke cikin duk na NLG guda, kuma yana nuna awon ya ƙiƙiro daga wata shekara na daban, wanda ba'a sani ba, kuma yana karanta daga tsarin danne-tarakin multi-Domen.", 'bo': 'སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་ཀྱི་མ་ལག་ཅིག་ཡིན་པའི་ཆ་ཤས་ཤིག་རེད། This paper presents a Recurrent Neural Network based Encoder-Decoder architecture, in which an LSTM-based decoder is introduced to select, aggregate semantic elements produced by an attention mechanism over the input elements, and to produce the required utterances. དམིགས་འཛུགས་ཀྱི་སྐྱེས་ཚོགས་འདི་ལ་ཚིག་གི་སྒྲིག་འགོད་དང་གདོང་རིས་མཐུན་སྒྲིག་ནི་ཕན་ཚུན་བསྐྱེད་པའི་སྐད དམིགས་འཛུགས་པའི་མ་དབྱིབས་ནི་NLG སྒྲིག་ཆ་འཕྲིན་ཡིག་གཟུགས་རིས་བཞིན་གྲངས་སུ་རྩིས་བཏུབ་བྱས་པ The experimental results showed that the proposed generators not only consistently outperform the previous methods across all the NLG domains but also show an ability to generalize from a new, unseen domain and learn from multi-domain datasets.'}
{'en': 'Graph-based Neural Multi-Document Summarization', 'ar': 'تلخيص عصبي متعدد المستندات قائم على الرسم البياني', 'es': 'Resumen de documentos múltiples neuronales basado en gráficos', 'fr': 'Synthèse neuronale multi-documents basée sur des graphes', 'pt': 'Resumo neural de vários documentos com base em gráfico', 'ja': 'グラフベースのニューラルマルチドキュメントの要約', 'ru': 'Суммирование нейронных множественных документов на основе графов', 'hi': 'ग्राफ-आधारित तंत्रिका बहु-दस्तावेज़ सारांशीकरण', 'zh': '盖图形之神经多文档摘要', 'ga': 'Achoimre Ildhoiciméad Néarach bunaithe ar ghraf', 'ka': 'Name', 'hu': 'Graf alapú, többdokumentumos idegi összefoglaló', 'el': 'Νευρική Σύνοψη πολλαπλών εγγράφων με βάση γραφήματα', 'kk': 'Графикалық негіздеген нейралық көп құжат тұжырымдамасыName', 'lt': 'Grafinis daugiadokumentas', 'mk': 'Сумаризација на неурални мултидокументи базирана на график', 'it': 'Sintesi multi-documento neurale basata su grafici', 'ml': 'ഗ്രാഫ് അടിസ്ഥാനമായ നെയുറല്\u200d പല രേഖയുടെ ചുരുക്കം', 'ms': 'Penapisan Multi-Dokumen Neural Berasas Graf', 'mt': 'Sommarju Multi-Dokument Newrali bbażat fuq grafika', 'mn': 'График суурилсан мэдрэлийн олон-баримт нийлүүлэлт', 'ro': 'Rezumată de mai multe documente neurale bazată pe grafic', 'sr': 'Sažetanje neuroloških višestrukih dokumenta na grafiku', 'no': 'Name', 'pl': 'Podsumowanie wielu dokumentów neuronowych opartych na wykresie', 'sv': 'Grafbaserad neural flerdokumentsammanfattning', 'si': 'ග්\u200dරාෆ් අධාරිත සාමාන්\u200dය විශේෂ විශේෂය', 'so': 'Qoraalka qofka ku saleysan karta ee Neural Multi-Documenti', 'ta': 'வரைபடத்தில் அடிப்படையிலான நெயுரல் பல- ஆவணம் சுருக்கம்', 'ur': 'Graph-based Neural Multi-Document Summarization', 'uz': 'Graph-based Neural Multi-Document Summarization', 'vi': 'Giải thích đa tài liệu', 'bg': 'Графично обобщаване на неврални многодокументи', 'da': 'Grafbaseret neural flerdokumentopsummering', 'nl': 'Grafische neuronale samenvatting van meerdere documenten', 'hr': 'Sažetak neuroloških višestrukih dokumenta na grafiku', 'de': 'Grafenbasierte neuronale Zusammenfassung mehrerer Dokumente', 'id': 'Penapisan Multi-Dokumen Neural Berdasarkan Graf', 'fa': 'جمع\u200cسازی مجدد سند\u200cهای عصبی بر اساس گراف', 'ko': '그림 기반 신경 네트워크 다중 문서 요약', 'sw': 'Ujumbe wa nyaraka nyingi za Neural-based Neural', 'tr': 'Grafik tabanly Däşer-Sened Toplaýyşy', 'af': 'Name', 'sq': 'Përmbledhje e shumëdokumenteve neuronale me bazë në grafik', 'am': 'አቀማመጥ', 'hy': 'Գրաֆի հիմնված նյարդային բազմաթիվ փաստաթղթերի համառոտագրություն', 'az': 'Grafik-tabanlı nöral çox-Dökümət Toplaşdırması', 'bn': 'গ্রাফ ভিত্তিক নিউরাল বহুল নথি সামারিজেশন', 'bs': 'Sažetak neuroloških multidokumenta na grafiku', 'ca': 'Resume neuronal multidocumental basat en gràfics', 'cs': 'Graficky založené neuronové shrnutí více dokumentů', 'et': 'Graafikapõhine neuraalne mitme dokumendi kokkuvõte', 'fi': 'Kaaviopohjainen hermojen monidokumenttien yhteenveto', 'jv': "Menu item to Open 'Search for Open Files' dialog", 'sk': 'Povzetek živčnih večdokumentov na osnovi grafikona', 'ha': 'KCharselect unicode block name', 'he': 'סדרת מסמכים רבים נוירוליות מבוססת על גרפים', 'bo': 'Graph-based Neural Multi-Document Summarization'}
{'en': 'We propose a neural multi-document summarization system that incorporates sentence relation graphs. We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence embeddings obtained from Recurrent Neural Networks as input node features. Through multiple layer-wise propagation, the GCN generates high-level hidden sentence features for salience estimation. We then use a greedy heuristic to extract salient sentences that avoid redundancy. In our experiments on DUC 2004, we consider three types of sentence relation graphs and demonstrate the advantage of combining sentence relations in graphs with the representation power of deep neural networks. Our model improves upon other traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multi-document summarization systems.', 'ar': 'نقترح نظام تلخيص عصبي متعدد المستندات يشتمل على رسوم بيانية لعلاقة الجملة. نحن نستخدم شبكة الرسم البياني التلافيفية (GCN) على الرسوم البيانية للعلاقة ، مع تضمين الجمل التي تم الحصول عليها من الشبكات العصبية المتكررة كميزات عقدة الإدخال. من خلال التكاثر متعدد الطبقات ، يُنشئ GCN ميزات جمل خفية عالية المستوى لتقدير البروز. ثم نستخدم طريقة إرشادية جشعة لاستخراج الجمل البارزة التي تتجنب التكرار. في تجاربنا على DUC 2004 ، نأخذ في الاعتبار ثلاثة أنواع من الرسوم البيانية لعلاقات الجملة ونوضح ميزة الجمع بين علاقات الجملة في الرسوم البيانية مع قوة التمثيل للشبكات العصبية العميقة. يعمل نموذجنا على تحسين الأساليب الاستخراجية التقليدية الأخرى القائمة على الرسم البياني ونموذج تسلسل GRU الفانيليا بدون رسم بياني ، ويحقق نتائج تنافسية مقابل أحدث أنظمة تلخيص متعددة المستندات.', 'fr': "Nous proposons un système de résumé neuronal multi-documents qui intègre des graphes de relation de phrase. Nous utilisons un réseau convolutionnel de graphe (GCN) sur les graphes de relation, avec des intégrations de phrases obtenues à partir de réseaux de neurones récurrents comme entités de nœuds d'entrée. Grâce à la propagation par couches multiples, le GCN génère des caractéristiques de phrases cachées de haut niveau pour l'estimation de la saillance. Nous utilisons ensuite une heuristique gourmande pour extraire des phrases saillantes qui évitent la redondance. Dans nos expériences sur DUC 2004, nous examinons trois types de graphes de relations de phrases et démontrons l'avantage de combiner les relations de phrases dans des graphes avec la puissance de représentation des réseaux neuronaux profonds. Notre modèle améliore les autres approches d'extraction traditionnelles basées sur des graphes et le modèle de séquence GRU standard sans graphe, et il obtient des résultats compétitifs par rapport à d'autres systèmes de synthèse multi-documents de pointe.", 'zh': '发一包句神经多文档摘要系统。 图卷积网络(GCN),销递归神经网络句为输节点特征。 传闻数重,GCN 生高隐显著性度。 然后以贪启发式取免冗余之奇句。 DUC 2004之实验,吾思三句之图,而展其深神经网络之势。 改入旧法,与无图香草GRU序,与诸先进多文档摘要系统有竞争力。', 'es': 'Proponemos un sistema de resumen neuronal de varios documentos que incorpora gráficos de relación de oraciones. Empleamos una Red Convolucional de Gráficos (GCN) en los gráficos de relación, con incrustaciones de oraciones obtenidas de Redes Neuronales Recurrentes como entidades de nodo de entrada. A través de la propagación por capas múltiples, el GCN genera características de oraciones ocultas de alto nivel para la estimación de la prominencia. Luego utilizamos una heurística codiciosa para extraer frases destacadas que eviten la redundancia. En nuestros experimentos en DUC 2004, consideramos tres tipos de gráficos de relación de oraciones y demostramos la ventaja de combinar las relaciones entre oraciones en gráficos con el poder de representación de las redes neuronales profundas. Nuestro modelo mejora otros enfoques extractivos tradicionales basados en gráficos y el modelo de secuencia GRU básico sin gráfico, y logra resultados competitivos en comparación con otros sistemas de resumen de documentos múltiples de última generación.', 'pt': 'Propomos um sistema neural de sumarização multi-documento que incorpora grafos de relação de sentença. Empregamos uma Rede Convolucional de Grafos (GCN) nos grafos de relação, com embeddings de sentenças obtidos de Redes Neurais Recorrentes como recursos de nós de entrada. Por meio de propagação em várias camadas, o GCN gera recursos de sentença oculta de alto nível para estimativa de saliência. Em seguida, usamos uma heurística gulosa para extrair sentenças salientes que evitam redundância. Em nossos experimentos no DUC 2004, consideramos três tipos de grafos de relação de sentença e demonstramos a vantagem de combinar relações de sentença em grafos com o poder de representação de redes neurais profundas. Nosso modelo melhora outras abordagens extrativas baseadas em gráficos tradicionais e o modelo de sequência GRU vanilla sem gráfico, e alcança resultados competitivos em relação a outros sistemas de sumarização de vários documentos de última geração.', 'ja': '文章関係グラフを組み込んだニューラルマルチドキュメントサマリゼーションシステムを提案します。リレーショングラフにはグラフ畳み込みネットワーク（ GCN ）を採用しており、リカレントニューラルネットワークから得られた文の埋め込みを入力ノードの特徴としている。複数のレイヤーごとの伝播を通じて、GCNは、サリエンス推定のための高レベルの隠れた文章機能を生成します。次に、貪欲なヒューリスティックを使用して、冗長性を避ける顕著な文を抽出します。DUC 2004の実験では、3種類の文の関係グラフを検討し、グラフの文の関係と深層ニューラルネットワークの表現力を組み合わせる利点を示しました。当社のモデルは、従来のグラフベースの抽出アプローチとグラフなしのバニラGRUシーケンスモデルを改善し、他の最先端のマルチドキュメント要約システムと競合する結果を実現します。', 'ru': 'Предложена система нейронного многодокументного суммирования, включающая в себя графики отношения предложений. Мы используем Graph Convolutional Network (GCN) на графах отношений, с вложениями предложений, полученными из рекуррентных нейронных сетей в качестве входных признаков узла. Благодаря многоуровневому распространению, GCN генерирует функции скрытых предложений высокого уровня для оценки выраженности. Затем мы используем жадную эвристику для извлечения существенных предложений, которые избегают избыточности. В наших экспериментах на DUC 2004 мы рассматриваем три типа графов отношения предложений и демонстрируем преимущество объединения отношений предложений в графах с репрезентативной мощностью глубоких нейронных сетей. Наша модель улучшает другие традиционные подходы к извлечению на основе графов и модель последовательности ванили GRU без графа, и она достигает конкурентных результатов по сравнению с другими современными системами обобщения нескольких документов.', 'hi': 'हम एक तंत्रिका बहु-दस्तावेज़ सारांशीकरण प्रणाली का प्रस्ताव करते हैं जिसमें वाक्य संबंध रेखांकन शामिल हैं। हम संबंध रेखांकन पर एक ग्राफ कनवल्शनल नेटवर्क (जीसीएन) को नियोजित करते हैं, जिसमें इनपुट नोड सुविधाओं के रूप में आवर्तक तंत्रिका नेटवर्क से प्राप्त वाक्य एम्बेडिंग होते हैं। एकाधिक परत-वार प्रसार के माध्यम से, GCN लचीलापन अनुमान के लिए उच्च-स्तरीय छिपी हुई वाक्य सुविधाओं को उत्पन्न करता है। फिर हम अतिरेक से बचने वाले मुख्य वाक्यों को निकालने के लिए एक लालची ह्यूरिस्टिक का उपयोग करते हैं। DUC 2004 पर हमारे प्रयोगों में, हम तीन प्रकार के वाक्य संबंध रेखांकन पर विचार करते हैं और गहरे तंत्रिका नेटवर्क की प्रतिनिधित्व शक्ति के साथ रेखांकन में वाक्य संबंधों के संयोजन के लाभ का प्रदर्शन करते हैं। हमारा मॉडल अन्य पारंपरिक ग्राफ-आधारित निष्कर्षण दृष्टिकोण और बिना किसी ग्राफ के वेनिला जीआरयू अनुक्रम मॉडल पर सुधार करता है, और यह अन्य अत्याधुनिक बहु-दस्तावेज़ सारांशीकरण प्रणालियों के खिलाफ प्रतिस्पर्धी परिणाम प्राप्त करता है।', 'ga': 'Molaimid córas achoimrithe néarúil ildhoiciméad a ionchorpraíonn graif maidir le habairtí. Bainimid úsáid as Líonra Comhtháite Graf (GCN) ar na graif ghaolmhara, le leabú abairtí a fhaightear ó Líonraí Néaracha Athfhillteacha mar ghnéithe nód ionchuir. Trí iomadú ciseal-ciallmhar, gineann an GCN gnéithe ardleibhéil abairte folaithe chun meastachán a dhéanamh ar shuaimhneas. Bainimid úsáid as heorastúil greedy ansin chun abairtí suntasacha a sheachnaíonn iomarcaíocht a bhaint as. Inár dturgnaimh ar DUC 2004, déanaimid machnamh ar thrí chineál de ghraif choibhneasta abairtí agus léirímid an buntáiste a bhaineann le caidreamh abairtí i ngraif a chomhcheangal le cumhacht ionadaíochta líonraí néaracha doimhne. Feabhsaítear ár samhail ar chuir chuige eastóscacha traidisiúnta eile atá bunaithe ar ghraif agus ar mhúnla seicheamh GRU fanaile gan aon ghraif, agus baintear amach torthaí iomaíocha i gcoinne córais achoimrithe ildhoiciméid eile den scoth.', 'ka': 'ჩვენ შეგიძლიათ ნეიროლური მრავალური დოკუმენტის სისტემა, რომელიც სიტყვების შესახებ გრაფიკების შესახებ დავყენება. ჩვენ გრაფიკური ქსელი (GCN) გამოყენებთ გრაფიკური გრაფიკური გრაფიკური გრაფიკური შესახებ, როგორც გრაფიკური ნეიროლური ქსელებიდან მიიღებული სიტყვების შესახებ. მრავალ მონაცემების გამოყენებით GCN იქნება სილიენციის განსაზღვრებისთვის უფრო მეტი დონე დამატებული სიტყვები. შემდეგ ჩვენ გამოყენებთ წარმოდგენელი ჰერისტიკის გამოყენება, რომლებიც გამოცდილობენ წარმოდგენელობა. ჩვენი ექსპერიმენტებში DUC 2004-ში, ჩვენ ვფიქრობთ სამი ტიპი სიტყვების გრაფიკების შესახებ და გამოსახულება სიტყვების შესახებ გრაფიკში გამოყენებული სიტყვების გამოსახულება, რომე ჩვენი მოდელი სხვა ტრადიციონალური გრაფიკური ექსტრაქტიური მოხმარებისთვის და განილური GRU სერექტიური მოდელზე, რომელიც არაფერი გრაფიკური არსებობს, და ის მიიღება კონსპექტიური შედეგილებ', 'el': 'Προτείνουμε ένα νευρικό σύστημα σύνοψης πολλαπλών εγγράφων που ενσωματώνει γραφήματα σχέσεων προτάσεων. Χρησιμοποιούμε ένα Δίκτυο Σύγκλισης Γραφημάτων (GCN) στα γραφήματα σχέσεων, με ενσωματωμένες προτάσεις που λαμβάνονται από Επαναλαμβανόμενα Νευρικά Δίκτυα ως χαρακτηριστικά κόμβων εισόδου. Μέσω της πολλαπλής διάδοσης στρωμάτων, το GCN παράγει υψηλού επιπέδου κρυφά χαρακτηριστικά προτάσεων για την εκτίμηση της σημασίας. Στη συνέχεια, χρησιμοποιούμε έναν άπληστο heuristic για να εξάγουμε σημαντικές ποινές που αποφεύγουν την περιτροπή. Στα πειράματά μας για το DUC 2004 εξετάζουμε τρεις τύπους γραφικών σχέσεων προτάσεων και καταδεικνύουμε το πλεονέκτημα του συνδυασμού σχέσεων προτάσεων σε γραφήματα με τη δύναμη αναπαράστασης των βαθέων νευρωνικών δικτύων. Το μοντέλο μας βελτιώνεται σε σχέση με άλλες παραδοσιακές εξαγωγικές προσεγγίσεις βασισμένες σε γραφήματα και το μοντέλο ακολουθίας βανίλιας χωρίς γράφημα, και επιτυγχάνει ανταγωνιστικά αποτελέσματα έναντι άλλων υπερσύγχρονων συστημάτων σύνοψης πολλαπλών εγγράφων.', 'hu': 'Javasolunk egy neurális többdokumentumos összefoglaló rendszert, amely magában foglalja a mondatkapcsolat grafikonokat. A kapcsolati grafikonokhoz egy Graph Convolutional Network (GCN) alkalmazunk, amelyet az ismétlődő neurális hálózatokból származó mondatbágyazások bemeneti csomópontként használnak. Többrétegű terjedéssel a GCN magas szintű rejtett mondatfunkciókat generál a kiemelkedő becsléshez. Ezután egy kapzsi heurisztikát használunk, hogy kivonjuk a kiemelkedő mondatokat, amelyek elkerülik a redundanciát. A DUC 2004-es kísérleteinkben három típusú mondatkapcsolat grafikont veszünk figyelembe, és bemutatjuk, hogy milyen előnyös a mondatkapcsolatok grafikonokban való kombinálása a mély neurális hálózatok reprezentációs erejével. Modellünk továbbfejleszti a hagyományos gráf alapú extraktív megközelítéseket és a vanília GRU szekvencia modellt grafikon nélkül, és versenyképes eredményeket ér el más korszerű többdokumentumos összefoglaló rendszerekkel szemben.', 'it': "Proponiamo un sistema neurale di sintesi multi-documento che incorpora grafici di relazione delle frasi. Impieghiamo una Graph Convolutional Network (GCN) sui grafici di relazione, con incorporazioni di frasi ottenute da Recurrent Neural Networks come caratteristiche di nodo di input. Attraverso la propagazione a più livelli, il GCN genera funzioni di frase nascoste di alto livello per la stima della salienza. Usiamo poi un eurista avido per estrarre frasi salienti che evitino ridondanza. Nei nostri esperimenti su DUC 2004, consideriamo tre tipi di grafici di relazione di frase e dimostriamo il vantaggio di combinare le relazioni di frase in grafici con il potere di rappresentazione delle reti neurali profonde. Il nostro modello migliora gli altri approcci estrattivi tradizionali basati su grafici e il modello di sequenza GRU vanilla senza grafico e raggiunge risultati competitivi rispetto ad altri sistemi di sintesi multi-documento all'avanguardia.", 'kk': 'Біз сөздерді графикалық қатынасын қосып тұратын невралдық көп құжатты жазылу жүйесін ұсынамыз. Қосымша графикалық графикалық графикалық графикалық желі (GCN) қолданып, қайталанатын невралдық желілерден ендірілген сөйлемелерді қайталанатын невралдық желілерден ендіру тобының мүмкіндігі Бірнеше қабат жүйесінде пропагациясы арқылы, GCN жасырылған сөздерді бағалау үшін жоғары деңгейінде жасырылады. Содан кейін біз қалқымалықты қалқымалықпен қалқымалы сөйлемелерді шығару үшін сәтті геуристік қолданамыз. 2004 DUC туралы тәжірибелерімізде, үш түрлі сөйлеме графикалық қатынасын қатынасыз және сөйлеме қатынасын графикалық қатынастарды түрлендіру үшін негралық желіктердің күшін көрсетеді. Біздің үлгіміз басқа традиционалды график негіздеген экстрактивті түрде және график жоқ vanilla GRU редакциясының үлгісін жасайды. Ол басқа көп құжатты көптеген жүйелердің көптеген күйіне қарсы жақсы нә', 'lt': 'Siūlome nervinę daugiadokumentę santraukų sistemą, į kurią įtraukiami sakinių santykio grafikai. Ryšių grafikams naudojame Graph Convolutional Network (GCN), kuriame įterpiami sakiniai, gaunami iš kartotinių nervinių tinklų kaip įvesties mazgų savybės. Įvairių sluoksnių atžvilgiu GCN sukuria aukšto lygio paslėptų sakinių savybes, kad būtų galima įvertinti druską. Tada naudosime greedy heuristic, kad ištrauktume tirsius sakinius, kurie išvengtų pertekliaus. Mūsų eksperimentuose dėl DUC 2004, mes svarstome tris sakinių santykių grafikus ir parodome pranašumą derinti sakinių santykius grafikuose su giliųjų nervų tinklų atstovavimo galia. Mūsų modelis tobulinamas taikant kitus tradicinius grafiniu būdu pagrįstus gavybos metodus ir vanilės GRU sekos model į be grafiko, ir jis užtikrina konkurencinius rezultatus, palyginti su kitomis moderniausiomis daugiadokumentėmis suvestinių sistemomis.', 'ms': 'Kami cadangkan sistem pengringkasan multi-dokumen saraf yang mengandungi graf hubungan kalimat. Kami menggunakan Rangkaian Graf Konveolutional (GCN) pada graf hubungan, dengan pembenaman kalimat yang diperoleh dari Rangkaian Neural Sekali-kali sebagai ciri nod input. Melalui pelebaran berbilang lapisan-wise, GCN menghasilkan ciri kalimat tersembunyi tahap tinggi untuk penilaian salience. Kemudian kita menggunakan heuristik serakah untuk mengekstrak kalimat yang salient yang menghindari redundansi. Dalam eksperimen kami pada DUC 2004, kami mempertimbangkan tiga jenis graf hubungan kalimat dan menunjukkan keuntungan menggabungkan hubungan kalimat dalam graf dengan kuasa mewakili rangkaian saraf dalam. Model kami memperbaiki pendekatan ekstraktif tradisional berdasarkan graf lain dan model urutan GRU vanilla tanpa graf, dan ia mencapai keputusan kompetitif terhadap sistem pengringkasan berbilang dokumen yang lain.', 'mk': 'Предложуваме нервен мултидокументарен систем за резултати кој вклучува графики за речениците. Ние употребуваме графска конволуционална мрежа (GCN) на графиките за врски, со вложување на реченици добиени од Рекурентните неврални мрежи како карактеристики на влезниот јазол. Преку многуте слоеви пропагација, ГНК генерира сокриени функции на високо ниво за проценка на ослободувањето. Потоа користиме алчен хеористик за да извлечеме ослободни реченици кои избегнуваат претерување. Во нашите експерименти на ДУК 2004, разгледуваме три видови графики за реченици и ја демонстрираме предноста од комбинацијата на речениците во графиките со застапната моќ на длабоките неурални мрежи. Нашиот модел се подобрува со други традиционални графички екстрактивни пристапи и моделот на ванилска грУ секвенца без граф, и постигнува конкурентни резултати против другите најсовремени мултидокументарни системи за резултати.', 'mt': 'We propose a neural multi-document summarization system that incorporates sentence relation graphs.  Aħna nużaw Netwerk ta’ Konveoluzzjoni Grafika (GCN) fuq il-grafiċi ta’ relazzjoni, b’inkorporazzjonijiet ta’ sentenzi miksuba minn Netwerks Newrali Rikorrenti bħala karatteristiċi tan-nodi ta’ input. Permezz ta’ propagazzjoni b’diversi saffi, il-GCN tiġġenera karatteristiċi ta’ sentenza moħbija ta’ livell għoli għall-istima tas-salienza. Imbagħad a ħna nużaw ħewristika għaqda biex neħħew sentenzi salienti li jevitaw is-sensja. Fl-esperimenti tagħna dwar id-DUC 2004, qed nikkunsidraw tliet tipi ta’ graffi ta’ relazzjoni ta’ sentenzi u qed nippruvaw il-vantaġġ li ngħaqdu r-relazzjonijiet ta’ sentenzi fil-graffi mas-saħħa ta’ rappreżentazzjoni ta’ netwerks newrali profondi. Il-mudell tagħna jtejjeb fuq approċċi estrattivi tradizzjonali oħra bbażati fuq grafika u l-mudell tas-sekwenza tal-GRU vanilla mingħajr grafika, u jikseb riżultati kompetittivi kontra sistemi ta’ sommarju multidokumenti l-aktar avvanzati.', 'ml': 'വാക്കുകളുടെ ബന്ധത്തിന്റെ ഗ്രാഫുകളില്\u200d ചേര്\u200dക്കുന്ന ഒരു പുരുഷന്\u200d പല രേഖകളുടെ ചുരുക്കം സിസ്റ്റം ഞങ്ങള്\u200d പ നമ്മള്\u200d ബന്ധുക്കളുടെ ഗ്രാഫ് കോണ്\u200dവോള്\u200dട്ടോളേഷന്\u200d നെറ്റ്വര്\u200dക്കുകളില്\u200d നിന്നും വാക്കുകള്\u200d ലഭ്യമാക്കിയിരിക്കുന്നു ഒരുപാട് layer-wise പ്രഖ്യാപനത്തിലൂടെ, ജിസിനില്\u200d നിന്നും ഒരുപാട് മറഞ്ഞിരിക്കുന്ന വാക്കിന്റെ വിശേഷത്തിനുള്ള വി പിന്നീട് നമ്മള്\u200d ഒരു ലാഗ്യം ഹെയൂരിസ്റ്റിക്ക് ഉപയോഗിക്കുന്നു. കുറഞ്ഞ വാക്കുകള്\u200d ഒഴിവാക്കുന്ന ഡിയുസി 2004-ലെ നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d നമ്മള്\u200d വാക്കുകളുടെ ബന്ധങ്ങള്\u200d മൂന്നു തരം ഗ്രാഫില്\u200d കൂട്ടിക്കൊണ്ടിരിക്കുന്നു. ആഴത്തെ ന്യൂറല്\u200d നെറ നമ്മുടെ മോഡല്\u200d മറ്റു പാരമ്പര്യമായ ഗ്രാഫ് അടിസ്ഥാനത്തുള്ള വിദ്യാഭാഗങ്ങളിലും വാനില്ലാത്ത GRU സെക്കന്റ് മോഡലിനും മുന്\u200dകൂട്ടുന്നു. ഗ്രാഫ് ഇല്ലാത്ത മാതൃ', 'pl': 'Proponujemy neuronowy system podsumowywania wielu dokumentów, który zawiera wykresy relacji zdań. Na wykresach relacji stosujemy sieć konwolucyjną grafu (GCN), z osadzeniami zdań uzyskanymi z sieci powtarzających się jako cechy węzłów wejściowych. Poprzez wielowarstwową propagację GCN generuje wysokiego poziomu ukryte funkcje zdań dla oszacowania wyraźności. Następnie używamy chciwego heurystyki do wydobycia ważnych zdań, które unikają zbędności. W naszych eksperymentach na DUC 2004 rozważamy trzy rodzaje wykresów relacji zdań i demonstrujemy zaletę łączenia relacji zdań w wykresach z mocą reprezentacji głębokich sieci neuronowych. Nasz model ulepsza inne tradycyjne podejścia ekstrakcyjne oparte na wykresie oraz model sekwencji waniliowej GRU bez wykresu i osiąga konkurencyjne wyniki w stosunku do innych najnowocześniejszych systemów podsumowywania wielu dokumentów.', 'mn': 'Бид мэдрэлийн олон баримт дурангуудын системийг санал болгож өгүүлбэр графикийн харилцааны холбоотой. Бид харилцааны графикийн график дээр график конвольционал сүлжээ (GCN) хэрэглэдэг. Дахин дахин мэдрэлийн сүлжээний шинж тэмдэглэгдсэн өгүүлбэрээс гаргасан өгүүлбэртэй. Гэхдээ олон давхар давхар хөгжүүлэхээр GCN нь салбарын тооцоололтын тулд өндөр түвшинд нуугдааг өгүүлбэрийг бий болгодог. Дараа нь бид дутуу хэмжээсүүдийг гаргахын тулд цэвэрхэн хэлбэрийг ашигладаг. 2004 оны ДУК-ын туршилтанд бид 3 төрлийн өгүүлбэрийн харилцааны график болон өгүүлбэрийн харилцааны талаар графикийн харилцааны тусламжтай харилцааны ашиг харуулж байна. Бидний загвар нь бусад уламжлалт график дээр суурилсан нэмэлт арга загваруудыг, график байхгүй vanilla GRU дарааллын загваруудыг сайжруулдаг. Энэ нь бусад олон урлагийн олон баримт дүгнэлтийн системийн эсрэг өрсөлдөөн үр дүнг гарга', 'no': 'Vi foreslår eit neiralt multidokumentsamanseringssystem som inkluderer setningsstyrke med graf. Vi bruker eit graf-konvolusjonell nettverk (GCN) på relasjonsgrafikk, med setningar som er inntekne frå gjentaande neiralnettverk som inntaksnittfunksjonar. Gjennomsiktige setningar i høg nivå gjer GCN med fleire lagsvising. Vi bruker derfor ein grød heuristisk for å pakka ut salient setningar som unngår redundans. I våre eksperimenter på DUC 2004, ser vi på tre typar setningsrunksjonsgraf og demonstrerer fordelen til å kombinere setningsrunksjonar i grafikk med representasjonstyrken på dype neuralnettverk. Modellen vårt forbetrar på andre tradisjonelle grafikkbaserte ekstraktiv tilnærmingar og vanylige GRU-sekvensmodellen utan ingen graf, og den oppnår konkurrentiv resultat mot andre sammendragssystemer for multidokument.', 'ro': 'Propunem un sistem neural de sintetizare multi-documente care încorporează grafice de relații cu fraze. Utilizăm o Rețea Convoluțională Grafică (GCN) pe graficele de relații, cu încorporări de propoziții obținute din Rețelele Neurale Recurente ca caracteristici ale nodului de intrare. Prin propagarea mai multor straturi, GCN generează caracteristici ascunse de nivel înalt pentru estimarea salienței. Apoi folosim un eurist lacom pentru a extrage propoziții importante care evită redundanța. În experimentele noastre pe DUC 2004, luăm în considerare trei tipuri de grafice de relații de propoziții și demonstrăm avantajul combinării relațiilor de propoziții în grafice cu puterea de reprezentare a rețelelor neuronale profunde. Modelul nostru îmbunătățește alte abordări extractive tradiționale bazate pe grafice și modelul secvenței GRU vanilie fără grafic și obține rezultate competitive față de alte sisteme de rezumare multi-document de ultimă generație.', 'sr': 'Predlažemo nervni sistem za sažetak multidokumenta koji uključuje grafike veze rečenica. Koristimo konvolucionalnu mrežu grafika (GCN) na grafiku veze, sa ugrađenim rečenicama koje su dobile od ponovnih neuronskih mreža kao karakteristike ulaznog čvora. Kroz višestruku propagaciju na slojevima, GCN stvara skrivenu rečenicu na visokom nivou za procjenu salijencije. Onda koristimo pohlepnu heuristiku da izvučemo salijene rečenice koje izbjegavaju redundanciju. U našim eksperimentima o DUC 2004, razmišljamo o tri vrste odnosa rečenica i pokazujemo prednost kombinacije odnosa rečenica u graficima sa predstavljanjem moći dubokih neuralnih mreža. Naš model se poboljšava na drugim tradicionalnim ekstraktivnim pristupima na grafiku i modelu sekvence vanile GRU bez grafika, i postiže konkurentni rezultati protiv drugih sistema sažetanja multidokumenta stanja.', 'si': 'අපි ප්\u200dරයෝජනය කරන්නේ වාර්තාව සම්බන්ධ විධානයක් සම්බන්ධ වෙන්න. අපි ග්\u200dරාෆ් සම්බන්ධ ජාලය (GCN) සම්බන්ධ ග්\u200dරාෆ් එකක් භාවිත කරනවා, වාක්ය සම්බන්ධ කරනවා, ආයෙත් න්\u200dයුරල් ජාලයෙන් ඇත ගොඩක් ස්ථානයෙන් ප්\u200dරවේශනය සඳහා, GCN නිර්මාණය විශේෂ විශේෂය සඳහා උපස්ථානයෙන් හැංගුණු වාක් ඊට පස්සේ අපි ප්\u200dරයෝජනයක් පාවිච්චි කරනවා ප්\u200dරයෝජනයක් ප්\u200dරයෝජනය කරනවා කියලා. අපේ පරීක්ෂණයේ DUC 2004 වලින්, අපි වාක්ෂා තුන් වර්ගයක් ග්\u200dරාෆ් වලින් සම්බන්ධතා කරනවා ඒ වගේම වාක්ෂා සම්බන්ධතාවක් සංමුණු  අපේ මොඩල් අනුවෙන් සාමාන්\u200dය ග්\u200dරාෆ් අධාරිත විසින් ප්\u200dරවේශනය සහ වැනිල්ලා GRU ක්\u200dරමාණ මදුල්ය නැති විසින් විසින් විසින් ප්\u200dරවේශනය ව', 'so': "Waxaynu soo jeedaynaa nidaamka qorsheynta qoraalka kala duduwan oo neurada ah oo ku qoran xarumo xiriir ah. Waxaynu ku shaqaynaynaa shabakadda xariirka (GCN) ee ku saabsan sawirada xariirka, waxaana lagu soo bandhigayaa ciqaab ka soo galay shabakadda Neural Network (Recurrent Neural Network), sida xarumo ah input node. Through multiple layer-wise propagation, the GCN generates high-level hidden sentence features for salience estimation.  Markaas waxaynu isticmaalnaa sharaf faa'iido ah si aan u soo bixino ciqaab salitaan oo ka fogaaday wax yar. Imtixaanadeena DUC 2004, waxaan ka fiirsanaynaa saddex nooc oo kala duduwan xarunta xafiiska, waxaana muujinaynaa faa'iidada ku xiriira xiriirka furashada ee xarumaha iyo xuquuqda xubinta shabakada neurada ee mool dheer. Tusaalkayaga ayaa horumarinaya hababka kale ee lagu soo saaray xarunta iyo tusaalaha kale ee asalka ah ee vanilla GRU oo aan la arag lahayn, wuxuuna helaa resultooyin tartanka ah oo ka gees ah nidaamka qoraalka kala duduwan.", 'sv': 'Vi föreslår ett neuralt multi-dokument sammanfattningssystem som innehåller meningsrelationsgrafer. Vi använder ett Graph Convolutional Network (GCN) på relationsgraferna, med meningsinbäddningar erhållna från återkommande neurala nätverk som inmatningsnodfunktioner. Genom flerskiktsmässig spridning genererar GCN dolda meningsfunktioner på hög nivå för saliensuppskattning. Vi använder sedan en girig heuristisk för att extrahera viktiga meningar som undviker redundans. I våra experiment på DUC 2004 betraktar vi tre typer av meningsrelationsgrafer och visar fördelen med att kombinera meningsrelationer i grafer med representationskraften hos djupa neurala nätverk. Vår modell förbättrar mot andra traditionella grafbaserade extraktionsmetoder och vanilj GRU sekvensmodellen utan diagram, och den uppnår konkurrenskraftiga resultat mot andra state-of-the-art multi-document summering system.', 'ta': 'நாம் ஒரு புதிய பல ஆவணங்கள் சுருக்கல் அமைப்பை பரிந்துரைக்கிறோம் வாக்கு தொடர்பு வரைப்படங்களை சேர்க்கிறது. நாங்கள் தொடர்பு வரைபடங்கள் மீது ஒரு வரைப்படத்தின் தொடர்பு பிணையத்தை பயன்படுத்துகிறோம், மறுநிகழ்ந்த நியூரால் வலைப்பின்னலிலிருந்து பெ பல அடுக்கு விளக்கம் மூலம் GCN விளக்கத்திற்கு உயர்நிலையில் மறைந்த வாக்கியத்தின் குணங்களை உருவாக்குகிறது. பின்னர் குறைவு தவிர்க்கும் வாக்கியங்களை வெளியேற்ற ஒரு பெரும் பொருள் உபயோகிக்கிறோம். டியூசி 2004-ல் எங்கள் சோதனைகளில், நாம் மூன்று வகையான வாக்கு இணைப்பு வரைபடங்களில் வாக்கு தொடர்புகளை ஒன்று சேர்க்க வேண்டும் ஆழமான புதிய பிணை Our model improves upon other traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multi-document summarization systems.', 'ur': 'ہم ایک نئورل multi-document summarization system کی پیشنهاد کرتے ہیں جو sentence relation graphs شامل ہوتی ہے. ہم رابطہ گراف پر ایک گراف کنویروشن نیٹ ورک (GCN) کو استعمال کرتے ہیں، اس کے ساتھ مجددا نیورال نیٹ ورک سے اینپیٹ نوڈ فوکتورک بناتے ہیں۔ بہت سی لائر-سمندر پراپاژن کے ذریعہ، GCN نے سیلینس ارزیابی کے لئے بلند سطح چھپا ہوا جماعت ویٹیوں کو پیدا کیا ہے. پھر ہم ایک گھوٹی آہستگی کا استعمال کریں گے کہ ایک دوسرے سے بچتے ہیں ہمارے DUC 2004 کی آزمائش میں، ہم نے تین قسم کا فیصلہ گراف کے ارتباط کا نظر رکھا ہے اور فیصلہ کے ارتباط کا فائدہ دکھاتے ہیں گراف میں جہنم نیورل نیورل نیٹورک کی روشن قدرت کے ساتھ۔ ہماری مدل دوسری سنتی گراف بنیادی اخلاقی طریقے پر اور vanilla GRU sequence مدل کے بغیر گراف کے، اور یہ دوسری حالت-آرت multi-document summarization سیستم کے مقابلہ میں مساوی نتائج پہنچتا ہے.', 'uz': "Biz bir necha hujjat hisobotini tahrirlash tizimini tahrirlash talab qilamiz. Bu so'zlar murojaat grafiklarini birlashtiradi. @ info: status @ info Keyin biz cheksizlikni olib tashlash uchun qo'llanmiz. 2004-yildan DUC-yillarda biz uch xil munosabatlar grafiklarini tasavvur qilamiz va grammatika murakkab munosabatlarni birlashtirish imkoniyatini ko'rsatamiz va juda yaxshi neyron tarmoqlarining kuchini tashqarish imkoniyatini ko'rsatamiz. Bizning modelimiz boshqa tabiiy grafik asosida ekstraktiv usullar va vanillar GRU sequence modeli yordam beradi, va bu boshqa dokumenta bir xil muhitiyat tizimlariga rivojlantirish natijalarini bajaradi.", 'vi': 'Chúng tôi đề xuất hệ thống tóm tắt tập tin đa tài liệu thần kinh chứa các biểu đồ liên quan câu chữ. Chúng tôi sử dụng mạng lưới hình sự có kết quả (GCN) về các biểu đồ tương quan, với sự nhúng câu được lấy từ các mạng thần kinh phục hồi theo lệ nhập. Qua việc rải nhiều lớp, GCN tạo ra các tính năng bị cấm cao cấp để đánh giá độ nổi bật. Sau đó chúng tôi sử dụng một chế độ thần kinh tham lam để trích ra những câu hỏi lớn tránh dự phòng. Trong các thí nghiệm của chúng tôi về rạch ròi, chúng tôi xem xét ba loại hình liên quan đến các bản án và thể hiện lợi thế của việc kết hợp các bản án trong biểu đồ với sức mạnh đại diện của các mạng thần kinh sâu. Mô hình của chúng tôi cải thiện cách tiếp cận khai thác đồ thị truyền thống và mô hình chuỗi GRU vani không có đồ thị, và nó đạt kết quả cạnh tranh với các hệ thống tổng kết nhiều tài liệu hiện đại.', 'bg': 'Предлагаме невронна мултидокументална система за обобщаване, която включва графики за отношенията на изреченията. Използваме Графична конвелуционна мрежа (ГНС) върху релационните графики, с вграждане на изречения, получени от повтарящи се неврални мрежи като входни елементи. Чрез многослойно разпространение GCN генерира скрити изречения на високо ниво за оценка на видимостта. След това използваме алчна евристика, за да извлечем ясни изречения, които избягват излишните. В нашите експерименти с ДУК 2004 разглеждаме три типа графични релации на изречения и демонстрираме предимството на комбинирането на релации на изречения в графики с представителната сила на дълбоки невронни мрежи. Нашият модел подобрява други традиционни графични екстрактивни подходи и ваниловия модел на последователност без графика и постига конкурентни резултати спрямо други съвременни системи за обобщаване на множество документи.', 'nl': 'We stellen een neuraal multi-document samenvattingssysteem voor dat zinsrelatiegrafieken bevat. We gebruiken een Graph Convolutional Network (GCN) op de relatiegrafieken, met zinsinsluitingen verkregen uit Recurrent Neural Networks als input node features. Door middel van meerdere lagen verspreiding genereert de GCN verborgen zinnenfuncties op hoog niveau voor saliëntieschatting. We gebruiken dan een hebzuchtige heuristiek om opvallende zinnen te extraheren die overbodigheid voorkomen. In onze experimenten met DUC 2004 bekijken we drie soorten zinnenverhoudingsgraffen en demonstreren we het voordeel van het combineren van zinnenverhoudingen in grafieken met de representatiekracht van diepe neurale netwerken. Ons model verbetert andere traditionele grafiekgebaseerde extractieve benaderingen en het vanille GRU-sequentiemodel zonder grafiek, en het bereikt concurrerende resultaten ten opzichte van andere state-of-the-art multi-document samenvattingssystemen.', 'hr': 'Predlažemo sistem za sažetak neuralnih višestrukih dokumenta koji uključuje grafike veze rečenica. Upotrijebimo konvolucionalnu mrežu grafika (GCN) o graficima veze s ugrađenim rečenicama iz ponovnih neuronskih mreža kao karakteristike ulaznog čvora. Kroz višestruku propagaciju na slojima, GCN stvara skrivenu rečenicu na visokoj razini za procjenu salijencije. Onda koristimo pohlepnu heurističku rečenicu da izvučemo salijente rečenice koje izbjegavaju redundanciju. U našim eksperimentima o DUC 2004, razmišljamo o tri vrsta rečenica o grafiku veze i pokazujemo prednost kombinacije odnosa rečenica u graficima s predstavljanjem moći dubokih neuralnih mreža. Naš model se poboljšava na drugim tradicionalnim ekstraktivnim pristupima na grafiku i modelu sekvence vanilla GRU bez grafika, i postiže konkurentni rezultati protiv drugih sustava za sažetak multidokumenta.', 'da': 'Vi foreslår et neuralt multi-dokument opsummeringssystem, der inkorporerer sætningsforhold grafer. Vi anvender et Graph Convolutional Network (GCN) på relationsgraferne, med sætningsindlejringer opnået fra Recurrent Neural Networks som input node funktioner. Gennem flere lag-vis udbredelse genererer GCN skjulte sætningsfunktioner på højt niveau til fremhævelsesestimering. Vi bruger derefter en grådig heurist til at udtrække vigtige sætninger, der undgår redundans. I vores eksperimenter med DUC 2004 overvejer vi tre typer sætningsrelationsgrafer og demonstrerer fordelen ved at kombinere sætningsrelationer i grafer med repræsentationsstyrken af dybe neurale netværk. Vores model forbedrer andre traditionelle grafbaserede ekstraktive tilgange og vanilje GRU sekvensmodellen uden graf, og den opnår konkurrencedygtige resultater i forhold til andre state-of-the-art multi-dokument opsummering systemer.', 'de': 'Wir schlagen ein neuronales Mehrdokumentensystem vor, das Satzrelationsgraphen enthält. Wir verwenden ein Graph Convolutional Network (GCN) auf den Beziehungsgraphen, wobei Satzbedlungen aus wiederkehrenden neuronalen Netzwerken als Eingabeknotenmerkmale erhalten werden. Durch die mehrschichtige Ausbreitung generiert das GCN hochrangige versteckte Satzmerkmale für die Salienzschätzung. Wir verwenden dann eine gierige Heuristik, um markante Sätze zu extrahieren, die Redundanz vermeiden. In unseren Experimenten zu DUC 2004 betrachten wir drei Arten von Satzrelationsgraphen und demonstrieren den Vorteil, Satzrelationen in Graphen mit der Darstellungskraft tiefer neuronaler Netze zu kombinieren. Unser Modell verbessert andere herkömmliche graphenbasierte extraktive Ansätze und das vanille GRU Sequenzmodell ohne Graph und erzielt wettbewerbsfähige Ergebnisse gegenüber anderen hochmodernen Multi-Document Summaryzation Systemen.', 'id': 'Kami mengusulkan sistem penghasilan multidokumen saraf yang mengandung grafik hubungan kalimat. Kami menggunakan jaringan konvolusi Graph (GCN) pada grafik hubungan, dengan penempatan kalimat yang diperoleh dari jaringan neural yang berkembang sebagai fitur node input. Melalui propagasi berbilang lapisan-wise, GCN menghasilkan fitur kalimat tersembunyi tingkat tinggi untuk penilaian saliensi. Kemudian kita menggunakan heuristik serakah untuk mengekstrak kalimat salient yang menghindari redundansi. Dalam eksperimen kami pada DUC 2004, kami mempertimbangkan tiga jenis grafik hubungan kalimat dan menunjukkan keuntungan dari menggabungkan hubungan kalimat dalam grafik dengan kekuatan representatif jaringan saraf dalam. Our model improves upon other traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multi-document summarization systems.', 'fa': 'ما یک سیستم جمع کردن سند\u200cهای مختلف عصبی را پیشنهاد می\u200cکنیم که رابطه\u200cهای جمله\u200cها را جمع می\u200cکند. ما از شبکه\u200cهای مجموعه گراف (GCN) در گراف ارتباط استفاده می\u200cکنیم، با جمله\u200cهای مجموعه\u200cای که از شبکه\u200cهای عصبی دوباره به عنوان ویژه\u200cهای گراف وارد شده\u200cاند. از طریق گسترش بسیاری به سمت طبقه\u200cای، GCN ویژگی\u200cهای مخفی در طبقه بالا برای ارزیابی قابل تولید می\u200cکند. بعدش از یک حوریست آرامش استفاده می کنیم تا جمله\u200cهای آرامش را خارج کنیم که از سرعت دور می\u200cشوند. در آزمایشات ما در DUC ۲۰۰۴، ما سه نوع نسبت به گرافیک\u200cهای جمله را در نظر می\u200cگیریم و سودی از ترکیب رابطه\u200cهای جمله در گرافیک\u200cها با قدرت نمایش شبکه\u200cهای عصبی عمیق را نشان می\u200cدهیم. مدل ما بر روی دیگر دستورات خارج از گراف سنتی و مدل دستورات GRU vanilla بدون گراف بهتر می شود و نتیجه رقابتی در مقابل دیگر سیستم جمع کردن مدل های زیادی از هنر را می رساند.', 'ko': '우리는 문장 관계도를 포함하는 신경 다중 문서 요약 시스템을 제시했다.우리는 관계도에 도권적 네트워크(GCN)를 사용하여 귀속신경 네트워크에서 얻은 문장을 입력 노드의 특징으로 삽입했다.다중 전파를 통해 GCN은 고급 숨겨진 문장 특징을 생성하여 현저한 평가에 사용한다.그리고 우리는 탐욕스러운 계발식 방법을 사용하여 쓸데없는 현저한 문장을 추출한다.DUC 2004에서의 실험에서 우리는 세 가지 유형의 문장 관계도를 고려했고 그림 속의 문장 관계와 심도 신경 네트워크의 표현 능력을 결합시키는 장점을 보여 주었다.우리의 모델은 다른 전통적인 그림 기반 추출 방법과 그림이 없는 vanilla-GRU 서열 모델을 개선하고 다른 가장 선진적인 다중 문서 요약 시스템에 비해 경쟁력 있는 결과를 얻었다.', 'sw': 'Tunazipendekeza mfumo wa muhtasari wa nyaraka za kidini ambao unajumuisha picha za kuhusiana na hukumu. Tunatumia Mtandao wa Kujitoleza Graph (GCN) kuhusu picha za mahusiano, kwa hukumu zilizopatikana kutoka kwenye mitandao ya Neural ya hivi karibuni kama vipengele vya habari. Kupitia propaganda kwa vipande kadhaa, GCN inatengeneza hukumu yenye kiwango cha juu zilizofichikana kwa ajili ya estimation ya usawa. Kisha tunatumia hekima yenye umasikini ili kuondoa hukumu za mauzi ambazo huepuka kupungua. In our experiments on DUC 2004, we consider three types of sentence relation graphs and demonstrate the advantage of combining sentence relations in graphs with the representation power of deep neural networks.  Mfano wetu unaboresha juu ya mbinu nyingine za kitamaduni za kutengenezwa na mfumo wa mfumo wa mfululizo wa bure wa GRU bila picha, na unapata matokeo ya ushindani dhidi ya mfumo wa muhtasari wa dokumentari nyingine wa sanaa.', 'af': "Ons voorstel 'n neurale multi-dokument opsomming stelsel wat saam verwanting grafieke inkorpreer. Ons gebruik 'n Grafiese Konvolusionele Netwerk (GCN) op die verwanting grafieke, met setinge inbettings ontvang van Herhaalde Neurale Netwerke as invoer node funksies. Deur veelvuldige laagwyse propagasie genereer die GCN hoë vlak verborge setingsfunksies vir saliensestimatie. Ons gebruik dan 'n groet heuristies om salient setings uit te trek wat oorvloedigheid vervaar. In ons eksperimente op DUC 2004, dink ons drie tipes setningsraak van grafieke en wys die voordeel van die kombinasie van setningsraakte in grafieke met die verteenwoordingskrag van diep neuralnetwerke. Ons model verbeter op ander tradisionele graf-gebaseerde ekstraktiewe toegange en die vanilla GRU-sekwensiemodel met geen graf nie, en dit bereik mededingste resultate teen ander staat-van-die-kuns multi-dokumentopsomming stelsels.", 'tr': 'Biz senediň grafiklerinde baglanmasyny dahil etmek üçin näyral bir multi-sened toplanty sistemini teklip edip görýäris. Biz grafik howply grafiklerde Grafik ködlemeleri (GCN) işleýäris GCN birnäçe gatlak döwletlerinden çykyş bolup geçirmek üçin ýokary dereje ýigry sözlem üýtgedir. Sonra çykarmakdan çykarmak üçin ýumursuz bir heuristik sözleri çykarmak üçin ulanýarys. DUC 2004-nji ýyldaky deneylerimizde, biz 3 tür sözlem grafikleri bilen baglaşyklaryň grafiklerinde sözlem baglaşyklaryny grafiklerde bir baglaşyk bilen tanyşyklaryň güýjüni görkeýäris. Biziň modelimiz beýleki däpli grafik tabanly ekstra ýagdaýlaryň üstüne gelişýär we ol grafik bolmasa vanilla GRU terjime nusgasyny we başga möhüm-sanat multi-sened terjime sistemalaryna garşy çykýar.', 'sq': 'Ne propozojmë një sistem të përmbledhjes nervore me shumë dokumente që përfshin grafikë të lidhjes me fjalët. We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence embeddings obtained from Recurrent Neural Networks as input node features.  Nëpërmjet përhapjes së nivelit të shumtë, GCN gjeneron karakteristika të fjalëve të fshehta të nivelit të lartë për vlerësimin e saliencës. Pastaj përdorim një heuristik lakmues për të nxjerrë fjalë të thella që shmangen redundancës. Në eksperimentet tona në DUC 2004, ne konsiderojmë tre lloje grafike të lidhjes me fjalët dhe demonstrojmë përparësinë e kombinimit të marrëdhënieve me fjalët në grafikë me fuqinë përfaqësuese të rrjeteve nervore të thella. Modeli ynë përmirësohet në metodat e tjera ekstraktive tradicionale bazuar në grafik dhe modelin e sekuencës së vanilës GRU pa grafik dhe arrin rezultate konkurruese kundër sistemeve të tjera të përmbledhjes së shumëdokumenteve.', 'am': 'የሥርዓት ግንኙነት ግንኙነትን የሚጨምር የብዙዎች የሰነድ አቀማመጥ ሲስተም እናሳልቃለን፡፡ የግንኙነት ቀረበቶች (GCN) የተጠቃሚ የግንኙነት መረብ እናስገድዳለን፡፡ በሁለት ደረጃዎች በጥበብ አካሄድ GCN የደረጃ ደረጃ የተሰወረውን የደረጃ ግንኙነት ለባህላዊ አካባቢ ማሳየት ነው፡፡ ከዚህም በኋላ የዋጋ አርስቲክ ክፍሎችን ለማውጣት እናስቀምጣለን፡፡ በዲዩሲ 2004 ፈተናዎች ውስጥ ሦስት ዓይነት የፍርድ ግንኙነት ቀረጽ እናስታውቃለን እና የፍርድ ግንኙነትን በግራፎች ውስጥ የጥልቅ የናውሬው መረብ ኃይል እናሳያልን፡፡ ሞዴሌያችን በሌላ ባሕላዊ ግንኙነት የግራፊ ውጤት እና የvaniላ GRU sequence ሞዴል በማይሻለል፣ እናም በሌላ ሀገራት በብዙ-አካል የሰነድ አካባቢ ክፍል ላይ ፍሬዎችን ያገኛል፡፡', 'az': 'Biz cümlələrlə bağlantılı grafikləri içərisində olan nöral çox-belə qurğulu sistemi təklif edirik. Biz Grafik Convolutional Network (GCN) ilə bağlantı grafiklərində istifadə edirik, yenidən Nüral Netiklərindən giriş düyünün fərqli olaraq alınan cümlələrlə birlikdə istifadə edirik. Çoxlu səviyyə tərzində genişlənmək üçün GCN yüksək səviyyədə gizli cümlələr tərzlərini salınmaq üçün yaradır. Sonra çoxluğundan çəkinməkdən çəkinən süslü cümlələri çıxartmaq üçün arxayınlı bir heuristik istifadə edirik. DUC 2004-ci təcrübələrimizdə, üç cümlənin grafikləri barəsində düşünürük və cümlələr ilişkilerini Grafiklərdə qarşılaşdırmağa faydası göstəririk. Bizim modellərimiz digər cümmətli grafik tabanlı ekstraktif tərzlərinə və vanilla GRU sequence modelini grafik olmadan daha yaxşılaşdırır və bu, digər cümmətli məlumat sistemi ilə müqayisədə müqayisədə sonuçlarını başa çatdırır.', 'hy': 'Մենք առաջարկում ենք նյարդային բազմաթիվ փաստաթղթերի համառոտագրման համակարգ, որը ներառում է նախադասությունների հարաբերության գրաֆիկներ: Մենք օգտագործում ենք Գրաֆ հակառակցման ցանց (GNC) հարաբերությունների գրաֆիկներում, որտեղ նախադասությունների ներդրումները ստացվում են Հիմացած Նյարդային ցանցերից որպես ներդրման կետի հատկություններ: Through multiple layer-wise propagation, the GCN generates high-level hidden sentence features for salience estimation.  Այնուհետև մենք օգտագործում ենք գաղտնի հյուրիստիկ, որպեսզի դուրս բերենք լուրջ նախադասություններ, որոնք խուսափեցնում են անհրաժեշտության: 2004 թվականի ընթացքում մենք դիտարկում ենք նախադասությունների երեք տեսակի գրաֆիկներ և ցույց ենք տալիս նախադասությունների հարաբերությունները գրաֆիկներում համադրելու առավելությունը խորը նյարդային ցանցերի ներկայացուցման ուժի հետ: Մեր մոդելը բարելավվում է այլ ավանդական գրաֆիկով հիմնված արտադրողական մոտեցումների և վանիլայի GRU-ի հաջորդականության մոդելի վրա առանց գրաֆիկի, և այն հասնում է մրցակցության արդյունքների, հակառակ մյուս բարձրագույն բազմաթղթերի համառոտագրման համակար', 'bn': 'আমরা একটি নিউরেল ডকুমেন্টের সারসংক্ষিপ্ত সিস্টেম প্রস্তাব করি যা শাস্তি সম্পর্কের গ্রাফের মধ্যে যুক্ত করে। সম্পর্কের গ্রাফ কনভোলেশনেশন নেটওয়ার্ক (জিসিনি) সম্পর্কের উপর আমরা একটি গ্রাফ কনভোলেশনাল নেটওয়ার্ক চাকরি করি, পুনরায় নিউরাল নেটওয়ার্ক থেকে প্ বেশ কয়েকটি স্তরের বিজ্ঞান প্রচারণার মাধ্যমে জিসিনি বিশেষ হিসেবে লুকিয়ে রাখা উচ্চপর্যের বাক্যের বৈশিষ্ট্যের ব তারপর আমরা একটি লোভী হারিস্টিক ব্যবহার করি যাতে সেলিয়েন্টের শাস্তি বের করে আনা যায় যেটা ক্ষতিগ্রস্ত থেকে  ডিউসি ২০০৪-এ আমাদের পরীক্ষায়, আমরা তিনটি ধরনের রায়ের সম্পর্ক গ্রাফ বিবেচনা করি এবং গভীর নিউরেল নেটওয়ার্কের প্রতিনিধিত্বের ক্ষমতার সাথে গ্রা আমাদের মডেল অন্যান্য ঐতিহ্যবাহী গ্রাফ ভিত্তিক ক্ষেত্রে বেরিয়ে যাচ্ছে এবং ভ্যানিলা জিআরউ সেকেন্স মডেল কোন গ্রাফ ছাড়া আর এটি প্রতিযোগিতার ফলাফল অর্জন করে যা', 'bs': 'Predlažemo nervni sistem za sažetak multidokumenta koji uključuje grafike veze rečenica. Mi koristimo konvolucionalnu mrežu grafika (GCN) o graficima veze, sa ugrađenim rečenicama koje su dobile od ponovnih neuronskih mreža kao funkcije ulaznog čvora. Kroz višestruku propagaciju, GCN stvara skrivenu rečenicu na visokom nivou za procjenu salijencije. Onda koristimo pohlepnu heuristiku da izvučemo salijene rečenice koje izbjegavaju redundaciju. U našim eksperimentima o DUC 2004, razmišljamo o tri vrsta odnosa rečenica i pokazujemo prednost kombinacije odnosa rečenica u graficima sa predstavljanjem moći dubokih neuralnih mreža. Naš model se poboljšava na drugim tradicionalnim ekstraktivnim pristupima na grafiku i modelu sekvence vanila GRU bez grafika, i postiže konkurentni rezultati protiv drugih sustava za sažetak multidokumenta.', 'ca': "Proposem un sistema neural de resum multidocumental que incorpore gràfics de relació de frases. Empreguem una xarxa gráfica de conversió (GCN) en els gràfics de relació, amb incorporacions de frases obtingudes de les xarxes neurals recurrents com característiques del nodre d'entrada. A través de multiples capes de propagació, el GCN genera característiques de frases amagades de alt nivell per estimar la saliència. Després fem servir una heurística ganada per extrair frases salients que evitan redundancia. En els nostres experiments de DUC 2004, considerem tres tipus de gràfics de relació de frases i demostrem l'avantatge de combinar les relacions de frases en gràfics amb el poder de representació de les xarxes neuronales profundes. El nostre model millora amb altres enfocaments extractius tradicionals basats en gràfics i el model de seqüència GRU de vanilla sense gràfics, i aconsegueix resultats competitius en comparació amb altres sistemes de resume multidocumental d'última generació.", 'cs': 'Navrhujeme neuronový multi-dokumentový souhrnný systém, který obsahuje grafy vztahů vět. Na vztahových grafech používáme grafovou konveluční síť (GCN) s větami získanými z recidivních neuronových sítí jako prvky vstupních uzlů. Prostřednictvím šíření více vrstev generuje GCN skryté věty na vysoké úrovni pro odhad salience. Pak použijeme chamtivou heuristiku k extrakci významných vět, které se vyhnou nadbytečnosti. V našich experimentech na DUC 2004 uvažujeme o třech typech větových vztahových grafů a demonstrujeme výhodu kombinace větových vztahů v grafech s reprezentační sílou hlubokých neuronových sítí. Náš model zlepšuje ostatní tradiční extrakční přístupy založené na grafech a vanilkový GRU sekvenční model bez grafu a dosahuje konkurenčních výsledků oproti ostatním nejmodernějším systémům shrnutí více dokumentů.', 'et': 'Pakume välja neuraalse mitme dokumendi kokkuvõtliku süsteemi, mis sisaldab lausesuhte graafikuid. Suhtegraafikutel kasutame graafika konvolutsioonivõrku (GCN), sisendsõlmede funktsioonidena on lausepõimitud korduvatest neurovõrkudest. Mitmekihilise leviku kaudu loob GCN kõrgetasemelised varjatud lausefunktsioonid silmuse hindamiseks. Seejärel kasutame ahnet heuristikat, et välja võtta silmapaistvaid lauseid, mis vältivad liigsust. Oma DUC 2004 eksperimentides kaalume kolme tüüpi lauseseoste graafikuid ja demonstreerime eeliseid lauseseoste kombineerimisel graafikutes sügavate närvivõrkude esindusjõuga. Meie mudel täiustab teisi traditsioonilisi graafikutel põhinevaid ekstraheerimismeetodeid ja graafikuta vanilje GRU jadamudelit ning saavutab konkurentsivõimelised tulemused teiste kaasaegsete mitme dokumendi kokkuvõtlussüsteemidega.', 'fi': 'Ehdotamme neurodokumenttien yhteenvedon järjestelmää, joka sisältää lausesuhdekaavioita. Suhteen kuvaajiin käytetään Graph Convolutional Network (GCN), jossa toistuvista hermoverkoista saadut lauseupotukset ovat tulosolmuominaisuuksia. Monikerroksisen leviämisen avulla GCN tuottaa korkean tason piilotettuja lauseominaisuuksia salienssin arvioimiseksi. Sitten käytämme ahneutta heuristiikkaa poimimaan esiin merkittäviä lauseita, jotka välttävät tarpeettomuuden. DUC 2004:llä tehdyissä kokeissa tarkastelemme kolmentyyppisiä lausesuhdegraafeja ja osoitamme, miten hyödyllistä on yhdistää lausesuhteet graafeihin syvien hermoverkkojen esitysvoiman kanssa. Mallimme parantaa perinteisiä graafipohjaisia uuttamismenetelmiä ja vaniljan GRU-sekvenssimallia ilman graafikkoa, ja se saavuttaa kilpailukykyisiä tuloksia muihin huippuluokan monidokumenttien yhteenvetojärjestelmiin verrattuna.', 'jv': 'Awak dhéwé ngerasah sistem dadi nggawe multi-dokumen seneng pisan nggambar nggambar barang. We use a Graph convolution Network Attribute Awak dhéwé éntuk kesempatan heuristik dhéwé kanggo ngerasah luwih-luwih dumadhi kaé ora tau nguasai. Nang barêng-barêng naning DUT 2004, kéné sawayaké tanggal 3 kalih perusahaan langgambar nggambar barang nggambar kuwi tindakan nggambar perusahaan winih kanggo nggawe nguasakno karo pawaran kuwi tindakan netwisan nyerané. Model sing nyusan nganggo barang nggawe barang nggawe barang nggawe barang paragraph sing basa gambar ditambah karo model sing perusahaan bakal dumateng, iki dadi iso dianggap banjur perusahaan langkung sampulan langgar state-of-the-arts multi-document resumen sistem.', 'sk': 'Predlagamo nevronski sistem za povzetek večdokumentov, ki vključuje grafe odnosov stavkov. Na relacijskih grafih uporabljamo grafično konvolucijsko omrežje (GCN), pri čemer so vgradnje stavkov pridobljene iz ponavljajočih se živčnih omrežij kot funkcije vhodnega vozlišča. Z večplastnim razmnoževanjem GCN ustvari visoko stopnjo skritih stavkov za oceno izpostavljenosti. Nato uporabimo pohlepno heuristiko, da izvlečemo pomembne stavke, ki se izognejo odvečnosti. V naših eksperimentih na DUC 2004 obravnavamo tri vrste grafov stavkovnih relacij in prikazujemo prednost združevanja stavkovnih relacij v grafih z močjo reprezentacije globokih nevronskih omrežij. Naš model izboljšuje druge tradicionalne ekstraktivne pristope, ki temeljijo na grafu, in vanilijev model zaporedja GRU brez grafov, ter dosega konkurenčne rezultate v primerjavi z drugimi najsodobnejšimi sistemi za povzemanje več dokumentov.', 'ha': "Munã buɗa wani na'urar takardar ƙararin multi-dokuman na ƙara cikin fassarar danganta. Tuna yi amfani da Shirin Narrafi (GN) kan karatun na mazaɓa, da sauran filinaiki da aka samu da shi daga Naural Networks na Recurrent as feature of inputs node. Ga bayani na zane-zane-zane-zane-zane, GCR yana mai ƙidãya masu tsari ga salon da aka ɓõye daraja mai tsawo. Sa'an nan kuma Munã yi amfani da heuristic dõmin mu fitar da salon da za'a sami da sauri daga kashi. Daga jarrabayenmu a kan DUC 2004, muna bincike nau'i-nau'i uku na fassarar danganta na danganta na danganta ga koma da danganta danganta cikin grafyuta da ƙarfin shaidar zangaren neura. MisalinMu ya ƙara kan wasu hanyoyin bayani na grafyuta da aka ƙayyade wasu na'urar-na'ura da kuma misãlin mai sauran GRU na ƙarya ba da grafyuta ba, kuma yana sãmu matsalar ta yi ƙidãya a kan wasu halin-na-kungita masu ƙari ga-rubutun-multi-rubutu.", 'he': 'אנו מציעים מערכת מסמכים רבים נוירוניים שמכילה גרפים יחסי משפטים. We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence embeddings obtained from Recurrent Neural Networks as input node features.  באמצעות התרבות במספר שכבות, GCN יוצר תכונות משפטים חבויים ברמה גבוהה לערכת מילוי. ואז אנחנו משתמשים בהוריסטיקה חמדנית כדי לחלץ משפטים מפרקים שממנעים מיותרים. בניסויים שלנו על DUC 2004, אנחנו שוקלים שלושה סוגים של גרפים של יחסי משפטים ומוכיחים את היתרון של שילוב יחסי משפטים בגרפים עם כוח המייצג של רשתות עצביות עמוקות. הדוגמא שלנו משתפר על גישות חיפושיות מסורתיות מבוססות בגרף, ודוגמא רצף וונילה GRU ללא גרף, והיא משיגה תוצאות תחרותיות נגד מערכות מסדרות רבות של מצב המדינה.', 'bo': 'ང་ཚོས་རང་ཉིད་ཀྱི་དཔུད་རིས་ཡིག་ཆའི་བཅུད་སྡུད་ཀྱི་རྩིས་འབྲེལ་བ་ཡིག་ཆའི་མ་ལག་ཅིག་སྤྲོད་ཀྱི་ཡོད We employ a Graph Convolutional Network (GCN) on the relation graphs, with sentence embeddings obtained from Recurrent Neural Networks as input node features. འཇིག་རིས་ལ་ཕྱོགས་པའི་སྒུལ་སྤྱོད་འདྲ་བ་བསྟུན་ནས་ GCN དེ་འཁྱེར་ནས་བཟོ་རྣམ་པ་ལ་མཐོ་རིམ་པ་ཡིན་པའི་ཚིག་གཟུགས་རི དེ་ནས་འུ་ཚོས་བློ་ཚིག་གི་ཚིག་རྗེས་སུ་ཕྱིར་འདོན་པའི་ཚིག་རྗེས་སུ་ལག་ལེན་འཐབ་བྱེད། DUC 2004ལ་ང་ཚོའི་སྒེར་ཚོགས་ནང་གི་ཚིག Our model improves on other traditional graph-based extractive approaches and the vanilla GRU sequence model with no graph, and it achieves competitive results against other state-of-the-art multi-document summarization systems.'}
{'en': 'CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies', 'ar': 'المهمة المشتركة لـ CoNLL 2017: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية', 'fr': 'Tâche partagée ConLL 2017\xa0: analyse multilingue du texte brut aux dépendances universelles', 'pt': 'Tarefa compartilhada CoNLL 2017: análise multilíngue de texto bruto para dependências universais', 'es': 'Tarea compartida de CoNll 2017: análisis multilingüe del texto sin procesar a las dependencias universales', 'ja': 'CoNLL 2017共有タスク:生テキストからユニバーサル依存関係への多言語解析', 'zh': 'CoNLL 2017 共事:自始文本至通用赖项者多言解析', 'hi': 'CoNLL 2017 साझा कार्य: यूनिवर्सल निर्भरताओं के लिए कच्चे पाठ से बहुभाषी पार्सिंग', 'ru': 'Совместная задача CoNLL 2017: многоязычный парсинг от необработанного текста к универсальным зависимостям', 'ga': 'Tasc Comhroinnte CoNLL 2017: Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch', 'ka': 'CoNLL 2017 გაყოფილი პარამეტრები: მრავალენგური პარამეტრების გადაწყვება გარეშე ტექსტიდან უნივერსალური განსაკუთრებებიდან', 'it': 'Compito condiviso CoNLL 2017: analisi multilingue dal testo grezzo alle dipendenze universali', 'el': 'Κοινή εργασία: Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις', 'hu': 'CoNLL 2017 Megosztott feladat: Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig', 'mk': 'CoNLL 2017 заедничка задача: Мултијазично анализирање од суров текст до универзални зависности', 'lt': 'CoNLL 2017 m. bendra užduotis: daugiakalbis analizavimas iš žaliavinio teksto į visuotines priklausomybes', 'ml': 'കോണ്\u200dഎല്\u200d 2017 പങ്കാളിയുള്ള ജോലി: റോ ടെക്സ്റ്റില്\u200d നിന്നും യൂണിവല്\u200d ആധിപത്യം', 'ms': 'CoNLL 2017 Tugas Berkongsi: Penghuraian Berbahasa Dari Teks Raw ke Dependensi Universal', 'mt': 'CoNLL 2017 Kompitu Konġunt: Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali', 'kk': 'CoNLL 2017 ортақтастырылған тапсырма: Көптілік талдау мәтіннен көптілік талдау', 'mn': 'CoNLL 2017 Холбоотой ажил: Олон хэлний талаар Raw Text-ээс Universal Dependencies руу', 'no': 'CoNLL 2017 Delt oppgåve: fleirspråk tolking frå råtekst til universelle avhengighet', 'ro': 'Sarcină partajată CoNLL 2017: Parsing multilingv de la text brut la dependențe universale', 'si': 'CoNLL 2017 සමාගත වැඩක්: වැඩ භාෂාවික විශ්ලේෂණය', 'so': 'CoNLL 2017 Shaqada la sharciyey: Jardiiska luuqadaha badan ee Raw-to Universal Dependations', 'pl': 'CoNLL 2017 Wspólne zadanie: Wielojęzyczne analizowanie tekstu surowego do uniwersalnych zależności', 'ta': 'கோன்எல் 2017 பகிர்ந்த பணி', 'sr': 'CoNLL 2017. zajednièki zadatak: Multilingual Parsing from Raw Text to Universal Dependencies', 'sv': 'CoNLL 2017 Delad uppgift: Flerspråkig tolkning från obehandlad text till universella beroenden', 'ur': 'CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies', 'uz': 'Comment', 'vi': 'Công việc chia sẻ Coinll bây giờ: đa ngôn ngữ học phân tích từ văn bản thô sang phụ thuộc chung', 'hr': 'CoNLL 2017. zajednički zadatak: Multilingual Parsing from Raw Text to Universal Dependencies', 'bg': 'Споделена задача: Многоезично анализиране от суров текст до универсални зависимости', 'nl': 'CoNLL 2017 Gedeelde taak: Meertalig Parsen van ruwe tekst naar universele afhankelijkheden', 'da': 'CoNLL 2017 delt opgave: Flersproget fortolkning fra rå tekst til universelle afhængigheder', 'de': 'CoNLL 2017 Gemeinsame Aufgabe: Mehrsprachiges Parsing von Rohtext zu universellen Abhängigkeiten', 'id': 'CoNLL 2017 Tugas Berkongsi: Penganalisan berbagai bahasa dari Teks Raw ke Dependensi Universal', 'fa': 'کاری مشترک CoNLL ۲۰۰۷: تحلیل زیادی زبان از متن خالی به بستگی جهانی', 'ko': 'CoNLL 2017 공유 작업: 원본 텍스트에서 일반 종속성까지의 다중 언어 해석', 'sw': 'CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies', 'af': 'CoNLL 2017 Gedeelde Opdrag: Multilingual Toesteling van Ro Teks na Universele Afhanklikhede', 'sq': 'CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies', 'tr': 'CoNLL 2017 Mazmunlar Taýişi: Çoklu dilli Taýýarlama', 'hy': 'Դադար', 'am': 'CoNLL 2017 የተሰራጨ ስራ: Multilingual Parsing from Raw Text to Universal dependencies', 'az': 'CoNLL 2017 paylaşılmış iş iş: Böyük mətndən Universal Dependenciyə qədər çoxlu dil analizi', 'bn': 'কএনএল ২০১৭ শেয়ার কর্মসূচি: রাও টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভরিত পার্সিং', 'bs': 'CoNLL 2017 Podijeljeni zadatak: Multilingual Parsing from Raw Text to Universal Dependencies', 'ca': 'CoNLL 2017 Task Shared: Multilingual Parsing from Raw Text to Universal Dependencies', 'cs': 'CoNLL 2017 Sdílená úloha: Vícejazyčné parsování z syrového textu do univerzálních závislostí', 'et': 'CoNLL 2017 jagatud ülesanne: mitmekeelne parsimine toortekstist universaalsetele sõltuvustele', 'fi': 'CoNLL 2017 Jaettu tehtävä: Monikielinen parsaus raakatekstistä universaaleihin riippuvuuksiin', 'jv': 'CoNLL 1997 Joined tasks: Multilanguage', 'ha': 'KCharselect unicode block name', 'he': 'CoNLL 2017 משימה משותפת: מעבדה רבת שפותית מטקסט ראש לתמכויות יוניברסליות', 'sk': 'Skupna naloga CoNLL 2017: večjezično razčlenitev iz surovega besedila do univerzalnih odvisnosti', 'bo': 'CoNLL 2017 མཉམ་སྤྱོད་པའི་བྱ་འགུལ་དངོས་ཡིག་ཆ་རྩིས་ཐོག་ལས་ཕར་ཐོག་ཡི་གེ་ལས་ སྤྱི་ཁོངས་ལ་རང་མཐུན་རྟེན་དང་།'}
{'en': 'The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All test sets followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems.', 'ar': 'يتميز مؤتمر تعلم اللغة الطبيعية الحسابية (CoNLL) بمهمة مشتركة ، حيث يقوم المشاركون بتدريب واختبار أنظمة التعلم الخاصة بهم على نفس مجموعات البيانات. في عام 2017 ، تم تكريس المهمة لتعلم محللي التبعية لعدد كبير من اللغات ، في بيئة واقعية دون أي تعليق توضيحي قياسي على المدخلات. اتبعت جميع مجموعات الاختبار مخططًا توضيحيًا موحدًا ، أي نظام التبعيات العالمية. في هذه الورقة ، نحدد المهمة ومنهجية التقييم ، ونصف كيف تم إعداد مجموعات البيانات ، ونبلغ عن النتائج الرئيسية ونحللها ، ونقدم تصنيفًا موجزًا للنهج المختلفة للأنظمة المشاركة.', 'es': 'La Conferencia sobre Aprendizaje Computacional de Lenguajes Naturales (CoNLL) presenta una tarea compartida, en la que los participantes entrenan y prueban sus sistemas de aprendizaje en los mismos conjuntos de datos. En 2017, la tarea se dedicó a aprender analizadores de dependencias para un gran número de idiomas, en un entorno real sin ninguna anotación de referencia en la entrada. Todos los conjuntos de pruebas siguieron un esquema de anotación unificado, a saber, el de Dependencias universales. En este artículo, definimos la metodología de tareas y evaluación, describimos cómo se prepararon los conjuntos de datos, informamos y analizamos los principales resultados y proporcionamos una breve categorización de los diferentes enfoques de los sistemas participantes.', 'pt': 'A Conferência sobre Aprendizagem Computacional de Línguas Naturais (CoNLL) apresenta uma tarefa compartilhada, na qual os participantes treinam e testam seus sistemas de aprendizagem nos mesmos conjuntos de dados. Em 2017, a tarefa foi dedicada ao aprendizado de analisadores de dependência para um grande número de idiomas, em uma configuração do mundo real sem nenhuma anotação padrão-ouro na entrada. Todos os conjuntos de testes seguiram um esquema de anotação unificado, ou seja, de Dependências Universais. Neste artigo, definimos a tarefa e a metodologia de avaliação, descrevemos como os conjuntos de dados foram preparados, relatamos e analisamos os principais resultados e fornecemos uma breve categorização das diferentes abordagens dos sistemas participantes.', 'fr': "La Conference on Computational Natural Language Learning (ConLL) propose une tâche partagée, dans laquelle les participants entraînent et testent leurs systèmes d'apprentissage sur les mêmes ensembles de données. En 2017, la tâche a été consacrée à l'apprentissage des analyseurs de dépendance pour un grand nombre de langues, dans un environnement réel sans aucune annotation de référence en entrée. Tous les ensembles de tests suivaient un schéma d'annotation unifié, à savoir celui des dépendances universelles. Dans cet article, nous définissons la tâche et la méthodologie d'évaluation, décrivons comment les ensembles de données ont été préparés, rapportons et analysons les principaux résultats, et fournissons une brève catégorisation des différentes approches des systèmes participants.", 'ja': '計算自然言語学習会議（ CONLL ）は、参加者が同じデータセット上で学習システムを訓練し、テストするという共通の課題を特徴としている。2017年、このタスクは、入力に対する金本位制の注釈なしに、現実の環境で、多数の言語の依存関係解析器を学習することに専念しました。すべての試験器は、統一された注釈スキーム、すなわちユニバーサル依存性のスキームに従った。本稿では、タスクと評価方法論を定義し、データセットがどのように準備されたかを説明し、主な結果を報告および分析し、参加システムの異なるアプローチの簡単な分類を提供する。', 'ru': 'Конференция по вычислительному изучению естественного языка (CoNLL) имеет общую задачу, в рамках которой участники обучают и тестируют свои системы обучения на одних и тех же наборах данных. В 2017 году задача была посвящена изучению парсеров зависимостей для большого количества языков, в реальной обстановке без какой-либо золотой стандартной аннотации на входе. Все тестовые наборы следовали единой схеме аннотаций, а именно схеме универсальных зависимостей. В настоящем документе мы определяем задачу и методологию оценки, описываем, как были подготовлены наборы данных, сообщаем и анализируем основные результаты, а также даем краткую категоризацию различных подходов участвующих систем.', 'zh': '计自然语言学会议(CoNLL)有共享之务,参与者同数集上训练而试之。 在2017年,务在世界学大言赖解析器,无所注黄金。 凡试集皆遵一注方案,即通用依注方案。 其在本文,定义质法,述数集是所备,告析大体,简其参统。', 'hi': 'कम्प्यूटेशनल प्राकृतिक भाषा सीखने पर सम्मेलन (CoNLL) में एक साझा कार्य है, जिसमें प्रतिभागी एक ही डेटा सेट पर अपने सीखने की प्रणालियों को प्रशिक्षित और परीक्षण करते हैं। 2017 में, यह कार्य बड़ी संख्या में भाषाओं के लिए निर्भरता पार्सर सीखने के लिए समर्पित था, इनपुट पर किसी भी सोने के मानक एनोटेशन के बिना वास्तविक दुनिया की सेटिंग में। सभी परीक्षण सेटों ने एक एकीकृत एनोटेशन योजना का पालन किया, अर्थात् यूनिवर्सल निर्भरताओं का। इस पेपर में, हम कार्य और मूल्यांकन पद्धति को परिभाषित करते हैं, वर्णन करते हैं कि डेटा सेट कैसे तैयार किए गए थे, मुख्य परिणामों की रिपोर्ट और विश्लेषण करते हैं, और भाग लेने वाले सिस्टम के विभिन्न दृष्टिकोणों का एक संक्षिप्त वर्गीकरण प्रदान करते हैं।', 'ga': 'Tá tasc comhroinnte sa Chomhdháil ar Fhoghlaim Teangacha Nádúrtha Ríomhaireachtúla (CoNLL), ina ndéanann rannpháirtithe oiliúint agus tástáil ar a gcórais foghlama ar na tacair sonraí céanna. In 2017, díríodh an tasc ar pharsálaithe spleáchais a fhoghlaim do líon mór teangacha, i suíomh fíordhomhanda gan aon nótaí órchaighdeán ar ionchur. Lean na tacair tástála go léir scéim anótála aontaithe, eadhon scéim Spleáchais Uilíocha. Sa pháipéar seo, sainímid an mhodheolaíocht tasc agus meastóireachta, déanaimid cur síos ar conas a ullmhaíodh na tacair sonraí, tuairiscímid agus anailísimid na príomhthorthaí, agus cuirimid catagóiriú gairid ar fáil ar na cineálacha cur chuige éagsúla atá ag na córais rannpháirteacha.', 'hu': 'A számítástechnikai természetes nyelvtanulásról szóló konferencia (CoNLL) egy közös feladatot tartalmaz, amelyben a résztvevők ugyanazon adatkészleteken képezik és tesztelik tanulási rendszerüket. 2017-ben a feladatot a függőség-elemzők nagyszámú nyelven történő tanulására szentelték, valós környezetben, anélkül, hogy a bemeneti jegyzetek aranyszabású lennének. Minden tesztkészlet egységes jegyzetelési sémát követett, nevezetesen az univerzális függőségeket. Ebben a tanulmányban meghatározzuk a feladat- és értékelési módszertant, bemutatjuk, hogyan készültek az adatkészletek, jelentjük és elemezzük a fő eredményeket, és rövid kategorizálást adunk a résztvevő rendszerek különböző megközelítéseiről.', 'ka': 'CoNLL-ის კონფიგურაცია კომპუტაციონალური თავისუფალური ენის სწავლების (კონფიგურაციონალური თავისუფალური ენის სწავლების) საშუალებელი რაოდენობა, რომელიც 2017 წლის შემდეგ დავალება დასაწყებელებისთვის უფრო დიდ რაოდენობით ენებისთვის, რეალური მსოფლიოში არსებობით წლის სტანდარტური ანოტაციაში. ყველა ტესტის სეტები შემდეგ ერთადერთი ანტორაციის სემის შემდეგ, რომელიც სამყარო განსაზღვრებების შემდეგ. ამ დომენტში ჩვენ განსაზღვრებით რაოდენობა და განსაზღვრების მეტოლოგია, განსაზღვრებით თუ როგორ მონაცემების კონფიგურაცია იყო, განაზღვრებით და განაზღვრებით მნიშვნელოვანი შედეგი შედეგი', 'el': 'Το Συνέδριο για την Υπολογιστική Μάθηση Φυσικής Γλώσσας (περιλαμβάνει ένα κοινό έργο, στο οποίο οι συμμετέχοντες εκπαιδεύουν και δοκιμάζουν τα μαθησιακά τους συστήματα στα ίδια σύνολα δεδομένων. Το 2017, η εργασία αφιερώθηκε σε αναλύσεις εξάρτησης εκμάθησης για μεγάλο αριθμό γλωσσών, σε ένα πραγματικό περιβάλλον χωρίς κανένα χρυσό πρότυπο σχολιασμό στην εισαγωγή. Όλα τα σύνολα δοκιμών ακολούθησαν ένα ενοποιημένο σύστημα σχολιασμού, δηλαδή αυτό των καθολικών εξαρτήσεων. Στην παρούσα εργασία, καθορίζουμε τη μεθοδολογία εργασίας και αξιολόγησης, περιγράφουμε τον τρόπο προετοιμασίας των συνόλων δεδομένων, αναφέρουμε και αναλύουμε τα κύρια αποτελέσματα και παρέχουμε μια σύντομη κατηγοριοποίηση των διαφόρων προσεγγίσεων των συμμετεχόντων συστημάτων.', 'lt': 'Konferencijoje dėl kompiuterinės gamtinės kalbos mokymosi (CoNLL) numatyta bendra užduotis, kurioje dalyviai moko ir bando savo mokymosi sistemas tuose pačiuose duomenų rinkiniuose. 2017 m. užduotis buvo skirta mokymosi priklausomybės analizatoriams daugeliui kalbų realiame pasaulyje be jokių aukso standartinių įrašų. Visi bandymų rinkiniai atitiko vieningą annotacijos schemą, t. y. Universaliųjų priklausomybių sistemą. Šiame dokumente apibrėžiame užduotį ir vertinimo metodiką, apibūdiname, kaip buvo parengti duomenų rinkiniai, teikiame ataskaitas ir analizuojame pagrindinius rezultatus ir trumpai suskirstome įvairius dalyvaujančių sistemų metodus.', 'kk': 'Компьютерлік тәуелді тіл оқыту конференциясы (CoNLL) бөлек тапсырманы көрсетеді. Қатысушылар осы деректер жинақтарында оқыту жүйелерін тексеріп тұрады. 2017 жылы тапсырма бірнеше тіл үлкен тілдер үшін тәуелсіздік талдаушыларына, келтірілген алтын- стандартты жазылмаған әлемді орнатылған. Барлық сынақ жиындары біріктірілген жазбалар сұлбасына келеді. Мәселен, Universal Dependencies сұлбасына келеді. Бұл қағазда тапсырманы және оқу методологиясын анықтап, деректер жиындары қалай дайындалды, хабарлау және негізгі нәтижелерді анализ және қатысушылардың әртүрлі жағдайларының қысқа категориясын береміз.', 'mk': 'Конференцијата за Компутационално учење на природен јазик (CoNLL) има заедничка задача, во која учесниците ги обучуваат и тестираат своите системи за учење на истите податоци. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input.  Сите тестови следеа единствена шема на анотации, имено онаа на универзалните зависности. Во овој документ, ја дефинираме методологијата на задачата и евалуацијата, опишуваме како се подготвени податоците, известуваме и ги анализираме главните резултати и обезбедуваме кратка категоризација на различните пристапи на учествувачките системи.', 'ms': 'Konferensi tentang Pelajaran Bahasa Alami Komputasi (CoNLL) mengandungi tugas berkongsi, di mana peserta melatih dan menguji sistem belajar mereka pada set data yang sama. Pada tahun 2017, tugas ini ditugaskan untuk mempelajari penghurai dependensi untuk sejumlah besar bahasa, dalam tetapan dunia nyata tanpa sebarang anotasi piawai emas pada input. Semua set ujian mengikut skema anotasi bersatu, iaitu skema Dependensi Universal. Dalam kertas ini, kami menentukan metodologi tugas dan penilaian, menjelaskan bagaimana set data telah disediakan, melaporkan dan menganalisis keputusan utama, dan menyediakan kategorisasi singkat pendekatan yang berbeza dari sistem yang berpartisipasi.', 'it': "La Conferenza sull'apprendimento computazionale delle lingue naturali (CoNLL) prevede un compito condiviso, in cui i partecipanti addestrano e testano i loro sistemi di apprendimento sugli stessi set di dati. Nel 2017, il compito è stato dedicato all'apprendimento dei parser di dipendenza per un gran numero di lingue, in un ambiente reale senza alcuna annotazione gold-standard in input. Tutti i set di test hanno seguito uno schema di annotazione unificato, vale a dire quello delle dipendenze universali. In questo articolo definiamo il compito e la metodologia di valutazione, descriviamo come sono stati preparati i set di dati, riportiamo e analizziamo i principali risultati e forniamo una breve categorizzazione dei diversi approcci dei sistemi partecipanti.", 'ml': 'കമ്പ്യൂട്ടിഷന്\u200d സ്വാഭാവിക ഭാഷ പഠിപ്പിക്കുന്നതിന്\u200dറെ കോണ്\u200dക്കോണ്\u200dഷന്\u200dസ് ഒരു പങ്കാളിയുള്ള ജോലിയുണ്ട്, അതില്\u200d പങ്കാളികള്\u200d പഠിക 2017-ല്\u200d ഈ ജോലി ഒരുപാട് ഭാഷകള്\u200dക്കായി ആശ്രയിച്ച പാര്\u200dസറുകള്\u200d പഠിപ്പിക്കാന്\u200d വേണ്ടിയായിരുന്നു. ഇന്\u200dപുട്ടില്\u200d സ്വര്\u200dണ്ണ-സ്റ എല്ലാ ടെസ്റ്റ് സജ്ജീകരണങ്ങളും ഒരു യൂണിക്കേറ്റ് അറ്റാന്റേഷന്\u200d പദ്ധതിയുടെ പിന്നാലെ നടന്നു. അതായത് യൂ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ജോലിയും വിലയിക്കുന്ന രീതിയും വിശദീകരിക്കുന്നു, ഡേറ്റാ സജ്ജീകരണങ്ങള്\u200d എങ്ങനെ തയ്യാറാക്കിയിരുന്നു എന്ന് വിശദീകരിക്കുന്നു, പ', 'mn': 'Компьютерийн Байгалийн хэл суралцах (CoNLL) Конференцийн хувьд оролцогчдын ажил нь ижил өгөгдлийн санд суралцах системийг шалгаж байдаг. 2017 онд маш олон хэл дээр хамааралтай байдлыг сурах хүмүүст зориулагдсан, үнэндээ дэлхий дээр ямар ч алт-стандарт анзааралгүйгээр зориулагдсан. Бүх шалгалтууд нэгтгэл тайлбарлах схемийг дагаж байлаа. Энэ бол Universal Dependencies. Энэ цаасан дээр бид ажил болон үнэлэх методологийг тодорхойлж, өгөгдлийн багц хэрхэн бэлдэгдсэн бөгөөд үндсэн үр дүн шинжилгээ тайлбарлаж, оролцох системийн өөр өөр арга баримтуудыг бага зэрэг хуваалцаж өгдөг.', 'ro': 'Conferința privind învățarea limbilor naturale computaționale (CoNLL) cuprinde o sarcină comună, în care participanții își pregătesc și își testează sistemele de învățare pe aceleași seturi de date. În 2017, sarcina a fost dedicată învățării analizoarelor de dependență pentru un număr mare de limbi, într-un cadru real, fără nici o adnotare de aur standard la intrare. Toate seturile de teste au urmat o schemă unificată de adnotare, și anume cea a Dependențelor Universale. În această lucrare, definim sarcina și metodologia de evaluare, descriem modul în care au fost pregătite seturile de date, raportăm și analizăm principalele rezultate și oferim o scurtă clasificare a diferitelor abordări ale sistemelor participante.', 'no': 'Konferansen om Computational Natural Language Learning (CoNLL) inneheld ei delt oppgåve, der deltakarar treng og testar læringssystemene sine på samme datasett. I 2017 vart oppgåva spesifisert til å lære avhengighetsanalyserar for mange språk, i eit verkeleg innstilling utan eit gull-standard merking på inndata. Alle testinnstillingane følgja eit vienot notasjonsskjema, som er universell avhengighet. I denne papiret definerer vi oppgåva og evalueringsmetodologien, beskriver korleis datasettet vart forberedt, rapportert og analysert hovudresultatene, og gjev ei kort kategorisering av dei ulike tilnærmingane av deltakende systema.', 'mt': 'Il-Konferenza dwar it-Tagħlim tal-Lingwi Naturali Komputazzjonali (CoNLL) għandha kompitu komuni, li fih il-parteċipanti jħarrġu u jittestjaw is-sistemi ta’ tagħlim tagħhom fuq l-istess settijiet ta’ dejta. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input.  All test sets followed a unified annotation scheme, namely that of Universal Dependencies.  F’dan id-dokument, niddefinixxu l-metodoloġija tal-kompitu u l-evalwazzjoni, niddeskrivu kif ġew ippreparati s-settijiet tad-dejta, nirrappurtaw u naliżizzaw ir-riżultati ewlenin, u nipprovdu kategorizzazzjoni qasira tal-approċċi differenti tas-sistemi parteċipanti.', 'pl': 'Konferencja Computational Natural Language Learning (CoNLL) to wspólne zadanie, w ramach którego uczestnicy szkolą i testują swoje systemy uczenia się na tych samych zbiorach danych. W latach 2017 zadanie poświęcono analizie zależności uczenia się dla dużej liczby języków, w świecie rzeczywistym bez żadnych złotych standardowych adnotacji na wejściu. Wszystkie zestawy testów posiadały ujednolicony schemat adnotacji, a mianowicie system uniwersalnych zależności. W niniejszym artykule definiujemy zadanie i metodologię oceny, opisujemy sposób przygotowania zbiorów danych, raportujemy i analizujemy główne wyniki oraz przedstawiamy krótką kategoryzację różnych podejść uczestniczących systemów.', 'sv': 'Konferensen om beräkningsmässigt naturligt språkinlärning (CoNLL) innehåller en gemensam uppgift, där deltagarna tränar och testar sina inlärningssystem på samma datauppsättningar. Under 2017 ägnades uppgiften åt att lära sig beroendetolkare för ett stort antal språk, i en verklig miljö utan någon guldstandard anteckning på indata. Alla testuppsättningar följde ett enhetligt kommentarschema, nämligen Universal Dependences. I denna uppsats definierar vi uppgifts- och utvärderingsmetodik, beskriver hur datauppsättningarna utarbetades, rapporterar och analyserar de viktigaste resultaten samt ger en kort kategorisering av de olika tillvägagångssätten för de deltagande systemen.', 'ta': 'தொகுப்பு இயல்பான மொழி கற்றுக்கொடுப்பு (CoNLL) கூட்டிய செயலை குறிப்பிடுகிறது, அதில் பங்கிடுபவர்கள் ஒரே தரவு அமைப்புகளில் கற்றுக் கொள் 2017-ல், சார்ந்த சார்பு பார்சர்கள் கற்றுக் கொள்ள செயல்பாடு சுலபமாக இருந்தது, நிறைய மொழிகளுக்கு, உள்ளீட்டு வெளியீட்டு எந்த தங் அனைத்து சோதனைகளும் ஒருங்கிணைக்கப்பட்ட அறிவிப்பு முறைமையைப் பின்பற்றியது, அது பொதுவான சார்புகள். இந்த காகிதத்தில், நாம் பணி மற்றும் evaluation முறைமையை வரையறுக்கிறோம், தரவு அமைப்புகள் எப்படி தயாரிக்கப்பட்டுள்ளது, அறிவிக்கை மற்றும் முக்கிய முடிவுகளை ஆர', 'so': 'Kulamaanka barashada afka dabiicadda ah (CoNLL) wuxuu qabanqaabiyaa shuqul la qaybsan, kaas oo ay ka qeybqaadan yihiin inay ku tababaridaan iyo ku tijaabiyaan nidaamka waxbarashada ee iskuullada isku mid ah. Maalmadii 2017 waxaa loogu talogalay in baarlamaanka ku xiran lagu barto luqado badan, taas oo lagu qoray qoraal caalami ah oo aan laguugu qorin warqad caadi ah oo dahab ah. Heshiiska imtixaanka oo dhammu waxay raaceen qorshaha la xiriira, kaas oo ah mid ku xiran masruufka caalamiga ah. Qoraalkan waxaynu ku qornaa qaababka shaqada iyo qaababka qiimeynta, waxaannu ku qoraynaa sida kooxda macluumaadka loo diyaariyay, wargelin karo, baaritaanna resultiyada ugu horeeya, waxaana u qoraynaa kooxo kooxo hababka kala duduwan ee nidaamka qayb-qaadashada.', 'si': 'කොම්පියුටර් ස්වභාවික භාෂාවක් ඉගෙනීම (CoNLL) ගැන සම්බන්ධ වැඩක් තියෙනවා, ඒ වගේම සම්බන්ධ වෙනුවෙන් කාර්ය 2017 දී, මේ වැඩේ විශාල භාෂාවක් ගොඩක් ගොඩක් විශාල භාෂාවක් ඉගෙන ගන්න අවශ්\u200dය වෙලා තියෙනවා, ඇත්ත ලෝකයේ සුන්ද සියළු පරීක්ෂණ සෙට් එක්ක සම්බන්ධයක් පස්සෙන් පස්සෙන් ඉන්නවා, ඒ වගේම ජාතික විශේෂතාවක්  මේ පත්තරේ අපි වැඩ සහ විශ්ලේෂණ විධානය විශ්වාස කරනවා, තොරතුරු සෙට් කොහොමද සූදානම් කරලා තියෙනවා, වාර්තාව සහ විශේෂණය කරනවා, සහ', 'ur': 'کمپیوٹریشن طبیعی زبان تعلیم (CoNLL) کی کنفرانس ایک مشترک کام ہے جس میں مشترکین ٹرین کریں اور ان کی تعلیم سیستموں کو ایک ہی ڈیٹ سٹ پر امتحان کریں۔ ۲۰۱۷ میں یہ کام بہت سی زبانوں کے لئے آئندسٹی پارسروں کی تعلیم کے لئے مطالبہ کیا گیا تھا، ایک حقیقی دنیا کی تنظیم میں، سوال کے بغیر کوئی سونے-استاندارڈ اظہار کے. تمام آزمائش سٹے ایک متحدہ آزمائش طریقے کے پیچھے چلے، یعنی Universal Dependencies کی. اس کاغذ میں ہم نے تابع اور ارزیابی کا طریقہ مقرر کیا ہے، دکھائی سٹے کیسے تیار کیے گئے تھے، راپورت کیے گئے اور اصلی نتیجے کا تحلیل کیے گئے ہیں، اور مشارکت سیستموں کے مختلف طریقوں کا ایک تھوڑا طریقہ تقسیم کیے جاتے ہیں۔', 'sr': 'Konferencija o učenju kompjuterskih prirodnih jezika (CoNLL) prikazuje zajednički zadatak, u kojem su učesnici vlakovali i testirali svoje sisteme učenja na istim setima podataka. U 2017. godini, zadatak je bio posvećen parserima zavisnosti za veći broj jezika, u stvarnom svijetu, bez zlatnog standardnog annotacije o ulazu. Svi testovi su pratili ujedinjenu annotaciju, a to je univerzalne zavisnosti. U ovom papiru definišemo metodologiju zadataka i procjene, opisujemo kako su podaci pripremljeni, prijavili i analizirali glavne rezultate, i pružali kratku kategoriju različitih pristupa sustava sudjelovanja.', 'uz': "Name 2017 yilda, bu vazifa bir necha tillar uchun qo'llanmalar o'rganish uchun boshqaruvchi парламент o'rganishga ishlaydi, o'sha dunyodagi narsalar yordamida qo'llanmagan narsalar yoʻq. @ info Bu hujjatda, biz vazifa va qiymatning metodini aniqlamiz, maʼlumot tuzuvlari qanday tayyorlanligini aniqlab, asosiy natijalarini taʼrif qilib taʼrifi qilamiz, va boshqa natijalarni taʼminlovchi bo'lgan boshqa usullarning qisqa darajasini koʻrsatish.", 'vi': 'Hội nghị về Học Ngôn ngữ Tự Do Dự Tính Tính Tính Tính Tính Tính có một nhiệm vụ chung, trong đó có những người tham gia huấn luyện và thử nghiệm hệ thống học trên cùng một bộ dữ liệu. Nhiệm vụ được giao là tìm hiểu các phân tích phụ thuộc cho nhiều ngôn ngữ, ở một thế giới thực mà không có ghi chú tiêu chuẩn vàng về nguồn nhập. Tất cả các nhóm thử nghiệm đều đi theo một kế hoạch chú thích thống nhất, đó là hệ thống kể cả. Trong tờ giấy này, chúng tôi xác định phương pháp phân tích nhiệm vụ và phương pháp đánh giá, miêu tả cách soạn các bộ dữ liệu, báo cáo và phân tích kết quả chính, và cung cấp một phân loại ngắn các phương pháp khác nhau của các hệ thống tham gia.', 'bg': 'Конференцията по компютърно учене на естествени езици (CoNLL) включва споделена задача, в която участниците обучават и тестват своите учебни системи на едни и същи масиви от данни. През 2017 г. задачата беше посветена на анализатори на зависимостта от учене за голям брой езици, в реална среда без никаква анотация със златен стандарт върху входа. Всички тестови набори следват единна схема на анотация, а именно тази на Универсалните зависимости. В настоящата статия дефинираме задачата и методологията за оценка, описваме как са изготвени наборите от данни, отчитаме и анализираме основните резултати и предоставяме кратка категоризация на различните подходи на участващите системи.', 'da': 'Konferencen om Computational Natural Language Learning (CoNLL) indeholder en fælles opgave, hvor deltagerne træner og tester deres læringssystemer på de samme datasæt. I 2017 blev opgaven dedikeret til at lære afhængighedsfortolkere for et stort antal sprog i en virkelig verden uden nogen guldstandard annotation på input. Alle testsæt fulgte en samlet annotationsordning, nemlig universelle afhængigheder. I denne artikel definerer vi opgave og evalueringsmetode, beskriver, hvordan datasættene blev udarbejdet, rapporterer og analyserer de vigtigste resultater og giver en kort kategorisering af de forskellige tilgange til de deltagende systemer.', 'nl': 'De Conferentie on Computational Natural Language Learning (CoNLL) heeft een gedeelde taak, waarbij deelnemers hun leersystemen trainen en testen op dezelfde datasets. In 2017 werd de taak gewijd aan het leren van afhankelijkheidsparsers voor een groot aantal talen, in een echte omgeving zonder gouden standaard annotatie op invoer. Alle testsets volgden een uniform annotatieschema, namelijk dat van Universal Dependencies. In dit artikel definiëren we de taak- en evaluatiemethodologie, beschrijven we hoe de datasets zijn opgesteld, rapporteren en analyseren we de belangrijkste resultaten en geven we een korte categorisering van de verschillende benaderingen van de deelnemende systemen.', 'hr': 'Konferencija o učenju računalnih prirodnih jezika (CoNLL) prikazuje zajednički zadatak u kojem sudionici vladaju i testiraju svoje sustave učenja na istim podacima. U 2017. godini, zadatak je bio posvećen razmatračima zavisnosti za veći broj jezika u stvarnom svijetu bez zlatnog standardnog annotacije o ulazu. Svi testovi su slijedili jedinstvenu annotaciju, a to je univerzalnu zavisnost. U ovom papiru definiramo metodologiju zadataka i procjene, opisujemo kako su pripremljeni setovi podataka, prijavili i analizirali glavne rezultate, i pružali kratku kategoriju različitih pristupa sustava sudjelovanja.', 'de': 'Die Conference on Computational Natural Language Learning (CoNLL) bietet eine gemeinsame Aufgabe, bei der Teilnehmer ihre Lernsysteme auf denselben Datensätzen trainieren und testen. In 2017 widmete sich die Aufgabe dem Lernen von Abhängigkeitsparsern für eine große Anzahl von Sprachen, in einer realen Umgebung ohne Goldstandard-Anmerkungen bei der Eingabe. Alle Testsätze folgten einem einheitlichen Annotationsschema, nämlich dem von Universal Dependencies. In diesem Beitrag definieren wir die Aufgabenstellung und Evaluationsmethodik, beschreiben die Aufbereitung der Datensätze, berichten und analysieren die wichtigsten Ergebnisse und geben eine kurze Kategorisierung der verschiedenen Ansätze der beteiligten Systeme.', 'id': 'Konferensi tentang Komputasi Belajar Bahasa Alami (CoNLL) memiliki tugas yang sama, di mana peserta melatih dan menguji sistem belajar mereka pada set data yang sama. Pada tahun 2017, tugas ini didedikasikan untuk mempelajari pengendalian dependensi untuk sejumlah besar bahasa, dalam pengaturan dunia nyata tanpa anotasi standar emas apapun pada input. Semua set tes mengikuti skema anotasi yang bersatu, yaitu skema Dependensi Universal. Dalam kertas ini, kami mendefinisikan metodologi tugas dan evaluasi, menjelaskan bagaimana set data telah disediakan, melaporkan dan menganalisis hasil utama, dan menyediakan kategorisasi singkat dari pendekatan yang berbeda dari sistem yang berpartisipasi.', 'ko': '컴퓨팅 자연 언어 학습 회의(ConLL)는 공유 임무를 특색으로 하고 참가자들은 같은 데이터 집합에서 그들의 학습 시스템을 훈련하고 테스트한다.2017년에 이 임무는 실제 환경에서 대량의 언어의 의존 관계 해석기를 배우는 데 주력했고 입력에 어떠한 금표준 주석도 없었다.모든 테스트 집합은 일반적인 의존적인 주석 방안인 통일된 주석 방안을 따른다.본고에서 우리는 임무와 평가 방법을 정의하고 데이터 집합이 어떻게 준비되었는지 묘사하며 주요 결과를 보고하고 분석했으며 참여 시스템의 다양한 방법을 간략하게 분류했다.', 'fa': 'کنفرانس درباره یادگیری زبان طبیعی کامپیوتر (CoNLL) یک کار مشترک را مشخص می\u200cکند که مشترک\u200cها در آن آموزش می\u200cکنند و سیستم یادگیری خود را در یک مجموعه داده\u200cها آزمایش می\u200cکنند. در سال ۲۰۱۷، این وظیفه برای یادگیری پارسالهای بستگی برای تعداد زیادی از زبانها، در یک تنظیمات دنیای واقعی بدون هیچ نویسندگی طلا و استاندارد در ورودی استفاده کرد. تمامی مجموعه\u200cهای آزمایش یک برنامه\u200cی آزمایش متحده را دنبال کردند، که به عنوان بستگی جهانی است. در این کاغذ، ما روش ارزش و ارزش را تعریف می\u200cکنیم، تعریف می\u200cکنیم که چگونه مجموعه\u200cهای داده\u200cها آماده شده، گزارش می\u200cکنیم و نتایج اصلی را تحلیل می\u200cکنیم، و یک دستور کوتاه از دستور\u200cهای مختلف سیستم\u200cهای شرکت می\u200cکنند.', 'sw': 'Mkutano wa Elimu ya Lugha ya Kiasili (CoNLL) unaonyesha kazi ya ushirikiano, ambapo washiriki wanafunza na kujaribu mfumo wao wa kujifunza katika seti za data hizo. Mwaka 2017, jukumu lililenga kujifunza bunge la kutegemea kwa lugha nyingi, katika mazingira ya kimataifa bila matangazo yoyote ya kawaida ya dhahabu. Vitengo vyote vya majaribio vilifuatilia mpango wa kuchanganyikiwa, yaani kutegemea matumaini ya ulimwengu. Katika karatasi hii, tunaelezea mbinu za kazi na uchunguzi, tunaelezea jinsi seti za data zilvyoandaliwa, kuripoti na uchambuzi matokeo makuu, na kutoa makundi fupi ya mbinu tofauti za mfumo wa ushiriki.', 'tr': "CoNLL Kompýuterler tebigat dil öwrenmesi barada konferensiýa (kompýuterler tebigat dillerini öwrenmesi barada) paylaşyk bir zady barýar. Şol wagtlar hem iştirakçiler şol wagtlar bilen öwrenme sistemalaryny bir maglumatlarda ç 2017-nji ýylda bu zady birnäçe diller üçin daşary çykyşlyklary öwrenmek üçin paýlaşdy. Gerçek dünýäde girişinde altyn-standart täblişenler ýok edildi. Hemme testiň düzümleri birleşikde bir täblisaň şemasyny yzarlady, iň görä Universal dependencies'iň. Bu kagyzda, biz görevi we deňlenme methodologiýany tassyýarys, maglumat düzümleriniň nähili taýýarlandygyny, hasaplap we esasy netijelerini çözdirip, we çarpyşyk sistemleriniň beýleki golaýlaryny saýlaýrys.", 'af': "Die Konferensie oor Rekenaar Natuurlike Taal Leer (CoNLL) is 'n gedeelde taak, waarin deelnaders trein en toets hul leersystems op dieselfde data stelle. In 2017, die taak was besluit om afhanklikheidverwerkers te leer vir 'n groot aantal tale, in 'n regte wêreld instelling sonder enige goud-standaard annotasie op invoer. Alle toets stelle volg 'n eenvoudige annotasie skema, naamlik wat van Universele Afhanklikhede. In hierdie papier definieer ons die taak en evalueringsmetodologie, beskrywe hoe die data stelle berei was, raporteer en analyseer die hoofresultate, en verskaf 'n kort kategoriseering van die verskillende toegang van die deelnadende stelsels.", 'sq': 'Konferenca mbi Mësimin e Gjuhave Natyrore Komputative (CoNLL) paraqet një detyrë të përbashkët në të cilën pjesëmarrësit trainojnë dhe testojnë sistemet e tyre të mësimit në të njëjtat grupe të dhënash. Në 2017, detyra u përkushtua mësimit të analizuesve të varësisë për një numër të madh gjuhësh, në një ambient të botës reale pa ndonjë anotacion të standartit të artë në hyrje. Të gjitha grupet e testit pasuan një skemë të unifikuar anotacioni, veçanërisht atë të Varësive Universale. Në këtë letër, ne përcaktojmë metodologjinë e detyrës dhe vlerësimit, përshkruajmë si u përgatitën grupet e të dhënave, raportojmë dhe analizojmë rezultatet kryesore dhe ofrojmë një kategorizim të shkurtër të qasjeve të ndryshme të sistemeve pjesëmarrëse.', 'am': 'ጉባኤው በኮንቡቲካዊ ትምህርት ቋንቋ ትምህርት (CoNLL) የተጠቃሚ ስራዎችን ያስተካክላል፤ በተጨማሪዎቹ በዚያው ዳታ ተማሪዎች ሲስተማርናቸውን ይሞክራሉ፡፡ በ2017፣ ስራው በብዙ ቋንቋዎች ላይ የተደገመ የፓርላር ምርጫዎች ለመማር ነው፡፡ የፍትሕት ምርጫዎች በዚህ ፕሮግራም፣ የስራውን እና ማስታወቂያውን ማድረግ እናሳውቃለን፣ የዋነኛው ፍሬዎችን እንዴት እንደተዘጋጁ፣ እንደተዘጋጁ እና እንደምናስተምር እና የልዩ ሥርዓቶች ልዩ ልዩ ልዩነት ክፍተቶችን እናሳውቃለን፡፡', 'hy': 'Համակարգչային բնական լեզվի սովորելու կոնֆերանսը (CONSL) ունի ընդհանուր խնդիր, որտեղ մասնակիցները մարզի և փորձում են իրենց սովորելու համակարգերը նույն տվյալների համակարգերի վրա: 2017 թվականին խնդիրը նվիրված էր շատ լեզուների սովորելու կախվածության վերլուծումներին իրական աշխարհում առանց որևէ ոսկու ստանդարտ նշումների: Բոլոր փորձարկման համակարգերը հետևում էին միասնական annoտացիայի համակարգին, հատկապես համաշխարհային կախվածությունների համակարգին: Այս թղթի մեջ մենք սահմանում ենք առաջադրանքը և գնահատման մեթոդոլոգիան, նկարագրում ենք, թե ինչպես են պատրաստվել տվյալների համակարգերը, զեկուցում և վերլուծում հիմնական արդյունքները, և տրամադրում են կարճ կատեգորիզացիա մասնակցում առկա համակարգերի տար', 'az': 'Kompüterlik Təbiətli Dil Öyrənməsi (CoNLL) konferensiyası paylaşılan bir işə məxsus edir, orada iştirakçilər birlikdə öyrənmə sistemlərini eyni verilən setlərdə təhsil edir. 2017-ci ildə bu işin çox dillər üçün bağımlılıq ayırıcıları öyrənməyə məcburiyyət edildi. Gerçek dünyada heç bir qızıl-standart istifadə edilmədən. Bütün sınama qurğuları birləşdirilmiş şəkildə təqib etdi, o da Universal dependencies. Bu kağızda, iş və değerlendirmə metodikasını belə tanımlıyıq, verilən qurğularının necə hazırlandığını, raporlarını və başqa sonuçlarını analiz edirik, və müxtəlif sistemlərin müxtəlif tərzlərinin qısa kategoriyasını təmin edirik.', 'ca': "La Conferència sobre l'aprenentatge computacional de llenguatges naturals (CoNLL) té una tasca compartida, en la qual els participants entrenen i testen els seus sistemes d'aprenentatge en els mateixos conjunts de dades. El 2017, la tasca va ser dedicada a aprendre analitzadors de dependencies per moltes llengües, en un entorn real sense cap anotació d'or. All test sets followed a unified annotation scheme, namely that of Universal Dependencies.  En aquest paper, definim la metodologia de la tasca i l'evaluació, descrivim com van preparar els conjunts de dades, informem i analitzem els principals resultats i proporcionem una breu categorització dels diferents enfocaments dels sistemes participants.", 'cs': 'Konference o výpočetním učení přírodního jazyka (CoNLL) představuje společný úkol, ve kterém účastníci trénují a testují své učební systémy na stejných datových sadách. V letech 2017 byl úkol věnován analýze závislosti učení pro velké množství jazyků, v reálném prostředí bez jakékoliv zlaté standardní anotace na vstupu. Všechny testovací sady se řídily jednotným anotačním schématem, konkrétně univerzálními závislostmi. V tomto článku definujeme metodiku úkolu a hodnocení, popisujeme způsob přípravy datových sad, nahlásíme a analyzujeme hlavní výsledky a stručně kategorizujeme různé přístupy zúčastněných systémů.', 'et': 'Arvutusliku looduskeeleõppe konverents (CoNLL) sisaldab ühist ülesannet, kus osalejad treenivad ja testivad oma õppesüsteeme samade andmekogumitega. 2017. aastal pühendati ülesanne õppesõltuvuse parseritele paljude keelte jaoks reaalses maailmas, ilma et sisendil oleks mingeid kuldstandardite annotatsioone. Kõik testikomplektid järgisid ühtset annoteerimisskeemi, nimelt universaalsete sõltuvuste skeemi. Käesolevas töös määratleme ülesande ja hindamismeetodi, kirjeldame andmekogumite koostamist, esitame ja analüüsime peamisi tulemusi ning esitame lühikese kategoorialiseerimise osalevate süsteemide erinevatest lähenemisviisidest.', 'fi': 'Konferenssi Computational Natural Language Learning (CoNLL) sisältää yhteisen tehtävän, jossa osallistujat harjoittelevat ja testaavat oppimisjärjestelmiään samoilla tietokokonaisuuksilla. Vuonna 2017 tehtävä omistettiin oppimisriippuvuuden parsereille monille kielille todellisessa maailmassa ilman kultaisia merkintöjä syötteessä. Kaikki testisarjat noudattivat yhtenäistä merkintäjärjestelmää, nimittäin Universaaliset riippuvuudet. Tässä työssä määritellään tehtävä- ja arviointimenetelmä, kuvataan aineistojen valmistelua, raportoidaan ja analysoidaan tärkeimmät tulokset sekä esitetään lyhyt kategorisointi osallistuvien järjestelmien eri lähestymistavoista.', 'bs': 'Konferencija o učenju kompjuterskih prirodnih jezika (CoNLL) prikazuje zajednički zadatak, u kojem učesnici treniraju i testiraju svoje sustave učenja na istim podacima. U 2017. godini, zadatak je bio posvećen parserima zavisnosti za veći broj jezika, u stvarnom svijetu, bez zlatnog standardnog annotacije o ulazu. Svi testovi su pratili ujedinjenu annotaciju, a to je univerzalne zavisnosti. U ovom papiru definišemo metodologiju zadataka i procjene, opisujemo kako su podaci pripremljeni, prijavili i analizirali glavne rezultate, i pružali kratku kategoriju različitih pristupa sustava sudjelovanja.', 'bn': 'কনফিউটাশনেশনের প্রাকৃতিক ভাষা শিক্ষা সম্মেলনের (কএনএল) একটি শেয়ার কর্মসূচী প্রদর্শন করেছে, যার মধ্যে অংশগ্রহণকারীরা একই তথ্য সেটে তাদে ২০১৭ সালে এই কাজটি বিশাল ভাষার জন্য নির্ভর পার্সার শিক্ষার জন্য বিশেষ করা হয়েছিল, যেখানে ইনপুটের কোন সোনার্ন্ডারেন্ড সকল পরীক্ষার সেট একটি একত্রিত অ্যান্টারেশন পরিকল্পনা অনুসরণ করেছে, যেটি বিশ্ববিদ্যালয়ের নির্ভর। এই কাগজটিতে আমরা কাজ ও মূল্যায়নের পদ্ধতি নির্ধারণ করি, বর্ণনা করি কিভাবে তথ্য সেট প্রস্তুত, রিপোর্ট এবং প্রধান ফলাফল বিশ্লেষণ করা হয়েছে এবং অংশগ্রহণকার', 'sk': 'Konferenca o računalniškem učenju naravnih jezikov (CoNLL) predstavlja skupno nalogo, v kateri udeleženci usposabljajo in testirajo svoje učne sisteme na istih podatkovnih nizikih. Leta 2017 je bila naloga posvečena razčlenjevalnikom odvisnosti od učenja za veliko število jezikov, v realnem svetu brez kakršnih koli zlatih standardov pripomb na vnos. Vsi preskusni nabori so sledili enotni shemi označevanja, in sicer shemi univerzalnih odvisnosti. V prispevku opredelimo nalogo in metodologijo ocenjevanja, opišemo pripravo podatkovnih nizov, poročamo in analiziramo glavne rezultate ter zagotovimo kratko kategorizacijo različnih pristopov sodelujočih sistemov.', 'he': 'הישיבה על הלימוד של שפת טבעית מחשבית (CoNLL) מכילה משימה משותפת, שבה השתתפים מאמן ומבחנים את מערכות הלימוד שלהם על אותם קבוצות נתונים. בשנת 2017, המשימה הוקדשה ללמוד חוקרי תלויות למספר גדול של שפות, במסגרת עולם אמיתי ללא שום ציון סטנדרטי זהב על הכניסה. כל הקבוצות הבדיקות עקבו אחרי תכנית הערות מאוחדת, כלומר של תלויות יוניברסליות. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems.', 'ha': "Umarnin da ake amfani da wani aikin da aka sanar da shi a cikin Lugha na Kamutar Natural (CoNLL) na ƙayyade wani shirin aiki, a cikinsa mãsu shirin zama suna yin amfani da kuma suna jarraba tsarin su masu karantawa a kan daidaita data masu daidaita. A shekara 2017, aikin ya yi amfani da karatun parser masu inganci ga wasu harshe masu yawa, a cikin a daidaita duniya masu gaskiya, kuma bã da wani alama na tsarin zĩnãriya na daidaita kan injistan. Duk tsari na jarraba suka bi wani shirin zartar da aka haɗa, yanzu, Bayan Kwanza da Kwanza. Ga wannan takardan, muna bayyana hanyar aikin da ake ƙaddara wa muhimmada, kuma muna bayyana kowanka hanyoyin bayani na tsari, a bayani, da kuma mu yi rarraba fassarar farko, kuma mu ƙayyade nau'i-nau'i ga masu motsi na fassarar shirin da ke haɗuwa.", 'jv': '"CoNLL" Anyone" for "a", "Bravo" for "inset politenessoffpolite"), and when there is a change ("assertive Nang paper iki, kéné Definir mêtho sing dadi nggawe sistem dadi nggawe, winih lan cara nggawe perusahaan sistem sing dadi nggawe, winih lan cara nggawe sistem sing berarti, lan nyeanye sakjane kategorisi sing menyang gerakan nganggep sistem sing beraksi banget.', 'bo': 'རྩིས་འཁོར་གྱི་སྤྱི་ཚོགས ༢༠༡༧་ལོའི་ནང་དུ་འཇུག་སྣོད་འདི་ལྟ་བུའི་ནང་དུ་རྟེན་འབྲེལ་བའི་སྐད་རིགས་མང་ཆེ་ཤོས་ལ་བསླབས་པའི་མིང་རྩལ་གྱི་སྒྲིག་སྟངས་ལ་ བརྟག་ཞིབ ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་བྱ་ཚིག་དང་གཟུགས་རིས་ཐབས་ལམ་ལུགས་གསལ་བཤད་ཀྱི་ཡོད།'}
{'en': 'Stanford’s Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task', 'ar': 'محلل التبعية العصبية المستند إلى الرسم البياني في جامعة ستانفورد في المهمة المشتركة CoNLL 2017', 'fr': 'Analyseur de dépendance neuronale basé sur des graphes de Stanford lors de la tâche partagée ConLL 2017', 'es': 'El analizador de dependencias neuronales basado en gráficos de Stanford en la tarea compartida de CoNll 2017', 'pt': 'Analisador de dependência neural baseado em gráfico de Stanford na tarefa compartilhada CoNLL 2017', 'ja': 'CoNLL 2017共有タスクでのスタンフォードのグラフベースのニューラル依存性パーサー', 'zh': '斯坦福大学基于图神经赖解析器在CoNLL 2017共之', 'hi': 'CoNLL 2017 साझा कार्य में स्टैनफोर्ड का ग्राफ-आधारित तंत्रिका निर्भरता पार्सर', 'ru': 'Анализатор нейронной зависимости на основе графов Стэнфорда на совместной задаче CoNLL 2017', 'ga': 'Parsálaí um Spleáchas Néarach de chuid Stanford ag Tasc Comhroinnte CoNLL 2017', 'ka': 'სტანფორდის განსაზღვრებული ნეიროლური განსაზღვრებულობის პარჯერი CoNLL 2017 დასაზღვრებული დავალება', 'el': 'Η ανάλυση νευρωνικής εξάρτησης με βάση το γράφημα του Στάνφορντ στην κοινή εργασία CoNLL 2017', 'hu': 'Stanford grafikaalapú neurális függőség elemzője a CoNLL 2017 megosztott feladaton', 'mk': 'Стенфордскиот графички анализатор на неурална зависност на заедничката задача CoNLL 2017', 'it': 'Il parser di dipendenza neurale basato su grafico di Stanford al CoNLL 2017 Shared Task', 'lt': 'Stanford grafiniu būdu pagrįstas neurologinio priklausomybės analizatorius CoNLL 2017 m. bendroje užduotyje', 'kk': 'Стэнфордтың графикалық негіздеген нейрондық тәуелдік талдаушысы CoNLL 2017 ортақ тапсырмасында', 'ms': 'Penjana Dependensi Neural Berasas Graf Stanford di Tugas Berkongsi CoNLL 2017', 'ml': 'സ്റ്റാന്\u200dഫോര്\u200dഡിന്\u200dറെ ഗ്രാഫ് അടിസ്ഥാനമായ നെയുറല്\u200d ഡിപ്പെന്\u200dസി പാര്\u200dസര്\u200d കോണ്\u200dഎല്\u200d 2017 പങ്കുചേര്\u200dത്ത പണി', 'mt': "Il-Parser tad-Dipendenza Newrali bbażat fuq il-Grafiki ta' Stanford fil-Kompitu Konġunt CoNLL 2017", 'mn': 'Стэнфордын график суурилсан мэдрэлийн хамааралын парзер 2017 оны CoNLL', 'pl': "Stanford's Graph-based Neuronal Dependency Parser w CoNLL 2017 Shared Task", 'ro': 'Analizatorul de dependență neurală bazat pe grafice al Stanford la sarcina partajată CoNLL 2017', 'sr': 'Stanfordski razmatrač Neuralne zavisnosti na grafiku na CoNLL 2017. delu zadataka', 'si': 'ස්ටැන්ෆෝර්ඩ්ගේ ග්\u200dරාෆ් අධාරිත නිර්මාණ විශේෂතාවක් පරිස්සර් කරනවා CoNLL 2017 කොටස් කාර්ය', 'so': 'Jardiino ku saabsan qoyska mas’uulka ee Stanford ee ku saleysan Graph ee CoNLL 2017', 'sv': 'Stanfords grafbaserade neural beroendeanalysator vid CoNLL 2017 Shared Task', 'ta': 'கோன்எல் 2017 பகிர்ந்த பணியில் ஸ்டான்போர்டின் வரைபடத்திலான நெயுரல் சார்ந்த சார்ந்த பார்சர்', 'no': 'Stanford sin grafikkbasert neuralavhengighetsanalyser på CoNLL 2017 delt oppgåve', 'ur': 'سنفورد کے گراف بنیادی نیورل ڈیفاندنسی پارسر کی CoNLL 2017 شریک ٹاکس میں', 'uz': 'Comment', 'vi': 'Bộ phân tích thần kinh thuộc s ự phân phối của Stanford tại hội đồng', 'bg': 'Графичен анализ на нервната зависимост на Станфорд на споделената задача', 'da': 'Stanfords grafbaserede neural afhængighed parser ved CoNLL 2017 delte opgave', 'nl': "Stanford's Graph-based Neural Dependency Parser bij de CoNLL 2017 Shared Task", 'hr': 'Stanfordski analitičar neurološke zavisnosti na grafiku na CoNLL 2017.', 'id': 'Stanford Graph-based Neural Dependency Parser di CoNLL 2017 Shared Task', 'ko': '스탠퍼드대 CoNLL 2017 공유 임무에 대한 도형 기반 신경 의존성 해상도', 'de': "Stanford's Graph-based Neurol Dependency Parser am CoNLL 2017 Shared Task", 'sw': 'Mbunge wa Uhuru wa Neural anayeishi kwenye Graph wa Stanford katika CoNLL 2017', 'af': 'Stanford se graf-gebaseerde neurale afhanklikheidverwerker by die CoNLL 2017 Gedeelde taak', 'fa': 'پارسال اعتمادی عصبی بر اساس گراف استنفورد در کار مشترک CoNLL 2017', 'am': 'የስቴንፎርድ ካለው የኔural ድጋፍ ፓርስር በኮንጆል 2017 የተሰራጨው ስራ', 'sq': 'Analizatori i Varësisë Neurale me bazë në grafikë i Stanfordit në detyrën e përbashkët të CoNLL 2017', 'hy': 'Ստենֆորդի գրաֆային հիմնված նյարդային կախվածության խմբագրիչը 2017 թվականի համագործակցած հանձնարարում', 'tr': 'CoNLL 2017-nji CoNLL sahypasynda Stanfordyň grafiki tabanly näsaz baglanyşyklygyny s özledi', 'az': "Stanford's Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task", 'bn': 'কনএল ২০১৭ সালে স্টানফোর্ডের গ্রাফ ভিত্তিক নিউরাল নির্ভর পার্সার', 'bs': 'Stanfordski analitičar Neuralne zavisnosti na grafiku na CoNLL 2017-om zajedničkom zadatku', 'cs': 'Stanfordův graf založený na neuronové závislosti Parser na CoNLL 2017 Sdílená úloha', 'et': 'Stanfordi graafikapõhine neurosõltuvuse parser CoNLL 2017 jagatud ülesandel', 'fi': 'Stanfordin graafinen neuroriippuvuuden parser CoNLL 2017:n yhteisessä tehtävässä', 'ca': "L'analitzador neuronal de Dependencia basat en gràfics de Stanford a la CoNLL 2017 Shared Task", 'jv': 'Graph-Ngawe Buffet-Buffet seneng Neral Dewekenengke Paraser nang CoNLL 2013 Joined Job', 'ha': 'KCharselect unicode block name', 'sk': 'Stanfordov pregledovalnik nevronske odvisnosti, ki temelji na grafu, na skupni nalogi CoNLL 2017', 'he': 'מפרסם תלויות נוירוליות בסטנפורד במשימה משותפת CoNLL 2017', 'bo': 'CoNLL 2017 མཉམ་སྤྱོད་པའི་བྱ་སྤྱོད་ལ་Stanford་ཡིག་པར་གཞི་བརྟེན་པའི་ནུས་པ་རྒྱུན་ལྡན་གྱི་གཟུགས་རིས།'}
{'en': 'This paper describes the neural dependency parser submitted by Stanford to the CoNLL 2017 Shared Task on parsing Universal Dependencies. Our system uses relatively simple LSTM networks to produce part of speech tags and labeled dependency parses from segmented and tokenized sequences of words. In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters. Our system was ranked first according to all five relevant metrics for the system : UPOS tagging (93.09 %), XPOS tagging (82.27 %), unlabeled attachment score (81.30 %), labeled attachment score (76.30 %), and content word labeled attachment score (72.57 %).', 'ar': 'تصف هذه الورقة محلل التبعية العصبية المقدم من ستانفورد إلى المهمة المشتركة لـ CoNLL 2017 حول تحليل التبعيات العالمية. يستخدم نظامنا شبكات LSTM بسيطة نسبيًا لإنتاج جزء من علامات الكلام وتحليلات التبعية ذات العلامات من تسلسلات الكلمات المجزأة والمرمز لها. من أجل معالجة مشكلة الكلمات النادرة التي تزخر باللغات ذات التشكل المعقد ، نقوم بتضمين تمثيل الكلمة المستند إلى الأحرف الذي يستخدم LSTM لإنتاج الزخارف من تسلسل الأحرف. تم تصنيف نظامنا في المرتبة الأولى وفقًا لجميع المقاييس الخمسة ذات الصلة بالنظام: علامات UPOS (93.09٪) ، وعلامات XPOS (82.27٪) ، ودرجة المرفقات غير المصنفة (81.30٪) ، ودرجة المرفقات المصنفة (76.30٪) ، والمرفق المسمى كلمة المحتوى درجة (72.57٪).', 'fr': "Cet article décrit l'analyseur de dépendance neuronale soumis par Stanford à la tâche partagée ConLL 2017 sur l'analyse des dépendances universelles. Notre système utilise des réseaux LSTM relativement simples pour produire une partie des étiquettes vocales et des analyses de dépendance étiquetées à partir de séquences de mots segmentées et tokenisées. Afin de résoudre le problème des mots rares qui abondent dans les langues à morphologie complexe, nous incluons une représentation de mots basée sur des caractères qui utilise un LSTM pour produire des incorporations à partir de séquences de caractères. Notre système a été classé premier selon les cinq indicateurs pertinents pour le système\xa0: marquage UPOS (93,09\xa0%), marquage XPOS (82,27\xa0%), score de pièces jointes sans étiquette (81,30\xa0%), score de pièces jointes étiquetées (76,30\xa0%) et score de pièces jointes étiquetées par mot de contenu (72,57\xa0%).", 'es': 'Este artículo describe el analizador de dependencias neuronales presentado por Stanford a la tarea compartida de CoNll 2017 sobre el análisis de dependencias universales. Nuestro sistema utiliza redes LSTM relativamente simples para producir parte de etiquetas de voz y análisis de dependencias etiquetadas a partir de secuencias de palabras segmentadas y tokenizadas. Para abordar el raro problema de palabras que abunda en los idiomas con morfología compleja, incluimos una representación de palabras basada en caracteres que utiliza un LSTM para producir incrustaciones a partir de secuencias de caracteres. Nuestro sistema ocupó el primer lugar de acuerdo con las cinco métricas relevantes para el sistema: etiquetado UPOS (93,09%), etiquetado XPOS (82,27%), puntuación de adjuntos sin etiqueta (81,30%), puntuación de adjuntos etiquetados (76,30%) y puntuación de adjuntos etiquetados con palabras de contenido (72,57%).', 'pt': 'Este artigo descreve o analisador de dependência neural enviado por Stanford à tarefa compartilhada CoNLL 2017 sobre análise de dependências universais. Nosso sistema usa redes LSTM relativamente simples para produzir parte de tags de fala e análises de dependência rotuladas de sequências de palavras segmentadas e tokenizadas. Para resolver o problema de palavras raras que abunda em idiomas com morfologia complexa, incluímos uma representação de palavras baseada em caracteres que usa um LSTM para produzir embeddings de sequências de caracteres. Nosso sistema foi classificado em primeiro lugar de acordo com todas as cinco métricas relevantes para o sistema: marcação UPOS (93,09%), marcação XPOS (82,27%), pontuação de anexo não rotulado (81,30%), pontuação de anexo rotulado (76,30%) e anexo rotulado de palavra de conteúdo pontuação (72,57%).', 'ja': '本稿では、ユニバーサル依存関係の解析に関するCoNLL 2017共有タスクにスタンフォードが提出したニューラル依存関係解析器について説明する。当社のシステムは、比較的単純なLSTMネットワークを使用して、セグメント化されトークン化された単語シーケンスから音声タグの一部とラベル付けされた依存関係パースを生成します。複雑な形態を持つ言語に多く存在する希少な単語の問題に対処するために、LSTMを使用して文字のシーケンスから埋め込みを生成する文字ベースの単語表現を含めます。当社のシステムは、UPOSタグ付け（ 93.09 ％ ）、XPOSタグ付け（ 82.27 ％ ）、非標識添付スコア（ 81.30 ％ ）、標識添付スコア（ 76.30 ％ ）、およびコンテンツ単語標識添付スコア（ 72.57 ％ ）の5つの関連する指標すべてに基づいて1位にランク付けされました。', 'zh': '本文言斯坦福大学交CoNLL 2017共享之神经依赖性解析器,其事涉解析通用赖。 吾统用简 LSTM 网络生于分段、标之单词序词性标记赖解析。 杂形之语,比于奇单词,盖一符之单词,其用LSTM嵌于字符也。 凡系统五相关指标第一:UPOS标(93.09%),XPOS标(82.27%),未标附件分数(81.30%),标附件分数(76.30%)与单词标附件分数(72.57%)。', 'hi': 'यह पेपर स्टैनफोर्ड द्वारा प्रस्तुत किए गए तंत्रिका निर्भरता पार्सर का वर्णन करता है, जो यूनिवर्सल निर्भरताओं को पार्स करने पर CoNLL 2017 साझा कार्य में प्रस्तुत किया गया है। हमारा सिस्टम भाषण टैग के हिस्से का उत्पादन करने के लिए अपेक्षाकृत सरल एलएसटीएम नेटवर्क का उपयोग करता है और शब्दों के खंडित और टोकन अनुक्रमों से लेबल निर्भरता पार्स। जटिल आकृति विज्ञान वाली भाषाओं में प्रचुर मात्रा में आने वाली दुर्लभ शब्द समस्या को संबोधित करने के लिए, हम एक चरित्र-आधारित शब्द प्रतिनिधित्व शामिल करते हैं जो वर्णों के अनुक्रमों से एम्बेडिंग का उत्पादन करने के लिए एक एलएसटीएम का उपयोग करता है। हमारे सिस्टम को सिस्टम के लिए सभी पांच प्रासंगिक मैट्रिक्स के अनुसार पहले स्थान पर रखा गया था: UPOS टैगिंग (93.09%), XPOS टैगिंग (82.27%), बिना लेबल वाले अनुलग्नक स्कोर (81.30%), लेबल किए गए अनुलग्नक स्कोर (76.30%), और सामग्री शब्द लेबल अनुलग्नक स्कोर (72.57%)।', 'ru': 'В этой статье описывается нейронный парсер зависимостей, представленный Стэнфордом совместной задаче CoNLL 2017 по синтаксическому анализу универсальных зависимостей. Наша система использует относительно простые сети LSTM для создания части речевых тегов и синтаксического анализа зависимостей из сегментированных и токенизированных последовательностей слов. Чтобы решить проблему редких слов, которая изобилует в языках со сложной морфологией, мы включаем представление слов на основе символов, которое использует LSTM для создания вложений из последовательностей символов. Наша система заняла первое место по всем пяти релевантным показателям для системы: метки UPOS (93,09%), метки XPOS (82,27%), оценка немеченого вложения (81,30%), оценка меченого вложения (76,30%) и оценка контентного слова меченого вложения (72,57%).', 'ga': 'Déanann an páipéar seo cur síos ar an parsálaí spleáchais néaraigh a chuir Stanford isteach chuig Tasc Comhroinnte CoNLL 2017 maidir le Spleáchais Uilíocha a pharsáil. Úsáideann ár gcóras líonraí LSTM sách simplí chun cuid de chlibeanna cainte agus parsanna spleáchais lipéadaithe a tháirgeadh ó sheichimh focal deighilte agus tokenized. Chun dul i ngleic leis an bhfadhb neamhchoitianta focal atá go flúirseach i dteangacha le moirfeolaíocht chasta, tá léiriú focal bunaithe ar charachtar san áireamh againn a úsáideann LSTM chun leabaithe a tháirgeadh ó sheichimh de charachtair. Rangaíodh ár gcóras ar dtús de réir na gcúig mhéadracht ábhartha go léir don chóras: clibeáil UPOS (93.09%), clibeáil XPOS (82.27%), scór ceangaltán neamhlipéadaithe (81.30%), scór ceangaltán lipéadaithe (76.30%), agus ábhar iatán lipéadaithe i bhfocail scór (72.57%).', 'el': 'Αυτή η εργασία περιγράφει τον αναλυτή νευρωνικής εξάρτησης που υποβλήθηκε από το Στάνφορντ στην κοινή εργασία για την ανάλυση καθολικών εξαρτήσεων. Το σύστημά μας χρησιμοποιεί σχετικά απλά δίκτυα για την παραγωγή μέρους ετικετών ομιλίας και μαρκαρισμένων αναλύσεων εξάρτησης από τμηματικές και σημειωμένες ακολουθίες λέξεων. Προκειμένου να αντιμετωπιστεί το σπάνιο πρόβλημα λέξεων που αφθονεί σε γλώσσες με σύνθετη μορφολογία, συμπεριλαμβάνουμε μια απεικόνιση λέξεων βασισμένη σε χαρακτήρες που χρησιμοποιεί ένα LSTM για την παραγωγή ενσωμάτωσης από ακολουθίες χαρακτήρων. Το σύστημά μας κατατάχθηκε πρώτος σύμφωνα με τις πέντε σχετικές μετρήσεις για το σύστημα: βαθμολογία επισυνάπωσης χωρίς επισήμανση (81.30%) βαθμολογία επισυνάπωσης (76.30%) και βαθμολογία συνημμένου περιεχομένου με επισήμανση (72.57%).', 'hu': 'Ez a tanulmány bemutatja a Stanford által az Univerzális Függőségek elemzéséről szóló CoNLL 2017 Shared Task-hoz benyújtott neurális függőség elemzőt. Rendszerünk viszonylag egyszerű LSTM hálózatokat használ a beszédcímkék és a címkézett függőségi elemzések egy részének előállítására szegmentált és tokenizált szavak sorozataiból. Annak érdekében, hogy kezeljük a ritka szóproblémát, amely komplex morfológiával rendelkező nyelveken bővelkedik, olyan karakter alapú szóreprezentációt tartalmazunk, amely LSTM-t használ a karaktersorozatok beágyazására. Rendszerünk mind az öt releváns mérőszám alapján az első helyen állt: UPOS címkézés (93,09%), XPOS címkézés (82,27%), címke nélküli mellékleti pontszám (81,30%), címkézett mellékleti pontszám (76,30%) és tartalomszó címkézett mellékleti pontszám (72,57%).', 'ka': 'ამ დოკუნტის აღწერა სტანფორდის ნეირალური დადარწმუნებელობის პანსერაცია, რომელიც CoNLL 2017-ში გაყოფილი საზოგადოებული დავალებისთვის. ჩვენი სისტემა გამოყენება relatively simple LSTM ქსელების გამოყენება სიტყვების ჩანაწერების ნაწილი და მინიშვნელოვანი დასამხოლობა პარაზების სიტყვების და ტოკენიზულების სიტყვე სიტყვების პრობლემა, რომელიც კომპლექსიკური მორპოლოგიაში გახდება, ჩვენ შეგვიყვანეთ სიტყვების გამოსაყენება, რომელიც LSTM გამოყენებს სიტყვების სიტყვების შემდეგ შემ ჩვენი სისტემა პირველი იყო ყველა ხუთ მნიშვნელოვანი მეტრიკის განმავლობაში: UPOS-ის მაგრამ (93.09%), XPOS-ის მაგრამ (82.27%), დაკავშირებული მაგრამ (81.30%), მაგრამ დაკავშირებული მაგრამ (76.30%), და მნიშვნელოვანი სიტყვას მაგრამ (72.57', 'it': "Questo articolo descrive il parser di dipendenza neurale presentato da Stanford al CoNLL 2017 Shared Task sull'analisi delle dipendenze universali. Il nostro sistema utilizza reti LSTM relativamente semplici per produrre parte di tag vocali e analisi di dipendenza etichettate da sequenze segmentate e tokenizzate di parole. Per affrontare il problema delle parole rare che abbonda in linguaggi con morfologia complessa, includiamo una rappresentazione di parole basata sui caratteri che utilizza un LSTM per produrre incorporazioni da sequenze di caratteri. Il nostro sistema è stato classificato al primo posto in base a tutte e cinque le metriche rilevanti per il sistema: tag UPOS (93,09%), tag XPOS (82,27%), punteggio allegato non etichettato (81,30%), punteggio allegato etichettato (76,30%) e punteggio allegato etichettato con parole di contenuto (72,57%).", 'lt': 'Šiame dokumente aprašomas Stanford pasiūlytas neurologinio priklausomybės analizatorius bendrai CoNLL 2017 m. užduotims, susijusioms su universaliųjų priklausomybių analizavimu. Mūsų sistema naudoja palyginti paprastus LSTM tinklus, kad galėtų gaminti dalį kalbos žymenų ir žymėtų priklausomybės analizių iš segmentuotų ir žymėtų žodžių sekų. Siekiant išspręsti retą žodžių problem ą, kuri kyla sudėtingomis morfologinėmis kalbomis, mes įtraukiame ženklais pagrįstą žodžių atstovavimą, kuris naudoja LSTM gaminant įterpimus iš ženklų sekų. Mūsų sistema pirmiausia buvo priskirta prie visų penkių svarbių sistemos rodiklių: UPOS žymėjimas (93,09 %), XPOS žymėjimas (82,27 %), nepažymėtas pritvirtinimo taškas (81,30 %), pažymėtas pritvirtinimo taškas (76,30 %) ir turinio žodis žymėtas pritvirtinimo taškas (72,57 %).', 'mk': 'Овој весник го опишува анализаторот на нервната зависност поднесен од Стенфорд на Соделената задача CoNLL 2017 за анализирање на универзалните зависности. Нашиот систем користи релативно едноставни LSTM мрежи за да произведува дел од говорните ознаки и ознаки анализи на зависност од сегментирани и ознаки секвенции на зборови. In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters.  Нашиот систем беше рангиран прв според сите пет релевантни метрики за системот: УПОС означување (93,09%), XPOS означување (82,27%), неозначена оценка на приклучување (81,30%), означена оценка на приклучување (76,30%) и оценка на содржина означена со зборот на приклучување (72,57%).', 'ms': 'Kertas ini menggambarkan penghurai dependensi saraf dihantar oleh Stanford kepada Tugas Berkongsi CoNLL 2017 mengenai hurai dependensi Universal. Sistem kami menggunakan rangkaian LSTM relatif sederhana untuk menghasilkan sebahagian dari tag ucapan dan huraian dependensi yang ditanda dari urutan perkataan yang disegmen dan ditanda. Untuk mengatasi masalah perkataan langka yang bertambah dalam bahasa dengan morfologi kompleks, kita termasuk perwakilan perkataan berdasarkan aksara yang menggunakan LSTM untuk menghasilkan penyambungan dari urutan aksara. Our system was ranked first according to all five relevant metrics for the system: UPOS tagging (93.09%), XPOS tagging (82.27%), unlabeled attachment score (81.30%), labeled attachment score (76.30%), and content word labeled attachment score (72.57%).', 'kk': 'Бұл қағаз Стэнфорд 2017 жылы CoNLL 2017 жылы Ортақ тапсырмасын талдау үшін жіберілген невралдық тәуелдік талдаушысын анықтайды. Біздің жүйеміз сөйлеу тегтерінің бөлігін жасау үшін салыстырмалы қарапайым LSTM желілерін қолданады және сөздердің бөлігін белгіленген тәуелсіздік талдауын сегментті Комплекс морфологиялық тілдерде көбірек сөздер мәселесін шешу үшін, LSTM деген сөздерді таңбалардың реттерінен ендіру үшін қолданатын сөздерді таңдау үшін қолданатын. Жүйеміздің бес маңызды метрикаларына сәйкес ретінде бірінші ретінде орнатылды: UPOS тегтері (93, 09%), XPOS тегтері (82, 27%), тіркемелер нәтижесі (81, 30%), тіркемелер нәтижесі (76, 30%), мазмұнды тіркемелер нәтижесі (72, 57%).', 'ml': 'ഈ പത്രത്തില്\u200d സ്റ്റാന്\u200dഫോര്\u200dഡിന്റെ സ്റ്റാന്\u200dഫോര്\u200dഡ് ചെയ്തിട്ടുള്ള ന്യൂറല്\u200d ആശ്രയിക്കുന്ന പാര്\u200dസിങ്ങ് യൂണിവര്\u200dണല്\u200d  നമ്മുടെ സിസ്റ്റത്തില്\u200d എളുപ്പമുള്ള LSTM നെറ്റുകള്\u200d ഉപയോഗിക്കുന്നു. സംസാരിക്കുന്ന ടാഗുകളില്\u200d നിന്നും സംസാരിക്കുന്ന ആശ്രയ കുറഞ്ഞ വാക്കുകളുടെ പ്രശ്നമാണ് ഭാഷകളില്\u200d വളര്\u200dന്നുകൊണ്ടിരിക്കുന്നത്, കുഴപ്പമുള്ള മോര്\u200dഫോളജിയോടൊപ്പം കൂടിയ വാക്കുകളുടെ പ്രതിനിധിയ നമ്മുടെ സിസ്റ്റത്തിന്റെ എല്ലാ അഞ്ച് പ്രധാനപ്പെട്ട മെട്രിക്കുകളും ആദ്യം റെഞ്ച് ചെയ്യപ്പെട്ടിരുന്നു: UPOS ടാഗിങ്ങ് (93. 09%), XPOS ടാഗിങ്ങ് (82. 27%), അടയാളപ്പെടാത്ത അറ്റാച്ചെന്\u200dറ് സ്ക', 'mt': 'Dan id-dokument jiddeskrivi l-analizzatur tad-dipendenza newrali ppreżentat minn Stanford lill-CoNLL 2017 Shared Task dwar l-analizzazzjoni tad-Dipendenzi Universali. Is-sistema tagħna tuża netwerks LSTM relattivament sempliċi biex tipproduċi parti mit-tikketti tad-diskors u l-analiżijiet tad-dipendenza ttikkettati minn sekwenzi ta’ kliem segmentati u tokenizzati. Sabiex nindirizzaw il-problem a rari tal-kliem li tinsab abbundanti f’lingwi b’morfoloġija kumplessa, ninkludu rappreżentazzjoni tal-kliem ibbażata fuq il-karattri li tuża LSTM biex tipproduċi inkorporazzjonijiet minn sekwenzi ta’ karattri. Is-sistema tagħna kienet ikklassifikata l-ewwel skont il-ħames metriċi rilevanti kollha għas-sistema: tikkettar UPOS (93.09%), tikkettar XPOS (82.27%), punteġġ ta’ twaħħil mingħajr tikketta (81.30%), punteġġ ta’ twaħħil tikkettat (76.30%), u punteġġ ta’ twaħħil tikkettat bil-kelma tal-kontenut (72.57%).', 'mn': 'Энэ цаас Стэнфорд 2017 оны CoNLL 2017 оны Дэлхийн хамааралтай хамааралтай ажлыг хуваалцах тухай мэдрэлийн хамааралтай хуваалцагчийг тайлбарладаг. Бидний систем харьцангуй энгийн LSTM сүлжээг ашиглаж ярианы тегтүүдийн нэг хэсэг болон нэрлэгдсэн хамааралтай талаар хэлбэрээс, хэлбэрээс хамааралтай хэлбэрээс ашигладаг. Комплексийн морфологийг хэлэлцэх ховор үгний асуудлыг шийдэхийн тулд бид LSTM-г хэрэглэдэг хүмүүсийн дарааллаас бүрдүүлэх үгнээг нэмж байна. Бидний систем системийн таван хамааралтай метриктикүүдийн хувьд анхны хувьд анхны хувьд дүрслэгдсэн: UPOS Tagging (93.09%), XPOS Tagging (82.27%), бичигдэггүй attachment score (81.30%), attachment score (76.30%), content word labeled attachment score (72.57%).', 'pl': 'Niniejszy artykuł opisuje parser zależności neuronowej przesłany przez Stanford do wspólnego zadania CoNLL 2017 na temat parsowania zależności uniwersalnych. Nasz system wykorzystuje stosunkowo proste sieci LSTM do produkcji części tagów mowy i etykietowanych analiz zależności z segmentowanych i tokenizowanych sekwencji słów. Aby rozwiązać rzadki problem słów, który obfituje w języki o złożonej morfologii, zawieramy reprezentację słów opartą na znakach, która wykorzystuje LSTM do tworzenia osadzeń z sekwencji znaków. Nasz system znalazł się na pierwszym miejscu według wszystkich pięciu istotnych dla systemu wskaźników: tagowanie UPOS (93.09%) tagowanie XPOS (82.27%) punktowanie załącznika bez oznakowania (81.30%) punktowanie załącznika oznakowanego (76.30%) oraz punktowanie załącznika zawartości oznaczonego słowem oznaczonym załącznikiem (72.57%).', 'ro': 'Această lucrare descrie analizatorul de dependență neurală prezentat de Stanford la CoNLL 2017 Shared Task privind analizarea dependențelor universale. Sistemul nostru folosește rețele LSTM relativ simple pentru a produce o parte din etichetele vocale și analize de dependență etichetate din secvențe segmentate și tokenizate de cuvinte. Pentru a aborda problema cuvintelor rare care abundă în limbi cu morfologie complexă, includem o reprezentare bazată pe caractere cuvinte care utilizează un LSTM pentru a produce încorporări din secvențe de caractere. Sistemul nostru a fost clasat pe primul loc în funcție de toate cele cinci valori relevante pentru sistem: etichetarea UPOS (93,09%), etichetarea XPOS (82,27%), scorul atașamentului fără etichetă (81,30%), scorul atașamentului etichetat (76,30%) și scorul atașamentului etichetat cu cuvântul conținut (72,57%).', 'no': 'Denne papiret skildrar den neuralavhengighetsanalysen som Stanford sender til CoNLL 2017 delt oppgåve ved tolking av universelle avhengighet. Sistemet vårt bruker relativt enkle LSTM-nettverk for å produsera del av taletaggar og merke avhengighetstolkar frå segmenterte og tokniserte ordsekvens. For å setja opp det sjeldande ordproblemet som er opp i språk med komplekse morfologi, inkluderer vi eit teiknbasert ordrepresentasjon som brukar ein LSTM for å produsera innbygging frå rekkjefølgja teikn. Systemet vårt vart rankert først etter alle fem relevante metrikar for systemet: UPOS-merking (93,09%), XPOS-merking (82,27%), ubeabelte vedleggscore (81,30%), merket vedleggscore (76,30%), og innhaldsord merket vedleggscore (72,57%).', 'sr': 'Ovaj papir opisuje analizator neuralne zavisnosti koji je Stanford predao podijeljenom zadatku CoNLL 2017 o analizanju univerzalnih zavisnosti. Naš sistem koristi relativno jednostavne LSTM mreže kako bi proizveli deo znakova govora i preglede zavisnosti iz segmentiranih i tokeniranih sekvencija reči. Da bi se riješili rijetki problem riječi koji se širi jezicima sa kompleksnom morfologijom, uključujemo predstavljanje reči na karakteru koja koristi LSTM kako bi proizvela integracije iz sekvencija karaktera. Naš sistem je prvi rečen prema svim pet relevantnih metrika za sistem: označavanje UPOS-a (93,09%), označavanje XPOS-a (82,27%), zabilježeni rezultat priključenja (81,30%), označeno rezultat priključenja (76,30%), i rezultat priključenja sadržaja (72,57%).', 'so': 'Kanu wuxuu ku qoran yahay baaritaanka ku xirnaanta neural-dependency Parameer oo ay Stanford u soo dhiibtay CoNLL 2017 Shaqada la sharciyey baaritaanka ku xiran dhamaanshaha jaamacadda. nidaamkayagu wuxuu isticmaalaa shabakado fudud oo LSTM ah si uu uga soo bixiyo qeyb ka mid ah warqadaha hadalka iyo baaritaanka ku xiran ee laga soo bandhigayo qayb ka mid ah hadal-ka iyo qeyb-qayb. Si a an ugu sheekeyno dhibaatada hadalka saxda ah oo afafka ku badatay, waxaynu ku qornaa macluumaad ku saabsan qoraal, kaas oo isticmaalaya LSTM si uu uga soo bixiyo qalabka saxda ah. Sida ugu horeysa nidaamka waxaa lagu qoray shan metric oo muhiimsan ee nidaamka: UPOS tagging (93.09%), XPOS tagging (82.27%), kooxda xiriirka la xiriiri karo (81.30%), kooxda xiriirka lagu qoray (76.30%), iyo hadalka waxyaabaha ku jira oo lagu qoray iskuul xiriir (72.57%).', 'sv': 'Denna uppsats beskriver den neurala beroendetolkaren som Stanford skickade in till CoNLL 2017 Shared Task om tolkning av universella beroenden. Vårt system använder relativt enkla LSTM-nätverk för att producera delar av taltaggar och märkta beroendetolkningar från segmenterade och tokeniserade ordsekvenser. För att lösa problemet med sällsynta ord som finns i överflöd av språk med komplex morfologi, inkluderar vi en teckenbaserad ordrepresentation som använder en LSTM för att producera inbäddningar från sekvenser av tecken. Vårt system rankades först enligt alla fem relevanta mätvärden för systemet: UPOS-märkning (93,09%), XPOS-märkning (82,27%), omärkt bilagspoäng (81,30%), märkt bilagspoäng (76,30%) och innehållsordmärkt bilagspoäng (72,57%).', 'si': 'මේ පැත්තේ ස්ටැන්ෆෝර්ඩ් එක්ක පිළිගත්ත නිර්මාණ විශේෂ විශේෂ විශේෂ විශේෂ කරනවා කොන්ලි 2017 වල සමාග අපේ පද්ධතිය සාමාන්\u200dය LSTM ජාලය භාවිතා කරනවා කතා ටැග් කොටසක් නිර්මාණය කරන්න සහ ලේබල් විශේෂතා පරීක්ෂණය සහ ප්\u200dරති සම්පූර්ණ ප්\u200dරශ්නයක් තියෙන භාෂාවල් වලින් ප්\u200dරශ්නයක් ලැබෙන්න, අපි අක්ෂර අධාරිත වචන ප්\u200dරශ්නයක් ඇතුළත් කරනවා ඒක LST අපේ පද්ධතිය පටන් ගත්තා පද්ධතියට සියලුම් මෙට්\u200dරික් පහක් අනුවෙන් පටන් ගත්තා: UPOS ටැග් ගත්තා (93.09%), XPOS ටැග් ගත්තා (82.27%), ඇතුළු ගත්තා (81.30%), ලේබ් ගත්තා ඇතුළු ගත', 'ta': 'இந்த தாள் புதிய சார்ந்த சார்பு பரிசோதனையை குறிப்பிடுகிறது பொது உலகளாவிய சார்புகளை பாசிக்கும் பொருட்டு ஸ்டான்போர எங்கள் அமைப்பு எளிமையான LSTM வலைப்பின்னல்களை பயன்படுத்துகிறது பேச்சு குறிகள் மற்றும் குறிப்பிட்ட சார்பு பார்வைகள் மற்றும் க மொழிகளில் சிக்கலான மொழியில் அதிகமாக இருக்கும் சிறிய வார்த்தை பிரச்சினைகளை முகவரிக்க வேண்டுமானால், நாம் ஒரு எழுத்து அடிப்படையான சொல் அமைப்பிற்கான அனைத்து தொடர்புடைய மெட்ரிக்களுக்கும் முதலில் எங்கள் அமைப்பு ஆரம்பிக்கப்பட்டது: UPOS ஒட்டுதல் (93. 09%), XPOS ஒட்டு (82. 27%), அறியாத இணைப்பு புள்ளி', 'ur': 'This paper describes the neural dependency parser submitted by Stanford to the CoNLL 2017 Shared Task on parsing Universal Dependencies. ہماری سیسٹم نے نسبتا ساده LSTM نیٹورک استعمال کرتا ہے کہ زبان ٹاگ میں سے کچھ حصہ پیدا کرے اور لکیٹ کی ناپاکیزگی پارس کے ساتھ لکیٹے جاتے ہیں۔ اس لئے کہ زبانوں میں پیچیدہ مورفولوژی کے ساتھ بہت زیادہ مشکل کے بارے میں مشکل کریں، ہم ایک شخصت پر بنیاد لکھی لکھی ہوئی لکھی روشنی شامل کریں جو ایک LSTM کا استعمال کرتا ہے تاکہ اس کے ذریعے لکھنے لگیں. ہماری سیستم پہلی بار سیستم کے لئے پانچ معاملہ متریک کے مطابق رینڈ کی گئی تھی: UPOS ٹاگ (93.09%), XPOS ٹاگ (82.27%), ناپذیر اٹیٹمنٹ اسکور (81.30%), لابلیٹ اٹیٹمنٹ اسکور (76.30%), اور منزل لکھی ہوئی اٹیٹمنٹ اسکور (72.57%).', 'uz': "Bu hujjat Universal qoidalarini ajratish uchun Stanford'ning CoNLL 2017'ga bogʻliq vazifani anglatadi. Bizning tizimimiz juda oddiy LSTM tarmoqlaridan foydalanadi, gapiruvchi taglarning bir qismlarini yaratish va qo'llangan soʻzlardan qo'llangan va qo'llangan soʻzlardan qo'llaniladi. Bu tilda murakkab morfologi bilan ko'paytirilgan qisqa so'z muammolarni talab qilish uchun biz bir qattiq so'zni qo'shish uchun LSTM yordamida qo'llanmalarni qo'llashga ishlatish uchun qoʻllab-asosiy so'zni tahrirlash. Birinchi birinchi tizimmiz tizimga barcha bogʻ'liq metriklarga kiritildi: UPOS tagning (93. 09%), XPOS tagning (82. 27%), hech qanday ilova qiymati (81. 30%), ilova qiymati chegarasi (76. 30%), maʼlumot bogʻlamaning qiymati chegarasi (72.57%).", 'vi': 'Tờ giấy này mô tả phân tích phụ thuộc thần kinh được Stanford gửi tới CLB Chia sẻ Coinb thẩm mái về phân tích các mối quan hệ chung. Hệ thống của chúng tôi sử dụng hệ thống LSTM tương đối đơn giản để sản xuất một phần của các thẻ phát âm và được đánh dấu phụ thuộc phân tách từ các chuỗi các từ. Để giải quyết vấn đề ngôn ngữ hiếm có chứa nhiều ngôn ngữ nhiều từ phức tạp, chúng tôi bao gồm một mô tả từ dựa vào tính cách dùng LSTM để tạo sự tác hợp từ các chuỗi các ký tự. Hệ thống của chúng tôi được xếp hạng đầu theo năm thước đo liên quan cho hệ thống: định vị UPOS (3.09 Name), định vị XPOS (82.27=), ghi chú đính kèm (81.30=), ghi nhãn ghi điểm đính kèm (Thank.30=)) và ghi nhãn ghi chú tập tin các từ nội dung đính kèm (72.57=).', 'bg': 'Настоящата статия описва анализатора на нервната зависимост, представен от Станфорд на споделената задача за анализ на универсалните зависимости. Системата ни използва относително прости мрежи, за да произвежда част от речните тагове и етикетирани зависимост анализи от сегментирани и токенезирани последователности от думи. За да се справим с проблема с редките думи, който изобилства от езици със сложна морфология, ние включваме символно-базирано слово представяне, което използва LSTM за създаване на вграждания от последователности от знаци. Системата ни беше класирана на първо място според всичките пет подходящи показателя за системата: маркиране на етикета (93,09%), маркиране на етикета (82,27%), оценка на прикачения файл без етикет (81,30%), оценка на прикачения файл с етикет (76,30%) и оценка на прикачения файл с етикет съдържание (72,57%).', 'da': 'Denne artikel beskriver den neurale afhængighedsfortolker, som Stanford sendte til CoNLL 2017 Shared Task om parsing af universelle afhængigheder. Vores system bruger relativt enkle LSTM-netværk til at producere en del af taletags og mærkede afhængighedsparser fra segmenterede og tokeniserede sekvenser af ord. For at løse problemet med sjældne ord, der overflod af sprog med kompleks morfologi, inkluderer vi en tegnbaseret ordrepræsentation, der bruger en LSTM til at producere indlejringer fra sekvenser af tegn. Vores system blev rangeret første i henhold til alle fem relevante målinger for systemet: UPOS-mærkning (93,09%), XPOS-mærkning (82,27%), ikke-mærket vedhæftet fil score (81,30%), mærket vedhæftet fil score (76,30%) og indholdsordmærket vedhæftet fil score (72,57%).', 'hr': 'Ovaj papir opisuje analizator neuralne zavisnosti koji je Stanford predao podijeljenom zadatku CoNLL 2017 o analizanju univerzalnih zavisnosti. Naš sustav koristi relativno jednostavne LSTM mreže kako bi proizveli dio znakova govora i označene analize zavisnosti iz segmentiranih i tokeniranih sekvencija riječi. Da bi se riješili rijetki problem riječi koji se povećava na jezicima sa složenom morfologijom, uključujemo predstavljanje riječi na karakteru koja koristi LSTM kako bi proizvela integracije iz sekvencija znakova. Naš sustav je prvi bio rankiran prema svim pet relevantnih metrika za sustav: označavanje UPOS-a (93,09%), označavanje XPOS-a (82,27%), zabilježeni rezultat priključenja (81,30%), označeno rezultat priključenja (76,30%), i rezultat priključenja sadržaja označavane riječima označavanim priključenjem (72,57%).', 'nl': 'Dit artikel beschrijft de neurale afhankelijkheidsparser die door Stanford is ingediend bij de CoNLL 2017 Shared Task over het parsen van universele afhankelijkheden. Ons systeem maakt gebruik van relatief eenvoudige LSTM-netwerken om een deel van spraaktags en gelabelde afhankelijkheidsparsen te produceren van gesegmenteerde en tokeniseerde woordreeksen. Om het zeldzame woordprobleem aan te pakken dat overvloedig is aan talen met complexe morfologie, hebben we een karaktergebaseerde woordrepresentatie opgenomen die gebruik maakt van een LSTM om insluitingen te produceren van reeksen tekens. Ons systeem werd op de eerste plaats gerangschikt op basis van alle vijf relevante statistieken voor het systeem: UPOS tagging (93.09%) XPOS tagging (82.27%) onbetekende attachment score (81.30%) gelabelde attachment score (76.30%) en content word gelabeld attachment score (72.57%).', 'de': 'Diese Arbeit beschreibt den neuronalen Abhängigkeitsparser, der Stanford an die CoNLL 2017 Shared Task zum Parsen universeller Abhängigkeiten übermittelt hat. Unser System verwendet relativ einfache LSTM-Netzwerke, um einen Teil von Sprachtags und beschriftete Abhängigkeitsparsen aus segmentierten und tokenisierten Wortsequenzen zu erzeugen. Um das seltene Wortproblem anzugehen, das in Sprachen mit komplexer Morphologie reichlich vorkommt, schließen wir eine zeichenbasierte Wortdarstellung ein, die ein LSTM verwendet, um Einbettungen aus Zeichenfolgen zu erzeugen. Unser System wurde nach allen fünf relevanten Kennzahlen für das System als Erster eingestuft: UPOS-Tagging (93.09%) XPOS-Tagging (82.27%) nicht beschrifteter Anhang-Score (81.30%) beschrifteter Anhang-Score (76.30%) und Inhaltswort-beschrifteter Anhang-Score (72.57%).', 'ko': '본고는 스탠퍼드대가 CoNLL 2017 유니버설 의존 해석 공유 임무에 제출한 신경 의존 해석기를 묘사한다.우리 시스템은 비교적 간단한 LSTM 네트워크를 사용하여 단락과 표기화된 단어 서열에서 단어성 표기와 표기 의존항 해석을 생성합니다.복잡한 문법 언어에 보편적으로 존재하는 보기 드문 단어 문제를 해결하기 위해 우리는 문자를 기반으로 하는 단어 표현법을 도입했다. LSTM을 사용하여 문자 서열에서 삽입을 생성한다.시스템의 다섯 가지 관련 지표에 따르면 UPOS 태그(93.09%), XPOS 태그(82.27%), 첨부 파일 미태그(81.30%), 첨부 파일 태그(76.30%), 컨텐트 단어 태그 첨부 파일 점수(72.57%)가 1위를 차지했다.', 'id': 'Kertas ini menjelaskan parser ketergantuan saraf yang dikirim oleh Stanford ke CoNLL 2017 Shared Task on parsing Universal Dependencies. Our system uses relatively simple LSTM networks to produce part of speech tags and labeled dependency parses from segmented and tokenized sequences of words.  Untuk mengatasi masalah kata langka yang berjumlah dalam bahasa dengan morfologi kompleks, kita termasuk represisi kata berdasarkan karakter yang menggunakan LSTM untuk menghasilkan embedding dari urutan karakter. Sistem kami ditandai pertama menurut lima metrik yang relevan untuk sistem: penandaan UPOS (93,09%), penandaan XPOS (82,27%), skor lampiran tidak ditandai (81,30%), skor lampiran ditandai (76,30%), dan skor lampiran ditandai kata isi (72,57%).', 'tr': 'Bu kagyz Stanford tarapyndan CoNLL 2017-nji ýyllary tarapyndan jemgylanan nural baglançylyk täze hasaplaýar. Biziň sistemimiz çykyş taglaryň bir parçasyny bejermek üçin relativ basit LSTM aňlaryny ulanýar we bu etitlendirilen baglanylyk parselerini segment we tokenilýan sözlerin hatlaryndan ullanmak üçin ullanýar. Gaty morfologiýa bilen ululan söz meselesini çözmek üçin karakterlere tabanly söz temizlemek üçin bir karakterlere golaýlaýarys. Biziň sistemimiz sistemiň beş möhüm metriklerine görä ilkinji gezek bellenildi: UPOS etiketlemesi (93.09%), XPOS etiketlemesi', 'fa': 'این کاغذ توضیح داده شده است که توسط استنفورد به کار مشترک CoNLL 2017 در مورد تحلیل بستگی جهانی ارائه داده شده است. سیستم ما از شبکه\u200cهای LSTM نسبتا ساده استفاده می\u200cکند تا بخشی از نقاشی سخنرانی را تولید کند و پاره\u200cهای بستگی نامیده شده از نقاشی\u200cهای کلمات جدایی و توکید کند. برای حل کردن مشکل کلمات نادر که در زبانها با مورفولوژی پیچیده می شود، ما شامل یک نمایش کلمات بر اساس شخصیت استفاده می کنیم که از LSTM برای تولید داخلی از دسته\u200cهای شخصیت استفاده می\u200cکند. سیستم ما اول بر اساس تمام پنج متریک مربوط به سیستم درجه گرفته شد: نقاشی UPOS (93.09%), نقاشی XPOS (82.27%), نقاشی نقاشی (81.30%), نقاشی نقاشی نقاشی نقاشی نقاشی نقاشی (76.30%) و نقاشی محتوای کلمه نقاشی نقاشی نقاشی (72.57%).', 'sw': 'Gazeti hili linaelezea mchambuzi wa kituo cha kutegemea uraia uliotolewa na Stanford kwa CoNLL 2017 Kushirikishwa na kazi ya kuuchapisha Mategemeo ya Chuo Kikuu. Mfumo wetu unatumia mitandao rahisi ya LSTM ili kutengeneza sehemu ya alama za hotuba na viungo vinavyotegemea kutoka kwa mfululizo wa maneno yanayotengenezwa na kutangazwa. Ili kuzungumzia tatizo la neno nadra ambalo linaongezeka kwa lugha yenye utata wa kifolojia, tunajumuisha uwakilishi wa maneno yenye msingi wa kibiashara unaotumia LSTM kutengeneza vifaa kutoka kwa mfululizo wa wahusika. Mfumo wetu ulipangwa kwanza kwa mujibu wa mbinu zote tano muhimu kwa mfumo: wimbo wa UPOS (93.09%), wimbo wa XPOS (82.27%), score ya ujasiri usiofanywa (81.30%), score ya kiungo (76.30%), na neno la maudhui lililoitwa ujumbe (72.57%).', 'sq': 'Ky dokument përshkruan analizuesin e varësisë nervore të dërguar nga Stanford në Detyrën e Përbashkët të CoNLL 2017 për analizimin e varësive universale. Sistemi ynë përdor rrjete relativisht të thjeshta LSTM për të prodhuar pjesë të etiketave të fjalimit dhe analizave të etiketuara të varësisë nga sekuencat e segmentuara dhe të tokenizuara të fjalëve. Për të trajtuar problem in e fjalëve të rralla që mbushet në gjuhë me morfologji komplekse, ne përfshijmë një përfaqësim fjalësh të bazuar në karakter që përdor një LSTM për të prodhuar përfshirje nga sekuenca karakterësh. Sistemi ynë u rendit i pari sipas pesë metrikave të rëndësishme për sistemin: etiketat UPOS (93.09%), etiketat XPOS (82.27%), piketat e lidhjes pa etiketë (81.30%), piketat e lidhjes me etiketë (76.30%) dhe piketat e lidhjes me përmbajtje (72.57%).', 'am': 'ይህም ፕሮግራም የኔural ደጋፊነት ተሟጋቾችን ለኮንጆንLL 2017 በዓለማዊ ግንኙነት ማጋራት ላይ የተሰራጨውን ስራ ይናገራል፡፡ የድምፅ አካባቢነታችን የንግግር ምልክቶች እና የተደገመ የፋርስ ክፍል እና በተለየ እና በተለየ ቃላት ግንኙነት እና ግንኙነትን ለመፍጠር ቀላል የLSTM መረብ ይጠቅማል፡፡ ቋንቋዎች በተጨማሪው ሞፎሎጂ ቋንቋ የሚበዛውን ትንሽ ቃላት መከራ ለመቀበል እናስፈልጋለን፡፡ የውይይት መድረክ (93.09%), የXPOS ምልክት (82.27%), የአጠቃሚ ጥያቄ score (81.30%), የአጠቃሚ ጥያቄ score (76.30%) እና የግንኙነት ቃላት የአጠቃሚ ክፍል (72.57%).', 'af': 'Hierdie papier beskrywe die neurale afhanklikheidspanseerder wat deur Stanford aan die CoNLL 2017 deelde taak voorgestuur het om universele afhanklikhede te verwerk. Ons stelsel gebruik relativies eenvoudige LSTM netwerke om deel van spraak etikette te produseer en gemerkte afhanklikheidverwerkinge van segmenteerde en tokeniseerde volgorde van woorde. In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters. Ons stelsel was eerste rangeer volgens alle vyf relevante metrike vir die stelsel: UPOS etiketting (93.09%), XPOS etiketting (82.27%), ongeabelde aanhegstelling (81.30%), etiketeerde aanhegstelling (76.30%), en inhoud woord etiketeerde aanhegstelling (72.57%).', 'az': "Bu kağıt Stanford 2017'nin CoNLL 2017'nin Universal bağlılıqları ayırılması barəsində təyin edilmiş nöral bağlılıq ayırıcısını tanımar. Sistemimiz söz etiketlərinin bir parçasını yaratmaq üçün çox basit LSTM ağlarını və etiketli bağlılıq analarını segmentləndirilmiş və tokenizlənmiş sözlərin seçməsi üçün istifadə edir. Müxtəlif morfoloji ilə dillərdə böyük nadir söz problemlərini çəkmək üçün, karakter-tabanlı sözləri LSTM istifadə etmək üçün cümlətlərin səviyyələrindən içərik. Sistemimiz sistemin bütün beş mövcud metriklərinə görə ilk dərəcə verildi: UPOS etiketi (93.09%), XPOS etiketi (82.27%), etiketsiz bağlama nöqtəsi (81.30%), etiketli bağlama nöqtəsi (76.30%), məlumat nöqtəsi (72.57%).", 'bn': 'এই পত্রিকাটি বিশ্ববিদ্যালয়ের নির্ভর্তা পার্সিং নিয়ে স্ট্যানফোর্ড দ্বারা স্ট্যানফোর্ড প্রদান করেছে কনএল ২০১৭ সা Our system uses relatively simple LSTM networks to produce part of speech tags and labeled dependency parses from segmented and tokenized sequences of words.  কমপ্ল্যাক্স মোরোফোলজি সহ ভাষায় বৃদ্ধি প্রকাশ করার জন্যে আমরা একটি অক্ষর-ভিত্তিক শব্দের প্রতিনিধিত্ব করি যা এক এলসিএম ব্যবহার করে অক্ষরের স আমাদের সিস্টেমের প্রথমে পাঁচটি প্রাসঙ্গিক মেট্রিক অনুসারে: UPOS ট্যাগিং (93. 09%), XPOS ট্যাগিং (82. 27%), অলাইন সংযুক্ত স্কোর (81. 30%), লেবেলেট সংযুক্ত স্কোর (76. 30%), এবং বিষয়বস্তুর লেবেলে', 'bs': 'Ovaj papir opisuje analizator neuralne zavisnosti koji je Stanford predao podijeljenom zadatku CoNLL 2017 o analizanju univerzalnih zavisnosti. Naš sistem koristi relativno jednostavne LSTM mreže kako bi proizveli dio znakova govora i označene analize zavisnosti iz segmentiranih i tokeniranih sekvencija riječi. Da bi se riješili rijetki problem riječi koji se povećava na jezicima sa kompleksnom morfologijom, uključujemo predstavljanje riječi na karakteru koja koristi LSTM kako bi proizvela integracije iz sekvencija znakova. Naš sistem je prvi bio rankiran prema svim pet relevantnih metrika za sistem: označavanje UPOS-a (93,09%), označavanje XPOS-a (82,27%), zabilježeni rezultat priključenja (81,30%), označeno rezultat priključenja (76,30%), i rezultat priključenja sadržaja (72,57%).', 'cs': 'Tento článek popisuje neuronový závislostní parser předložený Stanfordem ke sdílenému úkolu CoNLL 2017 o parsování univerzálních závislostí. Náš systém používá relativně jednoduché LSTM sítě k produkci části řečových tagů a označených analýz závislostí ze segmentovaných a tokenizovaných sekvencí slov. Abychom řešili vzácný problém slov, který je hojný v jazycích se složitou morfologií, zahrnujeme znakovou reprezentaci slov, která využívá LSTM k vytváření vložení z sekvencí znaků. Náš systém byl zařazen na první místo podle všech pěti relevantních metrik systému: UPOS tagování (93.09%) XPOS tagování (82.27%) neznačené skóre přílohy (81.30%) označené skóre přílohy (76.30%) a obsahové slovo označené přílohou skóre (72.57%).', 'et': 'Käesolevas artiklis kirjeldatakse Stanfordi poolt esitatud närvisõltuvuse parserit CoNLL 2017. aasta jagatud ülesandele universaalsete sõltuvuste parsimiseks. Meie süsteem kasutab suhteliselt lihtsaid LSTM-võrke, et toota osa kõnesildidest ja märgistatud sõltuvuse parse segmenteeritud ja tokeniseeritud sõnade jadadest. Selleks et lahendada haruldaste sõnaprobleemide probleemi, mis on palju keerulise morfoloogiaga keeltes, lisame märgipõhise sõnapõhise esituse, mis kasutab LSTM-i sümbolite järjestustest manustamiseks. Meie süsteem oli kõigi viie asjakohase süsteemi mõõdiku järgi esimene: UPOS sildistamine (93,09%), XPOS sildistamine (82,27%), märgistamata manuste skoor (81,30%), märgistatud manuste skoor (76,30%) ja sisusõna sildistatud manuste skoor (72,57%).', 'hy': 'Այս հոդվածը նկարագրում է Ստենֆորդի կողմից ներկայացված նյարդային կախվածության վերլուծումը 2017-ի ԿոնԼԼ համագործակցական կախվածությունների վերլուծության ընթացքում: Մեր համակարգը օգտագործում է համեմատաբար պարզ LSMT ցանցեր, որպեսզի ստեղծի խոսքի նշանների մի մասը և նշանված կախվածության վերլուծումները բառերի սեգմետրացված և նշանված հաջորդականություններից: Որպեսզի լուծենք հազվադեպ բառերի խնդիրը, որը բազմազան է բարդ մորֆոլոգիաներով լեզուներում, մենք ներառում ենք բառերի ներկայացումը, որը օգտագործում է LSMT-ը, որպեսզի ստեղծի ներառումներ բառերի հաջորդականություններից: Մեր համակարգը առաջինը դասակարգում էր համակարգի բոլոր հինգ նշանակալի չափումների համաձայն. UPO նշաններ (93.9), XPOS նշաններ (82.27), աննշաններ կապված գնահատականներ (81.30), նշաններ կապված գնահատականներ (76.30), և պարունակության բառեր՝ նշաններ կապված գնահատականներ (72.57 տոկո', 'ca': "Aquest article descriu l'analitzador de dependencies neuronals submetit per Stanford a la CoNLL 2017 Shared Task on analyzing Universal Dependencies. El nostre sistema utilitza xarxes LSTM relativament senzilles per produir part de les etiquetes de parla i els paràtics de dependencia etiquetats a partir de seqüències de paraules segmentades i tokenitzades. Per abordar el problem a de paraules rares que s'abonda en llengües amb morfologia complexa, inclouem una representació de paraules basada en caràcters que utilitza un LSTM per produir incorporacions a partir de seqüències de caràcters. El nostre sistema va ser classificat en primer lloc segons les cinc mètriques pertinents del sistema: etiqueta UPOS (93,09%), etiqueta XPOS (82,27%), puntuació no etiquetada d'attachment (81,30%), puntuació etiquetada d'attachment (76,30%) i puntuació de contenut de paraula etiquetada d'attachment (72,57%).", 'fi': 'Tässä artikkelissa kuvataan Stanfordin toimittama neuroriippuvuuden parseri CoNLL 2017 Shared Task on parsing Universal Dependences -ohjelmaan. Järjestelmämme käyttää suhteellisen yksinkertaisia LSTM-verkkoja tuottamaan osan puhetageista ja merkittyjä riippuvuuksien jäsennyksiä segmentoiduista ja tokenisoiduista sanasarjoista. Jotta voimme ratkaista harvinaisen sanaongelman, joka on runsaasti monimutkaisia kieliä, tarjoamme merkkipohjaisen sanaesityksen, joka käyttää LSTM:ää tuottamaan upotuksia merkkisekvensseistä. Järjestelmämme sijoittui ensimmäisenä kaikkien viiden järjestelmän kannalta merkityksellisen mittarin mukaan: UPOS-merkinnät (93,09%), XPOS-merkinnät (82,27%), merkitsemättömät liitteet (81,30%), merkinnät liitteet (76,30%) ja sisältösanamerkinnät liitteet (72,57%).', 'jv': 'Perintah iki rambarang kelas urip nggambar urip nggawe Tiftun, nggawe STANLL karo CoNLL 1997 Daftar Ngawe Perintah Ngubah Universe Sistem awak dhéwé sistem sing wis nggambar luwih operasi layar-layar politenessoffpolite"), and when there is a change ("assertivepolite"), when there is a change ("assertive Sistem dhéwé wis rakonton tualke siwehi saben penting metik kanggo sistem: USB merket-saben', 'ha': "Wannan karatun na describe the neural dependance parser that was sent by Stanford to the CoNLL 2017 Shared job on paring Universal Deputs. @ info: whatsthis In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters.  An ranar da tsarin mu farko da aka rubutu kowace mafiya masu amfani da matrico shan masu amfani da wa'uran na tsari: tagogi na UPS (93.09%), tagogi na XPS (82.27%), score na fanel ba'a rubutu (81.30%), score na fanon fanel na rubutu (76.30%), da kuma sune na tsari wanda aka yi rubutu da fanel na rubutu (42.57%).", 'sk': 'Ta prispevek opisuje razčlenjevalnik nevronske odvisnosti, ki ga je Stanford predložil CoNLL 2017 Shared Task o razčlenjevanju univerzalnih odvisnosti. Naš sistem uporablja relativno preprosta LSTM omrežja za izdelavo dela govornih oznak in označene razčlenitve odvisnosti iz segmentiranih in žetoniziranih zaporedij besed. Za reševanje težav z redkimi besedami, ki se pojavljajo v jezikih s kompleksno morfologijo, vključujemo besedno reprezentacijo na podlagi znakov, ki uporablja LSTM za izdelavo vdelav iz zaporedij znakov. Naš sistem je bil uvrščen na prvo mesto po vseh petih ustreznih meritvah za sistem: označevanje UPOS (93,09%), označevanje XPOS (82,27%), ocena neoznačenih prilog (81,30%), ocena označenih prilog (76,30%) in ocena vsebine besede označene priloge (72,57%).', 'bo': 'ཤོག་བྱང་འདིས་Stanford་གིས་CoNLL ལ་སྤྱོད་པའི་དྲ་རྒྱ་རྐྱེན་རྟེན་འབྲེལ་བ་དེ་འགྲེལ་བཤད་ཀྱི་ཡོད། Our system uses relatively simple LSTM networks to produce part of speech tags and labeled dependency parses from segmented and tokenized sequences of words. In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters. Our system was ranked first according to all five relevant metrics for the system: UPOS tagging (93.09%), XPOS tagging (82.27%), unlabeled attachment score (81.30%), labeled attachment score (76.30%), and content word labeled attachment score (72.57%).', 'he': 'העיתון הזה מתאר את מעבד התלויות העצביות שנשלח על ידי סטנפורד למשימה משותפת CoNLL 2017 על מעבדת תלויות Universal. המערכת שלנו משתמשת ברשתות LSTM פשוטות יחסית כדי לייצר חלק מהתוויות הנאום ומעבדות התלויות המתווידות מהרצפים של מילים מסגמנים ומתווידים. על מנת להתמודד עם בעיית המילים הנדרדרות שמגבוהה בשפות עם מורפולוגיה מורכבת, אנחנו מכילים מייצג מילים מבוסס על אופים שמשתמש LSTM כדי לייצר תוספות מהרצפים של אופים. Our system was ranked first according to all five relevant metrics for the system: UPOS tagging (93.09%), XPOS tagging (82.27%), unlabeled attachment score (81.30%), labeled attachment score (76.30%), and content word labeled attachment score (72.57%).'}
{'en': 'Combining Global Models for Parsing Universal Dependencies', 'ar': 'الجمع بين النماذج العالمية لتحليل التبعيات العالمية', 'pt': 'Combinando modelos globais para analisar dependências universais', 'fr': 'Combiner des modèles globaux pour analyser les dépendances universelles', 'ja': 'ユニバーサル依存関係を解析するためのグローバルモデルの組み合わせ', 'es': 'Combinación de modelos globales para analizar dependencias universales', 'zh': '合局模形以解析通用倚仗', 'hi': 'पार्सिंग यूनिवर्सल निर्भरताओं के लिए वैश्विक मॉडल का संयोजन', 'ru': 'Объединение глобальных моделей для анализа универсальных зависимостей', 'ga': 'Múnlaí Domhanda a Chomhcheangail chun Spleáchais Uilíocha a Pharsáil', 'ka': 'გლობალური მოდელების გადაწყვეტილებისთვის გამოყენება', 'el': 'Συνδυασμός παγκόσμιων μοντέλων για την ανάλυση καθολικών εξαρτήσεων', 'hu': 'Globális modellek kombinálása az univerzális függőségek értelmezésére', 'it': "Combinazione di modelli globali per l'analisi delle dipendenze universali", 'kk': 'Жалпы тәуелдіктерді талдау үшін жалпы үлгілерді біріктіру', 'mk': 'Комбинирање глобални модели за анализирање на универзалните зависности', 'lt': 'Visuotinių priklausomybių analizavimo pasaulinių modelių derinimas', 'ms': 'Combining Global Models for Parsing Universal Dependencies', 'mt': 'Il-Kombinazzjoni ta’ Mudelli Globali għall-Analiżi tad-Dipendenzi Universali', 'ml': 'പാര്\u200dസ് ചെയ്യുന്നതിനായി ഗ്ലോബല്\u200d മോഡലുകള്\u200d കൊണ്ടുവരുന്നു', 'mn': 'Дэлхийн хамааралтай байдлыг талдахын тулд дэлхийн загваруудыг нэгтгэх', 'no': 'Kombinerer globale modeller for tolking av universelle avhengighet', 'ro': 'Combinarea modelelor globale pentru analizarea dependențelor universale', 'pl': 'Łączenie globalnych modeli analizy uniwersalnych zależności', 'sr': 'Kombinacija globalnih modela za razmatranje univerzalnih zavisnosti', 'si': 'ජාතික විශේෂ විශේෂ විශේෂය සඳහා ජාතික විශේෂ මොඩල් එකතු කරනවා', 'sv': 'Kombinera globala modeller för tolkning av universella beroenden', 'ta': 'அனைத்து சார்ந்த பொருள் சார்புகளுக்கான பொது மாதிரிகளை சேர்க்கிறது', 'so': 'Combination Models Global for Parsing Dependences Universal', 'ur': 'Universal Dependencies Parsing for Global Models Combining', 'uz': 'Umumiy qoĘ»llanmalar', 'vi': 'Kết hợp phật chế toàn cầu cho Chế độ phân tích chung', 'hr': 'Kombinacija globalnih modela za razmatranje univerzalnih ovisnosti', 'bg': 'Комбиниране на глобални модели за анализ на универсални зависимости', 'id': 'Kombinasi Model Global untuk Menghurai Dependensi Universal', 'de': 'Kombination globaler Modelle zur Analyse universeller Abhängigkeiten', 'ko': '전역 모델과 결합하여 유니버설 의존항 분석', 'sw': 'Kuunganisha Modeli za Dunia kwa ajili ya Kuchapisha Kutegemea Ulimwengu', 'nl': 'Globale modellen combineren voor het analyseren van universele afhankelijkheden', 'da': 'Kombination af globale modeller til fortolkning af universelle afhængigheder', 'sq': 'Përbashkimi i modeleve globale për analizimin e varësive universale', 'af': 'Kombineer Globale Modelle vir verwerking van Universele Afhanklikhede', 'hy': 'Combining Global Models for Parsing Universal Dependencies', 'am': 'Combining Global Models for Parsing Universal Dependencies', 'fa': 'ترکیب مدل جهانی برای تحلیل بستگی جهانی', 'az': 'Universel bağlılıqları oxumaq üçün Global Modelləri birləşdirilən', 'bn': 'পার্সিং করার জন্য গ্লোবাল মোডেল কমাইন করা হচ্ছে', 'bs': 'Kombinacija globalnih modela za razmatranje univerzalnih zavisnosti', 'ca': 'Combinant Models Global for Parsing Universal Dependencies', 'cs': 'Kombinace globálních modelů pro analýzu univerzálních závislostí', 'fi': 'Globaalien mallien yhdistäminen yleismaailmallisten riippuvuuksien analysoimiseksi', 'tr': 'Halkara ynamlyklary analyz etmek üçin Umumy nusgala', 'et': 'Ülemaailmsete mudelite kombineerimine universaalsete sõltuvuste analüüsimiseks', 'he': 'Name', 'sk': 'Združevanje globalnih modelov za razčlenitev univerzalnih odvisnosti', 'jv': 'Jejaring', 'ha': 'KCharselect unicode block name', 'bo': 'སྤྱི་ཚོགས་ཀྱི་རྟེན་འབྲེལ་མཐུན་ལ་བཤད་ཀྱི་སྤྱི་ཚོགས་ཀྱི་མ་དབྱིབས་མཐུན་བཟོ་བྱེད་བཞིན་པ'}
{'en': 'We describe our entry, C2L2, to the CoNLL 2017 shared task on parsing Universal Dependencies from raw text. Our system features an ensemble of three global parsing paradigms, one graph-based and two transition-based. Each model leverages character-level bi-directional LSTMs as lexical feature extractors to encode morphological information. Though relying on baseline tokenizers and focusing only on parsing, our system ranked second in the official end-to-end evaluation with a macro-average of 75.00 LAS F1 score over 81 test treebanks. In addition, we had the top average performance on the four surprise languages and on the small treebank subset.', 'ar': 'وصفنا إدخالنا ، C2L2 ، إلى المهمة المشتركة CoNLL 2017 حول تحليل التبعيات العالمية من النص الخام. يتميز نظامنا بمجموعة من ثلاثة نماذج تحليل عالمية ، واحدة تعتمد على الرسم البياني واثنتان على أساس الانتقال. يستفيد كل نموذج من LSTMs ثنائية الاتجاه على مستوى الحرف كمستخلصات معجمية لتشفير المعلومات المورفولوجية. على الرغم من الاعتماد على الرموز المميزة الأساسية والتركيز فقط على التحليل ، احتل نظامنا المرتبة الثانية في التقييم الرسمي الشامل بمتوسط ماكرو قدره 75.00 LAS F1 على 81 بنكًا شجريًا للاختبار. بالإضافة إلى ذلك ، كان لدينا أعلى متوسط أداء في اللغات الأربع المفاجئة وعلى المجموعة الفرعية لضفة الأشجار الصغيرة.', 'es': 'Describimos nuestra entrada, C2L2, a la tarea compartida de CoNll 2017 sobre el análisis de dependencias universales a partir de texto sin formato. Nuestro sistema presenta un conjunto de tres paradigmas de análisis global, uno basado en gráficos y dos basados en transiciones. Cada modelo aprovecha los LSTM bidireccionales a nivel de caracteres como extractores de características léxicas para codificar información morfológica. Aunque se basaba en tokenizadores de referencia y se centraba solo en el análisis, nuestro sistema ocupó el segundo lugar en la evaluación oficial de extremo a extremo con un macropromedio de 75.00 las F1 en 81 bancos de árboles de prueba. Además, obtuvimos el rendimiento promedio más alto en los cuatro idiomas sorpresa y en el subconjunto de bancos de árboles pequeños.', 'fr': "Nous décrivons notre entrée, C2L2, pour la tâche partagée ConLL 2017 sur l'analyse des dépendances universelles à partir du texte brut. Notre système comprend un ensemble de trois paradigmes d'analyse globale, un basé sur des graphes et deux basés sur des transitions. Chaque modèle utilise des LSTM bidirectionnels au niveau des caractères comme extracteurs de caractéristiques lexicales pour coder les informations morphologiques. Bien qu'il s'appuie sur des tokeniseurs de base et qu'il se concentre uniquement sur l'analyse syntaxique, notre système s'est classé deuxième dans l'évaluation officielle de bout en bout avec une macro-moyenne de 75,00 points LAS F1 sur 81 banques d'arbres de test. De plus, nous avons obtenu les meilleures performances moyennes pour les quatre langues surprises et pour le petit sous-ensemble de banques d'arbres.", 'pt': 'Descrevemos nossa entrada, C2L2, para a tarefa compartilhada CoNLL 2017 na análise de dependências universais de texto bruto. Nosso sistema apresenta um conjunto de três paradigmas de análise global, um baseado em gráfico e dois baseados em transição. Cada modelo aproveita LSTMs bidirecionais em nível de caractere como extratores de recursos lexicais para codificar informações morfológicas. Embora dependa de tokenizers de linha de base e se concentre apenas na análise, nosso sistema ficou em segundo lugar na avaliação oficial de ponta a ponta com uma média macro de 75,00 pontuação LAS F1 em 81 bancos de árvores de teste. Além disso, tivemos o desempenho médio superior nas quatro linguagens surpresa e no subconjunto de banco de árvore pequeno.', 'ja': 'RAWテキストからのユニバーサル依存関係の解析に関するCoNLL 2017共有タスクへのエントリC 2 L 2について説明します。当社のシステムは、1つのグラフベースと2つのトランジションベースの3つのグローバル構文解析パラダイムのアンサンブルを備えています。各モデルは、文字レベルの双方向LSTMを語彙特徴抽出器として活用し、形態情報を符号化する。ベースライントークンナイザーに依存し、構文解析のみに焦点を当てていますが、当社のシステムは、81のテストツリーバンクにわたる75.00 LAS F 1スコアのマクロ平均で、公式のエンドツーエンド評価で2位でした。さらに、4つのサプライズ言語と小さなツリーバンクのサブセットでトップの平均パフォーマンスがありました。', 'zh': '述我条 C2L2,施于 CoNLL 2017 本解析通用赖项之共同任务。 吾统有三全局解析范式之集,一基于图形,二基于转换。 每模皆用字符双向 LSTM 为词法特征提取器以编码形息。 虽赖基线分词器而专注于解析,然系统于官方端到端评估第二,于81试树库中得75.00 LAS F1之宏观平均值。 此外四者,言语小树库子集上之均最高也。', 'hi': 'हम अपनी प्रविष्टि, C2L2, CoNLL 2017 साझा कार्य के लिए कच्चे पाठ से यूनिवर्सल निर्भरताओं को पार्स करने पर वर्णन करते हैं। हमारे सिस्टम में तीन वैश्विक पार्सिंग प्रतिमानों, एक ग्राफ-आधारित और दो संक्रमण-आधारित का एक पहनावा है। प्रत्येक मॉडल रूपात्मक जानकारी को एन्कोड करने के लिए लेक्सिकल फीचर एक्सट्रैक्टर्स के रूप में चरित्र-स्तर द्वि-दिशात्मक एलएसटीएम का लाभ उठाता है। हालांकि बेसलाइन टोकनाइज़र पर भरोसा करते हुए और केवल पार्सिंग पर ध्यान केंद्रित करते हुए, हमारी प्रणाली 81 परीक्षण ट्रीबैंक पर 75.00 एलएएस एफ 1 स्कोर के मैक्रो-औसत के साथ आधिकारिक एंड-टू-एंड मूल्यांकन में दूसरे स्थान पर रही। इसके अलावा, हमारे पास चार आश्चर्य भाषाओं और छोटे ट्रीबैंक सबसेट पर शीर्ष औसत प्रदर्शन था।', 'ru': 'Мы описываем наш вход, C2L2, в совместную задачу CoNLL 2017 по синтаксическому анализу универсальных зависимостей из необработанного текста. Наша система включает в себя три глобальные парадигмы синтаксического анализа: одну на основе графа и две на основе перехода. Каждая модель использует двунаправленные LSTM на уровне символов в качестве экстракторов лексических признаков для кодирования морфологической информации. Хотя наша система опирается на базовые токенизаторы и фокусируется только на синтаксическом анализе, она занимает второе место в официальной сквозной оценке с макросредним баллом 75,00 LAS F1 по 81 тестовому древу. Кроме того, мы имели лучшие средние показатели по четырем языкам сюрпризов и по подмножеству малых берегов деревьев.', 'ga': 'Déanaimid cur síos ar ár n-iontráil, C2L2, ar thasc roinnte CoNLL 2017 maidir le Spleáchas Uilíoch a pharsáil ó bhunthéacs. Tá ensemble de thrí paraidím parsála domhanda ar ár gcóras, ceann amháin bunaithe ar ghraif agus dhá cheann trasdula. Déanann gach samhail giaráil LSTM déthreoracha ar leibhéal carachtar mar fháiscirí gné foclóireachta chun faisnéis mhoirfeolaíoch a ionchódú. Cé go raibh sé ag brath ar chomharthaí bonnlíne agus ag díriú ar pharsáil amháin, tháinig ár gcóras sa dara háit sa mheastóireacht oifigiúil ceann go ceann le macra-mheán scór 75.00 LAS F1 thar 81 banc crann tástála. Ina theannta sin, bhí an meánfheidhmíocht is airde againn ar na ceithre theanga iontasacha agus ar an bhfothacar crann crann beag.', 'ka': 'ჩვენ ჩვენი შეწყვეტის C2L2-ს, CoNLL 2017-ის გაყოფილი დავაწერა სამყარო ტექსტიდან სამყარო დასაწერებაზე. ჩვენი სისტემა იქნება სამი გლობალური პარადიგმების ინსენემბელი, ერთი გრაფიკური და ორი გადატანაციის დაბათი. ყოველ მოდელმა მხარდაჭერების ორედირექციონალური LSTMs როგორც ლექსიკალური ფუნქციის ექსტრექტორიები მოპოროლოგიური ინფორმაციის კოდირებისთვის მაგრამ ჩვენი სისტემა გადასრულებული დასრულებაში დააყენებულია და მხოლოდ გასრულებაზე დააყენებულია, ჩვენი სისტემა დასრულებული დასრულებაში მეორე დასრულებაში მაკრო-საშუალოდ 75,00 LAS F1 წერტილი 81 ტე დამატებით, ჩვენ გვაქვს საშუალო საშუალო გამოვიყენება ოთხი საინტერესო ენაზე და პატარა საბოლო საბოლო საბოლოში.', 'el': 'Περιγράφουμε την καταχώρησή μας, C2L2, στην κοινή εργασία για την ανάλυση καθολικών εξαρτήσεων από ακατέργαστο κείμενο. Το σύστημά μας διαθέτει ένα σύνολο τριών παγκόσμιων παραδειγμάτων ανάλυσης, ένα με βάση γραφήματα και δύο με βάση μετάβαση. Κάθε μοντέλο χρησιμοποιεί δικατευθύνσεις σε επίπεδο χαρακτήρων ως εξαγωγείς λεξικών χαρακτηριστικών για την κωδικοποίηση μορφολογικών πληροφοριών. Αν και βασιζόμενοι σε δείκτες βάσης και εστιάζοντας μόνο στην ανάλυση, το σύστημά μας κατατάχθηκε δεύτερη στην επίσημη τελική αξιολόγηση με μακρομέσο όρο 75.00 βαθμολογίας σε σχέση με 81 δοκούς δέντρων. Επιπλέον, είχαμε την κορυφαία μέση απόδοση στις τέσσερις γλώσσες έκπληξης και στο μικρό υποσύνολο δέντρων.', 'hu': 'Az Univerzális függőségek nyers szövegből történő elemzéséről szóló CoNLL 2017 megosztott feladat C2L2 bejegyzését írjuk le. Rendszerünk három globális elemzési paradigmából áll, egy gráf alapú és két átmeneti alapú. Minden modell karakterszintű kétirányú LSTMeket használ lexikális jellemző extraktorként a morfológiai információk kódolására. Bár a kiindulási tokenizátorokra támaszkodva, és csak az elemzésre összpontosítva, rendszerünk a második helyen állt a hivatalos end-to-end értékelésben 75,00 LAS F1 pontszámmal 81 teszt fából. Ezenkívül a négy meglepetés nyelven és a kisebb fabank részhalmazon volt a legmagasabb átlagos teljesítményünk.', 'lt': 'Mes apibūdiname mūsų įrašą C2L2 į CoNLL 2017 bendrą užduotį analizuoti visuotines priklausomybes nuo žaliavinio teksto. Mūsų sistemoje yra trijų pasaulinių analizavimo paradigmų, vieno grafiko ir dviejų pereinamojo laikotarpio. Kiekvienas modelis, koduojant morfologinę informaciją, naudoja dvikrypčius simbolių lygio LSTM kaip leksinių savybių ekstraktorius. Though relying on baseline tokenizers and focusing only on parsing, our system ranked second in the official end-to-end evaluation with a macro-average of 75.00 LAS F1 score over 81 test treebanks.  Be to, mes patyrėme didžiausią vidutinį rezultatą keturiose stebuklingose kalbose ir mažame medžio pagrindų pogrupyje.', 'it': "Descriviamo la nostra voce, C2L2, al compito condiviso CoNLL 2017 sull'analisi delle dipendenze universali dal testo grezzo. Il nostro sistema presenta un insieme di tre paradigmi globali di analisi, uno basato su grafici e due basati su transizione. Ogni modello utilizza LSTMs bidirezionali a livello di carattere come estrattori lessicali per codificare le informazioni morfologiche. Pur facendo affidamento sui tokenizer di base e concentrandosi solo sul parsing, il nostro sistema si è classificato secondo nella valutazione ufficiale end-to-end con una macro-media di 75,00 LAS F1 score su 81 treebank test. Inoltre, abbiamo avuto la massima performance media sulle quattro lingue a sorpresa e sul sottoinsieme di piccole banche degli alberi.", 'kk': 'Біз, C2L2 жазуымызды, CoNLL 2017 жазуына "Universal Dependencies" мәтіннен талдау үшін ортақтастырған тапсырмаңызды таңдадық. Біздің жүйеміз үш жалпы талдау парадигмінің белгісін, бір график негізінде және екі ауыстыру негізінде тұрады. Әрбір үлгі морфологиялық мәліметті кодтау үшін лаксикалық мүмкіндіктердің екі бағытты LSTMs таңбалардың деңгейін түрлендіреді. Бірақ негізгі тегіншілер мен тек талдау үшін көмектесіп, жүйеміздің соңғы соңғы бағалауында, 75,00 LAS F1 жылдамдығы 81 сынақтан артық тегіншілердің орташа макро-орташасында екінші ретінде орташады. Қосымша, біз төрт қызықтық тілдерде және кішкентай орташа жұмыс істейді.', 'mk': 'Го опишуваме нашиот запис, C2L2, на заедничката задача на CoNLL 2017 за анализирање на универзалните зависности од суров текст. Нашиот систем има ансембл од три глобални парадигми за анализирање, еден на график и два на транзиција. Секој модел ги користи бидирекционалните LSTMs на ниво на карактери како екстрактори на лексични карактеристики за кодирање на морфолошки информации. И покрај тоа што се потпираат на основните токенизатори и се фокусираат само на анализирање, нашиот систем се рангираше втор во официјалната оценка крај до крај со макро-просек од 75,00 LAS F1 оценка над 81 тестирани дрвја. Покрај тоа, имавме највисока просечна изведба на четирите изненадувачки јазици и на малиот подгруп на дрвјата.', 'ms': 'Kami menggambarkan masukan kami, C2L2, ke tugas kongsi CoNLL 2017 untuk menghurai Dependensi Universal dari teks mentah. Sistem kita mengandungi kumpulan tiga paradigm penghuraian global, satu berdasarkan graf dan dua berdasarkan transisi. Setiap model menggunakan LSTM bidireksi aras-aksara sebagai pengekstraktor ciri leksikal untuk mengekodkan maklumat morfologik. Walaupun bergantung pada tokenizer asas dan fokus hanya pada penghuraian, sistem kami berturut kedua dalam penilaian rasmi akhir-akhir dengan makro-rata-rata 75.00 skor LAS F1 lebih dari 81 pangkalan pepohonan ujian. In addition, we had the top average performance on the four surprise languages and on the small treebank subset.', 'ml': 'ഞങ്ങള്\u200d നമ്മുടെ എണ്ട്രി സി2L2, കോണ്\u200dഎല്\u200d 2017-ലേക്ക് പങ്കെടുത്ത ജോലിയെ വിശദീകരിക്കുന്നു. മോശമായ പദാവലിയില്\u200d നിന്നും പ Our system features an ensemble of three global parsing paradigms, one graph-based and two transition-based.  എല്ലാ മോഡലിനും അക്ഷരസഞ്ചയം ബി- നേരിട്ടെല്\u200d LSTMs ലെക്സിക്കല്\u200d ഗുണഗണങ്ങള്\u200d എക്സ്ട്രെക്റ്റര്\u200d ആയി ലെഫ്രോഫോളിക്കല്\u200d  ബേസ്റ്റ്ലൈന്\u200d ട്രീബാങ്കുകള്\u200dക്ക് മാത്രമേ നമ്മുടെ സിസ്റ്റത്തില്\u200d ആശ്രയിക്കുകയും ചെയ്യുകയും ചെയ്യുന്നുള്ളൂ. കൂടാതെ, നമുക്ക് നാല് അത്ഭുതകരമായ ഭാഷകളിലും ചെറിയ ട്രീബാങ്കിലും ഏറ്റവും ഉത്തമമായ പ്രദര്\u200dശനം ഉണ്ടായിരുന്നു.', 'mt': 'Aħna niddeskrivu d-dħul tagħna, C2L2, għall-kompitu komuni CoNLL 2017 dwar l-analiżi tad-Dipendenzi Universali mit-test mhux ipproċessat. Our system features an ensemble of three global parsing paradigms, one graph-based and two transition-based.  Kull mudell iħeġġeġ LSTMs bidirezzjonali fuq livell ta’ karattri bħala estratturi ta’ karatteristiċi lexiċi biex jikkodifikaw l-informazzjoni morfoloġika. Għalkemm tiddependi fuq it-tokenizers tal-linja bażi u tiffoka biss fuq l-analiżi, is-sistema tagħna kklassifikat it-tieni fl-evalwazzjoni uffiċjali minn tarf sa tarf b’makromedja ta’ 75.00 punteġġ LAS F1 fuq 81 punt tas-siġar tat-test. Barra minn hekk, kellna l-ogħla prestazzjoni medja fuq l-erba’ lingwi sorpriżi u fuq is-sottosett tal-banek żgħar tas-siġar.', 'mn': 'Бид 2017 оны CoNLL-д бидний C2L2-г универсал хамааралтай байдлыг хуваалцахын тулд хуваалцах үйлдлийг тайлбарлаж байна. Бидний систем 3 дэлхийн хуваалцах парадигм, нэг график дээр суурилсан, хоёр шилжилт дээр суурилсан. Загвар бүр морфологик мэдээллийг кодлохын тулд хоёр давхар-түвшинд LSTMs-г лексикийн шинжлэх ухааныг нэмэгдүүлдэг. Гэхдээ суурь шугамын тодорхойлолтуудыг анхаарлаа, зөвхөн хуваалцах дээр анхаарлаа төвлөрсөн ч, бидний систем официально төгсгөлд дундаж 75.00 LAS F1-ийн дундаж 75.00 гаруй шалгалтын тооны 81 шалгалтын давхар дээр хоёр давхар Мөн бид дөрвөн гайхалтай хэл болон жижиг дагуулын дагуу дээр дундаж үйл ажиллагаа хийсэн.', 'pl': 'Opisujemy nasz wpis, C2L2, do wspólnego zadania CoNLL 2017 dotyczącego parsowania uniwersalnych zależności z tekstu surowego. Nasz system obejmuje zespół trzech globalnych paradygmatów parsowania, jednego opartego na wykresie i dwóch opartych na przejściu. Każdy model wykorzystuje dwukierunkowe LSTMy na poziomie znaków jako ekstraktory cech leksykalnych do kodowania informacji morfologicznych. Chociaż opierając się na podstawowych tokenizerach i koncentrując się wyłącznie na parsowaniu, nasz system zajął drugi miejsce w oficjalnej ocenie końcowej z makro średnią 75.00 wyniku LAS F1 ponad 81 testowymi bankami drzew. Ponadto mieliśmy najwyższą średnią wydajność w czterech językach niespodzianek i na małym podzbiorze drzew.', 'ro': 'Descriem intrarea noastră, C2L2, la sarcina partajată CoNLL 2017 privind analizarea Dependențelor Universale din text brut. Sistemul nostru dispune de un ansamblu de trei paradigme globale de analizare, unul bazat pe grafic și două bazate pe tranziție. Fiecare model utilizează LSTMs bidirecționale la nivel de caracter ca extractori de caracteristici lexicale pentru a codifica informațiile morfologice. Deși se bazează pe tokenizere de bază și se concentrează doar pe analizare, sistemul nostru s-a clasat pe locul doi în evaluarea oficială end-to-end, cu o medie macro de 75,00 LAS F1 scor peste 81 de treebanks test. În plus, am avut performanța medie superioară pe cele patru limbi surpriză și pe subansamblul mic de brațe.', 'no': 'Vi skildrar oppføringa vårt C2L2 til CoNLL 2017 delt oppgåve om tolking av universelle avhengighet frå råtekst. Sistemet vårt inneheld ein ensembel av tre globale tolkingsprogrammer, ein grafikkbasert og to overgangsbasert. Kvar modell leverer teiknenivå på to retning av LSTMs som tekstfunksjonsekstraktorar for å koda morfologiske informasjon. Selv om det er på grunnlinje-tokenarar og berre fokusert på tolking, systemet vårt rangerte sekund i den offisielle ende-til-sluttevalueringa med makro-gjennomsnittlig 75,00 LAS F1-poeng over 81 test-treebank. I tillegg hadde vi den øvre gjennomsnittlige utviklinga på de fire overraskingspråka og på den lille treebanken.', 'sr': 'Opišemo naš ulaz, C2L2, na CoNLL 2017. zajednièki zadatak o analizu univerzalne zavisnosti od sirovog teksta. Naš sistem ukazuje na osnovu tri globalne paradigme za analizu, jednog na grafiku i dva na osnovu prijenosa. Svaki model utiče na dvosmjernu LSTMs nivou karaktera kao ekstraktore leksičkih karaktera kako bi kodirali morfološke informacije. Iako se oslanjajući na početne tokenizere i fokusirajući se samo na analizu, naš sistem je bio drugi u službenoj procjeni kraja do kraja sa makro-prosječnom procjenom od 75,00 LAS F1 rezultata preko 81 testova. Osim toga, imali smo najveću prosječnu predstavu na četiri jezika iznenađenja i na malim podskupinama.', 'si': 'අපි අපේ ඇතුලට, C2L2, CoNLL 2017 වලින් ජාතික විශේෂ විශේෂ විශේෂතාවක් පරික්ෂණය කරලා තියෙන්නේ. අපේ පද්ධතිය සම්බන්ධ විශ්වාසික පාර්ඩිග්ම් තුනක් සංවිධානයක් තියෙන්නේ, ග්\u200dරාෆ් එකක් අධාරිත හැම ප්\u200dරමාණයක්ම අක්ෂර- ප්\u200dරමාණයෙන් දෙවෙනි ප්\u200dරමාණයෙන් LSTMs විදිහට ලෙක්සිකල් විශේෂ විශේෂ අක්ෂර ස්ථානික ටොකෙනිසර් වලට විශ්වාස කරනවා නමුත් අපේ පද්ධතිය පරීක්ෂණය විතරයි, අපේ පද්ධතිය පද්ධතිය ප්\u200dරතික්\u200dරියාත්මක අවසාන විශ්වාස කරලා ති ඒ වගේම, අපිට පුදුම භාෂාවක් හතරයි පුදුම සාමාන්\u200dය ප්\u200dරදේශය තිබුනා.', 'so': 'Waxaannu u qoraynaa qoraalkayagii C2L2, CoNLL 2017 oo ku saabsan baaritaanka qiimaha dhamaanka jaamacadda ee qoraalka baaritaanka. nidaamkayaga waxaa ku yaala tusaale ahaan saddex baaritaanka caalamiga ah, hal graf ku saleysan iyo labo baaritaanka. Tusaale kasta waxaa ku qora xaraf-heer bi-directive LSTMs oo ah xeelad-xeeral, si loo koobo macluumaad morfological ah. In kastoo aad ku kalsoonaydo qoraal-bannaan oo kaliya baaritaanka, nidaamkayagii wuxuu ka soo bandhigay qiyaastii rasmiga ah ee ugu dambaysta ee ugu dambeeya, qiyaastii ugu dhexaysay 75.00 LAS F1 score ka badan 81 jareenka baaritaanka. Intaas waxaa dheer oo aan sameynay waxyaabaha ugu sarreeya afartii luqadood oo la yaabo iyo koobsiga yar ee treebaanka.', 'sv': 'Vi beskriver vår post, C2L2, till CoNLL 2017 delade uppgift om att tolka Universal Beroenden från råtext. Vårt system består av tre globala analysparadigm, ett grafbaserat och två övergångsbaserade. Varje modell utnyttjar LSTMs på karaktärsnivå som lexikala funktionsextraktorer för att koda morfologisk information. Även om vårt system förlitar sig på baslinjetokenizers och fokuserar endast på tolkning, rankades vårt system tvåa i den officiella end-to-end utvärderingen med ett makro-genomsnitt på 75,00 LAS F1 poäng över 81 testträdbanker. Dessutom hade vi den högsta genomsnittliga prestandan på de fyra överraskningsspråken och på den lilla trädbanken deluppsättningen.', 'ta': 'நாங்கள் எங்கள் உள்ளீடு, C2L2, கோன்எல் 2017 க்கு பங்கிட்ட பணியை விவரிக்கிறோம் குறைந்த உரையில் இருந்து அனைத்து சார்பு சார நம் அமைப்பு மூன்று உலக பாகுபடுத்தல் பகுதிகள், ஒரு வரைபடத்தை அடிப்படையாக மற்றும் இரண்டு மாற்றம் அடிப்படையில் உள்ளது. ஒவ்வொரு மாதிரியிலும் எழுத்து- நிலை இர- திசையாக LSTMs லெக்சிகல் குணங்கள் வெளியீட்டாளராக குறியீட்டு தகவலை குறி அடிப்படைக்கோட்டு குறிப்பாளர்கள் மீது நம்பிக்கை மற்றும் பாடல் மீது மட்டும் கவனம் செலுத்தி இருந்தாலும், எங்கள் அமைப்பு தேவையான முடிவு மதிப்பில் இரண் மேலும், நான்கு ஆச்சரியமான மொழிகள் மற்றும் சிறிய மூன்று துணையில் மேல் சராசரி செயல்பாடு இருந்தது.', 'ur': 'ہم نے اپنا آنٹر C2L2 کو CoNLL 2017 کے ساتھ مشترک کام کے بارے میں تقسیم کرنے کے لئے تقسیم کیا ہے۔ ہماری سیستم نے تین گلوبی پارسینگ پاراڈیگ کے علائم کو ایک گراف پر بنیاد رکھا ہے اور دو تغییر پر بنیاد رکھا ہے Each model leverages character-level two-directional LSTMs as lexical feature extractors to encode morphological information. اگرچہ بنیادی لین ٹوکینیزر پر بھروسہ کرتا ہے اور صرف پارسینٹ پر تمرکز کرتا ہے، ہماری سیسٹم نے رسمی انتظام کے بعد دوسری امتحان میں ایک مکرو متوسط 75.00 LAS F1 اسکور 81 ٹریبنک پر ہے۔ اور ہم نے چار عجیب زبانوں اور چھوٹی ٹریب بانک سٹ پر عمدہ عمدہ کیا۔', 'uz': "Biz C2L2, CoNLL 2017 ta'minlovchi tashkilotlarimizni qiyin matnni koʻchirish uchun Universal Dependenciyatlarni qaytadi. Bizning tizimimiz uchta global parsing paradigmlarini bir grafik asosida va ikkita ta'lim asosida yaratish mumkin. @ info Agar baseline belgilariga ishlatayotganda va faqat parsing uchun foydalanish mumkin, bizning tizimmiz faqat faqat boshqaruvchiga birinchi qiymatda o'zgarishni boshlaydi. 75.00 LAS F1 qiymati 81 ta'minlovchi darajadagi darajaga ega bo'ladi. Ko'pchilik, bizda to'rtta ajoyib tillar va kichkina treebank tub sohasida eng eng darajada bajarish natijasi bor edi.", 'vi': 'Chúng tôi mô tả mục nhập của chúng tôi, Cnă-2, vào nhiệm vụ chung của Coyl phần thưởng thẩm quyền phân tích các quan hệ chung từ chữ nguyên bản. Hệ thống của chúng tôi có một kết hợp gồm ba biểu tượng phân tích toàn cầu, một căn cứ đồ thị và hai phương án chuyển đổi. Mỗi mô- đun điều khiển ký tự cấp hai bộ phận định hướng là bộ dẫn hóa chất để mã hóa thông tin lịch sự. Mặc dù chỉ dựa vào các hiệu đồ cơ bản và chỉ tập trung vào phân tách, hệ thống được xếp hạng thứ hai trong các đánh giá cuối cùng chính thức cùng cùng với tỉ lệ số tiến lớn của 75.00 LAS F1 vượt qua 81 thử thách ba cốc. Ngoài ra, chúng tôi có một suất suất trung bình cao trên bốn ngôn ngữ ngạc nhiên và trong nhóm nhỏ.', 'bg': 'Описваме нашето участие, C2L2, в споделената задача за анализиране на универсални зависимости от суров текст. Нашата система разполага с ансамбъл от три глобални парадигми за анализ, една базирана на графика и две базирани на преход. Всеки модел използва двупосочни ЛСТМ на ниво знаци като лексикални екстрактори за кодиране на морфологична информация. Въпреки че разчитахме на базовите токенизатори и се фокусирахме само върху анализирането, нашата система се класира на второ място в официалната оценка от край до край с макросредно 75,00 резултат над 81 тест рейбънка. Освен това, ние имахме най-високо средно представяне на четирите езика изненада и на малкия поднабор от дървета.', 'nl': "We beschrijven onze vermelding, C2L2, voor de gedeelde taak CoNLL 2017 over het parsen van universele afhankelijkheden van ruwe tekst. Ons systeem beschikt over een ensemble van drie globale parsing paradigma's, één op grafiek en twee op overgang gebaseerd. Elk model maakt gebruik van karakterniveau bi-directionele LSTMs als lexicale feature extractors om morfologische informatie te coderen. Hoewel ons systeem vertrouwt op baseline tokenizers en zich alleen richt op parsen, werd ons systeem tweede in de officiële end-to-end evaluatie met een macro-gemiddelde van 75.00 LAS F1 score boven 81 testboombanken. Daarnaast hadden we de top gemiddelde prestaties op de vier verrassingstalen en op de kleine boombank subset.", 'da': "Vi beskriver vores post, C2L2, til CoNLL 2017 delte opgave om at analysere universelle afhængigheder fra rå tekst. Vores system indeholder et ensemble af tre globale parsing paradigmer, et grafbaseret og to overgangsbaseret. Hver model udnytter LSTMs'er på karakterniveau i to retninger som leksikalske funktionsekstraktorer til at kode morfologisk information. Selvom vi er afhængige af baseline tokenizere og kun fokuserer på parsing, rangerede vores system andenpladsen i den officielle end-to-end evaluering med et makro-gennemsnit på 75,00 LAS F1 score over 81 test treebanks. Derudover havde vi den højeste gennemsnitlige præstation på de fire overraskelsessprog og på den lille treebank delmængde.", 'hr': 'Opišemo naš ulaz, C2L2, na CoNLL 2017 zajednički zadatak o analizu univerzalnih zavisnosti od sirovog teksta. Naš sustav pokazuje kompleks tri globalne paradigme za analizu, jedan na grafu baziran i dva na temelju prijenosa. Svaki model utiče na dvosmjernu LSTMs nivou karaktera kao ekstraktore leksičkih karaktera kako bi kodirali morfološke informacije. Iako se oslanjajući na početne tokenizere i fokusirajući se samo na analizu, naš sustav je bio drugi u službenoj procjeni kraja do kraja sa makro prosječnom procjenom od 75,00 LAS F1 rezultata iznad 81 testova. Osim toga, imali smo najviši prosječni izvod na četiri jezika iznenađenja i na malim podskupinama.', 'de': 'Wir beschreiben unseren Eintrag C2L2 zur gemeinsamen Aufgabe CoNLL 2017 zum Parsen universeller Abhängigkeiten aus Rohtext. Unser System besteht aus drei globalen Parsing-Paradigmen, einem graphenbasierten und zwei transitionsbasierten. Jedes Modell nutzt bidirektionale LSTMs auf Zeichenebene als lexikalische Merkmalsextraktoren, um morphologische Informationen zu kodieren. Obwohl unser System sich auf Baseline-Tokenizer stützte und sich nur auf Parsing konzentrierte, belegte es in der offiziellen End-to-End-Bewertung den zweiten Platz mit einem Makro-Durchschnitt von 75,00 LAS F1-Score gegenüber 81-Testbaumbanken. Darüber hinaus hatten wir die höchste durchschnittliche Leistung auf den vier Überraschungssprachen und auf der kleinen Baumbank Subset.', 'id': 'Kami menggambarkan masukan kami, C2L2, untuk tugas CoNLL 2017 berbagi untuk menghurai Dependensi Universal dari teks mentah. Sistem kita mengandung sebuah ensemble dari tiga paradigma penghuraian global, satu berdasarkan grafik dan dua berdasarkan transisi. Setiap model mempengaruhi LSTM dua arah karakter sebagai ekstraktor karakter lexik untuk mengkode informasi morfologi. Meskipun bergantung pada tokenizer dasar dan fokus hanya pada penghuraian, sistem kami tertarik kedua dalam evaluasi resmi akhir-akhir dengan makro-rata-rata 75,00 LAS F1 skor lebih dari 81 batang pohon tes. Selain itu, kami memiliki pertunjukan rata-rata atas pada empat bahasa kejutan dan pada subset punggung pohon kecil.', 'ko': 'CoNLL 2017 공유 작업의 항목 C2L2에 대해 설명했습니다. 이 작업은 원본 텍스트에서 공통 의존 항목을 해석하는 것입니다.우리 시스템은 세 가지 전역 해석 모델을 포함하는데 하나는 도형을 바탕으로 하고 두 가지는 전환을 바탕으로 한다.모든 모델은 문자급 양방향 LSTM을 문법적 특징 추출기로 이용하여 형태학 정보를 인코딩한다.비록 우리 시스템은 기선 표기기에 의존하고 해석에만 관심을 가지지만 정부측의 단말기부터 단말기까지의 평가에서 우리 시스템은 2위를 차지했고 81개의 테스트 트리 라이브러리에서 LAS F1의 거시적 평균 점수는 75.00이었다.그 밖에 우리는 네 가지 의외의 언어와 소형 트리 라이브러리 서브집합에서 평균 성능이 가장 높다.', 'fa': 'ما وارد شدن C2L2 را توصیف می\u200cکنیم، به کاری CoNLL 2017 که در مورد بررسی بستگی\u200cهای جهانی از متن خارج است. سیستم ما یک جمله از سه پارادیگ\u200cهای تجزیه جهانی، یک گراف بر اساس آن و دو تغییر بر اساس آن نشان می\u200cدهد. هر مدل به عنوان خارج کننده\u200cهای ویژه\u200cهای زبانی برای رمزگذاری اطلاعات مورفولوژیکی سطح شخصیت دو طریق LSTMs را تغییر می\u200cدهد. اگرچه بر نشان\u200cدهندگان پایین\u200cخط و تمرکز کردن تنها بر پایین\u200cدهندگان، سیستم ما در ارزیابی رسمی به پایان\u200cرسمی با یک مکرو متوسط ۲۵۰۰ نمونه\u200cای LAS F1 بیش از ۱۸ نمره\u200cهای آزمایش درجه گرفته است. علاوه بر این، ما عملکرد متوسط بالاترین در چهار زبان سورپرایز و در قسمت کوچک درخت کوچک داشتیم.', 'tr': 'Biz 철z giri힊imizi, C2L2, CoNLL 2017-nji 첵ylda Uniwersal Ba첵umlyklary 챌yz metinden ay캇rmak 체챌in pa첵la힊dyk. Bizim sistemimiz 체챌 d체n첵채d채ki analyz paradigmany흫 bir g철rn철힊i, bir grafik tabanly we iki g철rn철힊im tabanly bir g철rn철힊i bar. Her nusga morfolojik maglumaty kodlemek 체챌in karakter derejesini iki g철rn철힊i g철rkez Hat 챌izgi tokeniz챌ilerine g체venip, sadece analiz etmek 체zere odaklanmam캇za ra휓men sistemimiz resmi son-son de휓erlendirmesinde 75,00 LAS F1 ortalamas캇 81 test 챌ubu휓undan fazla noktas캇 vard캇r. Munu흫 체챌in d철rt sany ge흫 첵agtylyk dilinde we ki챌i bag챌ylyk toparynda orta sanymyz bar.', 'sw': 'Tunaelezea kuingia kwetu, C2L2, kwa CoNLL 2017, kazi ya kusambaza kutengeneza matumaini ya ulimwengu kutoka kwa ujumbe mzuri. Mfumo wetu unaonyesha mifano ya mabadiliko matatu duniani, picha moja na mbili za mpito. Kila mifano inatumia alama-daraja moja kwa moja LSTMs kama wataalamu wa kilexico ili kuweka taarifa za kifolojia. Ingawa wanategemea wataalamu wa msingi na wakijikita tu kwenye kuimba, mfumo wetu ulipandisha sekunde ya pili katika tathmini rasmi ya mwisho kwa wastani wa wastani wa 75.00 LAS F1 zaidi ya viwanja vya uchunguzi 81. Zaidi ya hayo, tulikuwa na utendaji wa wastani wa juu katika lugha nne za kushangaza na kwenye kituo hicho kidogo cha mitaani.', 'sq': 'Ne përshkruajmë hyrjen tonë, C2L2, në detyrën e përbashkët të CoNLL 2017 për analizimin e Varësive Universale nga teksti i papërpunuar. Sistemi ynë paraqet një komplet prej tre paradigmave globale të analizimit, një bazuar në grafik dhe dy bazuar në tranzicion. Çdo model nxjerr LSTMs dy-drejtues në nivelin e karakterit si nxjerrës lexik të karaktereve për të koduar informacionin morfologjik. Though relying on baseline tokenizers and focusing only on parsing, our system ranked second in the official end-to-end evaluation with a macro-average of 75.00 LAS F1 score over 81 test treebanks.  Përveç kësaj, ne patëm shfaqjen mesatare më të lartë në katër gjuhët e befasuara dhe në nëngrupin e vogël të bazës së pemëve.', 'af': "Ons beskryf ons inskrywing, C2L2, na die CoNLL 2017 gedeelde taak op verwerking van Universele Afhanklikhede van rooi teks. Ons stelsel is 'n ensemble van drie globale verwerking paradigme, een graafgebaseerde en twee oorgang gebaseer. Elke model verwyder karaktervlak bi- rigting LSTMs as leksiese funksie uitpakers om morfologiese inligting te kodeer. Alhoewel jy op baselyn tokenizers vertrou en slegs op verwerking fokus, ons stelsel het tweede in die offisiele einde- na- einde evaluasie met 'n makro- gemiddelde van 75. 00 LAS F1 telling oor 81 toets treebanks. In addition, we had the top average performance on the four surprise languages and on the small treebank subset.", 'am': 'የC2L2 መግቢያችንን ከጥቁር ጽሑፍ የተለየውን የዓለማዊ ድጋፍ ማጋራት የኮንஎல_2017ስራዎችን እናሳውቃለን፡፡ ስርዓታችን በሦስት ዓለምአቀፍ ማኅበረሰብ፣ አንዲት graph-based እና ሁለት ተለይቷል፡፡ የሞዴል ዓይነት አቀማመጥ ምንም እንኳን በመስመር ላይ የሚታመን እና ማኅበራዊ ማኅበረሰብ ብቻ ሲሆን፣ የሥልጣን መጨረሻ መጨረሻ ሁለተኛ ክፍል ላይ በተመሳሳይ የ75.00 LAS F1 ክፍል በ81 ድምፅ ክፍል ላይ የተመሳሳይ ሁለተኛ ክፍል ነው፡፡ በተጨማሪም፣ በአራቱ የበረታች ቋንቋዎች እና ታናሹ የሦስት ደብዳቤ አካባቢ ላይ የበለጠው የድምፅ ውጤት ነበረን፡፡', 'bn': 'আমরা আমাদের প্রবেশ, সি২এল২, কনএল ২০১৭ সালের কাছে পার্সিং বিশ্ববিদ্যালয়ের নির্ভরযোগ্য কাজ শেয়ার করেছি। আমাদের সিস্টেম তিনটি বিশ্বব্যাপী পার্সিং প্যারাডিম, একটি গ্রাফ ভিত্তিক এবং দুটি ট্রান্সপ্রান্স ভিত্তি প্রত্যেক মডেলের লেভারেজের অক্ষর-স্তর বি-সরাসরি LSTMs লেক্সিক্যাল বৈশিষ্ট্যাবলী বৈশিষ্ট্যাবলী বৈশিষ্ট্যাবল যদিও বেস্লাইনের অঙ্গীকারীদের উপর নির্ভর করে এবং শুধুমাত্র পার্সিং নিয়ে মনোযোগ প্রদান করে, আমাদের সিস্টেম অফিসিয়াল শেষ পর্যন্ত মূল্যের দ্বিতীয় সেক এছাড়াও, আমাদের চারটি বিস্ময়কর ভাষা এবং ছোট ট্রিবাঙ্কের সাববেটে সর্বোচ্চ গড়া প্রদর্শন করা হয়েছে।', 'az': 'Biz, C2L2-imizi, CoNLL 2017-ci ilə Universal bağımlılıqlarını süt metindən ayırmaq haqqında paylaşır. Sistemimiz üç küresel ayırma paradiglərinin, bir grafik-tabanlı və iki dəyişiklik-tabanlı bir ensembli mövcuddur. Hər model morfolojik məlumatları kodlamaq üçün cüzələr-seviyyəsini iki yönəldən LSTMs kimi leksik xüsusiyyət ekstraktörləri yaradır. Sətir tokenizerlərinə təvəkkül edib yalnız analizə tərəf tərəf tərəf yönəldilərsə də, sistemimiz resmi sona-sona tərəf müəyyən edilməsində 75,00 LAS F1 dərəcəsi 81 test çubuqlarının üstündə olan bir makro ortalaması ilə ikinci dərəcədə yerləşdirdi. Əvvəlcə, dört təəccüblü dillərin və küçük çörək sübutların üstündə ortalama performansı var idi.', 'hy': 'Մենք նկարագրում ենք մեր գրությունը, C2L2, 2017-ի ԿոնԼԼ-ի ընդհանուր հանձնարարությունը՝ համաշխարհային կախվածությունների վերլուծությունը չափով տեքստից: Մեր համակարգը ունի երեք գլոբալ վերլուծության պարադիգմերի համակարգ, մեկ գրաֆիայի և երկու վերափոխման պարադիգմերի համակարգ: Յուրաքանչյուր մոդել օգտագործում է բնավորության մակարդակի երկիուղղությամբ LSMT-ները որպես լեքսիկական հատկանիշների հանողներ, որպեսզի կոդավորի մորֆոլոգիական տեղեկատվությունը: Though relying on baseline tokenizers and focusing only on parsing, our system ranked second in the official end-to-end evaluation with a macro-average of 75.00 LAS F1 score over 81 test treebanks.  Ավելին, մենք ունեինք ամենաբարձր միջին արտադրողականությունը չորս զարմանալի լեզուներում և փոքր ծառի բակի հատվածում:', 'ca': "Descrivem la nostra entrada, C2L2, a la tasca compartida CoNLL 2017 en analitzar les Dependencies Universals a partir del text brut. El nostre sistema té un conjunt de tres paradigmes globals d'analització, un basat en gràfics i dos basats en transició. Cada model utilitza LSTMs bidireccionals a nivell de caràcter com extractors de característiques lècsiques per codificar informació morfològica. Encara que confiant en els fitxes de base i centrant-nos només en l'analització, el nostre sistema es va classificar segon en l'evaluació oficial de final a final amb una macromitjana de 75,00 puntuacions LAS F1 sobre 81 bancs d'arbres de prova. A més, vam tenir el rendiment mitjà superior en les quatre llengües sorprenents i en el petit subconjunt.", 'cs': 'Popisujeme náš záznam C2L2 ke sdílenému úkolu CoNLL 2017 o parsování univerzálních závislostí z surového textu. Náš systém obsahuje soubor tří globálních parsovacích paradigmatů, jednoho grafového a dvou přechodového. Každý model využívá obousměrné LSTMs na úrovni znaků jako lexikální extraktory znaků k kódování morfologických informací. Ačkoli se spoléhá na základní tokenizátory a zaměřuje se pouze na analýzu, náš systém se v oficiálním end-to-end hodnocení zařadil na druhé místo s makroprůměrem 75,00 LAS F1 skóre nad 81 testovacími stromy. Kromě toho jsme měli nejvyšší průměrný výkon ve čtyřech překvapivých jazycích a na malé podmnožině stromů.', 'et': 'Kirjeldame oma kandet C2L2 CoNLL 2017 jagatud ülesandesse universaalsete sõltuvuste parsimiseks toortekstist. Meie süsteem koosneb kolmest globaalsest parsimise paradigmast, ühest graafikapõhisest ja kahest üleminekupõhisest. Iga mudel kasutab märgitasemel kahesuunalisi LSTMsid leksikaalsete omaduste ekstraktoritena morfoloogilise teabe kodeerimiseks. Kuigi meie süsteem tugineb algtaseme tokeniseritele ja keskendub ainult parsimisele, oli ametlikus lõpp-lõpuni hindamises teisel kohal makrokeskmiselt 75,00 LAS F1 skoori üle 81 testipuupunkti. Lisaks oli meil parim keskmine tulemus neljas üllatuskeeles ja väikeses puupangas alamhulgas.', 'bs': 'Opišemo naš ulaz, C2L2, na CoNLL 2017 zajednički zadatak o analizu univerzalnih zavisnosti od sirovog teksta. Naš sistem pokazuje kompleks tri globalne paradigme za analizu, jedan na grafu baziran i dva na prelaznoj bazi. Svaki model utiče na dvosmjernu LSTMs nivou karaktera kao ekstraktore leksičkih karaktera za kodiranje morfoloških informacija. Iako se oslanjajući na početne tokenizere i fokusirajući se samo na analizu, naš sistem je bio drugi u službenoj procjeni kraja do kraja sa makro-prosječnom procjenom od 75,00 LAS F1 rezultata iznad 81 testova. Osim toga, imali smo najviši prosječni izvod na četiri jezika iznenađenja i na malim podskupinama za treeban.', 'fi': 'Kuvaamme artikkelimme C2L2 CoNLL 2017:n yhteiseen tehtävään Universaalisten riippuvuuksien jäsentämisestä raakatekstistä. Järjestelmämme koostuu kolmesta globaalista jäsennysparadigmasta, joista yksi on graafinen ja kaksi siirtymäpohjainen. Jokainen malli hyödyntää merkkitason kaksisuuntaisia LSTMs:itä leksikaalisina ominaisuuksien uuttajina morfologisen tiedon koodaamiseksi. Vaikka järjestelmämme luotti perusviivan tokenizereihin ja keskittyi vain jäsentämiseen, se sijoittui toiseksi virallisessa end-to-end-arvioinnissa makrokeskiarvolla 75,00 LAS F1 -pisteellä 81 testipuupenkillä. Lisäksi meillä oli korkein keskimääräinen suorituskyky neljässä yllätyskielessä ja pienessä treebankin osaryhmässä.', 'jv': "Awakdhéwé rak nggawe Entrance, C2L2, nggo CoNLL 1997 that's a condolete task en te ayoleh Universal dependancies from red text. Sistem-sistem kita ngawehi sistem karo akeh basa tanggal liyane karo perusahaan kanggo nggawe barang, sampek kayata barang sampek durung. Same model Nombo Nambah, awak dhéwé wis ngerasakno kanggo kalaha dolanan sing sepira luwih karo nganggo cara-cara sing sepira mburu.", 'he': 'אנחנו מתארים את הכניסה שלנו, C2L2, למשימה משותפת CoNLL 2017 על חקירת תלויות Universal מטקסט ראוי. המערכת שלנו מכילה אסמבל של שלושה פרדיגמות מעבדה גלובלית, אחד מבוסס בגרף ושני מבוססים על מעבר. כל מודל משתמש בשימוש LSTMs ביכיווני רמת אופים כחולץ תכונות לקסיות כדי לקוד מידע מורפולוגי. למרות שסומכים על סימנים בסיסיים ומתמקדים רק על בדיקה, המערכת שלנו התייצבה שנייה בהערכה רשמית בסוף לסוף עם מקרו-ממוצע של 75.00 נקודות LAS F1 מעל 81 בנקי עץ מבחן. בנוסף, היתה לנו את ההופעה הממוצעת ביותר בארבעה שפות הפתעה ובתחתונה הקטנה של קצה העץ.', 'sk': 'Opisujemo naš vnos C2L2 v skupno nalogo CoNLL 2017 o razčlenitvi univerzalnih odvisnosti iz surovega besedila. Naš sistem vsebuje ansambl treh globalnih paradigem razčlenitve, eno na grafični in dve na prehodni osnovi. Vsak model uporablja dvosmerne LSTMs na ravni znakov kot leksikalne ekstraktorje znakov za kodiranje morfoloških informacij. Čeprav se je naš sistem zanašal na osnovne žetonizatorje in se osredotočal samo na razčlenjevanje, se je v uradni oceni od konca do konca uvrstil na drugo mesto z makropovprečjem 75,00 LAS F1 rezultata nad 81 testnimi drevesi. Poleg tega smo imeli najboljšo povprečno uspešnost v štirih jezikih presenečenj in na majhnem podnaboru dreebank.', 'ha': "Tuna bayyana mataimakanmu, C2L2, zuwa CoNLL 2017 mai rabo aikin da aka yi parse Universal Dekurs daga raw text. TsarinMu na ƙunsa da wata samfani na parse ta duniya uku, da karagrafi-da'a biyu ta shige. @ info: whatsthis Inã da amfani da masu tsari da basalin ayukan bango kuma yana da fokus a kan parse kawai, na'asarmu ta ranar da sakan da aka ƙayyade karɓi na rubutun ta fara ta ƙari zuwa ƙarshen, kuma an samu karatun wata macro-gwargwadon MAS F1 na ƙaranci akan 81 na jarrabo. Kuma da wancan, mun sami babban rabo a kan harshen huɗu na mãmãki da kuma a kan ƙanƙan ƙarami na bakwai.", 'bo': 'ང་ཚོས་རང་གི་འཇུག་ཐོག་C2L2, CoNLL ལ་སྤྱད་པའི་བྱ་འགུལ་གྱི་ནང་དུ་འཇུག་སྣོད་ཀྱི་རྩོམ་འབྲེལ་མིའི་ནང་དུ་བཤད་པ ང་ཚོའི་མ་ལག་གི་རྣམ་གྲངས་ཀྱིས་འཛམ་གླིང་ཡུལ་གྱི་མིང་དཔྱད་གསུམ་ཀྱི་དཔེ་མཚོན་རྟགས་འདུག། Each model leverages character-level bi-directional LSTMs as lexical feature extractors to encode morphological information. Though relying on baseline tokenizers and focusing only on parsing, our system ranked second in the official end-to-end evaluation with a macro-average of 75.00 LAS F1 score over 81 test treebanks. With a macro-average of 75.00 LAS F1 score over 81 test treebanks.[citation needit] ད་དུང་། ང་ཚོར་ཚོར་སྐྱེས་པའི་བརྗོད་མཁན་གྱི་སྐད་རིགས་བཞིན་དང་ཁྱེར་ཆུང་ཆུང་གི་གྲལ་སུ་རྒྱ་ཆེ་མཐོང་བ'}
{'en': 'The HIT-SCIR System for End-to-End Parsing of Universal Dependencies', 'ar': 'نظام HIT-SCIR لتحليل التبعيات الشاملة من طرف إلى طرف', 'fr': "Le système HIT-SCIR pour l'analyse de bout en bout des dépendances universelles", 'pt': 'O sistema HIT-SCIR para análise ponta a ponta de dependências universais', 'zh': '通用以端到端解析者 HIT-SCIR 统', 'es': 'El sistema HIT-SCIR para el análisis de extremo a extremo de dependencias universales', 'ja': 'ユニバーサル依存関係のエンドツーエンド解析のためのHIT - SCIRシステム', 'ru': 'Система HIT-SCIR для сквозного анализа универсальных зависимостей', 'hi': 'यूनिवर्सल निर्भरताओं के एंड-टू-एंड पार्सिंग के लिए HIT-SCIR सिस्टम', 'ga': 'Córas HIT-SCIR chun Spleáchais Uilíocha a Pharsáil ó cheann go ceann', 'ka': 'Name', 'el': 'Το σύστημα για την ολοκληρωμένη ανάλυση καθολικών εξαρτήσεων', 'hu': 'HIT-SCIR rendszer az univerzális függőségek végpontos értelmezésére', 'lt': 'The HIT-SCIR System for End-to-End Parsing of Universal Dependencies', 'it': "Il sistema HIT-SCIR per l'analisi end-to-end delle dipendenze universali", 'kk': 'HIT- SCIR Universal Dependencies талдау жүйесі', 'mk': 'HIT- SCIR системот за анализирање на универзалните зависности од крај до крај', 'ml': 'എല്ലാവര്\u200dക്കും അവസാനിക്കുന്നതിനുള്ള HIT-SCIR സിസ്റ്റം', 'ms': 'Sistem HIT-SCIR untuk Penghuraian Akhir-Akhir Kedependensi Universal', 'mt': 'Is-Sistema HIT-SCIR għall-Analiżi minn tmiem sa tmiem tad-Dipendenzi Universali', 'mn': 'HIT-SCIR System for End-to-End Parsing of Universal Dependencies', 'pl': 'System HIT-SCIR do kompleksowego parowania uniwersalnych zależności', 'ro': 'Sistemul HIT-SCIR pentru analizarea completă a dependenţelor universale', 'sr': 'HIT-SCIR sistem za razmatranje univerzalnih zavisnosti', 'no': 'HIT- SCIR- systemet for end- to- end tolking av universelle avhengighet', 'si': 'HIT-SCIR පද්ධතිය අවසානයෙන් අවසානයෙන් අවසාන විශ්වාස විශ්වාස කරන්න', 'so': 'Xeerka dhamaadka ee dhamaadka dhamaadka ee dhamaadka ee dhamaadka', 'ta': 'பொது சார்ந்த சார்புகளுக்கான HIT- SCIR அமைப்பு', 'sv': 'HIT-SCIR-systemet för fullständig tolkning av universella beroenden', 'ur': 'Name', 'uz': 'Umumiy qoʻllanmalar uchun HIT-SCIR tizimi', 'vi': 'Hệ thống HIT-SCRM để phân tích kết thúc các mối quan hệ chung', 'hr': 'HIT-SCIR sustav za razmatranje univerzalnih zavisnosti', 'nl': 'Het HIT-SCIR systeem voor end-to-end parsen van universele afhankelijkheden', 'bg': 'Системата за анализ от край до край на универсалните зависимости', 'da': 'HIT-SCIR systemet til end-to-end fortolkning af universelle afhængigheder', 'de': 'Das HIT-SCIR System zum durchgängigen Parsen universeller Abhängigkeiten', 'id': 'Sistem HIT-SCIR untuk Analisasi Akhir-Akhir Dependensi Universal', 'fa': 'سیستم HIT-SCIR برای پایان و پایان تحلیل بستگی جهانی', 'ko': '공통 종속성 종단 간 해결된 HIT-SCIR 시스템', 'sw': 'Mfumo wa UKIMWI wa Uchaguzi wa UKIMWI', 'tr': 'HIT-SCIR Halkara Baýramlyklaryň ahyry-soňy Taýýarlamak üçin sistemi', 'sq': 'Sistemi HIT-SCIR për analizimin nga fundi në fund të varësive universale', 'af': 'Name', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'The HIT-SCIR System for End-to-End Parsing of Universal Dependencies', 'az': 'Universel bağımlılıqların sonu-sonu analizi üçün HIT-SCIR sistemi', 'bn': 'বিশ্ববিদ্যালয়ের নির্ভরিত পার্সিং এর HIT-SCIR সিস্টেম', 'bs': 'HIT-SCIR sistem za razmatranje univerzalnih zavisnosti', 'ca': "El sistema HIT-SCIR per l'analització final de les dependencies universals", 'et': 'HIT-SCIR süsteem universaalsete sõltuvuste täielikuks parsimiseks', 'cs': 'HIT-SCIR systém pro komplexní analýzu univerzálních závislostí', 'fi': 'HIT-SCIR-järjestelmä universaalien riippuvuuksien kokonaisvaltaiseen analysointiin', 'jv': 'HIT-scIR Sistem kanggo End-to-End Ndelengkapan universe dipendénsi', 'he': 'מערכת HIT-SCIR עבור בדיקת תלויות יוניברסליות', 'sk': 'Sistem HIT-SCIR za celovito razčlenitev univerzalnih odvisnosti', 'ha': 'KCharselect unicode block name', 'bo': 'ཡོངས་ཁྱབ་རྟེན་འབྲེལ་གྱི་ཆ་བཤད་ཀྱི་HIT-SCIR མ་ལག'}
{'en': 'This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared task : Multilingual Parsing from Raw Text to Universal Dependencies. Our system includes three pipelined components : tokenization, Part-of-Speech (POS) tagging and dependency parsing. We use character-based bidirectional long short-term memory (LSTM) networks for both tokenization and POS tagging. Afterwards, we employ a list-based transition-based algorithm for general non-projective parsing and present an improved Stack-LSTM-based architecture for representing each transition state and making predictions. Furthermore, to parse low / zero-resource languages and cross-domain data, we use a model transfer approach to make effective use of existing resources. We demonstrate substantial gains against the UDPipe baseline, with an average improvement of 3.76 % in LAS of all languages. And finally, we rank the 4th place on the official test sets.tokenization,\n      Part-of-Speech (POS) tagging and dependency parsing.\n      We use character-based bidirectional long short-term memory (LSTM) networks for\n      both tokenization and POS tagging.\n      Afterwards, we employ a list-based transition-based algorithm for general\n      non-projective parsing and present an improved Stack-LSTM-based architecture\n      for representing each transition state and making predictions.\n      Furthermore, to parse low/zero-resource languages and cross-domain data, we use\n      a model transfer approach to make effective use of existing resources.\n      We demonstrate substantial gains against the UDPipe baseline, with an average\n      improvement of 3.76% in LAS of all languages. And finally, we rank the 4th\n      place on the official test sets.\n    ', 'ar': 'تصف هذه الورقة نظامنا (HIT-SCIR) للمهمة المشتركة لـ CoNLL 2017: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. يشتمل نظامنا على ثلاثة مكونات متسلسلة: الترميز ، وعلامات جزء من الكلام (POS) ، وتحليل التبعية. نحن نستخدم شبكات الذاكرة طويلة المدى ثنائية الاتجاه القائمة على الأحرف (LSTM) لكل من الترميز وعلامات نقاط البيع. بعد ذلك ، نستخدم خوارزمية قائمة على الانتقال للتحليل العام غير الإسقاطي ونقدم بنية محسّنة قائمة على Stack-LSTM لتمثيل كل حالة انتقالية وإجراء تنبؤات. علاوة على ذلك ، لتحليل اللغات منخفضة / صفر الموارد والبيانات عبر المجالات ، نستخدم نهج نقل النموذج للاستفادة الفعالة من الموارد الحالية. لقد أظهرنا مكاسب كبيرة مقابل خط الأساس UDPipe ، مع تحسن متوسط قدره 3.76٪ في LAS لجميع اللغات. وأخيرًا ، احتلنا المرتبة الرابعة في مجموعات الاختبار الرسمية.', 'pt': 'Este artigo descreve nosso sistema (HIT-SCIR) para a tarefa compartilhada CoNLL 2017: Análise multilíngue de texto bruto para dependências universais. Nosso sistema inclui três componentes em pipeline: tokenização, marcação de parte de fala (POS) e análise de dependência. Usamos redes de memória de longo prazo (LSTM) bidirecionais baseadas em caracteres para tokenização e marcação POS. Em seguida, empregamos um algoritmo baseado em transição baseado em lista para análise geral não projetiva e apresentamos uma arquitetura baseada em Stack-LSTM aprimorada para representar cada estado de transição e fazer previsões. Além disso, para analisar linguagens de baixo/zero recursos e dados entre domínios, usamos uma abordagem de transferência de modelo para fazer uso eficaz dos recursos existentes. Demonstramos ganhos substanciais em relação à linha de base do UDPipe, com uma melhoria média de 3,76% no LAS de todos os idiomas. E, finalmente, classificamos o 4º lugar nos conjuntos de testes oficiais.', 'fr': "Cet article décrit notre système (HIT-SCIR) pour la tâche partagée ConLL 2017\xa0: Parsing multilingue du texte brut aux dépendances universelles. Notre système comprend trois composants en pipeline\xa0: la tokenisation, le balisage de la partie du discours (POS) et l'analyse des dépendances. Nous utilisons des réseaux LSTM (Long Short-Term Memory) bidirectionnels basés sur des caractères à la fois pour la segmentation en jetons et le marquage POS. Ensuite, nous utilisons un algorithme de transition basé sur une liste pour l'analyse non projective générale et présentons une architecture améliorée basée sur Stack-LSTM pour représenter chaque état de transition et faire des prédictions. De plus, pour analyser les langages à ressources faibles ou nulles et les données interdomaines, nous utilisons une approche de transfert de modèle afin d'utiliser efficacement les ressources existantes. Nous démontrons des gains substantiels par rapport à la base UDPipe, avec une amélioration moyenne de 3,76\xa0% pour la langue LAS dans toutes les langues. Enfin, nous occupons la 4ème place sur les sets de test officiels.", 'es': 'Este artículo describe nuestro sistema (HIT-SCIR) para la tarea compartida de CoNll 2017: Análisis multilingüe del texto sin procesar a las dependencias universales. Nuestro sistema incluye tres componentes canalizados: tokenización, etiquetado de parte de voz (POS) y análisis de dependencias. Utilizamos redes de memoria a corto plazo (LSTM) bidireccionales basadas en caracteres tanto para la tokenización como para el etiquetado de PDV. Posteriormente, empleamos un algoritmo basado en transiciones basado en listas para el análisis general no proyectivo y presentamos una arquitectura mejorada basada en Stack-LSTM para representar cada estado de transición y hacer predicciones. Además, para analizar lenguajes de recursos bajos o nulos y datos entre dominios, utilizamos un enfoque de transferencia de modelos para hacer un uso eficaz de los recursos existentes. Demostramos ganancias sustanciales en comparación con la línea de base UDPipe, con una mejora promedio del 3,76% en LAS de todos los idiomas. Y, por último, ocupamos el cuarto lugar en las pruebas oficiales.', 'ja': '本稿では、CoNLL 2017の共有タスク「Raw TextからUniversal Dependenciesへの多言語構文解析」のためのシステム（ HIT - SCIR ）について説明します。当社のシステムには、3つのパイプライン化されたコンポーネントが含まれています。トークン化、音声パート（ POS ）タグ付け、依存関係解析です。文字ベースの双方向長期メモリ（ LSTM ）ネットワークを使用して、トークン化とPOSタグ付けの両方を行います。その後、一般的な非投機的解析のためにリストベースの遷移ベースのアルゴリズムを採用し、各遷移状態を表し、予測を行うための改良されたスタック- LSTMベースのアーキテクチャを提示する。さらに、低/ゼロリソース言語とクロスドメインデータを解析するには、モデル転送アプローチを使用して、既存のリソースを有効に活用します。私たちは、すべての言語のLASで平均3.76 ％の改善があり、UDPipeベースラインに対して大幅な改善を示しています。そして最後に、公式テストセットの4位にランクインします。', 'zh': '本文言CoNLL 2017共享之统(HIT-SCIR):自始文本至通用者多言解析。 凡三管道组件:曰标记化,曰词性 (POS) 曰凭解析。 余以字符双向长短期记(LSTM)网络为记POS。 其后列表非投影解析,更进Stack-LSTM架构,示转换而占之。 解析卑/零,言语跨域数,用模传输法,以效见资。 比之UDPipe基线,我得实质性益,于诸语言LAS中均增3.76%。 最后官方试集排名第4位。', 'hi': 'यह पेपर CoNLL 2017 साझा कार्य के लिए हमारे सिस्टम (HIT-SCIR) का वर्णन करता है: रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग। हमारे सिस्टम में तीन पाइपलाइन घटक शामिल हैं: टोकनीकरण, पार्ट-ऑफ-स्पीच (पीओएस) टैगिंग और निर्भरता पार्सिंग। हम टोकनाइजेशन और पीओएस टैगिंग दोनों के लिए चरित्र-आधारित द्विदिश दीर्घकालिक दीर्घकालिक मेमोरी (एलएसटीएम) नेटवर्क का उपयोग करते हैं। इसके बाद, हम सामान्य गैर-प्रोजेक्टिव पार्सिंग के लिए एक सूची-आधारित संक्रमण-आधारित एल्गोरिथ्म को नियोजित करते हैं और प्रत्येक संक्रमण राज्य का प्रतिनिधित्व करने और भविष्यवाणियां करने के लिए एक बेहतर स्टैक-एलएसटीएम-आधारित वास्तुकला प्रस्तुत करते हैं। इसके अलावा, कम / शून्य-संसाधन भाषाओं और क्रॉस-डोमेन डेटा को पार्स करने के लिए, हम मौजूदा संसाधनों का प्रभावी उपयोग करने के लिए एक मॉडल हस्तांतरण दृष्टिकोण का उपयोग करते हैं। हम UDPipe बेसलाइन के खिलाफ पर्याप्त लाभ प्रदर्शित करते हैं, सभी भाषाओं के एलएएस में 3.76% के औसत सुधार के साथ। और अंत में, हम आधिकारिक परीक्षण सेट पर 4 वें स्थान पर हैं।', 'ru': 'В этой статье описывается наша система (HIT-SCIR) для совместной задачи CoNLL 2017: многоязычный парсинг от необработанного текста к универсальным зависимостям. Наша система включает в себя три конвейерных компонента: токенизацию, тегирование части речи (POS) и синтаксический анализ зависимостей. Мы используем двунаправленные сети длинной кратковременной памяти (LSTM) на основе символов как для токенизации, так и для маркировки POS. Затем мы используем основанный на списке алгоритм перехода для общего непроективного синтаксического анализа и представляем улучшенную архитектуру на основе стека-LSTM для представления каждого переходного состояния и составления прогнозов. Кроме того, для анализа языков с низкими/нулевыми ресурсами и междоменных данных мы используем модельный подход к передаче для эффективного использования существующих ресурсов. Мы демонстрируем существенный рост по сравнению с базовым уровнем UDPipe, со средним улучшением на 3,76% в LAS всех языков. И, наконец, мы занимаем 4-е место на официальных тестовых сетах.', 'ga': 'Déanann an páipéar seo cur síos ar ár gcóras (HIT-SCIR) do thasc roinnte CoNLL 2017: Parsáil Ilteangach ó Théacs Raw go Spleáchas Uilíoch. Cuimsíonn ár gcóras trí chomhpháirt píblíne: tokenization, clibeáil Cuid-de-Urlabhra (POS) agus parsáil spleáchais. Bainimid úsáid as líonraí déthreoracha cuimhne gearrthéarmacha (LSTM) atá bunaithe ar charachtair le haghaidh comharthaíochta agus clibeáil POS. Ina dhiaidh sin, bainimid úsáid as algartam trasdul-bhunaithe liosta-bhunaithe le haghaidh parsáil ghinearálta neamhtheilgeanach agus cuirimid i láthair ailtireacht fheabhsaithe atá bunaithe ar Stack-LSTM chun ionadaíocht a dhéanamh ar gach stát trasdula agus chun tuar a dhéanamh. Ina theannta sin, chun teangacha íseal-acmhainne/nialasacha agus sonraí tras-fearainn a pharsáil, úsáidimid cur chuige aistrithe eiseamláireach chun úsáid éifeachtach a bhaint as acmhainní atá ann cheana féin. Léirímid gnóthachain shuntasacha i gcoinne bhunlíne na Píopaí UDP, le feabhas meánach de 3.76% i LAS na dteangacha go léir. Agus ar deireadh, déanaimid an 4ú háit ar na tacair tástála oifigiúla.', 'hu': 'Ez a tanulmány bemutatja a CoNLL 2017 megosztott feladatának rendszerét (HIT-SCIR): Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig. Rendszerünk három csővezetékes összetevőt tartalmaz: tokenizálás, beszédrész (POS) címkézés és függőség elemzés. Karakteralapú kétirányú hosszú rövid távú memória (LSTM) hálózatokat használunk tokenizáláshoz és POS címkézéshez. Ezt követően lista alapú átmeneti algoritmust alkalmazunk az általános nem projektív elemzéshez, és bemutatunk egy továbbfejlesztett Stack-LSTM alapú architektúrát az egyes átmeneti állapotok megjelenítéséhez és előrejelzésekhez. Továbbá az alacsony/nulla erőforrásokat tartalmazó nyelvek és a domain közötti adatok elemzéséhez modellátviteli megközelítést alkalmazunk a meglévő erőforrások hatékony kihasználására. Jelentős előnyöket mutatunk az UDPipe alapjához képest, átlagosan 3,76%-os javulással az összes nyelv LAS-jében. És végül a negyedik helyet rangsoroljuk a hivatalos tesztkészleteken.', 'ka': 'ამ დოკუმენტი ჩვენი სისტემის (HIT-SCIR) შესახებ CoNLL 2017-ის გაყოფილი დავალებისთვის: მრავალენგური პარამეტრების შესახებ შესახებ მნიშვნელოვანი ტექსტიდან უნივერსურ ჩვენი სისტემა აქვს სამი გარგებული კომპონენტები: ტოკენიზაცია, სიტყვის ნაწილი (POS) ჭდეები და დასარგებელობის პარაზაცია. ჩვენ გამოიყენებთ სიმბოლოების ბიდერექციონის ძირითადი სიმბოლოების (LSTM) ქსელების ტოკენიზაციის და POS-ის ჭდეებისთვის. შემდეგ ჩვენ ჩვენ სიტყვების გარეშე გარეშე ალგორიტიმ, რომელიც არ არის პროექტიური პარაქტირებისთვის და გამოსახულებული Stack-LSTM-ის გარეშე აქტიქტირება, რომელიც ყოველ გარეშე სტრაქტირების და გარე დამატებით, მარტივი/ნულ-რესურსის ენაზები და კრესომინის მონაცემები გავამყენებთ მოდელური გადატანსტრების პროგრამის გამოყენება, რომ მსგავსი რესურ ჩვენ ევმონსტრაცით ძალიან გავიღება UDPipe-ის ფესური ხაზი, საშუალოდ 3.76% უფრო მეტი ყველა ენების LAS-ში. თ ნაი-კპაწ, ჩვენ პანეზთპამვ 4-ჲრჲ მწჟრჲ ნა ჲტთუთალნთრვ რვჟრთ.', 'el': 'Η παρούσα εργασία περιγράφει το σύστημά μας (HIT-SCIR) για την κοινή εργασία του προγράμματος: Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Το σύστημά μας περιλαμβάνει τρία συστατικά: επισήμανση, επισήμανση μέρους ομιλίας και ανάλυση εξάρτησης. Χρησιμοποιούμε δίκτυα μακροχρόνιας βραχυπρόθεσμης μνήμης με βάση χαρακτήρες, τόσο για την επισήμανση όσο και για την επισήμανση. Στη συνέχεια, χρησιμοποιούμε έναν αλγόριθμο μετάβασης βασισμένο στη λίστα για γενική μη προβολική ανάλυση και παρουσιάζουμε μια βελτιωμένη αρχιτεκτονική βασισμένη στη στοίβα για την αναπαράσταση κάθε κατάστασης μετάβασης και την πραγματοποίηση προβλέψεων. Επιπλέον, για την ανάλυση γλωσσών χαμηλού/μηδενικού πόρου και δεδομένων μεταξύ τομέων, χρησιμοποιούμε μια πρότυπη προσέγγιση μεταφοράς για να κάνουμε αποτελεσματική χρήση των υφιστάμενων πόρων. Αποδεικνύουμε σημαντικά κέρδη έναντι της βάσης με μέση βελτίωση 3,76% σε όλες τις γλώσσες. Και τέλος, κατατάσσουμε την 4η θέση στα επίσημα σετ δοκιμών.', 'it': "Questo articolo descrive il nostro sistema (HIT-SCIR) per il compito condiviso CoNLL 2017: Analisi multilingue dal testo grezzo alle dipendenze universali. Il nostro sistema include tre componenti pipelined: tokenizzazione, tag Part-of-Speech (POS) e analisi delle dipendenze. Utilizziamo reti bidirezionali a lungo termine (LSTM) basate sui caratteri sia per la tokenizzazione che per il tagging POS. Successivamente, utilizziamo un algoritmo di transizione basato su liste per l'analisi generale non proiettiva e presentiamo un'architettura migliorata basata su Stack-LSTM per rappresentare ogni stato di transizione e fare previsioni. Inoltre, per analizzare linguaggi a basso/zero risorse e dati cross-domain, utilizziamo un approccio di trasferimento modello per utilizzare efficacemente le risorse esistenti. Abbiamo dimostrato notevoli guadagni rispetto alla base UDPipe, con un miglioramento medio del 3,76% in LAS di tutte le lingue. E infine, ci classifichiamo al quarto posto nei test ufficiali.", 'kk': 'Бұл қағаз CoNLL 2017 жылы ортақ тапсырманың жүйемізді (HIT- SCIR) анықтайды: Қара мәтіннен көп тілді талдау әлемдік тәуелдіктеріне. Біздің жүйемізде үш таңбалаған компоненттер бар: токенизация, сөйлеу бөлігі (POS) тегтері мен тәуелдік талдау. Біз таңбаларға негізделген бидиеркционалдық қысқа уақыт жады (LSTM) желілерін қолданамыз токенизациялау мен POS тегтері үшін. Содан кейін, біз тізімде негізделген ауыстыру алгоритмін проективті емес талдау үшін және әрбір ауыстыру күйін көрсету және алгоритмін көрсету үшін Stack-LSTM негізделген архитектураны қолданамыз. Қосымша, жоғары/нөл ресурс тілдерін және бірнеше домен деректерін талдау үшін, бар ресурстарды эффективті пайдалану үшін үлгі тасымалдау қасиетін қолданамыз. Біз UDPipe негізгі сызығына қарсы көп жеттерді көрсетедік, барлық тілдердің LAS-де орташа 3,76% жақсарту арқылы. Соңында, официалдық сынақтардың 4-ші жерін сақтаймыз.', 'lt': 'Šiame dokumente apibūdinama mūsų sistema (HIT-SCIR) bendrai CoNLL 2017 m. užduotims: daugiakalbis analizavimas nuo žaliavinio teksto iki universaliųjų priklausomybių. Mūsų sistemoje yra trys vamzdynų sudedamosios dalys: tokenizacija, kalbos dalies žymėjimas ir priklausomybės analizavimas. Mes naudojame ženklais pagrįstus dvikryptinius ilgalaikio atminties (LSTM) tinklus tokenizacijai ir POS žymėjimui. Vėliau naudojame sąrašu pagrįstą pereinamojo laikotarpio algoritmą bendram nenusprojektyviam analizavimui ir pristatome patobulintą stack-LSTM pagrįstą architektūrą kiekvienai pereinamajai valstybei atstovauti ir prognozuoti. Be to, norint analizuoti mažai išteklių turinčias kalbas ir tarpsritinius duomenis, naudojame modelio perdavimo metodą veiksmingam esamų išteklių panaudojimui. Mes parodome didelę naudą, palyginti su UDPipe pradiniu lygiu, vidutiniškai pagerėjus visų kalbų LAS 3,76 %. Ir galiausiai, mes klasifikuojame ketvirtą vietą oficialiuose bandymų rinkiniuose.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ സിസ്റ്റത്തെ (HIT-SCIR) കോണ്\u200dഎല്\u200d 2017 പങ്കെടുത്ത ജോലിക്ക് വിവരിച്ചുകൊടുക്കുന്നു: റോ ടെക്സ്റ്റില്\u200d നിന് നമ്മുടെ സിസ്റ്റത്തില്\u200d മൂന്നു പൈപ്പെല്ലിന്\u200dറ് ഭാഗങ്ങള്\u200d ഉള്\u200dപ്പെടുന്നു നീണ്ട നീണ്ട മെമ്മറി (LSTM) നെറ്റുകള്\u200d ഉപയോഗിക്കുന്ന അക്ഷരത്തിന്റെ അടിസ്ഥാനത്തിലുള്ള ബിഡര്\u200dട്ടിക്കല്\u200d മെമ്മറിക അതിനുശേഷം, നമ്മള്\u200d ഒരു ലിസ്റ്റില്\u200d അടിസ്ഥാനമായി പ്രോജക്ടീവ് അല്\u200dഗോരിത്മിനുള്ള ലിസ്റ്റ് അടിസ്ഥാനത്തുള്ള ആല്\u200dഗോരിത്മം നിര്\u200dമ്മിക്കുകയും, ഓരോ ട്ര അതിനുശേഷം, നിലവിലുള്ള വിഭവങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനായി ഞങ്ങള്\u200d ഒരു മോഡല്\u200d മാറ്റം ഉപയോഗിക്കുന്നു. യുഡിപിപ്പി ബെസ്ലൈനിനെതിരെ നമ്മള്\u200d വലിയ സമ്പാദ്യങ്ങള്\u200d കാണിക്കുന്നു, എല്ലാ ഭാഷകളിലും 3.76% മെച്ചപ്പെടുത്തുന്നു. അവസാനം, നമ്മള്\u200d ഓഫീസല്\u200d ടെസ്റ്റ് സെറ്റില്\u200d നാലാം സ്ഥലം നിയന്ത്രിക്കുന്നു.', 'ms': 'Kertas ini menggambarkan sistem kami (HIT-SCIR) untuk tugas kongsi CoNLL 2017: Menghurai Berbahasa Dari Teks Raw ke Dependensi Universal. Sistem kami termasuk tiga komponen pipelined: tokenization, Part-of-Speech (POS) tagging dan penghuraian dependensi. Kami menggunakan rangkaian memori jangka pendek berdasarkan aksara bidireksi (LSTM) untuk tokenization dan tag POS. Afterwards, we employ a list-based transition-based algorithm for general non-projective parsing and present an improved Stack-LSTM-based architecture for representing each transition state and making predictions.  Selain itu, untuk menghurai bahasa sumber rendah/sifar dan data melintasi-domain, kami menggunakan pendekatan pemindahan model untuk membuat penggunaan efektif sumber yang ada. Kami menunjukkan keuntungan yang besar terhadap dasar UDPipe, dengan peningkatan rata-rata 3.76% dalam LAS semua bahasa. Dan akhirnya, kita rank ke-4 di set ujian rasmi.', 'mk': 'Овој весник го опишува нашиот систем (HIT-SCIR) за заедничката задача на CoNLL 2017: Мултијазично анализирање од суров текст до универзални зависности. Нашиот систем вклучува три нафтоводени компоненти: токенизација, означување на дел од говорот (POS) и анализирање на зависноста. Ние користиме дводрекционални, долгорочни мрежи на меморија (LSTM) базирани на карактери за токенизација и POS означување. После тоа, употребуваме алгоритм базиран на листата на транзиција за генерално непроективно анализирање и претставуваме подобрена архитектура базирана на Stack-LSTM за претставување на секоја транзициска држава и правење предвидувања. Покрај тоа, за да ги анализираме јазиците со ниски/нули ресурси и транспортните податоци, користиме моделен пристап на трансфер за ефикасна употреба на постоечките ресурси. Демонстрираме значителни добивки во однос на основата на UDPipe, со просечно подобрување од 3,76 отсто во ЛАС на сите јазици. И конечно, го рангираме четвртото место на официјалните тестови.', 'mt': "Dan id-dokument jiddeskrivi s-sistema tagħna (HIT-SCIR) għall-kompitu kondiviż CoNLL 2017: Parsing Multilingual from Raw Text to Universal Dependencies. Is-sistema tagħna tinkludi tliet komponenti fil-pajpijiet: it-tokenizzazzjoni, it-tikkettar tal-Parti tal-Kellem (POS) u l-analiżi tad-dipendenza. Aħna nużaw netwerks bidirezzjonali ta’ memorja fuq medda qasira ta’ żmien ibbażati fuq il-karattri (LSTM) kemm għat-tokenizzazzjoni kif ukoll għat-tikkettar POS. Wara dan, a ħna nużaw algoritmu bbażat fuq il-list a ta’ tranżizzjoni għall-analiżi ġenerali mhux proġettiva u nippreżentaw arkitettura mtejba bbażata fuq Stack-LSTM biex nirrappreżentaw kull stat ta’ tranżizzjoni u nagħmlu previżjonijiet. Furthermore, to parse low/zero-resource languages and cross-domain data, we use a model transfer approach to make effective use of existing resources.  Aħna nuru kisbiet sostanzjali kontra l-linja bażi tal-UDPipe, b’titjib medju ta’ 3.76% fil-LAS tal-lingwi kollha. U fl-aħħar nett, aħna nqabbdu r-raba' post fis-settijiet uffiċjali tat-testijiet.", 'pl': 'Niniejszy artykuł opisuje nasz system (HIT-SCIR) dla wspólnego zadania CoNLL 2017: Wielojęzyczne Parsowanie z tekstu surowego do zależności uniwersalnych. Nasz system składa się z trzech komponentów: tokenizacji, tagowania części mowy (POS) i parsowania zależności. Do tokenizacji i tagowania POS wykorzystujemy znakowe sieci dwukierunkowej pamięci krótkoterminowej (LSTM) oparte na znakach. Następnie wykorzystujemy algorytm oparty na liście przejść do ogólnego parsowania nieprojektywnego i przedstawiamy ulepszoną architekturę opartą na Stack-LSTM do reprezentowania każdego stanu przejścia i prognozowania. Ponadto, aby analizować języki niskiego/zerowego zasobu oraz dane między domenami, stosujemy modelowe podejście transferowe w celu efektywnego wykorzystania istniejących zasobów. Wykazujemy znaczące zyski w stosunku do bazy danych UDPipe, ze średnią poprawą 3,76% w LAS we wszystkich językach. I wreszcie zajmujemy czwartą pozycję w oficjalnych zestawach testowych.', 'mn': 'Энэ цаас бидний системийг (HIT-SCIR) 2017 оны CoNLL-ийн хуваалцааны ажлын тухай тайлбарладаг: Raw Text-ээс олон хэлний шинжилгээ дэлхийн хамааралтай байдаг. Бидний систем гурван хоолойн шулууны компонент: тодорхойлолт, ярианы хэсэг, хамааралтай хуваалцалт. Бид харилцааны үндсэн хоёр дахин богино хугацааны санамж (LSTM) хоёуланг хоёуланг болон POS тэмдэглэх хоёуланг ашигладаг. Дараа нь бид нийтийн проектив бус ажиллах алгоритмыг жагсаалт дээр суурилсан шилжилт дээр суурилсан алгоритмыг ашиглаж, шилжилт байдал бүрийг харуулж, таамаглах үед Stack-LSTM дээр суурилсан архитектурыг ашиглаж байна. Дараа нь, бага/0-нөөц хэл болон хязгаарлагдсан мэдээллийг хуваалцахын тулд бид суурилсан нөөц бүтээгдэхүүний үр дүнтэй хэрэглэх үед загварын шилжүүлэх арга загварыг ашигладаг. Бид UDPipe суурь шугамын эсрэг маш чухал ялгааг үзүүлдэг. Энэ нь бүх хэлний LAS-д дундаж 3.76% улам сайжруулсан. Эцэст нь бид ерөнхийлөгчийн туршилтын 4-р орон дээр байрлаж байна.', 'no': 'Denne papiret beskriver systemet vårt (HIT-SCIR) for delt CoNLL 2017- oppgåve: Multispråk tolking frå Raw Text til Universal Avhengighet. Sistemet vårt inneheld tre pipeline komponentar: tokenisering, del av tale (POS) merking og tolking av avhengighet. Vi brukar teiknbasert bidireksjonal langsiktig minne (LSTM) for både tokenisering og POS-merking. Etter denne, bruker vi ein listebasert overgangsbasert algoritme for generell ikkje-projektiv tolking og presenterer ein forbetra Stack-LSTM-basert arkitektur for å representera kvar overgangsstatus og gjera foregåver. For å tolka låg/null-ressursspråk og cross-domain-data, bruker vi eit modell-overføringslinjen for å gjera effektivt bruk av eksisterande ressursar. Vi demonstrerer stor forståking mot UDPipe-baselinja, med gjennomsnittlig forbedring av 3,76 % i LAS av alle språka. Og til slutt, vi rankerer den fire plassen på den offisielle testsetten.', 'ro': 'Această lucrare descrie sistemul nostru (HIT-SCIR) pentru sarcina comună CoNLL 2017: Parsing multilingv de la text brut la dependențe universale. Sistemul nostru include trei componente pipelined: tokenizare, etichetare Part-of-Speech (POS) și analizarea dependențelor. Folosim rețele bidirecționale de memorie pe termen scurt (LSTM) bazate pe caractere atât pentru tokenizare, cât și pentru etichetarea POS. Ulterior, folosim un algoritm de tranziție bazat pe liste pentru analizarea generală non-proiectivă și prezentăm o arhitectură îmbunătățită bazată pe Stack-LSTM pentru a reprezenta fiecare stare de tranziție și a face previziuni. În plus, pentru analizarea limbajelor cu resurse scăzute/zero și a datelor cross-domeniu, folosim o abordare de transfer model pentru a utiliza eficient resursele existente. Demonstrăm câștiguri substanțiale față de baza UDPipe, cu o îmbunătățire medie de 3,76% în LAS a tuturor limbilor. Și în cele din urmă, am clasat locul 4 în seturile oficiale de testare.', 'so': "Warqaddan waxaa lagu qoraa nidaamka (HIT-SCIR) ee CoNLL 2017 shaqo la qaybiyey: Jardiino luuqadaha badan oo ka soo baxay Raw-SCIR ilaa masruufka caalamiga ah. Systemkanaga waxaa ku jira saddex qeybood oo la xiriiray: calaamad, qeyb ka mid ah luqada (POS) tagging iyo jardiinada ku xiran. Waxaynu isticmaalnaa shabakado ku saleysan xaraf xafiiska waqti dheer (LSTM) oo ku qoran calaamad iyo POS tagging. Markaas kadib waxaynu u shaqaynaynaa algorithm ku saleysan qoraal-ku-qoran oo lagu qoray qoraal-qoraal ah oo a an wax lagu qorayo baaritaanka caadiga ah, waxaana keenaynaa dhismo kordhisan oo ku qoran Stack-LSTM-based si ay u representaan dowlad kasta oo soo wareegsan iyo wax u sii sheegid. Furthermore, si aan u kala soogalno luuqadaha hoos/zero-resource iyo macluumaadka gudaha ah, waxaynu isticmaalnaa qaab qaab u beddelista si aan u isticmaalno faa’iido isticmaalka rasmiga ah. Waxaannu muujinnaa faa'iido badan oo ka gees ah UDPipe-da, waxaana ku qornaa kororsiinta ugu badnaanta 3,76% ee luqadaha LAS oo dhan. And finally, we rank the 4th place on the official test sets.", 'sv': 'Denna uppsats beskriver vårt system (HIT-SCIR) för CoNLL 2017 delade uppgift: Flerspråkig tolkning från råtext till universella beroende. Vårt system innehåller tre pipelinerade komponenter: tokenisering, POS-märkning (Part-of-Speech) och beroendetolkning. Vi använder teckenbaserade dubbelriktade långtidsminnen (LSTM) nätverk för både tokenisering och POS-märkning. Därefter använder vi en listbaserad övergångsbaserad algoritm för allmän icke-projektiv tolkning och presenterar en förbättrad Stack-LSTM-baserad arkitektur för att representera varje övergångstillstånd och göra förutsägelser. För att tolka språk med låg/noll resurs och domänöverskridande data använder vi en modell överföringsmetod för att effektivt utnyttja befintliga resurser. Vi uppvisar betydande vinster jämfört med UDPipes baslinje, med en genomsnittlig förbättring på 3,76% i LAS av alla språk. Och slutligen rankas vi på fjärde plats i de officiella testseten.', 'sr': 'Ovaj papir opisuje naš sistem (HIT-SCIR) za zajednički zadatak CoNLL 2017: Multilingual Parsing from Raw Text to Universal Dependencies. Naš sistem uključuje tri komponenta sa kanalizacijom: tokenizaciju, dijelom govora (POS) oznake i analizu zavisnosti. Koristimo na karakteru dvodirektivne dugoročne memorije (LSTM) mreže za tokenizaciju i označavanje POS-a. Nakon toga, upotrebimo algoritam na spisku baziran na prelaznoj strani za općeg neprojektivnog analiza i predstavljamo poboljšanu arhitekturu na Stack-LSTM-u za predstavljanje svakog prelaznog stanja i predviđanje. Osim toga, za analizu jezika niskih/nulih resursa i podataka preko domena, koristimo model pristup premeštanja kako bi se učinkovito iskoristili postojeće resurse. Pokazujemo značajne dobitke protiv početne linije UDPipe, s prosječnim poboljšanjem od 3,76% u LAS svih jezika. I konačno, postavljamo četvrto mesto na službenim testovima.', 'si': 'මේ පැත්තේ අපේ පද්ධතිය (HIT-SCIR) CoNLL 2017 භාවිත වැඩක් වෙනුවෙන් විස්තර කරනවා: රාව් පාළුවෙන් පාළුවෙන් ජාතික විශේෂ අපේ පද්ධතියේ පායිප්ලින් තුනක් අංකය තියෙනවා: ටොකෙනිස්, භාෂාව (POS) කොටස් ටැග් කරන්න සහ අවශ්\u200dයතාවක් පර අපි අක්ෂර අධිරූපය සහ POS ටැග් කරන්න සඳහා අක්ෂර අධිරූපය ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය කරන්නේ. ඊට පස්සේ, අපි ලැයිස්තු අධාරිත ප්\u200dරවේශනය නොප්\u200dරවේශනය විශ්ලේෂණය සඳහා සාමාන්\u200dය විශ්ලේෂණය සඳහා ස්ටැක්-LSTM-අධාරිත ස්ථාපනය සඳහ ඉතින්, අඩුම/ශූන්ය-සම්පති භාෂාව සහ ක්\u200dරිස්ඩෝමින් දත්ත පරීක්ෂා කරන්න, අපි ප්\u200dරමාණයක් ප්\u200dරමාණයක් භා අපි UDPipe බේස්ලායින් විරුද්ධ විශාල ප්\u200dරදේශයක් පෙන්වන්නම්, සියලු භාෂාවල ලැබීමේ සාමාන්\u200dය විශාලයක් 3. අන්තිමේදි, අපි පරීක්ෂණා සේට් එකේ 4වෙනි ස්ථානයක් තියෙනවා.', 'ta': 'இந்த தாள் எங்கள் அமைப்பை (HIT-SCIR) கோNLL 2017 பகிர்ந்த பணிக்கு விவரிக்கிறது: ரி உரையிலிருந்து பல மொழி பாசிங் உலகளாவிய சார்புகளுக்கு. எங்கள் கணினியில் மூன்று படப்படுத்தப்பட்ட கூறுகள் உள்ளன: குறிப்பு, பேச்சின் பாகம் (POS) ஒட்டுதல் மற்றும் சார்ந்த பாடல். நாங்கள் எழுத்து அடிப்படையிலான பிடிடர் நீண்ட நினைவகம் (LSTM) வலைப்பின்னல்களை பயன்படுத்தி குறிப்பிடுதல் மற்றும் POS ஒ பின்னர், நாம் ஒரு பட்டியலில் அடிப்படையான மாற்றம் அடிப்படையில்லாத பொது திட்டப்பணி இல்லாத பாசிங்குக்கு ஒரு பட்டியலை பயன்படுத்தி ஒவ்வொரு மாற்று நிலையில அதற்கும், குறைந்த/பூஜ்ஜியமான மூலத்தின் மொழிகள் மற்றும் குறைந்த தரவுகளை பிரிக்க, நாம் ஒரு மாதிரி மாற்று வழிமுறையை பயன்படுத UDPipe அடிப்படைக்கு எதிராக பெரிய வாய்ப்புகளை நாம் காட்டுகிறோம், அனைத்து மொழிகளிலும் 3.76% மேம்படுத்தல் 3. மேலும் இறுதியில், நாம் அதிகார சோதனை அமைப்பில் 4வது இடத்தை நிறுத்துகிறோம்.', 'ur': 'This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared task: Multilingual Parsing from Raw Text to Universal Dependencies. ہماری سیسٹم تین پیپ لینڈ رغتوں میں شامل ہے: ٹوکنیزی، بات کی حصہ (POS) ٹاگ اور اعتماد پارسینگ. ہم شخص بنیاد بیڈیریٹریکیشن لنگ مدت مہمانی (LSTM) نیٹورک دونوں ٹوکینس اور POS ٹاگ کے لئے استعمال کرتے ہیں. اس کے بعد، ہم ایک لکھ پر بنیاد تغییر پر بنیاد الگوریتم کو عمومی غیر پروژیکٹی پارسینگ کے لئے استعمال کرتے ہیں اور ہر تغییر وضعیت اور پیش بینی کے لئے استک-LSTM-بنیاد تہجد بناتے ہیں. اور اس کے علاوہ، کم/صفر-سروسیز زبانیں اور کرس-ڈومین ڈاٹ کا پارس کرنے کے لئے، ہم موجود موجود سروسیلوں کے مطابق استعمال کرنے کے لئے ایک مدل ترنسفور طریقہ استعمال کرتے ہیں. ہم نے UDPipe baseline کے مقابلہ میں بہت بڑے فائدہ دکھائے ہیں، ہر زبان کے لاس میں 3.76% کا متوسط improvement ہے. اور بالآخر، ہم چوتھا جگہ رسمی امتحان سٹوں پر رکھتے ہیں.', 'uz': "Бу саҳифа CONLL 2017 тақдим қилинган вазифаси учун системамизни (HIT-SCIR) айтиб беради: Ray матдан кўп тил парламент умумий параметрлариш. Bizning tizimimizda uchta qoʻllangan komponentlar bor: tokenization, speech qismlari qismlari (POS) tagging and dependency parsing. @ info: whatsthis Keyin biz roʻyxat asosida o'zgarishlar asosiy tarkibi algorithini ishlayapmiz va har bir vazifa davlatni tashkilotga ko'rsatish uchun Stack-LSTM asosida bajariladigan arxituvni ishga tushunamiz. Koʻrsatganda, biz mavjud rasmlarni ishlatish uchun model transfer usulini foydalanamiz. Biz UDPip asosiy tarkibini ko'rsatganmiz, hamma tillardan 3.76% o'zgarishni ko'rsatdik. Va oxirida, biz tashqari sinov sohasida 4 chi joyni boshqaramiz.", 'vi': 'Tờ giấy này mô tả hệ thống (HIT-SCLAR) của chúng ta cho nhiệm vụ chia sẻ CONLEL 137: Phát triển ngôn ngữ từ văn bản thô đến các cấp chung. Hệ thống của chúng tôi bao gồm ba thành phần đường ống: hiệu ứng, cách phát âm và phân tích độ lệ thuộc. Chúng tôi dùng mạng bộ nhớ ngắn hạn theo tính riêng (LSTM) cho cả hiệu ứng và kết xuất. Sau đó, chúng tôi sử dụng một thuật toán dựa trên danh sách cho phân tích tổng thể không có dự đoán và trình bày một kiến trúc "Stacks-LSTM" cải tiến để đại diện mỗi trạng thái chuyển tiếp và tiên đoán. Hơn nữa, để phân tích ngôn ngữ ít nguồn không và dữ liệu xuyên lục địa, chúng tôi sử dụng phương pháp chuyển nhượng mẫu để sử dụng tài nguyên hiện thời. Chúng tôi sử thấy được sự giải tăng lớn so với bộ một sự tổ nghiệp UDPipe, với một cách tổng trung của 3.chợ trong tất cả cả ngôn ngữ hội. Và cuối cùng, chúng tôi xếp hạng quốc khánh trong các bộ thử nghiệm chính thức.', 'bg': 'Тази статия описва нашата система (ХИТ-СКИР) за споделената задача на КоНЛ 2017: Многоезично анализиране от суров текст до универсални зависимости. Нашата система включва три тръбопроводи компонента: токенизация, маркиране на част от речта (ПОС) и анализ на зависимости. Използваме двупосочни мрежи за краткосрочна памет (ЛСТМ) както за токенизация, така и за маркиране на ПОС. След това използваме алгоритъм базиран на списък преход за общо непроективно анализиране и представяме подобрена архитектура базирана на стак за представяне на всяко състояние на преход и правене на прогнози. Освен това, за да анализираме езици с нисък/нулев ресурс и данни от междудомейни, използваме подход за трансфер на модели, за да използваме ефективно съществуващите ресурси. Ние демонстрираме значителни печалби спрямо базовата база, със средно подобрение от 3,76% в ЛАС на всички езици. И накрая, класираме се на 4-то място в официалните тестови комплекти.', 'nl': 'Dit artikel beschrijft ons systeem (HIT-SCIR) voor de gezamenlijke taak CoNLL 2017: Meertalig Parsen van ruwe tekst naar universele afhankelijkheden. Ons systeem bestaat uit drie pipeline componenten: tokenization, Part-of-Speech (POS) tagging en afhankelijkheidsparsing. We gebruiken karaktergebaseerde bidirectionele long-term memory (LSTM) netwerken voor zowel tokenization als POS tagging. Daarna gebruiken we een lijst-gebaseerd transitie-gebaseerd algoritme voor algemene niet-projectieve parsing en presenteren we een verbeterde Stack-LSTM-gebaseerde architectuur voor het weergeven van elke overgangsstatus en het maken van voorspellingen. Bovendien gebruiken we voor het parsen van low/zero-resource talen en cross-domein data een model transfer aanpak om effectief gebruik te maken van bestaande resources. We tonen aanzienlijke winsten ten opzichte van de UDPipe baseline, met een gemiddelde verbetering van 3,76% in LAS van alle talen. En tot slot rangschikken we de 4e plaats op de officiële testsets.', 'da': 'Denne artikel beskriver vores system (HIT-SCIR) for CoNLL 2017 delte opgave: Flersproget tolkning fra rå tekst til universelle afhængigheder. Vores system omfatter tre pipelinerede komponenter: tokenisering, POS-taggning (Part-of-Speech) og afhængighedsparsing. Vi bruger tegnbaserede to-retningsbaserede langtidshukommelsesnetværk (LSTM) til både tokenisering og POS tagging. Bagefter anvender vi en liste-baseret overgangsbaseret algoritme til generel ikke-projektiv parsing og præsenterer en forbedret Stack-LSTM-baseret arkitektur til at repræsentere hver overgangstilstand og lave forudsigelser. Desuden bruger vi en model overførsel til at analysere lav/nul-ressource sprog og data på tværs af domæner for at gøre effektiv brug af eksisterende ressourcer. Vi demonstrerer betydelige gevinster i forhold til UDPipe baseline, med en gennemsnitlig forbedring på 3,76% i LAS af alle sprog. Og endelig rangerer vi fjerdepladsen på de officielle testsæt.', 'hr': 'Ovaj papir opisuje naš sustav (HIT-SCIR) za zajednički zadatak CoNLL 2017: Multilingual Parsing from Raw Text to Universal Dependencies. Naš sustav uključuje tri komponenta sa cijevima: tokenizacija, dijela govora (POS) označavanje i analizanje ovisnosti. Koristimo dvodirektivne dugoročne sjećanje (LSTM) mreže na karakteru kako za tokenizaciju i označavanje POS-a. Nakon toga, zapošljavamo algoritam baziran na popisu premještaja za opće neprojektivno analiziranje i predstavljamo poboljšanu arhitekturu baziranu na Stack-LSTM-u za predstavljanje svakog prelaznog stanja i predviđanje. Osim toga, za analizu jezika niskih/nulih resursa i podataka o prekršenom domenu, koristimo model pristup prijenosa kako bi se učinkovito iskoristili postojeće resurse. Pokazujemo značajne dobitke protiv početne linije UDPipe, s prosječnim poboljšanjem od 3,76% u LAS svih jezika. I konačno, činimo četvrto mjesto na službenim testovima.', 'de': 'Dieser Beitrag beschreibt unser System (HIT-SCIR) für die gemeinsame Aufgabe CoNLL 2017: Mehrsprachiges Parsen von Rohtext zu Universal Dependencies. Unser System umfasst drei pipelined Komponenten: Tokenisierung, Part-of-Speech (POS)-Tagging und Dependency Parsing. Wir verwenden characterbasierte bidirektionale Long-Term Memory (LSTM)-Netzwerke für Tokenisierung und POS-Tagging. Anschließend verwenden wir einen listenbasierten Übergangs-basierten Algorithmus für das allgemeine nicht-projektive Parsen und präsentieren eine verbesserte Stack-LSTM-basierte Architektur, um jeden Übergangszustand darzustellen und Vorhersagen zu treffen. Um ressourcenarme Sprachen und domänenübergreifende Daten zu analysieren, verwenden wir einen Modelltransfer-Ansatz, um vorhandene Ressourcen effektiv zu nutzen. Wir zeigen deutliche Zuwächse gegenüber der UDPipe Baseline, mit einer durchschnittlichen Verbesserung von 3,76% in LAS aller Sprachen. Und schließlich belegen wir den vierten Platz in den offiziellen Testsets.', 'id': 'Kertas ini menjelaskan sistem kami (HIT-SCIR) untuk tugas kongsi CoNLL 2017: Penganalisan berbagai bahasa dari teks mentah ke Dependensi Universal. Sistem kami termasuk tiga komponen pipa: tokenization, Part-of-Speech (POS) tagging dan penghuraian dependency. Kami menggunakan jaringan memori jangka pendek berdasarkan karakter bidireksi (LSTM) untuk tokenization dan POS tagging. Kemudian, kami menggunakan algoritma berdasarkan daftar-berdasarkan transisi untuk pemeriksaan umum tidak proyektif dan mempersembahkan arsitektur berdasarkan Stack-LSTM yang terbaik untuk mewakili setiap negara transisi dan membuat prediksi. Furthermore, to parse low/zero-resource languages and cross-domain data, we use a model transfer approach to make effective use of existing resources.  Kami menunjukkan keuntungan besar melawan dasar UDPipe, dengan peningkatan rata-rata 3,76% di LAS dari semua bahasa. Dan akhirnya, kami menaiki tempat ke-4 di set tes resmi.', 'ko': '본고는 우리 시스템(HIT-sCIR)이 CoNLL 2017 공유 작업에 사용되는 원시 텍스트부터 일반적인 의존 항목까지의 다중 언어 해석을 기술한다.우리의 시스템은 세 가지 유수선 구성 요소를 포함하는데 그것이 바로 표기화, 어성 표기와 의존성 분석이다.우리는 문자 기반의 양방향 장단시 기억(LSTM) 네트워크를 사용하여 표기화와 단어 표시를 한다.그 다음에 우리는 목록을 바탕으로 하는 전환 알고리즘을 이용하여 일반적인 비투영 분석을 하고 개선된 창고 기반 LSTM의 구조를 제시하여 모든 전환 상태를 표시하고 예측했다.그 밖에 저/제로 자원 언어와 전역 데이터를 분석하기 위해 우리는 모델 전환 방법을 사용하여 기존 자원을 효과적으로 이용한다.UDPipe 베이스라인과 비교할 때 우리는 현저한 발전을 이루었고 모든 언어의 LAS는 평균 3.76% 증가했다.마지막으로 우리는 공식 테스트에서 4위를 차지했다.', 'fa': 'این کاغذ سیستم ما (HIT-SCIR) را برای کار مشترک CoNLL 2017 توصیف می\u200cکند: تحلیل زیادی زبان از متن Raw به بستگی جهانی. سیستم ما شامل سه عنصر از لوله\u200cهای لوله\u200cای است: توکین\u200cسازی، قسمتی از سخن\u200cگویی (POS) تاگ\u200cسازی و پاره\u200cسازی بستگی. ما از شبکه های حافظه کوتاه زمانی (LSTM) بر پایه شخصیت استفاده می کنیم که برای نشان شناسایی و نقاشی POS. بعد از آن، ما الگوریتم بر اساس تغییرات بر اساس لیست استفاده می کنیم برای پردازش غیر پروژه\u200cای عمومی و یک معماری بر اساس Stack-LSTM بهتر برای نمایش هر وضعیت تغییر و پیش\u200cبینی\u200cها را نشان می\u200cدهیم. علاوه بر این، برای تجزیه زبانهای کم/صفر منبع و داده های مختلف دامنه، از طریق انتقال مدل استفاده می کنیم تا از منابع موجود استفاده کنیم. ما در مقابل خط پایین UDPipe پیروزی بسیار زیادی را نشان می دهیم، با توسعه متوسط ۳.76% در LAS از همه زبانها. و بالاخره، ما چهارمین جایی را در مجموعه آزمایش رسمی قرار می دهیم.', 'tr': 'Bu käze biziň sistemimizi (HIT-SCIR) CoNLL 2017-nji ýylda paylaşdyrylýan zady üçin tassyýar: Ýagdaş Metinden Wagtlaýyn Metinden Halkara baglanyşlara çevrilýär. Biziň sistemimiz üç pipeline komponentleri: tokenizacija, sözleýän bir parça (POS) taglama we baglançylyk parslama dahil edýär. Karakter daýry edilen ýerleşmeler üçin elimizde tertiblemek üçin köçü tertiblemek üçin ullanýarys Sonra, biz list tabanly geçiş algoritmini projektiv ýok ählisini gözlemek üçin ullanýarys we her geçiş durumyny täze etmek üçin Stack-LSTM tabanly bir arhitektura gurlýarys. Munuň üçin, düşük/nul-resurs dillerini we çoklu domeny maglumatlaryny analyz etmek üçin, bar resurslaryň etkinleşen ulanmagy üçin bir nusga terjime metodyny ullanýarys. UDPipe baseline garşynda örän uly gazançlygy görkeýäris, LAS dillerinde ortalama 3.76% gelişmeleri bar. Soňunda resmi testiň düzeninde 4-nji ornymyzy paýlaşýarys.', 'af': "Hierdie papier beskryf ons stelsel (HIT-SCIR) vir die CoNLL 2017 gedeelde taak: veelvuldige verwerking van Raw Teks tot Universele afhanklikhede. Ons stelsel inkluit drie pipelineerde komponente: tokenisasie, Deel van spraak (POS) etiket en afhanklikheidverwerking. Ons gebruik karaktergebaseerde bidireksjonale lang- term geheue (LSTM) netwerke vir beide tokenisasie en POS merking. Daarna gebruik ons 'n lys-gebaseerde transisie-gebaseerde algoritme vir algemeen nie-projektiewe verwerking en voorsien 'n verbeterde Stack-LSTM-gebaseerde arkitektuur vir verteenwoordiging van elke transisie-staat en voorskoue. Ons gebruik ook 'n model oordrag toegang om effektief gebruik van bestaande hulpbronne te maak om lae/nul-hulpbronne tale en kruisdomein-data te verwerk. Ons vertoon substantiele verkrywings teen die UDPipe baselyn, met 'n gemiddelde verbetering van 3.76% in LAS van alle tale. En eindelik, ons rank die 4de plek op die offisiele toets stel.", 'sq': 'Ky dokument përshkruan sistemin tonë (HIT-SCIR) për detyrën e përbashkët të CoNLL 2017: analizimin shumëgjuhës nga teksti i papërdorur në varësitë universale. Sistemi ynë përfshin tre komponente të tubuara: tokenization, Part-of-Speech (POS) tagging dhe analizimin e varësisë. Ne përdorim rrjete të kujtesës së afatit të shkurtër (LSTM) bazuar në karakter për tokenizim dhe POS tagging. Pas kësaj, ne përdorim një algoritëm bazuar në list ë për analizimin e përgjithshëm jo-projektiv dhe paraqesim një arkitekturë të përmirësuar bazuar në Stack-LSTM për përfaqësimin e çdo shteti të tranzicionit dhe duke bërë parashikime. Përveç kësaj, për të analizuar gjuhët e ulëta/zero-burimeve dhe të dhënat ndër-domeni, ne përdorim një metodë modeli transferimi për të bërë përdorim efektiv të burimeve ekzistuese. Ne demonstrojmë fitime thelbësore kundër bazës së UDPipe, me një përmirësim mesatar prej 3.76% në LAS të të gjitha gjuhëve. Dhe më në fund, ne rendisim vendin e katërt në grupet zyrtare të testit.', 'sw': 'Gazeti hili linaelezea mfumo wetu (HIT-SCIR) kwa ajili ya kazi ya CoNLL 2017 ilisambazwa: Uchapishaji wa lugha mbalimbali kutoka Maandishi ya Raw hadi Uingereza. Mfumo wetu unajumuisha vifaa vitatu vinavyotumiwa: alama, sehemu ya mazungumzo (POS) na wimbo wa kutegemea. Tunatumia mitandao ya kumbukumbu ya muda mfupi (LSTM) yenye msingi wa wahusika kwa ajili ya kuonyesha alama na alama za POS. Baada ya hayo, tunatumia algorithi yenye msingi wa mpito wa orodha kwa ajili ya uchimbaji mkuu usio na mradi na kuweka ujenzi mzuri wa msingi wa Stack-LSTM kwa kuwakilisha kila nchi ya mpito na kufanya utabiri. Zaidi ya hayo, kuendeleza lugha za chini/rasilimali sifuri na data za ndani, tunatumia mbinu za usafirishaji wa model ili kutengeneza matumizi ya rasilimali zilizopo tayari. Tunaonyesha mafanikio makubwa dhidi ya msingi wa UDPipe, kwa kiwango cha kuongezeka kwa asilimia 3.76 katika lugha zote za LAS. Na hatimaye, tuna nafasi ya nne kwenye seti rasmi ya jaribio.', 'am': 'ይህ ገጽ ድምፅን (HIT-SCIR) ለኮንஎல_2017የተለየ ስራ ይናገራል፤ ከRaw ጽሑፍ ወደ ዓለማዊ ድጋፍ የቋንቋ ማዘጋጀት ነው፡፡ Our system includes three pipelined components: tokenization, Part-of-Speech (POS) tagging and dependency parsing.  የአሁኑን ቦታ እና የPOS ማተሚያ ለመጠቀም የረጅም የአሁኑን ዘመን ማስታወሻ (LSTM) መረብ ተጠቀምን፡፡ ከዚህም በኋላ የፕሮጀክት አካባቢ ሳይሆን ማኅበረሰብ ላይ የተመሳሳይን የዝርዝር መሠረት እናደርጋለን፡፡ ከዚህም በላይ የዝናብ/zero-resource ቋንቋዎች እና የዶሜን ዳታ ለመለጠፍ እና የአሁኑን ሀብት ለመጠቀም የሞዴል መተላለፊያ ሥርዓት እናስቀምጣለን፡፡ በUDPip መደገፊያው ላይ የበረታዊ ጥቅም እናሳየዋለን፡፡ በቋንቋዎች ሁሉ ላይ 3.76 በመቶ የበለጠ ጥቅም እናደርጋለን፡፡ በመጨረሻም ባለሥልጣናት ፈተናዎች ላይ 4ተኛውን ስፍራ እናደርጋለን፡፡', 'bn': 'এই পত্রিকা আমাদের সিস্টেম (এইট-এসসিআর) কনএল ২০১৭ শেয়ার কর্মসূচির জন্য বর্ণনা করেছে: রো টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করা  আমাদের সিস্টেমের মধ্যে তিনটি পাইপেলিং অংশ রয়েছে: প্রতিবেদন, অফ-ভাষার অংশ (পোএস) ট্যাগিং এবং নির্ভরশীল পার্জিং। আমরা অক্ষরের ভিত্তিক বৈদীর্ঘ মেমোরি (LSTM) নেটওয়ার্ক ব্যবহার করি অঙ্গীকার এবং পোস ট্যাগিং উভয়ের জন্য। এর পরে আমরা একটি তালিকা ভিত্তিক ক্ষেত্রে প্রতিটি ট্রান্সফ্রেন্স রাষ্ট্রের প্রতিনিধিত্বের প্রতিনিধি এবং ভবিষ্যতের প্রতিনিধিত্ব করার জন্য একটি উন্নত স্ এছাড়াও, নিম্ন/শূন্য-সম্পদ ভাষা এবং ক্রাস্ড ডোমেইন ডাটা পার্স করার জন্য, আমরা বিদ্যমান সম্পদের কার্যকর ব্যবহারের জন্য একটি মডেল পরি আমরা উডিপিপি বেসাইনের বিরুদ্ধে গুরুত্বপূর্ণ অর্জন প্রদর্শন করি, যেখানে সকল ভাষায় ৩. এবং অবশেষে, আমরা অফিসিয়াল পরীক্ষা সেটে ৪ তম স্থানের স্থান নির্ধারণ করি।', 'az': "Bu kağıt bizim sistemimizi (HIT-SCIR) CoNLL 2017 paylaşılan işləri ilə tanıyır: Səfər Metindən Universel Bağlamlıqlara çoxlu dil analizi. Sistemimiz üç pipeline komponenti: tokenizasyon, sözlərin bir parçası (POS) etiketi və bağlılıq ayırması barəsindədir. Biz Karakter-tabanlı ikidiktiv uzun-müddət hafıza (LSTM) ağlarını da tokenizaq və POS etiketləri üçün istifadə edirik. Sonra, hər dəyişiklik durumunu və tədbirləri göstərmək üçün Stack-LSTM tabanlı bir dəyişiklik tabanlı dəyişiklik algoritmi istifadə edirik. Daha sonra, düşük/sıfır-ressurs dillərini və çox-domen məlumatlarını ayırmaq üçün, mövcud resursların istifadəsini etmək üçün modeli təkrar metodlarını istifadə edirik. UDPipe baseline qarşısında böyük qənimətlər göstəririk, bütün dillərin LAS'də ortalama 3.76%-ini artırmaq üçün. Sonunda, resmi sınama qurularında dördüncü yerə səf veririk.", 'hy': 'Այս հոդվածը նկարագրում է մեր համակարգը (ՀԻT-ՍՔԻՌ) 2017-ի ԿոնԼԼ հանրային հանձնարարության համար՝ բազմալեզու վերլուծությունը՝ Մար տեքստից մինչև համաշխարհային կախվածություններ: Մեր համակարգը ներառում է երեք խողովակաշար բաղադրիչներ՝ տոկենիզացիա, խոսքի մասի (POS) նշաններ և կախվածության վերլուծություն: Մենք օգտագործում ենք բնավորության հիմնված երկու ուղղությամբ երկարաժամկետ հիշողության (LSMT) ցանցեր, ինչպես թոկենիզացիայի, ինչպես նաև POS-ի նշանների համար: Հետո մենք օգտագործում ենք ցուցակի հիմնված հաղորդակցման ալգորիթմ ընդհանուր ոչ պրոեկտիվ վերլուծության համար և ներկայացնում ենք բարելավված Stack-LSMT հիմնված ճարտարապետություն յուրաքանչյուր հաղորդակցման վիճակի ներկայացման և կանխատեսման համար: Ավելին, որպեսզի վերլուծենք ցածր և զրոյից ռեսուրսներ ունեցող լեզուները և միջբնագավառի տվյալները, մենք օգտագործում ենք մոդելների փոխանցման մոտեցում գոյություն ունեցող ռեսուրսների արդյունավետ օգտա Մենք ցույց ենք տալիս, որ UDPipe-ի սկզբնական համեմատությունը նշանակալի զարգացում է, որի միջին զարգացումը 3.76 տոկոսով է LAS-ում բոլոր լեզուներում: Եվ վերջապես, մենք դասավորում ենք 4-րդ տեղը պաշտոնական փորձարկումների համակարգերի վրա:', 'ca': "Aquest article descriu el nostre sistema (HIT-SCIR) per a la tasca compartida CoNLL 2017: Analització multilingüe del text brut a Dependencies Universals. El nostre sistema inclou tres components acoplats: la fitogenització, l'etiquetatge part-of-speech (POS) i l'analització de la dependencia. Utilitzem xarxes bidireccionals de memòria a curt termini basades en caràcters (LSTM) tant per a l'etiquetage de tokenization com POS. Després, utilitzem un algoritme basat en la llista de transició per a l'analització general no projeccional i presentem una arquitectura millorada basada en Stack-LSTM per representar cada estat de transició i fer prediccions. A més, per analitzar les llengües amb recursos baixos o zero i les dades transdomíniques, fem servir un enfocament de transfer ència model per utilitzar eficaçment els recursos existents. We demonstrate substantial gains against the UDPipe baseline, with an average improvement of 3.76% in LAS of all languages.  I finalment, classifiquem el quart lloc en els grups oficials.", 'et': 'Käesolevas artiklis kirjeldatakse meie süsteemi (HIT-SCIR) CoNLL 2017 jagatud ülesande jaoks: mitmekeelne parsimine toortekstist universaalsete sõltuvusteni. Meie süsteem sisaldab kolme torujuhtmega komponendit: tokeniseerimine, kõneosa (POS) sildistamine ja sõltuvuse parsimine. Kasutame märgipõhiseid kahesuunalisi pikaajalisi lühiajalisi mälu (LSTM) võrke nii tokeniseerimiseks kui ka POSi sildistamiseks. Seejärel kasutame loendipõhist üleminekupõhist algoritmi üldiseks mitteprojektiivseks parsimiseks ja esitame täiustatud Stack-LSTM-põhist arhitektuuri iga ülemineku oleku esindamiseks ja prognooside tegemiseks. Lisaks kasutame olemasolevate ressursside tõhusaks kasutamiseks madala ressursiga keelte ja valdkondadevaheliste andmete parsimiseks mudeli edastamise lähenemisviisi. Näitame märkimisväärset kasu võrreldes UDPipe algtasemega, keskmiselt paranes LAS kõigis keeltes 3,76%. Ja lõpuks oleme ametlikus testikomplektis neljandal kohal.', 'bs': 'Ovaj papir opisuje naš sistem (HIT-SCIR) za zajednički zadatak CoNLL 2017: Multilingual Parsing from Raw Text to Universal Dependencies. Naš sistem uključuje tri komponenta sa cijevima: tokenizacija, dijela govora (POS) oznake i analiza ovisnosti. Koristimo dvodirektivne dugoročne sjećanje (LSTM) mreže na karakteru za tokenizaciju i označavanje POS-a. Nakon toga, zapošljavamo algoritam baziran na popisu na prelaznoj strani za općeg neprojektivnog analiza i predstavljamo poboljšanu arhitekturu baziranu na Stack-LSTM-u za predstavljanje svakog prelaznog stanja i predviđanje. Osim toga, za analizu jezika niskih/nulih resursa i podataka o prekršenom domenu, koristimo model pristup transfer a kako bi se učinkovito iskoristili postojeće resurse. Pokazujemo značajne dobitke protiv početne linije UDPipe, s prosječnim poboljšanjem od 3,76% u LAS svih jezika. I konačno, činimo četvrto mjesto na službenim testovima.', 'fi': 'Tässä artikkelissa kuvataan järjestelmäämme (HIT-SCIR) CoNLL 2017:n yhteiseen tehtävään: monikielinen parsing from Raw Text to Universal Dependences. Järjestelmämme sisältää kolme pipelined komponenttia: tokenisaatio, osa-of-Speech (POS) tagging ja riippuvuuden parsing. Käytämme merkkipohjaisia kaksisuuntaisia pitkän aikavälin muistiverkkoja (LSTM) sekä tokenisointiin että POS-tagaukseen. Tämän jälkeen käytämme listapohjaista siirtymäalgoritmia yleiseen ei-projektiiviseen jäsentämiseen ja esittelemme parannetun Stack-LSTM-pohjaisen arkkitehtuurin kunkin siirtymätilan esittämiseen ja ennusteiden tekemiseen. Lisäksi matalan/nollaresurssin kielien ja toimialueiden välisen datan jäsentämiseksi käytämme mallinsiirtomenetelmää nykyisten resurssien tehokkaaseen hyödyntämiseen. Osoitamme merkittäviä hyötyjä UDPipe-lähtötasoon verrattuna, ja kaikkien kielten LAS-tasossa keskimääräinen parannus on 3,76%. Ja lopuksi, sijoittumme neljänneksi virallisissa testisarjoissa.', 'cs': 'Tento článek popisuje náš systém (HIT-SCIR) pro sdílený úkol CoNLL 2017: Multilingual Parsing from Raw Text to Universal Dependences. Náš systém zahrnuje tři komponenty: tokenizaci, značení části řeči (POS) a analýzu závislostí. Používáme znakové obousměrné sítě dlouhodobé krátkodobé paměti (LSTM) jak pro tokenizaci, tak pro tagování POS. Následně používáme algoritmus založený na přechodu založený na seznamu pro obecné neprojekční analýzu a prezentujeme vylepšenou architekturu založenou na Stack-LSTM pro reprezentaci každého stavu přechodu a provádění predikcí. Kromě toho k analýze jazyků s nízkými/nulovými zdroji a dat mezi různými doménami používáme přístup k modelovému přenosu pro efektivní využití stávajících zdrojů. Prokázali jsme značné zisky oproti základnímu standardu UDPipe, s průměrným zlepšením 3,76% v LAS všech jazycích. A konečně máme čtvrté místo v oficiálních testovacích sadách.', 'sk': 'Ta prispevek opisuje naš sistem (HIT-SCIR) za skupno nalogo CoNLL 2017: večjezično razčlenjevanje iz surovega besedila v univerzalne odvisnosti. Naš sistem vključuje tri cevovodne komponente: žetonizacijo, označevanje delov govora (POS) in razčlenitev odvisnosti. Za žetonizacijo in označevanje POS uporabljamo dvosmerna dolgoročna kratkoročna pomnilniška omrežja (LSTM), ki temeljijo na znakih. Nato uporabimo algoritem, ki temelji na prehodu na seznamu, za splošno neprojektivno razčlenitev in predstavimo izboljšano arhitekturo, ki temelji na Stack-LSTM, za predstavitev vsakega stanja prehoda in izdelavo napovedi. Poleg tega za razčlenitev jezikov z nizkimi/ničelnimi viri in meddomenskih podatkov uporabljamo model transfer pristop za učinkovito uporabo obstoječih virov. Dokazujemo znatne dobičke v primerjavi z osnovno vrednostjo UDPipe, s povprečnim izboljšanjem LAS za 3,76% vseh jezikov. Na koncu smo uvrstili 4. mesto v uradnih testnih nizih.', 'ha': "Wannan karatun yana bayyana na'urarmu (HT-SCIR) wa shirin aikin CoNLL 2017 @ info: whatsthis @ label Afiraya, za mu aiki algoritm wanda aka bingeda a list-based wa mai parse ga jama'a na-wata-projeative kuma munã gabatar da wani gyare-asanin Stack-LSSM dõmin ya wakilisha duk halin transiti da ke aikata bayani. Furan, dõmin a yin parse ga lugha masu ƙasƙanci/sifire-resource da data masu tsohon-Domen, za mu yi amfani da kwamfyuta misalin motsi dõmin ya yi amfani da amfani da masu buƙata. Muna nuna kashi mai girma a kangaran Udepipe, da an ƙara tsakanin kodi na 3,76% cikin LS duk harshe. Na ƙarshe, za'a danganta na huɗu a kan matsayin jarrabai rasmi.", 'he': "העיתון הזה מתאר את המערכת שלנו (HIT-SCIR) עבור המשימה המשותפת CoNLL 2017: המערכת שלנו כוללת שלושה רכיבים צנרת: טוקניזציה, תווית חלק מהדיבור (POS) ותחקירת תלויות. We use character-based bidirectional long short-term memory (LSTM) networks for both tokenization and POS tagging.  לאחר מכן, אנו משתמשים באלגוריתם המבוסס על רשימה למחקר כללי לא פרויקטיבי ולהציג ארכיטקטורה ממבוססת על Stack-LSTM שיפורסמת כדי לייצג כל מדינת המעבר ולעשות ציפויים. חוץ מזה, כדי לחקור שפות נמוכות/אפס-משאבים ומידע בין תחומות, אנו משתמשים באמצעות גישה מודל להעברה כדי לעשות שימוש יעיל של משאבים קיימים. אנו מראים רווחים משמעותיים נגד ראשון UDPipe, עם שיפור ממוצע של 3.76% בלאס אנג'לס בכל שפות. ולבסוף, אנו מגדירים את המקום הרביעי במבחנים הרשמיים.", 'jv': 'Perintah sing paling nggawe sistem (HIT-scIR) kanggo kowe CoNLL 1997 didasal nggawe task: Multilanguage Parasing suku rawe Text suku Universal dependancies. Sistem-sistem sing nduwé telu kompon sing nggawe lanjut: tokenizer, parts-of-speaking (po S) section Murah, kita kelompok nggawe kelompok nggawe barang sistem sing basa gambar transform-basa Algorithm kanggo kowe nggawe barang pengguna-pengguna nggawe barang kelompok nggawe Stack-LTT-basa architecture nggawe barang nggawe geranggawe kebebasan tarjamahan lan nggawe ulwih dumadhi. We use a model transfer method to make effect use of current tools. Awak dhéwé éntukno akeh bantên penggunaké sawar mêng pancen ning weruh-sistem UTPipe, lan padha tanggal 3.7% nang LAS kuwi sabên langa. Banyak, awak dhéwé luwih cara-cara sing wis 4 nang masa resan offisisi.', 'bo': 'འོག་གི་ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག (HIT-SCIR)ལ་མཉམ་དུ་འཇུག་སྤྱོད་ཀྱི་ལས་འགུལ་ལ་བཤད་ཀྱི་ཡོད། ང་ཚོའི་མ་ལག་གི་རྒྱུད་དུང་གི་ཆ་ཤས་གསུམ་ཀྱི་ནང་དུ་ཡོད། ང་ཚོས་ཡིག་འབྲུ་གཞུང་དང་མཐུད་པའི་བརྡ་བཀོད་བྱས་པ་ལས་ཐག་རིང་བའི་ཚད་འཛིན་བྱ་རིམ། Sonra, we employ a list-based transition-based algorithm for general non-projective parsing and present an improved Stack-LSTM-based architecture for representing each transition state and making predictions. ད་དུང་། འུ་ཅག་གིས་གནས་སྟངས་དཀྱིས་ཀླད་པའི་སྐད་རིགས་དང་མཐུན་གྲངས་ཆ་འཕྲིན་ཡིག ང་ཚོས་UDPipe་ཡི་གཞུང་ཕྱོགས་ཀྱི་རྒྱལ་ཁབ་གཙང་དག་ཡར་རྒྱས་གཏོང་བྱེད་ཀྱི་ཡོད། སྐད་ཡིག་ཆ་ཚང་གི་LAS་ནང་གི་སྤྱི་ཚོགས་ མཐའ་མར་དུ། ང་ཚོས་གཞུང་འབྲེལ་གྱི་བརྟག་ཞིབ་ཀྱི་སྒྲིག་ཆ་བཞིན་གྲངས་ཀ་རེད།'}
{'en': 'A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations', 'ar': 'نظام لتحليل التبعية متعدد اللغات يعتمد على تمثيلات ميزة LSTM ثنائية الاتجاه', 'pt': 'Um sistema para análise de dependência multilíngue com base em representações bidirecionais de recursos LSTM', 'fr': "Système d'analyse de dépendance multilingue basé sur des représentations de caractéristiques LSTM bidirectionnelles", 'es': 'Un sistema para el análisis de dependencias multilingües basado en representaciones de funciones LSTM bidireccionales', 'ja': '双方向LSTM特徴表現に基づく多言語依存性解析のためのシステム', 'zh': '一基于双向LSTM者,多言赖解析统也', 'hi': 'द्विदिश LSTM सुविधा अभ्यावेदन पर आधारित बहुभाषी निर्भरता पार्सिंग के लिए एक प्रणाली', 'ru': 'Система многоязычного анализа зависимостей на основе двунаправленных представлений функций LSTM', 'ga': 'Córas um Pharsáil Spleáchais Ilteangacha bunaithe ar Léirithe Déthreoracha ar Ghné LSTM', 'ka': 'Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations', 'hu': 'Többnyelvű függőség-értelmezés rendszere kétirányú LSTM funkcióképviseleteken alapuló', 'el': 'Ένα σύστημα ανάλυσης πολυγλωσσικής εξάρτησης βασισμένο σε αμφίδρομες αναπαραστάσεις χαρακτηριστικών LSTM', 'it': 'Un sistema di analisi delle dipendenze multilingue basato sulle rappresentazioni bidirezionali delle funzionalità LSTM', 'lt': 'Daugiakalbio priklausomybės analizavimo sistema, pagrįsta dvikryptiniais LSTM požymiais', 'kk': 'Көптілік тәуелдік талдау жүйесі LSTM қасиеттерінің екі бағытталған', 'mk': 'Name', 'ms': 'Name', 'mt': 'Sistema għall-Analiżi ta’ Dipendenza Multilingwi bbażata fuq Rappreżentazzjonijiet Bidirezzjonali tal-Karatteristiċi tal-LSTM', 'ml': 'ബൈഡഡലിയല്\u200d LSTM വിശേഷതകള്\u200d പ്രതിനിധികളില്\u200d അടിസ്ഥാനമായി പല ഭാഷകളുടെ ആശ്രയിക്കുന്ന ഒരു സിസ്റ്റം', 'mn': 'Олон хэл хамааралтай байдлын шинжилгээний систем хоёр багын LSTM өөрчлөлтийн төлөөлөлт', 'no': 'Name', 'pl': 'System wielojęzycznego parowania zależności oparty na dwukierunkowych reprezentacjach funkcji LSTM', 'ro': 'Un sistem de analizare multilingvă a dependenței bazat pe reprezentarea caracteristicilor LSTM bidirecționale', 'sr': 'Sistem za razmatranje višejezičkih zavisnosti na temelju dvosmjernih predstavljanja LSTM funkcije', 'si': 'Name', 'so': 'Xiriiridda mas’uuliyadda luuqadaha badan ee lagu saleysan yahay nidaamka u baaraandegista noocyada LSTM', 'sv': 'Ett system för flerspråkig beroendetolkning baserat på dubbelriktade LSTM-funktionsrepresentationer', 'ta': 'இருதிசையாக LSTM தன்மைகளை அடிப்படையிலான பல மொழி சார்ந்த ஒதுக்கீட்டு அமைப்பு', 'ur': 'Multilingual Dependency Parsing for A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations', 'uz': 'Name', 'vi': 'Một hệ thống đa ngôn ngữ phân khủng bộ nhiệm dự đoạn dựa trên bộ trưởng giao dịch LSD', 'bg': 'Система за многоезично анализиране на зависимостта въз основа на двупосочни представяне на характеристиките', 'nl': 'Een systeem voor meertalige afhankelijkheidsparsing op basis van Bidirectionele LSTM Feature Representaties', 'hr': 'Sistem za razmatranje višejezičkih zavisnosti na temelju dvosmjernih predstavljanja LSTM funkcija', 'da': 'Et system til flersproget afhængighedsfortolkning baseret på bidirektionelle LSTM-funktionsrepræsentationer', 'id': 'Sistem untuk Penganalisan Dependensi Berbahasa berdasarkan Representasi Feature LSTM Bidirectional', 'ko': '쌍방향 LSTM 특징을 바탕으로 하는 다중 언어 의존 분석 시스템', 'de': 'Ein System für mehrsprachiges Dependency Parsing basierend auf bidirektionalen LSTM Feature Representations', 'tr': 'Köp dilli baglançylyk Taýramçylyk Görkezilmesi Bidirectional LSTM Görkezilişi Görkezilmeleri', 'sw': 'A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations', 'fa': 'Name', 'hy': 'Բազլեզու կախվածությունների վերլուծության համակարգը, որը հիմնված է երկիուղղային LSMT ֆիլմերի ներկայացումների վրա', 'am': 'አዲስ ዶሴ ፍጠር', 'az': 'Bir çoxlu dil bağlılıq analizi sistemi LSTM Feature Representations Based on Multidirectional Dependency Parsing', 'af': 'Name', 'bn': 'বাইডেডিয়াল LSTM বৈশিষ্ট্যাবলী প্রতিনিধির ভিত্তিক মাল্টিভাষার নির্ভর পার্সিং এর একটি সিস্টেম', 'sq': 'Një Sistem për analizimin e varësive shumëgjuhësore bazuar në përfaqësime dydrejtuese të funksionit LSTM', 'cs': 'Systém pro analýzu vícejazyčné závislosti založený na obousměrných reprezentacích vlastností LSTM', 'ca': 'A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations', 'et': 'Kahesuunalistel LSTM funktsioonide esitustel põhinev mitmekeelse sõltuvuse parsimise süsteem', 'fi': 'Kaksisuuntaisiin LSTM-ominaisuuksien esittämiseen perustuva monikielinen riippuvuuden parsausjärjestelmä', 'bs': 'Sistem za razmatranje višejezičkih zavisnosti na temelju dvosmjernih predstavljanja LSTM funkcije', 'he': 'Name', 'jv': 'A System for Multilanguage dependance', 'ha': 'KCharselect unicode block name', 'sk': 'Sistem za večjezično razvrščanje odvisnosti, ki temelji na dvosmernih predstavitvah funkcij LSTM', 'bo': 'སྐད་རིགས་མང་ཙམ་འབྲེལ་གྱི་རྟེན་འབྲེལ་ལ་དབྱེ་ཞིབ་ཀྱི་རྒྱུ་དངོས་གཞི་བཞག་ཡོད་པ LSTM ཁྱད་ཆོས་ཚན་བཤད་པ'}
{'en': 'In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with Multilingual Parsing from Raw Text to Universal Dependencies. Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser. Thanks to multilingual word embeddings and one hot encodings for languages, our system can use both monolingual and multi-source training. We trained 69 monolingual language models and 13 multilingual models for the shared task. Our multilingual approach making use of different resources yield better results than the monolingual approach for 11 languages. Our system ranked 5 th and achieved 70.93 overall LAS score over the 81 test corpora (macro-averaged LAS F1 score).', 'ar': 'في هذه الورقة ، نقدم محلل التبعية متعدد اللغات الذي تم تطويره لمهمة CoNLL 2017 UD المشتركة التي تتناول "التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية". يقوم المحلل اللغوي الخاص بنا بتوسيع محلل BIST أحادي اللغة كمحلل متعدد المصادر قابل للتدريب متعدد اللغات. بفضل عمليات تضمين الكلمات متعددة اللغات والتشفير الساخن للغات ، يمكن لنظامنا استخدام التدريب أحادي اللغة ومتعدد المصادر. قمنا بتدريب 69 نموذجًا بلغة واحدة و 13 نموذجًا متعدد اللغات للمهمة المشتركة. نهجنا متعدد اللغات باستخدام موارد مختلفة يؤدي إلى نتائج أفضل من النهج أحادي اللغة لـ 11 لغة. احتل نظامنا المرتبة الخامسة وحقق 70.93 درجة إجمالية في LAS مقارنة بـ 81 مجموعة اختبار (درجة LAS F1 متوسطة الحجم).', 'es': 'En este artículo, presentamos nuestro analizador de dependencias multilingüe desarrollado para la tarea compartida UD de CoNll 2017 que trata del «análisis multilingüe del texto sin procesar a las dependencias universales». Nuestro analizador amplía el analizador BIST monolingüe como un analizador capacitable multilingüe de múltiples fuentes. Gracias a las incrustaciones de palabras multilingües y a las codificaciones en caliente para los idiomas, nuestro sistema puede utilizar tanto la formación monolingüe como la de múltiples fuentes. Entrenamos 69 modelos lingüísticos monolingües y 13 modelos multilingües para la tarea compartida. Nuestro enfoque multilingüe que hace uso de diferentes recursos produce mejores resultados que el enfoque monolingüe para 11 idiomas. Nuestro sistema ocupó el quinto lugar y obtuvo una puntuación general de LAS de 70,93 sobre los 81 cuerpos de prueba (puntuación LAS F1 macropromediada).', 'fr': "Dans cet article, nous présentons notre analyseur de dépendances multilingue développé pour la tâche partagée UD ConLL 2017 traitant de «\xa0L'analyse multilingue du texte brut aux dépendances universelles\xa0». Notre parser étend le BistParser monolingue en un analyseur multisource multilingue pouvant être formé. Grâce aux intégrations de mots multilingues et aux encodages à chaud pour les langues, notre système peut utiliser une formation monolingue et multisource. Nous avons formé 69 modèles linguistiques monolingues et 13 modèles multilingues pour la tâche partagée. Notre approche multilingue utilisant différentes ressources donne de meilleurs résultats que l'approche monolingue pour 11 langues. Notre système s'est classé 5ème et a obtenu 70,93 score LAS global sur les 81 corpus de test (score LAS F1 macro-moyen).", 'pt': 'Neste artigo, apresentamos nosso analisador de dependência multilíngue desenvolvido para a Tarefa Compartilhada CoNLL 2017 UD que trata de “Parsing multilíngue de texto bruto para dependências universais”. Nosso analisador estende o analisador BIST monolíngue como um analisador multilíngue treinável de várias fontes. Graças às incorporações de palavras multilíngues e uma codificação quente para idiomas, nosso sistema pode usar treinamento monolíngue e multi-fonte. Treinamos 69 modelos de linguagem monolíngue e 13 modelos multilíngues para a tarefa compartilhada. Nossa abordagem multilíngue, usando diferentes recursos, produz melhores resultados do que a abordagem monolíngue para 11 idiomas. Nosso sistema ficou em 5º lugar e alcançou 70,93 pontuação geral LAS sobre os 81 corpora de teste (pontuação LAS F1 com média macro).', 'ja': '本稿では、「Raw TextからUniversal Dependenciesへの多言語構文解析」を扱うCoNLL 2017 UD Shared Taskのために開発された多言語依存構文解析器について紹介する。当社のパーサーは、単一言語のBISTパーサーをマルチソースの多言語トレーニング可能なパーサーとして拡張します。多言語の単語埋め込みと1つの言語のホットエンコーディングのおかげで、当社のシステムは単語とマルチソースの両方のトレーニングを使用できます。私たちは、共有タスクのために69のモノリンガル言語モデルと13の多言語モデルをトレーニングしました。さまざまなリソースを活用した当社の多言語アプローチは、11言語の単一言語アプローチよりも優れた結果をもたらします。当社のシステムは5位であり、81の試験コーラ（マクロ平均LAS F 1スコア）を上回る70.93のLASスコアを達成しました。', 'zh': '在本文中,我们介绍了CoNLL 2017 UD共享职务开发的多言语依赖关系解析器,该职务处理"从原始文本到通用依赖的多言语解析"。 吾解析器将单语 BIST 解析器广为多源多言可以训解析器。 多语言词嵌和一种语言热编码,我们的系统可以用单语和多源培训。 共职训练69单语语言13多言模。 多言异资,胜于11言单语术。 我们的系统排名第 5 位,在 81 个测试语料库(宏观平均值 LAS F1 分数)中得 70.93 的总 LAS 分数。', 'hi': 'इस पेपर में, हम CoNLL 2017 UD Shared Task के लिए विकसित हमारे बहुभाषी निर्भरता पार्सर को प्रस्तुत करते हैं जो "रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग" से निपटता है। हमारे पार्सर एक बहु-स्रोत बहुभाषी trainable पार्सर के रूप में मोनोलिंगुअल BIST-पार्सर का विस्तार करता है। बहुभाषी शब्द एम्बेडिंग और भाषाओं के लिए एक गर्म एन्कोडिंग के लिए धन्यवाद, हमारी प्रणाली मोनोलिंगुअल और बहु-स्रोत प्रशिक्षण दोनों का उपयोग कर सकती है। हमने साझा कार्य के लिए 69 मोनोलिंगुअल भाषा मॉडल और 13 बहुभाषी मॉडल को प्रशिक्षित किया। विभिन्न संसाधनों का उपयोग करने वाला हमारा बहुभाषी दृष्टिकोण 11 भाषाओं के लिए मोनोलिंगुअल दृष्टिकोण की तुलना में बेहतर परिणाम देता है। हमारे सिस्टम को 5 वें स्थान पर रखा गया और 81 परीक्षण निगम (मैक्रो-औसत एलएएस एफ 1 स्कोर) पर 70.93 समग्र एलएएस स्कोर हासिल किया।', 'ru': 'В этой статье мы представляем наш многоязычный синтаксический анализатор зависимостей, разработанный для совместной задачи CoNLL 2017 UD, посвященной «Многоязычному синтаксическому анализу от необработанного текста к универсальным зависимостям». Наш парсер расширяет одноязычный BIST-парсер в качестве многоисточника многоязычного обучаемого парсера. Благодаря многоязычным вложениям слов и одному горячему кодированию для языков наша система может использовать как одноязычное, так и многоисточниковое обучение. Мы обучили 69 одноязычных языковых моделей и 13 многоязычных моделей для общей задачи. Наш многоязычный подход с использованием различных ресурсов дает лучшие результаты, чем одноязычный подход для 11 языков. Наша система заняла 5-е место и достигла 70,93 общего балла по шкале LAS по сравнению с 81 тестовым тестом (средний макробалл по шкале LAS F1).', 'ga': 'Sa pháipéar seo, cuirimid i láthair ár gcuid parsálaí spleáchais ilteangach a forbraíodh do Thasc Comhroinnte UD CoNLL 2017 a dhéileálann le “Parsáil Ilteangach ó Théacs Amh go dtí Spleáchais Uilíocha”. Síneann ár parsálaí an parsálaí aonteangach BIST mar pharsálaí ilfhoinse inaistrithe ilteangach. A bhuí le leabú focal ilteangach agus le hionchóduithe te amháin do theangacha, is féidir lenár gcóras oiliúint aonteangach agus ilfhoinse a úsáid. Chuireamar oiliúint ar 69 múnla teanga aonteangacha agus 13 mhúnla ilteangach don tasc roinnte. Is fearr an toradh a bhíonn ar an gcur chuige ilteangach atá againn maidir le húsáid acmhainní éagsúla ná an cur chuige aonteangach do 11 theanga. Bhí ár gcóras sa 5 ú háit agus bhain sé amach 70.93 scór iomlán LAS thar an 81 corpora tástála (scór macra-mheánmhéid LAS F1).', 'ka': 'ამ დოკუნში ჩვენ ჩვენი მრავალენგური დასახლოების პანელიზერი გავიქცევა, რომელიც CoNLL 2017-ის UD გაყოფილი საქმე, რომელიც "მრავალენგური გადაწყვანა ტექსტიდან უნივერსალური დასახლოები ჩვენი პანსერტი მონოლენგური BIST-პანსერტის მრავალენგური მრავალენგური გასწავლა პანსერტი. მრავალენგური სიტყვების შესაძლებლობა და ერთი მხოლოდ სიტყვების შესაძლებლობა, ჩვენი სისტემა შეუძლია გამოყენოთ მონოლენგური და მრავალენგური განსწავლების ჩვენ 69 მონოლენგური ენის მოდელები და 13 მრავალენგური მოდელები გავაკეთეთ საერთო დავალებისთვის. ჩვენი მრავალენგური პროგრამის გამოყენება განსხვავებული რესურსების გამოყენებას უკეთესი წარმოდგენება, ვიდრე მონოლენგური პროგრამის 11 ენ ჩვენი სისტემა ხუთი წერტილია და 70,93 წერტილი LAS წერტილია 81 ტესტის კოპორაზე (მაკრო განსაზღვრებული LAS F1 წერტილი).', 'hu': 'Ebben a tanulmányban bemutatjuk a CoNLL 2017 UD Shared Task számára kifejlesztett többnyelvű függőség-elemzőt, amely a "Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig". Elemzőnk kiterjeszti az egynyelvű BIST-elemzőt, mint egy többforrásból képzett többnyelvű elemzőt. A többnyelvű szóbeágyazásnak és egy forró kódolásnak köszönhetően rendszerünk egynyelvű és többforráskódú képzést is használhat. 69 egynyelvű nyelvi modellt és 13 többnyelvű modellt képeztünk a megosztott feladatra. A különböző erőforrásokat felhasználó többnyelvű megközelítésünk jobb eredményeket eredményez, mint az egynyelvű megközelítés 11 nyelven. Rendszerünk 5. helyen állt, és 70,93 összesített LAS pontszámot ért el a 81 tesztkorona (makro-átlagos LAS F1 pontszám).', 'el': 'Σε αυτή την εργασία, παρουσιάζουμε τον πολύγλωσσο αναλυτή εξάρτησης που αναπτύχθηκε για την κοινή εργασία που ασχολείται με την "Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις". Ο αναλυτής μας επεκτείνει τον μονογλωσσικό αναλυτή ως πολυγλωσσικό εκπαιδευόμενο αναλυτή πολλών πηγών. Χάρη στην πολύγλωσση ενσωμάτωση λέξεων και μία καυτή κωδικοποίηση για γλώσσες, το σύστημά μας μπορεί να χρησιμοποιήσει τόσο μονογλωσσική όσο και πολύγλωσση εκπαίδευση. Εκπαιδευτήκαμε 69 μονογλωσσικά μοντέλα και 13 πολύγλωσσα μοντέλα για το κοινό έργο. Η πολύγλωσση προσέγγισή μας που χρησιμοποιεί διαφορετικούς πόρους αποφέρει καλύτερα αποτελέσματα από τη μονογλωσσική προσέγγιση για τις έντεκα γλώσσες. Το σύστημά μας κατατάχθηκε στην 5η και πέτυχε 70.93 συνολική βαθμολογία σε σχέση με τα 81 σώματα δοκιμής (μακρομεσαία βαθμολογία LAS F1).', 'lt': 'Šiame dokumente pristatome savo daugiakalbį priklausomybės analizatorių, parengtą CoNLL 2017 UD bendros užduoties, susijusios su "daugiakalbiu analizavimu nuo žaliavinio teksto iki universaliųjų priklausomybių". Mūsų analizatorius išplečia vienkalbį BIST analizatorių kaip daugiakalbį traukiamą analizatorių. Dėl daugiakalbių žodžių įterpimo ir vieno karšto kalbų kodavimo mūsų sistema gali naudotis tiek vienakalbiu, tiek daugiakalbiu mokymu. Mokėjome 69 vienakalbius modelius ir 13 daugiakalbius modelius bendrai užduotims atlikti. Mūsų daugiakalbis požiūris, naudojantis skirtingais ištekliais, duoda geresnių rezultatų nei vienkalbis požiūris 11 kalbų. Mūsų sistema buvo 5-oji ir pasiekė 70,93 bendro LAS balo, palyginti su 81 bandymų korpora (makroekonominio LAS F1 balo vidurkis).', 'it': "In questo articolo, presentiamo il nostro analizzatore di dipendenze multilingue sviluppato per l'UD Shared Task CoNLL 2017 che si occupa di 'Analisi multilingue dal testo grezzo alle dipendenze universali'. Il nostro parser estende il parser BIST-monolingue come un parser multilingue multi-source trainable multilingue. Grazie alle incorporazioni di parole multilingue e a una codifica calda per le lingue, il nostro sistema può utilizzare sia corsi monolingue che multi-source. Abbiamo formato 69 modelli linguistici monolingue e 13 modelli multilingui per il compito condiviso. Il nostro approccio multilingue che utilizza risorse diverse produce risultati migliori rispetto all'approccio monolingue per 11 lingue. Il nostro sistema si è classificato 5° e ha ottenuto il punteggio LAS complessivo di 70,93 su 81 corpi test (punteggio LAS F1 macro-mediato).", 'mk': 'Во овој весник, го претставуваме нашиот мултијазичен анализатор на зависност развиен за Соделената задача на CoNLL 2017 UD која се занимава со „Мултијазичен анализатор од сув текст до универзални зависности“. Нашиот анализатор го проширува монојазичниот анализатор БИСТ како мултијазичен анализатор. Благодарение на мултијазичните зборови и една жешка кодирање за јазиците, нашиот систем може да користи и монојазични и мултијазични обуки. Трениравме 69 модели на монојазички јазик и 13 мултијазички модели за заедничката задача. Нашиот мултијазичен пристап кој користи различни ресурси дава подобри резултати од монојазичкиот пристап за 11 јазици. Нашиот систем се рангираше на 5-тото место и постигна 70,93 целокупни резултати на ЛАС во однос на 81 тестирани корпора (макро-просечен резултат на ЛАС Ф1).', 'kk': 'Бұл қағазда біз бірнеше тілдік тәуелдік талдаушысын CoNLL 2017 жылы UD ортақтастырған тапсырмалар үшін "Көп тілдік талдау мәтінінен универсалдық тәуелдіктерге" дегенді көрсетедік. Біздің талдаушысыз бірнеше тілді бірнеше тілді бақылау үшін бірнеше тілді бақылау үшін бірнеше тілді BIST- талдаушысын кеңейтеді. Көптілік сөздерді ендіру және тілдер үшін бір жылу кодтамасына рақмет, біздің жүйеміз бірнеше тілдер мен бірнеше көздерді оқытуға болады. Біз 69 монолингі тіл моделдерін және 13 көп тіл моделдерін ортақ тапсырманың үшін оқыдық. Біздің көптеген тілдеріміздің әртүрлі ресурстарды қолдану үшін 11 тілдердің бірнеше тілдерінің жақсы нәтижелерін көрсетеді. Біздің жүйеміз 5-ші деңгейі және 81 сынақ корпорасында 70,93 жалпы LAS нәтижесін жетті (макро орташа LAS F1 нәтижесі).', 'ms': "Dalam kertas ini, kami memperkenalkan penghurai dependensi berbilang bahasa kami yang dikembangkan untuk Tugas Berkongsi CoNLL 2017 UD yang berurusan dengan 'Penghuraian berbilang bahasa dari Teks Raw ke Dependenci Universal'. Penghurai kami memperluas penghurai BIST monobahasa sebagai penghurai berbagai sumber yang boleh dilatih. Terima kasih kepada penyembedding perkataan berbilang bahasa dan satu pengekodan panas untuk bahasa, sistem kita boleh menggunakan latihan monobahasa dan berbilang sumber. Kami melatih 69 model bahasa monobahasa dan 13 model berbilang bahasa untuk tugas berkongsi. pendekatan berbilang bahasa kami yang menggunakan sumber yang berbeza memberikan hasil yang lebih baik daripada pendekatan monobahasa untuk 11 bahasa. Sistem kami ditangkap ke-5 dan mencapai skor keseluruhan LAS 70.93 atas 81 korpra ujian (skor LAS F1 makro-rata).", 'ml': 'ഈ പത്രത്തില്\u200d, ഞങ്ങള്\u200d നമ്മുടെ പല ഭാഷാ ആശ്രയിക്കുന്ന പ്രദര്\u200dശനം കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കെടുത്ത പണിയില്\u200d നിര്\u200dമ്മിക്കുന്നു. റൂ ലേക്സില്\u200d നിന്നും യ നമ്മുടെ പരിശീലിക്കുന്നത് മോണോളില്\u200d ഭാഷ ബിസ്റ്റ്-പാര്\u200dസറിനെ പല-സോര്\u200dസ്സ് ട്രെയിനിക്കാവുന്ന ഒരു പരി പല ഭാഷയിലെ വാക്കുകളും ഭാഷകള്\u200dക്ക് ഒരു ചൂടുള്ള കോഡിങ്ങുകളും കൊണ്ട് ഞങ്ങളുടെ സിസ്റ്റത്തിന് മോണോളില്\u200dഭാഷ, പല-സോര്\u200dസ് ഞങ്ങള്\u200d 69 മോനോളില്\u200d ഭാഷ മോഡല്\u200d പരിശീലിപ്പിച്ചിട്ടുണ്ട്. പങ്കുചേര്\u200dന്ന ജോലിക്കായി 13 പല ഭാഷ മോഡലുകളും. Our multilingual approach making use of different resources yield better results than the monolingual approach for 11 languages.  ഞങ്ങളുടെ സിസ്റ്റത്തിന്റെ 5 മണ്ണില്\u200d നിന്നും 70.93 ലേസ് സ്കോര്\u200dട്ട് 81 ടെസ്റ്റ് കോര്\u200dപ്പോരിയില്\u200d എത്തി (മാക്രോവിലെ സാധ', 'mt': "F'dan id-dokument, aħna nippreżentaw il-analizzatur tad-dipendenza multilingwi żviluppat tagħna għall-ħidma kondiviża tal-UD CoNLL 2017 li tittratta l-'Analiżi Multilingwi minn Test Prim għal Dipendenzi Universali'. Il-parser tagħna jestendi l-parser BIST monolingwi bħala parser multilingwi li jista’ jitħarreġ. Grazzi għall-inkorporazzjoni ta’ kliem multilingwi u kodifikazzjoni sħuna waħda għall-lingwi, is-sistema tagħna tista’ tuża taħriġ kemm monolingwi kif ukoll multisorsi. Taħriġna 69 mudell monolingwi u 13-il mudell multilingwi għall-kompitu kondiviż. L-approċċ multilingwi tagħna li jagħmel użu minn riżorsi differenti jagħti riżultati aħjar mill-approċċ monolingwi għal 11-il lingwa. Is-sistema tagħna kklassifikat fil-5 u kisbet 70.93 punteġġ globali tal-LAS fuq l-81 korpra tat-test (punteġġ makro-medju tal-LAS F1).", 'ro': 'În această lucrare, prezentăm analizatorul nostru de dependență multilingv dezvoltat pentru CoNLL 2017 UD Shared Task care se ocupă de "Parsing multilingv de la text brut la dependențe universale". Parserul nostru extinde parserul BIST monolingv ca parser multilingv multilingv instruibil. Datorită încorporărilor de cuvinte multilingve și codărilor rapide pentru limbi străine, sistemul nostru poate utiliza atât instruirea monolingvă, cât și cea multi-sursă. Am instruit 69 de modele lingvistice monolingve și 13 modele multilingve pentru sarcina comună. Abordarea noastră multilingvă care utilizează resurse diferite oferă rezultate mai bune decât abordarea monolingvă pentru 11 limbi. Sistemul nostru s-a clasat pe locul 5 și a obținut un scor LAS total de 70,93 pe cele 81 de corpuri de test (scor LAS F1 macro-mediu).', 'pl': 'W niniejszym artykule przedstawiamy nasz wielojęzyczny parser zależności opracowany dla wspólnego zadania CoNLL 2017 UD zajmujący się "Wielojęzycznym Parsowaniem z tekstu surowego do zależności uniwersalnych". Nasz parser rozszerza jednojęzyczny parser BIST jako wielojęzyczny parser treningowy. Dzięki wielojęzycznym osadzeniom słów i jednym gorącym kodowaniu dla języków, nasz system może korzystać z szkoleń jednojęzycznych i wielojęzycznych. Szkoliliśmy 69 modele jednojęzyczne oraz 13 modele wielojęzyczne dla wspólnego zadania. Nasze wielojęzyczne podejście wykorzystujące różne zasoby daje lepsze rezultaty niż podejście jednojęzyczne dla jedenastu języków. Nasz system zaliczył piątą klasyfikację i osiągnął ogólny wynik LAS 70.93 nad 81 korpusami testowymi (makro-średni wynik LAS F1).', 'no': 'I denne papiret presenterer vi vår multispråk avhengighetsanalyser utvikla for den delte oppgåva CoNLL 2017 som handler med «Multispråk tolking frå Raw Text til universelle avhengighet». Tolkaren vårt utvidar monospråk BIST- tolkaren som ein fleire kildekode multispråk trenbar tolkar. Takk på innbygging av fleire språk og ein varme koding for språk, kan systemet vårt bruka både monospråk og fleirkjeldeopplæring. Vi trenga 69 monospråk- modeller og 13 multispråk- modeller for delt oppgåve. Vår fleirspråk tilnærming som gjer bruk av ulike ressursar gjer bedre resultat enn den monospråk tilnærming for 11 språk. Sistemet vårt rangert 5. og oppnådd 70,93 overalt LAS-poeng over 81 testkorpora (makro gjennomsnittt LAS F1-poeng).', 'mn': 'Энэ цаасан дээр бид олон хэлний хамааралтай хуваалцааны хувьд 2017 оны CoNLL-ын UD хуваалцааны ажлын хувьд "Raw Text-ээс олон хэлний шинжилгээ универсал хамааралтай" болох олон хэлний хуваалцааны хуваалцагч бол Бидний хуваарч хэлний BIST-хуваарч нь олон эх үүсвэрийн олон хэлний суралцах боломжтой хуваарч гэж нэмэгдүүлдэг. Бидний систем хэл болон олон эх үүсвэрийн сургалтыг ашиглаж болно. Бид 69 хэл загварыг, 13 олон хэл загварыг хуваалцах ажлын тулд суралцаж өгсөн. Бидний олон хэлний арга нь өөр баялаг ашиглан 11 хэлний нэг хэлний арга баримтаас илүү сайн үр дүнг өгдөг. Бидний систем 5-р дүрс хүртэл 70.93 ЛАС оноо 81 тест корпоратын хувьд хүрсэн.', 'si': "මේ පැත්තේ, අපි අපේ බොහොම භාෂාවික විශ්වාස විශ්වාස කරනවා CoNLL 2017 UD කොටස් විශේෂ කරලා තියෙන්නේ 'බොහොම භාෂාවික විශ්වාස අපේ විශ්වාසකයෙන් එක භාෂාවක් BIST- විශ්වාසකයෙන් විශාල කරනවා වගේම විශාල භාෂාවක් විශාල කර බොහොම භාෂාවක් වචන ස්තූතියි, භාෂාව සඳහා ගොඩක් කෝඩින්ඩ් එකක්, අපේ පද්ධතිය ප්\u200dරයෝජනය එක භාෂාවක්  අපි එක භාෂාවක් මොඩල් 69 වලින් භාෂාවක් මොඩල් 13 වලින් භාෂාවක් මොඩල් 13 වලින් කැමතියි කාර් අපේ ගොඩක් භාෂාවික ප්\u200dරවේශනය වෙනස් සම්බන්ධ ප්\u200dරවේශනය කරන්න පුළුවන් විදිහට වඩා එක භාෂාවික ප අපේ පද්ධතිය පරීක්ෂණය පරීක්ෂණා පරීක්ෂණා කොර්පෝරා 81 විසින් 70.93 විසින් පරීක්ෂණාව ලැබුනා.", 'sr': 'U ovom papiru predstavljamo naš multijezički analitičar ovisnosti razvijen za CoNLL 2017 UD zajednički zadatak koji se bavi "Multilingual Parsing from Raw Text to Universal Dependencies". Naš analizator proširi monojezički BIST-analizator kao multiizvorski multijezički analizator. Zahvaljujući multijezičkim ugrađenjima riječima i jednim vrućim kodiranjem jezika, naš sistem može koristiti i monojezičku i multiizvornu obuku. Obučavali smo 69 monojezičkih modela i 13 multijezičkih modela za zajednički zadatak. Naš multijezički pristup korištenjem različitih resursa donosi bolji rezultat nego monojezički pristup 11 jezika. Naš sistem je postao 5. i postigao 70,93 ukupni rezultat LAS-a iznad 81 testnog korporacije (makro-srednji rezultat LAS F1).', 'so': 'Qoraalkan waxaynu soo bandhignaa baaritaanka ku xiran luuqadaha kala duduwan ee loo qoray CoNLL 2017 UD oo la qaybsaday shaqo la xiriira jardiinada luuqadaha kala duduwan ee Raw-Text-to-Universal dependency. Parsarkanagu wuxuu u fidiyaa baaritaanka bilowga BIST-baaritaanka sida kooras badan oo luuqadaha kala duduwan ah. Mahadsano waxaa loogu talagalay hadalka luuqadaha kala duduwan iyo hal cod kulul oo luuqadaha lagu qorayo, nidaamkayagu wuxuu isticmaali karaa waxbarasho af luuqad ah iyo koorasyo badan. Waxaannu tababarinnay 69 tusaalooyin luuqadaha afka maskaxda ah iyo 13 qaabab luuqado kala duduwan oo shaqada la waday. Dhaqdhaqaalaha luuqadaha kala duduwan ee isticmaalka maalmaha kala duduwan waxay keentaa resulti ka wanaagsan qaababka nooca ah ee 11 luuqadood. Our system ranked 5 th and achieved 70.93 overall LAS score over the 81 test corpora (macro-averaged LAS F1 score).', 'sv': 'I denna uppsats presenterar vi vår flerspråkiga beroendeparser utvecklad för CoNLL 2017 UD Shared Task som behandlar "Flerspråkig tolkning från råtext till universella beroenden". Vår parser utökar den enspråkiga BIST-parsern som en flerspråkig, utbildningsbar parser med flera källor. Tack vare flerspråkiga ordinbäddningar och en hetkodning för språk kan vårt system använda både enspråkig och flerspråkig utbildning. Vi utbildade 69 enspråkiga språkmodeller och 13 flerspråkiga modeller för den gemensamma uppgiften. Vårt flerspråkiga tillvägagångssätt med hjälp av olika resurser ger bättre resultat än det enspråkiga tillvägagångssättet för 11 språk. Vårt system rankades 5:e och uppnådde 70,93 totala LAS poäng över 81 testkorpor (makrogränsad LAS F1 poäng).', 'ta': "இந்த காக்கியத்தில், நாம் எங்கள் பல மொழி சார்பு சார்பு பரிசுத்தம் அமைப்பை கோன்எல் 2017 யுடி பங்கிடப்பட்ட பணிக்காக உருவாக்கினோம் 'ரு உரையிலிருந் பல- மூல மொழி பயிற்சி பயிற்சியாகும் பிஸ்ட்- பரிசோதனையாக எங்கள் பகுதியை விரிவாக்குகிறது. Thanks to multilingual word embeddings and one hot encodings for languages, our system can use both monolingual and multi-source training.  நாங்கள் 69 மொழி மொழி மாதிரிகளை பயிற்சி செய்தோம் மற்றும் 13 பல மொழி மாதிரிகளை பங்கிட்ட பணிக்கு பயிற்ச வேறு மொழிகளை பயன்படுத்துவதற்காக எங்கள் பல மொழியின் வழிமுறைகள் 11 மொழிகளுக்கு சிறந்த முடிவுகளை கொடுக்கும். எங்கள் அமைப்பு 5 ஆம் நிறைந்தது 70. 93 மொத்த LAS மதிப்பு 81 சோதனை நிறுவனத்திற்கு மேல் அடைந்தது (மேக்ரோ சராசரி LAS F1 புள்ளி).", 'ur': 'اس کاغذ میں ہم نے اپنے multilingual dependency parser کو پیش کیا CoNLL 2017 کے لئے UD شریک ٹاکس کے ساتھ "راہ ٹیکسٹ سے بہت سی زبان پارسینگ" کے بارے میں "Universal Dependencies" کے بارے میں معاملہ کیا ہے. ہمارا پارچر ایک زبان کی BIST-پارچر کو متعد-سورج multilingual trainable parser کے طور پر پھیلاتا ہے. بہت سی زبان کلمات کے مطابق اور زبانوں کے لئے ایک گرم اکنوڈینگ کا شکریہ، ہماری سیستم ایک زبان کی اور بہت سی سور کی آموزش کا استعمال کرسکتا ہے۔ ہم نے 69 واحد زبان کی مدلکوں اور 13 ملتی زبان کی مدلکوں کو مشترک کام کے لئے آموزش دی۔ ہماری بہت سی زبان کی تقریبا 11 زبانوں کے لئے ایک زبان کی تقریبا سے بہتر نتائج حاصل کرتا ہے۔ ہمارا سیستم پانچ مرتبہ تھا اور 70.93 لس اسکور کو 81 امتحان کرپور پر پہنچ گیا۔', 'vi': 'Trong tờ giấy này, chúng tôi giới thiệu nhà phân tích phụ thuộc đa dạng của chúng tôi được phát triển cho CLB Đô đốc CoNLIll phần thưởng UDDE7 xử lý "Phân tích ngôn ngữ đa từ văn bản thô đến các môi trường chung." Vị cha xứ của chúng tôi mở rộng ngôn ngữ mắc dịch hạch lớn thành phân tích đa nguồn. Nhờ sự nhúng vào các từ ngữ đa dạng và có một mã tổ hợp ngôn ngữ nóng, hệ thống của chúng ta có thể dùng cả đào tạo độc ngôn ngữ lẫn đa nguồn. Chúng tôi đã huấn luyện 69 mô hình ngôn ngữ chung, và 13 các mô- đun cho công việc chung. Cách tiếp cận đa dạng của chúng ta, sử dụng nguồn tài nguyên khác nhau sẽ có kết quả tốt hơn cách tiếp cận ngôn ngữ 11. Hệ th ống của chúng tôi xếp hạng 5 th và đạt được tỉ số 7093 LAS trên thi 81p (ghi số căn bản LAS F1).', 'uz': "Bu hujjatda biz ko'pchilik tillar ishlatuvchi parametrlarimizni KNLL 2017 UD'ning bir necha tillar o'zgartirilgan vazifani ko'pchilik matnning ko'pchilik taʼminlovchiga bog'liqdir. Bizning moslamalarimiz bir necha tili o'rganib boʻladigan bo'lgan bir xil sohasi bo'lgan boshqalarga BIST-parametrlarni ajratishdir. Bir nechta so'zlar ichki so'zlarni aytib keladi va bir qiyin kodlash usuli uchun, bizning tizimmiz monolingual va ko'plab-manba tizimga foydalanishi mumkin. Biz 69 monolingual tilning modellarini o'rganimiz va 13 tilning bir necha modellarini o'rganimiz. Bizning bir necha tildagi tilni boshqa rasmlarni ishlatish natijalarimiz 11 tillar uchun o'xshash natijalaridan bajaradi. Bizning tizimmiz 5 marta chegara bo'lgan va 81 sinov kompaniyasida umuman LAS scorini bajardi.", 'hr': 'U ovom papiru predstavljamo naš multijezički analitičar zavisnosti razvijen za zajednički zadatak CoNLL 2017 s obzirom na "Multilingual Parsing from Raw Text to Universal Dependencies". Naš analizator proširi monojezički BIST-analizač kao multiizvorski multijezički analizač treninga. Zahvaljujući multijezičkim ugrađenjima riječima i jednim vrućim kodiranjem jezika, naš sustav može koristiti i monojezičku i multiizvornu obuku. Obučavali smo 69 monojezičkih modela i 13 multijezičkih modela za zajednički zadatak. Naš multijezički pristup korištenjem različitih resursa pruža bolji rezultat nego monojezički pristup 11 jezika. Naš sustav je dobio 5. redak i postigao 70,93 cjelokupan rezultat LAS-a iznad 81 testnog tijela (makro-srednji rezultat LAS F1).', 'nl': "In dit artikel presenteren we onze meertalige afhankelijkheidsparser ontwikkeld voor de CoNLL 2017 UD Shared Task die zich bezighoudt met 'Meertalige Parsing van ruwe tekst naar universele afhankelijkheden'. Onze parser breidt de eentalige BIST-parser uit tot een multi-source meertalige trainable parser. Dankzij meertalige woord embeddings en één hot codering voor talen kan ons systeem zowel eentalige als meertalige training gebruiken. We hebben 69 eentalige taalmodellen en 13 meertalige modellen getraind voor de gedeelde taak. Onze meertalige aanpak waarbij gebruik wordt gemaakt van verschillende bronnen levert betere resultaten op dan de eentalige aanpak voor elf talen. Ons systeem scoorde vijfde en behaalde 70.93 totale LAS score boven de 81 testcorpora (macro-gemiddelde LAS F1 score).", 'id': "Dalam kertas ini, kami mempersembahkan parser kebiasaan berbilang bahasa kami yang dikembangkan untuk CoNLL 2017 UD Shared Task yang berurusan dengan 'Parsing berbilang bahasa dari Teks Raw ke Universal Dependencies'.. Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser.  Terima kasih kepada pembangunan kata berbagai bahasa dan satu kode panas untuk bahasa, sistem kita dapat menggunakan latihan monobahasa dan multisumber. Kami melatih 69 model bahasa monobahasa dan 13 model berbagai bahasa untuk tugas yang sama. Our multilingual approach making use of different resources yield better results than the monolingual approach for 11 languages.  Sistem kami mencetak nilai ke-5 dan mencapai 70,93 skor LAS secara umum atas 81 korpra tes (nilai LAS F1 makro-rata).", 'da': "I denne artikel præsenterer vi vores flersprogede afhængighedsfortolker udviklet til CoNLL 2017 UD Shared Task, der beskæftiger sig med 'Flersproget tolkning fra rå tekst til universelle afhængigheder'. Vores parser udvider den ensprogede BIST-parser som en multi-source flersproget træningsbar parser. Takket være flersprogede ordindlejringer og en varm kodning til sprog, kan vores system bruge både ensproget og flersproget træning. Vi har uddannet 69 ensprogede sprogmodeller og 13 flersprogede modeller til den fælles opgave. Vores flersprogede tilgang, der gør brug af forskellige ressourcer, giver bedre resultater end den ensprogede tilgang for 11 sprog. Vores system rangerede på 5. plads og opnåede 70,93 samlede LAS score over 81 test corpora (makro-gennemsnit LAS F1 score).", 'ko': "본고에서 우리는 CoNLL 2017 UD 공유 임무를 위해 개발한 다중 언어 의존 항목 해석기를 소개했는데 이 작업은'원시 텍스트에서 일반적인 의존 항목까지의 다중 언어 해석'을 처리한다.Google 파서는 단일 언어 BIST 파서를 다중 소스 다중 언어로 확장하여 파서를 훈련할 수 있습니다.다국어 단어 삽입과 언어의 핫코딩 덕분에 우리 시스템은 단어와 다원 훈련을 사용할 수 있다.우리는 공유 임무를 위해 69개의 단어 언어 모델과 13개의 다중 언어 모델을 양성했다.11개 언어에 대해 우리는 서로 다른 자원을 이용한 다언어 방법이 단어 방법보다 더 좋은 결과를 얻었다.우리 시스템은 5위를 차지했고 81개 테스트 자료 라이브러리에서 LAS의 총 점수는 70.93(거시적 평균 LAS F1 점수)에 달했다.", 'sw': "Katika karatasi hii, tunaonyesha mchambuzi wetu wa kutegemea lugha mbalimbali ulioandaliwa kwa ajili ya chama cha CoNLL 2017 UD kilichoshirikishwa na shughuli za 'Uchaji wa lugha mbalimbali kutoka Maandishi ya Raw hadi Utegemea ulimwengu'. Mchambuzi wetu hueneza mchambuzi wa lugha ya kimapenzi wa BIST kama mchambuzi wa mafunzo ya lugha mbalimbali. Shukrani kwa maneno ya lugha mbalimbali na taratibu moja yenye moto kwa lugha, mfumo wetu unaweza kutumia mafunzo ya lugha na vyanzo vingi. Tulifunza mifano ya lugha 69 za kiutamaduni na mifano 13 ya lugha nyingine kwa ajili ya kazi hiyo ya ushirikiano. Matokeo yetu ya lugha ya lugha kwa kutumia rasilimali tofauti yanaleta matokeo bora kuliko mbinu za lugha 11. Mfumo wetu ulipata kiwango cha tano na kufikia score 70.93 jumla ya LAS kwa kupitia kampuni ya jaribio 81 (score ya kiwango cha wastani wa LAS F1).", 'bg': 'В тази статия представяме нашия многоезичен анализатор на зависимости, разработен за споделената задача, която се занимава с "Многоезично анализиране от суров текст до универсални зависимости". Нашият анализатор разширява едноезичния анализатор като многоизточник многоезичен тренируем анализатор. Благодарение на многоезичните вграждания на думи и едно горещо кодиране за езици, нашата система може да използва едноезично и многоизточно обучение. Обучихме 69 едноезични езикови модела и 13 многоезични модела за споделената задача. Нашият многоезичен подход, използващ различни ресурси, дава по-добри резултати от едноезичния подход за 11 езика. Нашата система се класира на 5-то място и постигна 70.93 общ резултат над 81 тестови корпуса (макросредуциран резултат).', 'de': 'In diesem Beitrag stellen wir unseren mehrsprachigen Dependency Parser vor, der für den CoNLL 2017 UD Shared Task entwickelt wurde, der sich mit dem Thema "Mehrsprachiges Parsing von Rohtext zu Universal Dependencies" befasst. Unser Parser erweitert den einsprachigen BIST-Parser um einen mehrsprachigen, trainierbaren Parser. Dank mehrsprachiger Wort-Einbettungen und einer heißen Codierung für Sprachen kann unser System sowohl ein- als auch mehrsprachige Schulungen verwenden. Wir trainierten 69-sprachige Sprachmodelle und 13-sprachige Modelle für die gemeinsame Aufgabe. Unser mehrsprachiger Ansatz, der verschiedene Ressourcen nutzt, liefert bessere Ergebnisse als der einsprachige Ansatz für elf Sprachen. Unser System rangierte auf dem fünften Platz und erzielte 70.93 Gesamt-LAS-Score gegenüber den 81-Testkorpora (makro-gemittelter LAS F1-Score).', 'tr': 'Bu kagyzda, biziň coNLL 2017-nji ýyldaky CoNLL 2017-nji ýyldaky UD\'yň "Ýük diller Parlamak Metinden Üniversal Baýramlyklara" üçin gelişmiş işlerimizi görkezip otyrdyk. Bizim çözümleyicisimiz monodilli BIST-tanşörünü çoklu çeşmeli multi-dilli eğitimli tanşör olarak uzatır. Çoklu diller içeren sözler üçin sag bol we bir yst ködleme üçin, biziň sistemimiz hem monodil hem köp çeşmeler üçin ullanabilir. Biz 69 ünsli dil nusgalaryny we 13 sany köp dil nusgalaryny paylaşdyrdyk. Çeşitli çeşmeleri ulanmakda 11 diller üçin monodil ýagdaýyndan gowy netijede bolýar. Biziň sistemamyz 5-nji derejä boldy we 70,93 üstüne ýetirdi we 81-nji test korporasyndan üst(makro ortalamaly LAS F1 powda).', 'af': "In hierdie papier, ons stel ons multilinglike afhanklikheidspanseerder ontwikkeld vir die CoNLL 2017 UD deelde taak wat met 'Multilingual verwerking van Raw Text na Universele afhanklikhede verwerp het. Ons ontleerder uitbrei die monolinglike BIST- parser as 'n multi- bron multi- language trainable ontleerder. Dankie vir multitaalse woord inbêring en een warm kodering vir tale, ons stelsel kan gebruik beide monotale en multibronne onderwerp. Ons het 69 monolinge taal modele opgelei en 13 multilinge modele vir die gedeelde taak. Ons multitaalske toegang wat gebruik van verskillende hulpbronne beter resultate gee as die monotaalske toegang vir 11 taal. Ons stelsel rangeer 5. en het 70. 93 gevolgende LAS skakel oor die 81 toets korpora (makro- gemiddelde LAS F1 skakel).", 'hy': "In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with 'Multilingual Parsing from Raw Text to Universal Dependencies'.  Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser.  Շատ լեզվով բառերի ներգրավման և լեզվի համար մեկ տաք կոդավորման շնորհիվ մեր համակարգը կարող է օգտագործել միալեզվով և բազմաաղբյուրների ուսումնասիրություն: Մենք սովորեցրեցինք 69 միալեզվով լեզվով մոդել և 13 բազլեզվով մոդել ընդհանուր խնդրի համար: Մեր բազմալեզու մոտեցումը տարբեր ռեսուրսների օգտագործման միջոցով ավելի լավ արդյունք է ստանում, քան միալեզու մոտեցումը 11 լեզուների համար: Մեր համակարգը գնահատվել է 5-րդ և հասել է 70.93 ամբողջ LAS-ի գնահատականի 81 փորձարկումների ընթացքում (մակրոմիջին LAS F1 գնահատականի ընթացքում):", 'am': 'በዚህ ፕሮግራም፣ ለኮንஎல_2017የኦዲ አካባቢ የቋንቋ-ቋንቋዎች ማዘጋጀት ከRaw ጽሑፍ ጀምሮ እስከ ዩንቨርስቲ ድጋፍ ተሟጋቾችን የሚደረገውን ስራ እናቀርባታለን፡፡ የፊደል ቋንቋዎች የBIST-ምርጫን በብዙ ቋንቋዎች ተማሪ እንደሚሆን ይዘረጋል፡፡ በብዙ ቋንቋ ቃላት እና አንዲት ለቋንቋዎች አቀማመጥ፣ ስርዓታችን በሞላዊ ቋንቋ እና በብዙ ቋንቋ ማህበረሰብ ይችላል፡፡ 69 የሞሎንቋ ቋንቋ ምሳሌዎችን እና 13 የቋንቋ ዓይነቶች ተማርተናል፡፡ የቋንቋ ቋንቋዎች ከመጠቀም የተለየ ሀብትን ከመጠቀም የተሻለ ፍሬዎችን ከአንድ ቋንቋዎች ይልቅ ያሳያል፡፡ ሲስተኛችን 5.93 የLAS score በ81 ፈተና ኮርፖራ ላይ ደረሰ፡፡', 'sq': "Në këtë letër, ne paraqesim analizuesin tonë të varësisë shumëgjuhësore të zhvilluar për Detyrën e Përbashkët të CoNLL 2017 UD që merret me 'analizimin shumëgjuhësor nga teksti i parë në Varësitë Universale'. Analizatori ynë zgjeron analizuesin monogjuhës BIST si analizuesin multigjuhës që mund të trajnohet. Falë përfshirjes së fjalëve shumëgjuhëse dhe një kodifikimi të nxehtë për gjuhët, sistemi ynë mund të përdorë si trainimin monogjuhës ashtu edhe shumë burime. Kemi trajnuar 69 modele monogjuhësh dhe 13 modele shumëgjuhësh për detyrën e përbashkët. Përqasja jonë shumëgjuhëse duke përdorur burime të ndryshme jep rezultate më të mira se metoda monogjuhëse për 11 gjuhë. Our system ranked 5 th and achieved 70.93 overall LAS score over the 81 test corpora (macro-averaged LAS F1 score).", 'fa': 'در این کاغذ، ما متخصص بستگی های زیادی زبان ما را برای کار مشترک CoNLL ۲۰۱۷ در مورد "بازرسی های زیادی زبان از متن Raw به بستگی های جهانی" نشان می دهیم. ویرایشگر ما ویرایشگر یک زبان BIST را به عنوان یک ویرایشگر متن\u200cمنبع متن\u200cزبانی فراوان گسترش می\u200cدهد. سپاسگزاری از جمع کردن کلمات زیادی زبان و یک رمز گرم برای زبان، سیستم ما می تواند از آموزش یک زبان و چند منبع استفاده کند. ما 69 مدل زبان تک زبان و 13 مدل متعدد زبان را برای کار مشترک آموزش دادیم. دستور زیادی زبان ما برای استفاده از منابع مختلف نتیجه\u200cهای بهتر از دستور یک زبان برای ۱۱ زبان می\u200cدهد. سیستم ما پنجم درجه داشت و به 70.93 درجه کل نمایش LAS بر 81 شرکت آزمایش رسید (نمایش LAS F1 ماکروسط).', 'bs': 'U ovom papiru predstavljamo naš multijezički analitičar ovisnosti razvijen za CoNLL 2017 UD zajednički zadatak koji se bavi "Multilingual Parsing from Raw Text to Universal Dependencies". Naš analizator proširi monojezički BIST-analizator kao multiizvorski multijezički praćeni analizator. Zahvaljujući multijezičkim ugrađenjima riječima i jednim vrućim kodiranjem jezika, naš sistem može koristiti i monojezičku i multiizvornu obuku. Obučavali smo 69 monojezičkih modela i 13 multijezičkih modela za zajednički zadatak. Naš multijezički pristup korištenjem različitih resursa donosi bolji rezultat nego monojezički pristup 11 jezika. Naš sistem je postao 5. i postigao 70,93 ukupni rezultat LAS-a iznad 81 testnog korporacije (makro-srednji rezultat LAS F1).', 'bn': "এই কাগজটিতে আমরা আমাদের বহুভাষার নির্ভরশীল প্যারেজের সামনে উপস্থাপন করছি কনএল ২০১৭ ইউডি শেয়ার করা কাজের জন্য যাতে 'রো টেক্সট থেকে বিশ্ববিদ্যা আমাদের প্রশিক্ষক বিস্ট-প্রশিক্ষণের জন্য মাল্টিভাষা প্রশিক্ষণের প্রশিক্ষণ হিসেবে মোনোলিভাল বিস্ট-প্য মাল্টিভাষায় শব্দের প্রবেশ করার জন্য ধন্যবাদ এবং ভাষার জন্য একটি গরম এনকোডিং, আমাদের সিস্টেম অনুভূতি এবং বহুভাষার প্রশিক্ষণ ব আমরা ৬৯ মানুষ ভাষার মডেল প্রশিক্ষণ দিয়েছি এবং শেয়ার করা কাজের জন্য ১৩ মাল্টিভাষার মডেল। বিভিন্ন সম্পদ ব্যবহারের জন্য আমাদের মাল্টিভাষার পদক্ষেপ ১১ ভাষার চেয়ে ভাল ফলাফল প্রদান করে। আমাদের সিস্টেম ৫ থেকে লাঞ্ছিত এবং ১৮ টেস্ট কোর্পোরার মাধ্যমে ৭০. ৯৩ সারা স্কোর অর্জন করেছে (ম্যাক্রো গড়ে ল্যাস এফ১ স", 'cs': 'V tomto článku představujeme náš vícejazyčný parser závislostí vyvinutý pro sdílenou úlohu CoNLL 2017 UD zabývající se "Multilingual Parsing from Raw Text to Universal Dependencies". Náš parser rozšiřuje jednojjazyčný BIST-parser jako vícezdrojový vícejazyčný trénovatelný parser. Díky vícejazyčnému vložení slov a jednomu horkému kódování pro jazyky může náš systém používat jak jednojjazyčné, tak vícezdrojové školení. Trénovali jsme 69 jednojjazyčné modely a 13-jazyčné modely pro sdílený úkol. Náš vícejazyčný přístup využívající různé zdroje přináší lepší výsledky než monojazyčný přístup pro jedenáct jazyků. Náš systém zařadil 5.tý a dosáhl 70.93 celkového LAS skóre nad 81 testovacími korpusy (makro-průměrné LAS F1 skóre).', 'et': "Käesolevas töös tutvustame meie mitmekeelset sõltuvuspartserit, mis on välja töötatud CoNLL 2017 UD Shared Task'i jaoks, mis käsitleb mitmekeelset parsimist toortekstist universaalseteni sõltuvusteni. Meie parser laiendab ühekeelset BIST-parser kui mitmekeelne mitmekeelne treenitav parser. Tänu mitmekeelsele sõna manustamisele ja ühele keelte kuumkodeeringule saab meie süsteem kasutada nii ühe- kui ka mitmeallilist koolitust. Koolitasime ühise ülesande jaoks 69 ühekeelset keelemudelit ja 13 mitmekeelset mudelit. Meie mitmekeelne lähenemisviis, mis kasutab erinevaid ressursse, annab paremaid tulemusi kui ühekeelne lähenemisviis 11 keele puhul. Meie süsteem oli viiendal kohal ja saavutas 81 testikorpuse üldise LAS skoori 70,93 (makrokeskmine LAS F1 skoor).", 'az': 'Bu kağızda, çoxlu dil bağımlılığımız ayırıcımızı, CoNLL 2017-ci CoNLL UD paylaşılmış işləri ilə "Sür Metindən Üniversal bağımlılıqlara çoxlu dil ayırılması" ilə müvəffəq edirik. Bizim ayırıcımız monodil BIST-ayırıcını çoxlu mənbə çoxlu dil təhsil edən ayırıcısı olaraq genişləşdirir. Çoxlu dil sözləri birləşdirməyə və dillərə isti kodlamaya səbəb, sistemimiz monodil və çoxlu mənbə təhsil edə bilər. Biz 69 dil modellərini və 13 dil modellərini paylaşdırdıq. Bizim çoxlu dil tərəfimiz müxtəlif kaynaqları istifadə etmək 11 dillərin monodil tərəfimizdən daha xeyirli sonuçlarını verir. Sistemimiz 5. dərəcə və 81 test korporası üstündə 70.93 nəticəsini qəbul etdi.', 'ca': "In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with 'Multilingual Parsing from Raw Text to Universal Dependencies'.  Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser.  Thanks to multilingual word embeddings and one hot encodings for languages, our system can use both monolingual and multi-source training.  We trained 69 monolingual language models and 13 multilingual models for the shared task.  Our multilingual approach making use of different resources yield better results than the monolingual approach for 11 languages.  El nostre sistema es va classificar en la 5ª posició i va aconseguir 70,93 puntuacions globals de LAS sobre els 81 corpores de prova (puntuacions macromitjanes de LAS F1).", 'fi': 'Tässä artikkelissa esittelemme monikielisen riippuvuuden parserin, joka on kehitetty CoNLL 2017 UD Shared Task -tehtävään, jossa käsitellään "Multilingual Parsing from Raw Text to Universal Dependences". Analysoijamme laajentaa monikielisen BIST-jäsentäjän monikieliseksi koulutettavaksi jäsentäjäksi. Monikielisten sanaupotusten ja yhden kuuman kielikoodauksen ansiosta järjestelmämme voi käyttää sekä monikielistä että monikielistä koulutusta. Koulutimme jaettuun tehtävään 69 monikielistä kielimallia ja 13 monikielistä mallia. Monikielinen lähestymistapa, jossa hyödynnetään erilaisia resursseja, tuottaa parempia tuloksia kuin yksikielinen lähestymistapa 11 kielellä. Järjestelmämme sijoittui 5. sijalle ja saavutti 70,93 LAS-pisteen 81 testikorpussa (makrokeskiarvo LAS F1 -pisteet).', 'jv': "Nang pepulan iki, kita mudhaya akeh sampeyan akeh multilengu dipunangkapan kanggo kelas CoNLL 1997, UT Sampeyan tasks nggawe 'Multilanguage Awak dhéwé artisanor ngapterunti multi-source multi-language Sugeng barêng-barêng langkung akeh akeh basa lan akeh koding kanggo langgar, sistem dhéwé iso nggambar cara-langgar lan akeh akeh-susaran. Awak dhéwé dituruti 9 sampek lang sampek lan 13 sampek multilengu model kanggo nyebutaké nggawe barang. Ndheke sampeyan akeh langkung sampeyan nggawe sistem kaya sistem sing paling apik dhéwé dadi supoyo sing luwih apik kanggo sabané ingkang 11. Sistem dhéwé wis rangpun 5 sampeyan ate wis rampun sedhaya punika LAS liyane karo perusahaan dengok asai (macro-mediated LAS F1 punika).", 'ha': "In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with 'Multilingual Parsing from Raw Text to Universal Dependencies'.  Parallel ɗin da ke shimfiɗa mabarancin BIS-na'ura da multi-source multi-multilingular mai fassara. Ina gõde ga maganar mulki'ura da kodi guda mai kulma wa lugha, na'uranmu yana iya amfani da mafarin mulki-lugha da mulki-na'ura. Mun sanar da misãlai na lugha 69 da kuma misalin 13 masu mulki cikin aikin da aka raba shi. MataimakinMu na mulki-lingui da za'a yi amfani da abincin dabam-dabam, yana da mafiya alhẽri ga matsala daga hanyarwa na monoli-harshen 11. Tsarinmu ya danganta 5 kuma ya isa kodi 70.93 na L.S. kowace kowace na jarraba 81 (makaranti na MAS F1 score).", 'he': 'בעיתון הזה, אנו מציגים את מעבד ההתמודדות המורבית שלנו שפותח עבור משימה משותפת של CoNLL 2017 UD שמטפלת ב"מעבדה רבת שפות מתוך טקסט ראש לתמכדות יוניברסליות". Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser.  הודות לתכניות מילים רבות שפות וקודות חמות אחת לשפות, המערכת שלנו יכולה להשתמש באימונים מונושפות ומרבות מקורות. אימנו 69 דוגמנים לשפה מונושפת ו-13 דוגמנים רבות לשפה למשימה המשותפת. הגישה הרב-שפתית שלנו בהשתמשות משאבים שונים נותנת תוצאות טובות יותר מהגישה המונושפתית ל-11 שפות. המערכת שלנו הגיעה לדרגה ה-5 והגיעה ל-70.93 נקודה כללית של LAS על 81 גופורה מבחן (נקודת LAS F1 בממוצע מקרו).', 'sk': 'V tem članku predstavljamo naš večjezični razčlenjevalnik odvisnosti, razvit za skupno nalogo CoNLL 2017 UD, ki obravnava "Večjezično razčlenjevanje od surovega besedila do univerzalnih odvisnosti". Naš razčlenjevalnik razširi enojezični BIST-razčlenjevalnik kot večjezični razčlenjevalnik, ki ga je mogoče trenirati. Zahvaljujoč večjezičnim vključevanjem besed in enim vročim kodiranjem za jezike, lahko naš sistem uporablja enojezično in večvirno usposabljanje. Za skupno nalogo smo usposobili 69 enojezičnih jezikovnih modelov in 13 večjezičnih modelov. Naš večjezični pristop z uporabo različnih virov prinaša boljše rezultate kot enojezični pristop za 11 jezikov. Naš sistem se je uvrstil na 5. mesto in dosegel 70,93 skupnega LAS rezultata v 81 testnih korpusih (makropovprečni LAS F1 rezultat).', 'bo': "In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with 'Multilingual Parsing from Raw Text to Universal Dependencies'. Our parser extends the monolingual BIST-parser as a multi-source multilingual trainable parser. སྐད་རིགས་མང་ཙམ་གྱི་ཐ་སྙད་ནང་དུ་འཇུག ང་ཚོས་རིགས་སྐད་ཀྱི་སྐད་རིགས་ཀྱི་མིང་དཔེ་དབྱིབས་འབྲི་བ་དང་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་ལྡན་བཅུ་གསུམ་ཀྱི་དཔ ང་ཚོའི་སྐད་ཡིག Our system ranked 5 and achieved 70.93 overall LAS score over the 81 test corpora (macro-averaged LAS F1 score)."}
{'en': 'Parsing with Context Embeddings', 'fr': 'Analyse syntaxique avec des intégrations de contexte', 'es': 'Análisis con incrustaciones de contexto', 'ar': 'الاعراب مع تضمين السياق', 'pt': 'Análise com Embeddings de Contexto', 'ja': 'コンテキスト埋め込みによる解析', 'zh': '用上下文嵌解析', 'hi': 'प्रसंग एम्बेडिंग के साथ पार्सिंग', 'ru': 'Синтаксический анализ с контекстными вставками', 'ga': 'Parsáil le Leabú Comhthéacs', 'el': 'Ανάλυση με ενσωμάτωση περιβάλλοντος', 'kk': 'Контексті ендіру', 'ka': 'კონტექსტის ინბედირებით პარალიზება', 'hu': 'Feldolgozás a kontextusbeágyazásokkal', 'mk': 'Анализирање со контекстни вградувања', 'ms': 'Menghurai dengan Penjelmaan Konteks', 'mt': 'Analiżi bl-Inkorporazzjonijiet tal-Kuntest', 'lt': 'Apdorojimas su konteksto įdėjimais', 'mn': 'Контекст нэмж', 'pl': 'Parsowanie z osadzeniami kontekstowymi', 'no': 'Tolkar med kontekstinnlegg', 'it': 'Analisi con incorporazioni contestuali', 'ml': 'ഉള്ളിലുള്ള എംബെഡിങുകളുമായി പാര്\u200dസ് ചെയ്യുന്നു', 'ro': 'Parsare cu încorporarea contextului', 'sr': 'Analiziranje sa kontekstskim integracijama', 'ta': 'உள்ளமைப்புகளுடன் பாசிடுகிறது', 'so': 'Ka baaraandegista qalabka gudaha', 'sv': 'Tolka med sammanhangsbelägg', 'ur': 'کنٹکسٹ ایمبڈینگ کے ساتھ پارس کیا جاتا ہے', 'si': 'සම්බන්ධ සම්බන්ධය සමග විශ්ලේෂණය', 'uz': '@ info: whatsthis', 'vi': 'Chế độ nội dung', 'hr': 'Analiziranje sa uključenim kontekstima', 'nl': 'Parsen met contextinsluitingen', 'id': 'Parsing with Context Embeddings', 'da': 'Tolkning med kontekstindlejringer', 'bg': 'Разглеждане с вграждания в контекста', 'de': 'Analysieren mit Kontext-Einbettungen', 'ko': '컨텍스트 포함을 사용하여 해결', 'sw': 'Hifadhi na Mitandao', 'fa': 'تحلیل با وارد کردن محیط', 'tr': 'Kontekst içinde ahtarylýar', 'af': 'Verwerking met Konteks Inbetering', 'sq': 'Duke analizuar përmbajtjet e kontekstit', 'bn': 'বিষয়বস্তু দিয়ে পার্স করা হচ্ছে', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Comment', 'az': 'Kontekst ńį√ßeri il…ô ńįŇül…ônir', 'ca': "Analitzar amb l'incorporació de context", 'cs': 'Analýza s kontextovými vloženími', 'bs': 'Analiza sa kontekstskim integracijama', 'fi': 'Käsitellään kontekstin upotuksia', 'et': 'Parsimine kontekstipõimimistega', 'jv': 'bookmarks', 'ha': 'KCharselect unicode block name', 'he': 'מעבדה עם תוכניות קונטקסט', 'bo': 'རྣམ་གྲངས་མཚོན་རྟགས་ཀྱིས་དཔེ་ཞིབ་བྱེད་བཞིན་པ', 'sk': 'Razdelava z vdelavami konteksta'}
{'en': 'We introduce context embeddings, dense vectors derived from a language model that represent the left / right context of a word instance, and demonstrate that context embeddings significantly improve the accuracy of our transition based parser. Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser. We participated in the CoNLL 2017 UD Shared Task as the Ko University team and our system was ranked 7th out of 33 systems that parsed 81 treebanks in 49 languages.', 'ar': 'نحن نقدم تضمين سياق ، متجهات كثيفة مشتقة من نموذج لغوي يمثل السياق الأيسر / الأيمن لمثال كلمة ، ونوضح أن تضمين السياق يحسن بشكل كبير دقة المحلل اللغوي القائم على الانتقال. يتكون نموذجنا من نموذج لغة قائم على LSTM (BiLSTM) ثنائي الاتجاه تم تدريبه مسبقًا للتنبؤ بالكلمات في نص عادي ، ونموذج قرار متعدد الطبقات (MLP) يستخدم ميزات من نموذج اللغة للتنبؤ بالإجراءات الصحيحة لـ المحلل اللغوي القائم على انتقال ArcHybrid. شاركنا في المهمة المشتركة لـ CoNLL 2017 UD كفريق "جامعة Koç" وتم تصنيف نظامنا في المرتبة السابعة من بين 33 نظامًا قامت بتحليل 81 بنكًا للأشجار في 49 لغة.', 'es': 'Introducimos incrustaciones de contexto, vectores densos derivados de un modelo de lenguaje que representan el contexto izquierdo/derecho de una instancia de palabra, y demostramos que las incrustaciones de contexto mejoran significativamente la precisión de nuestro analizador basado en transiciones. Nuestro modelo consiste en un modelo de lenguaje basado en LSTM bidireccional (BilSTM) que está preentrenado para predecir palabras en texto sin formato, y un modelo de decisión de perceptrón multicapa (MLP) que utiliza características del modelo de lenguaje para predecir las acciones correctas para un analizador basado en transiciones de Archybrid. Participamos en la tarea compartida UD de CoNll 2017 como el equipo de la «Universidad de Koç» y nuestro sistema ocupó el séptimo lugar de 33 sistemas que analizaron 81 bancos de árboles en 49 idiomas.', 'pt': 'Apresentamos embeddings de contexto, vetores densos derivados de um modelo de linguagem que representa o contexto esquerdo/direito de uma instância de palavra, e demonstramos que os embeddings de contexto melhoram significativamente a precisão de nosso analisador baseado em transição. Nosso modelo consiste em um modelo de linguagem bidirecional baseado em LSTM (BiLSTM) que é pré-treinado para prever palavras em texto simples e um modelo de decisão multicamada perceptron (MLP) que usa recursos do modelo de linguagem para prever as ações corretas para um Analisador baseado em transição ArcHybrid. Participamos do CoNLL 2017 UD Shared Task como a equipe “Koç University” e nosso sistema foi classificado em 7º entre 33 sistemas que analisaram 81 bancos de árvores em 49 idiomas.', 'fr': "Nous introduisons des intégrations de contexte, des vecteurs denses dérivés d'un modèle de langage qui représentent le contexte gauche/droit d'une instance de mot, et nous démontrons que les intégrations de contexte améliorent considérablement la précision de notre analyseur basé sur la transition. Notre modèle se compose d'un modèle de langage bidirectionnel basé sur LSTM (BilsTM) qui est pré-entraîné pour prédire les mots en texte brut, et d'un modèle de décision perceptron multicouche (MLP) qui utilise les caractéristiques du modèle de langage pour prédire les actions correctes pour un analyseur basé sur une transition Archybrid. Nous avons participé au ConLL 2017 UD Shared Task en tant qu'équipe «\xa0Koç University\xa0» et notre système a été classé 7ème sur 33 systèmes analysant 81 banques d'arbres en 49 langues.", 'zh': '引入上下文嵌,即从言语模形派生之密向量,示单词例左/右上下文,并证上下文嵌显基转换之解析器准确性。 吾之所以双向 LSTM (BiLSTM) 者,与一重感知器 (MLP) 决之,先练以候纯文本之单词,以言占 Archybrid 转之解析器。 吾以"Koç University"团队与CoNLL 2017 UD共之,吾系于解析49言之81个树库33系统排名第7位。', 'ja': 'コンテキスト埋め込みを導入し、単語インスタンスの左右のコンテキストを表す言語モデルから派生した濃密なベクトルを導入し、コンテキスト埋め込みがトランジションベースの構文解析器の精度を大幅に向上させることを実証します。当社のモデルは、プレーンテキストで単語を予測するために事前にトレーニングされた双方向LSTM （ BiLSTM ）ベースの言語モデルと、言語モデルからの特徴を使用してArcHybridトランジションベースの構文解析器の正しいアクションを予測する多層パーセプトロン（ MLP ）決定モデルから構成されています。CONLL 2017 UD Shared Taskに「Koç University」チームとして参加し、当社のシステムは、49言語で81のツリーバンクを解析した33のシステムのうち7位にランクされました。', 'ru': 'Мы вводим вложения контекста, плотные векторы, полученные из языковой модели, которые представляют левый/правый контекст экземпляра слова, и демонстрируем, что вложения контекста значительно повышают точность нашего парсера на основе перехода. Наша модель состоит из двунаправленной языковой модели на основе LSTM (BiLSTM), которая предварительно обучена предсказывать слова в простом тексте, и многослойной модели принятия решений перцептрона (MLP), которая использует функции из языковой модели для предсказания правильных действий для парсера на основе перехода ArcHybrid. Мы участвовали в CoNLL 2017 UD Shared Task в качестве команды «Koç University», и наша система заняла 7-е место из 33 систем, которые проанализировали 81 берег деревьев на 49 языках.', 'hi': 'हम संदर्भ एम्बेडिंग, घने वैक्टर को एक भाषा मॉडल से व्युत्पन्न करते हैं जो एक शब्द उदाहरण के बाएं / दाएं संदर्भ का प्रतिनिधित्व करते हैं, और प्रदर्शित करते हैं कि संदर्भ एम्बेडिंग हमारे संक्रमण आधारित पार्सर की सटीकता में काफी सुधार करते हैं। हमारे मॉडल में एक द्विदिश एलएसटीएम (BiLSTM) आधारित भाषा मॉडल शामिल है जो सादे पाठ में शब्दों की भविष्यवाणी करने के लिए पूर्व-प्रशिक्षित है, और एक बहु-परत परसेप्ट्रॉन (एमएलपी) निर्णय मॉडल जो एक ArcHybrid संक्रमण आधारित पार्सर के लिए सही कार्यों की भविष्यवाणी करने के लिए भाषा मॉडल से सुविधाओं का उपयोग करता है। हमने CoNLL 2017 UD Shared Task में "Koç University" टीम के रूप में भाग लिया और हमारी प्रणाली को 33 प्रणालियों में से 7 वें स्थान पर रखा गया था जो 49 भाषाओं में 81 ट्रीबैंक को पार्स करते थे।', 'ga': 'Tugaimid isteach leabaithe comhthéacs, veicteoirí dlútha a dhíorthaítear ó mhúnla teanga a léiríonn an comhthéacs clé/dheis de chás focal, agus léirímid go gcuireann leabú comhthéacs feabhas suntasach ar chruinneas ár bparsálaí tras-bhunaithe. Is éard atá inár múnla ná múnla teanga déthreorach bunaithe ar LSTM (BiLSTM) atá réamh-oilte chun focail a thuar i ngnáth-théacs, agus múnla cinnteoireachta ilchiseal perceptron (MLP) a úsáideann gnéithe ón múnla teanga chun na gníomhartha cearta a thuar don Parsálaí tras-bhunaithe ArcHybrid. Ghlacamar páirt i dTasc Comhroinnte UD CoNLL 2017 mar fhoireann “Ollscoil Koç” agus rangaíodh ár gcóras sa 7ú háit as 33 córas a rinne parsáil ar 81 banc crann i 49 teanga.', 'ka': "ჩვენ კონტექსტური ინტერნექციები, სიტყვების მარცხენა/მარცხენა კონტექსტურის მოდელიდან გამოვიყენებთ, და გამოჩვენებთ, რომ კონტექსტური ინტერნექციები ძალიან უფრო მეტივად გავაკეთებ ჩვენი მოდელი იყოს ბიდერექციონალური LSTM (BiLSTM) ენის მოდელზე, რომელიც პირველი ტექსტის სიტყვების წინასწარმოადგენა, და მრავალური სიტყვების წინასწარმოადგენის მოდელზე, რომელიც ენის მოდელზე გამოყენებული ფუნქციები, რომელიც ArcHybrid გა ჩვენ 2017-ს CoNLL UD-ის გაყოფილი საქმე როგორც 'Koc University' ჯგუფი და ჩვენი სისტემა 33 სისტემაში შვიდი წერტილი იყო, რომლებიც 49 ენაში 81 გაყოფილი საქმე.", 'el': 'Εισάγουμε ενσωματώσεις περιβάλλοντος, πυκνά διανύσματα που προέρχονται από ένα μοντέλο γλώσσας που αντιπροσωπεύουν το αριστερό/δεξί πλαίσιο μιας παρουσίας λέξης, και καταδεικνύουμε ότι οι ενσωματώσεις περιβάλλοντος βελτιώνουν σημαντικά την ακρίβεια του αναλυτή που βασίζεται στη μετάβαση. Το μοντέλο μας αποτελείται από ένα μοντέλο γλώσσας που βασίζεται σε δύο κατευθύνσεις και ένα μοντέλο λήψης αποφάσεων πολλαπλών επιπέδων που χρησιμοποιεί χαρακτηριστικά από το μοντέλο γλώσσας για να προβλέψει τις σωστές ενέργειες για έναν αναλυτή μετάβασης που βασίζεται σε μετάβαση. Συμμετείχαμε στην κοινή εργασία ως ομάδα του Πανεπιστημίου Κόκ και το σύστημά μας κατατάχθηκε 7ο από τα 33 συστήματα που αναλύουν 81 δένδρες σε 49 γλώσσες.', 'hu': 'Bemutatjuk a kontextusbeágyazásokat, a nyelvi modellből származó sűrű vektorokat, amelyek egy szópéldány bal/jobb kontextusát képviselik, és bemutatjuk, hogy a kontextusbeágyazások jelentősen javítják az átmeneti alapú elemzőnk pontosságát. Modellünk egy kétirányú LSTM (BiLSTM) alapú nyelvmodellből áll, amely előre kiképzett a szövegben szereplő szavak előrejelzésére, valamint egy többrétegű perceptron (MLP) döntési modellből áll, amely a nyelvmodell funkcióit használja, hogy előrejelezze a helyes műveleteket egy ArcHybrid átmeneti alapú elemző. A CoNLL 2017 UD Shared Task-ban a "Koc University" csapatként vettünk részt, és rendszerünk a 7. helyen állt a 33 rendszer közül, amelyek 49 nyelven 81 fabank elemzését végezték.', 'mk': 'Ние воведуваме контекстни вградувања, густи вектори извлечени од јазички модел кој го претставуваат левиот/десниот контекст на зборна инстанција, и демонстрираме дека контекстните вградувања значително ја подобруваат точноста на нашиот процесор базиран на транзи Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser.  Ние учествувавме во Соделената задача на УД КоНЛ 2017 како тим на „Универзитетот Кок“ и нашиот систем беше рангиран на 7-ми место од 33 системи кои проверија 81 дрвја на 49 јазици.', 'it': "Introduciamo incorporazioni di contesto, vettori densi derivati da un modello di linguaggio che rappresentano il contesto sinistro/destro di un'istanza di parola, e dimostriamo che le incorporazioni di contesto migliorano significativamente l'accuratezza del nostro parser basato sulla transizione. Il nostro modello consiste in un modello linguistico bidirezionale basato su LSTM (BiLSTM) pre-addestrato per predire le parole in testo semplice, e un modello decisionale di percettron multistrato (MLP) che utilizza le funzionalità del modello linguistico per predire le azioni corrette per un parser basato su transizione ArcHybrid. Abbiamo partecipato al CoNLL 2017 UD Shared Task come team 'Koc University' e il nostro sistema si è classificato 7 ° su 33 sistemi che hanno analizzato 81 treebank in 49 lingue.", 'lt': 'We introduce context embeddings, dense vectors derived from a language model that represent the left/right context of a word instance, and demonstrate that context embeddings significantly improve the accuracy of our transition based parser.  Mūsų model į sudaro dvikryptis LSTM (BiLSTM) pagrįstas kalbos model is, kuris yra iš anksto parengtas aiškiame tekste numatyti žodžius, ir daugelio sluoksnių perceptrono (MLP) sprendimų modelis, kuriuo naudojamos kalbos modelio savybės, kad būtų galima numatyti teisingus veiksmus, taikytinus archibridiniam pereinamojo laikotarpio analizatoriui. Mes dalyvavome CoNLL 2017 UD bendroje užduotyje kaip "Koc universiteto" komanda ir mūsų sistema buvo 7-oji iš 33 sistemų, kurios išanalizavo 81 medžių bankus 49 kalbomis.', 'mt': "We introduce context embeddings, dense vectors derived from a language model that represent the left/right context of a word instance, and demonstrate that context embeddings significantly improve the accuracy of our transition based parser.  Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser.  We participated in the CoNLL 2017 UD Shared Task as the 'Koc University' team and our system was ranked 7th out of 33 systems that parsed 81 treebanks in 49 languages.", 'ms': "Kami memperkenalkan penyembedding konteks, vektor tebal yang berasal dari model bahasa yang mewakili konteks kiri/kanan contoh perkataan, dan menunjukkan bahawa penyembedding konteks meningkatkan ketepatan penghurai berasaskan transisi kita secara signifikan. Model kami terdiri dari model bahasa berdasarkan LSTM (BiLSTM) bidireksi yang dilatih-dilatih untuk meramalkan perkataan dalam teks biasa, dan model keputusan persepton berbilang-lapisan (MLP) yang menggunakan ciri-ciri dari model bahasa untuk meramalkan tindakan yang betul untuk penghurai berdasarkan trangsi Archybrid. Kami berpartisipasi dalam Tugas Berkongsi CoNLL 2017 UD sebagai pasukan 'Universiti Koc' dan sistem kami dipilih ke-7 daripada 33 sistem yang menghurai 81 pangkalan pokok dalam 49 bahasa.", 'kk': "Біз мәтін инстанциясының сол/ оң контекстігін көрсету үшін контексті ендіруді, тіл үлгісінен келтірілген тұрақтық векторларды таңдап, мәтін инстанциясының сол/ оң жақтағы контекстігін көрсету үшін Біздің үлгіміз кәдімгі мәтінде сөздерді таңдау үшін алдын- ала оқылған LSTM (BiLSTM) негіздеген тіл үлгісін, және архибрид ауыстыру бағдарламасының дұрыс әрекеттерін таңдау үшін тіл үлгісінің қасиеттерін қолданатын көп қабатты қа Біз 2017 жылы CoNLL UD ортақ тапсырмасына 'Кок университетінің' командасы ретінде қатынасыз келді. Жүйеміз 49 тілде 81 құрылғы бөлінген 33 жүйелерден 7-ші ретінде болды.", 'pl': 'Wprowadzamy osadzenia kontekstowe, gęste wektory pochodzące z modelu językowego, które reprezentują lewy/prawy kontekst instancji słowa i demonstrujemy, że osadzenia kontekstowe znacznie poprawiają dokładność naszego parsera opartego na przejściach. Nasz model składa się z dwukierunkowego modelu językowego opartego na LSTM (BiLSTM), który jest wstępnie przeszkolony do przewidywania słów w zwykłym tekście, oraz wielowarstwowego modelu decyzji perceptronowego (MLP), który wykorzystuje funkcje z modelu językowego do przewidywania prawidłowych działań dla parsera przejść ArcHybrid. Uczestniczyliśmy w CoNLL 2017 UD Shared Task jako zespół "Koc University", a nasz system został na siódmym miejscu spośród 33 systemów analizujących 81 banki drzew w 49-językach.', 'ro': 'Introducem încorporări de context, vectori densi derivati dintr-un model de limbaj care reprezintă contextul stânga/dreapta al unei instanțe de cuvinte și demonstrăm că încorporările de context îmbunătățesc semnificativ acuratețea parserului nostru bazat pe tranziție. Modelul nostru constă dintr-un model lingvistic bidirecțional LSTM (BiLSTM), care este pre-instruit pentru a prezice cuvintele în text simplu, și un model de decizie perceptron multistrat (MLP), care utilizează caracteristici din modelul lingvistic pentru a prezice acțiunile corecte pentru un parser bazat pe tranziție ArcHybrid. Am participat la CoNLL 2017 UD Shared Task ca echipă "Koc University" și sistemul nostru a fost pe locul 7 din 33 de sisteme care au analizat 81 de brațe în 49 de limbi.', 'ml': "ഒരു വാക്കിന്റെ ഇടത്ത്/വലതുഭാഗത്തുനിന്നും പ്രതിനിധിക്കുന്ന ഭാഷ മോഡലില്\u200d നിന്നും കൂടുതല്\u200d വെക്റ്റോര്\u200dട്ടുകാരെ പരിചയപ്പെടുത്തുന്നു. പ്രത്യേകിച നമ്മുടെ മോഡലില്\u200d ഒരു ബിഡിയര്\u200dക്ഷന്\u200d LSTM (ബില്\u200dസ്റ്റം) അടിസ്ഥാനത്തുള്ള ഭാഷ മോഡലിലുണ്ട്. അത് സാധാരണ വാക്കുകളില്\u200d പ്രവചിക്കാന്\u200d മുമ്പ് പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു. ഒരു മോഡലില്\u200d നിന ഞങ്ങള്\u200d 'കോക്ക് യൂണിവേഴ്സിറ്റി' ടീമായി കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കെടുത്ത ടാസ്കില്\u200d പങ്കുചേര്\u200dന്നു. ഞങ്ങളുടെ സിസ്റ്റം 49 ഭാഷകളില്\u200d 81 ട്രീബാ", 'no': 'Vi introduserer kontekstinnleggingar, tette vektorar som er deriverte frå eit språk-modell som representerer den venstre/høgre konteksten av eit ordinstans, og demonstrerer at kontekstinnlegginga er betydelig forbetra nøyaktigheten til den overgangsbaserte tolkaren vår. Modellen vårt inneheld eit bidireksjonal LSTM (BiLSTM) basert språk- modell som er føretrainert for å foregå ord i enkelt tekst, og eit multi layer perceptron (MLP) beslutningsmodul som brukar funksjonar frå språk- modellen for å foregå korrige handlingar for ein ArcHybrid- overgang basert tolkar. Vi delta i CoNLL 2017 UD-delt oppgåve som gruppa Koc Universiteten og systemet vårt var rankert 7. av 33 systemer som tolka 81 treebanks i 49 språk.', 'so': "Waxaynu soo bandhignaynaa qalabka hoose, qaababka luuqada oo ka soo baxa noocyada bidix/midig ee ku qoran tusaale ahaan hadalka, waxaana muujinaynaa in mukhtarka ka soo baxa si aad u hagaajiyaa saxda kooxda kooxda soo wareegista. Tusaale ahaan waxaa ka mid ah model luqada ku saleysan LSTM (BiLSTM) oo horay loo baran karo in lagu sii sheego hadal saxda ah, iyo model go'aanka kala duduwan (MLP) oo isticmaalaya tusaale ahaan afka ku qoran si uu u sii sheego falimaha saxda ah ee lagu soo wareejiyo ArcHybrid baaritaanka ku saleysan. Waxaannu ka qayb galnay Shaqada loo qaybsaday CoNLL 2017 oo ah kooxda 'jaamacadda' Koc, nidaamkayagana waxaa ka mid ahaa 7aad oo ka mid ah 33 nidaam oo ku qoray 81 treebank oo 49 luqadood ku qoran.", 'mn': 'Бид нэг үгийн зүүн/баруун тохиолдолын тухай тохиолдолд авсан тохиолдол, жинхэнэ векторуудыг танилцуулж, харин нөхцөл байдал нь бидний шилжүүлэлтийн хуваагч нарийн тохиолдлыг илүү сайжруулж чадна. Бидний загварын загвар нь хэл загвараас ашиглаж, ArcHybrid шилжүүлэлтийн хуваалцагчийн зөв үйл ажиллагааг тодорхойлдох хоёр давхар LSTM (BiLSTM) суурилсан хэл загварын загвар юм. Бид 2017 оны CoNLL-ын UD-ын хуваалтын ажил "Кок Их Сургуулийн" багийнхээ хувьд оролцсон бөгөөд бидний систем 49 хэл дээр 81 ургамлыг хуваалцсан 33 системээс 7-р ангид орсон.', 'sv': "Vi introducerar kontextinbäddningar, täta vektorer härledda från en språkmodell som representerar vänster/höger kontext i en ordinstans, och visar att kontextinbäddningar avsevärt förbättrar noggrannheten i vår övergångsbaserade parser. Vår modell består av en dubbelriktad LSTM (BiLSTM) baserad språkmodell som är förberedd för att förutsäga ord i vanlig text, och en flerlagers perceptron (MLP) beslutsmodell som använder funktioner från språkmodellen för att förutsäga korrekta åtgärder för en ArcHybrid övergångsbaserad parser. Vi deltog i CoNLL 2017 UD Shared Task som 'Koc University'-teamet och vårt system rankades 7:e av 33 system som analyserade 81 trädbanker på 49 språk.", 'si': 'අපි සම්බන්ධ සංවේදනය සම්බන්ධ වෙක්ටර්, භාෂා මොඩේලයෙන් පිළිගත්ත භාෂාවක් වලින් පිළිගත්තා, වචන සංවේදනයෙන් වමුන්/දක අපේ මොඩල් එක්ක බිඩිරෙක්ෂන් LSTM (BiLSTM) භාෂා මොඩල් එකක් තියෙනවා, ඒ වගේම සාමාන්ය පාළුවන් වචන සිදුවීම සඳහා ප්\u200dරශ්නය කරලා තියෙන්න පුළුවන් ප්\u200dරශ්නය කරලා ති අපි කොක් විශ්වාසිත්තාවේ කණ්ඩායමක් විදියට සහ අපේ පද්ධතියේ පද්ධතිය 33 නිසා 7වෙනි පද්ධතියෙන් ඉන්නේ කොක් විශ්වාසිත්තාවේ', 'ta': "ஒரு மொழி மாதிரியிலிருந்து கொண்டுள்ள சூழ்நிலையை நாம் குறிப்பிடுகிறோம், ஒரு மொழி மாதிரியிலிருந்து குறிப்பிட்ட உள்ளடக்கங்களை குறிப்பிடுக எங்கள் மாதிரி ஒரு மொழி மொழி மாதிரி உள்ளது. இது வெறும் உரையில் முன்பயிற்சி செய்யப்பட்டுள்ளது, மற்றும் ஒரு மொழி மாதிரியிலிருந்து தன்மைகளை பயன்படுத்தி சரியான செயல்களை முன்பார்க்கும் மாதிர நாங்கள் கோன்எல் 2017 UD பணியில் பங்கிட்டோம் 'கோக் கல்லூரி' குழுவில் மற்றும் எங்கள் கணினியில் 33 முறைமைகளில் இருந்து 81 ட்ரெபாங்க்களை 49 ம", 'sr': 'Predstavljamo kontekstske integracije, gusti vektori iz jezičkog model a koji predstavlja levi/desni kontekst riječi instanca, i pokazujemo da kontekstski integracija značajno poboljšava tačnost našeg prethodnog analizatora. Naš model se sastoji od dvodirektivnog jezičkog model a osnovanog LSTM (BiLSTM) koji je pre-obučen za predviđanje riječi na prostom tekstu, i model odluke multislojnog perceptrona (MLP) koji koristi karakteristike iz jezičkog modela kako bi predvidjeli ispravne akcije za analizatora koji je osnovan na akhibridu. Učestvovali smo u zajedničkom zadatku CoNLL 2017 UD-a kao tim "Koc Univerziteta", a naš sistem je bio 7. iz 33 sistema koji je analizirao 81 treebancije na 49 jezika.', 'ur': 'ہم ایک کلام کے بائیں/دائیں کنٹکس مہینڈنگ کو معلوم کرتے ہیں، ایک زبان موڈل سے پیدا ہوئے گہرے ویکتور جو ایک کلام کے مثال کے بائیں/دائیں کنٹکس کو معلوم کرتی ہے، اور دکھاتے ہیں کہ کنٹکس مہینڈنگ ہمارے تغییر کے متعلق پا ہمارا موڈل ایک دوسری مستقل LSTM (BiLSTM) کی زبان موڈل سے ہے جو صریح متن میں کلمات کی پیش آموزش کی جاتی ہے اور ایک multi layer perceptron (MLP) تصمیم موڈل سے استعمال کرتا ہے جو زبان موڈل سے روشنی کرتا ہے تاکہ ایک ArcHybrid transition based parser کے لئے درست عمل کی پیش آموزش کرے۔ ہم نے CoNLL 2017 کے UD شریک ٹاکس میں شامل کیا تھا "کوک یونیوریس" ٹیکم اور ہماری سیستم 33 سیستم میں سے 7م درجہ تھا جو 49 زبانوں میں 81 ٹریبنک پارس کیا تھا۔', 'uz': "Biz bir so'zning chap/oʻngdagi darajaga ega bo'lgan qiyin vectorlarni anglatamiz va muzlatning chap/oʻngdagi imkoniyatlarini ko'rsatishimiz mumkin. Ularning asosida o'zgarishning tashkilotlarimizning tashkilligini juda ham oshirish mumkin. Bizning modelimiz oddiy matnni oldin so'zlarni oldin oldin ishlatish uchun LSTM (BiLSTM) asosida bir xil modeli mavjud. Bir necha qatlam (MLP) xossalaridan foydalanuvchi, ArkHybrid tarjima qilish asosida to ʻgʻri amallarni predict qilish uchun bir necha qator modeldan foydalanadi. We participated in the CoNLL 2017 UD Shared Task as the 'Koc University' team and our system was ranked 7th out of 33 systems that parsed 81 treebanks in 49 languages.", 'vi': 'Chúng tôi giới thiệu sự nhúng ghép ngữ cảnh, tỉ lệ sinh viên kết hợp từ mô hình ngôn ngữ đại diện cho trường hợp bên phải của một trường hợp chữ, và chứng minh rằng sự nhúng trường hợp này cải thiện đáng kể độ chính xác của người phân tích chuyển đổi. Mô hình của chúng ta gồm một mô hình ngôn ngữ dựa theo hai hướng (BiLSTM) có khả năng dự đoán từ trong văn bản thường, và một mô hình nhận thức đa cấp (MLP) dùng các tính năng từ mô hình ngôn ngữ để dự đoán các hành động chính xác cho một cha phân tách dây truyền hình. Chúng tôi tham gia vào CLB "Đô Thành viên Koc University" và hệ thống của chúng tôi được xếp hạng bảy ở 33 hệ thống phân tích 81 treebacks bằng 4ph.', 'hr': 'Upoznajemo kontekstske integracije, gusti vektori iz jezičkog model a koji predstavljaju lijevo/desno kontekst riječi instanca, i pokazujemo da kontekstski integracija značajno poboljšava preciznost našeg razmatrača na temelju prijenosa. Naš model se sastoji od dvodirektivnog jezičkog model a osnovanog LSTM (BiLSTM) koji je predobučen predvidjeti riječi na prostom tekstu, i model odluke multislojnog perceptrona (MLP) koji koristi karakteristike iz jezičkog modela kako bi predvidjeli ispravne akcije za analizatora na temelju prijenosa Archybrida. Učestvovali smo u zajedničkom zadatku CoNLL 2017 UD kao tim Univerziteta Koc, a naš sustav je bio 7. iz 33 sustava koji su analizirali 81 treebanca na 49 jezika.', 'bg': 'Въвеждаме вграждания на контекст, гъсти вектори, получени от езиков модел, които представляват ляв/десен контекст на дадена дума, и демонстрираме, че вгражданията на контекст значително подобряват точността на нашия базиран на преход анализ. Нашият модел се състои от двупосочен базиран езиков модел, който е предварително обучен да предвижда думи в обикновен текст, и многослоен възприетон модел, който използва функции от езиковия модел, за да прогнозира правилните действия за базиран на преход анализ. Участвахме в Споделената задача като екип на Университета "Коц" и нашата система беше класирана на 7-мо място от 33 системи, които анализираха 81 дървесни ленти на 49 езика.', 'da': "Vi introducerer kontekst indlejringer, tætte vektorer afledt fra en sprogmodel, der repræsenterer venstre/højre kontekst i en ordforekomst, og demonstrerer, at kontekst indlejringer markant forbedrer nøjagtigheden af vores overgangsbaserede fortolker. Vores model består af en bidirectional LSTM (BiLSTM) baseret sprogmodel, der er prætrænet til at forudsige ord i almindelig tekst, og en multi-lags perceptron (MLP) beslutningsmodel, der bruger funktioner fra sprogmodellen til at forudsige de korrekte handlinger for en ArcHybrid overgangsbaseret fortolker. Vi deltog i CoNLL 2017 UD Shared Task som 'Koc University'-teamet, og vores system blev rangeret 7. ud af 33 systemer, der analyserede 81 treebanks på 49 sprog.", 'de': 'Wir stellen Kontexteinbettungen vor, dichte Vektoren, die aus einem Sprachmodell abgeleitet werden, die den linken/rechten Kontext einer Wortinstanz darstellen, und zeigen, dass Kontexteinbettungen die Genauigkeit unseres Übergangs-basierten Parsers signifikant verbessern. Unser Modell besteht aus einem bidirektionalen LSTM (BiLSTM) basierten Sprachmodell, das vortrainiert ist, Wörter im Klartext vorherzusagen, und einem mehrschichtigen Perzeptron (MLP)-Entscheidungsmodell, das Funktionen des Sprachmodells verwendet, um die richtigen Aktionen für einen ArcHybrid-Übergangs-basierten Parser vorherzusagen. Wir nahmen als Team der Koc University an der CoNLL 2017 UD Shared Task teil und unser System wurde Siebter unter 33-Systemen, die 81-Baumbänke in 49-Sprachen parsten.', 'nl': "We introduceren context embeddings, dichte vectoren afgeleid van een taalmodel die de linker/rechter context van een woordinstantie vertegenwoordigen, en tonen aan dat context embeddings de nauwkeurigheid van onze transitie gebaseerde parser aanzienlijk verbeteren. Ons model bestaat uit een bidirectioneel LSTM (BiLSTM) gebaseerd taalmodel dat vooraf is getraind om woorden in platte tekst te voorspellen, en een meerlaags perceptron (MLP) beslissingsmodel dat functies uit het taalmodel gebruikt om de juiste acties te voorspellen voor een ArcHybrid transitie gebaseerde parser. We namen deel aan de CoNLL 2017 UD Shared Task als het 'Koc University' team en ons systeem werd 7e van 33-systemen die 81 boombanken in 49-talen parsen.", 'ko': "우리는 상하문 삽입, 즉 단어의 실례를 나타내는 왼쪽/오른쪽 상하문의 언어 모델에서 파생되는 밀집 벡터를 도입했고 상하문 삽입은 전환을 바탕으로 하는 해석기의 정확성을 현저히 향상시켰다는 것을 증명했다.우리의 모델은 양방향 LSTM(BilSTM)을 바탕으로 하는 언어 모델과 다중 감지기(MLP) 결정 모델을 포함한다. 전자는 순수한 텍스트의 단어를 예측하기 위해 미리 훈련하고 후자는 언어 모델의 특징을 이용하여 ArcHybrid 변환을 바탕으로 하는 해석기의 정확한 조작을 예측한다.CoNLL 2017 UD 공유 임무에는'Koc대학'팀으로 참여했으며, 우리 시스템은 49개 언어를 해석한 81개 트리 라이브러리 33개 시스템 중 7위에 올랐다.", 'id': "Kami memperkenalkan konteks embedding, vektor padat yang berasal dari model bahasa yang mewakili konteks kiri/kanan dari contoh kata, dan menunjukkan bahwa konteks embedding meningkatkan dengan signifikan akurasi parser berdasarkan transisi kita. Model kami terdiri dari model bahasa berdasarkan LSTM bidireksi (BiLSTM) yang dilatih-dilatih untuk memprediksi kata-kata dalam teks biasa, dan model keputusan persepton multi-lapisan (MLP) yang menggunakan fitur dari model bahasa untuk memprediksi tindakan yang benar untuk parser berdasarkan transisi Arkhibrid. Kami berpartisipasi di CoNLL 2017 UD Shared Task sebagai tim 'Universitas Koc' dan sistem kami ditandai ke-7 dari 33 sistem yang memeriksa 81 bank pohon dalam 49 bahasa.", 'fa': 'ما وسیله\u200cهای محیط را معرفی می\u200cکنیم، ویکتورهای محیط از یک مدل زبانی که محیط چپ/راست یک مثال کلمه را معرفی می\u200cکند، و نشان می\u200cدهیم که محیط محیط بسیار زیادی دقیق بازیگر بر اساس تغییر ما را بهتر می\u200cکند. مدل ما از یک مدل زبان بنیادی LSTM (BiLSTM) است که پیش آموزش داده شده تا کلمات را در متن ساده پیش بینی کند، و مدل تصمیم\u200cگیری چندین لایه (MLP) که از ویژه\u200cهای مدل زبان استفاده می\u200cکند برای پیش بینی کردن اقدام درست برای ویژه\u200cکننده\u200cی تغییرات پایه ArcHybrid است. ما به عنوان تیم دانشگاه Koc شریک UD در سال ۲۰۱۷ شرکت کردیم و سیستم ما به عنوان تیم دانشگاه Koc درجه ۷م از سیستم ۳۳ درجه درجه گرفته شد که ۱۸ درجه درجه با ۴۹ زبان تقسیم کرد.', 'tr': "Biz bir söz örneğinin sol/sag kontekstlerini üýtgedýän bir dil modelinden gelen kontekst integralary tanyşdyrýarys we geçişimin paýlaşmanyň dogrylygyny gowy görkez. Biziň modelimiz düzgün tekstde sözleri önlemek üçin öňünde bilinmeli LSTM (BiLSTM) tabanly bir dil nusgasyny bar we ullanýan çözüm nusgasyny (MLP) üçin ullanýan çözüm nusgasyny Archybrid geçişi üçin dogry emellerini önlemek üçin ullanýar. Biz 2017-nji ýylda CoNLL 2017-nji ýylda UD toparyna 'Kok Uniwersitet' toparyna goşuldyk we sistemimiziň 49 dilde 81 sany çyzgyş bölegi paýlandyk 33 sistemden 7-nji derejä döredildi.", 'sw': 'We introduce context embeddings, dense vectors derived from a language model that represent the left/right context of a word instance, and demonstrate that context embeddings significantly improve the accuracy of our transition based parser.  Mfano wetu una muundo wa lugha yenye msingi wa LSTM (BiLSTM) ambao umefundishwa kabla ya kutabiri maneno katika ujumbe wa maneno ya wazi, na modeli ya uamuzi (MLP) inayotumia utofauti kutoka mtindo wa lugha kutabiri vitendo sahihi kwa ajili ya mpito wa ArcHybrid anayeishi msingi wa kihistoria. Tumeshiriki katika kampuni ya CoNLL 2017 UD ilishiriki kazi kama timu ya ‘Chuo Kikuu cha Koc’ na mfumo wetu ulipangwa rangi ya 7 kati ya mifumo 33 iliyoandaliwa na benki 81 kwa lugha 49.', 'sq': "Ne prezantojmë përfshirje konteksti, vektorë të dendur të nxjerrë nga një model gjuhësh që përfaqësojnë kontekstin e majtë/të djathtë të një shembulli fjalësh, dhe demonstrojmë se përfshirjet e kontekstit përmirësojnë ndjeshëm saktësinë e analizuesit tonë të bazuar në tranzicion. Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser.  Ne morëm pjesë në Detyrën e Përbashkët të CoNLL 2017 UD si ekipi i 'Universitetit Koc' dhe sistemi ynë u rendit i shtati nga 33 sisteme që analizuan 81 baza pemësh në 49 gjuhë.", 'am': 'የቋንቋ አካባቢዎች፣ ቀኝ/ቀኝ የቃላትን ምሳሌ ማሳየት የሚደረጉትን ጥቁር እናሳየዋለን፡፡ ሞዴሌያችን የቋንቋ አካባቢ LSTM (BiLSTM) የሚደረገው ቋንቋ ሞዴል በጥሩ ጽሑፍ ውስጥ ቃላትን ለመለመቀበል በፊት የተማረ ነው፤ እናም የቋንቋ ምሳሌ ፍጥረቶችን ለመቀበል የሚጠቅመው የአርክስብሪድ መተላለፊያ ተሳሳይ የሚጠቅመው የልዩ ደረጃ ዓይነት (MLP) የፊደል ክፍተት ሞዴል ነው፡፡ በ ኮንஎல_2017ዩዲ የኮኮክ ዩንቨርስቲ ቋንቋ ሲሆን ተጋሪዎች ነበርን፡፡ ስርዓታችንም በ49 ቋንቋዎች 81 ድጋፍ የተሰፈረ ከ33 ስርዓቶች ሰባተኛውን ተካክሎአል፡፡', 'af': "Ons introduseer konteks inbêdings, dense vektores wat van 'n taal model afgelei word wat die linker/regter konteks van 'n woord voorbeeld verteenwoordig, en wys dat konteks inbêring betekeurig die presisiteit van ons oorgang gebaseerde parser verbeter. Ons model bestaan van 'n bidireksjonale LSTM (BiLSTM) gebaseerde taal model wat is vooraf-opgelei om woorde in eenvoudige teks te voorskou, en 'n multi-layer perceptron (MLP) besluit model wat gebruik funksies van die taal model na voorskou die korrekte aksies vir 'n Archybrid oordrag gebaseerde parser. Ons het gedeel in die CoNLL 2017 UD deelde taak as die 'Koc Universiteit' team en ons stelsel is 7de van 33 stelsels gelê wat 81 treebanks in 49 tale ontleed het.", 'az': "Biz məlumatları, dil modelinin sol/sağ məlumatlarını göstərən yoxluq vektörlərini təşkil edirik və bu məlumatların daxilində bizim keçiş məlumatlarımızın doğruluğunu çox yaxşılaşdırır. Bizim modelimiz düzgün mətndə sözləri təmin etmək üçün əvvəl təhsil edilmiş LSTM (BiLSTM) tabanlı dil modeli və çoxlu-katlı təhsil (MLP) seçimləri modeli ilə birlikdə dil modeli təhsil edən ArcHybrid keçirməsi üçün düzgün eylemlərini təmin etmək üçün istifadə edər. Biz 2017-ci CoNLL UD paylaşılmış işə 'Koc Universiteti' ekibi olaraq iştirak etdik. Sistemimiz 49 dildə 81 treebanklar ayırdı 33 sistemlərdən 7-ci səf idi.", 'ca': "We introduce context embeddings, dense vectors derived from a language model that represent the left/right context of a word instance, and demonstrate that context embeddings significantly improve the accuracy of our transition based parser.  Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser.  Vam participar en el CoNLL 2017 UD Shared Task com l'equip de la 'Universitat Koc' i el nostre sistema va ser classificat en 7 de 33 sistemes que analitzaven 81 bancs d'arbres en 49 llengües.", 'cs': 'Představujeme kontextové vložení, husté vektory odvozené z jazykového modelu, které reprezentují levý/pravý kontext instance slova, a demonstrujeme, že kontextové vložení výrazně zlepšuje přesnost našeho přechodového parseru. Náš model se skládá z obousměrného jazykového modelu založeného na LSTM (BiLSTM), který je předem trénován na předpovídání slov v prostém textu, a vícevrstvého rozhodovacího modelu perceptronu (MLP), který používá funkce z jazykového modelu k předpovědi správných akcí pro parser založený na přechodu ArcHybrid. Účastnili jsme se CoNLL 2017 UD Shared Task jako tým "Koc University" a náš systém byl sedmý z 33 systémů, které analyzovaly 81 stromové banky v 49 jazycích.', 'hy': 'Մենք ներկայացնում ենք կոնտեքստի ներդրումներ, խտուն վեկտորներ, որոնք ստացվում են լեզվի մոդելի միջոցով, որոնք ներկայացնում են բառի օրինակի ձախ-աջ կոնտեքստը, և ցույց են տալիս, որ կոնտեքստի ներդրումները նշանակալի բարելավում են մեր Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser.  Մենք մասնակցեցինք 2017 թվականի ԿոՆԼ-ի UD-ի կիսված գործին որպես "Կոքի համալսարանի" թիմ, և մեր համակարգը 33 համակարգերից 7-րդ դասակարգում էր, որոնք վերլուծում էին 81 ծառի բակ 49 լեզուներով:', 'bs': 'Predstavljamo kontekstske integracije, gusti vektori iz jezičkog model a koji predstavlja lijevi/desni kontekst riječi instanca, i pokazujemo da kontekstski integracija značajno poboljšava preciznost našeg analizatora temeljnog na prijelazu. Naš model se sastoji od dvodirektivnog jezičkog model a osnovanog LSTM (BiLSTM) koji je predobučen za predviđanje riječi na prostom tekstu, i model odluke multislojnog perceptrona (MLP) koji koristi karakteristike iz jezičkog modela kako bi predvidjeli ispravne akcije za analizatora baziranog na Arkhibridu. Učestvovali smo u zajedničkom zadatku CoNLL 2017 UD kao tim "Koc Univerziteta", a naš sistem je bio 7. iz 33 sustava koji je analizirao 81 treebancije na 49 jezika.', 'et': 'Tutvustame konteksti manustamist, tihedaid vektoreid, mis on saadud keelemudelist, mis esindavad sõnaeksemplari vasakut/paremat konteksti, ning näitame, et konteksti manustamine parandab oluliselt meie üleminekupõhise parseri täpsust. Meie mudel koosneb kahesuunalisest LSTM (BiLSTM) põhisest keelemudelist, mis on eelnevalt väljaõpetatud ennustama sõnu lihttekstis, ja mitmekihilisest perceptroni (MLP) otsustusmudelist, mis kasutab keelemudeli funktsioone ArcHybridi üleminekupõhise parseri õigete toimingute prognoosimiseks. Osalesime CoNLL 2017 UD jagatud ülesandes "Koc University" meeskonnana ja meie süsteem oli seitsmendal kohal 33 süsteemist, mis parsisid 81 puupunkti 49 keeles.', 'bn': 'আমরা একটি ভাষার মডেল থেকে গভীর ভেক্টর তৈরি করেছি, যা একটি শব্দের বাম/ডান প্রেক্ষাপটের প্রতিনিধিত্ব করেছে, আর প্রদর্শন করেছি যে প্রেক্ষেত্রের বিভিন্ন প্রক আমাদের মডেলের মধ্যে একটি বাইডিয়ারেক্টরিয়াল এলস্টিএম (বিএলস্টিএম) ভিত্তিক ভাষায় ভিত্তিক মডেল রয়েছে যা সাধারণ টেক্সটের ভিত্তিতে শব্দ প্রত্যাশিত হয়েছে, আর্কাইব্রিডের ভিত্তিক প আমরা কএনএল ২০১৭ সালে কোক বিশ্ববিদ্যালয়ের দল হিসেবে অংশগ্রহণ করেছি এবং ৩৩ সিস্টেম থেকে আমাদের ব্যবস্থা ৪৯ ভাষায় ৮১ ট্রিব্যাংক পার্স করেছ', 'fi': 'Esittelemme konteksti-upotuksia, kielimallista johdettuja tiheitä vektoreita, jotka edustavat sanaesiintymän vasenta/oikeaa kontekstia, ja osoitamme, että konteksti-upotukset parantavat merkittävästi siirtymäpohjaisen jäsentäjämme tarkkuutta. Mallimme koostuu kaksisuuntaisesta LSTM (BiLSTM) -kielimallista, joka on ennalta koulutettu ennustamaan sanoja tavallisessa tekstissä, ja monikerroksisesta perceptron-päätösmallista, joka käyttää kielimallin ominaisuuksia ennustamaan ArcHybrid-siirtymäpohjaisen jäsentäjän oikeat toimet. Osallistuimme CoNLL 2017 UD Shared Task -ohjelmaan "Koc University" -tiiminä ja järjestelmämme sijoittui seitsemänneksi 33 järjestelmästä, jotka analysoivat 81 puupankkia 49 kielellä.', 'sk': 'Predstavljamo kontekstne vdelave, goste vektorje, izpeljane iz jezikovnega modela, ki predstavljajo levi/desni kontekst besednega primerka, in dokazujemo, da vdelave konteksta bistveno izboljšajo natančnost našega prehodnega razčlenjevalnika. Naš model je sestavljen iz dvosmernega jezikovnega modela LSTM (BiLSTM), ki je vnaprej usposobljen za napovedovanje besed v navadnem besedilu, in večplastnega modela odločanja perceptrona (MLP), ki uporablja funkcije jezikovnega modela za napovedovanje pravilnih dejanj za razčlenjevalnik ArcHybrid prehoda. Sodelovali smo v skupni nalogi CoNLL 2017 UD Shared Task kot ekipa Univerze Koc in naš sistem je bil uvrščen na 7. mesto od 33 sistemov, ki so razčlenili 81 drevesnih plošč v 49 jezikih.', 'jv': "Awak dhéwé nglanggar aturan embedding model dhéwé wis nambah karo model sing dibutuhke yang gadoh tanggal, lan basa gambar obah dumaten kanggo ngerasai pawaran teks sing klok, lan model multi-layer perbleptron (MLP) sing nambah dhéwé ngerasai pawaran winih model nggawe aksi dibutuhke tarjamahan kanggo dumadhi nggawe dolanan ArkHyBridge terakhir. Awak dhéwé ngerasati nêmên kelas ing CoNLL 1997 udan wis kelas 'Koc Universite' karo sistem dhéwé wis rampung sedhaya sing katêmên karo alam sing katêmên karo sistem sing wis ngawehi bener (ndelok) ning 49 dilawak dhéwé", 'ha': "Tuna ƙunsa da kewayi, masu sakawi masu sauya daga wani misali na harshen wanda ke wakilishi mazaunin hagu/dama na mazaɓa wa misali na magana, kuma Muke nuna cewa muhimmin muhimmin da ke samar da tsari na shawarar transiti. @ info: whatsthis Mun yi rabo da shirin aiki a CoNLL 2017 UD kamar 'Kilain Koc' kuma na sami tsarin mu ya zama 7 na cikin tsarin 33 wanda ya sami 81 ta cikin linguin 49.", 'bo': 'ང་ཚོས་ཁོར་ཡུག Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser. ང་ཚོའི་CoNLL 2017 UD མཉམ་སྤྱོད་པའི་བྱ་རིམ་ལ་བསྡད་པ་དང་ང་ཚོ་གི་མ་ལག་གི་དབང་ཆ་Koc ཡིན་གནས་ཚུལ།', 'he': 'אנחנו מציגים קישורים קונטקסטים, ווקטורים צפופים שנוצרים ממודל שפה שמייצג את הקשור שמאל/ימין של דוגמה מילים, ומוכיחים שהקישורים הקשורים משתפרים באופן משמעותי את מדויקת הפרסם המבוסס במעבר שלנו. המודל שלנו מורכב ממודל שפה מבוסס על LSTM (BiLSTM) שני כיוונים שהוא מאומן מראש כדי לחזות מילים בטקסט פשוט, ומודל החלטה ממספר שכבות (MLP) שמשתמש במונדל השפה כדי לחזות את הפעולות הנכונות עבור מעבד מבוסס על מעבר ארכיברידי. השתתפנו במשימה המשותפת של "אוניברסיטת קוק" של CoNLL 2017, והמערכת שלנו הוצבה ב-7 מתוך 33 מערכות שהעברו 81 בנקי עץ ב-49 שפות.'}
{'en': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'ar': 'الترميز ، ووضع علامات على نقاط البيع ، و Lemmatizing و Parsing UD 2.0 باستخدام UDPipe', 'es': 'Tokenización, etiquetado de PDV, lematización y análisis UD 2.0 con UDPipe', 'pt': 'Tokenização, marcação POS, lematização e análise de UD 2.0 com UDPipe', 'fr': 'Tokenisation, marquage POS, lemmatisation et analyse UD 2.0 avec UDpipe', 'ja': 'UDPipeを使用したトークン化、POSタグ付け、レマッティング、解析UD 2.0', 'zh': '以 UDPipe 纪化、POS 记、词形还、解析 UD 2.0', 'hi': 'Tokenizing, पॉस टैगिंग, Lemmatizing और UDPipe के साथ पार्सिंग UD 2.0', 'ru': 'Токенизация, маркировка POS, лемматизация и парсинг UD 2.0 с помощью UDPipe', 'ga': 'Comharthaíocht, Clibeáil POS, Lemmatizing agus Parsáil UD 2.0 le UDPipe', 'el': 'Τοκνοποίηση, σήμανση, Lemmatizing και ανάλυση UD 2.0 με UDPipe', 'hu': 'Tokenizálás, POS Tagging, Lemmatizálás és Parsing UD 2.0 UDPipe segítségével', 'ka': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2. 0 with UDPipe', 'mk': 'Name', 'kk': 'UDPipe арқылы UD 2. 0 тегістеу, POS тегістеу, лемматизация және талдау', 'it': 'Tokenizing, POS Tagging, Lemmatizing e Parsing UD 2.0 con UDPipe', 'lt': 'Tokenizavimas, POS žymėjimas, lemmatizavimas ir UD 2.0 analizavimas su UDPipe', 'ms': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'ml': 'ഉഡിപിപ്പിയോടൊപ്പം യുഡി 2. 0 പാര്\u200dസ് ചെയ്യുന്ന, പോസ് ടാഗ്ഗിങ്ങ്, ലെമ്മാറ്റിങ് ചെയ്യുന്നു', 'mt': 'Tokenizzazzjoni, Tagging POS, Lemmatizzar u Parsing UD 2.0 b’UDPipe', 'ro': 'Tokenizare, etichetare POS, Lemmatizare și Parsing UD 2.0 cu UDPipe', 'pl': 'Tokenizowanie, tagowanie POS, lemmatyzowanie i analizowanie UD 2.0 z UDPipe', 'mn': 'UDPipe-тай холбоотой, POS Tagging, Lemmatizing, Parsing UD 2.0', 'so': 'Tokening, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'no': 'Tokenisering, POS- merking, lemmatisering og tolking av UD 2. 0 med UDPipe', 'sv': 'Tokenisering, POS Tagging, Lemmatisering och Parsing UD 2.0 med UDPipe', 'ta': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'sr': 'Tokenizacija, označavanje POS-a, limatizacija i razmatranje UD 2.0 sa UDPipeom', 'ur': 'UDPipe کے ساتھ UD 2.0 کو ٹوکینٹ کرتا ہے، POS ٹاگ کرتا ہے', 'si': 'Name', 'vi': 'Nước Tokenizing, POS Tagaging, Lemmatizing and Parsing UD 2.0 với UDPipe', 'uz': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'bg': 'Токенизиране, ПОС етикетиране, лематизиране и анализ на UD 2.0 с UDPipe', 'da': 'Tokenisering, POS Tagging, Lemmatisering og Parsing UD 2.0 med UDPipe', 'hr': 'Tokenizacija, označavanje POS-a, lijematizacija i razmatranje UD 2.0 sa UDPipeom', 'nl': 'Tokeniseren, POS Tagging, Lemmatiseren en Parsen UD 2.0 met UDPipe', 'de': 'Tokenisieren, POS Tagging, Lemmatisieren und Parsing UD 2.0 mit UDPipe', 'id': 'Tokenizing, POS Tagging, Lemmatizing dan Parsing UD 2.0 dengan UDPipe', 'ko': 'UDPipe를 사용하여 UD 2.0에 대한 표기화, 단어 표기, 레몬화 및 해석', 'tr': 'UDPipe bilen ýerleşdirilýär, POS Taglamak, Lemmatizleýän we Taýýarlanýan UD 2.0', 'sw': 'Kutengeneza, Ujumbe wa POS, Ujumbe na Kucheza UD 2.0 na UDPipe', 'af': 'Name', 'fa': 'توکین\u200cسازی، نقاشی POS، تغییر\u200cسازی و تولید UD 2. 0 با UDPipe', 'am': '0', 'hy': 'Comment', 'bs': 'Tokenizacija, označavanje POS-a, Lemmatizacija i razmatranje UD 2.0 sa UDPipeom', 'sq': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'az': 'UDPipe il톛 UD 2', 'cs': 'Tokenizace, POS Tagging, Lemmatizace a Parsing UD 2.0 s UDPipe', 'et': "Tokeniseerimine, POS märgistamine, lemmatiseerimine ja parsimine UD 2.0 UDPipe'iga", 'fi': 'Tokenisointi, POS-tunnisteet, lemmatisointi ja jäsentäminen UD 2.0 UDPipella', 'bn': 'টোকেনিং, পোস ট্যাগিং, লেমাটাইজিং এবং পার্সিং উডিপিপি ২.', 'ca': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'jv': 'Tokenising, poliS tag, Lematising lan Parasing ud2.0 karo udPipe', 'he': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe', 'ha': 'KCharselect unicode block name', 'sk': 'Tokenizacija, označevanje POS, Lemmacizacija in Razčlenjevanje UD 2.0 z UDPipe', 'bo': 'Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe'}
{'en': 'Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps   tokenization and segmentation, most likely also POS tagging and lemmatization, and commonly parsing as well. A multilingual pipeline performing these steps can be trained using the Universal Dependencies project, which contains annotations of the described tasks for 50 languages in the latest release UD 2.0. We present an update to UDPipe, a simple-to-use pipeline processing CoNLL-U version 2.0 files, which performs these tasks for multiple languages without requiring additional external data. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format. UDPipe is a standalone application in C++, with bindings available for Python, Java, C # and Perl. In the CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.', 'ar': 'تبدأ العديد من مهام معالجة اللغة الطبيعية ، بما في ذلك المهام الأكثر تقدمًا ، بشكل روتيني بعدة خطوات معالجة أساسية - الترميز والتجزئة ، وعلى الأرجح أيضًا وضع علامات POS و lemmatization ، والتحليل الشائع أيضًا. يمكن تدريب خط أنابيب متعدد اللغات يؤدي هذه الخطوات باستخدام مشروع التبعيات العالمية ، والذي يحتوي على تعليقات توضيحية للمهام الموصوفة لـ 50 لغة في أحدث إصدار UD 2.0. نقدم تحديثًا لـ UDPipe ، وهو برنامج سهل الاستخدام لمعالجة ملفات CoNLL-U الإصدار 2.0 ، والذي يؤدي هذه المهام بلغات متعددة دون الحاجة إلى بيانات خارجية إضافية. نحن نقدم نماذج لجميع اللغات الخمسين لـ UD 2.0 ، علاوة على ذلك ، يمكن تدريب خط الأنابيب بسهولة باستخدام البيانات بتنسيق CoNLL-U. UDPipe هو تطبيق مستقل بلغة C ++ ، مع روابط متاحة لـ Python و Java و C # و Perl. في المهمة المشتركة لـ CoNLL 2017: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية ، كان UDPipe هو أفضل ثمانية أنظمة ، مع تحقيق أوقات تشغيل منخفضة ونماذج متوسطة الحجم.', 'es': 'Muchas tareas de procesamiento del lenguaje natural, incluidas las más avanzadas, comienzan rutinariamente con varios pasos básicos de procesamiento: tokenización y segmentación, muy probablemente también etiquetado y lematización de PDV y, por lo general, también análisis. Se puede capacitar a una canalización multilingüe que realice estos pasos mediante el proyecto Dependencias universales, que contiene anotaciones de las tareas descritas para 50 idiomas en la última versión UD 2.0. Presentamos una actualización de UDPipe, una canalización fácil de usar que procesa archivos Conll-u versión 2.0, que realiza estas tareas para varios idiomas sin necesidad de datos externos adicionales. Proporcionamos modelos para los 50 idiomas de UD 2.0 y, además, la canalización se puede entrenar fácilmente utilizando datos en formato Conll-U. UDPipe es una aplicación independiente en C++, con enlaces disponibles para Python, Java, C# y Perl. En CoNll 2017 Shared Task: Multilingüe Parsing From Raw Text to Universal Dependencies, UDPipe fue el ocho mejor sistema, al tiempo que logró tiempos de ejecución bajos y modelos de tamaño moderado.', 'fr': "De nombreuses tâches de traitement du langage naturel, y compris les plus avancées, commencent régulièrement par plusieurs étapes de traitement de base\xa0: tokenisation et segmentation, très probablement aussi marquage et lemmatisation POS, et généralement également analyse syntaxique. Un pipeline multilingue effectuant ces étapes peut être formé à l'aide du projet Universal Dependencies, qui contient des annotations des tâches décrites pour 50 langues dans la dernière version UD 2.0. Nous présentons une mise à jour d'UDPipe, un pipeline simple à utiliser traitant les fichiers ConLL-U version 2.0, qui effectue ces tâches pour plusieurs langues sans nécessiter de données externes supplémentaires. Nous fournissons des modèles pour les 50 langues de UD 2.0 et, en outre, le pipeline peut être facilement formé à l'aide de données au format ConLL-U. UDPipe est une application autonome en C++, avec des liaisons disponibles pour Python, Java, C# et Perl. Dans la tâche partagée ConLL 2017\xa0: Multilingual Parsing from Raw Text to Universal Dependencies, UDpipe était le huitième meilleur système, tout en obtenant des temps d'exécution réduits et des modèles de taille moyenne.", 'pt': 'Muitas tarefas de processamento de linguagem natural, incluindo as mais avançadas, iniciam rotineiramente por várias etapas básicas de processamento – tokenização e segmentação, provavelmente também marcação e lematização de POS, e geralmente também análise. Um pipeline multilíngue executando essas etapas pode ser treinado usando o projeto Dependências Universais, que contém anotações das tarefas descritas para 50 idiomas na versão mais recente do UD 2.0. Apresentamos uma atualização para o UDPipe, um pipeline simples de usar que processa arquivos CoNLL-U versão 2.0, que executa essas tarefas para vários idiomas sem exigir dados externos adicionais. Fornecemos modelos para todas as 50 linguagens do UD 2.0 e, além disso, o pipeline pode ser treinado facilmente usando dados no formato CoNLL-U. UDPipe é um aplicativo autônomo em C++, com ligações disponíveis para Python, Java, C# e Perl. Na Tarefa Compartilhada CoNLL 2017: Análise Multilíngue de Texto Bruto para Dependências Universais, o UDPipe foi o oitavo melhor sistema, alcançando tempos de execução baixos e modelos de tamanho moderado.', 'ja': '最も高度なものを含む多くの自然言語処理タスクは、トークン化とセグメンテーション、おそらくはPOSタグ付けとレマティゼーション、そして一般的に解析といったいくつかの基本的な処理ステップから始まります。 これらの手順を実行する多言語パイプラインは、最新のリリースUD 2.0の50言語のタスクの説明を含むUniversal Dependenciesプロジェクトを使用してトレーニングすることができます。 外部データを追加することなく、複数の言語でこれらのタスクを実行する、CoNLL - Uバージョン2.0ファイルを処理する使いやすいパイプラインであるUDPipeのアップデートをご紹介します。 UD 2.0の50言語すべてに対応したモデルを提供しており、さらにCoNLL - U形式のデータを使用してパイプラインを簡単にトレーニングすることができます。 UDPipeはC ++のスタンドアロンアプリケーションで、Python、Java、C #、Perlで利用可能なバインディングを備えています。 CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependenciesでは、UDPipeは8つの最高のシステムであり、実行時間が短く、モデルのサイズも中程度でした。', 'zh': '诸自然语言处务,至于先进之务,常从数本 - 标记分割,或有POS标词形还原,及常分也。 可用通用赖项项目训练多语言管道,其项目包最新版本 UD 2.0 中 50 种语者注之。 言 UDPipe 之更新,UDPipe 一处 CoNLL-U 2.0 版文之简易用管,无额外之数而为多种语言行之。 凡 UD 2.0 50 种语供模形,此外可用 CoNLL-U 式之数轻练管道。 UDPipe者,C++中之独应用程序,绑定可施于Python,Java,C#Perl也。 于CoNLL 2017共事:自始文本至通用多言解析中,UDPipe为八最,兼成卑行大小之体。', 'ru': 'Многие задачи по обработке естественного языка, в том числе наиболее продвинутые, обычно начинаются с нескольких основных этапов обработки – токенизации и сегментации, скорее всего, также POS-тегирования и лемматизации, а также, как правило, синтаксического анализа. Многоязычный конвейер, выполняющий эти шаги, может быть обучен с помощью проекта Universal Dependencies, который содержит аннотации описанных задач для 50 языков в последнем выпуске UD 2.0. Мы представляем обновление UDPipe, простого в использовании конвейера обработки CoNLL-U версии 2.0 файлов, который выполняет эти задачи для нескольких языков без необходимости дополнительных внешних данных. Мы предоставляем модели для всех 50 языков UD 2.0, и, кроме того, конвейер может быть легко обучен с использованием данных в формате CoNLL-U. UDPipe - это отдельное приложение на C++, с привязками, доступными для Python, Java, C# и Perl. В CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe была лучшей системой из восьми, при этом достигалось низкое время работы и модели умеренного размера.', 'hi': 'कई प्राकृतिक भाषा प्रसंस्करण कार्य, जिनमें सबसे उन्नत लोग शामिल हैं, नियमित रूप से कई बुनियादी प्रसंस्करण चरणों से शुरू होते हैं - टोकनीकरण और विभाजन, सबसे अधिक संभावना है कि पीओएस टैगिंग और लेमेटाइजेशन भी, और आमतौर पर पार्सिंग भी। इन चरणों को निष्पादित करने वाली बहुभाषी पाइपलाइन को यूनिवर्सल निर्भरताएँ प्रोजेक्ट का उपयोग करके प्रशिक्षित किया जा सकता है, जिसमें नवीनतम रिलीज़ UD 2.0 में 50 भाषाओं के लिए वर्णित कार्यों के एनोटेशन शामिल हैं। हम UDPipe के लिए एक अद्यतन प्रस्तुत करते हैं, एक सरल-से-उपयोग पाइपलाइन प्रसंस्करण CoNLL-U संस्करण 2.0 फ़ाइलें, जो अतिरिक्त बाहरी डेटा की आवश्यकता के बिना एकाधिक भाषाओं के लिए इन कार्यों को निष्पादित करता है। हम UD 2.0 की सभी 50 भाषाओं के लिए मॉडल प्रदान करते हैं, और इसके अलावा, पाइपलाइन को CoNLL-U प्रारूप में डेटा का उपयोग करके आसानी से प्रशिक्षित किया जा सकता है। UDPipe सी ++ में एक स्टैंडअलोन एप्लिकेशन है, जिसमें पायथन, जावा, सी # और पर्ल के लिए बाइंडिंग उपलब्ध हैं। CoNLL 2017 साझा कार्य में: कच्चे पाठ से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग, UDPipe आठ सर्वश्रेष्ठ प्रणाली थी, जबकि कम चलने वाले समय और मध्यम आकार के मॉडल प्राप्त कर रही थी।', 'ga': 'Tosaíonn go leor tascanna próiseála teanga nádúrtha, lena n-áirítear na cinn is forbartha, go rialta le roinnt bunchéimeanna próiseála - comharthaíocht agus deighilt, is dóichí freisin clibeáil POS agus liomatúchán, agus parsáil coitianta freisin. Is féidir píblíne ilteangach a fheidhmíonn na céimeanna seo a oiliúint trí úsáid a bhaint as an tionscadal um Spleáchas Uilíoch, ina bhfuil nótaí ar na tascanna a bhfuil cur síos déanta orthu do 50 teanga san eisiúint is déanaí UD 2.0. Cuirimid nuashonrú i láthair do UDPipe, píblíne simplí le húsáid a phróiseálann comhaid CoNLL-U leagan 2.0, a chomhlíonann na tascanna seo le haghaidh teangacha iolracha gan sonraí seachtracha breise a bheith ag teastáil. Cuirimid múnlaí ar fáil do gach ceann de na 50 teanga de UD 2.0, agus ina theannta sin, is féidir an píblíne a oiliúint go héasca ag baint úsáide as sonraí i bhformáid CoNLL-U. Is feidhmchlár neamhspleách é UDPipe in C++, le ceangail ar fáil do Python, Java, C# agus Perl. I dTasc Comhroinnte CoNLL 2017: Parsáil Ilteangach ó Théacs Amh go dtí Spleáchais Uilíocha, ba é UDPipe an t-ocht gcóras ab fhearr, agus amanna reatha ísle agus samhlacha meánmhéide á mbaint amach aige.', 'ka': 'ბევრი თავისუფალური ენის პროცესი დავალება, ყველაზე უფრო დავიწყება, რამდენიმე ფუნქციური პროცესის ნაწილად დავიწყება - ტოკენიზაცია და სეგენეცია, უფრო შესაძლოა ასევე POS-ს ჭდე მრავალენგური ფეხლინი, რომელიც ამ ნაწილის გამოყენება, შეიძლება იყენება სამყარო პროექტის გამოყენებით, რომელიც სამყარო 50 ენათებისთვის გამოყენება UD 2.0-ში. ჩვენ UDPipe-ს განახლება, რომელიც CoNLL-U ვერსია 2.0 ფაილების გამოყენება, რომელიც ამ დავალებების გავაკეთება მრავალ ენებისთვის, დამატებული გარეშე მონაცემებით უნდა მოჭირდება. ჩვენ ყველა 50 წლის UD 2.0-ის მოდელების მოდულების შესაძლებელია, და დამატებით, უფრო მარტივი მონაცემების გამოყენება CoNLL-U ფორმატში. Name CoNLL 2017-ის გაყოფილი დავალებში: მრავალენგური გადაწყვება ტექსტიდან უნივერსალური განსაზღვრებისთვის, UDPipe იყო 8 საუკეთესო სისტემა, როცა მარტივი გადაწყვება და მედირელურად განსაზღვრებული', 'el': 'Πολλές εργασίες επεξεργασίας φυσικής γλώσσας, συμπεριλαμβανομένων των πιο προηγμένων, ξεκινούν συστηματικά από διάφορα βασικά βήματα επεξεργασίας για την επισήμανση και την τμηματοποίηση, πιθανότατα επίσης επισήμανση και λεμματοποίηση, και συνήθως ανάλυση επίσης. Ένας πολύγλωσσος αγωγός που εκτελεί αυτά τα βήματα μπορεί να εκπαιδευτεί χρησιμοποιώντας το έργο καθολικών εξαρτήσεων, το οποίο περιέχει σχόλια των περιγραφόμενων εργασιών για 50 γλώσσες στην τελευταία έκδοση 2.0. Παρουσιάζουμε μια ενημέρωση στο ένα απλό στη χρήση αγωγό επεξεργασίας αρχείων έκδοσης 2.0, το οποίο εκτελεί αυτές τις εργασίες για πολλές γλώσσες χωρίς να απαιτεί πρόσθετα εξωτερικά δεδομένα. Παρέχουμε μοντέλα για όλες τις 50 γλώσσες και επιπλέον, ο αγωγός μπορεί να εκπαιδευτεί εύκολα χρησιμοποιώντας δεδομένα σε μορφή. Το UDPipe είναι μια αυτόνομη εφαρμογή σε C++, με συνδέσεις διαθέσιμες για Python, Java, C# και Perl. Στην Κοινή Εργασία Πολυγλωσσική Ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις, το ήταν το οκτώ καλύτερο σύστημα, ενώ επιτυγχάνει χαμηλούς χρόνους λειτουργίας και μετρίου μεγέθους μοντέλα.', 'it': "Molte attività di elaborazione del linguaggio naturale, tra cui quelle più avanzate, iniziano regolarmente con diversi passaggi di elaborazione di base - tokenizzazione e segmentazione, molto probabilmente anche tag POS e lemmatizzazione, e comunemente parsing pure. Una pipeline multilingue che esegue questi passaggi può essere addestrata utilizzando il progetto Universal Dependences, che contiene annotazioni delle attività descritte per 50 lingue nell'ultima versione UD 2.0. Presentiamo un aggiornamento a UDPipe, una pipeline semplice da usare che elabora file CoNLL-U versione 2.0, che esegue queste attività per più lingue senza richiedere ulteriori dati esterni. Forniamo modelli per tutte le 50 lingue di UD 2.0, e inoltre, la pipeline può essere addestrata facilmente utilizzando i dati in formato CoNLL-U. UDPipe è un'applicazione standalone in C ++, con collegamenti disponibili per Python, Java, C # e Perl. Nell'attività condivisa CoNLL 2017: analisi multilingue dal testo grezzo alle dipendenze universali, UDPipe è stato l'otto sistema migliore, ottenendo tempi di esecuzione ridotti e modelli di dimensioni moderate.", 'lt': 'Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps - tokenization and segmentation, most likely also POS tagging and lemmatization, and commonly parsing as well.  Šiuos žingsnius atliekantis daugiakalbis vamzdynas gali būti mokomas naudojant Universal Dependencies projektą, kuriame pateikiamos aprašytų užduočių 50 kalbų anotacijos naujausiame išleidime UD 2.0. We present an update to UDPipe, a simple-to-use pipeline processing CoNLL-U version 2.0 files, which performs these tasks for multiple languages without requiring additional external data.  Pateikiame modelius visoms 50 UD 2.0 kalbų, be to, vamzdynas gali būti lengvai mokomas naudojant CoNLL-U formato duomenis. UDPipe is a standalone application in C++, with bindings available for Python, Java, C# and Perl.  In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.', 'hu': 'Számos természetes nyelvfeldolgozási feladat, beleértve a legfejlettebb feladatokat is, rutinszerűen több alapvető feldolgozási lépéssel kezdődik - tokenizálás és szegmentálás, valószínűleg POS címkézés és lemmatizálás, valamint általában elemzés is. Az ezeket a lépéseket végző többnyelvű csatornát az Univerzális függőségek projekt segítségével képezhetjük, amely az UD 2.0 legújabb kiadásában 50 nyelvre vonatkozó leírt feladatok jegyzeteit tartalmazza. Bemutatjuk az UDPipe frissítését, egy egyszerűen használható, CoNLL-U 2.0 verziójú fájlokat feldolgozó csővezetéknek, amely ezeket a feladatokat több nyelven végzi el anélkül, hogy további külső adatokat igényelne. Az UD 2.0 mind az 50 nyelvéhez modelleket kínálunk, továbbá CoNLL-U formátumú adatok felhasználásával egyszerűen képezhető a csővezeték. Az UDPipe egy önálló alkalmazás C ++, kötésekkel Python, Java, C # és Perl. A CoNLL 2017 megosztott feladat: többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig, az UDPipe volt a nyolc legjobb rendszer, miközben alacsony üzemidőt és mérsékelt méretű modelleket ért el.', 'kk': 'Табиғи тілдерді өңдеу тапсырмалары, ең жақсы, әдетте бірнеше негізгі өңдеу қадамдары бойынша бастады - токенизация және сегментация, сондай-ақ POS тегтері және лемматизация және көпшілікті талдау. Бұл қадамдарды орындайтын көптеген тілік қабырғы көпшілік қабырғы жұмыс істейтін Universal dependance жобасы қолдануға болады. Соңғы UD 2. 0 дегенде 50 тілдегі тапсырмалардың жазбалары бар. Біз UDPipe- ге жаңартуды таңдаймыз. Қосымша сыртқы деректер талап алмай, CoNLL- U 2. 0 нұсқасының қарапайым құрылғысын қолдану үшін қарапайым құрылғысы бар. Біз UD 2.0 тілдерінің барлық 50 тілдер үлгілерін келтіреміз. Сонымен қатар, конвейер жолы CoNLL- U пішімінде деректерді оңай қолдануға болады. Comment CoNLL 2017 ортақтастырылған тапсырмасы: Көптілік мәтіннен көптілік талдау әлемдік тәуелдіктерге дейін UDPipe сегіз ең жақсы жүйе болды, жұмыс уақыттарын төмен және көпшілік өлшемі үлгілерін же', 'ms': 'Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps - tokenization and segmentation, most likely also POS tagging and lemmatization, and commonly parsing as well.  Name Kami perkenalkan kemaskini kepada UDPipe, pemprosesan baris paip yang mudah digunakan fail CoNLL-U versi 2.0, yang melakukan tugas ini untuk berbilang bahasa tanpa memerlukan data luaran tambahan. Kami menyediakan model untuk semua 50 bahasa UD 2.0, dan selain itu, saluran paip boleh dilatih dengan mudah menggunakan data dalam format CoNLL-U. UDPipe is a standalone application in C++, with bindings available for Python, Java, C# and Perl.  In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.', 'mk': 'Многу природни задачи за обработување јазик, вклучувајќи ги и најнапредните, рутински започнуваат со неколку основни чекори за обработување - токенизација и сегментација, најверојатно исто така POS тегирање и лиматизација, како и обично анализирање. A multilingual pipeline performing these steps can be trained using the Universal Dependencies project, which contains annotations of the described tasks for 50 languages in the latest release UD 2.0.  Презентираме новости на UDPipe, едноставен процес за процес на гасоводот CoNLL-U верзија 2.0 датотеки, кој ги извршува овие задачи за повеќе јазици без потреба од дополнителни надворешни податоци. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format.  UDPipe is a standalone application in C++, with bindings available for Python, Java, C# and Perl.  In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.', 'ml': 'സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയഭാഷ പ്രവര്\u200dത്തിപ്പിക്കുന്ന ജോലികള്\u200d, ഏറ്റവും മുന്നറിയിപ്പുള്ള പ്രവര്\u200dത്തനങ്ങളുടെ കൂട്ടത്തില്\u200d, സാധാരണ പല അടിസ്ഥാനപ്രക്ര ഈ പടികള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്ന പല ഭാഷ പൈപ്പെലൈന്\u200d ഉപയോഗിച്ച് പഠിപ്പിക്കാന്\u200d സാധിക്കും. അതില്\u200d അടുത്ത അവസാനത്തെ UD 2. 0 വിട്ടുകൊണ്ട് 50 ഭാ പുറത്തുള്ള വിവരങ്ങള്\u200d ആവശ്യമില്ലാത്ത ഒരു പൈപെലിന്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്ന കോNLL-U പതിപ്പ് 2. 0 ഫയലുകള്\u200dക്കായി യുഡിപിപിപ്പിയിലേക്ക് ഒരു പു നമ്മള്\u200d യുഡി 2. 0-ലെ എല്ലാ 50 ഭാഷകള്\u200dക്കും മോഡലുകള്\u200d നല്\u200dകുന്നു. അതിനുശേഷം പൈപ്പെലൈന്\u200d കോണ്\u200dഎല്\u200d- യൂ ഫോര്\u200dമാറ്റില്\u200d ഡേറ്റായി ഉപയ യുഡിപിപിപ്പി C++-ല്\u200d സ്ഥാപിക്കുന്ന ഒരു പ്രയോഗത്താണു്, പൈത്തോന്\u200d, ജാവ, C# എന്നിവയ്ക്കുള്ള ബന്ധുകള്\u200d ലഭ്യമാണു്. കോണ്\u200dഎല്\u200d 2017-ല്\u200d പങ്കുചേര്\u200dത്ത പണിയില്\u200d: റൂ ടെക്സ്റ്റ് ലേക്സില്\u200d നിന്നും യൂഡിപിപ്പിയില്\u200d നിന്നും ഏറ്റവും മികച്ച സിസ്റ്റം ആയിരുന്നു. കുറഞ്ഞ സമയ', 'mt': 'Ħafna kompiti naturali tal-ipproċessar tal-lingwi, inklużi dawk l-aktar avvanzati, jibdew b’mod regolari minn diversi stadji bażiċi tal-ipproċessar - it-tokenizzazzjoni u s-segmentazzjoni, l-aktar probabbli wkoll it-tikkettar u l-lemmatizzazzjoni tal-POS, u wkoll l-analizzazzjoni komuni. A multilingual pipeline performing these steps can be trained using the Universal Dependencies project, which contains annotations of the described tasks for 50 languages in the latest release UD 2.0.  Aħna nippreżentaw a ġġornament lill-UDPipe, fajls tal-ipproċessar tal-pipeline CoNLL-U verżjoni 2.0 sempliċi għall-użu, li jwettaq dawn il-kompiti għal diversi lingwi mingħajr ma jeħtieġu dejta esterna addizzjonali. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format.  UDPipe is a standalone application in C++, with bindings available for Python, Java, C# and Perl.  In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.', 'pl': 'Wiele zadań przetwarzania języka naturalnego, w tym najbardziej zaawansowanych, rutynowo rozpoczyna się od kilku podstawowych etapów przetwarzania tokenizacji i segmentacji, najprawdopodobniej również tagowania POS i lemmatyzacji, a także powszechnie parsowania. Wielojęzyczny rurociąg wykonujący te kroki może być przeszkolony przy użyciu projektu Universal Dependencies, który zawiera adnotacje opisanych zadań dla 50 języków w najnowszej wersji UD 2.0. Przedstawiamy aktualizację UDPipe, prostego w użyciu rurociągu przetwarzającego pliki CoNLL-U wersji 2.0, który wykonuje te zadania dla wielu języków bez konieczności dodatkowych danych zewnętrznych. Dostarczamy modele dla wszystkich 50-języków UD 2.0, a ponadto rurociąg może być łatwo trenowany przy użyciu danych w formacie CoNLL-U. UDPipe to samodzielna aplikacja w C++, z powiązaniami dostępnymi dla Python, Java, C# i Perl. W ramach wspólnego zadania CoNLL 2017: Wielojęzyczne analizowanie tekstu surowego do uniwersalnych zależności UDPipe było ośmioma najlepszymi systemami, przy jednoczesnym osiągnięciu niskich czasów pracy i umiarkowanych modeli.', 'ro': 'Multe sarcini de procesare a limbajului natural, inclusiv cele mai avansate, încep în mod obișnuit prin mai mulți pași de procesare de bază - tokenizare și segmentare, cel mai probabil și etichetarea POS și lemmatizarea, precum și analizarea frecvent. O conductă multilingvă care efectuează acești pași poate fi instruită folosind proiectul Dependențe universale, care conține adnotări ale activităților descrise pentru 50 de limbi în ultima versiune UD 2.0. Vă prezentăm o actualizare la UDPipe, o conductă simplu de utilizat care procesează fișierele CoNLL-U versiunea 2.0, care efectuează aceste sarcini pentru mai multe limbi fără a necesita date externe suplimentare. Oferim modele pentru toate cele 50 de limbi UD 2.0 și, în plus, conducta poate fi instruită cu ușurință folosind date în format CoNLL-U. UDPipe este o aplicație independentă în C ++, cu legături disponibile pentru Python, Java, C # și Perl. În CoNLL 2017 Shared Task: Parsing multilingv de la text brut la dependențe universale, UDPipe a fost cel mai bun opt sistem, obținând în același timp timpi de funcționare reduși modele de dimensiuni moderate.', 'no': 'Mange naturlege språkshandsamar oppgåver, inkludert dei mest avanserte, vanlegvis startar av fleire grunnleggjande handsamar - tokenisering og segmentasjon, sannsynlegvis også POS- merking og lemmatisering, og ofte tolking også. Ein fleirspråk røyr som utfører desse stegane kan trenjast ved hjelp av universelle avhengighetsprosjektet, som inneheld merknader av dei beskrivne oppgåva for 50 språk i den siste utgåva UD 2.0. Vi presenterer ei oppdatering til UDPipe, ein enkel for å bruka røyrlinjehandsaming av CoNLL-U versjon 2.0 filer, som utfører desse oppgåva for fleire språk utan å kreva eksterne data. Vi gjev modeller for alle 50 språk med UD 2.0, og likevel kan rørslinja trennast lett med data i CoNLL-U-format. UDPipe er eit enkelt program i C++, med bindingar tilgjengelege for Python, Java, C# og Perl. I CoNLL 2017 delt oppgåve: fleirspråk tolking frå råtekst til universelle avhengighet var UDPipe den åtte beste systemet, mens det gjer låg køyrande tidar og moderære modeller.', 'mn': 'Ихэнх байгалийн хэл боловсруулах үйл ажиллагаа, хамгийн хөгжсөн, олон үндсэн үйл ажиллагаагаар эхэлдэг. Олон хэлний хоолойн шугам нь эдгээр алхамтыг хөгжүүлж байгаа Универсалдын хамааралтай төсөл ашиглаж болох юм. Энэ нь хамгийн сүүлийн үеийн UD 2.0-д 50 хэлний тайлбарлагдсан ажил дээр тайлбарлаж байгаа. Бид UDPipe-д хувилбар 2.0 файлуудыг ашиглах энгийн хоолойн шугам боловсруулах боломжтой UDPipe-д шинэчлэл өгдөг. Энэ нь нэмэлт гадаад өгөгдлийг шаардахгүй олон хэлний ажил хийдэг. Бид бүх 50 UD 2.0 хэлний загварыг хангаж өгдөг. Мөн хоолойн шугам нь CoNLL-U формат дээр өгөгдлийг ашиглан амархан суралцаж болох юм. UDPipe бол C++-ын ганцаараа ганцаараа зохион байгуулалт, Python, Java, C# болон Perl-ын холбоотой байгуулалт юм. CoNLL 2017 оны хуваалтын ажил: Raw Text-ээс Universal Dependencies руу олон хэлний шинжилгээ, UDPipe нь найм сайн систем байсан бөгөөд бага хугацаанд, орчин үеийн хэмжээтэй загваруудыг хүртэл байдаг.', 'so': 'Shaqooyin ka baaraandegista luqada asalka ah oo badan, kuwaas oo ah kuwa ugu horeeya, sida caadiga ah waxay u billaabiyaan tallaabooyin baaraandegista aasaasiga ah - bandhigista iyo qeybinta, waxaa laga yaabaa in ugu badan in POS lagala tago iyo in la soo bandhigi karo. Waxaa la baran karaa booliska luuqadaha kala duduwan oo qabanaya tallaabooyinkaas oo lagu isticmaali karo shahaadada xirfadaha caalamiga ah, kaas oo ku qoran warqadaha lagu qoray oo lagu qoray 50 luuqadood ugu dambeyn fasaxa UD 2.0. UDPipe waxaan u soo bandhignaa macluumaad cusub oo ah kooNLL-U versiyaha 2.0, kaas oo sameeya shaqooyinkaas oo luuqado kala duduwan oo a an u baahnayn macluumaad dheeraad ah oo dibadda ah. Sidoo kale waxaa si fudud looga baran karaa macluumaadka CoNLL-U. UDPipe waa codsi kali ah oo ku qoran C++, bindings ay ku jiraan Python, Java, C# iyo Perl. Shaqada la sharciyey ee CoNLL 2017: Jardiino luuqadaha badan ee laga soo bilaabo Raw-to-Dependeeries Universal, UDPipe wuxuu ahaa siddeed nidaam oo ugu fiican, iyadoo ay gaadhay wakhtiyo yar oo la soconayo iyo modello aad u hoosaysay.', 'sv': 'Många bearbetningsuppgifter för naturligt språk, inklusive de mest avancerade, börjar rutinmässigt med flera grundläggande bearbetningssteg - tokenisering och segmentering, troligen också POS-märkning och lemmatisering, och vanligtvis tolkning också. En flerspråkig pipeline som utför dessa steg kan utbildas med hjälp av projektet Universal Dependences, som innehåller anteckningar av de beskrivna uppgifterna för 50 språk i den senaste versionen UD 2.0. Vi presenterar en uppdatering av UDPipe, en lättanvänd pipeline som behandlar CoNLL-U version 2.0-filer, som utför dessa uppgifter för flera språk utan att kräva ytterligare externa data. Vi tillhandahåller modeller för alla 50 språk i UD 2.0, och dessutom kan pipeline enkelt tränas med data i CoNLL-U-format. UDPipe är ett fristående program i C ++, med bindningar tillgängliga för Python, Java, C # och Perl. I CoNLL 2017 Shared Task: Flerspråkig tolkning från råtext till universella beroende var UDPipe det åtta bästa systemet, samtidigt som de uppnådde låga driftstider och måttliga modeller.', 'ta': 'இயல்பான மொழி செயல்படுத்தல் செயல்கள், அதிக முன்னேற்றப்பட்ட செயல்கள், வழக்கமாக, பல அடிப்படை செயல்படுத்தல் படிகளால் துவங்குகிறது - அடிப்படை செயல்படுத்தல் மற்றும்  இந்த படிகளை செய்யும் பல மொழி பைப்பெல்லைன் பொது உலகளாவிய சார்ந்திருப்பு திட்டத்தை பயன்படுத்தி பயிற்சி செய்யலாம், அதில் சமீபத்தில் UD 2. 0 வை  நாம் UDPipe க்கு ஒரு புதுப்பிப்பை காண்பிக்கிறோம், ஒரு எளிய- பயன்படுத்தல் பைப்லைன் செயல்படுத்தல் CoNLL- U பதிப்பு 2. 0 கோப்பு We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format.  UDPipe is a standalone application in C++, with bindings available for Python, Java, C# and Perl. Name CoNLL 2017 பகிர்ந்த பணியில்: Raw Text to Universal சார்புகளுக்கு பல மொழி பாசிங் UDPipe என்பது எட்டு சிறந்த அமைப்பு, குறைந்த இயக்கும் நேரங்கள் மற்றும் நடுவில் அளவு மாதி', 'sr': 'Mnogi prirodni zadatak obrađivanja jezika, uključujući najnaprednije, uobičajeno počinju nekoliko osnovnih koraka obrađivanja - tokenizacija i segmentacija, najverovatnije i označavanje POS-a i lematizacija, i uobičajeno analiziranje. Većina jezičkih cijevi koji izvode te korake može biti obučena koristeći univerzalne zavisnosti projekt, koji sadrži annotacije opisanih zadataka za 50 jezika u poslednjem oslobađanju UD 2.0. Predstavljamo a žuriranje UDPipe, jednostavno za korištenje proizvodnje naftnih datoteka CoNLL-U verzije 2.0, koja obavlja ove zadatke za višestruke jezike bez zahteva dodatnih vanjskih podataka. Mi pružamo modele svih 50 jezika UD 2.0, i dodatno, cijev linija može biti lako obučena koristeći podatke u formatu CoNLL-U. UDPipe je samostalna aplikacija u C++, sa dostupnim vezama za Python, Java, C# i Perl. U CoNLL 2017. zajednièkom zadatku: multijezičko analiziranje od Raw Text do univerzalne zavisnosti, UDPipe je bio osam najboljih sistema, dok je postigao nisko trčanje vremena i moderno veličine modela.', 'si': 'ගොඩක් ස්වභාවික භාෂාව ප්\u200dරක්\u200dරියාස කරනවා වැඩි වැඩි වැඩි වැඩි කාර්ය, සාමාන්\u200dය වැඩි ප්\u200dරක්\u200dරියාස කරනවා මූලික ප්\u200dරක්\u200dරියාස කරනවා වලින විශ්\u200dවාසික විශේෂ ව්\u200dයාපෘතිය භාෂාවිත පායිප්ලයින් මෙම පැත්තුවක් කරන්න පුළුවන් විශේෂ විශේෂ විද්\u200dයාපෘතිය භාෂ අපි UDPipe ට අවස්ථාවක් පෙන්වන්න, CoNLL-U සංවිධානය 2.0 ගොනුවන් පායිප්ලින් ප්\u200dරකාරීයක් භාෂා කරන්න, ඒකෙන් අවස්ථාවක් බාහි අපි UD 2.0 වලින් හැම භාෂාවක්ම 50ක් වෙනුවෙන් මොඩල් දෙන්න පුළුවන්, ඒ වගේම, පායිප්ලායින් CoNLL-U වලින් දත්ත භාව Name CoNLL 2017 සමාගත වැඩක් තියෙන්නේ: රාව් පාළුවෙන් විශාල පාළුවෙන් විශාල විශාල විශාල විශාල වෙනුවෙන්, UDPipe තමයි හොඳම පද්ධතිය අටයි', 'ur': 'بہت سی طبیعی زبان کی پردازی کی تابعیں، سب سے زیادہ آگے بڑھنے والے، بہت سی بنیادی پردازی کی سٹیوں سے شروع ہوتے ہیں - ٹوکینیزی اور سٹوکیٹ، بہت زیادہ ممکن ہے POS ٹاگ اور لیمیٹ کرنا، اور بہت زیادہ پردازی کرنا۔ ان قدموں کی عملہ کرتی ہوئی ملتی زبان پیپ لین کی تعلیم کی جاتی ہے یونلوسٹ اعتمادی پروژہ کے مطابق، جس میں 50 زبانوں کے لئے وینلوسٹ کی مطابق مطابق ہے آخرین رخصت UD 2.0 میں۔ ہم نے UDPipe کو ایک آڈیٹ دکھائی، ایک ساده پائپ لین کے استعمال کرنے کے لئے CoNLL-U ورزی 2.0 فائل، جو ان کاموں کو بہت سی زبانوں کے لئے زیادہ بیرونی ڈائٹے کی ضرورت نہیں کرتی۔ ہم نے UD 2.0 کے تمام 50 زبانوں کے لئے نمونڈل پیدا کئے ہیں، اور اس کے بعد پیپ لین کو CoNLL-U فرمود میں آسان طریقے سے استعمال کر سکتا ہے. Name CoNLL 2017 میں شریک ٹاکس میں: رائ ٹکسٹ سے متعدد زبان پارسینگ یونلورڈیل اعتمادی تک، UDPipe آٹھ بہترین سیستم تھا، اور کم چلنے کے وقت اور متعدد اندازے کے مدل تک پہنچ رہے تھے.', 'vi': 'Rất nhiều công việc xử lý ngôn ngữ tự nhiên, bao gồm những công việc tiên tiến nhất, thường bắt đầu bằng vài bước xử lý cơ bản: hiệu hóa và phân loại, nhiều khả năng cũng có hiệu ứng kết quả và mô-lát, và phân tích thường xuyên. Một ống dẫn đa dạng thực hiện những bước này có thể được huấn luyện bằng dự án Đặc quyền chung, chứa ghi chú các công việc đã mô tả với 50 ngôn ngữ trong lần ra mới nhất UD 2.0. Chúng tôi sẽ cập nhật tin cập nhật cho UDPipe, một phần mềm trong việc xử lý cung cấp Colt-U phiên bản 2.0, mà thực hiện các công việc này cho nhiều ngôn ngữ mà không cần thêm dữ liệu bên ngoài. Chúng tôi cung cấp các mô hình cho mọi ngôn ngữ 50 của UD 2.0, và thêm nữa, đường ống có thể được đào tạo dễ dàng bằng dữ liệu in CoNLL-U. UDPipe là một ứng dụng đơn độc trong C+, với các nút buộc sẵn cho Python, Java, C\\ 35; và Perl. Trong Nhiệm vụ chia sẻ CONll lấy giá trị file Query: đa ngôn ngữ phân tích từ văn bản thô đến các phụ thuộc chung, UDPipe là tám hệ thống tốt nhất, trong khi đạt được thời gian chạy thấp và mô hình vừa vặn.', 'uz': "Ko'pchilik tabiiy tilni boshqarish vazifalari, eng yaxshi darajadagi vazifalar, odatda bir necha asosiy jarayonlar bilan boshlanadi - teglashtirish va segment qilish, balki ko'pchilik POS yolg'on va lematlashtirish, va oddiy vazifani ko'paytirish. Ushbu qadamlarni bajarish uchun bir necha tillar pipeline Universal Dependences Project yordamida o'rganadi. Universal Dependences Project yordamida, bu yerda eng oxirgi UD 2.0 yordamida qidirilgan 50 tillar vazifalar taʼminlovchisi mavjud. @ info Biz hamma 50 tilni UD 2.0 tilning modellarini yaratdik, va keyin esa pipelin CoNLL-U formatidagi maʼlumot yordamida oddiy foydalanish mumkin. Name 2017 CoNLL yilda Sharob qilingan vazifani: Ray Matdan Universal Dependenclariga ko'plab tillar parsing UDPip sakkiz eng eng eng eng yaxshi tizim edi, lekin ishlayotgan vaqtlarni kamaytirish va katta oʻlchami modellarni bajarish mumkin.", 'da': 'Mange naturlige sprogbehandlingsopgaver, herunder de mest avancerede, starter rutinemæssigt med flere grundlæggende behandlingstrin - tokenisering og segmentering, sandsynligvis også POS tagging og lemmatisering, og almindeligvis også parsing. En flersproget pipeline, der udfører disse trin, kan trænes ved hjælp af projektet Universal Dependences, som indeholder noteringer af de beskrevne opgaver for 50 sprog i den seneste udgave UD 2.0. Vi præsenterer en opdatering til UDPipe, en brugervenlig pipeline, der behandler CoNLL-U version 2.0-filer, som udfører disse opgaver på flere sprog uden at kræve yderligere eksterne data. Vi leverer modeller til alle 50 sprog i UD 2.0, og derudover kan pipelinen nemt trænes ved hjælp af data i CoNLL-U format. UDPipe er et selvstændigt program i C ++, med bindinger til rådighed for Python, Java, C # og Perl. I CoNLL 2017 delt opgave: Flersproget tolkning fra rå tekst til universelle afhængigheder var UDPipe det otte bedste system, samtidig med at de opnåede lave driftstider og moderat størrelse modeller.', 'bg': 'Много задачи по обработка на естествения език, включително най-напредналите, рутинно започват с няколко основни етапа на обработка - токенизация и сегментация, най-вероятно и маркиране и лематизация на ПОС, както и често анализиране. Многоезичен тръбопровод, изпълняващ тези стъпки, може да бъде обучен с помощта на проекта Универсални зависимости, който съдържа анотации на описаните задачи за 50 езика в последното издание. Представяме актуализация на прост за използване тръбопровод, който обработва файлове версия 2.0, който изпълнява тези задачи за няколко езика, без да изисква допълнителни външни данни. Ние предоставяме модели за всички 50 езика, а освен това тръбопроводът може да бъде обучен лесно с помощта на данни във формат. UDPipe е самостоятелно приложение в C++, с връзки, достъпни за Python, Java, C # и Perl. В Споделена задача: Многоезично анализиране от суров текст до универсални зависимости, беше осемте най-добри системи, като същевременно постигаше ниски работни времена и умерени модели.', 'nl': 'Veel natuurlijke taalverwerkingstaken, waaronder de meest geavanceerde, beginnen routinematig met verschillende basisverwerkingsstappen voor tokenisering en segmentatie, hoogstwaarschijnlijk ook POS-tagging en lemmatisatie, en meestal ook parsen. Een meertalige pipeline die deze stappen uitvoert, kan worden getraind met behulp van het Universal Dependencies project, dat annotaties bevat van de beschreven taken voor 50-talen in de nieuwste versie UD 2.0. We presenteren een update voor UDPipe, een eenvoudig te gebruiken pijplijn die CoNLL-U versie 2.0 bestanden verwerkt, die deze taken voor meerdere talen uitvoert zonder extra externe gegevens nodig te hebben. We bieden modellen voor alle 50-talen van UD 2.0, en bovendien kan de pijplijn gemakkelijk getraind worden met behulp van data in CoNLL-U formaat. UDPipe is een zelfstandige toepassing in C++, met bindingen beschikbaar voor Python, Java, C# en Perl. In de gezamenlijke taak CoNLL 2017: meertalige parsing van ruwe tekst naar universele afhankelijkheden, UDPipe was het acht beste systeem, terwijl lage looptijden en matige modellen werden bereikt.', 'ko': '최상급 임무를 포함한 많은 자연 언어 처리 임무는 보통 몇 가지 기본적인 처리 절차부터 시작한다. 표기화와 단락, 단어성 표기와 레몬화도 있을 수 있고 해석도 있을 수 있다.UD 2.0의 최신 버전에서 50개 언어로 설명된 작업에 대한 설명을 포함하는 UD 2.0 버전의 이 절차를 수행하는 다중 언어 파이핑을 Universal Dependencies 프로젝트에서 교육할 수 있습니다.우리는 UDPipe에 대한 업데이트를 제공했다. UDPipe는 사용하기 쉬운 파이프 처리 CoNLL-U 2.0 버전 파일로 외부 데이터가 필요하지 않은 상황에서 여러 언어에 대한 작업을 수행할 수 있다.우리는 UD 2.0의 모든 50개 언어에 모델을 제공하고 CoNLL-U 형식의 데이터로 쉽게 파이프를 훈련할 수 있다.UDPipe는 Python, Java, C# 및 Perl에 사용할 수 있는 C++의 독립된 응용 프로그램입니다.CoNLL 2017의 공유 작업: 원본 텍스트부터 일반 의존항까지의 다중 언어 해석에서 UDPipe는 8대 최고의 시스템으로 낮은 운행 시간과 중간 크기의 모델을 실현했다.', 'de': 'Viele natürliche Sprachverarbeitungsaufgaben, einschließlich der fortschrittlichsten, beginnen routinemäßig mit mehreren grundlegenden Verarbeitungsschritten der Tokenisierung und Segmentierung, höchstwahrscheinlich auch POS-Tagging und Lemmatisierung und häufig auch Parsing. Eine mehrsprachige Pipeline, die diese Schritte ausführt, kann mit dem Universal Dependencies Projekt trainiert werden, das Anmerkungen zu den beschriebenen Aufgaben für 50-Sprachen in der neuesten Version UD 2.0 enthält. Wir präsentieren ein Update für UDPipe, eine einfach zu bedienende Pipeline-Verarbeitung CoNLL-U Version 2.0 Dateien, die diese Aufgaben für mehrere Sprachen ohne zusätzliche externe Daten ausführt. Wir stellen Modelle für alle 50-Sprachen von UD 2.0 zur Verfügung, und darüber hinaus kann die Pipeline leicht mit Daten im CoNLL-U-Format trainiert werden. UDPipe ist eine eigenständige Anwendung in C++ mit Bindings für Python, Java, C# und Perl. In der CoNLL 2017 Shared Task: Mehrsprachiges Parsing von Rohtext zu Universal Dependencies war UDPipe das acht beste System bei niedrigen Laufzeiten und moderaten Modellen.', 'sw': 'Kazi nyingi za upasuaji wa lugha za asili, ikiwa ni pamoja na maendeleo zaidi, mara kwa mara huanza na hatua kadhaa za msingi za upasuaji – utoaji picha na kutengeneza vigezo, pengine pia viungo vya mkononi vya POS na unyanyasaji, na kwa kawaida pia kuchimba. Pili ya lugha nyingine inayofanya hatua hizi inaweza kufundishwa kwa kutumia Mradi wa Ulimwengu wa Kutegemea, ambayo ina matangazo ya kazi zinazoelezwa kwa lugha 50 katika kuachia UD 2.0 hivi karibuni. Tunaweza kutoa habari mpya kwa UDPipe, faili nyepesi za kutumia pipesi za kompyuta za CoNLL-U 2.0 ambazo zinafanya kazi hizi kwa lugha mbalimbali bila kuhitaji takwimu za nje. Tunatoa mifano kwa lugha zote 50 za UD 2.0, na zaidi ya hayo, pipeline inaweza kufundishwa kwa urahisi kwa kutumia taarifa katika mfumo wa CoNLL-U. UDPipe ni matumizi ya pekee katika C++, yenye viungo vinavyopatikana kwa Python, Java, C# na Perl. Katika kazi ya CoNLL 2017 ilishiriki: Uchapishaji wa lugha nyingi kutoka Maandishi ya Raw hadi Uingereza, UDPipe ilikuwa mfumo mzuri wa miaka nane, wakati huo ulifika muda mdogo unaoendelea na mifano yenye kiwango kikubwa.', 'fa': 'بسیاری از وظیفه\u200cهای پردازش زبان طبیعی، شامل ترین وضعیت\u200cهای پیشرفته\u200cترین، معمولاً با چند قدم\u200cهای پردازش بنیادی شروع می\u200cکنند - توکین\u200cسازی و بخش\u200cسازی، احتمالاً همچنین نقاشی POS و لیماتیزی، و معمولا یک لوله\u200cهای زیادی زبان که این قدم\u200cها را انجام می\u200cدهد می\u200cتواند با استفاده از پروژه اعتماد جهانی آموزش داده شود، که شامل اعلام\u200cهای کار توصیف شده برای ۵۰ زبان در آخرین آزادی UD ۲.۰ است. ما به UDPipe، یک پروندهٔ نسخه ۲.۰ پرونده\u200cهای لوله ساده برای استفاده از لوله\u200cهای راهنمایی را پیشنهاد می\u200cکنیم که این وظیفه\u200cها را برای زبانهای چندین انجام می\u200cدهد بدون نیاز به داده\u200cهای خارجی بیشتر انجام می\u200cدهد. ما مدل\u200cها را برای همه ۵۰ زبان UD ۲.۰ پیشنهاد می\u200cدهیم، و در ضمن، خط لوله می\u200cتواند با استفاده از داده\u200cها در شکل CoNLL-U به آسانی آموزش داده شود. UDPipe یک کاربرد تنهایی در C++، با پیوندهای موجود برای Python, Java, C# و Perl است. در کار مشترک CoNLL ۲۰۱۷: تحلیل زیادی زبان از متن Raw به بستگی جهانی، UDPipe هشت بهترین سیستم بود، در حالی که مدل\u200cهای پایین و مدل\u200cهای اندازه\u200cی عمومی به دست آورد.', 'id': 'Banyak tugas proses bahasa alami, termasuk tugas yang paling maju, biasanya dimulai dengan beberapa langkah proses dasar - tokenisasi dan segmentasi, kemungkinan juga POS tagging dan lemmatisasi, dan biasanya menghurai juga. Pipa berbilang bahasa yang melakukan langkah-langkah ini dapat dilatih menggunakan proyek Universal Dependencies, yang mengandung anotasi dari tugas yang diterangkan untuk 50 bahasa dalam pembebasan terbaru UD 2.0. Kami mempersembahkan pemutakhiran ke UDPipe, pemprosesan saluran pipa sederhana untuk digunakan berkas CoNLL-U versi 2.0, yang melakukan tugas ini untuk berbagai bahasa tanpa membutuhkan data eksternal tambahan. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format.  UDPipe adalah aplikasi standar dalam C++, dengan ikatan tersedia untuk Python, Java, C# dan Perl. Dalam Tugas Berkongsi CoNLL 2017: Penganalisan berbagai bahasa dari Teks Raw ke Dependensi Universal, UDPipe adalah delapan sistem terbaik, sementara mencapai waktu berjalan rendah dan model ukuran moderat.', 'sq': 'Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps - tokenization and segmentation, most likely also POS tagging and lemmatization, and commonly parsing as well.  Një tubacion shumëgjuhës që kryen këto hapa mund të trajnohet duke përdorur projektin e Varësive Universale, i cili përmban anotacione të detyrave të përshkruara për 50 gjuhë në lëshimin e fundit UD 2.0. Ne paraqesim një përditësim në UDPipe, një tubacion të thjeshtë për përdorim që proceson file CoNLL-U versioni 2.0, i cili kryen këto detyra për gjuhë të shumta pa kërkuar të dhëna shtesë të jashtme. Ne ofrojmë modele për të gjitha 50 gjuhët e UD 2.0, dhe më tepër, tubacioni mund të trajnohet lehtë duke përdorur të dhënat në format CoNLL-U. UDPipe është një aplikacion i vetmuar në C++, me lidhje në dispozicion për Python, Java, C# dhe Perl. Në detyrën e përbashkët të CoNLL 2017: analiza shumëgjuhëse nga teksti i papërdorur në varësitë universale, UDPipe ishte tetë sistemi më i mirë, duke arritur kohë të ulëta funksionimi dhe modele të madhësisë moderate.', 'am': 'ብዙ የፍጥረታዊ ቋንቋ ማቀናቀል ስራዎችን፣ አብዛኛዎቹ የበለጡትን፣ በአካባቢው የሥርዓት ደረጃዎች፣ ማስታወቂያውን እና ግንኙነትን፣ የፖএস ማተሚያ እና ማስታወቂያ እና አብዛኛውን ማጋራት እና አስተያየት ይጀምራሉ፡፡ እነዚህን እርምጃዎች የሚያደርጉ በብዙ ቋንቋዎች የፊደል ፕሮጀክት የዓለማዊ ደጋፊዎች ፕሮጀክት ሲያስተምር ይችላል፡፡ ይህ በኋለኛው ፈቃድ UD 2.0 በሚል 50 ቋንቋዎች ላይ የተዘረጉትን አድራጊዎች ያስተምራል፡፡ ወደ UDPipe አዲስ ማሻሻሻል እናደርጋለን፡፡ በUD 2.0 ቋንቋዎች ሁሉ ምሳሌዎችን እናደርጋለን፡፡ UDPipe - C++ ለPython፣ ያva፣ C# እና ፕሬል የተገኘ እስራት ነው፡፡ በCoNLL 2017 የተሰራጨ ስራዎችን: ከRaw Text to Universal Depends Multilingual Parsing, UDPipe የስምንት የበለጠ ሲስተካከል፣ ጥቂት ጊዜ እና በመካከለኛው መጠን መተላለፊያ ሞዴላዎችን አግኝቷል፡፡', 'hr': 'Mnogi prirodni zadaci obrađivanja jezika, uključujući najnaprednije, obično počinju nekoliko osnovnih koraka obrađivanja - tokenizacija i segmentacija, najvjerojatnije i označavanje POS-a i lematizacija, te uobičajeno analiziranje. Većina jezičkih cijevi koji izvode te korake mogu se obučavati koristeći projekt Univerzalne zavisnosti, koji sadrži annotacije opisanih zadataka za 50 jezika u posljednjem oslobađanju UD 2.0. Predstavljamo aktualizaciju UDPipe, jednostavnom obrađivanju cijevi za upotrebu datoteka CoNLL-U verzije 2.0, koja obavlja ove zadatke za višestruke jezike bez zahtjeva dodatnih vanjskih podataka. Mi pružamo modele svih 50 jezika UD 2.0, i dodatno, cijev linija može biti lako obučena koristeći podatke u formatu CoNLL-U. UDPipe je samostalna aplikacija u C++, s dostupnim vezama za Python, Java, C# i Perl. U CoNLL 2017. zajedničkom zadatku: multijezičko analiziranje od Raw Text do univerzalnih zavisnosti, UDPipe je bio osam najboljih sustava, dok je postigao nisko trčanje vrijeme i moderno veličine modela.', 'hy': "Շատ բնական լեզվի վերամշակման խնդիրներ, ներառյալ ամենազարգացած խնդիրները, սովորաբար սկսում են որոշ հիմնական վերամշակման քայլերով' թոկենիզացիա և սեգմետրացիա, հավանաբար նաև POS-ի նշաններ և լեմմատիզացիա, ինչպես նաև Այս քայլերը իրականացնող բազմալեզու խողովակաշար կարող է սովորեցնել օգտագործելով Universal Depndenties նախագիծը, որը պարունակում է նկարագրված խնդիրները 50 լեզու համար վերջին հրապարակում UD 2.0-ում: Մենք ներկայացնում ենք UDPipe-ի վերականգնումը, մի պարզ խողովակաշար, որը օգտագործում է CONSL-U տարբերակի 2.0 ֆայլերը, որը կատարում է այս խնդիրները բազմաթիվ լեզուներում առանց ավելին արտաքին տվյալներ պահանջելու: Մենք մոդելներ ենք տրամադրում UD 2.0 բոլոր 50 լեզուների համար, և նաև խողովակաշարը հեշտությամբ կարող է սովորեցնել օգտագործելով տվյալներ CONSL-U ֆորմատով: UDPipe-ն անկախ ծրագիր է C++-ում, որտեղ կապեր կան 2017-ի ԿՈՆԼ-ի ընդհանուր հանձնարարության մեջ՝ բազմալեզու վերլուծություն, որը սկսվում է ոչ թղթի տեքստից մինչև համաշխարհային կախվածություններ, UDPipe-ը ութ լավագույն համակարգը էր, մինչդեռ հասնում էր ցածր ընթացքի ժամանակներին և", 'af': "Baie natuurlike taal verwerking opdragte, insluitend die mees gevorderde opdragte, routineel begin deur verskeie basiese verwerking stappe - tokenisasie en segmentasie, mees waarskynlik ook POS merking en lemmatisasie, en gewoonlik verwerking ook. 'n Veelvuldige pyplyn wat hierdie stappe uitvoer kan word onderwerp word deur te gebruik van die Universele Afhanklikheidsprojek, wat bevat notasies van die beskrywe taak vir 50 tale in die nuutste verlossing UD 2.0. Ons stel 'n opdatering a an UDPipe, 'n eenvoudig na gebruik pipelyn verwerking van CoNLL-U weergawe 2.0 lêers, wat hierdie opdragte vir veelvuldige tale uitvoer sonder om eksterne eksterne data te benodig. Ons verskaf modele vir alle 50 taal van UD 2. 0, en daarna kan die pyplyn maklik opgelei word deur data in CoNLL- U formaat te gebruik. UDPipe is 'n standalone toepassing in C++, met bindings beskikbaar vir Python, Java, C# en Perl. Name In die CoNLL 2017 Gedeelde Opdrag: Veelvuldige verwerking van Raw Teks tot Universele afhangighede, UDPipe was die agt beste stelsel, terwyl die lae loop tye en moderate grootte modele bereik het.", 'bs': 'Mnogi prirodni zadaci obrađivanja jezika, uključujući najnaprednije, uobičajeno počinju nekoliko osnovnih koraka obrađivanja - tokenizacija i segmentacija, najvjerojatnije također i označavanje POS-a i lematizacija, i uobičajeno analiziranje. Većina jezičkih cijevi koji izvode te korake može se obučavati koristeći projekt Univerzalne zavisnosti, koji sadrži annotacije opisanih zadataka za 50 jezika u najnovijim oslobađanjima UD 2.0. Predstavljamo aktualizaciju UDPipe, jednostavno za upotrebu proizvodnje cijevi CoNLL-U verzije 2.0 datoteka, koja obavlja ove zadatke za višestruke jezike bez zahtjeva dodatnih vanjskih podataka. Mi pružamo modele svih 50 jezika UD 2.0, i dodatno, cijev linija može biti lako obučena koristeći podatke u formatu CoNLL-U. UDPipe je samostalna aplikacija u C++, sa dostupnim vezama za Python, Java, C# i Perl. U CoNLL 2017. zajedničkom zadatku: Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe je bio osam najboljih sustava, dok je postigao nisko trčanje vremena i moderno veličine modela.', 'az': "Birçox təbiətli dil işləmə işləri, ən ilerli işləri də dahil edərkən, çoxlu temel işləmə adımları ilə başlayırlar - tokenizacija və segmentasiya, çoxlu olaraq POS etiketi və limmatizasyonu, və çoxlu olaraq ayırılır. Bu adımları çalışan çoxlu dilli bor çizgi, dünya bağlılıqları layihəsi ilə təhsil edilə bilər, ki, son release UD 2.0 içində 50 dil üçün təfsil edilmiş işlərin açıqlaması barəsində təhsil edilir. Biz UDPipe'ə çoxlu dillər üçün bu işləri çoxlu daxil məlumatları lazım olmadan asanlıqla istifadə etmək üçün çoxlu xəta çəkirik. Biz UD 2.0 dilinin bütün 50 modellərini təmin edirik. Buna görə də, bor çizgi CoNLL-U format ında verilən məlumatları asanlıqla təhsil edilə bilər. UDPipe, Python, Java, C# və Perl üçün mövcuddur, C++'da tək başqa bir uyğulamadır. CoNLL 2017'nin paylaşılan işində: Raw Text'dən Universal Dependenciyə qədər çoxlu dil analizi, UDPipe səkkiz ən yaxşı sistem idi, düşük çalışma zamanları və orta ölçüdə modellər yetirərkən.", 'tr': "Täbiýal diller işleýän işleri, iň gelişmiş işleriň hem, diňe birnäçe temel işleýän adımlar tarapyndan başlaýarlar - tokenizat we segmentasiýa, POS etiketlemesi we limmatizaýa hem köplenç. Bu ädimleri ýerine ýetiren bir çoklu dilli pipeline Universal Dependencies Projesini ulanyp bilip biler. Bu iň soňky release UD 2.0'da 50 dillerde tassyklanan täzelikler bardyr. Biz UDPipe'e bir güncelleştirip görkezip, CoNLL-U 2.0 faýllary işlemek üçin basit bir pipeline işleýän, bu işi birnäçe diller üçin ekleýän çäreler üçin edip bilýäris. Biz UD 2.0 dilinden ähli 50 diller üçin modeller saýlaýrys we şonuň üçin pipeline CoNLL-U formatda maglumatlary ýeňil şekilde bilip biler. UDPipe, Python, Java, C# we Perl üçin bir ýeke taýdan uygulama dir. CoNLL 2017-nji ýylda Paýlaşılan Görevde: Raw Metin we Universal Dependensiýa çenli köp diller Parlamak, UDPipe 8 iň gowy sistemdi we düşük wagtlary we orta ölçü modellerini ýetirýärdi.", 'bn': 'অনেক প্রাকৃতিক ভাষা প্রক্রিয়ার কাজ, যার মধ্যে সবচেয়ে উন্নত, সাধারণত বেশ কিছু মৌলিক প্রক্রিয়ার পদক্ষেপের মাধ্যমে শুরু করে - প্রত্যাশিত এবং সংযোগ,  বিশ্ববিদ্যালয়ের নির্ভরিত প্রকল্প ব্যবহার করে একটি বহুভাষায় পাইপেলাইন প্রশিক্ষণ প্রদান করা যাবে, যার মধ্যে সাম্প্রতিক মুক্তির মধ্যে ৫০ ভাষার আমরা ইউডিপিপিপে একটি আপডেট উপস্থাপন করি, একটি সহজ- ব্যবহার করা পাইপেলাইন প্রক্রিয়া কএনএল-U সংস্করণ ২. ০ ফাইল, যা বাইরের তথ্য প্রয়োজন না করে বেশ কিছু ভাষার জন আমরা ইউডি ২. ০ এর সকল ৫০ ভাষার জন্য মডেল প্রদান করি এবং এছাড়াও পাইপেলাইন কনএল-ইউ ফর্ম্যাটে তথ্য ব্যবহার করে সহজে প্রশিক্ষণ করা যাবে। ইউডিপিপি সি+ এ একটি স্থানীয় অ্যাপ্লিকেশন, যার জন্য পাইথন, জাভা, C# এবং পার্ল বাইন্ডিং আছে। কএনএল ২০১৭ সালে শেয়ার করা কাজ: রাও টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভরশীল পর্যন্ত মাল্টিভাষার পার্জিং ইউডিপিপি ছিল আটটি সেরা সিস্টেম, য', 'ca': "Moltes tasques naturals de processament de llenguatges, incloent les més avançades, comencen rutinàriament per diverses etapes bàsiques de processament - fitogenització i segmentació, probablement també etiquetage POS i lemmatització, i també normalment analitzar. Un pipeline multilingüe que fa aquestes etapes es pot formar fent servir el projecte Universal Dependencies, que conté anotacions de les tasques descrites per 50 llengües en la última versió UD 2.0. Presentam una actualització a UDPipe, un producte simple de processament de tubs CoNLL-U versió 2.0, que fa aquestes tasques per múltiples llengües sense requerir dades externes adicionals. Proporcionem models per a totes les 50 llengües d'UD 2.0, i a més, el pipeline pot ser entrenat fàcilment utilitzant dades en format CoNLL-U. UDPipe és una aplicació independent en C++, amb vincles disponibles per Python, Java, C# i Perl. En la tasca compartida CoNLL 2017: Analització multillengua des del text brut a les Dependencies Universals, UDPipe va ser el vuit millor sistema, aconseguint temps de funcionament baixos i models de mida moderada.", 'cs': 'Mnoho úloh zpracování přirozeného jazyka, včetně těch nejpokročilejších, běžně začíná několika základními kroky zpracování tokenizace a segmentace, s největší pravděpodobností také POS tagování a lemmatizace a běžně také parsování. Vícejazyčné potrubí provádějící tyto kroky lze trénovat pomocí projektu Universal Dependencies, který obsahuje anotace popsaných úloh pro 50 jazyky v nejnovější verzi UD 2.0. Představujeme aktualizaci UDPipe, jednoduché potrubí zpracovávající CoNLL-U verze 2.0 soubory, které tyto úlohy provádí pro více jazyků bez nutnosti dalších externích dat. Poskytujeme modely pro všechny 50-jazyky UD 2.0 a navíc lze potrubí snadno trénovat pomocí dat ve formátu CoNLL-U. UDPipe je samostatná aplikace v C++, s vazbami dostupnými pro Python, Java, C# a Perl. Ve sdíleném úkolu CoNLL 2017: Vícejazyčné analýzy od systému Raw Text do univerzálních závislostí byl UDPipe osm nejlepších systémů, přičemž dosahoval nízkých časů provozu a modelů středně velkých.', 'fi': 'Monet luonnollisen kielen käsittelytehtävät, mukaan lukien edistyneimmät, alkavat rutiininomaisesti useista peruskäsittelyvaiheista - tokenisoinnista ja segmentoinnista, todennäköisimmin myös POS-tunnisteista ja lemmatisoinnista sekä yleisesti myös jäsentämisestä. Nämä vaiheet suorittava monikielinen putkisto voidaan kouluttaa käyttämällä Universal Dependences -projektia, joka sisältää huomautuksia 50 kielen tehtävistä viimeisimmässä UD 2.0 -julkaisussa. Esittelemme päivityksen UDPipeen, helppokäyttöiseen putkistoon, joka käsittelee CoNLL-U version 2.0 tiedostoja, joka suorittaa nämä tehtävät useilla kielillä ilman ulkoisia lisätietoja. Tarjoamme malleja kaikille UD 2.0:n 50 kielelle, ja lisäksi putkisto voidaan kouluttaa helposti CoNLL-U-formaatin tietojen avulla. UDPipe on itsenäinen sovellus C++, jossa on sidoksia saatavilla Pythonille, Java, C# ja Perl. CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependences -julkaisussa UDPipe oli kahdeksan parasta järjestelmää, mutta saavutti alhaiset käyttöajat ja kohtalaisen kokoiset mallit.', 'et': 'Paljud looduskeele töötlemise ülesanded, sealhulgas kõige arenenumad, algavad tavaliselt mitme põhitegevuse etapiga - tokeniseerimine ja segmenteerimine, tõenäoliselt ka POS sildistamine ja lemmatiseerimine ning tavaliselt ka parsimine. Neid samme täitvat mitmekeelset torujuhet saab koolitada, kasutades projekti Universaalsed sõltuvused, mis sisaldab viimases versioonis UD 2.0 kirjeldatud ülesannete märkusi 50 keele kohta. Tutvustame UDPipe värskendust, lihtsalt kasutatav torustik töötleb CoNLL-U versiooni 2.0 faile, mis täidab neid ülesandeid mitmes keeles ilma täiendavate välisandmete nõudmiseta. Pakume mudeleid UD 2.0 kõigile 50 keelele ja lisaks saab torujuhtme lihtsalt koolitada, kasutades andmeid CoNLL-U formaadis. UDPipe on eraldiseisev rakendus C++, sidudega saadaval Python, Java, C# ja Perl. CoNLL 2017. aasta jagatud ülesandes: mitmekeelne parsimine toortekstist universaalsete sõltuvusteni oli UDPipe kaheksa parimat süsteemi, saavutades samas madala tööaja ja mõõduka suurusega mudeleid.', 'jv': 'ProgressBarUpdates Awak dhéwé multilangkung piwat nggawe barang iki iso nggawe ngubah perusahaan Universal Dehendikulti, sing nduwe akeh nyong nggawe gerasane nggawe perusahaan kanggo soko perusahaan langkung sampek kanggo nyenggawe udah 2.0. Awak dhéwé ngéwanggal Négandik kanggo udPipe, sampeyan-ngéwanggal kanggo nggunakake perusahaan koNLL-U versi 2.0 Berusahaan Awak dhéwé ngewehke model kanggo sampeyan gak peduté karo urip UT 2.0 lan uga sampeyan, ginarangke iso disenyakake data ning format CoNLL-U Language Nang CoNLL 1997 Sampeyan Taaksi: Multi-Lingui Parasing sing suku Pindah Tekst Sampeyan Universal, udPipe kuwi sistem sing gawe isih sing luwih apik, sampeyan nguasai kapan lanjut sampeyan sakjane model sing paling maneh lanjut.', 'ha': "Akwai masu aiki na zartar da harshen aiki masu natura, ikin waɗanda suka fi zamanta, ana fara a bayani da wasu hanyõyi masu aikin aiki masu bastarwa - bonofati da surori, ko da sannan akwai tagogi da salimi na PoS, kuma yana yin parse da kawaici. An sanar da wani pipe na mulki-lingui wanda ke aikata waɗannan hanyõyin, za'a yi amfani da shirin Projeya Universal Deputs, wanda ke ƙunsa da sunan zane wa aikin da aka bayyana wa masu 50 harshen cikin fassaran a ƙarshe na UD 2.0. Tuna gaurar da wani takarda zuwa UD-ipe, wata fayil mai sauƙi da za'a yi amfani da pibleine na CoNLL-U version 2.0, wanda ke aikata wannan aikin wa wasu harshen daban-daban, bã da ƙayyade data masu ƙarai ba. Mu ƙayyade misãlai ga duk harshen UD 2.0, kuma a ƙara wannan, za'a iya amfani da misalin pilin da sauƙi cikin tsarin CoNLL-U. @ info: status In the CoNLL 2017 Shared Takar: Fara multilinguin parse from Raw Text to Universal Dekurs, UP was the 8 best system, while he achieved lower run time and size moderate.", 'sk': 'Številna opravila obdelave naravnega jezika, vključno z najnaprednejšimi, se rutinsko začnejo z več osnovnimi koraki obdelave - žetonizacija in segmentacija, najverjetneje tudi označevanje POS in lemmatizacija ter običajno tudi razčlenitev. Večjezični cevovod, ki izvaja te korake, lahko usposabljate s projektom Univerzalne odvisnosti, ki vsebuje opombe opisanih opravil za 50 jezikov v zadnji izdaji UD 2.0. Predstavljamo posodobitev UDPipe, preprostega za uporabo cevovoda, ki obdeluje datoteke CoNLL-U različice 2.0, ki opravlja ta opravila za več jezikov brez potrebe po dodatnih zunanjih podatkih. Ponujamo modele za vseh 50 jezikov UD 2.0, poleg tega pa je cevovod mogoče enostavno usposabljati z uporabo podatkov v formatu CoNLL-U. UDPipe je samostojna aplikacija v C++, z vezavami na voljo za Python, Java, C# in Perl. V skupni nalogi CoNLL 2017: večjezično razčlenjeno besedilo od surovega besedila do univerzalnih odvisnosti je bil UDPipe osem najboljših sistemov, hkrati pa je dosegel nizek čas delovanja in zmerno velike modele.', 'he': 'הרבה משימות עיבוד שפת טבעיות, כולל המשימות הכי מתקדמות, מתחילות בדרך כלל על ידי כמה צעדים עיבוד בסיסיים - טוקניזציה וסגמנציה, סביר להניח שגם תווים POS ולימטיזציה, וגם בדיקת בדרך כלל. צינור רב-שפתי שמבצע את הצעד הזה יכול להיות מאומן באמצעות פרויקט "תלויות יוניברסליות", שמכיל הערות על המשימות המתאורות עבור 50 שפות בשחרור האחרון UD 2.0. אנו מציגים עדכון לאודפייפ, שימוש בצינור פשוט-לשימוש מעבד קובצים CoNLL-U גרסה 2.0, שמבצע את המשימות הללו למספר שפות מבלי לדרוש נתונים חיצוניים נוספים. אנחנו מספקים דוגמנים לכל 50 שפות של UD 2.0, וחוץ מזה, הצינור יכול להיות מאומן בקלות באמצעות נתונים בצורה CoNLL-U. UDPipe הוא יישום בודד ב- C++, עם קשרים זמינים עבור Python, Java, C# ופרל. במשימה המשותפת של CoNLL 2017: בדיקת רבות שפות מתוך טקסט ראש לתיכונות Universal, UDPipe היה שמונה המערכת הטובה ביותר, בעוד השיגה זמנים רץ נמוכים ומודלים בגודל מוביל.', 'bo': 'རང་བཞིན་གྱི་སྐད་ཡིག་ལས་སྦྱོར་ཀྱི་བྱ་འགུལ་ལ་མང་པོ་ཞིག་ནི་མཐོ་རིམ་མང་ཆེ་ཤོས་ཀྱི་འགོ་བཙུགས་ཡོད། A multilingual pipeline performing these steps can be trained using the Universal Dependencies project, which contains annotations of the described tasks for 50 languages in the latest release UD 2.0. We present an update to UDPipe, a simple-to-use pipeline processing CoNLL-U version 2.0 files, which performs these tasks for multiple languages without requiring additional external data. We provide models for all 50 languages of UD 2.0, and furthermore, the pipeline can be trained easily using data in CoNLL-U format. UDPipe is a standalone application in C++, with bindings available for Python, Java, C# and Perl. CoNLL 2017 དེ་མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་ནང་དུ། Raw Text ལས་ཡིག་ཆ་འཕྲིན་ལ་ཡོངས་རྫོགས་གནང་བ་རེད། UDPipe་ནི་འཛམ་གླིང་གི་མ་ལག་གི་༨་རེད་དུས་ཚོད་ལྟར'}
{'en': 'UParse : the Edinburgh system for the CoNLL 2017 UD shared task', 'ar': 'UParse: نظام إدنبرة للمهمة المشتركة CoNLL 2017 UD', 'pt': 'UParse: o sistema de Edimburgo para a tarefa compartilhada CoNLL 2017 UD', 'fr': "UpArse\xa0: le système d'Edimbourg pour la tâche partagée ConLL 2017 UD", 'es': 'uParse: el sistema de Edimburgo para la tarea compartida de CoNll 2017 UD', 'ja': 'UParse ： CoNLL 2017 UD共有タスクのエディンバラシステム', 'zh': 'UParse:CoNLL 2017 UD共爱丁堡统', 'hi': 'UParse: CoNLL 2017 UD साझा कार्य के लिए एडिनबर्ग प्रणाली', 'ru': 'UParse: Эдинбургская система для совместной задачи CoNLL 2017 UD', 'ga': 'UParse: córas Dhún Éideann do thasc roinnte CoNLL 2017 UD', 'ka': 'UParse: ვებინდონის სისტემა CoNLL 2017 UD დაყოფილი საქმე', 'hu': 'UParse: az Edinburgh rendszer a CoNLL 2017 UD megosztott feladatához', 'el': 'UParse: το σύστημα του Εδιμβούργου για το κοινό έργο του CoNLL 2017 UD', 'it': 'UParse: il sistema di Edimburgo per il compito condiviso CoNLL 2017 UD', 'kk': 'UParse: CoNLL 2017 UD ортақ тапсырманың Эдинбург жүйесі', 'mk': 'УПАРС: Единбуршкиот систем за заедничката задача на УД CoNLL 2017', 'lt': 'UParse: Edinburgo sistema, skirta 2017 m. bendros UD užduotims', 'ml': 'UParse: the Edinburgh system for the CoNLL 2017 UD shared task', 'mn': 'UParse: Эдинбургийн систем 2017 оны CoNLL-ын UD хуваалцах ажил', 'no': 'UParse: Edinburgh system for CoNLL 2017 UD delt oppgåve', 'pl': 'UParse: system Edynburga dla wspólnego zadania CoNLL 2017 UD', 'ro': 'UParse: sistemul Edinburgh pentru sarcina comună CoNLL 2017 UD', 'si': 'UPARE: CoNLL 2017 UD එක්ක කාර්යය සඳහා එඩිබර්න් පද්ධතිය', 'sr': 'UParse: Edinburgov sistem za zajednièki zadatak CoNLL 2017.', 'so': 'UParse: nidaamka Edinburgh ee CoNLL 2017 UD shaqo qayb ah', 'sv': 'UParse: Edinburgh-systemet för CoNLL 2017 UD delad uppgift', 'ms': 'UParse: sistem Edinburgh untuk tugas kongsi UD CoNLL 2017', 'mt': 'UParse: is-sistema ta’ Edinburgh għall-kompitu komuni tal-UD CoNLL 2017', 'ta': 'UParse: CoNLL 2017 UD பகிர்ந்த பணிக்கான Edinburgh அமைப்பு', 'ur': 'UParse: CoNLL 2017 UD شریک کام کے لئے ادینڈمبر سیسٹم', 'uz': 'UParse: CoNLL 2017 UD bilan birlashtirilgan vazifa uchun Edinburgh tizimi', 'vi': 'UPass: hệ thống Edingurgg for the CoNLL bây bây giờ UD Name', 'bg': 'Обща задача: Единбургската система за съвместната задача на СД за 2017 г.', 'da': 'UParse: Edinburgh-systemet for CoNLL 2017 UD delt opgave', 'nl': 'UParse: het Edinburgh systeem voor de gezamenlijke taak CoNLL 2017 UD', 'hr': 'UParse: Edinburgov sustav za zajednički zadatak CoNLL 2017.', 'de': 'UParse: das Edinburgh System für die gemeinsame Aufgabe CoNLL 2017 UD', 'ko': 'Uparse: CoNLL 2017 UD가 작업을 공유하는 에든버러 시스템', 'id': 'UParse: sistem Edinburgh untuk tugas kongsi CoNLL 2017 UD', 'sw': 'UParse: Mfumo wa Edinburgh wa CoNLL 2017 UD ulishiriki kazi', 'tr': "UPARS: CoNLL 2017 UD'yň CoNLL sistemi üçin beýleki zady", 'af': 'UParse: die Edinburgh stelsel vir die CoNLL 2017 UD deel taak', 'am': 'UParse: CoNLL 2017 የኤዲንቡር ስርዓት ተካፈለ', 'hy': 'UPARS. Էդինբուրգի համակարգը 2017-ի ԿոնԼԼ ԱՄՆ-ի ընդհանուր հանձնարարության համար', 'sq': 'UParse: Sistemi i Edinburgut për detyrën e përbashkët të CoNLL 2017 UD', 'bn': 'ইউপার্স: কনএল ২০১৭ সালে ইউডি কাজ শেয়ার করেছেন এডিনবার্গ সিস্টেম', 'az': 'UParse: CoNLL 2017 UD şəkli iş üçün Edinburgh sistemi', 'bs': 'UParse: Edinburgov sistem za zajednički zadatak CoNLL 2017.', 'cs': 'UParse: Edinburghský systém pro sdílený úkol CoNLL 2017 UD', 'et': 'UParse: Edinburghi süsteem CoNLL 2017 UD jagatud ülesande jaoks', 'ca': "UParse: el sistema d'Edimburgue per a la tasca compartida de l'UD CoNLL 2017", 'fi': 'UParse: Edinburghin järjestelmä CoNLL 2017 UD jaettua tehtävää varten', 'fa': 'UParse: سیستم ادینبرگ برای کار مشترک UD CoNLL 2017', 'jv': 'Pakarsa: siji-siji Ubuntu kanggo kowe CoNLL 1997 udah nang task dikarolan', 'ha': 'UParse: the edinburg system for the CoNLL 2017 UD share job', 'he': 'UParse: מערכת אדינבורג עבור המשימה המשותפת של CoNLL 2017 UD', 'sk': 'UParse: Edinburghski sistem za skupno nalogo UD CoNLL 2017', 'bo': 'UParse: CoNLL 2017 UD མཉམ་སྤྱོད་གྱི་Edinburgh system for the CoNLL 2017 UD shared task'}
{'en': 'This paper presents our submissions for the CoNLL 2017 UD Shared Task. Our parser, called UParse, is based on a neural network graph-based dependency parser. The parser uses features from a bidirectional LSTM to to produce a distribution over possible heads for each word in the sentence. To allow transfer learning for low-resource treebanks and surprise languages, we train several multilingual models for related languages, grouped by their genus and language families. Out of 33 participants, our system achieves rank 9th in the main results, with 75.49 UAS and 68.87 LAS F-1 scores (average across 81 treebanks).', 'ar': 'تقدم هذه الورقة التقديمات الخاصة بنا للمهمة المشتركة CoNLL 2017 UD. المحلل اللغوي الخاص بنا ، المسمى UParse ، يعتمد على محلل تبعية يعتمد على الرسم البياني للشبكة العصبية. يستخدم المحلل اللغوي ميزات من LSTM ثنائي الاتجاه لإنتاج توزيع على الرؤوس المحتملة لكل كلمة في الجملة. للسماح بنقل التعلم لضفاف الأشجار منخفضة الموارد واللغات المفاجئة ، نقوم بتدريب العديد من النماذج متعددة اللغات للغات ذات الصلة ، مجمعة حسب جنسهم وعائلاتهم اللغوية. من بين 33 مشاركًا ، حقق نظامنا المرتبة التاسعة في النتائج الرئيسية ، مع 75.49 UAS و 68.87 LAS F-1 (المتوسط عبر 81 ضفافًا للأشجار).', 'pt': 'Este documento apresenta nossas submissões para a Tarefa Compartilhada CoNLL 2017 UD. Nosso analisador, chamado UParse, é baseado em um analisador de dependência baseado em gráfico de rede neural. O analisador usa recursos de um LSTM bidirecional para produzir uma distribuição sobre possíveis cabeças para cada palavra na frase. Para permitir o aprendizado de transferência para bancos de árvores de poucos recursos e idiomas surpresa, treinamos vários modelos multilíngues para idiomas relacionados, agrupados por gênero e famílias linguísticas. Dos 33 participantes, nosso sistema alcança a 9ª posição nos principais resultados, com 75,49 UAS e 68,87 LAS F-1 (média em 81 treebanks).', 'fr': "Cet article présente nos soumissions pour la tâche partagée ConLL 2017 UD. Notre analyseur, appelé UpParse, est basé sur un analyseur de dépendances basé sur un graphe de réseau neuronal. L'analyseur utilise les caractéristiques d'un LSTM bidirectionnel pour produire une distribution sur les têtes possibles pour chaque mot de la phrase. Pour permettre l'apprentissage par transfert pour les banques d'arbres à faibles ressources et les langues surprises, nous formons plusieurs modèles multilingues pour des langues apparentées, regroupées par genre et familles de langues. Sur 33 participants, notre système atteint le 9e rang dans les résultats principaux, avec 75,49 scores UAS et 68,87 LAS F-1 (moyenne sur 81 banques d'arbres).", 'es': 'Este documento presenta nuestras propuestas para la tarea compartida de la UD de CoNll 2017. Nuestro analizador, llamado uParse, se basa en un analizador de dependencias basado en gráficos de redes neuronales. El analizador utiliza características de un LSTM bidireccional para producir una distribución sobre posibles cabezas para cada palabra de la oración. Para permitir la transferencia de aprendizaje para bancos de árboles de bajos recursos e idiomas sorpresa, capacitamos varios modelos multilingües para idiomas relacionados, agrupados por género y familias lingüísticas. De los 33 participantes, nuestro sistema alcanza el noveno lugar en los resultados principales, con 75,49 puntajes UAS y 68,87 LAS F-1 (promedio en 81 bancos de árboles).', 'ja': '本稿では、CoNLL 2017 UD Shared Taskのための提出物を紹介します。UParseと呼ばれる当社の構文解析器は、ニューラルネットワークグラフベースの依存関係構文解析器に基づいています。構文解析器は、双方向LSTMからへの機能を使用して、文の各単語の可能なヘッドにわたる分布を生成する。低資源のツリーバンクとサプライズ言語のための転送学習を可能にするために、関連する言語のためのいくつかの多言語モデルを、その属と言語ファミリーによってグループ化してトレーニングします。33人の参加者のうち、当社のシステムは主な結果で9位を達成し、75.49 UASと68.87 LAS F -1スコア（ 81ツリーバンクの平均）を達成しています。', 'zh': '本文引我为CoNLL 2017 UD共其任。 吾解析器谓之UParse,盖神经网络图之所恃解析器。 解析器用自双向 LSTM ,句中单词生。 为许低资源树库惊喜语迁学,相关言语数般言语,随其属语家分组。 33名参与者中,系统排名第9位,75.49 UAS68.87 LAS F-1分数(81个树岸之平均值)。', 'hi': 'यह पेपर CoNLL 2017 UD Shared Task के लिए हमारी प्रस्तुतियाँ प्रस्तुत करता है। हमारा पार्सर, जिसे UParse कहा जाता है, एक तंत्रिका नेटवर्क ग्राफ-आधारित निर्भरता पार्सर पर आधारित है। पार्सर वाक्य में प्रत्येक शब्द के लिए संभावित सिर पर एक वितरण का उत्पादन करने के लिए एक द्विदिश LSTM से सुविधाओं का उपयोग करता है। कम-संसाधन ट्रीबैंक और आश्चर्य भाषाओं के लिए स्थानांतरण सीखने की अनुमति देने के लिए, हम संबंधित भाषाओं के लिए कई बहुभाषी मॉडलों को प्रशिक्षित करते हैं, जो उनके जीनस और भाषा परिवारों द्वारा समूहीकृत होते हैं। 33 प्रतिभागियों में से, हमारी प्रणाली 75.49 यूएएस और 68.87 एलएएस एफ -1 स्कोर (81 ट्रीबैंक में औसत) के साथ मुख्य परिणामों में 9 वें स्थान पर पहुंच ती है।', 'ru': 'В этой статье представлены наши материалы для совместной задачи CoNLL 2017 UD. Наш парсер, называемый UParse, основан на нейросетевом графовом парсере зависимостей. Синтаксический анализатор использует функции из двунаправленного LSTM в, чтобы получить распределение по возможным головам для каждого слова в предложении. Чтобы обеспечить возможность трансферного обучения для малоресурсных древовидных банков и языков-сюрпризов, мы обучаем несколько многоязычных моделей для родственных языков, сгруппированных по их роду и языковым семьям. Из 33 участников наша система достигает 9-го места в основных результатах, набрав 75,49 баллов UAS и 68,87 баллов LAS F-1 (в среднем по 81 бэнку деревьев).', 'ga': 'Cuireann an páipéar seo ár n-aighneachtaí i láthair do Thasc Comhroinnte UD CoNLL 2017. Tá ár parsálaí, ar a dtugtar UParse, bunaithe ar pharsálaí spleáchais graf-bhunaithe líonra néar. Úsáideann an parsálaí gnéithe ó LSTM déthreoch chun dáileadh a dhéanamh thar chinn fhéideartha do gach focal san abairt. Chun foghlaim aistrithe a cheadú do chrainn chrainn acmhainní ísle agus teangacha iontasacha, déanaimid oiliúint ar roinnt samhlacha ilteangacha do theangacha gaolmhara, arna ngrúpáil de réir a géineas agus a dteaghlaigh teanga. As 33 rannpháirtí, baineann ár gcóras 9ú háit amach sna príomhthorthaí, le 75.49 scóir UAS agus 68.87 scóir LAS F-1 (meán thar 81 banc crann).', 'el': 'Η παρούσα εργασία παρουσιάζει τις αιτήσεις μας για την κοινή εργασία του CoNLL 2017 UD. Ο αναλυτής μας, που ονομάζεται UParse, βασίζεται σε έναν αναλυτή εξάρτησης νευρωνικού δικτύου βασισμένο σε γραφήματα. Ο αναλυτής χρησιμοποιεί χαρακτηριστικά από μια αμφίδρομη LSTM για να παράγει μια κατανομή πάνω από πιθανές κεφαλές για κάθε λέξη της πρότασης. Για να επιτρέψουμε τη μάθηση μεταφοράς για δεντράκια χαμηλού πόρου και γλώσσες έκπληξης, εκπαιδεύουμε πολλά πολύγλωσσα μοντέλα για σχετικές γλώσσες, ομαδοποιημένα ανά γένος και γλωσσικές οικογένειες. Από τους 33 συμμετέχοντες, το σύστημά μας επιτυγχάνει 9η θέση στα κύρια αποτελέσματα, με 75.49 UAS και 68.87 LAS F-1 βαθμολογίες (μέσος όρος σε 81 δένδρες).', 'ka': 'ეს დოკუნტი ჩვენი მომხმარება CoNLL 2017-ის UD საზოგადომი დავალებისთვის. ჩვენი პანელიზერი, UParse-ის სახელი, ნეიროლური ქსელის დაფართობის დასაწყებელობის პანელიზერზე დაბაზია. პანსერტი გამოყენებს ბედირექციონალური LSTM-ის განსაზღვრება, რომ ყველა სიტყვის ყველა სიტყვის განსაზღვრება შესაძლებელია. რომელსაც მინუს რესურსისების საბოლოს და განაცემების ენებისთვის გასწავლა, ჩვენ მრავალენგური მოდელების გასწავლავთ, რომელსაც შესაბამისი ენებისთვის და ენების ოჯახების 33 მოთავსწავლებელიდან ჩვენი სისტემა მიიღება პირველი წინაღებში 9-ი წინაღება, 75,49 UAS და 68,87 LAS F-1 წინაღებებით (სისტემა 81 წინაღებში).', 'it': "Questo articolo presenta i nostri contributi per il CoNLL 2017 UD Shared Task. Il nostro parser, chiamato UParse, si basa su un parser di dipendenza basato su grafici di rete neurale. Il parser utilizza funzionalità di un LSTM bidirezionale per produrre una distribuzione su possibili teste per ogni parola della frase. Per consentire l'apprendimento di trasferimento per banchi di alberi a basso contenuto di risorse e lingue a sorpresa, addestriamo diversi modelli multilingue per lingue correlate, raggruppati per genere e famiglie linguistiche. Su 33 partecipanti, il nostro sistema raggiunge il 9 ° posto nei risultati principali, con 75,49 UAS e 68,87 LAS F-1 punteggi (media su 81 banchi degli alberi).", 'kk': 'Бұл қағаз біздің CoNLL 2017 жылы UD ортақтастырылған тапсырманың жіберімізді көрсетеді. UParse деген парзеріміз неврал желінің графикалық тәуелдік талдаушына негізделген. Пансор сөздердің әрбір сөздерінің үлестірімін жасау үшін қолданылады. Төмен ресурс құрылғылар мен ауырмашылық тілдер үшін оқытуға мүмкіндік беру үшін бірнеше тілдер үшін бірнеше тіл үлгілерін оқыту үшін, олардың гені мен тіл үйлері бойынша топтастыр 33 қатысушылардан біздің жүйеміз негізгі нәтижелерде 9-нәтижелерді жеткізеді, 75,49 UAS және 68,87 LAS F-1 нәтижелері (орташа 81 жақсы жақсы).', 'hu': 'Ez a tanulmány bemutatja a CoNLL 2017 UD megosztott feladatra vonatkozó beadványainkat. Az UParse nevű elemzőnk egy neurális hálózati gráf alapú függőségi elemzőn alapul. Az elemző a kétirányú LSTM funkcióit használja, hogy eloszlást hozzon létre a mondat minden egyes szójához. Annak érdekében, hogy lehetővé tegyük az alacsony erőforrású faalakok és meglepetés nyelvek transzfertanulását, többnyelvű modellt képzünk a rokon nyelvek számára, nemzetségük és nyelvcsaládjaik szerint csoportosítva. A 33 résztvevő közül rendszerünk a 9. helyezést ér el a fő eredmények között, 75,49 UAS és 68,87 LAS F-1 pontszámmal (átlagosan 81 fapadon).', 'mk': 'Овој весник ги претставува нашите поднесувања за заедничката задача на CoNLL 2017. Нашиот анализатор, наречен UParse, е базиран на анализатор на зависност на нервната мрежа базиран на график. Анализаторот ги користи карактеристиките од двојно LSTM за да создаде дистрибуција над можните глави за секој збор во реченицата. To allow transfer learning for low-resource treebanks and surprise languages, we train several multilingual models for related languages, grouped by their genus and language families.  Од 33 учесници, нашиот систем постигна 9-ти ранг во главните резултати, со 75,49 УАС и 68,87 ЛАС Ф-1 резултати (просечно низ 81 дрвја).', 'ms': 'Kertas ini memperkenalkan penghantaran kami untuk Tugas Berkongsi UD CoNLL 2017. Penghurai kami, dipanggil UParse, berdasarkan penghurai dependensi rangkaian saraf berdasarkan graf. The parser uses features from a bidirectional LSTM to to produce a distribution over possible heads for each word in the sentence.  Untuk membenarkan pemindahan belajar untuk pangkalan pokok sumber rendah dan bahasa kejutan, kami melatih beberapa model berbilang bahasa untuk bahasa berkaitan, dikumpulkan oleh jenis dan keluarga bahasa mereka. Dari 33 peserta, sistem kami mencapai peringkat ke-9 dalam hasil utama, dengan 75.49 UAS dan 68.87 skor F-1 LAS (rata-rata di 81 pangkat pokok).', 'ml': 'ഈ പത്രത്തില്\u200d കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കെടുത്ത ജോലിക്ക് ഞങ്ങളുടെ കീഴ്പ്പെടുത്തിയിരിക്കുന്നു. യുപാര്\u200dസ് എന്ന പേരുള്ള നമ്മുടെ പരാജയപ്രകാരം, ന്യൂറല്\u200d നെറ്ററല്\u200d നെറ്റോവര്\u200dക്ക് ഗ്രാഫ് അടിസ്ഥാനത്തിലാണ വാക്കിലുള്ള ഓരോ വാക്കുകള്\u200dക്കും വിതരണം വരുത്തുവാന്\u200d സാധ്യതയുള്ള തലക്കുകള്\u200dക്കുമേല്\u200d വിതരണം കൊടുക്കുന്നതിനായ കുറഞ്ഞ വിഭവങ്ങള്\u200d ട്രീബാങ്കുകള്\u200dക്കും അത്ഭുതപ്പെട്ട ഭാഷകള്\u200dക്കും പഠിക്കാന്\u200d അനുവദിക്കാന്\u200d, നമ്മള്\u200d പല ഭാഷകള്\u200dക്കും പരിശീലനം നല്\u200dകു 33 പങ്കാളികളില്\u200d നിന്നും ഞങ്ങളുടെ സിസ്റ്റത്തില്\u200d പ്രധാനഫലങ്ങളില്\u200d 9ആം നിലവില്\u200d എത്തുന്നു. 75. 49 UAS, 68. 87 ലാസ് F-1 സ്കോര്\u200dട്ടും ഉള്ളതാണ്.', 'mn': 'Энэ цаас 2017 оны CoNLL-ын UD хуваалцааны ажлын хувьд бидний нийтлэл дэвшүүлдэг. UParse гэдэг мэргэжилтэн нь мэдрэлийн сүлжээний график дээр хамааралтай хуваалцагч дээр суурилсан. Тайлбар нь өгүүлбэр бүрийн үг бүрт хуваарилалтыг бүтээхэд хоёр давхар LSTM-ээс ашигладаг. Бага боловсролын зам болон гайхамшигтай хэлд суралцах боломж олгохын тулд бид олон хэл загварыг холбоотой хэлд суралцах, жинхэнэ болон хэл гэр бүлийн бүлэгтэй бүлэгтэй. 33 оролцогчдын хувьд бидний систем үндсэн үр дүн дээр 9-р дүн гарч ирдэг. 75.49 UAS болон 68.87 LAS F-1 оноо (дундаж 81 дагуулын дундаж).', 'no': 'Denne papiret viser våre tilsendingar for CoNLL 2017 UD-delt oppgåve. Tolkaren vårt, kalla UParse, er basert på eit neiralnettverksgraf-basert avhengighetsanalyser. Tolkaren brukar funksjonar frå ein bidireksjonal LSTM for å produsera ein distribusjon over moglege hoder for kvar ord i setninga. For å tillata læring av overføringar for låg ressurstrykk og overraska språk, treng vi fleire fleire språk-modeller for tilhøyrande språk, gruppere av sine gener og språk-familier. Ut 33 deltakarar oppnår systemet vårt rank 9 i hovudresultatene, med 75,49 UAS og 68,87 LAS F-1-poeng (gjennomsnittlig over 81 treebank).', 'mt': 'Dan id-dokument jippreżenta s-sottomissjonijiet tagħna għall-Kompitu Konġunt tal-UD CoNLL 2017. Il-analizzatur tagħna, imsejjaħ UParse, huwa bbażat fuq analizzatur tad-dipendenza tan-netwerk newrali bbażat fuq grafika. Il-analizzatur juża karatteristiċi minn LSTM bidirezzjonali biex jipproduċi distribuzzjoni fuq ir-ras possibbli għal kull kelma fis-sentenza. Biex nippermettu t-trasferiment tat-tagħlim għal banek tas-siġar b’riżorsi baxxi u lingwi sorpriżi, aħna nħarrġu diversi mudelli multilingwi għal lingwi relatati, raggruppati skont il-ġeneru u l-familji lingwistiċi tagħhom. Minn 33 parteċipant, is-sistema tagħna tikseb id-disa’ grad fir-riżultati ewlenin, b’75.49 UAS u 68.87 punteġġ F-1 tal-LAS (medja fuq 81 bank tas-siġar).', 'lt': 'Šiame dokumente pateikiami mūsų pasiūlymai dėl 2017 m. bendros UD užduoties. Mūsų analizatorius, vadinamas UParse, grindžiamas nervinio tinklo priklausomybės analizatoriumi. Analizatorius naudoja dvikrypčių LSTM savybes, kad kiekvienam sakinyje esančiam žodžiui būtų galima paskirstyti galimas galvas. Kad būtų galima perkelti mokymąsi mažai išteklių turintiems medžių pagrindams ir stebuklingoms kalboms, rengiame kelis daugiakalbius susijusių kalbų modelius, suskirstytus pagal jų giminę ir kalbų šeimas. Iš 33 dalyvių mūsų sistema pasiekia 9-ąjį lygį pagrindiniuose rezultatuose, o 75,49 UAS ir 68,87 LAS F-1 rezultatai (vidutiniškai 81 medžio bankuose).', 'pl': 'Niniejszy artykuł prezentuje nasze zgłoszenia dotyczące wspólnego zadania CoNLL 2017 UD. Nasz parser, zwany UParse, opiera się na analizie zależności sieci neuronowej opartej na wykresie. Parser wykorzystuje funkcje z dwukierunkowego LSTM, aby wytworzyć rozkład nad możliwymi głowami dla każdego słowa w zdaniu. Aby umożliwić naukę transferową dla niskich zasobów drzew i języków zaskakujących, trenujemy kilka wielojęzycznych modeli języków pokrewnych, pogrupowanych według ich rodzaju i rodzin językowych. Spośród 33 uczestników nasz system osiąga dziewiąte miejsce w wynikach głównych, z wynikami 75.49 UAS i 68.87 LAS F-1 (średnio na 81 bankach drzew).', 'ro': 'Această lucrare prezintă depunerile noastre pentru CoNLL 2017 UD Shared Task. Analizorul nostru, numit UParse, se bazează pe un analizor de dependență bazat pe grafice de rețea neurală. Parserul folosește caracteristici dintr-un LSTM bidirecțional pentru a produce o distribuție peste capete posibile pentru fiecare cuvânt din propoziție. Pentru a permite transferul de învățare pentru brațe cu resurse reduse și limbi surpriză, instruim mai multe modele multilingve pentru limbi conexe, grupate după genul și familiile lor lingvistice. Din 33 de participanți, sistemul nostru atinge locul 9 în rezultatele principale, cu 75.49 UAS și 68.87 LAS F-1 scoruri (medie pe 81 de brațe).', 'sr': 'Ovaj papir predstavlja naše podatke za zajednički zadatak CoNLL 2017. Naš parsor, zove se UParse, zasnovan je na grafičkom analizu zavisnosti na nervnoj mreži. Analizator koristi karakteristike od dvodirektivnog LSTM kako bi proizvela distribuciju preko mogućih glava za svaku reč u rečenici. Da bismo omogućili da prebacimo učenje za manje resurse i jezike iznenađenja, treniramo nekoliko multijezičkih modela za povezane jezike, skupljenih od njihovih gena i jezičkih porodica. Iz 33 učesnika, naš sistem postiže rank 9 u glavnim rezultatima, sa 75,49 UAS i 68,87 LAS F-1 rezultatima (prosječno preko 81 treebana).', 'si': 'මේ පැත්තේ අපේ පණිවිඩය පෙන්වන්නේ 2017 CoNLL UD කොටස් එක්ක කාර්ය වෙනුවෙන්. අපේ පරීක්ෂකය, UPARSE කියලා කියලා, න්\u200dයූරල් ජාලයේ ග්\u200dරාෆ් අධාරිත විශේෂකයේ අධාරිත විශේ විශාලකයෙන් විශේෂතාවක් භාවිත කරන්න බිදිරික්ෂිත LSTM වලින් ප්\u200dරයෝජනය කරන්න පුළුවන් ඔළුවන් වචන අඩුම සම්බන්ධ භාෂාව සහ පුදුම භාෂාව සඳහා අඩුම සම්බන්ධ භාෂාවක් ඉගෙනගන්න අවශ්\u200dය වෙනුවෙන්, අපි ගොඩක් භාෂ අපේ පද්ධතියේ ප්\u200dරධාන ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d', 'so': 'Kanu wuxuu soo bandhigaa warqadayada u soo diraya shaqada la sharciyey ee CoNLL 2017. Parser, magaca UParse, wuxuu ku saleysan yahay shabakadda neural oo ku saleysan xarunta ku xiran. Parsarku wuxuu isticmaalaa qeybo ka mid ah LSTM, si uu u soo bixiyo qayb ka gaar ah madaxa suurtagalka ah oo uu eray kasta ku qoro. Si aan u ruqsado in waxbarashada looga wareejiyo luqadaha hoose ee nolosha iyo luqadaha la yaabo, waxaynu baranaynaa tusaalooyin kala duduwan oo luuqadaha la xiriira, kooxa qoysaska jinsigooda iyo luuqadooda. 33 ka mid ah ayaa nidaamkayaga waxay gaadhaa fasalka 9aad ee ugu weyn, waxayna leeyihiin 75.49 UAS iyo 68.87 LAS F-1 score (qiyaastii ku badnaan 81 treebank).', 'sv': 'Denna uppsats presenterar våra bidrag till CoNLL 2017 UD Shared Task. Vår parser, kallad UParse, är baserad på en neuralt nätverksgrafbaserad beroendeparser. Tolkern använder funktioner från en dubbelriktad LSTM för att producera en fördelning över möjliga huvuden för varje ord i meningen. För att möjliggöra transferinlärning för lågresursträd och överraskningsspråk utbildar vi flera flerspråkiga modeller för besläktade språk, grupperade efter deras släkte och språkfamiljer. Av 33 deltagare uppnår vårt system 9:e plats i huvudresultaten, med 75,49 UAS och 68,87 LAS F-1 poäng (genomsnitt över 81 trädbackar).', 'ta': 'இந்த காகிதம் கோன்எல் 2017 UD பகிர்ந்த பணிக்கு எங்கள் கட்டளைகளை அளிக்கிறது. நம்முடைய பிரச்சனை, UParse என்று அழைக்கப்பட்டது, ஒரு புதிய வலைப்பின்னல் வரைபடத்தின் சார்ந்த சார்பு பகுதி வாக்கியத்தில் உள்ள ஒவ்வொரு வார்த்தைக்கும் மேல் பங்கீடு தலைப்புகளை உருவாக்குவதற்கு பிடியின் LSTM யிலிருந் குறைந்த மூலங்களுக்கு கற்றுக் கொடுப்பதை அனுமதிக்கும் மற்றும் ஆச்சரியமான மொழிகளுக்கு, நாம் பல மொழிகளின் மாதிரிகளை பயிற்சி செய்க 33 இல் சேர்ந்தவர்களில், எங்கள் அமைப்பு முக்கிய முடிவில் 9வது தரம் பெறுகிறது, 75. 49 UAS மற்றும் 68. 87 LAS F-1 புள்ளிகள் (சராசரி 81 ட்ரீபாங்குகள் மு', 'ur': 'This paper presents our submissions for the CoNLL 2017 UD Shared Task. ہمارا پارچر، UParse کا نام ہے، ایک نئورل نیٹورک گراف پر بنیاد رکھا گیا ہے۔ پارچر ایک دوسری لس ٹیم سے ویژگی استعمال کرتا ہے کہ ہر کلم کے لئے ممکن سروں پر تقسیم پیدا کرے۔ نیچے منبع ترین بینگ اور تعجب زبانوں کے لئے تعلیم سکھانے کی اجازت دینے کے لئے ہم تعلیم زبانوں کے متعلق بہت سی زبان مدل کی تعلیم دیتے ہیں، جو ان کے جنس اور زبان خاندان کے ذریعے جمع کئے گئے ہیں. 33 شرکت کرنے والوں میں سے، ہماری سیسٹم کی اصلی نتیجے میں ۹ درجہ پہنچتی ہے، 75.49 UAS اور 68.87 LAS F-1 اسکور کے ساتھ (متوسط 81 تریبانک میں).', 'uz': "Bu sahifa 2017 UD bilan bogʻliq vazifani qo'shishga ishonchimizni beradi. UParse (UParse) deb nomlangan parser, neural tarmoq grafik asosida ishlatiladi. Name Ko'pchilik rasmlar uchun o'rganishni o'rganishga ruxsat berish uchun biz bir necha tilning modellarini o'rganamiz, ularning genus va tillar qo'llari bilan bir necha tilni o'rganamiz. 33 ta'qituvchilar davomida, bizning tizimmiz asosiy natijada 9 darajaga ega bo'ladi, 75.49 UAS va 68.87 LAS F-1 scori (81 treebank sohalari bo'lgan darajada).", 'vi': 'Tờ giấy này giới thiệu công việc chia sẻ của chúng tôi cho Coyll Buổi diễn tập. Vị cha xứ chúng tôi, gọi là UPass, dựa trên một hệ thần kinh phân tích phụ thuộc vào đồ thị Người phân tích sử dụng các tính năng từ một LSTM hai bên để sản xuất ra một phân phối trên các đầu có thể cho mỗi từ trong câu. Để cho phép học chuyển nhượng cho các ngôn ngữ ba chiều thấp và những ngôn ngữ ngạc nhiên, chúng tôi đào tạo các mô hình đa dạng cho các ngôn ngữ tương tự, tập hợp theo chi và ngôn ngữ. Bên ngoài 33, hệ thống của chúng tôi đạt được cấp 9th trong kết quả chính, với số lượng nước 97.42 UAS và 687 LAS F-1 điểm số trung bình trong 81 treebacks.', 'bg': 'Настоящата статия представя нашите предложения за споделената задача на КоНЛ 2017. Нашият анализатор, наречен UParse, се базира на нервна мрежа базиран на графика анализатор на зависимост. Парсорът използва функции от двупосочна ЛСТМ, за да създаде разпределение върху възможни глави за всяка дума в изречението. За да позволим трансферно обучение за нискоресурсни дървесни ленти и изненадващи езици, ние обучаваме няколко многоезични модела за сродни езици, групирани по род и езикови семейства. От 33 участници, нашата система постига 9-то място в основните резултати, със 75.49 ОУ и 68.87 ОУ (средно при 81 дървета).', 'da': 'Denne artikel præsenterer vores indlæg til CoNLL 2017 UD Shared Task. Vores fortolker, kaldet UParse, er baseret på et neuralt netværk grafbaseret afhængighedsfortolker. Parseren bruger funktioner fra en tovejet LSTM til at producere en fordeling over mulige hoveder for hvert ord i sætningen. For at muliggøre overførsel af træbække med lav ressource og overraskelsessprog, træner vi flere flersprogede modeller for beslægtede sprog, grupperet efter deres slægt og sprogfamilier. Ud af 33 deltagere opnår vores system rang 9. i hovedresultaterne med 75,49 UAS og 68,87 LAS F-1 scorer (gennemsnit på 81 træbanker).', 'nl': 'Dit document presenteert onze inzendingen voor de CoNLL 2017 UD Shared Task. Onze parser, genaamd UParse, is gebaseerd op een neuronale netwerk grafiek gebaseerde afhankelijkheidsparser. De parser gebruikt functies van een bidirectionele LSTM om een verdeling over mogelijke koppen voor elk woord in de zin te produceren. Om transferleren voor boombanken en verrassende talen mogelijk te maken, trainen we meerdere meertalige modellen voor verwante talen, gegroepeerd op hun geslacht en taalfamilies. Van de 33-deelnemers behaalt ons systeem de 9e plaats in de belangrijkste resultaten, met 75.49 UAS en 68.87 LAS F-1 scores (gemiddeld over 81-boombanken).', 'id': 'Kertas ini memperlihatkan pengiriman kami untuk CoNLL 2017 UD Shared Task. Our parser, called UParse, is based on a neural network graph-based dependency parser.  Penganalis menggunakan fitur dari LSTM bidireksi untuk menghasilkan distribusi di atas kepala mungkin untuk setiap kata dalam kalimat. Untuk memungkinkan transfer belajar untuk pangkalan pohon sumber daya rendah dan bahasa kejutan, kami melatih beberapa model berbagai bahasa untuk bahasa yang berhubungan, terkumpul oleh jenis dan keluarga bahasa mereka. Dari 33 peserta, sistem kami mencapai peringkat ke-9 dalam hasil utama, dengan 75,49 UAS dan 68,87 LAS F-1 skor (rata-rata melewati 81 batang pohon).', 'de': 'Dieses Papier stellt unsere Einreichungen für die CoNLL 2017 UD Shared Task vor. Unser Parser, genannt UParse, basiert auf einem graphenbasierten Abhängigkeitsparser für neuronale Netze. Der Parser verwendet Features aus einem bidirektionalen LSTM, um eine Verteilung über mögliche Köpfe für jedes Wort im Satz zu erzeugen. Um Transferlernen für ressourcenarme Baumbänke und Überraschungssprachen zu ermöglichen, trainieren wir mehrere mehrsprachige Modelle für verwandte Sprachen, gruppiert nach ihren Gattungen und Sprachfamilien. Von den 33-Teilnehmern erreicht unser System den neunten Rang in den Hauptergebnissen, mit 75.49 UAS und 68.87 LAS F-1 Scores (Durchschnitt über 81-Baumbänke).', 'ko': '이 문서에서는 우리가 제출한 CoNLL 2017 UD 공유 작업에 대해 설명합니다.우리의 해석기는 Uparse라고 하는데, 이것은 신경 네트워크 그림을 바탕으로 하는 의존성 해석기를 바탕으로 한다.해석기는 양방향 LSTM의 특징을 사용하여 문장의 모든 단어에 가능한 머리 분포를 생성합니다.저자원 트리 라이브러리와 깜짝 언어의 이동 학습을 실현하기 위해 우리는 몇 가지 관련 언어의 다중 언어 모델을 훈련하여 그 속과 어족에 따라 그룹을 나누었다.참여자 33명 가운데 우리 시스템은 75.49 UAS와 68.87 LAS F-1 득점(81개 트리은행 평균)으로 주요 결과 9위에 올랐다.', 'hr': 'Ovaj papir predstavlja naše podatke za zajednički zadatak CoNLL 2017. Naš analitičar, zove UParse, zasnovan je na grafu ovisnosti na grafu neuralne mreže. Analizator koristi karakteristike od bidirectional LSTM kako bi proizvela distribuciju nad mogućim glavama za svaku riječ u rečenici. Da bi omogućili prebacivanje učenja za manje resurse i jezike iznenađenja, treniramo nekoliko višejezičkih modela za povezane jezike, skupljenih od njihovih gena i jezičkih obitelji. Iz 33 učesnika, naš sustav postiže rank 9 u glavnim rezultatima, s 75,49 UAS-om i 68,87 LAS F-1 rezultatima (prosječan preko 81 treebana).', 'tr': "Bu k채ze bizi흫 CoNLL 2017-nji 첵yly흫 UD b철l체ni힊 i힊i 체챌in arzanlarymyzy g철rkez첵채r. UParse adl캇 챌철z체mleyiz, n철ral a 휓 grafi휓ine dayanan ba휓l캇l캇k 챌철z체mleyicisine dayan캇yor. Ta첵dala힊챌y s철zleri흫 her s철zi흫 체챌in m체mkin kellelerinden pa첵la힊mak 체챌in ikinji g철rn체힊 LSTM'den 철zellikleri ulan첵ar. I챌i kaynakly 챌yzgymlar 체챌in 철wrenm채ge rugsat bermek 체챌in, bir n채챌e sany diller 체챌in 첵aly diller 체챌in, 첵azyl we dil ma힊galalaryndan toparlan첵arys. 33 i힊tirak챌ilerden, sistemimizi흫 esasy netijede 9-nji derej채 챌yk첵ar, 75.49 UAS we 68.87 LAS F-1 sany (ortalama 81 sany 챌yk첵ar).", 'sw': 'Makala hii inaonyesha ujumbe wetu wa chama cha CoNLL 2017. Mwanachambuzi wetu, anayeitwa UParse, anategemea kwenye mtandao wa ubongo wa picha inayotegemea. Mchambuzi huyo anatumia vipengele vya LSTM kwa ajili ya kutengeneza usambazaji zaidi ya vichwa vinavyowezekana kwa kila neno kwenye hukumu. Kuruhusu kuhamisha kujifunza kwa lugha za mitatu za rasilimali na lugha za kushangaza, tunafundisha mifano kadhaa ya lugha mbalimbali kwa lugha zinazohusiana, na makundi ya familia zao za kijinsia na lugha. Miongoni mwa washiriki 33, mfumo wetu unapata nafasi ya 9 katika matokeo makuu, yenye score 75.49 UAS na 68.87 LAS F-1 (wastani katika viwanja vya mitaani 81).', 'fa': 'این کاغذ تحویل\u200cهای ما برای کار مشترک UD CONLL 2017 را نشان می\u200cدهد. بازیگر ما، به نام UParse، بر اساس یک بازیگر بستگی بر روی شبکه عصبی است. ویرایشگر از ویرایش\u200cهای LSTM برای تولید یک توزیع بر سرهای ممکن برای هر کلمه در جمله استفاده می\u200cکند. برای اجازه دادن تعلیم برای تغییر یادگیری برای تغییر تغییر تغییر و زبانهای سورپرایز کم منابع، ما چند مدل متعدد زبان را برای زبانهای ارتباط آموزش می دهیم، که توسط خانواده های ژنتی و زبان آنها از 33 شرکت کننده، سیستم ما در نتیجه اصلی درجه ۹ درجه رسیده است، با 75.49 UAS و 68.87 امتیاز LAS F-1 (متوسط در 81 درجه درجه).', 'af': "Hierdie papier stel ons onderskrywings voor die CoNLL 2017 UD deelde taak. Ons ontwerker, UParse genoem, is gebaseer op 'n neural netwerk graaf-gebaseerde afhanklikheidspanser. Die ontleerder gebruik funksies van 'n bidireksjonale LSTM om 'n verspreiding oor moontlik koppe te produseer vir elke woord in die seting. Om oordrag te laat toe vir lae hulpbronne treebanks en verbaastaals, tref ons verskeie multitaalse modele vir verwante tale, groepeer deur hul genus en taalsfamilies. Van 33 deelnaders, ons stelsel bereik rank 9de in die hoofresultate, met 75.49 UAS en 68.87 LAS F-1 telling (gemiddelde oor 81 treebanks).", 'sq': 'Ky dokument paraqet paraqitjet tona për detyrën e përbashkët të CoNLL 2017 UD. Analizatori ynë, i quajtur UParse, është bazuar në një analizues të varësisë në rrjetin nervor bazuar në grafik. Analizatori përdor funksione nga një LSTM dy drejtues për të prodhuar një shpërndarje mbi kokat e mundshme për çdo fjalë në fjalë. Për të lejuar transferimin e mësimit për bazat e pemëve me burime të ulëta dhe gjuhët e befasuara, ne trajnojmë disa modele shumëgjuhësore për gjuhët e lidhura, të grupuara nga gjini dhe familjet e tyre gjuhësh. Nga 33 pjesëmarrës, sistemi ynë arrin rendin e 9-të në rezultatet kryesore, me 75.49 UAS dhe 68.87 LAS F-1 pikë (mesatare në 81 pikë pemësh).', 'am': 'ይህም ገጽ ለኮንLL 2017 የኦዲ ስራ የተሰራጨውን ጥያቄዎችን ያቀርባል፡፡ የUParse የተባለው ተሳታፊያችን በኔural network graph-based ተሟጋቾችን በመሠረት ነው፡፡ ማጠቃለያው በክፍሉ ውስጥ ለሁሉም ቃላት በሚቻለው ራስ ላይ ትካክል እንዲያደርግ ከ አዲስ LSTM የተባለው ምርጫዎች ይጠቅማል። ለታናሹ ሀብት እና ለመደነቂያ ቋንቋዎች ትምህርትን ለመስጠት እናስቀራለን፤ በተለየ ቋንቋዎች እና በቋንቋ ወገኖቻቸው የተሰበሰቡ ብዙዎችን የቋንቋዎች ምሳሌዎችን እናስተምራለን፡፡ ከ33 ተጋሪዎች ውስጥ ስርዓታችን የዋነኛው ፍጥረት 9ኛ ደረጃን ያገኛል፤ 75.49 UAS እና 68.87 LAS F-1 score (average over 81 treebank) ይደረጋል፡፡', 'hy': 'Այս հոդվածը ներկայացնում է մեր ներկայացումները 2017 թվականի ՄԻԱՎ-ի ՄԻԱՎ-ի հանձնարարության համար: Մեր վերլուծողը, որը կոչվում է UPass, հիմնված է նյարդային ցանցի գրաֆիկայի հիմնված կախվածության վերլուծողի վրա: Փորձարկողը օգտագործում է երկու ուղղությամբ LSMT-ի հատկանիշներ, որպեսզի ստեղծի տարածումը նախադասության յուրաքանչյուր բառի վերաբերյալ: Այսպիսով, որպեսզի կարողանանք տեղափոխել ուսումնասիրությունը ցածր ռեսուրսների ծառերի հիմնադրամների և զարմանալի լեզուների համար, մենք սովորեցնում ենք բազմալեզու մոդելներ հարաբեր լեզուների համար, խմբավորված նրանց սերնդի և Out of 33 participants, our system achieves rank 9th in the main results, with 75.49 UAS and 68.87 LAS F-1 scores (average across 81 treebanks).', 'az': 'Bu kağıt bizim CoNLL 2017-ci UD paylaşılmış işi üçün göndəriləcəyimizi göstərir. UParse adlı analizacımız nöral a ğ grafından bağlılıq parçasına dayandırılır. Parsatçı hər sözdə mümkün baş üstündə dağıtış yaratmaq üçün bidirectional LSTM-dən xüsusiyyətlər istifadə edir. Düşük ressurs çubuqları və təəccüblü dilləri üçün öyrənmək üçün çoxlu dil modellərini bağlı dillər üçün təhsil edirik, cins və dil ailələri ilə birləşdirilmiş. 33 iştirakçılardan, sistemimiz ana sonuçlarında 9. dərəcə gəlir, 75.49 UAS və 68.87 LAS F-1 dərəcələri ilə (ortalama 81 treebanklar arasında).', 'bn': 'এই পত্রিকাটি কনএল ২০১৭ সালের উডি শেয়ার কর্মসূচির জন্য আমাদের প্রতিক্রিয়া উপস্থাপন করেছে। আমাদের বিশ্লেষক, যার নাইউরুল নেটওয়ার্ক ভিত্তিক গ্রাফ ভিত্তিক নির্ভরশীল প্যারেজ। প্রত্যেক শব্দের জন্য সম্ভাব্য মাথার উপর বিতরণ করার জন্য বিভাগের বিশেষ বৈশিষ্ট্য LSTM থেকে ব্যবহার করা হয়েছে। কম সম্পদের ট্রিব্যাংক এবং বিস্ময়কর ভাষার জন্য শিক্ষা নিয়ে যাওয়ার অনুমতি দেয়ার জন্যে আমরা বেশ কয়েকটি মাল্টিভাষার মডেল প্রশিক্ষণ দেই, যার ৩৩ জন অংশগ্রহণকারীদের মধ্যে আমাদের সিস্টেম প্রধান ফলাফলের ৯ স্তরে পৌঁছায়, যার ফলে ৭৫. ৪৯ ইউএস আর ৬৮. ৮৭ ল্যাস F-1 স্কোর (গড়ে ৮১ ট্রি', 'ca': "Aquest paper presenta les nostres presentacions per la CoNLL 2017 UD Shared Task. El nostre analitzador, anomenat UParse, es basa en un analitzador de dependencies basat en gràfics de la xarxa neural. L'analitzador utilitza característiques d'un LSTM bidireccional per produir una distribució sobre els caps possibles per cada paraula de la frase. Per permetre la transfer ència d'aprenentatge per bancs d'arbres de baix recursos i llengües sorprenents, treinem varis models multilingües per llengües relacionades, agrupats pel seu gènere i les seves famílies de llengües. De 33 participants, el nostre sistema obté el nou rangde resultats principals, amb 75,49 UAS i 68,87 LAS F-1 puntuacions (mitjana entre 81 bancs d'arbre).", 'et': 'Käesolevas artiklis esitatakse meie ettepanekud CoNLL 2017 UD Shared Task kohta. Meie parser, UParse, põhineb neurovõrgu graafikutel põhineval sõltuvuse parser. Parser kasutab kahesuunalise LSTM funktsioone, et toota jaotus võimalike peade üle iga lause sõna jaoks. Selleks et võimaldada siirdeõpet vähese ressursiga puupankadele ja üllatuskeeltele, koolitame mitmeid mitmekeelseid mudeleid seotud keeltele, rühmitatud nende perekondade ja perekondade järgi. 33-st osalejast saavutas meie süsteem peamistes tulemustes 9. koha, 75,49 UAS ja 68,87 LAS F-1 skooriga (keskmine 81 puupunkti kohta).', 'fi': 'Tässä artikkelissa esitellään artikkelimme CoNLL 2017 UD Shared Task -hankkeesta. Analysoijamme UParse perustuu neuroverkon graafiin perustuvaan riippuvuuden analysoijaan. Analysoija käyttää kaksisuuntaisen LSTM:n ominaisuuksia tuottamaan jakelun mahdollisten päiden yli jokaiselle lauseen sanalle. Mahdollistaaksemme siirtooppimisen vähävaraisille puupankeille ja yllätyskieleille, koulutamme useita monikielisiä malleja sukupolven ja kieliperheiden mukaan ryhmiteltyjä kieliä varten. 33 osallistujasta järjestelmämme saavutti 9. sijan päätuloksissa, 75,49 AMK:n ja 68,87 LAS F-1:n pisteet (keskiarvo 81 puupenkillä).', 'cs': 'Tento článek představuje naše příspěvky pro sdílený úkol CoNLL 2017 UD. Náš parser, nazývaný UParse, je založen na neuronové síti graf závislosti parser. Parser používá funkce z obousměrného LSTM k vytvoření distribuce nad možnými hlavami pro každé slovo ve větě. Abychom umožnili přenosové učení pro stromové břehy s nízkými zdroji a překvapivé jazyky, trénujeme několik vícejazyčných modelů pro příbuzné jazyky seskupených podle jejich rodu a jazykových rodin. Z 33 účastníků dosahuje náš systém devátého místa v hlavních výsledcích, s 75.49 UAS a 68.87 LAS F-1 skóre (průměr napříč 81 stromovými březy).', 'bs': 'Ovaj papir predstavlja naše podatke za zajednički zadatak CoNLL 2017. Naš analitičar, zove UParse, zasnovan je na grafičkom analitičaru ovisnosti na grafu neuralne mreže. Analizator koristi karakteristike od bidirectional LSTM kako bi proizvela distribuciju preko mogućih glava za svaku riječ u rečenici. Da bi omogućili prebacivanje učenja za manje resurse i jezike iznenađenja, treniramo nekoliko multijezičkih modela za povezane jezike, skupljene od njihovih gena i jezičkih porodica. Iz 33 učesnika, naš sistem postiže rank 9 u glavnim rezultatima, sa 75,49 UAS i 68,87 LAS F-1 rezultatima (prosječno preko 81 treebana).', 'jv': 'Gambar iki bakal ngewehi nggawe tarjamahan kanggo CoNLL Iwak task tah werak-barêng nggawe Kernel Ngubah Mbok perusaha kanggo ngilanggar kuwi tindang karo pakeh-pakeh karo nganggo urip sing surang, awak dhéwé luwih akeh model multi-lenguang kanggo langga, gek nggawe jenis karo perusahaan langga. Sistem sing wis nambah tanggal pirang-pirang, ditambah sing wis rampung liyane 9 ing panjuré supoyo sing mungkin, karo 75.49 US lan 6.7 LAS F-1 (sing wis ambang cara mbégal sabên dengan mbégal).', 'he': 'העיתון הזה מציג את ההעברות שלנו למשימה המשותפת של CoNLL 2017 UD. המחקר שלנו, שנקרא UParse, מבוסס על מעבד תלויות רשת עצבית מבוסס בגרף. המחקר משתמש באיכויים מ LSTM שתיים כיוונים כדי לייצר פיצוח מעל ראשים אפשריים לכל מילה במשפט. כדי לאפשר להעביר את הלימודים עבור עצי משאבים נמוכים ושפות הפתעה, אנו מאמן מספר דוגמנים רבים לשפות הקשורות, קבוצים על ידי מין ומשפחות השפות שלהם. מתוך 33 משתתפים, המערכת שלנו מגיעה לדרגה ה-9 בתוצאות העיקריות, עם 75.49 UAS ו-68.87 נקודות F-1 של LAS (בממוצע על 81 בנקי עץ).', 'ha': "This paper presents our submissions for the CoNLL 2017 UD Shared Task.  Parser Parser ɗin ya yi amfani da tsaro daga wata LTRM mai gabatar da shi don ya nuna rabo a kan duk takardar sunayen da aka iya iya cikin ƙohon. Ko iya yarda da in motsi da aka sauƙaƙara wa masu karatun na fassarar-nau'in-nau'i ko da harshen na yi mãmãki, za'a sanar da misãlai masu yawa wa lugha masu husũma, masu haɗi da jama'a na genus da harshe. Daga mãsu shirin 33, na kasarsa yana sãmun darajõji na 9 cikin matsalan maɓallin ƙarshen, da nau'in watanni na 65.49 UA da 68.87 lass F-1 score (mai tsakanin 81 ta shawara).", 'sk': 'Ta prispevek predstavlja naše prispevke za skupno nalogo UD CoNLL 2017. Naš razčlenjevalnik, imenovan UParse, temelji na razčlenjevalniku odvisnosti na nevronskem omrežju. Razčlenjevalnik uporablja funkcije dvosmernega LSTM za ustvarjanje porazdelitve preko možnih glav za vsako besedo v stavku. Da bi omogočili prenosno učenje za nizko porabljene drevesne mreže in jezike presenečenja, usposabljamo večjezične modele za sorodne jezike, razvrščene po rodu in jezikovnih družinah. Od 33 udeležencev je naš sistem dosegel 9. mesto v glavnih rezultatih, s 75,49 UAS in 68,87 LAS F-1 rezultati (povprečje pri 81 treebanks).', 'bo': 'ཤོག་བྱང་འདིས་CoNLL 2017 UD རྩིས་སྤྱོད་པའི་བྱ་འགུལ་ལ་ང་ཚོའི་མཉམ་དུ་སྟོན་པ ང་ཚོའི་དབྱེ་སྤྱོད་པ་(UParse)མིང་དུ་ནུས་མཐུན་འབྲེལ་གྱི་གྲངས་སྒྲིག་ཀྱི་རྟེན་འབྲེལ་བཤད་པ་ཞིག དབྱེ་སྟངས་ནང་དུ་ཚིག་ཚན་རེ་རེ་བ་སྤྱོད་པའི་གནད་དོན་བཀོད་སྤྱོད་ཀྱི་གནད་དོན་གཅིག་ལས་སྤྱོད་པ དངོས་ཡིག་ཆ་ཉུང་བའི་རྒྱུ་དངོས་ཡིག་ཅིག་ལ་སྐྱེས་པའི་སྐད་རིགས་ཚོའི་ནང་དུ་སྤྱིར ཞུགས་སྡུད་འདི་གསུམ་པ་ལས་ང་ཚོའི་མ་ལག་གི་གྲངས་ཚད་རིམ་པ་ནང་ལྡན་ནམ་པ་ཞིག་ཡིན།'}
{'en': 'Multi-Model and Crosslingual Dependency Analysis', 'fr': 'Analyse des dépendances multi-modèles et multilingues', 'ar': 'تحليل التبعية متعدد النماذج واللغات', 'es': 'Análisis de dependencias multimodelo y multilingüe', 'pt': 'Análise de dependência multi-modelo e multilíngue', 'zh': '多与跨语相依', 'ja': 'マルチモデルとクロスリンガルの依存関係分析', 'hi': 'बहु मॉडल और Crosslingual निर्भरता विश्लेषण', 'ru': 'Мультимодельный и кросслингвальный анализ зависимости', 'ga': 'Anailís ar Spleáchas Ilmhúnla agus Trastheangach', 'hu': 'Több modell és többnyelvű függőségi elemzés', 'el': 'Ανάλυση πολυμοντέλων και διασταυρούμενης εξάρτησης', 'ka': 'Multi- Model და Crosslingual Dependency Analysis', 'kk': 'Көп үлгі және көшетілік тәуелдік анализ', 'it': 'Analisi della dipendenza multi-modello e cross-lingual', 'mk': 'Мултимоделна и крстојазична анализа на зависност', 'lt': 'Daugiapavyzdžiė ir tarpkalbinė priklausomybės analizė', 'ms': 'Analisis Dependensi Multi-Model dan Salib Bahasa', 'mn': 'Олон загвар болон олон хэл хамаарлын шинжилгээ', 'mt': 'Analiżi ta’ Dipendenza Multimudell u Crosslingual', 'no': 'Multimodell og krysspråk avhengighetsanalyse', 'ml': 'Multi- Model and Crosslingual dependency Analysis', 'pl': 'Analiza zależności wielomodowej i wielojęzycznej', 'sr': 'Multi Model i Crosslingual Dependency Analysis', 'ro': 'Analiza dependenței multimodel și translingvă', 'so': 'Analysis ku xiran luqada iskuulka', 'si': 'Multi- Model සහ Crosslanguage Dependency විශ්ලේෂණය', 'sv': 'Flermodells- och tvärspråkig beroendeanalys', 'ur': 'Multi-Model and Crosslingual Dependency Analysis', 'ta': 'பல- மாதிரி மற்றும் க்ராஸ்மொழியின் சார்ந்த ஆராய்ச்சி', 'uz': 'Name', 'vi': 'Nhân loại và phân biệt ngôn ngữ', 'bg': 'Многомоделен и междуезичен анализ на зависимостта', 'nl': 'Meermodel- en meertalige afhankelijkheidsanalyse', 'id': 'Multi-Model and Crosslingual Dependency Analysis', 'hr': 'Većina modela i analiza krstojezičke zavisnosti', 'da': 'Analyse af flere modeller og tværsproget afhængighed', 'de': 'Multi-Modell- und Crosslingual Dependency Analysis', 'ko': '다중 모델과 다중 언어 의존 분석', 'fa': 'تحلیل بستگی زیادی مدل و متوسط زبان', 'sq': 'Multi-Model and Crosslingual Dependency Analysis', 'tr': 'Çot-Mody we Çapraz Diller Bağlamlık Analizi', 'af': 'Multi- Model en Crosslingual Dependency Analysis', 'sw': 'Anachambua Uhuru wa lugha nyingi na Uchunguzi', 'am': 'ቋንቋዎች', 'bn': 'বহুমাত্র মোডেল এবং ক্রোশ্লিঙ্গুয়েল নির্ভর বিশ্লেষণ', 'bs': 'Višemodelna i krstojezička analiza zavisnosti', 'hy': 'Շատ մոդել և միջլեզու կախվածության վերլուծություն', 'ca': 'Anàlisi de dependencies multimodels i translingües', 'et': 'Mitmemudeli ja keeleülese sõltuvuse analüüs', 'fi': 'Monimallinen ja monikielinen riippuvuusanalyysi', 'cs': 'Vícemodelová a vícejazyčná analýza závislosti', 'az': '√áoxlu Model v…ô √á…ôrz Dili Baƒülamlƒ±q Analizi', 'he': 'ניתוח תלויות רבות מודל וצלב', 'ha': 'Ana Analyza na Tsararre na Wata-Motel da KCharselect unicode block name', 'sk': 'Večmodelna in večjezična analiza odvisnosti', 'bo': 'Multi-Model and Crosslingual Dependency Analysis', 'jv': 'Multi-model lan multi-language dependanci Taal'}
{'en': 'This paper describes the system of the Team Orange-Deskin, used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. We based our approach on an existing open source tool (BistParser), which we modified in order to produce the required output. Additionally we added a kind of pseudo-projectivisation. This was needed since some of the task’s languages have a high percentage of non-projective dependency trees. In most cases we also employed word embeddings. For the 4 surprise languages, the data provided seemed too little to train on. Thus we decided to use the training data of typologically close languages instead. Our system achieved a macro-averaged LAS of 68.61 % (10th in the overall ranking) which improved to 69.38 % after bug fixes.', 'ar': 'تصف هذه الورقة نظام Team Orange-Deskin̈ المستخدم في مهمة CoNLL 2017 UD المشتركة في تحليل التبعية متعدد اللغات. اعتمدنا نهجنا على أداة مفتوحة المصدر موجودة (BistParser) ، والتي قمنا بتعديلها من أجل إنتاج المخرجات المطلوبة. بالإضافة إلى ذلك ، أضفنا نوعًا من الإسقاط الزائف. كان هذا ضروريًا نظرًا لأن بعض لغات المهمة بها نسبة عالية من أشجار التبعية غير الإسقاطية. في معظم الحالات ، استخدمنا أيضًا حفلات الزفاف. بالنسبة للغات الأربع المفاجئة ، بدت البيانات المقدمة قليلة جدًا بحيث لا يمكن التدرب عليها. لذلك قررنا استخدام بيانات التدريب الخاصة باللغات القريبة نسبيًا بدلاً من ذلك. حقق نظامنا معدل LAS الكلي بلغ 68.61٪ (العاشر في الترتيب العام) والذي تحسن إلى 69.38٪ بعد إصلاحات الأخطاء.', 'fr': "Cet article décrit le système de la Team Orange-Deskin, utilisé pour la tâche partagée ConLL 2017 UD dans l'analyse des dépendances multilingues. Nous avons basé notre approche sur un outil open source existant (BistParser), que nous avons modifié afin de produire le résultat requis. De plus, nous avons ajouté une sorte de pseudo-projectivisation. Cela était nécessaire car certains langages de la tâche présentent un pourcentage élevé d'arbres de dépendance non projectifs. Dans la plupart des cas, nous avons également utilisé des intégrations de mots. Pour les 4 langues surprises, les données fournies semblaient insuffisantes pour s'entraîner. Nous avons donc décidé d'utiliser à la place les données d'apprentissage des langues typologiquement proches. Notre système a atteint une moyenne macroéconomique LAS de 68,61\xa0% (10e du classement général), qui s'est amélioré à 69,38\xa0% après la correction de bogues.", 'es': 'Este artículo describe el sistema del Team Orange-Deskin̈, utilizado para la tarea compartida UD de CoNll 2017 en el análisis de dependencias multilingües. Basamos nuestro enfoque en una herramienta de código abierto existente (BistParser), que modificamos para producir el resultado requerido. Además, añadimos una especie de pseudoproyectivización. Esto era necesario ya que algunos de los lenguajes de la tarea tienen un alto porcentaje de árboles de dependencias no proyectivas. En la mayoría de los casos, también empleamos incrustaciones de palabras. Para los 4 idiomas sorpresa, los datos proporcionados parecían muy pocos para entrenar. Por lo tanto, decidimos utilizar en su lugar los datos de entrenamiento de idiomas tipológicamente cercanos. Nuestro sistema logró un LAS macropromediado del 68,61% (10º en la clasificación general), que mejoró al 69,38% después de la corrección de errores.', 'pt': 'Este artigo descreve o sistema do Team Orange-Deskin̈, usado para o CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. Baseamos nossa abordagem em uma ferramenta de código aberto existente (BistParser), que modificamos para produzir a saída necessária. Além disso, adicionamos uma espécie de pseudo-projetivização. Isso foi necessário, pois algumas das linguagens da tarefa têm uma alta porcentagem de árvores de dependência não projetivas. Na maioria dos casos, também empregamos incorporação de palavras. Para os 4 idiomas surpresa, os dados fornecidos pareciam muito pequenos para treinar. Assim, decidimos usar os dados de treinamento de linguagens tipologicamente próximas. Nosso sistema alcançou uma média macro de LAS de 68,61% (10º na classificação geral), que melhorou para 69,38% após correções de bugs.', 'hi': 'यह पेपर टीम ऑरेंज-डेस्किन की प्रणाली का वर्णन करता है, जिसका उपयोग बहुभाषी निर्भरता पार्सिंग में CoNLL 2017 UD साझा कार्य के लिए किया जाता है। हमने अपने दृष्टिकोण को एक मौजूदा ओपन सोर्स टूल (BistParser) पर आधारित किया, जिसे हमने आवश्यक आउटपुट का उत्पादन करने के लिए संशोधित किया। इसके अतिरिक्त हमने एक प्रकार का छद्म-प्रोजेक्टिवाइजेशन जोड़ा। इसकी आवश्यकता थी क्योंकि कार्य की कुछ भाषाओं में गैर-प्रोजेक्टिव निर्भरता पेड़ों का उच्च प्रतिशत होता है। ज्यादातर मामलों में हमने शब्द एम्बेडिंग को भी नियोजित किया। 4 आश्चर्यजनक भाषाओं के लिए, प्रदान किए गए डेटा पर प्रशिक्षित करने के लिए बहुत कम लग रहा था। इस प्रकार हमने इसके बजाय टाइपोलॉजिकल रूप से बंद भाषाओं के प्रशिक्षण डेटा का उपयोग करने का फैसला किया। हमारे सिस्टम ने 68.61% (समग्र रैंकिंग में 10 वें) का एक मैक्रो-औसत एलएएस हासिल किया, जो बग फिक्स के बाद 69.38% तक सुधार हुआ।', 'ja': '本稿では、多言語依存関係解析におけるCoNLL 2017 UD共有タスクに使用されるTeam Orange - Deskinのシステムについて説明します。私たちのアプローチは、既存のオープンソースツール（ BistParser ）に基づいています。これは、必要な出力を生成するために修正されました。さらに、一種の擬似投影法を追加しました。タスクの言語の中には、非投機的依存関係ツリーの割合が高いものがあるため、これが必要でした。ほとんどの場合、単語埋め込みも採用しました。4つのサプライズ言語については、提供されたデータがあまりにも少なく、トレーニングすることができなかったようです。したがって、類型的に近い言語のトレーニングデータを代わりに使用することにしました。当社のシステムは、バグ修正後に69.38 ％に改善されたマクロ平均LAS 68.61 ％ （全体ランキング10位）を達成しました。', 'zh': '本文引用于多言赖解析中 CoNLL 2017 UD 共任者橙色-Deskin 团队统。 吾道基于开源器(BistParser),吾改其器以成其输。 又添了一种伪投影化。 此必须也,以其言语有比例者非投影之树也。 多少,我们还用了词嵌入。 其于4种可讶之语,其数似少而不可练。 故改类型学近习数。 统成68.61%宏观均LAS(排名第10位)于一体,修复于误69.38%。', 'ru': 'В этой статье описывается система Team Orange-Deskin, используемая для совместной задачи CoNLL 2017 UD в многоязычном парсинге зависимостей. Мы основывали наш подход на существующем инструменте с открытым исходным кодом (BistParser), который мы модифицировали, чтобы получить необходимый результат. Кроме того, мы добавили своего рода псевдопроективизацию. Это было необходимо, поскольку некоторые языки задачи имеют высокий процент непроективных деревьев зависимостей. В большинстве случаев мы также использовали вставки слов. Для 4 языков-сюрпризов предоставленных данных оказалось слишком мало для обучения. Таким образом, мы решили использовать вместо этого данные обучения типологически близких языков. Наша система достигла среднего макроса LAS 68,61% (10-е место в общем рейтинге), который улучшился до 69,38% после исправления ошибок.', 'ga': "Déanann an páipéar seo cur síos ar chóras Team Orange-Deskin̈, a úsáidtear le haghaidh Tasc Comhroinnte UD CoNLL 2017 i bParsáil Spleáchais Ilteangacha. Bhunaíomar ár gcur chuige ar uirlis foinse oscailte a bhí ann cheana féin (BistParser), a d’athraíomar chun an t-aschur riachtanach a tháirgeadh. Ina theannta sin chuireamar cineál bréige-theilgean leis. Bhí sé seo ag teastáil ó tharla go bhfuil céatadán ard de chrainn spleáchais neamhtheilgeanacha ag cuid de theangacha an tasc. I bhformhór na gcásanna d'úsáideamar leabaithe focal freisin. Maidir leis na 4 theanga iontasacha, ba chosúil nach raibh na sonraí a soláthraíodh róbheag le hoiliúint a chur orthu. Mar sin shocraigh muid úsáid a bhaint as sonraí oiliúna teangacha atá gar do thíopeolaíocht. Bhain ár gcóras amach LAS macra-mheánmhéide de 68.61% (10ú sa rangú foriomlán) a d'fheabhsaigh go dtí 69.38% tar éis réiteach fabhtanna.", 'ka': 'ამ დოკუნტის სისტემის შესახებ, რომელიც CoNLL 2017-ის UD გაყოფილი პარამეტრებისთვის გამოყენებულია მრავალენგური დასამხლოლოლობაში. ჩვენ ჩვენი წარმოდგენა გახსნა გამოსახულებული ფოსტური ხელსაწყოთან (BistParser), რომელიც ჩვენ შევცვალოთ, რომ მოჭირდებული გამოსახულება წარმოდგენა. დამატებით ჩვენ პროექსო პროექტივიზაციას დამატებით. ეს უნდა იყო, რადგან რამდენიმე რაოდენობის ენათების უფრო დიდი პროექტიური დადარდამდგენებული ხელების პროცენტიური პროცენტიური პროცენტიური პ უფრო მეტი შემთხვევაში ჩვენ ასევე დავყენებდით სიტყვები. 4 წლის გამოვაკვირებული ენებისთვის მონაცემები ძალიან ცოტა გამოიყურება. ამიტომ ჩვენ დავიწყეთ, რომ ტიპოლოგიურად დახურებული ენების მონაცემების გამოყენება. ჩვენი სისტემა 68,61% (ყველა რინდში 10) მაკრო განსაზღვრებული LAS-ის მიღება, რომელიც შეცდომის კონფიგურაციის შემდეგ 69,38%-დან უფლება.', 'el': 'Η παρούσα εργασία περιγράφει το σύστημα της Ομάδας Πορτοκαλί-Deskin που χρησιμοποιήθηκε για την Κοινή Εργασία στην Ανάλυση Πολυγλωσσικής Εξαρτήσεως. Βασίσαμε την προσέγγισή μας σε ένα υπάρχον εργαλείο ανοιχτού κώδικα (το οποίο τροποποιήσαμε προκειμένου να παραγάγουμε την απαιτούμενη παραγωγή. Επιπλέον προσθέσαμε ένα είδος ψευδοπροβολής. Αυτό ήταν απαραίτητο δεδομένου ότι ορισμένες από τις γλώσσες της εργασίας έχουν υψηλό ποσοστό μη προβολικών δέντρων εξάρτησης. Στις περισσότερες περιπτώσεις χρησιμοποιήσαμε επίσης ενσωμάτωση λέξεων. Για τις τέσσερις γλώσσες έκπληξης, τα δεδομένα που παρείχαν φάνηκαν πολύ λίγα για να εκπαιδευτούν. Έτσι αποφασίσαμε να χρησιμοποιήσουμε τα εκπαιδευτικά δεδομένα τυπολογικά κοντινών γλωσσών. Το σύστημά μας πέτυχε ένα μακρομεσαίο δείκτη LAS 68.61% (10η στη συνολική κατάταξη) το οποίο βελτιώθηκε σε 69.38% μετά από διορθώσεις σφαλμάτων.', 'it': "Questo articolo descrive il sistema del Team Orange-Deskin , utilizzato per il CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. Abbiamo basato il nostro approccio su uno strumento open source esistente (BistParser), che abbiamo modificato per produrre l'output richiesto. Inoltre abbiamo aggiunto una sorta di pseudo-proiezione. Ciò era necessario poiché alcuni dei linguaggi dell'attività hanno un'alta percentuale di alberi di dipendenza non proiettivi. Nella maggior parte dei casi abbiamo utilizzato anche incorporazioni di parole. Per le 4 lingue a sorpresa, i dati forniti sembravano troppo pochi per allenarsi. Così abbiamo deciso di utilizzare i dati formativi di lingue tipologicamente vicine. Il nostro sistema ha raggiunto un LAS medio macro del 68,61% (decimo nella classifica generale) che è migliorato al 69,38% dopo correzioni di bug.", 'kk': 'Бұл қағаз "Orange-Deskin" тобының жүйесін, CoNLL 2017 жылы UD ортақ тапсырмасын бірнеше тілдік тәуелдік талдау үшін қолданылатын. Біз бар ашық көзінің құралына (BistParser) тәсілдігімізді негіздеп, қажетті шығысты құру үшін өзгертіп тұрдық. Қосымша біз псевдо- проективизациясын қолдандық. Бұл тапсырманың кейбір тілдерінің проективті емес тәуелдік ағаштардың пайызы жоғары. Көпшілігінде сондай-ақ сөздерді ендіру жұмыс істедік. 4 қызықтық тілдер үшін келтірілген деректері өте кішкентай болды. Бұл үшін біз типтологиялық тілдерді жабуға шешіміз келді. Біздің жүйеміз 68,61% (жалпы жолдарда 10- ші) макроорташа LAS жеткізді. Бұл қателерді түзетуден кейін 69,38% дегенге жақсы болды.', 'hu': 'Ez a tanulmány ismerteti a Team Orange-Deskin rendszerét , amelyet a CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing alkalmazásához használnak. Megközelítésünket egy meglévő nyílt forráskódú eszközre (BistParser) alapoztuk, amelyet a szükséges kimenet előállítása érdekében módosítottunk. Továbbá hozzáadtunk egyfajta pszeudovetítést. Erre azért volt szükség, mert a feladat egyes nyelvei nagy arányban vannak a nem projektív függőségi fák. A legtöbb esetben szóbeágyazást is alkalmaztunk. A négy meglepetési nyelv esetében a megadott adatok túl kevésnek tűntek ahhoz, hogy továbbképződjön. Így döntöttünk úgy, hogy inkább tipológiailag közeli nyelvek képzési adatait használjuk fel. Rendszerünk 68,61%-os makro-átlagos LAS értéket ért el (10. a teljes rangsorban), ami 69,38%-ra javult a hibajavítások után.', 'mk': 'This paper describes the system of the Team Orange-Deskin , used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing.  Го базиравме нашиот пристап на постоечката алатка на отворен код (BistParser), која ја модификувавме со цел да ја произведеме потребната излез. Покрај тоа додадовме некаква псевдо-проективизација. Ова беше потребно бидејќи некои од јазиците на задачата имаат висок процент на дрвјата на непроективна зависност. In most cases we also employed word embeddings.  За четирите изненадувачки јазици, дадените податоци изгледаа премногу мали за обука. Така одлучивме да ги користиме податоците за обука на типологички блиски јазици наместо тоа. Нашиот систем постигна макро-просечен ЛАС од 68,61 % (десеттиот во целокупното рангирање) кој се подобри на 69,38 отсто по поправка на бубачки.', 'ms': 'Kertas ini menggambarkan sistem Pasukan Orange-Deskin, digunakan untuk Tugas Berkongsi UD CoNLL 2017 dalam Pengesahan Dependensi Berbahasa. Kami mendasarkan pendekatan kami pada alat sumber terbuka yang ada (BistParser), yang kami ubah-ubah untuk menghasilkan output yang diperlukan. Selain itu, kami menambah semacam pseudo-projektivisasi. Ini diperlukan kerana beberapa bahasa tugas mempunyai peratus yang tinggi pokok dependensi tidak projektif. Dalam kebanyakan kes kami juga menggunakan penyembedding perkataan. Untuk 4 bahasa kejutan, data yang diberikan nampak terlalu sedikit untuk berlatih. Thus we decided to use the training data of typologically close languages instead.  Our system achieved a macro-averaged LAS of 68.61% (10th in the overall ranking) which improved to 69.38% after bug fixes.', 'lt': 'Šiame dokumente aprašoma grupės „Orange-Deskin“ sistema , naudojama CoNLL 2017 m. UD bendros užduoties daugiakalbio priklausomybės analizavimo srityje. Mūsų požiūris grindžiamas esama atvirojo kodo priemone (BistParser), kuri buvo pakeista siekiant sukurti reikiamą produkciją. Additionally we added a kind of pseudo-projectivisation.  Tai buvo būtina, nes kai kurios užduoties kalbos turi didelę nepriklausomybės medžių dalį. Daugeliu atvejų mes taip pat panaudojome žodžių įterpimą. Keturiose stebuklingose kalbose pateikti duomenys atrodė per maži, kad būtų galima mokytis. Taigi nusprendėme vietoj to naudoti tipiškai artimų kalbų mokymo duomenis. Mūsų sistema pasiekė 68,61 proc. makroekonominio vidurkio LAS (dešimtojo bendro rango), kuris pagerėjo iki 69,38 proc. po klaidų ištaisymo.', 'ml': 'ഈ പത്രത്തില്\u200d ടീം ഓറഞ്ച് ഡെസ്കിന്\u200dറെ സിസ്റ്റം വിവരിക്കുന്നു, കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കുചേര്\u200dത്ത ജോലിയുടെ കാര്യം മിടുല്\u200dലിങ്ക നിലവിലുള്ള ഒരു തുറന്ന ഉറവിട ഉപകരണത്തിന്\u200dറെ (ബിസ്റ്റ് പാര്\u200dസര്\u200d) അടിസ്ഥാനമാക്കിയിരിക്കുന്നു. ആവശ്യമുള്ള ഫല കൂടാതെ നമ്മളൊരു പ്രൊജക്ടിവേഷന്\u200d ചേര്\u200dത്തു. ചില ജോലിയുടെ ഭാഷകളില്\u200d പ്രോജക്ടീവ് ആശ്രയിക്കാത്ത വൃക്ഷങ്ങളുടെ ഉയര്\u200dന്ന ശതമാനമുണ്ട്. മിക്കവാറും കാര്യങ്ങളില്\u200d ഞങ്ങള്\u200d വാക്കുകള്\u200d ചെയ്തിരുന്നു. നാല് അത്ഭുതപ്പെട്ട ഭാഷകള്\u200dക്ക് വേണ്ടി ഡേറ്റാ കൊടുത്തത് പരിശീലിക്കാന്\u200d വളരെ കുറച്ച് കുറച് അതുകൊണ്ട് നമ്മള്\u200d സാധാരണ ഭാഷകള്\u200d അടച്ചുവെക്കുന്നതിനുപകരം ട്രെയിനില്\u200d ഡേറ്റായി ഉപയോഗിക്ക Our system achieved a macro-averaged LAS of 68.61% (10th in the overall ranking) which improved to 69.38% after bug fixes.', 'mt': 'Dan id-dokument jiddeskrivi s-sistema tat-Tim Orange-Deskin , użata għall-Ħidma Kondiviża tal-UD CoNLL 2017 fl-Analiżi tad-Dipendenza Multilingwi. Aħna bbażat l-approċċ tagħna fuq għodda eżistenti ta’ sors miftuħ (BistParser), li mmodifikatna sabiex nipproduċu l-output meħtieġ. Barra minn hekk żiedu tip ta’ psewdoprjetivizzazzjoni. Dan kien meħtieġ peress li wħud mil-lingwi tal-kompitu għandhom perċentwal għoli ta’ siġar ta’ dipendenza mhux proġettiv. Fil-biċċa l-kbira tal-każijiet impjegajna wkoll l-inkorporazzjoni tal-kliem. Għall-erba’ lingwi sorpriżi, id-dejta pprovduta dehret ftit wisq biex titħarreġ. Għalhekk iddeċidew li minflok nużaw id-dejta tat-taħriġ ta’ lingwi tipikament magħluqa. Is-sistema tagħna kisbet LAS makro-medja ta’ 68.61% (l-għaxar fil-klassifikazzjoni globali) li tjiebet għal 69.38% wara l-korrezzjonijiet tal-bug.', 'ro': 'Această lucrare descrie sistemul echipei Orange-Deskin , utilizat pentru CoNLL 2017 UD Shared Task în Multilingval Dependency Parsing. Ne-am bazat abordarea pe un instrument open source existent (BistParser), pe care l-am modificat pentru a produce rezultatul necesar. În plus, am adăugat un fel de pseudo-proiecție. Acest lucru a fost necesar deoarece unele dintre limbile activității au un procent ridicat de arbori de dependență non-proiectivi. În majoritatea cazurilor am folosit, de asemenea, încorporări de cuvinte. Pentru cele 4 limbi surpriză, datele furnizate păreau prea puține pentru a se antrena. Astfel am decis să folosim datele de instruire ale limbilor tipologic apropiate. Sistemul nostru a obținut un LAS mediu macro de 68,61% (al 10-lea în clasamentul general), care s-a îmbunătățit la 69,38% după remedierea erorilor.', 'no': 'Denne papiret beskriver systemet for gruppa Orange-Deskin, brukt for CoNLL 2017 UD-delt oppgåve i fleirspråk avhengighetstolking. Vi baserer tilnærming vårt på eit eksisterande opna kjeldeverktøy (BistParser), som vi endra for å produsera den nødvendige utdata. I tillegg legg vi til ein slags pseudoprojektivizasjon. Dette var nødvendig sidan nokre av oppgåvesspråka har eit høg prosent av ikkje-prosjektive avhengighetstrær. I dei fleste tilfellene har vi også arbeida ord-innbygging. For dei 4 overraskingspråka lykte data for lite å trenja på. I staden bestemte vi å bruka opplæringsdata for typisk lukk språk i staden. Sistemet vårt oppnådd eit makro gjennomsnittleg LAS med 68,61% (10 i den generelle rangeringa), som forbetra til 69,38% etter feilrettinga.', 'mn': 'Энэ цаас CoNLL 2017 оны UD-ын олон хэлний хамааралтай хамааралтай ажил дээр хэрэглэгдсэн Orange-Deskin багийн системийг тайлбарладаг. Бид суурилсан нээлттэй эх үүсвэрийн хэрэгсэл (BistParser) дээр суурилсан арга барилгыг бид хэрэгтэй үр дүн гаргахын тулд өөрчлөгдсөн. Мөн бид нэг төрлийн pseudo-проектив үзүүлэлт нэмсэн. Энэ нь ажлын зарим хэлнүүдийн хувь нь проектив бус хамааралтай моднуудын өндөр хувь нь хэрэгтэй байсан. Ихэнх тохиолдолд бид мөн үг нэвтрүүлэхийг ажилладаг. 4 гайхалтай хэл дээр өгөгдлийн мэдээллийг сургуульд хэтэрхий бага байлаа. Тиймээс бид өөрсдийн оронд хэл ойрхон хэлний дасгал өгөгдлийг ашиглах гэж шийдсэн. Бидний систем 68.61% (нийтлэг хэмжээнд 10) макро дундаж ЛАС гарсан бөгөөд буруу шийдвэрлэсэн дараа 69.38%.', 'so': "Kanu wuxuu ku qoran yahay nidaamka guryaha Orange-Deskin ee loo isticmaalay CoNLL 2017 Shaqada UD ee lagu sharciyey jardiinada ku xiran luqadaha badan. Dhaqsadeena waxaynu ku saleynnay qalabka ay jiraan oo furan (BistParser), taasoo aan u beddelinay si aan u soo bixino waxa loo baahan yahay. Sidoo kale waxaynu ku dari jirnay cayn cayn ah Tan waxaa loo baahan yahay, sababtoo ah luuqadaha shaqada qaarkood waxay leeyihiin boqolkiiba dheer oo ah geedo aan wax ku filnayn. Xaaladaha badankood waxaan sidoo kale shaqo ku qabannay codsiga. Afka luqada la yaabo waxaa loola jeedaa in macluumaadku ay wax ku baran karto. Sidaa darteed waxaan go'aannay inaan isticmaalno macluumaadka waxbarashada sida caadiga ah u xidhan luqadaha. Systemkanagu wuxuu gaadhay macro-average LAS oo ka mid ah 68.61% (10th in the total range) oo kordhisay 69.38% kadib in bug fixo kadib.", 'pl': 'Niniejszy artykuł opisuje system zespołu Orange-Deskin wykorzystywany do wspólnego zadania CoNLL 2017 UD w parowaniu zależności wielojęzycznej. Nasze podejście opieraliśmy na istniejącym narzędziu open source (BistParser), które zmodyfikowaliśmy w celu uzyskania wymaganego wyjścia. Dodatkowo dodaliśmy rodzaj pseudo-projekcji. Było to potrzebne, ponieważ niektóre języki zadania mają wysoki procent drzew zależności nieprojektywnych. W większości przypadków stosowaliśmy również osadzenia słów. W przypadku czterech języków niespodzianek dostarczone dane wydawały się zbyt małe do treningu. Dlatego postanowiliśmy zamiast tego wykorzystać dane szkoleniowe języków bliskich typologicznie. Nasz system osiągnął makro średnią LAS 68.61% (dziesiąty w rankingu ogólnym), która poprawiła się do 69.38% po poprawie błędów.', 'ta': 'இந்த தாள் குழு ஆரஞ்சு-டெசின் அமைப்பை விளக்குகிறது, கோNLL 2017 யுடி பங்கிட்ட பணியை பல மொழி சார்ந்த சார்ந்த பாசிங்கில் பயன்படுத நாங்கள் எங்கள் முறைமையை அடிப்படையில் தேவைப்படும் வெளியீட்டை உருவாக்குவதற்காக ஏற்கனவே இருக்கும் திறந்த மூல கூடுதலாக நாம் ஒரு வகையான பிஸுடோ-திட்டப்பணியை சேர்த்தோம். சில பணியின் மொழிகளில் திட்டப்பணியின் சார்ந்த சார்ந்த மரங்களின் அதிக சதவிகிதத்தில் இருக்கிறது. In most cases we also employed word embeddings.  4 ஆச்சரியமான மொழிகளுக்கு, தகவல் வழங்கப்பட்டது பயிற்சி சிறியதாக இருந்தது. எனவே நாங்கள் வழக்கமாக மூடிய மொழிகளின் பயிற்சி தரவை பயன்படுத்த தீர்மானித்தோம். எங்கள் கணினியில் 68. 61% (மொத்த வரிசையில் 10வது)', 'ur': 'This paper describes the system of the Team Orange-Deskin, used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. ہم نے اپنے طریقے پر ایک موجود اوپن سورس تولیل (BistParser) پر بنیاد رکھا ہے جسے ہم نے ضروری اپوٹ پیٹ پیدا کرنے کے لئے بدل دیا ہے۔ ہم نے اضافہ ایک جوڑا پیسڈو-پروژیکٹ ویزایش اضافہ کیا۔ اس کی ضرورت تھی کیونکہ کچھ دنیا کی زبانوں میں سے بہت زیادہ فیصد غیر پروژیکٹیوں کے درختوں کے درخت ہیں۔ اکثر مواقع میں ہم نے کلمات انڈینگ بھی استعمال کیا۔ چرے تعجب زبانوں کے لئے، دیئے ہوئے ڈیٹے بہت کم بنتے تھے کہ ان پر ترین کریں۔ اسی طرح ہم نے فیصلہ کیا تایپولوژیکی زبانوں کی تربین ڈیٹا استعمال کرنا۔ ہماری سیستم نے 68.61% کی مکرومتوسط LAS (عملہ رینگ میں 10) کو پہنچ لیا تھا۔ جو بوگ اصلاح کے بعد 69.38% تک بہتر ہوا۔', 'si': 'මේ පැත්තේ කණ්ඩායම් නාරංජ් ඩෙස්කින්ගේ පද්ධතිය විස්තර කරනවා, CoNLL 2017 UD කොටස් එක්ක කාර්ය විශේෂ විශේෂ විශේ අපි තියෙන්නේ විසින් ප්\u200dරවෘත උපකරණය (BistParzer) විසින් අපේ ප්\u200dරවෘත්තිය අධාරිත කරනවා, ඒක අපි අවශ්\u200dය ප්\u200dරව තවත් අපි ප්\u200dරශ්නයක් එකතු කළා. මේක අවශ්\u200dය වෙලා තියෙන්නේ කාර්යාගේ භාෂාවල් කිසිම භාෂාවක් ගැන ප්\u200dරශ්නයක් නැති විශාලයක්  ගොඩක් අවස්ථාවන් අපි වචනය සම්බන්ධ කරලා තියෙනවා. පුදුම භාෂාවක් 4ක් වෙනුවෙන්, දෙන්න තොරතුරු ප්\u200dරශ්නයක් පුළුවන් වෙලා වගේ. ඉතින් අපි තීරණය කරලා තියෙන්නේ විද්\u200dයාපාරික භාෂාව වහන්න පුළුවන් දත්ත භාවිත කරන්න අපේ පද්ධතියට 68.61% (සාමාන්\u200dය ප්\u200dරමාණයෙන් 10වෙනි පද්ධතියෙන්) මැක්රෝ අවුරුද්ධ LAS එකක් ලැබුනා, ඒක 69.38% වෙනුවෙන් ප්\u200dරමා', 'sr': 'Ovaj papir opisuje sistem tima Orange-Deskin , koji se koristi za zajednički zadatak CoNLL 2017 UD u razmatranju multijezičkih zavisnosti. Naš pristup je zasnovan na postojećem otvorenom izvornom alatu (BistParser), koju smo modifikovali kako bi proizveli potrebni izlaz. Dodatno smo dodali pseudoprojektivizaciju. To je potrebno otkako neki jezici zadatka imaju visok procenat drveæa neoprojektivne zavisnosti. U veæini sluèajeva smo takoðe zaposlili ukljuèenje reèi. Za četiri jezika iznenađenja, podaci koji su pruženi izgledali su previše malo da bi obučili. Tako smo odlučili da koristimo podatke o obuci tipološki bliskih jezika umjesto toga. Naš sistem je postigao makro srednji LAS od 68,61% (10. u ukupnom redovištu) koji je poboljšao do 69,38% nakon popravke buba.', 'sv': 'Denna uppsats beskriver systemet för Team Orange-Deskin , som används för CoNLL 2017 UD Shared Task i flerspråkig beroendetolkning. Vi byggde vårt tillvägagångssätt på ett befintligt open source-verktyg (BistParser), som vi modifierade för att producera önskad output. Dessutom lade vi till en slags pseudo-projicering. Detta behövdes eftersom vissa av uppgiftens språk har en hög andel icke-projektiva beroendeträd. I de flesta fall använde vi även ordinbäddningar. För de fyra överraskningsspråken verkade de data som tillhandahölls för lite för att träna på. Därför bestämde vi oss för att använda utbildningsdata för typologiskt nära språk istället. Vårt system uppnådde en makro-genomsnittlig LAS på 68,61% (tionde i den totala rankningen) vilket förbättrades till 69,38% efter buggfixar.', 'uz': "Бу саҳифа кўп тил парламент тааллуқида фойдаланилган ҚАНЛ 2017 (CONLL) учун фойдаланилган Қуйи темицент-дескин системни айтиб беради. Biz mavjud ochiq manba asbobi asbobi (BistParser) asosida o'zgarishmiz kerakli natijani yaratish uchun. Ko'pchilik esa biz bir necha pseudo-projektsiyotni qoʻshishdik. This was needed since some of the task's languages have a high percentage of non-projective dependency trees.  Ko'pchilik holatda biz so'zlarni ishlayapmiz. 4 qiziqarli tillar uchun maʼlumotlar qo'shilga o'rganish juda qisqa edi. Shunday qilib biz o'rniga oddiy tilni yopish haqida o'rganishga qaror qildik. @ info: status", 'vi': 'Tờ giấy này mô tả hệ thống của đội Orange-Deskin, được dùng cho hoạt động chia sẻ Coin phần Lời 7 trong chế độ phân phối ngôn ngữ đa. Chúng tôi dựa trên một công cụ mở nguồn (BisTParser), mà chúng tôi đã thay đổi để sản xuất yêu cầu. Thêm nữa, chúng tôi thêm vào một kiểu giả mạo. Điều này cần thiết vì một s ố ngôn ngữ của nhiệm vụ có một số lượng lớn các cây phụ thuộc không dự đoán. Trong hầu hết các trường hợp, chúng tôi cũng dùng từ ngữ: Với bốn ngôn ngữ ngạc nhiên, dữ liệu cung cấp dường như quá ít để tập luyện. Do đó chúng tôi quyết định sử dụng dữ liệu đào tạo của các ngôn ngữ khác nhau. Hệ thống của chúng tôi đã đạt được một LAS tái trung nhất trong 62.61= (10th in the overall ranking) mà đã cải tiến thành 69.38=* sau khi sửa lỗi.', 'da': 'Dette dokument beskriver systemet for Team Orange-Deskin , der anvendes til CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. Vi baserede vores tilgang på et eksisterende open source-værktøj (BistParser), som vi ændrede for at producere det ønskede output. Derudover tilføjede vi en slags pseudo-projektivering. Dette var nødvendigt, da nogle af opgavens sprog har en høj procentdel af ikke-projektive afhængighedstræer. I de fleste tilfælde anvendte vi også ordindlejringer. For de 4 overraskelsessprog syntes de data, der blev givet, for lidt til at træne på. Derfor besluttede vi at bruge træningsdata fra typologisk tætte sprog i stedet. Vores system opnåede et makro-gennemsnit LAS på 68,61% (10. i den samlede ranking), som forbedredes til 69,38% efter fejlrettelser.', 'hr': 'Ovaj papir opisuje sustav tima Orange-Deskin , koji se koristi za zajednički zadatak CoNLL 2017 UD u razmatranju multijezičke zavisnosti. Na temelju našeg pristupa na postojećem otvorenom izvornom alatu (BistParser), kojeg smo modificirali kako bismo proizveli potrebni izlaz. Osim toga, dodali smo pseudoprojektivizaciju. To je potrebno otkako neki jezici zadatka imaju visok procenat drveća neoprojektivne zavisnosti. U većini slučajeva smo također zaposlili uključenje riječi. Za četiri jezika iznenađenja, podaci koje su pružene činili su previše malo da bi se obučili. Tako smo odlučili koristiti podatke o obuci tipološki bliskih jezika umjesto toga. Naš sustav je postigao makro srednji LAS od 68,61% (10. u ukupnom redovištu), koji je poboljšao do 69,38% nakon popravke buba.', 'bg': 'Настоящата статия описва системата на екипа "Оранжево-дескин", използвана за съвместната задача за многоезично анализиране на зависимостта. Базирахме подхода си на съществуващ инструмент с отворен код (БистПарсер), който модифицирахме, за да произведем необходимия изход. Освен това добавихме един вид псевдо-проектизация. Това беше необходимо, тъй като някои от езиците на задачата имат висок процент дървета на непроективна зависимост. В повечето случаи използвахме и вграждане на думи. За четирите езика изненада предоставените данни изглеждаха твърде малко, за да се обучават. Затова решихме вместо това да използваме данните за обучение на типологично близки езици. Системата ни постигна макро-средна стойност от 68.61% (10-то в общата класация), която се подобри до 69.38% след поправки на грешки.', 'de': 'Diese Arbeit beschreibt das System des Team Orange-Deskin, das für die CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing verwendet wurde. Unser Ansatz basiert auf einem bestehenden Open Source Tool (BistParser), welches wir modifiziert haben, um die benötigte Ausgabe zu erzeugen. Zusätzlich haben wir eine Art Pseudo-Projektion hinzugefügt. Dies war notwendig, da einige der Sprachen der Aufgabe einen hohen Prozentsatz an nicht-projektiven Abhängigkeitsbäumen aufweisen. In den meisten Fällen haben wir auch Worteinbettungen eingesetzt. Für die vier Überraschungssprachen schienen die bereitgestellten Daten zu wenig zu trainieren. Daher haben wir uns entschieden, stattdessen die Trainingsdaten typologisch naher Sprachen zu verwenden. Unser System erzielte einen makro-gemittelten LAS von 68.61% (zehnter im Gesamtranking), der sich nach Fehlerbehebungen auf 69.38% verbesserte.', 'nl': 'Dit artikel beschrijft het systeem van het Team Orange-Deskin dat wordt gebruikt voor de CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. We baseerden onze aanpak op een bestaande open source tool (BistParser), die we hebben aangepast om de benodigde output te produceren. Daarnaast hebben we een soort pseudo-projectievisatie toegevoegd. Dit was nodig omdat sommige talen van de taak een hoog percentage niet-projectieve afhankelijkheidsbomen hebben. In de meeste gevallen hebben we ook gebruik gemaakt van woord embeddings. Voor de vier verrassingstalen leek de verstrekte gegevens te weinig om op te trainen. Daarom hebben we besloten om in plaats daarvan de trainingsgegevens van typologisch hechte talen te gebruiken. Ons systeem behaalde een macro-gemiddelde LAS van 68.61% (10e in de algemene ranking) die verbeterde naar 69.38% na bugfixes.', 'ko': '본고는 CoNLL 2017 UD 공유 작업에 사용되는 다중 언어 의존 해석을 위한 Team Orange Deskin 시스템을 기술합니다.BistParser(BistParser)는 기존 소스 오픈 툴을 기반으로 필요한 출력을 생성하도록 수정했습니다.이 밖에 우리는 위조 투영도 추가했다.일부 임무의 언어는 비투영 의존 트리에 비례하기 때문에 필요하다.대부분의 경우, 우리도 단어를 사용하여 삽입한다.이 네 가지 의외의 언어에 대해 제공된 데이터가 너무 적어 훈련을 할 수 없을 것 같다.따라서 유형이 비슷한 언어의 훈련 데이터를 사용하기로 했다.우리 시스템은 68.61%의 거시 평균 LAS(전체 10위)를 실현해 오류를 복구한 뒤 69.38%로 높였다.', 'id': "Kertas ini menggambarkan sistem Tim Orange-Deskin, digunakan untuk CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. Kami mendasarkan pendekatan kami pada alat sumber terbuka yang ada (BistParser), yang kami modifikasikan untuk menghasilkan output yang diperlukan. Selain itu kami menambahkan semacam pseudoproyektivisasi. This was needed since some of the task's languages have a high percentage of non-projective dependency trees.  Dalam kebanyakan kasus kami juga menggunakan pembangunan kata. Untuk 4 bahasa kejutan, data yang diberikan tampaknya terlalu sedikit untuk dilatih. Jadi kami memutuskan untuk menggunakan data latihan dari bahasa tertutup tipologi sebagai gantinya. Sistem kami mencapai LAS makro-rata-rata 68,61% (10 dalam peringkat keseluruhan) yang meningkat ke 69,38% setelah perbaikian bug.", 'fa': 'این کاغذ سیستم تیم Orange-Deskin را توصیف می\u200cکند، که برای کارهای مشترک UD در بازجویی بسیاری از زبان\u200cها استفاده می\u200cشود. ما روش خود را بر روی ابزار منبع باز موجود (BistParser) تغییر دادیم که برای تولید خروجی لازم تغییر دادیم. به اضافه، ما یک نوع تغییر تغییر فکری را اضافه کردیم. این از زمانی که بعضی از زبانهای کار درصدی بالا از درختان بستگی غیر پروژه\u200cای دارند نیاز داشته است. در اکثر مواقع ما همچنین کلمه\u200cهایی را استخدام کردیم. برای چهار زبان سورپرایز، داده\u200cهایی که روزی داده می\u200cشوند خیلی کم به نظر می\u200cرسد که آموزش دهند. بنابراین تصمیم گرفتیم از اطلاعات آموزشی از زبانهای نزدیک تایپولوژیک استفاده کنیم. سیستم ما به یک LAS متوسط میکرومتوسط 68.61 درصد (۱۰ درجه کل درجه) رسید که بعد از اصلاح مشکلات به 69.38 درصد بهتر شد.', 'sw': 'Gazeti hili linaelezea mfumo wa timu ya Orange-Deskin , uliotumiwa kwa ajili ya chama cha CoNLL 2017 UD kilichoshirikisha kazi katika Uhuru wa lugha mbalimbali. Tulianzisha mbinu yetu kwa kutumia zana iliyo wazi (BistParser), ambayo tulibadilisha ili kutengeneza matokeo yanayohitajika. Kwa nyongeza tuliongeza aina ya utaratibu wa kududu. Hili lilihitajika tangu baadhi ya lugha za kazi zina asilimia kubwa ya miti isiyo tegemea. Katika matukio mengi pia tulitumia ujumbe wa maneno. Kwa lugha nne za kushangaza, taarifa hizo zilionekana kuwa ni ndogo sana ya kufundisha. Thus we decided to use the training data of typologically close languages instead.  Mfumo wetu ulipata kiwango cha kuongezeka kwa kiwango cha LAS cha 68.61 (cha 10 katika eneo la jumla) ambalo liliongezeka kwa asilimia 69.38 baada ya kurekebisha mabadiliko.', 'am': 'ይህ ገጽ የብዙልቋንቋ ተሟጋቾች ፓርቲ በኮንஎல_2017የተጠቀም የቡድን ኦርጌ-ዴኪን ስርዓት ይናገራል፡፡ የተፈቀደውን ውጤት ለመፍጠር በተገኘው የክፈት ምንጭ ሀብት (BistParser) በመሠረት ላይ አቀረብን፡፡ በተጨማሪም የ ዓይነት ፕሮጀክት ጨምርን:: የአንዳንዶች የስራ ቋንቋዎች የፕሮጀክት የማይታመኑት ዛፎች ከፍ በመቶው ይኖራሉ፡፡ በብዛት ጉዳይ እና የቃላትን አካባቢ እናገራለን፡፡ ለ4 የበረታች ቋንቋዎች፣ የዳርተኞቹ ሊማር በጣም ጥቂት መስሎ ይመስላል፡፡ እንደዚሁም የድምፅ ቋንቋዎችን ለመጠቀም ወሰንን፡፡ ስርዓታችን የስህተት ክፍል ካደረገ በኋላ 68.61 በመቶ ማክሮር ተቃውሞ LAS (በሙሉ ክፍል 10 በመቶ) አግኝቷል፡፡', 'tr': 'Bu kagyz bir topar Orange-Deskin sistemini, CoNLL 2017-nji ýylda UD Birleşik Diller Baýramlyk Parlamasynda ullanýar Biziň approach bolan açyk çeşme guralymyza daýan ýardyk. gerekli çizgi üretmek üçin üýtgedik. Üstelik bir şekilde pseudo-taslama ekledik. Bu işiň käbir dilinden projektif ýok agaçlaryň ýokarynda gerek bolandy. Köp wagtda biz hem sözlerimizi daşary ulandyk. 4 sany geň gyzyklanýan diller üçin berilen maglumatlar üçin gaty kiçi görünýärdi. Şol sebäpli biz typolojik ýakyn diller üçin bilim maglumatyny ulanmak kararyna geldik. Biziň sistemamyz 68,61% (ähli derejede 10-nji derejä) makro ortalyk LAS bilen ýetdi we bähler tamirlendikden soň 69,38%-a gelişmiş.', 'hy': 'This paper describes the system of the Team Orange-Deskin , used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing.  Մենք հիմնեցինք մեր մոտեցումը գոյություն ունեցող բաց կոդ գործիքի վրա (ԲիսթՓարսեր), որը մենք փոփոխեցինք, որպեսզի ստանանք պահանջված արտադրությունը: Ավելին, մենք ավելացրեցինք մի տեսակ կեղծ պրոեկտիվացման: Սա կարիք ուներ, քանի որ խնդրի որոշ լեզուներն ունեն ոչ պրոեկտիվ կախվածության ծառերի բարձր տոկոս: In most cases we also employed word embeddings.  Չորս զարմանալի լեզուների համար տրամադրված տվյալները չափազանց քիչ էին թվում ուսուցանելու համար: Այսպիսով, մենք որոշեցինք օգտագործել տիպոլոգիապես մոտ լեզուների ուսուցման տվյալները: Մեր համակարգը հասավ 68.61 տոկոսի մակրոմիջին LAS-ի (10-րդ դասակարգում), որը բարելավվեց մինչև 69.38 տոկոս սխալների ուղղումից հետո:', 'af': "Hierdie papier beskrywe die stelsel van die Team Orange-Deskin , gebruik vir die CoNLL 2017 UD Gedeelde Opdrag in Multilingual Afhanklikheidverwerking. Ons gebaseer ons toegang op 'n bestaande open bron hulpmiddel (BistParser), wat ons verander om die benodige uitvoer te produseer. In addition we added a type of pseudo-projectivisation. Dit was benodig sedert sommige van die taak se tale 'n hoë persentasie van nie-projektiewe afhanklikheidsbome het. In meeste gevalle het ons ook woord inbettings gebruik. Vir die 4 verrassing tale het die verskafde data te klein gelyk om op te trein. So het ons besluit om die onderwerp data van tipologies toe taal te gebruik. Ons stelsel het 'n makro-gemiddelde LAS van 68.61% (10de in die hele rangering) bereik wat verbeter na 69.38% na fout regstellings.", 'az': 'Bu kağıt çoxlu dil bağımlılığı Parsing içində kullanılan CoNLL 2017 UD paylaşılan işin Sistemini təsdiqləyir. Biz müəyyən edilmiş açıq mənbə aracı (BistParser) üzərində tərəfimizi dəyişdirdik ki, ehtiyacı olan çıxış yaratmaq üçün dəyişdirdik. Daha da pseudo-projektivizasiya eklədik. Bu işin bəzisinin dillərində projektif olmayan bağımlılıq a ğacların yüksək procenti olmasına görə ehtiyacı vardır. Daha çox məsələlərdə də sözləri istifadə etdik. 4 təəccüblü dillər üçün təmin edilmiş verilər çox az görünürdü. Beləliklə biz typolojik yaxın dillərin təhsil məlumatlarını istifadə etməyə karar verdik. Sistemimiz 68,61% (bütün səviyyədə 10%) makro-ortalamalı LAS qəbul etdi və xəta düzəltdikdən sonra 69,38%-ə düzəltdi.', 'ca': "Aquest article descriu el sistema de l'equip Orange-Deskin, utilitzat per la CoNLL 2017 UD Shared Task in Multilingual Dependence Parsing. Vam basar el nostre enfocament en una eina de codi obert (BistParser), que vam modificar per produir la producció requerida. A més, vam afegir una mena de pseudoprojectivització. This was needed since some of the task's languages have a high percentage of non-projective dependency trees.  En la majoria de casos també utilitzàvem integracions de paraules. Per a les quatre llengües sorprenents, les dades proporcionades semblaven massa poces per entrenar-se. Així que vam decidir utilitzar les dades d'entrenament de llengües tipològicament estretes. El nostre sistema va aconseguir un LAS macromitjà de 68,61% (10è en la classe global) que va millorar al 69,38% després de corregir els errors.", 'sq': "This paper describes the system of the Team Orange-Deskin , used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing.  Ne bazuam qasjen tonë në një mjet ekzistues të burimit të hapur (BistParser), të cilin e modifikuam me qëllim që të prodhojmë daljen e kërkuar. Përveç kësaj shtuam një lloj pseudoprojektivizimi. This was needed since some of the task's languages have a high percentage of non-projective dependency trees.  In most cases we also employed word embeddings.  Për 4 gjuhët e befasuara, të dhënat e dhëna dukeshin të pakta për të trajnuar. Thus we decided to use the training data of typologically close languages instead.  Sistemi ynë arriti një LAS makro-mesatare prej 68.61% (e dhjeta në renditjen e përgjithshme) që u përmirësua në 69.38% pas rregullimit të gabimeve.", 'bs': 'Ovaj papir opisuje sistem tima Orange-Deskin , koji se koristi za zajednički zadatak CoNLL 2017 UD u razmatranju multijezičkih zavisnosti. Naš pristup je zasnovan na postojećem otvorenom izvornom alatu (BistParser), kojeg smo modificirali kako bi proizveli potrebni izlaz. Dodatno smo dodali pseudoprojektivizaciju. To je potrebno otkako neki jezici zadatka imaju visok procenat drveća neoprojektivne zavisnosti. U većini slučajeva smo također zaposlili uključenje riječi. Za četiri jezika iznenađenja, podaci koje su pružene činili su previše malo da bi obučili. Tako smo odlučili da koristimo podatke o obuci tipološki bliskih jezika umjesto toga. Naš sistem je postigao makro srednji LAS od 68,61% (10. u ukupnom redovištu), koji je poboljšao do 69,38% nakon popravke buba.', 'fi': 'Tässä artikkelissa kuvataan Team Orange-Deskin järjestelmää, jota käytetään CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing -tutkimuksessa. Lähestymistapamme perustui olemassa olevaan avoimen lähdekoodin työkaluun (BistParser), jota muokkasimme tuottamaan tarvittavan tuotoksen. Lisäksi lisäsimme eräänlaisen pseudo-projektiivisoinnin. Tämä oli tarpeen, koska joissakin tehtävän kielissä on suuri prosenttiosuus ei-projektiivisista riippuvuuspuista. Useimmissa tapauksissa käytimme myös sanaupotuksia. Neljän yllätyskielen osalta annetut tiedot vaikuttivat liian vähäisiltä harjoitettavaksi. Niinpä päätimme käyttää sen sijaan typologisesti läheisten kielten koulutustietoja. Järjestelmämme saavutti makrokeskiarvon LAS 68,61% (10. kokonaissijoituksessa), joka parani 69,38 prosenttiin virheiden korjauksen jälkeen.', 'et': 'Käesolevas dokumendis kirjeldatakse Team Orange-Deskin süsteemi , mida kasutatakse CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. Meie lähenemisviis tugines olemasolevale avatud lähtekoodiga tööriistale (BistParser), mida muutsime vajaliku väljundi tootmiseks. Lisaks lisasime teatud pseudoprojektiviseerimise. Seda oli vaja, sest mõnedes ülesande keeltes on suur protsent mitteprojektiivseid sõltuvuspuid. Enamikul juhtudel kasutasime ka sõnade manustamist. Nelja üllatuskeele puhul tundusid esitatud andmed liiga vähe, et treenida. Seega otsustasime kasutada selle asemel tüpoloogiliselt lähedaste keelte koolitusandmeid. Meie süsteem saavutas makrokeskmise LAS 68,61% (kümnes üldises edetabelis), mis paranes 69,38%ni pärast veaparandusi.', 'bn': 'এই পত্রিকাটি টিম অরেঞ্জ-ডেসিনের ব্যবস্থা বর্ণনা করেছে, যা কএনএল ২০১৭ সালে মাল্টিভাষার নির্ভরশীল পার্জিং-এ ব্যবহার করা হয়েছে। আমরা বিদ্যমান একটি উন্মুক্ত সোর্স টুল (বিস্টপার্সার) নিয়ে আমাদের প্রতিক্রিয়া ভিত্তিক করেছি যা প্রয়োজনীয় আউট এছাড়াও আমরা একটি ধরনের প্রজেক্টিভিশন যোগ করেছি। কাজের কিছু ভাষার কিছু প্রকল্প নির্ভরশীল গাছের উচ্চশতাংশ আছে। বেশীরভাগ ক্ষেত্রে আমরা শব্দ ব্যবহার করেছি। চারটি বিস্ময়কর ভাষার জন্য, তথ্য প্রদান করা হয়েছে তারা অনেক কম প্রশিক্ষণ করতে পারে। Thus we decided to use the training data of typologically close languages instead.  আমাদের সিস্টেম ম্যাক্রো গড়ে ৬৮. ৬১% (সাধারণ রেঙ্কিং এর ১০তম) অর্জন করেছে যা বাগ সংশোধনের পরে ৬৯. ৩৮% উন্নত হয়েছে।', 'cs': 'Tento článek popisuje systém týmu Orange-Deskin používaný pro sdílenou úlohu CoNLL 2017 UD ve vícejazyčném parsování závislosti. Náš přístup jsme založili na existujícím open source nástroji (BistParser), který jsme upravili tak, aby vytvořil požadovaný výstup. Navíc jsme přidali takový druh pseudo-projekce. To bylo zapotřebí, protože některé jazyky úkolu mají vysoké procento neprojektivních závislostních stromů. Ve většině případů jsme také použili slovní vložení. V případě čtyř jazyků překvapení se poskytnutá data zdála být příliš málo na trénování. Proto jsme se rozhodli použít výcviková data typologicky blízkých jazyků. Náš systém dosáhl makro-průměrného LAS 68.61% (desátého v celkovém žebříčku), který se po opravách chyb zlepšil na 69.38% .', 'jv': 'Perintah iki oleh nggambar sistem Grup Orange-Deskin , nggawe CoNLL 1997 udah Kejaratan Job lan Multilenguasi dipenengke Parasing. Awak dhéwé ngewasi tanggal diagram nang sampeyan open source (bistParaser), sing iki dadi nambah kanggo ngejaraké output dianggap teragram Puntuan sing dipunangé sedhaya, nganggep kuwi tindang nggawe Dadine wis gadhah, kita hukum nggambar kelas embedding kanggo nganggo langkung 4, dadi neng dongke sampek kiya banget tuli. Dadine awak dhéwé wis disimbalki nggawe data nggawe barang tipik, dadi kapan langgar. Sistem dhéwé iso nglanggar macro-mediarané sing wis rampun sedhaya karo 60.60% (10) sing ditambah sing ditambah menyang kalah-arah sing ditambah kanggo kalah-arah sing lunak-arah sing luwih sabên, wé menyang kalah-arah sing luwih dumadhi diwé.', 'he': 'This paper describes the system of the Team Orange-Deskin , used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing.  הבססנו את הגישה שלנו על כלי מקור פתוח קיים (BistParser), אשר שינונו כדי לייצר את ההוצאה הנדרשת. בנוסף הוספנו סוג של פסאודו-פרויקטיביזציה. זה היה נחוץ מכיוון שלחלק מהשפות של המשימה יש אחוז גבוה של עצי תלויות לא פרויקטיביים. ברוב המקרים השתמשנו גם בתכניות מילים. לארבעה שפות הפתעה, הנתונים שנספקו נראו מעט מדי להתאמן עליהם. כך החלטנו להשתמש במידע האימוני של שפות טיפולוגיות קרובות במקום. המערכת שלנו השיגה LAS בממוצע מקרו של 68.61% (עשרה ברמה הכללית) אשר השתפר ל 69.38% אחרי תיקון באגים.', 'sk': 'Ta prispevek opisuje sistem Team Orange-Deskin , ki se uporablja za CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. Naš pristop smo temeljili na obstoječem odprtokodnem orodju (BistParser), ki smo ga spremenili, da bi ustvarili potrebno rezultato. Poleg tega smo dodali nekakšno psevdo-projektivizacijo. To je bilo potrebno, saj imajo nekateri jeziki opravila visok odstotek neprojektivnih dreves odvisnosti. V večini primerov smo uporabili tudi besedne vdelave. Za štiri jezike presenečenja se je zdelo, da so bili predloženi podatki premalo za usposabljanje. Zato smo se odločili, da namesto tega uporabimo podatke o usposabljanju tipološko tesnih jezikov. Naš sistem je dosegel makropovprečno LAS 68,61% (10. v splošni lestvici), ki se je po popravkih napak izboljšal na 69,38%.', 'ha': "Wannan karatun na describe the system of the Team Orang-deskin , used for the CoNLL 2017 UD Shared Takar in multiziman Deputy Parse. Mun ƙayyade kanmu a kan wata zanar ajiye mai buɗe (BistParser), wanda muka gyare shi dõmin ya sami gabatar da fitarwa wanda ake ƙayyade. Da haka, muka ƙara wani irin mutane na kududo. An buƙata wannan, sabõda akwai wasu harshen aikin su da wani asilimi mai tsawo na itãcen da bã ya dõgara. Ga mafi yawan kashfa, mun yi aiki da maganar da aka zura. Ga harshen 4 da aka yi mãmãki, data da aka ba ta zama mai ƙaranci ba ga ya yi wa lõkaci. Kayya, sai muka yi fatan mu yi amfani da data na tsarin lugha na'ura. @ info: status", 'bo': 'ཤོག We based our approach on an existing open source tool (BistParser), which we modified in order to produce the required output. འོན་ཀྱང་། ང་ཚོས་དུས་ཡོད་པའི་འཚོལ་ཞིབ་བྱེད་པའི་ཐབས་ལམ་ཞིག་ཁ་སྣོན་བྱས་པ་རེད། འདི་ལ་ལས་འགུལ་གྱི་སྐད་རིགས་ཁ་ཤས་ཀྱི་རྒྱ་ཆ་མཐོ་བར་ནུས་པ་མིན་པས་རྐྱེན་སྐྱེས་བ་ཡོད། ཕལ་ཆེར་མང་ཆེ་བའི་ནང་དུ་ང་ཚོས་ཀྱང་སྦྲེལ་བའི་ཐ་སྙད་ཀྱི་འཛིན་བྱས་པ་ཡིན། སྐད་རིགས་འདིའི་ནང་དུ་མཛུབ་མཁན་གྱི་སྐད་ཡིག་ཆ་བཞིན་ལ་སྐྱེས་བ་ཡོད་པས། དེར་བརྟེན། ང་ཚོས་སྐད་རིགས་དབྱིན་གྱིས་སྒོ་རྒྱག་པའི་བརྡ་འཕྲིན་གྲངས་བ་དེ་བེད་སྤྱོད་དགོས། ང་ཚོའི་མ་ལག་གི་སྡོམ་གྲངས་ཀྱི་ཚད་གཞི་བརྗོད་མཁན་68.61% (གྲངས་སྒྲིག་གྲངས་ཀྱི་བཅུ་ཐམ་ཆ་གཅིག་གི་ནང་དུ་འགྱུར་སོང་་སྐྱེས་ཚད་ལྡན་མ་'}
{'en': 'TurkuNLP : Delexicalized Pre-training of Word Embeddings for Dependency Parsing', 'ar': 'TurkuNLP: تدريب مسبق غير مكتمل على Word Embeddings لتحليل التبعية', 'es': 'TurkunLP: preentrenamiento deslicalizado de incrustaciones de palabras para el análisis de dependencias', 'pt': 'TurkuNLP: Pré-treinamento deslexicalizado de Word Embeddings para análise de dependência', 'fr': "TurkunLP\xa0: Pré-apprentissage délexicalisé des intégrations de mots pour l'analyse des dépendances", 'ja': 'TurkuNLP ：依存関係解析のためのWord埋め込みのデレクシライズされた事前トレーニング', 'ru': 'TurkuNLP: Delexicalized Pre-training of Word Embeddings for Dependency Parsing', 'zh': 'TurkuNLP:赖解析词销德莱克化预训练', 'hi': 'TurkuNLP: निर्भरता पार्सिंग के लिए Word Embeddings के Delexicalized पूर्व प्रशिक्षण', 'ga': 'TurkuNLP: Réamh-Oiliúint Dhíleicseála ar Leabú Focal le haghaidh Parsáil Spleáchais', 'ka': 'TurkuNLP', 'el': 'ΤερκούNLP: Απεξαξιοποιημένη Προεκπαίδευση των Ενσωματώσεων λέξεων για ανάλυση εξάρτησης', 'hu': 'TurkuNLP: Szövegbeágyazások eltávolított előképzése a függőség értelmezéséhez', 'it': "TurkuNLP: Pre-formazione Delessicalizzata delle incorporazioni di parole per l'analisi delle dipendenze", 'kk': 'ТүркуNLP: Тәуелсіздік талдау үшін сөздерді ендіру алдындағы өшіру', 'lt': 'TurkuNLP: Deleksionalizuotas išankstinis žodžių įrangos mokymas priklausomybės analizei', 'mk': 'ТуркуNLP: Делексикализиран предобук за вградување на зборови за анализирање зависности', 'ms': 'TurkuNLP: Pra-latihan Dideleksikalkan untuk Penyesuaian Perkataan', 'mt': 'TurkuNLP: Taħriġ ta’ Qabel Delessjalizzat ta’ Embeddings tal-kliem għall-Analiżi tad-Dipendenza', 'mn': 'TurkuNLP: Хувьсгалын хууль шалгалтын тулд хамааралтай үгийн эхний сургалт', 'ml': 'തുര്\u200dക്കുNLP: വാക്കുകളുടെ എംബെഡിങ്ങുകള്\u200dക്ക് മുന്\u200dപ് പരിശീലിപ്പിക്കപ്പെട്ടിരിക്കുന്നു', 'no': 'TurkuNLP: Deleksisert føreøving av ordinnbygging for avhengighetstolking', 'sr': 'TurkuNLP: Deleksikalizirana predobuka za uključenje riječi za analizu zavisnosti', 'pl': 'TurkuNLP: Deleksykalizowane szkolenie wstępne osadzeń słowa do parowania zależności', 'ro': 'TurkuNLP: Pre-instruirea delexicalizată a încorporărilor Word pentru analizarea dependenței', 'si': 'Name', 'so': 'TurkuNLP: Delexicalized Pre-training of Word Embedding for Dependence Parsing', 'sv': 'TurkuNLP: Delexikaliserad förhandsutbildning av Word Embeddings för beroendetolkning', 'ta': 'துருக்குNLP: சார்ந்த பாசிங்குக்கான வார்த்தை உடைப்புகளின் முன் பயிற்சியை நீக்கு', 'ur': 'ترکوNLP: اعتمادی پارسینگ کے لئے کلمات امڈینگ کی پیش آموزش کی حذف کرتی ہے', 'uz': 'TurkuNLP: EĘĽtibor berish', 'vi': 'TurkuNLP: Tập Trước huấn khai thác Bàn Tay.', 'bg': 'ТуркуНЛП: Делексикализирано предварително обучение на вграждания на думи за анализ на зависимостта', 'nl': 'TurkuNLP: Delexicaliseerde Voortraining van Word Embeddings voor afhankelijkheidsparsing', 'hr': 'TurkuNLP: Deleksikalizirana predobuka uključenja riječi za razmatranje ovisnosti', 'da': 'TurkuNLP: Deleksiseret Pre-Training of Word Embeddings for Dependency Parsing', 'de': 'TurkuNLP: Delexikalized Pre-Training von Word Embeddings für Dependency Parsing', 'fa': 'TurkuNLP: تحصیلات پیش از آموزش کلمات برای تحلیل بستگی', 'ko': 'TurkuNLP: 분석에 의존하는 단어에 삽입된 어휘화 예습 훈련', 'id': 'TurkuNLP: Deleksialised Pre-training of Word Embeddings for Dependency Parsing', 'tr': 'Türk', 'sw': 'Uturuki NLP: Kufukuzwa kwa mafunzo ya Kujiunga na Uhuru', 'sq': 'TurkuNLP: Deleksionalizuar paratrajnimi i përfshirjeve të fjalëve për analizimin e varësive', 'af': 'Name', 'bn': 'তুর্কুনএনএলপি: নির্ভর পার্সিং এর জন্য শব্দ এমবেডিং এর পূর্ব প্রশিক্ষণের প্রশিক্ষণ প্রদান করা হয়েছে', 'am': 'ቱርኩንNLP: Delexicaled Pre-training of Word Embeddings for Dependency Parsing', 'hy': 'Թուրկու', 'az': 'TurkuNLP: Bağılıqlıq Parlaması üçün Sözlər İfadələrinin Ön-təhsilini Delexicalized Pre-training of Word Embeddings', 'ca': 'TurkuNLP: Pre-entrenament delexicalitzat de Word Embeddings for Dependency Parsing', 'et': 'TurkuNLP: Sõnapõimimiste deleksikaliseeritud eelkoolitus sõltuvuse parsimiseks', 'cs': 'TurkuNLP: Delexikalizovaný předškolení vložení slov pro analýzu závislostí', 'fi': 'TurkuNLP: Sanaupotusten deleksikalisoitu esikoulutus riippuvuuden analysointiin', 'bs': 'TurkuNLP: Deleksikalizirana predobuka za uključenje riječi za analizu zavisnosti', 'ha': '@ action', 'sk': 'TurkuNLP: Deleksikalizirano Predusposabljanje vdelav besed za razčlenitev odvisnosti', 'he': 'TurkuNLP: אימון מראשי דלקסיקלי של התקפיצות מילים עבור בדיקת תלויות', 'jv': 'Name', 'bo': 'TurkuNLP: Delexicalized Pre-training of Word Embeddings for Dependency Parsing'}
{'en': 'We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. The system is based on the UDPipe parser with our focus being in exploring various techniques to pre-train the word embeddings used by the parser in order to improve its performance especially on languages with small training sets. The system ranked 11th among the 33 participants overall, being 8th on the small treebanks, 10th on the large treebanks, 12th on the parallel test sets, and 26th on the surprise languages.', 'fr': "Nous présentons l'entrée TurkunLP dans la tâche partagée ConLL 2017 sur l'analyse multilingue du texte brut aux dépendances universelles. Le système est basé sur l'analyseur UDPipe, notre objectif étant d'explorer diverses techniques pour pré-entraîner les intégrations de mots utilisées par l'analyseur afin d'améliorer ses performances, en particulier sur les langages avec de petits ensembles d'apprentissage. Le système s'est classé 11e parmi les 33 participants au total, se classant 8e sur les petites berges, 10e sur les grandes rives, 12e sur les ensembles de tests parallèles et 26e sur les langues surprises.", 'es': 'Presentamos la entrada de TurkunLP en la tarea compartida de CoNll 2017 sobre análisis multilingüe del texto sin procesar a las dependencias universales. El sistema se basa en el analizador UDPipe y nos centramos en explorar varias técnicas para preentrenar las incrustaciones de palabras utilizadas por el analizador para mejorar su rendimiento, especialmente en idiomas con conjuntos de entrenamiento pequeños. El sistema ocupó el puesto 11 entre los 33 participantes en general, siendo el 8° en los bancos de árboles pequeños, el 10° en los bancos de árboles grandes, el 12° en los conjuntos de pruebas paralelas y el 26 en los idiomas sorpresa.', 'ar': 'نقدم إدخال TurkuNLP في المهمة المشتركة لـ CoNLL 2017 حول التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. يعتمد النظام على المحلل اللغوي UDPipe مع تركيزنا على استكشاف تقنيات مختلفة للتدريب المسبق على الكلمة التي يستخدمها المحلل اللغوي لتحسين أدائها خاصة في اللغات ذات مجموعات التدريب الصغيرة. احتل النظام المرتبة 11 من بين 33 مشاركًا بشكل عام ، حيث احتل المرتبة الثامنة على ضفاف الأشجار الصغيرة ، والمرتبة 10 على ضفاف الأشجار الكبيرة ، والمرتبة 12 في مجموعات الاختبار المتوازية ، والمرتبة 26 في اللغات المفاجئة.', 'pt': 'Apresentamos a entrada TurkuNLP na tarefa compartilhada CoNLL 2017 sobre análise multilíngue de texto bruto para dependências universais. O sistema é baseado no analisador UDPipe com nosso foco em explorar várias técnicas para pré-treinar os embeddings de palavras usados pelo analisador para melhorar seu desempenho principalmente em linguagens com pequenos conjuntos de treinamento. O sistema ficou em 11º lugar entre os 33 participantes no geral, sendo 8º nos bancos de árvores pequenos, 10º nos bancos de árvores grandes, 12º nos conjuntos de testes paralelos e 26º nas linguagens surpresa.', 'hi': 'हम CoNLL 2017 में TurkuNLP प्रविष्टि प्रस्तुत करते हैं, जो कि रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग पर साझा कार्य है। सिस्टम UDPipe पार्सर पर आधारित है, जिसमें हमारा ध्यान विभिन्न तकनीकों की खोज करने के लिए पार्सर द्वारा उपयोग किए जाने वाले शब्द एम्बेडिंग को पूर्व-प्रशिक्षित करने के लिए किया जा रहा है ताकि विशेष रूप से छोटे प्रशिक्षण सेट वाली भाषाओं पर अपने प्रदर्शन में सुधार हो सके। सिस्टम कुल मिलाकर 33 प्रतिभागियों के बीच 11 वें स्थान पर है, छोटे ट्रीबैंक पर 8 वें, बड़े ट्रीबैंक पर 10 वें, समानांतर परीक्षण सेट पर 12 वें, और आश्चर्य भाषाओं पर 26 वें स्थान पर है।', 'ja': '私たちは、生テキストから普遍的な依存関係への多言語解析に関するCoNLL 2017共有タスクでTurkuNLPエントリを提示します。このシステムは、UDPipeパーサーに基づいており、特に小さなトレーニングセットを持つ言語でパフォーマンスを向上させるために、パーサーが使用する単語埋め込みを事前にトレーニングするためのさまざまなテクニックを探求することに焦点を当てています。このシステムは、全体で33人の参加者のうち11位にランクされ、小さなツリーバンクで8位、大きなツリーバンクで10位、並列テストセットで12位、サプライズ言語で26位でした。', 'zh': '于 CoNLL 2017 中言 TurkuNLP 条目,当事涉原始文本至通用赖者多言解析。 其统UDPipe解析器,吾之重者,探诸术以预训练解析器其词嵌之,以崇其性,特在小集之言。 其统在33名参与者中排名第11位,在小树岸上排名第8位,在大树岸上排名第10位,在并行测试集排名第12位,在惊喜语中排名第26位。', 'ru': 'Мы представляем запись TurkuNLP в CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. Система основана на парсере UDPipe с нашим акцентом на изучении различных методов предварительного обучения вложений слов, используемых парсером, чтобы улучшить его производительность, особенно на языках с небольшими обучающими наборами. Система заняла 11-е место среди 33 участников в целом, 8-е место на малых берегах деревьев, 10-е место на больших берегах деревьев, 12-е место на параллельных тестовых наборах и 26-е место на языках сюрпризов.', 'ga': 'Cuirimid iontráil TurkuNLP i láthair i dTasc Comhroinnte CoNLL 2017 ar Pharsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch. Tá an córas bunaithe ar pharsálaí an UDPipe agus dírímid ar iniúchadh a dhéanamh ar theicnící éagsúla chun an leabú focal a úsáideann an parsálaí a réamh-thraenáil chun a fheidhmíocht a fheabhsú go háirithe ar theangacha le tacair bheaga oiliúna. Bhí an córas sa 11ú háit i measc na 33 rannpháirtí san iomlán, agus é san 8ú háit ar na bruacha beaga crann, sa 10ú háit ar na bruacha móra crann, sa 12ú háit ar na tacair tástála comhthreomhara, agus sa 26ú háit ar na teangacha iontasacha.', 'hu': 'Bemutatjuk a TurkuNLP bejegyzést a CoNLL 2017 megosztott feladatának többnyelvű értelmezéséről a nyers szövegtől az univerzális függőségekig. A rendszer az UDPipe elemzőn alapul, különböző technikák feltárására összpontosítunk, hogy előkészítsük az elemző által használt beágyazásokat annak érdekében, hogy javítsuk teljesítményét, különösen a kis képzési készletekkel rendelkező nyelveken. A rendszer a 11. helyen állt a 33 résztvevő közül, 8. helyen a kisebb fapadokon, 10. helyen a nagyobb fapadokon, 12. helyen a párhuzamos tesztkészleteken, 26. helyen a meglepetés nyelveken.', 'ka': 'ჩვენ შევაჩვენეთ TurkuNLP-ის ჩანაწერა CoNLL 2017-ის მრავალენგური წარმოწმების მნიშვნელოვანი დავალების მნიშვნელოვანი ტექსტიდან უნივერსოლური განსაზღვრებაში. სისტემა UDPipe პანსერერისთვის ბაზია, რომელიც ჩვენი ფონსური ტექნექციების განსხვავებაში იქნება, რომ პანსერისთვის გამოყენებული სიტყვების გარეშე განსხვავებლად განსხვავებული სიტყვების გა სისტემა 33 მოთავსწავლებელი შორის 11-ია, 8-ია პატარა საბოლოში, 10-ია დიდი საბოლოში, 12-ია პარალელი ტესტის სეტებში და 26-ია საბოლოო ენაში.', 'kk': 'Біз 2017 жылы CoNLL 2017 жылы ТуркNLP бағдарламасының бірнеше тілдік талдау жұмысына көп тілдік талдау жұмысына келтірдік. Бұл жүйе UDPipe талдаушысына негізделген, басқа технологияларды зерттеу үшін, талдаушы қолданылатын сөздерді ендіру үшін, өзіміздің әдеттегісін өзгерту үшін, әдетте, кішкентай оқыту бағдарламал Бұл жүйе 33 қатысушылардың 11-інші ретінде, кішкентай құрылғылардың 8-інші ретінде, 10-інші үлкен құрылғыларында, 12-інші параллель сынақтар жиындарында, 26-інші тілде.', 'it': "Presentiamo la voce TurkuNLP nel CoNLL 2017 Shared Task sull'analisi multilingue dal testo grezzo alle dipendenze universali. Il sistema si basa sul parser UDPipe con l'obiettivo di esplorare varie tecniche per pre-formare le parole embeddings utilizzate dal parser al fine di migliorarne le prestazioni soprattutto su linguaggi con piccoli set di formazione. Il sistema si è classificato undicesimo tra i 33 partecipanti complessivi, essendo ottavo sui piccoli alberi, decimo sui grandi alberi, dodicesimo sui set di test paralleli e 26esimo sulle lingue a sorpresa.", 'lt': 'Mes pristatome TurkuNLP įrašą CoNLL 2017 m. bendrame uždavinyje daugiakalbis analizavimas iš žaliavinio teksto į visuotines priklausomybes. Sistema grindžiama UDPipe analizatoriumi, kuriame daugiausia dėmesio skiriama įvairiems metodams, kuriais iš anksto rengiami žodžiai, kuriuos naudoja analizatorius, siekiant pagerinti jo veiksmingumą, ypač kalbomis su mažais mokymo rinkiniais. The system ranked 11th among the 33 participants overall, being 8th on the small treebanks, 10th on the large treebanks, 12th on the parallel test sets, and 26th on the surprise languages.', 'mk': 'Го претставуваме влезот на ТуркуНЛП во Соделената задача на CoNLL 2017 за повеќејазично анализирање од суров текст до универзални зависности. Системот е базиран на апараторот UDPipe со нашиот фокус на истражување на различни техники за преобука на зборовите вградени користени од апараторот со цел подобрување на неговата перформанса особено на јазиците со мали обуки. Системот се рангираше на 11-тото место меѓу вкупно 33 учесници, осмиот на малите дрвја, десетото на големите дрвја, 12-тото на паралелните тестови и 26-тото на изненадувачките јазици.', 'ml': 'ഞങ്ങള്\u200d കോണ്\u200dഎല്\u200d 2017 ലെ തുര്\u200dക്കുന്ന എണ്ട്രിപ്പിനെ കാണിച്ചുകൊടുക്കുന്നു. റോ ടെക്സ്റ്റില്\u200d നിന്നും യൂണിവര്\u200dണ്ണല്\u200d ആധിപത്യ ഈ സിസ്റ്റത്തിന്റെ അടിസ്ഥാനത്താണ് യുഡിപിപിപി പരിശോധിക്കുന്നത്, ചെറിയ ട്രെയിനിസ്റ്റുകള്\u200d മുന്\u200dകൂട്ടി പരിശീലിക്കുന്ന വാക്കുകള്\u200d പരിശീല 33 പങ്കാളികളില്\u200d മുഴുവനും ഈ സിസ്റ്റത്തിന്റെ 11മത്തേതാണ് ഉള്ളത്, ചെറിയ ട്രീബ്ബാങ്കില്\u200d എട്ടാം ആയിരുന്നു, വലിയ ട്രീബാങ്കില്\u200d പത്താമത്തേത്,', 'ms': 'Kami memperkenalkan masukan TurkuNLP dalam Tugas Berkongsi CoNLL 2017 tentang penghuraian berbilang bahasa dari Teks Raw ke Dependensi Universal. Sistem ini berdasarkan penghurai UDPipe dengan fokus kami adalah dalam mengeksplorasi berbagai teknik untuk melatih awal penyembahan perkataan yang digunakan oleh penghurai untuk meningkatkan prestasinya terutama pada bahasa dengan set latihan kecil. Sistem ini berturut-turut ke-11 diantara 33 peserta secara keseluruhan, menjadi ke-8 di atas bank pokok kecil, ke-10 di atas bank pokok besar, ke-12 di set ujian selari, dan ke-26 pada bahasa kejutan.', 'el': 'Παρουσιάζουμε την καταχώρηση στην κοινή εργασία για την πολύγλωσση ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Το σύστημα βασίζεται στον αναλυτή με έμφαση στην εξερεύνηση διαφόρων τεχνικών προεκπαίδευσης της λέξης που χρησιμοποιεί ο αναλυτής προκειμένου να βελτιωθεί η απόδοσή του ειδικά σε γλώσσες με μικρά σύνολα εκπαίδευσης. Το σύστημα κατατάχθηκε 11η μεταξύ των 33 συμμετεχόντων συνολικά, 8η στις μικρές όχθες δέντρων, 10η στις μεγάλες όχθες δέντρων, 12η στα παράλληλα δοκιμαστικά σύνολα και 26η στις γλώσσες έκπληξης.', 'mt': 'Aħna nippreżentaw l-entrata TurkuNLP fil-Kompitu Konġunt CoNLL 2017 dwar l-Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali. Is-sistema hija bbażata fuq il-analizzatur UDPipe bil-fokus tagħna huwa fl-esplorazzjoni ta’ diversi tekniki biex jitħarrġu minn qabel il-kliem inkorporati użati mill-analizzatur sabiex tittejjeb il-prestazzjoni tiegħu speċjalment fuq lingwi b’settijiet żgħar ta’ taħriġ. Is-sistema kklassifikat fil-11 fost it-33 parteċipant b’mod ġenerali, li kienu t-8 fuq il-banek żgħar tas-siġar, l-10 fuq il-banek kbar tas-siġar, it-12 fuq is-settijiet paralleli tat-testijiet, u s-26 fuq il-lingwi tas-sorpriża.', 'mn': 'Бид 2017 оны CoNLL 2017 оны ТуркуNLP-н олон хэлний талаарх олон хэлний талаарх хуваалцах үйл ажиллагааг харуулж байна. Энэ систем нь UDPipe хуваалцагч дээр суурилсан, бидний анхаарлаа олон технологиудыг судалж, хуваалцагчид ашиглаж буй үгийг илүү сайжруулахын тулд, ялангуяа жижиг сургалтын хэл дээр ажиллах боломжтой. Энэ систем 33 оролцогчдын 11-р дүрс байсан бөгөөд жижиг дагуу дээр 8-р дүрс байсан бөгөөд том дагуу дээр 10-р дүрс байсан бөгөөд параллель тест дээр 12-р дүрс байсан бөгөөд 26-р гайхалтай хэл дээр байсан.', 'no': 'Vi presenterer TurkuNLP- oppføringa i CoNLL 2017 delt oppgåve om fleirspråk tolking frå råtekst til universelle avhengighet. Systemet er basert på UDPipe-tolkaren med fokusen vår i å utforska ulike teknikk for å først trenga innbygginga av ordet som skal brukast av tolkaren for å forbetra utviklinga sitt spesielt på språk med små opplæringssett. Systemet rangerte 11. mellom de 33 deltakarane i alt, som er 8. på dei lille treebankene, 10. på dei store treebankene, 12. på parallelle testsettene, og 26. på oversiktspråka.', 'ro': 'Prezentăm intrarea TurkuNLP în CoNLL 2017 Shared Task on Multilingv Parsing from Raw Text to Universal Dependents. Sistemul se bazează pe parserul UDPipe, concentrându-ne pe explorarea diferitelor tehnici de pre-antrenare a cuvântului încorporat folosit de parser pentru a îmbunătăți performanța acestuia în special pe limbile cu seturi mici de instruire. Sistemul s-a clasat pe locul 11 în rândul celor 33 de participanți în total, fiind al 8-lea pe brațele mici, al 10-lea pe brațele mari, al 12-lea pe seturile paralele de testare și al 26-lea pe limbile surpriză.', 'pl': 'Przedstawiamy wpis TurkuNLP w CoNLL 2017 Shared Task on Multilingual Parsing from Sur Text to Universal Dependences. System oparty jest na parserze UDPipe, koncentrujemy się na badaniu różnych technik wstępnego treningu osadzeń słowa używanych przez parser w celu poprawy jego wydajności, zwłaszcza w językach z małymi zestawami szkoleniowymi. System zajął jedenasty miejsce wśród 33 uczestników ogólnie, był ósmym na małych brzegach drzew, dziesiątym na dużych brzegach drzew, dwunastym na równoległych zestawach testowych i 26-tym w językach zaskoczenia.', 'sr': 'Predstavljamo ulaz TurkuNLP u CoNLL 2017. zajednièki zadatak o multijezičkom razmatranju sa sirovog teksta na univerzalne zavisnosti. Sistem je zasnovan na UDPipe analizatoru sa fokusiranjem u istraživanju različitih tehnika za predobuku reči koje je koristio analizator kako bi poboljšao svoj učinkovit posebno na jezicima sa male obuke. Sistem je bio 11. među 33 sudionika u ukupnom položaju, 8. na malim područjima, 10. na velikim područjima, 12. na paralelnim testovima, i 26. na jezicima iznenađenja.', 'si': 'අපි තුර්කුන්ල්ප් ඇතුලට පෙන්වන්නේ 2017 CoNLL වලින් බොහොම භාෂාවක් විශාල විශාල විශාල විශාල විශාල විශාල වෙන මේ පද්ධතිය UDPipe විශේෂකයේ අධාරණය වෙන්නේ අපේ අවධානය විවිධ ප්\u200dරකාශයක් පරීක්ෂණය කරනවා විශේෂකයෙන් විශේෂකයෙන් භාවිත කර පද්ධතිය සාමාන්\u200dයයෙන් අංක 33 අතර පද්ධතිය කරලා තියෙනවා, පුංචි විදියට 8වෙනි විදියට, 10වෙනි විශාල විදියට, 12වෙනි විදියට පරීක්ෂා', 'so': 'Waxaynu soo bandhignaynaa qoraalka TurkuNLP ee CoNLL 2017 ee lagu sharciyey shaqo ku saabsan jardiinada luuqadaha kala duduwan ee Raw Text-to-Suomiyada jaamacadda. nidaamka waxaa ku saleysan baaritaanka UDPipe (UDPipe Parser) iyadoo aad ku haysato baaritaanka kala duduwan si ay horay u baaraandegiso hadalka ku saabsan baaritaanka beeraha lagu isticmaalo si uu u hagaajiyo tababarka si gaar ah oo ku qoran luuqadaha waxbarasho yar. Tirku wuxuu ka mid ahaa 11aad oo ka mid ah 33-ka saaxiib ah, waxayna ahaayeen 8aad oo ku taal dareecadaha yaryar, Tiraad oo ku taal dareecadaha waaweyn, 12aad oo ku qoran heerarka imtixaanka lambarka ah, 26aad oo ku qoran luqadaha yaabka leh.', 'sv': 'Vi presenterar TurkuNLP-posten i CoNLL 2017 delad uppgift om flerspråkig tolkning från råtext till universella beroende. Systemet är baserat på UDPipe parser med vårt fokus på att utforska olika tekniker för att pre-träna ordet inbäddningar som används av parser för att förbättra dess prestanda särskilt på språk med små träningsuppsättningar. Systemet rankades 11:e bland de 33 deltagarna totalt och var 8:e på de små trädbackarna, 10:e på de stora trädbackarna, 12:e på de parallella testuppsättningarna och 26:e på överraskningsspråken.', 'ur': 'We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. سیسٹم UDPipe پارچر پر بنیاد ہے کہ ہمارا منظور مختلف ٹیکنالوں کی تحقیق کرنے کے لئے مختلف ٹیکنالوں میں ہے کہ پارچر کے ذریعے استعمال ہونے والی کلمات کے مطابق استعمال کرنے کے لئے اس کی عملکرد مخصوصاً چھوٹی ٹیکنالوں کے م سیسٹم 33 شرکت کرنے والوں میں سب سے 11م درجہ تھا، چھوٹے ٹریب بانک پر 8م، 10م درجہ ٹریب بانک پر، 12م درجہ تست سٹ پر، اور 26م تعجب زبانوں پر۔', 'ta': 'நாங்கள் கோன்எல் 2017 ல் துருக்குNLP நுழைவை காண்பிக்கிறோம் ரா உரையிலிருந்து உலக சார்ந்த சார்புகளுக்கு பல மொழி பாசிங்கள்  இந்த அமைப்பு UDPipe தொகுப்பானை அடிப்படையாக இருக்கிறது சிறிய பயிற்சி அமைப்புகளுடன் முன் பயிற்சி செய்யும் வார்த்தையை முன் பயிற்சி செய்ய ம 33 பங்குபவர்களில் 11வது முறையாக அமைப்பு முறையில் உள்ளது, சிறிய treebanks எட்டாவது, பெரிய மரப்பாங்கில் 10வது, இணைப்பு சோதனைகளில் 12வது, ஆச்சரியமான மொழிகளில் 26', 'uz': "Biz CoNLL 2017-yilda TurkuNLP yozuvchi vazifani Ray Matn bilan bir necha tillar parsing vazifani Universal qoʻllanmalar bilan birlashtiramiz. Name Tizim butun 33 ta'lim participlarning 11 chi chegarasi o'zgarishdi, 8 chi kichkina treebanglarda, 10 chi katta treebanlarda, 12 chi parallel sinov satlarida, va 26 chi qiziqarli tillarda.", 'vi': 'Chúng tôi giới thiệu bản ghi TurkuNLP trong Tập đoàn CoNll Buổi đọc Chúa Công tác chia sẻ về triệt tích đa ngôn ngữ từ văn bản thô đến các quan hệ chung. Hệ thống này dựa trên bộ phân tách UDPipe và tập trung nghiên cứu các kỹ thuật khác nhau để sửa chữa những từ ngữ được sử dụng bởi phân viên để tăng hiệu suất của nó, nhất là trên các ngôn ngữ có các bộ giáo dục nhỏ. Hệ thống được xếp hạng 11th trong giới hợp 33, là thứ 8th ở các cây ba nhỏ, 10th trên các cây giá ba lớn, 12th trên các bộ bài kiểm tra song song, và 2th trên các ngôn ngữ ngạc nhiên.', 'bg': 'Представяме записа на ТюркуНЛП в споделената задача за многоезично анализиране от суров текст до универсални зависимости. Системата е базирана на анализатора, като фокусът ни е в проучването на различни техники за предварително обучение на вградените думи, използвани от анализатора, за да подобрим ефективността му особено на езици с малки набори за обучение. Системата се класира на 11-о място сред 33-те участници като цяло, като се класира на 8-о място в малките дървесни ленти, на 10-то място в големите дървесни ленти, на 12-то място в паралелните тестови комплекти и на 26-то място в езиците изненада.', 'nl': 'We presenteren de TurkuNLP-vermelding in de CoNLL 2017 Shared Task on Multilingual Parsing van Raw Text naar Universele Afhankelijkheden. Het systeem is gebaseerd op de UDPipe parser met onze focus ligt op het verkennen van verschillende technieken om de woord embeddings die door de parser worden gebruikt vooraf te trainen om de prestaties te verbeteren, vooral op talen met kleine trainingssets. Het systeem werd 11e onder de 33-deelnemers in het algemeen, 8e op de kleine boombanken, 10e op de grote boombanken, 12e op de parallelle testsets en 26e op de verrassingstalen.', 'da': 'Vi præsenterer TurkuNLP-indgangen i CoNLL 2017 delt opgave om flersproget tolkning fra rå tekst til universelle afhængigheder. Systemet er baseret på UDPipe parseren med vores fokus på at udforske forskellige teknikker til forudtræning af ordet embeddings brugt af parseren for at forbedre dens ydeevne især på sprog med små træningssæt. Systemet rangerede 11. blandt de 33 deltagere samlet og var 8. på de små træbakker, 10. på de store træbakker, 12. på de parallelle testsæt og 26. på overraskelsessprog.', 'hr': 'Predstavljamo ulaz TurkuNLP-a u CoNLL 2017. zajednički zadatak o multijezičkom razmatranju s sirovog teksta na univerzalne zavisnosti. Sistem je zasnovan na UDPipe analizatoru s fokusiranjem u istraživanju različitih tehnika za predobučavanje riječi uključenih od strane analizatora kako bi poboljšali svoj učinkovit posebno na jezicima s malim nastavacima obuke. Sistem je uopće bio 11. među 33 sudionika, 8. na malim podjelama, 10. na velikim podjelama, 12. na paralelnim testovima i 26. na jezicima iznenađenja.', 'de': 'Wir präsentieren den TurkuNLP Eintrag in der CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. Das System basiert auf dem UDPipe Parser, wobei unser Fokus auf der Erforschung verschiedener Techniken liegt, um die Worteinbettungen vorzutrainieren, die vom Parser verwendet werden, um seine Leistung insbesondere bei Sprachen mit kleinen Trainingssets zu verbessern. Das System belegte insgesamt den elften Platz unter den 33-Teilnehmern: acht auf den kleinen Baumbänken, zehnte auf den großen Baumbänken, zwölfte auf den parallelen Testsets und 26ste auf den Überraschungssprachen.', 'id': 'Kami memperkenalkan masukan TurkuNLP di CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. Sistem ini berdasarkan pada analisis UDPipe dengan fokus kami adalah dalam mengeksplorasi berbagai teknik untuk melatih-melatih kata-kata yang digunakan oleh analisis untuk meningkatkan prestasinya khususnya pada bahasa dengan set latihan kecil. The system ranked 11th among the 33 participants overall, being 8th on the small treebanks, 10th on the large treebanks, 12th on the parallel test sets, and 26th on the surprise languages.', 'sw': 'We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies.  Mfumo unategemea mchambuzi wa UDPipe wenye lengo letu la kutafuta mbinu mbalimbali za kufundisha ujumbe wa maneno yaliyotumiwa na mchambuzi ili kuboresha utendaji wake hasa katika lugha zetu kwa seti ndogo za mafunzo. Mfumo huo ulikuwa na rangi ya 11 kati ya washiriki 33 kwa ujumla, wakiwa na umri wa nane kwenye viwanja vidogo vya mitatu, wa 10 kwenye viwanja vikubwa vya mitaani, na ya 12 kwenye vituo vya vipimo vya usambazaji, na ya 26 katika lugha za kushangaza.', 'fa': 'ما وارد TurkuNLP را در کار مشترک CoNLL 2017 در مورد تحلیل زیادی زبان از متن Raw به بستگی جهانی پیشنهاد می کنیم. این سیستم بر پایه بازیگر UDPipe بنیادی است که تمرکز ما در تحقیق تکنیک های مختلف برای پیش آموزش کردن کلمه استفاده از بازیگر برای بهبود کردن عملکرد خود مخصوصا بر زبانها با مجموعه های آموزش کوچک است. سیستم در کل ۱۱م از ۳۳ شرکت کنندگان بود، ۸م بر تخته\u200cهای کوچک، ۱۰م بر تخته\u200cهای بزرگ، ۱۲م بر تست\u200cهای parallel و ۲۶م بر زبان\u200cهای سورپرایز.', 'ko': '우리는 CoNLL 2017 공유 임무에서 TurkuNLP 항목을 소개했는데 이 임무는 원시 텍스트부터 일반적인 의존 항목까지의 다중 언어 해석을 포함한다.이 시스템은 UDPipe 해상도를 바탕으로 각종 기술을 탐색하여 해상도가 사용하는 단어를 미리 훈련시켜 성능을 향상시키는 데 중점을 두고 있으며 특히 훈련집이 비교적 작은 언어에 중점을 두고 있다.이 시스템은 참여자 33명 중 11위, 작은 트리 그래프 그룹 중 8위, 큰 트리 그래프 그룹 중 10위, 평행 테스트 집중 12위, 깜짝 언어 중 26위에 올랐다.', 'tr': 'Biz TurkuNLP 2017-nji CoNLL 2017-nji ýylda Mazmunlar Metinden Çap Metinden Halkara Baýramlyklara Beýlaşdyryn Sistem UDPipe täzeledigine görkezilýär. Biziň fokusymyz düzümlerni kiçi okuw düzümleri bilen ýene-täzelemek üçin ullanýan sözleri öňünden öňünden geçirmek üçin düzümlerni ýüzeltmek üçin düzümlerni ýüzeltýäris. Sistem 33-nji chikançylarda 11-nji derejä döredildi, kiçi çyzgymlarda 8-nji derejä, uly çyzgymlarda 10-nji, parallel çyzgymlarda 12-nji derejä we geň galap dilinde 26-nji derejä döredildi.', 'sq': 'Ne paraqesim hyrjen e TurkuNLP në CoNLL 2017 Task Shared on Multilingual Parsing from Raw Text to Universal Dependencies. Sistemi është bazuar në analizuesin UDPipe me fokusin tonë në eksplorimin e teknikave të ndryshme për të paratrajnuar fjalët e përdorura nga analizuesi me qëllim që të përmirësojë shfaqjen e tij veçanërisht në gjuhët me set të vogla trajnimi. Sistemi u rendit i 11-ti midis 33 pjesëmarrësve në përgjithësi, duke qenë i 8-ti në bazat e pemëve të vogla, i 10-ti në bazat e pemëve të mëdha, i 12-ti në bazat e testimeve paralele dhe i 26-ti në gjuhët e befasuara.', 'am': 'የቱርቱንኤንLP ግንኙነቱን ከRaw ጽሑፍ ጀምሮ እስከ ዓለማዊ ግንኙነት ድረስ የተለየ የቋንቋ ጋዜጠኞች ስራዎችን እናቀርባለን፡፡ ሲስተምሩ በUDPip ተፈላጊያው ላይ ነው፡፡ ሲስተምሩ በ33 ተጋሪዎች መካከል 11 አንደኛው ቁጥር ያረጀ ነበር፤ ስምንተኛው ታናሹ ዛፎች፣ አሥረኛው በታላቁ ዱር ክፍሎች፣ አሥራ 12 በተለየው ተፈተና ማዕከላዊው ቋንቋዎች፣ 26ኛ በመደነቂያ ቋንቋዎች ላይ ነው፡፡', 'hy': 'Մենք ներկայացնում ենք Թուրկու ՆԼՊ-ի գրառումը 2017 թվականի ԿՈՆԼ-ի համախմբված հանձնարարության մեջ, որը վերաբերում է բազմալեզվով վերլուծությանը՝ ոչ թղթից տեքստից մինչև համաշխարհային կախվածություններ Համակարգը հիմնված է UDPipe-ի վերլուծողի վրա, որտեղ մենք կենտրոնացնում ենք տարբեր մեթոդներ ուսումնասիրելու համար վերլուծողի կողմից օգտագործված բառերի վերլուծման նախապատրաստման համար, որպեսզի բարելավվի իր արտադրողությունը, հատկապես փոքր ուս Այս համակարգը համաշխարհային 33 մասնակիցների 11-րդ դասակարգում էր, որն էլ 8-րդն էր փոքր ծառերի վրա, 10-րդը՝ մեծ ծառերի վրա, 12-րդը՝ զուգահեռ փորձարկումների վրա և 26-րդը՝ զարմանալի լեզուների վրա:', 'af': 'Ons voorsien die TurkuNLP inskrywing in die CoNLL 2017 deelde taak op veelvuldige verwerking van Roë Teks tot Universele afhanklikhede. Die stelsel is gebaseer op die UDPipe-ontleerder met ons fokus om verskillende teknike te ondersoek om die woord ingesluit te trein wat deur die ontleerder gebruik word om sy prestasie te verbeter spesiaal op tale met klein onderwerp stelle. Die stelsel het 11de rangeer onder die 33 deelnimmers totaal, 8de op die klein treebanks, 10de op die groot treebanks, 12de op die parallele toets stel, en 26de op die verrassing tale.', 'az': "Biz TürkiNLP 2017-ci CoNLL'in çoxlu dil analizi haqqında paylaşılmış işi ilə birləşdiririk. Sistem UDPipe ayırıcısına dayanılır. Bizim fərqli tekniklərimizi araşdırmaq üçün, ayırıcıdan istifadə edilən sözləri təhsil etmək üçün, özlərinə də kiçik təhsil qurmaqları ilə dillərini təhsil etmək üçün təhsil etmək üçün, UDPipe ayırıcısına dayanılır. Sistem 33 iştirakçıların arasında 11-ci səf idi, kiçik çubuqların üstündə 8-ci səf idi, böyük çubuqların üstündə 10-ci səf idi, paralel test setlərində 12-ci səf idi və şaşırtma dillərində 26-ci səf idi.", 'bs': 'Predstavljamo ulaz TurkuNLP u CoNLL 2017. zajednički zadatak o multijezičkom razmatranju sa Raw Text na univerzalne zavisnosti. Sistem je zasnovan na UDPipe analizatoru s fokusiranjem u istraživanju različitih tehnika za predvježbanje riječi o integraciji koje je koristio analizator kako bi poboljšali svoj učinkovit posebno na jezicima sa malim obukom. Sistem je uopšte bio 11. među 33 sudionika, 8. na malim područjima, 10. na velikim područjima, 12. na paralelnim testovima i 26. na jezicima iznenađenja.', 'ca': "We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies.  El sistema està basat en l'analitzador UDPipe, centrant-nos en explorar diverses tècniques per pré-entrenar les paraules incorporades que utilitza l'analitzador per millorar el seu rendiment especialment en llengües amb petits conjunts d'entrenament. El sistema es va classificar 11ª entre els 33 participants en general, la 8ª a les petites bances d'arbres, la 10ª a les grans bances d'arbres, la 12ª a les proves paralleles i la 26ª a les llengües sorprenents.", 'et': 'Tutvustame TuruNLP kandet CoNLL 2017. aasta ühises ülesandes mitmekeelse parsingi kohta toortekstist universaalsete sõltuvusteni. Süsteem põhineb UDPipe parseril, keskendudes erinevate tehnikate uurimisele parseri poolt kasutatavate sõnade manustamise eelõpetamiseks, et parandada selle jõudlust eriti väikeste koolituskomplektidega keeltes. Süsteem oli kokku 33 osalejast 11. kohal, olles 8. kohal väikestel puukottidel, 10. kohal suurtel puukottidel, 12. paralleelsetel testidel ja 26. kohal üllatuskeeltel.', 'fi': 'Esittelemme TurkuNLP-merkinnän CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependences -sarjassa. Järjestelmä perustuu UDPipe-parseriin ja keskitymme tutkimaan erilaisia tekniikoita parserin käyttämien sanaupotusten esikoulutukseen parantaaksemme sen suorituskykyä erityisesti kielillä, joilla on pieniä koulutussarjoja. Järjestelmä sijoittui 33 osallistujasta 11. sijalle, joka oli 8. sijalle pienissä puupenkeissä, 10. sijalle suurissa puupenkeissä, 12. sijalle rinnakkaisissa testisarjoissa ja 26. sijalle yllätyskieleissä.', 'bn': 'আমরা কএনএল ২০১৭ সালে তুর্কুনএলপি প্রবেশের কাজ শেয়ার করেছি রাও টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করে। সিস্টেমটি ইউডিপিপি প্যালেজের উপর ভিত্তিক রয়েছে যেখানে আমাদের মনোযোগ প্রদান করা হচ্ছে বিভিন্ন প্রযুক্তি বিশেষ করে ছোট ট প্রশিক্ষণের সাথে প্রশ ৩৩ জন অংশগ্রহণকারীদের মধ্যে এই সিস্টেমের ১১ তারিখ ছিল, ছোট্ট ট ট্রিব্যাংকে ৮তম, বিশাল ট্রিব্যাংকের ১০ তারিখ, প্যারালেল পরীক্ষা সেটে ১২', 'cs': 'Představujeme záznam TurkuNLP v CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependences. Systém je založen na parseru UDPipe s naším zaměřením na zkoumání různých technik pro předtrénování slovních vložení používaných parserem za účelem zlepšení jeho výkonu zejména u jazyků s malými tréninkovými sadami. Systém byl jedenáctý mezi 33účastníky celkově, osmý na malých stromových březích, desátý na velkých stromových březích, dvanáctý na paralelních testovacích sadách a 26tý na překvapivých jazycích.', 'jv': 'We present the turu NLP entries in the CoNLL 1997 shared tasks on Multilanguage Sistem wis saben ning kelas UTPipe karo ingkang dipoleh kapan ning sampek teknik sing wis dipunanggap kanggo mulai nggawe layar Sistem sing ditambah luwih sedhaya sing wis 11 maneh ning alam-alam sing gak ngelarang, sampeyan 8 patik sing gak bener, 10 patik sing nganggo lawak bab, 12 patik sing ditambah tentang paralele, lan 16 patik sing ngejaraké idiomah.', 'ha': 'Tuna halatar da ketin turuNLP a CoNLL 2017 An asa shi a kan shirin UDAipe da fassarar da fokus idan yana sami cikin jarraba masu shirya masu shiryuwa masu ko-gaba-wa-tunkuɗe maganar da aka yi amfani da shi na parser, dõmin ya canza aikin sa da haske kan harshen da tsarin mai ƙarami. Ana dangani na kasa 11th daga mãsu haɗi na 33 a jumla, tare da shekara 8na a kan manyan tufãfin, na 10 kan manyan tufafi, na 12 a kan samun jarrabi masu fasalin, da na 26th a kan harshen waɗanda ke yi mãmãki.', 'he': 'אנחנו מציגים את הכתובת של TurkuNLP במשימה משותפת CoNLL 2017 על בדיקת רבות שפות מ טקסט ראש לתלויות universal. המערכת מבוססת על מעבד UDPipe עם המרכז שלנו הוא לחקור טכניקות שונות כדי לאמן מראש את המילים הקשורות על ידי מעבד כדי לשפר את ביצועיו במיוחד על שפות עם קבוצות אימונים קטנות. המערכת התייצבה ב-11 בין 33 השתתפים באופן כללי, שהייתה ה-8 על גבי העץ הקטנים, ה-10 על גבי העץ הגדולים, ה-12 על גבי הבדיקות המזוריות, ו-26 על שפות ההפתעה.', 'sk': 'Predstavljamo vnos TurkuNLP v skupni nalogi CoNLL 2017 o večjezičnem razčlenjanju od surovega besedila do univerzalnih odvisnosti. Sistem temelji na razčlenjevalniku UDPipe, pri čemer se osredotočamo na raziskovanje različnih tehnik predusposabljanja besed, ki jih uporablja razčlenjevalnik, da bi izboljšali njegovo učinkovitost zlasti na jezikih z majhnimi nabori usposabljanja. Sistem se je uvrstil na 11. mesto med 33 udeleženci skupno, 8. mesto na majhnih drevesnih ploščah, 10. mesto na velikih drevesnih ploščah, 12. mesto na vzporednih testnih nizikih in 26. mesto na jezikih presenečenj.', 'bo': 'ང་ཚོས་CoNLL 2017 ནང་དུ་TurkuNLP ནང་འཇུག མ་ལག་གི་ལག་ལེན་པ་ UDPipe དབྱེ་སྟངས་ལ་ང་ཚོའི་དམིགས་གཏད་འདུག་ནི་བཟོ་རྩོལ་ནུས་མེད་པའི་ལག་ལེན་འཐབ་རྩོལ་སྒྲིག མ་ལག'}
{'en': 'The parse is darc and full of errors : Universal dependency parsing with transition-based and graph-based algorithms', 'ar': 'التحليل هو darc ومليء بالأخطاء: تحليل التبعية الشامل باستخدام الخوارزميات القائمة على الانتقال والخوارزميات القائمة على الرسم البياني', 'pt': 'A análise é escura e cheia de erros: análise de dependência universal com algoritmos baseados em transição e baseados em gráfico', 'fr': "L'analyse est sombre et pleine d'erreurs\xa0: analyse de dépendance universelle avec des algorithmes basés sur des transitions et des graphes", 'es': 'El análisis es oscuro y está lleno de errores: análisis de dependencias universal con algoritmos basados en transiciones y gráficos', 'ja': '構文解析はDARCであり、誤差に満ちています：トランジションベースおよびグラフベースのアルゴリズムを使用したユニバーサル依存性構文解析', 'zh': '解析为darc,充溢之误:用基于转易,通于图形之算依赖性解析', 'ru': 'Анализ DARC и полный ошибок: Универсальный синтаксический анализ зависимостей с алгоритмами на основе перехода и графов', 'hi': 'पार्स डार्क और त्रुटियों से भरा है: संक्रमण-आधारित और ग्राफ-आधारित एल्गोरिदम के साथ यूनिवर्सल निर्भरता पार्सिंग', 'ga': 'Tá an pharsáil darc agus lán earráidí: Parsáil spleáchais uilíoch le halgartaim atá bunaithe ar thrasdul agus graf-bhunaithe', 'ka': 'პარასი ცოტა და შეცდომების შესახებით დამატებულია: სანტრანციო დამატებული და გრაფიური ალგორიტიმთან უნივერსალური დამატებულობის პარასი', 'hu': 'Az elemzés darc és tele van hibákkal: Univerzális függőség elemzés átmeneti és grafikon alapú algoritmusokkal', 'el': 'Η ανάλυση είναι σκοτεινή και γεμάτη σφάλματα: καθολική ανάλυση εξάρτησης με αλγόριθμους βασισμένους στη μετάβαση και γραφήματα', 'it': 'Il parse è darc e pieno di errori: Analisi delle dipendenze universale con algoritmi basati su transizione e grafici', 'kk': 'Бұл талдау қателерден тұрақ және толық: Керегіс негіздеген және график негіздеген алгоритмдермен әлемдік тәуелдік талдау', 'lt': 'The parse is darc and full of errors: Universal dependency parsing with transition-based and graph-based algorithms', 'ml': 'പാര്\u200dസ് ദാര്\u200dക്കും തെറ്റുകള്\u200d നിറഞ്ഞിരിക്കുന്നു; മാറ്റങ്ങള്\u200d അടിസ്ഥാനമാക്കുന്ന ആല്\u200dഗോരിത്മുകള്\u200d കൊണ്ട് യൂണിവല', 'mk': 'Анализацијата е дарка и полна со грешки: Анализација на универзалната зависност со алгоритми базирани на транзиција и график', 'ms': 'huraian adalah darc dan penuh dengan ralat: huraian dependensi universal dengan algoritma berasaskan-transisi dan graf', 'mt': 'L-analiżi hija darc u mimlija b’żbalji: Analiżi tad-dipendenza universali b’algoritmi bbażati fuq tranżizzjoni u grafiċi', 'no': 'Tolkinga er mørk og full av feil: Universell tolking av avhengighet med overgangsbaserte og grafobaserte algoritme', 'sr': 'Analiza je tamna i puna greška: univerzalna analiza ovisnosti sa algoritmima na prelazu i na grafu baziranim', 'mn': 'Шинжлэх нь алгоритмын дүүрэн дүүрэн, ертөнцийн хамааралтай байдал нь шилжилт дээр суурилсан, график дээр суурилсан алгоритмыг хуваалцах юм.', 'si': 'විශ්ලේෂණය අදුරු සහ වැරදිලි පූර්ණයි: ජාතික විශ්වාස විශ්ලේෂණය සහ ග්\u200dරාෆ් අධාරිත ඇල්ගෝරිතම්', 'so': 'Baarlamaanka waxaa ka buuxa qalad: jardiinada ku xiran dhamaadka caalamiga ah oo ku qoran algorityo ku saleysan qoraalka', 'pl': 'Parse jest darc i pełen błędów: Uniwersalne parsowanie zależności z algorytmami opartymi na przejściach i wykresach', 'ro': 'Analiza este darc și plină de erori: Analizarea dependenței universale cu algoritmi bazați pe tranziție și grafice', 'sv': 'Tolkningen är darc och full av fel: Universell beroendetolkning med övergångsbaserade och grafbaserade algoritmer', 'ur': 'پارس اندھیر ہے اور غلطی سے بھر ہوا ہے: واسطے پر اور گراف بنیادی الگوریتم کے ساتھ Universal dependency parsing', 'ta': 'The parse is darc and full of errors: Universal dependency parsing with transition-based and graph-based algorithms', 'uz': 'Paragrafning darq va toʻliq xatolari: Universal dependency, transition- based va graph- asosiy algorithm bilan parsing', 'vi': 'The parre is darc and full of wrong: Universal dependence phân tích with Transportation-based và đồ thị analytms', 'nl': 'De parse is darc en vol fouten: Universele afhankelijkheidsparsing met transitie- en grafiekgebaseerde algoritmen', 'bg': 'Парализирането е дарк и пълно с грешки: Универсално анализиране на зависимост с алгоритми, базирани на преход и графични алгоритми', 'da': 'Parsen er darc og fuld af fejl: Universel afhængighedsanalyse med overgangsbaserede og grafbaserede algoritmer', 'hr': 'Analiza je mračna i puna grešaka: analiza univerzalne zavisnosti s algoritmima na prelazu i na grafu baziranim', 'de': 'Die Parse ist darc und voller Fehler: Universelles Abhängigkeitsparsen mit transitions- und graphenbasierten Algorithmen', 'id': 'Analisasi adalah darc dan penuh dengan kesalahan: Analisasi dependensi universal dengan algoritma berdasarkan transisi dan grafik', 'ko': '해석은darc의 오류로 가득 차 있습니다: 변환과 그림 기반 알고리즘의 일반적인 의존 해석', 'sw': 'Bunge hilo ni dhahiri na imejaa makosa: Kutegemea ulimwengu wa kimataifa ukiimba na algorithi zilizoko kwenye mtandao wa mpito na picha', 'sq': 'Analiza është darc dhe plot me gabime: analizimi i varësisë universale me algoritme bazuar në tranzicion dhe grafik', 'am': 'ፓርላማው ጥሩ እና ስህተት ሞልቶአል፤ የዓለማዊ ተደጋጋፊ እና በgraph-based algorithm ማጋራት ነው፡፡', 'hy': 'Փորձարկման մեջ սխալներ կան: Համաշխարհային կախվածությունը վերլուծում է վերափոխման և գրաֆիկի հիմնված ալգորիթմներով', 'fa': 'تقسیم سیاه و پر از اشتباهی است: تقسیم بستگی جهانی با الگوریتم\u200cهای بر اساس تغییر و بر اساس گراف', 'az': 'Analiz qaranlıq və hatalardan dolu: Ünversal bağımlılıq, keçişkil-tabanlı və grafik-tabanlı algoritmi ilə ayırılmaqdır.', 'bn': 'পার্স হচ্ছে দারুণ এবং ত্রুটির পূর্ণ: বিশ্ববিদ্যালয়ের নির্ভরিত পার্সের সাথে যাত্রা করা এবং গ্রাফ ভিত্তিক অ্', 'tr': 'Bu ayrıştırma çörekli ve hatalardan dolu: Üniversitel bağlılık geçişimin üstünde ve grafik tabanlı algoritmaları ile analiz edilmesi', 'af': 'Die verwerking is donker en vol van foute: Universele afhanklikheid verwerking met transisie-gebaseerde en graafgebaseerde algoritme', 'bs': 'Analiza je mračna i puna greška: Univerzalna analiza ovisnosti sa algoritmima na prelazu i na grafu baziranim', 'ca': "L'analisi és darc i plena d'errors: l'analisi de la dependencia universal amb algoritmes basats en la transició i gràfics", 'cs': 'Parse je darc a plná chyb: Univerzální analýza závislostí s algoritmy založenými na přechodu a grafech', 'et': 'Parsimine on darc ja täis vigu: Universaalne sõltuvuse parsimine üleminekupõhiste ja graafikapõhiste algoritmidega', 'fi': 'Käsittely on darc ja täynnä virheitä: Yleinen riippuvuuden jäsentäminen siirtymä- ja graafipohjaisilla algoritmeilla', 'jv': 'Algorithm', 'he': 'המחקר הוא דארק ומלא שגיאות: מחקר תלויות יוניברסלית עם אלגוריתמים מבוססים על מעבר וגרף', 'ha': 'Paris is darc and full of errors: Universal depend on paring with transitional-based algoritymes and graph-based', 'sk': 'Razčlenitev je darc in polna napak: Razčlenitev univerzalne odvisnosti z algoritmi na osnovi prehoda in grafikona', 'bo': 'དབྱེ་སྟངས་ནི་གནད་རིས་དང་ནོར་འཁྲུལ་བ་མང་པོ་་ཡིན།'}
{'en': 'We developed two simple systems for dependency parsing : darc, a transition-based parser, and mstnn, a graph-based parser. We tested our systems in the CoNLL 2017 UD Shared Task, with darc being the official system. Darc ranked 12th among 33 systems, just above the baseline. Mstnn had no official ranking, but its main score was above the 27th. In this paper, we describe our two systems, examine their strengths and weaknesses, and discuss the lessons we learned.', 'ar': 'لقد طورنا نظامين بسيطين لتحليل التبعية: darc ، وهو محلل قائم على الانتقال ، و mstnn ، وهو محلل قائم على الرسم البياني. اختبرنا أنظمتنا في CoNLL 2017 UD Shared Task ، مع كون darc النظام الرسمي. احتل Darc المرتبة 12 من بين 33 نظامًا ، أعلى بقليل من خط الأساس. لم يكن لدى Mstnn مرتبة رسمية ، لكن درجتها الرئيسية كانت أعلى من المرتبة 27. في هذه الورقة ، نصف نظامينا ، ونفحص نقاط القوة والضعف ، ونناقش الدروس التي تعلمناها.', 'fr': "Nous avons développé deux systèmes simples pour l'analyse des dépendances\xa0: darc, un analyseur basé sur les transitions, et mstnn, un analyseur basé sur des graphes. Nous avons testé nos systèmes dans le cadre de la tâche partagée ConLL 2017 UD, darc étant le système officiel. Darc s'est classé 12e parmi 33 systèmes, juste au-dessus de la ligne de base. Mstnn n'avait pas de classement officiel, mais son score principal était supérieur au 27e. Dans cet article, nous décrivons nos deux systèmes, examinons leurs forces et leurs faiblesses et discutons des leçons que nous avons apprises.", 'es': 'Desarrollamos dos sistemas simples para el análisis de dependencias: darc, un analizador basado en transiciones, y mstnn, un analizador basado en gráficos. Probamos nuestros sistemas en la tarea compartida UD de CoNll 2017, siendo darc el sistema oficial. Darc ocupó el puesto 12 entre 33 sistemas, justo por encima de la línea base. Mstnn no tenía clasificación oficial, pero su puntuación principal estaba por encima del 27. En este artículo, describimos nuestros dos sistemas, examinamos sus puntos fuertes y débiles y discutimos las lecciones que aprendimos.', 'pt': 'Desenvolvemos dois sistemas simples para análise de dependência: darc, um analisador baseado em transição, e mstnn, um analisador baseado em grafo. Testamos nossos sistemas no CoNLL 2017 UD Shared Task, sendo o darc o sistema oficial. O Darc ficou em 12º lugar entre 33 sistemas, logo acima da linha de base. O Mstnn não tinha ranking oficial, mas sua pontuação principal ficou acima do 27º. Neste artigo, descrevemos nossos dois sistemas, examinamos seus pontos fortes e fracos e discutimos as lições que aprendemos.', 'ja': '依存関係解析のための2つの単純なシステムを開発しました遷移ベースの構文解析器であるdarcとグラフベースの構文解析器であるmstnnですCoNLL 2017 UD Shared Taskでシステムをテストしました。DACが公式システムです。DARCは33系統中12位で、ベースラインをわずかに上回っていた。Mstnnには公式ランキングはなかったが、本塁打数は27本を上回った。本稿では、2つのシステムについて説明し、その長所と短所を検討し、学んだ教訓について考察する。', 'zh': 'darc者,解析之解析器也。 试我于CoNLL 2017 UD,darc官方系统。 Darc在33统中排名第12位,略高于基线。 Mstnn无官名,然要得分高第27。 于本文中,述我两统,检其善恶,论我经训。', 'hi': 'हमने निर्भरता पार्सिंग के लिए दो सरल प्रणालियां विकसित कीं: डार्क, एक संक्रमण-आधारित पार्सर, और mstnn, एक ग्राफ-आधारित पार्सर। हमने CoNLL 2017 UD Shared Task में अपने सिस्टम का परीक्षण किया, जिसमें darc आधिकारिक प्रणाली थी। डार्क 33 प्रणालियों के बीच 12 वें स्थान पर है, बेसलाइन के ठीक ऊपर। Mstnn की कोई आधिकारिक रैंकिंग नहीं थी, लेकिन इसका मुख्य स्कोर 27 वें से ऊपर था। इस पेपर में, हम अपने दो प्रणालियों का वर्णन करते हैं, उनकी ताकत और कमजोरियों की जांच करते हैं, और हमारे द्वारा सीखे गए पाठों पर चर्चा करते हैं।', 'ru': 'Мы разработали две простые системы для синтаксического анализа зависимостей: darc, синтаксический анализатор на основе перехода, и mstnn, синтаксический анализатор на основе графа. Мы протестировали наши системы в CoNLL 2017 UD Shared Task, при этом DARC является официальной системой. DARC занял 12-е место среди 33 систем, чуть выше базовой линии. У Мстнна не было официального рейтинга, но его основной счет был выше 27-го. В этом документе мы описываем наши две системы, изучаем их сильные и слабые стороны и обсуждаем извлеченные уроки.', 'ga': 'D’fhorbraíomar dhá chóras shimplí do pharsáil spleáchais: darc, parsálaí tras-bhunaithe, agus mstnn, parsálaí graf-bhunaithe. Rinneamar tástáil ar ár gcórais i dTasc Comhroinnte UD 2017 CoNLL, agus ba é darc an córas oifigiúil. Rangaíodh Darc sa 12ú háit i measc 33 córas, díreach os cionn na bunlíne. Ní raibh aon rangú oifigiúil ag Mstnn, ach bhí a phríomhscór os cionn an 27ú. Sa pháipéar seo, déanaimid cur síos ar an dá chóras atá againn, scrúdaítear a láidreachtaí agus a laigí, agus pléimid na ceachtanna a d’fhoghlaimíomar.', 'ka': 'ჩვენ განვითარებეთ ორი მარტივი სისტემები განსაზღვრებისთვის განსაზღვრებისთვის: darc, განსაზღვრებისთვის განსაზღვრებული პარასერი და mstnn, გრაფიკური პარასერი ჩვენ ჩვენი სისტემები CoNLL 2017-ში UD-ის გაყოფილი რაოდენობაში შევცვალოთ, როგორც darc იყო პროფიციალური სისტემა. დარიფი 33 სისტემების 12-ზე, მხოლოდ დამატებით. მაგრამ მისი პროგრამეტური არ იყო, მაგრამ მისი პროგრამეტური დამატებული 27-ზე. ჩვენ ჩვენი ორი სისტემაში აღწერით, შევხედავთ მათი ძალიან ძალიან და ცოცხლებები, და დავუბრუნეთ სწავლებები, რომლებიც ჩვენ ვისწავლით.', 'el': 'Αναπτύξαμε δύο απλά συστήματα για την ανάλυση εξαρτήσεων: το darc, ένα αναλυτή μετάβασης, και το mstnn, ένα αναλυτή γραφής. Δοκιμάσαμε τα συστήματά μας στην κοινή εργασία με το να είναι το επίσημο σύστημα. Ο Νταρκ κατατάχθηκε 12ος ανάμεσα στα 33 συστήματα, ακριβώς πάνω από τη γραμμή βάσης. Η Mstn δεν είχε επίσημη κατάταξη, αλλά η κύρια βαθμολογία της ήταν πάνω από την 27η. Στην παρούσα εργασία περιγράφουμε τα δύο συστήματα μας, εξετάζουμε τα δυνατά και αδύνατα σημεία τους και συζητάμε τα διδάγματα που μάθαμε.', 'hu': 'Két egyszerű függőségi elemző rendszert fejlesztettünk ki: darc, egy átmeneti alapú elemző, és mstnn, egy gráf alapú elemző. Rendszereinket a CoNLL 2017 UD Shared Task keretében teszteltük, a darc volt a hivatalos rendszer. Darc a 12. helyen állt a 33 rendszer közül, közvetlenül az alap felett. Mstnn nem rendelkezett hivatalos ranglistával, de fő pontszáma a 27. fölött volt. Ebben a tanulmányban bemutatjuk két rendszerünket, megvizsgáljuk erősségeiket és gyengeségeiket, és megvitatjuk a tanulságokat.', 'it': "Abbiamo sviluppato due semplici sistemi per l'analisi delle dipendenze: darc, un parser basato sulla transizione, e mstnn, un parser basato su grafici. Abbiamo testato i nostri sistemi nel CoNLL 2017 UD Shared Task, con darc come sistema ufficiale. Darc si è classificato 12esimo tra 33 sistemi, appena sopra la linea di base. Mstnn non aveva una classifica ufficiale, ma il suo punteggio principale era superiore al 27esimo. In questo articolo descriviamo i nostri due sistemi, esaminiamo i loro punti di forza e di debolezza e discutiamo le lezioni che abbiamo imparato.", 'kk': 'Тәуелсіздік талдау үшін екі қарапайым жүйелерді жасадық: darc, ауыстыру негіздеген талдаушы және mstnn, график негіздеген талдаушы. Біз жүйелерімізді CoNLL 2017 жылы UD ортақтастырған тапсырманы тексердік. Түсінші жүйе болып тұрмыз. Дарк 33 жүйелердің 12- ші ретінде, негізгі жолдың үстінен. Мыстан официалдық жолдары жоқ, бірақ негізгі нөмірі 27- ші жоғары болды. Бұл қағазда екі жүйемізді таңдап, олардың күштерін және бақыттарын тексеріп, біз үйренген сабақтарды талқылаймыз.', 'ml': 'ആശ്രയിതമായ പാര്\u200dസിങ്ങിനുള്ള രണ്ടു സിസ്റ്റമുണ്ടാക്കി: ഡാര്\u200dക്ക്, ട്രാന്\u200dസിന്\u200dറെ അടിസ്ഥാനമായ പരാജയപ്രകാരം, എസ്റ്റ ഞങ്ങള്\u200d ഞങ്ങളുടെ സിസ്റ്റത്തെ കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കെടുത്ത ജോലിയില്\u200d പരീക്ഷിച്ചു. ധൈര്യം ഓഫിക്കല്\u200d സിസ്റ്റത് 33 സിസ്റ്റമുകളില്\u200d ഇരുട്ടാമത്തെ റാങ്ങ് ചെയ്തു, ബെസ്റ്റലൈനില്\u200d മുകളില്\u200d. മിസ്റ്റ്നിന് ഓഫിക്കല്\u200d റെങ്കിങ്ങ് ഇല്ല, പക്ഷെ അതിന്\u200dറെ പ്രധാന സ്കോര്\u200d 27-ല്\u200d മുകളിലായിരുന്നു. In this paper, we describe our two systems, examine their strengths and weaknesses, and discuss the lessons we learned.', 'lt': 'Sukūrėme dvi paprastas priklausomybės analizavimo sistemas: darc, pereinamojo laikotarpio analizatorius ir mstnn, grafiniu analizatorius. Mes išbandėme savo sistemas CoNLL 2017 UD bendrame uždavinyje, darc yra oficiali sistema. Dark buvo 12-oji iš 33 sistemų, tiesiog virš pradinio lygio. Mstnn nebuvo oficialiai įvertintas, tačiau pagrindinis jo rezultatas buvo didesnis už 27-ąjį. In this paper, we describe our two systems, examine their strengths and weaknesses, and discuss the lessons we learned.', 'mk': 'Развивме два едноставни системи за анализирање на зависноста: darc, анализирач базиран на транзиција, и mstnn, анализирач базиран на график. Ги тестиравме нашите системи во Соделената задача на КоНЛ 2017, а Дарк е официјален систем. Дарк се рангираше на 12-тото место меѓу 33 системи, веднаш над основата. Mstnn немаше официјално рангирање, но неговиот главен резултат беше над 27-миот. Во овој документ, ги опишуваме нашите два системи, ги испитуваме нивните сили и слабости, и разговараме за лекциите што ги научивме.', 'mn': 'Бид хамааралтай хуваалцааны тулд хоёр энгийн системийг хөгжүүлсэн: darc, шилжилт суурилсан хуваалцагч, мс. mstnn, график суурилсан хуваалцагч. Бид 2017 оны CoNLL-ийн UD хуваалцааны ажлын системийг шалгаж үзсэн. Дарк 33 системийн 12-р дүрс байлаа. Хатагтан ерөнхийдөө хэмжээний цэг байхгүй, гэхдээ түүний гол цэг 27-р дээр байсан. Энэ цаасан дээр бид хоёр системийг тайлбарлаж, хүчтэй, хүчтэй байдлыг судалж, бидний сурсан хичээлийг ярьж байна.', 'mt': 'Żviluppajna żewġ sistemi sempliċi għall-analiżi tad-dipendenza: darc, analizzatur ibbażat fuq it-tranżizzjoni, u mstnn, analizzatur ibbażat fuq il-grafika. Ittestjna s-sistemi tagħna fil-Ħidma Konġunta tal-UD CoNLL 2017, bid-darc tkun is-sistema uffiċjali. Darc ikklassifikat fit-12-il post fost 33 sistema, eżatt ogħla mil-linja bażi. Mstnn ma kellu l-ebda klassifikazzjoni uffiċjali, iżda l-punteġġ ewlieni tiegħu kien ogħla mis-27. F’dan id-dokument, niddeskrivu ż-żewġ sistemi tagħna, niddiskutu l-qawwiet u d-dgħufijiet tagħhom, u niddiskutu t-tagħlimiet li għallmu.', 'ms': 'We developed two simple systems for dependency parsing: darc, a transition-based parser, and mstnn, a graph-based parser.  We tested our systems in the CoNLL 2017 UD Shared Task, with darc being the official system.  Dark berturut-turut ke-12 diantara 33 sistem, tepat di atas asas. Mstnn tidak mempunyai peringkat rasmi, tetapi skor utamanya adalah di atas 27. Dalam kertas ini, kami menggambarkan dua sistem kami, memeriksa kekuatan dan kelemahan mereka, dan membincangkan pelajaran yang kami belajar.', 'no': 'Vi utvikla to enkle systemer for tolking av avhengighet: darc, ein oversikningsbasert tolkar, og mstnn, ein grafikkbasert tolkar. Vi testa systemet våre i CoNLL 2017 UD-delt oppgåve, med mørk å vera den offisielle systemet. Darc rankert 12. mellom 33 systemer, akkurat over grunnlinja. Mstnn hadde ingen offisielle rangering, men hovudscoren var over 27. I denne papiret beskriver vi to systema våre, undersøker størrelsen og svakleiken sine, og diskuterer øvinga vi lærte.', 'ro': 'Am dezvoltat două sisteme simple pentru analizarea dependențelor: darc, un parser bazat pe tranziție, și mstnn, un parser bazat pe grafice. Am testat sistemele noastre în CoNLL 2017 UD Shared Task, darc fiind sistemul oficial. Darc s-a clasat pe locul 12 printre cele 33 de sisteme, chiar deasupra valorii de referinţă. Mstnn nu a avut nici un clasament oficial, dar scorul său principal a fost peste 27. În această lucrare, descriem cele două sisteme ale noastre, examinăm punctele forte și punctele slabe ale acestora și discutăm lecțiile pe care le-am învățat.', 'si': 'අපි සාමාන්\u200dය පද්ධතිය දෙකක් විශ්වාස කළා: Darc, ප්\u200dරවර්තනය සඳහා පද්ධතිය පද්ධතිය, mst, ග්\u200dරාෆ් අධාරිත විශ අපි අපේ පද්ධතිය පරීක්ෂා කරලා තියෙන්නේ CoNLL 2017 UD කොටස් එක්ක කාර්යාලයේ සාමාන්\u200dය පද්ධතියෙන් ඩාර්ක් ව ඩාර්ක් පද්ධතිය 33 අතර 12වෙනි පද්ධතිය, පද්ධතියෙන් ඉහළට. මිස්ටන්න්ට නියෝජිත ප්\u200dරමාණයක් නැහැ, ඒත් ඒකේ ප්\u200dරමාණ ප්\u200dරමාණ ප්\u200dරමාණයක් 27 විතරයි. මේ පත්තරේ අපි අපේ පද්ධතිය දෙකක් විස්තර කරනවා, ඔවුන්ගේ ශක්තිමත්වය හා දුර්වල් පරීක්ෂණය කරනවා, අපි ඉගෙන ගත්ත', 'pl': 'Opracowaliśmy dwa proste systemy do parsowania zależności: darc, parser oparty na przejściu i mstnn, parser oparty na wykresie. Przetestowaliśmy nasze systemy w CoNLL 2017 UD Shared Task, a oficjalnym systemem jest darc. Darc zajął się dwunastym miejscem wśród 33 systemów, tuż powyżej linii wyjściowej. Mstnn nie miał oficjalnego rankingu, ale jego główny wynik był ponad 27-tym. W niniejszym artykule opisujemy nasze dwa systemy, analizujemy ich mocne i słabe strony oraz omówimy wyciągnięte wnioski.', 'sr': 'Razvili smo dve jednostavne sisteme za analizu zavisnosti: darc, pretraživač na transiciji i mstnn, analizač na grafiku. Testirali smo naše sisteme u CoNLL 2017 UD zajedničkom zadatku, a Darc je zvanični sistem. Darc je 12. reda među 33 sistema, baš iznad početne linije. Gðica nije imala službenog reda, ali glavni rezultat je iznad 27. godine. U ovom papiru opisujemo naše dve sisteme, pregledavamo njihove snage i slabosti, i razgovaramo o lekcijama koje smo naučili.', 'so': 'Waxaan horumarinay laba nidaam oo fudud oo ay baarlamaha ku xiran tahay: darc, a baarlamaanka ku saleysan, and mstnn, baarlamaanka xarafta ku saleysan. nidaamkayaga aan ku tijaabiyey shaqo la sharciyey CoNLL 2017, iyadoo aan dareejinnay inay tahay nidaamka rasmi ah. Mugdi wuxuu ka mid ahaa 12aad oo ka mid ah 33 nidaam, taasoo ka sareeya saldhigga hoose. Ms. Guurta ma lahan sameynta rasmi ah, laakiin scorta ugu horeysa waxay ahayd mid ka sarreeya 27aad. Warqaddan waxaan ku qornaa labadayada nidaam, baaritaan xooggooda iyo itaaldarradooda, waxaana kala sheekaynaynaa waxbarashada aan baranay.', 'sv': 'Vi utvecklade två enkla system för beroendetolkning: darc, en övergångsbaserad parser, och mstnn, en grafbaserad parser. Vi testade våra system i CoNLL 2017 UD Shared Task, där darc är det officiella systemet. Darc rankades 12:e bland 33 system, strax över baslinjen. Mstnn hade ingen officiell rankning, men dess huvudpoäng var över den 27:e. I denna uppsats beskriver vi våra två system, undersöker deras styrkor och svagheter och diskuterar de lärdomar vi lärt oss.', 'ta': 'சார்ந்த பாடலுக்கான இரண்டு எளிய அமைப்புகளை நாம் உருவாக்கினோம்: darc, a transition- based analyser, and mstnn, a graph- based பகுதி நாங்கள் எங்கள் கணினிகளை கோன்எல் 2017 UD பகிர்ந்த பணியில் சோதித்தோம், வழக்கமான அமைப்பு இருக்கும் தொடர்புடன். 33 முறைமைகளில் இருள் 12வது, அடிப்படைக்கோட்டிற்கு மேல். மிஸ்டின் அலுவலகமான வரிசையில் இல்லை, ஆனால் அதன் முக்கிய மதிப்பு 27வதுக்கு மேல் இருந்தது. இந்த காகிதத்தில், நாம் எங்கள் இரண்டு அமைப்புகளை விவரிக்கிறோம், அவர்களுடைய சக்திகளையும் பலஹீனமையையும் பரிசோதிக்க, நா', 'ur': 'ہم نے ڈرینسیٹ پارسینگ کے لئے دو سادہ سیستموں کو ایجاد کیا ہے: darc, a transition-based parser, and mstnn, a graph-based parser. ہم نے CoNLL 2017 میں اپنے سیستموں کی آزمائش کی، UD شریک ٹاکس کے ساتھ تارک کے ساتھ رسمی سیستموں میں ہے. ڈارک 33 سیستموں میں 12درجہ تھا، بالکل بنیادی لین پر۔ مسٹن کے پاس کوئی رسمی رقم نہیں تھا، لیکن اس کی اصلی نقطہ 27 سے زیادہ تھا. اس کاغذ میں ہم اپنے دو سیستم کی توصیح کرتے ہیں، ان کی قوت اور کمزوری کی تحقیق کرتے ہیں، اور ہم نے یاد کی تعلیمات کی بحث کرتے ہیں.', 'uz': "Biz tashkilotni tasdiqlash uchun ikkita oddiy tizimni yaratdik: darc, transition asosida parametrlar, va mstnn, grafik asosida yaratilgan parametrlar. Biz 2017 KNLL'da bir tizimimizni sinov qildik, rasm tizim bo'lganligi davomida. 33 tizimdagi ikkinchi qora, asosiy satrning yuqorida. Mstnn had no official ranking, but its main score was above the 27th.  Bu qogʻozda biz ikki tizimimizni anglatamiz, ularning қувватларимизни ва заифликларини текширамиз va biz o'rganilgan o'rganilgan o'rganishlar haqida gapiramiz.", 'vi': 'Chúng tôi phát triển hai hệ thống phân tích phụ thuộc đơn giản: Darc, một phân tích trải qua, và msnn, một phân tích đồ thị. Chúng tôi đã thử nghiệm hệ thống hoạt động cùng hoạt động hoạt động của chúng tôi trong Tháp đôi! Darc phân loại 12th trong 33 hệ thống, ngay phía trên đường cơ sở. Mụ Mụ không có thứ hạng chính thức, nhưng điểm chính của bả nằm trên tàu 27. Trong tờ giấy này, chúng ta mô tả hai hệ thống, xem xét điểm mạnh và yếu của họ, và thảo luận về những bài học chúng ta đã học.', 'bg': 'Разработихме две прости системи за анализ на зависимости: дарк, базиран на преход анализ, и mstnn, базиран на графика анализ. Тествахме системите си в Споделената задача, като официалната система е Дарк. Дарк се класира на 12-о място сред 33 системи, малко над базовата линия. Мщн няма официално класиране, но основният му резултат е над 27-то. В тази статия описваме нашите две системи, изследваме техните силни и слаби страни и обсъждаме поуките, които научихме.', 'da': 'Vi udviklede to enkle systemer til afhængighedsanalyse: darc, en overgangsbaseret fortolker, og mstnn, en grafbaseret fortolker. Vi testede vores systemer i CoNLL 2017 UD Shared Task, hvor darc er det officielle system. Darc rangerede 12. blandt 33 systemer, lige over baseline. Mstnn havde ingen officiel placering, men dens primære score var over 27. I denne artikel beskriver vi vores to systemer, undersøger deres styrker og svagheder og diskuterer de erfaringer, vi har lært.', 'nl': 'We ontwikkelden twee eenvoudige systemen voor afhankelijkheidsparsen: darc, een transitie-based parser, en mstnn, een grafiek-based parser. We hebben onze systemen getest in de CoNLL 2017 UD Shared Task, waarbij darc het officiële systeem is. Darc scoorde 12e onder de 33-systemen, net boven de baseline. Mstnn had geen officiële ranking, maar de belangrijkste score lag boven de 27e. In dit artikel beschrijven we onze twee systemen, onderzoeken hun sterke en zwakke punten en bespreken we de lessen die we hebben geleerd.', 'hr': 'Razvili smo dva jednostavna sustava za analizu ovisnosti: darc, pretraživač baziran na prijelazu i mstnn, pretraživač baziran na grafiku. Testirali smo naše sustave u zajedničkom zadatku UD-a CoNLL 2017, a darc je zvanični sustav. Darc je redovao 12. između 33 sustava, upravo iznad početne linije. Gđica nije imala službenog reda, ali glavni rezultat je iznad 27. godine. U ovom papiru opisujemo naše dva sustava, pregledavamo njihove snage i slabosti, i razgovaramo o lekcijama koje smo naučili.', 'de': 'Wir haben zwei einfache Systeme für das Parsen von Abhängigkeiten entwickelt: darc, einen Übergangs-basierten Parser, und mstnn, einen graphenbasierten Parser. Wir haben unsere Systeme in der CoNLL 2017 UD Shared Task getestet, wobei darc das offizielle System ist. Darc belegte den 12-ten Platz unter den 33-Systemen, knapp über der Basislinie. Mstnn hatte keine offizielle Rangliste, aber seine Hauptpunktzahl lag über dem 27ten. In diesem Beitrag beschreiben wir unsere beiden Systeme, untersuchen ihre Stärken und Schwächen und diskutieren die daraus gewonnenen Erkenntnisse.', 'ko': '우리는 두 가지 간단한 의존항 분석 시스템을 개발했다. 바로 변환된 해상도darc와 도형 기반의 해상도 mstnn이다.우리는 CoNLL 2017 UD 공유 임무에서 우리의 시스템을 테스트했다.darc는 공식 시스템이다.Darc는 33개 시스템 중 12위로 기준선보다 약간 높았다.Mstnn은 공식 순위는 없지만 주요 점수는 27을 웃돌았다.본고에서 우리는 우리의 두 시스템을 묘사하고 그들의 장단점을 검사하며 우리가 배운 경험과 교훈을 토론할 것이다.', 'id': 'Kami mengembangkan dua sistem sederhana untuk penghuraian dependensi: darc, penghuraian berdasarkan transisi, dan mstnn, penghuraian berdasarkan grafik. Kami menguji sistem kami di CoNLL 2017 UD Shared Task, dengan Darc menjadi sistem resmi. Dark ditangkap ke-12 diantara 33 sistem, tepat di atas dasar. Mstnn tidak punya peringkat resmi, tapi skor utamanya di atas 27. Dalam kertas ini, kami menggambarkan dua sistem kami, memeriksa kekuatan dan kelemahan mereka, dan membahas pelajaran yang kami pelajari.', 'sw': 'Tumeunda mifumo miwili rahisi kwa ajili ya parge ya kutegemea: darc, mchambuzi wa mpito, na mstnn, mchanganyiko wa picha. Tulijaribu mifumo yetu katika mashindano ya CoNLL 2017 UD ilishirikisha kazi, na kwa ujasiri kuwa mfumo rasmi. Giza lilikuwa na rangi ya 12 kati ya mifumo 33, zaidi ya msingi. Mstnn hakuwa na vyeo rasmi, lakini vipindi vyake vikuu vilikuwa juu ya 27. Katika karatasi hii, tunaelezea mifumo yetu miwili, tutachungulia nguvu zao na udhaifu wao, na kujadili masomo tuliyojifunza.', 'af': "Ons het twee eenvoudige stelsels ontwikkel vir afhanklikheid verwerking: darc, 'n transition-based ontwerker en mstnn, 'n graafgebaseerde ontwerker. Ons het ons stelsels in die CoNLL 2017 UD Gedeelde Opdrag toegetest, met darc die offisiele stelsel te wees. Darc rangeer 12de onder 33 stelsels, net bo die basislien. Mstnn het geen offisiele rangering gehad nie, maar sy hoofpunt was bo die 27ste. In hierdie papier beskryf ons twee stelsels, ondersoek hulle sterkte en swakhede en bespreek die geleenthede wat ons geleer het.", 'sq': 'Kemi zhvilluar dy sisteme të thjeshta për analizimin e varësisë: darc, një analizues me bazë tranzicioni, dhe mstnn, një analizues me bazë grafike. Ne testuam sistemet tona ne CoNLL 2017 UD Task Shared, me Darc te qene sistemi zyrtar. Darc u rendit i 12-ti midis 33 sistemeve, pikërisht mbi bazën. Mstnn nuk kishte asnjë renditje zyrtare, por rezultati kryesor i saj ishte mbi të 27-tën. Në këtë letër, ne përshkruajmë dy sistemet tona, shqyrtojmë fuqitë dhe dobësitë e tyre dhe diskutojmë mësimet që mësuam.', 'am': 'በጥያቄ ማጋራት ላይ ሁለት ቀላል ስርዓቶችን ደጋግመን:: ዳc ፣ በጥያቄ መተላለፊያ፣ እና mstnn ፣ በgraph-based ተሳታፊ፡፡ ስብሰባችንን በኮንஎல_2017የኦዲ ስራዎችን በመፈትነናል፣ ባለሥልጣዊ ስርዓት መሆኑን በመቃወም ሞከርን፡፡ በ33 ስርዓቶች ውስጥ ጨለማ 12 ተለይቷል፡፡ የስቴን ባለሥልጣዊ ክፍል አልነበረም ነገር ግን የዋነቱ ቁጥር ከ27ኛ በላይ ነው፡፡ በዚህ ገጽ የሁለቱን ሥርዓቶች እናሳውቃለን፣ ኃይላቸውንና ድካማዎቻቸውን ትምህርት እናስታውቃለን፡፡', 'hy': 'Մենք զարգացրեցինք երկու պարզ համակարգ կախվածության վերլուծության համար՝ Դարկ, համընթացքում հիմնված վերլուծության համակարգ և ՄՍթն, գրաֆիայի հիմնված վերլուծության համակարգ: Մենք փորձարկեցինք մեր համակարգերը 2017-ի ԿոՆԼ-ի UD-ի ընդհանուր հանձնարարության մեջ, որտեղ Դարքը պաշտոնական համակարգ է: Դարքը դասակարգված էր 33 համակարգերի 12-րդ մասում, հենց հիմքի վրա: Մսթնին ոչ մի պաշտոնական դասակարգ չուներ, բայց նրա գլխավոր գնահատականը 27-րդից վեր էր: Այս թղթի մեջ մենք նկարագրում ենք մեր երկու համակարգերը, ուսումնասիրում ենք նրանց ուժեղությունները և թույլությունները, և քննարկում ենք մեր սովորած դասերը:', 'fa': 'ما دو سیستم ساده برای تقسیم بستگی توسعه دادیم: darc، یک تقسیم بر اساس تغییر، و mstnn، یک تقسیم بر اساس گراف. ما سیستم\u200cهایمان را در کار مشترک UD ۲۰۱۷ آزمایش کردیم، با سیستم رسمی دارک باشد. دارک 12 درجه بين سيستم 33، درست بالاي خط پايگاه خانم "تن" هيچ صفحه رسمي نداشت، ولي نقطه اصلي اون بالاتر از 27م بود. در این کاغذ، ما دو سیستم\u200cهایمان را توصیف می\u200cکنیم، قدرت و ضعیفه\u200cهایشان را تحقیق می\u200cکنیم، و درس\u200cهایی را که یاد گرفتیم بحث می\u200cکنیم.', 'az': 'Biz bağımlılıq ayırılması üçün iki basit sistemi yaratdıq: darc, transition-based ayırıcı, mstnn, grafik-based ayırıcı. Biz sistemlərimizi CoNLL 2017-ci UD paylaşılmış işdə imtahana çəkdik, çünki qaranlıq sistemi olaraq. Darc 33 sistemlərin arasındakı 12-ini dərəcə, həqiqətən də temiz çizginin üstündə. Mstnn resmi dərəcəsi yoxdur, amma onun əsas dərəcəsi 27-ci dərəcənin üstündə idi. Bu kağıtda, iki sistemimizi təsdiqləyirik, güclərini və zəifliklərini incidirik, öyrəndiyimiz dərsələri mübahisə edirik.', 'bn': 'নির্ভর পার্সিং এর জন্য আমরা দুটি সাধারণ সিস্টেম উন্নয়ন করেছি: ডার্ক, একটি ট্রান্সফিকেশন ভিত্তিক প্যারালার, এবং এসটি আমরা কএনএল ২০১৭ সালে আমাদের ব্যবস্থা পরীক্ষা করেছিলাম যেখানে সরকারি ব্যবস্থা হিসেবে সাহস করা হয়েছিল। ৩৩ সিস্টেমের মধ্যে অন্ধকারের ১২ তারিখ, বেস্ট লাইনের উপরে এমস্টিনের কোন অফিসিয়াল রেঙ্কিং ছিল না, কিন্তু তার প্রধান স্কোর ২৭ থেকে বেশি। এই কাগজটিতে আমরা আমাদের দুই সিস্টেম বর্ণনা করি, তাদের শক্তি এবং দুর্বলতা পরীক্ষা করি, এবং আমরা যে শিক্ষা শিক্ষা প্রদান করেছি', 'tr': 'Ba휓lantylyk ay캇rmak 체챌in iki basit sistemi geli힊tirdik: darc, ge챌i힊ikli 챌철z체mler, mstnn, grafik tabanly 챌철z체mler. Biz sistemlerimizi CoNLL 2017-nji 첵ylda UD Pa첵la힊dyrmak 체챌in synany힊dyrdyk. Dark 33 sistemalary흫 arasynda 12-nji derejesi, esasy 챌yzgynda. Hanyny흫 resmi sahypalary 첵ok, 첵철ne esasy sany 27-nji 체st체ndeydi. Bu kagyzda, biz 철z iki sistemamyzy tassy첵ardyk, g체첵챌lerini we zafluklaryny barla첵arys we 철wrendi휓imiz sapaklarymyzy g체rr체흫 ber첵채ris.', 'bs': 'Razvili smo dva jednostavna sustava za analizu ovisnosti: darc, pretraživač na transiciji i mstnn, pretraživač na grafiku. Testirali smo naše sisteme u zajedničkom zadatku CoNLL 2017, a Darc je zvanični sistem. Darc je redovao 12. među 33 sistema, baš iznad početne linije. Gđica nije imala službenog reda, ali glavni rezultat je iznad 27. godine. U ovom papiru opisujemo naše dvije sisteme, pregledavamo njihove snage i slabosti, i razgovaramo o lekcijama koje smo naučili.', 'ca': "Vam desenvolupar dos sistemes senzills d'analització de dependencies: darc, un analitzador basat en transició, i mstnn, un analitzador basat en gràfics. Vam provar els nostres sistemes a la CoNLL 2017 UD Shared Task, amb darc ser el sistema oficial. El Darc es va classificar al 12è entre 33 sistemes, just per sobre de la base. Mstnn no tenia cap classificació oficial, però la seva puntuació principal era més enllà del 27. En aquest paper, descrivim els nostres dos sistemes, examinem les seves forces i debilitats, i discutem les lliçons que vam aprendre.", 'cs': 'Vyvinuli jsme dva jednoduché systémy pro analýzu závislostí: darc, parser založený na přechodu a mstnn, parser založený na grafech. Testovali jsme naše systémy v CoNLL 2017 UD Shared Task, přičemž oficiálním systémem je darc. Darc měl dvanácté místo mezi 33 systémy, těsně nad základní hodnotou. Mstnn neměl žádné oficiální hodnocení, ale jeho hlavní skóre bylo nad sedmdesátou. V tomto článku popisujeme naše dva systémy, zkoumáme jejich silné a slabé stránky a diskutujeme ponaučení, které jsme se naučili.', 'et': "Töötasime välja kaks lihtsat sõltuvuse parsimise süsteemi: darc, üleminekupõhine parser ja mstnn, graafik-põhine parser. Testisime oma süsteeme CoNLL 2017 UD Shared Task'is, kus darc on ametlik süsteem. Darc oli 33 süsteemi seas 12. kohal, veidi üle algtaseme. Mstnnil polnud ametlikku edetabelit, kuid tema peamine skoor oli üle 27. Käesolevas dokumendis kirjeldame oma kahte süsteemi, uurime nende tugevaid ja nõrku külgi ning arutame saadud õppetunde.", 'fi': 'Kehitimme kaksi yksinkertaista järjestelmää riippuvuuksien parsaukseen: darc, siirtymäpohjainen parser, ja mstnn, graafinen parser. Testasimme järjestelmämme CoNLL 2017 UD Shared Task -ohjelmassa, jossa darc on virallinen järjestelmä. Darc sijoittui 12. sijalle 33 järjestelmästä, hieman lähtötilanteen yläpuolella. Mstnnillä ei ollut virallista sijoitusta, mutta sen pääpisteet olivat yli 27. Tässä artikkelissa kuvailemme kahta järjestelmäämme, tarkastelemme niiden vahvuuksia ja heikkouksia sekä keskustelemme kokemistamme kokemuksista.', 'jv': 'Awak dhéwé nggawe sistem sing sampeyan kanggo kelas urip nggawe: dar, un nggawe sistem sing basa gambar, lan mstpn, un sumer barang nggawe Awak dhéwé ngewekke sistem dhéwé ning CoNLL-2011, UT Gejahatan taske, karo dar nggawe sistem offisisi. Dac wis rak 12 luwih cara-cara sing 32 sistem, ditambah kuwi wis ambang cara. Kemerdekaan ora ono offisisi sing ditambah, njuk disempatan wong kuwi wis ana banget tanggal wehhet. Nang mapun iki, awak dhéwé ngerasakno sistem awak dhéwé, bisalui nggambar barang nggawe lan ujarané, lan pisan dérané awak dhéwé wis arah awak dhéwé.', 'sk': 'Razvili smo dva preprosta sistema za razčlenitev odvisnosti: darc, razčlenjevalnik, ki temelji na prehodu, in mstnn, razčlenjevalnik, ki temelji na grafu. Naše sisteme smo testirali v CoNLL 2017 UD Shared Task, pri čemer je darc uradni sistem. Darc se je uvrstil na 12. mesto med 33 sistemi, tik nad osnovno vrednostjo. Mstnn ni imel uradne lestvice, vendar je bil njegov glavni rezultat nad 27. mestom. V prispevku opisujemo naša dva sistema, preučujemo njihove prednosti in slabosti ter razpravljamo o izkušnjah, ki smo jih pridobili.', 'ha': "Mun buɗe tsari biyu masu sauƙi wa parse ɗin da ke ƙayyade: darc, an danna parse a kan shawarar da aka shige, da msn, parser mai ƙayyade grafyuta. We tested our systems in the CoNLL 2017 UD Shared Task, with darc being the official system.  Dare na ranar 12th daga 33 na'ura, a saman layin. @ item: inmenu Ga wannan takardan, Munã bayyana na'asarmu biyu, domin ka sami ƙarfinsu da itagonsu, kuma mu yi jayayya a cikin ayukan da muka sanar.", 'he': 'פיתחנו שתי מערכות פשוטות עבור בדיקת תלויות: דרק, בדיקת מבוססת מעבר, ומסטן, בדיקת מבוססת בגרף. בדקנו את המערכות שלנו במשימה המשותפת של CoNLL 2017 UD, עם Darc להיות המערכת הרשמית. דארק התייצב ב-12 בין 33 מערכות, מעל הבסיס. למסטן לא היה שום ציון רשמי, אבל הציון הראשי שלו היה מעל ה-27. בעיתון הזה, אנחנו מתארים את שתי המערכות שלנו, בודקים את כוחותיהם וחלשותיהם, ודיונים על השיעורים שלמדנו.', 'bo': 'ང་ཚོས་རྟེན་འབྲེལ་བ་དེ་བསམ་དབྱེ་ཞིབ་ཐབས་ལམ་གཉིས་ལས་མཐུན་བཟོ་བྱས་པ་ཡིན། darc,transition-based parser,mstnn,graph-based parser ཞིབ་ཆས་འདུག ང་ཚོས་རིམ་ལ་CoNLL 2017 UD(Shared Task)ནང་དུ་ལྟ་ཞིབ་བྱས་པ་ལས་ཁོང་གིས་གཞུང་གི་མ་ལག་ཞིག་ཡིན་པ་དང་། Darc དེ་ནི་རིམ་ལུགས་ཀྱི་ཚད་ལྡན་གཉིས་པ་དང་མཐོ་བར་མཐའ་དབུགས་ཀྱི་བཀོད་པ་རེད། དེའི་མིང་གིས་གཞུང་འབྲེལ་གྱི་གྲངས་ཀ་གཅིག་ཀྱང་མེད། ཡིན་ནའང་དེ་གི་རྩ་བའི་གྲངས་ཀ་དེ་༢༧་ལས་མཐོ་ ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོའི་མ་ལག་གཉིས་དབར་གྱི་ནུས་པ་དང་ཞན་ཆ་གཤིས་ཡོད་པ་ཚོར་བརྟག་ཞིབ་བྱེད་ཀྱི་ཡོད'}
{'en': 'A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing', 'ar': 'نموذج شبكة عصبية جديد لوضع علامات نقاط البيع المشتركة وتحليل التبعية المستند إلى الرسم البياني', 'pt': 'Um novo modelo de rede neural para marcação conjunta de POS e análise de dependência baseada em gráfico', 'es': 'Un nuevo modelo de red neuronal para el etiquetado conjunto de puntos de venta y el análisis de dependencias basado en gráficos', 'fr': "Un nouveau modèle de réseau neuronal pour le marquage conjoint des points de vente et l'analyse des dépendances basée sur des graphes", 'ja': 'ジョイントPOSタグ付けとグラフベースの依存関係解析のための新規ニューラルネットワークモデル', 'zh': '一以合POS表,解析以神经网络形', 'hi': 'संयुक्त पीओएस टैगिंग और ग्राफ-आधारित निर्भरता पार्सिंग के लिए एक उपन्यास तंत्रिका नेटवर्क मॉडल', 'ru': 'Новая модель нейронной сети для совместной маркировки POS и анализа зависимостей на основе графиков', 'ga': 'Samhail Líonra Néarúil Nua do Chomhchlibeáil POS agus Parsáil Spleáchais Bunaithe ar Ghraf', 'el': 'Ένα νέο μοντέλο νευρωνικού δικτύου για κοινή σήμανση και ανάλυση εξάρτησης με βάση γραφήματα', 'hu': 'Új neurális hálózati modell a közös POS címkézéshez és grafikon alapú függőség-értelmezéshez', 'ka': 'Name', 'it': "Un nuovo modello di rete neurale per l'etichettatura congiunta dei POS e l'analisi della dipendenza basata su grafici", 'kk': 'Жалпы POS тегтерін және графикалық тәуелдік талдау үшін жаңа невралдық желі моделі', 'ms': 'Name', 'ml': 'യൂണ്ട് പോഎസ് ടാഗ്ഗിങ്ങിനും ഗ്രാഫ് അടിസ്ഥാനമായിട്ടുള്ള പാര്\u200dസിങ്ങിനും ഒരു നോവല്\u200d നെയുറല്\u200d നെറ്റ്വര്\u200dക്', 'mn': 'Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing', 'lt': 'A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing', 'mk': 'Name', 'no': 'Name', 'mt': 'Mudell ta’ Netwerk Newrali Ġdid għat-Tagging Konġunt tal-POS u l-Analiżi tad-Dipendenza bbażata fuq il-Grafika', 'ro': 'Un nou model de rețea neurală pentru etichetarea comună a POS-urilor și analizarea dependenței bazată pe grafice', 'pl': 'Nowy model sieci neuronowej dla wspólnego tagowania POS i parowania zależności opartego na wykresie', 'sr': 'Novi neuronski model za zajedničku oznake POS-a i analizu zavisnosti na grafiku', 'si': 'Name', 'sv': 'En ny neural nätverksmodell för gemensam POS-märkning och grafbaserad beroendetolkning', 'so': 'Model of Neural Network for Joint POS Tagging and Graph-based dependency Parsing', 'ur': 'Name', 'ta': 'Joint POS Tagging and Graph- based சார்ந்த சார்ந்த பாசிங்கு', 'uz': 'Name', 'vi': 'Mô hình mạng thần kinh tiểu thuyết cho thẻ bài vị kết vị kết hợp và dựa trên đồ họa', 'hr': 'Novi neuronski model za zajedničku oznake POS-a i razmatranje ovisnosti na grafiku', 'bg': 'Нов модел на неврална мрежа за съвместно маркиране на ПОС и графично базирано анализиране на зависимостта', 'nl': 'Een nieuw neuraal netwerkmodel voor gezamenlijke POS-tagging en grafiekgebaseerde afhankelijkheidsparsing', 'da': 'En ny neural netværksmodel til fælles POS-mærkning og grafbaseret afhængighedsanalyse', 'id': 'Model Rangkaian Neural Novel untuk Tagging POS dan Analisasi Dependensi Berdasarkan Graf', 'fa': 'Name', 'de': 'Ein neuartiges neuronales Netzwerkmodell für gemeinsames POS-Tagging und grafenbasiertes Dependency Parsing', 'sw': 'Mradi wa Mtandao wa Kipindi cha Neural kwa Uchaguzi wa Chama cha POS na Uhuru wa Uchaguzi', 'tr': 'POS Taglamak we Grafdaky Baýlyklyk Parlamak üçin Täze Taýral A ýry Modeli', 'sq': 'Një model i ri rrjeti nervor për etiketat e përbashkëta POS dhe analizimin e varësisë me bazë në grafik', 'af': 'Name', 'am': 'አዲስ የነጥብ መረብ ሞዴል ለJoint POS Tagging and Graph-based dependency Parsing', 'hy': 'Comment', 'bn': 'Joint POS ট্যাগিং এবং গ্রাফ ভিত্তিক নির্ভরশীল পার্সিং এর জন্য একটি নোভেল নেউরাল নেটওয়ার্ক মডেল', 'bs': 'Novi neuronski model za zajedničku oznake POS-a i analizu zavisnosti na grafiku', 'az': 'Joint POS Tagging və Graph-based Dependency Analyzing üçün Novel Nöral A ğ Modeli', 'ko': '연합어성 표기와 도형을 바탕으로 하는 의존 분석에 사용되는 신경 네트워크 모델', 'et': 'Uus neuroaalse võrgu mudel ühise POS märgistamiseks ja graafikapõhiseks sõltuvuse parsimiseks', 'cs': 'Nový model neuronové sítě pro společné značení POS a analýzu závislosti na grafech', 'ca': 'Un nou model de xarxa neuronal per etiquetar conjuntament POS i analitzar les dependencies basades en gràfics', 'fi': 'Uusi hermoverkkomalli yhteisen kassajärjestelmän merkintään ja graafiseen riippuvuuden analysointiin', 'jv': 'Name', 'ha': '@ action', 'sk': 'Nov model živčnega omrežja za označevanje skupnih POS-jev in grafično razčlenitev odvisnosti', 'he': 'Name', 'bo': 'Joint POS Tagging and Graph-based Dependency Parsing'}
{'en': 'We present a novel neural network model that learns POS tagging and graph-based dependency parsing jointly. Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem. Our extensive experiments, on 19 languages from the Universal Dependencies project, show that our model outperforms the state-of-the-art neural network-based Stack-propagation model for joint POS tagging and transition-based dependency parsing, resulting in a new state of the art. Our code is open-source and available together with pre-trained models at :https://github.com/datquocnguyen/jPTDP\n      ', 'ar': 'نقدم نموذجًا جديدًا للشبكة العصبية يتعلم علامات نقاط البيع وتحليل التبعية المستند إلى الرسم البياني بشكل مشترك. يستخدم نموذجنا LSTMs ثنائية الاتجاه لتعلم تمثيلات الميزات المشتركة لكل من علامات نقاط البيع ومهام تحليل التبعية ، وبالتالي التعامل مع مشكلة هندسة الميزات. تُظهر تجاربنا المكثفة ، التي أجريت على 19 لغة من مشروع التبعيات العالمية ، أن نموذجنا يتفوق في الأداء على نموذج تكدس التكديس المعتمد على الشبكة العصبية الحديث لوضع علامات نقاط البيع المشتركة وتحليل التبعية القائم على الانتقال ، مما أدى إلى حالة جديدة من الفن. الكود الخاص بنا مفتوح المصدر ومتوفر مع النماذج المدربة مسبقًا على: <https://github.com/datquocnguyen/jPTDP>', 'pt': 'Apresentamos um novo modelo de rede neural que aprende a marcação POS e a análise de dependência baseada em gráfico em conjunto. Nosso modelo usa LSTMs bidirecionais para aprender representações de recursos compartilhadas para tarefas de marcação de POS e análise de dependência, lidando assim com o problema de engenharia de recursos. Nossos extensos experimentos, em 19 linguagens do projeto Dependências Universais, mostram que nosso modelo supera o modelo de propagação de pilha baseado em rede neural de última geração para marcação conjunta de POS e análise de dependência baseada em transição, resultando em um novo estado da arte. Nosso código é de código aberto e está disponível junto com modelos pré-treinados em: <https://github.com/datquocnguyen/jPTDP>', 'es': 'Presentamos un nuevo modelo de red neuronal que aprende conjuntamente el etiquetado de PDV y el análisis de dependencias basado en gráficos. Nuestro modelo utiliza LSTM bidireccionales para aprender las representaciones de características compartidas para las tareas de etiquetado de PDV y análisis de dependencias, con lo que se maneja el problema de la ingeniería de funciones. Nuestros extensos experimentos, en 19 idiomas del proyecto Dependencias Universales, muestran que nuestro modelo supera al modelo de propagación de pilas basado en redes neuronales de última generación para el etiquetado conjunto de PDV y el análisis de dependencias basado en transiciones, lo que da como resultado un nuevo estado de la técnica. Nuestro código es de código abierto y está disponible junto con modelos previamente entrenados en: < https://github.com/datquocnguyen/jPTDP >', 'fr': "Nous présentons un nouveau modèle de réseau neuronal qui apprend conjointement le marquage POS et l'analyse de dépendance basée sur des graphes. Notre modèle utilise des LSTM bidirectionnels pour apprendre les représentations d'entités partagées à la fois pour les tâches de balisage POS et d'analyse des dépendances, gérant ainsi le problème d'ingénierie des fonctionnalités. Nos expériences approfondies, sur 19 langues du projet Universal Dependencies, montrent que notre modèle surpasse le modèle de propagation de pile basé sur un réseau de neurones de pointe pour le marquage conjoint POS et l'analyse de dépendance basée sur la transition, ce qui donne lieu à un nouvel état de la technique. Notre code est open source et disponible avec des modèles préformés sur\xa0: < https://github.com/datquocnguyen/jPTDP >", 'ja': '我々は、POSタグ付けとグラフベースの依存関係解析を共同で学習する新規のニューラルネットワークモデルを提示する。当社のモデルは、双方向LSTMを使用して、POSタグ付けと依存関係解析の両方のタスクで共有される機能表現を学習し、機能工学の問題を処理します。ユニバーサル依存性プロジェクトの19の言語での当社の広範な実験は、当社のモデルが、共同POSタグ付けおよび遷移ベースの依存性解析のための最先端のニューラルネットワークベースのスタック伝播モデルを上回り、新しい最先端をもたらすことを示しています。当社のコードはオープンソースで、事前にトレーニングを受けたモデルと一緒に利用できます。 <https://github.com/datquocnguyen/jPTDP>', 'zh': '吾为新神经网络,可与共学POS图之所恃以为解析。 吾法用双向 LSTM 以学 POS 志赖解析事,以处其功。 吾于通用 19 目之言多实验,明吾合 POS 标于转易解析优于先进之基,播之于神经网络堆栈,以成新技术水平。 吾代码开源也,可与豫教者用之:<https://github.com/datquocnguyen/jPTDP>', 'hi': 'हम एक उपन्यास तंत्रिका नेटवर्क मॉडल प्रस्तुत करते हैं जो पीओएस टैगिंग और ग्राफ-आधारित निर्भरता को संयुक्त रूप से पार्सिंग सीखता है। हमारा मॉडल पीओएस टैगिंग और निर्भरता पार्सिंग कार्यों दोनों के लिए साझा किए गए फीचर अभ्यावेदन सीखने के लिए द्विदिश एलएसटीएम का उपयोग करता है, इस प्रकार फीचर-इंजीनियरिंग समस्या को संभालता है। यूनिवर्सल डिपेंडेंसी प्रोजेक्ट से 19 भाषाओं पर हमारे व्यापक प्रयोगों से पता चलता है कि हमारा मॉडल संयुक्त पीओएस टैगिंग और संक्रमण-आधारित निर्भरता पार्सिंग के लिए अत्याधुनिक तंत्रिका नेटवर्क-आधारित स्टैक-प्रोपेगेशन मॉडल को मात देता है, जिसके परिणामस्वरूप कला की एक नई स्थिति होती है। हमारा कोड ओपन-सोर्स है और पूर्व-प्रशिक्षित मॉडल के साथ एक साथ उपलब्ध है: <https://github.com/datquocnguyen/jPTDP>', 'ru': 'Мы представляем новую модель нейронной сети, которая совместно изучает маркировку POS и анализ зависимостей на основе графов. Наша модель использует двунаправленные LSTM для изучения представлений функций, общих как для задач POS-тегов, так и для задач синтаксического анализа зависимостей, таким образом решая проблему разработки функций. Наши обширные эксперименты на 19 языках из проекта Universal Dependencies показывают, что наша модель превосходит современную модель распространения стека на основе нейронной сети для совместной POS-метки и синтаксического анализа зависимостей на основе перехода, что приводит к новому уровню техники. Наш код является открытым исходным кодом и доступен вместе с предварительно обученными моделями по адресу: <https://github.com/datquocnguyen/jPTDP>', 'ga': 'Cuirimid samhail líonra néarúil nua i láthair a fhoghlaimíonn clibeáil POS agus parsáil spleáchais bunaithe ar ghraif i gcomhpháirt. Úsáideann ár múnla LSTManna déthreoracha chun uiríll gné a roinntear le haghaidh tascanna clibeála POS agus parsála spleáchais a fhoghlaim, rud a láimhseálann fadhb na gné-innealtóireacht. Léiríonn ár dturgnaimh fhairsing, ar 19 dteanga ón tionscadal um Spleáchas Uilíoch, go n-éiríonn lenár múnla níos fearr ná an tsamhail iomadaithe Stack-iomadaithe néar-líonra úrscothach do chomhchlibeáil POS agus do pharsáil spleáchais atá bunaithe ar an trasdul, rud a fhágann go bhfuil staid nua ann. den ealaín. Tá ár gcód foinse oscailte agus tá sé ar fáil mar aon le samhlacha réamhoilte ag: <https://github.com/datquocnguyen/jPTDP>', 'ka': 'ჩვენ აჩვენებთ პრომენტური ნეიროლური ქსელის მოდელს, რომელიც POS-ს ჭდეების და გრაფიკური დამუშავებულობის გადაწყვეტილება ერთად. ჩვენი მოდელი გამოიყენება ბიდერექციონალური LSTMs გამოყენება, რომ სწავლოთ ფუნქციების გამოსახულებები, რომლებიც POS-ს მონიშნულება და დასახულებელობა პარალიზაციის დამუშ ჩვენი გაფართოვებული ექსპერიმენტები, 19 ენაზე სამყარო განსაკუთრებულობების პროექტიდან, ჩვენი მოდელი გავაკეთება ახალი სურათის განსაკუთრებულ ნეიროლური ქსელის განსაკუთრებულ მოდელზე, რომელიც შემდეგ ახალი სურათის განსაკუთრებულ ჩვენი კოდი არის გახსნილი ფორმა და მოხსნილია ერთად პროგრამეტრებული მოდელებით: https://github.com/datquocnguyen/jPTDP >', 'hu': 'Bemutatunk egy új neurális hálózati modellt, amely közösen tanulja a POS címkézést és a gráf alapú függőségi elemzést. Modellünk kétirányú LSTMeket használ a POS-címkézési és függőség-elemzési feladatokhoz megosztott funkcióreprezentációk megtanulására, így kezelve a funkciótervezési problémát. Az Univerzális Függőségek projekt 19 nyelvén végzett kiterjedt kísérleteink azt mutatják, hogy modellünk felülmúlja a legkorszerűbb neurális hálózat alapú Stack-terjedési modellt a közös POS címkézéshez és átmeneti alapú függőség-elemzéshez, ami új korszerűséget eredményez. Kódunk nyílt forráskódú és előre képzett modellekkel együtt elérhető: < https://github.com/datquocnguyen/jPTDP >', 'el': 'Παρουσιάζουμε ένα νέο μοντέλο νευρωνικού δικτύου που μαθαίνει από κοινού την επισήμανση και την ανάλυση εξάρτησης βάσει γραφής. Το μοντέλο μας χρησιμοποιεί αμφίδρομη για να μάθει αναπαραστάσεις χαρακτηριστικών που μοιράζονται τόσο για την επισήμανση όσο και για τις εργασίες ανάλυσης εξαρτήσεων, αντιμετωπίζοντας έτσι το πρόβλημα μηχανικής χαρακτηριστικών. Τα εκτεταμένα πειράματά μας, σε 19 γλώσσες από το έργο Οικουμενικές Εξαρτήσεις, δείχνουν ότι το μοντέλο μας ξεπερνά το σύγχρονο μοντέλο διάδοσης στοίβας που βασίζεται σε νευρωνικό δίκτυο για κοινή σήμανση και ανάλυση εξάρτησης βασισμένη σε μετάβαση, με αποτέλεσμα μια νέα κατάσταση της τέχνης. Ο κώδικας μας είναι ανοιχτός και διαθέσιμος μαζί με προ-εκπαιδευμένα μοντέλα στο: < https://github.com/datquocnguyen/jPTDP >', 'it': "Presentiamo un nuovo modello di rete neurale che impara congiuntamente il tagging POS e l'analisi delle dipendenze basata su grafici. Il nostro modello utilizza LSTMs bidirezionali per imparare le rappresentazioni delle funzionalità condivise sia per le attività di tagging POS che di analisi delle dipendenze, gestendo così il problema di feature engineering. I nostri estesi esperimenti, su 19 lingue del progetto Universal Dependences, mostrano che il nostro modello supera lo stato dell'arte del modello Stack-propagation basato sulla rete neurale per il tag POS congiunto e l'analisi delle dipendenze basata sulla transizione, con conseguente nuovo stato dell'arte. Il nostro codice è open source e disponibile insieme ai modelli pre-addestrati a: < https://github.com/datquocnguyen/jPTDP >", 'ms': 'Kami memperkenalkan model rangkaian saraf yang baru yang belajar mengesan POS dan penghuraian dependensi berdasarkan graf bersama-sama. Model kami menggunakan LSTM bidireksi untuk belajar perwakilan ciri-ciri berkongsi untuk kedua-dua tugas penghuraian POS dan dependensi, sehingga mengendalikan masalah teknik-ciri. Eksperimen ekstensif kami, pada 19 bahasa dari projek Universal Dependencies, menunjukkan bahawa model kami melampaui model pembangunan Stack-berdasarkan rangkaian saraf state-of-the-art untuk tag POS bersama dan penghuraian dependensi berdasarkan transisi, yang menghasilkan keadaan baru. Kod kami adalah sumber terbuka dan tersedia bersama-sama dengan model yang dilatih sebelum: < https://github.com/datquocnguyen/jPTDP >', 'kk': 'Біз POS тегтерін және график негізінде тәуелдік талдау үлгісін бірге үйренетін романдық неврал желі үлгісін таңдаймыз. Біздің үлгіміз POS тегтерін және тәуелдік талдау тапсырмаларының өзгерістерін үйрену үшін bidirectional LSTMs дегенді қолданады, сондықтан мүмкіндіктерді инженерлік мәселесін қамтамас Біздің кеңейтілген тәжірибелеріміз, 19 тілде "Universal dependance" жобаның 19 тілдерінде, моделіміз POS тегтерін және ауыстыру тәуелдігін талдау үшін жаңа жағдай өзінің күйіне негізделген невралдық желінің күйіне негізделген Stack- propagation моделі жоқ де Біздің кодымыз ашық көзі және алдын- ала оқылған үлгілерімен бірге қол жеткізеді: https://github.com/datquocnguyen/jPTDP >', 'lt': 'Mes pristatome naują neurologinio tinklo model į, kuris kartu moko POS žymėjimą ir grafiniu būdu pagrįstą priklausomybės analizavimą. Mūsų modelis naudoja dvikrypčius LSTM, kad išsiaiškintų savybių atstovavimus, pasidalijusius POS ženklinimo ir priklausomybės analizavimo užduotimis, taip spręsdami savybių inžinerijos problem ą. Mūsų ekstensyvūs eksperimentai, atlikti 19 Universal Dependencies projekto kalbų, rodo, kad mūsų modelis yra geriausias nei naujausias neurologinio tinklo pagrindu pagrįstas Stack propagation modelis, skirtas bendram POS žymėjimui ir pereinamojo laikotarpio priklausomybės analizei, dėl kurio atsiranda nauja pažanga. Mūsų kodas yra atviras ir prieinamas kartu su iš anksto parengtais modeliais: < https://github.com/datquocnguyen/jPTDP >', 'mk': 'We present a novel neural network model that learns POS tagging and graph-based dependency parsing jointly.  Нашиот модел користи дводрекционални ЛСТМ за да ги научи претставувањата на функциите заеднички за обележување на POS и зависноста на анализирање задачи, со што ќе се справи проблемот со инженерството на функциите. Нашите експерименти, на 19 јазици од проектот Универзални зависности, покажуваат дека нашиот модел го надминува најсовремениот модел за пропагација на стак-мрежата базиран на најновите нервни мрежи за заедничко означување на POS и анализирање на зависноста базирана на транзиција, што резултира со нова најнова смисла. Нашиот код е отворен код и достапен заедно со предобучени модели на: < https://github.com/datquocnguyen/jPTDP >', 'ml': 'പോഎസ് ടാഗ്ഗിങ്ങും ഗ്രാഫ് അടിസ്ഥാനമായിട്ടുള്ള ആശ്രയം പാര്\u200dജിങ്ങ് പഠിക്കുന്ന ഒരു നോവല്\u200d നെയുറല്\u200d നെറ്റര്\u200d ന നമ്മുടെ മോഡല്\u200d ഉപയോഗിക്കുന്നത് പോഎസ് ടാഗിങ്ങിനും ആശ്രയിക്കുന്ന പാര്\u200dജിങ്ങിനും വേണ്ടിയുള്ള പ്രതിനിധികള്\u200d പഠിക്കാന്\u200d വേണ്ട നമ്മുടെ വിശാലമായ പരീക്ഷണങ്ങള്\u200d, യൂണിട്ട് പോഎസ് ടാഗ്ഗിങ്ങ് ചെയ്യുന്നതും മാറ്റാന്\u200d അടിസ്ഥാനമായ ആശ്രയിക്കുന്ന സ്റ്റാക്ക് സ്റ്റാക്ക് സ്റ്റാക്ക് പ്രോപ്പഗ്രാജിങ്ങും  നമ്മുടെ കോഡ് തുറക്കുന്ന സ്രോതസ്സാണ് പിന്നെ പരിശീലന മോഡലുകളോടൊപ്പം ലഭ്യമാകുന്നു: < https://github.com/datquocnguyen/jPTDP >', 'mt': 'Aħna nippreżentaw mudell ġdid tan-netwerk newrali li jitgħallem it-tikkettar tal-POS u l-analiżi tad-dipendenza bbażata fuq il-grafika b’mod konġunt. Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem.  L-esperimenti estensivi tagħna, fuq 19-il lingwa mill-proġett tad-Dipendenzi Universali, juru li l-mudell tagħna huwa aktar avvanzat mill-mudell ta’ propagazzjoni tal-istack ibbażat fuq in-netwerk newrali l-aktar avvanzat għall-ittikkettjar konġunt tal-POS u l-analizzazzjoni tad-dipendenza bbażata fuq it-tranżizzjoni, li jirriżulta f’avvanz ġdid tal-a ħħar. Il-kodiċi tagħna huwa open-source u disponibbli flimkien ma’ mudelli mħarrġa minn qabel fuq: < https://github.com/datquocnguyen/jPTDP >', 'no': 'Vi presenterer eit romant neuralnettverksmodell som lærer POS-merking og grafikkbasert avhengighet å tolka saman. Modellen vårt bruker bidireksjonale LSTMs for å lære funksjonsrepresentasjonar delt for både POS-merking og avhengighetstolking av oppgåver, slik at funksjonsengineering-problemet handterar. Våre utvidende eksperimenter, på 19 språk frå universelle avhengighetsprosjektet, viser at modellen vårt utfører stående neuralnettverk-basert Stack-propagasjonsmodellen for joint POS-tagging og overgang-basert avhengighetstolking, som fører til ein ny tilstand i kunsten. Koden vårt er opna kjelde og tilgjengeleg saman med føreøvinga modeller på: < https://github.com/datquocnguyen/jPTDP >', 'pl': 'Przedstawiamy nowy model sieci neuronowej, który wspólnie uczy się tagowania POS i parsowania zależności opartego na wykresie. Nasz model wykorzystuje dwukierunkowe LSTMy do nauki reprezentacji funkcji współdzielonych zarówno dla tagowania POS, jak i parsowania zależności, w ten sposób rozwiązując problem inżynierii funkcji. Nasze rozległe eksperymenty na 19-językach z projektu Universal Dependencies pokazują, że nasz model przewyższa najnowocześniejszy model propagacji Stack oparty na sieci neuronowej dla wspólnego tagowania POS i parsowania zależności opartego na przejściach, co powoduje nowy stan techniki. Nasz kod jest open-source i dostępny wraz z wstępnie przeszkolonymi modelami pod adresem: < https://github.com/datquocnguyen/jPTDP >', 'ro': 'Vă prezentăm un nou model de rețea neurală care învață etichetarea POS și analizarea dependenței bazate pe grafice împreună. Modelul nostru folosește LSTMs bidirecționale pentru a afla reprezentările caracteristicilor partajate atât pentru sarcinile de etichetare POS, cât și pentru analizarea dependențelor, gestionând astfel problema de inginerie a caracteristicilor. Experimentele noastre extinse, pe 19 limbi din proiectul Dependențelor Universale, arată că modelul nostru depășește modelul de propagare Stack-bazat pe rețele neurale de ultimă oră pentru etichetarea POS comună și analizarea dependenței bazată pe tranziție, rezultând într-o nouă stare de tehnologie. Codul nostru este open-source și disponibil împreună cu modele pre-instruite la: < https://github.com/datquocnguyen/jPTDP >', 'sr': 'Predstavljamo nov model neuralne mreže koji uči zajedno za analizu zavisnosti na grafiku. Naš model koristi dvodirektivne LSTMs kako bi naučili predstave koje su dijelile za zadatke o razmatranju ozbiljnosti i zavisnosti, tako da rješavaju problem sa inženjerstvom funkcija. Naši široki eksperimenti, na 19 jezika iz projekta Univerzalne zavisnosti, pokazuju da naš model nadmašuje model neuralne mreže na državi umjetničke neuralne mreže za zajedničku analizu označavanja POS-a i prelazne zavisnosti, što rezultira u novom stanju umjetnosti. Naš kod je otvoren izvor i dostupan zajedno sa predobučenim modelima na: < https://github.com/datquocnguyen/jPTDP - Да.', 'so': 'Waxaannu sameynaa model shabakadda neurada ah oo ku baranaya baaritaanka POS iyo jardiinada ku saleysan maamulka ku xiran. Tusaale ahaan waxaa loo isticmaalaa LSTMs si uu u barto noocyo xuquuq ah oo loo qeybeeyay shaqooyinka baaritaanka POS iyo ku xiran baaritaanka, sidaa darteed aad u qabsato dhibaatada fircoonka. Imtixaanadeena dheeraadka ah oo ku qoran 19 luuqadood oo laga soo saaray shabakadda dhamaadka ee jaamacadda, waxaad tusaysaa in modelkayagu uu ka muujiyaa qoraalka shabakadda-ka-horumarka ee Stack-propagation ee wadajirka ah ee POS tagging iyo baarshaha ku xiran ee ku saleysan dhamaanka, taasoo sababtay xaalad cusub ee farshaxanka. Qoryaddeenu waa furan yahay, waxaana la jira samooyin horay loo tababaray: https://github.com/datquocnguyen/jPTDP >', 'mn': 'Бид POS-ийн маркинг болон график суурилсан хамааралтай хамааралтай хуваалцах шинэ мэдрэлийн сүлжээний загварыг харуулж байна. Бидний загварын загвар нь хоёр нь POS маркинг болон хамаарал хамааралтай ажил дээр хуваалцах загваруудыг суралцахын тулд хоёр загварын LSTMs-г ашигладаг. Иймээс функц-инженерийн асуудлыг Бидний өргөн туршилтууд, универсал хамааралтай төслийн 19 хэл дээр бидний загвар нь урлагийн мэдрэлийн сүлжээнд суурилсан Stack-propagation загварыг POS маркинг болон шилжилт дээр хамааралтай хамааралтай хуваалцах загварын тулд шинэ нөхцөлд гаргадаг. Бидний код нээлттэй эх үүсвэртэй, урд сургалтын загвартай хамтдаа ашиглаж байна: https://github.com/datquocnguyen/jPTDP >', 'sv': 'Vi presenterar en ny neural nätverksmodell som lär sig POS-taggning och grafbaserad beroendetolkning gemensamt. Vår modell använder tvåriktade LSTMs för att lära sig funktionsrepresentationer som delas för både POS-taggning och beroendetolkning, och därmed hantera funktionstekniska problemet. Våra omfattande experiment, på 19 språk från Universal Dependences-projektet, visar att vår modell presterar bättre än den senaste neurala nätverksbaserade Stack-propagation modellen för gemensam POS-taggning och övergångsbaserad beroendetolkning, vilket resulterar i ett nytt toppmodernt tillstånd. Vår kod är öppen källkod och finns tillgänglig tillsammans med färdigutbildade modeller på: < https://github.com/datquocnguyen/jPTDP >', 'si': 'අපි ප්\u200dරධාන න්\u200dයූරල් ජාලයේ නිර්මාණයක් පෙන්වන්න පුළුවන් විදිහට POS ටැග් ගන්න සහ ග්\u200dරාෆ් අධාරිත අපේ මොඩල් භාවිතා කරනවා බිදිරික්ෂිත LSTMs ප්\u200dරශ්නයක් ඉගෙන ගන්න, POS ටැගින් සහ අවශ්\u200dය විශ්වාසය විශ්වාසය සඳහා ප්\u200d අපේ විශාල ප්\u200dරයෝජනය, ජාතික විශාල විශාල විද්\u200dයාපයක් වලින් භාෂා 19 වලින්, පෙන්වන්න, අපේ මොඩේල් ප්\u200dරයෝජනය නිර්මාණික ජාතික ජාතික විද්\u200dයාපයක් ප්\u200dරය අපේ කෝඩ් විවෘත ක්\u200dරියාත්මක විතරයි සහ ප්\u200dරශ්නයක් තියෙන්නේ: < https://github.com/datquocnguyen/jPTDP >', 'ta': 'நாம் ஒரு புதிய புதிய பாதுகார வலைப்பின்னல் மாதிரி வழங்குகிறோம் அது POS குறிக்கும் மற்றும் வரைபடத்திலான சார எங்கள் மாதிரி LSTMs பயன்படுத்துகிறது குணங்கள் குறிப்புகளை போஸ் ஒட்டுதல் மற்றும் சார்ந்த பாடல் பணிகளுக்கும் பகிர்ந்து கொள்ளும், அதனா பொதுவான சார்புகள் திட்டத்தில் இருந்து 19 மொழிகளில் எங்கள் விரிவான சோதனைகளை காட்டுகிறது, எங்கள் மாதிரி ஒரு புதிய கலைப்பாட்டின் சேர்ந்து POS குறிப்பு மற்றும் மாற்றும் சார் Our code is open-source and available together with pre-trained models at: < https://github.com/datquocnguyen/jPTDP >', 'ur': 'ہم ایک نور نیورال نیٹ ورک موڈل کو پیش کرتے ہیں جو POS ٹاگ اور گراف بنیادی نیوڈنسیٹ پارس کی تعلیم کرتا ہے۔ ہمارا موڈل دوئڈرکیشن LSTMs کو استعمال کرتا ہے کہ POS ٹاگنگ اور اعتمادی پارسینگ کے کاموں کے لئے مشترک فائدہ نمایش سکھائیں، اسی طرح فائدہ انجینژی مسئلہ کی حفاظت کریں. ہمارے گھیرے تجربے، 19 زبانوں پر عمومی اعتمادی پروژہ سے، دکھائیں کہ ہماری مدل کو نئورل نیٹورل کی حالت پر استک-پراپاگوشن موڈل کے لئے ایک جوڑے POS ٹاگ اور ٹرانسیٹ-بنیاد اعتمادی پارسینگ کے لئے کامل کرتا ہے، اور اس کے نتیجہ میں ایک نئی حالت کا نتیجہ ہے۔ ہمارا کوڈ کھلی سورج ہے اور اس سے پہلے آموزش کی مدل کے ساتھ موجود ہے: https://github.com/datquocnguyen/jPTDP >', 'uz': "Biz yangi tarmoq modelini hozir qilamiz, bu POS teglagich va grafik asosida qo'llanmalarni birlashtirishni o'rganadi. Bizning modelimiz yordamchi LSTMsdan foydalanadi, POS teglash va vazifalar bilan birlashtirilgan xususiyatlarni o'rganish uchun foydalanadi, shunday qilib imkoniyatlar muhandiya muammolarini bajarishi mumkin. Bizning kengaytirish imtiyozlarimiz, Universal Dependations лоиҳаларdan 19 tillari bilan, modelimizning yangi holatda saqlash holatini boshlaydi. Qoidamiz ochilgan manba va oldin taʼminlovchi modellar bilan bir qanday mavjud. https://github.com/datquocnguyen/jPTDP >", 'vi': 'Chúng tôi giới thiệu một mô hình mạng thần kinh mới học Đánh dấu kết cục và phân tích phụ thuộc dựa vào đồ thị. Người mẫu của chúng ta sử dụng LSD trực tiếp để học các biểu tượng được chia sẻ cho cả các công việc phân tích vị trí và độ phụ thuộc, và giải quyết vấn đề tạo đặc trưng. Những thí nghiệm bao quát, dựa trên 19 ngôn ngữ từ dự án Chuyên môn Toàn cầu, cho thấy rằng mẫu của chúng ta hoàn thành hoàn thiện tiến trình phân tích từng bước trên mạng thần kinh, dựa trên lớp Stacks-truyền hình cho kết quả kết hợp kết hợp kết quả là một trạng thái mới của nghệ thuật. Mật mã của chúng tôi là nguồn mở và có sẵn cùng với các mẫu được huấn luyện: https://github.com/datquocnguyen/jPTDP Language', 'bg': 'Представяме нов модел на невронна мрежа, който научава съвместно маркиране на ПОС и анализ на зависимостта въз основа на графики. Нашият модел използва двупосочни ЛСТМ, за да научи представянето на функции, споделени както за задачите за маркиране на ПОС, така и за анализиране на зависимости, като по този начин се справя с проблема с инженерството на функциите. Нашите обширни експерименти на 19 езика от проекта "Универсални зависимости" показват, че нашият модел превъзхожда най-съвременния модел за разпространение на стак базиран на невронна мрежа за съвместно маркиране на ПОС и анализиране на зависимости въз основа на преход, което води до ново състояние на изкуството. Нашият код е с отворен код и се предлага заедно с предварително обучени модели на: < https://github.com/datquocnguyen/jPTDP >', 'hr': 'Predstavljamo nov model neuralne mreže koji uči zajedno analiziranje ovisnosti na grafiku. Naš model koristi dvije direktivne LSTMs kako bi naučili predstave koje su dijelile za zadatke o analiziranju ozbiljnosti i ozbiljnosti POS-a, tako rješavajući problem inženjerstva. Naši široki eksperimenti, na 19 jezika iz projekta Univerzalne zavisnosti, pokazuju da naš model iznosi model proširenja stanja umjetne neuralne mreže za zajedničku analizu zavisnosti označavanja POS-a i promjene, što rezultira u novom stanju umjetnosti. Naš kod je otvoren izvor i dostupan zajedno s predobučenim modelima na: < https://github.com/datquocnguyen/jPTDP >', 'da': 'Vi præsenterer en ny neural netværksmodel, der lærer POS tagging og grafbaseret afhængighed parsing i fællesskab. Vores model bruger tovejede LSTMs til at lære funktionsrepræsentationer, der er delt for både POS-tagging og afhængighedsanalyseopgaver, og dermed håndtere funktionsteknikproblemet. Vores omfattende eksperimenter, på 19 sprog fra Universal Dependences projektet, viser, at vores model overgår den state-of-the-art neurale netværksbaserede Stack-propagation model til fælles POS tagging og overgangsbaseret afhængighedsparsing, hvilket resulterer i en ny state of the art. Vores kode er open source og tilgængelig sammen med foruddannede modeller på: < https://github.com/datquocnguyen/jPTDP >', 'nl': 'We presenteren een nieuw neuraal netwerkmodel dat samen POS tagging en grafiekgebaseerde afhankelijkheidsparsing leert. Ons model maakt gebruik van bidirectionele LSTMs om functierepresentaties te leren die worden gedeeld voor zowel POS-tagging als afhankelijkheidsparsing taken, waardoor het feature-engineering probleem wordt opgelost. Onze uitgebreide experimenten, met 19-talen uit het Universal Dependencies project, tonen aan dat ons model beter presteert dan het state-of-the-art Stack-propagation model voor gezamenlijke POS tagging en transition-based dependence parsing, wat resulteert in een nieuwe state of the art. Onze code is open source en beschikbaar samen met voorgetrainde modellen op: < https://github.com/datquocnguyen/jPTDP >', 'de': 'Wir präsentieren ein neuartiges neuronales Netzwerkmodell, das POS-Tagging und graphenbasiertes Dependency Parsing gemeinsam lernt. Unser Modell verwendet bidirektionale LSTMs, um Funktionsdarstellungen zu erlernen, die sowohl für POS-Tagging- als auch für Dependency-Parsing-Aufgaben gemeinsam genutzt werden, um das Feature-Engineering-Problem zu lösen. Unsere umfangreichen Experimente mit 19-Sprachen aus dem Universal Dependencies-Projekt zeigen, dass unser Modell das hochmoderne Stack-Propagation-Modell für gemeinsames POS-Tagging und transitionsbasiertes Abhängigkeitsparsing übertrifft, was zu einem neuen Stand der Technik führt. Unser Code ist Open-Source und zusammen mit vortrainierten Modellen verfügbar unter: < https://github.com/datquocnguyen/jPTDP >', 'fa': 'ما یک مدل شبکه عصبی نو را پیشنهاد می\u200cکنیم که با همدیگر نشان\u200cگذاری POS و بستگی بر اساس گراف آموزش می\u200cدهد. مدل ما استفاده از LSTMs\u200cهای دوتایی برای یاد گرفتن نمایش\u200cهای ویژه\u200cهای مشترک برای نشان\u200cگیری POS و مشترک بستگی\u200cها استفاده می\u200cکند، بنابراین مشکل مهندسی ویژه\u200cها را حل می\u200cکند. آزمایش های وسیع ما، در ۱۹ زبان از پروژه اعتمادی جهانی، نشان می دهد که مدل ما مدل توسط شبکه عصبی معتقد به موقعیت استک-توسعه\u200cی شبکه\u200cهای عصبی برای بررسی بستگی POS با تغییر و تغییر معتقد است که به نتیجه یک موقعیت جدید هنر انجام می\u200cدهد. کد ما منبع باز و با مدل های پیش آموزش در: https://github.com/datquocnguyen/jPTDP >', 'id': 'Kami mempersembahkan model jaringan saraf yang baru yang mempelajari tagging POS dan penghuraian tergantung grafik bersama-sama. Model kami menggunakan LSTM bidireksi untuk belajar representation karakteristik yang dibagi untuk kedua tagging POS dan tugas penghuraian dependensi, sehingga menangani masalah teknik karakteristik. Eksperimen ekstensif kami, pada 19 bahasa dari proyek Universal Dependencies, menunjukkan bahwa model kami melebihi model pembangunan Stack-berdasarkan jaringan saraf terbaik untuk tag POS bersama dan penganalisan dependensi berdasarkan transisi, yang menyebabkan keadaan baru. Kode kami adalah sumber terbuka dan tersedia bersama dengan model terlatih di: < https://github.com/datquocnguyen/jPTDP >', 'ko': '우리는 새로운 신경 네트워크 모델을 제시했는데 이 모델은 단어적 표시와 도형을 바탕으로 하는 의존 분석을 결합시켜 학습한다.우리 모델은 쌍방향 LSTM 학습어성 표시와 의존항 해석 임무 공유의 특징 표시를 사용하여 특징 공학 문제를 처리한다.Universal Dependencies Project의 19개 언어에서 진행된 대량의 실험에서 우리의 모델은 연합어성 표시와 전환을 바탕으로 하는 의존항 해석 방면에서 가장 선진적인 신경 네트워크를 바탕으로 하는 창고 전파 모델보다 우수하여 새로운 최첨단 수준을 형성하였다.우리의 코드는 오픈소스이며 다음 웹 사이트에서 사전 교육을 받은 모델과 함께 사용할 수 있습니다.<https://github.com/datquocnguyen/jPTDP>', 'tr': 'POS taglanmasyny we grafik daýanýan baglanlygyny bir birlikde öwrenýän nural şebeke nusgasyny tanyşdyrýarys. Biziň nusgamyz ikinji edip görkezilýän LSTMsleri POS taglama we baglanylyk işleri üçin bölünýän özellikleri öwrenmek üçin ullanýar, şonuň üçin özellikler-enjiniýanyň meselesini çözýär. Biziň golaý deneylerimiz, Universal Dependenci projesiniň 19 dilinde, nusgasymyz POS etiketlemesi we geçişe tabanly baglanylyk analysiýasynyň durumyny täze bir şekilde çykarýar. Biziň kodymyz açyk-çeşme we öňünden eğlenen nusgalar bilen ýerleşýän: https://github.com/datquocnguyen/jPTDP >', 'sw': 'Tunaweza kutengeneza muundo wa mtandao wa kisasa wa uraia ambao unajifunza wimbo wa POS na kutegemea kwa picha kwa pamoja. Mfano wetu unatumia wasomi wa LSTMs ili kujifunza maonyesho yaliyosambazwa kwa ajili ya mabango ya POS na kutegemea kazi za parsing, kwa hiyo inatumia tatizo la ubunifu. Majaribio yetu makubwa, kwa lugha 19 kutoka mradi wa Ulimwengu wa Kutegemea Uingereza, inaonyesha kwamba modeli yetu inaonyesha muundo wa propaganda wa hali ya kisasa inayohusika na mitandao ya kisasa ya kisasa kwa ajili ya kuunga mkono chama cha POS na kuingia kituo cha kutegemea matumaini, na kusababisha hali mpya ya ya sanaa. Kodi letu ni chanzo cha wazi na kinapatikana pamoja na mifano ya mafunzo ya awali katika: https://github.com/datquocnguyen/jPTDP >', 'sq': 'Ne paraqesim një model të ri rrjeti nervor që mëson etiketat POS dhe analizimin e varësisë në grafik së bashku. Modeli ynë përdor LSTMs dy-drejtuese për të mësuar përfaqësime të funksioneve të ndara si për etiketën POS ashtu edhe për detyrat e analizimit të varësisë, duke trajtuar kështu problemin e inxhinierisë së funksioneve. Eksperimentet tona të zgjeruara, në 19 gjuhë nga projekti i Varësive Universale, tregojnë se modeli ynë kryeson model in më të lartë të përhapjes së rrjetit nervor bazuar në Stack-propagacion për etiketat e përbashkëta POS dhe analizimin e varësisë bazuar në tranzicion, që rezulton në një gjendje të re të artit. Kodi ynë është i hapur dhe i disponueshëm së bashku me modelet e paratrajnuar në: < https://github.com/datquocnguyen/jPTDP >', 'hy': 'Մենք ներկայացնում ենք նոր նյարդային ցանցի մոդել, որը սովորում է POS-ի նշաններ և գրաֆիկի հիմնված կախվածություն միասին վերլուծել: Մեր մոդելը օգտագործում է երկու ուղղությամբ LSMT-ներ, որպեսզի սովորենք առանձնահատկությունների ներկայացումներ, որոնք կիսվում են POS-ի նշանների և կախվածության վերլուծության խնդիրների համար, այսպես վերահսկելով առանձնահատկու Մեր ընդլայնված փորձարկումները, Universal Depndenties նախագիծի 19 լեզուներում, ցույց են տալիս, որ մեր մոդելը գերազանցում է ամենաբարձր նյարդային ցանցի հիմնված Stack-տարածման մոդելը POS-ի ընդհանուր նշանների և անցման հիմնված կախվածության վերլուծության համար, ինչը հանգեցնում է նոր տեխնոլոգիայի Մեր կոդը բաց աղբյուր է և հասանելի է միասին նախապատրաստված մոդելների հետ՝ https://github.com/datquocnguyen/jPTDP _', 'af': "Ons stel 'n nuwe neuralnetwerk model wat leer POS etiket en graafgebaseerde afhanklikheid verwerking saam. Ons model gebruik bidirectional LSTMs om funksie voorstellings te leer wat gedeel is vir beide POS merking en afhanklikheid verwerking opdragte, sodat die funksie-engineering probleme hanteer. Ons uitbreidige eksperimente, op 19 taal van die Universele afhanklikheidsprojek, wys dat ons model uitvoer die state-of-the-art neuralnetwerk-gebaseerde Stack-propagasie model vir joint POS merking en transisie-gebaseerde afhanklikheidverwerking, wat resultaat in 'n nuwe staat van die kuns. Ons kode is open-bron en beskikbaar saam met vooraf-opgelei modele op: < https://github.com/datquocnguyen/jPTDP >", 'am': 'የአሁኑን የጠለቀ የኔዌብ መረብ ሞዴል እና የPOS ማተሚያ እና የgraph-based ተደጋጋሚ ማኅበርን እናስተማራለን፡፡ ሞዴሌያችን የኢንተርኔንግ ችግር መቆጣጠር እና የፖስስ ማተሚያ እና የመታሰል ስራዎችን ለመማር የሚጠይቅ የግንኙነትን የኢንጂንጂንጂንጂን ችግር ለመቆጣጠር ይችላል፡፡ የ19 ቋንቋዎች የዓለማዊ ድጋፍ ፕሮጀክት ውስጥ ያሉትን አካባቢ ፈተናዎች፣ ሞዴሌዎቻችን የራሱን የጥረት መረብ-አካባቢ የኢንተርኔት አካባቢ ስታክ-ፕሮግራፊያ ሞዴል ለመጠቀም እና በመተላለፍ የተመሳሳይ ተሟጋቾችን ማዘጋጀት እና አዲስ የዐርድ ግንኙነት እንዲያሳየው ነው፡፡ ኮዱን የተከፈተ ምንጭ ነው እና በተጠቃሚ ምርጫዎች ላይ:< https://github.com/datquocnguyen/jPTDP >', 'bn': 'আমরা একটি নভেল নিউরেল নেটওয়ার্ক মডেল উপস্থাপন করছি যা পোএস ট্যাগিং এবং গ্রাফ ভিত্তিক নির্ভর পার্সিং শিখে থাকে। Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem.  আমাদের বিস্তারিত পরীক্ষা, বিশ্ববিদ্যালয়ের নির্ভর প্রকল্পের ১৯ ভাষায়, দেখাচ্ছে যে আমাদের মডেল দেখাচ্ছে যুক্ত পোস ট্যাগিং এবং অতিক্রমের ভিত্তিক নির্ভর পার্জিং এর জন্ আমাদের কোড খোলা সোর্স এবং পূর্ব প্রশিক্ষিত মডেলের সাথে পাওয়া যাচ্ছে: < https://github.com/datquocnguyen/jPTDP >', 'bs': 'Predstavljamo novi model neuralne mreže koji uči zajedno razmatranje zavisnosti na grafiku. Naš model koristi dvije direktivne LSTMs kako bi naučili predstave koje su dijelile za zadatke za analizu oznake i zavisnosti POS-a, tako rješavajući problem inženjerstva. Naši široki eksperimenti, na 19 jezika iz projekta Univerzalne zavisnosti, pokazuju da naš model iznosi model proširenja stanja umjetne neuralne mreže Stack-propagacije za zajedničku analizu zavisnosti na označavanju POS-a i premještanju, koji rezultira u novom stanju umjetnosti. Naš kod je otvoren izvor i dostupan zajedno sa predobučenim modelima na: < https://github.com/datquocnguyen/jPTDP -Da.', 'az': 'Biz POS etiketlərini və grafik tabanlı bağımlılıq ayırmasını öyrənən yeni nöral a ğ modelini göstəririk. Bizim modellərimiz, POS etiketi və bağımlılıq ayırma işləri üçün paylaşılan özellikləri öyrənmək üçün bidirectional LSTMs istifadə edir, buna görə də özellik inženjeri problemini çəkir. Bizim genişliyimiz təcrübələrimiz, Universal Dependencies projesinin 19 dilində, modellərimizin yeni bir məlumatı olaraq POS etiketi və keçişliyinə dayanan bağlılıq analizi üçün şəklindəki nöral şəklindəki Stack-propagasyon model in in üstünlüyünü göstərir. Bizim kodumuz açıq-kaynaklı və öyrənmiş modellərlə birlikdə mövcuddur: https://github.com/datquocnguyen/jPTDP >', 'ca': "Presentam un nou model de xarxa neural que aprenen a etiquetar POS i analitzar conjuntament la dependencia basada en gràfics. Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem.  Els nostres extensos experiments, en 19 llengües del projecte Universal Dependencies, mostren que el nostre model supera el model de propagació Stack basat en la xarxa neural més avançada per etiquetar conjuntament POS i analitzar dependencies basats en la transició, resultant en un nou estat d'art. El nostre codi és de codi obert i disponible juntament amb models pré-entrenats a: < https://github.com/datquocnguyen/jPTDP >", 'cs': 'Představujeme nový model neuronové sítě, který se učí POS tagování a grafové analýzy závislostí společně. Náš model používá obousměrné LSTMy k učení se reprezentací funkcí sdílených jak pro tagování POS, tak pro úlohy analýzy závislostí, tak pro řešení problému s inženýrstvím funkcí. Naše rozsáhlé experimenty na devatenácti jazycích z projektu Universal Dependences ukazují, že náš model překonává nejmodernější model Stack-propagace založený na neuronové síti pro společné POS tagování a transformační analýzu závislostí, což vede k novému stavu techniky. Náš kód je open-source a k dispozici spolu s předškolenými modely na adrese: < https://github.com/datquocnguyen/jPTDP >', 'fi': 'Esittelemme uuden neuroverkkomallin, joka oppii POS-taggingin ja graafisen riippuvuuden jäsentämisen yhdessä. Mallimme käyttää kaksisuuntaisia LSTMs:itä oppiakseen ominaisuusesityksiä, jotka on jaettu sekä POS-tagging- että riippuvuuden jäsennystehtäviin, ja näin ollen käsitellä ominaisuussuunnitteluongelmaa. Laajat kokeemme Universaaliset riippuvuudet -projektin 19 kielellä osoittavat, että mallimme on parempi kuin huipputekninen neuroverkkopohjainen Stack-propagaatiomalli yhteiseen POS-tagaukseen ja siirtymään perustuvaan riippuvuuden parsaukseen, mikä johtaa uuteen nykytilaan. Koodimme on avointa lähdekoodia ja saatavilla yhdessä esikoulutettujen mallien kanssa osoitteessa: < https://github.com/datquocnguyen/jPTDP >', 'et': 'Esitleme uudset närvivõrgumudelit, mis õpib ühiselt POS sildistamist ja graafikapõhist sõltuvuse parsimist. Meie mudel kasutab kahesuunalisi LSTMsid funktsioonide esitamiseks, mis on jagatud nii POS sildistamise kui sõltuvuse parsimise ülesannete jaoks, lahendades seega funktsioonide projekteerimise probleemi. Meie ulatuslikud eksperimendid Universaalsed sõltuvused projektist 19 keelel näitavad, et meie mudel ületab tipptasemel neurovõrgul põhinevat Stack-propagatsiooni mudelit ühise POS sildistamise ja üleminekupõhise sõltuvuse parsimise jaoks, mille tulemuseks on uus tehnika tase. Meie kood on avatud lähtekoodiga ja saadaval koos eelkoolitud mudelitega aadressil: < https://github.com/datquocnguyen/jPTDP >', 'jv': 'Kita nyebute nguwe model kuwi nyur, nggo kuwi nggambar sistem anyar nggawe We model use Biirectual LTT M to Learn character representations shared for all points Awakdhéwé éntuk dhéwé, ngéntuk 19 dilané ning pernik Universial Njuk-ajeng https://github.com/datquocnguyen/jPTDP >', 'sk': 'Predstavljamo nov model nevronskega omrežja, ki skupaj uči označevanje POS in razčlenitev odvisnosti na grafični osnovi. Naš model uporablja dvosmerne LSTMs za učenje predstavitev funkcij v skupni rabi za opravila označevanja POS in analiziranja odvisnosti, s čimer rešuje težavo z inženiringom funkcij. Naši obsežni eksperimenti na 19 jezikih iz projekta Univerzalne odvisnosti kažejo, da naš model presega najsodobnejši model razmnoževanja Stack-razmnoževanja na podlagi nevronskih omrežij za skupno označevanje POS in razčlenitev odvisnosti na podlagi prehoda, kar je posledica novega stanja tehnologije. Naša koda je odprtokodna in je na voljo skupaj s predhodno usposobljenimi modeli na naslovu: < https://github.com/datquocnguyen/jPTDP >', 'ha': "Tuna gabatar da wani salon jerin neural na yanzu wanda yana iya sanar da tagogi na PS da baka kan grafi da aka samu'a sami. @ info: whatsthis CiraryinMu masu shimfiɗa ɗãwa, a kan harshen 19 daga Projekt na Universal Deputs, za'a nuna cewa misalinmu yana samar da shirin-state-of-the-art-the-tarayya Stack-promotion-based Stack-Stack-Based for Jordon tagning and transitional-based parse-inganci, na ƙara wani halin na sanar. KodĩnMu yana da buɗe-source kuma yana da sami tare da misoden da aka yi amfani da shi a kan: https://github.com/datquocnguyen/jPTDP >", 'he': 'אנו מציגים מודל רשת עצבית חדש שלמד תווים POS ומבוססים על גרף התלויות מבוססים ביחד. הדוגמנית שלנו משתמשת באלס-טי-אם בינויים כדי ללמוד מייצגים של תכונות משותפים גם עבור תגים POS וגם עבור משימות בדיקת תלויות, כך לטפל בבעיית הנדסה של תכונות. הניסויים המרחבים שלנו, על 19 שפות מהפרוייקט "היניברסל תלויות", מראים שהדוגמא שלנו מובילה את הדוגמא המבוססת על רשת העצבית המאוחרת למודל התרבות של POS משותף הקוד שלנו הוא מקור פתוח זמין יחד עם דוגמנים מאומנים מראש ב: < https://github.com/datquocnguyen/jPTDP >', 'bo': 'ང་ཚོས་མཐུན་དྲ་བ་དང་མཐུན Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem. ང་ཚོའི་བརྟག་ཞིབ་ཕྱོགས་པའི་སྐད་ཡིག་གཟུགས་རིས་ཀྱི་ལས་འགུལ་ལས་ཀྱང་བའི་སྒེར་གྱི་ཚད་༡༩་ལས་མཐུན་སྒྲིག ང་ཚོའི་ཨང་ཀིས་ཁ་ཕྱེས་དང་མཉམ་དུ་སྔོན་གྲངས་སྒྲིག་གི་མིག་ཆས་འདུག: < https://github.com/datquocnguyen/jPTDP >'}
{'en': 'A non-DNN Feature Engineering Approach to Dependency Parsing   FBAML at CoNLL 2017 Shared Task', 'ar': 'نهج هندسي غير DNN لتحليل التبعية - FBAML في مهمة مشتركة CoNLL 2017', 'es': 'Un enfoque de ingeniería de funciones no DNN para el análisis de dependencias: FBAML en CoNll 2017 Shared Task', 'pt': 'Uma abordagem de engenharia de recursos não DNN para análise de dependência - FBAML na tarefa compartilhada CoNLL 2017', 'fr': "Une approche d'ingénierie des fonctionnalités non DNN pour l'analyse des dépendances — FBAML at ConLL 2017 Shared Task", 'ja': '依存関係解析への非DNN機能エンジニアリングアプローチ– CoNLL 2017共有タスクのFBAML', 'ru': 'Подход к анализу зависимостей, не связанный с DNN Feature Engineering – FBAML в CoNLL 2017 Shared Task', 'hi': 'निर्भरता पार्सिंग के लिए एक गैर-DNN फीचर इंजीनियरिंग दृष्टिकोण - CoNLL 2017 साझा कार्य पर FBAML', 'zh': '赖解析非 DNN 特征之法 – CoNLL 2017 共享其 FBAML', 'ga': 'Cur Chuige Gné-Innealtóireachta neamh-DNN maidir le Parsáil Spleáchais – FBAML ag CoNLL 2017 Tasc Comhroinnte', 'el': 'Μια προσέγγιση μηχανικής μη-DNN για την ανάλυση εξάρτησης από το FBAML στο Κοινή Εργασία', 'hu': 'A nem DNN funkciómérnöki megközelítés a függőség értelmezéséhez - FBAML a CoNLL 2017 megosztott feladaton', 'it': "Un approccio non DNN Feature Engineering all'analisi della dipendenza - FBAML al CoNLL 2017 Shared Task", 'kk': 'DNN мүмкіндік емес инженерлік тәуелдік талдауына қатынау - CoNLL 2017 ортақ тапсырмасында FBAML', 'lt': 'Ne DNN savybių inžinerijos metodas priklausomybės analizei – FBAML CoNLL 2017 m. bendroje užduotyje', 'mk': 'Не-DNN пристап на инженерски примероци за анализирање зависности - FBAML на CoNLL 2017 споделена задача', 'ms': 'Name', 'ml': 'ഡിഎന്\u200d എഞ്ചിനിയര്\u200d പാര്\u200dസിങ്ങിലേക്കുള്ള ഒരു പ്രശ്നമില്ലാത്ത എഞ്ചിനീയറിങ്ങിന്\u200d', 'ka': 'Non-DNN Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'mt': 'Approċċ ta’ Inġinerija tal-Karatteristiċi mhux DNN għall-Analiżi tad-Dipendenza - FBAML f’CoNLL 2017', 'no': 'Name', 'pl': 'Podejście inżynierii funkcji innych niż DNN do analizy zależności. FBAML w CoNLL 2017 Wspólne zadanie', 'ro': 'O abordare non-DNN de inginerie a caracteristicilor pentru analizarea dependenței - FBAML la CoNLL 2017 Shared Task', 'sr': 'NeDNN inženjerski pristup razmatranju ovisnosti - FBAML na CoNLL 2017-om zajedničkom zadatku', 'si': 'A non-DNN Featural Engineering approach to Dependency Parsing - FBAML at CoNLL 2017 shared Job', 'sv': 'Ett icke-DNN-funktionstekniskt tillvägagångssätt för beroendetolkning - FBAML på CoNLL 2017 Shared Task', 'so': 'A non-DNN Feature Engineering Approach to Dependence Parsing - FBAML at CoNLL 2017 Shared Task', 'ta': 'சார்ந்த பாடலுக்கு ஒரு DNN சிறப்பு இயந்திரம் தொடர்ந்து செல்லவில்லை - கோன்எல் 2017 பகிர்ந்த பணியில் FBAML', 'ur': 'ایک غیر DNN Feature Engineering approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'mn': 'DNN-гүй Feature Engineering approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'vi': 'Cơ chế đặc trưng không thuộc dạng DNS tiếp cận Chuyển nhượng Độ phân tích: FBAML ở CoNll Buổi trưa chia sẻ Nhiệm vụ.', 'uz': 'Name', 'bg': 'Подход на инженеринг на функциите, които не са част от ДНН, към анализирането на зависимостта - Споделена задача', 'hr': 'NeDNN inženjerski pristup razmatranju ovisnosti - FBAML na CoNLL 2017-om zajedničkom zadatku', 'da': 'En ikke-DNN Feature Engineering tilgang til afhængighedsanalyse - FBAML på CoNLL 2017 delt opgave', 'nl': 'Een niet-DNN Feature Engineering benadering voor afhankelijkheidsparsing van FBAML bij CoNLL 2017 Gedeelde taak', 'de': 'Ein Nicht-DNN Feature Engineering Ansatz zum Dependency Parsing von FBAML bei CoNLL 2017 Shared Task', 'ko': '의존항 해석의 비DNN 특징 공정 방법 - CoNLL 2017 공유 작업의 FBAML', 'fa': 'یک دسترسی مهندسی غیر DNN ویژه\u200cای برای تحلیل بستگی - FBAML در کار مشترک CoNLL 2017', 'id': 'A non-DNN Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'sw': 'Mhandisi wa Uhandisi wasio DNN Inakaribia Kuchapisha Uhuru - FBAML kwenye CoNLL 2017', 'af': "'n Non-DNN Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Deel Taak", 'sq': 'A non-DNN Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'tr': 'DNN Hatlary Mühendiseýji Jawany Maýdançalygyna Ýabşyrma - FBAML at CoNLL 2017 Paýlaşdy Görev', 'am': 'የDNN ምርጫዎች የኢንጂንጂንጂንጂር ወደ ድጋፍ ማቅረብ - FBAML በCoNLL 2017 የተሰራጨው ስራ', 'hy': 'ԴՆԹ-ի ոչ բնորոշ ինժեներական մոտեցում կախվածության վերլուծությանը - FBAML 2017-ի կոնլալ հատվածում', 'bn': 'ডিএনএন বৈশিষ্ট্যাবলী পার্জিং এর কাছাকাছি যাচ্ছে- কনএল ২০১৭ সালে কাজ শেয়ার করা হয়েছে।', 'az': 'DNN olmayan Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'bs': 'NeDNN inženjerski pristup razmatranju ovisnosti - FBAML na CoNLL 2017-om zajedničkom zadatku', 'ca': "Un enfocament d'enginyeria de característiques no del DNN en l'analització de dependencies - FBAML a CoNLL 2017 Shared Task", 'cs': 'Ne-DNN Feature Engineering přístup k analýze závislosti na FBAML na CoNLL 2017 Shared Task', 'et': 'Mitte-DNNi funktsioonide tehniline lähenemisviis sõltuvuse parsimisele - FBAML CoNLL 2017 jagatud ülesanne', 'fi': 'Ei-DNN Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'sk': 'Pristop inženiringa funkcij, ki ni del DNN, k analiziranju odvisnosti - FBAML na CoNLL 2017 skupni nalogi', 'ha': 'KCharselect unicode block name', 'he': 'הגישה הנדסה לא-DNN למחקר תלויות - FBAML ב CoNLL 2017 משימה משותפת', 'bo': 'A non-DNN Feature Engineering Approach to Dependency Parsing - FBAML at CoNLL 2017 Shared Task', 'jv': 'Aowah Gak-DNN Attribute Ingenisi Atosbah kanggo Dehensik Parasing - FBIML nang CoNLL 1997 shared task'}
{'en': 'For this year’s multilingual dependency parsing shared task, we developed a pipeline system, which uses a variety of features for each of its components. Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features. Specifically, we trained a linear classifier for sentence boundary prediction, linear chain conditional random fields (CRFs) for tokenization, part-of-speech tagging and morph analysis. A second order graph based parser learns the tree structure (without relations), and fa linear tree CRF then assigns relations to the dependencies in the tree. Our system achieves reasonable performance   67.87 % official averaged macro F1 score', 'ar': 'بالنسبة للمهمة المشتركة لتحليل التبعية متعددة اللغات لهذا العام ، قمنا بتطوير نظام خطوط الأنابيب ، والذي يستخدم مجموعة متنوعة من الميزات لكل مكون من مكوناته. على عكس مناهج التعلم العميق الشائعة التي تتعلم ميزات منخفضة الكثافة باستخدام المصنف غير الخطي ، يستخدم نظامنا المصنفات الخطية المنظمة لتعلم ملايين الميزات المتفرقة. على وجه التحديد ، قمنا بتدريب المصنف الخطي للتنبؤ بحدود الجملة ، والحقول العشوائية الشرطية للسلسلة الخطية (CRFs) للترميز ، وعلامات جزء من الكلام ، وتحليل التحويل. يتعلم المحلل اللغوي المستند إلى الرسم البياني من الدرجة الثانية بنية الشجرة (بدون علاقات) ، ثم يقوم FA الخطي شجرة CRF بتعيين العلاقات إلى التبعيات في الشجرة. يحقق نظامنا أداءً معقولاً - 67.87٪ متوسط رسمي متوسط لدرجة F1 الكلية', 'pt': 'Para a tarefa compartilhada de análise de dependência multilíngue deste ano, desenvolvemos um sistema de pipeline, que usa uma variedade de recursos para cada um de seus componentes. Ao contrário das recentes abordagens populares de deep learning que aprendem recursos densos de baixa dimensão usando classificador não linear, nosso sistema usa classificadores lineares estruturados para aprender milhões de recursos esparsos. Especificamente, treinamos um classificador linear para previsão de limite de sentença, campos aleatórios condicionais de cadeia linear (CRFs) para tokenização, marcação de parte da fala e análise de morfologia. Um analisador baseado em grafo de segunda ordem aprende a estrutura da árvore (sem relações), e um CRF de árvore linear então atribui relações às dependências na árvore. Nosso sistema atinge um desempenho razoável - 67,87% da pontuação média oficial da macro F1', 'fr': "Pour la tâche partagée d'analyse des dépendances multilingue de cette année, nous avons développé un système de pipeline qui utilise diverses fonctionnalités pour chacun de ses composants. Contrairement aux approches populaires récentes d'apprentissage profond qui apprennent des caractéristiques denses de faible dimension à l'aide d'un classificateur non linéaire, notre système utilise des classificateurs linéaires structurés pour apprendre des millions d'entités éparses. Plus précisément, nous avons formé un classificateur linéaire pour la prédiction de limites de phrases, les champs aléatoires conditionnels de chaîne linéaire (CRF) pour la tokenisation, le marquage de parties du discours et l'analyse de morphing. Un analyseur basé sur un graphe de second ordre apprend la structure de l'arbre (sans relations), et fa CRF d'arbre linéaire attribue ensuite des relations aux dépendances dans l'arbre. Notre système atteint des performances raisonnables - 67,87\xa0% de score macro F1 moyen officiel", 'es': 'Para la tarea compartida de análisis de dependencias multilingüe de este año, desarrollamos un sistema de canalización que utiliza una variedad de funciones para cada uno de sus componentes. A diferencia de los recientes enfoques populares de aprendizaje profundo que aprenden características densas de baja dimensión mediante el uso de clasificadores no lineales, nuestro sistema utiliza clasificadores lineales estructurados para aprender millones de características dispersas. Específicamente, entrenamos un clasificador lineal para la predicción de límites de oraciones, los campos aleatorios condicionales de cadena lineal (CRF) para la tokenización, el etiquetado de partes del discurso y el análisis de morph. Un analizador basado en gráficos de segundo orden aprende la estructura del árbol (sin relaciones), y fa CRF de árbol lineal asigna relaciones a las dependencias en el árbol. Nuestro sistema logra un rendimiento razonable: 67,87% de puntuación macro F1 promedio oficial', 'ja': '今年の多言語依存性解析共有タスクでは、各コンポーネントにさまざまな機能を使用するパイプラインシステムを開発しました。非線形分類子を使用して低次元密度特徴を学習する最近の人気のある深層学習アプローチとは異なり、当社のシステムは構造化線形分類子を使用して、数百万のまばらな特徴を学習します。具体的には、文の境界予測のための線形分類子、トークン化のための線形連鎖条件ランダムフィールド（ CRF ）、音声の一部タグ付けおよびモルフ分析を訓練した。二次グラフベースの構文解析器は、ツリー構造（関係なし）を学習し、ファー線形ツリーCRFは、ツリー内の依存関係に関係を割り当てます。当社のシステムは合理的なパフォーマンスを達成しています– 67.87%の公式平均マクロF 1スコア', 'zh': '今年多言赖解析共事,开一管道,当系统对其每组件用诸功能。 与近行用非线性类器学低维密特徵之深学不同,吾统用结构化线性分类器以学数百万个疏。 具体来说,我练一线性分类器以句界占之,线性随机字段(CRF)以标化,词性标形析之。 盖二阶图解析器学树结构(无关于),然后fa线性树CRF分给树中之恃。 吾统得其理 - 67.87%官方均宏观F1得分', 'hi': 'इस वर्ष की बहुभाषी निर्भरता पार्सिंग साझा कार्य के लिए, हमने एक पाइपलाइन प्रणाली विकसित की, जो इसके प्रत्येक घटक के लिए विभिन्न प्रकार की सुविधाओं का उपयोग करती है। हाल ही में लोकप्रिय गहरी सीखने के दृष्टिकोण के विपरीत जो गैर-रैखिक क्लासिफायर का उपयोग करके कम आयामी घने सुविधाओं को सीखते हैं, हमारी प्रणाली लाखों विरल सुविधाओं को सीखने के लिए संरचित रैखिक क्लासिफायरका उपयोग करती है। विशेष रूप से, हमने वाक्य सीमा भविष्यवाणी के लिए एक रैखिक क्लासिफायर, टोकनाइजेशन के लिए रैखिक श्रृंखला सशर्त यादृच्छिक क्षेत्र (सीआरएफ), पार्ट-ऑफ-स्पीच टैगिंग और मॉर्फ विश्लेषण को प्रशिक्षित किया। एक दूसरा क्रम ग्राफ आधारित पार्सर पेड़ की संरचना (संबंधों के बिना) को सीखता है, और एफए रैखिक पेड़ सीआरएफ तब पेड़ में निर्भरताओं के संबंधों को असाइन करता है। हमारी प्रणाली उचित प्रदर्शन प्राप्त करता है - 67.87% आधिकारिक औसत मैक्रो F1 स्कोर', 'ru': 'Для многоязычного анализа зависимостей в этом году мы разработали систему конвейеров, которая использует множество функций для каждого из своих компонентов. В отличие от недавних популярных подходов глубокого обучения, которые изучают низкомерные плотные признаки с использованием нелинейного классификатора, наша система использует структурированные линейные классификаторы для изучения миллионов редких признаков. В частности, мы обучили линейный классификатор для предсказания границ предложений, условные случайные поля линейной цепи (CRF) для токенизации, тегирования части речи и морфного анализа. Парсер на основе графа второго порядка изучает структуру дерева (без связей), а линейное дерево ИРК затем присваивает отношения зависимостям в дереве. Наша система достигает разумной производительности – 67,87% официальный средний макробалл F1', 'ga': "Le haghaidh tasc roinnte um pharsáil spleáchais ilteangach na bliana seo, d'fhorbraíomar córas píblíne, a úsáideann gnéithe éagsúla le haghaidh gach ceann dá chomhpháirt. Murab ionann agus na cineálacha cur chuige foghlama domhain coitianta le déanaí a fhoghlaimíonn gnéithe dlúth tríthoiseacha ísle ag baint úsáide as aicmitheoir neamhlíneach, úsáideann ár gcóras aicmitheoirí líneacha struchtúrtha chun na milliúin gnéithe tanaí a fhoghlaim. Go sonrach, chuireamar oiliúint ar aicmitheoir líneach chun teorainn na pianbhreithe a thuar, réimsí randamacha coinníollach slabhraí líneacha (CRFanna) le haghaidh tokenization, clibeáil pháirteach cainte agus anailís moirf. Foghlaimíonn parsálaí dara hordú bunaithe ar ghraf struchtúr an chrainn (gan caidreamh), agus sannann fa crann líneach CRF caidreamh leis na spleáchais sa chrann. Baineann ár gcóras feidhmíocht réasúnta amach – 67.87% meánscór oifigiúil macra F1", 'ka': 'ამ წლის მრავალენგური დასახულებელობის პანუსაციაში ჩვენ გავაკეთეთეთ პიროლინური სისტემი, რომელიც ყველა მას კომპონენტებისთვის გამოყენება განსხვავებული ფუნქ ჩვენი სისტემა გამოყენებს სტრუქტურებული ლეინერი კლასიფიკაციები, რომლებიც მილიონის ნაწილეობის ფუნქციების გამოყენებაც არ-ლეინერი კლასიფიკაციის გამოყენებას. განსაკუთრებულად, ჩვენ მივიღეთ ლეინერი კლასიფიკაციას წინასწარმოდგენისთვის წინასწარმოდგენისთვის, ლეინერი წინასწარმოდგენისთვის კონფიკაციის კონფიკაციის კონფიკაციას, სიტყვი მეორე წერტილის დაბათებული პანსტერის სტრუქტურაციას ვისწავლია (შესაბამისი გარეშე გარეშე) და fa ლინიერი ხე CRF-ს შემდეგ დასაბამისი დასაბამისი ხეში. ჩვენი სისტემა მიიღება წარმოდგენელი გამოსახულება - 67.87% უფრო საშუალო მაკრო F1 წარმოდგენა', 'el': 'Για τη φετινή πολύγλωσση εργασία ανάλυσης εξάρτησης, αναπτύξαμε ένα σύστημα αγωγών, το οποίο χρησιμοποιεί μια ποικιλία χαρακτηριστικών για κάθε ένα από τα συστατικά του. Σε αντίθεση με τις πρόσφατες δημοφιλείς προσεγγίσεις βαθιάς μάθησης που μαθαίνουν πυκνά χαρακτηριστικά χαμηλής διαστάσεως χρησιμοποιώντας μη γραμμικό ταξινομητή, το σύστημά μας χρησιμοποιεί δομημένους γραμμικούς ταξινομητές για να μάθει εκατομμύρια αραιή χαρακτηριστικά. Συγκεκριμένα, εκπαιδεύσαμε έναν γραμμικό ταξινομητή για πρόβλεψη ορίων προτάσεων, γραμμικά τυχαία πεδία υπό όρους αλυσίδας (για επισήμανση, επισήμανση μέρους του λόγου και ανάλυση μορφών. Ένας αναλυτής γραφήματος δεύτερης τάξης μαθαίνει τη δομή δέντρου (χωρίς σχέσεις), και στη συνέχεια αποδίδει σχέσεις στις εξαρτήσεις του δέντρου. Το σύστημά μας επιτυγχάνει εύλογη απόδοση.67.87% επίσημο μέσο σκορ μακροεντολής', 'hu': 'Az idei többnyelvű függőség-elemzési feladat céljából kifejlesztettünk egy csővezetékrendszert, amely különböző funkciókat használ minden összetevőjéhez. A közelmúltban népszerű mélytanulási megközelítésekkel ellentétben, amelyek alacsony dimenziós sűrű funkciókat tanulnak nemlineáris osztályozóval, rendszerünk strukturált lineáris osztályozókat használ, hogy több millió ritka funkciót tanuljanak meg. Konkrétan egy lineáris osztályozót képzettünk ki a mondatok határelőrejelzésére, lineáris lánc feltételes véletlenszerű mezőkre (CRF) tokenizálásra, beszédrész-címkézésre és morf elemzésre. Egy másodrendű grafikon alapú elemző megtanulja a fa struktúráját (kapcsolatok nélkül), majd az fa lineáris fa CRF kapcsolatokat rendel a fa függőségeihez. Rendszerünk ésszerű teljesítményt ér el - 67,87% hivatalos átlagos makró F1 pontszám', 'it': "Per l'analisi delle dipendenze multilingue di quest'anno, abbiamo sviluppato un sistema di pipeline, che utilizza una varietà di funzionalità per ciascuno dei suoi componenti. A differenza dei recenti approcci di deep learning popolari che imparano caratteristiche dense a bassa dimensione utilizzando classificatori non lineari, il nostro sistema utilizza classificatori lineari strutturati per imparare milioni di caratteristiche sparse. Nello specifico, abbiamo addestrato un classificatore lineare per la previsione del limite di frase, campi casuali condizionali a catena lineare (CRF) per la tokenizzazione, tag part-of-speech e analisi morfica. Un parser basato su grafici di secondo ordine impara la struttura dell'albero (senza relazioni), e fa linear tree CRF assegna quindi le relazioni alle dipendenze nell'albero. Il nostro sistema raggiunge prestazioni ragionevoli - 67,87% di punteggio medio ufficiale macro F1", 'lt': 'Šių metų daugiakalbės priklausomybės analizės bendra užduotis metu sukūrėme vamzdynų sistemą, kuri naudoja įvairias savybes kiekvienam jos komponentui. Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features.  Konkrečiai mes apmokėme linijinį klasifikatorių sakinių ribų prognozavimui, linijinės grandinės sąlyginiams atsitiktiniams laukams (CRF) tokenizavimui, kalbos dalies žymėjimui ir morfo analizei. Antrojo eilės grafiko pagrindu pagrįstas analizatorius sužino medžio struktūrą (be santykių), o fa linijinis medžio CRF paskui priskiria santykius priklausomybėms medyje. Our system achieves reasonable performance - 67.87% official averaged macro F1 score', 'kk': 'Бұл жылдың бірнеше тілдік тәуелдігін талдау тапсырмасы үшін біз оның компоненттерінің әрбір үшін бірнеше мүмкіндіктерді қолданатын pipeline жүйесін жасадық. Біздің жүйеміз миллиондардың кеңістік мүмкіндіктерді үйрену үшін құрастырылған сызық классификациясын қолдану үшін ең жаңа көпшілік түсінікті оқыту арқылы бірнеше көпшілік Сөздері, біз сызық шектерін таңдау үшін сызық классификаторын, сызық тізбектерді таңдау үшін кездейсоқ кездейсоқ өрістер (CRF), сөздердің бір бөлігін таңдау және морф анализ үшін оқыдық. Екінші реттік график негіздеген талдаушы ағаш құрылғысын (қатынасыз болмаса) оқыды, және фа сызық ағаш CRF дегенді ағаш тәуелдеріне қатынас береді. Біздің жүйеміз дұрыс жұмыс істейді - 67,87% официалдық орташа макро F1 нүктесі', 'mk': "For this year's multilingual dependency parsing shared task, we developed a pipeline system, which uses a variety of features for each of its components.  Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features.  Specifically, we trained a linear classifier for sentence boundary prediction, linear chain conditional random fields (CRFs) for tokenization, part-of-speech tagging and morph analysis.  A second order graph based parser learns the tree structure (without relations), and fa linear tree CRF then assigns relations to the dependencies in the tree.  Нашиот систем постигнува разумни резултати - 67,87 отсто официјални просечни макро-Ф1 оценки", 'ms': 'Untuk tugas berkongsi penghuraian dependensi berbilang bahasa tahun ini, kami mengembangkan sistem saluran paip, yang menggunakan berbagai ciri-ciri untuk setiap komponen. Tidak seperti pendekatan pembelajaran mendalam yang baru-baru ini yang mempelajari ciri-ciri padat dimensi rendah menggunakan pengklasifikasi bukan-linear, sistem kita menggunakan pengklasifikasi linear struktur untuk mempelajari jutaan ciri-ciri jarang. Secara khusus, kami melatih pengklasifikasi linear untuk ramalan batas kalimat, medan rawak rantai linear bersyarat (CRF) untuk tokenization, tag-part-of-speech dan analisis morph. Penghurai tertib kedua berasaskan graf belajar struktur pokok (tanpa hubungan), dan fa CRF pokok linear kemudian menulis hubungan ke dependensi dalam pokok. Sistem kita mencapai prestasi yang masuk akal - 67.87% skor makro F1 berrata-rata rasmi', 'ml': 'ഈ വർഷത്തിന്റെ പല ഭാഷകങ്ങളുടെ ആശ്രയിക്കുന്നതിനായി നമ്മൾ പങ്കെടുത്ത ജോലിയിലേക്ക് ഒരു പൈപ്പെലൈന്\u200d സിസ്റ്റം നിര്\u200dമ്മിച് അടുത്ത പ്രധാനപ്പെട്ട ആഴത്തില്\u200d പഠിക്കുന്ന സ്ഥിതികള്\u200dക്ക് വ്യത്യസ്തമായി മില്ല്യണ്\u200d ക്ലാസ്ഫിക്ഷയര്\u200d ഉപയോഗിച്ച് കുറഞ്ഞ ഡൈമെന്\u200dഷന്\u200d ഗു പ്രത്യേകിച്ച്, വാക്കിന്റെ അതിര്\u200dത്തിയില്\u200d നിന്നും നിലനില്\u200dക്കുന്ന ചങ്ങലയില്\u200d നിലനില്\u200dക്കുന്ന നിലപാടുകള്\u200dക്കും, സംസാരിക്കുന്ന ഭാഗവും മോ രണ്ടാമത്തെ ക്രമത്തിന്റെ അടിസ്ഥാനത്തുള്ള ഗ്രാഫ് പരിശോധന വൃക്ഷത്തിന്റെ (ബന്ധമില്ലാതെ) പഠിക്കുന്നു, പിന്നെ ഫാ ലൈനി നമ്മുടെ സിസ്റ്റത്തില്\u200d വിവേകമായ പ്രവര്\u200dത്തനങ്ങള്\u200d ലഭിക്കുന്നു - 67. 87% ഓഫീസല്\u200d ഓഫീസിലേക്ക് മാക്രോ എ', 'mt': 'Għall-analiżi tad-dipendenza multilingwi ta’ din is-sena tal-kompitu komuni, żviluppajna sistema ta’ pipeline, li tuża varjetà ta’ karatteristiċi għal kull wieħed mill-komponenti tagħha. Għall-kuntrarju tal-approċċi ta’ tagħlim profond popolari riċenti li jitgħallmu karatteristiċi densi dimensjonali baxxi bl-użu ta’ klassifikatur mhux lineari, is-sistema tagħna tuża klassifikaturi lineari strutturati biex titgħallmu miljuni ta’ karatteristiċi rari. Speċifikament, a ħna mħarrġin klassifikatur lineari għat-tbassir tal-limiti tas-sentenza, kampi kondizzjonali tal-katina lineari każwali (CRFs) għat-tokenizzazzjoni, it-tikkettar tal-parti tad-diskors u l-analiżi tal-morfu. Analizzatur ibbażat fuq grafika tat-tieni ordni jitgħallem l-istruttura tas-siġar (mingħajr relazzjonijiet), u fa siġar lineari CRF imbagħad jassenja relazzjonijiet mad-dipendenzi fis-siġar. Is-sistema tagħna tikseb prestazzjoni raġonevoli - 67.87% punteġġ medju uffiċjali tal-makro F1', 'mn': 'Энэ жилийн олон хэлний хамааралтай хамааралтай ажлыг хуваалцах үед бид хоолойн шугамны системийг бүтээсэн. Энэ нь бүх компонентүүдэд олон өөрчлөлт ашигладаг. Сүүлийн үеийн алдартай гүн гүнзгий суралцах ойлголтын ялгаатай, шугаман биш хэмжээсгүй хэмжээсүүдийг ашиглан бага хэмжээсүүдийн жинхэнэ хэмжээсүүдийг суралцаж, бидний систем сая сая сая жинхэнэ Ялангуяа бид өгүүлбэр хязгаар хэмжээний таамаглах, шулууны хэлбэрийн шаардлагатай санамсаргүй талбайг (CRFs) тодорхойлох, ярианы хэсгийг тавьж, морф шинжилгээ хийх шулуун хэлбэрийг суралцсан. Хоёр дахь дараагийн график суурилсан хуваарь модны бүтэц (харилцаагүйгээр) суралцдаг. Фа шулуун модны CRF нь модны хамааралтай холбоотой. Бидний систем ойлголттой үйл ажиллагааг гаргадаг. 67.87% ерөнхийлөгчийн дундаж макро F1 оноо.', 'pl': 'Dla tegorocznego wielojęzycznego parsowania zależności wspólnego zadania opracowaliśmy system rurociągu, który wykorzystuje różne funkcje dla każdego z jego komponentów. W przeciwieństwie do najnowszych popularnych podejść głębokiego uczenia się, które uczą się niskowymiarowych cech gęstych za pomocą nieliniowego klasyfikatora, nasz system wykorzystuje strukturyzowane klasyfikatory liniowe do nauki milionów rzadkich cech. W szczególności przeszkolono klasyfikator liniowy do przewidywania granic zdań, liniowe warunkowe pola losowe (CRF) do tokenizacji, tagowania części mowy i analizy morf. Parser oparty na wykresie drugiego rzędu uczy się struktury drzewa (bez relacji), a CRF liniowego drzewa fa przypisuje relacje do zależności w drzewie. Nasz system osiąga rozsądną wydajność.67.87% oficjalnego uśredniego wyniku makro F1', 'no': 'For å tolka delt oppgåve i fleirspråkbehandsinnstillingar i denne året, har vi utvikla eit rørslingssystem, som brukar mange funksjonar for kvar av sine komponentar. I motsetjing av dei siste populære dype læringstilnærmingane som lærer lave dimensjonal tette funksjonar ved hjelp av ikkje-lineær klassifisering, bruker systemet våre strukturerte lineære klassifiserar for å lære millioner av sparse funksjonar. Spesifisert treng vi ein lineær klassifiserer for førehandsvising av setningsgrense, lineær kjede-kondicionale tilfeller (CRF) for tokenisering, delar av talemerking og morphanalyse. Eit andre rekkefølgje basert tolkar lærer trestrukturen (utan forholdet), og fa lineær treCRF tilbyr forholdet til avhengigheten i treet. Sistemet vårt gjennomfører rett utvikling - 67,87% offisielle gjennomsnittsfarge makro F1- poeng', 'ro': 'Pentru analizarea dependențelor multilingve de anul acesta, am dezvoltat un sistem de pipeline, care utilizează o varietate de caracteristici pentru fiecare componentă a acestuia. Spre deosebire de abordările populare recente de învățare profundă care învață caracteristici dense dimensiuni reduse folosind clasificatorul non-liniar, sistemul nostru utilizează clasificatoare liniare structurate pentru a învăța milioane de caracteristici rare. Mai exact, am instruit un clasificator liniar pentru predicția limitelor propozițiilor, câmpurile aleatorii condiționate cu lanț liniar (CRF) pentru tokenizare, etichetare parțială de vorbire și analiza morph. Un parser bazat pe grafice de ordine a doua învață structura arborelui (fără relații), iar CRF arborelui liniar fa atribuie relații dependențelor din arbore. Sistemul nostru obține performanțe rezonabile - 67,87% scor mediu oficial macro F1', 'sr': 'Ove godine smo razvili zajednički zadatak za analizu multijezičke zavisnosti, koji koristi razne karakteristike za svaku od svojih komponenta. Za razliku od nedavnih popularnih dubokih pristupa učenja koji nauče niske dimenzionalne gustine karakteristike koristeći ne-linearne klasifikacije, naš sistem koristi strukturirane linearne klasifikacije da nauče milione rezervnih karakteristika. Posebno smo obučili linearnu klasifikaciju za predviđanje granice rečenica, linearne lance uslovne slučajne polje (CRF) za tokenizaciju, deo govorne etikete i morfičku analizu. Drugi graf bazirani analizator nauči strukturu drveta (bez odnosa), a fa linearno drvo CRF onda dodaje odnose zavisnosti drveta. Naš sistem postiže razumnu funkciju - 67,87% službenog srednjeg makro F1 rezultata', 'sv': 'För årets flerspråkiga beroendetolkning delade uppgift utvecklade vi ett pipeline system som använder en mängd olika funktioner för var och en av dess komponenter. Till skillnad från de senaste populära djupinlärningsmetoderna som lär sig lågdimensionella täta funktioner med hjälp av icke-linjär klassificering använder vårt system strukturerade linjära klassificerare för att lära sig miljontals glesa funktioner. Specifikt utbildade vi en linjär klassificerare för meningsgränsprediktion, linjära kedjebevillkorade slumpmässiga fält (CRF) för tokenisering, deltal-taggning och morfanalys. En andra ordningens grafbaserad parser lär sig trädstrukturen (utan relationer), och fa linjärt träd CRF tilldelar sedan relationer till beroenden i trädet. Vårt system uppnår rimlig prestanda - 67,87% officiell genomsnittlig makro F1 poäng', 'so': 'Sannadan waxay u sameyn jireen shaqo qayb ah oo ku saabsan baaritaanka luuqadaha kala duduwan, taasoo u isticmaalaya kooxo kala duduwan. Si u duwan qaababka waxbarashada ee ugu dambeeyay ee aad u weyn ee barashada hoose oo aad u barto tayooyin hoos u ah oo aan la isticmaalin fasalka aan la qorin, nidaamkayagu wuxuu u isticmaalaa fasaxyo sawir ah si ay u barto milyan oo tayo ah dhirta. Si gaar ah, waxaynu tababarinnay fasax liner ah si aan ugu tababarinno xuduudaha nidaamka, baaritaanka shacabka qoriga ah (CRFs). Gargaarka labaad oo ku saleysan xarunta labaad ayaa baranaya dhismaha geedka (aan xiriir lahayn), iyo geedka CRF ee linear ah, markaasna waxay u leeyihiin xiriirka ku xiran geedka. nidaamkayagu wuxuu gaadhaa bandhig sahlan - 67.87% rasmi ah ee macro F1 score', 'si': 'මේ අවුරුද්දේ ගොඩක් භාෂාවික විශ්වාස විශ්වාස කරන්න, අපි පායිප්ලායින් පද්ධතියක් විස්තර කරනවා, ඒකෙන් හැම කො අලුත් ලොකු ගොඩක් ගොඩක් ඉගෙනගන්න අවස්ථාවක් වගේ අනුවෙන් අපේ පද්ධතිය ප්\u200dරයෝජනය නොලිනියර් විශේෂකය භාවිත කරන්න බොහොමක්  විශේෂයෙන්, අපි වාක්ය සීමාව ප්\u200dරශ්නයක් වෙනුවෙන් ලේනියර් ක්\u200dරීසිකරුවක් ප්\u200dරශ්නයක් කළා, ලේනියර් සීමාව සීමාව සිද්ධ විස්ත දෙවෙනි ක්\u200dරමය අධාරිත විශේෂකයෙන් ගස් සංවිධානය (සම්බන්ධයක් නැති විශේෂකයෙන්) ඉගෙන ගස් සංවිධානය (සම අපේ පද්ධතිය සලකුණු ප්\u200dරමාණයක් ලැබෙනවා - 67.87% සාමාන්\u200dය විශේෂ මැක්රෝ F1 ප්\u200dරමාණය', 'ta': 'இந்த வருடத்தின் பல மொழி சார்பு சார்பு பகிர்ந்த பணிக்கு, நாம் ஒரு பைப்லைன் அமைப்பை உருவாக்கினோம், அது ஒவ்வொரு பொருளுக்கும் பல பண்ப Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features.  குறிப்பிட்டு, வாக்கியத்தின் எல்லைகளை முன்பார்வைக்கு நாம் ஒரு வரிசை வகுப்பாளரை பயிற்சி செய்தோம், வரிசையில் சங்கில நிலையில் நிலையான புல இரண்டாவது வரைப்படத்தின் அடிப்படையான வரைப்படத்தின் பகுதி மரத்தின் அமைப்பை கற்றுக் கொள்கிறது (இணைப்பில்லாமல்) மற்றும் fa நேரியல்  Our system achieves reasonable performance - 67.87% official averaged macro F1 score', 'ur': 'اس سال کے متعدد زبان اعتباری کے لئے ہم نے ایک پیپ لین سیستم کو ایجاد کیا ہے جو ہر قسم کے مطابق مختلف ویژگی استعمال کرتا ہے۔ ان اگلے عمیق سیکھنے کے قریبوں کے مطابق جو نیچے اندازے سے کم اندازے کے گہرے فائدے سیکھتے ہیں غیر لینیاری کلاسیر کے مطابق، ہماری سیسٹم نے ساختہ لینیاری کلاسیر کا استعمال کرتا ہے کہ میلیون اسپریز فوئدے کو سیکھ خاص طور پر، ہم نے ایک لینیاری کلاسیر کی تعلیم دی تھی جہنم کی حد سے پیش بینی کے لئے، لینیاری زنجیر کی کنڈیشن کاندیشن کھیتیں (CRFs) ٹوکنیزی کے لئے، کلام کی قسمت ٹاگنگ اور morph تحلیل کے لئے۔ ایک دوسری آرام گراف بنیاد پھیلانے والے درخت کی ساختار (رابطہ بغیر) سکھاتا ہے، اور fa لینار درخت CRF پھر درخت کے اعتباری کے ساتھ رابطہ مقرر کرتا ہے. ہماری سیسٹم قابل فعالیت حاصل کرتی ہے -67.87% رسمی میکرو F1 اسکور', 'vi': 'Với tỉ lệ phụ thuộc của năm nay, chúng tôi đã phát triển một hệ thống dẫn đường, nó s ử dụng rất nhiều tính năng cho mỗi thành phần của nó. Không giống các phương pháp được phổ biến gần đây, học hỏi các tính chất dày không gian thấp sử dụng các phân loại không tuyến, hệ thống của chúng tôi sử dụng các phân loại tuyến nội bộ cấu trúc để học hàng triệu tính năng. Cụ thể, chúng tôi đã đào tạo một nhà phân loại đường tuyến cho khả năng tiên đoán ranh giới của câu, các trường ngẫu nhiên theo dây chuyền tuyến tính (CRF) cho hiệu ứng, đánh dấu phần ngôn ngữ và phân tích tủy sống. Một nhà phân phân mục thứ hai học về cấu trúc cây (không có quan hệ) và hệ thống CRF đường thẳng phân phối các quan hệ phụ thuộc vào cây. Hệ thống của chúng ta đạt được hiệu suất hợp lý -67.87.', 'uz': "Bu yilning bir necha tillar ishni ajratish uchun biz bir necha xil qo'shilgan vazifani yaratdik. Bu bir xil komponentlarning bir xil xususiyatlaridan foydalanadi. Yaqinda ko'pchilik o'rganish muvaffaqiyatlariga o'rganadigan qo'shimcha cheksiz xususiyatlarni o'rganadi, bizning tizimmiz qanchalik darajasini ishlatadi millionlab soʻzning imkoniyatlarini o'rganish uchun. Ko'rsatilgan, biz gapiruvchi chegarasining chegarasi, chegara chegarasining chegarasining chegarasini (CRFs) tasdiqlash uchun, gapiring qismlari tagning qismlarini va morf analyzerini bajardik. Ikkinchi tarkibi grafik asosida bog'liq daraxt tuzuvni o'rganadi, va faqat qo'l CRF darajasi va daraxtdagi qo'llanmalarni boshqaradi. Bizning tizimimiz juda yaxshi bajarishga ega bo'ladi - 67.87% rasm makro F1 scori", 'bg': 'За тазгодишната многоезична задача за анализиране на споделената задача разработихме тръбопроводна система, която използва различни функции за всеки от нейните компоненти. За разлика от последните популярни подходи за дълбоко учене, които научават нискоизмерени плътни функции, използвайки нелинеен класификатор, нашата система използва структурирани линейни класификатори, за да научи милиони редки функции. По-конкретно, обучихме линеен класификатор за предсказване на границите на изреченията, линейни вериги условни произволни полета (КРФ) за токенизация, маркиране на част от речта и анализ на морфовете. Парсор, базиран на графика от втори ред, научава структурата на дървото (без релации), а след това възлага релации на зависимостите в дървото. Нашата система постига разумни резултати - 67.87% официален среден макро резултат', 'nl': "Voor de meertalige afhankelijkheidsparsing gedeelde taak van dit jaar ontwikkelden we een pijpleidingsysteem, dat een verscheidenheid aan functies voor elk van zijn componenten gebruikt. In tegenstelling tot de recente populaire deep learning benaderingen die laagdimensionale dichte kenmerken leren met behulp van niet-lineaire classificator, gebruikt ons systeem gestructureerde lineaire classificatoren om miljoenen schaarse kenmerken te leren. Specifiek hebben we een lineaire classificator getraind voor zinsgrens voorspelling, lineaire chain conditional random fields (CRF's) voor tokenisering, part-of-speech tagging en morph analyse. Een tweede orde grafiek gebaseerde parser leert de boomstructuur (zonder relaties), en fa lineaire boom CRF wijst vervolgens relaties toe aan de afhankelijkheden in de boom. Ons systeem bereikt redelijke prestaties.67.87% officiële gemiddelde macro F1 score", 'da': "Til årets flersprogede afhængighedsanalyse delte opgave har vi udviklet et pipeline system, som bruger en række funktioner til hver af dens komponenter. I modsætning til de nylige populære deep learning tilgange, der lærer lavdimensionelle tætte funktioner ved hjælp af ikke-lineær klassifikation, vores system bruger strukturerede lineære klassifikationer til at lære millioner af sparsomme funktioner. Specielt har vi uddannet en lineær klassificering til forudsigelse af sætningsgrænser, lineære kædebetingede tilfældige felter (CRF'er) til tokenisering, del-of-tale tagging og morph analyse. En anden rækkefølge grafbaseret fortolker lærer træstrukturen (uden relationer), og fa lineær træ CRF tildeler derefter relationer til afhængighederne i træet. Vores system opnår rimelig ydeevne - 67,87% officiel gennemsnitlig makro F1 score", 'hr': 'Za ovaj godini razvijamo zajednički zadatak za analizu višejezičke zavisnosti, razvili smo sistem cijevi koji koristi razne funkcije za svaku od svojih komponenta. Za razliku od nedavnih popularnih dubokih pristupa učenja koji uče niske dimenzionalne gustine funkcije koristeći ne-linearne klasifikacije, naš sistem koristi strukturirane linearne klasifikacije kako bi naučili milijune rezervnih funkcija. Posebno smo obučili linearnu klasifikaciju za predviđanje granice rečenica, linearne lance uslovne slučajne polje (CRF) za tokenizaciju, dijelom govorne etikete i morfičku analizu. Drugi graf na temelju razmatrača nauči strukturu drveta (bez odnosa), a fa linearno drvo CRF onda dodaje odnose ovisnosti na drvetu. Naš sustav postiže razumnu funkciju - 67,87% službenog srednjeg makro F1 rezultata', 'de': 'Für die diesjährige mehrsprachige Dependency Parsing Shared Task haben wir ein Pipeline-System entwickelt, das für jede seiner Komponenten eine Vielzahl von Funktionen verwendet. Im Gegensatz zu den neuesten populären Deep Learning-Ansätzen, die niederdimensionale Dichtemerkmale mithilfe eines nichtlinearen Klassifikators erlernen, verwendet unser System strukturierte lineare Klassifikatoren, um Millionen von spärlichen Merkmalen zu lernen. Speziell trainierten wir einen linearen Klassifikator für Satzgrenzvorhersage, lineare kettenbedingte Random Fields (CRFs) für Tokenisierung, Part-of-Speech-Tagging und Morph-Analyse. Ein graphenbasierter Parser zweiter Ordnung lernt die Baumstruktur (ohne Beziehungen), und fa linearer Baum CRF weist dann Beziehungen zu den Abhängigkeiten im Baum zu. Unser System erreicht eine vernünftige Leistung.67,87% offiziell gemittelter Makro F1 Score', 'id': 'Untuk kebiasaan berbilang bahasa tahun ini, kami mengembangkan sistem pipa, yang menggunakan berbagai ciri-ciri untuk setiap komponen. Tidak seperti pendekatan belajar mendalam populer baru-baru ini yang mempelajari fitur padat dimensi rendah menggunakan klasifikasi non-linear, sistem kami menggunakan klasifikasi linear struktur untuk mempelajari jutaan fitur langka. Secara spesifik, kami melatih klasifikasi linear untuk prediksi batas kalimat, rantai linear bersyarat lapangan acak (CRF) untuk tokenisasi, bagian-dari-pidato tag dan analisis morf. Analyser berbasis grafik perintah kedua mempelajari struktur pohon (tanpa hubungan), dan fa tree linear CRF kemudian menetapkan hubungan ke dependensi di pohon. Our system achieves reasonable performance - 67.87% official averaged macro F1 score', 'fa': 'برای بررسی کردن کار مشترک بستگی های زیادی زبان این سال، سیستم لوله را توسعه کردیم، که برای هر بخش از بخش\u200cهایش از ویژه\u200cهای مختلف استفاده می\u200cکند. برخلاف دسترسی های عمیق یادگیری اخیرا که ویژگی های عمیق بعدی کم را با استفاده از مختصات غیر خطی یاد می گیرند، سیستم ما از مختصات خطی ساخته شده استفاده می کند تا میلیون ها از ویژگی های خاصی یاد بگیرند. مخصوصاً ما یک کلینگر خطی را برای پیش\u200cبینی مرز جمله آموزش دادیم، زمینه\u200cهای تصادفی خطی (CRFs) برای توکین کردن، بخشی از نقاشی سخنرانی و تحلیل مورفی. یک گراف دوم بر اساس تقسیم\u200cکننده ساختار درخت (بدون رابطه) را یاد می\u200cگیرد، و fa درخت خطی CRF، سپس رابطه\u200cهای بستگی در درخت را تهیه می\u200cکند. سیستم ما به عملکرد منطقی رسیده - 67.87 درصد مقدار متوسط ماکرو F1', 'ko': '올해의 다중 언어 의존 항목 해석 공유 작업에 대해 우리는 모든 구성 요소에 다양한 기능을 사용할 수 있는 파이프 시스템을 개발했다.최근 유행하는 비선형 분류기를 이용하여 저차원 밀집 특징을 학습하는 깊이 있는 학습 방법과 달리 우리 시스템은 구조화된 선형 분류기를 이용하여 수백만 개의 희소한 특징을 학습한다.구체적으로 문장 경계 예측에 사용되는 선형 분류기, 표기화에 사용되는 선형 체인 조건 임의장(CRF), 어성 표기와 어형 분석을 훈련했다.2 단계 그림을 기반으로 하는 해석기는 트리 구조를 학습하고 fa선형 트리 CRF는 트리의 의존항에 관계를 분배합니다.우리 시스템은 합리적인 성능 - 67.87%의 공식 평균 거시 F1 점수를 실현했다', 'sw': 'Kwa mwaka huu, kuanzisha mfumo wa pipeline, ambao unatumia vipengele kadhaa kwa kila sehemu yake. Tofauti na mbinu za hivi karibuni maarufu za kujifunza kwa kina ambazo hujifunza vipengele vya chini vya ulimwengu kwa kutumia sifa isiyo na msingi, mfumo wetu unatumia wataalamu wa mistari ili kujifunza mamilioni ya vituo vya uchimbaji. Kwa hakika, tulimfundisha mwandishi wa mstari kwa kutabiri mipaka ya hukumu, maeneo ya hali ya msingi (CRFs) kwa ajili ya kuonyesha alama, sehemu ya maneno ya kujieleza na uchambuzi wa morph. Mtandao wa pili wa picha anajifunza muundo wa mti (bila mahusiano), na mti wa msingi wa CRF, kisha anahusiana na uhusiano unaoegemea mti huo. Mfumo wetu unapata ufanisi wa sahihi - asilimia 67.87 kwa wastani wa wastani wa kipindi cha F1', 'tr': 'Bu ýyl üçin bir näçe dilli baglanylyk işini paylaşdyrmak üçin, bir pipeline sistemini döredik. Bu işiň her komponenti üçin birnäçe üýtgewler ulanýar. Ýakyndaky meýdança derin öwrenmek golaýlaryň ýaly, çyzgyly klasifikatçy ýok öwrenmek üçin biziň sistemimiz milyonlary spar özelliklerini öwrenmek üçin düşür çyzgyly klasifikatçylary ulanýar. Adatça, biz sözlerin çizgi önlemesi üçin çizgi klasifikatçy, çizgi taryşma şeklinde rastgele taryşlar (CRF), sözlerin bir parçasyny taglama we morf analizi üçin eğitirdik. Ikinji sany grafik daýanýan çykyş agaç strukturuny (relasiýasyz bolmadyk) öwrenýär, we fa çyzgyly agaç CRF-a, soňra agaçyň bağlyklaryna baglaýyşlary takyklaýar. Biziň sistemamyz makul ukyplary ýeňýär - 67.87% resmi ortalama makro F1 nokat', 'af': "Vir hierdie jaar se multitaalse afhanklikheid verwerking van gedeelde taak het ons 'n pipelyn stelsel ontwikkel, wat 'n verskeie funksies gebruik vir elke van sy komponente. Ongelyks van die onlangse populêre diep leer toegang wat lae dimensie dens funksies leer deur nie-lineêre klassifiseerder te gebruik, gebruik ons stelsel struktureerde lineêre klassifiseerders om miljoene spasiefunksies te leer. Spesifieke, ons het 'n lineêre klassifiseerder opgelei vir sin grens voorskou, lineêre ketting voorwaardes willekeurige velde (CRF) vir tokenisasie, deel van-spreek etiketing en morf analisie. 'n tweede volgorde graaf gebaseerde parser leer die boom struktuur (sonder verwante), en fa lineêre boom CRF dan toewys relasies aan die afhanklikhede in die boom. Ons stelsel bereik redelike prestasie - 67.87% offisieel gemiddelde makro F1 punt", 'am': 'ለዚህ ዓመታት በብዙ ቋንቋዎች በተለያዩ የስራ ማኅበረሰብ፣ ለሁሉም ተቃውሞ የሚጠቅመውን የፖሊስ ስርዓት አካሄድን፡፡ ባለፈው ጠለቅ ትምህርት ጥልቅ ጥልቅ ደረጃዎች በሚያስተምሩ የዋክብት ጥልቅ ምርጫዎች በማይተማሩ አይተካከሉም፣ ስርዓታችን በመሊዮን የሚቆጠሩን ምርጫዎች ለመማር ይጠቅማል፡፡ በተለይም፣ ለፍርድ ዳርቻ ትንቢት፣ የመስመር ሰንሰር ክፍል አካላትን (CRFs) ለማስተናየት፣ የንግግር ማተሚያ ክፍል እና ማርፊያውን ለማስተማርን አቀረብን፡፡ የሁለተኛ ክፍል መተላለፊያ የዛፉን ሥርዓት (ግንኙነት ሳይኖር) ያስተምራል፡፡ እናም የቅርብ ዛፍ CRF እና በዛፉ ውስጥ ግንኙነትን ያስተካክላል፡፡ ስርዓታችን የአስተናክል ድረ ገጽ አግኝቷል - 67.87 በመቶ ባለሥልጣናት ማክሮው የF1 score', 'hy': 'Այս տարվա բազմալեզվով կախվածության համար, մենք զարգացրեցինք խողովակաշարերի համակարգ, որը օգտագործում է բազմաթիվ հատկություններ իր բաղադրիչներից յուրաքանչյուրի համար: Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features.  Հատկապես, մենք վարժեցրեցինք գծային դասակարգիչ նախադասությունների սահմանների կանխատեսման համար, գծային շղթային պայմանավորված պատահական դաշտերի (ԿՌՖ) նշանակելու համար, խոսքի մասի նշանակման և մորֆի վերլուծության համար: Երկրորդ դասակարգման գրաֆիկի հիմնված խմբագրիչը սովորում է ծառի կառուցվածքը (առանց հարաբերությունների), իսկ ֆա գծային ծառի ԿՌՖ-ը հետո հարաբերությունները տրամադրում է ծառի կախվածությունների հետ: Our system achieves reasonable performance - 67.87% official averaged macro F1 score', 'az': 'Bu ilin çoxlu dil bağlılığı paylaşdığı işləri ayırmaq üçün, hər bir komponent üçün müxtəlif fəaliyyətlər istifadə edən pipeline sistemini təhsil etdik. Əvvəlki məşhur dərin öyrənmə yaxınlıqlarına bənzəyir ki, linear olmayan klasifikatçı vasitəsilə düşük ölçülük yoxluqları öyrənir, sistemimiz milyonlarla fərqli fərqli öyrənmək üçün strukturlı linear klasifikatçıları istifadə edir. Özellikle, biz cümlələr sınırı öngörünür üçün linear klasifikatçı təhsil etdik, linear zincir müəyyənləşdirilməsi üçün müəyyənləşdirilmiş rastgele sahələri (CRF), sözlərin bir parçası etiketi və morph analizi üçün təhsil etdik. İkinci sırada yazılmış parçacılıq ağac quruluşunu öyrənir (əlaqəsiz olmadan), və fa linear ağac CRF sonra ağacın bağlılıqlarına ilişkilər təyin edir. Sistemimiz münasibətli performans yetirir - 67.87% resmi ortalama makro F1 nöqtəsi', 'bn': 'এই বছরের বহুভাষার নির্ভরশীল পার্সিং পার্সিং এর জন্য আমরা একটি পাইপেলাইন সিস্টেম উন্নয়ন করেছি, যা প্রত্যেকটি অংশের জন্য বিভিন্ন বৈশিষ্ট সাম্প্রতিক জনপ্রিয় গভীর শিক্ষার ক্ষেত্রেও যেগুলো নিম্নলিখিত গভীর বৈশিষ্ট্য ব্যবহার করে নিম্নলিখিত গভীর শিক্ষা ব্যবহার করে, আমাদের সিস্ বিশেষ করে আমরা শাস্তি সীমান্ত ভবিষ্যদ্বাণী, লাইনিয়ার চেইনের অবস্থান বৈধ ক্ষেত্রে (CRFs) প্রশিক্ষণ দিয়েছিলাম, বাক্যের অংশ ট্যাগিং এবং মর্ফ বিশ দ্বিতীয় অর্ডারের ভিত্তিক গ্রাফের সংস্কৃতি শিখে (সম্পর্ক ছাড়া) এবং ফা লাইনিয়ার গাছ CRF তারপর গাছের নির্ভরের সাথে সম্পর্ক ন আমাদের সিস্টেমের যৌক্তিক ভাবে অর্জন করে - ৬৭. ৮৭% কর্মকর্তা গড়ে ম্যাক্রো এফ১ স্কোর', 'bs': 'Ove godine smo razvili zajednički zadatak za analizu multijezičke zavisnosti, koji koristi razne funkcije za svaku od svojih komponenta. Za razliku od nedavnih popularnih pristupa dubokog učenja koji nauče niske dimenzionalne gustine karakteristike koristeći ne-linearne klasifikacije, naš sistem koristi strukturirane linearne klasifikacije da nauče milione rezervnih karakteristika. Posebno smo obučili linearnu klasifikaciju za predviđanje granice rečenica, linearne lance uslovne nasumične polje (CRF) za tokenizaciju, dijelom govorne etikete i morfičku analizu. Drugi graf bazirani analizator nauči strukturu drveta (bez odnosa), a fa linearno drvo CRF onda dodaje odnose zavisnosti drveta. Naš sistem postiže razumnu funkciju - 67,87% službenog srednjeg makro F1 rezultata', 'cs': 'Pro letošní vícejazyčnou analýzu závislostí jsme vyvinuli systém potrubí, který využívá různé funkce pro každou ze svých komponent. Na rozdíl od nedávných populárních přístupů hlubokého učení, které se učí nízko dimenzionální hustoty pomocí nelineárního klasifikátoru, náš systém používá strukturované lineární klasifikátory k učení se miliony řídkých funkcí. Konkrétně jsme vycvičili lineární klasifikátor pro predikci hranic věty, lineární řetězcové podmíněné náhodné pole (CRF) pro tokenizaci, značení části řeči a morph analýzu. Parser založený na grafech druhého řádu se naučí strukturu stromu (bez vztahů) a FA lineární strom CRF pak přiřadí vztahy závislostem ve stromu. Náš systém dosahuje přiměřeného výkonu.67% oficiálního průměrného skóre makra F1', 'ca': "For this year's multilingual dependency parsing shared task, we developed a pipeline system, which uses a variety of features for each of its components.  Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features.  En concret, vam entrenar un classificador linear per a predir les fronteres de frases, camps aleatòries condicionats de cadena linear (CRF) per a la fitogenització, etiquetar part-of-speech i anàlisi de morfa. Un analitzador basat en un gràfic de segon ordre aprene l'estructura d'arbre (sense relacions), i fa arbre linear CRF afecta relacions a les dependencies de l'arbre. Our system achieves reasonable performance - 67.87% official averaged macro F1 score", 'et': 'Selle aasta mitmekeelse sõltuvuse parsimiseks jagatud ülesandeks töötasime välja torujuhtmesüsteemi, mis kasutab erinevaid funktsioone iga komponendi jaoks. Erinevalt hiljutistest populaarsetest sügavõppe lähenemisviisidest, mis õpivad mittelineaarse klassifikaatori abil madalamõõtmelisi tihedaid funktsioone, kasutab meie süsteem struktureeritud lineaarseid klassifikaatoreid miljonite hõredate funktsioonide õppimiseks. Täpsemalt koolitasime lineaarset klassifikaatorit lausepiiride ennustamiseks, lineaarse ahela tingimusliku juhusliku välja (CRF) tokeniseerimiseks, kõneosa sildistamiseks ja morfianalüüsiks. Teise astme graafikutel põhinev parser õpib puustruktuuri (ilma seosteta) ja fa lineaarne puu CRF määrab seejärel seosed puu sõltuvustega. Meie süsteem saavutab mõistliku jõudluse - 67,87% ametlik keskmine makro F1 skoor', 'fi': 'Tämän vuoden monikielistä riippuvuuden jäsentämistä varten kehitimme putkijärjestelmän, joka käyttää erilaisia ominaisuuksia kullekin komponentilleen. Toisin kuin viimeaikaiset suositut syväoppimismenetelmät, joissa opitaan matalaulotteisia tiheitä ominaisuuksia epälineaarisen luokittimen avulla, järjestelmämme käyttää strukturoituja lineaarisia luokittelijoita miljoonien harvojen ominaisuuksien oppimiseen. Tarkemmin sanottuna koulutimme lineaarisen luokittelijan lauserajojen ennustamiseen, lineaarisen ketjun ehdollisiin satunnaiskenttiin (CRF) tokenisointiin, puheen osamerkintään ja morfianalyysiin. Toisen järjestyksen kaavioon perustuva jäsentäjä oppii puun rakenteen (ilman suhteita), ja fa lineaarinen puu CRF määrittää sitten suhteet puun riippuvuuksiin. Järjestelmämme saavuttaa kohtuullisen suorituskyvyn - 67,87% virallinen keskiarvo makro F1 pisteet', 'sq': 'Për varësinë shumëgjuhëse të këtij viti duke analizuar detyrën e përbashkët, ne zhvilluam një sistem tubacioni, i cili përdor një shumëllojshmëri karakteristike për secilin prej komponenteve të tij. Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features.  Specifically, we trained a linear classifier for sentence boundary prediction, linear chain conditional random fields (CRFs) for tokenization, part-of-speech tagging and morph analysis.  A second order graph based parser learns the tree structure (without relations), and fa linear tree CRF then assigns relations to the dependencies in the tree.  Our system achieves reasonable performance - 67.87% official averaged macro F1 score', 'sk': 'Za letošnjo večjezično razčlenjevanje odvisnosti od skupne naloge smo razvili cevovodni sistem, ki uporablja različne funkcije za vsako svojo komponento. Za razliko od nedavnih priljubljenih pristopov globokega učenja, ki se učijo nizkodimenzionalnih gostih funkcij z nelinearnim klasifikatorjem, naš sistem uporablja strukturirane linearne klasifikatorje za učenje milijonov redkih funkcij. Natančneje smo usposobili linearni klasifikator za napovedovanje meje stavkov, linearna verižna pogojna naključna polja (CRF) za žetonizacijo, označevanje delov govora in analizo morfov. Razčlenjevalnik drugega reda, ki temelji na grafu, nauči strukturo drevesa (brez relacij), linearno drevo fa CRF pa nato dodeli relacije odvisnostim v drevesu. Naš sistem dosega razumno zmogljivost - 67,87% uradno povprečno oceno makro F1', 'he': 'עבור התלויות רבות לשונות של השנה, בדיקת משימה משותפת, פיתחנו מערכת צינורות, אשר משתמשת במגוון של תכונות לכל אחד מהרכיבים שלה. בניגוד לגישות הלימודים העמוקים הפופולריות האחרונות שלמדות תכונות צפופופות במימד נמוך באמצעות מסווג לא לינרי, המערכת שלנו משתמשת בסווגים לינריים מבוססים ללמוד מיליוני תכונות נדירים. במיוחד, אימנו מסגר לינרי לחזוי גבול משפטים, שדות מיוחדים לינריים בשרשרת מיוחדים אקראיים (CRFs) לטוקניזציה, תג חלק מהדיבור וניתוח מורף. A second order graph based parser learns the tree structure (without relations), and fa linear tree CRF then assigns relations to the dependencies in the tree.  המערכת שלנו משיגה ביצועים הגיוניים - 67.87% נקודת מקרו F1 ממוצע רשמי', 'ha': "Ina ƙidãya ga parse aikin mulki-lingui da aka raba shi a shekara shekara wannan, mun buɗa wani na'urar misalin, wanda ke amfani da wasu shiryoyi masu tsari ga kowace compound. Di motsi da masu jama'a na farko da aka samu karatun tsari masu ƙari na sauri, masu amfani da tsari wa-linjeri, na'urar system yana yin amfani da fasalararori masu tsari na linjeri, dõmin su sanar millions na tsari. Aka ƙayyade, mun sanar da wani mai fassarwa na kwanan kwance wa babu wani abu na ƙetare, filin sarƙoƙi na tsaye (CRFs) wa tsari, rabin tagogi na magana da kuma analyn morf. Ana sanar da fassarar grafi na biyu yana karatun matsayin itãciyar (bã na tsaro), kuma yana danna wata itãce CRF, sa'an nan yana yarda da masu inganci ga itãciyar. Ga tsarinMu ya sami rabon da inganci - 67.87% rasmi mai karo matro F1 score", 'jv': 'Awak dhéwé nggawe akeh multilenguang dipunangkapan sawar nggawe gerakan karo sistem sing gak nggawe lan sistem sing memperbudhakan kanggo sampeyan akeh operasi kanggo sampeyan sampeyan Genjer-Genjer echoH e l l o space w o r l d periodHelloworldHello world Display active Sistem-sijiné punika perusahaan sing dikarepaké awak dhéwé - Setujug-akèh% offisisi sing wis menyang macro F1', 'bo': 'ལོ་འདིའི་རྒྱལ་སྐད་ཡིག་ཆ་རྒྱལ་ཁབ་ཀྱི་དབྱེ་སྟངས་བཤད་ཀྱི་ལས་འགུལ་སྤྱོད་ཀྱི་རྩིས་འཁོར་ཞིག་གསར་བསྐྲུན་བྱས། ས་་ཆ་ཤས་རེ་ Recently known deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of sparse features. Specifically, we trained a linear classifier for sentence boundary prediction, linear chain conditional random fields (CRFs) for tokenization, part-of-speech tagging and morph analysis. དབྱེ་རིགས་གཉིས་པ་དང་གཞི་བརྟེན་པའི་བཀོད་པ་གཉིས་པ་དེ་དབྱིབས་དབྱིབས་བཟོ་བྱེད་དེ་(འབྲེལ་མེད་པ་) དང་ ཕྱི་གྲལ་ཐོག་གི་རྩིས་པ ང་ཚོའི་མ་ལག་གི་སྐྱེས་ཚད་ལེན་རྐྱེན་སྟངས་འདྲ་བྱུང་ཡོད།'}
{'en': 'A non-projective greedy dependency parser with bidirectional LSTMs', 'ar': 'محلل تبعية جشع غير إسقاطي مع LSTMs ثنائية الاتجاه', 'es': 'Un analizador de dependencias avaricioso no proyectiva con LSTM bidireccionales', 'pt': 'Um analisador de dependência ganancioso não projetivo com LSTMs bidirecionais', 'fr': 'Un analyseur de dépendance gourmand non projectif avec des LSTM bidirectionnels', 'ja': '双方向LSTMを備えた非投機的な貪欲な依存関係構文解析器', 'zh': '有双向 LSTM 者非射贪恃解析器', 'hi': 'द्विदिश LSTMs के साथ एक गैर-प्रोजेक्टिव लालची निर्भरता पार्सर', 'ru': 'Непроективный жадный парсер зависимостей с двунаправленными LSTM', 'ga': 'Parsálaí spleáchais sanntach neamhtheilgneach le LSTManna déthreocha', 'ka': 'პროექტიური არაკეთექტიური დამხმარეობის პანელიზატორი, რომელიც მეორექტიური LSTMs', 'hu': 'Nem projektív mohó függőség-elemző kétirányú LSTMekkel', 'it': 'Un analizzatore di dipendenze avido non proiettivo con LSTMs bidirezionali', 'el': 'Ένας μη προβολικός αναλυτής άπληστης εξάρτησης με αμφίδρομη LSTMs', 'kk': 'Проективті емес сәттілік тәуелдік талдаушы', 'lt': 'Neprojektyvus greedy dependency parser su dvikryptiniais LSTM', 'mk': 'Непроективен анализатор на алчност со двоправни LSTMs', 'ms': 'Penghurai dependensi tidak-projektif serakah dengan LSTM bidireksi', 'ml': 'പ്രോജക്റ്റീവ് ആശ്രയിക്കാത്ത ആശ്രയിക്കാനുള്ള ഒരു പ്രക്രോജക്റ്റീവ് ലിസ്റ്റിക്കല്\u200d എസ്എസ', 'mt': 'Analizzatur tad-dipendenza mhux proġettiv b’affidabbiltà b’LSTMs bidirezzjonali', 'pl': 'Nieprojekcyjny parser chciwych zależności z dwukierunkowymi LSTMami', 'ro': 'Un parser de dependență lacom non-proiectiv cu LSTMs bidirecționale', 'sr': 'Neprojektivni analizač pohlepne zavisnosti sa dvodirektivnim LSTMsom', 'si': 'නොප්\u200dරෝජෙක්ටිවෙන්න ප්\u200dරශ්නයක් නොවිශ්වාසිත විශ්වාසයක් සමග දෙන්නේ LSTMs', 'so': 'A non-projective greed dependency parser with bidirectional LSTMs', 'sv': 'En icke-projektiv girig beroendetolkare med tvåriktade LSTMs', 'no': 'Name', 'mn': 'Нэг төсөл биш, хоёр дахь LSTMs-тэй холбоотой хамааралтай хамааралтай хуваалцагч', 'ta': 'Name', 'ur': 'ایک غیر پروژیکٹی گلیڈی ڈیفانسیٹ پارٹر جس کے ساتھ بیڈیرٹیکشنال LSTMs', 'vi': 'Một cha xứ phụ thuộc tham dự không bị dàn xếp với LSTM hai bên.', 'uz': 'Name', 'hr': 'Neprojektivni analizač pohlepne zavisnosti s bidirektivnim LSTMsom', 'da': 'En ikke- projektiv grådig afhængighedsfortolker med tovejede LSTMs', 'nl': 'Een niet-projectieve hebberige afhankelijkheidsparser met bidirectionele LSTMs', 'ko': '양방향 LSTM을 가진 비투영 탐욕 의존 해상도', 'id': 'Sebuah parser dependensi tidak proyektif serakah dengan LSTM bidireksi', 'de': 'Ein nicht-projektiver gieriger Abhängigkeitsparser mit bidirektionalen LSTMs', 'sw': 'Mchambuzi wa uchumi usio na mradi wa matarajio yenye utaratibu wa LSTMs', 'fa': 'یک بازیگر بستگی آلودگی غیر پروژه\u200cای با LSTMs دوباره', 'bg': 'Непроективен алчен анализатор на зависимости с двупосочни LSTMs', 'tr': 'Işdireksiyonal LSTM bilen faýly açylmady', 'af': 'Name', 'sq': 'Një analizues i varësisë jo-projektive me LSTMs dy-drejtues', 'am': 'ምርጫዎች', 'hy': 'Երկու ուղղությամբ LSMT-ներով ոչ պրոյեկտիվ խորամանկար կախվածություն', 'az': 'İkinci LSTMs ilə proyektiv olmayan arzulu bağlılıq ayırıcısı', 'bn': 'Name', 'ca': 'Un analitzador de dependencies no projeccionalamb LSTMs bidireccionals', 'cs': 'Neprojektivní chamtivý parser závislostí s obousměrnými LSTMs', 'bs': 'Neprojektivni analizač pohlepne zavisnosti sa dvodirektivnim LSTMsom', 'et': 'Mitteprojektiivne ahne sõltuvuse parser kahesuunaliste LSTMdega', 'fi': 'Ei-projektiivinen ahne riippuvuuden jäsentäjä kaksisuuntaisilla LSTMillä', 'jv': 'Sampeyan Open Failed', 'sk': 'Neprojektivni pohlepni razčlenjevalec odvisnosti z dvosmernimi LSTMi', 'ha': "Paramer ɗabi'a na-wata matalauci na dabam-daban", 'he': 'מעבד תלויות חמדן לא פרויקטיבי עם LSTMs שתיים כיוונים', 'bo': 'bidirectional LSTMs དང་འབྲེལ་བ་མིན་ལས་ཁོངས་སྤྱོད་མེད་པའི་འཇུག་རྟེན་འབྲེལ་མིན་འདུག'}
{'en': 'The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation of the Covington (2001) algorithm for non-projective dependency parsing. The bidirectional LSTM approach by Kiperwasser and Goldberg (2016) is used to train a greedy parser with a dynamic oracle to mitigate error propagation. The model participated in the CoNLL 2017 UD Shared Task. In spite of not using any ensemble methods and using the baseline segmentation and PoS tagging, the parser obtained good results on both macro-average LAS and UAS in the big treebanks category (55 languages), ranking 7th out of 33 teams. In the all treebanks category (LAS and UAS) we ranked 16th and 12th. The gap between the all and big categories is mainly due to the poor performance on four parallel PUD treebanks, suggesting that some ‘suffixed’ treebanks (e.g. Spanish-AnCora) perform poorly on cross-treebank settings, which does not occur with the corresponding ‘unsuffixed’ treebank (e.g. Spanish). By changing that, we obtain the 11th best LAS among all runs (official and unofficial). The code is made available athttps://github.com/CoNLL-UD-2017/LyS-FASTPARSE\n      ', 'ar': 'يقدم فريق LyS-FASTPARSE BIST-COVINGTON ، وهو تطبيق عصبي لخوارزمية Covington (2001) لتحليل التبعية غير الإسقاطية. يتم استخدام نهج LSTM ثنائي الاتجاه بواسطة Kiperwasser و Goldberg (2016) لتدريب محلل جشع باستخدام أوراكل ديناميكي لتخفيف انتشار الخطأ. شارك النموذج في مهمة CoNLL 2017 UD المشتركة. على الرغم من عدم استخدام أي من طرق التجميع واستخدام التجزئة الأساسية وعلامات PoS ، فقد حصل المحلل اللغوي على نتائج جيدة في كل من LAS و UAS في فئة بنوك الأشجار الكبيرة (55 لغة) ، حيث احتل المرتبة السابعة من بين 33 فريقًا. في فئة جميع الضفاف الشجرية (LAS و UAS) حصلنا على المركزين السادس عشر والثاني عشر. ترجع الفجوة بين الفئتين الكبيرة والكبيرة بشكل أساسي إلى الأداء الضعيف لأربعة بنوك شجرية متوازية PUD ، مما يشير إلى أن بعض ضفاف الأشجار "الملحقة" (مثل Spanish-AnCora) تعمل بشكل سيئ في إعدادات عبر ضفاف الأشجار ، وهو ما لا يحدث مع " ضفة الشجر غير المثبتة (مثل الإسبانية). من خلال تغيير ذلك ، نحصل على المركز الحادي عشر من بين أفضل الجامعات (الرسمية وغير الرسمية). الكود متاح على <https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>', 'es': 'El equipo de LYS-FastParse presenta BIST-COVINGTON, una implementación neuronal del algoritmo de Covington (2001) para el análisis de dependencias no proyectivas. El enfoque LSTM bidireccional de Kiperwasser y Goldberg (2016) se utiliza para entrenar a un analizador ávido con un oráculo dinámico para mitigar la propagación de errores. La modelo participó en la tarea compartida UD de CoNll 2017. A pesar de no utilizar ningún método de conjunto y utilizar la segmentación de línea base y el etiquetado PoS, el analizador obtuvo buenos resultados tanto en las macromedias LAS como en las UAS en la categoría de grandes bancos de árboles (55 idiomas), ocupando el séptimo lugar de 33 equipos. En la categoría de todos los bancos de árboles (LAS y UAS) ocupamos el puesto 16 y 12. La brecha entre todas las categorías y las grandes se debe principalmente al mal desempeño de cuatro bancos de árboles PUD paralelos, lo que sugiere que algunos bancos de árboles «sufijos» (por ejemplo, el español Ancora) tienen un rendimiento deficiente en entornos de bancos de árboles cruzados, lo que no ocurre con el banco de árboles «sin sufijo» correspondiente (por ejemplo, español). Al cambiar eso, obtenemos la undécima mejor LAS entre todas las carreras (oficiales y no oficiales). El código está disponible en < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'pt': "A equipe LyS-FASTPARSE apresenta o BIST-COVINGTON, uma implementação neural do algoritmo de Covington (2001) para análise de dependência não projetiva. A abordagem LSTM bidirecional de Kiperwasser e Goldberg (2016) é usada para treinar um analisador guloso com um oráculo dinâmico para mitigar a propagação de erros. O modelo participou da Tarefa Compartilhada CoNLL 2017 UD. Apesar de não utilizar nenhum método de ensemble e utilizar a segmentação de linha de base e marcação PoS, o analisador obteve bons resultados tanto em LAS macro-média quanto em UAS na categoria big treebanks (55 idiomas), ocupando o 7º lugar entre 33 equipes. Na categoria all treebanks (LAS e UAS) ficamos em 16º e 12º. A diferença entre as categorias all e big é principalmente devido ao baixo desempenho em quatro treebanks PUD paralelos, sugerindo que alguns treebanks com sufixo (por exemplo, Spanish-AnCora) têm um desempenho ruim em configurações cross-treebank, o que não ocorre com o correspondente ` treebank sem sufixo' (por exemplo, espanhol). Alterando isso, obtemos o 11º melhor LAS entre todas as corridas (oficiais e não oficiais). O código está disponível em <https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>", 'fr': "L'équipe LYS-FastParse présente BIST-COVINGTON, une implémentation neuronale de l'algorithme de Covington (2001) pour l'analyse de dépendance non projective. L'approche LSTM bidirectionnelle de Kiperwasser et Goldberg (2016) est utilisée pour entraîner un analyseur gourmand avec un oracle dynamique afin d'atténuer la propagation des erreurs. Le modèle a participé au ConLL 2017 UD Shared Task. Bien qu'il n'utilise aucune méthode d'ensemble et qu'il utilise la segmentation de base et le balisage PoS, l'analyseur a obtenu de bons résultats à la fois sur les LAS et les UAS macro-moyennes dans la catégorie des grandes banques d'arbres (55 langues), se classant 7e sur 33 équipes. Dans la catégorie toutes les banques d'arbres (LAS et UAS), nous nous sommes classés 16e et 12e. L'écart entre les catégories «\xa0all\xa0» et «\xa0big\xa0» est principalement dû à la piètre performance de quatre banques d'arbres PUD parallèles, ce qui donne à penser que certaines banques d'arbres «\xa0suffixes\xa0» (par exemple hispano-ANCORA) obtiennent de mauvais résultats sur les bancs d'arbres croisés, ce qui ne se produit pas avec la banque d'arbres «\xa0non suffixée\xa0» correspondante (par exemple l'espagnol). En changeant cela, nous obtenons le 11e meilleur LAS parmi toutes les descentes (officielles et non officielles). Le code est disponible sur < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'ja': 'LyS - FASTPARSEチームは、非投影的依存関係解析のためのCovington （ 2001 ）アルゴリズムのニューラル実装であるBIST - COVINGTONを発表します。 KiperwasserとGoldberg （ 2016 ）による双方向LSTMアプローチは、エラー伝播を軽減するために動的オラクルを備えた貪欲なパーサーを訓練するために使用される。 モデルは、CoNLL 2017 UD Shared Taskに参加しました。 アンサンブルメソッドを使用せず、ベースラインセグメンテーションとPoSタグ付けを使用したにもかかわらず、構文解析器はビッグツリーバンクカテゴリー（ 55言語）のマクロ平均LASとUASの両方で良好な結果を得て、33チーム中7位でした。 オールツリーバンクスカテゴリー（ LAS、UAS ）では16位、12位に入った。 すべてのカテゴリと大きなカテゴリの間のギャップは、主に4つの並行したpudツリーバンクのパフォーマンスが悪いことに起因しており、いくつかの「固定」ツリーバンク（スペイン語- AnCoraなど）は、対応する「固定されていない」ツリーバンク（スペイン語など）では発生しないクロスツリーバンクの設定ではパフォーマンスが悪いことを示唆しています。 それを変更することで、私たちはすべてのランの中で11番目に良いLASを取得します（公式および非公式）。 コードは次の場所で入手可能です。 <https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>', 'zh': 'LyS-FASTPARSE团队发BIST-COVINGTON,非投景赖解析之Covington(2001)算法之神经也。 Kiperwasser、Goldberg(2016)之双向LSTM,所以动机练贪解析器,以轻谬传也。 与CoNLL 2017 UD共事。 虽无所用,基线分PoS表,解析器在大树库之类(55言语)者宏观均LASUAS之美,排名第7于33团队。 凡树库类(LASUAS)中,各排名第16位第12位。 凡大伦相去,在于四平之PUD树库,此"后缀"树库(西班牙语 - AnCora)于跨树库不佳,此应"未后缀"树库(西班牙语)不生也。 变此者,行(官非官方)第11最佳LAS。 其代码可<https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>', 'hi': "LyS-FASTPARSE टीम BIST-COVINGTON, गैर-प्रोजेक्टिव निर्भरता पार्सिंग के लिए कोविंगटन (2001) एल्गोरिथ्म का एक तंत्रिका कार्यान्वयन प्रस्तुत करती है। किपरवासर और गोल्डबर्ग (2016) द्वारा द्विदिश एलएसटीएम दृष्टिकोण का उपयोग त्रुटि प्रसार को कम करने के लिए एक गतिशील ओरेकल के साथ एक लालची पार्सर को प्रशिक्षित करने के लिए किया जाता है। मॉडल ने CoNLL 2017 UD Shared Task में भाग लिया। किसी भी पहनावा विधियों का उपयोग नहीं करने और बेसलाइन विभाजन और पीओएस टैगिंग का उपयोग करने के बावजूद, पार्सर ने बड़े ट्रीबैंक्स श्रेणी (55 भाषाओं) में मैक्रो-औसत एलएएस और यूएएस दोनों पर अच्छे परिणाम प्राप्त किए, जो 33 टीमों में से 7 वें स्थान पर हैं। सभी treebanks श्रेणी (एलएएस और यूएएस) में हम 16 वें और 12 वें स्थान पर रहे। सभी और बड़ी श्रेणियों के बीच का अंतर मुख्य रूप से चार समानांतर PUD ट्रीबैंक पर खराब प्रदर्शन के कारण है, यह सुझाव देते हुए कि कुछ 'प्रत्ययित' ट्रीबैंक (जैसे स्पेनिश-AnCora) क्रॉस-ट्रीबैंक सेटिंग्स पर खराब प्रदर्शन करते हैं, जो संबंधित 'अनसफिक्स्ड' ट्रीबैंक (जैसे स्पेनिश) के साथ नहीं होता है। इसे बदलकर, हम सभी रनों (आधिकारिक और अनौपचारिक) के बीच 11 वां सर्वश्रेष्ठ एलएएस प्राप्त करते हैं। कोड <https://github.com/CoNLL-UD-2017/LyS-FASTPARSE> पर उपलब्ध कराया गया है", 'ru': 'Команда LyS-FASTPARSE представила BIST-COVINGTON, нейронную реализацию алгоритма Ковингтона (2001) для непроективного синтаксического анализа зависимостей. Двунаправленный подход LSTM Kiperwasser и Goldberg (2016) используется для обучения жадного парсера с динамическим оракулом для смягчения распространения ошибок. Модель участвовала в совместной задаче CoNLL 2017 UD. Несмотря на то, что не использовались методы ансамбля и базовая сегментация и PoS-тегирование, парсер получил хорошие результаты как по макросреднему LAS, так и по БАС в категории «большие банки деревьев» (55 языков), заняв 7-е место из 33 команд. В категории «все берега деревьев» (LAS и UAS) мы заняли 16-е и 12-е места. Разрыв между всеми и большими категориями объясняется главным образом низкими показателями по четырем параллельным пудам, что говорит о том, что некоторые "суффиксованные" берега деревьев (например, испанский язык - Анкора) плохо работают в условиях кросс-дерева, что не происходит с соответствующим "несуффиксованным" берегом деревьев (например, испанский язык). Изменяя это, мы получаем 11-е лучшее LAS среди всех заездов (официальных и неофициальных). Код доступен по адресу <https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>', 'ga': 'Cuireann foireann LyS-FASTPARSE BIST-COVINGTON i láthair, cur i bhfeidhm néarúil ar algartam Covington (2001) maidir le parsáil spleáchais neamhtheilgeach. Úsáidtear an cur chuige déthreorach LSTM ag Kiperwasser and Goldberg (2016) chun parsálaí greedy a oiliúint le oracle dinimiciúil chun iomadú earráide a mhaolú. Ghlac an tsamhail páirt i dTasc Comhroinnte UD 2017 CoNLL. In ainneoin nár úsáideadh aon mhodhanna ensemble agus úsáid á baint as deighilt bhunlíne agus clibeáil PoS, fuair an parsálaí torthaí maithe ar LAS macraimheánach agus UAS i gcatagóir na gcrann mór (55 teanga), ag rangú 7ú háit as 33 fhoireann. Sa chatagóir crannchuir uile (LAS agus UAS) rangaithe muid sa 16ú agus sa 12ú háit. Is é is cúis leis an mbearna idir na catagóirí iomlána agus mórchatagóirí go príomha ná an drochfheidhmíocht ar cheithre bhruach crann PUD chomhthreomhar, rud a thugann le tuiscint go n-éiríonn go dona le roinnt bruach crann “iarmhírithe” (m.sh. Spáinnis-AnCora) ar shuímh tras-chrann, rud nach dtarlaíonn leis an gcrannchur comhfhreagrach. bruach crann neamhleor (m.sh. Spáinnis). Trí é sin a athrú, faightear an 11ú LAS is fearr i measc na ritheanna go léir (oifigiúil agus neamhoifigiúil). Cuirtear an cód ar fáil ag <https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>', 'ka': "LyS-FASTPARSE ჯგუფი იყურება BIST-COVINGTON, კოვინდტონის (2001) ალგორიტიმს ნეიროლური გამოყენება, რომელიც არ არის პროექტიური დამართლებელობის პანუსაციისთვის. Kiperwasser და Goldberg (2016) მხოლოდ დინამიკური LSTM მიღება გამოყენებულია, რომელიც შეცდომის პროპაგიაციას გადასწავლად დინამიკური ორაკულით. მოდელის მოწყობილობა CoNLL 2017 UD საზოგადომი დავალებში. არ გამოყენებული ანსტემბლის მეტოვების და POS-ის ჭდეების გამოყენება, პანსტერი მიღება კარგი შედეგი მაკრო-средნაირი LAS და UAS-ის მაკრო-საშუალო საშუალო კატეგორიაში (55 ენები), რომელიც 33 ჯგუფი შვიდი წინა ყველა საბრძო კატეგორიაში (LAS და UAS) ჩვენ 16 და 12-ში დავწერეთ. ყველა და დიდი კატეგორიების შორის განსხვავება ძალიან ცოტა გამოსახულება ოთხი პარალელი PUD კონფიგურაციის გამოსახულებაზე, რომელიც აღწერს, რომ ზოგიერთი `suffixed' კონფიგურაციები (მაგალითად, სპანელი-AnCora) კონფიგურაციაში ცოტა გამოსახულება, რომელიც არ ამას ცვლილებით, ჩვენ მივიღეთ 11-ი უკეთესი LAS ყველა წარმოდგენების შორის (პროფიციალური და არაფექციალური). კოდის შესაძლებელია < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'hu': 'A LyS-FASTPARSE csapat bemutatja a BIST-COVINGTON, a Covington (2001) algoritmus neurális implementációját a nem projektív függőség elemzésére. A Kiperwasser és Goldberg (2016) kétirányú LSTM megközelítését arra használják, hogy dinamikus orákulummal rendelkező kapzsi elemzőt képezzen a hiba terjedésének enyhítésére. A modell részt vett a CoNLL 2017 UD Shared Task-ban. Annak ellenére, hogy nem használt együttes módszereket, valamint az alapszegmentációt és a PoS címkézést, az elemző jó eredményeket ért el mind a makróátlagos LAS, mind az UAS kategóriában (55 nyelv), 33 csapat közül 7. helyen. Az összes fák kategóriában (LAS és UAS) a 16. és 12. helyen álltunk. Az összes és a nagy kategóriák közötti különbség elsősorban a négy párhuzamos PUD-fák gyenge teljesítményének köszönhető, ami arra utal, hogy néhány "kiegészített" fák (pl. Spanyol-AnCora) rosszul teljesítenek a kereszt-fák beállításain, ami nem fordul elő a megfelelő "nem rögzített" fák (pl. spanyol). Ennek megváltoztatásával megszerezzük a 11. legjobb LAS-t az összes futás közül (hivatalos és nem hivatalos). A kód elérhetővé válik < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'el': 'Η ομάδα παρουσιάζει μια νευρωνική εφαρμογή του αλγόριθμου Κόβινγκτον (2001) για την ανάλυση μη προβολικής εξάρτησης. Η αμφίδρομη προσέγγιση των Κίπερwasser και Γκόλντμπεργκ (2016) χρησιμοποιείται για να εκπαιδεύσει έναν άπληστο αναλυτή με ένα δυναμικό μαντείο για να μετριάσει τη διάδοση σφαλμάτων. Το μοντέλο συμμετείχε στην κοινή εργασία CoNLL 2017 UD. Παρά τη μη χρησιμοποίηση μεθόδων συνόλου και τη χρήση της βασικής κατάτμησης και της σήμανσης PoS, ο αναλυτής πέτυχε καλά αποτελέσματα τόσο σε μακρο-μέσο όρο LAS όσο και σε UAS στην κατηγορία μεγάλων δέντρων (55 γλώσσες), με την 7η από τις 33 ομάδες. Στην κατηγορία όλων των δέντρων (LAS και UAS) κατατάξαμε 16η και 12η. Το χάσμα μεταξύ όλων και μεγάλων κατηγοριών οφείλεται κυρίως στην κακή απόδοση σε τέσσερις παράλληλες τράπεζες δέντρων, γεγονός που υποδηλώνει ότι ορισμένες "επιθετικές" τράπεζες δέντρων (π.χ. Ισπανική-AnCora) αποδίδουν άσχημα σε ρυθμίσεις διασταυρούμενης τράπεζας δέντρων, κάτι που δεν συμβαίνει με την αντίστοιχη "μη επικυρωμένη" τράπεζα δέντρων (π.χ. Ισπανικά). Αλλάζοντας αυτό, αποκτούμε το 11ο καλύτερο από όλες τις διαδρομές (επίσημες και ανεπίσημες). Ο κωδικός διατίθεται στη διεύθυνση < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'it': "Il team LyS-FASTPARSE presenta BIST-COVINGTON, un'implementazione neurale dell'algoritmo Covington (2001) per l'analisi delle dipendenze non proiettive. L'approccio bidirezionale LSTM di Kiperwasser e Goldberg (2016) viene utilizzato per formare un parser avido con un oracolo dinamico per mitigare la propagazione degli errori. Il modello ha partecipato al CoNLL 2017 UD Shared Task. Nonostante non abbia utilizzato alcun metodo di ensemble e utilizzando la segmentazione di base e il tag PoS, il parser ha ottenuto buoni risultati sia su LAS macro-media che su UAS nella categoria big treebanks (55 lingue), classificandosi settimo su 33 squadre. Nella categoria all treebanks (LAS e UAS) ci siamo classificati 16 ° e 12 ° posto. Il divario tra le categorie tutte e grandi è dovuto principalmente alle scarse prestazioni su quattro treebank paralleli PUD, suggerendo che alcuni treebank `suffissed' (ad esempio Spanish-AnCora) funzionano male sulle impostazioni cross-treebank, cosa che non si verifica con la corrispondente treebank `non affiliata' (ad esempio spagnolo). Cambiando questo, otteniamo l'undicesimo miglior LAS tra tutte le corse (ufficiali e non ufficiali). Il codice è reso disponibile all'indirizzo < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'mk': 'Тимот LyS-FASTPARSE го претставува BIST-COVINGTON, нервна имплементација на алгоритмот Ковингтон (2001) за непроективно анализирање зависност. Дивирективниот пристап на ЛСТМ од Kiperwasser и Goldberg (2016) се користи за обука на алчен анализатор со динамичен оракл за олеснување на пропагацијата на грешките. Моделот учествуваше во Соделената задача на УД CoNLL 2017. И покрај тоа што не се користат никакви методи на ансембл и со користење на основната сегментација и поS означувањето, анализаторот доби добри резултати на макро-просечниот ЛАС и УАС во категоријата на големите дрвени банки (55 јазици), рангирајќи се на седмиот од 33 тимови. Во категоријата на сите дрвја (ЛАС и УАС) се рангиравме на 16 и 12. Разнината помеѓу сите и големите категории е главно поради лошите резултати на четирите паралелни PUD дрвени ленти, што сугерира дека некои „ суфиксни “ дрвени ленти (np. шпанско-анкора) лошо резултираат со поставувањата на крстосто дрвени ленти, што не се случува со соодветната „ несуфиксна “ дрвена лента (np. шпанско Со промената на тоа, го добиваме 11-тиот најдобар ЛАС меѓу сите трки (официјален и неофицијален). The code is made available at < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'kk': "LyS- FASTPARSE тобы BIST- COVINGTON, проективті емес тәуелдік талдау үшін Covington (2001) алгоритмінің невралдық іске асыру алгоритмі болады. Кипервассер және Голдберг (2016) қатені көшірмелеу үшін динамикалық оракулы бақылау үшін қолданылады. Бұл үлгі CoNLL 2017 UD ортақ тапсырмасына қатысу үшін. Ештеңе ензембл әдістерін пайдалануға және негізгі жол сегментациясын және PoS тегтерін пайдалануға арналмағанда, талдаушы макро орташа LAS және UAS макро орташа нәтижелерін 33 топтардан 7-ші ретінде алды. Барлық құрылғылар санатында (LAS және UAS) 16-ші және 12-ші ретінде болдық. Барлық санаттар мен үлкен санаттар арасындағы аралығы төрт параллелі PUD құрылғының шектерінің шектерінің шектері себебі болады. Кейбір `suffixed' құрылғылар (мысалы, Испан- Анкора) құрылғы шектерінің параметрлерінде жарамсыз орындалады. Бұл `uffixed' құрылғының (мысалы, испа Бұны өзгертіп, барлық орындар арасындағы 11-ші ең жақсы LAS-ді (официалдық және официалдық) аламыз. Код <дегенде қол жеткізілді https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'lt': "LyS-FASTPARSE komanda pristato BIST-COVINGTON, Covington (2001) algoritmo neuralinį įgyvendinimą nenusprojektyviam priklausomybės analizavimui. Kiperwasser ir Goldberg dvikryptis LSTM metodas (2016 m.) naudojamas ahnus analizatorius su dinaminiu orakuliu klaidų plitimui mažinti. Modelis dalyvavo CoNLL 2017 m. bendroje UD užduotyje. In spite of not using any ensemble methods and using the baseline segmentation and PoS tagging, the parser obtained good results on both macro-average LAS and UAS in the big treebanks category (55 languages), ranking 7th out of 33 teams.  Visose medžių bankų kategorijose (LAS ir UAS) mes klasifikuojame 16-ąjį ir 12-ąjį. The gap between the all and big categories is mainly due to the poor performance on four parallel PUD treebanks, suggesting that some `suffixed' treebanks (e.g. Spanish-AnCora) perform poorly on cross-treebank settings, which does not occur with the corresponding `unsuffixed' treebank (e.g. Spanish).  Pakeisdami tai, mes gauname 11-ąją geriausią LAS iš visų runs (oficialiai ir neoficialiai). Kodas pateikiamas < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'ml': "ലൈസ്-ഫാസ്റ്റ്പാര്\u200dസ് ടീം ബിസ്റ്റ്-കോവിന്\u200dഗ്ടോണിനെ കാണിക്കുന്നു. കോവിങ്ടണ്\u200d (2001) ആല്\u200dഗോരിത്മിന്റെ പ്രൊജക്ടീവ് ആശ്രയിച്ച പാര്\u200d കിപ്പെര്\u200dവാസെരും ഗോള്\u200dഡ്ബെര്\u200dഗിന്റെയും കീപ്പര്\u200dവ്വസേരിന്റെയും പ്രോഗ്രാജിക്കുന്നതിനായി ഒരു ലാഗ്രി പാര്\u200dസറിനെ പരിശീലിപ്പി മോഡല്\u200d കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കുചേര്\u200dത്ത ടാസ്കില്\u200d പങ്കുചേര്\u200dന്നു. ബെസ്ലൈന്\u200d സെഗ്മെന്റേഷനും പോസ് ടാഗ്ഗിങ്ങും ഉപയോഗിക്കുന്നതിന് ശേഷം മാക്രോയില്\u200d സാധാരണ ലാസിലും ഉയാസിലും നല്ല ഫലങ്ങള്\u200d ലഭിച്ചിരുന്നു. (55 ഭാഷകളില്\u200d), 33 ടീമില്\u200d നിന എല്ലാ ത്രീബാങ്കുകളുടെയും വിഭാഗങ്ങളിലും ഞങ്ങള്\u200d 16-12-ല്\u200d റെഞ്ച് ചെയ്തു. എല്ലാവര്\u200dക്കും വലിയ വിഭാഗങ്ങള്\u200dക്കുമിടയിലുള്ള വ്യത്യാസം പ്രധാനപൂര്\u200dണ്ണമായ പിയുഡി ട്രീബാങ്കുകളില്\u200d പാവപ്പെട്ട പ്രവര്\u200dത്തനങ്ങള്\u200dക്ക് കാരണമാണ്. ചില `വെച്ചിരിക്കുന്നു' ട്രീബാങ്കുകള്\u200d (ഉദാ. സ്പാനിഷ് ആന അത് മാറ്റുന്നതിനാല്\u200d, എല്ലാ ഓട്ടക്കാരിലും 11ആം മികച്ച ലാസ്സ് നമുക്ക് ലഭിക്കാം. <ലില്\u200d കോഡ് ലഭ്യമാക്കിയിരിക്കുന്നു https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'ms': "Pasukan LyS-FASTPARSE hadir BIST-COVINGTON, pelaksanaan saraf algoritma Covington (2001) untuk penghuraian dependensi bukan projektif. pendekatan LSTM bidireksi oleh Kiperwasser dan Goldberg (2016) digunakan untuk melatih penghurai serakah dengan orakul dinamik untuk mengurangi penyebaran ralat. Model ini berpartisipasi dalam Tugas Berkongsi UD CoNLL 2017. Walaupun tidak menggunakan sebarang kaedah ensemble dan menggunakan segmentasi dasar dan tag PoS, penghurai mendapat keputusan yang baik pada kedua-dua LAS makro-rata-rata dan UAS dalam kategori pangkat pokok besar (55 bahasa), ranking ke-7 daripada 33 pasukan. Dalam semua kategori pangkalan pokok (LAS dan UAS) kami berturut-turut ke-16 dan ke-12. Lubang diantara semua kategori dan kategori besar adalah terutama disebabkan prestasi buruk pada empat batang pokok PUD selari, menyarankan bahawa sebahagian batang pokok `cukuplah' (cth. Spanish-AnCora) berjalan buruk pada tetapan batang pokok salib, yang tidak berlaku dengan batang pokok `tidak cukuplah' yang sepadan (cth. Spanish). By changing that, we obtain the 11th best LAS among all runs (official and unofficial).  Kod tersedia pada < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'mn': "LyS-FASTPARSE баг нь BIST-COVINGTON-г, 2001 оны Covington-ын мэдрэлийн хэрэглээний алгоритм юм. Кипервассер болон Голдберг (2016) улсын хоёр дахь LSTM арга зам нь алдаа хөгжлийг багасгахын тулд хөдөлгөөнтэй багш хөгжүүлэхэд хэрэглэгддэг. Энэ загвар 2017 оны CoNLL-ын UD хуваалтын ажил дээр оролцсон. Ямар ч арга загвар ашиглахгүй ч, үндсэн шугам болон PoS тэгжээлтийг ашиглахгүй ч, хуваарьчид макро дундаж LAS болон UAS хоёулаа том загварын хэлбэрээс (55 хэл), 33 багийн 7-т сайн үр дүнг авсан. Бид 16, 12-р ангид байлаа. Бүх болон том хэлбэрийн хоорондын ялгаа нь ихэвчлэн 4 параллел PUD дагуу дээрх ядуу үйл ажиллагааны шалтгаан юм. Зарим хэлбэрүүд нь `suffixed' дагуу (жишээ нь Испан-Анкора) дагуу дагуу дагуу дээр зөвхөн гүйцэтгэх боломжгүй байдаг. Үүнийг өөрчлөхөд бид бүх ажиллагааны 11-р сайн ЛАС авдаг. Энэ код < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'mt': 'It-tim Lys-FASTPARSE jippreżenta BIST-COVINGTON, implimentazzjoni newrali tal-algoritmu Covington (2001) għall-analiżi tad-dipendenza mhux proġettiva. L-approċċ bidirezzjonali tal-LSTM minn Kiperwasser u Goldberg (2016) jintuża biex jitħarreġ analizzatur greedy b’oracle dinamiku biex itaffi l-propagazzjoni tal-iżbalji. Il-mudell ipparteċipa fil-ħidma kondiviża tal-UD CoNLL 2017. Minkejja li ma użat l-ebda metodu ta’ ensemble u bl-użu tas-segmentazzjoni tal-linja bażi u t-tikkettar PoS, il-analizzatur kiseb riżultati tajbin kemm fuq l-LAS makro-medja kif ukoll fuq l-UAS fil-kategorija tal-banek tas-siġar il-kbar (55 lingwa), li kklassifikaw is-seba’ minn 33 tim. Fil-kategorija kollha tal-banek tas-siġar (LAS u UAS) ikklassifikajna s-16 u t-12. Id-differenza bejn il-kategoriji kollha u l-kategoriji l-kbar hija prinċipalment dovuta g ħall-prestazzjoni ħażina fuq erba’ banek tas-siġar tal-PUD paralleli, li tissuġġerixxi li xi banek tas-siġar “suffissi” (e ż. Spanjol-AnCora) jaħdmu ħażin fuq setturi tal-banek tas-siġar trasversali, li ma jseħħx mal-banek tas-siġar “mhux suffissi” korrispondenti (eż. Spanjol). Billi nbidlu dan, inkisbu l-11-il LAS l-aħjar fost il-linji kollha (uffiċjali u mhux uffiċjali). Il-kodiċi huwa disponibbli fuq < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'ro': 'Echipa LyS-FASTPARSE prezintă BIST-COVINGTON, o implementare neurală a algoritmului Covington (2001) pentru analizarea dependenței non-proiective. Abordarea bidirecțională LSTM realizată de Kiperwasser și Goldberg (2016) este folosită pentru a instrui un parser lacom cu un oracol dinamic pentru a atenua propagarea erorilor. Modelul a participat la CoNLL 2017 UD Shared Task. În ciuda faptului că nu a folosit nicio metodă de ansamblu și a utilizat segmentarea de bază și etichetarea PoS, parserul a obținut rezultate bune atât pe LAS macro-medii, cât și pe UAS în categoria Big Treebanks (55 limbi), clasându-se pe locul 7 din 33 de echipe. În categoria tuturor braebanks (LAS și UAS) am ocupat locurile 16 și 12. Diferența dintre toate categoriile și cele mari se datorează în principal performanțelor slabe pe patru brațe paralele PUD, sugerând că unele brațe "sufixe" (de exemplu Spanish-AnCora) performează slab pe setările cross-braebank, ceea ce nu apare cu brațul corespunzător "neaffixat" (de exemplu spaniolă). Prin schimbarea acestui lucru, obținem al 11-lea cel mai bun LAS dintre toate cursele (oficiale și neoficiale). Codul este disponibil la < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'pl': 'Zespół LyS-FASTPARSE prezentuje BIST-COVINGTON, neuronową implementację algorytmu Covington (2001) do analizy zależności nieprojekcyjnej. Dwukierunkowe podejście LSTM firmy Kiperwasser i Goldberg (2016) jest wykorzystywane do szkolenia chciwego parsera z dynamiczną wyrocznią w celu złagodzenia propagacji błędów. Model uczestniczył w udziale CoNLL 2017 UD Shared Task. Pomimo braku żadnych metod zespołowych oraz wykorzystania segmentacji bazowej i tagowania PoS, parser uzyskał dobre wyniki zarówno dla makro-średniej LAS, jak i UAS w kategorii dużych banków drzew (55 języków), miejsca siódmego z 33 drużyn. W kategorii wszystkie banki drzew (LAS i UAS) zaliczyliśmy szesnastą i dwunastą rangę. Różnica między wszystkimi i dużymi kategoriami jest głównie spowodowana słabą wydajnością na czterech równoległych bankach drzew PUD, co sugeruje, że niektóre banki drzew "przyrostkowych" (np. Spanish-AnCora) działają źle w ustawieniach cross-bank drzew, co nie występuje w przypadku odpowiedniego "niesforyfikowanego" banku drzew (np. hiszpańskiego). Zmieniając to, uzyskujemy jedenasty najlepszy LAS spośród wszystkich biegów (oficjalnych i nieoficjalnych). Kod jest udostępniony pod adresem < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'no': 'LyS-FASTPARSE-gruppa gjev BIST-COVINGTON, ein neuralimplementering av Covington-algoritmen (2001) for tolking av ikkje-projektiv avhengighet. Den bidireksjonale LSTM-tilnærminga av Kiperwasser og Goldberg (2016) vert brukt for å trena ein grødig tolkar med ein dynamisk orakul for å minne feilpropagasjon. Modellen delta i CoNLL 2017 UD- delt oppgåve. Til tross å ikkje bruka nokon ensemblemmetode og bruka baselinjestegninga og PoS-merkinga, tolkaren fikk gode resultat på både makro-gjennomsnittlige LAS og UAS i den store treebankkategorien (55 språk), rankinga 7. av 33 grupper. I alle treebankkategoriane (LAS og UAS) rangerte vi 16. og 12. Avstanden mellom all e og store kategoriane er hovudsakelig på grunn av dei dårlige utføringane på fire parallelle PUD-treebanktar, som tyder på at nokre « suffiks »-treebanktar (f.eks. spansk-AnCora) utfører ugyldig på kryss-treebank-innstillingar, som ikkje skjer med den tilsvarande « uffiks »-treebanka (f.eks. spansk). Ved å endra det, får vi den 11. beste LAS blant alle køyrer (offisielle og ufficiell). Koden er tilgjengeleg på < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'si': "The LyS-FASTPARSE group presents BIST-COVINGTON, a neural reuse of the Covingston (2001) algolorithm for non-forecast Dependency Parsing. කිපර්වාසෙර් සහ ගෝල්ඩ්බර්ගය (2016) වලින් දැනගත්තු LSTM ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරන්න භාවිත වෙනවා කියලා සාමාන්\u200dය විශාලක මොඩල් එක CoNLL 2017 UD කොටස් එක්ක සමාගත්තා. ප්\u200dරමාණය සහ පොස් ටැගින් භාවිතා කරන්න බැරි විධානයක් නොප්\u200dරයෝජනය කරලා තියෙනවා නමුත් ප්\u200dරමාණයෙන් හොඳ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරත සියළුම ට්\u200dරීබෑන්ක් වර්ගයේදී (LAS සහ UAS) අපි 16 වර්ගයෙන් 12 වර්ගයෙන්. සියලුම හා ලොකු වර්ගයක් අතර ඉන්න විශාලයක් විතරයි ප්\u200dරමාණය PUD ට්\u200dරීබැන්ක් හතරක් වලින් අනතුරු ක්\u200dරියාත්මක විදියට, ප්\u200dරශ්ණය කරනවා කියලා `sufFixed' ට්\u200dරීබැන්ක් වලින් සැකසුම් වලින ඒක වෙනස් කරනවා, අපි හැම දුර්වල් එක්ක 11වෙනි හොඳම LAS ගන්නවා. කෝඩ් ප්\u200dරවේශයක් තියෙන්නේ <at> https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'sr': 'LyS-FASTPARSE tim predstavlja BIST-COVINGTON, neuralnu implementaciju algoritma Kovingtona (2001) za analizu neprojektivne zavisnosti. Bidirektivni pristup LSTM od Kiperwasser a i Goldberga (2016) koristi se za treniranje pohlepnog analizatora sa dinamičnim orakulom za smanjenje propagacije grešaka. Model je sudjelovao u zajedničkom zadatku CoNLL 2017. Uprkos ne koristiti nikakve metode ensemble i koristeći osnovnu segmentaciju i označavanje PoS-a, analizator je dobio dobre rezultate na makro-prosječnom LAS i UAS-u u velikoj kategoriji trgovine (55 jezika), u redovima 7. iz 33 timova. U svim kategorijama kretanja (LAS i UAS) postali smo 16. i 12. reda. Praznina između svih i velikih kategorija je uglavnom zbog loše g izvođenja na četiri paralelne PUD treebancije, ukazujući na to da neki "suffikovani" treebanci (npr. španjolski-Ankora) loše izvršavaju na postavkama preko treebancija, koji se ne događa sa odgovarajućim "neobičnim" treebancima (npr. španjolski). Promenivši to, dobijemo 11. najbolji LAS među svim trkama (zvanični i neoficijalni). Kod je dostupan na < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE - Да.', 'ta': "LyS- FASTPARSE குழு பிஸ்ட்- COVINGTON காண்பிக்கும், காவிங்டன் (2001) அல்குறிப்பு சார்ந்த சார்பு பாடலுக்கான ஒரு புதிய முறைமையான செயல்படுத்தல Name The model participated in the CoNLL 2017 UD Shared Task. எந்த ஒளி முறைகளையும் பயன்படுத்தாமலும் போஸ் துண்டு மற்றும் அடிப்படையின் துண்டு மற்றும் பயன்படுத்தாமலும் இருந்தாலும், பெரிய மரப்பாங்க் வகையில் இருந்து மேக்ரோ சராசரி LA அனைத்து மூன்று பாங்க் வகையில் (LAS மற்றும் UAS) நாம் 16வதும் 12வதும் வரிசைப்பட்டோம். அனைத்து பெரிய வகுப்புகளுக்கும் இடையேயுள்ள வேறுபாடு முக்கியமாக 4 இணைப்பு PUD ட்ரீபாங்க்களில் ஏழை செயல்படுத்தல் காரணமாகும், சில 'பிடிக்கப்பட்ட' treebanks (உதாரணமாக ஸ்பானிஷ்- அன்கோரா) குறியீட்டு மூல அமைப்பு அதை மாற்றினால், நாம் எல்லா இயக்கிகளிலும் 11வது சிறந்த LAS பெற்றுக் கொள்கிறோம் (அதிகாரியம் மற்றும் அரச <லில் குறியீடு கிடைக்கப்பட்டது https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'ur': "The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation of the Covington (2001) algorithm for non-projective dependency parsing. Kiperwasser اور Goldberg (2016) کے ذریعہ دوسری الٹی ٹی سی ٹی مٹی کی طریقہ کا استعمال کیا جاتا ہے کہ خطا پھیلانے کے لئے سیدھی غلطی کے ساتھ ایک سیدھی غلطی پھیلانے کے لئے ایک سیدھی غلطی پارچر کی موڈل CoNLL 2017 کے UD شریک ٹاکس میں شریک ہوا۔ اگرچہ کسی ایسمبل طریقے کا استعمال نہ کرنا اور بنیاس لین سکیٹمنٹ اور پوس ٹاگنگ کا استعمال نہ کرنا، پارچر نے مکروسیل لاس اور UAS دونوں میں بہترین نتیجے حاصل کئے ہیں بڑے ٹریب بانک کاٹی (55 زبان) میں، پارچر 33 ٹیموں میں سے 7م رینگ. ہم 16 اور 12 درجے ہیں تمام اور بڑے کائٹیوں کے درمیان تفاوت صرف چار parallel PUD ٹریب بانک پر کمزور عمل کی وجہ سے ہے، یہ بات کرتا ہے کہ بعض 'suffixed' ٹریب بانک (جیسے اسپانیایی-انکورا) کرس-ٹریب بانک سیٹیوں پر کمزور عمل کرتے ہیں، جو مطابق 'unsuffixed' ٹریب بانک (جیسے اسپانیایی) کے ساتھ نہیں ہوتی۔ اس کے بدلنے کے ذریعہ ہم سب سے 11 بہترین LAS حاصل کرتے ہیں۔ <پر کوڈ موجود ہے https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'so': 'Kooxda LyS-FASTPARSE ee soo saara BIST-COVINGTON, kooxda neural implementation of the Covington (2001) algorithm for non-projective dependency parsing. Dhaqdhaqaaqa LSTM ee ku qoran Kiperwasser iyo Goldberg (2016) waxaa loo isticmaalaa inaad ku tababarido barbaarinta greedy Parser with a dynamic oral in uu koobo ogeysiiska qaladka. Tusaale ahaan ayaa ka qeybqaaday Shaqada loo qaybsaday CoNLL 2017 UD. Inkastoo aan isticmaalin habbooyinka iyo isticmaalka kooxaha kooxaha hoose ee kooxaha iyo PoS tagging, Parser wuxuu helay resulto wanaagsan oo ku saabsan macro-average LAS iyo UAS labadooda kooxaha waaweyn ee treebank (55 luqadood), oo kooxda 33 ka mid ah 7aad. In the all treebanks category (LAS and UAS) we ranked 16th and 12th.  Dhammaan iyo kooxo waaweyn waxaa ugu horeyn kara fasax miskiin ah oo ku saabsan afar meelood oo isku mid ah PUD treebank (tusaale ahaan Isbanish-AnCora) oo aan ku sameyn dareemaha saddexebank (tusaale ahaan Isbanish). Marka aan taas beddelno, waxaynu helaynaa wadamada 11aad ee ugu fiican ee LAS (rasmi iyo rasmi ah). Kaarka waxaa laga helaa < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'sv': 'LyS-FASTPARSE-teamet presenterar BIST-COVINGTON, en neural implementering av Covington (2001) algoritmen för icke-projektiv beroendetolkning. Den tvåriktade LSTM metoden av Kiperwasser och Goldberg (2016) används för att träna en girig parser med ett dynamiskt orakel för att mildra felspridning. Modellen deltog i CoNLL 2017 UD Shared Task. Trots att parsern inte använde några ensemblemetoder och använde baslinjesegmentering och PoS-märkning, fick tolkaren bra resultat på både makro-genomsnittlig LAS och UAS i kategorin stora trädbanker (55 språk), rankad 7:e av 33 lag. I kategorin alla trädbackar (LAS och UAS) rankades vi 16:e och 12:e. Skillnaden mellan alla och de stora kategorierna beror främst på den dåliga prestandan på fyra parallella PUD-trädbackar, vilket tyder på att vissa "sufficerade" trädbackar (t.ex. Spanish-AnCora) presterar dåligt på cross-treebank inställningar, vilket inte förekommer med motsvarande "oficerade" trädbackar (t.ex. spanska). Genom att ändra detta får vi den 11:e bästa LAS bland alla löpningar (officiella och inofficiella). Koden finns tillgänglig på < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'uz': 'Name Name Name Umumiy usullar ishlatilmasa va asosiy bogʻlash va PoS tagining asosiy yordamida, parameter 33 guruhdan 7 dan birinchi darajadagi makro- darajadagi LAS va UASda yaxshi natijalar olingan. Barcha treebank turi (LAS va UAS) davomida biz 16- chi va 12- chi ta\'limni boshladik. Hamma va katta guruhlar orasidagi gap asosiy to\'rt parallel PUD treebanklarda juda ham bajarish sababchi boʻladi. Masalan "qoʻllanmagan" treebanklar (m. g. Spanish-Ankora) oʻzgaruvchining moslamalarida juda yoqish mumkin. Buni o\'zgartirish orqali biz hamma vazifalarning 11 chi eng eng yaxshi LAS bajaramiz. Kodlash mavjud emas <da https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'vi': 'Đội LyS-FASTParis có mặt tại giải mã BINT-COVIGTON, một thuật toán Kết hợp cho phân tích phụ thuộc không dự bị. The bidtrực al LSTM approach by Kiperwasser and Goldberg (thẩm 66) is used to teaching a tham lam parter with a dynamic orals to premấy lỗi propagation. Mô hình này đã tham gia vào Nhiệm vụ chia sẻ CoNLIll Buổi diễn tập. Mặc dù không sử dụng các phương pháp dàn hợp, và sử dụng các phân tách cơ bản và nhãn Pog, kẻ phân tích tích tích tích tích tích tích tích tích tích tích tích tích tích tích tích tích tích giỏi, hắn đã đạt được kết quả tốt cả về LAS siêu lục và UAS trong hạng tam giác lớn (55. Trong các hạng giá ba bóng khác (LAS và UAS) chúng tôi xếp hạng hai. Khoảng cách giữa tất cả các loại và hạng lớn chủ yếu là do hiệu suất kém trên bốn cây giá ba song song, cho thấy một số giá ba dính đầy đủ (v.d. Spanish-AnCora) thực hiện không tốt trên thiết lập Thập tự do, mà không xảy ra với giá ba bóng tương ứng « không chịu được phục hồi » (v. d. Spanish). Thay đổi điều đó, chúng tôi nhận được 11th best LAS trong mọi lần (chính thức và không chính thức). Đoạn mã đã được làm sẵn ở https://github.com/CoNLL-UD-2017/LyS-FASTPARSE Language', 'hr': 'LyS-FASTPARSE tim predstavlja BIST-COVINGTON, neuralnu provedbu algoritma Kovingtona (2001) za analizu neoprojektivne zavisnosti. Bidirektivni pristup LSTM-a Kiperwasser i Goldberg (2016) koristi se za treniranje pohlepnog analizatora s dinamičnim orakulom za smanjenje propagacije greška. Model je sudjelovao u zajedničkom zadatku CoNLL 2017. Unatoč ne koristeći nikakve metode ensemble i koristeći početnu segmentaciju i označavanje PoS-a, analizator je dobio dobre rezultate na makro-prosječnom LAS-u i UAS-u u velikoj kategoriji trgovine (55 jezika), u redovima 7. iz 33 timova. U svim kategorijama kretanja (LAS i UAS) postali smo 16. i 12. reda. Praznina između svih i velikih kategorija je uglavnom zbog loše g učinka na četiri paralelne PUD-ove tržnice, što ukazuje na to da neki "suffikovani" tržnici (npr. španjolski-AnCora) loše izvršavaju na postavkama preko treebana, koji se ne događa s odgovarajućim "neobičnim" tržnim tržnicama (npr. španjolski). Promjenom toga, dobijemo 11. najbolji LAS među svim trkama (zvanični i neoficijalni). Kod je dostupan na < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'bg': "Екипът на LyS-FASTPARSE представя BIST-COVINGTON, невронно изпълнение на алгоритъма на Ковингтън (2001) за непроективно анализиране на зависимостта. Двупосочният подход на Кипервасер и Голдбърг (2016) се използва за обучение на алчен анализатор с динамичен оракул за смекчаване на разпространението на грешки. Моделът участва в споделената задача на СД 2017. Въпреки че не използва никакви ансамбълни методи и използва базовата сегментация и маркирането, анализаторът постигна добри резултати както при макросреднените ЛАС, така и на UAS в категорията големи дървета (55 езика), класирайки се на 7-о място от 33 отбора. В категорията всички дървета (ЛАС и УАС) се класирахме на 16-то и 12-то място. Разликата между всички и големите категории се дължи главно на лошото представяне на четири паралелни дървесни ленти, което предполага, че някои `sufixed' дървесни ленти (напр. Испански-АнКора) се представят слабо при настройките на кръстосаните дървесни ленти, което не се случва със съответната `непотвърдена' дървесна лента (напр. Испански). Променяйки това, получаваме 11-то най-добро LAS от всички серии (официални и неофициални). Кодът е достъпен на адрес < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'nl': "Het LyS-FASTPARSE team presenteert BIST-COVINGTON, een neurale implementatie van het Covington (2001) algoritme voor niet-projectieve afhankelijkheidsparsing. De bidirectionele LSTM benadering van Kiperwasser en Goldberg (2016) wordt gebruikt om een hebberige parser met een dynamisch orakel te trainen om foutpropagatie te beperken. Het model nam deel aan de CoNLL 2017 UD Shared Task. Ondanks het gebruik van geen ensemble methodes en het gebruik van de baseline segmentatie en PoS tagging, behaalde de parser goede resultaten op zowel macro-gemiddelde LAS als UAS in de grote boombanken categorie (55 talen), waarbij de 7e van 33 teams werd geplaatst. In de categorie boombanken (LAS en UAS) zijn we 16e en 12e gerangschikt. De kloof tussen de alle en grote categorieën is voornamelijk te wijten aan de slechte prestaties op vier parallelle PUD boombanken, wat suggereert dat sommige 'achtervoegsel' boombanken (bijv. Spanish-AnCora) slecht presteren op cross-boombank instellingen, wat niet voorkomt bij de overeenkomstige 'niet-bevestigde' boombank (bijv. Spaans). Door dat te veranderen, krijgen we de 11e beste LAS van alle runs (officieel en onofficieel). De code is beschikbaar op < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'da': "LyS-FASTPARSE holdet præsenterer BIST-COVINGTON, en neural implementering af Covington (2001) algoritmen til ikke-projektiv afhængighedsanalyse. Den bidirektionelle LSTM tilgang af Kiperwasser og Goldberg (2016) bruges til at træne en grådig fortolker med et dynamisk orakel til at afbøde fejludbredelse. Modellen deltog i CoNLL 2017 UD Shared Task. På trods af ikke at bruge nogen ensemble metoder og bruge baseline segmentering og PoS tagging, opnåede parseren gode resultater på både makro-gennemsnitlig LAS og UAS i kategorien store treebanks (55 sprog), placeret 7. ud af 33 hold. I kategorien alle treebanks (LAS og UAS) rangerede vi 16. og 12. plads. Forskellen mellem alle og store kategorier skyldes hovedsagelig den dårlige præstation på fire parallelle PUD-træbanker, hvilket tyder på, at nogle 'sufficerede' træbanker (f.eks. spansk-anCora) præsterer dårligt på tværs af træbanker indstillinger, hvilket ikke forekommer med den tilsvarende 'uformede' træbank (f.eks. spansk). Ved at ændre det får vi den 11. bedste LAS blandt alle løb (officiel og uofficiel). Koden er tilgængelig på < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'de': 'Das LyS-FASTPARSE Team stellt BIST-COVINGTON vor, eine neuronale Implementierung des Covington (2001)-Algorithmus für nicht-projektive Abhängigkeitsparsing. Der bidirektionale LSTM-Ansatz von Kiperwasser und Goldberg (2016) wird verwendet, um einen gierigen Parser mit einem dynamischen Orakel zu trainieren, um die Fehlerausbreitung zu mindern. Das Modell nahm an der CoNLL 2017 UD Shared Task teil. Trotz des Verzichts auf Ensemble-Methoden und der Verwendung der Baseline-Segmentierung und PoS-Tagging erzielte der Parser gute Ergebnisse sowohl auf makro-durchschnittlichen LAS als auch auf UAS in der Kategorie Big Treebanks (55-Sprachen) und rangierte sieben von 33-Teams. In der Kategorie "Alle Baumbänke" (LAS und UAS) belegten wir den 16.und 12.Platz. Die Lücke zwischen allen und großen Kategorien ist hauptsächlich auf die schlechte Leistung an vier parallelen PUD-Baumbänken zurückzuführen, was darauf hindeutet, dass einige `suffixierte\' Baumbänke (z. Indem wir das ändern, erhalten wir den elften besten LAS unter allen Läufen (offiziell und inoffiziell). Der Code ist verfügbar unter < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'id': "Tim LyS-FASTPARSE mempersembahkan BIST-COVINGTON, implementasi saraf algoritma Covington (2001) untuk penganalisan dependensi bukan proyektif. pendekatan LSTM bidireksi oleh Kiperwasser dan Goldberg (2016) digunakan untuk melatih parser serakah dengan orakul dinamik untuk mengurangi penyebaran kesalahan. Model ini berpartisipasi di CoNLL 2017 UD Shared Task. Meskipun tidak menggunakan metode ensemble apapun dan menggunakan segmentasi dasar dan tagging PoS, parser mendapat hasil yang baik pada kedua makro-rata LAS dan UAS dalam kategori pokok besar (55 bahasa), ranking ke-7 dari 33 tim. In the all treebanks category (LAS and UAS) we ranked 16th and 12th.  Lubang antara semua dan kategori besar adalah karena prestasi buruk pada empat batang pohon PUD paralel, menyarankan bahwa beberapa batang pohon `cukup' (misalnya Spanyol-AnCora) berfungsi buruk pada pengaturan batang pohon salib, yang tidak terjadi dengan batang pohon `tidak cukup' (misalnya Spanyol). Dengan mengubah itu, kami mendapatkan LAS yang terbaik ke-11 di antara semua runs (resmi dan tidak resmi). Kode tersedia di < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'fa': 'تیم LyS-FASTPARSE BIST-COVINGTON را به عنوان بررسی بستگی غیر پروژه\u200cدهنده آلگوریتم Covington (۲۰۰۱) اجرا می\u200cکند. دستور دوباره LSTM توسط Kiperwasser و Goldberg (۲۰۱۶) برای آموزش یک بازیگر آرامشی با یک واژه داینامیک برای تنگ کردن گلوله استفاده می\u200cشود. Model participated in the CoNLL 2017 UD Shared Task. با وجود استفاده از هیچ روش\u200cهای ابزار و استفاده از برچسب\u200cهای پایین\u200cخط و برچسب\u200cهای PoS، بازیگر نتیجه\u200cهای خوب بر هر دو LAS متوسط و UAS در برچسب\u200cهای بزرگ (55 زبان) درجه\u200cی 7م از 33 تیم یافت. در تمام مجموعه\u200cهای درخت\u200cها (LAS و UAS) ما ۱۶م و ۱۲م درجه\u200cای داشتیم. فاصله بین همه\u200cی گروه\u200cهای بزرگ و بزرگ در اصل به خاطر عملکرد فقیر روی چهار قطب\u200cهای درخت\u200cهای PUD parallel است که پیشنهاد می\u200cدهد که بعضی قطب\u200cهای درخت\u200cهای «suffixed» (مثلا اسپانیایی-انکورا) در تنظیم\u200cهای درخت\u200cهای درخت\u200cهای بد انجام می\u200cدهند، که با قطب\u200cهای «unsuffixed» (مثلاً اسپانیایی\u200c). با تغییر دادن آن، ما ۱۱م بهترین LAS را در میان همه فرار می گیریم (رسمی و غیر رسمی). کد در < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'af': "Die Lys-FASTPARSE-span wat BIST-COVINGTON voorsien is, 'n neurale implementasie van die Covington (2001) algoritme vir nie-projektiewe afhanklikheid verwerking. Die bidireksjonale LSTM toegang deur Kiperwasser en Goldberg (2016) word gebruik om 'n groet ontvanger te trein met 'n dinamiese orakel om fout propagasie te verminder. Die model het gedeel in die CoNLL 2017 UD deelde taak. Selfs nie gebruik enige ensemble metodes en gebruik die basisline segmentasie en PoS merking, het die ontwerker goeie resultate ontvang op beide makro- gemiddelde LAS en UAS in die groot treebankkategorie (55 tale), ranking 7de uit 33 teams. In die alle treebankkategorie (LAS en UAS) het ons 16de en 12de rangeer. Die afstand tussen die all e en groot kategorie is hoofsaaklik gevolg van die arme prestasie op vier parallele PUD treebanks, wat voorstel dat sommige 'suffiks' treebanks (bv. Spaanse-AnCora) sleg uitvoer op kruistreebank instellings, wat nie voorkom met die ooreenstemmende 'unsuffiks' treebank (bv. Spaanse). Deur dit te verander, kry ons die 11de beste LAS onder alle loop (offisieel en onoffisieel). Die kode is beskikbaar by < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'tr': 'LyS-FASTPARSE topary BIST-COVINGTON, projektiv ýok baglançylyk analysi üçin bir nuýral implementasiýasy Kiperwasser we Goldberg (2016) tarapyndan ikinji görnöşikli LSTM golaýy ýerleşdirilýär. Hata döwletlenmesini azaltmak üçin ýüregeli paýlaşçy bilen dinamik arzançy bilen ulanylýar. Bu nusga CoNLL 2017-nji ýylda UD Paýlaşan Görevde goşuldy. Hiç bir ensemble yöntemi ulanmaýan we baseline segmentasiýasyny we PoS etiketlemegini ullanyrmaýan ýöne, oýlanan uly çöplükler kategoriýasynda hem makro ortalama LAS we UAS üçin gowy netijeler aldy (55 diller), 33 topardan 7-nji dereje aldy. Hemme agaç sanlarynda (LAS we UAS) 16-nji we 12-nji dereje diýipdir. Bütin we uly kategoriýalaryň arasynyň gapysy dört parallel PUD çubuklarynyň garşy çubuklarynda garşy çubuklaryň sebäbi. Käbir \'suffik\' çubuklaryň (meselâ, Ispanýol-AnCora) çarpak çubuklaryň üstünde erbet çubuklary ýerine ýetirmekde täsir edýär. Bu \'uffik\' çubuklaryň (meselâ, ispanyol). Muny üýtgetmek bilen, ähli ýerlerde 11-nji iň gowy LAS gazanýarys (resmi we unofficial). "%s" faýly ewirilip başarmady çünki ol beter ullakan. https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'sw': 'Timu ya LyS-FASTPARSE inawasilisha BIST-COVINGTON, utekelezaji wa kidini wa algorithi ya Covington (2001) kwa ajili ya uchimbaji usio na mradi. Mtandao wa LSTM ulioandaliwa na Kiperwasser na Goldberg (2016) unatumiwa kufundisha mchambuzi wa uchunguzi wenye maneno ya kisasa ili kupunguza propaganda za makosa. Modeli ilishiriki katika kazi ya CoNLL 2017 UD ilishiriki. Pamoja na kutotumia mbinu yoyote za vifaa na kutumia viungo vya msingi na viungo vya PoS, chama cha uchambuzi alipata matokeo mazuri kwenye kiwango cha wastani cha LAS na UAS katika makundi makubwa ya mitaani (lugha 55), yenye rangi ya 7 kati ya timu 33. Katika makundi yote ya mitatu (LAS na UAS) tulipata rangi ya 16 na 12. Kutofautiana kati ya makundi yote na makubwa, hasa ni kwa sababu ya utendaji masikini kwenye mitandao minne mbalimbali ya PUD, ikipendekeza kuwa baadhi ya mabango ya mitatu (kwa mfano wa Kihispania-AnCora) yanafanya vibaya kwenye vituo vya mitaani vya mitaani, ambavyo havijatokea kwa kile kinachofanana na “treebank” ambacho hayajapatikana bila mafanikio (kwa mfano, Kihispania). Kwa kubadilisha hilo, tunapata LAS ya 11 bora miongoni mwa mashindano yote (rasmi na rasmi). Utawala unapatikana kwenye < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'sq': "Ekipi Lys-FASTPARSE prezanton BIST-COVINGTON, një zbatim nervor i algoritmit Covington (2001) për analizimin e varësisë jo-projektive. Metoda dy-drejtore LSTM nga Kiperwasser dhe Goldberg (2016) përdoret për të trajnuar një analizues lakmues me një orakul dinamik për të lehtësuar përhapjen e gabimeve. Modeli mori pjesë në detyrën e përbashkët të CoNLL 2017 UD. Megjithë mos përdorimin e asnjë metode të ansamblit dhe përdorimin e segmentimit bazë dhe etiketave PoS, analizuesi mori rezultate të mira si në LAS makro-mesatare, ashtu edhe në UAS në kategorinë e bazave të pemëve të mëdha (55 gjuhë), duke renditur të shtatën nga 33 ekipe. Në kategorinë e të gjitha vendeve të pemëve (LAS dhe UAS) ne u renditëm të 16-të dhe të 12-të. Ndryshimi midis të gjitha dhe kategorive të mëdha është kryesisht për shkak të performancës së dobët në katër baza pemësh paralele PUD, duke sugjeruar se disa baza pemësh `të mjaftueshme' (për shembull Spanjoll-AnCora) bëjnë keq në rregullimet e bazës së pemëve kryqëzuese, gjë që nuk ndodh me bazën e pemës `të papërmjaftueshme' (për shembull spanjoll). Duke ndryshuar këtë, ne arrijmë LAS-in e 11-të më të mirë midis të gjitha runs (zyrtare dhe jozyrtare). Kodi është bërë në dispozicion në < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'hy': "Լիս-Ֆասթպարեսի թիմը ներկայացնում է Բիստ-Կովինգթոնը, Կովինգթոնի (2001) ալգորիթմի նյարդային իրականացումը ոչ պրոեկտիվ կախվածության վերլուծության համար: KiPerwesen-ի և Goldberg-ի երկու ուղղությամբ LSMT մոտեցումը (2016) օգտագործվում է ագահությամբ վերլուծողի վարժեցնելու համար դինամիկ խոսքով սխալների տարածման նվազեցնելու համար: Մոդելը մասնակցեց 2017 թվականի ԿոՆԼ-ի UD-ի կիսված հանձնարարության մեջ: Չնայած, որ ոչ մի համակարգչային մեթոդներ չօգտագործեցին և օգտագործեցին հիմնական սեգմենտացիան և PoS-ի նշանները, վերլուծումը լավ արդյունքներ ստացավ նաև մակրոմիջին LAS-ի և UAS-ի համար մեծ ծառի բակի կատեգորիայի (55 լեզու) մեջ, որն 33 թիմերից 7-րդ Բոլոր ծառերի կատեգորիաներում (LAS և UAS) մենք դասակարգեցինք 16-րդ և 12-րդ դասակարգերը: Բոլոր և մեծ կատեգորիաների միջև տարբերությունը հիմնականում պատճառով է, որ չորս զուգահեռ POD ծառերի տախտակների արտադրողությունը վատ է, ինչը առաջարկում է, որ որոշ `բավարար' ծառերի տախտակներ (օրինակ Իսպաներեն-Անկորա) վատ են աշխատում ծառերի տախտակների տախտակներում, ինչը չի տեղի ունենում համապատասխանատու Այն փոխելով, մենք ստանում ենք 11-րդ լավագույն LAS-ը բոլոր կազմակերպություններում (պաշտոնական և ոչ պաշտոնական): Կոդը հասանելի է https://github.com/CoNLL-UD-2017/LyS-FASTPARSE _", 'ko': "LyS FASTPARSE팀은 BIST-COVINGTON을 제기했는데 이것은 COVINGTON(2001) 알고리즘의 신경 실현으로 비투영 의존성 해석에 사용된다.Kiperwasser와 Goldberg(2016)가 제시한 양방향 LSTM 방법은 탐욕스러운 해석기와 동적oracle을 훈련시켜 오류의 전파를 줄이는 데 사용된다.이 모델은 CoNLL 2017 UD 공유 작업에 사용됩니다.어떤 집적 방법도 사용하지 않았고 기선 분할과 어성 표기도 사용하지 않았지만 해상기는 대형 트리 은행 유형(55개 언어)의 거시적 평균 LAS와 UAS에서 모두 좋은 결과를 얻어 33개 팀 중 7위에 올랐다.온트리은행 카테고리(LAS와 UAS)에서는 각각 16위와 12위에 올랐다.all와 big 유형 간의 차이는 주로 네 개의 평행 PUD 트리 라이브러리가 좋지 않기 때문이다. 이것은 일부'접두사'트리 라이브러리(예를 들어 스페인어 Ancora)가 크로스 트리 라이브러리 설정에서 좋지 않은 반면에 상응하는'비접두사'트리 라이브러리(예를 들어 스페인어)는 나타나지 않았다는 것을 나타낸다.이를 바꿔 우리는 모든 경기(공식과 비공식) 중 11위를 차지했다.이 코드는 다음 웹 사이트에서 사용할 수 있습니다.<https://github.com/CoNLL-UD-2017/LyS-FASTPARSE>", 'am': 'የዋይኖን (2001) አልጎሪትምን ለመጠቀም የደኅንነት ማኅበረሰብ በቢST-COVINGTON አቅራቢያ የደረጃ ቋንቋ አዋጅ ነው፡፡ የኪperwasser እና ጎልdberg (2016) የደረጃ የLSTM ሥርዓት የተጠቃሚ የስህተት ፕሮግራሙን ለማቀናቀል ይጠቅማል፡፡ ሞዴል ከ.አ.አ.አ.አ.አ.አ.አ.ዲ ስራውን ተጋራጅ ነበር፡፡ ምንም እንኳን ምናልባት እና የbaseline segmentation እና PoS tagging ምንም እንኳን ባይጠቀም፣ ተማሪዎቹ ከ33 የቲርብክ ክፍተት 7 እኩል ሲሆን በመካro-average LAS እና UAS ላይ መልካም ፍሬቶች አገኘ፡፡ በዛፎቹ ሁሉ (LAS እና ኦAS) 16ተኛውና 12ኛ ደረስን። በሁሉም እና በታላቁ ክፍሎች መካከል የውጤት ክፍል በአራቱ ተቃውሞ PUD treebank (ምሳሌ ስፓኒሽ-አንኮራ) የድሀ ክፍል ነው፡፡ By changing that, we obtain the 11th best LAS among all runs (official and unofficial).  ኮድ በ < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'az': "LyS-FASTPARSE ekibi BIST-COVINGTON, proyektiv bağlılıq analizi üçün Covington (2001) algoritminin nöral işlətməsi üçün təşkil edir. Kiperwasser və Goldberg (2016) tarafından iki-diqqətli LSTM tərəfindən istifadə edilir ki, xəta propagasyonunu azaltmaq üçün dinamik oraklı bir parçacını təhsil etmək üçün istifadə edilir. Model 2017-ci CoNLL UD paylaşılmış iş işin ə katıldı. Böyük çubuqlar kategoriyasındakı makro ortalama LAS və UAS ilə birlikdə gözəl sonuçlar aldığı halda, həmçin in əsas çubuqlarını və PoS etiketlərini istifadə etmədikləri halda, ayırıcı büyük çubuqlar kategoriyasındakı makro ortalama LAS və UAS kategoriyasında (55 dillər), 33 dəstədən 7-ci dəstədə Bütün ayaqlar kategoriyasında 16-ci və 12-ci dərəcələr vardıq. Bütün və böyük kategoriyalar arasındakı ayrılıq dörd paralel PUD çubuqlarının yoxsulluqlarına g örədir, bəzi 'suffik' çubuqlarına (İspanyol-AnCora kimi İspanyol-AnCora'nın) qarışıq çubuqlarında pis işləməsini təsdiqləyir, bu da müəyyən olunmayan 'unsufficient' çubuqlarına (məsələn İspanyol çubuqlarına uyğun deyildir). Bunu dəyişdirərək, hər tərəfdən 11. ən yaxşı LAS alırıq. Kod %s'də faydalanır https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'bn': "লাইএস-ফাস্টপার্সের দল বিস্ট-কোভিন্টনের উপস্থাপন করছে, যিনি কোভিঙ্টন (২০০১) আলগরিদমের নিউরেল বাস্তবায়িত করেছেন পার্জিং এর জন্য। কিপারওয়াসের এবং গোল্ডবার্গ (২০১৬) দ্বিতীয় এলস্টিএম প্রতিযোগিতা ব্যবহার করা হয়েছে ত্রুটি প্রচারণা কমানোর জন্য একটি গ্রাফি প্যারেজা এই মডেল কএনএল ২০১৭ সালে অংশগ্রহণ করেছিল ইউডি শেয়ার কর্মসূচীতে। বেস্ট্রোব্যাঙ্কের বিভাগ ও পস ট্যাগিং ব্যবহার করার কোনো উপায় ব্যবহার করা ছাড়াও, প্যারাস্টার বিশাল ট্রাইব্যাঙ্ক বিভাগের (৫৫ ভাষা) বিশাল ট্রিব্যাংকের বিভাগ সকল ত্রীবাঙ্কের বিভাগে আমরা ১৬ এবং ১২ তারিখে রান্না করেছি। সকল এবং বড় বিভাগের মধ্যে পার্থক্য হচ্ছে মূলত চারটি প্যারালেল পিউডি ত্রিব্যাংকের উপর দরিদ্র প্রদর্শনের কারণে, যার পরামর্শ দেয়া হচ্ছে যে কেউ কেউ 'ভক্ত' ত্রিব্যাংক (যেমন স্প্যানিশ-অ্যান্কোরা) ক্রিস্প্যানিশ ব্ এই পরিবর্তনের মাধ্যমে আমরা সকল চালানোর মধ্যে ১১তম শ্রেষ্ঠ ল্যাস পেয়েছি (অফিসিয়াল এবং অফিসিয়াল)। <এ কোড পাওয়া যাচ্ছে https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'ca': "The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation of the Covington (2001) algorithm for non-projective dependency parsing.  L'enfocament bidireccional LSTM de Kiperwasser i Goldberg (2016) s'utilitza per formar un analitzador cobdiciós amb un oracle dinàmic per mitigar la propagació d'errors. El model va participar en el CoNLL 2017 UD Shared Task. Malgrat que no utilitzés cap mètode d'ensemble i la segmentació basal i l'etiqueta PoS, el analitzador va obtenir bons resultats tant en el LAS macromitjà com en l'UAS en la categoria de grans bancs d'arbres (55 llengües), classificant-se en 7 de cada 33 equips. En tota la categoria de bancs d'arbres (LAS i UAS) vam classificar el 16è i 12è. La diferència entre totes les categories i les grans es deu principalment a la mala performance en quatre bancs paralèls de PUD, suggerent que algunes bancs d'arbre `sufixides' (p.ex. Espanyol-AnCora) actuen malament en configuracions de bancs d'arbre cruzaçats, que no es produeix amb la corresponding banc d'arbre `no sufixides' (p.ex. espanyol). Al canviar això, obtenim la 11ª millor LAS entre totes les execucions (oficials i poc oficials). El codi està disponible a < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'bs': 'LyS-FASTPARSE tim predstavlja BIST-COVINGTON, neuralnu implementaciju algoritma Kovingtona (2001) za analizu neprojektivne zavisnosti. Bidirektivni pristup LSTM od Kiperwasser a i Goldberga (2016) se koristi za treniranje pohlepnog analizatora sa dinamičnim orakulom za smanjenje propagacije greška. Model je sudjelovao u zajedničkom zadatku CoNLL 2017. Uprkos ne koristiti nikakve metode ensemble i koristiti osnovnu segmentaciju i oznake PoS, analizator je dobio dobre rezultate na makro-prosječnom LAS i UAS-u u velikoj kategoriji trgovinskih granica (55 jezika), u redovima 7. iz 33 timova. U svim kategorijama kretanja (LAS i UAS) postali smo 16. i 12. reda. Praznina između svih i velikih kategorija je uglavnom zbog loše g izvođenja na četiri paralelne PUD treebancije, ukazujući na to da neki "suffikovani" treebanci (npr. španjolski-AnCora) loše izvršavaju na postavkama preko treebancija, koji se ne događa sa odgovarajućim "neobičnim" treebancima (npr. španjolski). Promjenom toga, dobijemo 11. najbolji LAS među svim trkama (zvanični i neoficijalni). Kod je dostupan na < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE -Da.', 'et': 'LyS-FASTPARSE meeskond tutvustab BIST-COVINGTONI, Covingtoni (2001) algoritmi neurorakendust mitteprojektiivse sõltuvuse parsimiseks. Kiperwasseri ja Goldbergi (2016) kahesuunalist LSTM-meetodit kasutatakse dünaamilise oraakeliga ahne parser vigade leviku leevendamiseks. Mudel osales CoNLL 2017 UD Shared Task\'is. Vaatamata sellele, et ühtegi ansambli meetodit ei kasutanud ning kasutas algtaseme segmenteerimist ja PoS-sildistamist, saavutas parser head tulemused nii makrokeskmisel LAS-il kui ka UAS-il suurte puupankade kategoorias (55 keelt), mis oli 33 meeskonnast seitsmes. Kõigi puupankade kategoorias (LAS ja UAS) olime 16. ja 12. kohal. Lõhe kõigi ja suurte kategooriate vahel on peamiselt tingitud nelja paralleelse PUD puupanga halvast tulemusest, mis viitab sellele, et mõned "suffikseeritud" puupangad (nt Hispaania-AnCora) toimivad halvasti puupankade seadetes, mida ei esine vastava "kinnitamata" puupanga (nt Hispaania) puhul. Muutes seda, saame 11. parima LAS kõigi jooksude hulgas (ametlikud ja mitteametlikud). Kood on kättesaadav aadressil < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'fi': 'LyS-FASTPARSE-tiimi esittelee BIST-COVINGTON-algoritmin neurototeutuksen ei-projektiiviseen riippuvuuden jäsentämiseen. Kiperwasserin ja Goldbergin (2016) kaksisuuntaista LSTM-menetelmää käytetään ahneen jäsentäjän kouluttamiseen dynaamisella oraakkelilla vähentämään virheiden leviämistä. Malli osallistui CoNLL 2017 UD Shared Task -ohjelmaan. Vaikka jäsentäjä ei käyttänyt ensemble-menetelmiä ja käytti lähtötason segmentointia ja PoS-tagausta, hän saavutti hyviä tuloksia sekä makrokeskiarvon LAS- että AMK-tasolla suurten puupankkien luokassa (55 kieltä), sijoittuen seitsemänneksi 33 joukkueesta. Kaikki puupenkit -luokassa (LAS ja AMK) sijoittuimme 16. ja 12. sijalle. Kaikkien ja suurten luokkien välinen kuilu johtuu pääasiassa heikosta suorituskyvystä neljällä rinnakkaisella PUD-puupenkillä, mikä viittaa siihen, että jotkut "sufixed" puupenkit (esim. Spanish-AnCora) suoriutuvat huonosti cross-treebank asetuksissa, mikä ei tapahdu vastaavalla "kiinnittymättömällä" puupenkillä (esim. espanja). Muuttamalla tätä saamme 11. parhaan LAS:n kaikista ajoista (virallisista ja epävirallisista). Koodi on saatavilla osoitteessa < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'cs': 'Tým LyS-FASTPARSE představuje BIST-COVINGTON, neuronovou implementaci Covingtonova algoritmu (2001) pro neprojektivní analýzu závislostí. Obousměrný LSTM přístup od Kiperwasser a Goldberga (2016) se používá k tréninku chamtivého parseru s dynamickým orákulem pro zmírnění šíření chyb. Model se podílel na sdíleném úkolu CoNLL 2017 UD. Navzdory nepoužití žádných souborových metod a použití základní segmentace a PoS tagování, parser dosáhl dobrých výsledků jak na makro-průměrné LAS, tak UAS v kategorii velkých stromových bank (55 jazyků) a sedmé z 33 týmů. V kategorii všechny stromové banky (LAS a UAS) jsme se umístili šestnáctý a dvanáctý. Rozdíl mezi všemi a velkými kategoriemi je způsoben především špatným výkonem na čtyřech paralelních PUD stromových bázích, což naznačuje, že některé "příponové" stromové báze (např. Spanish-AnCora) mají špatný výkon v nastavení cross-treebank, což není u odpovídající "nepříznivé" stromové báze (např. španělština). Tím, že tuto změnu získáme jedenáctý nejlepší LAS ze všech běhů (oficiální i neoficiální). Kód je k dispozici na adrese < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'jv': "Grup LiS-FILE-PARKSE karo BIRT-COMPLNGTON, alajur ngewehke Algorithm kanggo kowin nggo oleh dumadhi Gak-perusahaan dipeneksi Ndoleh sing dibireksiyonal LTT method nang Kiperwasser lan golberg (2011) nggawe oleh banter sing dumadhi kanggo nganggo perusahaan oras-dumadhi kanggo nambah akeh eror. Gosok model kang dipoleh ning CoNLL 1997 UT Joined Job Genjer ning lakong cara bakir dibenakake (LAS lan US) kita disenalke 16 lan 12. gap terus kategori sing gak lan akeh sing dumadhi iki, dadi sing ngentalungno ngono perusahaan kanggo nganggo dolanan sing perusahaan PND coral, supoyo wong-wong artik 'suffixed' Nggo njuk-njuk kuwi, kita luwih saben tanggal 11 liyane LAS sing gak ngono koyo ngono (offisial lan saiki offisial). Coverage https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'sk': "Ekipa LyS-FASTPARSE predstavlja BIST-COVINGTON, nevronsko implementacijo algoritma Covington (2001) za neprojektivno razčlenitev odvisnosti. Dvosmerni pristop LSTM Kiperwasserja in Goldberga (2016) se uporablja za usposabljanje pohlepnega razčlenjevalnika z dinamičnim oraklusom za ublažitev širjenja napak. Model je sodeloval pri deljeni nalogi CoNLL 2017 UD. Kljub temu, da ni uporabljal nobenih metod ansambla in uporabljal osnovne segmentacije in označevanja PoS, je razčlenjevalec dobil dobre rezultate tako na makropovprečnem LAS kot UAS v kategoriji velikih dreebanks (55 jezikov), pri čemer se je uvrstil na 7. mesto od 33 ekip. V kategoriji vseh dreebanks (LAS in UAS) smo se uvrstili na 16. in 12. mesto. Razkorak med vsemi in velikimi kategorijami je predvsem posledica slabe zmogljivosti na štirih vzporednih PUD drevesnih ploščah, kar kaže, da nekatere `priponne' drevesne plošče (npr. Spanish-AnCora) slabo delujejo pri nastavitvah navzkrižnih drevesnih plošč, kar se ne pojavi pri ustrezni `nepritrjeni' drevesni plošči (npr. španski plošči). S spremembo tega dosežemo 11. najboljši LAS med vsemi teki (uradni in neuradni). Koda je na voljo na spletni strani < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'he': 'צוות Lys-FASTPARSE מציג BIST-COVINGTON, שימוש עצבי של אלגוריתם קובינגטון (2001) עבור בדיקת תלויות לא פרויקטיבית. הגישה ה-LSTM בינוכית על ידי Kiperwasser וגולדברג (2016) משתמשת כדי לאמן מעבד חמדן עם אורקל דינמי כדי להקל את ההתפתחות של שגיאות. המודל השתתף במשימה המשותפת של CoNLL 2017 UD. למרות שלא השתמשו בשיטות אנסמבל ובשימוש בסגמנציה הבסיסית ובתוויות פוס, המחקר השיג תוצאות טובות גם על LAS מקרו-ממוצע וגם על UAS בקטגוריה של בנקי העץ הגדולים (55 שפות), המדרגות השביעית מתוך 33 קבוצות. בקטגוריה של כל חצי העץ (LAS ו UAS) הצווענו ב-16 ו-12. הפער בין כל הקטגוריות לבין הקטגוריות הגדולות הוא בעיקר בגלל ביצועים גרועים בארבעה עצי PUD מקבילים, מה שמציע שכמה עצי ‘ מספיקים ’ (np. ספרדית-אנקורה) מבצעים גרועים על הגדרות של חצי עצים, אשר לא מתרחש עם עצי ‘ לא מספיקים ’ (np. ספרדית). על ידי שינוי זה, אנחנו מקבלים את ה-11 LAS הטוב ביותר בין כל הריצויים (רשמיים ולא רשמיים). הקוד מופעל על < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >', 'ha': "The lyS-FATTPARCE team na halatar da BIS-COV NGTON, a neural administration of the algoritm of the coverington (2001) for non-projeative depend parse. @ info: whatsthis @ info: status Bai da amfani da shiryoyin ayuka da kuma ya yi amfani da sigar-segment da PoS ɗin basuɗe, Parser ya motsa fassara mai kyau a tsakanin macro-GAMA da USA cikin kategori babban Treebanks (55 languages), mai randin 7 daga jama'a 33. A cikin duk categori na uku (LauS da UAS) na sarrayi 16th da 12th. Difficen tsakanin duk jama'a da babban ƙungiya, mainli, yana son mafakin aikin matalauci a kan matabbatar da ke takardar rubutun PUD, kuma yana shawarar da wasu `an cire (misali, spanish-AnCora) su yi zartar zartar da shi a kan daidaita-Treebank (misali, spanish). Ga ka musanya wannan, za mu sami mafi kyaun LS na 11th daga duk tafiyar (rasmi da ba'a rasa ba). Ana samar da kodi a < https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >", 'bo': 'The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation of the Covington (2001) algorithm for non-projective dependency parsing. The bidirectional LSTM approach by Kiperwasser and Goldberg (2016) is used to train a greedy parser with a dynamic oracle to mitigate error propagation. Model participated in the CoNLL 2017 UD Shared Task. In spite of not using any ensemble methods and using the baseline segmentation and PoS tagging, the parser obtained good results on both macro-average LAS and UAS in the big treebanks category (55 languages), ranking 7th out of 33 teams. དབྱངས་ཁྱེར་གྱི་དབྱེ་རིམ་(LAS དང་ཨེ་ཨེསི་ཨེསི་)ནང་དུ་ང་ཚོ་གྲངས་༡༦པ་དང་༡༢པ་རེད། དབྱེ་རིགས་ཡོངས་དང་ཆེ་བའི་བར་སྟོང་གཉིས་ཀྱི་བར་སྟོང་པ་དེ་ལས་ཉུང་བའི་ངལ འདི་ལ་བསྒྱུར་བཅོས་སྐབས་ན། ང་ཚོས་རྒྱ་ནག་གཡོན་འཁོར་སྐྱོན་མེད་པའི་ལྕགས་ཤིག་གཅིག་པུ་མཐོང་ཐུབ། <ནང་དུ་ཨང་ཀིའི་སྤྱོད་སྤྱོད་རུང་བ https://github.com/CoNLL-UD-2017/LyS-FASTPARSE >'}
{'en': 'LIMSI@CoNLL’17 : UD Shared Task', 'ar': "LIMSI @ CoNLL'17: مهمة مشتركة لـ UD", 'es': "LIMSI @CoNLL '17: Tarea compartida de UD", 'fr': "LIMSI @CoNLL '17\xa0: Tâche partagée UD", 'pt': "LIMSI@CoNLL'17: Tarefa Compartilhada UD", 'ja': "LIMSI @ CoNLL '17: UD共有タスク", 'zh': 'LIMSI@CoNLL 17:UD 共之', 'hi': "LIMSI@CoNLL'17: UD साझा कार्य", 'ru': "LIMSI@CoNLL'17: UD Shared Task", 'ga': "LIMSI@CoNLL'17: Tasc Comhroinnte UD", 'ka': "LIMSI@CoNLL '17: UD გაყოფილი დავალება", 'hu': 'LIMSI@CoNLL "17: UD megosztott feladat', 'el': 'LIMSI@CoNLL "17: Κοινή εργασία UD', 'it': 'LIMSI@CoNLL "17: UD Shared Task', 'kk': "LIMSI@CoNLL '17: UD ортақтастырылған тапсырма", 'mk': "LIMSI@CoNLL '17: УД споделена задача", 'lt': 'LIMSI@CoNLL "17: Bendra UD užduotis', 'ms': "LIMSI@CoNLL '17: Tugas Berkongsi UD", 'ml': "LIMSI@CoNLL '17: UD Shared Task", 'mt': "LIMSI@CoNLL '17: Kompitu Konġunt tal-UD", 'mn': "LIMSI@CoNLL '17: UD хуваалтын ажил", 'no': 'LIMSI@CoNLL « 17: UD- delt oppgåve', 'pl': 'LIMSI@CoNLL "17: Wspólne zadanie UD', 'ro': 'LIMSI@CoNLL "17: Sarcină partajată UD', 'sr': "LIMSI@CoNLL '17: UD podeljeni zadatak", 'si': "LIMSI@CoNLL '17: UD සමාගත වැඩක්", 'so': "LIMSI@CoNLL '17: Shaqada UD ee la sharciyey", 'sv': 'LIMSI@CoNLL "17: Delad UD-uppgift', 'ta': "LIMSI@CoNLL '17: UD பகிர்ந்த பணி", 'ur': "LIMSI@CoNLL '17: UD Shared Task", 'uz': 'LIMSI@CoNLL 17: UD boĘ»lishilgan vazifa', 'vi': 'LIMSI@CoNLL "17: UD chia sẻ nhiệm vụ', 'hr': "LIMSI@CoNLL '17: UD zajednički zadatak", 'bg': 'LIMSI@CoNLL "17: Споделена задача UD', 'nl': 'LIMSI@CoNLL "17: Gedeelde taak van UD', 'id': "LIMSI@CoNLL '17: UD Shared Task", 'ko': 'LIMSI@CoNLL17: UD 공유 작업', 'de': 'LIMSI@CoNLL "17: Gemeinsame Aufgabe der UD', 'sw': "LIMSI@CoNLL '17: Kazi ya UD ilizoshirikishwa", 'fa': 'LIMSI@CoNLL ۱۷: کار مشترک UD', 'da': 'LIMSI@CoNLL "17: UD delt opgave', 'af': "LIMSI@CoNLL '17: UD Gedeelde Opdrag", 'sq': "LIMSI@CoNLL '17: UD Task Shared", 'hy': "LIMSI@CoNLL '17. UD-ի կիսված խնդիրը", 'az': "LIMSI@CoNLL '17: UD paylaşılan işlər", 'tr': 'LIMSI@CoNLL 1', 'am': 'LIMSI@CoNLL ምስሉን በሌላ ስም አስቀምጥ', 'bn': "LIMSI@CoNLL '17: UD শেয়ার কর্মসূচী", 'cs': 'LIMSI@CoNLL "17: sdílený úkol UD', 'et': 'LIMSI@CoNLL "17: UD ühisülesanne', 'bs': "LIMSI@CoNLL '17: UD zajednički zadatak", 'fi': 'LIMSI@CoNLL "17: UD:n jaettu tehtävä', 'ca': "LIMSI@CoNLL '17: UD Shared Task", 'jv': 'LIMSI@CoNLL checkbox', 'he': "LIMSI@CoNLL '17: משימה משותפת UD", 'sk': 'LIMSI@CoNLL "17: Skupna naloga UD', 'ha': "LIMSI@CoNLL '17: UD Shared Task", 'bo': "LIMSI@CoNLL '17 UD མཉམ་སྤྱོད་པའི་བྱ་འགུལ"}
{'en': 'This paper describes LIMSI’s submission to the CoNLL 2017 UD Shared Task, which is focused on small treebanks, and how to improve low-resourced parsing only by ad hoc combination of multiple views and resources. We present our approach for low-resourced parsing, together with a detailed analysis of the results for each test treebank. We also report extensive analysis experiments on model selection for the PUD treebanks, and on annotation consistency among UD treebanks.', 'ar': 'تصف هذه الورقة تقديم LIMSI إلى المهمة المشتركة لـ CoNLL 2017 UD ، والتي تركز على بنوك الأشجار الصغيرة ، وكيفية تحسين التحليل منخفض الموارد فقط من خلال مجموعة مخصصة من وجهات النظر والموارد المتعددة. نقدم نهجنا للتحليل منخفض الموارد ، جنبًا إلى جنب مع تحليل مفصل لنتائج كل شجرة اختبار. لقد أبلغنا أيضًا عن تجارب تحليلية مكثفة حول اختيار النموذج لبنوك الشجرة PUD ، واتساق الشروح بين بنوك شجرة UD.', 'pt': 'Este artigo descreve o envio do LIMSI para a Tarefa Compartilhada CoNLL 2017 UD, que é focada em pequenos bancos de árvores, e como melhorar a análise de poucos recursos apenas pela combinação ad hoc de várias visualizações e recursos. Apresentamos nossa abordagem para análise com poucos recursos, juntamente com uma análise detalhada dos resultados para cada banco de árvores de teste. Também relatamos extensos experimentos de análise na seleção de modelos para os bancos de árvores PUD e na consistência de anotação entre os bancos de árvores UD.', 'fr': "Cet article décrit la soumission de LIMSI à la tâche partagée ConLL 2017 UD, qui est axée sur les petites banques d'arbres, et comment améliorer l'analyse syntaxique à faibles ressources uniquement par une combinaison ad hoc de vues et de ressources multiples. Nous présentons notre approche pour l'analyse avec peu de ressources, ainsi qu'une analyse détaillée des résultats pour chaque banque d'arbres de test. Nous rapportons également des expériences d'analyse approfondies sur la sélection de modèles pour les banques d'arbres PUD, et sur la cohérence des annotations entre les banques d'arbres UD.", 'es': 'Este documento describe la presentación de LIMSI a la tarea compartida UD de CoNll 2017, que se centra en pequeños bancos de árboles, y cómo mejorar el análisis de bajos recursos solo mediante una combinación ad hoc de múltiples vistas y recursos. Presentamos nuestro enfoque para el análisis de bajos recursos, junto con un análisis detallado de los resultados de cada banco de árboles de prueba. También informamos de extensos experimentos de análisis sobre la selección de modelos para los bancos de árboles de PUD y sobre la consistencia de las anotaciones entre los bancos de árboles de UD.', 'ja': 'この論文では、小さなツリーバンクに焦点を当てたCoNLL 2017 UD Shared TaskへのLIMSIの提出と、複数のビューとリソースを臨機応変に組み合わせることによってのみ低リソースの構文解析を改善する方法について説明します。私たちは、低資源構文解析のためのアプローチを、各テストツリーバンクの結果の詳細な分析とともに提示します。また、Pudツリーバンクのモデル選択、UDツリーバンク間のアノテーションの一貫性に関する広範な分析実験を報告している。', 'zh': '本文言LIMSI与CoNLL 2017 UD共事者,务侧重于小树库,及何以数视图、资源之权宜改善资源匮乏之解析。 吾言吾低资源解析法,及每试树库之详细分析。 又白 PUD 树库模择及 UD 树库注一致性广析实验。', 'hi': 'यह पेपर CoNLL 2017 UD Shared Task के लिए LIMSI के सबमिशन का वर्णन करता है, जो छोटे treebanks पर केंद्रित है, और केवल कई दृश्यों और संसाधनों के तदर्थ संयोजन द्वारा कम-संसाधन पार्सिंग में सुधार कैसे करें। हम प्रत्येक परीक्षण ट्रीबैंक के लिए परिणामों के विस्तृत विश्लेषण के साथ-साथ कम संसाधन वाले पार्सिंग के लिए अपना दृष्टिकोण प्रस्तुत करते हैं। हम PUD treebanks के लिए मॉडल चयन पर व्यापक विश्लेषण प्रयोगों की भी रिपोर्ट करते हैं, और UD treebanks के बीच एनोटेशन स्थिरता पर।', 'ru': 'В этой статье описывается представление LIMSI общей задаче CoNLL 2017 UD, которая сосредоточена на небольших берегах деревьев, и как улучшить парсинг с ограниченными ресурсами только за счет специальной комбинации нескольких представлений и ресурсов. Мы представляем наш подход к парсингу с ограниченными ресурсами, а также подробный анализ результатов для каждого тестового банка деревьев. Мы также сообщаем об обширных аналитических экспериментах по выбору моделей для БЕРЕГОВ пудов и о согласованности аннотаций среди берегов деревьев UD.', 'ga': 'Déanann an páipéar seo cur síos ar aighneacht LIMSI chuig Tasc Comhroinnte 2017 UD CoNLL, atá dírithe ar bhruacha crann beaga, agus conas parsáil ar acmhainní ísle a fheabhsú trí mheascán ad hoc d’ilamhairc agus acmhainní amháin. Cuirimid ár gcur chuige do pharsáil ar acmhainní ísle i láthair, mar aon le hanailís mhionsonraithe ar thorthaí gach crann tástála. Tugaimid tuairisc freisin ar thurgnaimh anailíse fairsinge ar roghnú samhlacha do na bainc crann PUD, agus ar chomhsheasmhacht nótaí i measc na gcrann crann RA.', 'ka': 'ამ დოკუმენტი LIMSI-ის გასახულება CoNLL 2017 UD-ის გასახულებული დავალებისთვის, რომელიც ცოტაცია პატარა კონკუმენტებზე და როგორ უფრო უფრო უფრო უფრო უფრო უფრო უფრო მნიშვნელოვანი პანსპორ ჩვენ ჩვენი პროგორმაციას, რომელიც ცვლილების კონფიგურაციისთვის ცვლილებების განსაზღვრებისთვის, ჩვენ ჩვენი პროგორმაციას, რომელიც განსაზღვრებული ანალი ჩვენ ასევე აღწერეთ განსხვავებული ანალიზი ექსპერიმენტები მოდელის მონიშნულებაში PUD საბეჭდოებისთვის, და UD საბეჭდოებისთვის ანალიზებისთვის შემდეგ', 'hu': 'Ez a tanulmány bemutatja a LIMSI beadványát a CoNLL 2017 UD Shared Task-hoz, amely a kisebb fapadokra összpontosít, és hogyan lehet javítani az alacsony forrásokkal rendelkező elemzést csak több nézet és erőforrás ad hoc kombinációjával. Bemutatjuk az alacsony forrásokkal rendelkező elemzési megközelítésünket, valamint az eredmények részletes elemzését az egyes tesztek fából. Széleskörű elemzési kísérletekről is beszámolunk a PUD fák modellkiválasztásáról, valamint az UD fák közötti megjegyzések konzisztenciájáról.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή του στην Κοινή Εργασία που επικεντρώνεται σε μικρές τράπεζες δέντρων, και πώς να βελτιωθεί η ανάλυση χαμηλών πόρων μόνο με συνδυασμό πολλαπλών προβολών και πόρων. Παρουσιάζουμε την προσέγγισή μας για ανάλυση χαμηλού δυναμικού, μαζί με μια λεπτομερή ανάλυση των αποτελεσμάτων για κάθε δοκίμιο δέντρου. Επίσης, αναφέρουμε εκτεταμένα πειράματα ανάλυσης για την επιλογή μοντέλων για τις τράπεζες δέντρων και για τη συνέπεια σχολιασμού μεταξύ δέντρων UD.', 'it': "Questo articolo descrive la presentazione di LIMSI al CoNLL 2017 UD Shared Task, che è focalizzato su piccoli treebank, e come migliorare l'analisi a basso contenuto di risorse solo combinando ad hoc più visualizzazioni e risorse. Presentiamo il nostro approccio per il parsing a basso contenuto di risorse, insieme ad un'analisi dettagliata dei risultati per ogni albero di prova. Riportiamo anche approfonditi esperimenti di analisi sulla selezione dei modelli per i banchi degli alberi PUD e sulla coerenza delle annotazioni tra i banchi degli alberi UD.", 'kk': "Бұл қағаз LIMSI'ның CoNLL 2017 UD ортақ тапсырмасына жіберілген тапсырманы түсіндіреді. Бұл кішкентай құрылғыларға назар ауыстырылған және бірнеше көрініс мен ресурстардың ad hoc түрлендірілген түрлендірілген түрлендір Біз өзіміздің көп ресурстар талдау арқылы, әрбір сынақтардың нәтижелерін тегжейлі анализ келеді. Біз сондай-ақ PUD құрылғыларының үлгісін таңдау үшін тең анализ тәжірибелерін және UD құрылғыларының тәжірибелерін жазып береміз.", 'mk': 'Овој документ го опишува поднесувањето на ЛИМСИ на Соделената задача на УД CoNLL 2017, која се фокусира на малите дрвја, и како да се подобри анализирањето со ниски ресурси само со адхок комбинација на повеќе погледи и ресурси. Ние го претставуваме нашиот пристап за анализирање со ниски ресурси, заедно со детална анализа на резултатите за секоја тест на дрвото. We also report extensive analysis experiments on model selection for the PUD treebanks, and on annotation consistency among UD treebanks.', 'lt': 'Šiame dokumente aprašomas LIMSI pateiktas bendrai užduoties CoNLL 2017 m. UD uždaviniui, kuriame daugiausia dėmesio skiriama mažoms medžių s ąrankoms, ir kaip gerinti mažų išteklių analizę tik ad hoc derinant įvairias nuomones ir išteklius. Pateikiame savo požiūrį į mažų išteklių analizę ir išsamią kiekvieno bandymų medžio pagrindo rezultatų analizę. Taip pat pranešame apie išsamius analizės eksperimentus, susijusius su modelių atranka PUD medžių juostoms ir su UD medžių juostų anotacijos nuoseklumu.', 'ms': 'Kertas ini menggambarkan penghantaran LIMSI kepada Tugas Berkongsi UD CoNLL 2017, yang fokus pada bank pokok kecil, dan bagaimana untuk meningkatkan penghuraian sumber rendah hanya dengan kombinasi ad hoc pemandangan dan sumber berbilang. Kami memperkenalkan pendekatan kami untuk penghuraian sumber rendah, bersama dengan analisis terperinci keputusan untuk setiap pangkalan pepohonan ujian. Kami juga melaporkan eksperimen analisis ekstensif pada pemilihan model untuk pangkalan pokok PUD, dan pada konsistensi anotasi di antara pangkalan pokok UD.', 'ml': 'ഈ പത്രത്തില്\u200d ലിഎസ്ഐ കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കെടുത്ത പണിയിലേക്ക് കൊടുക്കുന്നതിനെ വിശദീകരിക്കുന്നു. അത് ചെറിയ ത്രീബാങ്കുകളില്\u200d ശ്രദ്ധിക്കുന്നു. കുറ ഞങ്ങള്\u200d കുറഞ്ഞ വിഭവങ്ങള്\u200d പാര്\u200dജിങ്ങള്\u200dക്ക് നമ്മുടെ അടുത്തേക്ക് കൊണ്ടുവരുന്നു. എല്ലാ പരീക്ഷണങ്ങളുടെ ഫലങ്ങള്\u200dക്കും വ പിയുഡി ട്രീബാങ്കുകള്\u200dക്കുള്ള മോഡല്\u200d തെരഞ്ഞെടുക്കുന്നതിനെക്കുറിച്ച് വിശാലമായ പരീക്ഷണങ്ങള്\u200d ഞങ്ങള്\u200d റിപ്പോര്\u200dട്ട്', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjoni tal-LIMSI lill-Ħidma Kondiviża tal-UD CoNLL 2017, li hija ffukata fuq banek żgħar tas-siġar, u kif tittejjeb l-analiżi b'riżorsi baxxi biss permezz ta' kombinazzjoni ad hoc ta' fehmiet u riżorsi multipli. Aħna nippreżentaw l-approċċ tagħna għall-analiżi b’riżorsi baxxi, flimkien ma’ analiżi dettaljata tar-riżultati għal kull bażi tas-siġar tat-test. Aħna nirrappurtaw ukoll esperimenti estensivi ta’ analiżi dwar l-għażla tal-mudell għall-banek tas-siġar PUD, u dwar il-konsistenza tal-annotazzjoni fost il-banek tas-siġar UD.", 'no': 'Denne papiret beskriver LIMSI sin tilføring til CoNLL 2017 UD- delt oppgåve, som er fokusert på små treebanklar, og korleis å forbetra låg ressurserte tolking berre ved ad hoc- kombinasjon av fleire visingar og ressursar. Vi presenterer tilnærminga vårt for låg ressurserte tolking, saman med detaljert analyse av resultatene for kvar test treebank. Vi rapporterer også ekstra analyserte eksperimenter om utvalet av modellen for PUD-treebankene, og om oppmerkingskonstensjon mellom UD-treebankene.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie LIMSI do wspólnego zadania CoNLL 2017 UD Shared Task, które koncentruje się na małych bankach drzew, oraz jak poprawić parsowanie niskich zasobów tylko poprzez ad hoc kombinację wielu widoków i zasobów. Przedstawiamy nasze podejście do parsowania o niskich zasobach wraz ze szczegółową analizą wyników dla każdego testowego drzewa. Raportujemy również obszerne eksperymenty analizowe dotyczące wyboru modeli dla banków drzew PUD oraz spójności adnotacji między bankami drzew UD.', 'ro': 'Această lucrare descrie prezentarea LIMSI la CoNLL 2017 UD Shared Task, care se concentrează pe brațe mici și cum să îmbunătățească analizarea cu resurse reduse numai prin combinația ad hoc de vizualizări și resurse multiple. Vă prezentăm abordarea noastră pentru analizarea cu resurse reduse, împreună cu o analiză detaliată a rezultatelor pentru fiecare braț de testare. De asemenea, raportăm experimente extinse de analiză privind selecția modelelor pentru brațele PUD și consecvența adnotării între brațele UD.', 'mn': 'Энэ цаас нь LIMSI-ын CoNLL 2017 оны UD-ын хуваалтын ажлыг тайлбарлаж байгааг харуулж байна. Энэ нь жижиг зам дээр анхаарлаа төвлөрсөн, зөвхөн олон үзэл болон нөөцийн ad hoc хуваалтыг хэрхэн сайжруулах боломжтой бага асуудалтай хуваалцах тал Бид бага асуудалтай хуваалцах аргыг харуулж, шалгалтын дагуулын үр дүнг бүрт нарийвчлан шинжилгээ хийдэг. Мөн бид PUD загварын загварын сонголтын тухай олон шинжилгээний туршилтын туршилтын тухай, UD загварын хоорондох загварын солилцооны тухай ярьдаг.', 'sr': 'Ovaj papir opisuje podnošenje LIMSI na zadatak CoNLL 2017, koji je usredotočen na male područje i kako poboljšati manje resurse analiziranje samo ad hoc kombinacijom višestrukih pogleda i resursa. Predstavljamo naš pristup analiziranju niskih resursa, zajedno sa detaljnom analiziranjem rezultata za svaku testnu obalu. Takoðe prijavljujemo široke analize eksperimente o modelu selekcije PUD treebancija, i o konsekvenciji annotacije izmeðu UD treebancija.', 'so': "Qoraalkan wuxuu ku qoraa in loo soo dhiibo LIMSI oo loo sharciyey CoNLL 2017 UD shaqo la sharciyey, kaas oo uu ku focus yahay weelasha yaryar, iyo sida loo kordhiyo jardiinada hoos-resourceed oo keliyahoo lagu kordhiyo isku daro aragtida iyo hantida kala duduwan. Waxaynu soo bandhignaynaa baarlamaanka hoos-rasmi ah, islamarkaasna baaritaanka faa'iidada ku saabsan arimaha baaritaanka oo dhan. Sidoo kale waxaynu wargelinaynaa imtixaanka baaritaanka dheer oo ku saabsan doorashada muusikada ee PUD, iyo dhibaatada ku saabsan qoraalka UD.", 'sv': 'Denna uppsats beskriver LIMSI:s bidrag till CoNLL 2017 UD Shared Task, som fokuserar på små trädbanker, och hur man kan förbättra lågresurstolkning endast genom ad hoc-kombination av flera vyer och resurser. Vi presenterar vårt tillvägagångssätt för lågresursanalys, tillsammans med en detaljerad analys av resultaten för varje test trädbank. Vi rapporterar även omfattande analysexperiment på modellval för PUD-trädbackarna, och på annotationskonsistens bland UD-trädbackarna.', 'si': 'මේ පැත්තේ LIMSI ගේ සම්පූර්ණය CoNLL 2017 UD සම්පූර්ණ වැඩක් විතරයි, ඒක පුංචි ට්\u200dරෙබැන්ක්ස් වලට අවධානය කරනවා, සහ කොහොමද අඩු සම්පූර්ණ විශ අපි පරීක්ෂණ විශ්ලේෂණය සඳහා අපේ ප්\u200dරමාණයක් පෙන්වන්න, හැම පරීක්ෂණ විශ්ලේෂණයක්ම සමග විස්තර විශ් අපි පරීක්ෂණය කරනවා PUD ට්\u200dරීබැන්ක් වලට තෝරාගන්න මදුල් තෝරාගන්න සහ UD ට්\u200dරීබැන්ක් වලට ප්\u200dරශ්නය විශාල පරීක', 'ta': 'இந்த காக்கிதத்தை குறிப்பிடுகிறது LIMSI கோன்எல் 2017 UD பகிர்ந்த பணிக்கு அனுப்பப்படுகிறது, அது சிறிய மூலங்கள் மீது கவனம் செலுத்தப்படுகிறது, மற்றும் எவ்வாறு குற நாம் குறைந்த மூலம் பாடலுக்கு எங்கள் அணுகும் வழியை காண்பிக்கிறோம், ஒவ்வொரு சோதனையின் முடிவுகளின் விளைவான ஆய நாம் PUD தேர்வு மாதிரி தேர்வு மீது விரிவான ஆய்வு சோதனைகளை அறிவிக்கிறோம் மற்றும் UD ட்ரீப்பாங்குகளில் ஒத்திசையா', 'ur': "This paper describes LIMSI's submission to the CoNLL 2017 UD Shared Task, which is focused on small treebanks, and how to improve low-resource parsing only by ad hoc combination of multiple views and resources. ہم اپنے طریقے کو کم رسسورٹ پارسینگ کے لئے پیش کرتے ہیں، اور ہر امتحان ٹریبنک کے لئے نتائج کا تفصیل کے ساتھ۔ ہم نے PUD ٹریبنک کے لئے مدل انتخاب کے بارے میں بڑی تحلیل کی آزمائش بھی گزاری کریں، اور UD ٹریبنک کے درمیان اظہار کی اتصال پر بھی گزاری ہے.", 'uz': 'Бу саҳифа LIMSI бутун маълумотни CONLL 2017 бутун маълумотларга мувофиқ вазифа кўрсатади, у кичик терминалларга мувофиқ кўриб ва манфаатларга мувофиқ муҳокама бўлиб туради, аммо кам манфаатли парламент таркиб қилиш мумкин. Biz bir sinov darajadagi natijalari haqida qanchalik nazar qilamiz. Bu yerda biz PUD treebanklarning modelini tanlash uchun kengaytirish imtiyozlarini hisoblash va UD treebanklarning orasidagi bir qanday taʼrif qilamiz.', 'vi': 'Tờ giấy này mô tả s ự nộp đơn của LISII vào hoạt động Đồng bộ Colt Wl7, tập trung vào các giá nhỏ, và làm thế nào để cải thiện việc phân tích ít nguồn lực chỉ bằng một sự kết hợp nhiều quan điểm và tài nguyên. Chúng tôi giới thiệu phương pháp phân tích ít nguồn, cùng với một phân tích chi tiết về kết quả cho mỗi lần thử nghiệm. Chúng tôi cũng báo cáo các thí nghiệm phân tích đầy đủ về mô hình tuyển dụng bóng cây DOM và về độ đồng nhất chú thích giữa bô UD.', 'bg': 'Тази статия описва представянето на ЛИМСИ към споделената задача, която е фокусирана върху малки дървесни ленти и как да подобри анализирането с ниски ресурси само чрез ad hoc комбинация от множество изгледи и ресурси. Представяме подхода си за анализ с нисък ресурс, заедно с подробен анализ на резултатите за всеки тест трибънк. Също така докладваме обширни експерименти за анализ на избора на модели за дървесни ленти и за консистенцията на анотацията между дървесни ленти.', 'nl': "Dit document beschrijft LIMSI's inzending aan de CoNLL 2017 UD Shared Task, die is gericht op kleine boombanken, en hoe low-resourced parsing alleen kan worden verbeterd door ad hoc combinatie van meerdere views en bronnen. We presenteren onze aanpak voor low-resourced parsing, samen met een gedetailleerde analyse van de resultaten voor elke testboombank. We rapporteren ook uitgebreide analyseexperimenten over modelselectie voor de PUD boombanken en over annotatieconsistentie tussen UD boombanken.", 'da': "Denne artikel beskriver LIMSI's indsendelse til CoNLL 2017 UD Shared Task, som er fokuseret på små træbanker, og hvordan man forbedrer lav ressource parsing kun ved ad hoc kombination af flere visninger og ressourcer. Vi præsenterer vores tilgang til parsing med lave ressourcer sammen med en detaljeret analyse af resultaterne for hver testtræbank. Vi rapporterer også omfattende analyseeksperimenter med modelvalg til PUD-træbænkene, og om annotationskonsistens blandt UD-træbækkene.", 'de': "Dieses Papier beschreibt LIMSI's Einreichung an die CoNLL 2017 UD Shared Task, die sich auf kleine Baumbänke konzentriert, und wie man Low-Resourced Parsing nur durch Ad-hoc-Kombination mehrerer Ansichten und Ressourcen verbessern kann. Wir stellen unseren Ansatz für ressourcenarmes Parsen vor, zusammen mit einer detaillierten Analyse der Ergebnisse für jede Testbaumbank. Wir berichten auch über umfangreiche Analyseexperimente zur Modellauswahl für die PUD-Baumbänke und zur Annotationskonsistenz unter UD-Baumbänken.", 'hr': 'Ovaj papir opisuje podnošenje LIMSI podijeljenom zadatku CoNLL 2017 UD-a, koji je usredotočen na male područje i kako poboljšati manje resurse analiziranje samo ad hoc kombinacijom višestrukih pogleda i resursa. Predstavljamo naš pristup analiziranju niskih resursa, zajedno s detaljnom analiziranjem rezultata za svaku testnu obalu. Također prijavljujemo široke analiziranje eksperimenata o odabiru modela PUD treebankova i o konsekvenciji annotacije između UD treebankova.', 'fa': 'این کاغذ تحویل LIMSI را به کار مشترک UD CoNLL 2017 توصیف می\u200cکند، که روی تخته\u200cهای کوچک تمرکز می\u200cشود، و چگونه تحویل\u200cکننده\u200cهای منابع کم را فقط با ترکیب ad hoc از دیدگاه\u200cهای متعدد و منابع بهبود می\u200cدهد. ما روش خودمون را برای تجزیه کردن کمترین منابع با تحلیل جزئیح نتیجه\u200cهای هر قطب آزمایش نشان می\u200cدهیم. ما همچنین آزمایشات تحلیل زیادی را در مورد انتخاب مدل برای تخت\u200cهای درخت PUD گزارش می\u200cدهیم، و در مورد تعامل توضیح بین تخت\u200cهای UD را گزارش می\u200cدهیم.', 'sw': 'Gazeti hili linaelezea ujumbe wa LIMSI wa chama cha CoNLL 2017 UD kilichoshirikishwa, ambacho kinajikita kwenye viwanja vidogo vya mitatu, na jinsi ya kuboresha uchimbaji wa mizigo yenye rasmi ya chini pekee kwa muunganiko mkubwa wa maoni na rasilimali mbalimbali. Tunajaribu mbinu yetu kwa ajili ya wimbo wa chini wa rasilimali, pamoja na uchambuzi wa matokeo ya kila miti ya jaribio. Pia tunaripoti majaribio makubwa ya uchambuzi kuhusu uchaguzi wa model kwa ajili ya viwanja vya PUD, na kwa uchunguzi unaohusiana na miti ya UD.', 'tr': "Bu kagyz LIMSI'i흫 CoNLL 2017-nji 첵yldaky UD Pa첵la힊y힊 G철revine g철nderildigini, ki챌i 챌yzgy힊lar barada fokus ed첵채n, we di흫e birn채챌e g철rn철힊 we 챌e힊meleri흫 ad hoc birle힊mesi bilen 첵eterle힊iklik pa첵la힊maklygyny tana첵ar. Biz d체힊체k resour챌ylyk 챌yzygyny흫 첵arymyny bilen test 챌yzygyny흫 netijelerini detaylar 챌철z체mle힊dir첵채ris. Biz hem PUD 챌ubuqlary 체챌in 철r채n sa첵lamak 체챌in uly 챌철z체mleme deneylerini we UD 챌ubuqlary흫 arasynda du첵durmany흫 bardygyny bildirip 첵철redik.", 'id': 'Kertas ini menjelaskan pengiriman LIMSI ke Tugas Berkongsi CoNLL 2017, yang fokus pada pangkalan pohon kecil, dan bagaimana untuk meningkatkan pengiriman sumber daya rendah hanya dengan kombinasi ad hoc dari berbagai pandangan dan sumber daya. Kami mempersembahkan pendekatan kita untuk penganalisis sumber rendah, bersama dengan analisis rinci dari hasil untuk setiap batang pohon tes. Kami juga melaporkan eksperimen analisis ekstensif pada pemilihan model untuk batang pohon PUD, dan pada konsistensi anotasi antara batang pohon UD.', 'af': "Hierdie papier beskrywe LIMSI se onderskrywing na die CoNLL 2017 UD Gedeelde Opdrag, wat is fokus op klein treebanks, en hoe om lae- hulpbron verhoog te maak slegs deur ad hoc kombinasie van veelvuldige aansigte en hulpbronne te verbeter. Ons voorsien ons toegang vir lae-hulpbron verwerking, saam met 'n gedetale analiseer van die resultate vir elke toets treebank. Ons rapporteer ook uitbreidige analiseerde eksperimente op model keuse vir die PUD treebanks, en op annotasie konsistensie onder UD treebanks.", 'ko': '본고는 LIMSI가 CoNLL 2017 UD 공유 임무에 제출된 상황을 묘사하는데 이 임무의 중점은 소형 트리 라이브러리와 여러 개의 보기와 자원을 임시로 조합함으로써 자원 부족의 해석을 개선하는 데 있다.우리는 우리의 저자원 분석 방법을 소개하고 모든 테스트 트리 라이브러리의 결과를 상세하게 분석했다.또한 PUD 트리 라이브러리의 모델 선택과 UD 트리 라이브러리 간의 주석 일치성에 대한 광범위한 분석 실험도 보고했습니다.', 'am': 'ይህ ገጽ የኢሊሜስI አካባቢ ለኮንஎல_2017የኦዲ አካባቢ ስራዎችን የሚያሳውቃት ነው፡፡ ይህም ትልቅ መሠረት ታናሽ ነው፡፡ የዝናብ ሰፊ ማኅበረሰብ እናቀርባታለን፣ ለሁሉም ፈተና የቴርብክ ክፍተቶችን እናሳውቃለን፡፡ በPUD ድረ ገበሮች ላይ እና በUD treebank መካከል በተቃውሞ የሞዴል ምርጫዎችን እናስታውሳለን፡፡', 'hy': "This paper describes LIMSI's submission to the CoNLL 2017 UD Shared Task, which is focused on small treebanks, and how to improve low-resourced parsing only by ad hoc combination of multiple views and resources.  Մենք ներկայացնում ենք մեր մոտեցումը ցածր ռեսուրսների վերլուծության համար, միասին յուրաքանչյուր փորձարկման ծառի արդյունքների մանրամասն վերլուծության հետ: Մենք նաև տեղեկացնում ենք էքսպանսիվ վերլուծության փորձարկումներ, որոնք վերաբերում են POD-ի ծառերի մոդելների ընտրությանը և UD-ի ծառերի մոդելների համապատասխանությունը:", 'az': "Bu kağıt, LIMSI'nin CoNLL 2017-ci UD paylaşılmış Task ə təsdiqlənməsini, kiçik çubuqlar üzərində fokus edilmiş və çoxlu görünüş və kaynaqların ad hoc kombinatsiyası ilə düşük resursu analizi necə yaxşılaşdırılmasını təsdiqləyir. Biz hər test çubuğunun sonuçlarının detaylı analizi ilə düşük ressurs analizi üçün tərzimizi göstəririk. Biz də PUD çubuqların modeli seçimləri və UD çubuqların arasındakı nöqtəsizlik müəyyən edilməsi barəsində geniş analiz təcrübələrini xəbər veririk.", 'sq': 'Ky dokument përshkruan paraqitjen e LIMSI në Detyrën e Përbashkët të CoNLL 2017 UD, e cila është përqëndruar në bazat e pemëve të vogla dhe si të përmirësohet analizimi me burime të ulta vetëm me kombinimin ad hoc të pamjeve dhe burimeve të shumta. Ne paraqesim qasjen tonë për analizimin me burime të ulta, së bashku me një analizë të hollësishme të rezultateve për çdo bazë druri. Ne raportojmë gjithashtu eksperimente të gjerë analize mbi zgjedhjen e modelit për bazat e pemëve PUD dhe mbi konsistencën e anotacionit midis bazave të pemëve UD.', 'bn': 'এই প্রবন্ধে লিএমআই ২০১৭ সালের কনএল ২০১৭ উডি শেয়ার করা কাজের প্রতি জমা দিয়েছে, যা ছোট ট্রিব্যাংকের দিকে মনোযোগ দেয়া হয়েছে, আর কিভাবে কেবল বিজ্ঞাপনী দৃষ্টি আমরা নিম্ন সম্পদ পার্জিং এর জন্য আমাদের পদক্ষেপ উপস্থাপন করি, একসাথে প্রত্যেক পরীক্ষার ফলাফলের বিস্তারিত বিশ্লেষণ। এছাড়াও আমরা পিউডি ত্রিব্যাংকের জন্য মডেল নির্বাচনের পরীক্ষার বিস্তারিত পরীক্ষা প্রতিবেদন প্রদান করি এবং উডি ট্রিব্যাংকের', 'ca': "Aquest paper descriu la presentació de LIMSI a la CoNLL 2017 UD Shared Task, centrada en petits bancs d'arbres, i com millorar l'analització amb baixos recursos només combinant múltiples vistes i recursos ad hoc. Presentam el nostre enfocament per a l'analització de baixos recursos, juntament amb una anàlisi detallada dels resultats de cada banc d'arbres de prova. També informem d'extensos experiments d'anàlisi sobre la selecció de models per a les bancs d'arbres PUD, i sobre la consistencia d'anotació entre les bancs d'arbres UD.", 'cs': 'Tento článek popisuje podání LIMSI do sdílené úlohy CoNLL 2017 UD, která je zaměřena na malé stromové břehy, a jak zlepšit analýzu s nízkými zdroji pouze ad hoc kombinací více zobrazení a zdrojů. Představujeme náš přístup k analýze nízkých zdrojů společně s detailní analýzou výsledků pro každou zkušební břeh stromů. Dále uvádíme rozsáhlé experimenty analýzy výběru modelu pro PUD stromové břehy a konzistence anotací mezi UD stromovými břehy.', 'et': "Käesolevas dokumendis kirjeldatakse LIMSI esitamist CoNLL 2017 UD Shared Task'ile, mis keskendub väikestele puupankadele ja kuidas parandada madala ressursiga parsimist ainult mitme vaate ja ressursi ad hoc kombinatsiooni abil. Esitleme oma lähenemisviisi madala ressursiga parsimisele koos iga katsepanga tulemuste üksikasjaliku analüüsiga. Samuti anname aru ulatuslikest analüüsikatsetest mudelite valimisel PUD puupankade jaoks ja annotatsiooni konsistentsi UD puupankade vahel.", 'fi': 'Tässä artikkelissa kuvataan LIMSI:n osallistumista CoNLL 2017 UD Shared Task -tehtävään, joka keskittyy pieniin puupalkkeihin, ja miten vähävaraista jäsennystä voidaan parantaa vain useiden näkymien ja resurssien ad hoc -yhdistelmällä. Esittelemme lähestymistapamme vähävaraiseen parsaukseen sekä yksityiskohtaisen analyysin kunkin testipuupankin tuloksista. Raportoimme myös laajoja analyysikokeita PUD-puiden mallivalinnasta ja UD-puiden huomautusten johdonmukaisuudesta.', 'bs': 'Ovaj papir opisuje podnošenje LIMSI na zadatak CoNLL 2017, koji je usredotočen na male područje i kako poboljšati manje resurse analiziranje samo ad hoc kombinacijom višestrukih pogleda i resursa. Predstavljamo naš pristup analiziranju niskih resursa, zajedno sa detaljnom analiziranjem rezultata za svaku testnu granicu. Također izvješćujemo široke analize eksperimente o modelu selekcije za PUD treebancije, i o konsekvenciji annotacije između UD treebancija.', 'jv': 'Perintah iki rambarang kelas LISMI nggawe CoNLL 1997 udah Kejaratan task, iki dadi wis diputara cara-cara nggawe barang, lan pejana iso nggawe hasil cara-cara perusahaan juara dhéwé, mengko iso nggawe alamat sekondiki oleh iso nggawe persilanggo lan alamat oleh nggawe persilanggo. Awak dhéwé nglanggar aturan kanggo kelas-nesaturan kanggo ditambalo Awak dhéwé nglembégal éntuk éntuk akeh cara-éntuk anyar neng model kanggo nggawe barang nggawe barang puD, lan nggo nggawe layang seneng dipunalan cara-brang UT.', 'sk': 'V tem prispevku je opisana predložitev LIMSI za skupno nalogo CoNLL 2017 UD Shared Task, ki se osredotoča na majhne drevesne plošče, in kako izboljšati razčlenjevanje z nizkimi viri le z ad hoc kombinacijo več pogledov in virov. Predstavljamo naš pristop za razčlenitev z nizkimi viri, skupaj s podrobno analizo rezultatov za vsako testno drevesno ploščo. Poročamo tudi obsežne analizne poskuse izbire modelov za PUD drevesne plošče in konsistentnosti označevanja med UD drevesne plošče.', 'he': 'העיתון הזה מתאר את ההעברה של LIMSI למשימה המשותפת של CoNLL 2017 UD, שמוקדמת על גבי עצים קטנים, ואיך לשפר בדיקת משאבים נמוכים רק על ידי שילוב ad hoc של מבטים רבים ומשאבים. אנו מציגים את הגישה שלנו לאבחן משאבים נמוכים, יחד עם ניתוח פרטי של התוצאות לכל עץ מבחן. אנחנו גם מדווחים על ניסויים ניתוח רחבים על בחירת מודל לבנקי עץ PUD, ועל התקבלות הערות בין שבנקי עץ UD.', 'ha': "Wannan takardan na describe LIMI'a iyar da shirin aiki na CoNLL 2017 UD, wanda aka yi makini a kan wuri masu ƙarami, kuma yadda ya kyautata parparse na wuri-resource kawai da ad hoc koma mai haɗiya ga mistakardu da resource. Tuna sami mataimakanmu ga parsin da aka rautar da shi, da rabo daki-daki na fassarar matsalar ga duk jarrabo. Za sami tuna bayani ga jarrabai masu ƙaranci a kan shirin ayuka na sami-zaɓen shirin sami na PUD, da kuma a kan taƙaitar da sami mai daidaita tsakanin na UD.", 'bo': 'ཤོག ང་ཚོས་རང་ཉིད་ཀྱི་གཟུགས་རིས་ཉུང་བའི་དབྱེ་ཞིབ་འཇུག་བྱེད་ཀྱི་ཐབས་ལམ་ལ་མཉམ་དུ་བསྡད་ཡོད། ང་ཚོས་PUD དབྱིབས་དབྱིབས་དབྱིབས་ཞིབ་དཔྱད་བརྗོད་ཚད་ལ་ཆེ་རུ་ཞིབ་དཔྱད་བྱེད་ཀྱི་ཡོད།'}
{'en': 'RACAI’s Natural Language Processing pipeline for Universal Dependencies', 'ar': 'خط أنابيب معالجة اللغة الطبيعية في RACAI للاعتماد العالمي', 'es': 'Canalización de procesamiento del lenguaje natural de RACAI para dependencias universales', 'fr': 'Le pipeline de traitement du langage naturel de RACAI pour les dépendances universelles', 'pt': 'Pipeline de processamento de linguagem natural da RACAI para dependências universais', 'ja': 'RACAIのユニバーサル依存性のための自然言語処理パイプライン', 'hi': 'यूनिवर्सल निर्भरताओं के लिए RACAI की प्राकृतिक भाषा प्रसंस्करण पाइपलाइन', 'zh': 'RACAI 通用自然语言管道', 'ru': 'Конвейер обработки естественного языка RACAI для универсальных зависимостей', 'ga': 'Píblíne Próiseála Teanga Nádúrtha RACAI le haghaidh Spleáchais Uilíocha', 'ka': 'RACAI-ის ნაირადი ენის პროცესი პროცესი უნივერსოლური განსაზღვრებებისთვის', 'hu': 'A RACAI természetes nyelvfeldolgozás csővezetéke az univerzális függőségekhez', 'el': 'Ο αγωγός επεξεργασίας φυσικής γλώσσας του RACAI για καθολικές εξαρτήσεις', 'it': 'Pipeline di elaborazione del linguaggio naturale RACAI per le dipendenze universali', 'mk': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'ms': 'Jalur paip Pemprosesan Bahasa Alami RACAI untuk Dependensi Universal', 'kk': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'lt': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'ml': 'സാധാരണ ഭാഷ പ്രവര്\u200dത്തനപ്രക്രിയയുടെ പൈപ്പെലിന്\u200d യൂണിവല്\u200d ആശ്രയിക്കുന്നതിനുള്ള RACAI', 'mt': 'Il-pipeline tal-ipproċessar tal-lingwi naturali tar-RACAI għad-Dipendenzi Universali', 'mn': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'ro': 'Conducta RACAI de procesare a limbajului natural pentru dependențele universale', 'sr': 'RACAI prirodni jezik obrađivanje kanala za univerzalne zavisnosti', 'pl': 'Pipeline przetwarzania języka naturalnego RACAI dla uniwersalnych zależności', 'no': 'RACAI sin naturleg språk- handteringsrøyr for universelle avhengighet', 'so': "RACAI's natural language Processing pipeline for Universal dependencies", 'ta': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'sv': 'RACAI:s Natural Language Processing pipeline för universella beroenden', 'si': "RACAI's Native language processing tube for Universal Dependencies", 'ur': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'uz': 'Name', 'vi': 'Ủy ban xử lý ngôn ngữ tự nhiên của Hội Bảo Hiểm Chung', 'da': "RACAI's Natural Language Processing pipeline til universelle afhængigheder", 'hr': 'RACAI prirodni jezik obrađivanje cijevi za univerzalne zavisnosti', 'bg': 'Процедура за обработка на естествени езици на РАКАИ за универсални зависимости', 'nl': "RACAI's Natural Language Processing pipeline voor universele afhankelijkheden", 'ko': 'RACAI의 공통 의존성 자연 언어 처리 파이프', 'sw': 'Nchi ya lugha ya asili ya RACAI inayoendeshwa kwa ajili ya kutegemea ulimwengu', 'tr': "RACAI'nin Dabiýal Dili Umumiy Baýlaşlary üçin işlemek pipeti", 'de': 'RACAIs Natural Language Processing Pipeline für universelle Abhängigkeiten', 'sq': "RRACAI's Natural Language Processing pipeline for Universal Dependencies", 'id': 'Pipa Proses Bahasa Alam RACAI untuk Dependensi Universal', 'af': 'RACAI se Natuurlike Taal Verwerking Pipellyn vir Universele Afhanklikhede', 'fa': 'لوله\u200cی پردازش زبان طبیعی RACAI برای بستگی جهانی', 'hy': 'RACAI-ի բնական լեզուների մշակույթը համաշխարհային կախվածությունների համար', 'bs': 'RACAI prirodni jezik procesirajući cijev za univerzalne zavisnosti', 'az': "RACAI's Natural Language Processing pipeline for Universal Dependencies", 'bn': 'সার্ভারেল ভাষার প্রক্রিয়ার পাইপেলাইন', 'cs': 'Pipeline zpracování přirozeného jazyka RACAI pro univerzální závislosti', 'et': 'RACAI looduskeele töötlemise toru universaalsete sõltuvuste jaoks', 'am': "RACAI's Natural language Processing pipeline for Universal Dependences", 'ca': 'El pipeline de Procesament de Llingua Natural de RACAI per a Dependencies Universal s', 'fi': 'RACAin luonnollisen kielen prosessointiputki yleismaailmallisille riippuvuuksille', 'jv': 'Rasa Kenal Perusahaan Ubah Habangkat kanggo Keamanan Universal', 'he': 'צינור מעבדת שפת טבעית של RACAI עבור תלויות יוניברסליות', 'ha': 'KCharselect unicode block name', 'sk': 'Cevovod RACAI za obdelavo naravnega jezika za univerzalne odvisnosti', 'bo': "RACAI's Natural Language Processing pipeline for Universal Dependencies"}
{'en': 'This paper presents RACAI’s approach, experiments and results at CONLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies. We handle raw text and we cover tokenization, sentence splitting, word segmentation, tagging, lemmatization and parsing. All results are reported under strict training, development and testing conditions, in which the corpora provided for the shared tasks is used as is, without any modifications to the composition of the train and development sets.', 'ar': 'تعرض هذه الورقة نهج RACAI وتجاربها ونتائجها في CONLL 2017 المهمة المشتركة: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. نتعامل مع النص الخام ونغطي الترميز ، وتقسيم الجملة ، وتجزئة الكلمات ، ووضع العلامات ، والتحليل اللغوي ، والتحليل. يتم الإبلاغ عن جميع النتائج في ظل ظروف تدريب وتطوير واختبار صارمة ، حيث يتم استخدام المجموعة المقدمة للمهام المشتركة "كما هي" ، دون أي تعديلات على تكوين مجموعات التدريب والتطوير.', 'pt': 'Este artigo apresenta a abordagem, experimentos e resultados do RACAI na tarefa compartilhada CONLL 2017: análise multilíngue de texto bruto para dependências universais. Lidamos com texto bruto e cobrimos tokenização, divisão de frases, segmentação de palavras, marcação, lematização e análise. Todos os resultados são reportados sob estritas condições de treinamento, desenvolvimento e teste, em que os corpora previstos para as tarefas compartilhadas são utilizados “como estão”, sem nenhuma modificação na composição dos conjuntos de treinamento e desenvolvimento.', 'fr': "Cet article présente l'approche, les expériences et les résultats de RACAI lors de la tâche partagée CONLL 2017\xa0: Multilingual Parsing from Raw Text to Universal Dependencies. Nous gérons le texte brut et nous couvrons la tokenisation, le fractionnement de phrases, la segmentation des mots, le balisage, la lemmatisation et l'analyse syntaxique. Tous les résultats sont rapportés dans des conditions strictes de formation, de développement et de test, dans lesquelles les corpus fournis pour les tâches partagées sont utilisés «\xa0tels quels\xa0», sans aucune modification de la composition du train et des ensembles de développement.", 'es': 'Este artículo presenta el enfoque, los experimentos y los resultados de RACAI en CONLL 2017 Shared Task: Multilingüe Parsing from Raw Text to Universal Dependencies. Manejamos el texto sin procesar y cubrimos la tokenización, la división de oraciones, la segmentación de palabras, el etiquetado, la lematización y el análisis. Todos los resultados se informan bajo estrictas condiciones de entrenamiento, desarrollo y prueba, en las que los cuerpos proporcionados para las tareas compartidas se utilizan «tal cual», sin ninguna modificación en la composición de los conjuntos de entrenamiento y desarrollo.', 'ja': 'この論文は、CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal DependenciesにおけるRACAIのアプローチ、実験、結果を紹介している。生のテキストを処理し、トークン化、文の分割、単語のセグメンテーション、タグ付け、レマティゼーション、構文解析をカバーします。すべての結果は、厳格なトレーニング、開発、およびテスト条件の下で報告され、共有タスクのために提供されたコーパスは、トレインと開発セットの構成に変更を加えることなく「現状のまま」使用されます。', 'zh': '本文言RACAI在CONLL 2017共享之法,实验与终始文本至通用多言解析。 我理本,我涵盖标,句拆分,分词,标,词形还原析。 凡训练、开试以闻,其供共事者语料库如故事而无所改。', 'hi': 'यह पेपर RACAI के दृष्टिकोण, प्रयोगों और परिणामों को CONLL 2017 साझा कार्य में प्रस्तुत करता है: रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग। हम कच्चे पाठ को संभालते हैं और हम टोकनीकरण, वाक्य विभाजन, शब्द विभाजन, टैगिंग, लेमेटाइजेशन और पार्सिंग को कवर करते हैं। सभी परिणामों को सख्त प्रशिक्षण, विकास और परीक्षण स्थितियों के तहत रिपोर्ट किया जाता है, जिसमें साझा कार्यों के लिए प्रदान किए गए कॉर्पोरेट का उपयोग "जैसा है" किया जाता है, ट्रेन और विकास सेट की संरचना में किसी भी संशोधन के बिना।', 'ru': 'В этой статье представлен подход, эксперименты и результаты RACAI на CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Мы обрабатываем необработанный текст и покрываем токенизацию, разделение предложений, сегментацию слов, тегирование, лемматизацию и синтаксический анализ. Все результаты сообщаются в строгих условиях обучения, разработки и тестирования, в которых корпорации, предоставленные для общих задач, используются «как есть», без каких-либо изменений в составе наборов поездов и разработок.', 'ga': 'Cuireann an páipéar seo cur chuige, turgnaimh agus torthaí RACAI i láthair ag CONLL 2017 Tasc Comhroinnte: Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch. Láimhseálann muid téacs amh agus clúdaíonn muid tokenization, scoilteadh abairtí, deighilt focal, clibeáil, lemmatization agus parsáil. Tuairiscítear na torthaí go léir faoi dhianchoinníollacha oiliúna, forbartha agus tástála, ina n-úsáidtear “mar atá” an corpora dá bhforáiltear do na tascanna comhroinnte, gan aon mhodhnú ar chomhdhéanamh na foirne traenach agus forbartha.', 'ka': 'ამ დოკუმენტი RACAI-ის პროგრამის, ექსპერიმენტების და შემდეგ CONLL 2017-ის გაყოფილი დავალების შესახებ: მრავალენგური პარამენტის შესახებ ტექსტიდან უნივერსალური დასახებ ჩვენ ვაკეთებთ წყველა ტექსტი და ჩვენ ვაკეთებთ ტოკენიზაცია, სიტყვების გაყოფილება, სიტყვების გაყოფილება, სიტყვების გაყოფილება, ლემეტიზაცია და გაა ყველა შედეგი შემდეგი შესაბამისი შესაბამისი განაკლება, განვითარება და ტესტის შესახებ, რომლებიც კოპორა, რომლებიც განაკეთებული საზოგადომი საქმედების გამოყენება "როგორც არის", არაფერ', 'el': 'Η παρούσα εργασία παρουσιάζει την προσέγγιση, τα πειράματα και τα αποτελέσματα του στην Κοινή Εργασία: Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Αντιμετωπίζουμε ακατέργαστο κείμενο και καλύπτουμε την επισήμανση, τον διαχωρισμό προτάσεων, την τμηματοποίηση λέξεων, την επισήμανση, την λεμματοποίηση και την ανάλυση. Όλα τα αποτελέσματα αναφέρονται υπό αυστηρές συνθήκες εκπαίδευσης, ανάπτυξης και δοκιμών, στις οποίες τα σώματα που παρέχονται για τις κοινές εργασίες χρησιμοποιούνται "ως έχουν", χωρίς καμία τροποποίηση στη σύνθεση της αμαξοστοιχίας και των συνόλων ανάπτυξης.', 'hu': 'A tanulmány bemutatja a RACAI megközelítését, kísérleteit és eredményeit a CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependences című konferencián. Kezeljük a nyers szövegeket és foglalkozunk tokenizációval, mondatszegmentációval, szószegmentálással, címkézéssel, lemmatizálással és elemzéssel. Minden eredményt szigorú képzési, fejlesztési és tesztelési körülmények között jelentenek be, amelyek során a megosztott feladatokra rendelkezésre álló társaságokat "ahogy vannak", a vonat és a fejlesztési készletek összetételének módosítása nélkül használják.', 'kk': 'Бұл қағаз RACAI жағдайын, эксперименттерді және нәтижелерін CONLL 2017 ортақ тапсырмасында көрсетеді: Қара мәтіннен бірнеше тілді талдау әлемдік тәуелдіктерге дейін. Біз жазылған мәтінді басып, токенизациялау, сөздерді бөлу, сөздерді бөлу, тегтерді, лиммациялау және талдау жасаймыз. Барлық нәтижелері қиын оқыту, жасау және сынақтау шарттарында хабарлады, бұл жерде ортақ тапсырмалар үшін корпора қолданылады, олардың тұмандық және жасау баптауларының құрылысына өзгерті', 'lt': 'Šiame dokumente pristatomas RACAI metodas, eksperimentai ir rezultatai CONLL 2017 bendroje užduotyje: daugiakalbis analizavimas nuo žaliavinio teksto iki universaliųjų priklausomybių. We handle raw text and we cover tokenization, sentence splitting, word segmentation, tagging, lemmatization and parsing.  Visi rezultatai pateikiami griežtomis mokymo, rengimo ir bandymų sąlygomis, kuriomis naudojamas „taip pat“ bendras užduotis atliekantis korporas, nekeičiant traukinio ir plėtros komplektų sudėties.', 'ms': "Kertas ini memperkenalkan pendekatan, eksperimen dan keputusan RACAI pada Tugas Berkongsi CONLL 2017: Menghurai Berbahasa Dari Teks Raw ke Dependensi Universal. Kami menangani teks mentah dan kami menutupi tokenization, pembahagian kalimat, segmentasi perkataan, tag, lemmatization dan penghuraian. Semua keputusan dilaporkan di bawah keadaan latihan, pembangunan dan ujian yang ketat, di mana corpora yang disediakan untuk tugas berkongsi digunakan 'seperti ini', tanpa sebarang perubahan kepada komposisi set kereta api dan pembangunan.", 'it': 'Questo articolo presenta l\'approccio, gli esperimenti e i risultati di RACAI al CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependences. Gestiamo il testo grezzo e copriamo tokenizzazione, frazionamento di frasi, segmentazione di parole, tagging, lemmatizzazione e parsing. Tutti i risultati sono riportati in condizioni rigorose di formazione, sviluppo e collaudo, in cui i corpi forniti per i compiti condivisi sono utilizzati "così com\'è", senza alcuna modifica alla composizione del treno e dei set di sviluppo.', 'mk': "Овој весник го претставува пристапот, експериментите и резултатите на RACAI на CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Работиме со суров текст и покриваме токенизација, поделба на реченици, сегментација на зборови, означување, лематизација и анализирање. All results are reported under strict training, development and testing conditions, in which the corpora provided for the shared tasks is used 'as is', without any modifications to the composition of the train and development sets.", 'ml': 'ഈ പത്രത്തില്\u200d റാക്കിയുടെ പരീക്ഷണങ്ങള്\u200d, പരീക്ഷണങ്ങളും ഫലങ്ങളും കോണ്\u200dഎല്\u200d 2017 പങ്കുചേര്\u200dത്ത ജോലിയില്\u200d നിന്ന് കാണിക്കുന്നു: റോ ലേഖനം മുതല്\u200d  വാക്ക് വേര്\u200dപെടുത്തുന്നത് കൈകാര്യം ചെയ്യുന്നു. വാക്കുകള്\u200d വേര്\u200dതിരിക്കുന്നത്, വേര്\u200dതിരിച്ചുവെക്കുന്നത്, ടാ എല്ലാ ഫലങ്ങളും കഠിനമായ പരിശീലനത്തിനും പരീക്ഷിക്കുന്നതിനും കീഴില്\u200d റിപ്പോര്\u200dട്ട് ചെയ്യുന്നു. പങ്കുചേര്\u200dക്കുന്ന ജോലികള്\u200dക്കായി കോര്\u200dപ്പോ', 'mt': 'Dan id-dokument jippreżenta l-approċċ, l-esperimenti u r-riżultati tar-RACAI fil-Kompitu Konġunt CONLL 2017: Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali. Aħna nżommu t-test mhux ipproċessat u nkopru t-tokenizzazzjoni, il-qsim tas-sentenzi, is-segmentazzjoni tal-kliem, it-tikkettar, il-lemmatizzazzjoni u l-analizzazzjoni. Ir-riżultati kollha huma rrappurtati taħt kundizzjonijiet stretti ta’ taħriġ, żvilupp u ttestjar, li fihom il-korpora pprovduta għall-kompiti kondiviżi tintuża “kif inhu”, mingħajr ebda modifika fil-kompożizzjoni tas-settijiet tal-ferrovija u tal-iżvilupp.', 'pl': 'Niniejszy artykuł prezentuje podejście, eksperymenty i wyniki RACAI w ramach CONLL 2017 Shared Task: Wielojęzyczna analiza tekstu surowego do uniwersalnych zależności. Zajmujemy się tekstem surowym i obejmujemy tokenizację, podział zdań, segmentację słów, tagowanie, lemmatyzację i parsowanie. Wszystkie wyniki są zgłaszane w ścisłych warunkach szkoleniowych, rozwojowych i testowych, w których korpusy przewidziane dla wspólnych zadań są wykorzystywane "tak, jak są", bez żadnych modyfikacji składu pociągu i zestawów rozwojowych.', 'no': 'Denne papiret viser RACAI sin tilnærming, eksperimenter og resultat på CONLL 2017 delt oppgåve: fleirspråk tolking frå råtekst til universelle avhengighet. Vi handterer råtekst og dekker tokenisering, setningsplitting, ordsegmentering, merking, lemmatisering og tolking. Alle resultater vert rapportert under strikt opplæring, utvikling og testforhold, der korpora som er tilgjengeleg for delte oppgåver vert brukt « som er », utan endringar til komponenten av toget og utviklingssett.', 'mn': 'Энэ цаас нь RACAI-ын арга, туршилт болон үр дүнг CONLL 2017 оны хуваалтын ажил: Raw Text-ээс олон хэлний шинжилгээ ертөнцийн хамааралтай байдаг. Бид цэвэр текстэй ажиллаж, тодорхойлолт, өгүүлбэрийг хувааж, үг хэлбэрийг, тегжинг, лемматизаци, хувааж байдаг. Бүх үр дүнг бүх сургалтын, хөгжлийн, тестийн нөхцөл байдлын дотор мэдэгдэгддэг. Корпора холбоотой ажлын төлөө хэрэглэгддэг бөгөөд тэнхлэг болон хөгжлийн бүтээгдэхүүний бүтээгдэхүүний өөрчлөл', 'ro': 'Această lucrare prezintă abordarea, experimentele și rezultatele RACAI la CONLL 2017 Shared Task: Parsing multilingv de la text brut la dependențe universale. Ne ocupăm de text brut și acoperim tokenizarea, divizarea propozițiilor, segmentarea cuvintelor, etichetarea, lemmatizarea și parsarea. Toate rezultatele sunt raportate în condiții stricte de instruire, dezvoltare și testare, în care corporele prevăzute pentru sarcinile partajate sunt utilizate "așa cum sunt", fără nicio modificare a compoziției trenului și seturilor de dezvoltare.', 'sv': 'Denna uppsats presenterar RACAI:s strategi, experiment och resultat vid CONLL 2017 Shared Task: Flerspråkig tolkning från råtext till universella beroende. Vi hanterar råtext och vi täcker tokenisering, meningsdelning, ordsegmentering, taggning, lemmatisering och tolkning. Alla resultat rapporteras under strikta utbildnings-, utvecklings- och testförhållanden, där de korpor som tillhandahålls för de delade uppgifterna används "i befintligt skick", utan några ändringar i sammansättningen av tåg och utvecklingssatser.', 'so': 'Kanu warqaddan wuxuu soo saaraa qaabilaada RACAI, imtixaanka iyo resultiyada ee CONLL 2017 Shaqada la sharciyey: Parsing luuqado badan oo ka soo baxay Raw-to Universal Assistence. Waxaynu xambaaraynaa qoraal xunxun, waxaynu ku daboolnaa calaamad, kala soocniinka, qeybinta hadalka, goosashada, korsashada iyo baaritaanka. Dhammaan resultiyada waxaa lagu soo sheegaa waxbarasho adag, horumarinta iyo imtixaanka, kaas oo shirkadaha lagu siiyo shaqada la qaybsado lagu isticmaalaa ‘sidoo kale’ iyadoon beddelin sameynta kooxda waxbarashada iyo horumarinta.', 'ur': "This paper presents RACAI's approach, experiments and results at CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. ہم روے متن کے ساتھ حملہ کرتے ہیں اور ٹوکنیزی کرتے ہیں، جماعت تقسیم کرتی ہے، لفظ تقسیم کرتی ہے، ٹاگ کرتی ہے، لیمٹیزی کرتی ہے اور پارس کرتی ہے. تمام نتائج مضبوط تعلیم، توسعہ اور آزمائش شرایطوں کے اندر گزارے جاتے ہیں، جہاں شرایط کار کے لئے پیش کیا گیا ہے، ٹرین اور توسعہ سٹوں کے سامنے کوئی بدلنے کے بغیر استعمال کیا جاتا ہے.", 'ta': 'இந்த தாள் RACAI செயல், பரிசோதனைகள் மற்றும் முடிவு நாம் குறைந்த உரையை கையாளும் மற்றும் நாம் குறிப்பிடுதல், வாக்கு, பிரிப்பு, வார்த்தை பிரிப்பு, ஒட்டு, பிரிப்பு,  எல்லா முடிவுகளும் கடினமான பயிற்சி, உருவாக்கத்தை மற்றும் சோதனைப்படுத்தும் நிலைமைகளில் அறிக்கப்படுகின்றன, அதில் பங்கிடப்பட்ட பணிகளுக்கு கொடுக', 'si': 'මේ පත්තුව RACAI ගේ ප්\u200dරවේශනය, පරීක්ෂණය සහ ප්\u200dරතිචාරය CONLL 2017 සමාගත වැඩි වැඩේ ප්\u200dරතිචාරයක් පෙන්වනවා: රාව් පාළුවන් වලින අපි පිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිපිළිප සියළු ප්\u200dරතිචාර ප්\u200dරශ්නයක්, විකාශය සහ පරීක්ෂණා අවස්ථාවක් පරීක්ෂණයක් තියෙනවා, ඒ වගේම කොර්පෝරා සම්බන්ධ වැඩ කරන්නේ', 'sr': 'Ovaj papir predstavlja pristup RACAI-a, eksperimenti i rezultate na CONLL 2017 podeljenom zadatku: Multilingual Parsing from Raw Text to Universal Dependencies. Mi vodimo sirov tekst i pokrivamo tokenizaciju, delivanje rečenica, segmentaciju rečenica, etiketiranje, limmatizaciju i parsiranje. Svi rezultati se prijavljuju pod strogim uvjetima obuke, razvoja i testiranja, u kojima se korpora predviđa zajednički zadatak koristi "kao što je", bez ikakvih izmjena kompozicije vlaka i razvoja.', 'uz': "Bu qog\xa0Ľoz RACAI orqali, tajribalarni va natijalarni CONLL 2017 bilan bog\xa0Ľliq vazifani ko\xa0Ľrsatiladi: Ray matnning ko'plab-bir tillar ta\xa0ľminlovchiga bog\xa0Ľlash. Biz qo'yish matnni boshqaramiz va so\xa0Ľzni ajratish, so\xa0Ľzni ajratish, tagging, lemmatization va parsing qilamiz. @ info", 'vi': 'Tờ giấy này trình bày cách tiếp cận, thí nghiệm và kết quả của ACLL bây bây giờ chia s ẻ Nhiệm vụ: phát ngôn từ Chữ nguyên bản cho đến môi trường chung. Chúng tôi xử lý văn bản thô và chúng tôi xử lý ký hiệu, đoạn bị chia cắt, phân đoạn từ, hiệu, bắt chước và phân tích. Tất cả kết quả được trình báo dưới những điều kiện huấn luyện, phát triển và kiểm tra nghiêm ngặt, trong đó người có trách nhiệm chia sẻ được sử dụng "như bây giờ", mà không có bất cứ thay đổi nào về cấu trúc của đoàn tàu và bộ phát triển.', 'bg': 'Настоящата статия представя подхода, експериментите и резултатите на Споделена задача: Многоезично анализиране от суров текст до универсални зависимости. Ние обработваме суров текст и обхващаме токенизация, разделяне на изречения, сегментация на думи, етикетиране, лематизация и анализ. Всички резултати се отчитат при строги условия на обучение, разработване и изпитване, при които корпусите, предвидени за споделените задачи, се използват "такива, каквито са", без никакви изменения в състава на влака и комплектите разработки.', 'da': 'Denne artikel præsenterer RACAI\'s tilgang, eksperimenter og resultater på CONLL 2017 Shared Task: Flersproget tolkning fra rå tekst til universelle afhængigheder. Vi håndterer rå tekst og vi dækker tokenisering, sætningsopdeling, ordsegmentering, tagging, lemmatisering og parsing. Alle resultater indberettes under strenge uddannelses-, udviklings- og testbetingelser, hvor de korpora, der er stillet til rådighed for de fælles opgaver, anvendes"som de er", uden ændringer af togets og udviklingssættenes sammensætning.', 'de': 'Dieser Beitrag stellt RACAIs Ansatz, Experimente und Ergebnisse bei CONLL 2017 Shared Task: Mehrsprachiges Parsing von Rohtext zu Universal Dependencies vor. Wir behandeln Rohtext und decken Tokenisierung, Satzteilung, Wortsegmentierung, Tagging, Lemmatisierung und Parsing ab. Alle Ergebnisse werden unter strengen Trainings-, Entwicklungs- und Testbedingungen gemeldet, wobei die für die gemeinsamen Aufgaben bereitgestellten Korpora "wie besehen" verwendet werden, ohne Änderungen an der Zusammensetzung des Trains und der Entwicklungssets.', 'id': "Kertas ini memperlihatkan pendekatan, eksperimen dan hasil RACAI di CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Kami menangani teks mentah dan kami menutupi tokenisasi, pemisahan kalimat, segmentasi kata, tagging, lemmatisasi dan penghuraian. Semua hasil dilaporkan di bawah kondisi latihan, pengembangan dan tes yang ketat, di mana corpora disediakan untuk tugas berbagi digunakan 'seperti ini', tanpa modifikasi apapun pada komposisi dari kereta dan set pengembangan.", 'fa': 'این کاغذ روش، آزمایش و نتیجه\u200cهای RACAI را در کار مشترک CONLL 2017 نشان می\u200cدهد: تحلیل زیادی زبان از متن Raw به بستگی جهانی. ما متن خالی را تحمل می\u200cکنیم و توکین\u200cسازی، قطع کردن جمله، قطع کردن کلمه، نقاشی، لیماتیزی و پردازی را پوشش می\u200cدهیم. تمام نتیجه\u200cها تحت تمرین، توسعه و آزمایش شدید گزارش داده می\u200cشوند، در حالی که شرکت برای کار مشترک استفاده می\u200cشود، بدون هیچ تغییری برای ساختن مجموعه قطار و توسعه استفاده می\u200cشود.', 'ko': "본고는 RACAI가 CONLL 2017 공유 작업에서의 방법, 실험과 결과를 소개했다. 원시 텍스트부터 통용적으로 의존하는 다중 언어 해석까지.우리는 표기화, 문장 분할, 분사, 표기, 레몬화, 해석을 포함한 원시 텍스트를 처리한다.모든 결과는 엄격한 교육, 개발과 테스트 조건에서 보고된 것으로 이러한 조건에서 공유 임무를 위한 자료 라이브러리는'원래대로'사용되고 교육과 개발집의 구성에 아무런 수정이 없다.", 'hr': 'Ovaj papir predstavlja pristup RACAI-a, eksperimenti i rezultate na CONLL 2017. zajedničkom zadatku: Multilingual Parsing od Raw Text-a na univerzalne zavisnosti. Mi vodimo sirov tekst i pokrivamo tokenizaciju, razdvajanje rečenica, segmentaciju riječi, označavanje, limmatizaciju i analiziranje. Svi rezultati se prijavljuju pod strogim uvjetima obuke, razvoja i testiranja, u kojima se tijela predviđa zajednički zadatak koristi "kao što je", bez ikakvih izmjena sastanka vlaka i razvoja.', 'nl': "Dit artikel presenteert RACAI's aanpak, experimenten en resultaten op CONLL 2017 Shared Task: Meertalige Parsing van ruwe tekst naar universele afhankelijkheden. We behandelen ruwe tekst en we behandelen tokenization, zinssplitsing, woordsegmentatie, tagging, lemmatisatie en parsing. Alle resultaten worden gerapporteerd onder strikte trainings-, ontwikkelings- en testvoorwaarden, waarbij de corpora's die voor de gedeelde taken worden verstrekt 'as is' gebruikt, zonder wijzigingen in de samenstelling van de trein en development sets.", 'sw': "Gazeti hili linaonyesha mbinu, majaribio na matokeo ya RACAI kwenye kazi ya CONLL 2017 iliyoambatana: Uchapishaji wa lugha kutoka Maandishi ya Raw hadi Uingereza. Tunakabili ujumbe mzuri na tunaweka taarifa, kupambanua hukumu, kutengwa kwa maneno, wimbo, unyanyasaji na wimbo. All results are reported under strict training, development and testing conditions, in which the corpora provided for the shared tasks is used 'as is', without any modifications to the composition of the train and development sets.", 'af': 'Hierdie papier stel RACAI se toegang, eksperimente en resultate by KonLL 2017 Gedeelde Opdrag: Veelvuldige verwerking van Ro Teks na Universele Afhanklikhede. Ons handvat rooi teks en ons dekk tokenisasie, setningsplitting, woord segmentasie, etiketing, lemmatisasie en verwerking. Alle resultate word verkondig onder strikte onderwerp, ontwikkeling en toets voorwaardes, waarin die korpora vir die gedeelde taak verskaf word "soos is", sonder enige veranderinge aan die opstelling van die trein en ontwikkelingsstelle.', 'tr': "Bu käze RACAI'nin yaklaşygyny, deneylerini we netijesini CONLL 2017-nji ýylda Paýlaşýan Görev: Ýöldi Diller Parsing From Raw Text to Universal Dependencies. Biz çyz metini ýöredip, sözleriň beýiklemesini, sözleriň beýiklemesini, etiketlemesini, limmatizlemesini we parslemesini öredik. Hemme netijeler çykyp bilim, gelişme we maslahat şertleri altynda görkezilýär. Şu wagtda korpora bölünýän zady üçin 'şeýle diýip' ulanýar, otlynyň we gelişme düzümleriniň üýtgetmegine hiç hili üýtgetmelidir.", 'am': "This paper presents RACAI's approach, experiments and results at CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.  ጥቁር ጽሑፎችን እናስቀምጣለን እናስታወቂያውን፣ የፍርድ ክፍል፣ የቃላትን ክፍት፣ ማጋጠም፣ ማህበረሰብ እና ማዘጋጀት እናደርጋለን፡፡ ሁሉም ፍሬቶች በጭንቅ ትምህርት፣ ትምህርት እና የመፈተኛ ጉዳይ ውስጥ ነው፣ የኮርፖርት ስራዎችን ለመጠቀም እንደሆነ ይታሰራሉ፡፡", 'az': "Bu kağıt RACAI'nin yaklaşımı, təcrübələri və sonuçlarını CONLL 2017 paylaşdırılmış Task'da göstərir: Zərr Metindən Universel bağlılıqlara çoxlu dil analizi. Biz çizgi metinləri idarə edirik və tokenizasyonu, cümlələri parçalayır, söz segmentasyonu, etiketləyirik, limmatizasyonu və analizasyonu örtürük. Bütün sonuçlar təhsil, təhsil və sınama şartları altında xəbər verilir ki, bu şərtlərin paylaşdırılmış işlər üçün korpora istifadə edilir, trenin və təhsil quruluğunun heç bir dəyişiklik olmadan.", 'bn': "এই পত্রিকাটি র\u200d্যাকাআইের পদক্ষেপ, পরীক্ষা এবং ফলাফল কনএল ২০১৭ সালে শেয়ার করা হয়েছে: রো টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করা মা আমরা ভালো লেখার মাধ্যমে কাজ করি এবং আমরা প্রত্যাখ্যান, বিভক্ত, শব্দ বিভক্ত, ট্যাগিং, লেম্যামেজেশন এবং পার্জিং এর উপর প্রক প্রশিক্ষণ, উন্নয়ন এবং পরীক্ষার পরিস্থিতির অধীনে সকল ফলাফল প্রতিবেদন প্রদান করা হয়েছে, যেখানে শেয়ার কর্মসূচীর জন্য কোর্পোরা প্রদান করেছে 'যেমনটা' ব্", 'ca': "This paper presents RACAI's approach, experiments and results at CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.  We handle raw text and we cover tokenization, sentence splitting, word segmentation, tagging, lemmatization and parsing.  All results are reported under strict training, development and testing conditions, in which the corpora provided for the shared tasks is used 'as is', without any modifications to the composition of the train and development sets.", 'sq': 'This paper presents RACAI\'s approach, experiments and results at CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.  Ne trajtojmë tekstin e papërpunuar dhe mbulojmë tokenizimin, ndarjen e fjalëve, segmentimin e fjalëve, etiketën, limmatizimin dhe analizimin. Të gjitha rezultatet janë raportuar nën kushte të ashpra trainimi, zhvillimi dhe testimi, në të cilën korpra e parashikuar për detyrat e përbashkëta përdoret "siç është", pa ndonjë ndryshim në përbërjen e grupeve të trenit dhe zhvillimit.', 'cs': 'Tento článek prezentuje přístup, experimenty a výsledky RACAI na CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Zpracováváme surový text a pokrýváme tokenizaci, dělení vět, segmentaci slov, tagování, lemmatizaci a parsování. Všechny výsledky jsou hlášeny za přísných tréninkových, vývojových a testovacích podmínek, ve kterých jsou korpusy poskytnuté pro sdílené úkoly používány "tak, jak jsou", bez jakýchkoli úprav složení vlaku a vývojových sad.', 'et': 'Käesolevas dokumendis tutvustatakse RACAI lähenemisviisi, katseid ja tulemusi konverentsil CONLL 2017 Shared Task: Mitmekeelne parsing toortekstist universaalsete sõltuvusteni. Tegeleme toortekstiga ning hõlmame tokeniseerimist, lausete jagamist, sõna segmenteerimist, sildistamist, lemmatiseerimist ja parsimist. Kõik tulemused esitatakse rangetes koolitus-, arendus- ja katsetingimustes, kus ühiste ülesannete jaoks ettenähtud korpuseid kasutatakse sellisena nagu need on, ilma rongi koosseisu ja arenduskomplektide muutmata.', 'bs': 'Ovaj papir predstavlja pristup RACAI-a, eksperimenti i rezultate na CONLL 2017-om zajedničkom zadatku: Multilingual Parsing from Raw Text to Universal Dependencies. Mi se bavimo sirovim tekstom i pokrivamo tokenizaciju, razdvajanje rečenica, segmentaciju rečenica, etiketiranje, limuziranje i analiziranje. Svi rezultati se prijavljuju pod strogim uvjetima obuke, razvoja i testiranja, u kojima se korpora predviđa zajednički zadatak koristi "kao što je", bez ikakvih izmjena sastavka seta vlaka i razvoja.', 'fi': 'Tässä artikkelissa esitellään RACAin lähestymistapa, kokeilut ja tulokset CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependences -tapahtumassa. Käsittelemme raakatekstiä ja käsittelemme tokenisaatiota, lauseiden jakamista, sanasegmentointia, tagausta, lemmatisointia ja jäsentämistä. Kaikki tulokset raportoidaan tiukassa koulutus-, kehitys- ja testausolosuhteissa, joissa yhteisiin tehtäviin tarkoitettuja korpusia käytetään sellaisenaan ilman muutoksia junan kokoonpanoon ja kehityssarjoihin.', 'hy': "This paper presents RACAI's approach, experiments and results at CONLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.  Մենք վերաբերում ենք ոչ թղթի տեքստին և ծածկում ենք նշաններ, նախադասություններ բաժանելը, բառերի բաժանելը, նշաններ, լեմմատիզացիան և վերլուծությունը: All results are reported under strict training, development and testing conditions, in which the corpora provided for the shared tasks is used 'as is', without any modifications to the composition of the train and development sets.", 'jv': "Perintah iki nggawe kelompok, perintah karo akeh barêng nang COMNLL 1997 Gebah Taaksi: Multilanguage Parasing sitaké nang rawé Text nggo Universal dependancies. Anyone Lah pejalaké dipepot ngomong nik nggawe luwih-luwih, nggunakake lan ngono ujian sing dirampa, ning kebonan kuwi tindakan babagan kelompok nggawe bener 'dadi' sing ngewehku, ora ono cah apik dhéwé, mengko iso nggawe gerakan sampeyan luwih dumadhi iki banget.", 'sk': 'Ta prispevek predstavlja pristop RACAI, poskuse in rezultate na konferenci CONLL 2017 Shared Task: Večjezično razčlenjevanje od surovega besedila do univerzalnih odvisnosti. Obravnavamo surovo besedilo in pokrivamo žetonizacijo, delitev stavkov, segmentacijo besed, označevanje, lemmatizacijo in razčlenitev. Vsi rezultati se poročajo pod strogimi pogoji usposabljanja, razvoja in preskušanja, pri čemer se korpusi, zagotovljeni za skupne naloge, uporabljajo takšni, kot so, brez kakršnih koli sprememb sestave vlakov in razvojnih sklopov.', 'he': 'העבודה הזו מציגה את הגישה, הניסויים והתוצאות של RACAI במשימה משותפת CONLL 2017: חקירה רבת-שפתית מתוך טקסט ראש לתלויות universal. אנחנו מתמודדים עם טקסט גרוע ואנחנו מכסים את הטוקניזציה, ניתוח משפטים, ניתוח מילים, תגים, לימטיזציה ומחקר. כל התוצאות מדווחות תחת תנאי אימון, פיתוח ובדיקות קשים, שבהם הקופורה מספקת עבור המשימות המשותפות משתמשת "כפי שהוא", בלי שינויים במערכת רכבת ופיתוח.', 'ha': "Wannan karatun na gaurar wa Raw Text to Universal depend. Tuna yi amfani da matsayin raw kuma munã rufe alama, tsãge, rabin magana, sigarin maganar, tagogi, salãmiya da parse. Kowane matsalar da aka sanar da shi a cikin shirin tsari mai tsanani, shirin ayuka da aka jarraba shi, inda makampuni da ke samar da aikin da ake raba su a yi amfani da 'kamar da' kuma, bã da wani gyare wa tsarin tsarin na togi da shiryoyin ayuka.", 'bo': 'RACAI ལ་ཤོག་བྱང་འདིས་གཟུགས་སྐོར་དང་། སྒེར་གྱི་གནད་སྡུད་དང་། CONLL 2017ལ་མཉམ་སྤྱོད་པའི་བྱ་ཚིག་དང་། སྐད་ཡིག་རྣམས་མེད་པའི་ཚིག We handle raw text and we cover tokenization, sentence splitting, word segmentation, tagging, lemmatization and parsing. གྲུབ་འབྲས་ཡོངས་རྫོགས་ལྡན་བཟོ་བྱེད་སྐབས་གནད་དོན་གཙོ་རིམ་དང་བརྟག་དཔྱད་བརྟན་ཞིབ་འཇུག་པ་གནང་།'}
{'en': 'Delexicalized transfer parsing for low-resource languages using transformed and combined treebanks', 'ar': 'تحليل نقل غير مكتمل للغات منخفضة الموارد باستخدام ضفاف الأشجار المحولة والمجمعة', 'pt': 'Análise de transferência deslexicalizada para linguagens de poucos recursos usando treebanks transformados e combinados', 'fr': "Analyse de transfert délexicalisée pour les langues à faibles ressources à l'aide de banques d'arbres transformées et combinées", 'es': 'Análisis de transferencia desexicalizado para lenguajes de bajos recursos mediante bancos de árboles transformados y combinados', 'ja': '変換および結合されたツリーバンクを使用した低リソース言語のためのデレクシアル化された転送構文解析', 'zh': '用转合者树库德凯化传输解析于下', 'hi': 'परिवर्तित और संयुक्त treebanks का उपयोग कर कम संसाधन भाषाओं के लिए delexicalized स्थानांतरण पार्सिंग', 'ru': 'Делексиализованный синтаксический анализ переноса для языков с низким уровнем ресурсов с использованием преобразованных и комбинированных древовидных блоков', 'ga': 'Parsáil aistrithe díleicseálach do theangacha íseal-acmhainne ag baint úsáide as bainc crann claochlaithe agus comhcheangailte', 'ka': 'Name', 'el': 'Απεξαξιοποιημένη ανάλυση μεταφοράς για γλώσσες χαμηλού πόρου χρησιμοποιώντας μετασχηματισμένες και συνδυασμένες βάσεις δέντρων', 'hu': 'Delexikalizált transzfer elemzés alacsony erőforrású nyelvekhez transzformált és kombinált fabank segítségével', 'it': 'Analisi di trasferimento delessicalizzata per linguaggi a basso contenuto di risorse utilizzando treebank trasformati e combinati', 'kk': 'Төмен ресурстар тілдеріне аударылған және біріктірілген үлесті тілдер үшін өшірілген аудару талдауы', 'lt': 'Deleksitalizuotas perdavimo analizavimas mažai išteklių turinčioms kalboms naudojant transformuotus ir kombinuotus medžių langelius', 'mk': 'Делексикализирано анализирање на трансфер за јазици со ниски ресурси користејќи трансформирани и комбинирани дрвени ленти', 'ms': 'Penghuraian pemindahan dipilih untuk bahasa sumber rendah menggunakan pangkalan pokok yang diubah dan bergabung', 'ml': 'ട്രീബാങ്കുകള്\u200d കൂട്ടിച്ചേര്\u200dത്തു് മാറ്റുകയും കൂട്ടിച്ചേര്\u200dക്കുകയും ചെയ്തു് കുറഞ്ഞ വിഭവഭാഷകള്\u200dക്ക', 'mt': 'Analiżi delegata tat-trasferimenti għal lingwi b’riżorsi baxxi bl-użu ta’ banek tas-siġar trasformati u kkombinati', 'mn': 'Өнгөрсөн болон холбогдсон загваруудыг ашиглаж буй бага боловсруулагч хэл дээр хуваалцах', 'no': 'Deleksisert tolking av overføringar for låg ressursspråk ved bruk av transformerte og kombinerte trekantar', 'pl': 'Deleksykalizowane parsowanie transferów dla języków niskich zasobów przy użyciu przekształconych i połączonych banków drzew', 'ro': 'Analizarea transferurilor delexicalizată pentru limbaje cu resurse reduse folosind brake transformate și combinate', 'sr': 'Deleksikalizirano analizanje prijenosa za jezike niskih resursa koristeći transformisane i kombinirane granice', 'so': 'Baarshaha wareejisashada ee luqadaha hoose-resource ee lagu isticmaalayo isbedelka iyo isku xiran treebanka', 'sv': 'Delexikaliserad överföringstolkning för språk med låg resurs med hjälp av omvandlade och kombinerade trädbanker', 'ta': 'Name', 'si': 'අඩුම සම්බන්ධ භාෂාව සඳහා ප්\u200dරවර්තනය සහ සම්බන්ධ වැඩසටහන් සඳහා ප්\u200dරවර්තනය කරන්න', 'ur': 'تغییر اور تری بانک کے مطابق نیچے رسورس زبانوں کے لئے منحصر کیا گیا تری نقل پارسینگ', 'uz': 'Name', 'vi': 'Phân tách chuyển nhượng cho ngôn ngữ ít tài nguyên dùng ba thay đổi và kết hợp', 'bg': 'Делексикализирано трансферно анализиране за езици с нисък ресурс, използвайки трансформирани и комбинирани дървесни ленти', 'nl': 'Delexicaliseerde transfer parsing voor low-resource talen met behulp van getransformeerde en gecombineerde boombanken', 'hr': 'Deleksikalizirano analiziranje prijenosa za jezike niskih resursa koristeći transformirane i kombinirane granice', 'da': 'Deleksiseret overførsel parsing for lav ressource sprog ved hjælp af transformerede og kombinerede træbanker', 'de': 'Delexikalisiertes Transferparsing für ressourcenarme Sprachen mit transformierten und kombinierten Baumbänken', 'ko': '변환 트리와 조합 트리를 바탕으로 하는 저자원 언어의 문법화 이동 분석', 'id': 'Pemindahan transfer delegat untuk bahasa sumber daya rendah menggunakan batang pohon yang diubah dan kombinasi', 'fa': 'پاکسازی انتقال تغییر داده شده برای زبانهای کم منبع با استفاده از تغییر داده و ترکیب کردن تغییر داده شده', 'sw': 'Hifadhi ya usafirishaji kwa lugha chini ya rasilimali kwa kutumia mabadiliko na kuunganishwa kwa miti', 'tr': 'Içi-çeşme diller üçin ön bellenen we üýtgeden çubuqlary ullan', 'sq': 'Analizimi i transferit të deleksifikuar për gjuhët me burime të ulta duke përdorur baza pemësh të transformuara dhe të kombinuara', 'af': 'Uitvee geskiedenis oordrag verwerking vir lae- hulpbron tale gebruik transformeerde en gekombineerde trebalke', 'am': 'ምስሉን በሌላ ስም አስቀምጥ', 'hy': 'Նվագ ռեսուրսներ ունեցող լեզուների վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ', 'az': 'Düşük ressurs dilləri ilə dəyişdirilmiş və birləşdirilmiş çubuqların istifadəsində silinməli transfer ayırılması', 'bn': 'ট্রিব্যাংক ব্যবহার করে নিম্ন-সম্পদ ভাষার জন্য ডেলিস্ক্যালিক্যালেশন পরিবর্তন পার্সিং করা হয়েছে', 'bs': 'Deleksikalizirano analiziranje prijenosa za jezike niskih resursa koristeći transformirane i kombinirane granice', 'ca': "Analització de transfer ències delegata per llengües de baix recursos utilitzant bancs d'arbres transformades i combinades", 'cs': 'Delexikalizovaná analýza přenosu pro jazyky s nízkými zdroji pomocí transformovaných a kombinovaných stromových bank', 'et': 'Deleksikaliseeritud ülekande parsimine vähese ressursiga keeltele, kasutades muundatud ja kombineeritud puuribasid', 'fi': 'Poistettu siirtoparsaus vähäresurssisille kielille muunnettujen ja yhdistettyjen puupalkkien avulla', 'jv': 'text-tool-action', 'ha': 'QRegExp', 'he': 'מחקר העברה דלקסיקלי לשפות משאבים נמוכות בשימוש בנקי עץ משתנים ומשולבים', 'sk': 'Deleksikalizirano razčlenjevanje prenosov za jezike z nizkimi viri z uporabo pretvorjenih in kombiniranih drevesnih zbirk', 'bo': 'བསུབ་པ་ཡོད་པའི་ཆ་རྐྱེན་ཆ་ཉུང་བའི་སྐད་རིགས་ལ་བསུབ་ནས་དབྱིབས་བཟོ་བཅོས་བྱེད་ཀྱི་ཡོད་པ'}
{'en': 'This paper describes our dependency parsing system in CoNLL-2017 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We primarily focus on the low-resource languages (surprise languages). We have developed a framework to combine multiple treebanks to train parsers for low resource languages by delexicalization method. We have applied transformation on source language treebanks based on syntactic features of the low-resource language to improve performance of the parser. In the official evaluation, our system achieves an macro-averaged LAS score of 67.61 and 37.16 on the entire blind test data and the surprise language test data respectively.', 'ar': 'تصف هذه الورقة نظام تحليل التبعية الخاص بنا في المهمة المشتركة CoNLL-2017 حول التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. نحن نركز بشكل أساسي على اللغات منخفضة الموارد (اللغات المفاجئة). لقد قمنا بتطوير إطار عمل للجمع بين العديد من بنوك الأشجار لتدريب المحللين اللغويين على اللغات منخفضة الموارد عن طريق طريقة إزالة اللغة. لقد طبقنا التحويل على البنوك الشجرية للغة المصدر استنادًا إلى الميزات النحوية للغة منخفضة الموارد لتحسين أداء المحلل اللغوي. في التقييم الرسمي ، حقق نظامنا درجة LAS بمتوسط ماكرو 67.61 و 37.16 على بيانات الاختبار الأعمى بأكملها وبيانات اختبار اللغة المفاجئة على التوالي.', 'pt': 'Este artigo descreve nosso sistema de análise de dependência na tarefa compartilhada CoNLL-2017 na análise multilíngue de texto bruto para dependências universais. Nós nos concentramos principalmente nas linguagens de poucos recursos (linguagens surpresa). Desenvolvemos uma estrutura para combinar vários bancos de árvores para treinar analisadores para linguagens de baixo recurso pelo método de deslexicalização. Aplicamos a transformação em treebanks da linguagem de origem com base em recursos sintáticos da linguagem de poucos recursos para melhorar o desempenho do analisador. Na avaliação oficial, nosso sistema alcança uma pontuação LAS com média macro de 67,61 e 37,16 em todos os dados do teste cego e nos dados do teste surpresa de idioma, respectivamente.', 'es': 'Este artículo describe nuestro sistema de análisis de dependencias en la tarea compartida de ConLL-2017 sobre el análisis multilingüe del texto sin procesar a las dependencias universales. Nos centramos principalmente en los idiomas de bajos recursos (idiomas sorpresa). Hemos desarrollado un marco para combinar varios bancos de árboles para entrenar analizadores para lenguajes de bajos recursos mediante el método de delexicalización. Hemos aplicado la transformación en los bancos de árboles del idioma de origen en función de las características sintácticas del lenguaje de bajos recursos para mejorar el rendimiento del analizador. En la evaluación oficial, nuestro sistema logra una puntuación LAS macropromediada de 67.61 y 37.16 en todos los datos de la prueba ciega y en los datos de la prueba de idioma sorpresa, respectivamente.', 'fr': "Cet article décrit notre système d'analyse des dépendances dans la tâche partagée ConLL-2017 sur l'analyse multilingue du texte brut aux dépendances universelles. Nous nous concentrons principalement sur les langues à faibles ressources (langues surprises). Nous avons développé un framework pour combiner plusieurs banques d'arbres afin de former des analyseurs pour les langues à faibles ressources par la méthode de délexicalisation. Nous avons appliqué la transformation aux banques d'arbres de la langue source en fonction des caractéristiques syntaxiques du langage à faibles ressources afin d'améliorer les performances de l'analyseur. Dans l'évaluation officielle, notre système obtient un score LAS macro-moyen de 67,61 et 37,16 sur l'ensemble des données du test à l'aveugle et des données du test de langue surprise respectivement.", 'ja': '本稿では、Raw TextからUniversal Dependenciesへの多言語構文解析に関するCoNLL -2017の共有タスクにおける依存関係解析システムについて説明する。主に低資源言語（サプライズ言語）に焦点を当てています。複数のツリーバンクを組み合わせて、低リソース言語の構文解析器をデレキシカル化法でトレーニングするフレームワークを開発しました。低リソース言語の構文機能に基づいてソース言語ツリーバンクに変換を適用し、構文解析器のパフォーマンスを向上させました。公式評価では、当社のシステムは、盲検試験データ全体とサプライズ言語試験データでそれぞれマクロ平均LASスコア67.61と37.16を達成しています。', 'hi': 'यह पेपर CoNLL-2017 में हमारी निर्भरता पार्सिंग सिस्टम का वर्णन करता है, जो रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग पर साझा कार्य करता है। हम मुख्य रूप से कम-संसाधन भाषाओं (आश्चर्य भाषाओं) पर ध्यान केंद्रित करते हैं। हमने delexicalization विधि द्वारा कम संसाधन भाषाओं के लिए पार्सर को प्रशिक्षित करने के लिए कई treebanks गठबंधन करने के लिए एक रूपरेखा विकसित की है। हमने पार्सर के प्रदर्शन में सुधार करने के लिए कम-संसाधन भाषा की वाक्यात्मक विशेषताओं के आधार पर स्रोत भाषा ट्रीबैंक पर परिवर्तन लागू किया है। आधिकारिक मूल्यांकन में, हमारी प्रणाली पूरे अंधे परीक्षण डेटा और आश्चर्य भाषा परीक्षण डेटा पर क्रमशः 67.61 और 37.16 के मैक्रो-औसत एलएएस स्कोर को प्राप्त करती है।', 'ru': 'В этой статье описывается наша система синтаксического анализа зависимостей в CoNLL-2017, разделяемая задачей по многоязычному синтаксическому анализу от необработанного текста к универсальным зависимостям. Основное внимание мы уделяем малоресурсным языкам (языкам-сюрпризам). Мы разработали структуру, объединяющую несколько берегов деревьев для обучения парсеров для языков с низким уровнем ресурсов методом делексикализации. Мы применили трансформацию на древовидных банках исходного языка на основе синтаксических особенностей языка с низким ресурсом для улучшения производительности парсера. В официальной оценке наша система достигает макроусредненного балла LAS 67,61 и 37,16 по всем данным слепого теста и данных внезапного теста языка соответственно.', 'zh': '本文言CoNLL-2017之依赖解析系统于原始文本至通用赖之多言解析务。 主注资匮之言(惊喜语)。 开一框架以合数树库,中心化去低资源言之解析器。 吾以低资源言之语法对源言树库宜转易,以崇解析器性。 官方评估,全盲测数与意外语言测试数据上分得67.6137.16OS常平分。', 'ga': 'Déanann an páipéar seo cur síos ar ár gcóras parsála spleáchais i dTasc Comhroinnte CoNLL-2017 maidir le Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch. Dírímid go príomha ar na teangacha íseal-acmhainne (teangacha iontas). Tá creat forbartha againn chun ilchúnna crann a chomhcheangal chun parsálaithe a oiliúint do theangacha íseal-acmhainne trí mhodh díleicseála. Chuireamar claochlú i bhfeidhm ar chrainn na teanga foinse bunaithe ar ghnéithe comhréire den teanga ísealacmhainne chun feidhmíocht an pharsálaí a fheabhsú. Sa mheastóireacht oifigiúil, baintear amach ár gcóras scór LAS macra-mheánmhéide de 67.61 agus 37.16 ar na sonraí tástála dall iomlána agus na sonraí tástála teanga iontas faoi seach.', 'el': 'Αυτή η εργασία περιγράφει το σύστημα ανάλυσης εξάρτησης σε κοινή εργασία για την Πολυγλωσσική Ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Εστιάζουμε κυρίως στις γλώσσες χαμηλής περιεκτικότητας (γλώσσες έκπληξης). Έχουμε αναπτύξει ένα πλαίσιο για να συνδυάσουμε πολλαπλές τράπεζες δέντρων για να εκπαιδεύσουμε αναλυτές για γλώσσες χαμηλού πόρου με μέθοδο αποπεξιkalization. Έχουμε εφαρμόσει μετασχηματισμό σε βάσεις δέντρων γλώσσας προέλευσης με βάση συντακτικά χαρακτηριστικά της γλώσσας χαμηλού πόρου για να βελτιώσουμε την απόδοση του αναλυτή. Στην επίσημη αξιολόγηση, το σύστημά μας επιτυγχάνει μια μακρομέση βαθμολογία των 67.61 και 37.16 σε όλα τα δεδομένα των τυφλών εξετάσεων και τα δεδομένα των γλωσσικών εξετάσεων έκπληξης αντίστοιχα.', 'hu': 'Ez a tanulmány bemutatja a CoNLL-2017 megosztott feladatunkat a többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig. Elsősorban az alacsony erőforrású nyelvekre (meglepetés nyelvekre) összpontosítunk. Kifejlesztettünk egy keretrendszert, amely több fabank kombinálására szolgál, hogy delexikalizációs módszerrel dolgozzák ki az alacsony erőforrású nyelveket. Az alacsony erőforrású nyelvű nyelv szintaktikai tulajdonságain alapuló transzformációt alkalmaztunk az elemző teljesítményének javítása érdekében. A hivatalos értékelés során rendszerünk makro-átlagos LAS pontszámot ér el 67,61, illetve 37,16 a teljes vakvizsgálati adatok, illetve a meglepetési nyelvvizsgálati adatok tekintetében.', 'ka': 'ეს დოკუმენტი ჩვენი შესახებ განსხვავება სისტემაში CoNLL- 2017 მრავალენგური განსხვავებაზე მრავალენგური განსხვავებაზე გაახსენებს. ჩვენ პირველად ფონსკურსირესური ენაზე (გამოვაკვირდება ენაზე). ჩვენ განვითარებეთ ფრამეტრი, რომელიც უფრო მეტად საბრძანო კომბიზაციას გავაკეთებთ, რომ პარამეტრების მცირე რესურსების ენათებისთვის დავი ჩვენ გამოყენებული ტრანფორმაცია მხოლოდ ენის სახელის სინტრაქტიკური ფუნქციებიდან დაბაზეულია, რომელიც პარასუტერის მუშაობას უფრო მხოლოდ გავაკეთ ჩვენი სისტემა შეიძლება 67,61 და 37,16 მაქრო განსაზღვრებული LAS მონაცემების მაკრო-განსაზღვრებული მონაცემების შესახებ.', 'it': "Questo articolo descrive il nostro sistema di analisi delle dipendenze nell'attività condivisa CoNLL-2017 sull'analisi multilingue dal testo grezzo alle dipendenze universali. Ci concentriamo principalmente sulle lingue a basso contenuto di risorse (lingue a sorpresa). Abbiamo sviluppato un framework per combinare più treebank per formare parser per linguaggi a basso contenuto di risorse tramite il metodo di delessicalizzazione. Abbiamo applicato la trasformazione sui treebank del linguaggio sorgente in base alle caratteristiche sintattiche del linguaggio a basso contenuto di risorse per migliorare le prestazioni del parser. Nella valutazione ufficiale, il nostro sistema raggiunge un punteggio LAS macro-medio di 67,61 e 37,16 rispettivamente su tutti i dati del test cieco e sui dati del test di lingua a sorpresa.", 'lt': 'Šiame dokumente aprašoma mūsų priklausomybės analizavimo sistema CoNLL-2017 m. bendra užduotis, susijusi su daugiakalbiu analizavimu nuo žaliavinio teksto iki universaliųjų priklausomybių. Daugiausia dėmesio skiriame mažai išteklių turinčioms kalboms (stebuklingoms kalboms). Sukurėme sistemą, pagal kurią būtų derinamos kelios medienos linijos, kuriose būtų mokomi analizatoriai mažai išteklių turinčiomis kalbomis, taikant deleksializacijos metodą. We have applied transformation on source language treebanks based on syntactic features of the low-resource language to improve performance of the parser.  Oficialaus vertinimo metu mūsų sistema pasiekia makroekonominio vidurkio LAS 67,61 ir 37,16 rezultatus, susijusius su visais aklų bandymų duomenimis ir stebuklingų kalbų bandymų duomenimis.', 'mk': 'Овој документ го опишува нашиот систем на анализирање на зависноста во CoNLL-2017 заедничка задача за повеќе јазички анализирање од суров текст до универзални зависности. Главно се фокусираме на јазиците со ниски ресурси (изненадувачки јазици). Развивме рамка за комбинирање на повеќе дрвја за обука на анализатори за јазици со ниски ресурси со метод на делексикализација. Ја применивме трансформацијата на дрвјата на изворниот јазик базирана на синтактичките карактеристики на јазикот со ниски ресурси за подобрување на перформансата на анализаторот. In the official evaluation, our system achieves an macro-averaged LAS score of 67.61 and 37.16 on the entire blind test data and the surprise language test data respectively.', 'kk': 'Бұл қағаз CoNLL- 2017 бағдарламалық талдау жүйесінің көптеген тілді талдау жүйесінің бірнеше мәтіннен Universal Dependencies бойынша ортақтастырылған тапсырманы анықтайды. Біз негізінде көп ресурстар тілдеріне назар аударып тұрмыз. Біз бірнеше аспан тілдерін біріктіру үшін бірнеше аспан тілдерін біріктіру үшін ресурс тілдерін өшіру тәсілі арқылы біріктірдік. Біз бастапқы тілдер тіліне аудару үшін талдау тілінің синтактикалық қасиеттеріне негізделген түрлендіріміз. Оригиялық оқиғанда, жүйеміз 67,61 және 37,16 макроорташа LAS нәтижесін жасайды.', 'ms': 'Kertas ini menggambarkan sistem penghuraian dependensi kami dalam tugas kongsi CoNLL-2017 mengenai penghuraian berbilang bahasa dari Teks Raw ke Kedependensi Universal. Kami terutama fokus pada bahasa sumber rendah (bahasa kejutan). We have developed a framework to combine multiple treebanks to train parsers for low resource languages by delexicalization method.  Kami telah melaksanakan pengubahan pada pangkalan pepohonan bahasa sumber berdasarkan ciri-ciri sintaktik bahasa sumber rendah untuk meningkatkan prestasi penghurai. Dalam penilaian rasmi, sistem kita mencapai nilai LAS makro-rata-rata 67.61 dan 37.16 pada seluruh data ujian buta dan data ujian bahasa kejutan berdasarkan.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ ആശ്രയിച്ച പാര്\u200dസിങ്ങ് സിസ്റ്റം കോണ്\u200dഎല്\u200d- 2017 ല്\u200d പങ്കെടുത്തിരിക്കുന്നു. റൂ ടെക്സ്റ്റ് ലേക്സില്\u200d ന നമ്മള്\u200d പ്രധാനപ്പെട്ട വിഭവങ്ങളുടെ ഭാഷകളിലേക്ക് ശ്രദ്ധിക്കുന്നു (അത്ഭുതപ്പെട്ട ഭാഷ) ഞങ്ങള്\u200d ഒരു ഫ്രെയിമ്പ് ഉണ്ടാക്കിയിരിക്കുന്നു. പല ട്രീബാങ്കുകള്\u200d കൂട്ടിക്കൊണ്ടിരിക്കുന്നതിനായി കുറഞ്ഞ വിഭവഭ സോര്\u200dസ്സ് ഭാഷ ട്രീബാങ്കുകളുടെ സിന്റാക്റ്റിക്ക് ഭാഷയുടെ സിന്\u200dട്രോര്\u200dസ്സ് ഭാഷയുടെ പ്രവര്\u200dത്തനത്തെ മെച്ചപ്പെടുത്ത ഓഫീസിലെ വിലാസങ്ങളില്\u200d, നമ്മുടെ സിസ്റ്റത്തിന്റെ മാക്രോ ശരാശരിയായ ലാഎസ് സ്കോര്\u200d 67.61, 37.16 മുഴുവന്\u200d കാഴ്ചയുള്ള പരീക്ഷണ വിവരങ്ങളും അത്', 'mt': 'This paper describes our dependency parsing system in CoNLL-2017 shared task on Multilingual Parsing from Raw Text to Universal Dependencies.  Aħna ffukaw primarjament fuq il-lingwi b’riżorsi baxxi (lingwi sorpriżi). Żviluppajna qafas biex nikkombinaw diversi banek tas-siġar biex inħarrġu l-analizzaturi għal lingwi b’riżorsi baxxi permezz ta’ metodu ta’ delessikalizzazzjoni. Applikajna trasformazzjoni fuq il-bażi tas-siġar tal-lingwa tas-sors ibbażata fuq karatteristiċi sinrattiċi tal-lingwa b’riżorsi baxxi biex tittejjeb il-prestazzjoni tal-analizzatur. Fl-evalwazzjoni uffiċjali, is-sistema tagħna tikseb punteġġ makro-medju tal-LAS ta’ 67.61 u 37.16 fuq id-dejta kollha tat-test għamja u d-dejta tat-test tal-lingwa sorpriża rispettivament.', 'mn': 'Энэ цаас CoNLL-2017 оны CoNLL-д бидний хамааралтай хуваалцааны системийг Raw Text-ээс олон хэлний хуваалцааны тухай ярьдаг. Бид ихэнхдээ бага боловсролын хэл (гайхалтай хэл) дээр анхаарлаа хандуулдаг. Бид олон зам замыг нэгтгэхэд бага нөөцийн хэлний талаар ажиллаачид сургуульд суралцах хөрөнгө оруулсан. Бид эх үүсвэрийн хэл загварын шилжилт хэрэглэсэн бөгөөд ажиллагчийн үйл ажиллагааг сайжруулахын тулд бага боловсролын хэлний синтактикийн шинжлэх ухааныг багасгасан. Шинжлэх ухаанд бидний систем 67.61, 37.16-ын макро дундаж шалгалтын мэдээлэл болон гайхалтай хэл шалгалтын мэдээлэл дээрх макро дундаж хүртдэг.', 'pl': 'Niniejszy artykuł opisuje nasz system analizowania zależności w zadaniu wspólnym CoNLL-2017 na temat analizowania wielojęzycznego z tekstu surowego do zależności uniwersalnych. Skupiamy się przede wszystkim na językach niskich zasobów (językach niespodzianek). Opracowaliśmy framework łączący wiele bank drzew w celu szkolenia parserów dla języków niskich zasobów za pomocą metody deleksykalizacji. Zastosowaliśmy transformację na bazie drzew języka źródłowego w oparciu o cechy składni języka niskiego zasobów, aby poprawić wydajność parsera. W oficjalnej ocenie nasz system osiąga makro średni wynik LAS 67.61 i 37.16 na całych danych testowych niewidomych oraz danych testowych języka niespodzianki.', 'no': 'Denne papiret beskriver avhengighetstolkingssystemet vår i CoNLL- 2017 delt oppgåve om fleirspråk tolking frå Raw Text til universelle avhengighet. Vi fokuserer hovudsakelig på låg ressursspråk (surprisespråk). Vi har utvikla eit rammeverk for å kombinere fleire trekantar for å trenja tolkarar for låg ressursspråk ved å deleksiseringsmetode. Vi har brukt transformasjon på kjeldespråk-trekantar basert på syntaktiske funksjonar på den låg ressursspråket for å forbetra utviklinga av tolkaren. I den offisielle evalueringa oppnår systemet vårt eit makro gjennomsnittt LAS-poeng med 67,61 og 37,16 på heile blinde test data og data for overraskingspråk.', 'ro': 'Această lucrare descrie sistemul nostru de analizare a dependențelor în sarcina partajată CoNLL-2017 privind analizarea multilingvă de la text brut la dependențe universale. Ne concentrăm în primul rând pe limbile cu resurse reduse (limbi surpriză). Am dezvoltat un cadru pentru a combina mai multe braebanks pentru a instrui parsere pentru limbaje cu resurse reduse prin metoda delexicalizării. Am aplicat transformarea pe treebanks-urile de limbaj sursă bazate pe caracteristicile sintactice ale limbajului cu resurse reduse pentru a îmbunătăți performanța parserului. În cadrul evaluării oficiale, sistemul nostru obține un scor LAS macro-mediu de 67,61 și 37,16 pe toate datele testului orb și, respectiv, pe datele testului surpriză de limbă.', 'sr': 'Ovaj papir opisuje naš sistem za analizu zavisnosti u CoNLL-2017 zajednièkom zadatku o multijezičkom analizu od Raw Text do univerzalnih zavisnosti. Usredotočili smo se na jezike niskih resursa (jezika iznenađenja). Razvili smo okvir za kombinaciju višestrukih granica za obuku parsera za niske jezike resursa sa metodom deleksikalizacije. Primijenili smo transformaciju na trgovinama izvornog jezika na osnovu sintaktičkih karakteristika jezika niskog resursa kako bi poboljšali provedbu analizatora. U službenoj procjeni, naš sistem postiže makro-srednji rezultat LAS od 67,61 i 37,16 o cijelim slijepim testovima i podacima iznenađenja jezika.', 'so': 'Kanu wuxuu ku qoran yahay nidaamka baaritaanka ku xiran ee ku qoran CoNLL-2017 shaqo la qaybsan jardiinada jardiinada luuqadaha badan ee Raw-Text-to-Shuruudaha jaamacadda. Sida ugu horeysa waxaynu ku kalsoonaynaa luqadaha hoose ee rasmiga ah (luqadaha la yaabo). Waxaannu horumarinnay shirkad aan u soo bandhignay dareecada badan si aan baarlamayaasha u tababarinno luqadaha hoose ee noocyada rasmiga ah, si aan u barno qaab xubin ah. Waxaannu ku codsannay beddelasho ku saleysan xarumaha luqada hoose-resource si aan u hagaajino tababarka baaritaanka. Qiimeynta rasmiga ah nidaamkayagu wuxuu gaadhaa qiyaastii baaritaanka luqada la yaab leh oo ku qoran 67.61 iyo 37.16.', 'sv': 'Denna uppsats beskriver vårt beroendeanalyssystem i CoNLL-2017 delade uppgift om flerspråkig tolkning från råtext till universella beroenden. Vi fokuserar främst på lågresursspråk (överraskningsspråk). Vi har utvecklat ett ramverk för att kombinera flera trädbanker för att utbilda tolkare för språk med låg resurs genom delexicalization metod. Vi har tillämpat transformation på källspråks treebanks baserat på syntaktiska funktioner i lågresursspråket för att förbättra tolkningens prestanda. I den officiella utvärderingen uppnår vårt system en makro-genomsnittlig LAS-poäng på 67,61 respektive 37,16 på alla blindtestdata respektive överraskningsspråkstestdata.', 'si': 'මේ පැත්තේ CoNLL- 2017 දී අපේ විශේෂතාව විශ්ලේෂණ පද්ධතිය පරීක්ෂණය විස්තර කරනවා කොන්ලි භාෂාවික විශ්ලේෂණයේ ව අපි ප්\u200dරධානයෙන්ම අඩුම භාෂාව (පුදුම භාෂාව) ගැන බලන්න. අපි ගොඩක් ට්\u200dරීබැන්ක් එකතු කරලා තියෙන්නේ ප්\u200dරශ්න භාෂාවට අඩුම භාෂාවට පරික්ෂා කරනවා කියලා. අපි මුළු භාෂාව ට්\u200dරෙබැන්ක් වලින් පහළ භාෂාව ප්\u200dරමාණය කරලා තියෙන්නේ ප්\u200dරමාණ භාෂාව ප්\u200dරමාණය කරනවා  අපේ පද්ධතියේ සාමාන්\u200dය විශ්ලේෂණයෙන්, අපේ පද්ධතියේ මැක්රෝස් අවුරුද්ධ විශ්ලේෂණයක් 67.61 සහ 37.16 පුරුදු පරීක්ෂණ දත්තේ ස', 'ta': 'This paper describes our dependency parsing system in CoNLL-2017 shared task on Multilingual Parsing from Raw Text to Universal Dependencies.  முதன்மையாக நாம் குறைந்த மூலத்தின் மொழிகளை கவனம் செலுத்துகிறோம் (ஆச்சரியமான மொழிகள்) குறைந்த மூலங்களுக்கு பார்சர்களை பயிற்சி செய்ய ஒரு சட்டம் நாம் உருவாக்கியிருக்கிறோம் பிரிவிசெலுத்தல் முறைமை குறைந்த மூலத்தின் மொழியின் செயல்பாட்டை மேம்படுத்துவதற்காக மூலம் மொழியின் மூலம் மூலப்பாங்கள் மாற்றம் செயல்படுத்தி Official evaluation, our system achieves a macro-average LAS score of 67.61 and 37.16 on the whole blind test data and the surprise language test data.', 'ur': 'This paper describes our dependency parsing system in CoNLL-2017 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. ہم سب سے زیادہ کم منبع زبانوں پر تمرکز کرتے ہیں۔ ہم نے بہت سی ٹریب بانک کو ترینس کرنے کے لئے پارس کی زبانوں کے لئے کم سرمایہ کی زبانوں کی ترینس کرنے کے لئے ایک فرم پیدا کیا ہے۔ ہم نے سراسر زبان تریب بانک پر تغییر لازم کیا ہے جو پارچر کے عملکرد کو بہتر کرنے کے لئے کم سراسر زبان کی سینٹاکسی ویٹیوں پر بنیاد ہے۔ رسمی ارزیابی میں، ہماری سیسٹم 67.61 اور 37.16 میں ایک مکرو متوسط LAS اسکور پہنچتی ہے جو تمام اندھے ٹیسٹ ڈیٹے پر ہے اور اس کی تعجب زبان امتحان ڈیٹے پر ہے۔', 'uz': "This paper describes our dependency parsing system in CoNLL-2017 shared task on Multilingual Parsing from Raw Text to Universal Dependencies.  Biz asosiy manbalar tilidan foydalanamiz. Biz bir nechta treebacha bir qatlamni birlashtirish uchun cheksiz rasm tillarini o'rganish uchun parserlarni birlashtirish uchun freymni yaratdik. Biz chegara manbalar tilining imkoniyatlarini bajarish uchun qo'llanmiz. Tasdiqlik qiymatida, bizning tizimmiz haqida hamma ko'p sinov maʼlumotlari va ajoyib tilning sinov maʼlumoti haqida 67.61 va 37.16 yordamida makro asosiy LAS scori topadi.", 'vi': 'Tờ giấy này mô tả hệ thống phân tích phụ thuộc của chúng ta trong tập đoàn CoNll-thẩm 7 chia sẻ nhiệm vụ phân tích đa ngôn ngữ từ văn bản thô đến các quan hệ chung. Chúng tôi tập trung vào các ngôn ngữ có ít nguồn (ngôn ngữ ngạc nhiên). Chúng tôi đã phát triển một cơ sở để kết hợp đa dạng máy móc để đào tạo phân tách ngôn ngữ ít tài nguyên bằng phương pháp chia sẻ. Chúng tôi đã áp dụng sự biến đổi ngôn ngữ gốc trên cơ sở bản dựa trên các tính năng cú pháp của ngôn ngữ ít tài nguyên để tăng hiệu quả của phân tách. Trong phần đánh giá chính thức, hệ thống đạt được một số lần LAS siêu lục của 67.61 và 37.16, liên quan đến dữ liệu thí nghiệm mù và kết quả kiểm tra ngôn ngữ bất ngờ.', 'bg': 'Тази статия описва нашата система за анализ на зависимостта в споделената задача за многоезично анализиране от суров текст до универсални зависимости. Фокусираме се основно върху езиците с нисък ресурс (езици изненадващи). Разработихме рамка за комбиниране на множество дървесни ленти за обучение на анализатори за езици с нисък ресурс чрез метод на делексикализация. Ние приложихме трансформация върху дървесни ленти на изходния език въз основа на синтактичните характеристики на езика с ниски ресурси, за да подобрим ефективността на анализатора. При официалната оценка нашата система постига макросреднени резултати от 67,61 и 37,16 съответно за всички данни от теста на сляпо и изненадващо езиково изпитване.', 'nl': 'Dit document beschrijft ons afhankelijkheidsparsing systeem in CoNLL-2017 gedeelde taak op Meertalig Parsen van ruwe tekst naar universele afhankelijkheden. We richten ons vooral op de low-resource talen (verrassingstalen). We hebben een framework ontwikkeld om meerdere boombanken te combineren om parsers te trainen voor low resource talen door delexicalisatiemethode. We hebben transformatie toegepast op boombanken in brontaal op basis van syntactische kenmerken van de low-resource taal om de prestaties van de parser te verbeteren. In de officiële evaluatie behaalt ons systeem een macro-gemiddelde LAS score van 67.61 en 37.16 op respectievelijk de volledige blinde testgegevens en de surprise taaltestgegevens.', 'da': 'Denne artikel beskriver vores afhængighedsanalysesystem i CoNLL-2017 delte opgave om flersproget tolkning fra rå tekst til universelle afhængigheder. Vi fokuserer primært på de lave ressourcesprog (overraskelsessprog). Vi har udviklet en ramme til at kombinere flere træbanker til at træne fortolkere til lav ressource sprog ved delekskalisering metode. Vi har anvendt transformation på kildesprog treebanks baseret på syntaktiske funktioner i lav ressource sprog for at forbedre ydeevnen af fortolkeren. I den officielle evaluering opnår vores system en makro-gennemsnitlig LAS score på 67,61 og 37,16 på alle blindtestdata og overraskelsessprogtestdata henholdsvis.', 'hr': 'Ovaj papir opisuje naš sustav analize zavisnosti u CoNLL-2017 zajedničkom zadatku o multijezičkom razmatranju od Raw teksta do univerzalnih zavisnosti. Usredotočili smo se na jezike niskih resursa (jezika iznenađenja). Razvili smo okvir za kombinaciju višestrukih kretanja za treniranje parsera za jezike niskih resursa putem deleksikalizacije. Primijenili smo transformaciju na trgovinama izvornog jezika na temelju sintaktičkih karakteristika jezika niskog resursa kako bi poboljšali učinkovitost analizatora. U službenoj procjeni naš sustav postiže makro-srednji rezultat LAS od 67,61 i 37,16 o cijelim podacima slepih testova i podacima o testu jezika iznenađenja.', 'de': 'Dieser Artikel beschreibt unser Dependency Parsing System in CoNLL-2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. Wir konzentrieren uns vor allem auf die ressourcenarmen Sprachen (Überraschungssprachen). Wir haben ein Framework entwickelt, um mehrere Baumbanken zu kombinieren, um Parser für ressourcenarme Sprachen mittels Delexikalisierungsmethode zu trainieren. Wir haben Transformationen auf Basis syntaktischer Merkmale der ressourcenarmen Sprache angewendet, um die Leistung des Parsers zu verbessern. In der offiziellen Auswertung erzielt unser System einen makro-gemittelten LAS-Score von 67.61 und 37.16 auf den gesamten Blindtestdaten bzw. den Überraschungssprachentestsdaten.', 'ko': '본고는CoNLL-2017 공유 작업 중의 의존 해석 시스템을 묘사하는데 이 작업은 원시 텍스트부터 통용적인 의존의 다중 언어 해석에 이르기까지 관련된다.우리는 주로 저자원 언어(깜짝 언어)에 주목한다.우리는 여러 개의 나무 라이브러리를 결합시켜 멕시코화 방법을 통해 저자원 언어의 해석기를 훈련시키는 프레임워크를 개발했다.우리는 저자원 언어의 문법 특징을 바탕으로 원시 언어 트리 라이브러리를 전환하여 해석기의 성능을 향상시켰다.공식 평가에서 우리 시스템이 전체 블라인드 테스트 데이터와 의외의 언어 테스트 데이터에서 거시적 평균 LAS 점수는 각각 67.61과 37.16이다.', 'id': 'Kertas ini menjelaskan sistem penghuraian dependensi kita di CoNLL-2017 tugas berbagi tentang penghuraian berbagai bahasa dari Teks Raw ke Dependensi Universal. Kami terutama fokus pada bahasa sumber daya rendah (bahasa kejutan). Kami telah mengembangkan rangkaian untuk menggabungkan beberapa batang pohon untuk melatih parser untuk bahasa sumber daya rendah dengan metode deleksialisasi. Kami telah menerapkan transformasi pada batang pohon bahasa sumber berdasarkan ciri sintaksi bahasa sumber rendah untuk meningkatkan prestasi parser. Dalam evaluasi resmi, sistem kita mencapai nilai makro-rata LAS 67,61 dan 37,16 pada seluruh data ujian buta dan data ujian bahasa kejutan.', 'fa': 'این کاغذ سیستم تجزیه بستگی ما را توصیف می\u200cکند که در کارهای CoNLL-2017 در مورد تجزیه\u200cهای زیادی زبان از متن Raw به بستگی جهانی مشترک می\u200cشود. ما در اصل روی زبانهای کم منبع تمرکز می کنیم (زبانهای سورپرایز). ما یک چهارچوب توسعه کرده ایم برای ترکیب بسیاری از چهارچوب\u200cهای درخت برای آموزش بازرسان برای زبانهای منابع کم به طریق طریق حذف\u200cسازی. ما تغییر دادن روی درختهای زبان منبع بر اساس ویژه\u200cهای سنتاکتیک زبان منبع کم برای تغییر فعالیت بازیگر را اجرا کردیم. در ارزیابی رسمی، سیستم ما یک نمونه LAS با مکرو متوسط از 67.61 و 37.16 در تمام داده\u200cهای آزمایش کور و داده\u200cهای آزمایش زبان سورپرایز را دریافت می\u200cکند.', 'sw': 'Gazeti hili linaelezea mfumo wetu wa wimbo wa maongezi huko CoNLL-2017 ulisambazwa kazi ya Uchaguzi wa lugha kutoka Maandishi ya Raw mpaka Utegemeo wa Ulimwengu. Kimsingi tunajikita kwenye lugha za rasilimali zilizo chini (lugha za kushangaza). Tumeunda mfumo wa kuunganisha vifaa vingi vya mite ili kuwafundisha wabunge kwa lugha ndogo ya rasilimali kwa njia ya uwakilishaji. We have applied transformation on source language treebanks based on syntactic features of the low-resource language to improve performance of the parser.  Katika tathmini rasmi, mfumo wetu unapata kiwango cha kiwango cha wastani cha LAS cha 67.61 na 37.16 kwa takwimu zote za vipofu na taarifa za uchunguzi wa lugha za kushangaza.', 'af': "Hierdie papier beskryf ons afhanklikheid verwerking stelsel in CoNLL- 2017 gedeelde taak op veelvuldige verwerking van Roë Teks na Universele afhanklikhede. Ons fokus voorskynlik op die lae hulpbron tale (verrassing tale). Ons het 'n raamwerk ontwikkel om veelvuldige treebanks te kombinieer om verwerkers vir lae hulpbron tale te trein deur verdeleksiksikaliseering metode. Ons het toegewend transformasie op bron taal treebanks gebaseer op sintaktika funksies van die lae hulpbron taal om die prestasie van die ontleerder te verbeter. In die offisiele evaluasie, ons stelsel bereik 'n makro-gemiddelde LAS aantal van 67.61 en 37.16 op die hele blinde toets data en die verbaastaal toets data respektief.", 'sq': 'Ky dokument përshkruan sistemin tonë të analizimit të varësisë në CoNLL-2017 detyrë të përbashkët mbi analizimin shumëgjuhës nga teksti i papërdorur në varësitë universale. Ne përqëndrohemi kryesisht në gjuhët me burime të ulëta (gjuhët e befasuara). Kemi zhvilluar një kuadër për të kombinuar shumë baza pemësh për të trajnuar analizuesit për gjuhët e ulëta të burimeve me metodën e deleksikalizimit. Ne kemi aplikuar transformimin në bazat e pemëve të gjuhës burimore bazuar në karakteristikat sintaktike të gjuhës me burime të ulëta për të përmirësuar performancën e analizuesit. Në vlerësimin zyrtar, sistemi ynë arrin një rezultat makro-mesatar LAS prej 67.61 dhe 37.16 mbi të gjitha të dhënat e testit të verbër dhe të dhënat e testit të gjuhës së befasuar respektivisht.', 'am': 'ይህ ገጽ ከረw ጽሑፍ ጀምሮ እስከ ዓለማዊ ግንኙነት ላይ በተለየ የቋንቋ ፓርቲ ስርዓታችንን በኮንLL-2017 የተጠቃሚ ስራ ይናገራል፡፡ በመጀመሪያ የምናስከትለው የክፍለ ሀብት ቋንቋዎች (የበረታች ቋንቋ) ለጥቂት የክፍለ ምዕራፍ ቋንቋዎች ለማስተማር በብዙ የዛፍ መጋረጃዎችን ለማቀናቀል ፍሬማርቶችን አቀረብን፡፡ የቋንቋ ቋንቋ-ቋንቋ በክፍለ ስህተት ላይ የተደረገውን ለውጥ በመጠቀም የዝናብ-resource ቋንቋ አካባቢ እና ተሳታፊውን ለመሻል ነው፡፡ ባለሥልጣኑ ማስታወቂያ፣ ስርዓታችን በቁጥር 67.61 እና 37.16 የዕውር ፈተና ዳታ እና የቋንቋው ፈተና ዳታዎችን በማድረግ የሆኑት የLAS ደረጃ ደረጃ ያገኛል፡፡', 'hy': 'Այս հոդվածը նկարագրում է մեր կախվածության վերլուծության համակարգը CONSL-2017-ի ընդհանուր հանձնարարությունը բազմալեզու վերլուծության մասին, որը տեղի է ունենում ոչ թվով տեքստից մինչև համաշխարհային կախվածություններ: Մենք հիմնականում կենտրոնանում ենք ցածր ռեսուրսների լեզուների վրա (զարմանալի լեզուներ): Մենք ստեղծել ենք մի շրջանակ, որպեսզի համադրենք բազմաթիվ ծառերի հիմնադրամներ՝ փորձարկումներ կազմակերպելու ցածր ռեսուրսների լեզուների համար դելեքսիկալիզացիայի մեթոդով: Մենք կիրառել ենք վերափոխություններ աղբյուր լեզվի ծառերի տախտակների վրա, հիմնված ցածր ռեսուրսների լեզվի սինտակտիկ հատկանիշների վրա վերլուծության արդյունավետության բարելավման համար: Օրիտական գնահատման ժամանակ մեր համակարգը հասնում է 67.61 և 37.16 մակրոմիջին LAS-ի գնահատականների ամբողջ կոյր փորձարկումների և հանկարծակի լեզվի փորձարկումների մասին:', 'bn': 'এই পত্রিকা কএনএল-২০১৭-এ আমাদের নির্ভরশীল পার্সিং সিস্টেমের বর্ণনা করেছে রাও টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করা হয়ে আমরা প্রাথমিকভাবে নীচের সম্পদ ভাষার উপর মনোযোগ দিচ্ছি (বিস্ময়কর ভাষা)। প্রতিনিধিত্বের মাধ্যমে কম সম্পদ ভাষার জন্য পার্সার প্রশিক্ষণের জন্য আমরা বেশ কয়েকটি ত্রিব্যাংকের সাথে সংযুক্ত করার একটি ফ্ We have applied transformation on source language treebanks based on syntactic features of the low-resource language to improve performance of the parser.  অফিসিয়াল মুল্যায়নের মধ্যে আমাদের সিস্টেম ম্যাক্রো গড়ে ল্যাস স্কোর পাওয়া যাচ্ছে পুরো অন্ধ পরীক্ষা তথ্য এবং বিস্ময়কর ভাষা পরীক্ষার ত', 'az': "Bu kağıt CoNLL-2017'də çoxlu dil Parsing haqqında bizim bağlılığımız ayırma sistemimizi yazır. Biz ilk dəfə düşük ressurs dillərinə odaqlanırıq. Biz çoxlu a ğaç çubuqlarını birləşdirmək üçün çubuqlar dillərini dəyişdirmək üçün çubuqları təhsil etdik. Biz küçük ressurs dilinin sintaktik xüsusiyyətlərinə dayanan mənbə dillərinin çubuqlarına transformasiya uyguladıq. Resmi değerlendirmədə sistemimiz 67,61 və 37,16 kör sınama məlumatlarında və təəccüblü dil sınama məlumatlarında makro-ortalamalı LAS poçundan başa düşər.", 'bs': 'Ovaj papir opisuje naš sistem analize zavisnosti u CoNLL-2017 zajedničkom zadatku o multijezičkom razmatranju od Raw Text do univerzalnih zavisnosti. Usredotočili smo se na jezike niskih resursa (jezika iznenađenja). Razvili smo okvir za kombinaciju višestrukih kretanja za treniranje parsera za niske jezike resursa pod metodom deleksikalizacije. Primijenili smo transformaciju na trgovinama izvornog jezika na temelju sintaktičkih karakteristika jezika niskog resursa kako bi poboljšali učinkovitost analizatora. U službenoj procjeni, naš sistem postiže makro-srednji rezultat LAS od 67,61 i 37,16 o cijelim slijepim testovima i podacima iznenađenja jezika.', 'ca': "Aquest article descriu el nostre sistema d'analització de dependencies de CoNLL-2017 tasca compartida en l'analització multilingüe des del text brut a les dependencies universals. Ens centrem principalment en les llengües de baix recursos (llengües sorprenents). Hem desenvolupat un marc per combinar múltiples bancs d'arbres per formar els analistes per llengües de baix recursos amb mètode de delexicalització. Hem aplicat la transformació en bancs d'arbres de llenguatges fonts basades en característiques sinàctiques del llenguatge de baix recursos per millorar el rendiment del analizador. En l'avaluació oficial, el nostre sistema aconsegueix una puntuació macromitjana de 67,61 i 37,16 en tota la data de prova cega i, respectivament, en la llengua de prova sorpresa.", 'cs': 'Tento článek popisuje náš systém analýzy závislostí ve sdíleném úkolu CoNLL-2017 na vícejazyčném analýzování z raw textu do univerzálních závislostí. Zaměřujeme se především na jazyky s nízkými zdroji (překvapivé jazyky). Vyvinuli jsme framework pro kombinaci více stromových bank k tréninku parserů pro jazyky s nízkými zdroji metodou delexikalizace. Aplikovali jsme transformaci na stromové banky zdrojového jazyka založené na syntaktických vlastnostech jazyka s nízkými zdroji, abychom zlepšili výkon parseru. Při oficiálním hodnocení dosahuje náš systém makro-průměrného LAS skóre 67.61 a 37.16 na celých slepých testovacích údajích resp. překvapivých jazykových testů.', 'fi': 'Tässä artikkelissa kuvataan riippuvuuksien jäsennysjärjestelmäämme CoNLL-2017:n yhteisessä tehtävässä monikielisestä parsing from Raw Text to Universal Dependences. Keskitymme ensisijaisesti vähävaraisiin kieliin (yllätyskieltoihin). Olemme kehittäneet viitekehyksen yhdistämään useita puupankkeja kouluttamaan jäsentäjiä vähäresurssisille kielille deleksikalisointimenetelmällä. Olemme soveltaneet muuntoa lähdekielen puupankkeihin, jotka perustuvat matalan resurssin kielen syntaktisiin ominaisuuksiin parserin suorituskyvyn parantamiseksi. Virallisessa arvioinnissa järjestelmämme saavuttaa makrokeskiarvon LAS-pisteet 67,61 ja 37,16 koko sokkotestin ja yllätyskielen testitietojen osalta.', 'et': 'Käesolevas artiklis kirjeldatakse meie sõltuvuse parsimise süsteemi CoNLL-2017 jagatud ülesandes mitmekeelse parsimise kohta toortekstist universaalseteni sõltuvusteni. Me keskendume peamiselt madala ressursiga keeltele (üllatuskeeled). Oleme välja töötanud raamistiku mitme puupunkti kombineerimiseks, et koolitada parsereid madala ressursiga keeltele deleksikaliseerimise meetodi abil. Oleme rakendanud teisendamist lähtekeele puupankadele, mis põhineb madala ressursiga keele süntaktilistel omadustel, et parandada parseri jõudlust. Ametliku hindamise käigus saavutab meie süsteem makrokeskmise LAS skoori 67,61 ja 37,16 vastavalt kogu pimetesti ja üllatuskeele testi andmete kohta.', 'tr': 'Bu kagyz CoNLL-2017-nji ýyldaky CoNLL-2017-nji ýyldaky baglanylyk analyz sistemimizi Raw Metinden Halkara Baýramçylyklary barada paylaşdyrýar. Biz esasy görä iň az resurslar dillerine üns berýäris. Bir näçe gaty gaty gaty çyzgymlary ýüze çykarmak üçin a ýdyşçylary iň az ressurs dilleri üçin birleştirmek üçin bir framlaýyp döredik. Biz çeşme dil baglaýyşlarynda çykyş edip analyzçynyň eserini geliştirmek üçin syntaktik dillerine dayanan çykyş çykyşlaryna üýtgedik. Resmi deňleşdirmede sistemamyz 67.61 we 37.16 kör testiň üstünde makro ortalamasynda ýetip biler.', 'jv': 'Perkara punika dipun nggawe akeh urip urip sistem kanggo nggawe CoNLL-1997 dipun task kanggo Multilanguage Awake dhéwé ngomong pengguna-pengguna kuwi tindang apat (pengguna luwih). Awak dhéwé éntuk sistem kanggo nggawe sistem sing wis ana karo pernik nggawe gerakan karo pernik apakno kanggo kalagayaan karo pernik nggawe Awak dhéwé wis aplikno nggawe transformasyon karo nggawe barang bangsa Nang resmi pancening offisisi, sistememuk dhéwé iso nggawe gerakan kelas macro-median sing ditambah LAS suji waé, sawar aké teka-teka sing beraksi barêng-barêng karo data sing nganggo cah-cah sing berarti kanggo nyenengaké perusahaan langkung sampek.', 'sk': 'Ta članek opisuje naš sistem razčlenitve odvisnosti v skupni opravili CoNLL-2017 o večjezičnem razčlenitvi od surovega besedila do univerzalnih odvisnosti. Osredotočamo se predvsem na jezike z nizkimi viri (jezike presenečenja). Razvili smo okvir za kombiniranje več drevesnih zbirk za usposabljanje razčlenjevalnikov za jezike z nizkimi viri z metodo deleksikalizacije. Za izboljšanje učinkovitosti razčlenjevalnika smo uporabili transformacijo na treebankah izvornega jezika, ki temelji na sintaktičnih značilnostih jezika z nizkimi viri. V uradni oceni naš sistem doseže makropovprečno LAS oceno 67,61 oziroma 37,16 na celotnih slepih testnih podatkih oziroma presenečenju jezika.', 'he': 'העיתון הזה מתאר את מערכת התמכרות שלנו במשימה משותפת CoNLL-2017 על בדיקה רבת שפותית מתוך טקסט ראש לתמכויות יוניברסליות. We primarily focus on the low-resource languages (surprise languages).  פיתחנו סגרת לשלב עצים רבים לאימון פרסמים לשפות משאבים נמוכות באמצעות שיטת דלקסיקליזציה. השתמשנו שינוי על עצי שפת המקור בהתבסס על תכונות סינטאקטיות של שפת המשאבים הנמוכים כדי לשפר את ההפעלה של המחקר. בהערכה הרשמית, המערכת שלנו משיגה נקודת LAS בממוצע מקרו של 67.61 ו-37.16 על כל נתוני מבחן עיוור ובנתוני מבחן שפת הפתעה בהתאם.', 'ha': "Wannan karatun yana bayyana maganar parse na cikin CoNLL-2017 da aka raba wani aikin da aka yi shirin da shi a kan Parse na Raw Text zuwa Universal dependanci. Tuna fokus a kan lugha masu ƙasƙanci (da ake yi wa'azi). Mun ƙãga wani firam dõmin Mu haɗa mabuɓa masu yawa dõmin su yi kõre parser wa lugha masu ƙasƙanci na resource-wuri da metoden mutane. Mun sami musanyawa a kan harshen salon da aka samu tsari masu hushi na lugha na ƙasan-resource dõmin ya kyautata aikin fassarar parser. In the official evaluation, our system achieves an macro-averaged LAS score of 67.61 and 37.16 on the entire blind test data and the surprise language test data respectively.", 'bo': 'CoNLL-2017 ནང་གི་ཤོག་བྱང་འདིས་ང་ཚོའི་རྟེན་འབྲེལ་མ་དབྱེ་སྟངས ང་ཚོས་རྒྱུ་དངོས་ཡིག་ཆ་ཉུང་བའི་སྐད་རིགས་དང་མཉམ་དུ་དམིགས་བསལ་བྱེད། ང་ཚོས་རང་ཉིད་ཀྱི་རྒྱུ་དངོས་ཐོག་ཁུངས་ལ་བསུབ་མེད་པའི་དབྱིབས་རྡེབ་མང་པོ་ཞིག་མཉམ་སྦྱར་བྱེད་ཀྱི་ཡོད། ང་ཚོས་ཐོག་མའི་སྐད་རིགས་དབྱིབས་ཀྱི་འགྱུར་བརྗོད་ནི་ལག་ལེན་འཐབ་བྱས་ཡོད་པ་དེ་ནི་དབྱེ་སྟངས་ལ་ཡར་རྒྱས་སྐྱོར གཞུང་འབྲེལ་གྱི་ཞིབ་དཔྱད་ནང་དུ་ང་ཚོའི་མ་ལག'}
{'en': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies', 'es': 'Enfoques de selección de corpus para el análisis multilingüe del texto sin procesar a las dependencias universales', 'ar': 'مناهج تحديد المجموعة للتحليل متعدد اللغات من النص الخام إلى التبعيات العامة', 'pt': 'Abordagens de seleção de corpus para análise multilíngue de texto bruto para dependências universais', 'fr': "Approches de sélection de corpus pour l'analyse multilingue du texte brut aux dépendances universelles", 'ja': '生テキストから普遍的依存関係への多言語構文解析のためのコーパス選択アプローチ', 'zh': '用原始文本至通用赖多言解析者语料库择法', 'hi': 'यूनिवर्सल निर्भरताओं के लिए कच्चे पाठ से बहुभाषी पार्सिंग के लिए कॉर्पस चयन दृष्टिकोण', 'ru': 'Подходы к выбору корпуса для многоязычного разбора от необработанного текста к универсальным зависимостям', 'ga': 'Cur Chuige Roghnúcháin Corpais maidir le Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch', 'ka': 'Name', 'it': "Approcci di selezione Corpus per l'analisi multilingue dal testo grezzo alle dipendenze universali", 'hu': 'Corpus kiválasztási megközelítések a többnyelvű értelmezéshez a nyers szövegtől az univerzális függőségekig', 'el': 'Προσεγγίσεις επιλογής σώματος για την πολύγλωσση ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις', 'lt': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies', 'mk': 'Приблизи за избор на корпус за повеќејазично анализирање од сув текст до универзални зависности', 'ms': 'Mendekati Pemilihan Corpus untuk Penghuraian Berbahasa Dari Teks Raw ke Dependensi Universal', 'kk': 'Корпус таңдау көптеген мәтіннен көп тілді талдау үшін әлемдік тәуелдіктерге қатынау арқылы', 'ml': 'കോര്\u200dപ്പുസ് തെരഞ്ഞെടുക്കുന്നതിനായി പല ഭാഷകങ്ങളുടെ പാര്\u200dസിങ്ങിലേക്ക് സമീപിക്കുന്നു', 'mt': 'Approċċi għall-Għażla tal-Korpus għall-Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali', 'no': 'Tilgang til utvalet av korpus for fleirspråk tolking frå råtekst til universelle avhengighet', 'mn': 'Бир олон хэл шалгалтын тулд биеийн сонголтын тулд олон хэл шалгалтын тулд', 'pl': 'Podejścia do wyboru korpusu dla parowania wielojęzycznego z tekstu surowego do zależności uniwersalnych', 'ro': 'Abordări de selecție Corpus pentru analizarea multilingvă de la text brut la dependențe universale', 'si': 'Name', 'sr': 'Pristupi za izbor korpusa za većinu jezičkih razmatranja od sirovog teksta do univerzalne zavisnosti', 'sv': 'Korpusval Metoder för flerspråkig tolkning från råtext till universella beroenden', 'so': 'Dalbashada Korpus waxay u dhawdahay jardiinada luuqadaha badan ee Raw Text-to Universal dependencies', 'ta': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies', 'ur': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies', 'uz': 'Name', 'vi': 'Các phương thức chọn tập thể cho khai thác ngôn ngữ rộng từ văn bản thô đến các nguồn chứa chung', 'bg': 'Подходи за избор на корпус за многоезично анализиране от суров текст до универсални зависимости', 'da': 'Korpusvalg Tilgange til flersproget tolkning fra rå tekst til universelle afhængigheder', 'de': 'Korpusselektionsansätze für mehrsprachiges Parsing von Rohtext zu universellen Abhängigkeiten', 'ko': '원시 텍스트에서 통용되는 다중 언어 문법 분석 자료 라이브러리 선택 방법', 'nl': 'Corpusselectie benaderingen voor meertalig parsen van ruwe tekst naar universele afhankelijkheden', 'fa': 'دسترسی برگزیدن کورپوس برای تحلیل چندین زبان از متن خالی به بستگی جهانی', 'id': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies', 'sw': 'Uchaguzi wa Corpus unapatikana kwa ajili ya Uchaguzi wa lugha nyingi kutoka Maandishi ya Raw hadi Kutegemea Ulimwengu', 'hr': 'Pristupi izbora korpusa za multijezičko pročitanje od sirovog teksta do univerzalne zavisnosti', 'af': 'Korpus Keuse Toegang vir Veelvuldige Toepassing van Raai Teks na Universele Afhanklikhede', 'sq': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies', 'az': 'Üstünlük Mətndən Üniversal Bağlamlıqlara Çoxlu Dil Çözümləməsi üçün Cənnət Seçimləri Yazılımlar', 'tr': 'Korpus Sa첵lawy 횉oklu Diller Ta첵첵arlamak 체챌in Wagtla첵yn Metinden 횥ni첵erli Ba첵umlyklara 첵erle힊첵채r', 'am': 'ምርጫ አጥፉ', 'ca': "Métodes de selecció de Corpus per a l'analització multilingüe des del text brut a les dependencies universals", 'bn': 'রং টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভরের জন্য কোর্পাস নির্বাচনের জন্য', 'cs': 'Přístupy výběru korpusu pro vícejazyčné analýzy od syrového textu do univerzálních závislostí', 'hy': 'Կորպուսի ընտրության մոտեցումները բազմալեզու վերլուծության համար', 'fi': 'Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependences', 'bs': 'Pristupi za izbor korpusa za multijezičko analizu od sirovog teksta do univerzalne zavisnosti', 'et': 'Corpuse valiku lähenemisviisid mitmekeelseks parsimiseks toortekstist universaalseteni sõltuvusteni', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': 'KCharselect unicode block name', 'sk': 'Pristopi za izbiro Corpusa za večjezično razčlenitev od surovega besedila do univerzalnih odvisnosti', 'he': 'הגישות לבחירה של קורפוס עבור בדיקת רבות שפות מתוך טקסט חום לתלויות יוניברסליות', 'bo': 'རྩིས་གཞུང་གི་ཡིག་གེ་ལས་མེད་པའི་ཡིག་གེ་ལ་སྣ་བརྗོད་ཀྱི་གཟུགས་འགྲོ་བར་གནང་བ་དང་།'}
{'en': 'This paper describes UALing’s approach to the CoNLL 2017 UD Shared Task using corpus selection techniques to reduce training data size. The methodology is simple : we use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting corpus to complete the parsing task. The training and parsing is done with the baseline UDPipe system (Straka et al., 2016). While our approach reduces the size of training data significantly, it retains performance within 0.5 % of the baseline system. Due to the reduction in training data size, our system performs faster than the nave, complete corpus method. Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries for this task. Our system is available at.CoNLL 2017 UD Shared Task using corpus selection techniques to reduce training data size. The methodology is simple: we use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting corpus to complete the parsing task. The training and parsing is done with the baseline UDPipe system (Straka et al., 2016). While our approach reduces the size of training data significantly, it retains performance within 0.5% of the baseline system. Due to the reduction in training data size, our system performs faster than the naïve, complete corpus method. Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries for this task. Our system is available at https://github.com/CoNLL-UD-2017/UALING. ', 'pt': 'Este artigo descreve a abordagem da UALing para a tarefa compartilhada CoNLL 2017 UD usando técnicas de seleção de corpus para reduzir o tamanho dos dados de treinamento. A metodologia é simples: usamos medidas de similaridade para selecionar um corpus de dados de treinamento disponíveis (mesmo de vários corpora para linguagens surpresa) e usamos o corpus resultante para concluir a tarefa de análise. O treinamento e a análise são feitos com o sistema UDPipe de linha de base (Straka et al., 2016). Embora nossa abordagem reduza significativamente o tamanho dos dados de treinamento, ela mantém o desempenho dentro de 0,5% do sistema de linha de base. Devido à redução no tamanho dos dados de treinamento, nosso sistema funciona mais rápido do que o método de corpus completo e ingênuo. Especificamente, nosso sistema é executado em menos de 10 minutos, classificando-o entre as entradas mais rápidas para esta tarefa. Nosso sistema está disponível em <https://github.com/CoNLL-UD-2017/UALING>.', 'ar': 'تصف هذه الورقة نهج UALing للمهمة المشتركة CoNLL 2017 UD باستخدام تقنيات اختيار المجموعة لتقليل حجم بيانات التدريب. المنهجية بسيطة: نستخدم مقاييس التشابه لاختيار مجموعة من بيانات التدريب المتاحة (حتى من مجموعات متعددة للغات المفاجئة) ونستخدم المجموعة الناتجة لإكمال مهمة التحليل. يتم التدريب والتحليل باستخدام نظام UDPipe الأساسي (Straka وآخرون ، 2016). بينما يقلل نهجنا من حجم بيانات التدريب بشكل كبير ، فإنه يحتفظ بالأداء في حدود 0.5٪ من النظام الأساسي. نظرًا لتقليص حجم بيانات التدريب ، فإن نظامنا يؤدي بشكل أسرع من طريقة الجسم الكاملة الساذجة. على وجه التحديد ، يعمل نظامنا في أقل من 10 دقائق ، مما يجعله من بين أسرع الإدخالات لهذه المهمة. نظامنا متاح على <https://github.com/CoNLL-UD-2017/UALING>.', 'es': 'Este documento describe el enfoque de UALing para la tarea compartida UD de CoNll 2017 mediante técnicas de selección de corpus para reducir el tamaño de los datos de entrenamiento. La metodología es simple: utilizamos medidas de similitud para seleccionar un corpus de los datos de entrenamiento disponibles (incluso de varios corpus para idiomas sorpresa) y utilizamos el corpus resultante para completar la tarea de análisis. El entrenamiento y el análisis se realizan con el sistema UDPipe de referencia (Straka et al., 2016). Si bien nuestro enfoque reduce significativamente el tamaño de los datos de entrenamiento, mantiene el rendimiento dentro del 0,5% del sistema de referencia. Debido a la reducción del tamaño de los datos de entrenamiento, nuestro sistema funciona más rápido que el método de corpus completo e ingenuo. Específicamente, nuestro sistema funciona en menos de 10 minutos, lo que lo sitúa entre las entradas más rápidas para esta tarea. Nuestro sistema está disponible en < https://github.com/CoNLL-UD-2017/UALING >.', 'fr': "Cet article décrit l'approche d'UAling pour la tâche partagée ConLL 2017 UD utilisant des techniques de sélection de corpus pour réduire la taille des données de formation. La méthodologie est simple\xa0: nous utilisons des mesures de similarité pour sélectionner un corpus à partir des données de formation disponibles (même à partir de plusieurs corpus pour les langages surprises) et nous utilisons le corpus résultant pour effectuer la tâche d'analyse. La formation et l'analyse sont effectuées avec le système UDPipe de base (Straka et al., 2016). Bien que notre approche réduise considérablement la taille des données d'entraînement, elle maintient les performances dans les limites de 0,5\xa0% du système de base. En raison de la réduction de la taille des données d'entraînement, notre système fonctionne plus rapidement que la méthode naïve et complète du corpus. Plus précisément, notre système fonctionne en moins de 10 minutes, ce qui le place parmi les entrées les plus rapides pour cette tâche. Notre système est disponible à l'adresse < https://github.com/CoNLL-UD-2017/UALING >.", 'zh': '本文言UALing用语料库择术以减小练数大小CoNLL 2017 UD共享之法。 其略曰:吾等用相似性度量择可用之数语料库(至择数语料库一语料库,以惊喜言语),以成语料库来成解析务。 训解析者,用基线UDPipe统成之(Straka,2016)也。 虽显减训练之大小,而性在基线统之 0.5% 内。 以训练数大小减小,我们的系统比朴素完全的语料库法行得更快。 具体来说,不及10分钟时,将其列为最疾。 我们的系统可以在<https://github.com/CoNLL-UD-2017/UALING>。', 'ja': 'この論文では、トレーニングデータサイズを縮小するためのコーパス選択技術を使用した、CoNLL 2017 UD共有タスクに対するUALingのアプローチについて説明します。方法論は簡単です。類似性測定を使用して、利用可能なトレーニングデータからコーパスを選択し（サプライズ言語のための複数のコーパスからでも）、得られたコーパスを使用して解析タスクを完了します。トレーニングと解析は、ベースラインUDPipeシステムで行われます（ Straka et al., 2016 ）。当社のアプローチは、トレーニングデータのサイズを大幅に削減しますが、ベースラインシステムの0.5%以内のパフォーマンスを維持します。トレーニングデータサイズの縮小により、当社のシステムはナイーブで完全なコーパス法よりも高速に実行されます。具体的には、当社のシステムは10分以内に動作し、このタスクの最速エントリにランク付けされます。弊社のシステムは、でご利用いただけ<https://github.com/CoNLL-UD-2017/UALING>ます。', 'hi': 'यह पेपर प्रशिक्षण डेटा आकार को कम करने के लिए कॉर्पस चयन तकनीकों का उपयोग करके CoNLL 2017 UD Shared Task के लिए UALing के दृष्टिकोण का वर्णन करता है। पद्धति सरल है: हम उपलब्ध प्रशिक्षण डेटा (यहां तक कि आश्चर्य भाषाओं के लिए कई कॉर्पोरेट से भी) से एक कॉर्पस का चयन करने के लिए समानता उपायों का उपयोग करते हैं और पार्सिंग कार्य को पूरा करने के लिए परिणामी कॉर्पस का उपयोग करते हैं। प्रशिक्षण और पार्सिंग बेसलाइन UDPipe प्रणाली (Straka et al., 2016) के साथ किया जाता है। जबकि हमारा दृष्टिकोण प्रशिक्षण डेटा के आकार को काफी कम कर देता है, यह बेसलाइन सिस्टम के 0.5% के भीतर प्रदर्शन को बरकरार रखता है। प्रशिक्षण डेटा आकार में कमी के कारण, हमारा सिस्टम भोले, पूर्ण कॉर्पस विधि की तुलना में तेजी से प्रदर्शन करता है। विशेष रूप से, हमारा सिस्टम 10 मिनट से भी कम समय में चलता है, इसे इस कार्य के लिए सबसे तेज़ प्रविष्टियों में से एक रैंकिंग देता है। हमारा सिस्टम <https://github.com/CoNLL-UD-2017/UALING> पर उपलब्ध है।', 'ru': 'В этой статье описывается подход UALing к общей задаче CoNLL 2017 UD с использованием методов отбора корпусов для уменьшения объема обучающих данных. Методология проста: мы используем показатели сходства для выбора корпуса из доступных обучающих данных (даже из нескольких корпусов для неожиданных языков) и используем полученный корпус для выполнения задачи синтаксического анализа. Обучение и разбор выполняются с помощью базовой системы UDPipe (Straka et al., 2016). Хотя наш подход значительно уменьшает объем данных обучения, он сохраняет производительность в пределах 0,5% от базовой системы. В связи с уменьшением объема обучающих данных, наша система работает быстрее, чем наивный, полный метод корпуса. В частности, наша система работает менее чем за 10 минут, ставя ее в один ряд с самыми быстрыми записями для этого задания. Наша система доступна по адресу<https://github.com/CoNLL-UD-2017/UALING>.', 'ga': 'Déanann an páipéar seo cur síos ar chur chuige UALing maidir le Tasc Comhroinnte UD CoNLL 2017 ag baint úsáide as teicnící roghnaithe corpais chun méid sonraí oiliúna a laghdú. Tá an mhodheolaíocht simplí: bainimid úsáid as bearta cosúlachta chun corpas a roghnú ó shonraí oiliúna atá ar fáil (fiú ó chorpas iolrach do theangacha iontasacha) agus úsáidimid an corpas mar thoradh air chun an tasc parsála a chur i gcrích. Déantar an oiliúint agus an pharsáil leis an gcóras bunlíne UDPipe (Straka et al., 2016). Cé go laghdaíonn ár gcur chuige méid na sonraí oiliúna go suntasach, coinníonn sé feidhmíocht laistigh de 0.5% den chóras bunlíne. Mar gheall ar an laghdú ar mhéid na sonraí oiliúna, feidhmíonn ár gcóras níos tapúla ná an modh corpais iomlán naïve. Go sonrach, ritheann ár gcóras i níos lú ná 10 nóiméad, agus é á rangú i measc na n-iontrálacha is tapúla don tasc seo. Tá ár gcóras ar fáil ag <https://github.com/CoNLL-UD-2017/UALING>.', 'ka': 'ამ დოკუმენტის შესახებ UALing-ის მიღება CoNLL 2017 UD-ის გაყოფილი დავალებისთვის, რომელიც გამოყენება კორპუსს მონიშნული ტექნოგიების გამოყენება, რომელიც შემდეგ განაკ მეტოდოლოგია უკეთესია: ჩვენ გამოყენებთ სხვადასხვა მონაცემების გამოყენებას, რომელიც შეიძლება შეიძლება სხვადასხვა მონაცემების მონაცემებიდან კორპუსს (რამდენიმე კორპორადან უ სტრაქტირება და პარასტირება დასრულია UDPipe სისტემაში (Straka et al., 2016). თუმცა ჩვენი მოხმარება უფრო მნიშვნელოვანია განაკეთებული მონაცემების ზომა, ეს უფრო მნიშვნელოვანობა 0,5% სისტემის შემდეგ. ჩვენი სისტემა უფრო ბეჭირდება, უფრო ბეჭირდება, უფრო ბეჭირდება, უფრო ბეჭირდება. განსაკუთრებულია, ჩვენი სისტემა 10 წუთით უფრო მეტად გადაწყება, რომელიც ამ დავალებისთვის ყველაზე სიჩქარე ჩანაწყება. ჩვენი სისტემა შესაძლებელია < https://github.com/CoNLL-UD-2017/UALING - ეა.', 'hu': 'Ez a tanulmány bemutatja az UALing megközelítését a CoNLL 2017 UD Shared Task alkalmazásával a korpusz kiválasztási technikákkal az edzési adatok méretének csökkentése érdekében. A módszertan egyszerű: hasonlósági mérésekkel választjuk ki a korpuszt a rendelkezésre álló képzési adatokból (akár több korpusztól is a meglepetés nyelvekhez), és az eredményekből eredő korpuszt használjuk az elemzési feladat elvégzéséhez. A képzés és elemzés az alapvető UDPipe rendszerrel történik (Straka et al., 2016). Míg megközelítésünk jelentősen csökkenti az edzési adatok méretét, a teljesítményt a kiindulási rendszer 0,5%-án belül tartja meg. Az edzési adatok méretének csökkenése miatt rendszerünk gyorsabban teljesít, mint a naiv, teljes korpusz módszer. Pontosabban, a rendszerünk kevesebb mint 10 perc alatt fut, és a feladat leggyorsabb bejegyzései közé sorolja. A rendszerünk elérhető a < https://github.com/CoNLL-UD-2017/UALING >.', 'el': 'Αυτή η εργασία περιγράφει την προσέγγιση της στην κοινή εργασία χρησιμοποιώντας τεχνικές επιλογής σώματος για τη μείωση του μεγέθους των δεδομένων κατάρτισης. Η μεθοδολογία είναι απλή: χρησιμοποιούμε μέτρα ομοιότητας για να επιλέξουμε ένα σώμα από τα διαθέσιμα δεδομένα εκπαίδευσης (ακόμη και από πολλαπλά σώματα για γλώσσες έκπληξης) και χρησιμοποιούμε το προκύπτον σώμα για να ολοκληρώσουμε την εργασία ανάλυσης. Η εκπαίδευση και ανάλυση γίνεται με το σύστημα βάσης (Στράκα κ.α., 2016). Ενώ η προσέγγισή μας μειώνει σημαντικά το μέγεθος των δεδομένων κατάρτισης, διατηρεί την απόδοση εντός 0,5% του συστήματος βάσης. Λόγω της μείωσης του μεγέθους των δεδομένων εκπαίδευσης, το σύστημά μας αποδίδει ταχύτερα από την αφελή, πλήρη μέθοδο σώματος. Συγκεκριμένα, το σύστημά μας λειτουργεί σε λιγότερο από δέκα λεπτά, ταξινομώντας το ανάμεσα στις ταχύτερες καταχωρήσεις για αυτήν την εργασία. Το σύστημά μας είναι διαθέσιμο στο < https://github.com/CoNLL-UD-2017/UALING >.', 'it': "Questo articolo descrive l'approccio di UALing al CoNLL 2017 UD Shared Task utilizzando tecniche di selezione del corpo per ridurre le dimensioni dei dati di allenamento. La metodologia è semplice: utilizziamo misure di somiglianza per selezionare un corpus dai dati di allenamento disponibili (anche da più corpora per linguaggi a sorpresa) e utilizzare il corpus risultante per completare il compito di analisi. L'allenamento e l'analisi vengono effettuati con il sistema UDPipe di base (Straka et al., 2016). Mentre il nostro approccio riduce significativamente le dimensioni dei dati di allenamento, mantiene le prestazioni entro lo 0,5% del sistema di base. Grazie alla riduzione delle dimensioni dei dati di allenamento, il nostro sistema funziona più velocemente del metodo ingenuo e completo del corpo. Nello specifico, il nostro sistema funziona in meno di 10 minuti, classificandolo tra le voci più veloci per questo compito. Il nostro sistema è disponibile all'indirizzo < https://github.com/CoNLL-UD-2017/UALING >.", 'kk': 'Бұл қағаз CoNLL 2017 UD ортақтастырылған тапсырманың UALing қасиетін корпус таңдау техникаларын өзгерту үшін деректер өлшемін азайту үшін қолданады. Бұл методология қарапайым: біз корпусты қол жеткізетін оқыту деректерінен таңдау үшін ұқсас мерзімдерін қолданамыз (бірнеше корпораттардан бірнеше қызықтық тілдер үшін де) және олардың талдау тап Бастапқы UDPipe жүйесі (Straka et al., 2016). Біздің тәсіліміздің оқыту деректерінің өлшемін өте қысқартып тұрғанда, ол негізгі жүйеңіздің 0,5% ішінде тәжірибесін сақтайды. Деректердің өлшемін төмендету сияқты, жүйеміз найтив, толық корпус әдісінен тез жұмыс істейді. Ескерту үшін, жүйеміз 10 минуттан аз орындалады. Бұл тапсырманың ең жылдам жазуларында орындалады. Біздің жүйеміз < https://github.com/CoNLL-UD-2017/UALING >.', 'mk': 'Овој документ го опишува пристапот на UALing кон Соделената задача на CoNLL 2017 UD користејќи техники за избор на корпус за намалување на големината на податоците за обука. Метологијата е едноставна: користиме мерки на сличност за да избереме корпус од достапните податоци за обука (дури и од повеќе корпуси за изненадувачки јазици) и да го користиме резултатот на корпус за да ја завршиме задачата за анализирање. Тренингот и анализирањето се завршуваат со основниот систем УДПИП (Straka et al., 2016). Иако нашиот пристап значително ја намалува големината на податоците за обука, таа ја задржува резултатот во рамките на 0,5 отсто од основниот систем. Поради намалувањето на големината на податоците за обука, нашиот систем функционира побрзо од наивниот, целосен корпус метод. Специфично, нашиот систем работи за помалку од 10 минути, рангирајќи го меѓу најбрзите записи за оваа задача. Нашиот систем е достапен на < https://github.com/CoNLL-UD-2017/UALING >.', 'lt': 'Šiame dokumente aprašomas UALing požiūris į CoNLL 2017 m. bendros UD užduotis, naudojant korpuso atrankos metodus mokymo duomenų dydžiui mažinti. Metodika paprasta: panašios priemonės naudojamos atrinkti korpusą iš turimų mokymo duomenų (net iš daugelio korpusų stebuklingoms kalboms) ir panaudoti gautą korpusą atliekant analizavimo užduotį. Mokymas ir analizavimas atliekami naudojant pradinę UDPipe sistemą (Straka et al., 2016). Nors mūsų metodas gerokai sumažina mokymo duomenų dydį, jis išlieka 0,5 % bazinės sistemos veiklos rezultatų. Dėl mokymo duomenų dydžio sumažėjimo mūsų sistema veikia greičiau nei naivus, visiškas korpuso metodas. Konkrečiai, mūsų sistema veikia per mažiau kaip 10 minučių, skirstant ją į greičiausius įrašus šiam uždaviniui. Mūsų sistema pateikiama < https://github.com/CoNLL-UD-2017/UALING >.', 'mn': 'Энэ цаас CoNLL 2017 оны UD хуваалтын ажлын тухай UALing-ын арга замыг Корпус сонголтын техникуудыг ашиглаж өгөгдлийн хэмжээ багасгах боломжтой болгон тайлбарладаг. Энэ методологи нь энгийн: бид корпус хэрэглэдэг боломжтой сургалтын мэдээллээс (олон корпоратаас ч гэсэн гайхалтай хэл дээр) холбогдолтой төстэй хэмжээсүүдийг ашиглаж, шинжилгээний ажлыг бүтээх үед корпу Боловсрол болон хуваалцах нь UDPipe системтэй дууссан. Бидний арга зам нь сургалтын өгөгдлийн хэмжээг маш чухал багасгаж байгаа ч, энэ нь суурь шугам системийн 0.5% дотор үйл ажиллагааг багасгадаг. Сургуулийн өгөгдлийн хэмжээг багасгах учраас бидний систем жинхэнэ, бүрэн корпус аргаас илүү хурдан ажилладаг. Ялангуяа бидний систем 10 минутаас бага явагдаж, үүнийг ажлын хамгийн хурдан оролцож байна. Бидний систем нь https://github.com/CoNLL-UD-2017/UALING >.', 'mt': 'Dan id-dokument jiddeskrivi l-approċċ tal-UALing għall-UNLL 2017 UD Shared Task bl-użu ta’ tekniki ta’ għażla korpus biex jitnaqqas id-daqs tad-dejta tat-taħriġ. Il-metodoloġija hija sempliċi: nużaw miżuri ta’ similarità biex nagħżlu korpus mid-dejta disponibbli ta’ taħriġ (anke minn korpuri multipli għal lingwi sorpriżi) u nużaw il-korpus li jirriżulta biex intemmu l-kompitu ta’ analiżi. It-taħriġ u l-analiżi jsiru mas-sistema UDPipe tal-linja bażi (Straka et al., 2016). Filwaqt li l-approċċ tagħna jnaqqas id-daqs tad-dejta tat-taħriġ b’mod sinifikanti, iżomm il-prestazzjoni fi ħdan 0.5% tas-sistema bażi. Minħabba t-tnaqqis fid-daqs tad-dejta tat-taħriġ, is-sistema tagħna tagħmel aktar malajr mill-metodu corpus komplet u naiv. B’mod speċifiku, is-sistema tagħna taħdem f’inqas minn 10 minuti, u tikklassifikaha fost l-eqreb entrati għal dan il-kompitu. Is-sistema tagħna hija disponibbli fuq < https://github.com/CoNLL-UD-2017/UALING >.', 'ms': 'Kertas ini menggambarkan pendekatan UALing kepada Tugas Berkongsi UD CoNLL 2017 menggunakan teknik pemilihan corpus untuk mengurangi saiz data latihan. Metodologi ini mudah: kita menggunakan tindakan persamaan untuk memilih mayat dari data latihan yang tersedia (walaupun dari mayat berbilang untuk bahasa kejutan) dan menggunakan mayat yang berasal untuk menyelesaikan tugas penghuraian. Latihan dan penghuraian dilakukan dengan sistem UDPipe asas (Straka et al., 2016). While our approach reduces the size of training data significantly, it retains performance within 0.5% of the baseline system.  Kerana mengurangi saiz data latihan, sistem kita berfungsi lebih cepat dari kaedah corpus yang naif. Secara khusus, sistem kita berjalan dalam kurang dari 10 minit, menandakannya diantara masukan paling cepat untuk tugas ini. Sistem kita tersedia di < https://github.com/CoNLL-UD-2017/UALING >.', 'ml': 'ഈ പത്രത്തില്\u200d കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കുചേര്\u200dത്ത പണിയിലേക്കുള്ള യുലിംഗിന്റെ നീക്കം വിവരിച്ചുകൊടുക്കുന്നു. പരിശീലനത്തി പാര്\u200dസിംഗ് ജോലി പൂര്\u200dത്തിയാക്കുവാന്\u200d ഒരു കോര്\u200dപ്പുസിനെ തെരഞ്ഞെടുക്കാന്\u200d സാധ്യതയുള്ള പരിശീലനത്തില്\u200d നിന്നും ഒരു കോര്\u200dപ്പുസിനെ ഉപയോ ഈ പരിശീലനവും പാര്\u200dസിങ്ങും ബെസ്റ്റ്ലൈന്\u200d യുഡിപിപ്പി സിസ്റ്റം കൊണ്ട് നടത്തി നമ്മുടെ പരിശീലന വിവരങ്ങളുടെ വലിപ്പം കുറവാക്കുമ്പോള്\u200d അത് ബെസ്ലൈന്\u200d സിസ്റ്റത്തില്\u200d 0.5% പ്രകടനം നിലനില്\u200dക്ക പരിശീലന വിവരങ്ങളുടെ വലിപ്പം കുറയ്ക്കുന്നതിനാല്\u200d, നമ്മുടെ സിസ്റ്റത്തിന്റെ നൈവിനെക്കാള്\u200d വേഗത്തിലാണ് പ് പ്രത്യേകിച്ച്, നമ്മുടെ സിസ്റ്റം പത്ത് മിനിട്ടിനുള്ളില്\u200d പ്രവര്\u200dത്തിക്കുന്നു, ഈ ജോലിക്കുള്ള ഏറ്റവും വേഗത ഞങ്ങളുടെ സിസ്റ്റത്തില്\u200d < https://github.com/CoNLL-UD-2017/UALING >.', 'sr': 'Ovaj papir opisuje pristup UALing za zajednički zadatak CoNLL 2017, koristeći korpusne tehnike izbora za smanjenje veličine podataka obuke. Metodologija je jednostavna: koristimo mjere sličnosti da izaberemo korpus iz dostupnih podataka o obuci (čak i iz višestruke korporacije za jezike iznenađenja) i koristimo rezultate korpusa da bi završili analizu zadatak. Treniranje i analizanje završeno je sa osnovnim UDPipe sistemom (Straka et al., 2016). Iako naš pristup značajno smanjuje veličinu podataka obuke, zadržava izvođenje unutar 0,5% početnog sistema. Zbog smanjenja veličine podataka obuke, naš sistem provodi brže od naivnog, kompletnog korpusnog metoda. Posebno, naš sistem se radi za manje od 10 minuta, u redu je među najbržim ulazima za ovaj zadatak. Naš sistem je dostupan na < https://github.com/CoNLL-UD-2017/UALING >', 'ro': 'Această lucrare descrie abordarea UALing față de CoNLL 2017 UD Shared Task folosind tehnici de selecție a corpurilor pentru a reduce dimensiunea datelor de formare. Metodologia este simplă: folosim măsuri de similitudine pentru a selecta un corpus din datele de instruire disponibile (chiar și din mai multe corpuri pentru limbi surpriză) și folosim corpul rezultat pentru a finaliza sarcina de analizare. Instruirea și analizarea se realizează cu sistemul UDPipe de bază (Straka et al., 2016). În timp ce abordarea noastră reduce semnificativ dimensiunea datelor de antrenament, menține performanța în limita a 0,5% din sistemul de referință. Datorită reducerii dimensiunii datelor de antrenament, sistemul nostru funcționează mai rapid decât metoda naivă, completă a corpului. Mai exact, sistemul nostru rulează în mai puțin de 10 minute, clasificându-l printre cele mai rapide intrări pentru această sarcină. Sistemul nostru este disponibil la < https://github.com/CoNLL-UD-2017/UALING >.', 'pl': 'Niniejszy artykuł opisuje podejście UALing do wspólnego zadania CoNLL 2017 UD z wykorzystaniem technik wyboru korpusów w celu zmniejszenia wielkości danych treningowych. Metodologia jest prosta: wykorzystujemy mierniki podobieństwa do wyboru korpusu z dostępnych danych treningowych (nawet z wielu korpusów dla języków niespodzianek) i wykorzystujemy wynikający korpus do wykonania zadania parsowania. Szkolenie i analiza odbywa się za pomocą bazowego systemu UDPipe (Straka et al., 2016). Chociaż nasze podejście znacznie zmniejsza wielkość danych treningowych, utrzymuje wydajność w granicach 0,5% systemu bazowego. Ze względu na zmniejszenie wielkości danych treningowych nasz system działa szybciej niż naiwna, kompletna metoda korpusu. W szczególności nasz system działa w mniej niż dziesięć minut, klasyfikując go wśród najszybszych wpisów do tego zadania. Nasz system jest dostępny pod adresem < https://github.com/CoNLL-UD-2017/UALING >.', 'no': 'Denne papiret beskriver UALing tilnærminga til CoNLL 2017 UD-delt oppgåve ved hjelp av corpus-utvalsteknikk for å redusera opplæringsstorleik på opplæringar. Metodologien er enkelt: vi brukar tilsvarande måtar for å velja ein korpus frå tilgjengelege treningsdata (sjølv frå fleire korporar for overraska språk) og brukar korpusen til å fullføra tolkingspråket. Øvinga og tolking er ferdig med UDPipe-system et (Straka et al., 2016). Mens tilnærminga vårt reduserer storleiken på opplæringsdata betydelig, beholder det utviklinga i 0,5 % av baselinjesystemet. På grunn av reduksjonen av opplæringsdatastorleiken utfører systemet vårt raskare enn den naive, fullstendige korpusmetoden. Systemet vårt køyrer i mindre enn 10 minutt og rankerer det blant dei raskeste oppføringane for denne oppgåva. Systemet vårt er tilgjengeleg på < https://github.com/CoNLL-UD-2017/UALING >', 'so': 'Warqaddan waxaa ku qoran qaabilaada UALing ee u soo jeeda CoNLL 2017 UD shaqo la sharciyey oo isticmaalaya qalabka doorashada korpus si uu u hoosayso tirada waxbarashada. Isku-qaabiyadu waa sahlan yahay: waxaynu isticmaalnaa qaababka isku mid ah si aannu uga dooranno macluumaadka waxbarashada (xataa shirkadaha qaarkood oo luqadaha la yaabeeyo) waxaana isticmaalaynaa qofka sababta ah si aan u dhamaado shaqada baaritaanka. Waxbarashada iyo baaritaanka waxaa lagu sameeyaa nidaamka UDPipe ee aasaasiga ah (Straka al., 2016). Inta lagu jiro dhaqdhaqaalahayagu uu hoosaysiiyo tirada waxbarashada si muhiim ah, waxay ku socotaa tababarka ku jirta 0.5% nidaamka aasaasiga ah. Due to the reduction in training data size, our system performs faster than the naive, complete corpus method.  Si gaar ah nidaamkayaga wuxuu ku soconayaa in ka yar 10 daqiiqood, wuxuuna ku soconayaa meelaha ugu dhaadheer shaqadaas. nidaamkayaga waxaa laga helaa https://github.com/CoNLL-UD-2017/UALING >.', 'si': 'මේ පැත්තේ UALing ගේ ප්\u200dරවේශනය CoNLL 2017 UD සමාගත වැඩක් සඳහා කොර්පස් තෝරණ ප්\u200dරවේශනය භාවිතා කරන්න ප්\u200dරවේශනය දත්ත ප්\u200dරම විදේශය සරලයි: අපි සමාන විදියට පරීක්ෂණයක් භාවිත කරන්න පුළුවන් ප්\u200dරධාන දත්තෙන් කොර්පස් එකක් තෝරගන්න (පුදුම භාෂාවක් වල ප්\u200dරේෂණය සහ විශ්ලේෂණය අවස්ථාව UDPipe පද්ධතිය (ස්ට්\u200dරාකා et al., 2016). අපේ පරීක්ෂණය විශේෂ දත්තේ ප්\u200dරමාණය අඩු කරනවා නමුත්, ඒක පරීක්ෂණ පද්ධතියේ 0.5% වලට ප්\u200dරමාණය තියාගන් අපේ පද්ධතිය නිර්මාණය, සම්පූර්ණ කොර්පුස් විදියට වඩා වේගයෙන් ඉඩ දෙනවා. විශේෂයෙන්, අපේ පද්ධතිය මිනිත්තු 10ක් වඩා පහත් වෙනවා, ඒක මේ වැඩේ ඉක්මනින් ප්\u200dරවේශනයක් ඇතුළට පහත් ව අපේ පද්ධතිය < https://github.com/CoNLL-UD-2017/UALING >', 'sv': 'Denna uppsats beskriver UALings förhållningssätt till CoNLL 2017 UD Shared Task med hjälp av korpusurvalstekniker för att minska storleken på träningsdata. Metoden är enkel: vi använder liknande mått för att välja en korpus från tillgängliga träningsdata (även från flera korpus för överraskningsspråk) och använder den resulterande korpusen för att slutföra tolkningen. Utbildningen och tolkningen görs med baseline UDPipe systemet (Straka et al., 2016). Även om vårt tillvägagångssätt minskar storleken på träningsdata avsevärt, behåller det prestanda inom 0,5% av baslinjen systemet. På grund av den minskade storleken på träningsdata presterar vårt system snabbare än den naiva, kompletta korpusmetoden. Vårt system körs på mindre än 10 minuter och rankas bland de snabbaste posterna för denna uppgift. Vårt system finns tillgängligt på < https://github.com/CoNLL-UD-2017/UALING >.', 'ta': 'இந்த காகிதத்தில் UALing செயல்பாட்டை கோன்எல் 2017 UD பகிர்ந்த பணி The methodology is simple: we use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting corpus to complete the parsing task.  பயிற்சி மற்றும் பாடல் அடிப்படையான UDPipe அமைப்புடன் செய்யப்பட்டுள்ளது (ஸ்டாகா வெட்டு அல், 2016). எங்கள் வழிமுறையில் பயிற்சி தரவுகளின் அளவை முக்கியமாக குறைக்கும் போது, அது தொடர்ந்து செயல்பாட்டை 0. 5% அடிப்படை பயிற்சி தரவு அளவின் குறைவு காரணத்தால், எங்கள் அமைப்பு நைவ் முறைமையை விட வேகமாக செயல்படுத்துகிறது. குறிப்பிட்டு, எங்கள் அமைப்பு 10 நிமிடங்களுக்கு குறைவாக இயங்குகிறது, இந்த பணிக்கு வேகமான வேகமான உள்ளீடுகளில் அத எங்கள் கணினியில் < https://github.com/CoNLL-UD-2017/UALING >.', 'ur': 'یہ کاغذ کو CONLL 2017 UD شریڈ ٹاکس کے لئے UALing کا طریقہ توصیف کرتا ہے کہ کورپوس انتخاب ٹیکنیکوں کے مطابق ترکینس ڈیٹا سائز کم کرے۔ یہ طریقہ ساده ہے: ہم ایک کورپوس کو استعمال کرتے ہیں کہ ایک کورپوس کو موجود ترینس ڈیٹے سے انتخاب کریں (اگرچہ بہت سی کورپور سے بھی تعجب زبانوں کے لئے) اور نتیجہ کورپوس کو استعمال کرتے ہیں کہ پارس کا کام پورا کرے۔ تدریس اور پارسینگ بنیس لین UDPipe سیسٹم (Straka et al., 2016) کے ساتھ کیا گیا ہے۔ اور ہماری طریقہ ڈیٹا کی اندازہ مزید کم کر رہی ہے، اس نے بنیاس لین سیسٹم کی 0.5% کے اندر عمل کو روک رکھا ہے. ہماری سیسٹم نایوب، کامل کورپوس طریقہ سے زیادہ سریع عمل کرتا ہے. خاص طور پر، ہماری سیسٹم 10 منٹوں سے کم چلتی ہے، اسے اس کام کے سب سے سریع اندر کے اندر رینگ کر رہی ہے. ہمارا سیسٹم موجود ہے https://github.com/CoNLL-UD-2017/UALING >', 'uz': "Бу саҳифа бажариш маълумотларнинг каттасини камайтириш учун қонун танланган суннатлар фойдаланиб UALing бажариши фойдаланади. Bu usuli oddiy. Biz mavjud taʼminlovchi maʼlumotni tanlash uchun bir xil kompaniyalaridan foydalanamiz va natijada parsing vazifani to ʻxtatish uchun ishlatish mumkin. Tashqi va parsing UDPip tizimi (Straka et al., 2016) asosida bajarildi. Agar bizning tilimiz taʼminlovchi maʼlumotning hajmini muhimiy kamaytirishda, bu bajarish asosiy tizimning 0.5% ichida davom etadi. Taʼminlovchi maʼlumot oʻlchamini kamaytirish sababi, bizning tizimmiz nazoratdan tez bajaradi, butun kopus usulida tez bajaradi. Ko'rsatilgan, bizning tizimmiz shu vazifa uchun eng tez yozuvlar orasidagi 10 daqiqa ichida bajaradi. Biz tizimmiz <da mavjud https://github.com/CoNLL-UD-2017/UALING >.", 'vi': 'Tờ giấy này mô tả phương pháp bố trí của Hạ Hầu Vũ đối với Công việc chia s ẻ COY7 UD, sử dụng kĩ thuật lựa chọn tập thể để giảm kích cỡ dữ liệu huấn luyện. Phương pháp này đơn giản: chúng tôi dùng phương pháp giống nhau để chọn một tập đoàn từ dữ liệu đào tạo có sẵn (thậm chí từ nhiều cơ thể cho ngôn ngữ ngạc nhiên) và sử dụng tập thể kết quả để hoàn thành nhiệm vụ phân tích. Việc huấn luyện và phân tách được thực hiện với hệ thống UDPipe (Straka et al., bây giờ). Trong khi phương pháp của chúng ta giảm đáng kể kích thước của dữ liệu về huấn luyện, nó vẫn duy trì hiệu suất trong 0.5. của hệ thống cơ bản. Do giảm kích thước dữ liệu huấn luyện, hệ thống của chúng ta tiến triển nhanh hơn phương pháp hữu hình ngây thơ, hoàn to àn. Đặc biệt, hệ thống của chúng ta chạy trong chưa đầy mười phút, xếp hạng nó trong những mục nhanh nhất cho nhiệm vụ này. Hệ thống chúng tôi có sẵn ở https://github.com/CoNLL-UD-2017/UALING -̀.', 'nl': "Dit document beschrijft UALing's benadering van de CoNLL 2017 UD Shared Task met behulp van corpusselectietechnieken om de grootte van trainingsgegevens te verminderen. De methodologie is simpel: we gebruiken vergelijkingsmaatregelen om een corpus te selecteren uit beschikbare trainingsgegevens (zelfs uit meerdere corpora voor verrassingstalen) en gebruiken het resulterende corpus om de parsing taak te voltooien. De training en parsing gebeurt met het baseline UDPipe systeem (Straka et al., 2016). Hoewel onze aanpak de omvang van trainingsgegevens aanzienlijk vermindert, blijven de prestaties binnen 0,5% van het basissysteem behouden. Door de afname van de trainingsdata presteert ons systeem sneller dan de naïeve, complete corpusmethode. Specifiek, ons systeem draait in minder dan tien minuten en rangschikt het tot de snelste inzendingen voor deze taak. Ons systeem is beschikbaar op < https://github.com/CoNLL-UD-2017/UALING >.", 'da': 'Dette dokument beskriver UALings tilgang til CoNLL 2017 UD Shared Task ved hjælp af korpusvalgteknikker for at reducere størrelsen af træningsdata. Metoden er enkel: Vi bruger lighedsforanstaltninger til at vælge et korpus ud fra tilgængelige træningsdata (selv fra flere korpus til overraskelsessprog) og bruger det resulterende korpus til at fuldføre fortolkningsopgaven. Træningen og tolkningen udføres med baseline UDPipe systemet (Straka et al., 2016). Mens vores tilgang reducerer størrelsen af træningsdata betydeligt, bevarer den ydeevnen inden for 0,5% af basissystemet. På grund af den reducerede størrelse af træningsdata fungerer vores system hurtigere end den naive, komplette corpus metode. Specielt kører vores system på mindre end 10 minutter og rangerer det blandt de hurtigste poster til denne opgave. Vores system er tilgængeligt på < https://github.com/CoNLL-UD-2017/UALING >.', 'bg': 'Настоящата статия описва подхода на УАЛинг към споделената задача, използвайки техники за подбор на корпуси за намаляване на размера на данните за обучение. Методологията е проста: използваме мерки за сходство, за да изберем корпус от наличните данни за обучение (дори от множество корпуси за езици изненадващи) и използваме получения корпус за завършване на задачата за анализ. Обучението и анализирането се извършва с базовата система (Страка и др., 2016). Докато нашият подход значително намалява размера на данните за обучение, той запазва ефективността в рамките на 0,5% от базовата система. Благодарение на намаляването на размера на данните за обучение, нашата система работи по-бързо от наивния, пълен корпус метод. По-конкретно, нашата система работи за по-малко от 10 минути, класирайки я сред най-бързите записи за тази задача. Нашата система е достъпна на < https://github.com/CoNLL-UD-2017/UALING >.', 'hr': 'Ovaj papir opisuje pristup UALing za zajednički zadatak CoNLL 2017, koristeći korpusne tehnike izbora za smanjenje veličine podataka obuke. Metodologija je jednostavna: koristimo mjere sličnosti kako bi odabrali korpus iz dostupnih podataka o obuci (čak i iz višestruke korporacije za jezike iznenađenja) i koristili rezultate korpusa kako bi dovršili analizu zadataka. Treniranje i analiza završeno je s početnim UDPipe sustavom (Straka et al., 2016). Iako naš pristup značajno smanjuje veličinu podataka obuke, zadržava učinkovitost unutar 0,5% početnog sustava. Zbog smanjenja veličine podataka obuke, naš sustav provodi brže od naivnog, kompletnog korpusnog metoda. Posebno, naš sustav radi za manje od 10 minuta, postavljajući ga među najbržim ulazima za ovaj zadatak. Naš sustav je dostupan na < https://github.com/CoNLL-UD-2017/UALING >', 'ko': '본고는 UALing이 어료 라이브러리 선택 기술을 사용하여 훈련 데이터량을 줄이는 CoNLL 2017 UD 공유 작업의 방법을 묘사한다.이 방법은 매우 간단하다. 우리는 유사성 도량을 사용하여 사용 가능한 훈련 데이터 중에서 하나의 자료 라이브러리(심지어 여러 개의 뜻밖의 언어 자료 라이브러리에서)를 선택하고 생성된 자료 라이브러리로 해석 작업을 완성한다.베이스라인 UDPipe 시스템을 사용하여 훈련과 분석(Straka 등, 2016)을 진행한다.비록 우리의 방법은 훈련 데이터의 크기를 현저히 감소시켰지만, 그것은 성능을 기선 시스템의 0.5% 이내로 유지할 것이다.훈련 데이터량의 감소로 인해, 우리 시스템은 간단하고 완전한 어료 라이브러리 방법보다 더욱 빨리 집행된다.구체적으로 말하면, 우리 시스템의 운행 시간은 10분도 안 되어, 이 임무를 완성하는 데 가장 빠른 항목 중의 하나이다.우리 시스템은<https://github.com/CoNLL-UD-2017/UALING>.', 'de': 'Dieses Papier beschreibt UALings Ansatz zur CoNLL 2017 UD Shared Task unter Verwendung von Korpusselektionstechniken, um die Größe der Trainingsdaten zu reduzieren. Die Methodik ist einfach: Wir verwenden Ähnlichkeitsmaße, um einen Korpus aus verfügbaren Trainingsdaten auszuwählen (sogar aus mehreren Korpora für Überraschungssprachen) und das resultierende Korpus zur Durchführung der Parsing-Aufgabe zu verwenden. Das Training und Parsing erfolgt mit dem Basissystem UDPipe (Straka et al., 2016). Während unser Ansatz die Größe der Trainingsdaten erheblich reduziert, bleibt die Leistung innerhalb von 0,5% des Basissystems erhalten. Durch die Reduzierung der Trainingsdatengröße ist unser System schneller als die naive, komplette Korpusmethode. Konkret läuft unser System in weniger als zehn Minuten und zählt damit zu den schnellsten Einträgen für diese Aufgabe. Unser System ist verfügbar unter < https://github.com/CoNLL-UD-2017/UALING >.', 'sw': 'Gazeti hili linaelezea mbinu ya UALing kwa ajili ya CoNLL 2017 UD ilishiriki kazi kwa kutumia mbinu za uchaguzi wa makampuni ili kupunguza ukubwa wa takwimu za mafunzo. Utawala huu ni rahisi: tunatumia hatua za usawa kuchagua viungo kutoka taarifa zinazopatikana (hata kutoka makampuni mbalimbali kwa lugha za kushangaza) na kutumia makampuni yanayosababishwa ili kumaliza kazi ya uchambuzi. The training and parsing is done with the baseline UDPipe system (Straka et al., 2016).  While our approach reduces the size of training data significantly, it retains performance within 0.5% of the baseline system.  Kutokana na kupunguza kwa kiwango cha mafunzo ya takwimu, mfumo wetu unafanya haraka zaidi ya mbinu za kisasa, kamili. Kwa ujumla, mfumo wetu unaendesha ndani ya dakika 10, na kuingia kati ya makazi ya haraka kwa kazi hii. Mfumo wetu unapatikana kwenye < https://github.com/CoNLL-UD-2017/UALING >.', 'tr': "Bu kagyz UALing'i흫 CoNLL 2017-nji UD Ta첵첵arlyk zadyny corpus sa첵law teknikleri 체챌in data ululykyny azaltmak 체챌in ullan첵ar Metodologi첵a birn채챌e basit: biz bar bilim maglumatyndan korpus sa첵lamak 체챌in me흫ze힊 철l챌체mleri ulan첵arys (hatda birn채챌e korporadan ge흫 gyzyklap diller 체챌in) we netij채ki korpusy 챌yky힊 etmek 체챌in ulan첵arys. UDPipe sistemi (Straka et l., 2016) bilen bilim we 챌yky힊 edildi. Bizi흫 첵ary힊ymyz bilim maglumaty흫 철l챌체sini wajyp 첵itir첵채n bolsa, bu sistemasy흫 체첵tgetmesi 0.5% i챌inde 첵itil첵채r. Data okuw챌ysyny흫 철l챌체sini azaltmakdan seb채bi sistemamyz naiwiz we komplet y철ntemden 챌alt i힊le첵채r. Adat챌a, bizi흫 sistemimiz 10 minutdan az i챌inde i힊le첵채r, ony bu i힊i흫 i흫 챌alt giri힊inden 챌ykar. Bizi흫 sistemimiz bar <at> https://github.com/CoNLL-UD-2017/UALING >", 'id': 'Kertas ini menggambarkan pendekatan UALing ke Tugas Berkongsi UD CoNLL 2017 menggunakan teknik seleksi corpus untuk mengurangi ukuran data pelatihan. Metodologi sederhana: kita menggunakan tindakan persamaan untuk memilih mayat dari data pelatihan yang tersedia (bahkan dari banyak mayat untuk bahasa kejutan) dan menggunakan mayat hasilnya untuk menyelesaikan tugas penghuraian. Pelatihan dan penghuraian dilakukan dengan sistem UDPipe dasar (Straka et al., 2016). Sementara pendekatan kita mengurangi ukuran data pelatihan secara signifikan, itu mempertahankan prestasi dalam 0,5% dari sistem dasar. Karena mengurangi ukuran data latihan, sistem kita bekerja lebih cepat dari metode corpus yang naif. Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries for this task.  Sistem kita tersedia di < https://github.com/CoNLL-UD-2017/UALING >.', 'am': 'ይህ ፕሮግራም የUALing የኮንጆ አካባቢ የካርፓስ ምርጫዎችን ለመያነስ የዳታ መጠን ለማንቀሳቀስ የካርፓስ ምርጫዎችን ለመያነስ የሚችል ነው፡፡ ዘዴዎ ቀላል ነው፤ የፓርቲው ስራ ለመፈጸም የሚችሉትን የድምፅ ማህበረሰብ ዳራዎችን ለመምረጥ እና የመጨረሻውን ኮፓስ ለመፈጸም እናስቀምጣለን፡፡ ትምህርት እና ማኅበረሰብ በUDPip ስርዓት (Straka et al., 2016) የተደረገ ነው፡፡ የአስተማሪነታችን ዳራዎችን በኩል የሚያሳፍር ሲሆን የሥርዓቱን መጠን በጥቅምት መቶ 0.5 በመቶ ውስጥ ይኖራል፡፡ Due to the reduction in training data size, our system performs faster than the naive, complete corpus method.  በተለይም፣ ስርዓታችን ከ10 ደቂቃ በላይ ይሮጣል፣ ለዚህም ስራ ፈጥኖ የሚደረገውን መግቢያ ይዘጋጅታል፡፡ ሲስተኛችን በ < https://github.com/CoNLL-UD-2017/UALING >', 'hy': 'Այս հոդվածը նկարագրում է UALing-ի մոտեցումը 2017 թվականի CONAL UD-ի ընդհանուր առաջադրանքին օգտագործելով կորպուսի ընտրության մեթոդներ՝ կրճատելու համար կրթական տվյալների չափը: The methodology is simple: we use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting corpus to complete the parsing task.  The training and parsing is done with the baseline UDPipe system (Straka et al., 2016).  Մինչդեռ մեր մոտեցումը նվազեցնում է ուսուցման տվյալների չափը, այն պահպանում է արդյունքը հիմնական համակարգի 0.5 տոկոսի մեջ: Քանի որ մեր համակարգը նվազեցնում է տվյալների չափսերը, ավելի արագ է աշխատում, քան նայիվ, ամբողջական կորպոս մեթոդը: Հատկապես, մեր համակարգը աշխատում է 10 րոպեից քիչ, դասավորելով այն այս խնդրի ամենաարագ մտքերի մեջ: Our system is available at < https://github.com/CoNLL-UD-2017/UALING ]:', 'sq': 'Ky dokument përshkruan qasjen e UALing ndaj detyrës s ë përbashkët të CoNLL 2017 UD duke përdorur teknikat e zgjedhjes së corpus për të reduktuar madhësinë e të dhënave të trainimit. Metodologjia është e thjeshtë: ne përdorim masat e ngjashmërisë për të zgjedhur një trup nga të dhënat e disponueshme të trajnimit (madje edhe nga trupa të shumta për gjuhët e befasuara) dhe përdorim trupin që rezulton për të përfunduar detyrën e analizimit. Trenimi dhe analizimi bëhet me sistemin bazë UDPipe (Straka et al., 2016). Ndërsa qasja jonë zvogëlon madhësinë e të dhënave të trajnimit në mënyrë të konsiderueshme, ajo mban performancën brenda 0.5% të sistemit bazë. Për shkak të reduktimit të madhësisë së të dhënave të trajnimit, sistemi ynë funksionon më shpejt se metoda naive, e plotë e korpusit. Veçanërisht, sistemi ynë funksionon për më pak se 10 minuta, duke e renditur atë midis hyrjeve më të shpejta për këtë detyrë. Sistemi ynë është në dispozicion në < https://github.com/CoNLL-UD-2017/UALING >.', 'af': "Hierdie papier beskryf UALing se toegang tot die CoNLL 2017 UD Gedeelde Opdrag met gebruik van korpus kies tekniks om onderwerp data grootte te verminder. Die metodologie is eenvoudig: ons gebruik gelykenis maat om 'n korpus te kies van beskikbare onderwerp data (selfs van veelvuldige korpore vir verbaastaal) en gebruik die resulteerde korpus om die onderwerp taak te voltooi. Die oefening en verwerking is gedoen met die basis UDPipe stelsel (Straka et al., 2016). Alhoewel ons toegang die grootte van onderwerp data betekeurig verduur, hou dit voorwerp binne 0.5% van die basilyn stelsel. Dus die reduksie van onderwerp data grootte, doen ons stelsel vinniger as die naive, volledige korpusmetode. Spesifieke, ons stelsel loop in minder as 10 minute, ranking dit onder die vinnigste inskrywings vir hierdie taak. Ons stelsel is beskikbaar by < https://github.com/CoNLL-UD-2017/UALING >", 'fa': 'این کاغذ روش UALing را برای کاهش اندازه داده آموزش به کار مشترک UD در CoNLL 2017 توصیف می\u200cکند. روش\u200cشناسی ساده است: ما از اندازه\u200cهای شبیه\u200cای برای انتخاب یک کورپوس از داده\u200cهای آموزش موجود استفاده می\u200cکنیم (حتی از چند کورپورا برای زبانهای سورپرایز) و از کورپوس نتیجه\u200cای برای کامل کردن کار\u200cشناسی استفاده می\u200cکنیم. آموزش و تجزیه با سیستم UDPipe (Straka et al., 2016) پایین خط پایین انجام شده است. در حالی که دسترسی ما اندازه داده های آموزش را به طور معنی کاهش می دهد، عملکرد در حدود 0.5% از سیستم پایین نگه می دارد. به دلیل کاهش اندازه داده آموزش، سیستم ما سریع تر از روش ساده و کامل جسد انجام می دهد. به طور خاص، سیستم ما در کمتر از ده دقیقه طول می\u200cکشد و در میان سریع\u200cترین ورودهای این کار آن را رقابت می\u200cدهد. سیستم ما در < https://github.com/CoNLL-UD-2017/UALING .', 'az': "Bu kağıt UALing'in CoNLL 2017-ci UD paylaşılmış iş işləri korpus seçim teknikləri ilə təhsil verilər böyüklüyünü azaltmaq üçün təhsil edir. Metodoloji basitdir: biz korpusu mümkün təhsil məlumatından seçmək üçün istifadə edirik (hətta çoxlu korporadan təəccüblü dillərə istifadə edirik) və sonuçları korpusu ayırma işini tamamlamaq üçün istifadə edirik. Eğitimi və ayırış sistemi UDPipe sistemi ilə tamamlandı (Straka et al., 2016). Yaxınlığımız təhsil məlumatının böyüklüyünü böyüklüyünü azaldığı halda, bu təhsil sisteminin 0,5%-ində performansını saxlayar. Məlumat ölçülərinin azaltmasına görə sistemimiz naiv, tamamlayan korpus metodumundan daha hızlı işləyir. Bizim sistemimiz 10 dəqiqədən az çalışır, bu işin ən hızlı giriş arasında sıralar. Sistemimiz < https://github.com/CoNLL-UD-2017/UALING >", 'bs': 'Ovaj papir opisuje pristup UALing za zajednički zadatak CoNLL 2017, koristeći korpusne tehnike izbora za smanjenje veličine podataka o obuci. Metodologija je jednostavna: koristimo mjere sličnosti da izaberemo korpus iz dostupnih podataka o obuci (čak i iz višestruke korporacije za jezike iznenađenja) i koristimo rezultate korpusa da bi završili analizu zadataka. Treniranje i analiza završeno je sa osnovnim UDPipe sistemom (Straka et al., 2016). Iako naš pristup značajno smanjuje veličinu podataka obuke, zadržava učinkovitost unutar 0,5% početnog sistema. Zbog smanjenja veličine podataka obuke, naš sistem provodi brže od naivnog, kompletnog korpusnog metoda. Posebno, naš sistem se radi za manje od 10 minuta, u redu je među najbržim ulazima za ovaj zadatak. Naš sistem je dostupan na < https://github.com/CoNLL-UD-2017/UALING - Da.', 'bn': 'এই পত্রিকাটি প্রশিক্ষণের তথ্যের আকার কমানোর জন্য কোনপাস নির্বাচন প্রযুক্তি ব্যবহার করে প্রশিক্ষণের মাপ কমানোর জন্য উলিং ২০১৭ এই পদ্ধতিটি সহজ: প্রশিক্ষণের তথ্য থেকে আমরা কোর্পাস বেছে নিতে একই ধরনের পদক্ষেপ ব্যবহার করি (এমনকি বিস্ময়কর ভাষার জন্য অনেক কর্পোরা থেকে বেছে নে প্রশিক্ষণ এবং পার্সিং বেস্ট লাইন ইউডিপিপি সিস্টেমের (স্ট্রাকা ট্রেনিং আল, ২০১৬)। যখন আমাদের প্রশিক্ষণের তথ্য গুরুত্বপূর্ণ কমিয়ে দেয়, তখন বেসাইলাইন সিস্টেমের ০. প্রশিক্ষণের তথ্য আকার কমানোর কারণে আমাদের সিস্টেম নাইভের চেয়ে দ্রুত, পূর্ণ কোর্পাস পদ্ধতির চেয়ে দ্রুত কা Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries for this task.  আমাদের সিস্টেমে পাওয়া যাচ্ছে < https://github.com/CoNLL-UD-2017/UALING >', 'et': "Käesolevas artiklis kirjeldatakse UALingi lähenemisviisi CoNLL 2017 UD Shared Task'ile, kasutades korpuse valimise meetodeid koolitusandmete suuruse vähendamiseks. Metoodika on lihtne: kasutame sarnasuse meetmeid, et valida korpus olemasolevatest koolitusandmetest (isegi mitmest korpusest üllatuskeelte puhul) ja kasutame tulemusena saadud korpust parsimise ülesande täitmiseks. Koolitus ja parsimine toimub baasil UDPipe süsteemiga (Straka et al., 2016). Kuigi meie lähenemisviis vähendab treeninguandmete suurust märkimisväärselt, säilitab see jõudluse 0,5% ulatuses baassüsteemist. Koolitusandmete suuruse vähenemise tõttu toimib meie süsteem kiiremini kui naiivne, täielik korpusmeetod. Täpsemalt töötab meie süsteem vähem kui 10 minutiga, asetades selle selle ülesande kiireimate kirjete hulka. Meie süsteem on saadaval aadressil < https://github.com/CoNLL-UD-2017/UALING >.", 'fi': 'Tässä artikkelissa kuvataan UALingin lähestymistapaa CoNLL 2017 UD Shared Task -tehtävään käyttämällä korpusvalintatekniikoita koulutusdatan koon pienentämiseksi. Menetelmä on yksinkertainen: käytämme samankaltaisuusmittareita valitaksemme korpusen saatavilla olevasta koulutustiedosta (jopa useista korpusista yllätyskieleille) ja käytämme tuloksena olevaa korpusta jäsennystehtävän suorittamiseen. Koulutus ja jäsentäminen tehdään UDPipe-järjestelmän perusaikataululla (Straka et al., 2016). Vaikka lähestymistapamme pienentää harjoitusdatan kokoa merkittävästi, se säilyttää suorituskyvyn 0,5%:ssa perusaikataulusta. Koulutusdatan koon pienenemisen vuoksi järjestelmämme toimii nopeammin kuin naiivi, täydellinen korpusmenetelmä. Tarkemmin sanottuna järjestelmämme toimii alle 10 minuutissa, mikä asettaa sen tämän tehtävän nopeimpien merkintöjen joukkoon. Järjestelmämme on saatavilla osoitteessa < https://github.com/CoNLL-UD-2017/UALING >.', 'cs': 'Tento článek popisuje UALingův přístup k CoNLL 2017 UD Shared Task pomocí technik výběru korpusů ke snížení velikosti tréninkových dat. Metodika je jednoduchá: používáme měřítka podobnosti k výběru korpusu z dostupných tréninkových dat (i z více korpusů pro překvapivé jazyky) a používáme výsledný korpus k dokončení parsovací úlohy. Školení a analýza probíhá pomocí základního systému UDPipe (Straka et al., 2016). Zatímco náš přístup výrazně snižuje velikost tréninkových dat, udržuje si výkon v rozsahu 0,5% od základního systému. Díky snížení velikosti tréninkových dat funguje náš systém rychleji než naivní, kompletní korpusová metoda. Konkrétně, náš systém běží za méně než deset minut, což ho řadí mezi nejrychlejší položky pro tento úkol. Náš systém je k dispozici na adrese < https://github.com/CoNLL-UD-2017/UALING >.', 'ca': "Aquest paper descriu l'enfocament d'UALing a la CoNLL 2017 UD Shared Task utilitzant tècniques de selecció corpus per reduir la mida de les dades d'entrenament. La metodologia és simple: utilitzem mesures de similitud per seleccionar un cos de les dades disponibles d'entrenament (fins i tot de múltiples corpores per idiomes sorprenents) i utilitzem el cos resultant per completar la tasca d'analització. L'entrenament i l'analisi es fan amb el sistema UDPipe basal (Straka et al., 2016). Mentre que el nostre enfocament redueix significativament la mida de les dades d'entrenament, manté el rendiment dins el 0,5% del sistema de base. Gràcies a la reducció de la mida de les dades d'entrenament, el nostre sistema funciona més ràpid que el mètode corpus naiu i complet. Concretament, el nostre sistema funciona en menys de 10 minuts, classificant-lo entre les entrades més ràpids d'aquesta tasca. El nostre sistema està disponible a < https://github.com/CoNLL-UD-2017/UALING >.", 'jv': 'Ngetong iki rambarang nggawe ndelok UELing kanggo CoNLL 1997 udh Sampeyan tasks nggambar teknik nggawe ngubah cara-cara nggawe data size nggawe Metotologi iku sampeyan: kita gambar perusahaan sampeyan mripan kanggo ngubah data sing wis nguasai perusahaan (dumadhi kapan podho kapan kanggo kebebasan pangan) lan nganggep sistem sampeyan gawe ngubah tanggal nggawe perusahaan mripan. Rasané karo urip nggawe lan oleraning nggo sistem UTPipe sisané (Strika et al, 2011). Alpha Ngomongke tambah kuwi ngrusak kuwi tindakan data size nggawe sistem iki dadi luwih karo ngono nggawe dolanan liyane Laptop" and "Desktop Sistem-sistem sing ditambah < https://github.com/CoNLL-UD-2017/UALING >', 'he': 'הנייר הזה מתאר את הגישה של UALing למשימה המשותפת של CoNLL 2017 UD בשימוש טכניקות בחירה קורפוס כדי להפחית את גודל נתוני האימונים. המטדולוגיה פשוטה: אנו משתמשים באמצעי דמיון כדי לבחור גופוס ממידע האימון זמין (אפילו ממספר גופורים לשפות הפתעה) ולהשתמש בקורפוס הנוצא כדי להשלים את משימה ההעברה. האימון והחקירה נעשה עם מערכת UDPipe (Straka et al., 2016). בעוד הגישה שלנו מפחידה את גודל נתוני האימונים באופן משמעותי, היא שומרת ביצועים בתוך 0.5% מהמערכת הבסיסית. Due to the reduction in training data size, our system performs faster than the naive, complete corpus method.  במיוחד, המערכת שלנו פועלת בתוך פחות מ-10 דקות, מעצבת אותה בין הכניסות המהירות ביותר למשימה הזאת. המערכת שלנו זמינה ב < https://github.com/CoNLL-UD-2017/UALING >.', 'ha': "Wannan takardan na describe ULLing's move to the CoNLL 2017 UD Shared Tafiyar da aka yi amfani da koptura selected tactiyoyin yin ƙaranci data size. Tsarin ya zama mai sauƙi: tuna amfani da takwara masu daidaita don mu zãɓi wani nau'i daga data masu amfani da (kõ kuwa daga makampuni masu amfani da lugha masu yin mãkirci) kuma mu yi amfani da nau'in da za'a cika aikin parse. An cika shirin da aka samu game da na'urar Udepipe (Traaka et al., 2016). A lokacin da hanyarmu ke ƙara girmar data na amfani da muhimu, sai yana riƙe aikin aiki guda 0.5% na'urar kasar basalin. Due to the reduction in training data size, our system performs faster than the naive, complete corpus method.  A ƙayyade, na tafiyar da tsarinmu guda daga dakika 10, yana ranar da shi daga matsayin sauri mafi kashi wa wannan aikin. An iya samar da na'uranmu a < https://github.com/CoNLL-UD-2017/UALING >", 'sk': 'Ta prispevek opisuje pristop UALing do CoNLL 2017 UD Shared Task z uporabo tehnik izbire korpusov za zmanjšanje velikosti podatkov o usposabljanju. Metodologija je preprosta: uporabljamo merila podobnosti za izbiro korpusa iz razpoložljivih podatkov o usposabljanju (tudi iz več korpusov za jezike presenečenja) in uporabljamo rezultat korpusa za dokončanje naloge razčlenitve. Usposabljanje in razčlenitev poteka z osnovnim sistemom UDPipe (Straka et al., 2016). Medtem ko naš pristop bistveno zmanjšuje velikost podatkov o vadbi, ohranja zmogljivost v okviru 0,5% osnovnega sistema. Zaradi zmanjšanja velikosti podatkov o usposabljanju naš sistem deluje hitreje kot naivna, popolna korpusna metoda. Natančneje, naš sistem deluje v manj kot 10 minutah in ga uvršča med najhitrejše vnose za to nalogo. Naš sistem je na voljo na < https://github.com/CoNLL-UD-2017/UALING >.', 'bo': "ཤོག་བྱང་འདིས་ UALing's approach to the CoNLL 2017 UD Shared Task with corpus selection techniques to reduce training data size. ཐབས་ལམ་དེ་ལས་སླ་བོ་རེད། ང་ཚོས་མཐུན་རྐྱེན་གྱི་ཐབས་ལམ་ལྟར་བྱས་པར་མཐུན་མཁན་ཞིག་གདམ་པར་མཐུད་པའི་གནས་ཚུལ། གཞུང་སྤྲོད་དང་དབྱེ་ཞིབ་བྱེད་རྒྱུ་དང་ལྟར་གཞུང་གི་UDPipe་རིམ་པ་དེ་རྒྱབ་སྐྱོར་མེད་པ(Straka et al., 2016) ང་ཚོའི་གཟུགས་སྐོར་ལ་གཙོ་རིམ་གྱི་ཚད་ཆེ་ཆུང་དུ་གཏོང་ཐུབ་པ་ཡིན་ནའང་། གཙོ་རིམ་གྱི་མ་ལག་གི་ཚད་ལྡན་0.5 དབྱིན་བཟོ་བྱེད་ཀྱི་ཆེ་ཆུང་དུ་བཏོན་བཤེར་བྱེད་ནུས། ང་ཚོའི་མ་ལག་གིས་མིའི་ཐབས་ལམ་ལྟར་མཇུག་བསྡད་ཡོད། ཁྱད་པར་ན་ང་ཚོའི་མ་ལག་གིས་སྐར་ཆ་གཅིག་ལས་ཉུང་བའི་ནང་འཁོར་སྐྱོད་བྱེད་པ ང་ཚོའི་མ་ལག་ནི་<ལ་སྤྱོད་ཚར་བ https://github.com/CoNLL-UD-2017/UALING >"}
{'en': 'Initial Explorations of CCG Supertagging for Universal Dependency Parsing', 'es': 'Exploraciones iniciales del superetiquetado CCG para el análisis universal de dependencias', 'ar': 'الاستكشافات الأولية لتطبيق CCG Supertagging لتحليل التبعية الشاملة', 'fr': "Explorations initiales du supertagging CCG pour l'analyse universelle des dépendances", 'pt': 'Explorações iniciais do CCG Supertagging para análise de dependência universal', 'ja': '普遍的な依存関係解析のためのCCGスーパータグの初期の探索', 'hi': 'यूनिवर्सल निर्भरता पार्सिंग के लिए CCG Supertagging के प्रारंभिक अन्वेषण', 'zh': 'CCG超标记之初探,用于通用赖解析', 'ru': 'Первоначальные исследования CCG Supertagging для универсального анализа зависимостей', 'ga': 'Iniúchtaí Tosaigh ar Sárchlibeáil CCG le haghaidh Parsáil Spleáchais Uilíoch', 'ka': 'CCG სუპერტეგური განსაზღვრებისთვის პირველი გამოყენება', 'hu': 'A CCG szupercímkézés kezdeti feltárásai az univerzális függőség-értelmezéshez', 'el': 'Αρχική Εξερεύνηση της υπερσήμανσης CCG για την ανάλυση καθολικής εξάρτησης', 'it': "Esplorazioni iniziali del Supertagging CCG per l'analisi universale della dipendenza", 'kk': 'Жалпы тәуелдік талдау үшін CCG супертегтегі бастапқы зерттеулері', 'mk': 'Првични истражувања на CCG суперознака за универзално анализирање зависности', 'lt': 'Pagrindiniai bendrosios priklausomybės analizės pagrindinės sandorio šalies papildomo ženklinimo tyrimai', 'ms': 'Penjelasan awal Supertagging CCG untuk Penghuraian Dependensi Universal', 'mt': 'Esplorazzjonijiet Inizjali tas-Supertagging tas-CCG għall-Analiżi Universali tad-Dipendenza', 'mn': 'Дэлхийн хамаарал хамааралтай шалгалтын CCG Supertagging эхний судалгаа', 'ml': 'സിസിജി സൂപ്പര്\u200dടാഗിങ്ങിന്റെ ആദ്യമായ പരിശോധനങ്ങള്\u200d', 'no': 'Førehandsvising av CCG- supermerking for universell avhengighetstolking', 'pl': 'Wstępne badania CCG Supertagging dla uniwersalnego parowania zależności', 'ro': 'Explorarea inițială a superetichetării CCG pentru analizarea dependenței universale', 'sr': 'Početna istraživanja CCG Supertagging za razmatranje univerzalne zavisnosti', 'so': 'Qoraalka ugu horeysa baaritaanka dhamaanka jaamacadda', 'sv': 'Inledande utforskningar av CCG-supermärkning för universell beroendetolkning', 'si': 'CCG සුපිරිටැගින් විශාල විශ්වාසය සඳහා පළමු ප්\u200dරශ්නය', 'ta': 'பொதுவான சார்ந்த பாசிங்குக்கான CCG முதன்மை ஏற்றுமதி', 'ur': 'Universal Dependency Parsing کے لئے CCG Supertagging کی آغاز تحقیقات', 'uz': 'Name', 'vi': 'Khám phá đầu tiên về kỹ thuật đỉnh cao về độ quan hệ chung', 'bg': 'Първоначални проучвания на супермаркет за анализ на универсалната зависимост', 'hr': 'Početna istraživanja CCG Supertagging za razmatranje univerzalne zavisnosti', 'nl': 'Eerste verkenningen van CCG Supertagging voor Universal Dependency Parsing', 'da': 'Indledende undersøgelser af CCG Supertagging for Universal Dependency Parsing', 'de': 'Erste Explorationen von CCG Supertagging für Universal Dependency Parsing', 'fa': 'تحقیقات اولیه CCG Supertagging برای تحلیل بستگی جهانی', 'ko': 'CCG 하이퍼마크 일반 의존 해석에서의 초보적인 탐색', 'id': 'Penjelasan awal dari Supertagging CCG untuk Parsing Dependensi Universal', 'sw': 'Maelezo ya mwanzo ya Ujumbe wa CCG kwa ajili ya Uchaguzi wa Uhuru ulimwengu', 'af': 'Aanvanklike Verklaring van CCG Supertagging vir Universele Afhanklikheidverwerking', 'tr': 'CCG Başlyg Taýýarlamanyň Başlyg Görnöşimleri Aňlamak üçin', 'am': 'ምርጫዎች', 'sq': 'Zbulimet fillestare të mbietiketave CCG për analizimin universal të varësisë', 'hy': 'Համաշխարհային կախվածության վերլուծության հիմնական հետազոտությունները', 'bn': 'সিসিজি সুপার্ট্যাগিং এর প্রাথমিক এক্সপ্লোরেশন', 'az': "Universal Dependency Analyzing üçün CCG Supertagging'in başlanğıç Explorations", 'ca': "Exploracions inicials de superetiquetes de GCC per a l'analització universal de dependencies", 'cs': 'Počáteční průzkum CCG Supertagging pro univerzální analýzu závislosti', 'fi': 'CCG Supertaggingin alustavat tutkimukset yleismaailmallisen riippuvuuden analysoimiseksi', 'et': 'CCG supermärgistuse esialgsed uuringud universaalse sõltuvuse analüüsimiseks', 'bs': 'Početna istraživanja CCG Supertagging za razmatranje univerzalne zavisnosti', 'jv': 'Ngucap Inisih Keteraksi Gambar CVG super-taging kanggo Universal Dewekelang Parasing', 'he': 'חקירות קודמיות של תג על CCG עבור בדיקת תלויות יוניברסלית', 'ha': 'KCharselect unicode block name', 'sk': 'Začetne raziskave nadoznačevanja CCG za razvrščanje univerzalne odvisnosti', 'bo': 'CCG Supertagging for Universal Dependency Parsing ཡི་གྲྭའི་འགོ་འཛུགས་ཀྱི་དཔྱད་ཞིབ་བྱས་པ'}
{'en': 'In this paper we describe the system by METU team for universal dependency parsing of multilingual text. We use a neural network-based dependency parser that has a greedy transition approach to dependency parsing. CCG supertags contain rich structural information that proves useful in certain NLP tasks. We experiment with CCG supertags as additional features in our experiments. The neural network parser is trained together with dependencies and simplified CCG tags as well as other features provided.', 'ar': 'في هذا البحث نصف النظام الذي وضعه فريق METU لتحليل التبعية الشاملة للنص متعدد اللغات. نحن نستخدم محلل تبعية قائم على الشبكة العصبية له نهج انتقال جشع لتحليل التبعية. تحتوي العلامات الفوقية CCG على معلومات هيكلية غنية تثبت فائدتها في بعض مهام البرمجة اللغوية العصبية. نجرب العلامات الفوقية CCG كميزات إضافية في تجاربنا. يتم تدريب محلل الشبكة العصبية جنبًا إلى جنب مع التبعيات وعلامات CCG المبسطة بالإضافة إلى الميزات الأخرى المتوفرة.', 'pt': 'Neste artigo descrevemos o sistema da equipe METU para análise de dependência universal de texto multilíngue. Usamos um analisador de dependência baseado em rede neural que tem uma abordagem de transição gananciosa para análise de dependência. As supertags CCG contêm informações estruturais ricas que se mostram úteis em certas tarefas de PNL. Experimentamos supertags CCG como recursos adicionais em nossos experimentos. O analisador de rede neural é treinado em conjunto com dependências e tags CCG simplificadas, além de outros recursos fornecidos.', 'es': 'En este artículo describimos el sistema del equipo de METU para el análisis universal de dependencias de texto multilingüe. Utilizamos un analizador de dependencias basado en redes neuronales que tiene un enfoque de transición ambicioso para el análisis de dependencias. Las superetiquetas CCG contienen abundante información estructural que resulta útil en ciertas tareas de PNL. Experimentamos con superetiquetas CCG como características adicionales en nuestros experimentos. El analizador de redes neuronales se entrena junto con dependencias y etiquetas CCG simplificadas, así como otras funciones proporcionadas.', 'fr': "Dans cet article, nous décrivons le système mis en place par l'équipe METU pour l'analyse dépendante universelle de texte multilingue. Nous utilisons un analyseur de dépendances basé sur un réseau de neurones qui a une approche de transition gourmande pour l'analyse des dépendances. Les supertags CCG contiennent des informations structurales riches qui s'avèrent utiles dans certaines tâches de PNL. Nous expérimentons les supertags CCG comme fonctionnalités supplémentaires dans nos expériences. L'analyseur de réseau neuronal est entraîné avec les dépendances et les étiquettes CCG simplifiées ainsi que d'autres fonctionnalités fournies.", 'ru': 'В этой статье мы описываем систему команды METU для универсального синтаксического анализа многоязычного текста. Мы используем нейронный сетевой синтаксический анализатор зависимостей, который имеет жадный переходный подход к синтаксическому анализу зависимостей. Супертеги CCG содержат богатую структурную информацию, которая оказывается полезной в некоторых задачах NLP. Мы экспериментируем с супертегами CCG в качестве дополнительных функций в наших экспериментах. Парсер нейронной сети обучается вместе с зависимостями и упрощенными тегами CCG, а также другими предоставляемыми функциями.', 'zh': '本文者,述METU团队以多语言文本通用赖解析之统也。 吾用神经网络者恃解析器,其贪婪者恃解析转换方法。 CCG超级标富结,有征于NLP。 实验以 CCG 超级表为实验。 神经网络解析器与赖项简化者 CCG 标记及他功能训练。', 'ja': 'この論文では、多言語テキストの普遍的な依存関係解析のためのMETUチームによるシステムについて説明します。ニューラルネットワークベースの依存関係解析器を使用し、依存関係解析への欲張りな遷移アプローチを採用しています。CCGスーパータグには、特定のNLPタスクで有用であることが証明されている豊富な構造情報が含まれています。CCGスーパータグを追加機能として実験しています。ニューラルネットワーク構文解析器は、提供される他の機能だけでなく、依存関係および簡略化されたCCGタグと共に訓練される。', 'hi': 'इस पेपर में हम बहुभाषी पाठ के सार्वभौमिक निर्भरता पार्सिंग के लिए METU टीम द्वारा सिस्टम का वर्णन करते हैं। हम एक तंत्रिका नेटवर्क-आधारित निर्भरता पार्सर का उपयोग करते हैं जिसमें निर्भरता पार्सिंग के लिए एक लालची संक्रमण दृष्टिकोण होता है। CCG supertags में समृद्ध संरचनात्मक जानकारी होती है जो कुछ NLP कार्यों में उपयोगी साबित होती है। हम अपने प्रयोगों में अतिरिक्त सुविधाओं के रूप में CCG supertags के साथ प्रयोग करते हैं। तंत्रिका नेटवर्क पार्सर निर्भरता और सरलीकृत सीसीजी टैग के साथ-साथ प्रदान की गई अन्य सुविधाओं के साथ एक साथ प्रशिक्षित किया जाता है।', 'ga': 'Sa pháipéar seo déanaimid cur síos ar an gcóras atá ag foireann METU le haghaidh parsáil spleáchais uilíoch ar théacs ilteangach. Bainimid úsáid as parsálaí spleáchais néar-bhunaithe líonra a bhfuil cur chuige trasdula sanntach maidir le parsáil spleáchais. Tá faisnéis shaibhir struchtúrach i sárchlibeanna CCG a bhíonn úsáideach i dtascanna áirithe NLP. Déanaimid tástáil le sárchlibeanna CCG mar ghnéithe breise inár gcuid turgnaimh. Cuirtear oiliúint ar pharsálaí an líonra néaraigh mar aon le spleáchais agus clibeanna CCG simplithe chomh maith le gnéithe eile a chuirtear ar fáil.', 'ka': 'ამ დოკუნში ჩვენ METU ჯგუფის სისტემის სისტემის განსაზღვრებას უნივერსალური განსაზღვრებულობაზე მრავალენგური ტექსტის განსაზღვრებისთვის. ჩვენ გამოვიყენებთ ნეიროლური ქსელის დამატებული დავარდამდგენების პანუზერი, რომელიც საკუთარი გადარდამდგენების გადაწყენება. CCG სუპერტიკატები აქვს ბედნიერი სტრუქტურული ინფორმაცია, რომელიც განსაკუთრებული NLP დავალებში გამოიყენება. ჩვენ ექსპერიმენტირებით CCG სუპერტეგებით, როგორც ჩვენი ექსპერიმენტებში დამატებით. ნეიროლური ქსელის პანელიზატორი დააკეთებულია დასახლოებით და გამოყენებული CCG ჭდეებით და სხვა ფუნქციებით.', 'el': 'Στην παρούσα εργασία περιγράφουμε το σύστημα της ομάδας ΜΕΤΑΕ για την καθολική ανάλυση εξάρτησης πολυγλωσσικού κειμένου. Χρησιμοποιούμε έναν αναλυτή εξάρτησης βασισμένο σε νευρωνικό δίκτυο που έχει μια άπληστη προσέγγιση μετάβασης στην ανάλυση εξάρτησης. Οι υπερετικέτες περιέχουν πλούσιες δομικές πληροφορίες που αποδεικνύονται χρήσιμες σε ορισμένες εργασίες. Πειραματιζόμαστε με υπερετικέτες ως πρόσθετα χαρακτηριστικά στα πειράματά μας. Ο αναλυτής νευρωνικών δικτύων εκπαιδεύεται μαζί με εξαρτήσεις και απλοποιημένες ετικέτες καθώς και άλλα χαρακτηριστικά που παρέχονται.', 'hu': 'Ebben a tanulmányban bemutatjuk a METU csapat által a többnyelvű szöveg univerzális függőségi elemzésének rendszerét. Egy neurális hálózat alapú függőség elemzőt használunk, amely kapzsi átmeneti megközelítést alkalmaz a függőség elemzéséhez. A CCG szupercímkék gazdag strukturális információkat tartalmaznak, amelyek hasznosak bizonyos NLP feladatokban. Kísérleteink során CCG szupercímkékkel kísérletezünk további funkcióként. A neurális hálózati elemzőt függőségekkel és egyszerűsített CCG címkékkel, valamint egyéb funkciókkal együtt képezik.', 'it': "In questo articolo descriviamo il sistema del team METU per l'analisi universale delle dipendenze del testo multilingue. Usiamo un parser di dipendenza basato su rete neurale che ha un approccio di transizione avido all'analisi delle dipendenze. I supertag CCG contengono informazioni strutturali ricche che si rivelano utili in alcune attività NLP. Sperimentiamo con i supertag CCG come funzionalità aggiuntive nei nostri esperimenti. Il parser di rete neurale è addestrato insieme alle dipendenze e tag CCG semplificati, così come altre funzionalità fornite.", 'kk': 'Бұл қағазда біз METU тобының жүйесін бірнеше тілдік мәтінді талдау үшін көпшілік тәуелсіздік талдау үшін анықтаймыз. Біз неврал желінде тәуелдік талдау үшін тәуелдікті ауыстыру тәсілдігін қолданамыз. CCG супертегтерінде NLP тапсырмаларында пайдалы болатын құрастырмалы мәлімет бар. Біз CCG супертегтермен тәжірибелерімізде қосымша мүмкіндіктер ретінде тәжірибелеміз. Невралды желі талдаушысы тәуелдіктермен және қарапайым CCG тегтерімен және басқа мүмкіндіктерімен бірге оқылған.', 'lt': 'In this paper we describe the system by METU team for universal dependency parsing of multilingual text.  Naudojame nerviniu tinklu pagrįstą priklausomybės analizatorių, kurio perėjimo prie priklausomybės analizavimo metodas yra skanus. Pagrindinės sandorio šalies superženkluose pateikiama daug struktūrinės informacijos, kuri yra naudinga tam tikroms NLP užduotims atlikti. Mūsų eksperimentuose eksperimentuojame su CCG superženklais kaip papildomais požymiais. Naujojo tinklo analizatorius mokomas kartu su priklausomybe ir supaprastintais CCG ženklais bei kitomis teikiamomis savybėmis.', 'mk': 'Во овој весник го опишуваме системот на тимот на МеТУ за универзално анализирање на мултијазичен текст. Користиме анализатор на зависност на нервната мрежа кој има алчен пристап на транзиција до анализатор на зависност. Суперознаките на CCG содржат богати структурни информации кои се покажуваат корисни за одредени NLP задачи. Експериментираме со CCG суперознаки како дополнителни карактеристики во нашите експерименти. Анализаторот на нервната мрежа е обучен заедно со зависности и поедноставени CCG ознаки, како и други обезбедени карактеристики.', 'mt': 'F’dan id-dokument niddeskrivu s-sistema mit-tim METU għall-analiżi tad-dipendenza universali tat-test multilingwi. Aħna nużaw analizzatur tad-dipendenza bbażat fuq in-netwerk newrali li għandu approċċ ta’ tranżizzjoni għaqli għall-analizzazzjoni tad-dipendenza. Is-supertags tas-CCG fihom informazzjoni strutturali rikka li hija utli f’ċerti kompiti tal-NLP. Aħna ninsperimentaw bis-supertags tas-CCG bħala karatteristiċi addizzjonali fl-esperimenti tagħna. Il-analizzatur tan-netwerk newrali huwa mħarreġ flimkien mad-dipendenzi u t-tikketti simplifikati tas-CCG kif ukoll karatteristiċi oħra pprovduti.', 'ms': 'Dalam kertas ini kami menggambarkan sistem oleh pasukan METU untuk penghuraian dependensi universal teks berbilang bahasa. Kami menggunakan penghurai dependensi berdasarkan rangkaian saraf yang mempunyai pendekatan trangsi serakah untuk penghurai dependensi. Supertag CCG mengandungi maklumat struktur yang kaya yang membuktikan berguna dalam tugas NLP tertentu. Kami eksperimen dengan supertag CCG sebagai ciri-ciri tambahan dalam eksperimen kami. Penghurai rangkaian saraf dilatih bersama dengan dependensi dan tag CCG mudah serta ciri-ciri lain yang diberikan.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d മെടിയുവിന്റെ ടീം വിശദീകരിക്കുന്നു. പ്രപഞ്ച ആശ്രയിക്കാനുള്ള സിസ്റ്റം പല ഭാഷകങ്ങള നമ്മള്\u200d ന്യൂറല്\u200d നെറ്റൂറല്\u200d നെറ്റോവര്\u200dക്ക് അടിസ്ഥാനമായ ആശ്രയിക്കുന്ന പ്രദര്\u200dശനം ഉപയോഗിക്കുന്നു. ആശ്രയിച് CCG supertags contain rich structural information that proves useful in certain NLP tasks.  നമ്മുടെ പരീക്ഷണങ്ങളില്\u200d കൂടുതല്\u200d പരീക്ഷണങ്ങളായി സിസിജി സൂപ്പര്\u200dട്ടാഗുകളുമായി പരീക്ഷിക്കുന്നു. ന്യൂറല്\u200d നെറ്റര്\u200d നെറ്റര്\u200d നെറ്റ്\u200cവര്\u200dക്ക് പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു. ആശ്രയിച്ചിരിക്കുന്നതിന്\u200dറെ കൂടെ', 'mn': 'Энэ цаасан дээр бид METU багийнхаа системийг олон хэлний текст хуваалцах универсал хамааралтай байдлын талаар тайлбарлаж байна. Бид мэдрэлийн сүлжээнд суурилсан хамааралтай хуваалцааг ашиглаж байна. Энэ нь хамааралтай хуваалцааг хамааралтай шилжилт хэрэгтэй. CCG супертегтүүд зарим NLP ажлын тухай ашигтай баян бүтэц мэдээллийг агуулдаг. Бид CCG супер тегтэйгээ туршилтад нэмэлт өөрчлөлт гэж туршиж байна. Неврал сүлжээний хуваарч нь хамааралтай, хялбар CCG тегтэй болон бусад чанартай хамтдаа суралцагдсан.', 'pl': 'W artykule opisano system zespołu METU do uniwersalnego parsowania zależności tekstu wielojęzycznego. Używamy analizatora zależności opartego na sieci neuronowej, który ma chciwe podejście do analizowania zależności. Supertagi CCG zawierają bogate informacje strukturalne, które okazują się przydatne w niektórych zadaniach NLP. Eksperymentujemy z supertagami CCG jako dodatkowymi funkcjami w naszych eksperymentach. Parser sieci neuronowej jest trenowany wraz z zależnościami i uproszczonymi tagami CCG oraz innymi udostępnianymi funkcjami.', 'ro': 'În această lucrare descriem sistemul de analizare universală a dependenței textului multilingv de către echipa METU. Folosim un parser de dependență bazat pe rețeaua neurală care are o abordare de tranziție lacomă la analizarea dependenței. Supertagurile CCG conțin informații structurale bogate care se dovedesc utile în anumite sarcini PNL. Experimentăm cu supertaguri CCG ca caracteristici suplimentare în experimentele noastre. Analizorul de rețea neurală este instruit împreună cu dependențele și etichetele CCG simplificate, precum și alte caracteristici furnizate.', 'no': 'I denne papiret beskriver vi systemet av METU-gruppa for universell tolking av fleirspråk tekst. Vi bruker ein neuralnettverk-basert avhengighetsanalyser som har ein grødig overgang tilnærming til tolking av avhengighet. CCG- supertaggar inneheld rike strukturinformasjon som viser nyttig i enkelte NLP- oppgåver. Vi eksperimenterer med CCG-supertaggar som ekstra funksjonar i eksperimentet våre. Neuralnettverkstolkaren er trent saman med avhengighet og enkelte CCG- taggar og andre funksjonar som er tilgjengelege.', 'so': 'Qoraalkan waxaan ku qornaa kooxda METU ee ku qoran jardiinada ku saabsan baaritaanka farshaxanka luuqadaha kala duduwan. Waxaynu isticmaalnaa baarlamaha ku xiran shabakadda neurada ee ku saleysan xiriirka, kaas oo leedahay hab-beddelista baarlamaanka ku xiran. CCG supertag waxaa ku jira macluumaad taajir ah oo ku caddeysa faa’iido leh goobaha qaarkood oo la sameeyo NLP. Imtixaanadeena waxaa lagu tijaabiyey CCG supertag oo kale. Internetka neurada ah waxaa la wada tababariyaa xiriirka ku xiran iyo alaabta CCG iyo sidoo kale tayooyin kale oo la siiyo.', 'sr': 'U ovom papiru opisujemo sistem METU tim za analizu univerzalne zavisnosti multijezičkog teksta. Koristimo analizator ovisnosti na neuralnoj mreži koji ima pohlepan pristup prema analizanju ovisnosti. Superetikete CCG sadrže bogate strukturne informacije koje dokazuju korisne u određenim NLP zadatkima. Eksperimentiramo sa CCG superznakovima kao dodatne karakteristike u našim eksperimentima. Analizator neuralne mreže je obučen zajedno sa ovisnošću i pojednostavljenim oznakem CCG-a, kao i drugim osiguranim karakteristikama.', 'sv': 'I denna uppsats beskriver vi METU-teamets system för universell beroendetolkning av flerspråkig text. Vi använder en neuralt nätverksbaserad beroendeparser som har en girig övergångsmetod till beroendetolkning. CCG supertaggar innehåller rik strukturell information som visar sig användbar i vissa NLP-uppgifter. Vi experimenterar med CCG supertaggar som ytterligare funktioner i våra experiment. Den neurala nätverkstolkaren tränas tillsammans med beroenden och förenklade CCG-taggar samt andra funktioner som tillhandahålls.', 'si': 'මේ පත්තරේ අපි පද්ධතිය METU කණ්ඩායමෙන් විවෘත කරන්නේ විශේෂ භාෂාවක් පාළුවේ සාමාන්\u200dය විශේෂ අපි න්\u200dයූරල් ජාලයේ අධාරිත විශ්වාසයක් පාවිච්චි කරනවා, ඒකෙන් විශ්වාසය විශ්වාසයක් තියෙ CCG සුපර්ටැග් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් තොරතුරු තියෙනවා ඒකෙන් NLP වැඩ අපි CCG සුපර් ටැග් එක්ක පරීක්ෂණය කරනවා අපේ පරීක්ෂණාවට තවත් අවස්ථාවක් විදියට. න්\u200dයූරල් ජාලය විශේෂකය සමග විශේෂතාවක් සහ සරල CCG ටැග් සහ අනිත් අවශ්\u200dයතාවක් සඳහා පරීක්ෂණය කරලා', 'ta': 'இந்த காகிதத்தில் நாம் மெட்யு குழுவின் மூலம் முறைமையை விவரிக்கிறோம் பல மொழி உரையின் சார்ந்த சார்பு பா நாம் ஒரு புதிய வலைப்பின்னல் சார்பு சார்ந்த பாடலுக்கு சார்பு மாற்றும் வழிமாற்றம் உள்ளது. CCG supertags contain rich structural information that proves useful in certain NLP tasks.  நாங்கள் சிசிஜி சூப்பர்டாக்கள் மூலம் சோதனை செய்கிறோம் எங்கள் சோதனைகளில் கூடுதல் தன்மைகளாக. புதிய வலைப்பின்னல் பிரிப்பாளர் சார்புகளுடன் பயிற்சி செய்யப்பட்டுள்ளது மற்றும் சிசிஜி ஒட்டுகளுடன் சுலபமாக்கப்', 'ur': 'اس کاغذ میں ہم METU تیم کے ذریعہ سیسٹم کو متعدد زبان کے متن کی نسبت وابستگی کا پارس کرنے کے لئے بیان کرتے ہیں. ہم ایک نیورال نیٹ ورک بنیاد ڈیرنسیٹ پارچر استعمال کرتے ہیں جس کے پاس نیوڈنسیٹ پارچینگ کے لئے ایک گہری تغییر تقریبا ہے۔ CCG سوپر ٹاگ میں ثروت ساختار معلومات ہے جو کچھ NLP کاموں میں فائدہ دکھاتی ہے۔ ہم CCG سوپر ٹاگ کے ساتھ آزمائش کرتے ہیں اور ہمارے آزمائش میں اضافہ ویژگی کے طور پر۔ نیورال نیٹ ورک پارچر نیڈنسیٹ کے ساتھ اور ساده سی جی ٹاگ اور دوسری فرصت کے ساتھ تربیت کی جاتی ہے.', 'uz': "Bu hujjatda, biz bir necha til matnni ajratish uchun tizimni METU guruhiga qaramaymiz. Biz neyrolik tarmoq asosida ishlatadigan ishlatuvchi parametrlaridan foydalanamiz. Bu tashkilotni tasdiqlash uchun qo'shimcha tarmoqni qo'shish muvaffaqiyatsiz bor. Name Biz tajribamizda CCG supertaglari bilan qoʻshimcha xususiyatlar deb o'rganamiz. Name", 'vi': 'Trong tờ giấy này, chúng tôi mô tả hệ thống của đội MEU để phân tích mối quan hệ của văn bản đa dạng. Chúng tôi sử dụng một phân tích phụ thuộc dựa trên mạng thần kinh có một phương pháp chuyển đổi tham lam để phân tích phụ thuộc. Siêu nhãn CCG chứa chứa nhiều thông tin cấu trúc cực kỳ hữu ích trong một số việc làm của NMB. Chúng tôi thử nghiệm với thẻ CCG như những tính năng phụ trong thí nghiệm. Bộ phân tách mạng thần kinh được huấn luyện cùng với các quan hệ phụ thuộc và các thẻ CCG dễ dàng hơn và các tính năng khác được cung cấp.', 'nl': 'In dit artikel beschrijven we het systeem van het METU team voor universele afhankelijkheidsparsing van meertalige tekst. We gebruiken een op neuraal netwerk gebaseerde afhankelijkheidsparser die een hebberige overgangsaanpassing heeft voor afhankelijkheidsparsing. CCG-supertags bevatten rijke structurele informatie die nuttig blijkt te zijn bij bepaalde NLP-taken. We experimenteren met CCG supertags als extra features in onze experimenten. De neurale netwerkparser wordt getraind samen met afhankelijkheden en vereenvoudigde CCG-tags, evenals andere functies verstrekt.', 'bg': 'В настоящата статия описваме системата от екипа на МЕТУ за универсално анализиране на зависимостта на многоезичен текст. Използваме нервна мрежа базиран анализатор на зависимости, който има алчен преход към анализа на зависимостта. Супертаговете съдържат богата структурна информация, която се оказва полезна при определени задачи на НЛП. Експериментираме със супертагове като допълнителни функции в нашите експерименти. Неврологичният анализатор на мрежата се обучава заедно с зависимости и опростени тагове, както и други предоставени функции.', 'da': 'I denne artikel beskriver vi METU-teamets system til universel afhængighedsanalyse af flersproget tekst. Vi bruger en neural netværksbaseret afhængighedsfortolker, der har en grådig overgangstilgang til afhængighedsfortolkning. CCG supertags indeholder rige strukturelle oplysninger, der viser sig nyttige i visse NLP-opgaver. Vi eksperimenterer med CCG supertags som ekstra funktioner i vores eksperimenter. Den neurale netværk parser er trænet sammen med afhængigheder og forenklede CCG tags samt andre funktioner, der leveres.', 'hr': 'U ovom papiru opisujemo sistem METU tim za analizu univerzalne zavisnosti multijezičkog teksta. Koristimo analizator ovisnosti na neuralnoj mreži koji ima pohlepan prijelaz prema analizanju ovisnosti. Superznakovi CCG sadrže bogate strukturne informacije koje dokazuju korisne u određenim zadatkima NLP-a. Eksperimentiramo s CCG superznakovima kao dodatne karakteristike u našim eksperimentima. Analizator neuronske mreže obučen je zajedno s ovisnošću i pojednostavljenim oznakem CCG-a, kao i drugim osiguranim karakteristikama.', 'de': 'In diesem Beitrag beschreiben wir das System des METU-Teams zum universellen Dependency Parsing von mehrsprachigem Text. Wir verwenden einen neuronalen Netzwerk-basierten Abhängigkeitsparser, der einen gierigen Übergangsansatz für Abhängigkeitsparsing hat. CCG-Supertags enthalten umfangreiche strukturelle Informationen, die sich bei bestimmten NLP-Aufgaben als nützlich erweisen. Wir experimentieren mit CCG Supertags als zusätzliche Features in unseren Experimenten. Der neuronale Netzwerk-Parser wird zusammen mit Abhängigkeiten und vereinfachten CCG-Tags sowie weiteren Funktionen trainiert.', 'id': 'Dalam kertas ini kami menggambarkan sistem oleh tim METU untuk penghuraian dependensi universal dari teks multibahasa. Kami menggunakan parser dependensi jaringan saraf yang memiliki pendekatan transisi serakah untuk parsing dependensi. Supertag CCG mengandung informasi struktur yang kaya yang membuktikan berguna dalam tugas NLP tertentu. Kami eksperimen dengan supertag CCG sebagai fitur tambahan dalam eksperimen kami. Analyser jaringan saraf dilatih bersama dengan dependensi dan tags CCG yang sederhana serta fitur lain yang diberikan.', 'fa': 'در این کاغذ ما سیستم را توسط تیم METU برای تقسیم بستگی جهانی از متن multilingual توصیف می کنیم. ما از یک بازیگر بستگی بر روی شبکه عصبی استفاده می کنیم که یک طریق تغییر آرامشی برای بازیگر بستگی دارد. برچسب\u200cهای سی\u200cجی شامل اطلاعات ساختاری ثروتمند است که ثابت می\u200cکند در کار\u200cهای NLP خاص مفید باشد. ما به عنوان ویژه های اضافه در آزمایشات ما با برچسب های سی.جی آزمایش می کنیم. ویرایشگر شبکه عصبی با بستگی\u200cها و نقاشی\u200cهای CCG ساده\u200cشده و دیگر ویرایشگر\u200cهای پیشنهاد آموزش داده می\u200cشود.', 'ko': '본고에서 우리는 METU팀이 개발한 다국어 텍스트의 통용 의존 해석 시스템을 묘사했다.우리는 신경 네트워크를 바탕으로 하는 의존성 해석기를 사용하는데, 이 해석기는 탐욕 변환 방법으로 의존성 해석을 한다.CCG SuperTag에는 일부 NLP 작업에서 유용하다는 사실이 입증된 다양한 구조 정보가 포함되어 있습니다.우리는 실험에서 CCG supertags를 추가 기능으로 사용했다.신경 네트워크 분석기는 의존항, 간소화된 CCG 표기 및 제공된 기타 기능과 함께 훈련한다.', 'tr': 'Bu kagyzda biz METU topary tarapyndan uniwersal dilli metin baglanyşyklygyny tanyşdyrýarys. Biz näyral şebeke daýanýan baglançylyk tansçysyny ulanýarys. CCG süper tägleri baý struktur maglumaty bardyr ki bu NLP işinde faydaly görkez. Biz CCG süper taglary bilen synanyşmalarymyzda köpüräk özellikler diýip barýarys. Näyral şebek tansçysy baglyklar bilen birlikte, basitlendirilen CCG tägleri we beýleki özellikler bilen eğlenýär.', 'sw': 'Katika karatasi hii tunaelezea mfumo wa timu ya METU kwa ajili ya wimbo wa kuaminika kwa lugha mbalimbali. Tunatumia mchambuzi wa kutegemea mtandao wa neurali ambao una mbinu za mabadiliko ya uchumi kwa ajili ya kuingiza kituo cha kutegemea. Jukwaa la CCG lina taarifa zenye utajiri wa miundombinu inayothibitisha kuwa na ufanisi katika kazi fulani za NLP. Tunajaribu kwa vifaa vya CCG kama vipengele vya ziada katika majaribio yetu. Mtandao wa kituo cha neurali unafundishwa pamoja na kutegemea na viungo rahisi vya CCG pamoja na vipengele vingine vinavyotolewa.', 'af': "In hierdie papier beskryf ons die stelsel deur METU-span vir universele afhanklikheid verwerking van multilingse teks. Ons gebruik 'n neuralnetwerk-gebaseerde afhanklikheidspanser wat 'n groet oordrag toegang het na afhanklikheidspansering. CCG superetikette bevat ryk struktuurlike inligting wat gebruiklik bevestig in sekere NLP taak. Ons eksperimenteer met CCG superetikette as addisionele funksies in ons eksperimente. Die neuralnetwerk ontleerder is opgelei saam met afhanklikhede en eenvoudige CCG etikette as ook ander funksies verskaf.", 'sq': 'Në këtë letër ne e përshkruajmë sistemin nga ekipi METU për analizimin universal të varësisë së tekstit shumëgjuhësor. Ne përdorim një analizues të varësisë në rrjetin nervor që ka një metodë tranzicionale lakmuese për analizimin e varësisë. Supertags CCG përmbajnë informacion strukturor të pasur që është e dobishme në disa detyra NLP. Ne eksperimentojmë me superetiketa CCG si karakteristika shtesë në eksperimentet tona. Analizatori i rrjetit nervor është trajnuar së bashku me varësitë dhe etiketat e thjeshta CCG si dhe karakteristikat e tjera të ofruara.', 'am': 'በዚህ ፕሮግራም የብዙልቋንቋ ጽሑፎችን ለመጠቀም የምሜቲዩን ቡድን እናሳውቃለን፡፡ የናቡራል መረብ-based የጠቃሚ ተሟጋቾች መተላለፊያ እናስጠጋለን፡፡ CCG supertags contains rich structural information that proves useful in some NLP tasks. ከ CCG supertags ጋር በሞከራችንን አብዛኛዎች የፊደል ፈተና እናደርጋለን፡፡ የኔውሩኤል መረብ ተማሪ በተማሪዎቹ እና የCCG መክፈቻዎች እና ሌሎች ምርጫዎች በተቀራረቡ ነው፡፡', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք համակարգը Մետու թիմի կողմից բազլեզու տեքստի համընդհանուր կախվածության վերլուծության համար: Մենք օգտագործում ենք նյարդային ցանցի հիմնված կախվածության վերլուծողը, որը ունի կախվածության վերլուծման հարաբերության ագահոտ վերափոխման մոտեցում: Հիմնական համակարգչային համակարգչային սուպերթեգերը պարունակում են հարուստ կառուցվածքային ինֆորմացիա, որը պարզվում է օգտակար որոշ ՆԼՊ-ի առաջադրանքներում: We experiment with CCG supertags as additional features in our experiments.  Նյարդային ցանցի վերլուծումը վարժեցվում է միասին կախվածությունների, պարզ համակարգչային հատվածների, ինչպես նաև այլ առանձնահատկությունների հետ:', 'ca': "En aquest paper descrivim el sistema per l'equip METU per l'analització universal de la dependencia del text multillenguatge. Utilitzem un analitzador de dependencies basat en la xarxa neuronal que té un enfocament de transició agradable a l'analització de dependencies. Les superetiquetes de la CCG contenen informació estructural rica que resulta útil en determinades tasques del NLP. Experimentem amb superetiquetes CCG com característiques adicionals en els nostres experiments. L'analitzador de xarxa neural està entrenat juntament amb dependencies i etiquetes CCG simplificades, com també altres característiques proporcionades.", 'bn': 'এই কাগজটিতে আমরা বিশ্বব্যাপী নির্ভরশীল পার্জিং এর জন্য মেটিউ টিমের ব্যবস্থা বর্ণনা করি। আমরা নিউরেল নেটওয়ার্ক ভিত্তিক নির্ভরশীল প্যারেন্ট ব্যবহার করি যা নির্ভরশীল পার্সিং এর জন্য একটি লাভী প্রতিবেদন প সিসিজি সুপার্ট্যাগের মধ্যে সমৃদ্ধ কাঠামোর তথ্য রয়েছে যা কিছু NLP কাজে কার্যকর প্রমাণ করে। আমরা সিসিজি সুপার্ট্যাগের সাথে পরীক্ষা করি আমাদের পরীক্ষায় আরো বৈশিষ্ট্য হিসেবে। নিউরেল নেটওয়ার্ক প্যারেজার একসাথে নির্ভরশীল এবং সিসিজি ট্যাগ সহজ করে এবং অন্যান্য বৈশিষ্ট্য প্রদান করা হয়।', 'cs': 'V tomto článku popisujeme systém týmu METU pro univerzální analýzu závislostí vícejazyčného textu. Používáme analýzu závislostí založený na neuronové síti, který má chamtivý přechod k analýze závislostí. CCG supertagy obsahují bohaté strukturální informace, které jsou užitečné v některých úkolech NLP. Experimentujeme s CCG supertagy jako další funkce v našich experimentech. Parser neuronové sítě je trénován společně se závislostmi a zjednodušenými CCG tagy a dalšími poskytovanými funkcemi.', 'et': 'Käesolevas töös kirjeldame METU meeskonna poolt mitmekeelse teksti universaalse sõltuvuse parsimise süsteemi. Me kasutame närvivõrgupõhist sõltuvuse parserit, millel on ahne üleminek sõltuvuse parsimisele. CCG supersildid sisaldavad rikkalikku struktuuriinfot, mis osutub kasulikuks teatud NLP ülesannetes. Me eksperimenteerime CCG supersiltidega kui lisafunktsioonidega oma eksperimentides. Närvivõrgu parser on koolitatud koos sõltuvuste ja lihtsustatud CCG siltide ning muude pakutavate funktsioonidega.', 'fi': 'Tässä artikkelissa kuvaillaan METU-tiimin järjestelmää monikielisen tekstin yleisriippuvuuden jäsentämiseksi. Käytämme neuroverkkopohjaista riippuvuuden parseria, jolla on ahne siirtymälähestymistapa riippuvuuden parsirointiin. CCG-supertagit sisältävät runsaasti rakenteellista tietoa, joka osoittautuu hyödylliseksi tietyissä NLP-tehtävissä. Kokeilemme CCG-supertageja lisäominaisuuksina kokeiluissamme. Neuroverkon jäsentäjä on koulutettu yhdessä riippuvuuksien ja yksinkertaistettujen CCG-tagien sekä muiden ominaisuuksien kanssa.', 'az': 'Bu kağızda çoxlu dil mətnlərin üniversal bağımlılıq ayırması üçün METU ekibi ilə sistemi tanımlıyıq. Biz nöral a ğ tərəfindən bağlılıq parçacısını istifadə edirik ki, bağlılıq ayırılmasına könüllü bir dəyişiklik tərəfindən istifadə edir. CCG süper etiketləri bəzi NLP işlərində faydalı göstərən zəngin strukturlu məlumatlar barəsindədir. Biz CCG süper etiketlərlə imtahana çəkirik, eksperimentlərimizdə əlavə özelliklər olaraq. Nöral ağ ayırıcısı bağlılıqlarla birlikdə təhsil edilir, CCG etiketləri və başqa özellikləri təhsil edilir.', 'bs': 'U ovom papiru opisujemo sistem METU tim za analizu univerzalne zavisnosti multijezičkog teksta. Koristimo analizator ovisnosti na neuralnoj mreži koji ima pohlepan pristup prema analizanju ovisnosti. Superznakovi CCG sadrže bogate strukturne informacije koje dokazuju korisne u određenim NLP zadatkima. Eksperimentiramo sa CCG superznakovima kao dodatne karakteristike u našim eksperimentima. Analizator neuronske mreže obučen je zajedno s ovisnošću i jednostavljenim oznakem CCG-a, kao i drugim osiguranim karakteristikama.', 'jv': 'Nang pepulan iki, kita ngubah sistem karo perintah MET dumateng kapan universel dipunangkapan kanggo teks multilanggar. Kernel Display boxes Awak dhéwé énsurutan karo pergambar-pergambar yang mpungatan karo ingkang énsurutan. Kernel', 'sk': 'V prispevku opisujemo sistem ekipe METU za razčlenitev univerzalne odvisnosti večjezičnega besedila. Uporabljamo razčlenjevalnik odvisnosti, ki temelji na nevronskem omrežju, ki ima pohlepen pristop k razčlenjevanju odvisnosti. CCG superoznake vsebujejo bogate strukturne informacije, ki so koristne pri določenih nalogah NLP. Kot dodatne funkcije v naših poskusih eksperimentiramo s CCG superoznakami. Razčlenjevalnik nevronskega omrežja je usposobljen skupaj z odvisnostmi in poenostavljenimi oznakami CCG ter drugimi funkcijami.', 'ha': "Ga wannan takardan da Muke bayyana na'urar na'urar da team na METU wa karatun littãfin da ke cikin multilala. Munã yi amfani da wani parse mai da aka ƙayyade bakin tarayya na neural wanda yana da wata mataimaki mai kwaɗayi zuwa parse da inganci. @ info Za jarraba da CCG surtags kamar wasu mistakardar da ke cikin jarrabamarmu. Ana sanar da shirin taruwar neural na haɗi da ɗayan tagogi na CCG da masu sauƙi da wasu tayari da aka samar da.", 'he': 'בעיתון הזה אנחנו מתארים את המערכת על ידי צוות METU עבור בדיקת תלויות אוניברסלית של טקסט רב-שפתי. We use a neural network-based dependency parser that has a greedy transition approach to dependency parsing.  CCG supertags contain rich structural information that proves useful in certain NLP tasks.  אנו מנסים עם תגים על CCG כתכונות נוספות בניסויים שלנו. מעבד הרשת העצבית מאומן יחד עם תלויות ותגיות CCG מופשטות כמו גם תכונות אחרות שנספקו.', 'bo': 'ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་METU་དབང་ཆ་གྱི་སྤྱི་ཚོགས་རྟེན་འབྲེལ་མཐུན་ཡིག་གི་དབྱེ་སྟངས་ལ་བཤད་ཀྱི་མིང་། ང་ཚོས་རང་ཉིད་དྲ་རྟེན་དང་མཉམ་དུ་འབྲེལ་བའི་རྟེན་འབྲེལ་ཞིག་བེད་སྤྱོད་ཀྱི་ཡོད། CCG supertags contain rich structural information that proves useful in certain NLP tasks. ང་ཚོས་ཚོའི་སྒེར་གྱི་ནང་དུ་CCG གཟུགས་རིས་ལག་ལེན་བྱེད་བཞིན་པའི་ཁྱད་ཆོས་ཁྱད་ཆོས་ཡོད། ནུས་མཐུན་དྲ་ཞིབ་པས་རྟེན་འབྲེལ་བ་དང་སྔོན་བསླབ་པའི་CCG ཤོག་བྱང་དང་ཁྱད་ཆོས་གཞན་ཞིག'}
{'en': 'CLCL (Geneva) DINN Parser : a Neural Network Dependency Parser Ten Years Later', 'ar': 'محلل CLCL (جنيف) DINN: محلل تبعية الشبكة العصبية بعد عشر سنوات', 'es': 'Analizador DINN de CLCL (Ginebra): un analizador de dependencias de redes neuronales diez años después', 'fr': 'CLCL (Genève) DINN Parser\xa0: un analyseur de dépendance de réseaux neuronaux dix ans plus tard', 'pt': 'Analisador DINN CLCL (Genebra): um analisador de dependência de rede neural dez anos depois', 'ja': 'CLCL （ジュネーブ） DINNパーサー： 10年後のニューラルネットワーク依存パーサー', 'zh': 'CLCL(日内瓦)DINN 解析器:十年之神经网络赖解析器', 'hi': 'CLCL (जिनेवा) DINN पार्सर: एक तंत्रिका नेटवर्क निर्भरता पार्सर दस साल बाद', 'ru': 'CLCL (Женева) DINN Parser: a Neural Network Dependency Parser Десять лет спустя', 'ga': 'CLCL (An Ghinéiv) Parsálaí DINN: Parsálaí um Spleáchas Líonra Néarach Deich mBliana ina dhiaidh sin', 'hu': 'CLCL (Genf) DINN Parser: a Neural Network Dependency Parser Tíz évvel később', 'el': 'Η ανάλυση της εξάρτησης από το Νευρικό Δίκτυο δέκα χρόνια αργότερα', 'it': 'CLCL (Ginevra) CENA Parser: un Neural Network Dependency Parser Dieci Anni dopo', 'kk': 'CLCL (Женева) DINN параметрі: нейрондық желінің тәуелдігі өзгертуші 10 жылдан кейін', 'lt': 'CLCL (Ženevo) DINN analizatorius: neurologinio tinklo priklausomybės analizatorius po dešimties metų', 'mk': 'CLCL (Женева) DINN анализатор: анализатор на зависноста од невралната мрежа 10 години подоцна', 'ml': 'Name', 'ms': 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser Ten Years Later', 'mt': 'CLCL (Ġinevra) DINN Parser: Parser tad-Dipendenza tan-Netwerk Newrali għaxar snin wara', 'mn': 'CLCL (Женева) DINN Parser: a Neural Network Dependency Parser 10 Years Later', 'ka': 'CLCL', 'no': 'CLCL (Geneva) DINN- tolkar: ein neuralnettverk avhengighet tolkar ti år seinare', 'pl': 'CLCL (Genewa) PARser DINN: parser zależności od sieci neuronowej dziesięć lat później', 'ro': 'CLCL (Geneva) CENA Parser: o rețea neurală de dependență Parser zece ani mai târziu', 'sr': 'CLCL (Ženeva) DINN Parser: Neuralna mreža zavisnost Parser 10 godina kasnije', 'so': 'CLCL (Geneva) DINN Parser: a Neural Network Dependence Parser 10 years later', 'si': 'CLCL (ජෙනෙවා) DINN පරීක්ෂකය: න්\u200dයූරාල ජාල විශේෂතාවක් අවුරුදු දහයක් පස්සේ පරීක්ෂකය', 'sv': 'CLCL (Genève) DINN Parser: en Neural Network Dependency Parser tio år senare', 'ta': 'CLCL (Geneva) DINN Parser: ஒரு புதிய வலைப்பின்னல் சார்ந்த சார்ந்த Parser பத்து ஆண்டுகள் பின்னர்', 'ur': 'CLCL', 'uz': 'Name', 'vi': '[Trong một trường hợp khác nhau]', 'nl': 'CLCL (Genève) DINN Parser: een neuronale netwerkafhankelijkheid Parser tien jaar later', 'bg': 'Дневен анализ: Десет години по-късно анализ на зависимостта от невралната мрежа', 'da': 'CLCL (Geneve) DINN Parser: a Neural Network Dependency Parser Ti Years Later', 'hr': 'CLCL (Ženeva) DINN Parser: Neuralna mreža zavisnost Parser 10 godina kasnije', 'id': 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser 10 tahun kemudian', 'fa': 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser 10 Years Later', 'sw': 'CLCL (Geneva) Mbunge wa DINN: Mwaka kumi baadae', 'de': 'CLCL (Genf) DINN Parser: ein neuronaler NetzwerkabhĂ¤ngigkeitsparser zehn Jahre spĂ¤ter', 'ko': 'CLCL(제네바)DINN 해상도: 10년 후의 신경 네트워크 의존 해상도', 'af': 'CLCL (Geneva) DINN verwerker: 芒聙聶n Neurale netwerk afhanklikheid verwerker tien jaar Later', 'sq': 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser Ten Years Later', 'am': 'CLCL (Geneva) DINN Parser: የኔural Network Dependency Parser Ten ዓመት በኋላ', 'hy': 'ՔԼԼ (Ջենեվա) ԴԻՆ վերլուծողը՝ նյարդային ցանցի կախվածության վերլուծողը 10 տարի անց', 'az': 'CLCL (Geneva) DINN Parser: Nöral Ağ bağımlılığı Parser 10 il sonra', 'tr': 'CLCL', 'bn': 'সিএলসিএল (জেনেভা) ডিনেন প্যারার: একটি নিউরেল নেটওয়ার্ক নির্ভরিত পার্সার দশ বছর পরে', 'bs': 'CLCL (Ženeva) DINN Parser: Neuralna mreža zavisnost Parser 10 godina kasnije', 'cs': 'CLCL (Ženeva) DINN Parser: analýza závislosti na neuronových sítích o deset let později', 'et': 'CLCL (Geneva) DINN Parser: neuraalse võrgu sõltuvuse parser kümme aastat hiljem', 'fi': 'CLCL (Geneve) DINN Parser: hermoverkon riippuvuuden parser kymmenen vuotta myöhemmin', 'ca': 'CLCL (Genève) DINN Parser: un Parser de Dependencies de la Rede Neural 10 anys després', 'jv': 'CLCL', 'sk': 'CLCL (Ženeva) DINN Parser: Parser nevralne mreže odvisnosti deset let kasneje', 'ha': 'KCharselect unicode block name', 'he': 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser Ten Years Later', 'bo': 'CLCL (Geneva) DINN Parser: a Neural Network Dependency Parser Ten Years Later'}
{'en': 'This paper describes the University of Geneva’s submission to the CoNLL 2017 shared task Multilingual Parsing from Raw Text to Universal Dependencies (listed as the CLCL (Geneva) entry). Our submitted parsing system is the grandchild of the first transition-based neural network dependency parser, which was the University of Geneva’s entry in the CoNLL 2007 multilingual dependency parsing shared task, with some improvements to speed and portability. These results provide a baseline for investigating how far we have come in the past ten years of work on neural network dependency parsing.', 'ar': 'تصف هذه الورقة تقديم جامعة جنيف إلى المهمة المشتركة لـ CoNLL 2017 التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية (المدرجة باسم إدخال CLCL (جنيف)). نظام الاعراب المقدم لدينا هو الحفيد الأول لمحلل تبعية الشبكة العصبية القائم على الانتقال ، والذي كان بمثابة دخول جامعة جنيف في مهمة تحليل التبعية متعددة اللغات لـ CoNLL 2007 ، مع بعض التحسينات على السرعة وقابلية النقل. توفر هذه النتائج أساسًا للتحقيق في مدى تقدمنا في السنوات العشر الماضية من العمل على تحليل تبعية الشبكة العصبية.', 'fr': "Cet article décrit la soumission de l'Université de Genève à la tâche partagée ConLL 2017 Multilingual Parsing from Raw Text to Universal Dependencies (listée comme entrée CLCL (Genève)). Notre système d'analyse est le petit-fils du premier analyseur de dépendance de réseau neuronal basé sur la transition, qui a été l'entrée de l'Université de Genève dans la tâche partagée d'analyse de dépendance multilingue ConLL 2007, avec quelques améliorations de vitesse et de portabilité. Ces résultats fournissent une base de référence pour étudier le chemin parcouru au cours des dix dernières années de travail sur l'analyse de dépendance des réseaux neuronaux.", 'pt': 'Este artigo descreve a submissão da Universidade de Genebra à tarefa compartilhada CoNLL 2017 Análise multilíngue de texto bruto para dependências universais (listada como a entrada CLCL (Genebra)). Nosso sistema de análise submetido é o neto do primeiro analisador de dependência de rede neural baseado em transição, que foi a entrada da Universidade de Genebra na tarefa compartilhada de análise de dependência multilíngue CoNLL 2007, com algumas melhorias na velocidade e portabilidade. Esses resultados fornecem uma linha de base para investigar até que ponto chegamos nos últimos dez anos de trabalho na análise de dependência de rede neural.', 'es': 'Este artículo describe la presentación de la Universidad de Ginebra a la tarea compartida CoNLL 2017 Análisis multilingüe del texto sin procesar a las dependencias universales (incluida como la entrada CLCL (Ginebra)). Nuestro sistema de análisis presentado es el nieto del primer analizador de dependencias de redes neuronales basado en transición, que fue la entrada de la Universidad de Ginebra en la tarea compartida de análisis de dependencias multilingües de CoNll 2007, con algunas mejoras en la velocidad y la portabilidad. Estos resultados proporcionan una base para investigar hasta dónde hemos llegado en los últimos diez años de trabajo en el análisis de dependencias de redes neuronales.', 'ja': '本稿では、ジュネーブ大学がCONLL 2017に提出した、生テキストから普遍的な依存関係への多言語構文解析（ CLCL （ジュネーブ）エントリとしてリストされています）について説明します。私たちが提出した構文解析システムは、最初の遷移ベースのニューラルネットワーク依存性構文解析器の孫です。これは、速度とポータビリティをいくつか改善したCoNLL 2007の多言語依存性構文解析共有タスクへのジュネーブ大学のエントリでした。これらの結果は、ニューラルネットワーク依存性解析に関する過去10年間の研究でどの程度の成果を上げたかを調査するためのベースラインを提供します。', 'zh': '本文引日内瓦大学向CoNLL 2017共享提交的从原始文本到通用靠关系的多言语解析(列为CLCL(日内瓦)条目)。 臣等提交解析统,首基于转换神经网络赖解析器之子孙,此日内瓦大学于CoNLL 2007多言赖解析共享之条目,速可移植性改也。 十年之神经网络依赖性解析,多所进基线。', 'hi': 'यह पेपर जिनेवा विश्वविद्यालय के CoNLL 2017 साझा कार्य बहुभाषी पार्सिंग को कच्चे पाठ से यूनिवर्सल निर्भरताओं (CLCL (जिनेवा) प्रविष्टि के रूप में सूचीबद्ध) के लिए प्रस्तुत करने का वर्णन करता है। हमारी प्रस्तुत पार्सिंग प्रणाली पहले संक्रमण-आधारित तंत्रिका नेटवर्क निर्भरता पार्सर का पोता है, जो कि CoNLL 2007 बहुभाषी निर्भरता पार्सिंग साझा कार्य में जिनेवा विश्वविद्यालय की प्रविष्टि थी, गति और पोर्टेबिलिटी में कुछ सुधार के साथ। ये परिणाम जांच के लिए एक आधार रेखा प्रदान करते हैं कि हम तंत्रिका नेटवर्क निर्भरता पार्सिंग पर काम के पिछले दस वर्षों में कितनी दूर आ गए हैं।', 'ru': 'В этой статье описывается представление Женевского университета на совместную задачу CoNLL 2017 «Многоязычный парсинг от необработанного текста к универсальным зависимостям» (указана как запись CLCL (Женева)). Наша представленная система синтаксического анализа является внуком первого синтаксического анализатора зависимостей нейронной сети на основе перехода, который был введен Женевским университетом в многоязычную задачу синтаксического анализа зависимостей CoNLL 2007 с некоторыми улучшениями скорости и переносимости. Эти результаты служат основой для исследования того, насколько далеко мы продвинулись за последние десять лет в работе по синтаксическому анализу зависимостей нейронных сетей.', 'ga': "Déanann an páipéar seo cur síos ar aighneacht Ollscoil na Ginéive chuig tasc comhroinnte CoNLL 2017 Parsáil Ilteangach ó Théacs Raw go Spleáchais Uilíocha (liostaithe mar iontráil CLCL (An Ghinéiv). Is é ár gcóras parsála a cuireadh isteach ná garleanbh an chéad pharsálaí spleáchais néarlíonra atá bunaithe ar thrasdul, arbh é iontráil Ollscoil na Ginéive é i dtasc roinnte spleáchais ilteangach CoNLL 2007, le roinnt feabhsuithe ar an luas agus ar an inaistritheacht. Soláthraíonn na torthaí seo bonnlíne chun imscrúdú a dhéanamh ar cé chomh fada agus atáimid le deich mbliana anuas d'obair ar pharsáil spleáchais ar líonraí néaracha.", 'ka': 'ამ დოკუმენტის შესახებ ზენეგონის სუნივერტის შესახებ, რომელიც CoNLL 2017 წევრილი მრავალენგური პარამეტრების შესახებ მრავალენგური ტექსტიდან უნივერსალური განსახებებისთვის. ჩვენი გადაწყვეტილი პარაზიციის სისტემა არის პირველი გადაწყვეტილი ნეიროლური ქსელის დაფართობის პარაზერი, რომელიც იყო ზენეგას სუნივერტის გადაწყვეტილი CoNLL 2007-ში მულტილური დაფართობის გადაწყვეტილი დავაწყვეტი ამ შედეგი შემდეგი შემდეგი გავაკეთებთ, რომლებიც გავაკეთებთ შემდეგი 10 წლის სამუშაო სამუშაო ნეიროლური ქსელის დასაკეთებელობაზე.', 'el': 'Η παρούσα εργασία περιγράφει την υποβολή του Πανεπιστημίου της Γενεύης στην κοινή εργασία Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις (καταχωρισμένη ως καταχώρηση CLCL (Γενεύη). Το υποβαλλόμενο σύστημα ανάλυσης είναι το εγγόνι του πρώτου αναλυτή εξάρτησης νευρωνικών δικτύων που βασίζεται στη μετάβαση, ο οποίος ήταν η είσοδος του Πανεπιστημίου της Γενεύης στην πολυγλωσσική εργασία ανάλυσης εξάρτησης 2007, με ορισμένες βελτιώσεις στην ταχύτητα και τη φορητότητα. Αυτά τα αποτελέσματα παρέχουν μια βάση για τη διερεύνηση του πόσο μακριά έχουμε φτάσει τα τελευταία δέκα χρόνια εργασίας σχετικά με την ανάλυση εξάρτησης νευρωνικών δικτύων.', 'hu': 'Ez a tanulmány bemutatja a Genfi Egyetem benyújtását a CoNLL 2017 megosztott feladathoz Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig (CLCL (Genf) bejegyzés). A benyújtott elemzési rendszerünk az első átmeneti alapú neurális hálózati függőség-elemző unokája, amely a Genfi Egyetem bejegyzése volt a CoNLL 2007 többnyelvű függőség-elemző megosztott feladatban, néhány javítással a sebesség és hordozhatóság terén. Ezek az eredmények alapját adják annak vizsgálatára, hogy milyen messzire jutottunk az elmúlt tíz év ideghálózati függőség elemzésével kapcsolatos munka során.', 'it': "Questo articolo descrive la presentazione dell'Università di Ginevra al compito condiviso CoNLL 2017 Multilingual Parsing from Raw Text to Universal Dependences (elencato come la voce CLCL (Ginevra). Il nostro sistema di analisi presentato è il nipote del primo parser di dipendenza della rete neurale basato sulla transizione, che è stato l'ingresso dell'Università di Ginevra nel compito condiviso di analisi delle dipendenze multilingue CoNLL 2007, con alcuni miglioramenti in termini di velocità e portabilità. Questi risultati forniscono una base di riferimento per indagare fino a che punto siamo arrivati negli ultimi dieci anni di lavoro sull'analisi delle dipendenze della rete neurale.", 'kk': 'Бұл қағаз Женева университетінің CoNLL 2017 жылы бірнеше тілді талдау тапсырмасына жеткізілген тапсырмаларды бірнеше тілді талдау (CLCL (Женева) деп аталады. Біздің келтірілген талдау жүйесіміз - бірінші ауыстыру негізгі желінің тәуелсіздік талдаушысының баласы. Бұл Женева университетінің CoNLL 2007 жылы бірнеше тілдік тәуелсіздік талдау тапсырмасының баласы. Бұл Бұл нәтижелер неврал желінің тәуелсіздік талдау үшін оның соңғы он жылда жұмыс істеу үшін негізгі сызық болады.', 'lt': 'Šiame dokumente aprašomas Ženevos universiteto pranešimas dėl bendros CoNLL 2017 m. užduoties daugiakalbis analizavimas iš žaliavinio teksto į universaliąsias priklausomybes (išvardytas kaip CLCL (Ženevo) įrašas). Mūs ų pateikta analizavimo sistema yra pirmojo pereinamojo laikotarpio priklausomybės nuo nervų tinklo analizatoriaus vaikas, kuris buvo Ženevos universiteto įrašas į 2007 m. CoNLL daugiakalbį priklausomybės analizatorių bendrą užduotį, kai kurie greičio ir perkeliamumo pagerinimai. Šie rezultatai yra pagrindas tyrimui, kaip toli per pastaruosius dešimt metų dirbome su priklausomybės nuo nervų tinklo analize.', 'mk': 'Овој весник го опишува поднесувањето на Универзитетот во Женева на заедничката задача CoNLL 2017 Multilingual Parsing from Raw Text to Universal Dependencies (listed as the CLCL (Geneva)). Нашиот поднесен систем на анализирање е внукот на првиот анализирач на зависност од нервната мрежа базиран на транзиција, кој беше влезот на Универзитетот во Женева во Мултијазичната зависност CoNLL 2007 анализирајќи заедничка задача, со некои подобрувања во брзината и преносносноста. Овие резултати обезбедуваат основа за истрага колку далеку стигнавме во изминатите десет години на работата на анализирањето на зависноста од нервната мрежа.', 'ms': 'Kertas ini menggambarkan penghantaran Universiti Geneva kepada tugas kongsi CoNLL 2017 Penghuraian Berbahasa Dari Teks Raw ke Dependencies Universal (terdaftar sebagai masukan CLCL (Geneva). Sistem penghuraian yang dihantar kami adalah cucu penghuraian dependensi rangkaian saraf berdasarkan transisi pertama, yang merupakan masukan Universiti Geneva dalam penghuraian dependensi berbilang bahasa CoNLL 2007, dengan beberapa peningkatan pada kelajuan dan portabiliti. Hasil ini menyediakan dasar untuk menyelidiki sejauh mana kita telah datang dalam 10 tahun terakhir kerja pada penghuraian dependensi rangkaian saraf.', 'mt': "Dan id-dokument jiddeskrivi s-sottomissjoni tal-Università ta' Ġinevra lill-kompitu kondiviż CoNLL 2017 Parsing Multilingual from Raw Text to Universal Dependencies (listed as the CL (Geneva)). Is-sistema ta’ analiżi sottomessa tagħna hija n-nieqes tal-ewwel analizzatur tad-dipendenza tan-netwerk newrali bbażat fuq it-tranżizzjoni, li kien id-dħul tal-Università ta’ Ġinevra fil-ħidma ta’ analiżi tad-dipendenza multilingwi CoNLL 2007, b’xi titjib fil-veloċità u l-portabbiltà. These results provide a baseline for investigating how far we have come in the past ten years of work on neural network dependency parsing.", 'mn': 'Энэ цаас Женевын Их Сургууль 2017 оны CoNLL-д хэлсэн ажлыг Raw Text-ээс олон хэлний шинжилгээ дэвшүүлэхэд (CLCL (Женева) нэртэй нэртэй). Бидний хуваалцах систем бол анхны шилжилтийн мэдрэлийн сүлжээний хамаарал хамааралтай хуваалцагч юм. Энэ нь Женева Их Сургууль 2007 оны CoNLL-ын олон хэлний хамааралтай хамааралтай ажлыг хуваалцаж, хурдан, хөдөлгөөнтэй хурдан сайжруулсан ажил Эдгээр үр дүнүүд нь мэдрэлийн сүлжээний хамааралтай хуваалцааны ажлын сүүлийн 10 жилийн турш бидний хэр хол ирсэн талаар судлах суурь шугам гаргадаг.', 'pl': 'Niniejszy artykuł opisuje zgłoszenie Uniwersytetu Genewskiego do wspólnego zadania CoNLL 2017 Wielojęzyczne Parsowanie z tekstu surowego do uzależnień powszechnych (wymienione jako wpis CLCL (Genewa). Nasz przesłany system parsowania jest wnukiem pierwszego parsera zależności sieci neuronowej opartego na przejściu, który był wejściem Uniwersytetu Genewskiego w wielojęzyczne zadanie parsowania zależności CoNLL 2007, z pewnymi ulepszeniami szybkości i przenośności. Wyniki te stanowią podstawę do zbadania, jak daleko zaszliśmy w ciągu ostatnich dziesięciu lat pracy nad parsowaniem zależności sieci neuronowych.', 'ml': "This paper describes the University of Geneva's submission to the CoNLL 2017 shared task Multilingual Parsing from Raw Text to Universal Dependencies (listed as the CLCL (Geneva) entry).  നമ്മുടെ സമ്മതിച്ച പാര്\u200dജിങ്ങ് സിസ്റ്റം ആദ്യത്തെ പ്രാന്\u200dസിന്\u200dറെ അടിസ്ഥാനമായ ന്യൂറല്\u200d നെറ്റല്\u200d നെറ്റല്\u200d ആശ്രയിക്കുന്നതിന്\u200dറെ മുത്തശിശുദ്ധിയാണ്, അത് കോണ്\u200dഎല ഈ ഫലങ്ങള്\u200d ന്യൂറല്\u200d നെറ്റര്\u200d നെറ്റോര്\u200dവര്\u200dഷത്തിന്റെ ആശ്രയിച്ച പാര്\u200dസിങ്ങില്\u200d എത്ര ദൂരം ഞങ്ങള്\u200d എത്ര ജോലിയില്\u200d എത്തിയെ", 'no': 'Denne papiret beskriver at Universiteten av Ženeva s øker til den delte oppgåva CoNLL 2017, fleirspråk tolking frå Raw Text til universelle avhengighet (lista som oppgåva CLCL (Geneva). Vårt tilsendte tolkingssystem er avborgen av den første overgangsbaserte neuralnettverksavhengighetsanalyseren, som var oppføringa i Universiteten av Geneva i CoNLL 2007 for å tolka delt oppgåve med nokre forbedringar til fart og portabilitet. Desse resultatene gjev ein grunnlinje for å undersøke kor langt vi har komme i dei siste ti årene av arbeidet på analysering av avhengighet på neuralnettverket.', 'sr': 'Ovaj papir opisuje podnošenje Univerziteta Ženeve na CoNLL 2017. zajednički zadatak Multilingual Parsing od Raw Text na univerzalne zavisnosti (navedeno kao ulaz CLCL (Ženeva). Naš predloženi analizacijski sistem je unuk prvog razmatrača zavisnosti neuralne mreže, koji je bio ulaz Univerziteta Ženeve u multijezičku zavisnost u analizu zajedničkog zadatka CoNLL 2007, s nekim poboljšanjem brzine i prenošljivosti. Ovi rezultati pružaju osnovnu liniju za istragu koliko smo dosli u poslednjih deset godina posla na analizu zavisnosti neurone mreže.', 'ro': 'Această lucrare descrie depunerea Universității din Geneva la sarcina comună CoNLL 2017 Parsing Multilingv from Raw Text to Universal Dependents (listată ca intrarea CLCL (Geneva). Sistemul nostru de analizare prezentat este nepotul primului parser de dependență a rețelei neurale bazat pe tranziție, care a fost intrarea Universității din Geneva în sarcina comună de analizare a dependențelor multilingve CoNLL 2007, cu unele îmbunătățiri ale vitezei și portabilității. Aceste rezultate oferă o bază de referință pentru a investiga cât de departe am ajuns în ultimii zece ani de muncă privind analizarea dependenței rețelelor neurale.', 'sv': 'Denna uppsats beskriver Genèves bidrag till CoNLL 2017 delade uppgift Flerspråkig tolkning från råtext till universella beroende (listad som CLCL-posten (Genève). Vårt inlämnade parsningssystem är barnbarn till den första övergångsbaserade beroendetolkaren för neurala nätverk, som var Genèves universitets bidrag i CoNLL 2007 flerspråkig beroendetolkning delade uppgift, med vissa förbättringar av hastighet och portabilitet. Dessa resultat ger en baslinje för att undersöka hur långt vi kommit under de senaste tio åren av arbete med beroendeanalys av neurala nätverk.', 'so': "Kanu wuxuu ku qoran yahay warqaddan jaamacadda Geneva uu u dhiibay CoNLL 2017 jardiinada luuqadaha kala duduwan ee Raw Text to Universal Dependences (listed as the CLCL (Geneva). Xiligayada baarlamaanka la soo dhiibay waa babka shabakadda neurada ee ugu horeysa ee ku saleysan tartamaha, kaas oo ahaa jaamacadda Geneva's entry ee CoNLL 2007, ku xiran jardiinada ku xiran luuqadaha kala duduwan, iyadoo lagu hagaajiyey qaar ka horumarinta dhaqsaha iyo habaarka. Arrimahaas waxay ka heleysaa shabakad baaritaanka ku saabsan baaritaanka ku saabsan shabakadda neurada.", 'ta': 'இந்த காக்கிதத்தை குறிப்பிடுகிறது ஜென்வா கல்லூரியில் கோன்எல் 2017 க்கு கொடுக்கப்பட்ட பணியில் இருந்து பல மொழி பாசிங்கில் இருந்து உலக சார்ந்த சா எங்கள் வழங்கப்பட்ட பாடல் அமைப்பு முதல் மாற்றத்தில் சார்ந்த புத்தகத்தின் சார்பு பிரச்சினையாகும், அது ஜென்வா கலைஞரில் உள்ள நுழைவு கோன்எல் 2007 பல மொழி சார்பு சார இந்த முடிவுகள் எத்தனை வரை நாங்கள் கடந்த பத்து ஆண்டுகளில் வேலை செய்திருக்கிறோம் என்பதை அறிவிக்க ஒரு அடிப்படைக்கோடு வழங', 'si': 'මේ පැත්තේ ජෙනෙවාගේ විශ්වාසිත්තාව සම්පූර්ණය සම්පූර්ණය කරනවා සම්පූර්ණ භාෂාවික විශේෂය සම්පූර්ණ විශේෂය (CLCL ( අපේ පරීක්ෂණ පද්ධතිය පරීක්ෂණ පද්ධතිය තමයි පලවෙනි පරීක්ෂණ පද්ධතිය න්\u200dයූරාල ජාලම් විශ්වාසයේ ජෙනිවා විශ්වාසිතාවේ ප්\u200dරවේශනය CoNLL 2007 මේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරවේශයක් ප්\u200dරවේශනය කරනවා අපි අන්තිම අවුරුදු දහයක් වැඩේ වැඩ කරල', 'ur': "This paper describes the University of Geneva's submission to the CoNLL 2017 shared task Multilingual Parsing from Raw Text to Universal Dependencies (listed as the CLCL (Geneva) entry). ہماری پیش فرض پارسینگ سیسٹم پہلی تغییر پر بنیاد رکھی نیورل نیٹ ورک اعتمادی پارچر کی نوزاد ہے، جسے CoNLL 2007 میں ملتی زبان اعتمادی پارسینس کی اولینستی تھی، ایک سرعت اور پورٹیبلیٹی کے ساتھ بہترین تغییرات کے ساتھ۔ یہ نتیجے ان کی تحقیق کے لئے ایک بنسس لین دیتے ہیں کہ ہم کس طرح اگلوں کے دس سالوں میں نیورل نیٹورک اعتباری پارسینگ پر آئے ہیں۔", 'uz': "Bu gaz Geneva Universitetga CoNLL 2017 bogʻliq vazifani ko'plab chiqaradi, Raw Matdan Universal Dependentlariga (CLCL (Geneva) yozuvga bogʻliq boʻlgan vazifa. Biz ajratilgan parsing tizimimiz, birinchi transition asosida neyrol tarmoqni ishlatuvchi qo'shimcha, bu CoNLL 2007 Universitetdagi bir necha tillar qo'shilgan vazifani o'zgartirish uchun birinchi tarmoq tarmoqning qo'shiladi, tezlik va tadbirlik bilan bir necha yaxshi o'zgarishlar bor. Bu natijalar past 10 yil ichida biz neyrol tarmoqning tashkilotlariga ishga qanchalik kelayotganimizni aniqlashga asosiy satrlar beradi.", 'vi': 'Tờ giấy này mô tả s ự đệ trình của Đại học Geneva đến giao dịch chung của Colt Thậm chí là đa ngôn ngữ phân tích từ văn bản thô đến các môi trường chung. Hệ thống phân tích được gửi đến là cháu của bộ phân tích hệ thần kinh đầu tiên dựa trên s ự chuyển hóa, vốn là mục nhập của Đại học Geneva, thành lập hệ thống phân chia sẻ sự phụ thuộc thuộc thuộc thuộc ngôn ngữ Codonl Mẹ, với một vài cải tiến về tốc độ và vận tải. Những kết quả này là một cơ sở để tìm hiểu xem chúng ta đã đi xa đến mức nào trong mười năm qua trong việc phân tích sự phụ thuộc mạng thần kinh.', 'bg': 'Настоящата статия описва представянето на Женевския университет в споделената задача Многоезична обработка от суров текст до универсални зависимости (изброена като запис за Женева). Нашата представена система за анализ е внуче на първия базиран на преход анализ на зависимостта от невронна мрежа, който беше влизането на Университета в Женева в многоезичния анализ на споделената задача, с някои подобрения в скоростта и преносимостта. Тези резултати осигуряват база за изследване колко далеч сме стигнали през последните десет години работа по анализ на зависимостта от невронната мрежа.', 'hr': 'Ovaj papir opisuje podnošenje Univerziteta Ženeve u CoNLL 2017. zajedničkom zadatku Multilingual Parsing od Raw Text na univerzalne zavisnosti (navedeno kao ulaz CLCL (Ženeva). Naš podnošeni analizacijski sustav je unuk prvog razmatrača zavisnosti neuralne mreže, koji je bio ulaz Univerziteta Ženeve u razmatranje multijezičke zavisnosti CoNLL 2007, zajedničkog zadatka s nekim poboljšanjem brzine i prenošljivosti. Ovi rezultati pružaju osnovnu liniju za istragu koliko smo dosli u posljednjih deset godina rada na analizu zavisnosti neurone mreže.', 'da': "Denne artikel beskriver universitetet i Genève's indsendelse til CoNLL 2017 delte opgave Flersproget tolkning fra rå tekst til universelle afhængigheder (opført som CLCL (Genève) post). Vores indsendte parsing system er barnebarn af den første overgangsbaserede neurale netværk afhængighed parser, som var University of Geneve's indgang i CoNLL 2007 flersprogede afhængighed parsing delt opgave, med nogle forbedringer af hastighed og portabilitet. Disse resultater giver en baseline for at undersøge, hvor langt vi er kommet i de sidste ti års arbejde med analyse af neurale netværk afhængighed.", 'nl': 'Dit artikel beschrijft de inzending van de Universiteit van Genève aan de gezamenlijke taak Meertalig Parsen van ruwe tekst naar universele afhankelijkheden (vermeld als de CLCL (Genève) vermelding). Ons ingezonden parsing systeem is het kleinkind van de eerste transitie-gebaseerde neuronale netwerk afhankelijkheidsparser, die de Universiteit van Genève was opgenomen in de CoNLL 2007 meertalige afhankelijkheidsparser, met enkele verbeteringen op het gebied van snelheid en draagbaarheid. Deze resultaten bieden een basis voor het onderzoeken van hoe ver we zijn gekomen in de afgelopen tien jaar van werk aan neuronale netwerkafhankelijkheid parsen.', 'id': 'Kertas ini menjelaskan pengiriman Universitas Geneva ke tugas kongsi CoNLL 2017 Penganalisan Berbahasa Berbahasa Dari Teks Raw ke Dependensi Universal (terdaftar sebagai entri CLCL (Geneva). Sistem penghuraian yang diserahkan kami adalah cucu dari penghuraian tergantung jaringan saraf berdasarkan transisi pertama, yang merupakan masukan Universitas Geneva di CoNLL 2007 penghuraian berbagai bahasa tugas berbagi, dengan beberapa peningkatan pada kecepatan dan portabilitas. These results provide a baseline for investigating how far we have come in the past ten years of work on neural network dependency parsing.', 'de': 'Dieser Beitrag beschreibt die Einreichung der Universität Genf an die gemeinsame Aufgabe CoNLL 2017 Mehrsprachiges Parsing von Rohtext zu Universal Dependencies (gelistet als CLCL (Genf) Eintrag). Unser eingereichtes Parsing-System ist das Enkelkind des ersten Übergangs-basierten neuronalen Netzwerkabhängigkeitsparsers, der der Einstieg der Universität Genf in die mehrsprachige Aufgabe CoNLL 2007 war, mit einigen Verbesserungen in Bezug auf Geschwindigkeit und Portabilität. Diese Ergebnisse liefern eine Grundlage für die Untersuchung, wie weit wir in den letzten zehn Jahren der Arbeit am Parsing von Abhängigkeiten neuronaler Netzwerke gekommen sind.', 'fa': 'این کاغذ تحویل دانشگاه ژنوا به کارهای زیادی از متن Raw به بستگی جهانی (به عنوان وارد CLCL (ژنوا) مشترک شده است. سیستم تحلیل فرستادن ما نوه\u200cی اولین وابستگی شبکه عصبی بر اساس تغییرات است که وارد دانشگاه ژنوا در قطار بستگی زیادی زبان CoNLL ۲۰۰۷ بود، با برخی تغییرات به سرعت و قابلیت حمل. این نتیجه\u200cها برای تحقیقات چقدر در ده سال گذشته از کار روی بررسی بستگی شبکه عصبی آمده\u200cایم، یک خط بنیادی برای تحقیق می\u200cکنند.', 'sw': 'Gazeti hili linaelezea ujumbe wa Chuo Kikuu cha Geneva kwa ajili ya CoNLL 2017 ulisambazwa kazi ya Bunge la Lugha kutoka Maandishi ya Raw hadi Uingereza (yaliorodheshwa kama kituo cha CLCL (Geneva). Mfumo wetu uliotolewa na bunge ni mtoto wa mitandao ya kwanza ya kutegemea matumizi ya neura ya mpito, ambao ulikuwa ni kuingia Chuo Kikuu cha Geneva katika CoNLL 2007, kwa ajili ya kuchunga matumaini ya lugha nyingine, na baadhi ya maendeleo ya haraka na uwezekano. Matokeo haya yanatoa msingi wa uchunguzi wa kiasi gani tumefika katika miaka kumi iliyopita kwa ajili ya kutegemea wimbo wa kijamii.', 'af': "Hierdie papier beskryf die Universiteit van Geneva se onderskrywing aan die CoNLL 2017 deel taak Veelvuldige onderskrywing van Roë Teks na Universele Afhanklikhede (gelys as die CLCL (Geneva) inskrywing). Ons ingestuurde verwerking stelsel is die oubaba van die eerste transisie-gebaseerde neuralnetwerk afhanklikheidspanseerder, wat was die Universiteit van Geneva se inskrywing in die CoNLL 2007 veelvuldige afhanklikheid verwerking van gedeelde taak, met sommige verbeteringe tot spoed en portabiliteit. Hierdie resultate verskaf 'n basislien vir ondersoek hoe ver ons in die verlede tien jaar werk het op neuralnetwerk afhanklikheid verwerking.", 'tr': 'Bu kagyz Ženewiň Uniwersitetiniň CoNLL 2017-nji ýylda esaslaşdyrylmagyny Roz Metinden Halkara Baýramlyklara (CLCL (Ženewiň) girişi ýazylýar. Biziň gönderilýän çözümleme sistemamyz ilkinji gezek taýýarlykly netral şebek baglanyşygynyň torüs üdir. Bu Jeneviň Uniwersiteti CoNLL 2007-nji ýylyň multi dil baglanyşygynyň paylaşdyrylygyny aýdyrylýan işi, häzirlenme we taýýarlyklygyny bejermek üçin Bu netijeler näçe wagt geçen on ýylda näçe işimizi näçe bolandygyny barlamak üçin esasy çyzgylygyny saýlaýarlar.', 'ko': '본고는 제네바대학이 CoNLL 2017 공유 임무에 제출한 파일을 기술하는데 원시 텍스트부터 통용 의존항까지의 다중 언어 해석(CLCL(제네바) 항목에 열거)을 포함한다.우리가 제출한 해석 시스템은 처음으로 전환된 신경 네트워크 의존성 해석기를 기반으로 한 손자이다. 이 해석기는 제네바대학의 2007년 CoNLL 다중 언어 의존성 해석 공유 임무의 일부로 속도와 이식성이 개선되었다.이러한 결과는 우리가 지난 10년 동안 신경 네트워크 의존성 분석에서 얻은 진전에 기반을 마련해 주었다.', 'am': 'ይህ ገጽ ከረw ጽሑፍ ወደ ዩንቨርስቲ (CLCL (Geneva) ጥያቄ የተለየ የኢንተርኔት አካባቢ) የኢንቨርስቲ ዩንቨርስቲ የኮንஎல_2017የክፍል ጉዳይ የብዙ ቋንቋ ፓርቲ ይናገራል፡፡ የደረሰን የፓርቲ ስርዓት የፊተኛውን የነዌብ መረብ ተሟጋቾችን የዘር ልጅ ነው፤ ይህም በኮንLL 2007 የዩንቨርስቲ የዩንቨርስቲ የቋንቋዊ ደጋፊነት የፓርቲ ስርዓት፣ ለፍጥነት እና የግማሽ ክፍተት እና አካባቢነት ነው፡፡ እነዚህ ፍሬዎች ባለፉት አሥር ዓመታት የኔውራዊ መረብ የታመነ ፓርቲ ላይ እንዴት እንደደረግንበት ሥራ ለመመርመር የመጀመሪያው ደረጃዎች ናቸው፡፡', 'sq': 'Ky dokument përshkruan paraqitjen e Universitetit të Gjenevës në detyrën e përbashkët të CoNLL 2017, analizimin shumëgjuhës nga teksti i papërdorur në varësitë universale (të listuar si hyrja në CLCL (Gjenevë). Sistemi ynë i paraqitur është nipi i analizuesit të parë të varës is ë s ë rrjetit nervor të bazuar në tranzicion, i cili ishte hyrja e Universitetit të Gjenevës në varës in ë shumëgjuhëse të CoNLL 2007 duke analizuar detyrën e përbashkët, me disa përmirësime në shpejtësinë dhe portabilitetin. Këto rezultate ofrojnë një bazë për hetimin se sa larg kemi arritur në dhjetë vitet e fundit të punës mbi analizimin e varësisë së rrjetit nervor.', 'az': "Bu kağıt Ženeva Universitetinin CoNLL 2017-ci ilə birləşdirilməsi ilə birləşdirilmiş çoxlu dil Parsing məktubundan Universal Dependenciyə (CLCL (Geneva) girişi kimi daxil edir. Bizim göndərilmiş analiz sistemimiz ilk keçişkil nöral ağ bağlılığı parçacıs ının torunudur. Bu, Geneva Universitetinin CoNLL 2007'də çoxlu dil bağlılılığı paylaşdığı işləri analiz edir, tezliklə və portabiliyyətinə bir neçə düzəltmələr ilə. Bu sonuçlar nöral şəbəkə bağımlılığı ayırmaq haqqında son on il işimizdə nə qədər uzaqlaşdığımızı soruşmaq üçün əsas səhifələri təmin edir.", 'bs': 'Ovaj papir opisuje podnošenje Univerziteta Ženeve u CoNLL 2017. zajedničkom zadatku Multilingual Parsing od Raw Text na univerzalne zavisnosti (navedeno kao ulaz CLCL (Ženeva). Naš podnosni analizacijski sistem je unuk prvog razmatrača zavisnosti neuralne mreže, koji je bio ulaz Univerziteta Ženeve u multijezičku zavisnost za analizu zajedničkog zadatka CoNLL 2007, s nekim poboljšanjem brzine i prenošljivosti. Ovi rezultati pružaju osnovnu liniju za istragu koliko smo dosli u poslednjih deset godina posla na analizu zavisnosti neurone mreže.', 'ca': "Aquest article descriu la presentació de la Universitat de Ginebra a la tasca compartida CoNLL 2017 Parsing Multilingual from Raw Text to Universal Dependencies (listed as the CLCL (Geneva)). El nostre sistema d'analització submetit és el nét del primer analitzador de la dependència de la xarxa neuronal basat en la transició, que va ser l'entrada de la Universitat de Ginebra a la CoNLL 2007 de la dependencia multilingüe analitzant tasca compartida, amb algunes millores en velocitat i portabilitat. Aquests resultats proporcionen una base per investigar fins a quin punt hem arribat en els darrers 10 anys de treball en l'analització de la dependència de la xarxa neuronal.", 'cs': 'Tento článek popisuje podání univerzity Ženevské na sdílený úkol CoNLL 2017 Multilingual Parsing from Raw Text to Universal Dependencies (uvedený jako CLCL (Ženeva). Náš předložený parsovací systém je vnukem prvního parseru závislosti neuronové sítě založeného na přechodu, který byl vstupem Ženevské univerzity do vícejazyčného parsování závislostí CoNLL 2007, s některými zlepšeními rychlosti a přenositelnosti. Tyto výsledky poskytují základní základ pro zkoumání toho, jak daleko jsme zašli v posledních deseti letech práce na analýze závislosti na neuronových sítích.', 'hy': 'Այս հոդվածը նկարագրում է Ջենեվայի համալսարանի ներկայացումը 2017 թվականի ԿոՆԼ-ի հանրային հանձնարարության մեջ, որը բազմալեզու վերլուծություն է կատարվում ոչ թմրա տեքստից մինչև համաշխարհային կախվածություններ: Մեր ներկայացված վերլուծության համակարգը վերաբերվում է վերաբերյալ հիմնված առաջին նյարդային ցանցի կախվածության վերլուծության փոքրիկ թոռներին, որը Ջենեվայի համալսարանի 2007 թվականի համալսարանի բազլեզու կախվածության մեջ էր վերլուծում ընդհանուր խնդիրը, որոշ բարելավումներով արա Այս արդյունքները հիմք են տալիս ուսումնասիրելու համար, թե ինչքան հեռու ենք մենք հասել նյարդային ցանցի կախվածության վերլուծության վերջին տասը տարիների ընթացքում:', 'fi': 'Tässä artikkelissa kuvataan Geneven yliopiston osallistumista CoNLL 2017:n yhteiseen tehtävään Multilingual Parsing from Raw Text to Universal Dependences (lueteltu CLCL (Geneve) -merkinnänä). Toimitettu jäsennysjärjestelmämme on ensimmäisen siirtymäpohjaisen neuroverkkoriippuvuuden jäsentäjän lapsenlapsi, joka oli Geneven yliopiston tulo CoNLL 2007 monikieliseen riippuvuuden jäsentämiseen jaettuun tehtävään. Nämä tulokset tarjoavat perustan selvittääksemme, kuinka pitkälle olemme päässeet viimeisten kymmenen vuoden aikana neuroverkkoriippuvuuden analysoinnissa.', 'bn': 'এই পত্রিকাটি জেনেভা বিশ্ববিদ্যালয়ের প্রতি কএনএল ২০১৭ সালে প্রকাশিত কাজ শেয়ার করা হয়েছে রো টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর (সিএলসিএল ( আমাদের জবাব দিয়েছে পার্গিং সিস্টেম হচ্ছে প্রথম অতিক্রমের ভিত্তিক নিউরেল নেটওয়ার্ক নির্ভরশীল বিশ্ববিদ্যালয়ের প্রবেশ, যা কএনএল ২০০৭ সালের বিশ্ববিদ্যা এই ফলাফল একটি বেসেলাইন দেয়া হয়েছে যাতে আমরা বিগত দশ বছর ধরে নিউরেল নেটওয়ার্কের নির্ভরশীল পার্জিং নিয়ে কাজ করেছি।', 'et': 'Käesolevas artiklis kirjeldatakse Genfi Ülikooli esitamist CoNLL 2017. aasta jagatud ülesandele mitmekeelne parsing toortekstist universaalsetele sõltuvustele (loetletud kui CLCL (Geneva) kanne). Meie esitatud parsimissüsteem on esimese üleminekupõhise närvivõrgu sõltuvuse parseri lapselaps, mis oli Genfi Ülikooli osalus CoNLL 2007 mitmekeelse sõltuvuse parsimise jagatud ülesandes, millega kaasati mõningaid parandusi kiiruses ja kaasaskantavuses. Need tulemused annavad aluse uurida, kui kaugele oleme jõudnud viimase kümne aasta jooksul närvivõrgu sõltuvuse parsimisel.', 'jv': 'Perintah sing paling apik nyong nggawe Universite of Genève nang CoNLL, ndheke ndheke kapan kanggo kelas barang Multilenguang Awak dhéwé ngewehi urip nggawe sistem sing nganggo barêng-barêng, iso nggawe sistem sing dibutuhke tarjamahan sing perusahaan anyar nggawe sistem sing dibutuhke tarjamahan kanggo mbaar nggawe netwisik, sing wis dumateng gawe Universite de Genève nggawe CoNLL 2007 sampek urip bantên liyane karo akeh perusahaan ngen Rejaling iki bakal ngewehke kelas perusahaan kanggo masalah segala punika sing tukang mrih tau ing nguasai kapan tanggal alam wigatining ketahan maneh.', 'he': "העיתון הזה מתאר את ההעברה של אוניברסיטת ג'נבה למשימה המשותפת CoNLL 2017 בדיקת רבות שפות מהטקסט ראש לתמכויות יוניברסליות (רשומה כהכניסה של CLCL (ג'נבה)). Our submitted parsing system is the grandchild of the first transition-based neural network dependency parser, which was the University of Geneva's entry in the CoNLL 2007 multilingual dependency parsing shared task, with some improvements to speed and portability.  These results provide a baseline for investigating how far we have come in the past ten years of work on neural network dependency parsing.", 'sk': 'Ta prispevek opisuje predložitev Univerze v Ženevi na skupno nalogo CoNLL 2017 Večjezično razčlenjevanje iz surovega besedila v univerzalne odvisnosti (navedeno kot vnos CLCL (Ženeva). Naš predloženi sistem za razčlenjanje je vnuk prvega prehodnega razčlenjevalnika odvisnosti od nevronskih omrežij, ki je bil vpis Univerze v Ženevi v CoNLL 2007 večjezični razčlenjevalnik odvisnosti skupne naloge, z nekaterimi izboljšavami hitrosti in prenosljivosti. Ti rezultati so osnova za raziskavo, kako daleč smo prišli v zadnjih desetih letih dela na področju analiziranja odvisnosti od nevronskih omrežij.', 'ha': "Wannan karatun describes the University of Java's inputs to the CoNLL 2017 share job Parse from Raw Text to Universal Deputs (listed as the CLCL (General) entry). Ubuntu da aka bai wa fassarar parse is the child of the first transitional net neural deposition, which was the University of jenva's entry in the CoNLL 2007, deposited multilingular parse business share, with some improvements to Faso and Portable. Haƙĩƙa, waɗannan matsalar yana da wani basuɓani ga yin tambaya inda duk shekara 10 na shida suka zo a kan parse ɗin neural.", 'bo': 'CoNLL 2017 ཡི་གེ་ཤོག་བྱང་འདིས་Ženevav་ གི་ཆ་འཕྲིན་ལ་འཇུག ང་ཚོའི་མིང་ཚོའི་དབྱེ་སྟངས་འཛིན་བྱས་པའི་དྲ་རྒྱ་སྐྱེས་ཀྱི་རྨོ་བ་ཞིག་རེད། དབྱངས་འབྲེལ་འདིས་ང་ཚོ་རང་ཉིད་ཀྱི་དུས་རབས་པའི་ལོ་ངོ་བཅུ་ཐམ་གྱི་རྩིས་འབྲེལ་མཐུད་དྲ་རྟེན་འབྲེལ་བཤད་ཀྱི་དབྱེ་ཞིབ་བ'}
{'en': 'A Fast and Lightweight System for Multilingual Dependency Parsing', 'ar': 'نظام سريع وخفيف الوزن للتحليل التبعي متعدد اللغات', 'fr': "Un système rapide et léger pour l'analyse des dépendances multilingues", 'pt': 'Um sistema rápido e leve para análise de dependência multilíngue', 'es': 'Un sistema rápido y ligero para el análisis de dependencias multilingües', 'ja': '多言語依存関係解析のための高速で軽量なシステム', 'zh': '多言赖解析速轻量级系统', 'hi': 'बहुभाषी निर्भरता पार्सिंग के लिए एक फास्ट और लाइटवेट सिस्टम', 'ru': 'Быстрая и легкая система для многоязычного анализа зависимостей', 'ga': 'Córas Mear agus Éadrom le haghaidh Parsála Spleáchais Ilteangacha', 'el': 'Ένα γρήγορο και ελαφρύ σύστημα ανάλυσης πολυγλωσσικής εξάρτησης', 'hu': 'Gyors és könnyű rendszer a többnyelvű függőség értelmezéséhez', 'ka': 'Name', 'kk': 'Көптілік тәуелдік талдау үшін тез жүйесі', 'lt': 'Greita ir lengva daugiakalbio priklausomybės analizavimo sistema', 'it': "Un sistema veloce e leggero per l'analisi multilingue della dipendenza", 'mk': 'Name', 'mt': 'Sistema Rapida u ħafifa għall-Analiżi ta’ Dipendenza Multilingwi', 'ms': 'Name', 'ml': 'Multilingual dependency Parsing-നുള്ള വേഗത്തിലും ലളിതമായ വ്യവസ്ഥ സിസ്റ്റംName', 'mn': 'Олон хэл хамааралын хувьд хурдан, амархан жингийн систем', 'no': 'Name', 'pl': 'Szybki i lekki system do parowania zależności wielojęzycznej', 'ro': 'Un sistem rapid și ușor pentru analizarea dependenței multilingve', 'sr': 'Brzi i lagani sistem za razmatranje višejezičkih zavisnosti', 'so': 'Xiriiridda qiimaha luuqadaha badan ee degdeg iyo fudud', 'si': 'Name', 'sv': 'Ett snabbt och lätt system för flerspråkig beroendetolkning', 'ta': 'பல மொழி சார்ந்த சார்ந்த பாசிங்குக்கான வேகம் மற்றும் எளிதான அளவு அமைப்பு', 'ur': 'Name', 'uz': 'Name', 'vi': 'Một Hệ thống Nhanh và Nhẹ cho độ phụ thuộc đa ngôn ngữ', 'bg': 'Бърза и лека система за многоезично анализиране на зависимостта', 'da': 'Et hurtigt og let system til flersproget afhængighedsanalyse', 'nl': 'Een snel en lichtgewicht systeem voor meertalige afhankelijkheidsparsing', 'de': 'Ein schnelles und leichtes System für mehrsprachiges Dependency Parsing', 'hr': 'Brzi i lagani sustav za razmatranje višejezičkih zavisnosti', 'id': 'Sistem cepat dan ringan untuk Penganalisan Dependensi Berbahasa', 'fa': 'Name', 'sw': 'Mfumo wa haraka na nyepesi kwa ajili ya Kuchapisha Uhuru wa lugha nyingi', 'tr': 'Çoklu diller baglançylyk Parlamak üçin Hızlı we Haýyklyk Sistemi', 'af': 'Name', 'am': 'A Fast and Lightweight System for Multilingual Dependency Parsing', 'hy': 'Շատլեզու կախվածության վերլուծության արագ և թեթև համակարգ', 'ko': '빠른 경량급 다중 언어 의존 해석 시스템', 'sq': 'Një sistem i shpejtë dhe i lehtë për analizimin e varësive shumëgjuhësore', 'az': 'Çoxlu dil bağlılıq analizi üçün hızlı və hafif sistem', 'bn': 'বহুভাষী নির্ভরিত পার্সিং এর জন্য দ্রুত এবং লাইটওয়েট সিস্টেম', 'ca': "Un sistema ràpid i llixer d'analització de dependencies multilingües", 'cs': 'Rychlý a lehký systém pro analýzu vícejazyčné závislosti', 'fi': 'Nopea ja kevyt järjestelmä monikieliseen riippuvuuden analysointiin', 'bs': 'Brzi i lagani sistem za razmatranje višejezičkih zavisnosti', 'et': 'Kiire ja kerge süsteem mitmekeelse sõltuvuse parsimiseks', 'jv': 'Sistem Latar lan ngawasi luwih kanggo soko akeh bantuan sabanjur', 'he': 'מערכת מהירה ומשקלת קלה למחקר תלויות רבות', 'sk': 'Hiter in lahek sistem za večjezično razvrščanje odvisnosti', 'ha': 'KCharselect unicode block name', 'bo': 'སྐད་རིགས་ཀྱི་རྟེན་འབྲེལ་བའི་དབྱེ་ཞིབ་ལ་མགྱོག་མྱུར་བའི་མ་ལག་ཅིག་'}
{'en': 'We present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier. We trained our transition-based projective parser in UD version 2.0 datasets without any additional data. The parser is fast, lightweight and effective on big treebanks. In the CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33 %.', 'ar': 'نقدم محلل تبعية متعدد اللغات مع مستخرج ميزة LSTM ثنائي الاتجاه (BiLSTM) ومصنف متعدد الطبقات (MLP). قمنا بتدريب المحلل اللغوي الإسقاطي القائم على النقل في مجموعات بيانات UD الإصدار 2.0 دون أي بيانات إضافية. المحلل اللغوي سريع وخفيف الوزن وفعال على ضفاف الأشجار الكبيرة. في المهمة المشتركة لـ CoNLL 2017: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية ، تُظهر النتائج الرسمية أن درجة LAS F1 ذات المتوسط الكلي لنظام Mengest هي 61.33٪.', 'fr': "Nous présentons un analyseur de dépendance multilingue avec un extracteur de caractéristiques LSTM bidirectionnel (BilsTM) et un classificateur de perceptron multicouche (MLP). Nous avons formé notre analyseur projectif basé sur la transition aux ensembles de données UD version 2.0 sans aucune donnée supplémentaire. L'analyseur est rapide, léger et efficace sur les grandes banques d'arbres. Dans la tâche partagée ConLL 2017\xa0: Multilingual Parsing from Raw Text to Universal Dependencies, les résultats officiels montrent que le score LAS F1 macro-moyen de notre système Mengest est de 61,33\xa0%.", 'es': 'Presentamos un analizador de dependencias multilingüe con un extractor de funciones LSTM bidireccional (BilsTM) y un clasificador perceptrón multicapa (MLP). Entrenamos a nuestro analizador proyectivo basado en transiciones en conjuntos de datos UD versión 2.0 sin ningún dato adicional. El analizador es rápido, ligero y eficaz en bancos de árboles grandes. En CoNll 2017 Shared Task: Multilingüe Parsing from Raw Text to Universal Dependencies, los resultados oficiales muestran que la puntuación LAS F1 macropromediada de nuestro sistema Mengest es del 61,33%.', 'pt': 'Apresentamos um analisador de dependência multilíngue com um extrator de características bidirecional-LSTM (BiLSTM) e um classificador multi-layer perceptron (MLP). Treinamos nosso analisador projetivo baseado em transição em conjuntos de dados UD versão 2.0 sem nenhum dado adicional. O analisador é rápido, leve e eficaz em grandes bancos de árvores. Na tarefa compartilhada CoNLL 2017: análise multilíngue de texto bruto para dependências universais, os resultados oficiais mostram que a pontuação LAS F1 média macro do nosso sistema Mengest é de 61,33%.', 'ja': '双方向LSTM （ BiLSTM ）機能抽出器と多層パーセプトロン（ MLP ）分類器を備えた多言語依存構文解析器を提示します。トランジションベースの投影解析器は、追加データなしでUDバージョン2.0データセットでトレーニングしました。パーサーは高速、軽量で、大きなツリーバンクに効果的です。CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependenciesにおいて、公式結果は、当社システムMengestのマクロ平均LAS F 1スコアが61.33%であることを示しています。', 'ru': 'Предложен многоязычный парсер зависимостей с двунаправленным извлекателем признаков LSTM (BiLSTM) и многослойным классификатором перцептронов (MLP). Мы обучили наш проективный парсер на основе перехода в наборах данных UD версии 2.0 без каких-либо дополнительных данных. Анализатор быстрый, легкий и эффективный на больших берегах деревьев. В CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies официальные результаты показывают, что макроусредненный балл LAS F1 нашей системы Mengest составляет 61,33%.', 'zh': '多言赖解析器,含双向 LSTM (BiLSTM) 特征提取器感知器 (MLP) 类器。 于 UD 版本 2.0 数集练投影式解析器,无他数也。 解析器疾速,轻量级有效于大树库。 在CoNLL 2017共享:自始文本至通用多语言解析中,官方结果显示,系统Mengest者宏观均LAS F1分为61.33%。', 'hi': 'हम एक द्विदिश-LSTM (BiLSTM) सुविधा चिमटा और एक बहु-परत परसेप्ट्रॉन (MLP) क्लासिफायर के साथ एक बहुभाषी निर्भरता पार्सर प्रस्तुत करते हैं। हमने बिना किसी अतिरिक्त डेटा के यूडी संस्करण 2.0 डेटासेट में अपने संक्रमण-आधारित प्रोजेक्टिव पार्सर को प्रशिक्षित किया। पार्सर तेजी से, हल्के और बड़े treebanks पर प्रभावी है. CoNLL 2017 साझा कार्य में: रॉ टेक्स्ट से यूनिवर्सल निर्भरताओं के लिए बहुभाषी पार्सिंग, आधिकारिक परिणाम बताते हैं कि हमारे सिस्टम मेंजेस्ट का मैक्रो-औसत LAS F1 स्कोर 61.33% है।', 'ga': 'Cuirimid parsálaí spleáchais ilteangach i láthair a bhfuil eastóscadh gné déthreorach-LSTM (BiLSTM) aige agus aicmitheoir ilchiseal perceptron (MLP). Chuireamar oiliúint ar ár gcuid parsálaí teilgin atá bunaithe ar an trasdul i dtacar sonraí leagan UD 2.0 gan aon sonraí breise. Tá an parsálaí tapa, éadrom agus éifeachtach ar bhruacha crann mór. I dTasc Comhroinnte CoNLL 2017: Parsáil Ilteangach ó Théacs Raw go dtí Spleáchais Uilíocha, léiríonn na torthaí oifigiúla gurb é 61.33% an scór macra-mheánmhéide LAS F1 dár gcóras Mengest.', 'ka': 'ჩვენ მრავალენგური დასამხრებელობის პანსერტირების გამოყენება ორიდერექციონალ-LSTM (BiLSTM) ფუნქციების ექსტრაკტორი და მრავალენგური პერსპტრონი (MLP) კლასიფიკაცია ჩვენ გადავიტანეთ ჩვენი პროექტიური პროექტიური პროექტიური პროექტიური პროექტიური UD ვერსიაში 2.0 მონაცემების კონფიგურაციაში. პანუზერი ძალიან, სიმაღლე და ეფექტიურია დიდი საბეჭდოებში. CoNLL 2017-ის გაყოფილი დავალებში: მრავალენგური პარამეტრებისგან მნიშვნელოვანი ტექსტიდან უნიშვნელოვანი განსაზღვრებისგან, официальные შედეგი გამოჩვენება, რომ ჩვენი სისტემის Mengest-ის მაკრო განსაზღვრებული LAS F1 წერ', 'el': 'Παρουσιάζουμε έναν πολύγλωσσο αναλυτή εξάρτησης με έναν δικατεύθυνση-εξαγωγέα χαρακτηριστικών και έναν πολυστρωματικό ταξινομητή perceptron (MLP). Εκπαιδεύσαμε τον προβολικό αναλυτή που βασίζεται στη μετάβαση σε σύνολα δεδομένων έκδοσης 2.0 χωρίς πρόσθετα δεδομένα. Ο αναλυτής είναι γρήγορος, ελαφρύς και αποτελεσματικός σε μεγάλα δέντρα. Στην Κοινή Εργασία Πολυγλωσσική Ανάλυση από Ακατέργαστο Κείμενο σε Οικουμενικές Εξαρτήσεις, τα επίσημα αποτελέσματα δείχνουν ότι η μακρομέση βαθμολογία του συστήματός μας είναι 61.33%.', 'hu': 'Bemutatunk egy többnyelvű függőség elemzőt kétirányú LSTM (BiLSTM) funkciókivonóval és egy többrétegű perceptron (MLP) osztályozóval. Átmeneti alapú projektív elemzőnket UD 2.0 verziójú adatkészletekre képeztük további adatok nélkül. Az elemző gyors, könnyű és hatékony a nagy fapadokon. A CoNLL 2017 Megosztott feladat: Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig, a hivatalos eredmények azt mutatják, hogy rendszerünk Mengest makróátlagos LAS F1 pontszáma 61,33%.', 'it': 'Presentiamo un parser di dipendenza multilingue con un estrattore di funzionalità bidirezionale-LSTM (BiLSTM) e un classificatore di percettron multistrato (MLP). Abbiamo addestrato il nostro parser proiettivo basato sulla transizione in set di dati UD versione 2.0 senza alcun dato aggiuntivo. Il parser è veloce, leggero ed efficace sulle grandi sponde degli alberi. Nel CoNLL 2017 Shared Task: Analisi multilingue dal testo grezzo alle dipendenze universali, i risultati ufficiali mostrano che il punteggio LAS F1 macro-medio del nostro sistema Mengest è del 61,33%.', 'kk': 'Біз бірнеше тілік тәуелдік талдаушысын бірнеше тілік- LSTM (BiLSTM) мүмкіндіктерін тарқатушы мен көптеген қабаттық түсініктері (MLP) классификациясы арқылы көрсетедік. Біз UD 2. 0 нұсқасындағы проективті талдаушыларымызды қосымша деректер қорларымыз жоқ. Пансерлер үлкен жабыс панелінде жылдам, жеткілікті және эффективні. CoNLL 2017 ортақтастырылған тапсырмасы: Қара мәтіннен көп тілді талдау әлемдік тәуелдіктерге дейін, официалдық нәтижелер жүйеңіздің Менгестігінің макро орташа LAS F1 нәтижесі 61,33% дегенді көрсетеді.', 'lt': 'Mes pristatome daugiakalbį priklausomybės analizatorių su dvikryptiniu LSTM (BiLSTM) savybių ekstraktoriumi ir daugiakalbiu perceptrono (MLP) klasifikatoriumi. Mes apmokėme savo pereinamojo laikotarpio projektinį analizatorių UD 2.0 versijos duomenų rinkiniuose be jokių papildomų duomenų. Analizatorius yra greitas, lengvas ir veiksmingas ant didelių medžių. CoNLL 2017 m. bendroje užduotyje: daugiakalbis analizavimas iš žaliavinio teksto į universaliąsias priklausomybes oficialūs rezultatai rodo, kad mūsų sistemos „Mengest“ makroekonominis vidurkis LAS F1 yra 61,33 %.', 'mk': 'Презентираме мултијазичен анализатор на зависност со двоправен екстрактор на функции на LSTM (BiLSTM) и класификатор на повеќето слоеви на перцептрон (MLP). Го трениравме нашиот проективен анализатор базиран на транзиција во UD верзија 2.0 датотеки без дополнителни податоци. Анализаторот е брз, лесен и ефикасен на големите дрвја. Во Соделената задача на CoNLL 2017: Мултијазично анализирање од суров текст до универзални зависности, официјалните резултати покажуваат дека макро-просечната оценка на LAS F1 на нашиот систем Менгест е 61,33 отсто.', 'ml': 'ഒരു ബിഡിറ്റര്\u200dഷന്\u200d LSTM (ബില്\u200dഎസ്റ്റമിന്റെ) പ്രത്യേക വിഭാഗത്തിന്റെയും ഒരു multilingual- ആശ്രയിക്കുന്നതിന്\u200dറെയും കൂട്ടത്തില്\u200d ഞങ്ങള്\u200d ഒരു പ്രദര്\u200dശി We trained our transition-based projective parser in UD version 2.0 datasets without any additional data.  വേഗം, വെളുത്ത ഭാരം, വലിയ ട്രീബാങ്കുകളില്\u200d പ്രവർത്തികമാണ്. കോണ്\u200dഎല്\u200d 2017-ല്\u200d പങ്കെടുത്ത പണിയില്\u200d: റോ ടെക്സ്റ്റില്\u200d നിന്നും യൂണിവര്\u200dക്കല്\u200d ഡിപ്പെന്\u200dസികളിലേക്കും പല ഭാഷക്കുകള്\u200d പാര്\u200dസിങ് കാണിക്കുന്നു. ഓഫിക്കല്\u200d ഫലങ്', 'ms': 'Kami perkenalkan penghurai dependensi berbilang bahasa dengan pengekstrak ciri-ciri LSTM-bidireksi (BiLSTM) dan pengklasifikasi perseptron berbilang lapisan (MLP). Kami melatih penghurai projektif berasaskan transisi dalam set data UD versi 2.0 tanpa data tambahan. Penyemak ini cepat, ringan dan berkesan pada bank pokok besar. In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33%.', 'mn': 'Бид олон хэлний хамааралтай хамааралтай хуваалцагчийг хоёр давхар-LSTM (BiLSTM) шинж тэмдэглэгч болон олон давхар ойлголтын (MLP) хуваалцагчийг харуулж байна. Бид UD хувилбар 2.0 өгөгдлийн санг нэмэлт өгөгдлийн байдлаар шилжүүлэх төслийн ажиллаач сургалтыг суралцаж өгсөн. Тайлагч маш хурдан, хөнгөн, том модон дээр үр дүнтэй. CoNLL 2017 оны хуваалтын ажил: Raw Text-ээс Universal Dependencies руу олон хэлний шинжилгээ, үндсэн үр дүнд нь манай системийн Mengest-ын макро дундаж LAS F1 тоо 61.33% гэдгийг харуулж байна.', 'mt': 'Aħna nippreżentaw analizzatur tad-dipendenza multilingwi b’estrattur tal-karatteristiċi bidirezzjonali-LSTM (BiLSTM) u klassifikatur tal-perċepton b’diversi saffi (MLP). Taħriġna l-analizzatur proġettiv tagħna bbażat fuq it-tranżizzjoni f’settijiet tad-dejta UD verżjoni 2.0 mingħajr ebda dejta addizzjonali. Il-parser huwa mgħaġġel, ħafif u effettiv fuq il-banek tas-siġar il-kbar. Fil-Kompitu Konġunt CoNLL 2017: Analiżi Multilingwi mit-Test Prim għad-Dipendenzi Universali, ir-riżultati uffiċjali juru li l-punteġġ makro-medju tal-LAS F1 tas-sistema tagħna Mengest huwa ta’ 61.33%.', 'no': 'Vi presenterer ein fleirspråk avhengighetsanalyser med ein bidirectional-LSTM (BiLSTM) funksjonsekstraktor og ein multi layer perceptron (MLP) klassifiserer. Vi trenga overgangsbasert prosjektiv tolkar i UD versjon 2. 0- datasett utan nokon ekstra data. Tolkaren er rask, lett og effektiv på store trekantar. I CoNLL 2017 delt oppgåve: fleirspråk tolking frå råtekst til universelle avhengighet viser det offisielle resultatet at makro-gjennomsnittet LAS F1-poeng av systemet vår Mengest er 61,33%.', 'pl': 'Przedstawiamy wielojęzyczny parser zależności z dwukierunkowym ekstraktorem cech LSTM (BiLSTM) oraz wielowarstwowym klasyfikatorem perceptronu (MLP). Szkoliliśmy nasz parser projektywny oparty na przejściu w wersji UD 2.0 bez żadnych dodatkowych danych. Parser jest szybki, lekki i skuteczny na dużych drzewach. W CoNLL 2017 Shared Task: Wielojęzyczna analiza tekstu surowego do uniwersalnych zależności oficjalne wyniki pokazują, że makro-średni wynik LAS F1 naszego systemu Mengest wynosi 61,33%.', 'sr': 'Predstavljamo višejezički analizator ovisnosti sa dodatnim ekstraktorom funkcije LSTM (BiLSTM) i klasifikatorom višeslojnih perceptron a (MLP). Obučavali smo naš projektiv analizator na temelju prijenosa u UD verziji 2.0 podataka bez dodatnih podataka. Analizator je brz, lagan i efikasan na velikim treebancima. U CoNLL 2017. zajednièkom zadatku: Multilingual Parsing from Raw Text to Universal Dependencies, zvanični rezultati pokazuju da je makro-averaged LAS F1 score našeg sistema Mengest 61,33%.', 'ro': 'Vă prezentăm un parser de dependență multilingv cu un extractor de caracteristici bidirecțional-LSTM (BiLSTM) și un clasificator perceptron multistrat (MLP). Am instruit parserul nostru proiectiv bazat pe tranziție în seturi de date UD versiunea 2.0 fără date suplimentare. Pătrunzătorul este rapid, ușor și eficient pe brațele mari. În CoNLL 2017 Shared Task: Parsing multilingv de la text brut la dependențe universale, rezultatele oficiale arată că scorul LAS F1 macro-mediu al sistemului nostru Mengest este de 61,33%.', 'si': 'අපි ගොඩක් භාෂාවක් විශේෂතාවක් විශේෂකයෙක් පෙන්වන්නේ බිදිරික්ෂණ-LSTM (BiLSTM) විශේෂකයක් නිර්මාණකයෙක් සහ ගොඩක් ල අපි UD සංවිධානය 2.0 දත්ත සෙට්ටුවෙන් අපේ ප්\u200dරමාණය අධාරිත ප්\u200dරක්\u200dරියාත්මක විශේෂකය කළා. විශාලකය වේගයි, ලොකු බැල්ලි වලට ප්\u200dරශ්ණයි. CoNLL 2017 සමාගත වැඩේ වැඩේ තියෙන්නේ: රාව් පාළුවෙන් පාළුවෙන් විශේෂ පාළුවෙන් විශේෂ විශේෂ විශේෂ විශේෂ වෙනුවෙන්, අධාරික ප්\u200d', 'so': 'Waxaan keenaynaa baaritaanka ku saabsan luuqadaha kala duduwan oo leh wadajir-LSTM (BiLSTM) iyo qayb-qayb-faro badan (MLP). We trained our transition-based projective parser in UD version 2.0 datasets without any additional data.  Parsarku waa dhaqso, miisaan fudud iyo waxqabad badan oo ku saabsan garoonka weyn. Shaqooyinka la sharciyey ee CoNLL 2017: Jardiiska luuqadaha badan ee Raw-Text-to Universal Dependences, resultariyada rasmiga ah waxay muuqataa in koox macro-average LAS F1 koox koox koox koox koox koowaad ee systemeena Mengest waa 61.33%.', 'sv': 'Vi presenterar en flerspråkig beroendetolkare med en tvåriktad LSTM-funktionsextraktor (BiLSTM) och en MLP-klassificerare med flera lager. Vi tränade vår övergångsbaserade projektiva parser i UD version 2.0 datauppsättningar utan ytterligare data. Parsern är snabb, lätt och effektiv på stora trädbackar. I CoNLL 2017 Shared Task: Flerspråkig tolkning från råtext till universella beroenden visar de officiella resultaten att den makrogränsade LAS F1-poängen för vårt system Mengest är 61,33%.', 'ta': 'நாம் ஒரு பல மொழி சார்பு பாதுகாப்பு பகுதியை காண்பிக்கிறோம் ஒரு பிடிவின் LSTM (பில்STM) குணங்கள் வெளியீட்டாளர் மற்றும் ஒரு பல அடுக்கு பார நாங்கள் UD பதிப்பு 2. 0 தரவு அமைப்புகளில் பயிற்சி செய்தோம். பரப்பு வேகமாக, எளிதான எடையும் பெரிய தோட்டங்களில் வெளியேறுதலும். கோன்எல் 2017 பகிர்ந்த பணியில்: Raw Text to Universal சார்புகளுக்கு பல மொழி பாசிங் காட்டுகிறது, official results show the macro- average LAS F1 score of our system Mengest is 61.33%.', 'ur': 'ہم ایک multilingual dependency parser کو ایک دودیرٹیکشنال-LSTM (BiLSTM) فائدہ اضافہ کرنے والا اور ایک multi layer perceptron (MLP) کلاسیر کے ساتھ پیش کرتے ہیں. ہم نے UD ورژن 2.0 ڈاٹ سٹ کے بغیر کسی اضافہ ڈیٹ کے اپنے تغییر پر بنیاد پروژیکٹ پارچر کو تربیت کی۔ پارچر تیز، ہلکا وزن اور بڑے ٹریبنک پر اثر دیتا ہے. CoNLL 2017 میں مشترک ٹاکس میں: رائ ٹکسٹ سے ملی زبان پارسینگ واحد سے Universal Dependencies تک، رسمی نتائج دکھاتے ہیں کہ ہمارے سیستم Mengest کی مکرو متوسط LAS F1 اسکور 61.33%.', 'uz': "Biz bir necha tilda ishlatuvchi parametrlarni bir necha tilda qo'l ishlatuvchi ajratuvchi va bir necha qatlam (MLP) darajasini ajratuvchi. Biz UD versiyasi 2.0 maʼlumotlar tarkibini qoʻshimcha maʼlumot yoʻq. Name 2017 KoNLL'da Sharob qilingan vazifani: Ray matn bilan umumiy davomida bir necha tillar parsing, rasmiy natijalar bu tizimning boshqaruvchimizning makro- 平均 LAS F1 scori 61.33%.", 'vi': 'Chúng tôi giới thiệu một phân tích phụ thuộc đa dạng với một dịch vụ có tính chất kích thích và một chuyên gia cấp đa lớp (MLP). Chúng tôi đã đào tạo ra bộ phân tích ánh sáng xuyên qua phiên bản UD 2.0 mà không có dữ liệu phụ. Vị cha vấn nhanh, nhẹ và hiệu quả trên những xâu bóng lớn. Trong Nhiệm vụ chia sẻ CONLL giá CON11: phát ngôn từ văn bản thô đến phụ thuộc chung, các kết quả chính thức cho thấy điểm số LAS F1 bị tổng trung hóa trong hệ thống Mạnh Đức là 61.33 Name', 'da': 'Vi præsenterer en flersproget afhængighedsfortolker med en bidirectional-LSTM (BiLSTM) feature extractor og en multi-lags perceptron (MLP) klassificering. Vi trænede vores overgangsbaserede projektive parser i UD version 2.0 datasæt uden yderligere data. Parseren er hurtig, let og effektiv på store trækanter. I CoNLL 2017 delt opgave: Flersproget tolkning fra rå tekst til universelle afhængigheder viser de officielle resultater, at den makro-gennemsnitlige LAS F1 score for vores system Mengest er 61,33%.', 'de': 'Wir präsentieren einen mehrsprachigen Abhängigkeitsparser mit einem bidirektionalen LSTM (BiLSTM) Feature Extractor und einem mehrschichtigen Perzeptron (MLP)-Klassifikator. Wir trainierten unseren transition-basierten projektiven Parser in UD Version 2.0 Datensätzen ohne zusätzliche Daten. Der Parser ist schnell, leicht und effektiv auf großen Baumbänken. In der CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies zeigen die offiziellen Ergebnisse, dass der makro-durchschnittliche LAS F1 Score unseres Systems Mengest 61.33%.', 'hr': 'Predstavljamo višejezički analizač ovisnosti sa dodatnim ekstraktorom funkcije LSTM (BiLSTM) i klasifikatorom višeslojnih perceptron a (MLP). Uvježbali smo naš projektivni analizač na temelju prijenosa u UD verziji 2.0 podataka bez dodatnih podataka. Analizator je brz, lagan i učinkovit na velikim područjima. U CoNLL 2017. zajedničkom zadatku: višejezičko analiziranje od sirovog teksta do univerzalnih ovisnosti, službeni rezultati pokazuju da je makroesrednji rezultat LAS F1 rezultata našeg sustava Mengest 61,33%.', 'id': 'Kami mempersembahkan parser dependensi berbilang bahasa dengan ekstraktor fitur bidireksi LSTM (BiLSTM) dan klasifikasi persepton multi-lapisan (MLP). Kami melatih proyektif parser berdasarkan transisi kami dalam set data UD versi 2.0 tanpa data tambahan. Parser itu cepat, ringan dan efektif pada tiang pohon besar. Dalam Tugas Berkongsi CoNLL 2017: Penganalisan berbagai bahasa dari Teks Raw ke Dependensi Universal, hasil resmi menunjukkan bahwa nilai makro-rata LAS F1 dari sistem kita Mengest adalah 61,33%.', 'ko': '우리는 양방향 LSTM(BilSTM) 특징 추출기와 다중 감지기(MLP) 분류기를 가진 다중 언어 의존 해상도를 제시했다.우리는 UD 2.0 버전의 데이터에서 변환을 기반으로 하는 투영 해상도를 집중적으로 훈련했는데, 어떠한 추가 데이터도 없었다.이 해석기는 속도가 빠르고 무게가 가벼워 대형 나무 창고에서 매우 효과적이다.CoNLL 2017 공유 작업: 원본 텍스트부터 일반 의존항까지의 다중 언어 해석에서 공식 결과에 따르면 우리 시스템Mengest의 거시적 평균 LAS F1 점수는 61.33% 였다.', 'bg': 'Представяме многоезичен анализатор на зависимости с двупосочен екстрактор на функции и многослоен възприетон класификатор. Обучихме нашия преходен проективен анализатор във версия 2.0 без допълнителни данни. Парсерът е бърз, лек и ефективен при големи дървесни дънки. В Споделена задача: Многоезично анализиране от суров текст до универсални зависимости официалните резултати показват, че макросредният резултат на системата е 61.33%.', 'nl': 'We presenteren een meertalige afhankelijkheidsparser met een bidirectionele LSTM (BiLSTM) feature extractor en een multi-layer perceptron (MLP) classificator. We hebben onze transitiegebaseerde projectieve parser getraind in UD versie 2.0 datasets zonder extra data. De parser is snel, lichtgewicht en effectief op grote boombanken. In de CoNLL 2017 Shared Task: Meertalige Parsing van ruwe tekst naar universele afhankelijkheden, tonen de officiële resultaten aan dat de macro-gemiddelde LAS F1 score van ons systeem Mengest 61.33%.', 'sw': 'Tunawasilisha mchambuzi wa kujitegemea lugha mbalimbali na mtangazaji wa lugha-LSTM (BiLSTM) na mtazamo wa ngazi nyingi (MLP). Tulimfundisha mradi wetu wa mpito katika toleo la UD 2.0 bila taarifa za ziada. Mchangiaji ni haraka, uzito na ufanisi kwenye viwanja vikubwa vya miti. In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33%.', 'tr': "Biz bir näçe dilli baglançylyk tansçysyny bidireksiyonal-LSTM (BiLSTM) hasaplançy hasaplançy we bir näçe gatlak tansçysyny (MLP) klasifikatçy bilen tansýarys. Biz geçiş sistemimizi UD 2.0 veri setirlerimizde hiç hili ekleme maglumaty ýüze taýýarlapdyk. Çaplayışçy tiz, yüngül we uly çubuklarda etkinleýär CoNLL 2017-nji ýylda Paýlaşmış Görevde: Raw Text'den Universal Dependenciýa çenli köp diller Parsing, resmi netijeler sistemimiziň Mengest 61.33% dyr.", 'sq': 'Ne paraqesim një analizues të varësisë shumëgjuhëse me një ekstraktor me dy drejtime LSTM (BiLSTM) dhe një klasifikues me shumë shtresa perceptron (MLP). Kemi trajnuar analizuesin tonë projektiv bazuar në tranzicion në UD version in 2.0 të dhënave pa të dhëna shtesë. Analizatori është i shpejtë, i lehtë dhe efektiv në vendet e mëdha të pemës. Në detyrën e përbashkët të CoNLL 2017: analiza shumëgjuhëse nga teksti i papërdorur në varësitë universale, rezultatet zyrtare tregojnë se rezultati makro-mesatar LAS F1 i sistemit tonë Mengest është 61.33%.', 'am': 'የብልቋንቋ-የግንኙነት-LSTM (BiLSTM) የፊደል አቀማመጥ እና የብዙልደረጃ ምርጫዎችን (MLP) መፍጠር እናደርጋለን፡፡ በ.ዲ ክፍል 2.0 ዳታዎችን ያለ ዳታ ሳይኖር የግንኙነት ፕሮጀክት ተማሪዎችን አስተማርተናል፡፡ ምርጫው ፈጥኖ፣ ቀላል እና ትልቅ የዛፍ ውጤቶች ነው፡፡ በካንLL 2017 የተሰራጨ ስራ ውስጥ: ከRaw Text to Universal Dependences Multilingual Parsing, ባለሥልጣናት ውጤቶች ማክሮው-average LAS F1 score የስርዓታችን ማነጋገስ 61.33 በመቶ ነው፡፡', 'fa': 'ما یک مشخص بستگی بستگی زیادی زبان را با یک خارج کننده ویژگی LSTM (BiLSTM) و یک مشخص بین لایه\u200cهای زیادی (MLP) نشان می\u200cدهیم. ما ویرایشگر پروژه\u200cای بر اساس تغییرات ما را در نسخه ۲.۰ داده\u200cهای UD بدون هیچ داده اضافه آموزش دادیم. تقسیم کننده سریع، وزن سبک و موثر روی چوب های بزرگ است. در کار مشترک CoNLL ۲۰۱۷: تحلیل زیادی زبان از متن Raw به بستگی جهانی، نتیجه رسمی نشان می دهد که نمونه\u200cهای مکرو متوسط LAS F1 از سیستم ما Mengest 61.33 درصد است.', 'az': "Biz bir çoxlu dil bağlılığı parçacısını iki tərəfli-LSTM (BiLSTM) fəaliyyəti ekstraktörü və çoxlu-katlı gözləyir (MLP) klasifikatörü ilə göstəririk. Biz UD verksiyonu 2.0 veri qurğuları heç bir əlavə məlumatı olmadan dəyişdirdik. Analizator hızlı, yüngül və böyük çubuqlar üzərində etkilidir. CoNLL 2017'nin paylaşılmış işində: Səfər Metindən Universal Dependenciyə qədər çoxlu dil analizi, resmi sonuçlar sistemimizin Mengest'in makro-ortalamalı LAS F1 dərəcəsi 61,33 olduğunu göstərir.", 'af': "Ons stel 'n veelvuldige afhanklikheidspanseerder met 'n bidirectional- LSTM (BiLSTM) funksie ekstraktor en 'n multi- layer perceptron (MLP) klassifiseerder voor te stel. Ons het ons transisie-gebaseerde projektiewe ontwerker opgelei in UD weergawe 2.0 datastelle sonder enige addisionele data. Die ontleerder is vinnig, liggewig en effektief op groot trebalke. In die CoNLL 2017 Gedeelde Opdrag: veelvuldige verwerking van Ro Teks na Universele Afhanklikhede, die offisiele resultate wys dat die makro-gemiddelde Las F1 telling van ons stelsel Mengest 61.33%.", 'ca': "We present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier.  Vam entrenar el nostre analitzador projectiu basat en transició en conjunts de dades UD versió 2.0 sense dades adicionals. L'analitzador és ràpid, llixer i efectiu en grans bancs d'arbres. En el CoNLL 2017 Task Shared: Multilingual Parsing from Raw Text to Universal Dependencies, els resultats oficials mostren que la puntuació macromitjana de LAS F1 del nostre sistema Mengest és del 61,33%.", 'hy': 'Մենք ներկայացնում ենք բազմալեզու կախվածության վերլուծողը, որը ունի երկու ուղղությամբ LSMT (BLSMT) առանձնահատկություններ և բազմաշերտ ընկալման (MLP) դասակարգիչ: We trained our transition-based projective parser in UD version 2.0 datasets without any additional data.  Պատրաստիչը արագ, թեթև և արդյունավետ է մեծ ծառերի վրա: In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33%.', 'bn': 'আমরা একটি মাল্টিভাষার নির্ভরশীল বিশেষভাবে উপস্থাপন করি একটি বিদ্যুত-এলস্টিএম (বিএলস্টিএম) বৈশিষ্ট্যের বিশেষ উদ্যোক্তা এবং এক বহুস্তরের আমরা আমাদের প্রজেক্টিভিত্তিক সংস্করণ ২. ০ ডাটাসেটে প্রশিক্ষণ দিয়েছি যার কোনো ডাটা ছাড়া। বিশ্লেষণ দ্রুত, হাল্কা এবং বিশাল ট্রাইব্যাংকের উপর কার্যকর। In the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33%.', 'et': 'Esitleme mitmekeelset sõltuvuspartserit kahesuunalise LSTM (BiLSTM) funktsioonide ekstraktori ja mitmekihilise perceptroni (MLP) klassifikaatoriga. Koolitasime oma üleminekupõhise projektiivse parseri UD versiooni 2.0 andmekogumites ilma lisaandmeteta. Parser on kiire, kerge ja efektiivne suurte puude puhul. CoNLL 2017. aasta jagatud ülesanne: mitmekeelne parsimine toortekstist universaalsete sõltuvusteni näitavad ametlikud tulemused, et meie süsteemi Mengest makrokeskmine LAS F1 skoor on 61,33%.', 'bs': 'Predstavljamo multijezički analitičar ovisnosti sa dodatnim ekstraktorom funkcije LSTM (BiLSTM) i klasifikatorom višeslojnih perceptora (MLP). Trenirali smo naš projektiv analizator na temelju prijenosa u UD verziji 2.0 podataka bez dodatnih podataka. Analizator je brz, lagan i učinkovit na velikim treebancima. U CoNLL 2017. zajedničkom zadatku: Multilingual Parsing from Raw Text to Universal Dependencies, zvanični rezultati pokazuju da je makro-srednji rezultat LAS F1 našeg sustava Mengest 61,33%.', 'cs': 'Představujeme vícejazyčný parser závislostí s obousměrným extraktorem vlastností LSTM (BiLSTM) a vícevrstvým klasifikátorem perceptronu (MLP). Náš projektivní parser založený na přechodu jsme vyškolili v UD verzi 2.0 datových sad bez dalších dat. Parser je rychlý, lehký a efektivní na velkých stromech. Ve sdíleném úkolu CoNLL 2017: Multilingual Parsing from Raw Text to Universal Dependences oficiální výsledky ukazují, že makro-průměrné skóre LAS F1 našeho systému Mengest je 61,33%.', 'fi': 'Esittelemme monikielisen riippuvuuden jäsentäjän, jossa on kaksisuuntainen LSTM (BiLSTM) -ominaisuusuutin ja monikerroksinen perceptron (MLP) -luokitus. Koulutimme siirtymäpohjaisen projektiivisen parserin UD version 2.0 datasarjoissa ilman lisätietoja. Parseri on nopea, kevyt ja tehokas suurille puille. CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependences -julkaisussa viralliset tulokset osoittavat, että Mengest-järjestelmämme makrokeskiarvo LAS F1 -pistemäärä on 61,33%.', 'jv': 'We present I am mobile." / "John is mobile. text Nang CoNLL 2011 Sampeyan Job: Multilanguage Parasing sing mengko Ngubah Tekst Sampeyan Universal', 'ha': 'Tuna ƙayyade wani fassarar ɗari na mulki-lingui da wata mai bajari na-LSM (BiLStM) da kuma wata daraja mai yawa-daraja (MLP). Mun sanar da mazaɓa masu bassi da aka shige masu bastarwa a cikin rubutun UD na 2.0, ba da wasu data ba. Ana fitarwa mai maras sauri, mai sauƙi da mai amfani da masu sauri. In the CoNLL 2017 Shared Takar: Many linguistic Parse from Raw Text to Universal Deputies, the offisive matsalar nuna that the macro-aged MAS F1 score of the system Mengest is 61.33%.', 'he': 'אנו מציגים מעבד תלויות רבות שפות עם מחלץ תכונות LSTM-bidirectional (BiLSTM) והקלאס של פספטרון רבות שכבות (MLP). We trained our transition-based projective parser in UD version 2.0 datasets without any additional data.  המחקר מהיר, קל ויעיל על עצים גדולים. במשימה המשותפת של CoNLL 2017: בדיקת רבות שפות מתוך טקסט ראוי לתלויות יוניברסליות, התוצאות הרשמיות מראות שהתוצאות הממוצעות של LAS F1 במערכת שלנו מנגסט היא 61.33%.', 'sk': 'Predstavljamo večjezični razčlenjevalnik odvisnosti z dvosmernim LSTM (BiLSTM) izvlečkom funkcij in večplastnim zaznavanjem (MLP). Naš projektivni razčlenjevalnik, ki temelji na prehodu, smo usposobili v UD različici 2.0 podatkovnih nizov brez dodatnih podatkov. Razčlenjevalec je hiter, lahek in učinkovit na velikih drevesnih ploščah. Uradni rezultati kažejo, da je makropovprečna ocena LAS F1 našega sistema Mengest 61,33%.', 'bo': 'We present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier. We trained our transition-based projective parser in UD version 2.0 datasets without any additional data. དབྱེ་སྟངས་མྱུར་ཚད་ལྡན་རིམ་པ་ཆེ་བའི་ནང་དུ་ཉུང་བ་ཞིག་ཡོད། CoNLL 2017 མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་ནང་དུ། སྐད་རིགས་ཀྱི་ཆ་འཕྲིན་ཡིག་ལས་ཕར་ཐོག་ཡིག་གཟུགས་ཀྱི་ནང་དུ་ཡོད།'}
{'en': 'The ParisNLP entry at the ConLL UD Shared Task 2017 : A Tale of a # ParsingTragedy', 'fr': "L'entrée de ParisNLP au ConLL UD Shared Task 2017\xa0: A Tale of a #ParsingTragedy", 'pt': 'A entrada do ParisNLP no ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'ar': 'دخول ParisNLP في مهمة مشتركة لـ ConLL UD 2017: قصة #ParsingTragedy', 'es': 'La entrada de ParisNLP en la CoNll UD Shared Task 2017: A Tale of a #ParsingTragedy', 'zh': '巴黎NLP在ConLL UD共事2017参赛一#ParsingTragedy', 'ja': 'ConLL UD Shared Task 2017: A Tale of a # ParsingTragedyのParisNLPエントリ', 'ru': 'Запись ParisNLP на ConLL UD Shared Task 2017: История #ParsingTragedy', 'hi': 'ConLL UD Shared Task 2017 में ParisNLP प्रविष्टि: एक #ParsingTragedy की एक कहानी', 'ga': 'An iontráil ParisNLP ag Tasc Comhroinnte ConLL UD 2017: A Tale of a #ParsingTragedy', 'ka': 'ParisNLP-ის ჩანაწერა 2017-ს ConLL UD გაყოფილი პარამეტრი: #ParsingTragedy', 'hu': 'A ParisNLP bejegyzés a ConLL UD Shared Task 2017-ben: A Tale of a #ParsingTragedy', 'el': 'Η καταχώρηση στο κοινό έργο 2017: Μια ιστορία μιας τραγωδίας', 'it': 'La voce ParisNLP al ConLL UD Shared Task 2017: Un racconto di una #ParsingTragedy', 'lt': 'ParisNLP įrašas ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'mk': 'Приказната за #ParsingTragedy', 'ml': 'കോണ്\u200dഎല്\u200d യുഡി പങ്കെടുത്ത പണിയില്\u200d പാരിസ്നെല്\u200dപി എന്\u200dട്രിക്ക്: ഒരു #പാര്\u200dസിങ്ങ് ട്രാജെഡിയുടെ സംസാരം:', 'ms': 'Masukan ParisNLP pada Tugas Berkongsi ConLL UD 2017: Sebuah Kisah #ParsingTragedy', 'mt': 'L-annotazzjoni ParisNLP fil-Kompitu Konġunt tal-UD tal-ConLL 2017: Story of a #ParsingTragedy', 'pl': 'Wpis ParisNLP na ConLL UD Shared Task 2017: Opowieść o #ParsingTragedii', 'mn': 'ParisNLP 2017 оны ConLL UD хуваалцаагүй ажил дээр орж ирсэн: #ParsingTragedy-ын түүх', 'no': 'ParisNLP- oppføringa på ConLL UD- delt oppgåve 2017: Storleik på eit # ParsingTragedy', 'kk': 'ConLL UD 2017 ортақтастырылған тапсырманың ParisNLP жазуы: # ParsingTragedy журналы', 'ro': 'Intrarea ParisNLP la ConLL UD Shared Task 2017: O poveste de #ParsingTragedie', 'sr': 'ParisNLP ulaz na ConLL UD zajednièki zadatak 2017: prièa o #ParsingTragedy', 'si': '2017 කෝන්ල් UD සමාගත වැඩේ පැරිස්නල්ප් ඇතුළුවේ: #පර්සින්ග් ට්\u200dරැජිඩි වලින් කතාවක්', 'so': 'Galgelinta ParisNLP ee ku saabsan Shaqada UD ee KonLL UD 2017: Hadal ku saabsan #ParsingTragedy', 'ta': 'கான்எல் UD பகிர்ந்த பணியில் பாரிஸ்NLP நுழைவு: ஒரு # பார்சிங்க்Tragedy', 'sv': 'ParisNLP-posten vid ConLL UD Shared Task 2017: En berättelse om en #ParsingTragedi', 'ur': 'ConLL UD Shared Task 2017 میں ParisNLP آنٹر: ایک #ParsingTragedy کا داستان', 'uz': 'KonLL UD Vazifani boʻlishilgan ParisNLP yozuvchisi 2017: ParsingTragedy', 'vi': 'The ParisNLP entry at the Conll UD shared Task bây bây bây giờ: A Tale of a\\ 35; Parsing Travedy', 'hr': 'ParisNLP ulaz na ConLL UD zajednički zadatak 2017: priča o #ParsingTragedy', 'nl': 'De ParisNLP inzending op de ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'da': 'ParisNLP-indlægget til ConLL UD Shared Task 2017: En fortælling om en #ParsingTragedi', 'bg': 'Входът в Парижката програма на споделената задача 2017: Приказка за #парсингтрагедия', 'fa': 'ورودی ParisNLP در کار مشترک کنل UD ۲۰۱۷: داستان یک #ParsingTragedy', 'de': 'Der ParisNLP-Eintrag beim ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'id': 'Entri ParisNLP di ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'ko': '2017년 유니버설 개발사 콘퍼런스에서 임무를 공유하는 Paris NLP 프로젝트: #Parsing Tragedy의 이야기', 'sq': 'Entrata në ParisNLP në ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'sw': 'Ujumbe wa ParisNLP kwenye UKIMWI ulishirikiana na kazi 2017: Hotuba ya #Gaza la ParsingTradi', 'hy': 'Պարիս', 'tr': "ConLL UD'yň 2017-nji ýylda ParisNLP girişi: Bir #ParsingTragedy", 'az': 'ConLL UD paylaşılmış işin 2017-ci ParisNLP girişi: #ParsingTragedy', 'am': 'በካንLL UD ስራ 2017 የፓርሲንNLP ማግባት: የ#ParsingTragedy እና ተናገር', 'af': "Die ParisNLP inskrywing by die ConLL UD Gedeelde Opdrag 2017: 'n Tale van 'n #ParsingTragedy", 'bn': 'প্যারিসএনএলপি প্রবেশ করা কন্ল ইউডি শেয়ার করা কাজ ২০১৭: একটি #পার্সিং ট্রেজেডির কথা', 'cs': 'Příspěvek ParisNLP na ConLL UD Shared Task 2017: Příběh #ParsingTragedy', 'bs': 'ParisNLP ulaz na ConLL UD zajednički zadatak 2017: priča o #ParsingTragedy', 'et': 'The ParisNLP kanne ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'fi': 'ParisNLP-julkaisu ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy -tapahtumassa', 'ca': "L'entrada de ParisNLP a la ConLL UD Shared Task 2017: Una història d'una #ParsingTragedy", 'ha': 'The ParisNLP entry at the ConLL UD Shared Takar 2017: A Tale of a #ParsingTraged', 'he': 'הכתובת של פריסNLP במשימה המשותפת של קונל UD 2017: סיפור של #ParsingTragedy', 'jv': 'Nambah Parais NLP nang barêng KonLL UT Gebah Taha-barêng-barêng', 'sk': 'Vpis ParisNLP na ConLL UD Shared Task 2017: A Tale of a #ParsingTragedy', 'bo': 'The ParisNLP entry at the ConLL UD Shared Task 2017: a Tale of a #ParsingTragedy'}
{'en': 'We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task. In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers. All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected. Unfortunately, a glitch in the shared task’s Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models. Because of this # ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.', 'ar': 'نقدم إدخال ParisNLP في مهمة التحليل المشتركة UD CoNLL 2017. بالإضافة إلى نماذج UDpipe المتوفرة ، قمنا ببناء نماذج الرمز المميز المعتمدة على البيانات الخاصة بنا ، ومُجزئة الجملة والمحللات الصرفية القائمة على المعجم. تم استخدام كل هذه مع مجموعة من نماذج التحليل المختلفة (عصبية أم لا ، غنية بالميزات أم لا ، انتقالية أو قائمة على الرسم البياني ، إلخ) وتم اختيار أفضل تركيبة لكل لغة. لسوء الحظ ، أدى وجود خلل في مصفوفة المهمة المشتركة إلى قيام محدد النموذج الخاص بنا بتشغيل نماذج معجمية عامة ضعيفة ، مصممة خصيصًا للغات المفاجئة ، بدلاً من نماذج مجموعة البيانات الخاصة بنا. بسبب #ParsingTragedy ، احتلنا المرتبة 27 رسميًا ، بينما احتلت نماذجنا الحقيقية أخيرًا المرتبة السادسة بشكل غير رسمي.', 'pt': 'Apresentamos a entrada ParisNLP na tarefa compartilhada de análise do UD CoNLL 2017. Além dos modelos UDpipe fornecidos, construímos nossos próprios modelos de tokenização baseados em dados, segmentador de frases e analisadores morfológicos baseados em léxico. Todos eles foram usados com uma variedade de diferentes modelos de análise (neural ou não, rico em recursos ou não, baseado em transição ou gráfico, etc.) e a melhor combinação para cada idioma foi selecionada. Infelizmente, uma falha na Matrix da tarefa compartilhada levou nosso seletor de modelos a executar modelos genéricos e fracamente lexicalizados, adaptados para linguagens surpresa, em vez de nossos modelos específicos de conjunto de dados. Por causa dessa #ParsingTragedy, oficialmente ocupamos o 27º lugar, enquanto nossos modelos reais finalmente ficaram não oficialmente em 6º.', 'es': 'Presentamos la entrada de ParisNLP en la tarea compartida de análisis de la UD CoNll 2017. Además de los modelos UDPipe proporcionados, creamos nuestros propios modelos de tokenización basados en datos, segmentadores de oraciones y analizadores morfológicos basados en léxicos. Todos estos se usaron con una variedad de modelos de análisis diferentes (neuronales o no, con o sin funciones, de transición o basados en gráficos, etc.) y se seleccionó la mejor combinación para cada idioma. Desafortunadamente, una falla en la matriz de tareas compartidas llevó a nuestro selector de modelos a ejecutar modelos genéricos, débilmente lexicalizados, diseñados para lenguajes sorpresa, en lugar de nuestros modelos específicos de conjuntos de datos. Debido a este #ParsingTragedy, oficialmente ocupamos el puesto 27, mientras que nuestros modelos reales finalmente ocuparon el sexto lugar extraoficialmente.', 'fr': "Nous présentons l'entrée ParisNLP lors de la tâche partagée d'analyse UD ConLL 2017. En plus des modèles UDPipe fournis, nous avons créé nos propres modèles de tokenisation pilotés par les données, un segmenteur de phrases et des analyseurs morphologiques basés sur des lexiques. Tous ces modèles ont été utilisés avec différents modèles d'analyse (neuronal ou non, riche en fonctionnalités ou non, transition ou graphique, etc.) et la meilleure combinaison pour chaque langue a été sélectionnée. Malheureusement, un problème dans la matrice de la tâche partagée a conduit notre sélecteur de modèles à exécuter des modèles génériques faiblement lexicalisés, adaptés aux langages surprises, au lieu de modèles spécifiques à nos ensembles de données. Grâce à ce #ParsingTragedy, nous nous sommes officiellement classés 27e, tandis que nos vrais modèles se sont finalement classés 6e de manière officieuse.", 'ja': 'PARISNLPエントリをUD CoNLL 2017の解析共有タスクで紹介します。提供されているUDpipeモデルに加えて、独自のデータ駆動型トークン化モデル、文章セグメンタ、およびレキシコンベースの形態分析器を構築しました。これらのすべては、さまざまな構文解析モデル（ニューラルまたは非ニューラル、特徴豊富または非ニューラル、トランジションまたはグラフベースなど）と共に使用され、各言語の最適な組み合わせが選択された。残念ながら、共有タスクのマトリックスの不具合により、データセット固有のモデルではなく、サプライズ言語に合わせた一般的で弱い語彙化されたモデルを実行することになりました。この# ParsingTragedyのおかげで、私たちは公式に27位にランクインしましたが、実際のモデルは非公式に6位にランクインしました。', 'zh': '共 UD CoNLL 2017 解析 ParisNLP 条目。 非供UDpipe之外,构其数驱,句分割器词典形分析器。 凡此诸解析,或非神经解析,功能丰富或不丰,济)并用,为言最佳。 不幸者,共事之Matrix小故障而选择器行通用,弱词汇化之形,惊喜言量身制,非吾数特定集也。 此#ParsingTragedy正排名第27位,吾真形终排名第6位。', 'hi': 'हम UD CoNLL 2017 में पेरिसएनएलपी प्रविष्टि को साझा कार्य को पार्स करते हुए प्रस्तुत करते हैं। प्रदान किए गए UDpipe मॉडल के अलावा, हमने अपने स्वयं के डेटा-संचालित टोकनाइजेशन मॉडल, वाक्य सेगमेंटर और शब्दकोश-आधारित रूपात्मक विश्लेषकों का निर्माण किया। इन सभी का उपयोग विभिन्न पार्सिंग मॉडल (तंत्रिका या नहीं, फीचर-समृद्ध या नहीं, संक्रमण या ग्राफ-आधारित, आदि) की एक श्रृंखला के साथ किया गया था और प्रत्येक भाषा के लिए सबसे अच्छा संयोजन चुना गया था। दुर्भाग्य से, साझा कार्य के मैट्रिक्स में एक गड़बड़ ने हमारे मॉडल चयनकर्ता को हमारे डेटासेट-विशिष्ट मॉडल के बजाय, आश्चर्यजनक भाषाओं के लिए तैयार किए गए जेनेरिक, कमजोर रूप से लेक्सिकलाइज्ड मॉडल चलाने के लिए प्रेरित किया। इस #ParsingTragedy के कारण, हम आधिकारिक तौर पर 27 वें स्थान पर रहे, जबकि हमारे वास्तविक मॉडल अंततः अनौपचारिक रूप से 6 वें स्थान पर रहे।', 'ru': 'Мы представляем запись ParisNLP на совместной задаче анализа UD CoNLL 2017. В дополнение к предоставленным моделям UDpipe, мы создали собственные модели токенизации на основе данных, сегмент предложений и морфологические анализаторы на основе лексикона. Все они использовались с различными моделями синтаксического анализа (нейронными или нет, богатыми или нет, переходными или на основе графов и т. д.), и была выбрана наилучшая комбинация для каждого языка. К сожалению, сбой в матрице общей задачи привел к тому, что наш селектор моделей запустил общие, слабо лексикализованные модели, адаптированные для неожиданных языков, вместо наших моделей, специфичных для набора данных. Из-за этого # ParsingTragedy мы официально заняли 27-е место, в то время как наши реальные модели, наконец, неофициально заняли 6-е место.', 'ga': 'Cuirimid iontráil ParisNLP i láthair ag tasc roinnte parsála UD CoNLL 2017. I dteannta leis na samhlacha UDphíobáin a cuireadh ar fáil, chuireamar lenár múnlaí téaltaithe sonraí-tiomáinte féin, deighleoir abairtí agus anailísí moirfeolaíocha bunaithe ar fhoclóirí. Úsáideadh iad seo go léir le raon de mhúnlaí éagsúla parsála (neodrach nó neamhbheo, gné-saibhir nó neamh-saibhir, trasdul nó graf-bhunaithe, etc.) agus roghnaíodh an meascán is fearr do gach teanga. Ar an drochuair, de bharr glitch i Maitrís an taisc chomhroinnte d’éirigh lenár roghnóir samhlacha a bheith ag rith samhlacha cineálacha, lagfhoclóirithe, a bhí saincheaptha do theangacha iontasacha, in ionad ár samhlacha a bhaineann go sonrach le tacair shonraí. Mar gheall ar an #ParsingTragedy seo, rinneamar an 27ú háit go hoifigiúil, ach bhí ár bhfíor-mhúnlaí sa 6ú háit go neamhoifigiúil ar deireadh.', 'ka': 'ჩვენ გავაჩვენოთ ParisNLP ჩანაწერის UD CoNLL 2017-ში გაყოფილი დავაწერა. UDpipe მოდელების დამატებით, ჩვენ შევქმნა ჩვენი მონაცემების ტოკენიზაციის მოდელები, სიტყვების სეგმენტერი და ლექსიკონური მორპოლოგიური ანალიზატორი. ყველაფერი გამოყენებულია განსხვავებული პარასტირების მოდელებით (ნეიროლი ან არა, ფუნქციების ბეჭდვილი ან არა, გადატანაცია ან გრაფიკური დაბათებული განსხვავებული განსხვავებული) და ყოველ მარტიკისგან ჩვენი მოდელური მოდელექტორის მარტიკისგან ჩვენი მოდელური მოდელექტორის გადაყენება სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა მდე ამის შემთხვევაში #ParsingTragedy, ჩვენ პროფიციალურად 27-ს წერტილი, მაგრამ ჩვენი რეალური მოდელები ნაკლებად არაფექციურად 6-ი წერტილი.', 'hu': 'Bemutatjuk a ParisNLP bejegyzést az UD CoNLL 2017 megosztott feladat elemzésén. A rendelkezésre álló UDpipe modellek mellett saját adatvezérelt tokenizációs modelleket, mondatszegmentert és lexikon alapú morfológiai analizátorokat építettünk. Mindezeket különböző elemzési modellekkel használtuk (neurális vagy nem, funkciókban gazdag vagy nem, átmeneti vagy gráf alapú stb.), és minden nyelvhez kiválasztottuk a legjobb kombinációt. Sajnos a megosztott feladat Mátrixában bekövetkezett hiba miatt modellválasztónk általános, gyengén lexikalizált modelleket futtat, amelyek meglepetési nyelvekre szabottak, az adatkészletspecifikus modellek helyett. A #ParsingTragedy miatt hivatalosan 27. helyen álltunk, míg valódi modelleink végül nem hivatalosan 6. helyen álltak.', 'el': 'Παρουσιάζουμε την καταχώρηση στην ανάλυση κοινής εργασίας. Εκτός από τα μοντέλα που παρέχονται, κατασκευάσαμε τα δικά μας μοντέλα επισήμανσης βασισμένα σε δεδομένα, τμήματα προτάσεων και μορφολογικούς αναλυτές βασισμένους στο λεξικό. Όλα αυτά χρησιμοποιήθηκαν με μια σειρά διαφορετικών μοντέλων ανάλυσης (νευρωνικά ή όχι, πλούσια σε χαρακτηριστικά ή όχι, μετάβαση ή γραφήματα, κλπ.) και επιλέχθηκε ο καλύτερος συνδυασμός για κάθε γλώσσα. Δυστυχώς, μια δυσλειτουργία στο Μάτριξ της κοινής εργασίας οδήγησε τον επιλογέα μοντέλων μας να εκτελεί γενικά, αδύναμα λεξιλογικά μοντέλα, προσαρμοσμένα για γλώσσες έκπληξης, αντί για συγκεκριμένα μοντέλα δεδομένων. Εξαιτίας αυτής της τραγωδίας, κατατάξαμε επίσημα 27η, ενώ τα πραγματικά μοντέλα μας τελικά ανεπίσημα κατατάχθηκαν 6η.', 'it': 'Presentiamo la voce ParisNLP al compito condiviso di analisi UD CoNLL 2017. Oltre ai modelli UDpipe forniti, abbiamo costruito i nostri modelli di tokenizzazione basati sui dati, segmentatore di frasi e analizzatori morfologici basati sul lessico. Tutti questi sono stati utilizzati con una gamma di diversi modelli di analisi (neurali o meno, ricchi di funzionalità o meno, transizioni o grafici, ecc.) e la migliore combinazione per ogni lingua è stata selezionata. Sfortunatamente, un glitch nella Matrix del compito condiviso ha portato il nostro selettore di modelli ad eseguire modelli generici, debolmente lessicalizzati, su misura per linguaggi a sorpresa, invece dei nostri modelli specifici per il set di dati. A causa di questa #ParsingTragedy, siamo ufficialmente al 27esimo posto, mentre i nostri modelli reali sono finalmente al sesto posto.', 'kk': 'Ортақ тапсырманы талдау UD CoNLL 2017 бағдарламасында ParisNLP жазуын келтірік. UDpipe үлгілерінің қосымша, өзіміздің деректеріміздің токенизациялау үлгілерімізді, сөздер сегментері және лексикандық морфологиялық анализаторларымызды құрдық. Бұл барлығы бірнеше талдау үлгілерімен қолданылды (неврал немесе емес, мүмкіндіктерді бағалау немесе емес, ауыстыру немесе график негізінде және т. б.) және әрбір тіл үшін ең жақсы комбинацияс Кешіріңіз, бөлінген тапсырманың Матриксиясындағы біздің үлгі таңдаушысымызды жалпы, бақытты лексикализациялау үлгілерін жегуге, біздің деректер жиының ерекше үлгілерінің орнына, өзгертілген тілдерге Бұл #Парсинг Трагедия сияқты біз 27-ші ретінде, бірақ шын моделдеріміз аяқталмай 6-ші ретінде.', 'mk': "Го претставуваме влезот во Парис НЛП во УД CoNLL 2017 за анализирање на заедничката задача. Покрај обезбедените UDpipe модели, ние ги изградивме нашите сопствени модели за токенизација, сегментер на реченици и морфолошки анализатори базирани на лексикони. Сите овие беа употребени со голем број различни модели за анализирање (неурални или не, богати или не, транзиција или графика итн.) и беше избрана најдобрата комбинација за секој јазик. Unfortunately, a glitch in the shared task's Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models.  Поради оваа #ParsingTragedy, официјално се рангиравме на 27, додека нашите вистински модели конечно не се рангираа на 6.", 'ml': 'ഞങ്ങള്\u200d യുഡി കോണ്\u200dഎല്\u200d 2017 പാര്\u200dസ് ചെയ്ത ജോലിയില്\u200d പാരിസ്നെല്\u200dപി എന്\u200dട്രിക്ക് കാണിക്കുന്നു. യുഡിപ്പിപ്പ് മോഡലുകള്\u200dക്ക് കൂടാതെ, ഞങ്ങള്\u200d നമ്മുടെ സ്വന്തം വിവരങ്ങള്\u200d നടത്തിക്കൊണ്ടിരിക്കുന്ന ടോണിജേഷന്\u200d മോഡല്\u200d പണിതു, വാക്ക്  ഇതെല്ലാം വ്യത്യസ്ത പാര്\u200dസിംഗ് മോഡലുകളുമായി ഉപയോഗിക്കപ്പെട്ടിരിക്കുന്നു (ന്യൂറല്\u200d അല്ലെങ്കില്\u200d, ഗ്രാഫ്റ്റിങ്ങ് അല്ലെങ്കില്\u200d, മാ ഭാഗ്യവശാലം, പങ്കുള്ള ജോലിയുടെ മാറ്റിക്സില്\u200d ഒരു സ്ലിച്ച് നമ്മുടെ മോഡല്\u200d തെരഞ്ഞെടുക്കുന്നത് സാധാരണ, ദുര്\u200dബലമായ ലെക്സിക്കേഷന്\u200d മോഡലുകള്\u200d നടത Because of this #ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.', 'mt': 'Aħna nippreżentaw l-annotazzjoni tal-PariġiNLP fl-UD CoNLL 2017 bl-analiżi tal-kompitu komuni. Minbarra l-mudelli UDpipe pprovduti, aħna bnijna mudelli ta’ tokenizzazzjoni bbażati fuq id-dejta tagħna stess, segmentatur tas-sentenzi u analizzaturi morfoloġiċi bbażati fuq il-lexicon. Dawn kollha ntużaw ma’ firxa ta’ mudelli differenti ta’ analiżi (newrali jew le, b’ħafna karatteristiċi jew le, tranżizzjoni jew grafika, eċċ.) u ntgħa żlet l-aħjar kombinazzjoni għal kull lingwa. Sfortunatament, falliment fil-Matrix tal-kompitu kondiviż wassal biex is-selettur tal-mudell tagħna jmexxi mudelli ġeneriċi, b’leżikalizzazzjoni dgħajfa, imfassla għal lingwi sorpriżi, minflok mudelli speċifiċi għa s-sett tad-dejta tagħna. Minħabba din il-#ParsingTragedy, aħna uffiċjalment ikklassifikati fis-27, filwaqt li l-mudelli reali tagħna finalment ikklassifikati mhux uffiċjalment fis-6.', 'mn': 'Бид 2017 оны CoNLL-ын UD-д ParisNLP-ын хуваалцааны ажлыг хуваалцаж өгсөн. UDpipe загваруудын нэмэлт нь бид өөрсдийн өгөгдлийн дамжуулагдсан томонизийн загваруудыг, өгүүлбэл загваруудыг, лексикон дээр суурилсан морфологик шинжилгээчийг бүтээсэн. Эдгээр бүх зүйлс өөр хэлбэртэй хуваалцах загвартай хэрэглэгдсэн (мэдрэлийн эсвэл биш, өөрчлөлт баян эсвэл биш, шилжилт эсвэл график суурилсан, т.д.) болон хэл бүрт хамгийн сайн нэгтгэл сонгогдсон. Харамсалтай нь бидний загвар сонгогч Матрикс-ын хуваалтын нэг харагдаж өгөгдлийн сангийн тодорхой загваруудын оронд гайхалтай хэлнүүдийн загвар ашиглаж байв. Энэ #ParsingTragedy-ын тулд бид ерөнхийдөө 27-р багтаж байлаа. Гэхдээ бидний бодит загвар эцэст нь 6-р багтаж байлаа.', 'lt': "Paryžiaus NLP įrašas pristatomas UD CoNLL 2017 m. analizuojant bendrą užduotį. Be pateiktų UDpipe modelių, sukūrėme savo duomenimis pagrįstus tokenizacijos modelius, sakinių segmentatorių ir leksikonu pagrįstus morfologinius analizatorius. Visi jie buvo naudojami su įvairiais analizavimo modeliais (nerviniais arba ne, turinčiais daug savybių arba ne, pereinamuoju arba grafiniu pagrindu ir t. t.) ir pasirinktas geriausias kiekvienos kalbos derinys. Unfortunately, a glitch in the shared task's Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models.  Dėl šios #ParsingTragedy, mes oficialiai rankavome 27-ąjį, o mūsų tikrieji modeliai pagaliau neformaliai rankavo 6-ąjį.", 'pl': 'Przedstawiamy wpis ParisNLP w UD CoNLL 2017 parsując wspólne zadanie. Oprócz dostarczonych modeli UDpipe zbudowaliśmy własne modele tokenizacji oparte na danych, segmenter zdań oraz analizatory morfologiczne oparte na leksykonie. Wszystkie z nich zostały użyte z szeregiem różnych modeli parsowania (neuronowych lub nie, bogatych w funkcje lub nie, przejściowych lub wykresów itp.) i wybrano najlepszą kombinację dla każdego języka. Niestety, usterka w Matrixie współdzielonego zadania doprowadziła nasz selektor modeli do uruchomienia generycznych, słabo leksykalizowanych modeli, dostosowanych do języków niespodzianek, zamiast modeli specyficznych dla zestawu danych. Z powodu tego #ParsingTragedy oficjalnie zajęliśmy 27-tą rangę, podczas gdy nasze prawdziwe modele ostatecznie nieoficjalnie zajęły się szóstym miejscem.', 'ro': 'Prezentăm intrarea ParisNLP la UD CoNLL 2017 parsing shared task. În plus față de modelele UDpipe furnizate, am construit propriile noastre modele de tokenizare bazate pe date, segmentare de propoziții și analizoare morfologice bazate pe lexicon. Toate acestea au fost folosite cu o gamă de modele de analizare diferite (neurale sau nu, bogate sau nu, tranziții sau grafice, etc.) și a fost selectată cea mai bună combinație pentru fiecare limbă. Din păcate, o eroare în Matrix sarcinii partajate a condus selectorul nostru de modele să ruleze modele generice, slab lexicalizate, adaptate pentru limbi surpriză, în loc de modelele noastre specifice setului de date. Datorită acestui #ParsingTragedy, am ocupat oficial locul 27, în timp ce modelele noastre reale au ocupat în cele din urmă neoficial locul 6.', 'ms': 'We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task.  Selain model UDpipe yang diberikan, kami bina model tokenisasi pemacu data kami sendiri, segmenter kalimat dan analisis morfologi berdasarkan leksikon. Semua ini digunakan dengan julat model penghuraian yang berbeza (saraf atau tidak, kaya atau tidak, peralihan atau berdasarkan graf, dll.) dan kombinasi terbaik bagi setiap bahasa dipilih. Malangnya, kesalahan dalam Matriks tugas terkongsi memimpin pemilih model kita untuk menjalankan model yang generik, lemah, disesuaikan untuk bahasa kejutan, bukan model spesifik set data kita. Kerana #ParsingTragedy ini, kami secara rasmi berturut-turut ke-27, sementara model sebenar kami akhirnya tidak secara rasmi berturut-turut ke-6.', 'no': 'Vi presenterer ParisNLP- oppføringa på UD CoNLL 2017 som tolkar delt oppgåve. I tillegg til UDpipe-modellen som er tilgjengeleg, bygde vi våre eige data-drivte tokeniseringsmodeller, setningsssegmenterer og morfologiske analyserar som er basert på leksikonbasert. Alle desse vart brukte med eit rekke av ulike tolkingsmodular (neuralt eller ikkje, funksjonsryg eller ikkje, overgang eller grafikkbasert osv.) og det beste kombinasjonen for kvar språk vart valt. Dessverre førte ein glisk i matrisen til delt oppgåve vår modelleveljaren til å køyra generiske, svakte lexikaliserte modeller, som er tilpassa for surprisespråk i staden for våre datasettspesifikke modeller. På grunn av denne #ParsingTragedy, har vi offisielt rekna 27th, mens våre verkelege modeller slutt ufficielt rekna 6th.', 'so': 'Waxaynu soo bandhignaynaa jardiinada baarlamaanka ee UD CoNLL 2017 ee baarlamaanka shaqada la qaybsaday. Tusaalada UDpipe ee la soo saaray ka sokow, waxaynu dhisnay modeliyada la soo saaray macluumaadka, kooxaha xabsiga iyo wax analyaalka morphologiga ee leksikan ku saleysan. Dhammaan waxaa lagu isticmaalay tusaalooyin baaritaanka kala duduwan (neural ama aan ahayn, taajir ama aan ahayn, beddelka ama xarafka, etc.) waxaana la doortay isku xiriirka ugu fiican ee luqad kasta. Nasiib xumaatooyinka Matrix ee shaqada la qaybsan ayaa ku hoggaamiyey doorashada modellkayaga in uu sameeyo modelalka geneeral, tabar yar oo la sawiray, waxaana lagu qoray luuqadaha la yaabo, taasoo ka badalta modelalka gaarka ah ee macluumaadkayaga. Because of this #ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.', 'sv': 'Vi presenterar ParisNLP-posten vid UD CoNLL 2017 parsing shared task. Utöver UDpipe-modellerna byggde vi egna datadrivna tokeniseringsmodeller, meningssegmenterare och lexikonbaserade morfologiska analysatorer. Alla dessa användes med en rad olika tolkningsmodeller (neurala eller inte, funktionsrika eller inte, övergångs- eller grafbaserade etc.) och den bästa kombinationen för varje språk valdes ut. Tyvärr fick ett fel i den delade uppgiftens Matrix vår modellväljare att köra generiska, svagt lexikaliserade modeller, skräddarsydda för överraskningsspråk, istället för våra datasetsspecifika modeller. På grund av denna #ParsingTragedy rankade vi officiellt 27:e, medan våra riktiga modeller slutligen inofficiellt rankade 6:e.', 'sr': 'Predstavljamo ulaz ParisNLP na UD CoNLL 2017. za analizu zajedničkog zadatka. Uz predviđene UDpipe modele, izgradili smo sopstvene modele tokenizacije podataka, segmentera rečenica i morfološke analizatore na leksikonu. Sve ovo je korišteno sa nizom različitih modela za analizu (neuralno ili ne, bogat ili ne, prelazak ili na grafiku, itd.) i najbolja kombinacija za svaki jezik je izabrana. Nažalost, pogled u Matrixu zajedničkog zadatka doveo je našeg selektora model a da vodi generične, slabe leksikalizirane modele, pripremljene za jezike iznenađenja umjesto našeg modela specifičnih podataka. Zbog ovog #ParsingTragedyja, zvanično smo bili 27. redovi, dok su naši pravi modeli konačno neoficijalni 6. redovi.', 'si': 'අපි UD CoNLL 2017 වැදගත් වැඩක් විශ්ලේෂණය කරනවා පාරිස්න්ල් ඇතුලට පෙන්වන්න. UD පායිප් මෝඩේල් එක්ක, අපි අපේ දත්ත ප්\u200dරවේශකය විශ්ලේෂකයෝ නිර්මාණය කරනවා. මේ හැමෝම භාවිතා වෙනස් විශේෂ මොඩේල් එක්ක භාවිත කරලා තියෙනවා (න්\u200dයූරාල් නැත්නම්, විශේෂ- ප්\u200dරතිශේෂ නැත්නම්, ස අවාසනාවෙන්නේ, කොටස් එකේ මැට්\u200dරික්ස් එක්ක සාමාන්\u200dය වැඩකරුවෙන් අපේ මොඩල් තෝරණ කරුණාකරුවෙක් සාමාන්\u200dය, දුර්වල් ලෙක්සිකල් වැඩකරල මේක නිසා #පර්සින්ග්ට්\u200dරැජිඩි නිසා, අපි නියෝජිතයෙන් 27වෙනි ස්ථානයෙන් ඉන්නවා, ඒත් අපේ ඇත්ත මොඩේල් අවසාන', 'ta': 'நாங்கள் பாரிஸ்NLP நுழைவை காண்பிக்கிறோம் யு டி கோன்எல் 2017 பகிர்ந்த பணியை பாடல். UDpipe மாதிரிகளுக்கு மேலும், நாங்கள் எங்கள் சொந்த தரவு இயக்கப்பட்ட ஒளிக்கும் மாதிரிகளை உருவாக்கினோம், வாக்கு பிரிவு மற்றும் லெக் இவையனைத்தையும் வேறு வித்தியாசமான பாடல் மாதிரிகளுடன் பயன்படுத்தப்பட்டது (புதிய அல்லது இல்லை, குணங்கள் சார்ந்த அல்லது இல்லை, மாற்றம் அல்லது வரைகலைப துரதிர்ஷ்டவசமாக, பங்கிடப்பட்ட பணியின் மாட்ரிக்ஸில் ஒரு glitch led our model selector to run generic, weakly lexicalized model s, tailored for surprise languages, instead of our data set-specific models. இந்த #ParsingTragedy காரணம், நாங்கள் officially ranked 27வது, ஆனால் இறுதியாக எங்கள் உண்மையான மாதிரிகள் ஆறாவது வரிசையில் இல்லை.', 'ur': 'We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task. UDpipe مدلکوں کے علاوہ ہم نے اپنے ڈاٹ کے ذریعہ ٹوکینیزی مدلکوں، جماعت سجنگٹر اور لکسیکون کے ذریعہ دار مورفیق تحلیل کرنے والوں کو بنایا۔ اور ہر زبان کے لئے بہترین ترکیب گزاری گئی۔ بدبختی کے ساتھ، مشترک کام کے ماتریکس میں ایک گلچ نے ہمارے موڈل انتخاب کرنے والوں کو جسمانی، ضعیف لکسیکلیز موڈل چلنے کے لئے لایا تھا، جو ہمارے ڈیٹ سٹ کے خاص موڈل کے بدلے تعجب کی گئی تھی. اس #پارسینگ تراگڈی کے سبب، ہم رسمی طور پر 27 درجے تھے، حالانکہ ہمارے حقیقی نمونڈے بالآخر چھ درجے غیر رسمی طور پر تھے.', 'uz': "Biz parisNLP yozuvchi UD CoNLL 2017'da bir necha vazifani ajratishga yetdik. UDpipe modellaridan koʻproq, biz o'zimiz ma'lumotlar bilan ishlab chiqarish modellarimizni yaratdik, sentencening segmenter va leksika asosida morfologik analyzerlarini yaratdik. Ushbu hamma boshqa parsing modellari bilan ishlatiladi (neyural yoki ma'lumot, xotira yoki taʼminlovchi yoki grafik asosida) va har bir tillar uchun eng yaxshi kombinatsiya tanlangan. Uzunlik, bu vazifaning bir qismlari Matrix bilan bir qismi modelimizni o'zgartirish uchun umumiy, yaxshi leksikatlik modellarini ishga tushirish uchun o'zgartirdi. Maʼlumotlar saqlash modellarimizni oʻrniga qo'yish mumkin. Bu #ParsingTragedy sababini, biz rasmiy 27 marta boshlanamiz, balki bizning haqiqiqiy modellarimiz shaxsiy ikkinchi odamni o'zgartiradi.", 'vi': 'Chúng tôi giới thiệu mục nhập của Paris NLP tại UD CoNLL thẩm 7 phân tích công việc chia sẻ. Ngoài các mô hình UDpipe cung cấp, chúng tôi đã xây dựng các mô hình trưng bày dữ liệu riêng, câu đã phân biệt chủng và từ-hoá dựa theo morphine. Tất cả những thứ này được dùng với một loạt các mô hình phân tách khác nhau (thần kinh hay không, giàu có hay không, chuyển đổi hay dựa vào đồ thị, v.v.). và kết hợp tốt nhất cho mỗi ngôn ngữ được chọn. Tiếc thay, một s ự cố nhỏ trong Ma Trận của công việc chia sẻ đã dẫn trình chọn mẫu của chúng ta chạy các mô hình chung, thiếu sót từ hoá học, được may cho ngôn ngữ bất ngờ, thay vì các mô hình cụ. Bởi vì thứ này\\ 35; Parsing Tranghiêm, chúng ta chính thức xếp hàng 27, trong khi mẫu thật cuối cùng là không chính thức đứng thứ sáu.', 'bg': 'Представяме вписването в Парижката програма за анализ на споделената задача. В допълнение към предоставените модели създадохме собствени модели за токенизация, базирани на данни, сегментиращи изречения и морфологични анализатори, базирани на лексикон. Всички те са използвани с набор от различни модели за анализ (невронни или не, богати на функции или не, преход или графични и др.) и е избрана най-добрата комбинация за всеки език. За съжаление, бъг в Матрицата на споделената задача накара нашия селектор на модели да стартира генерични, слабо лексикализирани модели, пригодени за езици изненадващи, вместо специфични модели за набор от данни. Заради тази #ПарсингТрагедия официално се класирахме на 27-то място, докато истинските ни модели най-накрая неофициално се класираха на 6-то място.', 'da': 'Vi præsenterer ParisNLP-indgangen ved UD CoNLL 2017 parsing delt opgave. Ud over UDpipe-modellerne byggede vi vores egne datadrevne tokeniseringsmodeller, sætningssegmenter og leksikonbaserede morfologiske analysatorer. Alle disse blev brugt med en række forskellige parsingsmodeller (neurale eller ej, funktionsrige eller ej, overgangs- eller grafbaserede osv.), og den bedste kombination for hvert sprog blev valgt. Desværre fik en fejl i den delte opgaves Matrix vores modelvælger til at køre generiske, svagt leksikaliserede modeller, skræddersyet til overraskelsessprog, i stedet for vores datasætsspecifikke modeller. På grund af denne #ParsingTragedy rangerede vi officielt 27., mens vores rigtige modeller endelig rangerede 6.', 'nl': 'We presenteren de ParisNLP-vermelding bij de UD CoNLL 2017 parsing shared task. Naast de verstrekte UDpipe modellen hebben we onze eigen data-gedreven tokenization modellen, zinssegmenter en lexicon gebaseerde morfologische analyzers gebouwd. Deze werden allemaal gebruikt met een reeks verschillende parsing modellen (neuraal of niet, feature-rich of niet, overgang of grafiek gebaseerd, enz.) en de beste combinatie voor elke taal werd geselecteerd. Helaas leidde een storing in de Matrix van de gedeelde taak ertoe dat onze modelselector generieke, zwak gelexicaliseerde modellen uitvoerde, afgestemd op verrassingstalen, in plaats van onze dataset-specifieke modellen. Door deze #ParsingTragedy zijn we officieel 27e geworden, terwijl onze echte modellen uiteindelijk onofficieel 6e werden.', 'hr': 'Predstavljamo ulaz ParisNLP na UD CoNLL 2017. za analizu zajedničkog zadatka. Osim dodatnih UDpipe modela, izgradili smo vlastite modele tokenizacije podataka, segmentera rečenica i morfološke analizatore na temelju leksikona. Sve ovo je korišteno s rasponom različitih analiziranih modela (neuralno ili ne, bogat ili ne, prelazak ili na grafiku osnovan itd.) i odabrana je najbolja kombinacija za svaki jezik. Nažalost, pogled u matriksu zajedničkog zadatka doveo je našeg selektora model a da vodi generične, slabe leksikalizirane modele, prilagođene za jezike iznenađenja, umjesto našeg modela specifičnih podataka. Zbog ovog #ParsingTragedyja, zvanično smo bili 27. redovi, dok su naši pravi modeli konačno neoficialni redovi 6. redovi.', 'de': 'Wir präsentieren den ParisNLP Eintrag bei der UD CoNLL 2017 Parsing Shared Task. Zusätzlich zu den bereitgestellten UDpipe-Modellen bauten wir eigene datengetriebene Tokenisierungsmodelle, Satzsegmentierer und lexikon-basierte morphologische Analysatoren. Alle diese wurden mit einer Reihe von verschiedenen Parsing-Modellen (neuronal oder nicht, feature-rich oder nicht, transition oder graph-based, etc.) verwendet und die beste Kombination für jede Sprache ausgewählt. Leider führte ein Fehler in der Matrix der geteilten Aufgabe dazu, dass unser Modellselektor generische, schwach lexikalisierte Modelle anstelle unserer datensatzspezifischen Modelle ausführte, die auf Überraschungssprachen zugeschnitten waren. Aufgrund dieser #ParsingTragedy belegten wir offiziell den 27ten Platz, während unsere echten Modelle schließlich inoffiziell den sechsten Platz belegten.', 'fa': 'ما وارد پاریزNLP را در UD CoNLL 2017 نشان می دهیم که مشترک کار مشترک است. در اضافه به مدل UDpipe پیشنهاد، ما مدل توکینز داده های خودمان را ساختیم، مجموعه\u200cکننده\u200cی جمله\u200cها و تحلیل\u200cکننده\u200cهای مورفولوژیکی بر اساس لکسیکون. همه اینها با مجموعه\u200cی مدل\u200cهای پردازی متفاوت استفاده می\u200cشوند (عصبی یا نه، ویژه\u200cهای ثروتمند یا نه، تغییر یا بنیاد گراف و غیر گراف) و بهترین ترکیب برای هر زبان انتخاب شده\u200cاند. متاسفانه، یک چشم در ماتریکس کار مشترک به انتخاب مدل ما رهبری کرد تا مدل های ژنتیک و ضعیف زبان\u200cهای متعجیب، به جای مدل\u200cهای ویژه\u200cهای داده\u200cهای ما را اجرا کند. به خاطر این تراژدهای پارسینگ، ما رسمی ۲۷م درجه داشتیم، در حالی که مدلهای واقعی ما بالاخره ۶م درجه غیر رسمی بود.', 'ko': 'UD CoNLL 2017에서 공유 작업을 해결할 때 ParisNLP 항목을 보여줍니다.제공된 Udpipe 모델을 제외하고 우리는 자신의 데이터 구동 표기화 모델, 문장 절분기와 사전 기반 형태 분석기를 구축했다.이 모든 것은 일련의 서로 다른 해석 모델(신경 또는 비신경, 기능이 풍부하거나 비기능, 변환 또는 도형 기반 등)에 사용되고 각 언어의 최적 조합을 선택한다.불행하게도 공유 작업 매트릭스 중의 작은 고장으로 인해 우리의 모델 선택기가 통용되고 약한 어휘화된 모델을 운행하게 되었다. 이 모델들은 의외의 언어를 위한 것이지 우리가 데이터 집합에 특정한 모델이 아니다.이 #Parsing Tragedy로 인해 우리는 정식으로 27위를 차지했고, 우리의 실제 모델은 최종적으로 비공식적으로 6위를 차지했다.', 'sw': 'Tunaweza kuwasilisha kuingia ParisNLP kwenye chama cha UD CoNLL 2017 kilichoshirikishwa. Zaidi ya mifano ya UDpipe iliyotolewa, tulijenga mifano yetu ya utoaji wa taarifa, mtangazaji wa hukumu na wachambuzi wa kimorphological anayeishi lexico. All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected.  Kwa bahati mbaya, kitendo cha Matrix kilichoshirikiana na kazi hiyo kilipelekea mteule wetu wa modeli kuendesha mifano ya kijamii, dhaifu ya lexico, iliyochukuliwa kwa lugha za kushangaza, badala ya mifano yetu maalum ya taarifa. Kwa sababu ya janga hili la #ParsingTragedy, tulipanda rangi rasmi ya 27, wakati mifano yetu ya kweli hatimaye ilipangwa rasmi ya 6.', 'tr': 'UD CoNLL 2017-nji ýylda ParisNLP girişini paylaşdyrylýan işi analyz edýäris UDpipe modellerine de ödüllendirilmiş, biz öz verilerimizi taýýarlayan tokenizaç modellerimizi, sözlem segmentçisi we leksikon tabanlı morfolojik analýzerlerimizi inşa etdik. Bularyň hemmesi farklı tansçylyk nusgalary bilen ullanýardy (neural ýa-da däl, tansçylyk baý ýa-da däl, geçişik ýa grafik tabanly ýa-da) we her dil üçin iň gowy kombinasiýa saýlandy. Gynansakda, Matrixyň paylaşyk zadynyň bir s üýtgesi biziň model s a ýlawçymyzyň döredilik, iň zayıf leksikelizat nusgalaryny çaplamak üçin guruldy, geýtgeç düzümlerniň ýerine süýtgeýän dillerimizi taýýarlapdyr. Bu #ParsingTragediýanyň sebäbi resmi ýagdaýda 27-nji dereje geçirdik, ýöne biziň hakyky nusgalarymyz soňunda 6-nji dereje diýipdir.', 'af': "Ons stel die ParisNLP inskrywing by die UD CoNLL 2017 verwerking van gedeelde taak. In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers. Alle van hierdie was gebruik met 'n omvang van verskillende verwerking modele (neurale of nie, funksie- ryk of nie, transisie of graf- gebaseer, ensfh.) en die beste kombinasie vir elke taal was gekies. Ongelukkig het 'n glitch in die gedeelde taak se Matrix ons model kieser gelei om generieke, swakkelik leksikaliseerde modele te hardloop, gegryp vir verbaastaal, in plaas van ons dataset-spesifieke modele. Omdat hierdie #ParsingTragedy, het ons offisieel 27ste rangeer, terwyl ons regte modele eindelik onoffisieel 6de rangeer.", 'am': 'በዩዲ ኮንLL 2017 የፓርሲን NLP ግንኙነት አቀረብን፡፡ ከUDpipe ሞዴላዎችን በቀር የራሳችንን ዳታ-የነፃነታችንን እና የፍርድ ግንኙነት እና የሌክሲኮን ሞሮፎሎጂ analyzerን ሠርተናል፡፡ እነዚህ ሁሉ በተለየ ልዩ መለያየት ማዘጋጀት ዓይነቶች (ባሕራዊ ወይም ባይሆን፣ ባለጠጋ ወይም ባይሆን፣ ትልፍ ወይም graph-based፣ etc) የተጠቀሙት እና ለቋንቋው ሁሉ የተሻለ ክፍል ተመረጠው። በተካፈለው ስራ ማትሪክስ የሞዴል ምርጫችንን አቅራቢያ፣ ደካማ የሊክሲካሲ ዓይነቶችን ለመፈለግ፣ ለደካማ ቋንቋዎች፣ ከዳታ-set-specific ዓይነታችን ፋንታ ለመደነቂያ ቋንቋዎች ማቅረብ ነው፡፡ ስለዚህም #ፓርsingTragedy፣ ባለሥልጣን 27 እየተደረግነው ነው፣ እውነተኛውም ሞዴላዎቻችን ግን በስድስተኛው ክፍል አልደረሰንም፡፡', 'az': "Biz ParisNLP girişini UD CoNLL 2017'də paylaşılan işləri ayırmaq üçün göstəririk. UDpipe modellərinin istifadəsində, özümüzə verilən tokenizasyon modelləri, cümlələr segmentatçısı və leksikon tabanlı morfolojik analizacıları inşa etdik. Bunların hamısı müxtəlif ayırma modelləri ilə istifadə edilmişdir (nöral, yox, fərqli, yox, keçiş, graf tabanlı, etc.) və hər dilin ən yaxşı kombinatsiyası seçildi. Necə olaraq, paylaşılmış işlərin Matrixlərin bir gözlüyü modellərimizin seçicisini generik, zəif leksikalizli modelləri idarə etdi, təəccüblü dillərə təmizlənmiş, verilən qurğumuzun müəyyən modellərimizin yerinə. Bu #ParsingTragedy sayəsində, biz resmi olaraq 27. dərəcə düzəldik, halbuki həqiqət modellərimiz sonunda olaraq 6. dərəcə düzəldik.", 'id': 'Kami memperkenalkan masukan ParisNLP di UD CoNLL 2017 menguji tugas yang sama. Selain model UDpipe yang diberikan, kami membangun model tokenisasi berdasarkan data kami sendiri, segmenter kalimat dan analiser morfologi berdasarkan lexikon. Semua ini digunakan dengan jangkauan model penghuraian yang berbeda (saraf atau tidak, kaya atau tidak, transisi atau berdasarkan grafik, dll.) dan kombinasi terbaik untuk setiap bahasa dipilih. Sayangnya, sebuah kesalahan dalam Matriks tugas berbagi memimpin pemilih model kita untuk menjalankan model yang generik, lemah, disesuaikan untuk bahasa kejutan, bukan model spesifik dataset kita. Karena #ParsingTragedy ini, kami secara resmi mendaftar ke-27, sementara model asli kami akhirnya tidak resmi mendaftar ke-6.', 'bn': 'আমরা প্যারিসএনএলপি এন্ট্রিকে ২০১৭ সালে পার্সিং শেয়ার করার কাজে উপস্থাপন করছি। ইউডিপিপ মডেল প্রদান করা ছাড়াও আমরা আমাদের নিজেদের ডাটা চালিয়ে যাচ্ছি টোনাইনজেশন মডেল, শাস্তি বিভিন্ন বিশ্লেষক এবং লেক্সিকোন এগুলো সবাই বিভিন্ন ধরনের পার্সিং মডেল দিয়ে ব্যবহার করা হয়েছে (নিউরেল অথবা না, বৈশিষ্ট্যাবলী সমৃদ্ধ অথবা না, প্রান্ত বা গ্রাফ ভিত্তিক ভিত্ত দুর্ভাগ্যবশত, শেয়ার করা কাজের ম্যাট্রিক্সের একটি গ্লিচ আমাদের মডেল নির্বাচনের নেতৃত্ব দিয়েছিলেন সাধারণ, দুর্বল লেক্সিক্সিকাল মডেল চালান এই #পার্সিংট্রেজেডির কারণে আমরা আনুষ্ঠানিকভাবে ২৭তম রান্না করেছি, কিন্তু শেষ পর্যন্ত আমাদের আসল মডেল অফিসিয়াল ভাবে ৬', 'bs': 'Predstavljamo ulaz ParisNLP na UD CoNLL 2017. analiziranje zajedničkog zadatka. Uz predviđene UDpipe modele, izgradili smo vlastite modele tokenizacije podataka, segmentera rečenica i morfološke analizatore na leksikonu. Sve ovo je korišteno sa nizom različitih modela za analizu (neuralno ili ne, bogat ili ne, prelazak ili na grafiku, itd.) i najbolja kombinacija za svaki jezik je izabrana. Nažalost, pogled u matriksu zajedničkog zadatka doveo je naš selektor model a da vodi generične, slabe leksikalizirane modele, pripremljene za jezike iznenađenja umjesto naših modela specifičnih podataka. Zbog ovog #ParsingTragedy, zvanično smo bili 27. redovi, dok naši pravi modeli konačno nisu oficijalni 6. redovi.', 'cs': 'Představujeme záznam ParisNLP na UD CoNLL 2017 parsování sdílené úlohy. Kromě poskytnutých modelů UDpipe jsme postavili vlastní datově řízené tokenizační modely, segmentátor vět a lexikonové morfologické analyzátory. Všechny tyto modely byly použity s řadou různých parsovacích modelů (neuronových nebo ne, bohatých na funkce nebo ne, přechodových nebo grafových modelů atd.) a byla vybrána nejlepší kombinace pro každý jazyk. Bohužel závada v Matrixu sdíleného úkolu vedla náš výběr modelu k spuštění obecných, slabě lexikalizovaných modelů přizpůsobených překvapivým jazykům namísto našich modelů specifických pro datovou sadu. Kvůli této #ParsingTragedy jsme oficiálně umístili sedmdesátou, zatímco naše skutečné modely nakonec neoficiálně umístily šesté.', 'sq': "Ne paraqesim hyrjen e ParisNLP në UD CoNLL 2017 duke analizuar detyrën e përbashkët. Përveç modeleve UDpipe të ofruara, ndërtuam modelet tona të tokenizimit, segmentuesit e fjalëve dhe analizuesit morfologjik të bazuar në lexikon. Të gjitha këto u përdorën me një gamë modelesh të ndryshëm analizimi (neuronal apo jo, të pasur apo jo, tranzicion apo grafik, etj.) dhe u zgjodh kombinimi më i mirë për çdo gjuhë. Unfortunately, a glitch in the shared task's Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models.  Për shkak të kësaj #ParsingTragedy, ne zyrtarisht renditëm të 27-të, ndërsa modelet tona të vërteta përfundimisht nuk renditën zyrtarisht të 6-të.", 'et': 'Tutvustame ParisNLP kirjet UD CoNLL 2017 parsimise jagatud ülesandel. Lisaks UDpipe mudelitele ehitasime välja oma andmepõhised tokeniseerimismudelid, lausesegmenteerija ja leksikonipõhised morfoloogilised analüsaatorid. Kõiki neid kasutati erinevate parsimismudelitega (neuraalsed või mitte, funktsioonilised või mitte, ülemineku- või graafikapõhised jne) ning valitud parim kombinatsioon igale keelele. Kahjuks viis tõrge jagatud ülesande maatriksis meie mudelivaliku käivitama üldised, nõrgalt leksikaliseeritud mudelid, mis on kohandatud üllatuskeeltele, mitte meie andmekogumi spetsiifiliste mudelite asemel. Selle #ParsingTragedy tõttu saime ametlikult 27. koha, samas kui meie tõelised mudelid lõpuks mitteametlikult 6. koha.', 'fi': 'Esittelemme ParisNLP-merkinnän UD CoNLL 2017 jäsentämällä jaettua tehtävää. Toimitettujen UDpipe-mallien lisäksi rakensimme omat datavetoiset tokenisaatiomallit, lausesegmentointimallit ja sanastopohjaiset morfologiset analysaattorit. Kaikkia näitä käytettiin erilaisilla jäsennysmalleilla (neuraali tai ei, ominaisuusrikas tai ei, siirtymä- tai graafipohjaiset jne.) ja valittiin kullekin kielelle paras yhdistelmä. Valitettavasti jaetun tehtävän Matrixissa ilmennyt vika johti mallivalitsijamme ajamaan yleisiä, heikosti leksikalisoituja malleja, jotka on räätälöity yllätyskieleille tietojoukkokohtaisten mallien sijaan. Tämän #ParsingTragedian ansiosta olemme virallisesti sijalla 27, kun taas todelliset mallimme lopulta epävirallisesti sijalla 6.', 'ca': "Presentam la entrada de ParisNLP a la UD CoNLL 2017 analitzant tasca compartida. A més dels models UDpipe proporcionats, vam construir els nostres propis models de tokenització basats en dades, segmentadors de frases i analitzadors morfològics basats en lexicons. Tots aquests van ser utilitzats amb una gama de diferents models d'analització (neural o no, rics o no en característiques, transició o gràfic, etc.) i va ser seleccionada la millor combinació per cada llenguatge. Malauradament, un error en la Matrix de la tasca compartida va portar al nostre selector model a executar model s genèrics, fracassament lexicalitzats, adaptats a llengües de sorpresa, en lloc de models específics del conjunt de dades. Gràcies a aquesta #ParsingTragedy, oficialment vam classificar el 27è, mentre els nostres models reals finalment no oficialment van classificar el 6è.", 'hy': "Մենք ներկայացնում ենք ՓարիզՆԼՊ-ի գրառումը UD COՆԼԼ 2017-ի ընդհանուր խնդիրների վերլուծում: Ավելին UDtube-ի մոդելներին, մենք կառուցեցինք մեր սեփական տվյալների հիմնված տոկենիզացիայի մոդելները, նախադասությունների սեգմետրերը և լեքսիկոնի հիմնված մորֆոլոգիական վերլուծումները: All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected.  Unfortunately, a glitch in the shared task's Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models.  Because of this #ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.", 'jv': 'Kita menehi kelompok kelompok Nambah nambah karo model UDpi gawe nggawe data-drived tokenizer model, seneng segmenter karo leqsik-basain modolyane Laptop" and "Desktop Lahor lah, sing paling kelas nêmên podho matriks nggawe model sing bisa ngubah model sing nyimpen generic, weakness lexêkalisé modelo, geulakno kanggo ngerasakno itédiurané idiomat hayo. Soalé hal iki', 'ha': 'Tuna halatar da matsayin Paris NLP a UD CoNLL 2017. Babu da misãlai na UDpipe wanda aka samar, mun sami misãlai masu shirya da data, segmentor da baƙaƙƙe masu fasalin mutane a kan leksikon. Wannan dukansu aka yi amfani da wasu misãlai masu yin parsewa daban (neural ko ba, mai riki ko, mai shida ko kan grafi) da aka zãɓe komai da mafi kyaun kowace lugha. Babu rabo, wani gliyi a cikin matrix wanda ke raba da shi, ya shiryar da zaɓa ɓen misalinmu don ya yi tafiyar da misãlai masu jenci, masu rauni na leksisi, an yi ƙaranci zuwa harshen mãkirci, musamman da misãlai masu daidaita. Because of this #ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.', 'he': "אנחנו מציגים את הכניסה של פריס NLP ב UD CoNLL 2017 מעבדת משימה משותפת. In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers.  כל אלה השתמשו באמצעות מגוון של דוגמנים בדיקת שונים (עצביים או לא, עשירים או לא, מעבר או מבוססים בגרף, וכל דבר) והשילוב הטוב ביותר לכל שפה נבחר. Unfortunately, a glitch in the shared task's Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models.  בגלל #ParsingTragedy זה, אנחנו רשמית הצוות 27, בעוד הדוגמנים האמיתיים שלנו סוף סוף הצוות לא רשמי 6.", 'sk': 'Vnos ParisNLP predstavljamo na UD CoNLL 2017 razčlenitve deljenega opravila. Poleg UDpipe modelov smo izdelali tudi lastne podatkovno usmerjene modele žetonizacije, segmentatorje stavkov in morfološke analizatorje na osnovi leksikona. Vsi ti so bili uporabljeni z različnimi modeli razčlenjanja (nevronski ali ne, bogati s funkcijami ali ne, prehodi ali grafični podatki itd.) in izbrana je bila najboljša kombinacija za vsak jezik. Na žalost je zaradi napake v matriki skupnega opravila naš izbirnik modelov zažgal generične, slabo leksikalizirane modele, prilagojene jezikom presenečenja, namesto modelov, specifičnih za nabor podatkov. Zaradi te #ParsingTragedije smo se uradno uvrstili na 27. mesto, medtem ko so naši pravi modeli končno neuradno uvrstili na 6. mesto.', 'bo': 'ང་ཚོས་UD CoNLL ལྟ་ཀློག་པའི་ParisNLP་ནང་འཇུག་པ་དེ་སྤྱད་ཡོད་པའི་བྱ་འགུལ་ཚོར་མིང་སྟོན་པ In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers. All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected. ཡིན་ནའང་མི་ཆེ། དེའི་རྒྱུ་མཚན་ནི་#ParsingTragedy དེ་ལས་ང་ཚོའི་ལས་འགུལ་གྱིས་ཨང་ཆེན་པོ་༡༧་པ་ཡིན།'}
{'en': 'Universal Joint Morph-Syntactic Processing : The Open University of Israel’s Submission to The CoNLL 2017 Shared Task', 'ar': 'المعالجة النحوية الشاملة المشتركة: تقديم جامعة إسرائيل المفتوحة إلى المهمة المشتركة CoNLL 2017', 'pt': 'Processamento Sintático Conjunto Universal: Apresentação da Universidade Aberta de Israel para a Tarefa Compartilhada CoNLL 2017', 'es': 'Procesamiento morfosintáctico conjunto universal: la presentación de la Universidad Abierta de Israel a la tarea compartida de CoNll 2017', 'fr': "Universal Joint Morph-Syntactic Processing\xa0: la soumission de l'Open University of Israel à la tâche partagée ConLL 2017", 'ja': "Universal Joint Morph - Syntactic Processing: The Open University of Israel 's Submission to the CoNLL 2017 Shared Task", 'zh': '通用合变形句法:以色列开大学于CoNLL 2017之共同任务', 'hi': 'यूनिवर्सल संयुक्त मॉर्फ-सिंटैक्टिक प्रोसेसिंग: द ओपन यूनिवर्सिटी ऑफ इज़राइल के CoNLL 2017 साझा कार्य के लिए प्रस्तुत करना', 'ru': 'Универсальная совместная морфо-синтаксическая обработка: подача Открытым университетом Израиля совместной задачи CoNLL 2017', 'ga': 'Próiseáil Chomhpháirteach Morph-Syntactic Uilíoch: Aighneacht Ollscoil Oscailte Iosrael chuig Tasc Comhroinnte CoNLL 2017', 'ka': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to the CoNLL 2017 Shared Task", 'el': 'Παγκόσμια Κοινή Μορφο-Συντακτική Επεξεργασία: Η Υποβολή του Ανοικτού Πανεπιστημίου του Ισραήλ στην Κοινή Εργασία', 'hu': 'Univerzális közös morf-szintaktikus feldolgozás: Az Izraeli Nyílt Egyetem alávetette magát a CoNLL 2017 megosztott feladatnak', 'it': 'Elaborazione morfo-sintattica congiunta universale: la sottomissione della Open University of Israel al compito condiviso CoNLL 2017', 'kk': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'lt': 'Universalus bendras morfinis ir sintaktinis procesas: Izraelio atvirasis universitetas pateikia 2017 m. CoNLL bendros užduoties projektą', 'mk': 'Универзалниот заеднички морф-синтактички процес: Предложувањето на Отворениот универзитет на Израел на заедничката задача CoNLL 2017', 'ms': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'ml': 'പൊതുവായ യോണ്ട് മോര്\u200dഫ്- സിന്റാക്റ്റിക് പ്രക്രിയസി: കോണ്\u200dഎല്\u200d 2017 പങ്കെടുത്ത പണി', 'mt': 'Ipproċessar Universali Konġunt Morfo-Sintattiku: Is-Sottomissjoni tal-Università Miftuħa tal-Iżrael għall-Kompitu Konġunt CoNLL 2017', 'mn': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'no': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to the CoNLL 2017 Shared Task", 'pl': 'Uniwersalne wspólne przetwarzanie morph-syntaktyczne: Otwarty Uniwersytet Izraela zgłasza się do CoNLL 2017 Wspólne Zadanie', 'ro': 'Procesarea Morph-Sintactică Comună Universală: Depunerea Universității Deschise din Israel la sarcina comună CoNLL 2017', 'sr': 'Univerzalni zajednièki morf-sintaktièki proces: Otvoren Univerzitet Izraela podmission za zajednièki zadatak CoNLL 2017.', 'si': 'ජාතික සම්බන්ධ මොර්ෆ්-සන්තැක්ටික ප්\u200dරක්\u200dරියාව: ඉස්රායේල් විශ්වාසිත්තාවේ විශ්වාසිත්තාවේ අරි', 'so': "Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'sv': "Universal Joint Morph-Syntaktic Processing: Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'ta': 'பொதுவான இணைப்பு மார்ப்- ஒத்திசைவு செயல்பாடு: கோன்எல் 2017 பகிர்ந்த பணி', 'ur': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'uz': "Umumiy Joint Morf-Syntactic Processes: The Open University of Israel's Submission to the CoNLL 2017 Sharpening Vazifa", 'vi': 'KCharselect unicode block name Lý Điều trị liên kết tại một trường đại học rộng lớn', 'bg': 'Универсална съвместна морф-синтактична обработка: Подчинението на отворения университет на Израел към споделената задача', 'da': 'Universal Joint Morph-Syntaktic Processing: Det Åbne Universitets Undergivelse til CoNLL 2017 delte Opgave', 'hr': 'Univerzalni zajednički morf-sintaktički proces: Otvoreni sveučilište Izraela podmission na zajednički zadatak CoNLL 2017.', 'nl': 'Universele gezamenlijke morph-syntactische verwerking: de inzending van de Open Universiteit van Israël aan de CoNLL 2017 Gedeelde taak', 'id': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'de': "Universal Joint Morph-Syntaktic Processing: Die Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'ko': '이스라엘 유니버설 대학이 2017년 공동으로 제출한 문법 처리 임무', 'fa': 'پروسه\u200cسازی مورف-سنتاکتیک جهانی: مسئله باز دانشگاه اسرائیل به کار مشترک CoNLL 2017', 'sw': 'Kikuu cha Joint Morph-Syntactic Process: The Open University of Israel Submission to The CoNLL 2017 Shared Task', 'tr': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'af': 'Universele Joint Morph-Syntactic Processing: Die Open Universiteit van Israel se Submission na die CoNLL 2017 Gedeelde Opdrag', 'sq': 'Universal Joint Morph-Syntactic Processing: Submission of the Open University of Israel to The CoNLL 2017 Shared Task', 'am': "የዓለማዊ Joint Morph-Syntactic Process: The Open University of Israel's Submission to the CoNLL 2017 Shared Task", 'hy': 'Իսրայելի բաց համալսարանի հանձնարարությունը', 'bn': 'বিশ্ববিদ্যালয়ের যুদ্ধ মর্ফ-সিন্ট্যাক্টিক প্রক্রিয়া: দি কনএল ২০১৭ শেয়ার করা কাজ', 'cs': 'Univerzální společné morph-syntaktické zpracování: Otevřená izraelská univerzita předložila CoNLL 2017 Sdílený úkol', 'az': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'et': 'Universaalne ühine morf-süntaktiline töötlemine: Iisraeli avatud ülikooli esitamine CoNLL 2017 ühisele ülesandele', 'bs': 'Univerzalni zajednički morf-sintaktički proces: Otvoreni univerzitet Izraela podmission na zajednički zadatak CoNLL 2017.', 'ca': "Universal Joint Morph-Syntactic Processing: La Submission de la Universitat Oberta d'Israel a The CoNLL 2017 Shared Task", 'fi': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'jv': "Universal Joint Marph-Singatik Prosissi: Open Universite of Israel's Submisi kanggo The CoNLL 1997 Joined Job", 'sk': 'Univerzalna skupna morfistična obdelava: predložitev Odprte univerze v Izraelu v skupni nalogi CoNLL 2017', 'ha': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task", 'he': 'התהליך המורף-סינטקטי המשותף היניברסלי: המשימה של האוניברסיטה הפתוחה של ישראל למשימה המשותפת של CoNLL 2017', 'bo': "Universal Joint Morph-Syntactic Processing: The Open University of Israel's Submission to The CoNLL 2017 Shared Task"}
{'en': 'We present the Open University’s submission to the CoNLL 2017 Shared Task on multilingual parsing from raw text to Universal Dependencies. The core of our system is a joint morphological disambiguator and syntactic parser which accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output. Our parser requires a lattice as input, so we generate morphological analyses of surface tokens using a data-driven morphological analyzer that derives its lexicon from the UD training corpora, and we rely on UDPipe for sentence segmentation and surface-level tokenization. We report our official macro-average LAS is 56.56. Although our model is not as performant as many others, it does not make use of neural networks, therefore we do not rely on word embeddings or any other data source other than the corpora themselves. In addition, we show the utility of a lexicon-backed morphological analyzer for the MRL Modern Hebrew. We use our results on Modern Hebrew to argue that the UD community should define a UD-compatible standard for access to lexical resources, which we argue is crucial for MRLs and low resource languages in particular.', 'ar': 'نقدم تقديم الجامعة المفتوحة إلى المهمة المشتركة لـ CoNLL 2017 حول التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. جوهر نظامنا هو أداة إزالة الغموض المورفولوجية المشتركة والمحلل النحوي الذي يقبل الرموز المميزة السطحية التي تم تحليلها شكليًا كمدخلات ويعيد أشجار التبعية غير الملتبسة شكليًا كمخرجات. يتطلب المحلل اللغوي الخاص بنا شبكة كمدخلات ، لذلك نقوم بإنشاء تحليلات مورفولوجية للرموز السطحية باستخدام محلل مورفولوجي مدفوع بالبيانات يستمد معجمه من مجموعة تدريب UD ، ونعتمد على UDPipe لتجزئة الجملة والترميز على مستوى السطح. أبلغنا أن متوسط LAS الكلي الرسمي هو 56.56. على الرغم من أن نموذجنا ليس بنفس الأداء مثل العديد من النماذج الأخرى ، إلا أنه لا يستخدم الشبكات العصبية ، لذلك لا نعتمد على تضمين الكلمات أو أي مصدر بيانات آخر غير المجموعة نفسها. بالإضافة إلى ذلك ، نعرض فائدة المحلل الصرفي المدعوم من المعجم لـ MRL العبرية الحديثة. نستخدم نتائجنا في اللغة العبرية الحديثة لنجادل في أن مجتمع UD يجب أن يحدد معيارًا متوافقًا مع UD للوصول إلى الموارد المعجمية ، والتي نجادل بأنها ضرورية لقواعد MRLs واللغات منخفضة الموارد على وجه الخصوص.', 'pt': 'Apresentamos a submissão da Open University para a CoNLL 2017 Shared Task sobre análise multilíngue de texto bruto para dependências universais. O núcleo do nosso sistema é um desambiguador morfológico conjunto e um analisador sintático que aceita tokens de superfície morfologicamente analisados como entrada e retorna árvores de dependência morfologicamente desambiguadas como saída. Nosso analisador requer uma treliça como entrada, então geramos análises morfológicas de tokens de superfície usando um analisador morfológico orientado a dados que deriva seu léxico dos corpora de treinamento UD, e contamos com UDPipe para segmentação de frases e tokenização de nível de superfície. Relatamos que nosso LAS macro médio oficial é 56,56. Embora nosso modelo não seja tão performático quanto muitos outros, ele não faz uso de redes neurais, portanto, não contamos com word embeddings ou qualquer outra fonte de dados que não os próprios corpora. Além disso, mostramos a utilidade de um analisador morfológico baseado em léxico para o hebraico moderno MRL. Usamos nossos resultados em hebraico moderno para argumentar que a comunidade UD deve definir um padrão compatível com UD para acesso a recursos lexicais, o que argumentamos ser crucial para MRLs e linguagens de baixo recurso em particular.', 'es': 'Presentamos la presentación de la Universidad Abierta a la Tarea Compartida de CoNll 2017 sobre el análisis multilingüe del texto sin procesar a las dependencias universales. El núcleo de nuestro sistema es un desambiguador morfológico conjunto y un analizador sintáctico que acepta fichas de superficie analizadas morfológicamente como entrada y devuelve árboles de dependencias morfológicamente desambiguados como salida. Nuestro analizador requiere una red como entrada, por lo que generamos análisis morfológicos de tokens de superficie utilizando un analizador morfológico basado en datos que deriva su léxico de los cuerpos de entrenamiento de UD, y confiamos en UDPipe para la segmentación de oraciones y la tokenización a nivel de superficie. Informamos que nuestro MACRO-promedio LAS oficial es de 56,56. Aunque nuestro modelo no es tan eficaz como muchos otros, no utiliza redes neuronales, por lo que no nos basamos en la incrustación de palabras ni en ninguna otra fuente de datos que no sea los propios cuerpos. Además, mostramos la utilidad de un analizador morfológico respaldado por léxico para el hebreo moderno MRL. Utilizamos nuestros resultados en Hebreo Moderno para argumentar que la comunidad de la UD debería definir un estándar compatible con la UD para el acceso a los recursos léxicos, lo que consideramos crucial para los LMR y los idiomas de bajos recursos en particular.', 'fr': "Nous présentons la soumission de l'Open University à la tâche partagée ConLL 2017 sur l'analyse multilingue du texte brut aux dépendances universelles. Le cœur de notre système est un analyseur syntaxique et désambiguïateur morphologique qui accepte les jetons de surface analysés morphologiquement comme entrée et renvoie des arbres de dépendance désambiguïsés morphologiquement en sortie. Notre analyseur nécessite un réseau en entrée. Nous générons donc des analyses morphologiques de jetons de surface à l'aide d'un analyseur morphologique piloté par les données qui dérive son lexique des corpus d'entraînement UD, et nous nous appuyons sur UDPipe pour la segmentation des phrases et la segmentation en jetons au niveau de la surface. Nous rapportons que notre moyenne macroéconomique officielle est de 56,56. Bien que notre modèle ne soit pas aussi performant que beaucoup d'autres, il n'utilise pas de réseaux neuronaux, c'est pourquoi nous ne nous appuyons pas sur les intégrations de mots ou sur toute autre source de données autre que les corpus eux-mêmes. De plus, nous montrons l'utilité d'un analyseur morphologique basé sur un lexique pour l'hébreu moderne MRL. Nous utilisons nos résultats sur l'hébreu moderne pour soutenir que la communauté UD devrait définir une norme compatible avec l'UD pour l'accès aux ressources lexicales, ce qui, selon nous, est crucial pour les LMR et les langues à faibles ressources en particulier.", 'ja': '私たちは、生テキストからユニバーサル依存関係への多言語構文解析に関するCoNLL 2017共有タスクへのオープン大学の提出物を提示します。 私たちのシステムのコアは、形態学的に分析されたサーフェストークンを入力として受け入れ、形態学的に曖昧さを解消した依存関係木を出力として返す、合同の形態学的曖昧さ解消ツールと構文解析ツールです。 当社の構文解析器は入力として格子を必要とするため、UDトレーニングコーラから派生したデータ駆動型の形態分析器を使用して表面トークンの形態分析を生成し、文のセグメンテーションと表面レベルのトークン化はUDPipeに依存しています。 公式のマクロ平均LASは56.56と報告しています。 当社のモデルは他の多くのモデルほどパフォーマンスは高くありませんが、ニューラルネットワークを利用しているわけではありません。したがって、ワード埋め込みやコーパス自体以外のデータソースには依存していません。 さらに、我々は、MRL Modern Hebrewのためのレキシコンバックの形態学的分析器の有用性を示しています。 現代ヘブライ語の結果を使用して、UDコミュニティは語彙リソースへのアクセスのためにUD互換性のある標準を定義すべきであると主張しています。これはMRL、特に低リソース言語にとって重要であると主張しています。', 'hi': 'हम CoNLL 2017 साझा कार्य के लिए ओपन यूनिवर्सिटी के सबमिशन को कच्चे पाठ से यूनिवर्सल निर्भरताओं के लिए कच्चे पाठ से बहुभाषी पार्सिंग पर प्रस्तुत करते हैं। हमारी प्रणाली का कोर एक संयुक्त रूपात्मक disambiguator और वाक्यात्मक पार्सर है जो इनपुट के रूप में रूपात्मक रूप से विश्लेषण किए गए सतह टोकन को स्वीकार करता है और आउटपुट के रूप में रूपात्मक रूप से विघटित निर्भरता पेड़ों को लौटाता है। हमारे पार्सर को इनपुट के रूप में एक जाली की आवश्यकता होती है, इसलिए हम डेटा-संचालित रूपात्मक विश्लेषक का उपयोग करके सतह टोकन के रूपात्मक विश्लेषण उत्पन्न करते हैं जो यूडी प्रशिक्षण निगम से अपने शब्दकोश को प्राप्त करता है, और हम वाक्य विभाजन और सतह-स्तर के टोकनीकरण के लिए यूडीपाइप पर भरोसा करते हैं। हम रिपोर्ट करते हैं कि हमारा आधिकारिक मैक्रो-औसत एलएएस 56.56 है। यद्यपि हमारा मॉडल कई अन्य लोगों के रूप में प्रदर्शन नहीं करता है, यह तंत्रिका नेटवर्क का उपयोग नहीं करता है, इसलिए हम शब्द एम्बेडिंग या खुद को कॉर्पोरेट के अलावा किसी अन्य डेटा स्रोत पर भरोसा नहीं करते हैं। इसके अलावा, हम एमआरएल आधुनिक हिब्रू के लिए एक शब्दकोश-समर्थित रूपात्मक विश्लेषक की उपयोगिता दिखाते हैं। हम आधुनिक हिब्रू पर अपने परिणामों का उपयोग यह तर्क देने के लिए करते हैं कि यूडी समुदाय को लेक्सिकल संसाधनों तक पहुंच के लिए एक यूडी-संगत मानक को परिभाषित करना चाहिए, जो हम तर्क देते हैं कि विशेष रूप से एमआरएल और कम संसाधन भाषाओं के लिए महत्वपूर्ण है।', 'ru': 'Мы представляем представление Открытого университета на совместную задачу CoNLL 2017 по многоязычному синтаксическому анализу от необработанного текста до универсальных зависимостей. Ядром нашей системы является совместный морфологический дезамбигуатор и синтаксический парсер, который принимает морфологически анализируемые поверхностные токены в качестве входных данных и возвращает морфологически дезамбигированные деревья зависимостей в качестве выходных данных. Наш парсер требует решетки в качестве входных данных, поэтому мы генерируем морфологические анализы поверхностных токенов с помощью морфологического анализатора, управляемого данными, который извлекает свой лексикон из обучающих корпусов UD, и мы полагаемся на UDPipe для сегментации предложений и токенизации на уровне поверхности. Мы сообщаем, что наш официальный средний МАКРОКОЭФФИЦИЕНТ LAS составляет 56,56. Хотя наша модель не так эффективна, как многие другие, она не использует нейронные сети, поэтому мы не полагаемся на вложения слов или любой другой источник данных, кроме самих корпусов. Кроме того, мы показываем полезность морфологического анализатора на основе лексикона для современного иврита MRL. Мы используем наши результаты на современном иврите, чтобы утверждать, что сообщество UD должно определить UD-совместимый стандарт для доступа к лексическим ресурсам, который, по нашему мнению, имеет решающее значение для MRL и языков с низкими ресурсами в частности.', 'zh': '言于CoNLL 2017,自始文本至通用多言解析之共同任务。 所系之心,合形态学消歧义器与句法解析器,受形态学析表以为输,而反形态学上消歧义之所恃以为输。 吾解析器须一格为输,故以数驱之形分析器以成形析之,当分析器从UD教习语料库使生其词典,而吾以UDPipe句分外。 告我官方宏观平均值LAS为56.56。 虽非他高性能,不用神经网络,故不依词嵌语料库外数据源。 此外示词典支形分析器MRL今希伯来语之实用性也。 吾以吾今希伯来语论之UD社区宜定义一与UD兼容之准以访词汇资,臣等以为于MRL、低资源言尤至重。', 'ga': 'Cuirimid aighneacht na hOllscoile Oscailte i láthair do Thasc Comhroinnte CoNLL 2017 ar pharsáil ilteangach ó bhunthéacs go Spleáchais Uilíocha. Is é croí-lár ár gcóras comh-dhíréagróir moirfeolaíoch agus parsálaí comhréire a ghlacann le comharthaí dromchla arna anailísiú go moirfeolaíoch mar ionchur agus a thugann crainn spleáchais atá dídhébhríoch de réir moirfeolaíocha ar ais mar aschur. Teastaíonn laitíse ónár bparsálaí mar ionchur, mar sin ginimid anailísí moirfeolaíocha ar chomharthaí dromchla ag baint úsáide as anailísí moirfeolaíocha faoi thiomáint sonraí a fhaigheann a fhoclóir ón gcorpas oiliúna UD, agus táimid ag brath ar UDPipe le haghaidh deighilt abairtí agus comharthaíocht leibhéal an dromchla. Tuairiscímid gurb é 56.56 ár LAS oifigiúil macra-mheánmhéide. Cé nach bhfuil ár múnla chomh feidhmiúil le go leor eile, ní bhaineann sé úsáid as líonraí néaracha, mar sin ní bhíonn muid ag brath ar leabú focal nó ar aon fhoinse sonraí eile seachas an corpora féin. Ina theannta sin, léirímid áisiúlacht anailísí moirfeolaíocha le tacaíocht fhoclóra don MRL Nua-Eabhrais. Bainimid úsáid as ár dtorthaí ar an Eabhrais Nua-Aimseartha chun a mhaíomh gur cheart don phobal UD caighdeán atá comhoiriúnach le DU a shainiú maidir le rochtain ar acmhainní foclóireachta, rud a d’áitímid atá ríthábhachtach do MRLanna agus do theangacha íseal-acmhainne go háirithe.', 'hu': 'Bemutatjuk a Nyílt Egyetem benyújtását a CoNLL 2017 Shared Task című közös feladatra a nyers szövegtől az univerzális függőségekig. Rendszerünk magja egy közös morfológiai egyértelműsítő és szintaktikus elemző, amely morfológiailag elemzett felületi tokeneket fogad el bemenetként, és morfológiailag egyértelműsített függőségi fákat adja vissza kimenetként. Az elemzőnk rácsot igényel bemenetként, ezért a felületi tokenek morfológiai elemzését egy adatvezérelt morfológiai analizátor segítségével készítjük, amely lexikonját az UD képzőcorporákból származik, és az UDPipe-re támaszkodunk a mondatszegmentációhoz és a felületi tokenizációhoz. A hivatalos makro-átlagos LAS 56,56. Bár modellünk nem olyan teljesítményes, mint sokan mások, nem használ neurális hálózatokat, ezért nem támaszkodunk szóbeágyazásokra vagy más adatforrásokra, mint maguk a corporák. Ezenkívül bemutatjuk a lexikon alapú morfológiai analizátor hasznosságát az MRL Modern Hebrew számára. A modern héber nyelvű eredményeinket arra használjuk fel, hogy az UD közösségnek UD-kompatibilis szabványt kellene meghatároznia a lexikai erőforrásokhoz való hozzáférés tekintetében, ami alapvető fontosságú az MRL-ek és az alacsony erőforrású nyelvek szempontjából.', 'el': "Παρουσιάζουμε την υποβολή του Ανοικτού Πανεπιστημίου στην Κοινή Εργασία για την πολύγλωσση ανάλυση από ακατέργαστο κείμενο σε Οικουμενικές Εξαρτήσεις. Ο πυρήνας του συστήματός μας είναι ένας κοινός μορφολογικός αποσαφηνιστής και συντακτικός αναλυτής ο οποίος δέχεται μορφολογικά αναλυμένα επιφανειακά σήματα ως εισαγωγή και επιστρέφει μορφολογικά αποσαφηνισμένα δέντρα εξάρτησης ως παραγωγή. Ο αναλυτής μας απαιτεί ένα πλέγμα ως εισαγωγή, γι' αυτό παράγουμε μορφολογικές αναλύσεις επιφανειακών σημάτων χρησιμοποιώντας έναν μορφολογικό αναλυτή που βασίζεται σε δεδομένα που αντλεί το λεξικό του από τα σώματα εκπαίδευσης και βασιζόμαστε στο για την τμηματοποίηση προτάσεων και την επισήμανση επιφανειακού επιπέδου. Αναφέρουμε ότι ο επίσημος μακρομέσος όρος LAS είναι 56.56. Αν και το μοντέλο μας δεν είναι τόσο αποτελεσματικό όσο πολλά άλλα, δεν χρησιμοποιεί νευρωνικά δίκτυα, επομένως δεν βασιζόμαστε σε ενσωμάτωση λέξεων ή σε οποιαδήποτε άλλη πηγή δεδομένων εκτός από τα ίδια τα σώματα. Επιπλέον, καταδεικνύουμε τη χρησιμότητα ενός λεξικού υποστηριζόμενου μορφολογικού αναλυτή για το ΑΟΚ Σύγχρονης Εβραϊκής. Χρησιμοποιούμε τα αποτελέσματά μας στη Σύγχρονη Εβραϊκή για να υποστηρίξουμε ότι η κοινότητα θα πρέπει να ορίσει ένα συμβατό πρότυπο για την πρόσβαση σε λεξικούς πόρους, το οποίο υποστηρίζουμε ότι είναι κρίσιμο για τα ΑΟΚ και τις γλώσσες χαμηλής περιεκτικότητας ειδικότερα.", 'ka': 'ჩვენ განხორციული სუნივერსის შემდეგ CoNLL 2017-ის გაყოფილი მრავალენგური პარასტის შესახებ მრავალენგური ტექსტიდან უნივერსალური დასახებ. ჩვენი სისტემის კონდერი არის ერთადერთი მორპოლოგიური განამბიგუატორი და სინტაქტიური პანელიზატორი, რომელიც მორპოლოგიურად ანალიზაციულად გადატანალიზებული სამყარო ტექენების შესახებ ჩვენი პანსერტორის შესაძლებელია ლატიკი, როგორც ჩემი მონაცემის მონაცემის მოპოროლოგიური ანალიზაცია, რომელიც მონაცემის მონაცემის მონაცემის ანალიზატორის გამოყენება, რომელიც მისი ლექციკონის UD განაკლებ ჩვენ ჩვენი სატუალური მაკრო-საშუალური LAS არის 56.56. მაგრამ ჩვენი მოდელი არ არის მსგავსი, როგორც მეტი სხვა, ის არ გამოყენებს ნეიროლური ქსელების გამოყენება, რადგან ჩვენ არ გვერდება სიტყვების ინტებიზაციაზე ან სხვა მონაცე დამატებით, ჩვენ მოჩვენებთ ლექსიკონის მოპოროლოგიური ანალიზატორის გამოყენება MRL მოდინარე ჰებერი. ჩვენ მოვიყენებთ ჩვენი წარმოდგენების მომდინარე ჰებერიაში, რომ UD საზოგადოება უნდა განსაზღვრება UD-სკომპორტირებული სტანდენტი, რომელიც გვაქვს, რომ MRLs და მარტივი რესურსის ენებისთ', 'it': "Presentiamo la presentazione della Open University al CoNLL 2017 Shared Task sull'analisi multilingue dal testo grezzo alle dipendenze universali. Il nucleo del nostro sistema è un disambiguatore morfologico congiunto e un parser sintattico che accetta i token superficiali analizzati morfologicamente come input e restituisce gli alberi di dipendenza morfologicamente disambiguati come output. Il nostro parser richiede un reticolo come input, quindi generiamo analisi morfologiche dei token di superficie utilizzando un analizzatore morfologico data-driven che deriva il suo lessico dai corpi di formazione UD, e ci affidiamo a UDPipe per la segmentazione delle frasi e la tokenizzazione a livello di superficie. Riportiamo che la nostra LAS macro-media ufficiale è 56,56. Anche se il nostro modello non è performante come molti altri, non fa uso di reti neurali, quindi non ci affidiamo a word embedding o a qualsiasi altra fonte di dati diversa dai corpora stessi. Inoltre, mostriamo l'utilità di un analizzatore morfologico basato sul lessico per l'MRL Modern Hebrew. Usiamo i nostri risultati su Modern Hebrew per sostenere che la comunità UD dovrebbe definire uno standard compatibile con UD per l'accesso alle risorse lessicali, che riteniamo sia cruciale per gli MRL e i linguaggi a basso contenuto di risorse in particolare.", 'kk': 'Ашық университетінің CoNLL 2017 жылы бірнеше тілді талдау үшін бірнеше мәтіннен Universal Dependencies-ге ортақтастырылған тапсырманы келтіреміз. Жүйеміздің негізгі - морфологиялық дизамбигуатор мен синтактикалық талдаушы. Бұл морфологиялық талдау таңбаларын енгізу ретінде қабылдап, морфологиялық тәуелдік ағаштарды шығыс ретінде қайтарады. Пансеріміз латицияны келтіру үшін талап етеді, сондықтан біз мәліметті UD оқыту корпорасынан лексиканы көмектесетін морфологиялық таңбаларды жасап, мәліметті сегментациялау мен поверхносттың токенизациялау үшін UDPipe-ге Біз әкімшілігіміздің макро орташа LAS 56.56 дегенді хабарлаймыз. Біздің үлгіміз басқаларға сәйкес істемейді, ол невралдық желілерді қолданбады, сондықтан біз мәліметтерді ендіру не корпорадан басқа деректер көзіне сенбейміз. Қосымша, МRL күнделік Иврит үшін лексиканды қолданатын морфологиялық анализаторының утилитасын көрсетедік. Біз кәзіргі Иврит тілінің нәтижелерімізді қолдану үшін UD компаниясы лексикалық ресурстарына қатынау үшін UD- үйлесімді стандартты анықтауға тиіс деп айту үшін қолданамыз. Бұл мәлімет МRL мен', 'lt': 'Mes pristatome atvirojo universiteto pranešimą CoNLL 2017 m. bendram uždaviniui dėl daugiakalbio analizavimo iš žaliavinio teksto į universaliąsias priklausomybes. Mūsų sistemos pagrindas yra jungtinis morfologinis disambiguatorius ir sintaksinis analizatorius, kuris priima morfologiškai analizuotus paviršiaus ženklus kaip įvestį ir grąžina morfologiškai disambiguotus priklausomybės medžius kaip išvestį. Mūsų analizatorius reikalauja užrašo kaip įvesties, taigi mes sukuriame paviršinių žymenų morfologinę analizę naudojant duomenų pagrįstą morfologinį analizatorių, kuris gauna jo leksikoną iš UD mokymo korporacijos, ir mes pasikliaujame UDPipe sakinių segmentacijai ir paviršinio lygio tokenizacijai. Mes pranešame, kad mūsų oficialus makroekonominis LAS yra 56,56. Nors mūsų model is nėra toks veiksmingas kaip daugelis kitų, jis nenaudoja nervinių tinklų, todėl mes nesitikime žodžių įterpimu ar bet kokiu kitu duomenų šaltiniu, išskyrus pačią korporą. Be to, mes parodome, kad naudingas leksikonu pagrįstas morfologinis analizatorius MRL šiuolaikiniam hebrajui. Naudojame šiuolaikinio hebrajų rezultatus argumentuojant, kad UD bendruomenė turėtų nustatyti UD suderinamą prieigos prie leksinių išteklių standartą, kuris, mūsų nuomone, yra labai svarbus DLK ir ypač mažai išteklių turinčių kalbų atžvilgiu.', 'mk': 'Го претставуваме поднесувањето на Отворениот универзитет на Соделената задача CoNLL 2017 за мултијазичко анализирање од суров текст до универзални зависности. Јадрото на нашиот систем е заеднички морфолошки раздвојувач и синтактички анализатор кој прифаќа морфолошки анализирани површини како влез и враќа морфолошки раздвојувани дрвја на зависност како излез. Нашиот анализатор бара латика како влог, па генерираме морфолошки анализи на површината со користење на податоци-управуван морфолошки анализатор кој го извлекува својот лексикон од УД тренинг корпората, и се потпираме на УДПајп за сегментација на речениците и токенизација на површината. Ние известуваме дека нашиот официјален макро-просечен ЛАС е 56,56. И покрај тоа што нашиот модел не е толку извршен како многу други, не користи нервни мрежи, затоа не се потпираме на зборови вградени или на било кој друг извор на податоци освен самиот корпора. Покрај тоа, ја покажуваме корисноста на морфолошкиот анализатор поддржан од лексикони за МРЛ Модерниот Евреин. Ние ги користиме нашите резултати за Модерниот Евреј за да тврдиме дека заедницата на УД треба да дефинира стандард компатибилен со УД за пристап до лексичките ресурси, кој тврдиме дека е клучен за МРЛ и особено за јазиците со ниски ресурси.', 'ms': 'Kami memperkenalkan penghantaran Universiti terbuka kepada Tugas Berkongsi CoNLL 2017 mengenai penghuraian berbilang bahasa dari teks mentah ke Dependensi Universal. Pusat sistem kita adalah penyahambiguator morfologik kongsi dan penghurai sintaktik yang menerima token permukaan yang dianalisis secara morfologik sebagai input dan mengembalikan pokok dependensi yang tidak disambiguasi secara morfologik sebagai output. Penghurai kami memerlukan lattice sebagai input, jadi kami menghasilkan analisis morfologik token permukaan menggunakan analisis morfologik dipandu data yang menghasilkan leksikonnya dari korpra latihan UD, dan kami bergantung pada UDPipe untuk segmentasi kalimat dan tokenisasi aras permukaan. Kami laporkan makro-rata-rata LAS rasmi kami adalah 56.56. Walaupun model kita tidak berpengaruh sebanyak yang lain, ia tidak menggunakan rangkaian saraf, oleh itu kita tidak bergantung pada penyampaian kata atau mana-mana sumber data lain selain dari korpora mereka sendiri. In addition, we show the utility of a lexicon-backed morphological analyzer for the MRL Modern Hebrew.  Kami menggunakan keputusan kami pada Hebrew Modern untuk menyangka bahawa komuniti UD patut menentukan piawai yang serasi UD untuk akses kepada sumber leksikal, yang kami menyangka adalah penting untuk MRL dan bahasa sumber rendah khususnya.', 'mt': 'Aħna nippreżentaw is-sottomissjoni tal-Università Miftuħa lill-Ħidma Konġunta CoNLL 2017 dwar l-analiżi multilingwi minn test mhux ipproċessat għal Dipendenzi Universali. Il-qalba tas-sistema tagħna hija diżambiguatur morfoloġiku konġunt u analizzatur sintetiku li jaċċetta tokens tal-wiċċ analizzati morfoloġikament bħala input u jirritorna siġar tad-dipendenza diżambiguat morfoloġikament bħala output. Il-analizzatur tagħna jeħtieġ lattika bħala input, għalhekk niġġeneraw analiżi morfoloġika ta’ tokens tal-wiċċ bl-użu ta’ analizzatur morfoloġiku mmexxi mid-dejta li jidderiva l-lexicon tiegħu mill-korpora ta’ taħriġ UD, u niddependi fuq UDPipe għas-segmentazzjoni tas-sentenzi u t-tokenizzazzjoni tal-livell tal-wiċċ. Aħna nirrappurtaw li l-LAS makro-medja uffiċjali tagħna hija 56.56. Għalkemm il-mudell tagħna mhuwiex prestanti daqs ħafna oħrajn, ma jagħmilx użu minn netwerks newrali, għaldaqstant ma nistrieħu fuq l-inkorporazzjoni tal-kliem jew kwalunkwe sors ieħor ta’ dejta għajr il-korpora nnifisha. Barra minn hekk, nuru l-utilità ta’ analizzatur morfoloġiku appoġġjat minn lexicon għall-MRL Modern Hebrew. We use our results on Modern Hebrew to argue that the UD community should define a UD-compatible standard for access to lexical resources, which we argue is crucial for MRLs and low resource languages in particular.', 'ml': 'തുറന്ന യൂണിവേഴ്സിറ്റിയില്\u200d നിന്നും വൃത്തികെട്ട വാക്കുകളില്\u200d നിന്നും യൂണിവേഴ്സിലേക്കുള്ള പാര്\u200dസിങ്ങിനെ കോണ്\u200d നമ്മുടെ സിസ്റ്റത്തിന്റെ അടിസ്ഥാനത്തിന്റെ കൂട്ടത്തിലുള്ള മൊര്\u200dഫോളജിക്കല്\u200d ഡിബിബിഗ്വേറ്റരും സിനിട്ടാക്ടിക്ക് പരാജയങ്ങളുമാണ്. അത് മോര്\u200dഫോളി നമ്മുടെ പരാജയപ്രകാരം ഇന്\u200dപുട്ടില്\u200d ഒരു ലാറ്റിക്സ് ആവശ്യമുണ്ട്, അതുകൊണ്ട് നമുക്ക് മോര്\u200dഫോളിക്കല്\u200d അടയാളങ്ങളുടെ അന്വേഷണങ്ങള്\u200d ഉണ്ടാക്കുന്നു. അതുകൊണ്ട് നമ്മുടെ ഡേറ്റാ നടത്തിയ മോര്\u200d ഞങ്ങള്\u200d നമ്മുടെ ഓഫീഷണല്\u200d മാക്രോ ശരാശരി LAS 56.56 ആണെന്ന് റിപ്പോര്\u200dട്ട് ചെയ്യുന്നു. നമ്മുടെ മോഡല്\u200d മറ്റുള്ളവരെപ്പോലെയല്ല പ്രദര്\u200dശിദ്ധനാണെങ്കിലും, അത് ന്യൂറല്\u200d നെറ്റര്\u200d നെറ്റോവര്\u200dക്കുകള്\u200d ഉപയോഗിക്കുന്നില്ല, അതുകൊണ്ട് നമു കൂടാതെ, നമ്മള്\u200d എംആര്\u200dഎല്\u200d മോഡോര്\u200dണാന്\u200d ഹീബ്രീയിന്റെ ഉപയോഗിക്കുന്ന ഒരു ലെക്സിക്കന്\u200d പിന്തുണയുള്ള മോര്\u200dഫോളിക്കല്\u200d  ഞങ്ങള്\u200d മോഡോണ്\u200d ഹെബ്രൂട്ടിലെ ഫലങ്ങള്\u200d ഉപയോഗിക്കുന്നു. യുഡി സമൂഹത്തിന് ലെക്സിക്കല്\u200d വിഭവങ്ങള്\u200dക്ക് ലഭ്യമാകുന്നതിന് യുഡി-യോഗ്യമായ ഒരു സാധാരണ നിര്\u200dണയ', 'no': 'Vi presenterer oppgåva av Opna Universiteten til CoNLL 2017 i delt oppgåve om fleirspråk tolking frå råtekst til universelle avhengighet. Kjarten av systemet vårt er eit samanlig morfologisk disambiguator og syntaktisk tolkar som godtek morfologisk analyserte overflate som inndata og returnerer morfologisk forskytta avhengighetstrær som utdata. Tolkaren vårt krev ein lattice som inndata, så vi lagar morfologiske analyser av overflate med ein morfologisk analyser som utfører leksikon frå UD- treningskorpora, og vi bruker UDPipe for setningsssegmentering og overflate-tokenisering. Vi rapporterer våre offisielle makro-gjennomsnittlige LAS er 56,56. Selv om modellen vårt er ikkje så utfører som mange andre, kan det ikkje bruka neuralnettverk, derfor er vi ikkje tilbakekalla på ordinnbygging eller andre datakjelde enn korporen seg selv. I tillegg viser vi verktøyet til ein morfologisk analyser med leksikon for MRL-moderne Hebrew. Vi bruker våre resultat på Modern Hebrew for å argumentere at UD-fellesskapen bør definera ein UD-kompatibel standard for tilgang til leksiske ressursar, som vi argumenterer er viktig for MRLs og særlig lave ressursspråk.', 'pl': 'Przedstawiamy zgłoszenie Uniwersytetu Otwartego do CoNLL 2017 Shared Task na temat wielojęzycznego parsowania tekstu surowego do uniwersalnych zależności. Rdzeń naszego systemu stanowi wspólny dyambiguator morfologiczny i parser składni, który akceptuje morfologicznie analizowane tokeny powierzchni jako wejście i zwraca morfologicznie rozproszone drzewa zależności jako wyjście. Nasz parser wymaga siatki jako wejścia, dlatego generujemy analizy morfologiczne tokenów powierzchniowych za pomocą analizatora morfologicznego opartego na danych, który czerpie swój leksykon z korpusów treningowych UD, a do segmentacji zdań i tokenizacji na poziomie powierzchni polegamy na UDPipe. Nasz oficjalny makro średni LAS wynosi 56.56. Chociaż nasz model nie jest tak wydajny jak wiele innych, nie wykorzystuje sieci neuronowych, dlatego nie polegamy na osadzeniu słów czy innych źródłach danych poza samymi korpusami. Ponadto pokazujemy użyteczność analizatora morfologicznego opartego na leksykonie dla MRL Modern Hebrew. Wykorzystujemy nasze wyniki na temat nowoczesnego hebrajskiego, aby argumentować, że społeczność UD powinna zdefiniować standard zgodny z UD dla dostępu do zasobów leksykalnych, co jest kluczowe dla NDL i języków niskich zasobów w szczególności.', 'ro': 'Prezentăm depunerea Universității Deschise la CoNLL 2017 Shared Task privind analizarea multilingvă de la text brut la Dependențe universale. Nucleul sistemului nostru este un dezambiguizator morfologic comun și un parser sintactic care acceptă jetoane de suprafață analizate morfologic ca intrare și returnează copaci de dependență dezambiguizați morfologic ca ieșire. Parserul nostru necesită o rețea ca intrare, astfel încât generăm analize morfologice ale jetoanelor de suprafață folosind un analizor morfologic bazat pe date care își derivă lexiconul din corpurile de instruire UD și ne bazăm pe UDPipe pentru segmentarea frazelor și tokenizarea la nivel de suprafață. Raportăm că LAS-ul nostru macro-mediu oficial este 56,56. Deși modelul nostru nu este la fel de performant ca multe altele, nu folosește rețele neuronale, prin urmare nu ne bazăm pe încorporări de cuvinte sau pe orice altă sursă de date, altele decât corporele înseși. În plus, arătăm utilitatea unui analizor morfologic bazat pe lexicon pentru LMR Modern Hebrew. Folosim rezultatele noastre pe limba ebraică modernă pentru a argumenta că comunitatea UD ar trebui să definească un standard compatibil UD pentru accesul la resursele lexicale, ceea ce susținem că este crucial pentru LMR și limbile cu resurse reduse, în special.', 'mn': 'Бид 2017 оны CoNLL-д нээлттэй Их Сургуульд хэдэн хэлний хуваалцааны тухай олон хэлний хуваалцааны ажлыг дэвшүүлж байна. Бидний системийн үндсэн зүйл бол морфологик эмзэг, синтактик хуваагч юм. Энэ нь морфологик шинжилгээ хийсэн гадаргуйн тэмдэгүүдийг орлуулж, морфологикийн эмзэг хамааралтай моднуудыг үр дүн болгож буй. Манай ажиллагчид латик өгөгдлийн шинжилгээ хэрэгтэй. Тиймээс бид өгөгдлийн хөдөлгөөний морфологик шинжилгээ ашиглаж, UD дасгал хөдөлгөөний корпорас лексиконыг авдаг. Мөн бид UDPipe-г өгөгдлийн хэмжээ, гадаргын хэмжээний тодорхойло Бид үндсэн макро дундаж ЛАС 56.56 гэдгийг мэднэ. Бидний загвар бусад олон хүмүүстэй адилхан үйлдвэрлэгч биш ч гэсэн, энэ нь мэдрэлийн сүлжээг ашиглахгүй. Тиймээс бид Корпора-аас өөр өөр ямар ч өгөгдлийн эх үүсвэрт итгэдэггүй. МRL Одоогийн Хеврийн Лексикон дэмждэг морфологик шинжилгээчийн хэрэглээ харуулж байна. Бид орчин үеийн Хеврийн үр дүнг ашиглаж, UD-ын нийгэмд лексикийн боловсрол дээр нэвтрүүлэх UD-тэй холбоотой стандарт тодорхойлох хэрэгтэй гэдгийг хэлдэг. Энэ нь MRL болон хамгийн бага боловсрол хэл дээр чухал гэдгийг бид', 'sr': 'Predstavljamo podnošenje otvorenog univerziteta podijeljenom zadatku CoNLL 2017 o multijezičkom analizu od sirovog teksta do univerzalnih zavisnosti. Željeznica našeg sistema je zajednički morfološki disambiguator i sintaktički analitičar koji prihvaća morfološki analizirane tokene površine kao ulaz i vraća morfološki disambiguovane drveće zavisnosti kao output. Naš analitičar zahteva lattice kao ulaz, tako da generiramo morfološke analize površinskih znakova koristeći morfološki analitičar koji vodi podatke koji proizvodi leksikon iz treninga korpore UD-a, i oslanjamo se na UDPipe za segmentaciju rečenica i tokenizaciju površine. Prijavljujemo da je naša zvanična makro-prosječna LAS 56,56. Iako naš model nije izvršen kao i mnogi drugi, ne koristi neuralne mreže, stoga se ne oslanjamo na reèi ukljuèenja ili bilo koji drugi izvor podataka osim samog korpora. Osim toga, pokazujemo korisnost morfološkog analizatora koji podržava leksikon za moderni hebrejski MRL. Koristimo svoje rezultate na modernom hebrejskom da tvrdimo da bi zajednica UD trebala definisati UD-kompatibilni standard za pristup leksičkim resursima, koji tvrdimo da je ključno za jezike MRL-a i niske resurse posebno.', 'so': 'Waxaynu soo bandhignaynaa sameynta jaamacadda furan ee CoNLL 2017 oo lagu sharciyey shaqo ku saabsan baaritaanka luuqadaha kala duduwan ee laga soo diro macluumaad raw ilaa masruufka caalamiga ah. Xirka nidaamkayagu waa qayb ka mid ah morfologi iyo syntactic Parser, kaas oo aqbala calaamada dhulka oo morphologically analyzed sida input oo kale, wuxuuna ku soo celiyaa geedo ku xiran sida midho oo kale. Pararkeena wuxuu u baahan yahay lattice sida input, sidaas daraaddeed waxaynu sameynaa baaritaanka calaamadaha surface ee morphological ah, kaas oo ka soo bixinaya leksikankiisa korporada waxbarashada UD, waxaana ku kalsoonaynaa UDPipe si aan u qeybinno iyo calaamadda dhulka-bannaanta. Waxaannu wargelinnaa waxyaabaha rasmiga ah ee LAS waa 56.56. In kastoo aan modeleenu u ahayn sida wax kale oo kale, ma isticmaalo shabakado neurada ah, sidaas darteed kuma isku hallayno hadal ka soo baxa ama wax kale oo macluumaad ah oo aan aheyn shirkadaha. Intaas waxaa dheer, waxaannu tusnaa isticmaalka sawirada asalka ah ee leksikon-dib-u-taagan qoraalka afka Cibraaniya ee MRL Modern ah. Waxaynu isticmaalnaa resultiyada Cibraaniyada Modern ah si aan ugu doodno in bulshada UD ay u yaqaano standard u eg UD oo ay u sawiraan hantida leksikada, taas oo aynu ka doodno inay muhiim u tahay luqadaha MRLs iyo luuqadaha hoose ee resourceyda.', 'sv': 'Vi presenterar Öppna universitetets bidrag till CoNLL 2017 Shared Task om flerspråkig tolkning från råtext till universella beroenden. Kärnan i vårt system är en gemensam morfologisk disambiguator och syntaktisk parser som accepterar morfologiskt analyserade yttokens som input och returnerar morfologiskt disambiguated beroende träd som output. Vår parser kräver ett gitter som indata, så vi genererar morfologiska analyser av yttokens med hjälp av en datadriven morfologisk analysator som härleder sitt lexikon från UD-träningscorpora, och vi förlitar oss på UDPipe för meningssegmentering och yttokensering. Vi rapporterar att vår officiella makro-genomsnittliga LAS är 56,56. Även om vår modell inte är lika presterande som många andra använder den inte neurala nätverk, därför förlitar vi oss inte på ordinbäddningar eller någon annan datakälla än korporarna själva. Dessutom visar vi nyttan av en lexikonbaserad morfologisk analysator för MRL modern hebreiska. Vi använder våra resultat på modern hebreiska för att argumentera för att UD-gemenskapen bör definiera en UD-kompatibel standard för tillgång till lexikala resurser, vilket vi hävdar är avgörande för MRL och språk med låga resurser i synnerhet.', 'si': 'අපි විශ්වාසිත්තාවේ අරින්දු විද්\u200dයාප්\u200dරාමාණික විද්\u200dයාප්\u200dරාමාණයට CoNLL 2017 වලින් භාෂාවික විශේෂ කරනවා කාර්ය අපේ පද්ධතියේ ප්\u200dරධානය තමයි සම්පූර්ණ විශ්ලේෂණ විශ්ලේෂණ විශ්ලේෂණ විශ්ලේෂණ කරපු ප්\u200dරධානයක් ඇතුළු විදිහට ප්\u200dර අපේ පරීක්ෂකයෙන් ලටිස් එක ඇතුළු විදියට අවශ්\u200dය වෙනවා, ඉතින් අපි මොර්ෆෝලෝජික විශ්ලේෂණයේ පුළුවන් ටොකන්ස් විශ්ලේෂකයෙන් ප්\u200dරයෝජනය කරනව අපි අපේ ප්\u200dරධානිය මැක්රෝ සාමාන්\u200dය LAS 56.56 කියලා වාර්තා කරනවා. අපේ මොඩල් විදියට අනිත් ගොඩක් විදියට වැඩ කරන්නේ නැහැ, ඒක න්\u200dයූරල් ජාලයේ ප්\u200dරයෝජනය කරන්නේ නැහැ, ඉතින් අපි වචන සම්බන්ධ විදි ඒ වගේම, අපි පෙන්වන්නේ ලෙක්සිකෝන් බැක්ස් විශ්ලේෂකයෙක්ගේ ප්\u200dරයෝජනය MRL අධ්\u200dයාත්මක හබ්\u200dරියෝ  අපි අධ්\u200dයාත්මක හිබ්\u200dරෝවියේ ප්\u200dරතිචාරයක් භාවිත කරනවා UD සමාජයේ UD-සම්බන්ධ විශ්වාස කරන්න ඕනි ලෙක්සිකල් සම්බන්ධ භාෂාවට ප', 'ta': 'நாங்கள் திறந்த கல்லூரிக்கத்திற்கு கோன்எல் 2017 பங்கிடப்பட்ட பணியை காண்பிக்கிறோம் ராவ் உரையிலிருந்து உலகளாவிய சார்புகளு எங்கள் கணினியின் மூலம் ஒரு இணைய மோர்போலிக் பிரிப்பாளர் மற்றும் ஒத்திசைவு பிரிப்பாளர் மற்றும் மோர்போலியலியலாக ஆராய்ந்த மேல் குறிகளை உள்ளீட்டாக எங்கள் பரிசுத்தம் உள்ளீட்டாக ஒரு லாட்டிக்ஸ் தேவைப்படுகிறது, எனவே நாம் தரவு செயல்படுத்தப்பட்ட மோர்போலியல் ஆராய்ச்சியை உருவாக்குகிறோம். இது UD பயிற்சி நிறுவனத்திலிருந்து லெக நாங்கள் எங்கள் அரசியல் மேக்ரோ சராசரி LAS என்பது 56.56 ஆகும். எங்கள் மாதிரி மற்றவர்களுக்கு போன்ற செயல்பாடு அல்ல, அது புதிய வலைப்பின்னல்களை பயன்படுத்த முடியாது, அதனால் நாம் வார்த்தை உள்ளிடுதல் அல்லது நிறு மேலும், நாம் எம்ஆர்எல் மாதிரி ஹீப்ரிக்கான ஒரு லெக்சிகோன் பின்புறுத்தப்பட்ட morphological analyser பயன்பாட்டை காட்டு நாம் மாதிரி ஹெப்ரியில் எங்கள் முடிவு', 'ur': 'ہم نے CoNLL 2017 کی عملکرد کے لئے اوپن یونیورسٹ کا مستقل پیش کیا ہے جو بہت سی زبان کے متن سے یونیورسٹ اعتباری تک شریک ہے۔ ہمارے سیسٹم کی کور ایک جوڑی مورپولوژیکی نامبیوٹر اور سینٹاکتیک پارچر ہے جو مورپولوژیکی طریقے سے سطح ٹوکنوں کو وارد کے طور پر تحلیل کرتا ہے اور مورپولوژیک طریقے سے نامبیوٹ اعتماد درختوں کو اپوٹٹ کے طور پر واپس ہمارے پارٹیس کے لئے لاتیس کا انتظام ضرورت ہے، تو ہم سطح ٹوکنوں کی مورپولوجی تحقیقات کے ذریعہ ایک ڈاٹ پر چلائی ہوئی مورپولوجی تحقیقات کے مطابق پیدا کرتے ہیں جو اس کا لکسون UD تطابق کورپور سے اگاتا ہے، اور ہم ویڈ پیپ پر ویڈ پیپ کے ساتھ بھرو ہم نے ہماری رسمی مکرو متوسط لاس 56.56 کی گزارش دی ہے. اگرچہ ہماری مدل بہت سے دوسروں کی طرح عمل کرنے والی نہیں ہے، یہ نئورل نیٹورک سے استعمال نہیں کرتا، تو ہم کلمات میں انڈینگ یا ان کے سوا کسی اور ڈیٹ سورج پر اعتماد نہیں کرتے۔ اور اس کے علاوہ، ہم ایک لکسیکن پشتی مارفولوژیک تحقیقات کرنے والے MRL مدرن یہودی کے لئے استعمال کریں گے۔ ہم مدرن ہبری کے نتیجے کو استعمال کرتے ہیں کہ UD کمونٹی کا ایک UD-مطابق استاندارد مقرر کرنا چاہیے لکسیکل سراسروں کے دسترسی کے لئے، جسے ہم جھگڑتے ہیں MRLs اور نیچے سراسروں کی زبانوں کے لئے ضروری ہے۔', 'uz': "Biz Ochiq Universitetga CoNLL 2017 tashkilotni ko'plab tildagi bir necha xil parsing vazifani Universal Dependentlariga qarasamiz. Tizimmizning signali bir bir necha morfologik diffaqiyator va syntactik parameter, bu orfologik analyzed jadvalning belgini kiritish deb qabul qiladi va morfologik qiymatlarini natijasida ishlatadigan daraxtga қайтаради. Biz параметрларимизга лойиқ таркиб қилиш зарур. Шундай қилиб, без маълумотлар ўтказилган morfological таҳлилни таркиб этиб, UD trening kompaniyasidan hech qanday leksisini yaratish mumkin, va maxfiy so ʻzni ajratish va surf darajasini ko'paytirish uchun UDPipга таваккал қиламиз. We report our official macro-average LAS is 56.56.  Agar biz modelmiz boshqa tarmoqlarga bajariladigan emas, bu neyrol tarmoqda ishlatilmaydi, chunki biz quyidagi soʻzlarni ishlatmaymiz yoki kompaniya bilan boshqa maʼlumot manbasiga ishlatmaymiz. Ko'pchilik, Lekson qoʻllangan morfologik analyzerning foydalanishini ko'rsatamiz MRL Modern Hebrew uchun. Biz Modern Yahudiya haqida natijalarimizni foydalanamiz, UD jamiyati leksikal rasmlariga murojaat qilish uchun UD'ga mos keladigan standardni aniqlash kerak. Biz murakkab qilamiz, MRLs va qisqa Resource Tillari uchun muhim.", 'vi': 'Chúng tôi xin giới thiệu Công việc chia s ẻ của trường đại học mở cho CLB CoNLL Buổi duyệt Chia sẻ về chế độ đọc nhiều loại từ văn bản nguyên bản cho đến các quan hệ chung. The core of our system is a join morphological dismbiguator and synatic parster which chấp morphology phân tích surface tokens as nhập và revenge morphology dismbiated dependence trees as outdẫn. Nhân viên phân tách cần một tấm lưới để nhập, nên chúng tôi tạo ra các phân tích lịch sử của các vật bản mặt bằng cách phân tích lịch sử dựa trên dữ liệu, phân tích từ ngôn ngữ đó bắt nguồn từ cơ thể huấn luyện UD, và chúng tôi dựa vào UDPipe để phân loại các bản án và hiệu hoá cấp trên. Chúng tôi báo cáo hệ thống LAS siêu phổ biến chính thức là 56.56. Mặc dù mẫu của chúng tôi không có trình độ như bao nhiêu người khác, nhưng nó không sử dụng các mạng thần kinh, nên chúng tôi không dựa vào sự nhúng tay từ ngữ hay bất kỳ nguồn dữ liệu nào khác ngoài cơ thể. Ngoài ra, chúng tôi cho thấy tiện ích của một phân tích lịch sử mặc đồ có nền di truyền cho MRL Modern Hebrew. Sử dụng kết quả của chúng ta trên chế độ chữ Do Thái hiện đại để nói rằng cộng đồng UD phải xác định một tiêu chuẩn phù hợp với UD cho việc truy cập tài nguyên từ, mà chúng ta cho rằng rất quan trọng đối với chiết khấu và đặc biệt ngôn ngữ có ít tài nguyên.', 'bg': 'Представяме представянето на отворения университет в споделената задача за многоезично анализиране от суров текст до универсални зависимости. Ядрото на нашата система е съвместен морфологичен дисамбигуатор и синтактичен анализатор, който приема морфологично анализирани повърхностни знаци като вход и връща морфологично разграничени дървета за зависимост като изход. Нашият анализатор изисква решетка като вход, така че генерираме морфологични анализи на повърхностни токени, използвайки морфологичен анализатор, задвижван от данни, който извлича лексикона си от тренировъчните корпуси и разчитаме на сегментация на изреченията и токенизация на повърхностно ниво. Докладваме, че средната ни макросредна LAS е 56.56. Въпреки че нашият модел не е толкова перфективен, колкото много други, той не използва невронни мрежи, затова ние не разчитаме на вграждането на думи или друг източник на данни, различен от самите корпуси. В допълнение, ние показваме полезността на лексиконно-базиран морфологичен анализатор за МДГОВ модерен иврит. Използваме нашите резултати за съвременен иврит, за да твърдим, че общността на СД трябва да определи стандарт, съвместим със СД за достъп до лексикални ресурси, който според нас е от решаващо значение за МДГОВ и по-специално езиците с нисък ресурс.', 'nl': "We presenteren de inzending van de Open Universiteit aan de CoNLL 2017 Shared Task over meertalig parsen van ruwe tekst naar universele afhankelijkheden. De kern van ons systeem is een gezamenlijke morfologische disambiguator en syntactische parser die morfologisch geanalyseerde oppervlaktetokens accepteert als input en morfologisch ondubbelzinnige afhankelijkheidsbomen als output retourneert. Onze parser vereist een raster als input, dus we genereren morfologische analyses van oppervlaktetokens met behulp van een data-gedreven morfologische analyzer die zijn lexicon ontleent aan de UD-trainingscorpora, en we vertrouwen op UDPipe voor zinssegmentatie en tokenisering op oppervlakteniveau. We melden dat onze officiële macro-gemiddelde LAS 56.56 is. Hoewel ons model niet zo performant is als vele andere, maakt het geen gebruik van neurale netwerken, daarom vertrouwen we niet op woord embeddings of enige andere gegevensbron anders dan de corpora zelf. Daarnaast tonen we het nut van een lexicon-ondersteunde morfologische analysator voor de MRL Modern Hebrew. We gebruiken onze resultaten op Modern Hebreeuws om te argumenteren dat de UD gemeenschap een UD-compatibele standaard moet definiëren voor toegang tot lexicale bronnen, wat volgens ons cruciaal is voor MRL's en low resource talen in het bijzonder.", 'da': "Vi præsenterer Open University's indlæg til CoNLL 2017 Shared Task om flersproget parsing fra rå tekst til universelle afhængigheder. Kernen i vores system er en fælles morfologisk disambiguator og syntaktisk fortolker, der accepterer morfologisk analyseret overflade tokens som input og returnerer morfologisk disambiguate afhængighedstræer som output. Vores parser kræver et gitter som input, så vi genererer morfologiske analyser af overflade tokens ved hjælp af en datadrevet morfologisk analysator, der stammer sit leksikon fra UD-træningskorpora, og vi er afhængige af UDPipe til sætningssegmentering og overflade-niveau tokensisering. Vi rapporterer, at vores officielle makro-gennemsnit LAS er 56,56. Selvom vores model ikke er så effektiv som mange andre, gør den ikke brug af neurale netværk, derfor er vi ikke afhængige af ord indlejringer eller nogen anden datakilde end korpora selv. Derudover viser vi nytten af en leksikon-bakket morfologisk analysator for MRL Modern Hebraic. Vi bruger vores resultater på moderne hebraisk til at argumentere for, at UD-fællesskabet bør definere en UD-kompatibel standard for adgang til leksikalske ressourcer, hvilket vi hævder er afgørende for MRL og lav ressource sprog i særdeleshed.", 'de': 'Wir präsentieren die Einreichung der Open University an die CoNLL 2017 Shared Task zum mehrsprachigen Parsen von Rohtext zu Universal Dependencies. Kern unseres Systems ist ein gemeinsamer morphologischer Disambiguator und syntaktischer Parser, der morphologisch analysierte Oberflächentoken als Input akzeptiert und morphologisch eindeutige Abhängigkeitsbäume als Output zurückgibt. Unser Parser benötigt ein Gitter als Eingabe, daher generieren wir morphologische Analysen von Oberflächentokens mit einem datengetriebenen morphologischen Analysator, der sein Lexikon aus den UD-Trainingskorpora ableitet, und wir verlassen uns auf UDPipe für Satzsegmentierung und Oberflächentokenisierung. Wir berichten, dass unser offizieller makrodurchschnittlicher LAS 56.56 beträgt. Obwohl unser Modell nicht so performant ist wie viele andere, nutzt es keine neuronalen Netze, daher verlassen wir uns nicht auf Worteinbettungen oder andere Datenquellen außer den Korpora selbst. Darüber hinaus zeigen wir den Nutzen eines lexikon-gestützten morphologischen Analysators für die MRL Modern Hebrew. Wir verwenden unsere Ergebnisse auf Modern Hebräisch, um zu argumentieren, dass die UD-Gemeinschaft einen UD-kompatiblen Standard für den Zugang zu lexikalischen Ressourcen definieren sollte, was unserer Meinung nach entscheidend für MRLs und ressourcenarme Sprachen ist.', 'id': 'Kami mempersembahkan pengiriman Universitas terbuka ke CoNLL 2017 Shared Task on multilingual parsing from raw text to Universal Dependencies. Intinya dari sistem kita adalah disambiguator morfologis kongsi dan parser sintaksi yang menerima token permukaan yang dianalisis secara morfologis sebagai input dan mengembalikan pohon dependensi yang disambiguasi secara morfologis sebagai output. Analisa kami membutuhkan lattice sebagai input, sehingga kami menghasilkan analisis morfologi token permukaan menggunakan analisir morfologi berdasarkan data yang menghasilkan leksikonnya dari korpora latihan UD, dan kami bergantung pada UDPipe untuk segmentasi kalimat dan tokenisasi tingkat permukaan. Kami melaporkan makro rata-rata LAS resmi kami adalah 56,56. Although our model is not as performant as many others, it does not make use of neural networks, therefore we do not rely on word embeddings or any other data source other than the corpora themselves.  Selain itu, kami menunjukkan utilitas dari analisir morfologi didukung lexikon untuk MRL Hebrew Modern. Kami menggunakan hasil kami pada Hebrew Modern untuk berdebat bahwa komunitas UD harus mendefinisikan standar kompatibel UD untuk akses ke sumber daya leksikal, yang kami berdebat adalah penting untuk MRL dan bahasa sumber daya rendah khususnya.', 'ko': '우리는 CoNLL 2017에 개방대학이 제출한 원본 텍스트부터 공통적으로 의존하는 다국어 해석에 대한 공유 임무를 제출했다.우리 시스템의 핵심은 형태분석의 표면표시를 입력으로 하고 형태분석의 의존트리를 출력으로 되돌려주는 연합형태소멸기와 문법분석기이다.우리의 해석기는 수정격을 입력으로 해야 하기 때문에 우리는 데이터로 구동되는 형태학 분석기를 사용하여 표면 표기의 형태학 분석을 생성한다. 이 분석기는 UD훈련 자료 라이브러리에서 어휘를 얻고 우리는 UDPipe에 의존하여 문장 분할과 표면 표기화를 한다.우리가 보고한 공식 거시적 평균 LAS는 56.56이다.비록 우리 모델의 성능은 다른 많은 모델보다 못하지만, 신경 네트워크를 사용하지 않기 때문에, 우리는 단어가 삽입되거나 어료 라이브러리 자체를 제외한 다른 데이터 원본에 의존하지 않는다.그 밖에 우리는 어휘가 지원하는 형태 분석기가 MRL 현대 히브리어에서의 응용을 보여 주었다.우리는 현대 히브리어에 대한 연구 결과를 이용하여 UD 지역사회가 어휘자원의 방문을 위해 UD와 호환되는 기준을 정의해야 한다고 주장했다. 이것은 MRL과 저자원 언어에 특히 중요하다고 생각한다.', 'sw': 'Tunaonyesha ujumbe wa Chuo Kikuu cha Open kwa ajili ya CoNLL 2017 Kusambaza kazi za wimbo wa lugha mbalimbali kutoka ujumbe mzuri wa maandishi kwenda kwa Kutegemea Ulimwengu. Msingi wa mfumo wetu ni mchanganyiko wa kimoja wa morphological na mchanganyiko wa syntactic ambao unakubali ishara za uso wa morphologically anachambuwa kama input na kurudisha miti ya kifolojia inayotegemea kama matokeo. Mchangiaji wetu anahitaji kuchanganyikiwa kama input, kwa hiyo tunatengeneza uchambuzi wa maadili wa ishara za uso kwa kutumia mchambuzi wa kinachoendeshwa na taarifa inayoleta lexico yake kutoka kwenye kampuni ya mafunzo ya UDD, na tunategemea UDPipe kwa ajili ya kutenganisha hukumu na kuonyesha kiwango cha juu cha uso. Tunatoa taarifa rasmi ya wastani wa LAS ni 56.56. Ingawa muundo wetu haupo kama mchezaji wengi, haitumii mitandao ya neura, kwa hiyo hatutegemea maneno yanayotumika au vyanzo vingine vya taarifa badala ya kampuni wenyewe. Zaidi ya hayo, tunaonyesha matumizi ya mchambuzi wa kifolojia aliyeunga mkono lexico kwa Kihebu cha Modern cha MRL. Tunatumia matokeo yetu kuhusu Kihebu cha Modern ili kusema kuwa jumuiya ya Umoja wa Mataifa inapaswa kufafanua kiwango kinachofanana na chama cha UD cha upatikanaji wa rasilimali za lexico, ambacho tunahoji ni muhimu kwa lugha za MRLs na rasilimali chini hasa.', 'tr': "Biz Aç Uniwersitetiň CoNLL 2017-nji ýylyň CoNLL aýratynyň halk dilinden Çizgi metinden Halkara Baýramlyklara bölünýän zadyny görkeýäris. Sistemimizin çekirdeği morfolojik düzenlemesi ve sintaktik tanımlayıcıdır. Morfolojik analiz yüzeysel tokenleri giriş olarak kabul eden ve morfolojik şekilde boşaltılan bağlılılık a ğaçlarını çıkış olarak geri verir. Bizim tanıtıcımız bir lattice giriş şeklinde gerek, bu yüzden yüzeysel tokenlerin morfolojik analizi kullanarak veri sürünen morfolojik analizi yaparak, UD eğitim korporasından leksikonini sağlayan ve cümle segmentasyon ve yüzeysel seviyelerin tokenizasyonuna dayanarak UDPipe'e bağlıyız. Resmi macro ortalama LAS 56.56 olduğunu bildiriyoruz. Biziň modelimiz başga birnäçe iş edip bilmeýän bolsa, bu neural şebekelerinden ullanyşýar. Şol sebäpli biz söz integrasyna we korporadan başga bir maglumatyň çeşmesine ynamýarys. Ayrıca, MRL Modern Ýühüdçe için leksikon arkasındaki morfolojik çözümlerinin kullanımını gösteririz. Modern Ýähüdçe netijelerimizi ulanýarys çünki UD jemgyýetiniň leksi çeşmelere erişmek üçin UD-yla täsirli standartlary takyklaýandygyny mübahisə etmek üçin, bu nusga MRL we iň köp çeşmeler üçin has möhüm däldir.", 'af': "Ons stel die oop Universiteit se onderskrywing aan die CoNLL 2017 deelde taak op veelvuldige verwerking van rooi teks tot universele afhanklikhede. Die kern van ons stelsel is 'n joint morfologiese ontsammingsboom en sintaktiële ontsamling wat aanvaar morfologiese analiseerde oorspronklike tokens as invoer en teruggee morfologiese ontsammingsboom as uitvoer. Ons ontleerder benodig 'n lattice as invoer, sodat ons genereer morfologiese analiserings van oorspronklike tokens met gebruik van 'n data-gedrywe morfologiese analiseerder wat sy leksikon van die UD-onderwerp afgelei het, en ons vertrou op UDPipe vir setsegmentasie en oorspronklike vlak tokenisasie. Ons rapporteer ons offisiele makro-gemiddelde LAS is 56.56. Alhoewel ons model nie so uitvoerder as baie ander is nie, maak dit nie gebruik van neurale netwerke nie, daarom vertrou ons nie op woord inbettings of enige ander data bron anders as die korpora self nie. In addition, we show the utility of a lexicon-backed morphological analyzer for the MRL Modern Hebrew. Ons gebruik ons resultate op Moderne Hebreeus om te argumenteer dat die UD-gemeenskap 'n UD-kompatibel standaard moet definieer vir toegang tot leksiese hulpbronne, wat ons argumenteer is crucial vir MRLs en lae hulpbronne tales in besonderhede.", 'sq': 'Ne paraqesim paraqitjen e Universitetit të Hapur në Detyrën e Përbashkët të CoNLL 2017 mbi analizimin shumëgjuhës nga teksti i papërdorur në Varësitë Universale. Qendra e sistemit tonë është një disimbiguator morfologjik i përbashkët dhe analizues sintaktik i cili pranon shenjat e sipërfaqes të analizuara morfologjikisht si input dhe kthen pemët e varësisë morfologjikisht të çambiguara si output. Analizatori ynë kërkon një lattice si input, kështu që ne gjenerojmë analiza morfologjike të tokens sipërfaqe duke përdorur një analizues morfologjik të udhëhequr nga të dhënat që nxjerr lexikonin e tij nga korpora e trajnimit UD, dhe ne mbështetemi në UDPipe për segmentimin e fjalëve dhe tokenizimin e nivelit sipërfaqe. Raportojmë se LAS-ja zyrtare është 56.56. Megjithëse modeli ynë nuk është aq performant sa shumë të tjerë, nuk përdoret rrjetet nervore, prandaj ne nuk mbështetemi në përfshirjen e fjalëve apo ndonjë burim tjetër të të dhënave përveç vetë korprës. Përveç kësaj, ne tregojmë përdorimin e një analizuesi morfologjik të mbështetur nga lexikoni për MRL Hebrej modern. Ne përdorim rezultatet tona në Hebrew in Modern për të argumentuar se komuniteti i UD duhet të përcaktojë një standard kompatibil me UD për qasjen e burimeve leksikale, të cilat argumentojmë se është vendimtare për MRLs dhe gjuhët e ulëta të burimeve në veçanti.', 'hr': 'Predstavljamo podatke otvorenog univerziteta podijeljenom zadatku CoNLL 2017 o multijezičkom analizu od sirovog teksta do univerzalnih ovisnosti. Zbog našeg sustava je zajednički morfološki disambiguator i sintaktički analitičar koji prihvaća morfološki analizirane znakove površine kao ulaz i vraća morfološki disambigirane drveće zavisnosti kao izlaz. Naš analitičar zahtijeva lattice kao ulaz, tako da proizvedemo morfološke analize površinskih znakova koristeći morfološki analitičar koji vodi podatke koji proizvodi leksikon iz treninga tijela UD-a i oslanjamo se na UDPipe za segmentaciju rečenica i tokenizaciju površine. Prijavljujemo da je naša zvanična makro-prosječna LAS 56,56. Iako naš model nije izvršen kao i mnogi drugi, ne koristi neuralne mreže, stoga se ne oslanjamo na riječi ugrađenje ili bilo koji drugi izvor podataka osim samog tijela. Osim toga, pokazujemo korisnost morfološkog analizatora za MRL modernog hebrejskog. Koristimo svoje rezultate na modernom hebrejskom kako bismo tvrdili da zajednica UD treba definirati standard koji odgovara UD-u za pristup leksičkim resursima, što tvrdimo da je ključno za jezike MRL-a i niske resurse posebno.', 'am': 'የክፈት ዩንቨርስቲ ከጥሩ ጽሑፍ ወደ ዓለማዊ ደጋፊዎች የክፈት የኮንஎல_2017ስራዎችን ለብልቋንቋ ማጋራት እናቀርባታለን፡፡ የስርዓታችን ውይይት የሞሮፎሎጂ አካባቢሎጂ እና የሲንተርቲክ ፓርቲ ነው፡፡ መግለጫችን የድምፅ ግንኙነት እንደሚያስፈልጋል ጥቅምት ያስፈልጋል፤ ስለዚህም የዳታ የሞሮፎሎጂ ግንኙነቶችን ከዩዲ ትምህርት ኮርፖርተር የሌክሲኮንን መግለጫ እናደርጋለን፡፡ ባለሥልጣናዊ ማክሮ-average LAS 56.56 እንደሆነ እናስታውቃለን፡፡ ምሳሌያችን እንደ ሌሎቹ ብዙዎች ቢሆን እንኳን የናውራዊ መረብ አይጠቀምም፤ ስለዚህም ከኮርፖር ራሳቸውን በቀር ቃላትን ወይም የዳታ ክፍሎች ምንንም አይታመንም፡፡ በተጨማሪም፣ ለሌክስዎን አዲስ ዕብራይስቱ የሞሮፎሎጂ አዳራቢ አካባቢውን እናሳየዋለን፡፡ አዲስ ዕብራዊ ላይ ፍሬዎቻችንን እንጠይቃለን፤ የዩዲ አካባቢ ጉዳይ የሌክሲካዊ ሀብትን ለመግኘት የዩዲ ተቃውሞ መግለጫ እንዲችል እናውቀዋለን፡፡ በተለየንም ለMRLs እና የዋና የክፍለ ዕቃ ቋንቋዎች በጣም አስቸጋሪ ነው፡፡', 'hy': 'Մենք ներկայացնում ենք բաց համալսարանի ներկայացումը 2017-ի ԿոՆԼԼ-ի համախմբված հանձնարարությանը բազմալեզու վերլուծությունից մինչև համաշխարհային կախվածություններ: Մեր համակարգի հիմնադրամը միավոր մորֆոլոգիական բացատրող և սինտակտիկ վերլուծում է, որը ընդունում է մորֆոլոգիապես վերլուծված մակերեսի նշանները որպես մուտք և վերադարձնում է մորֆոլոգիապես բացատրված կախվածության ծառերը որպես մուտք: Մեր խմբագրիչը պահանջում է լատիկ որպես ներմուծք, այնպես որ մենք ստեղծում ենք մակերևույթի նշանների մորֆոլոգիական վերլուծություններ օգտագործելով տվյալներով հիմնված մորֆոլոգիական վերլուծում, որը հանում է իր լեքսիկոնը UD-ի ուսումնասիրության կոպորատից, և մենք հույս ենք կախված UDPipe-ի նա We report our official macro-average LAS is 56.56.  Չնայած մեր մոդելը նույնքան արդյունավետ չէ, որքան շատ ուրիշները, այն չի օգտագործում նյարդային ցանցերը, ուստի մենք չենք հիմնված բառերի ներդրման կամ այլ տվյալների աղբյուրների վրա, բացի կոպորատից: Ավելին, մենք ցույց ենք տալիս լեքսիկոնի հիմնված մորֆոլոգիական վերլուծողի օգտակարությունը ՄՌԿ-ի ժամանակակից եբրայի համար: Մենք օգտագործում ենք մեր արդյունքները ժամանակակից եբրայից, որպեսզի փաստարկենք, որ UD-ի համայնքը պետք է սահմանի UD-ի համապատասխանատու ստանդարտ լեքսիկական ռեսուրսների հասանելիության համար, որը մենք փաստարկում ենք, կարևոր է ՄՌԼ-ի և հատկապես ցա', 'bn': 'আমরা উন্মুক্ত বিশ্ববিদ্যালয়ের প্রতি কনএল ২০১৭ সালের কাজ শেয়ার করেছি বিশ্ববিদ্যালয়ের পার্জিং থেকে ভালো টেক্সট থেকে  The core of our system is a joint morphological disambiguator and syntactic parser which accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output.  আমাদের বিশ্লেষকে ইনপুট হিসেবে ল্যাটিকেসের প্রয়োজন, তাই আমরা তথ্য চালিয়ে যাচ্ছি মরোফোলিক্যাল বিশ্লেষক ব্যবহার করে মোরফোলিকাল বিশ্লেষণ তৈরি করি, যা ইউডি প্রশিক্ষণ কর্পোরার ক আমরা আমাদের অফিসিয়াল ম্যাক্রো গড়ে ল্যাসের সংবাদ প্রদান করি ৫৬. যদিও আমাদের মডেল অন্যান্য অনেকের মতো প্রদর্শনকারী নয়, তবে এটা নিউরেল নেটওয়ার্ক ব্যবহার করে না, তাই আমরা কোর্পোরা নিজেদের ছাড়া কোনো তথ্য উৎস নির্ভ এছাড়াও, আমরা লেক্সিকোন-ব্যাক্তিগত মোরফোলিকাল বিশ্লেষকের ব্যবহার দেখাচ্ছি এমআরএল মোডার্ন হিব্রুর জন্য। আমরা আধুনিক হিব্রুতে আমাদের ফলাফল ব্যবহার করি যুক্তি প্রদান করি যে ইউডি সম্প্রদায় লেক্সিক্যাল সম্পদের প্রবেশের জন্য একটি ইউডি-মান্ডার নির্ধারণ করা উচিত, যা', 'az': "Biz Açıq Universitetinin 2017-ci CoNLL şəkildə çoxlu dil ayırılması haqqında çoxlu mətndən Universal Dependencilərə təklif edirik. Sistemimizin kökü bir morfolojik disambiguator və sintaktik ayırıcıdır ki, morfolojik analizi üzərin toklarını girdi kimi qəbul edir və morfolojik müvəffəqiyyət a ğaclarını çıxış kimi geri qaytarır. Bizim parçacımız bir lattice giriş kimi lazım edir, bu yüzden biz, verilən morfolojik analizəçisini UD təhsil korporasından təhsil edən bir morfolojik analizəçi vasitəsilə yaratdıq, və biz cümlələr segmentasyonu və səviyyədə tokenizasyonu üçün UDPipe'ə təvəkkül edirik. Biz resmi makro ortalama LAS 56.56 olduğunu bildiririk. Bizim modellərimiz başqa bir çox insan istifadə etməsə də, bu nöral ağlarını istifadə etməz, buna görə də biz korporadan başqa heç bir məlumat kaynağına təvəkkül etmirik. Əvvəlcə, biz MRL Modern Hebrew üçün leksikon-backed morfolojik analizacının istifadəsini göstəririk. Biz Modern a Hüdeybiyyədə sonuçlarımızı istifadə edirik ki, UD toplumunun leksik kaynaqlarına istifadə etməsi üçün UD-kompatibil standart təyin etməsi lazımdır. Bu, mübahisə edirik ki, MRL və özlərinə də düşük kaynaqlar dilləri üçün çox vacibdir.", 'fa': 'ما تحویل دانشگاه باز را به کارهای مشترک CoNLL 2017 در مورد جداکندن متن زیادی به بستگی جهانی پیشنهاد می کنیم. core of our system is a joint morphological disambiguator and syntactic parser that accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output. ویرایشگر ما به عنوان ورودی لاتیک نیاز دارد، بنابراین ما با استفاده از یک ویرایشگر مورفولوژیکی که از مرکز آموزش UD استفاده می\u200cکند، تحلیل\u200cهای مورفولوژیکی از نشانه\u200cهای سطح تولید می\u200cکنیم، و ما به UDPipe وابسته می\u200cشویم برای جدایی کردن جمله\u200cها و توکین سط ما گزارش رسمی ماکروسیع LAS 56.56 هستیم. اگرچه مدل ما به اندازه بسیاری دیگر اجرایی نیست، این از شبکه\u200cهای عصبی استفاده نمی\u200cکند، بنابراین ما به کلمه\u200cهای داخلی یا هیچ منبع دیگری جز خودشان اطمینان نمی\u200cکنیم. علاوه بر این، ما استفاده از یک تحلیل\u200cکننده مورفولوژیکی پشتیبانی به زبان\u200cشناسی برای ابریویی مدرن MRL را نشان می\u200cدهیم. ما از نتیجه\u200cهایمان در ابریشمی مدرن استفاده می\u200cکنیم تا بحث کنیم که جامعه UD باید استاندارد با UD برای دسترسی به منابع زبان\u200cهای زبان\u200cشناسی تعریف کند، که ما بحث می\u200cکنیم برای MRLs و زبان\u200cهای منابع کم مهم است.', 'bs': 'Predstavljamo podnošenje otvorenog univerziteta podijeljenom zadatku CoNLL 2017 o multijezičkom analizu od sirovog teksta do univerzalnih zavisnosti. jezgra našeg sistema je zajednički morfološki disambiguator i sintaktički analitičar koji prihvaća morfološki analizirane znakove površine kao ulaz i vraća morfološki disambiguovane drveće zavisnosti kao output. Naš analitičar zahtijeva lattice kao ulaz, tako da generiramo morfološke analize površinskih znakova koristeći morfološki analitičar koji vodi podatke koji proizvodi leksikon iz treninga tijela UD-a, i oslanjamo se na UDPipe za segmentaciju rečenica i tokenizaciju površine. Prijavljujemo da je naša zvanična makro-prosječna LAS 56,56. Iako naš model nije izvršen kao i mnogi drugi, ne koristi se neuralnih mreža, stoga se ne oslanjamo na riječi ugrađenje ili bilo koji drugi izvor podataka osim samog korpora. Osim toga, pokazujemo korisnost morfološkog analizatora koji podržava leksikon za moderni hebrejski MRL. Koristimo naše rezultate na modernom hebrejskom da tvrdimo da bi zajednica UD trebala definisati standard za pristup leksičkim resursima koji tvrdimo da je ključno za jezike MRL-a i niske resurse posebno.', 'ca': "Presentam la presentació de la Open University a la CoNLL 2017 Shared Task on multilingual parsing from raw text to Universal Dependencies. The core of our system is a joint morphological disambiguator and syntactic parser which accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output.  El nostre analitzador requereix una làctica com entrada, així que generem anàlisis morfològics de fitxes de superfície utilitzant un analitzador morfològic basat en dades que deriva el seu lexicó de la corpora d'entrenament UD, i confiem en UDPipe per segmentar frases i tokenitzar a nivell superfície. Informem que el nostre LAS macromitjà oficial és 56,56. Malgrat que el nostre model no és tan performant com molts altres, no utilitza xarxes neurals, per tant no ens confiem en les integracions de paraules o qualsevol altre font de dades que no sigui el propi corpora. A més, demostram l'utilitat d'un analitzador morfològic recolzat per a la LMR moderna hebreu. Utilitzem els nostres resultats en l'hebreu modern per argumentar que la comunitat UD hauria de definir un estàndard compatible amb UD per a l'accés a recursos lèxics, que argumentem que és crucial per a LMR i llengües de baix recursos en particular.", 'cs': 'Představujeme příspěvek Open University ke sdílenému úkolu CoNLL 2017 na vícejazyčné parsování ze surového textu do univerzálních závislostí. Jádrem našeho systému je společný morfologický disambiguator a syntaktický parser, který přijímá morfologicky analyzované povrchové tokeny jako vstup a vrací morfologicky rozšířené závislostní stromy jako výstup. Náš parser vyžaduje mřížku jako vstup, proto generujeme morfologické analýzy povrchových tokenů pomocí datově řízeného morfologického analyzátoru, který odvozuje svůj lexikon z UD tréninkových korpusů, a spoléháme na UDPipe pro segmentaci vět a tokenizaci na úrovni povrchu. Oficiální makro-průměrný LAS je 56,56. Přestože náš model není tak výkonný jako mnoho jiných, nevyužívá neuronových sítí, proto se nespoléháme na slovní vložení nebo jiný zdroj dat kromě samotných korpusů. Dále ukazujeme užitečnost lexikonového morfologického analyzátoru pro MRL moderní hebrejštinu. Naše výsledky v moderní hebrejštině používáme k tomu, abychom argumentovali, že komunita UD by měla definovat UD kompatibilní standard pro přístup k lexikálním zdrojům, což je zásadní zejména pro MLL a jazyky s nízkými zdroji.', 'et': "Esitleme avatud ülikooli esitlust CoNLL 2017 ühisele ülesandele mitmekeelse parsimise kohta toortekstist universaalsete sõltuvusteni. Meie süsteemi tuum on ühine morfoloogiline eristaja ja süntaktiline parser, mis aktsepteerib morfoloogiliselt analüüsitud pinnamärke sisendina ja tagastab morfoloogiliselt eristatud sõltuvuspuud väljundina. Meie parser vajab sisendina võrku, seega genereerime pinnamärkide morfoloogilisi analüüse, kasutades andmepõhist morfoloogilist analüsaatorit, mis tuletab selle leksikoni UD-koolituskorporastest, ning tugineme lausete segmenteerimiseks ja pinnatasandi tokeniseerimiseks UDPipe'ile. Me teatame, et meie ametlik makrokeskmine LAS on 56,56. Kuigi meie mudel ei ole nii tulemuslik kui paljud teised, ei kasuta see närvivõrke, mistõttu me ei toetu sõna manustamisele ega muudele andmeallikatele peale korpuste endi. Lisaks näitame leksikonil põhineva morfoloogilise analüsaatori kasulikkust MRL kaasaegse heebrea keele jaoks. Kasutame oma tulemusi tänapäeva heebrea keele kohta väiteks, et UD kogukond peaks määratlema UD-ga ühilduva standardi leksikaalsetele ressurssidele juurdepääsuks, mis on meie arvates jääkide piirnormide ja eelkõige vähese ressursiga keelte jaoks ülioluline.", 'fi': 'Esittelemme avoimen yliopiston esityksen CoNLL 2017 Shared Task -ohjelmaan monikielisestä jäsentämisestä raakateksistä universaaleihin riippuvuuksiin. Järjestelmämme ydin on yhteinen morfologinen erottelija ja syntaktinen jäsentäjä, joka hyväksyy morfologisesti analysoidut pintamerkit syötteenä ja palauttaa morfologisesti eritellyt riippuvuuspuut tuotoksena. Analysoijamme tarvitsee syötteenä ristikon, joten luomme pintamerkkien morfologisia analyysejä datavetoisella morfologisella analysaattorilla, joka johtaa sanaston UD-harjoituskorpusista, ja luotamme UDPipeen lausesegmentoinnissa ja pintatason tokenisoinnissa. Raportoimme virallisen makrokeskiarvomme olevan 56,56. Vaikka mallimme ei ole yhtä suorituskykyinen kuin monet muut, se ei hyödynnä neuroverkkoja, joten emme luota sanaupotuksiin tai mihinkään muuhun tietolähteeseen kuin korpusiin itse. Lisäksi näytämme sanastolla varustetun morfologisen analysaattorin hyödyllisyyttä nykyheprean MRL:ssä. Käytämme nykyhepreaa koskevia tutkimustuloksiamme väittääksemme, että UD-yhteisön olisi määriteltävä UD-yhteensopiva standardi leksikaalisten resurssien saatavuudelle, mikä on mielestämme ratkaisevan tärkeää erityisesti jäämien enimmäismäärien ja vähävaraisten kielten kannalta.', 'sk': 'Predstavljamo predstavitev Odprte univerze na CoNLL 2017 Shared Task o večjezičnem razčlenjanju iz surovega besedila do univerzalnih odvisnosti. Jedro našega sistema je skupni morfološki razčlenjevalec in sintaktični razčlenjevalec, ki sprejema morfološko analizirane površinske žetone kot vhod in vrne morfološko razčlenjena drevesa odvisnosti kot izhod. Naš razčlenjevalec zahteva mrežo kot vhod, zato generiramo morfološke analize površinskih žetonov s pomočjo podatkovno usmerjenega morfološkega analizatorja, ki izpelje svoj leksikon iz UD trening korpusov, in se zanašamo na UDPipe za segmentacijo stavkov in površinsko žetonizacijo. Poročamo, da je naš uradni makropovprečni LAS 56,56. Čeprav naš model ni tako učinkovit kot mnogi drugi, ne uporablja nevronskih omrežij, zato se ne zanašamo na besedne vdelave ali katerega koli drugega vira podatkov razen korpusov samih. Poleg tega smo prikazali uporabnost leksikonskega morfološkega analizatorja za MRL Modern Hebrew. Naše rezultate o sodobni hebrejščini uporabljamo za trditev, da bi morala skupnost UD opredeliti standard, združljiv z UD, za dostop do leksikalnih virov, za katerega menimo, da je ključnega pomena zlasti za MRL in jezike z nizkimi viri.', 'ha': "Tuna halatar da aikin University Open zuwa CoNLL 2017 The core of our system is a joint morphological disambiguator and syntactic parser which accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output.  Parser ɗin mu na ƙayyade wani littãfi kamar inputi, don haka, mu ƙiƙiro anallari na fofologi a cikin ayõyin bakwai da za'a yi amfani da wani Analysari na-da-data-run morfological wanda yake iya ƙara shi daga shirin na UD, kuma munã dõgara ga UDipe ga segmentation da ãyarin-daraja ga fuskar. Munã faɗa ma'abũcin macro-daidai Ingawa misalinmu ba ta zama mai amfani da kamar da wasu mutane ba, sai bã ya amfani da zanen neura, don haka kuma ba mu dõgara a kan maganar da ke shiga ko da wani wuri na dangani wanin da ke kamfata. Da wannan, za mu nuna amfani da wani mai analyzawa na-ƙaranci na leksikon wa Kibraanin na MRL. Tuna amfani da matsalayinMu a kan Yahũdãwa na Modern dõmin mu yi jãyayya cẽwa jamii na UD ya ƙayyade wata kima mai kamata zuwa ma'anar mutane na UD, da kuma za mu yi jãyayya yanzu ta zama muhimu ga lughan MRLs da masu ƙaranci resource.", 'he': 'אנחנו מציגים את ההעברה של האוניברסיטה הפתוחה למשימה המשותפת של CoNLL 2017 על חקירה רבת-שפותית מטקסט גרוע לתלויות universal. הליבה של המערכת שלנו היא מנתק מורפולוגי משותף ומחקר סינטאקטי שמקבל סימני פנים מופרפולוגיים כמכניסה ומחזיר עצי תלויות מופרפולוגיים מנתקים כתוצאה. המחקר שלנו דורש מעט כתוצאה, אז אנחנו יוצרים ניתוח מורפולוגי של סימני פני השטח באמצעות ניתוח מורפולוגי מונע על ידי נתונים שמוציא את הלקסיקון שלה מהגופורה של אימון UD, ואנחנו סומכים על UDPipe עבור סגמנציה משפטים ורמת השטח tokenization. We report our official macro-average LAS is 56.56.  למרות שהמודל שלנו לא מופיע כמו הרבה אחרים, הוא לא משתמש ברשתות עצביות, לכן אנחנו לא סומכים על קישור מילים או כל מקור נתונים אחר חוץ מהגופרה עצמה. בנוסף, אנו מראים את היעילות של מנתח מורפולוגי מאומן לקסיקון עבור העברית המודרנית MRL. We use our results on Modern Hebrew to argue that the UD community should define a UD-compatible standard for access to lexical resources, which we argue is crucial for MRLs and low resource languages in particular.', 'jv': 'Awakdhéwé nggawe Open Universite seneng nggawe CoNLL 1997 Gebah Taaksi kanggo kelas urip bantuan nggambar text nang Universal dependancies. The corte of the we sistem is a joint phoromphoric disabled mbigutor and textaction browser that Accepts shapelogically detected surpass token as input and returns shapelogically disabled Genjer Awak dhéwé ngerti barang resmi macro-median LAS seneng sesuk maning, limang-limang. Awak dhéwé model sing ora dadi ngono akeh liyane, dadi iki éwé iso nggunakake netwisan anyar, dadi awak dhéwé kuwi wis ana sakjane awak dhéwé, sampeyan awak dhéwé. Nambah, kita mungko alat kanggo kelsikon-baker modrolojek kanggo nganggo MRL Cebu Moderno. Awak dhéwé nggunakaé pembalkuné ning Hebrew Moderno kanggo ngerasah saben komunitas UT kudu nggawe stampen kuwi adis-kompatible kanggo akses karo perusahaan kelakos seneng nggawe gerarak bantuan kanggo MRLs karo akeh alam sing wis ana sak barêng-barêng.', 'bo': 'ང་ཚོས་CoNLL 2017 རིགས་སྤྱོད་པའི་ཆ་འཕྲིན་ཡིག་གི་དབྱེ་སྟངས་ལ་ཆ་རྩིས་ཡིག་གཟུགས་འགོད་པའི་ལྟ་བུ་བཤད་ཀྱི་ཡོད། The core of our system is a joint morphological disambiguator and syntactic parser which accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output. Our parser requires a lattice as input, so we generate morphological analyses of surface tokens using a data-driven morphological analyzer that derives its lexicon from the UD training corpora, and we rely on UDPipe for sentence segmentation and surface-level tokenization. ང་ཚོས་རང་ཉིད་ཀྱི་གཞུང་འབྲེལ་གྱི་མ་ཁོར་ཡན་སྐྱེལ་ཆེན་56རེད། ང་ཚོའི་མ་གཟུགས་རིས་གཞན་དང་འདྲ་བ་མང་པོ་ཞིག་མ་ཡིན་ནའང་དེ་སྒེར་གྱི་རྒྱུ་དངོས་ལག་ལེན་འཐབ་མེད་པས། འུ་ཅག་གིས་གཟུགས་རིས་ལྟ་བུའི་ལག་ཆ་སྟངས་ལ་རྒྱབ་སྐྱོར་གྱི་དབྱེ་ཞིབ་ཆས་ཀྱི་ལག་ཆ་སྟངས་མངོན་འཆར་ཡོད། ང་ཚོས་དུས་ཀྱི་གནད་དོན་hebreའི་ཐོག་ལས་ང་ཚོའི་རྩིས་ཐོག'}
{'en': 'A Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task', 'ar': 'نهج شبه عالمي قائم على الأنابيب للمهمة المشتركة لـ CoNLL 2017 UD', 'es': 'Un enfoque segmentado semiuniversal para la tarea compartida de CoNll 2017 UD', 'pt': 'Uma Abordagem Encadeada Semi-universal para a Tarefa Compartilhada CoNLL 2017 UD', 'fr': 'Une approche semi-universelle en pipeline de la tâche partagée ConLL 2017 UD', 'ja': 'CoNLL 2017 UD共有タスクへの半普遍的なパイプライン化されたアプローチ', 'ru': 'Полууниверсальный трубопроводный подход к общей задаче CoNLL 2017 UD', 'hi': 'CoNLL 2017 UD साझा कार्य के लिए एक अर्ध-सार्वभौमिक पाइपलाइन दृष्टिकोण', 'zh': 'CoNLL 2017 UD 共事半通用流水线法', 'ga': 'Cur Chuige Píblíne Leath-Uilíoch i leith Thasc Comhroinnte UD CoNLL 2017', 'el': 'Μια ημικαθολική προσέγγιση με αγωγούς για την κοινή εργασία CoNLL 2017 UD', 'ka': 'სამუშაო სამუშაო სამუშაო სამუშაო პარამეტრი CoNLL 2017', 'hu': 'Féluniverzális csővezetékes megközelítés a CoNLL 2017 UD megosztott feladathoz', 'lt': 'Pusuniversalus suvienodintas požiūris į 2017 m. bendros UD užduoties įgyvendinimą', 'kk': 'CoNLL 2017 UD ортақтастырылған тапсырмасының жарты-әмгілік пиплиндің жағдайына қатынау', 'it': 'Un approccio semi-universale pipelined al compito condiviso di CoNLL 2017 UD', 'mk': 'Полууниверзален пристап до заедничката задача на УД CoNLL 2017', 'ml': 'കോണ്\u200dഎല്\u200d 2017 യുഡി പങ്കെടുത്ത പണി', 'mt': 'Approċċ Semi-Universali Pipelined għall-Kompitu Konġunt tal-UD CoNLL 2017', 'mn': 'CoNLL 2017 оны UD хуваалцаагүй ажлын хагас ертөнцөд хэмжээний хүрээлэн', 'pl': 'Półuniwersalne podejście do wspólnego zadania CoNLL 2017 UD', 'ms': 'A Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task', 'ro': 'O abordare semi-universală a misiunii partajate a UD CoNLL 2017', 'si': 'කොන්ල් 2017 UD කොටස් එක්ක සම්පූර්ණික පිප්ලින්ඩ් එක්ක අවස්ථාව', 'no': 'Name', 'so': 'A Semi-universal Pipelled Approach to the CoNLL 2017 UD Shared Task', 'sv': 'En halvuniversell pipelined strategi för CoNLL 2017 UD delad uppgift', 'ta': 'A semi- universal Pipelled Approach to the CoNLL 2017 UD Shared Task', 'sr': 'Polauniverzalni pristup obavljenom zadatku CoNLL 2017.', 'ur': 'CoNLL 2017 UD Shared Task کے تقرب کی نصف-universal Pipelined Approach', 'uz': 'Semi- universal Pipelled to CoNLL 2017 UD Sharpening Vazifalar', 'vi': 'Một phương pháp chuyển ống nửa phổ biến đến Nhiệm vụ chia sẻ CodLL phần Ngực Ngực Ngực Ngực Ngực Ngực.', 'hr': 'Polauniverzalni pristup podijeljenom zadatku CoNLL 2017.', 'da': 'En semi-universel pipelined tilgang til CoNLL 2017 UD delt opgave', 'bg': 'Полууниверсален тръбопроводен подход към споделената задача на КоНЛ 2017', 'nl': 'Een semi-universele pipeline benadering van de CoNLL 2017 UD gedeelde taak', 'id': 'Sebuah Pendekatan Semi-Universal Pipelined ke Tugas Berkongsi UD CoNLL 2017', 'de': 'Ein halbuniverseller Pipelined-Ansatz für die gemeinsame Aufgabe von CoNLL 2017 UD', 'fa': 'یک دسترسی نیمه عمومی به کار مشترک UD CoNLL 2017', 'tr': 'Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task', 'sw': 'Kimataifa cha Semi-universe kilichowekwa pembezoni kwenda CoNLL 2017 UD ilishiriki kazi', 'ko': 'CoNLL 2017 UD 공유 작업의 절반 공통 흐름 방법', 'hy': 'Առաջին համընդհանուր մոտեցումը 2017 թվականի ընդհանուր UD-ի հանձնարարության համար', 'am': 'universal Pipelled to the CoNLL 2017 UD Shared Task', 'sq': 'A Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task', 'af': "'n Semi-universele Pipeline toegang tot die CoNLL 2017 UD deelde taak", 'az': 'CoNLL 2017-ci UD paylaşılan iş üçün yarı-universel Pipelined Yaxınlıq', 'bn': 'সেমি বিশ্ববিদ্যালয়ের পাইপেলিং কোনএল ২০১৭ সালের কাছে প্রবেশ করা হয়েছে।', 'ca': "Un enfocament semiuniversal a la tasca compartida de l'UD CoNLL 2017", 'cs': 'Poloviverzální potrubní přístup ke sdílenému úkolu CoNLL 2017 UD', 'et': 'Pooluniversaalne torujuhtmeline lähenemisviis CoNLL 2017 UD jagatud ülesandele', 'fi': 'Semiuniversaali putkimainen lähestymistapa CoNLL 2017 UD Shared Task -ohjelmaan', 'bs': 'Polauniverzalni pristup podijeljenom zadatku CoNLL 2017.', 'jv': 'ProgressBarUpdates', 'sk': 'Poluniverzalni cevovodni pristop k skupni nalogi CONLL 2017 UD', 'he': 'גישה חצי-אוניברסלית עם צינורות למשימה המשותפת של CONLL 2017', 'ha': 'A Semi-universal Piled Approach to the CoNLL 2017 UD Shared Tasks', 'bo': 'CoNLL 2017 UD མཉམ་སྤྱོད་པའི་བྱ་འགུལ་ལ་ཆོག་ཐལ་ཆོག་ཅན་གྱི་འགྲོ་སྐབས་'}
{'en': 'This paper presents our system submitted for the CoNLL 2017 Shared Task, Multilingual Parsing from Raw Text to Universal Dependencies. We ran the system for all languages with our own fully pipelined components without relying on re-trained baseline systems. To train the dependency parser, we used only the universal part-of-speech tags and distance between words, and applied deterministic rules to assign dependency labels. The simple and delexicalized models are suitable for cross-lingual transfer approaches and a universal language model. Experimental results show that our model performed well in some metrics and leads discussion on topics such as contribution of each component and on syntactic similarities among languages.', 'fr': "Cet article présente notre système soumis pour la tâche partagée ConLL 2017, «\xa0Multilingual Parsing from Raw Text to Universal Dependencies\xa0». Nous avons exécuté le système pour toutes les langues avec nos propres composants entièrement en pipeline, sans dépendre de systèmes de base réentraînés. Pour entraîner l'analyseur de dépendances, nous n'avons utilisé que les balises universelles de partie du discours et la distance entre les mots, et nous avons appliqué des règles déterministes pour attribuer des étiquettes de dépendance. Les modèles simples et délexicalisés conviennent aux approches de transfert multilingue et à un modèle linguistique universel. Les résultats expérimentaux montrent que notre modèle a donné de bons résultats dans certains paramètres et mène des discussions sur des sujets tels que la contribution de chaque composant et les similitudes syntaxiques entre les langues.", 'ar': 'تقدم هذه الورقة نظامنا المقدم للمهمة المشتركة لـ CoNLL 2017 ، "التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية." قمنا بتشغيل النظام لجميع اللغات بمكوناتنا الخاصة بالكامل بدون الاعتماد على أنظمة أساسية مُعاد تدريبها. لتدريب محلل التبعية ، استخدمنا فقط علامات جزء من الكلام العام والمسافة بين الكلمات ، وطبقنا القواعد الحتمية لتعيين تسميات التبعية. النماذج البسيطة وغير اللغوية مناسبة لمقاربات النقل عبر اللغات ونموذج اللغة العالمي. تُظهر النتائج التجريبية أن نموذجنا كان يؤدي أداءً جيدًا في بعض المقاييس ويقود المناقشة حول موضوعات مثل مساهمة كل مكون وأوجه التشابه النحوية بين اللغات.', 'es': 'Este documento presenta nuestro sistema presentado para la tarea compartida de CoNll 2017, «Análisis multilingüe del texto sin procesar a las dependencias universales». Ejecutamos el sistema para todos los idiomas con nuestros propios componentes totalmente canalizados sin depender de sistemas básicos reentrenados. Para entrenar el analizador de dependencias, utilizamos solo las etiquetas universales de parte del discurso y la distancia entre palabras, y aplicamos reglas deterministas para asignar etiquetas de dependencia. Los modelos simples y delicados son adecuados para enfoques de transferencia multilingüe y un modelo de lenguaje universal. Los resultados experimentales muestran que nuestro modelo tuvo un buen desempeño en algunas métricas y lidera el debate sobre temas como la contribución de cada componente y las similitudes sintácticas entre idiomas.', 'pt': 'Este artigo apresenta nosso sistema enviado para a Tarefa Compartilhada CoNLL 2017, “Multilingual Parsing from Raw Text to Universal Dependencies”. Executamos o sistema para todos os idiomas com nossos próprios componentes totalmente em pipeline, sem depender de sistemas de linha de base retreinados. Para treinar o analisador de dependência, usamos apenas as tags universais de parte do discurso e a distância entre as palavras e aplicamos regras determinísticas para atribuir rótulos de dependência. Os modelos simples e deslexicalizados são adequados para abordagens de transferência multilíngue e um modelo de linguagem universal. Resultados experimentais mostram que nosso modelo teve bom desempenho em algumas métricas e conduz a discussão em tópicos como contribuição de cada componente e semelhanças sintáticas entre linguagens.', 'hi': 'यह पेपर CoNLL 2017 साझा कार्य के लिए प्रस्तुत हमारे सिस्टम को प्रस्तुत करता है, "यूनिवर्सल निर्भरताओं के लिए कच्चे पाठ से बहुभाषी पार्सिंग। हमने फिर से प्रशिक्षित बेसलाइन सिस्टम पर भरोसा किए बिना अपने स्वयं के पूरी तरह से पाइपलाइन वाले घटकों के साथ सभी भाषाओं के लिए सिस्टम चलाया। निर्भरता पार्सर को प्रशिक्षित करने के लिए, हमने केवल सार्वभौमिक पार्ट-ऑफ-स्पीच टैग और शब्दों के बीच की दूरी का उपयोग किया, और निर्भरता लेबल असाइन करने के लिए नियतात्मक नियमों को लागू किया। सरल और delexicalized मॉडल क्रॉस-लिंगुअल ट्रांसफर दृष्टिकोण और एक सार्वभौमिक भाषा मॉडल के लिए उपयुक्त हैं। प्रयोगात्मक परिणामों से पता चलता है कि हमारे मॉडल ने कुछ मैट्रिक्स में अच्छा प्रदर्शन किया और प्रत्येक घटक के योगदान और भाषाओं के बीच वाक्यात्मक समानताओं जैसे विषयों पर चर्चा की ओर जाता है।', 'zh': '本文引我们为CoNLL 2017共享事务"从原始文本到通用靠关系的多言语解析"提交的系统。 吾以全流水线之组件为一切言行,而不赖于重练之基线。 以习为解析器,以通词性单词之间,以确定性法分依赖关系。 简去中心化者,跨语移法,通言语。 实验结果表明我形于指标,发于组件献言语语法相似性论。', 'ja': '本稿では、CoNLL 2017 Shared Task「Multilingual Parsing from Raw Text to Universal Dependencies」のために提出されたシステムを紹介します。「私たちは、再訓練されたベースラインシステムに頼ることなく、独自の完全にパイプライン化されたコンポーネントですべての言語のためのシステムを実行しました。依存関係解析器をトレーニングするために、普遍的な音声部分タグと単語間の距離のみを使用し、依存関係ラベルを割り当てるために決定論的ルールを適用しました。単純化および非複雑化されたモデルは、クロスリンガル転送アプローチおよび普遍的な言語モデルに適している。実験結果は、私たちのモデルがいくつかの指標で優れたパフォーマンスを発揮し、各コンポーネントの貢献や言語間の構文の類似性などのトピックに関する議論を導いていることを示しています。', 'ru': 'В этой статье представлена наша система, представленная для совместной задачи CoNLL 2017 «Многоязычный парсинг от необработанного текста к универсальным зависимостям.« Мы запустили систему для всех языков с нашими собственными полностью конвейерными компонентами, не полагаясь на переобученные базовые системы. Для обучения анализатора зависимостей мы использовали только универсальные теги part-of-speech и расстояние между словами, а также применяли детерминированные правила для присвоения меток зависимостей. Простые и делексикализованные модели подходят для межъязыковых подходов к переводу и универсальной языковой модели. Экспериментальные результаты показывают, что наша модель показала хорошие результаты в некоторых показателях и ведет обсуждение таких тем, как вклад каждого компонента и синтаксическое сходство между языками.', 'ga': 'Cuireann an páipéar seo i láthair ár gcóras a cuireadh isteach le haghaidh Tasc Comhroinnte CoNLL 2017, “Parsáil Ilteangach ó Théacs Amh go Spleáchas Uilíoch”. Reáchtáileamar an córas do gach teanga lenár gcomhpháirteanna lánphíblíne féin gan a bheith ag brath ar chórais bhonnlíne ath-oilte. Chun an parsálaí spleáchais a oiliúint, níor úsáideamar ach na clibeanna uilíocha cuid cainte agus an fad idir focail, agus chuireamar rialacha cinntitheacha i bhfeidhm chun lipéid spleáchais a shannadh. Tá na samhlacha simplí agus díleicseála oiriúnach do chur chuige aistrithe tras-teangacha agus do mhúnla teanga uilíoch. Léiríonn torthaí turgnamhacha gur éirigh go maith lenár múnla i roinnt méadrachta agus treoraíonn sé plé ar thopaicí ar nós cur le gach comhpháirt agus ar chosúlachtaí comhréire i measc teangacha.', 'hu': 'Ez a tanulmány bemutatja a CoNLL 2017 megosztott feladatra benyújtott rendszerünket, "Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig". Minden nyelven futtattuk a rendszert saját teljesen csővezetékes komponenseinkkel, anélkül, hogy újraképzett alaprendszerekre támaszkodnánk. A függőség-elemző képzéséhez csak az univerzális beszédrész-címkéket és a szavak közötti távolságot használtuk, és determinisztikus szabályokat alkalmaztunk a függőség-címkék hozzárendeléséhez. Az egyszerű és delexikalizált modellek alkalmasak a többnyelvű transzfer megközelítésekre és egy univerzális nyelvi modellre. A kísérleti eredmények azt mutatják, hogy modellünk jól teljesített bizonyos mérőszámokban, és olyan témákat vezet, mint például az egyes komponensek hozzájárulása és a nyelvek közötti szintaktikus hasonlóságok.', 'el': 'Η παρούσα εργασία παρουσιάζει το σύστημά μας που υποβλήθηκε για την Κοινή Εργασία "Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις". Τρέξαμε το σύστημα για όλες τις γλώσσες με τα δικά μας πλήρως σωληνωμένα συστατικά χωρίς να βασιζόμαστε σε επαναεκπαιδευμένα συστήματα βάσης. Για να εκπαιδεύσουμε τον αναλυτή εξάρτησης, χρησιμοποιήσαμε μόνο τις καθολικές ετικέτες τμήματος ομιλίας και την απόσταση μεταξύ λέξεων, και εφαρμόσαμε determinιστικούς κανόνες για την εκχώρηση ετικετών εξάρτησης. Τα απλά και αποσπασματικά μοντέλα είναι κατάλληλα για προσεγγίσεις διασυνοριακής μεταφοράς και ένα καθολικό γλωσσικό μοντέλο. Τα πειραματικά αποτελέσματα δείχνουν ότι το μοντέλο μας πέτυχε καλά σε ορισμένες μετρήσεις και οδηγεί σε συζήτηση σε θέματα όπως η συμβολή κάθε συστατικού και στις συντακτικές ομοιότητες μεταξύ των γλωσσών.', 'ka': 'ეს გვერდის ჩვენი სისტემა, რომელიც CoNLL 2017-ის გაყოფილი საქაღალდე საქაღალდე, "მრავალენგური პარამეტრების გადაწყვება ტექსტიდან უნივერსოლური განსაზღვრებისთვის ჩვენ ყველა ენების სისტემა გავაკეთეთ, რომელიც ჩვენი ყველაფერად გარგებული კომპონტენტებით გარგებული ფესტლინის სისტემაში დავიწყებთ. ჩვენ მხოლოდ სიტყვების უნივერსალური ნაწილი და განსხვავებული სიტყვების განსხვავებაში გამოყენეთ განსხვავებული წესები და განსხვავებული განსხვავებული განსხვავებული წესები დავყენ მარტივი და დელექსიკოლიზური მოდელები შესაძლებელია მრავალური ტრანსტრესტის მიღებებისთვის და უნივერსალური ენის მოდელზე. ექსპერიმენტიური შედეგები აჩვენებს, რომ ჩვენი მოდელი კარგი გავაკეთებულია ზოგიერთი მეტრიკაში და გავაკეთება ტემებზე, როგორც ყოველ კომპონენტების დამატებული და სინტაქ', 'it': "Questo articolo presenta il nostro sistema presentato per l'attività condivisa CoNLL 2017, 'Analisi multilingue dal testo grezzo alle dipendenze universali.' Abbiamo eseguito il sistema per tutte le lingue con i nostri componenti completamente pipelined senza affidarci a sistemi di base ri-addestrati. Per addestrare il parser di dipendenze, abbiamo usato solo i tag universali part-of-speech e la distanza tra le parole, e abbiamo applicato regole deterministiche per assegnare etichette di dipendenza. I modelli semplici e delessicalizzati sono adatti per approcci di trasferimento multilingue e un modello linguistico universale. I risultati sperimentali mostrano che il nostro modello ha funzionato bene in alcune metriche e conduce discussioni su argomenti come il contributo di ogni componente e sulle somiglianze sintattiche tra le lingue.", 'kk': 'Бұл қағаз біздің жүйемізді CoNLL 2017 ортақ тапсырмасына жіберілген тапсырманы "Көптілік талдау мәтіннен Universal Dependencies" деп көрсетеді. Біз бүкіл тілдердің жүйесін қайта оқылған негізгі жүйелерде қайта оқылмай тұрған компоненттерімізмен орындадық. Тәуелсіздік талдаушысын оқыту үшін, біз тек сөздер арасындағы әлемдік бөлігін мен қашықтығын қолданып, тәуелсіздік жарлықтарын таңдау үшін deterministic ережелерді қолдандық. Қарапайым және делегсикалық үлгілер көптілікті аудару жағдайларына және әмбелік тіл үлгісі үшін жақсы. Эксперименталдық нәтижелері біздің моделіміз кейбір метрикалықта жақсы орындалды және әрбір компонент және тілдер арасындағы синтактикалық ұқсастықтарды талқылады.', 'lt': 'Šiame dokumente pristatoma mūsų sistema, pateikta 2017 m. bendros CoNLL užduoties „Daugiakalbis žaliavinio teksto analizavimas visuotinėms priklausomybėms“. We ran the system for all languages with our own fully pipelined components without relying on re-trained baseline systems.  Siekdami apmokyti priklausomybės analizatorių, mes naudojome tik universaliąsias kalbos dalis ir atstumą tarp žodžių, ir taikėme deterministines taisykles priklausomybės etiketėms priskirti. Paprasti ir deleksilizuoti modeliai yra tinkami tarpkalbiniams perdavimo metodams ir universaliam kalbų modeliui. Experimental results show that our model performed well in some metrics and leads discussion on topics such as contribution of each component and on syntactic similarities among languages.', 'mk': "This paper presents our system submitted for the CoNLL 2017 Shared Task, 'Multilingual Parsing from Raw Text to Universal Dependencies.'  Го управувавме системот за сите јазици со нашите компоненти кои се целосно вклучени без да се потпираат на реобучени основни системи. За да го тренираме анализаторот на зависноста, ги користевме само универзалните ознаки на делот од говорот и растојанието меѓу зборовите, и применетите децентристички правила за додавање ознаки на зависноста. Простите и делексикализираните модели се соодветни за крстојазични пристапи на трансфер и универзален јазички модел. Експерименталните резултати покажуваат дека нашиот модел успеа добро во некои метрики и води дискусија за теми како што е придонесот на секој компонент и за синтактичките сличности меѓу јазиците.", 'mn': 'Энэ цаас бидний системийг 2017 оны CoNLL-ийн хуваалтын ажлын хувьд "Ороо текстээс олон хэлний шинжилгээ олон хэлний хамааралтай байдлыг илэрхийлж байна" гэдэг. Бид бүх хэлний системийг дахин сургалтын суурь тогтолцоонд итгэлгүйгээр өөрсдийн бүрэн хоолойны компонентүүдтэй ажиллаж байсан. Харин хамааралтай хуваалцагчийг суралцахын тулд бид зөвхөн универсал ярианы хэсгийг, үгний хоорондын зай ашиглаж, хамааралтай тэмдэгтийг тайлбарлахын тулд deterministic дүрмийг хэрэглэсэн. Хэдхэн хэл шилжүүлэх арга барилга болон универсал хэл загварын хувьд энгийн, хувьсгал загварууд нь зөв. Эмчилгээний үр дүнд бидний загвар зарим метрик дээр сайн үйлдвэрлэж, хэлний хоорондын нэгдэл болон синтактикийн төстэй тэнцүү байдлын тухай ярилцлага гаргадаг.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങളുടെ സിസ്റ്റത്തെ കോണ്\u200dഎല്\u200d 2017 പങ്കെടുത്ത പണിയിലേക്ക് സമ്മതിപ്പിച്ചിരിക്കുന്നു "റൂ ലെക്സ്റ്റില്\u200d  എല്ലാ ഭാഷകള്\u200dക്കും വേണ്ടി നമ്മുടെ സ്വന്തം പിപ്പെല്ലിന്\u200d പൂര്\u200dണ്ണമായ ഘടകങ്ങള്\u200d കൊണ്ട് സിസ്റ്റം നടത്തിയിരിക ആശ്രയിക്കുന്നതിനുള്ള പ്രദര്\u200dശിപ്പിക്കാന്\u200d, വാക്കുകള്\u200dക്കിടയിലെ പൊതുവായി സംസാരിക്കുന്ന ടാഗുകളും ദൂരെയും മാത്രം ഞങ്ങള്\u200d ഉപയോഗ എളുപ്പമുള്ള പ്രധാനപ്പെടുത്തിയ മോഡലുകള്\u200d ക്രിവ്ലാങ്കില്\u200d മാറ്റുന്ന വഴികള്\u200dക്കും പ്രപഞ്ച ഭാഷ മോഡലുകള്\u200dക പരീക്ഷണ ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ മോഡല്\u200d ചില മെറ്റിക്കളില്\u200d നന്നായി പ്രവര്\u200dത്തിച്ചുകൊണ്ടിരിക്കുന്നു എന്നും, ഓര', 'mt': "Dan id-dokument jippreżenta s-sistema tagħna ppreżentata għall-Kompitu Konġunt CoNLL 2017, 'Parsing Multilingual from Raw Text to Universal Dependencies.' We ran the system for all languages with our own fully pipelined components without relying on re-trained baseline systems.  Biex inħarrġu l-analizzatur tad-dipendenza, użajna biss it-tikketti universali tal-parti tad-diskors u d-distanza bejn il-kliem, u applikajna regoli determinattivi biex jassenjaw it-tikketti tad-dipendenza. Il-mudelli sempliċi u delissikalizzati huma adattati għal approċċi ta’ trasferiment translingwi u mudell ta’ lingwa universali. Riżultati esperimentali juru li l-mudell tagħna sar tajjeb f’xi metriċi u jwassal għal diskussjoni dwar suġġetti bħall-kontribuzzjoni ta’ kull komponent u dwar similaritajiet sintetiċi fost il-lingwi.", 'ms': "Kertas ini memperkenalkan sistem kami dihantar untuk Tugas Berkongsi CoNLL 2017, 'Penghuraian Berbahasa Dari Teks Raw ke Dependensi Universal.' Kami menjalankan sistem untuk semua bahasa dengan komponen kami yang terpasang secara penuh tanpa bergantung pada sistem asas dilatih semula. Untuk melatih penghurai dependensi, kami hanya menggunakan tag bahagian-dari-ucapan universal dan jarak antara perkataan, dan peraturan penentuan yang dilaksanakan untuk menyerahkan label dependensi. Model sederhana dan diselesaikan adalah sesuai untuk pendekatan pemindahan saling bahasa dan model bahasa universal. Hasil percubaan menunjukkan bahawa model kami berjaya dengan baik dalam beberapa metrik dan memimpin perbincangan mengenai topik seperti kontribusi setiap komponen dan tentang persamaan sintaktik di antara bahasa.", 'no': 'Denne papiret viser systemet vårt som er sendt til CoNLL 2017 delt oppgåve, «fleirspråk tolking frå råtekst til universelle avhengighet». Vi køyrde systemet for alle språk med våre eige fullstendige røyd-komponentar utan å køyre på reintrengte grunnlinjesystemet. For å trenja avhengighetstolkaren, brukte vi berre den universele delen av taletaggane og avstanden mellom ord, og brukte deterministiske reglane for å tilordna avhengighetsmerkelappen. Den enkle og deleksiserte modellen er passande for tilnærmingar med krysspråk og ein universell språk-modell. Eksperimentale resultat viser at modellen vårt utført godt i noen metriske måtar og fører diskusjon på emner som bidrag av kvar komponent og på syntaktiske likningar mellom språk.', 'ro': "Această lucrare prezintă sistemul nostru prezentat pentru CoNLL 2017 Shared Task, 'Parsing Multilingv from Raw Text to Universal Dependents.' Am rulat sistemul pentru toate limbile cu propriile noastre componente complet pipelined fără a ne baza pe sisteme de bază re-instruite. Pentru a instrui parserul de dependență, am folosit numai etichetele universale part-of-speech și distanța dintre cuvinte și am aplicat reguli deterministe pentru a atribui etichete de dependență. Modelele simple și delexicalizate sunt potrivite pentru abordările translingvistice și un model lingvistic universal. Rezultatele experimentale arată că modelul nostru a performat bine în unele metrici și conduce discuții pe teme precum contribuția fiecărei componente și similaritățile sintactice dintre limbi.", 'pl': 'W niniejszym artykule przedstawiono nasz system zgłoszony do wspólnego zadania CoNLL 2017 – "Wielojęzyczna analiza tekstu surowego do uniwersalnych zależności". Uruchomiliśmy system dla wszystkich języków z naszymi własnymi komponentami w pełni rurociągowymi bez polegania na ponownie przeszkolonych systemach bazowych. Aby trenować parser zależności, użyliśmy tylko uniwersalnych tagów części mowy i odległości między słowami oraz zastosowaliśmy reguły deterministyczne do przypisywania etykiet zależności. Proste i deleksykalizowane modele nadają się do podejść transferowych między językami i uniwersalnego modelu językowego. Wyniki eksperymentalne pokazują, że nasz model sprawdził się dobrze w niektórych wskaźnikach i prowadzi dyskusję na tematy takie jak wkład każdego składnika i podobieństwa składni między językami.', 'si': "මේ පැත්තේ අපේ පද්ධතිය CoNLL 2017 වැදගත් කාර්යය සඳහා පෙන්වන්න පුළුවන් විදිහට තියෙන්නේ, 'වැදිලි පාළුවන් වලින් විශ අපි සියළු භාෂාවට පද්ධතිය පරීක්ෂණය කරන්නේ අපේ සියළු පායිප්ලින්ඩ් කොටස් එක්ක, ආයෙත් ප්\u200dරශ්නය කරල අපි විශේෂතාවක් විශේෂ කරගන්න, වාර්තාවක් අතර ප්\u200dරතිශේෂතාවක් සහ අතර ප්\u200dරතිශේෂතාවක් විතරයි භාවිත කරනවා, සහ සාමාන්\u200dය හා ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට සහ ජාතික පරීක්ෂණාත්මක ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ මොඩල් හොඳ විදියට ප්\u200dරතිචාරයක් විදියට කරනවා ඒ වගේම ප්\u200dරතිචාරයක් ව", 'sr': 'Ovaj papir predstavlja naš sistem podignut za zajednièki zadatak CoNLL 2017, "Multilingual Parsing from Raw Text to Universal Dependencies". Provjerili smo sistem za sve jezike sa svojim komponentima potpuno cijeviranim bez oslanjanja na ponovno obučene osnovne sisteme. Da bi obučili analizatora zavisnosti, koristili smo samo univerzalne oznake govora i udaljenost između riječi, i primjenjivali determinističke pravila za dodavanje etiketa zavisnosti. Jednostavni i deleksikalizirani modeli su odgovarajući za pristupe preko jezika i univerzalni jezički model. Eksperimentalni rezultati pokazuju da je naš model dobro proveo u nekim metrikama i vodi diskusiju o temama poput doprinosa svake komponente i o sintaktičnim sličnostima među jezicima.', 'ta': 'இந்த காகிதத்தில் கோன்எல் 2017 பங்கிடப்பட்ட பணி நாங்கள் மீண்டும் பயிற்சி முறைமைகளை நம்பாமல் அனைத்து மொழிகளுக்கும் கணினியை இயக்கினோம். சார்பு பகுதியை பயிற்சி செய்ய, வார்த்தைகளுக்கும் இடையேயும் பேச்சு ஒட்டுகளுக்கும் பொதுவான ஒட்டுகளுக்கும் இடையே எளிய மற்றும் பிரிவுசெய்யப்பட்ட மாதிரிகள் பல மொழி மாற்றும் முறைமைகளுக்கும் பொருத்தமானது மற்றும் ஒரு பொதுவ முயற்சி முடிவுகள் சில மெட்ரிக்களில் எங்கள் மாதிரி நன்றாக செயல்பட்டுள்ளது மற்றும் ஒவ்வொரு பொருளின் பங்கு மற்றும் மொழிகளில் ஒத்தி', 'sv': 'Denna uppsats presenterar vårt system som lämnats in för CoNLL 2017 Shared Task, "Flerspråkig tolkning från råtext till universella beroende". Vi körde systemet för alla språk med våra egna helt rörbundna komponenter utan att förlita oss på omdrännade baslinjesystem. För att utbilda beroendetolkaren använde vi bara de universella delar av tal taggarna och avståndet mellan ord, och tillämpade deterministiska regler för att tilldela beroendeetiketter. De enkla och delexikaliserade modellerna lämpar sig för tvärspråkliga överföringsmetoder och en universell språkmodell. Experimentella resultat visar att vår modell presterade bra i vissa mått och leder diskussion om ämnen som bidrag av varje komponent och om syntaktiska likheter mellan språk.', 'ur': "This paper presents our system submitted for the CoNLL 2017 Shared Task, 'Multilingual Parsing from Raw Text to Universal Dependencies'. ہم نے تمام زبانوں کے لئے سیسٹم کو اپنے پورے پورے پیپ لائن کی رشتہ داروں کے ساتھ دوبارہ تطالب کیے بیس لائن سیسٹم پر بھروسہ نہیں کیا۔ ہم نے صرف کلام کے اعتباری ٹاگ اور کلمات کے درمیان دور کو استعمال کیا تھا، اور اعتباری لابلوں کو مقرر کرنے کے لئے تصدیق کرنے والی قوانین کو استعمال کیا تھا. سادھے اور ڈیلسکسیکسیکسیکسیزی موڈل کرسی زبان ترنسیس کے لئے مناسب ہیں اور ایک واحد زبان موڈل کے لئے مناسب ہیں. Experimental results show that our model performed well in some metrics and led discussion on topics such as contribution of each component and on syntactic similarities among languages.", 'so': 'Kanu wuxuu soo bandhigaa nidaamka loo soo dhiibay shaqada la sharciyey CoNLL 2017, Xiriiriga luuqadaha kala duduwan ee ka soo baxay qoraalka Raw ilaa masruufka caalamiga ah. nidaamka oo dhan waxaynu ku soconnay kooxo aan ku kalsoonayn nidaamka hoose-tababarida. Si aan u tababarinno baaritaanka ku xiran, waxaynu isticmaalnay qeybta caalamiga ah ee hadalka iyo meelaha u dhexeeya oo kaliya, waxaana sameynnay sharciyada ku saabsan si aan u fidinno alaabta ku xiran. Tusaalada fudud ee la isku daray waxaa haboon qaababka lagu wareejiyo luuqadaha kala duwan iyo model luuqada caalamiga ah. Imtixaanka waxaa ka muuqda in modellkayagu uu si wanaagsan u sameeyay qaababka qaarkood, wuxuuna hoggaamiyey sheekeysi ku saabsan topicyo tusaale ahaan bidixinta kooxo kasta iyo isku mid ahaanshaha luuqadaha.', 'uz': "Бу саҳифа, CONLL 2017 параметрланган вазифани «Ray матдан кўп тил парламент умумий параметрлашимизни кўрсатади», деб айтилади. Biz hamma tillar uchun tizimni o'zimiz komponentlarimiz bilan ishga tushirib, qaytadan o'rgangan baseline tizimlariga ishlatmaymiz. @ info: whatsthis Name Tajriba natijalari ko'rsatadi, bizning modelimiz bir necha metrikada bajarildi va har bir komponent qanday bogʻ'lash va tillarda bir xil bir xil bir xil bo'lgan mavzularda talab qiladi.", 'vi': 'Tờ giấy này giới thiệu hệ thống được gửi cho "Nhiệm vụ chia sẻ CONLL̉i"Phân tích ngôn ngữ đa từ văn bản thô sang phụ thuộc chung" Chúng tôi đã chạy hệ thống cho tất cả các ngôn ngữ với các thành phần hoàn chỉnh ống dẫn mà không dựa vào hệ thống cơ bản được đào tạo lại. Để huấn luyện kẻ phân biệt sự phụ thuộc, chúng tôi chỉ sử dụng phần phổ biến của bài phát biểu và khoảng cách giữa các từ, và các quy tắc tự động áp dụng để gán các nhãn phụ thuộc. Các mô hình đơn giản và ngôn ngữ hoá được thích hợp cho phương pháp chuyển giao ngôn ngữ khác nhau và một mô hình ngôn ngữ phổ biến. Kết quả thí nghiệm cho thấy mô hình của chúng tôi diễn đạt tốt trong một số lượng tử và dẫn đầu thảo luận về các chủ đề như sự đóng góp của mỗi thành phần và về điểm tương đồng pháp thuật giữa các ngôn ngữ.', 'bg': 'Настоящата статия представя нашата система, представена за споделената задача "Многоезично анализиране от суров текст до универсални зависимости". Изпълнихме системата за всички езици със собствени напълно тръбопроводни компоненти, без да разчитаме на повторно обучени базови системи. За да тренираме анализатора на зависимости, използвахме само универсалните тагове за част от речта и разстоянието между думите, и приложихме детерминистични правила за присвояване на етикети на зависимост. Простите и делексикализирани модели са подходящи за подходи за междуезичен трансфер и универсален езиков модел. Експерименталните резултати показват, че нашият модел се представя добре в някои показатели и води дискусия по теми като принос на всеки компонент и синтактични прилики между езиците.', 'da': "Denne artikel præsenterer vores system indsendt til CoNLL 2017 Shared Task, 'Flersproget Parsing fra rå tekst til universelle afhængigheder.' Vi kørte systemet for alle sprog med vores egne fuldt pipelinerede komponenter uden at stole på re-trænede baseline systemer. For at træne afhængighedsfortolkeren brugte vi kun de universelle del-af-tale-mærker og afstand mellem ord og anvendte deterministiske regler til at tildele afhængighedsmærker. De enkle og delekskaliserede modeller er velegnede til tværsprogede overførselsmetoder og en universel sprogmodel. Eksperimentelle resultater viser, at vores model klarede sig godt i nogle metrics og leder diskussion om emner som bidrag af hver komponent og syntaktiske ligheder mellem sprog.", 'nl': "Deze paper presenteert ons systeem dat is ingediend voor de CoNLL 2017 Shared Task, 'Meertalige Parsing van Raw Text naar Universele Afhankelijkheden'. We hebben het systeem voor alle talen uitgevoerd met onze eigen volledig pipelined componenten zonder te vertrouwen op opnieuw getrainde baseline systemen. Om de afhankelijkheidsparser te trainen, gebruikten we alleen de universele deeltags en de afstand tussen woorden, en pasten we deterministische regels toe om afhankelijkheidslabels toe te wijzen. De eenvoudige en gedexexicaliseerde modellen zijn geschikt voor cross-lingual transfer benaderingen en een universeel taalmodel. Experimentele resultaten tonen aan dat ons model goed presteerde in sommige metrics en leidt tot discussie over onderwerpen zoals bijdrage van elke component en syntactische overeenkomsten tussen talen.", 'de': "Dieses Papier stellt unser System vor, das für die CoNLL 2017 Shared Task eingereicht wurde, 'Mehrsprachiges Parsing von Rohtext zu Universal Dependencies'. Wir haben das System für alle Sprachen mit unseren eigenen vollständig pipelined Komponenten betrieben, ohne auf neu trainierte Basissysteme angewiesen zu sein. Um den Abhängigkeitsparser zu trainieren, haben wir nur die universellen Sprachteiltags und den Abstand zwischen Wörtern verwendet und deterministische Regeln angewendet, um Abhängigkeitsbezeichnungen zuzuweisen. Die einfachen und delexikalisierten Modelle eignen sich für sprachübergreifende Transferansätze und ein universelles Sprachmodell. Experimentelle Ergebnisse zeigen, dass unser Modell in einigen Metriken gut abschneidet und Diskussionen über Themen wie den Beitrag jeder Komponente und syntaktische Ähnlichkeiten zwischen Sprachen führt.", 'hr': "Ovaj papir predstavlja naš sustav podignut za zajednički zadatak CoNLL 2017, 'Multilingual Parsing from Raw Text to Universal Dependencies.' Provjerili smo sistem za sve jezike sa svojim potpuno cijeviranim komponentima bez oslanjanja na ponovno obučene početne sustave. Da bi obučili analizator ovisnosti, koristili smo samo univerzalne oznake dijela govora i udaljenost između riječi i primjenjene determinističke pravila za dodavanje oznake ovisnosti. Jednostavni i deleksikalizirani modeli su odgovarajući za pristupe preko jezika i univerzalni jezički model. Eksperimentalni rezultati pokazuju da je naš model dobro proveo u nekim metrikama i vodi diskusiju o temama poput doprinosa svake komponente i o sintaktičkim sličnostima među jezicima.", 'id': "Kertas ini memperkenalkan sistem kami yang dikirim untuk Tugas Bersama CoNLL 2017, 'Penganalisan berbagai bahasa dari Teks Raw ke Dependensi Universal.' Kami menjalankan sistem untuk semua bahasa dengan komponen kami yang sepenuhnya terpipelin tanpa bergantung pada sistem dasar yang dilatih kembali. To train the dependency parser, we used only the universal part-of-speech tags and distance between words, and applied deterministic rules to assign dependency labels.  Model sederhana dan deleksikal cocok untuk pendekatan trans-bahasa transfer dan model bahasa universal. Hasil eksperimen menunjukkan bahwa model kami berhasil dengan baik dalam beberapa metrik dan memimpin diskusi mengenai topik seperti kontribusi setiap komponen dan perbedaan sintaksi antara bahasa.", 'ko': "본고는 우리가 CoNLL 2017 공유 임무인'원본 텍스트에서 일반 의존항까지의 다중 언어 해석'에 제출한 시스템을 소개한다.우리는 재훈련을 거친 기선 시스템에 의존하지 않고 모든 언어를 실행하기 위해 자신의 완전 유수선 구성 요소를 사용합니다.의존성 해석기를 훈련시키기 위해, 우리는 통용적인 단어 표기와 단어 사이의 거리만 사용하고, 의존성 라벨을 분배하는 확실한 규칙을 적용한다.이런 간단한 어휘화 모델은 다중 언어 이동 방법과 통용 언어 모델에 적용된다.실험 결과에 의하면 우리의 모델은 일부 지표에서 양호한 모습을 보였고 모든 구성 요소의 공헌과 언어 간의 문법 유사성 등 주제에서 토론을 불러일으켰다.", 'tr': "Bu kagyz biziň sistemimizi CoNLL 2017-nji ýylda Paýlaşan Görevi üçin görkezýär, 'Halkara dilli Taýýarlama Metinden Halkara Baýramlyklara' . Biz ähli diller üçin öz pipet komponentlerimiz bilen ýene-de eğlenen baz sistemalara ynanmaýdyk. Baýramçylyk tansçysyny öwretmek üçin diňe uniwersal çykyş täglerini we sözlerin arasyndaky uzaklaşyklary ulandyk we baglanylyk etiketlerini bejermek üçin ulandyk. Basit we çykyş nusgalar uluslary dil göçürmek üçin gowy görýär. Testiýa netijeleri biziň modelimiziň käbir metrikada gowy edendigini we her komponentin we dilleriň arasynda syntaktik ýaly meňzeşliklerini çykarýandygyny görkezýär.", 'sw': "This paper presents our system submitted for the CoNLL 2017 Shared Task, 'Multilingual Parsing from Raw Text to Universal Dependencies.'  Tuliendesha mfumo wa lugha zote kwa vifaa vyetu vikubwa vizuri vyetu bila kutegemea mfumo wa msingi unaoendelea tena. Ili kufundisha mchambuzi wa kutegemea, tulitumia tu sehemu ya viungo vya kuongea na umbali kati ya maneno, na kutumia sheria za kuthibitisha ili kutoa maabara ya kutegemea. Mifano rahisi na yenye utaratibu ni muhimu kwa namna za kuhamisha lugha mbalimbali na mtindo wa lugha ya ulimwengu. Matokeo ya majaribio yanaonyesha kuwa mtindo wetu ulifanya vizuri katika baadhi ya mitindo na unaongoza mijadala juu ya mada kama vile mchango wa kila sehemu na kwa usawa wa lugha.", 'af': 'Hierdie papier stel ons stelsel voorgestel vir die CoNLL 2017 Gedeelde Opdrag, \'Veelvuldige verwerking van Roë Teks tot Universele Afhanklikhede.\'" Ons hardloop die stelsel vir al die tale met ons eie volledige pipelineerde komponente sonder om te vertrou op heroefende basilyn stelsels. Om die afhanklikheidspanser te oefen, gebruik ons slegs die universele deel van spraak etikette en afstand tussen woorde en toepassing van deterministiese reëls om afhanklikheidspansels te toewys. Die eenvoudige en deleksikasiseerde modele is geskik vir kruistale oordrag toegang en \'n universele taal model. Eksperimentele resultate wys dat ons model goed in sommige metries uitgevoer het en verlei diskusie oor onderwerpe soos bydraag van elke komponent en op sintaktieke gelykenisse onder tale.', 'sq': "Ky dokument paraqet sistemin tonë të paraqitur për detyrën e përbashkët të CoNLL 2017, 'Analizim shumëgjuhës nga teksti i parë në varësitë universale.' Ne drejtuam sistemin për të gjitha gjuhët me komponentet tona plotësisht të tubuara pa u mbështetur në sistemet e rindërtimit bazë. Për të trajnuar analizuesin e varësisë, ne përdorëm vetëm etiketat universale të pjesës së fjalës dhe distancën mes fjalëve, dhe zbatuam rregullat përcaktuese për të caktuar etiketat e varësisë. Modelet e thjeshta dhe të deleksializuara janë të përshtatshme për metodat e transferimit ndërgjuhësor dhe një model gjuhësh universale. Rezultatet eksperimentale tregojnë se modeli ynë funksionoi mirë në disa metrika dhe udhëheq diskutimin mbi temë të tilla si kontributi i çdo komponenti dhe mbi ngjashmëritë sintaktike midis gjuhëve.", 'az': "Bu kağıt bizim sistemimizi CoNLL 2017'nin paylaşılmış Task üçün təbliğ edir, 'Səşər Metindən Üniversal Bağlamlıqlara çoxlu dilli Parsing'. Biz bütün dillər üçün sistemi yenidən təhsil edilmiş baseline sistemlərə güvənmədən tamamlanmış komponentlərimizlə çalışırdıq. Bağımsızlıq ayırıcısını təhsil etmək üçün, sözlərin üniversal parçasının etiketlərini və sözlərin arasındakı uzaqlaşmasını və bağlılıq etiketlərini təhsil etmək üçün deterministik qaydaları istifadə etdik. Basit və deleksikalizirlən modellər çoxlu dil transfer tərəfindən və universel dil modeli üçün uyğun olacaqlar. Müxtəlif sonuçları göstərir ki, modellərimiz bəzi metriklərdə yaxşı işlədi və hər komponentin və dillərin arasında sintaktik similarlıqlarına bənzər məsələlər barəsində mübahisə edir.", 'am': 'ይህ ገጽ ለኮንLL 2017 ስራዎችን የተሰራጨውን ስርዓት ያቀርባል ‹ከRaw ጽሑፍ ወደ ዓለማዊ ድጋፍ› የቋንቋዎች ሁሉ ስብስቡን በሙሉ የተጠለፈ ክፍተቶችን በተመሳሳይ የደብተር ድምፅ ሲስተማርን አነሳን፡፡ To train the dependency parser, we used only the universal part-of-speech tags and distance between words, and applied deterministic rules to assign dependency labels.  ቀላል እና አዲስ ምሳሌዎች ለቋንቋ መቀናቀል እና የዓለምአቀፍ ቋንቋ ሞዴል የሚገባ ናቸው፡፡ ፈተና ውጤቶች ሞዴላታችን በአንዳንድ ማተሚያ ውስጥ መልካም እንደደረገ እና ለሁሉም ጉዳዩ እና በቋንቋዎች መካከል በተስማማማዊ ትክክል እንደተደረገ ጉዳዮች ላይ ውይይትን እንዲመራ ያሳያል፡፡', 'hy': 'Այս հոդվածը ներկայացնում է մեր համակարգը, որը ներկայացվել է 2017 թվականի ԿՈՆԼ-ի հանձնարարության համար, «Բազլեզու վերլուծություն չափով տեքստից դեպի համաշխարհային կախվածություններ»: We ran the system for all languages with our own fully pipelined components without relying on re-trained baseline systems.  Որպեսզի վարժեցնենք կախվածության վերլուծումը, մենք օգտագործեցինք միայն խոսքի համընդհանուր մասը և բառերի միջև գտնվող հեռավորությունը, և կիրառեցինք որոշող կանոնները կախվածության վերլուծումը: The simple and delexicalized models are suitable for cross-lingual transfer approaches and a universal language model.  Փորձարկվող արդյունքները ցույց են տալիս, որ մեր մոդելը լավ աշխատել է որոշ չափումներում և առաջնորդում է քննարկումներ այնպիսի թեմաների, ինչպիսիք են յուրաքանչյուր բաղադրամի ներդրումը և լեզուների սինտակտիկ նմանություններ', 'bs': "Ovaj papir predstavlja naš sistem podignut za zajednički zadatak CoNLL 2017, 'Multilingual Parsing from Raw Text to Universal Dependencies.' Provjerili smo sistem za sve jezike sa svojim komponentima punim cijevima bez oslanjanja na ponovno obučene početne sustave. Da bi obučili analizator ovisnosti, koristili smo samo univerzalne oznake dio govora i udaljenost između riječi, i primjenjivali determinističke pravila za dodavanje etiketa ovisnosti. Jednostavni i deleksikalizirani modeli su odgovarajući za pristupe preko jezika i univerzalni jezički model. Eksperimentalni rezultati pokazuju da je naš model dobro proveo u nekim metrikama i vodi diskusiju o temama poput doprinosa svake komponente i o sintaktičnim sličnostima među jezicima.", 'fa': 'این کاغذ سیستم ما را برای کار مشترک CoNLL ۲۰۱۷ پیشنهاد می\u200cکند، «تحلیل زیادی زبان از متن Raw به بستگی جهانی». ما سیستم را برای همه زبانها با بخش\u200cهای کامل لوله\u200cهای خودمان اجرا کردیم بدون اعتماد به سیستم\u200cهای پایین\u200cخط\u200cهای دوباره آموزش داده\u200cایم. برای آموزش بازیگر بستگی، ما فقط برچسب\u200cهای جهانی و فاصله بین کلمات استفاده کردیم، و قوانین تصمیم\u200cگیری را برای تعیین برچسب\u200cهای بستگی استفاده کردیم. Models simple and delexicalized are suitable for cross-language transfer approaches and a universal language model. نتیجه\u200cهای تجربه\u200cی ما نشان می\u200cدهند که مدل ما در بعضی متریک خوب انجام می\u200cدهد و در مورد موضوع\u200cهای مانند رشته\u200cگیری از هر بخش و شبیه\u200cهای سنتاکتیک بین زبان\u200cها رهبری می\u200cکند.', 'ca': "Aquest paper presenta el nostre sistema presentat per la tasca compartida CoNLL 2017, 'Analització multilingüe del text brut a les dependencies universals'. Vam fer funcionar el sistema per totes les llengües amb els nostres propis components totalment aconseguits sense confiar en sistemes de base reestruïts. Per formar l'analitzador de dependencies, vam utilitzar només les etiquetes de la part universal de la fala i la distància entre paraules, i vam aplicar regles deterministes per assenyar etiquetes de dependencies. Els models senzills i desxitalitzats són adequats per a abords de transfer ència translingüística i un model de llenguatge universal. Els resultats experimentals mostren que el nostre model va funcionar bé en algunes mètriques i condueix la discussió sobre temes com la contribució de cada component i sobre similituds sinàctiques entre les llengües.", 'et': 'Käesolevas artiklis tutvustatakse meie süsteemi, mis on esitatud CoNLL 2017. aasta jagatud ülesandele "Mitmekeelne parsing toortekstist universaalsetele sõltuvustele". Me kasutasime süsteemi kõigis keeltes oma täielikult torujuhtmetega komponentidega, toetumata ümberõppega baassüsteemidele. Sõltuvuspartseri koolitamiseks kasutasime ainult universaalseid kõneosa silte ja sõnadevahelist kaugust ning sõltuvuspildiste määramiseks rakendasime deterministlikke reegleid. Lihtsad ja deleksikaliseeritud mudelid sobivad keeleülese siirde lähenemiseks ja universaalseks keelemudeliks. Eksperimentaalsed tulemused näitavad, et meie mudel on mõnedes mõõdikutes hästi toiminud ja juhib arutelu teemadel, nagu iga komponendi panus ja keelte süntaktilised sarnasused.', 'bn': 'এই পত্রিকাটি আমাদের সিস্টেম কনএল ২০১৭ শেয়ার করা কাজের জন্য প্রদান করা হয়েছে “রো টেক্সট থেকে বিশ্ববিদ্যালয়ের নির্ভর করা ম আমরা পুনরায় প্রশিক্ষিত বেসাইলাইন সিস্টেমের উপর নির্ভর করি না দিয়ে সকল ভাষার জন্য সিস্টেম চালাই। নির্ভর প্রশিক্ষণ প্রশিক্ষণের জন্য আমরা শুধুমাত্র বিশ্ববিদ্যালয়ের অংশের ভাষণের ট্যাগ এবং শব্দের মধ্যে দূরত্ব ব ব্যবহার করেছি এবং নির সাধারণ এবং প্রতিনিধিত্ব করা মডেলগুলো প্রবাহিত ভাষার পরিবর্তন এবং বিশ্বব্যাপী ভাষার মডেলের জন্য যথাযথ। পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের মডেল কিছু মেট্রিকে ভালো করেছে এবং বিষয়ে আলোচনা নেয়, যেমন প্রত্যেক উপাদানের অবদান এবং ভাষার মধ্যে একই ধরনে', 'cs': "Tento článek představuje náš systém předložený pro sdílený úkol CoNLL 2017, 'Multilingual Parsing from Raw Text to Universal Dependences'. Systém jsme spustili pro všechny jazyky s vlastními plně potrubními komponenty, aniž bychom se spoléhali na přepracované základní systémy. Pro trénink parser závislostí jsme použili pouze univerzální značky části řeči a vzdálenost mezi slovy a použili jsme deterministická pravidla k přiřazení popisků závislostí. Jednoduché a delexikalizované modely jsou vhodné pro přístupy mezi jazyky a univerzální jazykový model. Experimentální výsledky ukazují, že náš model vedl v některých metrikách dobře a vede diskusi o tématech, jako je přínos jednotlivých komponent a syntaktické podobnosti mezi jazyky.", 'fi': "Tämä artikkeli esittelee järjestelmämme, joka on toimitettu CoNLL 2017 Shared Task, 'Multilingual Parsing from Raw Text to Universal Dependences'. Käytimme järjestelmää kaikilla kielillä omilla täysin putkitetuilla komponenteilla luottamatta uudelleenkoulutettuihin perusjärjestelmiin. Riippuvuusparserin kouluttamiseksi käytimme vain universaaleja puheen osatunnisteita ja sanojen välistä etäisyyttä, ja sovelsimme deterministisiä sääntöjä riippuvuuslaitteiden määrittämiseen. Yksinkertaiset ja deleksikalisoidut mallit soveltuvat monikielisiin siirtomenetelmiin ja universaaliin kielimalliin. Kokeelliset tulokset osoittavat, että mallimme suoriutui hyvin joissakin mittareissa ja johtaa keskustelua aiheista, kuten kunkin komponentin panoksesta ja syntaktisista yhtäläisyyksistä kielten välillä.", 'jv': "Ngerti iki bakal ngewehhu sistem nambah kanggo CoNLL 1997 Sampeyan task, 'Multilanguage Awak dhéwé mlayu sistem kanggo saben langa-saben kanggo sampeyan mruput Ditoles model sing sampeyan karo perusahaan nggo ndelok Pametuné sing paling nggambar kuwi model nyebutne sak gagal ngono urip nggawe gerarané karo sistem sing dumadhi, kaya ngono nggambar barang sampeyan ingkang sampeyan karo sistem sing luwih apik.", 'sk': 'Ta prispevek predstavlja naš sistem, predložen za skupno nalogo CoNLL 2017, "Večjezično razporejanje iz surovega besedila v univerzalne odvisnosti". Sistem smo upravljali za vse jezike z lastnimi popolnoma cevovodnimi komponentami, ne da bi se zanašali na ponovno usposobljene osnovne sisteme. Za usposabljanje razčlenjevalnika odvisnosti smo uporabili samo univerzalne oznake dela govora in razdaljo med besedami ter uporabili deterministična pravila za dodeljevanje oznak odvisnosti. Preprosti in deleksikalizirani modeli so primerni za pristope medjezičnega prenosa in univerzalni jezikovni model. Eksperimentalni rezultati kažejo, da se je naš model dobro izkazal v nekaterih metrikah in vodi razpravo o temah, kot so prispevek vsake komponente in sintaktične podobnosti med jeziki.', 'ha': "Bu takardan na gaya na'asarmu wanda aka saka wa shirin aikin CoNLL 2017, 'Fassarar lingui masu yawa daga Raw Text zuwa Universal dependanci'. Mun yi tafiyar na'urar tsari ga duk harshe da ƙananan da ke cikakken ƙarami, kuma ba mu dõgara a kan tsari na'urar da aka tsare shi ba. Yana amfani da kawai rabon tagogi na bayani da tsakanin magana, kuma mun yi amfani da sharuya masu ƙayyade zuwa alama masu dõgara. @ info: whatsthis Matarin jarrabai na nuna cewa misalinmu ya sami da shi cikin wasu mitriki kuma yana shirya magana a kan masu kama da ƙarami ga duk compoki da kuma a kan daidaita misalin harshe.", 'bo': 'ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་གི་CoNLL 2017་ལ་མཉམ་སྤྱོད་པའི་བྱ We ran the system for all languages with our own fully pipelined components without relying on re-trained baseline systems. To train the dependency parser, we used only the universal part-of-speech tags and distance between words, and applied deterministic rules to assign dependency labels. སྤྱིར་བཏང་བ་ཡོད་པའི་མིག་གཟུགས་རིས་གཅིག་མཚུངས་ཀྱི་སྐུལ་འདྲི་ཞིབ་དང་སྤྱི་ཁྱད་ཆོས Experimental results show that our model performed well in metrics and led discussion on topics such as contribution of each component and on syntactic similarities among languages.', 'he': 'העבודה הזו מציגה את המערכת שלנו שנשלחה למשימה המשותפת של CoNLL 2017, "בדיקת רבות שפות מטקסט ראש לתלויות יוניברסליות." ניהלנו את המערכת לכל השפות עם המרכיבים שלנו מוצנצים לחלוטין בלי לסמוך על מערכות תחילות מאומנות מחדש. כדי לאמן את מעבד ההתמודדות, השתמשנו רק בתגים של החלק האוניברסלי של הנאום והמרחק בין מילים, והשתמשו חוקים קבעניים כדי להזמין תוויות ההתמודדות. הדוגמנים הפשוטים והדלקסיקלים מתאימים לגישוי העברה לשפתיים וחושב שפת אוניברסלי. Experimental results show that our model performed well in some metrics and leads discussion on topics such as contribution of each component and on syntactic similarities among languages.'}
{'en': 'A rule-based system for cross-lingual parsing of Romance languages with Universal Dependencies', 'ar': 'نظام قائم على القواعد للتحليل اللغوي للغات الرومانسية مع التبعيات العالمية', 'es': 'Un sistema basado en reglas para el análisis multilingüe de lenguas romances con dependencias universales', 'fr': "Un système basé sur des règles pour l'analyse multilingue des langues romanes avec des dépendances universelles", 'pt': 'Um sistema baseado em regras para análise multilíngue de línguas românicas com dependências universais', 'ja': '普遍的な依存関係を持つロマンス言語のクロスリンガル解析のためのルールベースのシステム', 'hi': 'यूनिवर्सल निर्भरताओं के साथ रोमांस भाषाओं के क्रॉस-लिंगुअल पार्सिंग के लिए एक नियम-आधारित प्रणाली', 'zh': '盖规矩之统,施于通用罗曼言语解析', 'ru': 'Основанная на правилах система для кросс-лингвистического синтаксического анализа романских языков с универсальными зависимостями', 'ga': 'Córas bunaithe ar rialacha chun teangacha Rómánsacha a pharsáil go trasteangach le Spleáchas Uilíoch', 'ka': 'პრომინური ენების მრავალური პარასიზაციისთვის, რომელიც უნივერსოლური განსაზღვრებულებებით, განსაზღვრებული სისტემა', 'el': 'Ένα σύστημα βασισμένο σε κανόνες για την ανάλυση των Ρομαντικών γλωσσών με καθολικές εξαρτήσεις', 'hu': 'Szabályalapú rendszer az univerzális függőségekkel rendelkező román nyelvek többnyelvű értelmezésére', 'it': "Un sistema basato su regole per l'analisi cross-lingual di lingue romanze con dipendenze universali", 'kk': 'Романтиялық тілдерді бірнеше тілдерді талдау үшін ережелер негіздеген жүйеName', 'lt': 'Taisyklėmis grindžiama romėnų kalbų tarpkalbinio analizavimo su visuotinėmis priklausomybėmis sistema', 'mk': 'Систем базиран на правила за прекујазично анализирање на романските јазици со универзални зависности', 'ms': 'A rule-based system for cross-lingual parsing of Romance languages with Universal Dependencies', 'mt': 'Sistema bbażata fuq ir-regoli għall-analiżi translingwistika tal-lingwi Romani mad-Dipendenzi Universali', 'ml': 'റോമാന്\u200dസ് ഭാഷകളുടെ പാര്\u200dസിങ്ങിനുള്ള നിയമത്തില്\u200d അടിസ്ഥാനമായ ഒരു സിസ്റ്റം', 'mn': 'Ромын хэлний олон хэлний хуваалцааны систем нь ертөнцийн хамааралтай', 'no': 'Name', 'pl': 'System oparty na regułach do parsowania wielojęzycznego języków romańskich z uniwersalnymi zależnościami', 'sr': 'Pravilni sistem za razmatranje rumunskih jezika sa univerzalnim zavisnostima', 'ta': 'ரோமான்ஸ் மொழிகளின் பல மொழிகள் பாடலுக்கான விதிமுறைமை', 'ro': 'Un sistem bazat pe reguli pentru analizarea încrucișată a limbilor romanice cu dependențe universale', 'si': 'Name', 'sv': 'Ett regelbaserat system för tvärspråklig tolkning av romanska språk med universella beroende', 'so': 'Isticmaalka luqadaha lagu qoray oo ku qoran qoraalka lagu qorayo oo ku qoran xirfadaha jaamacadda', 'ur': 'رومانس زبانوں کی مختلف زبان پارسینگ کے لئے ایک قانون بنیادی سیستم جس میں ارومین اعتمادی ہے', 'uz': 'Name', 'vi': 'Một hệ thống quy định cho việc phân tích ngôn ngữ ngữ chung', 'bg': 'Основана на правила система за междуезично анализиране на романски езици с универсални зависимости', 'nl': 'Een regelgebaseerd systeem voor meertalig parsen van Romaanse talen met universele afhankelijkheden', 'da': 'Et regelbaseret system til tværsproget tolkning af romanske sprog med universelle afhængigheder', 'hr': 'Pravilni sustav za razmatranje rumunskih jezika s univerzalnim ovisnostima', 'de': 'Ein regelbasiertes System zum sprachübergreifenden Parsen romanischer Sprachen mit universellen Abhängigkeiten', 'ko': '규칙 기반의 범의존 로맨스 언어 크로스 언어 분석 시스템', 'id': 'Sebuah sistem berdasarkan aturan untuk penghuraian bahasa saling bahasa bahasa Romans dengan Dependensi Universal', 'fa': 'یک سیستم بر اساس قانونی برای تجزیه کردن زبانهای متوسط زبان رومانی با بستگی جهانی', 'sw': 'Mfumo wa utawala wa wimbo wa lugha mbalimbali wa lugha za KiRomania na Utegemeo wa Ulimwengu', 'tr': 'Universal Dependensiýa bilen Roma dillerini çarpaz diller analyze üçin düzgün sistemi', 'sq': 'Një sistem bazuar në rregulla për analizimin ndërgjuhësor të gjuhëve romake me varësitë universale', 'af': 'Name', 'am': 'የሮሜኒያን ቋንቋዎች በዩንቨርስቲ ግንኙነት ለመቀላቀል የሥርዓት ሥርዓት', 'bn': 'A rule-based system for cross-lingual parsing of Romance languages with Universal Dependencies', 'hy': 'Հռոմանական լեզուների միջլեզվային վերլուծության կանոններով հիմնված համակարգ համաշխարհային կախվածությունների հետ', 'ca': "Un sistema basat en regles d'analització translingüística de llengües romàniques amb Dependencies Universals", 'cs': 'Systém založený na pravidlech pro analýzu románských jazyků s univerzálními závislostmi', 'et': 'Reeglitel põhinev süsteem universaalsete sõltuvustega romaani keelte keeleüleseks parsimiseks', 'fi': 'Säännöpohjainen järjestelmä romanien kielten monikieliseen jäsentämiseen universaaleilla riippuvuuksilla', 'az': 'Universal Dependencies olan Romalı dillərin çoxlu dil ayırılması sistemi', 'bs': 'Pravilni sistem za razmatranje rumunskih jezika sa univerzalnim zavisnostima', 'jv': 'Ngubah-sistem sing basa kanggo oleh-oleh dumaten ning limi rumani karo Universal Dijehenduluran', 'he': 'מערכת מבוססת על חוקים עבור בדיקת שפתים רומנטיות בין שפתים עם תלויות יוניברסליות', 'bo': 'རོ་མ་ཡིས་སྐད་རིགས་ཚོའི་དབྱེ་ཞིབ་ཀྱི་སྲོལ་ལམ་ལུགས་གཞུང་གི་མ་ལག་ཅིག་ཡིན་ནའང་ཡིན་པའི་སྤྱི་ཚོགས་ལ', 'sk': 'Sistem, ki temelji na pravilih za večjezično razčlenitev romanskih jezikov z univerzalnimi odvisnostmi', 'ha': 'An kasa rubutun da aka ƙayyade wa parse na lugha na faransa-harshe na Rumori da Universal Dekurs'}
{'en': 'This article describes MetaRomance, a rule-based cross-lingual parser for Romance languages submitted to CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies. The system is an almost delexicalized parser which does not need training data to analyze Romance languages. It contains linguistically motivated rules based on PoS-tag patterns. The rules included in MetaRomance were developed in about 12 hours by one expert with no prior knowledge in Universal Dependencies, and can be easily extended using a transparent formalism. In this paper we compare the performance of MetaRomance with other supervised systems participating in the competition, paying special attention to the parsing of different treebanks of the same language. We also compare our system with a delexicalized parser for Romance languages, and take advantage of the harmonized annotation of Universal Dependencies to propose a language ranking based on the syntactic distance each variety has from Romance languages.', 'ar': 'توضح هذه المقالة MetaRomance ، وهو محلل متعدد اللغات قائم على القواعد للغات الرومانسية تم إرساله إلى المهمة المشتركة لـ CoNLL 2017: التحليل متعدد اللغات من النص الخام إلى التبعيات العالمية. النظام عبارة عن محلل لغوي تقريبًا ولا يحتاج إلى بيانات تدريبية لتحليل اللغات الرومانسية. يحتوي على قواعد ذات دوافع لغوية تستند إلى أنماط علامة PoS. تم تطوير القواعد المدرجة في MetaRomance في حوالي 12 ساعة من قبل خبير واحد ليس لديه معرفة مسبقة في التبعيات العالمية ، ويمكن توسيعها بسهولة باستخدام شكليات شفافة. في هذا البحث ، نقارن أداء MetaRomance مع الأنظمة الخاضعة للإشراف الأخرى المشاركة في المسابقة ، مع إيلاء اهتمام خاص لتحليل مختلف الضفاف الشجرية من نفس اللغة. نحن نقارن أيضًا نظامنا بالمحلل اللغوي غير اللغوي للغات الرومانسية ، ونستفيد من التعليق التوضيحي المنسق للاعتمادات العالمية لاقتراح تصنيف اللغة بناءً على المسافة النحوية لكل مجموعة متنوعة من اللغات الرومانسية.', 'fr': "Cet article décrit MetaRomance, un analyseur multilingue basé sur des règles pour les langues romanes soumis à ConLL 2017 Shared Task\xa0: Multilingual Parsing from Raw Text to Universal Dependencies. Le système est un analyseur presque délexicalisé qui n'a pas besoin de données d'apprentissage pour analyser les langues romanes. Il contient des règles motivées par la langue, basées sur des modèles de balises POS. Les règles incluses dans MetaRomance ont été développées en 12 heures environ par un expert sans connaissance préalable des dépendances universelles, et peuvent être facilement étendues à l'aide d'un formalisme transparent. Dans cet article, nous comparons les performances de MetaRomance avec celles d'autres systèmes supervisés participant au concours, en accordant une attention particulière à l'analyse de différentes banques d'arbres de la même langue. Nous comparons également notre système avec un analyseur délexicalisé pour les langues romanes, et nous tirons parti de l'annotation harmonisée des dépendances universelles pour proposer un classement des langues basé sur la distance syntaxique de chaque variété par rapport aux langues romanes.", 'es': 'Este artículo describe MetaRomance, un analizador multilingüe basado en reglas para lenguas romances presentado a CoNll 2017 Shared Task: Multilingüe Parsing from Raw Text to Universal Dependencies. El sistema es un analizador casi delicalizado que no necesita datos de entrenamiento para analizar las lenguas romances. Contiene reglas de motivación lingüística basadas en patrones de etiquetas POS. Las reglas incluidas en MetaRomance fueron desarrolladas en aproximadamente 12 horas por un experto sin conocimientos previos en Dependencias Universales, y pueden ampliarse fácilmente mediante un formalismo transparente. En este artículo comparamos el rendimiento de MetaRomance con otros sistemas supervisados que participan en la competencia, prestando especial atención al análisis de diferentes bancos de árboles del mismo idioma. También comparamos nuestro sistema con un analizador delexicalizado para lenguas romances, y aprovechamos la anotación armonizada de Dependencias Universales para proponer una clasificación de idiomas basada en la distancia sintáctica que cada variedad tiene de las lenguas romances.', 'pt': 'Este artigo descreve o MetaRomance, um analisador multilíngue baseado em regras para idiomas românicos submetido à tarefa compartilhada CoNLL 2017: análise multilíngue de texto bruto para dependências universais. O sistema é um analisador quase deslexicalizado que não precisa de dados de treinamento para analisar as línguas românicas. Ele contém regras motivadas linguisticamente baseadas em padrões de tags PoS. As regras incluídas no MetaRomance foram desenvolvidas em cerca de 12 horas por um especialista sem conhecimento prévio em Dependências Universais, e podem ser facilmente estendidas usando um formalismo transparente. Neste artigo comparamos o desempenho do MetaRomance com outros sistemas supervisionados participantes da competição, prestando atenção especial ao parsing de diferentes treebanks da mesma linguagem. Também comparamos nosso sistema com um analisador deslexicalizado para línguas românicas e aproveitamos a anotação harmonizada de Dependências Universais para propor uma classificação de idioma com base na distância sintática que cada variedade tem das línguas românicas.', 'zh': '本文介 MetaRomance,此一款法之跨语解析器,宜用于提交 CoNLL 2017 共事者罗曼语语:自始文本至通用赖项者多言解析。 其统几中心化之解析器,不须练数析罗曼语。 其包盖 PoS 标式之言动机则。 MetaRomance之道,通用无先验知识之家,大约12时发之,而可以明形式主义轻广。 本文以MetaRomance性较诸监督,特留意同语树库解析。 又以吾等之统与罗曼语系言之中心化解析器较之,而因通用之调注,各以变体与罗曼语系语之语法相去为名。', 'ru': 'В этой статье описывается MetaRomance, основанный на правилах кросс-лингвистический парсер для романских языков, представленный CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Система является почти delexicalized parser, который не нуждается в обучающих данных для анализа романских языков. Он содержит лингвистически мотивированные правила, основанные на шаблонах PoS-тегов. Правила, включенные в MetaRomance, были разработаны примерно за 12 часов одним экспертом, не имеющим предварительных знаний в области универсальных зависимостей, и могут быть легко расширены с использованием прозрачного формализма. В этой статье мы сравниваем производительность MetaRomance с другими контролируемыми системами, участвующими в конкурсе, уделяя особое внимание синтаксическому анализу различных берегов деревьев одного языка. Мы также сравниваем нашу систему с делексикализованным парсером для романских языков и используем согласованную аннотацию универсальных зависимостей, чтобы предложить рейтинг языков на основе синтаксического расстояния, которое каждая разновидность имеет от романских языков.', 'hi': 'यह आलेख वर्णन करता है कि MetaRomance, CoNLL 2017 साझा कार्य के लिए सबमिट की गई रोमांस भाषाओं के लिए एक नियम-आधारित क्रॉस-भाषाई पार्सर: बहुभाषी पार्सिंग कच्चे पाठ से यूनिवर्सल निर्भरताओं के लिए। सिस्टम एक लगभग delexicalized पार्सर है जो रोमांस भाषाओं का विश्लेषण करने के लिए प्रशिक्षण डेटा की आवश्यकता नहीं है। इसमें पीओएस-टैग पैटर्न के आधार पर भाषाई रूप से प्रेरित नियम शामिल हैं। MetaRomance में शामिल नियमों को सार्वभौमिक निर्भरताओं में कोई पूर्व ज्ञान के साथ एक विशेषज्ञ द्वारा लगभग 12 घंटे में विकसित किया गया था, और आसानी से एक पारदर्शी औपचारिकता का उपयोग करके बढ़ाया जा सकता है। इस पेपर में हम प्रतियोगिता में भाग लेने वाले अन्य पर्यवेक्षित प्रणालियों के साथ मेटारोमेंस के प्रदर्शन की तुलना करते हैं, एक ही भाषा के विभिन्न ट्रीबैंक के पार्सिंग पर विशेष ध्यान देते हैं। हम रोमांस भाषाओं के लिए एक delexicalized पार्सर के साथ भी हमारे सिस्टम की तुलना करते हैं, और रोमांस भाषाओं से प्रत्येक किस्म की वाक्यात्मक दूरी के आधार पर एक भाषा रैंकिंग का प्रस्ताव करने के लिए यूनिवर्सल निर्भरताओं के सामंजस्यपूर्ण एनोटेशन का लाभ उठाते हैं।', 'ja': 'この記事では、CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependenciesに送信されたロマンス言語のためのルールベースのクロスリンガルパーサーであるMetaRomanceについて説明します。 このシステムはほとんどデレクシアル化された構文解析器であり、ロマンス言語を分析するためのトレーニングデータは必要ありません。 PoSタグパターンに基づいた言語的に動機づけられたルールが含まれています。 MetaRomanceに含まれるルールは、ユニバーサル依存関係に関する事前の知識を持たない1人の専門家によって約12時間で開発され、透明な形式主義を使用して簡単に拡張することができます。 本稿では、同じ言語の異なるツリーバンクの構文解析に特に注意を払いながら、MetaRomanceのパフォーマンスをコンペティションに参加する他の監視対象システムと比較します。 また、システムをロマンス言語用のデレクシラライズされた構文解析器と比較し、Universal Dependenciesの統一されたアノテーションを利用して、各バリエーションがロマンス言語から持つ構文距離に基づいた言語ランキングを提案します。', 'ga': "Déanann an t-alt seo cur síos ar MetaRomance, parsálaí trasteangacha bunaithe ar rialacha do theangacha Rómánsacha a cuireadh isteach chuig CoNLL 2017 Tasc Comhroinnte: Parsáil Ilteangach ó Théacs Raw go Spleáchas Uilíoch. Parsálaí atá beagnach díleicseálach is ea an córas nach dteastaíonn sonraí oiliúna uaidh chun anailís a dhéanamh ar theangacha Rómánsacha. Tá rialacha teanga inspreagtha ann bunaithe ar phatrúin chlibeanna PoS. D'fhorbair saineolaí amháin nach raibh aon eolas aige roimh ré ar Spleáchais Uilíocha na rialacha atá san áireamh i MetaRomance i thart ar 12 uair an chloig, agus is féidir iad a leathnú go héasca trí fhoirmiúlacht thrédhearcach a úsáid. Sa pháipéar seo cuirimid feidhmíocht MetaRomance i gcomparáid le córais eile faoi mhaoirseacht a ghlacann páirt sa chomórtas, ag tabhairt aird ar leith ar pharsáil bainc crann éagsúla den teanga chéanna. Déanaimid ár gcóras a chur i gcomparáid freisin le parsálaí díleicseálaithe do theangacha Rómánsacha, agus bainimid leas as anótáil chomhchuibhithe ar Spleáchas Uilíoch chun rangú teanga a mholadh bunaithe ar an bhfad comhréire atá ag gach cineál ó theangacha Rómánsacha.", 'ka': 'ამ წესტილის შესახებ MetaRomance, რომელიც პრომანეთის ენებისთვის კრესი-ენგური პანსერიზატორია, რომელიც CoNLL 2017-ში გაყოფილი საზოგადოებული დავალება: მრავალენგური პანსერიზაცია წესტიდან უ სისტემა არის პირდაპირად დელექსიკოლიზური პარასერი, რომელიც არ იჭირდება მონაცემები პრომინური ენების ანალიზაციისთვის. ეს იყენებს ლენგურისტიკურად მოტივირებული წესები, რომლებიც POS- Tag შაბლონებზე დაბაზიან. MetaRomance-ში ჩვენი წესები 12 საათში განვითარებულია ერთი ექსპერტის განმავლობაში, რომელიც უნდა იყოს სამყარო განმავლობაში სამყარო უცნობაში, და შეიძლება უფრო ადვილედ გაფარგებ ამ დოკუნეში ჩვენ მეტარომინსის პროცენტის გამოყენებას სხვა ნართებული სისტემებით, რომლებიც კონტენეციაში დავამყენებენ, სპეციალური ინტერნეციას განსხვავებული სამყარ ჩვენ ასევე ჩვენი სისტემას დელექსიკალიზებული პოსტერისტიკური ენათებისთვის შემდგენებთ და გამოყენებთ სამყაროებული ინოსტერისტიკური განსაზღვრებებისთვის სამყაროებული ინოსტერისტიკური რენექტიკური განტოლებ', 'hu': 'Ez a cikk a CoNLL 2017 Megosztott feladathoz benyújtott román nyelvek szabályalapú, többnyelvű értelmezését ismerteti: Többnyelvű értelmezés a nyers szövegtől az univerzális függőségekig. A rendszer egy szinte delexikalizált elemző, amelynek nincs szüksége képzési adatokra a román nyelvek elemzéséhez. Nyelvileg motivált szabályokat tartalmaz PoS-tag mintákon alapuló. A MetaRomance szabályait körülbelül 12 óra alatt fejlesztette ki egy olyan szakértő, akinek nincs előzetes ismerete az univerzális függőségekről, és átlátható formalizmussal könnyen kiterjeszthetők. Ebben a tanulmányban összehasonlítjuk a MetaRomance teljesítményét a versenyben részt vevő más felügyelt rendszerekkel, különös figyelmet fordítva ugyanazon nyelvű különböző fapadok elemzésére. Ezenkívül összehasonlítjuk rendszerünket egy delexikalizált elemzővel a romantikus nyelvekhez, és kihasználjuk az Univerzális függőségek harmonizált jegyzékét, hogy javasoljunk egy nyelvi rangsorolást a romantikus nyelvektől való szintaktikai távolság alapján.', 'el': 'Αυτό το άρθρο περιγράφει έναν γλωσσικό αναλυτή βασισμένο σε κανόνες για τις ρομαντικές γλώσσες που υποβάλλονται στο Κοινή εργασία: Πολυγλωσσική ανάλυση από ακατέργαστο κείμενο σε καθολικές εξαρτήσεις. Το σύστημα είναι ένας σχεδόν απεξαρτημένος αναλυτής που δεν χρειάζεται δεδομένα εκπαίδευσης για την ανάλυση των Ρομαντικών γλωσσών. Περιέχει γλωσσικά υποκινούμενους κανόνες που βασίζονται σε μοτίβα ετικετών PoS. Οι κανόνες που περιλαμβάνονται στο Μεταρομαντισμό αναπτύχθηκαν σε περίπου δώδεκα ώρες από έναν ειδικό χωρίς προηγούμενη γνώση στις Οικουμενικές Εξαρτήσεις και μπορούν εύκολα να επεκταθούν χρησιμοποιώντας έναν διαφανή φορμαλισμό. Στην παρούσα εργασία συγκρίνουμε την απόδοση του με άλλα εποπτευόμενα συστήματα που συμμετέχουν στον διαγωνισμό, δίνοντας ιδιαίτερη προσοχή στην ανάλυση διαφορετικών δέντρων της ίδιας γλώσσας. Επίσης συγκρίνουμε το σύστημά μας με έναν απεξαξιοποιημένο αναλυτή για τις Ρομαντικές γλώσσες και εκμεταλλευόμαστε την εναρμονισμένη σχολιασμό των Οικουμενικών Εξαρτήσεων για να προτείνουμε μια γλωσσική κατάταξη βασισμένη στη συντακτική απόσταση που έχει κάθε ποικιλία από τις Ρομαντικές γλώσσες.', 'it': "Questo articolo descrive MetaRomance, un parser multilingue basato su regole per le lingue romanze inviato a CoNLL 2017 Shared Task: Analisi multilingue dal testo grezzo alle dipendenze universali. Il sistema è un parser quasi delessicalizzato che non ha bisogno di dati di formazione per analizzare le lingue romanze. Contiene regole motivate linguisticamente basate su modelli di tag PoS. Le regole incluse in MetaRomance sono state sviluppate in circa 12 ore da un esperto senza conoscenze preliminari in Dipendenze Universali, e possono essere facilmente estese utilizzando un formalismo trasparente. In questo articolo confrontiamo le prestazioni di MetaRomance con altri sistemi supervisionati partecipanti al concorso, prestando particolare attenzione all'analisi di diversi banchi degli alberi della stessa lingua. Confrontiamo anche il nostro sistema con un parser delessicalizzato per le lingue romanze e sfruttiamo l'annotazione armonizzata delle dipendenze universali per proporre una classifica linguistica basata sulla distanza sintattica che ogni varietà ha dalle lingue romanze.", 'lt': 'Šiame straipsnyje aprašomas „MetaRomance“ – taisyklėmis pagrįstas tarpkalbis romėnų kalbų analizatorius, pateiktas CoNLL 2017 m. Bendra užduotis: daugiakalbis analizavimas iš žaliavinio teksto į universaliąsias priklausomybes. Sistema yra beveik deleksilizuotas analizatorius, kuriam nereikia mokymo duomenų romėnų kalboms analizuoti. It contains linguistically motivated rules based on PoS-tag patterns.  MetaRomance taisyklės buvo parengtos per maždaug 12 valandų vieno eksperto, kuris iš anksto nesužinojo apie universaliąsias priklausomybes, ir jos gali būti lengvai išplėstos skaidriu formalumu. Šiame dokumente palyginame MetaRomance veiklos rezultatus su kitomis konkurse dalyvaujančiomis prižiūrimomis sistemomis, ypatingą dėmesį skiriant skirtingų tos pačios kalbos medžių juostų analizei. Mes taip pat palyginame savo sistemą su deleksilizuotu kompiuteriu romėnų kalboms ir pasinaudodami suderinta Universaliųjų priklausomybių anotacija siūlome kalbų klasifikavimą, pagrįstą kiekvienos veislės sintaksiniu atstumu nuo romėnų kalbų.', 'kk': 'Бұл мақала, CoNLL 2017 жылы ортақ тапсырмасына жіберілген Романтиялық тілдер үшін ережелер негіздеген көптілік талдаушы MetaRomance дегенді анықтайды: Көптілік талдау мәтіннен әлемдік тәуелдіктерге Бұл жүйе Румындағы тілдерді анализ үшін оқыту деректері қажет емес деген өзгертілген талдаушы. Онда PoS- тегті үлгілеріне негізделген лингвистикалық мотивациялық ережелер бар. Метароманцияда қосылған ережелер 12 сағат бойынша бір эксперт әлемдік тәуелдіктерінің білімі жоқ, және мөлдірлікті оңай офилизмді қолдануға болады. Бұл қағазда MetaRomance жұмысын басқа бақылау жүйелерімен салыстырып, бір тілдің әртүрлі тілдерін талдау үшін өзгертіп тұрмыз. Мұндай-ақ біз жүйемізді Румындық тілдер үшін делексикализацияланған талдаушылармен салыстырып, әрбір түрлі түрлі тілдердің синтактикалық қашықтығына негізделген тілдерді қолдану үшін Universal Dependencies жазбаларының арнаулығын қолд', 'mk': 'Оваа статија ја опишува Метатроманција, прекујазичен анализатор за романски јазици базиран на правила, поднесен на CoNLL 2017. Соделена задача: Мултијазичен анализатор од суров текст до универзални зависности. Системот е речиси делексикализиран анализатор кој нема потреба од податоци за обука за анализирање на романските јазици. Таа содржи јазички мотивирани правила базирани на шеми на PoS-tag. Правилата вклучени во Метатроманција беа развиени за околу 12 часа од еден експерт без претходно знаење во универзалните зависности, и лесно може да се продолжи со транспарентен формализам. Во овој документ ја споредуваме изведбата на Метатроманс со другите надгледувани системи кои учествуваат во натпреварот, посебно внимание врз анализирањето на различните дрвја на истиот јазик. We also compare our system with a delexicalized parser for Romance languages, and take advantage of the harmonized annotation of Universal Dependencies to propose a language ranking based on the syntactic distance each variety has from Romance languages.', 'ms': 'Artikel ini menggambarkan MetaRomance, penghurai saling bahasa berdasarkan peraturan untuk bahasa Romance dihantar kepada CoNLL 2017 Tugas Berkongsi: Penghuraian Berbahasa Dari Teks Raw ke Dependensi Universal. Sistem ialah penghurai hampir diselesaikan yang tidak memerlukan data latihan untuk menganalisis bahasa Romansi. Ia mengandungi peraturan motivasi secara bahasa berdasarkan corak-tag PoS. The rules included in MetaRomance were developed in about 12 hours by one expert with no prior knowledge in Universal Dependencies, and can be easily extended using a transparent formalism.  In this paper we compare the performance of MetaRomance with other supervised systems participating in the competition, paying special attention to the parsing of different treebanks of the same language.  Kita juga membandingkan sistem kita dengan penghurai deleksikal untuk bahasa Romans, dan mengambil keuntungan dari anotasi harmonisasi Dependensi Universal untuk melamar rangkaian bahasa berdasarkan jarak sintaktik setiap jenis mempunyai dari bahasa Romans.', 'mt': 'Dan l-artikolu jiddeskrivi MetaRomance, parser translingwistiku bbażat fuq ir-regoli għal-lingwi Romani sottomess lill-CoNLL 2017 Kompitu Konġunt: Parsing Multilingwistiku minn Test Prim għal Dipendenzi Universali. Is-sistema hija parser kważi delissikalizzat li ma jeħtieġx dejta ta’ taħriġ biex janalizza l-lingwi Romani. Fih regoli motivati lingwistikament ibbażati fuq mudelli PoS-tag. Ir-regoli inklużi fil-MetaRomance ġew żviluppati f’madwar 12-il siegħa minn espert wieħed mingħajr għarfien minn qabel fid-Dipendenzi Universali, u jistgħu jiġu estiżi faċilment bl-użu ta’ formaliżmu trasparenti. F’dan id-dokument aħna nqabblu l-prestazzjoni tal-MetaRomance ma’ sistemi oħra sorveljati li jipparteċipaw fil-kompetizzjoni, filwaqt li nagħtu attenzjoni speċjali lill-analiżi ta’ għelieqi differenti tas-siġar tal-istess lingwa. Aħna nqabblu wkoll is-sistema tagħna ma’ analizzatur delessikalizzat għall-lingwi Romani, u napprofittaw mill-annotazzjoni armonizzata tad-Dipendenzi Universali biex nipproponu klassifikazzjoni lingwistika bbażata fuq id-distanza sintattika li kull varjetà għandha mil-lingwi Romani.', 'mn': 'Энэ баримт "MetaRomance"-г, Романчуудын хэлний гишүүн дээрх олон хэл хуваалцагч, CoNLL 2017 оны хуваалцагдсан ажил: Raw Text-ээс олон хэл хуваалцах нь ертөнцийн хамааралтай. Энэ систем нь Ромын хэлний хэлний шинжилгээнд сургалтын өгөгдлийг шалгахын тулд бараг сэргээгдсэн хуваарч юм. Энэ нь PoS-Tag хэлбэрээр үндсэн хэлний урам зориулсан дүрмийг агуулдаг. MetaRomance-д оролцсон дүрмийг 12 цагт нэг мэргэжилтэн универсалд хамааралтай мэдлэгтэй байсан бөгөөд түүний тодорхой официализмыг ашиглан амархан нэмэгдүүлж чадна. Энэ цаасан дээр бид MetaRomance-ын үйл ажиллагааг дамжуулалт дээр оролцож бусад удирдагчийн системтэй харьцуулж, ижил хэл дээрх өөр хэлбэрийн дамжуулалтын хуваалцааны анхаарлыг удирдаж байна. Мөн бид өөрсдийн системийг романдын хэлний хувьд хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны хувьцааны тусламжтай харьцуулж, олон', 'pl': 'W tym artykule opisano MetaRomance, oparty na regułach parser wielojęzyczny dla języków romańskich przesłanych do CoNLL 2017 Wspólne zadanie: Parsowanie wielojęzyczne z tekstu surowego do zależności uniwersalnych. System jest niemal deleksykalizowanym parserem, który nie potrzebuje danych treningowych do analizy języków romańskich. Zawiera językowo motywowane reguły oparte na wzorcach tagów PoS. Zasady zawarte w MetaRomance zostały opracowane w ciągu około 12-godzin przez jednego eksperta bez wcześniejszej wiedzy w zakresie zależności powszechnych i mogą być łatwo rozszerzone za pomocą przejrzystego formalizmu. W artykule porównujemy wydajność MetaRomance z innymi systemami nadzorowanymi biorącymi udział w konkursie, zwracając szczególną uwagę na analizę różnych banków drzew tego samego języka. Porównujemy również nasz system z deleksykalizowanym parserem języków romańskich i wykorzystujemy zharmonizowaną adnotację uniwersalnych zależności, aby zaproponować ranking językowy oparty na odległości składniowej każdej odmiany od języków romańskich.', 'ro': 'Acest articol descrie MetaRomance, un parser multilingv bazat pe reguli pentru limbile romance trimis la CoNLL 2017 Shared Task: Parsing multilingv de la text brut la dependențe universale. Sistemul este un parser aproape delexicalizat care nu are nevoie de date de instruire pentru a analiza limbile romance. Acesta conține reguli motivate lingvistic bazate pe modele PoS-tag. Regulile incluse în MetaRomance au fost elaborate în aproximativ 12 ore de către un expert fără cunoștințe prealabile în Dependențe Universale și pot fi extinse cu ușurință folosind un formalism transparent. În această lucrare comparăm performanțele MetaRomance cu alte sisteme supravegheate participante la competiție, acordând o atenție deosebită analizării diferitelor bănci de copac din aceeași limbă. De asemenea, comparăm sistemul nostru cu un parser delexicalizat pentru limbile romance și profităm de adnotările armonizate ale Dependențelor Universale pentru a propune un clasament lingvistic bazat pe distanța sintactică pe care fiecare varietate o are de limbile romance.', 'no': 'Denne artikkelen beskriver MetaRomance, eit regelbasert krysspråk- tolkar for romske språk som er sendt til CoNLL 2017 Delt oppgåve: Multispråk tolking frå Raw Text til universelle avhengighet. Systemet er ein nesten deleksisert tolkar som ikkje treng opplæringsdata for å analysera romske språk. Det inneheld språkstisk motiverte reglar basert på PoS- merkemønsterelement. Reglane som er inkludert i MetaRomance ble utvikla i omtrent 12 timar av ein ekspert utan førre kunnskap i universelle avhengighet, og kan lett utvideast med eit gjennomsiktig formalisme. I denne papiret samanliknar vi utviklinga av MetaRomance med andre oversikte systemer som deltar i konkurransen, og har spesielt oppmerksomhet til tolking av ulike treebanklar i det same språket. Vi sammenliknar også systemet vårt med ein deleksikalisert analyser for romske språk, og tar nyttig av den harmoniserte annotasjonen av universelle avhengighet for å foreslå eit språkkranking basert på den syntaktiske avstanden kvar variasjon har frå romske språk.', 'so': 'Warqaddan waxaa loola jeedaa MetaRomance, a rule-based cross-language Parser for Romanse language submitted to CoNLL 2017 Shaqad Shared: Parsing luuqado badan from Raw Text to Universal Dependences. nidaamka waa baaritaanka loo qeybiyay oo aan u baahnayn macluumaad lagu baahan karo si ay u analysaan luuqadaha Rooma. Waxaa ku qoran sharciyada luuqadda la hagayo oo ku saleysan qaababka PoS-tag. Sharciyada ku qoran MetaRomance waxay horumariyeen qiyaastii 12 saacadood, mid gaar ah oo aan aqoon hore ku lahayn xirfadaha jaamacadaha, waxaana si fudud loogu fidin karaa isticmaalka rasmiga muuqashada. Qoraalkan waxaynu isbarbardhignaa muuqashada MetaRomance iyo nidaam kale oo ilaaliyey oo ka qayb gala tartanka, waxaana si gaar ah u dhegaysanaynaa baarlamaanka qoraalka kala duduwan ee isku luqada. Sidoo kale waxaynu isbarbardhignaa nidaamka oo la barbaarinayo kala duwan luqadaha Romansiyada, waxaana isticmaalaynaa dhibaatada la isku dayo ee iskudarka jaamacadda, si aan u soo jeedno luqada aad u kala duwan leedahay dhinacyada rasmiga ah.', 'sr': 'Ovaj članak opisuje MetaRomance, međujezički pretraživač na pravilima za rumunske jezike podignut na CoNLL 2017 podeljeni zadatak: Multilingual Parsing from Raw Text to Universal Dependencies. Sistem je skoro deleksikaliziran analizator koji ne treba podatke za obuku za analiziranje rumunskih jezika. Ona sadrži jezički motivisana pravila na osnovu obrazaca PoS-tag. Pravila uključena u MetaRomance razvila je jedan stručnjak za oko 12 sati bez prethodnih znanja u univerzalnim zavisnicama, i može se lako proširiti koristeći transparentni formalizm. U ovom papiru uspoređujemo izvršnost MetaRomance sa drugim nadzornim sistemima koji sudjeluju u konkurenciji, obraćajući posebnu pažnju na analizu različitih područja istih jezika. Također uspoređujemo naš sistem sa deleksikaliziranom analizatorom rumunskih jezika, i iskoristimo harmoniziranom annotacijom univerzalnih zavisnosti da predložimo jezički ranking na temelju sintaktičke udaljenosti koje svaka raznolikost ima od rumunskih jezika.', 'ml': 'ഈ ലിപ്പോര്\u200dട്ട് മെറ്റാറോമാന്\u200dസിനെ വിശദീകരിക്കുന്നു, ഒരു നിയമപരമായ ക്രില്\u200dലിങ്ങ് ഭാഷകള്\u200dക്കായി റോമാന്\u200dസ് ഭാഷകള്\u200dക്കായി കോണല്\u200d 2017 പങ്കു ഈ സിസ്റ്റത്തില്\u200d ഒരു പ്രധാനപ്പെടുത്തിയ പ്രദര്\u200dശനമാണ്. റോമാന്\u200dസ് ഭാഷകളെ അന്വേഷിക്കാന്\u200d പരിശീലിപ്പി പോസ്-ടാഗ് മാതൃകങ്ങള്\u200d അടിസ്ഥാനമാക്കിയ ഭാഷക്കാരില്\u200d നിയമങ്ങള്\u200d ഉണ്ട്. മെറ്റാറോമാന്\u200dസില്\u200d ഉള്ള നിയമങ്ങള്\u200d 12 മണിക്കൂറിനുള്ളില്\u200d നിര്\u200dമ്മിക്കപ്പെട്ടിരുന്നു. യൂണിവര്\u200dണണല്\u200d ഡിപ്പെന്\u200dസികളില്\u200d മുമ്പ് അറിവ ഈ പത്രത്തില്\u200d നമ്മള്\u200d മെറ്റാറ്റോമാന്\u200dസിന്\u200dറെ പ്രകടനത്തെ താല്\u200dപ്പര്യമാക്കുന്നു. മറ്റു നിരീക്ഷിക്കപ്പെട്ട സിസ്റ്റമുകളുമായി മത്സരത നമ്മുടെ സിസ്റ്റത്തിനെയും റോമാന്\u200dസിന്റെ ഭാഷകള്\u200dക്കുള്ള ഒരു ഡെക്സിക്സിക്കേഷന്\u200d പരാജയപ്പെടുത്തുന്നതിനെയും നമ്മുടെ സിസ്റ്റത്തിനെയും തുല്യമാക്കു', 'sv': 'I den här artikeln beskrivs MetaRomance, en regelbaserad flerspråkig tolkning för romanska språk som skickas till CoNLL 2017 Delad uppgift: Flerspråkig tolkning från råtext till universella beroende. Systemet är en nästan delexikaliserad parser som inte behöver utbildningsdata för att analysera romanska språk. Den innehåller språkligt motiverade regler baserade på PoS-taggmönster. Reglerna som ingår i MetaRomance utvecklades på cirka 12 timmar av en expert utan förkunskaper i Universal Dependences, och kan enkelt utökas med hjälp av en transparent formalism. I denna uppsats jämför vi MetaRomances prestanda med andra övervakade system som deltar i tävlingen, med särskild uppmärksamhet på tolkningen av olika trädbanker av samma språk. Vi jämför också vårt system med en delexikaliserad parser för romanska språk, och drar nytta av den harmoniserade kommenteringen av Universal Dependences för att föreslå en språkrankning baserad på det syntaktiska avståndet varje sort har från romanska språk.', 'ur': 'This article describes MetaRomance, a rule-based cross-lingual parser for Romance languages submitted to CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. سیسٹم تقریباً حذف کردیا گیا پارچر ہے جو رومانس زبانوں کا تحلیل کرنے کے لئے دکھانے کی ضرورت نہیں ہے۔ اس میں پوس ٹاگ پٹرنوں پر بنیادی زبان کے ذریعہ منتخب ہوئے قانون ہیں. MetaRomance میں شامل ہوئے قوانین 12 گھنٹوں میں ایک متخصص کے ذریعے ایک علم کی وجہ سے گھیر لیا گیا تھا جس سے پہلے کوئی علم نہ تھا وہاں ایک روشن روشنی کے ذریعے آسانی طرح پھیلائی جاتی ہے۔ اس کاغذ میں ہم MetaRomance کی عملکرد کو دوسری نظام کے ساتھ مقابلہ کرتے ہیں جو مسابلہ میں شامل ہوتے ہیں، اور ایک ہی زبان کی مختلف ٹریب بانک کے پارس کرنے کے لئے خاص توجه کرتے ہیں. اور ہم نے اپنے سیستم کو رومانس زبانوں کے لئے ایک ڈیلکسیکیسی پیٹر کے ساتھ مقایسہ کر دیا ہے اور ہر مختلف مختلف رومانس زبانوں سے ایک زبان رینگ کا پیشنهاد کرنا ہے۔', 'ta': 'இந்த கட்டுரை மெட்ரான்ஸ், ஒரு விதிமுறையான குறும்மொழி பரிசோதனையை கோன்எல் 2017 க்கு கொடுக்கப்பட்ட பணிக்கு கூடிய காட்சிக்கு வரையறுக்கும் விதி இந்த அமைப்பு ஒரு கிட்டத்தட்ட பிரிவாக்கியமைக்கப்பட்ட பரப்பான் It contains linguistically motivated rules based on PoS-tag patterns.  மெடாரன்ஸில் சேர்க்கப்பட்ட விதிகள் 12 மணி நேரத்திற்குள் உருவாக்கப்பட்டுள்ளது. உலக சார்ந்த சார்புகளில் முன்னால் அறிவு இல்லாத ஒரு அறிவிப இந்த காகிதத்தில் நாம் மெடாரோமான்ஸின் செயல்பாட்டை ஒப்பிடுகிறோம் மற்ற கண்காணிக்கப்பட்ட கணினிகளுடன் போரிடுவதில் ஒப்பிடுகிறோம ரோமான்ஸ் மொழிகளுக்கு நாம் எங்கள் கணினியை ஒப்பிடுகிறோம், மற்றும் உலக சார்ந்த சார்புகளின் ஒத்திசைப்படுத்தப்பட்ட மொழியை பயன்படுத்துகிறோம். ஒவ்வொரு', 'si': 'මේ ලේඛනය මෙටාරෝමින්ස් විස්තර කරනවා, රෝමින්ස් භාෂාව සඳහා නියෝජිත විශාල භාෂාවක් විස්තර කරනවා CoNLL 2017 සමාගත වැඩිය වැඩි පද්ධතිය තමයි රෝමාන්සි භාෂාව විශ්ලේෂනය කරන්න ප්\u200dරශ්නය දත්ත අවශ්\u200dය නැති විශ්ලේෂණය කරන්න ප ඒකේ භාෂාවික විදියට පොස් ටැග් පෙට්ටර් වලට අධාරිත නීතිය තියෙනවා. මෙටාරෝමින්ස් වල ඇතුළත් නීතියක් පැය 12 ගානක් විශ්වාස කරලා තියෙන්නේ විශේෂ විශේෂ විශේෂ විශේෂ විශේෂ විදිය මේ පත්තරේ අපි මෙටා රෝමාන්ස්ගේ ප්\u200dරමාණය සමග අනිත් ප්\u200dරධාන පද්ධතිය සමග සම්බන්ධ කරනවා, එකම භාෂාවේ වෙනස් බ්\u200dරීබැන්ක් ව අපි අපේ පද්ධතියට රෝමාන්ස් භාෂාවල් සඳහා ප්\u200dරතික්ෂිත විශ්වාසයෙන් සම්බන්ධ කරනවා, සම්බන්ධ විශ්වාසික විශ්වාසයේ සම්බන්ධ කරලා ති', 'vi': 'Bài viết này mô tả MetaRomance, một nhà phân tách ngôn ngữ khác nhau phổ biến cho ngôn ngữ Romance được gửi cho CLB "Trợ giúp"! Hệ thống này là một phân tích hầu như có lỗi, không cần dữ liệu đào tạo để phân tích ngôn ngữ Romance. Nó chứa các quy tắc ngôn ngữ dựa trên các mẫu thẻ xanh. Những quy tắc trong MetaRomance đã được phát triển trong khoảng 12h tiếng bởi một chuyên gia không có kiến thức về sự phụ thuộc chung, và có thể được mở rộng dễ dàng bằng một thủ tục trong suốt. Trong tờ giấy này, chúng tôi so sánh hiệu quả của MetaRomance với các hệ thống giám sát khác nhau tham gia cuộc thi, đặc biệt chú ý đến cách phân tách các loại máy móc khác nhau của cùng một ngôn ngữ. Chúng tôi cũng so sánh hệ thống của chúng tôi với một cha xứ thần thoại cho ngôn ngữ Romance, và sử dụng cẩn thận hóa ghi chú về sự phụ thuộc chung chung để đề xuất xếp thứ bậc ngôn ngữ dựa trên độ dài cú pháp mỗi loại có từ ngôn ngữ Romance.', 'uz': "Name Name Name Name Ushbu sahifani biz MetaRomannising ijodkorligini o'zgartirib turgan boshqa taʼminlovchi tizimlar bilan o'xshash qilamiz, va bir tillardan boshqa suhbat suhbatlarini o'zgarishga tayyorlash mumkin. Biz buning tizimimizni rasm tillari uchun deleksikatlik boʻlgan parametrlar bilan kamaytirimiz va Universal Dependenclarining tashkilotlaridan foydalanamiz. Biz har bir xil soʻzni Rumincha tillaridagi bir xil darajaga asoslangan tilni tasavvur qilish uchun foydalanamiz.", 'bg': 'Тази статия описва базиран на правила междуезичен анализатор за романски езици, представен на споделена задача: многоезично анализиране от суров текст до универсални зависимости. Системата е почти дексикализиран анализатор, който не се нуждае от данни за обучение, за да анализира романските езици. Съдържа лингвистично мотивирани правила, базирани на шаблони. Правилата, включени в МетаРоманс, са разработени за около 12 часа от един експерт без предварителни познания по универсални зависимости и могат лесно да бъдат удължени с помощта на прозрачен формализъм. В настоящата статия сравняваме представянето на МетаРоманс с други контролирани системи, участващи в конкурса, като обръщаме специално внимание на анализирането на различни дървесни ленти на един и същ език. Също така сравняваме нашата система с делексикализиран анализатор за романски езици и се възползваме от хармонизираната анотация на Универсални зависимости, за да предложим езиково класиране въз основа на синтактичното разстояние, което всеки сорт има от романските езици.', 'nl': 'Dit artikel beschrijft MetaRomance, een regelgebaseerde meertalige parser voor Romaanse talen die is ingediend bij CoNLL 2017 Gedeelde taak: Meertalige Parsing van ruwe tekst naar universele afhankelijkheden. Het systeem is een bijna gedexexicaliseerde parser die geen trainingsgegevens nodig heeft om Romaanse talen te analyseren. Het bevat taalkundig gemotiveerde regels gebaseerd op PoS-tag patronen. De regels van MetaRomance zijn in ongeveer twaalf uur ontwikkeld door één expert zonder voorkennis in Universele Afhankelijkheden en kunnen eenvoudig worden uitgebreid met behulp van een transparant formalisme. In dit artikel vergelijken we de prestaties van MetaRomance met andere begeleide systemen die deelnemen aan de competitie, waarbij we speciale aandacht besteden aan het parsen van verschillende boombanken van dezelfde taal. We vergelijken ons systeem ook met een delexicaliseerde parser voor Romaanse talen en maken gebruik van de geharmoniseerde annotatie van Universele Afhankelijkheden om een taalrangschikking voor te stellen op basis van de syntactische afstand die elke variëteit heeft van Romaanse talen.', 'da': 'Denne artikel beskriver MetaRomance, en regelbaseret tværsproget fortolker til romanske sprog, der sendes til CoNLL 2017 Delt opgave: Flersproget fortolkning fra rå tekst til universelle afhængigheder. Systemet er en næsten delekskaliseret fortolker, som ikke behøver træningsdata til at analysere romanske sprog. Den indeholder sprogligt motiverede regler baseret på PoS-tag mønstre. Reglerne i MetaRomance blev udviklet på ca. 12 timer af en ekspert uden forudgående viden om universelle afhængigheder og kan nemt udvides ved hjælp af en gennemsigtig formalisme. I denne artikel sammenligner vi MetaRomances ydeevne med andre overvågede systemer, der deltager i konkurrencen, med særlig opmærksomhed på tolkningen af forskellige træbanker af samme sprog. Vi sammenligner også vores system med en delekskaliseret fortolker for romanske sprog, og drager fordel af den harmoniserede annotation af universelle afhængigheder til at foreslå en sprograngering baseret på den syntaktiske afstand hver sort har fra romanske sprog.', 'hr': 'Ovaj članak opisuje MetaRomance, međujezički analitičar na pravilima za rumunske jezike podignut CoNLL 2017. zajedničkom zadatku: multijezičko analiziranje od sirovog teksta na univerzalne zavisnosti. Sistem je skoro deleksikiran analitičar koji ne treba podatke za obuku za analiziranje rumunskih jezika. sadrži jezički motivirana pravila na temelju obrazaca PoS-tag. Pravila uključena u MetaRomance razvila je jedan stručnjak za oko 12 sati bez prethodnih znanja u univerzalnim ovisnostima i može se lako proširiti koristeći transparentni formalizm. U ovom papiru uspoređujemo učinkovitost MetaRomance s drugim nadzornim sustavima koji sudjeluju u natjecanju, obraćajući posebnu pažnju na analizu različitih treebana istih jezika. Također uspoređujemo naš sustav sa deleksikaliziranom analizatorom rumunskih jezika, i iskoristimo harmoniziranom annotacijom univerzalnih zavisnosti kako bi predložili jezički redoviti na temelju sintaktičke udaljenosti koje svaka raznolikost ima iz rumunskih jezika.', 'de': 'Dieser Artikel beschreibt MetaRomance, einen regelbasierten, mehrsprachigen Parser für romanische Sprachen, der an CoNLL 2017 übermittelt wurde. Das System ist ein fast delexikalisierter Parser, der keine Trainingsdaten benötigt, um romanische Sprachen zu analysieren. Es enthält sprachlich motivierte Regeln, die auf PoS-Tag-Mustern basieren. Die in MetaRomance enthaltenen Regeln wurden in etwa zwölf Stunden von einem Experten ohne Vorkenntnisse in Universellen Abhängigkeiten entwickelt und können durch einen transparenten Formalismus leicht erweitert werden. In diesem Beitrag vergleichen wir die Leistung von MetaRomance mit anderen überwachten Systemen, die am Wettbewerb teilnehmen, wobei besonderes Augenmerk auf das Parsen verschiedener Baumbänke derselben Sprache gelegt wird. Wir vergleichen unser System auch mit einem delexikalisierten Parser für romanische Sprachen und nutzen die harmonisierte Annotation von universellen Abhängigkeiten, um ein Sprachranking basierend auf der syntaktischen Distanz jeder Sorte zu romanischen Sprachen vorzuschlagen.', 'id': 'Artikel ini menggambarkan MetaRomance, penganalis saling bahasa berdasarkan aturan untuk bahasa Romance yang dikirim ke CoNLL 2017 Shared Task: Penganalis berbagai bahasa dari Teks Raw ke Dependensi Universal. Sistem ini adalah parser yang hampir berantakan yang tidak membutuhkan data latihan untuk menganalisis bahasa Romans. Ini mengandung aturan berbakti bahasa berdasarkan pola PoS-tag. Aturan yang termasuk dalam MetaRomance dikembangkan dalam sekitar 12 jam oleh satu ahli tanpa pengetahuan sebelumnya di Universal Dependencies, dan dapat mudah diperpanjang menggunakan formalisme transparan. Dalam kertas ini kita membandingkan pertunjukan MetaRomance dengan sistem yang lainnya yang diawasi yang berpartisipasi dalam kompetisi, memperhatikan spesial pada penghuraian batang pohon yang berbeda dari bahasa yang sama. Kami juga membandingkan sistem kami dengan parser deleksikal untuk bahasa Romans, dan mengambil keuntungan dari anotasi harmonisasi dari Dependensi Universal untuk mengusulkan rangkaian bahasa berdasarkan jarak sintaksi setiap variasi memiliki dari bahasa Romans.', 'ko': '본고는 MetaRoman을 소개했는데 이것은 규칙을 바탕으로 하는 다중 언어 문법 분석기로서 CoNLL 2017 공유 작업에 제출된 Roman 언어: 원시 텍스트부터 통용 의존항까지의 다중 언어 문법 분석에 적용된다.이 시스템은 거의 멕시코화 해상도로 로맨스 언어를 분석하기 위한 훈련 데이터가 필요 없다.그것은 단어적 표기 패턴을 바탕으로 하는 언어 규칙을 포함한다.메타로망스에 포함된 규칙은 보편적 의존성을 사전에 알지 못한 전문가가 약 12시간 만에 개발한 것으로 투명한 형식주의로 쉽게 확장할 수 있다.본고에서 우리는 MetaRoman과 다른 경쟁에 참여하는 감독 시스템의 성능을 비교했고 특히 같은 언어의 서로 다른 트리 라이브러리의 해석에 주목했다.또한 우리의 시스템과 로맨스 언어에 사용되는 탈서구화 해석기를 비교하고 유니버설 의존항의 조화로운 주석을 이용하여 각 변체와 로맨스 언어 간의 문법 거리에 따라 언어 순위를 제시했다.', 'fa': 'این مقاله مترومانس را توصیف می\u200cکند، یک بازیگر مترومانس بر اساس قانونی برای زبانهای رومانسی که به کار مشترک CoNLL 2017 ارسال شده است: بازیگر مترومانسی از متن Raw به بستگی جهانی. این سیستم تقریباً یک بازیگر تقریباً نابود شده است که نیاز به داده آموزش برای تحلیل زبانهای رومانسی نیست. شامل قانون انگیزه زبانی بر اساس الگوهای PoS-tag است. قانونی که در مترومانس شامل شده\u200cاند در حدود ۱۲ ساعت توسط یک متخصص توسط هیچ دانش پیشینی در بستگی جهانی وجود نداشته\u200cاند، توسط یک قانون شفافیت به آسانی گسترش داده می\u200cشود. در این کاغذ ما عملکرد مترومانس را با سیستم های مترومانس که در مسابقه مشارکت می کنند مقایسه می کنیم، و توجه ویژه به پالاس کردن پالایه های متفاوت از زبان یکسان می دهیم. ما همچنین سیستم\u200cمان را با یک بازیگر نازل شده برای زبان رومانسی مقایسه می\u200cکنیم، و از نوشته\u200cهای هماهنگی اعتمادی جهانی استفاده می\u200cکنیم تا یک امتیاز زبانی را پیشنهاد دهیم که بر اساس فاصله\u200cهای سنتاکتیک هر گونه گونه از زبان رومانسی دارد.', 'sw': 'Makala hii inaelezea MetaRomance, mchambuzi wa lugha mbalimbali za utawala kwa lugha za KiRomani zilizowasilishwa kwa CoNLL 2017: Kuchapisha lugha nyingi kutoka Raw text hadi Utegemeo wa Kimataifa. Mfumo huu ni mchanganyiko wa karibu unaofanywa na ubaguzi ambao hauhitaji taarifa za mafunzo ili kuchambua lugha za KiRomania. Ina sheria zinazohamasishwa kwa lugha kwa kutumia mitindo ya PoS. Sheria zilizojumuishwa katika MetaRomance zilianzishwa kwa takriban masaa 12 na mtaalam mmoja ambaye hakuna ufahamu wa zamani katika Mategemeo ya Ulimwengu, na inaweza kuongezeka kwa urahisi kwa kutumia utaratibu wa wazi. Katika gazeti hili tunalinganisha ufanisi wa MetaRomance na mifumo mingine inayofuatiliwa kushiriki mashindano hayo, tukizingatia msimamo maalum wa wimbo tofauti wa lugha hiyo. Pia tunalinganisha mfumo wetu na mchambuzi wa lugha za KiRomania, na tunatumia matumizi ya kuchanganyikiwa na matangazo ya Ulimwengu wa Ulimwengu ili pendekeza lugha yenye rangi inayotengenezwa kwa msingi wa kiwango cha ushirikiano kila aina yake inatokana na lugha za KiRomania.', 'sq': 'Ky artikull përshkruan MetaRomance, një analizues ndërgjuhësor bazuar në rregulla për gjuhët romake të dërguar në CoNLL 2017 Task Shared: Multilingual Parsing from Raw Text to Universal Dependencies. The system is an almost delexicalized parser which does not need training data to analyze Romance languages.  Ajo përmban rregulla të motivuara gjuhësisht bazuar në modelet PoS-tag. Rregullat e përfshira në MetaRomance u zhvilluan për rreth 12 orë nga një ekspert pa njohuri të mëparshme në Varësitë Universale dhe mund të zgjerohen lehtë duke përdorur një formalizëm transparent. Në këtë letër krahasojmë shfaqjen e MetaRomance me sisteme të tjerë të mbikqyrur që marrin pjesë në konkurs, duke i kushtuar vëmendje të posaçme analizimit të bazave të pemëve të ndryshme të të njëjtës gjuhë. Ne gjithashtu krahasojmë sistemin tonë me një analizues të deleksifikuar për gjuhët romake dhe përfitojmë nga anotimi i harmonizuar i Varësive Universale për të propozuar një renditje gjuhësh bazuar në distancën sintaktike që çdo varietet ka nga gjuhët romake.', 'am': 'ይህ ጽሑፍ ማትሮማንስ፣ የሥርዓት-መተላለፊያ ቋንቋ መተላለፊያ ለሮማሲ ቋንቋዎች ለኮንഎല_2017የተሰራው ስራ እንዲሰጥ ይናገራል፤ ከRaw Text ወደ Universal Dependences ብዙ ቋንቋዎች ማዘጋጀት ነው፡፡ ሲስተምሩ የራሳቸውን ቋንቋዎች ለማስተምር የሚያስፈልገው ዳታዎችን አያስፈልግም፡፡ በቋንቋው ውስጥ የፖስስ-tag ዓይነቶች የተመሳሳይ ሥርዓቶች ውስጥ ይኖራል፡፡ በሜትሮማኒስ ውስጥ ያሉት ሥርዓቶች በ12 ሰዓት ውስጥ አስቀድሞ የዓለማዊ ድጋፍ እውቀት ሳይኖር አንድ አስተማሪ ተዘጋጅተዋል፡፡ በዚህ ፕሮግራም የሜትሮማኖስን ድምፅ እናሳያታለን፣ በተለዩ ቋንቋ ላይ የተለየውን የዛፎች ማኅበረሰብ እናስከትላለን፡፡ ደግሞም ሲስተኛችንን ለሮማሲ ቋንቋዎች በተመሳሳይ እናሳያታለን፣ የዓለማዊ ደጋፊዎች በተመሳሳይ ቋንቋ ላይ በተመሳሳይ የሮማሲ ቋንቋ የሚኖረውን የቋንቋን መግለጫ እናጠቃታለን፡፡', 'hy': "This article describes MetaRomance, a rule-based cross-lingual parser for Romance languages submitted to CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies.  Համակարգը գրեթե դելեքսիկալիզացված վերլուծում է, որը չի անհրաժեշտ կրթության տվյալներ ռոմանական լեզուների վերլուծության համար: Այն պարունակում է լեզվաբանական մոտիվացված կանոններ, որոնք հիմնված են PoS-տակ կաղապարների վրա: Մետառոմանսիայում ներառված կանոնները զարգացել են մոտ 12 ժամվա ընթացքում մի մասնագետի կողմից, որն առանց նախորդ գիտելիքների համաշխարհային կախվածություններում, և դրանք հեշտությամբ կարող են ընդլայնվել թափանցիկ ձևավորման միջ In this paper we compare the performance of MetaRomance with other supervised systems participating in the competition, paying special attention to the parsing of different treebanks of the same language.  Մենք նաև համեմատում ենք մեր համակարգը ռոմանական լեզուների դելեքսիկալիզացված խմբագրիչի հետ և օգտագործում ենք Համաշխարհային Համակարգվածությունների համընդհանուր գրառումը' առաջարկելու լեզվի դասակարգման, որը հիմնված է յուրաքանչյուր տեսակի սինտակտիկ հեռավորության վրա", 'az': "Bu m…ôktub, CoNLL 2017-ci CoNLL paylaŇüdńĪrńĪlmńĪŇü M…ôktub'a g√∂nd…ôril…ôn Roma dill…ôrinin √ßoxlu dil analizi MetaRomance'i t…ôsdiql…ôyir. Sistem RomalńĪ dill…ôrini analiz…ô etm…ôk √ľ√ß√ľn t…ôhsil etm…ôk lazńĪmdńĪr. Bu, PoS-tag √∂rt√ľkl…ôrin…ô dayanan dilind…ô motivatlńĪ kurallar bar…ôsind…ôdir. MetaRomance-da daxil edil…ôn kurallar 12 saat i√ßind…ô √ľniversal bańüńĪmlńĪqlarńĪnda …ôvv…ôlki bilgi olmayan bir ekspertin t…ôŇükil edildi v…ô a √ßńĪq formalizm vasit…ôsil…ô asanlńĪqla geniŇül…ônir. Bu kańüńĪtda MetaRomance performansńĪnńĪ m√ľharib…ôsind…ô m√ľharib…ôy…ô katńĪlan baŇüqa g√∂zl…ôyirli sisteml…ôrl…ô qarŇüńĪlaŇüdńĪrńĪrńĪq, eyni dilin m√ľxt…ôlif √ß…ôkid…ô √ß…ôkilm…ôsin…ô x√ľsusiyy…ôt veririk. Biz h…ôm√ßinin sistemimizi RomalńĪ dill…ôrin deleksiksikalizirl…ôndirilmiŇü ayńĪrńĪcńĪ il…ô qarŇüńĪlaŇüdńĪrńĪrńĪq v…ô h…ôr c√ľr m√ľxt…ôlif dill…ôrin Romanca dill…ôrind…ôn olan dil d…ôr…ôc…ôsini t…ôklif etm…ôk √ľ√ß√ľn Universel bańüńĪmlńĪlńĪqlarńĪn harmonizirl…ôndirilmiŇü x…ôb…ôrdarlńĪqlarńĪndan faydalanńĪrńĪq.", 'bn': 'এই প্রবন্ধের বর্ণনা হচ্ছে মেটারোমান্স, রোমান্স ভাষার জন্য নিয়ম-ভিত্তিক ক্রাশ-ভাষার প্রসারিত রোমান ভাষার জন্য, যা কএনএল ২০১৭ সালে প্রকা এই সিস্টেম প্রায় একটি প্রায় প্রতিনিধিত্বিত প্রক্রিয়া যা রোমান ভাষাকে বিশ্লেষণ করার জন্য প্রশিক্ষণের ত এটিতে ভাষাভাষায় উৎসাহিত নিয়ম রয়েছে পোস-ট্যাগ প্যান্টারের ভিত্তিক ভাষায়। প্রায় ১২ ঘন্টার মধ্যে মেটারোমান্সের নিয়ম উন্নয়ন করা হয়েছে এক বিশেষজ্ঞ যারা বিশ্ববিদ্যালয়ের পূর্বের জ্ঞান নেই এবং স্বচ্ছতা বিভাগ এই কাগজটিতে আমরা মেটারোমান্সের প্রভাবের তুলনা করি এই প্রতিযোগিতায় অন্যান্য পর্যবেক্ষণকারী সিস্টেমের সাথে অংশগ্রহণ করে, একই ভাষায় বিভি আমরা আমাদের সিস্টেমের সাথে রোমান্স ভাষার প্রতি প্রতিটি বিভিন্ন ভাষার সাথে তুলনা করি এবং বিশ্ববিদ্যালয়ের নির্ভরিত বিভিন্ন ভাষার প্রস্তাব করার জন্য', 'bs': 'Ovaj članak opisuje MetaRomance, međujezički analitičar na pravilima za rumunske jezike podignut CoNLL 2017. zajedničkom zadatku: Multilingual Parsing from Raw Text to Universal Dependencies. Sistem je skoro deleksikaliziran analitičar koji ne treba podatke za obuku za analiziranje rumunskih jezika. Ona sadrži lingvistički motivirana pravila na osnovu obrazaca PoS-tag. Pravila uključena u MetaRomance razvijena je za oko 12 sati jedna stručnjaka bez prethodnih znanja u univerzalnim zavisnicama, te može se lako proširiti koristeći transparentni formalizm. U ovom papiru uspoređujemo učinkovitost MetaRomance sa drugim nadzornim sistemima koji sudjeluju u konkurenciji, obraćajući posebnu pažnju na analizu različitih granica istih jezika. Također uspoređujemo naš sistem sa deleksikaliziranom analizatorom rumunskih jezika, i iskoristimo harmoniziranu annotaciju univerzalnih zavisnosti kako bi predložili jezički rang na temelju sintaktičke udaljenosti koje svaka raznolikost ima iz rumunskih jezika.', 'af': "Hierdie artikel beskryf MetaRomance, 'n reël-gebaseerde kruis-tale ontwerker vir Romas tale wat na CoNLL 2017 gedeelde taak voorgestuur is: Multilingual verwerking van Ro-teks na Universele afhanklikhede. Die stelsel is 'n amper deleksikaliseerde ontleerder wat nie nodig onderwerp data om Romanse tale te analyseer nie. Dit bevat lingwisieslik motiveerde reëls gebaseer op PoS- etiket patrone. Name Die reëls ingesluit in MetaRomance was ontwikkeld in omtrent 12 uur deur een eksperteer met geen voorheede kennis in Universele Afhanklikhede nie, en kan maklik uitbrei word deur 'n deursigtige formalisme. In hierdie papier vergelyk ons die prestasie van MetaRomance met ander ondersoekte stelsels wat in die mededing deel, met spesiaal aandag aan die verwerking van verskillende treebanks van dieselfde taal. Ons vergelyk ons stelsel ook met 'n deleksikaliseerde ontwerker vir Romas tale en neem voordeel van die harmoniseerde annotasie van universele afhanklikhede om 'n taal rangering te voorstel wat gebaseer is op die sintaktieke afstand elke verskilligheid het van Romas tale.", 'tr': "Bu makala MetaRomance'i, Romança dilleri üçin bir karar-dilli analyz edip CoNLL 2017-nji ýylda Paýlaşan Görevi: Raw Metinden Üniversal Baýramlyklara süýtgedi. Bu sistem Romança dillerini analyzmak üçin maglumatlary gerek däldir. PoS etiketlerine dayanan dillerinde nöbet edilen kurallar bar. MetaRomanda dahil edilen kurallar 12 sagat içinde bir uzmanyň tarapyndan öňki bilgi ýok bolmady we dünýädäki bağımlıklarda ukyp bilen döredildi. Bu kagyzda MetaRomansiýanyň başga gözetli sistemalary ýaryşdyrylyp bilen çykyş etmäge has üns berýäris. Biz hem sistemamyzy Roma dilleri üçin deleksizlik çykyşlyk bilen karşılaştyrýarys we her çeşitli görnüşinden bir dil görkezmek üçin Universal Başlyklaryň howlanýan duýularyny ulanýarys.", 'ca': "Aquest article descriu MetaRomance, un analitzador de llengües romàniques basat en regles submetit a CoNLL 2017 Task Shared: Multilingual Parsing from Raw Text to Universal Dependencies. El sistema és un analitzador gairebé desxitalitzat que no necessita dades d'entrenament per analitzar les llengües romàniques. Contén normes motivades lingüísticament basades en patrons PoS-tag. Les normes incloses en MetaRomance van ser desenvolupades en unes 12 hores per un expert sense coneixement previ en Dependencies Universals, i es poden estendre fàcilment fent servir un formalisme transparent. En aquest article comparem l'actuació de MetaRomance amb altres sistemes supervisats que participen a la competició, prestant especial atenció a l'analització de diferents bancs d'arbres de la mateixa llengua. També comparam el nostre sistema amb un analitzador delexicalitzat de llengües romàniques, i aprofitem l'anotació armonizada de Dependencies Universals per proposar una classificació de llengües basada en la distància sinàctica que cada varietat té de llengües romàniques.", 'et': "Selles artiklis kirjeldatakse reeglitel põhinevat romaani keelte vahelist parserit MetaRomance, mis on esitatud CoNLL 2017. aasta jagatud ülesandele: mitmekeelne parsimine toortekstist universaalseteks sõltuvusteks. Süsteem on peaaegu deleksikaliseeritud parser, mis ei vaja koolitusandmeid romaani keelte analüüsimiseks. See sisaldab keeleliselt motiveeritud reegleid, mis põhinevad PoS-sildi mustritel. MetaRomance'is sisalduvad reeglid töötas välja umbes 12 tunniga üks ekspert, kellel puuduvad eelnevad teadmised universaalsetest sõltuvustest, ning neid saab lihtsalt pikendada läbipaistva formaalsuse abil. Käesolevas töös võrdleme MetaRomance'i tulemuslikkust teiste võistlusel osalevate järelevalvesüsteemidega, pöörates erilist tähelepanu sama keele erinevate puupankade parsimisele. Samuti võrdleme oma süsteemi deleksikaliseeritud parseriga romaani keeltele ja kasutame ära universaalsete sõltuvuste harmoneeritud annotatsiooni, et pakkuda keelejärjestust, mis põhineb iga sorti süntaktilisel kaugusel romaani keeltest.", 'fi': 'Tässä artikkelissa kuvataan MetaRomance, sääntöpohjainen monikielinen jäsennysohjelma romanikielille, joka on toimitettu CoNLL 2017:n jaettuun tehtävään: monikielinen jäsennys raakatekstistä universaaleihin riippuvuuksiin. Järjestelmä on lähes deleksikalisoitu parser, joka ei tarvitse koulutustietoja analysoida romanisia kieliä. Se sisältää kielellisesti motivoituja sääntöjä, jotka perustuvat PoS-tagin kuvioihin. MetaRomancen säännöt on kehitetty noin 12 tunnissa yhden asiantuntijan toimesta, jolla ei ole aikaisempaa tietoa yleismaailmallisista riippuvuuksista, ja niitä voidaan helposti laajentaa läpinäkyvällä muodollisuudella. Tässä työssä vertaamme MetaRomancen suorituskykyä muihin kilpailuun osallistuviin valvottuihin järjestelmiin kiinnittäen erityistä huomiota saman kielen eri puiden jäsentämiseen. Vertaamme järjestelmäämme myös deleksikalisoituun romaanisten kielten jäsentäjään ja hyödynnämme Universaalisten riippuvuuksien harmonisoitua merkintää ehdottaaksemme kielirankingia, joka perustuu kunkin lajikkeen syntaktiseen etäisyyteen romaanisista kielistä.', 'cs': 'Tento článek popisuje MetaRomance, vícejazyčný parser založený na pravidlech pro románské jazyky odeslané na CoNLL 2017 Sdílená úloha: vícejazyčné analýzy z surového textu do univerzálních závislostí. Systém je téměř delexikalizovaný parser, který nepotřebuje tréninková data k analýze románských jazyků. Obsahuje lingvisticky motivovaná pravidla založená na vzorcích PoS-tagů. Pravidla obsažená v MetaRomance byla vyvinuta asi za dvanáct hodin jedním odborníkem bez předchozích znalostí v Univerzálních závislostech a lze je snadno rozšířit transparentním formalismem. V tomto článku porovnáváme výkon MetaRomance s ostatními supervizovanými systémy účastnícími se soutěže a věnujeme zvláštní pozornost analýze různých stromových břehů stejného jazyka. Dále porovnáváme náš systém s delexikalizovaným parserem pro románské jazyky a využíváme harmonizované anotace univerzálních závislostí k navržení jazykového řazení založeného na syntaktické vzdálenosti každé odrůdy od románských jazyků.', 'ha': "@ item: inmenu The system is an almost delexicalized parser which does not need training data to analyze Romance languages.  Kana ƙunsa da Rubuwan da aka gabatar da cikin harshen da aka ƙayyade gafakan-tag. Rubuwan da aka shigar da shi a MetaRomce ne aka developed cikin taki 12 hours na wani watani wanda bai da wani ilmi ba a gabatar da Bayani Bayancin Duffai, kuma an iya cire shi da sauƙi a yi amfani da wani formalism mai bayyanãwa. A cikin wannan takarda, Munã samfani mafarin MetaRomce da wasu na'urar tsari masu tsaro da su yi ta haɗa a cikin competarin, kuma munã kiyaye masu hushi ga pargaron turɓãya masu cikin lugha guda. Tuna samfani da tsarin mu da wani taƙaitãwa wa lingui na Romiski, kuma tuna amfani da shirin da aka haɗa masu yiwuwa na Universal Dekur'a ko da za'a gabatar da wata harshe wanda ke danganta a kan salon da dukkan daraja na daga harshen Rumitti.", 'he': 'המאמר הזה מתאר את המטרומנציה, מעבדת שפת צלולת מבוססת על חוקים לשפות רומנטיות שנשלחה ל CoNLL 2017 משימה משותפת: מעבדת רבת שפת מתוך טקסט ראש לתלויות universal. המערכת היא מעבדת כמעט משותקת שלא צריכה נתונים אימונים כדי לנתח שפות רומנטיות. זה מכיל חוקים מוטיבציה לשונית מבוססים על דפוסי תווים POS. החוקים שנמצאים במטרומנסיה פותחו בעוד כ-12 שעות על ידי מומחה אחד ללא ידע קודם בהתלויות Universal, ואפשר להאריך בקלות באמצעות פורמליזם שקל. בעיתון הזה אנחנו משוותים את ההופעה של MetaRomance עם מערכות שולטות אחרות משתתפות בתחרות, שמשמים תשומת לב מיוחדת לאבחן של עצי שונים של אותה שפה. אנחנו משוותים גם את המערכת שלנו עם מעבד משותף לשפות רומנטיות, ונשתמש מהציון הארמוניזני של תלויות יוניברסליות כדי להציע ציור שפה מבוסס על מרחק סינטקטי שכל מגוון יש משפות רומנטיות.', 'sk': 'Ta članek opisuje MetaRomance, večjezični razčlenjevalnik za romanske jezike, ki temelji na pravilih, predložen CoNLL 2017 Shared Task: Večjezično razčlenjevanje iz surovega besedila v univerzalne odvisnosti. Sistem je skoraj deleksikaliziran razčlenjevalec, ki ne potrebuje podatkov o usposabljanju za analizo romanskih jezikov. Vsebuje jezikovno motivirana pravila, ki temeljijo na vzorcih PoS-tag. Pravila, vključena v MetaRomance, je v približno 12 urah razvil en strokovnjak brez predhodnega znanja o univerzalnih odvisnostih in jih je mogoče enostavno podaljšati s preglednim formalizmom. V prispevku primerjamo uspešnost MetaRomance z drugimi nadzorovanimi sistemi, ki sodelujejo na tekmovanju, pri čemer posebno pozornost posvečamo razčlenitvi različnih drevesnih plošč istega jezika. Naš sistem primerjamo tudi z deleksikaliziranim razčlenjevalnikom za romanske jezike in izkoristimo harmonizirano označevanje univerzalnih odvisnosti, da predlagamo razvrstitev jezikov, ki temelji na sintaktični razdalji, ki jo ima vsaka sorta od romanskih jezikov.', 'jv': 'Artiklé iki olaraé meta-rumani, rule-supported inter-language browser for romanic Languages forwarded to CoNLL 1997 shared task: Multilanguage Parasing from Roo Text to Universal dependancies. Sistem kuwi mesthi kapan kelas kanggo disimpen sing ora butuh data nggawe dilakon bangsane rumani. It has language instructed Regulars supported on PuS-tag patterns. Golembak sing katya karo meta-romani sing ditambah luwih dumadhi lawang 12 huran kanggo nguasai perbudhakan sing ora ono sabên kenalé awak dhéwé ning nguasai Universal Nang kuwi iki, kita komparahan kanggo ngerasakno perusahaan meta-rumani karo sistem sing wis nguasai perusahaan, sing wis ngerasakno ité nggo ngerasakno ité perusahaan karo perusahaan langkung sampeyan. Awak dhéwé nggawe sistem karo perusahaan kanggo kelas urip sing perusahaan karo perusahaan kanggo kalaman karo perusahaan sing rumangsa, lan nggawe nguasakno sistem sing dipunangkapan karo perusahaan Universi dipunangkapan kanggo nguasakno sing sampek winih sing sampek kaya langkung sampek sing rumangsa.', 'bo': 'འདིས་ཡིག་གེ་ནང་དུ་MetaRomance་ཡིག་གཟུགས་བརྗོད་བྱས་པ་དེ་རྣམ་གྲངས་based cross-lingual parser for Romance languages submitted to CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. མ་ལག དེའི་ནང་དུ་PoS-tag གཟུགས་རིས་གཞི་བརྟེན་ནས་སྐད་ཡིག་ཆ་ལུགས་ཀྱིས་འགྱུར་བའི་སྲོལ་ཁུངས་ཡོད། ངལ་རྩོམ་པ་གཅིག་གིས་སྤེལ་གསོག་འཇུག་རྒྱུ་དང་། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་གི་ལྟ་བུའི་རིམ་པ་གཞན་དང་ We also compare our system with a delexicalized parser for Romance languages, and take advantage of the harmonized annotation of Universal Dependencies to propose a language ranking based on the syntactic distance each has from Romance languages.'}
