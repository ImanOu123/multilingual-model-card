{'en': 'RewardsOfSum : Exploring Reinforcement Learning Rewards for Summarisation', 'ar': 'RewardsOfSum: استكشاف مكافآت التعلم المعززة للتلخيص', 'fr': "RewardsOfSum\xa0: Explorer les récompenses d'apprentissage par renforcement pour la synthèse", 'pt': 'RewardsOfSum: Explorando Recompensas de Aprendizado por Reforço para Resumir', 'es': 'RewardsOfSum: Explorando las recompensas de aprendizaje por refuerzo para resumir', 'ja': 'RewardsOfSum ：要約のための強化学習報酬の探求', 'zh': '赏总结:探总结', 'hi': 'RewardsOfSum: सारांशीकरण के लिए सुदृढीकरण सीखने के पुरस्कारों की खोज', 'ru': 'RewardsOfSum: Изучение наград за обучение подкреплению для подведения итогов', 'ga': 'RewardsOfSum: Ag Iniúchadh ar Fhoghlaim Treisithe Luaíochtaí le haghaidh Achoimre', 'ka': 'გადავიწყება', 'hu': 'RewardsOfSum: A megerősítési tanulási jutalmak feltárása az összefoglaláshoz', 'el': 'ΑνταμοιβέςOfSum: Εξερευνώντας Ανταμοιβές Μάθησης Ενίσχυσης για Σύνοψη', 'it': "RewardsOfSum: Esplorare le ricompense per l'apprendimento di rinforzo per la sintesi", 'kk': 'Қайталау', 'mk': 'Одплатите од сумата: Истражување на наградите за зајакнување на учењето за резултат', 'lt': 'RewardsOfSum: Reinforcement Learning reward for Summary', 'ml': 'തിരിച്ചുവരുന്ന OfSum: Exploring Reinforcement Learning Rewards for Summary', 'mn': 'RewardsOfSum: Баталгаа суралцах үйл ажиллагааг судлах', 'mt': 'RigwardsOfSum: L-esplorazzjoni tar-Rigwardji tat-Tagħlim għat-Tisħiħ għas-Sommarju', 'pl': 'RewardsOfSum: Badanie nagród uczenia się wzmocnienia w celu podsumowania', 'no': 'GjenopprettaOfSum: Utforskar forstørring av forstørringar tilbake for sammendrag', 'sr': 'Vratite se OfSum: istraživanje pojačanja učenja nagrade za sažetak', 'si': 'RewardsofSum: ප්\u200dරශ්නයක් විශ්වාස කරනවා ආපහු ප්\u200dරශ්නයක් ඉගෙනගන්න ආපහු ප්\u200dරශ්නයක්', 'so': 'RewardsOfSum: Exploring Reinforcement Learning Rewards for Summary', 'sv': 'RewardsOfSum: Exploring Förstärkning Lärande belöningar för Sammanfattning', 'ms': 'RewardsOfSum: Exploring Reinforcement Learning Rewards for Summarisation', 'ta': 'மீண்டும் OfSum: Exploring Reinforcement Learning Rewards for Summary', 'ur': 'RewardsOfSum: reinforcement Learning Reward for Summarisation', 'ro': 'RecompensOfSum: Explorarea recompenselor de învățare pentru rezumare', 'uz': 'OfSum: Exploring Reinforcement Learning Rewards for Summary', 'vi': 'Phần bổ sung:', 'bg': 'Награди за обобщаване на знанията за подсилване', 'hr': 'RewardsOfSum: istraživanje pojačanja učenja nagrade za sažetak', 'da': 'RewardsOfSum: Udforsk forstærket læringsbelønninger til opsummering', 'nl': 'RewardsOfSum: Het verkennen van Reinforcement Learning Rewards voor samenvatting', 'de': 'RewardsOfSum: Exploring Reinforcement Learning Belohnungen zur Zusammenfassung', 'ko': '보상 총결산: 탐색 강화 학습 보상 총결산', 'id': 'RewardsOfSum: Exploring Reinforcement Learning Rewards for Summarisation', 'fa': 'بازگشت\u200cسازیOfSum: تحقیق توسعه یادگیری پاداش یادگیری برای جمع\u200cسازی', 'af': 'Herstel OfSum: Ondersoek Verbevesting Leer Herstelling vir Opsomming', 'sw': 'Upande wa Mpya: Kuchunguza Kufundisha Kufundisha Kujifunza', 'tr': 'Täzeleşme', 'sq': 'RewardsOfSum: Shqyrtimi i shpërblimeve të mësimit të forcuar për përmbledhjen', 'am': 'Sum: Exploring Reinforcement Learning Rewards for Summary', 'bn': 'পুনরায় অফ সাম: সামারসংক্রান্ত শিক্ষা শিক্ষা প্রত্যাবর্তন করা হচ্ছে', 'hy': 'RerewsOFSum: Exploring BookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBookBook', 'bs': 'RewardsOfSum: istraživanje pojačanja učenja nagrade za sažetak', 'az': 'RewardsOfSum', 'ca': "RewardsOfSum: Explorar Rewards d'Aprendiment de reforç per a resumir", 'et': 'RewardsOfSum: Tugevdamise õppe uurimine', 'fi': 'RewardsOfSum: Vahvistusoppimisen tutkiminen', 'cs': 'RewardsOfSum: Prozkoumání odměn za posílení učení pro shrnutí', 'jv': 'undo-type', 'he': 'פרסים של סכום: לחקור פרסים ללימודים מחדשים לסיום', 'sk': 'RewardsOfSum: Raziskovanje okrepitve učenja Nagrade za povzetek', 'ha': 'Sum: Exploring reInheritor Learn Learn for Summary', 'bo': 'RewardsOfSum: བསྐྱར་གསོ་སྡུད་ཀློག་སྟངས་ལ་བསྡུས་དང་།'}
{'en': 'To date, most abstractive summarisation models have relied on variants of the negative log-likelihood (NLL) as their training objective. In some cases, reinforcement learning has been added to train the models with an objective that is closer to their evaluation measures (e.g. ROUGE). However, the reward function to be used within the reinforcement learning approach can play a key role for performance and is still partially unexplored. For this reason, in this paper, we propose two reward functions for the task of abstractive summarisation : the first function, referred to as RwB-Hinge, dynamically selects the samples for the gradient update. The second function, nicknamed RISK, leverages a small pool of strong candidates to inform the reward. In the experiments, we probe the proposed approach by fine-tuning an NLL pre-trained model over nine summarisation datasets of diverse size and nature. The experimental results show a consistent improvement over the negative log-likelihood baselines.', 'ar': 'حتى الآن ، اعتمدت معظم نماذج التلخيص التجريدية على متغيرات احتمالية السجل السلبي (NLL) كهدف تدريبي لها. في بعض الحالات ، تمت إضافة التعلم المعزز لتدريب النماذج بهدف أقرب إلى تدابير التقييم الخاصة بهم (مثل ROUGE). ومع ذلك ، فإن وظيفة المكافأة التي سيتم استخدامها في نهج التعلم المعزز يمكن أن تلعب دورًا رئيسيًا في الأداء ولا تزال غير مستكشفة جزئيًا. لهذا السبب ، في هذه الورقة ، نقترح وظيفتين للمكافأة لمهمة التلخيص التجريدي: الوظيفة الأولى ، المشار إليها باسم RwB-Hinge ، تختار ديناميكيًا العينات لتحديث التدرج. الوظيفة الثانية ، الملقبة بـ RISK ، تستفيد من مجموعة صغيرة من المرشحين الأقوياء لإبلاغ المكافأة. في التجارب ، قمنا بفحص النهج المقترح من خلال ضبط نموذج NLL مدرب مسبقًا على تسع مجموعات بيانات تلخيص ذات أحجام وطبيعة متنوعة. تظهر النتائج التجريبية تحسنًا ثابتًا على خطوط الأساس السلبية للسجل المحتمل.', 'es': 'Hasta la fecha, la mayoría de los modelos de resumen abstractivo se han basado en variantes de la probabilidad logarítmica negativa (NLL) como objetivo de entrenamiento. En algunos casos, se ha añadido el aprendizaje por refuerzo para entrenar a los modelos con un objetivo más cercano a sus medidas de evaluación (por ejemplo, ROUGE). Sin embargo, la función de recompensa que se utilizará dentro del enfoque de aprendizaje por refuerzo puede desempeñar un papel clave para el rendimiento y aún no se ha explorado parcialmente. Por esta razón, en este artículo proponemos dos funciones de recompensa para la tarea de resumen abstractivo: la primera función, denominada RWB-Hinge, selecciona dinámicamente las muestras para la actualización del gradiente. La segunda función, apodada RISK, aprovecha un pequeño grupo de candidatos fuertes para informar la recompensa. En los experimentos, probamos el enfoque propuesto ajustando un modelo previamente entrenado de NLL en nueve conjuntos de datos de resumen de diversos tamaños y naturaleza. Los resultados experimentales muestran una mejora constante con respecto a las líneas de base de probabilidad logarítmica negativa.', 'fr': "À ce jour, la plupart des modèles de synthèse abstraits se sont appuyés sur des variantes du log de vraisemblance négatif (NLL) comme objectif de formation. Dans certains cas, l'apprentissage par renforcement a été ajouté pour former les modèles avec un objectif plus proche de leurs mesures d'évaluation (par exemple ROUGE). Cependant, la fonction de récompense à utiliser dans le cadre de l'approche d'apprentissage par renforcement peut jouer un rôle clé pour la performance et est encore partiellement inexplorée. Pour cette raison, dans cet article, nous proposons deux fonctions de récompense pour la tâche de synthèse abstraite\xa0: la première fonction, appelée RWB-hinge, sélectionne dynamiquement les échantillons pour la mise à jour du gradient. La deuxième fonction, surnommée RISK, tire parti d'un petit bassin de candidats solides pour informer la récompense. Dans les expériences, nous étudions l'approche proposée en ajustant un modèle pré-entraîné NLL sur neuf ensembles de données de synthèse de différentes tailles et de différentes natures. Les résultats expérimentaux montrent une amélioration constante par rapport aux valeurs de base du log de vraisemblance négative.", 'pt': 'Até o momento, a maioria dos modelos de sumarização abstrativos baseou-se em variantes do log-likelihood negativo (NLL) como seu objetivo de treinamento. Em alguns casos, o aprendizado por reforço foi adicionado para treinar os modelos com um objetivo mais próximo de suas medidas de avaliação (por exemplo, ROUGE). No entanto, a função de recompensa a ser usada dentro da abordagem de aprendizado por reforço pode desempenhar um papel fundamental para o desempenho e ainda é parcialmente inexplorada. Por esta razão, neste artigo, propomos duas funções de recompensa para a tarefa de sumarização abstrativa: a primeira função, denominada RwB-Hinge, seleciona dinamicamente as amostras para a atualização do gradiente. A segunda função, apelidada de RISK, aproveita um pequeno grupo de candidatos fortes para informar a recompensa. Nos experimentos, sondamos a abordagem proposta ajustando um modelo pré-treinado de NLL em nove conjuntos de dados de sumarização de diversos tamanhos e naturezas. Os resultados experimentais mostram uma melhoria consistente sobre as linhas de base de probabilidade logarítmica negativa.', 'ja': 'これまで、ほとんどの抽象的な要約モデルは、トレーニング目標として負の対数尤度（ NLL ）のバリアントに依存してきた。 場合によっては、モデルを評価尺度に近い目標で訓練するために強化学習が追加されている（例：ルージュ）。 しかし、強化学習アプローチ内で使用される報酬関数は、パフォーマンスのための重要な役割を果たすことができ、まだ部分的には探求されていません。 このため、本稿では、抽象的な要約のタスクのための2つの報酬関数を提案する。RwB - Hingeと呼ばれる最初の関数は、勾配更新のためのサンプルを動的に選択する。 2つ目の関数はリスクと呼ばれ、強力な候補者の小さなプールを活用して報酬を通知します。 実験では、多様なサイズと性質の9つの要約データセットにわたってNLL事前にトレーニングされたモデルを微調整することによって、提案されたアプローチを探索する。 実験結果は、負の対数尤度ベースラインよりも一貫した改善を示す。', 'zh': '迄今为止,多抽象总结模形,皆赖负对数似然(NLL)变体以为训练。 加之以化学,近之以估(如ROUGE)。 然于化学之赏函数可以起关键作用,而犹未穷也。 由此言之,抽象总结二奖函数:一函数谓之RwB-Hinge,动择梯度新样本。 第二职,绰号为RISK,因一小群强选以通奖。 实验之中,因九大小性质之总数集上微调NLL预练模形以探其术。 实验结果表明,比负对数似然基线,实验终改善。', 'hi': 'आज तक, अधिकांश अमूर्त सारांश मॉडल ने अपने प्रशिक्षण उद्देश्य के रूप में नकारात्मक लॉग-संभावना (एनएलएल) के रूपों पर भरोसा किया है। कुछ मामलों में, सुदृढीकरण सीखने को एक उद्देश्य के साथ मॉडल को प्रशिक्षित करने के लिए जोड़ा गया है जो उनके मूल्यांकन उपायों (जैसे रूज) के करीब है। हालांकि, सुदृढीकरण सीखने के दृष्टिकोण के भीतर उपयोग किए जाने वाले इनाम फ़ंक्शन प्रदर्शन के लिए एक महत्वपूर्ण भूमिका निभा सकते हैं और अभी भी आंशिक रूप से अज्ञात हैं। इस कारण से, इस पेपर में, हम अमूर्त सारांशीकरण के कार्य के लिए दो इनाम कार्यों का प्रस्ताव करते हैं: पहला फ़ंक्शन, जिसे आरडब्ल्यूबी-हिंज के रूप में जाना जाता है, गतिशील रूप से ग्रेडिएंट अपडेट के लिए नमूनों का चयन करता है। दूसरा फ़ंक्शन, जिसका उपनाम जोखिम है, इनाम को सूचित करने के लिए मजबूत उम्मीदवारों के एक छोटे से पूल का लाभ उठाता है। प्रयोगों में, हम विभिन्न आकार और प्रकृति के नौ सारांश डेटासेट पर एक एनएलएल पूर्व-प्रशिक्षित मॉडल को ठीक करके प्रस्तावित दृष्टिकोण की जांच करते हैं। प्रयोगात्मक परिणाम नकारात्मक लॉग-संभावना बेसलाइन पर एक सुसंगत सुधार दिखाते हैं।', 'ru': 'На сегодняшний день большинство моделей абстрактного обобщения опираются на варианты отрицательного логарифмического правдоподобия (НЛЛ) в качестве цели обучения. В некоторых случаях было добавлено дополнительное обучение для обучения моделей с целью, которая ближе к их оценке (например, ROUGE). Однако функция вознаграждения, которая будет использоваться в подходе к обучению подкреплению, может играть ключевую роль для эффективности и все еще частично не изучена. По этой причине в данной работе мы предлагаем две функции вознаграждения для задачи абстрактного обобщения: первая функция, называемая RwB-Hinge, динамически выбирает выборки для обновления градиента. Вторая функция, прозванная РИСК, использует небольшой пул сильных кандидатов, чтобы информировать награду. В экспериментах мы исследуем предлагаемый подход путем тонкой настройки предварительно обученной модели NLL для девяти сводных наборов данных различного размера и природы. Экспериментальные результаты показывают постоянное улучшение по сравнению с отрицательными исходными уровнями логарифмической правдоподобия.', 'ga': 'Go dtí seo, bhí an chuid is mó de na samhlacha achoimre teibí ag brath ar leaganacha de na dóchúlachtaí logála diúltacha (NLL) mar chuspóir oiliúna acu. I gcásanna áirithe, cuireadh leis an bhfoghlaim atreisithe chun na samhlacha a oiliúint le cuspóir atá níos gaire dá mbearta meastóireachta (e.g. ROUGE). Mar sin féin, féadfaidh an fheidhm luach saothair atá le húsáid laistigh den chur chuige foghlama treisithe príomhról a imirt maidir le feidhmíocht agus tá sé fós gan iniúchadh i bpáirt. Ar an ábhar sin, sa pháipéar seo, molaimid dhá fheidhm luaíochta don tasc a bhaineann le hachoimriú teibí: roghnaíonn an chéad fheidhm, ar a dtugtar RwB-Hinge, na samplaí don nuashonrú grádáin go dinimiciúil. Déanann an dara feidhm, ar a dtugtar RISK, giaráil ar líon beag iarrthóirí láidre chun an luach saothair a chur ar an eolas. Sna turgnaimh, déanaimid iniúchadh ar an gcur chuige atá beartaithe trí mhionchoigeartú a dhéanamh ar shamhail réamh-oilte NLL thar naoi tacar sonraí achoimriúcháin de mhéid agus nádúr éagsúil. Léiríonn na torthaí turgnamhacha feabhas comhsheasmhach thar na bonnlínte diúltacha dóchúlachta logála.', 'hu': 'Eddig a legtöbb absztraktív összefoglaló modell a negatív log-valószínűség (NLL) variánsaira támaszkodott képzési célként. Egyes esetekben kiegészítették a megerősített tanulást annak érdekében, hogy a modelleket olyan célkitűzéssel képezzék, amely közelebb áll az értékelési intézkedésekhez (pl. ROUGE). A megerősítő tanulási megközelítésben alkalmazott jutalmazási funkció azonban kulcsszerepet játszhat a teljesítmény szempontjából, és részben még mindig feltáratlan. Ezért ebben a tanulmányban két jutalomfüggvényt javasolunk az absztraktív összefoglalás feladatához: az első függvény, amelyet RwB-Hinge néven említenek, dinamikusan választja ki a gradiens frissítéséhez szükséges mintákat. A második funkció, a Kockázat beceneve, erős jelöltek kis csoportját használja fel a jutalom tájékoztatására. A kísérletek során a javasolt megközelítést úgy vizsgáljuk, hogy egy NLL előre képzett modell finomhangolásával kilenc, különböző méretű és természetű összefoglaló adatkészleten alapul. A kísérleti eredmények következetes javulást mutatnak a negatív log-valószínűség alapjaihoz képest.', 'el': 'Μέχρι σήμερα, τα περισσότερα μοντέλα αφηρημένης σύνοψης βασίστηκαν σε παραλλαγές της αρνητικής πιθανότητας καταγραφής (NLL) ως εκπαιδευτικό στόχο τους. Σε ορισμένες περιπτώσεις, προστέθηκε η ενισχυτική μάθηση για την κατάρτιση των μοντέλων με στόχο πιο κοντά στα μέτρα αξιολόγησης τους (π.χ. ROUGE). Ωστόσο, η λειτουργία ανταμοιβής που θα χρησιμοποιηθεί στο πλαίσιο της προσέγγισης ενίσχυσης μάθησης μπορεί να διαδραματίσει βασικό ρόλο για την απόδοση και εξακολουθεί εν μέρει να είναι ανεξερεύνητη. Για το λόγο αυτό, στην παρούσα εργασία, προτείνουμε δύο λειτουργίες ανταμοιβής για το έργο της αφηρημένης σύνοψης: η πρώτη συνάρτηση, που αναφέρεται ως αρθρωτή, επιλέγει δυναμικά τα δείγματα για την ενημέρωση της διαβάθμισης. Η δεύτερη λειτουργία, με το ψευδώνυμο ΚΙΝΔΥΝΟΣ, αξιοποιεί μια μικρή ομάδα ισχυρών υποψηφίων για να ενημερώσει την ανταμοιβή. Στα πειράματα, εξετάζουμε την προτεινόμενη προσέγγιση με την τελειοποίηση ενός προ-εκπαιδευμένου μοντέλου σε εννέα σύνολα δεδομένων σύνοψης διαφορετικού μεγέθους και φύσης. Τα πειραματικά αποτελέσματα δείχνουν συνεπή βελτίωση σε σχέση με τις αρνητικές γραμμές καταγραφής πιθανοτήτων βάσης.', 'ka': 'ახლა, უფრო მეტი აბსტრაქტიური სიმბოლოების მოდელები გადარწმუნდება, როგორც საკუთარი საკუთარი საკუთარი მიზეზების გარიანტებით. რამდენიმე შემთხვევაში სწავლება დამატებულია, რომ მოდელები გასწავლათ მისი მიზეზი, რომელიც უფრო კიდევ მისი გაუმუშავება (მაგალითად ROUGE). მაგრამ, სამუშაო ფუნქცია, რომელიც სწავლად სწავლას შესაძლებლობად გამოიყენება, შეიძლება გავაკეთოთ სამუშაო პროლის გასაკეთებლად და უკვე ნაწილა ამ მიზეზით, ამ დომენტში, ჩვენ აბსტრაქტიგური სიმბოლოების დასაწყისთვის ორი სამუშაო ფუნქციების შესაძლებლობა: პირველი ფუნქცია, რომელიც RwB-Hinge, დინამიკურად განახლებელად მეორე ფუნქცია, სახელი RISK, ძალიან ძალიან კანდიდენტების მარტივი ბასონი იმპორტირება. ექსპერიმენტებში, ჩვენ შევცვალობთ წარმოიდგინული პროგრამა, რომელიც NLL-ს წარმოადგილებული მოდელის შესახებ, ცხრა განსხვავებული განსხვავებული განსხვავებული განსხვავებული მო ექსპერიმენტიური წარმოდგენების შესაძლებლობა მინდომენტიური ლოგური შესაძლებლობაზე შესაძლებელი დააწყება.', 'kk': 'Күніне, абстрактивтік жазу үлгілерінің көпшілігі негативті журнал мүмкіндігі (NLL) бақылау мақсаты ретінде тәуелді. Кейбір жағдайда, үлгілерді оқыту мақсаттарына жақын оқыту үшін қолданылады (мысалы, ROUGE). Бірақ қолданылатын көмектесу тәсілдерінде қолданылатын көмектесу функциясы оқу тәсілдерінің көмектесу үшін көмектесу рөлін ойлап, бірақ бөлімі күтпеген Бұл себептен, бұл қағазда, абстрактивті тұжырымдамасының тапсырмасының екі жоғары функциясын ұсынамыз: RwB- Hinge деп аталатын бірінші функциясы, динамикалық градиенттің жаңарту үшін үлгіле Екінші функциясы, RISK атауы үшін үлкен кандидаттардың кішкентай жиілігін қолданады. Тәжірибелерде, біз NLL алдын- ала оқылған үлгілерді тоғыз көлемі мен табиғатты қосымша деректер жинақтарының түрлі түрлі мәліметі мен қасиеттің түрлі түрлендіру арқылы ұсын Тәжірибелі нәтижелер негативті журнал мүмкіндіктерінің негативті жолдарында тұрақты жақсарту көрсетеді.', 'it': "Ad oggi, la maggior parte dei modelli di sintesi astratti si è basata su varianti della probabilità di log negativa (NLL) come obiettivo formativo. In alcuni casi, è stato aggiunto il rafforzamento dell'apprendimento per formare i modelli con un obiettivo più vicino alle loro misure di valutazione (ad esempio ROUGE). Tuttavia, la funzione di ricompensa da utilizzare all'interno dell'approccio di apprendimento di rinforzo può svolgere un ruolo chiave per le prestazioni ed è ancora parzialmente inesplorata. Per questo motivo, in questo articolo, proponiamo due funzioni di ricompensa per il compito di sintesi astratta: la prima funzione, detta RwB-Hinge, seleziona dinamicamente i campioni per l'aggiornamento gradiente. La seconda funzione, soprannominata RISK, sfrutta un piccolo pool di candidati forti per informare la ricompensa. Negli esperimenti, sondiamo l'approccio proposto mettendo a punto un modello pre-addestrato NLL su nove set di dati di sintesi di diverse dimensioni e natura. I risultati sperimentali mostrano un miglioramento costante rispetto ai valori di riferimento negativi per la probabilità di log.", 'lt': 'Iki šiol dauguma abstrakcinių santraukų modelių, kaip mokymo tikslas, rėmėsi neigiamos log tikimybės variantais. Kai kuriais atvejais mokymasis stiprinamas siekiant modelių mokymo tikslo, kuris yra artimesnis jų vertinimo priemonėms (pvz., ROUGE). Vis dėlto darbo užmokesčio funkcija, naudojama taikant mokymosi stiprinimu metodą, gali atlikti svarbų vaidmenį veiklos rezultatams ir vis dar iš dalies neištirta. Dėl šios priežasties šiame dokumente siūlome dvi atlyginimo funkcijas už abstrakcinės santraukos užduotį: pirmoji funkcija, vadinama RwB-Hinge, dinamiškai atrenka mėginius gradientui atnaujinti. Antroji funkcija, vadinama RISK, suteikia galimybę informuoti mažą grupę stiprių kandidatų apie atlygį. Eksperimentuose ištiriame siūlomą metodą tiksliai pritaikant iš anksto parengtą NLL model į į devynis įvairių dydžių ir gamtos duomenų rinkinius. Eksperimentiniai rezultatai rodo nuoseklų pagerėjimą palyginti su neigiama log tikimybės bazine verte.', 'mk': 'Досега, повеќето апстрактивни модели за резултат се потпираа на варијантите на негативната веројатност на логот (НЛЛ) како нивна обука. Во некои случаи, додадено е зајакнување на учењето за обука на моделите со цел кој е поблиску до нивните мерки за проценка (np. ROUGE). Сепак, функцијата на награда која треба да се користи во рамките на пристапот на зајакнување на учењето може да одигра клучна улога за изведувањето и сé уште е делумно неиспитана. Од оваа причина, во овој весник, предложуваме две функции на награда за задачата на апстрактивна резултатација: првата функција, наречена RwB-Hinge, динамично ги избира примероците за градијантното ажурирање. Втората функција, наречена РИСК, користи мал базен силни кандидати за да ја информира наградата. Во експериментите, го испитуваме предложениот пристап со финетизирање на предобучениот модел на НЛЛ преку девет резултати на податоци од различна големина и природа. Експерименталните резултати покажуваат константно подобрување во однос на базите на негативните лог-веројатности.', 'ms': 'Sehingga kini, kebanyakan model ringkasan abstraktif telah bergantung pada varian kemungkinan log negatif (NLL) sebagai objektif latihan mereka. In some cases, reinforcement learning has been added to train the models with an objective that is closer to their evaluation measures (e.g. ROUGE).  However, the reward function to be used within the reinforcement learning approach can play a key role for performance and is still partially unexplored.  Untuk sebab ini, dalam kertas ini, kami cadangkan dua fungsi hadiah untuk tugas ringkasan abstraktif: fungsi pertama, yang disebut sebagai RwB-Hinge, memilih secara dinamik sampel untuk kemaskini gradien. Fungsi kedua, bernama RISK, menggunakan sekumpulan kecil calon kuat untuk memberitahu hadiah. Dalam percubaan ini, kita menguji pendekatan yang direncanakan dengan menyesuaikan model NLL yang dilatih-dilatih lebih dari sembilan set data ringkasan saiz dan sifat berbeza. Hasil percubaan menunjukkan peningkatan konsisten atas garis dasar log-kemungkinan negatif.', 'ml': 'ഇന്നത്തേക്കുള്ള സമയത്ത്, ഏറ്റവും അസാധ്യതയില്ലാത്ത ചിഹ്നങ്ങളുടെ മോഡല്\u200d അവരുടെ പരിശീലനത്തിന്റെ ലക്ഷ്യം ആയിരിക്കുന്നു. In some cases, reinforcement learning has been added to train the models with an objective that is closer to their evaluation measures (e.g. ROUGE).  എന്നാലും, കൂടുതല്\u200d പഠിക്കുന്നതിനുള്ളില്\u200d ഉപയോഗിക്കുന്ന പ്രതിഫലം പ്രദര്\u200dശനത്തിനുള്ള താക്കോല്\u200d പ്രവർത്തിക്കുന്നത ഈ പേപ്പറില്\u200d നമ്മള്\u200d രണ്ട് പ്രതിഫല പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രായശ്ചിത്തം ചെയ്യുന്നു: ആദ്യത്തെ പ്രവര്\u200dത്തനത്തിന് RwB-ഹിങ്ങ് എന്ന് വിളിക്കുന്നു. ഗ്രേഡിഗ്ര രണ്ടാമത്തെ പ്രവൃത്തിക്ക്, RISK എന്ന പേര്, പ്രതിഫലം അറിയിക്കാന്\u200d ശക്തിയുള്ള പ്രാര്\u200dത്ഥികളുടെ ഒരു ചെറിയ പൂള പരീക്ഷണങ്ങളില്\u200d, നമ്മള്\u200d പ്രൊദ്ദേശിക്കപ്പെട്ട ഒരു NLL മുമ്പ് പരിശീലിക്കപ്പെട്ട മോഡലിനെ പരിശോധിക്കുന്നത് നമ്മള്\u200d പരിശോധിക്ക പരീക്ഷണത്തിന്റെ ഫലങ്ങള്\u200d നെഗറ്റീവ് ലോഗ് സാധ്യതയുള്ള അടിസ്ഥാനത്തില്\u200d മെച്ചപ്പെടുത്തുന്നത് കാണിക്', 'mn': 'Өнөөдөр ихэнх абстрактив тодорхойлолтын загварууд нь тэдний сургалтын зорилго болгон сөрөг боломжтой (NLL) логины хувилбаруудыг хамаарна. Зарим тохиолдолд, загваруудыг оюутнуудын шалгалтын шалгалтын тулд хамгийн ойрхон зорилготой зорилгоор сургалтыг нэмэгдүүлсэн. Гэхдээ шагналын функцийг нэмэгдүүлэх суралцах аргын дотор ашиглах шагналын функц нь үйл ажиллагаанд хамгийн чухал үүрэг тоглож чадна. Гэхдээ хэсэг хэсэг нь тодорхойгүй. Ийм шалтгаанаас, энэ цаасан дээр бид abstractive summary-ын даалгаварын хоёр шагналын функцүүдийг санал болгож байна: RwB-Hinge гэдэг анхны функц, динамик градиентын жагсаалтын жишээг сонгож байна. Хоёр дахь функц, RISK нэртэй нэртэй нэртэй, шагналыг мэдээллийн тулд хүчирхэг хүндрэгчдийн жижиг хэмжээг ашигладаг. Эдгээр туршилтуудын тулд бид NLL сургалтын өмнө сургалтын загварыг 9 дахин олон хэмжээст болон байгалийн тодорхойлолтын хэмжээний өгөгдлийн сангуудыг судалж байна. Үүний туршилтын үр дүнд сөрөг лог магадлалын суурь шугам дээр тогтмол сайжруулалт гаргадаг.', 'pl': 'Do tej pory większość abstrakcyjnych modeli podsumowania opierała się na wariantach negatywnej prawdopodobieństwa logowania (NLL) jako celu szkoleniowego. W niektórych przypadkach dodano uczenie się wzmacniające w celu szkolenia modeli z celem bliższym do ich środków oceny (np. ROUGE). Jednakże funkcja nagrody, która ma być wykorzystywana w ramach podejścia do uczenia się wzmacniającego, może odgrywać kluczową rolę dla wydajności i jest nadal częściowo niezbadana. Z tego względu w niniejszym artykule proponujemy dwie funkcje nagrody dla zadania abstrakcyjnego podsumowania: pierwsza funkcja, zwana RwB-Zawiasem, dynamicznie dobiera próbki do aktualizacji gradientu. Druga funkcja, zwana RISK, wykorzystuje niewielką pulę silnych kandydatów do informowania o nagrodzie. W eksperymentach badamy proponowane podejście poprzez dostrojenie wstępnie przeszkolonego modelu NLL na dziewięciu zestawach danych podsumowujących o różnej wielkości i charakterze. Wyniki eksperymentalne wskazują na stałą poprawę w stosunku do ujemnych linii bazowych log-prawdopodobieństwa.', 'no': 'Til dag har dei fleste abstraktive sammendragsmodulane relieve på variantane av den negativ loggsannsynligheten (NLL) som opplæringsmålet. I enkelte tilfeller er stipringslæring lagt til for å lære modellen med eit mål som er nærmere deres evalueringsmål (f.eks. ROUGE). Dette funksjonen kan imidlertid brukast i læringstilnærminga for reinforcement kan spela ein nøkkelrolle for utviklinga og er fortsatt delvis uventa. I denne papiret foreslår vi to løftefunksjonar for oppgåva av abstraktive sammendrag: den første funksjonen, kalla som RwB-Hinge, dynamisk veljer prøver for oppdateringa av fargeovergangane. Den andre funksjonen, kallenamnet RISK, leverer ein liten pool av sterke kandidatar for å informere renten. I eksperimentene prøver vi den foreslåde tilnærminga ved å finne opp ein NLL-føretrained modell over ni samanseringsdata med ulike storleik og natur. Eksperimentale resultatet viser ein konsistent forbedring over den negative logsannsynlege baselinjene.', 'mt': 'Sal-lum, il-biċċa l-kbira tal-mudelli abstrattivi ta’ sommarju ddependew fuq varjanti tal-probabbiltà negattiva ta’ reġistrazzjoni (NLL) bħala l-għan tat-taħriġ tagħhom. F’xi każijiet, it-tagħlim ta’ rinfurzar ġie miżjud biex jitħarrġu l-mudelli b’objettiv li huwa eqreb g ħall-miżuri ta’ evalwazzjoni tagħhom (pereżempju ROUGE). Madankollu, il-funzjoni ta’ premju li għandha tintuża fl-approċċ tat-tagħlim ta’ rinfurzar jista’ jkollha rwol ewlieni għall-prestazzjoni u għadha parzjalment mhux esplorata. Għal din ir-raġuni, f’dan id-dokument, qed nipproponu żewġ funzjonijiet ta’ premju għall-kompitu ta’ sommarju astrattiv: l-ewwel funzjoni, imsejħa RwB-Hinge, tagħżel dinamikament il-kampjuni għall-aġġornament tal-gradjenti. It-tieni funzjoni, magħrufa bħala RISK, tagħti spinta lil grupp żgħir ta’ kandidati b’saħħithom biex jinfurmaw il-premju. Fl-esperimenti, aħna nistudjaw l-approċċ propost billi nirranġaw mudell imħarreġ minn qabel tal-NLL fuq disa’ settijiet ta’ dejta ta’ sommarju ta’ daqs u natura varji. Ir-riżultati sperimentali juru titjib konsistenti fuq il-linji bażi negattivi tal-probabbiltà log.', 'ro': 'Până în prezent, cele mai multe modele abstractive de sinteză s-au bazat pe variante ale probabilității log negative (NLL) ca obiectiv de formare. În unele cazuri, s-a adăugat consolidarea învățării pentru a instrui modelele cu un obiectiv mai aproape de măsurile lor de evaluare (de exemplu, ROUGE). Cu toate acestea, funcția de recompensare care trebuie utilizată în cadrul abordării de învățare de consolidare poate juca un rol cheie pentru performanță și este încă parțial neexplorată. Din acest motiv, în această lucrare, propunem două funcții de recompensare pentru sarcina de rezumare abstractivă: prima funcție, denumită RwB-Balage, selectează dinamic eșantioanele pentru actualizarea gradientului. A doua funcție, poreclită RISK, mobilizează un mic grup de candidați puternici pentru a informa recompensa. În cadrul experimentelor, analizăm abordarea propusă prin reglarea fină a unui model pre-instruit NLL pe nouă seturi de date de rezumare de dimensiuni și natură diverse. Rezultatele experimentale arată o îmbunătăţire constantă faţă de valorile de referinţă ale probabilităţii jurnaliste negative.', 'sr': 'Do sada, većina apstraktivnih modela za sažetak oslanjaju se na variante negativne verovatnosti dnevnika (NLL) kao njihov cilj obuke. U nekim slučajevima, dodana je učenje pojačanja kako bi obučila modele objektivnim ciljem koji je bliži njihovim mjerama procjene (npr. ROUGE). Međutim, funkcija nagrade koja se koristi unutar pristupa pojačanja učenja može imati ključnu ulogu za izvođenje i još je djelomično neočekivana. Zbog ovog razloga, u ovom papiru predlažemo dve nagrade za zadatak abstraktivne sažetke: prva funkcija, pod nazivom RwB-Hinge, dinamički odabere uzorke za aktualizaciju gradienta. Druga funkcija, nadimak RISK, utiče na mali bazen jakih kandidata da obavijesti nagradu. U eksperimentima, istražujemo predloženi pristup kako bi finalizirali predobučeni model NLL preko devet rezimetriranih podataka različitih veličina i prirode. Eksperimentalni rezultati pokazuju konsekventno poboljšanje na osnovnim linijama negativne verovatnosti.', 'si': 'අවස්ථානයෙන්, ගොඩක් අවස්ථාවක් සංශ්\u200dය සංශ්\u200dය විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත විද්\u200dයාපිත ව සමහර අවස්ථාවක් වලින්, විශ්වාස කරන්න පුළුවන් ඉගෙනගන්න ලැබුණා මොඩේල් එක්ක අභියෝගයක් සඳහා ඔවුන්ගේ විශ්වා නමුත්, ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරයෝජනය විශ්වාස කරන්න පුළුවන් ප්\u200dරයෝජනය වෙනුවෙන් ප්\u200dරතිචාර ප්\u200dරයෝජන මේ හේතුවෙන්, මේ පත්තරයේ අපි ප්\u200dරතිචාර දෙකක් ප්\u200dරතිචාර කරන්න ප්\u200dරතිචාර දෙකක් ප්\u200dරතිචාර කරනවා: පළමු ප්\u200dරතිචාර ක්\u200dරියාව, RwB-හින දෙවෙනි ප්\u200dරකාර, RISK නාමය, ප්\u200dරතිචාරයක් තියෙන්න පුළුවන් පුළුවන් පුළුවන් පුළුවන් පුළුවන පරීක්ෂණයේ අපි ප්\u200dරශ්නයක් පරීක්ෂණය කරනවා NLL ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් විවිධ ප්\u200dරමාණයක් සහ ස්වභාවිතයෙන් අනුවෙ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන් විශාලනයක් ව', 'so': "Maanta la joogo waxaa ku xiran qaababka habaarka ah oo ay ku xiran yihiin noocyo kala duduwan qoraalka diidmada ah (NLL) oo ah goal waxbarashadooda. Xaaladaha qaarkood waxaa lagu darsaday inaad kordhiso waxbarashada lagu barto tusaalayaasha, kaas oo ku dhow qaababka qiimeynta (tusaale ahaan ROUGE). Si kastaba ha ahaatee shaqada mushaarka lagu isticmaali karo habka kordhiska waxbarashadu waxay noqon kartaa qayb ka mid ah qayb la'aan. Sababtaas darteed waxan warqaddan ku qoran, waxaan u soo jeedaynaa laba shaqooyin oo mushaar ah oo u qoran shaqo la'aan oo la soo saaro cayiman ah: kooxda ugu horeeyay ee lagu magacaabay RwB-Hinge, oo lagu magacaabay dhaqdhaqaaqa samooyinka sawirida. Shaqooyinka labaad, magaca RISK, wuxuu soo saaraa balli yar oo ka mid ah kandidiyayaasha xoogga badan si uu mushahaarada u ogeysiiyo. Imtixaanka, waxaynu tijaabinaynaa dhaqdhaqaaqa la soo jeeday si fiican looga sameynayo model la tababaray NLL oo ka sarreeya sagaal xagaaminta macluumaad oo kala duduwan tirada iyo dabiicadda kala duduwan. resultinta imtixaanka waxaa ka muuqda horumarinta ku socota qorshaha suurtagalka diidiga ah.", 'sv': 'Hittills har de flesta abstrakta sammanfattningsmodeller förlitat sig på varianter av negativ log-sannolikhet (NLL) som träningsmål. I vissa fall har förstärkt lärande lagts till för att utbilda modellerna med ett mål som ligger närmare deras utvärderingsåtgärder (t.ex. ROUGE). Den belöningsfunktion som används inom förstärkningsstrategin kan dock spela en nyckelroll för prestationen och är fortfarande delvis outforskad. Av denna anledning föreslår vi i denna uppsats två belöningsfunktioner för uppgiften med abstraktiv sammanfattning: den första funktionen, kallad RwB-Hinge, väljer dynamiskt proverna för gradientuppdateringen. Den andra funktionen, smeknamnet RISK, utnyttjar en liten pool av starka kandidater för att informera belöningen. I experimenten undersöker vi det föreslagna tillvägagångssättet genom att finjustera en NLL-förberedd modell över nio sammanfattningsdatauppsättningar av olika storlek och natur. De experimentella resultaten visar en konsekvent förbättring jämfört med den negativa log-sannolikhetsbaselinen.', 'ta': 'இந்த நேரத்திற்கு பெரும்பாலான சுருக்கம் மாதிரிகள் எதிர்மறை பதிவு சாத்தியமான (NLL) மாறிகளை அவர்களுடைய பயிற்சி பொருளாக நம் சில நிகழ்ச்சிகளில், கல்வி கற்றுக்கொள்ள மாதிரிகளை பயிற்சியுடன் சேர்க்கப்பட்டுள்ளது, அது அவர்களுடைய மதிப்பீட்டு அளவுகளுக்கு அருகில ஆயினும், வலுப்படுத்தல் முறையில் பயன்படுத்த வேண்டிய கூலி செயல்பாடு செயல்பாட்டிற்கான முக்கிய விளையாட்டை விளையாட இந்த காரணத்தில், நாம் செயல்பாட்டிற்கான இரண்டு கூலி செயல்பாடுகளை பரிந்துரைக்கிறோம்: முதல் செயல்பாடு, RwB- Hinge என்று குறிப்பிடப்பட்டால், தானாகவே சார் இரண்டாவது செயல்பாடு, RISK புனைப்பெயர், கூலி அறிவிப்பதற்கு ஒரு சிறிய குளியீட்டை வழங்குகிறது. பரிசோதனைகளில், நாம் பரிந்துரைக்கப்பட்ட செயல்பாட்டை சரியாக ஒரு NLL முன் பயிற்சி மாதிரியை ஒன்பது முறை சுருக்கி தகவல் அமைப்புகளில இந்த சோதனையின் முடிவுகள் எதிர்மறை பதிவு சாத்தியமான அடிப்படைகளை காட்டும்.', 'ur': 'یہاں تک، اکثر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غ بعض موقعیت میں، مدلس کی تعلیم کی زیادتی کے ساتھ اضافہ کی گئی ہے ایک موقعیت کے ساتھ جو ان کے ارزش اندازے کے قریب ہے (مثل ROUGE). However, the reward function to be used in reinforcement learning approach can play a key role for performance and still partially unexplored. اس وجہ سے، ہم اس کاغذ میں دو اجرت فناوری پیشنهاد کرتے ہیں کہ ابتراذی تعداد کے کام کے لئے دو اجرت فناوری: پہلی فناوری، RwB-Hinge کا نام لیا گیا ہے، سینامیک طور پر گراڈینٹ اوڈڈیٹ کے لئے نمونے انتخاب کرتے ہیں. دوسری فنقش، RISK کے نام کا نیک نام، مزدوری سے خبردار کرنے کے لئے ایک چھوٹا پائل ہے۔ آزمائش میں، ہم نے ایک NLL پیش آموزش کی مدل کو نو مختلف اندازے اور طبیعت کے ذریعہ سے اپنا پیش آموزش دینے والی ڈیٹ سٹ کے ذریعہ پیش آموزش دینے کے ذریعہ پیش آموزش دیے ہیں. آزمائش نتیجے منفی لاگ-احتمالات بنیس لین پر ایک ثابت قدم ترقی دکھاتے ہیں.', 'vi': 'Cho đến nay, hầu hết các mô hình tóm tắt trừu tượng đã dựa vào các biến thể của khả năng nhật ký âm (NLL) làm mục tiêu huấn luyện của chúng. Trong một số trường hợp, việc học gia cường đã được thêm vào để huấn luyện các mô- đun với một mục tiêu g ần hơn với các biện pháp đánh giá của chúng (v.d. ROSELE). Tuy nhiên, chức năng phần thưởng được sử dụng trong phương pháp huấn luyện gia tăng có thể đóng vai trò quan trọng trong việc vận hành và vẫn chưa được khám phá một phần. Vì vậy, trong tờ giấy này, chúng tôi đề xuất hai chức năng thưởng cho nhiệm vụ tổng hợp trừu tượng: chức năng đầu tiên, được gọi là RwB-Hinge, sẽ chọn theo động lực các mẫu cho lần cập nhật dốc. Lần thứ hai, biệt danh RISK, cầm một nhóm nhỏ các ứng viên mạnh để góp phần thưởng. Trong các thí nghiệm, chúng tôi thăm dò phương pháp được đề nghị bằng cách tinh chỉnh một mô hình Trước ICL hơn chín tập hợp dữ liệu với kích thước và tự nhiên khác nhau. Xét nghiệm kết quả cho thấy tỉ lệ tốt hơn so với các căn cứ về duyên khẩu âm.', 'uz': "Bu yerda ko'pchilik muvaffaqiyatsiz modellari ularning taʼminlovchi maqsadiga (NLL) oʻzgarishga ishlatadi. Ba'zi holatda, o'rganishni qoʻshish qoʻshildi, modellarni qiymatning qiymatlariga quyidagi maqsad bilan o'rganish mumkin. Lekin, o'rganish usulida foydalanish muvaffaqiyatli o'rganish qoidasi bajarish uchun muhim roli o'ynashi mumkin va ammo qismi unutilmaydi. For this reason, in this paper, we propose two reward functions for the task of abstractive summarisation: the first function, referred to as RwB-Hinge, dynamically selects the samples for the gradient update.  Ikkinchi funksiyat RISK nomli, muammolar haqida o'zgartirish uchun kichkina qismi qo'shiladi. Tajribalar davomida, biz birinchi taʼminlovchi NLL modelini yaxshi ko'ra ko'proq taʼminlovchi 9 ta'minlovchi taʼminlovchi maʼlumotlar tarkibini o'rganish mumkin. Sertifikatlar natijalari negativ logning asosiy asosiy sonlarida davom etishni ko'rsatadi.", 'hr': 'Do sada, većina apstraktivnih modela za sažetak oslanjala se na variante negativne mogućnosti dnevnika (NLL) kao njihov cilj obuke. U nekim slučajevima dodana je učenje pojačanja za obuku modela s ciljem koji je bliži njihovim mjerama procjene (npr. ROUGE). Međutim, funkcija nagrade koja se koristi unutar pristupa pojačanja učenja može imati ključnu ulogu za učenje i još je djelomično neočekivana. Zbog ovog razloga, u ovom papiru predlažemo dvije nagrade za zadatak abstraktivne sažetke: prva funkcija, naziva se RwB-Hinge, dinamički odabere uzorke za aktualizaciju gradienta. Druga funkcija, nadimak RISK, utiče na mali bazen jakih kandidata da obavijesti nagradu. U eksperimentima, istražujemo predloženi pristup finaliziranjem predobučenog model NLL-a preko devet rezimetriranih podataka različitih veličina i prirode. Eksperimentalni rezultati pokazuju konsekventno poboljšanje na osnovnim linijama negativne mogućnosti dnevnika.', 'nl': 'Tot op heden hebben de meeste abstracte samenvattingsmodellen als trainingsdoelstelling gebruik gemaakt van varianten van de negatieve log-waarschijnlijkheid (NLL). In sommige gevallen is versterking learning toegevoegd om de modellen te trainen met een doel dat dichter bij hun evaluatiemaatregelen ligt (bijv. ROUGE). De beloningsfunctie die moet worden gebruikt binnen de versterkende leeraanpak kan echter een belangrijke rol spelen voor prestaties en is gedeeltelijk nog onontdekt. Daarom stellen we in dit artikel twee beloningsfuncties voor de taak van abstractieve samenvatting voor: de eerste functie, aangeduid als RwB-scharnier, selecteert dynamisch de samples voor de gradiënt update. De tweede functie, genaamd RISK, maakt gebruik van een kleine pool van sterke kandidaten om de beloning te informeren. In de experimenten onderzoeken we de voorgestelde aanpak door een NLL voorgetraind model af te stemmen over negen samenvattingsdatasets van verschillende grootte en aard. De experimentele resultaten tonen een consistente verbetering ten opzichte van de negatieve log-waarschijnlijkheid baselines.', 'id': 'Sehingga saat ini, kebanyakan model resumsi abstraktif telah bergantung pada varian dari kemungkinan log negatif (NLL) sebagai tujuan latihan mereka. Dalam beberapa kasus, pemerintahan belajar telah ditambah untuk melatih model dengan tujuan yang lebih dekat dengan tindakan evaluasi mereka (misalnya ROUGE). However, the reward function to be used within the reinforcement learning approach can play a key role for performance and is still partially unexplored.  Untuk alasan ini, di kertas ini, kami mengusulkan dua fungsi hadiah untuk tugas resumen abstraktif: fungsi pertama, disebut sebagai RwB-Hinge, dinamik memilih sampel untuk pemutakhiran gradien. The second function, nicknamed RISK, leverages a small pool of strong candidates to inform the reward.  Dalam eksperimen ini, kami menyelidiki pendekatan yang direncanakan dengan memperbaiki model NLL yang terlatih lebih dari sembilan dataset ringkasan ukuran dan alam yang berbeda. Hasil percobaan menunjukkan peningkatan konsisten atas garis dasar log-kemungkinan negatif.', 'da': 'Hidtil har de fleste abstrakte opsummeringsmodeller baseret sig på varianter af den negative log-sandsynlighed (NLL) som deres træningsmål. I nogle tilfælde er der tilføjet forstærket læring for at uddanne modellerne med et mål, der ligger tættere på deres evalueringsforanstaltninger (f.eks. ROUGE). Belønningsfunktionen, der skal bruges inden for forstærkningslæringsmetoden, kan dog spille en nøglerolle for ydeevnen og er stadig delvist uudforsket. Derfor foreslår vi i denne artikel to belønningsfunktioner til opgaven med abstraktiv opsummering: Den første funktion, kaldet RwB-Hinge, udvælger dynamisk prøverne til gradient opdateringen. Den anden funktion, kaldet RISK, udnytter en lille pulje af stærke kandidater til at informere belønningen. I eksperimenterne undersøger vi den foreslåede tilgang ved at finjustere en NLL præ-trænet model over ni sammenfattende datasæt af forskellig størrelse og natur. De eksperimentelle resultater viser en konsekvent forbedring i forhold til de negative log-sandsynlighed basislinjer.', 'ko': '지금까지 대부분의 추상적인 총결산 모델은 마이너스 대수 유사(NLL) 변수에 의존하여 훈련 목표로 삼았다.어떤 경우 훈련 목표가 평가 지표에 더욱 가까워지도록 학습을 강화하는 모델(예를 들어 연지)을 추가했다.그러나 학습 방법을 강화하는 데 사용되는 장려 함수는 실적에 관건적인 역할을 할 수 있기 때문에 아직 일부는 탐색하지 못했다.따라서 본고에서 우리는 추상적으로 임무를 정리하는 데 사용되는 두 가지 보상 함수를 제시했다. 첫 번째 함수는 RwB 경첩이라고 하고 동적 선택 사다리 업데이트에 사용되는 견본이다.두 번째 기능은 리스크라는 별명으로 강력한 후보들을 이용해 보상을 알리는 것이다.실험에서 우리는 9개의 서로 다른 크기와 성질의 집합 데이터 집합의 NLL 예비 훈련 모델을 미세하게 조정함으로써 제시한 방법을 탐색했다.실험 결과 마이너스 대수의 유사 기선에 비해 이 방법은 일치된 개선을 보였다.', 'de': 'Bisher haben sich die meisten abstraktiven Zusammenfassungsmodelle auf Varianten der negativen Log-Likelihood (NLL) als Trainingsziel verlassen. In einigen Fällen wurde Verstärkungslernen hinzugefügt, um die Modelle mit einem Ziel zu trainieren, das näher an ihren Evaluationsmaßnahmen liegt (z.B. ROUGE). Die Belohnungsfunktion, die im Rahmen des Verstärkungslernens eingesetzt werden soll, kann jedoch eine Schlüsselrolle für die Leistung spielen und ist teilweise noch unerforscht. Aus diesem Grund schlagen wir in diesem Beitrag zwei Belohnungsfunktionen für die Aufgabe der abstraktiven Zusammenfassung vor: Die erste Funktion, genannt RwB-Scharnier, wählt dynamisch die Samples für die Verlaufsaktualisierung aus. Die zweite Funktion, genannt RISK, nutzt einen kleinen Pool starker Kandidaten, um die Belohnung zu informieren. In den Experimenten untersuchen wir den vorgeschlagenen Ansatz durch Feinabstimmung eines NLL-vortrainierten Modells über neun Zusammenfassungsdatensätze unterschiedlicher Größe und Natur. Die experimentellen Ergebnisse zeigen eine konsistente Verbesserung gegenüber den negativen Log-Likelihood Baselines.', 'bg': 'Към днешна дата повечето абстрактни модели за обобщаване разчитат на варианти на отрицателната логаритметична вероятност (НЛЛ) като цел на обучение. В някои случаи е добавено засилено обучение за обучение на моделите с цел, която е по-близо до мерките за оценка (напр. Въпреки това, функцията за възнаграждение, която трябва да се използва в рамките на подхода за укрепване на обучението, може да играе ключова роля за изпълнението и все още е частично неизследвана. Поради тази причина в настоящата статия предлагаме две възнаграждаващи функции за задачата на абстрактно обобщаване: първата функция, наречена Панта, динамично избира образците за обновяване на градиента. Втората функция, наречена РИСК, използва малък набор от силни кандидати, за да информира наградата. В експериментите изследваме предложения подход чрез фина настройка на предварително обучен модел на НЛЛ върху девет обобщени набора от данни с различен размер и природа. Експерименталните резултати показват последователно подобрение спрямо базовите линии на отрицателната log-вероятност.', 'tr': 'Şu wagt, iň köp abstraktiw jemgyýet nusgalary negatif log-sanlykynyň (NLL) üýtgetmek maksady bolup geçirdi. Käbir ýagdaýda, nusgalary düzenlemek üçin köpräk öwrenmeler (meseläm ROUGE) düzenlemek golaýynda golaýlaşdyryldy. Ýöne, taýýarlanmak öwrenmek approwasynda ulanylýan täsirli işleýän fonksiýa performans üçin a çyk roli oýnap biler we heniz hem be ýleki şekilde tanamaýar. Bu sebäpden, bu kagyzda abstraktiw toplantyň zadynyň üçin iki täsirli fonksiyony teklip edip görýäris: ilkinji funksiýa, RwB-Hinge diýilip atlanýar, dinamik görnöşi üçin örnekleri saýlaýar. Ikinji faýly, RISK atlandyrylýan, tämiýeti biljek üçin güýçli kandidýalaryň kiçi howluny süýtgedýär. Deneylerde, NLL öňünden eğlenen nusga 9 topar ululyk we tebigatyň üstünde teklip eden nusgasyny çykaryp barýarys. Deneymeli netijeler negatif günlük mümkinçiliki üssüňlerde sürekli gelişmeleri görkezýär.', 'sw': 'Mpaka sasa, mifano mingi ya muhtasari usio na maana yametegemea tofauti ya uwezekano wa log hasi (NLL) kama lengo la mafunzo yao. Katika baadhi ya matukio mengine, mafunzo ya kuuza umeongezeka kufundisha mifano kwa lengo ambalo ni karibu zaidi na hatua za uchunguzi (kwa mfano, ROUGE). Hata hivyo, jukumu la malipo linalotumiwa ndani ya mbinu za kujifunza linaweza kucheza jukumu la msingi kwa ajili ya utendaji na bado haujajua. Kwa sababu hii, katika gazeti hili, tunapendekeza kazi mbili za malipo kwa ajili ya jukumu la muhtasari wa kidini: kazi ya kwanza, inayoitwa RwB-Hinge, kwa nguvu tunachagua mifano kwa ajili ya upya wa kisasa. Kifungu cha pili, kinachoitwa jina la RISK, kina kichwa kidogo cha wagombea wenye nguvu kutoa taarifa ya malipo. Katika majaribio hayo, tunajaribu mbinu zilizopendekezwa kwa kuunganisha muundo wa zamani wa NLL kwa zaidi ya seti za taarifa za muhtasari tisa za ukubwa na asili tofauti. Matokeo ya majaribio yanaonyesha maendeleo yanayoendelea zaidi ya uwezekano wa kuandika hasi.', 'af': "Op dag het die meeste abstraktiewe opsomming modele op veranderinge van die negatiewe log-waarskynlik (NLL) as hul opsomming-objek opgelê. In sommige gevalle is die versterking leer bygevoeg om die modele te oefen met 'n doel wat naby is aan hulle evalueringsmaat (bv. ROUGE). Maar, die loon funksie wat binne die versterking leer toegang gebruik moet word, kan speel 'n sleutel rol vir prestasie en is nog gedeeltelik onverkondig. Vir hierdie rede, in hierdie papier, voorstel ons twee vergelde funksies vir die taak van abstraktiewe opsomming: die eerste funksie, verwys na as RwB- Hinge, dinamies kies die voorbeelde vir die gradient opdateer. Die tweede funksie, bynaam RISK, verwyder 'n klein pool van sterke kandidate na informasie die loon. In die eksperimente probeer ons die voorgestelde toegang deur 'n NLL voor-opgelei model te fin-tuning oor nege opsomming datastelle van verskeie grootte en natuur. Die eksperimentale resultate vertoon 'n konsistente verbetering oor die negatiewe log-waarskynlike basisline.", 'hy': 'Այսօր վերացրական համառոտագրման մոդելների մեծ մասը հիմնված է բացասական լոգ-հավանականության (ՆԼԼ) տարբերակների վրա որպես իրենց ուսուցման նպատակ: Որոշ դեպքերում ուժեղացված ուսումնասիրությունը ավելացվել է, որպեսզի մոդելները վարժեցնեն նպատակով, որը ավելի մոտ է նրանց գնահատման չափումներին (օրինակ ROUge). Այնուամենայնիվ, վարձի գործառույթը, որը պետք է օգտագործվի ուսուցման ուժեղացման մոտեցում, կարող է ունենալ արտադրողության կարևոր դեր և դեռ մասամբ չի ուսումնասիրել: Այս պատճառով, այս թղթի մեջ մենք առաջարկում ենք երկու հատուկ ֆունկցիաներ վերացական համառոտագրման խնդրի համար. առաջին ֆունկցիան, որը կոչվում է RwB-Հինգ, դինամիկ կերպով ընտրում է նմուշները դասավորման վերականգնման համար: Երկրորդ ֆունկցիան, որը կոչվում է RIsk, օգտագործում է մի փոքրիկ հավաքածու ուժեղ թեկնածուներ, որպեսզի տեղեկացնեն պարգևը: Փորձարկումների ընթացքում մենք ուսումնասիրում ենք առաջարկած մոտեցումը, բարելավելով ՆԼԼ-ի նախապատրաստված մոդելը տարբեր չափերի և բնության ինն համառոտագրման տվյալների համակարգերի միջոցով: Փորձարկվող արդյունքները ցույց են տալիս, որ բացասական լոգ-հավանականության հիմնական գծերի հետ կապված բարելավում է:', 'am': 'To date, most abstractive summarisation models have relied on variants of the negative log-likelihood (NLL) as their training objective.  አንዳንድ ጉዳይ፣ ማስተማር ተጨማሪው ተጨማሪው በሞዴላዎችን ማስተምር የተጨመረ ነው፡፡ ነገር ግን የደመወዝ ሥራ በማድረግ ውስጥ የሚጠቀሙት የድጋፍ ማድረግ ማድረግ ማድረግ የሚችል የቁልፍ ሚዛን ይጫወታል፡፡ ስለዚህ ምክንያት፣ በዚህ ገጽ፣ ለጥያቄ አካባቢ ስርዓት ሁለት የዋጋ ፍትወቶችን እናሳውቃለን፤ የመጀመሪያው ክፍል RwB-Hinge የተባለውን ምሳሌዎችን ለቀዳሚ አዲስ ማሻሻሻል ይምረጣል፡፡ ሁለተኛይቱ ስርዓት RISK የተባለው የደመወዙን ለማሳወቅ የብርቱ አማካሪዎችን ታናሽ የውኃ ሙቀት ሰጥቷል፡፡ በተፈተናው ውስጥ የዘጠኝ አነስተኛነት ዳታዎችን በተለየ መጠን እና በሥርዓት ላይ የተለየውን የNLL ሞዴል በመጠቀም በተፈተናው ልማት እና በሥርዓት የተለየ ጥያቄዎችን እናሳውቃለን፡፡ የሞከሩ ውጤቶች የnegative የሎግ-ምናልባት መቀመጫዎች ላይ የሚተካክለውን ትክክል ያሳያል፡፡', 'fa': 'تا حال، بیشترین مدل\u200cهای جمع\u200cآوری مطلق به عنوان هدف آموزش آنها بر تغییرات احتمال منفی (NLL) اعتماد دارند. در بعضی موارد، یادگیری پشتیبانی برای آموزش مدلها با هدف نزدیکتر به اندازه\u200cهای ارزیابی آنها (مثال ROUGE) اضافه شده است. ولی، عملکرد پاداش که در دستور یادگیری افزایش استفاده می\u200cشود، می\u200cتواند نقش کلید برای اجرا را را بازی کند و هنوز قسمتی غیر توضیح داده می\u200cشود. به خاطر این دلیل، در این کاغذ، دو تابع پاداش برای کار جمع\u200cآوری abstractive پیشنهاد می\u200cکنیم: اولین تابع، به عنوان RwB-Hinge، دینامیک نمونه\u200cها را برای جدید\u200cسازی گراده انتخاب می\u200cکند. عملکرد دوم، اسم RISK، یک استخره کوچک از کاندیدای قوی برای اطلاعات پاداش را ارائه می دهد. در این آزمایشات، ما روش پیشنهاد را با تنظیم یک مدل پیش آموزش NLL بیش از نو مجموعه داده\u200cهای جمع کردن اندازه و طبیعت مختلف تحقیق می\u200cکنیم. نتیجه آزمایشی بر اساس پایین\u200cهای احتمال منفی بهتر شدن را نشان می\u200cدهد.', 'az': 'Şimdiye qədər, çox abstraktiv qurğulama modelleri onların təhsil məqsədili olaraq negatif log-likeliğinin variablarına təvəkkül edir. Bazı vaxtlarda, modelləri təhsil etmək üçün daha yaxın bir məqsəd ilə öyrənmək öyrənmək üçün artırmaq öyrənməsi artırıldı (məsələn, ROUGE). Ancaq mükafat funksiyası artırmaq öyrənmə tərzində istifadə ediləcək tərzdə performans üçün anahtar rolü oynaya bilər və hələ də bir qismi a çıq-aydın deyildir. Bu səbəbdən, bu kağızda abstraktiv təmizləmə görevi üçün iki mükafat funksiyasını təbliğ edirik: ilk funksiyası, RwB-Hinge adlandırılmış, dinamik olaraq gradient güncelləməsi üçün nümunələri seçir. İkinci funksiyası, RISK adlı nickname, mükafatı bildirmək üçün güclü kandidátların küçük bir havuna istifadə edir. İşlemlərdə, NLL əvvəlcə təhsil edilmiş modeli doqquz müxtəlif ölçü və təbiəti ilə təhsil edilmiş verilən verilən qurbanların təhsil edilməsini təsdiq edirik. Müxtəlif sonuçlar negatif log-likeliğinin səhifələrində müəyyən bir improvement göstərir.', 'ca': "To date, most abstractive summarisation models have relied on variants of the negative log-likelihood (NLL) as their training objective.  En alguns casos, s'ha afegit l'aprenentatge de reforç per formar els models amb un objectiu que és més proper a les seves mesures d'evaluació (per exemple ROUGE). No obstant això, la funció de recompensa que s'ha d'utilitzar en l'enfocament d'aprenentatge de reforç pot jugar un paper clau per al rendiment i encara no ha estat explorada en part. Per això, en aquest paper proposem dues funcions de recompensa per la tasca de resum abstractiu: la primera funció, anomenada RwB-Hinge, selecciona dinàmicament les mostres per a l'actualització del gradient. La segona funció, anomenada RISK, utilitza un petit grup de candidats forts per informar la recompensa. En els experiments, investigam l'enfocament proposat ajustando un model pré-entrenat de NLL sobre nou conjunts de dades de resum de mida i naturalesa diverses. Els resultats experimentals mostren una millora constantsobre les línies de base negatives de probabilitat de registre.", 'sq': 'Deri tani, shumica e modeleve abstraktive të përmbledhjes janë mbështetur në variantet e probabilitetit negativ të regjistrimit (NLL) si objektivin e tyre të trajnimit. Në disa raste, mësimi i forcimit është shtuar për të trajnuar modelet me një objektiv që është më pranë masave të tyre të vlerësimit (për shembull ROUGE). Megjithatë, funksioni i shpërblimit që do të përdoret brenda qasjes së forcimit të mësimit mund të luajë një rol kyç për performancën dhe është ende pjesërisht i papërshqyrtuar. For this reason, in this paper, we propose two reward functions for the task of abstractive summarisation: the first function, referred to as RwB-Hinge, dynamically selects the samples for the gradient update.  Funksioni i dytë, i quajtur RISK, nxjerr një grup të vogël kandidatësh të fortë për të informuar shpërblimin. Në eksperimente, ne vëzhgojmë qasjen e propozuar duke përshtatur një model të paratrajnuar NLL mbi nëntë grupe të dhënash të përmbledhur të madhësisë dhe natyrës së ndryshme. Rezultatet eksperimentale tregojnë një përmirësim konsistent lidhur me linjat bazë negative të probabilitetit të log.', 'cs': 'Dosud se většina abstraktivních souhrnných modelů spoléhala na varianty negativní log-pravděpodobnosti (NLL) jako cíl výcviku. V některých případech bylo přidáno posílení učení pro trénink modelů s cílem, který je blíže jejich hodnotícím opatřením (např. ROUGE). Funkce odměny, která má být použita v rámci přístupu k posilování učení, však může hrát klíčovou roli pro výkon a je stále částečně neprozkoumaná. Z tohoto důvodu v tomto článku navrhujeme dvě funkce odměny pro úkol abstraktivního shrnutí: první funkce, označovaná jako RwB-Hinge, dynamicky vybírá vzorky pro aktualizaci gradientu. Druhá funkce, přezdívaná RISK, využívá malou skupinu silných kandidátů, aby informovala odměnu. V experimentech zkoumáme navržený přístup jemným laděním NLL předtrénovaného modelu na devíti souhrnných datových sadách různé velikosti a povahy. Experimentální výsledky ukazují konzistentní zlepšení oproti negativním log-pravděpodobnosti základních linií.', 'fi': 'Tähän mennessä useimmat abstraktit yhteenvetomallit ovat käyttäneet koulutustavoitteena negatiivisen log-todennäköisyyden variantteja. Joissakin tapauksissa mallien kouluttamiseen on lisätty tehostettua oppimista tavoitteena, joka on lähempänä niiden arviointitoimenpiteitä (esim. ROUGE). Vahvistusoppimisessa käytettävällä palkitsemistoiminnolla voi kuitenkin olla keskeinen rooli suorituskyvyn kannalta, ja sitä ei ole vielä osittain tutkittu. Tästä syystä tässä työssä ehdotamme kahta palkitsemisfunktiota abstraktiivisen yhteenvedon tehtävään: ensimmäinen funktio, jota kutsutaan nimellä RwB-Hinge, valitsee dynaamisesti näytteet gradientin päivitystä varten. Toinen toiminto, lempinimeltään RISK, hyödyntää pientä vahvojen ehdokkaiden joukkoa ilmoittamaan palkkiosta. Kokeiluissa tutkitaan ehdotettua lähestymistapaa hienosäätämällä esikoulutettua NLL-mallia yhdeksään erikokoiseen ja luonteeltaan erikokoiseen yhteenvetoaineistoon. Kokeelliset tulokset osoittavat jatkuvan parannuksen negatiivisen log-todennäköisyyden perusviivoista.', 'bn': 'এখন পর্যন্ত নেতিবাচক লগ-সম্ভাবনা নির্ভর করে বেশীরভাগ সংক্রান্ত মডেল তাদের প্রশিক্ষণের লক্ষ্য হিসেবে নির্ভর করেছে। কিছু ক্ষেত্রে শিক্ষা বাড়িয়ে দিয়েছে মডেলের শিক্ষা প্রশিক্ষণের জন্য যোগ করা হয়েছে যা তাদের মূল্যায়নের কাছাকাছি (যেমন রোজের ক কিন্তু ক্ষেত্রে ব্যবহার করা পুরস্কারের কাজের ক্ষেত্রে ব্যবহার করা যায় তা প্রদর্শনের জন্য একটি গুরুত্বপূর্ণ ভূমিকা খেলতে প এই কারণের জন্য, এই কাগজটিতে আমরা অস্বীকৃতিক সংক্রান্ত কাজের জন্য দুটি পুরস্কার প্রস্তাব করছি: প্রথম ফাংশন, যার নাম রিউবি-হিঙ্গ বলা হচ্ছে, গ্রেডিয়েন্ড আপড দ্বিতীয় ফাংশন, রিএসকে নাম দেয়া হয়েছে, পুরস্কার জানানোর জন্য একটি ছোট পুলের প্রার্থীদের একটি পুল প্রদান করেছে। পরীক্ষার মধ্যে আমরা প্রস্তাবিত পদ্ধতি প্রমাণ করি একটি এনএল পূর্ব প্রশিক্ষিত মডেলের মাধ্যমে নয়টি সংক্ষিপ্ত তথ্যের বিভিন্ন আকার ও প পরীক্ষার ফলাফল নেতিবাচক লগ-সম্ভাবনার বেসাইনের ব্যাপারে একেবারে উন্নতি প্রদর্শন করে।', 'bs': 'Do sada, većina apstraktivnih modela za sažetak oslanjala se na variante negativne mogućnosti dnevnika (NLL) kao njihov cilj obuke. U nekim slučajevima, dodana je učenje pojačanja kako bi obučila modele objektivnim ciljem koji je bliži njihovim mjerama procjene (npr. ROUGE). Međutim, funkcija nagrade koja se koristi unutar pristupa pojačanja učenja može imati ključnu ulogu za izvođenje i još je djelomično neočekivana. Zbog ovog razloga, u ovom papiru predlažemo dve nagrade funkcije za zadatak abstraktivne sažetke: prva funkcija, pod nazivom RwB-Hinge, dinamički odabere uzorke za aktualizaciju gradienta. Druga funkcija, nadimak RISK, utiče na mali bazen jakih kandidata da obavijesti nagradu. U eksperimentima, istražujemo predloženi pristup tako što ćemo ispraviti predobučeni model NLL preko devet rezimetriranih podataka različitih veličina i prirode. Eksperimentalni rezultati pokazuju konsekventno poboljšanje na osnovnim linijama negativne mogućnosti dnevnika.', 'et': 'Praeguseks on enamik abstraktseid kokkuvõtlusmudeleid oma koolituse eesmärgina tuginenud negatiivse logitõenäosuse variantidele. Mõnel juhul on lisatud tugevdatud õppimine, et koolitada mudeleid eesmärgiga, mis on lähemal nende hindamismeetmetele (nt ROUGE). Siiski võib tugevdamisõppe meetodi raames kasutatav tasuvusfunktsioon mängida tulemuslikkuse seisukohalt võtmerolli ja seda on veel osaliselt uurimata. Sel põhjusel pakume selles töös välja kaks preemiafunktsiooni ülesandeks abstraktne kokkuvõte: esimene funktsioon, mida nimetatakse RwB-Hinge, valib dünaamiliselt näidised gradienti uuendamiseks. Teine funktsioon, hüüdnimega RISK, võimendab väikest tugevate kandidaatide kogumit, et teavitada tasu. Katsetes analüüsime kavandatud lähenemisviisi, täpsustades NLL eelõpetatud mudelit üheksa erineva suuruse ja iseloomuga kokkuvõtliku andmekogumi kaudu. Katsetulemused näitavad pidevat paranemist negatiivse logaritmilise tõenäosuse baasjoonega võrreldes.', 'jv': 'Daftar, akeh di sistem absolute dadi resumen model sing wis dianggawe karo variant dadi log-like (NLL) nganggo nggawe aksil ngucap Slacky Nanging, bongkin nggo dianggap sistem kang nggawe Jejaring Awak dhéwé, ning basa iki, kita mulungi iki bakal nggawe bakal dhéwé basa sing perusahaan karo hal-perusahaan: nambah tanggal tuatah, nambah RwB-hint deep Nang ujaran ning rabi, kita ngubah akses nggawe layakno ning kebutuhan NLL kuwi model sing wis antara awak dhéwé dadi nggawe barang sampek kanggo kalagayut karo bumi. Rejalaké sing diperaksi wong kaé mpungasane kanggo ngilangno sistem sing gawe kaya nguasakno', 'sk': 'Do danes se je večina abstraktivnih modelov povzetka zanašala na različice negativne log verjetnosti (NLL) kot cilj usposabljanja. V nekaterih primerih je bilo dodano okrepitveno učenje za usposabljanje modelov s ciljem, ki je bližji njihovim ukrepom ocenjevanja (npr. ROUGE). Vendar pa lahko funkcija nagrajevanja, ki se uporablja v okviru pristopa krepitvenega učenja, igra ključno vlogo za uspešnost in je še vedno delno neraziskana. Zato v tem prispevku predlagamo dve nagradni funkciji za nalogo abstraktivnega povzetka: prva funkcija, imenovana RwB-Hinge, dinamično izbere vzorce za posodobitev gradienta. Druga funkcija, imenovana RISK, vzvodi majhen nabor močnih kandidatov za obveščanje o nagradi. V poskusih smo preučili predlagani pristop z natančnim nastavitvijo vnaprej usposobljenega modela NLL na devetih naborih povzetkov podatkov različnih velikosti in narave. Poskusni rezultati kažejo konsistentno izboljšanje glede na izhodiščne vrstice negativne log verjetnosti.', 'ha': "Ga yanzu, mafi yawan motsi na ƙidãya masu kanana sun dõgara a kan variant na masu yiwur-rubutun-rubutun (NLL) kamar abun na tsari. In some cases, reinforcement learning has been added to train the models with an objective that is closer to their evaluation measures (e.g. ROUGE).  A lokacin da ake amfani da aikin ijãrar da aka ƙara cikin hanyarwa da za'a yi amfani da shi, ko kuma yana da rabon aiki wanda ba'a buƙata ba. Saboda haka, a cikin wannan takarda, Munã buɗar da misalin biyu na musamman wa aikin da aka tsare masu kanana: aikin na farko, wanda aka kallo na RwB-Hige, yana zãɓi misãlai na don a sake tsari na-sãɓa. Fara na biyu, wanda aka sunan RiSK, yana samar da wani abu mai ƙaranci daga kandida mai ƙarfi dõmin ya sanar da ijãra. Daga jarrabai, za'a jarraba kafin da za'a sami wata misalin na NLL a gaba-wa'anar da taki tara shekarar data masu turu'in girma da halin. Mataimakin jarrabai na nuna wata gyãra mai daidai a kan salummai mai yiwuwa-log-negative.", 'he': 'עד היום, רוב הדוגמנים המתוקפים המתוקפים הסמכו על שונות של סבירות השלילית של לוג-סבירות (NLL) כמטרה האימונים שלהם. במקרים מסוימים, הוספה למידת גיבוי כדי לאמן את הדוגמנים עם מטרה שהיא קרובה יותר לאמצעי הערכה שלהם (למשל ROUGE). בכל אופן, התפקיד הפרס שימש בתוך גישת הלימוד התגבורה יכול לשחק תפקיד מפתח לביצוע ועדיין לא חוקר חלקית. מסיבה זו, בעיתון הזה, אנו מציעים שתי תפקידים פרס למשימה של סכם אוסטרקטיבי: הפונקציה הראשונה, שנקראת RwB-Hinge, בוחרת דינמית את הדגימות למעדכון המדרגות. הפונקציה השנייה, בשם RISK, משתמשת בבריכה קטנה של מועמדים חזקים כדי להודיע על הפרס. בניסויים, אנו חוקרים את הגישה המוצעת על ידי שיפור מודל מאומן מראש של NLL מעל תשע קבוצות מידע של גודל ומגוון טבע. תוצאות הניסויים מראות שיפור קבוע מעל קווי הבסיס של סבירות לוג שליליים.', 'bo': 'ད་ལྟ་མི་མང་ཆེ་བ་དག་གི་བསྡུས་བརྗོད་སྟངས་ཀྱི་ནང་དུ་ཉུང་འབྲེལ་བ་དང་མཉམ་དུ་འགྱུར་བ་ཡིན། གལ་སྲིད་ལ་ཤས་ཀྱི་ནང་དུ། མིག་རྩལ་བསྐྱེད་ཚད་སྒྲིག་གི་མཐུན་རྐྱེན་ཐབས་ལམ་ལ་ཁྱད་ནས་མཐུན་རྐྱེན་བཟོ་བྱས་ཡོད། ཡིན་ནའང་། རྒྱབ་སྐྱོར་གྱི་གཟུགས་རིས་སྟོན་པར་ལག་ལེན་འཐབ་དགོས་པ་དེ་ལས་ཀྱང་སྐྱོང་ཆེན་པོ་ཞིག་རྩེ་བ་ལས། འོན་ཀྱང་། རྒྱུ་མཚན་འདིའི་ནང་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོའི་རྗེས་སུ་འབྲངས་ཀ་གཉིས་འཆར་འདོད་པ་ཡིན། the first function, referred to as RwB-Hinge, dynamically selects the samples for the gradient update. དངོས་པོ་གཉིས་པ་་ཡིན་པའི་མིང་མིང RISK་་་་ཆ་རྐྱེན་སྐོར་ཆེན་པོ་ཆུང་ཀུ་ཉེ་ཆར་སྤྲོད་ཡོད། འུ་ཅག་གིས་བརྟག་ཞིབ་བྱས་པའི་སྔོན་གྲངས་སྒྲིག་འགོད་བྱས་པའི་གཟུགས་རིས་ལྟར་ཞིབ་བཤེར་བྱེད་ཀྱི་ཡོད། གྲུབ་ཕྱོགས་གྱི་གནད་སྡུད་དུ་ཚད་རྐྱེན་ཐོག་ནས་གནས་སྟངས་གང་ཟག་ཞིག་མཐོང་ནུས་'}
{'en': 'SmBoP : Semi-autoregressive Bottom-up Semantic Parsing', 'ar': 'SmBoP: التحليل الدلالي شبه التلقائي من الأسفل إلى الأعلى', 'fr': 'SMBop\xa0: analyse sémantique ascendante semi-autorégressive', 'pt': 'SmBoP: análise semântica de baixo para cima semiautoregressiva', 'es': 'SmBoP: análisis semántico ascendente semiautorregresivo', 'ja': 'SmBoP ：セマンティック構文解析の半自動回帰', 'zh': 'SmBoP:半自归上语义解析', 'ru': 'SmBoP: Полуавторегрессивный восходящий семантический разбор', 'hi': 'SmBoP: अर्ध-autoregressive नीचे ऊपर शब्दार्थ पार्सिंग', 'ga': 'SmBoP: Parsáil Shéimeantach ón mBun aníos leath-uath-chéimneach', 'ka': 'Comment', 'el': 'SmBoP: Ημι-αυτοανακριτική Σημαντική ανάλυση από κάτω προς τα πάνω', 'hu': 'SmBoP: Félig-autoregresszív alulról felfelé szemantikus értelmezés', 'it': "SmBoP: Analisi semantica semi-autoregressiva dal basso verso l'alto", 'kk': 'SmBoP: Төменгі төменгі шегінен жарты авторессивні талдау', 'mk': 'SmBoP: полуавторегресивно семантично анализирање од дното нагоре', 'mt': 'SmBoP: Analiżi Semantika Semantika Semawtoregressiva minn isfel għal fuq', 'ms': 'SmBoP: Penghuraian Semantic Semantic Semi-Autoregressif Bottom-Up', 'ml': 'എമ്പോപി: താഴെ താഴെ സെമാന്റിക് പാര്\u200dസിങ്ങ്', 'no': 'SmBoP: semi- autoregressiv nedre- opp semiantisk tolking', 'lt': 'SmBoP: pusiau autoregresinis žemyn atliekamas seminis analizavimas', 'pl': 'SmBoP: Półautoregresywne Oddolne Parsowanie Semantyczne Semantyczne', 'ro': 'SmBoP: Analizare semantică semi-autoregresivă de jos în sus', 'si': 'Comment', 'sr': 'SmBoP: polu-autoregresivno ispod-gore semantičko razmatranje', 'sv': 'SmBoP: Semi-autoregressiv nedifrån och upp semantisk tolkning', 'mn': 'СМБ: Гуравдаа автоматжруулсан доорх төвшин төвшин шинжилгээ', 'so': 'SmBoP: Semi-autoregressive Bottom-up Semantic Parsing', 'ur': 'سیمبوپ: نیچے- آٹوگریسٹی نیچے- اوپر سیمانٹی پارسینگ', 'ta': 'SmBoP: பிரிவு- தானியங்கி கட்டுப்பாடு', 'uz': 'Name', 'vi': 'Mẹ cục súc', 'nl': 'SmBoP: Semi-autoregressieve Bottom-up semantische parsing', 'da': 'SmBoP: Semi- autoregressiv bottom-up semantisk fortolkning', 'bg': 'SmBoP: Полуавторегресивен Семантичен анализ отдолу нагоре', 'hr': 'SmBoP: polu-autoregresivno ispod semiantičkog razmatranja', 'id': 'SmBoP: Semi-autoregressive Bottom-up Semantic Parsing', 'ko': 'SmBop: 반자귀환 자저상향 의미 분석', 'de': 'SmBoP: Semi-autoregressives Bottom-up Semantisches Parsing', 'sw': 'SmBoP: Kufungua kwa kujitawala', 'fa': 'Comment', 'tr': 'SmBoP:Yarı-otoregressiv Altı Semantik Parlama', 'af': 'Name', 'am': 'ምርጫዎች', 'az': 'SmBoP: YarńĪ-otoregressiv AŇüańüńĪ-YuxarńĪ Semantik ńįzl…ôm…ô', 'hy': 'SmBoP: Semi-autoregressive Bottom-up Semantic Parsing', 'bn': 'SmBoP: স্বয়ংক্রিয়ভাবে নিম্নলিখিত সেম্যান্টিক পার্সিং', 'bs': 'SmBoP: polu-autoregresivno ispod semiantičkog razmatranja', 'et': 'SmBoP: Poolautoregressiivne alt-üles semantiline parsimine', 'ca': 'SmBoP: Analització Semàtica Semàtica Semàtica Semi-autoregressiva', 'fi': 'SmBoP: Semi- autoregressiivinen alhaalta ylöspäin suuntautuva semanttinen analyysi', 'cs': 'SmBoP: Semiautoregresivní sémantické parsování zdola nahoru', 'sq': 'SmBoP: Semi-autoregressive Bottom-up Semantic Parsing', 'jv': 'SmBoP:', 'sk': 'SmBoP: Semi- avtoregresivna semantična analiza od spodaj navzgor', 'he': 'SmBoP: Semi-autoregressive Bottom-up Semantic Parsing', 'bo': 'SmBoP：རང་འགུལ་གྱིས་རྒྱ་ཤར་བའི་མགོ་རིམ་ལ་ཟུར་བ་ཞིབ་བཤེར', 'ha': '@ action'}
{'en': 'The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal. In this work, we propose an alternative approach : a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height   t. Our parser enjoys several benefits compared to top-down autoregressive parsing. From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear. From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees. We apply SmBoP on Spider, a challenging zero-shot semantic parsing benchmark, and show that SmBoP leads to a 2.2x speed-up in decoding time and a ~5x speed-up in training time, compared to a semantic parser that uses autoregressive decoding. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'ar': 'كانت طريقة فك التشفير المعيارية الواقعية للتحليل الدلالي في السنوات الأخيرة هي فك شفرة شجرة التركيب المجردة للبرنامج الهدف بشكل تلقائي باستخدام اجتياز العمق أولاً من أعلى إلى أسفل. في هذا العمل ، نقترح نهجًا بديلًا: محلل شبه تلقائي من أسفل إلى أعلى (SmBoP) يبني عند خطوة فك التشفير t الأشجار الفرعية العلوية K ذات الارتفاع t. يتمتع المحلل اللغوي الخاص بنا بالعديد من الفوائد مقارنة بالتحليل التنازلي التلقائي من أعلى إلى أسفل. من منظور الكفاءة ، يسمح التحليل التصاعدي بفك تشفير جميع الأشجار الفرعية بارتفاع معين بالتوازي ، مما يؤدي إلى تعقيد وقت التشغيل اللوغاريتمي بدلاً من الخطي. من منظور النمذجة ، يتعلم المحلل اللغوي من أسفل إلى أعلى تمثيلات البرامج الفرعية الدلالية ذات المعنى في كل خطوة ، بدلاً من الأشجار الجزئية الخالية من الناحية الدلالية. نحن نطبق SmBoP على Spider ، وهو معيار تحليل دلالي صعب إطلاق النار عليه ، ونبين أن SmBoP يؤدي إلى تسريع 2.2x في وقت فك التشفير وتسريع ~ 5x في وقت التدريب ، مقارنة بالمحلل الدلالي الذي يستخدم فك الانحدار التلقائي . حصل SmBoP على 71.1 من دقة الدلالة على Spider ، مما أدى إلى إنشاء حالة جديدة من الفن ، ومطابقة تامة 69.5 ، قابلة للمقارنة مع 69.6 مطابقة تامة للإنحدار التلقائي RAT-SQL + Grappa.', 'es': 'El método de decodificación estándar de facto para el análisis semántico en los últimos años ha sido decodificar autorregresivamente el árbol de sintaxis abstracta del programa objetivo utilizando un recorrido en profundidad de arriba hacia abajo. En este trabajo, proponemos un enfoque alternativo: un analizador ascendente semiautorregresivo (SMBop) que construye en el paso de decodificación t los K-sub-árboles superiores de altura t. Nuestro analizador tiene varios beneficios en comparación con el análisis autorregresivo descendente. Desde una perspectiva de eficiencia, el análisis ascendente permite decodificar todos los subárboles de cierta altura en paralelo, lo que lleva a una complejidad logarítmica del tiempo de ejecución en lugar de lineal. Desde una perspectiva de modelado, un analizador de abajo hacia arriba aprende representaciones de subprogramas semánticos significativos en cada paso, en lugar de árboles parciales semánticamente vacíos. Aplicamos SmBoP en Spider, un desafiante punto de referencia de análisis semántico de tiro cero, y demostramos que SMBop conduce a una aceleración de 2,2 veces en el tiempo de decodificación y una aceleración de ~ 5 veces en el tiempo de entrenamiento, en comparación con un analizador semántico que usa decodificación autorregresiva. SmBoP obtiene una precisión de denotación de 71.1 en Spider, estableciendo una nueva coincidencia exacta de última generación y de 69.5, comparable a la coincidencia exacta de 69.6 de la rata-SQL+GRAPPA autorregresiva.', 'pt': 'O método de decodificação padrão de fato para análise semântica nos últimos anos tem sido decodificar auto-regressivamente a árvore de sintaxe abstrata do programa de destino usando uma travessia de profundidade de cima para baixo. Neste trabalho, propomos uma abordagem alternativa: um Semi-autoregressive Bottom-up Parser (SmBoP) que constrói na etapa de decodificação t as K sub-árvores de altura t. Nosso analisador possui vários benefícios em comparação com a análise autoregressiva de cima para baixo. De uma perspectiva de eficiência, a análise de baixo para cima permite decodificar todas as subárvores de uma certa altura em paralelo, levando a uma complexidade de tempo de execução logarítmica em vez de linear. De uma perspectiva de modelagem, um analisador de baixo para cima aprende representações para subprogramas semânticos significativos em cada etapa, em vez de árvores parciais semanticamente vazias. Aplicamos o SmBoP no Spider, um benchmark desafiador de análise semântica de tiro zero, e mostramos que o SmBoP leva a uma aceleração de 2,2x no tempo de decodificação e uma aceleração de ~5x no tempo de treinamento, em comparação com um analisador semântico que usa decodificação autorregressiva . O SmBoP obtém uma precisão de denotação de 71,1 no Spider, estabelecendo um novo estado da arte, e uma correspondência exata de 69,5, comparável à correspondência exata de 69,6 do RAT-SQL+Grappa autorregressivo.', 'fr': "La méthode de décodage standard de facto pour l'analyse sémantique au cours des dernières années a été de décoder de manière autorégressive l'arbre syntaxique abstrait du programme cible en utilisant une traversée descendante en profondeur d'abord. Dans ce travail, nous proposons une approche alternative\xa0: un analyseur semi-autorégressif Bottom-up (smBop) qui construit à l'étape de décodage t les sous-arbres K supérieurs de hauteur t. Notre analyseur bénéficie de plusieurs avantages par rapport à l'analyse autorégressive descendante. Du point de vue de l'efficacité, l'analyse ascendante permet de décoder tous les sous-arbres d'une certaine hauteur en parallèle, ce qui entraîne une complexité d'exécution logarithmique plutôt que linéaire. Du point de vue de la modélisation, un analyseur de bas en haut apprend des représentations pour des sous-programmes sémantiques significatifs à chaque étape, plutôt que pour des arbres partiels sémantiquement vides. Nous appliquons SmBop sur Spider, un test d'analyse sémantique zero-shot difficile, et montrons que SmBop entraîne une accélération de 2,2 fois le temps de décodage et une accélération d'environ 5 fois le temps d'entraînement, par rapport à un analyseur sémantique qui utilise le décodage autorégressif. SmBop obtient une précision de dénotation de 71,1 sur Spider, établissant une nouvelle technologie de pointe, et une correspondance exacte de 69,5, comparable à la correspondance exacte de 69,6 de l'autorégressive RAT-SQL+Grappa.", 'zh': '近年以来,语义解析之事实标准解码法用自上而下深度优先遍历自归解码趋序之象语法树。 半自归自下而上解析器(SmBoP),于解码步驿t处造高t之顶K子树。 比之自上而下者自归解析,吾解析器有胜势。 以效率角观之,自下而上者解析许并行解码必高之所有子树,以致对数行复杂性非线性也。 由建模观之,自下而上者解析器每步学意义之语义,非语义上之偏树也。 吾于Spider上用SmBoP,此一挑战性之零次语义解析准,明与用自归解码之语义解析器,SmBoP致解码日倍2.2,练日速约倍5。 SmBoP得71.1于Spider,立先进之匹,与69.5之精,与归RAT-SQL + Grappa之69.6。', 'ru': 'Стандартный метод декодирования де-факто для семантического синтаксического анализа в последние годы заключался в авторегрессивном декодировании абстрактного синтаксического дерева целевой программы с использованием траверсы «сверху вниз». В этой работе мы предлагаем альтернативный подход: полуавторегрессивный восходящий парсер (SmBoP), который строит на этапе декодирования t верхние поддерева K высотой  t. Наш парсер обладает несколькими преимуществами по сравнению с нисходящим авторегрессивным парсингом. С точки зрения эффективности, восходящий парсинг позволяет декодировать все поддерева определенной высоты параллельно, что приводит к логарифмической сложности времени выполнения, а не к линейности. С точки зрения моделирования, восходящий парсер изучает представления для значимых семантических подпрограмм на каждом шаге, а не для семантически пустых частичных деревьев. Мы применяем SmBoP к Spider, сложному эталону семантического анализа с нулевым выстрелом, и показываем, что SmBoP приводит к ускорению декодирования во времени в 2,2 раза и ускорению тренировочного времени в ~5 раз по сравнению с семантическим парсером, в котором используется авторегрессивное декодирование. SmBoP получает точность обозначения 71,1 на Spider, устанавливая новое современное и точное соответствие 69,5, сопоставимое с точным соответствием 69,6 авторегрессивного RAT-SQL+Grappa.', 'ja': '近年のセマンティック構文解析のデファクトスタンダードなデコード方法は、トップダウンの深さ優先トラバーサルを使用してターゲットプログラムの抽象構文木を自動的にデコードすることである。 この研究では、別のアプローチを提案します。高さtのトップ- Kサブ木をデコードするステップtで構築する半自動回帰ボトムアップパーサー（ SmBoP ）です。 当社の構文解析ツールは、トップダウンの自動回帰構文解析と比較して、いくつかの利点があります。 効率性の観点から、ボトムアップ構文解析では、特定の高さのすべてのサブツリーを並列にデコードすることができ、線形ではなく対数的なランタイムの複雑さをもたらします。 モデリングの観点から、ボトムアップ構文解析器は、意味的に真空の部分木ではなく、各ステップで意味的なサブプログラムの表現を学習します。 SmBoPをゼロショットのセマンティック構文解析ベンチマークであるSpiderに適用し、自動回帰デコードを使用するセマンティック構文解析器と比較して、SmBoPがデコード時間が2.2倍、トレーニング時間が約5倍のスピードアップにつながることを示します。 SmBoPは、Spiderで71.1の表記精度を取得し、自己回帰型RAT - SQL + Grappaの69.6の完全一致に匹敵する、最新の69.5の完全一致を確立します。', 'hi': 'हाल के वर्षों में शब्दार्थ पार्सिंग के लिए वास्तविक मानक डिकोडिंग विधि एक शीर्ष-डाउन गहराई-पहले ट्रैवर्सल का उपयोग करके लक्ष्य कार्यक्रम के अमूर्त वाक्यविन्यास पेड़ को ऑटोरिग्रेसिव रूप से डीकोड करने के लिए किया गया है। इस काम में, हम एक वैकल्पिक दृष्टिकोण का प्रस्ताव करते हैं: एक अर्ध-ऑटोरिग्रेसिव बॉटम-अप पार्सर (SmBoP) जो डीकोडिंग चरण टी पर निर्माण करता है, ऊंचाई टी के शीर्ष-कश्मीर उप-पेड़। हमारे पार्सर को ऊपर-नीचे ऑटोरिग्रेसिव पार्सिंग की तुलना में कई लाभ मिलते हैं। एक दक्षता परिप्रेक्ष्य से, बॉटम-अप पार्सिंग समानांतर में एक निश्चित ऊंचाई के सभी उप-पेड़ों को डीकोड करने की अनुमति देता है, जिससे रैखिक के बजाय लॉगरिदमिक रनटाइम जटिलता होती है। एक मॉडलिंग परिप्रेक्ष्य से, एक बॉटम-अप पार्सर प्रत्येक चरण में सार्थक शब्दार्थ उप-कार्यक्रमों के लिए प्रतिनिधित्व सीखता है, बजाय शब्दार्थ-खाली आंशिक पेड़ों के लिए। हम स्पाइडर पर SmBoP लागू करते हैं, एक चुनौतीपूर्ण शून्य-शॉट सिमेंटिक पार्सिंग बेंचमार्क, और दिखाते हैं कि SmBoP डिकोडिंग समय में 2.2x स्पीड-अप और प्रशिक्षण समय में ~ 5x स्पीड-अप की ओर जाता है, एक शब्दार्थ पार्सर की तुलना में जो ऑटोरिग्रेसिव डिकोडिंग का उपयोग करता है। SmBoP स्पाइडर पर 71.1 denotation सटीकता प्राप्त करता है, एक नया अत्याधुनिक स्थापित करता है, और 69.5 सटीक मैच, autoregressive RAT-SQL + Grappa के 69.6 सटीक मैच के बराबर है।', 'ga': 'Is é an modh díchódaithe caighdeánach de-facto do pharsáil shéimeantach le blianta beaga anuas ná crann comhréire teibí an chláir sprice a dhíchódú go huathoibríoch ag baint úsáide as trasnú doimhneacht-an-tús ón mbarr anuas. San obair seo, molaimid cur chuige eile: Parsálaí Leath-uathchéimneach ón mBun aníos (SmBoP) a dhéanann na fochrainn barr-K d’airde t ag an gcéim díchódaithe t. Tá buntáistí éagsúla ag ár bparsálaí i gcomparáid le parsáil uath-aischéimnitheach ón mbarr anuas. Ó thaobh na héifeachtúlachta de, ceadaíonn parsáil ón mbun aníos gach fo-chrainn d’airde áirithe a dhíchódú go comhthreomhar, rud a fhágann go mbíonn castacht ama rite logartamach seachas líneach. Ó thaobh na samhaltaithe de, foghlaimíonn parsálaí ón mbun aníos léiriúcháin d’fhochláir shéimeantacha brí ag gach céim, seachas do pháirtchrainn shéimeantacha-fholúsacha. Cuirimid SmBoP i bhfeidhm ar Spider, tagarmharc parsála séimeantach náid-urchar dúshlánach, agus léirímid go dtagann luas suas 2.2x in am díchódaithe agus luas suas ~5x in am traenála mar thoradh ar SmBoP, i gcomparáid le parsálaí séimeantach a úsáideann díchódú uathchéimnitheach. . Faigheann SmBoP 71.1 cruinneas sainchomhartha ar Spider, ag bunú cluiche nua den scoth, agus 69.5 meaitseáil bheacht, atá inchomparáide leis an meaitseáil bheacht 69.6 den autoregressive RAT-SQL+Grappa.', 'hu': 'Az elmúlt években a szemantikai elemzéshez szükséges de-facto szabványos dekódolási módszer az volt, hogy a célprogram absztrakt szintaxisfáját automatikusan dekódolja egy felülről lefelé mélységi első áthaladással. Ebben a munkában egy alternatív megközelítést javasolunk: egy Semi-autoregressive Bottom-up Parser (SmBoP), amely a t magasságú felső K alfákat dekódoló lépésnél építi fel. Az elemzőnk több előnyt élvez a felülről lefelé automatizált elemzéshez képest. Hatékonysági szempontból az alulról építkező elemzés lehetővé teszi, hogy párhuzamosan dekódolhassunk minden bizonyos magasságú alterületet, ami logaritmikus futásidő komplexitásához vezet, nem lineáris. Modellezési perspektívából az alulról felfelé épülő elemző minden lépésben megtanulja a jelentős szemantikai alprogramok reprezentációit, nem pedig a szemantikailag üres részleges fák esetében. Az SmBoP-t a Spider-re alkalmazzuk, egy kihívást jelentő zero-shot szemantikai elemzési referenciaértéket, és megmutatjuk, hogy az SmBoP 2,2x felgyorsulást eredményez a dekódolási időben és ~ 5x felgyorsulást az edzési időben, összehasonlítva egy automatikus dekódolást használó szemantikai elemzővel. Az SmBoP 71.1-es jelölési pontosságot biztosít Spider-en, így egy új korszerű és 69.5 pontos egyezést hoz létre, amely összehasonlítható az autoregresszív RAT-SQL+Grappa 69.6 pontos egyezésével.', 'el': 'Η τυπική μέθοδος αποκωδικοποίησης για τη σημασιολογική ανάλυση τα τελευταία χρόνια ήταν η αυτόματη αποκωδικοποίηση του αφηρημένου δέντρου σύνταξης του προγράμματος-στόχου χρησιμοποιώντας μια διαδρομή από πάνω προς τα κάτω. Σε αυτή την εργασία, προτείνουμε μια εναλλακτική προσέγγιση: μια ημι-αυτοανακριτική ανάλυση από κάτω προς τα πάνω (που κατασκευάζει στο βήμα αποκωδικοποίησης τα υποδόδεντρα κορυφής-Κ του ύψους Ο αναλυτής μας απολαμβάνει πολλά οφέλη σε σύγκριση με την αυτοανακριτική ανάλυση από πάνω προς τα κάτω. Από άποψη αποδοτικότητας, η ανάλυση από κάτω προς τα πάνω επιτρέπει την αποκωδικοποίηση όλων των υποδέντρων ενός συγκεκριμένου ύψους παράλληλα, οδηγώντας σε λογαριθμική πολυπλοκότητα χρόνου εκτέλεσης και όχι γραμμική. Από μια οπτική μοντελοποίησης, ένας αναλυτής από κάτω προς τα πάνω μαθαίνει αναπαραστάσεις για σημασιολογικά υποπρογράμματα σε κάθε βήμα, και όχι για σημασιολογικά κενά μερικά δέντρα. Εφαρμόζουμε το SmBoP στον Σπάιντερ, ένα προκλητικό σημείο αναφοράς σημασιολογικής ανάλυσης μηδενικού πυροβολισμού, και δείχνουμε ότι το SmBoP οδηγεί σε 2,2ταχύτητα στον χρόνο αποκωδικοποίησης και σε ~5ταχύτητα στο χρόνο εκπαίδευσης, σε σύγκριση με έναν σημασιολογικό αναλυτή που χρησιμοποιεί αυτόματη αποκωδικοποίηση. Η SmBoP αποκτά ακρίβεια ένδειξης 71.1 στον Σπάιντερ, καθιερώνοντας μια νέα υπερσύγχρονη και 69.5 ακριβή αντιστοιχία, συγκρίσιμη με την 69.6 ακριβή αντιστοιχία του αυτοαναδρομικού RAT-SQL+Grappa.', 'ka': 'დე-ფაქტო სტანდექტური სტანდექტური სტანდექტური პროგრამის აბსტრაქტური სტანდექტის მეტი, რომელიც შემდეგ წლის განაწერისთვის, იყო ავტორეგრექსიურად სტანდექტური სინტაქსის ამ სამუშაოში, ჩვენ დავიწყებთ ალტენტიფიური პროგრამა: სამუშაო- ავტორეგრესიური ქვემო- ზემო პროგრამა (SmBoP) რომელიც კონფიგურაციაში კონფიგურაციაში t სამუშაო- K სამუშაო სიმაღლეობის სამუშაო ხე ეფექტიურობის პერსპექტიკისგან, ქვემოთ პანსტირება შესაძლებელია ყველა ქვემო ხელის განსაკუთრებული სიმაღლე პარალელეში, რომელიც ლოდარიტური წარმოდგენის კომპლექტირება მოდელური პერსპექტიკის დამატებით, დამატებითი პერსპექტიკი სწავლის გამოსახულებების სანიშვნელოვანი სემონტიკური პროგრამების განმავლობაში, ვიდრე სემონტიკურად გაკუნტი ჩვენ SmBoP-ს Spider-ზე გამოყენებთ, საშუალებელი ნულ სტატიული სმენტიკური პანქმენტიკური პანქმენტის ბენქმენტი, და ჩვენ აჩვენებთ, რომ SmBoP-ს გამოყენება 2.2x სიჩქარე და ~5x სიჩქარე სტატიკური სიჩქარე, რომელიც ავტორეგრესი SmBoP მიიღება 71.1 მონიშნულების წარმოდგენება Spider-ზე, ახალი სურათის სურათის სურათი და 69.5 წარმოდგენება, რომელიც 69.6 წარმოდგენებულია სურათი RAT-SQL+Grappa-ის წარმოდგენება.', 'it': "Il metodo di decodifica standard de facto per l'analisi semantica negli ultimi anni è stato quello di decodificare automaticamente l'albero della sintassi astratta del programma di destinazione utilizzando una profondità-first traversal dall'alto verso il basso. In questo lavoro, proponiamo un approccio alternativo: un Semi-autoregressivo Bottom-up Parser (SmBoP) che costruisce al passo di decodifica t i sub-alberi top-K di altezza t. Il nostro parser gode di diversi vantaggi rispetto al top-down autoregressivo parsing. Dal punto di vista dell'efficienza, l'analisi bottom-up consente di decodificare tutti i sub-alberi di una certa altezza in parallelo, portando alla complessità logaritmica del runtime piuttosto che lineare. Da una prospettiva di modellazione, un parser bottom-up impara rappresentazioni per sottoprogrammi semantici significativi ad ogni passo, piuttosto che per alberi parziali semanticamente vacui. Applichiamo SmBoP su Spider, un impegnativo benchmark di analisi semantica zero-shot, e mostriamo che SmBoP porta a una velocità di 2,2x nel tempo di decodifica e una velocità di ~ 5x nel tempo di allenamento, rispetto ad un parser semantico che utilizza decodifica autoregressiva. SmBoP ottiene una precisione di denotazione 71.1 su Spider, stabilendo un nuovo stato dell'arte, e 69.5 esatta corrispondenza, paragonabile alla corrispondenza esatta 69.6 dell'autoregressivo RAT-SQL+Grappa.", 'lt': 'Pastaraisiais metais semantinio analizavimo de facto standartinis dekodizavimo metodas buvo automatiškai dekoderuoti tikslinės programos abstraktųjį sintaksų medį naudojant pirmąjį perėjimą iš viršaus į apačią. In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height  t. Our parser enjoys several benefits compared to top-down autoregressive parsing.  From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  Iš modeliavimo perspektyvos analizatorius iš apačios į viršų mokosi kiekvienu etapu reikšmingų semantinių paprogramų, o ne semantiniu požiūriu vakuolių dalinių medžių. Mes taikome SmBoP Spider, sunkų nulinio nuotraukos semantinio analizavimo lyginamąjį rodiklį, ir rodome, kad SmBoP sukelia 2,2 karto greitesnį dekodiavimo laiko ir ~5x greitesnį mokymo laiko, palyginti su semantiniu analizatoriumi, kuris naudoja autoregresinį dekodiavimą. SmBoP gauna 71,1 denotacijos tikslumą Spider, nustatant naują naujausią pažangą ir 69,5 tikslų atitiktį, palyginamą su 69,6 tiksliu autoregresinio RAT-SQL+Grappa atitiktimi.', 'kk': 'Соңғы жылдарда семантикалық талдау үшін де- факто стандартты декодтау әдісі - мақсатты бағдарламаның абстракты синтаксис бұтағын жоғары- төменгі тереңдік алғашқы тереңдігін қолдану арқылы авторес Бұл жұмыста, біз альтернативті қасиетін таңдаймыз: Төмендегі төмендегі авторегрессивнің төмендегі парзері (SmBoP) декодтамасында құрылады. Эффективдік перспективінен төмендегі талдау барлық төмендегі бұтақтарды параллель биіктігіне декодтауға мүмкіндік береді. Логарифмдік орындау уақытын сызықты емес, жұмыс уақытын Модельдің перспективінен төмендегі талдаушы бір қадамда semantic ішкі бағдарламалардың негізгі суббағдарламаларын біледі, семантикалық бөлікті ағаштардың орнына. Біз Спидерде SmBoP қолданып, нөл- шектердің семантикалық талдау белгісін қолданып, SmBoP декодтау уақытында 2. 2x жылдамдығын және ~5x жылдамдығын бақылау уақытында салыстырып, автоregressивті декодтау қолданылатын семантикалық талдаушысына салыстыр SmBoP Спидердің 71. 1 деңгейіндегі дұрыстығын жеткізеді, жаңа суреттің күйін орнату және 69. 5 деңгейіндегі дұрыс сәйкес келеді. Автогрессивнің RAT- SQL+Grappa ның 69. 6 деңгейіндегі дұрыс сәйкес келеді.', 'mk': 'Дефактичниот стандарден метод на декодирање за семантично анализирање во последните години беше авторегресивно декодирање на апстрактното синтаксиско дрво на целната програма користејќи перверзник од горе до долу. Во оваа работа, предложуваме алтернативен пристап: полуавторегресивен анализатор од дното нагоре (SmBoP) кој конструира на чекорот на декодирање t на највисоките K поддрвја од висина t. Нашиот анализатор ужива во неколку бенефиции во споредба со анализатор од горе нагоре нагоре. Од перспектива на ефикасност, анализирањето од дното нагоре овозможува декодирање на сите поддрвја од одредена висина паралелно, што води до логаритмичка комплексност на текот наместо линијарна. Од перспектива на моделирање, анализаторот од дното нагоре научи претставувања за значајни семантични подпрограми во секој чекор, наместо за семантички вакуозни делумни дрвја. Го применуваме СМБОП на Пајак, предизвикувачки семантичен анализатор со нула снимка, и покажуваме дека СМБОП води до 2,2x забрзување во времето на декодирање и ~5x забрзување во времето на тренинг, во споредба со семантичен анализатор кој користи авторегресивно декодирање. СМБоП добива точност од 71,1 на спојувањето на Пајак, воспоставувајќи нова најнова технологија и 69,5 точност, во споредба со точноста од 69,6 на авторегресивната RAT-SQL+Grappa.', 'ms': 'The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal.  Dalam kerja ini, kami cadangkan pendekatan alternatif: Penjana Semi-Autoregressif Bottom-Up (SmBoP) yang membina pada langkah penyahkodan t sub-pokok atas-K tinggi t. Penjana kami menikmati beberapa keuntungan dibandingkan dengan penyahkodan autoregressif atas-bawah. From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees.  Kami melaksanakan SmBoP pada Spider, tanda benchmark penghuraian semantik tanpa tembakan sifar, dan menunjukkan bahawa SmBoP membawa kepada 2.2x kecepatan dalam masa penyahkodan dan ~5x kecepatan dalam masa latihan, dibandingkan dengan penghuraian semantik yang menggunakan penyahkodan autoregresif. SmBoP mendapat akurat denotasi 71.1 pada Spider, menetapkan keadaan-state-of-the-art baru, dan 69.5 persamaan yang tepat, dibandingkan dengan persamaan 69.6 persamaan RAT-SQL+Grappa autoregresif.', 'ml': 'അടുത്ത വര്\u200dഷങ്ങളില്\u200d സെമാന്റിക് പാര്\u200dസിങ്ങിനുള്ള ഡെഫാക്റ്റോ സാധാരണ ഡികോഡിങ്ങ് രീതിയിലായിരിക്കുന്നു ലക്ഷ്യം പ്രോഗ്രാമിലെ അബ്രാക്ട ഈ പ്രവര്\u200dത്തനത്തില്\u200d നമ്മള്\u200d മറ്റൊരു മാറ്റം പ്രായോഗ്രാം ചെയ്യുന്നു: മുകളില്\u200d നിന്നും നിര്\u200dമ്മിക്കുന്ന പാര്\u200dസിങ്ങിന്\u200dറെ മുകളില്\u200d കെയിട്ടുള്ള ഉയരത്തിന്\u200dറെ ഉയര്\u200dച്ചയില്\u200d  From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  ഒരു മോഡലിങ് കാഴ്ചപ്പാടില്\u200d നിന്നും ഒരു താഴെയുള്ള പാല്\u200dസാര്\u200d പഠിക്കുന്നു, ഓരോ പടിയിലും അര്\u200dത്ഥമായ സെമാന്\u200dറിക് സബ് പ്രോഗ്രാമുകള്\u200dക സ്പൈഡരില്\u200d സ്മോബോപ്പിനെ പ്രയോഗിക്കുന്നു. പൂജ്യത്തിന്റെ സെമാന്റിക് പാര്\u200dക്കിങ് ബെന്\u200dമാര്\u200dക്കില്\u200d വെച്ച് പ്രയോഗിക്കുന്നു. സ്മോംബോപിന് സമയത്തിന്റെ ഡികോഡിങ്ങിലേക സ്മോബോപി സ്പൈഡരില്\u200d 71. 1 ഡെനോറേഷന്\u200d വിശേഷം ലഭിക്കുന്നു. ഒരു പുതിയ സ്റ്റേറ്റ് ഓഫ് സ്റ്റേറ്റ് സ്ഥാപിക്കുന്നു. 69. 5 പ്രധാനപൂര്\u200dണ്ണമായ മാന്റ് സ്പെയിന്\u200d', 'mt': 'Il-metodu ta’ dekodifikazzjoni standard de-facto għall-analizzazzjoni semantika f’dawn l-a ħħar snin kien li jiġi dekodifikat awtoregressivament is-siġra tas-sintaks astratt tal-programm fil-mira bl-użu ta’ traversal minn fuq għal isfel minn fond għall-ewwel. F’dan ix-xogħol, qed nipproponu approċċ alternattiv: Parser Semi-awtoregressiv minn isfel għal fuq (SmBoP) li jibni fil-pass tad-dekodifikazzjoni t is-subsiġar t a’ fuq K ta’ għoli t. Il-parser tagħna jgawdi minn diversi benefiċċji meta mqabbel mal-parsing awtoregressiv minn fuq għal isfel. Minn perspettiva ta’ effiċjenza, l-analiżi minn isfel għal fuq tippermetti d-dekodifikazzjoni tas-subsiġar kollha ta’ ċertu għoli b’mod parallel, li jwassal għal kumplessità logaritmika tal-ħin ta’ tħaddim aktar milli lineari. Minn perspettiva ta’ mudell, analizzatur minn isfel għal fuq jitgħallem rappreżentazzjonijiet għal sottoprogrammi semantiċi sinifikanti f’kull pass, aktar milli għal siġar parzjali semantikament vojt. Aħna napplikaw SmBoP fuq Spider, punt ta’ riferiment semantiku ta’ analiżi mingħajr skop ta’ sfida, u nuru li SmBoP iwassal għal veloċità ta’ 2.2x fil-ħin tad-dekodifikazzjoni u veloċità ta’  ~5x fil-ħin tat-taħriġ, meta mqabbel ma’ analizzatur semantiku li juża dekodifikazzjoni awtoregressiva. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'pl': 'De-facto standardową metodą dekodowania do parsowania semantycznego w ostatnich latach było autoregresywne dekodowanie abstrakcyjnego drzewa składni programu docelowego przy użyciu traversalu głębokości pierwszej. W niniejszej pracy proponujemy alternatywne podejście: Semi-autoregresywny Bottom-up Parser (SmBoP), który konstruuje w kroku dekodowania poddrzewa top-K o wysokości t. Nasz parser cieszy się kilkoma korzyściami w porównaniu z autoregresywnym parsowaniem górnym w dół. Z punktu widzenia efektywności parsowanie oddolne pozwala równolegle dekodować wszystkie poddrzewa o określonej wysokości, co prowadzi do logarytmicznej złożoności czasu wykonania, a nie liniowego. Z perspektywy modelowania, parser oddolny uczy się reprezentacji znaczących podprogramów semantycznych na każdym kroku, a nie dla semantycznie pustych drzew częściowych. Stosujemy SmBoP na Spiderze, wymagającym zerowym standardzie analizy semantycznej, i pokazujemy, że SmBoP prowadzi do 2,2x przyspieszenia czasu dekodowania i ~5x przyspieszenia w czasie treningu, w porównaniu z parserem semantycznym wykorzystującym autoregresywne dekodowanie. SmBoP uzyskuje dokładność oznaczenia 71.1 na Spiderze, ustanawiając nowy state-of-the-art i 69.5 dokładne dopasowanie, porównywalne do 69.6 dokładnego dopasowania autoregresywnego RAT-SQL+Grappa.', 'mn': 'Сүүлийн жилүүдэд семантик хуваалцах стандарт шинэчлэлтийн арга нь зорилготой програмын абстрактик синтаксисын модыг автоматаар хуваалцах юм. Энэ ажлын хувьд бид өөр нэг арга замыг санал болгож байна: доорх автоматжруулагч доорх доорх хэмжээний (SmBoP) парзер. t дээд-K суб-мод өндөртэй (t) хэмжээний арга замыг шинэчлэхэд үүсгэдэг. Үзэмшилтэй байдлаас доорх хуваалцах нь бүх субмодыг параллел дээр хуваалцах боломжтой. Логарифмын ажиллах цаг хугацааны цогцуудыг шулууны оронд хуваалцах боломжтой. Загварчлалын үзэл дээр суурь хуваарч нь алхам тутамд ямар нэгэн утгатай semantic суб-программыг суралцаж суралцаж байлаа. Энгээд суурь хуваарь моднуудын оронд. Бид СМБОП-г СМБОП-д хэрэглэдэг. Зуун зураг шинжилгээний шинжилгээ нь шаардлагатай. СМБОП нь авторегрессийн шинжилгээ ашигладаг семантик шинжилгээнтэй харьцуулахад 2.2x хурдыг хурдан шинжилгээ, сургалтын цаг дээр ~5x хурдан хурдан хүргэж байна. СМБО 71.1 хуваалтын зөв тодорхойлолт гаргаж, урлагийн шинэ байдал үүсгэдэг, 69.5 хуваалтыг автоregressive RAT-SQL+Grappa-тай харьцуулж байна.', 'ro': 'Metoda de decodare standard de facto pentru analizarea semantică în ultimii ani a fost decodarea automată a arborelui sintaxei abstracte al programului țintă folosind o traversare adâncime sus-în jos. În această lucrare, propunem o abordare alternativă: un Parser semi-autoregressiv Bottom-up (SmBoP) care construiește la pasul de decodare t sub-arborii K de vârf de înălțime t. Parserul nostru beneficiază de mai multe beneficii comparativ cu parsing auto-regressiv de sus în jos. Din perspectiva eficienței, analizarea de jos în sus permite decodarea tuturor subarborilor de o anumită înălțime în paralel, ducând la complexitatea logaritmică a timpului de rulare mai degrabă decât liniară. Dintr-o perspectivă de modelare, un parser de jos în sus învață reprezentări pentru sub-programe semantice semnificative la fiecare pas, mai degrabă decât pentru copaci parțiali semantic-vacui. Aplicăm SmBoP pe Spider, un criteriu de analiză semantică zero-shot provocator, și arătăm că SmBoP duce la o viteză de 2,2x în timpul de decodare și o viteză de ~ 5x în timpul de formare, comparativ cu un parser semantic care utilizează decodarea autoregresivă. SmBoP obține o precizie de denotare 71.1 pe Spider, stabilind un nou stat-of-the-art, și 69.5 potrivire exactă, comparabilă cu potrivirea exactă 69.6 a autoregresivului RAT-SQL+Grappa.', 'sr': 'Standardna metoda dekodiranja de-fakto za semantičko analizu u poslednjih godina je bila da autoregresivno dekodira abstraktno sintaksno drvo ciljnog program a koristeći najgornju dubinu-prvu traverzalnu. U ovom poslu predlažemo alternativni pristup: polu-autoregresivni dolje-gore Parser (SmBoP) koji konstruuje na dekodiranju koraka t poddrveta visine top-K i t. Naš analizač uživa u nekoliko koristi u usporedbi sa autoregresivnim analizacijom vrha dole. Iz perspektive učinkovitosti, analizanje donjeg gore omogućava da dekodira sve poddrveće određene visine paralelno, što dovodi do logaritmske složenosti kretanja umjesto linearne. Iz modeliranog perspektiva, razglednik dole uči predstave za značajne semantičke podprograme na svakom koraku, a ne za semantički odvažne djelomične drveće. Primjenjujemo SmBoP na Pajder, izazovnu semantičku analizu bez pucnjave, i pokažemo da SmBoP vodi do brzine od 2,2x u dekodiranju vremena i brzinu od ~5x u vreme treninga u usporedbi sa semantičkim analizatorom koji koristi autoregresivnu dekodiranju. SmBoP dobija tačnost 71,1 denotacije na Pajderu, uspostavljajući novu stanju umjetnosti, i 69,5 tačnu utakmicu, usporedbenu sa tačnom utakmicom 69,6 autoregresivnog RAT-SQL+Grape.', 'no': 'Standarddekoderingsmetoden for semantisk tolking i siste år har vært til å autoregressivt dekode abstrakt syntakstrået i målprogrammet med ein første traversal på topp- ned dybde. I denne arbeida foreslår vi ein alternativ tilnærming: ein semi- autoregressiv nedover- lesar (SmBoP) som konstruerer ved dekodering av steg t den øvre- K- undertråda med høgda t. Tolkaren vårt brukar fleire fordeler samanlikna med autoregressiv tolking øvre ned. Fra ein effektivt perspektiv kan undertrekk dekode alle undertrekk med ein viss høgd i parallell, som fører til logaritmisk køyrande kompleksitet i staden for lineær. Fra ein modelleringsperspektiv lærer ein tolkar nedover representasjonar for meaningfulle semantiske underprogram på kvar steg, i staden for semantisk-vakus delvis tre. Vi bruker SmBoP på Spider, eit vanskeleg semantisk tolking av nullsett, og viser at SmBoP fører til ein 2,2x raskaren i dekoderingstid og ein ~5x raskaren i treningstid, samanlikna med ein semantisk tolkar som brukar autoregressivt dekodering. SmBoP får 71,1 nøyaktighet på Spider, opprettar eit nytt kunsttilstand og 69,5 nøyaktig treff, sammenlignbar med nøyaktig 69,6 nøyaktig treff på den autoregressive RAT-SQL+Grappa.', 'so': 'Soo dhowaadkii sannadihii ugu dambeeyey waa in aad automatic dib u deymisaa geedkii ka baxsaday syntada ee barnaamijka la jiiday oo lagu isticmaalo hoos-hoos-hoos-ugu-horraysa. Markaas waxan, waxaynu soo jeedaynaa qaab kale ah: koob-auto-regressive Bottom-up Parser (SmBoP) oo ku dhisan jardiinada deynta iyo geedaha hoose-K ee sare Sida aad aragtida faa’iidada ku jirto, jardiinada hoose-hoose wuxuu u ogolaan karaa inuu kordhiyo geedaha hoose ee sare oo dhan, taasoo ka horeysa dhibaatada xiliga ku socoshada qoraalka, taasoo ka bedela qoraalka. Sida muuqashada, baaritaanka hoose-ka-sareeya ayaa wax ka baranaya noocyada kooxaha hoose-barnaamijyada ah oo maanka ah ee semantic sub-programka, badala geedaha qayb ahaan ee qeybta ah. Waxaynu ku dalbannaa SmBoP-ka Spider, mid qiimo ah zero-shot semantic parsing benchmark, waxaana muujinaynaa in SmBoP uu keenaa 2.2x speed-up xilliga deynta iyo ~5x speed-up xilliga waxbarashada, compared to a semantic Parser that uses autoregressive decoding. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'sv': 'De facto standardavkodningsmetoden för semantisk tolkning under de senaste åren har varit att autoregressivt avkoda det abstrakta syntaxträdet i målprogrammet med hjälp av en uppifrån och ner djupgående första traversal. I detta arbete föreslår vi ett alternativt tillvägagångssätt: en Semi-autoregressiv bottom-up parser (SmBoP) som konstruerar vid avkodning steg t de översta K sub-träden av höjd t. Vår parser har flera fördelar jämfört med top-down autoregressiv parsing. Ur ett effektivitetsperspektiv gör bottom-up parsing det möjligt att avkoda alla underträd med en viss höjd parallellt, vilket leder till logaritmisk körtidskomplexitet snarare än linjär. Ur ett modelleringsperspektiv lär sig en bottom-up parser representationer för meningsfulla semantiska delprogram vid varje steg, snarare än för semantiskt vakuum partiella träd. Vi tillämpar SmBoP på Spider, en utmanande noll-shot semantisk parsing benchmark, och visar att SmBoP leder till en 2,2x hastighet i avkodningstid och en ~ 5x hastighet i träningstid, jämfört med en semantisk parser som använder autoregressiv avkodning. SmBoP erhåller 71,1 denotation noggrannhet på Spider, vilket etablerar en ny state-of-the-art, och 69,5 exakt matchning, jämförbar med 69,6 exakt matchning av den autoregressiva RAT-SQL+Grappa.', 'si': 'සෙමැන්ටික් විශ්ලේෂණය සඳහා ප්\u200dරමාණික සංකේෂණ විධානය අවස්ථානයෙන් ස්ථාවිත සංකේෂණ විධානය ස්වයංක්\u200dරීය විශ්ලේෂණය මේ වැඩේ අපි වෙනස් විදිහට ප්\u200dරවේශනයක් ප්\u200dරයෝජනය කරනවා: බිම- ස්වයංක්\u200dරියාත්මක ප්\u200dරවේශකය (SmBoP) කිරීමේ ප්\u200dරවේශකයෙන් ප්\u200dරවේශකයෙන් ප්\u200dරවේශකයෙන් ප්\u200dරවේශකයෙ ප්\u200dරශ්ණතාවයක් ප්\u200dරදේශයක් නිසා, පහලට පාර්සික් කරන්න පුළුවන් සමාන්\u200dයයෙන් හැම සබ- ගස් වලින් සියළු උස්සම් වලින් සාමා මොඩේලන් ප්\u200dරදේශයක් නිසා, බිඳින් විශේෂකයෙක් ඉගෙන ගන්නවා හැම පැත්තෙන්ම විශේෂ සැමැන්තික සැබැන්තික ව්\u200dයාප්\u200dරකාරයක අපි ස්පායිඩර් වල SmBoP භාවිතා කරනවා, සුන්ධ ශූන්ධ විශේෂ සෙමැන්ටික් විශේෂ බෙන්ච්මාර්ක් වලින් ස්මාන්ටික් විශේෂ කරනවා, ඒ වගේම පෙන්වන්නේ ස්මාන්ටික Name', 'ta': 'சமீபத்திய ஆண்டுகளில் பெமான்டிக் பாசிங்குக்கான de- facto standard decoding method has been to automatically decode the abstract syntax tree of the target program using a top- down depth- first traversal. இந்த வேலையில், நாம் மாற்று முறையான முறையீட்டை பரிந்துரைக்கிறோம்: மேல்- கீழ் தானியங்கி கட்டுப்பாட்டின் மேல்- K துணை மரங்களை உயரத்தில் கட்டும் பொருட்டு பாக்கி ஒரு செயல்பாட்டின் காட்சியிலிருந்து, கீழ் மேல் பாசிங் குறிப்பிட அனைத்து உயரத்தின் துணை மரங்களையும் இணையில் குறியீடு அனுமதிக்கும், கோட ஒரு மாதிரி காட்சியிலிருந்து, கீழ்- மேல் பகுதிகள் ஒவ்வொரு படியிலும் அர்த்தமான பெமான்டிக் துணை நிரல்களுக்கு குறிப்புகளை கற்று கொ ஸ்பைட்டரின் மீது சிம்போபி பயன்படுத்துகிறோம், பூஜ்ஜியமான பெமான்டிக் பாக்கிங் பென்க்மேக் பாங்க்கில் சிக்கலான செய்யும், எம்போபி குறியீட்டு நேரத்தில் 2. 2x வேகத்திற SmBoP சுழற்சியில் 71. 1 டென்டாக்கு சரியான மதிப்பை கிடைக்கும், புதிய கலை நிலையை நிறுவுகிறது, மற்றும் 69. 5 சரியான விளையாட்டை பொருத்துகிறது, தானியங்கி ராட்-SQ', 'ur': 'اگلے سالوں میں سیمنٹی پارسینگ کے لئے استاندارڈ ڈیکوڈنگ طریقہ یہ ہے کہ موقع پروگرامہ کے مطلوب سینٹکس درخت کو اپنا دفع کرنا چاہے۔ اس کام میں ہم ایک الٹی طریقہ پیش کریں گے: ایک نیچے-اٹی-اٹی-اٹی پارس (SmBoP) جو سٹے کو دکوڈ کرنے کے لئے بناتا ہے۔ ایک عملکرد نظر سے، نیچے بالا پارسینگ کے ذریعہ ایک مقررہ بلند درخت کے سارے زیر درختوں کو دھوکا دینے کے لئے اجازت دیتا ہے، لینار کے بغیر لوگریٹمیک رونٹمیک زمانہ پیچیدگی کی وجہ سے۔ ایک نمڈلینگ نظر سے، ایک نیچے پارچر نے ہر قدم پر مطلوب سیمانٹی ساب پروگراموں کے لئے نمونات سکھائی ہے، بغیر اس سے کہ ایک نمونٹی پارٹی درخت کے لئے نمونات سکھائی جاتی ہیں. ہم اسپیڈر پر SMBoP کو لازم کرتے ہیں، ایک مشکل صفر-شٹ سیمنٹی پارسینگ بنچم مارک، اور دکھاتے ہیں کہ اسم بوپ کو دکوندیوں کے وقت میں 2.2x سرعت آپٹ تک پہنچاتا ہے اور ایک ~5x سرعت آپٹ تطالب وقت میں، ایک سیمنٹی پارسینٹر کے مقابلہ میں جو autoregressive ڈکوندیوں کا استعمال کر اسم بوپ اسپیڈر پر 71.1 دقیق دقیق حاصل کرتا ہے، ایک نئی حالت-آرت، اور 69.5 دقیق مطابق مطابق، 69.6 دقیق مطابق RAT-SQL+Grappa کے مطابق مطابق مطابق ہے.', 'uz': "Yaqinda yil davomida semantik parsing uchun de-facto standard kodlash usuli avtomatik kodlash usuli, yuqori- pastdagi koʻp- birinchi traversal yordamida ravishda avtomatik kodlash usuli. Bu vazifanda, biz boshqa usul bilan boshlanamiz: Semi-auto-regressiv pastor (SmBoP), yuqori K'ning sarlavhasi darajadagi sub-darajadagi darajaga yaratish. Parametrning eng yuqori darajaga avto-regressiv parsing bilan bir nechta foydalanadi. Ko'rinishidan foydalanish uchun pastki parsing boshqa darajadagi hamma tub darajalarni parametrlarda kodlash imkoniyatlariga ruxsat beradi. Model ko'rinishidan pastki parametr har bir qadamdagi semantik sub-dasturlarning xususiyatlarini o'rganadi va semantik vaqt bo'lgan qismi daraxtlaridan o'rganadi. Name Name", 'vi': 'Cách giải mã kiểu mẫu cho việc phân tích theo ngữ pháp trong những năm gần đây là tự vệ giải mã cấu trúc tổng thể của chương trình đạt mục tiêu bằng màn xuyên đầu tiên. Trong công việc này, chúng t ôi đề nghị một phương pháp khác: một thầy phân tích con mẹ mẹ ngược chiều (SmBoP) làm ra ở bậc giải mã tầng trên K. Vị cha của chúng tôi có nhiều lợi ích so với bậc phân giải ngược chiều trên. Từ góc độ hiệu quả, phân tách từ dưới cho phép giải tất cả các chi nhánh có độ cao nhất định song song song, dẫn tới tính phức tạp dòng thời gian logaritic hơn là tuyến. Từ góc độ người mẫu, một cha xứ tìm hiểu các biểu tượng về các chương trình theo ngữ pháp đầy ý nghĩa ở mỗi bước, thay vì với cây nhỏ dãi theo ngữ nghĩa. Chúng ta áp dụng SmBoP on Spider, một tiêu chuẩn phân tích không phải đầy thử thách, và cho thấy SmBoP có một tốc độ 2.2x trong thời gian giải mã và một tốc độ cao hơn 5x trong thời gian huấn luyện, so với một phân tích ngữ pháp dùng thiết kế tự vệ. Một sự chất nhận được lên trên Spider, nhận ra một ít sự thấy mới tinh thần, và thiết lịch 69.6, tương đương với to án bộ thống RAT-SQL+Grappa.', 'bg': 'Де-факто стандартният метод за декодиране на семантичен анализ през последните години е бил авторегресивно декодиране на абстрактното синтаксисно дърво на целевата програма, използвайки нависоко дълбочина-първо траверсално. В тази работа предлагаме алтернативен подход: полу-авторегресивен анализатор отдолу нагоре (който конструира при декодиране на стъпалото отгоре-К поддървета с височина Нашият анализатор се радва на няколко предимства в сравнение с авторегресивния анализатор отгоре-надолу. От гледна точка на ефективността, анализаторът отдолу нагоре позволява да се декодират всички поддървета с определена височина паралелно, което води до логаритмична сложност по време на изпълнение, а не линейна. От гледна точка на моделирането, анализаторът отдолу нагоре научава представяне за смислени семантични подпрограми на всяка стъпка, а не за семантично празни частични дървета. Ние прилагаме на предизвикателен нулев семантичен анализ бенчмарк и показваме, че води до 2.2кратно ускорение във времето за декодиране и ~ 5кратно ускорение във времето за обучение, в сравнение със семантичен анализатор, който използва авторегресивно декодиране. СмБоП получава 71.1 точност на обозначаване на Спайдър, установявайки ново състояние на изкуството и 69.5 точно съвпадение, сравнимо с 69.6 точното съвпадение на авторегресивния РАТ-SQL+Грапа.', 'nl': "De feitelijke standaard decoderingsmethode voor semantisch parsen in de afgelopen jaren is het autoregressief decoderen van de abstracte syntaxisboom van het doelprogramma met behulp van een top-down deep-first traversal. In dit werk stellen we een alternatieve aanpak voor: een Semi-autoregressieve Bottom-up Parser (SmBoP) die bij decoderingsstap t de top-K subbomen van hoogte t construeert. Onze parser geniet verschillende voordelen ten opzichte van top-down autoregressieve parsing. Vanuit een efficiëntieperspectief maakt bottom-up parsing het mogelijk om alle subbomen van een bepaalde hoogte parallel te decoderen, wat leidt tot logaritmische runtime complexiteit in plaats van lineair. Vanuit een modelleringsperspectief leert een bottom-up parser bij elke stap representaties voor betekenisvolle semantische subprogramma's in plaats van voor semantisch-vacueuze deelbomen. We passen SmBoP toe op Spider, een uitdagende zero-shot semantische parsing benchmark, en laten zien dat SmBoP leidt tot een 2,2x versnelling in decoderingstijd en een ~5x versnelling in trainingstijd, vergeleken met een semantische parser die autoregressieve decodering gebruikt. SmBoP verkrijgt 71.1 denotatie nauwkeurigheid op Spider, waardoor een nieuwe state-of-the-art, en 69.5 exacte match wordt vastgesteld, vergelijkbaar met de 69.6 exacte match van de autoregressieve RAT-SQL+Grappa.", 'de': 'Die de-facto Standard-Dekodierungsmethode für semantisches Parsen in den letzten Jahren bestand darin, den abstrakten Syntaxbaum des Zielprogramms mittels eines Top-Down Tiefen-First Traversals autoregressiv zu dekodieren. In dieser Arbeit schlagen wir einen alternativen Ansatz vor: einen semi-autoregressiven Bottom-up Parser (SmBoP), der im Dekodierungsschritt t die top-K Unterbäume der Höhe t konstruiert. Unser Parser hat mehrere Vorteile gegenüber dem top-down autoregressiven Parsen. Aus Effizienzsicht erlaubt Bottom-up Parsing, alle Unterbäume einer bestimmten Höhe parallel zu dekodieren, was zu logarithmischer Laufzeitkomplexität anstatt linear führt. Aus Modellierungsperspektive lernt ein Bottom-up-Parser bei jedem Schritt Repräsentationen für sinnvolle semantische Unterprogramme, anstatt für semantisch-vakuöse Teilbäume. Wir wenden SmBoP auf Spider an, einen herausfordernden Zero-Shot semantischen Parsing Benchmark, und zeigen, dass SmBoP im Vergleich zu einem semantischen Parser, der autoregressive Decodierung verwendet, zu einer 2,2x Beschleunigung der Decodierungszeit und zu einer ~5xen Beschleunigung der Trainingszeit führt. SmBoP erhält 71.1 Denotationsgenauigkeit auf Spider, wodurch eine neue State-of-the-Art und 69.5 exakte Übereinstimmung hergestellt wird, vergleichbar mit der 69.6 exakten Übereinstimmung des autoregressiven RAT-SQL+Grappa.', 'id': 'Metode dekodasi standar de-facto untuk penghuraian semantis selama bertahun-tahun terakhir adalah untuk dekodasi secara otomatis pohon sintaks abstrak dari program sasaran menggunakan perjalanan kedalaman atas ke bawah pertama. Dalam pekerjaan ini, kami mengusulkan pendekatan alternatif: Penyesuai Semi-Autoregressif Bottom-Up (SmBoP) yang membangun pada langkah dekoding t sub-pohon atas-K tinggi t. Penyesuai kami menikmati beberapa keuntungan dibandingkan dengan penyelesuai autoregressif atas-bawah. Dari perspektif efisiensi, penghuraian bawah-atas memungkinkan untuk mendekode semua sub-pohon tinggi tertentu secara paralel, yang menyebabkan kompleksitas logaritmi waktu berjalan daripada linear. Dari sudut pandang model, penganalis bawah-atas belajar representation untuk sub-program semantis yang berarti pada setiap langkah, daripada untuk pepohonan parsial semantis-vakus. Kami menerapkan SmBoP pada Spider, benchmark analisis semantis yang menantang nol tembakan, dan menunjukkan bahwa SmBoP mengarah ke 2,2x kecepatan dalam waktu dekoding dan ~5x kecepatan dalam waktu latihan, dibandingkan dengan analisis semantis yang menggunakan dekoding autoregresif. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'fa': 'روش دکوندن استاندارد استاندارد در سال های اخیر برای تجزیه\u200cگیری سیمانتیک به طور خودآفرینشی درخت سنتاکس مطلق برنامه هدف را با استفاده از درخت عمیق اول عمیق پایین دکورد می\u200cکند. در این کار، ما پیشنهاد می\u200cکنیم یک طریق متفاوت: یک پارسال پایین\u200cپایین\u200cپذیر (SmBoP) که در قدم\u200cهای دکوندی در پایین-K زیر درخت بالای بالا و بالا و بالا را ساخته می\u200cشود. پارسال ما در مقایسه با پارسالی خودگریزی پایین به چند نفع لذت می\u200cبرد. از دیدگاه موثرتی، بررسی پایین بالا اجازه می دهد که تمام زیر درخت\u200cهای بالای یک بلندی معین را در parallel دکورد کند، که به پیچیدگی زمان چرخش لاگریتمی به جای خط است. از یک نگاه نمونه\u200cبندی، یک بازیگر پایین بالا نمایش\u200cهای زیر برنامه\u200cهای semantic معنی در هر قدم یاد می\u200cگیرد، به جای درخت\u200cهای تقسیم\u200cباری بی\u200cفایده\u200cای. ما SMBoP را روی عنکبوت تغییر می\u200cدهیم، یک مقدار تجزیه\u200cکننده\u200cی سیمانتیک صفر را مشکل می\u200cدهیم، و نشان می\u200cدهیم که SmBoP به سرعت 2.2x در زمان decoding و سرعت ~5x در زمان آموزش در مقایسه با یک تجزیه\u200cکننده\u200cی سیمانتیک که از دستگاه\u200cهای خودگریزی استفاده می\u200cکند. SmBoP accuracy of 71.1 denomination on Spider, establishing a new state of the art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'hr': 'Standardna metoda dekodiranja de-facto za semantičko analiziranje u posljednjih godina bila je autoregresivno dekodirati abstraktno sintaksno drvo ciljnog program a koristeći najgornju dubinu-prvu traversal. U ovom poslu predlažemo alternativni pristup: polu-autoregresivni razrednik dolje (SmBoP) koji konstruira na dekodiranju koraka t poddrveta visine top-K i t. Naš analizač uživa u nekoliko koristi u usporedbi s autoregresivnim analizacijom vrha dolje. Iz perspektive učinkovitosti, razmatranje dolje omogućava dekodirati sve poddrveće određene visine paralelno, što dovodi do logaritmičke složenosti kretanja umjesto linearne. Iz modeliranog perspektiva, razglednik dolje uči predstave za značajne semantičke podprograme na svakom koraku, a ne za semantički odvažne djelomične drveće. Primjenjujemo SmBoP na Spider, izazovnu semantičku analizu bez pucnjave i pokazujemo da SmBoP vodi do brzine 2,2x u vrijeme dekodiranja i brzinu ~5x u vrijeme obuke u usporedbi s semantičkim analizatorom koji koristi autoregresivnu dekodiranju. SmBoP dobiva tačnost 71,1 denotacije na Spider, uspostavljajući novi stanje umjetnosti, i 69,5 tačne poklapanja, usporedno s to čnim poklapanjem autoregresivnog RAT-SQL+Grape.', 'da': 'De-facto standard afkodningsmetode til semantisk parsing i de seneste år har været at autoregressivt afkode det abstrakte syntakstræ af målprogrammet ved hjælp af en top-down dybde-første traversal. I dette arbejde foreslår vi en alternativ tilgang: en semi-autoregressiv bottom-up parser (SmBoP), der ved afkodning trin t konstruerer top-K sub-træer af højde t. Vores fortolker har flere fordele sammenlignet med top-down autoregressiv parsing. Fra et effektivitetsperspektiv giver bottom-up parsing mulighed for at afkode alle undertræer af en bestemt højde parallelt, hvilket fører til logaritmisk kørselskompleksitet snarere end lineær. Fra et modelleringsperspektiv lærer en bottom-up parser repræsentationer for meningsfulde semantiske delprogrammer på hvert trin, snarere end for semantisk-vakuum deltræer. Vi anvender SmBoP på Spider, en udfordrende zero-shot semantisk parsing benchmark, og viser, at SmBoP fører til en 2,2x speed-up i afkodningstid og en ~ 5x speed-up i træningstid, sammenlignet med en semantisk parser, der bruger autoregressiv afkodning. SmBoP opnår 71,1 denotation nøjagtighed på Spider, der etablerer en ny state-of-the-art, og 69,5 nøjagtig match, sammenlignelig med 69,6 nøjagtige match af den autoregressive RAT-SQL+Grappa.', 'sw': 'Utawala wa decodi wa kiwango cha kiwango cha ukodi kwa ajili ya uchimbaji wa kimapenzi katika miaka ya hivi karibuni umekuwa ni kwa ajili ya kudhibiti kwa ajili ya kudhibiti mti wa kompyuta wa uongozi wa mpango huo kwa kutumia viwango vya kwanza vya juu-chini. In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height  t. Our parser enjoys several benefits compared to top-down autoregressive parsing.  Kutokana na mtazamo wa ufanisi, ubaguzi wa chini unaruhusu kupunguza miti yote ya chini ya kiwango fulani kwa kiwango fulani, na kusababisha utata wa muda wa magari badala ya mstari. Kutokana na mtazamo wa mifano, mchanganyiko wa chini unajifunza maonyesho kwa ajili ya programu za mitindo ya kishindani kwa kila hatua, badala ya mti wa sekunde usio na usawa. Tunatumia simu za mkononi kwenye Spider, bendera ya uchimbaji wa semantiki isiyo na changamoto, na kuonyesha kwamba SmBoP inapelekea kuongezeka kwa kasi ya muda wa kupunguza muda wa 2.2x na kasi ya ~5x kwa muda wa mafunzo, ukilinganisha na chama cha semantic kinachotumia uchimbaji wa kudhibiti. Vyombo vya SmBoP vinapata uhakika wa punguzo 71.1 kwa Spider, kuanzisha hali mpya ya sanaa, na mchezo wa sahihi 69.5, ukilinganishwa na chama cha 69.6 kinachofanana na RAT-SQL+Grappa.', 'ko': '최근 몇 년 동안 의미 분석의 실제 표준 디코딩 방법은 목표 프로그램의 추상적인 문법 트리를 위에서 아래로 깊이 우선적으로 옮겨다니며 자귀환 디코딩하는 것이다.이 작업에서 우리는 또 다른 방법을 제시했다. 반자귀환자상향해석기 (SmBop) 는 디코딩 단계 t에서 높이가 t인 top-K 서브트리를 구성한다. 위에서 아래로 자귀환해석하는 것보다 우리의 해석기는 몇 가지 장점이 있다.효율의 측면에서 볼 때, 밑에서 위로 분석하면 특정 고도의 모든 하위 트리를 병렬 디코딩할 수 있어, 선형이 아니라 대수가 운행할 때 복잡성을 초래한다.모델링의 측면에서 볼 때 아래에서 위로의 해석기는 의미가 있는 의미 서브루틴의 표시를 한 걸음 한 걸음 배우는 것이지 의미가 텅 빈 부분의 트리가 아니다.SmBop을 스파이더에 적용했는데 도전적인 제로포 의미 해석 기준 테스트였는데, 그 결과 자귀환 디코딩을 사용하는 의미 해석기보다 SmBop이 디코딩 시간에서 2.2배, 훈련 시간에서 약 5배 높아진 것으로 나타났다.SmBop은 스파이더에서 71.1의 표시 정확도를 얻어 새로운 최첨단 수준을 세웠다. 69.5의 정확한 일치는 복귀 RAT-SQL+Grappa의 69.6의 정확한 일치와 비슷하다.', 'tr': "Soňky ýyllar üçin semantik ködleme taýýarlamak üçin faktiski standart kodlemek üçin bu program'yň abstrakt agajyny otoregressiv bir şekilde a çmaktadyr. Bu işde, başga bir golf teklif edip görýäris: semi-autoregressiv Ast-Ast Parser (SmBoP) Etkinlik perspektivden, a şaky parslemek üçin parallel bir alty agaçlaryň ählisini çyzygynda kodlamak üçin eline alýar. Bu da logaritmik işleme zamany çyzygynda çyzygyndan başga edir. Modelleşdirýän perspektivden, a şak bir täzeleçi semantik sub-programlaryň her adımda möhüm ýerleri öwrenip, semantik boş baglaryň ýerine öwrenip otyrýar. Biz Spider üzerinde SmBoP'i uygulaýarys, 0-atly semantik analýşim çykyşynda çykyş çykyşlygy we SmBoP'i otoregressiv kodlamak üçin 2.2x hızynda deňleýän bir depleksiýa we ~5x hızyndan geçirilýär SmBoP örümdeki 71.1 hasaplanjaň dogrylygyny kabul edip, täze bir sanat taýýarlanýar we 69.5 hasaplanjaň dogrylygyny düzenleýär. Otomatik regressiv RAT-SQL+Grappanyň dogrylygyny ýarylýar.", 'af': "Die de- facto standaard dekoding metode vir semantiese verwerking in onlangse jaar is om die abstrakte sintaks boom van die doel program te dekode met 'n bo- down diepte- eerste traversal te gebruik. In hierdie werk voorstel ons 'n alternatiewe toegang: ' n Semi- autoregressief Bodem- Op Parser (SmBoP) wat konstrukteer by dekodering stap t die bo- K sub- bome van hoogte & # 160; t. Ons analyseer verkies verskeie voordele vergelyk met bo- down autoregressief verwerking. Van 'n effektief perspektief laat onderste verwerking toe om alle sub- bome van 'n sekere hoogte in parallele te dekode, wat lei na logaritmiske uitvoerde tydskompleksiteit eerder as lyn. Van 'n modeling perspektief leer 'n onderste ontvanger voorstellings vir betekende semantiese subprogramme op elke stap, eerder as vir semantiese-vacuuus gedeeltelike bome. Ons wend SmBoP op Spider toe, 'n pragtige nul-skoot semantiese verwerking benchmark, en wys dat SmBoP lei na 'n 2.2x spoed- up in dekodering tyd en 'n ~5x spoed- up in oefening tyd, vergelyk met 'n semantiese ontwerker wat outomatiese dekodering gebruik. Name", 'am': 'በአሁኑ ዓመታት ውስጥ የዶ-facto standard decoding method for semantic parsing has been automatically decorated the abstract Syntax tree of the target program using a top-down depth-first traversal. በዚህ ስራ፣ የተለየ ልዩ ልማድ አካሄድ እናስባለን፡፡ ከላይ-የክፍለ ደረጃዎች በላይ የK ደብዳቤ ዛፎች ከፍተኛ ክፍል ላይ በሚያሳድግ የተመሠረተውን Semi-autoregressive-bottom-Parser (SmBoP) እናሳውቃለን፡፡ ከ ጥያቄ ማሳየት፣ ወደ ታች ማዘጋጀት በቁመት ላይ ያሉትን የጥልቅ ዛፎችን ሁሉ ማሳየት ይችላል፡፡ ከ ምሳሌ ምሳሌ ምሳሌ፣ ከታች-በላይ ማተር፣ በየደረጃው የሚታየው የsemantic sub-ፕሮግራም ምሳሌዎችን ያስተምራል፡፡ በSpider ላይ SmBoP፣ የzero-shot semantic parsing benchmark እና ሰምቦP በክፍለ ዘመን 2.2x ፈጥኖ ማሳየት እና ~5x ፈጥኖ ማሳየት ጊዜ እና ምናልባት ምዕራፍ ክፍተት የሚጠቅመውን የsemantic Parser. ሰምቦፕ የራሳቸውን ራስ-SQL+ግራፕን ለመተካከል አዲስ የልግስና ግዛት እና 69.6 አካላይነት በ69.6 እርግጠኛ ተቃውሞ የሚያስፈልገውን ያግኛል።', 'az': "Son illərdə semantik ayırmaq üçün de-facto standart dekoding metodu, məqsəd proqramının abstrakt sintaksi a ğacını, üst-aşağı derinlik-ilk traversal vasitəsilə avtomatik olaraq kodlamaq idi. Bu işdə alternatif bir t ərzim təbliğ edirik: yuxarı-yuxarı a şağı-yuxarı Üstünlük Üstünlüyü (SmBoP) kodlamaqda inşa edir t üst-K Üstünlüyünün yüksək ağaclarının altındakı üstünlüyü t. parserimiz yuxarı-yuxarı Otomatik Üstünlüyü ilə müqayisədə çox faydalar alır. Etkinlik perspektivindən, a şağıdaki ayırma hər bir altın ağaclarını parallel olaraq kodlamağa imkan verir, linear yerinə logaritmik sürüm kompleksitəsinə yol verir. modelləşdirmək perspektivindən, a şağı-yuxarı ayırıcı hər adımda anlamlı semantik apa-proqramlar üçün göstəricilər öyrənir, semantik-vacibli parçalı ağaclar yerinə. Biz Örümcəyə SmBoP uygulayırıq, çətin sıfır-shot semantik analizi benchmark, və göstəririk ki, SmBoP'in kodlama vaxtında 2.2x hızlandırması və təhsil vaxtında ~5x hızlandırması ilə, autoregressiv kodlama istifadə edən semantik analizi ilə qarşılaşdırır. SmBoP Örümcə üzərində 71.1 dəyişiklik doğruluğu alır, yeni sanatın durumu təyin edir, 69.5 dəyişiklik eşitməsi, 69.6 dəyişiklik RAT-SQL+Grappa ilə qarşılaşır.", 'bs': 'Standardna metoda dekodiranja de-facto za semantičko analiziranje u posljednjih godina bila je da autoregresivno dekodira abstraktno sintaksno drvo ciljnog program a koristeći prvu traversalnu dubinu od vrha dole. U ovom poslu predlažemo alternativni pristup: polu-autoregresivni razmatrač dolje (SmBoP) koji konstruira na dekodiranju koraka t poddrveta visine top-K i t. Naš analizač uživa u nekoliko koristi u usporedbi s autoregresivnim analizacijom vrha dolje. Iz perspektive učinkovitosti, analizanje donjeg gore omogućava dekodirati sve poddrveće određene visine paralelno, što dovodi do logaritmske složenosti kretanja umjesto linearne. Iz modeliranog perspektiva, analitičar donjeg gore uči predstave za značajne semantičke podprograme na svakom koraku, a ne za semantički odvažne djelomične drveće. Primjenjujemo SmBoP na Spider, izazovnu semantičku analizu bez pucnjave, i pokazujemo da SmBoP vodi do brzine od 2,2x u vrijeme dekodiranja i brzine od ~5x u vrijeme treninga u usporedbi sa semantičkim analizatorom koji koristi autoregresivno dekodiranje. SmBoP dobija tačnost 71,1 denotacije na Pajderu, uspostavljajući novi stanje umjetnosti, i 69,5 tačno odgovarajući, usporedno sa to čnim odgovaranjem autoregresivnog RAT-SQL+Grape.', 'bn': 'সাম্প্রতিক বছরগুলোতে সেমেন্টিক পার্সিং এর ডি-ফ্যাক্টো স্থান্যান্ডার ডিকোডিং পদ্ধতি স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয়ভাবে অবরোধ করা হয়েছে য In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height  t. Our parser enjoys several benefits compared to top-down autoregressive parsing.  From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  একটি মডেলিং দৃষ্টিভঙ্গি থেকে, একটি নীচ-আপ প প্যারার্সার প্রতিটি পদক্ষেপে অর্থহীন সেমান্টিক সাব-প্রোগ্রামের প্রতিনিধিত্ব শিখ আমরা স্পাইডারের উপর স্ম্যামবোপ প্রয়োগ করি, একটি চ্যালেঞ্জ শুটের সেমেন্টিক পার্চিং বেনম্যার্ক, এবং দেখাচ্ছি যে স্ম্বোপ সময় ডিকোডিং সময়ে ২. ২ x গতি বেড়ে যায় এবং প্রশিক্ষণের সময়ে একটি ~ স্পিডারের উপর ৭১. ১ ডেনোটেশন সঠিকভাবে পেয়েছে, নতুন রাষ্ট্র-অফ-শিল্প এবং ৬৯. ৫ ঠিক ম্যাচ নির্মাণ করেছে, যা স্বয়ংক্রিয়ভাবে র\u200d্যাট-এসকিএল+গ্রাপ্পারের ৬', 'cs': 'De-facto standardní dekódovací metoda pro sémantickou parsování v posledních letech byla autoregresivní dekódování abstraktního syntaxe stromu cílového programu pomocí traversalu shora-dolů hloubka-první. V této práci navrhujeme alternativní přístup: Semi-autoregresivní Bottom-up Parser (SmBoP), který konstruuje v dekódování kroku t podstromy top-K výšky t. Náš parser má několik výhod ve srovnání s autoregresivním parsováním shora dolů. Z hlediska efektivity, bottom-up parsing umožňuje dekódovat všechny podstromy určité výšky paralelně, což vede k logaritmické runtime složitosti spíše než lineární. Z hlediska modelování se parser zdola nahoru učí reprezentace smysluplných sémantických podprogramů v každém kroku, spíše než pro sémanticky vakuózní parciální stromy. Používáme SmBoP na Spider, náročný nulový sémantický parsing benchmark, a ukazujeme, že SmBoP vede k 2,2x zrychlení dekódování a ~5x zrychlení tréninkové doby ve srovnání se sémantickým parserem, který používá autoregresivní dekódování. SmBoP získává 71.1 denotační přesnost na Spideru, což vytváří nový state-of-the-art a 69.5 přesnou shodu, srovnatelnou s 69.6 přesnou shodou autoregresivního RAT-SQL+Grappa.', 'et': 'De facto standardne dekodeerimismeetod semantilise parsimise jaoks viimastel aastatel on olnud autoregressiivselt dekodeerida sihtprogrammi abstraktne süntaksipuu, kasutades ülevalt allapoole sügavust esimesena. Käesolevas töös pakume välja alternatiivse lähenemisviisi: Poolautoregressiivne alt-üles parser (SmBoP), mis konstrueerib dekodeerimise sammul t ülalt-K alampuud kõrgusega t. Meie parser naudib mitmeid eeliseid võrreldes ülalt-alla autoregressiivse parsimisega. Tõhususe seisukohast võimaldab alt-üles parsimine dekodeerida paralleelselt kõiki teatud kõrgusega alampuid, mis põhjustab pigem logaritmilist tööaja keerukust kui lineaarset. Modelleerimise perspektiivist õpib alt-üles parser igal etapil tähenduslike semantiliste alamprogrammide esitusi, mitte semantiliselt tühjade osaliste puude puhul. Me rakendame SmBoP-i Spiderile, väljakutsuvale null-shot semantilisele parsimise võrdlusalusele, ja näitame, et SmBoP viib 2,2x kiirenemiseni dekodeerimisajal ja ~5x kiirenemiseni treeningajal, võrreldes semantilise parseriga, mis kasutab autoregressiivset dekodeerimist. SmBoP saavutab Spideril 71,1 tähistustäpsuse, luues uue tehnika taseme ja 69,5 täpse vaste, mis on võrreldav autoregressiivse RAT-SQL+Grappa 69,6 täpse vastega.', 'fi': 'Semanttisen parsauksen de facto-standardi on viime vuosina ollut kohdeohjelman abstraktin syntaksipuun autoregressiivinen dekoodaminen ylhäältä alaspäin, syvyys ensin. Tässä työssä ehdotamme vaihtoehtoista lähestymistapaa: Semi-autoregressiivinen Bottom-up Parser (SmBoP), joka rakentaa dekoodausvaiheessa t korkeuden t ylä-K alapuita. Parserillamme on useita etuja ylhäältä alaspäin autoregressiiviseen parsaukseen verrattuna. Tehokkuuden näkökulmasta alhaalta ylös -parsaus mahdollistaa kaikkien tietyn korkeuden alapuiden purkamisen rinnakkain, mikä johtaa logaritmiseen ajoajan monimutkaisuuteen lineaarisen sijaan. Mallintamisen näkökulmasta alhaalta ylös -jäsentäjä oppii jokaisen vaiheen merkityksellisten semanttisten alaohjelmien representaatioita semanttisesti tyhjien osapuiden sijaan. Sovellamme SmBoP:tä Spideriin, haastavaan nollahaun semanttiseen parsaukseen, ja osoitamme, että SmBoP johtaa 2,2x nopeuteen dekoodausajassa ja noin 5x nopeuteen harjoitteluajassa verrattuna semanttiseen parsaukseen, joka käyttää autoregressiivistä dekoodausta. SmBoP saa Spiderille 71.1-tarkkuuden, luoden uuden huipputekniikan ja 69.5-tarkkuuden, joka on verrattavissa autoregressiivisen RAT-SQL+Grappa-mallin 69.6-tarkkuuteen.', 'ca': "The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal.  In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height  t. Our parser enjoys several benefits compared to top-down autoregressive parsing.  From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees.  Aplicam SmBoP a Spider, un repte de referència semàntica d'analització senàntica de zero, i demostram que SmBoP porta a una velocitat de 2,2x en el temps de descodificació i una velocitat de ~5x en el temps d'entrenament, comparat amb un analitzador semàntic que utilitza una descodificació autoregressiva. SmBoP obté la precisió de la denotació de 71,1 a Spider, estabelecent un nou avançat, i 69,5 coincidencies exactes, comparables a la de 69,6 coincidencies exactes de la RAT-SQL+Grappa autoregressiva.", 'hy': "Վերջին տարիների ընթացքում սեմանտիկ վերլուծության դե-փակտային ստանդարտ կոդավորման մեթոդը նպատակային ծրագրի վերացական սինտաքսի ծառը ինքնաբացահայտելն է օգտագործելով վերևի ներքև խորության առաջին խաչընթացքը: Այս աշխատանքի ընթացքում մենք առաջարկում ենք այլընտրանքային մոտեցում' կիսա-ինքնաբացատրական ներքև վերևի վերևի վերևի վերևի վերևի վերևի վերևի վերևի կենտրոնում (SMBoP), որը կառուցվում է վերևի կենտրոնում գտնվող K-ի ծառերի վերևի կենտրոնում (t). Մեր վերևի կենտրոնում բազ From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees.  We apply SmBoP on Spider, a challenging zero-shot semantic parsing benchmark, and show that SmBoP leads to a 2.2x speed-up in decoding time and a ~5x speed-up in training time, compared to a semantic parser that uses autoregressive decoding.  SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.", 'sq': 'The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal.  In this work, we propose an alternative approach: a Semi-autoregressive Bottom-up Parser (SmBoP) that constructs at decoding step t the top-K sub-trees of height  t. Our parser enjoys several benefits compared to top-down autoregressive parsing.  From an efficiency perspective, bottom-up parsing allows to decode all sub-trees of a certain height in parallel, leading to logarithmic runtime complexity rather than linear.  From a modeling perspective, a bottom-up parser learns representations for meaningful semantic sub-programs at each step, rather than for semantically-vacuous partial trees.  Ne aplikojmë SmBoP në Merimangë, një referencë sfiduese për analizimin semantik zero-shot, dhe tregojmë se SmBoP shpie në një shpejtësi 2.2x në kohën e dekodimit dhe një shpejtësi ~5x në kohën e stërvitjes, krahasuar me një analizues semantik që përdor dekodimin autoregressiv. SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'ha': 'Tsarin kodi na de-facto na daidaita wa parse na semantic a cikin kwanan shekara na farko, ya kasance ana yin diode farat ɗaya game da itãcen taƙatan syntaxewa na shirin ayuka na goan da ya yi amfani da wata shiversal ta kwance-kwance ta sama-ƙasa. Daga wannan aikin, Muke goyyade wata hanyor musamman: wata matsayi mai amfani na biyu-domin-duk-faɗi (SmBoP) wanda ke samar yin rufe-K-ƙan an an-daraja na maɗaukaki t. Parser ɗinMu yana da amfani masu yawa sami da parse na sama-ƙasa farat ɗaya. Fara wani fili mai amfani da parse ta ƙasan-ƙasa yana yarda ya yi kodi kode duk itãce na ƙan an an da wani girmar da aka yi daidaita, kuma yana ƙara wa adadin lokaci na tafiyar da shi mai lokaci kuma bã ya kasa linje. From an motsi mai motsi, an sanar Paramer ɗin-sama yana karatun masu motsi wa sub-program masu muhimmi na semantic a kowace kwance, kuma amma dõmin tsarin itãce na semantically-evacuous. Tuna amfani da SmBoP kan SPPs, wani mai tsãwa ga parse na semantic wanda bai yi sifanci ba, kuma Muke nuna cewa SmBoP zai iya ƙara wa sauri 2.2x cikin lokacin yin kodi da kuma a `5x-farto cikin zaman shawarar, sami da parse na semantic wanda ke amfani da diregressive kodin. SmBoP yana samun taƙaita 71.1 kan Yũsufu, mai daidaita wani halin-mai-sanar, da mai daidaita 69.5, daidai da daidaita na 69.6 mai daidaita na farat-raT-SQL+Grappa.', 'sk': 'Dejanska standardna metoda dekodiranja semantičnega razčlenjanja je bila v zadnjih letih avtoregresivno dekodiranje abstraktnega sintakse ciljnega programa z uporabo globinskega prehoda od zgoraj navzdol. V tem delu predlagamo alternativni pristop: Semi-autoregressive Bottom-up Parser (SmBoP), ki konstruira na stopnji dekodiranja t vrh-K poddrevesa višine t. Naš razčlenjevalec uživa več prednosti v primerjavi z zgoraj-navzdol samoregresivnim razčlenjem. Z vidika učinkovitosti razčlenjevanje od spodaj navzgor omogoča vzporedno dekodiranje vseh poddreves določene višine, kar vodi do logaritmične kompleksnosti delovanja in ne linearne. Z vidika modeliranja razčlenjevalnik spodaj navzgor uči predstavitve za pomembne semantične podprograme v vsakem koraku, ne pa za semantično prazna delna drevesa. Uporabljamo SmBoP na Spiderju, zahtevnem merilu semantičnega razčlenjanja brez strela, in pokažemo, da SmBoP vodi do 2,2-kratne pospešitve v času dekodiranja in ~5-kratne pospešitve v času vadbe v primerjavi s semantičnim razčlenjevalnikom, ki uporablja samoregresivno dekodiranje. SmBoP pridobi 71,1 natančnost denotacije na Spiderju, kar vzpostavi novo najsodobnejše in 69,5 natančno ujemanje, primerljivo z 69,6 natančnim ujemanjem avtoregresivnega RAT-SQL+Grappa.', 'bo': 'The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal. In this work, we propose an alternative approach: a semi-autoregressive Bottom-up Parser (SmBoP)that constructs a t decoding step t the top-K sub-trees of height & & t. Our parser enjoys several benefits compared to top-down autoregressive parsing. The following examples are: ལས་སྒྲུབ་ཅན་གྱི་མཐོང་སྣང་ཚུལ་ལས་ མགོ་རིམ་སྒྲིག འདི་ལྟ་བུའི་མཐོང ང་ཚོས་Spider ཐོག་ཏུ་SmBoP་ལས་སྤྱོད་དགོས་པ་མིན་འདུག SmBoP obtains 71.1 denotation accuracy on Spider, establishing a new state-of-the-art, and 69.5 exact match, comparable to the 69.6 exact match of the autoregressive RAT-SQL+Grappa.', 'jv': 'The de-Actualo Standard decoding method for semanti In this job, we proposal an Alternate method: a semii-autoRegresve bottom-up parent politenessoffpolite"), and when there is a change ("assertivepoliteness Mulai perspekteman modeli, akeh-akeh mlakuner tentang nggambar semantar semantar pod-program sing sabên kuwi basa, liyane semantar-bakalan og barang kelas. Awak dhéwé aplikasi SmBoP uwong spider, nggawe 0-nggawe semanti nggawe bench, SmBoP dinopakan uwong a 2.2x jenenge dipolete nggawe ngucap tan nggawe ©5 x jenenge tanggal waji wis antara, nggawe semanti nggawe ngucap sistem sistem sistem sistem pakan. SmBoP luwih kelompok 1.1 nggawe spider, nggawe Status-perthi gawe lan saiki perthi gawe lan saiki ono barêng, karo segala saiki ono barêng sampeyan nêmêr. Perintahaan langgambar uwong sing perthi marito karo section', 'he': 'The de-facto standard decoding method for semantic parsing in recent years has been to autoregressively decode the abstract syntax tree of the target program using a top-down depth-first traversal.  בעבודה הזו, אנו מציעים גישה אלטרנטיבית: מחקר תחת למעלה חצי-אוטורגרסיבי (SmBoP) שמבנה בשלב הפענוח t את העצים העליוניים של K בגובה t. המבחן שלנו נהנה ממספר יתרונות בהשוואה לחקר אוטורגרסיבי מעל למטה. מפרספקטיבית יעילות, בדיקת התחתית למעלה מאפשרת לפענח את כל העצים התחתוניים בגובה מסוים במקביל, מה שמוביל למרכיבות לוגריטמית של זמן הריצה במקום לינרית. מבחינה של דוגמניות, מעבד מתחת למעלה לומד מייצגים עבור תוכניות סמנטיות משמעותיות בכל צעד, במקום עבור עצים חלקיים חסריים סמנטיות. אנחנו משתמשים SmBoP על עכביש, נקודת מבחן של בדיקת סמנטית אפס-ירי מאתגרת, ולהראות ש SmBoP מוביל למהירות 2.2x בזמן הפענוח והמהירות ~5x בזמן האימון, בהשוואה לפרסם סמנטי שמשתמש בפענוח אוטומגרסיבי. SmBoP מקבל מדויקת הדינוטציה 71.1 על עכביש, להקים מצב חדש של האמנות, ו-69.5 בדיוק התאמה, שווה לתאמה מדויקת 69.6 של RAT-SQL+Grappa האוטו-אגרסיבי.'}
{'en': 'Mode recovery in neural autoregressive sequence modeling', 'pt': 'Recuperação de modo na modelagem de sequência autoregressiva neural', 'ar': 'استعادة الوضع في نمذجة التسلسل العصبي الذاتي', 'es': 'Recuperación de modo en el modelado de secuencias autorregresivas neuronales', 'fr': 'Récupération de mode dans la modélisation de séquence autorégressive neuronale', 'ja': 'ニューラル自己回帰シーケンスモデリングにおけるモード回復', 'zh': '神经自归序建模中式复之', 'hi': 'तंत्रिका autoregressive अनुक्रम मॉडलिंग में मोड वसूली', 'ru': 'Восстановление режима при моделировании нейронной авторегрессивной последовательности', 'ga': 'Aisghabháil modha i samhaltú seicheamh uath-aischéimnitheach néar', 'ka': 'ნეიროლური ავტორეგრესიგური მოდელის რეჟიმის გამოყენება', 'hu': 'Mód helyreállítása neurális autoregresszív szekvencia modellezésében', 'el': 'Ανάκτηση τρόπου στη μοντελοποίηση νευρωνικών αυτοανακριτικών ακολουθιών', 'it': 'Recupero di modalità nella modellazione di sequenza autoregressiva neurale', 'kk': 'Невралдық авторегрессивні реттеу моделінде режім қалпына келтіру', 'mk': 'Резервирање на режимот во моделирање на нервната авторегресивна секвенца', 'lt': 'Naujovių autoregresinės sekos modeliavimo režimo atkūrimas', 'ms': 'Pemulihan mod dalam pemodelan urutan autoregresif saraf', 'ml': 'ന്യൂറല്\u200d സ്വയം രീതിയിലുള്ള സെക്രട്ടിവിന്റെ മോഡലിങില്\u200d പുനരുത്ഥാപിക്കുക', 'mt': 'L-irkupru tal-modalità fl-immudellar tas-sekwenza awtoregressiva newrali', 'mn': 'Неврал авторегрессивны дарааллын загварын загвар сэргээх', 'no': 'Modus gjenoppretting i nøyrale autoregressiv sekvensmodellering', 'pl': 'Odzyskiwanie trybu w neuronowym modelowaniu sekwencji autoregresywnej', 'sr': 'Opravak režima u modelima neuralne autoregresivne sekvence', 'ro': 'Recuperarea modului în modelarea secvențelor neuronale autoregresive', 'si': 'ස්වයංක්\u200dරීය ස්වයංක්\u200dරීය ප්\u200dරමාණයක් නිර්මාණය කරනවා', 'so': 'dib u soo celinta midowga naxaasta', 'sv': 'Mode recovery in neural autoregressive sekvens modellering', 'ta': 'Mode recovery in neural autoregressive sequence modeling', 'ur': 'نئورل اٹوگریسٹ سٹم موڈلینگ میں موڈ استعمال کرنا', 'uz': 'Name', 'vi': 'Chế độ phục hồi trong chế độ tự vệ thần kinh', 'bg': 'Възстановяване на режима при моделиране на невронната авторегресивна последователност', 'da': 'Tilstandsgenerering i neural autoregressiv sekvensmodellering', 'hr': 'Opravak režima u modelima neuralne autoregresivne sekvence', 'nl': 'Mode herstel in neuronale autoregressieve sequentiemodeling', 'id': 'Mode recovery in neural autoregressive sequence modeling', 'de': 'Mode Recovery in neuronaler autoregressiver Sequenzmodellierung', 'ko': '신경 회귀 시퀀스 모델링에서의 패턴 회복', 'fa': 'دریافت حالت در مدل\u200cسازی خودگریزگریزگریز عصبی', 'sw': 'Kupata upya katika mifano ya kandamizi binafsi', 'af': 'Modus herstelling in neural outo- regressief sekvens modeling', 'tr': 'Näyral otoregressiv hat modellerinde faýllary gaýtalandyrma modi', 'sq': 'Rikthimi i modalitetit në modelimin e sekuencës neurologjike', 'am': 'Mode recovery in neural autoregressive sequence modeling', 'hy': 'Նյարդային ավտոգրեսիվ հաջորդականության մոդելավորման մեջ', 'az': 'N칬ral otoregressiv se칞m톛 modell톛rind톛 mod geri al캼nmas캼', 'bn': 'নিউরেল স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয় সেকেন্স মডেলিং এ মোড পুনরুদ্ধার করা হবে', 'bs': 'Opravak režima u modelima neuralne autoregresivne sekvence', 'ca': 'La recuperació del món en la modelació de seqüències neurals autoregressives', 'cs': 'Obnova režimu v neuronovém autoregresivním modelování sekvence', 'et': 'Režiimi taastamine neuraalse autoregressiivse jada modelleerimisel', 'fi': 'Tilan palautuminen neuron autoregressiivisessä sekvenssimallinnassa', 'jv': 'Ngubah restaran anyar nambah autoRegresno seneng dadi', 'sk': 'Obnovitev načina pri modeliranju nevralnih avtoregresivnih zaporedih', 'ha': "Canza tsari cikin motsi na'urar farat ɗaya", 'he': 'Mode recovery in neural autoregressive sequence modeling', 'bo': 'ནུས་མཐུན་གྱིས་རང་འགུལ་གྱིས་རྗེས་ཀྱི་དབྱེ་རིམ་དབྱེ་བ་ནང་དུ་བསྐྱར་གསོ་རྣམ་པ'}
{'en': 'Despite its wide use, recent studies have revealed unexpected and undesirable properties of neural autoregressive sequence models trained with maximum likelihood, such as an unreasonably high affinity to short sequences after training and to infinitely long sequences at decoding time. We propose to study these phenomena by investigating how the modes, or local maxima, of a distribution are maintained throughout the full learning chain of the ground-truth, empirical, learned and decoding-induced distributions, via the newly proposed mode recovery cost. We design a tractable testbed where we build three types of ground-truth distributions : (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution. Our study reveals both expected and unexpected findings. First, starting with data collection, mode recovery cost strongly relies on the ground-truth distribution and is most costly with the semi-structured distribution. Second, after learning, mode recovery cost from the ground-truth distribution may increase or decrease compared to data collection, with the largest cost degradation occurring with the semi-structured ground-truth distribution. Finally, the ability of the decoding-induced distribution to recover modes from the learned distribution is highly impacted by the choices made earlier in the learning chain. We conclude that future research must consider the entire learning chain in order to fully understand the potentials and perils and to further improve neural autoregressive sequence models.learning chain of the ground-truth, empirical, learned and decoding-induced distributions, via the newly proposed mode recovery cost. We design a tractable testbed where we build three types of ground-truth distributions: (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution. Our study reveals both expected and unexpected findings. First, starting with data collection, mode recovery cost strongly relies on the ground-truth distribution and is most costly with the semi-structured distribution. Second, after learning, mode recovery cost from the ground-truth distribution may increase or decrease compared to data collection, with the largest cost degradation occurring with the semi-structured ground-truth distribution. Finally, the ability of the decoding-induced distribution to recover modes from the learned distribution is highly impacted by the choices made earlier in the learning chain. We conclude that future research must consider the entire learning chain in order to fully understand the potentials and perils and to further improve neural autoregressive sequence models.', 'ar': 'على الرغم من استخدامه على نطاق واسع ، فقد كشفت الدراسات الحديثة عن خصائص غير متوقعة وغير مرغوب فيها لنماذج التسلسل الانحدار الذاتي العصبي المدربة بأقصى احتمالية ، مثل التقارب العالي بشكل غير معقول للتسلسلات القصيرة بعد التدريب والتسلسلات الطويلة بلا حدود في وقت فك التشفير. نقترح دراسة هذه الظواهر من خلال التحقيق في كيفية الحفاظ على الأنماط ، أو الحدود القصوى المحلية ، للتوزيع في جميع أنحاء سلسلة التعلم الكاملة للتوزيعات الواقعية ، والتجريبية ، والتعليمية ، والناجمة عن فك التشفير ، عبر تكلفة استعادة الوضع المقترحة حديثًا. نصمم قاعدة اختبار قابلة للتتبع حيث نبني ثلاثة أنواع من توزيعات الحقيقة الأرضية: (1) توزيع منظم قائم على LSTM ، (2) توزيع غير منظم حيث لا يعتمد احتمال التسلسل على محتواه ، و (3) منتج من هذين اللذين نسميهما التوزيع شبه المنظم. تكشف دراستنا عن النتائج المتوقعة وغير المتوقعة. أولاً ، بدءًا من جمع البيانات ، تعتمد تكلفة استرداد الوضع بشدة على توزيع الحقيقة الأساسية وتكون أكثر تكلفة مع التوزيع شبه المنظم. ثانيًا ، بعد التعلم ، قد تزيد تكلفة استرداد الوضع من توزيع الحقيقة الأرضية أو تنقص مقارنةً بجمع البيانات ، مع حدوث أكبر انخفاض في التكلفة مع التوزيع شبه المنظم للحقيقة الأرضية. أخيرًا ، تتأثر قدرة التوزيع الناتج عن فك التشفير على استعادة الأوضاع من التوزيع الذي تم تعلمه بشدة بالخيارات التي تم إجراؤها مسبقًا في سلسلة التعلم. نستنتج\nيجب أن يأخذ البحث المستقبلي في الاعتبار سلسلة التعلم بأكملها من أجل فهم الإمكانات والمخاطر بشكل كامل ولزيادة تحسين نماذج تسلسل الانحدار الذاتي العصبي.', 'es': 'A pesar de su amplio uso, estudios recientes han revelado propiedades inesperadas e indeseables de los modelos de secuencias autorregresivas neurales entrenados con máxima probabilidad, como una afinidad excesivamente alta por secuencias cortas después del entrenamiento y por secuencias infinitamente largas en el momento de la decodificación. Proponemos estudiar estos fenómenos investigando cómo se mantienen los modos, o máximos locales, de una distribución a lo largo de toda la cadena de aprendizaje de las distribuciones de verdad fundamental, empíricas, aprendidas e inducidas por la decodificación, a través del costo de recuperación del modo recientemente propuesto. Diseñamos un banco de pruebas manejable donde construimos tres tipos de distribuciones reales: (1) una distribución estructurada basada en LSTM, (2) una distribución no estructurada donde la probabilidad de una secuencia no depende de su contenido, y (3) un producto de estas dos que llamamos distribución semiestructurada. Nuestro estudio revela hallazgos esperados e inesperados. En primer lugar, comenzando con la recopilación de datos, el costo de recuperación del modo depende en gran medida de la distribución fidedigna y es más costoso con la distribución semiestructurada. En segundo lugar, después del aprendizaje, el costo de recuperación del modo de la distribución de verdad sobre el terreno puede aumentar o disminuir en comparación con la recopilación de datos, y la mayor degradación de costos ocurre con la distribución de verdad del terreno semiestructurada. Por último, la capacidad de la distribución inducida por la decodificación para recuperar modos de la distribución aprendida se ve muy afectada por las elecciones realizadas anteriormente en la cadena de aprendizaje. Concluimos\nque la investigación futura debe considerar toda la cadena de aprendizaje para comprender completamente los potenciales y los peligros y mejorar aún más los modelos de secuencia autorregresiva neuronal.', 'pt': 'Apesar de seu amplo uso, estudos recentes revelaram propriedades inesperadas e indesejáveis de modelos de sequências autoregressivas neurais treinados com máxima probabilidade, como uma afinidade excessivamente alta para sequências curtas após o treinamento e para sequências infinitamente longas no momento da decodificação. Propomos estudar esses fenômenos investigando como os modos, ou máximos locais, de uma distribuição são mantidos ao longo de toda a cadeia de aprendizado das distribuições verdadeiras, empíricas, aprendidas e induzidas por decodificação, por meio do custo de recuperação de modo recentemente proposto. Projetamos um testbed tratável onde construímos três tipos de distribuições de verdade: (1) uma distribuição estruturada baseada em LSTM, (2) uma distribuição não estruturada onde a probabilidade de uma sequência não depende de seu conteúdo e (3) um produto de esses dois que chamamos de distribuição semi-estruturada. Nosso estudo revela resultados esperados e inesperados. Primeiro, começando com a coleta de dados, o custo de recuperação de modo depende fortemente da distribuição de verdade e é mais caro com a distribuição semiestruturada. Em segundo lugar, após o aprendizado, o custo de recuperação do modo da distribuição de verdade pode aumentar ou diminuir em comparação com a coleta de dados, com a maior degradação de custo ocorrendo com a distribuição de verdade semiestruturada. Finalmente, a capacidade da distribuição induzida por decodificação de recuperar modos da distribuição aprendida é altamente impactada pelas escolhas feitas anteriormente na cadeia de aprendizado. Nós concluimos\nque pesquisas futuras devem considerar toda a cadeia de aprendizado para entender completamente os potenciais e perigos e melhorar ainda mais os modelos de sequência autoregressiva neural.', 'ja': '広く使用されているにもかかわらず、最近の研究では、最大の可能性で訓練されたニューラル自己回帰配列モデルの予期せぬ望ましくない特性、例えば、訓練後の短い配列及びデコード時間における無限に長い配列に対する不当に高い親和性が明らかになっている。 これらの現象を、新たに提案されたモード回復コストを介して、地上真理分布、実証分布、学習分布、復号化誘発分布の全学習チェーンを通じて、分布のモード、または局所最大値がどのように維持されるかを調査することによって研究することを提案する。 私たちは、（ 1 ） LSTMベースの構造化分布、（ 2 ）シーケンスの確率がその内容に依存しない非構造化分布、および（ 3 ）私たちが半構造化分布と呼ぶこれら2つの積の3種類の地上真実分布を構築するトラクタブルテストベッドを設計します。 私たちの研究は、予想される所見と予期しない所見の両方を明らかにします。 第一に、データ収集から始まり、モード回復コストは地上真実分布に強く依存し、半構造化分布では最もコストがかかります。 第２に、学習後、地上真理分布からのモード回復コストは、データ収集と比較して増加または減少し得、半構造化地上真理分布では最大のコスト低下が発生する。 最後に、復号化誘導分布が学習分布からモードを回復する能力は、学習チェーンの先ほどの選択によって大きく影響を受けると結論づける。\n将来の研究では、潜在的な危険性を完全に理解し、ニューラル自己回帰シーケンスモデルをさらに改善するために、学習チェーン全体を考慮しなければならない。', 'fr': "Malgré sa large utilisation, des études récentes ont révélé des propriétés inattendues et indésirables de modèles de séquences autorégressives neuronales entraînés avec le maximum de vraisemblance, comme une affinité déraisonnablement élevée pour les séquences courtes après entraînement et pour les séquences infiniment longues au moment du décodage. Nous proposons d'étudier ces phénomènes en étudiant comment les modes, ou maxima locaux, d'une distribution sont maintenus tout au long de la chaîne d'apprentissage de la vérité de terrain, des distributions empiriques, apprises et induites par le décodage, via le coût de récupération de mode nouvellement proposé. Nous concevons un banc d'essai souple dans lequel nous construisons trois types de distributions de vérité de terrain\xa0: (1) une distribution structurée basée sur LSTM, (2) une distribution non structurée où la probabilité d'une séquence ne dépend pas de son contenu, et (3) un produit de ces deux que nous appelons une distribution semi-structurée. Notre étude révèle des résultats à la fois attendus et inattendus. Tout d'abord, en commençant par la collecte de données, le coût de récupération de mode dépend fortement de la distribution de la vérité de terrain et est le plus coûteux avec la distribution semi-structurée. Deuxièmement, après apprentissage, le coût de récupération de mode à partir de la distribution de vérité de terrain peut augmenter ou diminuer par rapport à la collecte de données, la dégradation des coûts la plus importante se produisant avec la distribution de vérité de terrain semi-structurée. Enfin, la capacité de la distribution induite par le décodage à récupérer des modes à partir de la distribution apprise est fortement influencée par les choix faits plus tôt dans la chaîne d'apprentissage. Nous concluons\nque les recherches futures doivent prendre en compte l'ensemble de la chaîne d'apprentissage afin de bien comprendre les potentiels et les dangers et d'améliorer encore les modèles de séquences autorégressives neuronales.", 'zh': '虽博用,近者究见以至神经自归其不意,如短序解码无限长序之高亲和力。 臣等建议以究分布之模式、局部最大值如何以新发之模式复成本,在全真、经验、学解码诱布之全学链中持布之模式、局部最大值以究之。 设一易之试,为三真之布:(1)基于LSTM之结构化,(2)序之概率不依非结构化,及(3)二乘之积,谓之半结构化。 我们的研究揭示了预期和不意的发现。 首,自数收始,模式复本强烈依地真,而半结构化本最高。 其次经学,比数收比,地面实布之式复本或增或减,其半结构化真布成本降幅度最大。 最后,解码诱布从学布中复模式之力链中早为选择所染。 我们总结\n未来之论,必思全学,以尽知潜危,更进神经自归序。', 'hi': 'इसके व्यापक उपयोग के बावजूद, हाल के अध्ययनों ने अधिकतम संभावना के साथ प्रशिक्षित तंत्रिका ऑटोरिग्रेसिव अनुक्रम मॉडल के अप्रत्याशित और अवांछनीय गुणों का खुलासा किया है, जैसे कि प्रशिक्षण के बाद छोटे अनुक्रमों के लिए एक अनुचित रूप से उच्च आत्मीयता और डिकोडिंग समय में असीम रूप से लंबे अनुक्रमों के लिए। हम इन घटनाओं का अध्ययन करने का प्रस्ताव करते हैं कि कैसे एक वितरण के मोड, या स्थानीय मैक्सिमा, नए प्रस्तावित मोड रिकवरी लागत के माध्यम से जमीन-सत्य, अनुभवजन्य, सीखा और डिकोडिंग-प्रेरित वितरण की पूर्ण सीखने की श्रृंखला में बनाए रखा जाता है। हम एक सभ्य टेस्टबेड डिज़ाइन करते हैं जहां हम तीन प्रकार के ग्राउंड-ट्रुथ वितरण का निर्माण करते हैं: (1) एक एलएसटीएम आधारित संरचित वितरण, (2) एक असंरचित वितरण जहां एक अनुक्रम की संभावना इसकी सामग्री पर निर्भर नहीं करती है, और (3) इन दोनों का एक उत्पाद जिसे हम अर्ध-संरचित वितरण कहते हैं। हमारे अध्ययन से अपेक्षित और अप्रत्याशित दोनों निष्कर्षों का पता चलता है। सबसे पहले, डेटा संग्रह के साथ शुरू करते हुए, मोड वसूली लागत दृढ़ता से जमीन-सत्य वितरण पर निर्भर करती है और अर्ध-संरचित वितरण के साथ सबसे महंगी है। दूसरा, सीखने के बाद, ग्राउंड-ट्रुथ वितरण से मोड रिकवरी लागत डेटा संग्रह की तुलना में बढ़ सकती है या घट सकती है, जिसमें अर्ध-संरचित ग्राउंड-ट्रुथ वितरण के साथ होने वाली सबसे बड़ी लागत गिरावट हो सकती है। अंत में, सीखे गए वितरण से मोड को पुनर्प्राप्त करने के लिए डिकोडिंग-प्रेरित वितरण की क्षमता सीखने की श्रृंखला में पहले किए गए विकल्पों से अत्यधिक प्रभावित होती है। हम निष्कर्ष निकालते हैं\nकि भविष्य के अनुसंधान को क्षमताओं और खतरों को पूरी तरह से समझने और तंत्रिका autoregressive अनुक्रम मॉडल में और सुधार करने के लिए पूरी सीखने की श्रृंखला पर विचार करना चाहिए।', 'ru': 'Несмотря на его широкое использование, недавние исследования выявили неожиданные и нежелательные свойства нейронных авторегрессивных моделей последовательностей, обученных с максимальной вероятностью, такие как необоснованно высокая аффинность к коротким последовательностям после обучения и к бесконечно длинным последовательностям во время декодирования. Мы предлагаем изучить эти явления, исследуя, как поддерживаются режимы, или локальные максимумы, распределения по всей цепочке обучения распределений «земля-правда», эмпирических, изученных и декодированных, посредством вновь предложенной стоимости восстановления режима. Мы проектируем тяговый испытательный стенд, где мы строим три типа распределений «земля-правда»: (1) структурированное распределение на основе LSTM, (2) неструктурированное распределение, где вероятность последовательности не зависит от ее содержания, и (3) произведение этих двух типов, которое мы называем полуструктурированным распределением. Наше исследование выявляет как ожидаемые, так и неожиданные результаты. Во-первых, начиная со сбора данных, затраты на восстановление режима в значительной степени зависят от распределения "земля-правда" и наиболее дорого обходятся полуструктурированному распределению. Во-вторых, после изучения затраты на восстановление режима из распределения "земля-правда" могут увеличиваться или уменьшаться по сравнению со сбором данных, причем наибольшая деградация затрат происходит при полуструктурированном распределении "земля-правда". Наконец, на способность декодированного распределения восстанавливать режимы из изученного распределения сильно влияют варианты, сделанные ранее в цепочке обучения.\nчто будущие исследования должны учитывать всю цепочку обучения, чтобы полностью понять потенциалы и риски и далее улучшать модели нейронной авторегрессивной последовательности.', 'ga': "In ainneoin a n-úsáid fhorleathan, léirigh staidéir le déanaí airíonna gan choinne agus neamh-inmhianaithe de mhúnlaí seicheamh uath-aischéimnithe néaracha atá oilte leis an dóchúlacht uasta, amhail cleamhnas ró-ard le seichimh ghearra tar éis oiliúna agus le seichimh gan teorainn fhada ag am díchódaithe. Tá sé beartaithe againn staidéar a dhéanamh ar na feiniméin seo trí imscrúdú a dhéanamh ar an gcaoi a gcoinnítear modhanna, nó uasta áitiúla, dáileacháin ar fud an tslabhra foghlama iomlán de na dáileacháin atá bunaithe ar an talamhfhírinne, eimpíreach, foghlamtha agus díchódaithe, tríd an gcostas aisghabhála modha nua-mholta. Dearaimid leaba tástála inrianaithe ina ndéanaimid trí chineál dáiltí fírinne ar an talamh: (1) dáileadh struchtúrtha bunaithe ar LSTM, (2) dáileadh neamhstruchtúrtha nuair nach mbraitheann dóchúlacht seicheamh ar a ábhar, agus (3) táirge de an dá rud a dtugaimid dáileadh leath-struchtúrtha orthu. Nochtann ár staidéar torthaí ionchais agus torthaí gan choinne. Ar an gcéad dul síos, ag tosú le bailiú sonraí, braitheann costas aisghabhála modha go mór ar dháileadh na fírinne ar an talamh agus is costasaí é leis an dáileadh leath-struchtúrtha. Ar an dara dul síos, tar éis foghlaim, d'fhéadfadh méadú nó laghdú a dhéanamh ar chostas aisghabhála modha ón dáileadh talamhfhírinne i gcomparáid le bailiú sonraí, agus an díghrádú costais is mó ag tarlú leis an dáileadh leath-struchtúrtha talamhfhírinne. Ar deireadh, bíonn tionchar mór ag na roghanna a rinneadh níos luaithe sa slabhra foghlama ar chumas an dáilte díchódaithe modhanna a ghnóthú ón dáileadh foghlamtha. i gcrích againn\ngo gcaithfidh taighde sa todhchaí an slabhra foghlama iomlán a mheas chun na féidearthachtaí agus na guaiseacha a thuiscint go hiomlán agus chun samhlacha seicheamh uath-aischéimnithe néaracha a fheabhsú tuilleadh.", 'ka': 'მისი დიდი გამოყენებას მაგრამ, ახალი სწავლებები აღმოჩნდა, რომ ნეიროლური ავტორეგრესიური მოდელების შესაბამისი მაქსიმალური შესაბამისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთვისთ ჩვენ უნდა ამ ფენომენების შესწავლობა, როგორ განახლება, ან ლოკალური მაქსიმა, განახლების სამყარო სწავლების წერტილის მუშაობაში, ემპერიკალური, სწავლილი და განახლებული განახლებების განახლების გამოყენება. ჩვენ შევქმნით ტრაქტურაციის ტესტი, სადაც ჩვენ შევქმნით სამი ტიპი ფონტურაციის განსაზღვრება: (1) LSTM-ის განსაზღვრებული სტრუქტურაცია, (2) არსტრუქტურაციული განსაზღვრება, სადაც წერტილის შესაძლებლობა არ დაახლოდება მისი შე ჩვენი სწავლება აღმოჩნდება ორივე მომეხოვრებული და უნდა მომეხოვრებული მონაცემები. პირველად, მონაცემების კოლექციაზე დაწყება, რეჟიმის გამოყენება ძალიან ძალიან დარწმუნება სამხოლოდ სინამდვილეში და უფრო ძალიან სამხოლოდ სტრუქტურ მეორე, მასწავლების შემდეგ, რეჟიმის განახლების კონფიგურაციის მონაცემების განახლებისგან შეიძლება მონაცემების კოლექციის შემდეგ გაზრდება ან გაზრდება, რომელიც უფრო დიგრადიაცია,  საბოლოოდ, სწავლილი განყოფილების შესაძლებლობა, რომელიც განაკეთებული განყოფილების შესაძლებლობა, ძალიან გააკეთებული განყოფილების შესაძლებლობა იქნება უფრო მხოლოდ სწავლის წერტი ჩვენ დავაკეთებთ\nრომ მომავალი სწავლობა უნდა აღმოჩნოთ ყველა სწავლობა, რომელიც უფრო უფრო უნდა იცოდეს პოტენტიალები და პერილები და უფრო უფრო უფრო უფრო უფრო უფ', 'el': 'Παρά την ευρεία χρήση του, πρόσφατες μελέτες έχουν αποκαλύψει απροσδόκητες και ανεπιθύμητες ιδιότητες των νευρωνικών αυτοανακριτικών μοντέλων ακολουθίας που εκπαιδεύονται με μέγιστη πιθανότητα, όπως μια παράλογα υψηλή συγγένεια με σύντομες ακολουθίες μετά την προπόνηση και με απείρως μεγάλες ακολουθίες στο χρόνο αποκωδικοποίησης. Προτείνουμε να μελετήσουμε αυτά τα φαινόμενα διερευνώντας πώς οι τρόποι, ή τα τοπικά μέγιστα, μιας κατανομής διατηρούνται σε όλη την πλήρη μαθησιακή αλυσίδα της επίγειας αλήθειας, εμπειρικής, μαθημένης και αποκωδικοποιητικής κατανομής, μέσω του πρόσφατα προτεινόμενου κόστους ανάκτησης τρόπου. Σχεδιάζουμε ένα δοκιμαστικό κρεβάτι όπου κατασκευάζουμε τρεις τύπους κατανεμήσεων επίγειας αλήθειας: (1) μια δομημένη κατανομή βασισμένη στο LSTM, (2) μια ανεκτίμητη κατανομή όπου η πιθανότητα μιας ακολουθίας δεν εξαρτάται από το περιεχόμενό της, και (3) ένα προϊόν αυτών των δύο που ονομάζουμε ημιδομημένη κατανομή. Η μελέτη μας αποκαλύπτει τόσο αναμενόμενα όσο και απρόσμενα ευρήματα. Πρώτον, ξεκινώντας με τη συλλογή δεδομένων, το κόστος αποκατάστασης τρόπου εξαρτάται έντονα από τη διανομή επίγειας αλήθειας και είναι πιο δαπανηρό με την ημιδομημένη διανομή. Δεύτερον, μετά τη μάθηση, το κόστος ανάκτησης τρόπου από τη διανομή επίγειας αλήθειας μπορεί να αυξηθεί ή να μειωθεί σε σύγκριση με τη συλλογή δεδομένων, με τη μεγαλύτερη υποβάθμιση κόστους που συμβαίνει με την ημιδομημένη κατανομή επίγειας αλήθειας. Τέλος, η ικανότητα της αποκωδικοποιητικής κατανομής να ανακτά τρόπους από τη μαθησιακή κατανομή επηρεάζεται σε μεγάλο βαθμό από τις επιλογές που έγιναν νωρίτερα στην μαθησιακή αλυσίδα. Συμπεραίνουμε\nότι η μελλοντική έρευνα πρέπει να εξετάσει ολόκληρη την μαθησιακή αλυσίδα προκειμένου να κατανοήσει πλήρως τις δυνατότητες και τους κινδύνους και να βελτιώσει περαιτέρω τα μοντέλα νευρωνικών αυτοανακριτικών ακολουθιών.', 'hu': 'Széles körű alkalmazása ellenére a közelmúltbeli tanulmányok feltárták a maximális valószínűséggel kiképzett neurális autoregresszív szekvencia modellek váratlan és nemkívánatos tulajdonságait, mint például ésszerűtlenül nagy affinitás a rövid szekvenciákhoz edzés után és a dekódolás időpontjában végtelenül hosszú szekvenciákhoz. Azt javasoljuk, hogy ezeket a jelenségeket tanulmányozzuk annak vizsgálatával, hogy egy eloszlás módjai, illetve helyi maximális értékei hogyan maradnak fenn az alap-igazság, empirikus, tanult és dekódolás által indukált eloszlások teljes tanulási láncán keresztül, az újonnan javasolt mód-helyreállítási költségeken keresztül. Tervezünk egy vonható tesztágyat, ahol három típusú alap-igazság eloszlást építünk: (1) LSTM alapú strukturált eloszlást, (2) strukturálatlan eloszlást, ahol egy sorozat valószínűsége nem függ a tartalmától, és (3) e kettő termékét, amit félstrukturált eloszlásnak nevezünk. Tanulmányunk várható és váratlan eredményeket is feltár. Először is, kezdve az adatgyűjtéssel, az üzemmód-helyreállítási költségek nagymértékben az alap-igazság elosztásán alapulnak, és a félstrukturált elosztás esetében a legköltségesebbek. Másodszor, a tanulás után az alap-igazság eloszlásából származó üzemmód-helyreállítási költségek növekedhetnek vagy csökkenhetnek az adatgyűjtéshez képest, a legnagyobb költségbomlás pedig a félstrukturált alap-igazság eloszlásával történik. Végezetül a dekódolás által indukált eloszlás képességét, hogy visszanyerje a módokat a tanult eloszlásból, nagymértékben befolyásolják a tanulási lánc korábbi döntései. Megállapítjuk, hogy\nhogy a jövőbeli kutatásoknak figyelembe kell venniük a teljes tanulási láncot annak érdekében, hogy teljes mértékben megértsük a potenciálokat és veszélyeket, és tovább fejlesszük az idegi autoregresszív szekvencia modelleket.', 'it': "Nonostante il suo ampio utilizzo, studi recenti hanno rivelato proprietà inaspettate e indesiderabili dei modelli di sequenza autoregressiva neurale addestrati con la massima probabilità, come un'affinità irragionevolmente elevata a sequenze corte dopo l'allenamento e a sequenze infinitamente lunghe al momento della decodifica. Proponiamo di studiare questi fenomeni indagando come i modi, o massimi locali, di una distribuzione sono mantenuti lungo l'intera catena di apprendimento delle distribuzioni basate sulla verità di base, empiriche, apprese e indotte dalla decodifica, attraverso il costo di recupero della modalità appena proposto. Progettiamo un banco di prova trattabile in cui costruiamo tre tipi di distribuzioni di base-verità: (1) una distribuzione strutturata basata su LSTM, (2) una distribuzione non strutturata in cui la probabilità di una sequenza non dipende dal suo contenuto, e (3) un prodotto di questi due che chiamiamo distribuzione semi-strutturata. Il nostro studio rivela sia risultati attesi che inaspettati. In primo luogo, a partire dalla raccolta dei dati, il costo di recupero delle modalità dipende fortemente dalla distribuzione della verità di base ed è più costoso con la distribuzione semi-strutturata. In secondo luogo, dopo l'apprendimento, i costi di recupero della modalità dalla distribuzione della verità del suolo possono aumentare o diminuire rispetto alla raccolta dei dati, con il più grande degrado dei costi che si verifica con la distribuzione semi-strutturata della verità del suolo. Infine, la capacità della distribuzione indotta dalla decodifica di recuperare modalità dalla distribuzione appresa è fortemente influenzata dalle scelte fatte in precedenza nella catena di apprendimento. Concludiamo\nche la ricerca futura deve considerare l'intera catena di apprendimento per comprendere appieno i potenziali e i pericoli e migliorare ulteriormente i modelli di sequenza autoregressiva neurale.", 'lt': 'Nepaisant to, kad jis plačiai naudojamas, neseniai atlikti tyrimai atskleidė netikėtas ir nepageidaujamas neurologinių autoregresyvinių sekų modelių savybes, apmokytų didžiausią tikimybę, pvz., nepagrįstai didelį afinitetą trumpoms sekoms po mokymo ir nepagrįstai ilgoms sekoms dekoduojant laiką. Siūlome išnagrinėti šiuos reiškinius, tirdami, kaip platinimo būdai arba vietos maksimalumai išlaikomi visoje žemės tikrovės, empirinių, išmoktų ir dekoduojamų platinimų mokymosi grandinėje, pasitelkiant naujai pasiūlytas režimo atkūrimo sąnaudas. Mes sukonstruojame traktuojamą bandomąjį pagrindą, kuriame statome tris tipus antžeminės tiesos platinimų: 1) struktūrizuotas platinimas pagal LSTM, 2) nesustruktūrizuotas platinimas, kuriame sekos tikimybė nepriklauso nuo jos turinio, ir 3) šių dviejų produktų produktas, kurį vadiname pusiau struktūrizuotu platinimu. Mūsų tyrimas atskleidžia ir tikėtinas, ir netikėtas išvadas. Pirma, pradedant duomenų rinkimu, režimo atkūrimo sąnaudos labai priklauso nuo antžeminės tiesos platinimo ir yra brangiausia už pusstruktūrinį platinimą. Antra, po mokymosi režimo atsigavimo išlaidos, patirtos naudojant antžeminę tiesą, palyginti su duomenų rinkimu, gali padidėti arba sumažėti, o didžiausias išlaidų sumažėjimas pasireiškia naudojant pusiau struktūrizuotą antžeminę tiesą. Finally, the ability of the decoding-induced distribution to recover modes from the learned distribution is highly impacted by the choices made earlier in the learning chain.  Baigiame\nkad būsimi moksliniai tyrimai turi apsvarstyti visą mokymosi grandinę, kad būtų galima visiškai suprasti potencialą ir pavojų ir toliau tobulinti neurologinių autoregresyvių sekos modelius.', 'ms': 'Walaupun penggunaannya luas, kajian baru-baru ini telah mengungkapkan ciri-ciri yang tidak dijangka dan tidak diinginkan bagi model urutan autoregresif saraf dilatih dengan kemungkinan maksimum, seperti afini yang tidak masuk akal tinggi kepada urutan pendek selepas latihan dan urutan yang tidak terbatas pada masa penyahkodan. Kami cadangkan untuk mempelajari fenomena ini dengan menyelidiki bagaimana mod, atau maksimum setempat, distribusi yang disimpan sepanjang rantai pembelajaran penuh kebenaran-tanah, empirik, belajar dan penyahkodan-didukasikan distribusi, melalui kos pemulihan mod yang baru diusulkan. Kami merancang tempat ujian yang boleh dicuba di mana kita membina tiga jenis distribusi kebenaran-tanah: (1) distribusi struktur berdasarkan LSTM, (2) distribusi tidak struktur di mana kemungkinan urutan tidak bergantung pada kandungannya, dan (3) produk dari kedua-dua ini yang kita panggil distribusi setengah struktur. Ujian kami mengungkapkan kedua-dua penemuan yang dijangka dan tidak dijangka. Pertama, bermula dengan koleksi data, biaya pemulihan mod bergantung dengan kuat pada distribusi kebenaran-tanah dan paling mahal dengan distribusi semi-struktur. Kedua, selepas belajar, biaya pemulihan mod dari distribusi kebenaran-tanah boleh meningkat atau menurun dibandingkan dengan koleksi data, dengan pengurangan biaya terbesar berlaku dengan distribusi kebenaran-tanah semistruktur. Finally, the ability of the decoding-induced distribution to recover modes from the learned distribution is highly impacted by the choices made earlier in the learning chain.  Kami mengakhiri\nkajian masa depan mesti mempertimbangkan seluruh rantai pembelajaran untuk memahami sepenuhnya potensi dan bahaya dan untuk meningkatkan lebih lanjut model urutan autoregresif saraf.', 'mk': 'И покрај нејзината широка употреба, неодамнешните студии открија неочекувани и нежелни сопствености на моделите на невропска авторегресивна секвенца обучени со максимална веројатност, како што е неразумно висока афинитет на кратките секвенци по обуката и на бесконечно долги секвенции на време на деко Предложуваме да ги проучуваме овие феномени со истрага како режимите, или локалните максимали, на дистрибуцијата се одржуваат низ целиот ланец на учење на теренската вистина, емпиричната, научена и декодирана дистрибуција, преку новиот предложен режим цена за обновување. Ние дизајнираме трактабилен тестовен кревет каде што градиме три видови на дистрибуции на земја-вистина: (1) структурирана дистрибуција базирана на ЛСТМ, (2) неструктурирана дистрибуција каде веројатноста на секвенца не зависи од нејзината содржина, и (3) производ од овие двајца кој ние го нарекуваме полуструктурира Нашата студија открива очекувани и неочекувани откритија. Прво, почнувајќи со собирање на податоци, цената на режимот за обнова силно зависи од дистрибуцијата на земјата-вистина и е најскапа со поластруктурираната дистрибуција. Второ, по учењето, трошоците за обнова на режимот од дистрибуцијата на земјата-вистина може да се зголемат или да се намалат во споредба со собирањето на податоци, со најголемата деградација на трошоците што се случува со поластруктурираната дистрибуција на земјата-вистината. Конечно, способноста на декодираната дистрибуција за обнова на режимите од научената дистрибуција е високо влијана на изборите направени претходно во ланецот на учење. We conclude\nдека идното истражување мора да го разгледа целиот ланец на учење за целосно да ги разбере потенцијалите и опасностите и понатаму да ги подобри моделите на нервната авторегресивна секвенца.', 'kk': 'Жаңа зерттеулерді қолдануға қарамастан, жаңа зерттеулері күтпеген және күтпеген невралдық авторегрессиялық реттеу моделдерінің қасиеттері, максимум мүмкіндікті болып тұрған, мысалы, оқытудан кейін қысқа реттеулерге көмектеспеген Біз бұл жағдайларды зерттеу, импирикалық, үйренген және декодтау үшін жаңа таңдалған режімді қалай үлестіріп, жергілікті максималық үлестіріміздің толық оқыту тізімінде қалай сақталғанын зерттеу керек. Біз үш түрлі жергілікті дистрибуттарын құру кестесін құрастырамыз: (1) LSTM негізінде құрылған дистрибуттары, (2) құрылмаған дистрибуттары, олардың мазмұнына тәуелді емес, және (3) бұл екеуінің жарты құрылған дистрибуттары деп аталатын продукттер Біздің зерттеулеріміз күтпеген және күтпеген іздеулерді көрсетеді. Біріншіден, деректер жинақтауынан басталып, режімінің қалпының бағасы жергілікті үлестіріміне тәуелді және жарты құрылған үлестіріміне ең бағатты. Екіншіден, оқытудан кейін, тәсілдік үлестірімінен көтеру бағасы деректер жинағына салыстырып, көтерілген жұмыс бағаттарының ең үлкен деградациясы жарым-құрылған жергілікті үлестірі Соңында, білім үлестірімінен қалпына келтірілген үлестірім үлестірімін декодтау мүмкіндігінің көмегімен бірге оқыту тізбегінде жасалған таңдаулардың көп нәрсе ө Біз соңында\nБолашақ зерттеулердің барлық оқыту тізбегін толық түсіну үшін және невралдық авторегрессиялық реттеулердің үлгілерін жақсарту үшін ойлау керек.', 'ml': 'അതിന്റെ വിശാലമായ ഉപയോഗിച്ചാലും അടുത്ത പഠനങ്ങള്\u200d പ്രതീക്ഷിക്കപ്പെടാത്ത പ്രതീക്ഷിതമായ വ്യവസ്ഥകള്\u200d വെളിപ്പെടുത്തിയിരിക്കുന്നു, അസാധ്യതയില്ലാത്ത നെയുറല്\u200d സെക്രട്ടിവ ഈ സംഭവങ്ങള്\u200d പഠിക്കാന്\u200d ഞങ്ങള്\u200d പ്രൊദ്ദേശിക്കുന്നു, പുതിയ പ്രൊദ്ദേശിച്ച രീതിയില്\u200d എങ്ങനെയാണെന്നോ, ലോക്കല്\u200d മാക്സിമ, ഭൂമിയിലെ മുഴുവന്\u200d പഠിക്കുന്ന ചങ്ങല്\u200d  നമ്മള്\u200d ഒരു ട്രാക്കേബിള്\u200d ടെസ്സ്ബെഡ് നിര്\u200dമ്മിക്കുന്നു. അവിടെ നാം മൂന്നു തരം ഭൂമിയിലെ സത്യ വിഭാഗങ്ങള്\u200d പണിയുന്നു: (1) ഒരു LSTM അടിസ്ഥാനമാക്കിയ വിതരണം, (2) ഒരു സെക്കന്\u200dസിന്\u200dറെ സാധ നമ്മുടെ പഠനം പ്രതീക്ഷിക്കുന്നതും പ്രതീക്ഷിക്കാത്ത കണ്ടുപിടികളും വെളിപ്പെടുത്തുന് ആദ്യം, വിവരങ്ങള്\u200d സംഘടിപ്പിക്കുന്നതില്\u200d തുടങ്ങുന്നത് മോഡ് വീണ്ടും വില വില വ്യവസ്ഥയില്\u200d ശക്തമായി ആശ്രയിക്കുന്നു. അതിന്റെ  രണ്ടാമതായി, പഠിക്കുന്നതിനു ശേഷം ഭൂമിയിലെ സത്യ വിതരണത്തില്\u200d നിന്നുള്ള മോഡ് വീണ്ടെടുക്കുന്നതിനുള്ള ചെലവ് വീണ്ടെടുക്കുന്നതിന് വേണ്ട അവസാനം, പഠിക്കുന്ന വിതരണ മോഡുകളില്\u200d നിന്നും വീണ്ടെടുക്കാനുള്ള ഡികോഡിങ്ങ് ഇന്\u200dഡര്\u200dഷന്\u200d വിതരണ മാറ്റങ്ങളുടെ കഴിവ് പഠിച്ച വി ഞങ്ങള്\u200d അവസാനിക്കുന്നു\nഭാവിയുടെ പരിശോധന മുഴുവന്\u200d പഠിക്കുന്ന ചങ്ങലയെക്കുറിച്ച് വിചാരിക്കേണ്ടതുണ്ട്. പൂര്\u200dണ്ണമായും അപകടത്തെയും മനസ്സിലാക്കാന്\u200d', 'mn': 'Түүний шинэ хэрэглээнд хэдий ч, саяхан судалгаанууд дасгал хөдөлгөөний дараа, дасгал хөдөлгөөний дараа, цаг хугацаанд хязгааргүй урт удаан дараа сургалтын мэдрэлийн авторегрессийн дасгал загварын чадварыг харуулсан. Бид эдгээр үйл явдлыг судалж, хэрхэн хуваалцах, эсвэл орон нутгийн максима нь газрын үнэний, эзэнт, сурсан, шинжлэх ухааны хуваалцааны бүрэн суралцах хэлбэрээр шинэ санал дэвшүүлэгдсэн хуваалцааны үнэ зэрэг хадгалагдаж байгааг судалж Бид гурван төрлийн жинхэнэ хуваарилцаа бүтээж байгаа трактеб шалгалтыг зохион байгуулдаг: (1) LSTM-ын бүтээгдэхүүний хуваарилцаа, (2) дарааллын магадлал нь үүнийг хамаарахгүй байх боломжтой хуваарилцаа, мөн (3) эдгээр хоёр хоёрын бүтээгдэхүүний бүтээгдэхүүнийг Бидний судалгаанд хүлээн зөвшөөрөгдсөн, хүлээн зөвшөөрөгдсөн ололтуудыг харуулдаг. Эхлээд, өгөгдлийн цуглуулалтаас эхлээд, загварын эрүүлэлтийн зардал нь газрын үнэний хуваарилалтаас хамгийн их үнэтэй бөгөөд хагас бүтээгдэхүүнтэй хуваарилалт. Хоёрдугаар, суралцахын дараа, газрын үнэний хуваарилалтын зардал нь өгөгдлийн цуглуулалтын харьцуулахад хамгийн том зардал багасгах боломжтой. Харин хагас бүтээгдэхүүний хуваарилалтын хамгийн том зардал нь Эцэст нь, сурсан хуваарилалтын хуваарилалтын тусламжтай хуваарилалтын чадвар суралцах хэлхээс өмнө хийгдсэн сонголтууд маш их нөлөөлдөг. Бид\nирээдүйн судалгаагаар бүх суралцах хэлхээ ойлгохын тулд хүчирхэг болон аюулыг бүрэн ойлгох, мэдрэлийн авторегрессийн дарааллын загваруудыг илүү сайжруулах хэрэгтэй.', 'no': 'Til tross på breidde bruk har nyleg studiar oppdaga uventa og uventa eigenskapar for neuralautoregressiv sekvensmodeller som treng med maksimal sannsynlighet, slik som ein uansett høg affinitet til kort sekvens etter trening og til uendelig lang sekvens ved dekoding av tid. Vi foreslår å studiera desse fenomena ved å undersøke korleis modusene, eller lokale maksimum, av ei distribusjon vert beholde gjennom den fulle læringskjeden av bakgrunnsannheten, empiriske, lærte og dekodingsinduserte distribusjonane, gjennom den nye foreslåde gjenoppretting av modus. Vi designerer ein tråtabell testen der vi bygger tre typar grunnsannhetsdistribusjonar: (1) ein LSTM-basert strukturert distribusjon, (2) ein unstrukturt distribusjon der sannsynligheten av ei sekvens ikkje avhengig av innhaldet sin, og (3) ein produkt av desse to som vi kallar ein semistrukturert distribusjon. Studien vårt viser både venta og uventa finning. Først, startar med datasamlinga, avhengingskostnaden for modus er sterkt på grunnsannhetsdistribusjonen og er mest kostna med den halvstrukturerte distribusjonen. Andre, etter læring, kan modus gjenopprettingskostene frå bakgrunnsannhetsdistribusjonen auke eller redusere sammenlignet med datasamlinga, med den største kostnadedegradasjonen som skjer med den halvstrukturerte bakgrunnsannhetsdistribusjonen. Etter slutt, kan det dekodingsinduserte distribusjonen gjenoppretta modus frå lærte distribusjon heilt påvirke av vala som er gjort tidlegare i læringskjeden. Vi avsluttar\nat framtidige forskning må betra heile læringskjeden for å forstå potensialene og perilene fullstendig, og for å forbetra meir neurale autoregressive sekvensmodeller.', 'mt': 'Minkejja l-użu wiesa’ tiegħu, studji riċenti wrew proprjetajiet mhux mistennija u mhux mixtieqa ta’ mudelli ta’ sekwenza awtoregressiva newrali mħarrġa b’probabbiltà massima, bħal affinità għolja mhux raġonevoli għal sekwenzi qosra wara t-taħriġ u għal sekwenzi infinitament twal fil-ħin tad-dekodifikazzjoni. Aħna nipproponu li nistudjaw dawn il-fenomeni billi ninvestigaw kif il-modi, jew il-massimi lokali, ta’ distribuzzjoni jinżammu tul il-katina sħiħa tat-tagħlim tad-distribuzzjonijiet tal-ground-truth, empiriċi, imgħallma u indotti mid-dekodifikazzjoni, permezz tal-ispiża tal-irkupru tal-modalità proposta l-ġdida. Aħna niddisinjaw test bed li jista’ jiġi ttrattat fejn nibnu tliet tipi ta’ distribuzzjonijiet tal-verità tal-art: (1) distribuzzjoni strutturata bbażata fuq LSTM, (2) distribuzzjoni mhux strutturata fejn il-probabbiltà ta’ sekwenza ma tiddependix fuq il-kontenut tagħha, u (3) prodott minn dawn it-tnejn li jissejħu distribuzzjoni semistrutturata. L-istudju tagħna juri kemm sejbiet mistennija kif ukoll mhux mistennija. L-ewwel nett, mill-ġbir tad-dejta, l-ispiża tal-irkupru tal-modalità tiddependi b’mod qawwi fuq id-distribuzzjoni tal-ground-truth u hija l-aktar għalja bid-distribuzzjoni semistrutturata. It-tieni, wara t-tagħlim, l-ispiża tal-irkupru tal-modalità mid-distribuzzjoni tal-verità tal-art tista’ tiżdied jew tonqos meta mqabbel mal-ġbir tad-dejta, bl-akbar degradazzjoni tal-ispejjeż li sseħħ mad-distribuzzjoni tal-verità tal-art semistrutturata. Fl-aħħar nett, l-abbiltà tad-distribuzzjoni indotta mid-dekodifikazzjoni li tirkupra modi mid-distribuzzjoni mitgħallma hija affettwata ħafna mill-għażliet li saru qabel fil-katina tat-tagħlim. Aħna nikkonkludu\nthat future research must consider the entire learning chain in order to fully understand the potentials and perils and to further improve neural autoregressive sequence models.', 'pl': 'Pomimo jego szerokiego zastosowania, ostatnie badania ujawniły nieoczekiwane i niepożądane właściwości neuronowych modeli sekwencji autoregresywnych trenowanych z maksymalnym prawdopodobieństwem, takie jak nierozsądnie wysokie powinowactwo do krótkich sekwencji po treningu i do nieskończonie długich sekwencji w czasie dekodowania. Proponujemy badanie tych zjawisk poprzez zbadanie, w jaki sposób tryby lub maksymalne lokalne dystrybucji są utrzymywane w całym łańcuchu uczenia się podstawowych, empirycznych, uczonych i dekodowanych dystrybucji, poprzez nowo proponowany koszt odzyskiwania trybu. Projektujemy traktowalny zestaw testowy, w którym budujemy trzy typy rozkładów podstawowych prawdy: (1) strukturalną dystrybucję opartą na LSTM, (2) niestrukturalną dystrybucję, w której prawdopodobieństwo sekwencji nie zależy od jej zawartości, oraz (3) produkt tych dwóch, które nazywamy dystrybucją półstrukturalną. Nasze badanie ujawnia zarówno oczekiwane, jak i nieoczekiwane wyniki. Po pierwsze, począwszy od gromadzenia danych, koszt odzyskiwania w trybie mocno zależy od dystrybucji prawdy podstawowej i jest najbardziej kosztowny w przypadku dystrybucji półstrukturalnej. Po drugie, po nauce koszt odzyskiwania w trybie trybu z dystrybucji podstawowej prawdy może wzrosnąć lub zmniejszyć w porównaniu do gromadzenia danych, przy największej degradacji kosztów występuje w przypadku półstrukturalnej dystrybucji podstawowej prawdy. Wreszcie, zdolność dystrybucji indukowanej dekodowaniem do odzyskiwania trybów z dystrybucji uczonej jest w dużym stopniu wpływem wyborów dokonanych wcześniej w łańcuchu uczenia się. Podsumowujemy\nże przyszłe badania muszą uwzględnić cały łańcuch uczenia się, aby w pełni zrozumieć potencjał i zagrożenia oraz aby dalej ulepszyć neuronowe autoregresywne modele sekwencji.', 'ro': 'În ciuda utilizării sale largi, studiile recente au dezvăluit proprietăți neașteptate și nedorite ale modelelor de secvențe neuronale autoregresive instruite cu probabilitate maximă, cum ar fi o afinitate nerezonabil de mare la secvențe scurte după antrenament și la secvențe infinit de lungi la timpul decodificării. Ne propunem să studiem aceste fenomene prin investigarea modului în care modurile, sau maximele locale, ale unei distribuții sunt menținute pe tot parcursul lanțului de învățare al distribuțiilor bazate pe adevăr, empirice, învățate și induse de decodare, prin intermediul noilor costuri de recuperare a modului propus. Proiectăm un pat de testare tractabil în care construim trei tipuri de distribuții bazate pe adevăr: (1) o distribuție structurată bazată pe LSTM, (2) o distribuție nestructurată în care probabilitatea unei secvențe nu depinde de conținutul său și (3) un produs din aceste două distribuții pe care le numim distribuție semi-structurată. Studiul nostru dezvăluie atât constatări așteptate, cât și neașteptate. În primul rând, începând cu colectarea datelor, costul de recuperare a modului se bazează puternic pe distribuția de bază-adevăr și este cel mai costisitor cu distribuția semi-structurată. În al doilea rând, după învățare, costurile de recuperare a modului din distribuția solului-adevăr pot crește sau scădea în comparație cu colectarea datelor, cea mai mare degradare a costurilor având loc cu distribuția semi-structurată solului-adevăr. În cele din urmă, capacitatea distribuției induse de decodare de a recupera moduri din distribuția învățată este foarte influențată de alegerile făcute mai devreme în lanțul de învățare. Încheiem\ncă cercetările viitoare trebuie să ia în considerare întregul lanț de învățare pentru a înțelege pe deplin potențialele și pericolele și pentru a îmbunătăți în continuare modelele de secvență autoregresivă neurală.', 'si': 'එයාගේ විශාල භාවිතාවක් නමුත්, අලුත් පරීක්ෂණයක් ප්\u200dරතික්\u200dරියාත්මක විශේෂ කරලා තියෙන්නේ නියුරාල ස්වයංක්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විශේෂ වි අපි ප්\u200dරශ්නය කරනවා මේ සිද්ධ විදිහට පරීක්ෂණය කරන්න ප්\u200dරශ්නයක් හෝ ස්ථානික ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් පරීක්ෂණය කරන්න පුළුවන් ඉගෙනගන්න පුළුවන් සි අපි පරීක්ෂණයක් සිද්ධා කරනවා කොහෙද අපි පරීක්ෂණයක් තුන් වර්ගයක් හදන්නේ: (1) LSTM අධාරිත සැකසුම් විතරයක්, (2) නිර්මාණ විතරයක් විතරයක් තියෙනවා කියලා, ක්\u200dරමණයේ ස අපේ පරීක්ෂණය ප්\u200dරකාශ කරනවා බලාපොරොත්තු හා බලාපොරොත්තු හොයාගන්න. මුලින්, දත්ත සංගීතනයෙන් පටන් ගන්න, විදියට ආරම්භ විශාල විදියට බලාපොරොත්තු විදියට විශ්වාස කරනවා සම්පූ දෙවෙනියි, ඉගෙන ගන්න පස්සේ, භූමිය-ඇත්ත විතරයෙන් ප්\u200dරමාණය ප්\u200dරමාණය විතරයෙන් විශාලනය කරන්න පුළුවන් නැහැ නැහැ නැහැ ද අන්තිමේදි, ඉගෙන ගත්ත විතරයෙන් පුළුවන් විතරයෙන් පුළුවන් විතරයෙන් පුළුවන් විතරයෙන් පුළුවන් පුළුවන් ව අපි අවසානය කරනවා.\nඅනාගතයේ පරීක්ෂණය සම්පූර්ණයෙන් ඉගෙන ගන්න පුළුවන් පරීක්ෂණය සහ භාවිතාවක් සම්පූර්ණයෙන් තේරුම් ගන්න සහ න', 'sr': 'Uprkos širom korištenju, nedavna ispitivanja otkrila su neočekivane i neočekivane vlasništvo modela neuralne autoregresivne sekvence obučenih sa maksimalnom verovatnošću, kao što je nepravedno visoka afiniteta na kratke sekvence nakon treninga i beskonačno duge sekvence na vrijeme dekodiranja. Predlažemo da proučimo ove fenomene istražujući kako se režimi, ili lokalna maksima, distribucije održavaju u celom lancu učenja zemaljske istine, empiričkih, naučenih i dekodiranih distribucija, putem novog predloženog troškova oporavljanja režima. Mi dizajniramo testovanje traktala gde izgradimo tri vrste distribucije zemaljske istine: 1) strukturiranu distribuciju osnovanu na LSTM, (2) nestrukturalnu distribuciju gde verovatnost sekvence ne zavisi od njegovog sadržaja, i (3) proizvod ovih dvoje koje zovemo polu-strukturiranu distribuciju. Naša studija otkriva očekivane i neočekivane nalaze. Prvo, poèevši sa kolekcijom podataka, troškovi oporavke režima se jako oslanjaju na distribuciju zemaljske istine i najskuplji je sa polu-strukturiranom distribucijom. Drugo, nakon učenja, troškovi povratka režima iz distribucije zemaljske istine mogu povećati ili smanjiti u usporedbi sa kolekcijom podataka, s najvećim degradacijom troškova koja se dešava sa polu-strukturiranom distribucijom zemaljske istine. Konačno, sposobnost distribucije indukovane za dekodiranje režima za oporavak iz učenog distribucije vrlo utječe na izbore koje su donijele ranije u lancu učenja. Završili smo\nda buduća istraživanja mora razmotriti cijeli lanac učenja kako bi potpuno razumela potencijale i opasnosti i da bi dalje poboljšali modele neuralne autoregresivne sekvence.', 'so': 'Inkastoo isticmaalkeeda ballaadhan, waxbarashooyinkii ugu dambeeyey waxay muujiyeen noocyo aan la filanayn oo aan la filanayn oo aan la suurtoonayn dabeecada naxaasta ah oo lagu baray si ugu dhaqdhaqaaqi ah, tusaale ahaan xiriir dheer oo gaaban xilliyada waxbarashada kadib iyo xilliga aad u dheer xilliga decodiga. Waxaynu soo jeedaynaa in aan barano waxyaabahaas si aan u baaraandegiso qaababka ama maximada, sida ay u haystaan iskuulka waxbarashada oo dhan ee runta dhulka, qiimeeyada, barashada iyo waxyaabaha la qoray, waxaana lagu soo bandhigayaa kharashka cusub ee lagu soo jeeday. We design a tractable testbed where we build three types of ground-truth distributions: (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution.  Waxbarashadeenu wuxuu muujiyaa dhamaantooda la rajaynayo iyo wixii aan filanayn. Marka ugu horeysa, marka lagu bilaabo soo urursashada macluumaadka, qaabka dib u soo celinta kharashkiisu aad buu ugu xiran yahay qaybinta runta, wuxuuna ugu kharash yahay qaybinta qaybinta semi-dhisan. Second, kadib waxbarashada dabadeed, kharashka ku baxa qaybinta runta dhulka ayaa kordhi kara ama hoos u dhici kara si la barbarto ururka macluumaadka, waxaana ka soo baxa kharashka ugu weyn oo ku kala qaybsan qaybinta runta dhulka. Ugu dambaysta waxaa saameyn ku leh doorashooyinka horay loo sameeyay silsilada waxbarashada. Waxaan dhamaystirnaa\nin baaritaanka mustaqbalka ah waa in ay ka fikiraan silsilada waxbarashada oo dhan si aad u garato awoodda iyo khatar-khatar iyo si ay u sii kordhiso qaababka naxaasta oo jidhka ah.', 'sv': 'Trots dess utbredda användning har nyare studier avslöjat oväntade och oönskade egenskaper hos neurala autoregressiva sekvensmodeller tränade med maximal sannolikhet, såsom en orimligt hög affinitet till korta sekvenser efter träning och till oändligt långa sekvenser vid avkodningstid. Vi föreslår att studera dessa fenomen genom att undersöka hur olika sätt, eller lokala maximer, för en distribution upprätthålls genom hela inlärningskedjan av grundsanning, empiri, lärd och avkodningsinducerad distribution, via den nyligen föreslagna modeåtervinningskostnaden. Vi designar en trakterbar testbädd där vi bygger tre typer av jordsanningsfördelningar: (1) en LSTM baserad strukturerad distribution, (2) en ostrukturerad distribution där sannolikheten för en sekvens inte beror på dess innehåll, och (3) en produkt av dessa två som vi kallar en semistrukturerad distribution. Vår studie visar både förväntade och oväntade resultat. För det första, med början i datainsamlingen, förlitar sig kostnaderna för återställning av läge starkt på jordsanningsfördelningen och är dyrast med den semi-strukturerade distributionen. För det andra, efter lärandet, kan kostnaderna för återställning av läge från fördelningen av marksanning öka eller minska jämfört med datainsamling, med den största kostnadsförsämringen sker med den semi-strukturerade marksanningsfördelningen. Slutligen påverkas den avkodningsinducerade distributionens förmåga att återhämta lägen från den lärda distributionen starkt av de val som gjorts tidigare i inlärningskedjan. Vi avslutar\natt framtida forskning måste beakta hela inlärningskedjan för att fullt ut förstå potentialer och faror och ytterligare förbättra neurala autoregressiva sekvensmodeller.', 'ta': 'அண்மையான பயன்பாட்டின் போது, சமீபத்திய ஆய்வுகள் எதிர்பாராத மற்றும் எதிர்பாராத பண்புகளை காண்பித்துள்ளார்கள் மற்றும் குறைந்த நேரத்திற்குப் பின்னர் குறைவான வரிசைகளுக்கு  புதிய பரிந்துரைக்கப்பட்ட முறைமையில், அல்லது உள்ளூர் மெக்சிமா எப்படி பங்கீடு முழுவதும் கற்பனை செய்யப்பட்டுள்ளது என்பதை அறிந்து கொள்ள இந்த விஷயங்களை நாம் பரிந்துரைக் We design a tractable testbed where we build three types of ground-truth distributions: (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution.  நம் ஆய்வு எதிர்பார்த்த மற்றும் எதிர்பாராத கண்டுபிடிப்புகளை வெளிப்படுத்துகிறது. முதலில், தரவு தொகுப்புடன் துவங்கும் பாங்கு மீட்டு செலவு மீட்டெடுக்கும் விலை நிலத்தின் உண்மை பகிர்ந்தத்தை மீது உறுதியா இரண்டாவது, கற்றுக்கொண்ட பிறகு, நிலத்திலிருந்து உண்மை பகிர்ந்ததிலிருந்து முறை மீட்டு விலை செலவு தரவு தொகுப்புடன் அதிகப்படுத்தலாம் அல்லது குறைக்கல இறுதியில், கல்வி பங்கிலிருந்து முறைகளை மீட்டெடுப்பதற்கான குறிமுறையாக்கப்பட்ட பங்கீட்டின் இயல்பானது முன்பு கற்றல் சங்கில நாம் முடிவு\nஎதிர்கால ஆராய்ச்சி முழு கற்றல் சங்கிலியையும் புரிந்து கொள்ள வேண்டும் என்று பார்க்க வேண்டும் என்று தெரியவேண்டும் அத', 'ur': 'اس کی وسیع استعمال کے بغیر، اچھی تحقیقات نے ناامید اور ناپسندیدہ غیر منتظر ہونے والی مثالیں نازل کی ہیں جن کی مزید احتمال کے ساتھ تعلیم کی گئی ہے، جیسے ایک غیر منطقی بلند غیر منطقی تعلیم کے بعد چھوٹے تعلیمات کے ساتھ اور بے انتہائی طویل تعلیمات کے لئے ڈ ہم یہ اتفاقات کو تحقیق کرنے کے لئے پیشنهاد کرتے ہیں کہ ایک تقسیم کے موڈ یا محلی مکسima کی طرح زمین حقیقت کی پوری سیکھ زنجیر کے ذریعے مطالعہ کریں، مصریح، علم اور ڈیکوڈ کی تقسیم کے ذریعے، نئی پیشنهاد کی موڈ کے مطالعہ سے، کس طرح حفاظت کیے جاتے ہیں۔ ہم ایک تراکٹیبل آزمائش کی طرح طراحی کرتے ہیں جہاں ہم تین طرح زمین حقیقت تقسیم کریں: (1) ایک LSTM بنیاد ساختہ تقسیم, (2) ایک غیر ساختہ تقسیم جہاں ایک سطح کی احتمال اس کے منصفات پر نہیں ہے اور (3) ان دونوں میں سے ایک محصول ہے جسے ہم نصف ساختہ تقسیم کرتے ہیں۔ ہمارا مطالعہ منتظر ہے اور منتظر نہیں ہیں۔ پہلے، ڈیٹا کالکٹ سے شروع ہوا، موڈ کی بازیابی کے قیمت مضبوط زمین-حقیقی تقسیم پر اعتماد ہوتی ہے اور اس سے زیادہ مزید مزید مزید ہے جو نصف ساختہ تقسیم کے ساتھ ہے. دوسرا، سیکھنے کے بعد، زمین حقیقت کے تقسیم سے موڈ کے مطابق مصادر کے مطابق بڑھا یا کم ہو سکتا ہے، اور نیم ساختہ زمین حقیقت کے تقسیم کے مطابق سب سے زیادہ مصادر ہے. آخر میں، سیکھا ہوا تقسیم سے موڈ اٹھانے کے لئے ڈیکوڈ کی تقسیم کا قابل بہت اثر دیتا ہے جو پہلے سیکھ زنجیر میں کیا گیا ہے. ہم فیصلہ کر رہے ہیں\nکہ مستقبل تحقیقات تمام تعلیم زنجیر کو سمجھنا چاہیے تاکہ پورے پورٹنسیل اور خطرات کو سمجھ سکیں اور نیورال اتروگریسٹی نمڈل کو اضافہ کریں۔', 'uz': "Yaqinda ishlatilganligini taʼminlovchi bo'lsa, yangi o'qituvchilar kutilmagan va noural avto-regressiv seksiyatlarning xususiyatlarini ko'proq imkoniyatlar bilan o'rganish imkoniyatlarini ko'rsatadi. Masalan, treningan keyin qisqa seksiyatlarning qisqa cheksiz cheksizlik darajalariga juda yetarli holatdir. Biz bu narsalarni o'rganishni tahrirlashni istaysizki, yangi talab qilingan holatning turlari va lokal maximalari qanday o'rganishni o'rganishni o'rganamiz, o'rganishni va ko'paytirishni o'rganish mumkin. Biz bu yerda uchta tur soʻzni rasm tarqatishni yaratishimiz mumkin: (1) LSTM asosida yaratilgan darajadagi tarqatishni (2) yaratish mumkin, bu sonlarning tarkibini ishga tushirilmaydi va bu ikkita narsalarning taʼminotga ishlatmaydigan narsalarni (3) va biz semi-structured distribution deb ataymiz. Bizning o'qituvchimiz kutilmagan va kutilmagan natijalarni ko'rsatadi. Birinchi marta, maʼlumot toʻplami bilan boshlanmoqda, holatni qaytarish qiymati yuqori soʻzni haqiqida ishlatadi va qiymati tarqatishda juda qiymati. Ikkinchi so'zda o'rganishdan keyin soʻzni tasdiqlashdan foydalanish mumkin va maʼlumot to ʻplagini kamaytirish mumkin. Qaytadan ajratilgan sonlarning eng katta qismi chegarasini kamaytirish mumkin. Endi, o'rganish sohalarini o'zgartirish imkoniyatini o'zgartirish imkoniyatini o'rganish boshqalarida o'rganishdan oldin tanlangan choʻllarining o'zgarishlariga juda ko'p qo'llaniladi. Biz bunday\nkelajakda o'rganishni butun o'rganishni o'rganishni o'ylashingiz kerak, xususiyatlarni butunlay o'rganish mumkin, va neyrolik avto-regressiv seksektiv modellarini oshirish uchun o'zgartirish kerak.", 'vi': 'Mặc dù được sử dụng rộng rãi, các nghiên cứu gần đây đã tiết lộ tính chất bất ngờ và không mong đợi của các mô- đun tự vệ thần kinh được đào tạo với mức độ xác suất tối đa, như khả năng không thể đạt mức độ đồng thuận với các chuỗi ngắn sau khi tập luyện và cho chuỗi dài vô tận trong thời gian giải mã. Chúng tôi đề nghị nghiên cứu những hiện tượng này bằng cách điều tra các chế độ, hay tối đa địa phương, của phân phối được duy trì trong suốt các chuỗi học tập đầy đủ của các phân phát trên mặt đất, thực tế, học được và giải mã, thông qua các chi phí phục hồi chế độ mới dự kiến. Chúng tôi thiết kế một giường thử với dấu vết nơi chúng tôi xây dựng ba loại phân phối Chân Lý: 1) một phân phối cơ cấu trúc dựa trên LSTM, 2) một phân phối không xây dựng nơi tính xác suất của một chuỗi không phụ thuộc vào nội dung của nó, và (3) một sản phẩm của hai thứ mà chúng tôi gọi là phân phối phân phối phân loại Sắp xếp. Nghiên cứu của chúng tôi cho thấy cũng như bất ngờ. Đầu tiên, bắt đầu với việc thu thập dữ liệu, các chi phí phục hồi chế độ phụ thuộc chặt vào việc phân phối thực tế mặt đất và sẽ tốn kém nhất với phân phối phân tích. Thứ hai, sau khi học xong, chi phí phục hồi chế độ từ phân phối Chân Lý có thể tăng hoặc giảm so với bộ sưu tập dữ liệu, với mức độ thoái hóa lớn nhất xảy ra với phân phối mặt đất-Chân-ổn định. Cuối cùng, khả năng phân phối do giải mã phục hồi các chế độ từ phân phối đã học ảnh hưởng rất lớn đến các lựa chọn được thực hiện trước đây trong chuỗi học tập. Kết thúc\nrằng nghiên cứu tương lai phải xem xét to àn bộ chuỗi học để có thể hiểu hết tiềm năng và nguy hiểm và cải tiến các mô hình tự vệ thần kinh của các chuỗi.', 'bg': 'Въпреки широкото му използване, последните изследвания разкриват неочаквани и нежелани свойства на невронните авторегресивни модели на последователност, обучени с максимална вероятност, като неразумно висок афинитет към кратки последователности след тренировка и към безкрайно дълги последователности при декодиране. Предлагаме да се изследват тези явления, като се проучи как режимите, или локалните максими, на разпределението се поддържат през цялата учебна верига на разпределенията на базата истина, емпирични, научени и декодирани чрез новопредложените разходи за възстановяване на режима. Ние проектираме проследимо тестово поле, където изграждаме три вида разпределения на базата на истината: (1) базирано на ЛСТМ структурирано разпределение, (2) неструктурирано разпределение, където вероятността за последователност не зависи от съдържанието му, и (3) продукт от тези две, които наричаме полуструктурирано разпределение. Нашето проучване разкрива както очаквани, така и неочаквани открития. Първо, започвайки със събирането на данни, разходите за възстановяване на режима силно разчитат на разпределението на истината и са най-скъпи с полуструктурираното разпределение. Второ, след ученето разходите за възстановяване на режима от разпределението на базата истина могат да се увеличат или намалят в сравнение с събирането на данни, като най-голямото влошаване на разходите се случва при полуструктурираното разпределение на базата истина. И накрая, способността на индуцираното от декодиране разпределение да възстановява режимите от наученото разпределение е силно повлияна от изборите, направени по-рано в учебната верига. Заключваме\nче бъдещите изследвания трябва да разгледат цялата учебна верига, за да се разберат напълно потенциалите и опасностите и да се подобрят допълнително невронните авторегресивни последователни модели.', 'nl': 'Ondanks het brede gebruik ervan, hebben recente studies onverwachte en ongewenste eigenschappen onthuld van neurale autoregressieve sequentiemodellen getraind met maximale waarschijnlijkheid, zoals een onredelijk hoge affiniteit voor korte sequenties na training en oneindig lange sequenties tijdens decoderingstijd. We stellen voor om deze fenomenen te bestuderen door te onderzoeken hoe de modi, of lokale maxima, van een distributie worden gehandhaafd gedurende de volledige leerketen van de grond-waarheid, empirische, geleerde en decodering-geïnduceerde distributies, via de nieuw voorgestelde mode recovery kosten. We ontwerpen een traceerbare testbed waarin we drie soorten grond-waarheidsverdelingen bouwen: (1) een LSTM gebaseerde gestructureerde distributie, (2) een ongestructureerde verdeling waarbij de waarschijnlijkheid van een reeks niet afhangt van de inhoud ervan, en (3) een product van deze twee die we een semi-gestructureerde verdeling noemen. Ons onderzoek onthult zowel verwachte als onverwachte bevindingen. Ten eerste, te beginnen met gegevensverzameling, hangen de kosten voor modeherstel sterk af van de grondse-waarheidsdistributie en zijn ze het duurst bij de semi-gestructureerde distributie. Ten tweede, na het leren, kunnen de herstelkosten van de grond-waarheid distributie stijgen of dalen in vergelijking met gegevensverzameling, waarbij de grootste kostendegradatie optreedt bij de semi-gestructureerde grond-waarheid distributie. Ten slotte wordt het vermogen van de decodering-geïnduceerde distributie om modi te herstellen van de geleerde distributie sterk beïnvloed door de keuzes die eerder in de leerketen zijn gemaakt. Wij concluderen\nDat toekomstig onderzoek rekening moet houden met de hele leerketen om de mogelijkheden en gevaren volledig te begrijpen en neurale autoregressieve sequentiemodellen verder te verbeteren.', 'de': 'Trotz ihrer breiten Anwendung haben neuere Studien unerwartete und unerwünschte Eigenschaften neuronaler autoregressiver Sequenzmodelle gezeigt, die mit maximaler Wahrscheinlichkeit trainiert werden, wie eine unangemessen hohe Affinität zu kurzen Sequenzen nach dem Training und zu unendlich langen Sequenzen zur Dekodierungszeit. Wir schlagen vor, diese Phänomene zu untersuchen, indem wir untersuchen, wie die Modi oder lokalen Maxima einer Verteilung über die gesamte Lernkette der Ground-Truth, empirischen, erlernten und decoding-induzierten Verteilungen über die neu vorgeschlagenen Mode Recovery Kosten aufrechterhalten werden. Wir entwerfen ein traktables Testbed, in dem wir drei Arten von Ground-Truth-Verteilungen erstellen: (1) eine LSTM basierte strukturierte Verteilung, (2) eine unstrukturierte Verteilung, bei der die Wahrscheinlichkeit einer Sequenz nicht von ihrem Inhalt abhängt, und (3) ein Produkt dieser beiden, das wir eine semi-strukturierte Verteilung nennen. Unsere Studie zeigt sowohl erwartete als auch unerwartete Ergebnisse. Erstens, beginnend mit der Datenerfassung, hängen die Wiederherstellungskosten stark von der Ground-Truth-Verteilung ab und sind bei der semi-strukturierten Verteilung am teuersten. Zweitens können nach dem Lernen die Kosten für die Wiederherstellung des Modus aus der Ground-Truth-Verteilung im Vergleich zur Datenerhebung steigen oder sinken, wobei die größte Kostendegradation bei der semi-strukturierten Ground-Truth-Verteilung auftritt. Schließlich wird die Fähigkeit der decodierenden Verteilung, Modi aus der erlernten Verteilung wiederherzustellen, stark durch die Entscheidungen beeinflusst, die früher in der Lernkette getroffen wurden. Wir schließen\nDie zukünftige Forschung muss die gesamte Lernkette berücksichtigen, um die Potentiale und Gefahren vollständig zu verstehen und neuronale autoregressive Sequenzmodelle weiter zu verbessern.', 'da': 'På trods af dens brede anvendelse har nylige undersøgelser afsløret uventede og uønskede egenskaber ved neurale autoregressive sekvensmodeller trænet med maksimal sandsynlighed, såsom en urimelig høj affinitet til korte sekvenser efter træning og til uendeligt lange sekvenser ved afkodningstiden. Vi foreslår at studere disse fænomener ved at undersøge, hvordan de tilstande, eller lokale maksimum, af en fordeling opretholdes gennem hele læringskæden af grundsandhed, empiriske, lærte og afkodningsinducerede fordelinger, via de nyligt foreslåede mode recovery omkostninger. Vi designer en tractable testbed, hvor vi bygger tre typer jordsandhedsfordelinger: (1) en LSTM baseret struktureret fordeling, (2) en ustruktureret fordeling, hvor sandsynligheden for en sekvens ikke afhænger af dens indhold, og (3) et produkt af disse to, som vi kalder en semi-struktureret fordeling. Vores undersøgelse afslører både forventede og uventede resultater. For det første afhænger omkostningerne til gendannelse af tilstande i høj grad af fordelingen af jordsandheden og er dyrest med den semi-strukturerede distribution. For det andet kan omkostningerne til genvinding af tilstande fra jordsandhedsfordelingen efter læring stige eller falde sammenlignet med dataindsamling, hvor den største omkostningsnedbrydning forekommer med den semi-strukturerede jordsandhedsfordeling. Endelig påvirkes den afkodningsinducerede distributions evne til at genvinde modes fra den lærte distribution i høj grad af de valg, der er truffet tidligere i læringskæden. Vi konkluderer\nat fremtidig forskning skal overveje hele læringskæden for fuldt ud at forstå potentialer og farer og yderligere forbedre neurale autoregressive sekvensmodeller.', 'hr': 'Uprkos širom primjene, nedavna ispitivanja otkrila su neočekivane i neočekivane vlasništva modela neuroloških autoregresivnih sekvencija obučenih s maksimalnom vjerojatnošću, kao što je nepravedno visoka afiniteta na kratke sekvence nakon treninga i beskonačno duge sekvence na vrijeme dekodiranja. Predlažemo proučavati te fenomene istražujući kako se raspodjela režima ili lokalna maksima održava tijekom punog lanca učenja zemaljske istine, empiričkih, naučenih i dekodiranih raspodjela, putem novog predloženog troškova oporavljanja režima. Mi dizajniramo testovanje traktala gdje izgradimo tri vrste distribucije zemaljske istine: (1) strukturirane distribucije osnovane na LSTM, (2) neostrukturirane distribucije gdje vjerojatnost sekvence ne zavisi od njenog sadržaja, i (3) proizvod tih dva koje zovemo polu strukturiranu distribuciju. Naša studija otkriva očekivane i neočekivane nalaze. Prvo, počevši s prikupljanjem podataka, troškovi oporavke režima teško se oslanjaju na distribuciju zemaljske istine i najskuplji je s polu strukturiranom distribucijom. Drugo, nakon učenja, troškovi povratka režima iz distribucije zemaljske istine mogu povećati ili smanjiti u usporedbi s kolekcijom podataka, s najvećom degradacijom troškova koja se događa s polu-strukturiranom distribucijom zemaljske istine. Konačno, sposobnost distribucije indukovane za dekodiranje povratka režima iz učenog distribucije vrlo utječe na izbore koje su prije odlučili u lancu učenja. Zaključili smo\nda buduće istraživanje mora razmotriti cijeli lanac učenja kako bi potpuno razumio potencijale i opasnosti i dalje poboljšao modele autoregresivne sekvence neurona.', 'id': 'Despite its wide use, recent studies have revealed unexpected and undesirable properties of neural autoregressive sequence models trained with maximum likelihood, such as an unreasonably high affinity to short sequences after training and to infinitely long sequences at decoding time.  Kami mengusulkan untuk mempelajari fenomena-fenomena ini dengan menyelidiki bagaimana modus, atau maksimum lokal, distribusi tersebut tetap di seluruh rantai belajar penuh kebenaran tanah, empiris, belajar dan dekodifikasi-induksi distribusi, melalui biaya pemulihan mode yang baru diusulkan. Kami merancang tempat ujian yang dapat diseret di mana kami membangun tiga jenis distribusi kebenaran-tanah: (1) distribusi struktur berdasarkan LSTM, (2) distribusi tidak struktur di mana kemungkinan urutan tidak bergantung pada isi, dan (3) produk dari kedua ini yang kami sebut distribusi semi-struktur. Studi kami mengungkapkan kedua penemuan yang diharapkan dan tidak diharapkan. Pertama, mulai dengan koleksi data, biaya pemulihan mode sangat bergantung pada distribusi dasar-kebenaran dan paling mahal dengan distribusi semi-struktur. Kedua, setelah belajar, biaya pemulihan mode dari distribusi kebenaran-tanah mungkin meningkat atau menurun dibandingkan dengan koleksi data, dengan degradasi biaya terbesar yang terjadi dengan distribusi semi-strukturasi kebenaran-tanah. Akhirnya, kemampuan distribusi yang disebabkan dekodifikasi untuk memulihkan modus dari distribusi yang belajar sangat terpengaruh oleh pilihan yang dibuat lebih awal dalam rantai belajar. We conclude\nbahwa penelitian masa depan harus mempertimbangkan seluruh rantai belajar untuk memahami sepenuhnya potensi dan bahaya dan untuk meningkatkan lebih lanjut model urutan autoregresif saraf.', 'ko': '비록 그 용도가 광범위하지만 최근의 연구는 최대 유사법으로 훈련된 신경자귀환 서열 모델의 의외와 원하지 않는 특성, 예를 들어 훈련 후 짧은 서열에 대한 친화력이 너무 높고 디코딩할 때 무한장 서열에 대한 친화력이 너무 높다는 것을 보여 주었다.우리는 새로운 모델을 통해 원가를 회복하고 지면의 진상, 경험, 학습과 디코딩이 분포를 유도하는 전체 학습 체인에서 분포하는 모델이나 국부적 최대치를 어떻게 유지하는지 연구함으로써 이러한 현상을 연구할 것을 제안한다.우리는 조작하기 쉬운 테스트 플랫폼을 설계했다. 여기서 우리는 세 가지 유형의 지면 진가 분포를 구축했다. (1) LSTM의 구조화 분포를 바탕으로 하고 (2) 서열 확률은 그 내용의 비구조화 분포에 의존하지 않는다. (3) 이 두 가지 분포의 곱셈을 우리는 반구조화 분포라고 부른다.우리의 연구는 예상과 의외의 발견을 보여 주었다.우선, 데이터 수집부터 모델 복구 비용은 지면 진상 분포에 강하게 의존하고 반구조화 분포의 비용이 가장 높다.그 다음으로 학습 후에 데이터 수집에 비해 지면 진가 분포의 모델 회복 원가가 증가하거나 감소할 수 있다. 그 중에서 반구조화된 지면 진가 분포의 원가가 가장 큰 폭으로 낮아진다.마지막으로 디코딩 유도 분포가 학습 분포에서 패턴을 회복하는 능력은 학습 체인이 초기에 선택한 높은 영향을 받는다.우리는 결론을 얻어냈다\n미래의 연구는 잠재적인 위험을 충분히 이해하고 신경 자귀환 서열 모델을 더욱 개선하기 위해 전체 학습 체인을 고려해야 한다.', 'fa': 'با وجود استفاده گسترده\u200cاش، تحقیقات اخیراً ویژگی\u200cهای غیرمنتظر و ناخوشایند از مدل\u200cهای مجموعه\u200cی خودگریزگریزگریزگریزگریزگری عصبی که با احتمال بیشتری آموزش یافته\u200cاند، به عنوان یک نسبت غیر منطقی بالا به دنباله\u200cهای کوتاه بعد از تمرین و به دنبال ما پیشنهاد می\u200cکنیم این اتفاقات را با تحقیق کردن چگونه روش\u200cها، یا مکسیما محلی، در طول زنجیر یادگیری کامل از حقیقت زمینی، امپراتیک، یاد گرفته و تهیه شده\u200cاند، از طریق هزینه\u200cهای جدید پیشنهاد داده شده\u200cاند، تحقیق کنیم. ما یک آزمایش ردیابی را طراحی می\u200cکنیم که ما سه نوع توزیع حقیقت زمینی را ساختیم: (1) یک توزیع ساخته شده LSTM بنیاد می\u200cگیریم, (2) یک توزیع ساخته نشده که احتمال یک ردیابی بر محتویاتش بستگی ندارد، و (3) یک تولید از این دو که ما به یک توزیع نصف ساخته می\u200cگوییم. مطالعه\u200cی ما هر دو پیدا\u200cهای انتظار و غیرمنتظر را نشان می\u200cدهد. اول، از جمع داده ها شروع می کنیم، هزینه بازیابی حالت به شدت بر تقسیم حقیقت زمینی بستگی دارد و بیشتر با تقسیم نصف ساخته شده است. دوم، بعد از یادگیری، هزینه\u200cهای بازیابی حالت از تقسیم حقیقت زمینی می\u200cتواند در مقایسه با جمع داده\u200cها افزایش یا کاهش دهد، با بزرگترین کاهش هزینه\u200cای که با تقسیم حقیقت زمینی نصف ساخته می\u200cشود. بالاخره، توانایی توزیع\u200cدهنده\u200cی تغییر\u200cدهنده\u200cای برای بازیابی از توزیع\u200cدهنده\u200cی یادآوری از انتخاب\u200cهای پیش\u200cفرض در زنجیر یادآوری به شدت اثر می\u200cدهد. ما نتیجه می کنیم\nکه تحقیقات آینده باید کل زنجیر یادگیری را در نظر بگیرد تا کاملاً توانایی و خطر را درک کنند و مدل\u200cهای خودگریزگیری عصبی را بهتر کند.', 'tr': 'Ýagynyň ýakyn ulanmasyna rağmen, iň soňky aramalar neural otoregressiv hatlaryň gözlenmedik we ýok sanlyklary bilen bilinämli bir şekilde, okuwçylygdan soň ýok bir affinit ýaly gysga sequencere garaşylýar we köp sanlyklary dekodine geçirmekde azamsız bir şekilde garaşylýar. Biz bu äpişgeleri çözerek modlaryň, ýa-da ýerli maksimanyň nähili öwrenme zincirinde, empirik, öwrenmeden we dekoderlenen daýlamalaryň täze teklip etmäge maslahat berýäris. Biz traktablik testi çykarypdyrys we üç tür çykyş hakyky daýlamagymyzy inşadyrys: (1) LSTM tabanly döredilmiş daýlamagymyz, (2) bir düzgün daýlamagymyz şol ýerde bir düzgün mümkinçiligiň maksadyna baglanmaýar we (3) bu ikilerin bir ýarym-düzgün daýlamagymyz diýip atlandyrýarys. Biziň öwrenimiz hem garaşylýan hem garaşylmadyk tapylyklary görkeýär. Ilkinji gezek, maglumat koleksiýanyň başlanynda, modyň ýetişmesi üçin kän bir şekilde ýer-gerçeklik daýratyndan ynamly we ýarys-strukturlyk daýratynyň bilen iň bahasy bar. Ikinji gezek, öwrenmeden soňra, ýer-gerçeklik distribýusinden soňra ýarys-strukturlyk ýer-dogry distribýusiýanyň has baglary artyp ýa-da azalyp biler. Soňunda, öwrenen daýratyndan yzarlanýan modlary öwrenmek zincirinde öňki saýlamalar tarapyndan täsirli etýär. Biz çykýarys\nGeljekki araştyrmalar hemme öwrenme zincirini doly potensiýalary we periýolaryny düşünmek üçin we neural otoregressiv dizileri düzeltmek üçin düşünmeli bolýar.', 'sw': 'Pamoja na matumizi yake mengi, tafiti za hivi karibuni zimeonyesha utaratibu usiotarajiwa na usio na uwezekano wa mifumo ya kudhibiti ubongo ulioendeshwa kwa uwezekano wa kiasi kikubwa, kama vile uhusiano mkubwa wa sekta fupi baada ya mafunzo na kwa mfululizo wa muda mrefu wa kupunguza. Tunazipendekeza kusoma hali hii kwa kuchunguza namna namna ya usambazaji, au uwezekano wa maeneo ya eneo hilo, utaratibu wa usambazaji unavyoendelea kuendelea katika mfungo mzima wa kujifunza ukweli wa ardhi, msimamo, umejifunza na kuchunguza usambazaji huu, kupitia gharama mpya zilizopendekezwa. Tunaweza kutengeneza vifaa vya teknolojia ambapo tunajenga aina tatu ya usambazaji wa ukweli wa ardhi: (1) usambazaji ulioanzishwa kwa LSTM, (2) usambazaji ulioanzishwa ambapo uwezekano wa mfumo hautegemea maudhui yake, na (3) uzalishaji wa hizi mbili ambazo tunaita usambazaji wa sekunde. Utafiti wetu unaonyesha matokeo yanayotarajiwa na yasiyotarajiwa. Kwanza, kuanzia kwa mkusanyiko wa taarifa, gharama za kurejesha upya zinategemea sana kwa usambazaji wa ukweli wa ardhi na ni gharama kubwa kwa usambazaji wa sekondari. Pili, baada ya kujifunza, gharama za upya kutoka kwa usambazaji wa ukweli wa ardhi inaweza kuongezeka au kupunguza ukilinganishwa na mkusanyiko wa data, na kiwango kikubwa cha gharama kinachotokea na usambazaji wa ukweli wa ardhi wa sekondari. Mwisho, uwezo wa usambazaji wa kupunguza vifaa vya kupunguza aina kutoka kwa usambazaji wa elimu umeathiriwa sana na uchaguzi uliofanywa mapema katika mfungo wa kujifunza. tunahitimisha\nkwamba utafiti wa baadaye lazima utafakari mfungwa mzima wa kujifunza ili kuelewa vizuri na hatari na kuendeleza mifano ya kudhibiti mfumo wa neura.', 'af': "Terwyl sy wyde gebruik, het onlangse studie onverwagte en onverwagbare eienskappe van neurale autoregressiewe sekwensiemodele ontvang met maksimum waarskynlik, soos 'n ongeregtig hoë affiniteit na kort sekwensies na onderwerp en na onbeëindig lanke sekwensies by dekodering tyd geopenbaar. Ons voorstel om hierdie fenomene te ondersoek deur te ondersoek hoe die modus of plaaslike maksima van 'n verspreiding onderhou word deur die volle leer ketting van die grond-waarheid, empiriese, leer en dekodeerde verspreidings deur die nuwe voorgestelde modus herstel koste. Ons ontwerp 'n tractable toets waar ons drie tipes grond-waarheid verspreidings bou: (1) ' n LSTM gebaseerde struktureerde verspreiding, (2) ' n ongestruktureerde verspreiding waar waarskynlik van 'n sekvensie nie afhang van sy inhoud nie, en (3)  'n produkt van hierdie twee wat ons noem 'n semistruktureerde verspreiding. Ons studie vertoon beide verwagte en onverwagte vindings. Eerste, begin met data versameling, modus herstelling koste sterk verlig op die grond-waarheid verspreiding en is mees koste met die semistruktureerde verspreiding. Tweede, na die leer, die modus herstel koste van die grond-waarheid verspreiding kan vergroot of verklein word vergelyk met data versameling, met die grootste koste verspreiding wat voorkom met die semistruktureerde grond-waarheid verspreiding. Eindelik, die moontlik van die dekodeerde verspreiding na herstel modus van die geleerde verspreiding is baie invloek deur die keuses wat vroeër gemaak is in die leer ketting. Ons sluit\ndat toekomstige ondersoek die hele leer ketting moet beskou om die potensiele en periëls volledig te verstaan en om neurale autoregressiewe sekwensiemodele verder te verbeter.", 'sq': 'Pavarësisht nga përdorimi i saj i gjerë, studimet e fundit kanë zbuluar pronësi të papritura dhe të padëshirueshme të modeleve të sekuencës nervore autoregressive të stërvitur me gjasa maksimale, të tilla si një afinitet të lartë pa arsye ndaj sekuencave të shkurtra pas stërvitjes dhe sekuencave të pafund të gjata në kohën e dekodimit. Ne propozojmë të studiojmë këto fenomene duke hetuar se si modalitetet, apo maksimalet lokale, të një shpërndarjeje mbahen nëpër zinxhirin e plotë të mësimit të të vërtetës tokësore, empirike, të mësuara dhe të dekodifikuara të shpërndarjeve, nëpërmjet kostos së ri të propozuar për ripërtëritjen e modalitetit. Ne dizajnojmë një shtrat të testueshëm ku ndërtojmë tre lloje shpërndarje tokësore-të vërtetës: (1) një shpërndarje strukturuar bazuar në LSTM, (2) një shpërndarje jo strukturuar ku probabiliteti i një sekuence nuk varet nga përmbajtja e saj, dhe (3) një produkt i këtyre dy që ne e quajmë shpërndarje gjysmë strukturuar. Studimi ynë zbulon gjetje të pritura dhe të papritura. Së pari, duke filluar me mbledhjen e të dhënave, kostoja e ripërtëritjes së modalitetit mbështetet fort në shpërndarjen tokë-të vërtetës dhe është më e shtrenjtë me shpërndarjen gjysmë-strukturuar. Së dyti, pas mësimit, kostoja e ripërtëritjes së modalitetit nga shpërndarja tokë-e të vërtetës mund të rritet apo të zvogëlohet krahasuar me mbledhjen e të dhënave, me degradimin më të madh të kostos që ndodh me shpërndarjen gjysmë-strukturuar tokë-e të vërtetës. Më në fund, aftësia e shpërndarjes së shkaktuar nga dekodimi për të rikuperuar modalitetet nga shpërndarja e mësuar është ndikuar shumë nga zgjedhjet e bërë më parë në zinxhirin e mësimit. Ne përfundojmë\nse kërkimi i ardhshëm duhet të konsiderojë të gjithë zinxhirin e mësimit me qëllim që të kuptojë plotësisht potencialet dhe rreziqet dhe të përmirësojë më tej modelet e sekuencës neurologjike.', 'am': 'ምንም እንኳን በተዘጋጀ ጥያቄው ቢሆንም፣ የቀድሞው ተማሪዎቹ በተስፋ እና የማይፈጸመ የናውሬል የራሳቸውን ሥርዓት ሥርዓት ምርጫዎች በሚያስተማሩበት በትልቁ ምናልባት፣ እንደምናልባት ከትምህርት በኋላ ትንሽ ስርዓት ለመቆጣጠር እና ለረጅም ዘመን በክፍለ ዘመን ለመግጠም የማይችል ጥቅረት አግኝቷል፡፡ We propose to study these phenomena by investigating how the modes, or local maxima, of a distribution are maintained throughout the full learning chain of the ground-truth, empirical, learned and decoding-induced distributions, via the newly proposed mode recovery cost.  3 ዓይነት የመሬት-እውነትን ክፍል የምንሠራበት የግንኙነት አካባቢ (1) የግንኙነት ክፍል (2) በተመሳሳይ ግንኙነት በይነመረብ ላይ የማይታመን ግንኙነት (3) የእነዚህን ሁኔታ ክፍል እናስባለን፡፡ ትምህርታችን ተስፋ የሌለበት ፍላጎቶችንም ይገልጣል፡፡ መጀመሪያ፣ ከዳታ ክፍል ጀምሮ በመሬት-እውነት አካባቢ እና በክፍለ ክፍል በጣም ዋጋ ነው፡፡ በሁለተኛው፣ ከተማረ በኋላ የምድር-እውነት ክፍል የመሬት ክፍለ ክፍል ማድረግ ወይም ከዳታ ክፍል ጋር በሚያሳድግ፣ በተመሠረተች መሬት-እውነት ክፍተት የተለየ ትልቁ ክፍል የሚያሳዝን ይችላል፡፡ በመጨረሻው፣ የመማር ሰንሰለት መጀመሪያ የተደረገውን ምርጫዎች ከመመለስ የሚችለውን የዝክዶ-የነጥብ አካባቢ ማድረግ ሥልጣን እጅግ የበለጠ ነው፡፡ መጨረሻ እናደርጋለን\nየኋለኛይቱ ምርመራ የሙሉ ትምህርት ሰንሰለት እና የፍርሃቶችን ሙሉ ለማስተዋል እና የናቡራልን የራሳቸውን የሥልጣን ሥርዓት ምሳሌዎችን ለማሻል ያስፈልጋል፡፡', 'hy': 'Չնայած դրա լայն օգտագործման, վերջին ուսումնասիրությունները բացահայտել են նյարդային ավտոռեգրեսիվ հաջորդականության մոդելների անսպասելի և անցանկալի հատկություններ, որոնք վարժեցվել են առավելագույն հավանականությամբ, ինչպիսիք են օրինակ չափազանց բարձր աֆինանսականությունը վարժեցման հետ Մենք առաջարկում ենք ուսումնասիրել այս երևույթները հետազոտելով, թե ինչպես են բաշխման մեթոդները կամ տեղական մեծամասնությունները պահպանվում գետնին ճշմարտության, էմպրիկական, սովորված և կոդավորված բաշխման ամբողջ ուսումնասիրության շղթաներում նորից առաջարկված մեթոդների վերականգնման արժե We design a tractable testbed where we build three types of ground-truth distributions: (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution.  Մեր ուսումնասիրությունը բացահայտում է նաև սպասելի, նաև անսպասելի բացահայտումներ: Առաջինը՝ սկսելով տվյալների հավաքածուց, մեդիդի վերականգնման արժեքը ուժեղ կախված է հիմնական-ճշմարտության տարածման վրա և ամենաթանկ է կիսակառուցվածքի տարածման վրա: Երկրորդ, սովորելուց հետո, մակարդակի ճշմարտության տարածման արդյունքում վերականգնման արժեքը կարող է աճել կամ նվազել, համեմատած տվյալների հավաքածուի հետ, որտեղ ամենամեծ արժեքի դեգրադացիան տեղի է ունենում կես-կառուցվածքավոր Վերջապես, կոդավորման արդյունքում առաջացված բաշխման կարողությունը վերականգնել սովորված բաշխման մեթոդները մեծ ազդեցություն ունի սովորելու շղթաում ավելի վաղ ընտրություններից: Մենք եզրակացնում ենք,\nthat future research must consider the entire learning chain in order to fully understand the potentials and perils and to further improve neural autoregressive sequence models.', 'az': 'Yaxınlıqlarının genişliyi istifadə etməsinə rağmen, çox gözləməz və gözləməz nöral autoregressiv modellərin mümkün olması ilə təhsil edilməyən ən yüksək mümkün olaraq, təhsil etdikdən sonra qısa sıralar və çox uzun sıralar kimi təhsil edilmişdir. Biz bu parçaları araşdırmaq üçün təklif edirik, yeni təklif edilmiş modunun təmizlənməsi maliyyəti ilə, həqiqət, empirik, öyrənmiş və kodlamalı dağıtımların tüm öyrənmə zincirində növbəni, ya da yerli maksimanın necə tutulmasını araşdırmaq üçün. Biz üç növ yerli haqq dağıtımı inşa edirik: LSTM tabanlı strukturlu dağıtımı, (2) sıralama mümkün olmayan dağıtımı təyin edirik. Bu ikisinin yarı-strukturlu dağıtımı adlandırırıq. Bizim təcrübəmiz də gözlənilməmiş və gözlənilməmiş tapıları göstərir. Əvvəlcə, məlumat koleksiyonundan başlayıb, mod təkrarlama maliyyəti yerli-gerçək dağıtımın üstündə çox yüklüdür və yarı-strukturlı dağıtımla çox yüklüdür. İkincisi, öyrəndikdən sonra, yer-həqiqət dağıtılışından ən böyük mal-dövləti, yarı-struktürlü yerli-həqiqət dağıtılışıyla müqayisədə daha yüksək ya da azaltır. Sonunda, öyrənmiş dağıtımdan keçmək üçün dekodinləndirilmiş dağıtının qabiliyyəti öyrənmək zəncirlərində əvvəl yapılmış seçimlər təsirləndirilir. Biz\ngələcək araştırmalar bütün öyrənmə zincirini tamamilə anlamaq üçün və nöral otoregressiv modellərini daha da yaxşılaşdırmaq üçün gözləməlidir.', 'bn': 'তার ব্যবহার সত্ত্বেও সাম্প্রতিক গবেষণা প্রকাশ করেছে নিউরেল স্বয়ংক্রিয় সেকেন্ডের মোডেলের অপ্রত্যাশিত এবং অপ্রত্যাশিত বৈশিষ্ট্যের বৈশিষ্ট্য প্রশিক্ষণ প্রদান করা হয়েছে, যে নতুন প্রস্তাবিত মোড পুনরুদ্ধারের মাধ্যমে কিভাবে মোড বা স্থানীয় ম্যাক্সিমা বিতরণের মাধ্যমে পুরো শিক্ষার শিক্ষার শিক্ষা শিক্ষার শিক্ষার শিক্ষার শিকার, সম আমরা একটি ট্র্যাক্সাবেল পরীক্ষা করি যেখানে আমরা তিনটি ধরনের ভূমি সত্য বিতরণ তৈরি করি: (১) একটি এলসিএম ভিত্তিক বিতরণ, (২) একটি অক্ষরিত বিতরণ যেখানে সেকেন্ডের সম্ভাবনা তার বিষয়বস্তুর উপর নি আমাদের গবেষণা প্রকাশ করে দেখা যাচ্ছে প্রত্যাশা এবং অপ্রত্যাশিত খুঁজে পাওয়া। প্রথমত, ডাটা সংগ্রহের মাধ্যমে শুরু হয়, মোড পুনরুদ্ধারের খরচ ভাবে ভূমির সত্য বিতরণের উপর নির্ভর করে এবং সেমি কাঠামো বিতরণের জন্য দ্বিতীয়, শিখার পর, মোডের খরচ ভূমির-সত্য বিতরণ থেকে পুনরুদ্ধার করতে পারে তথ্য সংগ্রহের তুলনায় বৃদ্ধি অথবা কমে যাবে, যেখানে সেমি কাঠামো ভূমির-সত্য শেষ পর্যন্ত শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার শিক্ষার্থীর কাছ থেকে ম আমরা শেষ করেছিলাম\nযে ভবিষ্যতের গবেষণা অবশ্যই পুরো শিক্ষার শিক্ষার শিক্ষার চেইন বিবেচনা করতে হবে যাতে পুরো সম্ভাবনা এবং বিপদ বুঝতে পারে এবং নিউরেলের', 'bs': 'Uprkos širom primjene, nedavna ispitivanja otkrila su neočekivane i neočekivane vlasništvo modela neuroloških autoregresivnih sekvencija obučenih sa maksimalnom vjerojatnošću, kao što je nepravedno visoka afinita do kratkih sekvencija nakon treninga i beskonačno dugih sekvencija u vrijeme dekodiranja. Predlažemo da proučimo te fenomene istražujući kako se režimi, ili lokalna maksima, distribucije održavaju u cijelom lancu učenja zemaljske istine, empiričkih, naučenih i dekodiranih distribucija, putem novog predloženog troškova oporavljanja režima. Mi dizajniramo testovanje traktala gdje izgradimo tri vrste distribucije zemaljske istine: (1) strukturirane distribucije osnovane na LSTM, (2) nestrukturalnu distribuciju gdje vjerojatnost sekvence ne zavisi od njegovog sadržaja, i (3) proizvod tih dva koje zovemo polu-strukturiranu distribuciju. Naša studija otkriva očekivane i neočekivane nalaze. Prvo, počevši sa kolekcijom podataka, troškovi oporavke režima se jače oslanjaju na distribuciju zemaljske istine i najskuplji je sa polu-strukturiranom distribucijom. Drugo, nakon učenja, troškovi povratka režima iz distribucije zemaljske istine mogu povećati ili smanjiti u usporedbi s kolekcijom podataka, s najvećom degradacijom troškova koja se događa sa polu-strukturiranom distribucijom zemaljske istine. Na kraju, sposobnost distribucije indukovane za dekodiranje režima povratka iz učenog distribucije visoko utječe na izbore koje su prije odlučili u lancu učenja. Zaključili smo\nda buduće istraživanje mora razmotriti cijeli lanac učenja kako bi potpuno razumio potencijale i opasnosti i da bi se dalje poboljšao modeli autoregresivne sekvence neurona.', 'ca': "Malgrat la seva ampla utilitat, estudis recents han revelat propietats inesperades i indesiderables de models de seqüència autoregressiva neural entrenats amb la màxima probabilitat, com una afinitat poc raonablement alta a les breves seqüències després de l'entrenament i a seqüències infinitament llargues al temps de decodificació. Proposem estudiar aquests fenomens investigant com es mantenen els mods, o màxims locals, d'una distribució a través de la cadena d'aprenentatge completa de les distribucions induïdes per la veritat terrestre, empírica, aprendida i decodificada, a través del cost de recuperació del món proposat. dissenyem un banc de prova tractable on construim tres tipus de distribucions de veritat terrestre: (1) una distribució estructurada basada en LSTM, (2) una distribució no estructurada on la probabilitat d'una seqüència no depèn del seu contingut, i (3) un producte d'aquests dos que anomenem distribució semiestructurada. Our study reveals both expected and unexpected findings.  Primer, començant amb la col·lecció de dades, el cost de recuperació del món depende fortament de la distribució terrestre-veritat i és el més cost ós amb la distribució semiestructurada. Segon, després d'aprendre, el cost de recuperació del món a partir de la distribució de la veritat terrestre pot augmentar o disminuir en comparació amb la col·lecció de dades, amb la més gran degradació del cost ocurrint amb la distribució semiestructurada de la veritat terrestre. Finalment, l'habilitat de la distribució induïda per la descodificació de recuperar els mods de la distribució aprenida està fortament afectada pels decisions fets abans a la cadena d'aprenentatge. Conclouem\nque la futura investigació ha de considerar la cadena d'aprenentatge sencera per entendre plenament els potencials i perills i millorar més els models de seqüència autoregressiva neuronal.", 'cs': 'Navzdory širokému využití, nedávné studie odhalily neočekávané a nežádoucí vlastnosti neuronových autoregresivních sekvenčních modelů trénovaných s maximální pravděpodobností, jako je například nepřiměřeně vysoká afinita k krátkým sekvencím po tréninku a k nekonečně dlouhým sekvencím v době dekódování. Navrhujeme studovat tyto jevy prostřednictvím zkoumání toho, jak jsou módy nebo lokální maxima distribuce udržovány v celém učebním řetězci základních, empirických, učených a dekódovaných distribucí, prostřednictvím nově navržených nákladů na zotavení režimu. Navrhujeme traktivní testování, kde sestavíme tři typy distribucí základní pravdy: (1) strukturované distribuce založené na LSTM, (2) nestrukturované distribuce, kde pravděpodobnost sekvence nezávisí na jejím obsahu, a (3) produkt těchto dvou, které nazýváme polostrukturované distribuce. Naše studie odhaluje očekávané i neočekávané nálezy. Za prvé, počínaje sběrem dat, náklady na obnovu režimu silně závisí na distribuci základní pravdy a jsou nejnákladnější u polostrukturované distribuce. Za druhé, po učení se mohou náklady na obnovu režimu z distribuce základní pravdy zvýšit nebo snížit ve srovnání se sběrem dat, přičemž největší degradace nákladů dochází u polostrukturované distribuce základní pravdy. Konečně, schopnost dekódované distribuce obnovit režimy z učené distribuce je velmi ovlivněna volbami učeného řetězce. Závěrem\nže budoucí výzkum musí brát v úvahu celý učební řetězec, aby plně porozuměl potenciálům a nebezpečím a dále zlepšoval neuronové autoregresivní sekvenční modely.', 'et': 'Vaatamata selle laialdasele kasutamisele on hiljutised uuringud näidanud maksimaalse tõenäosusega treenitud neuraalsete autoregressiivsete jadamudelite ootamatuid ja soovimatuid omadusi, näiteks ebamõistlikult suur afiinsus lühikeste järjestuste suhtes pärast treeningut ja lõpmatult pikkade järjestuste suhtes dekodeerimise ajal. Me teeme ettepaneku uurida neid nähtusi, uurides, kuidas jaotuse režiime või kohalikke maksimume säilitatakse kogu maapinna tõe, empiiriliste, õppitud ja dekodeerimisest tingitud jaotuste kogu õppeahela jooksul uue kavandatud režiimi taastamiskulude kaudu. Me projekteerime jälgitava testiplatsi, kus me ehitame kolme tüüpi maapinna tõe jaotusi: (1) LSTM põhinev struktureeritud jaotus, (2) struktureerimata jaotus, kus jada tõenäosus ei sõltu selle sisust, ja (3) nende kahe toote, mida me nimetame poolstruktureeritud jaotuseks. Meie uuring näitab nii oodatud kui ka ootamatud leiud. Esiteks, alustades andmete kogumisest, sõltub režiimi taastamise kulud tugevalt põhjalikust jaotusest ja on poolstruktureeritud jaotuse puhul kõige kulukam. Teiseks, pärast õppimist võivad režiimi taastamise kulud maapealse tõe jaotusest suureneda või väheneda võrreldes andmete kogumisega, kusjuures suurim kulude halvenemine toimub poolstruktureeritud maapealse tõe jaotusega. Lõpuks mõjutavad dekodeerimisest tingitud jaotuse võimet taastada õppitud jaotusest varasemad valikud suuresti. Me järeldame\net tulevased uuringud peavad kaaluma kogu õppeahela, et täielikult mõista potentsiaale ja ohte ning täiustada neuro autoregressiivseid jadamuudeleid.', 'fi': 'Laajasta käytöstä huolimatta viimeaikaiset tutkimukset ovat paljastaneet maksimaalisella todennäköisyydellä koulutettujen neuroautoregressiivisten sekvenssimallien odottamattomia ja epätoivottuja ominaisuuksia, kuten kohtuuttoman suuren affiniteetin lyhyihin sekvensseihin harjoittelun jälkeen ja äärettömän pitkiin sekvensseihin dekoodauksen aikana. Ehdotamme näiden ilmiöiden tutkimista tutkimalla, miten jakauman muodot, tai paikalliset maksimit, ylläpidetään koko maa-totuus-, empiirinen, opitun ja dekoodauksen aiheuttaman jakelun oppimisketjun läpi uuden moodin talteenottokustannusten kautta. Suunnittelemme seurattavan testialustan, jossa rakennamme kolmentyyppisiä ground-truth-jakaumia: (1) LSTM-pohjainen strukturoitu jakelu, (2) strukturoimaton jakelu, jossa sekvenssin todennäköisyys ei riipu sen sisällöstä, ja (3) näiden kahden tuotteen, jota kutsumme puolistrukturoiduksi jakeluksi. Tutkimuksemme paljastaa sekä odotettuja että odottamattomia löydöksiä. Ensinnäkin tiedonkeruusta alkaen moodin palautuskustannukset riippuvat vahvasti pohjatotuusjakauksesta ja ovat kalleimpia puolistrukturoidun jakelun yhteydessä. Toiseksi oppimisen jälkeen moodin talteenottokustannukset pohjatotuusjakauksesta voivat nousta tai laskea verrattuna tiedonkeruuseen, ja suurin kustannusten heikkeneminen tapahtuu puolistrukturoidulla pohjatotuusjakauksella. Lopuksi, dekoodauksen aiheuttaman jakelun kykyyn palauttaa modaaleja opitusta jakelusta vaikuttavat suuresti aiemmin oppimisketjussa tehdyt valinnat. Päätämme\nTulevassa tutkimuksessa on otettava huomioon koko oppimisketju, jotta voidaan täysin ymmärtää potentiaalit ja vaarat ja kehittää edelleen neuron autoregressiivisia sekvenssimalleja.', 'he': 'למרות השימוש הרחב שלו, מחקרים לאחרונה חשפו תכונות בלתי צפויות ולא רצויות של דוגמני רצף אוטומגרסיבי עצבי מאומנים עם סבירות מקסימה, כמו אפניות גבוהה בלתי הגיונית לרצף קצר לאחר האימון ולרצפים ארוכים ללא סוף בזמן הפענוח. אנו מציעים לחקור את התופעות האלה על ידי לחקור איך הצנועות, או המקסימום המקומיים, של פיצוח נשמרים במהלך שרשרת הלימודים המלאה של התפיצות האדמה-אמת, אמפירית, למדות והפיצוי, באמצעות עלות התאוששות במצב החדש שהצעה. אנו מעצבים מיטה מבחן שאפשר לנסות בה אנו בונים שלושה סוגים של פיצוצי אמת-קרקע: (1) פיצוץ מבוסס על LSTM, (2) פיצוץ לא מבוסס שבו הסבירות של רצף לא תלוי בתוכו, ו (3) תוצר של שני אלה שאנחנו קוראים פיצוץ חצי מבוסס. Our study reveals both expected and unexpected findings.  ראשית, בהתחלה באספת נתונים, עלות התאוששות במצב תלויה בכוחות בהפצה האמת-האדמה והיא הכי יקרה בהפצה חצי-מבנה. שנית, לאחר הלימודים, עלות התאוששות במצב מהפיצוץ האמת האדמה עלולה לגדול או להוריד בהשוואה לאספת נתונים, עם הפרעת העלות הגדולה ביותר מתרחשת עם פיצוץ האמת האדמה-האדמה חצי מבושל. סוף סוף, היכולת של ההפצה הנוגעת לפיתוח לפיתוח שיחזרו דרכים מהפצה הנלמדה משפיעה ביותר על ידי הבחירות שנעשו קודם בשרשרת הלימוד. אנחנו מסתיימים\nthat future research must consider the entire learning chain in order to fully understand the potentials and perils and to further improve neural autoregressive sequence models.', 'sk': 'Kljub široki uporabi so nedavne študije pokazale nepričakovane in neželene lastnosti nevronskih avtoregresivnih modelov zaporedja, usposobljenih z največjo verjetnostjo, kot je nerazumno visoka afiniteta do kratkih zaporedij po treningu in do neskončno dolgih zaporedij v času dekodiranja. Predlagamo preučevanje teh pojavov z raziskovanjem, kako se načini ali lokalne maksime porazdelitve ohranjajo skozi celotno učno verigo osnovne resnice, empiričnih, učenih in dekodiranih distribucij prek novo predlaganih stroškov obnovitve načina. Zasnovamo sledljivo testno ploščo, kjer zgradimo tri vrste osnovnih resničnih distribucij: (1) strukturirano distribucijo na osnovi LSTM, (2) nestrukturirano distribucijo, kjer verjetnost zaporedja ni odvisna od njene vsebine, in (3) produkt teh dveh, ki jih imenujemo polstrukturirana distribucija. Naša študija razkriva tako pričakovane kot nepričakovane ugotovitve. Prvič, začenši z zbiranjem podatkov, so stroški obnovitve načina močno odvisni od distribucije osnovne resnice in so najdražji pri polstrukturirani distribuciji. Drugič, po učenju se lahko stroški povračila načina iz porazdelitve resnice na osnovi povečajo ali zmanjšajo v primerjavi z zbiranjem podatkov, pri čemer se največja degradacija stroškov pojavi pri polstrukturirani porazdelitvi resnice na osnovi. Na sposobnost dekodirane distribucije, da obnovi načine iz učene distribucije, močno vplivajo odločitve, sprejete prej v učni verigi. Zaključimo\nda morajo prihodnje raziskave upoštevati celotno učno verigo, da bi v celoti razumeli potenciale in nevarnosti ter nadalje izboljšali modele avtoregresivnega zaporedja nevronskih sistemov.', 'ha': "Babu amfani da amfani da shi, masu ƙarami sun nuna wasu properproperties na wanda ba'a yi tsammãni ba da kuma ba'a sanar da shi ba na sami-misãlai na sequence na neurar mutane da aka sanar da shi a tsakanin kowace, kamar wata na'ura da ya yi nau'i ga nau'in matsayi kure bayan mafaka da kuma zuwa matsakaicin na dacewa. Munã kwaɗayin mu karanta wannan abu da ke iya ƙidãya a ƙidãya yadda aka tsare diffukan, ko kuma a lokal maxima, a cikin cikakken matsayin da aka sani bakin ƙasa-gaskiyar, ana karatun da rabon da aka buɗe da shi, ana sami kyautar da kwamfyutan da aka buƙata. Mu ƙayyade wani matsayi wanda za'a samar da su ci turu uku masu tsari ga ƙasa: (1) an samar da LSSM a samanta, rabon da aka daidaita, (2) wani rabon da ba'a samu'a da ba'a ƙayyade shi ba, da kuma (3) wata birnin waɗannan biyu, da Muke kiran a rabo-da-sakan. Kayan karatunmu na bayyana misãlai da ba'a yi tsammãni ba. Kayyan da, yana fara da haɗin data, ma'anar musammi mai girma na dõgara ga raba ƙasa-gaskiya kuma yana da mafi kyauta da rabon rabon da aka saka. Piki na, daga bayan an karanta, za'a ƙara yin rabon shirin shiryi daga rabin ƙasa da gaskiya, ko kuma ya ƙara da sami da sami da haɗin data, da kuma mafi girma taƙaitarwa ta sami da rabin gaske-sannin da aka saka-sakan. Haƙĩƙa, awon rabon rabon da ko-induced zuwa duba-tsari daga rabon da aka sani yana mai girma wa zaɓen zaɓen ka gabatar a cikin sarƙon da aka karanta. Munã ƙarama\nIna kamata in ƙidãya a kammala kammala matsayin da za'a fahimta cikakken mataimaki da hatari, kuma dõmin ya ƙara kowane misãlai na mutumar mutumari na farar kwamfyuta.", 'bo': 'Despite its wide use, recent studies have revealed unexpected and undesirable properties of neural autoregressive sequence models trained with maximum likelihood, such as an unreasonably high affinity to short sequences after training and to infinitely long sequences at decoding time. ང་ཚོས་བྱ་ཚུལ་འདི་ཚོ་རྣམས་ལས་བརྟག་ཞིབ་འཇུག་བྱེད་དགོས་མིན་འདུག། We design a tractable testbed where we build three types of ground-truth distributions: (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution. ང་ཚོའི་བརྩམས་ཆོས་རེ་བ་དང་རེ་འདུན་མེད་པའི་རྙན་པ་གཉིས་ཀྱི་རྟོགས་ཚར་བ་རེད། དང་པོ་ནས་བཙུགས་པ་ནི། ཐབས་ལམ་གྱིས་བསྐྱེད་སྐྱོང་གི་དངོས་སྐྱེས་ཚད་གནོད་ངང་གི་བགོ་སྤྲོད་ཀྱི་ཡོད་པ་དང་འདྲ་བའི་རྫོགས་ཆེ་ཤོ གཉིས་པ། སློབ་རྗེས་སུ། ཐབས་ལམ་གྱིས་རྒྱལ་ཁབ་དང་བདེན་བཤད་ཀྱི་བགོ་སྤྲོད་ནས་གནས་སྡུད་ཆ་མཉམ་དུ་མཐུན་རྐྱེན་སྐྱེན་ཚད་དང་མཉམ་དུ་ཉེ་བར་ མཇུག་རྫོགས་ན། སྒྲ་ཚུལ་གྱིས་ཕབ་ལེན་པའི་བགོ་སྤྲོད་ཀྱི་ཐབས་ལམ་དེ་ཚོ་སླ་རྩོལ་ནུས་མེད་སྤྲོད་ཀྱི་རྒྱུ་དངོས་བྱུང་། ང་ཚོས་མཇུག་ལྡན།\nམ་འོངས་པའི་འཚོལ་ཞིབ་བྱས་པར་སྐྱོན་བརྟན་པར་མཐོང་ནུས་ཀྱི་རྒྱུ་ལམ་ཡོངས་རྫོགས་ལ་བསམ་དགོས།', 'jv': 'Nereje nambah yang kalagayarno, akeh dumatenno hukum gak bakal terusan mulalah karo hal-hal ono Awak dhéwé nggunakake beraksi perbudhakan iki dadi iki dadi sakjane perusahaan kelas, winih, lan akeh dhéwé kuwi tindakan kejahatan We design a tractable test here we create 3 types of background-true Distribubutions:(1) an LTT-supported structural Distribution; Where am I Awak dhéwé, Mulai ngono data gatewak, perusahaan langgambar deweke nggawe barang kotak tentang kanggo kaleh true kuwi tindakan lan ngawe barang dhéwé Wis Nyong ngombye, kapan karo ndelok tentang kanggo ngubah modo sing paling kelangan karo Distribusi dipunangke punika dipunangke kapan ning sampek kelangan layer-mode-effects\nLaptop" and "Desktop'}
{'en': 'Using Hierarchical Class Structure to Improve Fine-Grained Claim Classification', 'ar': 'استخدام هيكل الفئة الهرمي لتحسين تصنيف المطالبات الدقيقة', 'pt': 'Usando a Estrutura de Classes Hierárquica para Melhorar a Classificação Refinada de Reivindicações', 'fr': 'Utilisation de la structure hiérarchique des classes pour améliorer la classification précise des revendications', 'es': 'Uso de la estructura jerárquica de clases para mejorar la clasificación detallada de las reclamaciones', 'ja': '階層的なクラス構造を使用して細かいクレーム分類を改善する', 'zh': '以层类结构改进细粒度声明分类', 'ru': 'Использование иерархической структуры классов для улучшения классификации мелких претензий', 'hi': 'पदानुक्रमित वर्ग संरचना का उपयोग करने के लिए ठीक दानेदार दावा वर्गीकरण में सुधार करने के लिए', 'ga': 'Struchtúr Ordlathach Aicme a Úsáid chun Aicmiú Éilimh Mhionghráthaithe a Fheabhsú', 'ka': 'ჰიერარიქული კლასის სტრუქტურაციის გამოყენება', 'hu': 'Hierarchikus osztályszerkezet használata a finomszemű követelések besorolásának javítására', 'el': 'Χρήση ιεραρχικής δομής κλάσης για τη βελτίωση της λεπτόκοκκης ταξινόμησης αξιώσεων', 'kk': 'Иерархикалық класс құрылымын қолдану үшін жақсы түрлі классификациясын жақсарту үшін', 'lt': 'Hierarchinės klasės struktūros naudojimas, siekiant pagerinti smulkių grūdų reikalavimų klasifikavimą', 'it': 'Utilizzo della struttura gerarchica delle classi per migliorare la classificazione delle rivendicazioni a grana fine', 'mk': 'Користење на хиерархична класична структура за подобрување на класификацијата на фино-зелените барања', 'ms': 'Mengguna Struktur Kelas Hierarkikal untuk meningkatkan Klasifikasi Claim Grained-Baik', 'ml': 'ക്ലാസിമിന്റെ ക്ലാസ്സിഷന്\u200d മുന്\u200dകൂട്ടുന്നതിനായി ഹീരാര്\u200dക്കിക്കല്\u200d ക്ലാസ്സ് സ്ട്രാക്ട്രൂട്ട', 'no': 'Bruk hierarkisk klassestruktur for å forbedra finn- grenseklassifikasjon', 'mt': 'L-użu tal-Istruttura tal-Klassi Ħerarkika għat-Titjib tal-Klassifikazzjoni tat-Talbiet b’Ħruġ Fin', 'mn': 'Хэрэглэгч класс бүтцийг ашиглах нь хөнгөн хэмжээний классификацийг сайжруулахын тулд', 'si': 'හොඳ ග්\u200dරේන්ඩ් ක්\u200dලාසික්ෂිය සංවිධානය විස්තර කරන්න', 'pl': 'Korzystanie z hierarchicznej struktury klas w celu poprawy drobnoziarnistej klasyfikacji roszczeń', 'ro': 'Utilizarea structurii ierarhice a claselor pentru a îmbunătăți clasificarea cererilor cu granule fine', 'sv': 'Använda hierarkisk klasstruktur för att förbättra finkornig klassificering', 'so': 'Isticmaalayaal fasalka Hierarchical Structure to Improve Fine-Grained Classification', 'sr': 'Koristenje hijerarhičke klase strukture za poboljšanje finog klasifikacije', 'ur': 'پاکیزہ گرینڈ کلام کلاس ساختار کی استعمال کرتا ہے', 'ta': 'நல்ல வகுப்பு வகுப்பு உருவாக்கத்தை மேம்படுத்த பயன்படுத்துகிறது', 'vi': 'Sử dụng cấu trúc sinh lớp học để cải thiện thẻ khai thác', 'uz': 'Using Hierarchical Class Structure to Improve Fine-Grained Claim Classification', 'nl': 'Hiërarchische klassenstructuur gebruiken om fijnkorrelige claimclassificatie te verbeteren', 'bg': 'Използване на йерархична класова структура за подобряване на класификацията на претенции с фино зърно', 'hr': 'Koristeći hijerarhičku strukturu klase za poboljšanje klasifikacije fino-graviranog klada', 'ko': '층별 구조를 이용하여 세립도 클레임 분류를 개선하다', 'da': 'Brug af hierarkisk klassestruktur til at forbedre klassificeringen af finkornede krav', 'sw': 'Kwa kutumia Mradi wa darasa la Hierarchical to improvise Classification', 'tr': 'Hierarhiýal Taýsy Baglançylyk Taýikligini Improved etmek üçin Taýiklik Taýikligi ullan', 'fa': 'استفاده از ساختار کلاس تحریک برای توسعه کلاس تحریک', 'de': 'Verwendung der hierarchischen Klassenstruktur zur Verbesserung der feinkörnigen Claim-Klassifizierung', 'id': 'Menggunakan Struktur Kelas Hierarkis untuk meningkatkan Klasifikasi Claim Grained-Fine', 'am': 'ሁኔታ፦', 'hy': 'Հիերարխիկ դասարանի կառուցվածքը բարելավելու համար', 'az': 'İyi qədər çəkilmiş Klasifikasyonu Improved etmək üçün hiyerarşik Sınıf strukturasını istifadə edir', 'bn': 'সুন্দর-গ্রেফতার ক্লাস সংক্রান্ত ব্যবহার করা হচ্ছে', 'af': 'Gebruik hierarsies klas struktuur om Fine- Grain Klassifikasie te verbeter', 'cs': 'Použití hierarchické struktury tříd ke zlepšení jemnozrnné klasifikace reklamací', 'sq': 'Duke përdorur strukturën e klasës hierarkike për të përmirësuar klasifikimin e kërkesave me të holla', 'fi': 'Hierarkisen luokkarakenteen käyttäminen hienojyväisten korvausvaatimusten luokittelun parantamiseksi', 'et': 'Hierarhilise klassistruktuuri kasutamine peeneteraliste nõuete klassifitseerimise parandamiseks', 'ca': 'Utilitzant estructura de classe hieràrquica per millorar la classificació de reclamacions fines', 'bs': 'Koristeći hijerarhičku klasičnu strukturu za poboljšanje klasifikacije finog ograničenog klada', 'jv': 'Jejaring', 'he': 'Using Hierarchical Class Structure to Improve Fine-Grained Claim Classification', 'sk': 'Uporaba hierarhične strukture razredov za izboljšanje razvrstitve drobnozrnatih zahtevkov', 'ha': 'KCharselect unicode block name', 'bo': 'སྒྲིག་འཛུགས་ཀྱི་དབྱིབས་གྱི་དབྱིབས་སྒྲིག་འཛུགས་འདི་སྤྱད་ནས་མཐའ་རྡེབ་སྤྱོད་པ'}
{'en': 'The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory Controlling Migration might have subcategories Asylum limit or Border installations). A major challenge for automatic claim classification is the large number and low frequency of such subclasses. We address it by jointly predicting pairs of matching super- and subcategories. We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.claim ontologies (e.g. for immigration, a supercategory “Controlling Migration” might have subcategories “Asylum limit” or “Border installations”). A major challenge for automatic claim classification is the large number and low frequency of such subclasses. We address it by jointly predicting pairs of matching super- and subcategories. We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.', 'ar': 'يتطلب تحليل المناقشات العامة بشكل حاسم تصنيف المطالب السياسية وفقًا لأنطولوجيا الادعاء الهرمية (على سبيل المثال ، بالنسبة للهجرة ، قد يكون للفئة الفائقة "مراقبة الهجرة" فئات فرعية "حد اللجوء" أو "المنشآت الحدودية"). التحدي الرئيسي لتصنيف المطالبات التلقائي هو العدد الكبير والتكرار المنخفض لهذه الفئات الفرعية. نعالجها من خلال التنبؤ المشترك بأزواج من الفئات العليا والفرعية المتطابقة. نقوم بتفعيل هذه الفكرة من خلال (أ) ترميز القيود الناعمة في مصنف المطالبة و (ب) فرض قيود صارمة عبر البرمجة الخطية الصحيحة. تُظهر تجاربنا مع مصنفات المطالبات المختلفة في مجموعة صحف الهجرة الألمانية زيادات متسقة في الأداء للتنبؤ المشترك ، لا سيما للفئات النادرة ومناقشة تكامل النهجين.', 'pt': 'A análise dos debates públicos exige fundamentalmente a classificação das demandas políticas de acordo com ontologias de reivindicação hierárquicas (por exemplo, para imigração, uma supercategoria “Controlando a Migração” pode ter subcategorias “Limite de asilo” ou “Instalações de fronteira”). Um grande desafio para a classificação automática de sinistros é o grande número e a baixa frequência dessas subclasses. Nós o abordamos prevendo conjuntamente pares de super e subcategorias correspondentes. Operacionalizamos essa ideia (a) codificando restrições flexíveis no classificador de declarações e (b) impondo restrições rígidas via Programação Linear Inteira. Nossos experimentos com diferentes classificadores de reivindicações em um corpus de jornal de imigração alemão mostram aumentos consistentes de desempenho para previsão conjunta, em particular para categorias pouco frequentes e discutem a complementaridade das duas abordagens.', 'es': 'El análisis de los debates públicos requiere de manera crucial la clasificación de las demandas políticas de acuerdo con ontologías jerárquicas de reclamos (por ejemplo, para la inmigración, una supercategoría «Control de la migración» podría tener subcategorías «Límite de asilo» o «Instalaciones fronterizas»). Un desafío importante para la clasificación automática de reclamaciones es el gran número y la baja frecuencia de tales subclases. Lo abordamos mediante la predicción conjunta de pares de supercategorías y subcategorías coincidentes. Ponemos en práctica esta idea (a) codificando restricciones flexibles en el clasificador de reclamos y (b) imponiendo restricciones estrictas a través de la Programación Lineal de Enteros. Nuestros experimentos con diferentes clasificadores de reclamos en el corpus de un periódico de inmigración alemán muestran aumentos consistentes en el rendimiento para la predicción conjunta, en particular para categorías poco frecuentes y discuten la complementariedad de los dos enfoques.', 'fr': "L'analyse des débats publics nécessite de manière cruciale la classification des revendications politiques selon des ontologies hiérarchiques de revendications (par exemple, pour l'immigration, une supercatégorie «\xa0Contrôler la migration\xa0» peut avoir des sous-catégories «\xa0Limite d'asile\xa0» ou «\xa0Installations frontalières\xa0»). Le grand nombre et la faible fréquence de ces sous-classes constituent un défi majeur pour le classement automatique des revendications. Nous y répondons en prédisant conjointement des paires de super et de sous-catégories correspondantes. Nous opérationnalisons cette idée en (a) encodant des contraintes souples dans le classificateur de revendications et (b) en imposant des contraintes strictes via la programmation linéaire entière. Nos expériences avec différents classificateurs de demandes sur un corpus de journaux allemands sur l'immigration montrent des augmentations de performance constantes pour la prédiction conjointe, en particulier pour les catégories peu fréquentes, et discutent de la complémentarité des deux approches.", 'ja': '公開討論の分析には、階層的な主張オントロジーに従って政治的要求を分類する必要があります（例えば、移民については、スーパーカテゴリ「移住の管理」に「亡命制限」または「国境設備」というサブカテゴリがある場合があります）。自動クレーム分類の大きな課題は、そのようなサブクラスの数が多く、頻度が低いことです。私たちは、マッチするスーパーカテゴリとサブカテゴリのペアを共同で予測することによってそれに対処します。このアイデアは、(a)特許請求の範囲分類子のソフト制約を符号化し、(b)整数線形プログラミングを介してハード制約を課すことによって実用化する。ドイツの移民新聞コーパスにおける異なるクレーム分類子の実験では、特に頻度の低いカテゴリでの共同予測のための一貫したパフォーマンスの増加を示し、2つのアプローチの相補性について議論しています。', 'zh': '凡论议至要,以等言本体分类(如移民,"制移民"超级类或有"庇护限"、"边境设施"之类)。 自索赔分类者,此类多且频率下。 共占超级类与子类对来决之。 吾以(a)求分类器中编码软约束(b)以全数线性规加刚束以行之。 吾于德国移民报纸语料库上用异索赔分类之实验见,合占之性长,特于不常之类,而论此二术之互补性。', 'hi': 'सार्वजनिक बहस के विश्लेषण के लिए महत्वपूर्ण रूप से पदानुक्रमित दावे के अनुसार राजनीतिक मांगों के वर्गीकरण की आवश्यकता होती है (उदाहरण के लिए आव्रजन के लिए, एक सुपरकैटेगरी "माइग्रेशन को नियंत्रित करना" उपश्रेणियां "शरण सीमा" या "सीमा प्रतिष्ठानों" हो सकती हैं)। स्वचालित दावा वर्गीकरण के लिए एक बड़ी चुनौती बड़ी संख्या और ऐसे उपवर्गों की कम आवृत्ति है। हम संयुक्त रूप से मिलान सुपर और उपश्रेणियों के जोड़े की भविष्यवाणी करके इसे संबोधित करते हैं। हम इस विचार को (ए) दावा क्लासिफायर में नरम बाधाओं को एन्कोडिंग करके और (बी) पूर्णांक रैखिक प्रोग्रामिंग के माध्यम से कठिन बाधाओं को लागू करके संचालित करते हैं। एक जर्मन आव्रजन समाचार पत्र कॉर्पस पर विभिन्न दावा क्लासिफायरके साथ हमारे प्रयोग संयुक्त भविष्यवाणी के लिए लगातार प्रदर्शन में वृद्धि दिखाते हैं, विशेष रूप से अक्सर श्रेणियों के लिए और दो दृष्टिकोणों की पूरकता पर चर्चा करते हैं।', 'ru': 'Анализ публичных дебатов крайне требует классификации политических требований в соответствии с иерархической онтологией претензий (например, для иммиграции суперкатегория «Контроль за миграцией» может иметь подкатегории «Предел убежища» или «Пограничные объекты»). Серьезной проблемой для автоматической классификации претензий является большое число и низкая частота таких подклассов. Мы решаем эту проблему, совместно прогнозируя пары соответствующих супер- и подкатегорий. Мы реализуем эту идею путем (a) кодирования мягких ограничений в классификаторе формулы изобретения и (b) наложения жестких ограничений с помощью целочисленного линейного программирования. Наши эксперименты с различными классификаторами претензий на корпусе немецкой иммиграционной газеты показывают последовательное увеличение производительности для совместного прогнозирования, в частности для редких категорий, и обсуждают взаимодополняемость двух подходов.', 'ga': 'Éilíonn anailís ar dhíospóireachtaí poiblí go n-aicmiú na héilimh pholaitiúla de réir ontologies éilimh ordlathacha (m.sh. maidir le hinimirce, d’fhéadfadh fochatagóirí “Teorainn Tearmainn” nó “Suiteálacha Teorann” a bheith ag forchatagóir “Imirce a Rialú”. Dúshlán mór maidir le haicmiú éileamh uathoibríoch is ea líon mór agus minicíocht íseal na bhfo-aicmí sin. Dírímid air trí phéirí sárchatagóirí agus fochatagóirí meaitseála a thuar i gcomhpháirt. Déanaimid an smaoineamh seo a oibriú trí (a) srianta boga a ionchódú san aicmitheoir éilimh agus (b) srianta crua a fhorchur trí Chlárú Líneach Slánuimhir. Léiríonn ár dturgnaimh le haicmitheoirí éilimh éagsúla ar chorpas nuachtáin inimirce Gearmánach méaduithe comhsheasmhacha feidhmíochta le haghaidh comhthuar, go háirithe maidir le catagóirí neamhchoitianta agus pléann siad comhlántacht an dá chur chuige.', 'ka': "პოლიტიკური განსაზღვრების ანალიზაცია უფრო მნიშვნელოვანია პოლიტიკური მოთხოვრების კლასიფიკაცია იერაქტიკური განსაზღვრების ანტოლოგიისთვის (მაგალითად, იმიგრაციისთვის, სუპერკატეგორია 'კონტროლინური მი მნიშვნელოვანი განსაზღვრება ავტომატური განსაზღვრებისთვის კლასიფიკაციაში არის ასეთი ქვეკლასის დიდი რიცხვი და ცოტა ფერიცია. ჩვენ ამას ერთადერთად წარმოდგენით სუპერ და სუპკატეგორია. ჩვენ ამ იდეას a) კოდირების მარტივი ზომილებებით კლასიფიკაციაში და b) კოდირებული ზომილებების შესახებ დავყენებთ ინტერჯერი ლინიური პროგრამის გამოყენებით. ჩვენი ექსპერიმენტები, რომელიც განსხვავებული კლასიფიკაციებით გერმანეთის იმიგრაციის გვერდის კორპუსში, ჩვენი ექსპერიმენტები იქნება სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა პროგრა", 'el': 'Η ανάλυση των δημόσιων συζητήσεων απαιτεί καθοριστικά την ταξινόμηση των πολιτικών απαιτήσεων σύμφωνα με ιεραρχικές οντολογίες αξιώσεων (π.χ. για τη μετανάστευση, μια υπερκατηγορία "Έλεγχος της μετανάστευσης" μπορεί να έχει υποκατηγορίες "Όριο ασύλου" ή "Συνοριακές εγκαταστάσεις"). Μια σημαντική πρόκληση για την αυτόματη ταξινόμηση αξιώσεων είναι ο μεγάλος αριθμός και η χαμηλή συχνότητα τέτοιων υποκατηγοριών. Το αντιμετωπίζουμε προβλέποντας από κοινού ζεύγη αντιστοιχισμένων υπερ- και υποκατηγοριών. Λειτουργούμε αυτή την ιδέα (α) κωδικοποιώντας μαλακούς περιορισμούς στον ταξινομητή αξιώσεων και (β) επιβάλλοντας σκληρούς περιορισμούς μέσω Ακέραιου Γραμμικού Προγραμματισμού. Τα πειράματά μας με διαφορετικούς ταξινομητές αξιώσεων σε ένα σώμα γερμανικών εφημερίδων μετανάστευσης δείχνουν συνεπείς αυξήσεις απόδοσης για κοινή πρόβλεψη, ιδίως για σπάνιες κατηγορίες και συζητούν τη συμπληρωματικότητα των δύο προσεγγίσεων.', 'hu': 'A nyilvános viták elemzése alapvetően megköveteli a politikai igények hierarchikus igények ontológiái szerinti osztályozását (például a bevándorlás esetében a "Migráció ellenőrzése" szuperkategóriában a "Menekültügyi korlátozás" vagy a "Határmenti létesítmények") alkategóriák lehetnek. Az automatikus kárigények besorolásának egyik legnagyobb kihívása az ilyen alkosztályok nagy száma és alacsony gyakorisága. Ezt úgy kezeljük, hogy közösen megjósoljuk a megfelelő szuper- és alkategóriák párjait. Ezt az elképzelést (a) puha korlátozások kódolásával kódoljuk a követeléscsoportosítóban, és (b) kemény korlátozások bevezetésével az egész lineáris programozással. Egy német bevándorlási újságkorpuszon végzett különböző állításcsoportosítókkal végzett kísérleteink következetes teljesítménynövekedést mutatnak a közös előrejelzés tekintetében, különösen a ritka kategóriák esetében, és megvitatják a két megközelítés komplementaritását.', 'it': 'L\'analisi dei dibattiti pubblici richiede di fondamentale importanza la classificazione delle richieste politiche secondo ontologie gerarchiche delle rivendicazioni (ad esempio, per quanto riguarda l\'immigrazione, una sottocategoria "Controllo della migrazione" potrebbe avere sottocategorie "Limite di asilo" o "Impianti di frontiera"). Una sfida importante per la classificazione automatica dei sinistri è l\'elevato numero e la bassa frequenza di tali sottoclassi. Lo affrontiamo predicendo congiuntamente coppie di super e sottocategorie corrispondenti. Operazionalizziamo questa idea (a) codificando vincoli morbidi nel claim classificator e (b) imponendo vincoli rigidi tramite Integer Linear Programming. I nostri esperimenti con diversi claim classificatori su un corpus di giornali tedeschi sull\'immigrazione mostrano aumenti costanti delle prestazioni per la previsione congiunta, in particolare per le categorie rare e discutono la complementarità dei due approcci.', 'kk': "Көпшілік дискуссиялардың анализациясы иерархиялық сұрақтар онтологиясына сәйкес керек (мысалы, иммиграция үшін, 'Контроллеу миграциясы' деген супер санатының супер категориясы 'Атыл шегі' немесе 'Шегінің орнатылуы'). Автоматты сұрау классификациясының негізгі мәселесі - осы ішкі классының үлкен саны мен жиілігі. Біз оны супер- және супер- санаттарының екеуін біріктіруге болады. Біз бұл идеяны (a) кодтамасыз керек шектеулерінде және (b) бөлім сызық бағдарламасы арқылы қиын шектеулерді орындаймыз. Немігтік иммиграциялық жаңалық корпусындағы әртүрлі жаңалық классификациялардың тәжірибелеріміз біріктірілген таңдау үшін тәжірибелерін көрсетеді, осымен қатар кейбір категориялар үшін, екі жаңалықта", 'ms': "Analisis debat awam memerlukan kelasukan permintaan politik mengikut ontologi permintaan hierarkis (cth. untuk imigrasi, superkategori 'Mengkawal Migrasi' mungkin mempunyai subkategori 'Had Asil' atau 'Pemasangan Sempadan'). Satu cabaran utama untuk klasifikasi klaim automatik adalah nombor besar dan frekuensi rendah bagi subkelas tersebut. Kami mengatasinya dengan meramalkan pasangan super dan subcategori yang sepadan. Kami operasikan idea ini dengan (a) pengekodan keterangan lembut dalam pengklasifikasi tuntutan dan (b) memaksa keterangan keras melalui Perprogram Linear Integer. Eksperimen kami dengan pengklasifikasi tuntutan yang berbeza pada Korpus surat khabar imigrasi Jerman menunjukkan peningkatan prestasi konsisten untuk ramalan bersama, terutama untuk kategori yang jarang dan membincangkan komplementariti kedua-dua pendekatan.", 'mk': 'Анализата на јавните дебати клучно бара класификација на политичките барања според хиерархичните тврдења онтологии (на пример за имиграција, суперкатегоријата „Контролирање на миграцијата“ може да има подкатегории „гранични ограничувања“ или „гранични инсталации“). Голем предизвик за автоматска класификација на барања е големиот број и ниска фреквенција на ваквите подкласи. Ние го решаваме тоа заедно предвидувајќи парови соодветни супер и подкатегории. Ја операционализираме оваа идеја со (a) кодирање на меки ограничувања во класификаторот на тврдењата и (b) наметнување на тешки ограничувања преку Целиот линијарен програмирање. Нашите експерименти со различни класификатори на тврдења на германскиот корпус за имиграциски весници покажуваат константни зголемувања на перформансите за заеднички предвидувања, особено за ретки категории и разговараат за комплементарноста на двата пристапи.', 'ml': "The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory 'Controlling Migration' might have subcategories 'Asylum limit' or 'Border installations').  സ്വയമായി ക്ലാസ്ഫിക്ഷന്\u200d ആവശ്യപ്പെടുന്നതിനുള്ള ഒരു പ്രധാനപ്പെട്ട വ്യാല്\u200dക്കാള്\u200d ഇത്തരം സബ്ക്ലാസിന് സൂപ്പര്\u200d വിഭാഗങ്ങളോടൊപ്പം പ്രവചിക്കുന്ന രണ്ട് ജോലികളെ ഞങ്ങള്\u200d കൂട്ടിച്ചേര്\u200dക്കുന്നു. നമ്മള്\u200d ഈ ഐഡിയയെ പ്രവര്\u200dത്തിപ്പിക്കുന്നു (a) വാദിക്കുന്നതില്\u200d സൌമ്യമായ നിര്\u200dബന്ധങ്ങള്\u200d നിര്\u200dബന്ധമാക്കുന്നു. അതിനാല്\u200d (b) ഇന്\u200dറ ജര്\u200dമ്മന്\u200d കോര്\u200dപ്പുസില്\u200d വ്യത്യസ്ത വിഭാഗങ്ങളുമായി നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കൊണ്ട് നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു സഹപ്രവചനങ്ങള്\u200dക്ക് ഒരുപാട് പ്രകടനം", 'mt': "L-analiżi tad-dibattiti pubbliċi teħtieġ b'mod kruċjali l-klassifikazzjoni tad-domandi politiċi skont l-ontoloġiji tal-pretensjonijiet ġerarkiċi (pereżempju g ħall-immigrazzjoni, superkategorija 'Kontroll tal-Migrazzjoni' jista' jkollha sottokategoriji 'Limitu tal-Asil' jew 'Installazzjonijiet tal-Fruntiera'). Sfida ewlenija għall-klassifikazzjoni awtomatika tat-talbiet hija n-numru kbir u l-frekwenza baxxa ta’ dawn is-sottoklassijiet. Aħna nindirizzawha billi nipprevedixxu b’mod konġunt pari ta’ super- u sottokategoriji li jaqblu. Aħna noperazzjonalizzaw din l-idea billi (a) nikkodifikaw restrizzjonijiet mhux vinkolanti fil-klassifikatur tat-talbiet u (b) jimponu restrizzjonijiet iebsa permezz tal-Programmazzjoni Linjari Integri. L-esperimenti tagħna b’klassifikaturi differenti tal-pretensjonijiet fuq korpus Ġermaniż tal-gazzetta tal-immigrazzjoni juru żidiet konsistenti fil-prestazzjoni għat-tbassir konġunt, b’mod partikolari għall-kategoriji mhux frekwenti u jiddiskutu l-kumplimentarjetà taż-żewġ approċċi.", 'no': 'Analysen av offentlige debatar krev å klassifisera politiske etterspørsmål etter hierarkiske etterspørsmål ontologiar (f.eks. for imigrasjon, kan ein superkategori «Kontrollering av migrasjon» ha underkategoriar «Asylum limit» eller «Border installations»). Ein stor utfordring for automatisk etterspørsel er det store tal og låg frekvensen av slike underklassar. Vi adresserer det ved å forhåndsvisa par av passande super- og underkategoriar. Vi operasjonar denne ideen ved a) koding av måke begrensningar i tiltak- klassifiseringen og b) for å setja vanskeleg begrensningar gjennom heiltal linjerprogram. Våre eksperimenter med forskjellige tiltak-klassifiserar på eit tysk imigrasjonspapirkorpus viser konsistent utviklingar økt for felles forebygging, særskilt for frekvenske kategoriar og diskuterer komplementariteten av dei to tilnærmingane.', 'mn': 'Олон нийтийн ярилцлагын шинжилгээнд үндсэн зүйл нь улс төрийн шаардлагатай асуудлуудын хуваалцах шаардлагатай байдаг (жишээ нь, хөдөлгөөний тулд, супер хэлбэрийн "Контроллер Шүүргээн" гэх супер хэлбэрийн "Асгийн хязгаар" эсвэл "Хязгаар суурь Автоматик хүлээн зөвшөөрөлтийн хуваалтын чухал сорилт нь ийм суурь хичээлийн том, бага тоо. Бид үүнийг супер болон супер-категорийн хоёрыг нийлүүлж таамаглаж байна. Бид энэ санааг (a) кодлох энгийн хязгаарлаар хэрэгжүүлж буй хүлээн авагч болон (b) бүхэл шугамны програмчлалын аргаар хэцүү хязгаарлалт хийдэг. Бидний туршилтууд Германы хөдөлгөөн сонины корпус дээрх өөр өөр хэлбэртэй хүмүүстэй холбогдолтой таамаглалтын үр дүнг нэмэгдүүлж, ялангуяа дараагийн хэлбэрүүдийн хувьд, хоёр ойлголтын нэмэгдүүлэлтийг ярьж байна.', 'pl': 'Analiza debat publicznych zasadniczo wymaga klasyfikacji żądań politycznych według hierarchicznych ontologii roszczeń (np. w przypadku imigracji superkategoria "Kontrolowanie migracji" może mieć podkategorie "Limit azylowy" lub "Instalacje graniczne"). Głównym wyzwaniem dla automatycznej klasyfikacji roszczeń jest duża liczba i niska częstotliwość takich podklas. Rozwiązujemy ją poprzez wspólne przewidywanie par pasujących super- i podkategorii. Operacjonalizujemy tę ideę poprzez (a) kodowanie ograniczeń miękkich w klasyfikatorze roszczeń i (b) nakładanie ograniczeń twardych za pomocą programowania liniowego całkowitego. Nasze eksperymenty z różnymi klasyfikatorami roszczeń na korpusie niemieckiej gazety imigracyjnej pokazują konsekwentny wzrost wyników wspólnych przewidywań, w szczególności dla rzadkich kategorii i omawiają komplementarność tych dwóch podejść.', 'sr': 'Analiza javnih debata je ključno potrebna klasifikacija političkih zahtjeva u skladu s hijerarhijskim ontologijama zahtjeva (npr. za imigraciju, superkategorija "Kontrolirana migracija" može imati podkategorije "granične granice" ili "granične instalacije". Veliki izazov za klasifikaciju automatskih zahteva je veliki broj i niska frekvencija takvih podklasa. Obraèunamo ga zajedno predviðanjem par odgovarajućih super-i podkategorija. Operalizujemo ovu ideju sa a) mekim ograničenjima kodiranja u klasifikatoru zahteva i b) nameštajući teške ograničenja putem kompletnog linijskog programiranja. Naši eksperimenti sa različitim klasifikatorima tvrdnji na nemačkom imigracionom novinskom korpusu pokazuju konsekventno povećanje učinka za zajedničku predviđanje, posebno za naredne kategorije i razgovaraju o komplementarnosti dva pristupa.', 'ro': 'Analiza dezbaterilor publice necesită în mod esențial clasificarea cerințelor politice în funcție de ontologiile ierarhice ale revendicărilor (de exemplu, în cazul imigrației, o supercategorie "Controlul migrației" ar putea avea subcategoriile "Limită de azil" sau "Instalații de frontieră"). O provocare majoră pentru clasificarea automată a cererilor este numărul mare și frecvența scăzută a acestor subclase. O abordăm prin prezicerea împreună a perechilor de super- și subcategorii potrivite. Operaționalizăm această idee prin (a) codificarea constrângerilor soft în clasificatorul de revendicări și (b) impunerea constrângerilor dure prin Programarea Lineară Integer. Experimentele noastre cu diferiți clasificatori de revendicări pe un corpus de ziare germane de imigrație arată creșteri consistente ale performanțelor pentru predicțiile comune, în special pentru categoriile rare și discută complementaritatea celor două abordări.', 'lt': "The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory 'Controlling Migration' might have subcategories 'Asylum limit' or 'Border installations').  A major challenge for automatic claim classification is the large number and low frequency of such subclasses.  Mes jį sprendžiame kartu nuspėjant poras atitinkamų super ir subkategorijų. Įgyvendiname šią idėją: a) koduojant lengvus reikalavimų klasifikatoriaus apribojimus ir b) nustatant griežtus apribojimus per Integruotą linijinę programavimą. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.", 'so': "Baaritaanka debaanka dadweynaha si muhiim ah waxaa loo baahan yahay in loo kala soocayo baahida siyaasadeedka si waafaqsan codsiga hierarkiisa (tusaale ahaan dadka dalka u soo guurey, kooxo ka mid ah 'Xukummada soo guurista' ama xuquuqda xuduudaha '). Takhasuska iskuulladaas ee iskuullada asalka ah waxaa laga yaabaa mid aad u badan iyo aad u yar. Waxaynu ku sheekeynaa si wadajir ah wax u sii sheegno laba nooc oo isku mid ah oo la eg kooxo super- iyo kooxo. Waxaannu ka shaqeynaa fikradan (a) koobnaha kooban ee dhaqdhaqaaq ah oo ku qoran tababarka codsiga iyo (b) xadhig adag oo ku sameynaya qorshaha qoraalka caadiga ah. Imtixaankayada oo ku qoran koorasyada jardiinada dadka dalka u soo guuray oo Jarmal ah waxay muuqataa waxyaabaha la sii kordhiyo sii-socda, khusuusan kooxo ka soo socda iyo kala sheekeysta dhamaanka labada qaabilsan.", 'si': 'සාමාජික විශ්ලේෂණය ගැන විශ්ලේෂණය ක්\u200dරියාත්මක විශ්ලේෂණය සඳහා රජාත්\u200dරික අවශ්\u200dය අවශ්\u200dය අවශ්\u200dය අවශ්\u200dය අවශ්\u200dය අවශ්\u200dය (උදාහරණය සඳහා අම්ම ස්වයංක්\u200dරීය විශේෂණය සඳහා ප්\u200dරධාන ප්\u200dරශ්නයක් තියෙන්නේ මුළු ප්\u200dරශ්නයක් තමයි වගේ ප්\u200dරශ්නයක අපි ඒක සම්බන්ධ විශ්වාස කරන්නේ සුපුර- සහ සබ් විශ්වාස වලට සම්බන්ධ විශ්වාස කරන්න. අපි මේ අදහසට (a) සංකේතනය සීමාවක් සඳහා ක්\u200dරියාත්මක කරනවා ක්\u200dරියාත්මකය සහ (b) සංකේතනය සීමාවක් සඳහා අමාරු සීමාවක් සි අපේ පරීක්ෂණය සමඟ වෙනස් ප්\u200dරශ්නයක් ජර්මාන් වාර්ථාව ප්\u200dරශ්නයක් වලින් ජර්මාන් වාර්ථාව ප්\u200dරශ්නයක් පෙන්වන්න පුළුවන් විශේෂය', 'sv': 'Analysen av offentliga debatter kräver av avgörande betydelse att politiska krav klassificeras enligt hierarkiska anspråkontologier (t.ex. för invandring kan en underkategori "Att kontrollera migrationen" ha underkategorierna "Asylgräns" eller "Gränsanläggningar"). En stor utmaning för automatisk klassificering av fordringar är det stora antalet och låga frekvensen av sådana underklasser. Vi tar itu med det genom att gemensamt förutsäga par matchande super- och underkategorier. Vi operativiserar denna idé genom att (a) koda mjuka begränsningar i claimklassificeraren och (b) införa hårda begränsningar via Integer Linear Programmering. Våra experiment med olika claimklassificerare på en tysk immigrationstidningskorpus visar konsekventa prestandaökningar för gemensam förutsägelse, särskilt för ovanliga kategorier och diskuterar komplementariteten mellan de två tillvägagångssätten.', 'ur': "عمومی بحث کا تحقیق ضروری طور پر سیاسی درخواست کا کلاسپی کرنا ضروری ہے کہ حیراتیکی درخواست کے مطابق (مثال ہجرت کے لئے، ایک سوپر کاٹیو 'کنٹرولینگ ماجرینگ' کے مطابق زیر کاٹیوں 'Asylum limit' یا 'Border installations' کے مطابق ہو سکتا ہے). اٹوٹوٹوٹ ترک کلیسی کے لئے ایک بڑا چال یہ ہے کہ اس طرح کی زیادہ تعداد اور کم فرکانس ہے. ہم اسے مشترک طور پر پیش بینی کرنے کے ذریعہ ایک دوسرے سے بات کریں گے ہم اس ایڈیوں کو (a) اکنوڈینگ نرم محدودیت کے ذریعہ (نرم محدودیت) کے ذریعہ کررہے ہیں اور (b) کلیسائر میں سخت محدودیت رکھتے ہیں۔ ہماری آزمائش ایک جرمانی مہاجرین کاغذ کاغذ پر مختلف فریق کلاسیفوں کے ساتھ مشترک آزمائش کا بڑھا جاتا ہے، مخصوصاً مختلف کلاسیوں کے لئے اور دو طریقوں کی تعداد کے مطابق بحث کرتا ہے.", 'ta': "பொது விவாதத்தின் ஆய்வு முக்கியமாக அரசியல் தேவைகளை வகைப்படுத்த வேண்டும் (உதாரணமாக புறப்பாடுகளுக்கு, மேல் வகுப்பு 'அகத்திற்கான வரம்பு' அல்லது 'எல்லை நிறுவனங்கள்' அல்லத தானியங்கி வகுப்பு வகுப்புக்கான ஒரு மிகப் பெரிய சவால் மேலும் துணை வகுப்புகளுடனும் பொருந்தும் ஜோடிகளையும் ஒன்றாக முன்வாக்கி வைப்போம். நாம் (a) குறியீட்டு மென்னெழுத்து கட்டுப்பாடுகளை செயல்படுத்துகிறோம் கேட்பாடு வகைப்பாட்டில் மற்றும் (b) முதன்மையான வரி ந ஒரு ஜெர்மன் காட்சிக் கார்புஸ் மீது வேறு வகுப்பாளர்களுடன் எங்கள் பரிசோதனைகளை காண்பிக்கிறது சேர்ந்த முடிவு அதிகரிக்கும், குறிப்பாக பின்வரும் வகுப்பு", 'vi': 'Phân tích tranh luận công cộng nghiêm trọng đòi hỏi phân loại các yêu cầu chính trị theo các quy trình xã hội đòi hỏi quy mô (v.d. nhập cảnh, một siêu cấp "Điều khiển di trú" có thể có phân loại "giới hạn nhà tù" hoặc "nhà biên giới". Một thách thức lớn với việc phân loại yêu cầu tự động là số lượng lớn và tần số thấp của các phân loại này. Chúng tôi giải quyết bằng cách dự đoán các cặp siêu và phân loại khớp. Chúng tôi vận hành ý tưởng này b ằng a) mã hóa các giới hạn mềm trong người phân phối yêu cầu và (b) áp đặt các giới hạn cứng nhờ cài đặt tuyến giáp Integer. Những thí nghiệm của chúng tôi với các phân loại yêu cầu khác nhau trên một tập đoàn báo chí nhập cư Đức cho thấy tỉ lệ tăng vọt trong việc dự đoán chung, đặc biệt cho các phân loại hiếm gặp và bàn về sự bổ sung của hai phương pháp.', 'uz': 'Umumiy debatlarni таҳлил қилиш muhim kerak, hierarchik talabatlarni o\'zgarishga (масалан, "Uzorat boshqaruvchisini boshqarish" darajasi yoki "Chegara oʻrnatilishini boshqarish" kabi kategoriga e g a bo\'lishi mumkin). Name Biz buni birlashtirishni super- va sub- guruhga mos keladigan ikkita xil ko\'plarini ko\'rib chiqaramiz. Biz bu g\'oyani (a) davomiy qiluvchi darajadagi soft kodlash usullari bilan ishlatamiz va (b) shaxsiy Line dasturi orqali qisqarli qatlamlarni qo\'yish mumkin. Bizning bir xil tarjimalar davlatlarimiz, Olmon kampudagi qanday tajribalarni ko\'rsatadi, bu ikkita usulning murakkablarini ko\'paytirish uchun bir qanday ishni ko\'rsatadi.', 'da': 'Analysen af offentlige debatter kræver afgørende en klassificering af politiske krav efter hierarkiske krav ontologier (f.eks. for indvandring kan en superkategori"Kontrol med migration"have underkategorier"Asylgrænse"eller"grænseanlæg"). En stor udfordring for automatisk klassificering af skader er det store antal og lave hyppighed af sådanne underklasser. Vi løser det ved i fællesskab at forudsige par af matchende super- og underkategorier. Vi operationealiserer denne idé ved at (a) kode bløde begrænsninger i kravsklassificatoren og (b) pålægge hårde begrænsninger via Integer Linear Programmering. Vores eksperimenter med forskellige klageklassificere på et tysk immigrationsaviskorpus viser konsekvente resultatstigninger for fælles forudsigelser, især for sjældne kategorier, og diskuterer komplementariteten mellem de to tilgange.', 'bg': 'Анализът на обществените дебати изисква категоризирането на политическите искания според йерархичните онтологии на претенциите (напр. за имиграцията, суперкегорията "Контролиране на миграцията" може да има подкатегории "Гранични инсталации"). Основно предизвикателство за автоматичното класифициране на претенции е големият брой и ниската честота на такива подкласове. Ние решаваме това чрез съвместно предсказване на двойки съвпадащи супер и подкатегории. Опционализираме тази идея чрез (а) кодиране на меки ограничения в класификатора на претенции и (б) налагане на твърди ограничения чрез цялостно линейно програмиране. Експериментите ни с различни класификатори на претенции върху германски имиграционен вестник показват последователно увеличение на ефективността при съвместно прогнозиране, особено при редки категории и обсъждат взаимното допълване на двата подхода.', 'nl': "Voor de analyse van publieke debatten is van cruciaal belang dat politieke eisen worden ingedeeld volgens hiërarchische claimontologieën (bijvoorbeeld voor immigratie kan een supercategorie 'Migratie beheersen' subcategorieën 'Asiellimiet' of 'Grensinstallaties') bevatten. Een grote uitdaging voor automatische claimclassificatie is het grote aantal en lage frequentie van dergelijke subklassen. We pakken het aan door gezamenlijk paren van overeenkomende super- en subcategorieën te voorspellen. We operationaliseren dit idee door (a) zachte beperkingen te coderen in de claimclassificator en (b) harde beperkingen op te leggen via Integer Lineair Programmeren. Onze experimenten met verschillende claimclassificatoren op een Duits immigratiekrantencorpus tonen consistente prestatieverhogingen voor gezamenlijke voorspellingen, met name voor zeldzame categorieën en bespreken de complementariteit van de twee benaderingen.", 'hr': "Analiza javnih rasprava ključno zahtijeva klasifikaciju političkih zahtjeva u skladu s hijerarhijskim ontologijama zahtjeva (npr. za imigraciju, superkategorija 'Kontrolirana migracija' može imati podkategorije 'granična ograničenja azila' ili 'granične instalacije'). Veliki izazov za klasifikaciju automatskih zahtjeva je veliki broj i niska frekvencija takvih podklasa. Odgovaramo s tim zajedno predviđanjem par odgovarajućih super-i podkategorija. Operaliziramo ovu ideju mekim ograničenjima kodiranja u klasifikatoru zahtjeva i b) stavljajući teške ograničenja putem kompletnog linijskog programiranja. Naši eksperimenti s različitim klasifikatorima tvrdnji na njemačkom imigracionom novinskom korpusu pokazuju konsekventne povećanje učinkovitosti za zajedničke predviđanje, posebno za sljedeće kategorije i razgovaraju o komplementarnosti dva pristupa.", 'de': 'Die Analyse öffentlicher Debatten erfordert entscheidend die Klassifizierung politischer Forderungen nach hierarchischen Anspruchsontologien (z.B. für Einwanderung könnte eine Superkategorie "Migration kontrollieren" Unterkategorien "Asylgrenze" oder "Grenzanlagen" haben). Eine große Herausforderung für die automatische Schadensklassifizierung ist die große Anzahl und die geringe Häufigkeit solcher Unterklassen. Wir gehen darauf ein, indem wir gemeinsam Paare von passenden Super- und Unterkategorien vorhersagen. Wir operationalisieren diese Idee, indem (a) Soft Constraints im Claim Classifier kodiert und (b) Hard Constraints über Integer Linear Programming eingeführt werden. Unsere Experimente mit verschiedenen Schadenklassifizierern an einem deutschen Zeitungskorpus zeigen konsistente Leistungssteigerungen für gemeinsame Vorhersagen, insbesondere für seltene Kategorien und diskutieren die Komplementarität der beiden Ansätze.', 'sw': "Uchambuzi wa mijadala ya umma unahitaji kutangazwa kwa madai ya kisiasa kwa mujibu wa madai ya uhamiaji (kwa mfano kwa ajili ya uhamiaji, kigezo kikubwa cha 'Kudhibiti Uhamiaji' kinaweza kuwa na makundi makubwa ya 'mpaka wa Asylum' au 'Taasisi za Mipaka'). Changamoto kubwa kwa kudai usafi wa kujitegemea ni idadi kubwa na kiwango cha chini cha darasa hili. Tunaongelea kwa kutabiri pamoja majiwili yanayofanana na makundi makubwa. Tunafanya wazo hili kwa (a) kuandika vizuizi vya soft katika madai ya kutangaza na (b) kuweka vikwazo vigumu kupitia programu ya Ujumbe wa Simu. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.", 'ko': "공공 변론에 대한 분석은 매우 중요하기 때문에 등급 클레임 본체에 따라 정치적 수요를 분류해야 한다(예를 들어 이민에 대해'이민을 통제하는'슈퍼 유형은'비호제한'또는'국경시설'의 하위 유형이 있을 수 있다).자동 클레임 분류의 주요 도전은 이런 종류의 수량이 많고 빈도가 낮다는 것이다.우리는 연합 예측이 일치하는 초유별과 하위 유별을 통해 이 문제를 해결한다.우리는 (a) 클레임 분류기에서 코딩된 소프트 제약과 (b) 정수선형 계획을 통해 하드 제약을 가해서 이 생각을 실현한다.독일 이민신문 어료고에서 서로 다른 클레임 분류기를 사용한 실험에서 연합 예측의 성능이 일치했고 특히 흔치 않은 유형에 대해 이 두 가지 방법의 상호 보완성을 논의했다.", 'fa': "تحلیل بحث عمومی به عنوان ضروری نیاز دارد که فرقه\u200cبندی از درخواست سیاسی بر اساس فرقه\u200cهای تحریک\u200cشناسی (مثال برای مهاجرت، یک فرقه\u200cی supercategory 'کنترل مهاجرت' ممکن است از زیر فرقه\u200cهای 'محدوده\u200cی اسلیم' یا 'دستگاه\u200cهای مرز' داشته باشد). یک چالش بزرگی برای تجارت تجارت خودکار تعداد بزرگ و فرکانس کم از چنین طبقه\u200cهای زیر کلاس است. ما با پیش بینی کردن جفت\u200cهای متفاوت و زیر گروه\u200cهای متفاوت به آن صحبت می\u200cکنیم. ما این ایده را با (a) محدودیت\u200cهای نرم رمزبندی در محدودیت\u200cکننده و (b) محدودیت\u200cهای سخت با طریق برنامه\u200cسازی کلی خط\u200cبندی اجرا می\u200cکنیم. آزمایش\u200cهای ما با گروهی از ادعا مختلف در یک کاغذ روزنامه\u200cهای مهاجرت آلمانی نشان می\u200cدهند که برای پیش\u200cبینی\u200cهای مشترک، مخصوصا برای گروهی\u200cهای غیر\u200cاثر، افزایش عملکرد\u200cهای مشترک، و در مورد تعدادی دو دسترسی بحث می\u200c", 'id': "Analisis debat publik sangat membutuhkan klasifikasi permintaan politik menurut ontologi klaim hierarkis (misalnya untuk imigrasi, superkategori 'Mengontrol Migrasi' mungkin memiliki subkategori 'Hadiran Asil' atau 'Instalasi perbatasan'). A major challenge for automatic claim classification is the large number and low frequency of such subclasses.  We address it by jointly predicting pairs of matching super- and subcategories.  Kita operasikan ide ini dengan (a) pengekodan batas lembut dalam klasifikasi klaim dan (b) memaksa batas keras melalui Programmasi Linar Integer. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.", 'am': "The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory 'Controlling Migration' might have subcategories 'Asylum limit' or 'Border installations').  ለራሱ ክፍል ማቀናቀል ትልቅ ውጤት ነው፡፡ በሙሉ ሁለት ዓይነቶችን እና አጋራቢ እና አዋራቢዎች በመፍጠር እናስጠይቃታለን፡፡ ይህንን አሳብ (a) የሶፍትር ግንኙነት አቋራጭ እና (b) በመጠቀም የኢንተርኔት Linear ፕሮግራም የጭንቅ ግንኙነትን እናደርጋለን፡፡ በጀርመን ስደተኛ የጋርማዊ የጋዜጠኛ ኮፕስስ ላይ በተለየ የግንኙነታችንን ፈተናዎች የሁኔታ ውይይት ለማድረግ ይጨመርላቸዋል፣ በተለዩ ክፍሎች ላይ እና የሁለቱን ደረጃዎች አካባቢነት እና ማነጋገር ነው፡፡", 'tr': "Halkara debatlaryň çözümleriniň çözümleriniň iýerararşik iddialaryna g örä syýasy talaplaryň klasifikasyny gerek däldir (meselâ, göçmek üçin, süper kategoriýa 'Göçme Kontroli' subkategoriýasy 'Asylum hadysy' ýa 'Ters ilatlary'). Otomatik iddialar klasifikasy üçin esasy kynçylyk şöyle subklaslaryň uly sany we düşük sıklygy. Biz muny süper we süper kategoriýalary üçin bir toparlaşyp çaklaýarys. Biz bu ideýi (a) ködleme ýigrençä terjimeler bilen işleýäris ýigrençä terjimeler we (b) gaty Hat Programlamak bilen kyn çöplükler goýýarys. Biziň olarymyz Germaniýanyň göçmenlik gazety korpusynda farklı iddia klasifikatlarymyz bilen birlikde önüşlemek üçin daşary täsirleşen täsirlerimizi görkez we olaryň iki golaýynyň täsirleşligini taryşýarys.", 'hy': "The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory 'Controlling Migration' might have subcategories 'Asylum limit' or 'Border installations').  Ամենամեծ մարտահրավերն է ավտոմատիկ պահանջման դասակարգման համար նման ենթադասարանների մեծ քանակն ու ցածր հաճախականությունը: Մենք դիտարկում ենք այն միասին կանխատեսելով համապատասխանող սուպեր- և ենթախմբերի զույգեր: Մենք գործողություն ենք կատարում այս գաղափարով՝ a) կոդավորելով փափուկ սահմանափակումներ պահանջման դասավորման մեջ և b) պարտադրելով ծանր սահմանափակումներ ամբողջ գծային ծրագրավորման միջոցով: Մեր փորձարկումները գերմանացի միմիգրացիայի թերթերի կորպոսի տարբեր հաղորդակցողների հետ ցույց են տալիս միասին կանխատեսելու արդյունավետության մշտապես աճ, հատկապես հազվադեպ կատեգորիաների համար և քննարկում են երկու մոտե", 'af': "Die analisie van publieke debate wat krysbaar is, benodig die klasifikasie van politieke vrae volgens hierarkies aanvra ontologies (bv. vir imigrasie, 'n superkategorie 'Controlling Migration' dalk mag subkategorie 'Asylum limit' of 'Grens Installerings' hê). 'n Groot uitdrukking vir outomatiese aanvrag klasifikasie is die groot nommer en lae frekwensie van sodanige subklasse. Ons adres dit deur joint voorskou paar van ooreenstemmende super- en subkategories. Ons operatiseer hierdie idee deur (a) enkodering sagte begrense in die aanvrag klassifiseerder en (b) die harde begrense deur heelteger Lineêre Programming in te stel. Ons eksperimente met verskillende aandrukkingsklassifiseerders op 'n Duitse immigrasie koerant korpus wys konsistente uitdrukking verhoog vir joint voorskou, in besonderhede vir onvolledige kategorie en bespreek die komplementariteit van die twee toegang.", 'az': "Halkı müzakirələrin analizi hiyerarşik iddialarına g örə siyasi taleqların klasifikasyonu lazımdır (immigrasyon üçün, süper kategoriya 'Control Migration' apar kategoriyaları 'Asylum limiti' və ya 'Sınır quruluşları'). Avtomatik iddia klasifikasiyasının böyük sayı və düşük sıralarının böyük səbəbi. Biz bunu süper və süper kategoriyaları ilə birlikdə təmin edirik. Biz bu fikirləri (a) kodlama yumuşaq müəyyənləşdirir və (b) b ütün çətin programlama vasitəsilə çətin müəyyənləşdiririk. Bizim təcrübələrimiz Alman imigrasyon kağıdı korpusu ilə müxtəlif təcrübələrimiz birlikdə təcrübə üçün müxtəlif təcrübələr artırır, özlərinə də sıxıntılı kategoriyalar üçün və bu iki tərəflərin tamamlanmasını mübahisə edir.", 'bn': 'জনগণের বিতর্কের বিশ্লেষণের গুরুত্বপূর্ণ বিশ্লেষণের প্রয়োজন হিয়ারার্কিয়ার দাবী অনুসারে রাজনৈতিক দাবীর বিশ্লেষণ (যেমন অভিবাসীদের জন্য, অভিবাসীদের নিয়ন্ত্রণ করা এক সু A major challenge for automatic claim classification is the large number and low frequency of such subclasses.  আমরা সুপার- এবং সাববিগ্রেটগুলোর সাথে যুক্ত জোড়ার সাথে কথা বলি। আমরা (a) দাবীদের ক্লাসিফারের মাধ্যমে সফটক নিয়ম লাভ করার মাধ্যমে এই চিন্তাটি কার্যকর কর করি এবং (b) গুরুত্বপূর্ণ লাইনের প্রোগ্র জার্মান অভিবাসী সংবাদপত্রের উপর বিভিন্ন দাবি বিভিন্ন পরীক্ষাদের সাথে আমাদের পরীক্ষা দেখা যাচ্ছে যৌথ ভবিষ্যতের জন্য যোগাযোগ বৃদ্ধি প্রদর্শন করে, বিশে', 'ca': "L'anàlisi dels debats públics requereix crucialment la classificació de les exigències polítiques segons les ontologies jeràrquiques de reclamacions (per exemple, per a l'immigració, una supercategoria 'Controllar la migració' podria tenir subcategories 'Limite d'asil' o 'Installacions fronteres'). Un repte major per la classificació automàtica de reclamacions és el gran nombre i baixa freqüència d'aquestes subclasses. L'abordem predint conjuntament parelles de super i subcategories. We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming.  Els nostres experiments amb diferents classificadors de reclamacions d'un corpus de diaris d'immigració alemany mostren augments consistents de rendiment per a prediccions conjuntes, en particular per a categories poc freqüents i discuten la complementaritat dels dos enfocaments.", 'sq': "The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory 'Controlling Migration' might have subcategories 'Asylum limit' or 'Border installations').  Një sfidë e madhe për klasifikimin automatik të pretendimeve është numri i madh dhe frekuenca e ulët e nënklasave të tilla. Ne e trajtojmë duke parashikuar së bashku dy super- dhe nënkategori të përshtatshme. We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming.  Eksperimentet tona me klasifikues të ndryshëm të pretendimeve në një korpus të gazetës gjermane të emigracionit tregojnë rritje konsistente të performancës për parashikimet e përbashkëta, veçanërisht për kategori të pakufrekta dhe diskutojnë komplementaritetin e të dy qasjeve.", 'et': 'Avalike arutelude analüüs nõuab oluliselt poliitiliste nõudmiste liigitamist hierarhiliste nõuete ontoloogiate järgi (nt sisserände puhul võib superkategoorial "Rände kontrollimine" olla alamkategooriad "Varjupaigapiir" või "Piirirajatised"). Nõuete automaatse klassifitseerimise peamine probleem on selliste alamklasside suur arv ja madal sagedus. Me tegeleme sellega, ennustades ühiselt sobivate super- ja alamkategooriate paare. Me rakendame seda ideed (a) kodeerides nõuete klassifitseerijas pehmeid piiranguid ja (b) kehtestades rangeid piiranguid täieliku lineaarse programmeerimise kaudu. Meie eksperimendid erinevate nõuete klassifitseerijatega Saksamaa immigratsiooniajalehe korpuses näitavad järjepidevat tulemuslikkuse kasvu ühiste prognooside puhul, eriti harvade kategooriate puhul, ning arutavad kahe lähenemisviisi vastastikust täiendavust.', 'fi': 'Julkisten keskustelujen analysointi edellyttää ratkaisevan tärkeää poliittisten vaatimusten luokittelua hierarkkisten vaateontologioiden mukaan (esimerkiksi maahanmuuton osalta siirtolaisuuden valvonnan superluokassa saattaa olla alaluokkia turvapaikkaraja tai rajalaitokset). Automaattisen korvausluokituksen suuri haaste on tällaisten alaluokkien suuri määrä ja harva esiintymistiheys. Käsittelemme sitä ennustamalla yhdessä yhteensopivien super- ja alaluokkien pareja. Toteutamme tämän ajatuksen (a) koodaamalla pehmeitä rajoituksia väittämien luokittelussa ja (b) asettamalla kovia rajoituksia Integer Linear Programming -ohjelmalla. Kokeemme eri korvausluokittelijoiden kanssa saksalaisessa maahanmuuttosanomalehdessä osoittavat johdonmukaista suorituskykyä yhteisten ennusteiden osalta, erityisesti harvojen luokkien osalta, ja keskustelevat näiden kahden lähestymistavan täydentävyydestä.', 'bs': "Analiza javnih debata je ključno zahtijevala klasifikaciju političkih zahtjeva u skladu s hijerarhijskim ontologijama zahtjeva (npr. za imigraciju, superkategorija 'Kontrolirana migracija' može imati podkategorije 'granična granica' ili 'granične instalacije'). Veliki izazov za klasifikaciju automatskih zahtjeva je veliki broj i niska frekvencija takvih podklasa. Obraćamo se zajedno predviđanjem par odgovarajućih super-i podkategorija. Operaliziramo ovu ideju sa a) mekim ograničenjima kodiranja u klasifikatoru zahtjeva i b) nameštajući teške ograničenja putem kompletnog linijskog programiranja. Naši eksperimenti sa različitim klasifikatorima tvrdnji na njemačkom imigracionom novinskom korpusu pokazuju konsekventno povećanje učinka za zajedničku predviđanje, posebno za sljedeće kategorije i razgovaraju o komplementarnosti dva pristupa.", 'cs': 'Analýza veřejných debat zásadně vyžaduje klasifikaci politických požadavků podle hierarchických deklaračních ontologií (např. pro přistěhovalectví by superkategorie "Řízení migrace" mohla mít podkategorie "Azylový limit" nebo "Pohraniční zařízení"). Hlavní výzvou pro automatickou klasifikaci reklamací je velký počet a nízká frekvence těchto podtříd. Řešíme ji společným predikcí párů odpovídajících super- a podkategorií. Tuto myšlenku operujeme (a) kódováním měkkých omezení v klasifikátoru reklamací a (b) zavedením tvrdých omezení pomocí integer lineárního programování. Naše experimenty s různými klasifikátory reklamací na korpusu německých imigračních novin ukazují konzistentní zvýšení výkonnosti pro společnou predikci, zejména pro vzácné kategorie a diskutují o doplňkovosti obou přístupů.', 'jv': 'Genjer Slackfree Awak dhéwé ngomong nambah Awak dhéwé operasi sistem iki oleh (a) iso nggawe nguasar paten sing dibenalke butine Awak dhéwé éntuk karo perusahaan-perusahaan sing dipulangan karo perusahaan anyar tentang kanggo kalagayan karo perusahaan kuwi, ning ngerasakno kanggo ngerasakno sing gak perusahaan karo perusahaan sing dibutmaci iki.', 'he': "ניתוח הדיונים הציבוריים דורש באופן חיוני את ההקליטה של הדרישות הפוליטיות לפי אונטולוגיות הטענות הייררכיות (למשל עבור ההגירה, לקטגוריה על 'שליטה בהגירה' ייתכן שיש לקטגוריות 'גבול מקלט' או 'התקנות גבולות'). אתגר גדול להקליטת תביעות אוטומטית הוא מספר גדול ותדירות נמוכה של תת-כיסות כאלה. אנו מתייחסים לזה על ידי צפייה משותפת של סופר-תת-קטגוריות מתאימות. אנו מפעילים את הרעיון הזה על ידי (a) קוד מחסומות רכות בקליסדר הטענות ו (b) מכניס מחסומות קשות באמצעות תוכנית לינרית שלמה. הניסויים שלנו עם מסגרי טענות שונים על קורפוס עיתון ההגירה גרמני מראים שיעור ביצועים קבוע לציון משותף, במיוחד לקטגוריות נדירות ולדיון על התלמידיות של שתי הגישות.", 'sk': 'Analiza javnih razprav ključnega pomena zahteva razvrstitev političnih zahtev glede na hierarhične ontologije zahtevkov (npr. za priseljevanje ima superkategorija "Nadzor migracij" lahko podkategorije "Azilna meja" ali "Obrati na mejah"). Glavni izziv za avtomatsko razvrstitev zahtevkov je veliko število in nizka pogostost takih podrazredov. Obravnavamo ga s skupnim napovedovanjem pare ujemajočih super- in podkategorij. To idejo operacionalizaliziramo tako, da (a) kodiramo mehke omejitve v klasifikatorju trditev in (b) uvedemo trde omejitve prek celotnega linearnega programiranja. Naši eksperimenti z različnimi razvrščevalci zahtevkov na nemškem časopisnem korpusu za priseljevanje kažejo dosledno povečanje uspešnosti pri skupnih napovedih, zlasti pri redkih kategorijah, in razpravljajo o dopolnjevanju obeh pristopov.', 'ha': "Ana ƙayyade rabo na jami ya ƙayyade rarrabẽwa g a tambayar siyasa, kamar daidaita taƙaitori (misali, muhimmin da aka yi shige, wani tsohon ¦Controller of Miji' mai yiwuwa ya samu-jama'ar 'Shirin maganardi' ko 'Shirin Hanyar Asyli'). Wani mai girma wa siffarwa farat ɗaya yana da yawan da kuma mafi ƙaranci matsalon wannan. Ina yi matayya da shi gaba-gaba ko biyu masu kami da sauri. Ina amfani da wannan idãnan da (a) kodinga tsari masu nau'i na matsayin da aka ƙayyade fassarar da kuma (b) za'a zartar da tsari masu nauyi a samun Shirin Linje na Intara. Kayan jarrabõyinmu da wasu mãsu kallo na dabam'a kan karatasin jerumani na muhimmi, yana nuna aikin na ƙara wa muhimmin da ake yi wa bashirin gabanin haɗiya, da haske ga jama'a-jama'a, kuma don ka yi musu kamfatanci ga matsayin biyu.", 'bo': "The analysis of public debates crucially requires the classification of political demands according to hierarchical claim ontologies (e.g. for immigration, a supercategory 'Controlling Migration' might have subcategories 'Asylum limit' or 'Border installations'). རང་འགུལ་གྱིས་དམིགས་འཛུགས་ཀྱི་དབྱེ་སྟངས་ལ་ཆེ་བའི་གྲངས ང་ཚོས་འདིར་མཐུན་དང་རྣམ་གྲངས་ཀ་དང་མི་མཐུན་པ་མཚུངས་པའི་སྔོན་ལྟར་བྱེད་ཀྱི་ཡོད། We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming. ང་ཚོའི་བརྟག་ཞིག་གི་དབུགས་སྡུད་པ་ཞིག་དང་མཉམ་དུ་གཏོང་མཁན་གྱི་དབུགས་ཆ་མི་འདྲ་བ་དང་མཉམ་དུ་མཐུན"}
