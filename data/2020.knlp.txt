{'en': 'Social Media Medical Concept Normalization using RoBERTa in Ontology Enriched Text Similarity Framework', 'ar': 'تطبيع المفهوم الطبي لوسائل التواصل الاجتماعي باستخدام RoBERTa في إطار تشابه النص المخصب في علم الوجود', 'es': 'Normalización de conceptos médicos de redes sociales mediante Roberta en el marco de similitud de texto enriquecido con ontología', 'fr': 'Normalisation du concept médical des médias sociaux utilisant Roberta dans le cadre de similarité de texte enrichi en ontologie', 'pt': 'Normalização de conceito médico de mídia social usando RoBERTa na estrutura de similaridade de texto enriquecido de ontologia', 'ja': 'オントロジーのRoBERTaを使用したソーシャルメディア医療概念の正規化豊富なテキスト類似性フレームワーク', 'zh': '社交媒体医学大概规范化,于本体丰文本相似性框架用RoBERTa', 'hi': 'सामाजिक मीडिया चिकित्सा अवधारणा सामान्यीकरण Ontology समृद्ध पाठ समानता फ्रेमवर्क में RoBERTa का उपयोग कर', 'ru': 'Нормализация медицинской концепции в социальных сетях с использованием RoBERTa в системе онтологического сходства с обогащенным текстом', 'ga': 'Meáin Shóisialta Coincheap Leighis Normalú ag baint úsáide as RoBERTa in Ontology Creat Cosúlachta Téacs Saibhrithe', 'ka': 'სოციალური მედიციო მედიციო კონფესტის ნორმალიზაცია რობერტის გამოყენებით Ontology-ში განბეჭირებული ტექსტის განსხვავება', 'hu': 'Közösségi média orvosi koncepció normalizálása RoBERTa használatával az Ontológia Gazdagított szöveghasonlósági keretrendszerben', 'el': 'Κανονικοποίηση Ιατρικής Έννοιας Κοινωνικών Μέσων με χρήση του στο Πλαίσιο Ομοιότητας Κειμένου Εμπλουτισμένου Οντολογίας', 'kk': 'Онтологияда RoBERTa қолданатын социалдық медицина медицина концепциясын нормализациялау', 'it': 'Normalizzazione del concetto medico dei social media utilizzando RoBERTa in Ontology Enriched Text Similarity Framework', 'lt': 'Social Media Medical Concept Normalization using RoBERTa in Ontology Enriched Text Similarity Framework', 'mk': 'Нормализација на медицинските концепти за социјални медиуми со користење на RoBERTa во онтологија богата рамка за сличност на текст', 'ms': 'Normalisasi Konsep Medikal Media Sosial menggunakan RoBERTa dalam kerangka Kesempatan Teks Dikaya Ontologi', 'mt': 'Il-Kunċett Mediku tal-Midja Soċjali Normalizzazzjoni bl-użu ta’ RoBERTa fil-Qafas ta’ Similarità tat-Test Enriched Ontology', 'ml': 'സോഷ്യല്\u200d മെഡിക്കല്\u200d കോണ്\u200dസെപ്റ്റ് നോര്\u200dമിലേഷന്\u200d ഓണ്\u200dടോളോഗിയിലെ റോബെര്\u200dട്ടാവില്\u200d മെഡിക്കല്\u200d ഫ്രെമിക്ക്', 'mn': 'Нийгмийн медицийн эмчилгээний онологид RoBERTa-г ашиглаж баялагдсан Текст тэнцүү хэлбэр', 'pl': 'Normalizacja koncepcji medycznych w mediach społecznościowych z wykorzystaniem RoBERTa w ramach podobieństwa tekstu wzbogaconego w ontologię', 'ro': 'Normalizarea conceptului medical social media folosind RoBERTa in cadrul de similitudine a textului imbogatit de ontologie', 'sr': 'Normalizacija socijalne medijske medicinske koncepcije koristeći RoBERTa u okviru podrazuma obogaćenog teksta', 'no': 'Normalisering av sosiale medisinske konsept ved bruk av RoBERTa i Ontologi', 'so': 'Normalization using RoBERta in Ontology Enriched Text Similarity Framework', 'sv': 'Social Media Medical Concept Normalisering med RoBERTa i Ontology Enriched Text Similarity Framework', 'ta': 'Name', 'ur': 'سوسیل میڈیا مڈیسی ڈیسی نظر عامل کرنا اونتلوژی میں روBERTa کے استعمال کرتا ہے', 'si': 'සාමාජික මධ්\u200dයමාධ්\u200dය මධ්\u200dයමාධ්\u200dයම සාමාන්\u200dයිකරණය', 'uz': 'Name', 'vi': 'Dịch hoá ý tưởng y khoa Phúc theo tác dụng RoBERTa trong khoa ứng phong văn bản Enright Similarity', 'bg': 'Нормализиране на медицинската концепция в социалните медии с помощта на Рамка за обогатена текстова сходство', 'nl': 'Social Media Medical Concept Normalisatie met behulp van RoBERTa in Ontologie Verrijkt Tekst Similarity Framework', 'hr': 'Normalizacija medicinskog koncepta socijalnih medija koristeći RoBERTa u okviru sličnosti obogaćenog teksta', 'da': 'Social Media Medical Concept Normalisering ved hjælp af RoBERTa i Ontology Enriched Text Similarity Framework', 'id': 'Konsep Medis Media Sosial Normalisasi menggunakan RoBERTa dalam Ontologi Enriched Text Similarity Framework', 'ko': '풍부한 텍스트 유사성 프레임워크에서 RoBERTA를 사용한 소셜 미디어 의학 개념 규범화', 'de': 'Social Media Medizinische Konzeptnormalisierung mit RoBERTa im Ontologie Enriched Text Similarity Framework', 'fa': 'مفهوم پزشکی رسانه\u200cهای اجتماعی با استفاده از RoBERTa در چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها', 'sw': 'Udhibiti wa matibabu ya kijamii kwa kutumia RoBERTa katika Ontology', 'af': 'Soziale Media Mediese Koncepsie Normaliseering gebruik RoBERTa in Ontologie Verryk Teks Similariteit Raamwerk', 'sq': 'Normalizimi i konceptit mjekësor të medias sociale duke përdorur RoBERTa në kuadrin e ngjashmërisë së tekstit të pasur në Ontologji', 'tr': 'Social Media Medical Concept Normalization using RoBERTa in Ontology Enriched Text Similarity Framework', 'am': 'ማኅበራዊ ሚዲያ ማህበራዊ መፍሰስ Normalization using RoBERta in Ontology Enriced Text Similarity Framework', 'hy': 'Սոցիալական լրատվամիջոցների բժշկական հասկացությունը Նորմալիզացիա օգտագործելով ՌոBERՏա-ը', 'az': 'Ontologiyada RoBERTa vasit…ôsil…ô Zenginl…ônmi≈ü Metin Similarity Framework', 'bn': 'সামাজিক মিডিয়া মেডিকেল কনসেপ্ট স্বাভাবিকভাবে অনটলোগিতে রোবের্তা ব্যবহার করে স্বাভাবিকভাবে স্থাপন করা হয়', 'ca': 'Normalització del concepte mèdic dels mitjans socials utilitzant RoBERTa en un marc de similitud de text enriquegut en Ontologia', 'bs': 'Normalizacija medicinskog koncepta socijalnih medija koristeći RoBERTu u okviru sličnosti obogaćenog teksta u Ontologiji', 'fi': 'Sosiaalisen median lääketieteellisen konseptin normalisointi RoBERTa:n avulla ontologian rikastetussa tekstikehyksessä', 'cs': 'Normalizace medicínských konceptů s využitím RoBERTa v rámci ontologického rámce obohaceného textu', 'et': 'Sotsiaalmeedia meditsiinilise kontseptsiooni normaliseerimine RoBERTa kasutades ontoloogia rikastatud teksti sarnasuse raamistikus', 'jv': 'Public Media Media Media Media Care Normalizer', 'sk': 'Normalizacija medicinskega koncepta družbenih medijev z RoBERTa v ontologiji obogatenega besedilnega okvira podobnosti', 'he': 'מושג רפואי מדיה חברתית נורמליזציה באמצעות RoBERTa במסגרת דמיון טקסט עשיר באונטולוגיה', 'ha': 'KCharselect unicode block name', 'bo': 'Ontology Enriched Text Similarity Framework ཐོག་ཏུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་མཐུན་གྱི་གནས་སྟངས་མཐུན་རྒྱུན་ལྡན་བཟོ་བ'}
{'en': 'Pattisapu et al. (2020) formulate medical concept normalization (MCN) as text similarity problem and propose a model based on RoBERTa and graph embedding based target concept vectors. However, graph embedding techniques ignore valuable information available in the clinical ontology like concept description and synonyms. In this work, we enhance the model of Pattisapu et al. (2020) with two novel changes. First, we use retrofitted target concept vectors instead of graph embedding based vectors. It is the first work to leverage both concept description and synonyms to represent concepts in the form of retrofitted target concept vectors in text similarity framework based social media MCN. Second, we generate both concept and concept mention vectors with same size which eliminates the need of dense layers to project concept mention vectors into the target concept embedding space. Our model outperforms existing methods with improvements up to 3.75 % on two standard datasets. Further when trained only on mapping lexicon synonyms, our model outperforms existing methods with significant improvements up to 14.61 %. We attribute these significant improvements to the two novel changes introduced.', 'pt': 'Pattisapu et ai. (2020) formulam a normalização de conceito médico (MCN) como problema de similaridade de texto e propõem um modelo baseado em RoBERTa e vetores de conceito alvo baseados em incorporação de grafos. No entanto, técnicas de incorporação de gráficos ignoram informações valiosas disponíveis na ontologia clínica, como descrição de conceitos e sinônimos. Neste trabalho, aprimoramos o modelo de Pattisapu et al. (2020) com duas novas mudanças. Primeiro, usamos vetores de conceito de destino adaptados em vez de vetores baseados em incorporação de gráficos. É o primeiro trabalho a alavancar tanto a descrição do conceito quanto os sinônimos para representar conceitos na forma de vetores de conceito alvo adaptados em uma estrutura de similaridade de texto baseada em mídia social MCN. Em segundo lugar, geramos vetores de conceito e menção de conceito com o mesmo tamanho, o que elimina a necessidade de camadas densas para projetar vetores de menção de conceito no espaço de incorporação de conceito de destino. Nosso modelo supera os métodos existentes com melhorias de até 3,75% em dois conjuntos de dados padrão. Além disso, quando treinado apenas no mapeamento de sinônimos de léxico, nosso modelo supera os métodos existentes com melhorias significativas de até 14,61%. Atribuímos essas melhorias significativas às duas novas mudanças introduzidas.', 'ar': 'باتيسابو وآخرون. (2020) صياغة تطبيع المفهوم الطبي (MCN) كمشكلة تشابه النص واقترح نموذجًا يعتمد على RoBERTa ورسومات تضمين متجهات مفهوم الهدف القائمة على الرسم البياني. ومع ذلك ، فإن تقنيات تضمين الرسم البياني تتجاهل المعلومات القيمة المتوفرة في الأنطولوجيا السريرية مثل وصف المفهوم والمرادفات. في هذا العمل ، نقوم بتحسين نموذج Pattisapu et al. (2020) مع تغييرين جديدين. أولاً ، نستخدم متجهات مفهوم الهدف المعدلة بدلاً من المتجهات القائمة على تضمين الرسم البياني. إنه أول عمل للاستفادة من وصف المفهوم والمرادفات لتمثيل المفاهيم في شكل ناقلات مفهوم الهدف المعدلة في إطار عمل تشابه النص على الشبكات الاجتماعية متعددة القنوات. ثانيًا ، نقوم بإنشاء نواقل ذكر المفهوم والمفهوم بنفس الحجم مما يلغي الحاجة إلى طبقات كثيفة لعرض متجهات ذكر مفهوم المشروع في مساحة تضمين مفهوم الهدف. يتفوق نموذجنا على الأساليب الحالية مع تحسينات تصل إلى 3.75٪ على مجموعتي بيانات قياسيتين. علاوة على ذلك ، عندما يتم تدريبه فقط على تعيين مرادفات المعجم ، يتفوق نموذجنا على الأساليب الحالية مع تحسينات كبيرة تصل إلى 14.61٪. نعزو هذه التحسينات الهامة إلى التغييرين الجديدين اللذين تم إدخالهما.', 'fr': "Pattisapu et al. (2020) formulent la normalisation des concepts médicaux (MCN) comme un problème de similarité de texte et proposent un modèle basé sur Roberta et des vecteurs de concepts cibles basés sur l'intégration de graphes. Cependant, les techniques d'intégration graphique ignorent les informations précieuses disponibles dans l'ontologie clinique, comme la description du concept et les synonymes. Dans ce travail, nous améliorons le modèle de Pattisapu et al. (2020) avec deux nouveaux changements. Tout d'abord, nous utilisons des vecteurs conceptuels de cible ajustés au lieu de vecteurs basés sur l'intégration de graphes. Il s'agit du premier travail à exploiter à la fois la description du concept et les synonymes pour représenter des concepts sous la forme de vecteurs de concepts cibles modernisés dans le MCN de médias sociaux basé sur un cadre de similarité de texte. Ensuite, nous générons des vecteurs de mention de concept et de concept de même taille, ce qui élimine le besoin de couches denses pour projeter des vecteurs de mention de concept dans l'espace d'intégration du concept cible. Notre modèle surpasse les méthodes existantes avec des améliorations allant jusqu'à 3,75\xa0% sur deux ensembles de données standard. De plus, lorsqu'il est formé uniquement à la cartographie des synonymes de lexiques, notre modèle surpasse les méthodes existantes avec des améliorations significatives allant jusqu'à 14,61\xa0%. Nous attribuons ces améliorations significatives aux deux nouveaux changements introduits.", 'es': 'Pattisapu et al. (2020) formulan la normalización de conceptos médicos (MCN) como un problema de similitud de texto y proponen un modelo basado en vectores de concepto objetivo basados en Roberta e incrustación de gráficos. Sin embargo, las técnicas de incrustación de gráficos ignoran información valiosa disponible en la ontología clínica, como la descripción del concepto y los sinónimos. En este trabajo, mejoramos el modelo de Pattisapu et al. (2020) con dos cambios novedosos. En primer lugar, utilizamos vectores de concepto de objetivo adaptados en lugar de vectores basados en incrustación de gráficos. Es el primer trabajo que aprovecha tanto la descripción del concepto como los sinónimos para representar conceptos en forma de vectores de concepto objetivo retroadaptados en el marco de similitud de texto basado en redes sociales MCN. En segundo lugar, generamos vectores de mención de concepto y concepto con el mismo tamaño, lo que elimina la necesidad de capas densas para proyectar vectores de mención de concepto en el espacio de inserción del concepto objetivo. Nuestro modelo supera a los métodos existentes con mejoras de hasta un 3,75% en dos conjuntos de datos estándar. Además, cuando se capacita solo en mapear sinónimos de léxico, nuestro modelo supera a los métodos existentes con mejoras significativas de hasta un 14,61%. Atribuimos estas mejoras significativas a los dos cambios novedosos introducidos.', 'ja': 'Pattisapu et al. (2020)は、医学概念正規化(MCN)をテキスト類似性の問題として定式化し、RoBERTaとグラフ埋め込みに基づくターゲット概念ベクトルに基づくモデルを提案している。 しかし、グラフ埋め込み技術は、概念記述や同義語などの臨床オントロジーで利用可能な貴重な情報を無視します。 本作では、Pattisapu et al .( 2020)のモデルを2つの新規変更で強化している。 まず、グラフ埋め込みベクトルの代わりに改造されたターゲットコンセプトベクトルを使用します。 これは、コンセプト記述と同義語の両方を活用して、テキスト類似性フレームワークベースのソーシャルメディアMCNで改造されたターゲットコンセプトベクターの形式でコンセプトを表現する最初の作品です。 第二に、コンセプトとコンセプトの両方のメンションベクトルを同じサイズで生成します。これにより、コンセプトのメンションベクトルをターゲットコンセプト埋め込み空間に投影するための密度の高いレイヤーの必要性がなくなります。 当社のモデルは、2つの標準データセットで最大3.75%の改善を施し、既存の方法を上回っています。 さらに、マッピング辞書の類義語のみで訓練された場合、当社のモデルは既存の方法よりも優れており、最大14.61 ％の大幅な改善があります。 これらの大幅な改善は、導入された2つの新規の変更に起因すると考えています。', 'zh': 'Pattisapu等(2020)将医学概归一化(MCN)表为文本相似性问,并立一基于RoBERTa、基于图向量。 然图嵌术忽临床本体中可用者信息,如概述同义词。 于此二变增Pattisapu等(2020)之。 先用改进之概向量,非图嵌之向量也。 此二者同义词文本相似性框架社交媒体MCN以变向量名也。 其次,同大小之概与二向量,此去其概向量投于空中之密也。 臣等模形优于今,于两准数集上改进3.75%。 此外,当仅训练于映射词典同义词,模形优于今法,著于高达14.61%。 改此二新归因于。', 'hi': 'Pattisapu et al. (2020) पाठ समानता समस्या के रूप में चिकित्सा अवधारणा सामान्यीकरण (MCN) तैयार करते हैं और RoBERTa और ग्राफ एम्बेडिंग आधारित लक्ष्य अवधारणा वैक्टर पर आधारित एक मॉडल का प्रस्ताव करते हैं। हालांकि, ग्राफ एम्बेडिंग तकनीकें अवधारणा विवरण और पर्यायवाची शब्द ों जैसे नैदानिक आंटोलॉजी में उपलब्ध मूल्यवान जानकारी को अनदेखा करती हैं। इस काम में, हम दो उपन्यास परिवर्तनों के साथ Pattisapu et al. (2020) के मॉडल को बढ़ाते हैं। सबसे पहले, हम ग्राफ एम्बेडिंग आधारित वैक्टर के बजाय रेट्रोफिटेड लक्ष्य अवधारणा वैक्टर का उपयोग करते हैं। यह अवधारणा विवरण और पर्यायवाची दोनों का लाभ उठाने के लिए पहला काम है जो पाठ समानता ढांचे आधारित सोशल मीडिया एमसीएन में रेट्रोफिटेड लक्ष्य अवधारणा वैक्टर के रूप में अवधारणाओं का प्रतिनिधित्व करता है। दूसरा, हम दोनों अवधारणा और अवधारणा एक ही आकार के साथ वेक्टर का उल्लेख करते हैं जो अवधारणा को प्रोजेक्ट करने के लिए घने परतों की आवश्यकता को समाप्त करते हैं, लक्ष्य अवधारणा एम्बेडिंग स्पेस में वैक्टर का उल्लेख करते हैं। हमारा मॉडल दो मानक डेटासेट पर 3.75% तक के सुधार के साथ मौजूदा तरीकों को मात देता है। इसके अलावा जब केवल शब्दकोश पर्यायवाची मैपिंग पर प्रशिक्षित किया जाता है, तो हमारा मॉडल 14.61% तक महत्वपूर्ण सुधार के साथ मौजूदा तरीकों को मात देता है। हम इन महत्वपूर्ण सुधारों को पेश किए गए दो उपन्यास परिवर्तनों के लिए जिम्मेदार ठहराते हैं।', 'ru': 'Pattisapu et al. (2020) формулируют нормализацию медицинской концепции (MCN) как проблему текстового сходства и предлагают модель, основанную на RoBERTa и векторах целевой концепции, основанных на встраивании графиков. Однако методы встраивания графов игнорируют ценную информацию, доступную в клинической онтологии, такую как описание концепции и синонимы. В этой работе мы улучшаем модель Pattisapu et al. (2020) двумя новыми изменениями. Во-первых, мы используем модернизированные целевые векторы концепции вместо векторов на основе встраивания графов. Это первая работа, использующая как описание концепции, так и синонимы для представления концепций в виде модернизированных целевых векторов концепции в текстовой структуре сходства на основе социальных сетей MCN. Во-вторых, мы генерируем как концептуальные, так и концептуальные векторы с одинаковым размером, что исключает необходимость плотных слоев для проецирования концептуальных векторов в целевое концептуальное пространство вложений. Наша модель превосходит существующие методы с улучшениями до 3,75% на двух стандартных наборах данных. Кроме того, при обучении только картированию лексических синонимов наша модель превосходит существующие методы со значительными улучшениями до 14,61%. Мы приписываем эти значительные улучшения двум новым изменениям.', 'ga': 'Bhí Pattisapu et al. (2020) normalú coincheapa leighis (MCN) a fhoirmiú mar fhadhb cosúlachta téacs agus múnla a mholadh bunaithe ar RoBERTa agus veicteoirí sprioc-choincheapa bunaithe ar ghraif a leabú. Mar sin féin, déanann teicnící leabaithe graf neamhaird ar fhaisnéis luachmhar atá ar fáil san onteolaíocht chliniciúil cosúil le cur síos ar choincheap agus comhchiallaigh. San obair seo, cuirimid feabhas ar mhúnla Pattisapu et al. (2020) le dhá athrú úrscéal. Ar an gcéad dul síos, úsáidimid sprioc-veicteora coincheapa iarfheistithe in ionad veicteoirí bunaithe ar ghraif a leabú. Is é an chéad obair í chun cur síos ar choincheap agus comhchiallaigh araon a ghiaráil chun coincheapa a léiriú i bhfoirm veicteoirí sprioc-choincheapa iarfheistithe i gcreat cosúlachta téacs bunaithe ar na meáin shóisialta MCN. Ar an dara dul síos, gineann muid veicteoirí luadh coincheap agus coincheap den mhéid céanna a chuireann deireadh leis an ngá atá le sraitheanna dlúth chun veicteoirí lua coincheap a thionscnamh sa spás neadaithe coincheap sprice. Is fearr lenár samhail na modhanna atá ann cheana féin agus feabhsuithe suas le 3.75% ar dhá thacar sonraí caighdeánacha. Anuas air sin nuair nach bhfuil oiliúint againn ach ar chomhchiallaigh foclóireachta a mhapáil, sáraíonn ár samhail na modhanna atá ann cheana féin le feabhsuithe suntasacha suas le 14.61%. Cuirimid na feabhsuithe suntasacha seo i leith an dá athrú úra a tugadh isteach.', 'el': 'Οι Παττισάπου κ.α. (2020) διατυπώνουν την ομαλοποίηση ιατρικής έννοιας (ως πρόβλημα ομοιότητας κειμένου και προτείνουν ένα μοντέλο βασισμένο σε διανύσματα έννοιας στόχου και γραφής που ενσωματώνουν βασισμένα σε διανύσματα έννοιας στόχου. Ωστόσο, οι τεχνικές ενσωμάτωσης γραφικών αγνοούν πολύτιμες πληροφορίες που είναι διαθέσιμες στην κλινική οντολογία όπως περιγραφή εννοιών και συνώνυμα. Στην εργασία αυτή, ενισχύουμε το μοντέλο του Παττισάπου κ.α. (2020) με δύο νέες αλλαγές. Πρώτον, χρησιμοποιούμε αναδρομικά ενσωματωμένα διανύσματα έννοιας στόχου αντί για διανυσματικά βασισμένα σε γραφήματα. Είναι το πρώτο έργο που αξιοποιεί τόσο την περιγραφή της έννοιας όσο και τα συνώνυμα για να αναπαραστήσει έννοιες με τη μορφή αναδρομέων εννοιών στόχων σε πλαίσιο ομοιότητας κειμένου που βασίζονται στα κοινωνικά μέσα. Δεύτερον, παράγουμε και τα διανύσματα αναφοράς εννοιών και εννοιών με το ίδιο μέγεθος που εξαλείφει την ανάγκη των πυκνών στρωμάτων για να προβάλει τα διανύσματα αναφοράς εννοιών στην έννοια στόχου που ενσωματώνει το διάστημα. Το μοντέλο μας ξεπερνά τις υπάρχουσες μεθόδους με βελτιώσεις μέχρι 3,75% σε δύο τυποποιημένα σύνολα δεδομένων. Επιπλέον, όταν εκπαιδεύεται μόνο στη χαρτογράφηση συνώνυμων λεξικού, το μοντέλο μας ξεπερνά τις υπάρχουσες μεθόδους με σημαντικές βελτιώσεις μέχρι 14.61%. Αποδίδουμε αυτές τις σημαντικές βελτιώσεις στις δύο νέες αλλαγές που εισήχθησαν.', 'hu': 'Pattisapu és társai (2020) megfogalmazzák az orvosi koncepció normalizációját (MCN) mint szöveghasonlósági problémát, és javaslatot tesznek egy RoBERTa és gráf beágyazású célkoncepció vektorok modelljére. A grafikonbeágyazási technikák azonban figyelmen kívül hagyják a klinikai ontológiában rendelkezésre álló értékes információkat, mint például a koncepció leírása és a szinonimák. Ebben a munkában két újszerű változással javítjuk Pattisapu et al. (2020) modelljét. Először is, utólagosan beépített célkoncepció vektorokat használunk a gráf beágyazása alapú vektorok helyett. Ez az első munka, amely mind a koncepció leírását, mind a szinonimákat használja fel, hogy a koncepciókat átalakítsa a cél koncepció vektorok formájában a szöveghasonlósági keretrendszer alapú közösségi média MCN. Másodszor, ugyanolyan méretű koncepciós és koncepciós említési vektorokat generálunk, amelyek kiküszöbölik a sűrű rétegek szükségességét ahhoz, hogy a koncepciós említési vektorokat a célkoncepcióba ágyazó térbe vetítsék. Modellünk két standard adatkészleten akár 3,75%-os fejlesztéssel felülmúlja a meglévő módszereket. Továbbá, ha csak a lexikon szinonimák feltérképezésére képzett modellünk, akár 14,61%-os jelentős fejlesztésekkel felülmúlja a meglévő módszereket. Ezeket a jelentős fejlesztéseket a két új változásnak tulajdonítjuk.', 'ka': 'Pattisapu et al. (2020) ფორმულაცია მედიცინური ნორმალიზაცია (MCN) როგორც ტექსტის განსხვავებული პრობლემის პრობლემის პრობლემის და გრაფის დამატებული მიზეზი კონცექტის გვექტორი მაგრამ, გრაფიკური ინტექნექციის ტექნექციები იგნორიურება მნიშვნელოვანი ინფორმაციას, როგორც კლინიკური ანტოლოგიაში, როგორც კონცექტის ამ სამუშაოში, ჩვენ პოტისო et al. (2020) ორი პრომენტის ცვლილებით მოვიქცევთ. პირველი, ჩვენ გამოყენებთ მიზეზი კონცექტის გვექტორების გარეშე დავყენებული გექტორების გარეშე. ეს არის პირველი სამუშაო, რომელიც კონცექტურის გამოსახულება და სინონიმის გამოსახულება, რომელიც კონცექტურების განსახულება ტექსტის სხვადასხვა ფრამეტში სოციალური მედია MCN მეორე, ჩვენ შევქმნით კონცექტი და კონცექტი განსაზღვრებული გვექტორები იგივე ზომით, რომელიც გამოწყენებს საჭირო სიგრძე პროექტის კონცექტის კონ ჩვენი მოდელი უფრო გავაკეთება მსგავსი მეტოვები, რომელიც 3.75% უფრო მეტია ორი სტანდარტული მონაცემების კონფიგურაციაში. შემდეგ, როდესაც მხოლოდ ლექსიკონის სინონიმების მართებაში შესწავლა, ჩვენი მოდელი გავაკეთება არსებობს მნიშვნელოვანი მეტოვები 14.61%-ზე. ჩვენ ატრიბუტირებთ ეს მნიშვნელოვანი უფლება ორი პრომენტის ცვლილებისთვის.', 'lt': 'Pattisapu et al. (2020) formuluoja medicininės koncepcijos normalizavimą (MCN) kaip teksto panašumo problem ą ir siūlo model į, pagrįstą RoBERTa ir grafiniu būdu įtrauktais tiksliniais koncepcijos vektoriais. Tačiau grafikų įterpimo metodai ignoruoja vertingą klinikinėje ontologijoje turimą informaciją, pavyzdžiui, koncepcijos aprašymą ir sinonimus. Šiame darbe patobuliname Pattisapu ir kt. (2020) model į su dviem naujais pakeitimais. Pirma, mes naudojame naujai pritaikytus tikslinius vektorius užuot įterpę grafinius vektorius. Tai pirmasis darbas, kuriuo siekiama sutelkti sąvokų aprašymą ir sinonimus, kad būtų galima atspindėti sąvokas tikslinių sąvokų vektorių forma teksto panašumo pagrindu grindžiamoje social in ės žiniasklaidos MCN. Antra, mes sukuriame tiek koncepciją, tiek koncepciją, tiek tą patį dydį turinčius vektorius, kurie pašalina tankių sluoksnių poreikį projektuoti koncepciją paminėti vektorius į tikslinę koncepciją įterpiant erdvę. Mūsų modelis viršija esamus metodus, o dviejuose standartiniuose duomenų rinkiniuose – iki 3,75 %. Be to, kai mokoma tik žemėlapizuoti lexikonų sinonimus, mūsų modelis viršija esamus metodus ir gerokai patobulina iki 14,61 proc. Šiuos reikšmingus patobulinimus priskiriame dviem naujiems pakeitimams.', 'kk': 'Pattisapu et al. (2020) медицина концепциясын нормализациялау (MCN) мәтін ұқсас мәселесі ретінде формулизациялау және RoBERTa және графика негіздеген мақсатты концепциялық векторларға негізделген ү Бірақ графикалық ендіру техникалары клиникалық онтологияда қол жеткізетін мәнді мәліметтерді елемейді, яғни концепттің сигномдары мен синонимдері сияқты. Бұл жұмыс ішінде, Патисапу эл. (2020) үлгісін екі романдық өзгерістерімен көтереміз. Біріншіден, графикалық ендіру векторының орнына қайта келтірілген нақты концепция векторларын қолданамыз. Бұл концепциялық сигномдар мен синонимдердің бірінші жұмысын мәтін ұқсас бағдарламасындағы мәтін ұқсас бағдарламалық медиаға негізделген концепциялық векторлардың түрінде қайта қара Екіншіден, біз концепциясы мен концепциясы бір өлшемімен бір векторларды жасап береміз. Бұл векторларды жоба концепциясының қажеттігін жобалау үшін бірдей өлшеміне айналысатын болып Біздің үлгіміз бар әдістерді екі стандартты деректер қорларында 3,75% деп жақсарту арқылы жасайды. Енді тек лексикалық синонимдерді картақтау үшін біздің үлгіміз бар әдістерді 14,61% дегенге көмектеседі. Біз осы үлкен жақсартуларды екі романдық өзгерістеріне қатынаймыз.', 'mk': 'Pattisapu et al. (2020) формулираат медицинска нормализација на концептот (MCN) како проблем со сличноста на текстот и предложуваат модел базиран на RoBERTa и вектори на концепт базиран на график со цел. Сепак, техниките на вградување на графици ги игнорираат вредните информации достапни во клиничката онтологија како опис на концептот и синоними. Во оваа работа го зајакнуваме моделот на Патисапу и други (2020) со две нови промени. Прво, користиме рестрофикувани вектори за концепт на мета наместо вектори базирани на график. Ова е првата работа што се користи и описот на концептот, и синонимите за претставување на концептите во форма на рестрофикувани вектори на концептот на цел во рамките за текст на сличност базирани на социјалните медиуми MCN. Второ, генерираме и концепт и вектори со иста големина кои ја елиминираат потребата од густи слоеви за проект да споменат вектори во концептот на цел кој вклучува простор. Нашиот модел ги надминува постоечките методи со подобрувања до 3,75 отсто на двата стандардни податоци. Понатаму, кога се тренира само за мапирање на лексикони синоними, нашиот модел ги надминува постоечките методи со значителни подобрувања до 14,61 отсто. Ги припишуваме овие значителни подобрувања на двете нови промени што се воведени.', 'ml': 'പാറ്റ്റിസാപ്പു ഒരു അല്\u200d. (2020) മെഡിക്കല്\u200d ആശയം സാധാരണ പ്രശ്നമാക്കുന്നത് ടെക്സ്റ്റ് സമമായ പ്രശ്നമാണ്. റോബെര്\u200dട്ടാവിനെ അടിസ്ഥാനമാക്കിയ മോഡല്\u200d  എങ്കിലും ക്ലിനിക്കല്\u200d നോട്ടോളജിയില്\u200d ലഭ്യമായ വിലയിലുള്ള വിവരങ്ങള്\u200d ഗ്രാഫ് ചെയ്യുന്ന സാങ്കേതികവിവരങ്ങള്\u200d ഉപേ ഈ ജോലിയില്\u200d, നമ്മള്\u200d പാറ്റ്റിസാപുവിന്റെ മോഡല്\u200d അല്\u200d. (2020) രണ്ട് നോവല്\u200d മാറ്റങ്ങള്\u200d കൊണ്ട് വരുന്നു. ആദ്യം, നമ്മള്\u200d ഗ്രാഫിന്റെ അടിസ്ഥാനത്തിലുള്ള വെക്റ്ററുകള്\u200dക്ക് പകരം തിരിച്ചറിയിക്കപ്പെട്ട ലക്ഷ്യം വ ആദ്യത്തെ പ്രവര്\u200dത്തനമാണ് ആദ്യത്തെ പ്രവര്\u200dത്തിപ്പിക്കുന്നത്, ആശയവിശദീകരണവും സിനോണിമുകളും പ്രതിനിധിക്കുന്നത്. ആദ്യത്തെ പ്രവര്\u200dത്തിക്കുന് രണ്ടാമതായി, നമ്മള്\u200d ഒരേ വലിപ്പത്തോടൊപ്പം ആഗ്രഹിക്കുന്ന ആശയവും ആഗ്രഹിക്കുന്ന വെക്റ്ററുകളും സൃഷ്ടിക്കുന്നു. അത് പ്രോജക്ടിന്റെ ആവശ്യം  നമ്മുടെ മോഡല്\u200d നിലവിലുള്ള രീതികള്\u200d മുന്\u200dകൂട്ടുന്നത് 3.75% മുന്\u200dകൂട്ടുന്നതാണ്. രണ്ട് സാധാരണ ഡാറ്റാസറ് Further when trained only on mapping lexicon synonyms, our model outperforms existing methods with significant improvements up to 14.61%.  ഈ പ്രധാനപ്പെട്ട മെച്ചപ്പെടുത്തിയ രണ്ട് നോവലിന്റെ മാറ്റങ്ങള്\u200dക്ക് നമ്മള്\u200d വ്യക്തമാക്കുന', 'it': "Pattisapu et al. (2020) formulano la normalizzazione del concetto medico (MCN) come problema di somiglianza del testo e propongono un modello basato su RoBERTa e vettoriali di concetto target basati sull'incorporazione del grafico. Tuttavia, le tecniche di incorporazione dei grafici ignorano le informazioni preziose disponibili nell'ontologia clinica come la descrizione del concetto e i sinonimi. In questo lavoro, valorizziamo il modello di Pattisapu et al. (2020) con due novità. In primo luogo, usiamo vettori concettuali retromontati invece di vettori basati sull'incorporazione di grafici. È il primo lavoro a sfruttare sia la descrizione del concetto che i sinonimi per rappresentare i concetti sotto forma di vettori di concetto target retrofit nei social media MCN basati su framework di somiglianza testuale. In secondo luogo, generiamo vettori di menzione concettuale e concettuale con la stessa dimensione che elimina la necessità di strati densi per proiettare vettori di menzione concettuale nel concetto di destinazione incorporando lo spazio. Il nostro modello supera i metodi esistenti con miglioramenti fino al 3,75% su due set di dati standard. Inoltre, se addestrato solo sulla mappatura dei sinonimi lessicali, il nostro modello supera i metodi esistenti con miglioramenti significativi fino al 14,61%. Attribuiamo questi significativi miglioramenti ai due nuovi cambiamenti introdotti.", 'ms': 'Pattisapu et al. (2020) membentuk normalisasi konsep perubatan (MCN) sebagai masalah persamaan teks dan melamar model berdasarkan vektor konsep berasaskan graf dan RoBERTa. Namun, teknik penyampaian graf mengabaikan maklumat berharga yang tersedia dalam ontologi klinik seperti keterangan konsep dan sinonims. Dalam kerja ini, kami meningkatkan model Pattisapu et al. (2020) dengan dua perubahan novel. Pertama, kita gunakan vektor konsep sasaran yang dipasang semula selain dari vektor yang dipasang graf. Ia adalah kerja pertama untuk menggunakan kedua-dua keterangan konsep dan sinonim untuk mewakili konsep dalam bentuk vektor konsep sasaran yang dipasang semula dalam kerangka kesamaan teks media sosial berdasarkan MCN. Kedua, kita menghasilkan kedua-dua konsep dan konsep menyebut vektor dengan saiz yang sama yang menghapuskan keperluan lapisan tebal untuk projek konsep menyebut vektor ke ruang penyembedding konsep sasaran. Model kami melampaui kaedah sedia ada dengan peningkatan sehingga 3.75% pada dua set data piawai. Lebih lanjut bila dilatih hanya pada pemetaan sinonim leksikon, model kita melampaui cara yang wujud dengan peningkatan yang signifikan sehingga 14.61%. Kami atribut perbaikan yang signifikan ini kepada dua perubahan novel yang diperkenalkan.', 'pl': 'Pattisapu et al. (2020) sformułują normalizację koncepcji medycznej (MCN) jako problem podobieństwa tekstowego i proponują model oparty na RoBERTa oraz wektorach koncepcji docelowych osadzających wykres. Jednak techniki osadzania wykresów ignorują cenne informacje dostępne w ontologii klinicznej, takie jak opis koncepcji i synonimy. W niniejszej pracy wzbogacamy model Pattisapu et al. (2020) o dwie nowe zmiany. Po pierwsze, używamy zmodernizowanych wektorów koncepcji docelowej zamiast wektorów opartych na osadzeniu wykresu. Jest to pierwsza praca, która wykorzystuje zarówno opis koncepcji, jak i synonimy do reprezentowania koncepcji w postaci doposażonych wektorów koncepcji docelowych w ramach podobieństwa tekstowego MCN w mediach społecznościowych. Po drugie, generujemy zarówno wektory wspomnień koncepcyjnych, jak i koncepcyjnych o tym samym rozmiarze, co eliminuje potrzebę gęstych warstw do projektowania wektorów wspomnień koncepcyjnych do koncepcji docelowej osadzającej przestrzeń. Nasz model przewyższa istniejące metody dzięki ulepszeniom do 3,75% na dwóch standardowych zbiorach danych. Ponadto, gdy nasz model jest przeszkolony tylko w zakresie mapowania synonimów leksykonu, przewyższa istniejące metody z znaczącymi ulepszeniami do 14,61%. Te znaczące ulepszenia przypisujemy dwóm wprowadzonym nowatorskim zmianom.', 'mn': 'Pattisapu et al. (2020) медицины ойлголт нормализацийг текст төстэй асуудал гэж тодорхойлж, RoBERTa болон график дээр суурилсан загварын загварын векторуудыг санал болгодог. Гэхдээ график солилцох технологиуд клиникийн онтологид хэрэглэгддэг үнэ цэнэтэй мэдээллийг тодорхойлох боломжтой тодорхойлолт болон синонимууд шиг анзаарахгүй байдаг. Энэ ажил дээр бид Патисапу et al. (2020) хоёр шинэ өөрчлөлтийг нэмэгдүүлнэ. Эхлээд, бид график дээр суурилсан векторуудын оронд шинэ загварын концепцийн векторуудыг ашиглаж байна. Энэ нь ойлголтын тодорхойлолт болон синонимуудыг харуулах анхны ажил юм. Энэ нь текст төстэй хэлбэрээр харьцуулагдсан зорилготой тодорхойлолтын векторуудын хэлбэрээр илэрхийлэх зорилго юм. Хоёр дахь, бид ойлголт болон ойлголт нь векторуудыг адилхан хэмжээтэй бий болгодог. Энэ нь тодорхойлолтын тулд жинхэнэ давхаруудын хэрэгцээг төсөөлөх болно. Бидний загвар нь хоёр стандарт өгөгдлийн санд 3.75% хүртэл суурилсан арга загварыг дамжуулдаг. Үүний дараа нь зөвхөн зураг зураг зураг дээр сургалтын тулд бидний загвар нь 14.61% хүртэл сургалтын арга загвараас илүү сайжруулдаг. Бид эдгээр чухал сайжруулалтыг хоёр шинэ өөрчлөлтийг харуулж байна.', 'mt': 'Pattisapu et al. (2020) jifformulaw in-normalizzazzjoni tal-kunċett mediku (MCN) bħal a problema ta’ similarità tat-test u jipproponu mudell ibbażat fuq RoBERTa u vetturi tal-kunċett fil-mira bbażati fuq l-inkorporazzjoni tal-graff. Madankollu, it-tekniki ta’ inkorporazzjoni tal-grafika jinjoraw l-informazzjoni ta’ valur disponibbli fl-ontoloġija klinika bħad-deskrizzjoni tal-kunċett u s-sinonimi. F’dan ix-xogħol, aħna ntejbu l-mudell ta’ Pattisapu et al. (2020) b’żewġ bidliet ġodda. First, we use retrofitted target concept vectors instead of graph embedding based vectors.  Hija l-ewwel ħidma li tħaddem kemm id-deskrizzjoni tal-kunċett kif ukoll is-sinonimi biex tirrappreżenta kunċetti fil-forma ta’ vetturi tal-kunċett fil-mira retrofitted fil-qafas ta’ similarità tat-test ibbażat fuq il-midja soċjali MCN. It-tieni nett, niġġeneraw kemm il-kunċett kif ukoll il-kunċett jissemma l-vetturi bl-istess daqs li jeliminaw il-ħtieġa ta’ saffi densi biex il-kunċett jissemma l-vetturi fil-kunċett immirat li jinkorpora l-ispazju. Il-mudell tagħna jipproduċi metodi eżistenti b’titjib sa 3.75% fuq żewġ settijiet ta’ dejta standard. Barra minn hekk, meta mħarreġ biss fuq l-immappjar tas-sinonimi tal-lexicons, il-mudell tagħna jaqbeż il-metodi eżistenti b’titjib sinifikanti sa 14.61%. Aħna nappribwixxu dan it-titjib sinifikanti liż-żewġ bidliet ġodda introdotti.', 'sr': 'Pattisapu et al. (2020) formuliše normalizaciju medicinskog koncepta (MCN) kao problem sličnosti teksta i predlažem model baziran na RoBERTi i grafiku koji uključuju vektore ciljnog koncepta. Međutim, tehnike ugrađenja grafika ignorišu dostupne vrijedne informacije u kliničkoj ontologiji poput opisa koncepta i sinonima. U ovom poslu, poboljšavamo model Pattisapu et al. (2020) sa dve novelne promjene. Prvo, koristimo retroficirane vektore ciljnog koncepta umjesto ugrađenog vektora na grafiku. To je prvi rad koji utiče na opis koncepta i sinonima koji predstavljaju koncept u obliku retroficiranih vektora ciljnog koncepta u okviru tekstualne sličnosti baziranog socijalnog medija MCN. Drugo, stvaramo i koncept i koncept spominjajući vektore sa istom veličinom koji eliminiše potrebu gustih slojeva za projektiranje koncepta spominjajući vektore u ciljni koncept uključujući prostor. Naš model iznosi postojeće metode sa poboljšanjem do 3,75% na dva standardna seta podataka. Dalje, kada je obučeno samo na mapiranju leksičkih sinonima, naš model iznosi postojeće metode sa značajnim poboljšanjem do 14,61%. Pripisujemo te značajne poboljšanje dve novelne promjene.', 'no': 'Pattisapu et al. (2020) formerer medisinsk konseptnormalisering (MCN) som problem med tekstsimilaritet og foreslår eit modell basert på RoBERTa og grafen som innebygger baserte målkonseptvektorar. Dette er imidlertid å ignorera verdileg informasjon som er tilgjengeleg i klinisk ontologi som konseptskildring og synonym. I denne arbeiden forbedrar vi modellen av Pattisapu et al. (2020) med to romanske endringar. Først bruker vi gjenopprette målkonseptvektorar i staden for innbygging av grafen baserte vektorar. Det er det første arbeidet som skal levera både konseptskildring og synonym for å representera konseptar i form av gjenopprette målkonseptvektorar i tekstsamsvar-rammeverket basert på sosiale media MCN. For det andre, lager vi både konsept og konsept med same storleik som eliminerer nødvendighet for tette lag for å gjera vektorar som mener vektorar i målkomponenten som innebygger mellomrom. Modellen vårt utfører eksisterande metodar med forbetringar opp til 3,75% på to standardsetar. Førre når det berre trengte på kartleggingssynonymar for leksikon, vil modellen vårt utføra eksisterande metodar med betydelige forbetringar opp til 14,61%. Vi attriburer desse signifikante forbedringane til dei to novele endringane som er introduserte.', 'ro': 'Pattisapu et al. (2020) formulează normalizarea conceptului medical (MCN) ca problemă de similitudine a textului și propun un model bazat pe RoBERTa și vectorii conceptului țintă bazat pe încorporarea graficului. Cu toate acestea, tehnicile de încorporare a graficului ignoră informațiile valoroase disponibile în ontologia clinică, cum ar fi descrierea conceptului și sinonimele. În această lucrare, îmbunătățim modelul Pattisapu et al. (2020) cu două schimbări noi. În primul rând, folosim vectorii conceptului de țintă modernizați în loc de vectorii bazați pe încorporarea graficului. Este prima lucrare care valorifică atât descrierea conceptului, cât și sinonimele pentru a reprezenta concepte sub forma vectorilor conceptului țintă modernizat în cadrul de analiză a textului MCN. În al doilea rând, generăm atât vectori de mențiune conceptuală, cât și vectori de concepție cu aceeași dimensiune, ceea ce elimină nevoia straturilor dense pentru a proiecta vectori de mențiune conceptuală în conceptul țintă care încorporează spațiul. Modelul nostru depășește metodele existente cu îmbunătățiri de până la 3,75% pe două seturi de date standard. Mai mult, atunci când este instruit doar pe cartografierea sinonimelor lexiconice, modelul nostru depășește metodele existente, cu îmbunătățiri semnificative de până la 14,61%. Atribuim aceste îmbunătățiri semnificative celor două modificări noi introduse.', 'si': 'Pattispu et al. (2020යි) වෛද්\u200dය සාමාන්\u200dය සංවේදනය (MCN) පාළ සමාන්\u200dය ප්\u200dරශ්නයක් විදියට පරීක්ෂණය සහ RoBERTa සහ ග්\u200dරාෆ් සංවේදනය සඳහා  නමුත්, ග්\u200dරාෆ් ඇම්බෙන්ඩ් තාක්ෂිකාවක් අවශ්\u200dය තොරතුරු අවශ්\u200dය තොරතුරු අවශ්\u200dය විස්තරාවක් සහ සම මේ වැඩේ අපි පැටිසාපූ එට් අල් වලින් ප්\u200dරමාණය වැඩ කරනවා. මුලින්ම, අපි ආපහු ලේඛනය වෙක්ටර්ව ප්\u200dරයෝජනය කරන්න පුළුවන් වෙක්ටර් වලට ග්\u200dරාෆ් අධාරිත ඒක තමයි පලවෙනි වැඩක් විදිහට සාමාජික මිඩියාව අධාරිත සාමාජික වීක්ටර් වල ප්\u200dරතිනිශ්චා කරන්න පුළුවන් වැඩක්. දෙවෙනියි, අපි පරීක්ෂණය සහ පරීක්ෂණය සමග වෙක්ටර් එකම ප්\u200dරමාණයෙන් නිර්මාණය කරනවා, ඒකෙන් වෙක්ටර් කිරීමට පරීක්ෂණය ස අපේ මොඩල් ප්\u200dරමාණයක් තියෙන විදිහට ප්\u200dරමාණයක් තියෙන්නේ ප්\u200dරමාණය දත්ත සැට් දෙකට 3.75% වැඩි විදි ඉතින් ලෙක්සිකෝන් සිනෝනිම් සැලසුම් විතරයි ප්\u200dරශ්නයක් විතරයි, අපේ මොඩල් ඉතින් විදිහට ප්\u200dරශ්නයක් විත අපි මේ විශේෂ ප්\u200dරවෘත්තියක් ප්\u200dරවෘත්ති කරනවා නියම වෙනස් දෙකට.', 'ta': 'பாட்டிசாபு மற்றும் அல்( 2020) மருத்துவ கருத்து இயல்பாக்கம் (MCN) உரை சமமான பிரச்சனையாக உருவாக்கி மற்றும் ரோபிர்டாவை அடிப்படையில் உள்ளிடும் வரைபடம ஆயினும், வரைபடம் உள்ளிடும் தொழில்நுட்பத்தில் மதிப்புள்ள தகவல் புறக்கணி இந்த வேலையில் நாம் பாட்டிசாபு மற்றும் அல் மாதிரியை மேம்படுத்துகிறோம். 2020) இரண்டு புதிய மாற்றங்கள் உடன முதலில், நாம் மீண்டும் பெற்ற இலக்கு கருத்து நெறிகளை பயன்படுத்துகிறோம் வரைபடத்தின் அடிப்படையில் உள்ள வெக் மீண்டும் பெற்றுக் கொண்ட இலக்கு கருத்து நெறிகளை உரையில் ஒத்திசைப்படுத்தும் சட்டத்தில் சார்ந்த சமூக ஊடகங்களை அடிப்படையில் உள்ள உரை இரண்டாவது, நாம் கருத்து மற்றும் கருத்து வெக்டார்களை உருவாக்குகிறோம் அதே அளவுடன் அது திட்டத்தின் குறிப்பு நெறிகளை குறிப்பிடும் இடம் உள்ள எங்கள் மாதிரி இருக்கும் முறைமைகளை முன்னேற்றும் 3.75% முறையாக முடிக்கிறது இரண்டு நிலையான தரவு அமைப்பு Further when trained only on mapping lexicon synonyms, our model outperforms existing methods with significant improvements up to 14.61%.  நாம் இந்த முக்கியமான முன்னேற்றங்களை குறிப்பிடுகிறோம் என்று அறிவிக்கப்பட்ட இரண்டு புதிய மா', 'ur': 'Pattisapu et al. (۲۰۰۲) پزشکی تفصیل عاملی (MCN) کو تفصیل سیدھی مسئلہ کے طور پر فرمول کرتا ہے اور روBERTa اور گراف پر بنیاد رکھتا ہے موقع تفصیل ویکتوروں پر ایک مدل پیشنهاد کرتا ہے۔ However, graph embedding techniques ignore valuable information available in the clinical ontology like concept description and synonyms. اس کام میں ہم پٹیسپو اور ال کی مدل کو بڑھاتے ہیں۔ پہلے، ہم نے گراف بنے ہوئے ویکتروں کے بدلے دوبارہ ٹیلٹ کامپیوتر ویکتروں کو استعمال کیا۔ یہ سب سے پہلے کام ہے جو تفصیل کی توصیف اور سینونیم کو متوجہ کرنے کے لئے تفصیل کی تصویر کی شکل میں متوجہ ہوئی موقعیت ویکتوروں کی تصویر کرنے کے لئے متوجہ ہوئی ہے۔ دوسرا، ہم دونوں منظور اور منظور ویکتروں کو ایک ہی اندازہ کے ساتھ جوڑ دیتے ہیں جو گہرے لہروں کی ضرورت کو ٹوٹ دیتے ہیں کہ پروژه کی منظور ویکتروں کا ذکر کرنا موقع کی منظور جگہ میں داخل ہونے کے لئے۔ ہمارا موڈل دو استاندارڈیٹ سٹ پر 3.75% تک سیدھی ترکیب کے مطابق موجود طریقے سے کام لیتا ہے۔ اس کے بعد جب صرف لکسیون سینونیم کے مطالعہ میں آموزش کی جاتی ہے، ہماری مدل موجود طریقوں سے 14.61% تک بڑھ جاتی ہے۔ ہم ان بڑے اچھے تغییرات کو دو روانوی تغییروں کے ذریعہ تغییر دیتے ہیں۔', 'sv': 'Pattisapu et al. (2020) formulerar medicinsk konceptnormalisering (MCN) som textlikhetsproblem och föreslår en modell baserad på RoBERTa och grafinbäddning baserade målkonceptvektorer. Grafinbäddningstekniker ignorerar dock värdefull information som finns tillgänglig i klinisk ontologi såsom begreppsbeskrivning och synonymer. I detta arbete förstärker vi modellen av Pattisapu m.fl. (2020) med två nya förändringar. Först använder vi eftermonterade målkonceptvektorer istället för grafinbäddningsbaserade vektorer. Det är det första arbetet att utnyttja både konceptbeskrivning och synonymer för att representera koncept i form av eftermonterade målkonceptvektorer i textliknande rambaserade sociala medier MCN. För det andra genererar vi både koncept- och konceptomnämningsvektorer med samma storlek vilket eliminerar behovet av täta lager för att projicera konceptomnämningsvektorer i målkonceptet som bäddar in utrymme. Vår modell överträffar befintliga metoder med förbättringar på upp till 3,75% på två standarddatauppsättningar. När vår modell endast tränas i kartläggning av lexikonsynonymer överträffar vi befintliga metoder med betydande förbättringar upp till 14,61%. Vi tillskriver dessa betydande förbättringar till de två nya förändringar som införts.', 'so': 'Pattisapu et al. (2020) wuxuu u sameeyaa habab caafimaad ah (MCN) sida dhibaato u eg matxaf oo isku mid ah, wuxuuna soo jeedaa model ku saleysan RoBERTA iyo qoraal ku saleysan vectoro dhanka goalka ku saleysan. Si kastaba ha ahaatee dhakhtarka ku qoran karta ayaa ka jeeda macluumaadka qiimaha ah ee lagu helaa dhakhtarka caafimaadka sida sawirida iyo sawirada fikrada. In this work, we enhance the model of Pattisapu et al. (2020) with two novel changes.  Marka ugu horeysa waxaynu isticmaalnaa wadooyin qaababka goalka ah oo aan ka bedelnaynno wadooyin ku saleysan karta. Waa shuqulka ugu horeeya in la soo wareejiyo sawirida fikrada iyo isku mid ah, in loo sameeyo fikrada oo u eg qaababka waddooyinka hagitaanka ee loo soo celiyey qoraalka qoraalka oo isku mid ah MCN. Second, waxaynu abuurnaa fikrada iyo fikrada aan ku sheegno wadooyin isku mid ah, kaas oo dhameystiraya baahida qasnadaha hoose si ay uga sheego vectoriyada ku qoran dhanka waxyaabaha lagu galo. Tusaalkayaga ayaa soo saara qaabab joogta ah oo korodhsan 3.75% ku qoran labada sawirada standard. Sidoo kale marka lagu tababariyey kartooyinka lexicon oo kaliya, modelkayagu wuxuu soo saaraa qaababka joogta ah oo aad u beddelan ilaa 14,61 boqolkiiba. Waxaannu hagaajinnaa labada beddelka ee warqada ah ee la soo bandhigay.', 'uz': "Name Ammo, grafik ichki teknologiya taʼminlovchi va synonym kabi klinikal ontologiyasidagi qiymati maʼlumotini eʼtibor berilmadi. In this work, we enhance the model of Pattisapu et al. (2020) with two novel changes.  Birinchisi, biz tegi asosiy vektoriga kiritilgan grafikni oʻrniga qayta olib tashlanamiz. Name Ikkinchi so'zda, biz bir xil va concept va o'zgartirish vectorlarini bir oʻlchami bilan yaratib, bu loyihani hisoblash uchun qismi qatlamning muhimligini olib tashlash mumkin. Bizning modelimiz mavjud usullarni 3.75% dan 2 standard maʼlumot etishda bajaradi. Koʻrsatganda faqat Lekson synonymetrlarida o'rganishda, modelmiz mavjud usullarni 14.61%gakatta yaxshi o'zgartiradi. Biz bu ikki novel o'zgarishlariga muhim yaxshi o'zgarishni anglatamiz.", 'vi': 'Một loại một loại một loại một loại một loài một của một quỷ bị thưởng y giách y khoa (MCN) như vấn đề của một loài một cái mộ tương đột vị của chế bị thố Tuy nhiên, các kỹ thuật lắp đồ thị bỏ qua những thông tin có giá trị trong môn khảo cổ lâm sàng như mô tả khái niệm và từ đồng. Trong công việc này, chúng tôi nâng cao mô hình của Patti et al. (2020) với hai thay đổi mới. Đầu tiên, chúng tôi dùng véc- tơ đích được sửa lỗi thay cho véc- tơ dựa vào đồ thị. It is the first work to handling both khái niệm description and synonyns to đại diện hai Khái mi in the retopened cateưa cầu vectors in text tương tự Vừa based social media MCN. Thứ hai, chúng tôi tạo ra cả các véc- tơ tên và khái niệm có cùng kích thước loại bỏ sự cần thiết của lớp dày để dự đoán các sinh vật có thể được nhắc đến với các môi trường định hình đích. Phần mềm của chúng ta hoàn thiện các phương pháp tồn tại với cải tiến lên đến 3.75. trên hai nhà dữ liệu tiêu chuẩn. Hơn nữa khi được huấn luyện chỉ để vẽ bản đồ từ điển đồng, mẫu của chúng ta thực hiện các phương pháp tồn tại với cải tiến đáng kể đến 14.61=. Chúng tôi quy định những cải tiến đáng kể này cho hai thay đổi mới.', 'bg': 'Патисапу и др. (2020) формулират нормализиране на медицинската концепция като проблем за сходство на текста и предлагат модел, базиран на вектори на целевата концепция, базирани на вграждане на графики. Въпреки това, техниките за вграждане на графики игнорират ценната информация, налична в клиничната онтология, като описание на концепцията и синоними. В тази работа подобряваме модела на Патисапу и др. (2020) с две нови промени. Първо, ние използваме модернизирани целеви концепции вектори вместо вграждане на графични вектори. Това е първата работа, която използва както описанието на концепцията, така и синонимите за представяне на концепции под формата на модернизирани целеви понятия вектори в рамка за сходство на текста базирани социални медии. Второ, генерираме както концептуални, така и концептуални вектори със същия размер, което елиминира необходимостта от плътни слоеве за проектиране на концептуални вектори за споменаване в целевата концепция, вграждаща пространството. Нашият модел надминава съществуващите методи с подобрения до 3,75% на два стандартни набора данни. Освен това, когато се обучава само за картографиране на синонимите на лексикона, нашият модел надминава съществуващите методи със значителни подобрения до 14.61%. Приписваме тези значителни подобрения на двете внесени нови промени.', 'hr': 'Pattisapu et al. (2020) formuliraju normalizaciju medicinskog koncepta (MCN) kao problem sličnosti teksta i predlažu model bazirani na RoBERTi i grafiku koji uključuju vektore ciljnog koncepta. Međutim, tehnike ugrađenja grafika ignoriraju dostupne vrijedne informacije u kliničkoj ontologiji poput opisa koncepta i sinonima. U ovom poslu, poboljšavamo model Pattisapu et al. (2020) s dvije novelne promjene. Prvo koristimo retroficirane vektore ciljnog koncepta umjesto ugrađenih vektora na grafiku. To je prvi rad koji će primjenjivati opis koncepta i sinonima kako bi predstavljali koncept u obliku retroficiranih vektora ciljnog koncepta u okviru sličnosti teksta temeljenom na društvenim medijima MCN. Drugo, stvaramo i koncept i koncept spominjanje vektora sa istom veličinom koji eliminira potrebu gustih slojeva za projektiranje koncepta spominjanja vektora u ciljni koncept uključujući prostor. Naš model iznosi postojeće metode s poboljšanjem do 3,75% na dva standardna seta podataka. Nadalje, kad je obučeno samo na mapiranju leksičkih sinonima, naš model iznosi postojeće metode sa značajnim poboljšanjem do 14,61%. Pripisujemo te značajne poboljšanje dvije novelne promjene.', 'da': 'Pattisapu et al. (2020) formulerer medicinsk begreb normalisering (MCN) som tekst lighedsproblem og foreslår en model baseret på RoBERTa og grafindlejring baseret målbegrebsvektorer. Dog ignorerer grafindlejringsteknikker værdifulde oplysninger tilgængelige i den kliniske ontologi som begrebsbeskrivelse og synonymer. I dette arbejde forbedrer vi modellen af Pattisapu et al. (2020) med to nye ændringer. Først bruger vi eftermonterede målkonceptvektorer i stedet for grafindlejring baserede vektorer. Det er det første arbejde, der udnytter både konceptbeskrivelse og synonymer til at repræsentere koncepter i form af eftermonterede målkonceptvektorer i tekst lighedsramme baseret sociale medier MCN. For det andet genererer vi både koncept og koncept nævnelsesvektorer med samme størrelse, hvilket eliminerer behovet for tætte lag til at projicere konceptnævnelsesvektorer i målkonceptet indlejring af rum. Vores model overgår eksisterende metoder med forbedringer på op til 3,75% på to standarddatasæt. Når vores model kun er uddannet i kortlægning af leksikonssynonymer, overgår vores eksisterende metoder med betydelige forbedringer på op til 14,61%. Vi tillægger disse væsentlige forbedringer de to nye ændringer, der er indført.', 'nl': 'Pattisapu et al. (2020) formuleren medische conceptnormalisatie (MCN) als tekstgelijkenisprobleem en stellen een model voor gebaseerd op RoBERTa en grafiek embedding gebaseerde doelconceptvectoren. Graph embedding technieken negeren echter waardevolle informatie die beschikbaar is in de klinische ontologie, zoals conceptbeschrijving en synoniemen. In dit werk versterken we het model van Pattisapu et al. (2020) met twee nieuwe veranderingen. Ten eerste gebruiken we retrofitte target concept vectoren in plaats van grafiek embedded gebaseerde vectoren. Het is het eerste werk dat zowel conceptbeschrijving als synoniemen gebruikt om concepten weer te geven in de vorm van retrofitte doelconceptvectoren in het tekstvergelijkingsframework gebaseerd social media MCN. Ten tweede genereren we zowel concept- als concept-vermeldingsvectoren met dezelfde grootte, wat de noodzaak van dichte lagen elimineert om conceptvermeldingsvectoren te projecteren in het doelconcept waarin ruimte wordt ingebed. Ons model overtreft bestaande methoden met verbeteringen tot 3,75% op twee standaard datasets. Bovendien, wanneer ons model alleen getraind is op het in kaart brengen van lexicon synoniemen, presteert ons model beter dan bestaande methoden met aanzienlijke verbeteringen tot 14.61%. We schrijven deze significante verbeteringen toe aan de twee nieuwe veranderingen die zijn ingevoerd.', 'de': 'Pattisapu et al. (2020) formulieren medizinische Konzeptnormalisierung (MCN) als Textähnlichkeitsproblem und schlagen ein Modell vor, das auf RoBERTa- und Grapheneinbettungsfaktoren basiert. Allerdings ignorieren Graph Embedding Techniken wertvolle Informationen, die in der klinischen Ontologie verfügbar sind, wie Konzeptbeschreibung und Synonyme. In dieser Arbeit erweitern wir das Modell von Pattisapu et al. (2020) um zwei neue Änderungen. Zunächst verwenden wir nachgerüstete Zielkonzeptvektoren anstelle von Grapheneinbettungs-basierten Vektoren. Es ist die erste Arbeit, die sowohl Konzeptbeschreibung als auch Synonyme nutzt, um Konzepte in Form von nachgerüsteten Zielkonzeptvektoren in Text Ähnlichkeitsframework basierenden Social Media MCN darzustellen. Zweitens generieren wir sowohl Konzept- als auch Konzept-Erwähnungsvektoren mit gleicher Größe, was die Notwendigkeit von dichten Ebenen eliminiert, um Konzept-Erwähnungsvektoren in den Zielkonzept Einbettungsraum zu projizieren. Unser Modell übertrifft bestehende Methoden mit Verbesserungen bis zu 3,75% auf zwei Standarddatensätzen. Darüber hinaus übertrifft unser Modell, wenn es nur auf das Mappen von Lexikon-Synonymen trainiert wird, bestehende Methoden mit signifikanten Verbesserungen bis zu 14.61%. Wir führen diese signifikanten Verbesserungen den beiden neuen Änderungen zu.', 'id': 'Pattisapu et al. (2020) formulir konsep medis normalisasi (MCN) sebagai masalah kesamaan teks dan melamar model berdasarkan RoBERTa dan graf embedding target konsep vektor. Namun, teknik memasukkan grafik mengabaikan informasi berharga yang tersedia dalam ontologi klinik seperti deskripsi konsep dan sinonim. Dalam pekerjaan ini, kami meningkatkan model Pattisapu et al. (2020) dengan dua perubahan novel. Pertama, kita menggunakan vektor konsep target yang dipasang kembali bukannya vektor berbasis grafik. Ini adalah pekerjaan pertama untuk menggunakan kedua deskripsi konsep dan sinonim untuk mewakili konsep dalam bentuk vektor konsep target retrofitted dalam rangka persamaan teks berdasarkan media sosial MCN. Kedua, kita menghasilkan konsep dan konsep menyebutkan vektor dengan ukuran yang sama yang menghapuskan kebutuhan lapisan tebal untuk proyek konsep menyebutkan vektor ke konsep target ruang penerbangan. Model kita melebihi metode yang ada dengan peningkatan sampai 3,75% pada dua set data standar. Lebih lanjut ketika dilatih hanya dalam pemetaan sinonim leksikon, model kami melampaui cara yang ada dengan peningkatan yang signifikan sampai 14,61%. Kami atribut perbaikan yang signifikan ini pada dua perubahan baru yang diperkenalkan.', 'ko': 'Pattisapu 등(2020)은 의학 개념 규범화(MCN)를 텍스트의 유사성 문제로 묘사하고 RoBERTA 기반과 그림 기반 삽입의 목표 개념 벡터를 기반으로 한 모델을 제시했다.그러나 그림 삽입 기술은 임상 본체에서 가치 있는 정보, 예를 들어 개념 묘사와 동의어를 소홀히 했다.이 작업에서 우리는Pattisapu 등(2020년)의 모델에 대해 두 가지 새로운 개선을 진행했다.우선, 우리는 개선된 목표 개념의 벡터를 그림에 삽입된 벡터를 대체합니다.텍스트 유사성 프레임워크를 기반으로 한 소셜미디어 MCN에서 개념 묘사와 동의어를 활용해 개선된 목표 개념의 양적 형태로 개념을 표시한 것은 이번이 처음이다.그 다음에 우리는 크기가 같은 개념과 개념 언급 벡터를 생성한다. 그러면 밀집층이 개념 언급 벡터를 목표 개념이 공간에 투영할 필요가 없다.우리의 모델은 기존의 방법보다 우수하여 두 표준 데이터 집합의 개선률이 3.75% 에 달한다.그 밖에 시사어휘 동의어만 훈련할 때 우리의 모델은 기존 방법보다 14.61% 높아졌다.우리는 이러한 중대한 개선을 도입된 두 가지 새로운 변화에 기인할 것이다.', 'fa': 'Pattisapu et al. (۲۰۰۲) به عنوان مشکل شبیه\u200cسازی متن مفکرات پزشکی (MCN) فرمول می\u200cکند و یک مدل بر روی ویکتورهای مفهوم هدف بنیاد RoBERTa و گراف پیشنهاد می\u200cدهد. با این حال، تکنیک\u200cهای پیدا کردن گراف، اطلاعات ارزشمند را در آنتونولوژی کلینیکی مانند توصیف نظریه و سنونیم نادیده بگیرد. در این کار، ما مدل Pattisapu et al (۲۰۰۲) را با دو تغییر رمانی بیشتر می\u200cکنیم. اول، ما از ویکتورهای مفهوم هدف دوباره استفاده می کنیم به جای ویکتورهای بنیادی گراف. این اولین کاری است که توصیف نظریه و سنونیم را برای نمایش نظریه\u200cها در شکل ویکتورهای هدف باز رسیده شده در چهارچوب شبیه\u200cسازی متن بر اساس رسانه\u200cهای اجتماعی MCN تحت تاثیر قرار می\u200cدهد. دوم، ما هر دو مفهوم و مفهوم را با اندازه\u200cای مشابه می\u200cکنیم که نیازی لایه\u200cهای عمیق برای پروژه\u200cی مفهوم\u200cهای ویکتورها را در فضای مشابه\u200cکننده هدف تبدیل می\u200cکند. مدل ما روش موجودات موجود را با بهبود تا 3.75 درصد در دو مجموعه داده استاندارد انجام می دهد. هنگامی که فقط در نقشه\u200cسازی\u200cهای لکسیون آموزش داده می\u200cشود، مدل ما از روش\u200cهای موجود با بهترین شدید تا ۱۴.۱۶ درصد بیشتر انجام می\u200cدهد. ما این تغییرات بزرگی را به دو تغییرات رمانی معرفی می کنیم.', 'sw': 'Pattisapu et al. (2020) inatengeneza utaratibu wa dhana ya afya (MCN) kama tatizo la maandishi yanayofanana na pendekeza modeli inayohusiana na RoBERTa na picha zinazoingia kwenye vectors za malengo. Hata hivyo, teknolojia za picha zinazotumia kupuuza taarifa za thamani zinazopatikana katika utaalamu wa kliniki kama maelezo na synonyesho. In this work, we enhance the model of Pattisapu et al. (2020) with two novel changes.  Kwanza, tunatumia vector za malengo ya upya badala ya ramani zinazoingia vector zilizoko kwenye msingi. Ni kazi ya kwanza ya kutumia maelezo ya mawazo na synonyesho ya kuwakilisha dhana katika namna ya vectori za malengo yaliyofikiliwa katika mfumo wa simu za viganjani wa mitandao ya kijamii MCN. Pili, tunatengeneza dhana na dhana tunazotaja vectors kwa kiwango hicho kinachoondoa haja ya vifaa vya ndani ili kutambua vectors katika dhana ya malengo. Mfano wetu unaonyesha njia zilizopo na maboresho ya kufikia asilimia 3.75 kwenye seti mbili za takwimu za kiwango cha kawaida. Zaidi pale ulipofundishwa kwa ajili ya ramani za synonyesho la lexico tu, mtindo wetu unaonyesha mbinu zilizopo na maboresho makubwa zaidi ya asilimia 14.61. Tunawaweka maendeleo haya muhimu kwa mabadiliko ya riwaya mbili yaliyoanzishwa.', 'af': "Pattisapu et al. (2020) formeer mediese konsepte normalisering (MCN) as teks gelykenis probleem en voorstel 'n model gebaseer op RoBERTa en graaf wat inbêer gebaseerde doel konsepte vektore. Maar graaf inbetering teknike ignoreer waardelike inligting beskikbaar in die kliëniese ontologie soos konseptbeskrywing en sinonime. In hierdie werk verbeter ons die model van Pattisapu et al. (2020) met twee novele veranderinge. Eerste, ons gebruik teruggevind doel konsepte vektore in plaas van graaf inbêer gebaseerde vektore. It is the first work to leverage both concept description and synonyms to represent concepts in the form of retrofitted target concept vectors in text similarity framework based social media MCN. Tweede, ons genereer beide konsepte en konsepte spesifieke vektore met dieselfde grootte wat elimineer die behoefte van dense laagte na projek konsepte spesifieke vektore binne in die doel konsepte inbinneste ruimte. Ons model uitvoer bestaande metodes met verbeteringe tot 3. 75% op twee standaard datastelle. Verder wanneer slegs opgelei word op die kaart van leksikoniese sinonime, sal ons model uitvoer bestaande metodes met betekende verbeteringe tot 14.61%. Ons eienskap hierdie betekende verbeteringe aan die twee novele veranderinge wat ingestel is.", 'tr': "Pattisapu et al. (2020) tıbbi düşünceleri normalization (MCN) metin benzeri meselesi hökmünde formlat we RoBERTa we grafik tabanlı hedef vektörlerine dayanan bir modeli teklif et. Ýöne, grafik gaýşartma teknikleri kliniki ontologiýada, düşünjä waspy we synonymlar ýaly meňzeş maglumatlary görmeýär. Bu işde Pattisapu et al modelini geliştirdik. (2020) iki roman üýtgeşigi bilen. İlk olarak grafik içinde sabitlenmiş vektörler yerine yeniden gelen hedef vektörlerini kullanırız. Bu, mantıklı tanımlama ve sinonimlerde farklı fikirler oluşturmak için ilk çalışmadır. Metin benzeri bir çerçevesinde sosyal medya tabanlı MCN'e dayanan hedef vektörlerinin şeklinde oluşturmak için düşünceleri temsil etmek. İkinci olarak, vektörleri de aynı boyutla konuşan konseptler oluşturuyoruz. Bu şekilde, vektörleri de hedefi içeren uzaya dahil etmek için yoğun katların ihtiyacını eliminer. Biziň nusgamyz 2 standart veri setirlerinde gelişmeler bilen bar ýagdaýlary çykarýar. Diňe leksikon synonymlary bilen bilinmedilen bolsa, biziň modelimiz bolan yönlerimizi 14.61%-a çenli düzeldiler. Biz bu wajyp gelişmeleri iki roman üýtgewlerine golaýlaýarys.", 'sq': 'Pattisapu et al. (2020) formulojnë normalizimin e konceptit mjekësor (MCN) si problem të ngjashmërisë së tekstit dhe propozojnë një model bazuar në RoBERTa dhe vektorët e konceptit të objektivit të përfshirë në grafik. Megjithatë, teknikat e përfshirjes së grafikut injorojnë informacionin e vlefshëm të disponueshëm në ontologjinë klinike si përshkrimi i konceptit dhe sinonimet. Në këtë punë, ne përmirësojmë modelin e Pattisapu et al. (2020) me dy ndryshime të reja. Së pari, ne përdorim vektorë koncepti objektiv të përshtatur në vend të vektorëve të bazuar në grafik. Kjo është puna e parë për të nxitur si përshkrimin e konceptit, ashtu edhe sinonimet për të përfaqësuar konceptet në form ën e vektorëve të konceptit objektiv të përsëritur në kuadrin e ngjashmërisë teksti të medias sociale MCN. Së dyti, ne gjenerojmë si konceptin ashtu edhe konceptin përmendim vektorët me të njëjtin madhësi që eliminon nevojën e shtresave të dendura për të projektuar konceptin përmendim vektorët në konceptin objektiv që përfshin hapësirën. Modeli ynë mbizotëron metodat ekzistuese me përmirësime deri në 3.75% në dy grupe të dhënash standarde. Further when trained only on mapping lexicon synonyms, our model outperforms existing methods with significant improvements up to 14.61%.  Ne i atribuojmë këto përmirësime të rëndësishme dy ndryshimeve të paraqitura.', 'am': 'Pattisapu et al. (2020) ማህበራዊ ሐሳብ (MCN) እንደ ጽሑፍ ብጤት መሆኑን በመግለጽ እና በሮBERTA እና በክፍለ ጉዳይ ላይ የተመሳሳይ መተላለፊያ ማዘጋጀት ነው፡፡ However, graph embedding techniques ignore valuable information available in the clinical ontology like concept description and synonyms.  በዚህ ሥራ፣ የPattisapu እና al (2020) ምሳሌ በሁለት የመረጃ ለውጦች እናበጅላለን፡፡ መጀመሪያ፣ የግንኙነቱን መግለጫ በመስጠት የደረጃ መሳሪያ vectors እናስቀምጣለን፡፡ የመጀመሪያ ሥራ ነው የዓይነቱን ትርጓሜ እና የሲኒናምን ማህበራዊ ማኅበራዊ ሚዲያ ማህበራዊ ማኅበራዊ ሚዲያ በመስመር ላይ የተቀማጠለውን አካባቢ አካባቢዎችን በመስጠት ማሳየት እና ማሳየትን በመስጠት ማሳየት ነው፡፡ Second, both concept and concept vectors with the same size that eliminates the need to create deep layers to mention vectors into the target concept space. ሞዴሌያችን የሚኖረውን ሥርዓት 3.75 በመቶ ላይ በሁለት የዳታ መስመር ላይ ያሳርፋል፡፡ በተጨማሪም ለሌክኮን ሲንynonyም ብቻ በተማረ ጊዜ፣ ሞዴላያችን በ14.61 በመቶ የሚያሳውቀው የሥልጣን መንገዶች ያሳድጋል፡፡ እነዚህን ተለይተው ለሁለቱ አረንጓዴዎች የሚያሳውቋቸውን ትልቅ ማድረግ እናደርጋለን፡፡', 'hy': "Պատիզապո և այլն (2020) ձևավորեն բժշկական գաղափարը նորմալիզացիա (MNC) որպես տեքստի նմանության խնդիր և առաջարկում են մի մոդել, որը հիմնված է Ռոբեռտայի և գծագրի վրա ներառված նպատակային գաղափարի վեկտորների վրա Այնուամենայնիվ, գծագրի ներառման տեխնիկաները անտեսում են կլինիկական օնտոլոգիայում հասանելի արժեքավոր տեղեկատվություն, ինչպիսիք են գաղափարի նկարագրությունը և սինոնիմները: Այս աշխատանքի ընթացքում մենք բարելավում ենք Պատիզապո և այլների մոդելը (2020 թ․-ին) երկու նոր փոփոխություններով: Առաջինը, մենք օգտագործում ենք վերականգնված նպատակային գաղափարի վեկտորներ գրաֆիկի ներառման փոխարեն: It is the first work to leverage both concept description and synonyms to represent concepts in the form of retrofitted target concept vectors in text similarity framework based social media MCN.  Երկրորդ, մենք ստեղծում ենք նաև գաղափար, և նաև նշենք նույն չափի վեկտորներ, որոնք վերացնում են խտուն շերտերի անհրաժեշտությունը, որպեսզի նախագծի գաղափարը նշեն վեկտորները նպատակային գաղափարի ներառման տարած Մեր մոդելը ներկայացնում է գոյություն ունեցող մեթոդներ' բարելավելով մինչև 3.75 տոկոս երկու ստանդարտ տվյալների համակարգերի վրա: Ավելի ուշ, երբ մեր մոդելը պատրաստված է միայն լեքսիկոնի սինոնիմների քարտեզագրման վրա, մեր մոդելը գերազանցում է գոյություն ունեցող մեթոդները, որոնք նշանակալի բարելավումներ են տալիս մինչև 14.61 տո We attribute these significant improvements to the two novel changes introduced.", 'bn': 'প্যাট্রিসাপু এবং আল. (২০২০০) মেডিকেল ধারণা স্বাভাবিকভাবে টেক্সটের সমতামূলক সমস্যা হিসেবে তৈরি করে এবং রোবের্তার উপর ভিত্তিক একটি মডেল প্রস্তাব করুন,  তবে ক্লিনিক্যাল অনটলজিতে প্রাপ্ত মূল্যবান তথ্য উপেক্ষা করা যায়, যেমন ধারণা বর্ণনা এবং সিনোনিয়াম। এই কাজে আমরা প্যাট্রিসাপু এবং আলের মডেল বৃদ্ধি করি (২০২০) দুই নভেল পরিবর্তনের মাধ্যমে। প্রথমত, আমরা গ্রাফ ভিত্তিক ভেক্টর ভিত্তিক ভেক্টরের পরিবর্তে পুনঃনির্বাচিত লক্ষ্য ধারণা ব্যবহার করি। এটি প্রথম কাজ যে ধারণা বিবরণ এবং সিনোনিমগুলোকে প্রতিনিধিত্ব করা হয়েছে টেক্সট সামাজিক প্রচার মাধ্যম এমজিনিস ভিত্তিক সোশ্যাল মিডিয়া এ দ্বিতীয়, আমরা একই আকারে ধারণা এবং ধারণা উল্লেখ করি ভেক্টর তৈরি করি যা প্রকল্পের ধারণা উল্লেখ করার প্রয়োজনীয় ভেক্টরকে লক্ষ্য ধারণার মধ্যে দিয়ে য আমাদের মডেল বিদ্যমান পদ্ধতিগুলোতে প্রাপ্ত ৩. আর যখন শুধুমাত্র লেক্সিকোন সিনোনিম ম্যাপ প্রশিক্ষণ প্রশিক্ষণ করা হয়, তখন আমাদের মডেল বিদ্যমান পদ্ধতি প্রকাশ করে ১৪.৬১%। আমরা এই দুই উপন্যাস পরিবর্তনের কাছে গুরুত্বপূর্ণ উন্নয়নের বিষয়টি উল্লেখ করি।', 'cs': 'Pattisapu et al. (2020) formulují normalizaci medicínského konceptu (MCN) jako problém podobnosti textu a navrhují model založený na vektorech RoBERTa a grafu založených na vložení cílových konceptů. Techniky vkládání grafů však ignorují cenné informace dostupné v klinické ontologii, jako je popis konceptu a synonyma. V této práci rozšíříme model Pattisapu et al. (2020) o dvě nové změny. Nejprve používáme retrofitované cílové koncepce vektorů namísto grafů založených na vkládání grafů. Je to první práce, která využívá jak popis konceptu, tak synonyma k reprezentaci konceptů ve formě retrofitovaných cílových konceptů v textovém rámci podobnosti MCN založeném na sociálních médiích. Za druhé generujeme vektory konceptu i konceptu zmínky se stejnou velikostí, což eliminuje potřebu hustých vrstev pro promítání vektorů konceptu zmínky do cílového konceptu vkládajícího prostor. Náš model překonává stávající metody s vylepšením až 3,75% na dvou standardních datových sadách. Navíc, když je náš model trénován pouze na mapování synonymů lexikonu, překonává stávající metody s významnými zlepšeními až do 14,61%. Tato významná zlepšení připisujeme dvěma novým změnám.', 'ca': "Pattisapu et al. (2020) formulen la normalització del concepte mèdic (MCN) com un problem a de similitud de text i proponen un model basat en RoBERTa i els vectors de concepte objectiu basats en gràfics. Tot i així, les tècniques d'incorporació del gràfic ignoren la valorosa informació disponible en l'ontologia clínica com la descripció del concepte i els sinonims. En aquesta feina, millorem el model de Pattisapu et al. (2020) amb dos canvis noves. Primer, utilitzem vectors de concepte objectiu retrofitats en lloc de vectors basats en gràfics. És la primera feina a aprofitar tant la descripció de concepte com els sinònims per representar conceptes en forma de vectors de concepte objectiu retrofitats en marc de similitud de text basat en mitjans socials MCN. Segon, generam vectors de menció conceptual i conceptual amb la mateixa mida que elimina la necessitat de capes denses per projectar vectors de menció conceptual en el concepte d'objectiu incorporant espai. El nostre model supera els mètodes existents amb millores fins al 3,75% en dos conjunts de dades estàndard. Més aviat, quan només es treina en el mapatge de sinònims de lexicones, el nostre model supera els mètodes existents amb millores significatives fins al 14,61%. We attribute these significant improvements to the two novel changes introduced.", 'et': 'Pattisapu jt. (2020) sõnastavad meditsiinilise kontseptsiooni normaliseerimise (MCN) teksti sarnasuse probleemina ja pakuvad välja mudeli, mis põhineb RoBERTa ja graafikutel põhinevatel sihtkontseptsiooni vektoritel. Graafikute manustamise tehnikad ignoreerivad kliinilises ontoloogias kättesaadavat väärtuslikku teavet, nagu kontseptsiooni kirjeldus ja sünonüümid. Käesolevas töös täiustame Pattisapu jt. (2020) mudelit kahe uue muudatusega. Esiteks kasutame graafikutel põhinevate vektorite asemel moderniseeritud sihtkontseptsiooni vektoreid. See on esimene töö, mis kasutab nii kontseptsiooni kirjeldust kui ka sünonüüme, et esindada kontseptsioone moderniseeritud sihtkontseptsiooni vektorite kujul teksti sarnasuse raamistikul põhinevas sotsiaalmeedias MCN. Teiseks genereerime nii kontseptsiooni kui kontseptsiooni mainimise vektorid sama suurusega, mis välistab tihedate kihtide vajaduse kontseptsiooni mainimise vektorite projekteerimiseks sihtkontseptsiooni ehitamiseks ruumi. Meie mudel ületab olemasolevaid meetodeid, parandades kahte standardset andmekogumit kuni 3,75%. Lisaks, kui meie mudel on koolitatud ainult leksikoni sünonüümide kaardistamiseks, on meie mudel olemasolevatest meetoditest parem, parandades oluliselt kuni 14,61%. Me omistame need olulised parandused kahele uuele muudatusele.', 'fi': 'Pattisapu et al. (2020) muotoilevat lääketieteellisen käsitteen normalisoinnin (MCN) tekstin samankaltaisuusongelmaksi ja ehdottavat mallia, joka perustuu RoBERTa:iin ja graafiseen upottamiseen pohjautuviin kohdekäsitteen vektoreihin. Graafien upotustekniikoissa ei kuitenkaan huomioida kliinisessä ontologiassa olevaa arvokasta tietoa, kuten käsitteen kuvaus ja synonyymit. Tässä työssä parannamme Pattisapu et al. (2020) mallin kahdella uudella muutoksella. Ensin käytämme jälkiasennettuja kohdekonseptivektoreita graafiseen upottamiseen perustuvien vektorien sijaan. Kyseessä on ensimmäinen työ, jossa hyödynnetään sekä käsitteen kuvausta että synonyymejä esittääkseen konsepteja jälkiasennettujen kohdekonseptivektorien muodossa tekstien samankaltaisuuden viitekehykseen perustuvassa sosiaalisessa mediassa MCN. Toiseksi luomme sekä konsepti- että konseptiviestinvektoreita samankokoisiksi, mikä eliminoi tiheiden kerrosten tarpeen projektittaa konseptiviestinvektoreita kohdekonseptiin, joka upottaa tilaa. Mallimme suoriutuu nykyisistä menetelmistä jopa 3,75%:n parannuksilla kahteen vakioaineistoon. Lisäksi kun mallimme on koulutettu vain sanaston synonyymien kartoittamiseen, se suoriutuu olemassa olevista menetelmistä merkittävästi jopa 14,61%. Nämä merkittävät parannukset johtuvat kahdesta uudesta muutoksesta.', 'az': 'Pattisapu et al. (2020) T…ôbbi konsepti normalizasyonu (MCN) metin similarity problemi olaraq form√ľl…ôyir v…ô RoBERTa v…ô grafqa tabanlńĪ m…ôqs…ôd konsepti vekt√∂rl…ôrin…ô dayanan modeli t…ôklif edir. Lakin, qraf in Ňüa metodlarńĪ kliniki ontologiyada m√ľ…ôyy…ôn qiym…ôtli m…ôlumatlarńĪ v…ô sinoniml…ôr kimi m…ôlumatlarda istifad…ô edirl…ôr. Bu iŇüd…ô, Pattisapu et al. (2020) modelini iki yeni d…ôyiŇüiklik il…ô artńĪrńĪrńĪq. ńįlk d…ôf…ô, graf inŇüa edil…ôn vekt√∂rl…ôrin yerin…ô yenid…ôn d…ôyiŇüdirilmiŇü m…ôqs…ôd vekt√∂rl…ôrini istifad…ô edirik. ńįlk iŇüdir ki, m…ôtn b…ônz…ôrini qurulmuŇü sosyal media MCN-d…ô t…ôsdiql…ônmiŇü m…ôqs…ôd vekt√∂rl…ôrinin formasńĪnda fikirl…ôri t…ôsdiql…ônm…ôk √ľ√ß√ľn concept description v…ô synonymlarńĪ t…ôsdiql…ônm…ôkdir. ńįkincisi, h…ôr ikimiz konsept v…ô konsept vekt√∂rl…ôrini eyni √∂l√ß√ľ il…ô yaradńĪrńĪq ki, proqramńĪn vekt√∂rl…ôrini n…ôz…ôrd…ô edil…ôn m…ôqs…ôd konsepti i√ßind…ô uzaqlaŇüdńĪrmaq m…ôqs…ôdil…ô yoxlu s…ôviyy…ôl…ôrin ehtiyacńĪnńĪ sil…ôr. Modelimiz iki standart veri qurularńĪnda 3.75%-…ô q…ôd…ôr daha yaxŇüńĪlaŇüdńĪrmaq √ľ√ß√ľn mevcut metodlarńĪ √ľst√ľn edir. Daha sonra yalnńĪz leksikon sinoniml…ôrini maplamaq √ľ√ß√ľn t…ôhsil edildikd…ô, modell…ôrimiz m√∂vcuddur metodlarńĪ 14.61%-…ô q…ôd…ôr daha yaxŇüńĪlaŇüdńĪrńĪr. Biz bu m√∂hk…ôm d…ôyiŇüiklikl…ôri iki yeni d…ôyiŇüiklikl…ôr…ô t…ôsdiql…ôyirik.', 'bs': 'Pattisapu et al. (2020) formulira normalizaciju medicinskog koncepta (MCN) kao problem sličnosti teksta i predlaže model baziran na RoBERTi i grafiku koji uključuju vektore ciljnog koncepta. Međutim, tehnike ugrađenja grafika ignoriraju dostupne vrijedne informacije u kliničkoj ontologiji poput opisa koncepta i sinonima. U ovom poslu, poboljšavamo model Pattisapu et al. (2020) sa dvije novelne promjene. Prvo, koristimo retroficirane vektore ciljnog koncepta umjesto ugrađenog vektora na grafiku. To je prvi rad koji bi uticali na opis koncepta i sinonima kako bi predstavljali koncept u obliku retroficiranih vektora ciljnog koncepta u okviru tekstualne sličnosti baziranog socijalnog medija MCN. Drugo, stvaramo i koncept i koncept spominjaju vektore sa istom veličinom koji eliminira potrebu gustih slojeva za projektiranje koncepta spominjajući vektore u ciljni koncept uključujući prostor. Naš model iznosi postojeće metode sa poboljšanjem do 3,75% na dva standardna seta podataka. Dalje, kada je obučeno samo na mapiranju leksičkih sinonima, naš model iznosi postojeće metode sa značajnim poboljšanjima do 14,61%. Pripisujemo te značajne poboljšanje na dvije novelne promjene.', 'ha': "@ info: whatsthis A lokacin da, jigon grafyutan wanda ke ƙunsa da, su ƙyale information masu inganci wanda ke da cikin taƙalumun agogon wannan, kamar description da sunonime. Ga wannan aikin, za mu ƙara misalin Fattsiyopa et al. (2020) da musanyawa biyu na nowaya. farkon, za'a yi amfani da shiryoyi masu motsi da aka riƙe shi na shiryoyi na ƙiya Wannan na farkon aikin da za'a samar da su bayyana misãlai da synonim da kuma su ƙayyade zato cikin shirin shiryoyi na tagar da aka mottar da shi cikin firam masu daidaita matsayi MUN. Piki, za'a ƙãga kowanta zaɓen da ke ambato shiryoyi da girma guda, da za'a eliminate hajji na zane-zane-zane-zane-zane-zaɓen-zane-zaɓen-zaɓen zuwa filin mai shiga @ info: whatsthis Furan idan an sanar da shi kawai kan karnin synonim na leksikon, misalinmu yana samar da metoden da ke da muhimmin improvements up to 14.61%. Munã sarrafa waɗannan mafiya kyauta ga musanyawa biyu na nowaya waɗanda aka zo.", 'sk': 'Pattisapu et al. (2020) formulirajo medicinsko normalizacijo koncepta (MCN) kot problem podobnosti besedila in predlagajo model, ki temelji na RoBERTa in grafičnih vdelavah na osnovi ciljnih konceptov. Vendar pa tehnike vključevanja grafov ignorirajo dragocene informacije, ki so na voljo v klinični ontologiji, kot so opis koncepta in sinonimi. V tem delu smo izboljšali model Pattisapu et al. (2020) z dvema novima spremembama. Najprej uporabljamo posodobljene ciljne konceptne vektorje namesto vektorjev, ki temeljijo na vdelavi grafov. Gre za prvo delo, ki uporablja opis koncepta in sinonime za predstavitev konceptov v obliki naknadno opremljenih ciljnih konceptnih vektorjev v okviru besedilne podobnosti MCN. Drugič, ustvarimo tako konceptne kot konceptne omembe vektorje z enako velikostjo, kar odpravlja potrebo po gostih plasteh za projiciranje konceptnih omembe vektorjev v ciljni koncept, ki vključuje prostor. Naš model presega obstoječe metode z izboljšavami do 3,75% na dveh standardnih naborih podatkov. Nadalje, ko smo usposobljeni samo za kartiranje besediških sinonimov, naš model presega obstoječe metode z znatnimi izboljšavami do 14,61%. Te pomembne izboljšave pripisujemo dvema novima spremembama.', 'he': 'Pattisapu et al. (2020) formulate medical concept normalization (MCN) as text similarity problem and propose a model based on RoBERTa and graph embedding based target concept vectors.  However, graph embedding techniques ignore valuable information available in the clinical ontology like concept description and synonyms.  בעבודה הזו, אנחנו משתפרים את הדוגמא של פטיסאפו וכל. (2020) עם שני שינויים חדשים. ראשית, אנו משתמשים בוקטורים מושגים מחדש במטרה במקום בוקטורים מבוססים בגרף. זהו העבודה הראשונה כדי להשתמש בין תיאור מושג וגם סינונימים כדי לייצג מושג בצורה של ווקטורי מושג מטרה מחדש במסגרת דמיון טקסט מבוססת מדיה חברתית MCN. שנית, אנחנו יוצרים גם את הרעיון וגם את הרעיון מזכירים ווקטורים עם אותו גודל אשר מחסל את הצורך של שכבות צפופופות המודל שלנו מציג שיטות קיימות עם שיפורים עד 3.75% בשני קבוצות נתונים סטנדרטיים. יותר כשמאומנים רק על מיפות סינונימות לקסיקונים, המודל שלנו מוביל שיטות קיימות עם שיפורים משמעותיים עד 14.61%. אנחנו מחזיקים שיפורים משמעותיים אלה לשני השינויים הרומניים שהופיעו.', 'jv': 'PacTipu et al. (2020) formate therapist design normal alization (MTN) as text Simlarty error and proposal a model supported on RBERT and graph embedding basic goal design vectors. politenessoffpolite"), and when there is a change ("assertivepoliteness Nang barêng-barêng iki, kéné iso nglanggar model ning patisak et al (2020) nganggep kuwi tur alih sing nyelarani. pe buddy 2D Monday Laptop" and "Desktop Awak dhéwé éntuk nglanggar kuwi ngéwé éntuk kanggo ngerasakno sing iki dadi.', 'bo': 'Pattisapu et al. (2020) formulate medical concept normalization (MCN) as text similarity problem and propose a model based on RoBERTa and graph embedding based target concept vectors. However, graph embedding techniques ignore valuable information available in the clinical ontology like concept description and synonyms. ལཱ་སྟངས་འདིའི་ནང་གི་ངེད་ཚོས་པ་ཊི་སི་པཱལ་ཨཱལ་གྱི་མ་དབྱིབས་རྒྱལ་ཁབ་གཉིས་ཀྱི་ནང་དུ་ཡར་རྒྱས་གཏོང་། First, we use retrofitted target concept vectors instead of graph embedding based vectors. It is the first work to leverage both concept description and synonyms to represent concepts in the form of retrofitted target concept vectors in text similarity framework based social media MCN. Second, we generate both concept and concept mention vectors with same size which eliminates the need of dense layers to project concept mention vectors into the target concept embedding space. ང་ཚོའི་མ་དབྱིབས་སྔོན་སྒྲིག་གནད་སྡུད་ཚན་གཉིས་ཀྱིས་མཐོང་རྐྱེན་བྱེད་ཐབས་ལམ་ལ་ཡར་རྒྱས་གཏོང་བ འོན་ཀྱང་། གཟུགས་རིས་ཁོངས་ལ་སྤྱོད་ཀྱི་དབྱེ་རིག ང་ཚོས་གསར་གཏོད་པར་བཟོ་བཅོས་དེ་གཉིས་ཀྱི་ནང་དུ་ཆེས་ཉིད་ཅིག་ཡར་རྒྱས་གཏོང་བ་དེ་རེད།'}
{'en': 'BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using Chemical Structure Information', 'ar': 'BERTChem-DDI: تحسين التنبؤ بالتفاعل بين الأدوية والعقاقير من النص باستخدام معلومات التركيب الكيميائي', 'es': 'Bertchem-DDI: predicción mejorada de la interacción entre fármacos a partir del texto utilizando información de estructura química', 'pt': 'BERTChem-DDI: Predição de interação droga-droga aprimorada a partir de texto usando informações de estrutura química', 'fr': "BertChem-DDI\xa0: Prédiction améliorée des interactions médicamenteuses à partir d'un texte utilisant des informations sur la structure chimique", 'ja': 'BERTChem - DDI ：化学構造情報を使用したテキストからの改善された薬物-薬物相互作用予測', 'hi': 'BERTChem-DDI: रासायनिक संरचना जानकारी का उपयोग कर पाठ से बेहतर दवा-ड्रग इंटरैक्शन भविष्यवाणी', 'zh': 'BERTChem-DDI 曰: 用化学结信-药用相知也', 'ru': 'BERTChem-DDI : Улучшенное прогнозирование межлекарственного взаимодействия из текста с использованием информации о химической структуре', 'ga': 'BERTChem-DDI : Réamh-mheastachán Feabhsaithe maidir le hIdirghníomhaíocht Drugaí-Drugaí ó théacs ag úsáid Faisnéis ar Struchtúr Ceimiceach', 'hu': 'BERTChem-DDI: Javított gyógyszer-gyógyszer kölcsönhatás előrejelzése szövegből kémiai szerkezeti információk használatával', 'ka': 'BERTChem- DDI : გასაკეთებული ნაპროგრამის ინტერქექცია ტექსტიდან გამოყენებული ქიმიკური სტრუქტურის ინფორმაცია', 'el': 'Βελτιωμένη πρόβλεψη αλληλεπίδρασης φαρμάκων-φαρμάκων από κείμενο χρησιμοποιώντας πληροφορίες χημικής δομής', 'it': "BERTChem-DDI: Migliorata la previsione dell'interazione farmaco-farmaco dal testo utilizzando le informazioni sulla struttura chimica", 'kk': 'BERTChem- DDI : Химикалық құрылғы мәліметін қолданатын мәтіннен құрылған наркотикалық интерфекциялық бағдарламасы', 'mk': 'BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using Chemical Structure Information', 'lt': 'BERTChem-DDI: Geresnis narkotikų sąveikos prognozė iš teksto, naudojant cheminės struktūros informaciją', 'mt': 'BERTChem-DDI : Tbassir imtejjeb tal-interazzjoni bejn id-drogi u d-drogi mit-test bl-użu ta’ Informazzjoni dwar l-Istruttura Kimika', 'ms': 'BERTChem-DDI : Pertamaan Perlakangan Interaksi dadah-dadah dari teks menggunakan Maklumat Struktur Kimia', 'ml': 'ബെര്\u200dട്ടിചെമ്- ഡിഡിഐ: ചെമിക്കല്\u200d സ്ട്രാക്ട്രൂക്ടര്\u200d വിവരങ്ങള്\u200d ഉപയോഗിച്ച് മയക്കുമരുന്നുവെട്ടിയുടെ വിവരങ്ങള്\u200d', 'mn': 'BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using Chemical Structure Information', 'no': 'BERTChem-DDI : Forhåndsvising av forbetra narkotika-interaksjon frå tekst ved hjelp av kjemiske struktureinformasjon', 'sr': 'BERTChem-DDI : Poboljšana predviđanja interakcije droga iz teksta koristeći informacije o kemijskoj strukturi', 'pl': 'BERTChem-DDI: Udoskonalona predykcja interakcji lekowo-lekowych na podstawie tekstu z wykorzystaniem informacji o strukturze chemicznej', 'ro': 'BERTChem-DDI: Predicția îmbunătățită a interacțiunii medicament-medicament din text folosind informații privind structura chimică', 'so': 'BERTChem-DDI : Improved Drug-drug Interaction Prediction from text using Chemical Structure Information', 'si': 'BERTChem', 'sv': 'BERTChem-DDI: Förbättrad prognos för läkemedelsinteraktion från text med hjälp av kemisk strukturinformation', 'ta': 'BERTChem- DDI: சைமிக்கல் அமைப்பு தகவலை பயன்படுத்தி முன்னேற்றப்பட்ட Drug- Drug Interaction Prediction from text', 'ur': 'BERTChem-DDI : Chemical Structure Information using text from Improved Drug-Drug Interaction Prediction', 'uz': 'QUnicodeControlCharacterMenu', 'vi': 'Sự tương tác thuốc kích thích tốt từ văn bản dùng thông tin cấu trúc hóa học', 'bg': 'Подобрено прогнозиране на взаимодействието лекарство-лекарство от текст, използващ информация за химическата структура', 'da': 'BERTChem-DDI: Forbedret forudsigelse af lægemiddelinteraktion fra tekst ved hjælp af kemisk strukturinformation', 'hr': 'BERTChem-DDI : Poboljšana interakcija droga iz teksta koristeći informacije o kemijskoj strukturi', 'nl': 'BERTChem-DDI: Verbeterde Drug-Drug Interactie Voorspelling op basis van tekst met behulp van Chemische Structuur Informatie', 'id': 'BERTChem-DDI : Perkiraan interaksi obat-obat meningkat dari teks menggunakan Informasi Struktur Kimia', 'de': 'BERTChem-DDI: Verbesserte Vorhersage von Arzneimittel-Arzneimittel-Wechselwirkungen aus Texten unter Verwendung chemischer Strukturinformationen', 'fa': 'BERTChem-DDI : پیشنهاد تفاوت مواد مخدر و مواد بهتر شده از متن استفاده از اطلاعات ساختار شیمیایی', 'sw': 'BERTChem-DDI : Udhibiti wa Ushirikiano wa dawa ulioboreshwa kutoka maandishi kwa kutumia taarifa za Miundombinu', 'ko': 'BERTChem DDI: 화학 구조 정보를 활용하여 텍스트에서 약물 상호작용 예측 개선', 'tr': 'BERTChem-DDI : Çimi struktur Maglumaty ullanýan metin üçin gelişmiş narkotik ilatyny', 'af': 'BERTChem- DDI : Geverbeterde Drug- Drug Interaksie Voorskou van teks gebruik Chemical Structure Information', 'am': 'BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using Chemical Structure Information', 'sq': 'BERTChem-DDI : Parashikimi i përmirësuar i ndërveprimit të drogës-drogës nga teksti duke përdorur informacionin e strukturës kimike', 'hy': 'BERCH-DRI. Թմրադեղերի և թմրադեղերի ինտերակցիայի բարելավված կանխատեսումը տեքստից, օգտագործելով քիմիական կառուցվածքի տեղեկատվություն', 'az': 'BERTChem-DDI : Chemical Structure Information vasit…ôsil…ô m…ôtnd…ôn uyuŇüturucu-uyuŇüturucu Interaction Prediction', 'bn': 'BERTChem-DDI: কেমিক্যাল কাঠামো তথ্য ব্যবহার করে মাদক-মাদক ইন্টারনেশনের সুবিধা', 'bs': 'BERTChem-DDI : Poboljšana predviđanja interakcije droga iz teksta koristeći informacije o kemijskoj strukturi', 'ca': 'BERTChem-DDI: Improved Drug-Drug Interaction Prediction from text using Chemical Structure Information', 'cs': 'BERTChem-DDI: Zlepšená predikce interakce léčiv-léčiv z textu s využitím informací o chemické struktuře', 'et': 'BERTChem-DDI: ravimite ja ravimite parema koostoime prognoosimine keemilise struktuuri teabe abil', 'fi': 'BERTChem-DDI: Parannettu lääkkeiden ja lääkkeiden yhteisvaikutuksen ennuste tekstistä käyttäen kemiallista rakennetta koskevia tietoja', 'jv': 'BERT Kemik-DDN: Bukak Drog-Drog interaction predikyon seng teks nggambar Kemik structural Informasi', 'sk': 'BERTChem-DDI: Napoved boljšega medsebojnega delovanja med zdravili iz besedila z uporabo informacij o kemijski strukturi', 'he': 'BERTChem-DDI: שיפור התאמה בין תרופות ולסמים מתוך טקסט באמצעות מידע מבנה כימי', 'ha': 'KCharselect unicode block name', 'bo': 'BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using Chemical Structure Information'}
{'en': 'Traditional biomedical version of embeddings obtained from pre-trained language models have recently shown state-of-the-art results for relation extraction (RE) tasks in the medical domain. In this paper, we explore how to incorporate domain knowledge, available in the form of molecular structure of drugs, for predicting Drug-Drug Interaction from textual corpus. We propose a method, BERTChem-DDI, to efficiently combine drug embeddings obtained from the rich chemical structure of drugs (encoded in SMILES) along with off-the-shelf domain-specific BioBERT embedding-based RE architecture. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other strong baselines architectures by 3.4 % macro F1-score.', 'ar': 'أظهرت النسخة الطبية الحيوية التقليدية للزفافات التي تم الحصول عليها من نماذج اللغة المدربة مسبقًا مؤخرًا أحدث النتائج لمهام استخراج العلاقة (RE) في المجال الطبي. في هذه الورقة ، نستكشف كيفية دمج معرفة المجال ، المتوفرة في شكل التركيب الجزيئي للأدوية ، للتنبؤ بالتفاعل بين الأدوية والعقاقير من مجموعة النصوص. نقترح طريقة ، BERTChem-DDI ، للجمع بكفاءة بين عمليات دمج الأدوية التي تم الحصول عليها من التركيب الكيميائي الغني للأدوية (المشفرة في SMILES) جنبًا إلى جنب مع بنية BioBERT القائمة على التضمين القائمة على المجال الجاهز. تشير التجارب التي أجريت على مجموعة DDIExtraction 2013 بوضوح إلى أن هذه الإستراتيجية تعمل على تحسين بنى خطوط الأساس القوية الأخرى بنسبة 3.4٪ من الدرجة الكلية F1.', 'pt': 'Versões biomédicas tradicionais de embeddings obtidas a partir de modelos de linguagem pré-treinados mostraram recentemente resultados de última geração para tarefas de extração de relações (ER) no domínio médico. Neste artigo, exploramos como incorporar o conhecimento do domínio, disponível na forma de estrutura molecular de drogas, para prever a interação droga-droga a partir do corpus textual. Propomos um método, BERTChem-DDI, para combinar eficientemente incorporações de drogas obtidas a partir da rica estrutura química de drogas (codificadas em SMILES) juntamente com arquitetura de RE baseada em incorporação específica de domínio BioBERT pronta para uso. Experimentos conduzidos no corpus DDIExtraction 2013 indicam claramente que essa estratégia melhora outras arquiteturas de linhas de base fortes em 3,4% macro F1-score.', 'fr': "Les versions biomédicales traditionnelles des intégrations obtenues à partir de modèles de langage préformés ont récemment montré des résultats de pointe pour les tâches d'extraction de relations (RE) dans le domaine médical. Dans cet article, nous explorons comment intégrer les connaissances du domaine, disponibles sous la forme de la structure moléculaire des médicaments, pour prédire l'interaction médicament-médicament à partir d'un corpus textuel. Nous proposons une méthode, Bertchem-DDI, pour combiner efficacement des enrobages de médicaments obtenus à partir de la structure chimique riche des médicaments (codée dans SMILES) avec une architecture RE basée sur l'intégration BioBert spécifique au domaine standard. Les expériences menées sur le corpus DDIExtraction 2013 indiquent clairement que cette stratégie améliore d'autres architectures de base solides de 3,4\xa0% avec un score macro F1.", 'es': 'La versión biomédica tradicional de las incorporaciones obtenidas de modelos lingüísticos previamente entrenados ha mostrado recientemente resultados de vanguardia para las tareas de extracción de relaciones (RE) en el dominio médico. En este artículo, exploramos cómo incorporar el conocimiento del dominio, disponible en forma de estructura molecular de los fármacos, para predecir la interacción entre fármacos a partir de un corpus textual. Proponemos un método, Bertchem-DDI, para combinar eficazmente las incrustaciones de fármacos obtenidas de la rica estructura química de los fármacos (codificados en SMILES) junto con la arquitectura de RE basada en la incrustación de BioBert específica del dominio disponible. Los experimentos realizados en el corpus DDIExtraction 2013 indican claramente que esta estrategia mejora otras arquitecturas de líneas de base sólidas en un 3,4% de puntuación de F1 macro.', 'ja': '事前にトレーニングされた言語モデルから得られた埋め込みの従来の生物医学的バージョンは、最近、医療領域における関係抽出（ RE ）タスクの最先端の結果を示しています。この論文では、テキストコーパスから薬物-薬物相互作用を予測するために、薬物の分子構造の形で利用可能なドメイン知識を組み込む方法を探求する。医薬品の豊富な化学構造（ SMILESでコード化）から得られた医薬品埋め込みと、既製のドメイン固有のBioBERT埋め込みベースのREアーキテクチャを効率的に組み合わせる方法、BERTChem - DDIを提案します。DDIExtraction 2013コーパスで実施された実験は、この戦略が他の強力なベースラインアーキテクチャを3.4 ％のマクロF 1スコアで改善することを明確に示しています。', 'zh': '先训语模生物医学版本近见医学领域取(RE)之最新。 论药分子结构域,占药于文本语料库 - 药之用也。 立一法,BERTChem-DDI,以效合化学结构(编码)嵌于SMILES中,嵌于成者基于BioBERT嵌之RE。 DDIExtraction 2013 语料库上实验明白,该策将他强基线体系结构增 3.4% 宏观 F1 分数。', 'hi': 'पूर्व-प्रशिक्षित भाषा मॉडल से प्राप्त एम्बेडिंग के पारंपरिक बायोमेडिकल संस्करण ने हाल ही में चिकित्सा डोमेन में संबंध निष्कर्षण (आरई) कार्यों के लिए अत्याधुनिक परिणाम दिखाए हैं। इस पेपर में, हम यह पता लगाते हैं कि डोमेन ज्ञान को कैसे शामिल किया जाए, जो दवाओं की आणविक संरचना के रूप में उपलब्ध है, जो पाठ्य कॉर्पस से ड्रग-ड्रग इंटरैक्शन की भविष्यवाणी करने के लिए है। हम एक विधि, BERTChem-DDI का प्रस्ताव करते हैं, जो दवाओं की समृद्ध रासायनिक संरचना (SMILES में एन्कोडेड) से प्राप्त दवा एम्बेडिंग को कुशलतापूर्वक संयोजित करने के साथ-साथ ऑफ-द-शेल्फ डोमेन-विशिष्ट BioBERT एम्बेडिंग-आधारित आरई आर्किटेक्चर के साथ है। DDIExtraction 2013 कॉर्पस पर किए गए प्रयोगस्पष्ट रूप से इंगित करते हैं कि यह रणनीति 3.4% मैक्रो F1-स्कोर द्वारा अन्य मजबूत बेसलाइन आर्किटेक्चर में सुधार करती है।', 'ru': 'Традиционная биомедицинская версия вложений, полученных из предварительно обученных языковых моделей, недавно показала современные результаты для задач экстракции отношений (RE) в медицинской области. В этой статье мы исследуем, как включить знания домена, доступные в форме молекулярной структуры лекарств, для прогнозирования лекарственного взаимодействия из текстового корпуса. Мы предлагаем метод BERTChem-DDI для эффективного сочетания вложений лекарственных средств, полученных из богатой химической структуры лекарственных средств (закодированных в УЛЫБКАХ), наряду с готовой домен-специфичной архитектурой RE на основе вложений BioBERT. Эксперименты, проведенные на корпусе DDIExtraction 2013, ясно показывают, что эта стратегия улучшает другие сильные базовые архитектуры на 3,4% макро- F1-балла.', 'ga': 'Léirigh leagan bithleighis thraidisiúnta de leabú a fuarthas ó mhúnlaí teanga réamhoilte torthaí úrscothacha le déanaí maidir le tascanna asbhainte caidrimh (RE) sa réimse leighis. Sa pháipéar seo, déanaimid iniúchadh ar conas eolas fearainn, atá ar fáil i bhfoirm struchtúr móilíneach drugaí, a ionchorprú chun Idirghníomhaíocht Drugaí-Drugaí a thuar ó chorpas téacsúil. Molaimid modh, BERTChem-DDI, chun leabú drugaí a fhaightear ó struchtúr saibhir ceimiceach na ndrugaí (atá ionchódaithe i SMILES) a chomhcheangal go héifeachtach in éineacht le hailtireacht RE atá bunaithe ar leabú BioBERT atá bunaithe ar an bhfearann go sonrach agus lasmuigh den tseilf. Léiríonn turgnaimh a rinneadh ar chorpas DDIExtraction 2013 go soiléir go bhfeabhsaítear leis an straitéis seo ailtireachtaí bonnlínte láidre eile faoi 3.4% macra-scór F1.', 'ka': 'ტრადიციონალური ბიომედიციური ვერსია, რომელიც წინაშემოწმებული ენის მოდელებიდან მიღებულია, უკვე შემდეგ ჩვენება მედიციონალური დიომინში შესახებ შესახებ შესახებ შესახებ შესახე ამ დოკუმენში, ჩვენ განსხვავებთ როგორ დავყენებთ დემონიური ცოდნა, როგორც მოლეკუალური სტრუქტურაციის ფორმაში, პროგრამის შესახებ ექსპერქტურის ინტერქექციის შესა ჩვენ გვეყველა მეტი, BERTChem-DDI, რომელიც ექსპექტიკური კონფიგურაციას გამოიყენებს, რომელიც ბეჭდვი ჰიმიკური სტრუქტურაციას (SMILES-ში კონფიგურაცია) მიღებულია პროფიქტიკური პროფიქტიკურ DDIExtraction 2013 კოპპუსში გამოყენებული ექსპერიმენტები წარმოდგენია, რომ ეს სტრატიგია სხვა ძალიან ბაზის აქტიქტიქტურება 3,4% მაკრო F1- სოფლიოში.', 'hu': 'Az előképzett nyelvi modellekből származó beágyazások hagyományos orvosbiológiai változata a közelmúltban korszerű eredményeket mutatott az orvosi területen végzett kapcsolatextrakciós (RE) feladatok tekintetében. Ebben a tanulmányban azt vizsgáljuk, hogyan lehet beépíteni a gyógyszerek molekuláris struktúrájában elérhető domain ismereteket a gyógyszer-gyógyszer interakció előrejelzéséhez szöveges korpuszból. Javasoljuk a BERTChem-DDI módszert, amely hatékonyan kombinálja a gyógyszerek gazdag kémiai struktúrájából (SMILES-ben kódolt) nyert gyógyszerek beágyazását, valamint az elérhető domain specifikus BioBERT beágyazási alapú RE architektúrát. A DDIExtraction 2013 korpuszon végzett kísérletek egyértelműen azt mutatják, hogy ez a stratégia 3,4%-kal javítja a többi erős alapvonalas architektúrát.', 'el': 'Η παραδοσιακή βιοϊατρική έκδοση των ενσωματώσεων που λαμβάνονται από προ-εκπαιδευμένα γλωσσικά μοντέλα έδειξε πρόσφατα αποτελέσματα τελευταίας τεχνολογίας για εργασίες εξαγωγής σχέσεων στον ιατρικό τομέα. Στην παρούσα εργασία, διερευνούμε πώς να ενσωματώσουμε τη γνώση του τομέα, διαθέσιμη με τη μορφή μοριακής δομής των φαρμάκων, για την πρόβλεψη της αλληλεπίδρασης φαρμάκων-φαρμάκων από το κειμενικό σώμα. Προτείνουμε μια μέθοδο, για να συνδυάσουμε αποτελεσματικά τις ενσωματώσεις φαρμάκων που λαμβάνονται από την πλούσια χημική δομή των φαρμάκων (κωδικοποιημένες σε SMILES) μαζί με την τυποποιημένη αρχιτεκτονική βασισμένη στην ενσωμάτωση τομέα. Τα πειράματα που διεξήχθησαν στο σώμα δείχνουν σαφώς ότι αυτή η στρατηγική βελτιώνει άλλες ισχυρές αρχιτεκτονικές γραμμών βάσης κατά 3,4% μακρο-βαθμολογία F1.', 'it': "La versione biomedica tradizionale degli embedding ottenuti da modelli linguistici pre-formati ha recentemente mostrato risultati all'avanguardia per le attività di estrazione delle relazioni (RE) in ambito medico. In questo articolo, esploriamo come incorporare la conoscenza del dominio, disponibile sotto forma di struttura molecolare dei farmaci, per predire l'interazione farmaco-farmaco dal corpus testuale. Proponiamo un metodo, BERTChem-DDI, per combinare in modo efficiente gli embedding di farmaci ottenuti dalla ricca struttura chimica dei farmaci (codificati in SMILES) insieme all'architettura RE basata su embedding BioBERT. Gli esperimenti condotti sul corpus DDIExtraction 2013 indicano chiaramente che questa strategia migliora altre architetture di base forti del 3,4% macro F1-score.", 'lt': 'Tradicinė biomedicinė įrangos versija, gauta naudojant iš anksto parengtus kalbų modelius, neseniai parodė naujausius santykių ekstrahavimo (RE) užduočių medicinos srityje rezultatus. Šiame dokumente mes tiriame, kaip įtraukti srities žinias, kurios yra prieinamos kaip molekulinė narkotikų struktūra, narkotikų ir narkotikų sąveikai iš tekstinio korpuso prognozuoti. Siūlome metodą, BERTChem-DDI, veiksmingai derinti narkotikų įterpimą, gautą iš turtingos cheminės narkotikų struktūros (koduota SMILES), kartu su bioBERT įterpimo į rinką srities specifine RE architektūra. Iš DDIExtraction 2013 korpuso atliktų eksperimentų aiškiai matyti, kad šia strategija 3,4 % makroekonominiu F1 rezultatu pagerinamos kitos tvirtos bazinės architektūros.', 'kk': 'Алдын- оқылған тіл үлгілерінен алған ендірудің традиционалдық биомедикалық нұсқасы медицина доменінде қатынау (RE) тапсырмаларының күй- жайында көрсетілді. Бұл қағазда, біз домен білімін қалай біріктіру керектігін текстуалды корпустың молекулялдық құрылымының түрінде қолданылатын, наркот-наркот интерактивін бақылау үшін іздейміз. Біз BERTChem-DDI әдісін таңдаймыз, наркотикалық құрылғылардың бағасы химиялық құрылғысынан (SMILES дегенде кодталған) құрылғылардың біріктіру үшін қолданатын наркотикалық құрылғыларды біріктіруге мүмкіндік береді. DDIExtraction 2013 корпус тәжірибесінде істеген тәжірибелер бұл стратегия басқа күшті негізгі сызықтардың архитектураларын 3,4% F1- нұсқасы архитектураларды жақсартады.', 'mk': 'Традиционалната биомедициска верзија на вградувањата добиени од предобучените јазички модели неодамна покажа најсовремени резултати за задачите за извлекување врски (РЕ) во медицинскиот домен. Во овој весник, истражуваме како да го вклучиме знаењето на доменот, достапно во форма на молекуларна структура на дрогата, за предвидување на интеракција дрога-дрога од текстуалниот корпус. Предложуваме метод, БЕРТКЕМ-ДДИ, за ефикасна комбинација на вградувања на дрога добиени од богатата хемиска структура на дрога (кодирана во СМИЛЕС) заедно со архитектурата на БИОБЕРТ базирана на вградуваое на дрога, специфична за доменот надвор од Експериментите спроведени на корпусот ДДИЕкстракција 2013 јасно покажуваат дека оваа стратегија ги подобрува другите силни основни архитектури за 3,4 отсто од макро-оценката Ф1.', 'ms': 'Versi biomedikal tradisional penyembedding yang diperoleh dari model bahasa terlatih telah baru-baru ini menunjukkan keputusan state-of-the-art untuk tugas ekstraksi hubungan (RE) dalam domain perubatan. Dalam kertas ini, kami mengeksplorasi bagaimana untuk memasukkan pengetahuan domain, tersedia dalam bentuk struktur molekul dadah, untuk meramalkan interaksi dadah-dadah dari korpus teks. Kami mengusulkan kaedah, BERTChem-DDI, untuk menggabungkan dengan efektif penyembedding dadah yang diperoleh dari struktur kimia kaya dadah (dikodifikasikan dalam SMILES) bersama dengan arkitektur RE berbasis BioBERT yang spesifik domain off-the-shelf. Eksperimen yang dilakukan pada korpus DDIExtraction 2013 jelas menunjukkan bahawa strategi ini memperbaiki arkitektur garis dasar kuat lain dengan 3.4% makro-skor F1.', 'ml': 'പഠിപ്പിക്കപ്പെട്ട ഭാഷ മോഡലുകളില്\u200d നിന്നും ലഭിക്കുന്ന പാഠമായ ജീവിയോമിക്കല്\u200d പതിപ്പുകള്\u200d മുമ്പ് പരിശീലന മാതൃകങ്ങളില്\u200d നിന്നും കിട്ടിയ ഈ പത്രത്തില്\u200d നമ്മള്\u200d കണ്ടെത്തുന്നത് എങ്ങനെയാണ് ഡൊമെയിനിലെ അറിവ് ഉള്\u200dപ്പെടുത്തേണ്ടതെന്ന്, മയക്കുമരുന്നുകളുടെ രൂപത്തില്\u200d ലഭ്യമാക്കുന്നത്,  ബെര്\u200dട്ടിചെമ്-ഡിഡിഐ നമ്മള്\u200d ഒരു രീതിയില്\u200d നിര്\u200dദ്ദേശിക്കുന്നു, സമ്പന്നതയുള്ള മരുന്നുകൊണ്ടുള്ള അടിസ്ഥാനത്തില്\u200d നിന്നും സാധാരണമായി കൂട്ടിക്കൊണ്ടുവരാന്\u200d മരുന്നുകളുടെ സ DDIExtraction 2013 കോര്\u200dപ്പുസില്\u200d നടത്തിയ പരീക്ഷണങ്ങള്\u200d വ്യക്തമായി തെളിയിക്കുന്നു ഈ strategy മറ്റു ശക്തിയുള്ള ബെസ്റ്റേലൈന്\u200d ആര്\u200dക്കിട്ടുകള്\u200d മുന്\u200dക', 'mn': 'Эхлээд сургалтын хэл загвараас авсан уламжлалтын биологийн эмнэлгийн хувилбар нь саяхан эмнэлгийн хэл загвараас хамтын үр дүнг харуулсан. Энэ цаасан дээр бид нарийн молекулын бүтээгдэхүүний хувьд хэрхэн хамтын мэдлэг бүрдүүлэхийг судалж байна. Мэдээж нарийн нарийн харилцааны харилцааныг textual corpus-аас таамаглах боломжтой. Бид, BERTChem-DDI-ын арга загвар, эмийн баян химийн бүтээгдэхүүнээс (SMILES-д кодлогдсон) бүтээгдэхүүнтэй хамтдаа эмийн бүтээгдэхүүнийг үр дүнтэй нэгтгэх гэсэн санал өгдөг. DDIExtraction 2013 корпус дахь туршилтын туршилт нь энэ стратеги нь бусад хүчтэй суурь шугамын архитектуруудыг 3.4% F1-н хэмжээнд сайжруулдаг гэдгийг тодорхой харуулж байна.', 'mt': 'Verżjoni bijomedika tradizzjonali ta’ inkorporazzjonijiet miksuba minn mudelli lingwistiċi mħarrġa minn qabel dan l-aħħar uriet riżultati l-aktar avvanzati għall-kompiti ta’ estrazzjoni ta’ relazzjonijiet (RE) fil-qasam mediku. F’dan id-dokument, nistudjaw kif inkorporaw l-għarfien tad-dominju, disponibbli fil-forma ta’ struttura molekulari tad-drogi, għat-tbassir tal-Interazzjoni bejn id-Drogi u d-Drogi minn korpus testwali. We propose a method, BERTChem-DDI, to efficiently combine drug embeddings obtained from the rich chemical structure of drugs (encoded in SMILES) along with off-the-shelf domain-specific BioBERT embedding-based RE architecture.  L-esperimenti mwettqa fuq id-DDIExtraction 2013 corpus jindikaw b’mod ċar li din l-istrateġija ttejjeb arkitetturi oħra b’linji bażi b’3.4% makro-punteġġ F1.', 'ro': 'Versiunea biomedicală tradițională a încorporărilor obținute din modele lingvistice pre-instruite a arătat recent rezultate de ultimă oră pentru sarcinile de extragere a relațiilor (RE) în domeniul medical. În această lucrare, explorăm cum să încorporăm cunoștințele de domeniu, disponibile sub forma structurii moleculare a medicamentelor, pentru predicția interacțiunii medicament-medicament din corpul textual. Propunem o metodă, BERTChem-DDI, pentru a combina eficient încorporarea medicamentelor obținute din structura chimică bogată a medicamentelor (codificată în SMILES) împreună cu arhitectura RE bazată pe încorporarea domeniului specific BioBERT. Experimentele efectuate pe corpul DDIExtraction 2013 indică clar faptul că această strategie îmbunătățește alte arhitecturi puternice de bază cu 3,4% scor macro F1.', 'pl': 'Tradycyjna biomedyczna wersja osadzeń uzyskana na podstawie wstępnie przeszkolonych modeli językowych pokazała ostatnio najnowocześniejsze wyniki dla zadań ekstrakcji relacji (RE) w dziedzinie medycznej. W artykule badamy, jak włączyć wiedzę domenową dostępną w postaci struktury molekularnej leków do przewidywania interakcji lekowo-lekowych z korpusu tekstowego. Proponujemy metodę BERTChem-DDI, aby skutecznie łączyć osadzenia leków uzyskane z bogatej struktury chemicznej leków (kodowane w SMILES) z gotową architekturą RE opartą na osadzeniu BioBERT. Eksperymenty przeprowadzone na korpusie DDIExtraction 2013 wyraźnie wskazują, że strategia ta poprawia inne silne architektury bazowe o 3,4% makro F1-score.', 'no': 'Tradisjonale biomedisinsk versjon av innbyggingar som er fått frå føretrainerte språk-modeller har nyleg vist tilstand-of-the-art-resultat for relasjonspakking (RE) oppgåver i medisinsk domenet. I denne papiret utforskar vi korleis domenekunnskap skal inkluderast, tilgjengeleg i form av molekylt struktur av narkotika, for å foregå narkotika-interaksjon frå tekstkorpus. Vi foreslår ein metode, BERTChem-DDI, for å effektivt kombinere innbygging av narkotika som er henta frå den rike kjemiske strukturen av narkotika (koda i SMILES) saman med off the-shelf-domenespesifikke bioBERT-basert RE-arkitektur. Eksperiment gjennomført på DDIExtraction 2013 corpus tyder klart på at denne strategien forbedrar andre sterke baselinjer med 3,4% makro F1- poeng.', 'sr': 'Tradicionalna biomedicinska verzija uključenih iz predobučenih jezičkih modela nedavno su pokazala rezultate stanja umjetnosti za izvlačenje odnosa (RE) zadataka u medicinskoj domenu. U ovom papiru istražujemo kako da uključimo znanje domena, dostupno u obliku molekularne strukture droge, za predviđanje interakcije droge iz tekstualnog korpusa. Predlažemo metodu, BERTChem-DDI, da efikasno kombinujemo integracije droge koje su dobile od bogate kemijske strukture droge (kodirane u SMILES) zajedno sa arhitekturom bioBERT-a na osnovu bioBERT-a, specifičnom domenu. Eksperimenti provedeni na korpusu DDIExtraction 2013 jasno ukazuju na to da ova strategija poboljšava druge jake osnovne arhitekture za 3,4% makro F1 rezultata.', 'si': 'Name මේ පත්තරේ අපි පරීක්ෂණය කරනවා කොහොමද දේමින් දන්නවත් සම්බන්ධ කරන්නේ, විද්\u200dයාවයේ මනුෂ්\u200dය සංවිධානයෙන් පුළුවන් විද්\u200d අපි ප්\u200dරශ්නයක්, BERTChem-DDI, විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් සම්බන්ධ විද්\u200dයාවක් සම්බන්ධ විද්\u200dයාවක් සම්බන්ධ වෙන්න පුළුවන් විශේෂයෙන් ව DDIExtraction 2013 කොර්පුස් වල පරීක්ෂණාවල් පැහැදිලිවම ප්\u200dරකාශයෙන් පෙන්වන්නේ මේ සංයෝජනය විශ්වාස කරනවා අනිත් ශක්තිමත් ප', 'so': 'Dalka caadiga ah ee warqadaha dhakhaatiirta ah ee noocyada afka hore laga helay waxay ugu dhowaad muuqatay arimaha la soo saaro (RE) shaqooyinka caafimaadka. Warqaddan waxaynu ka baaraannaa sida loo soo koobi karo aqoonta deegaanka, kaas oo loo heli karo qaabka dhakhaatiirta daawooyinka, si loo sii sheegayo Interugga Drugga ee dhakhtarka. Waxaynu soo jeedaynaa qaab, BERTChem-DDI, si fiican loogu soo wada ururiyo dawooyinka laga helay dhismaha hodantinimada kjemikamka ee dawooyinka (ku qoran SMILES) iyo qori-shelf domain-specific BioBERT oo ku saleysan RE-based architecture. Imtixaanka lagu sameeyay DDIExtraction 2013 corpus bayaan u muuqata in strategiyadu uu kordhiyo dhismaha kale oo xoogga leh ee qoriga hoose lagu sameeyo 3.4% macro F1 score.', 'sv': 'Traditionell biomedicinsk version av inbäddningar som erhållits från färdigutbildade språkmodeller har nyligen visat på state-of-the-art resultat för relationsextraktion (RE) uppgifter inom det medicinska området. I denna uppsats undersöker vi hur man kan införliva domänkunskap, tillgänglig i form av molekylär struktur av läkemedel, för att förutsäga Drug-Drug Interaction från textkorpus. Vi föreslår en metod, BERTChem-DDI, för att effektivt kombinera läkemedelsinbäddningar som erhållits från den rika kemiska strukturen hos läkemedel (kodade i SMILES) tillsammans med domänspecifik BioBERT inbäddningsbaserad RE-arkitektur. Experiment utförda på DDIExtraction 2013 corpus tyder tydligt på att denna strategi förbättrar andra starka baslinjearkitekturer med 3,4% makro F1-poäng.', 'ta': 'முன் பயிற்சிக்கப்பட்ட மொழி மாதிரிகளிலிருந்து பெற்ற பாரம்பரிய ஜியோமரிக்க வெளியீடுகளின் பதிப்பு இந்த காகிதத்தில், நாம் எவ்வாறு களம் அறிவை சேர்க்க வேண்டும் என்று கண்டறிக்கிறோம், மருந்துகள் வடிவத்தில் கிடைக்கும் வடிவமைப்பில், மருந்து இட We propose a method, BERTChem-DDI, to efficiently combine drug embeddings obtained from the rich chemical structure of drugs (encoded in SMILES) along with off-the-shelf domain-specific BioBERT embedding-based RE architecture.  DDIExtraction 2013 குறும்பத்தில் செயல்படுத்தப்பட்ட சோதனைகள் தெளிவாக இந்த திட்டம் 3. 4% மேக்ரோ F1- score மூலம் மேம்படுத்துகிறது என்பதை குறிக்கிறது.', 'ur': 'پہلے تدریس کی زبان مدلکوں سے حاصل ہونے والی ایمبڈینگ کی پیدائمی بیوڈینگ کی نسخہ اٹھانے کے لئے اٹھانے کے (RE) کاموں کے لئے اٹھانے کی حالت-of-the-art نتائج دکھائے گئے ہیں۔ اس کاغذ میں ہم دیکھتے ہیں کہ ڈومین علم کو کس طرح شامل کرنا ہے، مواد کی مولکولی ساختاری کے شکل میں موجود ہے، ڈروگ-ڈروگ اٹراکسٹیکशन کی پیش بینی کے لئے تفصیل کورپوس سے۔ ہم ایک طریقہ، BERTChem-DDI کی پیشنهاد کرتے ہیں، مواد کے مطابق مخلوقات کے مطابق مخلوقات کے مطابق مخلوقات کی رومیایی ساختار سے (SMILES میں کدھی گیا) حاصل کرنے کے لئے مخلوقات کے مطابق مخلوقات کو ترکیب کرنے کے لئے۔ DDIExtraction 2013 کورپوس کی تجربیات صریح دکھاتی ہے کہ یہ استراتژی دوسری قوی بنسس لین معماری 3.4% مکرو F1-اسکور سے بہتر ہوتی ہے.', 'uz': "Name Bu qogʻozda, biz narsalarning molekyl tuzuvlari shaklida qo'yishni qanday o'rganishni o'rganamiz, va texnologiya qo'llanmalarni kutib chiqarish uchun. Biz BERTChem-DDI, narsalarning hosil kemikali tuzuvlaridan (SMILES'da kodlash) qo'shilgan narsalarni ishlab chiqarish usuli bilan boshlanamiz. Name", 'vi': 'Truyền sinh sản của sự nhúng tay từ những mẫu ngôn ngữ được đào tạo trước đây đã cho thấy kết quả hiện đại nhất trong lĩnh vực y học về việc trích dẫn các mối quan hệ (R). Trong tờ giấy này, chúng tôi tìm hiểu làm thế nào để kết hợp kiến thức miền, có thể cung cấp trong cấu trúc phân tử của thuốc, để dự đoán giao thức ma túy từ tập thể hình. Chúng tôi đề xuất một phương pháp, BERTChem-DDI, để kết hợp các loại ma túy được lấy từ cấu trúc hóa chất giàu có của ma túy (mã hóa trong SMILS) cùng với các công trình nền kinh ngạc đặc trưng của BioBERT tái ghép lại dựa trên kiến trúc R. Các thí nghiệm về tập đoàn DDIExtvợ được thực thể rõ ràng cho thấy rằng chiến lược này cải thiện các cấu trúc cơ bản vững chắc khác bằng 3.4)', 'hr': 'Tradicionalna biomedicinska verzija uključenih iz predobučenih jezičkih modela nedavno je pokazala rezultate stanja umjetnosti za zadatke izvlačenja odnosa (RE) u medicinskoj domenu. U ovom papiru istražujemo kako uključiti znanje domena, dostupno u obliku molekularne strukture droge, za predviđanje interakcije droge i droge iz tekstualnog korpusa. Predlažemo metodu, BERTChem-DDI, kako bi učinkovito kombinirali ugrađenje lijekova koji su dobili od bogate kemijske strukture lijekova (kodirane u SMILES) zajedno s arhitekturom na temelju bioBERT-a na temelju izvan granice. Iskusi provedeni na korpusu DDIExtraction 2013 jasno ukazuju na to da ta strategija poboljšava druge jake osnovne arhitekture za 3,4% makro F1 rezultata.', 'bg': 'Традиционната биомедицинска версия на вграждания, получена от предварително обучени езикови модели, наскоро показа най-съвременни резултати за задачи за извличане на релации (РЕ) в областта на медицината. В тази статия изследваме как да включим домейна знания, налични под формата на молекулярна структура на лекарствата, за прогнозиране на взаимодействието лекарство-лекарство от текстов корпус. Предлагаме метод за ефективно комбиниране на вграждането на наркотици, получени от богатата химична структура на лекарствата (кодирани в SMILES), заедно с специфичната за домейна архитектура на базата на вграждането биоBERT архитектура. Експериментите, проведени върху корпуса на DDIExtraction 2013 ясно показват, че тази стратегия подобрява други силни базови архитектури с 3,4% макрос F1-резултат.', 'nl': 'Traditionele biomedische versies van embeddings verkregen uit voorgetrainde taalmodellen hebben recentelijk state-of-the-art resultaten getoond voor relationextractie (RE) taken in het medische domein. In dit artikel onderzoeken we hoe domeinkennis, beschikbaar in de vorm van moleculaire structuur van geneesmiddelen, kan worden geïntegreerd voor het voorspellen van Drug-Drug Interactie vanuit tekstueel corpus. We stellen een methode voor, BERTChem-DDI, om medicijnembeddingen verkregen uit de rijke chemische structuur van geneesmiddelen (gecodeerd in SMILES) efficiënt te combineren met standaard domeinspecifieke BioBERT embedding-based RE architectuur. Experimenten uitgevoerd op het DDIExtraction 2013 corpus geven duidelijk aan dat deze strategie andere sterke baselinearchitecturen verbetert met 3,4% macro F1-score.', 'da': 'Traditionel biomedicinsk version af embeddings opnået fra præuddannede sprogmodeller har for nylig vist state-of-the-art resultater for relationsudvinding (RE) opgaver på det medicinske område. I denne artikel undersøger vi, hvordan man indarbejder domæne viden, der er tilgængelig i form af molekylær struktur af lægemidler, til at forudsige Drug-Drug Interaction fra tekstkorpus. Vi foreslår en metode, BERTChem-DDI, til effektivt at kombinere lægemiddelindlejringer opnået fra den rige kemiske struktur af lægemidler (kodet i SMILES) sammen med off-the-shelf domænespecifikke BioBERT indlejringsbaseret RE arkitektur. Eksperimenter udført på DDIExtraction 2013 corpus tyder klart på, at denne strategi forbedrer andre stærke basisarkitekturer med 3,4% makro F1-score.', 'de': 'Traditionelle biomedizinische Einbettungen, die aus vortrainierten Sprachmodellen gewonnen wurden, haben kürzlich State-of-the-Art Ergebnisse für Relation Extraction (RE) Aufgaben im medizinischen Bereich gezeigt. In diesem Beitrag untersuchen wir, wie Domänenwissen, das in Form der molekularen Struktur von Medikamenten verfügbar ist, zur Vorhersage von Drug-Drug-Interaktionen aus textuellem Korpus einfließen kann. Wir schlagen eine Methode vor, BERTChem-DDI, um Wirkstoffeinbettungen, die aus der reichen chemischen Struktur von Medikamenten (kodiert in SMILES) gewonnen werden, effizient mit einer domänenspezifischen BioBERT-Einbettungsarchitektur zu kombinieren. Experimente am Korpus DDIExtraction 2013 zeigen deutlich, dass diese Strategie andere starke Baselinearchitekturen um 3,4% Makro F1-Score verbessert.', 'ko': '미리 훈련된 언어 모델에서 얻은 전통 생물의학 버전의 삽입은 최근 의학 분야의 관계추출(RE) 임무에서 가장 선진적인 결과를 보였다.본고에서 우리는 약물 분자 구조로 제공된 분야 지식을 어떻게 결합시켜 텍스트 자료 라이브러리에서 약물의 상호작용을 예측하는지를 연구했다.약물이 풍부한 화학구조(스마일코드)에서 얻은 약물 파묻기와 기존의 특정 분야 기반 바이오비트의 파묻기 재건구조를 효과적으로 결합하는 BERTChem DDI 방법을 제시했다.DDI 2013 어료 라이브러리에서 진행된 실험은 이 전략이 다른 강기선 체계 구조의宏F1 점수를 3.4% 높였다는 것을 분명히 나타냈다.', 'id': 'Versi biomedis tradisional dari embedding yang diperoleh dari model bahasa yang terlatih baru-baru ini menunjukkan hasil state-of-the-art untuk tugas ekstraksi hubungan (RE) di daerah medis. Dalam kertas ini, kami mengeksplorasi bagaimana untuk memasukkan pengetahuan domain, tersedia dalam bentuk struktur molekuler obat, untuk memprediksi interaksi obat-obat dari tubuh teks. Kami mengusulkan metode, BERTChem-DDI, untuk menggabungkan efisien penyembedding narkoba yang diperoleh dari struktur kimia kaya narkoba (terkodifikasi dalam SMILES) bersama dengan arsitektur RE berbasis BioBERT domain-spesifik off-the-shelf. Eksperimen yang dilakukan pada korpus DDIExtraction 2013 jelas menunjukkan bahwa strategi ini memperbaiki arsitektur garis dasar yang kuat lainnya dengan 3,4% makro-skor F1.', 'fa': 'نسخه\u200cی زیست\u200cپزشکی سنتی از مطالعه\u200cهای پیش آموزش یافته از مدل\u200cهای زبانی اخیرا نتیجه\u200cهای وضعیت-هنری برای اخراج (RE) وضعیت\u200cهای ارتباطی در دامنۀ پزشکی نشان داده\u200cاند. در این کاغذ، ما کشف می\u200cکنیم که چگونه علم دامنی را جمع کنیم، که در شکل ساختار مولکولی مولکولی مواد است، برای پیش\u200cبینی از تفاوت مواد مواد مخدر و مواد مخدر از جسد متن است. ما یک روش، BERTChem-DDI را پیشنهاد می\u200cکنیم تا موثرت\u200cآفرینش داروها را از ساختار شیمیایی ثروتمند داروها (که در SMILES kodیده شده) همراه با ساختار آفرینش آفرینش\u200cهای مخصوص بیوBERT که بر پایه\u200cی ساختار آفرینش\u200cهای آفرینش\u200cهای بیوBERT متصل شده، به طور مو تجربه\u200cهای DDIExtraction Corpus ۲۰۰۳ روشن نشان می\u200cدهد که این استراتژی باقی\u200cمانده\u200cهای پایه\u200cخط\u200cهای قوی با نمونه\u200cهای ۳.۴ درصد Makro F1 بهتر می\u200cشود.', 'tr': 'Edilmiş dil nusgalaryndan alınan däpli biomedical versiýasy medical domynda näme üçin state-of-the-art netijesi görkezildi. Bu kağıtda, sanat korpusundan uyuşturucu-uyuşturucu etkinleşimi şeklinde nähili domena bilgileri içereni keşfetýäris. BERTChem DDIExtraction 2013-nji korpusyň bardygyny öränler bu stratejiýanyň beýleki güýçli baz hatlary arhitekturmalaryny 3.4% makro F1-score bilen gowurandyrýandygyny belli edip bilýär.', 'sw': 'Toleo la kitamaduni la kitabibu la vifaa vinavyopatikana kutoka kwenye mitindo ya lugha zilizofunzwa kabla imeonyesha matokeo ya sanaa ya utekelezaji wa mazingira (RE) katika maeneo ya matibabu. Katika karatasi hii, tunachunguza jinsi ya kuingiza maarifa ya ndani, inayopatikana katika muundo wa molekylia wa dawa, kwa kutabiri namna ya kuingiza huduma ya dawa za madawa kutoka kwenye makampuni ya msingi. Tunazipendekeza njia, BERTChem-DDI, kuunganisha vifaa vya dawa vilivyopatikana kwa ufanisi kutoka kwenye muundo tajiri wa kemikali wa madawa (iliyoandikwa kwa SMILES) pamoja na ujenzi maalum wa BioBERT unaoandaliwa na viwanda vya RE. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other strong baselines architectures by 3.4% macro F1-score.', 'af': "Tradisjoneel biomediese weergawe van inbêdings wat vanaf voorafgevorderde taal modele ontvang het onlangs vertoon state-of-the-art resultate vir verwanting uitpakking (RE) opdragte in die mediese domein. In hierdie papier, ondersoek ons hoe om domein kennis te inkorporeer, beskikbaar in die vorm van molekuleer struktuur van drogs, vir voorskou van Drug-Drug Interaksie van tekstuurlike korpus. Ons voorstel 'n metode, BERTChem-DDI, om effektief narkotika inbettings te kombinerer wat van die ryk kemikatiese struktuur van narkotike ontvang word (in SMILES kodeerd) saam met af-die-shelf domein-spesifieke BioBERT-inbetering-gebaseerde RE-arkitektuur te kombinerer. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other strong baseline architectures by 3.4% macro F1-score.", 'am': 'የባሕላዊው የባሕላዊ መሠረት ድምፅ ከቀድሞ ተማሪ ቋንቋ ሞዴል የተገኘውን የድረአምባዊ የባሕላዊ ድምፅ በጥምቀት አካባቢ (RE) ስራዎችን ለመውጣት አግኝቷል፡፡ በዚህ ፕሮግራም፣ የዶሜን እውቀት እንዴት እንደሚያሳስብ እናደርጋለን፡፡ BERTChem-DDI (BERTChem-DDI) የሀብታም የኪሞክሪካ አካውንት (SMILES) በተለየ የዶሜይን ዶሜይን-ፍጥረት BioBERT በተመሳሳይ RE መሠረት እናሳስባታለን፡፡ በDDIExtraction 2013 ካርፓስ ላይ የተደረገውን ፈተና ይህ strategy ሌሎችን ብርቱ መሠረት መሠረቶች በ3.4 በመቶ ማክሮው F1-score እንዲያሳድግ ይገልጣል፡፡', 'az': '∆Źvv…ôlc…ô t…ôhsil edilmiŇü dil modellerind…ôn alńĪnan n…ôtic…ô biomedical versiyonu t…ôhsil edil…ôn m…ôlumatlarńĪn m…ôlumatlarńĪnńĪn …ôlaq…ôsi (RE) m…ôlumatlarńĪna son zamanlarda g√∂st…ôrmiŇüdir. Bu kańüńĪzda, m…ôktub korpusundan uyuŇüturucu-uyuŇüturucu interaksiyasńĪnńĪ √∂yr…ônm…ôk √ľ√ß√ľn, m…ôlumatlarńĪn m…ôlumatlarńĪnńĪ nec…ô inkiŇüaf ed…ôc…ôyini keŇüfetmiŇüik. Bel…ôlikl…ô, BERTChem-DDI metodlarńĪnńĪ t…ôklif edirik ki, UyuŇüturuqlarńĪn z…ôngin kimyasal quruluŇüundan (SMILES-d…ô kodlanmńĪŇü) √ľr…ôkl…ôrl…ô birl…ôŇüdirilmiŇü uyuŇüturucu in ŇüallarńĪnńĪ birl…ôŇüdirsin. DDIExtraction 2013 korpusu t…ôcr√ľb…ôl…ôrind…ô etdiyi t…ôcr√ľb…ôl…ôr bu strateji baŇüqa q√ľvv…ôtli s…ôhif…ôl…ôrin arhitektarńĪnńĪ 3,4% makro F1-score il…ô yaxŇüńĪlaŇüdńĪrńĪr.', 'bn': 'প্রথম প্রশিক্ষিত ভাষা মডেল থেকে পাওয়া প্রচলিত বায়োমেডিকেল সংস্করণ সম্প্রতি চিকিৎসার ডোমেইনে সম্পর্ক বের করার (RE) কাজের জন্য প্রতিষ্ঠানের এই কাগজটিতে আমরা খুঁজে বের করি কিভাবে ডোমেইনের জ্ঞান যুক্ত করতে পারি, যা মাদকের কাঠামোর আকারে পাওয়া যায়, যা কিভাবে পাওয়া যায়, টেক্সটুয়াল কো আমরা একটি পদ্ধতি প্রস্তাব করছি, বের্টিচেম-ডিডিআই, যাতে সমৃদ্ধ রাসায়নিক কাঠামো থেকে পেয়েছে (এসমিলিএস-এ এনকোড করা হয়েছে) যার সাথে শেল্ফ ডোমেইন-নির্দিষ্ট বিয়োবের্ট বিভিন্ন ভি ডিডিআইএক্সট্র্যাক্ট্র্যাকশন ২০১৩ কোর্পাসে অনুষ্ঠিত পরীক্ষার পরীক্ষা পরিষ্কার প্রমাণ করেছে যে এই কৌশল ৩. ৪% ম্যাক্রো এফ১ স্কো', 'bs': 'Tradicionalna biomedicinska verzija uključenih iz predobučenih jezičkih modela nedavno su pokazala rezultate stanja umjetnosti za izvlačenje odnosa (RE) zadataka u medicinskoj domenu. U ovom papiru istražujemo kako uključiti znanje domena, dostupno u obliku molekularne strukture droge, za predviđanje interakcije droge iz tekstualnog korpusa. Predlažemo metodu, BERTChem-DDI, kako bi efikasno kombinirali ugrađenje droge iz bogate kemijske strukture droge (kodirane u SMILES) zajedno s arhitekturom na osnovu bioBERT-a na osnovu bioBERT-a. Eksperimenti provedeni na korpusu DDIExtraction 2013 jasno ukazuju na to da ova strategija poboljšava druge jake osnovne arhitekture za 3,4% makro F1 rezultata.', 'cs': 'Tradiční biomedicínská verze vložení získaná z předškolených jazykových modelů v poslední době ukázala nejmodernější výsledky pro úlohy extrakce vztahů (RE) v lékařské oblasti. V tomto článku zkoumáme, jak začlenit doménové znalosti dostupné ve formě molekulární struktury léčiv pro predikci interakce léčiv-léčiv z textového korpusu. Navrhujeme metodu BERTChem-DDI, která efektivně kombinuje vložení léků získané z bohaté chemické struktury léků (kódované v SMILES) s standardní doménově specifickou architekturou BioBERT založenou na vložení RE. Experimenty provedené na korpusu DDIExtraction 2013 jasně ukazují, že tato strategie zlepšuje ostatní silné architektury základních linek o 3,4% makro F1 skóre.', 'sq': 'Versioni tradicional biomedikal i përfshirjeve të përfshira nga modelet e gjuhës së paratrajnuar kanë treguar kohët e fundit rezultate më të larta për detyrat e nxjerrjes së marrëdhënieve (RE) në fushën mjekësore. Në këtë letër, ne eksplorojmë si të përfshijmë njohuritë e domenit, të disponueshme në form ën e strukturës molekulare të drogës, për parashikimin e ndërveprimit të drogës-drogës nga korpusi tekstual. Ne propozojmë një metodë, BERTChem-DDI, për të kombinuar me efektshmëri përfshirjet e drogës të përfshira nga struktura kimike e pasur e drogave (të koduar në SMILES) së bashku me arkitekturën e BE-së bazuar në përfshirjen e domenit të jashtëm shelf BioBERT. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other strong baselines architectures by 3.4% macro F1-score.', 'et': 'Traditsioonilised biomeditsiinilised versioonid eelkoolitud keelemudelitest on hiljuti näidanud kaasaegseid tulemusi seoste ekstraheerimise (RE) ülesannete jaoks meditsiini valdkonnas. Käesolevas töös uurime, kuidas kasutada ravimite molekulaarse struktuuri kujul kättesaadavaid domeeniteadmisi ravimite ja ravimite koostoime prognoosimiseks tekstikorpusest. Pakume välja meetodi, BERTChem-DDI, et tõhusalt kombineerida ravimite rikkalikust keemilisest struktuurist saadud ravimite manustamist (kodeeritud SMILES-is) koos bioBERT manustamispõhise taastuvenergia arhitektuuriga. DDIExtraction 2013 korpusega läbi viidud katsed näitavad selgelt, et see strateegia parandab muid tugevaid baasarhitektuure 3,4% võrra F1 makroskoori võrra.', 'fi': 'Esikoulutetuista kielimalleista saadut perinteiset biol瓣瓣ketieteelliset versiot ovat viime aikoina osoittaneet viimeisimpi瓣 tuloksia relaatioekstraktioteht瓣viss瓣 l瓣瓣ketieteen alalla. T瓣ss瓣 artikkelissa selvit瓣mme, miten l瓣瓣keaineiden molekyylirakenteen muodossa saatavaa verkkotietoa voidaan hy繹dynt瓣瓣 l瓣瓣keaineiden yhteisvaikutuksen ennustamiseen tekstikorpusesta. Ehdotamme BERTChem-DDI-menetelm瓣瓣, jolla yhdistet瓣瓣n tehokkaasti l瓣瓣kkeiden rikkaasta kemiallisesta rakenteesta saadut upotukset (SMILES-koodattu) ja off-the-shelf-domain-spesifinen BioBERT upotuspohjainen RE-arkkitehtuuri. DDIExtraction 2013 -korpusella tehdyt kokeet osoittavat selv瓣sti, ett瓣 t瓣m瓣 strategia parantaa muita vahvoja perusrakenteita 3,4% F1-makropisteell瓣.', 'hy': 'Բիոբժշկական ներդրումների ավանդական բիոբժշկական տարբերակը, որը ստացվել է նախապատրաստված լեզվի մոդելներից, վերջերս ցույց են տվել վերջին արդյունքները բժշկական ոլորտում հարաբերությունների վերացման (ՌԵ) խնդիրների համար: Այս թղթի մեջ մենք ուսումնասիրում ենք, թե ինչպես ներառել տիեզերական գիտելիքներ, որոնք հասանելի են թմրադեղերի մոլեկուլային կառուցվածքի ձևով, թմրադեղերի և թմրադեղերի ինտերակցիայի կանխատեսման համար տեքստալ մարմնից: Մենք առաջարկում ենք մի մեթոդ, Բերթքիմ-ԴԻ, որպեսզի արդյունավետ համադրենք դեղամիջոցների ներդրումները, որոնք ստացվում են դեղամիջոցների հարուստ քիմիական կառուցվածքից (կոդավորված SMILes-ում) միասին բիոբերթ ներդրման կոնկրետ բիոբերթ ոլորտի ներդրման կոն 2013 թվականի DDiextraction կորպուսի վրա կատարված փորձարկումները ակնհայտորեն ցույց են տալիս, որ այս ռազմավարությունը բարելավում է այլ ուժեղ հիմնական ճարտարապետությունները 3.4 տոկոսով մակրո F1-ի գնահատականով:', 'ca': "La versió biomèdica tradicional d'incorporacions obtenides a partir de models de llenguatge pré-entrenats ha mostrat recentment resultats d'última generació per a les tasques d'extracció de relacions (RE) en el domini mèdic. En aquest paper, explorem com incorporar coneixements de domini, disponibles en forma d'estructura molecular de medicaments, per predir l'interacció entre medicaments del cos textual. Proposem un mètode, BERTChem-DDI, per combinar eficientment les incorporacions de medicaments obtenides de l'estructura química rica de medicaments (codificada en SMILES) juntament amb l'arquitectura RE basada en incorporació bioBERT específica en el domini off-shelf. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other strong baselines architectures by 3.4% macro F1-score.", 'jv': 'Name In this paper, we find out about the design of domain knowingthat, available in the format of individual structural of narkoties, for preview Drog-Drog interaction from textual Body. We proposal a method, BERT Kemik-DDN, to effectly combine narkotic embedding from the wealth Chinese structural of narkoties (kodkoded in SMIBESS) together with off-the-shell domain-special BIBERT embedding-supported RE architecture. The software is not installable and software can be accessable. Gebudhakan langkung barang nggawe DDEextration 2013 babagan kelas ngomongke ngerasahan punika ingkang dianggawe barang nggawe dolanan sing wis ambang barang 3.4% macro F1-punika.', 'sk': 'Tradicionalna biomedicinska različica vdelav, pridobljenih iz predhodno usposobljenih jezikovnih modelov, je nedavno pokazala najsodobnejše rezultate za naloge ekstrakcije relacij (RE) na medicinskem področju. V prispevku raziskujemo, kako vključiti domensko znanje, ki je na voljo v obliki molekularne strukture zdravil, za napovedovanje interakcije med zdravili iz besedilnega korpusa. Predlagamo metodo BERTChem-DDI za učinkovito kombiniranje vdelanih zdravil, pridobljenih iz bogate kemijske strukture zdravil (kodiranih v SMILES), skupaj z bioBERT vdelano arhitekturo, ki temelji na vdelanju, specifično za domeno. Eksperimenti, opravljeni na korpusu DDIExtraction 2013, jasno kažejo, da ta strategija izboljšuje druge močne osnovne arhitekture za 3,4% makro ocene F1.', 'ha': "@ info: status Ga wannan takardan, Munã yin amfani da yadda za mu shigar da ilmi a cikin wurãre, wanda ke da shi a cikin tsarin kullum na madawara, kuma don ka yi bayani ga aikin Nafi-Nafi daga nau'in rubutu. Tuna buɗar da wata hanyor, BERTchem-DDi, ta koma da amfani da dawwamamman da aka sãmu daga rikin matsayin chemical na narkoki (kodi cikin SMILES) sami da bayan-shelf-Domen-Specific BioBERT embedding-based re-architecture. Tajarakin da aka aikata a kan DDiExtration 2013, na bayyana bayan bayani, wannan zanyarci yana ƙara wasu matsakan masu ƙarfi da 3.4% macro F1-score.", 'he': 'גרסה ביו-רפואית מסורתית של תוכניות שנקבלו מדוגמנים לשפה מאומנים מראש הראה לאחרונה תוצאות חדשות למשימות חיפוש יחסים (RE) בתחום הרפואי. בעיתון הזה, אנו חוקרים כיצד להכיל ידע שטח, זמין בצורה של מבנה מולקולרי של תרופות, לחזות אינטראקציה סמים-סמים מהקורפוס טקסטולי. אנו מציעים שיטה, BERTChem-DDI, שילוב יעיל תוספות סמים שנוצאות מהמבנה הכימי העשיר של סמים (מוצפנים בסמיילס) יחד עם ארכיטקטורה המבוססת על תוספת ביוברט מחוץ למדף. ניסויים על הקורפוס של DDIExtraction 2013 מצביעים בבירור כי אסטרטגיה זו משפר ארכיטקטורות בסיסיות חזקות אחרות על ידי 3.4% נקודת מקרו F1.', 'bo': 'Traditional biomedical version of embeddings obtained from pre-trained language models have recently shown state-of-the-art results for relation extraction (RE) tasks in the medical domain. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ཁྱད་པར་དུ་གླེང་སྒྲའི་གནས་ཚུལ་འདྲ་ཞིག་དང་། We propose a method, BERTChem-DDI, to efficiently combine drug embeddings obtained from the rich chemical structure of drugs (encoded in SMILES) along with off-the-shelf domain-specific BioBERT embedding-based RE architecture. Experiments conducted on the DDIExtraction 2013 corpus clearly indicate that this strategy improves other strong baselines architectures by 3.4% macro F1-score.'}
