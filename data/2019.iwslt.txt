{'en': 'The IWSLT 2019 Evaluation Campaign', 'es': 'La campaña de evaluación de IWSLT 2019', 'fr': "La campagne d'évaluation 2019 de l'IWSLT", 'ar': 'حملة تقييم IWSLT 2019', 'pt': 'A Campanha de Avaliação do IWSLT 2019', 'zh': 'IWSLT 2019 评估', 'ru': 'Кампания по оценке IWSLT 2019', 'ja': 'IWSLT 2019評価キャンペーン', 'hi': 'IWSLT 2019 मूल्यांकन अभियान', 'ga': 'Feachtas Measúnaithe IWSLT 2019', 'ka': '2019 წლის IWSLT გამოსახულება', 'hu': 'Az IWSLT 2019 értékelési kampánya', 'el': 'Η εκστρατεία αξιολόγησης του IWSLT 2019', 'it': 'La campagna di valutazione IWSLT 2019', 'lt': 'IWSLT 2019 m. vertinimo kampanija', 'kk': '2019 IWSLT бағалау кампаниясы', 'mk': 'Кампањата за евалуација на IWSLT 2019', 'ms': 'Kampanye Evaluasi IWSLT 2019', 'mt': 'Il-Kampanja ta’ Evalwazzjoni tal-IWSLT 2019', 'mn': '2019 оны IWSLT дүгнэлт кампанийг', 'ml': 'IWSLT 2019 എവിലൂഷന്\u200d ക്യാമ്പെയിന്\u200d', 'pl': 'Kampania ewaluacyjna IWSLT 2019', 'sr': 'Kampanja za procjenu IWSLT 2019.', 'ro': 'Campania de evaluare IWSLT 2019', 'no': 'Evalueringskampanjen for IWSLT 2019', 'si': 'IWSLT 2019 විශ්ලේෂණ කම්පානය', 'so': 'IWSLT 2019 Kamcampaign evaluation', 'sv': 'Utvärderingskampanjen för IWSLT 2019', 'ta': 'IWSLT 2019 மதிப்பீடு விளையாட்டு', 'ur': 'IWSLT 2019 ارزش کمپین', 'uz': 'IWSLT 2019 tasdiqlash campaign', 'vi': 'Cảnh đánh giá IWSLT dùm tôi', 'da': 'Evalueringskampagnen for IWSLT 2019', 'bg': 'Кампания за оценка на IWSLT 2019', 'de': 'Die IWSLT 2019 Evaluierungskampagne', 'id': 'Kampanye Evaluasi IWSLT 2019', 'fa': 'کمپانی ارزیابی IWSLT 2019', 'sw': 'Kampeni ya Tathmini ya IWSLT 2019', 'nl': 'De IWSLT 2019 Evaluatiecampagne', 'hr': 'Kampanja za procjenu IWSLT 2019.', 'tr': 'IWSLT 2019 Ýyllama Kampany', 'af': 'Die IWSLT 2019-evalueringskampanje', 'ko': 'IWSLT 2019년 평가 활동', 'hy': 'IwPLT 2019 թվականի գնահատման քարոզարշավը', 'bn': 'IWSLT ২০১৯ প্রচারাভিযান', 'az': 'IWSLT 2019 Yaxınlıq Kampanyası', 'sq': 'Kampanja e vlerësimit të IWSLT 2019', 'bs': 'Kampanja za procjenu IWSLT 2019.', 'am': 'የIWSLT 2019 አድራሻ ዘመቻ', 'ca': "La campanya d'evaluació IWSLT 2019", 'fi': 'IWSLT 2019 -arviointikampanja', 'et': 'IWSLT 2019 hindamiskampaania', 'cs': 'Hodnotící kampaň IWSLT 2019', 'jv': 'kampanyen IWSLT 2011', 'he': 'קמפיין ההערכה של IWSLT 2019', 'ha': 'KCharselect unicode block name', 'sk': 'Akcija ocenjevanja IWSLT 2019', 'bo': 'The IWSLT 2019 Evaluation Campaign'}
{'en': 'The IWSLT 2019 evaluation campaign featured three tasks : speech translation of (i) ', 'ar': 'تضمنت حملة تقييم IWSLT 2019 ثلاث مهام: ترجمة الكلام لـ (1) محادثات TED و (2) مقاطع فيديو How2 التعليمية من الإنجليزية إلى الألمانية والبرتغالية ، و (3) ترجمة نصية لمحادثات TED من الإنجليزية إلى التشيكية. بالنسبة للمهمتين الأوليين ، شجعنا تقديم أنظمة تحويل الكلام إلى نص من طرف إلى طرف ، وبالنسبة للمهمة الثانية ، يمكن للمشاركين أيضًا استخدام الفيديو كمدخل إضافي. تلقينا تقديمات من 12 فريق بحث. تقدم هذه اللمحة العامة وصفاً مفصلاً للبيانات وشروط التقييم لكل مهمة وتقارير عن نتائج الأنظمة المشاركة.', 'fr': "La campagne d'évaluation IWSLT 2019 comportait trois tâches\xa0: traduction vocale de (i) conférences TED et (ii) vidéos pédagogiques How2 de l'anglais vers l'allemand et le portugais, et (iii) traduction de textes de conférences TED de l'anglais vers le tchèque. Pour les deux premières tâches, nous avons encouragé la soumission de systèmes de synthèse vocale de bout en bout, et pour la seconde tâche, les participants pouvaient également utiliser la vidéo comme entrée supplémentaire. Nous avons reçu des soumissions de 12 équipes de recherche. Cette vue d'ensemble fournit des descriptions détaillées des données et des conditions d'évaluation de chaque tâche et rend compte des résultats des systèmes participants.", 'pt': 'A campanha de avaliação do IWSLT 2019 apresentou três tarefas: tradução de fala de (i) palestras TED e (ii) vídeos instrucionais How2 de inglês para alemão e português e (iii) tradução de texto de palestras TED de inglês para tcheco. Para as duas primeiras tarefas, incentivamos o envio de sistemas de fala para texto de ponta a ponta e, para a segunda tarefa, os participantes também podiam usar o vídeo como entrada adicional. Recebemos submissões de 12 equipes de pesquisa. Esta visão geral fornece descrições detalhadas dos dados e condições de avaliação de cada tarefa e relata os resultados dos sistemas participantes.', 'es': 'La campaña de evaluación IWSLT 2019 incluyó tres tareas: traducción de voz de (i) charlas TED y (ii) vídeos instructivos de How2 del inglés al alemán y al portugués, y (iii) traducción de textos de las charlas TED del inglés al checo. Para las dos primeras tareas, alentamos el envío de sistemas de voz a texto de extremo a extremo, y para la segunda tarea, los participantes también pudieron usar el video como entrada adicional. Recibimos propuestas de 12 equipos de investigación. Esta descripción general proporciona descripciones detalladas de los datos y las condiciones de evaluación de cada tarea e informa los resultados de los sistemas participantes.', 'ja': 'IWSLT 2019評価キャンペーンでは、(i) TEDトークと(ii) How 2インストラクショナルビデオを英語からドイツ語とポルトガル語に、(iii) TEDトークを英語からチェコ語にテキスト翻訳するという3つのタスクが行われました。最初の2つのタスクでは、エンドツーエンドのスピーチツーテキストシステムの提出を奨励し、2番目のタスクの参加者はビデオを追加の入力として使用することもできました。12の研究チームから応募をいただきました。この概要では、各タスクのデータと評価条件の詳細な説明を行い、参加システムの結果を報告します。', 'zh': 'IWSLT 2019评估三务:(i)TED语音译、(ii)How2教学视频从英语翻译成德语、葡萄牙语,及(iii)TED演从英语翻译成捷克语本。 前二务者,劝提端到端语音转文本系统,其次,参与者亦得以视频为附输。 得12治团队投稿。 本概述备言每项事之数、评估,以告于统。', 'hi': 'IWSLT 2019 मूल्यांकन अभियान में तीन कार्य शामिल थे: (i) TED वार्ता का भाषण अनुवाद और (ii) अंग्रेजी से जर्मन और पुर्तगाली में How2 अनुदेशात्मक वीडियो, और (iii) अंग्रेजी से चेक में TED वार्ता का पाठ अनुवाद। पहले दो कार्यों के लिए हमने एंड-टू-एंड स्पीच-टू-टेक्स्ट सिस्टम की प्रस्तुतियों को प्रोत्साहित किया, और दूसरे कार्य के लिए प्रतिभागी वीडियो को अतिरिक्त इनपुट के रूप में भी उपयोग कर सकते हैं। हमें 12 शोध टीमों द्वारा प्रस्तुतियां प्राप्त हुईं। यह अवलोकन प्रत्येक कार्य के डेटा और मूल्यांकन शर्तों का विस्तृत विवरण प्रदान करता है और भाग लेने वाले सिस्टम के परिणामों की रिपोर्ट करता है।', 'ru': 'Кампания по оценке IWSLT 2019 включала три задачи: речевой перевод (i) выступлений TED и (ii) обучающих видеороликов How2 с английского на немецкий и португальский языки и (iii) текстовый перевод выступлений TED с английского на чешский язык. Для первых двух задач мы поощряли представление сквозных речевых текстовых систем, а для второй задачи участники также могли использовать видео в качестве дополнительного вклада. Мы получили материалы от 12 исследовательских групп. В настоящем обзоре содержится подробное описание данных и условий оценки каждой задачи и сообщается о результатах работы участвующих систем.', 'ga': 'Bhí trí thasc i gceist le feachtas meastóireachta IWSLT 2019: aistriúchán cainte ar (i) cainteanna TED agus (ii) físeáin teagaisc How2 ó Bhéarla go Gearmáinis agus Portaingéilis, agus (iii) aistriúchán téacs ar chainteanna TED ó Bhéarla go Seicis. Don chéad dá thasc spreagamar aighneachtaí ar chórais urlabhra-go-deireadh ó cheann ceann go ceann, agus don dara tasc d’fhéadfadh rannpháirtithe an fhís a úsáid mar ionchur breise freisin. Fuaireamar aighneachtaí ó 12 fhoireann taighde. Soláthraíonn an forbhreathnú seo cur síos mionsonraithe ar shonraí agus ar choinníollacha meastóireachta gach tasc agus tuairiscíonn sé torthaí na gcóras rannpháirteach.', 'ka': 'IWSLT 2019-ის განსაზღვრების კამპანიაში სამი მოქმედება: i) TED-ის განსაზღვრების განსაზღვრება და ii) How2 ინსტრუქციალური ვიდეოები ინგლისონიდან გერმანეთიდან და პორტეგუტიდან, და iii) TED-ის განსაზღვრების ტექსტი პირველი ორი დავალებისთვის ჩვენ დავიწყეთ საკუთარი სისტემის დასასრულებას, და მეორე დავალების დანაწილებელებისთვის შეგვიძლია გამოიყენოთ ვიდეო როგორც დამატებული დანაწილება. ჩვენ 12 სწავლობის განმავლობით მივიღეთ. ამ სახელსაწყისი განახლება ყველა დავალების მონაცემების და განახლების შესახელსაწყისი და გამოცემების შესახელსაწყისი.', 'hu': 'Az IWSLT 2019 értékelő kampány három feladatot tartalmazott: i) TED előadások és ii) How2 oktató videók beszédfordítása angolról németre és portugálra, valamint iii) TED előadások szövegfordítása angolról cseh nyelvre. Az első két feladat esetében ösztönöztük a végpontos beszéd-szöveg rendszerek benyújtását, a második feladat esetében pedig a résztvevők további bemenetként is használhatták a videót. 12 kutatócsoporttól kaptunk pályázatokat. Ez az áttekintés részletes leírást ad az egyes feladatok adatairól és értékelési feltételeiről, és jelentést ad a részt vevő rendszerek eredményeiről.', 'el': 'Η εκστρατεία αξιολόγησης του IWSLT 2019 περιελάμβανε τρία καθήκοντα: μετάφραση ομιλίας (i) ομιλιών TED και (ii) βίντεο διδασκαλίας How2 από τα αγγλικά στα γερμανικά και πορτογαλικά, και (iii) μετάφραση κειμένου ομιλιών TED από τα αγγλικά στα τσεχικά. Για τις δύο πρώτες εργασίες ενθαρρύναμε την υποβολή ολοκληρωμένων συστημάτων ομιλίας σε κείμενο και για τη δεύτερη εργασία οι συμμετέχοντες θα μπορούσαν επίσης να χρησιμοποιήσουν το βίντεο ως πρόσθετη εισαγωγή. Λάβαμε αιτήσεις από δώδεκα ερευνητικές ομάδες. Αυτή η επισκόπηση παρέχει λεπτομερείς περιγραφές των δεδομένων και των συνθηκών αξιολόγησης κάθε εργασίας και αναφέρει τα αποτελέσματα των συμμετεχόντων συστημάτων.', 'it': "La campagna di valutazione IWSLT 2019 ha caratterizzato tre compiti: traduzione vocale di (i) TED talks e (ii) How2 video didattici dall'inglese al tedesco e al portoghese, e (iii) traduzione testuale di TED talks dall'inglese al ceco. Per i primi due compiti abbiamo incoraggiato la presentazione di sistemi end-to-end speech-to-text, e per il secondo compito i partecipanti potrebbero anche utilizzare il video come input aggiuntivo. Abbiamo ricevuto contributi da 12 gruppi di ricerca. Questa panoramica fornisce descrizioni dettagliate dei dati e delle condizioni di valutazione di ogni attività e riporta i risultati dei sistemi partecipanti.", 'kk': 'IWSLT 2019 жылы бағалау кампаниясы үш тапсырманы көрсетті: i) TED сөйлерінің аударуы және ii) ағылшын тілінен неміс және португалдық тілінен қауіпсіздік видео аударуы және iii) TED сөйлерінің ағылшын тілінен чек Бірінші екі тапсырма үшін біз сөйлеу-мен-мәтін жүйелерін соңғы-аяқтау жүйесіне жіберу үшін көмектесдік. Екінші тапсырма қатысушылар да видеоны қосымша келтіру үші Біз 12 зерттеу командасынан жіберілген. Бұл тапсырма әрбір тапсырманың деректер мен оқу шарттарының егжей- тегжейі сипаттамаларын жұмыс істейді.', 'mk': 'The IWSLT 2019 evaluation campaign featured three tasks: speech translation of (i) TED talks and (ii) How2 instructional videos from English into German and Portuguese, and (iii) text translation of TED talks from English into Czech.  За првите две задачи ги охрабривме поднесувањата на системите од крај до крај на говор до текст, и за вторите задачи учесниците, исто така, можеа да го користат видеото како дополнителен влог. Примивме поднесувања од 12 истражувачки тимови. Овој преглед обезбедува детални описи на податоците и условите за евалуација на секоја задача и известува за резултатите на учествувачките системи.', 'ml': 'IWSLT 2019 വിലാസപ്രകാരം മൂന്നു ജോലികളുടെ കാര്യങ്ങള്\u200dക്കുള്ളതാണ്: ടെഡി സംസാരിക്കുന്നതിന്\u200dറെ (i) വാക്ക് അനുവാദം ചെയ്യുന്നതിന്\u200dറെ (ii) ഇംഗ്ലീഷില്\u200d നിന്നും ജര ആദ്യത്തെ രണ്ട് ജോലികള്\u200dക്കായി ഞങ്ങള്\u200d അവസാനിക്കുന്ന സംസാരത്തില്\u200d നിന്നും വാക്ക് വിശേഷങ്ങള്\u200d അവസാനിപ്പിക്കുന്നു. രണ്ടാമത്തെ ജോല 12 പരിശോധന കുടുംബങ്ങള്\u200d ഞങ്ങള്\u200dക്ക് കീഴടങ്ങള്\u200d ലഭിച്ചു. ഈ പ്രദര്\u200dശനത്തില്\u200d പങ്കുചേര്\u200dക്കുന്ന സിസ്റ്റത്തിന്റെ ഫലങ്ങള്\u200d വിശദീകരിക്കുന്ന ഡേറ്റാ വിവരങ്ങളും വിവരങ്ങളും വിവ', 'ms': 'Kampanye penilaian IWSLT 2019 mengandungi tiga tugas: terjemahan ucapan dari (i) perbincangan TED dan (ii) How2 video pengajaran dari Inggeris ke Jerman dan Portugis, dan (iii) terjemahan teks perbincangan TED dari Inggeris ke Cek. Untuk dua tugas pertama kami mendorong penghantaran sistem ucapan-ke-teks hujung-hujung, dan untuk peserta tugas kedua juga boleh menggunakan video sebagai input tambahan. Kami menerima pengiriman oleh 12 pasukan penyelidikan. Paparan ringkasan ini menyediakan deskripsi terperinci data dan keadaan penilaian setiap tugas dan laporan keputusan sistem yang berpartisipasi.', 'mt': 'Il-kampanja ta’ evalwazzjoni IWSLT 2019 kellha tliet kompiti: traduzzjoni tad-diskors ta’ (i) taħditiet TED u (ii) How2 vidjows ta’ tagħlim mill-Ingliż għall-Ġermaniż u l-Portugiż, u (iii) traduzzjoni tat-test ta’ taħditiet TED mill-Ingliż għaċ-Ċek. Għall-ewwel żewġ kompiti inkoraġġajna s-sottomissjonijiet ta’ sistemi ta’ diskors fit-test minn tmiem sa tmiem, u għat-tieni kompitu l-parteċipanti setgħu jużaw ukoll il-vidjo bħala input addizzjonali. Irċevejna sottomissjonijiet minn 12-il tim ta’ riċerka. Din il-ħarsa ġenerali tipprovdi deskrizzjonijiet dettaljati tad-dejta u l-kundizzjonijiet ta’ evalwazzjoni ta’ kull kompitu u tirrapporta r-riżultati tas-sistemi parteċipanti.', 'pl': 'Kampania ewaluacyjna IWSLT 2019 obejmowała trzy zadania: tłumaczenie mowy (i) wykładów TED i (ii) filmów instrukcyjnych How2 z języka angielskiego na niemiecki i portugalski oraz (iii) tłumaczenie tekstów wykładów TED z języka angielskiego na czeski. Dla dwóch pierwszych zadań zachęcaliśmy do zgłaszania kompleksowych systemów mowy-tekstowych, a dla drugiego zadania uczestnicy mogli również wykorzystać wideo jako dodatkowe wejście. Otrzymaliśmy zgłoszenia dwunastu zespołów badawczych. Przegląd ten zawiera szczegółowe opisy danych i warunków oceny każdego zadania oraz raportuje wyniki uczestniczących systemów.', 'lt': 'IWSLT 2019 m. vertinimo kampanijoje dalyvavo trys uždaviniai: i) TED kalbų vertimas kalbomis ir ii) How2 mokymo vaizdo įrašai i š anglų į vokiečių ir portugalų ir iii) TED kalbų vertimas tekstais iš anglų į čekų. Pirmosiose dviejose užduotyse skatinome teikti kalbos tekstui sistemas nuo vienos iki kitos, o antrosios užduoties dalyviai taip pat galėtų naudoti vaizdo įrašą kaip papildomą įrašą. Gavome 12 mokslinių tyrimų grupių pareiškimus. Šioje apžvalgoje pateikiami išsamūs kiekvienos užduoties duomenų ir vertinimo sąlygų aprašymai ir ataskaitos apie dalyvaujančių sistemų rezultatus.', 'ro': 'Campania de evaluare IWSLT 2019 a cuprins trei sarcini: traducerea discursurilor TED și (ii) videoclipurilor instrucționale How2 din engleză în germană și portugheză și (iii) traducerea textelor discursurilor TED din engleză în cehă. Pentru primele două sarcini am încurajat trimiterea unor sisteme end-to-end de vorbire-text, iar pentru a doua sarcină participanții ar putea folosi videoclipul ca input suplimentar. Am primit propuneri de la 12 echipe de cercetare. Această prezentare generală oferă descrieri detaliate ale datelor și condițiilor de evaluare ale fiecărei sarcini și raportează rezultatele sistemelor participante.', 'no': 'IWSLT 2019-evalueringskampanjen viste tre oppgåver: taleomsetjing av i) TED-taler og ii) How2 instruksjonsvideoar frå engelsk til tysk og portugisk, og iii) tekstomsetjing av TED-taler frå engelsk til tysk. For dei første to oppgåvene vart vi oppretta å senda inn av dei ende-til-slutt speech-to-text-systema, og for den andre oppgåvedeltakarane kunne også bruka videoen som ekstra inndata. Vi motteke tillegg av 12 forskningsgrupper. Denne oversikten gjev detaljerte skildringar av data og evalueringsvilkåra for kvar oppgåve og rapporter resultatet av deltakarsystemet.', 'so': 'Campaiino qiimeynta IWSLT 2019 waxaa ku qoran saddex shaqooyin: turjumista hadalka (i) TED talooyinkooda iyo (ii) How2 fiidiyooyin hagitaan oo ka yimid Ingiriis ilaa Jarmal iyo Burtuqiis, iyo (iii) tarjumaadda qoraalka TED ee afka Ingiriis ilaa Czech. Shaqooyinka ugu horreeyay ee ugu horeeyay waxaan ku dhiirrigelinnay inay soo dhiiraan nidaamka ugu dhammaadka-dhammaadka-ilaa-dhammaadka-text, kuwa ka qayb galana shaqada labaadna waxay sidoo kale u isticmaali karaan fiidiyowga sida input dheeraad ah. Waxaannu helnay warqado 12 koox waxbarasho ah. Tan overview waxay ka heleysaa qoraal gaar ah oo macluumaadka iyo qiimeynta shuruudaha shaqo walba iyo wargelinta arimaha nidaamka qayb-qaadashada.', 'sr': 'IWSLT 2019. evaluacijska kampanja uključila je tri zadatke: prevod govora o TED pregovorima i ii) How2 instruktivnih video sa engleskog na njemački i portugalski, i iii) prevod teksta TED pregovora sa engleskog na češki. Za prve dve zadatke smo potaknuli podatke sistema govora na tekst kraja do kraja, a za druge sudionike zadatka takođe bi mogli koristiti video kao dodatni ulaz. Dobili smo podatke od 12 istraživačkih timova. Ovaj pregled pruža detaljne opise podataka i uvjeta procjene svakog zadatka i izvještava rezultate sustava sudjelovanja.', 'si': 'IWSLT 2019 විශ්ලේෂණ ක්\u200dරියාපනය විශ්වාස කරන්නේ වැඩ තුනක් තියෙනවා: කතාවක් භාෂා කරනවා (i) TED කතාවක් සහ (i) How2 ක්\u200dරියාපනය වීඩියෝ ඉංග්\u200dරීසියෙන පලවෙනි වැඩක් දෙකට අපි අවසානයෙන් කතා කරන්න පුළුවන් විදියෝ අවසානයෙන් අවසානය කරන්න පුළුවන් විදියෝ අවසානයෙන් ප්\u200dරවේශ අපිට පරීක්ෂණා කණ්ඩායම් 12 කණ්ඩායම් එක්ක පිළිගන්න පුළුවන්. මේ ප්\u200dරවේශනය ප්\u200dරවේශනය විස්තර විස්තර විස්තර කිරීම සහ අවශ්\u200dය ස්ථානය සහ ප්\u200dරවේශනය විස්තර කිරීම සහ ප්\u200d', 'mn': 'IWSLT 2019 оны оюун шалгалтын кампанид 3 даалгавар тавьсан: i) TED ярианы хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн Эхний хоёр даалгаварын тулд бид ярианы төгсгөл-төгсгөл-төгсгөл-төгсгөл-төгсгөл-төгсгөл-төгсгөл-төгсгөл-төгсгөл-төгсгөл системийн тусламжтай Бид 12 судалгааны багийн сургуульд авсан. Энэ тодорхойлолт нь ажил бүрийн өгөгдлийн, үнэлгээний нөхцөл байдлын талаар нарийвчлалтай тодорхойлолтуудыг харуулдаг.', 'sv': 'Utvärderingskampanjen IWSLT 2019 innehöll tre uppgifter: talöversättning av (i) TED-föreläsningar och (ii) How2-instruktionsvideor från engelska till tyska och portugisiska, och (iii) textöversättning av TED-föreläsningar från engelska till tjeckiska. För de två första uppgifterna uppmuntrade vi inlämningar av tal-till-text-system, och för den andra uppgiften kunde deltagarna också använda videon som ytterligare input. Vi fick bidrag från 12 forskargrupper. Denna översikt ger detaljerade beskrivningar av data och utvärderingsvillkor för varje uppgift och rapporterar resultaten från de deltagande systemen.', 'ta': 'IWSLT 2019 மூன்று பணிகள் குறிப்பிடப்பட்டுள்ளது: பேச்சு மொழிபெயர்ப்பு (i) TED பேச்சுகள் மற்றும் (ii) ஆங்கிலத்திலிருந்து ஜெர்மன் மற்றும் போர்த்துகீசிக்குள் காட முதல் இரண்டு பணிகளுக்கு நாம் முடிவில் இருந்து பேச்சு முறைமையில் இருந்து உரை அமைப்புகளை ஒப்புக்கொள்ள உறுதிப்படுத்தினோம், மற்று 12 ஆராய்ச்சி குழுக்களால் நாங்கள் கட்டளைகள் கிடைத்தது. @ info', 'ur': 'IWSLT 2019 کی ارزیابی کمپین نے تین کاموں کو شامل کیا: i) TED صحبت کی تعلیم اور ii) ہو۲ انگلیسی سے جرمانی اور پورٹوګیسی میں استعمال ویڈیوں کی تعلیم اور (iii) TED صحبت کی تفسیر انگلیسی سے چک میں۔ ہم نے پہلی دو کاموں کے لئے آخر-to-end speech-to-text سیستم کی تعلیم کی قول دی اور دوسرے کام شرکت کرنے والوں کے لئے ویڈیو کو اضافہ کے طور پر بھی استعمال کر سکتے تھے. ہم نے 12 تحقیق تیموں کے ذریعہ مسلمانوں کو ملا۔ This overview provides detailed descriptions of the data and evaluation conditions of each task and reports the results of the participating systems.', 'uz': "IWSLT 2019 qiymati kampeni uchta vazifalar bilan iborat qiladi: talab tarjima qilish (i) TED talablaridan (i) va (ii) Inglizchadan Inglizchadan Olmoncha va Portugalcha tilidan How2 taʼminlovchi video va (iii) Inglizchadan TED talablarining matn tarjima qilish chekschaga. Birinchi ikki vazifalar uchun biz oxirigi gapiruvchi va matn tizim tizimini qo'shish imkoniyatini ishlatdik, ikkinchi vazifaning qismlari uchun video yozib kirishi mumkin. Biz 12 taʼminlovchi guruhlar tomonidan imzolangan. @ info", 'vi': 'Trong chiến dịch đánh giá IWSLT 2009 gồm ba nhiệm vụ: Bản dịch diễn văn của buổi nói chuyện: i) cuộc nói chuyện: Từ người Anh đến người Anh, người Bồ Đào Nha, còn cả bản dịch về Ted từ tiếng Anh đến Séc. Đối với hai nhiệm vụ đầu tiên, chúng tôi khuyến khích sự phát biểu của hệ thống ngôn ngữ-văn-kết thúc (kết thúc) và đối với người phụ trách thứ hai cũng có thể dùng đoạn video làm thêm. Chúng tôi đã nhận được tin tức từ 12. Thông tin này cung cấp mô tả chi tiết về dữ liệu và môi trường đánh giá của mỗi nhiệm vụ và báo cáo kết quả của hệ thống tham gia.', 'bg': 'Кампанията за оценка включваше три задачи: речен превод на (i) лекции и (ii) инструкционни видеоклипове от английски на немски и португалски и (iii) текстов превод на лекции от английски на чешки. За първите две задачи насърчихме подаването на системи от край до край реч към текст, а за втората задача участниците също можеха да използват видеото като допълнителен вход. Получихме предложения от 12 изследователски екипа. Този преглед предоставя подробни описания на данните и условията за оценка на всяка задача и докладва резултатите от участващите системи.', 'da': 'IWSLT 2019 evalueringskampagnen omfattede tre opgaver: taleoversættelse af (i) TED-foredrag og (ii) How2 instruktionsvideoer fra engelsk til tysk og portugisisk, og (iii) tekstoversættelse af TED-foredrag fra engelsk til tjekkisk. Til de første to opgaver opfordrede vi til indsendelse af end-to-end tale-to-text systemer, og til den anden opgave kunne deltagerne også bruge videoen som ekstra input. Vi modtog indlæg fra 12 forskerhold. Denne oversigt indeholder detaljerede beskrivelser af data og evalueringsbetingelser for hver opgave og rapporterer resultaterne af de deltagende systemer.', 'hr': 'IWSLT 2019. evaluacijska kampanja uključila je tri zadatke: prevod govora o i) TED pregovorima i ii) How2 instrukcijskih snimaka s engleskog na njemački i portugalski, i iii) prevod teksta TED pregovora s engleskog na češki. Za prve dvije zadatke smo potaknuli podatke sustava govora do teksta, a za druge sudionike zadatka također bi mogli koristiti video kao dodatni ulaz. Dobili smo podatke od 12 istraživačkih timova. Ovaj pregled pruža detaljne opise podataka i uvjeta procjene svakog zadatka i izvješća rezultata sustava sudjelovanja.', 'nl': "De IWSLT 2019 evaluatiecampagne bestond uit drie taken: spraakvertaling van (i) TED talks en (ii) How2 instructievideo's van het Engels naar het Duits en het Portugees, en (iii) tekstvertaling van TED talks van het Engels naar het Tsjechisch. Voor de eerste twee taken moedigden we het indienen van end-to-end spraak-to-text systemen aan, en voor de tweede taak konden deelnemers de video ook gebruiken als extra input. We kregen inzendingen van twaalf onderzoeksteams. Dit overzicht geeft gedetailleerde beschrijvingen van de gegevens en evaluatievoorwaarden van elke taak en rapporteert resultaten van de deelnemende systemen.", 'de': 'Die Evaluationskampagne IWSLT 2019 umfasste drei Aufgaben: Sprachübersetzung von (i) TED-Vorträgen und (ii) How2-Lehrvideos aus dem Englischen ins Deutsche und Portugiesische und (iii) Textübersetzung von TED-Vorträgen aus dem Englischen ins Tschechische. Für die ersten beiden Aufgaben ermutigten wir die Einreichung von End-to-End-Sprach-Systemen, und für die zweite Aufgabe konnten die Teilnehmer das Video auch als zusätzlichen Input nutzen. Wir erhielten Einreichungen von zwölf Forschungsteams. Diese Übersicht bietet detaillierte Beschreibungen der Daten und Auswertungsbedingungen jeder Aufgabe und berichtet über die Ergebnisse der teilnehmenden Systeme.', 'id': 'Kampanye evaluasi IWSLT 2019 mengandung tiga tugas: terjemahan pidato dari (i) pembicaraan TED dan (ii) How2 video instruksional dari Inggris ke Jerman dan Portugis, dan (iii) terjemahan teks dari pembicaraan TED dari Inggris ke Cek. Untuk dua tugas pertama kami mendorong pengiriman sistem dari akhir ke akhir berbicara ke teks, dan untuk peserta tugas kedua juga dapat menggunakan video sebagai input tambahan. Kami menerima pengiriman dari 12 tim penelitian. Penjelasan ini menyediakan deskripsi rinci dari data dan kondisi evaluasi setiap tugas dan laporan hasil dari sistem yang berpartisipasi.', 'ko': 'IWSLT 2019년 평가 활동에는 (i)TED 강연과 (ii)How2 교학 영상을 영어에서 독일어와 포르투갈어로 번역하고, (iii)TED 강연을 영어에서 체코어로 번역하는 세 가지 임무가 있다.앞의 두 가지 임무에 대해 우리는 끝까지 음성을 텍스트 시스템에 제출하는 것을 권장하고 두 번째 임무에 대해 참여자도 영상을 추가 입력으로 사용할 수 있다.우리는 12개 연구진이 제출한 의견서를 받았다.이 개요에서는 각 작업에 대한 데이터 및 평가 기준을 자세히 설명하고 시스템 참여 결과를 보고합니다.', 'fa': 'کمپین ارزیابی IWSLT ۲۰۱۹ سه تا کار را مشخص کرد: ترجمه سخنرانی (i) صحبت TED و (ii) ویدئو آموزشی از انگلیسی به آلمان و پورتوژیک و (iii) ترجمه متن TED صحبت از انگلیسی به چک. برای اولین دو وظیفه تحویل دادیم از سیستم\u200cهای گفتگو به متن آخر و پایان آخر، و برای شرکت دوم وظیفه\u200cای هم می\u200cتوانند از ویدئو به عنوان ورودی اضافه استفاده کنند. ما توسط 12 تیم تحقیقات تحقیقات فرستادیم. این روش توضیح\u200cهای جزئیات داده\u200cها و شرایط ارزیابی هر کار و نتیجه\u200cهای سیستم\u200cهای شرکت\u200cکننده را پیشنهاد می\u200cدهد.', 'sw': 'Kampeni ya uchunguzi wa IWSLT 2019 ilionyesha kazi tatu: tafsiri ya hotuba (i) mazungumzo ya TED na (ii) video za uongozi kutoka Kiingereza hadi Ujerumani na Kireno, na tafsiri ya maandishi ya mazungumzo ya TED kutoka Kiingereza kwenda Kizech. Kwa kazi mbili za kwanza tuliwahamasisha kuutumiwa kwa mfumo wa hotuba hadi mwisho wa maandishi, na kwa washiriki wa juhudi la pili pia wanaweza kutumia video hii kama input wa ziada. Tulipata ujumbe wa timu 12 za utafiti. Tovuti hii inatoa maelezo ya taarifa na upatikanaji wa mazingira ya kila kazi na taarifa za matokeo ya mfumo wa ushiriki.', 'tr': 'IWSLT 2019-nji ýylyň barlamasynyň kampanyasynda üç zady belirtdi: i) TED gürrüňleriniň terjimesini we (ii) How2 i ňlisçe we portugalça dilinden gürrüňlemeli videolar we (iii) TED-iňlisçe häçe dilinden gürrüňlemeli metin terjimesini. İlk iki görev için "end-to-end speech-to-text sistemlerine" teklif sistemlerini teslim ettik ve ikinci görev iştirakçilerine göre videoyu daha fazla giriş olarak kullanabilirdik. 12 araşdyrma toparynyň suratlaryny aldyk. Bu ýagdaý görnöşi her zadyň maglumatyň we çykyş şartlarynyň detayly tassymlaryny temin edir we paýlaşýan sistemlerin netijesini berir.', 'sq': 'Fushata e vlerësimit IWSLT 2019 paraqiti tre detyra: përkthimi i fjalës i (i) bisedimeve të TED dhe (ii) How2 videove mësuese nga anglisht në gjermanisht dhe portugalsht dhe (iii) përkthimi teksti i bisedimeve të TED nga anglisht në çek. Për dy detyrat e para ne inkurajuam paraqitjen e sistemeve nga fundi në fund të fjalimit në tekst dhe për pjesëmarrësit e dytë të detyrës mund të përdorin gjithashtu videon si input shtesë. Ne morëm paraqitje nga 12 ekipe kërkimore. Ky përmbledhje ofron përshkrime të hollësishme të të dhënave dhe kushteve të vlerësimit të çdo detyre dhe raporton rezultatet e sistemeve pjesëmarrëse.', 'af': 'Die IWSLT 2019-evalueringskampanie het drie taak gedoen: spraak vertaling van (i) TED praat en (ii) How2 instruksionele videos van Engels na Duits en Portugees en (iii) teks vertaling van TED praat van Engels na Tsjechse. Vir die eerste twee taak het ons die voorskrywings van die einde-na-einde spreek-na-teks stelsels, en vir die tweede taak deelnaders kon ook die video as addisionele invoer gebruik. Ons ontvang onderstellings deur 12 ondersoek teams. Hierdie oorskou verskaf gedetale beskrywings van die data en evaluering voorwaardes van elke taak en rapporteer resultate van die deelnadende stelsels.', 'am': 'የIWSLT 2019 ማስታወቂያ ዘመቻ ሦስት አድራጊዎች: ንግግር ትርጉም (i) ቴድ ንግግር እና (ii) ሆw2 የመግለጫ ቪዲዮች ከንግግሊዝና ጀርመን እና ፖርቱጋልኛ እና (iii) የቴድ ንግግር ትርጉም ጽሑፍ ትርጉም ከንግግሊዝኛ ወደ ቻክክ ነው። ለመጀመሪያዎቹ ሁለት ስራዎች የንግግር-ወደ-መጨረሻ-የጽሑፍ ስርዓቶች መዘዋወር እና ለሁለተኛው ስራ ተጋሪዎች ደግሞ የቪዲዮውን ጥያቄ ለመጠቀም ይችላሉ፡፡ በ12 ምርመራ ቡድን አዋጅ ተቀበልን፡፡ ይህ overview የሁሉንም ስራ እና የአካባቢው ስርዓት ውጤቶች የሚጠይቁትን የዳታ እና የአካባቢ ውጤቶች እና የስርዓት ውጤቶች የሚያሳውቅ ትርጉም ይሰጣል።', 'hy': 'IwPLT 2019 թվականի գնահատման քարոզարշավը ներկայացրեց երեք խնդիր: i) TED ելույթների խոսքի թարգմանությունը, և i) Ինչպես 2 ուսուցման տեսանյութեր անգլերենից գերմաներեն և պորտուգալերեն, և III) TED ելույթների տեքստի թարգմանությունը անգլերե Առաջին երկու հանձնարարությունների համար մենք խրախուսեցինք վերջ-վերջ խոսքի-տեքստի համակարգերի ներկայացումը, և երկրորդ հանձնարարության մասնակիցները կարող էին օգտագործել տեսագրությունը որպես ավելին ներմուծք: Մենք ստացանք 12 հետազոտական խմբի ներկայացումներ: Այս ընդհանուր դիտարկումը պարունակում է յուրաքանչյուր խնդրի տվյալների և գնահատման պայմանների մանրամասն նկարագրություններ, ինչպես նաև ներկայացնող համակարգերի արդյունքները:', 'az': 'IWSLT 2019 değerlendirmə kampanyası üç görev göstərdi: i) TED danışmalarının danışması və ii) How2 İngilizdən Almanca və Portugalca danışması və iii TED danışmalarının mətn çevirisi İngilizdən Çəkə danışması. İlk iki işlər üçün sona-sona-sona söz-mətn sistemlərini təsdiqlədik və ikinci işlər iştirakçıların video də artıq girişi olaraq istifadə edə bilərdilər. Biz 12 araşdırma tərəfindən göndərdik. Bu görünüş hər işin verilən məlumatların və değerlendirmə şartlarının detaylı tanımlamalarını və iştirak sistemlərin sonuçlarını bildirir.', 'bn': 'আইউএসএলটি ২০১৯ মূল্য প্রচারণা তিনটি কাজের বিশেষ করে দেয়া হয়েছে: ভাষণ অনুবাদ (i) টেডি আলোচনা এবং (ii) ইংরেজী থেকে জার্মান এবং পর্তুগীজে হাউ২ নির্দেশিত ভিডিও এবং (আই)  প্রথম দুটি কাজের জন্য আমরা শেষ-পর্যন্ত বক্তৃতা থেকে টেক্সট সিস্টেমের প্রতি উৎসাহ প্রদান করেছি এবং দ্বিতীয় কাজের অংশগ্রহণকারী ১২ গবেষণা দলের দ্বারা আমাদের অনুপ্রেরণা পেয়েছে। এই সার্ভিউ প্রত্যেক কাজের তথ্য এবং মূল্য পরিস্থিতির বিস্তারিত বর্ণনা এবং অংশগ্রহণকারী সিস্টেমের ফলাফলের প্রত', 'bs': 'IWSLT 2019. evaluacijska kampanja uključila je tri zadatke: prevod govora o TED pregovorima i ii) How2 instruktivnih snimaka sa engleskog na njemački i portugalski, i iii) prevod teksta TED pregovora sa engleskog na češki. Za prve dvije zadatke smo potaknuli podatke sustava govora do teksta, a za druge sudionike zadatka također bi mogli koristiti video kao dodatni ulaz. Dobili smo podatke od 12 istraživačkih timova. Ovaj pregled pruža detaljne opise podataka i uvjeta procjene svakog zadatka i izvještava rezultate sustava sudjelovanja.', 'ca': "La campanya d'evaluació de l'IWSLT 2019 va comportar tres tasques: traducció del discurs i) conferències TED i ii) How2 vídeos instructius d'anglès a alemany i portuguès, i iii) traducció del text de conferències TED d'anglès a cec. Per les dues primeres tasques vam animar la presentació de sistemes de discurs fins a text, i per la segona tasca els participants també podrien utilitzar el vídeo com entrada adicional. Vam rebre presentacions de 12 equips de recerca. Aquesta panorama proporciona descripcions detalladas de les dades i condicions d'evaluació de cada tasca i informa dels resultats dels sistemes participants.", 'cs': 'Evaluační kampaň IWSLT 2019 obsahovala tři úkoly: překlad řeči (i) TED přednášek a (ii) instrukční videa How2 z angličtiny do němčiny a portugalštiny a (iii) textový překlad TED přednášek z angličtiny do češtiny. Pro první dva úkoly jsme podporovali předkládání komplexních systémů řeči-textu a pro druhý úkol mohli účastníci video použít i jako další vstup. Obdrželi jsme podání dvanácti výzkumných týmů. Tento přehled poskytuje podrobný popis dat a podmínek hodnocení každého úkolu a podává zprávy o výsledcích zúčastněných systémů.', 'et': 'IWSLT 2019 hindamiskampaania hõlmas kolme ülesannet: i) TED kõnede tõlkimine ja ii) How2 õppevideod inglise keelest saksa ja portugali keelde ning iii) TED kõnede tõlkimine inglise keelest tšehhi keelde. Kahe esimese ülesande puhul julgustasime esitama täiendavaid kõne-teksti süsteeme ning teise ülesande puhul said osalejad kasutada videot lisasisendina. Saime ettepanekud 12 uurimisrühma poolt. Selles ülevaates kirjeldatakse üksikasjalikult iga ülesande andmeid ja hindamistingimusi ning esitatakse osalevate süsteemide tulemused.', 'fi': 'IWSLT 2019 -arviointikampanja sisälsi kolme tehtävää: i) TED-puheiden ja ii) How2-opetusvideoiden puhekääntäminen englannista saksaksi ja portugaliksi sekä iii) TED-puheiden tekstikääntäminen englannista tšekkiin. Kahdessa ensimmäisessä tehtävässä rohkaisimme end-to-end-speech-to-text-järjestelmien lähettämistä, ja toisessa tehtävässä osallistujat saivat käyttää videota myös lisäsyötteenä. Saimme ehdotuksia 12 tutkimusryhmältä. Tässä yleiskatsauksessa kuvataan yksityiskohtaisesti kunkin tehtävän tiedot ja arviointiehdot sekä raportoidaan osallistuvien järjestelmien tulokset.', 'jv': 'kampanya IWSLT 2011 sing entuk sing nyengkuyung telu operasi: pitik nglarani (i) nglarani (i) nglarani (i) When a nglarani (i) When a nglarani video sing perusahaan Inggris ngangge Pertualisan lan Pertualisan, lan (i ii) When a nglarani video sing tarjamahan kanggo tyang inglisan ngangge Pertualisan. Awak dhéwé éntuk sistem sing perusahaan tanggal gawe nguasai video gampang- to-end language-to-text sistem, lan kanggo sampeyan segondi task gawe nguasai video lagi wis dianggap Awak dhéwé éntuk kelas telu 12 ngresmi. Awakdhéwé iki nggawe akeh mbéksi tindakan data lan asserti durung nggawe barang nggawe barang sistem sing nyeangke tarjamahan.', 'sk': 'Ocenjevalna kampanja IWSLT 2019 je obsegala tri naloge: prevajanje govora (i) TED govorov in (ii) učnih videoposnetkov How2 iz angleščine v nemščino in portugalščino ter (iii) prevajanje besedila TED govorov iz angleščine v češčino. Za prvi dve nalogi smo spodbujali oddajo celovitih sistemov govora v besedilo, za drugo nalogo pa so lahko udeleženci uporabili video kot dodatni vhod. Dobili smo prispevke 12 raziskovalnih ekip. Ta pregled vsebuje podrobne opise podatkov in pogojev ocenjevanja vsake naloge ter poroča o rezultatih sodelujočih sistemov.', 'ha': "The IWSLT 2019 evaluation campcampin feature three tasks: language translation (i) TeD talks and (ii) How2 instructive video from English to Jarman and Portuguesi, and (ii) text translation of TeD talks from English to Czech. Ji da na farkon aikin biyu, muka ƙara wa musulunta-ƙari-na-matsayin-zuwa-matsayi, kuma dõmin masu haɗi da aikin na farko, za'a iya amfani da video kamar ƙari. Mun motsa misãlai da jama'a 12. Wannan bayani na buga bayani na faƙatan bayani na data da evaluation muhalli na kõwane aikin, da ƙidãyayyuta na musamman masu haɗuwa.", 'he': "קמפיין הערכה IWSLT 2019 פירסם שלושה משימות: תרגום נאום של (i) שיחות TED ו (ii) How2 וידאו הוראה מאנגלית לגרמנית ופורטוגזית, ו (iii) תרגום טקסט של שיחות TED מאנגלית לצ'ק. לשני המשימות הראשונות העדכנו את ההעברות של מערכות נאום לטקסט מסוף-לסוף, ולמשתתפי המשימה השנייה יכולים גם להשתמש בסרטון כתוצאה נוספת. קיבלנו הצעות של 12 קבוצות מחקר. המראה המפורסמת הזו מספקת תיאורים מפורסמים של הנתונים והתנאי הערכה של כל משימה ודווחים על תוצאות המערכות המשתתפות.", 'bo': 'The IWSLT 2019 evaluation campaign featured three tasks: speech translation of (i) TED talks and (ii) How2 instructional videos from English to German and Portuguese, and (iii) text translation of TED talks from English to Czech. ངེད་ཚོས་བྱ་རིམ་དང་པོ་གཉིས་ཀྱིས་མཇུག་བསྡུ་བའི་སྐད་ཡིག་གི་མ་ལག་གི་ཚིག་མཉམ་དུ་འཇུག་སྣོད་ཀྱི་མ་ལག་སྟར་བྱེད་སྐབས་ཡིན་ཐབས ང་ཚོས་དབྱེ་ཞིབ་བྱེད་པའི་ཆ་ཚོད་ལྡན་གཉིས་དང་། བྱ་འགུལ་སྔོན་ལྟ་ཀློག་སྟངས་དེ་རེ་བ་མ་ལག་གི་ཐོག་ལས་ཆ་འཕྲིན་དང་གསལ་བཤད་མང་ཙམ་སྟོན་པ་ཡིན།'}
{'en': 'ESPnet How2 Speech Translation System for IWSLT 2019 : Pre-training, Knowledge Distillation, and Going Deeper', 'ar': 'نظام ترجمة الكلام ESPnet How2 لـ IWSLT 2019: التدريب المسبق وتقطير المعرفة والتعمق أكثر', 'pt': 'Sistema de tradução de fala ESPnet How2 para IWSLT 2019: pré-treinamento, destilação de conhecimento e aprofundamento', 'fr': 'Système de traduction vocale ESPnet How2 pour IWSLT 2019\xa0: pré-formation, distillation des connaissances et approfondissement', 'es': 'Sistema de traducción de voz ESPNet How2 para IWSLT 2019: preentrenamiento, destilación de conocimientos y profundización', 'ja': 'IWSLT 2019用ESPnet How 2音声翻訳システム：事前トレーニング、ナレッジディスティレーション、さらに深く', 'ru': 'Система перевода речи ESPnet How2 для IWSLT 2019: предварительное обучение, дистилляция знаний и углубление', 'zh': 'ESPnet How2 Speech Translation System for IWSLT 2019:预培训、知识深入', 'hi': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'ga': 'Córas Aistriúcháin Cainte ESPnet How2 le haghaidh IWSLT 2019: Réamh-oiliúint, Driogadh Eolais, agus Ag dul níos doimhne', 'ka': 'ESPnet How2 სიტყვების განსაგულისხმების სისტემა IWSLT 2019: წინ განსაგულისხმების, მეცნიერების განსაგულისხმების, და Going Deeper', 'el': 'Σύστημα μετάφρασης ομιλίας για την Προεκπαίδευση, απόσταξη γνώσεων και βαθύτερη πορεία', 'hu': 'ESPnet How2 beszédfordító rendszer az IWSLT 2019-hez: előképzés, tudás desztilláció és mélyebb menet', 'it': 'Sistema di traduzione vocale ESPnet How2 per IWSLT 2019: pre-formazione, distillazione della conoscenza e approfondimento', 'lt': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'kk': 'ESPnet How2 IWSLT 2019 жылы сөздерді аудару жүйесі: алдындағы оқыту, білім жетілдіру және Going Deeper', 'mk': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation and Going Deeper', 'ml': 'IWSLT 2019- നുള്ള എസ്പിനെറ്റ് ഹോവ്2 പ്രസ്താവ വ വിഭാഷ സിസ്റ്റം: മുന്\u200dപരിശീലനം, അറിവ് ഡിസ്ട്രിലേഷന്\u200d, ആഴത്തിലേക്ക', 'ms': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'mn': 'ESPnet How2 ярианы хөгжлийн хөгжлийн систем IWSLT 2019: Өмнөх сургалт, мэдлэг халдвар, Going Deeper', 'ro': 'Sistemul de traducere a vorbirii ESPnet How2 pentru IWSLT 2019: Pre-training, distilarea cunoștințelor și mergerea mai profundă', 'no': 'ESPnet How2 taleomsetjingssystem for IWSLT 2019: Førehandsvising, kjennomsetjingsstyrke og går dyper', 'pl': 'ESPnet How2 System tłumaczenia mowy dla IWSLT 2019: Przedszkolenia, destylacja wiedzy i głębsze wejście', 'sr': 'ESPnet How2 rečni prevodni sistem za IWSLT 2019: Preobuka, destilacija znanja i odlaska dublje', 'so': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Distribution of Knowledge, and Going Deeper', 'si': 'ESPnet How2 කතා පරිවර්තන පද්ධතිය IWSLT 2019: ප්\u200dරධාන ප්\u200dරශ්නයක්, දැනගැනීම විස්තර, සහ Going Deeper', 'sv': 'ESPnet How2 Talöversättningssystem för IWSLT 2019: Pre-training, kunskapsdestillation och gå djupare', 'mt': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'ta': 'ESPnet How2 பேச்சு மொழிபெயர்ப்பு அமைப்பு', 'ur': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'uz': 'IWSLT 2019 uchun ESPnet How2 Talk tarjima tizimi: Pre-training, Known Distillation and Deeper Going', 'vi': 'Hệ thống dịch ngôn ngữ ESPN How2 for IWSLT 209: pre-huấn luyện, sự phân sáng, and Going Sâu hơn', 'hr': 'ESPnet How2 govorni prevodni sustav za IWSLT 2019: Preobuka, destilacija znanja i odlaska dublje', 'da': 'ESPnet How2 taleoversættelsessystem til IWSLT 2019: Pre-training, videndedestillation og gå dybere', 'bg': 'Система за превод на реч за Предварително обучение, дестилация на знанието и задълбочаване', 'nl': 'ESPnet How2 spraakvertaalsysteem voor IWSLT 2019: Voortraining, kennisdestillatie en dieper gaan', 'id': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'de': 'ESPnet How2 SprachĂ¼bersetzungssystem fĂ¼r IWSLT 2019: Vortraining, Wissensdestillation und tiefer gehen', 'ko': '2019년 IWSLT의 ESPnet How2 음성 번역 시스템: 사전 교육, 지식 추출과 깊이 있는 학습', 'tr': 'ESPnet How2 IWSLT 2019: Öňki okuwçy, Bilgi Taýýarlama we Going Dereje', 'fa': 'ESPnet How2 System Translation Speech for IWSLT 2019: Pre-training, Destillation of Knowledge, and Going Deeper', 'sw': 'ESPnet How2 Mfumo wa Tafsiri wa How2 kwa ajili ya IWSLT 2019: Ufunzi wa kabla ya mafunzo, Ujuzi, na Kuelekea zaidi', 'af': 'ESPnet How2 Spraak Vertaling Stelsel vir IWSLT 2019: Vooroerring, kennis verstyling en Going Deeper', 'sq': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Distillation of Knowledge, and Going Deeper', 'az': 'ESPnet How2 S칬z T톛rc칲m톛 Sistemi IWSLT 2019: 칐nceki t톛hsil, Bilim Destilm톛si v톛 Going Deeper', 'am': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation and Going Deeper', 'hy': '2019 թվականի IW-ՍԼT-ի համար', 'bs': 'ESPnet How2 govorni prevodni sistem za IWSLT 2019: Preobuka, destilacija znanja i odlaska dublje', 'ca': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper', 'et': 'ESPnet How2 kõnetõlkesüsteem IWSLT 2019: eelkoolitus, teadmiste destilleerimine ja sügavamale minek', 'fi': 'ESPnet How2 puhekäännösjärjestelmä IWSLT 2019: esikoulutus, tietämyksen tislaus ja syvemmälle meneminen', 'bn': 'IWSLT ২০১৯ এর জন্য ESPnet How2 ভাষণ অনুবাদ সিস্টেম: প্রশিক্ষণ, জ্ঞান বিভ্রান্ত, এবং গভীরে যাচ্ছে', 'cs': 'ESPnet How2 překladový systém řeči pro IWSLT 2019: Předškolení, destilace znalostí a jít hlouběji', 'jv': 'ESPnet Ho2 Terjamahan Panjenengan Sistem kanggo IWSLT 2011: Mbak-terjamahan, Distiljut Panjenengan, lan Going deep', 'sk': 'ESPnet How2 govorni prevajalni sistem za IWSLT 2019: predusposabljanje, destilacija znanja in globlje', 'ha': 'ESPnet How2 Spelling Translate system for IWSLT 2019: Pre-Training, Dislitation of ilmi, and Going Deƙaser', 'he': 'ESPnet How2 מערכת תרגום דיבורים עבור IWSLT 2019: אימון מראש, דיסטילציה של ידע, ונכנס עמוק יותר', 'bo': 'ESPnet How2 Speech Translation System for IWSLT 2019: Pre-training, Knowledge Distillation, and Going Deeper'}
{'en': 'This paper describes the ESPnet submissions to the How2 Speech Translation task at IWSLT2019. In this year, we mainly build our systems based on Transformer architectures in all tasks and focus on the end-to-end speech translation (E2E-ST). We first compare RNN-based models and Transformer, and then confirm Transformer models significantly and consistently outperform RNN models in all tasks and corpora. Next, we investigate pre-training of E2E-ST models with the ASR and MT tasks. On top of the pre-training, we further explore knowledge distillation from the NMT model and the deeper speech encoder, and confirm drastic improvements over the baseline model. All of our codes are publicly available in ESPnet.', 'ar': 'تصف هذه الورقة عمليات إرسال ESPnet إلى مهمة How2 Speech Translation في IWSLT2019. في هذا العام ، قمنا ببناء أنظمتنا بشكل أساسي استنادًا إلى بنيات المحولات في جميع المهام والتركيز على ترجمة الكلام من طرف إلى طرف (E2E-ST). نقارن أولاً النماذج المستندة إلى RNN والمحولات ، ثم نؤكد أن نماذج Transformer تتفوق بشكل كبير ومتسق على نماذج RNN في جميع المهام والمجموعات. بعد ذلك ، نتحرى عن التدريب المسبق لنماذج E2E-ST مع مهام ASR و MT. علاوة على التدريب المسبق ، نستكشف تقطير المعرفة من نموذج NMT ومشفّر الكلام الأعمق ، ونؤكد التحسينات الجذرية على النموذج الأساسي. جميع رموزنا متاحة للجمهور في ESPnet.', 'es': 'Este documento describe los envíos de ESPnet a la tarea de traducción de voz How2 en IWSLT2019. Este año, construimos principalmente nuestros sistemas basados en arquitecturas Transformer en todas las tareas y nos centramos en la traducción de voz de extremo a extremo (E2E-ST). Primero comparamos los modelos basados en RNN y Transformer, y luego confirmamos que los modelos Transformer superan de manera significativa y consistente a los modelos RNN en todas las tareas y cuerpos. A continuación, investigamos la capacitación previa de los modelos E2E-ST con las tareas de ASR y MT. Además de la capacitación previa, exploramos más a fondo la destilación de conocimientos del modelo NMT y el codificador de voz más profundo, y confirmamos mejoras drásticas con respecto al modelo de referencia. Todos nuestros códigos están disponibles públicamente en ESPnet.', 'fr': "Ce document décrit les soumissions d'ESPNet dans le cadre de la tâche de traduction vocale How2 à l'IWSLT2019. Cette année, nous construisons principalement nos systèmes basés sur des architectures Transformer dans toutes les tâches et nous nous concentrons sur la traduction vocale de bout en bout (E2E-ST). Nous comparons d'abord les modèles basés sur RNN et Transformer, puis nous confirmons que les modèles Transformer surpassent de manière significative et constante les modèles RNN dans toutes les tâches et tous les corpus. Ensuite, nous étudions la pré-formation des modèles E2E-ST avec les tâches ASR et MT. En plus de la pré-formation, nous explorons la distillation des connaissances à partir du modèle NMT et de l'encodeur vocal plus profond, et nous confirmons des améliorations drastiques par rapport au modèle de base. Tous nos codes sont accessibles au public sur ESPnet.", 'pt': 'Este artigo descreve os envios da ESPnet para a tarefa How2 Speech Translation no IWSLT2019. Neste ano, construímos principalmente nossos sistemas baseados em arquiteturas Transformer em todas as tarefas e focamos na tradução de fala de ponta a ponta (E2E-ST). Primeiro comparamos modelos baseados em RNN e Transformer e, em seguida, confirmamos que os modelos Transformer superam significativamente e consistentemente os modelos RNN em todas as tarefas e corpora. Em seguida, investigamos o pré-treinamento dos modelos E2E-ST com as tarefas ASR e MT. Além do pré-treinamento, exploramos ainda mais a destilação do conhecimento do modelo NMT e do codificador de fala mais profundo e confirmamos melhorias drásticas em relação ao modelo de linha de base. Todos os nossos códigos estão disponíveis publicamente na ESPnet.', 'hi': 'यह पेपर IWSLT2019 पर How2 वाक् अनुवाद कार्य के लिए ESPnet प्रस्तुतियों का वर्णन करता है। इस वर्ष में, हम मुख्य रूप से सभी कार्यों में ट्रांसफॉर्मर आर्किटेक्चर के आधार पर अपने सिस्टम का निर्माण करते हैं और अंत-से-अंत भाषण अनुवाद (E2E-ST) पर ध्यान केंद्रित करते हैं। हम पहले RNN-आधारित मॉडल और ट्रांसफॉर्मर की तुलना करते हैं, और फिर ट्रांसफॉर्मर मॉडल की पुष्टि करते हैं और लगातार सभी कार्यों और कॉर्पोरेट में RNN मॉडल को मात देते हैं। अगला, हम एएसआर और एमटी कार्यों के साथ ई 2 ई-एसटी मॉडल के पूर्व-प्रशिक्षण की जांच करते हैं। पूर्व-प्रशिक्षण के शीर्ष पर, हम आगे एनएमटी मॉडल और गहरे भाषण एन्कोडर से ज्ञान आसवन का पता लगाते हैं, और बेसलाइन मॉडल पर कठोर सुधार की पुष्टि करते हैं। हमारे सभी कोड सार्वजनिक रूप से ESPnet में उपलब्ध हैं।', 'zh': '本文引 IWSLT2019 上 How2 语音译者 ESPnet。 今年构基于Transformer架构统,专于端到端语音译(E2E-ST)。 先较RNN之与Transformer,然后Transformer之于任与语料库中显,终始RNN于形。 臣等考用 ASR MT , E2E-ST 模范预训练。 预培训之基,探其NMT深层次之音编码器,审其大基线。 凡诸代码皆公给于ESPnet。', 'ja': 'この論文では、IWSLT 2019のHow 2 Speech TranslationタスクへのESPnetの提出について説明します。今年は、すべてのタスクでTransformerアーキテクチャに基づいたシステムを構築し、エンドツーエンドの音声翻訳（ E 2 E - ST ）に焦点を当てています。まず、RNNベースのモデルとトランスフォーマーを比較し、次にすべてのタスクとコーポラルでトランスフォーマーモデルがRNNモデルを大幅かつ一貫して上回っていることを確認します。次に、ASRおよびMTタスクを使用したE 2 E - STモデルの事前トレーニングについて調査します。事前トレーニングに加えて、NMTモデルとより深い音声エンコーダからの知識蒸留をさらに探り、ベースラインモデルよりも劇的な改善を確認します。当社のコードはすべてESPnetで公開されています。', 'ru': 'В этой статье описываются представления ESPnet для задачи перевода речи How2 на IWSLT2019. В этом году мы в основном строим наши системы на основе архитектур Transformer во всех задачах и фокусируемся на сквозном переводе речи (E2E-ST). Сначала мы сравниваем модели на основе RNN и Transformer, а затем подтверждаем, что модели Transformer значительно и последовательно превосходят модели RNN во всех задачах и группах. Далее мы исследуем предварительное обучение моделей E2E-ST с задачами ASR и MT. В дополнение к предварительному обучению мы дополнительно изучаем дистилляцию знаний на основе модели НМТ и более глубокого кодирования речи и подтверждаем радикальные улучшения по сравнению с базовой моделью. Все наши коды общедоступны в ESPnet.', 'ga': 'Déanann an páipéar seo cur síos ar aighneachtaí ESPnet don tasc Aistriú Cainte How2 ag IWSLT2019. I mbliana, tógaimid go príomha ár gcórais bunaithe ar ailtireachtaí Trasfhoirmeora i ngach tasc agus dírímid ar an aistriúchán cainte ó cheann ceann go ceann (E2E-ST). Déanaimid comparáid idir samhlacha RNN-bhunaithe agus Trasfhoirmeoir ar dtús, agus ansin deimhnímid samhlacha Trasfhoirmeoir go suntasach agus go seasta níos fearr ná samhlacha RNN i ngach tasc agus corpora. Ansin, déanaimid imscrúdú ar réamhoiliúint ar shamhlacha E2E-ST leis na tascanna ASR agus MT. Anuas ar an réamhoiliúint, déanaimid iniúchadh breise ar dhriogadh eolais ón tsamhail NMT agus ón ionchódóir cainte níos doimhne, agus deimhnímid feabhsuithe móra thar an tsamhail bhunlíne. Tá ár gcód go léir ar fáil go poiblí in ESPnet.', 'hu': 'Ez a tanulmány bemutatja az ESPnet beadványait az IWSLT2019 How2 beszédfordítási feladatához. Ebben az évben elsősorban Transformer architektúrákon alapuló rendszereinket építjük ki minden feladatban, és az end-to-end beszédfordításra (E2E-ST) összpontosítunk. Először összehasonlítjuk az RNN alapú modelleket és a Transformert, majd megerősítjük, hogy a Transformer modellek jelentősen és következetesen felülmúlják az RNN modelleket minden feladatban és corporában. Ezt követően az E2E-ST modellek előképzését vizsgáljuk ASR és MT feladatokkal. Az előképzés tetején tovább vizsgáljuk az NMT modellből és a mélyebb beszédkódolóból származó tudás desztillációt, és megerősítjük a drasztikus javulást az alapmodellhez képest. Minden kódunk nyilvánosan elérhető az ESPneten.', 'el': 'Η παρούσα εργασία περιγράφει τις υποβολές του ESPnet στο έργο Μετάφραση ομιλίας How2 στο IWSLT2019. Φέτος, κατασκευάζουμε κυρίως τα συστήματά μας βασισμένα σε αρχιτεκτονικές σε όλες τις εργασίες και εστιάζουμε στην ολοκληρωμένη μετάφραση ομιλίας (ΕΟΕ-ST). Πρώτα συγκρίνουμε μοντέλα βασισμένα σε και μετασχηματιστή και στη συνέχεια επιβεβαιώνουμε ότι τα μοντέλα μετασχηματιστή ξεπερνούν σημαντικά και σταθερά τα μοντέλα σε όλες τις εργασίες και σώματα. Στη συνέχεια, διερευνούμε την προεκπαίδευση των μοντέλων με τις εργασίες ASR και MT. Εκτός από την προεκπαίδευση, εξερευνούμε περαιτέρω την απόσταξη γνώσεων από το μοντέλο και τον βαθύτερο κωδικοποιητή ομιλίας, και επιβεβαιώνουμε δραστικές βελτιώσεις σε σχέση με το μοντέλο βάσης. Όλοι οι κωδικοί μας είναι δημόσιοι διαθέσιμοι στο ESPnet.', 'ka': 'ამ წიგნის აღწერა ESPnet-ის გადაწერების შეტყობინება საუკეთესო სიტყვების გადაწყვეტის საქმე IWSLT2019-ში. ამ წლის განმავლობაში ჩვენ ჩვენი სისტემები შევქმნით ყველა საქმების განმავლობაში ტრანფორმეტრის აქტიქტიქტურის ბაზეზე და კონუქტურაციას დასრულებული სიტყვების განმა ჩვენ პირველად RNN-დაბათი მოდელები და ტრანფორმაციის შემდეგ გადაწყენებთ და შემდეგ ტრანფორმაციის მოდელების მნიშვნელოვანი და მუშაობელოვანი RNN მოდელების შემდეგ ყველა დავალებში შემდეგ, ჩვენ E2E-ST მოდელების წინ შესწავლობთ ASR და MT დავალებით. ჩვენ უფრო უფრო მეტად განვიცემების განსხვავება NMT მოდელიდან და უფრო დიბოლო სიტყვა კოდერიდან, და დარწმუნეთ დირასტიური უფრო მეტადება ბაზლინის მოდელიდან. გჟთფკთ ნთ კჲეთ ჟა ოსბლთფნჲ ეჲჟრაგვნთ გ ESPnet.', 'it': "Questo articolo descrive i contributi di ESPnet al compito How2 Speech Translation di IWSLT2019. In quest'anno, costruiamo principalmente i nostri sistemi basati su architetture Transformer in tutte le attività e ci concentriamo sulla traduzione vocale end-to-end (E2E-ST). Prima confrontiamo modelli basati su RNN e Transformer, e poi confermiamo che i modelli Transformer superano significativamente e costantemente i modelli RNN in tutte le attività e corpora. Successivamente, esaminiamo la pre-formazione dei modelli E2E-ST con le attività ASR e MT. Oltre al pre-training, esploriamo ulteriormente la distillazione della conoscenza dal modello NMT e dal codificatore vocale più profondo, e confermiamo miglioramenti drastici rispetto al modello di base. Tutti i nostri codici sono pubblicamente disponibili in ESPnet.", 'lt': 'Šiame dokumente aprašomi ESPnet pranešimai apie How2 kalbos vertimo užduotį IWSLT2019. Šiais metais daugiausia kuriame savo sistemas, grindžiamas Transformer architektūromis, atliekant visas užduotis ir daugiausia dėmesio skiriame kalbos vertimui nuo pabaigos (E2E-ST). Pirmiausia palyginame RNN pagrįstus modelius su Transformer, o vėliau patvirtiname Transformer modelius reikšmingai ir nuosekliai viršijančius RNN modelius visose užduotyse ir korpora. Toliau tiriame E2E-ST modelių parengiamąjį mokymą atliekant ASR ir MT užduotis. Be parengiamojo mokymo, toliau tiriame NMT modelio ir gilesnio kalbos kodavimo žinių distiliavimą ir patvirtiname drastiškus pokyčius, palyginti su pradiniu modeliu. Visi mūsų kodai viešai skelbiami ESPnet tinkle.', 'kk': 'Бұл қағаз IWSLT2019 жылы "How2 Speech Translation" тапсырмасына ESPnet жіберілімдерін таңдайды. Бұл жылда, біз жүйелерімізді түрлендіру архитектурасына негізделген жүйелерді бүкіл тапсырмаларда құрып, аяқтау- аяқтау аудармасына (E2E- ST) көздейміз. Біз біріншіден RNN негіздеген үлгілерді және түрлендірушілерді салыстырып, кейін түрлендіруші үлгілерді маңызды және әрбір тапсырмалардың және корпорада RNN үлгілерін салы Келесіден, біз ASR және MT тапсырмаларымен E2E-ST моделдерінің алдындағы оқытуын зерттейміз. Алдыңғы оқытудың үстінде, NMT үлгісінен білім түрлендірімізді және үлкен сөйлендіру кодерінен бастап, негізгі үлгісінен драстикалық жақсартуларды тексеріп тұрмыз. Барлық кодтарымыз ESPnet-де жалпы жұмыс істейді.', 'ml': 'ഈ പേപ്പറിന്\u200dറെ എസ്പിനെറ്റിന്\u200dറെ സമര്\u200dപ്പിക്കുന്നത് IWSLT2019-ല്\u200d ഹൌ2 സ്പീസ് പരിഭാഷണ ജോലിയിലേക്കാണ്. ഈ വര്\u200dഷത്തില്\u200d, ഞങ്ങള്\u200d പ്രധാനപ്പെട്ട നമ്മുടെ സിസ്റ്റമുകള്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d ആര്\u200dക്കിട്ടുകളില്\u200d അടിസ്ഥാനമാക്കി എല്ലാ ജോലികളില ആദ്യം നമ്മള്\u200d RNN-അടിസ്ഥാനമായ മോഡലുകളെയും ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റുന്നതിനെയും തുല്യമാക്കുന്നു. പിന്നീട് ട്രാന്\u200dസ്ഫോര്\u200dമാറ്റ് മ പിന്നെ നമ്മള്\u200d എസ്ആരും എംടി ജോലികളുമായി E2E-ST മോഡലുകള്\u200d പരിശീലിക്കുന്നത് അന്വേഷിക്കുന്നു. മുമ്പ് പരിശീലനത്തിന്\u200dറെ മുകളില്\u200d നമ്മള്\u200d NMT മോഡലില്\u200d നിന്നും ആഴത്തെ സംസാര കോഡിഡരില്\u200d നിന്നും അറിവ് വേര്\u200dപെടുത്തുന്നത് പരിശോധിക് ഞങ്ങളുടെ എല്ലാ കോഡുകളും എസ്പിനെറ്റില്\u200d പ്രത്യേകം ലഭ്യമാണ്.', 'mk': 'Овој документ ги опишува поднесувањата на ЕСПнет на задачата How2 Speech Translation на IWSLT2019. Оваа година, главно ги градиме нашите системи базирани на трансформерните архитектури во сите задачи и се фокусираме на преводот на говорот од крај до крај (E2E-ST). We first compare RNN-based models and Transformer, and then confirm Transformer models significantly and consistently outperform RNN models in all tasks and corpora.  Следно, истражуваме предобука на моделите Е2E-ST со задачите на АСР и МТ. Покрај предобуката, понатаму ја истражуваме дистилацијата на знаење од моделот НМТ и подлабокиот говорен кодер, и потврдиме драстични подобрувања во однос на основниот модел. Сите наши кодови се јавно достапни на ЕСПнет.', 'ms': 'Kertas ini menggambarkan penghantaran ESPnet kepada tugas Terjemahan Cahaya How2 di IWSLT2019. Pada tahun ini, kita terutama membina sistem kita berdasarkan arkitektur Transformer dalam semua tugas dan fokus pada terjemahan ucapan akhir-akhir (E2E-ST). Pertama kita membandingkan model berasaskan RNN dan Transformer, dan kemudian mengesahkan model Transformer secara signifikan dan konsisten melebihi model RNN dalam semua tugas dan korpra. Seterusnya, kami menyelidiki praselatihan model E2E-ST dengan tugas ASR dan MT. Di atas pralatihan, kami meneroka lebih lanjut pengusiran pengetahuan dari model NMT dan pengekod ucapan yang lebih dalam, dan mengesahkan peningkatan drastik terhadap model asas. All of our codes are publicly available in ESPnet.', 'mt': 'Dan id-dokument jiddeskrivi s-sottomissjonijiet tal-ESPnet għall-kompitu tat-traduzzjoni tal-kelmiet How2 fl-IWSLT2019. F’din is-sena, aħna prinċipalment nibnu s-sistemi tagħna bbażati fuq arkitetturi Transformer fil-kompiti kollha u niffokaw fuq it-traduzzjoni tad-diskors minn tarf sa tarf (E2E-ST). L-ewwel nett inqabblu mudelli bbażati fuq RNN u Transformer, u mbagħad nikkonfermaw mudelli Transformer b’mod sinifikanti u konsistenti li jaqbżu l-mudelli RNN fil-kompiti u l-korpra kollha. Imbagħad, ninvestigaw it-taħriġ minn qabel tal-mudelli E2E-ST bil-kompiti ASR u MT. Minbarra t-taħriġ ta’ qabel, aħna nistudjaw aktar id-distillazzjoni tal-għarfien mill-mudell NMT u l-kodifikatur tad-diskors aktar profond, u nikkonfermaw titjib drastiku fuq il-mudell ta’ referenza. Il-kodiċijiet tagħna kollha huma disponibbli pubblikament fl-ESPnet.', 'ro': 'Această lucrare descrie prezentările ESPnet la sarcina How2 Speech Translation la IWSLT22019. În acest an, construim în principal sistemele noastre bazate pe arhitecturi Transformer în toate sarcinile și ne concentrăm pe traducerea end-to-end a vorbirii (E2E-ST). Mai întâi comparăm modelele bazate pe RNN și Transformer, apoi confirmăm modelele Transformer în mod semnificativ și constant depășesc modelele RNN în toate sarcinile și corporele. Apoi, investigăm pre-instruirea modelelor E2E-ST cu sarcinile ASR și MT. Pe lângă pregătirea pregătită, explorăm în continuare distilarea cunoștințelor din modelul NMT și codificatorul de vorbire profund și confirmăm îmbunătățiri drastice față de modelul de bază. Toate codurile noastre sunt disponibile public în ESPnet.', 'pl': 'Niniejszy artykuł opisuje zgłoszenia ESPnet do zadania How2 Speech Translation na IWSLT2019. W tym roku budujemy nasze systemy głównie w oparciu o architektury Transformera we wszystkich zadaniach i koncentrujemy się na kompleksowym tłumaczeniu mowy (E2E-ST). Najpierw porównujemy modele oparte na RNN i Transformer, a następnie potwierdzamy, że modele Transformera znacznie i konsekwentnie przewyższają modele RNN we wszystkich zadaniach i korporach. Następnie badamy przedszkolenia modeli E2E-ST z zadaniami ASR i MT. Oprócz szkolenia przedszkoleniowego, badamy dalej destylację wiedzy z modelu NMT i głębszego kodera mowy i potwierdzamy drastyczne ulepszenia w stosunku do modelu bazowego. Wszystkie nasze kody są publicznie dostępne w ESPnet.', 'mn': 'Энэ цаас IWSLT2019 оны How2 ярианы хөгжлийн хөгжлийн ажлын ESPnet хэвлэлийг тайлбарладаг. Энэ жилд бид ихэвчлэн бүх ажил дээр Трансформер архитектуруудын үндсэн системийг бүтээж, төгсгөл ярианы хөгжүүлэлт (E2E-ST) дээр анхаарлаа хандуулдаг. Бид анх RNN-н суурилсан загвар болон Трансформаторыг харьцуулж, дараа нь Трансформатор загваруудыг маш чухал, үргэлж бүх ажил болон корпора дахь RNN загваруудыг бүтээж чаддаг. Дараа нь бид E2E-ST загварын өмнөх сургалтыг судалж, ASR болон MT даалгавартай. Өмнөх сургалтын дээд бид NMT загвараас мэдлэгийг өөрчлөх болон гүн гүнзгий ярианы коддогч болон суурь шугам загвараас гайхалтай сайжруулалтыг баталж байна. Бидний бүх кодыг ESPnet-д олон нийтэд ашиглаж байна.', 'no': 'Denne papiret beskriver ESPnet-tillegga til How2-taleomsetjingsprogrammet på IWSLT2019. I denne året bygger vi hovudsakelig systemet våre basert på Transformeringsarkitekturar i alle oppgåver og fokuserer på omsetjinga til slutten av tale (E2E-ST). Vi sammenliknar først RNN-baserte modeller og transformerer, og så bekrefter transformeremodeller betydelig og konsekvent utfør RNN-modeller i alle oppgåver og korpora. Neste undersøker vi føreøving av E2E-ST-modeller med ASR og MT-oppgåver. På øvst av føreøvinga, utforskar vi meir forskjellinga av kunnskap frå NMT-modellen og den dypere talekoderen, og stadfestiger drastiske forbedringar over baseline-modellen. Alle våre kodar er offentlig tilgjengeleg i ESPnet.', 'sr': 'Ovaj papir opisuje podaci ESPnet na zadatak How2 govornog prevoda na IWSLT2019. Ove godine, uglavnom gradimo naše sisteme na temelju Transformera arhitekture u svim zadacima i fokusiramo se na prevod govora do kraja (E2E-ST). Prvo uspoređujemo modele i transformer na RNN-u, a zatim potvrđujemo modele transformera značajno i konsekventno iznosi RNN modele u svim zadacima i korporama. Sledeće, istražujemo predobuku E2E-ST modela sa zadacima ASR-a i MT-a. Na vrhu predobuke, dalje istražujemo destilaciju znanja iz modela NMT-a i dubljeg kodera govora i potvrđujemo drastične poboljšanja u osnovnom modelu. Svi naši kodovi su javno dostupni u ESPnet-u.', 'so': 'Warqadan waxaa ku qoran warqada ESPnet oo loo soo dirayo shaqada turjumista ee How2-Speech at IWSLT2019. sanadkan, waxaan dhisaynaa nidaamkayaga oo ku saleysan dhismaha turjumista iyo shaqada oo dhan, waxaana ku kalsoonaynaa turjumista hadalka ugu dambaysta iyo dhammaadka (E2E-ST). Marka ugu horeysa waxaynu isbarbardhignaa samooyin ku saleysan RNN iyo Transformer, kadibna waxaynu xaqiijinaynaa qaabab aad u weyn oo ku socota sameynta samooyinka RNN ee shaqooyinka iyo shirkadaha oo dhan. Inta dambe waxaynu baaraynaa samooyinka E2E-ST-ka horumarinta oo lagu sameeyo shaqada ASR iyo MT. Isku qoran waxbarashada hore, waxaynu sii baaraynaa kala duwanaanta aqoonta sameynta NMT iyo qoraalka hadalka hoose u dhexeeya, waxaana xaqiijinnaa horumarinta hore ee modelka aasaasiga ah. Qoidahayaga oo dhan waxay ku jiraan ESPnet.', 'sv': 'Denna uppsats beskriver ESPnet inlämningar till How2 Speech Translation uppgiften på IWSLT2019. I år bygger vi främst våra system baserade på Transformer-arkitekturer i alla uppgifter och fokuserar på heltäckande talöversättning (E2E-ST). Vi jämför först RNN-baserade modeller och Transformer och bekräftar sedan Transformer-modeller betydligt och konsekvent bättre än RNN-modeller i alla uppgifter och corpora. Därefter undersöker vi fortbildning av E2E-ST-modeller med ASR- och MT-uppgifterna. Utöver förberedelserna undersöker vi vidare kunskapsdestillation från NMT-modellen och den djupare talkodaren, och bekräftar drastiska förbättringar jämfört med basmodellen. Alla våra koder är allmänt tillgängliga i ESPnet.', 'si': 'මේ පැත්තේ IWSLT2019 වලින් හොව2 කතාවක් වාර්තාවක් ගැන ESPnet පිළිගන්න විස්තර කරනවා. මේ අවුරුද්දේ, අපි ප්\u200dරධානයෙන් අපේ පද්ධතිය හැම වැඩවල් වෙනුවෙන් හැම වැඩවල් විස්තර විදියට අධාරණය කරනවා සහ අවසානය අපි මුලින්ම RNN-ආධාරිත මොඩේල් සහ ත්\u200dරාණ්පණය කරනවා, ඊට පස්සේ ත්\u200dරාණ්පණය කරපු මොඩේල්ස් විශේෂයෙන් සඳහා සාමාන්\u200dය වැඩ ඊළඟට, අපි E2E-ST මොඩේල්ස් එක්ක පරීක්ෂණය කරනවා ASR සහ MT වැඩක් එක්ක. ප්\u200dරධාන ප්\u200dරශ්නයක් වලින්, අපි දැනගන්නේ NMT මොඩේල් වලින් ගොඩක් ගොඩක් කතා කරුණාකරුවක් වලින් දැනගන්න, අධාන ප්\u200dරශ්න අපේ සියළුම කෝඩ් සාමාන්\u200dයයෙන් ESPnet එකේ ප්\u200dරතිකාරයෙන් ලැබෙනවා.', 'ta': 'This paper describes the ESPnet submissions to the How2 Speech Translation Job at IWSLT2019. இந்த வருடத்தில், முக்கியமாக நாம் மாற்று உருவாக்கி அனைத்து பணிகளிலும் அடிப்படையில் எங்கள் அமைப்புகளை உருவாக்கி முடிவு மொழிபேச்ச முதலில் RNN-அடிப்படையிலுள்ள மாதிரிகளையும் மாற்றியமைப்பையும் ஒப்பிடுகிறோம். பின்னர் மாற்று மாதிரி மாதிரிகளை மாற்றுகிறத அடுத்து, முன் பயிற்சியின் மேல், நாம் NMT மாதிரி மற்றும் ஆழமான பேச்சு குறியீட்டில் இருந்து அறிவு பிரிவை தேடுகிறோம், அடிப்படை மாதிரிய எங்கள் அனைத்து குறியீடுகளும் ESPnet-ல் பொதுவாக கிடைக்கும்.', 'ur': 'This paper describes the ESPnet submissions to the How2 Speech Translation task at IWSLT2019. اس سال میں ہم سب کاموں میں تغییر پھیلانے کے معماروں پر بنیاد رکھتے ہیں اور آخر-to-end speech translation (E2E-ST) پر تمرکز کرتے ہیں۔ ہم پہلی بار RNN بنیادی موڈل اور ترنسفور کے مطابق مقایسہ کرتے ہیں اور پھر ترنسفور موڈل کو مطمئن کرتے ہیں اور تمام کاموں اور کورپورا میں RNN موڈل سے کام کرتے ہیں۔ بعد، ہم نے E2E-ST موڈل کے پیش تربین کی تحقیق کی ASR اور MT کاموں کے ساتھ. پہلے کی تعلیم کے اوپر، ہم NMT موڈل اور عمیق بات کا کوڈر سے علم کے تفریق سے اضافہ کر رہے ہیں، اور بنیس لین موڈل پر بہت اضافہ کی تصدیق کررہے ہیں. ہمارے سب کڈ اکسپنیٹ میں ظاہر طور پر موجود ہیں.', 'uz': "Name Bu yilda, biz hamma vazifalar bilan Transformer arkitekalarning asosida tizimimizni yaratdik va oxirigi gapirish tarjimasiga foydalanamiz (E2E-ST). We first compare RNN-based models and Transformer, and then confirm Transformer models significantly and consistently outperform RNN models in all tasks and corpora.  Keyingi, biz ASR va MT vazifalari bilan E2E-ST modellarining oldingi tajribasini o'rganamiz. Birinchi taʼminlovchi sohasida, biz NMT modeldan va eng yuqori gapiruvni ajratishni ko'rganamiz va asosiy modelidagi murakkab o'zgarishni ishlatimiz. Hech qanday kodlar ESPnetda topilmadi.", 'vi': 'Tờ giấy này mô tả những phát biểu của ESPN với bài dịch của Howl2 tại IWSL2-009. Năm nay, chúng tôi chủ yếu xây dựng hệ thống dựa trên kiến trúc biến hình trong mọi công việc và tập trung vào dịch thuyết cuối cùng (E2E-ST). Trước tiên chúng ta so sánh các mô hình dựa trên RNN và Transformer rồi khẳng định các mô hình transformer còn đáng kể và hoàn toàn vượt trội các mô hình RNN trong mọi việc và hạ đẳng. Tiếp theo, chúng ta nghiên cứu các mẫu E2E-ST với các nhiệm vụ ASR và MTV. Ngoài việc luyện tập, chúng tôi còn nghiên cứu việc chưng cất kiến thức từ mẫu NMT và bộ mã hóa giọng sâu hơn, và xác nhận những cải tiến mạnh mẽ trên mô hình cơ bản. Tất cả các mã của chúng ta đều công khai trên mạng ESPN.', 'bg': 'Настоящата статия описва представянето на ЕСПнет по задачата How2 Speech Translation на ИВСЛТ2019. През тази година основно изграждаме нашите системи, базирани на трансформаторни архитектури във всички задачи и се фокусираме върху речния превод от край до край (Е2Е-СТ). Първо сравняваме базираните модели и трансформаторите, а след това потвърждаваме, че моделите на трансформаторите значително и последователно превъзхождат моделите във всички задачи и корпуси. След това изследваме предварителното обучение на Е2Е-СТ модели със задачите АСР и МТ. Освен предварителното обучение, ние допълнително изследваме дестилацията на знанията от модела и по-дълбокия речен кодер и потвърждаваме драстични подобрения спрямо базовия модел. Всички наши кодове са публично достъпни в ЕСПнет.', 'da': 'Dette dokument beskriver ESPnet-indlæg til How2 Speech Translation opgaven på IWSLT2019. I år bygger vi primært vores systemer baseret på Transformer-arkitekturer i alle opgaver og fokuserer på end-to-end taleoversættelse (E2E-ST). Vi sammenligner først RNN-baserede modeller og Transformer, og bekræfter derefter Transformer modeller betydeligt og konsekvent bedre end RNN modeller i alle opgaver og corpora. Dernæst undersøger vi forudtræning af E2E-ST modeller med ASR og MT opgaver. Ud over foruddannelsen undersøger vi videndedestillation fra NMT-modellen og den dybere talekoder, og bekræfter drastiske forbedringer i forhold til baseline-modellen. Alle vores koder er offentligt tilgængelige i ESPnet.', 'nl': "Dit artikel beschrijft de ESPnet inzendingen voor de How2 Speech Translation taak op IWSLT2019. In dit jaar bouwen we onze systemen voornamelijk op basis van Transformer architecturen in alle taken en richten we ons op de end-to-end spraakvertaling (E2E-ST). We vergelijken eerst RNN-gebaseerde modellen en Transformer, en bevestigen vervolgens dat Transformer-modellen significant en consistent beter presteren dan RNN-modellen in alle taken en corpora's. Vervolgens onderzoeken we pre-training van E2E-ST modellen met de ASR en MT taken. Naast de pre-training onderzoeken we verder kennisdistillatie vanuit het NMT-model en de diepere spraakencoder en bevestigen we drastische verbeteringen ten opzichte van het basismodel. Al onze codes zijn openbaar beschikbaar in ESPnet.", 'hr': 'Ovaj papir opisuje podatke ESPnet na zadatak How2 govornog prevoda na IWSLT2019. U ovoj godini, uglavnom gradimo naše sustave na temelju arhitekture transformera u svim zadacima i fokusiramo se na prevod govora do kraja (E2E-ST). Prvo uspoređujemo modele i transformer na RNN-u, a zatim potvrđujemo modele transformera značajno i konsekventno iznosi RNN modele u svim zadacima i tijelu. Sljedeće, istražujemo predobuku E2E-ST modela s zadatkom ASR-a i MT-a. Na vrhu predobuke, dalje istražujemo destilaciju znanja iz modela NMT-a i dubljeg kodera govora i potvrđujemo drastične poboljšanja u osnovnom modelu. Svi naši kodovi su javno dostupni u ESPnet-u.', 'de': 'Dieser Beitrag beschreibt die ESPnet-Einreichungen für die How2 Speech Translation Aufgabe bei IWSLT2019. In diesem Jahr bauen wir unsere Systeme hauptsächlich auf Transformer-Architekturen in allen Aufgaben auf und konzentrieren uns auf die End-to-End Sprachübersetzung (E2E-ST). Wir vergleichen zunächst RNN-basierte Modelle und Transformer und bestätigen dann, dass Transformer-Modelle in allen Aufgaben und Korpora RNN-Modelle signifikant und konsistent übertreffen. Als nächstes untersuchen wir das Vortraining von E2E-ST Modellen mit den ASR- und MT-Aufgaben. Zusätzlich zum Vortraining untersuchen wir die Wissensdestillation aus dem NMT-Modell und dem tieferen Sprachencoder und bestätigen drastische Verbesserungen gegenüber dem Basismodell. Alle unsere Codes sind öffentlich in ESPnet verfügbar.', 'id': 'Kertas ini menjelaskan pengiriman ESPnet ke tugas How2 Speech Translation di IWSLT2019. Pada tahun ini, kami terutama membangun sistem kami berdasarkan arsitektur Transformer dalam semua tugas dan fokus pada terjemahan pidato akhir-akhir (E2E-ST). Pertama kita membandingkan model berbasis RNN dan Transformer, dan kemudian mengkonfirmasi model Transformer secara signifikan dan konsisten melebihi model RNN dalam semua tugas dan korpra. Next, we investigate pre-training of E2E-ST models with the ASR and MT tasks.  Di atas pre-pelatihan, kami lebih lanjut mengeksplorasi destilasi pengetahuan dari model NMT dan pengekode pidato yang lebih dalam, dan mengkonfirmasi perbaikan drastis terhadap model dasar. Semua kode kita tersedia publik di ESPnet.', 'ko': '본고는 ESPnet이 IWSLT2019에서 제출한 How2 음성 번역 임무를 묘사한다.올해 우리는 주로 모든 임무에서 Transformer 구조를 바탕으로 시스템을 구축하고 끝까지 음성 번역(E2E-st)에 중점을 두었다.우리는 먼저 RNN을 바탕으로 하는 모델과 Transformer를 비교한 다음에 Transformer모델이 모든 임무와 자료 라이브러리에서 RNN모델보다 현저하고 일치하게 우수하다는 것을 확인한다.다음으로 우리는 ASR과 MT 임무로 E2E-st 모형의 예비 훈련을 연구한다.예비 훈련을 토대로 우리는 NMT 모델과 더욱 깊은 차원의 음성 인코더에서 지식을 추출하는 과정을 더욱 탐색하고 기선 모델에 대한 중대한 개선을 확인했다.EMC의 모든 코드는 ESPnet에서 공개적으로 액세스할 수 있습니다.', 'fa': 'این کاغذ تحویل\u200cهای ESPnet به کار ترجمه سخنرانی How2 در IWSLT2019 توصیف می\u200cکند. در این سال، ما در اصل سیستم\u200cهایمان را بر اساس معماری تغییر\u200cپذیر در همه کارها بسازیم و روی ترجمه\u200cهای سخنرانی پایان و پایان تمرکز کنیم (E2E-ST). اولین بار مدل\u200cهای بنیاد RNN و تغییر\u200cدهنده را مقایسه می\u200cکنیم، سپس مدل\u200cهای تغییر\u200cدهنده را به طور معنی تایید می\u200cکنیم و همیشه مدل\u200cهای RNN را در تمام وظیفه\u200cها و کوپرا بیشتر انجام می\u200cدهیم. بعدش، ما پیش آموزش مدل E2E-ST را با کارهای ASR و MT تحقیق می کنیم. بالای آموزش پیش از آموزش، ما از مدل NMT و رمز سخنرانی عمیق بیشتری تحقیق می کنیم، و بهترین ترتیب درجه مدل پایین تایید می کنیم. همه کدهای ما در ESPnet عمومی موجود هستند.', 'af': 'Hierdie papier beskryf die ESPnet onderskrywings na die How2 Spraak Vertaling taak by IWSLT2019. In hierdie jaar bou ons stelsels hoofsaaklik gebaseer op Transformer-arkitektuur in alle taak en fokus op die end-to-end-speech translation (E2E-ST). Ons vergelyk eerste RNN-gebaseerde modele en Transformer, en dan bevestig Transformer modele betekeurig en konsistentlik uitvoer RNN modele in alle opdragte en corpora. Volgende, ons ondersoek voor-oefening van E2E-ST-modele met die ASR en MT-opdragte. Op die bo-oefening van die voor-oefening, ondersoek ons verder kennis verskiling van die NMT-model en die dieper sprekking koder en bevestig drastiese verbeteringe oor die basisline model. Alle ons kodes is openlik beskikbaar in ESPnet.', 'sw': 'Gazeti hili linaelezea ujumbe wa ESPnet kwa kazi ya How2 ya Utafsiri katika IWSLT2019. Mwaka huu, kwa ujumla tunajenga mifumo yetu yenye misingi ya majengo ya Transfer katika kazi zote na tunajikita kwenye tafsiri ya mwisho ya hotuba (E2E-ST). Kwanza tunalinganisha mifano yenye asili ya RNN na Transformer, na kisha tunathibitisha mifano ya Transfer kwa kiasi kikubwa na kwa ujumla tunafanya mifano ya RNN katika kazi zote na kampuni. Baadae, tunachunguza mafunzo ya kabla ya mifano ya E2E-ST kwa kazi za ASR na MT. Katika juu ya mafunzo ya awali, tunatafuta zaidi utofauti wa maarifa kutoka kwa Mradi wa NMT na kodi ya hotuba ya kina zaidi, na kuhakikisha maendeleo makubwa zaidi ya mifano ya msingi. Alama zetu zote zinapatikana hadharani katika ESPnet.', 'hy': 'Այս հոդվածը նկարագրում է ԵՍՊnet-ի ներկայացումները Հով2 խոսքի թարգմանման առաջադրանքին IW-ՍԼԹ2019-ում: Այս տարվա ընթացքում մենք հիմնականում կառուցում ենք մեր համակարգերը, հիմնված Transforme ճարտարապետության վրա բոլոր խնդիրներում և կենտրոնանում ենք վերջ-վերջ խոսքի թարգմանման վրա (E2E-S): Սկզբում մենք համեմատում ենք ՌՆԹ-ով հիմնված մոդելները և Թանֆորմատորը, հետո հաստատում ենք Թանֆորմատորի մոդելները, որոնք նշանակալի և մշտապես գերազանցում են ՌՆԹ-ի մոդելները բոլոր առաջադրանքներ Next, we investigate pre-training of E2E-ST models with the ASR and MT tasks.  Նախապատրաստ ուսումնասիրության վրա մենք ավելի շատ ուսումնասիրում ենք NMT-ի մոդելի և խոսքի ավելի խորը կոդավորիչը, և հաստատում ենք հիմնական մոդելի հարաբերությունները: Մեր բոլոր կոդները հանրային հասանելի են ԵՍՊnet-ում:', 'tr': "Bu käze IWSLT2019'da How2 söz terjime täblisasyna ESPnet göndermelerini tassyýar. Bu ýylda sistemamyzy ähli zadyň içine transformer arhitekturlaryna daýanýar we soňra çykyş terjimesine (E2E-ST) üns berýäris. Ilkinji gezek RNN tabanly modelleri we Transformer modellerini karşılaştırıp, sonra Transformer modellerini önemli şekilde teşhis edip, tüm işlerimizde RNN modellerinden üstün tutuyoruz. Soňra, E2E-ST nusgalarynyň öňünden öňünden öňünden okuwçysyny ASR we MT zadyny bilen barlaýarys. Öň okuwçylygyň üstünde, NMT modeliniň we çykyş kodçyndan bilim tapawutlaryny aşdyrmak we baseline modeliniň üstünde drastik gelişmelerini tassyklanýar. Hemme kodlarymyz publika ESPnet'de bar.", 'am': 'ይህ ገጽ የኤስፒኤን አፍላጻዎችን በIWSLT2019 ውስጥ በHow2 ንግግር ትርጉም አድራሻ እንዲያሳያል ይናገራል፡፡ በዚህ ዓመቱ፣ አብዛኛውን በተለየ ትርጓሜ መሠረት ሁሉ ላይ በመሠረት ስርዓታችንን እናደርጋለን እና መጨረሻ ወደ መጨረሻ ንግግር ትርጓሜን እናስማማታለን፡፡ መጀመሪያ RNN-based models እና Transformer እና እናስተያየዋለን፣ ከዚያም በተለየ ሞዴላዎችን በብርቱ እና በሁሉም ስራ እና ኮርፖርተር ውስጥ RNN ሞዴላዎችን እናስተካክላለን፡፡ በኋላው የE2E-ST ሞዴላዎችን በASR እና MT ስራዎችን የምንመረምር ነው፡፡ የቀድሞው ትምህርት ላይ ከNMT model እና ጥልቅ ንግግር የፊደል ቁጥጥር እውቀትን እናረጋግጣለን፡፡ የኢሜይል ኮዶችንን ሁሉ ገልፅ ይችላል፡፡', 'sq': 'Ky dokument përshkruan paraqitjet e ESPnet në detyrën How2 Speech Translation në IWSLT2019. Në këtë vit, ne kryesisht ndërtojmë sistemet tona bazuar në arkitekturat Transformer në të gjitha detyrat dhe përqëndrohemi në përkthimin e fjalës nga fundi në fund (E2E-ST). Ne së pari krahasojmë modelet me bazë RNN dhe Transformer, dhe pastaj konfirmojmë modelet Transformer në mënyrë të rëndësishme dhe konsistente më tepër se modelet RNN në të gjitha detyrat dhe korpra. Pastaj, ne hetojmë paratrajnimin e modeleve E2E-ST me detyrat ASR dhe MT. Në krye të parastërvitjes, ne eksplorojmë më tej distillacionin e njohurive nga modeli NMT dhe koduesi më i thellë i fjalimit dhe konfirmojmë përmirësimet drastike lidhur me modelin bazë. Të gjitha kodet tona janë në dispozicion publik në ESPnet.', 'bn': 'এই পত্রিকাটি ইউএসএলটি২০১৯-এ হো২ ভাষা ভাষার অনুবাদ কাজের প্রতি এসপিনেট প্রদানের কথা বর্ণনা করেছে। এই বছরে আমরা প্রধানভাবে আমাদের সিস্টেম তৈরি করি সব কাজের ভিত্তিতে ট্রান্সফার্নার্নাফারের আর্কিকেটের উপর ভিত্তি করে এবং শেষ-শেষ ভ আমরা প্রথমে RNN ভিত্তিক মডেল এবং ট্রান্সফ্রান্সফারের তুলনা করি, তারপর ট্রান্সফ্রান্সফ্রান্স মডেল গুরুত্বপূর্ণ এবং সাধারণত R পরবর্তীতে, আমরা এসআর আর এমটি কাজের মাধ্যমে E2E-ST মডেলের পূর্ব প্রশিক্ষণ অনুসন্ধান করি। প্রথম প্রশিক্ষণের উপরে আমরা এনএমটি মডেল এবং গভীর ভাষণ কোডার থেকে জ্ঞানের বিচ্ছিন্ন বিষয়টি আবিষ্কার করি এবং বেসাইলাইনের মডেলের উপর গভীর উন All of our codes are publicly available in ESPnet.', 'ca': 'Aquest paper descriu les presentacions ESPnet a la tasca How2 Speech Translation de IWSLT2019. En aquest any construïm els nostres sistemes basats en arquitectures Transformer en totes les tasques i ens centrem en la traducció del discurs final a final (E2E-ST). Primer comparem models basats en RNN i Transformer, i després confirmem models Transformer que superen significativament i consistentment els models RNN en totes les tasques i corpores. Després investigam la pré-capacitació dels models E2E-ST amb les tasques ASR i MT. A més de la pré-capacitació, explorem més la distillació del coneixement del model NMT i el codificador fonamental del discurs, i confirmam millores dràstiques sobre el model basal. All of our codes are publicly available in ESPnet.', 'az': "Bu kağıt IWSLT2019'də How2 Söz Çeviri Göndərilməsi üçün ESPnet təbliğlərini təsbit edir. Bu il, bütün işlərdə Transformer arhitektürlərinə dayanan sistemlərimizi in şa edir və sona qədər sözlərin tercüməsinə (E2E-ST) odaqlayırıq. Biz ilk dəfə RNN tabanlı modelləri və Transformeri ilə qarşılaşdırırıq, sonra Transformer modelləri möhkəm təsdiqləyirik və sürəklə RNN modellərini bütün işlərdə və korporada daha üstün etdik. Sonra, ASR və MT işləri ilə E2E-ST modellərin əvvəl təhsil edilməsini incidirik. Ön təhsil edilməsinin üstündə, NMT modelindən və daha derin söz kodlayıcından elm ayrılığını keşfetdik və baseline modelində drastik düzəltmələri təsdiqlədik. Bütün kodlarımız ESPnet içində açıq-aşkar faydalanır.", 'bs': 'Ovaj papir opisuje podaci ESPnet na zadatak How2 govornog prevoda na IWSLT2019. U ovoj godini uglavnom gradimo naše sisteme na temelju Transformera arhitekture u svim zadacima i fokusiramo se na prevod govora do kraja (E2E-ST). Prvo uspoređujemo modele i transformer na RNN-u, a zatim potvrđujemo modele transformera značajno i konsekventno iznosi RNN modele u svim zadacima i korporama. Sljedeće, istražujemo predobuku E2E-ST modela sa zadacima ASR-a i MT-a. Na vrhu predobuke, dalje istražujemo destilaciju znanja iz modela NMT-a i dubljeg kodera govora i potvrđujemo drastične poboljšanja u osnovnom modelu. Svi naši kodovi su javno dostupni u ESPnet-u.', 'cs': 'Tento článek popisuje příspěvek ESPnet na úkol How2 Speech Translation na IWSLT2019. V letošním roce budujeme především naše systémy založené na architektuře Transformer ve všech úkolech a zaměřujeme se na end-to-end překlad řeči (E2E-ST). Nejprve porovnáme modely založené na RNN a Transformer a poté potvrdíme, že modely Transformer výrazně a důsledně překonávají RNN modely ve všech úkolech a korpusech. Dále zkoumáme předškolení E2E-ST modelů s ASR a MT úlohami. Kromě předškolení dále zkoumáme destilaci znalostí z NMT modelu a hlubšího kodéru řeči a potvrzujeme drastická zlepšení oproti základnímu modelu. Všechny naše kódy jsou veřejně dostupné v ESPnetu.', 'et': 'Käesolevas artiklis kirjeldatakse ESPNeti esitusi How2 kõne tõlke ülesandele IWSLT2019. Sellel aastal ehitame peamiselt Transformeri arhitektuuril põhinevad süsteemid kõigis ülesannetes ja keskendume otsast otsa kõnetõlkele (E2E-ST). Kõigepealt võrdleme RNN-põhiseid mudeleid ja Transformerit ning seejärel kinnitame Transformeri mudeleid oluliselt ja järjepidevalt ületavad RNN-mudelid kõigis ülesannetes ja korpustes. Seejärel uurime E2E-ST mudelite eelkoolitust ASR ja MT ülesannetega. Lisaks eelkoolitusele uurime täiendavalt NMT mudeli ja sügavama kõnekooderi teadmiste destilleerimist ning kinnitame olulisi parandusi võrreldes baasmudeliga. Kõik meie koodid on avalikult kättesaadavad ESPnetis.', 'fi': 'Tässä artikkelissa kuvataan ESPNet-julkaisuja How2 Speech Translation -tehtävään IWSLT2019. Tänä vuonna rakennamme pääasiassa Transformer-arkkitehtuuriin perustuvia järjestelmiä kaikissa tehtävissä ja keskitymme end-to-end puhekäännökseen (E2E-ST). Vertailemme ensin RNN-pohjaisia malleja ja Transformer-malleja ja vahvistamme sitten Transformer-mallit merkittävästi ja johdonmukaisesti paremmin kuin RNN-mallit kaikissa tehtävissä ja korpusissa. Seuraavaksi tutkimme E2E-ST-mallien esikoulutusta ASR- ja MT-tehtävissä. Esikoulutuksen lisäksi tutkimme tietämyksen tislausta NMT-mallista ja syvemmästä puhekooderista ja vahvistamme merkittäviä parannuksia perusmalliin verrattuna. Kaikki koodimme ovat julkisesti saatavilla ESPnetissä.', 'ha': "Wannan takardan na describe the ESPnet elements to the How2 Spelling Translate job at IWSLT2019. A shekara wannan, munã samar da system-yiwunmu a kan muhimman taskõkin Transformer a cikin duk aikin su kuma munã fokus kan fassarar magana ta ƙari-zuwa-ƙari (E2ES-Sta). @ info: whatsthis Next, we investigate pre-training of E2E-ST models with the ASR and MT tasks.  Ga kowaci na zaman shawara, za mu sami bayani na zane-zane daga misalin NMT da kodi mafi ƙaranci ga magana, kuma za mu gaskata kodi masu ƙaranci a kan misalin salon. Dukan kodoyinmu za'a iya samu'a cikin ESPnet.", 'jv': 'Gambar iki rambarang panjenengan ESPnet nang daftar Omuluh sing Ha2 Talk kanggo IWSLT2011. Nang marang iki, kita supoyo nggawe sistem sing basa ning architecture Transformer kanggo nganggo perusahaan lan gambaran kanggo tukang tarjamahan end-to-end (e2E-RT). Awak dhéwé first karganin model karo Transformer sampeyaké DNN, lan saka transformer model Transformer dumateng lan saiki ditawak dhéwé model R-N dumateng ning saben tasks karo corora. Tulung, awake dhewe kuclah Program prelimin kanggo model e2E-RT karo ASR karo MT dadi. Jagadeng bantuan prelimin, kita layakno nggawe layakno luwih dumadhi paten nggo model NMT lan koder sing nggawe barang nggambar, lan nggunakake tresnaké diagram barang model sing basa. Punika kode awak dhéwé Publik nang ESPnet', 'he': 'העיתון הזה מתאר את ההעברות של ESPnet למשימת התרגום של How2 Speech ב IWSLT2019. בשנה זו, אנחנו בעיקר בונים את המערכות שלנו מבוססות על ארכיטקטורות טרנספורסטר בכל המשימות ולהתמקד בתרגום הנאום בסוף לסוף (E2E-ST). קודם שווותים דוגמנים מבוססים על RNN וטרנספורר, ואז מאשר דוגמנים טרנספורר משמעותיים ובקבוע יותר ממודלים RNN בכל המשימות והגופורה. לאחר מכן, אנחנו חוקרים את האימונים הקדמיים של דוגמנים E2E-ST עם משימות ASR ו-MT. On top of the pre-training, we further explore knowledge distillation from the NMT model and the deeper speech encoder, and confirm drastic improvements over the baseline model.  כל הקודים שלנו זמינים לציבור באס.פי.נט.', 'sk': 'Ta prispevek opisuje prispevke ESPNet na nalogo How2 Speech Translation na IWSLT2019. V tem letu v glavnem gradimo sisteme, ki temeljijo na transformatorskih arhitekturah pri vseh nalogah in se osredotočamo na celovito govorno prevajanje (E2E-ST). Najprej primerjamo modele na osnovi RNN in transformatorjev, nato pa potrdimo, da modeli transformatorjev znatno in dosledno presegajo RNN modele v vseh opravilih in korpusih. Nato smo preučili predusposabljanje modelov E2E-ST z nalogami ASR in MT. Poleg predusposabljanja nadalje raziskujemo destilacijo znanja iz modela NMT in globljega kodirnika govora ter potrjujemo drastične izboljšave v primerjavi z osnovnim modelom. Vse naše kode so javno dostopne v ESPnet.', 'bo': 'ཤོག་བྱང་འདིས་ESPnet་ལ་How2 Speech Translation task at IWSLT2019་ལ་གཏོང་ཐུབ་པ In this year, we mainly build our systems based on Transformer architectures in all tasks and focus on the end-to-end speech translation (E2E-ST). ང་ཚོས་དང་པོ་ནས་RNN ལུས་ཡོད་པའི་མིག འོན་ཀྱང་། ང་ཚོས་E2E-ST དཔེ་དབྱིབས་གྱི་སྔོན་གྲངས་སྒྲིག་དཔེ་གཏོང་བྱེད་ཀྱི་ཡོད། Top of the pre-training, we further explore knowledge distillation from the NMT model and the deeper speech encoder, and confirm drastic improvements over the baseline model. ང་ཚོའི་ཨང་ཀྲངས་ཡོངས་རྫོགས་སྒེར་གྱི་རྩིས་ཡོངས་ཁྱབ་མང་ཙམ་སྤྱོད་ཚར་ཡོད།'}
{'en': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'ar': 'اتحاد أنظمة ترجمة الكلام من طرف إلى طرف ON-TRAC للمهمة المشتركة IWSLT 2019', 'pt': 'Sistemas de tradução de fala de ponta a ponta do Consórcio ON-TRAC para a tarefa compartilhada IWSLT 2019', 'es': 'Sistemas de traducción de voz de extremo a extremo del Consorcio ON-TRAC para la tarea compartida IWSLT 2019', 'fr': 'Systèmes de traduction vocale de bout en bout du consortium ON-TRAC pour la tâche partagée IWSLT 2019', 'ja': 'IWSLT 2019共有タスクのためのON - TRACコンソーシアムのエンドツーエンドの音声翻訳システム', 'zh': 'ON-TRAC联盟IWSLT 2019共事端端语音译', 'hi': 'ON-TRAC कंसोर्टियम एंड-टू-एंड वाक् अनुवाद सिस्टम IWSLT 2019 साझा कार्य के लिए', 'ru': 'Системы сквозного перевода речи консорциума ON-TRAC для общей задачи IWSLT 2019', 'ga': 'Cuibhreannas ON-TRAC Córais Aistriúcháin Cainte ó cheann ceann go ceann do Thasc Comhroinnte IWSLT 2019', 'ka': 'ON- TRAC Consortium End- to- End Speech Translation Systems for the IWSLT 2019 Shared Task', 'el': 'Ολοκληρωμένα συστήματα μετάφρασης ομιλίας της κοινοπραξίας για την κοινή εργασία', 'hu': 'ON-TRAC Konzorcium End-to-End beszédfordító rendszerek az IWSLT 2019 megosztott feladatához', 'kk': 'ON- TRAC Consortium End- to- End Speech Translation Systems for the IWSLT 2019 Shared Task', 'ms': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'ml': 'IWSLT 2019 പങ്കെടുത്ത പണി', 'mk': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'mt': 'On-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'lt': 'ON-TRAC konsorciumas 2019 m. IWSLT bendros užduoties kalbos vertimo sistemos', 'it': 'Sistemi di traduzione vocale end-to-end del consorzio ON-TRAC per il compito condiviso IWSLT 2019', 'mn': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'pl': 'Konsorcjum ON-TRAC Kompleksowe systemy tłumaczenia mowy dla IWSLT 2019 Wspólne zadanie', 'no': 'ON- TRAC Consortium End- to- End Speech Translation Systems for the IWSLT 2019 Shared Task', 'ro': 'Sisteme de traducere end-to-end a discursului consorțiului ON-TRAC pentru sarcina partajată IWSLT 2019', 'sr': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'so': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'si': 'ON- TRAC Consorium End- to- End කතාව පරිවර්තන පද්ධතිය IWSLT 2019 සමාගත වැඩිය', 'ta': 'IWSLT 2019 பகிர்ந்த பணி', 'sv': 'ON-TRAC Consortium End-to-End Speech Översättningssystem för IWSLT 2019 delade uppgifter', 'ur': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'uz': '@ info: whatsthis', 'vi': 'S·ªÅEƒë·ªãa ch·ªÅEc·ªßa KDE Comment', 'hr': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'da': 'ON-TRAC Consortium End-to-End taleoversættelsessystemer til IWSLT 2019 delt opgave', 'bg': 'Консорциум от край до край системи за превод на реч за споделената задача', 'nl': 'ON-TRAC Consortium End-to-End spraakvertaalsystemen voor de IWSLT 2019 Gedeelde taak', 'id': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'de': 'ON-TRAC Consortium End-to-End SprachĂĽbersetzungssysteme fĂĽr das IWSLT 2019 Gemeinsame Aufgabe', 'ko': 'IWSLT 2019 임무를 공유하는 ON-TRAC Consortium 단말기부터 단말기까지 음성 번역 시스템', 'fa': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'sw': 'Mfumo wa Tafsiri kwa ajili ya IWSLT 2019', 'sq': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'am': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'af': 'ON- TRAC Consortium End- to- End Speech Translation Systems for the IWSLT 2019 Shared Task', 'tr': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'hy': 'Կոնսորցիումը, որը տեղադրվում է 2019 թվականի IwSlaT-ի համագործակցած հանձնարարության վերջ-վերջ խոսքի թարգմանման համակարգերի համար', 'bn': 'IWSLT ২০১৯ শেয়ার করা কাজের জন্য ওন-TRAC কনসোর্টিয়াম শেষ-থেকে শেষ-শেষ-বক্তৃতা অনুবাদ সিস্টেম', 'az': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'cs': 'Konsorcium ON-TRAC End-to-End překladové systémy řeči pro IWSLT 2019 Sdílená úloha', 'bs': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'fi': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'ca': 'On-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task', 'et': 'ON-TRAC konsortsiumi lõppkõnetõlkesüsteemid IWSLT 2019 ühise ülesande jaoks', 'jv': 'on-TROC Konortium End-to-End Ketok Terjamahan Sistem kanggo IWSLT 2011 9 Ngawe task', 'he': 'קונזורציום ON-TRAC מערכות תרגום דיבורים סוף-סוף עבור משימה משותפת IWSLT 2019', 'ha': 'KCharselect unicode block name', 'sk': 'Konzorcij ON-TRAC iz konca do konca za skupno nalogo IWSLT 2019', 'bo': 'ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task'}
{'en': 'This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English Portuguese language pair. ON-TRAC Consortium is composed of researchers from three French academic laboratories : LIA (Avignon Universit), LIG (Universit Grenoble Alpes), and LIUM (Le Mans Universit). A single end-to-end model built as a neural encoder-decoder architecture with attention mechanism was used for two primary submissions corresponding to the two EN-PT evaluations sets : (1) TED (MuST-C) and (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of ', 'ar': 'تصف هذه الورقة أنظمة ترجمة اتحاد ON-TRAC التي تم تطويرها لمهمة النموذج الشامل لتقييم IWSLT 2019 للزوج اللغوي الإنجليزية والبرتغالية. يتكون اتحاد ON-TRAC من باحثين من ثلاثة مختبرات أكاديمية فرنسية: LIA (جامعة أفينيون) و LIG (جامعة غرونوبل ألب) و LIUM (جامعة لومان). تم استخدام نموذج واحد من طرف إلى طرف تم إنشاؤه كعمارة مفكك تشفير عصبي مع آلية الانتباه من أجل إرسالين أوليين يتوافقان مع مجموعتي تقييمات EN-PT: (1) TED (MuST-C) و (2) How2. في هذه الورقة ، قمنا بالتحقيق بشكل خاص في تأثير تجميع مجموعات غير متجانسة للتدريب ، وتأثير الترميز المستهدف (الأحرف أو BPEs) ، وتأثير تجزئة إدخال الكلام ونقارن أيضًا أفضل نموذج من طرف إلى طرف (BLEU 26.91 في MuST-C و 43.82 على مجموعات التحقق من صحة How2) لنهج خط الأنابيب (ASR + MT).', 'pt': 'Este artigo descreve os sistemas de tradução do Consórcio ON-TRAC desenvolvidos para a tarefa de modelo de ponta a ponta da Avaliação IWSLT 2019 para o par de idiomas Inglês→Português. O Consórcio ON-TRAC é composto por pesquisadores de três laboratórios acadêmicos franceses: LIA (Avignon Universitë), LIG (Universitë Grenoble Alpes) e LIUM (Le Mans Universitë). Um único modelo de ponta a ponta construído como uma arquitetura de codificador-decodificador neural com mecanismo de atenção foi usado para duas submissões primárias correspondentes aos dois conjuntos de avaliações EN-PT: (1) TED (MuST-C) e (2) How2. Neste artigo, investigamos notavelmente o impacto do agrupamento de corpora heterogêneos para treinamento, impacto da tokenização de destino (caracteres ou BPEs), impacto da segmentação de entrada de fala e também comparamos nosso melhor modelo de ponta a ponta (BLEU de 26,91 no MuST-C e 43,82 em conjuntos de validação How2) para uma abordagem de pipeline (ASR+MT).', 'es': 'Este documento describe los sistemas de traducción del Consorcio ON-TRAC desarrollados para la tarea modelo integral de la Evaluación IWSLT 2019 para la combinación de idiomas inglés→ portugués. El Consorcio ON-TRAC está compuesto por investigadores de tres laboratorios académicos franceses: LIA (Universidad de Aviñón), LIG (Universidad de Grenoble Alpes) y LIUM (Universidad de Le Mans). Se utilizó un único modelo de extremo a extremo construido como una arquitectura de codificador-decodificador neuronal con mecanismo de atención para dos presentaciones primarias correspondientes a los dos conjuntos de evaluaciones EN-PT: (1) TED (Must-C) y (2) Cómo2. En este artículo, investigamos notablemente el impacto de la agrupación de cuerpos heterogéneos para el entrenamiento, el impacto de la tokenización objetivo (personajes o BPE), el impacto de la segmentación de la entrada de voz y también comparamos nuestro mejor modelo de extremo a extremo (BLEU de 26,91 en Must-C y 43,82 en conjuntos de validación de How2) con un pipeline (ASR+MT) enfoque.', 'fr': "Cet article décrit les systèmes de traduction du Consortium ON-TRAC développés pour la tâche de modèle de bout en bout de l'IWSLT Evaluation 2019 pour la paire de langues anglais-portugais. Le Consortium ON-TRAC est composé de chercheurs issus de trois laboratoires universitaires français\xa0: LIA (Université d'Avignon), LIG (Université Grenoble Alpes) et LIUM (Université du Mans). Un modèle unique de bout en bout construit comme une architecture de codeur-décodeur neuronal avec mécanisme d'attention a été utilisé pour deux soumissions principales correspondant aux deux ensembles d'évaluations EN-PT\xa0: (1) TED (must-C) et (2) How2. Dans cet article, nous étudions notamment l'impact de la mise en commun de corpus hétérogènes pour la formation, l'impact de la tokenisation cible (caractères ou BPE), l'impact de la segmentation des entrées vocales et nous comparons également notre meilleur modèle de bout en bout (UEBL de 26,91 sur MUst-C et 43,82 sur les ensembles de validation How2) à un pipeline (ASR+MT) approche.", 'ja': 'この論文では、英語と→ポルトガル語のペアのためのIWSLT評価2019のエンドツーエンドモデルタスクのために開発されたON - TRACコンソーシアム翻訳システムについて説明します。ON - TRACコンソーシアムは、LIA （ Avignon Universitë ）、LIG （ Universitë Grenoble Alpes ）、LIUM （ Le Mans Universitë ）の3つのフランスの学術研究所の研究者で構成されています。注意メカニズムを備えたニューラルエンコーダデコーダアーキテクチャとして構築された単一のエンドツーエンドモデルを、２つのＥＮ － ＰＴ評価セットに対応する２つの主要なサブミッション： （ １ ） ＴＥＤ （ ＭｕＳＴ － Ｃ ）及び（ ２ ） Ｈｏｗ ２に使用した。この論文では、トレーニングのための不均一体のプーリングの影響、ターゲットトークン化（文字またはBPE ）の影響、音声入力セグメンテーションの影響を特に調査し、最良のエンドツーエンドモデル（ MuST - Cで26.91のBLEUとHow 2検証セットで43.82のBLEU ）をパイプライン（ ASR + MT ）アプローチと比較した。', 'zh': '本文引ON-TRAC联盟译系统,当系统为2019年IWSLT估端到端模型务开英语→葡萄牙语对。 ON-TRAC联盟自三法国学术实验室为:LIA(阿维尼翁大学),LIG(格勒诺布尔阿尔卑斯大学)、LIUM(勒芒大学)。 为注意机神经编码器 - 解码器架构构单端到端以应两EN-PT评集二要:(1)TED(MuST-C)、(2)How2。 其于本文,特究池化异构语料库训练之化,标记(字符、BPE),语音输入分割之化,以至端到端模型(MuST-C上BLEU为26.91,How2验集为43.82)与管道(ASR + MT)法较之。', 'ru': 'В этой статье описываются системы перевода Консорциума ON-TRAC, разработанные для задачи сквозной модели оценки IWSLT 2019 для→ португальской англоязычной пары. Консорциум ON-TRAC состоит из исследователей из трех французских академических лабораторий: LIA (Авиньонский университет), LIG (Гренобльский университет в Альпах) и LIUM (Университет Ле-Мана). Единая сквозная модель, построенная как архитектура нейронный кодер-декодер с механизмом внимания, была использована для двух первичных представлений, соответствующих двум наборам оценок EN-PT: (1) TED (MuST-C) и (2) How2. В этой статье мы, в частности, исследуем влияние объединения гетерогенных тел для обучения, влияние целевой токенизации (символов или BPE), влияние сегментации ввода речи, а также сравниваем нашу лучшую сквозную модель (BLEU 26,91 для MuST-C и 43,82 для наборов проверки How2) с подходом конвейера (ASR+MT).', 'hi': 'यह पेपर अंग्रेजी→ पुर्तगाली भाषा जोड़ी के लिए IWSLT मूल्यांकन 2019 के एंड-टू-एंड मॉडल कार्य के लिए विकसित ON-TRAC कंसोर्टियम अनुवाद प्रणालियों का वर्णन करता है। ON-TRAC कंसोर्टियम तीन फ्रांसीसी अकादमिक प्रयोगशालाओं के शोधकर्ताओं से बना है: LIA (Avignon Université), LIG (Université Grenoble Alpes), और LIUM (Le Mans Université)। ध्यान तंत्र के साथ एक तंत्रिका एनकोडर-डिकोडर आर्किटेक्चर के रूप में निर्मित एक एकल एंड-टू-एंड मॉडल का उपयोग दो ईएन-पीटी मूल्यांकन सेटों के अनुरूप दो प्राथमिक प्रस्तुतियों के लिए किया गया था: (1) टेड (म्यूएसटी-सी) और (2) How2। इस पेपर में, हम विशेष रूप से प्रशिक्षण के लिए विषम निगम पूलिंग के प्रभाव, लक्ष्य टोकनाइजेशन (वर्ण या बीपीई) के प्रभाव, भाषण इनपुट विभाजन के प्रभाव की जांच करते हैं और हम अपने सबसे अच्छे एंड-टू-एंड मॉडल (MUST-C पर 26.91 के BLEU और How2 सत्यापन सेट पर 43.82) की तुलना एक पाइपलाइन (ASR + MT) दृष्टिकोण से भी करते हैं।', 'ga': 'Déanann an páipéar seo cur síos ar na córais aistriúcháin Cuibhreannas ON-TRAC a forbraíodh don tasc samhail ó cheann go ceann de Mheastóireacht IWSLT 2019 don phéire Béarla → Portaingéilis. Tá Cuibhreannas ON-TRAC comhdhéanta de thaighdeoirí ó thrí shaotharlann acadúla Francacha: LIA (Avignon Universitë), LIG (Universitë Grenoble Alpes), agus LIUM (Le Mans Universitë). Baineadh úsáid as samhail amháin ceann go ceann a tógadh mar ailtireacht néarchódóra-díchódóra le meicníocht aird le haghaidh dhá aighneacht phríomha a fhreagraíonn don dá shraith meastóireachtaí EN-PT: (1) TED (MuST-C) agus (2) How2. Sa pháipéar seo, déanaimid fiosrú go háirithe ar an tionchar a bhíonn ag corpora ilchineálach a chomhthiomsú le haghaidh oiliúna, tionchar an chomharthaíochta sprice (carachtair nó BPEanna), tionchar deighilt ionchuir urlabhra agus déanaimid comparáid freisin ar ár múnla ceann-go-deireadh is fearr (BLEU de 26.91 ar MST-C). agus 43.82 maidir le tacair bhailíochtaithe How2) chuig cur chuige píblíne (ASR+MT).', 'ka': 'ამ წიგნის აღწერა ON-TRAC კონსორციომის გადაწყვეტილების სისტემებს, რომელიც განვითარებულია 2019 წლის IWSLT გადაწყვეტილების მოდელური მოდელური დავალებისთვის. ON-TRAC კონსორტიი სამი ფრანუსის აკადემიური ლაბორტიებიდან შექმნა: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) და LIUM (Le Mans Universite). ერთი საკუთარი მოდელი, როგორც ნეიროლური კოდერის რექტიქტიკური აქტიქტიკურაცია, როგორც აღმოჩენება მექნიქტიკური მექნისთვის გამოყენებულია ორი პირველური დამუშაობისთვის, როგორც შემდეგ ორი EN-PT განსაზღვ ამ დოკუნეში, ჩვენ განსაკუთრებულად განვიყენებთ ჰეტეროგენური კოპორაის შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების შედეგების და ჩვენ შემწყენებთ ჩვენი უკეთესი კონ', 'hu': 'Ez a tanulmány az angol portugál nyelvpár számára kifejlesztett ON-TRAC konzorcium fordítási rendszereit ismerteti. Az ON-TRAC konzorcium három francia tudományos laboratórium kutatóiból áll: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) és LIUM (Le Mans Universite). A két EN-PT értékelési készletnek megfelelő elsődleges beadványokhoz egyetlen, figyelemmechanizmusú neurális kódoló-dekódoló architektúra formájában épült end-to-end modellt használtunk: (1) TED (MuST-C) és (2) How2. Ebben a tanulmányban különösen a heterogén corporák összevonásának hatását vizsgáljuk a képzésben, a céltokenizáció hatását (karakterek vagy BPE-k), a beszédbemeneti szegmentáció hatását, valamint összehasonlítjuk a legjobb end-to-end modellünket (BLEU 26.91 a MuST-C és 43.82 a How2 validációs készletek) egy pipeline (ASR+MT) megközelítéssel.', 'el': 'Η παρούσα εργασία περιγράφει τα μεταφραστικά συστήματα της κοινοπραξίας που αναπτύχθηκαν για το ολοκληρωμένο έργο μοντέλου της αξιολόγησης 2019 για το ζευγάρι αγγλικής πορτογαλικής γλώσσας. Η κοινοπραξία αποτελείται από ερευνητές τριών γαλλικών ακαδημαϊκών εργαστηρίων: LIA (Πανεπιστήμιο Αβινιόν), LIG (Πανεπιστήμιο Γρενόμπλ Άλπεις) και LIUM (Πανεπιστήμιο Λε Μανς). Ένα ενιαίο μοντέλο που κατασκευάστηκε ως αρχιτεκτονική νευρικού κωδικοποιητή-αποκωδικοποιητή με μηχανισμό προσοχής χρησιμοποιήθηκε για δύο κύριες υποβολές που αντιστοιχούσαν στα δύο σύνολα αξιολόγησης EN-PT: (1) TED (MuST-C) και (2) How2. Σε αυτή την εργασία, εξετάζουμε κυρίως τον αντίκτυπο της συγκέντρωσης ετερογενών σωμάτων για την εκπαίδευση, τον αντίκτυπο της Tokenisierung στόχων (χαρακτήρες ή BPE), τον αντίκτυπο της τμηματοποίησης εισαγωγής ομιλίας και επίσης συγκρίνουμε το καλύτερο μοντέλο μας (26.91 στο MuST-C και 43.82 σε σύνολα επικύρωσης How2) με μια προσέγγιση αγωγού (ASR+MT).', 'it': "Questo articolo descrive i sistemi di traduzione del Consorzio ON-TRAC sviluppati per il compito end-to-end modello di IWSLT Evaluation 2019 per la coppia inglese portoghese. Il Consorzio ON-TRAC è composto da ricercatori provenienti da tre laboratori accademici francesi: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) e LIUM (Le Mans Universite). Un singolo modello end-to-end costruito come architettura encoder-decoder neurale con meccanismo di attenzione è stato utilizzato per due presentazioni primarie corrispondenti ai due set di valutazioni EN-PT: (1) TED (MuST-C) e (2) How2. In questo articolo, analizziamo in particolare l'impatto della condivisione di corpi eterogenei per la formazione, l'impatto della tokenizzazione del target (caratteri o BPE), l'impatto della segmentazione dell'input vocale e confrontiamo anche il nostro migliore modello end-to-end (BLEU di 26.91 su MuST-C e 43.82 sui set di convalida How2) con un approccio pipeline (ASR+MT).", 'lt': 'Šiame dokumente aprašomos ON-TRAC konsorciumo vertimo sistemos, sukurtos pagal IWSLT vertinimo 2019 m. pavyzdinę užduotį anglų ir portugalų kalbų porai. ON-TRAC konsorciumą sudaro mokslininkai iš trijų Prancūzijos akademinių laboratorijų: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) ir LIUM (Le Mans Universite). A single end-to-end model built as a neural encoder-decoder architecture with attention mechanism was used for two primary submissions corresponding to the two EN-PT evaluations sets: (1) TED (MuST-C) and (2) How2.  Šiame dokumente visų pirma tiriame įvairiapusių korprų derinimo mokymui poveikį, tikslinio ženklinimo poveikį (simboliai arba BPEs), kalbos įvedimo segmentacijos poveikį ir taip pat palyginame geriausią model į nuo galo iki galo (BLEU 26.91 dėl MuST-C ir 43.82 dėl How2 patvirtinimo rinkinių) su vamzdyno metodu (ASR+MT).', 'mk': 'Овој весник ги опишува системите на превод на конзорциумот ON-TRAC развиени за задачата од крај до крај на моделот на IWSLT Evaluation 2019 за парот англиски - португалски јазик. Конзорциумот ОН-ТРАЦ се состои од истражувачи од три француски академски лаборатории: ЛИА (Авињонскиот универзитет), ЛИГ (Универзитетот Гренобл Алпи) и ЛИУМ (Универзитетот Ле Манс). Еден модел од крај до крај изграден како архитектура на нервен кодер-декодер со механизам на внимание беше употребен за две примарни пренесувања кои одговараат на двата набори евалуации на EN-PT: (1) TED (MuST-C) и (2) How2. Во овој документ, ние особено го истражуваме влијанието на спојувањето хетерогенски корпора за обука, влијанието на токенизацијата на метата (карактери или БПЕ), влијанието на сегментацијата на влогот на говорот и, исто така, го споредуваме нашиот најдобар модел од крај до крај (БЛЕ од 26.91 на МУСТ-Ц и 43.82 на сетите на валидација How2) со приста', 'kk': 'Бұл қағаз "ON-TRAC Consortium" аудару жүйелерін 2019 жылы IWSLT бағалау үшін ағылшын және португаль тілдерінің екі үшін жасалған IWSLT үлгісінің соңындағы тапсырмасының үлгісін анықтайд ON- TRAC Консортия үш французша академиялық лабораториялардан зерттеушілерден құрылады: LIA (Авигнон университеті), LIG (Гренобл алпес университеті) және LIUM (Ле Манс университеті). Невралдық кодер- декодер архитектурасы ретінде құрылған бір аяқтау үлгісі, назардағы екі EN- PT мәліметтеріне сәйкес келетін екі негізгі жіберу үшін қолданылды: (1) TED (MuST- C) және (2) How2. Бұл қағазда, біз әсіресе гетероген корпораны біріктіру үшін, мақсатты токенизацияның (символдар немесе BPEs) нәтижесін (белгілер немесе белгілер немесе белгілер) сәйкестігінің сегментациясының нәтижесін зерттеп, сондай-ақ біз біздің ең жақсы аяқтау үлгімізді (МУ', 'ms': 'Kertas ini menggambarkan sistem terjemahan konsorcium ON-TRAC yang dikembangkan untuk tugas model akhir-akhir dari Evaluasi IWSLT 2019 untuk pasangan bahasa Inggeris Portugis. ON-TRAC Consortium terdiri daripada peneliti dari tiga makmal akademik Perancis: LIA (Avignon Universite), LIG (Universite Grenoble Alpes), dan LIUM (Le Mans Universite). Model tunggal akhir-akhir dibina sebagai arkitektur pengekod-dekoder saraf dengan mekanisme perhatian digunakan untuk dua penghantaran utama yang sepadan dengan dua set penilaian EN-PT: (1) TED (MuST-C) dan (2) How2. Dalam kertas ini, kami terutama menyelidiki kesan kumpulan corpora heterogene untuk latihan, kesan tokenisasi sasaran (aksara atau BPEs), kesan segmen input ucapan dan kami juga membandingkan model terbaik kami akhir-akhir (BLEU 26.91 pada MuST-C dan 43.82 pada set pengesahihan How2) dengan pendekatan paip (ASR+MT).', 'ml': 'ഈ പേപ്പറിന്റെ വിശദീകരിക്കുന്നു-TRAC കോണ്\u200dസോര്\u200dട്ടിയം പരിഭാഷ സിസ്റ്റമുകള്\u200dക്ക് ഐഡബ്ലോട്ട് അവസാനിക്കാനുള്ള മോഡല്\u200d ജോലിയുടെ അവസാനം  ON-TRAC കോണ്\u200dസോര്\u200dട്ടിയം മൂന്നു ഫ്രെഞ്ച് കാക്കേഡിക് ലേബറികളില്\u200d നിന്നും പഠിപ്പിക്കുന്ന നിരീക്ഷകരില്\u200d നിന്നും ഒരുപാട് ഉണ്ട്: ലിയা (അഭിനേനി ശ്രദ്ധിക്കുന്ന മെക്കയിസ്റ്റീമിനുള്ള പ്രധാനപ്രകാരം രണ്ടു പ്രധാനപ്രകാരം മോഡല്\u200d നിര്\u200dമ്മിക്കപ്പെട്ടിരിക്കുന്നു: (1) ടെഡി (മുസ്റ്റ്- സി) എന്\u200dറെ വിലാസങ്ങള്\u200d In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of speech input segmentation and we also compare our best end-to-end model (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.', 'mn': 'Энэ цаас ON-TRAC Консортиум хөгжлийн системийг 2019 оны IWSLT дүгнэлтийн 2019 оны төгсгөлийн загварын ажлын төгсгөлд хөгжүүлсэн юм. ON-TRAC Консортиум нь Французын академик лабораторийн 3 судлаачид: LIA (Авигнон университет), LIG (Гренобл алпес университет) болон LIUM (Ле Манс университет) юм. Нэг төгсгөлийн загвар, анхаарлаа хангах механизмтай мэдрэлийн кодер-декодер архитектур болгон бүтээгдэхүүний хоёр EN-PT дүгнэлттэй холбогдсон хоёр анхны дамжуулалтын хувьд хэрэглэгдсэн юм. (1) TED (MuST-C) болон (2) How2. Энэ цаасан дээр бид ихэвчлэн heterogeneous corpora-г суралцах, зорилготой тодорхойлолтын нөлөөг, илтгэлийн оролцооны үр дүнг, илтгэлийн оролцооны загварын нөлөөг судалж, мөн бид өөрсдийн хамгийн сайн төгсгөл загварыг (MuST-C 26.91 болон How2 шийдвэрлэх загвар дээр 43.82 BLEU) хоолойн шугам шуга', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi tat-traduzzjoni tal-Konsorzju ON-TRAC żviluppati għall-kompitu mudell minn tarf sa tarf tal-Evalwazzjoni tal-IWSLT 2019 għall-par tal-lingwa Ingliża Portugiża. Il-Konsorzju ON-TRAC huwa magħmul minn riċerkaturi minn tliet laboratorji akkademiċi Franċiżi: LIA (Avignon Universite), LIG (Universite Grenoble Alpes), u LIUM (Le Mans Universite). Mudell wieħed minn tarf sa tarf mibni bħala arkitettura ta’ dekoder newrali b’mekkaniżmu ta’ attenzjoni ntuża għal żewġ sottomissjonijiet primarji li jikkorrispondu għa ż-żewġ settijiet ta’ evalwazzjonijiet EN-PT: (1) TED (MuST-C) u (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of speech input segmentation and we also compare our best end-to-end model (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.', 'no': 'Denne papiret beskriver ON-TRAC Consortium-omsetjingssystemet utvikla for modellen til slutt-til-slutt i IWSLT-evalueringa 2019 for den engelske portugisiske paron. ON-TRAC Consortium er lagt av forskere frå tre fransk akademiske laboratoriar: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) og LIUM (Le Mans Universite). Ein enkel ende- til- sluttmodell bygd som ein neuralkoderingsarkitektur med oppmerksmekanisme ble brukt for to primære opplysningar som tilsvarar to EN- PT- evalueringssett: (1) TED (MuST- C) og (2) How2. I denne papiret særlig undersøker vi effekten av å poola heterogenen korpora for opplæring, effekten av målet tokenisering (teikn eller BPEs), effekten av opplæringssegmentasjon av tale, og vi sammenligner også vår beste endemodul (BLEU av 26,91 på MuST-C og 43,82 på How2-valeringssett) til ein tilnærming av røyr (ASR+MT).', 'sr': 'Ovaj papir opisuje sisteme prevođenja konzorcijama ON-TRAC razvijene za model kraja do kraja IWSLT ocjene 2019 za parove engleskog portugalskog jezika. ON-TRAC Konzorcijum sastoji se od istraživača iz tri francuske akademijske laboratorije: LIA (Univerzitet avignona), LIG (Univerzitet Grenoble Alpes) i LIUM (Univerzitet Le Mans). Jedan model do kraja izgrađen kao arhitektura neuronskog kodera sa mehanizam pažnje je korišćen za dve primarne isporuke koje odgovaraju dva seta procjene EN-PT: (1) TED (MuST-C) i (2) How2. U ovom papiru, posebno istražujemo uticaj okupljanja heterogenezne korpore na obuku, uticaj ciljne tokenizacije (karakteri ili BPE), uticaj segmentacije govora i uspoređujemo i naš najbolji model kraja do kraja (BLEU od 26,91 na MuST-C i 43,82 na sete validacije How2) sa pristupom naftovoda (ASR+MT).', 'pl': 'Niniejszy artykuł opisuje systemy tłumaczeń konsorcjum ON-TRAC opracowane dla kompleksowego zadania modelowego oceny IWSLT 2019 dla pary językowej angielskiego portugalskiego. Konsorcjum ON-TRAC składa się z naukowców z trzech francuskich laboratoriów akademickich: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) i LIUM (Le Mans Universite). Pojedynczy model end-to-end zbudowany jako architektura kodera neuronowego z mechanizmem uwagi został zastosowany do dwóch głównych zgłoszeń odpowiadających dwóm zestawom ocen EN-PT: (1) TED (MuST-C) i (2) How2. W niniejszym artykule badamy w szczególności wpływ łączenia heterogenicznych korpusów na trening, wpływ tokenizacji docelowej (znaków lub BPE), wpływ segmentacji wejścia mowy oraz porównujemy nasz najlepszy model end-to-end (BLEU 26.91 na MuST-C i 43.82 na zestawy walidacyjne How2) z podejściem pipeline (ASR+MT).', 'ro': 'Această lucrare descrie sistemele de traducere ON-TRAC Consortium dezvoltate pentru sarcina de model end-to-end a IWSLT Evaluation 2019 pentru perechea de limbi portugheze engleze. Consorțiul ON-TRAC este compus din cercetători din trei laboratoare academice franceze: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) și LIUM (Le Mans Universite). Un singur model end-to-end construit ca o arhitectură de encoder-decoder neural cu mecanism de atenție a fost utilizat pentru două depuneri primare corespunzătoare celor două seturi de evaluări EN-PT: (1) TED (MuST-C) și (2) How2. În această lucrare, investigăm în special impactul combinării corporelor eterogene pentru formare, impactul tokenizării țintelor (caractere sau BPE), impactul segmentării de intrare a vorbirii și comparăm, de asemenea, cel mai bun model end-to-end (BLEU de 26.91 pe MuST-C și 43.82 pe seturile de validare How2) cu o abordare pipeline (ASR+MT).', 'si': 'මේ පැත්තේ ON-TRAC Consorcium වාර්තාව පද්ධතිය ප්\u200dරවේශ කරනවා IWSLT විශ්ලේෂණය 2019 ගේ අන්තිම විශ්ලේෂණය සඳහා ඉංග්\u200dරීසිය  පුර්ත ON-TRAC Consorpium is composed of reseresectors from three French science labs: LIA (AviGnon Universte), LIG (Universte GreNoble Alps), and LIUM (La Mans Universte). එකම අවසානයෙන් අවසානයෙන් අවසානය කරලා තියෙන්නේ න්\u200dයූරාල් කෝඩාර් එක්ක සිද්ධාවක් විදියට අවසානය කරන්න ප්\u200dරධාන සිද්ධාවක් දෙකට භාවිතා කරලා ති මේ පැත්තේ, අපි විශේෂයෙන් පරීක්ෂණය කරන්නේ හෙටෙරෝජනේස් කොර්පෝරා එක්ක පරීක්ෂණය සඳහා පරීක්ෂණය, ඉලක්ෂණ ටොකෙනිස් සඳහා පරීක්ෂණය (අක්ෂරෝපය හෝ BPEs), වාර්තාවක් ඇතුළු ඇතුළු', 'ta': 'இந்த காகிதத்தின் ON- TRAC மொழிபெயர்ப்பு அமைப்புகளை வரையறுக்கிறது IWSLT மதிப்பீடு 2019 ஆங்கிலத்திற்கு - போர்த்துகீசிஷ் மொழி ஜோடி உருவாக்கப ON-TRAC Consortium is composed of researchers from three French academic laboratories: LIA (Avignon Universite), LIG (Universite Grenoble Alpes), and LIUM (Le Mans Universite).  இந்த இரண்டு EN- PT evaluations அமைப்புகளுக்குப் பொருத்தமான இரண்டு முதல் அனுப்புகளுக்கு ஒரு முடிவு மாதிரி உருவாக்கப்பட்டுள்ளது: (1) TED (MuST- C) மற்றும் (2) How2. இந்த காக்கியத்தில், நாம் குறிப்பாக பயிற்சிக்கு வெப்பநிறுவனத்தின் விளைவுகளை தேவைப்படுத்துகிறோம், இலக்கு குறிப்புகள் (எழுத்துகள் அல்லது BPEs), பேச்சு உள்ளீடு துண்டின் விளைவுகள், பேச்சு உள்ளீட்டு துண்டின', 'so': 'Kanu waa qoraal ku qoran qoraalka ON-TRAC Consortium-tarjuma nidaamka qoraalka oo loo horumariyey ugu dambeyn-to-end model task of IWSLT evaluation 2019 ee ingiriisiga /Burtuqiis labaad. ON-TRAC Consortium waxaa ka mid ah baaritaanka ka soo baxa saddex jaamacadeed ee Faraansiis: LIA (Avignon University), LIG (Universite Grenoble Alpes), and LIUM (Le Mans University). Tusaale hal ugu dambaysta ah oo loo dhisay dhismo neural encoder-decoder architecture with attention mechanism waxaa loo isticmaalay laba primary submissions oo u eg labadii EN-PT evaluations: (1) TED (MuST-C) and (2) How2. Qoraalkan waxaan si gaar ah u baaraynaa saameyn ku saabsan baabuurta shirkadda xiliga ah, saameyn ku yeelashada calaamadda waxyaabaha leh (xarafta ama BPEs), saameyn ku yeelashada qeybta galmada hadalka iyo sidoo kale waxaynu isbarbardhignaa qaababka ugu wanaagsan ee ugu dambeeya ugu dambaysta (BLEU 26.91 ee MuST-C iyo 43.82 ee ku saabsan How2-bandhigyada) xagga qaabka ah (ASR+MT).', 'sv': 'Denna uppsats beskriver ON-TRAC Consortium översättningssystem som utvecklats för IWSLT Evaluation 2019 för engelska portugisiska språkparet. ON-TRAC konsortiet består av forskare från tre franska akademiska laboratorier: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) och LIUM (Le Mans Universite). En enda end-to-end-modell byggd som en neural encoder-dekoder-arkitektur med uppmärksamhetsmekanism användes för två primära inlämningar motsvarande de två EN-PT utvärderingar uppsättningarna: (1) TED (MuST-C) och (2) How2. I denna uppsats undersöker vi särskilt påverkan av att poola heterogena corpora för träning, påverkan av måltokenisering (tecken eller BPE), påverkan av segmentering av talinmatning och vi jämför även vår bästa end-to-end modell (BLEU av 26,91 på MuST-C och 43,82 på How2 valideringsuppsättningar) med en pipeline (ASR+MT) metod.', 'ur': 'This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English ،Portuguese language pair. ON-TRAC Consortium تو تین فرانسوی علم آزمائش آزمائش کے پھیلانے والے ہیں: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) اور LIUM (Le Mans Universite). ایک آخر-پائندی موڈل بنایا گیا ہے نورول اکڈر-ڈیکڈر معماری کے طور پر جو توجه کی مکانیسم کے ساتھ بنائی گئی تھی، دو پائندی مکانیسم کے لئے استعمال کی گئی تھی جو دو EN-PT ارزیابی سٹ کے مطابق مطابق ہے: (1) TED (MuST-C) اور (2) How2. ہم اس کاغذ میں مخصوصا تحقیق کرتے ہیں کہ تدریس کے لئے ہٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ وٹ موڈل (MuST-C پر 26.91 بل وٹ وٹ وٹ وٹ وٹ و', 'vi': 'Tờ giấy này mô tả hệ thống dịch chuyển ON-TRAC được phát triển cho nhiệm vụ mô hình cuối cùng của IWSLT →  Cặp ngôn ngữ Bồ Đào Nha. N-TRAC Consortium được bao gồm các nhà nghiên cứu từ ba phòng thí nghiệm giáo dục Pháp: ALA (Avignon Universit5235;Grenoble Alpes) và LIum (Le Mans Universit235; Một mô hình cuối-tới-cuối được xây dựng như một cấu trúc bộ mã hóa thần kinh với cơ chế tập trung được sử dụng cho hai bộ trình bày đầu tiên tương ứng với hai bộ đánh giá ước lượng người: Trong tờ giấy này, chúng tôi đặc biệt nghiên cứu tác động của việc kết hợp các "vật thể khác giới" cho việc huấn luyện, tác động của vật thể đạt mục tiêu (ký tự hay BPA), tác động của phân đoạn nhập giọng nói, và chúng tôi cũng so sánh mô hình cuối cùng tốt nhất của chúng tôi (nguyên tắc 2nguyên.', 'uz': "This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English →  Name ON-TRAC konortium 3 Fransuz akademik laboratorielardan taʼminlovchilar yaratiladi: LIA (Avignon Universit ë), LIG (Universitë Grenoble Alpes), LIUM (Le Mans Universitë). Name Bu qogʻozda, biz mashhur qilish uchun hech qanday kompaniyalarni ko'rib chiqaramiz, qanday tashkilotni ko'rsatish (belgi yoki BPE), gapiruvchi kiritish qismlarini tasdiqlash natijasini o'rganamiz va bizning eng oxirigi modelimizni (26.91 MuST-C va How2 tasdiqlash uchun 43.82 ta'minlovchiga BLEU'ning eng yaxshi ko'rinishimizni o'rganamiz.", 'bg': 'Настоящата статия описва системите за превод на консорциума разработени за задачата на модела от край до край на Оценката на английския португалски език. Консорциумът е съставен от изследователи от три френски академични лаборатории: ЛИА (Авиньон Университет), ЛИГ (Университет Гренобъл Алпи) и ЛИУМ (Университет Льо Ман). Един модел от край до край, изграден като архитектура на невронен кодер-декодер с механизъм на внимание, беше използван за две първични подавания, съответстващи на двата комплекта оценки EN-PT: (1) TED (MuST-C) и (2) How2. В тази статия по-конкретно изследваме въздействието на обединяването на хетерогенни корпуси за обучение, въздействието на целевата токенизация (символи или БПЕ), въздействието на сегментацията на входящите речи и сравняваме най-добрия ни модел от край до край (от 26.91 за МСТ-С и 43.82 за наборите за валидиране на How2) с подхода на тръбопровода (ASR+MT).', 'da': "Denne artikel beskriver ON-TRAC Consortium-oversættelsessystemerne udviklet til IWSLT Evaluation 2019 for det engelsk portugisiske sprogpar. ON-TRAC konsortiet består af forskere fra tre franske akademiske laboratorier: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) og LIUM (Le Mans Universite). En enkelt end-to-end model bygget som en neural encoder-dekoder-arkitektur med opmærksomhedsmekanisme blev brugt til to primære indsendelser svarende til de to EN-PT evalueringssæt: (1) TED (MuST-C) og (2) How2. I denne artikel undersøger vi især virkningen af pooling af heterogene corpora til træning, virkningen af måltokenisering (tegn eller BPE'er), virkningen af taleinput segmentering og vi sammenligner også vores bedste end-to-end model (BLEU af 26,91 på MuST-C og 43,82 på How2 valideringssæt) med en pipeline (ASR+MT) tilgang.", 'hr': 'Ovaj papir opisuje sustave prevođenja konzorcijama ON-TRAC razvijene za model kraja do kraja ocjene IWSLT 2019 za parove engleskog i portugalskog jezika. ON-TRAC Konzorcijum sastoji se od istraživača iz tri francuske akademske laboratorije: LIA (Univerzitet avignona), LIG (Univerzitet Grenoble Alpes) i LIUM (Univerzitet Le Mans). Jedan model do kraja izgrađen kao arhitektura neuronskog kodera s mehanizam pažnje koristio se za dva primjerna isporuka odgovarajuća dva seta procjene EN-PT: (1) TED (MuST-C) i (2) How2. U ovom papiru, posebno istražujemo učinak okupljanja heterogeneznog korporacije za obuku, učinak ciljne tokenizacije (karakteri ili BPEs), učinak segmentacije uloga govora i uspoređujemo i naš najbolji model kraja do kraja (BLEU od 26,91 na MuST-C i 43,82 na sete validacije How2) s pristupom cijevi (ASR+MT).', 'nl': "Deze paper beschrijft de ON-TRAC Consortium vertaalsystemen ontwikkeld voor de end-to-end modeltaak van IWSLT Evaluation 2019 voor het Engels Portugees taalpaar. ON-TRAC Consortium bestaat uit onderzoekers van drie Franse academische laboratoria: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) en LIUM (Le Mans Universite). Een enkel end-to-end model gebouwd als een neurale encoder-decoder architectuur met aandacht mechanisme werd gebruikt voor twee primaire inzendingen die overeenkomen met de twee EN-PT evaluatiesets: (1) TED (MuST-C) en (2) How2. In dit artikel onderzoeken we met name de impact van het poolen van heterogene corpora voor training, de impact van target tokenization (karakters of BPE's), de impact van spraak input segmentatie en we vergelijken ook ons beste end-to-end model (BLEU van 26.91 op MuST-C en 43.82 op How2 validatie sets) met een pipeline (ASR+MT) benadering.", 'de': 'Dieser Beitrag beschreibt die Übersetzungssysteme des ON-TRAC Konsortiums, die für die End-to-End Modellaufgabe der IWSLT Evaluation 2019 für das englisch-portugiesische Sprachpaar entwickelt wurden. Das Konsortium ON-TRAC besteht aus Forschern aus drei französischen akademischen Labors: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) und LIUM (Le Mans Universite). Ein einzelnes End-to-End-Modell, das als neuronale Encoder-Decoder-Architektur mit Aufmerksamkeitsmechanismus gebaut wurde, wurde für zwei primäre Einreichungen verwendet, die den beiden EN-PT-Auswertungssätzen entsprechen: (1) TED (MuST-C) und (2) How2. In diesem Beitrag untersuchen wir insbesondere die Auswirkungen von Pooling heterogener Korpora für das Training, Auswirkungen von Target Tokenisierung (Zeichen oder BPEs), Auswirkungen von Spracheingabesegmentierung und vergleichen unser bestes End-to-End Modell (BLEU von 26.91 auf MuST-C und 43.82 auf How2 Validierungssets) mit einem Pipeline (ASR+MT)-Ansatz.', 'id': 'Kertas ini menjelaskan sistem terjemahan ON-TRAC Consortium yang dikembangkan untuk tugas model akhir-akhir dari IWSLT Evaluation 2019 untuk pasangan bahasa Inggris · Portugis. ON-TRAC Consortium terdiri dari peneliti dari tiga laboratorium akademik Perancis: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) dan LIUM (Le Mans Universite). Model tunggal dari akhir ke akhir dibangun sebagai arsitektur dekoder saraf dengan mekanisme perhatian digunakan untuk dua pengiriman utama yang cocok dengan dua set evaluasi EN-PT: (1) TED (MuST-C) dan (2) How2. Dalam kertas ini, kami terutama menyelidiki dampak dari mengumpulkan korpra heterogene untuk latihan, dampak tokenisasi sasaran (karakter atau BPEs), dampak dari segmentasi input pidato dan kami juga membandingkan model terbaik kami akhir-akhir (BLEU dari 26.91 pada MuST-C dan 43.82 pada set validasi How2) dengan pendekatan pipa (ASR+MT).', 'ko': '본고는 2019년 영어-포르투갈어에 대한 IWSLT 평가단부터 단까지 모델 임무를 위해 개발한 ON-TRAC 공동 번역 시스템을 묘사한다.ON-TRAC 연맹은 세 개의 프랑스 학술 실험실 연구원으로 구성되어 있는데 그것이 바로 LIA(아비니옹대학), LIG(그레노브르 알프스대학), LIUM(르망대학)이다.주의 메커니즘을 가진 신경 인코더-디코더 체계 구조로 구축된 단일 끝에서 끝 모델은 두 개의 주요 제출에 사용되며 두 개의 EN-PT 평가 집합에 대응한다. (1)TED(반드시-C)와 (2)How2.본고에서 우리는 이구 어료 라이브러리를 교육에 집중시키는 영향, 목표 표기화(문자 또는 BPE)의 영향, 음성 입력 분할의 영향을 중점적으로 연구하고 우리의 가장 좋은 끝에서 끝까지의 모델(MuST-C에서 BLEU는 26.91, How2 검증집에서 BLEU는 43.82)과 파이프(ASR+MT) 방법을 비교했다.', 'tr': 'Bu kagyz ON-TRAC konsortium terjime sistemlerini IWSLT we Portugalça dil çiftleri üçin 2019-nji ýylyň deňlenmesi üçin gelinýän täblisaň üçin bejerildi. ON-TRAC konsortium üç fransuz akademiki laboratoriýanyň barlagynda ýazylýar: LIA (Uniwersitet Avignon), LIG (Uniwersitet Grenoble Alpes) we LIUM (Uniwersitet Le Mans). Diňleşme mekanizmasy bilen nuýral kodçy arhitektura hasaplanýan ýeke taýdan soňra bir nuýumçy nuýumçy üçin iki sany EN-PT deňleşme düzümlerini (1) TED (MuST-C) we (2) How2 üçin ullanýardy. Bu kagyzda, biz çykyş girişi segmentasiýasynyň täsirini çykaryp, MuST-C we 43.82-de How2 hakyndaky iň gowy ýagdaýynyň (ASR+MT) golaýynyň (26.91 we How2 hakynda deňleýän çykyş şeklinde) täsirini çykarýarys.', 'fa': 'این کاغذ سیستم\u200cهای ترجمه ON-TRAC Consortium را توصیف می\u200cکند که برای کار مدل پایان و پایان در ارزیابی IWSLT ۲۰۱۹ برای جفت زبان انگلیسی پورتوژیک توسعه داده شده است. ON-TRAC Consortium از محققان سه آزمایشگاه دانشگاه فرانسوی ساخته شده است: LIA (Universite Avignon), LIG (Universite Grenoble Alpes) و LIUM (Le Mans Universite). یک مدل پایان به پایان ساخته شده به عنوان یک معماری که با مکانیسم توجه به عنوان یک ساختار کودکتر عصبی با یک مکانیسم برای دو تسلیم اصلی که با دو تنظیم ارزیابی EN-PT تسلیم می\u200cشود استفاده می\u200cشود: (۱) TED (MuST-C) و (۲) How2. در این کاغذ، ما مخصوصاً تحقیق تاثیر جمع کردن شرکت متفاوتی برای آموزش، تاثیر تفکیل هدف (karakters or BPEs), تاثیر بخش ورودی سخنرانی و همچنین بهترین مدل ورودی (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) را با یک دستور لوله (ASR+MT) مقایسه می\u200cکنیم.', 'af': "Hierdie papier beskrywe die ON-TRAC Consortium vertalingsstelsels ontwikkeld vir die einde-tot-einde model taak van IWSLT Evaluering 2019 vir die Engels  Portugese taal paar. ON-TRAC Consortium is bestuur van resekers van drie Franse akademiese laboratories: LIA (Avignon Universite), LIG (Universite Grenoble Alpes), en LIUM (Le Mans Universite). 'n Enkel einde-na-einde model gebou as 'n neural enkoder-dekoder-arkitektuur met aandag mekanisme is gebruik vir twee primêre onderwerplings wat ooreenstemmend aan die twee EN-PT evaluerings stel: (1) TED (MuST-C) en (2) How2. In hierdie papier, ons spesifieke ondersoek effekt van die pooling van heterogenee korpora vir onderwerp, effekt van doel tokenisasie (karakters of BPEs), effekt van spraak invoer segmentasie en ons vergelyk ook ons beste end-to-end-model (BLEU van 26.91 op MuST-C en 43.82 op How2 validasie stelle) met 'n pyplin toegang (ASR+MT).", 'sw': "Gazeti hili linaelezea mfumo wa utafsiri wa ON-TRAC ulioandaliwa kwa ajili ya kazi ya mwisho ya mifano ya Uchunguzi wa IWSLT 2019 kwa ajili ya Kiingereza 'wawili wa lugha ya Kireno'. Shirika la ON-TRAC linajumuishwa na watafiti kutoka kwenye maabara matatu ya kitaaluma ya Kifaransa: LIA (Chuo Kikuu cha Avignon), LIG (Makuu ya Kikuu cha Grenoble), na LIUM (Chuo Kikuu cha Le Mans). Mfano mmoja wa mwisho wa mwisho ulijengwa kama ujenzi wa kodi-decodi wa ubongo na mfumo wa kutoa hisia ulitumiwa kwa ajili ya ujumbe wa msingi wa vitabu viwili vya EN-PT yanayohusiana na tathmini hizo:(1) TED (MuST-C) na (2) How2. Katika karatasi hii, tunachunguza madhara ya kupunguza makampuni yenye rangi kwa ajili ya mafunzo, madhara ya kuonyesha alama ya malengo (wahusika au BPE), madhara ya mgawanyiko wa mazungumzo ya hotuba na pia tunalinganisha mfano wetu bora wa mwisho wa mwisho (BLEU wa 26.91 kwenye MuST-C na 43.82 kwenye seti ya How2) kwa njia ya pipeline (ASR+MT).", 'am': 'ይህ ፕሮግራም የፖርቱጋሊኛ ቋንቋ ሁኔታ የIWSLT ማስታወቂያ 2019 የመጨረሻ-ወደ-መጨረሻ ሞዴል ስራዎችን ለመግለጫው የON-TRAC ኮንኖርቲም ተርጓሚዎች ስርዓቶች ይናገራል፡፡ የ-TRAC ኮንስሮቲም ከሦስት ፈረንሳይኛ አካዳሚክ ተማሪ ተማሪዎችን ነው፤ LIA (የዩንቨርስቲ ዩንቨርስቲ), LIG (ዩንቨርስቲ ግሪባቢ አልፍ) እና LIUM (ሊ ማን ዩንቨርስቲ). የአንዲት የፍጻሜ መጨረሻ ሞዴል በሁለተኛው EN-PT ውጤቶች በሚያያያየው ሁለት የፊደል አካባቢ አካባቢ መሠረት ተጠቃሚ ነበር:(1) ቴድ (MuST-C) እና (2) ሆw2 በዚህ ፕሮግራም፣ የኮርፖርት ማኅበረሰብ፣ የጉዳዩ ማቀናቀል፣ የንግግር የውስጥ ግንኙነት ማቀናቀል፣ የፍጻሜውን የፍጻሜ ዓይነት እና በሙST-C ላይ 26.91 እና በሆ2ው አካል ላይ 43.82 (ASR+MT) ጥያቄን እናስተያየዋለን፡፡', 'hy': 'Այս հոդվածը նկարագրում է "Օն-ԹՌԱԿ" կոնսորցիումի թարգմանման համակարգերը, որոնք զարգացել են 2019 թվականի IW-Սլեթ գնահատման վերջ-վերջ մոդելի առաջադրանքի համար անգլերենի ՝ պորտուգալերենի զույգի համար: Կոնզորցիումը կազմված է երեք ֆրանսիական ակադեմիական լաբորատորիաների հետազոտողներից՝ ԼիԱ (Ավինիոն համալսարան), ԼիԳ (Գրենոբլ Ալպեսների համալսարան) և ԼիԱ (ԼեՄանս համալսարան): A single end-to-end model built as a neural encoder-decoder architecture with attention mechanism was used for two primary submissions corresponding to the two EN-PT evaluations sets: (1) TED (MuST-C) and (2) How2.  In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of speech input segmentation and we also compare our best end-to-end model (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.', 'bn': 'This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English  Portuguese language pair.  ওন-ট্রাক কনসোর্টিয়াম তিন ফ্রেঞ্চ শিক্ষাবিদ্যালয়ের শিক্ষার্থীদের মধ্যে তৈরি করা হয়েছে: লিয়া (এভিনেশন ইউনিভার্সিট), লিজি (বিশ্ববিদ্যালয় একটি শেষ পর্যন্ত মডেল তৈরি করা হয়েছে নিউরেল এনকোডার-ডেকোডার কাঠামো হিসেবে মনোযোগ দিয়ে মনোযোগ দিয়ে দুটি প্রাথমিক মূল্যায়নের জন্য ব্যবহার করা হয়েছে: (1) TED (মুস্টি-C) এব (2 এই কাগজটিতে আমরা বিশেষ করে প্রশিক্ষণ, লক্ষ্যের প্রভাব (চরিত্র অথবা বিপেস), বক্তৃতা ইনপুট বিভাগের প্রভাব, এবং আমরা আমাদের সর্বোচ্চ শেষ পর্যন্ত মডেলের (২৬. ৯১ এর বিলিউ মুস্টি-সি এবং হাউ২ বৈধ সেটে ৪৩.', 'az': 'Bu kağıt ON-TRAC Konsorcijum çevirim sistemlərini İngilizci və Portugal dili çiftləri üçün 2019-ci IWSLT Evaluyasının son-to-end modeli işi üçün hazırlanmışdır. ON-TRAC Konsorcijum üç Fransızca akademik laboratoriyalardan təhsil edilir: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) və LIUM (Le Mans Universite). İki EN-PT değerlendirmələri ilə müqayisədə olan iki ilk təklif təklif təklif üçün nöral kodlayıcı-dekoder arhitektarı kimi inşa edilmiş bir model: TED (MuST-C) və (2) How2. Bu kağıtda, biz müəyyən edilə ki, təhsil etmək üçün heterogenel korpora birləşdirmək, məqsəd tokenizasyonun (karakterlər və BPEs) təsirlərinin, sözlərin giriş segmentasiyasının təsirlərinin təsirini araşdırırıq. Biz də müəyyən olunmuş ən yaxşı modeliyimizi (MuST-C 26,91 və How2 təsdiqlənmək setlərində 43,82 BLEU-nin) bir bor (ASR+MT) approach ilə salırıq.', 'sq': 'This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English  Portuguese language pair.  ON-TRAC Consortium përbëhet nga kërkues nga tre laboratori akademikë francezë: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) dhe LIUM (Le Mans Universite). Një model i vetëm nga fundi në fund i ndërtuar si arkitekturë e koduesit nervor me mekanizëm vëmendjeje u përdorë për dy paraqitje kryesore që korrespondonin me dy grupet e vlerësimeve EN-PT: (1) TED (MuST-C) dhe (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of speech input segmentation and we also compare our best end-to-end model (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.', 'ca': "Aquest article descriu els sistemes de traducció del consorci ON-TRAC desenvolupats per a la tasca model de final a final de l'IWSLT Evaluation 2019 per al parell de llenguatge anglès - portuguès. El consortiu ON-TRAC està compost de investigadors de tres laboratoris acadèmics francesos: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) i LIUM (Le Mans Universite). Un únic model de final a final construït com a arquitectura de codificador neural amb mecanisme d'atenció va ser utilitzat per dues presentacions primàries que corresponden a dos conjunts d'evaluacions EN-PT: (1) TED (MuST-C) i (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of speech input segmentation and we also compare our best end-to-end model (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.", 'fi': 'Tässä artikkelissa kuvataan ON-TRAC Consortium -käännösjärjestelmiä, jotka on kehitetty IWSLT Evaluation 2019:n kokonaismallitehtävään englannin portugalin kieliparille. ON-TRAC Consortium koostuu tutkijoista kolmesta ranskalaisesta akateemisesta laboratoriosta: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) ja LIUM (Le Mans Universite). Kaksi EN-PT-arviointisarjaa vastaavaa ensisijaista aineistoa varten käytettiin yhdestä päästä päähän -mallista, joka rakennettiin neurokooderi-dekooderiarkkitehtuuriksi huomiomekanismilla: (1) TED (MuST-C) ja (2) How2. Tässä artikkelissa tutkimme erityisesti heterogeenisten korpusten yhdistämisen vaikutusta harjoitteluun, kohdetokenisoinnin vaikutusta (merkit tai BPE), puheensyötteen segmentoinnin vaikutusta ja vertaamme myös parasta end-to-end-malliamme (BLEU 26,91 MuST-C:ssä ja 43,82 How2-validointisarjassa) pipeline-lähestymistapaan (ASR+MT).', 'et': 'Käesolevas dokumendis kirjeldatakse ON-TRAC konsortsiumi tõlkesüsteeme, mis on välja töötatud IWSLT hindamise 2019. aasta lõpust-otsa mudeli ülesandeks inglise portugali keele paari jaoks. ON-TRAC konsortsium koosneb teadlastest kolmest Prantsuse akadeemilisest laborist: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) ja LIUM (Le Mans Universite). Kahe EN-PT hindamiskomplekti puhul kasutati ühte tähelepanumehhanismiga neurokodeeri-dekooderi arhitektuurina ehitatud otsast otsani mudelit: 1) TED (MuST-C) ja 2) How2. Selles töös uurime eriti heterogeensete korpuste koondamise mõju koolituseks, sihtmärkide tokeniseerimise mõju (märgid või BPE), kõnesisendi segmenteerimise mõju ning võrdleme ka oma parimat otsast otsani mudelit (BLEU 26,91 MuST-C ja 43,82 How2 valideerimiskomplektide kohta) torujuhtme (ASR+MT) lähenemisega.', 'cs': 'Tento článek popisuje překladové systémy konsorcia ON-TRAC vyvinuté pro komplexní modelovou úlohu IWSLT Evaluation 2019 pro jazykový pár angličtiny portugalštiny. Konsorcium ON-TRAC se skládá ze tří francouzských akademických laboratoří: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) a LIUM (Le Mans Universite). Pro dvě primární příspěvky odpovídající dvěma hodnotícím sadám EN-PT byl použit jeden end-to-end model postavený jako architektura neuronového kodéru a dekodéru s mechanismem pozornosti: (1) TED (MuST-C) a (2) How2. V tomto článku zkoumáme zejména vliv sdružování heterogenních korpusů pro trénink, vliv tokenizace cílů (znaky nebo BPE), vliv segmentace vstupu řeči a také porovnáváme náš nejlepší end-to-end model (BLEU 26.91 na MuST-C a 43.82 na How2 validační sady) s přístupem potrubí (ASR+MT).', 'bs': 'Ovaj papir opisuje sustave prevoda konzorcijuma ON-TRAC razvijene za model kraja do kraja IWSLT ocjene 2019 za parove engleskog i portugalskog jezika. ON-TRAC Konzorcijum sastoji se od istraživača iz tri francuske akademijske laboratorije: LIA (Univerzitet avignona), LIG (Univerzitet Grenoble Alpes) i LIUM (Univerzitet Le Mans). Jedan model do kraja izgrađen kao arhitektura neuronskog kodera s mehanizam pažnje je korišćen za dva primjerna podataka odgovarajuća dva seta procjene EN-PT: (1) TED (MuST-C) i (2) How2. U ovom papiru, posebno istražujemo učinak okupljanja heterogenezne korporacije za obuku, učinak ciljne tokenizacije (karakteri ili BPEs), učinak segmentacije ulaznog govora i uspoređujemo i naš najbolji model kraja do kraja (BLEU od 26,91 na MuST-C i 43,82 na sete validacije How2) s pristupom pipeline (ASR+MT).', 'jv': "Perintah iki rambaran tanggal sistem tarjamahan on-TROC Konortium nggawe nggawe sistem sistem tarjamahan kanggo nggawe modèl end-to-end nggawe IWSLT Tawihé tanggal 2011 kanggo kelas Inggris  Perusahaan. START console Mungkin model sing wis ana end-to-end gawan nggawe karo architecture de koder-decoder nerono karo mekanistik sing nyimpen kanggo kelas ramu nggawe suji kabeh luwih dumadhi sing sampeyan karo mulasai bino bakal dumadhi OPT (1) TI (MuRT-C) lan (2) Hay2. Nang paper iki, kita ngomong gunakake perusahaan denguné nggawe gerakan oleh-perusahaan kanggo tukang, seneng nggawe tokenisaan (caratar lan BBEs), seneng nggawe gerakan kelas nggawe lanjut sampek mulai gawe lan akeh sampek nambah dhéwé paraméel sing gawe nguasai sistêm nggawe gerakan (CLUE ning ayéwé ukuwa 'end-to-end' (CLUE ning ayéwé ning ayéwé ukuwa 'MuRT-C", 'he': 'העיתון הזה מתאר את מערכות התרגום של קונזורציום ON-TRAC שפותחות למשימה של מודל סוף-סוף של הערכה IWSLT 2019 של זוג השפה הפורטוגזית אנגלית. קונזורציום ON-TRAC מורכב מחקרים משלושה מעבדות אקדמיות צרפתיות: LIA (Avignon Universite), LIG (Universite Grenoble Alpes), LIUM (Le Mans Universite). מודל אחד בסוף עד הסוף שנבנה בתור ארכיטקטורה של קודד-קידור עצבי עם מנגנון תשומת לב השתמש בשני ההעברות העיקריות שמתאימות לשני ערכות EN-PT: (1) TED (MuST-C) ו (2) How2. בעיתון הזה, אנו חוקרים במיוחד את ההשפעה של ארגון גופות heterogeneous לאימונים, השפעה של טוקניזציה המטרה (דמויות או BPEs), השפעה של segmentation הכניסה הנאום ואנחנו גם משווה את המודל הטוב ביותר שלנו בסוף לסוף (BLEU של 26.91 על MuST-C ו 43.82 על קבוצות אימון How2) עם גישה צינור (ASR+MT).', 'sk': 'V prispevku so opisani prevajalski sistemi konzorcija ON-TRAC, ki so bili razviti za model celotne naloge IWSLT Evaluation 2019 za angleško-portugalski jezikovni par. Konzorcij ON-TRAC sestavljajo raziskovalci iz treh francoskih akademskih laboratorijev: LIA (Avignon Universite), LIG (Universite Grenoble Alpes) in LIUM (Le Mans Universite). En sam model od konca do konca, zgrajen kot arhitektura nevronskih kodirnikov-dekoderjev z mehanizmom pozornosti, je bil uporabljen za dve primarni predložitvi, ki ustrezata dvema vrednotenjema EN-PT: (1) TED (MuST-C) in (2) How2. V tem prispevku predvsem preučujemo vpliv združevanja heterogenih korpusov za trening, vpliv ciljne žetonizacije (znaki ali BPE), vpliv segmentacije govora vnosa in primerjamo tudi naš najboljši model od konca do konca (BLEU 26,91 na MuST-C in 43,82 na naborih validacije How2) s pristopom pipeline (ASR+MT).', 'ha': "Wannan karatun na bayyana the AN-TRac konortium translation system developed for the end-to-end job of the IWSLT Taimar 2019 for the English- language par. On-TRac konortium is composed of research from three French akadi labories: LIA (Universities), LIG (Universite Granobalfes), and LIUM (Le Mans University). An gina wani salon-ƙari na ƙara wanda aka gina kamar an bakar kwamfyuta-koda-koda da da ake amfani da muhalli masu nau'i biyu na farko da inganci biyu na EN-PT evaluation set: (1) TeD (Mustan-C) da (2) How2. Ga wannan takardan, munã ƙidãya musammin makampuni ta sheerogenous dõmin yin wa'azi, ma'abun haske na alama (karatun ko BLES), mai amfani da segment cikin ayukan ayuka, kuma masu samfani da misalin ƙarai zuwa ƙarami (BLEU na 26.91 na Mustan-C da 43.82 kan How2 masu ingancin) zuwa matsayin pipe (SAR+MT).", 'bo': 'ཤོག ON-TRAC Consortium is composed of researchers from three French academic laboratories: LIA (Avignon Universite), LIG (Universite Grenoble Alpes), and LIUM (Le Mans Universite). A single end-to-end model built as a neural encoder-decoder architecture with attention mechanism was used for two primary submissions corresponding to the two EN-PT evaluations sets: (1) TED (MuST-C) and (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of speech input segmentation and we also compare our best end-to-end model (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.'}
{'en': 'Transformer-based Cascaded Multimodal Speech Translation', 'fr': 'Traduction vocale multimodale en cascade basée sur un transformateur', 'ar': 'ترجمة الكلام متعدد الوسائط المتتالية المستندة إلى المحولات', 'es': 'Traducción de voz multimodal en cascada basada en transformadores', 'pt': 'Tradução de fala multimodal em cascata baseada em transformador', 'zh': '盖变压器之级联多模态音译也', 'ja': 'トランスフォーマーベースのカスケード式マルチモーダル音声翻訳', 'hi': 'ट्रांसफॉर्मर आधारित कैस्केड मल्टीमॉडल भाषण अनुवाद', 'ru': 'Трансформаторный каскадный мультимодальный перевод речи', 'ga': 'Aistriúchán Urlabhra Ilmhódúil Cascáideach-bhunaithe', 'ka': 'Name', 'hu': 'Transzformátor alapú kaszkádos multimodális beszédfordítás', 'el': 'Cascaded Multimodal Speech Translation με βάση τον μετασχηματιστή', 'it': 'Traduzione vocale multimodale a cascata basata su trasformatori', 'lt': 'Transformatoriais pagrįstas kaskadinis daugiarūšio kalbos vertimas', 'kk': 'Трансформация негіздеген көпModal сөз аудармасы', 'mk': 'Name', 'ml': 'Transformer- based Cascaded Multimodal Speech Translation', 'ms': 'Transformer-based Cascaded Multimodal Speech Translation', 'mt': 'Traduzzjoni Multimodali Cascaded Multimodal Speech ibbażata fuq it-Trasformer', 'mn': 'Төгсгөлдөр суурилсан Cascaded Multimodal Speech Translation', 'no': 'Transformeringsbasert kaskadert multimodal taleomsetjing', 'pl': 'Kaskadowe tłumaczenie mowy multimodalnej oparte na transformatorze', 'ro': 'Traducere vocală multimodală cascadă bazată pe transformator', 'sr': 'Превод на трансформацији каскадиран многомоделни реч', 'si': 'වාර්ථාපකය අධාරිත කැස්කේඩ් වැඩිමෝඩල් භාවිතය', 'sv': 'Transformarbaserad kaskadad multimodal talöversättning', 'so': 'Turjumista luuqadaha badan ee ku qoran', 'ta': 'மொழிபெயர்ப்பான மொழிபெயர்ப்பு மொழிபெயர்ப்பு', 'ur': 'Name', 'uz': 'Transformer-based Cascaded Multimodal Speech Translation', 'vi': 'Dịch/ chuyển đổi Name', 'nl': 'Transformer-gebaseerde Cascade multimodale spraakvertaling', 'bg': 'Трансформаторно базиран каскаден мултимодален речен превод', 'hr': 'Prevod multimodalnih govora na transformaciji', 'da': 'Transformerbaseret kaskaderet multimodal taleoversættelse', 'ko': '변환기 기반의 다중 모드 음성 번역', 'de': 'Transformatorbasierte kaskadierte multimodale Sprachübersetzung', 'fa': 'ترجمه سخنرانی بسیار متغیر', 'id': 'Transformer-based Cascaded Multimodal Speech Translation', 'sw': 'Translation', 'af': 'Name', 'am': 'ትርጉም', 'sq': 'Transformues-based Cascaded Multimodal Speech Translation', 'tr': 'Çoklumodal söz terjimeleri', 'bn': 'ভিত্তিক ভিত্তিক ক্যাসেড মাল্টিমোডাল ভাষার অনুবাদ', 'hy': 'Փոփոխակերպման հիմնված բազմամոդալ խոսքի թարգմանություն', 'bs': 'Prevod multimodalnih govora na transformaciji', 'az': 'Transformer-tabanlı Cascaded Multimodal Speech Translation', 'ca': 'Traducció multimodal cascada basada en transformadors', 'et': 'Transformer-põhine kaskadeeritud multimodaalne kõnetõlge', 'cs': 'Kaskádový multimodální překlad řeči založený na transformátoru', 'fi': 'Muuntajapohjainen Cascaded Multimodal Speech Translation', 'he': 'תורגם וסונכרן ע"י', 'sk': 'Večmodalni govorni prevod, ki temelji na transformatorju', 'jv': 'undo-type', 'ha': '@ item Text character set', 'bo': 'བཟོ་བཅོས་པ་ལ་གཞུང་བརྟེན་ཡོད་པའི་ཤོག་བྱང་ཆ་དབྱིབས་སྐད་འདིའི་སྐད་བརྗོད།'}
{'en': 'This paper describes the cascaded multimodal speech translation systems developed by Imperial College London for the IWSLT 2019 evaluation campaign. The architecture consists of an automatic speech recognition (ASR) system followed by a Transformer-based multimodal machine translation (MMT) system. While the ASR component is identical across the experiments, the MMT model varies in terms of the way of integrating the ', 'ar': 'تصف هذه الورقة أنظمة ترجمة الكلام متعددة الوسائط المتتالية التي طورتها إمبريال كوليدج لندن لحملة تقييم IWSLT 2019. تتكون البنية من نظام التعرف التلقائي على الكلام (ASR) متبوعًا بنظام الترجمة الآلية متعدد الوسائط (MMT) القائم على المحولات. بينما مكون ASR متطابق عبر التجارب ، يختلف نموذج MMT من حيث طريقة دمج السياق المرئي (التكييف البسيط مقابل الانتباه) ، ونوع الميزات المرئية المستغلة (المجمعة ، التلافيفية ، فئات العمل) والبنية الأساسية . بالنسبة للأخير ، نستكشف كلاً من المحول الأساسي ونسخته المداولة مع المتغيرات المضافة والمتتالية التي تختلف في كيفية دمج الانتباه النصي. عند إجراء تجارب مكثفة ، وجدنا أن (1) مخططات التكامل المرئي المستكشفة غالبًا ما تضر بأداء الترجمة للمحول والمداولات الإضافية ، ولكنها تحسن بشكل كبير من التداول التعاقبي ؛ (2) تدمج مداولات المحولات والتتالي الطريقة المرئية بشكل أفضل من التداول الإضافي ، كما يتضح من تحليل التناقض.', 'es': 'Este artículo describe los sistemas de traducción de voz multimodales en cascada desarrollados por el Imperial College de Londres para la campaña de evaluación IWSLT 2019. La arquitectura consiste en un sistema de reconocimiento automático de voz (ASR) seguido de un sistema de traducción automática multimodal (MMT) basado en Transformer. Si bien el componente ASR es idéntico en todos los experimentos, el modelo MMT varía en términos de la forma de integrar el contexto visual (condicionamiento simple frente a atención), el tipo de características visuales explotadas (agrupadas, convolucionales, categorías de acción) y la arquitectura subyacente. Para este último, exploramos tanto el transformador canónico como su versión de deliberación con variantes aditivas y en cascada que difieren en cómo integran la atención textual. Al realizar experimentos exhaustivos, descubrimos que (i) los esquemas de integración visual explorados a menudo perjudican el rendimiento de la traducción para la deliberación del transformador y la deliberación aditiva, pero mejoran considerablemente la deliberación en cascada; (ii) la deliberación en cascada y el transformador integran la modalidad visual mejor que la deliberación aditiva, como lo demuestra el análisis de incongruencia.', 'pt': 'Este artigo descreve os sistemas de tradução de fala multimodal em cascata desenvolvidos pelo Imperial College London para a campanha de avaliação do IWSLT 2019. A arquitetura consiste em um sistema de reconhecimento automático de fala (ASR) seguido por um sistema de tradução automática multimodal (MMT) baseado em Transformer. Embora o componente ASR seja idêntico em todos os experimentos, o modelo MMT varia em termos da maneira de integrar o contexto visual (condicionamento simples versus atenção), o tipo de recursos visuais explorados (grupos, convolucionais, categorias de ação) e a arquitetura subjacente . Para este último, exploramos tanto o transformador canônico quanto sua versão deliberativa com variantes aditivas e em cascata que diferem na forma como integram a atenção textual. Ao realizar extensos experimentos, descobrimos que (i) os esquemas de integração visual explorados muitas vezes prejudicam o desempenho de tradução para a deliberação transformadora e aditiva, mas melhoram consideravelmente a deliberação em cascata; (ii) a deliberação transformadora e em cascata integram melhor a modalidade visual do que a deliberação aditiva, conforme demonstrado pela análise de incongruência.', 'fr': "Cet article décrit les systèmes de traduction vocale multimodaux en cascade développés par l'Imperial College de Londres pour la campagne d'évaluation IWSLT 2019. L'architecture se compose d'un système de reconnaissance vocale automatique (ASR) suivi d'un système de traduction automatique multimodale (MMT) basé sur un transformateur. Alors que la composante ASR est identique entre les expériences, le modèle MMT varie en termes de façon d'intégrer le contexte visuel (conditionnement simple contre attention), le type de caractéristiques visuelles exploitées (regroupées, convolutives, catégories d'action) et l'architecture sous-jacente. Pour ce dernier, nous explorons à la fois le transformateur canonique et sa version de délibération avec des variantes additives et en cascade qui diffèrent par la façon dont elles intègrent l'attention textuelle. Après avoir mené des expériences approfondies, nous avons constaté que (i) les schémas d'intégration visuelle explorés nuisent souvent aux performances de traduction pour le transformateur et la délibération additive, mais améliorent considérablement la délibération en cascade\xa0; (ii) le transformateur et la délibération en cascade intègrent la modalité visuelle mieux que la délibération additive, comme le montre l'analyse d'incongruence.", 'ja': '本稿では、IWSLT 2019評価キャンペーンのためにインペリアル・カレッジ・ロンドンが開発したカスケード式マルチモーダル音声翻訳システムについて説明する。 アーキテクチャは、自動音声認識（ ＡＳＲ ）システム、続いてトランスフォーマーベースのマルチモーダルマシン翻訳（ ＭＭＴ ）システムで構成される。 ASRコンポーネントは実験全体で同一であるが、MMTモデルは、視覚的コンテキスト（単純なコンディショニング対注意）、利用される視覚的特徴の種類（プール、畳み込み、アクションカテゴリ）、および基礎となるアーキテクチャの統合方法の点で異なる。 後者については、テキストの注意をどのように統合するかで異なる加法的バリアントとカスケードバリアントを備えた正準変圧器とその審議バージョンの両方を探索します。 広範な実験を実施したところ、(i)探索された視覚的統合スキームは、変圧器および加法的審議のための翻訳パフォーマンスを損なうことが多いが、カスケード審議を大幅に改善すること、(ii)不整合分析によって示されるように、変圧器およびカスケード審議は加法的審議よりも視覚的モダリティをより良く統合することが見出された。', 'zh': '本文引伦敦帝国理工学院为 IWSLT 2019 评事级联多模态音译系统。 架构自语音识(ASR),后接Transformal多模态机器翻译(MMT)统。 虽ASR组件在诸实验同,而MMT在集成上下文(约与注意),因其视(池化,卷积,动作之类)与底架构异。 其于后者,探其规矩转换器与其审议版本,变体有加法级联变体,变体异于整合文。 既大实验,见(i)所探视积分方案,往往损转换器与加法审议转换性能,但会大改善级联审议。 (ii)变压器与级联议比加法议更善整合视模态,不一致性析也。', 'hi': 'यह पेपर IWSLT 2019 मूल्यांकन अभियान के लिए इंपीरियल कॉलेज लंदन द्वारा विकसित कैस्केड मल्टीमॉडल भाषण अनुवाद प्रणालियों का वर्णन करता है। आर्किटेक्चर में एक स्वचालित भाषण पहचान (एएसआर) प्रणाली होती है जिसके बाद ट्रांसफॉर्मर-आधारित मल्टीमॉडल मशीन अनुवाद (एमएमटी) प्रणाली होती है। जबकि एएसआर घटक प्रयोगों में समान है, एमएमटी मॉडल दृश्य संदर्भ (सरल कंडीशनिंग बनाम ध्यान) को एकीकृत करने के तरीके के संदर्भ में भिन्न होता है, दृश्य सुविधाओं के प्रकार का शोषण (पूल, कनवल्शनल, एक्शन श्रेणियां) और अंतर्निहित वास्तुकला। उत्तरार्द्ध के लिए, हम दोनों विहित ट्रांसफार्मर और additive और कैस्केड वेरिएंट के साथ इसके विचार-विमर्श संस्करण का पता लगाते हैं जो इस बात में भिन्न होते हैं कि वे पाठ्य ध्यान को कैसे एकीकृत करते हैं। व्यापक प्रयोगों का संचालन करने पर, हमने पाया कि (i) खोजी गई दृश्य एकीकरण योजनाएं अक्सर ट्रांसफॉर्मर और योजक विचार-विमर्श के लिए अनुवाद प्रदर्शन को नुकसान पहुंचाती हैं, लेकिन कैस्केड विचार-विमर्श में काफी सुधार करती हैं; (ii) ट्रांसफॉर्मर और कैस्केड विचार-विमर्श, additive विचार-विमर्श की तुलना में बेहतर दृश्य पद्धति को एकीकृत करते हैं, जैसा कि असंगतता विश्लेषण द्वारा दिखाया गया है।', 'ru': 'В этой статье описываются каскадные мультимодальные системы перевода речи, разработанные Имперским колледжем Лондона для кампании оценки IWSLT 2019. Архитектура состоит из системы автоматического распознавания речи (ASR), за которой следует система мультимодального машинного перевода (MMT) на основе трансформатора. Хотя компонент ASR идентичен в экспериментах, модель MMT варьируется с точки зрения способа интеграции визуального контекста (простое кондиционирование против внимания), типа используемых визуальных признаков (объединенные, сверточные, категории действий) и лежащей в их основе архитектуры. Для последнего мы исследуем как канонический трансформатор, так и его дискуссионный вариант с аддитивными и каскадными вариантами, которые отличаются тем, как они интегрируют текстовое внимание. Проведя обширные эксперименты, мы обнаружили, что (i) исследованные схемы визуальной интеграции часто наносят ущерб характеристикам перевода для трансформатора и аддитивного обсуждения, но значительно улучшают каскадное обсуждение; (ii) трансформаторное и каскадное обсуждение интегрируют визуальную модальность лучше, чем аддитивное обсуждение, как показывает анализ несоответствия.', 'ga': 'Déanann an páipéar seo cur síos ar na córais aistrithe cainte ilmhódacha cascáideacha arna bhforbairt ag Imperial College London le haghaidh feachtas meastóireachta IWSLT 2019. Is éard atá san ailtireacht córas uathaitheanta cainte (ASR) agus córas aistrithe meaisín ilmhódach bunaithe ar Trasfhoirmeoir (MMT) ina dhiaidh sin. Cé go bhfuil an chomhpháirt ASR comhionann ar fud na dturgnaimh, athraíonn an tsamhail MMT maidir leis an mbealach chun an comhthéacs amhairc a chomhtháthú (coinníoll simplí vs aird), cineál na ngnéithe amhairc a shaothraítear (catagóirí gníomhaíochta comhthiomsaithe, comhthiomsaithe) agus an ailtireacht bhunúsach. . Maidir leis an dara ceann, déanaimid iniúchadh ar an gclaochladán canónach agus ar a leagan pléite le leaganacha breisithe agus cascáideacha atá difriúil sa chaoi ina gcomhtháthaíonn siad aird an téacs. Tar éis turgnaimh fhairsing a dhéanamh, fuaireamar amach (i) go ndéanann na scéimeanna comhtháthaithe amhairc fiosraithe dochar go minic d’fheidhmíocht aistriúcháin an chlaochladáin agus an phlé breiseán, ach go bhfeabhsaítear go mór an plé cascáideach; (ii) comhtháthaíonn an plé ar an gclaochladán agus ar an easghluaiseachta an mhodhúlacht amhairc níos fearr ná an plé breiseán, mar a léirítear san anailís neamhréireachta.', 'ka': 'ამ კასკადის აღწერა კასკადის მულტიმოდიალური სისტემების განაცვლის სისტემები, რომელიც იმპერიალური კოლეჯის ლონდონის განვითარება 2019 წლის განაცვლის კამპა არქტიქტიკატი შექმნის ავტომატური სიტყვას განაცნობის (ASR) სისტემის შემდეგ გარემოსტრუქტირების მულტიმოდეალური მაქინის განაცნობის (MMT) სისტემის შემდეგ. ASR კომპონენტი ექსპერიმენტებში იდენტიკალურია, მაგრამ MMT მოდელი განსხვავებულია ვიზუალური კონტექსტის ინტერგურაციის გზით (უხოლოდ განსხვავება vs. ინტერგურაცია), ვიზუალური ფუნქციების ტიპი ექსპლუ შემდეგ ჩვენ კანონიკალური ტრანფორმაციის და მისი განსაზღვრებულ ვერსია დამატებული და კაკაკადის გარიანტებით განსხვავებულია როგორ ისინი ტექსტულის ინტერგურაციას. გავაკეთებეთ დიდი ექსპერიმენტების შემდეგ, ჩვენ აღმოჩნეთ, რომ i) განსხვავებული ვიზუალური ინტერგურაციის ქემები ზოგიერთად შემდეგ განსხვავების გამოსახულება ტრანფორმენტების და დამატებული განს ii) ტრანფორმაციელი და კასკადის დელიბერაცია ვიზუალური მოდიალობის ინტერგრაცია უფრო მეტი ვიდრე დამატებული დელიბერაციას, როგორც ჩვენებულია დამატებული ანალიზაციით.', 'hu': 'Ez a tanulmány bemutatja az Imperial College London által az IWSLT 2019 értékelő kampány céljából kifejlesztett, kaszkádozott multimodális beszédfordító rendszereket. Az architektúra egy automatikus beszédfelismerő (ASR) rendszerből áll, amelyet transzformátor alapú multimodális gépi fordító (MMT) rendszer követ. Míg az ASR komponens a kísérletek során azonos, az MMT modell a vizuális kontextus integrálásának módjában (egyszerű kondicionálás vs. figyelem), a kihasznált vizuális jellemzők típusában (összevont, konvolúciós, akciókategóriák) és a mögöttes architektúrában változik. Ez utóbbi esetében a kanonikus transzformátort és annak tanácskozási változatát is feltárjuk additív és kaszkád változatokkal, amelyek különbözőek a szöveges figyelem integrálásában. Széleskörű kísérletek elvégzése során megállapítottuk, hogy (i) a feltárt vizuális integrációs rendszerek gyakran károsítják a transzformátor fordítási teljesítményét és az additív tanácskozást, de jelentősen javítják a kaszkád tanácskozást; (ii) a transzformátor és a kaszkád tanácskozás jobban integrálja a vizuális módot, mint az additív tanácskozás, amint azt az inkongruencia elemzés mutatja.', 'el': 'Η παρούσα εργασία περιγράφει τα πολλαπλά συστήματα μετάφρασης ομιλίας που αναπτύχθηκαν από το Imperial College London για την εκστρατεία αξιολόγησης IWSLT 2019. Η αρχιτεκτονική αποτελείται από ένα σύστημα αυτόματης αναγνώρισης ομιλίας (ASR) που ακολουθείται από ένα σύστημα πολυμορφικής μηχανικής μετάφρασης με βάση τον μετασχηματιστή. Ενώ το συστατικό είναι πανομοιότυπο σε όλα τα πειράματα, το μοντέλο ποικίλλει όσον αφορά τον τρόπο ενσωμάτωσης του οπτικού πλαισίου (απλή ρύθμιση έναντι προσοχής), τον τύπο των οπτικών χαρακτηριστικών που χρησιμοποιούνται (συγκεντρωμένα, σύνθετα, κατηγορίες δράσης) και την υποκείμενη αρχιτεκτονική. Για το τελευταίο, εξερευνούμε τόσο τον κανονικό μετασχηματιστή όσο και την εκδοχή προβληματισμού του με πρόσθετες και διαδοχικές παραλλαγές που διαφέρουν στο πώς ενσωματώνουν την προσοχή του κειμένου. Κατά τη διενέργεια εκτεταμένων πειραμάτων, διαπιστώσαμε ότι (i) τα διερευνημένα συστήματα οπτικής ολοκλήρωσης συχνά βλάπτουν την απόδοση μετάφρασης για τον μετασχηματιστή και την πρόσθετη μελέτη, αλλά βελτιώνουν σημαντικά τη μελέτη του καταρράκτη. (ii) η μελέτη του μετασχηματιστή και του καταρράκτη ενσωματώνουν την οπτική τροπολογία καλύτερα από την πρόσθετη εξέταση, όπως αποδεικνύεται από την ανάλυση ασυνέπειας.', 'it': "Questo articolo descrive i sistemi di traduzione vocale multimodale a cascata sviluppati dall'Imperial College London per la campagna di valutazione IWSLT 2019. L'architettura consiste in un sistema di riconoscimento vocale automatico (ASR) seguito da un sistema di traduzione automatica multimodale (MMT) basato su Transformer. Mentre la componente ASR è identica in tutti gli esperimenti, il modello MMT varia in termini di modo di integrare il contesto visivo (condizionamento semplice vs attenzione), il tipo di caratteristiche visive sfruttate (categorie di azione congiunte, convoluzionali) e l'architettura sottostante. Per quest'ultimo, esploriamo sia il trasformatore canonico che la sua versione deliberativa con varianti additive e a cascata che differiscono per come integrano l'attenzione testuale. Dopo aver condotto esperimenti approfonditi, abbiamo scoperto che (i) gli schemi di integrazione visiva esplorati spesso danneggiano le prestazioni di traduzione per il trasformatore e la deliberazione additiva, ma migliorano notevolmente la deliberazione a cascata; (ii) il trasformatore e la deliberazione a cascata integrano la modalità visiva meglio della deliberazione additiva, come dimostrato dall'analisi dell'incongruenza.", 'kk': 'Бұл қағаз 2019 жылы IWSLT бағалау кампаниясы үшін Империялық Колледжи Лондоның құрылған көптеген көптеген сөздерді аудару жүйелерін анықтайды. Архитектура автоматты сөздерді анықтау (ASR) жүйесінің бірнеше модельді аудару (MMT) жүйесінен келеді. ASR компоненті тәжірибелерінде бірдей болғанда, MMT үлгісі көрініс контексті (қарапайым шарттармен қарапайым, қарапайым шарттармен қарапайым), көрініс мүмкіндіктерінің түрі (біріктірілген, қатынасыз, әрекеттер санаттары) мен астындағы архитектур Соңғы үшін, біз каноникалық түрлендіруші мен түрлендіруші нұсқасын текстікті қалай түрлендіру үшін қосымша және каскадтың түрлендірушілерімен зерттейміз. Кеңейтілген тәжірибелер жасағанда, i) зерттеген визуалдық интеграциялау сұлбалары көптеген түрлендіруші және қосымша мәліметтердің аудармаларының жағдайына көмектеседі, бірақ каскад бөлімін жа ii) түрлендіруші және каскадтың бөлімдеуі қосымша бөлімдеуінен артық бөлімдеуіне артық бөлімдеуіне қарай көрсетіледі.', 'mk': 'Овој весник ги опишува каскадираните мултимодилни системи за превод на говор развиени од Империјалниот колеџ Лондон за кампањата за евалуација на IWSLT 2019 година. Архитектурата се состои од автоматско препознавање на говорот (АСР), по кое следи систем на трансформски мултимодилен машински превод (ММТ). Иако компонентот АСР е идентичен во текот на експериментите, моделот ММТ се разликува во поглед на начинот на интеграција на визуелниот контекст (едноставно условување против вниманието), типот на визуелни карактеристики искористени (заеднички, конволуционални, акциони категории) и основ За последните, го истражуваме и каноничкиот трансформатор, и неговата разгледувачка верзија со дополнителни и каскадни варијанти кои се разликуваат во тоа како го интегрираат текстуалното внимание. По спроведувањето на експерименти, откривме дека (i) испитаните шеми на визуелна интеграција честопати ги штетат преводните резултати за трансформаторот и додатните разгледувања, но значително ги подобруваат каскадните разгледувања; (ii) трансформаторската и каскадната размислувања ја интегрираат визуелната моделност подобро од додатната размислувачка, како што покажува анализата на несогласувањето.', 'lt': 'Šiame dokumente aprašomos kaskadinės daugiarūšio kalbos vertimo sistemos, kurias Imperial College London sukūrė 2019 m. IWSLT vertinimo kampanijai. Arhitektūrą sudaro automatinio kalbos atpažinimo (ASR) sistema, po kurios eina daugiarūšio mašinų vertimo (MMT) sistema. Nors eksperimentuose ASR komponentas yra identiškas, MMT model is skiriasi atsižvelgiant į vizualinio konteksto integravimo būdą (paprastas kondicionavimas ir dėmesys), naudojamų vizualinių savybių tipą (suvestinės, konvoliucinės, veiksmų kategorijos) ir pagrindinę architektūrą. Pastaruoju atveju tiriame kanoninį transformatorių ir jo svarstymo versiją su priedais ir kaskadiniais variantais, kurie skiriasi, kaip jie integruoja tekstinį dėmesį. Atlikdami i šsamius eksperimentus, nustatėme, kad i) ištirtos vizualinės integracijos sistemos dažnai kenkia transformatoriaus vertimo rezultatams ir papildomiems svarstymams, tačiau gerokai pagerina kaskadinius svarstymus; ii) transformatorius ir kaskadinis svarstymas integruoja vaizdinį režimą geriau nei priedinis svarstymas, kaip rodo neatitikimo analizė.', 'ms': 'Kertas ini menggambarkan sistem terjemahan ucapan multimodal yang telah dikembangkan oleh Imperial College London untuk kampanye penilaian IWSLT 2019. Arkitektur terdiri dari sistem pengenalan pidato automatik (ASR) diikuti oleh sistem terjemahan mesin multimodal berasaskan-Transformer (MMT). Sementara komponen ASR adalah sama sepanjang eksperimen, model MMT berbeza dalam terma cara untuk mengintegrasikan konteks visual (kondisi ringkas vs. perhatian), jenis ciri-ciri visual yang dieksploitasi (berkumpul, konvolusi, kategori tindakan) dan arkitektur asas. Untuk yang terakhir, kita mengeksplorasi kedua-dua pengubah canonical dan versi deliberation dengan variasi aditif dan kaskad yang berbeza dalam bagaimana mereka mengintegrasikan perhatian teks. Setelah melakukan eksperimen luas, kami mendapati bahawa (i) skema integrasi visual yang dikeksplorasi sering merugikan prestasi terjemahan untuk penukar dan pertimbangan aditif, tetapi meningkatkan konsideratif pertimbangan kaskad; (ii) pembebasan pengubah dan kaskad mengintegrasikan modaliti visual lebih baik daripada pembebasan aditif, seperti yang menunjukkan oleh analisis ketidakpadanan.', 'ml': 'ഈ പേപ്പറിന്റെ വിശദീകരിക്കുന്ന പല്ലിമോഡാല്\u200d വാക്കുകള്\u200d പരിഭാഷപ്പെടുത്തുന്ന സിസ്റ്റത്തെ വിവരിച്ചുകൊടുക്കുന്നു. ഐഡബ് സ്വയം സംസാരം തിരിച്ചറിയുന്നതിനുശേഷം ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200d അടിസ്ഥാനമാക്കിയ ഒരു മള്\u200dടിമോഡല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തിയ പരീക്ഷണങ്ങള്\u200dക്ക് മുകളില്\u200d ASR ഘടകം സമമാകുമ്പോള്\u200d MMT മോഡല്\u200d വ്യത്യസ്തമായിരിക്കുന്നു. കാഴ്ചയുടെ കൂട്ടത്തില്\u200d ഒരുമിച്ചുകൂട്ടുന്നതിന്\u200dറെ (സാധാരണ കാര്യങ്ങള്\u200d vs. ശ്രദ്ധിക്ക അവസാനം, നമ്മള്\u200d കാനോണിക്കല്\u200d മാറ്റങ്ങളും അതിന്റെ ആലോചിച്ചറിയുന്ന പതിപ്പും കൂടുതല്\u200d മാറ്റങ്ങളും കാസ്കേഡ് വേറെന്ററികളും പരിശോധിക വിശാലമായ പരീക്ഷണങ്ങള്\u200d നടത്തിയപ്പോള്\u200d (I) കണ്ടെത്തിയ കാഴ്ചകളുടെ ഒരുമിച്ചുകൂട്ടത്തിന്റെ പരിപാടികള്\u200d പലപ്പോഴും മാറ്റുന്നതിനും കൂടുതല്\u200d ആലോചിക (ii) മാറ്റുന്നതും കാസ്കേഡ് ആലോചിക്കുന്നതും കൂടുതല്\u200d കൂടുതല്\u200d കാഴ്ചയുള്ള മോഡിറ്റിവിനെക്കാള്\u200d ഉത്തമമാക്കുന്നതും കൂടുതല്\u200d', 'mt': 'Dan id-dokument jiddeskrivi s-sistemi ta’ traduzzjoni tad-diskors multimodali kaskati żviluppati mill-Imperial College London għall-kampanja ta’ evalwazzjoni IWSLT 2019. L-arkitettura tikkonsisti f’sistema ta’ rikonoxximent awtomatiku tad-diskors (ASR) segwita minn sistema ta’ traduzzjoni multimodali tal-magna (MMT) ibbażata fuq it-Transformer. Filwaqt li l-komponent ASR huwa identiku fl-esperimenti kollha, il-mudell MMT ivarja f’termini tal-mod kif jintegra l-kuntest viżiv (kundizzjonar sempliċi vs. attenzjoni), it-tip ta’ karatteristiċi viżivi sfruttati (kategoriji miġbura flimkien, konvoluzzjonali, ta’ azzjoni) u l-arkitettura sottostanti. Għall-aħħar, aħna nesploraw kemm it-trasformatur kanoniku kif ukoll il-verżjoni ta’ deliberazzjoni tiegħu b’varjanti addittivi u kaskati li jvarjaw f’kif jintegraw l-attenzjoni testwali. Matul it-twettiq ta’ esperimenti estensivi, sabna li (i) l-iskemi ta’ integrazzjoni viżwali esplorati spiss jagħmlu ħsara lill-prestazzjoni tat-traduzzjoni għat-trasformatur u d-deliberazzjoni addittiva, i żda jtejbu b’mod konsiderevoli d-deliberazzjoni tal-kaskata; (ii) id-deliberazzjoni tat-trasformatur u tal-kaskata jintegraw il-modalità viżiva aħjar mid-deliberazzjoni addittiva, kif muri mill-analiżi tal-inkonsistenza.', 'mn': 'Энэ баримт 2019 оны IWSLT-ын оюутнуудын төлөө Лондонгийн Империал Колледжийн хөгжүүлсэн олон загварын ярианы хөгжүүлэлтийн системийг тайлбарладаг. Архитектур нь АСР-ын автоматик яриаг танихын тулд олон моделийн машины хөрөнгө оруулалт (MMT) системтэй байдаг. АСР компонент туршилтуудын дунд адилхан хэдий ч, MMT загвар нь харагдаж буй байдлыг (энгийн нөхцөл нөхцөл эсвэл анхаарлын төлөө) нэгтгэх арга загвартай өөрчлөгддөг. Хамгийн сүүлийн үед бид зураг шилжүүлэгч болон түүний ярилцлагын хувилбарыг текстурын анхаарлыг хэрхэн нэгтгэдэг талаар өөр өөр өөр өөр өөрчлөгдөж байгаа нэмэлт, каскад хувилбаруудыг судалж байна. Ихэнх туршилтуудын дараа бид судалсан дүрслэлийн нэгтгэл схемүүд ихэвчлэн шилжүүлэгч болон нэмэлт сэтгэл санаанд орчуулах үйл ажиллагааг нөлөөлдөг гэдгийг олж мэдсэн. ii) өөрчлөгч болон каскад зөвлөгөө нь нэмэлт санаагаас илүү харагдаж байгаа хариу үйлдлийг нэмэлт санаагаас илүү сайн нэгтгэдэг.', 'pl': 'W artykule opisano kaskadowe multimodalne systemy tłumaczenia mowy opracowane przez Imperial College London na potrzeby kampanii ewaluacyjnej IWSLT 2019. Architektura składa się z systemu automatycznego rozpoznawania mowy (ASR), a następnie z systemem multimodalnego tłumaczenia maszynowego opartego na Transformerze (MMT). Podczas gdy komponent ASR jest identyczny we wszystkich eksperymentach, model MMT różni się pod względem sposobu integracji kontekstu wizualnego (proste uwarunkowanie vs. uwaga), rodzaju wykorzystywanych cech wizualnych (zbiorowe, konwolucyjne, kategorie działania) oraz podstawowej architektury. Dla tego ostatniego badamy zarówno transformator kanoniczny, jak i jego wersję rozważania z wariantami dodatkowymi i kaskadowymi, które różnią się sposobem integracji uwagi tekstowej. Przeprowadzając szeroko zakrojone eksperymenty, stwierdziliśmy, że (i) badane schematy integracji wizualnej często szkodzą wydajności tłumaczenia transformatora i rozważania dodatkowego, ale znacznie poprawiają rozważanie kaskadowe; (ii) rozważanie transformatora i kaskady integrują modalność wizualną lepiej niż rozważanie dodatkowe, jak wykazuje analiza niezgodności.', 'no': 'Denne papiret beskriver dei kaskaderte multimodale taleomsetjingssystemene utviklet av Imperial College London for evalueringskampanjen IWSLT 2019. Arkitekturen inneheld eit automatisk tale- gjenkjenning (ASR) system etterfølgt av eit multimodal- maskinsomsetjing (MMT) på transformeringssystemet. Mens ASR-komponenten er identisk over eksperimentane, varierer MMT-modellen på måten å integrera visuelle kontekst (enkle conditioning vs. attention), typen visuelle funksjonar som er eksplodert (pooled, convolutional, action categories) og den underliggende arkitekturen. For dei siste utforskar vi både kanoniske transformasjonen og den deliberasjonsversjonen med additiv og kaskadvariantane som forskjeller i korleis dei integrerer tekstoppmerksomheten. På utvida utvida eksperimenter fann vi at i) utforska visuelle integrasjonsschemane ofte skader omsetjingsprogrammet for transformeringa og additiv deliberasjon, men det er betre å forbetra kaskaddeliberasjonen. ii) transformeringa og kaskaddeliberasjonen integrerer visuelle modaliteten bedre enn den additive deliberasjonen, som vist av analysen av inkongruens.', 'ro': 'Această lucrare descrie sistemele de traducere multimodală în cascadă dezvoltate de Imperial College London pentru campania de evaluare IWSLT 2019. Arhitectura constă dintr-un sistem automat de recunoaștere a vorbirii (ASR) urmat de un sistem de traducere automată multimodală (MMT) bazat pe Transformer. În timp ce componenta ASR este identică pe parcursul experimentelor, modelul MMT variază în ceea ce privește modul de integrare a contextului vizual (condiționare simplă vs. atenție), tipul de caracteristici vizuale exploatate (categorii de acțiune combinate, convoluționale) și arhitectura subiacentă. Pentru acesta din urmă, explorăm atât transformatorul canonic, cât și versiunea sa deliberativă cu variante aditive și cascade care diferă în modul în care integrează atenția textuală. La efectuarea unor experimente ample, am constatat că (i) schemele de integrare vizuală explorate afectează adesea performanța traducerii pentru transformator și deliberările aditive, dar îmbunătățesc considerabil deliberările în cascadă; (ii) deliberările transformatorului și în cascadă integrează modalitatea vizuală mai bine decât deliberările aditive, așa cum arată analiza incongruenței.', 'sr': 'Ovaj papir opisuje kaskadirane multimodalne prevodne reči koje je razvila Imperial College London za kampanju za procjenu IWSLT 2019. Arhitektura se sastoji od automatskog priznanja govora (ASR) sustava za kojim se slijedi sistem multimodalnog prevoda (MMT) na transformeru. Iako je komponent ASR identičan u svim eksperimentima, model MMT se razlikuje u smislu integracije vizuelnog konteksta (jednostavno uvjetovanje protiv pažnje), vrsta vizuelnih karakteristika iskorištenih (zajedničkih, konvolucionalnih, akcijskih kategorija) i temeljnih arhitektura. Za poslednji, istražujemo i kanonski transformator i njegovu verziju rasprave sa ovisnim i kaskadskim variantima koji se razlikuju u tome kako integriraju tekstualnu pažnju. Nakon provođenja širokih eksperimenata, otkrili smo da i) istražene vizualne integracije scheme često štete izvedbi prevoda za transformator i dodatne rasprave, ali značajno poboljšavaju raspravu o kazadima; ii) razmišljanje transformatora i kaskade integriše vizualnu modalitetu bolje od razmišljanja o additivama, kao što je pokazalo analiza nesklade.', 'so': 'Kanu wuxuu ku qoran yahay nidaamka turjumista hadalka oo kala duduwan oo loo soo qoray jaamacadda College London ee IWSLT 2019 qiimeynta. The architecture consists of an automatic speech recognition (ASR) system followed by a Transformer-based multimodal machine translation (MMT) system.  Inta lagu jiro kooxaha ASR waa isku mid ah jirrabaadka oo dhan, modelka MMT wuxuu ku kala duwan yahay habka la qabsashada daboolka aragga (xaaladaha fudud vs. dhegta), nooca aragtida la isticmaalay (pool, convoluto, categories of action) iyo dhismaha hoose. Marka ugu dambeeya waxaynu baaraynaa isbedelka kanonika iyo warqadiisa ka fiirsashada oo ku qoran isbedelka kalajarida iyo iskutallada ee kala duwan sida ay u qabtaan taxada hoose. Markii la sameynay jirrabaadyo badan, waxaan ogaanay in qorshaha la qabsashada aragga (i) inta badan waxyeeli kara fasaxa turjumidda ee beddelka iyo qorshaha kalajarida, laakiin aad buu u hagaajiyey qorshaha qalabka; (ii) Heshiiska beddelka iyo qalabka ku wareejinta waxaa ka wanaagsan qaababka aragnimada oo ka wanaagsan baaritaanka caadiga ah, sida loo muujiyey baaritaanka xaqdarrada ah.', 'si': 'මේ පැත්තේ කැස්කේඩ් විශ්වාස කරන්නේ කාස්කේඩ් විශ්වාස කරුණු පද්ධතියේ ඉම්පිරියාල් කලිජ් ලොන්ඩන් වලින ස්වයංක්\u200dරමය ස්වයංක්\u200dරියාත්මක කතා පද්ධතිය (ASR) පද්ධතියට පස්සේ ප්\u200dරවර්තනයක් පද්ධතියට පස්සෙන් පද්ධතියට ASR අංශය පරීක්ෂණයෙන් එකම වෙනස් වුනොත්, MMT මොඩල් වෙනස් වෙන්නේ දිහා සංශ්\u200dය සංවිධානය (සාමාන්\u200dය සංවිධානය vs. අවධානය) සඳහා පරීක්ෂණය සඳහා ප්\u200dරති අන්තිම වෙනුවෙන්, අපි කැනෝනික් වෙනස් කරුණාකරණය සහ එයාගේ විශ්වාස කරුණාකරණය සමඟ සම්බන්ධය සහ කැස්කේඩ් වෙනස් විදි විශාල පරීක්ෂණයක් කරනවාට, අපි හොයාගත්තා කියලා (i) පරීක්ෂණය කළ ප්\u200dරවේශනය සම්බන්ධ පරීක්ෂණයක් සාමාන්\u200dය විදියට පරිවර්තනය කරනවා වග (i) ප්\u200dරවර්තනය සහ කැස්කේඩ් විශ්ලේෂණය විශ්ලේෂණයෙන් පෙන්වන්න පුළුවන් විදිහට වඩා වඩා ප්\u200dරවර්තනය සහ කැස්කේඩ්', 'sv': 'Denna uppsats beskriver de kaskaderade multimodala talöversättningssystem som utvecklats av Imperial College London för utvärderingskampanjen IWSLT 2019. Arkitekturen består av ett system för automatisk taligenkänning (ASR) följt av ett transformatorbaserat multimodalt maskinöversättningssystem (MMT). Medan ASR-komponenten är identisk i experimenten varierar MMT-modellen i termer av hur man integrerar den visuella kontexten (enkel konditionering vs uppmärksamhet), vilken typ av visuella egenskaper som utnyttjas (poolade, konvulutionella, åtgärdskategorier) och den underliggande arkitekturen. För den senare undersöker vi både den kanoniska transformatorn och dess överläggningsversion med additiva och kaskadvarianter som skiljer sig åt i hur de integrerar textens uppmärksamhet. Vid utförandet av omfattande experiment fann vi att (i) de utforskade visuella integrationssystemen ofta skadar översättningsprestandan för transformatorn och additiv överläggning, men avsevärt förbättrar kaskadöverläggningen; ii) Transformator- och kaskadöverläggningarna integrerar den visuella metoden bättre än den additiva överläggningen, vilket framgår av inkonsekvensanalysen.', 'ta': 'இந்த காகிதத்தை குறிப்பிடுகிறது IWSLT 2019 மதிப்பிடும் பொருள் மொழிபெயர்ப்பு மொழிபெயர்ப்பு அமைப்புகள் உருவாக்கப்பட்டது. உருவாக்கம் தானியங்கி பேச்சு அடையாளம் (ASR) அமைப்பில் உள்ளது. மாற்றியமைக்கப்பட்ட பல்முறை இயந்திரம் மொழிபெயர்ப்பு (MMT) அமைப்பு While the ASR component is identical across the experiments, the MMT model varies in terms of the way of integrating the visual context (simple conditioning vs. attention), the type of visual features exploited (pooled, convolutional, action categories) and the underlying architecture.  இறுதியில் நாம் கானோனிக் மாற்றம் மற்றும் அதன் நிலையான பதிப்பும் கூடுதல் மற்றும் காக்கேட் மாறிகளுடன் தேடுகிறோம். இது எப்படி நிகரா விரிவான சோதனைகளை செய்யும் போது, நாங்கள் (i) கண்டுபிடித்த பார்வையான ஒருங்கிணைப்பு முறைமைகளை பெரும்பாலாக மாற்றி மற்றும் கூடுதல் கருத்து  (ii) மாற்றம் மற்றும் காஸ்கேட் நினைவூட்டத்தை ஒருங்கிணைக்கும் பார்வையான முறைமையை கூட்டுதல் கருத்தை விட சிறப்பாக்கு', 'ur': 'اس کاغذ کا مفصل IWSLT 2019 کی ارزیابی کمپینٹ کے لئے ایمپریل کالج لندن کے ذریعے پیدا کیا گیا ہے. اس معماری کی تعریف ایک آٹینفٹر بنیادی ملتی موڈال مشین ترجمہ (MMT) سیسٹم سے ہے۔ While the ASR component is identical in the experiments, the MMT model varies in terms of the visual context (simple conditioning vs. attention), the type of visual features exploited (pooled, convolutional, action categories) and the underlying architecture. آخرین کے لئے ہم کانونیک تغییر دینے والے اور اس کی مشورت کی نسخه کو اضافہ اور کاسڈ تغییرات کے ساتھ دیکھتے ہیں جو ان کی تغییر توجه کی طرح تغییر کرتے ہیں. ہم نے بہت بڑے تجربے کے بارے میں دیکھا کہ (i) محسوس کئے ہوئے نظر آزمائش طریقے اکثر تبدیل کرنے والے اور اضافہ مشورہ کے لئے ترجمہ کی عملیات کو نقصان پہنچاتے ہیں، لیکن کاسکے کی مشورت کو بہت اچھی طرح پہنچاتے ہیں۔ (ii) تغییر دینے والے اور کاسڈ کی مطلب کی تصویر کو اضافہ کی مطلب سے بہتر ترکیب دینے والی مطلب سے اضافہ کرتا ہے جس طرح غلط تحلیل کے ذریعے دکھائی جاتی ہے.', 'uz': "Bu qogʻoz IWSLT 2019 tashqi campaigning IWSLT 2019ning IWSLT uchun Imperial College London tomonidan yaratilgan multimodal talab tarjima tizimini anglatadi. Name ASR komponenti tajribalarda teng bo'lganda, MMT modeli ko'rinish muzdalarini birlashtirish usuli (oddiy holatni vs. taqdim qilish mumkin), ko'rinish xossalarining turi ishlatiladi (faqat, murakkab, amal turlari) va asosiy arxituvchisi. Keyingi davomida, biz kanonik o'zgarishni va tashqarish versiyasini ko'rib chiqaramiz, bu tugmalar qanday birlashtirishni o'zgartiradi. Ko'p tajribalarni bajarishda o'rganishda ko'p birlashtirish qoliplarini ko'proq o'zgarishni va qo'shishni ko'paytirish uchun tarjima qilish natijasini ko'paytudi, lekin kaskada tashqarishni ko'paytirishga qaror qiladi; (ii) Koʻrsatilgan o'zgartirish va kaskad tashkilotlarini ko'zgartirish usuligiga o'xshash usulni birlashtirish, muvaffaqiyatlarni aniqlash orqali ko'rsatish mumkin.", 'vi': 'Bài viết này mô tả hệ thống dịch chuyển ngôn ngữ biểu đồ theo nhiều phương thức được phát triển bởi Đại học Imperial tại London cho chiến dịch đánh giá IWSLT 209. Kiến trúc bao gồm một hệ thống nhận dạng ngôn ngữ tự động (ASR) sau đó là một hệ thống dịch chuyển biến đa phương (MMT). Trong khi các thành phần ASR giống nhau trong các thí nghiệm, mẫu MMT phân biệt theo cách dung hòa hình ảnh (điều hòa đơn giản với sự chú ý), các tính năng nhìn được khai thác (tổng hợp, xoắn ốc, các phân loại hành động) và cấu trúc cơ bản. Với vế sau, chúng ta nghiên cứu cả bộ chuyển hóa tiêu chuẩn và phiên bản cân luận của nó với các biến thể phụ và dây chuyền khác nhau trong cách họ hòa nhập sự chú ý kết cấu. Sau khi tiến hành các thí nghiệm lớn, chúng tôi phát hiện ra: i) những kế hoạch khai thác ảnh hưởng thường gây hại đến hiệu quả dịch của máy biến đổi và tính phụ, nhưng cải thiện đáng kể sự cân nhắc cẩn thận, Sự cân nhắc của máy biến đổi và dây chuyền hòa nhập bản tính trực tiếp trực tiếp tốt hơn so với giá trị phụ, như được hiển thị bởi phân tích chứng minh không đồng.', 'bg': 'Настоящата статия описва каскадните мултимодални системи за превод на реч, разработени от Империал Колидж Лондон за кампанията за оценка. Архитектурата се състои от система за автоматично разпознаване на речта, последвана от трансформаторна мултимодална система за машинен превод (ММТ). Докато компонентът на АСР е идентичен в рамките на експериментите, моделът на ММТ варира по отношение на начина на интегриране на визуалния контекст (прости условия срещу внимание), вида на експлоатираните визуални характеристики (обединени, конволюционни, категории действия) и основната архитектура. За последното изследваме както каноничния трансформатор, така и неговата дискусионна версия с добавки и каскадни варианти, които се различават по начина, по който интегрират текстовото внимание. При провеждането на обширни експерименти установихме, че (и) изследваните схеми за визуална интеграция често вредят на преводаческите показатели за трансформатора и допълнителното обсъждане, но значително подобряват каскадното обсъждане; ii) трансформаторното и каскадното обсъждане интегрират визуалния модал по-добре от допълнителното обсъждане, както е показано от анализа на несъответствието.', 'hr': 'Ovaj papir opisuje kaskadirane multimodalne sustave prevoda govora koje je razvila Imperial College London za procjenu kampanje IWSLT 2019. Arhitektura se sastoji od automatskog priznanja govora (ASR) sustava nakon sustava prevoda multimodalnih strojeva na transformeru (MMT). Iako je komponent ASR identičan u svim eksperimentima, model MMT-a se razlikuje u smislu integracije vizuelnog konteksta (jednostavnog uvjeta protiv pažnje), vrsta vizuelnih karakteristika iskorištenih (skupljenih, konvolucionalnih, akcijskih kategorija) i temeljnih arhitektura. Za posljednju istražujemo i kanonički transformator i njegovu verziju razmišljanja s varijantima additiva i kaskade koji se razlikuju u tome kako integriraju tekstualnu pažnju. Nakon provođenja širokih eksperimenata, otkrili smo da i) istraženi vizualni integracijski plan često šteti učinkovitosti prevođenja prevođenja transformatora i zavisnih razmišljanja, ali značajno poboljšava razmišljanje o kazadima; ii) razmišljanje transformatora i kaskade integriraju vizualnu modalitetu bolje od razmišljanja o ovisnicima, kao što je pokazalo analizijom nesklade.', 'da': 'Denne artikel beskriver de kaskaderede multimodale taleoversættelsessystemer udviklet af Imperial College London til IWSLT 2019 evalueringskampagnen. Arkitekturen består af et automatisk talegenkendelsessystem (ASR) efterfulgt af et Transformer-baseret multimodalt maskinoversættelsessystem (MMT). Mens ASR komponenten er identisk på tværs af eksperimenterne, varierer MMT modellen med hensyn til måden at integrere den visuelle kontekst (simpel konditionering vs. opmærksomhed), typen af visuelle træk udnyttet (pooled, konvulutional, action kategorier) og den underliggende arkitektur. For sidstnævnte undersøger vi både den kanoniske transformator og dens overvejelsesversion med additive og kaskadevarianter, der adskiller sig i, hvordan de integrerer tekstmæssig opmærksomhed. Ved udførelse af omfattende eksperimenter fandt vi, at (i) de undersøgte visuelle integrationsordninger ofte skader oversættelsespræstationen for transformatoren og additiv overvejelse, men forbedrer kaskadebehandlingen betydeligt; ii) transformerens- og kaskadebehandlingen integrerer den visuelle metode bedre end den additive overvejelse, som det fremgår af inkonsekvensanalysen.', 'de': 'Diese Arbeit beschreibt die kaskadierten multimodalen Sprachﾃｼbersetzungssysteme, die vom Imperial College London fﾃｼr die IWSLT 2019 Evaluationskampagne entwickelt wurden. Die Architektur besteht aus einem automatischen Spracherkennungssystem (ASR), gefolgt von einem Transformer-basierten multimodalen maschinellen ﾃ彙ersetzungssystem (MMT). Wﾃ､hrend die ASR-Komponente in allen Experimenten identisch ist, variiert das MMT-Modell hinsichtlich der Art der Integration des visuellen Kontexts (einfache Konditionierung vs. Aufmerksamkeit), der Art der ausgenutzten visuellen Merkmale (gepoolte, Faltungskategorien, Aktionskategorien) und der zugrunde liegenden Architektur. Fﾃｼr letztere erforschen wir sowohl den kanonischen Transformator als auch seine Deliberation-Version mit additiven und kaskadenartigen Varianten, die sich darin unterscheiden, wie sie die textliche Aufmerksamkeit integrieren. Nach umfangreichen Experimenten fanden wir heraus, dass (i) die untersuchten visuellen Integrationsschemata hﾃ､ufig die ﾃ彙ersetzungsleistung des Transformators und die additive Deliberation beeintrﾃ､chtigen, aber die Kaskadendiberation erheblich verbessern; (ii) Transformator und Kaskaden-Deliberation integrieren die visuelle Modalitﾃ､t besser als die additive Deliberation, wie die Inkongruenz-Analyse zeigt.', 'nl': "Dit artikel beschrijft de cascaded multimodale spraakvertaalsystemen ontwikkeld door Imperial College London voor de IWSLT 2019 evaluatiecampagne. De architectuur bestaat uit een automatisch spraakherkenningssysteem (ASR) gevolgd door een Transformer-gebaseerd multimodaal machinevertaalsysteem (MMT). Hoewel de ASR-component identiek is in de experimenten, varieert het MMT-model in termen van de manier waarop de visuele context wordt geïntegreerd (eenvoudige conditionering versus aandacht), het type visuele kenmerken die worden gebruikt (gepoold, convolutioneel, actiecategorieën) en de onderliggende architectuur. Voor de laatste onderzoeken we zowel de canonieke transformator als de deliberation versie met additieve en cascade varianten die verschillen in hoe ze de tekstuele aandacht integreren. Na het uitvoeren van uitgebreide experimenten, ontdekten we dat (i) de verkende visuele integratieschema's vaak schade toebrengen aan de vertaalprestaties voor de transformator en additieve deliberatie, maar de cascade deliberatie aanzienlijk verbeteren; (ii) de transformator en cascade deliberatie integreren de visuele modaliteit beter dan de additieve deliberatie, zoals blijkt uit de incongruentieanalyse.", 'fa': 'این کاغذ سیستم\u200cهای ترجمه\u200cهای مختلف سخنرانی که توسط کالج امپراتوری لندن توسعه داده شده برای کمپین ارزیابی IWSLT 2019 توصیف می\u200cکند. این معماری از سیستم شناسایی سخنرانی خودکار (ASR) پیروی از یک سیستم ترجمه ماشین multimodal (MMT) بر اساس تغییر دهنده است. در حالی که بخش ASR در طی آزمایشات یکسان است، مدل MMT به عنوان راهی از جمع کردن محیط دیده (شرایط ساده vs. توجه) تغییر می\u200cدهد، نوع ویژه\u200cهای دیده\u200cای که استفاده می\u200cشود (جمع شده، محیط\u200cسازی، مجموعه\u200cسازی، مجموعه\u200cسازی، مجموعه\u200cسازی برای آخرین، ما هر دو تغییردهنده کانونیکی و نسخه مشورت آن را با متفاوت های اضافه و کاسکید تحقیق می کنیم که در حالی که آنها توجه متن را تغییر می دهند. بعد از انجام آزمایش های گسترده، ما فهمیدیم که نقشه های ترکیب دیدگانی تحقیق شده اغلب به عملکرد ترکیب برای تغییر دهنده و مشورت اضافی آسیب می دهند، ولی به اندازه\u200cای که مشورت کاسکید را بهتر می\u200cکند. (ii) تغییر دهنده و مذاکره کاسکد از مذاکره اضافه\u200cای بهتر از مذاکره اضافه را از طریق تحلیل غیرقابل توجه می\u200cکند.', 'id': 'Kertas ini menjelaskan sistem terjemahan berbicara multimodal yang telah dikembangkan oleh Imperial College London untuk kampanye evaluasi IWSLT 2019. Arkitektur ini terdiri dari sistem pengakuan pidato otomatis (ASR) yang diikuti oleh sistem terjemahan mesin multimodal berasasi Transformer (MMT). While the ASR component is identical across the experiments, the MMT model varies in terms of the way of integrating the visual context (simple conditioning vs. attention), the type of visual features exploited (pooled, convolutional, action categories) and the underlying architecture.  Untuk yang terakhir, kami mengeksplorasi kedua transformator canonik dan versi deliberatnya dengan variasi aditif dan kaskat yang berbeda dalam bagaimana mereka mengintegrasi perhatian tekstual. Setelah melakukan eksperimen ekstensif, kami menemukan bahwa (i) skema integrasi visual yang dikeksplorasi sering merugikan prestasi terjemahan untuk penukar dan pembicaraan aditif, tetapi konsideratif meningkatkan pembicaraan kaskade; (ii) pembicaraan transformer dan kaskade mengintegrasikan modalitas visual lebih baik daripada pembicaraan aditif, seperti yang menunjukkan oleh analisis ketidakkonsistensi.', 'sw': 'Gazeti hili linaelezea mfumo wa utafsiri wa lugha mbalimbali uliotengenezwa na Chuo Kikuu cha Imperial London kwa ajili ya kampeni ya uchunguzi wa IWSLT 2019. Ujengo unajumuisha mfumo wa kutambua kujitegemea hotuba (ASR) uliofuatiliwa na mfumo wa kutafsiri mashine mbalimbali yenye asili ya Transformer (MMT). Wakati kitengele cha ASR kinafanana katika majaribio yote, modeli ya MMT inatofauti kwa namna ya kuunganisha muktadha wa kuona (mazingira rahisi dhidi ya usimamizi), aina ya vipengele vya kuona vilitumiwa (vikosi vibaya, makundi ya kiuchumi, makundi ya matendo) na ujenzi wa chini. Kwa mwisho, tunachunguza mabadiliko ya kanoni na toleo lake la makusudi kwa mabadiliko na mabadiliko yanayotofautiana na jinsi wanavyounganisha hisia za msingi. Upon conducting extensive experiments, we found that (i) the explored visual integration schemes often harm the translation performance for the transformer and additive deliberation, but considerably improve the cascade deliberation;  (ii) Mabadiliko na makubaliano ya mabadiliko yanaunganisha aina ya kuona bora ya makubaliano ya ziada, kama ilivyoonyeshwa na uchambuzi wa kutokuwepo usawa.', 'tr': 'Bu kagyz Imperial College London tarapyndan IWSLT 2019-nji ýylyň çykyş kampanyasy üçin gelişmiş multimodal çykyş sistemlerini tassyklaýar. Arhitektura bolan otomatik çykyş tanaýmasynyň (ASR) sisteminden soňra terjime edilen multimodal maşynyň terjime (MMT) sisteminden ybarat. ASR komponenti deneyler arasynda eynidir, MMT modeli görsel konteksti (basit modasy vs. üns) bilen üýtgedýän görsel özellikler (toplanýan, küçümsel, aksiyon kategoriýalary) we ilat arhitekturlygy bilen üýtgedýär. Son olarak kanonik dönüştürücünü ve danışmanın toplama ve kaskada farklı sürümlerini araştırıyoruz. Yükseler deneyler etdikde, biz (i) köplenç görsel integrasyň taslaýyşlaryň terjime edeniň eserlerini täzeden geçirip, üstüne keýşenler gürrüňleýändigini görüpdik. (ii) Tümleşici ve kazad aklaması toplam aklamalardan daha iyi görünüm modalitetini, düzgün bir analizi tarafından gösteriyor.', 'af': "Hierdie papier beskrywe die kaskadeerde multimodale sprekkingstelsels wat deur Imperial College London ontwikkel het vir die IWSLT 2019 evalueringskampanja. Die arkitektuur bestaan van 'n outomatiese woorde herken (ASR) stelsel volg deur' n Transformer- gebaseerde multimodaal masjien vertaling (MMT) stelsel. Alhoewel die ASR komponent is identiese deur die eksperimente, varieer die MMT model in terms van die manier om die visuele konteks te integreer (eenvoudige betaling teen aandag), die tipe van visuele funksies wat uitgebruik word (pooled, konvolusionele, aksie kategories) en die onderstelling arkitektuur. Vir die laaste, ondersoek ons beide die kanoniese transformeerder en sy deliberasie weergawe met additive en kaskade variante wat verskil word in hoe hulle die tektuele aandag integreer. Op uitbreiding eksperimente het ons gevind dat (i) die uitgesoekte visuele integrasie skeme dikwels die vertaling effektuur vir die transformeerder en additiewe besluit skade maar aansienlik die kaskaddeliberasie verbeter; (ii) die transformeerder en kaskaddeliberasie integreer die visuele modaliteit beter as die additive deliberasie, soos vertoon deur die onregverdiensanalisie.", 'ko': '본고는 런던제국이공대학이 IWSLT 2019 평가 활동을 위해 개발한 등급별 다중모드 음성 번역 시스템을 묘사한다.이 아키텍처는 자동음성인식(ASR) 시스템과 변압기 기반 다중모드머신번역(MMT) 시스템으로 구성됐다.ASR의 구성 부분은 모든 실험에서 동일하지만 MMT 모델은 시각 환경(단순 조건 반사와 주의)을 통합하는 방식, 이용하는 시각적 특징 유형(집합, 볼륨, 동작 유형)과 기초 구조가 다르다.후자에 대해 우리는 규범변환과 그의 심의판본, 그리고 텍스트의 주의를 어떻게 통합하는지에 있어서 서로 다른 가법과 급연변체를 연구했다.대량의 실험을 실시한 후에 우리는 (i)가 탐색한 시각 통합 방안이 통상적으로 전환과 가산심의의 번역 성능을 손상시킬 수 있으나 등급별 심의를 현저하게 개선할 수 있음을 발견했다.(ii) 불일치성 분석에서 보듯이 전환과 등급 연결 심의는 가법 심의보다 시각 모델을 더욱 잘 통합시킨다.', 'sq': 'Ky dokument përshkruan sistemet e përkthimit multimodal të fjalëve të kaskaduara të zhvilluara nga Imperial College London për fushatën e vlerësimit të IWSLT 2019. Arkitektura përbëhet nga një sistem i njohjes automatike të fjalës (ASR) pasuar nga një sistem i përkthimit multimodal të makinave me bazë në Transformer (MMT). Ndërsa komponenti ASR është identik nëpërmjet eksperimenteve, modeli MMT ndryshon në termat e mënyrës së integrimit të kontekstit vizual (kondicionim i thjeshtë vs. vëmendje), llojit të karakteristikave vizuale të shfrytëzuara (të përbashkëta, konvolutive, kategori veprimi) dhe arkitekturës themelore. Për të fundit, ne eksplorojmë si transformuesin kanonik dhe version in e tij të diskutimit me variante shtesë dhe kaskade që ndryshojnë në mënyrën se si integrojnë vëmendjen tekstuale. Në kryerjen e eksperimenteve të gjerë, gjetëm se (i) skemat e eksploruara të integrimit vizual shpesh dëmtojnë performancën e përkthimit për transformuesin dhe diskutimin shtesë, por përmirësojnë konsiderueshëm diskutimin e kaskadës; (ii) deliberacioni i transformuesit dhe kaskadës integrojnë modalitetin vizual më mirë se deliberacioni shtesë, siç tregohet nga analiza e mospërputhjes.', 'hy': 'Այս հոդվածը նկարագրում է բազմամոդալ խոսքի թարգմանման համակարգերը, որոնք զարգացել են Լոնդոնի Կամարգարանի կողմից 2019 թվականի IwSԼT-ի գնահատման քարոզարշավի համար: Ճապետական կառուցվածքը կազմված է խոսքի ավտոմատիկ ճանաչման (ASR) համակարգից, որը հետևում է տրանֆերմերսի հիմնված բազմամոդալ մեքենայի թարգմանման (mmT) համակարգից: Մինչդեռ ASR-ի բաղադրիչը փորձարկումների ընթացքում նույնն է, ՄՄԹ-ի մոդելը տարբերվում է տեսողական կոնտեքստի ինտեգրացիայի տեսքով (պարզ պայմանավորումը համեմատած ուշադրությունը), օգտագործված տեսողական հատկությունների տեսակի տեսակի տեսակի տեսակի տեսակի տեսակ Վերջիններին մենք ուսումնասիրում ենք նաև կանոնիկ վերափոխողը, նաև դրա խորհուրդման տարբերակը ավելացիվ և կասկադի տարբերակներով, որոնք տարբերվում են տեքստային ուշադրության ինտեգրման մեջ: Մենք բազմազան փորձարկումներ կատարելիս հայտնաբերեցինք, որ i) ուսումնասիրել վիզուալ ինտեգրացիայի ծրագրերը հաճախ վնասում են թարգմանման արդյունքներին վերածողի և ավելացիվ խորհուրդների համար, բայց նշանակալի բարելավում են կասկադի (II) վերափոխողը և կասկադի խորհուրդը ավելի լավ ինտեգրում են տեսողական մեթոդը, քան ավելացիվ խորհուրդը, ինչպես ցույց է տալիս անհամապատասխանության վերլուծության արդյունքում:', 'bn': 'এই পত্রিকাটি ব্যাখ্যা করেছে ইউএসএলটি ২০১৯ এর মূল্যায়ন প্রচারণার জন্য সাম্রাজ্যিক কলেজ লন্ডনের ক্ষেত্রে মাল্টিমোডাল ভাষণ অনুব স্বয়ংক্রিয়ভাবে ভাষণের স্বাক্ষর স্বীকৃতির (ASR) সিস্টেমের মধ্যে রয়েছে যার পরে ট্রান্সফার্নার ভিত্তিক বহুটিমোডাল ম এসআর সংক্রান্ত পরীক্ষাগুলোর মধ্যে একই রকম, এমএমটি মডেল দেখা যাচ্ছে দৃষ্টিভঙ্গিকে একত্রিত করার রাস্তায় (সহজ পরিস্থিতির বিরুদ্ধে মনোযোগ), দৃশ্য বৈশিষ্ট্য ব্যবহার করা হয়েছ পরবর্তীর জন্য আমরা ক্যানোনিক্যাল পরিবর্তন এবং তার পরিকল্পনা সংস্করণ উভয়কে খুঁজে বের করি যা কিভাবে তারা টেক্সচুয়ালের মনোযোগ একত্র করে। বিশাল পরীক্ষার পরীক্ষা করার পর আমরা পেয়েছিলাম যে (I) দৃষ্টিভঙ্গিকার পরিকল্পনা প্রায়শ পরিবর্তন এবং অতিরিক্ত পরিকল্পনার জন্য অনুবাদের অনুবাদের ক্ষতি কর (ii) the transformer and cascade deliberation integrate the visual modality better than the additive deliberation, as shown by the incongruence analysis.', 'az': 'Bu kağıt 2019-ci IWSLT qiyməti kampanyası üçün Imperial College Londra təşkil edilmiş çox modal danışma sistemlərini təsbit edir. Arhitektura, Transformer-tabanlı çoxlu modal maşın çeviricisi (MMT) sistemi ilə istifadə edilən otomatik söz tanımlaması sistemindən olub. ASR komponenti eksperimentlərin arasında eyni ola bilərsə, MMT modeli görünüş məlumatı (basit conditioning vs. attention) ilə birləşdirmək yolu ilə dəyişdirir, görünüş fəaliyyətlərin türü (birləşdirilmiş, konvolucional, eyni kategoriyalar) və yerli arhitektür. Sonrakılar üçün canonik transformatörünü və onun müzakirə versiyonunu təşkil edirik ki, textual dikkatini necə təşkil edirlər. Çox geniş təcrübələr etdikdən sonra, i) keşfedilmiş görünüş integrasiya schemları əksəriyyət transformatör və əlavə müzakirə üçün tercümə performansına zərər verir, amma kaskadın müzakirə çox yaxşılaşdırır. ii) transformatçı və kascada danışması, müəyyən edilmə analizi ilə göstərdiyi kimi, əlavə danışmasından daha yaxşı görünüş modalitətini birləşdirir.', 'am': 'ይህ ገጽ ለIWSLT 2019 ማስታወቂያ ዘመቻ የኢሜሪካል ኮሌጅ ሎንዶን የተዘጋጀውን የብዙኃን ንግግር ትርጉም ስርዓት ይናገራል፡፡ የመዝገብ ቤት ውስጥ የንግግር ማስታወቂያውን (ASR) ስርዓት የተገኘ የሆኑት ተርጓፊ-based multimodal machine ትርጉም (MMT) ስርዓት ነው፡፡ የASR አካባቢው በተፈተናው ሁሉ ላይ የሚመስል ሲሆን የMMT ሞዴል የዓይነቱን አካባቢ ለመቀነስ (ቀላል ጉዳይ vs. ትኩረት), የዓይነት ዓይነት ዓይነቶች (ጉዳዩ፣ ጉዳይ፣ የሥርዓት ክፍተት) እና የመሠረተ አካውንቲክ በመጠቀም መንገድ ይለያያል፡፡ ለኋለኛይቱ፣ የካኖኒካዊ ለውጥ እና የአካባቢው ክፍል እና የጽሑፉን ትኩረት እንዴት እንደሚያሳስቡ የሚለዩትን መለያየት እንፈልጋለን፡፡ በብዛት ፈተና በመፈለግ ጊዜ (i) የዓይኖችን ማኅበረሰብ ፕሮግራሙን በብዙ ጊዜ ለመለወጥ እና ለመጨመር በተርጓሚው ማስታወቂያውን የሚያጎድል፣ ነገር ግን የካስካድ ማስታወቂያውን በማሻል አግኝተናል፡፡ (ii) የዘለፋው እና የካስካድ አካሄድ ፍጥረት ከጨማሪው አሳብ ይልቅ የሚሻለውን አካባቢ እንዲያስተካክሉ፣ የግንኙነት ትምህርት ባሳየው ነው፡፡', 'bs': 'Ovaj papir opisuje kaskadirani multimodalni sustav prevoda govora koji je razvila Imperial College London za procjenu kampanje IWSLT 2019. Arhitektura se sastoji od automatskog priznanja govora (ASR) sustava za kojim se slijedi sistem multimodalnog prevoda mašine na transformeru (MMT). Iako je komponent ASR identičan u svim eksperimentima, model MMT se razlikuje u smislu integracije vizuelnog konteksta (jednostavno uvjetovanje protiv pažnje), vrsta vizuelnih karakteristika eksplodiranih (skupljenih, konvolucionalnih, akcijskih kategorija) i temeljnih arhitektura. Za poslednje istražujemo i kanonički transformator i njegovu verziju rasprave sa varijantima additiva i kaskade koji se razlikuju u tome kako integriraju tekstualnu pažnju. Nakon provođenja širokih eksperimenata, otkrili smo da i) istraženi vizualni integracijski šemi često šteti učinkovitosti prevođenja transformatora i dodatne rasprave, ali značajno poboljšavaju raspravu o kazadima; ii) razmišljanje o transformaciji i kazadima integriše vizualnu modalitetu bolje od razmišljanja o dodatnoj raspravi, kao što je pokazalo analiza nesklade.', 'ca': "Aquest paper descriu els sistemes de traducció multimodal cascades desenvolupats per l'Imperial College London per la campanya d'evaluació IWSLT 2019. L'arquitectura consisteix en un sistema de reconeixement automàtic de la voz (ASR) seguit d'un sistema de traducció multimodal de màquines (MMT) basat en Transformer. Mentre que el component ASR és idèntic en tots els experiments, el model MMT varia en termes d'integració del context visual (condicionament senzill vs atenció), el tipus de característiques visuals explotats (agrupats, convolucionals, categories d'acció) i l'arquitectura subjacente. Per a aquest últim, explorem tant el transformador canònic com la seva versió de deliberació amb variants aditius i cascades que difereixen en com integran l'atenció textual. Durant experiments extensos, vam descobrir que (i) els esquemes d'integració visual explorats sovint perjudiquen el rendiment de traducció del transformador i la deliberació aditiva, però milloren considerablement la deliberació cascada; ii) la deliberació de transformador i cascade integra la modalitat visual millor que la deliberació aditiva, com demostra l'anàlisi de la incongruència.", 'cs': 'Tento článek popisuje kaskádové multimodální překladové systémy řeči vyvinuté Imperial College London pro hodnotící kampaň IWSLT 2019. Architektura se skládá ze systému automatického rozpoznávání řeči (ASR) a následuje multimodální strojový překlad (MMT) založený na Transformeru. Zatímco ASR komponenta je napříč experimenty identická, MMT model se liší z hlediska způsobu integrace vizuálního kontextu (jednoduché podmínění vs. pozornost), typu využitých vizuálních prvků (sdružené, konvoluční, akční kategorie) a základní architektury. Pro tento druhý zkoumáme jak kanonický transformátor, tak jeho uvažovací verzi s aditivními a kaskádovými variantami, které se liší tím, jak integrují textovou pozornost. Po provedení rozsáhlých experimentů jsme zjistili, že (i) zkoumaná vizuální integrační schémata často poškozují překladovou výkonnost transformátoru a aditivní uvažování, ale výrazně zlepšují kaskádové uvažování; ii) transformátorové a kaskádové úvahy integrují vizuální modalitu lépe než aditivní úvahy, jak ukazuje analýza nesrovnalosti.', 'et': 'Käesolevas artiklis kirjeldatakse kaskaadseid mitmeliigilisi kõnetõlkesüsteeme, mille Imperial College London on välja töötanud IWSLT 2019 hindamiskampaania jaoks. Arhitektuur koosneb automaatsest kõnetuvastussüsteemist (ASR), millele järgneb transformaatoril põhinev multimodaalne masintõlke (MMT) süsteem. Kuigi ASR komponent on katsetes identne, varieerub MMT mudel visuaalse konteksti integreerimise viisi (lihtne tingimus vs tähelepanu), kasutatavate visuaalsete omaduste tüübi (ühendatud, konvolutsioonilised, tegevuskategooriad) ja aluseks oleva arhitektuuri poolest. Viimase puhul uurime nii kanoonilist transformaatorit kui ka selle aruteluversiooni aditiivsete ja kaskaadsete variantidega, mis erinevad tekstilise tähelepanu integreerimise poolest. Laiaulatuslike katsete läbiviimisel leidsime, et i) uuritud visuaalse integratsiooni skeemid kahjustavad sageli transformaatori tõlketõhusust ja lisanduvaid arutelusid, kuid parandavad märkimisväärselt kaskaadi arutelusid; ii) transformaatori ja kaskaadi arutelu integreerib visuaalse modaalsuse paremini kui lisanduva arutelu, nagu näitab lahknevuse analüüs.', 'fi': 'Tässä artikkelissa kuvataan Imperial College Londonin IWSLT 2019 -arviointikampanjaa varten kehittämät monimodaaliset puhekäännösjärjestelmät. Arkkitehtuuri koostuu automaattisesta puheentunnistusjärjestelmästä (ASR), jota seuraa muuntajapohjainen multimodaalinen konekäännösjärjestelmä (MMT). Vaikka ASR-komponentti on identtinen kaikissa kokeissa, MMT-malli vaihtelee visuaalisen kontekstin integrointitavan (yksinkertainen ehdollistaminen vs. huomio), hyödynnettyjen visuaalisten ominaisuuksien tyypin (yhdistetyt, konvolutionaaliset, toimintakategoriat) ja taustalla olevan arkkitehtuurin suhteen. Jälkimmäisen osalta tutkimme sekä kanonista muuntajaa että sen harkintaversiota lisäaine- ja kaskadiversioilla, jotka eroavat siitä, miten ne integroivat tekstin huomion. Laajoja kokeita tehdessämme huomasimme, että (i) tutkitut visuaaliset integraatiosuunnitelmat vahingoittavat usein muuntajan käännöstehokkuutta ja lisäaineharkintaa, mutta parantavat huomattavasti kaskadikäsittelyä; ii) muuntajan ja kaskadin käsittely integroi visuaalisen muodon paremmin kuin lisäaineen käsittely, kuten epäjohdonmukaisuusanalyysi osoittaa.', 'jv': 'Perintah iki rambarang nggawe sistem tarjamahan kanggo kalakno multimodal sing nyupir neng imperial kolèh (Universi ingkang ampani) kanggo kampanya IWSLT 2011. Arkturatura sing dumateng karo sistem sing otomatik bukisakno (ASR) siji dadine nganggep sistem Mulmodal karo Transformer Sampeyan ASR sing adil Sampeyan karo akeh operasi, model LTT dumadhi sak ngono corasai kapan titil (sampeyan usul karo ingkang sampeyan karo iso nggambar), kalih akeh operasi invisible (tambahan, convolution, kategori aksi) lan aketura sing dibutuhke Awak dhéwé, kita isih perusahaan kelas karo hal-perusahaan karo ngono perusahaan karo mulasar sing adilah ngon akeh podho Nang jewak éntuk éntuk éntuk sing dibenakake, awak dhéwé ngerasah (i) sak cara-cara sing bisa ngono nggawe barang nggawe tarjamahan kanggo transformer karo nambah sing beraksi lan tambah, njuk saiki beraksi yang cukup; (ii) Ngubah penting karo akeh-penting sing beraksi lan akeh-penting adilah ngono modalité sing luwih apik sing luwih apik karo nambah sing tambah apik, kaya ngono dipileksi sing gak dhéwé.', 'ha': "Wannan karatun na describe the caskaded multi-dimodal translation system developed by the Emperial College Lenin for the IWSLT 2019 evaluation campcampin. An ƙunsa da wani na'urar da aka gane na magana farat ɗaya (SSR) da aka bi'a na fassarar da multi-multiodal na Transformer-based translation (MMT). Aka da ƙanshi na SSR ya zama daidai a kokan jarrabai, misalin MMT yana sãɓã wa hanya da za'a haɗi mazaɓan gani (muhalli mai sauƙi versa aikin gani), nau'in abun gannai da aka amfani da (poopooled, fatauci, categories of action) da bakin arziki. Gani da na ƙarshe, za'a sami musanya na kanoniki da tsohon da ke yi taska da wasu variantu masu ƙaranci da kaskade da kwamfyuta ko da za su haɗa muhimmin littãfin. A lokacin da aka sami jarrabi masu ƙaranci, sai muka gane (na) mãkircin integratewa na gani, ko da yawa, za'a zartar da fassarar fassarar da za'a yi amfani da fassarar-na'urar da za'a shige da shi, kuma amma, sai ka kyautata kafaffiyar shirin kaskada; (ii) Shiryarwa da shirin kewaye, ya haɗi tsarin gani mafi alhẽri daga shirin da ke ƙara, kamar da aka nuna da Analissafin da ba'a taƙaita ba.", 'sk': 'V prispevku so opisani kaskadni multimodalni sistemi govornega prevajanja, ki jih je razvil Imperial College London za evalvacijsko kampanjo IWSLT 2019. Arhitektura je sestavljena iz sistema avtomatskega prepoznavanja govora (ASR), ki mu sledi multimodalni sistem strojnega prevajanja (MMT), ki temelji na transformatorju. Medtem ko je komponenta ASR v poskusih enaka, se model MMT razlikuje glede na način integracije vizualnega konteksta (preprosta kondicija proti pozornosti), vrsto izkoriščenih vizualnih značilnosti (združene, konvolucionalne, akcijske kategorije) in osnovno arhitekturo. Za slednje raziskujemo tako kanonični transformator kot njegovo različico razprave z aditivnimi in kaskadnimi variantami, ki se razlikujejo po tem, kako vključujejo besedilno pozornost. Ob izvedbi obsežnih poskusov smo ugotovili, da (i) raziskane sheme vizualne integracije pogosto škodujejo učinkovitosti prevajanja transformatorja in dodatnega razpravljanja, vendar bistveno izboljšujejo kaskadno razpravo; (ii) razprava transformatorja in kaskade bolje vključujeta vizualno modalnost kot dodatno razpravo, kot kaže analiza neskladnosti.', 'he': "העיתון הזה מתאר את מערכות ההתרשמות המולטומודליות של הנאום שהופכו על ידי הקולג' האימפריאלי לונדון לקמפיין הערכה IWSLT 2019. הארכיטקטורה מורכבת מערכת זיהוי דיבור אוטומטי (ASR), לאחר מכן מערכת תרגום מכונות רבות מודלית (MMT) מבוססת על טרנספורר. למרות שהרכיב ASR זהה במהלך הניסויים, מודל MMT שונה במונחים של האינטגרציה של הקשר הויזואלי (מיזוג פשוט נגד תשומת לב), הסוג של תכונות הויזואליות שמשתמשות (מאוחדות, משתנות, קטגוריות פעולה) והארכיטקטורה הנוכחית. עבור האחרון, אנחנו חוקרים גם את המעבר הקנוני וגרסה הדיון שלה עם שונים תוספים וקסקיד שמשונים באיך הם משתלבים את תשומת הלב הטקסטלית. לאחר ביצוע ניסויים רחבים, מצאנו כי (i) מערכות האינטגרציה ויזואלית המחוקרת לפגוע לעיתים קרובות ביצועי התרגום עבור המעבר והשיקול הנוסף, אבל משפר באופן משמעותי את שיקול הקסקיד; (ii) המעבר והשיקול קאסקל משתלבים את מודליות הראייה יותר טוב מהשיקול הנוסף, כפי שנראה על ידי ניתוח אי-תואמות.", 'bo': 'ཤོག་བུ་འདིས་ཀྱིས་གནད་སྡུད་དུས་འདིའི་ནང་དུ་Imperial College London་གིས་གསར་བསྐྲུན་པའི་སྐད་རིགས་ས multimodal speech system་ལ་བཤད་ཀྱི་ཡོད། The architecture consists of an automatic speech recognition (ASR) system followed by a Transformer-based multimodal machine translation (MMT) system. While the ASR component is identical across the experiments, the MMT model varies in terms of the way of integrating the visual context (simple conditioning vs. attention), the type of visual features exploited (pooled, convolutional, action categories) and the underlying architecture. འཛམ་གླིང་གི་ལྟ་བུའི་ནང་དུ་ང་ཚོས་canonical transformer་དང་མི་སེམས་ཅན་གྱི་འཐུས་རིམ་དང་ཁྱད་ཆོས ལྟ་བུ་ཆེན་པོ་ཞིག་གི་སྒེར་གྱི་རྗེས་སུ་ང་ཚོས་མཐོང་ན། (ii) དབྱིབས་བཟོ་བྱེད་དང་ཞེས་པ་དེ་གིས་མཐོང་བའི་ཐབས་ལམ་ལ་མཐོང་ནི་ཁ་སྡུད་མ་མཐོང་ཐབས་ལམ་འདྲ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'The LIG system for the English-Czech Text Translation Task of IWSLT 2019', 'fr': "Le système LIG pour la tâche de traduction de texte anglais-tchèque de l'IWSLT 2019", 'es': 'El sistema LIG para la tarea de traducción de textos inglés-checo de IWSLT 2019', 'ar': 'نظام LIG لمهمة ترجمة النص من الإنجليزية إلى التشيكية في IWSLT 2019', 'pt': 'O sistema LIG para a Tarefa de Tradução de Texto Inglês-Tcheco do IWSLT 2019', 'ja': 'IWSLT 2019の英語-チェコ語テキスト翻訳タスクのLIGシステム', 'hi': 'IWSLT 2019 के अंग्रेजी-चेक टेक्स्ट ट्रांसलेशन टास्क के लिए LIG सिस्टम', 'ru': 'Система LIG для английско-чешской задачи перевода текстов IWSLT 2019', 'zh': '用 IWSLT 2019 英语-捷克语文本译者 LIG 统', 'ga': 'An córas LIG do Thasc Aistriú Téacs Béarla-Seice de chuid IWSLT 2019', 'el': 'Το σύστημα για το έργο μετάφρασης κειμένου Αγγλικά-Τσεχικά της IWSLT 2019', 'hu': 'Az IWSLT 2019 angol-cseh szövegfordítási feladatainak LIG rendszere', 'ka': 'IWSLT 2019 წლის ტექსტის გასაგრძელების LIG სისტემი', 'kk': 'IWSLT 2019- нің ағылшын- Чех мәтін аудару тапсырмасының LIG жүйесі', 'it': 'Il sistema LIG per il compito di traduzione testo inglese-ceco di IWSLT 2019', 'ml': 'IWSLT 2019 ഇംഗ്ലീഷ്- ചെക്ക്- ടെക്സ്റ്റ് ട്രാന്\u200dസ്റ്റ് പരിഭാഷപ്പെടുത്താനുള്ള LIG സിസ്റ്റം', 'lt': 'IWSLT 2019 m. anglų ir čekų teksto vertimo užduoties LIG sistema', 'mt': 'Is-sistema LIG għall-kompitu tat-traduzzjoni tat-test Ingliż-Ċek tal-IWSLT 2019', 'mk': 'LIG системот за англиско-чешкиот текст преведувач на IWSLT 2019', 'ms': 'The LIG system for the English-Czech Text Translation Task of IWSLT 2019', 'mn': 'IWSLT 2019 оны Англи-Чех Текст хөгжүүлэх үйл ажиллагааны LIG систем', 'no': 'LIG- systemet for engelsk- tsjekkisk tekstomsetjing av IWSLT 2019', 'pl': 'System LIG dla zadania tłumaczenia tekstów angielsko-czeskich IWSLT 2019', 'ro': 'Sistemul LIG pentru sarcina de traducere engleză-cehă a textului IWSLT 2019', 'sr': 'LIG sistem za prevod engleskog-češkog teksta IWSLT 2019. godine', 'so': 'LiG-system for the Ingiriis-Czech text Translation Task of IWSLT 2019', 'si': 'IWSLT 2019 වලින් ඉංග්\u200dරීසිය- චෙක් පාළු භාවිතය වැඩේ LIG පද්ධතිය', 'sv': 'LIG-systemet f철r den engelsk-tjeckiska text철vers채ttningsuppgiften f철r IWSLT 2019', 'ta': 'IWSLT 2019 ஆங்கிலம்- செக் உரை மொழிபெயர்ப்பு பணிக்கான LIG அமைப்பு', 'ur': 'IWSLT 2019 کی انگلیسی-چیک ٹکسٹ ترجمہ ٹاکس کے لئے LIG سیستم', 'uz': 'Inglizcha matn tarjima vazifasi IWSLT 2019 uchun LIG tizimi', 'vi': 'Hệ thống LG cho dịch văn bản Anh-Séc của IWSLT bây giờ', 'bg': 'Системата за превод на текстове на английски-чешки език на ИВСЛТ 2019', 'nl': 'Het LIG-systeem voor de Engels-Tsjechische Tekstvertaaltaak van IWSLT 2019', 'da': 'LIG-systemet til den engelsk-tjekkiske tekstoversættelsesopgave af IWSLT 2019', 'hr': 'LIG sustav za posao prevoda teksta engleskog-češkog teksta IWSLT 2019.', 'id': 'Sistem LIG untuk Tugas Terjemahan Teks Bahasa Inggris-Tsek dari IWSLT 2019', 'de': 'Das LIG-System für die englisch-tschechische Textübersetzungsaufgabe von IWSLT 2019', 'fa': 'سیستم LIG برای ترجمه متن انگلیسی- چک از IWSLT 2019', 'sw': 'The LIG system for the English-Czech Text Translation Task of IWSLT 2019', 'tr': 'IWSLT 2019-nji ýylyň IWSLT terjime işi üçin LIG sistemi', 'ko': 'IWSLT 2019 영어-체코 어문본 번역 임무의 LIG 시스템', 'hy': '2019 թվականի Անգլերեն-Չեքսի տեքստի թարգմանման առաջադրանքի ԼիԳ համակարգը', 'af': 'Name', 'sq': 'Sistemi LIG për detyrën e përkthimit të tekstit anglisht-çek të IWSLT 2019', 'az': 'IWSLT 2019-in 캻ngiliz-칂톛k Metin 칂eviri G칬z톛li Sistemi', 'am': 'እንግሊዝኛ-ቻክኛ ጽሑፍ ትርጉም ስራ IWSLT 2019', 'bn': 'ইংরেজি- চেক টেক্সট অনুবাদ করার জন্য LIG সিস্টেম IWSLT ২০১৯', 'ca': 'El sistema LIG per la tasca de traducció del text anglès-cec de IWSLT 2019', 'bs': 'LIG sistem za posao prevoda teksta engleskog-češkog teksta IWSLT 2019.', 'et': 'LIG süsteem inglise-tšehhi tekstitõlke ülesandeks IWSLT 2019', 'cs': 'Systém LIG pro anglicko-český textový překlad IWSLT 2019', 'fi': 'LIG-järjestelmä IWSLT 2019:n englannin-tšekkiläisen tekstin kääntämistehtävään', 'jv': 'Sistem LIG kanggo Terjamahan Teks Inggris-Cek Teks Tarjamahan IWSLT 2011', 'he': "מערכת LIG עבור משימה התרגום טקסט אנגלי-צ'קית של IWSLT 2019", 'ha': '@ item license', 'sk': 'Sistem LIG za nalogo angleško-češkega prevajanja besedila IWSLT 2019', 'bo': 'The LIG system for the English-Czech Text Translation Task of IWSLT 2019'}
{'en': 'In this paper, we present our submission for the English to Czech Text Translation Task of IWSLT 2019. Our system aims to study how pre-trained language models, used as input embeddings, can improve a specialized machine translation system trained on few data. Therefore, we implemented a Transformer-based encoder-decoder neural system which is able to use the output of a pre-trained language model as input embeddings, and we compared its performance under three configurations : 1) without any pre-trained language model (constrained), 2) using a ', 'ar': 'في هذه الورقة ، نقدم تقديمنا لمهمة ترجمة النص من الإنجليزية إلى التشيكية لـ IWSLT 2019. يهدف نظامنا إلى دراسة كيف يمكن لنماذج اللغة المدربة مسبقًا ، والمستخدمة كإضافات إدخال ، تحسين نظام ترجمة آلي متخصص مدرب على القليل من البيانات. لذلك ، قمنا بتنفيذ نظام عصبي قائم على وحدة التشفير وفك التشفير والذي يكون قادرًا على استخدام إخراج نموذج لغة مُدرب مسبقًا كإضافات إدخال ، وقمنا بمقارنة أدائه ضمن ثلاثة تكوينات: 1) بدون أي نموذج لغة مُدرَّب مسبقًا ( مقيد) ، 2) باستخدام نموذج لغة تم تدريبه على الأجزاء أحادية اللغة من البيانات الإنجليزية-التشيكية المسموح بها (مقيدة) ، و 3) باستخدام نموذج لغة مدرَّب على كمية كبيرة من البيانات الخارجية أحادية اللغة (غير مقيدة). استخدمنا BERT كنموذج لغة خارجي مدرب مسبقًا (التكوين 3) ، وبنية BERT لتدريب نموذج اللغة الخاص بنا (التكوين 2). فيما يتعلق ببيانات التدريب ، قمنا بتدريب نظام الترجمة الآلية لدينا على كمية صغيرة من النص المتوازي: تتكون المجموعة الأولى فقط من مجموعة MuST-C المقدمة ، وتتكون المجموعة الأخرى من مجموعة MuST-C ومجموعة التعليقات على الأخبار من WMT. لاحظنا أن استخدام BERT الخارجي المدرب مسبقًا يحسن درجات نظامنا بمقدار +0.8 إلى +1.5 من BLEU في مجموعة التطوير الخاصة بنا ، و +0.97 إلى +1.94 من BLEU في مجموعة الاختبار. ومع ذلك ، يبدو أن استخدام نموذج اللغة الخاص بنا المدرب فقط على البيانات المتوازية المسموح بها يؤدي إلى تحسين أداء الترجمة الآلية فقط عندما يتم تدريب النظام على أصغر\nمجموعة البيانات.', 'ja': '本稿では、IWSLT 2019の英語からチェコ語へのテキスト翻訳タスクのための提出物を紹介します。 当社のシステムは、入力埋め込みとして使用される事前にトレーニングされた言語モデルが、ほとんどのデータでトレーニングされた専門の機械翻訳システムを改善する方法を研究することを目的としています。 そこで、事前に訓練された言語モデルの出力を入力埋め込みとして使用できるトランスフォーマーベースのエンコーダーデコーダーニューラルシステムを実装し、1 ）事前に訓練された言語モデルなし（制約付き）、2 ）許可された英語-チェコ語データの単語部分で訓練された言語モデル（制約付き）、3 ）大量の外部単語データで訓練された言語モデル（制約なし）の3つの構成下でそのパフォーマンスを比較した。 外部事前トレーニング言語モデルとしてBERTを使用し（構成3 ）、独自の言語モデルをトレーニングするためにBERTアーキテクチャを使用した（構成2 ）。 トレーニングデータに関しては、MTシステムを少量の並列テキストでトレーニングしました。1つのセットは提供されたMuST - Cコーパスのみで構成され、もう1つのセットはWMTのMuST - Cコーパスとニュースコメンタリーコーパスで構成されています。 外部の事前訓練されたBERTを使用すると、開発セットのBLEUのスコアが+0.8 ～+1.5、試験セットのBLEUのスコアが+0.97 ～+1.94向上することが観察されました。 しかし、許可された並列データのみで訓練された独自の言語モデルを使用すると、システムが最小限のデータで訓練されている場合にのみ、機械翻訳のパフォーマンスが向上するように思われます\nデータセット。', 'pt': 'Neste artigo, apresentamos nossa submissão para a tarefa de tradução de texto de inglês para tcheco do IWSLT 2019. Nosso sistema visa estudar como modelos de linguagem pré-treinados, usados como embeddings de entrada, podem melhorar um sistema especializado de tradução automática treinado com poucos dados. Portanto, implementamos um sistema neural codificador-decodificador baseado em Transformer que é capaz de usar a saída de um modelo de linguagem pré-treinado como embeddings de entrada e comparamos seu desempenho em três configurações: 1) sem nenhum modelo de linguagem pré-treinado ( restrito), 2) usando um modelo de idioma treinado nas partes monolíngues dos dados inglês-tcheco permitidos (restritos) e 3) usando um modelo de idioma treinado em uma grande quantidade de dados monolíngues externos (sem restrições). Usamos BERT como modelo de linguagem pré-treinado externo (configuração 3), e arquitetura BERT para treinar nosso próprio modelo de linguagem (configuração 2). Com relação aos dados de treinamento, treinamos nosso sistema MT em uma pequena quantidade de texto paralelo: um conjunto consiste apenas no corpus MuST-C fornecido e o outro conjunto consiste no corpus MuST-C e no corpus de comentários de notícias do WMT. Observamos que o uso do BERT pré-treinado externo melhora as pontuações do nosso sistema em +0,8 a +1,5 de BLEU em nosso conjunto de desenvolvimento e de +0,97 a +1,94 de BLEU no conjunto de teste. No entanto, usar nosso próprio modelo de linguagem treinado apenas nos dados paralelos permitidos parece melhorar o desempenho da tradução automática apenas quando o sistema é treinado no menor\nconjunto de dados.', 'fr': "Dans cet article, nous présentons notre soumission pour la tâche de traduction de texte de l'anglais vers le tchèque de l'IWSLT 2019. Notre système vise à étudier comment des modèles linguistiques préformés, utilisés comme intégrations d'entrée, peuvent améliorer un système de traduction automatique spécialisé formé sur peu de données. Par conséquent, nous avons mis en place un système neuronal encodeur-décodeur basé sur Transformer qui est capable d'utiliser la sortie d'un modèle de langage pré-entraîné comme intégration d'entrée, et nous avons comparé ses performances selon trois configurations\xa0: 1) sans modèle de langage pré-entraîné (contraint), 2) en utilisant un modèle de langage formé sur les parties monolingues des données anglais-tchèque autorisées (contraintes), et 3) à l'aide d'un modèle linguistique formé sur une grande quantité de données monolingues externes (sans contrainte). Nous avons utilisé BERT comme modèle de langage externe pré-entraîné (configuration 3) et l'architecture BERT pour former notre propre modèle de langage (configuration 2). En ce qui concerne les données de formation, nous avons formé notre système de traduction automatique sur une petite quantité de texte parallèle\xa0: un ensemble comprend uniquement le corpus must-C fourni, et l'autre ensemble comprend le corpus must-C et le corpus News Commentary de WMT. Nous avons observé que l'utilisation du BERT externe pré-entraîné améliore les scores de notre système de +0,8 à +1,5 de BLEU sur notre ensemble de développement, et de +0,97 à +1,94 de BLEU sur l'ensemble de test. Cependant, l'utilisation de notre propre modèle linguistique formé uniquement sur les données parallèles autorisées semble améliorer les performances de traduction automatique uniquement lorsque le système est formé sur le plus petit\nensemble de données.", 'es': 'En este artículo, presentamos nuestra presentación para la tarea de traducción de textos del inglés al checo de IWSLT 2019. Nuestro sistema tiene como objetivo estudiar cómo los modelos lingüísticos previamente entrenados, utilizados como incrustaciones de entrada, pueden mejorar un sistema de traducción automática especializado entrenado en pocos datos. Por lo tanto, implementamos un sistema neuronal codificador-decodificador basado en Transformer que es capaz de utilizar la salida de un modelo de lenguaje previamente entrenado como incrustaciones de entrada, y comparamos su rendimiento en tres configuraciones: 1) sin ningún modelo de lenguaje previamente entrenado (limitado), 2) utilizando un modelo de lenguaje entrenado en las partes monolingües de los datos inglés-checo permitidos (restringidos), y 3) utilizar un modelo lingüístico entrenado en una gran cantidad de datos monolingües externos (sin restricciones). Utilizamos BERT como modelo de lenguaje externo previamente entrenado (configuración 3) y la arquitectura BERT para entrenar nuestro propio modelo de lenguaje (configuración 2). Con respecto a los datos de entrenamiento, entrenamos nuestro sistema MT en una pequeña cantidad de texto paralelo: un conjunto solo consiste en el corpus Must-C proporcionado, y el otro conjunto consiste en el corpus Must-C y el corpus News Commentary de WMT. Observamos que el uso del BERT preentrenado externo mejora las puntuaciones de nuestro sistema en +0.8 a +1.5 de BLEU en nuestro set de desarrollo, y de +0.97 a +1.94 de BLEU en el set de prueba. Sin embargo, el uso de nuestro propio modelo de lenguaje entrenado solo en los datos paralelos permitidos parece mejorar el rendimiento de la traducción automática solo cuando el sistema está entrenado en los más pequeños\nconjunto de datos.', 'ru': 'В этой статье мы представляем нашу заявку на задание по переводу текста с английского на чешский язык IWSLT 2019. Наша система направлена на изучение того, как предварительно обученные языковые модели, используемые в качестве входных вложений, могут улучшить специализированную систему машинного перевода, обученную на небольшом количестве данных. Поэтому мы реализовали нейронную систему кодировщик-декодер на основе Трансформера, которая способна использовать выход предварительно обученной языковой модели в качестве входных вложений, и сравнили ее производительность в трех конфигурациях: 1) без какой-либо предварительно обученной языковой модели (ограниченной), 2) с использованием языковой модели, обученной на одноязычных частях разрешенных английско-чешских данных (ограниченной), и 3) с использованием языковой модели, обученной на большом количестве внешних одноязычных данных (неограниченной). Мы использовали BERT в качестве внешней предварительно обученной языковой модели (конфигурация 3) и архитектуру BERT для обучения нашей собственной языковой модели (конфигурация 2). Что касается данных обучения, мы обучили нашу систему MT небольшому количеству параллельного текста: один комплект состоит только из предоставленного корпуса MuST-C, а другой комплект состоит из корпуса MuST-C и корпуса новостных комментариев от WMT. Мы заметили, что использование внешнего предварительно обученного BERT улучшает баллы нашей системы на +0,8 до +1,5 BLEU на нашем наборе разработок и на +0,97 до +1,94 BLEU на наборе тестов. Тем не менее, использование нашей собственной языковой модели, обученной только на разрешенных параллельных данных, кажется, улучшает производительность машинного перевода только тогда, когда система обучена на самых маленьких\nдатасет.', 'zh': '本文IWSLT 2019英语捷克语文译。 我们的系统旨在研究输入嵌入的预训习言语模样怎么改进仅用少量数据训练的专用机器翻译系统。 故Transformer之编码器- 解码器神经系统,当以预练言语形输为嵌,校其三配:1) 预教者(受约束),2)用于许英语 - 捷克数者单语言语模形(受约束),及3)用于大外单语数以训之(不受约束)。 吾以BERT为外言之(置3),以BERT架构教吾言(置2)。 凡训练之数,少而教之机器翻译统:MuST-C 语料库为之,另一组 MuST-C 语料库与 WMT 新闻论语料库。 臣观之,用外之预训练 BERT 可系于开发集上之分 +0.8 于 +1.5 BLEU,试集上将 +0.97 于 +1.94 BLEU。 然用吾言语并行数,似系统于至小之数而后机器翻译能也。\n数。', 'hi': 'इस पेपर में, हम IWSLT 2019 के चेक टेक्स्ट ट्रांसलेशन टास्क के लिए अंग्रेजी के लिए अपना सबमिशन प्रस्तुत करते हैं। हमारी प्रणाली का उद्देश्य यह अध्ययन करना है कि इनपुट एम्बेडिंग के रूप में उपयोग किए जाने वाले पूर्व-प्रशिक्षित भाषा मॉडल, कुछ डेटा पर प्रशिक्षित एक विशेष मशीन अनुवाद प्रणाली में सुधार कर सकते हैं। इसलिए, हमने एक ट्रांसफॉर्मर-आधारित एन्कोडर-डिकोडर तंत्रिका प्रणाली को लागू किया जो इनपुट एम्बेडिंग के रूप में एक पूर्व-प्रशिक्षित भाषा मॉडल के आउटपुट का उपयोग करने में सक्षम है, और हमने तीन कॉन्फ़िगरेशन के तहत इसके प्रदर्शन की तुलना की: 1) बिना किसी पूर्व-प्रशिक्षित भाषा मॉडल (विवश), 2) अनुमत अंग्रेजी-चेक डेटा (विवश) के मोनोलिंगुअल भागों पर प्रशिक्षित भाषा मॉडल का उपयोग करके, और 3) बाहरी मोनोलिंगुअल डेटा (अप्रतिबंधित) की एक बड़ी मात्रा पर प्रशिक्षित भाषा मॉडल का उपयोग करके। हमने BERT को बाहरी पूर्व-प्रशिक्षित भाषा मॉडल (कॉन्फ़िगरेशन 3) के रूप में इस्तेमाल किया, और BERT आर्किटेक्चर को अपने स्वयं के भाषा मॉडल (कॉन्फ़िगरेशन 2) के प्रशिक्षण के लिए। प्रशिक्षण डेटा के बारे में, हमने अपने एमटी सिस्टम को समानांतर पाठ की एक छोटी मात्रा पर प्रशिक्षित किया: एक सेट में केवल प्रदान किए गए MuST-C कॉर्पस होते हैं, और दूसरे सेट में MuST-C कॉर्पस और WMT से समाचार कमेंट्री कॉर्पस होता है। हमने देखा कि बाहरी पूर्व-प्रशिक्षित BERT का उपयोग करने से हमारे विकास सेट पर BLEU के +0.8 से +1.5 तक हमारे सिस्टम के स्कोर में सुधार होता है, और परीक्षण सेट पर BLEU के +0.97 से +1.94 तक। हालांकि, केवल अनुमत समानांतर डेटा पर प्रशिक्षित हमारे अपने भाषा मॉडल का उपयोग करने से मशीन अनुवाद प्रदर्शन में सुधार होता है जब सिस्टम को सबसे छोटे पर प्रशिक्षित किया जाता है\nडेटासेट।', 'ga': 'Sa pháipéar seo, cuirimid ár n-aighneacht i láthair don Tasc Aistriúcháin Téacs Béarla go Seice de IWSLT 2019. Tá sé mar aidhm ag ár gcóras staidéar a dhéanamh ar conas is féidir le samhlacha teanga réamh-oilte, a úsáidtear mar leabú ionchuir, córas aistriúcháin meaisín speisialaithe a fheabhsú ar bheagán sonraí. Mar sin, chuireamar i bhfeidhm córas néar-ionchódóra-díchódóra-bhunaithe Trasfhoirmeoir atá in ann aschur samhail teanga réamhoilte a úsáid mar leabú ionchuir, agus rinneamar a fheidhmíocht i gcomparáid le trí chumraíocht: 1) gan aon mhúnla teanga réamhoilte ( srianta), 2) ag baint úsáide as múnla teanga atá oilte ar na codanna aonteangacha de na sonraí Béarla-Seicea ceadaithe (srianta), agus 3) ag baint úsáide as múnla teanga atá oilte ar líon mór sonraí aonteangacha seachtracha (gan srian). D’úsáideamar CRET mar shamhail teanga sheachtrach réamhoilte (cumraíocht 3), agus mar ailtireacht BERT chun ár múnla teanga féin a oiliúint (cumraíocht 2). Maidir leis na sonraí oiliúna, chuireamar oiliúint ar ár gcóras MT ar chainníocht bheag de théacs comhthreomhar: níl i sraith amháin ach an corpas MST-C a cuireadh ar fáil, agus is éard atá sa tacar eile an corpas MST-C agus an corpas News Commentary ó WMT. Thugamar faoi deara go bhfeabhsaítear scóir ár gcóras trí +0.8 go +1.5 de BLEU ar ár dtacar forbartha, agus +0.97 go +1.94 de BLEU ar an tacar tástála, trí úsáid a bhaint as an BERT réamhoilte seachtrach. Mar sin féin, dealraíonn sé nach bhfeabhsaítear feidhmíocht an aistriúcháin meaisín ach amháin nuair a bhíonn an córas oilte ar an méid is lú de bharr ár múnla teanga féin a úsáid atá oilte ar na sonraí comhthreomhara ceadaithe.\ntacar sonraí.', 'ka': 'მონაცემები.', 'hu': 'adatkészlet.', 'it': 'set di dati.', 'el': 'σύνολο δεδομένων.', 'kk': 'деректер жиыны.', 'lt': 'duomenų rinkinys.', 'mk': 'dataset.', 'ms': 'set data.', 'ml': 'ഡാറ്റാസെറ്റ്.', 'mn': 'өгөгдлийн хэлбэр.', 'no': 'dataset.', 'pl': 'zbiór danych.', 'ro': 'setul de date.', 'sr': 'Podaci.', 'si': 'දත්ත සෙට්.', 'so': 'sawirka macluumaadka', 'sv': 'Datauppsättning.', 'ta': 'தரவு அமைப்பு.', 'ur': 'dataset.', 'mt': 'sett ta’ dejta.', 'uz': 'maĘĽlumot bazasi.', 'vi': 'dữ liệu.', 'bg': 'набор от данни.', 'nl': 'dataset.', 'da': 'datasæt.', 'de': 'Datensatz.', 'hr': 'Podaci.', 'id': 'dataset.', 'fa': 'مجموعه داده', 'ko': '데이터 세트.', 'sw': 'seti ya data.', 'tr': 'dataseti.', 'sq': 'të dhënat.', 'af': 'dataset.', 'am': 'ዳታ ሳጥን', 'hy': 'տվյալներ:', 'az': 'dataset.', 'bs': 'Podaci.', 'bn': 'ডাটাসেট।', 'ca': 'conjunt de dades.', 'cs': 'datová sada.', 'et': 'andmekogum.', 'fi': 'dataset.', 'jv': 'dataset.', 'ha': 'QNetworkAccessFileBackend', 'sk': 'nabor podatkov.', 'he': 'קבוצת נתונים.', 'bo': 'dataset.'}
{'en': 'KIT’s Submission to the IWSLT 2019 Shared Task on Text Translation', 'ar': 'إرسال KIT إلى المهمة المشتركة IWSLT 2019 حول ترجمة النص', 'fr': 'Soumission de KIT à la tâche partagée IWSLT 2019 sur la traduction de texte', 'es': 'Presentación de KIT a la tarea compartida de IWSLT 2019 sobre traducción de textos', 'pt': 'Envio do KIT para a Tarefa Compartilhada do IWSLT 2019 sobre Tradução de Texto', 'ja': 'テキスト翻訳に関するIWSLT 2019共有タスクへのKITの提出', 'zh': 'KITIWSLT 2019文本译共之', 'ru': 'Представление комплекта к совместной задаче IWSLT 2019 по переводу текстов', 'hi': 'पाठ अनुवाद पर IWSLT 2019 साझा कार्य के लिए KIT का सबमिशन', 'ga': 'Aighneacht KIT chuig Tasc Comhroinnte IWSLT 2019 ar Aistriúchán Téacs', 'hu': 'A KIT beküldése az IWSLT 2019 megosztott feladatára a szövegfordítással kapcsolatban', 'el': 'Υποβολή του KIT στην κοινή εργασία για τη μετάφραση κειμένων', 'ka': 'KIT-ს IWSLT 2019 წევრი სამუშაო დავალება ტექსტის გაგრძელებაზე', 'it': 'Presentazione di KIT al compito condiviso IWSLT 2019 sulla traduzione di testi', 'kk': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'lt': 'KIT pristatymas 2019 m. IWSLT bendram teksto vertimo uždaviniui', 'mt': 'Sottomissjoni tal-KIT lill-IWSLT 2019 Kompitu Konġunt dwar it-Traduzzjoni tat-Test', 'mn': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'ml': 'ടെക്സ്റ്റ് പരിഭാഷയില്\u200d പങ്കുചേര്\u200dക്കുന്ന പണിയിലേക്ക് കെട്ടിയുടെ വിശേഷത', 'mk': 'Пренесување на КИТ на IWSLT 2019 заедничка задача за текст превод', 'ro': 'Trimiterea KIT la activitatea partajată IWSLT 2019 privind traducerea textelor', 'no': 'KIT s Submission to the IWSLT 2019 Shared Task on Text Translation', 'pl': 'Zgłoszenie KIT do IWSLT 2019 Wspólne zadanie dotyczące tłumaczenia tekstów', 'ms': 'Penghantaran KIT ke Tugas Berkongsi IWSLT 2019 mengenai Terjemahan Teks', 'si': "KIT's Sub-Mision to the IWSLT 2019 shared Job on Text translation", 'sr': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'ta': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'sv': 'KIT:s bidrag till IWSLT 2019 delad uppgift om textöversättning', 'ur': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'so': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'uz': 'Comment', 'vi': 'Sự đệ trình của KIT tại IWSLT A99 đã chia s ẻ nhiệm vụ dịch văn bản', 'bg': 'Представяне на КИТ към споделената задача за превод на текстове за 2019 г.', 'nl': 'Inzending van KIT aan de IWSLT 2019 Gedeelde Taak Tekstvertaling', 'da': "KIT's indsendelse til IWSLT 2019 delt opgave om tekstoversættelse", 'de': 'Beitrag des KIT zum IWSLT 2019 Gemeinsame Aufgabe zur Textübersetzung', 'hr': 'KIT-ov podatak IWSLT 2019. Dijeljeni zadatak o prevodu teksta', 'id': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'ko': 'KIT IWSLT 2019 텍스트 번역 공유 퀘스트에 제출', 'sw': 'Ujumbe wa KIT kwa IWSLT 2019', 'tr': "KIT'nin IWSLT 2019-nji Metin terjime hakynda paylaşyk Görevi", 'sq': 'Dërgimi i KIT në IWSLT 2019', 'am': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'fa': 'Submission of KIT to the IWSLT 2019 Shared Task on Text Translation', 'hy': 'Comment', 'af': 'KIT se Submission na die IWSLT 2019 Gedeelde Opdrag op Teks Vertaling', 'az': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'bs': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation", 'ca': 'Submissió de KIT a la IWSLT 2019 Task Shared on Text Translation', 'cs': 'Předložení KIT do IWSLT 2019 Sdílený úkol pro překlad textů', 'fi': 'KIT:n julkaisu IWSLT 2019:n tekstin kääntämistä koskevaan jaettuun tehtävään', 'et': 'KITi esitamine IWSLT 2019 ühisele tekstitõlke ülesandele', 'bn': 'IWSLT ২০১৯ টি টেক্সট অনুবাদে শেয়ার করা কাজ শেয়ার করা হয়েছে', 'jv': "KiT's Submis kanggo IWSLT 2011 Omah Ngawe Teks Terjamah", 'he': 'המשימה של KIT ל IWSLT 2019 משימה משותפת על תרגום טקסט', 'ha': 'KCharselect unicode block name', 'sk': 'Predložitev KIT za skupno nalogo IWSLT 2019 o prevajanju besedila', 'bo': "KIT's Submission to the IWSLT 2019 Shared Task on Text Translation"}
{'en': 'In this paper, we describe KIT’s submission for the IWSLT 2019 shared task on text translation. Our ', 'ar': 'في هذه الورقة ، نصف تقديم KIT لمهمة IWSLT 2019 المشتركة حول ترجمة النص. يعتمد نظامنا على نموذج المحولات [1] باستخدام تطبيقنا الداخلي. نقوم بزيادة بيانات التدريب المتاحة باستخدام الترجمة العكسية واستخدام الضبط الدقيق للنموذج النهائي. للحصول على أفضل النتائج ، استخدمنا تكوينًا كبيرًا للمحولات مكونًا من 12 طبقة ، وحققنا أحدث النتائج في مجموعة اختبار WMT2018. نجرب أيضًا نماذج الطالب والمعلم لتحسين أداء النماذج الأصغر.', 'fr': "Dans cet article, nous décrivons la soumission de KIT pour la tâche partagée IWSLT 2019 sur la traduction de texte. Notre système est basé sur le modèle de transformateur [1] utilisant notre implémentation interne. Nous augmentons les données d'entraînement disponibles à l'aide de la rétro-traduction et effectuons des réglages précis pour le modèle final. Pour obtenir de meilleurs résultats, nous avons utilisé une configuration de transformateur à 12 couches, obtenant des résultats de pointe sur le banc d'essai WMT2018. Nous expérimentons également des modèles élève-enseignant afin d'améliorer les performances des modèles plus petits.", 'pt': 'Neste artigo, descrevemos a submissão do KIT para a tarefa compartilhada IWSLT 2019 sobre tradução de texto. Nosso sistema é baseado no modelo de transformador [1] usando nossa implementação interna. Aumentamos os dados de treinamento disponíveis usando a tradução reversa e empregamos ajustes finos para o modelo final. Para nossos melhores resultados, usamos uma configuração grande de transformador de 12 camadas, alcançando resultados de última geração no conjunto de testes WMT2018. Também experimentamos modelos de aluno-professor para melhorar o desempenho de modelos menores.', 'es': 'En este documento, describimos la presentación de KIT para la tarea compartida de IWSLT 2019 sobre traducción de textos. Nuestro sistema se basa en el modelo de transformador [1] que utiliza nuestra implementación interna. Aumentamos los datos de entrenamiento disponibles mediante la retrotraducción y empleamos el ajuste para el modelo final. Para obtener los mejores resultados, utilizamos una configuración grande de transformador de 12 capas, logrando resultados de última generación en el conjunto de pruebas WMT2018. También experimentamos con modelos estudiante-profesor para mejorar el rendimiento de los modelos más pequeños.', 'ja': '本稿では、テキスト翻訳に関するIWSLT 2019の共有タスクのためのキットの提出について説明する。当社のシステムは、当社の社内実装を使用して変圧器モデル[1]に基づいています。バック翻訳を使用して利用可能なトレーニングデータを拡張し、最終モデルに微調整を採用します。最良の結果を得るために、12層の変圧器-ビッグ構成を使用し、WMT 2018テストセットで最先端の結果を達成しました。また、より小さなモデルのパフォーマンスを向上させるために、学生と教師のモデルを実験しています。', 'zh': '本文中,述KIT为IWSLT 2019交文本译共之。 吾统基于用吾内变压器 [1]。 吾以反向译增练数,而微调其形。 为获得最佳者,以12重变压器大配,WMT2018试集上最先进也。 又试师生模样,以崇小模之性。', 'hi': 'इस पेपर में, हम पाठ अनुवाद पर IWSLT 2019 साझा कार्य के लिए KIT के सबमिशन का वर्णन करते हैं। हमारा सिस्टम ट्रांसफॉर्मर मॉडल पर आधारित है [1] हमारे इन-हाउस कार्यान्वयन का उपयोग करके। हम बैक-ट्रांसलेशन का उपयोग करके उपलब्ध प्रशिक्षण डेटा को बढ़ाते हैं और अंतिम मॉडल के लिए ठीक-ट्यूनिंग को नियोजित करते हैं। हमारे सर्वोत्तम परिणामों के लिए, हमने एक 12-परत ट्रांसफार्मर-बिग कॉन्फ़िग-यूरेशन का उपयोग किया, जो WMT2018 परीक्षण सेट पर अत्याधुनिक परिणाम प्राप्त कर रहा था। हम छोटे मॉडलों के प्रदर्शन में सुधार करने के लिए छात्र-शिक्षक मॉडल के साथ भी प्रयोग करते हैं।', 'ru': 'В этой статье мы описываем подачу КОМПЛЕКТА для совместной задачи IWSLT 2019 по текстовому переводу. Наша система основана на трансформаторной модели [1] с использованием нашей собственной реализации. Мы увеличиваем доступные обучающие данные с помощью обратного перевода и используем точную настройку для окончательной модели. Для наших наилучших результатов мы использовали 12-слойную конфигурацию трансформатор-большой, достигая самых современных результатов на наборе испытаний WMT2018. Мы также экспериментируем с моделями «студент - преподаватель» для повышения производительности более мелких моделей.', 'ga': 'Sa pháipéar seo, déanaimid cur síos ar aighneacht KIT do thasc roinnte IWSLT 2019 ar aistriúchán téacs. Tá ár gcóras bunaithe ar an tsamhail claochladáin [1] ag baint úsáide as ár gcur i bhfeidhm intí. Méadaimid na sonraí oiliúna atá ar fáil trí úsáid a bhaint as aisaistriúchán agus úsáidimid mionchoigeartú don mhúnla deiridh. Chun ár dtorthaí is fearr a bhaint amach, d’úsáideamar cumraíocht 12-ciseal claochladán-mór, ag baint amach torthaí den scoth ar thacar tástála WMT2018. Déanaimid triail freisin le samhlacha mac léinn-múinteoirí chun feidhmíocht na múnlaí níos lú a fheabhsú.', 'el': 'Στην παρούσα εργασία, περιγράφουμε την υποβολή του ΚΙΤ για την κοινή εργασία για τη μετάφραση κειμένων. Το σύστημά μας βασίζεται στο μοντέλο μετασχηματιστή [1] χρησιμοποιώντας την εσωτερική μας εφαρμογή. Αυξάνουμε τα διαθέσιμα δεδομένα κατάρτισης χρησιμοποιώντας την πίσω μετάφραση και εφαρμόζουμε την τελειοποίηση για το τελικό μοντέλο. Για τα καλύτερα αποτελέσματά μας, χρησιμοποιήσαμε μια ρύθμιση μεγάλου μεγέθους μετασχηματιστή 12στρώματος, επιτυγχάνοντας αποτελέσματα τελευταίας τεχνολογίας στο σετ δοκιμών. Επίσης πειραματιζόμαστε με μοντέλα μαθητή-δασκάλου για να βελτιώσουμε την απόδοση μικρότερων μοντέλων.', 'hu': 'Ebben a tanulmányban bemutatjuk a KIT benyújtását a 2019-es IWSLT közös feladatra a szövegfordítással kapcsolatban. Rendszerünk a házon belüli megvalósításunkat alkalmazó transzformátormodellre [1] épül. A rendelkezésre álló képzési adatokat visszafordítással bővítjük, és finomhangolást alkalmazunk a végső modellhez. A legjobb eredményeink érdekében 12 rétegű transzformátor-nagy konfigurációt használtunk, így a WMT2018 tesztkészleten a legmodernebb eredményeket értünk el. A kisebb modellek teljesítményének javítása érdekében kísérletezünk diák-tanár modellekkel is.', 'ka': 'ამ დომენტში ჩვენ აღწერეთ KIT-ის გადაწყვეტილება ტექსტის გადაწყვეტილების IWSLT 2019 წლის გაყოფილი დავალება. ჩვენი სისტემა დაბაზიან ტრანფორმეტრის მოდელის [1] გამოყენებული ჩვენი სახლის გამოყენება. ჩვენ მოხმარებული მონაცემები გავაკეთებთ, რომელიც გამოყენებულია და დასაწყენებული მოდელეში გამოყენება. ჩვენი ყველაზე საუკეთესო შედეგებისთვის, ჩვენ გამოიყენეთ 12-layer transformer-big config-uration, რომელიც WMT2018 ტესტის შედეგების შედეგების შესაძლებლობა. ჩვენ ასევე ექსპერიმენტი სტუდენტების და სტუდენტების მოდელებით, რომლებიც პატარა მოდელების გამოსახულება.', 'it': "In questo articolo, descriviamo la presentazione di KIT per il compito condiviso IWSLT 2019 sulla traduzione del testo. Il nostro sistema si basa sul modello del trasformatore [1] utilizzando la nostra implementazione interna. Aumentiamo i dati di formazione disponibili utilizzando la traduzione posteriore e impieghiamo la messa a punto per il modello finale. Per i nostri migliori risultati, abbiamo utilizzato una configurazione a 12 strati con trasformatori grandi, ottenendo risultati all'avanguardia sul set di test WMT2018. Sperimentiamo anche modelli studente-insegnante per migliorare le prestazioni di modelli più piccoli.", 'kk': 'Бұл қағазда, 2019 жылы IWSLT және мәтін аудармасында ортақ тапсырманы KIT жіберілгенін анықтаймыз. Біздің жүйеміз үй ішінде орындалатын [1] түрлендіруші үлгісіне негізделген. Біз қол жеткізетін оқыту деректерін қайта аудару және соңғы үлгі үшін дұрыс баптауларды қолданамыз. Біздің ең жақсы нәтижелеріміз үшін WMT2018 сынақтағы 12 қабатты түрлендіруші үлкен баптауларды қолдандық. Сонымен қатар, студенттер-мұғалім үлгілерімен кішкентай үлгілерді жақсарту үшін тәжірибелеміз.', 'lt': "In this paper, we describe KIT's submission for the IWSLT 2019 shared task on text translation.  Mūsų sistema grindžiama transformatoriaus modeliu [1], naudojančiu mūsų vidaus įgyvendinimą. Mes papildome turimus mokymo duomenis naudojant grįžtamąjį vertimą ir naudojame galutinio modelio patobulinimą. Siekdami geriausių rezultatų, naudojome 12 sluoksnių transformatorių-didelę konfigūraciją, kad pasiektume naujausius rezultatus WMT2018 bandymų rinkinyje. Taip pat eksperimentuojame su student ų ir mokytojų modeliais, kad pagerintume mažesnių modelių rezultatus.", 'ms': 'Dalam kertas ini, kami menggambarkan penghantaran KIT untuk tugas kongsi IWSLT 2019 pada terjemahan teks. Sistem kita berdasarkan model pengubah [1] menggunakan implementasi dalam rumah kita. Kami menambah data latihan yang tersedia menggunakan terjemahan-balik dan menggunakan penyesuaian untuk model akhir. Untuk keputusan terbaik kami, kami menggunakan transformator 12 lapisan besar konfigurasi, mencapai keputusan state-of-the-art pada set ujian WMT2018. Kami juga eksperimen dengan model pelajar-guru untuk meningkatkan prestasi model yang lebih kecil.', 'ml': 'ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d കിട്ടിയുടെ ഉത്തരവ് വിവരിക്കുന്നു. ലെക്സ്റ്റ് പരിഭാഷണത്തില്\u200d വെച്ച് പങ്കുചേര്\u200dത്ത പണ നമ്മുടെ സിസ്റ്റം മാറ്റങ്ങളുടെ മോഡലിന്\u200dറെ അടിസ്ഥാനത്താണ് [1] നമ്മുടെ വീട്ടിലെ പ്രവര്\u200dത്തനപ്പെ പിന്നീട് ട്രെയിന്\u200dഷന്\u200d ഉപയോഗിച്ച് ലഭ്യമായ പരിശീലന വിവരങ്ങള്\u200d കൂട്ടിചേര്\u200dക്കുകയും അവസാനത്തെ മോഡലിന് നല് നമ്മുടെ ഏറ്റവും നല്ല ഫലങ്ങള്\u200dക്ക് വേണ്ടി ഞങ്ങള്\u200d 12-layer മാറ്റുന്നത്-വലിയ കോണ്\u200dഫിഗ്ഗ് യൂറേഷന്\u200d ഉപയോഗിച്ചു. WMT2018 ടെസ്റ്റ് സെറ്റില്\u200d നി ചെറിയ മോഡലുകളുടെ പ്രകടനം മെച്ചപ്പെടുത്താന്\u200d വിദ്യാര്\u200dത്ഥിക്കുന്ന മോഡലുകളുമായി ഞങ്ങള്\u200d പരീക്ഷ', 'mk': 'Во овој весник ја опишуваме поднесувањето на КИТ за заедничката задача на IWSLT 2019 за превод на текст. Нашиот систем се базира на моделот на трансформаторот [1] користејќи го нашето внатрешно спроведување. Ги зголемуваме достапните податоци за обука користејќи назад-превод и вработуваме финетизирање за финалниот модел. For our best results, we used a 12-layer transformer-big config- uration, achieving state-of-the-art results on the WMT2018 test set.  Исто така, експериментираме со студентски-учителски модели за подобрување на резултатите на помалите модели.', 'mt': "F'dan id-dokument, niddeskrivu s-sottomissjoni tal-KIT għall-IWSLT 2019 kompitu kondiviż dwar it-traduzzjoni tat-test. Our system is based on the transformer model [1] using our in-house implementation.  Aħna nżidu d-dejta disponibbli dwar it-taħriġ billi nużaw it-traduzzjoni lura u naħdmu aġġustamenti fini għall-mudell finali. Għall-a ħjar riżultati tagħna, użajna konfigurazzjoni kbira tat-trasformatur ta’ 12-il saff, li kisbet riżultati l-aktar avvanzati fis-sett tat-test WMT2018. Nisperimentaw ukoll b’mudelli ta’ studenti-għalliema biex itejbu l-prestazzjoni ta’ mudelli iżgħar.", 'mn': 'Энэ цаасан дээр бид 2019 оны IWSLT-ийн хуваалцааны ажлыг текст орчуулахын тулд KIT-ийн хэвлэлийг тайлбарлаж байна. Бидний систем гэр бүлийн үйлдвэрлэлийг ашиглан шилжүүлэгч загвар дээр суурилсан. Бид хамгийн сүүлийн загварын тулд хэрэглэгдэх боломжтой сургалтын мэдээллийг нэмэгдүүлнэ. Хамгийн сайн үр дүнд бид WMT2018 шалгалтын туршилтын үр дүнг хүртэл 12 давхар шилжүүлэгч-том конфигурацийг ашигласан. Бид мөн оюутан багш нарын загваруудыг жижиг загваруудыг сайжруулахын тулд туршилт хийдэг.', 'no': 'I denne papiret beskriver vi KIT sin sending for IWSLT 2019 delt oppgåve om tekstomsetjinga. Sistemet vårt er basert på transformeringsmodellen [1] med vårt innebygge implementasjon. Vi aukar dei tilgjengelege treningsdata ved å bruka tilbakeomsetjing og bruka finnstilling for den siste modellen. For det beste resultatet, brukte vi ein 12-lagtransformasjon med stor konfigurasjon, og når det gjer tilstanden til kunsten på WMT2018-testsettet. Vi eksperimenterer også med studentlæringsmodeller for å forbetra utviklinga av mindre modeller.', 'ro': 'În această lucrare, descriem depunerea KIT pentru sarcina comună IWSLT 2019 privind traducerea textului. Sistemul nostru se bazează pe modelul transformatorului [1] folosind implementarea internă. Îmbunătățim datele disponibile de instruire folosind traducerea înapoi și folosim ajustări fine pentru modelul final. Pentru rezultatele noastre cele mai bune, am folosit un transformator mare de 12 straturi, obținând rezultate de ultimă generație pe setul de testare WMT2018. De asemenea, experimentăm modele elev-profesor pentru a îmbunătăți performanța modelelor mai mici.', 'pl': 'W niniejszym artykule opisujemy zgłoszenie KIT do wspólnego zadania IWSLT 2019 dotyczącego tłumaczenia tekstów. Nasz system oparty jest na modelu transformatora [1] z wykorzystaniem naszej wewnętrznej implementacji. Poszerzamy dostępne dane szkoleniowe za pomocą backtranslacji i stosujemy dostosowanie do finalnego modelu. Aby uzyskać najlepsze wyniki, zastosowaliśmy 12-warstwową konfigurację transformatorową, osiągając najnowocześniejsze wyniki na zestawie testowym WMT2018. Eksperymentujemy również z modelami ucznia-nauczyciela w celu poprawy wydajności mniejszych modeli.', 'sv': 'I denna uppsats beskriver vi KIT:s bidrag till IWSLT 2019 delade uppgift om textöversättning. Vårt system är baserat på transformatormodellen [1] med vår interna implementering. Vi utökar tillgängliga träningsdata med hjälp av backöversättning och använder finjustering för den slutliga modellen. För våra bästa resultat använde vi en 12-lagers transformatorstor konfiguration, vilket uppnådde toppmoderna resultat på WMT2018 testset. Vi experimenterar också med elev-lärarmodeller för att förbättra prestandan hos mindre modeller.', 'ta': 'இந்த காகிதத்தில், நாங்கள் KIT மொழிபெயர்ப்பை வரையறுக்கிறோம் IWSLT 2019 உரை மொழிபெயர்ப்பில் பகிர்ந்த பணியை வி எங்கள் அமைப்பு மாற்றும் மாதிரி அடிப்படையாக உள்ளீட்டில் செயல்பாட்டை பயன்படுத்துகிறது. பின்மொழிபெயர்ப்பை பயன்படுத்தி கிடைக்கும் பயிற்சி தகவல்களை கூட்டுகிறோம் மற்றும் இறுதி மாதிரிக்கு நன எங்கள் சிறந்த முடிவுகளுக்கு, நாங்கள் 12 அடுக்கு மாற்றி பெரிய வடிவமைப்பு ஒளியில் பயன்படுத்தினோம், WMT2018 சோதனைப்பு அமைப்பில் உள்ள நில நாம் மாணவர் ஆசிரியர் மாதிரிகளுடன் சிறிய மாதிரிகளின் செயல்பாட்டை மேம்படுத்த வேண்டும்.', 'sr': 'U ovom papiru opisujemo podnošenje KIT-a za IWSLT 2019. zajednički zadatak o prevodu teksta. Naš sistem je zasnovan na modelu transformacije [1] koristeći našu implementaciju unutrašnjih kuća. Povećavamo dostupne podatke o treningu koristeći prevod natrag i zapošljavamo finalnu prilagodbu za konačni model. Za naš najbolji rezultat, koristili smo 12-slojni transformator-veliku konfiguraciju, ostvarili rezultate umjetnosti na setu WMT2018-a. Takođe eksperimentiramo sa modelima učenika i učitelja kako bi poboljšali izvršnost manjih modela.', 'si': 'මේ පත්තරේ අපි KIT ගේ පිළිබඳුම් විස්තර කරන්නේ 2019 IWSLT කාර්යයේ පාළිබඳ පරිවර්තනයේ භාවිත වැඩක්. අපේ පද්ධතිය පද්ධතිය ප්\u200dරවර්තනය කරන්නේ නිර්මාණකය මදුල [1] අපේ ගෙදර ඇතුල් ප්\u200dරවර්තනය කරන්නේ. අපි පුළුවන් ප්\u200dරශ්නය දත්ත වැඩ කරනවා පස්සේ අවවාදය සහ අවසාන මොඩේල් එක්ක සුදුසුම් කරනවා. අපේ හොඳම ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200d අපි පරීක්ෂණය කරනවා විද්\u200dයාඥාර්ථික-ගුරුත්තර මොඩේල් එක්ක ප්\u200dරශ්නය කරනවා පොඩි මොඩේල් එක', 'so': 'Qoraalkan, waxaynu ku qoraynaa warqaddan KIT u soo diritaanka IWSLT 2019 shaqo la qaybsaday ku saabsan turjumaadda text. nidaamkayagu wuxuu ku saleysan yahay qaababka bedelka [1] ee isticmaalaya habka guriga. Waxaan ku dareynaa macluumaadka waxbarashada ee la heli karo oo lagu isticmaalayo turjumista dib-u-isticmaalka, waxaana u shaqeynaa sameynta hagitaanka ugu dambeeya. Sababyadeena ugu wanaagsan, waxaynu isticmaalnay 12-layer beddelin-weyn config-uraan, waxayna gaadhay resultada-ka-farshaxanta ee qoraalka WMT2018. Sidoo kale waxaynu imtixaamaynaa tusaalooyin waxbarasho ah si aan u kordhino sameynta qaababka yar.', 'ur': 'اس کاغذ میں، ہم نے IWSLT 2019 کے لئے KIT کی مہمانی کا مفصل مترجم پر شریک کیا ہے۔ ہمارا سیستم ہمارے گھروں کی عملومات کے مطابق تغییر مدل پر بنیاد ہے [1]. ہم نے پیچھے ترجمہ کے مطابق موجود ترکینس ڈیٹے کو اضافہ کردیا ہے اور آخری موڈل کے لئے نیک ترکینس استعمال کریں۔ ہمارے بہترین نتیجے کے لئے ہم نے WMT2018 امتحان سٹ پر 12-layer transformer-big config-uration کا استعمال کیا تھا۔ ہم نے استاد-استاد مدل کے ساتھ بھی آزمائش کی ہے کہ چھوٹے موڈل کے عملکرد کو بہتر کریں۔', 'uz': "Bu hujjatda, biz Matn tarjimasida IWSLT 2019'ning IWSLT 2019'ning qismlarini ajratishni anglatamiz. Bizning tizimmiz uyidagi ishlayotganimizdan foydalanish modeli asosida. @ info: whatsthis Biz eng yaxshi natijalarimiz uchun, biz WMT2018 sinov sohasida 12 qatlam transformer-katta moslash urayasini ishlatdik. Biz o'qituvchi modellarning kichkina modellarni bajarish uchun o'qituvchi modellar bilan o'tibor beramiz.", 'vi': 'Trong tờ giấy này, chúng tôi mô tả s ự chịu trách nhiệm của KIT cho công việc chia sẻ IWSLT Edison về bản dịch. Hệ thống của chúng tôi dựa trên mô hình máy biến thế (1) sử dụng hệ thống nội bộ. Chúng tôi tăng cường dữ liệu đào tạo có thể sử dụng dịch phụ và sửa chữa mẫu cuối cùng. Để có kết quả tốt nhất, chúng tôi sử dụng máy biến thế 12-lớp lớn cấu hình, đạt được kết quả tối tân nhất trên bộ thử nghiệm WM2008. Chúng tôi cũng thử nghiệm các mẫu giáo sinh viên để nâng cao các mô hình nhỏ hơn.', 'bg': 'В настоящата статия описваме представянето на КИТ за споделената задача по превод на текстове. Нашата система се основава на модела на трансформатор [1], използвайки нашата вътрешна реализация. Увеличаваме наличните данни за обучение чрез обратен превод и използваме фина настройка за крайния модел. За нашите най-добри резултати използвахме 12-слойна конфигурация на трансформатор, постигайки най-съвременни резултати на тестовия комплект. Експериментираме и с модели ученик-учител, за да подобрим производителността на по-малки модели.', 'nl': 'In dit artikel beschrijven we de inzending van het KIT voor de IWSLT 2019 gedeelde taak tekstvertaling. Ons systeem is gebaseerd op het transformatormodel [1] met behulp van onze eigen implementatie. We breiden de beschikbare trainingsgegevens uit met back-translation en maken gebruik van finetuning voor het uiteindelijke model. Voor onze beste resultaten gebruikten we een 12-laagse transformatorgrote configuratie, waarmee we state-of-the-art resultaten behaalden op de WMT2018 testset. We experimenteren ook met student-leraar modellen om de prestaties van kleinere modellen te verbeteren.', 'da': "I denne artikel beskriver vi KIT's indsendelse til IWSLT 2019 delte opgave om tekstoversættelse. Vores system er baseret på transformermodellen [1] ved hjælp af vores interne implementering. Vi øger de tilgængelige træningsdata ved hjælp af back-translation og anvender finjustering til den endelige model. For vores bedste resultater anvendte vi en 12-lags transformer-stor konfiguration, hvilket opnåede state-of-the-art resultater på WMT2018 testsættet. Vi eksperimenterer også med elev-lærer modeller for at forbedre ydeevnen af mindre modeller.", 'hr': 'U ovom papiru opisujemo podatke KIT-a za IWSLT 2019. zajednički zadatak o prevodu teksta. Naš sustav se temelji na modelu transformacije [1] koristeći našu unutarnju provedbu. Povećavamo dostupne podatke o obuci koristeći natrag prevod i zapošljavamo finalnu prilagodbu za konačni model. Za naš najbolji rezultat, koristili smo 12-slojni transformator-veliku konfiguraciju, ostvarili rezultate umjetnosti na setu WMT2018-a. Također eksperimentiramo s modelima učenika i učitelja kako bi poboljšali učinkovitost manjih modela.', 'id': 'Dalam kertas ini, kami menggambarkan pengiriman KIT untuk tugas berbagi IWSLT 2019 pada terjemahan teks. Sistem kita berdasarkan model transformer [1] menggunakan implementasi dalam rumah kita. Kami menambah data pelatihan yang tersedia menggunakan terjemahan belakang dan menggunakan penyesuaian untuk model akhir. Untuk hasil terbaik kami, kami menggunakan transformator 12 lapisan besar konfigurasi, mencapai hasil terbaik pada set tes WMT2018. Kami juga eksperimen dengan model siswa-guru untuk meningkatkan prestasi model kecil.', 'de': 'In diesem Beitrag beschreiben wir die Einreichung des KIT für die gemeinsame Aufgabe IWSLT 2019 zur Textübersetzung. Unser System basiert auf dem Transformatormodell [1] mit unserer hauseigenen Implementierung. Wir erweitern die verfügbaren Trainingsdaten durch Backtranslation und führen Feinabstimmungen für das endgültige Modell durch. Für unsere besten Ergebnisse haben wir eine 12-lagige Transformator-Großkonfiguration verwendet, die am WMT2018 Testset State-of-the-Art Ergebnisse erzielt. Wir experimentieren auch mit Schüler-Lehrer-Modellen, um die Leistung kleinerer Modelle zu verbessern.', 'fa': 'در این کاغذ، ما تحویل KIT را برای کار مشترک IWSLT 2019 در مورد ترجمه متن توصیف می کنیم. سیستم ما بر اساس مدل تغییر دهنده [1] با استفاده از عملیات داخلی ما است. ما اطلاعات آموزش موجود را با استفاده از ترجمه پشتی افزایش می کنیم و برای مدل نهایی استفاده می کنیم. برای بهترین نتیجه\u200cهایمان، ما از یک تغییر\u200cدهنده\u200cی ۱۲ طبقه بزرگ پیکربندی استفاده کردیم، به رسیدن نتیجه\u200cهای موقعیت هنری در مجموعه آزمایش WMT2018 استفاده کردیم. ما همچنین با مدل دانش آموزان و دانش آموزان آزمایش می کنیم تا عملکرد مدل کوچک را بهتر کنیم.', 'ko': '본문에서 KIT가 제출한 텍스트 번역에 관한 IWSLT 2019 공유 임무를 기술했다.우리의 시스템은 변압기 모델을 바탕으로 우리의 내부를 이용하여 실현한다[1].우리는 역방향 번역을 사용하여 사용 가능한 훈련 데이터를 늘리고 최종 모델을 미세하게 조정합니다.최상의 효과를 얻기 위해 우리는 12층 변압기 대배치를 사용하여 WMT 2018 테스트집에서 가장 선진적인 결과를 얻었다.우리는 또한 학생-교사 모형에 대해 실험을 진행하여 비교적 작은 모형의 성능을 향상시켰다.', 'sw': 'Katika gazeti hili, tunaelezea ujumbe wa KIT kwa ajili ya IWSLT 2019 ulisambazwa kazi kwenye tafsiri ya maandishi. Mfumo wetu unategemea mtindo wa mabadiliko[1] kwa kutumia utekelezaji wetu wa nyumbani. Tunaweza kuongeza taarifa za mafunzo zinazopatikana kwa kutumia tafsiri ya nyuma na kufanya kazi nzuri kwa mtindo wa mwisho. Kwa matokeo yetu bora zaidi, tulitumia jukwaa la mabadiliko makubwa ya ubunifu wa ngazi 12, kupata matokeo ya hali ya sanaa kwenye seti ya mtihani wa WMT2018. Tunajaribu pia na mifano ya wanafunzi ili kuboresha utendaji wa mifano madogo.', 'sq': 'Në këtë letër, ne përshkruajmë paraqitjen e KIT për detyrën e përbashkët të IWSLT 2019 në përkthimin e tekstit. Sistemi ynë është bazuar në model in transformues [1] duke përdorur zbatimin tonë brenda. Ne shtojmë të dhënat e trajnimit të disponueshme duke përdorur përkthimin mbrapsht dhe duke përdorur rregullime për modelin përfundimtar. Për rezultatet tona më të mira, kemi përdorur një transformues 12 nivesh konfigurim të madh, duke arritur rezultate më të larta në kompletin e testit WMT2018. Ne gjithashtu eksperimentojmë me modele student ë-mësues për të përmirësuar performancën e modeleve më të vogla.', 'tr': "Bu kagyzda KIT'iň IWSLT 2019-nji ýygnagynda metin terjime etmekde paýlaşýarys Biziň sistemamyz öýümizdeki implementasymyzy ulanan transformer nusgasyna daýanýar. Biz elýeterli terjime etmek maglumatyny arka terjime etmek we soňky nusga üçin ýeterlik taýýarlamak üçin ulanýarys. Biziň iň gowy netijelerimiz üçin, WMT2018 testi düzeninde 12 gatlak üýtgewçiliki ullandyk. Biz hem okuwçy-mugallymyň nusgalary bilen kiçi nusgalaryny gowurak etmek üçin synanyşýarys.", 'am': 'በዚህ ገጾች ላይ የKIT አዋጅ በጽሑፍ ትርጓሜ ላይ የተካፈለውን ሥራ እናሳውቃለን፡፡ ስርዓታችን በቤት ውስጥ ተግባራችንን በመጠቀም የለውጥ model ነው፡፡ We augment the available training data using back-translation and employ fine-tuning for the final model.  ለመሻለል ፍጥረታችን የ12 ደረጃን ለውጥ-ትልቅ config-uration እና በWMT2018 ፈተና ላይ የ-art ፍጥረቶችን አግኝተን ነበር፡፡ እናም ተማሪ-አስተማሪ ምሳሌዎችን ትንሽን የሞዴል አድራጊዎችን ለማሻል እንሞክራለን፡፡', 'hy': 'Այս թղթի մեջ մենք նկարագրում ենք KIT-ի ներկայացումը 2019 թվականի IW-ՍԼT-ի ընդհանուր հանձնարարության համար տեքստի թարգմանման մասին: Մեր համակարգը հիմնված է վերափոխողի մոդելի վրա [1] օգտագործելով մեր ներքին իրականացումը: Մենք ավելացնում ենք հասանելի ուսումնասիրության տվյալները, օգտագործելով հետադարձ թարգմանություն և օգտագործում ենք վերջնական մոդելի համար բարելավումներ: Մեր լավագույն արդյունքների համար մենք օգտագործեցինք 12 շերտ վերափոխող մեծ կառուցվածք, որպեսզի ստանանք ամենակարևոր արդյունքներ World MT2018 թեստերի համակարգում: Մենք նաև փորձում ենք ուսանողների-ուսուցիչների մոդելների հետ, որպեսզի բարելավենք փոքր մոդելների արտադրողությունը:', 'af': "In hierdie papier, beskrywe on s Kit se onderwerp vir die IWSLT 2019 deel taak op teks vertaling. Ons stelsel is gebaseer op die transformeermodel [1] met die gebruik van ons in-huis implementasie. Ons vergroot die beskikbare onderwerp data deur terug-vertaling te gebruik en die fin-tuning vir die eindelike model gebruik. Vir ons beste resultate het ons 'n 12- laag transformeer- groot konfigurasie- verstelling gebruik, tot toegang van status- of- the- art resultate op die WMT2018 toets stel. Ons het ook eksperimenteer met studente-onderwyser-modelles om die prestasie van kleinere modelles te verbeter.", 'bn': 'এই কাগজটিতে আমরা কিটির সংবাদপত্রের বর্ণনা করেছি ইউএসএলটি ২০১৯ টি টেক্সট অনুবাদের কাজে শেয়ার করেছে। আমাদের সিস্টেম ব্যবহার করে আমাদের ঘরের বাস্তবতা ব্যবহার করে পরিবর্তন মডেলের উপর ভিত্তিত। আমরা প্রশিক্ষণের তথ্য যোগ করি ব্যাক-ট্রেনিং অনুবাদ ব্যবহার করে এবং চূড়ান্ত মডেলের জন্য ভালোভাবে টুইনিং করি। আমাদের সবচেয়ে ভাল ফলাফলের জন্য আমরা ১২ স্তরের বিশাল পরিবর্তন ব্যবহার করেছিলাম-বিশাল কনফিগারেশন-উরেশন, উইএমটি২০১৮ পরীক্ষার ফলাফল পাওয়ার ছাত্র-শিক্ষক মডেলের সাথে আমরা পরীক্ষা করছি ছোট মডেলের প্রভাব উন্নত করার জন্য।', 'az': "Bu kağızda, 2019 ilə IWSLT üçün KIT'nin vəzifəsini metin çevirilməsi barəsində paylaşır. Sistemimiz evdə işlədiyimiz transformer modeli üzərində dayanılır. Biz mümkün təhsil məlumatlarını geri çevirib son modeli üçün gözəl təhsil etməyi istifadə edirik. Ən yaxşı sonuçlarımıza görə, WMT2018 sınama qutusunda 12-katlı transformer-böyük yapılandırma işlədik. Biz də öğrenci-müəllimin modelləri ilə daha kiçik modellərin performansını yaxşılaşdırmaq üçün təcrübə edirik.", 'bs': 'U ovom papiru opisujemo podatke KIT-a za IWSLT 2019. zajednički zadatak o prevodu teksta. Naš sistem je baziran na modelu transformacije [1] koristeći našu implementaciju unutarnje kuće. Povećavamo dostupne podatke o obuci koristeći povratni prevod i zapošljavamo finalnu prilagodbu za konačni model. Za naš najbolji rezultat, koristili smo 12-slojni transformator-veliku konfiguraciju, ostvarili rezultate umjetnosti na setu WMT2018-a. Također eksperimentiramo sa modelima učenika i učitelja kako bi poboljšali učinkovitost manjih modela.', 'cs': 'V tomto článku popisujeme podání KIT pro sdílený úkol IWSLT 2019 v oblasti překladu textů. Náš systém je založen na modelu transformátoru [1] pomocí vlastní implementace. Dostupná tréninková data rozšiřujeme pomocí zpětného překladu a používáme jemné ladění pro finální model. Pro naše nejlepší výsledky jsme použili 12vrstvou konfiguraci velkého transformátoru, která dosáhla nejmodernějších výsledků na testovací sadě WMT2018. Experimentujeme také s modely studenta-učitele pro zlepšení výkonu menších modelů.', 'ca': "En aquest article, descrivim la presentació de KIT per la tasca compartida IWSLT 2019 sobre traducció de text. El nostre sistema està basat en el model de transformador [1] utilitzant la nostra implementació interna. augmentem les dades d'entrenament disponibles fent servir traducció posterior i utilitzem ajustes al model final. Per als nostres millors resultats, vam utilitzar una gran configuració de transformador de 12 capes, aconseguint resultats més avançats en el conjunt de proves WMT2018. També experimentem amb models estudiants-professors per millorar el rendiment de models més petits.", 'fi': 'Tﾃ､ssﾃ､ artikkelissa kuvailemme KIT:n osallistumista IWSLT 2019:n yhteiseen tekstikﾃ､ﾃ､ntﾃ､mistehtﾃ､vﾃ､ﾃ､n. Jﾃ､rjestelmﾃ､mme perustuu muuntajamalliin [1], jossa kﾃ､ytetﾃ､ﾃ､n sisﾃ､istﾃ､ toteutustamme. Lisﾃ､ﾃ､mme saatavilla olevaa koulutustietoa taaksekﾃ､ﾃ､nnﾃｶksen avulla ja kﾃ､ytﾃ､mme hienosﾃ､ﾃ､tﾃｶﾃ､ lopulliseen malliin. Parhaan tuloksen saamiseksi kﾃ､ytimme 12-kerroksista muuntajan isoa konfigurointia, joka saavutti huippuluokan tulokset WMT2018 testisarjassa. Kokeilemme myﾃｶs opiskelija-opettaja-malleja pienempien mallien suorituskyvyn parantamiseksi.', 'et': 'Käesolevas töös kirjeldame KITi esitamist IWSLT 2019 jagatud tekstitõlke ülesandele. Meie süsteem põhineb trafo mudelil [1], kasutades meie ettevõttesisest rakendust. Täiendame olemasolevaid koolitusandmeid tagantõlke abil ja kasutame lõpliku mudeli peenhäälestust. Parimate tulemuste saavutamiseks kasutasime 12-kihilist transformaatori suurt konfiguratsiooni, saavutades WMT2018 testikomplekti tipptasemel tulemused. Eksperimenteerime ka õpilase-õpetaja mudelitega, et parandada väiksemate mudelite jõudlust.', 'jv': 'Nang pemilih iki, kita sambah ngeremusi KT nggawe IWSLT, 2011 marang banter nggambar tarjamahan teks Sistem dadine yuwe dadine transformer model [1] dumaten kita keji mulai Awak dhéwé ngéwangi tanggal nggawe barang-terjamahan lan genajeng nggawe barang-terjamahan kanggo model sing ngwale. Laptop" and "Desktop Awak dhéwé éntuk éntuk karo model sing guru-guru mbut kuwi nggawe model sing nyimpen.', 'ha': "Ga wannan takardan, Munã bayyana KIT'in da aka wajabta aikin IWSLT 2019 wanda aka raba aiki na fassarar text. Ana bincike na'urarmu a kan misalin transformer[1] da ke amfani da shirin ayukanmu a cikin bayani. Mu ƙara data masu tsari da ke iya amfani da zane-zane-zane-zane-zane-zane kuma za mu yi aiki mai kyau zuwa misali ƙarshen. Ga mafiya kyauta, mun yi amfani da transformer-babban configment-12-Layer, kuma muka sami fassarar-the-art a kan jarrabin WMT2018. Kayya, Munã jarraba misãlai masu macallin da su kyautata gyaran misalin ƙarami.", 'sk': 'V tem prispevku opisujemo oddajo KIT za skupno nalogo IWSLT 2019 o prevajanju besedil. Naš sistem temelji na modelu transformatorja [1], ki uporablja našo lastno implementacijo. Razpoložljive podatke o usposabljanju dopolnjujemo s pomočjo nazaj prevajanja in uporabljamo fine nastavitve za končni model. Za naše najboljše rezultate smo uporabili 12-slojno konfiguracijo transformatorja, ki je dosegla najsodobnejše rezultate na testnem kompletu WMT2018. Prav tako eksperimentiramo z modeli učencev-učiteljev za izboljšanje učinkovitosti manjših modelov.', 'he': 'בעיתון הזה, אנחנו מתארים את ההעברה של KIT למשימה משותפת IWSLT 2019 על תרגום טקסט. המערכת שלנו מבוססת על מודל המעבר [1] בשימוש בהפעלה בתוך הבית שלנו. אנחנו מגדילים את נתוני האימונים הנוכחים באמצעות התרגום מאחור ומשתמשים התרגיל למודל הסופי. עבור התוצאות הטובות ביותר שלנו, השתמשנו במעבר 12 שכבות-גדול-סדרה, להשיג תוצאות חדשות במבחן WMT2018. אנחנו גם מנסים עם דוגמנים סטודנטים-מורים כדי לשפר את ההופעה של דוגמנים קטנים יותר.', 'bo': 'ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ཚོས་ཡིག་ཆ་ལ་འཇུག་སྣོད་ཀྱི་IWSLT 2019ལ་མཉམ་དུ་འཇུག་སྣོད་ཀྱི་གཏན་ཁེལ་བྱེད་པ ང་ཚོའི་མ་ལག་གིས་འདུག་ང་ཚོའི་ནང་གི་ལས་དབུས་བཟོ་བཅོས་མིན་པ་ལྟར་གཞུང་བྱེད་ཀྱི་ཡོད། ང་ཚོས་རྗེས་མཇུག་གི་མ་དབྱིབས་སྤྱད་ནས་དུས་ཚོད་ལས་ཕར་ཆེན་བྱེད་པའི་གནད་སྡུད་ཆ་འཕྲིན་དང་། For our best results, we used a 12-layer transformer-big config-uration, achieving state-of-the-art results on the WMT2018 test set. ང་ཚོས་ཀྱང་སློབ་ཆེན་ཁག་མ་དཔེ་བྱེད་པའི་མིག་རྩལ་བ་དང་མཐུན་རྐྱེན་ཚད་ལྡན་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Adapting Multilingual Neural Machine Translation to Unseen Languages', 'ar': 'تكييف الترجمة الآلية العصبية متعددة اللغات مع اللغات غير المرئية', 'fr': 'Adapter la traduction automatique neuronale multilingue à des langues inédites', 'es': 'Adaptación de la traducción automática neuronal multilingüe a idiomas invisibles', 'pt': 'Adaptando a tradução automática neural multilíngue para idiomas invisíveis', 'ja': '多言語ニューラル機械翻訳を隠れた言語に適応させる', 'zh': '使多言神经机器翻译应不见之语', 'hi': 'अनदेखी भाषाओं के लिए बहुभाषी तंत्रिका मशीन अनुवाद को अनुकूलित करना', 'ru': 'Адаптация многоязычного нейронного машинного перевода к невидимым языкам', 'ga': 'Aistriúchán Meaisín Néar Ilteangach a Chur in oiriúint do Theangacha Neamhfheicthe', 'ka': 'Multilingual Neural Machine Translation to Unseen Languages', 'it': 'Adattare la traduzione automatica neurale multilingue a lingue invisibili', 'hu': 'Többnyelvű idegi fordítás adaptálása láthatatlan nyelvekre', 'kk': 'Көптеген тілдердің нейрал машинаның аудармасын көрсетілмеген тілдерге өзгерту', 'el': 'Προσαρμογή της πολύγλωσσης νευρωνικής μηχανικής μετάφρασης σε αόρατες γλώσσες', 'ml': 'പല ഭാഷകളുടെ നെയുറല്\u200d യന്ത്രങ്ങള്\u200d അദൃശ്യമായ ഭാഷകളിലേക്ക് പരിഭാഷപ്പെടുത്തുന്നു', 'mk': 'Адаптирање на повеќејазичниот превод на неверојатни јазици', 'lt': 'Daugiakalbės neurologinės mašinos vertimo į nematomas kalbas pritaikymas', 'mt': 'Adattament tat-Traduzzjoni Multilingwi tal-Magna Newrali għal Lingwi Mhux Magħrufa', 'mn': 'Олон хэл мэдрэлийн машины хөгжлийн хэл дээр', 'no': 'Tilpass fleirspråk neuralmaskinsomsetjing til ukjende språk', 'pl': 'Dostosowanie wielojęzycznego neuronowego tłumaczenia maszynowego do niewidzialnych języków', 'si': 'ගොඩක් භාෂාවක් න්\u200dයූරාල් මේෂින් පරිවර්තනය නොදැකි භාෂාවට ඇතුළත් කරන්න', 'ms': 'Adapting Multilingual Neural Machine Translation to Unseen Languages', 'sr': 'Prilagođenje multijezičkog neuralnog prevoda na nevidljive jezike', 'ro': 'Adaptarea traducerii automate neurale multilingve la limbi nevăzute', 'ur': 'Multilingual Neural Machine Translation to Unseen Languages', 'sv': 'Anpassa flerspråkig neural maskinöversättning till osynliga språk', 'so': 'Turjumista luuqadaha qarsoon', 'ta': 'மொழிகளை மறைக்கப்படாத மொழிகளுக்கு பல மொழிகளின் நெருக்கல் இயந்திரம் மொழிபெயர்ப்பிடுகிறது', 'uz': 'Adapting Multilingual Neural Machine Translation to Unseen Languages', 'vi': 'Chỉnh sửa máy thần kinh đa ngôn ngữ sang ngôn ngữ không sâu', 'bg': 'Адаптиране на многоезичния неврален машинен превод към невидими езици', 'nl': 'Meertalige Neurale Machine Translation aanpassen aan onzichtbare talen', 'hr': 'Prilagođenje višejezičkog Neuralnog prevoda na nevidljive jezike', 'ko': '보이지 않는 언어에 적응하도록 다국어 신경 기계 번역', 'da': 'Tilpasning af flersproget neural maskinoversættelse til usynlige sprog', 'fa': 'تغییر دادن ماشین عصبی چندین زبان به زبانهای غیبی', 'de': 'Anpassung der mehrsprachigen neuronalen maschinellen Übersetzung an unsichtbare Sprachen', 'sw': 'Tafsiri ya Mashine ya Kifaragha ya Kireno kwa lugha isiyo fichikana', 'af': 'Aanpasser veelvuldige neurale masjien vertaling na Onsien Taal', 'sq': 'Adapting Multilingual Neural Machine Translation to Unseen Languages', 'am': 'ቋንቋዎች', 'tr': 'Çoklu dilli näyral maşynyň terjimesini görmedik dillere üýtget', 'id': 'Adaptasi Penerjemahan Mesin Neural Berbahasa ke Bahasa Tak Terlihat', 'bn': 'অদৃশ্য ভাষায় বহুভাষী নিউরাল মেশিন অনুবাদ করা হচ্ছে', 'az': 'Çoxlu dil nöral maşına çevirilən dillərə uyğunlaşdırma', 'cs': 'Přizpůsobení vícejazyčného neuronového strojového překladu do neviditelných jazyků', 'hy': 'Adapting Multilingual Neural Machine Translation to Unseen Languages', 'et': 'Mitmekeelse neuraalse masintõlke kohandamine nähtamatute keeltega', 'bs': 'Prilagođenje multijezičkog neuronskog prevoda na nevidljive jezike', 'ca': 'Adaptar la traducció multilingüe de màquines neuronals a llengües invisibles', 'fi': 'Monikielisen neurokäännöksen mukauttaminen näkymättömiin kieliin', 'jv': 'Ngubah kang banter Jejaral-Jejaral kang sampeyan Inggal', 'sk': 'Prilagajanje večjezičnega strojnega živčnega prevoda nevidnim jezikom', 'ha': 'Translate late to hidden languages', 'he': 'מתאים את התרגום של מכונת נוירולית רבות לשפות בלתי נראות', 'bo': 'སྐད་རིགས་མི་ཤེས་པའི་སྐད་ཡིག་དང་མཚུངས་བའི་མི་ལག་འཁྱེར་གྱི་ཚིག་བསྒྱུར་བཅུག་བྱེད་པ'}
{'en': 'Multilingual Neural Machine Translation (MNMT) for low- resource languages (LRL) can be enhanced by the presence of related high-resource languages (HRL), but the relatedness of HRL usually relies on predefined linguistic assumptions about language similarity. Recently, adapting MNMT to a ', 'ar': 'يمكن تحسين الترجمة الآلية العصبية متعددة اللغات (MNMT) للغات منخفضة الموارد (LRL) من خلال وجود لغات ذات موارد عالية (HRL) ، لكن ارتباط HRL يعتمد عادةً على افتراضات لغوية محددة مسبقًا حول تشابه اللغة. في الآونة الأخيرة ، أظهر تكييف MNMT مع LRL أنه يحسن الأداء بشكل كبير. في هذا العمل ، نستكشف مشكلة تكييف نموذج MNMT مع LRL غير المرئي باستخدام اختيار البيانات وتكييف النموذج. من أجل تحسين NMT لـ LRL ، نستخدم الحيرة لتحديد بيانات HRL الأكثر تشابهًا مع LRL على أساس مسافة اللغة. نستكشف على نطاق واسع اختيار البيانات في إعدادات NMT الشائعة متعددة اللغات ، وبالتحديد في الترجمة (بدون طلقة) ، وفي التكيف من نموذج متعدد اللغات مدرب مسبقًا ، لكلا الاتجاهين (LRL↔en). نوضح كذلك أن التكيف الديناميكي لمفردات النموذج ينتج عنه تقسيم أكثر ملاءمة لـ LRL مقارنةً بالتكيف المباشر. تُظهر التجارب انخفاضًا في وقت التدريب ومكاسب كبيرة في الأداء عبر خطوط الأساس LRL ، حتى مع عدم وجود بيانات LRL (+13.0 BLEU) ، حتى +17.0 BLEU للتكيف الديناميكي للنموذج متعدد اللغات المدربين مسبقًا مع اختيار البيانات ذات الصلة. تتفوق طريقتنا في الأداء على الأساليب الحالية ، مثل النماذج متعددة اللغات على نطاق واسع وزيادة البيانات ، على أربعة LRL.', 'fr': "La traduction automatique neuronale multilingue (MNMT) pour les langues à faibles ressources (LRL) peut être améliorée par la présence de langues à ressources élevées (HRL) associées, mais la parenté de la HRL repose généralement sur des hypothèses linguistiques prédéfinies concernant la similitude linguistique. Récemment, l'adaptation de MNMT à un LRL a permis d'améliorer considérablement les performances. Dans ce travail, nous explorons le problème de l'adaptation d'un modèle MNMT à une LRL invisible à l'aide de la sélection de données et de l'adaptation du modèle. Afin d'améliorer la NMT pour LRL, nous utilisons la perplexité pour sélectionner les données HRL les plus similaires à la LRL sur la base de la distance linguistique. Nous explorons de manière approfondie la sélection de données dans les paramètres NMT multilingues populaires, notamment dans la traduction (zero-shot), et dans l'adaptation à partir d'un modèle pré-entraîné multilingue, pour les deux directions (LRL ↔ en). Nous montrons également que l'adaptation dynamique du vocabulaire du modèle entraîne une segmentation plus favorable pour la LRL par rapport à l'adaptation directe. Les expériences montrent des réductions du temps d'entraînement et des gains de performance significatifs par rapport aux lignes de base LRL, même avec des données LRL nulles (+13,0 UEBL), jusqu'à +17,0 UEBL pour l'adaptation dynamique du modèle multilingue pré-entraîné avec sélection des données connexes. Notre méthode surpasse les approches actuelles, telles que les modèles massivement multilingues et l'augmentation des données, sur quatre LRL.", 'es': 'La traducción automática neuronal multilingüe (MNMT) para idiomas de bajos recursos (LRL) se puede mejorar con la presencia de idiomas de recursos altos (HRL) relacionados, pero la relación de los HRL generalmente se basa en suposiciones lingüísticas predefinidas sobre la similitud lingüística. Recientemente, la adaptación de la MNMT a un LRL ha demostrado mejorar considerablemente el rendimiento. En este trabajo, exploramos el problema de adaptar un modelo MNMT a un LRL invisible mediante la selección de datos y la adaptación del modelo. Con el fin de mejorar la NMT para LRL, utilizamos la perplejidad para seleccionar los datos de HRL que sean más similares al LRL en función de la distancia entre idiomas. Exploramos ampliamente la selección de datos en entornos populares de NMT multilingües, es decir, en la traducción (zero-shot) y en la adaptación de un modelo multilingüe previamente entrenado, para ambas direcciones (LRL ↔ es). Además, mostramos que la adaptación dinámica del vocabulario del modelo resulta en una segmentación más favorable para el LRL en comparación con la adaptación directa. Los experimentos muestran reducciones en el tiempo de entrenamiento y ganancias de rendimiento significativas con respecto a las líneas de base de LRL, incluso con datos de LRL cero (+13.0 BLEU), hasta +17.0 BLEU para la adaptación dinámica de modelos multilingües previamente entrenados con la selección de datos relacionados. Nuestro método supera a los enfoques actuales, como los modelos multilingües masivos y el aumento de datos, en cuatro LRL.', 'pt': 'A tradução automática neural multilíngue (MNMT) para linguagens de baixo recurso (LRL) pode ser aprimorada pela presença de linguagens relacionadas de alto recurso (HRL), mas o relacionamento de HRL geralmente depende de suposições linguísticas predefinidas sobre semelhança de linguagem. Recentemente, adaptar o MNMT a um LRL mostrou melhorar muito o desempenho. Neste trabalho, exploramos o problema de adaptar um modelo MNMT a um LRL não visto usando seleção de dados e adaptação de modelo. A fim de melhorar o NMT para LRL, empregamos perplexidade para selecionar dados HRL que são mais semelhantes ao LRL com base na distância do idioma. Exploramos extensivamente a seleção de dados em configurações NMT multilíngues populares, ou seja, na tradução (zero-shot) e na adaptação de um modelo pré-treinado multilíngue, para ambas as direções (LRL↔en). Mostramos ainda que a adaptação dinâmica do vocabulário do modelo resulta em uma segmentação mais favorável para o LRL em comparação com a adaptação direta. Os experimentos mostram reduções no tempo de treinamento e ganhos significativos de desempenho sobre as linhas de base LRL, mesmo com dados LRL zero (+13,0 BLEU), até +17,0 BLEU para adaptação dinâmica de modelo multilíngue pré-treinado com seleção de dados relacionados. Nosso método supera as abordagens atuais, como modelos massivamente multilíngues e aumento de dados, em quatro LRL.', 'ja': '低資源言語（ LRL ）の多言語ニューラル・マシン・トランスレーション（ MNMT ）は、関連する高資源言語（ HRL ）の存在によって強化することができるが、HRLの関連性は通常、言語の類似性に関する事前定義された言語学的仮定に依存する。 最近では、MNMTをLRLに適合させることで、パフォーマンスを大幅に向上させることが示されています。 この研究では、データ選択とモデルアダプタを使用して、MNMTモデルを見えないLRLに適応させる問題を探求する。 LRLのNMTを改善するために、言語距離に基づいてLRLに最も類似したHRLデータを選択するために困惑を利用します。 私たちは、（ゼロショット）翻訳、および両方向の多言語事前トレーニングモデルからの適応（ LRL↔ en ）という、人気のある多言語NMT設定でのデータ選択を幅広く探求しています。 さらに、モデルの語彙の動的適応は、直接適応と比較して、LRLにとってより好ましいセグメンテーションをもたらすことを示している。 実験では、LRLデータがゼロ（+13.0 BLEU ）であっても、事前にトレーニングされた多言語モデルの動的適応と関連データの選択のために、LRLベースラインよりもトレーニング時間が短縮され、パフォーマンスが大幅に向上することが示されています。 当社の方法は、大規模な多言語モデルやデータ拡張などの現在のアプローチを4つのLRLで上回っています。', 'zh': '低资源言语(LRL)者多言神经机器翻译(MNMT)可以相关高(HRL)者强,而HRL者相关性常赖言语相似性预定义语言假设。 近将MNMMT调LRL已验可大大提高性能。 于此,论用数适应性将MNMT应不见之LRL。 所以崇LRL之NMT,以困惑言语相去之本,择与LRL最相似者HRL数。 博求多言NMT置中之数据选择,(零次)译与多言预练模双向(LRLen↔)。 明与直比,词汇应LRL利细分。 实验虽 LRL 数为零(+13.0 BLEU),练时复调著,达 +17.0 BLEU豫练者多言动应数据选择。 吾法于四LRL上优于前,如大言模形及数据增强。', 'ru': 'Многоязычный нейронный машинный перевод (MNMT) для языков с низким уровнем ресурсов (LRL) может быть усилен наличием родственных языков с высоким уровнем ресурсов (HRL), но взаимосвязь HRL обычно основывается на заранее определенных лингвистических предположениях о сходстве языков. В последнее время, адаптация MNMT к LRL показала значительное улучшение производительности. В этой работе мы исследуем проблему адаптации модели MNMT к невидимому LRL с использованием выбора данных и адаптации модели. Для улучшения NMT для LRL мы используем недоумение, чтобы отобрать данные HRL, которые наиболее похожи на LRL на основе языкового расстояния. Мы широко изучаем выбор данных в популярных многоязычных настройках НБ, а именно в (нулевом) переводе и в адаптации из многоязычной предварительно обученной модели, для обоих направлений (LRL↔en). Мы далее показываем, что динамическая адаптация словарного запаса модели приводит к более благоприятной сегментации для LRL по сравнению с прямой адаптацией. Эксперименты показывают изменения в времени обучения и значительное увеличение производительности по сравнению с исходными уровнями LRL, даже при нулевых данных LRL (+13,0 BLEU), до +17,0 BLEU для предварительно обученной многоязычной модели динамической адаптации с соответствующим выбором данных. Наш метод превосходит современные подходы, такие как массивные многоязычные модели и расширение данных, на четырех LRL.', 'hi': 'कम संसाधन भाषाओं (एलआरएल) के लिए बहुभाषी न्यूरल मशीन ट्रांसलेशन (एमएनएमटी) को संबंधित उच्च-संसाधन भाषाओं (एचआरएल) की उपस्थिति से बढ़ाया जा सकता है, लेकिन एचआरएल की संबंधितता आमतौर पर भाषा समानता के बारे में पूर्वनिर्धारित भाषाई मान्यताओं पर निर्भर करती है। हाल ही में, MNMT को LRL में अनुकूलित करने से प्रदर्शन में बहुत सुधार हुआ है। इस काम में, हम डेटा चयन और मॉडल अनुकूलन का उपयोग करके एक अनदेखी एलआरएल के लिए एक MNMT मॉडल को अनुकूलित करने की समस्या का पता लगाते हैं। एलआरएल के लिए एनएमटी में सुधार करने के लिए, हम एचआरएल डेटा का चयन करने के लिए उलझन को नियोजित करते हैं जो भाषा दूरी के आधार पर एलआरएल के समान हैं। हम बड़े पैमाने पर लोकप्रिय बहुभाषी एनएमटी सेटिंग्स में डेटा चयन का पता लगाते हैं, अर्थात् (शून्य-शॉट) अनुवाद में, और दोनों दिशाओं (एलआरएलएन↔) के लिए एक बहुभाषी पूर्व-प्रशिक्षित मॉडल से अनुकूलन में। हम आगे दिखाते हैं कि मॉडल की शब्दावली के गतिशील अनुकूलन के परिणामस्वरूप प्रत्यक्ष अनुकूलन की तुलना में एलआरएल के लिए अधिक अनुकूल विभाजन होता है। प्रयोगों से पता चलता है कि प्रशिक्षण समय में पुन: डक्टियन और एलआरएल बेसलाइन पर महत्वपूर्ण प्रदर्शन लाभ, यहां तक कि शून्य एलआरएल डेटा (+ 13.0 BLEU) के साथ भी, संबंधित डेटा चयन के साथ पूर्व-प्रशिक्षित बहुभाषी मॉडल गतिशील अनुकूलन के लिए +17.0 BLEU तक। हमारी विधि वर्तमान दृष्टिकोणों को मात देती है, जैसे कि बड़े पैमाने पर बहुभाषी मॉडल और डेटा वृद्धि, चार एलआरएल पर।', 'ga': "Is féidir Aistriú Innealltáineach Ilteangach (MNMT) do theangacha íseal-acmhainne (LRL) a fheabhsú trí theangacha ard-acmhainne gaolmhara (HRL) a bheith ann, ach de ghnáth braitheann gaolmhaireacht HRL ar thoimhdí teangeolaíochta réamhshainithe faoi chosúlachtaí teanga. Le déanaí, léiríodh go bhfeabhsaítear feidhmíocht go mór trí MNMT a oiriúnú do LRL. Sa obair seo, déanaimid iniúchadh ar an bhfadhb a bhaineann le múnla MNMT a oiriúnú do LRL nach bhfacthas riamh roimhe agus úsáid á baint as roghnú sonraí agus oiriúnú samhla. D'fhonn NMT do LRL a fheabhsú, bainimid úsáid as anachain chun sonraí HRL a roghnú is cosúla leis an LRL ar bhonn achair teanga. Déanaimid iniúchadh forleathan ar roghnú sonraí i suíomhanna ilteangacha NMT a bhfuil móréilimh orthu, eadhon in aistriúchán (nialas), agus in oiriúint ó mhúnla ilteangach réamhoilte, don dá threo (LRL↔en). Léirímid freisin go mbíonn deighilt níos fabhraí don LRL i gcomparáid le hoiriúnú díreach mar thoradh ar oiriúnú dinimiciúil ar fhoclóir na samhla. Léiríonn turgnaimh laghduithe ar am oiliúna agus gnóthachain feidhmíochta suntasacha thar bhonnlínte LRL, fiú le nialas sonraí LRL (+13.0 BLEU), suas go +17.0 BLEU le haghaidh oiriúnú dinimiciúil réamh-oilte samhail ilteangach le roghnú sonraí gaolmhar. Is fearr lenár modh cur chuige reatha, ar nós samhlacha atá thar a bheith ilteangach agus méadú sonraí, ar cheithre LRL.", 'el': 'Η πολυγλωσσική νευρωνική μηχανική μετάφραση (MNMT) για γλώσσες χαμηλού πόρου (LRL) μπορεί να ενισχυθεί με την παρουσία σχετικών γλωσσών υψηλού πόρου (HRL), αλλά η συγγένεια της HRL συνήθως βασίζεται σε προκαθορισμένες γλωσσικές παραδοχές σχετικά με τη γλωσσική ομοιότητα. Πρόσφατα, η προσαρμογή σε ένα LRL έχει δείξει ότι βελτιώνει σημαντικά την απόδοση. Στην παρούσα εργασία, διερευνούμε το πρόβλημα της προσαρμογής ενός μοντέλου σε ένα αόρατο LRL χρησιμοποιώντας επιλογή δεδομένων και προσαρμογή μοντέλου. Προκειμένου να βελτιωθεί η NMT για το LRL, χρησιμοποιούμε σύγχυση για την επιλογή δεδομένων HRL που είναι πιο παρόμοια με το LRL βάσει της γλωσσικής απόστασης. Εξετάζουμε εκτενώς την επιλογή δεδομένων σε δημοφιλείς πολυγλωσσικές ρυθμίσεις, δηλαδή στη μετάφραση (μηδενική λήψη), και στην προσαρμογή από ένα πολύγλωσσο προ-εκπαιδευμένο μοντέλο, και για τις δύο κατευθύνσεις. Επιπλέον, καταδεικνύουμε ότι η δυναμική προσαρμογή του λεξιλογίου του μοντέλου οδηγεί σε μια ευνοϊκότερη κατάτμηση για το LRL σε σύγκριση με την άμεση προσαρμογή. Τα πειράματα δείχνουν μεταβολές στο χρόνο κατάρτισης και σημαντικά κέρδη απόδοσης σε σχέση με τις γραμμές βάσης ακόμη και με μηδενικά δεδομένα έως +17.0 για προ-εκπαιδευμένη πολύγλωσση δυναμική προσαρμογή μοντέλων με σχετική επιλογή δεδομένων. Η μέθοδος μας ξεπερνά τις τρέχουσες προσεγγίσεις, όπως μαζικά πολυγλωσσικά μοντέλα και αύξηση δεδομένων, σε τέσσερις LRL.', 'hu': 'Az alacsony erőforrású nyelvekre vonatkozó többnyelvű idegi fordítás (MNMT) javítható a kapcsolódó nagy erőforrású nyelvek (HRL) jelenléte, de a HRL kapcsolódása általában a nyelvhasonlóságra vonatkozó előre meghatározott nyelvi feltételezéseken alapul. A közelmúltban az MNMT LRL-hez való hozzáigazítása jelentősen javította a teljesítményt. Ebben a munkában azt a problémát vizsgáljuk, hogy egy MNMT modell egy láthatatlan LRL-hez igazítható adatválasztás és modelladaptáció segítségével milyen módon alakítható ki. Az NMT javítása érdekében a nyelvi távolság alapján zavarban választjuk ki az LRL-hez leginkább hasonló HRL-adatokat. Széles körben vizsgáljuk az adatok kiválasztását népszerű, többnyelvű NMT beállításokban, nevezetesen (zero-shot) fordításban, valamint egy többnyelvű előképzett modellből történő adaptációban mindkét irányban (LRL en). Megmutatjuk továbbá, hogy a modell szókincsének dinamikus adaptációja kedvezőbb szegmentációt eredményez az LRL számára a közvetlen adaptációhoz képest. A kísérletek szerint az oktatási idő visszaesése és az LRL alapvető teljesítménynövekedés jelentős mértékű, még a nulla LRL adat (+13,0 BLEU) esetén is akár +17,0 BLEU értékű, előre képzett, többnyelvű modelldinamikai adaptáció esetén, az ehhez kapcsolódó adatok kiválasztásával. Módszerünk négy LRL-en felülmúlja a jelenlegi megközelítéseket, például a többnyelvű modelleket és az adatbővítést.', 'it': "La traduzione automatica neurale multilingue (MNMT) per le lingue a basso contenuto di risorse (LRL) può essere migliorata dalla presenza di lingue ad alto contenuto di risorse correlate (HRL), ma la relazione di HRL di solito si basa su ipotesi linguistiche predefinite sulla somiglianza linguistica. Recentemente, adattare MNMT a una LRL ha dimostrato di migliorare notevolmente le prestazioni. In questo lavoro, esploriamo il problema dell'adattamento di un modello MNMT a un LRL invisibile utilizzando la selezione dei dati e l'adattamento del modello. Al fine di migliorare l'NMT per LRL, utilizziamo perplessità per selezionare i dati HRL più simili alla LRL in base alla distanza linguistica. Esploriamo ampiamente la selezione dei dati nelle impostazioni NMT multilingue popolari, vale a dire nella traduzione (zero-shot) e nell'adattamento da un modello multilingue pre-addestrato, per entrambe le direzioni (LRL en). Mostriamo inoltre che l'adattamento dinamico del vocabolario del modello porta ad una segmentazione più favorevole per l'LRL rispetto all'adattamento diretto. Gli esperimenti mostrano riduzioni del tempo di allenamento e significativi guadagni di performance rispetto alle linee di base LRL, anche con zero dati LRL (+13,0 BLEU), fino a +17,0 BLEU per l'adattamento dinamico del modello multilingue pre-addestrato con relativa selezione dei dati. Il nostro metodo supera gli approcci attuali, come modelli massicciamente multilingue e l'aumento dei dati, su quattro LRL.", 'lt': 'Daugiakalbis neurologinis mašinų vertimas (MNMT) mažai išteklių turinčioms kalboms gali būti sustiprintas esant susijusioms didelio išteklio kalboms (HRL), tačiau HRL ryšys paprastai grindžiamas iš anksto apibrėžtomis kalbinėmis prielaidomis apie kalbų panašumą. Recently, adapting MNMT to a LRL has shown to greatly improve performance.  In this work, we explore the problem of adapting an MNMT model to an unseen LRL using data selection and model adapta- tion.  Siekiant pagerinti LRL NMT, mes naudojame perpleksiją pasirinkdami HRL duomenis, kurie labiausiai panašūs į LRL pagal kalbinį atstumą. We extensively explore data selection in popular multilingual NMT settings, namely in (zero-shot) translation, and in adaptation from a multilingual pre-trained model, for both directions (LRL en).  Be to, rodome, kad dinamiškas modelio žodyno pritaikymas lemia palankesnę LRL segmentaciją, palyginti su tiesioginiu pritaikymu. Eksperimentai rodo, kad mokymo trukmė mažėja ir kad LRL bazinėse linijose rezultatai gerokai padidėja, net jei nėra duomenų apie LRL (+13,0 BLEU), o daugiakalbio modelio dinaminio pritaikymo su susijusiais duomenimis atveju – iki +17,0 BLEU. Mūsų metodas yra didesnis nei dabartiniai metodai, pavyzdžiui, masiniai daugiakalbiai modeliai ir duomenų didinimas keturiose LRL srityse.', 'kk': 'Көптеген тілдер үшін көптеген невралдық машинаның аудармасы (MNMT) төмен ресурстар тілдерінің (LRL) тілдері (HRL) қатынасы артық ресурстар тілдері (HRL) арқылы көтеруге болады, бірақ HRL қатынасы кәдімгі түрде тілдердің ұқсас тү Жуырда MNMT- ті LRL- ге адаптациялау үлкен жұмыс істеуі көрсетілді. Бұл жұмыс ішінде, МNMT үлгісін анықталмаған LRL үлгісіне қолданып, деректерді таңдау мен үлгісін адаптациялау мәселесін зерттейміз. LRL үшін NMT жақсарту үшін, тіл аралығына негіздеген HRL деректерін таңдау үшін, біз тіл аралығына ұқсас болатын HRL деректерін таңдаймыз. Біз көп тілді NMT параметрлерінде деректерді таңдау үшін көптеген зерттеп, мысалы (zero- shot) аудармасында және көптеген алдын- ала оқылған моделінен (LRL en) адаптациялау үшін. Біз үлгісінің сөздерінің динамикалық адаптациясын көрсету үшін LRL үшін динамикалық адаптациясы тікелей адаптациясымен салыстыру үшін жақсы бөлімдеу нәтижесін көрсету Тәжірибелер LRL негізгі жолдарына қайта бақылау уақытында және мәліметті жылдамдықтарды көрсетеді, сондай-ақ LRL деректері (+13, 0 BLEU) нөл (+17, 0 BLEU) дегенге қайта бақылау үшін бірнеше тілдік модель динамикалы Біздің әдіміміз көптілік үлгілер мен деректерді көбейту үлгілерін төрт LRL үшін көпшілікті жасайды.', 'ms': "Terjemahan Mesin Neural Berbahasa (MNMT) untuk bahasa sumber rendah (LRL) boleh ditambah oleh kehadiran bahasa sumber tinggi yang berkaitan (HRL), tetapi hubungan HRL biasanya bergantung pada asumsi bahasa terdefinisi mengenai persamaan bahasa. Recently, adapting MNMT to a LRL has shown to greatly improve performance.  In this work, we explore the problem of adapting an MNMT model to an unseen LRL using data selection and model adapta- tion.  Untuk meningkatkan NMT untuk LRL, kita menggunakan kekeliruan untuk memilih data HRL yang paling mirip dengan LRL berdasarkan jarak bahasa. Kami mengeksplorasi secara luas pemilihan data dalam tetapan NMT berbilang bahasa populer, iaitu dalam terjemahan (0-shot), dan dalam penyesuaian dari model pra-dilatih berbilang bahasa, untuk kedua-dua arah (LRL en). We further show that dynamic adaptation of the model's vocabulary results in a more favourable segmentation for the LRL in comparison with direct adaptation.  Experiments show re- ductions in training time and significant performance gains over LRL baselines, even with zero LRL data (+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic adaptation with related data selection.  Kaedah kita melebihi pendekatan semasa, seperti model berbilang bahasa besar dan peningkatan data, pada empat LRL.", 'mk': 'Мултијазичен неврален машински превод (MNMT) за јазици со ниски ресурси (LRL) може да се зголеми со присуството на поврзани јазици со високи ресурси (HRL), но поврзаноста на HRL обично се зависи од предефинирани јазички претпоставувања за јазичката сличност. Неодамна, адаптирањето на МНМТ на ЛРЛ покажа значително подобрување на резултатите. Во оваа работа, го истражуваме проблемот со адаптација на MNMT модел на невидлив LRL користејќи го изборот на податоци и адаптација на моделот. Со цел да го подобриме НМТ за ЛРЛ, употребуваме збунетост за да избереме податоци за ХРЛ кои се најслични на ЛРЛ на основа на јазичката дистанца. Ние екстремно истражуваме селекција на податоци во популарните мултијазични НМТ поставувања, имено во превод (нула снимка) и во адаптација од мултијазичен предобучен модел, за двете насоки (LRL en). Понатаму покажуваме дека динамичната адаптација на речникот на моделот резултира со поповолна сегментација за ЛРЛ во споредба со директната адаптација. Експериментите покажуваат редукции во времето на обука и значителни зголемувања на резултатите во врска со основните линии на ЛРЛ, дури и со нула податоци за ЛРЛ (+13,0 БЛЕ), до +17,0 БЛЕ за преобучено мултијазички модел динамично адаптација со поврзана избор на под Нашиот метод ги надминува актуелните пристапи, како што се масовните мултијазички модели и зголемување на податоците, на четири ЛРЛ.', 'ml': 'കുറഞ്ഞ വിഭവങ്ങളുടെ (LRL) ഭാഷകള്\u200dക്കായി പല ഭാഷ നെയുറല്\u200d മാഷീന്\u200d പരിഭാഷ (MNMT) കൂടുതല്\u200d മെച്ചപ്പെടുത്താന്\u200d സാധിക്കുന്നതാണു് (HRL), പക്ഷെ HRL-ന്റെ ബന്ധങ്ങള്\u200d സാധാരണയായി മുന അടുത്തിടെ എംഎംഎംഎലിലേക്ക് മാറ്റുന്നത് വളരെ മെച്ചപ്പെടുത്താന്\u200d കാണിച്ചിരിക്കുന്നു. ഈ ജോലിയില്\u200d, നമ്മള്\u200d ഒരു MNMT മോഡലിനെ ഒളിഞ്ഞ LRL-ലേക്ക് മാറ്റുന്നതിന്\u200dറെ പ്രശ്നം പരിശോധിക്കുന്നു. ഡേറ്റാ തെരഞ്ഞെട LRL-ന് NMT മെച്ചപ്പെടുത്താന്\u200d വേണ്ടി, LRL-നെപ്പോലെയാണ് ഏറ്റവും പോലെയുള്ള HRL വിവരങ്ങള്\u200d തെരഞ്ഞെടുക്കാന്\u200d ഞങ്ങള്\u200d പരിശോധത് പ്രധാനപ്പെട്ട പല ഭാഷയിലുള്ള NMT സജ്ജീകരണങ്ങളില്\u200d വിശാലമായ ഡേറ്റാ തെരഞ്ഞെടുക്കുന്നത് നമ്മള്\u200d പരിശോധിക്കുന്നു. അതായത് പൂര്\u200dണ്ണമായ (zero- shot) പരിഭാഷകളി നമ്മള്\u200d കൂടുതല്\u200d കാണിക്കുന്നുണ്ടെങ്കില്\u200d മോഡലിന്റെ വാക്കുപയോഗിക്കുന്നത് നേരിട്ട് നിര്\u200dത്തുന്നതിനെക്കുറിച്ച് LRL-ന് പരീക്ഷണങ്ങള്\u200d പരിശീലനത്തിന്റെ സമയത്തില്\u200d പുനര്\u200dജ്ജീകരണങ്ങള്\u200d കാണിക്കുന്നു. LRL ബെസ്ലൈനുകള്\u200dക്ക് പ്രധാനപ്പെട്ട പ്രകടനം ലഭ്യമാകുന്നു. LRL ഡേറ്റാ പൂജ്യം (+13. 0 ബെല്യൂ) ക നമ്മുടെ രീതിയില്\u200d ഇപ്പോഴത്തെ വഴികള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നത് നാല് എല്\u200dആര്\u200dഎലില്\u200d നിന്നും വളരെ അധികം പല ഭാഷ മോഡലുകളും ഡ', 'ka': 'მრავალენგიური ნეიროლური მაქსინის განსაგულაცია (MNMT) ცოტა რესურსის ენებისთვის (LRL) შეიძლება უფრო მეტივად შეიძლება გამოყენებული მეტი რესურსის ენებისთვის (HRL) გამოყენება, მაგრამ HRL-ის დაკავშირება სამუშ მხოლოდ, MNMT-ს LRL-ზე აეპორტირება მნიშვნელოვანია. ამ სამუშაოში, ჩვენ შევხედავთ პრობლემა, რომელიც MNMT მოდელის აეპორტირება, რომელიც არაჩვენებული LRL-ზე გამოყენებული მონაცემები და მოდელის აეპორტირება LRL-ის NMT-ის გასაკეთებლად, ჩვენ დავყენებთ HRL მონაცემებისთვის, რომლებიც ყველაზე მსგავსი LRL-ის განტოლება ენის განტოლებისთვის. ჩვენ ძალიან გავაკეთებთ მონაცემების არჩევა პოლუპური მულტილური NMT პარამეტრებში, ანუ (ნულ-სტარტი) გადაწყვეტში და მულტილური წინატარებული მოდელზე, ორივე მხარეს (LRL en). ჩვენ დავაჩვენებთ, რომ მოდელის სიტყვებულების დინამიკური ადაპტიფიკაცია უფრო მნიშვნელოვანი სეგმენტაციაში, რომელიც LRL-ს განმავლობაში პირადი ადაპტიკაციაზე Experiments show re-ductions in training time and significant performance gains over LRL baselines, even with zero LRL data (+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic adaptation with related data selection. ჩვენი მეთოდი გავაკეთებს მიმდინარე წარმოდგენების გარეშე, როგორც ძალიან მრავალენგური მოდელები და მონაცემების აზექტირება, 4 LRL-ზე.', 'no': 'Fleirspråk Neuralmaskinsomsetjing (MNMT) for låg ressursspråk (LRL) kan vera forbetra av tilhøyrande høg ressursspråk (HRL), men HRL-tilhøyrande tilhøyrande tilhøyrande tilhøyrande tilhøyrande tilhøyrande tilhøyrande tilhøyrande tilhøyrande språk er vanlegvis avhengig av føredefine Nyleg har MNMT tilpassa til ein LRL vist for å forbetra utviklinga. I dette arbeidet utforskar vi problemet med å tilpassa eit MNMT-modell til eit ukjent LRL med datautvalet og modell for tilpassing. For å forbetra NMT for LRL, bruker vi forskjellig for å velja HRL-data som er mest liknande til LRL på grunnlag av språkkavstanden. Vi utforskar utvalet av data i populære fleirspråk NMT-innstillingar, dvs. i (null-shot) omsetjinga, og i tilpassing frå ein fleirspråk før-trent modell for begge retningar (LRL en). Vi viser meir at dynamiske tilpassing av ordbokstaven i modellen resulterer i ein meir favoritt segmentasjon for LRL i sammenligning med direkte tilpassing. Eksperiment viser gjenopprettingar i treningstid og signifikante utviklingar over LRL-baselinjer, sjølv med null LRL-data (+13,0 BLEU), opp til +17,0 BLEU for dynamiske tilpassing av fleirspråk-modellen med relaterte datautval. Metoden vårt utfører gjeldande tilnærmingar, slik som massivt fleirspråk modeller og data augmentasjon, på fire LRL.', 'pl': 'Wielojęzyczne neuronowe tłumaczenie maszynowe (MNMT) dla języków niskich zasobów (LRL) może być zwiększone obecnością powiązanych języków o wysokich zasobach (HRL), ale związek HRL zazwyczaj opiera się na predefiniowanych założeniach językowych dotyczących podobieństwa językowego. Ostatnio dostosowanie MNMT do LRL wykazało znacznie poprawę wydajności. W niniejszej pracy badamy problem adaptacji modelu MNMT do niewidzialnego LRL za pomocą wyboru danych i adaptacji modelu. Aby poprawić NMT dla LRL, wykorzystujemy zdezorientowanie danych HRL, które są najbardziej podobne do LRL na podstawie odległości językowej. Szeroko badamy wybór danych w popularnych wielojęzycznych ustawieniach NMT, a mianowicie w tłumaczeniu (zero-shot) oraz w adaptacji z wielojęzycznego modelu wstępnie trenowanego, dla obu kierunków (LRL en). Ponadto pokazujemy, że dynamiczna adaptacja słownictwa modelu powoduje korzystniejszą segmentację dla LRL w porównaniu z adaptacją bezpośrednią. Eksperymenty wykazują zmiany czasu treningu i znaczące wzrosty wydajności w stosunku do linii bazowych LRL, nawet przy zerowych danych LRL (+13.0 BLEU), do +17.0 BLEU dla wstępnie przeszkolonych wielojęzycznych modeli dynamicznych z powiązanym wyborem danych. Nasza metoda przewyższa obecne podejścia, takie jak masowo wielojęzyczne modele i powiększanie danych, na czterech LRL.', 'ro': 'Traducerea automată neurală multilingvă (MNMT) pentru limbi cu resurse reduse (LRL) poate fi îmbunătățită prin prezența limbilor conexe cu resurse mari (HRL), dar relația HRL se bazează de obicei pe ipoteze lingvistice predefinite cu privire la similitudinea limbilor. Recent, adaptarea MNMT la un LRL a demonstrat că îmbunătățește foarte mult performanța. În această lucrare, explorăm problema adaptării unui model MNMT la un LRL nevăzut folosind selectarea datelor și adaptarea modelului. Pentru a îmbunătăți NMT pentru LRL, folosim perplexitate pentru a selecta date HRL care sunt cele mai similare cu LRL pe baza distanței lingvistice. Explorăm extensiv selecția datelor în setările NMT multilingve populare, și anume în traducere (zero-shot), și în adaptare dintr-un model multilingv pre-instruit, pentru ambele direcții (LRL en). De asemenea, demonstrăm că adaptarea dinamică a vocabularului modelului duce la o segmentare mai favorabilă pentru LRL în comparație cu adaptarea directă. Experimentele arată reduceri ale timpului de antrenament și câștiguri semnificative de performanță față de liniile de bază LRL, chiar și cu zero date LRL (+13,0 BLEU), până la +17,0 BLEU pentru adaptarea dinamică a modelului multilingv pre-instruit cu selecția datelor aferente. Metoda noastră depășește abordările actuale, cum ar fi modelele multilingve masive și mărirea datelor, pe patru LRL.', 'mn': 'Олон хэлний мэдрэлийн машины хөгжүүлэлт (MNMT) бага боловсруулагч хэл (LRL) болон хамааралтай өндөр боловсруулагч хэл (HRL) байдаг гэхдээ HRL-ын хамаарал ихэвчлэн хэлний төстэй талаар илүү тодорхойлдог хэлний төлөвлөгөөс хамаарна. Саяхан MNMT-г LRL-д зохицуулах нь үйл ажиллагааг маш сайжруулж байна. Энэ ажил дээр бид MNMT загварыг мэдээллийн сонголт болон загварын адаптацийг ашиглан харагдаагүй LRL-д загварчлах асуудлыг судалж байна. LRL-ийн NMT-г сайжруулахын тулд бид хэлний зай дээр хамгийн ижил LRL-тэй төстэй HRL-г сонгох боломжтой байдлыг ашигладаг. Бид олон хэлний NMT хэлбэрээр өгөгдлийн сонголтыг олон судалгаа судалж, тэр хэлний аль хэлний сургалтын загвараас хоёр талаар (LRL en) хөрөнгө оруулалт хийсэн. Бид дараа нь загварын үгийн динамик загварын өөрчлөлт нь LRL-ын шууд загвартай харьцуулахад илүү ашигтай загварын үр дүнг харуулж байна. Түүний туршилт LRL сургалтын цаг хугацаанд дахин дахин давтагдсан болон хамааралтай өгөгдлийн сонголттай олон хэлний загварын динамик загварын давхарлалтын тулд +17.0 BLEU хүртэл ашиглаж байна. Бидний арга нь одоогийн ойлголтыг олон хэл загвар, өгөгдлийн нэмэгдүүлэлтийг дөрвөн ЛРЛ дээр гаргадаг.', 'so': 'Turjumidda luuqadaha hoose-resource (MNMT) ee luuqadaha koowaad (LRL) waxaa lagu kordhin karaa horumarinta luuqadaha aad u xidhiidha luqadaha rasmiga ah (HRL), laakiin xiriirka HRL inta badan wuxuu ku xiran karaa malayaasha afka hore oo ku saabsan isku mid ah. Mudankii ugu dhowaaday, in MNMT la beddelo LRL uu muujiyey in aad u hagaajiyo tababarka. Shaqadan, waxaynu baarinaynaa dhibaatada ku bedelashada model MNMT oo aan qarsoonayn LRL lagu isticmaalo doorasho macluumaad iyo model adapta. Si aan u hagaajino NMT ee LRL, waxaynu u shaqaynaynaa dhibaato si aan u doorno data HRL oo ugu eg LRL oo ku saleysan dhegta luqada. Waxaan si dheer u baaraynaa doorasho macluumaad ah oo ku qoran qorshaha qoraalka afka kala duduwan ee NMT, kuwaas oo ah turjumidda (zero-shot) iyo tilmaamaha qoraalka hore oo luuqadaha badan, labada hagitaan (LRL en). Sidoo kale waxaan tusnaynaa in beddelka hadalka midowga ah uu sababto qayb ka wanaagsan oo u eg LRL si toos u beddelan. Imtixaanka waxaa ka muuqda dib-u-qabsashada wakhtiga waxbarashada iyo waxyaabaha muhiimka ah oo ka kordhaya qorshaha LRL, xataa zero LRL data (+13.0 BLEU), ilaa +17.0 BLEU, si uu u beddelo model mulki-luuqad ah oo u horeeyo bedelka bedelka bedelka oo ku saabsan doorashada data. Midabkayaga ayaa soo saara qaabab hada ah, tusaale ahaan qaabab badan oo luuqado kala duduwan iyo kordhiska macluumaadka afarta LRL.', 'si': 'Multilanguage neural machine translation (MNMT) for low- source language (LRL) can be improvised by the presence of high-source language (HRL), but the erltedness of HRL is generous on pre-determined language assumption on language comparity. අලුත් වෙලාවට, MNMT එක LRL එකට ඇතුළත් කරන්න පෙන්වන්නේ ගොඩක් වැඩි වැඩ කරන්න. මේ වැඩේ අපි MNMT මෝඩල් එකක් අදහස් වෙන්න ප්\u200dරශ්නයක් පරීක්ෂා කරනවා දත්ත තෝරණය සහ මන්ඩල් අනුමාණය සඳහා අනුමාණ LRL වෙනුවෙන් NMT වැඩ කරන්න, අපි HRL දත්ත තෝරාගන්න සම්පූර්ණතාවක් භාෂාව අධාරිතයෙන් LRL වෙනුවෙන් වඩා වර්ගයි. අපි ලොකු භාෂාවික NMT සැකසුම් වලට දත්ත තෝරණය පරීක්ෂා කරනවා, අනිවාර්ය (0-shot) පරීක්ෂණය සහ ගොඩක් භාෂාවික ප්\u200dරීක්ෂණය කරලා තියෙ අපි තවත් පෙන්වන්නේ මොඩේල්ගේ භාෂාවාදයේ වාර්ථාවික සැකසුම් වලට LRL වෙනුවෙන් වැඩිය ප්\u200dරයෝජනයක් ප්\u200dරතිච පරීක්ෂණය පෙන්වන්න පුළුවන් වෙලාවේ ප්\u200dරීක්ෂණා වෙලාවේ ප්\u200dරශ්නයක් සහ වැදගත් ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙනවා LRL ප්\u200dරශ්නයක් වලින්, සම්බන් අපේ විද්\u200dයාව ප්\u200dරසිද්ධ විදිහට ප්\u200dරසිද්ධ විදිහට ප්\u200dරසිද්ධ වෙන්න පුළුවන්, හරියට වැඩි භාෂාවික මොඩේ', 'sv': 'Multilingual Neural Machine Translation (MNMT) för lågresursspråk (LRL) kan förbättras genom närvaron av relaterade högresursspråk (HRL), men förhållandet mellan HRL beror vanligtvis på fördefinierade språkliga antaganden om språklikhet. Nyligen har anpassningen av MNMT till en LRL visat sig avsevärt förbättra prestandan. I detta arbete undersöker vi problemet med att anpassa en MNMT-modell till en osynlig LRL med hjälp av dataval och modellanpassning. För att förbättra NMT för LRL använder vi förvirring för att välja HRL-data som liknar LRL mest på grundval av språkavstånd. Vi undersöker i stor utsträckning dataval i populära flerspråkiga NMT-inställningar, nämligen i (noll-shot) översättning, och i anpassning från en flerspråkig pre-utbildad modell, för båda riktningarna (LRL en). Vi visar vidare att dynamisk anpassning av modellens vokabulär resulterar i en mer gynnsam segmentering för LRL jämfört med direkt anpassning. Experiment visar på minskningar i träningstid och signifikanta prestationsvinster jämfört med LRL-baselines, även med noll LRL-data (+13,0 BLEU), upp till +17,0 BLEU för färdigutbildad flerspråkig modelldynamisk anpassning med tillhörande dataval. Vår metod överträffar nuvarande metoder, såsom massivt flerspråkiga modeller och dataökning, på fyra LRL.', 'mt': 'Multilingual Neural Machine Translation (MNMT) for low- resource languages (LRL) can be enhanced by the presence of related high-resource languages (HRL), but the relatedness of HRL usually relies on predefined linguistic assumptions about language similarity.  Recently, adapting MNMT to a LRL has shown to greatly improve performance.  F’din il-ħidma, nistudjaw il-problema ta’ l-adattament ta’ mudell MNMT għal LRL mhux osservat bl-użu ta’ l-għażla tad-dejta u l-adattament tal-mudell. In order to improve NMT for LRL, we employ perplexity to select HRL data that are most similar to the LRL on the basis of language distance.  Aħna nesploraw b’mod estensiv l-għa żla tad-dejta f’ambjenti popolari multilingwi tal-NMT, jiġifieri fit-traduzzjoni (zero-shot), u f’adattament minn mudell multilingwi mħarreġ minn qabel, għaż-żewġ direzzjonijiet (LRL en). Aħna nuru wkoll li l-adattament dinamiku tal-vokabulari tal-mudell jirriżulta f’segmentazzjoni aktar favorevoli għall-LRL meta mqabbel mal-adattament dirett. L-esperimenti juru tnaqqis fil-ħin tat-taħriġ u kisbiet sinifikanti fil-prestazzjoni fuq il-linji bażi tal-LRL, anki b’dejta żero tal-LRL (+13.0 BLEU), sa +17.0 BLEU għal adattament dinamiku tal-mudell multilingwi mħarreġ minn qabel b’għażla relatata tad-dejta. Il-metodu tagħna jaqbeż l-approċċi attwali, bħal mudelli multilingwi massivi u żieda fid-dejta, fuq erba’ LRL.', 'ur': 'بہت سی زبان کی نیورال ماشین ترجمہ (MNMT) کم منبع زبانوں کے لئے (LRL) اچھی منبع زبانوں کی موجودگی سے زیادہ زیادہ کر سکتی ہے، لیکن HRL کی ارتباط معمولاً زبان مثالی کے بارے میں پہلے مقرر کی زبان مثالیں پر باقی رہتی ہے. اچھا، MNMT کو LRL کے ساتھ اضافہ کرنا بہت اضافہ کرتا ہے۔ اس کام میں ہم نے MNMT موڈل کو غیر مشاهده LRL کے مطابق ڈیٹ انتخاب اور موڈل اڈپٹ-ٹ کے مطابق مطابق کرنے کے مسئلہ کو دیکھا ہے. LRL کے لئے NMT کو بہتر کرنے کے لئے، ہم HRL ڈاکٹوں کو انتخاب کرنے کے لئے غلط استعمال کرتے ہیں جو زبان فاصلہ پر LRL کے زیادہ برابر ہیں. ہم بہت سی زبان مزید زبان NMT سیٹیوں میں ڈیٹا انتخاب کرنے کے لئے اضافہ کرتے ہیں، یعنی (صفر-شٹ) ترجمہ میں، اور ایک multilingual pre-trained model (LRL en) سے اضافہ کرنے کے لئے۔ ہم اس کے علاوہ دکھاتے ہیں کہ موڈل کی آواز شناسی کی سیمالیک اضافہ کا نتیجہ LRL کے لئے مستقیم اضافہ کے مقابلہ میں زیادہ مہربانی سقم میں ہے. تجربے کی تدریس زمان میں دوبارہ دکھاتے ہیں اور لرل بنیس لینٹوں پر اثر اثر حاصل کرتی ہیں، حتی لرل ڈیٹا (+13.0 BLEU) کے ساتھ +17.0 BLEU تک پہلے تدریس کی ملتی زبان کی موڈل ڈینامیک اثرات کے لئے۔ ہمارا طریقہ چار LRL پر موجود طریقے سے زیادہ اجرا کرتا ہے، جیسے بہت سی زبان مدل اور ڈیٹا اضافہ کرتا ہے.', 'sr': 'Mnogjezički Neuralni prevod mašine (MNMT) za jezike niskih resursa (LRL) može biti poboljšan prisustvom povezanih jezika visokih resursa (HRL), ali povezanost HRL obično oslanja na predodređene jezičke pretpostavke o sličnosti jezika. Nedavno je prilagođenje MNMT-a na LRL pokazalo da je veoma poboljšavanje funkcije. U ovom poslu istražujemo problem prilagođenja modela MNMT-a nevidljivom LRL koristeći izbor podataka i model adaptacije. Da bismo poboljšali NMT za LRL, upotrebljavali smo perpleksitet da izaberemo HRL podatke koje su najsličnije LRL na osnovu jezičke udaljenosti. Prošireno istražujemo selekciju podataka u popularnim multijezičkim postavljanjima NMT-a, a to je u (nul-shot) prevodu, i u adaptaciji iz multijezičkog predobučenog modela, za oba smjera (LRL en). Dalje pokazujemo da dinamična adaptacija rečnika model a rezultuje u boljim segmentacijama za LRL u usporedbi sa direktnom adaptacijom. Eksperimenti pokazuju revakcije u vreme obuke i značajne dobitke učinkovitosti iznad početnih linija LRL, čak i sa nulom podacima LRL (+13,0 BLEU), do +17,0 BLEU za predobučenu dinamičnu adaptaciju multijezičkog modela s povezanim selekcijom podataka. Naša metoda iznosi trenutne pristupe, poput masivnih multijezičkih modela i povećanja podataka, na četiri LRL.', 'ta': 'Name Recently, adapting MNMT to a LRL has shown to greatly improve performance.  இந்த வேலையில், நாம் ஒரு MNMT மாதிரியை மறைக்கப்படாத LRL மாதிரியும் பிரச்சினையை தேர்ந்தெடுத்து தரவு தேர்வு மற்றும் ம LRL க்கான NMT மேம்படுத்த வேண்டுமானால், மொழி தூரத்தை அடிப்படையில் HRL தரவை தேர்ந்தெடுக்க HRL தகவல்களை தேர்ந்தெடுக்க நாம் ச பிரபல மொழி NMT அமைப்புகளில் நாம் தரவு தேர்வை விரிவாக தேர்வு செய்கிறோம், அதாவது (பூஜ்ஜியம்) மொழிமாற்றில், மேலும் பல மொழி முன்பயிற்சி மாதிரியிலிரு நாம் மாதிரியின் சொல்வளத்தின் ஒழுங்குப்பொருட்களை மேலும் காட்டுகிறோம் என்றால் நேரான ஒழுங்குப்பொருட்டு LRL க்கு மேலு பரிசோதனைகள் பயிற்சி நேரத்தில் மற்றும் முக்கியமான செயல்பாடு LRL அடிப்படைகளில் வெற்றி பெறுகிறது, பூஜ்ஜியமாக LRL data (+13. 0 BLEU) கூட, முன்பயிற்சிக்கப்பட்ட பல மொழி மாதிரி மாத எங்கள் முறைமை நான்கு LRL மேல் நடப்பு முறைகளை வெளியேற்றுகிறது, அதாவது பல மொழி மாதிரிகள் மற்றும் தரவு மேம்படுத்தல்.', 'uz': "Name Yaqinda MNMT'ni LRL'ga oʻzgartirish imkoniyatini juda yaxshi ko'rsatadi. In this work, we explore the problem of adapting an MNMT model to an unseen LRL using data selection and model adapta- tion.  @ info Biz ko'plab tili NMT moslamalarida maʼlumot tanlashni aniqlamiz, bu tildan bir necha tildan foydalanadigan tarjima qilamiz, va bir necha tildan oldin foydalanilgan modeldan o'zgartirish uchun (LRL en). Ko'rib chiqqamiz, modelning vositalarning dynamic adaptation resultini LRL'ning soʻzlariga ko'rsatish uchun yaxshi bo'lishi mumkin. Name Бизнинг усулимиз ҳозирги усулларни тўртта LRL томонидан кўриб чиқади.", 'vi': 'Dịch đa ngôn ngữ thần kinh (MX) cho ngôn ngữ thấp nguồn (LL) có thể tăng cường nhờ có các ngôn ngữ cao chất liên quan (HRL) nhưng liên hệ với HRL thường dựa trên định nghĩa ngôn ngữ khác nhau được xác định trước về khả năng chung ngôn ngữ. Gần đây, việc sửa MX cho một con LR đã cho thấy hiệu quả tăng đáng kể. Trong công việc này, chúng ta sẽ tìm hiểu vấn đề sửa đổi mô hình MPT đến một loại LR vô hình. Dùng cách chọn dữ liệu và sửa mô hình. Để cải thiện NMT cho LL, chúng tôi dùng sự phức tạp để chọn những dữ liệu HRL gần nhất với LAL dựa trên độ xa ngôn ngữ. Chúng tôi tìm hiểu sâu về việc chọn dữ liệu trong thiết lập NMT nổi tiếng, cụ thể trong dịch (không bắn) và trong sửa đổi từ mô hình đã được huấn luyện nhiều loại, cho cả hai hướng (LL en). Chúng tôi cũng cho thấy s ự thích nghi từ vựng động động sẽ tạo ra một phân chia cho LL thuận lợi hơn so với thích ứng trực tiếp. Các thí nghiệm cho thấy có nhiều sản xuất trong thời gian huấn luyện và hiệu suất tăng đáng kể trên các đường hầm LL, thậm chí bằng không dữ liệu LL (+13.0 tạo tự động) cho đến (+17.0 lgU) cho mô- loa đa dạng đã được đào tạo theo tỷ lệ phụ thuộc với sự lựa chọn dữ liệu liên quan. Cách của chúng tôi vượt trội các phương pháp hiện tại, như các mô- đun đa dạng rộng lớn và gia tăng dữ liệu, trên bốn cột sống.', 'bg': 'Многоезичният неврален машинен превод (MNMT) за езици с нисък ресурс (LRL) може да бъде подобрен чрез наличието на свързани езици с висок ресурс (HRL), но връзката на HRL обикновено разчита на предварително определени езикови предположения за езиковата сходство. Наскоро адаптирането на MNMT към LRL показа значително подобряване на производителността. В тази работа изследваме проблема за адаптирането на модел към невидим ЛРЛ, използвайки избор на данни и адаптация на модела. За да подобрим НМТ за ЛРЛ, използваме объркване, за да изберем данни за ЛРЛ, които са най-подобни на ЛРЛ въз основа на езиковото разстояние. Изследваме обстойно подбора на данни в популярни многоезични настройки на НМТ, а именно в (нулев) превод и адаптация от многоезичен предварително обучен модел, за двете посоки. Освен това показваме, че динамичната адаптация на речника на модела води до по-благоприятна сегментация за ЛРЛ в сравнение с директната адаптация. Експериментите показват повторение на времето за обучение и значително повишаване на производителността спрямо базовите линии на ЛРЛ, дори при нулеви данни за ЛРЛ (+13.0 BLU), до +17.0 BLU за предварително обучена многоезична динамична адаптация на модела със съответния подбор на данни. Нашият метод превъзхожда настоящите подходи, като масово многоезични модели и увеличаване на данните, на четири ЛРЛ.', 'hr': 'Mnogjezički Neuralni prevod uređaja (MNMT) za jezike niskih resursa (LRL) može se poboljšati prisustvom povezanih jezika visokih resursa (HRL), ali povezanost HRL obično oslanja na predodređene jezičke pretpostavke o sličnosti jezika. Nedavno je prilagođenje MNMT-a na LRL pokazalo da je veoma poboljšanje učinka. U ovom poslu istražujemo problem prilagođenja modela MNMT-a nevidljivom LRL koristeći izbor podataka i model prilagođenja. Da bismo poboljšali NMT za LRL, upotrebljavali smo neprijatnost da izaberemo HRL podatke koje su najsličnije LRL na temelju jezičke udaljenosti. Prošireno istražujemo izbor podataka u popularnim multijezičkim postavljanjima NMT-a, a to je u (nul-shot) prevodu i prilagodbi iz multijezičkog predobučenog modela, za oba smjera (LRL en). Dalje pokazujemo da dinamična adaptacija rečnika model a rezultira u boljivom segmentaciji za LRL u usporedbi s direktnom adaptacijom. Eksperimenti pokazuju ponovne akcije u vrijeme obuke i značajne dobitke učinkovitosti iznad početnih linija LRL-a, čak i sa nulom podacima LRL-a (+13,0 BLEU), do +17,0 BLEU za predobučenu dinamičku adaptaciju multijezičkog modela s povezanim selekcijom podataka. Naša metoda iznosi trenutne pristupe, poput masivnih multijezičkih modela i povećanja podataka, na četiri LRL.', 'nl': "Multilingual Neural Machine Translation (MNMT) voor low-resource talen (LRL) kan worden verbeterd door de aanwezigheid van verwante high-resource talen (HRL), maar de verwantschap van HRL berust meestal op vooraf gedefinieerde linguïstische veronderstellingen over taalgelijkenis. Onlangs heeft het aanpassen van MNMT aan een LRL aangetoond de prestaties aanzienlijk te verbeteren. In dit werk onderzoeken we het probleem van het aanpassen van een MNMT model aan een onzichtbare LRL met behulp van data selectie en model aanpassing. Om NMT voor LRL te verbeteren, gebruiken we verwarring om HRL-gegevens te selecteren die het meest lijken op de LRL op basis van taalafstand. We onderzoeken uitvoerig data selectie in populaire meertalige NMT settings, namelijk in (zero-shot) vertaling, en in aanpassing van een meertalig voorgetraind model, voor beide richtingen (LRL en). Verder tonen we aan dat dynamische aanpassing van de woordenschat van het model resulteert in een gunstigere segmentatie voor de LRL in vergelijking met directe aanpassing. Experimenten tonen veranderingen in trainingstijd en significante prestatiewinsten ten opzichte van LRL baselines, zelfs met nul LRL data (+13.0 BLEU), tot +17.0 BLEU voor voorgetrainde meertalige model dynamische aanpassing met gerelateerde gegevensselectie. Onze methode overtreft de huidige benaderingen, zoals massaal meertalige modellen en data augmentatie, op vier LRL's.", 'da': 'Multilingual Neural Machine Translation (MNMT) for low-resource sprog (LRL) kan forbedres ved tilstedeværelsen af relaterede high-resource sprog (HRL), men forholdet mellem HRL afhænger normalt af foruddefinerede sproglige antagelser om sproglighed. For nylig har tilpasningen af MNMT til en LRL vist sig at forbedre ydeevnen betydeligt. I dette arbejde undersøger vi problemet med at tilpasse en MNMT-model til en usynlig LRL ved hjælp af datavalg og model tilpasning. For at forbedre NMT for LRL anvender vi forvirring til at vælge HRL data, der ligner mest LRL på grundlag af sprogafstand. Vi undersøger udførligt datavalg i populære flersprogede NMT-indstillinger, nemlig i (zero-shot) oversættelse, og i tilpasning fra en flersproget prætrænet model, for begge retninger (LRL en). Vi viser endvidere, at dynamisk tilpasning af modellens ordforråd resulterer i en mere gunstig segmentering for LRL sammenlignet med direkte tilpasning. Eksperimenter viser reduktioner i træningstiden og betydelige præstationsgevinster i forhold til LRL baselines, selv med nul LRL data (+13,0 BLEU), op til +17,0 BLEU for prætrænet flersproget model dynamisk tilpasning med relateret datavalg. Vores metode overgår nuværende tilgange, såsom massivt flersprogede modeller og data augmentation, på fire LRL.', 'id': 'Multilingual Neural Machine Translation (MNMT) untuk bahasa sumber daya rendah (LRL) dapat diperbaiki oleh kehadiran bahasa sumber daya tinggi yang berhubungan (HRL), tetapi hubungan HRL biasanya bergantung pada asumsi bahasa terdefinisi tentang persamaan bahasa. Baru-baru ini, mengadaptasi MNMT ke LRL telah menunjukkan untuk meningkatkan prestasi. Dalam pekerjaan ini, kami mengeksplorasi masalah adaptasi model MNMT ke LRL yang tidak terlihat menggunakan pemilihan data dan adaptasi model. Untuk meningkatkan NMT untuk LRL, kami menggunakan kekacauan untuk memilih data HRL yang paling mirip dengan LRL pada dasar jarak bahasa. Kami secara ekstensif mengeksplorasi seleksi data dalam pengaturan NMT multibahasa populer, yaitu dalam terjemahan (zero-shot), dan dalam adaptasi dari model pre-terlatih multibahasa, untuk kedua arah (LRL en). Kami lebih lanjut menunjukkan bahwa adaptasi dinamik dari vokabular model menghasilkan segmentasi yang lebih baik untuk LRL dibandingkan dengan adaptasi langsung. Eksperimen menunjukkan reduksi dalam waktu latihan dan peningkatan prestasi yang signifikan di atas garis dasar LRL, bahkan dengan nol data LRL (+13.0 BLEU), hingga +17.0 BLEU untuk adaptasi dinamik model multibahasa terlatih dengan seleksi data berkaitan. Metode kita melebihi pendekatan saat ini, seperti model multibahasa besar dan peningkatan data, pada empat LRL.', 'de': 'Multilingual Neural Machine Translation (MNMT) für Low-Resource Languages (LRL) kann durch das Vorhandensein verwandter High-Resource Languages (HRL) verbessert werden, aber die Verwandtschaft von HRL beruht in der Regel auf vordefinierten linguistischen Annahmen über Sprachähnlichkeit. In letzter Zeit hat sich gezeigt, dass die Anpassung von MNMT an eine LRL die Leistung erheblich verbessert. In dieser Arbeit untersuchen wir das Problem der Anpassung eines MNMT-Modells an eine unsichtbare LRL mittels Datenauswahl und Modellanpassung. Um NMT für LRL zu verbessern, verwenden wir Ratlosigkeit, um HRL-Daten auszuwählen, die den LRL am ähnlichsten sind, basierend auf der Sprachdistanz. Wir untersuchen ausführlich die Datenauswahl in gängigen mehrsprachigen NMT-Einstellungen, nämlich in (Zero-Shot) Übersetzung, und in Adaption aus einem mehrsprachigen vortrainierten Modell, für beide Richtungen (LRL en). Weiterhin zeigen wir, dass die dynamische Anpassung des Modellvokabulars zu einer günstigeren Segmentierung für die LRL im Vergleich zur direkten Anpassung führt. Experimente zeigten Reduktionen der Trainingszeit und signifikante Leistungszuwächse gegenüber LRL-Baselines, selbst bei null LRL-Daten (+13.0 BLEU), bis +17.0 BLEU für vortrainierte mehrsprachige Modelldynamik-Adaption mit zugehöriger Datenauswahl. Unsere Methode übertrifft aktuelle Ansätze, wie massiv mehrsprachige Modelle und Datenaugmentation, auf vier LRL.', 'ko': '저자원언어(LRL)의 다국어 신경기계번역(MNMT)은 관련 고자원언어(HRL)의 존재를 통해 강화할 수 있지만, HRL의 관련성은 일반적으로 미리 정의된 언어 유사성 가설에 의존한다.최근 MNMT를 LRL에 적용한 것은 성능을 크게 향상시킬 수 있다는 것을 증명했다.이 작업에서 우리는 데이터 선택과 모델 조정을 통해 MNMT 모델을 보이지 않는 LRL로 조정하는 방법을 모색했다.LRL의 NMT를 높이기 위해 우리는 곤혹도를 이용하여 언어 거리에 따라 LRL과 가장 비슷한 HRL 데이터를 선택한다.우리는 유행하는 다중 언어 NMT 설정에서의 데이터 선택, 즉 (제로 렌즈) 번역, 그리고 다중 언어 예비 훈련 모델에서 개편된 양방향 데이터 선택(LRL-en)을 광범위하게 연구했다.우리는 직접적 적응에 비해 모델 어휘의 동태적 적응이 LRL에 더욱 유리한 구분을 가져왔다는 것을 한층 더 밝혔다.실험에 따르면 LRL 기선에 비해 훈련 시간이 단축되고 성능이 현저히 향상된 것으로 나타났다. LRL 데이터가 0(+13.0 BLEU)이라도 미리 훈련된 다국어 모델의 동적 적응과 관련 데이터 선택에 대해 BLEU는 +17.0 BLEU에 달한다.네 가지 LRL에서 우리의 방법은 현재의 방법보다 우수하다. 예를 들어 대규모 다국어 모델과 데이터 확장이다.', 'af': "Veelvuldige Neurale Masjien Vertaling (MNMT) vir lae- hulpbron tale (LRL) kan deur die voorsiening van verwante hoë- hulpbron tale (HRL) verbeter word, maar die verwantigheid van HRL is gewoonlik op vooraf definieerde lingvisiese voorstellings oor taal gelykenis. Onlangs het die aanpassing van MNMT na 'n LRL vertoon om baie verbeter te maak. In hierdie werk, ons ondersoek die probleem van aanpassing van 'n MNMT model na' n ongesien LRL met gebruik van data keuse en model adapta- tion. In order to improve NMT for LRL, we employ perplexity to select HRL data that are most similar to the LRL on the basis of language distance. Ons uitbreidig uitsoek data keuse in populêre multitaalske NMT-instellings, bedoel in (nul-skoot) vertaling en in aanpassing van 'n multitaalske vooraf-onderwerp model, vir beide rigtings (LRL en). Ons vertoon verder dat dinamiese aanpassing van die model se woordeboek resultaat in 'n meer gunstige segmentasie vir die LRL in vergelyking met direk aanpassing. Eksperimente vertoon weer- ductions in oefening tyd en betekende funksie verskaffings oor LRL basisline, selfs met nul LRL data (+13. 0 BLEU), tot by +17. 0 BLEU vir vooraf- oefen multilinglike model dinamike aanpassing met verwante data keuse. Ons metode uitvoer huidige toegang, soos massief multilinglike modele en data augmentasie, op vier LRL.", 'fa': 'ترجمه ماشین عصبی چندین زبان (MNMT) برای زبان\u200cهای کم منبع (LRL) می\u200cتواند با وجود زبان\u200cهای منبع بالا (HRL) بیشتر شود، ولی ارتباط HRL معمولاً بر فرضیه\u200cهای زبان\u200cشناسی پیش\u200cفرض در مورد شبیه زبان\u200cشناسی بستگی دارد. اخیراً اضافه کردن MNMT به یک LRL نشان داده است که عملکرد بسیار بهتر شده است. در این کار، ما مشکل تغییر دادن یک مدل MNMT را با استفاده از انتخاب داده\u200cها و مدل تغییر داده\u200cها تحقیق می\u200cکنیم. برای بهتر کردن NMT برای LRL، برای انتخاب داده های HRL که بیشتر شبیه LRL بر اساس فاصله زبان هستند استفاده می کنیم. ما به وسیله انتخاب داده\u200cها در تنظیمات NMT زیادی زبان مشهور تحقیق می\u200cکنیم، یعنی در (صفر) ترجمه، و در تغییر از یک مدل پیش آموزش\u200cهای زیادی زبان، برای هر دو راهی (LRL en). ما به بعد نشان می دهیم که تغییرات دینامیک کلمات مدل نتیجه\u200cهای یک قسمت مناسب\u200cتر برای LRL در مقایسه با تغییرات مستقیم است. تجربه\u200cها در زمان آموزش و ارائه عملکرد مهم بر خط\u200cهای بنیادی LRL، حتی با داده\u200cهای LRL صفر (+13.0 BLEU) تا +17.0 BLEU برای تغییر\u200cآموزش مدل چندین زبانی پیش آموزش داده شده با انتخاب داده\u200cهای ارتباط، نشان می\u200cدهند. روش ما به عنوان مدل های زیادی زبان و افزایش داده ها در چهار LRL بیشتر از دسترسی های فعلی انجام می دهد.', 'tr': "Köp dilli Neural Maşynyň terjimesi (MNMT) düşük resurslar dilleri (LRL) üçin bilim ýokary resurslar dili (HRL) bilen gelişýär ýöne, ýöne HRL'iň golaýaty adatça diller ýaly görünýär barada öň bellenen diller barada ynanýar. Soňky wagtlar, MNMT'i LRL'a üýtgetmek ukyplary has gowurak görkezildi. Bu işde, biz MNMT modelini görünmemeýän LRL'e golaýlamak üçin problemini keşif edip duruyoruz. NMT üçin LRL üçin gelişmek üçin, HRL maglumaty üçin iň ýakyn LRL maglumaty dil aralygyna görä tertiblenmek üçin bir sarhoş işleýäris. Biz eýleki köp dilli NMT düzümlerinde maglumat saýlawyny ekleýän, hemişe-de (zero-shot) terjimelerinde we öňki dilli öňki bilim taýýarlanmasynda (LRL en). Biz nusganyň s özleriniň dinamik adaptasiýasynyň netijesini LRL'iň derejesi adaptasiýasy bilen görä has gowy bir segmentasyýany görkezýäris. Denminatlar LRL baz hatlaryň üstünde ýene-täzelikleri we möhüm kanunlaryň üstüne ýene-täzeliklerini görkezýär (+13.0 BLEU) we şu şekilde +17.0 BLEU-a gollanan ýagdaýda öň-täzelikli multi diller modi dinamik adaptasyýasy bilen tanyşdyrylýar. Biziň ýagdaýymyz häzirki ýagdaýlaryň çykyşyny dört LRL üstünde çykýar.", 'sw': 'Tafsiri ya Mashine ya Kifaragha (MNMT) kwa lugha ndogo ya rasilimali (LRL) inaweza kuongezwa na uwepo wa lugha zinazohusiana na rasilimali za juu (HRL), lakini uhusiano wa HRL mara nyingi hutegemea dhana za lugha zilizotanguliwa kuhusu usawa wa lugha. Hivi karibuni, kubadilisha MNMT kwa LRL imeonyesha kuboresha utendaji. Katika kazi hii, tunagundua tatizo la kubadilisha muundo wa MNMT kwa LRL asiyejulikana kwa kutumia uchaguzi wa data na upatikanaji wa mifano. Ili kuboresha NMT kwa LRL, tunatumia utata wa kuchagua data za HRL ambazo zinafanana zaidi na LRL kwa kiwango cha lugha. Tunafanya uchaguzi wa data kwa kiasi kikubwa katika mazingira maarufu ya lugha za NMT, yaani katika tafsiri (picha sifuri) na katika kuboresha kwa mtindo wa mafunzo ya lugha nyingine, kwa njia zote (LRL en). Tunaonyesha zaidi kuwa mabadiliko ya maneno ya mtindo huo yanasababisha mgawanyiko bora zaidi kwa LRL ukilinganisha na kuboresha kwa moja. Majaribio yanaonyesha shughuli za upya katika wakati wa mafunzo na utendaji wa ufanisi wa muhimu unapata zaidi ya misingi ya LRL, hata kwa data zero za LRL (+13.0 BLEU), hadi +17.0 BLEU kwa ajili ya kubadilishana kwa modeli ya lugha za awali yenye utaratibu wa taarifa zinazohusiana. Utawala wetu unaonyesha mbinu za sasa, kama vile mifano ya lugha mbalimbali na kuongezeka kwa takwimu, katika nchi nne za LRL.', 'am': 'የብዙ ቋንቋዎች የኔural machine ትርጓሜ (MNMT) ለlow-resource ቋንቋዎች (LRL) በተቃራረበ ከፍተኛ-resource ቋንቋዎች (HRL) ሊበረታ ይችላል፤ ነገር ግን የHRL ግንኙነት በተቀድሞ በቋንቋ ብጤት ላይ በተመሳሳይ ቋንቋ ይታያል። በቅርብ ጊዜ MNMT ወደ LRL በመጠቀም የራሳቸውን ትክክል ማድረግ አሳየ፡፡ በዚህ ስራ ውስጥ የMNMT ሞዴል በመቀበል እና የዳታ ምርጫ እና ሞዴል አዲፕታ በመጠቀም የደረሰውን LRL ማቀናቀል መከራን እንፈልጋለን፡፡ LRL ለማሻሻል፣ LRL በመስመር ቋንቋ ርቀት ላይ በተመሳሳይ HRL ዳታዎችን ለመምረጥ እናስቸጋጅላለን፡፡ We extensively explore data selection in popular multilingual NMT settings, namely in (zero-shot) translation, and in adaptation from a multilingual pre-trained model, for both directions (LRL en).  እናሳየዋለን የሞዴል ቃላት አካባቢ አካባቢ እንዲያሳየው የLRL አካባቢ አካባቢ እንዲያሳየው፡፡ ፈተናዎች የልዩ ቋንቋ ሞዴል እና አካባቢ የLRL መቀመጫዎች ላይ አግኝቷል፡፡ ዘዴያችን በአራቱ LRL ላይ ብዙ ቋንቋዎች እና ዳታ አጨማሪነቱን የሚያደርግ የአሁኑን ደረጃዎች ያሳያል፡፡', 'hy': 'Նյարդային մեքենայի բազմալեզու թարգմանություն (MNMT) ցածր ռեսուրսների լեզուների համար կարող է բարելավվել կապված բարձր ռեսուրսների լեզուների (HRL) գոյության միջոցով, բայց HRL-ի կապը սովորաբար հիմնված է նախասահմանված լեզվաբանական ենթադրությունների լեզվի նմանության մասին: Վերջերս MNMT-ի հարմարվելը LRL-ին ցույց է տալիս, որ շատ բարելավում է արդյունքները: Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք MNMT մոդելի ադապտացիայի խնդիրը անտեսանելի LRL-ի հետ օգտագործելով տվյալների ընտրությունը և մոդելի ադապտացիան: LRL-ի NMT-ը բարելավելու համար մենք օգտագործում ենք խառնաշփոթ HRL-ի տվյալներ ընտրելու համար, որոնք ամենաշատ նման են LRL-ին լեզվի հեռավորության հիմքում: Մենք էքսպենսիվ ուսումնասիրում ենք տվյալների ընտրությունը բազմալեզու NMT-ի համակարգերում, հատկապես (զրո-նկարների) թարգմանման և բազմալեզու նախապատրաստված մոդելի ադապտացիայի մեջ, երկու ուղղությունների համար (LRL en). Մենք նաև ցույց ենք տալիս, որ մոդելի բառագրի դինամիկ ադապտացիան հանգեցնում է LRL-ի առավելագույն սեգմետրացիային, համեմատած անմիջական ադապտացիային: Փորձարկումները ցույց են տալիս կրճատումներ ուսուցման ժամանակի մեջ և նշանակալի զարգացումներ LRL հիմնական գծերի վրա, նույնիսկ զրոյից LRL տվյալներ (+13.0 Blaus), մինչև +17.0 Blaus նախապատրաստված բազլեզու մոդելի դինամիկ ադապտացիայի համար կապված տվյալների ընտրության հետ Մեր մեթոդը գերազանցում է ներկայիս մոտեցումները, ինչպիսիք են զանգվածային բազլեզու մոդելները և տվյալների աճը, չորս LRL-ի վրա:', 'sq': "MNMT për gjuhët me burime të ulta (LRL) mund të përmirësohet nga prania e gjuhëve me burime të larta (HRL), por lidhja e HRL zakonisht mbështetet në supozimet e paracaktuara gjuhësore rreth ngjashmërisë gjuhësore. Recently, adapting MNMT to a LRL has shown to greatly improve performance.  Në këtë punë, ne eksplorojmë problemin e përshtatjes së një modeli MNMT në një LRL të padukshëm duke përdorur zgjedhjen e të dhënave dhe adaptimin e modelit. In order to improve NMT for LRL, we employ perplexity to select HRL data that are most similar to the LRL on the basis of language distance.  We extensively explore data selection in popular multilingual NMT settings, namely in (zero-shot) translation, and in adaptation from a multilingual pre-trained model, for both directions (LRL en).  We further show that dynamic adaptation of the model's vocabulary results in a more favourable segmentation for the LRL in comparison with direct adaptation.  Experiments show re- ductions in training time and significant performance gains over LRL baselines, even with zero LRL data (+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic adaptation with related data selection.  Metoda jonë ekziston më shumë se metodat aktuale, të tilla si modelet masive shumëgjuhësore dhe rritja e të dhënave, në katër LRL.", 'az': "Daha düşük ressurs dillərinin (LRL) çoxlu dillərin nöral maşına çevirisi (MNMT) ilə bağlı yüksək ressurs dillərinin (HRL) vasitəsilə daha yaxşılaşdırılabilir, amma HRL'in bağlılığı genellikle dil bənzəriliyi barəsində əvvəlcə belə tanımlanmış dillərin zənnələrinə bağlıdır. Son zamanlarda, MNMT'i LRL'ə uyğunlaşdırmaq çox xeyirli olaraq göstərildi. Bu işdə, MNMT modelini görmədiyimiz LRL-ə uyğunlaşdırmaq problemini keşfetirik, məlumat seçimləri və modelləri uyğunlaşdırmaq üçün. LRL üçün NMT yaxşılaşdırmaq üçün, dil uzaqlaşığına görə LRL məlumatlarını seçmək üçün ən bənzər HRL məlumatlarını istifadə edirik. Biz çox dilli NMT ayarlarında məlumat seçimlərini çox təhsil edirik, bu da (zero-shot) tercümələrində və çox dilli öyrənmiş modellərdən uyğunlaşdırılır, iki tərəfdən (LRL en). Daha sonra model in in s özlərinin dinamik uyğunlamasını göstəririk ki, LRL üçün düzgün uyğunlaşdırılması ilə qarşılaşdırmaq üçün daha yaxşı bir segmentasyon olar. Həqiqətən, təhsil vaxtında yenidən təhsil və möhkəm təhsil göstəricisi LRL təhsil çətinlərini, hətta Sıfır LRL veriləri (+13.0 BLEU) ilə +17.0 BLEU ilə birlikdə təhsil edilmiş çoxlu dil modeli dinamik uyğunlaşdırması üçün göstərir. Bizim metodumuz, dörd LRL üzerində çoxlu dil modelləri və məlumatları artırmaq kimi, ağıllı tərzlərindən daha çox yaxınlaşır.", 'bn': 'নিম্ন- সম্পর্কিত উচ্চ সম্পদ ভাষার (এইচআরএল) উপস্থিতির মাধ্যমে অনেক ভাষায় নিউরেল মেশিন অনুবাদ (এমএনএমটি) বাড়িয়ে দিতে পারে, কিন্তু এইচআরএলের সম্পর্ক সাধারণত ভাষার সমতুল্য সম্পর্কে ন সম্প্রতি এমএনএমটিকে এলআরএলের কাছে প্রতিযোগিতা বেশি উন্নত করে দেখিয়েছে। এই কাজে আমরা একটি এমএনএমটি মডেল প্রতিষ্ঠানের সমস্যা খুঁজে বের করি একটি অদৃশ্য এলআরএলের মাধ্যমে ডাটা নির্বাচন এবং মডেল অ্যাডাপ্ট In order to improve NMT for LRL, we employ perplexity to select HRL data that are most similar to the LRL on the basis of language distance.  জনপ্রিয় বহুভাষায় এনএমটি বৈশিষ্ট্যের মাধ্যমে আমরা ব্যাপক তথ্য নির্বাচন খুঁজে বের করি, যেমন (শূন্য-শুট) অনুবাদ, এবং বহুভাষায় প্রশিক্ষণের পূর্ববর্তী মডে আমরা আরো দেখাচ্ছি যে মডেলের শব্দভাণ্ডারের ডায়াম্যানিক আপেটপেটশনের ফলে এলআরএলের কাছে সরাসরি আপডেটেশনের তুলনায় আরো ভালো বিভিন্ন অং প্রশিক্ষণের সময়ে পুনরায় দায়িত্ব প্রদর্শন করা হয় এবং LRL বেসারেইনে গুরুত্বপূর্ণ প্রদর্শন করা হয়, এমনকি এমনকি শূন্য LRL ডাটা (+13. 0 বেলিউ), পূর্ব প্রশিক্ষিত বহুভাষী মডেলের ডায়াম্যা আমাদের পদ্ধতি বর্তমান প্রতিক্রিয়ার চার এলআরএল-এ, যেমন ব্যাপক বহুভাষায় মডেল এবং তথ্য যোগাযোগ করা।', 'ca': "La traducció multilingüe de màquines neuronals (MNMT) per llengües de baix recursos (LRL) pot ser millorada per la presença de llengües relacionades d'alt recurso (HRL), però la relació de HRL normalment es basa en suposicions lingüístices predefinides sobre la similitud lingüística. Recently, adapting MNMT to a LRL has shown to greatly improve performance.  En aquesta feina, explorem el problema d'adaptar un model MNMT a un LRL invisible fent servir la selecció de dades i l'adaptació del model. Per millorar la LRL, utilitzem la perplexitat per seleccionar les dades HRL més similars a la LRL en funció de la distància lingüística. Explorem ampliament la selecció de dades en configuracions populars multilingües del NMT, a saber, en traducció (zero-shot), i en adaptació d'un model multilingüe pré-entrenat, per ambdues direccions (LRL en). Ens demostram que l'adaptació dinàmica del vocabulari del model resulta en una segmentació més favorable per a la LRL en comparació amb l'adaptació directa. Els experiments mostran reduccions en el temps d'entrenament i guanys significatius de rendiment sobre les línies de base de LRL, fins i tot amb zero dades LRL (+13,0 BLEU), fins i tot +17,0 BLEU per adaptar dinàmicament al model multilingüe amb selecció de dades relacionada. El nostre mètode supera els enfocaments actuals, com els models multilingües i el augment de dades, en quatre LRL.", 'cs': 'Vícejazyčný neuronový strojový překlad (MNMT) pro jazyky s nízkými zdroji (LRL) může být zlepšen přítomností souvisejících jazyků s vysokými zdroji (HRL), ale souvislost HRL se obvykle opírá o předem definované lingvistické předpoklady o jazykové podobnosti. V poslední době se ukázalo, že adaptace MNMT na LRL výrazně zlepšuje výkon. V této práci zkoumáme problém adaptace MNMT modelu na neviditelnou LRL pomocí výběru dat a adaptace modelu. Abychom zlepšili NMT pro LRL, využíváme zmatenost k výběru HRL dat, která jsou LRL nejvíce podobná, na základě jazykové vzdálenosti. Důkladně zkoumáme výběr dat v oblíbených vícejazyčných NMT nastaveních, konkrétně v (nulovém) překladu, a v adaptaci z vícejazyčného předškoleného modelu, pro obě směry (LRL en). Dále ukazujeme, že dynamická adaptace slovníku modelu vede k příznivější segmentaci pro LRL ve srovnání s přímou adaptací. Experimenty ukazují zmenšení tréninkové doby a výrazné zvýšení výkonnosti nad základními liniemi LRL, a to i s nulovými LRL daty (+13.0 BLEU), až +17.0 BLEU pro předtrénovanou vícejazyčnou dynamickou adaptaci modelu s souvisejícím výběrem dat. Naše metoda překonává současné přístupy, jako jsou masivně vícejazyčné modely a rozšíření dat, na čtyřech LRL.', 'fi': 'Vähävaraisten kielten monikielistä neurokonekäännöstä (MNMT) voidaan tehostaa olemalla siihen liittyviä korkean resurssin kieliä (HRL), mutta HRL:n yhteys perustuu yleensä ennalta määriteltyihin kielioletuksiin kielen samankaltaisuudesta. Viime aikoina MNMT:n mukauttaminen LRL:ään on osoittanut parantavan suorituskykyä huomattavasti. Tässä työssä tutkitaan ongelmaa MNMT-mallin mukauttamisesta näkymättömään LRL:ään datan valinnan ja mallin mukauttamisen avulla. Parantaaksemme NMT:tä LRL:ssä käytämme hämmennystä valitaksemme HRL:n tietoja, jotka ovat LRL:n kaltaisia kielietäisyyden perusteella. Tutkimme laajasti datan valintaa suosituissa monikielisissä NMT-asetuksissa, nimittäin (nolla-shot) käännöksissä ja monikielisestä esikoulutetusta mallista, molempiin suuntiin (LRL en). Osoitamme lisäksi, että mallin sanaston dynaaminen mukauttaminen johtaa LRL:lle suotuisampaan segmentoitumiseen verrattuna suoraan sopeuttamiseen. Kokeet osoittavat, että harjoitteluaika on vähentynyt ja suorituskyky on parantunut merkittävästi LRL-lähtötasoon verrattuna, vaikka LRL-tiedot olisivat nolla (+13,0 BLEU), jopa +17,0 BLEU-tason tason tason esikoulutetussa monikielisessä mallin dynaamisessa sopeuttamisessa ja siihen liittyvässä tietojen valinnassa. Menetelmämme ylittää nykyiset lähestymistavat, kuten massiivisen monikieliset mallit ja datan lisääminen, neljällä LRL:llä.', 'et': 'Vähese ressursiga keelte mitmekeelset neuraalset masintõlket (MNMT) saab parandada seotud suure ressursiga keelte olemasoluga, kuid HRL seos tugineb tavaliselt eelnevalt määratletud keelelistele oletustele keele sarnasuse kohta. Hiljuti on MNMT kohandamine LRL-iga näidanud olulist jõudlust. Selles töös uurime MNMT mudeli kohandamise probleemi nähtamatule LRL-le, kasutades andmete valikut ja mudeli kohandamist. Selleks, et parandada NMT-d LRL-i puhul, kasutame hämmeldust, et valida HRL-i andmed, mis on kõige sarnasemad LRL-iga keele kauguse põhjal. Uurime põhjalikult andmete valikut populaarsetes mitmekeelsetes NMT seadetes, nimelt (null-shot) tõlkes ja kohandamises mitmekeelse eelkoolitud mudeli alusel mõlemas suunas (LRL en). Lisaks näitame, et mudeli sõnavara dünaamiline kohandamine toob LRL jaoks kaasa soodsama segmenteerimise võrreldes otsese kohandamisega. Katsed näitavad koolitusaja taastumist ja märkimisväärset jõudluse kasvu võrreldes LRL baasjoontega, isegi kui LRL andmed on null (+13,0 BLEU), kuni +17,0 BLEU eelnevalt koolitatud mitmekeelse mudeli dünaamilise kohandamise puhul koos sellega seotud andmete valikuga. Meie meetod ületab praeguseid lähenemisviise, nagu massiliselt mitmekeelsed mudelid ja andmete suurendamine, neljas LRL-is.', 'bs': 'Mnogjezički neurološki prevod uređaja (MNMT) za jezike niskih resursa (LRL) može se poboljšati prisustvom povezanih jezika visokih resursa (HRL), ali povezanost HRL obično oslanja na predodređene jezičke pretpostavke o sličnosti jezika. Nedavno je prilagođenje MNMT-a na LRL pokazalo da je veoma poboljšanje učinka. U ovom poslu istražujemo problem prilagođenja modela MNMT-a nevidljivom LRL koristeći selekciju podataka i adaptaciju modela. Da bismo poboljšali NMT za LRL, upotrebljavali smo neprijatnost da izaberemo HRL podatke koje su najsličnije LRL na temelju jezičke udaljenosti. Prošireno istražujemo selekciju podataka u popularnim multijezičkim postavkama NMT-a, a to je u (nul-shot) prevodu, i u adaptaciji iz multijezičkog predobučenog modela, za oba smjera (LRL en). Dalje pokazujemo da dinamična adaptacija rečnika model a rezultat rezultata boljih segmentacija za LRL u usporedbi s direktnom adaptacijom. Eksperimenti pokazuju revakcije u vrijeme obuke i značajne dobitke učinkovitosti iznad početnih linija LRL, čak i sa nulom podataka LRL (+13,0 BLEU), do +17,0 BLEU za predobučenu dinamičnu adaptaciju multijezičkog modela s povezanom selekcijom podataka. Naša metoda iznosi trenutne pristupe, poput masivnih multijezičkih modela i povećanja podataka, na četiri LRL.', 'jv': 'Multilengkang Neral Mas Terjamahan (MNMT) kanggo langgambar apat-pakan (LRL), iso disenyongno karo alêran langkung banjur-akeh liyane plug-in-action Nang barêng-barêng iki, kita gewusegno perkoro kanggo nambah gambar MNMT model nang LRL kuwi nggawe diumbane dadi lan model model model modèl Digawe kanggo nglanggar NMT kanggo LRL, kita nguasai perpliksi kanggo limian HRL dadi sing dibutuhke sing luwih dumadhi kanggo LRL dumadhi kapan langgar. Awak dhéwé luwih akeh nggawe dadi kanggo Kelangan hukum kanggo populer NMT tentang kanggo ngilangno: 0-ot ↔ en). Monday Getama Nalika dhéwé éngawe barang nggawe dolanan liyane, kaya ngono akeh multilenguang model lan ampungasi data, ning upat LRL.', 'sk': 'Večjezični nevralni strojni prevod (MNMT) za jezike z nizkimi viri (LRL) se lahko izboljša s prisotnostjo sorodnih jezikov z visokimi viri (HRL), vendar se povezanost HRL običajno opira na vnaprej določene jezikovne predpostavke o jezikovni podobnosti. V zadnjem času se je prilagoditev MNMT na LRL pokazala za močno izboljšanje zmogljivosti. V tem delu raziskujemo problem prilagajanja modela MNMT na nevidno LRL z uporabo izbire podatkov in prilagajanja modela. Da bi izboljšali NMT za LRL, uporabljamo zmedenost za izbiro podatkov HRL, ki so najbolj podobni LRL na podlagi jezikovne razdalje. Obsežno raziskujemo izbiro podatkov v priljubljenih večjezičnih NMT nastavitvah, in sicer v (ničelnem) prevajanju in prilagajanju iz večjezičnega vnaprej usposobljenega modela za obe smeri (LRL). ↔ sl). Dodatno dokazujemo, da dinamična prilagoditev besedišča modela prinaša ugodnejšo segmentacijo za LRL v primerjavi z neposredno prilagoditvijo. Eksperimenti kažejo ponovno zmanjšanje časa vadbe in znatno povečanje zmogljivosti v primerjavi z osnovnimi vrsticami LRL, tudi z nič podatkov LRL (+13,0 BLEU), do +17,0 BLEU za vnaprej usposobljeno večjezično dinamično prilagajanje modela s povezano izbiro podatkov. Naša metoda presega sedanje pristope, kot so množični večjezični modeli in povečanje podatkov, pri štirih LRL.', 'bo': 'སྐད་རིགས་ཀྱི་སྣ་མང་ཆེ་ཤོས་ཀྱི་Neural Machine Translation (MNMT)དང་རྐྱེན་འབྲེལ་བའི་སྐད་རིགས་ལ་མཐུན་ཡོད། Recently, MNMT adapting to a LRL has shown great performance. In this work, we explore the problem of adapting an MNMT model to an unseen LRL using data selection and model adapta-tion. LRL ལ་སྒྲིག་ཚད་ལ་རྒྱས་གཏོང་དགོས་པ་དེ་འོང་གིས་སྐད་ཀྱི་བར་ཐག We extensively explore data selection in popular multilingual NMT settings, namely in (zero-shot) translation, and in adaptation from a multilingual pre-trained model, for both directions (LRL) ↔ en). འུ་ཚོས་ཀྱིས་མ་དབྱིབས་གྱི་བརྡ་སྤྲོད་ཀྱི་གྲོས་རིམ་གྱི་གྲོས་མཐུན་འགྱུར་བ་དེ་ཚོ་ནི་ཕན་ཚུན་ཡོད་པའི་སྒྲིག་སྟངས་ལ་ཕན་ཚུན Experiments show re-ductions in training time and significant performance gains over LRL baselines, even with zero LRL data (+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic adaptation with related data selection. ང་ཚོའི་ལམ་ལུགས་འདིས་ད་ལྟོའི་ཐབས་ལམ་ལ་གཟུགས་འགོག་ཐབས་ལམ་ལུགས་མེད་པས། དཔེར་ན། སྣ་ཆེ་ཤོས་སྐད་ཀྱི་མིང་དཔེ་ལ་དང་', 'ha': "@ item: inmenu A yanzu, mai adadin MNMT zuwa wani LRL ya nuna don ya kyautata aiki. Daga wannan aikin, Munã jarraba matsayin ya canza tsarin wata misali na MNMT zuwa wani LRL wanda ba'a sani ba, don ka yi amfani da zaɓani da shirin ayuka na adapta-tion. Dõmin ya ƙara NMT wa LRL, sai mu yi aiki mai walãkanci dõmin mu zãɓi data na HRL da mafi daidaita zuwa LRL kan hanya na zaman harshen. @ info: whatsthis ↔ dictionary variant Tuna ƙara nuna cewa adadin ayukan misalin ayuka ya ƙara wani mai kyau wa LRL sami da adadin durowa. Experiments na nuna re-dual'a cikin shirin lokaci da mai girma ya ci over LRL-sales, kõ da sifiri na LRL data (+13.0 BLEU), up to+17.0 BLEU wa shirin mai zaman yin shirin mulki-linguin mulki-language adamantic adaptation with selected data related. Our method outperforms current approaches, such as massively multilingual models and data augmentation, on four LRL.", 'he': 'תורגם וסונכרן ע"י Qsubs מצוות לאחרונה, ההסתגלות של MNMT ל LRL הוכיחה שיפור גדול ביצועים. בעבודה הזו, אנו חוקרים את הבעיה של ההסתגלות מודל MNMT ל LRL בלתי נראה באמצעות בחירת נתונים ומודל ההסתגלות. על מנת לשפר את NMT עבור LRL, אנו משתמשים בלבוש לבחור נתונים HRL שהדומים ביותר ל LRL על בסיס מרחק השפה. אנו חוקרים באופן רחב את בחירת נתונים במסדרות NMT רבות שפוליות, במיוחד בתרגום (אפס-צילום), ובהתאמה ממודל מוכשר מראש רבות שפולית, לשני הכיוונים (LRL ↔ en). אנחנו גם מראים שהשימוש דינמי של ספר המילים של המודל מוביל בחלקה טובה יותר עבור LRL בהשוואה עם שימוש ישיר. ניסויים מראים שינויים בזמן האימון והשיכורים ביצועים משמעותיים מעל קווי הבסיס LRL, אפילו עם אפס נתונים LRL (+13.0 BLEU), עד +17.0 BLEU עבור התאמה דינמית מודל רב-שפתי מאומנת מראש עם בחירת נתונים קשורה. השיטה שלנו מעליפה גישות הנוכחיות, כמו דוגמנים רבות שפות ועודפות מידע, על ארבעה LRL.'}
{'en': 'Transformers without Tears : Improving the Normalization of Self-Attention', 'ar': 'محولات بدون دموع: تحسين تطبيع الانتباه الذاتي', 'pt': 'Transformadores sem Lágrimas: Melhorando a Normalização da Autoatenção', 'fr': "Transformateurs sans larmes\xa0: améliorer la normalisation de l'attention personnelle", 'es': 'Transformers without Tears: mejorar la normalización de la autoatención', 'ja': '涙のない変圧器：自己愛の正常化の向上', 'hi': 'आँसू के बिना ट्रांसफार्मर: आत्म-ध्यान के सामान्यीकरण में सुधार', 'zh': '无泪之变形金刚:贵自注之正常化', 'ru': 'Трансформаторы без разрывов: улучшение нормализации самовосприятия', 'ga': 'Claochladáin gan Tears: Feabhas a chur ar Normalú Féin-Aire', 'ka': 'ტრანფორმაცირები საშუალების გარეშე: საშუალების ნორმალიზაცია', 'el': 'Μετασχηματιστές χωρίς δάκρυα: Βελτίωση της κανονικοποίησης της αυτοπροσοχής', 'hu': 'Transzformátorok könnyek nélkül: az önfigyelem normalizálásának javítása', 'it': "Trasformatori senza lacrime: migliorare la normalizzazione dell'auto-attenzione", 'kk': 'Түрлі түрлендірушілер: Өзіңіздің қарапайым нормализациясын жақсарту', 'lt': 'Transformers without Tears: Improving the Normalization of Self-Attention', 'mk': 'Трансформирачи без солзи: подобрување на нормализацијата на самовниманието', 'ms': 'Penukar tanpa Air mata: Menyukur Normalisasi Perhatian Sendiri', 'mn': 'Өөрийгөө анхааралгүйгээр шилжүүлэгчид: Өөрийгөө анхааралгүйгээр', 'ml': 'ടീരുകളില്ലാത്ത പരിഭാഷകര്\u200d: സ്വയം ശ്രദ്ധിക്കുന്നതിന്റെ നോര്\u200dമിലേഷന്\u200d മുന്\u200dകൂട്ടുന്നു', 'mt': 'Transformers without Tears: Improving the Normalization of Self-Attention', 'no': 'Transformerer utan tærar: Forbetra normalisering av sjølvmerksomhet', 'pl': 'Transformatory bez łez: poprawa normalizacji uwagi na siebie', 'sr': 'Transformeri bez suza: poboljšavanje normalizacije samopouzdanja', 'so': 'Turjumayaasha aan Tear lahayn: Improving the Normalization of Self-Attention', 'ro': 'Transformatoare fără lacrimi: Îmbunătățirea normalizării auto-atenției', 'si': 'ස්වයංග්\u200dරහය නැති වෙනස් කරන්න: ස්වයංග්\u200dරහයේ සාමාන්\u200dය වැඩ කරන්න', 'ta': 'தேநீர் இல்லாத மாற்றுபவர்கள்:', 'sv': 'Transformatorer utan tårar: Förbättra normaliseringen av självuppmärksamhet', 'ur': 'تغییرات بغیر تغییرات: اپنا حواسطہ سیدھا سامان', 'uz': 'Name', 'vi': 'Biến hình mà không có mắt: Tăng cường hoá độ chú ý', 'bg': 'Трансформатори без сълзи: Подобряване на нормализацията на самовниманието', 'nl': 'Transformers zonder tranen: het verbeteren van de normalisatie van zelfaandacht', 'da': 'Transformere uden tårer: Forbedring af normalisering af selvopmærksomhed', 'hr': 'Transformeri bez suza: poboljšavanje normalizacije samopouzdanja', 'de': 'Transformatoren ohne Tränen: Verbesserung der Normalisierung der Selbstachtung', 'id': 'Transformer tanpa air mata: Menembak Normalisasi Perhatian Sendiri', 'sw': 'Watafsiri bila machozi: Kuboresha Uhalifu wa Kujihisia Huru', 'ko': '무루 변형 금강: 자아 관심의 정상화 향상', 'af': 'Transformeerders sonder Tears: Verbeter die Normaliseering van Selfwaarskuwing', 'fa': 'تغییر دهندگان بدون چارها: تغییر دهندگان توجه خود', 'tr': 'Derjessiz transformatçylar: Öz ünsüni bejermek üçin gowylaşdyrýar', 'az': 'Köy olmadan transformatörlər: Özünün təhlükəsizliklərini yaxşılaşdırma', 'sq': 'Transformuesit pa lotë: Përmirësimi i Normalizimit të Vetëvëmendjes', 'am': 'Transformers without Tears: Improving the Normalization of self-Attention', 'bs': 'Transformeri bez suza: poboljšavanje normalizacije samopouzdanja', 'hy': 'Արցունքից առանց վերածիչներ. ինքնաուշադրության նորմալիզացիայի բարելավումը', 'ca': "Transformers sense llàgrimes: millorar la normalització de l'auto-atenció", 'fi': 'Muuntajat ilman kyyneleitä: Parannetaan itsetunnon normalisointia', 'bn': 'কাঁদ ছাড়া ট্রান্সফার্সার: স্বাধীনতার স্বাভাবিক মনোযোগ প্রদান করা', 'et': 'Transformerid ilma pisarateta: Enesetähelepanu normaliseerimise parandamine', 'cs': 'Transformátory bez slz: zlepšení normalizace sebepozornosti', 'jv': 'Ngubah Rusak-warni kagunggo Ketok Tulungan', 'ha': 'KCharselect unicode block name', 'sk': 'Transformatorji brez solz: izboljšanje normalizacije samopozornosti', 'bo': 'དབྱིབས་ལུགས་མེད་པའི་བཟོ་བཅོས་པ། སྲོལ་རྒྱུན་ལྡན་གྱི་རྒྱུན་ལྡན་རྒྱས་གཏོང་།', 'he': 'משתנים ללא דמעות: שיפור נורמליזציה של תשומת לב עצמית'}
{'en': 'We evaluate three simple, normalization-centric changes to improve Transformer training. First, we show that pre-norm residual connections (PRENORM) and smaller initializations enable warmup-free, validation-based training with large learning rates. Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance. Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM). On five low-resource translation pairs from ', 'ar': "نقوم بتقييم ثلاثة تغييرات بسيطة تتمحور حول التطبيع لتحسين تدريب المحولات. أولاً ، نظهر أن الاتصالات المتبقية (PRENORM) والتهيئة الأصغر تتيح تدريبًا خاليًا من الإحماء وقائم على التحقق من الصحة بمعدلات تعلم كبيرة. ثانيًا ، نقترح تسوية المستوى الثاني بمعامل مقياس واحد (SCALENORM) لتدريب أسرع وأداء أفضل. أخيرًا ، نعيد التأكيد على فعالية تطبيع تزوير الكلمات بطول ثابت (FIXNORM). في خمسة أزواج ترجمة منخفضة الموارد من محاضرات TED ، تتقارب هذه التغييرات دائمًا ، مما يعطي متوسط +1.1 BLEU على أحدث خطوط الأساس ثنائية اللغة و 32.8 BLEU جديد في IWSLT '15 الإنجليزية-الفيتنامية. نحصل على منحنيات أداء أكثر وضوحًا ومعايير تدرج أكثر اتساقًا وعلاقة خطية بين مقياس التنشيط وعمق وحدة فك التشفير. من المثير للدهشة ، في الإعداد عالي الموارد (WMT '14 الإنجليزية-الألمانية) ، أن SCALENORM و FIXNORM يظلان تنافسيين ولكن PRENORM يحط من الأداء.", 'fr': "Nous évaluons trois changements simples centrés sur la normalisation afin d'améliorer la formation des transformateurs. Tout d'abord, nous montrons que les connexions résiduelles pré-normes (PRENORM) et les initialisations plus petites permettent un entraînement sans échauffement basé sur la validation avec des taux d'apprentissage élevés. Ensuite, nous proposons une normalisation L2 avec un seul paramètre d'échelle (SCALENORM) pour un entraînement plus rapide et de meilleures performances. Enfin, nous réaffirmons l'efficacité de la normalisation des intégrations de mots à une longueur fixe (FIXNORM). Sur cinq paires de traduction à faibles ressources issues de corpus basés sur TED Talks, ces changements convergent toujours, donnant une moyenne de +1,1 UEBL sur des bases de référence bilingues de pointe et une nouvelle UEBL de 32,8 sur IWSLT '15 anglais-vietnamien. Nous observons des courbes de performance plus nettes, des normes de gradient plus cohérentes et une relation linéaire entre la mise à l'échelle d'activation et la profondeur du décodeur. Étonnamment, dans le contexte des ressources élevées (WMT '14 anglais-allemand), SCALENORM et FIXNORM restent compétitifs mais PRENORM dégrade les performances.", 'es': "Evaluamos tres cambios simples y centrados en la normalización para mejorar el entrenamiento de Transformer. En primer lugar, mostramos que las conexiones residuales anteriores a la norma (PRENORM) y las inicializaciones más pequeñas permiten una capacitación basada en validación sin calentamiento con grandes tasas de aprendizaje. En segundo lugar, proponemos la normalización l2 con un único parámetro de escala (SCALENORM) para un entrenamiento más rápido y un mejor rendimiento. Finalmente, reafirmamos la eficacia de normalizar la incrustación de palabras a una longitud fija (FIXNORM). En cinco pares de traducción de bajos recursos de corpus basados en TED Talks, estos cambios siempre convergen, dando un promedio de +1,1 BLEU sobre las líneas de base bilingües de última generación y un nuevo 32,8 BLEU en el IWSLT '15 inglés-vietnamita. Observamos curvas de rendimiento más nítidas, normas de gradiente más consistentes y una relación lineal entre la escala de activación y la profundidad del decodificador. Sorprendentemente, en el entorno de altos recursos (WMT '14 inglés-alemán), SCALENORM y FIXNORM siguen siendo competitivas, pero PRENORM degrada el rendimiento.", 'pt': "Avaliamos três mudanças simples centradas na normalização para melhorar o treinamento do Transformer. Primeiro, mostramos que conexões residuais pré-norma (PRENORM) e inicializações menores permitem treinamento baseado em validação e sem aquecimento com grandes taxas de aprendizado. Em segundo lugar, propomos a normalização l2 com um único parâmetro de escala (SCALENORM) para treinamento mais rápido e melhor desempenho. Por fim, reafirmamos a eficácia da normalização de embeddings de palavras para um comprimento fixo (FIXNORM). Em cinco pares de tradução de poucos recursos de corpora baseados em TED Talks, essas mudanças sempre convergem, dando uma média de +1,1 BLEU sobre linhas de base bilíngues de última geração e um novo 32,8 BLEU no IWSLT '15 inglês-vietnamita. Observamos curvas de desempenho mais nítidas, normas de gradiente mais consistentes e uma relação linear entre a escala de ativação e a profundidade do decodificador. Surpreendentemente, no cenário de alto recurso (WMT '14 Inglês-Alemão), SCALNORM e FIXNORM permanecem competitivos, mas PRENORM degrada o desempenho.", 'ja': "私たちは、トランスフォーマーのトレーニングを改善するために、3つの単純で正規化中心の変更を評価します。まず、ノーム前残留接続（ PRENORM ）とより小さな初期化により、大きな学習率でウォームアップなしの検証ベースのトレーニングが可能になることを示します。第二に、より速いトレーニングとより良いパフォーマンスのために、単一スケールパラメータ（ SCALENORM ）を使用したl 2正規化を提案します。最後に、単語埋め込みを固定長（ FIXNORM ）に正規化することの有効性を再確認します。TED TALKSベースのコーラからの5つの低リソース翻訳ペアでは、これらの変更は常に収束し、最先端のバイリンガルベースラインの平均+1.1 BLEUと、IWSLT '15英語-ベトナム語の新しい32.8 BLEUが得られます。私たちは、より鮮明なパフォーマンス曲線、より一貫した勾配ノルム、および活性化スケーリングとデコーダ深度の間の線形関係を提供します。驚くべきことに、ハイリソース設定（ WMT' 14英独）では、SCALENORMとFIXNORMは競争力を維持しますが、PRENORMはパフォーマンスを低下させます。", 'zh': "估其三简,以规范化为心,以改 Transformer 教。 先明前范数残差接(PRENORM)小初始化可以成大学率无预热,基于验练。 次议用比例参数 (SCALENORM) l2 归一化,以成更快练善。 最后,重申销词规范化为定长(FIXNORM)之有效性。 于TED Talks之语料库五低资源译对上,其变常趋同在,视最先进之双语基线均+1.1 BLEU,于IWSLT '15英语- 越南语上与新32.8 BLEU。 共其清曲线,同其梯度规,激活缩放解码器深线性关系。 令人讶之,于高资置(WMT '14 英语-德语)中,SCALENORM FIXNORM 犹有竞争力,然 PRENORM 降性能。", 'ru': "Мы оцениваем три простых, ориентированных на нормализацию изменения для улучшения обучения трансформаторов. Во-первых, мы показываем, что донормные остаточные соединения (PRENORM) и более мелкие инициализации позволяют проводить обучение без прогрева и на основе валидации с большими показателями обучения. Во-вторых, мы предлагаем нормализацию l2 с помощью одномасштабного параметра (SCALENORM) для более быстрого обучения и лучшей производительности. Наконец, мы подтверждаем эффективность нормализации словесных вложений до фиксированной длины (FIXNORM). На пяти низкоресурсных переводческих парах от корпораций, основанных на TED TALKS, эти изменения всегда сходятся, давая в среднем +1,1 BLEU по сравнению с современными двуязычными базовыми линиями и новый 32,8 BLEU на английском и вьетнамском языках IWSLT '15. Мы обслуживаем более четкие кривые производительности, более согласованные градиентные нормы и линейную зависимость между масштабированием активации и глубиной декодера. Удивительно, что в условиях высоких ресурсов (англо-немецкий WMT '14), SCALENORM и FIXNORM остаются конкурентоспособными, но PRENORM ухудшает производительность.", 'hi': "हम ट्रांसफॉर्मर प्रशिक्षण में सुधार करने के लिए तीन सरल, सामान्यीकरण-केंद्रित परिवर्तनों का मूल्यांकन करते हैं। सबसे पहले, हम दिखाते हैं कि पूर्व-मानक अवशिष्ट कनेक्शन (PRENORM) और छोटे initializations बड़ी सीखने की दरों के साथ वार्मअप-मुक्त, सत्यापन-आधारित प्रशिक्षण को सक्षम करते हैं। दूसरा, हम तेजी से प्रशिक्षण और बेहतर प्रदर्शन के लिए एक एकल पैमाने पैरामीटर (SCALENORM) के साथ l2 सामान्यीकरण का प्रस्ताव करते हैं। अंत में, हम एक निश्चित लंबाई (FIXNORM) के लिए शब्द एम्बेडिंग को सामान्य करने की प्रभावशीलता की पुष्टि करते हैं। टेड टॉक्स-आधारित कॉर्पोरेट से पांच कम-संसाधन अनुवाद जोड़े पर, ये परिवर्तन हमेशा अभिसरण करते हैं, जो अत्याधुनिक द्विभाषी आधार रेखाओं पर औसत +1.1 BLEU और IWSLT '15 अंग्रेजी-वियतनामी पर एक नया 32.8 BLEU देते हैं। हम ob- तेज प्रदर्शन घटता, अधिक सुसंगत ढाल मानदंडों, और सक्रियण स्केलिंग और विकोडक गहराई के बीच एक रैखिक संबंध की सेवा करते हैं। हैरानी की बात है, उच्च संसाधन सेटिंग (WMT '14 अंग्रेजी-जर्मन) में, SCALENORM और FIXNORM प्रतिस्पर्धी रहते हैं लेकिन PRENORM प्रदर्शन degrades.", 'ga': "Déanaimid measúnú ar thrí athrú simplí, normalaithe-lárnach chun oiliúint Trasfhoirmeora a fheabhsú. Ar an gcéad dul síos, léirímid go gcumasaíonn naisc iarmharacha réamh-normálta (PRENORM) agus tosaighúcháin níos lú oiliúint atá saor ó théamh, bunaithe ar bhailíochtú le rátaí móra foghlama. Sa dara háit, molaimid normalú l2 le paraiméadar scála amháin (SCALENORM) le haghaidh oiliúna níos tapúla agus feidhmíocht níos fearr. Ar deireadh, athdhearbhaímid éifeachtacht leabú focal a normalú go fad seasta (FIXNORM). Ar chúig phéire aistriúcháin íseal-acmhainne ó chorpora TED Talks, tagann na hathruithe seo le chéile i gcónaí, rud a thugann meán +1.1 BLEU thar bhunlínte dátheangacha den scoth agus 32.8 BLEU nua ar IWSLT '15 Béarla-Vítneaimis. Breathnaímid ar chuair feidhmíochta níos géire, ar noirm grádáin níos comhsheasmhaí, agus ar ghaolmhaireacht líneach idir scálaiú gníomhachtaithe agus doimhneacht díchódóra. Is ionadh é, sa suíomh ard-acmhainne (WMT '14 Béarla-Gearmáinis), tá SCALENORM agus FIXNORM fós iomaíoch ach díghrádaíonn PRENORM an fheidhmíocht.", 'ka': "ჩვენ სამუშაო, ნორმალიზაციის ცვლილებების შესახებ ტრანფორმაციის განაკეთებაზე გაუკეთებლად გავაკეთებთ. პირველი, ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ პრონორმა დასრულებული კავშირები (PRENORM) და ცოტა ინციალიზაციები შეუძლიათ გადასრულება, გავალეცია დასრულებული გან მეორე, ჩვენ ი2 ნორმალიზაციას ერთი მაგალითის პარამეტრებით (SCALENORM) სწრაფად სწრაფად სწავლობა და უკეთესი გამოყენება. საბოლოოდ, ჩვენ ახლა დააღწერეთ სიტყვების სიტყვების ნორმალიზაციის ეფექტიურობა (FIXNORM). TED საუბრობის კოპორაზე ხუთი კომპორაზე, ეს ცვლილებები ყოველთვის შემდეგ შემდეგ შემდეგ შემდეგ შემდეგ გადაწყება +1.1 BLEU-ს განმავლობაში მეორე მეორე საუბრობოლოდ და ახალი 32.8 BLEU-ს IWSLT'15 ინგლისური-ვიტენმაი ჩვენ უფრო კონსპექციენტის კურსები, უფრო კონსპექციენტი გრადიენტის ნორმები, და ლინური შესახებ აკეთექციის სკენტირების და სკენტირების შორის. სხვადასხვა, მეტი რესურსის შესაძლებელობაში (WMT '14 ინგლისური-გერმანური) SCALENORM და FIXNORM კონპექტიური გადარჩენა, მაგრამ PRENORM სხვადასხვა კონპექტიურება.", 'el': "Αξιολογούμε τρεις απλές, ομαλοποιημένες αλλαγές για να βελτιώσουμε την εκπαίδευση μετασχηματιστών. Πρώτον, καταδεικνύουμε ότι οι προ-κανονικές υπολειμματικές συνδέσεις (και μικρότερες αρχικές ρυθμίσεις επιτρέπουν εκπαίδευση χωρίς προθέρμανση, βασισμένη στην επικύρωση με μεγάλα ποσοστά μάθησης. Δεύτερον, προτείνουμε την ομαλοποίηση με μια ενιαία παράμετρο κλίμακας (SCALENORM) για ταχύτερη εκπαίδευση και καλύτερη απόδοση. Τέλος, επιβεβαιώνουμε την αποτελεσματικότητα της ομαλοποίησης των ενσωμάτωσης λέξεων σε σταθερό μήκος (ΦΑΞΟΡΜ). Σε πέντε μεταφραστικά ζεύγη χαμηλών πόρων από σώματα βασισμένα στο TED Talks, αυτές οι αλλαγές συγκλίνουν πάντα, δίνοντας ένα μέσο +1.1 BLEU πάνω από τις υπερσύγχρονες δίγλωσσες γραμμές βάσης και ένα νέο 32.8 BLEU στο IWSLT '15 Αγγλικά-Βιετναμέζικα. Εξυπηρετούμε πιο αιχμηρές καμπύλες απόδοσης, πιο συνεπείς κανόνες διαβάθμισης, και μια γραμμική σχέση μεταξύ κλίμακας ενεργοποίησης και βάθους αποκωδικοποιητή. Παραδόξως, στο περιβάλλον υψηλών πόρων (WMT '14 Αγγλικά-Γερμανικά), οι SCALENORM και FIXNORM παραμένουν ανταγωνιστικές, αλλά η PRENORM υποβαθμίζει την απόδοση.", 'hu': "Három egyszerű, normalizációs központú változást értékelünk a Transformer képzés javítása érdekében. Először is megmutatjuk, hogy a pre-norm residue connections (PRENORM) és a kisebb inicializációk lehetővé teszik a warmup-mentes, validációs alapú képzést nagy tanulási aránnyal. Másodszor, javasoljuk az l2 normalizálást egyetlen skála paraméterrel (SCALENORM) a gyorsabb edzés és a jobb teljesítmény érdekében. Végül megerősítjük a szóbeágyazások fix hosszúságú normalizálásának hatékonyságát (FIXNORM). A TED Talks-alapú corpora öt alacsony erőforrású fordítási párján ezek a változások mindig konvergálnak, így átlagosan +1,1 BLEU-t eredményeznek a korszerű kétnyelvű alapvonalakon és egy új 32,8 BLEU-t eredményeznek az IWSLT '15 angol-vietnámi nyelven. Élesebb teljesítmény görbéket, konzisztensebb gradiens normákat, valamint lineáris kapcsolatot biztosítunk az aktiválási skálázás és a dekóder mélysége között. Meglepő módon a nagy erőforrásokat igénylő (WMT '14 angol-német) környezetben a SCALENORM és a FIXNORM továbbra is versenyképesek maradnak, de a PRENORM csökkenti a teljesítményt.", 'it': "Valutiamo tre semplici cambiamenti centrati sulla normalizzazione per migliorare l'allenamento Transformer. In primo luogo, mostriamo che le connessioni residue pre-norm (PRENORM) e le inizializzazioni più piccole consentono una formazione basata sulla convalida senza calore con grandi tassi di apprendimento. In secondo luogo, proponiamo la normalizzazione l2 con un singolo parametro di scala (SCALENORM) per un allenamento più veloce e migliori prestazioni. Infine, ribadiamo l'efficacia di normalizzare le incorporazioni di parole a una lunghezza fissa (FIXNORM). Su cinque coppie di traduzioni a basso contenuto di risorse provenienti da corpora basate su TED Talks, questi cambiamenti convergono sempre, dando una media di +1,1 BLEU su basi bilingue all'avanguardia e un nuovo BLEU 32,8 su IWSLT '15 inglese-vietnamita. Serviamo curve di prestazione più nitide, norme di gradiente più coerenti e una relazione lineare tra la scala di attivazione e la profondità del decoder. Sorprendentemente, nell'impostazione ad alto contenuto di risorse (WMT '14 inglese-tedesco), SCALENORM e FIXNORM rimangono competitivi ma PRENORM degrada le prestazioni.", 'kk': "Қарапайым, нормализациялау орталық өзгерістерді түрлендіруші бақылауын жақсарту үшін бағалаймыз. Біріншіден, біз нормалардың алдындағы қалдық қосылымдарды (PRENORM) және кіші инициализациялаулары үлкен оқыту жиіліктері менен жұмсау бос, тексеру бағдарламасын қолдануға мүм Екіншіден, біз l2 параметрін бір масштаб параметрімен (SCALENORM) жылдам оқыту және жақсы оқыту үшін нормализациялауды ұсындық. Соңында біз сөздерді ендіру үшін (FIXNORM) дұрыс ұзындығына нормализациялау мүмкіндігін қайта құптаймыз. TED Talks-based корпорасынан бес ресурстардың төменгі аудармалардың екі жолында, бұл өзгерістер әрқашанда біріктірілген, орташа +1,1 BLEU және IWSLT'15 ағылшын-Вьетнамша жаңа 32,8 BLEU болады. Біз көзгертіп жатқан жылдамдық қисықтарын, көзгертілген градиенттің нормаларын және белсендік масштабтау мен декодердің тереңдігін арасындағы сызық қатынасыз. Бірақ қызықты, жоғары ресурс параметрлерінде (WMT '14 ағылшын тілінде) SCALENORM және FIXNORM бағдарламалық болып тұр, бірақ PRENORM жылдамдығын бағалады.", 'lt': "Vertiname tris paprastus, normalizacijos centrinius pokyčius, siekiant pagerinti Transformuotojų mokymą. Pirma, mes parodome, kad likutinės jungtys prieš norm ą (PRENORM) ir mažesnės inicializacijos sudaro sąlygas mokymui be šildymo, pagrįstam patvirtinimu ir dideliu mokymosi tempu. Antra, siūlome normalizuoti l2 su vienu skalės parametru (SCALENORM) greitesniam mokymui ir geresniam veiksmingumui. Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM).  Penkių nedidelių išteklių vertimo poros iš TED kalbomis pagrįstos korporacijos pokyčiai visada konvergencija, duodant vidutinį +1,1 BLEU virš naujausių dvikalbių bazinių linijų ir naują 32,8 BLEU virš IWSLT 15 anglų ir vietnamų kalbų. Mes serveriame a štresnes veikimo kreives, nuoseklesnes gradientines normas ir linijinį ryšį tarp aktyvavimo skalės ir dekoderio gylio. Įspūdinga, kad didelių išteklių aplinkoje (WMT '14 anglų-vokiečių), SCALENORM ir FIXNORM išlieka konkurencingos, tačiau PRENORM mažina veiklos rezultatus.", 'ms': "Kami menilai tiga perubahan sederhana, pusat normalisasi untuk meningkatkan latihan Transformer. Pertama, kita tunjukkan bahawa sambungan residual pre-norm (PRENORM) dan awalkan lebih kecil memungkinkan latihan bebas pemanasan, berdasarkan pengesahihan dengan kadar belajar yang besar. Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance.  Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM).  On five low-resource translation pairs from TED Talks-based corpora, these changes always converge, giving an average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT '15 English-Vietnamese.  Kami ob- melayani lengkung prestasi yang lebih tajam, norm gradien yang lebih konsisten, dan hubungan linear antara pemindahan aktivasi dan kedalaman dekoder. Yang mengejutkan, dalam tetapan sumber-tinggi (WMT '14 Inggeris-Jerman), SCALENORM dan FIXNORM tetap bersaing tetapi PRENORM mengurangkan prestasi.", 'mk': "Ги проценуваме трите едноставни, нормализациски промени за подобрување на тренингот на трансформерот. Прво, покажуваме дека пренормалните резултатни врски (PRENORM) и помалите иницијализации овозможуваат обука без загревање, базирана на валидација со големи стапки на учење. Второ, предложуваме нормализација на l2 со еден параметр на скала (SCALENORM) за побрзо обука и подобра перформанса. Конечно, ја потврдиме ефикасноста на нормализирањето на вложувањата на зборови на фиксна должина (FIXNORM). На пет парови на превод со ниски ресурси од телефонот на TED Talks, овие промени секогаш се конверзираат, давајќи просечно +1,1 БЛЕ над најсовремените двојјазични основни линии и нова 32,8 БЛЕ на IWSLT '15 англиско-виетнамски. Ние об- служиме поостри криви на перформанса, поконстантни градиентни норми, и линијарна врска помеѓу активирање скалирање и длабочина на декодерот. Изненадувачки, во поставувањето на високи ресурси (WMT '14 англиско-германски), SCALENORM и FIXNORM остануваат конкурентни, но PRENORM ја деградира изведбата.", 'mt': "We evaluate three simple, normalization-centric changes to improve Transformer training.  L-ewwel nett, nuru li konnessjonijiet residwi qabel in-normi (PRENORM) u inizjalizzazzjonijiet iżgħar jippermettu taħriġ mingħajr sħana bbażat fuq il-validazzjoni b’rati kbar ta’ tagħlim. It-tieni nett, nipproponu normalizzazzjoni l2 b’parametru ta’ skala waħda (SCALENORM) għal taħriġ aktar mgħa ġġel u prestazzjoni aħjar. Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM).  On five low-resource translation pairs from TED Talks-based corpora, these changes always converge, giving an average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT '15 English-Vietnamese.  We ob- serve sharper performance curves, more consistent gradient norms, and a linear relationship between activation scaling and decoder depth.  Surprisingly, in the high-resource setting (WMT '14 English-German), SCALENORM and FIXNORM remain competitive but PRENORM degrades performance.", 'ml': "മൂന്നു എളുപ്പമുള്ള, സാധാരണ മാറ്റങ്ങള്\u200d മുന്നോട്ട് പരിശീലിക്കാനുള്ള മാറ്റങ്ങള്\u200d ഞങ്ങള്\u200d വിലയിച് First, we show that pre-norm residual connections (PRENORM) and smaller initializations enable warmup-free, validation-based training with large learning rates.  രണ്ടാമത്തേത്, ഒരു സ്കേല്\u200d പരാമീറ്റര്\u200d (SCALENORM) വേഗത്തില്\u200d പഠിപ്പിക്കുന്നതിനും നല്ല പ്രവര്\u200dത്തനങ്ങള്\u200dക്കും വേണ്ടി നാം l2 സാ അവസാനം, വാക്കുകള്\u200d സാധാരണമാക്കുന്ന വാക്കുകള്\u200d നിശ്ചയിക്കുന്നതിന്\u200dറെ പ്രഭാവം നമ്മള്\u200d പുനരുത്ഥാപിക്കുന്നു. ടെഡി സംസാരം അടിസ്ഥാനമായ കോര്\u200dപ്പോരിയില്\u200d നിന്നുള്ള അഞ്ച് കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഗങ്ങളില്\u200d നിന്നും ഈ മാറ്റങ്ങള്\u200d എപ്പോഴും മാറ്റുന്നു. സ്റ്റേറ്റ് +1. 1 ബെല്യൂ സ്റ നമ്മള്\u200d കൂടുതല്\u200d പ്രദര്\u200dശനത്തിന്റെ കയറുകള്\u200d സേവിക്കുന്നു, കൂടുതല്\u200d സ്ഥിരമായ ഗ്രേഡിയന്\u200d നിയമങ്ങള്\u200d, പ്രവര്\u200dത്തിപ്പിക്കുന്നതിന് അത്ഭുതപ്പെട്ടു കൊണ്ട്, ഉയര്\u200dന്ന വിഭവങ്ങളുടെ (WMT '14 ഇംഗ്ലീഷ്-ജര്\u200dമ്മന്\u200d), SCALENORM, FIXNORM എന്നിട്ടും മത്സരിക്കുന്നുണ്ട്, പക്ഷെ പ്രെ", 'mn': "Бид Трансформерийн сургалтыг сайжруулахын тулд гурван энгийн, нормализацийн төв өөрчлөлтийг үнэлдэг. Эхлээд бид нормын өмнө үлдсэн холбоотой холбоотой (PRENORM) болон жижиг эхлүүлэлт нь дулаан чөлөөгүй, шалгалтгүй суралцах боломжтой болно. Хоёрт, бид l2-г хурдан суралцах болон илүү сайн үйл ажиллагааны тулд нэг хэмжээний параметр (SCALENORM) хурдан хэмжээтэй нормализацийг санал болгоно. Эцэст нь, бид үг нэвтрүүлэх нь тодорхой урттай (FIXNORM) гэсэн үр дүнг дахин баталдаг. TED Talks-ын корпора-ын таван бага боловсролын хөрөнгө оруулалт дээр энэ өөрчлөлт үргэлж холбогдож байдаг. Энэ нь дундаж +1.1 BLEU-г хоёр хэлний суурь шугам болон IWSLT-ийн 15 Англи-Вьетнамчууд дээр шинэ 32.8 BLEU-г өгдөг. Бид илүү хурдан ажиллагааны муруй, илүү тогтвортой градиент нормууд, эсвэл ажиллагааны масштаб болон загварын гүнзгий хоорондын шулуун холбоотой. Гайхалтай нь, WMT '14 Англи хэлний Германы хэмжээнд SCALENORM болон FIXNORM өрсөлдөөнтэй ч PRENORM үйл ажиллагааг багасгаж байна.", 'ro': "Evaluăm trei schimbări simple, centrate pe normalizare pentru a îmbunătăți formarea Transformer. În primul rând, arătăm că conexiunile reziduale pre-norm (PRENORM) și inițializările mai mici permit formarea fără warmup, bazată pe validare, cu rate mari de învățare. În al doilea rând, propunem normalizarea l2 cu un singur parametru de scară (SCALENORM) pentru antrenament mai rapid și performanță mai bună. În cele din urmă, reafirmăm eficacitatea normalizării încorporărilor de cuvinte la o lungime fixă (FIXNORM). Pe cinci perechi de traduceri cu resurse reduse de la corpore bazate pe TED Talks, aceste schimbări converg întotdeauna, oferind o medie de +1,1 BLEU peste liniile de bază bilingve de ultimă generație și un nou BLEU 32,8 pe IWSLT '15 engleză-vietnameză. Obținem curbe de performanță mai clare, norme de gradient mai consistente și o relație liniară între scalarea activării și adâncimea decodorului. Surprinzător, în mediul cu resurse ridicate (WMT '14 engleză-germană), SCALENORM și FIXNORM rămân competitive, dar PRENORM scade performanța.", 'no': 'Vi evaluerer tre enkle, normaliserte endringar for å forbetra transformeringstrening. Først viser vi at første tilkoplingar (PRENORM) og mindre initialiseringar kan slå på oppvarming frå varmar, validasjonsbasert trening med stor læringsrate. Andre, vi foreslår l2- normalisering med ein enkelt skala parameter (SCALENORM) for raskare opplæring og bedre utvikling. I slutt stemmer vi på nytt effektiviteten for å normalisera ordinnbygging til ein fast lengd (FIXNORM). På fem låg ressursomsetjingar frå TED Talks-basert korpora blir desse endringane alltid samanlikna, og gjev eit gjennomsnittlig +1,1 BLEU over bilinguelt baselinjer og ein ny 32,8 BLEU på IWSLT-15 engelsk-Vietnamsk. Vi tjener skarpere funksjonskurver, meir konsistent fargeovergangssnorme, og ein lineær forhold mellom aktiveringsskalering og dekoderdybde. I høg ressursinnstillinga (WMT « 14 engelsk- tysk ») er SCALENORM og FIXNORM fortsatt konkurrentivt, men PRENORM forvrer utviklinga.', 'pl': "Oceniamy trzy proste, normalizacyjne zmiany w celu usprawnienia treningu Transformera. Po pierwsze, pokazujemy, że pre-normowe połączenia rezydualne (PRENORM) i mniejsze inicjalizacje umożliwiają szkolenie bez rozgrzewania, oparte na walidacji z dużym współczynnikiem uczenia się. Po drugie proponujemy normalizację l2 z jednym parametrem skali (SCALENORM) dla szybszego treningu i lepszej wydajności. Wreszcie potwierdzamy skuteczność normalizacji osadzeń słów na stałą długość (FIXNORM). W pięciu parach tłumaczeń opartych na TED Talks, zmiany te zawsze zbiegają się, dając średnią +1.1 BLEU na najnowocześniejszych dwujęzycznych liniach bazowych i nową 32.8 BLEU na IWSLT 15 angielsko-wietnamski. Obsługujemy ostrzejsze krzywe wydajności, bardziej spójne normy gradientowe oraz liniową zależność między skalowaniem aktywacji a głębokością dekodera. Co zaskakujące, w warunkach wysokich zasobów (WMT '14 angielsko-niemiecki), SCALENORM i FIXNORM pozostają konkurencyjne, ale PRENORM pogarsza wydajność.", 'sr': "Procjenjujemo tri jednostavne, normalizacione centrske promene kako bi poboljšali obuku transformera. Prvo pokazujemo da prenormalne ostatke veze (PRENORM) i manje inicijalizacije omogućavaju obuku na osnovu zagrijavanja, osnovanu na validaciji sa velikim stopama učenja. Drugo, predlažemo normalizaciju l2 sa jednim parametrom skale (SCALENORM) za brže obuku i bolju funkciju. Konačno potvrđujemo učinkovitost normaliziranja reči ugrađenja na određenu dužinu (FIXNORM). Na pet parova za prevođenje niskih resursa iz tela na TED Talks-u, te promjene se uvijek skupljaju, dajući prosječnu +1,1 BLEU preko dvojezičkih osnovnih linija države umjetnosti i novu 32,8 BLEU na IWSLT'15 engleski vijetnamski. Ob-služimo oštre krive performansije, konsekvencijske norme gradient a i linearnu vezu između aktivacije skaliranja i dubine dekodera. Iznenađujuće, u središtu visokog resursa (WMT '14 engleski-nemački), SCALENORM i FIXNORM ostaju konkurentni, ali PRENORM smanjuje učinkovitost.", 'so': "Waxaannu qiimeynaynaa saddex iskuul oo fudud, isbedelka barbaarinta dhexe si loo horumariyo waxbarashada soo wareegista. Marka ugu horeysa waxaynu tusnaynaa in xiriirka deganaanshaha ee hore (PRENORM) iyo bilowga yar waxay qaban karaan waxbarasho lacag la’aan ah oo shaqeyn kara qiimaha waxbarashada. Second, waxaynu soo jeedaynaa in I2 la soo caadi karo heer isku mid ah (SCALENORM) oo loo sameynayo waxbarasho dhaqso iyo sameynta wanaagsan. Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM).  Shan qof oo hoos-resource turjumista ah oo ka yimid shirkadaha TED Talks-based, waa beddelaadka mar walba, waxayna siisaa average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT '15 Ingiriis-Vietnamese. Waxaynu u adeegnaa qalabka muuqashada si sharaf ah, si ka sii daran qaababka heerka, iyo xiriirka xiliga ah oo u dhexeeya qiyaastiisa iyo moolka deynta. Waan la yaabaa, marka lagu qoro heerka sare resource (WMT '14 Ingiriis-German), SCALENORM iyo FIXNORM waxay sii socdaan tartank, laakiin PRENORM ayaa hooseeya sameynta.", 'sv': "Vi utvärderar tre enkla, normaliseringscentrerade förändringar för att förbättra Transformers träning. Först visar vi att pre-norm residue connections (PRENORM) och mindre initialiseringar möjliggör warmup-fri, valideringsbaserad träning med stora inlärningsfrekvenser. För det andra föreslår vi l2 normalisering med en enda skalparameter (SCALENORM) för snabbare träning och bättre prestanda. Slutligen bekräftar vi effektiviteten av att normalisera ordinbäddningar till en fast längd (FIXNORM). På fem översättningspar med låg resurs från TED Talks-baserade corpora konvergerar dessa förändringar alltid, vilket ger en genomsnittlig +1,1 BLEU över toppmoderna tvåspråkiga baslinjer och en ny 32,8 BLEU på IWSLT '15 engelsk-vietnamesiska. Vi levererar skarpare prestandakurvor, mer konsekventa gradientnormer och ett linjärt förhållande mellan aktiveringsskalning och avkodningsdjup. Överraskande nog är SCALENORM och FIXNORM fortfarande konkurrenskraftiga i högresursinställningen (WMT '14 engelsk-tyska), men PRENORM försämrar prestandan.", 'ta': "மாற்று பயிற்சியை மேம்படுத்த மூன்று எளிமையான, சாதாரண மாற்றங்களை மதிப்பிடுகிறோம். முதலில், நாம் முன் சாதாரண மீதி இணைப்பு Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance.  இறுதியில், நாம் ஒரு நிலையான நீளத்திற்கு வார்த்தைகளை இயல்பாக்கும் விளைவு TED பேச்சுகளை அடிப்படையிலிருந்து ஐந்து குறைந்த மொழிமாற்றி ஜோடிகளில் இந்த மாற்றங்கள் எப்போதும் மாற்றுகிறது, சராசரி  +1. 1 பிலியு நிலையில் இரு மொழிமொழிகள் அடிப்படைகளி நாங்கள் கூடுதலாக செயல்பாட்டு குறுக்குக்குறியீடுகளை சேவைப்போம், மேலும் நிலையான சாய்ந்த குறிப்புகள் மற்றும் செயல் அதிகப்பெரிய மூலம் அமைப்பில் (WMT '14 ஆங்கிலத்தில்- ஜெர்மன்லம்), SCALENORM மற்றும் FIXNORM போராட்டியில் இருக்கிறார்", 'ur': "ہم تین سادھی، عاملی-منطقی تغییرات کو تغییر دینے کے لئے تغییر دینے کے لئے ارزش کرتے ہیں. پہلی بار، ہم نشان دیتے ہیں کہ پیش نورمی باقی رہنے والی اتصال (PRENORM) اور چھوٹی آغاز کے ساتھ گرماپ بے نیاز، والدیسی بنیاد کی تعلیم بڑی تعلیم کے ساتھ کرتی ہے۔ دوسرا، ہم ایک اسکیل پارامیٹر (SCALENORM) کے ذریعہ ایک دوسرے کی تعلیم اور بہترین عملکرد کے لئے l2 عام کرنا پیشنهاد کرتے ہیں. آخر میں، ہم ایک ثابت قدم تک (FIXNORM) لفظ کے مطابقت کی تائید کرتے ہیں۔ TED Talks-based corpora سے پانچ کم منبع ترجمہ جوڑے پر یہ تبدیلی ہمیشہ متصل ہوتے ہیں، اور ان کے متوسط +1.1 بلیوس کو دوسری زبان باندلین پر اور IWSLT'15 انگلیسی ویتنامی پر ایک نئی 32.8 بلیوس دیتے ہیں. ہم تیز عملکرد کروٹوں کی خدمت کرتے ہیں، بہت سیدھی گریڈینٹ کے نوروں اور فعالیت کے اسکیل اور ڈکور کی عمیق کے درمیان ایک لینی رابطہ کرتے ہیں. عجیب ہے، بلند سرمایہ (WMT '14 انگلیسی-جرمن) میں، SCALENORM اور FIXNORM مسابقات رہتے ہیں لیکن PRENORM عملکرد کو ذلت دیتا ہے.", 'si': "අපි සරල, සාමාන්\u200dය විද්\u200dයාපිත වෙනස් තුනක් විශ්වාස කරන්න පුළුවන් වෙනුවෙන්. මුලින්ම, අපි පෙන්වන්නේ මුලින්ම සාමාන්\u200dය විශාල සම්බන්ධතාවය (PRENORM) සහ පොඩි පටන් ගන්න පුළුවන් විතරයි, ගොඩක් ඉගෙන ග දෙවනිය, අපි ඉක්මනින් ප්\u200dරශ්නයක් සහ හ හොඳ ප්\u200dරශ්නයක් සඳහා l2 සාමාන්\u200dය විශ්වාස කරන්න පුළුවන්. අන්තිමේදී, අපි ආයෙත් ප්\u200dරශ්නයක් කරනවා වචන සාමාන්\u200dය විශ්වාස කරනවා කියලා (FIXNORM). TED Talks-based Corp එකෙන් අඩුම සම්පත්ත පහයින් අනුවාර්ථක පහයින්, මේ වෙනස් හැමවෙලාවම සම්බන්ධ වෙනවා, සාමාන්\u200dය +1.1 BLUE දෙනවා +1.1 BLUE දෙන්නේ ජාතියේ දුවන්ත අපි අබ- සේවා විශාල ප්\u200dරභාව කුරුවල්, විශාල සාමාන්\u200dය විධානයක්, සක්\u200dරියාත්මක විශාල සහ සංවිධානයක් අතර ස පුදුම විදිහට, අධ්\u200dයම ප්\u200dරධාන සැකසුම (WMT '14 ඉංග්\u200dරීසි ජර්මාන්ස්-ජර්මාන්), SCALENORM සහ FIXNORM තර්ජනය කරනවා නමුත් PRENORM ප", 'uz': "Biz uchta oddiy, normal, markaziy o'zgarishlarni o'zgartirish uchun o'qiymatimiz. Birinchi ko'rib, biz oddiy oddiy qo'llanmalar (PRENORM) va kichik ishlayotlarni o'rganish qismi foydalanishini katta ta'lim qismi darajasi bilan ishlatishga ega bo'ladi. Ikkinchi so'zda, biz bir qolip parametr bilan l2 normalization soni tahlil qilamiz va yaxshi bajarish uchun. Oxirgi, biz oddiy soʻzni o'zgartirish qobiliyatiga (FIXNORM) qayta ishlatimiz. @ info: whatsthis Biz qo'shimcha bajarish vositasiga qaror qilamiz, ko'proq gradient qoidalariga, va aktivlashtirish va kodlash qobiliyati orasidagi qo'shiq munosabati. Shunday qilib, juda qiziqarli manba tarkibi (WMT '14 Ingliz-Olmoncha), SCALENORM va FIXNORM taxminan bo'ladi, lekin PRENORM bajarishni taxminan qiladi.", 'vi': "Chúng tôi đánh giá ba thay đổi đơn giản, bình thường trung tâm để cải thiện huấn luyện transformer. Thứ nhất, chúng tôi cho thấy các kết nối còn lại trước tiêu chuẩn (prenorM) và nhỏ hơn trước khi khởi tạo cho phép mở khóa gia nhập mở rộng. Thứ hai, chúng tôi đề nghị La-2 bình thường với một tham số quy mô duy nhất (SCALENORM) cho việc huấn luyện nhanh hơn và hiệu suất tốt hơn. Cuối cùng, chúng tôi xác nhận lại hiệu quả của việc làm hoá các từ nối dài cố định (FIXNORM). Trên năm cặp phiên dịch ít tài nguyên từ bằng lái bằng tiếng Latin, những thay đổi này luôn hội tụ, cho thấy có trung bình « 1.nguyên bản hai thứ được ưa thích và một chân dung mới 32.8 tiếng Anh trên IWSLT'(15 English-Việt). Chúng tôi có thể phục vụ các đường cong hiệu suất sắc hơn, các tiêu chuẩn chuẩn dốc hơn nhiều, và một mối quan hệ tuyến tính giữa kích hoạt và độ sâu giải mã. Ngạc nhiên là, trong môi trường cao tài nguyên (WRT'14-Đức), SCALENORM và FIXNORM vẫn còn cạnh tranh cạnh tranh, nhưng sơ bộ làm mất hiệu suất.", 'nl': "We evalueren drie eenvoudige, normalisatie-gerichte veranderingen om Transformer training te verbeteren. Eerst laten we zien dat pre-norm residual connections (PRENORM) en kleinere initialisaties warmup-vrije, validatie-gebaseerde training met grote leersnelheden mogelijk maken. Ten tweede stellen we l2 normalisatie voor met een enkele schaalparameter (SCALENORM) voor snellere training en betere prestaties. Tot slot bevestigen we opnieuw de effectiviteit van het normaliseren van woordinbeddingen tot een vaste lengte (FIXNORM). Op vijf low-resource vertaalparen van TED Talks gebaseerde corpora's convergeren deze veranderingen altijd, waardoor een gemiddelde +1.1 BLEU over state-of-the-art tweetalige basislijnen en een nieuwe 32.8 BLEU op IWSLT '15 Engels-Vietnamees. We bieden scherpere prestatiecurven, consistentere gradiëntennormen en een lineaire relatie tussen activeringsschaal en decoderdiepte. Verrassend genoeg blijven SCALENORM en FIXNORM concurrerend in de omgeving met hoge resources (WMT '14 Engels-Duits), maar PRENORM verslechtert de prestaties.", 'hr': "Procjenjujemo tri jednostavne, normalizacije-centrske promjene kako bi poboljšali obuku transformera. Prvo pokazujemo da prenormalne ostatke veze (PRENORM) i manje inicijalizacije omogućavaju obuku na osnovu zagrijavanja, osnovanu na validaciji s velikim stopama učenja. Drugo, predlažemo normalizaciju l2 s jednom parametrom skale (SCALENORM) za brže obuku i bolju učinku. Konačno potvrđujemo učinkovitost normalizacije ugrađenja riječi na određenu dužinu (FIXNORM). Na pet par prevoda s niskim resursima iz tela na temelju TED razgovora, te promjene se uvijek skupljaju, dajući prosječnu +1,1 BLEU preko dvojezičkih početnih linija države umjetnosti i novu 32,8 BLEU na IWSLT'15 engleski vijetnamski. Ob-služimo oštre zavjese učinkovitosti, konsekvencijske norme gradient a i linearnu vezu između skaliranja aktivacije i dubine dekodera. Iznenađujuće, u središtu visokog resursa (WMT '14 engleski-njemački), SCALENORM i FIXNORM ostaju konkurentni, ali PRENORM smanjuje učinkovitost.", 'da': "Vi evaluerer tre enkle, normalisering-centrerede ændringer for at forbedre Transformer træning. For det første viser vi, at pre-norm restforbindelser (PRENORM) og mindre initialiseringer muliggør varmefri, valideringsbaseret træning med store læringsrater. For det andet foreslår vi l2 normalisering med en enkelt skala parameter (SCALENORM) for hurtigere træning og bedre ydeevne. Endelig bekræfter vi effektiviteten af at normalisere ordindlejringer til en fast længde (FIXNORM). På fem oversættelsespar med lav ressource fra TED Talks-baserede corpora konvergerer disse ændringer altid, hvilket giver en gennemsnitlig +1,1 BLEU over state-of-the-art tosprogede baselines og en ny 32,8 BLEU på IWSLT '15 engelsk-vietnamesisk. Vi tjener skarpere præstationskurver, mere ensartede gradientnormer og et lineært forhold mellem aktiveringsskalering og dekoder dybde. Overraskende nok forbliver SCALENORM og FIXNORM konkurrencedygtige i de høje ressourcer-indstillinger (WMT '14 engelsk-tysk), men PRENORM forringer ydeevnen.", 'id': "Kami mengevaluasi tiga perubahan sederhana, normalisasi-sentrik untuk meningkatkan pelatihan Transformer. Pertama, kita menunjukkan bahwa koneksi residual pre-norm (PRENORM) dan inisialisasi lebih kecil memungkinkan pelatihan bebas pemanasan, berdasarkan validasi dengan tingkat belajar besar. Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance.  Akhirnya, kita mengkonfirmasi ulang efektivitas dari normalisasi pembenaman kata ke panjang tertentu (FIXNORM). Pada lima pasangan terjemahan sumber daya rendah dari korpora berdasarkan TED Talks, perubahan ini selalu berkonversi, memberikan rata-rata +1.1 BLEU atas garis dasar dua bahasa terbaik dan 32.8 BLEU baru pada IWSLT '15 Inggris-Vietnam. Kami ob- melayani kurva prestasi yang lebih tajam, norm gradien yang lebih konsisten, dan hubungan linear antara skala aktivasi dan kedalaman dekoder. Mengejutkan, dalam pengaturan sumber daya tinggi (WMT '14 Inggris-Jerman), SCALENORM dan FIXNORM tetap kompetitif tetapi PRENORM merusak prestasi.", 'ko': "우리는 변압기 교육을 개선하기 위해 간단하고 규범화된 세 가지 변경 사항을 평가했다.우선, 예비 규범 잉여 연결(PRENORM)과 비교적 작은 초기화는 예열이 없고 검증에 기반한 훈련을 실현할 수 있으며 비교적 높은 학습률을 가지고 있음을 나타낸다.그 다음으로 우리는 훈련 속도와 성능을 향상시키기 위해 단척도 파라미터(SCALENORM)를 사용하여 l2규범화하는 것을 권장한다.마지막으로 단어 삽입을 고정 길이(FIXNORM)로 규범화하는 유효성을 재확인했다.TED 대화 자료 라이브러리를 바탕으로 하는 다섯 쌍의 저자원 번역 대조에서 이러한 변화는 항상 일치한다. 가장 선진적인 이중 언어 기선에서 평균 +1.1 BLEU, IWSLT'15 영어-베트남어에서 평균 32.8 BLEU이다.우리는 더욱 뚜렷한 성능 곡선, 더욱 일치하는 사다리 규범, 그리고 축소와 디코더 깊이 간의 선형 관계를 활성화합니다.놀랍게도 고자원 환경(WMT'14영덕)에서 SCALENORM과 FIXNORM은 여전히 경쟁력을 가지고 있지만 PRENORM은 성능을 떨어뜨린다.", 'de': "Wir evaluieren drei einfache, normalisierungsorientierte Änderungen, um das Transformer-Training zu verbessern. Zunächst zeigen wir, dass Pre-Norm Residual Connections (PRENORM) und kleinere Initialisierungen warmup-freies, validationsbasiertes Training mit großen Lernraten ermöglichen. Zweitens schlagen wir eine l2-Normalisierung mit einem einzigen Skalenparameter (SCALENORM) für schnelleres Training und bessere Leistung vor. Abschließend bekräftigen wir die Wirksamkeit der Normalisierung von Worteinbettungen auf eine feste Länge (FIXNORM). Bei fünf ressourcenarmen Übersetzungspaaren aus TED Talks-basierten Korpora konvergieren diese Änderungen immer, was eine durchschnittliche +1.1 BLEU über modernste zweisprachige Baselines und eine neue 32.8 BLEU auf IWSLT '15 Englisch-Vietnamesisch ergibt. Wir bieten schärfere Leistungskurven, konsistentere Gradientennormen und eine lineare Beziehung zwischen Aktivierungsskalierung und Dekodiertiefe. Überraschenderweise bleiben SCALENORM und FIXNORM im ressourcenintensiven Umfeld (WMT '14 Englisch-Deutsch) wettbewerbsfähig, aber PRENORM verschlechtert die Leistung.", 'bg': 'Оценяваме три прости, ориентирани към нормализация промени, за да подобрим обучението на трансформаторите. Първо, показваме, че преднормативните остатъчни връзки (ПРЕНОРМ) и по-малките инициализации позволяват обучение без загряване, базирано на валидиране с големи темпове на обучение. Второ, предлагаме нормализиране с единичен скален параметър (СКАЛЕНОРМ) за по-бързо обучение и по-добра производителност. И накрая, потвърждаваме ефективността на нормализирането на вгражданията на думи с фиксирана дължина (ФИКСНОРМ). На пет двойки преводи с нисък ресурс от корпуси базирани на TED Talks, тези промени винаги се сближават, давайки средно +1.1 БЮ над най-съвременните двуезични базови линии и нов 32.8 БЮ на английски-виетнамски език. Ние обслужваме по-остри криви на производителността, по-последователни градиентни норми и линейна връзка между активационното мащабиране и дълбочината на декодера. Изненадващо, в обстановката на високите ресурси (английски-немски) СКАЛЕНОРМ и ФИКСНОРМ остават конкурентни, но ПРЕНОРМ влошава производителността.', 'tr': "Biz üç basit, düzenlemek-centrik üýtgewleri Transformer eğitimi geliştirmek üçin deňleýäris Ilkinji gezek, norm öňündeki çykyş baglaýyşlaryň (PRENORM) we kiçi başlangyşlaryň ısınmadan boş, uly öwrenmek derejesi bilen daýratyn taýýarlamasyny mümkin edýändigini görkez. Ikinjisi, bizler l2'i çalt okuwçylyk we gowylaşdyrmak üçin ýeke ölçekli paraýatçy bilen (SCALENORM) düzenlemegi teklip edýäris. Soňunda, sözleriň daňyrylygynyň täsirini sabitlendiriň (FIXNORM). TED Gürüşmeler tabanly korporatyň beş sany iň az karýerasy terjime eden çift sanynda bu üýtgeşmeler hemişe birleşýär. Bu üýtgeşmeler hemişe ortalama +1.1 BLEU iki dilli terjime eden döwletlerde we Täze 32.8 BLEU IWSLT '15 IWSLT iňlis we ýetnamlarda bolýar. Biz keskin etkinlik kurbaları, daha konsistentli gradient normları ve aktivasyon skalasy ve dekoder derinliği arasında bir çizgi ilişki yaratırız. Gynansakda, ýokary resurslar gurulmasynda (WMT '14 Iňlis-Almança), SCALENORM we FIXNORM duşuşykly bolýar ýöne PRENORM ukyp gaýd edýär.", 'fa': 'ما سه تغییر ساده و مرکز عادی را برای تغییر تغییر دهنده ارزیابی می کنیم. اول، ما نشان می دهیم که ارتباطات باقی مانده\u200cهای پیش\u200cنورمی (PRENORM) و آغاز کوچک\u200cهای کوچکتر، آموزش\u200cهای بی\u200cگرم و باقی مانده\u200cی تأیید با نرخ\u200cهای یادگیری بزرگ را اجازه می\u200cدهند. دوم، ما برای تمرین سریعتر و عملکرد بهتر l2 را با یک مقیاس مقیاس (SCALENORM) پیشنهاد می\u200cکنیم. بالاخره، ما تایید می\u200cکنیم فعالیت سازی کلمه\u200cها به طول ثابت (FIXNORM). در پنج جفت ترجمه کم منابع از شرکت متحد TED Talks، این تغییرات همیشه متصل می شوند، و این تغییرات همیشه متوسط +1.1 BLEU بر اساس خط\u200cهای زیر زبان\u200cهای دوزبان هنر و ۲۲.۸ BLEU جدید بر اساس IWSLT ۱۵ انگلیسی-ویتنام می\u200cدهند. ما تقویم عملکرد ترین را خدمت می\u200cکنیم، نورمهای گراده\u200cهای پایدار تر و یک رابطه خطی بین مقیاس فعالیت و عمیق dekoder. تعجب کننده است که در تنظیم منابع بالا (WMT ۱۴ انگلیسی-آلمانی) SCALENORM و FIXNORM مسابقه\u200cای باقی می\u200cمانند ولی PRENORM عملکرد را نابود می\u200cکند.', 'sw': "Tunatathmini mabadiliko matatu rahisi, mabadiliko ya kituo cha kawaida ili kuboresha mafunzo ya zamani. Kwanza, tunaonyesha kuwa mawasiliano ya kubaki ya kawaida (PRENORM) na kuanza kwa kiasi kidogo yanawezesha mafunzo yasiyoeleweka kwa ajili ya kujifunza kwa kiwango kikubwa. Pili, tunapendekeza utaratibu wa l2 kwa kiwango cha kipimo kimoja (SCALENORM) kwa ajili ya mafunzo ya haraka na utendaji bora. Mwisho, tunathibitisha ufanisi wa kuboresha maneno yanayoingia kwa muda mrefu (FIXNORM). Katika utafsiri wa rasilimali mitano chini kutoka kampuni ya mazungumzo yenye makampuni ya TED, mabadiliko haya mara zote hugeuka, kwa wastani +1.1 BLEU juu ya misingi ya lugha mbili za serikali na BLEU mpya 32.8 kwenye IWSLT '15 Kiingereza-Vietnam. Tunatutumia vizuizi vya utendaji vizuri zaidi, utamaduni wa msimamo mkali zaidi, na mahusiano ya msingi kati ya upungufu wa vitendo na kupunguza kina cha kupunguza. Kwa kushangaza, katika mazingira ya rasilimali yenye juu (WMT '14-Kiingereza-Ujerumani), SCALENORM na FIXNORM bado wanaendelea kushindana lakini PRENORM inazidi kushindwa.", 'af': "Ons evalueer drie eenvoudige, normalisering-sentrale veranderinge om Transformer-oefening te verbeter. Eerste, ons wys dat voor-norm oorblyfstelike verbindings (PRENORM) en kleiner inisialiserings aktiveer warming-vry, validatering-gebaseerde onderwerp met groot leer rate. Tweede, ons voorstel l2 normalisering met 'n enkele skaal parameter (SCALENORM) vir vinniger onderwerp en beter prestasie. Eindelik, ons bevestig die effektiviteit van normalisering van woord inbêding na 'n vaste lengte (FIXNORM). Op vyf lae hulpbron vertaling pare van TED Talks-baseerde korpora, hierdie veranderinge het altyd saamgekom, gegee 'n gemiddelde +1.1 BLES oor staat-of-die-kuns twee-tale basilyne en 'n nuwe 32.8 BLEU op IWSLT' 15 Engels-Viëtnamese. Ons bedien skerper prestasie kurves, meer konsistente gradient norme en 'n lineêre verhouding tussen aktivasie skalering en dekoderdiepte. In die hoë-hulpbron-instelling (WMT '14 Engels-Duits), SCALENORM en FIXNORM bly medelykbaar, maar PRENORM vernietig prestasie.", 'sq': "Ne vlerësojmë tre ndryshime të thjeshta, të qëndruara në normalizim për të përmirësuar trajnimin e Transformuesve. Së pari, ne tregojmë se lidhjet e mbetura para norm ës (PRENORM) dhe inicializimet më të vogla mundësojnë trajnim pa ngrohje, bazuar në validim me norma të mëdha mësimi. Së dyti, ne propozojmë normalizimin e l2 me një parameter shkallë të vetëm (SCALENORM) për trajnim më të shpejtë dhe performancë më të mirë. Më në fund, ne reafirmojmë efektshmërinë e normalizimit të përfshirjeve të fjalëve në një gjatësi të caktuar (FIXNORM). Në pesë çifte përkthimi me burime të ulëta nga korpora me bazë në TED Talks, këto ndryshime gjithmonë konvergerojnë, duke dhënë një mesatare +1.1 BLEU mbi linjat bazë dygjuhëse më të larta dhe 32.8 BLEU në IWSLT '15 anglisht-vietnamisht. Ne ob- shërbejmë kurva më të mprehta performancë, normë më konsistente gradient ësh, dhe një marrëdhënie lineare midis shkallëzimit të aktivizimit dhe thellësisë së dekodimit. Për mrekulli, në vendosjen e burimeve të larta (WMT '14 Anglisht-Gjerman), SCALENORM dhe FIXNORM mbeten konkurruese por PRENORM degradon performancën.", 'am': "ሦስት ቀላል፣ የተለመደው ማዕከላዊ ለውጦችን ለማሻሻል እናዋርዳለን፡፡ በመጀመሪያው፣ አስቀድሞ የተቀመጠውን ግንኙነት (PRENORM) እና ትንሹን መጀመሪያ መፍጠር፣ ለትምህርት ፍጥረት ማድረግ በታላቅ ትምህርት ፍጥረት ማድረግ እንዲችል እናሳያቸዋለን፡፡ Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance.  በመጨረሻው፣ የቃላትን አካባቢ አካባቢ (FIXNORM) ለማስተካከል ጥቅም እናደርጋለን፡፡ በአምስት የክፍለ ሀብት ትርጉም ሁለት ከቴድ ንግግር ኮርፖርት፣ እነዚህ ለውጦች ሁልጊዜ ይለውጣሉ፣ ጥሩ +1.1 BLEU በሀገር-የ-art-ሁለት ቋንቋል መደገፊያዎች እና አዲስ 32.8 BLEU IWSLT '15 እንግሊዘኛ-ቪትናምኛ ላይ ነው፡፡ እና በተጨማሪው የሥርዓት ደረጃዎች፣ በተጨማሪው የሥርዓት ትምህርት እና በጥልቅ ጥልቅ መካከል የመስመር ግንኙነት እናገዛለን፡፡ በተደነቀቀ፣ ከፍተኛ resource ማቀናጃ (WMT '14 እንግሊዘኛ-ጀርመን)፣ SCALENORM እና FIXNORM ግን ተቃዋሚው ይኖራል፡፡", 'hy': "Մենք գնահատում ենք երեք պարզ, նորմալիզացիայի կենտրոնական փոփոխություններ, որպեսզի բարելավենք տրանֆերմերների ուսումնասիրությունը: Առաջին հերթին, մենք ցույց ենք տալիս, որ նախանորմալ մնացած կապերը (PRԵՆՕՌՄ) և փոքր ինիցիալիզացիաները հնարավորություն են տաքացման ազատ, հավասարման հիմնված ուսուցում մեծ ուսուցման արագությամբ: Երկրորդ, մենք առաջարկում ենք I2-ի նորմալիզացիա մեկ մակարդակի պարամետրով' ավելի արագ վարժեցման և ավելի լավ արդյունավետության համար: Վերջապես, մենք կրկին հաստատում ենք նորմալ բառերի ներդրումների արդյունավետությունը ֆիքսավոր երկարությամբ (FIXNOMR). TED ելույթների հինգ ցածր ռեսուրսներով թարգմանվող զույգերի վրա այս փոփոխությունները միշտ համընկնում են, տալով միջին +1.1 ԲԼԵՆ-ը ամենաբարձր երկլեզու հիմնական գծերի վրա և նոր 32.8 ԲԼԵՆ-ը 15-ի անգլերեն-վիետնամերեն IwSԼT-ում: We ob- serve sharper performance curves, more consistent gradient norms, and a linear relationship between activation scaling and decoder depth.  Զարմանալի է, որ բարձր ռեսուրսների միջավայրում (14-րդ Անգլերեն-գերմաներեն Աշխարհային Միջազգային Միջազգային Միջազգային Միջազգային Միջազգային Միջազգային Միջազգային Միջազգային Միջա", 'bn': "আমরা তিনটি সাধারণ, স্বাভাবিক কেন্দ্রীয় পরিবর্তনের মূল্য দিচ্ছি ট্রান্সফার্ন প্রশিক্ষণ উন্নতি করা প্রথমত, আমরা দেখাচ্ছি যে পূর্ব স্বাভাবিক সংযোগ (প্রেনোর্ম) এবং ছোট প্রাথমিকভাবে উষ্ণ-মুক্ত, বৈধতা ভিত্তিক প্রশিক্ষণের সা দ্বিতীয়, আমরা একটি স্ক্যালের প্যারামিটার (সাকেলোয়ার্ম) দ্রুত প্রশিক্ষণ এবং ভালো প্রদর্শনের জন্য আই২ স্বাভাবিক প্রস্ত শেষ পর্যন্ত আমরা স্বাভাবিক শব্দের স্বাভাবিক করার কার্যকলাপ পুনরায় পুনরায় জানিয়ে দিচ্ছি (ফিক্সোরাম)। টেডি ভিত্তিক কোর্পোরা থেকে পাঁচটি কম সম্পদ অনুবাদ জোড়ায়, এই পরিবর্তন সবসময়ই পরিবর্তন করে, রাষ্ট্রের দ্বারা শিল্পের দুই ভাষার বেসাইনের উপর গড়ে ১. আমরা শ্রেষ্ঠতর প্রদর্শনীর কার্ভ, আরো সাধারণ গ্রেডিয়েন্ড নীতি এবং সক্রিয় কর্মের ক্যালিং এবং ডিকোডারের গভীরের মধ্যে একটি লাইনিয়া বিস্ময়কর, উচ্চ সম্পদের সেটে (উইএমটি '১৪ ইংরেজী-জার্মান), শ্যালেনোরাম এবং ফিক্সনোরাম প্রতিযোগিতায় থাকে, কিন্তু প্রেনোর্মের প্রত", 'bs': "Procjenjujemo tri jednostavne, normalizacijske centrske promjene kako bi poboljšali obuku transformera. Prvo, pokazujemo da prenormalne ostatke veze (PRENORM) i manje inicijalizacije omogućavaju obuku na osnovu zagrijavanja, osnovanu na validaciji sa velikim stopama učenja. Drugo, predlažemo normalizaciju l2 sa jednim parametrom skale (SCALENORM) za brže obuku i bolju funkciju. Konačno, potvrđujemo učinkovitost normalizacije ugrađenja riječi na određenu dužinu (FIXNORM). Na pet parova za prevod s niskih resursa iz tela na TED Talks-u, te promjene se uvijek skupljaju, dajući prosječnu +1,1 BLEU preko dvojezičkih početnih linija države umjetnosti i novu 32,8 BLEU na IWSLT'15 engleski vijetnamski. Ob-služimo oštre krive performanstva, konsekvencijske norme gradient a i linearnu vezu između skaliranja aktivacije i dubine dekodera. Iznenađujuće, u središtu visokog resursa (WMT '14 engleski-nemački), SCALENORM i FIXNORM ostaju konkurentni, ali PRENORM smanjuje učinkovitost.", 'ca': "Evaluam tres canvis senzills centrats en normalització per millorar l'entrenament de Transformer. En primer lloc, demostram que les connexions residuals pre-normatiques (PRENORM) i les inicialitzacions més petites permeten una formació sense calentament basada en validació amb grans nivells d'aprenentatge. Segon, proposem normalització l2 amb un paràmetre d'escala única (SCALENORM) per a una capacitació més ràpida i un rendiment millor. Finalment, reafirmam l'efectivitat de normalitzar les integracions de paraules a una llargada fixa (FIXNORM). On five low-resource translation pairs from TED Talks-based corpora, these changes always converge, giving an average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT '15 English-Vietnamese.  Servem corbes de rendiment més acutes, normes de gradient més consistents i una relació linear entre l'escala d'activació i la profunditat del decodificador. Surprisingly, in the high-resource setting (WMT '14 English-German), SCALENORM and FIXNORM remain competitive but PRENORM degrades performance.", 'cs': "Vyhodnocujeme tři jednoduché, normalizačně orientované změny pro zlepšení tréninku Transformer. Nejprve ukazujeme, že pre-normová reziduální připojení (PRENORM) a menší inicializace umožňují zahřívací školení založené na validaci s velkou rychlostí učení. Za druhé navrhujeme normalizaci l2 s jedním parametrem (SCALENORM) pro rychlejší trénink a lepší výkon. Na závěr potvrzujeme účinnost normalizace slovních vložení na pevnou délku (FIXNORM). Na pěti překladatelských párech s nízkými zdroji z korpusů založených na TED Talks se tyto změny vždy sbližují, což dává průměrný +1.1 BLEU nad nejmodernějšími dvojjazyčnými základními liniemi a nový 32.8 BLEU na IWSLT '15 anglicko-vietnamštině. Poskytujeme ostřejší křivky výkonu, konzistentnější normy gradientů a lineární vztah mezi aktivačním škálováním a hloubkou dekodéru. Překvapivě, v prostředí s vysokými zdroji (WMT '14 anglicky-němčina), SCALENORM a FIXNORM zůstávají konkurenceschopné, ale PRENORM snižuje výkon.", 'et': "Me hindame kolme lihtsat, normaliseerimiskeskset muutust Transformeri koolituse parandamiseks. Esiteks näitame, et normieelsed jääkühendused (PRENORM) ja väiksemad initsialiseerimised võimaldavad soojenemisevaba valideerimispõhine koolitus suure õppimismääraga. Teiseks pakume l2 normaliseerimist ühe skaala parameetriga (SCALENORM) kiiremaks treeninguks ja paremaks jõudluseks. Lõpuks kinnitame veel kord, kui tõhus on normaliseerida sõna manustamine fikseeritud pikkusega (FIXNORM). Viie madala ressursiga tõlkepaari puhul TED Talks-põhistest korpustest lähtuvad need muutused alati kokku, andes keskmiselt +1,1 BLEU üle kaasaegsete kakskeelsete lähtejoonte ja uue 32,8 BLEU IWSLT '15 inglise-vietnami keeles. Pakume teravamaid jõudluskõveraid, ühtlasemaid gradientnorme ning lineaarset seost aktiveerimiskaleerimise ja dekooderi sügavuse vahel. Üllataval kombel jäävad SCALENORM ja FIXNORM suurte ressursside puhul konkurentsivõimeliseks (WMT '14 inglise-saksa keeles), kuid PRENORM halvendab jõudlust.", 'az': "Üç basit, normalizasyon-merkezi dəyişiklikləri Transformer təhsilini yaxşılaşdırmaq üçün değerlendiririk. İlk dəfə, norm öyrənməsindən geri qalan bağlantılar (PRENORM) və daha kiçik başlanğıçlar böyük öyrənmə dərəcələri ilə istifadə etmədən, təhsil edilmədən təhsil etmişik. İkincisi, biz l2'i daha hızlı təcrübə və daha yaxşı təcrübə üçün bir ölçü parametru ilə normalizasyonu təklif edirik. Sonunda, sözlərin bir uzunluğa (FIXNORM) inşallarını normalizə etməsini təsdiqləyirik. TED Talks-based korporasından beş kaynaq çeviri ilə, bu dəyişikliklər həmişə birləşdirirlər, sanatın iki dil səhifələrində ortalama +1.1 BLEU və IWSLT'in 15 İngilizə-Vjetnamı ilə yeni 32.8 BLEU verirlər. Biz hərəkətli performans kurtlarını, daha sürəkli gradient normlarını və aktivasiya skalası və dekoder derinliklərinin arasındakı linear ilişkiləri qurtarıq. Xəbərdar ki, yüksək kaynaqlar quruluşunda (WMT '14 İngilizə-Almanca), SCALENORM və FIXNORM müqayisədə qalır, lakin PRENORM performansını dəyişdirir.", 'fi': "Arvioimme kolmea yksinkertaista, normalisoitumiskeskistä muutosta Transformer-koulutuksen parantamiseksi. Ensin näytämme, että normia edeltävät jäännösyhteydet (PRENORM) ja pienemmät alustukset mahdollistavat lämpimän ja validointiperusteisen koulutuksen suurella oppimisnopeudella. Toiseksi ehdotamme l2:n normalisointia yhdellä skaalaparametrilla (SCALENORM) nopeampaan harjoitteluun ja parempaan suorituskykyyn. Lopuksi vahvistamme sanaupotusten normalisoinnin tehokkuuden kiinteään pituuteen (FIXNORM). TED Talks -pohjaisten korpusten viidessä vähäresurssisessa käännösparissa nämä muutokset ovat aina yhteneviä, jolloin keskimäärin +1,1 BLEU:n keskiarvo ylittää huipputason kaksikieliset perusviivat ja uusi 32,8 BLEU:n keskiarvo IWSLT '15 englannin-vietnamin kielellä. Palvelemme terävämpiä suorituskykykäyriä, yhdenmukaisempia gradienttinnormeja sekä lineaarista suhdetta aktiiviskaalauksen ja dekooderisyvyyden välillä. Yllättävää kyllä SCALENORM ja FIXNORM pysyvät kilpailukykyisinä suurissa resursseissa (WMT '14 englanti-saksa), mutta PRENORM heikentää suorituskykyä.", 'he': "We evaluate three simple, normalization-centric changes to improve Transformer training.  ראשית, אנחנו מראים שהקשרים הנותרים לפני נורמה (PRENORM) והניזאליזציות הקטנות מאפשרות אימונים ללא התחממות, מבוססים באישור עם שיעורי לימוד גדולים. שנית, אנו מציעים ניורמליזציה של l2 עם פרמטר סקאלנורם אחד (SCALENORM) לאימון מהיר יותר והופעה טובה יותר. סוף סוף, אנו מאשר מחדש את היעילות של ניורמליזציה של מילים למרחק קבוע (FIXNORM). על חמישה זוגות תרגום נמוכות משאבים מהגופורה המבוססת על TED Talks, השינויים האלה תמיד מתקרבים, נותנים ממוצע +1.1 BLEU על קווי בסיס שתיים-לשונים מצוינים ו-32.8 BLEU חדש על IWSLT '15 אנגלי-וייטנאמי. אנחנו משרתים עקובות ביצועים חדות יותר, נורמות מערכות מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכת מערכ באופן מפתיע, בסיס המשאבים הגבוהים (WMT '14 אנגלי-גרמני), SCALENORM ופיקסנורם נשארים תחרותיים אבל PRENORM משפיל את ההופעה.", 'ha': "Ina ƙayyade musanya uku masu sauƙi, masu normal-centric don ya canza mafarin aikin Transformer. Kayyan, za'a nũna cewa, linki masu baka na farko na mazauni (PRENORM) da masu ƙaranci masu amfani da aikin mai tsari-da-inganci mai girma na da rabon learning. Na ƙarshe, za'a goyya da mai normal l2 da wata parameter guda (SCALENARM) wa wa'anar mafaka da mafiya alhẽri. Gani, za mu ƙara da aikin mai daidaita maganar da ke shiga zuwa tsawo mai ƙayyade (FIXNARM). On shan ƙasƙanci-resource translation nau'i biyu daga TeD Talks-based firma, waɗannan musanyawa ke daidai, sunã bãyar da an ƙidãya+1.1 BLEU over state-of-the-art-bilin base lines and a new 32.8 BLEU on IWSLT '15 Ingiriya- Fietnamcha. We ob- serve sharper performance curves, more consistent gradient norms, and a linear relationship between activation scaling and decoder depth.  Ina mãmãki, a cikin ma'anar sarki (WMT '14-Ingiriya-Jarman), SCALENARM da FIXNARM yana ƙaranci tarajar da kuma FENORM yana kasancẽwa babban rabo.", 'sk': "Za izboljšanje usposabljanja transformatorjev ocenjujemo tri preproste spremembe, usmerjene v normalizacijo. Najprej pokažemo, da prednormne preostale povezave (PRENORM) in manjše inicializacije omogočajo usposabljanje brez ogrevanja, ki temelji na validaciji z velikimi stopnjami učenja. Drugič, predlagamo normalizacijo l2 z enim merilnim parametrom (SCALENORM) za hitrejši trening in boljšo zmogljivost. Na koncu ponovno potrjujemo učinkovitost normalizacije besednih vdelav na fiksno dolžino (FIXNORM). Na petih nizkih virov prevajalskih parov iz korpusov, ki temeljijo na TED Talks, se te spremembe vedno zbližujejo, kar daje povprečno +1,1 BLEU nad najsodobnejšimi dvojezičnimi osnovnimi linijami in novo 32,8 BLEU na IWSLT '15 angleško-vietnamščini. Nudimo ostrejše krivulje zmogljivosti, doslednejše gradientne norme in linearno razmerje med aktivacijskim skaliranjem in globino dekoderja. Presenetljivo je, da v okolju z visokimi viri (angleško-nemščina WMT '14) SCALENORM in FIXORM ostajata konkurenčni, vendar PRENORM slabi zmogljivost.", 'jv': 'Awak dhéwé éntuk telu sampeyan, Normal-center kuwi nggawe turungi Transformer. Awak dhéwé, ngéwé éntukno sistem preNorm kuwi tanggal gak-tanggal gak nguasai perusahaan, dadi kebijakan podho nggawe barang resmi wis segondi, kita suggereja nggo "l2" kanggo kalagayaan karo singar parameter (dinor dinor) kanggo diangkat luwih nggawe lan akeh lanjut. Fine Awak lima sing paling-pernik nik nganggo tresnaning kanggo kowé nggawe gerakan karo telas telu Talks, nik nggawe ngupakan tanggal wih-wih telu kotak dhéwé +.1 B luwih telu kotak dhéwé karo perusahaan unggal sampeyan karo perusahaan anyar 32.8 B luwih nggo IWSLT \'14 Inglis-Latiné Kernel Awakdhéwé, barêng-barêng langgambar luwih nêmên (WêT \'14 Inggris-German), SEKALIENorM karo BEXNORT isih beraksi lan saiki perusahaan maneh, lan saiki KENNOM kuwi ora bisa pasangan sawar nggawe.', 'bo': "ང་ཚོས་གཞུང First, we show that pre-norm residual connections (PRENORM) and smaller initializations enable warmup-free, validation-based training with large learning rates. Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance. མཐའ་མར་དུ། ང་ཚོས་ཀྱིས་རྒྱུན་ལྡན་པའི་ཐ་སྙད་ནང་འཇུག་གི་ནུས་པ་ཐད་ཚོད་ལ་ངོས་འཛིན་བྱེད། On five low-resource translation pairs from TED Talks-based corpora, these changes always converge, giving an average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT '15 English-Vietnamese. ང་ཚོས་བྱ་བ་གཉིས་ཀྱི་ལས་འཕགས་རིས་ལྟར་བ་དང་མཐུན་པའི་སྣ་ཚུལ་མཐུན་གྱི་མཐུན་རིམ། Surprisingly, in the high-resource setting (WMT '14 English-German), SCALENORM and FIXNORM remain competitive but PRENORM degrades performance."}
{'en': 'Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade', 'es': 'Aprovechamiento de datos de entrenamiento indirectos para la traducción automática de voz de principio a fin: trucos del oficio', 'ar': 'تسخير بيانات التدريب غير المباشر للترجمة التلقائية للكلام: حيل التجارة', 'fr': 'Exploiter les données de formation indirectes pour une traduction vocale automatique de bout en bout\xa0: les astuces du métier', 'pt': 'Aproveitando dados de treinamento indireto para tradução automática de fala de ponta a ponta: truques do comércio', 'ja': 'エンドツーエンドの自動音声翻訳のための間接トレーニングデータの活用：取引のコツ', 'zh': '因间接练数端到端自音译:交易技巧', 'ru': 'Использование непрямых обучающих данных для сквозного автоматического перевода речи: торговые уловки', 'hi': 'एंड-टू-एंड स्वचालित भाषण अनुवाद के लिए अप्रत्यक्ष प्रशिक्षण डेटा का दोहन: व्यापार की ट्रिक्स', 'ga': 'Leas a Bhaint as Sonraí Oiliúna Indíreacha le haghaidh Aistriúchán Urlabhra Uathoibríoch ó cheann go ceann: Seifteanna na Trádála', 'el': 'Αξιοποίηση έμμεσων δεδομένων κατάρτισης για την αυτόματη μετάφραση ομιλίας εξ ολοκλήρου: κόλπα του εμπορίου', 'hu': 'Közvetett képzési adatok hasznosítása végpontos automatikus beszédfordításhoz: a kereskedelem trükkjei', 'ka': 'ბოლოდან ბოლოდან ბოლოდან დასრულებული სიტყვების თავისწორება: სამუშაო თავისწორება', 'it': 'Sfruttare i dati di formazione indiretta per una traduzione vocale automatica end-to-end: trucchi del mestiere', 'kk': 'Аяқтау- аяқтау автоматты сөйлеу аудармасының жетілдік оқыту деректерін қолдануға болады: Салымды тәртіптері', 'lt': 'Netiesioginio mokymo duomenų, skirtų automatiniam kalbos vertimui nuo pabaigos, panaudojimas: prekybos triukšmai', 'mk': 'Употреба на индиректни податоци за обука за автоматски превед на говор од крај до крај: Трикови од трговијата', 'mt': 'Harnessing Indirect Training Data for End-to-End Automatic Speech Translation: Tricks of the Trade', 'ml': 'അവസാന- മുതല്\u200d അവസാനിക്കുന്ന സ്വയമായി സംസാര പരിശീലന വിവരങ്ങള്\u200d', 'mn': 'Бүтээгдэхүүний төгсгөл-төгсгөлд автоматически ярианы хөрөнгө оруулалт: Худалдааны шинжлэх ухаан', 'ro': 'Utilizarea datelor indirecte de formare pentru traducerea automată a vorbirii end-to-end: trucurile comerțului', 'ms': 'Menggunakan Data Latihan Tidak Terlangsung untuk Terjemahan Ucapan Automatik Akhir-Akhir: Tricks of the Trade', 'pl': 'Wykorzystanie pośrednich danych szkoleniowych do kompleksowego automatycznego tłumaczenia mowy: sztuczki handlowe', 'no': 'Hentar indirekte treningsdata for automatisk taleomsetjing til slutt til slutt: Tricks of the Trade', 'si': 'අවසානයෙන් අවසානයෙන් ස්වයංක්\u200dරීය වාර්තාව සඳහා අනිත් ප්\u200dරධාන දත්ත සම්බන්ධ කරනවා: ව්\u200dයාපාරයේ ස', 'so': 'Turjumidda dhammaadka-to-End Automatic Speech: Tricks of the Trade', 'sv': 'Utnyttja indirekta träningsdata för automatisk talöversättning från början till slut: tricks of the trade', 'sr': 'Koristenje indirektnih podataka obuke za automatski prevod govora do kraja: Trikovi trgovine', 'ur': 'پایان سے پایان کے لئے نازل ترینیننگ ڈاٹے کے مطابق اپنا انویٹ ژنرال کیا جا رہا ہے: تجارت کی تریکس', 'ta': 'முடிவில் இருந்து முடிவில் இருந்து தானியங்கி பேச்சு மொழிபெயர்ப்பிற்கான குறிப்பிட்ட பயிற்சி தகவல்', 'uz': 'Tricks of the Trade', 'vi': 'Đang sử dụng dữ liệu giáo dục trực tiếp cho giai đoạn nói tự động cuối:', 'hr': 'Koristenje podataka o indirektnom obuku za automatski prevod govora do kraja: Trikovi trgovine', 'nl': 'Indirecte trainingsgegevens gebruiken voor end-to-end automatische spraakvertaling: trucs van de handel', 'bg': 'Използване на индиректни данни за обучение за автоматичен речен превод от край до край: трикове на търговията', 'da': 'Udnyttelse af indirekte træningsdata til automatisk taleoversættelse end-to-end: Tricks of te Trade', 'de': 'Indirekte Trainingsdaten für die End-to-End automatische Sprachübersetzung nutzen: Tricks of the Trade', 'id': 'Menggunakan Data Pelatihan Indirekt untuk Perjemahan Ucapan Otomatis Akhir-Akhir: Tricks of the Trade', 'ko': '간접 트레이닝 데이터를 이용하여 끝에서 끝까지 자동 음성 번역: 기교', 'fa': 'استفاده از داده\u200cهای آموزش غیرمستقیم برای ترجمه\u200cهای گفتگوی خودکار پایان به پایان: ترکیب\u200cهای تجارت', 'sw': 'Takwimu za mafunzo ya Kihindi kwa ajili ya Tafsiri ya kujieleza binafsi ya Kuishia hadi mwishoni: Tricks of the Trade', 'tr': 'Soňra-soňra Awtomatik Sözler terjime etmek üçin Taýratyn Ewezam Maglumaty Hareketlenýän: Täkiýet Trikleri', 'hy': 'Օգտագործելով անուղղակի ուսուցման տվյալները վերջ-վերջ ավտոմատիկ խոսքի թարգմանման համար.', 'am': 'Tricks of the Trade', 'af': 'Onderhou Indirekte Oefening Data vir Einde- na- Einde Automaties Spraak Vertaling: Tricks of the Trade', 'sq': 'Përdorimi i të dhënave të trajnimit të pavarur për përkthimin automatik të fjalës nga fundi në fund: Tricks of the Trade', 'bn': 'স্বয়ংক্রিয়ভাবে স্বাক্ষরিক ভাষণ অনুবাদের জন্য স্থানীয় প্রশিক্ষণের তথ্য হার্নাসিং করছে: ট্রাইডের ট্রিক', 'az': 'Son-to-end avtomatik s칬z 칞evirilm톛si 칲칞칲n indir톛t t톛hsil m톛lumat캼 istifad톛 edilir: ticar톛t s캼ralar캼', 'cs': 'Využití nepřímých tréninkových dat pro komplexní automatický překlad řeči: triky obchodu', 'bs': 'Koristenje podataka o indirektnom obuci za automatski prevod govora do kraja: Trikovi trgovine', 'et': 'Kaudse koolituse andmete kasutamine otsast otsani automaatse kõnetõlke jaoks: kaubanduse trikid', 'fi': 'Välillisten koulutustietojen hyödyntäminen päästä päähän automaattiseen puheen kääntämiseen: kaupan temput', 'ca': "Utilitzar les dades d'entrenament indirect per a traduir la llengua automàtica de final a final: trucs del comerç", 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'he': 'שימוש מידע אימון אינדריט לתרגום אוטומטי של נאום סוף-סוף: טריקים של הסחר', 'ha': '@ action', 'sk': 'Izkoriščanje podatkov o posrednem usposabljanju za avtomatsko prevajanje govora od konca do konca: triki trgovine', 'bo': 'མཇུག་ལ་མཇུག་གི་སྐད་ཡིག་ཆ་ལ་རང་འགུལ་གྱི་སྐད་བསྒྱུར་བཅོས་ཐབས་མེད་པའི་ཐད་ཚོགས་གཙོ་རིམ།'}
{'en': 'For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems. In this work, we evaluate several data augmentation and pretraining approaches for ', 'ar': 'بالنسبة للترجمة الآلية للكلام (AST) ، يتفوق أداء الأساليب الشاملة على النماذج المتتالية التي يتم نسخها باستخدام التعرف التلقائي على الكلام (ASR) ، ثم الترجمة الآلية (MT). أحد الأسباب الرئيسية لفجوة الأداء هو أنه في حين أن مجموعات AST الحالية صغيرة ، توجد مجموعات بيانات ضخمة لكل من النظامين الفرعيين لـ ASR و MT. في هذا العمل ، نقوم بتقييم العديد من أساليب زيادة البيانات والتدريب المسبق لـ AST ، من خلال مقارنة الكل في نفس مجموعات البيانات. أثبتت زيادة البيانات البسيطة عن طريق ترجمة نصوص ASR أنها أكثر فاعلية على مجموعة بيانات LibriSpeech المعززة باللغتين الإنجليزية والفرنسية ، مما أدى إلى سد فجوة الأداء من 8.2 إلى 1.4 BLEU ، مقارنة بسلسلة قوية جدًا يمكن أن تستخدم بشكل مباشر بيانات ASR و MT الوفيرة. نفس النهج الشامل بالإضافة إلى الضبط الدقيق يغلق الفجوة في مجموعة البيانات الإنجليزية-الرومانية MuST-C من 6.7 إلى 3.7 BLEU. بالإضافة إلى هذه النتائج ، نقدم توصيات عملية لزيادة وطرق التدريب. أخيرًا ، قمنا بتقليل فجوة الأداء إلى 0.01 BLEU باستخدام بنية قائمة على المحولات.', 'fr': "Pour la traduction vocale automatique (AST), les approches de bout en bout sont surpassées par les modèles en cascade qui transcrivent avec la reconnaissance vocale automatique (ASR), puis traduisent avec la traduction automatique (MT). L'une des principales causes de l'écart de performance est que, alors que les corpus AST existants sont petits, il existe des ensembles de données massifs pour les sous-systèmes ASR et MT. Dans ce travail, nous évaluons plusieurs approches d'augmentation de données et de pré-entraînement pour l'AST, en comparant toutes les approches sur les mêmes ensembles de données. L'augmentation simple des données par la traduction des transcriptions ASR s'avère plus efficace sur le jeu de données LibriSpeech augmenté anglais-français, comblant l'écart de performance de 8,2 à 1,4 UEBL, par rapport à une très forte cascade qui pourrait directement utiliser de nombreuses données ASR et MT. La même approche de bout en bout et le réglage fin comblent l'écart sur l'ensemble de données anglais-roumain MUST-C de 6,7 à 3,7 UEBL. En plus de ces résultats, nous présentons des recommandations pratiques pour les approches d'augmentation et de préentraînement. Enfin, nous réduisons l'écart de performance à 0,01 BLEU en utilisant une architecture basée sur Transformer.", 'pt': 'Para tradução automática de fala (AST), as abordagens de ponta a ponta são superadas por modelos em cascata que transcrevem com reconhecimento automático de fala (ASR) e depois traduzem com tradução automática (MT). Uma das principais causas da lacuna de desempenho é que, embora os corpora AST existentes sejam pequenos, existem grandes conjuntos de dados para os subsistemas ASR e MT. Neste trabalho, avaliamos várias abordagens de aumento de dados e pré-treinamento para AST, comparando todas nos mesmos conjuntos de dados. O aumento simples de dados traduzindo transcrições de ASR se mostra mais eficaz no conjunto de dados LibriSpeech aumentado em inglês-francês, fechando a lacuna de desempenho de 8,2 para 1,4 BLEU, em comparação com uma cascata muito forte que poderia utilizar diretamente dados copiosos de ASR e MT. A mesma abordagem de ponta a ponta mais o ajuste fino fecha a lacuna no conjunto de dados MuST-C inglês-romeno de 6,7 para 3,7 BLEU. Além desses resultados, apresentamos recomendações práticas para abordagens de aumento e pré-treinamento. Finalmente, reduzimos a diferença de desempenho para 0,01 BLEU usando uma arquitetura baseada em Transformer.', 'es': 'Para la traducción automática de voz (AST), los enfoques de extremo a extremo se ven superados por los modelos en cascada que transcriben con reconocimiento automático de voz (ASR) y luego se traducen con traducción automática (MT). Una de las principales causas de la brecha de rendimiento es que, si bien los cuerpos AST existentes son pequeños, existen conjuntos de datos masivos para los subsistemas ASR y MT. En este trabajo, evaluamos varios enfoques de aumento de datos y preentrenamiento para AST, comparando todos en los mismos conjuntos de datos. El simple aumento de datos mediante la traducción de transcripciones de ASR resulta más eficaz en el conjunto de datos de LibriSpeech ampliado en inglés y francés, ya que cierra la brecha de rendimiento de 8,2 a 1,4 BLEU, en comparación con una cascada muy sólida que podría utilizar directamente una gran cantidad de datos de ASR y MT. El mismo enfoque de extremo a extremo más el ajuste fino cierra la brecha en el conjunto de datos Must-C de inglés a rumano de 6,7 a 3,7 BLEU. Además de estos resultados, presentamos recomendaciones prácticas para enfoques de aumento y preentrenamiento. Finalmente, disminuimos la brecha de rendimiento a 0,01 BLEU mediante una arquitectura basada en Transformer.', 'ja': '自動音声翻訳（ ＡＳＴ ）の場合、エンドツーエンドのアプローチは、自動音声認識（ ＡＳＲ ）で転写し、次に機械翻訳（ Ｍ Ｔ ）で遅れて転写するカスケードモデルによって凌駕される。 パフォーマンスギャップの主な原因は、既存のASTコーラが小さい一方で、ASRサブシステムとMTサブシステムの両方に大規模なデータセットが存在することです。 この研究では、同じデータセット上のすべてを比較することによって、ASTのいくつかのデータ拡張および事前トレーニングアプローチを評価します。 ASRトランスクリプトを翻訳することによる単純なデータ拡張は、英仏の拡張LibriSpeechデータセットで最も効果的であることが証明されており、膨大なASRおよびMTデータを直接利用できる非常に強力なカスケードと比較して、8.2から1.4 BLEUまでのパフォーマンスギャップを埋めます。 同じエンドツーエンドのアプローチと微調整は、英語-ルーマニア語のMuST - Cデータセットの6.7から3.7 BLEUのギャップを埋めます。 これらの結果に加えて、拡張および事前トレーニングアプローチのための実用的な推奨事項を提示します。 最後に、トランスフォーマーベースのアーキテクチャでは、パフォーマンスギャップを0.01 BLEUに減らします。', 'zh': '其自语音译 (AST),端到端优于级联,用自语音 (ASR) 转录之,然后用机器翻译 (MT) 后期译。 性所以去者,虽见AST语料库小,而ASRMT子系统皆大集。 于此等事,比较同集数以增预训练方法,评AST数以增预训练方法。 译 ASR 转录本简数增于英语-法语增强型 LibriSpeech 数集上验为最效,与可径用多 ASR 与 MT 数之极强者比,将性相去自 8.2 BLEU缩小至 1.4%。 同端到端加微调英语 - 罗马尼亚MuST-C数集差从6.7缩小至3.7 BLEU。 自此之外,增预训练方法之实用建议。 最后,相去缩小0.01 BLEU基于Transformer架构。', 'hi': 'स्वचालित भाषण अनुवाद (एएसटी) के लिए, एंड-टू-एंड दृष्टिकोण कैस्केड मॉडल द्वारा बेहतर प्रदर्शन किया जाता है जो स्वचालित भाषण मान्यता (एएसआर) के साथ प्रतिलेखन करते हैं, फिर मशीन अनुवाद (एमटी) के साथ ट्रांस-लेट होते हैं। प्रदर्शन अंतर का एक प्रमुख कारण यह है कि, जबकि मौजूदा एएसटी कॉर्पोरेट छोटे हैं, एएसआर और एमटी सबसिस्टम दोनों के लिए बड़े पैमाने पर डेटासेट मौजूद हैं। इस काम में, हम एक ही डेटासेट पर सभी की तुलना करके एएसटी के लिए कई डेटा वृद्धि और प्रीट्रेनिंग दृष्टिकोणों का मूल्यांकन करते हैं। एएसआर टेपों का अनुवाद करके सरल डेटा वृद्धि अंग्रेजी-फ्रांसीसी संवर्धित LibriSpeech डेटासेट पर सबसे प्रभावी साबित होती है, 8.2 से 1.4 BLEU तक प्रदर्शन अंतर को बंद कर देती है, एक बहुत ही मजबूत कैस्केड की तुलना में जो सीधे प्रचुर मात्रा में एएसआर और एमटी डेटा का उपयोग कर सकती है। एक ही एंड-टू-एंड दृष्टिकोण प्लस फाइन-ट्यूनिंग अंग्रेजी-रोमानियाई MuST-C डेटासेट पर 6.7 से 3.7 BLEU तक के अंतर को बंद कर देता है। इन परिणामों के अलावा, हम वृद्धि और pretraining दृष्टिकोण के लिए व्यावहारिक rec-ommendations प्रस्तुत करते हैं। अंत में, हम प्रदर्शन अंतर को 0.01 BLEU तक कम करते हैं, जो हमें एक ट्रांसफॉर्मर-आधारित आर्किटेक्चर को कम करता है।', 'ru': 'Для автоматического перевода речи (AST) сквозные подходы превосходят каскадные модели, которые транскрибируют с автоматическим распознаванием речи (ASR), а затем транслируют с машинным переводом (MT). Основная причина разрыва в производительности заключается в том, что, хотя существующие корпуса AST являются небольшими, массивные наборы данных существуют как для подсистем ASR, так и для подсистем MT. В этой работе мы оцениваем несколько подходов к увеличению данных и предварительной подготовке для AST, сравнивая все на одних и тех же наборах данных. Простое увеличение данных путем перевода транскриптов ASR оказывается наиболее эффективным в наборе данных LibriSpeech с расширением на английском и французском языках, сокращая разрыв в производительности с 8,2 до 1,4 BLEU, по сравнению с очень сильным каскадом, который может непосредственно использовать обширные данные ASR и MT. Тот же сквозной подход плюс точная настройка сокращают разрыв на английском-румынском наборе данных MuST-C с 6,7 до 3,7 БЛЮ. В дополнение к этим результатам мы представляем практические рекомендации по подходам к увеличению и предварительной подготовке. Наконец, мы уменьшаем разрыв в производительности до 0,01 BLEU с помощью архитектуры на основе трансформатора.', 'ga': 'Maidir le haistriúchán cainte uathoibríoch (AST), tá cur chuige ceann-go-deireadh níos fearr ag samhlacha cascáideacha a thras-scríobhtar le haitheantas cainte uathoibríoch (ASR), a thrasnaíonn le haistriúchán meaisín (MT) ansin. Príomhchúis leis an mbearna feidhmíochta is ea, cé go bhfuil corparáidí AST reatha beag, go bhfuil tacair shonraí ollmhóra ann do na fochórais ASR agus MT araon. San obair seo, déanaimid meastóireacht ar roinnt cineálacha cur chuige um mhéadú sonraí agus réamhoiliúint do AST, trí chomparáid a dhéanamh idir iad uile ar na tacair sonraí céanna. Is éifeachtaí méadú sonraí simplí trí thrascríbhinní ASR a aistriú ar thacar sonraí méadaithe LibriSpeech Béarla-Fraincis, ag dúnadh na bearna feidhmíochta ó 8.2 go 1.4 BLEU, i gcomparáid le easghluaiseachta an-láidir a d’fhéadfadh úsáid dhíreach a bhaint as sonraí ollmhóra ASR agus MT. Dúnann an cur chuige ceann go ceann céanna chomh maith le mionchoigeartú an bhearna ar an tacar sonraí Béarla-Rómhánach MST-C ó 6.7 go 3.7 BLEU. Chomh maith leis na torthaí seo, cuirimid i láthair moltaí praiticiúla maidir le cur chuige méadaithe agus réamhoiliúint. Ar deireadh, laghdóimid an bhearna feidhmíochta go 0.01 BLEU ag baint úsáide as ailtireacht Claochladán-bhunaithe.', 'el': 'Για την αυτόματη μετάφραση ομιλίας (AST), οι ολοκληρωμένες προσεγγίσεις ξεπερνούν από διαδοχικά μοντέλα που μεταγραφούν με αυτόματη αναγνώριση ομιλίας (ASR) και στη συνέχεια μεταγραφούν με μηχανική μετάφραση (MT). Μια κύρια αιτία του χάσματος επιδόσεων είναι ότι, ενώ τα υπάρχοντα σώματα AST είναι μικρά, υπάρχουν τεράστια σύνολα δεδομένων τόσο για το υποσύστημα ASR όσο και για το MT. Στην εργασία αυτή, αξιολογούμε διάφορες προσεγγίσεις αύξησης και προεπιλογής δεδομένων για την AST, συγκρίνοντας όλα τα ίδια σύνολα δεδομένων. Η απλή αύξηση δεδομένων με τη μετάφραση μεταγραφών αποδεικνύεται πιο αποτελεσματική στο αγγλο-γαλλικό εμπλουτισμένο σύνολο δεδομένων κλείνοντας το χάσμα απόδοσης από 8.2 έως 1.4 σε σύγκριση με έναν πολύ ισχυρό καταρράκτη που θα μπορούσε άμεσα να χρησιμοποιήσει άφθονα δεδομένα ASR και MT. Η ίδια ολοκληρωμένη προσέγγιση και η τελειοποίηση κλείνουν το κενό στο αγγλο-ρουμανικό σύνολο δεδομένων MuST-C από 6.7 έως 3.7 BLEU. Εκτός από αυτά τα αποτελέσματα, παρουσιάζουμε πρακτικές συστάσεις για προσεγγίσεις αύξησης και προεπιλογής. Τέλος, μειώνουμε το χάσμα απόδοσης σε 0.01 δημιουργώντας μια αρχιτεκτονική βασισμένη στον μετασχηματιστή.', 'hu': 'Az automatikus beszédfordítás (AST) esetében a end-to-end megközelítéseket olyan kaszkádos modellek végzik, amelyek automatikus beszédfelismeréssel (ASR), majd gépi fordítással (MT) transzformálják. A teljesítmény hiányának egyik fő oka, hogy míg a meglévő AST testek kicsi, nagy adatkészletek léteznek mind az ASR, mind az MT alrendszerek esetében. Ebben a munkában több adatbővítési és előkészítési megközelítést értékelünk az AST esetében, ugyanazon adatkészletek összehasonlításával. Az ASR átiratok fordításával történő egyszerű adatbővítés a leghatékonyabbnak bizonyul az angol-francia kiterjesztett LibriSpeech adatkészleten, csökkentve a teljesítmény hiányát 8.2 és 1.4 BLEU között, összehasonlítva egy nagyon erős kaszkáddal, amely közvetlenül felhasználható bőséges ASR és MT adatokat. Ugyanez a teljes körű megközelítés és finomhangolás csökkenti az angol-román MuST-C adatkészlet 6.7-től 3.7-ig terjedő rését. Ezen eredmények mellett gyakorlati ajánlásokat is bemutatunk a kiterjesztési és előkészítési megközelítésekre vonatkozóan. Végezetül, a teljesítmény hiányát 0,01 BLEU-ra csökkentjük egy Transformer alapú architektúrával.', 'ka': 'ავტომატიკური სიტყვის განსაგულისხმებისთვის (AST) დასასრულისხმებისთვის დასასრულისხმებისთვის მოდელები, რომლებიც ავტომატიკური სიტყვის განსაგულისხმებით (ASR), შემდეგ მაქინის განსაგულისხმე მნიშვნელოვანი მიზეზი იყო, რომ არსებობს AST კოპორაა პატარა, მასტივი მონაცემები არსებობს ორივე ASR და MT სუფსისტემებისთვის. ამ სამუშაოში, რამდენიმე მონაცემების აგგენტაცია და AST-ის წინასწორება გავაკეთებთ, ყველაფერი იგივე მონაცემების შესაბამისად. მარტივი მონაცემების აზექტირება, რომელიც ASR ტრანსკრიპტის ტრანსკრიპტის გადატანა უფრო ეფექტიური ინგლისურ- ფრანგური აზექტირებული LibriSpeech მონაცემების შესახებ, რომელიც 8.2-დან 1.4 BLEU-დან გამოსახულებული გან იგივე დასრულებული დასრულებული დასრულებული დასრულებული დასრულება ინგლისური-პომინური მონაცემების მონაცემების დასრულება 6,7-3,7 BLEU-დან. ამ შედეგების დამატებით, ჩვენ გვეყვანეთ პრაქტიკური რეკომენდეციების შესახებ აზემონტიკაციის და წარმოდგენის შესახებ. საბოლოოდ, ჩვენ გავაკეთებთ სამუშაო განსხვავებას 0,01 BLEU-ში, რომელიც განსხვავებულია ტრანფორმეტრის მიერ აქტიქტურაცია.', 'lt': 'Automatiniam kalbos vertimui (AST) taikomi kaskadiniai modeliai, kurie transkribuojami automatiniu kalbos atpažinimu (ASR), o vėliau transkribuojami mašininiu vertimu (MT). Pagrindinė veikimo spragos priežastis yra ta, kad nors esami AST korporai yra maži, esami masiniai ASR ir MT posistemių duomenų rinkiniai. Šiame darbe vertiname keletą AST duomenų didinimo ir išankstinio mokymo metodų, palygindami visus tuos pačius duomenų rinkinius. Paprastas duomenų didinimas vertant ASR transkriptas įrodo, kad labiausiai veiksmingas anglų ir prancūzų tarpusavyje padidinto LibriSpeech duomenų rinkinio atžvilgiu, panaikinant veiklos spragą nuo 8,2 iki 1,4 BLEU, palyginti su labai stipria kaskada, kuri galėtų tiesiogiai panaudoti kopijuotus ASR ir MT duomenis. Taikant tą patį metodą nuo pabaigos prie pabaigos ir tiksliai koreguojant, anglų ir Rumunijos MUST-C duomenų rinkinio spraga užbaigiama nuo 6,7 iki 3,7 BLEU. Be šių rezultatų, pateikiame praktines rekomendacijas dėl didinimo ir išankstinio mokymo metodų. Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.', 'ms': 'Untuk terjemahan ucapan automatik (AST), pendekatan akhir-akhir dilakukan oleh model kaskad yang ditranskrip dengan pengenalan ucapan automatik (ASR), kemudian ditranslasi dengan terjemahan mesin (MT). Sebab utama bagi ruang prestasi ialah, walaupun korpra AST yang wujud adalah kecil, set data besar wujud untuk kedua-dua subsistem ASR dan MT. Dalam kerja ini, kita menilai beberapa data meningkat dan pendekatan pretraining untuk AST, dengan membandingkan semua pada set data yang sama. Pembesaran data sederhana dengan menerjemahkan transkrip ASR membuktikan yang paling berkesan pada set data LibriSpeech bertambah bahasa Inggeris-Perancis, menutup ruang prestasi dari 8.2 hingga 1.4 BLEU, dibandingkan dengan kaskad yang sangat kuat yang boleh menggunakan data ASR dan MT yang berkumpul secara langsung. Pendekatan hujung-hujung yang sama ditambah penyesuaian menutup ruang pada set data MuST-C Inggeris-Romania dari 6.7 ke 3.7 BLEU. Selain daripada hasil ini, kami memperkenalkan rekomansi praktik untuk peningkatan dan pendekatan pretraining. Akhirnya, kita menurunkan jarak prestasi kepada 0.01 BLEU kita- menjadi arkitektur berasaskan Transformer.', 'mk': 'За автоматски превод на говор (AST), пристапите од крај до крај се надминуваат од каскадирани модели кои се препишуваат со автоматско препознавање на говорот (ASR), потоа транс- доцна со машински превод (MT). Големата причина за разликата во резултатите е дека, иако постојните АСТ корпора се мали, постојат масовни податоци за подсистемите АСР и МТ. Во оваа работа, проценуваме неколку податоци за зголемување и претренирање на пристапите за АСТ, споредувајќи ги сите на истите податоци. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data.  Истиот пристап од крај до крај плус фино прилагодување ја затвора празнината на англиско-романското множество податоци МУСТ-Ц од 6,7 на 3,7 БЛЕУ. Покрај овие резултати, претставуваме практични препораки за зголемување и претренирање пристапи. Конечно, ја намалуваме празнината во резултатите на 0,01 БЛЕУ со трансформска архитектура.', 'ml': 'For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT).  പ്രകടനത്തിന്റെ പ്രധാന കാരണം, നിലവിലുള്ള ആസ്റ്റ് കോര്\u200dപ്പോര കൊണ്ട് ചെറുതായിരിക്കുമ്പോള്\u200d, ആസാരിന്റെയും എംടി ഉപസിസ് ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d പല ഡേറ്റാ കൂട്ടുന്നതിനെയും ആസ്റ്റിന്റെ അടുത്തുനിന്നും പ്രതീക്ഷിക്കുന്നതിനെയും പരിഗ ASR ട്രാന്\u200dസ്ക്രിപ്റ്റുകള്\u200d പരിശോധിപ്പിക്കുന്നതിനാല്\u200d എളുപ്പമുള്ള ഡേറ്റാ കൂട്ടിച്ചേര്\u200dക്കുന്നതിനാല്\u200d ഇംഗ്ലീഷ്- ഫ്രെഞ്ച് കൂട്ടിച്ചേര്\u200dത്ത ലിബ്രിസ്പെച്ച് ഡാറ അതേ അവസാനത്തിന്റെ അടുത്തേക്കുള്ള വഴിക്കുറിച്ചും സുന്ദരിക്കുന്നതും ഇംഗ്ലീഷ്-റോമാനിയന്\u200d മുസ്റ്റ്-സി ഡാറ്റാസറ്റെറ്റിന ഈ ഫലങ്ങളെക്കൂടാതെ, നമ്മള്\u200d കൂടുതല്\u200d പ്രാകൃതിക വീണ്ടും മാറ്റുന്നതിനും വേണ്ടിയാണ്. അവസാനം, നമ്മള്\u200d പ്രകടന വ്യത്യാസം 0.01 ബില്യൂ വരെ കുറവ് വരുത്തുന്നു. ട്രാന്\u200dസ്ഫോര്\u200dമാര്\u200d അടിസ്ഥാനമായ ഒരു ആര്\u200dക്കിട്', 'mt': 'Għal traduzzjoni awtomatika tad-diskors (AST), l-approċċi minn tarf sa tarf jitwettqu minn mudelli kaskati li jittraskrivu b’rikonoxximent awtomatiku tad-diskors (ASR), imbagħad jittraskrivu b’traduzzjoni bil-magna (MT). Kawża ewlenija tad-diskrepanza fil-prestazzjoni hija li, filwaqt li l-korpi AST eżistenti huma żgħar, jeżistu settijiet ta’ dejta massivi kemm għas-sottosistemi ASR kif ukoll MT. F’dan ix-xogħol, aħna jevalwaw diversi approċċi ta’ żieda fid-dejta u ta’ taħriġ minn qabel għall-AST, billi nqabblu kollha fuq l-istess settijiet ta’ dejta. Żieda sempliċi fid-dejta bit-traduzzjoni tat-traskrizzjonijiet ASR hija l-aktar effettiva fuq is-sett tad-dejta LibriSpeech miżjud bl-Ingliż-Franċiż, li jagħlaq id-distakk fil-prestazzjoni minn 8.2 għal 1.4 BLEU, meta mqabbel ma’ kaskata qawwija ħafna li tista’ tuża direttament dejta kopja ASR u MT. L-istess approċċ minn tarf għal tarf flimkien ma’ aġġustament fin jagħlaq id-distakk fis-sett tad-dejta MuST-C Ingliż-Rumen minn 6.7 sa 3.7 BLEU. Minbarra dawn ir-riżultati, qed nippreżentaw rakkomandazzjonijiet prattiċi għal approċċi ta’ żieda u taħriġ minn qabel. Fl-a ħħar nett, naqsu d-distakk fil-prestazzjoni għal 0.01 BLEU billi nibnu arkitettura bbażata fuq it-Transformer.', 'kk': 'Автоматты сөздерді аудару (AST) үшін аяқтау- аяқтау керектері автоматты сөздерді анықтау (ASR) мен аудару үлгілерімен аудару үлгілері (MT) жазылады. АҚШ корпорасы кішкентай болғанда, ASR және MT субжүйелер үшін үлкен деректер қорлары бар. Бұл жұмыс ішінде бірнеше деректер көптегендіруді және AST үшін келесі жағдайларды салыстырып, барлығын бір деректер жиындарына салыстырып бағалаймыз. ASR транскрипттерді аударып қарапайым деректерді көбейту үшін ағылшын- французша ағылшын- французша көбейтілген LibriSpeech деректер жиынында ең ең эффективні көрсетеді, 8. 2- 1. 4 BLEU- ден жұмыс аралығын жабу үшін, көп ASR мен MT дер Бірақ соңындағы жағдайды бірнеше баптау жағдайды ағылшын-руман МАСТ-С деректер жиынының 6,7-3,7 BLEU бойынша жабылады. Бұл нәтижелердің қосымша, көптегендіру және өзгерту арқылы практикалық қайта командаларды таңдаймыз. Соңғы сәтте, біз жылдамдығын 0,01 BLEU-ге қысқартамыз. Трансферлердің архитектурасы.', 'it': "Per la traduzione vocale automatica (AST), gli approcci end-to-end sono superati da modelli a cascata che trascrivono con riconoscimento vocale automatico (ASR), quindi trans-late con traduzione automatica (MT). Una delle principali cause del gap di performance è che, mentre i corpi AST esistenti sono piccoli, esistono enormi set di dati sia per i sottosistemi ASR che MT. In questo lavoro, valutiamo diversi approcci di aumento dei dati e pre-formazione per AST, confrontando tutti sugli stessi set di dati. Il semplice aumento dei dati attraverso la traduzione di trascrizioni ASR si rivela più efficace sul set di dati LibriSpeech aumentato inglese-francese, chiudendo il gap di prestazioni da 8.2 a 1.4 BLEU, rispetto a una cascata molto forte che potrebbe utilizzare direttamente abbondanti dati ASR e MT. Lo stesso approccio end-to-end e la messa a punto di fine-tuning colmano il gap sul set di dati MuST-C inglese-rumeno da 6.7 a 3.7 BLEU. Oltre a questi risultati, presentiamo raccomandazioni pratiche per gli approcci di aumento e pre-formazione. Infine, riduciamo il gap di performance a 0,01 BLEU con un'architettura basata su Transformer.", 'mn': 'Автоматик ярианы хөрөнгө оруулалт (AST), төгсгөл-төгсгөл арга барилгууд автоматжуулан ярианы хүлээн зөвшөөрөх (ASR) загвараар автоматжуулан хэлэлцдэг загварууд, дараа нь машин хөрөнгө оруулалт ( АСТ корпора нь жижиг, АСР болон MT субсистем хоёулаа маш том өгөгдлийн сангууд байдаг. Энэ ажил дээр бид олон өгөгдлийн нэмэгдүүлэлт болон АСТ-ийн арга баримтуудыг ижил өгөгдлийн санд харьцуулахад үнэлдэг. ASR транскриптүүдийг орчуулахад энгийн өгөгдлийн нэмэгдүүлэлт нь Англи-Францын нэмэгдсэн LibriSpeech өгөгдлийн санд хамгийн үр дүнтэй харагдаж байна. 8.2-аас 1.4 BLEU-ээс үр дүнтэй ялгааг хадгалж байна. Яг ижил төгсгөл, төгсгөл ойлголт нэмэх нь сайхан зохицуулах нь Англи-Румын МАСТ-С өгөгдлийн сангийн ялгааг 6.7-ээс 3.7 БЛЮС руу холбоотой. Эдгээр үр дүнд нэмэхэд бид дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахи Эцэст нь бид үйл ажиллагааны ялгааг 0.01 БЛУС-д багасгаж байна. Трансформатор суурилсан архитектур.', 'no': 'For automatisk taleomsetjing (AST) blir tilnærmingar til slutten utført av kaskaderte modeller som transkriver med automatisk tale- gjenkjenning (ASR), og så trans late med maskinsomsetjing (MT). Eit viktig grunn av utgangspunktet er at, mens eksisterande AST-korpora er lite, finst massiv datasett for både ASR og MT-undersystema. I dette arbeidet evaluerer vi fleire data-augmentasjon og trekking av tilnærmingar for AST ved å sammenligne alle på samme datasett. Ein enkel data-økning ved å oversette ASR-transkript viser det mest effektivt på den anglesk-fransk augmenterte LibriSpeech-dataset, og lukkar utgangspunktet frå 8,2 til 1,4 BLEU, sammenlignet med ein veldig sterk kaskade som kunne direkte bruka kopøre ASR-og MT-data. Dette same ende-til-slutt tilnærming pluss fin-tuning lukkar mellomrommet på datasettet engelsk-rumensk MuST-C frå 6,7 til 3,7 BLEU. I tillegg til desse resultatene presenterer vi praktiske rekommendringar for augmentasjon og trekking av tilnærmingar. I slutten reduserer vi utgangspunktet til 0,01 BLEU som gjer ein transformeringsarkitektur.', 'pl': 'W przypadku automatycznego tłumaczenia mowy (AST) podejścia końcowe są przewyższane przez modele kaskadowe, które transkrybują z automatycznym rozpoznawaniem mowy (ASR), a następnie transkrybują z tłumaczeniem maszynowym (MT). Główną przyczyną luki w wydajności jest to, że podczas gdy istniejące korpusy AST są małe, masowe zbiory danych istnieją zarówno dla podsystemów ASR, jak i MT. W niniejszej pracy oceniamy kilka metod zwiększania i wstępnego treningu danych dla AST, porównując wszystkie na tych samych zbiorach danych. Proste powiększanie danych poprzez tłumaczenie transkrypcji ASR okazuje się najbardziej skuteczne na angielsko-francuskim rozszerzonym zbiorze danych LibriSpeech, zmniejszając lukę wydajności od 8.2 do 1.4 BLEU, w porównaniu z bardzo silną kaskadą, która może bezpośrednio wykorzystać obfite dane ASR i MT. To samo kompleksowe podejście oraz precyzyjne dostosowanie zamyka lukę w angielsko-rumuńskim zbiorze danych MuST-C od 6.7 do 3.7 BLEU. Oprócz tych wyników przedstawiamy praktyczne zalecenia dotyczące podejść do rozszerzenia i wstępnego treningu. Wreszcie zmniejszamy lukę wydajnościową do 0.01 BLEU z architekturą opartą na Transformerze.', 'so': 'Tilmaamaha hadalka oo automatic ah (AST), waxaa lagu sameeyaa qaabab dhammaadka ugu dambaysta ah oo lagu qorayo qoraalka ku qoran aqoonsashada hadalka (ASR), dabadeedna trans-late with translation of machine (MT). Sababta ugu weyn ee burburka sameynta waa in marka shirkadda AST ay jiraan ay yaryihiin, waxaa jira sawirada macluumaadka badan ee ASR iyo MT hoosdhigyada. Markaas waxan, waxaynu qiimeynaynaa kordhiska macluumaadka iyo ka hor-soocidda AST, si aan u barbardhigno dhammaan sawirada isku mid ah. Soo saaridda macluumaadka fudud ee turjumidda qoraalka ASR waxay cadaynaysaa kuwa ugu shaqeeya ee ku saabsan macluumaadka afriiska-Faraansiinta oo afgeysay LibriSpeech, wuxuuna dabooli karaa gafafka performance ka baxay 8.2-1.4 BLEU, compared to a cascade aad u adag oo toos u isticmaali kara macluumaadka ASR iyo MT. Dhaqdooyinka ugu dambeeya isla dhamaadka iyo qurxinta qurxinta ayaa daboolaya burburka warqada ingiriisiga-Romanian MuST-C ee laga soo bilaabo 6.7-3.7 BLEU. Arrimahaan ka sokow, waxan soo bandhignaynaa dib-u-beddelasho ah oo la kordhiyo iyo soo-beddelasho. Ugu dambaysta, waxaynu hoos u dhignaa booska sameynta ilaa 0.01 BLEU - dhismaha baabuurta.', 'ro': 'Pentru traducerea automată a vorbirii (AST), abordările end-to-end sunt depășite de modele în cascadă care transcriu cu recunoașterea automată a vorbirii (ASR), apoi cu traducerea automată (MT). O cauză majoră a decalajului de performanță este că, în timp ce corpurile AST existente sunt mici, există seturi de date masive atât pentru subsistemele ASR, cât și MT. În această lucrare, evaluăm mai multe abordări de mărire a datelor și pre-formare pentru AST, prin compararea tuturor pe aceleași seturi de date. Amplificarea simplă a datelor prin traducerea transcrierilor ASR se dovedește cea mai eficientă pe setul de date LibriSpeech augmentat englez-francez, reducând decalajul de performanță de la 8.2 la 1.4 BLEU, comparativ cu o cascadă foarte puternică care ar putea utiliza direct numeroase date ASR și MT. Aceeași abordare end-to-end plus ajustarea fină elimină decalajul în setul de date MuST-C englez-român de la 6.7 la 3.7 BLEU. Pe lângă aceste rezultate, prezentăm recomandări practice pentru abordările de augmentare și pre-formare. În cele din urmă, reducem decalajul de performanță până la 0,01 BLEU pentru o arhitectură bazată pe Transformer.', 'si': 'ස්වයංක්\u200dරිය කතාවක් අවවාදය (AST) සඳහා, end-to-end අවවාදය නිසා ස්වයංක්\u200dරිය කතාවක් අවවාදය (ASR) සඳහා ස්වයංක්\u200dරිය කතාවක් අවවාදය (MT) ස ප්\u200dරශ්නයක් ප්\u200dරධානයක් තියෙන්නේ AST කොර්පෝරා පුංචි වෙලාවක්, ASR සහ MT සබස්සිස්ටම් දෙන්නම් ගොඩක් දත්ත සැට්  මේ වැඩේ අපි දත්ත විශාලනය සහ AST වෙනුවෙන් ප්\u200dරතික්\u200dරීයාවක් විශාලනය කරනවා, එකම දත්ත සේට් වල හැම දේවල්ම සමානු Name එකම අවසානයෙන් අවසානයෙන් අවසානයෙන් හොඳ අවසානය වෙනුවෙන් ඉංග්\u200dරීසිය-රෝමානියාන් මුස්ට් සී දත්ත සැටුම 6.7 ඉඳල මේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර අන්තිමේදි, අපි ප්\u200dරාර්ථනාවක් අවස්ථාවක් 0.01 බ්ලූස් වලට අඩු කරනවා. අපිට ප්\u200dරාර්ථනාවක් අධාරිත වින', 'sr': 'Za automatski prevod govora (AST), pristupi na kraj do kraja iznosi kaskadni modeli koji prepisuju automatskim priznanjem govora (ASR), a zatim prekasni sa prevodom mašine (MT). Veliki uzrok praznine izvedbe je da, iako postojeća AST korpora su mala, masivna podataka postoji za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkript ASR pokazuje najefikasniji na kompetu podataka o povećanju biblioteke na engleskom francuskom i francuskom jeziku, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi sa veoma jakom kaskadom koja bi mogla izravno iskoristiti kopijske ASR i MT podatke. Isti pristup do kraja plus fino podešavanje zatvara prazninu na podacima engleskog-rumunskog MuST-C od 6,7 do 3,7 BLEU. Pored ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koja nas je osnovala na transformeri arhitektura.', 'ta': '@ info செயல்பாட்டு வேறுபாட்டின் மிகப்பெரிய காரணம் என்னவென்றால், இருக்கும் AST நிறுவனத்தில் இருக்கும் போது ASR மற்றும் MT உப அமைப்ப இந்த வேலையில், நாம் பல தரவு அதிகரிப்பு மற்றும் AST க்கான முன்னேற்றம் செய்ய வேண்டும் மற்றும் அதே தரவு அமைப்புகளை ஒப்பி ASR எழுத்துருக்களை மொழிமாற்றி சுலபமான தகவல் மேலும் ஆங்கிலம்- பிரெஞ்சு மேம்படுத்தப்பட்ட லிப்ரிஸ்பேச் தகவல் அமைப்பில் மிகவும் விளைவாக தெரியும், செயல்பாட்டு வெளியேற்றம் 8.  அதே முடிவில் இருந்து முடிவு நெருக்கம் கூட்டல் நன்றாக மூடுகிறது ஆங்கிலத்தில் இருந்து ரோமானியன் முஸ்ட்- C தரவுத்தளத்தில் இருந இந்த முடிவுகளுக்கும் தவிர, நாம் மேம்படுத்தல் மற்றும் முன்னோக்கம் செய்ய முடிவுகளை கூட்டுதல் மற்றும் பெரும இறுதியில், நாம் செயல்பாட்டு இடைவெளியை 0.01 பிலியு எங்களுக்கு குறைக்கிறோம் - மாற்று அடிப்படையில் உள்ள ஒரு கட்டு', 'ur': 'اپنی بات کی ترجمہ (AST) کے لئے آخر-to-end approaches are performed by cascaded models that transcribe with automatic speech recognition (ASR) and then trans late with machine translation (MT). عملکرد فاصلہ کی ایک بڑی دلیل یہ ہے کہ، حالانکہ موجود AST کورپورا چھوٹے ہیں، ASR اور MT سوسٹیموں کے لئے بڑی ڈاٹ سٹ موجود ہیں. اس کام میں ہم نے بہت سی ڈیٹا اضافہ اور آسٹی کے لئے پرٹرینٹ کی طریقے کا ارزش کیا ہے، سب ایک ڈیٹ سٹ پر مقایسہ کرکے۔ ASR ٹرنسکرپٹوں کو ترجمہ کرنے کے ذریعہ ساده ڈاٹ اضافہ کرتا ہے انگلیسی-فرانسوی اضافہ کی لیبری اسپیچ ڈاٹ سٹ پر بہت اثر دیتا ہے، جو 8.2 سے 1.4 بلیوس سے کامپیوتر فاصلہ بند کرتا ہے، ایک بہت مضبوط کاسڈ کے مقابلے میں جو سیدھی آس آر اور ٹی ڈا اسی طرح انگلیسی-رومین ماسٹ-سی ڈاٹ سٹ کے اندر 6.7 سے 3.7 بلیوس کے لئے فاصلہ بند کرتا ہے۔ ان نتائج کے علاوہ، ہم اضافہ اور زیادتی کی طریقوں کے لئے قابل تدبیر کماندر پیش کرتے ہیں. آخر میں، ہم ایک تغییر پھیلانے والی معماری کو 0.01 BLEU تک کم کر رہے ہیں۔', 'sv': 'För automatisk talöversättning (AST) överträffas end-to-end-tillvägagångssätt av kaskadmodeller som transkriberar med automatisk taligenkänning (ASR) och sedan transkriberar med maskinöversättning (MT). En viktig orsak till prestandakravet är att även om befintliga AST-kroppar är små, finns det massiva datauppsättningar för både ASR- och MT-delsystemet. I detta arbete utvärderar vi flera dataförstärknings- och pretrainingmetoder för AST, genom att jämföra alla på samma datauppsättningar. Enkel dataökning genom att översätta ASR-transkript visar sig vara mest effektiv på den engelsk-franska förstärkta LibriSpeech-datauppsättningen, vilket minskar prestandakravet från 8,2 till 1,4 BLEU, jämfört med en mycket stark kaskad som direkt kunde utnyttja rikliga ASR- och MT-data. Samma heltäckande tillvägagångssätt plus finjustering minskar gapet i den engelsk-rumänska MuST-C-datauppsättningen från 6,7 till 3,7 BLEU. Utöver dessa resultat presenterar vi praktiska rekommendationer för förstärkning och pre-training metoder. Slutligen minskar vi prestandabalansen till 0,01 BLEU genom att använda en Transformer-baserad arkitektur.', 'uz': "@ info: whatsthis Va bajarish gapirishining asosiy sababi, mavjud ASAT kompaniya juda kichkina maʼlumot tizimi ASR va MT tizimlari uchun juda katta maʼlumot tizimi mavjud. Bu ishda biz bir necha maʼlumot qoʻshishni qiymatmiz va ASAT uchun yozish usullarini qiymatimiz, hamma bir necha maʼlumot sahifalarni bir necha ko'paytuvchimiz. Name Bu bir oxiriga qo'yish usuli va yaxshi suhbat usuli ingliz-Rumincha MuST-C maʼlumotlar tarkibini 6.7 dan 3.7 BLEU bilan o'zgartiradi. Bu natijalardan boshqa esa, biz tashkilotni oshirish va taqdim qilish usullarini bajaramiz. Endi biz tashkilotni 0.01 BLEU'ga kamaytamiz - Transformer asosiy arxituvchi.", 'vi': 'Đối với dịch ngôn ngữ tự động (AST), các phương pháp cuối-tới-cuối được thực hiện bởi các mô-đun ngẫu nhiên chuyển qua bằng nhận dạng ngôn ngữ tự động (ASR), sau đó chuyển mới bằng dịch cỗ máy (MTV). Một nguyên nhân quan trọng của việc đó là một trong số hệ thống ASR và MTV. Trong công việc này, chúng tôi đánh giá nhiều phương pháp gia tăng dữ liệu và nâng cấp cho AST bằng cách so sánh tất cả các bộ dữ liệu giống nhau. Đơn giản gia tăng dữ liệu bằng cách dịch chuyển các ghi chép ASR cho thấy hiệu quả nhất với hệ thống dữ liệu LyriSpeech cường Anh-Pháp, thu hồi khoảng cách hiệu suất từ 8.2 đến 1.4 bleU, so với một thác rất mạnh có thể trực tiếp sử dụng dữ liệu ASR và MTV. C ùng một phương pháp cuối cùng cộng với độ chỉnh sửa sửa sửa sửa sửa chữa lỗ hổng trong bộ nhớ dữ liệu giọng Tây Ban Nha MuST-C từ 6.7 tới 3.7 BleU. Ngoài những kết quả này, chúng tôi còn đưa ra các dự án thực tế cho việc tăng trưởng và nâng cấp phương pháp. Cuối cùng, chúng ta giảm khoảng trống hiệu suất đến 0.13 LEU- đang tạo ra một kiến trúc biến hình.', 'da': 'For automatisk taleoversættelse (AST) udføres end-to-end-tilgange af kaskademodeller, der transkriber med automatisk talegenkendelse (ASR) og derefter transskriber med maskinoversættelse (MT). En væsentlig årsag til performance gap er, at mens eksisterende AST corpora er små, eksisterer massive datasæt for både ASR og MT delsystemer. I dette arbejde evaluerer vi flere data augmentation og pre-training metoder for AST ved at sammenligne alle på de samme datasæt. Enkel dataudvidelse ved oversættelse af ASR-transskriptioner viser sig at være mest effektiv på det engelsk-franske augmented LibriSpeech datasæt, hvilket lukker præstationshullet fra 8,2 til 1,4 BLEU sammenlignet med en meget stærk kaskade, der direkte kunne udnytte rigelige ASR- og MT-data. Den samme end-to-end-tilgang plus finjustering lukker hullet i det engelsk-rumænske MuST-C datasæt fra 6,7 til 3,7 BLEU. Ud over disse resultater præsenterer vi praktiske anbefalinger til forstærkning og forudtræning tilgange. Endelig mindsker vi præstationskløften til 0,01 BLEU ved at bruge en Transformer-baseret arkitektur.', 'bg': 'При автоматичен речен превод (АСТ) подходите от край до край се превъзхождат от каскадни модели, които транскрибират с автоматично разпознаване на речта (АСР), след което транслатират с машинен превод (МТ). Основна причина за разликата в ефективността е, че докато съществуващите корпуси на AST са малки, съществуват масивни набори от данни както за подсистемите ASR, така и MT. В тази работа ние оценяваме няколко подхода за увеличаване и предтрениране на данни за АСТ, като сравняваме всички на едни и същи набори от данни. Опростеното увеличаване на данните чрез превод на транскрипции се оказва най-ефективно върху английско-френския разширен набор от данни, затваряйки разликата в ефективността от 8.2 до 1.4 в сравнение с много силна каскада, която може директно да използва изобилни данни. Същият подход от край до край плюс фина настройка затваря разликата в английско-румънския набор от данни от 6.7 до 3.7 Блеу. В допълнение към тези резултати представяме практически препоръки за подходи за разширение и предобучение. И накрая, намаляваме разликата в производителността до 0.01 чрез изграждане на базирана на трансформатор архитектура.', 'id': 'Untuk terjemahan pidato otomatis (AST), pendekatan akhir-akhir dilakukan oleh model kaskade yang transkrip dengan pengenal pidato otomatis (ASR), kemudian trans-terlambat dengan terjemahan mesin (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems.  Dalam pekerjaan ini, kami mengevaluasi beberapa data meningkat dan pendekatan pretraining untuk AST, dengan membandingkan semua pada set data yang sama. Pembesaran data sederhana dengan menerjemahkan transkrip ASR terbukti paling efektif pada set data LibriSpeech bertambah Inggris-Perancis, menutup ruang prestasi dari 8.2 ke 1.4 BLEU, dibandingkan dengan kaskade yang sangat kuat yang dapat langsung menggunakan data ASR dan MT yang saling berkuasa. Pendekatan akhir-akhir yang sama ditambah penyesuaian menutup ruang di dataset MuST-C Inggris-Romania dari 6.7 ke 3.7 BLEU. Selain hasil-hasil ini, kami mempersembahkan rekomandasi praktis untuk peningkatan dan pendekatan pretraining. Akhirnya, kita mengurangi ruang prestasi ke 0,01 BLEU kita- menjadi arsitektur berasaskan Transformer.', 'de': 'Bei der automatischen Sprachübersetzung (AST) werden End-to-End-Ansätze durch kaskadierte Modelle übertroffen, die mit automatischer Spracherkennung (ASR) transkribieren und dann mit maschineller Übersetzung (MT) übersetzen. Eine Hauptursache für die Leistungslücke ist, dass bestehende AST-Korpora zwar klein sind, aber massive Datensätze sowohl für das ASR- als auch für das MT-Subsystem existieren. In dieser Arbeit evaluieren wir verschiedene Ansätze zur Datenaugmentation und -pretraining für AST, indem wir alle auf denselben Datensätzen vergleichen. Die einfache Datenauswertung durch die Übersetzung von ASR-Transkripten erweist sich am effektivsten auf dem englisch-französischen erweiterten LibriSpeech-Datensatz und schließt die Leistungslücke von 8.2 bis 1.4 BLEU im Vergleich zu einer sehr starken Kaskade, die umfangreiche ASR- und MT-Daten direkt nutzen könnte. Der gleiche End-to-End-Ansatz und die Feinabstimmung schließen die Lücke im englisch-rumänischen MuST-C-Datensatz von 6.7 bis 3.7 BLEU. Zusätzlich zu diesen Ergebnissen präsentieren wir praktische Empfehlungen für Augmentations- und Vortrainingsansätze. Schließlich verringern wir die Leistungslücke auf 0.01 BLEU mit einer Transformer-basierten Architektur.', 'hr': 'Za automatski prevod govora (AST), pristupi na kraju do kraja iznosi kaskadirani modeli koji prepisuju s automatskim priznanjem govora (ASR), a zatim transkasnim s prevodom stroja (MT). Veliki uzrok praznine učinkovitosti je da, iako postojeća AST korpora su mala, masivna podaci postoje za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkripte ASR pokazuje najučinkovitiji na kompletu povećanih podataka LibriSpeech na engleskom francuskom i francuskom, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi s vrlo jakom kaskadom koja bi mogla izravno iskoristiti kopijske podatke ASR i MT-a. Isti pristup kraja do kraja plus fino podešavanje zatvara prazninu podataka engleskog-rumunskog MuST-C iz 6,7 do 3,7 BLEU-a. Osim ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koji nam je osnovana na transformeri arhitektura.', 'fa': 'برای ترجمه سخنرانی خودکار (AST) روش\u200cهای پایان به پایان از مدل\u200cهای کاسکیدی که با شناسایی سخنرانی خودکار (ASR) ترجمه می\u200cکنند، سپس با ترجمه\u200cهای ماشین (MT) ترجمه می\u200cکنند. یک دلیل بزرگی از فاصله عملکرد این است که در حالی که شرکت AST موجود کوچک هستند، مجموعه\u200cهای داده\u200cهای بزرگ برای سیستم\u200cهای ASR و MT وجود دارد. در این کار، ما چندین افزایش داده ها را ارزیابی می کنیم و به طریق مقایسه کردن همه روی مجموعه\u200cهای داده\u200cها و روش\u200cهای پیش\u200cگیری برای AST، با مقایسه کردن همه روی مجموعه\u200cهای یکسان داده\u200cها. افزایش داده\u200cهای ساده با ترجمه ترجمه\u200cهای ASR بر مجموعه داده\u200cهای LibriSpeech افزایش داده\u200cهای انگلیسی-فرانسوی ثابت می\u200cکند، و فاصله\u200cهای عملکرد از 8.2 تا 1.4 BLEU را بسته می\u200cکند، در مقایسه با یک کاسکید بسیار قوی که می\u200cتواند مستقیماً از داده\u200cهای ASR و MT استفاده کن همان دستور پایان و پایان و تنظیم نیکویی در مجموعه داده های انگلیسی-رومانی MuST-C از 6.7 تا 3.7 BLEU بسته است. در addition to these results, we present practical rec-commands for increased and pretraining approaches. بالاخره، ما فاصله عملکرد را به 0.01 BLEU کاهش می\u200cدهیم که یک معماری بنیاد تغییر دهنده است.', 'sw': 'Kwa kutafsiri hotuba ya kujitegemea (AST), mbinu za mwisho za mwisho zinaendeshwa na miundo mbinu yenye mabadiliko yanayoandikwa kwa kutambua hotuba ya kujitegemea (ASR), kisha kwa muda mrefu kwa kutafsiri mashine (MT). Sababu kubwa ya mchanganyiko wa utendaji ni kwamba, wakati kampuni ya AST iko ndogo, kuna seti kubwa za data kwa ajili ya mifumo ya ASR na MT. Katika kazi hii, tunatathmini kuongeza takwimu kadhaa na kutengeneza matukio ya AST, kwa kulinganisha vyote katika seti hizo za data. Kuongezeka kwa takwimu rahisi kwa kutafsiri maandishi ya ASR yanaonyesha kuwa na ufanisi zaidi kwenye seti ya data za LibriSpeech zilizoongezewa kwa Kiingereza-Kifaransa, kufunga gaidi ya utendaji kutoka 8.2 hadi 1.4 BLEU, ukilinganisha na kaskadi yenye nguvu sana inayoweza kutumia takwimu za ASR na MT. Mtakatifu huo mwishoni wa mwisho pamoja na ujumbe mzuri unafungua gaidi kuhusu takwimu za Kiingereza-Romanian MuST-C kutoka 6.7 hadi 3.7 BLEU. Zaidi ya matokeo haya, tunatoa mabadiliko ya hali halisi kwa ajili ya kuongeza na kutengeneza mbinu za kutengeneza. Mwisho, tunapunguza kiwango cha utendaji cha BLEU hadi 0.01 BLEU – kutufanya ujenzi wa asili ya Transformer.', 'af': "Vir outomatiese woorde vertaling (AST), die einde- na- einde toegang word uitgevoer deur kaskadeerde modele wat met outomatiese woorde herken (ASR), dan trans- laat met masjien vertaling (MT). 'n Hoogte oorsaak van die prestasie gap is dat, terwyl bestaande AST korpora klein is, massiewe datastelle bestaan vir beide die ASR en MT subsystemes. In hierdie werk, ons evalueer veelvuldige data vergroot en voorskyning toegang vir AST deur almal op dieselfde datastelle te vergelyk. Eenvoudige data vergroot deur die vertaling van ASR-transkripte te bevestig mees effektief op die Engelse-Franse vergroot LibriSpeech-datastel, toe die prestasie afstand van 8.2 tot 1.4 BLEU toesluit, vergelyk met 'n baie sterk kaskade wat direk kan gebruik kopiese ASR en MT-data. Die selfde einde-tot-einde toegang plus fin-tuning sluit die afstand op die Engelse-Romaniese MuST-C datastel van 6.7 tot 3.7 BLEU. In addition to these results, we present practical rec- commands for augmentation and pretraining approaches. Eindelik, ons verklein die prestasie afstand tot 0,01 BLES ons - om 'n Transformer-gebaseerde arkitektuur te verminder.", 'tr': "Otomatik çykyş terjime üçin Görniş gapysynyň esasy sebäbi bolsa, bar AST korporasy kiçi bolsa hem ASR we MT subsystemleriň üçin gaty maglumat setirleri bar. Bu işde, biz birnäçe maglumat üýtgetmesini we AST üçin golaýlaryny deňlendirip, hemmesini birnäçe veri setlerde karşılaştyrarak deňlendirip duruyoruz. ASR terjime edip basit maglumatlar ýetişdirilýär, iňlisçe-fransuzça gelişmiş LibriSpeech veri setinde iň täsirli ýagdaýda, performansyň gapysyny 8.2 we 1.4 BLEU-dan ýapýarylýar, kopy ASR we MT maglumatyny ullanabilen örän güýçli bir kaskada we deňleýär. Şol ýagdaý soňunda ýakynlaşdyrmak üçin iňlisçe-rumynça MuST-C veri sahypalarynyň 6.7 we 3.7 BLEU-dan çykarýar. Bu sonuçlar da arttırmak ve önlenme metodları için pratik bir tekrarlama komutanları sunuyoruz. Sonunda, performans boşluklarını 0.01 BLEU'a düşürüp, Transformer tabanlı bir arhitektura çevirdik.", 'nl': "Voor automatische spraakvertaling (AST) worden end-to-end benaderingen overtroffen door cascademodellen die transcriberen met automatische spraakherkenning (ASR) en vervolgens translate met machine translation (MT). Een belangrijke oorzaak van de prestatiekloof is dat, hoewel bestaande AST-corpora's klein zijn, enorme datasets bestaan voor zowel het ASR- als MT-subsysteem. In dit werk evalueren we verschillende data augmentatie en pretraining benaderingen voor AST, door ze allemaal op dezelfde datasets te vergelijken. Eenvoudige gegevensvergroting door ASR-transcripten te vertalen blijkt het meest effectief op de Engels-Franse augmented LibriSpeech dataset, waardoor de prestatiekloof van 8.2 tot 1.4 BLEU wordt dichten, vergeleken met een zeer sterke cascade die direct gebruik kan maken van overvloedige ASR- en MT-gegevens. Dezelfde end-to-end aanpak plus fine-tuning sluit de kloof op de Engels-Roemeense MuST-C dataset van 6.7 tot 3.7 BLEU. Naast deze resultaten presenteren we praktische aanbevelingen voor augmentatie en pretraining benaderingen. Tot slot verkleinen we de prestatiekloof tot 0.01 BLEU met een Transformer-gebaseerde architectuur.", 'bn': 'স্বয়ংক্রিয় ভাষণ অনুবাদের জন্য (AST) শেষ পর্যন্ত ক্যাস্কেডের মোডেল দ্বারা শেষ পর্যন্ত প্রদর্শন করা হয় যা স্বয়ংক্রিয় ভাষণ স্বীকৃতির সাথে লেখা লেখ প্রদর্শনের প্রধান কারণ হচ্ছে যে এসটি কোর্পোরা বিদ্যমান ছোট, এসআর আর এমটি সাবসিস্টেমের জন্য বিশাল ডাটাসেট রয়েছে। এই কাজে আমরা বেশ কয়েকটি তথ্য যোগাযোগ এবং আস্টের জন্য বৃষ্টিপাতের ক্ষেত্রেও মূল্যায়ন করি, একই তথ্যের সাথে তুলনা করে। Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data.  একই শেষ পর্যন্ত প্রতিক্রিয়া এবং সুন্দর টুনিং এর সাথে ইংরেজি-রোমানিয়ান মুস্টি-সি ডাটাসেট থেকে ৬. ৭ থেকে ৩. এই ফলাফল ছাড়াও আমরা বাড়তে পারি এবং বৃষ্টির প্রাকৃতিক পুনরাবৃত্তি উপস্থাপন করি। Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.', 'ko': '자동음성번역(AST)의 경우 종단 연결 모델보다 종단 연결 방법이 우수하며, 종단 연결 모델은 자동음성인식(ASR)으로 전송한 뒤 기계번역(MT)으로 번역한다.성능 차이의 주요 원인은 기존의AST 어료 라이브러리는 매우 작지만 ASR과 MT 서브시스템에 대량의 데이터 집합이 존재하기 때문이다.이 작업에서 우리는 같은 데이터 집합을 비교하여AST의 몇 가지 데이터 확장과 예비 훈련 방법을 평가했다.ASR 전사본 번역을 통한 간단한 데이터 확충은 영어-프랑스어 증강형 Libri Speech 데이터 세트에서 가장 효과적이며, ASR과 MT 데이터의 막대한 종속 연결을 직접 활용하기보다는 8.2BLEU에서 1.4BLEU로 성능 격차를 좁히는 것으로 나타났다.같은 끝에서 끝까지의 방법에 미세한 조정을 더해 영국-루마니아 MuST-C 데이터 세트의 6.7 BLEU에서 3.7 BLEU까지의 격차를 좁혔다.이러한 결과 외에 우리는 증강과 예훈련 방법의 실용적인 건의도 제기했다.마지막으로 우리는 변압기 기반 아키텍처를 사용하여 성능 격차를 0.01 BLEUus로 줄였습니다.', 'sq': 'For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT).  Një shkak kryesor i daljes së performancës është se, ndërsa korprat ekzistuese AST janë të vogla, të dhënat masive ekzistojnë si për nënsistemet ASR ashtu edhe MT. Në këtë punë, ne vlerësojmë disa rritje të të dhënave dhe metoda përpara stërvitjes për AST, duke krahasuar të gjitha në të njëjtat grupe të të dhënave. Rritja e thjeshtë e të dhënave duke përkthyer transkriptet ASR tregohet më e efektshme në grupin e të dhënave LibriSpeech të rritur anglisht-francez, duke mbyllur dallimin e performancës nga 8.2 në 1.4 BLEU, krahasuar me një kaskade shumë të fortë që mund të përdorte drejtpërdrejt të dhënat kopjoze ASR dhe MT. E njëjta qasje nga fundi në fund plus rregullimi e hollësisë mbyll boshllëkun në grupin e të dhënave anglo-rumune MuST-C nga 6.7 në 3.7 BLEU. Përveç këtyre rezultateve, ne paraqesim rekomandime praktike për rritje dhe metoda paratrajnimi. Më në fund, ne e zvogëlojmë dallimin e performancës në 0.01 BLEU - duke bërë një arkitekturë me bazë në Transformer.', 'bs': 'Za automatski prevod govora (AST), pristupi na kraju do kraja iznosi kaskadni modeli koji prepisuju automatskim priznanjem govora (ASR), a zatim prekasni sa prevodom mašine (MT). Veliki uzrok praznine predstave je da, iako postojeća AST korpora su mala, masivna podataka postoji za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkript ASR pokazuje najučinkovitiji na kompletu povećanih podataka LibriSpeech na engleskom francuskom i francuskom, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi sa vrlo jakom kaskadom koja bi mogla izravno iskoristiti kopijske ASR i MT podatke. Isti pristup kraja do kraja plus fino podešavanje zatvara prazninu na dataset engleskog-rumunskog MuST-C od 6,7 do 3,7 BLEU. Osim ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koji nam je osnovana na transformatorskoj arhitekturi.', 'az': 'Avtomatik sözlər tercüməsi (AST) üçün, maşına tercüməsi (MT) ilə yazılan kaskadlı modellər tərəfindən istifadə edilir. Perfekt boşluğunun ən böyük səbəbi is ə, mevcut AST korporası kiçik olduğu halda, ASR və MT subsystemləri üçün çox böyük veri qurğuları var. Bu işdə, bir neçə məlumat artırmağı və AST üçün təklif metodlarını değerləşdiririk, bütün məlumat qurmaqlarını bir-birinə qarşılaşdırırıq. ASR transkriptlərini tercümə edərək basit məlumat artırması İngiliz-Fransızca yüksələn LibriSpeech veri qutusunda ən etkili göstərir, performans boşluğunu 8.2 ilə 1.4 BLEU ilə bağlayar, köpüsü ASR və MT veriləri istifadə edə bilən çox qüvvətli kascada ilə qarşılaşdırır. Aynı son-to-end approach artıq fin tuning İngiliz-Rumun MuST-C veri qutusu 6,7-3,7 BLEU-dən istifadə edir. Bu sonuçları da artırmaq və təmizləmək üçün praktik yenidən təkrar-təkrarları göstəririk. Sonunda, performans boşluğunu 0,01 BLEU-ə düşürürük - Transformer-based arhitektura.', 'ca': "For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT).  A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems.  En aquest treball, evaluem diversos enfocaments d'augment de dades i de pré-capacitació per a AST, comparant-los tots en els mateixos conjunts de dades. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data.  El mateix enfocament de punta a punta, més ajustes, tanca la diferència en el conjunt de dades MuST-C anglo-rumun de 6,7 a 3,7 BLEU. A més d'aquests resultats, presentem recomanacions pràctiques per a l'augmentació i l'anticraining. Finalment, reduïm la diferència de rendiment a 0,01 BLEU, una arquitectura basada en Transformer.", 'cs': 'V případě automatického překladu řeči (AST) jsou koncové přístupy překonány kaskádovými modely, které přepisují s automatickým rozpoznáváním řeči (ASR) a poté překládají strojovým překladem (MT). Hlavní příčinou výkonnostní mezery je, že zatímco existující AST korpusy jsou malé, existují masivní datové sady jak pro subsystémy ASR, tak MT. V této práci vyhodnocujeme několik přístupů rozšíření a předškolení dat pro AST, porovnáním všech na stejných datových sadách. Jednoduchá rozšíření dat překladem ASR transkriptů se ukázalo jako nejúčinnější na anglicko-francouzském rozšířeném datovém souboru LibriSpeech, čímž uzavírá mezeru výkonu od 8.2 do 1.4 BLEU, ve srovnání s velmi silnou kaskádou, která by mohla přímo využít hojná ASR a MT data. Stejný end-to-end přístup a jemné ladění překlenují mezeru v anglicko-rumunské datové sadě MuST-C od 6.7 do 3.7 BLEU. Kromě těchto výsledků představujeme praktické doporučení pro augmentační a předškolení přístupů. Konečně snižujeme výkonnostní mezeru na 0.01 BLEU s architekturou založenou na Transformeru.', 'fi': 'Automaattisessa puheen kääntämisessä (AST) end-to-end-lähestymiset suoritetaan kaskadimalleilla, jotka transkriбираvat automaattisella puheentunnistuksella (ASR) ja sitten konekäännöksellä (MT). Suuri syy suorituskykyvajeeseen on se, että vaikka olemassa olevat AST-korpuset ovat pieniä, sekä ASR- että MT-osajärjestelmissä on massiivisia tietokokonaisuuksia. Tässä työssä arvioimme useita AST:n tiedonlisäys- ja esikoulutusmenetelmiä vertaamalla kaikkia samoja aineistoja. Yksinkertainen datan lisääminen kääntämällä ASR-transkriptit osoittautuu tehokkaimmaksi englannin-ranskan laajennetussa LibriSpeech-aineistossa, sulkemalla suorituskykykuilun 8.2:sta 1.4 BLEU:hun verrattuna erittäin vahvaan kaskadiin, joka voisi suoraan hyödyntää runsaasti ASR- ja MT-dataa. Sama kokonaisvaltainen lähestymistapa ja hienosäätö sulkevat englannin ja romanian MuST-C-aineiston kuilun 6,7–3,7 BLEU. Näiden tulosten lisäksi esittelemme käytännön suosituksia lisä- ja esikoulutukseen. Lopuksi vähennämme suorituskykykuilua 0,01 BLEU:hun Transformer-pohjaisen arkkitehtuurin avulla.', 'hy': "Ավտոմատիկ խոսքի թարգմանման (AST) համար վերջ-վերջ մոտեցումները դուրս են գալիս կասկադված մոդելների միջոցով, որոնք թարգմանվում են ավտոմատիկ խոսքի ճանաչման (ASR) միջոցով, հետո թարգմանվում են մեքենայի թարգմանման (MT) միջո Արդյունավետության բացառության հիմնական պատճառը այն է, որ մինչդեռ գոյություն ունի AST-ի կառուցվածքներ փոքր են, ASR-ի և MT-ի ենթահամակարգերի համար գոյություն ունի հսկայական տվյալներ: Այս աշխատանքի ընթացքում մենք գնահատում ենք որոշ տվյալների աճը և AST-ի նախադասական մոտեցումները' համեմատելով բոլորը նույն տվյալների համակարգերի վրա: ASR-ի թարգմանման միջոցով պարզ տվյալների աճը ամենաարդյունավետ է ապացուցում անգլերեն-ֆրանսերեն աճեցված գրադարձ տվյալների համակարգի վրա, փակելով արդյունավետության տարբերությունը 8.2-ից 1.4-ին, համեմատած շատ ուժեղ կասկադի հետ, որը կարող է անմիջապես օգտագործել ASR-ի և MT The same end-to-end approach plus fine-tuning closes the gap on the English-Romanian MuST-C dataset from 6.7 to 3.7 BLEU.  Ավելին այս արդյունքներին, մենք ներկայացնում ենք ավելացման և նախադասական մոտեցումների պրակտիկ խորհուրդներ: Վերջապես, մենք նվազեցնում ենք արտադրողականության բացառությունը մինչև 0.01 ԲԼԵՎ-ը, որը մեզ հիմնված է Թանֆերմերների ճարտարապետության միջոցով:", 'et': 'Automaatse kõnetõlke (AST) puhul ületatakse otsast otsa lähenemisviise kaskaadimudelitega, mis transkribeeritakse automaatse kõnetuvastusega (ASR), seejärel transkribeeritakse masintõlkega (MT). Tulemuslikkuse lõhe peamine põhjus on see, et kuigi olemasolevad AST korpused on väikesed, on nii ASR kui ka MT allsüsteemide jaoks olemas massiivsed andmekogumid. Käesolevas töös hindame mitmeid AST-i andmete suurendamise ja eeltreeningu meetodeid, võrreldes kõiki samadel andmekogumitel. Lihtne andmete suurendamine ASR transkriptsioonide tõlkimisega osutub inglise-prantsuse täiendatud LibriSpeech andmekogumi puhul kõige tõhusamaks, sulgedes jõudluse lõhe 8,2 kuni 1,4 BLEU-ni, võrreldes väga tugeva kaskaadiga, mis võiks otseselt kasutada palju ASR- ja MT-andmeid. Sama lõplik lähenemisviis koos peenhäälestusega kaotab lõhe inglise-rumeenia MuST-C andmekogumis vahemikus 6,7 kuni 3,7 BLEU. Lisaks nendele tulemustele esitame praktilisi soovitusi laiendamise ja eelõpetamise lähenemisviiside kohta. Lõpuks vähendame jõudluse lõhet 0,01 BLEU-ni, luues Transformer-põhise arhitektuuri.', 'am': 'For automatic speech translation (AST), the final approach is made by cascaded models that write with automatic speech recognition (ASR), then trans-late with machine translation (MT). የድምፅ ውጤት ግንኙነት በጣም ትልቅ ምክንያት ነው፣ የአስቲ ኮርፖርት ግን ትንሽ ነው፣ የASR እና MT ደብዳቤዎች ደግሞ የብዙ ዳታተር ሰርቨሮች አሉ፡፡ በዚህ ስራ፣ የዳታ አካባቢ እና የAST ደረጃዎችን ለመፍጠር እናሳውቃለን፡፡ ASR transcripts በመግለጫ ቀላል ዳታ ማድረግ በአፍሪካዊ-ፈረንሳይኛ የተጨማሪው የልቤሪንግ ቋንቋ ማድረጊያውን በመግለጫው ይታያል፡፡ ከ8.2 እስከ 1.4 BLEU በመግለጫው ነው፡፡ ይህም የመጨረሻ ቀውስ እና ጥሩ ቀለሞች እንግሊዝኛ-ሮማኒያን MuST-C ዳታተር ከ6.7 ጀምሮ 3.7 BLEU ላይ የሚደረገውን ክፍተት ይጠብቃሉ፡፡ ከዚህም ፍጥረቶች በቀር፣ ለመደጋገፍ እና ለመዘጋጀት የሚደረገውን የስህተት አካባቢ አዳራሽ እናደርጋለን፡፡ በመጨረሻውም የድምፅ ውጤት ወደ 0.01 BLEU እናጎድልናለን - የTransformer-based መሠረት መሠረት እናሳድጋለን፡፡', 'ha': "@ action: button Maɓalli wa gaura na aikin aiki ni'anar cẽwa, a lokacin da ke iya ƙaranci na shirin ATATAT, ana ƙunsa da data masu ƙaranci wa biyu masu ƙaranci na ATR da MT. Daga wannan aikin, muna ƙaddara ƙaramako da akan data da za'a ƙayyade hanyõyi wa ATATA, da sami-sami duk kan daidaita data. @ item license (short name) Tsarin duk ƙari zuwa ta ƙari kodi da tuning mai kyau yana rufe gap kan maɓallin Ingiriya-Romian Mustan-C na daga 6.7 zuwa 3.7 BLEU. Babu wannan matsayi, Munã halatar da mazaɓa na mazauni-mazaɓa wa ƙãri da kuma misãlai. Gani, Munã ƙarantar gaura da za'a kai 0.01 BLEU - ke samun makarantar da aka Transformer.", 'he': 'עבור התרגום אוטומטי של דיבור (AST), גישות סוף-סוף מתקדמות על ידי דוגמנים קאסקודים שטרנסקודים עם זיהוי דיבור אוטומטי (ASR), ואז טרנס- מאוחר עם התרגום מכונת (MT). סיבה גדולה של הפער ביצועי היא שבעוד גופות AST קיימות הן קטנות, קבוצות מידע מסיביות קיימות גם עבור מערכות ASR וגם MT. בעבודה הזו, אנו מעריכים מספר שיעורים של נתונים ולגישות מחדש של AST, על ידי השוואה של כולם על אותם קבוצות נתונים. שיעור נתונים פשוט על ידי תרגום תורגם ASR מוכיח הכי יעיל על קבוצת נתונים של LibriSpeech הגדלה אנגלית-צרפתית, לסגור את הפער ביצועים מ-8.2 ל-1.4 BLEU, בהשוואה לקסקד חזק מאוד שיכול להשתמש ישירות בנתונים ASR ומטה. באותו גישה מסוף-לסוף ועוד התרגיל עצום את הפער על קבוצת מידע MuST-C אנגלי-רומנית מ-6.7 ל-3.7 BLEU. בנוסף לתוצאות אלה, אנו מציגים המלצות מעשיות לגבילה ולגישות מחדש. סוף סוף, אנחנו מפחידים את הפער ביצועים ל-0.01 BLEU אנחנו - הארכיטקטורה מבוססת Transformer.', 'bo': 'For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans-late with machine translation (MT). performance gaps་ལ་གལ་ཆེ་བའི་རྒྱུ་མཚན་ནི་གནས་ཡུལ་ཡོད་པའི་ AST སྒེར་གྱི་མཐུད་སྒྲིག་ཆ་ཆུང In this work, we evaluate several data augmentation and pretraining approaches for AST, by comparing all on the same data sets. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. The same end-to-end approach plus fine-tuning closes the gaps on the English-Romanian MuST-C dataset from 6.7 to 3.7 BLEU. BLEU. གསལ་འབྲས་འདི་དག་ལས་བརྟེན། ང་ཚོས་རྒྱ་བསྐྱེད་སྐབས་སུ་གཏོང་བའི་ཐབས་ལམ་ལ་ཡང་བསྡད་པའི་བརྗོད་བཀོད་པ་ཞིག་ཡོད། མཐའ་མཇུག་དུ། འུ་ཅག་གིས་སྔར་ནས་དབྱིབས་བཟོས་པའི་བཟོ་བརྩིས་གཞི་བརྩིས་གཞི་བཟོ་བྱེད་ཀྱི་ཡོད་ཚད་0.01', 'sk': 'Pri avtomatskem govornem prevajanju (AST) se pristopi od konca do konca izvajajo s kaskadnimi modeli, ki prepišejo s samodejnim prepoznavanjem govora (ASR), nato pa s strojnim prevajanjem (MT). Glavni vzrok za vrzel v uspešnosti je, da so obstoječe korpuse AST majhne, vendar obstajajo ogromni podatkovni nizi za podsistema ASR in MT. V tem delu smo ocenili več pristopov povečanja in predtreninga podatkov za AST s primerjavo vseh na istih naborih podatkov. Enostavno povečanje podatkov s prevajanjem ASR transkripcij se izkaže za najučinkovitejše na angleško-francoskem naboru podatkov LibriSpeech, saj zmanjšuje vrzel v zmogljivosti od 8,2 do 1,4 BLEU v primerjavi z zelo močno kaskado, ki bi lahko neposredno uporabila obilne ASR in MT podatke. Isti pristop od konca do konca in natančno uravnavanje zapolnjuje vrzel v angleško-romunskem naboru podatkov MuST-C od 6,7 do 3,7 BLEU. Poleg teh rezultatov predstavljamo tudi praktične priporočila za pristope povečanja in predurjenja. Nazadnje pa zmanjšamo vrzel v zmogljivosti na 0,01 BLEU, kar pomeni arhitekturo, ki temelji na transformatorju.', 'jv': 'Wurungu perusahaan langgambar (AST), dadi kapan-kowe lan mbuh dumateng manut karo model kascade kang karo perusahaan karo perusahaan sesik (ASR), iso terusahaan karo terjamahan (MT). Mbak perusahaan langkung wigatahan kanggo ngerasai, terus akeh AST dumadhi kuwi mungkin, dadi akeh dumadhi kanggo sistem ASR karo MT Nyong-ngobro iki, awak dhéwé ngeremus akeh data nyang diuntingi podho karo AST ngono nggawe dataset sing berarti. Go Sampeyan nganggo cah-sampeyan nganggo cah-sampeyan ngupakan kelas telas nang ingkang-rumani MuRT-C dataset dadi 6.7 sampeyan 3.7 B Nambah gambarang iki, kita ngomong wektu nggawe rerakke praksi- ommendasi kanggo ngilangno karo hal-hal maneh. Lha wiwit, kita ngulinakake perusahaan kanggo 0.1'}
{'en': 'On Using SpecAugment for End-to-End Speech Translation', 'ar': 'حول استخدام SpecAugment لترجمة الكلام من طرف إلى طرف', 'pt': 'Sobre o uso do SpecAugment para tradução de fala de ponta a ponta', 'fr': "À propos de l'utilisation de SPECaugment pour la traduction vocale de bout en bout", 'es': 'Sobre el uso de SPECaugment para la traducción de voz de principio', 'ja': 'エンドツーエンドの音声翻訳のためのSpecAugmentの使用について', 'ru': 'Об использовании SpecAugment для сквозного перевода речи', 'zh': '其用法端到语音译', 'hi': 'एंड-टू-एंड वाक् अनुवाद के लिए युक्तिकरण का उपयोग करने पर', 'ga': 'Ar SpecAugment a Úsáid le haghaidh Aistriúcháin Cainte ó cheann go ceann', 'el': 'Για τη χρήση της ειδικής επέκτασης για την τελική μετάφραση ομιλίας', 'hu': 'A SpecAugment használata végpontos beszédfordításhoz', 'it': "Sull'uso di SpecAugment per la traduzione vocale end-to-end", 'mk': 'Користејќи спекAugment for End- to- End Speech Translation', 'lt': 'Naudojant spektrą kalbos vertimui nuo galo iki galo', 'ms': 'Pada Penggunaan SpecAugment for End-to-End Speech Translation', 'ml': 'ശബ്ദം ഉപയോഗിക്കുമ്പോള്\u200d അവസാന- മുതല്\u200d അവസാന സംസാര പരിഭാഷ', 'ka': 'სიტყვების გამოყენებაAugment for End- to- End Speech Translation', 'mt': 'On Using SpecAugment for End-to-End Speech Translation', 'mn': 'Сүүлийн төгсгөлд дуусах үеийн хөгжлийг ашиглах үед', 'no': 'På å bruk staveAugment for end- to- end- taleomsetjing', 'pl': 'O użyciu SpecAugment do kompleksowego tłumaczenia mowy', 'kk': 'Аяқтау- аяқтау аудармасының SpecAugment', 'sr': 'Pri korištenju SpecAugment za prevod govora do kraja', 'ro': 'Cu privire la utilizarea SpecAugment pentru traducerea vocală end-to-end', 'si': 'කතාවක් භාවිත කරන්න පුළුවන්', 'so': 'Isku isticmaalka hadalka', 'sv': 'Om användning av SpecAugment för End-to-End Talöversättning', 'ta': 'ஒலி மொழிபெயர்ப்பை பயன்படுத்தும்போது', 'ur': 'SpecAugment for End- to- End Speech Translation', 'uz': 'Augment for End- to- End Speech Translation', 'vi': 'Khi sử dụng thêm vật dụng cho giai đoạn giai đoạn cuối', 'bg': 'За използване на SpecAugment за превод на реч от край до край', 'hr': 'Pri korištenju SpecAugment za prevod govora do kraja', 'de': 'Zur Verwendung von SpecAugment für die End-to-End Sprachübersetzung', 'nl': 'Over het gebruik van SpecAugment voor end-to-end spraakvertaling', 'da': 'Om brug af SpecAugment til end-to-end tale oversættelse', 'ko': 'Specaugment의 단말기부터 단말기까지의 음성 번역에서의 응용', 'fa': 'در استفاده از استفاده SpecAugment برای ترجمه سخنرانی پایان تا پایان', 'sw': 'Augment for End-to-End Speech Translation', 'id': 'Pada Penggunaan SpecAugment for End-to-End Speech Translation', 'am': 'Augment for End-to-End Speech Translation', 'af': 'Op gebruik van SpeletjieAugment for End- to- End Speech Translation', 'hy': 'Օգտագործելով Speech Translate', 'bn': 'শেষ- থেকে শেষ- পর্যন্ত বাক্য অনুবাদের জন্য SpecAugment ব্যবহার করার সময়', 'bs': 'Na korištenju SpecAugment za prevod govora do kraja', 'sq': 'Në përdorimin e spektaklit për përkthimin e fjalës nga fundi në fund', 'tr': 'Soňra soňra söz terjime üçin speziýany ullanýanda', 'cs': 'O použití SpecAugment pro koncový překlad řeči', 'et': 'SpecAugmenti kasutamine lõpust lõpuni kõne tõlkimiseks', 'ca': 'En Usar SpecAugment per a traduir la voz de final a final', 'fi': 'SpecAugmentin k채ytt채minen p채채st채 p채채h채n -puheen k채채nt채miseen', 'az': 'S칬zl칲k T톛rcl톛m톛si 칲칞칲n S칬zl칲y칲 캻fad톛 Etdikd톛', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'ha': 'On Using SpecAugment for End-to-End Speech Translation', 'he': 'על השימוש של ספקאגмент לתרגום שיחה סוף-סוף', 'sk': 'O uporabi SpecAugmenta za prevajanje govora od konca do konca', 'bo': 'མཇུག་ལ་མཇུག་བསྡུ་ཡོད་པའི་སྐད་བརྗོད་སྟངས་སྤྱོད་བཞིན་པ'}
{'en': 'This work investigates a simple data augmentation technique, SpecAugment, for end-to-end speech translation. SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps. We apply SpecAugment on end-to-end speech translation tasks and achieve up to +2.2 % BLEU on LibriSpeech Audiobooks EnFr and +1.2 % on IWSLT TED-talks EnDe by alleviating ', 'ar': 'يبحث هذا العمل في تقنية بسيطة لزيادة البيانات ، وهي SpecAugment ، لترجمة الكلام من طرف إلى طرف. SpecAugment هي طريقة تنفيذ منخفضة التكلفة تُطبق مباشرةً على ميزات إدخال الصوت وتتكون من كتل إخفاء لقنوات التردد و / أو خطوات زمنية. نحن نطبق SpecAugment على مهام ترجمة الكلام من طرف إلى طرف ونحقق ما يصل إلى + 2.2٪ BLEU على LibriSpeech Audiobooks En → Fr و + 1.2٪ على IWSLT TED-talks En → De من خلال التخفيف من فرط التجهيز إلى حد ما. ندرس أيضًا فعالية الطريقة في مجموعة متنوعة من سيناريوهات البيانات ونبين أن الطريقة تؤدي أيضًا إلى تحسينات كبيرة في ظروف البيانات المختلفة بغض النظر عن كمية بيانات التدريب.', 'pt': 'Este trabalho investiga uma técnica simples de aumento de dados, SpecAugment, para tradução de fala de ponta a ponta. SpecAugment é um método de implementação de baixo custo aplicado diretamente aos recursos de entrada de áudio e consiste em mascarar blocos de canais de frequência e/ou etapas de tempo. Aplicamos SpecAugment em tarefas de tradução de fala de ponta a ponta e alcançamos até +2,2% BLEU em LibriSpeech Audiobooks En→Fr e +1,2% em IWSLT TED-talks En→De, aliviando até certo ponto o overfitting. Também examinamos a eficácia do método em uma variedade de cenários de dados e mostramos que o método também leva a melhorias significativas em várias condições de dados, independentemente da quantidade de dados de treinamento.', 'es': 'Este trabajo investiga una técnica simple de aumento de datos, SpecAugment, para la traducción de voz de extremo a extremo. SpecAugment es un método de implementación de bajo costo que se aplica directamente a las funciones de entrada de audio y consiste en enmascarar bloques de canales de frecuencia y/o pasos de tiempo. Aplicamos SPECaugment en tareas de traducción de voz de extremo a extremo y logramos hasta +2.2% BLEU en audiolibros LibriSpeech En→Fr y +1.2% en IWSLT TED-Talks En→De al aliviar el sobreajuste en cierta medida. También examinamos la eficacia del método en una variedad de escenarios de datos y demostramos que el método también conduce a mejoras significativas en varias condiciones de datos, independientemente de la cantidad de datos de entrenamiento.', 'fr': "Ce travail étudie une technique simple d'augmentation de données, SpecAugment, pour la traduction vocale de bout en bout. SPECAugment est une méthode d'implémentation peu coûteuse appliquée directement aux fonctions d'entrée audio et qui consiste à masquer des blocs de canaux de fréquence et/ou des pas de temps. Nous appliquons SPEcAugment aux tâches de traduction vocale de bout en bout et atteignons jusqu'à +2,2\xa0% d'UEBL sur LibriSpeech Audiobooks En→Fr et +1,2\xa0% sur IWSLT TED-Talks En→De en atténuant dans une certaine mesure le suréquipement. Nous examinons également l'efficacité de la méthode dans divers scénarios de données et montrons que la méthode conduit également à des améliorations significatives dans diverses conditions de données, quelle que soit la quantité de données d'entraînement.", 'ja': 'この研究では、エンドツーエンドの音声翻訳のための単純なデータ拡張技術、SpecAugmentを調査します。SpecAugmentは、オーディオ入力機能に直接適用される低コストの実装方法であり、周波数チャンネルのマスキングブロック、および/または時間ステップで構成されています。私たちは、エンドツーエンドの音声翻訳タスクにSpecAugmentを適用し、LibriSpeech Audiobooks En→ Frで最大+2.2%、IWSLT TED - Talks En→ Deで+1.2%のBLEUを達成します。また、様々なデータシナリオにおける方法の有効性を検討し、トレーニングデータの量に関係なく、様々なデータ条件の大幅な改善にもつながることを示した。', 'zh': '其治端到端音译者,略数增术SpecAugment。 SpecAugment者,直用于音频输功能之低成本,频率屏蔽,与/时步长成也。 于端音译用SpecAugment,于LibriSpeech有声读物En→Fr致达+2.2%之BLEU,于IWSLT TED-talks En→De得+1.2%之益,以减过拟合。 又考其法于诸数场中有效性,并明训练数据量如何,其法犹致显改。', 'hi': 'यह काम एक सरल डेटा संवर्धन तकनीक, SpecAugment, एंड-टू-एंड भाषण अनुवाद के लिए जांच करता है। SpecAugment एक कम लागत कार्यान्वयन विधि है जो सीधे ऑडियो इनपुट सुविधाओं पर लागू होती है और इसमें आवृत्ति चैनलों के मास्किंग ब्लॉक, और / या समय चरण होते हैं। हम एंड-टू-एंड स्पीच ट्रांसलेशन कार्यों पर SpecAugment लागू करते हैं और LibriSpeech Audiobooks En→Fr पर +2.2% BLEU तक और IWSLT TED-talks En→De पर +1.2% तक प्राप्त करते हैं। हम विभिन्न प्रकार के डेटा परिदृश्यों में विधि की प्रभावशीलता की भी जांच करते हैं और दिखाते हैं कि यह विधि प्रशिक्षण डेटा की मात्रा के बावजूद विभिन्न डेटा स्थितियों में महत्वपूर्ण सुधार की ओर भी ले जाती है।', 'ru': 'Эта работа исследует простой метод дополнения данных, SpecAugment, для сквозного перевода речи. SpecAugment - это недорогой метод реализации, применяемый непосредственно к функциям аудио ввода и состоящий из маскирующих блоков частотных каналов и/или временных шагов. Мы применяем SpecAugment для сквозных задач перевода речи и достигаем до +2,2% BLEU на аудиокнигах LibriSpeech En→Fr и +1,2% на IWSLT TED-talks En→De, в некоторой степени облегчая переобучение. Мы также изучаем эффективность метода в различных сценариях данных и показываем, что метод также приводит к значительному улучшению различных условий данных независимо от объема обучающих данных.', 'ga': 'Fiosraíonn an saothar seo teicníocht shimplí mhéadaithe sonraí, SpecAugment, le haghaidh aistriúchán cainte ceann go ceann. Is modh ísealchostais é SpecAugment a chuirtear i bhfeidhm go díreach ar na gnéithe ionchuir fuaime agus is éard atá ann bloic de chainéil minicíochta, agus/nó céimeanna ama a chumhdach. Cuirimid SpecAugment i bhfeidhm ar thascanna aistrithe cainte ceann go ceann agus bainimid suas le +2.2% BLEU ar Closleabhair LibriSpeech En→Fr agus +1.2% ar IWSLT TED-talks En→De trí rófheisteas a mhaolú go pointe áirithe. Scrúdaímid freisin éifeachtúlacht an mhodha i gcásanna sonraí éagsúla agus léirímid go dtagann feabhsuithe suntasacha ar choinníollacha sonraí éagsúla mar thoradh ar an modh, beag beann ar mhéid na sonraí oiliúna.', 'hu': 'Ez a munka egy egyszerű adatbővítési technikát, a SpecAugment-et vizsgálja a végpontos beszédfordításhoz. A SpecAugment egy alacsony költségű implementációs módszer, amelyet közvetlenül az audio bemeneti funkciókra alkalmaznak, és amely frekvenciacsatornák blokkjaiból és / vagy időlépésekből áll. A SpecAugment alkalmazását végpontos beszédfordítási feladatokra alkalmazzuk, és akár +2,2% BLEU-t érünk el a LibriSpeech Audiobooks En Fr-en és +1,2% IWSLT TED-talks En De-en azáltal, hogy bizonyos mértékben enyhítjük a túlterhelést. Megvizsgáljuk a módszer hatékonyságát különböző adatforgalmi forgatókönyvekben, és megmutatjuk, hogy a módszer jelentős javulást eredményez a különböző adatfeltételekben, függetlenül a képzési adatok mennyiségétől.', 'el': 'Η παρούσα εργασία διερευνά μια απλή τεχνική αύξησης δεδομένων, για την ολοκληρωμένη μετάφραση ομιλίας. Η μέθοδος εφαρμογής χαμηλού κόστους εφαρμόζεται απευθείας στα χαρακτηριστικά εισόδου ήχου και αποτελείται από την κάλυψη μπλοκ καναλιών συχνότητας ή/και χρονοβημάτων. Εφαρμόζουμε το σε ολοκληρωμένες εργασίες μετάφρασης ομιλίας και επιτυγχάνουμε έως +2.2% στα ακουστικά βιβλία και +1.2% στις ομιλίες με την ανακούφιση της υπερπροσαρμογής σε κάποιο βαθμό. Εξετάζουμε επίσης την αποτελεσματικότητα της μεθόδου σε ποικίλα σενάρια δεδομένων και αποδεικνύουμε ότι η μέθοδος οδηγεί επίσης σε σημαντικές βελτιώσεις σε διάφορες συνθήκες δεδομένων ανεξάρτητα από την ποσότητα των δεδομένων κατάρτισης.', 'ka': 'ეს სამუშაო მონაცემების მექნიკაცია, SpecAugment, საბოლოო დასასრულებელი სიტყვების გაგრძელება. SpecAugment არის ცოტა კონფიგურაციის გამოყენება მეტი, რომელიც აუდიო შეტყობინებაში მომხმარებულია და იქნება ფერიკურაციის კანალის ბლოკების მასკურაცია და/ან დროის ნაწ ჩვენ განვიყენებთ SpecAugment საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლოო საბოლო ჩვენ ასევე შევხედავთ განსხვავებული მონაცემების სენარიოში მეტის ეფექტიურობას და ჩვენ ჩვენ ჩვენ ჩვენ ჩვენ დავიწყებთ, რომ მეტი ასევე უფრო მნიშვნელოვანია განსხვავებული მონაცემებ', 'it': "Questo lavoro indaga una semplice tecnica di aumento dei dati, SpecAugment, per la traduzione vocale end-to-end. SpecAugment è un metodo di implementazione a basso costo applicato direttamente alle funzionalità di ingresso audio e consiste nel mascherare blocchi di canali di frequenza e/o passaggi temporali. Applichiamo SpecAugment sulle attività end-to-end di traduzione vocale e raggiungiamo fino a +2,2% BLEU sugli Audiolibri LibriSpeech En Fr e +1,2% sui TED-talks IWSLT En De alleviando in qualche misura l'overfitting. Esaminiamo anche l'efficacia del metodo in una varietà di scenari di dati e mostriamo che il metodo porta anche a miglioramenti significativi nelle varie condizioni di dati indipendentemente dalla quantità di dati di formazione.", 'lt': 'Šiuo darbu tiriamas paprastas duomenų didinimo metodas SpecAugment kalbos vertimui nuo pabaigos. SpecAugment yra nedidelės sąnaudos įgyvendinimo metodas, tiesiogiai taikomas garso įvedimo savybėms, kurį sudaro dažnių kanalų slėpimo blokai ir (arba) laiko žingsniai. Taikome SpecAugment kalbos vertimo užduotims nuo pabaigos ir siekiame iki +2,2 proc. BLEU kalbos knygose LibriSpeech En Fr ir +1,2 proc. kalbų TED kalbose IWSLT En De, tam tikru mastu sumažindami pernelyg didelę įrangą. We also examine the effectiveness of the method in a variety of data scenarios and show that the method also leads to significant improvements in various data conditions irrespective of the amount of training data.', 'kk': 'Бұл жұмыс сөздерді аяқтау- аяқтау үшін қарапайым деректерді көтеру техникасын, SpecAugment- ті зерттейді. SpecAugment - аудио келтіру мүмкіндіктеріне тікелей қолданылатын төмен бағаттарды іске асыру әдісі, және оның жиілік арналардың блоктарын қалқалау және/не уақыт қадамдарынан тұрад Біз SpecAugment сөздерді аяқтау кезінде аудару тапсырмаларына қолданатын және LibriSpeech аудио кітапшалары En Fr және +1.2% IWSLT TED- сөйлерінде En De дегенге көмектеседі. Мұндай-ақ біз әртүрлі деректер сценариясында тәжірибесін тексереміз және әдісі әртүрлі деректер шарттарындағы әртүрлі жақсартылығын қарай-қарай, әртүрлі деректер шарттарындағы әртүр', 'ms': 'Kerja ini menyelidiki teknik peningkatan data sederhana, SpecAugment, untuk terjemahan ucapan akhir-akhir. SpecAugment adalah kaedah pelaksanaan kosong rendah yang dilaksanakan secara langsung pada ciri-ciri input audio dan ia terdiri daripada menutup blok saluran frekuensi, dan/atau langkah masa. Kami melaksanakan SpecAugment pada tugas terjemahan ucapan akhir-akhir dan mencapai sehingga +2.2% BLEU pada LibriSpeech Audiobooks En Fr dan +1.2% pada IWSLT TED-talks En De dengan mengurangkan overfitting ke suatu kadar. We also examine the effectiveness of the method in a variety of data scenarios and show that the method also leads to significant improvements in various data conditions irrespective of the amount of training data.', 'ml': 'ഈ പ്രവര്\u200dത്തിക്കുന്നത് ഒരു ലളിതമായ ഡേറ്റാ കൂട്ടുന്നതിനുള്ള സ്പെക്ക് ഓഗ്മെന്\u200dറിന്\u200dറെ സാങ്കേതികവിദ്യ അന SpecAugment is a low- cost implementation method directly applied to the audio input features and it consists of frequency channels of masking blocks, and/or time steps. ഞങ്ങള്\u200d സ്പെക്ക് ആഗ്മെന്\u200dറ് അവസാന വാക്ക് പരിഭാഷണത്തിന്\u200dറെ ജോലികളില്\u200d പ്രയോഗിക്കുന്നു. ലിബ്രിസ്പ്യൂക്ക് ഓഡിയോബൂക്സില്\u200d 2. 2% ബില്ലിയൂ പ്രയോഗിക്കുന്നു. ലിവ്രിസ് വ്യത്യസ്ത വിവരങ്ങളുടെ പ്രകൃതിയുടെ രീതിയിലും നാം പരിശോധിക്കുന്നു. പരിശീലനത്തിനുള്ള വിവരങ്ങളുടെ വ്യത്യസ്തമായ വിവരങ്ങളില്\u200d നിന്നും വ്യത്', 'mn': 'Энэ ажил нь энгийн өгөгдлийн нэмэгдүүлэлтийн техник, СпекАгмент, төгсгөл ярианы хөгжүүлэлтийг судалдаг. SpecAugment гэдэг нь үнэт бага хэмжээний үйлдвэрлэлийн арга юм. Үүнд шууд үнэт хэмжээний арга болон/эсвэл цаг хугацааны хэсгүүдийг дүрслэх арга юм. Бид SpecAugment-г ярианы төгсгөлд хэлэх үйл ажиллагаанд хэрэглэж, LibriSpeech Audiobooks En Fr болон IWSLT TED-talks En De-д хэдэн хэмжээнд багасгаж нэмэгдүүлэхээр +2.2% BLEU хүртэл хүрэх болно. Мөн бид олон төрлийн өгөгдлийн хувилбарт аргын үр дүнг шалгаж, энэ арга нь мөн олон өгөгдлийн нөхцөлд сургалтын өгөгдлийн хэмжээнд хамаагүй олон нөхцөлд сайжруулдаг гэдгийг харуулж байна.', 'no': 'Dette arbeidet undersøker ein enkel dataaugmentasjonsteknikk, SpecAugment, for omsetjing av talet slutt til slutt. SpecAugment er ein låg kostnadsimplementasjonsmetode som vert brukt direkte til lyd-inndata-funksjonane, og det inneheld av maskeringsblokkar av frekvenskanalane og/eller tidsstrekk. Vi bruker SpecAugment på omsetjingsprogrammet til slutt- til- slutt og oppnår til +2,2% BLEU på LibriSpeech Audiobooks En Fr og +1,2% på IWSLT TED- talkar En De ved å alleviare overfitting til nokre måte. Vi undersøker også effektiviteten av metoden i mange datascenarior og viser at metoden fører også til signifikante forbedringar i ulike dataforhold uavhengig av kva mykje treningsdata.', 'pl': 'W niniejszej pracy badano prostą technikę powiększania danych, SpecAugment, do kompleksowego tłumaczenia mowy. SpecAugment to tania metoda implementacji stosowana bezpośrednio do funkcji wejścia audio i składa się z maskowania bloków kanałów częstotliwości i/lub kroków czasowych. Stosujemy SpecAugment do kompleksowych zadań tłumaczenia mowy i osiągamy do +2,2% BLEU na LibriSpeech Audiobooks En Fr oraz +1,2% na IWSLT TED-talks En De poprzez złagodzenie w pewnym stopniu nadmiernego dopasowania. Badamy również skuteczność metody w różnych scenariuszach danych i pokazujemy, że metoda ta prowadzi również do znaczącej poprawy w różnych warunkach danych niezależnie od ilości danych treningowych.', 'mk': 'Оваа работа истражува едноставна техника за зголемување на податоците, SpecAugment, за превод од крај до крај на говор. SpecAugment е метод за спроведување на ниските цени кој се применува директно на аудио внесувачките карактеристики и се состои од маскирање на блокови на фреквентни канали и/или временски чекори. Ние аплицираме SpecAugment за задачите за преведување на говорот од крај до крај и постигнуваме до +2,2 отсто БлеУ на авудиокнигите од LibriSpeech En Fr и +1,2 отсто на разговорите од IWSLT TED En De со олеснување на претерувањето во одреден степен. Исто така ја испитуваме ефикасноста на методот во различни сценарија на податоци и покажуваме дека методот, исто така, води до значителни подобрувања во различните услови на податоци без оглед на количината на податоци за обука.', 'ro': 'Această lucrare investighează o tehnică simplă de augmentare a datelor, SpecAugment, pentru traducerea end-to-end a vorbirii. SpecAugment este o metodă de implementare low-cost aplicată direct caracteristicilor de intrare audio și constă în mascarea blocurilor de canale de frecvență și / sau pași de timp. Aplicăm SpecAugment la sarcinile end-to-end de traducere a vorbirii și obținem până la +2,2% BLEU pe LibriSpeech Audiobook En Fr și +1,2% pe IWSLT TED-talks En De prin atenuarea suprasolicitării într-o anumită măsură. De asemenea, examinăm eficacitatea metodei într-o varietate de scenarii de date și arătăm că metoda duce, de asemenea, la îmbunătățiri semnificative în diferite condiții de date, indiferent de cantitatea de date de formare.', 'sr': 'Ovaj rad istražuje jednostavnu tehniku povećanja podataka, SpecAugment, za prevod govora do kraja. SpecAugment je metod implementacije niskoštanih troškova koji se primjenjuje direktno na zvukovne funkcije i sastoji se od maskiranja blokova frekvencijskih kanala i/ili vremenskih koraka. Primjenjujemo SpecAugment na zadatke prevoda govora do kraja i postižemo do +2,2% BLEU na LibriSpeech Audiobooksima En Fr i +1,2% na IWSLT TED-pregovorima En De, olakšavajući se u neku mjeru. Takođe pregledamo učinkovitost metode u raznim scenarijama podataka i pokazujemo da metod takođe vodi do značajnih poboljšanja u raznim uvjetima podataka bez obzira na količinu podataka o obuci.', 'mt': "Dan ix-xogħol jinvestiga teknika sempliċi ta’ żieda fid-dejta, SpecAugment, għat-traduzzjoni tad-diskors minn tarf sa tarf. SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps.  Aħna napplikaw SpecAugment dwar kompiti ta' traduzzjoni tad-diskors minn tarf sa tarf u nilħqu sa +2.2% BLEU fuq LibriSpeech Audibooks En Fr u +1.2% fuq IWSLT TED-talks En De billi jnaqqsu sa ċertu punt it-tagħmir żejjed. We also examine the effectiveness of the method in a variety of data scenarios and show that the method also leads to significant improvements in various data conditions irrespective of the amount of training data.", 'si': 'මේ වැඩේ සාමාන්\u200dය දත්ත විශාලනය විද්\u200dයාපයක් පරීක්ෂණය කරනවා, ස්පෙක්ස් ඇග්මෙන්ට්, අවසාන කතාවට අවස spell අපි ස්පෙක්ස් අවස්ථානය කරන්නේ end-to-end කතා අවස්ථානයේ අවස්ථානය සහ +2.2% BLUE වෙනුවෙන් +2.2% ලොබ්\u200dරිස්පෙච් අඩියෝබොක්ස් Enfr සහ +1.2% IWSLT TED-Talks Ende විශ අපි පරීක්ෂා කරනවා විවිධානයේ පරීක්ෂණය විවිධ දත්ත සීනාරියෝ වලින් විවිධානයක් වලින් පරීක්ෂණය කරනවා ඒ විධානය විවිධ', 'so': 'Shaqadaasu wuxuu baaraandegaa teknikada kordhiska macluumaadka ee fudud, SpecAugment, si loo turjumo luqada ugu dhammaado ilaa ugu dambaysta. SpecAugment waa qaab la soo saaro kharash ah oo toos loogu codsaday alaabta codka, waxaana ka mid ah goobaha isboobinta kanallada frequencies, iyo/ama tallaabooyin waqtiga ah. SpecAugment waxaynu ku codsanaynaa shaqada turjumaadda ugu dambaysta-to-end-speech and achieveynaa up to +2.2% BLEU oo ku saabsan LibriSpeech Audiobooks En Fr and +1.2% IWSLT TED-talks En De by reducing overfitting to some extent. Sidoo kale waxaynu baaritaannaa awoodda qaababka oo ku saabsan xaalada macluumaadka kala duduwan, waxaana tusinaynaa in qaababka uu ku hoggaamiyo hagaajinta aad u weyn, habase yeeshee tirada waxbarashada.', 'sv': 'Detta arbete undersöker en enkel dataförstärkningsteknik, SpecAugment, för heltäckande talöversättning. SpecAugment är en kostnadseffektiv implementeringsmetod som tillämpas direkt på ljudingångsfunktionerna och den består av maskering av block av frekvenskanaler och / eller tidssteg. Vi tillämpar SpecAugment på end-to-end talöversättningsuppgifter och uppnår upp till +2,2% BLEU på LibriSpeech Audiobooks En Fr och +1,2% på IWSLT TED-talks En De genom att lindra överpassning i viss mån. Vi undersöker också metodens effektivitet i en mängd olika datascenarier och visar att metoden också leder till betydande förbättringar i olika dataförhållanden oavsett mängden träningsdata.', 'ta': 'இந்த வேலை சுலபமான தரவு கூட்டுதல் தொழில்நுட்பத்தை தேடுகிறது, SpecAugment, முடிவில் இருந்து மொழிபேச்சு மொழிபெ SpecAugment is a low- cost implementation method directly applied to the audio input features and it is consistent with the masking of frequency channels, and/or time steps. We apply SpecAugment on end-to-end speech translation tasks and achieve up to +2.2% BLEU on LibriSpeech Audiobooks En Fr and +1.2% on IWSLT TED-talks En De by alleviating overfitting to some extent.  நாம் முறையின் விளைவுகளையும் பல தரவு காட்சிகளில் சோதிக்கிறோம் மற்றும் பயிற்சி தரவு அளவு எதுவும் இல்லாதிருந்தாலும் முறையிலும் முற', 'ur': 'یہ کام ایک ساده ڈیٹا افزایش ٹیکنیک کی تحقیق کرتا ہے، SpecAugment، آخر-to-end سخنرانی ترجمہ کے لئے۔ SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps. ہم نے اسپک اگنٹم کو پایان تک کلام کی ترجمہ کے کاموں پر لازم کیا ہے اور لیبری اسپک اڈیوبوک پر +2.2% BLEU تک پہنچ سکتے ہیں اور +1.2% IWSLT TED-talks En De پر کچھ اندازے سے زیادہ مہلت دیتے ہیں۔ ہم نے اس طرح طریقہ کی تاثیر کی تحقیق کی اور دکھائی کہ یہ طریقہ بھی مختلف ڈیٹ شرایط میں بہت اضافہ کرنے کی وجہ سے بہت اضافہ کرتا ہے.', 'vi': "Việc này nghiên cứu một kỹ thuật gia tăng dữ liệu đơn giản, Phát triển, để dịch qua kết thúc ngôn ngữ. Sự chỉ là một cách sự giải quyết học chính trực tiết với phần chất âm thanh. Nó bao gồm các nhà hành các các đường số tần số, và cái bước thời gian. Chúng tôi áp dụng Specment on end-to-end ngôn ngữ dịch vụ và sung mãn tới I+2.2=.='bleU on LibriSpeech Audiobobooks Ent Fru và +1.2=' on IWSLT chuyển Ted-No bằng cách giảm bớt các khoản bay qua. Chúng tôi cũng xem xét hiệu quả của phương pháp trong các mô phỏng dữ liệu khác nhau và cho thấy rằng phương pháp này cũng dẫn đến cải thiện đáng kể trong các tình trạng khác nhau về dữ liệu, bất kể số lượng dữ liệu đào tạo.", 'uz': 'Name Name @ info: status Шунингдек, биз турли маълумотлар фойдаларини кўриб турамиз ва шу усулда тахминлаш маълумотларнинг сони қанча ҳуқуқига эга бўлмаса ҳам, турли маълумотлар вазифасида муваффақиятсиз ўзгартирилтиришини кўрсатамиз.', 'da': 'Dette arbejde undersøger en enkel dataaugmentationsteknik, SpecAugment, til end-to-end taleoversættelse. SpecAugment er en billig implementeringsmetode, der anvendes direkte på lydindgangsfunktionerne, og den består af maskering blokke af frekvenskanaler og / eller tidstrin. Vi anvender SpecAugment på end-to-end taleoversættelsesopgaver og opnår op til +2,2% BLEU på LibriSpeech Audiobooks En Fr og +1,2% på IWSLT TED-talks En De ved at afhjælpe overtilpasning til en vis grad. Vi undersøger også metodens effektivitet i en række datascenarier og viser, at metoden også fører til betydelige forbedringer i forskellige dataforhold uanset mængden af træningsdata.', 'bg': 'Тази работа изследва проста техника за увеличаване на данните, за превод на реч от край до край. SpecAugment е нискоценен метод за внедряване, прилаган директно към аудио входните функции и се състои от маскиране на блокове от честотни канали и / или стъпки във времето. Ние прилагаме СпекУГМЕНТ при задачи за превод на реч от край до край и постигаме до +2.2% за аудиокнигите на ЛибриSpeech и +1.2% за лекции чрез облекчаване на пренапрежението до известна степен. Също така изследваме ефективността на метода в различни сценарии от данни и показваме, че методът води до значителни подобрения в различните условия на данни, независимо от количеството данни за обучение.', 'nl': "Dit werk onderzoekt een eenvoudige data augmentatie techniek, SpecAugment, voor end-to-end spraakvertaling. SpecAugment is een goedkope implementatiemethode die rechtstreeks wordt toegepast op de audio-invoerfuncties en bestaat uit het maskeren van blokken van frequentiekanalen en/of tijdstappen. We passen SpecAugment toe op end-to-end spraakvertaaltaken en bereiken tot +2,2% BLEU op LibriSpeech Audioboeken En Fr en +1,2% op IWSLT TED-talks En De door overfitting enigszins te verlichten. We onderzoeken ook de effectiviteit van de methode in verschillende datascenario's en laten zien dat de methode ook leidt tot aanzienlijke verbeteringen in verschillende datacondities ongeacht de hoeveelheid trainingsdata.", 'de': 'Diese Arbeit untersucht eine einfache Datenauswertungstechnik, SpecAugment, für die End-to-End Sprachübersetzung. SpecAugment ist eine kostengünstige Implementierungsmethode, die direkt auf die Audioeingabefunktionen angewendet wird und aus der Maskierung von Blöcken von Frequenzkanälen und/oder Zeitschritten besteht. Wir wenden SpecAugment auf End-to-End Sprachübersetzungsaufgaben an und erreichen bis zu +2,2% BLEU auf LibriSpeech Audiobooks En Fr und +1,2% auf IWSLT TED-Talks En De, indem wir Überfitting in gewissem Maße reduzieren. Zudem untersuchen wir die Effektivität der Methode in einer Vielzahl von Datenszenarien und zeigen, dass die Methode unabhängig von der Menge der Trainingsdaten auch zu signifikanten Verbesserungen in verschiedenen Datenbedingungen führt.', 'id': 'Pekerjaan ini menyelidiki teknik peningkatan data sederhana, SpecAugment, untuk terjemahan pidato akhir-akhir. SpecAugment adalah metode implementasi biaya rendah yang diterapkan langsung pada fitur input audio dan terdiri dari masking blok dari saluran frekuensi, dan/atau langkah waktu. Kami menerapkan SpecAugment pada tugas terjemahan pidato akhir-akhir dan mencapai hingga +2,2% BLEU pada LibriSpeech Audiobooks En Fr dan +1,2% pada IWSLT TED-talks En De dengan mengurangi overfitting ke suatu tingkat. Kami juga memeriksa efektivitas metode dalam berbagai skenario data dan menunjukkan bahwa metode juga mengarah kepada peningkatan signifikan dalam berbagai kondisi data tidak peduli jumlah data latihan.', 'hr': 'Ovaj rad istražuje jednostavnu tehniku povećanja podataka, SpecAugment, za prevod govora do kraja. SpecAugment je metod implementacije niskoštanih troškova primjenjen direktno na zvukovne funkcije i sastoji se od maskiranja blokova frekvencijskih kanala i/ili vremenskih koraka. Primjenjujemo SpecAugment na zadatke prevođenja govora do kraja i postignemo do +2,2% BLEU na LibriSpeech Audiobooksima En Fr i +1,2% na IWSLT TED-pregovorima En De olakšavajući se u neku mjeru. Također pregledamo učinkovitost metode u raznim scenarijama podataka i pokazujemo da metod također vodi do značajnih poboljšanja u raznim uvjetima podataka bez obzira na količinu podataka o obuci.', 'sw': 'This work investigates a simple data augmentation technique, SpecAugment, for end-to-end speech translation.  SpecAugment ni njia ya utekelezaji wa gharama ndogo inayotumiwa moja kwa moja kwenye vipengele vya sauti na inajumuisha kufungia vizuizi vya viwanja vya umeme, na/au hatua za muda. Tutumia SpecAugment katika kazi za kutafsiri kwa mwisho wa hotuba na kufikia asilimia 2.2 ya BLEU kwenye sauti za LibriSpeech En Fr na +1.2% katika mazungumzo ya IWSLT En De kwa kupunguza kusambaa kwa kiwango fulani. Pia tunachunguza ufanisi wa njia katika maeneo mbalimbali ya taarifa na kuonyesha kwamba mbinu hiyo pia inapelekea maboresho makubwa katika mazingira mbalimbali ya taarifa bila kujali kiasi cha taarifa za mafunzo.', 'ko': '본고는 단말기에서 단말기까지의 음성 번역에 사용되는 간단한 데이터 강화 기술인 Specaugment를 연구했다.Specaugment는 오디오 입력 기능에 직접 적용되는 저비용 실현 방법으로 주파수 채널 차단 블록과/또는 시간 보폭으로 구성되어 있다.Specaugment를 종단 간 음성 번역 임무에 적용해 과도한 의합을 어느 정도 완화함으로써 Libri Speech 오디오 리더 En Fr에서는 +2.2%에 달하는 BLEU를, IWSLT TED talks En De에서는 +1.2%의 BLEU를 구현했다.우리는 또한 이 방법이 각종 데이터 장면에서의 유효성을 검증한 결과 훈련 데이터의 양이 어떻든지 간에 이 방법은 각종 데이터 조건을 현저하게 개선할 수 있음을 나타냈다.', 'af': "Hierdie werk ondersoek 'n eenvoudige data augmentation techniek, SpecAugment, vir end- to- end spraak vertaling. SpecAugment is 'n lae koste implementering metode wat direk toegestel word na die oudio invoer funksies en dit bestaan van maskering blokke van frekwensiekanale en/of tyd stappe. Ons toewend SpecAugment op einde- na- einde spraak vertaling opdragte en bereik tot +2. 2% BLEU op LibriSpeech Audiobooks En Fr en +1. 2% op IWSLT TED- talks En De deur te alleviaat overfitting na sommige uitbreiding. Ons ondersoek ook die effektiviteit van die metode in 'n verskillende data scenarios en wys dat die metode ook na betekende verbeteringe in verskillende data voorwaardes lei, ongeag van die hoeveelheid onderwerking data.", 'fa': 'این کار یک تکنیک افزایش داده ساده، SpecAugment، برای ترجمه سخنرانی پایان و پایان تحقیق می\u200cکند. SpecAugment یک روش عملکرد هزینه کم است که مستقیماً به ویژه\u200cهای ورودی صوتی کاربرد می\u200cشود و از bloک\u200cهای ماسک\u200cسازی از کانال\u200cهای فرکانس و/یا قدم\u200cهای زمانی است. ما استفاده می\u200cکنیم SpecAugment در مورد کار ترجمه\u200cهای پایان و پایان سخنرانی و به +2.2% BLEU در LibriSpeech Audiobooks En Fr و +1.2% در IWSLT TED-talks En De با کمبود کردن زیادی به اندازه\u200cای. ما همچنین فعالیت روش را در مجموعه\u200cهای سناریو داده\u200cها تحقیق می\u200cکنیم و نشان می\u200cدهیم که این روش همچنین به بهترین شدید در شرایط داده\u200cهای مختلف، بی\u200cاثر مقدار داده\u200cهای آموزش، به سوی بهترین شدید ارائه می\u200cدهد.', 'tr': 'Bu işe basit maglumat ýetişdirmekçisi, SpecAugment, end-to-end çykyş terjime üçin barlanýar. SpecAugment ses girdi özelliklerine direkt uygulanan bir düşük kän eserleme yöntemidir we bu da frekanslar kanallaryň bloklaryndan, we/ýa zamanyň adımlarından oluşan bloklardyr. Biz specAugment soňunda çykyş täbliklerinde laýyşyrýarys we +2.2% BLEU LibriSpeech Audiobooksundan En Fr we +1.2% IWSLT TED-gepleklerinde En De-de birnäçe üýtgeşik bilen çykyşyrýarys. Biz hem daşary senaryolaryň täsirini maslahat edýäris we munuň ýagdaýynyň daşary şertlerde nähili üýtgetmeli maglumatlaryň haýsy bolmasyna raýtgetmeli däldigini görkez.', 'am': 'This work investigates a simple data augmentation technique, SpecAugment, for end-to-end speech translation.  Augment is a low cost implementation method directly used to the audio input features and it is consistent with masking blocks of frequency channels and/or time steps. በንግግር ለመጨረሻ መጨረሻ ትርጓሜ ስራዎችን እናደርጋለን እና ለብሪንግ ድምፅ ድምፅ አዲስ አዲስ እና በIWSLT ቴድ-ንግግር ዓይን ዲ በመስጠት እናስቀምጣለን፡፡ እና የሥርዓቱን ጥቅም በተለያዩ የዳታ ስናይኖች እናሳያልን እናሳያቸዋለን፣ የዳታ አካላት ብዛት ቢሆንም እናሳውቃለን፡፡', 'bn': 'এই কাজ শেষ থেকে শেষ পর্যন্ত ভাষণ অনুবাদের জন্য সাধারণ তথ্য যোগাযোগের প্রযুক্তি স্পেসিঅ্যাগমেন্ট, স্পেকঅ SpecAugment is a low-খরচ প্রয়োজনীয় পদ্ধতি যা সরাসরি অডিও ইনপুট বৈশিষ্ট্যাবলীর কাছে প্রয়োগ করা হয় এবং এর মধ্যে রয়েছে ফ্রেঞ্জি চ্যানেলের ব্লক, এবং/অথবা সময়ের প আমরা শেষ পর্যন্ত বক্তৃতা অনুবাদের কাজে স্পেকঅ্যাগ্রেমেন্ট প্রয়োগ করি এবং লিব্রিস্পেশ অডিওবুকে এন ফ্রেস এবং ১. We also examine the effectiveness of the method in a variety of data scenarios and show that the method also leads to significant improvements in various data conditions irrespective of the amount of training data.', 'az': "Bu işin basit veri artırma teknikəsini, SpecAugment, sona-sona söz çevirilməsi üçün incidir. SpecAugment audio girdi xüsusiyyətlərə düşük malik istifadə metodumudur. Bu, frekanlıq kanallarının bloklarını və/ya zaman adımlarının maskinə çevrildir. Biz SpecAugment'i son-to-end danışma işlərinə uygulayıq və LibriSpeech Audiobooksu En Fr və IWSLT TED-talks En De'də bir neçə qədər uyğunlaşdırmaq üçün +2.2% BLEU'a yetişirik. Biz həmçin in metodun müxtəlif məlumat senaryolarında təhsil edilməsini də incidirik və metodun təhsil məlumatlarının sayısına baxmayaraq, müxtəlif məlumat şartlarında möhkəm düzəltməsini də göstəririk.", 'bs': 'Ovaj rad istražuje jednostavnu tehniku povećanja podataka, SpecAugment, za prevod govora do kraja. SpecAugment je metod implementacije niskoštanih troškova koji se primjenjuje direktno na zvukovne funkcije i sastoji se od maskiranja blokova frekvencijskih kanala i/ili vremenskih koraka. Primjenjujemo SpecAugment na zadatke prevođenja govora do kraja i postignemo do +2,2% BLEU na LibriSpeech audiobooksima En Fr i +1,2% na IWSLT TED-pregovorima En De olakšavajući se u neku mjeru. Također pregledamo učinkovitost metode u raznim scenarijama podataka i pokazujemo da metod također vodi do značajnih poboljšanja u raznim uvjetima podataka bez obzira na količinu podataka o obuci.', 'cs': 'Tato práce zkoumá jednoduchou techniku rozšíření dat SpecAugment pro komplexní překlad řeči. SpecAugment je nízkonákladová implementační metoda aplikovaná přímo na audio vstupní funkce a skládá se z maskování bloků frekvenčních kanálů nebo časových kroků. Aplikujeme SpecAugment na komplexní úlohy překladu řeči a dosahujeme až +2,2% BLEU na LibriSpeech Audioknihy En Fr a +1,2% na IWSLT TED-přednáškách En De tím, že do určité míry zmírňujeme nadměrné vybavení. Dále zkoumáme efektivitu metody v různých datových scénářích a ukazujeme, že metoda vede rovněž k výraznému zlepšení v různých datových podmínkách bez ohledu na množství tréninkových dat.', 'sq': 'Ky punë heton një teknikë të thjeshtë të rritjes së të dhënave, SpecAugment, për përkthimin e fjalës nga fundi në fund. SpecAugment është një metodë zbatimi me kosto të ulët e aplikuar drejtpërdrejt në funksionet e hyrjes audio dhe përbëhet nga maskimi i blloqeve të kanaleve frekuence dhe/ose hapave kohore. Ne aplikojmë SpecAugment mbi detyrat e përkthimit të fjalës nga fundi në fund dhe arrijmë deri në +2.2% BLEU në LibriSpeech Audibooks En Fr dhe +1.2% në IWSLT TED-talks En De duke lehtësuar në një farë mënyre mbipajtimin. Ne gjithashtu shqyrtojmë efektshmërinë e metodës në një varietet skenarësh të të dhënave dhe tregojmë se metoda shpie gjithashtu në përmirësime të rëndësishme në kushtet e ndryshme të të dhënave pavarësisht nga sasia e të dhënave të trainimit.', 'et': 'Käesolevas töös uuritakse lihtsat andmete suurendamise tehnikat SpecAugmenti kõne lõpuni tõlkimiseks. SpecAugment on odav rakendusmeetod, mida rakendatakse otse helisisendi funktsioonidele ja mis koosneb sageduskanalite plokkide ja/või ajasammude varjamisest. Me rakendame SpecAugmenti kõnetõlke lõpp-lõpuni ülesannetele ja saavutame kuni +2,2% BLEU LibriSpeech Audiobooks En Fr ja +1,2% IWSLT TED-talks En De, leevendades teatud määral ülemäärast paigaldamist. Samuti uurime meetodi efektiivsust erinevates andmestsenaariumides ja näitame, et meetod toob kaasa ka erinevate andmetingimuste olulise paranemise olenemata koolitusandmete hulgast.', 'hy': 'Այս աշխատանքը ուսումնասիրում է պարզ տվյալների բարձրացման տեխնիկան, Սպեկագմենտ, խոսքի վերջ-վերջ թարգմանման համար: Spec Մենք օգտագործում ենք "Սպեկագում" խոսքի վերջ-վերջ թարգմանման խնդիրների վրա և հասնում ենք մինչև +2.2 տոկոսի "ԲԼԵՎ" գրադարանի ձայնային գրքերի վրա "Բիբրիսփեյս" և +1.2 տոկոսի "ԻՎՍԼԹ" TED-ելույթների վրա "Էն դե", որոշ չափով Մենք նաև ուսումնասիրում ենք մեթոդի արդյունավետությունը տարբեր տվյալների սցենարներում և ցույց ենք տալիս, որ մեթոդը նաև հանգեցնում է տարբեր տվյալների պայմաններում նշանակալի բարելավմաններին անկախ նրանից, թե որքան տվյալներ', 'fi': 'Tässä työssä tutkitaan yksinkertaista datan augmentaatiotekniikkaa, SpecAugment-tekniikkaa, puhekääntämiseen. SpecAugment on edullinen toteutusmenetelmä, jota sovelletaan suoraan äänituloominaisuuksiin ja joka koostuu taajuuskanavien lohkojen ja/tai aikavaiheiden peittämisestä. Sovellamme SpecAugmentia lopusta päähän -puhekäännöstehtäviin ja saavutamme jopa +2,2% BLEU:n LibriSpeech Audiobooks En Fr:ssä ja +1,2% IWSLT TED-talks En De:ssä lievittämällä ylikuormitusta jossain määrin. Tutkimme myös menetelmän tehokkuutta erilaisissa tietoskenaarioissa ja osoitamme, että menetelmä johtaa myös merkittäviin parannuksiin erilaisissa tietoolosuhteissa koulutustiedon määrästä riippumatta.', 'ca': "Aquesta feina investiga una tècnica simple d'augment de dades, SpecAugment, per a traduir la llengua de final a final. SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps.  Aplicam SpecAugment en tasques de traducció de llenguatge final a final i aconsegueixem fins a +2,2% BLEU en LibriSpeech Audibooks En Fr i +1,2% en IWSLT TED-talks En De alleviant en certa medida l'sobreafitament. També examinem l'eficacia del mètode en una varietat d'escenaris de dades i demostrem que el mètode també porta a millores significatives en diverses condicions de dades, independentment de la quantitat de dades d'entrenament.", 'jv': 'Label nyong bisa nggunakake sistem sistem pakan dones apakno, Espec AGment, kanggo tarjamahan end-to-end. Spelling Awakdhéwé nggunakaké Espec AGment tentang end-to-end pisan kelas terjamahan karo +.2% CLUE tentang +.2% nang Library iTalk Awak dhéwé éntuk pisan efek kanggo ngerasakno dadi seneng pisan anyari dadi, dadi iki dadi, nik awak dhéwé kuwi nggawe ngubah dhéwé ngerasakno kanggo ngerasakno dadi sing lihok, gak dhéwé, kudu nggawe data seneng pisan anyari dadi.', 'sk': 'V tem delu raziskujemo enostavno tehniko povečanja podatkov SpecAugment za prevajanje govora od konca do konca. SpecAugment je poceni izvedbeni način, ki se uporablja neposredno za funkcije avdio vhoda in je sestavljen iz maskiranja blokov frekvenčnih kanalov in/ali časovnih korakov. SpecAugment uporabljamo pri nalogah prevajanja govora od konca do konca in dosegamo do +2,2% BLEU pri LibriSpeech avdioknjigah En Fr in +1,2% pri IWSLT TED-talks En De z zmanjšanjem prekomernega prilagajanja do neke mere. Preučujemo tudi učinkovitost metode v različnih podatkovnih scenarijih in pokažemo, da metoda pomembno izboljšuje različne podatkovne pogoje ne glede na količino podatkov o usposabljanju.', 'ha': '@ info QShortcut @ action: button Kayya, Munã jarraba aikin methanin da ke cikin wasu fassarar data, kuma Muke nuna cewa metoden yana ƙara mafiya kyau a cikin mazaɓan data, kuma ko da tsakanin mutane na tsari.', 'bo': 'འདིས་ལས་སྒྲུབ་ཀྱིས་གསལ་བ་ཞིབ་འཇུག་བྱེད་ཀྱི་ཐབས་ལམ་ཞིག་བརྟན་ཞིབ་བྱེད་ཀྱི་ཡོད། SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps. We apply SpecAugment on end-to-end speech translation tasks and achieve up to +2.2% BLEU on LibriSpeech Audiobooks En Fr and +1.2% on IWSLT TED-talks En De by alleviating overfitting to some extent. ང་ཚོས་ཐབས་ལམ་ལུགས་གཙང་འབེབས་བྱས་མིན་འདུག་གི་ངལ་ཚོགས་སྐྱོང་བ་ཡིན་པས།', 'he': 'העבודה הזו חוקרת טכניקת שיפור נתונים פשוטה, SpecAugment, לתרגום נאום סוף-סוף. SpecAugment היא שיטת השימוש במחיר נמוך שמשתמשת ישירות לתוכניות הכניסה הקולנועית והיא מורכבת ממסות בלוקים של ערוצי תדירות, ו/או צעדים זמן. אנו משתמשים בספקאגמנט על משימות התרגום של נאום בסוף לסוף ולהשיג עד +2.2% BLEU על ספרי אודיו של LibriSpeech En Fr ו +1.2% על שיחות TED של IWSLT En De על ידי להקל על התאמה יתר במידה מסויימת. We also examine the effectiveness of the method in a variety of data scenarios and show that the method also leads to significant improvements in various data conditions irrespective of the amount of training data.'}
{'en': 'Estimating post-editing effort : a study on human judgements, task-based and reference-based metrics of MT quality', 'ar': 'تقدير جهود التحرير اللاحقة: دراسة عن الأحكام البشرية ، والمقاييس المستندة إلى المهام والمراجع لجودة الترجمة الآلية', 'pt': 'Estimando o esforço pós-edição: um estudo sobre julgamentos humanos, métricas baseadas em tarefas e baseadas em referência de qualidade MT', 'fr': "Estimation de l'effort de post-édition\xa0: une étude sur les jugements humains, les métriques basées sur les tâches et les références de la qualité de la traduction automatique", 'es': 'Estimación del esfuerzo posterior a la edición: un estudio sobre los juicios humanos, las métricas de calidad de la MT basadas en tareas y basadas en referencias', 'hi': 'पोस्ट-संपादन प्रयास का अनुमान लगाना: मानव निर्णयों पर एक अध्ययन, एमटी गुणवत्ता के कार्य-आधारित और संदर्भ-आधारित मीट्रिक', 'ja': 'ポストエディットの努力の推定： MT品質の人間の判断、タスクベース、および参照ベースの指標に関する研究', 'ru': 'Оценка усилий по постредактированию: исследование человеческих суждений, основанных на задачах и эталонных метрик качества МТ', 'zh': '度译后辑工作量:断人、基任、参机器翻译质量指标', 'ga': 'Iarracht iar-eagarthóireachta a mheas: staidéar ar bhreithiúnais dhaonna, méadracht tascbhunaithe agus tagairt-bhunaithe ar cháilíocht MT', 'el': 'Εκτίμηση της προσπάθειας μετά την επεξεργασία: μελέτη ανθρώπινων κρίσεων, μετρήσεων ποιότητας ΜΤ βάσει εργασιών και αναφοράς', 'ka': 'შემდეგ რედაქტირების ძალადობის განსაზღვრება: ადამიანის განსაზღვრების მეტრიკაზე, დავალების და რედაქტირებული მეტრიკაში', 'hu': 'Utószerkesztési erőfeszítések becslése: tanulmány az emberi megítélésekről, feladatalapú és referenciaalapú MT minőségi mutatókról', 'it': 'Stimare lo sforzo post-editing: uno studio sui giudizi umani, sulle metriche task-based e di riferimento della qualità MT', 'kk': 'Соңғы өңдеу жұмысын оқу: адамдардың оқиғалары, тапсырманың негізінде және сілтеме негізінде MT сапасы туралы зерттеу', 'lt': 'Po redakcijos atliktų pastangų apskaičiavimas: žmogaus vertinimo, MT kokybės pagal užduotis ir atskaitos kriterijų tyrimas', 'mk': 'Оценување на напорите по изданието: студија за човечките пресуди, метрики на квалитетот на МТ базирани на задачи и на референција', 'ms': 'Menghargai usaha selepas-edisi: kajian mengenai penilaian manusia, metrik berasaskan tugas dan rujukan kualiti MT', 'mt': 'Stima tal-isforz ta’ wara l-edizzjoni: studju dwar ġudizzji umani, metriċi bbażati fuq kompiti u metriċi bbażati fuq referenza tal-kwalità MT', 'ml': 'Estimating post-editing effort: a study on human judgements, task-based and reference-based metrics of MT quality', 'mn': 'Сүүлийн засварлалтын хичээл: хүн төрөлхтний шүүмжлээ, ажил дээр суурилсан, батлан суурилсан MT-ийн сайн талаар судалгаа.', 'no': 'Estemer etter redigeringsforsøk: ein studie om menneske uttrykk, oppgåvebasert og referansbasert metrikn av MT-kvalitet', 'pl': 'Ocena nakładu post-edycyjnego: badanie ocen ludzkich, wskaźników jakości MT opartych na zadaniach i referencjach', 'ro': 'Estimarea efortului post-editare: un studiu privind judecățile umane, măsurătorile bazate pe sarcini și referințe ale calității MT', 'sr': 'Procjenjivanje napora nakon redakcije: studija o ljudskim procenama, na zadatku bazirana i na referenciji bazirana metrika kvalitete MT-a', 'si': 'පස්ස සංපාදනය කරපු උත්සහ අනුමාන කරනවා: මිනිස්සු විශ්වාස, වැඩසටහන් අධාරණය සහ ප්\u200dරමාණය අධාරණය MT ක', 'so': 'Jahaadada sawirida kadib: waxbarasho ku saabsan xukunka dadka, shaqo-based iyo reference-based metrics of MT quality', 'sv': 'Uppskattning av efterredigeringsarbete: en studie om mänskliga bedömningar, uppgiftsbaserade och referensbaserade mätvärden för MT-kvalitet', 'ta': 'தொகுப்புப் பின் முயற்சி கணக்கிடுதல்: மனித த தீர்ப்புகள், பணி அடிப்படையில் மற்றும் குறிப்பு தரமான முறைமைகளின் மீத', 'ur': 'پوسٹ ویڈینگ کی کوشش کا ارزش کیا گیا ہے: انسان کے فیصلے کے بارے میں ایک تحقیق، ٹیس ٹی کیفیٹی کے متریک کے ذریعہ جو کام پر بنیاد ہے اور مرتبہ پر بنیاد ہے', 'uz': 'Tahrirlash orqali aniqlash', 'vi': 'Bộ định dạng kết nối: một nghiên cứu về các phán xét con người, các công việc dựa trên và các thước đo dạng MTV', 'hr': 'Procjenjivanje napora nakon redakcije: ispitivanje o ljudskim procjenima, temeljenim na zadatku i referentnim metrikama kvalitete MT-a', 'nl': 'Het schatten van post-editing inspanning: een studie naar menselijke oordelen, taakgebaseerde en referentiegebaseerde metrics van MT kwaliteit', 'da': 'Estimation post-editing indsats: en undersøgelse af menneskelige vurderinger, opgavebaserede og referencebaserede målinger af MT kvalitet', 'de': 'Abschätzung des Post-Editing Aufwands: eine Studie zu menschlichen Urteilen, aufgaben- und referenzbasierten Metriken der MT-Qualität', 'bg': 'Оценка на усилията след редактиране: изследване на човешките преценки, базирани на задачи и референтни показатели за качеството на МТ', 'ko': '편집 후의 작업량 추산: 기계 번역의 질에 대한 인간적 판단, 임무와 참고에 기초한 도량 연구', 'id': 'Perkiraan usaha setelah edisi: sebuah studi tentang penilaian manusia, metrik berbasis tugas dan berbasis referensi kualitas MT', 'fa': 'محاسبه تلاش بعد از ویرایش: مطالعه در مورد قضاوت انسان، متریک\u200cهای بنیاد عملیات و بنیاد مربوط به کیفیت MT', 'sw': 'Jaribio la kuhariri baada ya kuhariri: utafiti unaofanywa na maamuzi ya binadamu, yenye kazi na mbinu za usawa wa MT', 'af': 'Estimateer post-redigeering verskaf: ֳ¢ֲ€ֲ™n studie op menslike oordelings, taak-gebaseerde en verwysing-gebaseerde metries van MT-kwaliteit', 'sq': 'Vlerësimi i përpjekjes pas editimit: një studim mbi gjykimet njerëzore, metrikat e cilësisë MT bazuar në detyra dhe referencë', 'am': 'የፖስታ አስተካክል ፍላጎት: የሰው ፍርድ፣ የስራ እና የሥርዓት ማተሚያ የMT ጥጋት መጠን ላይ ትምህርት', 'tr': 'Sonra düzenlemek çabalaryny tahmin edip duran çabalar: adamlaryň hökmülerini, görevi tabanly we referens-tabanly MT kalitesi barada bir araştırma', 'hy': 'Ագնահատելով խմբագրությունից հետո փորձը՝ մարդկային դատողությունների, առաջադրանքների և համեմատական չափումների ուսումնասիրություն', 'az': 'Sonra d칲z톛ltm톛 칞abalar캼n캼 t톛min edir: insan h칬kml톛ri, g칬revi-tabanl캼 v톛 referans-tabanl캼 MT kaliteli metrikl톛ri haqq캼nda t톛hsil edilir.', 'ca': "Estima l'esforç posterior a l'edició: un estudi sobre els judicis humans, les mètriques de qualitat MT basades en tasques i en referències", 'bs': 'Procjenjivanje napora nakon editiranja: ispitivanje o ljudskim procenama, na zadatku bazirane i na referenciji bazirane metrike kvalitete MT-a', 'bn': 'পরিসম্পাদনের প্রচেষ্টা হিসেবে গবেষণা: মানুষের বিচার, কাজ ভিত্তিক এবং গণভিত্তিক মেটিকের উপর একটি গবেষণা:', 'cs': 'Odhad post editační úsilí: studie lidského úsudku, úkolových a referenčních metrik kvality MT', 'fi': 'Post-editing effort: tutkimus ihmisen arvosteluista, tehtäväperusteisista ja referenssipohjaisista mittausmenetelmistä MT:n laadusta', 'et': 'Hinnatakse toimetamisjärgset jõupingutust: uuring inimeste hinnangutest, ülesandepõhistest ja viitepõhistest MT kvaliteedi näitajatest', 'jv': 'Average', 'he': 'הערכה של מאמץ לאחר העורה: מחקר על שיפוטים אנושיים, מטריות מבוססות על משימה ומתמודדות על איכות MT', 'ha': 'Taking estimation aikin bayan editing: a research on humanity hukumies, a based job and Reference-based metrics of MT Quality', 'sk': 'Ocena napora po urejanju: študija človeških presoj, meritev kakovosti MT na podlagi nalog in referenc', 'bo': 'Estimating post-editing effort: a study on human judgements, task-based and reference-based metrics of MT quality'}
{'en': 'Devising ', 'ar': 'لطالما كان وضع مقاييس لتقييم جودة الترجمة في صميم أبحاث الترجمة الآلية. أظهرت المقاييس التقليدية المستندة إلى المراجع التلقائية ، مثل BLEU ، ارتباطات مع الأحكام البشرية المتعلقة بالكفاية والطلاقة وكانت ذات أهمية قصوى في تطوير نظام الترجمة الآلية. أدى التعهيد الجماعي إلى تعميم وتمكين قابلية المقاييس استنادًا إلى الأحكام البشرية ، مثل التقييمات الذاتية المباشرة (DA) للكفاية ، والتي يُعتقد أنها أكثر موثوقية من المقاييس التلقائية المستندة إلى المرجع. أخيرًا ، من المتوقع أن توفر القياسات القائمة على المهام ، مثل وقت التحرير اللاحق ، تقييمًا أكثر تفصيلاً لفائدة الترجمات لمهمة معينة. لذلك ، في حين أن متوسطات DA متوسطات أحكام الكفاية للحصول على تقييم للجودة (المتصورة) بشكل مستقل عن المهمة ، وتحاول المقاييس التلقائية المستندة إلى المرجع تقدير الجودة بموضوعية أيضًا بطريقة مستقلة عن المهمة ، فإن المقاييس المستندة إلى المهام هي القياسات التي تم الحصول عليها إما أثناء أو بعد أداء مهمة محددة. في هذه الورقة ، نناقش أنه على الرغم من أن القياسات القائمة على المهام باهظة الثمن ، إلا أنها الأكثر موثوقية عند تقدير جودة الترجمة الآلية في مهمة معينة ؛ في حالتنا ، هذه المهمة هي التحرير اللاحق. تحقيقًا لهذه الغاية ، نُبلغ عن تجارب على مجموعة بيانات بمؤشرات التحرير اللاحقة التي تم جمعها حديثًا ونبين فائدتها عند تقدير جهود التحرير اللاحقة. تُظهر نتائجنا أن المقاييس المستندة إلى المهام التي تقارن الإصدارات المترجمة آليًا والإصدارات المحررة لاحقًا هي الأفضل في التتبع\nجهود التحرير اللاحقة ، كما هو متوقع. هذه المقاييس يتبعها DA ، ثم المقاييس التي تقارن النسخة المترجمة آليًا والمراجع المستقلة. نقترح أن يكون ممارسو مسرح ماجنت مدركين لهذه الاختلافات وأن يعترفوا بآثارها عند تقرير كيفية تقييم مسرح ماجنت لأغراض التحرير اللاحق.', 'fr': "La conception de mesures permettant d'évaluer la qualité de la traduction a toujours été au cœur de la recherche en traduction automatique (TA). Les métriques automatiques traditionnelles basées sur des références, telles que BLEU, ont montré des corrélations avec les jugements humains de l'adéquation et de la fluidité et ont joué un rôle primordial dans l'avancement du développement des systèmes de TA. Le crowd-sourcing a popularisé et permis l'évolutivité de métriques basées sur des jugements humains, tels que les évaluations directes subjectives (DA) de l'adéquation, qui sont considérées comme plus fiables que les métriques automatiques basées sur des références. Enfin, les mesures basées sur les tâches, telles que le temps de post-édition, devraient fournir une évaluation plus détaillée de l'utilité des traductions pour une tâche spécifique. Par conséquent, alors que DA fait la moyenne des jugements d'adéquation pour obtenir une évaluation de la qualité (perçue) indépendamment de la tâche, et que les métriques automatiques basées sur des références tentent d'estimer objectivement la qualité également de manière indépendante de la tâche, les métriques basées sur les tâches sont des mesures obtenues soit pendant soit après tâche spécifique. Dans cet article, nous soutenons que, bien que coûteuses, les mesures basées sur les tâches sont les plus fiables pour estimer la qualité de la TA dans une tâche spécifique\xa0; dans notre cas, il s'agit de la post-édition. À cette fin, nous présentons des expériences sur un ensemble de données avec des indicateurs de post-édition récemment collectés et montrons leur utilité lors de l'estimation de l'effort de post-édition. Nos résultats montrent que les mesures basées sur les tâches comparant les versions traduites automatiquement et post-éditées sont les meilleures pour le suivi\neffort de post-édition, comme prévu. Ces métriques sont suivies par DA, puis par des métriques comparant la version traduite automatiquement et des références indépendantes. Nous suggérons que les praticiens de MT soient conscients de ces différences et reconnaissent leurs implications lorsqu'ils décident comment évaluer la MT à des fins de post-édition.", 'pt': 'A criação de métricas para avaliar a qualidade da tradução sempre esteve no centro da pesquisa de tradução automática (TA). Métricas tradicionais baseadas em referências automáticas, como BLEU, mostraram correlações com julgamentos humanos de adequação e fluência e têm sido fundamentais para o avanço do desenvolvimento de sistemas de TA. O crowdsourcing popularizou e possibilitou a escalabilidade de métricas baseadas em julgamentos humanos, como avaliações diretas subjetivas (DA) de adequação, que se acredita serem mais confiáveis do que métricas automáticas baseadas em referência. Finalmente, espera-se que as medições baseadas em tarefas, como o tempo de pós-edição, forneçam uma avaliação mais detalhada da utilidade das traduções para uma tarefa específica. Portanto, enquanto o DA calcula a média dos julgamentos de adequação para obter uma avaliação da qualidade (percebida) independentemente da tarefa, e as métricas automáticas baseadas em referência tentam estimar objetivamente a qualidade também de maneira independente da tarefa, as métricas baseadas em tarefas são medidas obtidas durante ou após realizar uma tarefa específica. Neste artigo, argumentamos que, embora caras, as medições baseadas em tarefas são as mais confiáveis ao estimar a qualidade da MT em uma tarefa específica; no nosso caso, essa tarefa é pós-edição. Para esse fim, relatamos experimentos em um conjunto de dados com indicadores de pós-edição recém-coletados e mostramos sua utilidade ao estimar o esforço de pós-edição. Nossos resultados mostram que as métricas baseadas em tarefas comparando versões traduzidas por máquina e pós-editadas são as melhores no rastreamento\nesforço de pós-edição, como esperado. Essas métricas são seguidas por DA e, em seguida, por métricas que comparam a versão traduzida por máquina e as referências independentes. Sugerimos que os praticantes de TA estejam cientes dessas diferenças e reconheçam suas implicações ao decidir como avaliar a TA para fins de pós-edição.', 'ja': '翻訳品質を評価するための指標を考案することは、常に機械翻訳（ MT ）研究の中心でした。 BLEUなどの従来の自動参照ベースの指標は、適切性と流暢性の人間の判断との相関関係を示しており、MTシステム開発の進歩にとって最も重要でした。 クラウドソーシングは、参照ベースの自動メトリックよりも信頼性が高いと考えられる、妥当性の主観的直接評価（ DA ）などの人間の判断に基づくメトリックの拡張性を普及させ、可能にしました。 最後に、ポストエディット時間などのタスクベースの測定は、特定のタスクのための翻訳の有用性のより詳細な評価を提供することが期待される。 したがって、DAは適切性の判断を平均化してタスクとは無関係に（知覚された）品質の評価を取得し、参照ベースの自動メトリックはタスクに依存しない方法でも品質を客観的に推定しようとするが、タスクベースのメトリックは、特定のタスクの実行中または実行後に取得される測定値である。 この論文では、特定のタスクのMT品質を推定する場合、高価でタスクベースの測定が最も信頼性が高いと主張しています。私たちの場合、このタスクはポストエディットです。 そのために、私たちは新しく収集されたポストエディットインジケーターを使用したデータセットの実験を報告し、ポストエディットの手間を推定する際にその有用性を示します。 私たちの結果は、機械翻訳版とポスト編集版を比較するタスクベースの指標が、トラッキングに最適であることを示しています。\n予想通りのポストエディットの努力。これらの指標の後にDAが続き、次に機械翻訳版と独立した参照を比較する指標が続きます。MTの実践者は、ポストエディット目的でMTを評価する方法を決定する際に、これらの違いを認識し、その影響を認識する必要があることを提案する。', 'es': 'La elaboración de métricas para evaluar la calidad de la traducción siempre ha estado en el centro de la investigación de la traducción automática (MT). Las métricas tradicionales basadas en referencias automáticas, como BLEU, han mostrado correlaciones con los juicios humanos de adecuación y fluidez y han sido fundamentales para el avance del desarrollo del sistema de MT. El crowdsourcing ha popularizado y permitido la escalabilidad de las métricas basadas en juicios humanos, como las evaluaciones directas subjetivas (DA) de la adecuación, que se cree que son más fiables que las métricas automáticas basadas en referencias. Finalmente, se espera que las mediciones basadas en tareas, como el tiempo de post-edición, proporcionen una evaluación más detallada de la utilidad de las traducciones para una tarea específica. Por lo tanto, mientras que el DA promedia los juicios de adecuación para obtener una evaluación de la calidad (percibida) independientemente de la tarea, y las métricas automáticas basadas en referencias intentan estimar objetivamente la calidad también de manera independiente de la tarea, las métricas basadas en tareas son mediciones obtenidas durante o después de realizar un tarea específica. En este artículo argumentamos que, aunque costosas, las mediciones basadas en tareas son las más fiables a la hora de estimar la calidad de la MT en una tarea específica; en nuestro caso, esta tarea es la postedición. Con ese fin, informamos de experimentos en un conjunto de datos con indicadores de postedición recién recopilados y mostramos su utilidad al estimar el esfuerzo posterior a la edición. Nuestros resultados muestran que las métricas basadas en tareas que comparan versiones traducidas automáticamente y post-editadas son las mejores en el seguimiento\nesfuerzo posterior a la edición, como se esperaba. Estas métricas van seguidas de DA y, a continuación, de métricas que comparan la versión traducida automáticamente y las referencias independientes. Sugerimos que los profesionales de MT sean conscientes de estas diferencias y reconozcan sus implicaciones a la hora de decidir cómo evaluar la MT con fines de post-edición.', 'zh': '设意评译者指标常机器翻译 (MT) 究其心。 古之道,自参之指标(BLEU)已见充分性流畅性之相关性,而于机器翻译之进退至重。 众包已通于人指标之可扩展性,如充分性之主直评(DA),指标以为比于参考之自指标也。 最后,基于任量,如译后辑日月,预计特定译者有用性更深评之。 故虽DA平均充分性断以得独立之(知)量,而本于参考之自指标,亦试以无关于事者,指标于特定任之间,而后得其量焉。 于本文,臣愚以为虽成本贵,盖度特定之机器翻译,最为可恃。 于我例中,此事后辑。 因用新译后编辑指标报数集上实验,并于估译后编辑工量展其有用性。 臣等之的结果表明,较机器翻译、后期编辑版本之本指标最善踪迹\n如预期者,译后辑事。 此指标后随 DA,然后较机器翻译版本、独引之指标。 臣等建议,机器翻译从业人员于定议评估机器翻译以译后编辑,宜知其异而承其影响。', 'ru': 'Разработка метрик для оценки качества перевода всегда была в центре исследований машинного перевода (MT). Традиционные автоматические эталонные метрики, такие как BLEU, показали корреляцию с человеческими суждениями об адекватности и беглости и имели первостепенное значение для продвижения развития системы MT. Краудсорсинг популяризировал и обеспечил масштабируемость метрик на основе человеческих суждений, таких как субъективные прямые оценки (DA) адекватности, которые считаются более надежными, чем эталонные автоматические метрики. Наконец, ожидается, что измерения на основе задач, такие как время после редактирования, обеспечат более детальную оценку полезности переводов для конкретной задачи. Таким образом, в то время как DA усредняет оценки адекватности для получения оценки (воспринимаемого) качества независимо от задачи, а эталонные автоматические метрики пытаются объективно оценить качество также независимо от задачи, метрики на основе задачи - это измерения, полученные во время или после выполнения конкретной задачи. В этой статье мы утверждаем, что, хотя измерения на основе задач являются дорогостоящими, они являются наиболее надежными при оценке качества МП в конкретной задаче; в нашем случае эта задача является постредактированием. С этой целью мы сообщаем об экспериментах над набором данных с вновь собранными показателями постредактирования и показываем их полезность при оценке усилий постредактирования. Наши результаты показывают, что метрики на основе задач, сравнивающие машинопереведенные и отредактированные версии, лучше всего отслеживают\nусилия после редактирования, как и ожидалось. За этими метриками следует DA, а затем метрики, сравнивающие версию, переведенную машиной, и независимые ссылки. Мы предлагаем, чтобы практические работники MT были осведомлены об этих различиях и признавали их последствия при принятии решения о том, как оценивать MT для целей пост-редактирования.', 'ga': 'Bhí meadracht a cheapadh chun cáilíocht an aistriúcháin a mheas mar chroílár taighde ar aistriúchán meaisín (MT) i gcónaí. Tá comhghaolta léirithe ag méadracht thraidisiúnta bunaithe ar thagairtí uathoibríocha, amhail BLEU, le breithiúnais daonna maidir le leordhóthanacht agus líofacht agus bhí siad ríthábhachtach chun forbairt córas MT a chur chun cinn. Tá tóir agus cumasaithe ag slua-fhoinsiú inscálaithe méadrachta bunaithe ar bhreithiúnais dhaonna, amhail measúnuithe díreacha suibiachtúla (DA) ar leordhóthanacht, a chreidtear a bheith níos iontaofa ná méadracht uathoibríoch atá bunaithe ar thagairtí. Ar deireadh, táthar ag súil go soláthróidh tomhais tascbhunaithe, amhail am iar-eagarthóireachta, luacháil níos mionsonraithe ar úsáideacht aistriúcháin do thasc ar leith. Mar sin, cé go ndéanann DA breithiúnais ar an meán leorgacht chun breithmheas a fháil ar cháilíocht (bhraite) neamhspleách ar an tasc, agus déanann méadracht uathoibríoch atá bunaithe ar thagairtí iarracht cáilíocht a mheas go hoibiachtúil ar bhealach atá neamhspleách ar thasc, is tomhais iad méadrachtaí tascbhunaithe a fhaightear le linn nó le linn. tar éis tasc ar leith a chomhlíonadh. Sa pháipéar seo áitímid, cé gurb iad tomhais costasacha, tascbhunaithe na cinn is iontaofa agus cáilíocht MT á mheas i dtasc ar leith; inár gcás, tá an tasc seo iar-eagarthóireacht. Chuige sin, tuairiscímid turgnaimh ar thacar sonraí le táscairí iar-eagarthóireachta nua-bhailithe agus léirímid a n-úsáidí agus iarracht iar-eagarthóireachta á meas. Léiríonn ár dtorthaí gurb iad méadracht thasc-bhunaithe a dhéanann comparáid idir leaganacha meaisín-aistrithe agus iar-eagarthóireachta na cinn is fearr maidir le rianú.\niarracht iar-eagarthóireachta, mar a bheifí ag súil leis. Leanann DA na méadrachtaí seo, agus ansin méadracht a dhéanann comparáid idir an leagan meaisín-aistrithe agus tagairtí neamhspleácha. Molaimid gur chóir go mbeadh cleachtóirí MT feasach ar na difríochtaí seo agus a n-impleachtaí a admháil agus cinneadh á dhéanamh conas MT a mheas chun críocha iar-eagarthóireachta.', 'hi': 'अनुवाद की गुणवत्ता का आकलन करने के लिए मीट्रिक तैयार करना हमेशा मशीन अनुवाद (एमटी) अनुसंधान के मूल में रहा है। पारंपरिक स्वचालित संदर्भ-आधारित मीट्रिक, जैसे कि BLEU, ने पर्याप्तता और प्रवाह के मानव निर्णयों के साथ सहसंबंध दिखाए हैं और एमटी सिस्टम विकास की प्रगति के लिए सर्वोपरि रहे हैं। क्राउड-सोर्सिंग ने मानव निर्णयों के आधार पर मीट्रिक की स्केलेबिलिटी को लोकप्रिय और सक्षम किया है, जैसे कि पर्याप्तता के व्यक्तिपरक प्रत्यक्ष आकलन (डीए), जिन्हें संदर्भ-आधारित स्वचालित मीट्रिक की तुलना में अधिक विश्वसनीय माना जाता है। अंत में, कार्य-आधारित माप, जैसे कि पोस्ट-एडिटिंग समय, से एक विशिष्ट कार्य के लिए अनुवाद की उपयोगिता का अधिक डी-टेल मूल्यांकन प्रदान करने की उम्मीद की जाती है। इसलिए, जबकि डीए कार्य से स्वतंत्र रूप से (कथित) गुणवत्ता का मूल्यांकन प्राप्त करने के लिए पर्याप्तता निर्णयों का औसत करता है, और संदर्भ-आधारित स्वचालित मीट्रिक निष्पक्ष रूप से गुणवत्ता का अनुमान लगाने का प्रयास करते हैं, कार्य-आधारित मीट्रिक एक विशिष्ट कार्य करने के दौरान या बाद में प्राप्त किए गए माप होते हैं। इस पेपर में हम तर्क देते हैं कि, हालांकि महंगा, कार्य-आधारित माप एक विशिष्ट कार्य में एमटी गुणवत्ता का अनुमान लगाते समय सबसे विश्वसनीय होते हैं; हमारे मामले में, यह कार्य पोस्ट-एडिटिंग है। उस अंत तक, हम नए-एकत्र किए गए पोस्ट-एडिटिंग संकेतकों के साथ डेटासेट पर प्रयोगों की रिपोर्ट करते हैं और पोस्ट-एडिटिंग प्रयास का अनुमान लगाते समय उनकी उपयोगिता दिखाते हैं। हमारे परिणामों से पता चलता है कि मशीन-अनुवादित और पोस्ट-संपादित संस्करणों की तुलना करने वाले कार्य-आधारित मीट्रिक ट्रैकिंग में सबसे अच्छे हैं\nपोस्ट संपादन प्रयास, के रूप में उम्मीद है. इन मैट्रिक्स के बाद DA, और फिर मशीन-अनुवादित संस्करण और स्वतंत्र संदर्भों की तुलना करने वाले मीट्रिक द्वारा किए जाते हैं। हमारा सुझाव है कि एमटी चिकित्सकों को इन मतभेदों के बारे में पता होना चाहिए और पोस्ट-एडिटिंग उद्देश्यों के लिए एमटी का मूल्यांकन करने के तरीके को तय करते समय उनके निहितार्थों को स्वीकार करना चाहिए।', 'ka': 'მეტრიკის მოწყობილობა, რომელიც გადაწყვეტილების კაalitეტის განსაზღვრება, ყოველთვის მაქინის გადაწყვეტილების (MT) სწორეში იყო. ტრადიციონალური ავტომატიკური რეფერენტიკური მეტრიკები, როგორც BLEU, გამოჩვენეთ ადამიანის წინასწორებების შესაძლებლობა და ფუნქციის შესაძლებლობა და MT სისტემის განვითარებას გასაკეთებლად სამყარო წარმოდგენა და მოძლევა მეტრიკას სკალუალურობას, როგორც ადამიანის წარმოდგენებიდან, როგორც სამყარო მხოლოდ სამყარო განსაზღვრება (DA), რომელიც იფიქრობენ უფრო დარწმუნელია, ვი საბოლოოდ, სამუშაო დამუშავებული მონაცემები, როგორც შემდეგ რედაქტირების დრო, უფრო განსაზღვრებული მონაცემების გამოყენება განსაზღვრებული მონაცემების გამოყენება. ამიტომ, რადგან ეკონტაქტის განსაკუთრებული კოლეტურის განსაკუთრებით (აღმოჩნდა) კალეტურის განსაკუთრებისთვის განსაკუთრებისთვის, და განსაკუთრებული ავტომატიკური მეტრიკის განსაკუთრებისთვის მოცდილობა დავადგინოთ კოლეტური საქმე ამ დომენტში გვაქვს რომ, მაგრამ ძალიან ძალიან ძალიან დასაწყებელი, რაოდენობის განზომილებები უფრო დარწმუნებელია, როდესაც MT-ის კონფიკური რაოდენობაში გა ჩვენი შემთხვევაში, ეს დავალება შემდეგ რედაქტირება. მისი დასაწყისთვის, ჩვენ ექსპერიმენტები მონაცემების კონფიგურაციაში ახალი კონფიგურაციული მორედაქტირების ინდექტორებით შეგვიყვანეთ და ჩვენ გამოყენებული გამოსახულ ჩვენი წარმოდგენები გამოჩვენებენ, რომ დავამუშავებული მეტრიკები მაქინის გადაწყვეტილება და შემდეგ რედაქტირებული ვერსიები უკეთესი შემდეგ\nშემდეგ რედაქტირების ძალადობა, როგორც უნდა იყოს. ამ მეტრიკების შემდეგ ეკონტურაცია და შემდეგ მეტრიკების შემდეგ მეტრიკების შემდეგ მანქანის გადაწყვეტილი ვერსია და უცნობიერი რეფერენციები. ჩვენ გვეძლევა, რომ MT პრაქტიციონტერები უნდა იცოდნენ ამ განსხვავებების შესახებ და იცოდნენ მისი შესახებ, როდესაც გადაწყვეტილება - როგორ გაუუმუშავება MT-ს პო', 'hu': 'A fordítási minőség értékelésére szolgáló mutatók kidolgozása mindig is a gépi fordítás (MT) kutatásának központi eleme volt. A hagyományos automatikus referencia-alapú mutatók, mint például a BLEU, összefüggést mutattak az emberi megfelelőségi és folyékonysági megítélésekkel, és kulcsfontosságúak voltak az MT rendszer fejlesztésének előrehaladásában. A közösségi források népszerűsítették és lehetővé tették az emberi ítéleteken alapuló mérőszámok skálázhatóságát, mint például a megfelelőség szubjektív közvetlen értékelése (DA), amelyek vélhetően megbízhatóbbak, mint a referenciaalapú automatikus mérőszámok. Végezetül a feladatalapú mérések, mint például a szerkesztés utáni idő, várhatóan pontosabban értékelik a fordítások hasznosságát egy adott feladathoz. Ezért míg a DA a feladattól függetlenül értékelhető (észlelt) minőség értékeléséhez szükséges átlagokat végez, a referenciaalapú automatikus mutatók pedig feladatfüggetlen módon is objektíven próbálják becsülni a minőséget, a feladatalapú mutatók egy adott feladat elvégzése során vagy után kapott mérések. Ebben a tanulmányban azzal érvelünk, hogy bár drága, feladatalapú mérések a legmegbízhatóbbak egy adott feladat MT minőségének becslésekor; A mi esetünkben ez a feladat utószerkesztés. Ennek érdekében újonnan összegyűjtött szerkesztési mutatókkal ellátott adatkészleten végzett kísérleteket jelentünk be, és megmutatjuk azok hasznosságát a szerkesztési erőfeszítések becslésekor. Eredményeink azt mutatják, hogy a gépi és utólagos verziókat összehasonlító feladatalapú mutatók a legjobb nyomon követésben\nutószerkesztési erőfeszítések, ahogy várták. Ezeket a mutatókat a DA, majd a géppel lefordított verziót és a független hivatkozásokat összehasonlító mutatók követik. Javasoljuk, hogy az MT gyakorlók tisztában legyenek ezekkel a különbségekkel, és ismerjék el azok következményeit, amikor eldöntik, hogyan értékeljék az MT utószerkesztési célokra.', 'el': 'Η ανάπτυξη μετρήσεων για την αξιολόγηση της ποιότητας της μετάφρασης ήταν πάντα ο πυρήνας της έρευνας για τη μηχανική μετάφραση (ΜΤ). Οι παραδοσιακές αυτόματες μετρήσεις που βασίζονται σε αναφορές, όπως η BLEU, έχουν δείξει συσχετισμούς με τις ανθρώπινες κρίσεις επάρκειας και ευκρίνειας και έχουν καθοριστεί για την πρόοδο της ανάπτυξης συστημάτων ΜΤ. Η εύρεση πλήθους έχει δημοσιοποιήσει και επιτρέψει την κλιμάκωση των μετρήσεων που βασίζονται σε ανθρώπινες κρίσεις, όπως οι υποκειμενικές άμεσες αξιολογήσεις επάρκειας, οι οποίες πιστεύεται ότι είναι πιο αξιόπιστες από τις αυτόματες μετρήσεις που βασίζονται σε αναφορές. Τέλος, οι μετρήσεις βάσει εργασιών, όπως ο χρόνος μετά την επεξεργασία, αναμένεται να παρέχουν μια πιο λεπτομερή αξιολόγηση της χρησιμότητας των μεταφράσεων για μια συγκεκριμένη εργασία. Ως εκ τούτου, ενώ ο μέσος όρος κρίνει την επάρκεια για να επιτύχει μια εκτίμηση της (αντιληπτής) ποιότητας ανεξάρτητα από την εργασία, και οι αυτόματες μετρήσεις βάσει αναφοράς προσπαθούν να εκτιμήσουν αντικειμενικά την ποιότητα, επίσης με τρόπο ανεξάρτητο από την εργασία, οι μετρήσεις βάσει εργασιών είναι μετρήσεις που λαμβάνονται είτε κατά τη διάρκεια είτε μετά την εκτέλεση μιας συγκεκριμένης εργασίας. Στην παρούσα εργασία υποστηρίζουμε ότι, αν και δαπανηρές, οι μετρήσεις βάσει εργασιών είναι οι πιο αξιόπιστες κατά την εκτίμηση της ποιότητας ΜΤ σε μια συγκεκριμένη εργασία. Στην περίπτωσή μας, αυτή η εργασία είναι μετά την επεξεργασία. Για το σκοπό αυτό, αναφέρουμε πειράματα σε ένα σύνολο δεδομένων με πρόσφατα συλλεγμένους δείκτες μετα-επεξεργασίας και δείχνουν τη χρησιμότητά τους κατά την εκτίμηση της προσπάθειας μετα-επεξεργασίας. Τα αποτελέσματά μας δείχνουν ότι οι μετρήσεις βάσει εργασιών που συγκρίνουν εκδόσεις μεταφρασμένες με μεταγενέστερες εκδόσεις είναι οι καλύτερες στην παρακολούθηση\nπροσπάθεια μετά την επεξεργασία, όπως αναμενόταν. Αυτές οι μετρήσεις ακολουθούνται από DA, και στη συνέχεια από μετρήσεις που συγκρίνουν την έκδοση που μεταφράζεται από μηχανή και ανεξάρτητες αναφορές. Προτείνουμε οι επαγγελματίες της ΜΤ να γνωρίζουν αυτές τις διαφορές και να αναγνωρίζουν τις επιπτώσεις τους όταν αποφασίζουν πώς θα αξιολογήσουν τη ΜΤ για σκοπούς μετα-μοντάζ.', 'it': "La definizione di metriche per valutare la qualità della traduzione è sempre stata al centro della ricerca sulla traduzione automatica (MT). Le metriche automatiche tradizionali basate su riferimento, come BLEU, hanno mostrato correlazioni con i giudizi umani di adeguatezza e fluidità e sono state fondamentali per l'avanzamento dello sviluppo del sistema MT. Il crowd-sourcing ha reso popolare e reso possibile la scalabilità delle metriche basate sui giudizi umani, come le valutazioni soggettive dirette (DA) dell'adeguatezza, ritenute più affidabili delle metriche automatiche basate su riferimento. Infine, le misurazioni basate su attività, come il tempo di post-editing, dovrebbero fornire una valutazione più dettagliata dell'utilità delle traduzioni per un'attività specifica. Pertanto, mentre DA media i giudizi di adeguatezza per ottenere una valutazione della qualità (percepita) indipendentemente dall'attività, e le metriche automatiche basate su riferimento cercano di stimare oggettivamente la qualità anche in modo indipendente dall'attività, le metriche basate su attività sono misurazioni ottenute durante o dopo l'esecuzione di una specifica attività. In questo articolo sosteniamo che, sebbene costose, le misurazioni basate su attività sono le più affidabili quando si stima la qualità MT in un compito specifico; nel nostro caso, questo compito è post-editing. A tal fine, riportiamo esperimenti su un set di dati con indicatori di post-editing appena raccolti e mostriamo la loro utilità nella stima dello sforzo post-editing. I nostri risultati mostrano che le metriche basate su attività che confrontano versioni tradotte automaticamente e post-modificate sono le migliori nel tracciamento\nlavoro post-editing, come previsto. Queste metriche sono seguite da DA, e poi da metriche che confrontano la versione tradotta automaticamente e i riferimenti indipendenti. Suggeriamo che i professionisti MT siano consapevoli di queste differenze e riconoscano le loro implicazioni quando decidono come valutare MT per scopi post-editing.", 'kk': 'Аудару сапатын бағалау үшін метрикалық құрылғылар әрқашан машинаны аудару (MT) зерттеулерінің негізінде болды. Тәдімгі автоматты сілтеме негіздеген метрикалық, БЛЕС секілді, адамдардың адамдардың адамдардың адамдардың оқиғаларына қатынасы көрсетті және MT жүйесінің жасау үшін көбірек болды. Адамдық шешімдерге негізделген метрикалық масштабын, мысалы, адамдардың тәуелдіктерінің тәуелдік оқиғалары (DA) деген дәреже оқиғалары, сілтеме негізделген автоматты метрикалық метрикадан артық. Соңында, тапсырманың негіздеген өлшемдері, мысалы өзгерту уақыты, нақты тапсырма үшін аудармалардың пайдаланушылығын көбірек оқиға болады. Сондықтан, ДК тапсырмасынан тәуелді (түсінілген) сапатты тапсырмасынан тәуелді (түсінілген) оқу үшін дұрыстығын орташа оқу үшін, және сілтеме негізінде автоматты метрикалық сапатты тапсырмасынан тәуелді тәуелді тәсілді оқу үші Бұл қағазда біз айтып тұрмыз, бірақ бағатты, тапсырманың негіздеген өлшемдері MT сапасын керек тапсырманың бағалауында ең сенімді болуы мүмкін. бұл тапсырма өзгертілген соң. Бұл соңында, жаңа жинақталған кейін өңдеу индикаторлары бар деректер жинағында тәжірибелерді және өңдеу көшірмесін оқиғанда олардың пайдалығын көрсетеді. Біздің нәтижелеріміз тапсырманың негіздеген метрикалық машина аударылған және өзгертілген нұсқаларды қадағалау үшін\nкүтпеген сияқты өңдеу күшін. Бұл метрикаларды бағдарламаның жалғастырып, мектрикалық аударылған нұсқасын және тәуелсіз сілтемелерді салыстырады. Біз MT профессионалықтары осы айырмашылықтарын біледі және соңғы өңдеу мақсаттары үшін MT бағалау үшін оның нәрселерін түсіндіру керек деп ойлаймыз.', 'lt': 'Vertimo kokybei įvertinti skirtų metrinių duomenų rengimas visada buvo pagrindinis mašininio vertimo (MT) mokslinių tyrimų pagrindas. Tradiciniai automatiniai atskaitos rodikliai, pavyzdžiui, BLEU, parodė koreliacijas su žmogaus tinkamumo ir lankstumo vertinimais ir buvo labai svarbūs MT sistemos kūrimui. Viešojo sektoriaus veikla populiarino ir sudarė galimybę skaliuoti žmogaus sprendimais pagrįstus metrinius rodiklius, pavyzdžiui, subjektyvius tiesioginius tinkamumo vertinimus (DA), kurie, manoma, yra patikimesni už standartinius automatinius metrinius rodiklius. Galiausiai tikimasi, kad pagal užduotis pagrįsti matavimai, pavyzdžiui, po redakcijos atlikimo, padės išsamiau įvertinti vertimų naudingumą konkrečiai užduotims atlikti. Todėl, nors DA vidutiniškai vertina tinkamumą, kad būtų galima įvertinti (suvokiamą) kokybę nepriklausomai nuo užduoties, ir nuorodomis pagrįstos automatinės metrijos bando objektyviai įvertinti kokybę taip pat nepriklausomai nuo užduoties, užduoties pagrįstos metrijos yra matavimai, gauti atliekant konkrečią užduotį arba po jos. Šiame dokumente teigiame, kad nors brangiai atliekami užduotis grindžiami matavimai yra patikimiausi vertinant MT kokybę konkrečioje užduotyje; mūsų atveju ši užduotis yra po redakcijos. To that end, we report experiments on a dataset with newly-collected post-editing indicators and show their usefulness when estimating post-editing effort.  Mūsų rezultatai rodo, kad užduotimis pagrįstos metrijos, palyginančios vertimo mašina ir po redakcijos versijas, yra geriausios sekant\npastangos po redakcijos, kaip tikėtasi. Po šių rodiklių eina DA, o vėliau lyginamos vertimo mašina versijos ir nepriklausomos nuorodos. Siūlome, kad MT specialistai žinotų apie šiuos skirtumus ir pripažintų jų poveikį nusprendžiant, kaip vertinti MT po redakcijos.', 'mk': 'Направањето метрики за проценка на квалитетот на преводот отсекогаш било во јадрото на истражувањето за машински превод (MT). Традиционалните автоматски референциски метрики, како што е БЛЕУ, покажаа корелации со човечките пресуди за соодветност и течност и беа најважни за напредокот на развојот на МТ системот. Популаризирањето на јавните извори ја популаризираше и овозможи скалабилноста на метриките врз основа на човечките пресуди, како што се субјективните директни проценки (ДА) на соодветноста, кои се смета дека се подоверливи од референтните автоматски метрики. Конечно, мерките базирани на задачите, како што е времето по уредувањето, се очекува да обезбедат поодредена оценка на корисноста на преводите за специфична задача. Затоа, додека обвинителството ги проценува пресудите за соодветност за да добие оценка на (перцепираниот) квалитет независно од задачата, и автоматските метрики базирани на референција се обидуваат објективно да го проценат квалитетот, исто така, на независен начин од задачата, метриките базирани на задачата се мерки добиени или за време Во овој документ тврдиме дека иако скапите, задачни мерки се најверојатни кога се проценува квалитетот на МТ во специфична задача; во нашиот случај, оваа задача е постуредување. За тоа, пријавуваме експерименти на датотеки со нови индикатори по уредување и покажуваме нивна корисност во проценката на напорите по уредување. Нашите резултати покажуваат дека метриката базирана на задачи во споредба со машински преведени и пост-уредени верзии се најдобрите во следењето\nнапори по уредување, како што се очекуваше. Овие метрики се следени од ДА, а потоа од метрики кои ја споредуваат машинската преведена верзија и независни референции. Предлагаме медицинските практики да бидат свесни за овие разлики и да ги признаат нивните импликации кога ќе одлучат како да го оценат медицинскиот медицински медицински медицински медицински медицински медицински медицински', 'ms': 'Peralatan metrik untuk menilai kualiti terjemahan sentiasa berada di inti penyelidikan terjemahan mesin (MT). Metrik berasaskan rujukan automatik tradisional, seperti BLEU, telah menunjukkan korelasi dengan penilaian manusia tentang keperluan dan keterlaluan dan telah menjadi penting untuk kemajuan pembangunan sistem MT. Sumber-ramai telah popularised dan membolehkan skalabiliti metrik berdasarkan penilaian manusia, seperti penilaian langsung subjektif (DA) keperluan, yang dianggap lebih dipercayai daripada metrik automatik berdasarkan rujukan. Akhirnya, pengukuran berasaskan tugas, seperti masa selepas-edisi, dijangka untuk menyediakan penilaian yang lebih dekat bagi kegunaan terjemahan untuk tugas tertentu. Therefore, while DA averages adequacy judgements to obtain an appraisal of (perceived) quality independently of the task, and reference-based automatic metrics try to objectively estimate quality also in a task-independent way, task-based metrics are measurements obtained either during or after performing a specific task.  Dalam kertas ini kami menyangka bahawa walaupun pengukuran berasaskan tugas yang mahal adalah pengukuran yang paling dipercayai apabila memperkirakan kualiti MT dalam tugas tertentu; dalam kes kita, tugas ini adalah post-edit. Untuk itu, kami laporkan eksperimen pada set data dengan indikator post-edisi yang baru dikumpulkan dan menunjukkan kegunaan mereka bila menghargai usaha post-edisi. Hasil kami menunjukkan bahawa metrik berasaskan tugas yang membandingkan versi terjemahan-mesin dan post-edit adalah yang terbaik dalam mengesan\nusaha post-edit, seperti yang dijangka. Metrik ini diikuti oleh DA, dan kemudian oleh metrik yang membandingkan versi terjemahan-mesin dan rujukan independen. Kami cadangkan bahawa ahli MT perlu sedar perbezaan ini dan mengakui implikasi mereka apabila memutuskan bagaimana untuk menilai MT untuk tujuan post-edit.', 'ml': 'പരിഭാഷപൂര്\u200dവ്വം പരിശോധിക്കാനുള്ള മെറ്റിക്കങ്ങള്\u200d എപ്പോഴും മെഷീന്\u200d പരിശോധനത്തിന്\u200dറെ (എംടി) പരിശോധന നട പാര്\u200dട്ടികമായ ആത്മികവിദ്യഭിന്നതയിലുള്ള മെട്രിക്കങ്ങള്\u200d, ബിലിയൂ പോലെ മനുഷ്യന്റെ വിധികളുമായി ബന്ധങ്ങള്\u200d കാണിച്ചിരിക്കുന്നു. എംടി സ ക്രൂഡ് സോര്\u200dസിങ് പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു മനുഷ്യരുടെ വിധികളില്\u200d അടിസ്ഥാനമായി മെട്രിക്കുകളുടെ കണക്കിന് സാധ്യതയോടെ പ്രാവര്\u200dത്തികമാക്കുന്നത അവസാനം, പിന്നീട് ചിട്ടപ്പെടുത്തുന്ന സമയത്തെപ്പോലുള്ള ജോലിയുടെ അടിസ്ഥാനമായ അളവുകള്\u200d, ഒരു പ്രത്യേകിച്ച പ്രവര്\u200dത്തനത്തിന്റെ ഉപ അതുകൊണ്ട് DA ജോലിയുടെ സ്വാതന്ത്ര്യത്തില്\u200d സ്വാതന്ത്ര്യം ലഭ്യമാക്കുന്ന ഒരു (മനസ്സിലാക്കുന്നു) വിവിധികള്\u200d പരിശോധിക്കാന്\u200d ഏറ്റവും ശരാധാര്യമായ വിധികളും, പ്രഖ്യാപിക്കുന്ന സ ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d വാദിക്കുന്നു എന്തെങ്കിലും വിലപ്പെട്ടതാണെങ്കിലും ജോലിയുടെ അടിസ്ഥാനത്തിലുള്ള അളവുകള്\u200d ഒരു പ്രത നമ്മുടെ കാര്യത്തില്\u200d, ഈ ജോലി പിന്നീട് ചിട്ടപ്പെടുത്തുന്നതാണ്. അതിന്റെ അവസാനത്തിനു വേണ്ടി നമ്മള്\u200d ഒരു ഡാറ്റാസെറ്റില്\u200d പരീക്ഷണങ്ങള്\u200d റിപ്പോര്\u200dട്ട് ചെയ്യുന്നു. പുതിയ എഡിറ്ററിങ്ങ് സംയ നമ്മുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നത് ജോലിയുടെ അടിസ്ഥാനമായ മെട്രിക്കകള്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തിയും പിന്നെ എടുത\npost-editing effort, as expected.  ഈ മെട്രിക്കങ്ങള്\u200d DA പിന്തുടരുന്നു. പിന്നീട് മെഷീന്\u200d പരിഭാഷപ്പെടുത്തിയ പതിപ്പിനെയും സ്വാതന്ത്ര്യ വിവരങ്ങള എംടി പരിശീലകന്\u200dമാര്\u200d ഈ വ്യത്യാസങ്ങളെക്കുറിച്ച് മനസ്സിലാക്കണമെന്നും അവരുടെ പ്രശ്നങ്ങള്\u200d സ്വീകരിക്കുമെന്നും ഞങ്ങള്\u200d ആലോചിക്കുന്ന', 'mt': 'It-tfassil ta’ metriċi biex tiġi vvalutata l-kwalità tat-traduzzjoni dejjem kien fil-qalba tar-riċerka dwar it-traduzzjoni bil-magna (MT). Traditional automatic reference-based metrics, such as BLEU, have shown correlations with human judgements of adequacy and fluency and have been paramount for the advancement of MT system development.  Il-crowd-sourcing ippopularizza u ppermetta l-iskalabbiltà tal-metriċi bbażati fuq sentenzi umani, bħal valutazzjonijiet diretti soġġettivi (DA) tal-adegwatezza, li huma maħsuba li huma aktar affidabbli mill-metriċi awtomatiċi bbażati fuq referenza. Fl-a ħħar nett, il-kejl ibbażat fuq ix-xogħol, bħall-ħin ta’ wara l-edizzjoni, huwa mistenni li jipprovdi evalwazzjoni aktar iddettaljata tal-utilità tat-traduzzjonijiet għal kompitu speċifiku. Therefore, while DA averages adequacy judgements to obtain an appraisal of (perceived) quality independently of the task, and reference-based automatic metrics try to objectively estimate quality also in a task-independent way, task-based metrics are measurements obtained either during or after performing a specific task.  F’dan id-dokument a ħna jargumentaw li, għalkemm il-kejl għali, ibbażat fuq ix-xogħol huwa l-aktar affidabbli meta tiġi stmata l-kwalità tal-MT f’kompitu speċifiku; fil-każ tagħna, dan il-kompitu huwa wara l-edizzjoni. Għal dak il-għan, nirrappurtaw esperimenti fuq sett ta’ dejta b’indikaturi ta’ wara l-edizzjoni miġbura reċentement u nuru l-utilità tagħhom fl-istima tal-isforz ta’ wara l-edizzjoni. Ir-riżultati tagħna juru li l-metriċi bbażati fuq ix-xogħol li jqabblu l-verżjonijiet tradotti bil-magna u wara editati huma l-aħjar fit-traċċar\nsforz ta’ wara l-edizzjoni, kif mistenni. Dawn il-metriċi huma segwiti minn DA, u mbagħad minn metriċi li jqabblu l-verżjoni tradotta bil-magna u referenzi indipendenti. Aħna ssuġġerixxu li l-prattikanti MT għandhom ikunu konxji minn dawn id-differenzi u jirrikonoxxu l-implikazzjonijiet tagħhom meta jiddeċiedu kif jevalwaw MT għal skopijiet ta’ wara l-edizzjoni.', 'ro': 'Elaborarea de valori pentru evaluarea calității traducerii a fost întotdeauna nucleul cercetării de traducere automată (MT). Măsurătorile tradiționale automate bazate pe referință, cum ar fi BLEU, au arătat corelații cu judecățile umane de adecvare și fluență și au fost esențiale pentru progresul dezvoltării sistemului MT. Crowd-sourcing a popularizat și a permis scalabilitatea măsurătorilor bazate pe judecățile umane, cum ar fi evaluările directe subiective (DA) ale adecvării, care se consideră a fi mai fiabile decât măsurătorile automate bazate pe referință. În cele din urmă, măsurătorile bazate pe sarcini, cum ar fi timpul post-editare, vor oferi o evaluare mai detaliată a utilității traducerilor pentru o anumită sarcină. Prin urmare, în timp ce DA evaluează calitatea medie pentru a obține o evaluare a calității (percepută) independentă de sarcină, iar măsurătorile automate bazate pe referință încearcă să estimeze în mod obiectiv calitatea și într-un mod independent de sarcină, măsurătorile bazate pe sarcini sunt măsurători obținute în timpul sau după efectuarea unei anumite sarcini. În această lucrare susținem că, deși scumpe, măsurătorile bazate pe sarcini sunt cele mai fiabile atunci când estimează calitatea MT într-o anumită sarcină; în cazul nostru, această sarcină este post-editare. În acest scop, raportăm experimente pe un set de date cu indicatori de post-editare recent colectați și arătăm utilitatea lor atunci când estimăm efortul de post-editare. Rezultatele noastre arată că valorile bazate pe sarcini care compară versiunile traduse automat și posteditate sunt cele mai bune la urmărire\nefortul de post-editare, așa cum era de așteptat. Aceste măsurători sunt urmate de DA, apoi de măsurători care compară versiunea tradusă automat și referințele independente. Sugerăm ca practicienii MT să fie conștienți de aceste diferențe și să recunoască implicațiile lor atunci când decid cum să evalueze MT în scopuri post-editare.', 'mn': 'Комбинацийн чанарыг үнэлэх метрик төхөөрөмж нь машин орчуулагчийн (MT) судалгааны гол түвшинд байдаг. БЛЕУ гэх мэт уламжлалтай автоматик санал суурилсан метрик нь хүн төрөлхтний зөв болон шингэний шийдвэрлэлтэй холбоотой болон MT системийн хөгжлийн хөгжлийн тулд чухал болсон. Хүн төрөлхтний шүүмжлэг дээр тооцоолж байгаа метрикийн масштабыг хүлээн зөвхөн зөвхөн зөвхөн зөвхөн үнэлгээний шалгалтыг (ДА) ашиглаж байна. Энэ нь баталгаар автоматик метрикийн үнэлгээс илүү итгэлтэй гэж боддог. Эцэст нь, ажил дээр суурилсан хэмжээсүүд, цаг хугацаа, тодорхой ажил дээр орчуулах хэрэгжүүлэгтийн хэрэгжүүлэгтийг илүү дүгнэх шалгалтыг гаргах гэж найдаж байна. Яагаад гэвэл ДОХ нь ажлын тухай тогтмол (ойлголтын) сайн чанарын шалгалтыг автоматжуулахын тулд зөвхөн адилхан шүүмжүүдийг дундаж дундаж үзүүлдэг. Баталгаар суурилсан автоматжуулалтын метрик нь ажлын тухай хамааралгүй аргаар ч мөн адилхан хэмжээг тооцоо Энэ цаасан дээр бид үнэтэй, ажлын үнэтэй хэмжээсүүд нь MT-ийн сайн чанарыг тодорхойлох үед хамгийн итгэлтэй гэдгийг хэлж байна. бидний хэрэглээнд энэ үйл ажиллагаа дараа нь засварлах болно. Ийм төгсгөлд бид шинэ цуглуулагдсан цахим хураагдах загвартай өгөгдлийн сангийн туршилтын туршилтыг тайлбарлаж, цахим хураагдах хичээлийг тооцоолж хэрэгжүүлэхийг харуулж байна. Бидний үр дүнд ажил дээр суурилсан метрик машин орчуулагдсан, эцэст нь өөрчлөгдсөн хувилбаруудыг харьцуулахад хамгийн сайн нь\nхүлээн зөвшөөрөх хичээл. Эдгээр метрийг ДНХ-ын дагалдаг, дараа нь машины хөрөнгө оруулсан хувилбарыг харьцуулдаг. Бид MT дасгал хөгжүүлэгчид эдгээр ялгааг мэдэх хэрэгтэй гэдгийг сануулж байна. МТ-г цааш өөрчлөлтийн зорилго дээр хэрхэн үнэлэх талаар шийдвэрлэхэд өөрсдийн нөлөө ойлгох хэрэгтэй.', 'no': 'Eining av metrikar for å vurdere omsetjingskvalitet har alltid vært i kjernen av forskning av maskineomsetjing (MT). Tradisjonale automatiske referansbaserte metrikar, som BLEU, har vist korrelasjonar med menneske uttrykk av adekvitet og fluktet, og har vært paramount for avansert av MT-systemutvikling. Krøvskjeldering har popularisert og slått på skalabilitet for metrikar basert på menneske sprøytebrukar, slik som subjektiv direkte vurdering av adekvitet, som vert trodd til å vera betre enn automatiske metrikar basert på referansbasert. Til slutt forventar oppgåvebaserte målingar, slik som post- redigeringstid, å gjera ei meir dehald evaluering av korleis omsetjingar er nyttig for eit spesifikke oppgåve. Derfor, mens DA gjennomsnittsverdi gjennomsnittsverdiar for å få eit vurdering av (oppfatte) kvalitet uavhengig av oppgåva, og automatiske metrikar som er basert på referansen prøver å objektiv vurdere kvalitet også på ein måte uavhengig av oppgåva, er oppgåvebaserte metrikar gjennomsnittsverdi enten under eller etter å utføra eit spesifikke oppgå I denne papiret argumenterer vi at selv om dykkare, oppgåvebaserte målingar er den mest betre når MT-kvaliteten er estimert i eit spesifikke oppgåve. i tilfellet vår er denne oppgåva postredigering. I denne slutten rapporterer vi eksperimenter på eit dataset med nytt samla postredigeringsindikatorer og viser deres nyttighet når du vurderer etter redigeringsforsøk. Resultatet våra viser at oppgåvebaserte metrikar som sammenlignar maskineomsette og etter redigerte versjonar er best ved sporing\netter redigeringsforsøk, som venta. Desse metrikane vert følgjande av DA, og deretter med metrikar som sammenlignar versjonen med maskineoversettet og uavhengige referanser. Vi foreslår at MT-praktiserane bør vera kjent på desse forskjellingane og godkjenner implikasjonane sine når dei bestemmer korleis MT skal evaluera for postredigeringsmål.', 'pl': 'Opracowanie wskaźników oceny jakości tłumaczeń zawsze było podstawą badań nad tłumaczeniem maszynowym (MT). Tradycyjne automatyczne wskaźniki oparte na referencjach, takie jak BLEU, wykazały korelacje z ludzkimi ocenami adekwatności i płynności i były kluczowe dla rozwoju systemów MT. Crowdsourcing upowszechnił i umożliwił skalowalność wskaźników opartych na osądach ludzkich, takich jak subiektywne bezpośrednie oceny adekwatności, które uważa się za bardziej wiarygodne niż automatyczne wskaźniki oparte na referencjach. Wreszcie oczekuje się, że pomiary oparte na zadaniach, takie jak czas po edycji, zapewnią bardziej precyzyjną ocenę przydatności tłumaczeń dla konkretnego zadania. W związku z tym, podczas gdy DA uśrednia ocena adekwatności w celu uzyskania oceny (postrzeganej) jakości niezależnie od zadania, a automatyczne wskaźniki oparte na referencjach starają się obiektywnie oszacować jakość również w sposób niezależny od zadania, wskaźniki oparte na zadaniach to pomiary uzyskane w trakcie lub po wykonaniu konkretnego zadania. W niniejszym artykule argumentujemy, że chociaż kosztowne pomiary oparte na zadaniach są najbardziej wiarygodne przy szacowaniu jakości MT w konkretnym zadaniu; W naszym przypadku zadaniem jest post-edycja. W tym celu raportujemy eksperymenty na zbiorze danych z nowo zebranymi wskaźnikami post-edycyjnymi i pokazujemy ich przydatność przy szacowaniu nakładu post-edycyjnego. Nasze wyniki pokazują, że mierniki oparte na zadaniach porównujące wersje przetłumaczone maszynowo i po edycji są najlepsze w śledzeniu\nwysiłek po edycji, zgodnie z oczekiwaniami. Po tych wskaźnikach następuje DA, a następnie wskaźniki porównujące wersję maszynową i niezależne referencje. Sugerujemy, aby praktycy MT powinni być świadomi tych różnic i uznać ich konsekwencje podczas decydowania o ocenie MT dla celów post-edycyjnych.', 'sr': 'Upravljanje metrika za procjenu kvalitete prevođenja uvek je bila u centru istraživanja automatskog prevođenja (MT). Tradicionalne automatske standardne metrike, poput BLEU, pokazale su korelacije sa ljudskim procenama o adekvatnosti i tečnosti i bile su najvažnije za napredak razvoja MT sistema. Pojavila se i omogućila skalabilnost metrika na osnovu ljudskih sudova, kao što su subjektivne direktne procjene adekvatnosti, koje se smatra pouzdanijim od automatske metrike na osnovu referencije. Na kraju, očekuje se da će mjere na temelju zadataka, poput vremena nakon editiranja, pružiti detaljniju procenu korisnosti prevoda za određeni zadatak. Stoga, dok tužilac prosječava odluke o adekvatnosti da bi dobio procenu kvalitete (percepcija) nezavisno od zadatka, a na osnovu referentnog automatske metrike pokušavaju objektivno procijeniti kvalitetu takođe na nezavisnom načinu na zadatku, metrike na zadatku dobijaju ili tokom ili nakon određenog zadatka. U ovom papiru tvrdimo da, iako su skupe mjere na zadatku najpouzdanije kada procjenjujemo kvalitet MT u određenom zadatku; u našem slučaju, ovaj zadatak je post-editing. Za to prijavljujemo eksperimente na setu podataka sa novim indikatorima nakon editiranja i pokazujemo im korisnost kada procjenjujemo napore nakon editiranja. Naši rezultati pokazuju da su na zadatku najbolja verzija u praćenju\nnakon uredbe napora, kao što je očekivano. Ove metrike prate tužilac, a onda metrike uspoređuju verziju prevedene mašine i nezavisnih referencija. Predlažemo da praktičnici MT-a trebaju biti svjesni ovih razlika i priznaju njihove implikacije kada odlučuju kako procjenjivati MT za postredišne svrhe.', 'si': 'පරිවර්තන කුළුවත් විශේෂය අවශ්\u200dය කරන්න මෙට්\u200dරික්ස් උපකරණය හැමවෙලේම පරිවර්තන (MT) පරීක්ෂණයේ  සාමාන්\u200dය ස්වයංක්\u200dරිය සංවේදනය සඳහා අධ්\u200dයාත්මක මෙට්\u200dරික්ස් වගේ, BLUE වගේ, මිනිස්සුන්ගේ අධ්\u200dයාත්මක සමග සම්බන්ධතාවය පෙ මිනිස්සුන් නිර්ධාරණය සඳහා මෙට්\u200dරික්ස් ස්කැලැබීම් සක්\u200dරිය කරලා තියෙනවා, වගේම ප්\u200dරශ්නය සම්බන්ධ විශ්වාස (DA) සම්බන්ධ විශ්වාසිත අන්තිමේදී, වැඩේ අධාරිත මාපය, පස්ස සංපාදනය වෙලාවක් වගේ, විශේෂ වැඩ සඳහා විශේෂ වැඩේ භාවිතාවක් ගැන ප්\u200dරයෝජ ඉතින්, ජාතිකාරියා ක්\u200dරියාත්මක විශේෂතාවක් ස්වයංක්\u200dරියාත්මක විශේෂතාවක් ලැබෙන්න, සහ ආයුත්මක ස්වයංක්\u200dරියාත්මක විශේෂතාවක් විශේෂතාවක් විසින් ව මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා කියලා, ගොඩක් වැඩියි, වැඩිය අධ්\u200dයාත්මක විශ්වාස කරන්නේ MT කුළුවත් විශේෂ ව අපේ විදියට, මේ වැඩේ පස්සේ සංපාදනය කරන්නේ. ඒ අවසානයෙන්, අපි දත්ත සෙට්ටුවට අළුත් සංයෝජනය කරනවා පස්සේ සංයෝජනය සඳහා පස්සේ සංයෝජනය සඳහා ප්\u200dරයෝජනය පෙන් අපේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිපත\nපිටිපස්සේ සංපාදනය කරන්න ප්\u200dරයෝජනය, බලාපොරොත්තු විදිහට. මේ මෙට්\u200dරික්ස්ටික්ස් පස්සේ DA වෙනුවෙන්, ඊට පස්සේ මෙට්\u200dරික්ස් වෙනුවෙන් පස්සේ පස්සේ පස්සේ පස්සේ  අපි ප්\u200dරශ්නයක් කරනවා MT ප්\u200dරේක්ෂකයෝ මේ වෙනස් ගැන දැනගන්න ඕනි කියලා, ඒ වගේම ඔවුන්ගේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ', 'ta': 'மொழிபெயர்ப்பு தரம் மதிப்பை மதிப்பிடுவதற்கான மெட்ரிக்கள் எப்போதும் இயந்திர மொழிபெயர்ப்பு (MT) ஆராய்ச் பாரம்பரிய தன்னியக்க குறிப்பு முறைமைகள் போன்ற BLEU, மனித த தீர்ப்புகளுடன் தொடர்புகளைக் காட்டியுள்ளது தான் MT முறைமையை மேம்படுத்துவதற்காகவு குறுக்கும் மூலம் மகிழ்ந்துள்ளது மற்றும் மனித விதிகளை அடிப்படையில் மெட்ரிக்களின் அளவு செயல்படுத்தப்படுகிறது, போன்ற சொந்த நேரடி மதிப்பு இறுதியில், பணியின் அடிப்படையான அளவுகோல் ஆகையால், DA செயலை தனித்தனியாக (பார்க்கப்பட்ட) தரம் பெற சராசரியான தீர்ப்புகள் பெறுவதற்காக, மற்றும் குறிப்பிட்ட செயலை செய்யும் போது தானாக தானியங்கி முறைகளையும் பொருட்படுத இந்த காகிதத்தில் நாம் விதமாக விவாதம் செய்தாலும், செயல் அடிப்படையிலான அளவுகள் ஒரு குறிப்பிட்ட பணியில் MT தரம் மதிப்பிட எங்கள் விஷயத்தில், இந்த செயல் திருத்தம் பின் தொகுப்பு To that end, we report experiments on a dataset with newly-collected post-editing indicators and show their usefulness when estimating post-editing effort.  முடிவு\nஎதிர்பார்க்கப்பட்ட பின் திருத்த முயற்சி These metrics are followed by DA, and then by metrics comparing the machine-translated version and independent references.  MT பயிற்சிகள் இந்த வேறுபாடுகளைப் பற்றி தெரிந்து கொள்ள வேண்டும் மற்றும் அவர்களுடைய விளைவுகளை ஒப்புக்கொள்ள வேண்டும் என்று நா', 'sv': 'Att ta fram m채tv채rden f철r att bed철ma 철vers채ttningskvaliteten har alltid varit k채rnan i maskin철vers채ttningsforskningen. Traditionella automatiska referensbaserade m채tv채rden, s책som BLEU, har visat korrelationer med m채nskliga bed철mningar av l채mplighet och flytande och har varit avg철rande f철r utvecklingen av MT-system. Crowd-sourcing har populariserat och m철jliggjort skalbarhet av m채tv채rden baserade p책 m채nskliga bed철mningar, s책som subjektiva direkta bed철mningar (DA) av adekvathet, som tros vara mer tillf철rlitliga 채n referensbaserade automatiska m채tv채rden. Slutligen f철rv채ntas uppgiftsbaserade m채tningar, s책som efterredigeringstid, ge en mer avgr채nsad utv채rdering av anv채ndbarheten av 철vers채ttningar f철r en viss uppgift. D채rf철r, medan DA genomsnittligt bed철mer adekvathetsbed철mningar f철r att f책 en bed철mning av (upplevd) kvalitet oberoende av uppgiften, och referensbaserade automatiska m채tv채rden f철rs철ker objektivt uppskatta kvaliteten 채ven p책 ett uppgiftsoberoende s채tt, 채r uppgiftsbaserade m채tv채rden m채tningar som erh책lls antingen under eller efter att ha utf철rt en viss uppgift. I denna uppsats h채vdar vi att 채ven om dyra, uppgiftsbaserade m채tningar 채r de mest tillf철rlitliga vid uppskattning av MT-kvalitet i en specifik uppgift; I v책rt fall 채r denna uppgift efterredigering. F철r detta 채ndam책l rapporterar vi experiment p책 en dataupps채ttning med nyligen insamlade indikatorer f철r efterredigering och visar deras anv채ndbarhet vid uppskattning av efterredigering. V책ra resultat visar att uppgiftsbaserade m채tv채rden som j채mf철r maskin철versatta och efterredigerade versioner 채r b채st p책 att sp책ra\nefterredigeringsarbete, som f철rv채ntat. Dessa m채tv채rden f철ljs av DA, och sedan av m채tv채rden som j채mf철r den maskin철versatta versionen och oberoende referenser. Vi f철resl책r att MT-ut철vare b철r vara medvetna om dessa skillnader och erk채nna deras konsekvenser n채r de beslutar hur MT ska utv채rderas f철r efterredigerings채ndam책l.', 'so': "Qorshaha metricooyinka in lagu qiimeeyo qiimeynta turjumaadda had iyo goorba waxay ku jirtay baaritaanka machine (MT). Qoraalka asalka ah ee loo soo jeedo, sida BLEU, waxay muujiyeen xiriir la xiriira xukunka dadka ee ku saabsan saxda iyo faa’iidada, waxayna ahaayeen mid u eg horumarinta koritaanka nidaamka MT. Dhinac-soo-baxa waa la korodhsaday, waana la fududaysiiyey baaritaanka ku saabsan xukunka dadka, tusaale ahaan qiimeynta tooska ah (DA) oo loo malaynayaa inay ka aamin tahay mid ka mid ah maamulka loo isticmaalay qof. Ugu dambaysta waxaa laga yaabaa in lagu sameeyo qiimeyn dheeraad ah oo faa’iidada turjubaanka shaqada gaar ah. Sidaa darteed, marka uu DA ugu dhexeeyo go'aanka ku saabsan in uu hesho qiimeynta (la garto) qiimeynta qiimo gaarka ah ee shaqada, iyo sidoo kale qaababka bilowga ah ee lagu soo jeedo, waxay isku dayaan in lagu qiimeeyo qiimo shaqo xor la’a an ah, waxaa laga helaa qiyaastii shaqada waqtiga ama ka dib marka lagu sameeyo shaqo gaar ah. Warqadan waxaynu ka doodaynaa in, in kastoo qiimo qaali ah, qiyaastii shaqo ku saleysan ay tahay mid ugu aamin marka lagu qiimeeyo qiimaha tayada MT oo shaqada gaar ah; xaaladeena, shaqadanu waa wax beddela kadib. Taas darteed waxaynu u wargelinaynaa imtixaanka taariikhda, taasoo leh calaamadaha lagu soo ururiyey dib-editing, waxaana tusnaa faa'iidadooda marka aan qiimeynayno hawlaha sawirida ka dib. Fashiyadayada waxay muuqanayaan in metrics-based shaqo la barbarto machine-translated and post-edited versions are the best at tracking\nJahaadada hagaajinta kadib, sida loo filay. Waxyaabahan waxaa soo daba socda DA, markaasna waxaa lagu soo bandhigaa qoraalka lagu turjumay mashiinka iyo codsiyada xorriyadda ah. Waxaan ka jeedaynaa in shaqo-bixiyayaasha MT ay ogaadaan kala duwanaankaas iyo in ay aqoonsadaan saamaynta marka aan go'aanno sida loo qiimeynayo MT-da ee loogu talo galay hagitaanka ka dib.", 'ur': 'ترجمہ کیفیت کا ارزش کرنے کے لئے متریک ڈیویس کرنا ہمیشہ ماشین ترجمہ (MT) تحقیقات کے مرکز میں ہوتا ہے. آگاہ آگاہ آگاہ بنیادی متریک، جیسے BLEU، نے انسان کے فیصلے کے مطابق اور طبیعت کے ساتھ تعلق دکھایا ہے اور MT سیستم کی پیشرفت کے لئے اضافہ کیا گیا ہے۔ اور انسان کے فیصلے پر بنیاد میٹریک کی ترازوٹی کی ترازوٹی کو قابل کر دیا گیا ہے، جیسے مستقیم مطابق مطابق کے مستقیم مطابق کے مطابق مطابق (DA) کے مطابق مطابق مطابق ہے، جن کو معلوم ہوتا ہے کہ مرکز کی اصل سے زیادہ اعتماد رکھنے آخر میں، تابع-بنیاد اندازے، جیسے بعد-editing وقت، ایک خاص تابع کے لئے ترجمہ کے فائدہ کے مطابق مطابق کے مطابق زیادہ اندازے کا انتظام کرنا انتظار کیا جاتا ہے. لہٰذا، جبکہ ڈی ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ا ہم اس کاغذ میں جھگڑتے ہیں کہ اگرچہ بہت گراں ہیں، تابع بنیاد کی اندازے ان سے زیادہ مطمئن ہیں جب ایک خاص کام میں MT کیفیت کا ارزش کرنا ہے۔ ہمارے موقع میں، یہ کام پیچھے سمجھ رہی ہے۔ اس لئے ہم نے ایک ڈاٹ سٹ پر آزمائش کی آزمائش گزاری جو نئی جمع ہوئی پوسٹ ویڈینگ نمایاٹروں کے ساتھ ہے اور ان کے فائدہ دکھاتے ہیں جب پوسٹ ویڈینگ تلاش کی آزمائش کرتے ہیں. ہمارے نتیجے دکھاتے ہیں کہ کام کی بنیادی میٹریک ماشین کی ترجمہ اور پیچھے سمجھ کی نسخہ ترکینگ میں سب سے بہتر ہیں\nاس طرح انتظار کیا گیا ہے کہ اس کے بعد سمجھنے کی کوشش۔ یہ میٹریک ڈی ای کے پیچھے چلتے ہیں، اور پھر میٹریک کے پیچھے ماشین کی ترجمہ کی نسخہ اور سزاواری نسخہ کے مطابق مقایسہ کرتے ہیں. ہم اس بات سے پیش کرتے ہیں کہ MT پڑھنے والوں کو ان تفاوتوں کے بارے میں آگاہ ہونا چاہیے اور ان کے اثرات کا تصدیق کرنا چاہیے جب فیصلہ کیا جاتا ہے -MT کا ارزش کس طرح پڑھنا چاہیے', 'uz': "Tarjima qiymatini qiymatish uchun metriklarni yaratish Name Koʻrib chiqish tarkibini ko'paytirish va inson xuddi asosida metriklarning qiymatlarini qo'llash imkoniyatini yordam beradi. Masalan, ma'lumot direktoriya qiymatlari (DA) davom etish imkoniyatlaridan foydalanish mumkin. @ info: whatsthis Therefore, while DA averages adequacy judgements to obtain an appraisal of (perceived) quality independently of the task, and reference-based automatic metrics try to objectively estimate quality also in a task-independent way, task-based metrics are measurements obtained either during or after performing a specific task.  Bu hujjatda biz murakkab qilamiz, ammo qiymati, vazifaning asosiy o'lchamlari muhim vazifaning MT сифатini qiymatish mumkin; Bu vazifa tahrirlashdan keyin. Shunday qilib, biz yangi тўпланган post-tahrirlash indikatlari bilan maʼlumotlar tarkibida taʼminlovchi taʼminlovchilar haqida foydalanishni koʻrsatimiz. Vazifaning natijalarimiz mashina tarjima qilingan va keyingi tahrirlangan versiyatlarni qidirish uchun eng yaxshi\n@ info Ushbu metriklar DA tomonidan qo'yiladi, va keyin mashina tarjima versiyasi va xotira parametrlari bilan birga mos keladi. Biz MT foydalanuvchilari bunday o'zgarishlar uchun MT qanday qiymatni o'ylashni boshlaganda ularning natijalarini aniqlash kerak.", 'vi': 'Thay đổi âm lượng để đánh giá chất lượng dịch luôn là mấu chốt của nghiên cứu về dịch chuyển cỗ máy (MTV). Âm lượng tự động truyền thống, như đại diện môi trường, đã cho thấy mối liên hệ với phán xét người về sự phù hợp và khéo léo và đã là tiên quyết cho tiến tiến hệ thống MTV. Tập đoàn người trích xuất đã phổ biến và cho phép khả năng mô phỏng các thước đo dựa trên phán quyết con người, như các đánh giá trực tiếp chủ quan (DA) về độ đủ, mà được cho là đáng tin cậy hơn các âm lượng tự động đó. Cuối cùng, các kích thước dựa trên nhiệm vụ, như thời gian sửa chữa sau, sẽ cung cấp một đánh giá chi tiết hơn về sự hữu dụng của dịch thuật cho một nhiệm vụ cụ thể. Do đó, khi công tố định giá mức độ phù hợp để có được một phép đánh giá chất lượng (được nhận thấy) độc lập với nhiệm vụ, và các đo tử lập tự động dựa trên điểm đó cố gắng phân tích chất lượng khách quan cũng theo một cách độc lập nhiệm vụ, các đo trình lượng dựa vào nhiệm vụ được lấy hoặc sau khi thực hiện một nhiệm vụ cụ thể. Trong tờ giấy này, chúng tôi cho rằng, cho dù giá trị của các công việc, nhưng đáng tin cậy nhất khi đánh giá chất lượng MTV trong một nhiệm vụ cụ thể; Trong trường hợp của chúng ta, nhiệm vụ này là sau sửa. Về mục đích đó, chúng tôi báo cáo các thí nghiệm trên một bộ dữ liệu với các chỉ số mới thu thập sau khi sửa chữa và cho thấy sự hữu dụng khi ước tính nỗ lực sau đó. Kết quả cho thấy rằng thước đo dựa vào các công việc so sánh phiên bản dịch cỗ máy và sau sửa chữa là tốt nhất\nNỗ lực sau sửa chữa, như dự kiến. Những thước đo này được theo sau bởi DA, và sau đó là những thước đo so sánh phiên bản dịch cỗ máy và độc lập. Chúng tôi đề nghị các bác sĩ trên kênh MTV nên biết về sự khác biệt này và nhận biết hậu quả của họ khi quyết định xem cách đánh giá kênh MTV để làm việc sau phiên bản.', 'bg': 'Създаването на показатели за оценка на качеството на превода винаги е било в основата на изследванията за машинния превод. Традиционните автоматични референтни показатели, като например показаха корелации с човешките преценки за адекватност и плавност и са от първостепенно значение за напредъка на развитието на МТ системата. Груповото снабдяване популяризира и позволява мащабируемостта на показателите въз основа на човешки преценки, като субективни директни оценки на адекватността, за които се смята, че са по-надеждни от автоматичните показатели въз основа на референции. И накрая, измерванията, базирани на задачи, като времето след редактиране, се очаква да осигурят по-подробна оценка на полезността на преводите за конкретна задача. Ето защо, докато ДА изчислява средните оценки за адекватност, за да получи оценка на (възприеманото) качество независимо от задачата, и референтните автоматични показатели се опитват обективно да оценят качеството и по независим от задачата начин, базираните на задачи показатели са измервания, получени по време или след изпълнението на конкретна задача. В тази статия твърдим, че макар и скъпи, измерванията, базирани на задачи, са най-надеждните при оценяване на качеството на МТ в конкретна задача; В нашия случай, тази задача е пост-редактиране. За тази цел докладваме експерименти върху набор от данни с новосъбрани индикатори за пост-редактиране и показваме тяхната полезност при оценяване на усилията за пост-редактиране. Нашите резултати показват, че базираните на задачи показатели, сравняващи машинно преведени и постредактирани версии, са най-добрите в проследяването\nпост-редактиране усилие, както се очакваше. Тези показатели са последвани от ДА, а след това от показатели, сравняващи машинно преведената версия и независимите препратки. Предлагаме практикуващите в МТ да са наясно с тези различия и да признаят техните последици, когато решават как да оценят МТ за целите на пост-редакцията.', 'nl': 'Het ontwikkelen van statistieken om de vertaalkwaliteit te beoordelen is altijd de kern geweest van het onderzoek naar machine translation (MT). Traditionele automatische referentie-gebaseerde metrics, zoals BLEU, hebben correlaties aangetoond met menselijke beoordelingen van toereikendheid en vloeiendheid en zijn van cruciaal belang geweest voor de vooruitgang van de ontwikkeling van MT-systemen. Crowdsourcing heeft de schaalbaarheid van statistieken op basis van menselijke oordelen, zoals subjectieve directe beoordelingen (DA) van adequaatheid, die betrouwbaarder worden geacht dan referentiegebaseerde automatische statistieken, populariseerd en mogelijk gemaakt. Tenslotte wordt verwacht dat taakgebaseerde metingen, zoals de nabewerkingstijd, een meer gedetailleerde evaluatie van het nut van vertalingen voor een specifieke taak opleveren. Daarom, terwijl DA gemiddeld toereikendheidsoordelen maakt om een beoordeling van (waargenomen) kwaliteit onafhankelijk van de taak te verkrijgen, en referentiegebaseerde automatische metrics proberen de kwaliteit objectief te schatten, ook op een taakafhankelijke manier, zijn taakgebaseerde metrics metingen die worden verkregen tijdens of na het uitvoeren van een specifieke taak. In dit artikel stellen we dat, hoewel dure, taakgebaseerde metingen het meest betrouwbaar zijn bij het schatten van MT kwaliteit in een specifieke taak; In ons geval is deze taak post-editing. Daartoe rapporteren we experimenten op een dataset met nieuw verzamelde post-editing indicatoren en tonen we hun nut bij het inschatten van post-editing inspanning. Onze resultaten tonen aan dat taakgebaseerde statistieken die machine-vertaalde en post-bewerkte versies vergelijken, het beste bij het bijhouden zijn\npost-editing inspanning, zoals verwacht. Deze statistieken worden gevolgd door DA, en vervolgens door statistieken die de machine-vertaalde versie en onafhankelijke referenties vergelijken. Wij stellen voor dat MT-beoefenaars zich bewust moeten zijn van deze verschillen en hun implicaties moeten inzien wanneer zij beslissen hoe MT moet worden geëvalueerd voor post-editing doeleinden.', 'de': 'Die Entwicklung von Metriken zur Bewertung der Übersetzungsqualität war schon immer der Kern der maschinellen Übersetzung (MT). Traditionelle automatische referenzbasierte Metriken, wie BLEU, haben Korrelationen mit menschlichen Einschätzungen von Angemessenheit und Fluency gezeigt und waren von entscheidender Bedeutung für die Weiterentwicklung der MT-Systementwicklung. Crowdsourcing hat die Skalierbarkeit von Metriken, die auf menschlichen Urteilen basieren, wie subjektive direkte Bewertungen der Angemessenheit (DA) popularisiert und ermöglicht, von denen angenommen wird, dass sie zuverlässiger sind als referenzbasierte automatische Metriken. Schließlich sollen aufgabenbasierte Messungen, wie z. B. die Nachbearbeitungszeit, eine genauere Bewertung der Nützlichkeit von Übersetzungen für eine bestimmte Aufgabe liefern. Während DA die Angemessenheitsbeurteilungen mittelt, um eine Bewertung der (wahrgenommenen) Qualität unabhängig von der Aufgabe zu erhalten, und referenzbasierte automatische Metriken versuchen, die Qualität objektiv auch auf eine aufgabenunabhängige Weise zu schätzen, sind aufgabenbasierte Metriken Messungen, die entweder während oder nach der Ausführung einer bestimmten Aufgabe erhalten werden. In diesem Papier argumentieren wir, dass, obwohl teuere, aufgabenbasierte Messungen die zuverlässigste sind, wenn es um die Schätzung der MT-Qualität in einer bestimmten Aufgabe geht; In unserem Fall ist diese Aufgabe Post-Editing. Dazu berichten wir Experimente an einem Datensatz mit neu gesammelten Post-Editing Indikatoren und zeigen deren Nützlichkeit bei der Abschätzung des Post-Editing Aufwands auf. Unsere Ergebnisse zeigen, dass aufgabenbasierte Metriken, die maschinell übersetzte und nachbearbeitete Versionen vergleichen, am besten nachverfolgen können.\nNachbearbeitungsaufwand, wie erwartet. Diesen Metriken folgen DA und dann Metriken, die die maschinell übersetzte Version und unabhängige Referenzen vergleichen. Wir schlagen vor, dass MT-Praktiker sich dieser Unterschiede bewusst sein und ihre Implikationen anerkennen sollten, wenn sie entscheiden, wie MT für Post-Editing-Zwecke bewertet werden soll.', 'ko': '번역의 질을 평가하는 지표를 설계하는 것은 기계번역(MT) 연구의 핵심이었다.전통적인 자동 참고를 바탕으로 하는 지표, 예를 들어 BLEU는 인류가 충분성과 유창성에 대한 판단과 관련이 있고 기계 번역 시스템 개발의 발전에 매우 중요하다.크라우드소싱은 인류의 판단을 바탕으로 하는 지표의 신축성을 보급하고 실현했다. 예를 들어 충분한 주관적 직접 평가(DA)는 참고를 바탕으로 하는 자동 지표보다 믿을 만하다.마지막으로 임무의 측정을 바탕으로 편집된 시간과 같이 특정 임무의 번역 유용성에 대해 더욱 상세한 평가를 제공할 수 있을 것이다.따라서 DA는 충분성 판단을 평균적으로 하여 임무에 독립된(감지) 품질 평가를 얻고, 참고를 바탕으로 하는 자동 도량도 임무에 독립된 방식으로 객관적으로 품질을 평가하려 하지만 임무에 기초한 도량은 특정한 임무를 수행하는 기간이나 이후에 얻은 도량이다.본고에서 우리는 비록 비싸지만 특정 임무 중의 기계 번역의 질을 평가할 때 임무를 바탕으로 하는 측정이 가장 믿을 만하다고 생각한다.우리의 예에서 이 임무는 후기 편집이다.이를 위해, 우리는 새로 수집한 편집 후 지표를 포함하는 데이터 집합의 실험을 보고했고, 편집 후 작업의 유용성을 예측했다.우리의 결과는 임무의 지표를 바탕으로 기계 번역과 편집 버전을 비교하는 것이 추적에 가장 뛰어나다는 것을 나타냈다\n예상대로 후기 편집 작업.이러한 메트릭은 DA 다음에 기계 번역 버전과 독립적으로 참조된 메트릭을 비교합니다.우리는 기계 번역 종사자들이 기계 번역을 어떻게 평가하여 후기 편집을 하는지를 결정할 때 이러한 차이를 의식하고 그 영향을 인정해야 한다고 건의한다.', 'da': 'Udvikling af metrics til vurdering af oversættelseskvaliteten har altid været kernen i maskinoversættelsesforskningen. Traditionelle automatiske referencebaserede målinger, såsom BLEU, har vist korrelationer med menneskelige vurderinger af tilstrækkelighed og flydenhed og har været afgørende for fremskridt i MT-systemets udvikling. Crowd-sourcing har populariseret og muliggjort skalerbarheden af målinger baseret på menneskelige vurderinger, såsom subjektive direkte vurderinger (DA) af tilstrækkelighed, der menes at være mere pålidelige end referencebaserede automatiske målinger. Endelig forventes opgavebaserede målinger, f.eks. efterredigeringstid, at give en mere afskrækket evaluering af nytten af oversættelser til en bestemt opgave. Mens DA derfor vurderer tilstrækkelighedsvurderinger for at opnå en vurdering af (opfattet) kvalitet uafhængigt af opgaven, og referencebaserede automatiske målinger forsøger objektivt at vurdere kvaliteten også på en opgaveafhængig måde, er opgavebaserede målinger målinger opnået enten under eller efter udførelsen af en bestemt opgave. I denne artikel argumenterer vi for, at selv om dyre, opgavebaserede målinger er de mest pålidelige ved vurdering af MT kvalitet i en bestemt opgave; I vores tilfælde er denne opgave post-redigering. Til det formål rapporterer vi eksperimenter på et datasæt med nyindsamlede indikatorer for efterredigering og viser deres nytte ved vurdering af efterredigeringsindsatsen. Vores resultater viser, at opgavebaserede målinger, der sammenligner maskinoversatte og postredigerede versioner, er de bedste til sporing\nefter redigering, som forventet. Disse målinger efterfølges af DA og derefter af målinger, der sammenligner den maskinoversatte version og uafhængige referencer. Vi foreslår, at MT-udøvere bør være opmærksomme på disse forskelle og anerkende deres konsekvenser, når de beslutter, hvordan MT skal evalueres til post-redigeringsformål.', 'hr': 'Upravljanje metrika za procjenu kvalitete prevođenja uvijek je bio u temelju istraživanja prevođenja strojeva (MT). Tradicionalna automatska standardna metrika, poput BLEU, pokazala su korelacije s ljudskim procenama o adekvatnosti i tečnosti i bila je najvažnija za napredak razvoja MT sistema. Pojavila se i omogućila skalabilnost metrika na temelju ljudskih osuđenja, poput subjektivnih direktnih procjena adekvatne procjene, koje se smatra pouzdanijim od automatske metrike na temelju referencije. Konačno se očekuje da će mjere na temelju zadataka, poput vremena nakon redakcije, pružiti detaljniju procjenu korisnosti prevoda za određeni zadatak. Stoga, dok tužilac prosječava odluke o adekvatnosti kako bi dobio procjenu kvalitete (percepcija) nezavisno od zadatka, a automatske metrike na osnovu referencije pokušavaju objektivno procijeniti kvalitetu također na nezavisnom načinu na zadatku, metrike na temelju zadatka dobijaju ili tijekom ili nakon određenog zadatka. U ovom papiru tvrdimo da, iako su skupe mjere na temelju zadatka najpouzdanije kada procjenjujemo kvalitet MT-a u određenom zadatku; u našem slučaju, ovaj zadatak je post-editing. Za to prijavljujemo eksperimente na setu podataka s novim indikatorima nakon editiranja i pokazujemo njihovu korisnost kada procjenjujemo napore nakon editiranja. Naši rezultati pokazuju da su na zadatku najbolji u praćenju metrike u usporedbi strojeva prevedene i nakon redaktiranih verzija\nnakon uredbe napora, kako je očekivalo. Ove metrike prate tužilac, a onda metrike uspoređuju verziju prevedenog stroja i nezavisnih referencija. Predlažemo da praktičnici MT-a moraju biti svjesni tih razlika i priznati njihove implikacije kada odlučuju kako procijeniti MT za posturedne svrhe.', 'id': 'Devising metrics to assess translation quality has always been at the core of machine translation (MT) research.  Metrik tradisional berdasarkan referensi otomatis, seperti BLEU, telah menunjukkan korelasi dengan penilaian manusia tentang keperluan dan keterbatasan dan telah menjadi penting untuk kemajuan pengembangan sistem MT. Sumber keramaian telah popularised dan memungkinkan skalabilitas metrik berdasarkan penilaian manusia, seperti penilaian langsung subjektif (DA) keperluan, yang dianggap lebih dipercaya daripada metrik otomatis berdasarkan referensi. Akhirnya, pengukuran berdasarkan tugas, seperti waktu pos-edisi, diharapkan untuk menyediakan evaluasi lebih dekat dari kebaikan terjemahan untuk tugas spesifik. Oleh karena itu, sementara DA rata-rata penilaian keperluan untuk mendapatkan penilaian kualitas (terperhatian) independen dari tugas, dan metrik otomatis berdasarkan referensi mencoba untuk objektif menilai kualitas juga dalam cara independen tugas, metrik berdasarkan tugas adalah pengukuran yang diperoleh baik selama atau setelah melakukan tugas spesifik. Dalam kertas ini kami berdebat bahwa, meskipun mahal, pengukuran berdasarkan tugas adalah yang paling dipercaya ketika memperkirakan kualitas MT dalam tugas spesifik; dalam kasus kita, tugas ini adalah post-edit. To that end, we report experiments on a dataset with newly-collected post-editing indicators and show their usefulness when estimating post-editing effort.  Hasil kami menunjukkan bahwa metrik berbasis tugas membandingkan versi terjemahan-mesin dan post-edit adalah yang terbaik dalam melacak\nusaha post-edit, seperti yang diharapkan. Metrik ini diikuti oleh DA, dan kemudian oleh metrik yang membandingkan versi terjemahan mesin dan referensi independen. Kami menyarankan bahwa praktek MT harus menyadari perbedaan ini dan mengakui implikasi mereka ketika memutuskan bagaimana untuk mengevaluasi MT untuk tujuan post-edit.', 'fa': 'طراحی متریک برای ارزیابی کیفیت ترجمه همیشه در مرکز تحقیقات ترجمه ماشین (MT) بوده است. متریک\u200cهای مربوط به مربوط خودکار سنتی، مثل BLEU، ارتباط با حکم\u200cهای انسان\u200cهای مناسب و طبیعت را نشان داده\u200cاند و برای پیشرفت توسعه سیستم\u200cهای MT مهم است. سرمایه\u200cگذاری کوه\u200cها محبوب شده و قابلیت مقیاس متریک بر اساس قضاوت\u200cهای انسان را فعال کرده است، مثل ارزیابی مستقیم مستقیم (DA) مناسب، که به نظر می\u200cرسد قابل اطمینان بیشتری از متریک\u200cهای خودکار بر اساس مرکز است. بالاخره، اندازه\u200cهای پایه\u200cی کار، مثل زمان بعد از ویرایش، انتظار دارند که یک ارزیابی بیشتری از اندازه\u200cهای استفاده از ترجمه\u200cها برای یک کار خاص را پیشنهاد کند. بنابراین، در حالی که دادستان دادستان در میانگین تصمیم مناسب برای تحقیق کیفیت (متوجه شدن) به تنهایی از وظیفه، و متریک اتوماتیک بر اساس مرکز سعی می\u200cکند کیفیت را به طور مستقل از وظیفه مستقل تحقیق کند، متریک بر اساس وظیفه\u200cهای وظیفه یا در طول یا بعد از انجام وظیفه خا در این کاغذ بحث می\u200cکنیم که، اگرچه اندازه\u200cهای گران، بر پایه\u200cی کار، در زمان ارزیابی کیفیت MT در یک کار خاص، بهترین اطمینان دارند. در مورد ما، این کار بعد از ویرایش است. برای همین، ما آزمایش\u200cهای روی مجموعه\u200cی داده\u200cها را گزارش می\u200cدهیم با نشان\u200cدهندگان بعد از ویرایش جدید جمع شده و در محاسبه تلاش بعد از ویرایش کاری\u200cشان را نشان می\u200cدهیم. نتیجه\u200cهای ما نشان می\u200cدهند که متریک\u200cهای پایه\u200cی کار مقایسه کردن نسخه\u200cهای مترجم و بعد از ویرایش\u200cشده بهترین در ردیابی هستند\nسعی بعد از ویرایش، همانطور که انتظار داشته باشد. این متریک\u200cها توسط دادستان دادستان تعقیب می\u200cشوند، و سپس با متریک\u200cها که نسخه\u200cهای مترجم به ماشین و نسخه\u200cهای مستقل را مقایسه می\u200cکنند. ما پیشنهاد می\u200cکنیم که تمرین\u200cکنندگان MT باید از این تفاوت\u200cها آگاه باشند و وقتی تصمیم گرفته باشند تاثیر\u200cهایشان را تصمیم بگیرند - چگونه ارزیابی MT برای هدف\u200cهای بعد از ویرایش کنند.', 'sq': 'Përgatitja e metrikave për të vlerësuar cilësinë e përkthimit ka qenë gjithmonë në qendër të kërkimit të përkthimit të makinave (MT). Metrikat tradicionale automatike bazuar në referencë, të tilla si BLEU, kanë treguar korrelacione me gjykimet njerëzore të përshtatshmërisë dhe fluencës dhe kanë qenë kryesore për përparimin e zhvillimit të sistemit MT. Përdorimi publik ka populizuar dhe ka mundësuar shkallimin e metrikave bazuar në gjykimet njerëzore, të tilla si vlerësimet subjektive të drejtpërdrejta (DA) të përshtatshmërisë, të cilat besohet të jenë më të besueshme se metrikat automatike bazuar në referencë. Më në fund, matjet bazuar në detyra, të tilla si koha e pas-editimit, pritet të ofrojnë një vlerësim më të shkurtër të dobishmit të përkthimeve për një detyrë të veçantë. Prandaj, ndërsa DA mesatarisht vlerëson vlerësimet e përshtatshmërisë për të marrë një vlerësim të cilësisë (të perceptuar) pavarësisht nga detyra dhe metrikat automatike të bazuara në referencë përpiqen të vlerësojnë objektivisht cilësinë gjithashtu në një mënyrë të pavarur nga detyra, metrikat e bazuara në detyrë janë matje të arritura gjatë apo pas kryerjes së një detyre të posa Në këtë letër argumentojmë se megjithëse matjet e shtrenjta bazuara në detyra janë më të besueshme kur vlerësojmë cilësinë e MT në një detyrë të veçantë; in our case, this task is post-editing.  Për këtë qëllim, ne raportojmë eksperimente në një grup të dhënash me tregues të sapo-mbledhur pas editimit dhe tregojmë dobinë e tyre kur vlerësojmë përpjekjen pas editimit. Rezultatet tona tregojnë se metrika bazuar në detyra që krahasojnë versionet e përkthyera nga makina dhe post-edituara janë më të mira në gjurmimin\npërpjekje pas redigimit, siç pritej. Këto metrika pasohen nga DA dhe pastaj nga metrika që krahasojnë versionin e përkthyer nga makina dhe referencat e pavarura. Ne sugjerojmë që praktikantët e MT duhet të jenë të ndërgjegjshëm për këto dallime dhe të pranojnë pasojat e tyre kur vendosin se si të vlerësojnë MT për qëllime pas redigimit.', 'af': "Toestel van metries om vertaling kwaliteit te asseer is altyd by die kern van masjien vertaling (MT) ondersoek. Tradisjoneel outomatiese verwysing-gebaseerde metries, soos BLEU, het korrelasies getoon met menslike oordelings van adekuasie en fluiditeit en is paramount vir die avanserting van MT stelsel ontwikkeling. Kroud-voorspoeding het populariseer en geaktiveer die skalabiliteit van metrike gebaseer op menslike oordelings, soos subjektiewe direkte oordelings van adekuasie, wat geloof word om meer betroubaar as verwysing-gebaseerde automatiese metrike te wees. Eindelik word die taak-gebaseerde measurements, soos post-redigeering tyd, verwag om 'n meer de-geëlde evaluasie van die gebruikerheid van vertalings vir 'n spesifieke taak te verskaf. Daarom, terwyl die DG gemiddelde oordelings van adekualiteit om 'n oordelings van (aangewerp) kwaliteit onverantlik van die taak te kry, en verwysing-gebaseerde automatiese metries probeer om objektief kwaliteit ook in 'n taak-onverantlik manier te vure, is taak-gebaseerde metries die oordelings wat of terwyl 'n spesifieke taak uitgevoer word. In hierdie papier het ons gespreek dat, alhoewel kosbare, taak-gebaseerde measurements die mees vertroubaar is wanneer MT-kwaliteit in 'n spesifieke taak bereken word; in ons geval, hierdie taak is post-redigeering. Op daardie einde, ons rapporteer eksperimente op 'n datastel met nuwe versamel post- redigeering indikators en wys hulle gebruikerheid wanneer hulle post- redigeering verskaf is. Ons resultate vertoon dat taak-gebaseerde metries vergelyking van masjien-vertaal en post-redigeerde weergawe is die beste by agtervolg\npost- redigeering verskaf, soos verwag. Hierdie metries word gevolg deur DA, en dan deur metries wat die masjien-vertaling weergawe en onafhanklike verwysing vergelyk word. Ons stel voorstel dat MT-praktisers bekend moet wees van hierdie verskille en hulle implikasies bekend word wanneer besluit - hoe om MT te evalueer vir post-redigeering doels.", 'tr': "Terjime kaliýetini barlamak üçin metrikler düzenlemek elmydama makine terjime (MT) araştyrmalaryň esasynda bolupdyr. Däpli awtomatik taýýarlanan metrikler, BLEU ýaly adamlaryň dogrudylygy we ýigrenligi barada ylalaşyklary görkezildi we MT sistem gelişmesi üçin örän möhüm. Gata sebäpleri adamlaryň çözümlerinde daýanýan metrikleriň ölçeklenmesini, suwersal düzgün deňleşmeler (DA) ýaly, Referans-daýanýan awtomatik metriklerden has güýçli diýip ynanýarlar. Soňunda, täzeliklerden daýanýan ölçümler, görä düzenlemek wagty ýaly, belli täzelikleriň üçin ullanlygyny golaýlaşdyrmak üçin ýene-de boýunça çykmak üçin gözlenýär. Şol sebäpli, DA howpsuzlyklaryň (görünýän) kynçylygyny işiň ýüzünden boýunça almak üçin adalatylyk çözümlerini ortalamak isleýär, we süýtgeden awtomatik metrikler maksady hem täze-ýüzünden boýunça hasaplamak üçin synanyşýar, görevi-tabanly metrikler bir zady wagtda ya da netije-de bir görev Bu kagyzda gürrüň edýäris, eger-de wagt, işe tabanly ölçümler MT keyfiýetini takyklaýanda iň ynamly we ynamly däldirler diýip pikir edýäris; biziň döwürimizde, bu işi taýdan düzenlemekdir. Şol üçin, taze ýygnanan soňra düzenlemek görkezilýän sanlaryň bardygyny we olaryň etkinligini barlap netijesini görkez. Biziň netijelerimiz görevimiz tabanly metrikler maşynyň terjime edilen we edit edilen wersiýalary yzarlamak üçin iň gowydygyny görkezýär.\ntaýdan editlemek synanyşy gözlenýän ýaly. Bu metrikler DA tarapyndan yzarlanýar, soňra metrikler maşynyň terjime edilen wersiýany we bağımsız referenslary bilen karşılaşýarlar. MT praktikçilerinin bu farklılıklardan haberdar edilmesini ve sonraki düzenleme amaçlarına MT'i nasıl değerlendirmesi gerektiğini tahmin ediyoruz.", 'sw': 'Kupanga mbinu za kutathmini ubora wa tafsiri mara zote umekuwa kwenye utafiti wa mashine (MT). mbinu za kujitegemea za kitamaduni kama vile BLEU, zimeonyesha uhusiano na uamuzi wa binadamu wa usawa na ufanisi na zimekuwa tayari kwa maendeleo ya mfumo wa MT. Kutokana na vyanzo vya kutawanya vimeongezeka na kuifanya uwezekano wa vifaa vya mafuta kwa kutumia maamuzi ya binadamu, kama vile tathmini za moja kwa moja (DA) za sahihi, ambazo zinadhaniwa kuwa ni za kutegemea zaidi ya mbinu za kujitegemea. Mwisho, mipango ya kazi, kama vile wakati wa kuhariri baada ya kufuatia, inatarajiwa kutoa tathmini zaidi ya matumizi ya tafsiri kwa kazi fulani. Kwa hiyo, wakati idadi ya maamuzi yanayohitajika ili kupata uchunguzi wa kiwango cha (kinachoelewa) bila uhuru wa kazi hiyo, na mbinu za kujitegemea zinazohusiana na maoni zinajaribu kutathmini ubora pia kwa njia huru ya kazi, mbinu za kazi zinapatikana ama wakati au baada ya kufanya kazi maalum. Katika karatasi hii tunahoji kuwa, ingawa gharama, mipango yenye kazi ni yenye uaminifu zaidi pale tunakadiria kiwango cha MT katika kazi maalumu; katika kesi yetu, kazi hii ni ya kuhariri baada ya kuandika. Kwa mwisho huo, tunaripoti majaribio kwenye seti ya taarifa yenye ishara mpya zilizokusanywa baada ya kuhariri na kuonyesha manufaa yao wakati tunakadiria juhudi za kuhariri baada ya kuhariri. Matokeo yetu yanaonyesha kuwa mbinu zilizoko kwenye kazi zinazolinganisha mashine yanayotafsiriwa na zile za baada ya kuhariri ni bora katika kufuatilia\njuhudi za baada ya kuhariri, kama ilivyotarajiwa. Mfumo huu unafuatiliwa na DA, na kisha kwa mbinu zinalinganisha toleo la mashine na maoni huru. Tunawapendekeza kwamba watumiaji wa MT wanapaswa kuwa na uelewa wa tofauti hizi na kutambua matokeo yao pale tunapoamua - kuamua namna ya kutathmini MT kwa malengo ya baada ya kuhariri.', 'hy': 'Մետրիկայի սարքելը թարգմանման որակի գնահատելու համար միշտ մեխանիզմի թարգմանման (MT) հետազոտության հիմքում էր: Հավանդական ավտոմատիկ հաղորդակցման հիմնված մետրիկները, ինչպիսիք են օրինակ ԲԼԵՎ-ը, ցույց են տալիս կապ մարդկային կարծիքների հետ, որոնք համապատասխանատվություն են և ճկունություն, և կարևոր են ՄԹ համակարգի զարգացման զարգացման համար: Ժողովրդի ծառայությունը բազմազանցել է և հնարավորություն է տալիս մարդկային դատողությունների վրա հիմնված մետրիկների ընդլայնելիությունը, ինչպիսիք են բավարարության սուբյեկտիվ ուղիղ գնահատումները, որոնք հավատում են, որ ավելի վստահելի են քան հաղորդակցման հիմնված ավտոմատիկ մետրիկները Վերջապես, խնդիրների վրա հիմնված չափումները, ինչպիսիք են օրինակ խմբագրման հետագա ժամանակը, ակնկալում են, որ կտրամադրեն ավելի խիստ գնահատում թարգմանությունների օգտակարության մասին որոշակի խնդիրների համար: Այսպիսով, մինչդեռ DA-ը միջինում է բավարարության դատողությունները, որպեսզի ստանա (ընկալված) որակի գնահատականը անկախ խնդրից, և հաղորդակցման հիմնված ավտոմատիկ մետրիկները փորձում են օբյեկտիվ գնահատել որակը նաև խնդրի անկախ ձևով, խնդրի հիմնված մետրիկները չափումն Այս թղթի մեջ մենք փաստարկում ենք, որ չնայած որ թանկ, խնդիրների հիմնված չափումները ամենավստահելի են MT որակի գնահատման ժամանակ որոշ խնդիրներում: մեր դեպքում, այս խնդիրը հետխմբագրությունն է: Այդ պատճառով մենք զեկուցում ենք փորձարկումներ մի տվյալների համակարգի վրա, որոնք վերջերս հավաքված են խմբագրության հետո ցույց տվյալներով և ցույց են տալիս նրանց օգտակարությունը խմբագրության հետո փորձի գնահատման համար: Մեր արդյունքները ցույց են տալիս, որ առաջադրանքներով հիմնված մետրիկները, որոնք համեմատում են մեքենայի թարգմանված և հետխմբագրված տարբերակները, լավագույնն են հետևելու\nինչպես ակնկալում էր: Այս մետրիկներին հետևում է DA-ը, հետո մետրիկները, որոնք համեմատում են մեքենայի թարգմանված տարբերակը և անկախ հղումները: Մենք առաջարկում ենք, որ MT-ի մասնագետները պետք է գիտակցեն այս տարբերությունները և ճանաչեն իրենց հետևանքները որոշելով, թե ինչպես գնահատել MT-ը խմբագրությունից հետո:', 'bn': 'অনুবাদের মান মূল্যের মূল্য পরিকল্পনা করার জন্য মেট্রিক তৈরি করা হচ্ছে মেশিন অনুবাদ (এমটি) গবেষণায়। ঐতিহ্যবাহী স্বয়ংক্রিয় স্বয়ংক্রিয়ভিত্তিক ভিত্তিক কৌশল, যেমন বিলিউ, মানুষের বিচার এবং প্রভাবের সাথে সম্পর্ক প্রদর্শন করেছে এবং এমটি সিস্ট ক্রাউড সোর্সিং জনপ্রিয় এবং মানুষের বিচারের ভিত্তিক ভিত্তিতে মেট্রিকের স্বাভাবিকতা সক্রিয় করেছে, যেমন বিষয়বস্তুর সরাসরি পরিচালিত মিনিস (ডিএ) যারা স্ব অবশেষে, কাজের ভিত্তিক পরিমাপ, যেমন পরিবর্তনের সময়, আশা করা হচ্ছে একটি নির্দিষ্ট কাজের জন্য অনুবাদের কার্যক্রমের ব্যবহারের জন্য অনুবাদের বে কাজেই ডিএ কাজের ব্যাপারে স্বাধীনভাবে পরিচিত (বুঝতে পারে) মান সম্পর্কে পর্যাপ্ত সিদ্ধান্তের বিচার পাওয়া যায় এবং স্বয়ংক্রিয় ভিত্তিক মেটিক চেষ্টা করে স্বাধীন কাজের ম এই কাগজটিতে আমরা যুক্তি দিচ্ছি যে, যদিও দামী কাজের ভিত্তিক পরিমাপ হচ্ছে এমটি মানের বিশেষ করে একটি নির্দিষ্ট কাজে হিসে আমাদের ক্ষেত্রে, এই কাজটা পোস্ট সম্পাদনা এই পর্যন্ত আমরা নতুন সংগ্রাপ্ত পোস্ট সম্পাদনার পরিকল্পনা নির্দেশকের সাথে একটি ডাটাসেটের পরীক্ষার পরীক্ষা প্রতিবেদন প্রদান করি এবং পরি আমাদের ফলাফল দেখাচ্ছে যে কাজের ভিত্তিক মেশিন-অনুবাদ এবং পরিশোধিত সংস্করণের সাথে তুলনা করা মেটিক\nপ্রত্যাশিত পোস্ট সম্পাদনার প্রচেষ্টা। These metrics are followed by DA, and then by metrics comparing the machine-translated version and independent references.  আমরা পরামর্শ দিচ্ছি যে এমটি প্রশিক্ষকদের এই পার্থক্য সম্পর্কে সচেতন থাকা উচিত এবং সিদ্ধান্ত নেয়ার পরে এমটিকে কিভাবে সম্পাদনের উদ্দেশ্', 'cs': 'Vývoj metrik pro hodnocení kvality překladu byl vždy jádrem výzkumu strojového překladu (MT). Tradiční automatické referenční metriky, jako je BLEU, prokázaly korelace s lidským úsudkem přiměřenosti a plynulosti a byly zásadní pro rozvoj MT systémů. Crowdsourcing popularizoval a umožnil škálovatelnost metrik založených na lidských úsudkech, například subjektivních přímých hodnoceních adekvátnosti (DA), které se považují za spolehlivější než automatické metriky založené na referencích. V neposlední řadě se očekává, že měření založená na úkolech, jako je doba po editaci, poskytnou více detailní hodnocení užitečnosti překladů pro konkrétní úkol. Proto zatímco DA průměrně posuzuje přiměřenost k získání hodnocení (vnímané) kvality nezávisle na úkolu a automatické metriky založené na referencích se snaží objektivně odhadnout kvalitu také způsobem nezávislým na úkolech, metriky založené na úkolech jsou měření získaná buď během nebo po provedení konkrétního úkolu. V tomto článku tvrdíme, že ačkoli drahá, úlohová měření jsou nejspolehlivější při odhadu kvality MT v konkrétním úkolu; V našem případě je tento úkol post editace. Za tímto účelem nahlásíme experimenty na datové sadě s nově shromážděnými post-editačními indikátory a ukazujeme jejich užitečnost při odhadu post-editačního úsilí. Naše výsledky ukazují, že metriky založené na úkolech porovnávající strojově přeložené a post editované verze jsou nejlepší při sledování\nposteditační úsilí, jak se očekávalo. Tyto metriky jsou následovány DA a poté metriky porovnávající strojově přeloženou verzi a nezávislé reference. Navrhujeme, aby si odborníci MT měli být vědomi těchto rozdílů a uznali jejich důsledky při rozhodování o tom, jak hodnotit MT pro účely post editace.', 'et': 'Tõlkekvaliteedi hindamiseks mõõdikute väljatöötamine on alati olnud masintõlke uuringute keskmes. Traditsioonilised automaatsed viitepõhised mõõdikud, nagu näiteks BLEU, on näidanud seoseid inimeste otsustega piisavuse ja sujuvuse kohta ning on olnud ülimalt olulised MT süsteemi arendamisel. Ühiskasutus on populariseerinud ja võimaldanud inimotsustel põhinevate mõõdikute skaleeritavust, näiteks subjektiivseid otsehindamisi piisavuse kohta, mida peetakse usaldusväärsemaks kui viitepõhiseid automaatseid mõõdikuid. Lõpuks eeldatakse, et ülesannetel põhinevad mõõtmised, näiteks toimetamisejärgne aeg, annavad tõlkete kasulikkuse täpsema hindamise konkreetse ülesande puhul. Seetõttu, kuigi DA teeb keskmised piisavuse hinnangud, et saada hinnang (tajutud) kvaliteedile ülesandest sõltumatult, ja viitepõhised automaatsed mõõdikud püüavad objektiivselt hinnata kvaliteeti ka ülesandest sõltumatul viisil, on ülesandepõhised mõõdikud mõõtmised, mis saadakse kas konkreetse ülesande täitmise ajal või pärast seda. Käesolevas dokumendis väidame, et kuigi kulukad, on ülesandepõhised mõõtmised kõige usaldusväärsemad MT kvaliteedi hindamisel konkreetses ülesandes; Meie puhul on see ülesanne järeltöötlus. Sel eesmärgil anname aru katsetest andmekogumil, millel on äsja kogutud järeltöötlusnäitajad ja näitame nende kasulikkust järeltöötlusjõupingutuste hindamisel. Meie tulemused näitavad, et masintõlgitud ja järelt redigeeritud versioonide võrdlemisel on ülesandepõhised mõõdikud parimad jälgimisel\ntoimetamisjärgsed pingutused, nagu oodati. Nendele mõõdikutele järgneb DA ja seejärel masintõlgitud versiooni ja sõltumatuid viiteid võrdlevad mõõdikud. Soovitame, et MT praktikud peaksid olema teadlikud nendest erinevustest ja tunnustama nende mõju otsustades, kuidas hinnata MT järeltöötlemise eesmärgil.', 'am': 'ትርጉም ብልሃት ማሰናከል ማተርጉም ማዕከላዊ ትርጉም (MT) ትርጉም ማዕከላዊ ሆኗል፡፡ የባሕላዊ አውቶማቲካዊ የፍትሕት ሥርዓት፣ እንደብሊዩን የሰው ፍርድ ግንኙነት እና ፍጥረት እና የMT ስርዓት ግንኙነትን ለመሻለል ተጋርቷል፡፡ የግንኙነት መልዕክት በሰው ፍርድ ላይ የተመሳሳይ እና የሰው ፍርድ ላይ የተመሳሳይ የሜትሪክ ክፍተት ያበረታል፡፡ Finally, task-based measurements, such as post-editing time, are expected to provide a more de- tailed evaluation of the usefulness of translations for a specific task.  ስለዚህም፣ DA በሚያስፈልገው (ታወቀው) ስራውን ብልሃት ለማግኘት (ለማስተዋል) የሚያስፈልገውን (ለማስተዋል) ጥያቄዎችን ለማግኘት ሲሞክሩ፣ የሥርዓት አካባቢ ማድረጊያውን በተለየ ስራ ነፃነት እና በተለየ ስራ ማድረግ ማድረግ እንዲሞክሩ ይሞክራሉ፡፡ በዚህ ገጽ ውስጥ ምንም እንኳ የከበረ ቢሆንም፣ የስራ ሚዛን በተወሰነ ስራ የMT ጥሩ እንዲቆጠር የሚታመን ነው፡፡ በጉዳዩ ይህ ስራ ከ በኋላ አስተካክል ነው:: ስለዚህም ምክንያት አዲስ ከተሰበሰቡ በኋላ ማቀናጃ ማሳየት እናሳየዋለን፡፡ ፍሬዎቻችን የሥርዓት መሠረት ማተርጓሜዎችን እና በኋላ የተዘጋጀ ክፍሎች በመግለጫ የተሻሉ ናቸው፡፡\nአዲስ ዶሴ ፍጠር እነዚህ ሜትሪኮች ከ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ. እንደዚህ ልዩነታቸውን ማወቅ እና ማስታወቂያውን እና የኢሜተር ተቃውሞ እንዴት እንዲያስተካክሉ በተወሰነ ጊዜ የግንኙነታቸውን ማወቅ እናስታውቃለን፡፡', 'fi': 'Mittareiden laatiminen käännöksen laadun arvioimiseksi on aina ollut konekäännöstutkimuksen ytimessä. Perinteiset automaattiset referenssipohjaiset mittarit, kuten BLEU, ovat osoittaneet korrelaatioita ihmisten asianmukaisuuden ja sujuvuuden arviointiin ja ovat olleet ensiarvoisen tärkeitä MT-järjestelmän kehityksen kannalta. Joukko-sourcing on popularisoinut ja mahdollistanut inhimillisiin arvioihin perustuvien mittarien skaalautuvuuden, kuten subjektiivisten suorien asianmukaisuusarviointien (DA), joiden uskotaan olevan luotettavampia kuin referenssipohjaiset automaattiset mittarit. Tehtäväpohjaisten mittausten, kuten jälkieditointiajan, odotetaan antavan selkeämmän arvion käännösten hyödyllisyydestä tietyssä tehtävässä. Vaikka DA laskee keskiarvoja riittävyyden arviointien saamiseksi (koetusta) laadusta tehtävästä riippumatta ja referenssipohjaiset automaattiset mittarit pyrkivät objektiivisesti arvioimaan laatua myös tehtäväriippumattomalla tavalla, tehtäväpohjaiset mittarit ovat mittauksia, jotka saadaan joko tietyn tehtävän suorittamisen aikana tai sen jälkeen. Tässä artikkelissa väitämme, että vaikka kalliit, tehtäväpohjaiset mittaukset ovat luotettavimpia arvioitaessa MT laatua tietyssä tehtävässä. Meidän tapauksessamme tämä tehtävä on jälkimuokkaus. Tätä varten raportoimme kokeista aineistossa, jossa on äskettäin kerättyjä jälkieditointiindikaattoreita, ja osoitamme niiden hyödyllisyyttä jälkieditointityötä arvioitaessa. Tuloksemme osoittavat, että konekäännettyjä ja jälkimuokattuja versioita vertailevat tehtäväpohjaiset mittarit ovat parhaita seurannassa\njälkimuokkaus, kuten odotettiin. Näiden mittareiden jälkeen käytetään DA-lukua ja konekäännettyä versiota ja riippumattomia viittauksia verrataan. Ehdotamme, että MT-ammattilaisten tulisi olla tietoisia näistä eroista ja tunnustaa niiden vaikutukset päättäessään, miten MT arvioidaan jälkieditointitarkoituksiin.', 'az': 'Tərcümə keyfiyyətini təsdiqləmək üçün metrik düzəltmə daim maşın çevirilməsi (MT) araştırmasının dibində idi. BLEU kimi, sadəcə olaraq avtomatik baxılış metriklər, insanların uyğunluğu və dəyişiklik hökmlərini göstərmiş və MT sistemin gelişməsi üçün çox mövcuddur. İnsanların hökmlərinə dayanan metriklərin ölçülüyünü, həmçinin dəyişiklik tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə tərzdə göstərməsini qabilleştirdi. Sonunda, işlər-tabanlı ölçüləri, məxluqatdan sonra düzəltmə vaxtı kimi, təkrarların istifadəsizliklərinin istifadəsizliklərini daha çox dəyişdirəcəyini gözləyirlər. Buna görə də, Sənin vəzifəsi işlərdən təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkcə təkc Bu kağızda mübahisə edirik ki, əvəzində xərcləyici, iş tabanlı ölçülər MT keyfiyyətini müəyyən etdikdə ən güvenilir. bizim vəziyyətimizdə bu işin sonrakı dəyişiklikdir. Bu səbəbdə, yeni toplanmış post-editing indikatorları ilə verilən təcrübələrdə təcrübələr təbliğ edirik və sonra editmə çabalarını hesablayarkən onların faydalanılığını göstəririk. Bizim sonuçlarımız görev tabanlı metrikləri maşına çevirilən və sonra editlən versiyonlarla karşılaşdırmaq üçün ən yaxşıdır.\ngözlədiyi kimi, sonra düzəltmə çabaları. Bu metrikləri DA təqib edir, sonra maşına çevirilən versiyonu və bağımsız referans ilə karşılaşdırılar. Biz MT praktikantları bu fərqlərdən xəbərdarlıq etməli və sonrakı düzəltmə məqsədilə MT necə müəyyən ediləcəyini təsdiqləndirdik.', 'bs': 'Upravljanje metrika za procjenu kvalitete prevođenja uvijek je bio u centru istraživanja prevođenja strojeva (MT). Tradicionalne automatske standardne metrike, poput BLEU, pokazale su korelacije sa ljudskim procenama o adekvatnosti i tečnosti i bile su najvažnije za napredak razvoja MT-a. Pojavila se i omogućila skalabilnost metrika na temelju ljudskih osuđenja, poput subjektivnih direktnih procjena adekvatnosti, koje se smatra pouzdanijim od automatske metrike na osnovu referencije. Na kraju, očekuje se da će mjere na temelju zadataka, poput vremena nakon editiranja, pružiti detaljniju procjenu korisnosti prevoda za određeni zadatak. Stoga, dok tužilac prosječava odluke o adekvatnosti kako bi dobio procjenu kvalitete (percepcija) nezavisno od zadatka, a na referenciji automatičke metrike pokušavaju objektivno procjenjivati kvalitetu također na nezavisnom načinu na zadatku, metrike na zadatku dobijaju ili tijekom ili nakon određenog zadatka. U ovom papiru tvrdimo da, iako su skupe mjere na temelju zadataka najpouzdanije kada procjenjujemo kvalitet MT u određenom zadatku; u našem slučaju, ovaj zadatak je post-editing. Za taj cilj, prijavljujemo eksperimente na setu podataka sa novim indikatorima nakon editiranja i pokazujemo im korisnost kada procjenjujemo napore nakon editiranja. Naši rezultati pokazuju da su na zadatku najbolji u praćenju metrike u usporedbi strojeva prevedenih i nakon editiranih verzija\nnakon uredbe napora, kao što je očekivano. Ove metrike prate tužilac, a onda metrike u usporedbi s verzijom prevedenom mašinom i nezavisnim referencijama. Predlažemo da praktičnici MT-a trebaju biti svjesni ovih razlika i priznaju njihove implikacije kada odlučuju kako procijeniti MT za posturedne svrhe.', 'ca': "El disseny de mètriques per evaluar la qualitat de la traducció sempre ha estat al nucli de la recerca de la traducció automàtica. Les mètriques automàtiques tradicionals basades en referència, com la BLEU, han mostrat correlacions amb els judicis humans d'adequació i fluïtat i han estat primordials per al progrés del desenvolupament del sistema MT. L'alimentació pública ha popularitzat i permet l'escalabilitat de les mètriques basades en jutges humans, com les evaluacions subjectives directes (DA) de l'adequació, que es creu que són més fiables que les mètriques automàtiques basades en referència. Finalment, es espera que les mesures basades en tasques, com el temps de postedició, proporcionen una evaluació més detallada de l'utilitat de les traduccions per una tasca específica. Així doncs, mentre que la DA mitja els judicis d'adequació per obtenir una valoració de la qualitat (perceptida) independentment de la tasca, i les mètriques automàtiques basades en referència intenten estimar objectivament la qualitat també d'una manera independent de la tasca, les mètriques basades en la tasca són mesures obtenides tant durant com després de l'execució d'una tasca específica. En aquest paper argumentem que, tot i que les mesures costoses basades en tasques són les més fiables quan estimem la qualitat del MT en una tasca específica; en el nostre cas, aquesta tasca és post-edició. Per això, informem d'experiments en un conjunt de dades amb indicadors de post-edició recentment recollits i demostrem la seva utilitat quan estimem l'esforç post-edició. Els nostres resultats mostren que les mètriques basades en tasques que comparan versions traduïdes per màquina i posteditades són les millors en el seguiment\ndesprés d'edició, com es esperava. Aquestes mètriques són seguides de DA, i després de mètriques que comparan la versió traduïda per màquina i les referències independents. Sugirem que els metges de MT siguin conscients d'aquestes diferències i reconeixin les seves implicacions quan decideixen com evaluar MT a fins post-edició.", 'he': 'התכנית מטריקה כדי להעריך איכות התרגום תמיד היתה ליבת מחקר התרגום המכונית (MT). מטריות אוטומטיות מסורתיות מבוססות על התייחסות, כמו BLEU, הראו קשרים עם השיפוטים האנושיים של מתאימות ושקטנות והיו חשובים בהתקדמות של פיתוח מערכת MT. המקורות הציבורים פופולריזמו ואפשרו את האפשרות של המטריקה מבוססת על שיפוטים אנושיים, כמו הערכות ישירות סוביקטיביות (DA) של מתאימות, שאומרות להיות אמינות יותר ממטריקה אוטומטית מבוססת התייחסות. סוף סוף, מדידות מבוססות על משימות, כמו זמן לאחר העורקה, מצפים לספק עריכה מועטפת יותר של השימוש של התרגשות למשימה מסוימת. לכן, בעוד התובע המחוזי ממוצע שיפוטים מתאימות כדי להשיג הערכה של איכות (נבחרת) ללא קשר למשימה, ומטריקות אוטומטיות מבוססת על התייחסות מנסות להעריך באופן אובייקטיבי גם באופן עצמאי למשימה, מטריות מבוססת על המשימה הם מדידות שנקבלו במהלך או לאחר ביצוע משימה מסויימת. בעיתון הזה אנחנו מתווכחים כי, למרות שידורים יקרים, מבוססים על משימה הם המדידות הכי אמינות בערכת איכות MT במשימה מסוימת; in our case, this task is post-editing.  למטרה זו, אנו מדווחים על ניסויים על קבוצת נתונים עם אינדיקטורים לאחר העורה שנאספו חדשים ולהראות את שימושיהם בערכת מאמץ לאחר העורה. התוצאות שלנו מראות שמטריקות מבוססות במשימות שיוות גרסאות מתרגמות ומאוחרות עורכות הן הטובות ביותר בעקבות\npost-editing effort, as expected.  המטריקות האלה עוקבות על ידי DA, ואז על ידי מטריקה שיווה את הגרסה המתורגמת במכונה וההתייחסות עצמאות. אנחנו מציעים שמרפאים MT צריכים להיות מודעים לדברים האלה ולהכיר את השלכות שלהם כשהם מחליטים איך להעריך MT למטרות אחרי העורקה.', 'jv': 'Peringatan metir kanggo nggunakaké kaliwat itoleh dumadhi neng coro pangunangan tarjamahan (MT). Tradisyonal sistem sistem sing diagram-reference-basa sistem, kayané lunak nglarangso sistem MT politenessoffpolite"), and when there is a change ("assertive FullName Anda tho, nggambar Da Averages Adjustments for Get an Appraise of Nang pepulan iki rasané, mengko karo akeh lanjut, dadi pipilihan sing paling nggawe barang nggawe barang MT kuwi nggawe barang nggawe gerakan; MT kuwi, ngawe malay Saiki, kita ngubah perintah sing beraksi barêng dataset nganggep sistem sing gawe ngubah-editor ambara batar nggawe barang nggawe usul dumadhan mrah-editing efforte. Rejaliane nambarang kelas karo task-basa meta kang sampeyan kelas-tarjamahan karo pak-editahan versi sing luwih apik dhéwé nang njaluk-njaluk\ntext-editor-action Perintah sing dipunangé karo Da, lan dipunangé metik karo nggawe versi-terjamahan karo perusahaan sing sampeyan. Awak dhéwé éntuk pernik MT dipoleh kanggo ngerasai perkara-perkara iki dadi, nik nggunakake perkara-perusahaan kuwi nggawe barang MT kanggo ngilangno mbutuhaké tarjamahan.', 'ha': "KCharselect unicode block name KCharselect unicode block name Crowd-sourcing has popularised and enabled the scalability of metrics based on human judgments, such as subjective direct assessments (DA) of adequacy, that are believed to be more reliable than reference-based automatic metrics.  Gani, ana ƙayyade gwargwadon aiki da aka ƙayyade shi, kamar lokaci na taƙaita bayan-editing, ana ƙayyade yana ƙaranci ƙidãya wa amfani da fassarar wa wani aiki na ƙayyade. Daga haka, a lokacin da DA ya tsakanin rabo masu daidai ga ya sami wani akan (an gane) mai ba da wani aikin, kuma metric da aka danne shi a kan karatunta farat ɗaya, yana jarraba yana ƙidãya ga gyarata, da kuma a kan iyakar wani aikin da ba'a sãɓa ba, sai a sami metriciki ko a lokacin da aka cika wani aikin wanda aka ƙayyade. Ga wannan takarda, Munã jãyayya cẽwa, kuma kõ da yana da kyauta, ma'auni a kan aikin, za'a iya aminci idan an ƙaddara tsarin MT a cikin wani aikin ƙayyadadde; wannan aikin yana daga bayan editi. Ga wannan, Muke jarraba masu jarraba kan wani tsarin da aka samun bayan-editi-yanzu, kuma Mu nuna amfani da su idan ana ƙayyade aikin bayan-editing. MatamayinMu na nũna cewa metrics a kan aikin da ke daidaita misalin-fassarar da kuma a bayan-edited versions are the best at tracing\npost-editing effort, as expected.  Disse metrics are followed by DA, sa'an nan kuma by metrics, yana sami da zanen-fassar version da misori wanda ba'a daidaita ba. Munã shauri cewa masu amfani da MT su san wannan gaura na musamman, kuma su gaskata matsayinsu idan sun yi zaɓi - yadda za su ƙaddara MT kan hanyarwa a bayan editorin.", 'sk': 'Oblikovanje meritev za ocenjevanje kakovosti prevajanja je bilo vedno v središču raziskav strojnega prevajanja. Tradicionalne samodejne referenčne meritve, kot je BLEU, so pokazale korelacije s človeškimi presojami ustreznosti in tekočosti ter so bile ključnega pomena za napredek razvoja sistema MT. Crowd sourcing je populariziral in omogočil razširljivost meritev, ki temeljijo na človeških presojah, kot so subjektivne neposredne ocene ustreznosti, za katere velja, da so zanesljivejše od referenčnih avtomatskih meritev. Nazadnje se pričakuje, da bodo meritve, ki temeljijo na opravilih, kot je čas po urejanju, zagotovile bolj razširjeno oceno uporabnosti prevodov za določeno nalogo. Medtem ko DA povprečje presoje ustreznosti za pridobitev ocene (zaznane) kakovosti neodvisno od opravila in referenčne avtomatske meritve poskušajo objektivno oceniti kakovost tudi neodvisno od opravila, so meritve, ki temeljijo na opravilih, meritve, pridobljene med opravljanjem določenega opravila ali po njem. V tem prispevku trdimo, da so, čeprav drage, meritve na podlagi nalog najbolj zanesljive pri ocenjevanju kakovosti MT v določeni nalogi; V našem primeru je ta naloga po urejanju. V ta namen poročamo o poskusih na naboru podatkov z novo zbranimi kazalniki po urejanju in pokažemo njihovo uporabnost pri ocenjevanju napora po urejanju. Naši rezultati kažejo, da so meritve na podlagi opravil, ki primerjajo strojno prevedene in po urejanju različic, najboljše pri sledenju\npo urejanju, kot je bilo pričakovano. Temu meritvam sledi DA, nato pa meritve, ki primerjajo strojno prevedeno različico in neodvisne reference. Predlagamo, da se strokovnjaki strokovne tehnologije zavedajo teh razlik in priznajo njihove posledice pri odločanju, kako oceniti strokovno tehnologijo za namene po urejanju.', 'bo': 'Devising metrics to assess translation quality has always been at the core of machine translation (MT) research. Traditional automatic reference-based metrics, such as BLEU, have shown correlations with human judgements of adequacy and fluency and have been paramount for the advancement of MT system development. Crowd-sourcing has popularised and enabled the scalability of metrics based on human judgments, such as subjective direct assessments (DA) of adequacy, that are believed to be more reliable than reference-based automatic metrics. མཐའ་མ་དེ། task-based measurements, such as post-editing time, are expected to provide a more de-tailed evaluation of the usefulness of translations for a specific task. Therefore, while DA averages adequacy judgements to obtain an appraisal of (perceived) quality independently of the task, and reference-based automatic metrics try to objectively estimate quality also in a task-independent way, task-based metrics are measurements obtained either during or after performing a specific task. འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་འོང་ཚོས་འཇུག་སྐྱོང་རྩིས་བ་དང་། ལས ང་ཚོའི་གནས་ཚུལ་ནང་དུ་ལས་འགུལ་འདི་ཞིབ་བསྒྱུར་བཅོས་བྱེད་ཀྱི་ཡོད། མཇུག་དེ་ལ་ང་ཚོས་ཞུགས་ཡོད་པའི་གནས་ཚུལ་སྒྲིག་གི་ཞིབ་དཔྱད་བྱེད་སྐབས་གསརཔ་ཞིག་བསྡུར་བ་ཡོད་པའི་བརྡ་སྟོན་བྱེད་སྐབས་ Our results show that task-based metrics comparing machine-translated and post-edited versions are the best at tracking\nརེ་འདུས་པ་ལྟར་བསྒྱུར་བཅོས་བྱེད་སྟངས། These metrics are followed by DA, and then by metrics comparing the machine-translated version and independent references. ང་ཚོས་MT ལག་ལེན་པ་ཚོ་རྣམས་ལ་ཁྱད་པར་འདི་དག་སྟོན་དང་། རྗེས་སྒྲུབ་ཀྱི་གནང་བ་དེ་རྟོགས་གནང་།'}
{'en': 'Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification', 'es': 'Exploración de las funciones del núcleo en la capa Softmax para la clasificación de palabras', 'pt': 'Explorando funções do kernel na camada Softmax para classificação contextual de palavras', 'zh': '于 Softmax 层中探上下文词分类之内核函数', 'ja': 'コンテキストワード分類のためのSoftmaxレイヤーのカーネル関数の探索', 'ar': 'استكشاف وظائف النواة في طبقة Softmax لتصنيف الكلمات السياقية', 'fr': 'Exploration des fonctions du noyau dans la couche Softmax pour la classification contextuelle des mots', 'hi': 'प्रासंगिक शब्द वर्गीकरण के लिए Softmax परत में कर्नेल फ़ंक्शन की खोज', 'ru': 'Изучение функций ядра в слое Softmax для контекстной классификации слов', 'ga': 'Feidhmeanna Eithne a Iniúchadh sa Chiseal Softmax le haghaidh Aicmiú Comhthéacsúil Focal', 'el': 'Εξερεύνηση λειτουργιών πυρήνου στο στρώμα για περιεκτική ταξινόμηση λέξεων', 'hu': 'Kernelfunkciók feltárása a Softmax rétegben a kontextuális szóosztályozáshoz', 'it': 'Esplorare le funzioni del kernel nel livello Softmax per la classificazione contestuale delle parole', 'ka': 'Name', 'mk': 'Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification', 'ms': 'Menjelaskan Fungsi Kernel dalam Lapisan Softmax untuk Klasifikasi Kata Konteksual', 'lt': 'Išnagrinėjamos branduolio funkcijos softmax sluoksnyje kontekstiniam žodžių klasifikavimui', 'kk': 'Контексті сөзді классификациялау үшін Softmax қабаттың Kernel функцияларын зерттеу', 'ml': 'കെര്\u200dണല്\u200d ഫങ്ഷനുകള്\u200d പരിശോധിക്കുന്നു', 'mn': 'Контекст үг классификацийн Softmax Layer-ын Kernel функцийг судлах', 'no': 'Utforskar kjernefunksjonar i «Softmax Layer» for kontekst- ordklassifikasjon', 'mt': 'L-esplorazzjoni tal-Funzjonijiet tal-Kernel fis-Saff Softmax għall-Klassifikazzjoni tal-Kliem Kuntest', 'sr': 'Eksplozirajući funkcije kernela u Softmax sloju za klasifikaciju kontekstalnih reči', 'ro': 'Explorarea funcțiilor Kernel în stratul Softmax pentru clasificarea contextuală a cuvintelor', 'so': 'Qorrada Kernel functions in the Softmax Layer for Context Word Classification', 'pl': 'Eksploracja funkcji jądra w warstwie Softmax dla kontekstowej klasyfikacji słów', 'si': 'සම්බන්ධ වචන වර්ගය සඳහා Softmax ස්තරේ කර්නල් වැඩසටහන් ප්\u200dරශ්නය කරන්න', 'ta': 'Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification', 'sv': 'Utforska kärnfunktioner i Softmax-lagret för kontextuell ordklassificering', 'ur': 'کنٹکسٹ ویر کلاسیفٹ کے لئے Softmax لائر میں کرنل فنکس شناسایی کی جاتی ہے', 'uz': 'Comment', 'vi': 'Khám phá các hàm nhân tạo trong lớp mềm mỏng cho mật khẩu chữ liên tiếp', 'da': 'Undersøgelse af kernefunktioner i Softmax-laget til kontekstuel ordklassificering', 'hr': 'Ispitivanje funkcija Kernela u Softmax sloju za klasifikaciju kontekstnih riječi', 'bg': 'Изследване на функциите на ядрата в слоя за контекстуална класификация на думи', 'nl': 'Het verkennen van kernelfuncties in de Softmax-laag voor contextuele woordclassificatie', 'de': 'Untersuchung von Kernel-Funktionen in der Softmax-Ebene für kontextuelle Wortklassifikation', 'id': 'Menjelaskan Fungsi Kernel dalam Lapisan Softmax untuk Klasifikasi Kata Konteksual', 'ko': 'Softmax 레이어에서 컨텍스트 단어 분류에 사용되는 핵 함수 탐색', 'fa': 'تحقیق عملکرد Kernel در لایه Softmax برای کلاسیف کلمه متوسط', 'sw': 'Mfumo wa Kernel katika Eneo la Softmax kwa ajili ya Classification of Context Word', 'tr': 'Kontekst Kelimi Sözleri üçin Softmax Kalatynda Kernel Kanunlary Saýlaw', 'am': 'undo-type', 'af': 'Vertoon Kernel Funksies in die Softmax Laag vir Konteksual Woord Klassifikasie', 'hy': 'Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification', 'sq': 'Duke eksploruar funksionet e bërthamës në shtresën Softmax për klasifikimin kontekstual të fjalëve', 'bn': 'Name', 'az': 'Kontext Kelimi Sınıfləməsi üçün Softmax Laşında Kernel Funksiyonlarını Səflət', 'cs': 'Prozkoumání funkcí jádra v vrstvě Softmax pro kontextovou klasifikaci slov', 'bs': 'Eksplozirajući funkcije Kernela u Softmax sloju za klasifikaciju kontekstalnih riječi', 'ca': 'Explorar funcions del nucli a la capa Softmax per la classificació de paraules contextuals', 'fi': 'Softmax-tason ytimen funktioiden tutkiminen kontekstuaalista sanaluokitusta varten', 'et': 'Kerneli funktsioonide uurimine Softmax kihis kontekstisõna klassifitseerimiseks', 'jv': 'Isobar Kernel Fongkapan ning Softmaximum Layer kanggo Kontextual Word', 'ha': 'KCharselect unicode block name', 'sk': 'Raziskovanje funkcij jedra v plasti Softmax za kontekstno razvrščanje besed', 'he': 'מחקר פונקציות הגרעין בשיעור Softmax עבור קליфікаציה קונטקסטית של מילים', 'bo': 'མཐའ་ནས་ཁུལ་ཡུག་གི་ཚིག་ཆ་སྒྲིག་ཆ་ཐོག་ཏུ་མཉེན་རིས་ཀྱི་ལས་འགན་སྟོན་པ'}
{'en': 'Prominently used in support vector machines and ', 'pt': 'Usado com destaque em máquinas de vetor de suporte e regressões logísticas, as funções do kernel (kernels) podem mapear implicitamente pontos de dados em espaços de alta dimensão e facilitar o aprendizado de limites de decisão complexos. Neste trabalho, ao substituir a função de produto interno na camada softmax, exploramos o uso de kernels para classificação contextual de palavras. Para comparar os kernels individuais, são realizados experimentos em tarefas de modelagem de linguagem padrão e tradução automática. Observamos uma ampla gama de desempenhos em diferentes configurações de kernel. Estendendo os resultados, observamos as propriedades do gradiente, investigamos várias estratégias de mistura e examinamos as habilidades de desambiguação.', 'ar': 'تستخدم بشكل بارز في آلات المتجهات الداعمة وإعادة الإدماج اللوجستي ، وظائف النواة (النواة) يمكنها ضمنيًا تعيين نقاط البيانات في مساحات عالية الأبعاد وتسهيل تعلم حدود القرار المعقدة. في هذا العمل ، من خلال استبدال وظيفة المنتج الداخلية في طبقة softmax ، نستكشف استخدام النواة لتصنيف الكلمات السياقية. من أجل مقارنة النوى الفردية ، يتم إجراء تجارب على نمذجة اللغة القياسية ومهام الترجمة الآلية. نلاحظ مجموعة واسعة من العروض عبر إعدادات kernel المختلفة. لتوسيع النتائج ، ننظر إلى خصائص التدرج ، ونبحث في استراتيجيات الخليط المختلفة ونفحص قدرات إزالة الغموض.', 'fr': "Utilisées en bonne place dans les machines à vecteurs de support et les régressions logistiques, les fonctions du noyau (noyaux) peuvent implicitement mapper des points de données dans des espaces de grande dimension et faciliter l'apprentissage des limites de décision complexes. Dans ce travail, en remplaçant la fonction interne du produit dans la couche softmax, nous explorons l'utilisation des noyaux pour la classification contextuelle des mots. Afin de comparer les différents noyaux, des expériences sont menées sur des tâches de modélisation linguistique standard et de traduction automatique. Nous observons un large éventail de performances dans les différents paramètres du noyau. En élargissant les résultats, nous examinons les propriétés du gradient, étudions diverses stratégies de mélange et examinons les capacités de désambiguïsation.", 'es': 'Utilizadas de forma destacada en máquinas de vectores de soporte y regresiones logísticas, las funciones del núcleo (núcleos) pueden mapear implícitamente puntos de datos en espacios de alta dimensión y facilitar el aprendizaje de límites de decisión complejos. En este trabajo, al reemplazar la función interna del producto en la capa softmax, exploramos el uso de núcleos para la clasificación de palabras contextuales. Para comparar los núcleos individuales, se llevan a cabo experimentos sobre tareas estándar de modelado del lenguaje y traducción automática. Observamos una amplia gama de rendimientos en diferentes configuraciones del núcleo. Ampliando los resultados, observamos las propiedades del degradado, investigamos varias estrategias de mezcla y examinamos las habilidades de desambiguación.', 'ja': 'サポートベクトルマシンおよびロジスティック再侵入で顕著に使用されるカーネル関数（カーネル）は、データポイントを高次元空間に暗黙的にマッピングし、複雑な決定境界を学習しやすくすることができる。この作業では、softmaxレイヤの内部製品関数を置き換えることで、コンテキストワード分類のためのカーネルの使用を探求します。個々のカーネルを比較するために、標準的な言語モデリングおよび機械翻訳タスクで実験が行われる。さまざまなカーネル設定で幅広いパフォーマンスを観察します。結果を拡張するには、勾配の特性を調べ、さまざまな混合戦略を調査し、曖昧さを解消する能力を調べます。', 'zh': '核函数(核)于向量机、逻辑重构中特用之,可隐式映数于高维空间,而使易于复杂之策。 于是代softmax层中之内积函数,探内核上下文词分类之用。 校诸内核,言建模机器翻译实验。 吾观异内核设中之广能也。 广之,视梯度性,论杂混合策略而省歧义能。', 'hi': 'प्रमुखता से समर्थन वेक्टर मशीनों और रसद re-gressions में उपयोग किया जाता है, कर्नेल फ़ंक्शन (कर्नेल) स्पष्ट रूप से उच्च आयामी रिक्त स्थान में डेटा बिंदुओं को मैप कर सकते हैं और जटिल निर्णय सीमाओं को सीखना आसान बना सकते हैं। इस काम में, सॉफ्टमैक्स परत में आंतरिक उत्पाद फ़ंक्शन को बदलकर, हम प्रासंगिक शब्द वर्गीकरण के लिए कर्नेल के उपयोग का पता लगाते हैं। व्यक्तिगत कर्नेल की तुलना करने के लिए, मानक भाषा मॉडलिंग और मशीन अनुवाद कार्यों पर प्रयोग किए जाते हैं। हम विभिन्न कर्नेल सेटिंग्स में प्रदर्शन की एक विस्तृत श्रृंखला का निरीक्षण करते हैं। परिणामों का विस्तार करते हुए, हम ग्रेडिएंट गुणों को देखते हैं, विभिन्न मिश्रण रणनीतियों की जांच करते हैं और बहुविकल्पीय क्षमताओं की जांच करते हैं।', 'ru': 'Функции ядра (ядра), которые широко используются в векторных машинах поддержки и логистических регрессиях, могут имплицитно отображать точки данных в высокомерные пространства и облегчать изучение сложных границ принятия решений. В этой работе, заменяя внутреннюю функцию продукта в слое softmax, мы исследуем использование ядер для контекстной классификации слов. Для сравнения отдельных ядер проводятся эксперименты по типовому языковому моделированию и задачам машинного перевода. Мы наблюдаем широкий спектр производительности в различных настройках ядра. Расширяя результаты, мы смотрим на градиентные свойства, исследуем различные стратегии смешивания и исследуем способности к расплывчатости.', 'ga': 'Úsáidtear go feiceálach i meaisíní veicteora tacaíochta agus aischéimniúcháin loighistice, is féidir le feidhmeanna eithne (eithne) pointí sonraí a mhapáil go hintuigthe isteach i spásanna ardtoiseacha agus é a dhéanamh níos éasca teorainneacha cinntí casta a fhoghlaim. Sa obair seo, trí fheidhm an táirge inmheánaigh a athsholáthar sa chiseal softmax, déanaimid iniúchadh ar úsáid eithne le haghaidh aicmiú focal comhthéacsúil. Chun comparáid a dhéanamh idir na heithne aonair, déantar turgnaimh ar shamhaltú caighdeánach teanga agus ar thascanna aistrithe meaisín. Breathnaímid ar raon leathan léirithe ar fud suíomhanna eithne éagsúla. Agus na torthaí á leathnú, féachaimid ar airíonna an ghrádáin, déanaimid imscrúdú ar straitéisí meascán éagsúla agus scrúdaimid na cumais dí-athbhrí.', 'el': 'Οι λειτουργίες πυρήνων (πυρήνες) μπορούν έμμεσα να χαρτογραφήσουν σημεία δεδομένων σε χώρους υψηλών διαστάσεων και να διευκολύνουν την εκμάθηση σύνθετων ορίων αποφάσεων. Σε αυτή την εργασία, αντικαθιστώντας την εσωτερική λειτουργία του προϊόντος στο στρώμα εξερευνούμε τη χρήση των πυρήνων για την περιεκτική ταξινόμηση λέξεων. Για τη σύγκριση των μεμονωμένων πυρήνων, διεξάγονται πειράματα σε τυπικές γλωσσικές μοντελοποιήσεις και εργασίες μηχανικής μετάφρασης. Παρατηρούμε ένα ευρύ φάσμα επιδόσεων σε διαφορετικές ρυθμίσεις πυρήνα. Επεκτείνοντας τα αποτελέσματα, εξετάζουμε τις ιδιότητες κλίσης, διερευνούμε διάφορες στρατηγικές μείγματος και εξετάζουμε τις δυνατότητες διασάφησης.', 'hu': 'Kiemelkedően a vektorgépek támogatásában és a logisztikai újrafeldolgozásokban használt kernel függvények (kernel) implicit módon feltérképezhetik az adatpontokat nagy dimenziós terekbe, és megkönnyítik a komplex döntési határok megismerését. Ebben a munkában a softmax rétegben a belső termékfüggvény helyettesítésével feltárjuk a magok használatát a kontextuális szóosztályozáshoz. Az egyes magok összehasonlítása érdekében kísérleteket végeznek standard nyelvi modellezési és gépi fordítási feladatokkal. A teljesítmények széles skáláját figyeljük meg a különböző kernel beállítások között. Az eredmények kiterjesztésével megvizsgáljuk a gradiens tulajdonságait, vizsgáljuk a különböző keverék stratégiákat és vizsgáljuk az egyértelműsítési képességeket.', 'it': "Utilizzate in modo prominente nelle macchine vettoriali di supporto e nelle ri-gressioni logistiche, le funzioni del kernel (kernel) possono mappare implicitamente i punti di dati in spazi ad alta dimensione e rendere più facile apprendere i confini decisionali complessi. In questo lavoro, sostituendo la funzione interna del prodotto nel livello softmax, esploriamo l'uso dei kernel per la classificazione contestuale delle parole. Al fine di confrontare i singoli kernel, vengono condotti esperimenti su attività standard di modellazione linguistica e traduzione automatica. Osserviamo una vasta gamma di prestazioni attraverso diverse impostazioni del kernel. Estendendo i risultati, esaminiamo le proprietà del gradiente, indaghiamo varie strategie di miscela ed esaminiamo le abilità di disambiguazione.", 'lt': 'Akivaizdžiai naudojami paramos vektorių mašinoms ir logistinėms regresijoms, branduolių funkcijos (branduoliai) gali netiesiogiai paversti duomenų taškus į didelės dimensijos erdves ir palengvinti sudėtingų sprendimų ribų mokymąsi. Šiame darbe, pakeičiant vidaus produkto funkciją softmax sluoksnyje, tiriame branduolių naudojimą kontekstiniam žodžių klasifikavimui. In order to compare the individual kernels, experiments are conducted on standard language modeling and machine translation tasks.  We observe a wide range of performances across different kernel settings.  Išplečiant rezultatus, vertiname gradientines savybes, tiriame įvairias mišinių strategijas ir išnagrinėjame galimybes atsisakyti abejonių.', 'kk': 'Виктор машиналарды және логистикалық қайта сұрыштарды қолдану үшін, өзек функциялары (көзек) деректер нүктелерін көп өлшемді бос орындарға картап, комплекс шешім шектерін оқыту үшін оңай алады. Бұл жұмыс ішкі продукттың ішкі функциясын бағдарламалық қабаттың орнына ауыстырып, контексті сөздерді классификациялау үшін көшелер қолдануын зерттейміз. Әрбір қыршектерді салыстыру үшін, тәжірибелер стандартты тілдерді моделдеу және машинаны аудару тапсырмаларында орындалады. Біз өзек параметрлерінде көп жұмыс аралығын қараймыз. Нәтижелерді кеңейту үшін, градиенттің қасиеттерін қараймыз, әртүрлі аралас стратегияларын зерттеп, бағдарламалық мүмкіндіктерін тексереміз.', 'ms': 'Ternyata digunakan dalam mesin vektor sokongan dan gresi-ulang logistik, fungsi kernel (kernel) boleh secara implicit peta titik data ke ruang dimensi tinggi dan membuatnya lebih mudah untuk belajar sempadan keputusan kompleks. Dalam kerja ini, dengan menggantikan fungsi produk dalaman dalam lapisan softmax, kami mengeksplorasi penggunaan kernel untuk klasifikasi perkataan kontekstual. Untuk membandingkan kernel individu, eksperimen dilakukan pada model bahasa piawai dan tugas terjemahan mesin. Kami mengamati julat luas prestasi melalui tetapan kernel yang berbeza. Meluaskan keputusan, kita melihat ciri-ciri gradien, menyelidiki berbagai strategi campuran dan memeriksa kemampuan penyelesaian.', 'ka': 'პრომენტიურად გამოყენებულია ვიქტორის მაქანებში და ლოგისტიკური რეგრესიაში, კურნელი ფუნქციები (კურნელი) შეუძლიათ იმპლიციტურად დანახავს მონაცემების უფრო მეტი განზომილებული ადგილებში ამ სამუშაოში, შეცვლით შინის პროექტის ფუნქცია სიტყვეტის სიტყვეტის სიტყვეტის სიტყვეტის სიტყვეტის გამოყენების გამოყენება, ჩვენ შევხედავთ კონტექსტური ინდიველური კერნელების შემდგენისთვის, ექსპერიმენტები სტანდარტული ენის მოდელირების და მაქსინის შემგრძელების მომდელირებისთვის გავაკეთება. ჩვენ განსხვავებული კურნალის პარამეტრებით უფრო დიდი პარამეტრები დანახვა. შედეგების გაფართვა, ჩვენ დავხედავთ გრადიენტის შესახებ, განსხვავება სტრატიგიები და განსხვავება განსხვავებული შესაძლებლობა.', 'mt': 'Jintużaw b’mod prominenti f’magni ta’ appoġġ għall-vetturi u f’regressjonijiet loġistiċi, il-funzjonijiet tal-kernel (kernels) jistgħu jimmappjaw b’mod impliċitu l-punti tad-dejta fi spazji dimensjonali għoljin u jagħmluha aktar faċli li jitgħallmu limiti kumplessi tad-deċiżjonijiet. F’dan ix-xogħol, billi tissostitwixxi l-funzjoni tal-prodott intern fis-saff softmax, nesploraw l-użu tal-qalba għall-klassifikazzjoni tal-kliem kuntestwali. In order to compare the individual kernels, experiments are conducted on standard language modeling and machine translation tasks.  Aħna nżommu firxa wiesgħa ta’ prestazzjonijiet f’setturi differenti tal-qalba. Fl-estensjoni tar-riżultati, aħna nħarsu lejn il-karatteristiċi gradjenti, ninvestigaw diversi strateġiji ta’ taħlitiet u jeżaminaw l-abbiltajiet ta’ diżambigwazzjoni.', 'ml': 'വെക്റ്റര്\u200d യന്ത്രങ്ങള്\u200dക്കും ലോഗിസ്റ്റിക്ക് വീണ്ടും പിന്തുണയ്ക്കാന്\u200d ഉപയോഗിക്കുന്നതിനും, കെര്\u200dണല്\u200d ഫങ്ഷനുകള്\u200d (കെര്\u200dണലുകള്\u200d) ഉയര്\u200dന്ന സ്ഥലങ്ങളില്\u200d ഡേറ ഈ പ്രവര്\u200dത്തിയില്\u200d, സോഫ്റ്റ്മാക്സ് ലേറ്റിലെ ഉള്ള ഉള്ളിലെ പ്രവൃത്തിക്കുള്ള ഫങ്ഷന്\u200d പകരം നമ്മള്\u200d കെര്\u200dണലുകള്\u200d ഉപയോഗിക്കു വ്യക്തിപരമായ കെര്\u200dണലുകളെ താരതമ്യം ചെയ്യാന്\u200d വേണ്ടി, സാധാരണ ഭാഷയുടെ മോഡലിങ്ങിലും യന്ത്രം പരിഭാഷകളുടെ ജോലികളില നമ്മള്\u200d വ്യത്യസ്ത കെര്\u200dണല്\u200d സജ്ജീകരണങ്ങള്\u200dക്ക് മുകളില്\u200d വ്യത്യസ്തമായ പ്രദര്\u200dശനങ്ങള്\u200d കാണുന്നു. Extending the results, we look at the gradient properties, investigate various mixture strategies and examine the disambiguation abilities.', 'no': 'Vanlegvis brukt i støtte av vektormaskiner og logistiske gjenopprettingar, kjernefunksjonar (kjerner) kan implisitt kartera datapunkt til høg dimensjonal mellomrom og gjera det lettere å lære komplekse avgjøringsgrenser. I dette arbeidet, ved å byta ut den innere produktfunksjonen i softmax-laget, utforskar vi bruken av kjerner for kontekstalt ordklassifikasjon. For å sammenligne dei individuelle kjernene, vert eksperimenterte gjennomført på standardmodeller for språk og maskinsomsetjingar. Vi observerer eit brett område av utføringar over ulike kjerneinnstillingar. Dersom vi utvidar resultatet, ser vi på fargeovergangseigenskapane, undersøker ulike blandingsstrategier og undersøker disambiguasjonskapasiteten.', 'mn': 'Вектор машинууд болон логистик дахин грассис гэх мэт хэрэглэгддэг бөгөөд көдрийн функцүүд (цөмбөлөг) өгөгдлийн цэгүүдийг өндөр хэмжээст орон зайд газрын зураг зураж, комплекс шийдвэр гаргах хязгаарыг су Энэ ажил дээр доторх бүтээгдэхүүний функцийг софтмакс давхар давхар дээр орчин үеийн хуваалцааны тусламжтайг судалж байна. Хувь цэргүүдийг харьцуулахын тулд стандарт хэл загвар болон машины орчуулах үйл ажиллагаанд туршилт хийгддэг. Бид өөр цөмийн тохиолдолд олон олон үйл ажиллагааг ажиглаж байна. Үүний үр дүнг нэмэгдүүлснээр бид градиентийн өөрчлөлтийг харж, олон төрлийн цуглуулах стратегийг судалж, буруутгах чадварыг судалж.', 'ro': 'Utilizate în mod prominent în mașinile vectoriale de suport și regresiunile logistice, funcțiile nucleului (nucleele) pot cartografia implicit punctele de date în spații dimensionale înalte și pot face mai ușor să învețe limitele complexe de decizie. În această lucrare, prin înlocuirea funcției interne a produsului în stratul softmax, explorăm utilizarea nucleelor pentru clasificarea contextuală a cuvintelor. Pentru a compara nucleele individuale, experimentele sunt efectuate pe sarcini standard de modelare lingvistică și traducere automată. Observăm o gamă largă de performanțe în diferite setări ale nucleului. Extindem rezultatele, analizăm proprietățile gradientului, investigăm diferite strategii de amestec și examinăm abilitățile de dezambiguizare.', 'mk': 'Претседателно употребени во векторните машини за поддршка и логистичките регресии, јадровите функции (јадровите) можат имплицитно да ги мапираат податочните точки во високи димензионални простори и да го олеснат научувањето на комплексни граници на одлу Во оваа работа, со замена на внатрешната функција на производот во слојот softmax, го истражуваме употребата на јадрите за контекстна класификација на зборови. За да се споредат индивидуалните јадри, се спроведуваат експерименти на стандардното јазичко моделирање и машински преведувачки задачи. Набљудуваме широк опсег на изведби низ различни поставувања на јадрото. Проширувајќи ги резултатите, ги гледаме градиентните сопствености, ги истражуваме различните стратегии за мешање и ги истражуваме способностите за раздвојување.', 'pl': 'Funkcje jądra (jądra) mogą bezpośrednio mapować punkty danych do przestrzeni wysokich wymiarów i ułatwiać naukę złożonych granic decyzji. W niniejszej pracy, zastępując wewnętrzną funkcję produktu w warstwie softmax, badamy wykorzystanie jąder do kontekstowej klasyfikacji słów. W celu porównania poszczególnych jąder prowadzone są eksperymenty na standardowych zadaniach modelowania językowego i tłumaczenia maszynowego. Obserwujemy szeroki zakres wydajności w różnych ustawieniach jądra. Rozszerzając wyniki, przyglądamy się właściwościom gradientu, badamy różne strategie mieszaniny i badamy zdolności dyjednoznaczności.', 'sr': 'Prominentno korišteno u podršku vektorskih mašina i logističkih pregresija, funkcije kernel (kernels) mogu implicitno mapirati tačke podataka u visoke dimenzionalne prostore i olakšati se učiti složene granice odluke. U ovom poslu, zamenimo funkciju unutrašnjeg proizvoda u softmax sloju, istražujemo korištenje kernela za kontekstualnu klasifikaciju riječi. Da bi usporedilo pojedinačne kernele, eksperimenti su provedeni na standardnim zadatkima za modeliranje jezika i prevod mašine. Pratimo širok raspon izvedbi u različitim nastavacima kernel. Proširenjem rezultata, pogledamo vlasništvo gradienta, istražujemo različite strategije mješavine i pregledamo sposobnosti disambigacije.', 'sv': 'Kärnfunktioner (kärnor) används i hög grad i stöd för vektormaskiner och logistiska omfördelningar och kan underförstått kartlägga datapunkter i högdimensionella utrymmen och göra det lättare att lära sig komplexa beslutsgränser. Genom att ersätta den inre produktfunktionen i softmax-lagret undersöker vi användningen av kärnor för kontextuell ordklassificering. För att jämföra de enskilda kärnorna utförs experiment på standardspråkmodellering och maskinöversättningsuppgifter. Vi observerar ett brett utbud av prestanda över olika kärninställningar. Utvidgningen av resultaten undersöker vi gradientegenskaperna, undersöker olika blandningsstrategier och undersöker desbetingande förmågor.', 'ta': 'வெக்டார் இயந்திரங்களுக்கும் புகுநிரல் மீண்டும் முன்னேற்றங்களுக்கும் ஆதரவு பயன்படுத்தப்படுகிறது, கெர்னல் செயல்பாடுகள் (கெர்னல்கள்) அதிக பரிமாற்றமா In this work, by replacing the inner product function in the softmax layer, we explore the use of kernels for contextual word classification.  தனிப்பட்ட கெர்னல்களை ஒப்பிடுவதற்கு, இயல்பான மொழி மாதிரி மாதிரி மற்றும் இயந்திர மொழி மொழிமாற்றி பணிகளில் சோதன நாம் பல்வேறு கருவி அமைப்புகளை பார்க்கிறோம். முடிவுகளை மேலும், நாம் சாம்பல் பண்புகளை பார்க்கிறோம், பல கலப்பு திட்டங்களை ஆய்வு செய்து பிரிவு செய்யும் தன்மைகளை பர', 'so': "Shaqooyinka kernelada (kernels) waxay si fudud ugu isticmaali karaan goobaha takhasuska ah oo aad u fududaato in aad barato xuduudaha go'aanka oo adag. Markaas waxan shaqada, si aan ugu beddelno shaqada dhaqaalaha hoose ee xarunta dhakhtarka, waxaynu baaraynaa isticmaalka kernellada si loo fasaxo hadalka hore. Si loo barbardhigo qalabka gaarka ah waxaa lagu sameeyaa imtixaamo lagu sameynayo tusaale ahaan luqada caadiga ah iyo shaqooyinka turjumidda machine. Waxaynu aragnaa tababaro faro badan oo ku yaal xarumaha qalabka kala duduwan. Faahfaahin dheeraad ah ayaannu fiirinaynaa, baaritaanno qalabka isku xiriirka ah, baaritaanka awoodda kala duwan ee kala duwan.", 'si': 'ප්\u200dරධානයෙන් වෙක්ටර් යන්ත්\u200dරය සහ ලෝජිස්ටික් ආපහු ග්\u200dරේසියන් සඳහා භාවිත කරන්න පුළුවන් වෙක්ටර් යන්ත්\u200dරය සඳහා කාර්නේල් වැඩක් ප්\u200dර මේ වැඩේදී, සොෆ්ට් මැක්ස් ලේයර් වල ඇතුළු ප්\u200dරවෘත්තිය හැදුවොත්, අපි ප්\u200dරවෘත්තිය වචන විශේෂණය සඳහා කර්නල් භ ප්\u200dරතිකෘත කර්නල් සමුදානම් කරන්න, ප්\u200dරමාණය භාෂාව මොඩිල් කරන්න සහ මැෂින් වාර්ථාව කාර්යාලයේ පරීක අපි වෙනස් කර්නල් සැකසුම් වලින් ප්\u200dරමාණයක් බලන්න. ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරශ්ණය පරීක්', 'ur': 'وکٹر ماشینوں اور لوجیسٹیک دوبارہ گریشن کے مددگار میں استعمال کیا جاتا ہے، کرنل فنسکینوں (کرنل) اچھے اندازے کے فضاؤں میں ڈاٹ پوینٹوں کو نقشه بنا سکتے ہیں اور اسے پیچیدہ فیصلہ کے حدود سے سیکھنا آسان کر سکتے ہیں۔ اس کام میں، نرم مکس لائر میں داخلی محصولات کا فناکٹ بدل کر، ہم متوسط لفظ کلاسیفوں کے لئے کرنل کے استعمال کا تحقیق کرتے ہیں. ایک شخص کرنل کے مقایسہ کرنے کے لئے آزمائش استاندارڈ زبان موڈلینگ اور ماشین ترجمہ کے کاموں پر عمل کیے جاتے ہیں. ہم مختلف کرنل امستیوں میں ایک گھیرے طریقے کی نمائش دیکھتے ہیں۔ نتیجے پھیلاتے ہیں، ہم گراڈینٹ کے خصوصے کو دیکھتے ہیں، مختلف میکسٹ استراتژی کی تحقیق کرتے ہیں اور مختلف اختلافات کی تحقیق کرتے ہیں.', 'vi': 'Thường được dùng trong các cỗ máy vector và hệ thống tình báo, các chức năng hạt nhân (hạt nhân) có khả năng ẩn ý chia dữ liệu vào các khu vực rộng lớn và dễ dàng tìm hiểu ranh giới quyết định phức tạp. Trong công việc này, thay thế chức năng sản phẩm bên trong trong trong trong lớp đa dạng, chúng tôi khám phá cách sử dụng hạt nhân để phân loại từ ngữ ngữ ngữ. Để so sánh các hạt nhân cá nhân, thử nghiệm được thực hiện trên các công việc thiết kế ngôn ngữ chuẩn và dịch thuật máy. Chúng tôi quan sát một loạt các trình độ của CPU khác nhau. Mở rộng kết quả, chúng tôi xem các thuộc tính dốc định, nghiên cứu các lược trộn khác nhau và kiểm tra khả năng biến dạng.', 'uz': "Name Bu ishda, dastur darajadagi narsalarning ichki narsalar funksiyasini almashtirish uchun kernellarni foydalanamiz. Name Biz har xil kernellar parametrlarida ko'p narsalarni ko'p ko'plab ko'rinamiz. Natijalarni ko'paytirish uchun gradient xossalariga qaramiz, har xil qanday bir qanday mixturening strategiyasini qidirish va qidirish imkoniyatlarini tekshiring.", 'bg': 'Известно използвани в поддържащи векторни машини и логистични повторения, функциите на ядрото (ядра) могат имплицитно да картографират точки от данни в пространства с високи измерения и да улеснят изучаването на сложни граници на решенията. В тази работа, като заменим вътрешната продуктова функция в слоя изследваме използването на ядра за контекстуална класификация на думите. За да се сравнят отделните ядра, се провеждат експерименти по стандартно езиково моделиране и задачи за машинен превод. Наблюдаваме широк спектър от изпълнения в различни настройки на ядрото. Разширявайки резултатите, разглеждаме градиентните свойства, изследваме различни стратегии за смесване и изследваме способностите за разграничаване.', 'hr': 'Prominentno korišteno u podršku vektorskih strojeva i logističkih pregresija, funkcije kernel (kernels) mogu implicitno mapirati tačke podataka u visoke dimenzionalne prostore i olakšati se učiti složene granice odluke. U ovom poslu, zamijenjem funkcije unutarnjeg proizvoda u softmax sloju, istražujemo korištenje kernela za kontekstualnu klasifikaciju riječi. Kako bi se usporedilo pojedinačne kernele, eksperimenti se provode na standardnim zadatkima za modeliranje jezika i prevod strojeva. Pratimo širok raspon izvođenja u različitim nastavacima kernel. Proširenjem rezultata, pogledamo vlasništvo gradienta, istražujemo različite mješavine strategije i pregledamo sposobnosti disambigacije.', 'da': 'Kernefunktioner (kerner) anvendes fremragende i understøttelsesvektormaskiner og logistiske gengressioner og kan implicit kortlægge datapunkter i højdimensionelle rum og gøre det lettere at lære komplekse beslutningsgrænser. I dette arbejde, ved at erstatte den indre produktfunktion i softmax laget, undersøger vi brugen af kerner til kontekstuel ordklassificering. For at sammenligne de enkelte kerner udføres eksperimenter med standardsprogmodellering og maskinoversættelsesopgaver. Vi observerer en bred vifte af ydeevner på tværs af forskellige kerneindstillinger. Udvidet resultaterne ser vi på gradientegenskaberne, undersøger forskellige blandingsstrategier og undersøger forskellige forskellige forskellige forskellige forskellige evner.', 'nl': 'Kernelfuncties (kernels) worden prominent gebruikt in ondersteunende vectormachines en logistieke re-gressies en kunnen impliciet gegevenspunten in hoge dimensionale ruimtes in kaart brengen en het gemakkelijker maken om complexe beslissingsgrenzen te leren. In dit werk onderzoeken we door de interne productfunctie in de softmax laag te vervangen het gebruik van kernels voor contextuele woordclassificatie. Om de afzonderlijke kernels te vergelijken, worden experimenten uitgevoerd met standaardtaalmodellering en machinevertaaltaken. We observeren een breed scala aan prestaties in verschillende kernel instellingen. Uitbreiding van de resultaten, kijken we naar de gradiënt eigenschappen, onderzoeken verschillende mengstrategieën en onderzoeken de disambiguatie capaciteiten.', 'de': 'Kernelfunktionen (Kernel) können Datenpunkte implizit in hochdimensionalen Räumen abbilden und das Erlernen komplexer Entscheidungsgrenzen erleichtern. In dieser Arbeit untersuchen wir durch Ersetzen der inneren Produktfunktion in der softmax-Schicht die Verwendung von Kerneln zur kontextuellen Wortklassifizierung. Um die einzelnen Kernel zu vergleichen, werden Experimente an Standard-Sprachmodellierungs- und maschinellen Übersetzungsaufgaben durchgeführt. Wir beobachten eine breite Palette von Leistungen in verschiedenen Kernel-Einstellungen. In der Erweiterung der Ergebnisse betrachten wir die Gradienteneigenschaften, untersuchen verschiedene Mischungsstrategien und untersuchen die Disambiguationsfähigkeiten.', 'id': 'Ternyata digunakan dalam mesin vektor dukungan dan re-gresi logistik, fungsi kernel (kernel) secara implicit dapat memetakan titik data ke ruang dimensi tinggi dan membuat lebih mudah untuk belajar perbatasan keputusan kompleks. Dalam pekerjaan ini, dengan menggantikan fungsi produk dalam dalam lapisan softmax, kami mengeksplorasi penggunaan kernel untuk klasifikasi kata kontekstual. Untuk membandingkan kernel individu, eksperimen dilakukan pada model bahasa standar dan tugas terjemahan mesin. Kami mengamati jangkauan luas pertunjukan melalui pengaturan kernel yang berbeda. Meluaskan hasilnya, kita melihat properti gradien, menyelidiki berbagai strategi campuran dan memeriksa kemampuan penyelesaian.', 'ko': '핵 함수(kernels)는 벡터기와logistic 회귀를 지원하는 데 광범위하게 응용되고 있으며 데이터 포인트를 고차원 공간에 은밀하게 비추어 복잡한 의사결정 경계의 학습을 더욱 쉽게 할 수 있다.이 작업에서softmax층의 내적 함수를 교체함으로써 우리는 내부 핵을 어떻게 사용하여 상하문어를 분류하는지 탐색했다.각 내핵을 비교하기 위해 우리는 표준 언어 모델링과 기계 번역 임무에서 실험을 진행하였다.우리는 서로 다른 내부 핵에 설치된 각종 성능을 관찰했다.확장 결과에 따라 우리는 사다리의 특성을 관찰하고 각종 혼합 전략을 연구하며 분해 능력을 검사한다.', 'fa': 'موقع استفاده از دستگاه\u200cهای پشتیبانی ویکتور و بازگشایش\u200cهای لوژیک، عملکرد\u200cهای کرنل (کرنل) می\u200cتوانند نقشه\u200cهای داده\u200cها را به فضای بالا اندازه\u200cای نقشه\u200cبندی کنند و آن را آسانتر می\u200cسازند که حدود تصمیم پیچیده را یاد بگیرند. در این کار، با جایگزینش فعالیت تولید داخلی در طبقه نرم\u200cماکس، استفاده از کرنه\u200cها برای کلمه\u200cهای متوسط تحقیق می\u200cکنیم. برای مقایسه کردن کرن\u200cهای شخصی، آزمایش\u200cها بر روی مدل\u200cسازی زبان و ترجمه\u200cهای ماشین استاندارد انجام می\u200cشوند. ما یک مجموعه عملکرد گسترده را در تنظیمات کرونل مختلف مشاهده می کنیم. در طول کشیدن نتیجه\u200cها، به ویژگی\u200cهای گسترده\u200cها نگاه می\u200cکنیم، استراتژی\u200cهای مختلف مختلف مخلوط را تحقیق می\u200cکنیم و توانایی\u200cهای مخلوط را تحقیق می\u200cکنیم.', 'tr': 'Gelişmiş vektör makineleri ve logistik yeniden greşimleri, kernel fonksiyonları (kerneler) yüksek boyutlu alanlara veri noktaları oluşturmak ve karmaşık karar sınırlarını öğrenmek kolaylaştırmak için kullanılır. Bu çalışmada, safık katmanın içindeki ürün fonksiyonunu değiştirerek, onçakly kelime klasifikasyonu için kernelerin kullanımını keşfet. Indiki kerneleri çykarmak üçin, deneyler standart dil modellendirmek we maşynyň terjime täbliklerinde çykylýar. Biz farklı kernel düzümlerinde birnäçe eserler görýäris. Netijeleri uzatlaşdyryp, gradient häsiýetlerini seredip, dürli karışyk stratejiýalaryny barlaň we çykyş ukyplaryny barlaň.', 'sw': 'Labda imetumiwa kusaidia mashine za vector na mabadiliko ya kimaadili, kazi za kerneli (kernels) inaweza kwa uhakika ramani vipengele vya taarifa katika maeneo ya juu na kufanya iwezekane kujifunza mipaka ya uamuzi magumu. Katika kazi hii, kwa kubadilisha kazi ya bidhaa ya ndani katika kiwango cha mfumo, tunachunguza matumizi ya kerneli kwa kutangaza neno la kawaida. Ili kulinganisha vifaa vya vifaa binafsi, majaribio yanafanywa kwa ajili ya mifano ya lugha ya kawaida na kazi za kutafsiri mashine. Tunaona maonyesho mengi katika mazingira mbalimbali ya viwanda. Kwa kuongeza matokeo yake, tunaangalia utaalam wa hali ya juu, tunachunguza mikakati mbalimbali ya mchanganyiko na kutathmini uwezo wa kutokuwepo kwa ubaguzi.', 'am': 'የዌር መሣሪያዎች እና የግንኙነት ግንኙነት፣ የኪርኔል функсия (kernels) የሚጠቀሙትን የዳታ እቅናቶች ወደ ከፍተኛ ስፍራዎች ማቅረብ ይችላል፡፡ In this work, by replacing the inner product function in the softmax layer, we explore the use of kernels for contextual word classification.  የአንዳንዱ የኩነቶች ክፍሎች ለማስተካከል የመድረክ ቋንቋ ምሳሌ እና የመሳሳይ ትርጉም ስራዎችን በመስመር ይደረጋል፡፡ በብዙ የኩነቶች አካባቢዎች ውስጥ ብዙ የፍለጋዎችን እናደርጋለን፡፡ ፍሬዎቹን በተጨማሪም፣ የሥርዓት ምርጫዎችን እናየዋለን፣ የተለያዩ የግንኙነት ስርዓት እናመርምር እና የግንኙነቱን ኃይል እናመርምር፡፡', 'af': "Prominent gebruik word in ondersteunde vektor masjiene en logistike hergrensies, kernel funksies (kernels) kan implisielik kaart data punte in hoë dimensie spasies en maak dit makliker om kompleks besluit grense te leer. In hierdie werk, deur die binneste produktfunksie in die softmax laag te vervang, ondersoek ons die gebruik van kernels vir contextual word klassifikasie. Om die individuele kernels te vergelyk, word eksperimente gedoen op standaard taal modeling en masjien vertaling opdragte. Ons hou 'n wyde omvang van uitvoerings oor verskillende kernelinstellings. Verlenging van die resultate, kyk ons na die gradient eienskappe, ondersoek verskillende gemengstellings en ondersoek die ontsammingskabiliteite.", 'sq': 'Duke u përdorur në mënyrë të shquar në makinat e mbështetjes të vektorëve dhe rishikimet logjistike, funksionet e bërthamës (bërthamat) mund të hartojnë implicitisht pikat e të dhënave në hapësira dimensionale të larta dhe të bëjnë më të lehtë mësimin e kufijve komplekse të vendimeve. In this work, by replacing the inner product function in the softmax layer, we explore the use of kernels for contextual word classification.  Me qëllim që të krahasohen bërthamat individuale, eksperimentet kryehen në modelimin standard të gjuhës dhe detyrat e përkthimit të makinave. Ne vëzhgojmë një gamë të gjerë shfaqjeve nëpërmjet rregullimeve të ndryshme të bërthamës. Duke zgjeruar rezultatet, ne shohim pronat e gradientit, hetojmë strategji të ndryshme përzierjesh dhe shqyrtojmë aftësitë e çambiguacionit.', 'hy': 'Առաջին հերթին օգտագործվում են վեկտորների աջակցության մեքենաներում և լոգոստիկայի վերադառնալիս, միջուկային ֆունկցիաները (միջուկները) միանգամայն կարող են քարտեզագրել տվյալների կետերը բարձր չափերի տարածքների մեջ և ավելի հեշտ դարձնել բարդ որո Այս աշխատանքի ընթացքում, փոխարինելով ներքին արտադրյալ ֆունկցիան հարթմաքսի շերտի մեջ, մենք ուսումնասիրում ենք միջուկների օգտագործումը կոնտեքստալ բառերի դասակարգման համար: Համեմատելու համար անհատական միջուկները փորձեր են կատարվում ստանդարտ լեզվի մոդելավորման և մեքենային թարգմանման խնդիրների վրա: Մենք դիտում ենք տարբեր արտադրությունների տարբեր տարբերակներ միջուկային համակարգերի միջոցով: Արդյունքները ընդլայնելով՝ մենք նայում ենք դասավորման հատկություններին, ուսումնասիրում ենք տարբեր խառնված ռազմավարությունները և ուսումնասիրում ենք բացատրելու ունակությունները:', 'az': 'Vektör makinelərini və loģistiki yenidən gresiyyətlərini dəstəkləndirmək üçün istifadə edilən məlumat noktalarını yüksək ölçülük məsafələrinə qoyub, karmaşık karar sınırlarını öyrənmək üçün asanlaşdıra bilər. Bu işdə, iç ürək funksiyasını yumuşaqlıq sütunda əvəz edərək, müxtəlif söz klasifikasyonu üçün kernelərin istifadəsini keşfetirik. Bütün kernelərin qarşılaşdırmaq üçün, təminatlar standart dil modelləri və maşın çevirilən işlərdə işlədilər. Biz müxtəlif kernel ayarlarında geniş performanslar görürük. Sonuçları genişləndirək, qrafiyat özelliklərinə baxarıq, müxtəlif karışıq stratejilərini incidirək və disambiguasyon yetkinliklərini incidirik.', 'cs': 'Jádrové funkce (jádra) jsou významně používány v podpůrných vektorových strojích a logistických reších a mohou implicitně mapovat datové body do vysoce dimenzionálních prostorů a usnadnit naučení složitých rozhodovacích hranic. V této práci nahrazením vnitřní funkce produktu ve vrstvě softmax zkoumáme využití jader pro kontextovou klasifikaci slov. Pro porovnání jednotlivých jader jsou prováděny experimenty na standardních jazykových modelováních a strojových překladech. Pozorujeme širokou škálu výkonů napříč různými nastaveními jádra. V rozšíření výsledků se podíváme na gradientové vlastnosti, zkoumáme různé strategie směsi a zkoumáme rozjasňovací schopnosti.', 'bs': 'Prominentno korišteno u podršku vektorskih strojeva i logističkih pregresija, funkcije kernel (kernels) mogu implicitno mapirati tačke podataka u visoke dimenzionalne prostore i olakšati se učiti složene granice odluke. U ovom poslu, zamjenjujući funkciju unutrašnjeg proizvoda u softmax sloju, istražujemo korištenje kernela za kontekstualnu klasifikaciju riječi. Da bi se usporedilo pojedinačni kerneli, eksperimenti su provedeni na standardnim zadatkima za modeliranje jezika i prevod mašine. Pratimo širok raspon izvoda u različitim nastavacima kernel. Proširenjem rezultata, pogledamo vlasništvo gradienta, istražujemo različite mješavine strategije i pregledamo sposobnosti disambigacije.', 'ca': "Prominently used in support vector machines and logistic re-gressions, kernel functions (kernels) can implicitly map data points into high dimensional spaces and make it easier to learn complex decision boundaries.  En aquesta obra, substituint la funció interior del producte a la capa softmax, explorem l'ús de núcles per a la classificació contextual de paraules. Per poder comparar els núcles individuals, s'experimenten en tasques de modelació de llenguatges i traducció màquina. Observem una gran varietat de performances a través de diferents configuracions del nucli. Si estendem els resultats, mirem les propietats del gradient, investigam diverses estratègies de mistura i examinem les habilitats de desambiguació.", 'bn': 'সম্ভবত ভেক্টর মেশিন এবং লোজিক্যাল পুনরায় ব্যবহার করার জন্য ব্যবহৃত, কের্নেল ফাংশন (কার্নেল) মানচিত্রের তথ্য বিন্দুক উচ্চমাত্রায় মানচিত্র এবং কঠিন সি এই কাজে, সফটম্যাক্স স্তরের ভিতরের পণ্যের ফাংশন প্রতিস্থাপনের মাধ্যমে আমরা কার্নেলের ব্যবহার খুঁজে বের করি। ব্যক্তিগত কার্নেলের তুলনা করার জন্য, স্ট্যান্ডার্ড ভাষা মডেলিং এবং মেশিন অনুবাদের কাজে পরীক্ষা করা হয়েছে। আমরা বিভিন্ন কেরেলের বৈশিষ্ট্যের বিভিন্ন প্রদর্শনের বিভিন্ন প্রদর্শন দেখি। ফলাফল বাড়িয়ে আমরা গ্রেডিয়েন্ড বৈশিষ্ট্যাবলীর দিকে তাকাই, বিভিন্ন মিশ্রিত কৌশল তদন্ত করে বিভিন্ন কৌশলের পরীক্ষা কর', 'et': 'Tugivektormasinates ja logistilistes ümberpaigutustes silmapaistvalt kasutatavad tuumafunktsioonid (tuumad) võivad kaudselt kaardistada andmepunkte kõrgemõõtmelistesse ruumidesse ja lihtsustada keerukate otsustamispiiride õppimist. Selles töös, asendades sisemise tootefunktsiooni softmax kihis, uurime tuumade kasutamist kontekstipõhiseks sõnade klassifitseerimiseks. Üksikute tuumade võrdlemiseks tehakse katseid standardsete keele modelleerimise ja masintõlke ülesannetega. Me jälgime erinevate kerneli seadete erinevaid toimivusi. Tulemuste laiendamiseks vaatame gradientide omadusi, uurime erinevaid segustrateegiaid ja uurime selgitusvõimeid.', 'fi': 'Ydintoiminnot (ytimet) voivat implisiittisesti kartoittaa datapisteitä suuriulotteisiin tiloihin ja helpottaa monimutkaisten päätösrajojen oppimista. Tässä työssä tutkitaan ytimen käyttöä kontekstuaalisessa sanaluokituksessa korvaamalla softmax-kerroksen sisäinen tuotefunktio. Yksittäisten ydinten vertailua varten tehdään kokeita kielimallinnuksen ja konekäännöksen vakiotehtävistä. Havaitsemme monenlaisia suorituksia eri ytimen asetuksissa. Laajennamme tuloksia tarkastelemme gradientin ominaisuuksia, tutkimme erilaisia sekoitusstrategioita ja selvitämme erottelukykyjä.', 'jv': 'politenessoffpolite"), and when there is a change ("assertive Slacklayer Jejaring Monday Jejaring', 'sk': 'Funkcije jedra, ki se izrazito uporabljajo v podpornih vektorskih strojih in logističnih preusmeritvah, lahko implicitno mapirajo podatkovne točke v visokodimenzionalne prostore in olajšajo učenje kompleksnih mej odločanja. V tem delu z zamenjavo notranje funkcije izdelka v sloju softmax raziskujemo uporabo jedrc za kontekstualno klasifikacijo besed. Za primerjavo posameznih jedrc so izvedeni poskusi na standardnem jezikovnem modeliranju in strojnem prevajanju. Opazujemo širok spekter učinkovitosti v različnih nastavitvah jedra. Z razširitvijo rezultatov pregledamo gradientne lastnosti, raziskujemo različne strategije mešanic in raziskujemo razločitvene sposobnosti.', 'ha': "Ana yiwuwa ana yi amfani da taimakon mashine masu sakar kwamfyuta da re-gyare masu lokaci, aiki na kernel (kernel) za'a iya iya iya amfani da shiryoyin data cikin filayen sauri na tsohon sigogi kuma ya sauƙi kwamfyuta ka karanta grensa masu adadi. Daga wannan aikin, da musanya aiki na ƙarani da ke cikin zane-zane-zane, za'a yi amfani da kernel wa fasalin kalma na takaici. To, dõmin a daidaita kayan kernel guda, za'a yi jarraba kan shirin misalin harshen na'ura da aikin fassarori masu motsi da mashine. Muna ganin wasu firawi mãsu yawa a kan kayan kernel dabam-dabam. Ga bayan matsala, sai mu dũba ga tayari na shagala, kuma mu yi ƙidãya ko-ƙulli masu haɗi da tarakiki ko kuma ka yi bincike abincin da ba'a gauraya.", 'he': 'משתמשים באופן מוקדם במכונות ויקטורים תמיכה וחזרות לוגיסטיות, פונקציות הגרעין (גרעינים) יכולות באופן מילוי למפות נקודות נתונים לחלל מימדים גבוהים ולקל יותר ללמוד גבולות החלטות מורכבות. בעבודה הזו, על ידי החלפת הפונקציה של המוצר הפנימי בשכבת softmax, אנו חוקרים את השימוש של גרעינים לסיווג מילים קונטקסטי. כדי להשוות את הגרעינים האישיים, ניסויים נעשים על מודל שפה סטנדרטי ומשימות התרגום מכונות. אנו רואים טווח רחב של הופעות ברחבי סדרות גזע שונות. מתרחבים את התוצאות, אנו מסתכלים על תכונות המדרגות, חוקרים אסטרטגיות מעורבות שונות ולבדוק את יכולות ההסבר.', 'bo': 'Prominently used in support vector machines and logistic re-gressions, kernel functions (kernels) can implicitly map data points in to high dimensional spaces and make it easier to learn complex decision boundaries. མཉེན་ཆས་ཆེ་ཤོས་ཀྱི་བང་རིམ་ནང་གི་བྱ་ཚིག་ཚབ་ཏུ་བཅུག་ནི། ལྕགས་རིས་མིན་གཅིག་གི་རྩེད་པ་དང་མཉམ་དུ་སྔོན་གྱི་སྐད་རིགས་དབྱེ་བ་དང་ལས་འགུལ་གྱི་བྱ་འགུལ་དང་། ང་ཚོས་kernel སྒྲིག་སྟངས་མ་འདྲ་བའི་གྲངས་ཚད་རྒྱ་ཚད་ལ་འཛིན་བྱེད་ཀྱི་ཡོད། ཕར་ཚུན་འབྲས་བ་མངོན་གསལ་བྱེད་སྐབས་འོང་བའི་རྒྱུ་དངོས'}
{'en': 'Generic and Specialized Word Embeddings for Multi-Domain Machine Translation', 'es': 'Incrustaciones de palabras genéricas y especializadas para la traducción automática multidominio', 'fr': 'Embeddings de mots génériques et spécialisés pour la traduction automatique multidomaine', 'ar': 'تضمين كلمة عامة ومتخصصة للترجمة الآلية متعددة المجالات', 'pt': 'Incorporações de palavras genéricas e especializadas para tradução automática de vários domínios', 'zh': '用多域机器翻译通用、专用词嵌', 'ja': 'マルチドメイン機械翻訳のための汎用的かつ特殊なWord埋め込み', 'hi': 'बहु-डोमेन मशीन अनुवाद के लिए जेनेरिक और विशेष Word एम्बेडिंग', 'ru': 'Универсальные и специализированные вставки слов для многодоменного машинного перевода', 'ga': 'Leabú Focal Cineálach agus Speisialaithe le haghaidh Aistriú Meaisín Ilfhearainn', 'ka': 'Name', 'el': 'Γενικές και εξειδικευμένες ενσωματώσεις λέξεων για μηχανική μετάφραση πολλαπλών τομέων', 'hu': 'Általános és speciális szóbeágyazások több tartományos gépi fordításhoz', 'it': 'Embedding di parole generiche e specializzate per la traduzione automatica multi-dominio', 'kk': 'Көп домен машинаның аудару үшін жалпы және ерекше сөздерді ендіру', 'lt': 'Bendras ir specializuotas žodžių įdėjimas daugiadominiam mašinų vertimui', 'mk': 'Општи и специјализирани вградувања на зборови за превод на мултидомени машини', 'ms': 'Penjelmaan Kata Generik dan Khas untuk Terjemahan Mesin Berbanyak Domain', 'ml': 'Multi- Domain Machine Translation', 'mt': 'Tagħmir ta’ kliem ġeneriku u speċjalizzat għat-traduzzjoni ta’ makkinarju b’ħafna dominji', 'mn': 'Олон домены машины хөрөнгө оруулалтын ерөнхий болон тодорхойлогдсон үг', 'no': 'Name', 'pl': 'Ogólne i specjalistyczne osadzenia słów do tłumaczenia maszynowego w wielu domenach', 'ro': 'Încorporări generice și specializate de cuvinte pentru traducerea automată pe mai multe domenii', 'sr': 'Generalni i specijalizovani integraciji reèi za prevod multidomena mašine', 'si': 'ගොඩක් ඩොමේන් මේෂින් පරිවර්තනය සඳහා සාමාන්\u200dය සහ විශේෂිත වචන සම්බන්ධය', 'so': 'Generic and Specialized Word Embeddings for Multi-Domain Machine Translation', 'sv': 'Generiska och specialiserade ordinbäddningar för maskinöversättning för flera domäner', 'ta': 'Multi- Domain Machine மொழிபெயர்ப்புக்கான பொதுவான மற்றும் குறிப்பிட்ட வார்த்தை உடைப்புகள்', 'ur': 'Multi- Domain Machine Translation', 'uz': 'Name', 'vi': 'KCharselect unicode block name', 'da': 'Generiske og specialiserede ordindlejringer til maskinoversættelse med flere domæner', 'de': 'Generische und spezialisierte Word-Einbettungen für maschinelle Übersetzung mit mehreren Domänen', 'bg': 'Генерални и специализирани словесни вграждания за многодомейнен машинен превод', 'nl': 'Generieke en gespecialiseerde Word Embeddings voor Multi-Domain Machine Translation', 'ko': '다영역 기계 번역에 사용되는 유니버설 및 전용 단어 삽입', 'id': 'Penjelmaan Kata Generik dan Spesialisasi untuk Terjemahan Mesin Multi-Domain', 'sw': 'Tafsiri za Mashine ya Kikundi', 'fa': 'Name', 'tr': 'Birnäçe-Domen Maşynyň Çevirmesi üçin Umumy we Ozip Kelimler', 'af': 'Name', 'sq': 'Generic and Specialized Word Embeddings for Multi-Domain Machine Translation', 'am': 'መግለጫ', 'hy': 'Comment', 'bs': 'Generične i specijalizirane integracije riječi za multidomenalnu prevodu mašine', 'az': '칂oxlu Domain Makinel톛rin T톛rc칲m톛si 칲칞칲n X칲susi v톛 T톛rc칲ml톛ndiril톛n S칬zl톛r 캻fad톛l톛ri', 'bn': 'বহুডোমেইন মেশিন অনুবাদের জন্য সাধারণ এবং বিশেষ শব্দের এমবেডিং', 'et': 'Üldised ja spetsialiseeritud sõnade manustamised mitme domeeni masintõlke jaoks', 'cs': 'Obecné a specializované vložení slov pro vícedoménový strojový překlad', 'ca': 'Generic and Specialized Word Embeddings for Multi-Domain Machine Translation', 'fi': 'Yleiset ja erikoistuneet sanaupotukset usean verkkotunnuksen konekääntämiseen', 'hr': 'Obične i specijalizirane integracije riječi za prevod mehaničkih domena', 'he': 'המילים המיוחדות והגנריות לתרגום מכונות רבות דומינים', 'ha': 'KCharselect unicode block name', 'jv': 'General lan Specialization', 'sk': 'Splošne in specializirane besedne vdelave za strojni prevod z več domenami', 'bo': '嘟︵荆嗉嬥綐嘟勦紜嘟嗋胶嗉嬥綎嗉嬥綐嘟氞郊嘟撪紜嘟⑧緹嘟傕溅嗉嬥綐嗉嬥剑嘟傕紜嘟傕讲嗉嬥溅嗑愢綉嗉嬥健嘟侧絺嗉嬥絾嗉嬥綋嘟勦紜嘟戉酱嗉嬥溅嗑む颈嘟侧舰嗉嬥綎嘟忇絼嗉嬥綎嗉嬥綉嘟勦紜嘟佮颈嘟戉紜嘟斷舰嗉嬥綉嘟樴讲嘟傕溅嗉嬥綘嘟涏酱嘟傕溅嗉嬥健嘟监綉嗉嬥綌'}
{'en': 'Supervised machine translation works well when the train and test data are sampled from the same distribution. When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences. We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources. Our proposal transposes to ', 'fr': "La traduction automatique supervisée fonctionne bien lorsque les données de train et de test sont échantillonnées à partir de la même distribution. Lorsque ce n'est pas le cas, les techniques d'adaptation permettent de garantir que les connaissances acquises à partir de textes hors domaine se généralisent aux phrases internes au domaine. Nous étudions ici un environnement connexe, l'adaptation multidomaine, où le nombre de domaines est potentiellement important et où s'adapter séparément à chaque domaine gaspillerait les ressources de formation. Notre proposition transpose à la traduction automatique neuronale la technique d'extension de fonctionnalités de (Daumë III, 2007)\xa0: elle isole les représentations lexicales indépendantes du domaine des représentations lexicales spécifiques au domaine, tout en partageant la plus grande partie du réseau entre les domaines. Nos expériences utilisent deux architectures et deux paires de langues\xa0: elles montrent que notre approche, bien que simple et peu coûteuse sur le plan informatique, surpasse plusieurs bases solides et fournit un système multidomaine qui traduit avec succès des textes provenant de sources diverses.", 'pt': 'A tradução automática supervisionada funciona bem quando os dados de treinamento e teste são amostrados da mesma distribuição. Quando este não é o caso, as técnicas de adaptação ajudam a garantir que o conhecimento aprendido de textos fora do domínio se generalize para frases no domínio. Estudamos aqui um cenário relacionado, adaptação multidomínio, onde o número de domínios é potencialmente grande e a adaptação separada para cada domínio desperdiçaria recursos de treinamento. Nossa proposta transpõe para a tradução automática neural a técnica de expansão de recursos de (Daumë III, 2007): ela isola as representações lexicais agnósticas de domínio das específicas de domínio, enquanto compartilha a maior parte da rede entre os domínios. Nossos experimentos usam duas arquiteturas e dois pares de idiomas: eles mostram que nossa abordagem, embora simples e computacionalmente barata, supera várias linhas de base fortes e oferece um sistema multidomínio que traduz com sucesso textos de diversas fontes.', 'ar': 'تعمل الترجمة الآلية الخاضعة للإشراف بشكل جيد عندما يتم أخذ عينات من بيانات القطار والاختبار من نفس التوزيع. عندما لا يكون الأمر كذلك ، تساعد تقنيات التكيف في ضمان أن المعرفة المستفادة من النصوص خارج المجال تعمم على الجمل الموجودة في المجال. ندرس هنا الإعداد ذي الصلة ، التكيف متعدد المجالات ، حيث يكون عدد المجالات كبيرًا ومن المحتمل أن يؤدي التكيف بشكل منفصل مع كل مجال إلى إهدار موارد التدريب. ينقل اقتراحنا إلى الترجمة الآلية العصبية تقنية توسيع الميزات (Daumë III ، 2007): فهي تعزل المجال الحيادي عن التمثيلات المعجمية الخاصة بالمجال ، بينما تشارك معظم الشبكة عبر المجالات. تستخدم تجاربنا هيكلين وأزواج لغتين: تُظهر أن نهجنا ، رغم أنه بسيط وغير مكلف من الناحية الحسابية ، يتفوق على العديد من خطوط الأساس القوية ويوفر نظامًا متعدد المجالات يترجم بنجاح النصوص من مصادر متنوعة.', 'es': 'La traducción automática supervisada funciona bien cuando se toman muestras de los datos del tren y de la prueba de la misma distribución. Cuando este no es el caso, las técnicas de adaptación ayudan a garantizar que el conocimiento aprendido de los textos fuera del dominio se generalice a las oraciones dentro del dominio. Estudiamos aquí un entorno relacionado, la adaptación multidominio, donde el número de dominios es potencialmente grande y adaptarse por separado a cada dominio desperdiciaría recursos de capacitación. Nuestra propuesta transpone a la traducción automática neuronal la técnica de expansión de funciones de (Daumë III, 2007): aísla las representaciones léxicas independientes del dominio de las específicas del dominio, al tiempo que comparte la mayor parte de la red entre dominios. Nuestros experimentos utilizan dos arquitecturas y dos combinaciones de idiomas: muestran que nuestro enfoque, si bien es simple y computacionalmente económico, supera varias líneas de base sólidas y ofrece un sistema multidominio que traduce con éxito textos de diversas fuentes.', 'hi': 'पर्यवेक्षित मशीन अनुवाद अच्छी तरह से काम करता है जब ट्रेन और परीक्षण डेटा एक ही वितरण से नमूना लिया जाता है। जब यह मामला नहीं है, तो अनुकूलन तकनीकें यह सुनिश्चित करने में मदद करती हैं कि आउट-ऑफ-डोमेन ग्रंथों से सीखा गया ज्ञान इन-डोमेन वाक्यों के लिए सामान्यीकृत हो। हम यहां एक संबंधित सेटिंग, मल्टी-डोमेन अनुकूलन का अध्ययन करते हैं, जहां डोमेन की संख्या संभावित रूप से बड़ी होती है और प्रत्येक डोमेन के लिए अलग-अलग अनुकूलन प्रशिक्षण संसाधनों को बर्बाद कर देगा। हमारा प्रस्ताव तंत्रिका मशीन अनुवाद (Daumé III, 2007) की सुविधा विस्तार तकनीक को स्थानांतरित करता है: यह डोमेन-विशिष्ट लेक्सिकल अभ्यावेदन से डोमेन-अज्ञेयवादी को अलग करता है, जबकि डोमेन में नेटवर्क के अधिकांश को साझा करता है। हमारे प्रयोग दो आर्किटेक्चर और दो भाषा जोड़े का उपयोग करते हैं: वे दिखाते हैं कि हमारा दृष्टिकोण, जबकि सरल और कम्प्यूटेशनल रूप से सस्ता है, कई मजबूत बेसलाइन को मात देता है और एक बहु-डोमेन प्रणाली प्रदान करता है जो विभिन्न स्रोतों से ग्रंथों का सफलतापूर्वक अनुवाद करता है।', 'zh': '其训练与测试数据同布采样,监督式机器翻译效甚佳。 当事不然,应术有助于域外文本中学到的知识推到域内句子。 论一相关,多领域以应之,其数可大,而独适其费培训资。 臣等议将特征广术(Daumë III,2007)移于神经机器翻译中:其将域不可知与域无关与域特定词法示隔离开,兼跨域共享大网络。 吾实验用二架构、二语:吾法虽简而计算成本低廉,性优于数强之基线,而资一多域之统,可以成异本。', 'ja': '列車と試験データが同じ分布からサンプリングされている場合、監視対象の機械翻訳はうまく機能します。そうでない場合、適応技法は、ドメイン外のテキストから学んだ知識がドメイン内の文章に一般化することを確実にするのに役立つ。ここでは、関連する設定であるマルチドメイン適応について研究しています。この設定では、ドメインの数が多い可能性があり、各ドメインに個別に適応すると、トレーニングリソースが無駄になります。私たちの提案は、（ Daumë III, 2007 ）の特徴拡張テクニックをニューラル機械翻訳に転用しています。これは、ドメイン間でネットワークの大部分を共有しながら、ドメイン固有の語彙表現からドメイン非依存を分離します。私たちの実験は、2つのアーキテクチャと2つの言語ペアを使用しています。それらは、私たちのアプローチが単純で計算的に安価である一方で、いくつかの強力なベースラインを上回り、多様なソースからテキストを正常に翻訳するマルチドメインシステムを提供することを示しています。', 'ru': 'Контролируемый машинный перевод хорошо работает, когда данные о поездах и испытаниях отбираются из одного и того же распределения. Когда это не так, методы адаптации помогают обеспечить, чтобы знания, полученные из внедоменных текстов, обобщали внутридоменные предложения. Мы изучаем здесь связанную с этим среду, многодоменную адаптацию, где количество областей потенциально велико и адаптация отдельно к каждой области приведет к пустой трате учебных ресурсов. Наше предложение переносит в нейронный машинный перевод методику расширения признаков (Daumë III, 2007): она изолирует домен-диагностику от доменно-специфических лексических представлений, в то же время деля большую часть сети между доменами. Наши эксперименты используют две архитектуры и две языковые пары: они показывают, что наш подход, хотя и прост и вычислительно недорог, превосходит несколько сильных базовых линий и обеспечивает многодоменную систему, которая успешно переводит тексты из различных источников.', 'ga': 'Oibríonn meaisínaistriúchán maoirsithe go maith nuair a dhéantar sampláil ar shonraí na traenach agus na tástála ón dáileadh céanna. Nuair nach mbíonn sé seo amhlaidh, cuidíonn teicnící oiriúnaithe lena chinntiú go ndéantar an t-eolas a fhoghlaimítear ó théacsanna lasmuigh den fhearann a ghinearálú go habairtí san fhearann. Déanaimid staidéar anseo ar shuíomh gaolmhar, oiriúnú ilfhearann, ina bhfuil líon na bhfearann a d’fhéadfadh a bheith mór agus ina gcuirfí amú acmhainní oiliúna dá ndéanfaí oiriúnú ar leithligh do gach fearann. Trasuíonn ár dtogra chuig aistriúchán meaisín néarach teicníc leathnaithe gné (Daumë III, 2007): leithlisíonn sé fearann-agnostic ó léirithe foclóireachta a bhaineann go sonrach leis an bhfearann, agus an chuid is mó den líonra á roinnt ar fud na bhfearann. Úsáideann ár dturgnaimh dhá ailtireacht agus dhá phéire teanga: léiríonn siad go sáraíonn ár gcur chuige, cé go bhfuil sé simplí agus neamhchostasach ó thaobh ríomhaireacht de, roinnt bonnlínte láidre agus go seachadann sé córas ilfhearainn a aistríonn go rathúil téacsanna ó fhoinsí éagsúla.', 'ka': 'მანქანის გადაწყვეტილება კარგი მუშაობა, როცა მონაცემები და ტესტის მონაცემები იგივე გადაწყვეტილებით გამოიყენება. როდესაც ეს არ არის შემთხვევაში, აეპტიფიკაციის ტექნოგიები დახმარება, რომ ცნობიერება, რომელიც დიომინის გარეშე ტექსტიდან ვისწავლია გენერალიზება დიომინის წეს ჩვენ აქ შევსწავლოთ შესაბამისი შესაბამისი შესაბამისი, მრავალეთ დომენის ადაპტიფიკაცია, სადაც დომენის რაოდენობა პროცენტურად დიდია და ადაპტიკაცია ყოველ დო ჩვენი წარმოდგენა ნეიროლური მაქინის გარგენისთვის ფუნქციების გარგენისთვის ტექნოგია (Daume III, 2007): ის იზოლეცია დიომინის ადნოსტიკის დიომინის განსაკუთრებული ლექსიკური გამოსახულებებიდან, როც ჩვენი ექსპერიმენტები გამოყენებს ორი აქტიქტიკური და ორი ენის ზოგები: ისინი ჩვენი მიღება, როგორც ჩვენი წარმოდგენა, როგორც მხოლოდ და კომპუტაციოლურად უფრო მუშაობელია, რამდენიმე ძალია', 'hu': 'A felügyelt gépi fordítás jól működik, ha a vonat- és tesztadatokat ugyanabból az elosztásból veszik mintába. Ha ez nem a helyzet, az adaptációs technikák segítenek biztosítani, hogy a területen kívüli szövegekből elsajátított ismeretek általánossá váljanak a területen belüli mondatokra. Itt tanulmányozunk egy kapcsolódó környezetet, több-domain adaptációt, ahol a domainek száma potenciálisan nagy, és az egyes domainekhez külön-külön alkalmazkodás pazarolja a képzési erőforrásokat. Javaslatunk (Daume III, 2007) funkcióbővítési technikáját átülteti a neurális gépi fordításra: a domain-agnosztikust elszigeteli a domain-specifikus lexikai reprezentációktól, miközben a hálózat nagy részét domainek között osztja meg. Kísérleteink két architektúrát és két nyelvpárt alkalmaznak: azt mutatják, hogy a megközelítésünk, bár egyszerű és számítástechnikailag olcsó, több erős alapvonalat is felülmúlja, és olyan több domain rendszert biztosít, amely sikeresen fordítja le a különböző forrásokból származó szövegeket.', 'el': 'Η εποπτευόμενη μηχανική μετάφραση λειτουργεί καλά όταν τα δεδομένα αμαξοστοιχίας και δοκιμής λαμβάνονται από την ίδια διανομή. Όταν αυτό δεν συμβαίνει, οι τεχνικές προσαρμογής βοηθούν να διασφαλίσουν ότι η γνώση που αποκτάται από κείμενα εκτός πεδίου γενικεύεται σε προτάσεις εντός πεδίου. Μελετάμε εδώ ένα σχετικό περιβάλλον, την προσαρμογή πολλαπλών τομέων, όπου ο αριθμός των τομέων είναι δυνητικά μεγάλος και η προσαρμογή ξεχωριστά σε κάθε τομέα θα σπαταλούσε πόρους κατάρτισης. Η πρότασή μας μεταφέρει στην νευρωνική μηχανική μετάφραση την τεχνική επέκτασης χαρακτηριστικών του (Δάμ ΙΙΙ, 2007): απομονώνει την αγνωστική περιοχή από τις λεξικές αναπαραστάσεις του τομέα, ενώ μοιράζεται το μεγαλύτερο μέρος του δικτύου μεταξύ των τομέων. Τα πειράματά μας χρησιμοποιούν δύο αρχιτεκτονικές και δύο γλωσσικά ζεύγη: δείχνουν ότι η προσέγγισή μας, ενώ είναι απλή και υπολογιστικά φθηνή, ξεπερνά αρκετές ισχυρές γραμμές βάσης και παραδίδει ένα σύστημα πολλαπλών τομέων που μεταφράζει με επιτυχία κείμενα από διαφορετικές πηγές.', 'it': 'La traduzione automatica supervisionata funziona bene quando i dati del treno e dei test vengono campionati dalla stessa distribuzione. Quando questo non è il caso, le tecniche di adattamento aiutano a garantire che le conoscenze apprese dai testi fuori dominio si generalizzino alle frasi in-dominio. Studiamo qui un ambiente correlato, adattamento multi-dominio, dove il numero di domini è potenzialmente grande e adattandosi separatamente a ciascun dominio sprecherebbe risorse di formazione. La nostra proposta traspone alla traduzione automatica neurale la tecnica di espansione delle funzionalità di (Daume III, 2007): isola il dominio-agnostico dalle rappresentazioni lessicali specifiche del dominio, condividendo la maggior parte della rete tra domini. I nostri esperimenti utilizzano due architetture e due coppie linguistiche: dimostrano che il nostro approccio, pur essendo semplice e computazionale economico, supera diverse linee di base forti e fornisce un sistema multi-dominio che traduce con successo testi provenienti da fonti diverse.', 'kk': 'Қолданатын компьютердің аудармасы бір үлестірімінен үлгілегенде жұмыс істейді. Бұл болмаса, адаптациялау техникалары домен мәтіндерінен білім берілген мәтіндерді домен сөйлемелеріне жалпы түрлендіру үшін көмектеседі. Мұнда біз бірнеше доменге қатысты баптау, көп домендің адаптациясын зерттейміз. Ол домендің саны мүмкін үлкен және әрбір доменге бөлек адаптациялау ресурстарын жоғалтыр Біздің ұсынысымыз невралдық компьютердің аудармасына (III күні, 2007 жылы) кеңейту техникасын аударады: ол доменге ерекше лексикалық кеңейтулерден доменге аударады, ол домендердің ең көпшілігін ортақтастырады. Біздің тәжірибеміз екі архитектура мен екі тіл екі қос қолданылады: олар біздің тәжірибемізді көрсетеді, бірақ қарапайым және компьютерлік түсінбейтін, бірнеше күшті негізгі сызықтарды жұмыс істейді, бірнеше көп', 'lt': 'Stebimas mašinų vertimas gerai veikia, kai traukinio ir bandymų duomenys imami iš tos pačios paskirstymo. Jei taip nėra, pritaikymo metodai padeda užtikrinti, kad žinios, įgytos iš ne srities tekstų, būtų generalizuotos į srities sakinius. Čia mes tiriame susijusią aplinką, daugiadominį pritaikymą, kur sričių skaičius gali būti didelis ir atskirai pritaikymas prie kiekvienos sričės prarastų mokymo išteklius. Mūsų pasiūlymu į neurologinį mašinų vertimą perkeliama (Daume III, 2007 m.): jis izoliuoja dominio agnostiką nuo dominio specifinių leksinių rodmenų, o dauguma tinklo dalijasi įvairiose srityse. Mūsų eksperimentuose naudojamos dvi architektūros ir dvi kalbų poros: jos rodo, kad mūsų požiūris, nors paprastas ir skaičiavimo požiūriu brangus, viršija kelias tvirtas bazines linijas ir sukuria daugiadominę sistemą, kuri sėkmingai verta tekstus iš įvairių šaltinių.', 'mk': 'Супервизираниот машински превод функционира добро кога податоците од возот и тестот се примеруваат од истата дистрибуција. Кога ова не е случајот, техниките на адаптација помагаат да се осигура дека знаењето научено од текстите надвор од домен се генерализира до речениците во домен. Тука студираме поврзано поставување, мултидомени адаптација, каде бројот на домени е потенцијално голем и адаптација одделно на секој домен би трошела ресурси за обука. Нашиот предлог ја транспортира техниката за проширување на функциите на (Daume III, 2007): изолира домен-агностик од лексикални претставувања специфични за домен, додека дели најголем дел од мрежата низ домени. Нашите експерименти користат две архитектури и два пара јазици: тие покажуваат дека нашиот пристап, иако едноставен и компјутационално нескап, ги надминува неколку силни основни линии и обезбедува мултидомен систем кој успешно преведува тексти од различни извори.', 'ms': 'Terjemahan mesin yang diawasi berfungsi dengan baik apabila data kereta api dan ujian dicampur dari distribusi yang sama. Apabila ini bukan kes, teknik penyesuaian membantu memastikan pengetahuan yang dipelajari dari teks luar domain menyebarkan kepada kalimat dalam domain. Kami belajar di sini tetapan berkaitan, penyesuaian multi-domain, di mana bilangan domain adalah potensi besar dan menyesuaikan secara terpisah kepada setiap domain akan membuang sumber latihan. cadangan kami menerjemahkan ke mesin saraf teknik pengembangan ciri (Daume III, 2007): ia mengisolasi domain-agnostic dari perwakilan leksikal spesifik domain, sementara berkongsi kebanyakan rangkaian melalui domain. Eksperimen kami menggunakan dua arkitektur dan dua pasangan bahasa: mereka menunjukkan bahawa pendekatan kita, walaupun sederhana dan secara komputasi tidak mahal, melampaui beberapa garis dasar yang kuat dan menyediakan sistem berbilang-domain yang berjaya menerjemahkan teks dari sumber berbeza.', 'ml': 'ട്രെയിനും പരീക്ഷണവിവരങ്ങളും ഒരേ വിതരണത്തില്\u200d നിന്നും ഉപയോഗിക്കപ്പെടുമ്പോള്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തിയ ഇതൊന്നുമല്ലെങ്കില്\u200d ഡോംമെയിന്\u200d ടെക്സ്റ്റുകളില്\u200d നിന്നും പഠിച്ച അറിവുകള്\u200d ഡൊമൈന്\u200d വാക്കുകളിലേക്ക് ജനറല്\u200d ചെയ്യുന്നു. We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources.  നമ്മുടെ പ്രൊദ്ദേശിപ്പ് ന്യൂറല്\u200d യന്ത്രം പരിഭാഷപ്പെടുത്തുന്നത് (ഡെയൂ III, 2007): അത് ഡൊമെയിനില്\u200d നിന്നും പ്രത്യേകിച്ച ലെക്സിക്കല്\u200d പ്രതിനിധികളില്\u200d നിന നമ്മുടെ പരീക്ഷണങ്ങള്\u200d രണ്ടു ആര്\u200dക്കിട്ടറികളെയും രണ്ടു ഭാഷ ജോടികളെയും ഉപയോഗിക്കുന്നു: നമ്മുടെ നടപടികള്\u200d കാണിക്കുന്നു, എളുപ്പമുള്ള, കണക്കിട്ടില്ലാത്തതും, കുറ', 'mn': 'Төв болон шалгалт өгөгдлийг ижил хуваалцааны шалгалтын үед ажилладаг. Хэрвээ ингэж биш бол, адилтгалын техник нь мэдлэгийг холбооны биеээс суралцаж байгаа мэдлэгийг холбооны өгүүлбэрээс ерөнхийлөгч болдог гэдгийг баталдаг. Бид энд холбоотой олон хэмжээний адилтгалыг судалж байна. Эдгээр хэмжээний тоо том бөгөөд хүрээлэн бусад хүрээлэн бусад хүрээлэн буй хүрээлэн буй хүрээлэн буй хүрээлэн буй хүрээлэн буй хүрээл Бидний санал бол мэдрэлийн машины хөгжлийн техник (Daume III, 2007) гэх мэт шинжлэх ухаан юм. Энэ нь холбооны хэлбэрээс агностик холбоотой хэлбэрээс холбогдож байна. Бидний туршилтууд хоёр архитектур, хоёр хэл хоёрыг хэрэглэдэг. Тэд бидний архитектурыг харуулж байна. Гэхдээ энгийн, тооцоололтоор тооцоолж чаддаггүй, олон хүчтэй суурь шугам гаргаж, олон төрлийн системийг олон эх үүсвэрээс амжилттай орчуулдаг', 'mt': 'Supervised machine translation works well when the train and test data are sampled from the same distribution.  Meta dan ma jkunx il-każ, it-tekniki ta’ adattament jgħinu biex jiżguraw li l-għarfien imgħallem minn testi barra d-dominju jiġġeneralizza għal sentenzi f’dominju. Hawnhekk nistudjaw ambjent relatat, adattament f’diversi dominji, fejn in-numru ta’ dominji huwa potenzjalment kbir u l-adattament separat għal kull dominju jiskadi r-riżorsi tat-taħriġ. Il-proposta tagħna tittrasponi għat-traduzzjoni tal-magni newrali t-teknika ta’ espansjoni tal-karatteristiċi ta’ (Daume III, 2007): iżolat id-dominju-agnostiku minn rappreżentazzjonijiet lexiċi speċifiċi għad-dominju, filwaqt li taqsam l-biċċa l-kbira tan-netwerk madwar id-dominji. L-esperimenti tagħna jużaw żewġ arkitetturi u żewġ pari lingwistiċi: juru li l-approċċ tagħna, filwaqt li huwa sempliċi u mhux għali b’mod komputattiv, jaqbeż diversi linji bażi b’saħħithom u jipprovdi sistema multidomestika li tittraduċi b’suċċess testi minn sorsi differenti.', 'sr': 'Nadzorni prevod mašine dobro funkcioniše kada se podaci vlaka i testa uzorke iz iste distribucije. Kada to nije slučaj, tehnike adaptacije pomognu osigurati da znanje naučeno iz teksta izvan domena generalizuje na rečenice u domenu. Ovdje proučavamo povezane postavke, multidomenalne adaptacije, gde je broj domenata potencijalno velika i prilagođenje odvojeno svakoj domenu potrošilo bi resurse obuke. Naš prijedlog transponiše u neuronski prevod tehnike proširenja karakteristike (Daume III, 2007): izolira agnostik domena iz specifičnih leksičkih predstavljanja domena, dok deli većinu mreže preko domena. Naši eksperimenti koriste dve arhitekture i dve jezičke pare: pokazuju da naš pristup, dok je jednostavan i računalno nepošteni, iznosi nekoliko jakih osnovnih linija i dostavlja multidomenički sistem koji uspešno prevodi tekste iz različitih izvora.', 'pl': 'Nadzorowane tłumaczenie maszynowe działa dobrze, gdy dane pociągu i testów są pobierane z tej samej dystrybucji. Jeśli tak nie jest, techniki adaptacyjne pomagają zapewnić, że wiedza zdobyta z tekstów poza domeną uogólnia się na zdania wewnątrz domeny. Badamy tutaj powiązane ustawienia, adaptację wielododomenową, w którym liczba domen jest potencjalnie duża, a dostosowanie się oddzielnie do każdej dziedziny zmarnowałoby zasoby szkoleniowe. Nasza propozycja transponuje do neuronowego tłumaczenia maszynowego technikę rozszerzania cech (Daume III, 2007): izoluje agnostykę domeny od specyficznych reprezentacji leksykalnych dla domeny, jednocześnie dzieląc się większą częścią sieci między domenami. Nasze eksperymenty wykorzystują dwie architektury i dwie pary językowe: pokazują, że nasze podejście, choć proste i niedrogie obliczeniowe, przewyższa kilka silnych linii bazowych i zapewnia system wielododomenowy, który z powodzeniem tłumaczy teksty z różnych źródeł.', 'ro': 'Traducerea automată supravegheată funcționează bine atunci când datele trenului și testelor sunt eșantionate din aceeași distribuție. Atunci când acest lucru nu este cazul, tehnicile de adaptare contribuie la asigurarea faptului că cunoștințele învățate din textele din afara domeniului se generalizează la propoziții din domeniu. Studiem aici un cadru conex, adaptarea multi-domeniu, unde numărul de domenii este potențial mare și adaptarea separat la fiecare domeniu ar risipi resurse de formare. Propunerea noastră transpune în traducerea automată neurală tehnica de extindere a caracteristicilor (Daume III, 2007): izolează agnosticul domeniului de reprezentările lexicale specifice domeniului, împărtășind în același timp cea mai mare parte a rețelei pe domenii. Experimentele noastre folosesc două arhitecturi și două perechi de limbi: ele arată că abordarea noastră, deși simplă și ieftină din punct de vedere computațional, depășește mai multe linii de bază puternice și oferă un sistem multi-domeniu care traduce cu succes texte din diverse surse.', 'no': 'Overvakt maskinsomsetjing fungerer godt når togen og test data vert utvala frå same distribusjon. Når dette ikkje er tilfellet, hjelper adaptasjonssteknikke å sikre at kunnskapen lærte frå ekstra domenetekstar generelliserer til i domenesetningar. Vi studerer her eit relatert innstilling, fleire domene-tilpassing, der antallet domene er potensielt stor og tilpassar separe til kvar domene vil avslutta opplæringsressursar. Vårt forslag transposerer til neuralmaskineomsetjinga funksjonen for utvidingsteknikken (Daume III, 2007): Det isolerer domeneagnostisk frå domenespesifikke leksiske representasjonar, medan dei fleste av nettverket deler over domene. Eksperimentane våre brukar to arkitektur og to språkparar: dei viser at tilnærminga vårt, mens enkelt og datamaskin utviklar fleire sterke baselinjer og leverer ein multidomenesystem som fullførleg oversetter tekstar frå ulike kilder.', 'si': 'පරීක්ෂා කරලා තියෙන්නේ පරීක්ෂණය සහ පරීක්ෂණය දත්ත එකම විතරයෙන් සැමැල් කරලා හොඳයි. මේක සැකසුම් නෙමෙයි නම්, සැකසුම් තාක්ෂණය උදව් කරන්න පුළුවන් විදිහට පරීක්ෂණය සඳහා දැනගන්න පුළුවන් පුළු අපි මෙතන සම්බන්ධ සැකසුම් සඳහා ගොඩක් ඩොමේන් සැකසුම් සම්බන්ධ වෙනුවෙන් ඉගෙන ගත්තා, කොහෙද සැකසුම් සැකසුම් ලො අපේ ප්\u200dරතිචාරය ප්\u200dරතිචාරය න්\u200dයූරාල් මැෂින් පරිවර්තනයට ප්\u200dරතිචාරය (Daume III, 2007): ඒක ප්\u200dරතිචාරය ප්\u200dරතිචාරයෙන් ඩෝමින් විශේෂ ලෙක් අපේ පරීක්ෂණය දෙකක් සහ භාෂාව දෙකක් භාවිතා කරනවා: ඔවුන් පෙන්වන්නේ අපේ ප්\u200dරවේශය, සරල සහ පරිගණික විශේෂයෙන් නැති විදියට, ශක්තිමත් පද්ධත', 'so': 'Turjumista mashiinka ee la ilaaliyo wuxuu si wanaagsan u shaqeeyaa marka lagu sameynayo waxbarashada iyo imtixaanka isku mid ah. Marka aysan saas ahayn, qaababka beddelka ayaa ka caawinaya in aqoontu ay ka bartay qoraalada gudaha laga soo baxo uu soo bandhigaa maxkamada gudaha. Halkan waxaynu ku baranaynaa qoraal la xiriira, hab-bedelka deegaanka oo kala duduwan, meesha ay tirada degmooyinku u tahay mid aad u weyn oo si gaar ah u beddelaysa dowlad walba waxay kharribi kartaa hantida waxbarashada. Isu’aankeenna wuxuu u wareejiyaa tarjumaadka neural machine-neural ah (Dalum III, 2007): wuxuu gooni uga soocaa domain-agnostik si gaar ah looga wadaa shabakadda ugu badan ee domain-agnostika. Imtixaanadayadu waxay isticmaalaan laba meelood oo arkin iyo labo luqad ah: waxay muujiyaan in dhaqdhaqaaqyadeenu ay si fudud u leedahay iyo xisaabta aan hawlgab lahayn, waxay samaysaa saldhigyo badan oo xoog badan iyo waxay samaysataa nidaam badan oo ku liibaan inay qoraalo ka tarjumaan sourceoyin kala duduwan.', 'sv': 'Övervakad maskinöversättning fungerar bra när tåg- och testdata tas från samma distribution. När så inte är fallet bidrar anpassningstekniker till att den kunskap som lärts från texter utanför domänen generaliserar till meningar inom domänen. Vi studerar här en relaterad miljö, multi-domain anpassning, där antalet domäner potentiellt är stort och att anpassa sig separat till varje domän skulle slösa utbildningsresurser. Vårt förslag överför till neural maskinöversättning funktionsexpansionstekniken i (Daume III, 2007): det isolerar domänagnostik från domänspecifika lexikala representationer, samtidigt som det delar det mesta av nätverket över domäner. Våra experiment använder två arkitekturer och två språkpar: de visar att vårt tillvägagångssätt, även om det är enkelt och beräkningsmässigt billigt, överträffar flera starka baslinjer och levererar ett flerdomänsystem som framgångsrikt översätter texter från olika källor.', 'ta': 'பயிற்சி மற்றும் சோதனை தகவல் மாதிரியும் போது மாற்றப்பட்ட இயந்திர மொழிபெயர்ப்பு நன்றாக செயல்படுகிறது. இது நிகழ்ச்சியாக இல்லையென்றால், மாற்றுதல் தொழில்நுட்பத்திற்கு உதவி அறிவு வெளியேற்றப்பட்டுள்ள உரைகளிலிருந்து அறிவு பொத நாம் இங்கே தொடர்புடைய அமைப்புகளை படிக்கிறோம், பல- டோமைன் ஒதுக்குப்பொருள், அங்கு உள்ளமைப்புகளின் எண்ணிக்கை பெரிய மற்றும் தனி எங்கள் பரிந்துரையை புதிய இயந்திரத்திற்கு மொழிபெயர்ப்பு செல்கிறது (டெம் III, 2007): அது களம் குறிப்பிட்ட லெக்சிக்சிக் குறிப்பிட்ட பிரதிப்புகளிலிருந்த எங்கள் சோதனைகள் இரண்டு அட்டவணைகளையும் இரண்டு மொழி ஜோடிகளையும் பயன்படுத்துகின்றன: எங்கள் வழிமுறையையும் எளிதாகவும் கணக்கிலும் இல்லாமலும் காட்டுகின்றன, பல வலிமையான', 'ur': 'جب ٹرین اور ٹیسٹ ڈیٹے ایک ہی تقسیم سے نمونے لگائے جائیں گے۔ جب یہ بات نہیں ہوتی، اضافہ تکنیکیاں مطمئن ہوتی ہیں کہ علم ڈومین کے خارج سے سیکھا گیا ہے، ڈومین کے جماعتوں تک عمومی کرتی ہے. ہم یہاں ایک رابطہ دار تنظیم کی تعلیم کریں گے، بہت سی ڈومین کی تعلیم، جہاں ڈومین کی تعداد بڑی ہے اور ہر ڈومین کے ساتھ مختلف طریقے سے اضافہ کریں گے، ٹرینگ سروسیلوں کو ضائع کریں گے ہماری پیشنهاد نیورل ماشین کی ترجمہ پر تغییر دیتا ہے (دائم III، 2007): یہ ڈومین کے مطابق مخصوص لکسیکل روشنی سے ڈومین کے سب سے زیادہ نیٹ ورک کا تقسیم کرتا ہے۔ ہماری آزمائش دو معماری اور دو زبان جوڑوں کو استعمال کرتی ہیں: وہ دکھاتے ہیں کہ ہماری طریقہ، حالانکہ ساده اور کمپیوٹریشن طور پر غیر منفی ہے، بہت سی قوت بنسٹ لینوں سے زیادہ مطابق کرتا ہے اور ایک بہت سی ڈومین سیسٹم کو پہنچاتا ہے جو متفرق مختل', 'uz': "Name Agar belgilansa, tahrirlash teknologiyani domen matnlaridan olingan maʼlumot domen maxfiy soʻzlariga generalisadi. Biz bu yerda bir xil domen adaptarini o'rganamiz, bu yerda domen sonlarining soni juda katta va har bir domen uchun alohida o'zgarishni o'rganamiz. Бизнинг суҳбатларимиз қонун мошини таркиб қилиш имкониятини таркиб қилиш (3. ден, 2007) учун тарқатилади: у дойн-agnostikни махсус кўриниш аъзолари ичидан ажратиб чиқади, аммо дойни маълумотларнинг энг катта таркиб компонентни бутунлай ажратиб чиқади. Bizning imtiyozlarimiz ikkita arkitekalarni va ikkita tilni qo'llashdan foydalanadi: ular bizning imkoniyatlarimizni ko'pchilik va kompyuterni juda qulay asboblarni bajaradi va muvaffaqiyatli tarjima qiladigan ko'plab domen tizimni boshqa manbalar tomonidan tarjima qiladi.", 'vi': 'Việc dịch chuyển máy giám sát hoạt động tốt khi mẫu tàu và dữ liệu thử được lấy từ cùng một bộ phân phối. Khi không phải vậy, kỹ thuật sửa chữa giúp đảm bảo kiến thức được học từ các văn bản ngoài lĩnh vực sẽ phổ biến thành câu trong miền. Chúng tôi nghiên cứu ở đây một thiết lập liên quan, sắp xếp nhiều lĩnh vực, nơi có khả năng nhiều khu vực lớn hơn và mỗi khu vực thích ứng riêng sẽ lãng phí nguồn lực đào tạo. Đề nghị của chúng tôi chuyển sang dịch thiết bị thần kinh qua dịch thuật mở rộng đặc tính của (Daume III, Phím: nó cách ly miền-agnostic từ các biểu tượng ngôn ngữ cụ miền, trong khi chia sẻ hầu hết mạng cho mỗi miền. Những thử nghiệm của chúng ta sử dụng hai kiến trúc và hai cặp ngôn ngữ: chúng cho thấy phương pháp đơn giản và tính toán rẻ hơn hoàn thành nhiều bản nền vững chắc và cung cấp một hệ thống đa miền có thành công chuyển văn bản từ nhiều nguồn khác nhau.', 'hr': 'Nadzorni prevod stroja dobro funkcionira kada se podaci vlaka i testa uzorke iz iste distribucije. Kada to nije slučaj, tehnike prilagodbe pomažu osigurati da znanje koje su naučene iz teksta izvan domena generalizira na kazne u domenu. Ovdje proučavamo povezane postavke, multidomenalne adaptacije, gdje je broj domena potencijalno velika i prilagođenje odvojeno za svaku domenu otpadalo bi resurse obuke. Naš prijedlog transponira neuronskom prevodu tehniku proširenja funkcija (Daume III, 2007): izolira agnostičku domenu iz specifičnih leksičkih predstavljanja domena, dok dijeli većinu mreže preko domena. Naši eksperimenti koriste dvije arhitekture i dvije jezičke pare: pokazuju da naš pristup, dok je jednostavan i računalno nepoštovan, iznosi nekoliko jakih osnovnih linija i dostavlja multidomenički sustav koji uspješno prevodi tekste iz različitih izvora.', 'da': 'Overvåget maskinoversættelse fungerer godt, når tog- og testdata udtages fra samme distribution. Når dette ikke er tilfældet, hjælper tilpasningsteknikker med at sikre, at den viden, der læres fra uden for domænet tekster, generaliseres til domænet sætninger. Vi studerer her en relateret ramme, multi-domæne tilpasning, hvor antallet af domæner potentielt er stort og tilpasning separat til hvert domæne ville spilde uddannelsesressourcer. Vores forslag transponerer funktionsudvidelsesteknikken (Daume III, 2007) til neural maskinoversættelse: det isolerer domæneagnostik fra domænespecifikke leksikalske repræsentationer, mens det deler det meste af netværket på tværs af domæner. Vores eksperimenter bruger to arkitekturer og to sprogpar: De viser, at vores tilgang, selv om den er enkel og beregningsmæssigt billig, overgår flere stærke basislinjer og leverer et multi-domænesystem, der med succes oversætter tekster fra forskellige kilder.', 'nl': 'Onder toezicht staande machinevertaling werkt goed wanneer trein- en testgegevens uit dezelfde distributie worden bemonsterd. Wanneer dit niet het geval is, helpen aanpassingstechnieken ervoor te zorgen dat de kennis die wordt geleerd uit out-of-domain teksten generaliseert naar in-domain zinnen. We bestuderen hier een verwante setting, multi-domein aanpassing, waarbij het aantal domeinen potentieel groot is en het afzonderlijk aanpassen aan elk domein trainingsmiddelen zou verspillen. Ons voorstel transponeert naar neurale machinevertaling de feature expansie techniek van (Daume III, 2007): het isoleert domein-agnostisch van domein-specifieke lexicale representaties, terwijl het grootste deel van het netwerk over domeinen wordt gedeeld. Onze experimenten maken gebruik van twee architecturen en twee taalparen: ze tonen aan dat onze aanpak, hoewel eenvoudig en rekenkundig goedkoop, meerdere sterke basislijnen overtreft en een multi-domein systeem levert dat met succes teksten uit verschillende bronnen vertaalt.', 'bg': 'Надзорният машинен превод работи добре, когато данните от влака и теста се вземат от едно и също разпределение. Когато това не е така, техниките за адаптация помагат да се гарантира, че знанията, придобити от текстове извън домейна, се обобщават до изречения в домейна. Тук изучаваме една свързана обстановка, многодомейнна адаптация, където броят на домейните е потенциално голям и адаптирането отделно към всяка област би пропиляло ресурсите за обучение. Нашето предложение транспонира в невронния машинен превод техниката за разширяване на характеристиките на (Даум III, 2007): тя изолира домейн-агностика от домейн-специфични лексикални представи, като същевременно споделя по-голямата част от мрежата между домейните. Нашите експерименти използват две архитектури и две езикови двойки: те показват, че нашият подход, макар и прост и изчислителен евтин, превъзхожда няколко силни базови линии и осигурява многодомейнна система, която успешно превежда текстове от различни източници.', 'de': 'Die überwachte maschinelle Übersetzung funktioniert gut, wenn Zug- und Testdaten aus derselben Verteilung entnommen werden. Wenn dies nicht der Fall ist, helfen Anpassungstechniken sicherzustellen, dass das Wissen aus fremden Texten zu In-Domain-Sätzen verallgemeinert wird. Wir untersuchen hier ein verwandtes Setting, Multi-Domain Adaption, bei dem die Anzahl der Domänen potenziell groß ist und eine separate Anpassung an jede Domäne Schulungsressourcen verschwenden würde. Unser Vorschlag transponiert auf neuronale maschinelle Übersetzung die Feature Expansion Technik von (Daume III, 2007): Es isoliert domänennagnostische von domänenspezifischen lexikalischen Repräsentationen und teilt den größten Teil des Netzwerks domänenübergreifend. Unsere Experimente verwenden zwei Architekturen und zwei Sprachpaare: Sie zeigen, dass unser Ansatz, obwohl einfach und rechnerisch günstig, mehrere starke Grundlinien übertrifft und ein Multi-Domain-System liefert, das Texte aus verschiedenen Quellen erfolgreich übersetzt.', 'sw': 'Tafsiri ya mashine zilizotajwa inafanya kazi vizuri pale treni na taarifa za jaribio zinapofanikiwa kutokana na usambazaji huo. Wakati hili si suala hili, mbinu za kuboresha zinasaidia kuhakikisha kwamba maarifa yanayojifunza kutokana na maandishi ya ndani yanajumuisha hukumu za ndani. Tunafuatilia hapa mazingira yanayohusiana, mabadiliko ya ndani mbalimbali, ambapo idadi ya maeneo yanawezekana kuwa makubwa na kubadilisha kwa kila ndani itapoteza rasilimali za mafunzo. pendekezo letu linasafiria kutafsiri teknolojia ya kuongezeka kwa mashine ya ubongo (tarehe III, 2007): inatenga mkono wa ndani kutoka kwa uwakilishi maalum wa lexico, wakati wakishirikisha mtandao wa intaneti zaidi katika maeneo mbalimbali. Majaribio yetu yanatumia majengo mawili na wawili wa lugha mbili: wanaonyesha kwamba mbinu yetu, wakati ambapo ni rahisi na kwa hisabati zisizo na uwezo, hufanya misingi kadhaa yenye nguvu na hutoa mfumo wa ndani mbalimbali ambao hutafsiri maandishi kutoka vyanzo mbalimbali.', 'fa': 'زمانی که داده های قطار و آزمایش از یک توزیع نمونه\u200cهای مشابه می\u200cشوند، ترجمه ماشین تحت نظر خوب کار می\u200cکند. وقتی این موضوع نیست، تکنیک تغییرات کمک می\u200cکنند تا مطمئن شوند که علم از متن های خارج از دامنه یاد گرفته شده به جمله های خارج از دامنه است. ما در اینجا یک تنظیم رابطه با تعداد بسیاری از دومین\u200cها را مطالعه می\u200cکنیم که تعداد دومین\u200cها احتمالاً بزرگ و متفاوت جدا به هر دومین\u200cها منابع آموزش را تباه می\u200cکند. پیشنهاد ما به ترجمه ماشین عصبی تکنیک گسترش ویژگی (دام III، ۲۰۰۷) ترجمه می\u200cکند: آن دومین-agnostic را از نمایش\u200cهای زبانی ویژه\u200cای ویژه\u200cای جدا می\u200cکند، در حالی که بیشترین شبکه را در دومین\u200cها تقسیم می\u200cکند. آزمایشات ما از دو معماری و دو جفت زبان استفاده می کنند: آنها نشان می دهند که دستور ما، در حالی که به طور ساده و کامپیوتر غیر گسترده، چند خط بنیادی قوی را انجام می دهد و سیستم زیادی از دومین را تحویل می دهد که به موفقیت متن را از منابع مختلف ترجمه می کند.', 'ko': '같은 기계에서 온 테스트 데이터와 번역 데이터가 같은 기계에서 좋은 샘플링을 할 때.상황이 그렇지 않을 때 적응 기술은 역외 텍스트에서 배운 지식을 역내 문장으로 확대하는 데 도움이 된다.우리는 여기서 관련 환경, 즉 여러 분야의 적응을 연구한다. 그 중에서 분야의 수량이 매우 많고 각 분야에 단독으로 적응하면 교육 자원을 낭비할 수 있다.우리의 건의는 (Daume III, 2007)의 특징 확장 기술을 신경기계 번역으로 전환한다. 분야가 알 수 없는 것과 분야가 특정한 어휘를 표시하는 것을 분리하고 분야를 뛰어넘어 대부분의 네트워크를 공유하는 것이다.우리의 실험은 두 가지 체계 구조와 두 가지 언어를 사용했다. 그것은 우리의 방법이 간단하고 계산 원가가 저렴하지만 몇 개의 강력한 기준선보다 우수하다는 것을 보여 주었고, 서로 다른 출처에서 온 텍스트를 성공적으로 번역할 수 있는 다역 시스템을 제공했다.', 'id': 'Terjemahan mesin yang diawasi bekerja dengan baik ketika data kereta dan tes dicampur dari distribusi yang sama. When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences.  We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources.  Our proposal transposes to neural machine translation the feature expansion technique of (Daume III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains.  Eksperimen kami menggunakan dua arsitektur dan dua pasangan bahasa: mereka menunjukkan bahwa pendekatan kita, sementara sederhana dan secara komputasional tidak mahal, melampaui beberapa garis dasar yang kuat dan menyediakan sistem multi-domain yang berhasil menerjemahkan teks dari berbagai sumber.', 'tr': 'Otly we testiň maglumaty bir daýratypdan örän gözle işleýär. Bu durum değildiğinde, adaptasyon teknolojileri, domuz dışında öğrenilen bilgilerin domuz sözlerine geliştirmesini sağlayar. Biz bu ýerde birnäçe domenyň esasy uly we bölegi bilen a ýratyn bir düzenleme, birnäçe domenyň adaptasiýasyny öwrenip otyrýarys. Bizim teklifimiz näyral maşynyň terjimesine (Daume III, 2007): Aýry köp şebekedeniň iň köpüsini domain-agnostik dilinden bölýär. Biziň deneylerimiz iki arhitektura we iki dil çiftini ulanýarlar: olar biziň ýaryşymyzy görkezýärler, we esasy we kalkularymyzdan boşluksuz bolsa, birnäçe güýçli baseliniň üstüne ýok bolup, we dürli çeşmelerden metinleri üstüne terjime eden bir multi-domeniň sistemasyny üýtged', 'af': "Ondersoektog masjien vertaling werk goed wanneer die trein en toets data vertoon word van dieselfde verspreiding. Wanneer dit nie die geval is nie, help aanpassingsteknike bevestig dat die kennis geleer van uit-domein-teks genereliseer na in-domein-teikens. Ons studeer hier 'n verwante instelling, multidomein-aanpassing, waar die nommer van domeine is potensieel groot en aanpassing aparte na elke domein sal onderwerp hulpbronne. Ons voorstel transposeer na neurale masjien vertaling die funksie uitbreidingstekniks van (Daume III, 2007): dit isolateer domein-agnostik van domein-spesifieke leksiese voorstellings, terwyl die meeste van die netwerk oor domeine deel. Ons eksperimente gebruik twee arkitektuur en twee taal paar: hulle vertoon dat ons toegang, terwyl eenvoudig en rekenaar onekspensief, verskeie sterke basisline uitvoer en 'n multidomein stelsel verdra wat suksesvol teks vertaling van verskeie bronne.", 'sq': 'Supervised machine translation works well when the train and test data are sampled from the same distribution.  When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences.  We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources.  Our proposal transposes to neural machine translation the feature expansion technique of (Daume III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains.  Eksperimentet tona përdorin dy arkitektura dhe dy çifte gjuhësh: ato tregojnë se qasja jonë, ndërsa e thjeshtë dhe e papërkushtueshme në llogari, kalon disa linja bazë të forta dhe ofron një sistem shumëdomenik që përkthen me sukses tekstet nga burime të ndryshme.', 'am': 'የሞክራዊ መተርጓሜ እና የሞክራዊ ዳታ ከsame ክፍል ሲያሳያል መልካም ይሠራል። ይህም ካልሆነ፣ ማስታወቂያው ማወቂያ ከውጭ ከዶሜን ጽሑፎች ውይይት ወደ ውይይት ፍርድ እንዲደርስ ይረዳል፡፡ We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources.  ፕሮጀክታችን የናውሬል መሣሪያን ለመግለጽ (ዳውሜ III, 2007)፤ የዶሜን-አጎኖስቲን ከዶሜን-አጎኖስቲ በተለየ ለሌክሲካዊ መልዕክቶች ይለየዋል፤ የመረብ መረብ በዙሪያው አካባቢ አካባቢ ነው፡፡ ፈተናዎቻችን ሁለት መዝገብ እና ሁለት ቋንቋዎች ሁለት ዓይነቶችን ይጠብቃሉ፡፡ ልግስናችን ግን ቀላል እና በተቆጣጠር ሳይሆን ብዙዎች ብርቱ መሠረቶች ያቆማል፡፡', 'hy': 'Supervised machine translation works well when the train and test data are sampled from the same distribution.  When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences.  Այստեղ մենք ուսումնասիրում ենք կապված միջավայր, բազմաբնագավառների ադապտացիա, որտեղ բնագավառների թիվը պոտենցիալ մեծ է և յուրաքանչյուր բնագավառների առանձին ադապտացիան կսպառի ուսուցման ռեսուր Our proposal transposes to neural machine translation the feature expansion technique of (Daume III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains.  Մեր փորձարկումները օգտագործում են երկու ճարտարապետություն և երկու լեզվի զույգ. դրանք ցույց են տալիս, որ մեր մոտեցումը, չնայած պարզ և հաշվարկների չափով, արտադրում է մի քանի ուժեղ հիմնական գծեր և ապահովում է բազմաբնագավառ համակարգ, որը հաջողակ թարգմանում', 'az': 'Mühafizə edilən mašin çeviri, tren və test veriləri eyni dağıtından nümunə alındığında yaxşı işlədi. Bu məsələn deyildikdə, adaptasyon teknikləri dəstədən öyrəndiyi bilgilərin domain sözlərinə generalizasyon etməsini əmin edir. Biz burada müxtəlif bir quruluş, çoxlu domena adaptasiyonu öyrənirik. Domena sayısı mümkün olaraq böyükdür və hər domena ayrı-ayrı adaptasiya ilə təhsil kaynaqlarını boşardı. Bizim teklifimiz nöral maşına çevirmək üçün (Daume III, 2007) genişləmə teknikəsini təşkil edir: domain-agnostiklərini domain-specific lexical representations təşkil edir, halbuki ağın çoxunu domenin arasında paylaşır. Bizim təcrübələrimiz iki arhitektür və iki dil çift istifadə edir: onlar bizim tərəfimizin, sadəcə və hesablamlı olaraq çox qüvvətli sətirlərdən üstün olduğunu göstərirlər və müxtəlif mənbələrdən metinləri tərcümə edən çoxlu domani sistemini tərcümə edirlər.', 'bn': 'ট্রেন এবং পরীক্ষা তথ্য একই বিতরণ থেকে উদাহরণ করা হলে সুপার্ভিসের মেশিন অনুবাদ ভালো কাজ করে। যখন এই ঘটনা ঘটে যায়, প্রযুক্তিগুলো নিশ্চিত করতে সাহায্য করে যে ডোমেইনের বাইরে পাঠানো টেক্সট থেকে জ্ঞান জেনারেলের সাথে ডোমে আমরা এখানে একটি সম্পর্কিত সেটিংস, মাল্টিডোমেইন অ্যাডাপেটশন, যেখানে ডোমেইনের সংখ্যা সম্ভবত বিশাল এবং প্রত্যেক ডোমেইনের সাথে আলাদ আমাদের প্রস্তাব নিউরুল মেশিনের অনুবাদের কাছে যাচ্ছে (ডেমোম্বর ৩, ২০০৭): এটি ডোমেইন-নির্দিষ্ট লেক্সিক্যাল প্রতিনিধিত্ব থেকে ডোমেইন-অ্যাঙ্কোস্ আমাদের পরীক্ষা দুটি স্থান এবং দুই ভাষার জোড়া ব্যবহার করে: তারা দেখাচ্ছে যে আমাদের পদক্ষেপ, যদিও সহজ এবং গণমেন্টিভাবে বেশ কয়েকটি শক্তিশালী বেসেলাইন প্রকাশ করে', 'ca': "La traducció màquina supervisada funciona bé quan les dades del tren i de la prova es mostren de la mateixa distribució. Quan no és així, les tècniques d'adaptació ajuden a assegurar que el coneixement aprengut dels textos fora de domini s'generalitza a les frases en domini. Estudem aquí un entorn relacionat, l'adaptació a múltiples dominis, on el nombre de dominis és potencialment gran i adaptar-se separadament a cada domini perdria recursos d'entrenament. La nostra proposta transposeix a la traducció neural la tècnica d'expansió de característiques (Daume III, 2007): aïlla l'agnòstica de domini de representacions lècsiques específices de domini, compartint la majoria de la xarxa a través de dominis. Els nostres experiments utilitzen dues arquitectures i dos parells de llenguatges: demostren que el nostre enfocament, encara que és simple i poc costós computacionalment, supera diverses línies de base fortes i proporciona un sistema multidominiu que tradueix amb èxit els textos de diverses fonts.", 'et': 'Järelevalve all olev masintõlge toimib hästi, kui rongi- ja katseandmed võetakse samast jaotusest. Kui see ei ole nii, aitavad kohandamismeetodid tagada, et domeenivälistest tekstidest saadud teadmised üldistaksid domeenisisesed laused. Siin uurime sellega seotud keskkonda, multivaldkondlikku kohanemist, kus valdkondade arv on potentsiaalselt suur ja iga valdkonnaga eraldi kohanemine raiskab koolitusressursse. Meie ettepanek võtab neuromasintõlkele üle funktsioonide laiendamise tehnika (Daume III, 2007): see isoleerib domeeni agnostika domeenispetsiifilistest leksikaalsetest esitustest, jagades samal ajal suuremat osa võrgust domeenide vahel. Meie eksperimendid kasutavad kahte arhitektuuri ja kahte keelepaari: need näitavad, et meie lähenemine on lihtne ja arvutuslikult odav, kuid ületab mitmeid tugevaid lähtejooni ning pakub mitme valdkonna süsteemi, mis edukalt tõlkib tekste erinevatest allikatest.', 'cs': 'Kontrolovaný strojový překlad funguje dobře, když jsou data vlaku a zkoušek odebrána ze stejné distribuce. Pokud tomu tak není, adaptační techniky pomáhají zajistit, že znalosti získané z mimo doménu textů se zobecní na věty v doméně. Studujeme zde související nastavení, multi-doménovou adaptaci, kde počet domén je potenciálně velký a přizpůsobení se samostatně každé doméně by plýtvalo školicími zdroji. Náš návrh transponuje do neuronového strojového překladu techniku rozšíření funkcí (Daume III, 2007): izoluje doménovou agnostiku od doménově specifických lexikálních reprezentací, přičemž sdílí většinu sítě napříč doménami. Naše experimenty používají dvě architektury a dva jazykové páry: ukazují, že náš přístup, i když je jednoduchý a výpočetně levný, překonává několik silných základních linií a poskytuje multidoménový systém, který úspěšně překládá texty z různých zdrojů.', 'fi': 'Valvottu konekäännös toimii hyvin, kun juna- ja testitiedot otetaan samasta jakelusta. Muussa tapauksessa sopeutumistekniikat auttavat varmistamaan, että verkkotunnuksen ulkopuolisista teksteistä oppima tieto yleistyy verkkotunnuksen sisäisiksi lauseiksi. Tutkimme tässä asiaan liittyvää, moniulotteista sopeutumista, jossa toimialojen määrä on potentiaalisesti suuri ja sopeutuminen erikseen kuhunkin toimialueeseen tuhlaisi koulutusresursseja. Ehdotuksemme siirtää neurokonekäännökseen (Daume III, 2007) feature expansion technique: se eristää domain-agnostic domain-spesifisistä lexikaalisista representaatioista ja jakaa suurimman osan verkosta toimialueiden kesken. Kokeissamme käytetään kahta arkkitehtuuria ja kahta kieliparia: ne osoittavat, että lähestymistapamme on yksinkertainen ja laskennallisesti edullinen, mutta se ylittää useita vahvoja lähtökohtia ja tuottaa moniulotteisen järjestelmän, joka kääntää menestyksekkäästi tekstejä eri lähteistä.', 'bs': 'Nadzorni prevod stroja dobro funkcioniše kada se podaci vlaka i testa uzorke iz iste distribucije. Kada to nije slučaj, tehnike adaptacije pomažu osigurati da znanje koje su naučene iz teksta izvan domena generalizuje na kazne u domenu. Ovdje proučavamo povezanu postavku, multidomenalnu adaptaciju, gdje je broj domena potencijalno velika i prilagođenje odvojeno za svaku domenu otpadalo bi resurse obuke. Naš prijedlog transponira neuronskom prevodu tehniku proširenja karakteristika (Daume III, 2007): izolira agnostičku domenu iz specifičnih leksičkih predstavljanja domena, dok dijeli većinu mreže preko domena. Naši eksperimenti koriste dvije arhitekture i dvije jezičke pare: pokazuju da naš pristup, dok jednostavan i računalno neucjenjivan, iznosi nekoliko jakih osnovnih linija i dostavlja multidomenički sistem koji uspješno prevodi tekste iz različitih izvora.', 'jv': 'Laptop" and "Desktop When this is not the Case, Adjustment Methods help sure that the knowness Learned from out-of-domain texts Generliss to in-domain words. We read here a connected settings, multi-domain modification, Where the number of domain is potentically big and Adjusting separately to every domain would be disinstructing information. We proposal Where\'s the reference', 'sk': 'Nadzorovano strojno prevajanje deluje dobro, kadar se vzorčijo podatki o vlaku in preskusu iz iste distribucije. Če to ni tako, tehnike prilagajanja pomagajo zagotoviti, da se znanje, pridobljeno iz besedil zunaj domene, posploši v domenske stavke. Tukaj preučujemo povezano okolje, prilagajanje več področij, kjer je število področij potencialno veliko, prilagajanje posameznim področjem pa bi zapravilo vire usposabljanja. Naš predlog v nevronsko strojno prevajanje prenaša tehniko razširitve funkcij (Daume III, 2007): izolira domensko agnostiko od domensko specifičnih leksikalnih reprezentacij, medtem ko deli večino omrežja med domenami. Naši eksperimenti uporabljajo dve arhitekturi in dva jezikovna pari: pokažeta, da naš pristop, čeprav preprost in računalniško poceni, presega več močnih osnovnih linij in zagotavlja večdomenski sistem, ki uspešno prevaja besedila iz različnih virov.', 'ha': "translation Idan bai so ba, Technical adaptation na taimake su yi amfani da cewa, an sanar da ilmi daga matsayin-don-Domen, ya ƙara zuwa cire-gareshi. Tuna karatun wannan da ke da wani matsayi wanda aka yi wa husũma, da adadi masu mutane, a inda yawan mutane masu ƙari zai iya girma kuma za'a daidaita kowane kashfiyar da mutane. Our proposal transposes to neural machine translation the feature expansion technique of (Daume III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains.  Kayan jarrabõyinmu, sunã amfani da matsayin biyu da mazan harshe biyu: sunã nũna cewa hanyarmu, kuma a lokacin da lissafa na sauƙi da lissafi, yana samar da wasu salofa mai ƙarfi kuma yana samar da tsarin multi-Domen wanda ke fassara misalin littafan daga sourcen dabam.", 'he': 'התרגום המכונה המשגיח עובד היטב כשהנתונים של הרכבת ומבחנים מודגים מאותה פיצוח. כאשר זה לא המקרה, טכניקות ההתאמה עוזרות להבטיח שהידע שנלמד מהטקסטים מחוץ לתחום מגנרל למשפטים בתחום. אנו לומדים כאן סדרה קשורה, התאמה במספר תרומות רבות, שבו מספר תרומות הוא פוטנציאלי גדול ומסתגל בנפרד לכל תרומה יבזבז משאבי אימון. הצעה שלנו מעבירה למכונה עצבית את טכניקת הרחיבה של (Daume III, 2007): היא מבודדת אגנוסטיקה-דומין מייצגים לקסיים ספציפיים לדמיון, בזמן שחלקת רוב הרשת ברחבי דומינים. הניסויים שלנו משתמשים בשני ארכיטקטורות ושני זוגות שפות: הם מראים שהגישה שלנו, בעוד פשוטה וחשבית לא יקרה, מגבילה מספר קווי בסיס חזקים ומסופק מערכת רבות דומיניות שמתרגמת בהצלחה טקסטים ממקורים רבים.', 'bo': 'ལྟ་རྟོག་ཞིབ་བྱས་པའི་མ་ལག་གི་སྐད་བསྒྱུར་ཆས་དང་བརྟག་ཞིབ When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences. We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources. Our proposal transposes to neural machine translation the feature expansion technique of (Daume III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains. Our experiments use two architectures and two language pairs: they show that our approach, while simple and computationally inexpensive, outperforms several strong baselines and delivers a multi-domain system that successfully translates texts from various sources.'}
{'en': 'Lexical Micro-adaptation for Neural Machine Translation', 'es': 'Microadaptación léxica para la traducción automática neuronal', 'ar': 'التكيف الجزئي المعجمي للترجمة الآلية العصبية', 'pt': 'Micro-adaptação léxica para tradução automática neural', 'fr': 'Micro-adaptation lexicale pour la traduction automatique neuronale', 'ru': 'Лексическая микроадаптация для нейронного машинного перевода', 'ja': '神経機械翻訳のための語彙的微小適応', 'zh': '用神经机器翻译词汇微适配', 'hi': 'न्यूरल मशीन अनुवाद के लिए लेक्सिकल माइक्रो-अनुकूलन', 'ga': "Micrea-oiriúnú foclóireachta d'aistriúchán meaisín néar", 'el': 'Λεξική μικροπροσαρμογή για τη νευρωνική μηχανική μετάφραση', 'hu': 'Lexikai mikroadaptáció a neurális gépi fordításhoz', 'ka': 'Name', 'it': 'Microadattamento lessico per la traduzione automatica neurale', 'kk': 'Неврал машинаны аудару үшін лексикалық микро- адаптациясы', 'lt': 'Leksinis mikropritaikymas neurologiniam mašinų vertimui', 'mk': 'Лексикална микроадаптација за превод на неврална машина', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷക്കുള്ള ലെക്സിക്കല്\u200d മൈക്രോ- അഡാപ്റ്റേഷന്\u200d', 'ms': 'Penyesuaian Mikro-leksikal untuk Terjemahan Mesin Neural', 'mt': 'Mikroattattattament Lessiku għat-Traduzzjoni tal-Magna Newrali', 'mn': 'Сэтгэл машины хөгжлийн лексикийн микро-адилтгал', 'pl': 'Leksykalna mikroadaptacja do neuronowego tłumaczenia maszynowego', 'ro': 'Microadaptare lexicală pentru traducerea mașinii neurale', 'no': 'Leksiske mikro- adaptering for neuralmaskinsomsetjing', 'sr': 'Leksička mikro-adaptacija za neuronski prevod mašine', 'si': 'Name', 'so': 'Turjumidda maskinada Neural ee Leksikal Mikro-adaptation', 'sv': 'Lexisk mikroanpassning för neural maskinöversättning', 'ta': 'Name', 'ur': 'نئرل ماشین ترجمہ کے لئے لکسیسی میکروٹ-اڈیٹ', 'uz': 'Name', 'vi': 'Dịch chuyên nghiệp về máy thần kinh', 'bg': 'Лексикална микроадаптация за неврален машинен превод', 'da': 'Lexisk mikrotilpasning til neural maskinoversættelse', 'nl': 'Lexische micro-aanpassing voor neuronale machinevertaling', 'hr': 'Leksička mikro-adaptacija za neuronski prevod strojeva', 'de': 'Lexische Mikroadaption für neuronale maschinelle Übersetzung', 'id': 'Micro-adaptasi Lexik untuk Translation Mesin Neural', 'ko': '신경기계 번역 중의 어휘 미시적 적응', 'fa': 'تغییرات میکروسکی برای ترجمه ماشین عصبی', 'sw': 'Utafiti wa Micro wa Kilexico kwa Tafsiri ya Mashine ya Njerumani', 'tr': 'Neural Maşynyň terjimesi üçin meksika mikro-adaptasyýasy', 'sq': 'Mikro-adaptim leksikal për përkthimin e makinës nervore', 'af': 'Name', 'am': 'ትርጉም', 'hy': 'Նյարդային մեքենայի թարգմանման համար լեքսիկական միկրոադապտացիա', 'bn': 'নিউরাল মেশিন অনুবাদের জন্য লেক্সিক্যাল মাইক্রো- অ্যাডাপ্টেশন', 'az': 'Nöral Makina Çeviri üçün Leksik Mikro-adaptasiya', 'bs': 'Leksička mikro-adaptacija za neuronski prevod mašine', 'ca': 'Microadaptació lèxica per a la traducció de màquines neurals', 'cs': 'Lexická mikroadaptace pro neuronový strojový překlad', 'et': 'Lexikaalne mikrokohandamine neuroaalse masintõlke jaoks', 'fi': 'Lexical Micro-adaption for Neural Machine Translation', 'sk': 'Lexična mikroprilagoditev za strojno prevajanje nevronov', 'ha': '@ item Text character set', 'jv': 'mikro-adalah Leksik kanggo Terjamahan Njaral', 'bo': 'ནུས་མེད་ལག་འཁྱེར་གྱི་སྤྱི་ཚོལ་ལུགས་སྲོལ་གྱི་Micro-adaptation', 'he': 'מיקרו-התאמה לקסיקה לתרגום מכונות נוירות'}
{'en': 'This work is inspired by a typical machine translation industry scenario in which translators make use of in-domain data for facilitating translation of similar or repeating sentences. We introduce a generic framework applied at ', 'pt': 'Este trabalho é inspirado em um cenário típico da indústria de tradução automática em que os tradutores fazem uso de dados do domínio para facilitar a tradução de frases semelhantes ou repetidas. Introduzimos uma estrutura genérica aplicada na inferência na qual um subconjunto de pares de segmentos é primeiro extraído dos dados de treinamento de acordo com sua semelhança com as sentenças de entrada. Esses segmentos são então usados para atualizar dinamicamente os parâmetros de uma rede NMT genérica, realizando assim uma microadaptação léxica. Nossa abordagem demonstra um forte desempenho de adaptação a conjuntos de dados novos e existentes, incluindo pseudo-dados no domínio. Avaliamos nossa abordagem em um conjunto de dados heterogêneo de treinamento inglês-francês mostrando ganhos de precisão em todos os domínios avaliados quando comparados a linhas de base de adaptação fortes.', 'es': 'Este trabajo se inspira en un escenario típico de la industria de la traducción automática en el que los traductores utilizan datos del dominio para facilitar la traducción de oraciones similares o repetidas. Introducimos un marco genérico aplicado en la inferencia en el que un subconjunto de pares de segmentos se extrae primero de los datos de entrenamiento de acuerdo con su similitud con las oraciones de entrada. Estos segmentos se utilizan para actualizar dinámicamente los parámetros de una red NMT genérica, realizando así una microadaptación léxica. Nuestro enfoque demuestra un sólido rendimiento de adaptación a conjuntos de datos nuevos y existentes, incluidos los datos pseudo en el dominio. Evaluamos nuestro enfoque en un conjunto de datos de capacitación heterogéneo en inglés y francés que muestra ganancias de precisión en todos los dominios evaluados en comparación con bases de adaptación sólidas.', 'ar': 'هذا العمل مستوحى من سيناريو صناعة الترجمة الآلية النموذجي الذي يستخدم فيه المترجمون البيانات في المجال لتسهيل ترجمة الجمل المماثلة أو المتكررة. نقدم إطارًا عامًا مطبقًا عند الاستدلال حيث يتم أولاً استخراج مجموعة فرعية من أزواج المقطع من بيانات التدريب وفقًا لتشابهها مع جمل الإدخال. تُستخدم هذه المقاطع بعد ذلك لتحديث معلمات شبكة NMT العامة ديناميكيًا ، وبالتالي إجراء تكيف معجمي دقيق. يوضح نهجنا أداءً قويًا للتكيف مع مجموعات البيانات الجديدة والحالية بما في ذلك البيانات الزائفة في المجال. نقوم بتقييم نهجنا على مجموعة بيانات تدريب إنجليزية وفرنسية غير متجانسة تُظهر مكاسب الدقة في جميع المجالات التي تم تقييمها عند مقارنتها بخطوط الأساس القوية للتكيف.', 'fr': "Ce travail s'inspire d'un scénario typique de l'industrie de la traduction automatique dans lequel les traducteurs utilisent des données internes pour faciliter la traduction de phrases similaires ou répétées. Nous introduisons un cadre générique appliqué à l'inférence dans lequel un sous-ensemble de paires de segments est d'abord extrait des données d'entraînement en fonction de leur similitude avec les phrases d'entrée. Ces segments sont ensuite utilisés pour mettre à jour dynamiquement les paramètres d'un réseau NMT générique, réalisant ainsi une micro-adaptation lexicale. Notre approche démontre de solides performances d'adaptation aux ensembles de données nouveaux et existants, y compris les pseudo-données dans le domaine. Nous évaluons notre approche sur un ensemble de données d'entraînement hétérogène anglais-français montrant des gains de précision sur tous les domaines évalués par rapport à des bases d'adaptation solides.", 'ja': 'この作品は、翻訳者が類似または繰り返しの文章の翻訳を容易にするためにドメイン内データを利用する典型的な機械翻訳業界のシナリオに触発されています。入力文との類似性に応じて、まず訓練データからセグメントペアのサブセットを抽出する、推論時に適用される一般的なフレームワークを紹介する。次いで、これらのセグメントは、一般的なＮＭＴネットワークのパラメータを動的に更新するために使用され、したがって、辞書的なマイクロアダプタを実行する。当社のアプローチは、疑似インドメインデータを含む新規および既存のデータセットに対する強力な適応パフォーマンスを示しています。私たちは、強力な適応ベースラインと比較して、評価されたすべてのドメインの正確さの向上を示す異種の英仏のトレーニングデータセットに関するアプローチを評価します。', 'hi': 'यह काम एक विशिष्ट मशीन अनुवाद उद्योग परिदृश्य से प्रेरित है जिसमें अनुवादक समान या दोहराए जाने वाले वाक्यों के अनुवाद को सुविधाजनक बनाने के लिए इन-डोमेन डेटा का उपयोग करते हैं। हम अनुमान पर लागू एक सामान्य रूपरेखा पेश करते हैं जिसमें खंड जोड़े का एक सबसेट पहली बार इनपुट वाक्यों के लिए उनकी समानता के अनुसार प्रशिक्षण डेटा से निकाला जाता है। इन खंडों का उपयोग तब एक सामान्य एनएमटी नेटवर्क के मापदंडों को गतिशील रूप से अपडेट करने के लिए किया जाता है, इस प्रकार एक लेक्सिकल माइक्रो-अनुकूलन का प्रदर्शन किया जाता है। हमारा दृष्टिकोण छद्म इन-डोमेन डेटा सहित नए और मौजूदा डेटासेट के लिए मजबूत अनुकूलन प्रदर्शन प्रदर्शित करता है। हम एक विषम अंग्रेजी-फ्रांसीसी प्रशिक्षण डेटासेट पर हमारे दृष्टिकोण का मूल्यांकन करते हैं जो मजबूत अनुकूलन बेसलाइन की तुलना में सभी मूल्यांकन किए गए डोमेन पर सटीकता लाभ दिखाते हैं।', 'zh': '其灵感自典刑机器翻译业场,其翻译人员以域内数据促相似重句之译。 引入一应用推理通用框架,其先据其与输句相似性取片段对集。 然后动更新通 NMT 网络之参数,而行词法微适配。 吾法展新见数集(伪域内数)强应性。 异构英语-法语练数集上料我之法,示与强适基线,凡质域之准确性皆有所提高。', 'ru': 'Эта работа вдохновлена типичным сценарием индустрии машинного перевода, в котором переводчики используют внутридоменные данные для облегчения перевода похожих или повторяющихся предложений. Введем общую структуру, применяемую при выводе, в которой подмножество пар сегментов сначала извлекается из обучающих данных в соответствии с их сходством с входными предложениями. Эти сегменты затем используются для динамического обновления параметров общей сети NMT, тем самым выполняя лексическую микроадаптацию. Наш подход демонстрирует высокую эффективность адаптации к новым и существующим наборам данных, включая псевдовнутридоменные данные. Мы оцениваем наш подход на основе гетерогенного английско-французского учебного набора данных, показывающего повышение точности во всех оцененных областях по сравнению с сильными исходными уровнями адаптации.', 'ga': 'Tá an saothar seo spreagtha ag gnáthchás thionscal an mheaisínaistriúcháin ina mbaineann aistritheoirí úsáid as sonraí in-fearainn chun aistriúchán ar abairtí comhchosúla nó athráite a éascú. Tugaimid isteach creat cineálach a chuirtear i bhfeidhm ar thátal ina mbaintear fo-thacar de phéirí teascán as sonraí oiliúna ar dtús de réir a gcosúlachta leis na habairtí ionchuir. Úsáidtear na míreanna seo ansin chun paraiméadair líonra cineálach NMT a thabhairt cothrom le dáta go dinimiciúil, agus mar sin déantar micrea-oiriúnú foclóireachta. Léiríonn ár gcur chuige feidhmíocht láidir oiriúnaithe do thacair sonraí nua agus reatha lena n-áirítear sonraí bréige in-fearainn. Déanaimid meastóireacht ar ár gcur chuige ar thacar sonraí oiliúna ilchineálach Béarla-Fraincis a thaispeánann gnóthachain chruinneas ar gach fearann a ndearnadh meastóireacht orthu i gcomparáid le bonnlínte oiriúnaithe láidre.', 'el': 'Το έργο αυτό εμπνέεται από ένα τυπικό σενάριο βιομηχανίας μηχανικής μετάφρασης στο οποίο οι μεταφραστές χρησιμοποιούν δεδομένα εντός του τομέα για τη διευκόλυνση της μετάφρασης παρόμοιων ή επαναλαμβανόμενων προτάσεων. Εισάγουμε ένα γενικό πλαίσιο που εφαρμόζεται στο συμπέρασμα στο οποίο ένα υποσύνολο ζευγαριών τμημάτων εξάγεται πρώτα από τα δεδομένα κατάρτισης σύμφωνα με την ομοιότητά τους με τις προτάσεις εισαγωγής. Αυτά τα τμήματα χρησιμοποιούνται στη συνέχεια για την δυναμική ενημέρωση των παραμέτρων ενός γενικού δικτύου NMT, πραγματοποιώντας έτσι μια λεξική μικροπροσαρμογή. Η προσέγγισή μας καταδεικνύει ισχυρή απόδοση προσαρμογής σε νέα και υπάρχοντα σύνολα δεδομένων, συμπεριλαμβανομένων των ψευδο-δεδομένων εντός του τομέα. Αξιολογούμε την προσέγγισή μας σε ένα ετερογενές σύνολο δεδομένων αγγλικής-γαλλικής εκπαίδευσης που δείχνουν κέρδη ακρίβειας σε όλους τους αξιολογούμενους τομείς σε σύγκριση με ισχυρές βάσεις προσαρμογής.', 'hu': 'Ezt a munkát egy tipikus gépi fordítási iparági forgatókönyv ihlette, amelyben a fordítók használják fel a domain belüli adatokat a hasonló vagy ismétlődő mondatok fordításának megkönnyítésére. Bevezetünk egy olyan általános következtetési keretet, amelyben a szegmenspárok egy részhalmazát először a képzési adatokból kivonjuk a bemeneti mondatokhoz való hasonlóságuk szerint. Ezeket a szegmenseket egy generikus NMT hálózat paramétereinek dinamikus frissítésére használják, így lexikális mikroadaptációt hajtanak végre. Megközelítésünk erőteljes alkalmazkodási teljesítményt mutat az új és meglévő adatkészletekhez, beleértve a pseudodomain adatokat is. Megközelítésünket heterogén angol-francia képzési adatok alapján értékeljük, amelyek minden értékelt területen pontosságnövekedést mutatnak az erős adaptációs alapokhoz képest.', 'ka': 'ეს სამუშაო იქნება ტიპური მაქინის გაგრძელება ინდუქტურის სინარიოში, რომელიც ტრანგლიტორები მონაცემების მონაცემების გამოყენება სხვადასხვა ან გაგრძელებული სინარიო ჩვენ ჩვენ შევცვალოთ სენერიკური ფრამეტრი, რომელიც სენერიკური ფრამეტრის პირველი სენერიკური ფრამეტრის გამოყენება მონაცემების მონაცემების გამოყენებაზე, რომელიც შე ეს სეგმენტები შემდეგ გამოყენება დინამიკური NMT ქსელის პარამეტრების განახლებისთვის, რადგან ლექსიკალური მიკრო აეპოდიაციაციას გავაკეთებთ. ჩვენი პროგორმაცია მომხმარებს ძალიან აეპრატიფიკაცია ახალი და მხოლოდ მონაცემების კონფიგურაციას, включая პესედო დემომინში მონაც ჩვენ გავუმუშავებთ ჩვენი წარმოდგენა ჰეტეროგენური ანგლისური-ფრანგური განსწავლების მონაცემების სახელი, როდესაც ყველა განსწავლებული დიომენტების წარმოდგენა, როდე', 'it': "Questo lavoro si ispira a uno scenario tipico del settore della traduzione automatica in cui i traduttori utilizzano dati interni al dominio per facilitare la traduzione di frasi simili o ripetute. Introducemo un framework generico applicato all'inferenza in cui un sottoinsieme di coppie di segmenti viene estratto per prima cosa dai dati di allenamento in base alla loro somiglianza con le frasi di input. Questi segmenti vengono poi utilizzati per aggiornare dinamicamente i parametri di una rete NMT generica, eseguendo così un micro-adattamento lessicale. Il nostro approccio dimostra forti prestazioni di adattamento a set di dati nuovi ed esistenti, inclusi dati pseudo in-domain. Valutiamo il nostro approccio su un set eterogeneo di dati di formazione inglese-francese che mostra guadagni di precisione su tutti i domini valutati se confrontati con solide basi di adattamento.", 'lt': 'Šis darbas grindžiamas tipiniu mašin ų vertimo pramonės scenarijumi, kuriame vertėjai naudojasi domeniniais duomenimis panašių arba pakartotinių sakinių vertimui palengvinti. Įdiegiame bendrą sistemą, taikomą išvadoje, kurioje segment ų poros pogrupis pirmą kartą išimamas iš mokymo duomenų, atsižvelgiant į jų panašumą į įvadinius sakinius. Tada šie segmentai naudojami dinamiškai atnaujinti generinio NMT tinklo parametrus ir taip atlikti leksinį mikropritaikymą. Mūsų požiūris rodo tvirtą prisitaikymo prie naujų ir esamų duomenų rinkinių, įskaitant pseudo duomenų srityse, veiksmingumą. Vertiname savo požiūrį į heterogenišką anglų ir prancūzų mokymo duomenų rinkinį, kuriame nurodoma, kad visose vertinamose srityse tiksliai padidėjo, palyginti su stipriomis prisitaikymo bazėmis.', 'kk': 'Бұл жұмыс ұқсас не қайталанатын сөздерді аударуға көмектесу үшін доменге аударуға көмектесетін компьютер индустриясының кәдімгі сценариясы болады. Біз бірінші бөліктердің бірінші бөліктерінің бірінші бөліктерінің бірінші бөліктерінің бірінші мәліметтерінен келтірілген жалпы қоршауын келтіреміз. Бұл сегменттер динамикалық NMT желінің параметрлерін жаңарту үшін қолданылады, сондықтан лексикалық микро- адаптациялау үшін. Біздің қасиетіміз домендегі псевдо деректерінің қосымша жаңа және бар деректер қорларына күшті адаптациялау мүмкіндігін көрсетеді. Біз тегероген ағылшын-французша оқыту деректер бағдарламасының барлық оқыту домендерінің дұрыстығын көрсетеді.', 'mk': 'Оваа работа е инспирирана од типичен сценарио за машински превод во кое преводниците користат податоци во домен за олеснување на преводот на слични или повторни реченици. Ние воведуваме генерална рамка аплицирана на конференција во која подгрупа парови од сегменти првпат се извлекуваат од податоците за обука според нивната сличност со влезните реченици. Овие сегменти потоа се користат за динамично ажурирање на параметрите на генералната НМТ мрежа, со што ќе се изврши лексичка микро-адаптација. Our approach demonstrates strong adaptation performance to new and existing datasets including pseudo in-domain data.  Ние го проценуваме нашиот пристап на хетероген англиско-француски набор на податоци за тренинг кој покажува прецизно добивање на сите проценети домени во споредба со силните бази на адаптација.', 'ms': 'Kerja ini diinspirasi oleh skenario industri terjemahan mesin biasa di mana penerjemah menggunakan data dalam domain untuk memudahkan terjemahan kalimat yang sama atau mengulang. Kami memperkenalkan kerangka generik yang dilaksanakan pada kesimpulan di mana subset pasangan segmen pertama dikekstrak dari data latihan mengikut persamaan mereka dengan kalimat input. Segmen ini kemudian digunakan untuk mengemaskini secara dinamik parameter rangkaian NMT generik, sehingga melakukan penyesuaian-mikro leksikal. pendekatan kita menunjukkan prestasi penyesuaian kuat kepada set data baru dan yang wujud termasuk data pseudo dalam domain. We evaluate our approach on a heterogeneous English-French training dataset showing accuracy gains on all evaluated domains when compared to strong adaptation baselines.', 'ml': 'ഈ ജോലി ഒരു സാധാരണ യന്ത്രത്തിന്റെ പരിഭാഷണത്തിന്റെ അനുവാദങ്ങള്\u200d ഉപയോഗിക്കുന്നതിനായി ഉപയോഗപ്പെടുത്തുന്നു അപകടത്തില്\u200d പ്രയോഗിക്കപ്പെട്ട ഒരു സാധാരണ ഫ്രെയിമെന്റ് നാം പരിചയപ്പെടുത്തുന്നു. അതില്\u200d ഒരു സിഗ്മെന്\u200dറ് ജോട്ടുകള്\u200d ആദ്യം പരിശീലനത്തി പിന്നീട് ഈ വിഭാഗങ്ങള്\u200d സാധാരണ NMT നെറ്റിന്റെ പരാമീറ്ററുകള്\u200d പുതുക്കുവാന്\u200d ഉപയോഗിക്കുന്നു. അതുകൊണ്ട് ലെക്സിക്കല്\u200d മൈക്രോ നമ്മുടെ അടുത്തേക്ക് പുതിയ ഡാറ്റാസറ്റുകള്\u200dക്ക് ശക്തിയുള്ള പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രദര്\u200dശിപ്പിക്കുന്നു നമ്മുടെ പ്രായോഗ്യത്തെ വിലാസപ്പെടുത്തുന്നത് ശക്തിയുള്ള അഡാപ്റ്റേഷന്\u200d ബെസ്റ്റേഷന്\u200d ലൈനുകള്\u200dക്ക് തുല്യമായി കാണിക്കു', 'no': 'Denne arbeidet er inspirert av ein typisk maskinsomsetjingsskrinisjon der omsetjarane brukar i domenedata for å gjere omsetjing av liknande eller gjentaande setningar. Vi introduserer eit generelt rammeverk som er brukt ved infeksjon der ein delt av segmentparr først er ekstrahert frå opplæringsdata etter dei tilsvarande innsetjingane. Desse segmentane vert derfor brukte for å dynamisk oppdatera parametrar i eit generelt NMT- nettverk, slik at det utfører ein leksisk mikro- adaptering. Tilnærminga vårt viser sterke tilpassingseffekt til nye og eksisterande datasett, inkludert pseudo i domenedata. Vi evaluerer tilnærminga vårt på ein heterogenen engelsk-fransk treningsdataset som viser nøyaktig innvikling på alle evaluerte domene når det sammenlignet med sterke adaptasjonsbaser.', 'mn': 'Энэ ажлыг машины хөрөнгө оруулах үйлдвэрлэлийн хувилбараас урам зориулсан. Энэ нь илүү төстэй, давтамжлах өгүүлбэрүүдийг хөрөнгө оруулахын тулд орчуулагчид ашигладаг. Бид халдвар дээр хэрэглэгдсэн ерөнхий хэлбэрийг танилцуулдаг. Эхлээд хэдэн хэлбэрийн хэлбэрээс өгөгдлийг сургалтын мэдээллээс хадгалагддаг. Эдгээр загварууд нь NMT сүлжээний ерөнхий параметрлүүдийг динамик шинэчлэхэд хэрэглэгддэг. Иймээс лексикийн микро адаптацийг хийдэг. Бидний арга баримт шинэ болон суурилсан өгөгдлийн сангууд дотор pseudo өгөгдлийн тухай хүчтэй адилтгалын үйл ажиллагааг харуулдаг. Бид англи-французын дасгал хөдөлгөөн өгөгдлийн сургалтын тухай ойлголтыг үнэлж үздэг. Хүчирхэг адилтгал хөдөлгөөн суурь шугам дээр харьцуулахад тодорхой үнэлгээ гаргадаг бүх хэсэ', 'mt': 'Dan ix-xogħol huwa ispirat minn xenarju tipiku tal-industrija tat-traduzzjoni tal-magni li fih it-tradutturi jagħmlu użu minn dejta interna biex jiffaċilitaw it-traduzzjoni ta’ sentenzi simili jew ripetuti. Aħna nintroduċu qafas ġeneriku applikat fl-inferenza li fiha s-sottosett ta’ pari tas-segmenti għall-ewwel jiġu estratti mid-dejta tat-taħriġ skont is-similarità tagħhom mas-sentenzi tal-input. Dawn is-segmenti mbagħad jintużaw biex jaġġornaw b’mod dinamiku l-parametri ta’ netwerk ġeneriku NMT, u b’hekk iwettqu mikroadattament lexiku. L-approċċ tagħna juri prestazzjoni qawwija ta’ adattament għal settijiet ta’ dejta ġodda u eżistenti inkluż dejta psewdo fid-dominju. Aħna jevalwaw l-approċċ tagħna fuq sett ta’ dejta ta’ taħriġ eteroġenu Ingliż-Franċiż li juri kisbiet ta’ preċiżjoni fl-oqsma kollha evalwati meta mqabbel ma’ linji bażi b’saħħithom ta’ adattament.', 'pl': 'Praca ta jest inspirowana typowym scenariuszem branży tłumaczeń maszynowych, w którym tłumacze wykorzystują dane w domenie do ułatwienia tłumaczenia podobnych lub powtarzających się zdań. Wprowadzamy ogólny framework stosowany przy wnioskowaniu, w którym podzbiór par segmentów jest najpierw ekstrahowany z danych treningowych według ich podobieństwa do zdań wejściowych. Segmenty te są następnie wykorzystywane do dynamicznej aktualizacji parametrów ogólnej sieci NMT, przeprowadzając w ten sposób mikroadaptację leksykalną. Nasze podejście wykazuje dużą wydajność adaptacji do nowych i istniejących zbiorów danych, w tym do pseudo-in-domain danych. Oceniamy nasze podejście w oparciu o heterogeniczny angielsko-francuski zestaw danych treningowych, który pokazuje wzrost dokładności we wszystkich ocenianych dziedzinach w porównaniu do silnych linii bazowych adaptacji.', 'ro': 'Această lucrare este inspirată de un scenariu tipic din industria traducerii automate, în care traducătorii utilizează date interne pentru a facilita traducerea frazelor similare sau repetate. Introducem un cadru generic aplicat la inferență în care un subset de perechi de segmente sunt extrase mai întâi din datele de formare în funcție de similaritatea lor cu propozițiile de intrare. Aceste segmente sunt apoi folosite pentru a actualiza dinamic parametrii unei rețele generice NMT, efectuând astfel o micro-adaptare lexicală. Abordarea noastră demonstrează performanțe puternice de adaptare la seturi de date noi și existente, inclusiv date pseudo-in-domeniu. Evaluăm abordarea noastră pe baza unui set eterogene de date de instruire engleză-franceză care arată câștiguri de precizie pe toate domeniile evaluate în comparație cu liniile de bază puternice de adaptare.', 'sr': 'Ovaj rad je inspirisan tipičnim scenarijem industrije prevođenja mašin a u kojem translatori koriste podatke u domenu za olakšanje prevođenja sličnih ili ponovnih rečenica. Predstavljamo generični okvir koji se primjenjuje na inferenciji u kojem su prvi dio parova segment a izvučeni iz podataka obuke prema njihovoj sličnosti ulaznim rečenicama. Ovi segmenti se onda koriste za dinamički aktualiziranje parametara generične NMT mreže, tako da izvode leksičku mikro-adaptaciju. Naš pristup pokazuje jaku prilagodbu novim i postojećim podacima, uključujući pseudo podatke u domenu. Procjenjujemo naš pristup heterogeneznom podacima o obuci engleskog-francuskog, pokazujući preciznost svih procjenjenih domena u usporedbi sa jakim podacima adaptacije.', 'si': 'මේ වැඩේ සාමාන්\u200dය යංක්\u200dරියාත්මක ව්\u200dයාපෘතික ව්\u200dයාපෘතික විද්\u200dයාපෘතික විද්\u200dයාපෘතික විද්\u200dයාපෘතික විද්\u200dයාපයක්  අපි සාමාන්\u200dය ප්\u200dරවේශයක් ප්\u200dරවේශනය කරනවා කියලා, ඒ වගේම මුලින්ම ප්\u200dරවේශනයක් ප්\u200dරවේශනයක් ප්\u200dරවේශනය කරලා තියෙනවා කියලා. Name අපේ පරීක්ෂණය පෙන්වන්නේ අළුත් සහ තියෙන්න තොරතුරු සූදානයට ශක්තිමත් සම්බන්ධතාව ප්\u200dරකාශයක අපි ඉංග්\u200dරේන්සි-ෆ්\u200dරෑන්සි ප්\u200dරශ්න දත්ත සූදානයට අපේ විශ්වාස කරන්නේ හැම විශ්වාස කරපු ඩෝමේන්ස් වල සියලුම්', 'so': 'Shaqodaas waxaa lagu waxyoodaa muusikada turjumidda ee muusikada caadiga ah oo ay turjumaan ku isticmaalaan macluumaadka internetka si ay u fududeeyaan turjumidda isku mid ah ama ku soo celiyaan hadallada. Waxaynu soo bandhignaynaa qoraal geneeral ah oo lagu codsaday cudurada labo ka mid ah, kaas oo marka ugu horeysa looga soo saaraa macluumaadka waxbarashada si waafaqsan ugu eg xarumaha soo gala. Markaas waxaa lagu isticmaalaa in lagu cusboonaysiiyo parameters of generic NMT network, sidaa darteed waxaa lagu sameeyaa lexical micro-adaptation. Dhaqdhaheenna waxay muujiyaan sameynta si adag loo beddelo oo uu u jeedo sameynta macluumaadka cusub iyo waxa jiraba, kuwaas oo ka mid ah macluumaadka gudaha. We evaluate our approach on a heterogeneous English-French training dataset showing accuracy gains on all evaluated domains when compared to strong adaptation baselines.', 'ta': '@ info நாம் பாதிப்பில் பயன்படுத்தப்பட்ட பொது சட்டத்தை குறிப்பிடுகிறோம். பின்னத்தில் பிரிவு ஜோடிகள் முதலில் பயிற்சி தகவலிலிருந்து ப பின்னர் இந்த துண்டுகள் பொதுவான NMT பிணையத்தின் அளபுருக்களை தேர்ந்தெடுக்க பயன்படுத்தப்படும், அதனால் லெக்சிக்சியல் மைக்ரோ- ஒ எங்கள் அணுக்கம் புதிய மற்றும் இருக்கும் தகவல் அமைப்புகளுக்கு வலிமையான ஒழுங்கும் செயல்பாட்டை காட்டுகிறது  நாங்கள் எங்கள் செயல்பாட்டை மதிப்பிடுகிறோம் வலிமை ஒப்புக்கொள்ளும் அடிப்படைகளை ஒப்பிடும் போது எல்லா மதிப்பிட்ட களங்களிலும', 'ur': 'یہ کام ایک معمولی مشین ترجمہ ایڈرنسی سناریو کے ذریعے الهام لگایا جاتا ہے جس میں ترجمہ کرنے والوں نے ایک جیسے یا دوبارہ کلمات کا ترجمہ آسانی کرنے کے لئے ڈومین میں ڈیٹا استعمال کیا ہے. ہم ایک عمومی فرمود کو معلوم کرتے ہیں جن میں سپٹ جوڑوں کا ایک سپٹ ڈیٹ کی تعلیم سے پہلے اُن کی مثالی کے مطابق اُن کے سوال جماعتوں کے مطابق اٹھایا جاتا ہے. اس کے بعد یہ سیگنٹ ڈینمانیک NMT نیٹ ورک کے پارامتروں کو آدٹ کرنے کے لئے استعمال کیا جاتا ہے، اسی طرح لکسیکل میکروٹ-اڈیٹ کرتا ہے. ہمارا طریقہ نئی اور موجود ڈاٹ سٹ کے لئے مضبوط اضافہ کی عملکرد دکھاتا ہے جو دامین ڈاٹ میں pseudo کے شامل ہے۔ ہم اپنے طریقے کو ایک غیر عام انگلیسی-فرانسوی ترینسی ڈیٹ سٹ پر ارزش دیتے ہیں کہ تمام مطابق مطابق مطابق بنسٹ لین کے مقابلہ میں مطابق غلبہ حاصل کرتا ہے.', 'sv': 'Detta arbete 채r inspirerat av ett typiskt scenario inom maskin철vers채ttningsbranschen d채r 철vers채ttare anv채nder dom채ndata f철r att underl채tta 철vers채ttning av liknande eller upprepade meningar. Vi introducerar ett generiskt ramverk som till채mpas vid inferens d채r en delm채ngd segmentpar f철rst extraheras fr책n tr채ningsdata enligt deras likhet med inmatningsmeningarna. Dessa segment anv채nds sedan f철r att dynamiskt uppdatera parametrarna f철r ett generiskt NMT-n채tverk, vilket g철r en lexikal mikroanpassning. V책rt tillv채gag책ngss채tt visar p책 starka anpassningsf철rm책ga till nya och befintliga dataupps채ttningar inklusive pseudoin-domain data. Vi utv채rderar v책rt tillv채gag책ngss채tt p책 ett heterogent engelsk-franskt tr채ningsdataset som visar noggrannhetsvinster p책 alla utv채rderade dom채ner j채mf철rt med starka anpassningsgr채nser.', 'uz': "@ info: whatsthis Biz qo'yish soʻzda qo'llanilgan genetikal freymni anglatamiz. Bu yerda birinchi qismlar guruhi birinchi xil qo'llangan taʼminlovchi maʼlumotdan foydalanadi. Keyin bu belgilar umumiy NMT tarmoqning parametrlarini yangilash uchun ishlatiladi, shunday qilib leksikal mikro adapterini bajarish mumkin. Bizning murojaatiyatlarimiz yangi va mavjud maʼlumotlar tarkibini qo'shish muvaffaqiyatlarini ko'rsatadi. Biz bir xil ingliz-Fransuzcha taʼminlovchi maʼlumotlar tarkibini qiymatimiz. Ko'rinishi mumkin bo'lgan hamma domeyalarda qiymatlar sonlarini ko'rsatadi.", 'vi': 'Tác phẩm này được truyền cảm hứng từ một kịch bản chuyên dịch cỗ máy điển hình, trong đó người phiên bản sử dụng dữ liệu nội bộ để dễ dàng dịch các câu tương tự hay phiên bản lặp lại. Chúng tôi giới thiệu một cơ sở chung được áp dụng khi kết luận trong đó một nhóm các bộ phân đoạn được chiết xuất đầu tiên từ dữ liệu đào tạo dựa trên sự giống nhau với các câu nhập. Những đoạn này được dùng để cập nhật tăng cường các tham số của mạng công ty NMT chung, bằng cách thực hiện vi sửa đổi từ. Cách tiếp cận của chúng tôi cho thấy hiệu quả thích ứng mạnh với các tập tin mới và tồn tại, gồm cả giả dữ liệu trong miền. Chúng tôi đánh giá phương pháp của chúng tôi về một bộ dữ liệu Anh-Pháp khác nhau về huấn luyện cho thấy sự chính xác ở tất cả các lĩnh vực được đánh giá khi so với các nền tảng sửa chữa mạnh.', 'bg': 'Тази работа е вдъхновена от типичен сценарий на индустрията за машинен превод, при който преводачите използват данни в домейна за улесняване на превода на подобни или повтарящи се изречения. Въвеждаме генерична рамка, приложена при заключение, в която подмножество сегментни двойки първо се извличат от тренировъчните данни според приликата им с входните изречения. След това тези сегменти се използват за динамично актуализиране на параметрите на генерична NMT мрежа, като по този начин се извършва лексикална микроадаптация. Нашият подход демонстрира силна адаптация към нови и съществуващи набори от данни, включително псевдо-в-домейн данни. Ние оценяваме нашия подход на хетерогенен англо-френски набор от данни за обучение, показващи повишаване на точността във всички оценени области в сравнение със силните базови линии на адаптацията.', 'hr': 'Ovaj rad je inspirisan tipičnim scenarijem industrije prevođenja strojeva u kojem se prevoditelji koriste podaci u domenu za olakšanje prevođenja sličnih ili ponovnih rečenica. Predstavljamo generički okvir koji se primjenjuje na infekciji u kojem su prvi dio parova segment a izvučeni iz podataka obuke prema njihovoj sličnosti ulaznim rečenicama. Tada se ovi segmenti koriste za dinamički aktualiziranje parametara generičke NMT mreže, tako što izvode leksičku mikro-adaptaciju. Naš pristup pokazuje jaku prilagodbu novim i postojećim podacima, uključujući pseudo podatke u domenu. Procjenjujemo naš pristup na heterogeneznom podacima o obuci engleskog-francuskog, pokazujući preciznost svih procjenjenih domena u usporedbi s jakim podacima prilagodbe.', 'da': 'Dette arbejde er inspireret af en typisk maskinoversættelsesindustri scenarie, hvor oversættere gør brug af domænedata til at lette oversættelse af lignende eller gentagne sætninger. Vi introducerer en generisk ramme anvendt ved udledning, hvor en delmængde segmentpar først udtrækkes fra træningsdata i henhold til deres lighed med input sætninger. Disse segmenter bruges derefter til dynamisk at opdatere parametrene i et generisk NMT-netværk og dermed udføre en leksikisk mikrotilpasning. Vores tilgang viser stærk tilpasningsydeevne til nye og eksisterende datasæt, herunder pseudo in-domain data. Vi evaluerer vores tilgang på et heterogent engelsk-fransk træningsdatasæt, der viser nøjagtighedsforbedringer på alle evaluerede områder sammenlignet med stærke tilpasningsbaselines.', 'nl': 'Dit werk is geïnspireerd op een typisch scenario in de machinevertaalindustrie waarin vertalers gebruik maken van in-domain data om het vertalen van vergelijkbare of herhalende zinnen te vergemakkelijken. We introduceren een generiek framework toegepast bij inferentie waarin een subset segmentparen eerst uit trainingsgegevens wordt geëxtraheerd op basis van hun gelijkenis met de invoerzinnen. Deze segmenten worden vervolgens gebruikt om de parameters van een generiek NMT netwerk dynamisch bij te werken, waardoor een lexicale micro-aanpassing wordt uitgevoerd. Onze aanpak toont sterke adaptatieprestaties aan nieuwe en bestaande datasets, waaronder pseudo-in-domain data. We evalueren onze aanpak op basis van een heterogene Engels-Franse trainingsdataset die nauwkeurigheidsvergrotingen toont op alle geëvalueerde domeinen in vergelijking met sterke adaptatiebaselines.', 'de': 'Diese Arbeit ist von einem typischen Szenario der maschinellen Übersetzung inspiriert, in dem Übersetzer In-Domain-Daten verwenden, um die Übersetzung ähnlicher oder sich wiederholender Sätze zu erleichtern. Wir stellen ein generisches Framework vor, das bei der Inferenz angewendet wird, in dem zunächst eine Teilmenge von Segmentpaaren anhand ihrer Ähnlichkeit mit den Eingabesätzen aus Trainingsdaten extrahiert wird. Diese Segmente werden dann verwendet, um die Parameter eines generischen NMT-Netzwerks dynamisch zu aktualisieren und so eine lexikalische Mikroadaptation durchzuführen. Unser Ansatz zeigt eine starke Anpassungsleistung an neue und bestehende Datensätze einschließlich Pseudo-In-Domain-Daten. Wir evaluieren unseren Ansatz anhand eines heterogenen englisch-französischen Trainingsdatensatzes, der im Vergleich zu starken Anpassungsbasislinien in allen untersuchten Bereichen einen Genauigkeitszuwachs zeigt.', 'id': 'Pekerjaan ini diinspirasi oleh skenario industri terjemahan mesin tipis di mana terjemahan menggunakan data dalam domain untuk memfasilitasi terjemahan kalimat yang sama atau mengulangi. We introduce a generic framework applied at inference in which a subset of segment pairs are first extracted from training data according to their similarity to the input sentences.  These segments are then used to dynamically update the parameters of a generic NMT network, thus performing a lexical micro-adaptation.  pendekatan kita menunjukkan prestasi adaptasi yang kuat untuk set data baru dan yang ada termasuk data pseudo dalam domain. Kami mengevaluasi pendekatan kita pada dataset latihan Inggris-Perancis heterogene menunjukkan keuntungan akurasi pada semua domain yang ditevaluasi ketika dibandingkan dengan garis dasar adaptasi yang kuat.', 'fa': 'این کار توسط یک سناریو صنعت ترجمه ماشین معمولی الهام می\u200cشود که ترجمه\u200cکنندگان از داده\u200cهای دامنی برای آسانی ترجمه\u200cهای جمله\u200cهای شبیه یا تکرار می\u200cکنند استفاده می\u200cکنند. ما یک چهارچوب عمومی را معرفی می\u200cکنیم که در آن یک زیر جفت بخش از داده\u200cهای آموزش بر اساس شبیه\u200cشان به جمله\u200cهای ورودی استخراج می\u200cشوند. سپس این بخش\u200cها برای تبدیل کردن پارامترهای شبکه NMT ژنرال استفاده می\u200cشوند، به همین دلیل یک مقایسه\u200cسازی میکروهای زبان\u200cشناسی انجام می\u200cدهند. دستور ما اجرای قابل توافق قوی برای مجموعه\u200cهای داده\u200cهای جدید و موجود را نشان می\u200cدهد که شامل داده\u200cهای pseudo در دومین است. ما روش خود را بر روی یک مجموعه اطلاعات آموزش انگلیسی و فرانسوی متفاوت ارزیابی می کنیم که در مقایسه با خطوط پایین\u200cهای قابل تغییر قابل توجه دقیق در تمام محل\u200cهای ارزیابی را نشان می\u200cدهد.', 'ko': '이 작업의 영감은 전형적인 기계 번역 업계의 장면에서 나온다. 이 장면에서 번역자는 역내 데이터를 이용하여 유사하거나 중복된 문장의 번역을 추진한다.우리는 추리에 사용되는 유니버설 프레임워크를 소개했는데, 이 프레임워크는 먼저 훈련 데이터에서 세션에 따라 입력 문장과 유사성에 따라 세션 쌍의 서브집합을 추출한다.그 다음에 이 부분들은 일반적인 NMT 네트워크의 매개 변수를 동적으로 업데이트하여 어휘의 미시적 적응을 실행하는 데 사용된다.우리의 방법은 새로운 것과 기존의 데이터 집합 (위역내 데이터 포함) 에 대해 매우 강한 적응성을 가지고 있다.우리는 이질적인 영어-프랑스어 훈련 데이터 집합에서 우리의 방법을 평가했는데, 강한 적응 기선에 비해 이 데이터 집합은 모든 평가 분야의 정확성이 향상되었다는 것을 보여 주었다.', 'sw': 'Kazi hii inahamasishwa na kituo cha kutafsiri cha mashine ambacho watafsiri wanatumia data za ndani kwa ajili ya kusaidia tafsiri ya hukumu kama hizo au kwa mara nyingine. Tunaonyesha mfumo wa msingi unaotumika katika ugonjwa ambao mfululizo wa wanandoa wa jinsia wanatengenezwa kwanza kutokana na taarifa za mafunzo kwa mujibu wa matumizi yanayofanana na matokeo hayo. Hizi vipengele vinatumika kwa nguvu upya vipengele vya mtandao wa kijamii wa NMT, kwa hiyo hufanya vizuri vya vidogo vya lexico. Hatua yetu inaonyesha ufanisi wa kuboresha upya wa data mpya na kuwepo ikiwa ni pamoja na data za ndani. Tunatathmini mbinu yetu katika seti ya mafunzo ya Kiingereza na Kifaransa yenye asili ya kibingereza zinazoonyesha mafunzo ya sahihi kwenye maeneo yote yanayothibitiwa wakati ukilinganishwa na misingi yenye nguvu ya mabadiliko.', 'af': "Hierdie werk is inspireer deur 'n tipiese masjien vertaling industrie scenario waarin vertalings gebruik word van in-domein data om vertaling van soortgelyke of herhaalde setinge te maak. Ons introduseer 'n algemene raamwerk wat toepassing is by inferensie waarin 'n subartikel van segmentpaar eerste uitgevoer word van onderwerp data volgens hulle gelykenis aan die invoer setnings. Hierdie segmente word dan gebruik om dinamies die parameters van 'n generieke NMT netwerk te opdateer, sodat 'n leksiese mikro- adaptasie uitvoer. Ons toegang vertoon sterk aanpassing effektuur na nuwe en bestaande datastelle insluitend pseudo in- domein data. Ons evalueer ons toegang op 'n heterogenee Engelse-Franse onderwerking datastel wat regverdigheid verskaf op alle evalueerde domene wanneer vergelyk word met sterke adaptasie basisline.", 'sq': 'Ky punë frymëzohet nga një skenar tipik i industrisë së përkthimit të makinave në të cilin përkthyesit përdorin të dhënat në domeni për lehtësimin e përkthimit të fjalëve të ngjashme apo përsëritjes. Ne futim një kuadër gjeneral të aplikuar në përfundim në të cilin një nëngrup çiftesh segmentesh nxirren së pari nga të dhënat e stërvitjes sipas ngjashmërisë së tyre me fjalët e hyrjes. These segments are then used to dynamically update the parameters of a generic NMT network, thus performing a lexical micro-adaptation.  Përqasja jonë demonstron performancë të fortë të përshtatjes ndaj të dhënave të reja dhe ekzistuese duke përfshirë të dhënat pseudo në domeni. Ne vlerësojmë qasjen tonë në një grup të dhënash heterogjene të trajnimit anglo-francez që tregojnë fitime të sakta në të gjitha fushat e vlerësuara kur krahasohen me linjat bazë të forta të përshtatjes.', 'tr': "Bu işi maşynyň terjime senaryýasy tarapyndan ilham alýar. Bu ýerde terjime edenler bolsa ýa-da sözleriň terjime etmesini a ňsat etmek üçin domin maglumatynda ullanyrlar. Biz çykyş etmäge uygulanan jeneral framey bilen tanyşdyrýarys. Bu bölüm çiftleri ilkinji gezek giriş sözlerine görä terjime etmekden çekilýärler. Soňra bu segmentler dinamik bir NMT network'iň parameterlerini güncellemek üçin ullanýar, şonuň üçin bir leksiýal mikro-adaptasyon etýär. Biziň ýaryşymyz täze we bar veri setirlerine pseudo-da-domain maglumatlary dahil güçli adaptasyon etkinligini görkez. Biz özümiziň ýaryşymyzy güýçli adaptasyon baseçiliklerine görä diňleýän iňlis-fransuzça öwrenmeli hereketlerde deňleýäris.", 'am': 'ይሄ ሥራ በተለየ ማሻሻሻል ትርጉም ጉዳይ ሲኒስትሪፖርት ነው፡፡ We introduce a generic framework applied at inference in which a subset of segment pairs are first extracted from training data according to their similarity to the input sentences.  በኋላም እነዚህ ክፍሎች የgeneric NMT መረብ አካላትን በማሻሻሻል ይጠቀማሉ፤ ስለዚህም ለሌክሲካዊ ሚክሮአዲስ ማድረግ ይደረጋሉ። የአዲስ እና የአሁኑን ዳታዎችን የጠንካራ አካባቢ ማድረግ እና የውጤት ዳታዎችን በዶሜን ዳታዎች ውስጥ የሚያሳያል፡፡ የኢንግሊዝና-ፈረንሳይ የፍሪስዳን ትምህርት ማድረግ ማድረግ ማድረግ ማድረጊያውን እናስተውለታለን፡፡', 'hy': 'Այս աշխատանքը ոգեշնչվում է տիպիկ մեքենային թարգմանման արդյունաբերության սցենարից, որտեղ թարգմանիչները օգտագործում են բնագավառի տվյալներ նման կամ կրկնվող նախադասությունների թարգմանման հեշտացնելու համար: Մենք ներկայացնում ենք ընդհանուր կառուցվածք, որը կիրառվում է հետևանքների ժամանակ, որտեղ սեգմենտի զույգերի ենթախումբը առաջին անգամ դուրս է հանում կրթության տվյալներից, կախված նման բաների հետ: Այնուհետև այս սեգմերները օգտագործվում են դինամիկ վերականգնելու համար ընդհանուր NMT ցանցի պարամետրերը, այսպես կատարելով լեքսիկական միկրոադապտացիա: Մեր մոտեցումը ցույց է տալիս նոր և գոյություն ունեցող տվյալների համակարգերի կարևոր ադապտացիոն արդյունքները, ներառյալ կեղծ տվյալները տիեզերքում: Մենք գնահատում ենք մեր մոտեցումը անգլերեն-ֆրանսերեն ուսումնասիրության տարբեր տվյալների համակարգում, որը ցույց է տալիս ճշգրիտ զարգացումներ բոլոր գնահատված ոլորտներում, համեմատած ուժեղ ադապտացիայի հի', 'bn': 'সাধারণ মেশিন অনুবাদ শিল্পের দৃশ্য দ্বারা এই কাজ অনুপ্রাণিত হয়েছে যেখানে অনুবাদকরা একই ধরনের অনুবাদ বা পুনরাবারের বাক্যের অনু ইনপুটের বাক্য অনুযায়ী প্রশিক্ষণের তথ্য থেকে প্রথম বিভিন্ন বিভিন্ন সংখ্যাগুলোকে প্রশিক্ষণের তথ্য থেকে বের করে আনা হয়। এরপর এই অংশগুলো জেনারিক এনএমটি নেটওয়ার্কের প্যারামিটার আপডেট করতে ব্যবহার করা হয়, যার ফলে লেক্সিক্যাল মাইক্রো-অ্যাডাপ্টেশন কর আমাদের প্রতিক্রিয়া নতুন এবং বিদ্যমান ডাটাসেটের প্রতি শক্তিশালী প্রদর্শন করছে, যার মধ্যে ডোমেইনের তথ্য রয়েছে। আমরা বিভিন্ন ইংরেজি ও ফরাসী প্রশিক্ষণের ডাটাসেটে আমাদের প্রতিযোগিতা মূল্যায়ন করি যেখানে প্রত্যেকটি মূল্যবান ডোমেনের সকল মূল্', 'az': 'Bu işlər, bənzər və tekrarlı cümlələrin tercüməsini olaraq çox asanlaşdırmaq üçün dəyişiklik bir maşın tercümə endüstri senaryosundan ilham alır. İlk dəfə segment çiftlərinin təhsil məlumatlarından istifadə edilməsi üçün istifadə edilən nümunə çerçevesini təşkil edirik. Bu segmentlər dinamik olaraq NMT a ğının parametrlərini güncelləmək üçün istifadə edilir, bu olaraq leksik mikro-adaptasiyanı təşkil edir. Yaxınlığımız yeni və mevcut verilən verilənlərə qüvvətli adaptasiya performansını göstərir. İngilizə-Fransızca təhsil verilən təhsil qutusunda təsirimizi müəyyən edirik ki, bütün təhsil edilmiş sahələrdə çox qüvvətli uyğunlaşdırma səhifələri ilə qarşılaşdığımız zaman dəyişiklik qazandığını göstərər.', 'bs': 'Ovaj rad je inspirisan tipičnim scenarijem industrije prevođenja mašin a u kojem translatori koriste podatke u domenu za olakšanje prevođenja sličnih ili ponovnih rečenica. Predstavljamo generički okvir koji se primjenjuje na infekciji u kojem su prvi dio parova segment a izvučeni iz podataka obuke prema sličnosti ulaznim rečenicama. Tada se ovi segmenti koriste za dinamički aktualiziranje parametara generične NMT mreže, tako da izvode leksičku mikro-adaptaciju. Naš pristup pokazuje jaku prilagodbu novim i postojećim podacima, uključujući pseudo podatke u domenu. Procjenjujemo naš pristup heterogeneznom kompletu podataka o obuci engleskog-francuskog, pokazujući preciznost svih procjenjenih domena u usporedbi sa jakim podacima adaptacije.', 'ca': "Aquesta obra està inspirada en un escenari típic de la indústria de traducció màquina en el qual els traductors utilitzen dades en domini per facilitar la traducció de frases similars o repetidas. Introduïm un marc genèric aplicat a la inferència en el qual un subconjunt de parelles de segments s'extraeix per primer cop de les dades d'entrenament segons la seva similitud a les frases d'entrada. Aquests segments s'utilitzen per actualitzar dinàmicament els paràmetres d'una xarxa NMT genèrica, fent així una microadaptació lèxica. El nostre enfocament demostra un fort rendiment d'adaptació a les dades noves i existents, incloent les pseudo en domini. Evaluam el nostre enfocament en un conjunt heterogène de dades d'entrenament anglès-francès mostrant guanys de precisió en tots els dominis evaluats comparats amb línies de base d'adaptació fortes.", 'et': 'See töö on inspireeritud tüüpilisest masintõlketööstuse stsenaariumist, kus tõlkijad kasutavad domeenisiseseid andmeid sarnaste või korduvate lausete tõlkimise hõlbustamiseks. Tutvustame üldist raamistikku, mida rakendatakse järeldusel, kus segmendipaaride alamhulk ekstraheeritakse esmalt treeninguandmetest vastavalt nende sarnasusele sisendlausetega. Neid segmente kasutatakse seejärel üldise NMT võrgu parameetrite dünaamiliseks ajakohastamiseks, tehes seega leksikaalse mikrokohanduse. Meie lähenemisviis näitab tugevat kohanemisvõimet uute ja olemasolevate andmekogumitega, sealhulgas pseudodomeenisiseste andmetega. Hindame oma lähenemisviisi heterogeense inglise-prantsuse koolituse andmekogumi põhjal, mis näitab täpsuse kasvu kõigis hinnatud valdkondades võrreldes tugevate kohanemise lähtejoontega.', 'fi': 'Tämä työ on saanut inspiraationsa tyypillisestä konekäännösalan skenaariosta, jossa kääntäjät käyttävät verkkotunnuksen tietoja helpottaakseen samankaltaisten tai toistuvien lauseiden kääntämistä. Esittelemme yleisluonteisen viitekehyksen, jota sovelletaan päättelyyn, jossa segmenttiparien osajoukko poimitaan ensin harjoitustiedoista sen mukaan, miten ne ovat samankaltaisia syöttölauseiden kanssa. Näitä segmenttejä käytetään dynaamisesti päivittämään geneerisen NMT-verkon parametreja, jolloin suoritetaan leksikaalinen mikrosopeutus. Lähestymistapamme osoittaa vahvaa sopeutumiskykyä uusiin ja olemassa oleviin tietokokonaisuuksiin, mukaan lukien pseudodomain-data. Arvioimme lähestymistapaamme heterogeenisestä englannin-ranskan koulutusaineistosta, joka osoittaa tarkkuuden paranemista kaikilla arvioituilla toimialoilla verrattuna vahvoihin sopeutumisperustoihin.', 'cs': 'Tato práce je inspirována typickým scénářem strojového překladu, ve kterém překladatelé využívají data v doméně pro usnadnění překladu podobných nebo opakujících se vět. Představujeme obecný rámec aplikovaný při inferenci, ve kterém je nejprve extrahována podmnožina segmentových párů z tréninkových dat podle jejich podobnosti se vstupními větami. Tyto segmenty se pak používají k dynamické aktualizaci parametrů generické NMT sítě, čímž se provádí lexikální mikroadaptace. Náš přístup demonstruje silný adaptační výkon na nové i stávající datové sady včetně pseudo-in-domain dat. Náš přístup hodnotíme na heterogenním anglicko-francouzském tréninkovém souboru, který ukazuje zvýšení přesnosti ve všech hodnocených doménách ve srovnání se silnými adaptačními základními liniemi.', 'he': 'העבודה הזאת מעוררת השראה על ידי תרחיש טיפוסי של תעשיית התרגום מכונות שבה התרגמים משתמשים במידע בתחום כדי להקל התרגום של משפטים דומים או חוזרים. אנו מציגים מסגרת גנרלית שמשתמשת בהנחה שבה תת-קבוצה של זוגות חלקים מווצאים לראשונה ממידע האימונים לפי הדמיון שלהם למשפטי הכניסה. These segments are then used to dynamically update the parameters of a generic NMT network, thus performing a lexical micro-adaptation.  Our approach demonstrates strong adaptation performance to new and existing datasets including pseudo in-domain data.  אנו מעריכים את הגישה שלנו על קבוצת נתונים האימונים האנגלית-צרפתית היטרוגנית שמראה את הרווחים מדויקים בכל התחומים המערכים בהשוואה לקווי בסיס התאמה חזקים.', 'ha': "Wannan aikin aka buɗa shi da wani fassarar masu fassarar da mashine na farko, wurin da fassarar za'a yi amfani da data cikin-Domen dõmin ya sauƙa ƙara fassarar da kamar ko da za'a sauya. Tuna fara wani firam na dama wanda aka yi amfani da shi a kasa-ƙaranci, a cikinsa ana samar da jama'a biyu masu fitarwa farko daga shirin data da ke daidaita zuwa tsarin da aka shigar. @ info: whatsthis MataimakinMu na nuna mafiya adadin adadi zuwa tsari na yanzu da ke jira, kamar ceudo da data cikin guda. Tuna ƙaddara hanyoyinmu a kan danna na tsari na Ingiriya-Faransa wanda ya taɓa da sauri, yana nũna ma'anar taƙaita a kan duk kammala da aka ƙaddara idan an sammenliki danne mai ƙarfi da adaptation.", 'sk': 'To delo navdihuje tipičen scenarij strojnega prevajanja, v katerem prevajalci uporabljajo domenske podatke za lažje prevajanje podobnih ali ponavljajočih se stavkov. Predstavljamo generični okvir, ki se uporablja pri sklepanju, v katerem se podmnožica parov segmentov najprej izvleče iz podatkov o usposabljanju glede na njihovo podobnost z vhodnimi stavki. Ti segmenti se nato uporabljajo za dinamično posodobitev parametrov generičnega NMT omrežja, s čimer se izvede leksikalna mikroprilagoditev. Naš pristop dokazuje močno prilagajanje novim in obstoječim naborom podatkov, vključno s psevdo podatki v domeni. Naš pristop ocenjujemo na podlagi heterogenega angleško-francoskega nabora podatkov o usposabljanju, ki kaže povečanje natančnosti na vseh ocenjenih področjih v primerjavi z močnimi osnovnimi vrsticami prilagajanja.', 'jv': 'This job is enthusiastic by a Typ device translation manus scenaro in whose translation make use of in-domain data for refining translation of like or recurring words. Awak dhéwé nggawe sistem sing paling-alaman sing nggawe nêmên karo mbengoké sekondi nggawe section We method displacement strength Awak dhéwé éntuk dhéwé ngerasakno karo data sing ngengguwisi-Perancis kuwi kesempatan kanggo ngerasakno pangan kuwi, nik awak dhéwé ngerasakno kanggo ngerasakno iki.', 'bo': 'This work is inspired by a typical machine translation industry scenario in which translators make use of in-domain data for facilitating translation of similar or repeating sentences. ང་ཚོས་རྣམ་པ་ལྟ་བུའི་མཐུན་རྐྱེན་དུ་འཇུག་སྤྱོད་པའི་རྣམ་གྲངས་གཞུང་ཞིག་གསལ་བྱེད་ཀྱི་ཡོད། These segments are then used to dynamically update the parameters of a generic NMT network, thus performing a lexical micro-adaptation. ང་ཚོའི་གཟུགས་སྐོར་གྱིས་གསརཔ་དང་གནས་ཡུལ་སྒྲིག་ཆ་སྒྲིག་འཛུགས་ཀྱི་གྲ་སྒྲིག་འགོད་མང་ཙམ་སྟོན་པ་ཡིན། ང་ཚོས་དབྱིན་ཡིག་གཟུགས་ཕྱོགས་སྐོར་ལས་ང་ཚོའི་ཐབས་ལམ་ལ་ཞིབ་བྱེད་ཀྱི་ཡོད།'}
{'en': 'Efficient Bilingual Generalization from Neural Transduction Grammar Induction', 'ar': 'التعميم ثنائي اللغة الفعال من الاستقراء النحوي للتنقل العصبي', 'fr': "Généralisation bilingue efficace grâce à l'induction de la grammaire par transduction", 'pt': 'Generalização Bilíngue Eficiente da Indução Gramática de Transdução Neural', 'es': 'Generalización bilingüe eficiente a partir de la inducción gramatical de transducción neuronal', 'ja': '神経伝達文法誘導からの効率的なバイリンガル一般化', 'zh': '从神经转导语法归高效双语泛化', 'hi': 'तंत्रिका ट्रांसडक्शन व्याकरण प्रेरण से कुशल द्विभाषी सामान्यीकरण', 'ru': 'Эффективное двуязычное обобщение в результате индукции грамматики нейронной трансдукции', 'ga': 'Ginearálú Éifeachtach Dátheangach ó Ionduchtú Gramadaí Neural Transduction', 'hu': 'Hatékony kétnyelvű generálás neurális transzducciós nyelvtani indukcióból', 'el': 'Αποτελεσματική δίγλωσση γενίκευση από την επαγωγή γραμματικής νευρωνικής μεταγωγής', 'ka': 'ნეიროლური გადატანსტუქციის გრამარის ინდექციისგან ეფექტიური მეორე გენერალაცია', 'kk': 'Нейрондық аудару грамматтарының индукциясынан ең көлемі екі жасау', 'lt': 'Veiksminga dvikalbė generalizacija, gauta iš nervų transduccijos gramos indukcijos', 'it': "Generalizzazione bilingue efficiente dall'induzione grammaticale della trasduzione neurale", 'mk': 'Ефикасна двојазична генерализација од индукција на грама за нервна трансдукција', 'ms': 'Jeneralisasi Bilingual Efisien dari Induksi Grammar Transduction Neural', 'ml': 'നെയുറല്\u200d ട്രാന്\u200dസങ്കേഷന്\u200d ഗ്രാമാര്\u200d നിര്\u200dണ്ണയിക്കുന്നതില്\u200d നിന്നുള്ള ബൈലിങ്കുള്ള ജനറലേഷന്\u200d', 'mt': 'Ġeneralizzazzjoni Bilingwali Effiċjenti mill-Induzzjoni Grammatika tat-Traduzzjoni Newrali', 'mn': 'Тархины шилжүүлэлтийн дамжуулалтын үр дүнтэй хоёр дамжуулалт', 'no': 'Effektivt bilenguelt generering frå nøyralt overføring', 'pl': 'Skuteczna dwujęzyczna generalizacja z indukcji gramatyki transdukcji neuronowej', 'ro': 'Generalizarea bilingvă eficientă din inducția gramaticală transducție neurală', 'sr': 'Efikasna dvostruka generalizacija iz neuralne prevode', 'si': 'ප්\u200dරශ්ණ ද්\u200dරව්\u200dයාත්මක සාමානය', 'so': 'Generalization from Neural Transfer Grammar Induction', 'ta': 'Efficient Bilingual Generalization from Neural Transduction Grammar Induction', 'ur': 'نیورال ٹرانسڈوکیشن گرم انڈاکٹ سے فعال دویلینگل جرانیل کرنا', 'sv': 'Effektiv tvåspråkig generalisering från neural transduktion grammatisk induktion', 'uz': 'Name', 'vi': 'Hiệu quả hóa giải phóng từ Truyền hình thần kinh', 'bg': 'Ефективна двуезична генерализация от граматична индукция на невралната трансдукция', 'nl': 'Efficiënte tweetalige generalisering van neuronale transductie grammatica inductie', 'da': 'Effektiv tosproget generalisering fra neural transduktion grammatisk induktion', 'hr': 'Učinjena dvostruka generalizacija iz gravitarne indukcije neurološke prenošenja', 'de': 'Effiziente zweisprachige Generalisierung durch Induktion der Grammatik der Neuralen Transduktion', 'id': 'Generalisasi Bilingual Efisien dari Indukti Grammar Transduksi Neural', 'ko': '신경전도 문법 귀납에 기초한 이중 언어의 효율적인 범화', 'fa': 'ژنرال\u200cسازی دوگانه\u200cای تاثیر از تغییر اندازه\u200cگیری عصبی', 'sw': 'Utengenezaji wa lugha yenye ufanisi kutoka katika Uoneshaji wa Tamko wa Uhamiaji wa Kifaransa', 'tr': 'smooth scrolling', 'af': 'Effektiewe Bilinguele Generalisasie van Neural Transduction Grammar Induksie', 'sq': 'Gjeneralizim i Efektshëm dygjuhësor nga induktimi i Gramave të Transdukcionit Neural', 'am': 'ቋንቋዎች', 'hy': 'Էֆեկցիոնալ երկլեզու գեներալիզացիա նյարդային հաղորդակցման գրամային ինդուկցիայից', 'bn': 'নিউরাল ট্রান্সট্রান্সট্রান্সকশন গ্রামার নির্দেশ থেকে কার্যকর বালিঙ্গুয়েল সাধারণ', 'ca': "Generalització bilingüe eficient de l'inducció gramàtica de la transducció neuronal", 'cs': 'Efektivní dvojjazyčná generalizace z indukce gramatiky neuronové transdukce', 'et': 'Tõhus kahekeelse generaliseerumine neurotransduktsiooni grammatika induktsioonist', 'fi': 'Tehokas kaksikielinen yleistyminen neurotransduktion kielioppien induktiosta', 'az': 'Nöral Transduksyon Grammar Induksyonundan İkinci İkinci Generalizasyon', 'bs': 'Učinjena dvostruka generalizacija iz neuralne prevode', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Učinkovita dvojezična generalizacija zaradi indukcije slovnice nevralne transdukcije', 'he': 'הגנרליזציה משולשת יעילה מתחילת גרמה', 'ha': 'KCharselect unicode block name', 'bo': 'ནུས་པ་ཚོད་བྱུང་བའི་སྐྱེལ་ཚད་གཞུང་སྐྱེལ་བ'}
{'en': 'We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, which we hypothesize that can efficiently learn complex biparse tree patterns. Our work distinguishes from sequential attention-based models, which are more traditionally found in neural machine translation (NMT) in three aspects. First, our ', 'pt': 'Apresentamos (1) uma nova estrutura de rede neural para modelagem bilíngue de pares de frases que permite a captura eficiente de relacionamento bilíngue por meio de composição biconstituinte, (2) o conceito de biparsing de rede neural, que se aplica não apenas à tradução automática (MT), mas também a uma variedade de outras áreas de pesquisa bilíngües, e (3) o conceito de um loop de treinamento biparsing-backpropagation, que nós hipotetizamos que pode aprender com eficiência padrões complexos de árvore biparse. Nosso trabalho se diferencia dos modelos sequenciais baseados em atenção, que são mais tradicionalmente encontrados na tradução automática neural (NMT) em três aspectos. Primeiro, nosso modelo impõe restrições de composição. Em segundo lugar, nosso modelo tem um espaço de busca menor em termos de descoberta de relacionamentos bilíngues a partir de pares de frases bilíngues. Terceiro, nosso modelo produz árvores biparse explícitas, que permitem uma análise transparente de erros durante a avaliação e restrições externas de árvores durante o treinamento.', 'fr': "Nous présentons (1) une nouvelle structure de réseau neuronal pour la modélisation bilingue de paires de phrases qui permet une capture efficace d'une relation bilingue via une composition biconstituante, (2) le concept de bianalyse de réseau neuronal, qui s'applique non seulement à la traduction automatique (MT) mais également à une variété d'autres domaines de recherche bilingues, et (3) le concept d'une boucle d'apprentissage biparsing-rétropropagation, dont nous supposons qu'elle peut apprendre efficacement des motifs d'arbres biparses complexes. Notre travail se distingue des modèles séquentiels basés sur l'attention, que l'on retrouve plus traditionnellement dans la traduction automatique neuronale (NMT) sous trois aspects. Tout d'abord, notre modèle impose des contraintes de composition. Deuxièmement, notre modèle dispose d'un espace de recherche plus restreint pour découvrir les relations bilingues à partir de paires de phrases bilingues. Troisièmement, notre modèle produit des arbres biparses explicites, qui permettent une analyse transparente des erreurs pendant l'évaluation et des contraintes d'arbre externes pendant la formation.", 'ar': 'نقدم (1) بنية شبكة عصبية جديدة للنمذجة ثنائية اللغة لأزواج الجمل التي تسمح بالتقاط فعال للعلاقة ثنائية اللغة عبر تكوين ثنائي التكوين ، (2) مفهوم الشبكة العصبية ثنائية النطاق ، والتي لا تنطبق فقط على الترجمة الآلية (MT) ولكن أيضًا على مجموعة متنوعة من مجالات البحث ثنائية اللغة الأخرى ، و (3) مفهوم حلقة التدريب على انتشار ثنائي الأبعاد ، والتي نفترض أنها يمكن أن تتعلم بكفاءة أنماط الأشجار المعقدة ثنائية الأقطاب. يميز عملنا عن النماذج المتسلسلة القائمة على الانتباه ، والتي توجد تقليديًا في الترجمة الآلية العصبية (NMT) في ثلاثة جوانب. أولاً ، يفرض نموذجنا قيودًا تركيبية. ثانيًا ، يحتوي نموذجنا على مساحة بحث أصغر من حيث اكتشاف العلاقات ثنائية اللغة من أزواج الجمل ثنائية اللغة. ثالثًا ، ينتج نموذجنا أشجارًا ثنائية الأبعاد واضحة ، والتي تتيح تحليلًا شفافًا للخطأ أثناء التقييم وقيود الشجرة الخارجية أثناء التدريب.', 'es': 'Presentamos (1) una estructura de red neuronal novedosa para el modelado bilingüe de pares de oraciones que permite la captura eficiente de la relación bilingüe a través de la composición biconstituyente, (2) el concepto de bianálisis de redes neuronales, que se aplica no solo a la traducción automática (MT) sino también a una variedad de otros áreas de investigación bilingües, y (3) el concepto de un ciclo de entrenamiento de biparsing-retropropagación, que suponemos que puede aprender de manera eficiente patrones de árboles biparsos complejos. Nuestro trabajo se distingue de los modelos secuenciales basados en la atención, que se encuentran más tradicionalmente en la traducción automática neuronal (NMT) en tres aspectos. En primer lugar, nuestro modelo aplica restricciones de composición. En segundo lugar, nuestro modelo tiene un espacio de búsqueda más pequeño en términos de descubrir relaciones bilingües a partir de pares de oraciones bilingües. En tercer lugar, nuestro modelo produce árboles biparse explícitos, que permiten el análisis transparente de errores durante la evaluación y las restricciones externas de los árboles durante el entrenamiento.', 'hi': 'हम (1) वाक्य जोड़े के द्विभाषी मॉडलिंग के लिए एक उपन्यास तंत्रिका नेटवर्क संरचना पेश करते हैं जो द्विआधारी संरचना के माध्यम से द्विभाषी संबंधों के कुशल कैप्चरिंग की अनुमति देता है, (2) तंत्रिका नेटवर्क द्विपार्सिंग की अवधारणा, जो न केवल मशीन अनुवाद (एमटी) पर लागू होती है, बल्कि विभिन्न प्रकार के अन्य द्विभाषी अनुसंधान क्षेत्रों पर भी लागू होती है, और (3) एक द्विपार्सिंग-बैकप्रोपेगेशन प्रशिक्षण लूप की अवधारणा,  जो हम परिकल्पना है कि कुशलतासे जटिल biparse पेड़ पैटर्न सीख सकते हैं. हमारा काम अनुक्रमिक ध्यान-आधारित मॉडल से अलग है, जो पारंपरिक रूप से तीन पहलुओं में तंत्रिका मशीन अनुवाद (एनएमटी) में पाए जाते हैं। सबसे पहले, हमारा मॉडल रचनात्मक बाधाओं को लागू करता है। दूसरा, हमारे मॉडल में द्विभाषी वाक्य जोड़े से द्विभाषी संबंधों की खोज के मामले में एक छोटा खोज स्थान है। तीसरा, हमारा मॉडल स्पष्ट द्विपार्स पेड़ों का उत्पादन करता है, जो प्रशिक्षण के दौरान मूल्यांकन और बाहरी पेड़ बाधाओं के दौरान पारदर्शी त्रुटि विश्लेषण को सक्षम करता है।', 'ja': '我々は、(1)バイコン成分組成を介してバイリンガル関係を効率的に取り込むことを可能にする文章ペアのバイリンガルモデリングのための新規のニューラルネットワーク構造、(2)機械翻訳(MT)だけでなく、他の様々なバイリンガル研究領域にも適用されるニューラルネットワークバイパーシングの概念、(3)複雑なバイパーシングの木のパターンを効率的に学習できるバイパーシングバックプロパゲーショントレーニングループの概念を紹介する。私たちの研究は、3つの側面でより伝統的にニューラル機械翻訳（ NMT ）に見られる順次注目ベースのモデルと区別しています。まず、私たちのモデルは構成的制約を強制します。第二に、私たちのモデルは、バイリンガル文のペアからバイリンガル関係を発見するという点で、より小さな検索スペースを持っています。第三に、私たちのモデルは明示的な二分木を生成し、評価中の透明なエラー分析とトレーニング中の外部ツリー制約を可能にします。', 'zh': '余言(1)一句双语建模之新型神经网络结构,当结构许以双构件获双语,(2)神经网络双解析之名,非特机器翻译(MT)也,亦宜于诸双语究领,及(3)双解析 -反传习循环之概。  设此可以效学杂双面树式。 臣等事与序意不同,后者三存神经机器翻译(NMT)中。 先是,我强制行约束。 其次,双语句双语小索空间。 其三曰,吾形生显式双解析树,评中明差,练中成外。', 'ru': 'Мы вводим (1) новую структуру нейронной сети для двуязычного моделирования пар предложений, которая позволяет эффективно захватывать двуязычные отношения через биконститутивный состав, (2) концепцию бипарсинга нейронной сети, которая применяется не только к машинному переводу (МП), но и к множеству других двуязычных областей исследований, и (3) концепцию учебного цикла бипарсинга-обратного распространения, которую мы гипотетируем, что можно эффективно изучать сложные бипарсионные шаблоны деревьев. Наша работа отличает от последовательных, основанных на внимании моделей, которые более традиционно встречаются в нейронном машинном переводе (НМП) в трех аспектах. Во-первых, наша модель обеспечивает соблюдение композиционных ограничений. Во-вторых, наша модель имеет меньшее пространство поиска с точки зрения обнаружения двуязычных отношений из двуязычных пар предложений. В-третьих, наша модель производит явные бипарсионные деревья, которые обеспечивают прозрачный анализ ошибок во время оценки и внешние ограничения дерева во время обучения.', 'ga': 'Tugaimid isteach (1) struchtúr líonra néarúil nua le haghaidh samhaltú dátheangach de phéirí abairtí a cheadaíonn caidreamh dátheangach a ghabháil go héifeachtach trí chomhdhéanamh dé-chomhdhéanta, (2) coincheap déphearsála líonra néaraigh, a bhaineann ní hamháin le haistriúchán meaisín (MT) ach freisin maidir le raon de réimsí taighde dátheangacha eile, agus (3) an coincheap de lúb traenála biparsing-backpropagation, a hypothesize againn gur féidir a fhoghlaim go héifeachtach patrúin crann dé-parse casta. Déanann ár gcuid oibre idirdhealú ó mhúnlaí seicheamhacha aird-bhunaithe, atá le fáil go traidisiúnta in aistriúchán meaisín néarach (NMT) i dtrí ghné. Ar an gcéad dul síos, cuireann ár múnla srianta comhdhéanamh i bhfeidhm. Ar an dara dul síos, tá spás cuardaigh níos lú ag ár múnla maidir le caidrimh dhátheangacha a fháil amach ó phéirí abairtí dátheangacha. Ar an tríú dul síos, táirgeann ár múnla crainn dhépharse follasacha, a chumasaíonn anailís thrédhearcach earráide le linn meastóireachta agus srianta crann seachtracha le linn oiliúna.', 'hu': 'Bevezetjük (1) a mondatpárok kétnyelvű modellezéséhez szükséges új neurális hálózati struktúrát, amely lehetővé teszi a kétnyelvű kapcsolatok hatékony rögzítését a bikonstituens kompozíció segítségével, (2) az neurális hálózati kétnyelvű kétnyelvű kétnyelvű kutatási területek fogalmát, és (3) a kétnyelvű-visszaterjedési tréninghurok fogalmát, Amit feltételezünk, hogy hatékonyan tanulhatnak komplex kétpáros fa mintákat. Munkánk megkülönböztet a szekvenciális figyelem alapú modellektől, amelyek hagyományosabban három szempontból megtalálhatók a neurális gépi fordításban (NMT). Először is, a modellünk kényszeríti a kompozíciós korlátozásokat. Másodszor, modellünk kisebb keresési térrel rendelkezik a kétnyelvű mondatpárokból származó kétnyelvű kapcsolatok felfedezésére. Harmadszor, modellünk kifejezetten kétpáros fákat állít elő, amelyek lehetővé teszik az átlátható hibaelemzést az értékelés során és a külső fakorlátozások az edzés során.', 'ka': 'ჩვენ (1) ახალი ნეიროლური ქსელის სტრუქტურაციას, რომელიც მხოლოდ მაქსინური გარგება (MT) მხოლოდ სხვადასხვა მეტსახელური შესწავლობის მსოფლიოდ ეფექტიური გარგება, და (3) მეტსახელური შესწავლობის კონცექტურაციის კონცექტურაციას, რომელიც ჩვენ ჰიპოტესტიზებთ, რომელიც შეგვიძლია ეფექციურად დავისწავლოთ კომპლექსიკური ბიოპასტის შაბლოები. ჩვენი სამუშაო განსხვავება სეკენტიური დაახლოებით მოდელებიდან, რომლებიც უფრო ტრადიციურად აღმოჩენიან ნეიროლური მაქინის გარგუნებაში (NMT) სამი ადექტში პირველად, ჩვენი მოდელი კომპოზიციონალური დარჩენება. მეორე, ჩვენი მოდელეში უფრო პატარა საძებო სივრცე აქვს ორიენგური შესახებ ორიენგური შესახებ. მესამე, ჩვენი მოდელი გამოიყენება განსაკუთრებული ბიოპასტის ხეები, რომლებიც შესაძლებელია განსაკუთრებული შეცდომის ანალიზაცია განსაკუთრებულებაში და გარეშე ხე', 'el': 'Παρουσιάζουμε (1) μια νέα δομή νευρωνικού δικτύου για τη δίγλωσση μοντελοποίηση ζευγαριών προτάσεων που επιτρέπει την αποτελεσματική καταγραφή δίγλωσσης σχέσης μέσω της διγλωσσικής σύνθεσης, (2) την έννοια της διπολικότητας νευρωνικών δικτύων, η οποία ισχύει όχι μόνο για τη μηχανική μετάφραση (ΜΤ) αλλά και για μια ποικιλία άλλων δίγλωσσων ερευνητικών τομέων, και (3) την έννοια ενός βρόχου εκπαίδευσης διπολικότητας-αντίστροφης διάδοσης, Το οποίο υποθέτουμε ότι μπορεί αποτελεσματικά να μάθει πολύπλοκα διπολικά μοτίβα δέντρων. Η εργασία μας διακρίνει από τα διαδοχικά μοντέλα που βασίζονται στην προσοχή, τα οποία βρίσκονται πιο παραδοσιακά στη νευρωνική μηχανική μετάφραση (NMT) σε τρεις πτυχές. Πρώτον, το μοντέλο μας επιβάλλει περιορισμούς σύνθεσης. Δεύτερον, το μοντέλο μας έχει μικρότερο χώρο αναζήτησης όσον αφορά την ανακάλυψη δίγλωσσων σχέσεων από δίγλωσσα ζεύγη προτάσεων. Τρίτον, το μοντέλο μας παράγει ρητά διπλάσια δέντρα, τα οποία επιτρέπουν διαφανή ανάλυση σφαλμάτων κατά την αξιολόγηση και εξωτερικούς περιορισμούς δέντρων κατά τη διάρκεια της εκπαίδευσης.', 'it': "Introduciamo (1) una nuova struttura di rete neurale per la modellazione bilingue delle coppie di frasi che consente di catturare efficacemente la relazione bilingue tramite composizione bicostituente, (2) il concetto di biparsing della rete neurale, che si applica non solo alla traduzione automatica (MT) ma anche a una varietà di altre aree di ricerca bilingue, e (3) il concetto di un ciclo di formazione biparsing-backpropagation, che ipotizziamo in grado di apprendere in modo efficiente complessi modelli di alberi bipari. Il nostro lavoro si distingue dai modelli sequenziali basati sull'attenzione, che si trovano più tradizionalmente nella traduzione automatica neurale (NMT) in tre aspetti. In primo luogo, il nostro modello impone vincoli compositivi. In secondo luogo, il nostro modello ha uno spazio di ricerca più piccolo in termini di scoprire relazioni bilingue da coppie di frasi bilingue. In terzo luogo, il nostro modello produce alberi bipari espliciti, che consentono un'analisi trasparente degli errori durante la valutazione e vincoli esterni degli alberi durante l'allenamento.", 'kk': 'Біз (1) екі тілді тілді қатынасын екі тілді түрлендіру үшін романдық невралды желінің құрылымын таңдаймыз. Бұл екі тілді қатынасын екі тілді құрылымыз арқылы, 2) невралдық желінің бипарсациялауының концепциясын таңдаймыз. Бұл тек компьютердің аударымына емес (MT), сондай-ақ басқа екі тілді зерт Біз оны тәжірибедік түрде комплекс бұтақ үлгілерін үйрене аламыз. Біздің жұмысамыз кейінгі назар негіздеген үлгілерден айырылады. Олар үш аспекте невралдық машинаның аудармасында (NMT) әдімгі түрде табылады. Біріншіден, біздің үлгіміз сәйкестік шектеулерді орындайды. Екіншіден, біздің үлгімізде екі тіл қатынасын табу үшін кіші іздеу орын бар. Үшіншіден, біздің үлгіміз таңдау ағаштарды құрады. Бұл оқыту кезінде мөлдірлік қатенің анализациясы және сыртқы ағаш шектеулері болады.', 'mk': 'Ние воведуваме (1) нова структура на нервната мрежа за двојно моделирање на парови на реченици, која овозможува ефикасно заземање на двојно-јазичниот однос преку двојно-конституционална композиција, (2) концептот на двојно-преработка на нервната мрежа, кој се однесува не само на машински превод (МТ), туку и на различни други двојно-јазични истражувачки област Која ја хипотезираме дека може ефикасно да научи комплексни двопарзни шеми на дрвјата. Нашата работа се разликува од секвенцијалните модели базирани на внимание, кои се потрадиционално пронајдени во преводот на невралните машини (НМТ) во три аспекти. Прво, нашиот модел ги спроведува композициските ограничувања. Второ, нашиот модел има помал простор за пребарување во поглед на откривање двојјазични односи од двојјазични реченици парови. Трето, нашиот модел произведува експлицитни двоперасни дрвја, кои овозможуваат транспарентна анализа на грешки за време на проценката и надворешни ограничувања на дрвјата за време на обуката.', 'lt': 'Įdiegiame (1) naują dvikalbio sakinių poros modeliavimo nervų tinklo struktūrą, leidžiančią veiksmingai užfiksuoti dvikalbį ryšį dvikalbiu būdu, 2) dvikalbio nervų tinklo apdorojimo sąvoką, kuri taikoma ne tik mašininiam vertimui (MT), bet ir įvairioms kitoms dvikalbio mokslinių tyrimų sritims, ir (3) dvikalbio ir atgalinio dauginimo mokymo grandinės sąvoką, - kurią mes hipotezuojame, kad galima veiksmingai išmokti sudėtingų dviejų rūšių medžių modelių. Mūsų darbas skiriasi nuo nuoseklių dėmesiu pagrįstų modelių, kurie tradiciškai randami nervinių mašin ų vertimo (NMT) trijuose aspektuose. Pirma, mūsų modelis užtikrina sudėties apribojimus. Antra, mūsų modelis turi mažesnę paieškos erdvę nustatant dvikalbius santykius iš dvikalbių sakinių poros. Trečia, mūsų modelis gamina aiškius dviejų rūšių medžius, kurie leidžia skaidrią klaidų analizę vertinimo metu ir išorinius medžių apribojimus mokymo metu.', 'ms': 'Kami memperkenalkan (1) struktur rangkaian saraf baru untuk pemodelan dua bahasa pasangan kalimat yang membolehkan menangkap hubungan dua bahasa secara efisien melalui komposisi dua bahasa, (2) konsep pembelajaran rangkaian saraf, yang berlaku tidak hanya untuk terjemahan mesin (MT) tetapi juga untuk berbagai kawasan penyelidikan dua bahasa lain, dan (3) konsep gelung latihan pembelajaran-pembelajaran dua bahasa belakang, Yang kita hipotesis yang boleh mempelajari corak pokok biparse kompleks secara efisien. Kerja kami membezakan dari model yang berdasarkan perhatian secara urutan, yang lebih tradisional ditemui dalam terjemahan mesin saraf (NMT) dalam tiga aspek. Pertama, model kita memaksa keterangan komposisi. Kedua, model kita mempunyai ruang gelintar yang lebih kecil dalam terma penemuan hubungan dua bahasa dari pasangan kalimat dua bahasa. Ketiga, model kita menghasilkan pokok biparse secara eksplicit, yang membolehkan analisis ralat yang transparan semasa penilaian dan batasan pokok luaran semasa latihan.', 'ml': '(1) വാക്കുകളുടെ രണ്ടു ഭാഷകളുടെ മാതൃകയ്ക്ക് വേണ്ടി ന്യൂറല്\u200d നെറ്റല്\u200d നെറ്റ്റര്\u200d നെറ്റര്\u200d സ്റ്റോര്\u200dട്ടാര്\u200dക്ക് നിര്\u200dമ്മിക്കുന്നു. അത് രണ്ടു ഭാഷകളുടെ ബന്ധം സാധ്യതയോടെ പിടിക്കാന്\u200d അനുവദിക്കുന്നു; (2) ന്യൂറല്\u200d നെറ്റ ഞങ്ങള്\u200dക്ക് വേണ്ടിയുള്ള സങ്കീര്\u200dണ്ണമായ വൃക്ഷത്തിന്റെ മാതൃകങ്ങള്\u200d പഠിക്കാന്\u200d കഴിയുന്നു നമ്മുടെ ജോലി മൂന്നു ഭാഗങ്ങളില്\u200d നിന്നും ശ്രദ്ധയോടെ അടിസ്ഥാനമായ മോഡലുകളില്\u200d നിന്നും വ്യത്യസ്തമാകുന്നു. ആദ്യം, നമ്മുടെ മോഡലിന്\u200dറെ ആന്\u200dഡോര്\u200dട്ടില്\u200d കൂടുതല്\u200d നിര്\u200dബന്ധങ്ങള്\u200d. Second, our model has a smaller search space in terms of discovering bilingual relationships from bilingual sentence pairs.  മൂന്നാമത്, നമ്മുടെ മോഡല്\u200d പ്രത്യക്ഷമായ ബൈപാര്\u200dസ് വൃക്ഷങ്ങള്\u200d ഉണ്ടാക്കുന്നു. അത് പരിശീലിക്കുമ്പോള്\u200d സ്വകാര്യ തെറ്റുകള്\u200d അന്വ', 'mt': 'Aħna nintroduċu (1) struttura ġdida tan-netwerk newrali għall-immudellar bilingwi ta’ pari ta’ sentenzi li tippermetti qbid effiċjenti tar-relazzjoni bilingwi permezz ta’ kompożizzjoni bikostitwita, (2) il-kunċett ta’ biparsing tan-netwerk newrali, li japplika mhux biss għat-traduzzjoni tal-magni (MT) iżda wkoll għal varjetà ta’ oqsma ta’ riċerka bilingwi oħra, u (3) il-kunċett ta’ ċiklu ta’ taħriġ ta’ biparsing-backpropa ) li nippreżentaw li jistgħu jitgħallmu b’mod effiċjenti mudelli kumplessi ta’ siġar biparsa. Ix-xogħol tagħna jiddistingwi minn mudelli sekwenzjali bbażati fuq l-attenzjoni, li jinsabu aktar tradizzjonalment fit-traduzzjoni tal-magni newrali (NMT) fi tliet aspetti. L-ewwel nett, il-mudell tagħna jinforza restrizzjonijiet tal-kompożizzjoni. It-tieni nett, il-mudell tagħna għandu spazju ta’ tiftix iżgħar f’termini ta’ skoperta ta’ relazzjonijiet billingwi minn pari ta’ sentenzi billingwi. It-tielet, il-mudell tagħna jipproduċi siġar biparsi espliċiti, li jippermettu analiżi trasparenti tal-iżbalji matul l-evalwazzjoni u restrizzjonijiet esterni tas-siġar matul it-taħriġ.', 'mn': 'Бид (1) хоёр хэлний моделлингийн шинэ мэдрэлийн сүлжээний бүтэц бий болгодог. Энэ нь хоёр хэлний харилцааны үр дүнтэй холбоотой холбоотой, 2) мэдрэлийн сүлжээний бипаралингийн ойлголтыг бий болгодог. Бид үүнийг бүтээмжтэй модны хэлбэрийг сурах боломжтой гэж боддог. Бидний ажил дараагийн анхаарлын төлөвлөгөөтэй загвараас ялгаатай. Энэ нь мэдрэлийн машин хөгжүүлэлт (NMT) 3 талаар илүү уламжлалтай байдаг. Эхлээд бидний загвар бүтээлч хязгаарыг хүргэж чадна. Хоёрдугаарт, бидний загвар хоёр хэл хэл хоорондын хоорондын хоорондын хоорондын хоорондын хоорондын хоорондын хоорондын хоорондын хоорондын хайлтын орон зай байдаг. Гурав дахь, бидний загвар нь тодорхой хоёр хуваагдах модыг бий болгодог. Энэ нь оюутнуудын үед тодорхой алдааны шинжилгээ болон гадаад модын хязгаарлалт болох боломжтой.', 'no': 'Vi introduserer (1) ein ny neuralnettverksstruktur for bilinguelt modellering av setningar par som tillater effektivt henting av bilinguelt forhold gjennom biconstituent samansetting, (2) konsepten av biparsing av neuralnettverk, som gjeld ikkje berre for maskinsomsetjing (MT), men også for fleire andre bilinguelt forskningsområde, og (3) konsepten av ein biparsing-backpropagasjonsøvingsloop, Det vi hypotiserer som kan lære komplekse biparseringsmønsterelement. Arbeidet vårt forskjeller frå sekvensiske oppmerksbaserte modeller, som er tradisjonell funne i omsetjinga av neuralmaskina (NMT) i tre aspektar. Først, modellen vårt køyrer komposisjonsbegrensningar. Andre, modellen vårt har eit mindre søkjemodus i uttrykk av to språkelige forhold frå to språkelige setningar. Tredje, modellen vårt produserer eksplisitt biparseringstrær, som aktiverer gjennomsiktige feilanalyser under evaluering og eksterne tråbegrensningar under opplæring.', 'ro': 'Introducem (1) o nouă structură de rețea neurală pentru modelarea bilingvă a perechilor de propoziții care permite captarea eficientă a relației bilingve prin compoziția biconstituentă, (2) conceptul de biparsing rețea neurală, care se aplică nu numai traducerii automate (MT), ci și unei varietăți de alte domenii de cercetare bilingvă, și (3) conceptul unei bucle de formare biparsing-backpropagation, Care presupunem că pot învăţa în mod eficient modele complexe de copaci bipari. Lucrarea noastră se deosebește de modelele secvențiale bazate pe atenție, care se regăsesc mai tradițional în traducerea automată neurală (NMT) în trei aspecte. În primul rând, modelul nostru impune constrângeri compoziționale. În al doilea rând, modelul nostru are un spațiu de căutare mai mic în ceea ce privește descoperirea relațiilor bilingve din perechile de propoziții bilingve. În al treilea rând, modelul nostru produce arbori bipari expliciți, care permit analiza transparentă a erorilor în timpul evaluării și constrângerile externe ale arborilor în timpul antrenamentului.', 'sr': 'Predstavljamo (1) novu strukturu neuralne mreže za dvojezičku modelizaciju parova rečenica koja omogućava efikasno uhvatiti dvojezičku vezu putem dvojezičkog sastanka, 2) koncept biparsiranja neuralne mreže, koji se odnosi ne samo na prevod uređaja (MT), već i na razne druge dvojezičke istraživačke oblasti, i 3) koncept obuke za biparsing-backpropagaciju, Što smo hipotezirali da može učiti kompleksno biparsiranje drveta. Naš rad se razlikuje od sekvencijskih modela na osnovu pažnje, koji su tradicionalnije pronađeni u prevodu neuralne mašine (NMT) na tri aspekta. Prvo, naš model primjenjuje kompozicijske ograničenje. Drugo, naš model ima manji prostor pretraživanja u smislu otkrivanja dvojezičkih odnosa iz dva rečenica. Treće, naš model proizvodi jasno dvoparsiranje drveća, koje omogućavaju transparentnu analizu grešaka tokom procjene i vanjskih ograničenja drveta tokom treninga.', 'pl': 'Wprowadzamy (1) nową strukturę sieci neuronowej do modelowania dwujęzycznego par zdań, która umożliwia efektywne uchwycenie relacji dwujęzycznych za pomocą składu dwujęzycznego, (2) koncepcję dwujęzycznego dwujęzycznego sieci neuronowej, która ma zastosowanie nie tylko do tłumaczenia maszynowego (MT), ale także do wielu innych dwujęzycznych obszarów badawczych, oraz (3) koncepcję pętli treningowej dwujęzykowo-wstecznej, Przypuszczamy, że można skutecznie nauczyć się złożonych wzorców drzew dwupalcowych. Nasza praca odróżnia się od sekwencyjnych modeli opartych na uwadze, które są bardziej tradycyjne w neuronowym tłumaczeniu maszynowym (NMT) w trzech aspektach. Po pierwsze, nasz model wymusza ograniczenia kompozycyjne. Po drugie, nasz model ma mniejszą przestrzeń wyszukiwania w zakresie odkrywania dwujęzycznych relacji z dwujęzycznych par zdań. Po trzecie, nasz model produkuje wyraźne drzewa dwupłaskie, które umożliwiają przejrzystą analizę błędów podczas oceny i zewnętrzne ograniczenia drzew podczas treningu.', 'si': 'අපි ප්\u200dරවේශනය (1) ප්\u200dරවේශනයක් නිර්මාණය ජාත්\u200dරික සංවේශනය සඳහා බිල්ජුවල් මොඩල් ප්\u200dරවේශනය සම්බන්ධයක් ප්\u200dරවේශනය කරන්න පුළුවන් වෙනුවෙන් ප්\u200dරවේශනය කරන්න පුළුවන් වෙනුවෙන් ප්\u200dරවේශනය සඳහා බිල්ජ අපි හිතන්නේ ඒක ගොඩක් ප්\u200dරශ්ණයෙන් ප්\u200dරශ්ණයෙන් ඉගෙන ගන්න පුළුවන්. අපේ වැඩේ විශ්වාස කරනවා පස්සේ අවධාන අවධානය විදිහට, ඒ වගේම සාමාන්\u200dය විදියටම න්\u200dයුරෝල් මැෂින් අවධානය (NMT මුලින්ම, අපේ මොඩල් එක්ක සංවිධානය අවධානය කරනවා. දෙවෙනි විදියට, අපේ මොඩල් එක්ක පොඩි හොයාගන්න තැනක් තියෙනවා දෙවෙනි භාෂාවක් සම්බන්ධ සම්බන්ධ සම තුන්වෙනි විදියට, අපේ මොඩල් ප්\u200dරශ්නයක් නිර්මාණය කරනවා ප්\u200dරශ්නයක් විශ්ලේෂණය සහ ප්\u200dරශ්නයක් විදියට පාර', 'sv': 'Vi introducerar (1) en ny neuralt nätverksstruktur för tvåspråkig modellering av meningspar som möjliggör effektiv fångst av tvåspråkiga relationer via bikonstituent komposition, (2) begreppet neuralt nätverk biparsing, som gäller inte bara maskinöversättning (MT) utan även för en mängd andra tvåspråkiga forskningsområden, och (3) begreppet en biparsing-backpropagation träningsslinga, som vi hypoteser att effektivt kan lära sig komplexa biparsa trädmönster. Vårt arbete skiljer sig från sekventiella uppmärksamhetsbaserade modeller, som mer traditionellt finns inom neural maskinöversättning (NMT) i tre aspekter. För det första, vår modell tvingar kompositionsbegränsningar. För det andra har vår modell ett mindre sökutrymme när det gäller att upptäcka tvåspråkiga relationer från tvåspråkiga meningspar. För det tredje producerar vår modell explicita biparsa träd, som möjliggör transparent felanalys under utvärdering och externa trädbegränsningar under träning.', 'so': '(1) Waxaynu soo bandhignaynaa qoraal shabakad neurada ah oo labada noocyo oo kala duduwan labada noocyo ah oo u ogolaada inay si fiican u qabsadaan xiriirka labada luuqadood oo ku qoran labada kooxood, 2) fekerka shabakadda neurada ah oo ku qoran maamulka machine oo keliya (MT) laakiin sidoo kale waxay u leedahay meelo kale oo kala duduwan waxbarashada labada luqadood ah, iyo (3) fekerka kooxaha baaraandegista, taasoo aynu u leenahay fikirrada, taasoo si fiican u baran karo qaabab adag oo geed ah. Shaqo-kayagu wuxuu ka kala duwan yahay tusaalooyin ku saabsan dareemada xigta, kuwaas oo si caadi ah looga helaa turjuma machine neural (NMT) saddex dhinac. First, our model enforces compositional constraints.  Second, modellkayagu waxay leedahay goob raadinta yar oo ku saabsan in laga ogaado xiriirka labada luqadood oo laga helo labada luqadood. Saddexda, modellkayagu wuxuu soo saaraa geedo tusaale ah oo ah geedo biparse ah, kaas oo kara baaritaanka khaladda muuqda ah marka lagu qiimeeyo iyo xadhka dhirta dibadda xilliga waxbarashada lagu baranayo.', 'ta': 'நாம் (1) வாக்கு ஜோடி மாதிரிக்க ஒரு புதிய புதிய புதிய வலைப்பின்னல் அமைப்பு முனையமைப்பை குறிப்பிடுகிறோம். இது இரண்டு மொழிகள் தொடர்பை பிடிப்பதற்கு அனுமதிக்கும். (2) புதிய புதிய வலைப்பின்னல் பைகாட்டும் கருத்து, இயந்தி நாங்கள் அதை கண்ணியமாக கற்று கொள்ள முடியும் சிக்கலான இரண்டு பார்ச் மரத்தின் வடிவங்கள். எங்கள் வேலை பின்வரும் கவனத்தை அடிப்படையான மாதிரிகளிலிருந்து வேறுபடுத்தப்படுகிறது, அது மூன்று பக்கங்களில் புதிய இயந்திரத் மொழ முதலில், எங்கள் மாதிரி செயல்படுத்தும் கட்டுப்பாடுகள். இரண்டாவது, எங்கள் மாதிரியில் ஒரு சிறிய தேடும் இடம் உள்ளது இரு மொழியில் இருந்து இரண்டு வாக்கியத்தில் இருந்து இரண்டாவது உ மூன்றாவது, எங்கள் மாதிரி வெளிப்படையான பைபார்ஸ் மரங்களை உருவாக்குகிறது, இது பயிற்சியில் செய்யும் போது தெரியாத பிழை ஆய்வ', 'ur': 'ہم نے (1) ایک نور نیورال نیٹ ورک ساختار کو معلوم کرتا ہے جو دو زبان کی موڈلینگ کے لئے دو زبان کی رابطہ کے مطابق موثر دیتا ہے اور دوسری زبان کی تعلیم کے مطابق موثر دیتا ہے اور (2) نیورل نیٹ ورک بیپارچینگ کا مطابق ہے جو صرف ماشین ترجمہ (MT) کے مطابق موثر نہیں کرتا بلکہ دوسری دو زبان کی تحقیق کے مطابق بھی موثر کرتا ہے اور ہم نے اسے سمجھ لیا ہے کہ پیچیدہ بیپارس درخت نمونے کو مفید طور پر سیکھ سکتے ہیں۔ ہمارا کام تین الگوں میں اچھی طرح کی توجه کی موڈل سے جدا ہوتا ہے جو نئورل ماشین ترجمہ (NMT) میں زیادہ سنتی سے پاتے ہیں۔ پہلے، ہمارا مدل کمپیوٹی محدودیت کو مضبوط کرتا ہے۔ دوسرا، ہماری مدل ایک چھوٹی جگہ ہے جگہ دو زبان کی تعلقات کو دو زبان کے جوڑوں سے پیدا کرنے کے لئے۔ تیسرا، ہمارا مدل صریح دو پارس درخت پیدا کرتا ہے، جو تعلیم کے موقع تحقیقات اور باہر درخت کی محدودیت کے وقت روشن خطا کا تحقیقات کرتا ہے.', 'uz': "Biz bir so'z bir necha tarmoq tizimini o'zgartirish imkoniyatini qo'shish uchun yangi tarmoq tizimni tahlil qilamiz. Bu ikkita tilni bir xil bog'liqlarni tasdiqlash imkoniyatini ishlatish imkoniyatini beradi, (2) bir necha tarmoq bir xil tarjima tarjima tarjima tarjima (MT) va boshqa ikkita tillar taʼminlovchi sohalarda qo'shiladi va (3) biparing-backpropagan taʼminlovchi yozuvga ega bo'ladi, Bu biz murakkablik ikki daraxt shakllarini o'rganish mumkin. Bizning ishimizni keyingi paytda o'zgartirish modellaridan o'zgartiradi. Bu narsalar neyron maskina tarjima (NMT) ta'sirida ko'proq o'xshash mumkin. First, our model enforces compositional constraints.  Ikkinchi so'zda, modelimizda ikkita tillar munosabalarini ikkita so'zlar qo'lingidan aniqlash uchun kichkina qidirish joy bor. Uchinchi modelimiz bir misol biparse daraxtlarini yaratadi. Bu taʼminlovchi soatda shaxsiy xato analysini amalga oshirish mumkin.", 'vi': 'Chúng ta giới thiệu (1) một cấu trúc mạng thần kinh mới cho việc mô hình hai trường câu, cho phép kết nối hai dạng có hiệu quả bắt giữ mối quan hệ mật thông qua cấu hình bầu sinh đôi; 2) khái niệm cấu trúc lưỡng tính mạng, không chỉ liên quan đến dịch thuật máy (MTV) mà còn liên quan đến nhiều khu vực nghiên cứu hai thứ khác, và (3) khái niệm về vòng đào tạo lưỡng cực-phân tích thần kinh, mà chúng tôi giả thiết rằng có thể học được các mô hình khủng bố phức tạp. Công việc của chúng tôi phân biệt với các mô hình tập trung theo kế tiếp, mà thường được tìm thấy trong dịch chuyển máy thần kinh (NMB) trong ba khía cạnh. Thứ nhất, kiểu mẫu này thiết lập các ràng buộc liên quan. Thứ hai, mẫu của chúng ta có một khoảng trống tìm kiếm nhỏ hơn về việc tìm ra mối quan hệ hai thứ từ cặp câu hai. Thứ ba, mẫu của chúng tôi sản xuất hàng cây lưỡng cực rõ ràng, giúp phép phân tích sai lầm trong quá trình đánh giá và hạn chế của cây trong thời gian huấn luyện.', 'bg': 'Въвеждаме (1) нова структура на невронната мрежа за двуезично моделиране на двойки изречения, която позволява ефективно улавяне на двуезични взаимоотношения чрез двуконституентен състав, (2) концепцията за невронно мрежово бипардиране, която се прилага не само за машинен превод (МТ), но и за различни други двуезични изследователски области, и (3) концепцията за двуезичен тренировъчен цикъл, която предполагаме, че може ефективно да научи сложни двулични дървесни модели. Нашата работа се отличава от последователните модели, базирани на вниманието, които по-традиционно се срещат в невронния машинен превод (НМТ) в три аспекта. Първо, нашият модел налага композиционни ограничения. Второ, нашият модел има по-малко пространство за търсене по отношение на откриването на двуезични връзки от двуезични двойки изречения. Трето, нашият модел произвежда изрични двустранни дървета, които позволяват прозрачен анализ на грешките по време на оценката и външни ограничения по време на обучението.', 'nl': 'We introduceren (1) een nieuwe neurale netwerkstructuur voor tweetalige modellering van zinsparen die het mogelijk maakt om tweetalige relatie efficiënt vast te leggen via biconstituent samenstelling, (2) het concept van neurale netwerkbipalen, dat niet alleen van toepassing is op machine translation (MT) maar ook op een verscheidenheid van andere tweetalige onderzoeksgebieden, en (3) het concept van een bipalen-backpropagatie trainingslus, Wat we veronderstellen dat complexe bipale boompatronen efficiënt kunnen leren. Ons werk onderscheidt zich in drie aspecten van sequentiële aandachtsmodellen, die meer traditioneel in neuronale machinevertaling (NMT) voorkomen. Ten eerste, ons model dwingt compositiebeperkingen op. Ten tweede heeft ons model een kleinere zoekruimte in termen van het ontdekken van tweetalige relaties uit tweetalige zinnenparen. Ten derde produceert ons model expliciete bipale bomen, die een transparante foutanalyse tijdens evaluatie en externe boombeperkingen tijdens training mogelijk maken.', 'da': 'Vi introducerer (1) en ny neural netværksstruktur til tosproget modellering af sætningspar, der gør det muligt effektivt at fange tosproget forhold via bikonstituent sammensætning, (2) begrebet neural netværk biparsing, som gælder ikke kun maskinoversættelse (MT), men også for en række andre tosprogede forskningsområder, og (3) begrebet en biparsing-backpropagation træningsloop, som vi antager, at det effektivt kan lære komplekse biparse træmønstre. Vores arbejde adskiller sig fra sekventielle opmærksomhedsbaserede modeller, som mere traditionelt findes i neural machine translation (NMT) i tre aspekter. For det første håndhæver vores model sammensætningsmæssige begrænsninger. For det andet har vores model et mindre søgeområde med hensyn til at opdage tosprogede relationer fra tosprogede sætningspar. For det tredje producerer vores model eksplicitte biparse træer, som muliggør gennemsigtig fejlanalyse under evaluering og eksterne træbegrænsninger under træning.', 'hr': 'Predstavljamo (1) novu strukturu neuralne mreže za dvojezičnu modelizaciju parova kazne koje omogućavaju učinkovito uhvatiti dvojezičku vezu putem dvojezičkog sastanka, 2) koncept biparsiranja neuralne mreže, koja se primjenjuje ne samo na prevod uređaja (MT), već i na razne druge dvojezičke istraživačke područje, i 3) koncept obuke za biparsing-backpropagaciju, Pretpostavljamo da može učinkovito naučiti kompleksne uzorke drveta. Naš rad se razlikuje od sekvencijskih modela na temelju pažnje, koji su tradicionalnije pronađeni u prevodu neuralnih strojeva (NMT) u tri aspekta. Prvo, naš model primjenjuje kompozicijske ograničenje. Drugo, naš model ima manji prostor pretraživanja u smislu otkrivanja dvojezičkih odnosa iz dvojezičkih parova kazne. Treće, naš model proizvodi jasno dvoparsiranje drveća, koje omogućavaju transparentnu analizu greške tijekom procjene i vanjskih ograničenja drveta tijekom obuke.', 'de': 'Wir stellen (1) eine neuartige neuronale Netzwerkstruktur für die bilinguale Modellierung von Satzpaaren vor, die eine effiziente Erfassung zweisprachiger Beziehungen über bikonstituente Zusammensetzung ermöglicht, (2) das Konzept des neuronalen Netzes Biparing, das nicht nur für maschinelle Übersetzung (MT) sondern auch für eine Vielzahl anderer zweisprachiger Forschungsbereiche gilt, und (3) das Konzept einer Biparing-Backpropagation Trainingsschleife, Wir gehen davon aus, dass komplexe bipolare Baummuster effizient erlernt werden können. Unsere Arbeit unterscheidet sich von sequentiellen aufmerksamkeitsbasierten Modellen, die traditionell in der neuronalen maschinellen Übersetzung (NMT) zu finden sind, in drei Aspekten. Erstens erzwingt unser Modell kompositorische Einschränkungen. Zweitens hat unser Modell einen kleineren Suchraum in Bezug auf die Entdeckung zweisprachiger Beziehungen aus zweisprachigen Satzpaaren. Drittens erzeugt unser Modell explizite zweipolige Bäume, die eine transparente Fehleranalyse während der Auswertung und externe Baumbeschränkungen während des Trainings ermöglichen.', 'id': 'We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, Yang kita hipotesis yang dapat mempelajari pola pohon biparse kompleks secara efisien. Pekerjaan kami membedakan dari model sekwensial berdasarkan perhatian, yang lebih tradisional ditemukan dalam terjemahan mesin saraf (NMT) dalam tiga aspek. Pertama, model kita memaksa batasan komposisi. Kedua, model kita memiliki ruang pencarian yang lebih kecil dalam terma menemukan hubungan dua bahasa dari pasangan kalimat dua bahasa. Ketiga, model kami menghasilkan pohon-pohon biparse eksplisit, yang memungkinkan analisis kesalahan transparen selama evaluasi dan batasan pohon luar selama latihan.', 'sw': 'Tunawasilisha muundo wa mtandao wa kitabu cha neurali kwa ajili ya mifano ya viwili vya hukumu ambalo linaruhusu kuchukua mahusiano ya lugha kwa ufanisi kupitia ujengenezaji binafsi, (2) dhana ya kutengeneza mtandao wa kituo cha neurali, ambacho hutumia si tu kutafsiri mashine (MT) bali pia kwenye maeneo mbalimbali ya utafiti wa lugha mbili, na (3) dhana ya mafunzo ya mafunzo ya mawasiliano, Ambayo tuna imani ambazo zinaweza kujifunza kwa ufanisi mfumo wa mti wa kutengeneza mbili. Kazi zetu zinatofautiana na mifano yenye msingi wa ufuatiliaji, ambazo zinapatikana zaidi katika tafsiri ya mashine ya ubongo (NMT) katika vipande vitatu. Kwanza, muundo wetu unatengeneza vikwazo vya viwanda. Pili, modeli yetu in a nafasi ndogo ya kutafuta kwa ajili ya kutambua mahusiano ya lugha mbili kutoka kwenye hukumu ya lugha mbili. Tatu, mtindo wetu unatengeneza mti wa biparse unaoelezea wazi, ambao unawezesha uchambuzi wa makosa ya wazi wakati wa kutathmini na vikwazo vya mti wa nje wakati wa mafunzo.', 'tr': 'Biz (1) diňe maşynyň terjime edilmesine (MT) däldir we beýleki bilim ylgamynyň tekizliklerini ýetirmekde mümkin eden täze bir nuýral şebekege düzümlendirdik. Bu diňe maşynyň terjime edilmesine mümkin däldir, we (3) bir beýleki bilim ylgamynyň tekizliklerine üýtgetmegine mümkin edýäris. Bu şekilde biziň pikirimiz, karmaşık bipars agaç nusgalaryny öwrenip biler. Biziň işimiz näyral maşynyň terjimesinde (NMT) üç sahypalarda näyral maşynyň terjimesinde tapar. Ilkinji gezek, biziň nusgymyz çykyş syýahatlary dowam edýär. Ikinjisi, nusgamyzyň ikili sözle çiftlerden iki dil baglaýyşyny a çmak üçin kiçi bir gözlemek alany bar. Üçünji, nusgamyz açık biparse agaçlary üretýär. Bu ýagdaýda ýüze çykyş we daşaryk agaç çykyşlaryny çalyşyrmakda transparent hata analyzasyny mümkin edýär.', 'fa': 'ما (۱) یک ساختار شبکه عصبی جدید برای مدل دو زبان جفت جمله را معرفی می\u200cکنیم که اجازه می\u200cدهد که از طریق ترکیب دو زبان موثرت\u200cآوری از طریق ترکیب دو زبان باشد, (۲) مفهوم دوپارش شبکه عصبی، که نه تنها برای ترکیب ماشین (MT) بلکه به طریق مختلف منطقه\u200cهای تحقیق دو زبان، و (۳) مفهوم دوپارش آموزش دوپارش پشتیبانی که ما فرض می\u200cکنیم که می\u200cتوانیم بطور موثرت الگوهای درخت پیچیده را یاد بگیریم. کارمون از مدل های توجه به دنبال تعریف می\u200cکند که در ترجمه\u200cهای ماشین عصبی (NMT) در سه منطقه سنتی\u200cتر پیدا می\u200cشوند. اول، مدل ما محدودیت ترکیبی را اجرا می کند. دوم، مدل ما یک فضای جستجو کوچکتر در مورد کشف رابطه های دوزبانی از جفت جمله دو زبان دارد. سوم، مدل ما درختان دو پارچ مشخص را تولید می\u200cکند که در زمان تحلیل و محدودیت درخت خارجی در طول تمرین قابل تحلیل خطای مشخص می\u200cکند.', 'sq': 'Ne prezantojmë (1) një strukturë të re rrjeti nervor për modelimin dygjuhës të çifteve të fjalëve që lejon kapjen e efektshme të marrëdhënieve dygjuhëse nëpërmjet kompozicionit dygjuhës, (2) konceptin e biparzimit të rrjetit nervor, i cili aplikohet jo vetëm për përkthimin e makinave (MT) por gjithashtu për një shumëllojshmëri të rajoneve të tjera të kërkimit dygjuhës, dhe (3) konceptin e një bucle trajnimi dypalësh-backpropagim  which we hypothesize that can efficiently learn complex biparse tree patterns.  Puna jonë dallon nga modelet sekuenciale bazuar në vëmendje, të cilat gjenden më tradicionalisht në përkthimin e makinave nervore (NMT) në tre aspekte. Së pari, modeli ynë zbaton kufizime kompozitive. Së dyti, modeli ynë ka një hapësirë kërkimi më të vogël në lidhje me zbulimin e marrëdhënieve dygjuhëse nga çiftet e fjalëve dygjuhëse. Së treti, modeli ynë prodhon pemë eksplicite të dyanalizuara, që mundësojnë analizën transparente të gabimeve gjatë vlerësimit dhe kufizimeve të jashtme të pemëve gjatë trajnimit.', 'af': "Ons introduseer (1) ֳ¢ֲ€ֲ™n nuwe neuralnetwerk struktuur vir twee tale modellering van sin paar wat toelaat effektief opneem van twee tale verwanting deur biconstituent opstelling, (2) die konsept van neuralnetwerk biparsing, wat toewend aan nie slegs masjien vertaling (MT) maar ook aan ֳ¢ֲ€ֲ™n verskillende ander twee tale verwanting gebiede, en (3) die konsept van ֳ¢ֲ€ֲ™n biparsing-backpropagation oerring loop, wat ons hipotesis wat effektief kan leer kompleks biparse boom patrone. Ons werk verkies van sekwensielle aandag-gebaseerde modele, wat meer tradisioneel gevind word in neurale masjien-vertaling (NMT) in drie aspekte. Eerste, ons model vervul komposisielle beheinings. Tweede, ons model het 'n kleiner soektog ruimte in terms of discovering bilingueel relasies from bilingueel sentence pairs. Trede, ons model produseer eksplisiese bieparse bome wat deursigtig fout analiseer aktiveer tydens evaluering en eksterne boom beheinings tydens onderwerp.", 'hy': 'Մենք ներկայացնում ենք (1) երկլեզու նախադասությունների զույգերի նոր նյարդային ցանցի կառուցվածք, որը հնարավորություն է տալիս երկլեզու հարաբերությունների արդյունավետ ձեռք բերել երկլեզու միջոցով երկլեզու կառուցվածքի միջոցով, (2) նյարդային ցանցի երկլեզու վերլուծության գաղափարը, որը կիրառվում է ոչ միայն մեքենային թարգմանության (MT) այլ երկլեզու հետազոտության տար որը մենք ենթադրում ենք, որ կարող է արդյունավետ սովորել բարդ երկար ծառերի կաղապարներ: Մեր աշխատանքը տարբերվում է հետևյալ ուշադրության հիմնված մոդելներից, որոնք ավելի ավանդական են գտնվում նյարդային մեքենայի թարգմանման (NMT) մեջ երեք ասպեկտներով: Առաջինը, մեր մոդելը պարտադրում է կառուցվածքային սահմանափակումներ: Second, our model has a smaller search space in terms of discovering bilingual relationships from bilingual sentence pairs.  Երրորդ, մեր մոդելը արտադրում է բացահայտ երկարժեք ծառեր, որոնք հնարավորություն են տալիս թափանցիկ սխալների վերլուծությունը գնահատման ընթացքում և ծառերի արտաքին սահմանափակումների ընթացքում:', 'am': '(1) በሁለት ቋንቋዎች የቋንቋዎች ግንኙነትን በሁለት ባሕላዊ ግንኙነት በጥሩ አካባቢ አካባቢ ለመያዝ የሚችል የኖረብ መረብ አካባቢ አካባቢ እናስጠጋለን፡፡ 2) የናውሬል መረብ ብፓርቲ ማኅበረሰብ ብቻ አይደለም (MT) ግን ለሌሎች ሁለት ልዩ ቋንቋዎች ትርጓሜዎች እና (3) ለሁለት ልዩ ልዩ ልዩ ልዩ ትምህርት ማኅበረሰብ ማኅበረሰብ ነው፡፡ የዚህን አካባቢነት በሙሉ የሚማር ውጤት የዛፍ ዓይነቶች እናውቃለን፡፡ ሥራችን በሦስት ጉዳይ ውስጥ የፀሐይ መሣሪያን ትርጓሜ (NMT) የተለየ ነው፡፡ መጀመሪያ፣ ሞዴላያችን የስብሰባ ግንኙነት አሰናክሎታል ። በሁለተኛው፣ ሞዴላያችን ከሁለት ቋንቋ ቃላት ሁለት ዓይነቶችን ማግኘት ታናሽ ፈተና ስፍራን አላቸው፡፡ በሦስተኛውም ሞዴላያችን የቢፓርስ ዛፎችን የሚያበቅል፣ በተማመነቱ እና በውጭ ዛፍ ግንኙነታችንን በሚያስተምርበት ጊዜ የግልፅ ስህተት ትምህርት የሚያስችል ነው፡፡', 'az': 'Biz (1) iki dilli cüt modellərinin yeni nöral a ğ strukturunu tanıyırıq ki, iki dilli ilişkilərin çoxluğuna müvəffəqiyyət edər, 2) nöral ağ biparsing fikrini, ancaq maşın tercüməsinə uyğun deyildir (MT), lakin başqa cüt dilli araştırma alanlarına da uyğun deyildir, və 3) biparsing-backpropagation təhsilinin fikrini, Biz onu müxtəlif bipars ağacı örtüklərini öyrənə biləcəyik. Bizim işimiz nöral maşına çevirilməsində üç aspektdə daha çox təhsil edilən təsirlərdən ayrılır. İlk dəfə, modellərimiz kompozisyonlu müəyyən edir. İkincisi, modelimiz iki dil cümlədən iki dil ilişkilerini keşfetmək üçün daha kiçik bir arama alanı var. Üçüncüsü, modellərimiz təhsil sırasında müəyyən edilmə və çətin ağaç çətinlikləri müddətində açıq-aydın bipars ağaclarını təhsil edir.', 'bn': 'We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, যেটাকে আমরা হিসেবে মিথ্যাবাদী যেটা কার্যকর ভাবে জটিল বাইপার্স গাছের প্যাটার শিখতে পারে। আমাদের কাজ তিন দিকে মনোযোগ প্রদান করা মডেল থেকে বিচ্ছিন্ন হয়েছে, যেগুলো প্রচলিত নিউরেল মেশিন অনুবাদ (এনএমটি) থেকে আরো ঐতি প্রথমত, আমাদের মডেলের প্রতিষ্ঠানের বাধ্যতা দ্বিতীয়, আমাদের মডেলে দুই ভাষার বাক্যের জোড়া থেকে দুই ভাষার সম্পর্ক আবিষ্কারের মাধ্যমে একটি ছোট খোঁজার স্থান তৃতীয়, আমাদের মডেল বাইপার্স গাছ উৎপাদন করে, যা প্রশিক্ষণের সময় স্বচ্ছতা ত্রুটি বিশ্লেষণ করে এবং বাইরের গাছের নিয়ন্ত্রণের সময় স্বচ', 'ko': '우리는 (1) 문장의 이중 언어 모델링에 사용되는 신형 신경 네트워크 구조를 소개했다. 이 구조는 이중 성분 합성을 통해 이중 언어 관계를 효과적으로 포획할 수 있다. (2) 신경 네트워크의 이중 그룹 개념은 기계 번역(MT)뿐만 아니라 다른 각종 이중 언어 연구 분야에도 적용된다. (3) 이중 그룹 역방향 전파 훈련 순환의 개념.우리는 그것이 복잡한 두 갈래 나무 모델을 효과적으로 배울 수 있다고 가정한다.우리의 작업은 전통적으로 신경기계번역(NMT)에서 발견된 순서에 기초한 주의 모델과 세 가지 측면에서 다르다.우선, 우리 모델은 조합 제약을 강제로 실시한다.둘째, 우리의 모델은 이중 언어 문장에서 이중 언어 관계를 발견하는 데 비교적 작은 검색 공간을 가진다.셋째, 우리 모델은 현식의 두 갈래 나무를 생성하고 평가 기간에 투명한 오류 분석을 하고 훈련 기간에 외부 나무의 제약을 한다.', 'bs': 'Predstavljamo (1) novu strukturu neuralne mreže za dvojezičku modelizaciju parova rečenica koja omogućava učinkovito uhvaćenje dvojezičkih odnosa putem dvojezičkog kompozicije, (2) koncept biparsiranja neuralne mreže, koja se primjenjuje ne samo na prevod uređaja (MT), već i na razne druge dvojezičke istraživačke područje, i (3) koncept obuke za biparsing-backpropagaciju, Što pretpostavljamo da može učiti kompleksno biparsiranje drveta. Naš rad se razlikuje od sekvencijskih modela na temelju pažnje, koji su tradicionalnije pronađeni u prevodu neuralne mašine (NMT) na tri aspekta. Prvo, naš model primjenjuje kompozicijske ograničenje. Drugo, naš model ima manji prostor pretraživanja u smislu otkrivanja dvojezičkih odnosa iz dva rečenica. Treće, naš model proizvodi jasno dvoparsiranje drveća, koje omogućavaju transparentnu analizu greške tijekom procjene i vanjskih ograničenja drveta tijekom obuke.', 'ca': "Introduïm (1) una nova estructura de xarxa neural per modelar bilingües parelles de frases que permet capturar eficientment la relació bilingüe a través de composició biconstitucional, (2) el concepte de biparsing de xarxa neural, que s'aplica no només a la traducció màquina (MT), sinó també a una varietat d'altres àrees de recerca bilingüe, i (3) el concepte d'un bucle de formació biparsing-backpropagation, que hipòtesis que pot aprendre de manera eficient patrons complexes de biparsis d'arbres. La nostra feina distingeix de models seqüencials basats en l'atenció, que es troben més tradicionalment en la traducció neural de màquines (NMT) en tres aspectes. Primer, el nostre model aplica restriccions de composició. Segon, el nostre model té un espai de cerca més petit en termes de descobrir relacions bilingües a partir de parells de frases bilingües. En tercer lloc, el nostre model produeix arbres biparsos explícits, que permeten l'anàlisi transparent d'errors durant l'evaluació i les restriccions externes d'arbres durant l'entrenament.", 'cs': 'Představujeme (1) novou strukturu neuronové sítě pro dvojjazyčné modelování větových párů, která umožňuje efektivní zachycení dvojjazyčného vztahu prostřednictvím dvojjazyčného složení, (2) koncept bipalení neuronové sítě, který se vztahuje nejen na strojový překlad (MT), ale také na řadu dalších dvojjazyčných výzkumných oblastí, a (3) koncept tréninkové smyčky bipalení-zpětné propagace, Předpokládáme hypotézu, že se efektivně naučí složité vzorce dvoupásných stromů. Naše práce se liší od sekvenčních modelů založených na pozornosti, které se tradičněji nacházejí v neuronovém strojovém překladu (NMT) ve třech aspektech. Za prvé, náš model vynucuje kompoziční omezení. Za druhé, náš model má menší vyhledávací prostor z hlediska objevování dvojjazyčných vztahů z dvojjazyčných větových párů. Za třetí, náš model produkuje explicitní dvoupásové stromy, které umožňují transparentní analýzu chyb při hodnocení a externí omezení stromů během tréninku.', 'et': 'Tutvustame (1) uudset närvivõrgustruktuuri lausepaaride kakskeelseks modelleerimiseks, mis võimaldab kahekeelse suhte efektiivset jäädvustamist kaksikkonstituntse koostise kaudu, (2) närvivõrgu kahekeelse suhte kontseptsiooni, mida rakendatakse mitte ainult masintõlke (MT), vaid ka mitmesuguste teiste kakskeelsete uurimisvaldkondade puhul, ning (3) kahekeelse-tagasipropagatsiooni koolitusilmuse kontseptsiooni, Mis me oletame, et suudab tõhusalt õppida keerukaid kahepoolseid puumustreid. Meie töö eristab järjestikustel tähelepanupõhistel mudelitel, mida traditsioonilisemalt leidub neuromasintõlkes (NMT) kolmes aspektis. Esiteks kehtestab meie mudel kompositsioonipiiranguid. Teiseks on meie mudelil väiksem otsinguruum kahekeelsete lausepaaride kahekeelsete suhete avastamiseks. Kolmandaks toodab meie mudel selgesõnalised kahepoolsed puud, mis võimaldavad läbipaistvat veaanalüüsi hindamise ajal ja väliseid puupiiranguid koolituse ajal.', 'fi': 'Esittelemme (1) uuden neuroverkkorakenteen lauseparien kaksikieliseen mallintamiseen, joka mahdollistaa kaksikielisen suhteen tehokkaan talteenoton kaksikonstituentin koostumuksen avulla, (2) neuroverkon kaksikielisen vuorovaikutuksen käsitteen, jota sovelletaan konekäännöksen lisäksi myös moniin muihin kaksikielisiin tutkimusalueisiin, ja (3) kaksikielisen takaisinlevityksen koulutussilmukan käsitteen, jonka oletamme voivamme tehokkaasti oppia monimutkaisia kaksipuolisia puukuvioita. Työssämme erotellaan sekvenssiaalisista huomiopohjaisista malleista, joita perinteisemmin esiintyy neurokonekäännöksessä (NMT) kolmella eri tavalla. Ensinnäkin mallimme asettaa kompositiivisia rajoituksia. Toiseksi mallillamme on pienempi hakutila kaksikielisten lauseparien kaksikielisten suhteiden löytämiseksi. Kolmanneksi mallimme tuottaa eksplisiittiset kaksipuoliset puut, jotka mahdollistavat läpinäkyvän virheanalyysin arvioinnin aikana ja ulkoiset puurajoitukset koulutuksen aikana.', 'he': 'We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, מה שאנחנו מניחים שיכול ללמוד באופן יעיל דפוסי עץ ביפרס מורכבים. העבודה שלנו מבחינת מודלים מסורתיים מבוססים על תשומת לב, שמוצאים יותר מסורתיות בתרגום מכונות עצביות (NMT) בשלושה היבטים. קודם כל, הדוגמא שלנו מכריח חוסר מייצב. שנית, למודל שלנו יש מרחב חיפוש קטן יותר במונחים לגלות יחסים שתיים-לשונים מזוגי משפטים שתיים-לשונים. שלישית, המודל שלנו יוצר עצים ביפרסים מוחלטים, שמאפשרים ניתוח שגיאות שקופה במהלך הערכה ומגבלות עצים חיצוניים במהלך האימון.', 'jv': "Awak dhéwé nyebute (1) nggawe sistem Nyural seneng dadi nggawe sistem sistem karo bilngual model sing permet met met petani soko kelompok nggawe barang kelompok nggambar luwih (2) nggawe sistem Nyural netwising, sing wis dipolet kanggo nyebute sistem terjamahan (MT) nggo nyebute sistem sing wis dipolet, lan (3) nggawe sistem sistem bek asjamahan podho podho podho podho podho karo pakem nggawe Tulung Awak dhéwé nglanggar aturan macem sing isiné karo model sing basa gambar n' titik, sing dadi biasane supoyo tarjamahan karo ingkang alat (NMT) lan sak telu Aspek. Awak dhéwé, model nambarang nggawe barang nggawe 2D, modelo sing dibutuhke buturan kanggo nyeleh Genjer-Genjer, model sing nambah urip-urip diolah", 'ha': "Tuna introduce wani tsarin jerin neural na'urar kwamfyutan da ke samun misãlai biyu na gargaɗin ayuka, wanda ke yarda da su iya intake zura da haɗi biyu biyu maimakon cikin compositi biyu, (2) zaɓen kwamfyutan tarakin neural da za'a yi biparse, wanda ke amfani da shi bai zama kawai a fassarar mashine na'ura (MT) kuma amma zuwa wasu ƙungiya biyu masu fassarar tafarki na biyu, da (3) zato'anin a danason wa na danganta mai bassarwa-baka-bayani, @ info: tooltip Kayan aikinMu yana rarraba daga misãlai masu bincike a bakin muhimmada, waɗanda ke fi haɗa a cikin fassarar mashine na neural (NMT) cikin sakan uku. Kayyan da, misalinmu na samu'ar da tsari. Dukkan na, misalinmu yana da filin aiki kaɗan da za'a gane danganta biyu daga maganar biyu biyu. Da na ukun, misalinmu yana fitar da misãlai ga itãcen biparse, wanda yana iya iya amfani da Analyze ɓata mai bayyanãwa a lokacin da za'a yi ƙidãya da tsarin itãce na fita a lokacin da za'a yi amfani da shi.", 'sk': 'Predstavljamo (1) novo strukturo živčnega omrežja za dvojezično modeliranje stavkov parov, ki omogoča učinkovito zajemanje dvojezičnega razmerja preko dvojezične kompozicije, (2) koncept dvojezičnega omrežja, ki se nanaša ne le na strojno prevajanje (MT), temveč tudi na različna druga dvojezična raziskovalna področja, in (3) koncept dvojezičnega-hrbtnega usposabljanja, Predpostavljamo, da se lahko učinkovito naučimo kompleksnih dvobaršnih drevesnih vzorcev. Naše delo se razlikuje od zaporednih modelov, ki temeljijo na pozornosti, ki jih tradicionalno najdemo v nevronskem strojnem prevajanju (NMT) v treh vidikih. Najprej, naš model uveljavlja kompozicijske omejitve. Drugič, naš model ima manjši iskalni prostor v smislu odkrivanja dvojezičnih odnosov iz dvojezičnih stavkov. Tretjič, naš model proizvaja eksplicitna dvopazna drevesa, ki omogočajo pregledno analizo napak med ocenjevanjem in zunanje drevesne omejitve med usposabljanjem.', 'bo': 'We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, མཐུན་རྩོམ་པ་གྱི་རྩིས་བ་ཆེ་་སླབས་ཆོས་བའི་དབྱེ་བ་དག་གི་ལག་ལེན་འཐབ་བྱེད་ཡོད། ང་ཚོའི་ལས་ཀ་ནི་ལྟར་བཤད་ཀྱི་གནད་དོན་ཡོད་པའི་མིག་རྣམས་མེད་པར་དབྱེ་བ་བཏུབ་ཡོད། དང་པོར་བརྗོད་དང་། ང་ཚོའི་མ་དབྱིབས་ཡུལ་ཆེན་དུ་གཏོང་བྱེད་ཀྱི་ཡོད། གཉིས་པ། ང་ཚོའི་མ་དབུགས་ལ་རྒྱ་ནག་གི་བར་སྟོང་ཆ་ཆུང་ཀྱི་རྣམ་པ་གཉིས་ཀྱི་ཚིག་རྟགས་དང་འབྲེལ Third, our model produces explicit biparse trees, which enable transparent error analysis during evaluation and external tree constraints during training.'}
{'en': 'Breaking the Data Barrier : Towards Robust Speech Translation via Adversarial Stability Training', 'ar': 'كسر حاجز البيانات: نحو ترجمة قوية للكلام من خلال تدريب ثبات الخصومة', 'es': 'Rompiendo la barrera de los datos: hacia una traducción de voz sólida a través del entrenamiento de estabilidad', 'fr': 'Franchir la barrière des données\xa0: vers une traduction vocale robuste grâce à une formation à la stabilité contradictoire', 'pt': 'Quebrando a barreira de dados: em direção à tradução de fala robusta por meio do treinamento de estabilidade adversária', 'ja': 'データ障壁の打破：対抗的安定性トレーニングによる堅牢なスピーチ翻訳に向けて', 'hi': 'डेटा बैरियर को तोड़ना: प्रतिकूल स्थिरता प्रशिक्षण के माध्यम से मजबूत भाषण अनुवाद की ओर', 'zh': '破数据障:对抗性稳定性练成稳健语音译', 'ru': 'Преодоление барьера данных: к надежному переводу речи с помощью обучения стабильности противника', 'ga': 'An Bhacainn Sonraí a Bhriseadh: I dTreo Aistriúchán Cainte Láidir trí Oiliúint um Chobhsaíocht Sáraíochta', 'ka': 'მონაცემების ბარიერის გაშვება: პრობსტური სიტყვას გაცვლილების გარეშე', 'hu': 'Az adatok akadályának megszakítása: a robusztus beszédfordítás felé az ellentétes stabilitási képzésen keresztül', 'el': 'Σπάζοντας το εμπόδιο δεδομένων: Προς τη στιβαρή μετάφραση ομιλίας μέσω της εκπαίδευσης αντιβιοτικής σταθερότητας', 'it': 'Rompere la barriera dei dati: verso una traduzione robusta del discorso attraverso la formazione sulla stabilità avversaria', 'kk': 'Деректер бариерін бұғаттау: Конверсариялық қасиеттерді оқыту арқылы робосты сөз аударуына қарсы', 'lt': 'Duomenų kliūčių šalinimas: siekiant patikimo kalbos vertimo per priešingą stabilumo mokymą', 'mk': 'Прекинувањето на бариерата на податоците: кон силен превед на говорот преку обука за спротивна стабилност', 'ms': 'Breaking the Data Barrier: Towards Robust Speech Translation via Adversarial Stability Training', 'ml': 'ഡേറ്റാ ബാറിയര്\u200d തകര്\u200dത്തുകൊണ്ടിരിക്കുന്നു:', 'mn': 'Дасгал барьерыг бууруулах: Робст ярианы хөгжлийн хөгжлийн дасгал хөгжлийн аргаар', 'no': 'Avbryt databarrieren: Gå til robust taleomsetjing via Adversarial Stability Training', 'pl': 'Przełamanie bariery danych: w kierunku solidnego tłumaczenia mowy poprzez szkolenie stabilności przeciwników', 'ro': 'Depășirea barierei de date: către o traducere robustă a discursului prin instruirea privind stabilitatea adversă', 'sr': 'Prekidanje barijere podataka: prema robotnom prevodu govora putem Adversarial Stability Training', 'si': 'දත්ත බැරියර් විනාශ කරනවා: ක්\u200dරියාත්මක වාර්තාවක් වාර්තාවක් ස්ථිර විද්\u200dයාපිත විද්\u200dයාපනය', 'so': 'Breaking the Data Barrier: Towards Robust Speech Translation via Adversarial Stability Training', 'sv': 'Att bryta databarriären: Mot en robust språköversättning via utbildning för negativ stabilitet', 'ta': 'தரவு பேரியர் முறித்துவிடுகிறது: மேலே சுற்று பேச்சு மொழிபெயர்ப்பு மொழிபெயர்ப்பு', 'ur': 'ڈاٹا باریر کو ٹکڑا کر رہا ہے: مہربانی سٹبلیٹی ٹرینینگ کے ذریعہ روبروست بات کی ترجمہ کی طرف', 'mt': 'Breaking the Data Barrier: Towards Robust Speech Translation via Adversarial Stability Training', 'uz': 'Name', 'vi': '"Vượt qua giới hạn dữ liệu: Hướng tới sự phát biểu bền vững qua mùa đông"', 'nl': 'De databarrière doorbreken: naar robuuste spraakvertaling via training voor tegenstrijdige stabiliteit', 'bg': 'Премахване на бариерата на данните: към здрав превод на речта чрез обучение за стабилност на рекламата', 'da': 'Bryde databarrieren: På vej mod robust taleoversættelse via modstandsstabilitetstræning', 'hr': 'Prekršenje barijere podataka: prema naprednoj prevodi govora preko proizvodnje obuke stabilnosti', 'de': 'Überwindung der Datenbarriere: Auf dem Weg zu robuster Sprachübersetzung durch adversariales Stabilitätstraining', 'ko': '데이터 장벽 깨기: 안정성 훈련에 대항하여 안정적인 음성 번역 실현', 'id': 'Menghancurkan Barrier Data: Ke Perjemahan Kekuatan Bicara melalui Latihan Stabilitas Menyebar', 'fa': 'شکستن بازیگر داده\u200cها: به سوی ترجمه سخنرانی سخنرانی استواری', 'sw': 'Kuvunja Barrier of Data: Tafsiri ya Hotuba Upande wa Tofauti kupitia mafunzo ya Uwezeshaji', 'tr': 'Maglumat Başyrysyny çykmak: Seresariýan Stability ýan Ewezam Aralygy bilen gaýşartmak üçin', 'af': 'Breek die Data Barrier: Gaan na Robust Spraak Vertaling deur Adversarial Stabiliteit Oefening', 'sq': 'Shkatërrimi i pengesës së të dhënave: drejt përkthimit të fortë të fjalës nëpërmjet stërvitjes kundërshtare të stabilitetit', 'am': 'የዳታ ባርሪ በመስጠት ላይ Robust Speech Translation via Adversarial Stability Training', 'hy': 'Տվյալների խոչընդոտը կոտրելը. Առաջ ուժեղ խոսքի թարգմանման հակառակ կայունության ուսուցման միջոցով', 'az': "Data Barrier'i qırılıb: Adversarial Stability Training vasitəsilə robust Speech Translation", 'bn': 'ডাটা ব্যারেয়ার ভেঙ্গে ফেলা হচ্ছে: বিভিন্ন স্থানীয় প্রশিক্ষণের মাধ্যমে উঠে রোবাস্ট ভাষা অনুবাদ', 'bs': 'Prekršenje barijere podataka: prema robotu prevodu govora putem Adversarialne obuke stabilnosti', 'ca': "Eliminar l'obstacle a les dades: cap a una traducció robusta de la voz a través d'una formació adversaria d'estabilitat", 'cs': 'Prolomení datové bariéry: směrem k robustnímu překladu řeči prostřednictvím tréninku nepřátelské stability', 'fi': 'Dataesteen murtaminen: kohti vankkaa puhekäännöstä adversariaalisen stabiilisuuskoulutuksen avulla', 'et': 'Andmetõkke murdmine: vastupidava kõnetõlke suunas kõrvalsüsteemi stabiilsuskoolituse abil', 'jv': 'Sokake Daftar barar: Tulung Terjamahan Jobst Diweke Perusahaan Adverorial Stable Learning', 'sk': 'Prekinitev ovire za podatke: proti robustnemu prevajanju govora prek usposabljanja za stabilnost neželenih učinkov', 'ha': 'KCharselect unicode block name', 'bo': 'Breaking the Data Barrier: Towards Robust Speech Translation via Adversarial Stability Training', 'he': 'לשבור את חסום המידע: לכיוון תרגום נאום חזק באמצעות אימון יציבות נוגדי'}
{'en': 'In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system. A standard ', 'ar': 'في نظام ترجمة الكلام عبر خطوط الأنابيب ، سيرسل نظام التعرف التلقائي على الكلام (ASR) أخطاء التعرف على نظام الترجمة الآلية (MT). عادةً ما يتم تدريب نظام الترجمة الآلية القياسي على مجموعة نصية متوازية تتكون من نص نظيف وسيؤدي أداءً ضعيفًا على النص مع ضوضاء التعرف ، وهي فجوة معروفة جيدًا في مجتمع ترجمة الكلام. في هذه الورقة ، نقترح بنية تدريب تهدف إلى جعل نموذج الترجمة الآلية العصبية أكثر قوة ضد أخطاء التعرف على الكلام. يعالج نهجنا المشفر ووحدة فك التشفير في وقت واحد باستخدام التعلم العدائي وزيادة البيانات ، على التوالي. تُظهر النتائج التجريبية لمهمة ترجمة الكلام IWSLT2018 أن نهجنا يمكنه سد الفجوة بين إخراج ASR ومدخلات MT ، ويتفوق على خط الأساس بما يصل إلى 2.83 BLEU على إخراج ASR الصاخب ، مع الحفاظ على الأداء الوثيق على نص نظيف.', 'es': 'En un sistema de traducción de voz en línea, el sistema de reconocimiento automático de voz (ASR) transmitirá errores de reconocimiento al sistema de traducción automática (MT) descendente. Un sistema de traducción automática estándar generalmente se entrena en corpus paralelos compuestos de texto limpio y tendrá un rendimiento deficiente en texto con ruido de reconocimiento, una brecha bien conocida en la comunidad de traducción de voz. En este artículo, proponemos una arquitectura de capacitación que tiene como objetivo hacer que un modelo de traducción automática neuronal sea más robusto contra los errores de reconocimiento de voz. Nuestro enfoque aborda el codificador y el decodificador simultáneamente mediante el aprendizaje contradictorio y el aumento de datos, respectivamente. Los resultados experimentales de la tarea de traducción de voz IWSLT2018 muestran que nuestro enfoque puede cerrar la brecha entre la salida de ASR y la entrada de MT, supera la línea de base en hasta 2,83 BLEU en la salida de ASR ruidosa y, al mismo tiempo, mantener un rendimiento cercano en texto limpio.', 'pt': 'Em um sistema de tradução de fala em pipeline, o sistema de reconhecimento automático de fala (ASR) transmitirá erros no reconhecimento para o sistema de tradução automática (MT) downstream. Um sistema de tradução automática padrão geralmente é treinado em corpus paralelo composto de texto limpo e terá um desempenho ruim em texto com ruído de reconhecimento, uma lacuna bem conhecida na comunidade de tradução de fala. Neste artigo, propomos uma arquitetura de treinamento que visa tornar um modelo de tradução automática neural mais robusto contra erros de reconhecimento de fala. Nossa abordagem aborda o codificador e o decodificador simultaneamente usando aprendizado adversário e aumento de dados, respectivamente. Resultados experimentais na tarefa de tradução de fala IWSLT2018 mostram que nossa abordagem pode preencher a lacuna entre a saída ASR e a entrada MT, superando a linha de base em até 2,83 BLEU na saída ASR ruidosa, mantendo um desempenho próximo em texto limpo.', 'fr': "Dans un système de traduction vocale en pipeline, le système de reconnaissance vocale automatique (ASR) transmet les erreurs de reconnaissance au système de traduction automatique (MT) en aval. Un système de traduction automatique standard est généralement formé sur un corpus parallèle composé de texte propre et fonctionnera mal sur un texte avec un bruit de reconnaissance, une lacune bien connue dans la communauté de la traduction vocale. Dans cet article, nous proposons une architecture de formation qui vise à rendre un modèle de traduction automatique neuronale plus robuste contre les erreurs de reconnaissance vocale. Notre approche s'adresse simultanément au codeur et au décodeur en utilisant l'apprentissage contradictoire et l'augmentation des données, respectivement. Les résultats expérimentaux de la tâche de traduction vocale IWSLT2018 montrent que notre approche peut combler l'écart entre la sortie ASR et l'entrée MT, surpasse la ligne de base jusqu'à 2,83 BLEU sur une sortie ASR bruyante, tout en maintenant des performances proches sur un texte propre.", 'ja': 'パイプライン音声翻訳システムでは、自動音声認識（ ＡＳＲ ）システムは、下流機械翻訳（ Ｍ Ｔ ）システムに認識のエラーを送信する。標準的な機械翻訳システムは、通常、クリーンなテキストで構成された並列コーパスでトレーニングされ、認識ノイズのあるテキストではパフォーマンスが悪く、音声翻訳コミュニティでよく知られているギャップです。本稿では、音声認識誤差に対する神経機械翻訳モデルをより堅牢にすることを目的としたトレーニングアーキテクチャを提案する。私たちのアプローチは、エンコーダとデコーダをそれぞれ対向学習とデータ拡張を使用して同時に対処します。IWSLT 2018音声翻訳タスクの実験結果は、私たちのアプローチがASR出力とMT入力の間のギャップを埋めることができ、クリーンテキストのクリーンなパフォーマンスを維持しながら、ノイズの多いASR出力で最大2.83 BLEUのベースラインを上回ることを示しています。', 'zh': '管译系统,自语音别(ASR)系统将识误传输下流机器翻译(MT)系统。 准的机器翻译系统常在净文本的并行语料库上训练,并且在有识噪声的文本上不佳,这在语音译社区中是众所周知的差距。 本文中,设训练架构,使神经机器翻译模形识误益壮。 吾法各用对抗性学数增强以处编码器解码器。 IWSLT2018音译之实验结果表明,吾法可弥合ASR输MT之间,嘈杂之ASR,比基线高2.83 BLEU,洁文近之。', 'hi': 'पाइपलाइन वाक् अनुवाद प्रणाली में, स्वचालित वाक् पहचान (ASR) प्रणाली डाउनस्ट्रीम मशीन अनुवाद (MT) प्रणाली को मान्यता में त्रुटियों को संचारित करेगी. एक मानक मशीन अनुवाद प्रणाली को आमतौर पर स्वच्छ पाठ से बने समानांतर कॉर्पस पर प्रशिक्षित किया जाता है और मान्यता शोर के साथ पाठ पर खराब प्रदर्शन करेगा, एक अंतर जो भाषण अनुवाद समुदाय में अच्छी तरह से जाना जाता है। इस पेपर में, हम एक प्रशिक्षण वास्तुकला का प्रस्ताव करते हैं जिसका उद्देश्य भाषण मान्यता त्रुटियों के खिलाफ एक तंत्रिका मशीन अनुवाद मॉडल को अधिक मजबूत बनाना है। हमारा दृष्टिकोण एन्कोडर और डिकोडर को एक साथ क्रमशः प्रतिकूल सीखने और डेटा वृद्धि का उपयोग करके संबोधित करता है। IWSLT2018 भाषण अनुवाद कार्य पर प्रयोगात्मक परिणाम बताते हैं कि हमारा दृष्टिकोण एएसआर आउटपुट और एमटी इनपुट के बीच की खाई को पुल कर सकता है, शोर एएसआर आउटपुट पर 2.83 BLEU तक बेसलाइन को मात देता है, जबकि स्वच्छ पाठ पर करीबी प्रदर्शन बनाए रखता है।', 'ru': 'В системе конвейерного перевода речи система автоматического распознавания речи (ASR) будет передавать ошибки распознавания в систему последующего машинного перевода (MT). Стандартная система машинного перевода обычно обучается на параллельном корпусе, состоящем из чистого текста, и будет плохо работать на тексте с шумом распознавания, пробелом, хорошо известным в сообществе речевого перевода. В этой статье мы предлагаем обучающую архитектуру, которая направлена на то, чтобы сделать модель нейронного машинного перевода более устойчивой к ошибкам распознавания речи. Наш подход адресован кодеру и декодеру одновременно с использованием состязательного обучения и расширения данных, соответственно. Экспериментальные результаты по задаче перевода речи IWSLT2018 показывают, что наш подход может преодолеть разрыв между выходом ASR и входом MT, превосходит базовую линию до 2,83 BLEU на шумном выходе ASR, сохраняя при этом близкую производительность на чистом тексте.', 'ga': 'I gcóras aistriúcháin urlabhra píblíne, tarchuirfidh córas uathaitheantais cainte (ASR) earráidí aitheantais chuig an gcóras aistriúcháin meaisín iartheachtacha (MT). Go hiondúil cuirtear oiliúint ar chóras aistriúcháin meaisín caighdeánach ar chorpas comhthreomhar comhdhéanta de théacs glan agus ní fheidhmeoidh sé go dona ar théacs le torann aitheantais, bearna atá ar eolas go maith i bpobal aistriúcháin urlabhra. Sa pháipéar seo, molaimid ailtireacht oiliúna a bhfuil sé mar aidhm aici múnla néar-aistriúcháin meaisín a dhéanamh níos láidre i gcoinne earráidí aitheantais cainte. Tugann ár gcur chuige aghaidh ar an ionchódóir agus ar an díchódóir ag an am céanna ag baint úsáide as foghlaim sháraíochta agus méadú sonraí, faoi seach. Léiríonn torthaí turgnamhacha ar thasc aistriúcháin cainte IWSLT2018 gur féidir lenár gcur chuige an bhearna idir an t-aschur ASR agus an t-ionchur MT a líonadh, go n-éiríonn leis an mbunlíne suas le 2.83 BLEU ar aschur torannach ASR, agus feidhmíocht dhlúth ar théacs glan á choinneáil ag an am céanna.', 'ka': 'Name სტანდარტური მაქინის გადაწყვეტილების სისტემა საუკეთესოდ პარალელი კორპუსზე განაკეთებულია, რომელიც ფრთხოვნილი ტექსტიდან შექმნილია და ტექსტიდან ცოტა გადაწყვეტილება,  ამ დომენტში, ჩვენ მივიღებთ სტრუქტურის აქტიქტურაციას, რომელიც მინდომა ნეიროლური მაქინის გაგრძელების მოდელს უფრო ძალიან სტრუქტურებელი ჩვენი პროგორმა კოდერს და დეკოდერს ერთადერთად გამოყენებს განსაკუთრებული სწავლება და მონაცემების აგგენტირება. ექსპერიმენტიური შედეგები IWSLT2018 სიტყვების გაგრძელებაში ჩვენი პროგრამა შეუძლია გახსნა ASR გაგრძელებაზე და MT გაგრძელებაზე, გავამუშავება ფესური ხაზი 2,83 BLEU-ზე სიტყვებით ASR გაგრძელებაზე', 'hu': 'A beszédfordító rendszerben az automatikus beszédfelismerő (ASR) rendszer a felismerési hibákat továbbítja a downstream gépi fordító (MT) rendszerbe. Egy szabványos gépi fordítási rendszert általában tiszta szövegből álló párhuzamos korpuszra képeznek, és rosszul teljesítenek a felismerési zajjal rendelkező szövegeken, ami jól ismert a beszédfordítói közösségben. Ebben a tanulmányban egy olyan képzési architektúrát javasolunk, amely célja, hogy egy neurális gépi fordítási modellt erősebbé tegyen a beszédfelismerési hibákkal szemben. Megközelítésünk a kódolót és a dekódolót egyidejűleg ellentétes tanulással, illetve adatbővítéssel foglalkozik. Az IWSLT2018 beszédfordítási feladat kísérleti eredményei azt mutatják, hogy a megközelítésünk áthidalja az ASR kimenet és az MT bemenet közötti szakadékot, zajos ASR kimenet esetén akár 2,83 BLEU-val felülmúlja az alapot, miközben tiszta szöveg esetén szoros teljesítményt tart fenn.', 'el': 'Σε ένα σύστημα μετάφρασης ομιλίας αγωγών, το σύστημα αυτόματης αναγνώρισης ομιλίας (ASR) θα διαβιβάσει σφάλματα αναγνώρισης στο μεταγενέστερο σύστημα μηχανικής μετάφρασης (MT). Ένα τυποποιημένο σύστημα μηχανικής μετάφρασης εκπαιδεύεται συνήθως σε παράλληλο σώμα που αποτελείται από καθαρό κείμενο και θα αποδίδει άσχημα σε κείμενο με θόρυβο αναγνώρισης, ένα κενό γνωστό στην κοινότητα μετάφρασης ομιλίας. Στην παρούσα εργασία, προτείνουμε μια εκπαιδευτική αρχιτεκτονική που στοχεύει στο να καταστήσει ένα μοντέλο νευρωνικής μηχανικής μετάφρασης πιο ανθεκτικό ενάντια σε σφάλματα αναγνώρισης ομιλίας. Η προσέγγισή μας απευθύνεται στον κωδικοποιητή και τον αποκωδικοποιητή ταυτόχρονα χρησιμοποιώντας την αντίθετη μάθηση και την αύξηση δεδομένων αντίστοιχα. Τα πειραματικά αποτελέσματα της εργασίας μετάφρασης ομιλίας δείχνουν ότι η προσέγγισή μας μπορεί να γεφυρώσει το χάσμα μεταξύ της εξόδου ASR και της εισόδου MT, ξεπερνά τη γραμμή βάσης μέχρι 2.83 σε θορυβώδη έξοδο ASR, διατηρώντας παράλληλα στενή απόδοση σε καθαρό κείμενο.', 'it': "In un sistema di traduzione vocale pipeline, il sistema di riconoscimento vocale automatico (ASR) trasmetterà gli errori di riconoscimento al sistema di traduzione automatica a valle (MT). Un sistema di traduzione automatica standard è solitamente addestrato su corpus parallelo composto da testo pulito e funzionerà male su testo con rumore di riconoscimento, una lacuna ben nota nella comunità di traduzione vocale. In questo articolo, proponiamo un'architettura di formazione che mira a rendere più robusto un modello di traduzione automatica neurale contro gli errori di riconoscimento vocale. Il nostro approccio affronta contemporaneamente l'encoder e il decoder utilizzando rispettivamente l'apprendimento avversario e l'aumento dei dati. I risultati sperimentali sull'attività di traduzione vocale IWSLT2018 mostrano che il nostro approccio può colmare il divario tra l'uscita ASR e l'ingresso MT, supera la linea di base fino a 2,83 BLEU su uscita ASR rumorosa, mantenendo al contempo prestazioni ravvicinate su testo pulito.", 'kk': 'Қызық сөздерді аудару жүйесінде автоматты сөздерді анықтау (ASR) жүйесі қателерді бағыттау (MT) жүйесіне қате береді. Стандартты машинаны аудару жүйесі әдетте таза мәтіннен құрылған параллелі корпус арқылы оқылған және мәтінді белгілеу дыбыстығымен, сөйлеу аудару коммуникасында жақсы белгілеп тұрады. Бұл қағазда, бұл невралдық компьютердің аудармасының үлгісін сөйлеу қатесіне қарсы көмектесетін оқыту архитектурасын таңдаймыз. Біздің қасиетіміз кодерге және декодерге қарсы оқу және деректерді көбейту көмегімен бірдей жеткізеді. IWSLT2018 сөздерді аудару тапсырмасының эксперименталдық нәтижелері ASR шығысын мен MT шығысының арасындағы аралығын көмектесе алады. АСR шығысын тыңдау үшін 2,83 BLEU- ге дейін негізгі жолды жетілдіреді. Жақын мәтінде жақы', 'mk': 'Во гасоводскиот систем на превод на говор, автоматското препознавање на говорот (АСР) ќе пренесе грешки во препознавањето на системот на машински превод (МТ). Стандардниот машински преведувачки систем обично е обучен на паралелен корпус составен од чист текст и лошо ќе функционира на текст со бучава за препознавање, празнина позната во заедницата за преведување на говорот. Во овој весник предложуваме архитектура за обука која има за цел да го направи моделот на превод на невровните машини посилен против грешките во препознавањето на говорот. Нашиот пристап се обраќа кон кодерот и декодерот истовремено користејќи противно учење и зголемување на податоците, односно. Експерименталните резултати на задачата за превод на говорот IWSLT2018 покажуваат дека нашиот пристап може да ја премине празнината помеѓу излезот на АСР и влогот на МТ, ја надминува основната вредност за до 2,83 БЛЕУ за бучниот излез на АСР, при што ќе се одржи блиска резултат', 'ml': 'ഒരു പൈപ്പെലൈന്\u200d സംസാര പരിഭാഷണ സിസ്റ്റത്തില്\u200d, സ്വയം സംസാരം തിരിച്ചറിയാനുള്ള സിസ്റ്റത്തില്\u200d തെറ്റുകള്\u200d താഴെ സ്ട്രീമിന്\u200d മ വൃത്തിയായ പദാവലിയില്\u200d ചേര്\u200dത്തിരിക്കുന്ന പാരളല്\u200d കോര്\u200dപ്സില്\u200d ഒരു സാധാരണ മെഷീന്\u200d പരിശീലന സിസ്റ്റം പരിശീലിക്കപ്പെടുന്നു. വാക് ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഒരു ട്രെയിനിന്\u200d ആര്\u200dക്ടിക്കേഷന്\u200d സ്ഥാനം പ്രായണം ചെയ്യുന്നു. അതിന്റെ ഉദ്ദേശം പ്രസ്താവിക്കുന്നത്  നമ്മുടെ അടുത്തുനിന്നുള്ള പ്രായോഗ്യം കോഡെറിനെയും വിരോധമായ പഠനം ഉപയോഗിക്കുന്നതിനെയും വിവരങ്ങള്\u200d കൂട്ടിക്ക IWSLT2018 സംസാരം പരീക്ഷിക്കുന്ന ഫലങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു ഞങ്ങളുടെ സമ്പാദ്യം ASR പുറത്തും MT ഇന്\u200dപുട്ടിനും തമ്മിലുള്ള വ്യത്യാസങ്ങള്\u200dക്കും തമ്മിലുള്ള പ്ര', 'mt': 'In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system.  A standard machine translation system is usually trained on parallel corpus composed of clean text and will perform poorly on text with recognition noise, a gap well known in speech translation community.  F’dan id-dokument, qed nipproponu arkitettura ta’ taħriġ li għandha l-għan li tagħmel mudell ta’ traduzzjoni tal-magni newrali aktar robust kontra żbalji ta’ rikonoxximent tad-diskors. L-approċċ tagħna jindirizza l-kodifikatur u d-dekoder fl-istess ħin bl-użu tat-tagħlim avversarju u ż-żieda tad-dejta, rispettivament. Riżultati esperimentali dwar il-kompitu tat-traduzzjoni tad-diskors tal-IWSLT2018 juru li l-approċċ tagħna jista’ jnaqqas id-distakk bejn il-produzzjoni tal-ASR u l-input tal-MT, jaqbeż il-linja bażi sa 2.83 BLEU dwar il-produzzjoni storbjuża tal-ASR, filwaqt li jżomm prestazzjoni mill-qrib fuq test nadif.', 'mn': 'Хөвөг шугамын хөгжлийн хөгжлийн хөгжлийн хөгжлийн системд автоматик ярианы таних систем нь доорх машин хөгжлийн хөгжлийн системд алдаа явуулна. Стандарттай машины орчуулах систем ихэвчлэн цэвэр текст бүтээгдэхүүнтэй параллел корпус дээр сургалт хийгддэг. Үүний орчуулах нийгэмд сайн мэддэг зай бий болно. Энэ цаасан дээр бид сургалтын архитектурыг санал болгож байна. Энэ нь мэдрэлийн машины хөгжлийн загварыг илүү хүчтэй болгох юм. Бидний арга зам нь кодлогч болон сайн суралцагч болон өгөгдлийн нэмэгдүүлэлтийг ашиглаж байгаа юм. IWSLT2018 илтгэл хөгжлийн даалгаврын туршилтын үр дүнд бидний арга нь ASR гаралт болон MT гаралт хоорондын ялгааг нэмэгдүүлж, үндсэн шугам нь ASR гаралт дээр 2.83 BLEU хүртэл нэмэгдүүлж чадна.', 'lt': 'Vamzdyno kalbos vertimo sistemoje automatinis kalbos atpažinimo (ASR) sistema perduoda pripažinimo klaidas į tolesnę mašinos vertimo (MT) sistemą. Standartinė mašin ų vertimo sistema paprastai mokoma lygiagrečiu korpusu, sudarytu iš švario teksto, ir blogai veikia tekste su pripažinimo triukšmu, kuris gerai žinomas kalbos vertimo bendruomenėje. Šiame dokumente siūlome mokymo architektūrą, kuria siekiama, kad nervinių mašinų vertimo modelis būtų patikimesnis prieš kalbos pripažinimo klaidas. Mūsų metodas taikomas koduotojui ir dekoderiui kartu naudojant priešingą mokymąsi ir duomenų didinimą. Eksperimentiniai IWSLT2018 kalbos vertimo užduoties rezultatai rodo, kad mūsų požiūris gali užkirsti kelią atotrūkiui tarp ASR išėjimo ir MT įėjimo, viršyti pradinę vertę iki 2,83 BLEU triukšmingo ASR išėjimo atveju, kartu išlaikydamas glaudžius švario teksto rezultatus.', 'no': 'I eit pipeline-taleomsetjingssystem vert automatisk tale-gjenkjenning (ASR) sendt feil i gjenkjenning til omsetjingssystemet (MT). Ein standard maskinsomsetjingssystem vert vanlegvis trent på parallelle korpus som er lagt av rein tekst og vil utføra slik på teksten med gjenkjenning av støy, eit mellomrom som er kjent i taleomsetjingsamfunnet. I denne papiret foreslår vi eit opplæringsarkitektur som målet å gjera ein neuralmaskinsomsetjingsmodul meir sterkt mot tale gjenkjenningsfeilar. Tilnærminga vårt adresserer koderen og dekoderen samtidig ved å bruka negativlæring og data-augmentasjon. Eksperimentale resultat på taleomsetjingsprogrammet IWSLT2018 viser at tilnærminga vårt kan bryta mellom ASR-utdata og MT-inndata, og utfører baselinja opp til 2,83 BLEU på støy ASR-utdata, mens du held nærare utviklingar på rein tekst.', 'pl': 'W systemie tłumaczenia mowy w rurociągu system automatycznego rozpoznawania mowy (ASR) przesyła błędy w rozpoznawaniu do dalszego systemu tłumaczenia maszynowego (MT). Standardowy system tłumaczenia maszynowego jest zwykle trenowany na równoległym korpusie składającym się z czystego tekstu i będzie słabo działał w tekście z szumem rozpoznawania, luką dobrze znaną w społeczności tłumaczeń mowy. W niniejszym artykule proponujemy architekturę szkoleniową, której celem jest uczynienie neuronowego modelu tłumaczenia maszynowego bardziej odpornego na błędy rozpoznawania mowy. Nasze podejście dotyczy kodera i dekodera jednocześnie przy użyciu odpowiednio uczenia się przeciwnego i powiększania danych. Wyniki eksperymentalne dotyczące zadania tłumaczenia mowy IWSLT2018 pokazują, że nasze podejście może zlikwidować lukę między wyjściem ASR a wejściem MT, przewyższa linię bazową o nawet 2.83 BLEU na szumownym wyjściu ASR, przy jednoczesnym utrzymaniu ścisłej wydajności w czystym tekście.', 'ms': 'Dalam sistem terjemahan ucapan baris paip, sistem pengenalan ucapan automatik (ASR) akan menghantar ralat dalam pengenalan ke sistem terjemahan mesin turun (MT). Sistem terjemahan mesin piawai biasanya dilatih pada corpus selari yang terdiri dari teks bersih dan akan melaksanakan buruk pada teks dengan bunyi pengenalan, ruang yang dikenali dalam komuniti terjemahan ucapan. Dalam kertas ini, kami cadangkan arkitektur latihan yang bertujuan untuk membuat model terjemahan mesin saraf lebih kuat terhadap ralat pengenalan ucapan. pendekatan kita menghadapi pengekod dan pengekod secara bersamaan menggunakan pembelajaran musuh dan peningkatan data, secara bersamaan. Keputusan percubaan pada tugas terjemahan ucapan IWSLT2018 menunjukkan bahawa pendekatan kita boleh menyelesaikan jarak antara output ASR dan input MT, melampaui dasar dengan sehingga 2.83 BLEU pada output ASR bunyi, sementara menjaga prestasi dekat pada teks bersih.', 'ro': 'Într-un sistem de traducere a vorbirii, sistemul automat de recunoaștere a vorbirii (ASR) va transmite erorile de recunoaștere către sistemul de traducere automată din aval (MT). Un sistem standard de traducere automată este de obicei instruit pe corpuri paralele compuse din text curat și va performa slab pe text cu zgomot de recunoaștere, un decalaj bine cunoscut în comunitatea traducerii vorbirii. În această lucrare, propunem o arhitectură de formare care vizează să facă un model de traducere automată neurală mai robust împotriva erorilor de recunoaștere a vorbirii. Abordarea noastră abordează simultan codificatorul și decodorul folosind învățarea adversară și, respectiv, mărirea datelor. Rezultatele experimentale ale sarcinii de traducere a vorbirii IWSLT2018 arată că abordarea noastră poate depăși decalajul dintre ieșirea ASR și intrarea MT, depășește valoarea de referință cu până la 2,83 BLEU la ieșirea ASR zgomotoasă, menținând în același timp performanțe strânse la text curat.', 'sr': 'U sistemu prevođenja govora na cijevima, sistem automatskog priznanja govora (ASR) prenosi će greške u priznanju sustavu prevođenja mašin a na spuštanju. Standardni sistem prevoda mašine je obično obučen na paralelnom korpusu sastavljenom od čistog teksta i loše će izvršiti tekst sa bukom priznanja, prazninom poznatom u prijevoznoj zajednici. U ovom papiru predlažemo arhitekturu obuke koja je cilj da napravi model prevoda neuronskih mašina jačaniji protiv grešaka prepoznavanja govora. Naš pristup se obraća koderu i dekoderu istovremeno koristeći neprijateljsko učenje i povećanje podataka. Eksperimentalni rezultati na zadatku prevoda govora IWSLT2018 pokazuju da naš pristup može prekriti prazninu između proizvoda ASR-a i ulaza MT-a, iznosi početnu liniju do 2,83 BLEU-a na bukni proizvod ASR-a, dok održava blizu provedbu na čistom tekstu.', 'si': 'Name සාමාන්\u200dය පද්ධතිය පද්ධතියක් සාමාන්\u200dය වාර්ථා පද්ධතියක් පිරිසිදු පාළුවෙන් සම්බන්ධ කරලා තියෙනවා ඒ වගේම පාළුවක්  මේ පත්තරේ අපි ප්\u200dරශ්නයක් සැලසුම් කරනවා, ඒකෙන් අදහස් කරන්නේ න්\u200dයූරාල් මැෂින් වාර්තාවක් නිර්මාණයක් විදි අපේ ප්\u200dරවේශනය යුද්ධ කරුණාකරණය සහ ඩිකෝඩර් එක්කෙනෙක් විරෝධ විදිහට පාවිච්චි කරනවා විරෝධික ඉ IWSLT2018 භාෂාව අවරංචාවයේ පරීක්ෂණ ප්\u200dරතිචාර ප්\u200dරතිචාරයක් පෙන්වන්නේ අපේ ප්\u200dරතිචාරය ASR ප්\u200dරතිචාරය සහ MT ඇතුළු අතර අතර අතර අතර අතර අතර අත', 'sv': 'I ett system f철r tal철vers채ttning i pipeline kommer automatisk taligenk채nning (ASR) att 철verf철ra fel i igenk채nning till maskin철vers채ttningssystemet nedstr철ms (MT). Ett standardmaskin철vers채ttningssystem utbildas vanligtvis p책 parallell korpus best책ende av ren text och fungerar d책ligt p책 text med igenk채nningsbrus, en lucka som 채r v채lk채nd inom spr책k철vers채ttningsgruppen. I denna uppsats f철resl책r vi en utbildningsarkitektur som syftar till att g철ra en neural maskin철vers채ttningsmodell mer robust mot taligenk채nningsfel. V책rt tillv채gag책ngss채tt behandlar kodaren och avkodaren samtidigt med hj채lp av kontradiktorisk inl채rning respektive data철kning. Experimentella resultat p책 IWSLT2018 tal철vers채ttningsuppgift visar att v책rt tillv채gag책ngss채tt kan 철verbrygga klyftan mellan ASR-utg책ngen och MT-ing책ngen, 철vertr채ffa baslinjen med upp till 2,83 BLEU p책 bullriga ASR-utg책ngar, samtidigt som vi bibeh책ller n채ra prestanda p책 ren text.', 'so': 'Isticmaalka turjumista hadalka ee pipeline, nidaamka aqoonsashada hadalka (ASR) wuxuu u dirayaa cadaawayaasha aqoonsashada qoraalka hoose ee machine-ka (MT). Sida caadiga ah nidaamka turjumaadda maskinada waxaa lagu tababaraa barbaarinta qoraalka daahirka ah oo ku qoran qoraalka saxda ah, codka aqoonsashada, goobta lagu yaqaan bulshada turjumaadda. Qoraalkan waxaynu soo jeedaynaa dhismo waxbarasho ah oo ku talo gala inuu sameeyo model turjumista maskaxda neurada oo ka gees ah qalbiyada aqoonsashada hadalka. Dhaqdhaqaalahayagu wuxuu u macaamiloodaa kooxda iyo codsiga islamarkaasna u isticmaalaa waxbarashada cadaawayaasha ah iyo kordhiska macluumaadka. Imtixaanka arimaha turjumaadda ee IWSLT2018 waxay muuqataa in qaababkayagu uu ka kooban karo kala duwan ka dhexeeya soo baxa ASR iyo input MT, wuxuu ka muujiyaa saldhigga ugu badnaan 2.83 BLEU oo ku saabsan codka ASR ka baxa, iyadoo xajisanaya dhamaanka dhaqdhaqaaqa saxda daahirka ah.', 'ur': 'پیپ لین کی بات ترجمہ سیسٹم میں، آٹوٹی بات شناسایی (ASR) سیسٹم کے ذریعہ ڈونسٹریم ماشین ترجمہ (MT) سیسٹم کی شناسایی میں خطا پیدا کرے گا۔ ایک استاندارڈ ماشین ترجمہ سیسٹم معمولاً پاکیزہ ٹیکسٹ سے جوڑے ہوئے parallel corpus پر آموزش کی جاتی ہے اور اس کے ذریعہ پہچان نے آواز کے ساتھ تفصیل کی جاتی ہے، ایک فاصلہ جو بات ترجمہ کمونٹ میں خوب جانتا ہے۔ اس کاغذ میں، ہم ایک تدریس معماری پیشنهاد کرتے ہیں جو ایک نیورل ماشین کی ترجمہ موڈل بنانے کے لئے زیادہ طاقتور بنانے کا ارادہ رکھتا ہے. ہمارا طریقہ ایک دوسرے کے ساتھ کوڈر اور ڈیکوڈر کے ذریعہ مخالف تعلیم اور ڈیٹا اضافہ کرتا ہے۔ IWSLT2018 سخنرانی ترجمہ تاسک پر تجربہ کا نتیجہ دکھاتا ہے کہ ہماری طریقہ ASR اپوٹ اور MT اپوٹ کے درمیان تفاوت کا فاصلہ برابر کر سکتی ہے، اس میں 2.83 بلیوس کے لئے آواز ASR اپوٹ کے ذریعے بنسٹ لین سے زیادہ اضافہ کرتا ہے، جب کہ پاکیزہ', 'ta': 'ஒரு பைப்லைன் பேச்சு மொழிபெயர்ப்பு அமைப்பில், தானியங்கி பேச்சு ஒப்புக்கொள்ள (ASR) அமைப்பு பிழைகளை அடிக்குறிப்பில் பிழை Name In this paper, we propose a training architecture which aims at making a neural machine translation model more robust against speech recognition errors.  நம்முடைய அணுகல் குறியீட்டை மற்றும் குறியீட்டு மற்றும் அதே நேரத்தில் எதிர்மறை கல்வி மற்றும் தரவு அதிகரிப்பை பயன்படுத IWSLT2018 பேச்சு மொழிபெயர்ப்பு செயல்பாட்டில் சோதனையின் முடிவுகள் காட்டுகிறது ASR வெளியீட்டிற்கும் MT உள்ளீட்டுக்கும் இடைவெளியீடு இடைவெளியீட்டை காட்டு', 'uz': "Name A standard machine translation system is usually trained on parallel corpus composed of clean text and will perform poorly on text with recognition noise, a gap well known in speech translation community.  Bu qogʻozda, biz o'rganish maktablarini tahrirlashni talab qilamiz. Bu tilni tasdiqlash xatolari haqida qo'shish uchun neyrol maskina tarjima modelini yaratish mumkin. Bizning usuli kodlash usulini va oddiy foydalanuvchi o'rganish va maʼlumot yozib qoʻshish bilan foydalanadi. Name", 'vi': 'Trong một hệ thống dịch giọng qua đường ống, hệ thống nhận dạng giọng nói tự động (ASR) sẽ truyền lỗi nhận dạng sang hệ thống dịch máy xuôi dòng (MTV). Một hệ thống dịch chuyển máy tiêu chuẩn thường được huấn luyện trên tập thể song song song, gồm một văn bản sạch và sẽ không làm tốt trên văn bản với tiếng ồn nhận diện, một khoảng trống nổi tiếng trong cộng đồng dịch giọng nói. Trong tờ giấy này, chúng tôi đề xuất một kiến trúc sư huấn luyện nhằm làm một mô hình dịch cỗ máy thần kinh vững chắc hơn chống lại lỗi nhận dạng ngôn ngữ. Cách tiếp cận của chúng tôi nhằm vào bộ mã hóa và bộ giải, đồng thời sử dụng nghiên cứu đối nghịch và gia tăng dữ liệu. Thí nghiệm kết quả dịch giọng nói cho thấy rằng phương pháp của chúng ta có thể đảo hẹp giữa kết quả ASR và cơ nhập MTV, vượt qua thực hiện cơ sở cơ sở cơ bản trước đến 2.83 bắn ASR ồn ào, trong khi duy trì hiệu suất tích cực về văn bản sạch.', 'bg': 'В тръбопроводна система за превод на реч системата за автоматично разпознаване на реч (АСР) ще предава грешки при разпознаване към системата за машинен превод (МТ) надолу по веригата. Стандартната система за машинен превод обикновено се обучава на паралелен корпус, съставен от чист текст, и ще се представи зле върху текст с разпознавателен шум, празнота, която е добре позната в общността за речен превод. В настоящата статия предлагаме архитектура за обучение, която има за цел да направи невронен машинен превод модел по-здрав срещу грешки при разпознаване на реч. Нашият подход е насочен едновременно към кодера и декодера, използвайки съответно съперническо обучение и увеличаване на данните. Експерименталните резултати по задачата за превод на реч показват, че нашият подход може да преодолее пропастта между изхода и входа на МТ, превъзхожда базовата база с до 2,83 при шумен изход, като същевременно поддържа близка производителност при чист текст.', 'da': 'I et system til taleoversættelse vil automatisk talegenkendelse (ASR) overføre fejl i genkendelse til downstream maskinoversættelse (MT) systemet. Et standard maskinoversættelsessystem er normalt uddannet på parallel korpus bestående af ren tekst og vil fungere dårligt på tekst med genkendelsesstøj, et hul velkendt i taleoversættelsessamfundet. I denne artikel foreslår vi en uddannelsesarkitektur, der sigter mod at gøre en neural maskinoversættelsesmodel mere robust mod talegenkendelsesfejl. Vores tilgang behandler encoder og dekoder samtidig ved hjælp af henholdsvis modstridende læring og dataforøgelse. Eksperimentelle resultater på IWSLT2018 taleoversættelsesopgave viser, at vores tilgang kan bygge bro over kløften mellem ASR output og MT input, overgår baseline med op til 2,83 BLEU på støjende ASR output, samtidig med at den opretholder tæt ydeevne på ren tekst.', 'nl': 'In een pijpleidingspraakvertaalsysteem zal het automatische spraakherkenningssysteem (ASR) fouten in herkenning doorgeven aan het downstream machine translation (MT) systeem. Een standaard machine translation systeem is meestal getraind op parallelle corpus bestaande uit schone tekst en zal slecht presteren op tekst met herkenningsgeluid, een kloof die bekend is in spraakvertaalgemeenschap. In dit artikel stellen we een trainingsarchitectuur voor die erop gericht is een neuraal machinevertaalmodel robuuster te maken tegen spraakherkenningsfouten. Onze aanpak richt zich op de encoder en de decoder gelijktijdig met behulp van respectievelijk adversariaal learning en data augmentation. Experimentele resultaten met IWSLT2018 spraakvertaaltaak tonen aan dat onze aanpak de kloof tussen de ASR-uitvoer en de MT-invoer kan overbruggen, de baseline met maximaal 2.83 BLEU op ruisige ASR-uitvoer overtreft, terwijl nauwe prestaties op schone tekst worden gehandhaafd.', 'hr': 'U sustavu prevođenja govora cijevi, sistem automatskog priznanja govora (ASR) prenijet će greške u priznanju sustavu prevođenja strojeva (MT). Standardni sustav prevoda stroja obično se obučava na paralelnom korpusu sastavljenom od čistog teksta i loše će izvršiti na tekstu s bukom priznanja, prazninom poznatom u prijevoznoj zajednici. U ovom papiru predlažemo arhitekturu obuke koja cilja napraviti model prevoda neuronskih strojeva jačaniji protiv grešaka prepoznavanja govora. Naš pristup se obraća koderu i dekoderu istovremeno koristeći negativno učenje i povećanje podataka. Eksperimentalni rezultati na zadatku prevođenja govora IWSLT2018 pokazuju da naš pristup može prekinuti prazninu između proizvoda ASR-a i ulaza MT-a, iznosi početnu liniju do 2,83 BLEU-a na bučni proizvod ASR-a, dok održava blizu učinku na čistom tekstu.', 'de': 'In einem Pipeline-Sprachﾃｼbersetzungssystem ﾃｼbertrﾃ､gt das automatische Spracherkennungssystem (ASR) Erkennungsfehler an das nachgeschaltete maschinelle ﾃ彙ersetzungssystem. Ein Standard-maschinelles ﾃ彙ersetzungssystem wird normalerweise auf einem parallelen Korpus trainiert, der aus sauberem Text besteht und schlecht auf Text mit Erkennungsrausch funktioniert, eine Lﾃｼcke, die in der Sprachﾃｼbersetzungsgemeinschaft bekannt ist. In diesem Beitrag schlagen wir eine Trainingsarchitektur vor, die darauf abzielt, ein neuronales maschinelles ﾃ彙ersetzungsmodell robuster gegen Spracherkennungsfehler zu machen. Unser Ansatz adressiert Encoder und Decoder gleichzeitig mit Hilfe von adversarialem Lernen bzw. Datenauswertung. Experimentelle Ergebnisse bei der Sprachﾃｼbersetzungsaufgabe IWSLT2018 zeigen, dass unser Ansatz die Lﾃｼcke zwischen der ASR-Ausgabe und der MT-Eingabe ﾃｼberbrﾃｼcken kann, die Baseline um bis zu 2,83 BLEU bei rauschender ASR-Ausgabe ﾃｼbertrifft und gleichzeitig eine enge Leistung bei sauberem Text beibehﾃ､lt.', 'id': 'Dalam sistem terjemahan pidato pipeline, sistem pengakuan pidato otomatis (ASR) akan mengirim kesalahan dalam pengakuan ke sistem terjemahan mesin turun (MT). Sistem terjemahan mesin standar biasanya dilatih pada corpus paralel yang terdiri dari teks bersih dan akan melaksanakan buruk pada teks dengan suara pengenalan, ruang yang dikenal dalam komunitas terjemahan pidato. Dalam kertas ini, kami mengusulkan arsitektur pelatihan yang bermaksud membuat model terjemahan mesin saraf lebih kuat melawan kesalahan pengenal pidato. pendekatan kita mengarah koder dan dekoder secara bersamaan menggunakan pembelajaran musuh dan peningkatan data, sesuai. Hasil eksperimental pada tugas terjemahan pidato IWSLT2018 menunjukkan bahwa pendekatan kita dapat menyembunyikan ruang antara output ASR dan input MT, melampaui batas dasar dengan sampai 2,83 BLEU pada output ASR berisik, sementara mempertahankan prestasi dekat pada teks bersih.', 'ko': '유수선 음성번역시스템에서 자동음성인식(ASR) 시스템은 인식 오류를 다운스트림 기계번역(MT) 시스템으로 전송한다.표준적인 기계 번역 시스템은 보통 깨끗한 텍스트로 구성된 병행 어료 라이브러리에서 훈련을 하고 소음을 식별하는 텍스트에서 좋지 않다. 이것은 음성 번역계가 잘 알고 있는 차이점이다.본고에서 우리는 신경 기계 번역 모델이 음성 식별 오류에 대해 더욱 강한 노봉성을 가지도록 하는 훈련 체계 구조를 제시했다.우리의 방법은 각각 대항식 학습과 데이터 강화를 사용하여 인코더와 디코더를 동시에 처리한다.IWSLT2018 음성 번역 임무에서의 실험 결과, ASR 출력과 기계 번역 입력 사이의 차이를 메울 수 있는 우리의 방법은 소음이 있는 ASR 출력에서 기준선보다 2.83 BLEU 높은 동시에 깨끗한 텍스트에서 근접한 성능을 유지할 수 있음을 나타냈다.', 'sw': 'Katika mfumo wa kutafsiri hotuba ya pipeline, mfumo wa kutambua hotuba binafsi (ASR) utatuma makosa kwa kutambua kwenye mfumo wa kutafsiri mashine ya chini ya mto (MT). Mfumo wa utafsiri wa mashine wa kawaida unafundishwa mara nyingi katika viungo vinavyotengenezwa na maandishi safi na utafanya vibaya kwenye simu za viganjani kwa sauti ya kutambua, gap linalofahamika vizuri katika jamii ya kutafsiri hotuba. Katika karatasi hii, tunapendekeza ujenzi wa mafunzo ambao unakusudia kutengeneza muundo wa kutafsiri mashine ya kisasa zaidi dhidi ya makosa ya kutambua hotuba. Hatua yetu inaongeza utambulisho huo na kupunguza kwa wakati ule kwa kutumia elimu tofauti na kuongezeka kwa takwimu. Matokeo ya majaribio kwenye kazi ya tafsiri ya hotuba ya IWSLT2018 yanaonyesha kuwa mbinu yetu inaweza kukabiliana na tofauti kati ya matokeo ya ASR na matokeo ya MT, yanaonyesha msingi mpaka 2.83 BLEU juu ya sauti ya utoaji wa ASR, wakati wa kuendelea utendaji wa karibu kwenye ujumbe mfupi wa safi.', 'af': "In 'n pipeline spreek vertaling stelsel sal outomatiese spreek herken (ASR) stelsel foute in herken na die onderstreem masjien vertaling (MT) stelsel stuur. 'n Standaard masjien vertaling stelsel is gewoonlik onderwerp op parallele korpus gemaak van skoon teks en sal verkeerd uitvoer op teks met herkening ruis, 'n afstand wat goed bekend is in spreek vertaling gemeenskap. In hierdie papier voorstel ons 'n onderwerp arkitektuur wat doel om 'n neurale masjien vertaling model meer sterk te maak teen spraak herken foute. Ons toegang adres die enkoder en die dekoder saam met teëstandige leer en data vergroot, respektief. Eksperimentale resultate op IWSLT2018 spraak vertaling opdrag wys dat ons toegang kan die spans tussen die ASR uitvoer en die MT ingevoer, uitvoer die basisline deur tot by 2.83 BLES op geluid ASR uitvoer, terwyl onderhou toemaak uitvoer op skoon teks.", 'sq': 'Në një sistem përkthimi të fjalës në tubacion, sistemi i njohjes automatike të fjalës (ASR) do të transmetojë gabime në njohjen në sistemin e përkthimit të makinës së poshtëm (MT). Një sistem standard përkthimi i makinave zakonisht është trajnuar në korpus paralel i përbërë nga tekst i pastër dhe do të funksionojë keq në tekst me zhurmë njohjeje, një boshllëk i njohur mirë në komunitetin e përkthimit të fjalës. Në këtë letër, propozojmë një arkitekturë trainimi që synon të bëjë një model përkthimi nervor makineri më të fortë kundër gabimeve të njohjes së fjalës. Përqasja jonë trajton koduesin dhe dekoderin duke përdorur njëkohësisht mësimin kundërshtar dhe rritjen e të dhënave respektivisht. Rezultatet eksperimentale në detyrën e përkthimit të fjalimit IWSLT2018 tregojnë se qasja jonë mund të mbulojë dallimin midis daljes së ASR dhe hyrjes së MT, e tejkalon bazën me deri në 2.83 BLEU në daljen zhurmuese të ASR, duke mbajtur performancën e ngushtë në tekst të pastër.', 'fa': 'در سیستم ترجمه کردن سخنرانی لوله، سیستم شناسایی سخنرانی (ASR) خطاها را در شناسایی به سیستم ترجمه ماشین پایین (MT) انتقال می\u200cدهد. یک سیستم ترجمه ماشین استاندارد معمولاً روی کورپوس پارالی که از متن پاک ساخته شده آموزش می\u200cشود و بد روی متن با صدای شناختن، یک فاصله در جامعه ترجمه سخنرانی شناخته می\u200cشود. در این کاغذ، ما یک معماری آموزش پیشنهاد می\u200cکنیم که هدف می\u200cگیرد یک مدل ترجمه ماشین عصبی بر خلاف اشتباهی شناسایی سخنرانی قوی تر باشد. دسترسی ما به عنوان تغییر داده\u200cها با استفاده از یادگیری دشمنی و افزایش داده\u200cها به همزمان رمز\u200cکننده و دکورده\u200cکننده را دریافت می\u200cکند. نتیجه\u200cهای تجربه روی کار ترجمه سخنرانی IWSLT2018 نشان می\u200cدهد که دستور ما می\u200cتواند فاصله بین نتیجه ASR و نتیجه MT را برابر کند، در حالی که عملکرد نزدیک روی متن تمیز به پایین تا 2.83 BLEU بر نتیجه ASR صوت می\u200cکند.', 'tr': 'Tanyş sözleri terjime sisteminde, otomatik sözleri tanamak (ASR) sisteminde a şaky makine terjime (MT) sistemine hata gönderer. Adatça maşynyň terjime sistemi arassa metin bilen ýazylýan parallel korpusda bilinýär we tanyş sesi bilen boş boşluk bilen metin edip biler. Bu kagyzda, biz nural maşynyň terjime nusgasyny çykarmak üçin ýeterlik arhitektura teklip edýäris. Biziň ýaryşymyz kodçy we dekoderi bir gezek teňkil öwrenmek we maglumatlary ulanýar. IWSLT2018 çykyş terjime täblisindeki örän netijeleri ASR çizginiň we MT girişiniň arasynda gaplarymyzy köpräk edip biljekdigini görkez, ASR çizginiň sesi barada 2,83 BLEU-a çenli boýunça çykýar we ýakyn hereketlerimizi temiz metin üstünde tutup bilýär.', 'am': 'በ ጥያቄ ንግግር ትርጉም ሲስተም፣ የንግግር ማስታወቂያ (ASR) ስርዓት ስህተቶችን ወደ ታችኛው ድምፅ ማሻሻሻል (MT) ስርዓት ይሰድዳል። በንግግር ትርጉም ማኅበረሰብ የሚታወቀው ስህተት በንጹሕ ጽሑፍ የተደረገ የፓርላማ ድምፅ የተጠቃሚ የሞክራዊ መተርጓሜ ስርዓት የተጠቃሚ ነው፡፡ በዚህ ካላት፣ የናቡር መሳሪያ ትርጉም ሞዴል በንግግር ማስታወቂያው ስህተት ላይ የበለጠ የጦማር መሠረት መሠረትን እናሳልቃለን፡፡ አካባቢነታችን የኮድዶችን እና ቀድሞው በተጨማሪው ትምህርት እና ዳራዎችን በመጨመር ይጨምርበታል፡፡ በIWSLT2018 ንግግር ትርጉም ማድረግ ላይ የፈተና ውጤቶች በASR ውጤት እና MT input መካከል የልዩነትን መለያየት እንዲያሳየው ያሳያል፡፡', 'hy': 'Խոսքի թարգմանման խողովակաշարի համակարգում խոսքի ավտոմատիկ ճանաչման (ASR) համակարգը սխալներ կփոխանցի ճանաչման մեջ մեքենայի թարգմանման (MT) համակարգին: Ստանդարտ մեքենայի թարգմանման համակարգը սովորաբար պատրաստվում է զուգահեռ կորպոսի վրա, որը կազմված է մաքուր տեքստից, և վատ է աշխատում տեքստի վրա, որտեղ հայտնի է ճանաչողական աղմուկ, խոսքի թար Այս թղթի մեջ մենք առաջարկում ենք ուսուցման ճարտարապետություն, որի նպատակով նյարդային մեքենայի թարգմանման մոդելը ավելի ուժեղ դարձնել խոսքի ճանաչման սխալների դեմ: Մեր մոտեցումը դիտարկում է կոդերը և կոդերը միաժամանակ օգտագործելով հակառակ սովորելը և տվյալների աճը: IwSlat2018-ի խոսքի թարգմանման փորձարկման արդյունքները ցույց են տալիս, որ մեր մոտեցումը կարող է հաղթահարել արտացոլությունը ASR-ի և MT-ի միջև, հաղթահարել հիմնական արտացոլությունը մինչև 2.83ԲԼԵԵ-ի համար աղմկոտ ASR-ի արտացոլությունը, մինչդեռ պա', 'ca': "In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system.  Un sistema estàndard de traducció màquina està format en un corpus paral·lel compost de text net i no funcionarà bé en text amb soroll de reconeixement, una diferència ben coneguda en la comunitat de traducció de la paraula. In this paper, we propose a training architecture which aims at making a neural machine translation model more robust against speech recognition errors.  El nostre enfocament es dirigeix al codificador i al decodificador al mateix temps utilitzant l'aprenentatge adversari i l'augment de les dades, respectivament. Els resultats experimentals de la tasca de traducció del discurs IWSLT2018 mostren que el nostre enfocament pot superar la bretxa entre la producció ASR i la producció MT, supera la base d'un valor fins a 2,83 BLEU en la producció sorollosa ASR, mantenint un rendiment estret en text net.", 'bn': 'একটি পাইপেলাইন ভাষণ অনুবাদ সিস্টেমে, স্বয়ংক্রিয়ভাবে ভাষণ স্বীকৃতির (ASR) সিস্টেম স্বীকৃতির জন্য ত্রুটি ডানদ্রীম ম মেশিন অনু সাধারণত একটি মেশিন অনুবাদ সিস্টেম পরিষ্কার লেখার প্যারালেল কর্পাসে প্রশিক্ষণ প্রদান করা হয় এবং স্বীকৃতির কণ্ঠস্বর দ্বারা টেক্সটে ত এই কাগজটিতে আমরা একটি প্রশিক্ষণ কাঠামোর প্রস্তাব করছি যার লক্ষ্য হচ্ছে বাক স্বীকৃতির বিরুদ্ধে নিউরেল মেশিন অনুবাদ মডেল তৈ আমাদের প্রতিক্রিয়া এই এনকোডার এবং ডেকোডার একই সাথে বিরোধী শিক্ষা এবং তথ্য যোগাযোগ ব্যবহার করেছে। IWSLT2018 ভাষণ অনুবাদের কাজে পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের প্রতিযোগিতা আসার আউটপুট এবং এমটি ইনপুটের মধ্যে বিভ্রান্তি প্রদান করতে পারে, যেখানে কাছে পরিষ্কার প্রদর্শন', 'bs': 'U sustavu prevoda govora za cijevi, sistem automatskog priznanja govora (ASR) prenijet će greške u priznanju sustavu prevoda strojeva (MT). Standardni sistem prevoda mašine se obično obučava na paralelnom korpusu sastavljenom od čistog teksta i loše će izvršiti na tekstu sa bukom priznanja, prazninom u prijevoznoj zajednici. U ovom papiru predlažemo arhitekturu obuke koja cilja napraviti model prevoda neuralnih strojeva jačaniji protiv grešaka prepoznavanja govora. Naš pristup se obraća koderu i dekoderu istovremeno koristeći neprijateljsko učenje i povećanje podataka. Eksperimentalni rezultati na zadatku prevođenja govora IWSLT2018 pokazuju da naš pristup može prekriti prazninu između proizvoda ASR-a i ulaza MT-a, iznosi početnu liniju do 2,83 BLEU-a na bukni proizvod ASR-a, dok održava blizu učinku na čistom tekstu.', 'cs': 'V potrubí systému překladu řeči systém automatického rozpoznávání řeči (ASR) přenáší chyby v rozpoznávání do následného systému strojového překladu (MT). Standardní strojový překladatelský systém je obvykle trénován na paralelním korpusu složeném z čistého textu a bude fungovat špatně na textu s rozpoznávacím šumem, což je mezera dobře známá v komunitě překladatelů řeči. V tomto článku navrhujeme výcvikovou architekturu, jejímž cílem je zvýšit odolnost neuronového strojového překladu proti chybám rozpoznávání řeči. Náš přístup se zabývá snímačem a dekodérem současně pomocí adversariálního učení a rozšíření dat. Experimentální výsledky překladu řeči IWSLT2018 ukazují, že náš přístup dokáže překlenut mezeru mezi výstupem ASR a vstupem MT, překonává základní hodnotu až o 2,83 BLEU na hlučném ASR výstupu a při zachování těsného výkonu na čistém textu.', 'et': 'Kõnetõlkesüsteemis edastab automaatne kõnetuvastussüsteem (ASR) tuvastusvead järgmisele masintõlkesüsteemile. Standardset masintõlkesüsteemi koolitatakse tavaliselt puhtast tekstist koosneva paralleelkorpusega ning see toimib halvasti tuvastusmüraga teksti puhul, mis on kõnetõlke kogukonnas hästi tuntud lõhe. Käesolevas töös pakume välja koolituse arhitektuuri, mille eesmärk on muuta neuromasintõlke mudel tugevamaks kõnetuvastusvigade vastu. Meie lähenemisviis käsitleb kodeerijat ja dekooderit samaaegselt, kasutades vastavalt vastastikust õppimist ja andmete suurendamist. IWSLT2018 kõnetõlke ülesande eksperimentaalsed tulemused näitavad, et meie lähenemisviis suudab ületada lõhe ASR väljundi ja MT sisendi vahel, ületab algväärtust kuni 2,83 BLEU võrra müraka ASR väljundi puhul, säilitades samas tiheda jõudluse puhta teksti puhul.', 'fi': 'Pipeline-puhek채채nn철sj채rjestelm채ss채 automaattinen puheentunnistusj채rjestelm채 (ASR) v채litt채채 tunnistusvirheet jatkojalostuksen konek채채nn철sj채rjestelm채채n (MT). Tavanomainen konek채채nn철sj채rjestelm채 on yleens채 koulutettu puhtaasta tekstist채 koostuvalle rinnakkaiskorpuselle, ja se toimii huonosti tunnistavalla 채채nell채 varustetulla tekstill채, joka on hyvin tunnettu puhek채채nn철syhteis철ss채. T채ss채 ty철ss채 ehdotamme koulutusarkkitehtuuria, jonka tavoitteena on tehd채 neurokonek채채nn철smallista vahvempi puheentunnistusvirheit채 vastaan. L채hestymistapamme kohdistuu kooderiin ja dekooderiin samanaikaisesti k채ytt채m채ll채 vastakohtaista oppimista ja datan lis채채mist채. IWSLT2018-puhek채채nn철steht채v채n kokeelliset tulokset osoittavat, ett채 l채hestymistapamme voi kuroa umpeen ASR-ulostulon ja MT-sy철t철n v채lisen kuilun, ylitt채채 l채ht철tilanteen jopa 2,83 BLEU:lla meluisassa ASR-ulostulossa ja pit채채 samalla tiukan suorituskyvyn puhtaassa tekstiss채.', 'az': "Şifrə çətinli sözlərin çeviri sistemində, avtomatik sözlərin tanıması (ASR) sistemi a şağı-aşağı maşın çeviri sisteminə xətalar göndərəcək. Standart mašin çeviri sistemi genellikle təmiz mətndən oluşan paralel korpus üzərində təhsil edilir və təhsil səslə mətndə, sözlərin çeviri toplumunda yaxşı tanınan boşluq üzərində pislik edər. Bu kağızda, bir təhsil arhitektarını təklif edirik ki, sözləri tanıma hatalarının əleyhinə bir nöral maşına çevirilməsi modelini daha qüvvətli etmək niyyəti edir. Bizim yaxınlığımız kodlayıcı və dekoderi bir-birindən düşmənçilik öyrənməsi və veri artırmağı istifadə edir. IWSLT2018 sözlərin çevirilməsi təcrübəsində təcrübə sonuçlarının ASR çıxışı və MT girişi arasındakı boşluğu körpüşdürə biləcəyini göstərir, səs ASR çıxışı ilə 2,83 BLEU'a qədər səs çıxışı ilə, təmiz metin üstündə yaxın performansını saxlayaraq tərtəmiz", 'jv': 'Nang Sistem Pangan langgambar kang nggambar, Sistem Otomatik (ASR) kang disenyong kelas karo peranggunakake kapan Nang Sistem Anyar Ngucap Sistem (MT). System Nang pember iki, kita supoyo architecture tukang nggawe layang kanggo ngilangno model itoleh karo penting gal nggawe barang urip kuwi kesempatan. Ndolek dhéwé ngerasakno koder karo dekojer sampeyan gayutan nguliné pakan karo pergambar obang-pakan karo ngono pergambar data. Refirming', 'sk': 'V cevovodnem sistemu prevajanja govora bo sistem samodejnega prepoznavanja govora (ASR) prenesel napake pri prepoznavanju v sistem strojnega prevajanja (MT). Standardni sistem strojnega prevajanja je običajno usposobljen na vzporednem korpusu, sestavljenem iz čistega besedila, in bo slabo deloval na besedilu s hrupom prepoznavanja, vrzel, ki je dobro znana v skupnosti govornega prevajanja. V prispevku predlagamo arhitekturo usposabljanja, katere cilj je narediti model nevronskega strojnega prevajanja robustnejši proti napakam pri prepoznavanju govora. Naš pristop obravnava kodirnik in dekoder hkrati z uporabo kontrastnega učenja oziroma povečanja podatkov. Eksperimentalni rezultati govornega prevajanja IWSLT2018 kažejo, da lahko naš pristop premosti vrzel med ASR izhodom in MT vhodom, presega osnovno vrednost za do 2,83 BLEU pri hrupnem ASR izhodu, hkrati pa ohranja tesno zmogljivost pri čistem besedilu.', 'ha': "In wani tsari na fassarar magana na pipe, na'ura na ganin magana farat ɗaya zai shige errors cikin sunan da aka sani zuwa tsarin matafiyar da kuma (MT) na ƙarƙashin kwamfyuta. An amfani da tsarin fassarar mashine na daidaita ko da ɗabi'a, ana haɗa koshi na rubutun mai tsari na matsayin kuma zai yi aiki mai maras daidai a kan sauri na ganin, gap da aka sani cikin jamii fassarar magana. Ga wannan takardan, Munã bukãtar da wani matsayi mai amfani da shi, da aimakin ya sanya wani misalin fassarar masu aikin neura da za'a yi mafi sauri wa misalin ayuka. MataimakinMu yana yin amfani da kodi sami da kuma yana ƙara zane-zane da data. Matarin da aka jarraba a kan aikin fassarar magana na IWSLT2018 ya nuna cewa hanyarmu yana iya samar da gaura tsakanin fitarwa na SSR da inputan MT, yana samar da mafi ƙaranci 2.83 BLEU a kan sauri na AsR da kuma yana tsare cikakken performance kan text mai tsari.", 'he': 'במערכת תורגם נאום צינור, מערכת זיהוי נאום אוטומטי (ASR) תשלח טעויות בהזיהוי למערכת התרגום המכונית המאוחרת (MT). מערכת תרגום מכונות סטנדרטית היא בדרך כלל מאומנת על קורפוס מקביל מורכב מטקסט נקי ויוציא מבצע רע בטקסט עם רעש זיהוי, פער ידוע היטב בקהילת תרגום נאום. בעיתון הזה, אנו מציעים ארכיטקטורה אימונים שמתכוונת להפוך מודל תרגום מכונת עצבית חזק יותר נגד שגיאות זיהוי נאום. הגישה שלנו מתייחסת לקודר והדקודר באותו הזמן בשימוש ללמוד יריבי ועדכון נתונים, בהתאם. תוצאות ניסיוניות על משימה התרגום נאום IWSLT2018 מראות שהגישה שלנו יכולה לגשר את הפער בין יציאת ASR וליציאת MT, מגבילה את הבסיס עד 2.83 BLEU על יציאת ASR רעילה, בזמן שמחזיק ביצועים קרובים על טקסט נקי.', 'bo': 'In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system. རྒྱུན་ལྡན་གྱི་མ་ལག་གི་ཡིག་སྒྲུང་ནི་ཕན་ཚུན་ལས་གནད་མེད་ཅིག་ཡིག་ཆའི་ནང་དུ་གཞུང་མཐུན་བཟོ་བ་ཡིན་ནའང་ངེས་འཛིན་པའི་སྒྲུང་ འུ་ཅག་གི་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རང་ཉིད་སྒྲིག་བཟོ་བཅོས་བྱེད་སྤྲོད་ཡོད་པ་དེ་ནི་ངོས་ཉིད་ཆས་གཞུང་གི་མ་ལག་སྟ ང་ཚོའི་གཟུགས་སྐོར་གྱིས་སྐྱོན་བརྗོད་པ་དང་མཛེས་བྱེད་མཁན་གྱི་དབང་ཆ་སྤྲོ་སྣང་དང་གསལ་རྩིས་མཐུན་གཏོང་ Experimental results on IWSLT2018 speech translation task show that our approach can bridge the gap between the ASR output and the MT input, outperforms the baseline by up to 2.83 BLEU on noisy ASR output, while maintaining close performance on clean text.'}
{'en': 'Controlling the Output Length of Neural Machine Translation', 'es': 'Control de la longitud de salida de la traducción automática neuronal', 'ar': 'التحكم في طول إخراج ترجمة الآلة العصبية', 'fr': 'Contrôle de la longueur de sortie de la traduction automatique neuronale', 'pt': 'Controlando o comprimento de saída da tradução automática neural', 'ja': '神経機械翻訳の出力長の制御', 'zh': '制神经机器翻译输长', 'hi': 'न्यूरल मशीन अनुवाद के आउटपुट लंबाई को नियंत्रित करना', 'ru': 'Управление выходной длиной нейронного машинного перевода', 'ga': 'Fad Aschuir an Aistriúcháin Néar-Inneallta a Rialú', 'ka': 'ნეიროლური მაქინის გადაწყვეტის სიგრძე', 'hu': 'A neurális gépi fordítás kimeneti hosszának szabályozása', 'el': 'Έλεγχος του μήκους εξόδου της νευρωνικής μηχανικής μετάφρασης', 'it': 'Controllo della lunghezza di uscita della traduzione automatica neurale', 'kk': 'Неурал машинаның аудармасының шығыс ұзындығын басқару', 'ml': 'നെയുറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിന്റെ പുറത്തുള്ള നീളം നിയന്ത്രിക്കുന്നു', 'mt': 'Controlling the Output Length of Neural Machine Translation', 'mn': 'Үүний мэдрэлийн машины хөрөнгө дамжуулалтын урт', 'mk': 'Контролирање на должината на излезот на преведувањето на невралната машина', 'lt': 'Neuralinės mašinos vertimo išėjimo ilgio kontrolė', 'no': 'Kontrollerer lengda på utdatamaskinsomsetjinga', 'ms': 'Mengkawal Panjang Output Terjemahan Mesin Neural', 'pl': 'Kontrolowanie długości wyjściowej neuronowego tłumaczenia maszynowego', 'so': 'Controling the Output Length of Neural machine Translation', 'ro': 'Controlul lungimii de ieșire a traducerii mașinii neurale', 'sr': 'Kontroliranje dužine izlaza neurološkog prevoda mašine', 'ur': 'نیورال ماشین ترجمہ کے آئٹپوٹ لمبی کنٹرول کر رہے ہیں', 'si': 'න්\u200dයූරාල් මේෂින් පරිවර්තනය ගැන ප්\u200dරතික්\u200dරියාව පාලනය කරන්න', 'sv': 'Styra utmatningslängden för neural maskinöversättning', 'ta': 'புதிய இயந்திரத்தின் வெளியீட்டு நீளத்தை கட்டுப்படுத்துகிறது', 'uz': 'Tarjima', 'vi': 'Điều khiển độ dài xuất của máy thần kinh dịch', 'hr': 'Kontroliranje dužine izlaza Neuralnog prevoda stroja', 'nl': 'Controle van de uitvoerlengte van neurale machinevertaling', 'bg': 'Контролиране на дължината на изхода на невралния машинен превод', 'da': 'Styring af udgangslængden af neural maskinoversættelse', 'de': 'Steuerung der Ausgabelänge der neuronalen maschinellen Übersetzung', 'id': 'Mengontrol Panjang Output dari Translation Mesin Neural', 'ko': '신경기계 번역 출력 길이 제어', 'fa': 'کنترل طول نتیجه ترجمه ماشین عصبی', 'sw': 'Uthibiti wa Utafiti wa Mashine ya Kijerumani', 'sq': 'Kontrollimi i gjatësisë së daljes së përkthimit të makinës nervore', 'tr': 'Neural Maşynyň Çikgi Uzunlaryny Kontrol edýär', 'am': 'ምርጫዎች', 'af': 'Kontroleer die Uitset Lengte van Neurale Masjien Vertaling', 'hy': 'Նյարդային մեքենայի թարգմանման արտադրության երկարությունը կառավարելը', 'az': 'Nöral Makinatın Çıqtının Uzunluğunu Kontrol Et', 'bn': 'নিউরাল মেশিন অনুবাদের আউটপুটের দীর্ঘ নিয়ন্ত্রণ করা হচ্ছে', 'bs': 'Kontroliranje dužine izlaza neurološkog prevoda stroja', 'cs': 'Řízení délky výstupu neuronového strojového překladu', 'et': 'Neuraalse masintõlke väljundpikkuse kontrollimine', 'fi': 'Neuraalisen konekäännöksen lähtöpituuden hallinta', 'ca': 'Controllar la llargada de la producció de la traducció de la màquina neuronal', 'jv': 'Jejaring', 'sk': 'Nadzor izhodne dolžine nevralnega strojnega prevajanja', 'ha': 'KCharselect unicode block name', 'he': 'שליטה על אורך יציאה של התרגום של מכונה נוירולית', 'bo': 'དབྱིན་རྩིས་འཁོར་གྱི་བསྒྱུར་བའི་ཚད་བརྗོད་བྱེད་ཀྱི་ཡོད་ཚད'}
{'en': 'The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of ', 'ar': 'تعمل التطورات الحديثة التي أدخلتها الترجمة الآلية العصبية (NMT) على توسيع مجالات تطبيق الترجمة الآلية بسرعة ، فضلاً عن إعادة تشكيل مستوى الجودة المراد استهدافه. على وجه الخصوص ، إذا كان على الترجمات أن تتناسب مع تصميم معين ، فلا ينبغي قياس الجودة من حيث الملاءمة والطلاقة فحسب ، بل يجب أيضًا قياس الطول. الحالات النموذجية هي ترجمة ملفات المستندات والعناوين الفرعية والنصوص للدبلجة ، حيث يجب أن يكون طول الإخراج بشكل مثالي أقرب ما يمكن إلى طول نص الإدخال. عناوين pa-per هذه لأول مرة ، على حد علمنا ، مشكلة التحكم في طول الإخراج في NMT. نحن نحقق في طريقتين لتحيز طول الإخراج باستخدام بنية المحولات: 1) تكييف الإخراج إلى فئة نسبة طول مصدر مستهدفة معينة و 2) إثراء التضمين الموضعي للمحول بمعلومات الطول. تُظهر تجاربنا أن كلا الطريقتين يمكن أن تحث الشبكة على إنشاء ترجمات أقصر ، بالإضافة إلى اكتساب مهارات لغوية قابلة للتفسير.', 'pt': 'Os avanços recentes introduzidos pela tradução automática neural (NMT) estão expandindo rapidamente os campos de aplicação da tradução automática, bem como reformulando o nível de qualidade a ser direcionado. Em particular, se as traduções tiverem que se adequar a um determinado layout, a qualidade não deve ser medida apenas em termos de adequação e fluência, mas também em comprimento. Casos exemplares são a tradução de arquivos de documentos, legendas e scripts para dublagem, onde o comprimento de saída deve ser o mais próximo possível do comprimento do texto de entrada. Este artigo aborda pela primeira vez, até onde sabemos, o problema de controlar o comprimento de saída em NMT. Nós investigamos dois métodos para polarizar o comprimento de saída com uma arquitetura de transformador: i) condicionar a saída a uma determinada classe de razão de comprimento de fonte-alvo e ii) enriquecer o encaixe posicional do transformador com informações de comprimento. Nossos experimentos mostram que ambos os métodos podem induzir a rede a gerar traduções mais curtas, além de adquirir habilidades linguísticas interpretáveis.', 'es': 'Los avances recientes introducidos por la traducción automática neuronal (NMT) están ampliando rápidamente los campos de aplicación de la traducción automática, así como remodelando el nivel de calidad al que se dirige. En particular, si las traducciones tienen que ajustarse a un diseño determinado, la calidad no solo debe medirse en términos de adecuación y fluidez, sino también de longitud. Los casos ejemplares son la traducción de archivos de documentos, subtítulos y guiones para doblaje, donde la longitud de salida debería ser lo más cercana posible a la longitud del texto de entrada. Este pa-per aborda por primera vez, según nuestro conocimiento, el problema de controlar la longitud de salida en NMT. Investigamos dos métodos para polarizar la longitud de salida con una arquitectura de transformador: i) acondicionar la salida a una clase dada de relación de longitud objetivo-fuente y ii) enriquecer la incrustación posicional del transformador con información de longitud. Nuestros experimentos muestran que ambos métodos pueden inducir a la red a generar traducciones más cortas, así como a adquirir habilidades lingüísticas interpretables.', 'fr': "Les récentes avancées introduites par la traduction automatique neuronale (NMT) élargissent rapidement les domaines d'application de la traduction automatique et remodèlent le niveau de qualité à cibler. En particulier, si les traductions doivent correspondre à une mise en page donnée, la qualité doit être mesurée non seulement en termes d'adéquation et de fluidité, mais également en termes de longueur. Des exemples sont la traduction de fichiers de documents, de sous-titres et de scripts pour le doublage, où la longueur de sortie doit idéalement être aussi proche que possible de la longueur du texte d'entrée. Ce pa-per aborde pour la première fois, au meilleur de nos connaissances, le problème du contrôle de la longueur de sortie en NMT. Nous étudions deux méthodes pour polariser la longueur de sortie avec une architecture de transformateur\xa0: i) conditionner la sortie à une classe de rapport longueur-source cible donnée et ii) enrichir l'intégration de position du transformateur avec des informations de longueur. Nos expériences montrent que les deux méthodes peuvent amener le réseau à générer des traductions plus courtes, ainsi qu'à acquérir des compétences linguistiques interprétables.", 'ja': '神経機械翻訳（ NMT ）によって導入された最近の進歩は、対象となる品質レベルを再形成するだけでなく、機械翻訳の応用分野を急速に拡大している。 特に、翻訳が特定のレイアウトに適合しなければならない場合、品質は、妥当性と流暢性だけでなく、長さの観点からも測定されるべきです。 例示的なケースは、ダビングのためのドキュメントファイル、字幕、およびスクリプトの翻訳であり、出力長は、理想的には、入力テキストの長さに可能な限り近づける必要があります。 このPA - PERは、私たちの知る限りでは、NMTで出力長を制御する問題に初めて対処します。 変圧器アーキテクチャで出力長さをバイアスするための2つの方法を検討します。i ）出力を所与のターゲットソース長さ比クラスに調整することと、ii ）変圧器位置埋め込みを長さ情報で濃縮することです。 私たちの実験は、両方の方法がネットワークを誘導してより短い翻訳を生成するだけでなく、言語スキルを得ることができることを示しています。', 'ru': 'Недавние достижения в области нейронного машинного перевода (НМП) быстро расширяют области применения машинного перевода, а также изменяют уровень качества, который должен быть нацелен. В частности, если переводы должны соответствовать определенному формату, качество должно измеряться не только с точки зрения адекватности и беглости, но и длины. Примерами являются переводы файлов документов, субтитров и сценариев для дублирования, где в идеале выходная длина должна быть как можно ближе к длине входного текста. Насколько нам известно, этот пункт впервые затрагивает проблему управления длиной выхода в НМП. Мы исследуем два метода смещения выходной длины с помощью архитектуры трансформатора: i) приведение выхода к заданному классу отношения длины источника к длине и ii) обогащение позиционного встраивания трансформатора информацией о длине. Наши эксперименты показывают, что оба метода могут побуждать сеть генерировать более короткие переводы, а также приобретать промежуточные лингвистические навыки.', 'zh': '神经机器翻译(NMT)引入最新进展方速广机器翻译应用领域,重塑其质平。 若译者必当其给定,则量不独当量以充分性流畅性,又当量以长短。 示例者,文档文也,字幕配音脚本之译也,意欲尽近文本也。 以吾所知,此pa-per初制NMT中输长度也。 臣等考用变压器架构偏置输长二法:i)将输调节为给定者比等,及ii)用长息丰衍变压器位嵌。 吾实验明之,此二者皆可诱网络生更短之译,而得交互之语。', 'hi': 'तंत्रिका मशीन अनुवाद (एनएमटी) द्वारा शुरू की गई हालिया प्रगति मशीन अनुवाद के आवेदन क्षेत्रों का तेजी से विस्तार कर रही है, साथ ही साथ लक्षित होने के लिए गुणवत्ता स्तर को फिर से आकार दे रही है। विशेष रूप से, यदि अनुवादों को कुछ दिए गए लेआउट को फिट करना है, तो गुणवत्ता को न केवल पर्याप्तता और प्रवाह के संदर्भ में मापा जाना चाहिए, बल्कि लंबाई भी। अनुकरणीय मामले डबिंग के लिए दस्तावेज़ फ़ाइलों, उपशीर्षकों और स्क्रिप्ट का अनुवाद हैं, जहां आउटपुट लंबाई आदर्श रूप से इनपुट पाठ की लंबाई के जितना संभव हो उतना करीब होना चाहिए। यह पीए-प्रति पते पहली बार, हमारे ज्ञान का सबसे अच्छा करने के लिए, एनएमटी में आउटपुट लंबाई को नियंत्रित करने की समस्या है। हम एक ट्रांसफॉर्मर आर्किटेक्चर के साथ आउटपुट लंबाई को पूर्वाग्रहित करने के लिए दो तरीकों की जांच करते हैं: i) किसी दिए गए लक्ष्य-स्रोत लंबाई-अनुपात वर्ग के लिए आउटपुट को कंडीशनिंग करना और ii) लंबाई की जानकारी के साथ ट्रांसफॉर्मर स्थितीय एम्बेडिंग को समृद्ध करना। हमारे प्रयोगों से पता चलता है कि दोनों विधियां नेटवर्क को छोटे अनुवाद उत्पन्न करने के लिए प्रेरित कर सकती हैं, साथ ही साथ अंतर-पूर्व-पूर्व-योग्य भाषाई कौशल प्राप्त कर सकती हैं।', 'ga': 'Tá an dul chun cinn le déanaí a tugadh isteach le haistriúchán meaisín néarach (NMT) ag leathnú go tapa ar réimsí iarratais an aistriúcháin mheaisín, chomh maith leis an leibhéal cáilíochta a bhfuiltear ag díriú air a athmhúnlú. Go háirithe, má chaithfidh aistriúcháin leagan amach áirithe a chur in oiriúint, ní hamháin gur chóir cáilíocht a thomhas i dtéarmaí leordhóthanachta agus líofachta, ach freisin i dtéarmaí fad. Is éard atá i gcásanna eiseamláireacha ná comhaid doiciméad, fotheidil, agus scripteanna a aistriú lena dubáil, áit ar cheart go mbeadh fad an aschuir chomh gar agus is féidir d’fhad an téacs ionchuir. Tugann an páipéar seo aghaidh den chéad uair, chomh fada agus is eol dúinn, ar an bhfadhb a bhaineann le fad an aschuir a rialú in NMT. Déanaimid imscrúdú ar dhá mhodh chun fad an aschuir a chlaonadh le hailtireacht claochladáin: i) an t-aschur a riochtú go dtí aicme cóimheas faid sprice-foinse tugtha agus ii) leabú suíomh an claochladáin a shaibhriú le faisnéis faid. Léiríonn ár dturgnaimh gur féidir leis an dá mhodh an gréasán a mhealladh chun aistriúcháin níos giorra a ghiniúint, chomh maith le scileanna teanga inléite a fháil.', 'ka': 'მიმდინარე პროგრესი, რომელიც ნეიროლური მანქანის გაგრძელებით (NMT) გამოიყენებულია, მანქანის გაგრძელების პროგრამის ფაილების გაფარდება, და მიზეზებელი კავილური დო განსაკუთრებულია, თუ განსაკუთრებულება უნდა დასწორება განსაკუთრებული სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვა სხვ მაგალითად შემთხვევაში არის დოკუმენტის ფაილების, საბეტატილის და სკრიპტის გადატყვება, სადაც გადატყვების სიგრძე იდეალურად უნდა იყოს შესაძლებელად გადარჩენა ტექსტის სიგრძ პირველი ჯერ, ჩვენი მეცნიერების უკეთესი, პრობლემა, რომელიც NMT-ში გამოყენებული სიგრძე კონტროლურება. ჩვენ შევსწავლობთ ორი მეტოვები გამოყენების სიგრძე განმავლობისთვის განმავლობისთვის განმავლობისთვის განმავლობისთვის: i) გამოყენების განმავლობას მინიშვნელი სიგრძე-სიგრძე კლასში და ii) განმავლობას ჩვენი ექსპერიმენტები აჩვენებს, რომ ორივე მეტები შეუძლიათ ქსელის წარმოიქმნა კიდევ კიდევ შეცვალობა, როგორც შეიძლია კიდევ კიდევ შეცვალობა, და ინტე', 'hu': 'A neurális gépi fordítás (NMT) által a közelmúltban bevezetett fejlesztések gyorsan bővítik a gépi fordítás alkalmazási területeit, valamint átalakítják a célzott minőségi szintet. Különösen, ha a fordításoknak meg kell illeszkedniük egy adott elrendezéshez, a minőséget nem csak a megfelelőség és a folyékonyság szempontjából kell mérniük, hanem a hossz is. Példaesetek a dokumentumfájlok, feliratok és szkriptek fordítása a szinkronizáláshoz, ahol a kimeneti hossznak ideális esetben a lehető legközelebb kell lennie a beviteli szöveg hosszához. Ez a pa-per első alkalommal, legjobb tudásunk szerint, foglalkozik a kimeneti hossz szabályozásának problémájával NMT-ben. Két módszert vizsgálunk a kimeneti hossz transzformátor architektúrával történő elfogulatosítására: i) a kimenet egy adott célforrás-hosszarány osztályra történő kondicionálására és ii) a transzformátor pozíciós beágyazásának hosszúsági információkkal gazdagítására. Kísérleteink azt mutatják, hogy mindkét módszer képes arra, hogy a hálózat rövidebb fordításokat generáljon, valamint értelmezhető nyelvi készségeket szerezzen.', 'el': 'Οι πρόσφατες εξελίξεις που εισάγονται από τη νευρωνική μηχανική μετάφραση (NMT) επεκτείνουν γρήγορα τους τομείς εφαρμογής της μηχανικής μετάφρασης, καθώς και αναδιαμορφώνουν το επίπεδο ποιότητας που πρέπει να στοχεύεται. Ειδικότερα, εάν οι μεταφράσεις πρέπει να ταιριάζουν σε κάποια συγκεκριμένη διάταξη, η ποιότητα δεν πρέπει να μετράται μόνο από την άποψη της επάρκειας και της ευκρίνειας, αλλά και του μήκους. Παραδείγματα είναι η μετάφραση αρχείων εγγράφων, υπότιτλων και σεναρίων για μεταγραφή, όπου το μήκος εξόδου θα πρέπει ιδανικά να είναι όσο το δυνατόν πιο κοντά στο μήκος του κειμένου εισαγωγής. Αυτό το pa-per αντιμετωπίζει για πρώτη φορά, από όσο γνωρίζουμε, το πρόβλημα του ελέγχου του μήκους εξόδου σε NMT. Ερευνούμε δύο μεθόδους για την προκατάληψη του μήκους εξόδου με μια αρχιτεκτονική μετασχηματιστή: i) τον καθορισμό της εξόδου σε μια δεδομένη κατηγορία μήκους-λόγου στόχου-πηγής και ii) τον εμπλουτισμό της θέσης ενσωμάτωσης του μετασχηματιστή με πληροφορίες μήκους. Τα πειράματά μας δείχνουν ότι και οι δύο μέθοδοι μπορούν να προκαλέσουν το δίκτυο να παράγει μικρότερες μεταφράσεις, καθώς και να αποκτήσει αξιόλογες γλωσσικές δεξιότητες.', 'it': "I recenti progressi introdotti dalla traduzione automatica neurale (NMT) stanno rapidamente espandendo i campi di applicazione della traduzione automatica, così come rimodellando il livello di qualità da indirizzare. In particolare, se le traduzioni devono adattarsi a un determinato layout, la qualità dovrebbe essere misurata non solo in termini di adeguatezza e fluidità, ma anche in termini di lunghezza. Casi esemplari sono la traduzione di file di documenti, sottotitoli e script per il doppiaggio, dove la lunghezza dell'output dovrebbe idealmente essere il più vicino possibile alla lunghezza del testo in ingresso. Questo pa-per affronta per la prima volta, al meglio delle nostre conoscenze, il problema del controllo della lunghezza di uscita in NMT. Esaminiamo due metodi per distorcere la lunghezza dell'uscita con un'architettura del trasformatore: i) condizionare l'uscita ad una data classe di rapporto lunghezza-sorgente target e ii) arricchire l'incorporamento posizionale del trasformatore con informazioni sulla lunghezza. I nostri esperimenti dimostrano che entrambi i metodi possono indurre la rete a generare traduzioni più brevi, oltre ad acquisire competenze linguistiche interpretabili.", 'kk': 'Невралдық компьютерді аудару (NMT) жуырдағы жаңа жағдайлары машинаның аудару өрістерін және мақсатты сапаттың деңгейін қайта жасау керек. Егер аудармалар кейбір келтірілген сәйкестіктерге сәйкес келсе, сапасы тек адекват мен жылдамдылық қасиетінде өлшемілмейді, сондай-ақ ұзындығы да. Мысалы, құжаттың файлдарын, субтитрлерін және скрипттерін аударуға болады. Кіріс мәтіннің ұзындығына идеалдық түрде жақын болуы мүмкін. Бұл папа адрестері бірінші рет, біліміздің ең жақсы білімізге, NMT шығыс ұзындығын басқару мәселесі. Біз шығыс ұзындығын түрлендіруші архитектурасы арқылы түрлендіру үшін екі әдістерді зерттеуді: i) шығысты келтірілген мақсатты көзінің ұзындығы класына шарттап, ii) ұзындығымен түрлендіруші ор Біздің тәжірибеміздің екі әдістеріміз желіне қысқа аудармаларды жасауға, және тілдік тілдік көңілдерін алу мүмкіндігін көрсетеді.', 'mk': 'Неодамнешните напредоци воведени од неуралниот машински превод (НМТ) брзо ги прошируваат полињата на апликациите на машински превод, како и го преформираат квалитетното ниво што треба да биде насочено. Особено, ако преведувањата мора да одговараат на одреден распоред, квалитетот треба да се мери не само во поглед на соодветноста и течноста, туку и должината. Примероци се преводот на датотеките на документите, субтитулите и скриптите за подбивање, каде должината на излезот идеално треба да биде што поблиску до должината на внесениот текст. Ова pa-per адреса за прв пат, од нашето најдобро знаење, проблемот со контролата на должината на излезот во НМТ. Истражуваме два методи за пристраснување на должината на излезот со архитектура на трансформаторот: i) кондиционирање на излезот на одредена класа за должина на изворот на целта и ii) богатство на позиционалното вградување на трансформаторот со информации за должина. Нашите експерименти покажуваат дека двата методи можат да ја индукционираат мрежата да генерира пократки преводи, како и да добие интерпретабилни јазични вештини.', 'lt': 'Naujausi pažanga, padaryta naudojant neurologinį mašinų vertimą (NMT), sparčiai išplečia mašinų vertimo taikymo sritis ir pertvarko tikslinį kokybės lygį. Visų pirma, jei vertimai turi atitikti tam tikrą išdėstymą, kokybė turėtų būti vertinama ne tik tinkamumo ir lankstumo, bet ir ilgio atžvilgiu. Pavyzdiniai atvejai yra dokumentų failų, subtitlų ir dubiavimo scenarijų vertimas, kai išvesties ilgis idealiai turėtų būti kuo artimesnis įvesties teksto ilgiui. Šis pa-per pirmą kartą, mūsų žiniomis, sprendžia NMT išėjimo ilgio kontrolės problem ą. Tiriame du i šėjimo ilgio nukreipimo metodus su transformatoriaus architektūra: i) išėjimo kondicionavimas į tam tikrą tikslinio šaltinio ilgio santykio klasę ir ii) transformatoriaus padėtinio įterpimo praturtinimas su ilgio informacija. Mūsų eksperimentai rodo, kad abu metodai gali paskatinti tinklą kurti trumpesnius vertimus ir įgyti aiškinamųjų kalbų įgūdžių.', 'ms': 'Kemajuan baru-baru ini diperkenalkan oleh terjemahan mesin saraf (NMT) mengembangkan dengan cepat medan aplikasi terjemahan mesin, serta membentuk semula aras kualiti yang akan ditujukan. Terutama, jika terjemahan perlu muat dengan beberapa bentangan yang diberikan, kualiti tidak hanya perlu diukur dalam terma keperluan dan keterlaluan, tetapi juga panjang. Kasus contoh adalah terjemahan fail dokumen, subtitle, dan skrip untuk dubbing, di mana panjang output patut secara ideal menjadi sebanyak yang mungkin dengan panjang teks input. Ini pa-per alamat untuk pertama kalinya, untuk yang terbaik dari pengetahuan kita, masalah mengawal panjang output dalam NMT. Kami menyelidiki dua kaedah untuk menentang panjang output dengan arkitektur pengubah: i) menguatkan output ke kelas nisbah panjang sumber-sasaran yang diberikan dan ii) memperkaya penerbangan kedudukan pengubah dengan maklumat panjang. Eksperimen kami menunjukkan bahawa kedua-dua kaedah boleh mendorong rangkaian untuk menghasilkan terjemahan yang lebih pendek, serta mendapatkan keterampilan bahasa yang boleh ditujukan.', 'ml': 'ന്യൂറല്\u200d യന്ത്രത്തിന്റെ പരിഭാഷ (NMT) നിര്\u200dമ്മിക്കുന്ന അടുത്തുള്ള പുരോഗങ്ങള്\u200d മെഷിന്\u200d പരിഭാഷ പ്രയോഗത്തിന്റെ പ്രയോഗത്തിന്റെ പ്രയോഗത പ്രത്യേകിച്ച്, വിഭാഷകങ്ങള്\u200d കൊടുത്തിട്ടുള്ള ലേയൌട്ടിന്റെ ആവശ്യമുണ്ടെങ്കില്\u200d തീര്\u200dച്ചയായും കൂടുതല്\u200d അളവും കൂടുതല്\u200d  @ info: whatsthis നമ്മുടെ അറിവിന്റെ ഏറ്റവും മികച്ച പ്രധാനപ്പെട്ട വിലാസങ്ങള്\u200dക്ക്, NMT-ലെ പുറത്തുള്ള നീളം നിയന്ത്രിക്കുന്നതി നീളം വിവരങ്ങള്\u200d കൊണ്ട് മാറ്റുന്ന ഒരു ലക്ഷ്യസ്സോര്\u200dസ് നീളമുള്ള ക്ലാസിലേക്ക് ഉള്ള പൂട്ടിന്\u200dറെ നീളമുള്ള നീളം പിന്തുടരുന്നതിനായി രണ്ട് രീതികള്\u200d  നമ്മുടെ പരീക്ഷണങ്ങള്\u200d കാണിച്ചു കൊണ്ടിരിക്കുന്നു രണ്ട് രീതികള്\u200dക്കും നെറ്റ്റര്\u200dനെറ്റില്\u200d ചെറുതായ പരിഭാഷകള്\u200d ഉണ്ടാക്കാ', 'mn': 'Сүүлийн үед мэдрэлийн машины хөгжүүлэлт (NMT) нь машины хөгжүүлэлтийн талбарыг хурдан нэмэгдүүлж байна. Мөн зориулахын тулд сайн чанарын түвшин дахин нэмэгдүүлж байна. Ялангуяа, хэрвээ орчуулалт зарим төлөвлөгдсөн төлөвлөгөөтэй байвал, сайн чанар зөвхөн адилхан, шингэнт, мөн урт хэмжээтэй биш. Жишээлбэл тохиолдол бол баримт файлуудын, суурь загваруудын, суурь загваруудын, шинжлэх зэрэг шинжлэх ухагдах скриптүүдийн орчуулалт юм. Ингээд өгөгдлийн текст урт нь хамгийн ойрхон байх ёстой Эхний удаа энэ аав-аас хамгийн сайн мэдлэгтэй, NMT-ийн үр дүнг удирдах асуудал юм. Бид бүтээгдэхүүний уртыг өөрчлөгчийн архитектуртай харьцуулахын тулд хоёр аргыг судалж байна: i) бүтээгдэхүүнийг өгөгдсөн зорилго-эх уртын харьцаа хичээл болон ii) уртын мэдээллээр шилжүүлэгчийн байр суурийг багасгаж байна. Бидний туршилтууд хоёр арга нь хоёр арга нь хугацаанд илүү богино орчуулалт үүсгэх боломжтой гэдгийг харуулдаг.', 'pl': 'Ostatnie postępy wprowadzone przez neuronalne tłumaczenie maszynowe (NMT) szybko rozszerzają obszary zastosowań tłumaczenia maszynowego, a także zmieniają poziom jakości, który ma być ukierunkowany. W szczególności jeśli tłumaczenia muszą pasować do danego układu, jakość powinna być mierzona nie tylko pod względem adekwatności i płynności, ale także długości. Przykładowymi przypadkami są tłumaczenia plików dokumentów, napisów i skryptów do dubbingu, gdzie długość wyjścia powinna być idealnie jak najbliższa długości tekstu wejściowego. Po raz pierwszy, zgodnie z naszą najlepszą wiedzą, to pa-per odnosi się do problemu kontroli długości wyjściowej w NMT. Badamy dwie metody biasowania długości wyjściowej z architekturą transformatora: i) uwarunkowanie wyjścia do danej klasy stosunku długości do źródła docelowego oraz ii) wzbogacenie osadzenia pozycji transformatora informacjami o długość. Nasze eksperymenty pokazują, że obie metody mogą skłonić sieć do generowania krótszych tłumaczeń, a także zdobywania interesujących umiejętności językowych.', 'no': 'Den siste avanserte utviklingane som er innført av neuralmaskinsomsetjinga (NMT) er raskt utvida programmefelta for maskinsomsetjing, og gjenoppretta kvalitetsnivået som skal gjenopprettast. Dersom omsetjingar må passa til nokre oppgjevne utforming, bør kvaliteten ikkje berre målare ved høve til adekvitet og fluktet, men også lengd. Eksempel tilfeller er omsetjinga av dokumentfiler, subtitler og skript for dubbeling, der utdata lengda skal ideelt vera så lukka som mogleg til lengden på inndata- teksten. Denne pa- per- adressen for første gong, til det beste vitninga vårt, problemet med å kontrollera utdata- lengden i NMT. Vi undersøker to metoder for å forskyve utgangspunktet med ein transformeringsarkitektur: i) forandrar utgangspunktet til ein gitt målkjeldende-forholdklasse og ii) røyke transformeringsposisjonell innbygging med lengdinformasjon. Eksperimentane våre viser at begge metodar kan indusera nettverket for å laga kortere oversettelsar, og å henta interpretabile språkstiske ferdighetar.', 'ro': 'Recentele progrese introduse de traducerea automată neurală (NMT) extind rapid domeniile de aplicare ale traducerii automate, precum și remodelarea nivelului de calitate care urmează să fie vizat. În special, dacă traducerile trebuie să se potrivească unui anumit aspect, calitatea ar trebui măsurată nu numai în termeni de adecvare și fluență, ci și în termeni de lungime. Cazurile exemplare sunt traducerea fișierelor de documente, subtitrărilor și scripturilor pentru dublare, în cazul în care lungimea ieșirii ar trebui să fie cât mai apropiată posibil de lungimea textului introdus. Acest pa-per abordează pentru prima dată, din câte ştim, problema controlării lungimii ieşirii în NMT. Investigăm două metode de părtinire a lungimii ieșirii cu o arhitectură de transformator: i) condiționarea ieșirii la o anumită clasă lungime-sursă și ii) îmbogățirea poziției transformatorului cu informații despre lungime. Experimentele noastre arată că ambele metode pot induce rețeaua să genereze traduceri mai scurte, precum și să dobândească abilități lingvistice interpreteabile.', 'sr': 'Nedavni napredak koji je uveden neuralnim prevodom mašine (NMT) brzo proširi polje prijave mašinskog prevoda, kao i ponovno preobraćaju nivo kvalitete koji će biti ciljani. Posebno, ako prevodi moraju da se uklapaju u neku određenu rasporedu, kvalitet bi trebala biti mjerena ne samo u smislu adekvatnosti i tekućine, nego i dužine. Na primer slučajevi su prevod dokumenta, podnaslova i skripta za dubljenje, gde bi dužina izlaza trebala biti najbliži što je moguće dužini ulaznog teksta. Ovaj tata po prvi put, na najbolje od našeg znanja, problem kontrole dužine izlaza u NMT-u. Istražujemo dve metode za predrasude dužine izlaza sa transformatorskom arhitekturom: i) uvođenje izlaza u određenu klasu dužine odnosa sa ciljevim izvorima i ii) bogatstvo transformatorskog pozicionalnog ugrađenja dužinskim informacijama. Naši eksperimenti pokazuju da obje metode mogu izazvati mrežu da proizvede kraće prevode, kao i nabavljanje interpretabilnih jezičkih vještina.', 'si': 'න්\u200dයුරල් මැෂින් පරිවර්තනය (NMT) වලින් ආරම්භ කරලා තියෙන අවස්ථාව පරිවර්තනය කරනවා මැෂින් පරිවර්තනයේ අවස්ථාව විශේෂයෙන්, පරිවර්තනය සමහර දෙන්න ප්\u200dරමාණය සමහර විදිහට සම්බන්ධ වෙන්න ඕන නම්, ප්\u200dරමාණය සහ ප්\u200dරමාණය සමහර වි සාමාන්\u200dය විදියට තත්වය ගොනුව, සබ්ටිටල් සහ ස්ක්\u200dරිප්ට් වලින් පරිවර්තන විදියයි, එළියට ප්\u200dරවිදියට ප්\u200dරවිදියට ඇතුළත් පා මේ තාත්තා ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප අපි පරීක්ෂණය කරන්න ප්\u200dරවෘතිය දෙකක් ප්\u200dරවෘතිය ප්\u200dරවෘතිය සඳහා ප්\u200dරවෘතිය ස්ථාපනය සඳහා ප්\u200dරවෘතිය ප්\u200dරවෘතිය: i) ප්\u200dරවෘතිය දෙන්න අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් දෙන්නම ප්\u200dරවේශය දෙන්නම් ජාලය ප්\u200dරවේශ කරන්න පුළුවන් විතරයි, වගේම අන්තර්ජ', 'so': 'Waxbarashada qoraalka neurada (NMT) ayaa si dhaqso ah u sii kordhinaya beeraha lagu turjumayo turjumista machine, sidoo kale beddelista heerka qiimaha ee la hagayo. Si gaar ah, haddii turjumaadu ay u baahan yihiin inay ku habboon qoraal cayiman, waa in la qiyaaso qiimaha ku saabsan saxda iyo faa’iidada, laakiin waa in la qiyaaso dhererka. Xaaladaha tusaale ahaan waa turjumidda filimaha dukumentiyada, meelaha hoose loo dhigo, iyo qoraal-tababarida, kuwaas oo ay ku habboon tahay in dhererka soo bixinta aad ugu dhaw karto dhererka qoraalka gudaha. Magaalooyinkan dada-per waa marka ugu horeysay, tan ugu fiican aqoonteenna, dhibaatada maamulida dhererka soo baxa ee NMT. Waxaynu baaraynaa laba qaab oo ku baahan karnaa dhererka soo baxa iyo dhismaha beddelinta: i) si aan u sameyno dhamaanka fasalka dhererka ee jiilaalka iyo (ii) oo ku hodanayno beddelinta beddelka si booska ah oo ku qoran macluumaadka dheer. Imtixaankayada waxay muuqan karaan in labada qaab ay ku sameyn karaan shabakadda si ay u soo saarto turjumaadyo gaaban, sidoo kale in ay helaan aqoonta luuqadda oo kala duwan.', 'sv': 'De senaste framstegen med neural maskinöversättning (NMT) expanderar snabbt tillämpningsområdena för maskinöversättning, samt omformar den kvalitetsnivå som ska målinriktas. Särskilt, om översättningar måste passa en viss layout, bör kvaliteten inte bara mätas i termer av lämplighet och flytighet, utan också längd. Exempelvis är översättning av dokumentfiler, undertexter och skript för dubbning, där utmatningslängden helst bör ligga så nära inmatningstextens längd som möjligt. Denna pa-per tar upp för första gången, så vitt vi vet, problemet med att kontrollera utmatningslängden i NMT. Vi undersöker två metoder för att förskjuta utgångslängden med en transformatorarkitektur: i) konditionera utgången till en given målkälllängdsklass och ii) berika transformatorns positionsinbäddning med längdinformation. Våra experiment visar att båda metoderna kan få nätverket att generera kortare översättningar, samt förvärva tolkningsbara språkkunskaper.', 'ta': 'புதிய இயந்திரத்தின் மொழிபெயர்ப்பால் முன்னேற்றப்பட்ட முன்னேற்றம் (NMT) இயந்திரத்தின் மொழிபெயர்ப்புப் புலங்களை விரைவாக விரிவா @ info @ info: whatsthis இந்த பாபா- per முதல் முகவரிகள், எங்கள் அறிவு சிறந்தது, NMT வெளியீட்டு நீளத்தை கட்டுப்படுத்தும் பிரச்சனை. We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information.  எங்கள் பரிசோதனைகள் இரண்டு முறைகளும் சிறிய மொழிபெயர்ப்புகளை உருவாக்க முடியும் என்பதையும் காண்பிக்கிறது, மற்றும் இடைமுறையா', 'ur': 'نیورل ماشین ترجمہ (NMT) کے ذریعے پہنچائے ہوئے اخیر پیشرفت مطابق ماشین ترجمہ کے فائلڈ کو تیز طور پر پھیلا رہے ہیں، اور مقرر کرنے کے لئے کیفیت سطح کو دوبارہ ترجمہ کرتا ہے. مخصوصاً اگر تعبیر کے لئے کچھ مقرر طریقے کے مطابق مطابق ہونا چاہیے، کیفیت صرف برابری اور طبیعت کے مطابق اندازہ نہ ہونا چاہیے، بلکہ طول بھی ہونا چاہیے۔ مثال کیسٹ ڈوبنگ کے لئے ڈاکومٹ فائل، subtitles اور اسکریٹ کا ترجمہ ہے، جہاں آئٹ لامٹ بہت نزدیک ہونا چاہیے وارد متن کی لامٹ کے لئے. پہلی بار، ہمارے علم کے سب سے بہترین جاننے کے لئے یہ پے-پے-پے آدرس، NMT میں نتیجہ لمبی کنٹرول کے مشکل ہے. ہم نے دوسری طریقوں کی تحقیق کرتی ہیں کہ ایک تغییر پھیلانے والے معماری کے ساتھ اپوٹ پیٹ کی لامٹی کی تغییر کریں: i) اپوٹ پیٹ کو ایک مقررہ target-source لامٹ-ریس کلاس کے ساتھ کنڈیسی کریں اور ii) تغییر پھیلانے ہمارے آزمائش دکھاتے ہیں کہ دونوں طریقے نیٹ ورک کو چھوٹی ترجمہ پیدا کرنے کے لئے اضافہ کر سکتے ہیں، اور ان میں سے متوجہ ہونے کے قابل زبان شناسی کائنات حاصل کرسکتے ہیں۔', 'mt': 'L-avvanzi reċenti introdotti mit-traduzzjoni tal-magni newrali (NMT) qed jespandu malajr l-oqsma tal-applikazzjoni tat-traduzzjoni tal-magni, kif ukoll qed ifasslu mill-ġdid il-livell ta’ kwalità li għandu jkun immirat. In particular, if translations have to fit some given layout, quality should not only be measured in terms of adequacy and fluency, but also length.  Każijiet eżemplari huma t-traduzzjoni ta’ fajls tad-dokumenti, subtitli, u skripti għad-dubbjar, fejn it-tul tal-ħruġ idealment għandu jkun kemm jista’ jkun qrib it-tul tat-test tal-input. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT.  We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information.  L-esperimenti tagħna juru li ż-żewġ metodi jistgħu jinduċu n-netwerk biex jiġġenera traduzzjonijiet iqsar, kif ukoll jikseb ħiliet lingwistiċi interpretabbli.', 'uz': "Name @ info: whatsthis @ info: whatsthis Bu dada birinchi marta manzillar, bizning eng yaxshi aniqligimizga, NMT natijasini boshqarish muammolari. @ info Bizning tajribalarimizni ko'rsatadi, ikkita usul tarjima tarjima yaratish uchun tarjima qilishi mumkin, va o'z tarjima tarjimalarning tarjima qilishi va o'z tarjima xizmatlarini o'rganish mumkin.", 'vi': 'Những tiến bộ gần đây được tiến hành bởi dịch chuyển máy thần kinh (NMB) đang nhanh chóng mở rộng các lĩnh vực ứng dụng của dịch vụ máy, cũng như thay đổi mức chất lượng được nhắm tới. Đặc biệt, nếu dịch phải phù hợp với một số sơ đồ đã đưa ra, chất lượng không chỉ phải được đo bằng mức độ phù hợp và khéo léo, mà còn bằng chiều dài. Ví dụ như phiên dịch của tập tin tài liệu, phụ đề, và tập lệnh để đánh dấu, nơi độ dài xuất nên ở càng gần chiều dài càng tốt. Đây là địa chỉ pa-per lần đầu tiên, theo như chúng ta biết, vấn đề về việc kiểm soát chiều dài xuất trong NMB. Chúng tôi đi ều tra hai phương pháp làm phai chiều dài xuất bằng một kiến trúc máy biến thế: i) điều chỉnh kết xuất thành một lớp tỷ lệ độ dài nguồn đích xác định, và II) làm bổ sung thêm cấu trúc vị bộ chuyển hóa với thông tin dài. Những thí nghiệm của chúng tôi cho thấy cả hai phương pháp có thể thúc đẩy mạng lưới tạo ra một bản dịch ngắn hơn, cũng như kiếm được kĩ năng ngôn ngữ.', 'bg': 'Последните постижения, въведени от невронния машинен превод (НМТ), бързо разширяват приложните области на машинния превод, както и променят нивото на качество, което трябва да бъде насочено. По-специално, ако преводите трябва да отговарят на дадено оформление, качеството следва да се измерва не само по отношение на адекватността и плавността, но и по отношение на дължината. Примерни случаи са преводът на документни файлове, субтитри и скриптове за дублиране, където дължината на изхода в идеалния случай трябва да бъде възможно най-близка до дължината на входния текст. Доколкото знаем, този папер за първи път разглежда проблема с контрола на дължината на изхода в NMT. Проучваме два метода за наклоняване на дължината на изхода с архитектура на трансформатора: i) кондициониране на изхода до определен клас дължина-източник и ii) обогатяване на позиционното вграждане на трансформатора с информация за дължината. Нашите експерименти показват, че и двата метода могат да накарат мрежата да генерира по-кратки преводи, както и да придобие интерпретирани езикови умения.', 'nl': 'De recente vooruitgang die wordt geïntroduceerd door neural machine translation (NMT) breidt de toepassingsgebieden van machinevertaling snel uit en verandert het te bereiken kwaliteitsniveau. Met name als vertalingen in een bepaalde lay-out moeten passen, moet de kwaliteit niet alleen worden gemeten in termen van adequaatheid en vloeiendheid, maar ook in termen van lengte. Voorbeelden hiervan zijn de vertaling van documentbestanden, ondertitels en scripts voor nasynchronisatie, waarbij de uitvoerlengte idealiter zo dicht mogelijk bij de lengte van de invoertekst moet liggen. Deze pa-per behandelt voor het eerst, naar ons beste weten, het probleem van het regelen van de outputlengte in NMT. We onderzoeken twee methoden om de uitgangslengte te biasen met een transformatorarchitectuur: i) conditioneren van de output naar een bepaalde doel-bron lengte-ratio klasse en ii) verrijken van de positionele inbedding van de transformator met lengterinformatie. Onze experimenten tonen aan dat beide methodes het netwerk ertoe kunnen aanzetten kortere vertalingen te genereren, evenals het verwerven van waardevolle taalvaardigheden.', 'hr': 'Nedavni napredak uvedeni neuralnim prevodom strojeva (NMT) brzo se proširi polja prijave za prevod strojeva, kao i ponovno preobraćaju razinu kvalitete koji će se ciljati. Posebno, ako prevodi moraju odgovarati određenom rasporedu, kvalitet se ne samo treba mjeriti u smislu adekvatnosti i tekućine, nego i dužine. Primjer slučajeva su prevod dokumentskih datoteka, podnaslova i skripta za dubljenje, gdje dužina izlaza treba idealno biti najbliža dužini ulaznog teksta. Ovaj tata po prvi put, na najbolje znanje, problem kontrole dužine izlaza u NMT-u. Istražujemo dvije metode za pristrašuvanje dužine izlaza s strukturom transformatora: i) uvođenje izlaza u određenu klasu dužine odnosa ciljeva izvora i ii) bogatstvo transformatorskog pozicionalnog ugrađenja s dužinskim informacijama. Naši eksperimenti pokazuju da obje metode mogu izazvati mrežu da proizvede kraće prevode, kao i dobiti interpretabilne jezičke vještine.', 'da': 'De seneste fremskridt, der er indført med neural maskinoversættelse (NMT), udvider hurtigt anvendelsesområderne for maskinoversættelse, samt omformer det kvalitetsniveau, der skal målrettes. Især hvis oversættelser skal passe til et bestemt layout, bør kvaliteten ikke kun måles med hensyn til tilstrækkelighed og flydenhed, men også med hensyn til længde. Eksempelvis er oversættelse af dokumentfiler, undertekster og scripts til dubbing, hvor output længden ideelt set bør være så tæt som muligt på længden af input tekst. Denne pa-per adresserer for første gang, så vidt vi ved, problemet med styring af udgangslængden i NMT. Vi undersøger to metoder til at skærpe udgangslængden med en transformerarkitektur: i) konditionering af udgangen til en given målkilde længdeforholdsklasse og ii) berigelse af transformatorpositionsindlejringen med længdeinformation. Vores eksperimenter viser, at begge metoder kan få netværket til at generere kortere oversættelser, samt erhverve fortolkningsdygtige sproglige færdigheder.', 'de': 'Die jüngsten Fortschritte der neuronalen maschinellen Übersetzung (NMT) erweitern die Anwendungsbereiche der maschinellen Übersetzung rasant und gestalten das angestrebte Qualitätsniveau neu. Insbesondere wenn Übersetzungen in ein bestimmtes Layout passen müssen, sollte die Qualität nicht nur in Bezug auf Angemessenheit und Fließfähigkeit, sondern auch in Bezug auf die Länge gemessen werden. Beispielhafte Beispiele sind die Übersetzung von Dokumentdateien, Untertiteln und Skripten für die Synchronisation, bei denen die Ausgabelänge idealerweise möglichst nah an der Länge des eingegebenen Textes liegen sollte. Diese Pa-per adressiert erstmals nach bestem Wissen das Problem der Steuerung der Ausgangslänge in NMT. Wir untersuchen zwei Methoden zur Voreinstellung der Ausgangslänge mit einer Transformatorarchitektur: i) Konditionierung des Ausgangs auf eine vorgegebene Ziel-Quelle-Längenverhältnisklasse und ii) Anreicherung der Transformatorposition mit Längeninformation. Unsere Experimente zeigen, dass beide Methoden das Netzwerk dazu bringen können, kürzere Übersetzungen zu generieren und sich wertvolle sprachliche Fähigkeiten anzueignen.', 'id': 'The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted.  Terutama, jika terjemahan harus cocok dengan beberapa layout yang diberikan, kualitas tidak hanya harus diukur dalam terma keperluan dan keterlaluan, tetapi juga panjang. Kasus contoh adalah terjemahan berkas dokumen, subtitle, dan skrip untuk dubbing, di mana panjang output ideal seharusnya sebagai dekat dengan panjang teks input. Ini pa-per alamat untuk pertama kalinya, untuk yang terbaik dari pengetahuan kita, masalah mengendalikan panjang output di NMT. Kami menyelidiki dua metode untuk membiasikan panjang keluaran dengan arsitektur transformer: i) mengkondisikan keluaran ke kelas jarak target-sumber dan ii) memperkaya posisi penerbangan transformer dengan informasi panjang. Eksperimen kami menunjukkan bahwa kedua metode dapat mendorong jaringan untuk menghasilkan terjemahan yang lebih pendek, serta memperoleh keterampilan bahasa yang dapat diterima.', 'ko': '신경기계번역(neural machine translation, NMT)의 최신 진전은 기계번역의 응용 분야를 신속하게 확장하고 목표의 품질 수준을 재구성했다.특히 번역이 특정한 구조에 부합해야 한다면 품질은 충분성과 유창성뿐만 아니라 길이도 따져야 한다.전형적인 예는 문서 파일, 자막 번역과 더빙에 사용되는 스크립트인데 그 중에서 출력 길이는 입력 텍스트의 길이에 최대한 가깝다.이 기사는 NMT에서 출력 길이를 제어하는 문제를 처음으로 해결한 것으로 알려졌다.우리는 변압기 구조를 사용하여 출력 길이를 편치하는 두 가지 방법을 연구했다. i) 출력을 주어진 목표원 길이비 유형으로 조절하고 ii) 사용 길이 정보가 풍부한 변압기 위치에 삽입하는 것이다.우리의 실험에 의하면 이 두 가지 방법은 모두 네트워크에서 비교적 짧은 번역을 유도하고 번역 가능한 언어 기능을 얻을 수 있다.', 'fa': 'پیشرفتهای اخیر که توسط ترجمه ماشین عصبی (NMT) معرفی شده\u200cاند، به سرعت زمینه\u200cهای کاربرد ترجمه ماشین را گسترش می\u200cدهند، و سطح کیفیت را برای هدف بازسازی می\u200cکنند. در خصوص، اگر ترجمه\u200cها مجبور به برخی از طرح\u200cهای داده\u200cشده\u200cاند، کیفیت نباید تنها به اندازه\u200cی مناسب و آلودگی اندازه\u200cگیری شود، بلکه طولانی هم باشد. پرونده\u200cهای مثال ترجمه پرونده\u200cهای سند، زیر عنوان و اسکریپت\u200cها برای ترجمه کردن است، جایی که طول خروج باید به نظر خیلی نزدیک تر از طول متن وارد باشد. این آدرس پدر برای اولین بار، به بهترین دانش ما، مشکل کنترل طول نتیجه در NMT است. ما دو روش تحقیق می\u200cکنیم که طول خروج را با یک معماری تغییر دهنده تحقیق می\u200cکنیم: i) در حالی که خروج را به یک کلاس طولانی نسبت به منبع هدف داده می\u200cشود و ii) در حالی که محل تغییر دهنده را با اطلاعات طولانی ثروت می\u200cکند. آزمایشات ما نشان می دهند که هر دو روش می تواند شبکه را به تولید ترجمه کوتاه\u200cتر و همچنین توانایی زبان\u200cشناسی که قابل تحریک می\u200cکنند، به تولید کند.', 'sw': 'Maendeleo ya hivi karibuni yaliyoanzishwa na tafsiri ya mashine ya neura (NMT) yanaongezea maeneo ya utafsiri wa mashine kwa haraka, pamoja na kuboresha kiwango cha kiwango kinacholengwa. Kwa hakika, kama tafsiri inapaswa kufananishwa na baadhi ya vifaa vinavyopewa, ubora haupaswi kupunguzwa tu kwa kiasi cha usahihi na ufanisi, bali pia lengo. Matukio ya mfano ni tafsiri ya faili za nyaraka, vichwa vya habari, na manuscripta kwa ajili ya kutengeneza nyaraka, ambapo ongezeko la matokeo ya uzito linapaswa kuwa karibu kadri inavyowezekana kufika kiwango cha duru ya maandishi ya input. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT.  Tunatachunguza mbinu mbili za upendeleo wa kiwango cha matokeo kwa ujenzi wa mabadiliko: i) kuhamasisha matokeo yake kwa darasa la kiwango cha urefu wa kiwango kinachopewa lengo na (ii) kutajirisha mabadiliko yenye nafasi kwa taarifa ndefu. Majaribio yetu yanaonyesha kuwa mbinu zote zinaweza kutengeneza mtandao wa kutengeneza tafsiri fupi, pamoja na kupata ujuzi wa lugha tofauti.', 'af': "Die onlangse avansies wat deur neurale masjien vertaling (NMT) ingestel word, word vinnig die aansoek velde van masjien vertaling uitbrei, en ook die kwaliteit vlak wat doel moet word herstel. Spesifieke, as vertalings sommige gegewe uitleg moet pas, moet kwaliteit nie slegs gemeet word nie in terms van adekuasie en fluiditeit, maar ook lengte. Voorskou gevalle is die vertaling van dokumentlêers, subtitles en skripte vir dubbeling, waar die uitvoer lengte ideeel so naby as moontlik wees na die lengte van die invoer teks. Hierdie pa-per adresse vir die eerste keer, tot die beste van ons kennis, die probleem van die uitvoer lengte in NMT beheer. Ons ondersoek twee metodes vir biasing van die uitvoer lengte met 'n transformeerder arkitektuur: i) voorwaarding van die uitvoer na' n gegewe doel- bron lengte- verhouding klas en ii) verrichting van die transformeerder posisieal inbêring met lengte informasie. Ons eksperimente vertoon dat beide metodes die netwerk kan induseer om korter vertalings te genereer, en ook interpretabile lingwisiese kunstenaars te kry.", 'sq': 'The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted.  Veçanërisht, në qoftë se përkthimet duhet të përshtaten në disa layout të dhëna, cilësia nuk duhet të matet vetëm në terma të përshtatshmërisë dhe fluencës, por gjithashtu gjatësisë. Shembulli i rasteve janë përkthimi i dosjeve të dokumenteve, nëntitujve dhe skripteve për dublim, ku gjatësia e daljes idealisht duhet të jetë sa më afër gjatësisë së tekstit të hyrjes. Ky pa-per adreson për herë të parë, për më të mirën e njohurive tona, problemi i kontrollit të gjatësisë së daljes në NMT. Ne hetojmë dy metoda për përkrahjen e gjatësisë së daljes me një arkitekturë transformuesi: i) kushtëzimin e daljes në një klasë të caktuar të gjatësisë së burimit dhe ii) pasurimin e përfshirjes pozitive të transformuesit me informacion të gjatësisë. Eksperimentet tona tregojnë se të dy metodat mund të induktojnë rrjetin për të gjeneruar përkthime më të shkurtra si dhe për të fituar aftësi gjuhësore të ndërpretshme.', 'am': 'በናቡር መሣሪያው ትርጉም (NMT) የተገኘው የአሁኑን ደረጃዎች የሜክስሎችን ትርጉም መሻሻዎችን በቶሎ ያሰፋሉ፡፡ በተለይም፣ ትርጉም በተሰጠው መግለጫ ማሰናከል ያስፈልጋል ቢኖር ጥሩ በሙሉ እና በጥጋት ብቻ አይደለም ነገር ግን ርዝመት ነው፡፡ ለሚምሳሌ ጉዳዮች የሰነድ ፋይሎች፥ አዲስ አናቶች እና ጽሑፎች ማተርጓሜ ነው፤ የውጤት ርዝመት ወደሚቻለው የጥቅምት ጽሑፍ ርዝመት በጣም ቅርብ ነው። ይህች አባ-per ለመጀመሪያ ጊዜ፣ እውቀታችንን ለመሻለል፣ የውጤቱን ርዝመት በNMT መቆጣጠር ጉዳይ ነው፡፡ የውጤቱን ርዝመት በተለወጠው የመሠረተ አካውንት ለመቀላቀል ሁለት ሥርዓቶችን እናመርምራለን:: i) የውጤቱን ክፍል ወደ ተሰጠው የክፍል ቁመት-ቁመት ክፍል እና (ii) በመለወጥ ስፍራውን በረጅም መረጃዎች በመጠቀም እናደርጋለን፡፡ ፈተናዎቻችን ሁለቱ ሥርዓቶች አነስተኛ ትርጓሜዎችን ለመፍጠር እና የቋንቋ ቋንቋዎችን ማግኘት እንዲችሉ ያሳየቃሉ፡፡', 'tr': 'NMT tarapyndan öňki gelişmeler (neural machine terjime) tarapyndan tanyşdyrylýan öňki gelişmeler maşynyň terjime alanynyň uygulamasynyň sahypalaryny çalt döwürýär, we maksadyň üstesini täzeden çykarýarlar. Aýratyn, eger terjimeler käbir berilen tizillere gollanmaly bolsa, kwalitet diňe ýeterlik we terjime etmeli däl, ýöne uzlukda ölçülmeli. Misal ýagdaýlar, sözbaşmak üçin sened faýllaryň, altsözlerniň we skriptleriniň terjimesi dir. Çikgi durmuşy giriş metiniň uzunluğuna elimizde ýakyn bolmaly. Her biri ilk defa bu adrese, bilgimizin en iyi şekilde, NMT çizgi uzunluğunu kontrol etmek sorunu. Çikgi uzmanyny bir arhitektura bilen biaslaşdyrmak üçin iki yöntemi inceleýäris: i) çizgisini berilen hedef-çeşme uzalyk baglanyşy klasine baglanýar we ii) transformer pozisiýaly baglanyşy baglanýar. Deneylerimiz hem de bu şekilde ağ kısa tercihleri oluşturmak için, hem de öğrenebilen dil yeteneklerini elde edebileceğini gösteriyor.', 'az': 'NMT t…ôrzind…ôn t…ôŇükil edil…ôn yeni t…ôdbirl…ôr maŇüńĪn √ßevirilm…ôsi il…ô t…ôŇükil edil…ôn proqramlar maŇüńĪn √ßevirilm…ôsi sah…ôl…ôrini v…ô m…ôqs…ôdil…ô t…ôŇükil edil…ôc…ôk kaliteli seviyy…ôtini yenid…ôn t…ôŇükil edirl…ôr. √Ėzellikle, …ôg…ôr t…ôrziml…ôr b…ôzi t…ôrziml…ôr…ô uymaq lazńĪmsa, keyfiyy…ôt yalnńĪz t…ôrzimliyi v…ô t…ôrzimliyi il…ô √∂l√ß√ľlm…ôsi lazńĪmdńĪr, ancaq uzunluńüu il…ô √∂l√ß√ľlm…ôsi lazńĪmdńĪr. M…ôs…ôl…ôn m…ôs…ôl…ôl…ôr d√∂k√ľm fayllarńĪnńĪn, altyazńĪlarńĪnńĪn v…ô √ß…ôkiŇüm…ô skriptl…ôrinin √ßevirildiyi m…ôs…ôl…ôl…ôrin uzunluńüuna q…ôd…ôr yaxńĪn olmasńĪ lazńĪmdńĪr. Bu, ilk d…ôf…ô, elmimizin …ôn yaxŇüńĪsńĪna g√∂r…ô, NMT √ßńĪxńĪŇü uzunluńüunu kontrol etm…ôk problemi. Biz √ßńĪxńĪŇü uzunluńüunu bir transformer arhitekt√ľs√ľ il…ô t…ôŇükil etm…ôk √ľ√ß√ľn iki metodlarńĪ araŇüdńĪrńĪrńĪq: i) √ßńĪxńĪŇüńĪ m√ľ…ôyy…ôn edilmiŇü m…ôqs…ôd-m…ônb…ô uzunluńüu-t…ôŇükil sńĪnńĪfńĪna t…ôŇükil edir v…ô ii) uzaq m…ôlumatńĪ il…ô transformer pozisyonu geniŇül…ôndirir. Bizim t…ôcr√ľb…ôl…ôrimiz h…ôr iki metod Ňü…ôb…ôk…ô daha qńĪsa terc√ľm…ôl…ôri yaratmaq √ľ√ß√ľn, h…ôm√ßinin interpretabilir dil yeteneklikl…ôrini almaq √ľ√ß√ľn t…ôŇükil ed…ô bil…ôr.', 'hy': 'Նյարդային մեքենայի թարգմանման (NMT) միջոցով ներդրված վերջին զարգացումները արագ ընդլայնում են մեքենայի թարգմանման ծրագրերի ոլորտները, ինչպես նաև վերաձևավորում նպատակային որակի մակարդակը: Հատկապես, եթե թարգմանությունները պետք է համապատասխանեն որոշ տեսակի դիրքերին, որակը պետք է չափվի ոչ միայն համապատասխանատվության և հեղության, այլ նաև երկարության առումով: Օրինակ օրինակներ են փաստաթղթի ֆայլերի, ենթագծերի և գրաֆիկների թարգմանությունը, որտեղ արտադրության երկարությունը իդեալական կերպ պետք է լինի որքան հնարավոր մոտ ներդրված տեքստի երկարությանը: Առաջին անգամ այս հայ-յուրաքանչյուր հասցեը, ըստ մեր լավագույն գիտելիքների, NMT-ի արտադրման երկարության վերահսկման խնդիրը: Մենք ուսումնասիրում ենք երկու մեթոդ, որոնք օգտագործում են վերափոխողի ճարտարապետության միջոցով վերափոխվող արտադրողի երկարության կողմնականությունը: i) վերափոխվող արտադրողի հատկությունը հատուկ նպատակի-աղբյուրի երկարության հարաբերության դասին վերափոխելու համար, և Մեր փորձարկումները ցույց են տալիս, որ երկու մեթոդները կարող են առաջացնել ցանցը ավելի կարճ թարգմանություններ ստեղծելու համար, ինչպես նաև լեզվաբանական հմտություններ ստանալու համար:', 'bn': 'The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted.  বিশেষ করে, যদি অনুবাদের কিছু নির্দিষ্ট বিন্যাসের সাথে যোগাযোগ করতে হবে, তাহলে মানের মান শুধুমাত্র যথাযথ এবং ফ্লাইসিস্ @ info প্রথমবারের জন্য বাপ-পারের ঠিকানা, আমাদের জ্ঞানের সর্বোচ্চ পর্যন্ত, এনএমটির আউটপুট দীর্ঘ নিয়ন্ত্রণের সমস্যা। আমরা আউটপুটের দীর্ঘদীর্ঘদিন পরিবর্তনের কাঠামো দিয়ে দুটি পদ্ধতি তদন্ত করি: আই) একটি টার্গেন্স-উৎসের দীর্ঘ দীর্ঘ শ্রেণীর ক্লাসে আউটপুটের ফলাফলের ব আমাদের পরীক্ষাগুলো দেখাচ্ছে যে দুই পদ্ধতি সংক্ষিপ্ত অনুবাদ তৈরি করতে পারে এবং তার মধ্যে ভাষাভাষার দক্ষতা পেতে পারে।', 'bs': 'Nedavni napredak uvedeni neuralnim prevodom mašina (NMT) brzo se proširi polja prijave mašinskog prevoda, kao i ponovno preobraćaju nivo kvalitete kojim se treba ciljati. Posebno, ako prevodi moraju odgovarati određenom rasporedu, kvalitet bi trebala biti mjerena ne samo u smislu adekvatnosti i tekućine, već i dužine. Primjer slučajeva su prevod dokumentskih datoteka, subtitle i skripta za dubljenje, gdje dužina izlaza treba idealno biti najbliža dužini ulaznog teksta. Ovaj tata po prvi put, na najbolje od našeg znanja, problem kontrole dužine izlaza u NMT-u. Istražujemo dvije metode za predrasude dužine izlaska sa transformatorskom arhitekturom: i) uvođenje izlaska u određenu klasu dužine odnosa sa ciljevim izvorima i ii) bogatstvo transformatorskog pozicionalnog ugrađenja dužinom informacijom. Naši eksperimenti pokazuju da obje metode mogu inducirati mrežu da proizvede kraće prevode, kao i da dobije interpretabilne jezičke vještine.', 'ca': "The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted.  En particular, si les traduccions han de ajustar a alguna disposició dada, la qualitat no només hauria de mesurar en termes d'adequació i fluïtat, sinó també en termes de longitud. Casos exemplaris són la traducció dels arxius de documentos, subtítulos i scripts de dubtació, on idealment la llargància de la sortida hauria d'estar tan proper com possible a la llargància del text d'entrada. Aquesta pa-per adreça per primera vegada, pel millor que sabem, el problema de controlar la llargada de la producció en NMT. Investiguem dos mètodes per orientar la longitud de la sortida amb una arquitectura de transformador: i) condicionar la sortida a una determinada classe de relació de longitud entre la font d'objectiu i ii) enriqueixer l'incorporació positional del transformador amb informació de longitud. Els nostres experiments demostren que ambdós mètodes poden inducir la xarxa a generar traduccions més curtes, i adquirir habilitats lingüístices interpretables.", 'cs': 'Nedávné pokroky představené neuronovým strojovým překladem (NMT) rychle rozšiřují oblasti aplikací strojového překladu a přetvářejí úroveň kvality, kterou má být cílená. Zejména pokud musí překlady odpovídat danému uspořádání, kvalita by měla být měřena nejen z hlediska přiměřenosti a plynulosti, ale také z hlediska délky. Příkladem je překlad souborů dokumentů, titulků a skriptů pro dabing, kde by délka výstupu měla být ideálně co nejblíže délce vstupního textu. Tento pa-per poprvé řeší, podle našich nejlepších znalostí, problém řízení délky výstupu v NMT. Zkoumáme dvě metody předběhu délky výstupu s architekturou transformátoru: i) kondicizaci výstupu na danou třídu poměru délky cílového zdroje a ii) obohacení polohového vložení transformátoru o informace o délku. Naše experimenty ukazují, že obě metody mohou přimět síť k generování kratších překladů a získání zajímavých jazykových dovedností.', 'et': 'Neuraalse masintõlke (NMT) hiljutised edusammud laiendavad kiiresti masintõlke rakendusvaldkondi ning muudavad sihitud kvaliteeditaset. Eelkõige, kui tõlked peavad sobima mõnele konkreetsele kujundusele, tuleks kvaliteeti mõõta mitte ainult piisava ja sujuva, vaid ka pikkuse poolest. Näiteks on dokumendifailide, subtiitrite ja dubleerimise skriptide tõlkimine, kus väljundi pikkus peaks ideaalselt olema sisestatud teksti pikkusele võimalikult lähedane. See pa-per käsitleb esimest korda, meie parimate teadmiste kohaselt, probleemi väljundpikkuse kontrollimisel NMT. Uurime kahte meetodit väljundpikkuse kallutamiseks trafo arhitektuuriga: i) väljundi konditsioneerimine konkreetse sihtallika pikkuse suhte klassi ja ii) trafo positsiooni rikastamine pikkusteabega. Meie eksperimendid näitavad, et mõlemad meetodid võivad innustada võrgustikku looma lühemaid tõlkeid ja omandama arusaadavaid keeleoskusi.', 'fi': 'Neurokonekäännöksen (NMT) viimeaikaiset edistysaskeleet laajentavat nopeasti konekäännöksen sovellusalueita sekä muokkaavat tavoiteltavaa laatutasoa. Erityisesti jos käännösten on sovittava tiettyyn ulkoasuun, laatua ei pitäisi mitata ainoastaan riittävyyden ja sujuvuuden vaan myös pituuden perusteella. Esimerkkitapauksia ovat dokumenttitiedostojen, tekstitysten ja dubbausta varten tarkoitettujen skriptien kääntäminen, jossa lähtöpituuden tulisi ihanteellisesti olla mahdollisimman lähellä syötetyn tekstin pituutta. Tämä pa-per käsittelee ensimmäistä kertaa parhaan tietomme mukaan NMT:n ulostulopituuden säätelyongelmaa. Tutkimme kahta menetelmää lähtöpituuden vinoutumiseen muuntajan arkkitehtuurilla: i) tuotoksen ehdollistaminen tiettyyn kohdelähteen pituussuhteen luokkaan ja ii) muuntajan sijainnin rikastaminen pituustiedolla. Kokeet osoittavat, että molemmat menetelmät voivat saada verkoston tuottamaan lyhyempiä käännöksiä sekä hankkimaan ymmärrettäviä kielitaitoja.', 'jv': 'Progress special Subtitles Pilihan pangan-pangan iki banget nang sampek, sak luwih apik dhéwé, njuk kesempatan kanggo nguasai mbuluk sing ditambah NMT. string" in "context_BAR_stringLink Awak dhéwé éntuk perbudhakan langkung sampeyan wis nguasai netulé nggawe tarjamahan lunak, lan ijol-ijolan cara-ijolan ingkang sampeyan.', 'sk': 'Nedavni napredek, ki ga uvaja nevronski strojni prevod (NMT), hitro širi področja uporabe strojnega prevajanja in preoblikuje raven kakovosti, ki jo je treba usmeriti. Zlasti, če morajo prevodi ustrezati določeni postavitvi, je treba kakovost meriti ne le z vidika ustreznosti in tekočosti, temveč tudi z vidika dolžine. Primeri primerov so prevod dokumentnih datotek, podnapisov in skriptov za dubljanje, kjer mora biti izhodna dolžina idealno čim bližja dolžini vhodnega besedila. Ta pa-per prvič, po našem najboljšem znanju, obravnava problem nadzora izhodne dolžine v NMT. Raziskovali smo dve metodi za pristranskost izhodne dolžine s transformatorsko arhitekturo: i) kondicioniranje izhodne dolžine na določen razred ciljnega vira in ii) obogatitev položajnega vgradnje transformatorja z informacijami o dolžini. Naši poskusi kažejo, da lahko obe metodi spodbudita mrežo k ustvarjanju krajših prevodov in pridobivanju razumljivih jezikovnih veščin.', 'ha': "@ info: whatsthis Kuma da ƙayyadadde, idan fassarar za'a fito da wani abu na tsari, to, ba a ƙayyade nau'in da aka ƙayyade kima da gwargwadon, kuma amma tsawo. @ info: whatsthis Wannan babu-per na shiryu zuwa mafi kyaun ilmi na farkon, matsalar masu controller durowa na fitarwa cikin NMT. Tuna jãyayya hanyoyin biyu na fitarwa da wata matsayin transformer: i) yana daidaita matsayin ayuka zuwa danna-rasmi-rassi da aka ƙayyade goan kuma (ii) yana rikitar da juyin shishi da ke cikin shirin ayuka da information tsawo. Kayan jarrabõnmu sun nũna cewa, hanyoyinMu biyu za'a iya iya ƙara zuwa shirin tarayya don su iya ƙiƙiro fassarori masu ƙaranci, da kuma a sami masu sami taƙaita masu fassarar cikin lugha da masu fassara.", 'he': 'ההתקדמות האחרונות שהופעו על ידי התרגום של מכונות עצביות (NMT) מרחיבות במהירות את שדות היישומים של התרגום של מכונות, כמו גם שינוי רמת איכות המטרה. במיוחד, אם התרגשות צריכות להתאים לתוכנית מסוימת, האיכות לא רק צריכה למדוד במונחים של מתאימות ונוזלות, אלא גם אורך. מקרים דוגמאים הם התרגום של קובצי מסמכים, תותווים, ותסריטים לשקול, שם אורך ההוצאה באופן אידיאלי צריך להיות קרוב ככל האפשר לאורך הטקסט ההוצאה. הפעם הראשונה, לפי הידע הטוב ביותר שלנו, הבעיה של לשלוט באורך ההוצאה ב-NMT. We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information.  הניסויים שלנו מראים ששתי השיטות יכולות לגרום לרשת לייצר תרגומות קצרות יותר, כמו גם להשיג כישורים שפתיים מתייחסים.', 'bo': 'The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted. དམིགས་བསལ་ན། གལ་སྲིད་ཀྱི་ཚིག Exemplary cases are the translation of document files, subtitles, and scripts for dubbing, where the output length should ideally be as close as possible to the length of the input text. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT. We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information. ང་ཚོའི་བརྟག་ཞིབ་ཕྱོགས་གཉིས་ཀྱིས་དྲ་རྒྱའི་ནང་དུ་ཆུང་ཉུང་བ་ཞིག་ཡོད་པ་དང་། སྐད་རིགས་སྔར་འཕགས་པའི་སྐད་རིགས་ལ་ཆ'}
