{'en': 'Improving Counterfactual Generation for Fair Hate Speech Detection', 'ar': 'تحسين الجيل المضاد للكشف العادل عن خطاب الكراهية', 'pt': 'Melhorando a geração contrafactual para detecção de discurso de ódio justo', 'fr': 'Améliorer la génération de documents contrefactuels pour la détection équitable des discours haineux', 'es': 'Mejorar la generación contrafáctica para la detección justa del discurso de odio', 'ja': '公正なヘイトスピーチ検出のための反事実的生成の改善', 'zh': '改进平仇言检测反事', 'ru': 'Улучшение контрафактной генерации для обнаружения речи на почве ненависти', 'hi': 'उचित हेट स्पीच डिटेक्शन के लिए काउंटरफैक्टिव जनरेशन में सुधार', 'ga': 'Giniúint Fhrithfhíorasach a Fheabhsú le hAghaidh Brath Urlabhra Is fuath liom', 'el': 'Βελτίωση της γενιάς πλαστών για την ανίχνευση δίκαιης ομιλίας μίσους', 'ka': 'მარტივი სამყარო სიტყვებისთვის შესაძლებელება', 'hu': 'A hamisítvány generálásának javítása a tisztességes gyűlölet beszédfelismeréséhez', 'it': 'Migliorare la generazione di contraffazioni per la rilevazione del discorso di odio equo', 'lt': 'Gerinti klastojimo gamybą sąžiningos neapykantos kalbos nustatymui', 'kk': 'Жарамсыз тілі анықтау үшін қарсы жасау', 'mk': 'Подобрување на лажната генерација за детекција на говорот на фер омраза', 'ms': 'Menembangkan Jenerasi palsu untuk Pengesanan Ucapan Kebencian Fair', 'ml': 'വെറുപ്പുള്ള വാക്കുകള്\u200d കണ്ടുപിടിക്കുന്നതിനുള്ള Counterfactual Generation for Fair Hate Speech Detection', 'mn': 'Дуураг үзэн ядуурлын яриаг олох үеийн эсрэг жинхэнэ төлөө сайжруулах', 'mt': 'Titjib fil-Ġenerazzjoni Falsifikata għall-Iżvelar ta’ Diskors Ġust ta’ Mibegħda', 'pl': 'Poprawa generacji fałszywych rzeczy dla sprawiedliwego wykrywania mowy nienawiści', 'ro': 'Îmbunătățirea generației contrafăcute pentru detectarea corectă a discursului de ură', 'no': 'Forbetra kontorefaktiske generering for feil hatt- tale', 'sr': 'Poboljšanje generacije protivnika za otkrivanje prave reči mržnje', 'si': 'සාධාරණ විරෝධ කතාව හොයාගන්න සඳහා විරෝධ විශ්වාස කරනවා', 'so': 'Horumarinta Generation of Counterfactual generation for Fair Hate Speech', 'sv': 'Förbättring av förfalskning för detektering av rättvist hattal', 'ta': 'சரியான வெறுப்பு பேச்சு கண்டுபிடிப்பதற்கான எண்ணிக்கை உருவாக்கத்தை மேம்படுத்துகிறது', 'ur': 'سیدھی عداوت کی بات شناسایی کے لئے کنٹر فارغ نسل بہترین کر رہا ہے', 'uz': 'factual generation for Fair Hat Speech Detection', 'vi': 'Tăng cường trường hợp ngược giá cho việc phát hiện thơ mộng', 'bg': 'Подобряване на фалшивото генериране за откриване на честна омраза', 'nl': 'Verbetering van namaakgeneratie voor eerlijke haatspraakdetectie', 'hr': 'Poboljšanje generacije protivnika za otkrivanje pravog govora mržnje', 'id': 'Menembangkan Generasi palsu untuk Deteksi Ucapan Kebencian Fair', 'de': 'Verbesserung der gefälschten Generierung für die Erkennung von Fair Hate Speech', 'fa': 'افزایش نسل\u200cهای مخالف برای شناسایی سخنرانی عداوت', 'da': 'Forbedring af generering af forfalskninger til detektering af fair had tale', 'tr': 'Hata sözleri tanamak üçin faýllary bejermek', 'af': 'Verbeter Teikerfekte Generasie vir Verkeerde Hate Spraak Opdekking', 'ko': '공평한 증오 음성 검출의 반사실 생성을 개선하다', 'sq': 'Përmirësimi i gjenerimit të rreme për zbulimin e fjalëve të urrejtjes së drejtë', 'sw': 'Kuboresha Uzalishaji wa Heshima kwa Kugundua Hotuba Sio za Kuchukia', 'hy': 'Ճշմարիտ ատելության խոսքի կեղծ ստեղծման բարելավումը', 'az': 'Düzgün nifrət sözlərini keşfetmək üçün Counterfactual Generation Improved', 'bn': 'ফ্যায়ার ঘৃণা বাক বক্তব্য সনাক্ত করার জন্য কাউন্টারফ্যাক্টেল জেনারেশন উন্নতি করা হচ্ছে', 'am': 'Improving Counterfactual Generation for Fair Hate Speech Detection', 'bs': 'Poboljšanje generacije protivnika za otkrivanje pravog govora mržnje', 'ca': 'Improving Counterfactual Generation for Fair Hate Speech Detection', 'fi': 'Parannetaan väärennettyä sukupolvea reilun vihan puheentunnistusta varten', 'cs': 'Zlepšení generace padělaných faktů pro spravedlivou detekci řeči z nenávisti', 'et': 'Võltsitud generatsiooni parandamine ausa vihkamise kõne tuvastamiseks', 'ha': 'factor for Fair Hate Spelling', 'he': 'שיפור הדורה מזויפת לגילוי נאום שונא הוגן', 'sk': 'Izboljšanje ponarejene generacije za odkrivanje poštenega sovraštva govora', 'bo': 'Fair Hate Speech Detection དོན་ལ་རྩིས་འབྲེལ་མི་དངོས་ཡོད་ཚད་ཡར་རྒྱས་འགྲོ་བ་སྐྱེལ་བཞིན་བཟོ་བཞིན།', 'jv': 'default:LTR'}
{'en': 'Bias mitigation approaches reduce models’ dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. In ', 'ar': 'تعمل مناهج تخفيف التحيز على تقليل اعتماد النماذج على السمات الحساسة للبيانات ، مثل الرموز المميزة للمجموعة الاجتماعية (SGTs) ، مما يؤدي إلى تنبؤات متساوية عبر الميزات الحساسة. ومع ذلك ، في اكتشاف الكلام الذي يحض على الكراهية ، قد تتجاهل معادلة التنبؤات النموذجية الاختلافات المهمة بين المجموعات الاجتماعية المستهدفة ، حيث يمكن أن يحتوي خطاب الكراهية على لغة نمطية خاصة بكل SGT. هنا ، لأخذ اللغة المحددة حول كل SGT في الاعتبار ، نعتمد على الإنصاف المضاد ونوازن التنبؤات بين الوقائع المضادة ، الناتجة عن تغيير SGTs. تقوم طريقتنا بتقييم التشابه في احتمالات الجملة (عبر نماذج اللغة المدربة مسبقًا) بين الوقائع المضادة ، لمعاملة SGTs على قدم المساواة فقط في السياقات القابلة للتبديل. من خلال تطبيق إقران السجل لمعادلة النتائج على المجموعة المقيدة من الوقائع المضادة لكل حالة ، نقوم بتحسين مقاييس الإنصاف مع الحفاظ على أداء النموذج في اكتشاف الكلام الذي يحض على الكراهية.', 'pt': 'As abordagens de mitigação de viés reduzem a dependência dos modelos em recursos confidenciais de dados, como tokens de grupo social (SGTs), resultando em previsões iguais entre os recursos confidenciais. Na detecção de discurso de ódio, no entanto, as previsões do modelo de equalização podem ignorar diferenças importantes entre os grupos sociais visados, pois o discurso de ódio pode conter linguagem estereotipada específica para cada SGT. Aqui, para levar em consideração a linguagem específica sobre cada SGT, contamos com a justiça contrafactual e equalizamos as previsões entre os contrafactuais, geradas pela alteração dos SGTs. Nosso método avalia a similaridade nas probabilidades de sentenças (através de modelos de linguagem pré-treinados) entre contrafactuais, para tratar SGTs igualmente apenas em contextos intercambiáveis. Ao aplicar o emparelhamento de logit para equalizar os resultados no conjunto restrito de contrafactuais para cada instância, melhoramos as métricas de imparcialidade e preservamos o desempenho do modelo na detecção de discurso de ódio.', 'es': 'Los enfoques de mitigación de sesgos reducen la dependencia de los modelos de las características sensibles de los datos, como los tokens de grupos sociales (SGT), lo que resulta en predicciones iguales en todas las funciones sensibles. Sin embargo, en la detección del discurso de odio, la igualación de las predicciones del modelo puede ignorar diferencias importantes entre los grupos sociales objetivo, ya que el discurso de odio puede contener un lenguaje estereotipado específico de cada SGT. Aquí, para tener en cuenta el lenguaje específico de cada SGT, nos basamos en la equidad contrafáctica e igualamos las predicciones entre las contrafácticas, generadas al cambiar las SGT. Nuestro método evalúa la similitud en las probabilidades de oración (a través de modelos lingüísticos previamente entrenados) entre los contrafácticos, para tratar las SGT por igual solo dentro de contextos intercambiables. Al aplicar el emparejamiento logit para igualar los resultados en el conjunto restringido de contrafácticos para cada instancia, mejoramos las métricas de equidad y preservamos el rendimiento del modelo en la detección de discursos de odio.', 'fr': "Les approches d'atténuation des biais réduisent la dépendance des modèles à l'égard des caractéristiques sensibles des données, telles que les jetons de groupe social (SGT), ce qui permet d'obtenir des prévisions égales entre les caractéristiques sensibles. Dans la détection des discours haineux, cependant, les prédictions du modèle d'égalisation peuvent ignorer les différences importantes entre les groupes sociaux ciblés, car les discours haineux peuvent contenir un langage stéréotypé propre à chaque SGT. Ici, pour prendre en compte le langage spécifique de chaque SGT, nous nous appuyons sur l'équité contrefactuelle et égalisons les prédictions entre les contrefactuelles, générées par la modification des SGT. Notre méthode évalue la similitude des probabilités de phrases (via des modèles de langage préformés) entre les contrefactuels, afin de traiter les SGT de manière égale uniquement dans des contextes interchangeables. En appliquant le couplage logit pour égaliser les résultats sur l'ensemble restreint de facteurs contrefactuels pour chaque instance, nous améliorons les mesures d'équité tout en préservant les performances du modèle en matière de détection des discours haineux.", 'ja': 'バイアス軽減アプローチは、ソーシャルグループトークン（ SGT ）などのデータの機密機能へのモデルの依存を減らし、機密機能全体で等しい予測をもたらします。しかし、ヘイトスピーチ検出では、ヘイトスピーチは各SGTに固有の定型的な言語を含む可能性があるため、均等化モデル予測はターゲット社会集団間の重要な違いを無視し得る。ここでは、各SGTに関する特定の言語を考慮に入れるために、SGTを変更することによって生成される反事実的公平性に依存し、反事実間の予測を均等化する。我々の方法は、（事前にトレーニングされた言語モデルを介して）反事実の間の文の尤度の類似性を評価し、交換可能な文脈内でのみSGTを平等に扱う。ロジットペアリングを適用して、各インスタンスの制限された反事実セットのアウトカムを均等化することで、ヘイトスピーチ検出のモデルパフォーマンスを維持しながら、公平性指標を改善します。', 'zh': '偏差缓法可减模数敏感特征(如群体令牌 (SGT))赖,以成敏感特征之占。 然仇言相检,均形可忽群体之要异,恨言可含特定每SGT之言.在此,虑每SGT之特定言,因反事公平性,更SGT于反事之间。 吾法评反事之间句相似性(预习语),但于可互换上下文中平等SGT。 因 logit 配对以均受限反事实集上,吾更进公平性指标,兼存仇言检测之性。', 'ru': 'Подходы к смягчению предвзятости снижают зависимость моделей от чувствительных характеристик данных, таких как токены социальных групп (SGT), что приводит к равным прогнозам по чувствительным характеристикам. Однако при обнаружении ненавистнических высказываний, уравнивающие модельные прогнозы могут игнорировать важные различия между целевыми социальными группами, поскольку ненавистнические высказывания могут содержать стереотипный язык, специфичный для каждого SGT. Здесь, чтобы принять во внимание конкретный язык о каждом SGT, мы полагаемся на контрафактную справедливость и уравниваем прогнозы среди контрафактов, сгенерированных изменением SGT. Наш метод оценивает сходство в вероятности предложений (с помощью предварительно обученных языковых моделей) среди контрафактивов, относиться к SGT одинаково только в взаимозаменяемых контекстах. Применяя логит-пару для выравнивания результатов по ограниченному набору контрафактов для каждого экземпляра, мы улучшаем метрики справедливости, сохраняя при этом эффективность модели при обнаружении ненавистнических высказываний.', 'hi': 'पूर्वाग्रह शमन दृष्टिकोण डेटा की संवेदनशील विशेषताओं पर मॉडल की निर्भरता को कम करते हैं, जैसे कि सामाजिक समूह टोकन (एसजीटी), जिसके परिणामस्वरूप संवेदनशील विशेषताओं में समान भविष्यवाणियां होती हैं। हेट स्पीच डिटेक्शन में, हालांकि, मॉडल भविष्यवाणियों को बराबर करने से लक्षित सामाजिक समूहों के बीच महत्वपूर्ण मतभेदों की अनदेखी हो सकती है, क्योंकि हेट स्पीच में प्रत्येक एसजीटी के लिए विशिष्ट रूढ़िवादी भाषा हो सकती है। यहां, प्रत्येक एसजीटी के बारे में विशिष्ट भाषा को ध्यान में रखने के लिए, हम प्रतिवादी निष्पक्षता पर भरोसा करते हैं और एसजीटी को बदलकर उत्पन्न प्रतिवादियों के बीच भविष्यवाणियों को बराबर करते हैं। हमारी विधि वाक्य संभावनाओं में समानता का मूल्यांकन करती है (पूर्व-प्रशिक्षित भाषा मॉडल के माध्यम से) प्रतिवादियों के बीच, एसजीटी को केवल विनिमेय संदर्भों के भीतर समान रूप से व्यवहार करने के लिए। प्रत्येक उदाहरण के लिए counterfactuals के प्रतिबंधित सेट पर परिणामों को बराबर करने के लिए लॉगिट युग्मन लागू करके, हम नफरत भाषण का पता लगाने पर मॉडल प्रदर्शन को संरक्षित करते हुए निष्पक्षता मीट्रिक में सुधार करते हैं।', 'ga': 'Laghdaíonn cur chuige maolaithe laofachta spleáchas na samhlacha ar ghnéithe íogaire sonraí, cosúil le comharthaí grúpa sóisialta (SGTanna), rud a fhágann go mbíonn tuar comhionann ar fud na ngnéithe íogaire. I mbrath fuathchaint, áfach, is féidir neamhaird a dhéanamh ar dhifríochtaí tábhachtacha i measc grúpaí sóisialta spriocdhírithe trí thuar samhlacha a chothromú, mar is féidir le fuathchaint teanga steiréitipiciúil a bhaineann go sonrach le gach SGT a chuimsiú. Anseo, chun an teanga shainiúil faoi gach SGT a chur san áireamh, táimid ag brath ar chothroime fhrithfhíorasach agus cothromú a dhéanamh ar thuartha i measc na bhfrithfhíorasach, a ghintear trí na SGTanna a athrú. Déanann ár modh meastóireacht ar chosúlacht na bpianbhreitheanna (trí mhúnlaí teanga réamhoilte) i measc na bhfrithfhíorasacha, chun caitheamh go cothrom le SGTanna laistigh de chomhthéacsanna idirmhalartaithe amháin. Trí phéireáil lóistíochta a chur i bhfeidhm chun torthaí a chomhionannú ar an tsraith shrianta de fhrithfhíorasacha do gach cás, cuirimid feabhas ar mhéadracht na cothroime agus ag an am céanna ag caomhnú feidhmíochta samhla ar bhrath fuathchaint.', 'el': 'Οι προσεγγίσεις μετριασμού της προκατάληψης μειώνουν την εξάρτηση των μοντέλων από ευαίσθητα χαρακτηριστικά των δεδομένων, όπως τα σήματα κοινωνικής ομάδας, με αποτέλεσμα ίσες προβλέψεις για τα ευαίσθητα χαρακτηριστικά. Στην ανίχνευση λόγου μίσους, ωστόσο, οι προβλέψεις εξισορρόπησης μοντέλων μπορεί να αγνοήσουν σημαντικές διαφορές μεταξύ στοχευμένων κοινωνικών ομάδων, καθώς η ομιλία μίσους μπορεί να περιέχει στερεοτυπική γλώσσα ειδική για κάθε Εδώ, για να λάβουμε υπόψη τη συγκεκριμένη γλώσσα για κάθε Εδώ, βασιζόμαστε στην αντιπραγματική δικαιοσύνη και εξισορροπούμε τις προβλέψεις μεταξύ των αντιπραγματικών, που δημιουργούνται με την αλλαγή των ΣΣΤ. Η μέθοδός μας αξιολογεί την ομοιότητα στις πιθανότητες προτάσεων (μέσω προ-εκπαιδευμένων γλωσσικών μοντέλων) μεταξύ των αντικαταρκτικών, ώστε να αντιμετωπίζονται οι SGT ισότιμα μόνο σε εναλλάξιμα πλαίσια. Εφαρμόζοντας τη σύζευξη για την εξισορρόπηση των αποτελεσμάτων στο περιορισμένο σύνολο αντιπαραγωγικών στοιχείων για κάθε περίπτωση, βελτιώνουμε τις μετρήσεις δικαιοσύνης διατηρώντας παράλληλα την απόδοση του μοντέλου στην ανίχνευση ομιλίας μίσους.', 'hu': 'A Bias enyhítésére irányuló megközelítések csökkentik a modellek függőségét az adatok érzékeny jellemzőitől, mint például a társadalmi csoportok tokenjeitől (SGT), ami egyenlő előrejelzéseket eredményez az érzékeny jellemzők között. A gyűlöletbeszéd felismerésében azonban a modelljóslatok kiegyenlítése figyelmen kívül hagyhatja a célzott társadalmi csoportok közötti fontos különbségeket, mivel a gyűlöletbeszéd tartalmazhat sztereotípikus nyelvet az egyes SGT-ekre vonatkozóan. Itt, hogy figyelembe vegyük az egyes SGT-ekre vonatkozó konkrét nyelvet, támaszkodunk az ellentényes igazságosságra és kiegyenlítjük az ellentények előrejelzéseit az SGT-k megváltoztatásával generált ellentények között. Módszerünk értékeli a mondatok hasonlóságát (előre képzett nyelvi modelleken keresztül) az ellentények között, hogy az SGT-eket egyenlően kezeljük csak cserélhető kontextusokban. A logit párosítás alkalmazásával, hogy kiegyenlítsük az eredményeket a korlátozott kontratényszerűsítő készleten minden példányban, javítjuk a méltányossági mutatókat, miközben megőrizzük a gyűlöletbeszéd felismerésére vonatkozó modellteljesítményt.', 'ka': 'Bias mitigation approaches reduce the dependence of models on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. მაგრამ მპატიური სიტყვების განსახულებაში, მოდელის განსახულებების განსახულება შეიძლება იგნონოთ მნიშვნელოვანი სოციალური ჯგუფის განსხვავებას, რადგან მპატიური სიტყვების განსახულება შეიძლება ყველა SGT-ზე სტერეოტიპური ენაში. აქ, რომ ყოველ SGT-ზე გან ჩვენი მეთოდი განსაზღვრებას სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა რომელიც ლოგიტიკური პორიზაციის გამოყენება, რომ განტოლება შედეგის შესახებ ყველა ინტერფექტულების შესახებ, ჩვენ ყველა ინტერფექტულების შესახებ უფრო უფრო უფრო უფრო უფრო', 'lt': 'Būvio mažinimo metodai mažina modelių priklausomybę nuo jautrių duomenų požymių, pavyzdžiui, socialinių grupių žymenų (SGT), o dėl to atsiranda vienodos prognozės dėl visų jautrių požymių. Tačiau neapykantos kalbos aptikimo metu modelių prognozių lyginimas gali ignoruoti svarbius skirtumus tarp tikslinių socialinių grupių, nes neapykantos kalba gali apimti stereotipinę kiekvienam SGT būdingą kalbą. Čia, siekiant atsižvelgti į konkrečią kalbą apie kiekvieną SGT, mes pasikliaujame priešingu teisingumu ir lyginamos prognozės tarp priešingų faktų, sukurtos keičiant SGT. Mūsų metodas vertina sąvokų tikimybės panašumą (naudojant iš anksto parengtus kalbos modelius) tarp priešingų faktų, kad SGT būtų vienodai vertinamos tik keičiamose aplinkybėse. Taikant logito pariavimą, kad kiekvienam atvejui būtų lyginami ribotų priešingų medžiagų rinkinio rezultatai, mes geriname sąžiningumo metriką, kartu išsaugodami modelio rezultatus neapykantos kalbos aptikimo srityje.', 'it': "Gli approcci di mitigazione del bias riducono la dipendenza dei modelli dalle caratteristiche sensibili dei dati, come i token di gruppo sociale (SGT), con conseguente previsione paritaria tra le caratteristiche sensibili. Nel rilevamento del discorso d'odio, tuttavia, l'equalizzazione delle previsioni dei modelli può ignorare importanti differenze tra gruppi sociali mirati, in quanto il discorso d'odio può contenere un linguaggio stereotipato specifico per ogni SGT. Qui, per prendere in considerazione il linguaggio specifico di ogni SGT, ci affidiamo all'equità controfattuale e equalizziamo le previsioni tra controfattuali, generate dal cambiamento dei SGT. Il nostro metodo valuta la somiglianza nelle probabilità di frase (tramite modelli linguistici pre-addestrati) tra i controfattuali, per trattare i SGT equamente solo all'interno di contesti intercambiabili. Applicando l'accoppiamento logit per equalizzare i risultati sul set ristretto di controfatti per ogni istanza, miglioriamo le metriche di equità preservando le prestazioni del modello sul rilevamento del discorso d'odio.", 'mk': 'Пристапите за намалување на навредата ја намалуваат зависноста на моделите од чувствителните карактеристики на податоците, како што се социјалните групи (СГТ), што резултира со еднакви предвидувања на чувствителните карактеристики. Во детекцијата на говорот на омраза, сепак, еднаквоста на предвидувањата на моделот може да ги игнорира важните разлики меѓу целните социјални групи, бидејќи говорот на омраза може да содржи стереотипичен јазик специфичен за секој SGT. Тука, за да го земеме во предвид специфичниот јазик за секој SGT, ние се потпираме на контрафактна праведност и еднакво Нашиот метод ја проценува сличноста во веројатностите на речениците (преку предобучени јазички модели) меѓу контрафактивните, за да се третира СГТ еднакво само во разменливи контексти. Со аплицирање на парирање на логит за да ги еднаквираме резултатите на ограничениот сет контрафактиви за секој случај, ние ја подобруваме метриката на фер, при што ја зачуваме моделната резултата на детекцијата на говорот на омраза.', 'ml': 'ബിയാസ് മീറ്റീഷന്\u200d അടുത്തുവരുന്നു. മോഡലുകളുടെ ആശ്രയിച്ചിരിക്കുന്നു. സാമൂഹ്യ ഗ്രൂപ്പിന്റെ അടയാളങ്ങള്\u200d പോലെയുള്ള വിവരങ്ങളുടെ സംബന്ധി വെറുപ്പുള്ള സംസാരത്തെ കണ്ടുപിടിക്കുന്നതില്\u200d, മോഡല്\u200d പ്രവചനങ്ങള്\u200d സമമാക്കുന്നതില്\u200d സാമൂഹിക ഗ്രൂപ്പുകളുടെ ഇടയില്\u200d പ്രധാനപ്പെട്ട വ്യത്യാസങ്ങള്\u200d അവഗണിക്കാന്\u200d സാധിക്കും. പക്ഷെ വാക്ക് എല്ലാ SGT-ന നമ്മുടെ രീതിയില്\u200d വാക്കിന്റെ സാധ്യതകളുടെ (മുമ്പ് പഠിപ്പിക്കപ്പെട്ട ഭാഷ മോഡലുകളിലൂടെ) സമമാണെന്ന് വിലയിച്ചുകൊണ്ടിരിക്കുന്ന എല്ലാ ഉദാഹരണത്തിനും നിര്\u200dബന്ധിതമായ പ്രവര്\u200dത്തനങ്ങള്\u200d സമമാക്കാന്\u200d ലോഗ്റ്റ് ജോടിയായി പ്രയോഗിക്കുന്നതിനാല്\u200d, വെറുപ്പ് സംസാരം കണ്ടെത്തുന്', 'mn': 'Bias mitigation approach reduces models dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. Гэхдээ үзэн ядах илтгэлийн тодорхойлолтын тулд, загварын тодорхойлолтын тодорхойлолтын тулд нийгмийн бүлгүүдийн хооронд чухал ялгааг үзэх боломжтой. Яагаад гэвэл үзэн ядах илтгэлийн хэл нь SGT бүрт тодорхойлолтой хэл байдаг. Бидний арга нь өгүүлбэрийн хувьд (сургалтын хэл загваруудын арга хэмжээгээр) зөвхөн өөрчлөлтийн нөхцөлд зөвхөн тэнцүү байдлаар эмчилгээ хийх боломжтой байдлыг үнэлдэг. Жишээлбэл бүрт хуурамч хэмжээний үр дүнг тэнцүү болгохын тулд логит хоорондоо ашиглаж, бид үзэн ядуурлын илтгэл тайлбарлахын тулд загварын үйл ажиллагааг сайн сайжруулдаг.', 'kk': 'Екінші реттеу үлгілердің тәуелдігін, мәліметтік топтың (SGT) белгілері секілді, мәліметтік топтың (СGT) сипаттамасынан, мәліметтің тәуелдігін көшірмелейді. Бірақ қарсылық сөйлерді анықтау үшін үлгі таңдау үшін мақсатты әлемдік топтардың арасындағы маңызды айырмашылығын елемей алады, себебі қарсылық сөйлері барлық SGT үшін стереотиптік тілді болады. Мұнда, әрбір SGT туралы ерекше тілді есептеу үшін, біз қарсылық а Біздің әдіміміз сөздердің ұқсастығын (алдын- оқылған тіл үлгілері арқылы) тек ауыстырылмайтын тәртіптердің ішінде тең болады. Логикалық біріктіру үшін әрбір мысал үшін шектелген жалғастыру жиынының шектелген нәтижелерін тең ету үшін қолдану үшін, біз жалғастыруды анықтау үшін үлгісін сақтау үшін дұрыс метрикал', 'no': 'Bias-mitigering nærmer å redusera modelleavhengighet av følsynlege funksjonar av data, som sosiale gruppetokens (SGT), og resulterer i like forhåndsvising over dei følsynlege funksjonane. Dette kan imidlertid ignorerast viktige forskjeller mellom målte sosiale grupper, slik at hatespråk kan innehalda stereotipisk språk spesifisert for kvar SGT. Her, for å ta opp den spesifikke språket om kvar SGT i konto, vert vi tilbakekalla på vilkårleg rettferdighet og tilsvara forandringar mellom vilkårlege grupper, som er generert ved å endra SGT. Metoden vårt evaluerer liknande uttrykk i setningsannsynlegvis (via før- trengte språk- modeller) mellom vilkårlege, for å behandla SGT berre i omfangsbare kontekstar. På å bruk av logisk par for å tilsvara utgåver på den grenserte setten av vilkårleg for kvar eksempel, er vi forbetra rettferdige metrikn mens vi lagrar modelleutgåva ved å oppdaga hatespråk.', 'pl': 'Podejścia łagodzące uprzedzenia zmniejszają zależność modeli od wrażliwych cech danych, takich jak tokeny grup społecznych (SGT), co prowadzi do równych przewidywań dla wrażliwych cech. W wykrywaniu mowy nienawiści jednak wyrównujące modele prognozowania mogą ignorować istotne różnice pomiędzy docelowymi grupami społecznymi, ponieważ mowa nienawiści może zawierać stereotypowy język specyficzny dla każdego SGT. Tutaj, aby uwzględnić konkretny język dotyczący każdego SGT, polegamy na sprawiedliwości kontrafaktowej i wyrównujemy przewidywania między kontrafaktowymi, generowane przez zmianę SGT. Nasza metoda ocenia podobieństwo prawdopodobieństwa zdań (za pomocą wstępnie przeszkolonych modeli językowych) wśród kontrafaktów, aby traktować SGT jednakowo tylko w wymiennych kontekstach. Stosując parowanie logitów w celu wyrównania wyników dla ograniczonego zestawu kontrafaktów dla każdego przypadku, poprawiamy wskaźniki sprawiedliwości przy jednoczesnym zachowaniu wydajności modelu w wykrywaniu mowy nienawiści.', 'ro': 'Abordările de atenuare a bias reduc dependența modelelor de caracteristicile sensibile ale datelor, cum ar fi jetoanele de grup social (SGT), rezultând în previziuni egale în ceea ce privește caracteristicile sensibile. În detectarea discursului de ură, totuși, egalizarea predicțiilor modelului poate ignora diferențe importante între grupurile sociale vizate, deoarece discursul de ură poate conține un limbaj stereotip specific fiecărui SGT. Aici, pentru a lua în considerare limbajul specific fiecărui SGT, ne bazăm pe echitatea contrafactuală și egalizăm predicțiile între contrafactuale, generate de schimbarea SGT. Metoda noastră evaluează asemănarea posibilităților propozițiilor (prin intermediul modelelor lingvistice pre-instruite) între contrafactuale, pentru a trata SGT în mod egal numai în contexte interschimbabile. Prin aplicarea asocierii logit pentru a egaliza rezultatele pe setul restricționat de contrafactuale pentru fiecare instanță, îmbunătățim măsurătorile corectitudinii, păstrând în același timp performanța modelului privind detectarea discursului la ură.', 'ms': 'Pendekatan perlemasan bias mengurangkan dependensi model pada ciri-ciri sensitif data, seperti token kumpulan sosial (SGT), yang menghasilkan ramalan yang sama di seluruh ciri-ciri sensitif. Dalam pengesan ucapan kebencian, bagaimanapun, persamaan ramalan model mungkin mengabaikan perbezaan penting di antara kumpulan sosial sasaran, kerana ucapan kebencian boleh mengandungi bahasa stereotipik yang spesifik bagi setiap SGT. Di sini, untuk mengambil bahasa spesifik mengenai setiap SGT dalam akaun, kami bergantung pada keadilan kontrafaktual dan persamakan ramalan diantara kontrafaktual, dijana dengan mengubah SGT. Kaedah kami menilai kesamaan dalam kemungkinan kalimat (melalui model bahasa yang dilatih-dilatih) diantara kontrafaktal, untuk melayan SGT sama sahaja dalam konteks yang boleh ditukar. Dengan melaksanakan pasangan logit untuk menyebabkan hasil pada set terhad kontrafaktal untuk setiap contoh, kita meningkatkan metrik keadilan sementara mempertahankan prestasi model pada pengesan ucapan kebencian.', 'mt': 'L-approċċi għall-mitigazzjoni tad-danni jnaqqsu d-dipendenza tal-mudelli fuq karatteristiċi sensittivi tad-dejta, bħal tokens tal-gruppi soċjali (SGTs), li jirriżultaw fi tbassir ugwali fil-karatteristiċi sensittivi kollha. In hate speech detection, however, equalizing model predictions may ignore important differences among targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs.  Il-metodu tagħna jevalwa s-similarità fil-probabbiltà tas-sentenzi (permezz ta’ mudelli lingwistiċi mħarrġa minn qabel) fost il-kontrofattwali, biex jittrattaw it-SGTs b’mod ugwali biss f’kuntesti interkambjabbli. Permezz tal-applikazzjoni tal-paragun tal-logit biex jiġu ugwalizzati r-riżultati dwar is-sett ristrett ta’ kontrofattwali għal kull każ, aħna ntejbu l-metriċi tal-ġustizzja filwaqt li nippreservaw il-prestazzjoni tal-mudell dwar id-detezzjoni tad-diskors tal-mibegħda.', 'sr': 'Približava se smanjivanju ovisnosti modela o osjetljivim karakteristikama podataka, poput znakova društvene grupe (SGT), što je rezultiralo jednakom predviđanju u raznim osjetljivim karakteristikama. Međutim, u otkrivanju govora mržnje, jednakost predviđanja modela može ignorirati važne razlike među ciljenim društvenim grupama, jer govor mržnje može sadržati stereotipni jezik specifičan svakom SGT-u. Ovde, da bismo uzeli u obzir specifični jezik o svakom SGT-u, oslanjali smo se na lažnu pravednost i jednakost predviđanja među lažnim grupama, proizvedenih izmjenom SGT- Naša metoda procjenjuje sličnost u verovatnoj rečenici (putem predobučenih jezičkih modela) među pogrešnim osobama, da se liječi SGT jednako samo u međumjenom kontekstu. Primjenjujući parenje logike za jednakost rezultata na ograničenom setu krivotvornih faktora za svaki primer, poboljšavamo metriku pravednosti dok čuvamo model izvršnosti otkrivanja govora mržnje.', 'so': 'Xiriiridda dabeecadu waxay u soo dhowaadaa inay hoos u dhigtaa noocyada ku xiran tababarada dhaqaalaha, tusaale ahaan calaamadaha bulshada (SGTs), taasoo sababto ah wax u sheegid si isku mid ah oo ku saabsan tababarada jilicsan. Si kastaba ha ahaatee hadal nacayb ah waxaa laga yaabaa in la jeedo wax muhiim ah oo ka mid ah kooxaha bulshada la hagayo, sababtoo ah hadalka nacaybka ayaa ku jirta luqada caadiga ah oo ku saabsan SGT. Halkan, si aad u qaadato luuqada gaarka ah oo ku saabsan SGT, waxaan isku hallaynaa caddaalad, si aan u dhigno wax u sheegno khilaaf ah, si loo beddelo SGT. Isku qiimeynaya qaababka aan isku mid ahayn xafiiska hadalka (via sameynta qaababka afka hore) oo ka mid ah qofka ka hor tababaray, in lagu tijaabiyo SGTs si siman oo kaliya xilliyada isbedeli karo. Sida lagu codsashada injiilka labada lamid ah si aan u simnaaneyno arimaha la xadgudbay, tusaale ahaan baaritaanka cadaaladda ah ayaannu kordhinaa qaababka cadaaladda marka lagu ilaalinayo sameynta muusikada ku saabsan aqoonta hadalka nacaybka.', 'sv': 'Metoder för begränsning av bias minskar modellens beroende av känsliga egenskaper i data, såsom sociala grupptokens (SGTs), vilket resulterar i lika förutsägelser för de känsliga funktionerna. Vid detektering av hattal kan dock utjämning av modellförutsägelser ignorera viktiga skillnader mellan riktade sociala grupper, eftersom hattal kan innehålla stereotypa språk specifikt för varje SGT. Vår metod utvärderar likheten i meningsskillnader (via förutbildade språkmodeller) bland kontrafakta, för att behandla SGT lika endast i utbytbara sammanhang. Genom att använda logitparaning för att utjämna utfallet på den begränsade uppsättningen kontrafakta för varje instans, förbättrar vi rättvisa mätvärden samtidigt som vi bevarar modellprestanda för detektering av hattal.', 'si': "Bias Mitigation approach minimises Model's Dependency on sensive Fearts of Data, e.g. සමාජික කණ්ඩායම් ටොකන්ස් (SGTs), that will lead to Equal forecast over the sensive Fearts. In Hate Talk Detection, though, Equivalizing Model forecast may be neglected Major Diffections in Tarirfed සාමාජික කණ්ඩායම් වලින්, as Hate Talk can have Steeotyp language especifixes to all SGT. Here, to Take the especifixes language on all SGT to account, we use on CountrfReal fairness and Equivalize forecast Among Countrfact Groups, generous by Changing the SGTs. අපේ විද්\u200dයාව වාර්තාවය සමාන්\u200dයතාවක් විශ්වාස කරනවා වාර්තාවක් විතරයි (ප්\u200dරීක්ෂිත භාෂාවක් මොඩේල් වලින්) විරුද්ධ විද්\u200dයාව හැම උදාහරණයක්ම සීමාවිත ප්\u200dරතිචාරයක්ම සමාන්තිය කරන්න ලොගිට් එක්ක සමාන්තිය කරන්න, අපි හැම උදාහරණයක්ම සමාන්තිය ප්\u200dරතිචාරයක", 'ta': 'பையாச் சுருக்கம் மாதிரிகளின் சார்ந்ததை குறைக்க முடியும், உணர்வுடைய குணங்கள் போன்ற சமூக குழுக்குறிகள் (SGTs) போன்ற முறைமைகளின் சார் வெறுப்பு பேச்சு கண்டுபிடிப்பில், ஒப்பிடும் மாதிரி முக்கியமான வேறுபாடுகளை குறிக்கலாம், ஏனெனில் வெறுப்பு பேச்சு ஒவ்வொரு SGT க்கும் குறிப்பிட்ட மொழியை கணக்கிட முடியும். ஒவ்வொரு SGT மொழ எங்கள் முறைமையில் வாக்கியின் சாத்தியங்களில் ஒத்தியத்தை மதிப்பிடுகிறது (முன் பயிற்சி மொழி மாதிரிகளின் வழியாக) எதிர்பார்ப்பாளர்களில்  ஒவ்வொரு நிகழ்வுக்கும் வரையறையான எதிர்காரணிகளை சமமாக்குவதற்கு நுழைவு ஜோடியை பயன்படுத்தி, நாம் வெறுப்பு பேச்சு கண்டுபிடிப்பில் மாதிரி', 'ur': 'دوسری مٹیانگ کی تقریبا ہے کہ مدلکوں کی نسبت دکھانے کے ذریعہ ذلیل کرتی ہے، جیسے سوسیل گروپ ٹوکنز (SGTs) کے، اس کے نتیجے میں حساس فرضیوں میں برابر پیش بینی کرتی ہیں. However, hate speech detection, equalizing model predictions may ignore important differences between targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language into account, we rely on counterfactual fairness and equate predictions among counterfactuals, generated by changing the SGT. ہماری طریقہ مفصل کے مطابق مطابق (پہلے آموزش کی زبان نمڈلوں کے ذریعہ) کے مطابق مطابق مطابق مطابق ہے کہ SGTs کو صرف تبدیلی حاصل کے مطابق سمجھنا چاہیں۔ ہر مثال کے لئے تقویت کا جوڑ برابر کرنا کے لئے لاگ جوڑنے کے ذریعہ سے ہر قسم کے مثال کے ذریعہ محدود ہونے کے لئے، ہم انصاف متریک کو بہتر کر رہے ہیں اور ناپسندیدہ بات شناسی کے ذریعہ موڈل کی عملی حفاظت کرتے ہیں.', 'uz': "Koʻchirish usuli modellarning sensitive xususiyatlariga ega bo'lishi imkoniyatlarini kamaytirish mumkin, huddi jamiyat guruhning imkoniyatlari (SGTs) kabi bir necha gapiruvchilarni kamaytirish mumkin. Hatta so'zni aniqlash uchun modelni tenglashtirish natijalar jamiyatlaridagi muhim o'zgarishlarni o'chirib boʻlishi mumkin, chunki hat so'zlari har bir SGT uchun stereotypical tillariga ega bo'lishi mumkin. Bu yerda, har bir SGT haqida xabar tillarni hisoblash uchun, biz faqat haqida ishlatamiz va SGT ni o'zgartirish orqali foydalanuvchilardan foydalanishimiz mumkin. Бизнинг усулимизнинг қонун ўзгартириб турувчи контектларда SGTs га баробар кўриш учун фойдаланиш мумкин вазиятлар орасидаги фойдаланишни бажаришга (бундан аввал тааллуқли тил мосламаларидан фойдаланиб) ҳисобланади. Har bir misol uchun cheksiz foydalanuvchilarning natijalarini teng qilish uchun foydalanish orqali foydalanishimiz mumkin, biz yolg'on gapirishni aniqlashda model amalni saqlash mumkin.", 'vi': 'Theo phương pháp giảm bớt sự phụ thuộc của mô- đun dựa trên tính chất nhạy cảm của dữ liệu, như thẻ của nhóm xã hội (GIVS), cho nên khả năng tiên đoán tương đồng trong các tính nhạy cảm. Trong việc phát hiện ngôn ngữ ghét, Tuy nhiên, khả năng cân bằng của mô hình có thể lờ đi những khác biệt quan trọng giữa các nhóm xã hội mục tiêu, vì ngôn ngữ căm ghét có thể chứa đựng ngôn ngữ theo kiểu rập khuôn của mỗi SGT. Ở đây, để cân nhắc ngôn ngữ cụ thể về mỗi SGT, chúng ta dựa trên sự công bằng ngược và cân bằng tiên đoán giữa các đối số, tạo ra bằng cách thay đổi SGT. Cách của chúng ta tìm ra một sự tương tự trong câu giống như một cách bằng lời trước tập luyện để tiếp tục, để chỉ điều đón chung chỉ trong môi trường hợp giữa nhau. Bằng cách sử dụng kết cấu lô-gic để cân bằng các kết quả trên một số công nhân ngược hạn cho mỗi ví dụ, chúng tôi cải tiến âm lượng công bằng trong khi giữ khả năng biểu hiện ghét giọng nói.', 'bg': 'Подходите за смекчаване на наклоненията намаляват зависимостта на моделите от чувствителните характеристики на данните, като например токени за социални групи (SGT), което води до равни прогнози за чувствителните характеристики. При откриването на речта на омразата обаче изравняването на прогнозите на модела може да игнорира важни разлики между целевите социални групи, тъй като речта на омразата може да съдържа стереотипен език, специфичен за всеки Тук, за да вземем предвид специфичния език за всеки ССЗ, разчитаме на контрафактическа справедливост и изравняваме прогнозите между контрафактите, генерирани чрез промяна на ССЗ. Нашият метод оценява сходството в вероятността от изречения (чрез предварително обучени езикови модели) между контрафактите, за да третираме СГТ еднакво само в взаимозаменяеми контексти. Чрез прилагането на логит сдвояване за изравняване на резултатите върху ограничения набор от контрафакти за всеки случай, ние подобряваме показателите за справедливост, като същевременно запазваме ефективността на модела при откриване на реч на омраза.', 'nl': "Bias mitigation benaderingen verminderen de afhankelijkheid van modellen van gevoelige kenmerken van gegevens, zoals social group tokens (SGT's), wat resulteert in gelijke voorspellingen over de gevoelige kenmerken. Bij haatspraakdetectie kunnen evenwel egaliserende modelvoorspellingen belangrijke verschillen tussen doelgroepen negeren, omdat haatspraak stereotype taal kan bevatten die specifiek is voor elke SGT. Om rekening te houden met de specifieke taal over elke SGT, vertrouwen we op contrafactische eerlijkheid en egaliseren we voorspellingen tussen contrafactische factoren, gegenereerd door het wijzigen van de SGT's. Onze methode evalueert de gelijkenis in zinswaarschijnlijkheid (via vooraf getrainde taalmodellen) tussen contrafacticals, om SGT's alleen binnen uitwisselbare contexten gelijk te behandelen. Door logit pairing toe te passen om resultaten op de beperkte set contrafacticals voor elk geval te egaliseren, verbeteren we eerlijkheidsstatistieken en behouden we de modelprestaties bij haatspraakdetectie.", 'da': "Tilgange til begrænsning af bias reducerer modellernes afhængighed af følsomme funktioner i data, såsom sociale gruppetokens (SGTs), hvilket resulterer i lige forudsigelser på tværs af de følsomme funktioner. I hadeforståelse kan udligning af modelforståelser imidlertid ignorere vigtige forskelle mellem målrettede sociale grupper, da hadeforståelser kan indeholde stereotypiske sprog specifikt for hver SGT. Her, for at tage højde for det specifikke sprog om hver SGT, er vi afhængige af kontrafaktisk retfærdighed og udligne forudsigelser blandt kontrafaktuelle elementer, der genereres ved at ændre SGT'erne. Vores metode evaluerer ligheden i sætningssikkerheder (via præ-trænede sprogmodeller) blandt kontrafaktuelle, for kun at behandle SGT ligeligt i udskiftelige sammenhænge. Ved at anvende logit parring til at udligne resultater på det begrænsede sæt kontrafaktuelle elementer for hvert enkelt tilfælde, forbedrer vi retfærdighedsmålinger, samtidig med at vi bevarer modellens ydeevne ved detektering af hadefulde taler.", 'de': 'Ansätze zur Bias-Minderung reduzieren die Abhängigkeit von Modellen von sensiblen Merkmalen von Daten, wie Social Group Tokens (SGTs), was zu gleichen Vorhersagen für die sensiblen Merkmale führt. Bei der Hassrede-Erkennung können jedoch ausgleichende Modellvorhersagen wichtige Unterschiede zwischen den Zielgruppen ignorieren, da Hassrede stereotype Sprache enthalten kann, die für jeden SGT spezifisch ist. Um die spezifische Sprache über jeden SGT zu berücksichtigen, setzen wir hier auf kontrafaktische Fairness und gleichen Vorhersagen unter kontrafaktischen Faktoren aus, die durch Änderung der SGT generiert werden. Unsere Methode bewertet die Ähnlichkeit der Satzwahrscheinlichkeiten (über vortrainierte Sprachmodelle) unter kontrafaktischen Faktoren, um SGTs nur in austauschbaren Kontexten gleich zu behandeln. Durch die Anwendung von Logit Pairing, um Ergebnisse auf dem beschränkten Satz kontrafaktischer Faktoren für jede Instanz auszugleichen, verbessern wir Fairness Metriken und bewahren gleichzeitig die Modellleistung bei der Erkennung von Hassreden.', 'hr': 'Pristup smanjenja smanjenja ovisnosti modela o osjetljivim karakteristikama podataka, poput znakova društvene grupe (SGT), što je rezultiralo jednakom predviđanju kroz osjetljive karakteristike. Međutim, u otkrivanju govora mržnje, jednakost predviđanja modela može ignorirati važne razlike među ciljnim društvenim skupinama, jer govor mržnje može sadržati stereotipični jezik specifičan za svaku SGT. Ovdje, kako bismo uzeli u obzir specifični jezik o svakom SGT-u, oslanjali smo se na lažnu pravdu i jednakost predviđanja među lažnim skupinama, proizvedenih izmjenom SG Naša metoda procjenjuje sličnost u vjerojatnosti rečenica (putem predobučenih jezičkih modela) među pogrešnim osobama, da se liječi SGT jednako samo u međumjenom kontekstu. Primjenjujući parenje logike za jednakost ishoda ograničenog skupa krivotvorenika za svaki primjer, poboljšavamo metriku pravednosti dok čuvamo model učinka otkrivanja govora mržnje.', 'id': 'Pendekatan penyemasan bias mengurangi ketergantungan model pada karakteristik sensitif data, seperti token kelompok sosial (SGT), yang menyebabkan prediksi yang sama di seluruh karakteristik sensitif. Dalam deteksi pidato kebencian, bagaimanapun, persamaan prediksi model mungkin mengabaikan perbedaan penting di antara kelompok sosial sasaran, karena pidato kebencian dapat mengandung bahasa stereotipis yang spesifik untuk setiap SGT. Di sini, untuk mempertimbangkan bahasa spesifik tentang setiap SGT, kami bergantung pada keadilan kontrafaktual dan persamakan prediksi di antara kontrafaktal, yang dihasilkan oleh mengubah SGT. Metode kami mengevaluasi kesempatan dalam kalimat kemungkinan (melalui model bahasa yang terlatih-terlatih) diantara kontrafaktal, untuk memperlakukan SGT sama hanya dalam konteks yang dapat ditukar. By applying logit pairing to equalize outcomes on the restricted set of counterfactuals for each instance, we improve fairness metrics while preserving model performance on hate speech detection.', 'sw': 'Utafiti wa mifumo unakaribia kupunguza mitindo ya kutegemea vipengele vya taarifa, kama vile alama za kijamii (SGTs), na kusababisha kutabiri sawa katika vipengele vinavyohisi vizuri. Katika kutambua hotuba za chuki, hata hivyo, kutabiri utabiri wa mifano unaweza kupuuza tofauti muhimu kati ya makundi ya kijamii yanayolengwa, kwa sababu hotuba ya chuki inaweza kuwa na lugha ya kisiasa maalum kwa kila SGT. Hapa, kuchukua lugha maalum kuhusu kila SGT kwa hisabu, tunategemea uadilifu na usawa wa pamoja na utabiri kati ya watu wenye asili, uliotengenezwa kwa kubadilisha SGT. Utawala wetu unatathmini sawa katika uwezekano wa hukumu (kwa kupitia mifano ya lugha zilizofunzwa kabla) miongoni mwa wapinzani, kutengeneza SGTs kwa usawa pekee katika matatizo yanayobadilika. Kwa kutumia ujumbe wa kujiunga kuunganisha matokeo yaliyozukiwa na vikwazo vya wapinzani kwa kila mfano, tunaboresha mitindo ya uadilifu wakati wa kuhifadhia utendaji wa mifano juu ya kutambua hotuba ya chuki.', 'ko': '편견 완화 방법은 사회단체 태그(SGT)와 같은 데이터 민감성 특성에 대한 모델의 의존도를 줄여 민감성 특징 사이에서 평등한 예측을 실현했다.그러나 헤이트 스피치 테스트에서 균형모델 예측은 각 SGT 특유의 판에 박힌 언어를 포함할 수 있는 대상 사회 집단 간의 중요한 차이를 간과할 수 있다. 여기서 각 SGT의 특정 언어를 고려하기 위해 우리는 반사실 형평성에 의존하고 SGT를 바꾸어 생성된 반사실 사이의 균형적인 예측에 의존한다.우리의 방법은 반사실문에서 문장의 가능성의 유사성(미리 훈련된 언어모델을 통해)을 평가하여 서로 바꿀 수 있는 언어 환경에서만 SGT를 평등하게 대할 수 있도록 한다.logit배합을 응용하여 모든 실례가 제한된 반사실집합에서의 결과를 균형 있게 함으로써 우리는 공평성 도량을 개선하고 증오 음성 검측의 모델 성능을 보존했다.', 'fa': 'توجه به کمبود کردن دو گاهی بستگی مدلها بر ویژگی های حساسی از داده\u200cها کاهش می\u200cکند، مانند نشانه\u200cهای گروه اجتماعی (SGTs) که به نتیجه\u200cی پیش\u200cبینی\u200cهای برابر در ویژگی\u200cهای حساسی می\u200cرسد. ولی در کشف سخنرانی متنفر، برابری پیش بینی\u200cهای مدل ممکن است تفاوت مهم بین گروه\u200cهای اجتماعی هدف را نادیده بگیرد، زیرا سخنرانی متنفر می\u200cتواند برای هر SGT زبان استریوطیفی مشخص داشته باشد. اینجا، برای گرفتن زبان خاصی در مورد هر SGT به حساب، ما بر عدالت حقیقی اعتماد داریم و پیش بینی\u200cها بین دروغگویان روش ما مشابه\u200cای را در مجازات (از طریق مدل\u200cهای زبان پیش آموزش) در بین دروغگویان ارزش می\u200cدهد، تا SGTs را به همانند اندازه\u200cای درمان کنند، فقط در موقعیت\u200cهای تغییر قابل تغییر. با استفاده از جفت منطقی برای برابری نتیجه\u200cهای محدودیت مجموعه\u200cی دروغگویی برای هر مثال، ما متریک عدالت را بهتر می\u200cکنیم در حالی که حفظ نمونه\u200cای برای شناسایی سخنرانی ناخوشایند را حفظ می\u200cکنیم.', 'af': 'Bias minkering toekom toe om model se afhanklikheid van sensitiewe funksies van data te verminder, soos sosiale groep tokens (SGTs), wat resultaat in gelyke voorskoude oor die sensitiewe funksies. Hier, om die spesifieke taal oor elke SGT in rekening te neem, vertrou ons op gefalde regverdigheid en gelyk voorskoude onder gevalle gemaakte sosiale groepe te ignoreer, omdat haatspraat stereotipies taal spesifieke kan bevat vir elke SGT. Hier, om die spesifieke taal oor elke SGT in rekening te neem, vertrou ons op gefalde regverdigheid en gelyk voorskoude onder gevalle te ver Ons metode evalueer die gelykenis in sin waarskynliks (deur voorafgevorderde taal modele) onder gefalde, om SGTs gelyk te behandel net binne interhangeerbare konteks. Deur toepassing van logiese paar om uitgevoerdes te gelyk op die beperkte stel van teëindiges vir elke voorbeeld, verbeter ons regverdigheid metries terwyl ons model prestasie bewaar op haat spraak beskrywing.', 'tr': "Beýik bir şekilde örän nusgalaryň hassasiyetli möhümlerden, sosyal grup tokenleri (SGTs), hassasiyetli möhümleriň arasynda deňil öňümleri azaltýar. Ýöne ýigrenýän çykyş tanyşynda, örän nusgalary deňleýän nusgalaryň arasynda möhüm baýramlary görmäge mümkin däldir, ýigrenýän çykyş hemme SGT üçin has diňe stereotipi dil barlap biler. Bu ýerde, her SGT hakynda adalat dili görä alyp bilýän we SGT üýtgedeniň tarapyndan döredilen täsir edil Biziň ýüregimiz sözler ýaly sanlarynda deňleýär (öňünden öňünden eğlenen dil modellerinden) hasaplanyşylar arasynda, SGT'leriň diňe deňleşen ýagdaýlarynda deňleýär. Her örän çykyş edilen netijeleri eşit etmek üçin logik çiftini uygulamak üçin, biz ýigrenýän çykyş tanyşynda adalat metriklerimizi gowylaşdyrýarys.", 'am': 'የቢያ ማኅበራዊ ጉዳይ ምልክቶች (SGTs) በሚያሳየው የዓይነቶች መደገፊያ በሚያሳየው የዳታዎችን በተቃወመ ማሰናከል እና በሚያሳውቀው እውቀት ይታሰፋል፡፡ በጥላቻ ንግግር አግኝቷል፣ የሞዴል ውይይት በተመሳሳይ ማኅበራዊ ቡድሮች መካከል አስፈላጊ ልዩነትን ይሸሻል፣ ጥል ንግግር ለሁሉም SGT የተለየውን የስቴትዮቲካዊ ቋንቋ ይችላል፡፡ የሥርዓት ግንኙነታችን በተቃዋሚዎች መካከል ተቃዋሚ የቋንቋ ምሳሌዎች (ከመቀድሞ ተማሪ የቋንቋ ምሳሌዎች) በተመሳሳይ እና SGTs በተለወጠው ግንኙነት ውስጥ ብቻ ነው፡፡ የጥል ንግግር ማሳየትን በመጠበቅ እናሳድጋለን፡፡', 'hy': 'Մոտեցումները, որոնք նվազեցնում են սպառությունը, նվազեցնում են մոդելների կախվածությունը տվյալների զգայուն հատկանիշներից, ինչպիսիք են սոցիալական խմբի նշանները, ինչը հանգեցնում է հավասար կանխատեսումների զգա Միևնույն է, ատելության խոսքի հայտնաբերման ժամանակ, մոդելի կանխատեսումների հավասարակշռությունը կարող է անտեսել նպատակային սոցիալական խմբերի կարևոր տարբերությունները, քանի որ ատելության խոսքը կարող է պարունակել յուրաքանչյուր ՍՍՏ-ի համար կոնկրետ կարծրատիպիկ լեզու: Այստեղ, հաշվի առնելու յուրաքանչյուր ՍՍՏ-ի մասին կոնկրետ լեզու Մեր մեթոդը գնահատում է նախադասությունների հավանականության նմանությունը (նախապատրաստված լեզվի մոդելների միջոցով) հակափաստական գործոնների միջև, որպեսզի համաչափ վերաբերվեն ՍԳԹ-ին միայն փոխակերպվող կոնտեքստներում: Օգտագործելով հավասարակշռություն, որպեսզի հավասարակշռությունը լինի յուրաքանչյուր օրինակի հակափաստական գործիքների սահմանափակ համակարգում, մենք բարելավում ենք արդարության մետրիկները, մինչդեռ պահպանում ենք ատելության խոսքի հայտն', 'az': "İki küçük məlumatların modellərin bağlılığını, sosyal qrup möcüzələri (SGTs) kimi məlumatların bağlılıqlarını azaltmağa bənzəyir. Bu məlumatların bənzərini hissləşdirir. Ancaq nifrət sözləri keşfetməsində, modellərin tədbirlərini istifadə etmək məqsədil sosial qruplar arasında mövcud fərqliyi görməyə qadir olar, çünki nifrət sözləri hər SGT üçün stereotipik dili içərir. Burada, hər SGT haqqında müəyyən dili hesablamaq üçün, biz haqsız ədalətə təvəkkül edirik və SGT dəyişdirilməklə tədbirlərini Bizim metodumuz SGT'ləri ancaq dəyişdirilmiş müxtəliflərdə eyni tərzdə təhsil etmək üçün cümlələr mümkünlüyü (əvvəl təhsil edilmiş dil modelləri vasitəsilə) təhsil edir. Hər məsəl üçün müəyyən edilmiş iftira qurmaqlarının sonuçlarını eşitmək üçün logit çiftini uygulayaraq, ədalətli metrikləri düzəltdiyimiz zaman nefret sözlərini keşfetmək üçün modeli performansını qoruyub saxlayacağıq.", 'sq': 'Përqasjet e lehtësimit të bllokimit reduktojnë varësinë e modeleve nga karakteristikat e ndjeshme të të dhënave, të tilla si shenjat e grupit shoqëror (SGTs), që rezultojnë në parashikime të barabarta nëpër karakteristikat e ndjeshme. Në zbulimin e fjalëve të urrejtjes, megjithatë, ekuilibrimi i parashikimeve të modelit mund të injorojë dallimet e rëndësishme midis grupeve shoqërore të synuar, pasi fjalimi i urrejtjes mund të përmbajë gjuhën stereotipike specifike për çdo SGT. Këtu, për të marrë parasysh gjuhën specifike për çdo SGT, ne mbështetemi në drejtësinë kundërfaktore dhe ekuilibrimi i parashikimeve midis kontrafaktorëve, të gje Metoda jonë vlerëson ngjashmërinë në mundësitë e fjalëve (nëpërmjet modeleve gjuhësore të trajnuara para-të) midis kontrafakteve, për të trajtuar SGT në mënyrë të barabartë vetëm brenda konteksteve të ndërmjetësueshme. Duke aplikuar çiftimin e logjit për të barazuar rezultatet në grupin e kufizuar të kontrafakteve për çdo rast, ne përmirësojmë metrikat e drejtësisë duke ruajtur paraqitjen e modelit në zbulimin e fjalimit të urrejtjes.', 'bs': 'Bias pristup smanjivanju ovisnosti modela o osjetljivim karakteristikama podataka, poput znakova socijalne grupe (SGT), što je rezultiralo jednakom predviđanju u svim osjetljivim karakteristikama. Međutim, u otkrivanju govora mržnje, jednakost predviđanja modela može ignorirati važne razlike među ciljnim društvenim grupama, jer govor mržnje može sadržati stereotipni jezik specifičan svakom SGT-u. Ovdje, da bismo uzeli u obzir specifični jezik o svakoj SGT-u, oslanjali smo se na lažnu pravdu i jednakost predviđanja među lažnim grupama, proizvedenim izmjenom SGT- Naša metoda procjenjuje sličnost u verovatnoj rečenici (putem predobučenih jezičkih modela) među pogrešnim, da se liječi SGT jednako samo u međumjenom kontekstu. Primjenjujući parenje logike za jednakost rezultata na ograničenom setu krivotvornih faktora za svaki primjer, poboljšavamo metriku pravednosti dok čuvamo model izvršnosti otkrivanja govora mržnje.', 'ca': "Els enfocaments de mitigació del bias redueixen la dependència dels models de les característiques sensibles de les dades, com les fitxes de grups socials (SGT), resultant en predictions iguals entre les característiques sensibles. En la detecció del discurs d'odi, no obstant això, equilibrar les prediccions del model pot ignorar diferències importants entre grups socials mirats, com el discurs d'odi pot contenir llenguatges stereotípics específics per cada SGT. Aquí, per tenir en compte la llenguatge específica sobre cada SGT, confiem en la justesa contrafetiva i equilibrar les prediccions entre els contrafets, generades canviant els SGT. El nostre mètode evalua la similitud en les probabilitats de frases (a través de models de llenguatge pré-entrenats) entre els contrafets, per tractar els SGT igualment només en contextes intercanviables. Aplicant un parell de logits per igualar els resultats en el conjunt restringit de contrafets per cada cas, millorem les mètriques d'equitat mentre conservem el desempeny del model en la detecció del discurs d'odi.", 'cs': 'Přístupy ke zmírnění předpokladů snižují závislost modelů na citlivých vlastnostech dat, jako jsou tokeny sociálních skupin (SGT), což vede k rovným predikcím u citlivých vlastností. Při detekci nenávistné řeči však vyrovnávací modelové predikce mohou ignorovat důležité rozdíly mezi cílovými sociálními skupinami, protože nenávistná řeč může obsahovat stereotypní jazyk specifický pro každou SGT. Zde, abychom vzali v úvahu specifický jazyk o každé SGT, spoléháme na kontrafactickou spravedlnost a vyrovnáváme predikce mezi kontrafacticaly generované změnou SGT. Naše metoda hodnotí podobnost pravděpodobnosti vět (prostřednictvím předškolených jazykových modelů) mezi kontrafakty, aby se SGT zacházelo stejně pouze v zaměnitelných kontextech. Použitím párování logitů pro vyrovnání výsledků omezené sady kontrafaktů pro každou instanci zlepšujeme metriky férovosti a zároveň zachováme výkon modelu při detekci nenávistné řeči.', 'bn': 'সামাজিক গ্রুপের চিহ্ন (এসজিটি) মতো সংবেদনশীল বৈশিষ্ট্যের প্রতি মোডেলের উপর নির্ভর করা মোডেলের নির্ভর করার প্রতিক্রিয়া কমিয়ে দেয়া যায় কিন্তু ঘৃণা ভাষার আবিষ্কারে মোডেলের সমান ভবিষ্যদ্বাণী সমান হতে পারে লক্ষ্য করা সামাজিক গ্রুপের মধ্যে গুরুত্বপূর্ণ পার্থক্যের উপেক্ষা করতে পারে, কারণ ঘৃণা ভাষণ প্রত্যেক এসজিটির জন্য বিশেষ ভাষায় আমাদের পদ্ধতি শাস্তির সম্ভাবনার মাধ্যমে (পূর্ব প্রশিক্ষিত ভাষার মডেলের মাধ্যমে) বিরোধীদের মধ্যে একই ধরনের মানুষের মাধ্যমে মূল্য করে দেয়,  প্রত্যেক উদাহরণের জন্য সীমিত বিরোধীদলের ফলাফল সমান করার জন্য লগইন জোড়ার মাধ্যমে আমরা ন্যায়বিচারের মেট্রিক বৃদ্ধি প্রদান করি যখন ঘৃণা বাক্য সনাক্', 'et': 'Eelarvamuste leevendamise lähenemisviisid vähendavad mudelite sõltuvust andmete tundlikest omadustest, nagu sotsiaalsete gruppide tokenid (SGT), mille tulemusel on tundlike omaduste puhul võrdsed prognoosid. Vihakõne tuvastamisel võivad võrdsustavad mudeliprognoosid siiski ignoreerida olulisi erinevusi sihtrühmade vahel, sest vihakõne võib sisaldada stereotüüpilist keelt, mis on spetsiifilised iga SGT kohta. Võttes arvesse iga SGT konkreetset keelt, tugineme vastufaktuaalsele õiglusele ja võrdsustame vastufaktuaalsete prognooside vahel, mis tekivad SGT muutmisel. Meie meetod hindab lausetõenäosuste sarnasust (eelõpetatud keelemudelite kaudu) vastufaktide vahel, et kohelda SGT-sid võrdselt ainult vahetatavates kontekstides. Rakendades logiti paaridust tulemuste võrdsustamiseks piiratud vastufaktuaalide komplektis iga juhtumi puhul, parandame õigluse mõõdikuid, säilitades samal ajal mudeli jõudluse vihakõne tuvastamisel.', 'fi': 'Bias-lieventämismenetelmät vähentävät mallien riippuvuutta datan arkaluonteisista ominaisuuksista, kuten sosiaalisen ryhmän tunnuksista (SGT), mikä johtaa yhtäläisiin ennusteisiin kaikilla arkaluonteisilla ominaisuuksilla. Vihanpuheen havaitsemisessa mallinnusten tasaaminen saattaa kuitenkin jättää huomiotta tärkeät erot kohderyhmien välillä, sillä vihapuhe voi sisältää kullekin SGT:lle ominaista stereotyyppistä kieltä. Tässä yhteydessä luotamme vastakohtaiseen oikeudenmukaisuuteen ja tasaamme vastakohtaisten ennusteiden väliset ennusteet, jotka saadaan aikaan SGT:n muuttamisella. Menetelmämme arvioi lauseiden todennäköisyyden samankaltaisuutta (esikoulutettujen kielimallien avulla) vastakohtaisten faktojen välillä, jotta SGT:t voidaan kohdella tasavertaisesti vain vaihdettavissa olevissa yhteyksissä. Hyödyntämällä logit-paritusta tulosten tasaamiseksi rajoitetulla vastakohtajoukolla kussakin tapauksessa parannamme oikeudenmukaisuusmittareita säilyttäen samalla mallin suorituskyvyn vihapuheen havaitsemisessa.', 'ha': "Shiryarwa na Bias yana kusa ya ƙara bayani ga misãlai, yana dõgara kan masu sauki masu tsari, kamar alamomi na jamii (SGTs), kuma yana ƙara bayani masu daidaita a kowace zafi na gane. A lokacin da za'a gane magana na ƙeta, amma, misalin mai daidaita misalin ayuka za'a ƙyale masu muhimmi a tsakanin jama'a waɗanda aka yi goani, kamar da magana na ƙeta ya iya ƙunsa da harshen bakwai masu ƙayyade zuwa duk SGT. A nan, dõmin ka ɗauki lugha masu ƙayyade na SGT don a lissafa shi, za'a dõgara ga masu daidaita da ãdalci kuma mu daidaita wani basĩri a tsakanin filayenaiki, wanda aka zaɓe shi da musanya Tsarakanmu yana ƙayyade daidaita cikin muhimmada na cewa (da misalin misalin harshen da aka yi wa zaman-wa) daga cikin masu motsi, dõmin a yi amfani da SGTs daidai guda cikin muhimman masu iya canza. Ina amfani da shiryoyin ayuka da za'a daidaita matsala a kan tsari masu motsi wa kowace misali, za'a ƙara mitori da ãdalci a lokacin da za'a tsare misalin ayuka na ƙi.", 'sk': 'Pristopi za ublažitev pristranskosti zmanjšujejo odvisnost modelov od občutljivih značilnosti podatkov, kot so žetoni družbenih skupin (SGT), kar ima za posledico enake napovedi v vseh občutljivih značilnostih. Pri odkrivanju sovražnega govora pa lahko izenačevanje modelov napovedi ignorira pomembne razlike med ciljnimi družbenimi skupinami, saj lahko sovražni govor vsebuje stereotipni jezik, specifičen za vsak SGT. Za upoštevanje specifičnega jezika vsakega SGT se zanašamo na kontrafaktualno pravičnost in izenačimo napovedi med kontrafaktualnimi, ki jih ustvari sprememba SGT. Naša metoda ocenjuje podobnost verjetnosti stavkov (prek vnaprej usposobljenih jezikovnih modelov) med kontractualnimi dejstvi, da bi SGT obravnavali enako samo v izmenljivih kontekstih. Z uporabo logitnega združevanja za izenačevanje rezultatov na omejenem naboru nasprotnih dejstev za vsak primer izboljšamo meritve pravičnosti in hkrati ohranjamo zmogljivost modela pri zaznavanju sovražnega govora.', 'jv': 'Mbok ndheke nggunakake Nanging kapan langgar sapa nglanggar, iso nglanggar sapa SaGT ingkang, kita isih luwih apik ingkang dipun ajeng cara nggawe barang soko nggawe barang sampeyan. Awak dhéwé éntualisi perusahaan sampeyan kanggo langgar sapa-perusahaan (karo model ro-cara nggawe luwih bantuan) sak kontribusi layarané, iso nggawe NGT kuwi nggawe barang langgar an cah-cah dumaten. Ngawe ngubah sistem logik nggawe alih dumadhi iki banget nggawe perusahaan sistem sing gak perusahaan, awak dhéwé kuwi tindakan kuwi dianggap perusahaan maneh sing nyimpen modèl', 'bo': "Bias mitigation approaches reduce models' dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. In hate speech detection, however, equalizing model predictions may ignore important differences among targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs. ང་ཚོའི་ཐབས་ལམ་ལྟར་ཚིག དཔེར་ན་རེ་རེའི་ནང་དུ་མིག", 'he': 'הגישויים למאטה של סביבה מפחידות תלויות של דוגמנים על תכונות רגישות של נתונים, כמו סימני קבוצה חברתית (SGTs), מה שמוביל בציפויים שווים ברחבי המתכונות הרגישות. In hate speech detection, however, equalizing model predictions may ignore important differences among targeted social groups, as hate speech can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs.  Our method evaluates the similarity in sentence likelihoods (via pre-trained language models) among counterfactuals, to treat SGTs equally only within interchangeable contexts.  על ידי שימוש בזוג לוגיט כדי לשוות תוצאות על קבוצת המגבלת של חומרים נגד עובדות לכל דוגמה, אנחנו משתפרים מטריות הוגנות בזמן שמירה מודל ביצועים על זיהוי נאום שנאה.'}
{'en': 'Context Sensitivity Estimation in Toxicity Detection', 'fr': 'Estimation de la sensibilité au contexte lors de la détection', 'ar': 'تقدير حساسية السياق في كشف السمية', 'pt': 'Estimativa de Sensibilidade ao Contexto na Detecção de Toxicidade', 'es': 'Estimación de la sensibilidad al contexto en la detección', 'ja': '毒性検出におけるコンテキスト感度の推定', 'zh': '毒性检中上下文灵敏度度', 'hi': 'विषाक्तता का पता लगाने में संदर्भ संवेदनशीलता अनुमान', 'ru': 'Оценка контекстной чувствительности при определении токсичности', 'ga': 'Meastachán Íogaireachta Comhthéacs maidir le Tocsaineacht a Bhrath', 'hu': 'Kontextusérzékenység becslése a toxicitás kimutatásában', 'el': 'Εκτίμηση ευαισθησίας περιβάλλοντος στην ανίχνευση τοξικότητας', 'it': 'Stima della sensibilità contestuale nella rilevazione di tossicità', 'kk': 'Контексті сезімділік теңдеу', 'lt': 'Konteksto jautrumo toksiškumo nustatymo vertinimas', 'ms': 'Pengiraan Sensitiviti Konteks dalam Pengesanan Toksiti', 'mk': 'Проценка на чувствителност на контекст во детекцијата на токсичност', 'mt': 'Stima tas-Sensittività fil-Kuntest fid-Detezzjoni tat-Tossiċità', 'mn': 'Тохиромжтой байдлын мэдрэмжтэй байдлын тооцоолол', 'ka': 'კონტექსტის სინტექსტივის განსაზღვრება ტექსტიკური განსაზღვრებაში', 'ml': 'ടോക്സിക്സിക്സിറ്റി ഡിറ്റിക്റ്റനിറ്റിയിലുള്ള സെന്\u200dസിറ്റിവിറ്റി', 'no': 'Kontekstfølselsestimaen i toksikitet', 'ro': 'Estimarea sensibilității contextului în detectarea toxicității', 'si': 'සම්බන්ධ සංවේදනය අනුමාණය විශ්වාස කරන්න', 'pl': 'Szacowanie wrażliwości kontekstu w wykrywaniu toksyczności', 'so': 'Xisaameynta xiriirka', 'sv': 'Uppskattning av kontextkänslighet vid detektering av toxicitet', 'ta': 'தொடர்பு கண்டுபிடிப்பில் உள்ள உணர்வு', 'ur': 'ٹوکسیسیتی آشنائی میں کنٹکسٹ سنسیٹیویٹ کا ارزش', 'sr': 'Oèekivanje osjetljivosti konteksta u otkrivanju toksičnosti', 'uz': 'Comment', 'vi': 'Tình trạng hiện trường', 'bg': 'Контекст Оценка на чувствителността при откриването на токсичност', 'nl': 'Context Sensitiviteitsschatting bij toxiciteitsdetectie', 'hr': 'Procjena osjetljivosti konteksta u otkrivanju toksičnosti', 'da': 'Kontekstfølsomhedsvurdering ved toksicitetspåvisning', 'de': 'KontextsensitivitĂ¤tsschĂ¤tzung bei der ToxizitĂ¤tserkennung', 'fa': 'ارزیابی احساسات محیط در بازرسی توکسیسیتی', 'ko': '독성 검출 중의 환경 민감성 예측', 'sw': 'Hesabu ya Uhisia wa Nchini Kutambua Ukosuko', 'tr': '_Mazmunlar', 'id': 'Perkiraan Sensitivitas Konteks dalam Deteksi Toksitas', 'sq': 'Vlerësimi i ndjeshmërisë së kontekstit në zbulimin e toksicitetit', 'af': 'Konteks Sensitiviteit Estimasie in Toxicity Detection', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'hy': 'Տոքսիվության հայտնաբերման կոնտեքստի զգացմունքի գնահատումը', 'bn': 'সংক্রান্ত সংক্রান্ত সংক্রান্ত সংক্রান্ত গণনা', 'ca': 'Estimat de sensibilitat al context en la detecció de toxicitat', 'bs': 'Procjena osjetljivosti konteksta u otkrivanju toksičnosti', 'az': 'Toxicity Detection', 'cs': 'Odhad citlivosti v kontextu v detekci toxicity', 'et': 'Tundlikkuse hindamine toksilisuse tuvastamisel', 'fi': 'Konteksti Herkkyyden arviointi myrkyllisyyden havaitsemisessa', 'jv': 'drawable-action', 'ha': 'KCharselect unicode block name', 'he': 'הערכת רגישות הקשר בזיהוי רעילות', 'sk': 'Ocena občutljivosti pri odkrivanju strupenosti', 'bo': 'ཚོར་བ་སྐྱེལ་དང་ཁོར་ཡུག་ལ་མཚོན་རྐྱེན་ཚོར་མཁན་'}
{'en': 'User posts whose perceived toxicity depends on the ', 'ar': 'منشورات المستخدم التي تعتمد سميتها المتصورة على سياق المحادثة نادرة في مجموعات بيانات الكشف عن السمية الحالية. ومن ثم ، فإن أجهزة الكشف عن السمية المدربة على مجموعات البيانات الحالية ستتجاهل أيضًا السياق ، مما يجعل اكتشاف السمية الحساسة للسياق أكثر صعوبة عند حدوثها. أنشأنا وأصدرنا مجموعة بيانات من 10 آلاف مشاركة مع نوعين من ملصقات السمية لكل مشاركة ، تم الحصول عليها من المعلقين الذين اعتبروا (1) كل من المنشور الحالي والسابق كسياق ، أو (2) المنشور الحالي فقط. نقدم مهمة جديدة ، تقدير حساسية السياق ، والتي تهدف إلى تحديد المشاركات التي تتغير سُميتها المتصورة إذا تم أيضًا مراعاة السياق (المنشور السابق). باستخدام مجموعة البيانات الجديدة ، نوضح أنه يمكن تطوير الأنظمة لهذه المهمة. يمكن استخدام هذه الأنظمة لتعزيز مجموعات بيانات الكشف عن السمية بمزيد من المنشورات التي تعتمد على السياق أو لاقتراح الوقت الذي يجب أن يأخذ فيه الوسطاء في الاعتبار المنشورات الرئيسية ، والتي قد لا تكون ضرورية دائمًا وقد تؤدي إلى تكاليف إضافية.', 'es': 'Las publicaciones de usuarios cuya toxicidad percibida depende del contexto conversacional son poco frecuentes en los conjuntos de datos de detección de toxicidad actuales. Por lo tanto, los detectores de toxicidad entrenados en los conjuntos de datos actuales también ignorarán el contexto, haciendo que la detección de toxicidad sensible al contexto sea mucho más difícil cuando se produce. Construimos y publicamos un conjunto de datos de 10.000 publicaciones con dos tipos de etiquetas de toxicidad por publicación, obtenidas de anotadores que consideraron (i) tanto la publicación actual como la anterior como contexto, o (ii) solo la publicación actual. Presentamos una nueva tarea, la estimación de la sensibilidad al contexto, que tiene como objetivo identificar publicaciones cuya toxicidad percibida cambia si también se considera el contexto (publicación anterior). Con el nuevo conjunto de datos, mostramos que se pueden desarrollar sistemas para esta tarea. Estos sistemas podrían usarse para mejorar los conjuntos de datos de detección de toxicidad con publicaciones más dependientes del contexto o para sugerir cuándo los moderadores deben considerar las publicaciones principales, lo que puede no siempre ser necesario y puede introducir costos adicionales.', 'pt': 'As postagens de usuários cuja toxicidade percebida depende do contexto de conversação são raras nos conjuntos de dados atuais de detecção de toxicidade. Portanto, detectores de toxicidade treinados em conjuntos de dados atuais também desconsideram o contexto, tornando a detecção de toxicidade sensível ao contexto muito mais difícil quando ocorre. Construímos e divulgamos publicamente um conjunto de dados de 10 mil posts com dois tipos de rótulos de toxicidade por post, obtidos de anotadores que consideraram (i) tanto o post atual quanto o anterior como contexto, ou (ii) apenas o post atual. Introduzimos uma nova tarefa, estimativa de sensibilidade ao contexto, que visa identificar postagens cuja toxicidade percebida muda se o contexto (post anterior) também for considerado. Usando o novo conjunto de dados, mostramos que sistemas podem ser desenvolvidos para esta tarefa. Esses sistemas podem ser usados para aprimorar conjuntos de dados de detecção de toxicidade com postagens mais dependentes do contexto ou para sugerir quando os moderadores devem considerar as postagens principais, o que pode nem sempre ser necessário e pode introduzir custos adicionais.', 'fr': "Les publications d'utilisateurs dont la toxicité perçue dépend du contexte conversationnel sont rares dans les ensembles de données actuels sur la détection de la toxicité. Par conséquent, les détecteurs de toxicité formés sur les ensembles de données actuels ne tiendront pas compte du contexte, ce qui rendra la détection d'une toxicité sensible au contexte beaucoup plus difficile lorsqu'elle se produit. Nous avons construit et publié un ensemble de données de 10 000 publications avec deux types d'étiquettes de toxicité par publication, obtenues auprès d'annotateurs qui ont considéré (i) à la fois la publication actuelle et la publication précédente comme contexte, ou (ii) uniquement la publication actuelle. Nous introduisons une nouvelle tâche, l'estimation de sensibilité au contexte, qui vise à identifier les publications dont la toxicité perçue change si le contexte (article précédent) est également pris en compte. À l'aide du nouveau jeu de données, nous montrons que des systèmes peuvent être développés pour cette tâche. De tels systèmes pourraient être utilisés pour améliorer les ensembles de données de détection de la toxicité avec des publications plus dépendantes du contexte ou pour suggérer quand les modérateurs devraient prendre en compte les publications parentes, ce qui n'est pas toujours nécessaire et peut entraîner des coûts supplémentaires.", 'ja': '毒性の感知が会話の文脈に依存するユーザー投稿は、現在の毒性検出データセットではまれです。したがって、現在のデータセットでトレーニングされた毒性検出器もコンテキストを無視して、コンテキストに依存した毒性の検出が発生したときに非常に困難になります。（ ｉ ）現在の投稿と以前の投稿の両方を文脈として考慮した注釈者から、または（ ｉ ｉ ）現在の投稿のみを考慮した注釈者から入手した、投稿ごとに２種類の毒性ラベルを有する１ ０ ｋの投稿のデータセットを構築し、公開した。文脈依存性推定という新しいタスクを導入し、文脈（前の投稿）も考慮すると、知覚毒性が変化する投稿を特定することを目的としています。新しいデータセットを使用して、このタスクのためにシステムを開発できることを示します。このようなシステムは、より文脈依存的な投稿で毒性検出データセットを強化するために、またはモデレーターがいつ親投稿を検討すべきかを提案するために使用することができ、親投稿は常に必要ではなく、追加のコストをもたらす可能性がある。', 'hi': 'उपयोगकर्ता पोस्ट जिनकी कथित विषाक्तता संवादात्मक संदर्भ पर निर्भर करती है, वर्तमान विषाक्तता का पता लगाने वाले डेटासेट में दुर्लभ हैं। इसलिए, वर्तमान डेटासेट पर प्रशिक्षित विषाक्तता डिटेक्टर भी संदर्भ की उपेक्षा करेंगे, जिससे संदर्भ-संवेदनशील विषाक्तता का पता लगाना बहुत कठिन हो जाता है जब यह होता है। हमने प्रति पोस्ट दो प्रकार के विषाक्तता लेबल के साथ 10k पदों के डेटासेट का निर्माण और सार्वजनिक रूप से जारी किया, जो एनोटेटरों से प्राप्त किया गया था, जिन्होंने (i) वर्तमान पोस्ट और पिछले एक को संदर्भ के रूप में माना था, या (ii) केवल वर्तमान पोस्ट। हम एक नया कार्य, संदर्भ-संवेदनशीलता अनुमान पेश करते हैं, जिसका उद्देश्य उन पदों की पहचान करना है जिनकी कथित विषाक्तता बदलजाती है यदि संदर्भ (पिछली पोस्ट) पर भी विचार किया जाता है। नए डेटासेट का उपयोग करके, हम दिखाते हैं कि इस कार्य के लिए सिस्टम विकसित किए जा सकते हैं। इस तरह की प्रणालियों का उपयोग अधिक संदर्भ-निर्भर पदों के साथ विषाक्तता का पता लगाने वाले डेटासेट को बढ़ाने के लिए किया जा सकता है या यह सुझाव देने के लिए कि मॉडरेटरों को माता-पिता के पदों पर कब विचार करना चाहिए, जो हमेशा आवश्यक नहीं हो सकते हैं और अतिरिक्त लागत पेश कर सकते हैं।', 'ru': 'Публикации пользователей, воспринимаемая токсичность которых зависит от разговорного контекста, редко встречаются в текущих наборах данных по обнаружению токсичности. Следовательно, детекторы токсичности, обученные на текущих наборах данных, также будут игнорировать контекст, что значительно усложняет обнаружение чувствительной к контексту токсичности, когда она возникает. Мы создали и публично выпустили набор данных из 10 тысяч сообщений с двумя видами меток токсичности на сообщение, полученных от аннотаторов, которые рассматривали (i) как текущую, так и предыдущую запись в качестве контекста, или (ii) только текущую запись. Мы вводим новую задачу, контекстно-чувствительную оценку, которая направлена на выявление постов, воспринимаемая токсичность которых изменяется, если также рассматривается контекст (предыдущий пост). Используя новый набор данных, мы показываем, что системы могут быть разработаны для этой задачи. Такие системы могли бы использоваться для совершенствования наборов данных об обнаружении токсичности с помощью более контекстуальных постов или для определения того, когда модераторы должны рассматривать родительские посты, что не всегда может быть необходимым и может повлечь за собой дополнительные расходы.', 'zh': '用户帖之感知毒性决于对话上下文,此在今之毒性检测数据集少。 是以数集上之毒检测器亦将略上下文,使上下文敏而检之益难。 构而显发10k帖数集,各有二毒,自注释者,虑(i)前帖与前一帖为背景,或(ii)仅为帖。 引入一新,即上下文敏感性度之,其志在思上下文(前帖)识其感知毒性变化之帖。 用新数据集,吾明可为开。 此系统可于增强毒性检测数据集,使有多上下文相关帖子,或建议主持人何时当思父帖子,或非常须,且有额外之费。', 'ga': 'Is annamh a bhíonn postálacha úsáideoirí a bhfuil a tocsaineacht braite ag brath ar an gcomhthéacs comhrá i dtacar sonraí braite tocsaineachta faoi láthair. Mar sin, ní dhéanfaidh brathadóirí tocsaineachta atá oilte ar thacair sonraí reatha neamhaird ar an gcomhthéacs, rud a fhágfaidh go mbeidh sé i bhfad níos deacra tocsaineacht atá íogair ó thaobh comhthéacs a bhrath nuair a tharlaíonn sé. Thógamar agus scaoileamar go poiblí tacar sonraí de 10k postáil le dhá chineál lipéad tocsaineachta in aghaidh an phoist, faighte ó na nótaíadóirí a mheas (i) an post reatha agus an post roimhe sin mar chomhthéacs, nó (ii) an post reatha amháin. Tugaimid isteach tasc nua, meastachán íogaireachta comhthéacs, a bhfuil sé mar aidhm aige poist a aithint a n-athraíonn a tocsaineacht braite má dhéantar an comhthéacs (an post roimhe seo) a mheas freisin. Ag baint úsáide as an tacar sonraí nua, léirímid gur féidir córais a fhorbairt don tasc seo. D’fhéadfaí córais den sórt sin a úsáid chun tacair sonraí braite tocsaineachta a fheabhsú le poist a bhraitheann níos mó ar an gcomhthéacs nó chun a mholadh cén uair ar cheart do mhodhnóirí breathnú ar na poist mháthairchuideachta, rud nach mbeadh riachtanach i gcónaí agus a d’fhéadfadh costais bhreise a thabhairt isteach.', 'el': 'Δημοσιεύσεις χρηστών των οποίων η αντιληπτή τοξικότητα εξαρτάται από το πλαίσιο συζήτησης είναι σπάνιες στα τρέχοντα σύνολα δεδομένων ανίχνευσης τοξικότητας. Ως εκ τούτου, οι ανιχνευτές τοξικότητας εκπαιδευμένοι σε τρέχοντα σύνολα δεδομένων θα αγνοήσουν επίσης το πλαίσιο, καθιστώντας την ανίχνευση τοξικότητας ευαίσθητης στο πλαίσιο πολύ πιο δύσκολη όταν συμβαίνει. Κατασκευάσαμε και δημοσιοποιήσαμε ένα σύνολο δεδομένων με δύο είδη ετικετών τοξικότητας ανά ανάρτηση, το οποίο λαμβάνεται από σχολιαστές που θεώρησαν (i) τόσο την τρέχουσα όσο και την προηγούμενη ως πλαίσιο, ή (ii) μόνο την τρέχουσα ανάρτηση. Εισάγουμε μια νέα εργασία, εκτίμηση ευαισθησίας περιβάλλοντος, η οποία στοχεύει στον εντοπισμό θέσεων των οποίων η αντιληπτή τοξικότητα αλλάζει αν ληφθεί υπόψη και το πλαίσιο (προηγούμενη ανάρτηση). Χρησιμοποιώντας το νέο σύνολο δεδομένων, δείχνουμε ότι μπορούν να αναπτυχθούν συστήματα για αυτό το έργο. Τέτοια συστήματα θα μπορούσαν να χρησιμοποιηθούν για την ενίσχυση των συνόλων δεδομένων ανίχνευσης τοξικότητας με θέσεις που εξαρτώνται περισσότερο από το περιβάλλον ή για να προτείνουν πότε οι συντονιστές θα πρέπει να εξετάσουν τις μητρικές θέσεις, κάτι που μπορεί να μην είναι πάντα απαραίτητο και μπορεί να επιφέρει πρόσθετο κόστος.', 'ka': 'მომხმარებელი პოსტი, რომლებიც აღმოჩნევა ტოქსიტები დაახლოდება შემდეგ კონტექსტური კონტექსტიდან, რომლებიც მიმდინარე ტოქსიტების განახლო ამიტომ, მიმდინარე მონაცემების კონტექსტის ტექსტიური განვიცემები უფრო რთული იქნება, როდესაც მოხდება კონტექსტიური ტექსტიური განვიცემება. ჩვენ შევქმნით და ადამიანურად გახსნა 10 k პოსტის მონაცემები, რომელიც ორი ტიპის ტოქსიტური ნიშანები პოსტის, რომელიც მიიღებული მონაცემებისგან, რომელიც ახლა მიმდინარე პოსტის და წინასწინასწინასწინ ჩვენ ახალი დავაყენებთ, კონტექსტის სიგრძნობის განსაზღვრება, რომელიც მინდა განსაზღვრება პოსტი, რომელიც მინდომა ტექსტიური ცვლილება თუ კონტექსტი (წინა პოსტი ახალი მონაცემების სეტის გამოყენება ჩვენ გამოჩვენებთ, რომ სისტემები ამ დავალებისთვის შეიძლება განვითარება. ასეთი სისტემები შეიძლება გამოყენება ტექსტიკური მონაცემების განახლებისთვის, რომელიც უფრო კონტექსტიკური მონაცემებით დაახლოებით, ან შესაძლებელია, როდესაც მოდერატორები უნდა იფიქრობს', 'it': 'I post degli utenti la cui tossicità percepita dipende dal contesto conversazionale sono rari negli attuali set di dati di rilevamento della tossicità. Pertanto, i rivelatori di tossicità formati sui set di dati attuali ignoreranno anche il contesto, rendendo molto più difficile la rilevazione di tossicità sensibile al contesto quando si verifica. Abbiamo costruito e pubblicato pubblicamente un dataset di 10k post con due tipi di etichette di tossicità per post, ottenute da commentatori che consideravano (i) sia il post attuale che quello precedente come contesto, o (ii) solo il post attuale. Introducemo un nuovo compito, la stima della sensibilità al contesto, che mira a identificare i post la cui tossicità percepita cambia se si considera anche il contesto (post precedente). Utilizzando il nuovo dataset, mostriamo che i sistemi possono essere sviluppati per questo compito. Tali sistemi potrebbero essere utilizzati per migliorare i set di dati di rilevamento della tossicità con post più dipendenti dal contesto o per suggerire quando i moderatori dovrebbero prendere in considerazione i post genitori, il che potrebbe non essere sempre necessario e potrebbe comportare costi aggiuntivi.', 'kk': 'Қолданыстағы токсичілікті табылған пайдаланушының жіберушілері қазіргі токсичілікті анықтау деректер қорларында тәуелді. Сондықтан, назардағы деректер қорларында бақылатын токситлық анықтаушылары қолданып, контексті сезімді токситлықты анықтауға мүмкіндік береді. Біз 10 км жіберілген деректер жиынын құрып, әрбір жіберілген жарлықтардың екі түрлі токситылық жарлықтарымен шығарып, қазіргі жіберілген (i) және алдыңғы жарлықтарды тек қазіргі жарлықтардан алған. Біз жаңа тапсырма, контекстік сезімділігін бағалап береміз. Бұл, егер контексті (алдыңғы тапсырма) сәйкес қаласаңыз, өзгертілген жарлықтарды анықтауға мақсатты. Жаңа деректер жиынын қолдану үшін жүйелер осы тапсырма үшін жасауға болады. Бұл жүйелер контексті тәуелді жіберілген деректер қорларын қарастыру үшін, немесе модераторлар әрқашанда қажет болмауы мүмкін, әрқашанда қажет болуы керек және қосымша бағаттарын таңдауға болады.', 'lt': 'User posts whose perceived toxicity depends on the conversational context are rare in current toxicity detection datasets.  Taigi dabartiniuose duomenų rinkiniuose parengti toksiškumo detektoriai taip pat neatsižvelgs į aplinkybes, todėl aplinkybei jautrio toksiškumo nustatymas bus daug sunkesnis. Sukūrėme ir vieša i paskelbėme 10k post ų duomenų rinkinį su dviejų rūši ų toksiškumo etiketėmis vienam postui, gautais iš annotatorių, kurie laiko i) dabartinį ir ankstesnį postus kontekstu, arba ii) tik dabartinį postą. Įdiegiame naują užduotį – jautrumo kontekstui vertinimą, kuriuo siekiama nustatyti pareigas, kurių pastebimas toksiškumas pasikeičia, jei taip pat atsižvelgiama į kontekstą (ankstesnį pareigas). Naudodami naują duomenų rinkinį, parodome, kad šioms užduotims galima sukurti sistemas. Tokios sistemos galėtų būti naudojamos toksiškumo nustatymo duomenų rinkiniams, kuriuose yra labiau priklausomų nuo aplinkybių, gerinti arba siūlyti, kada vidutinio lygio darbuotojai turėtų apsvarstyti pagrindines pareigas, o tai ne visada gali būti būtina ir gali sukelti papildomas išlaidas.', 'ms': 'Pos pengguna yang tersangka toksik bergantung pada konteks perbualan adalah jarang dalam set data pengesan toksik semasa. Oleh itu, pengesan toksiciti dilatih pada set data semasa juga akan mengabaikan konteks, membuat pengesan toksiciti sensitif konteks jauh lebih sukar bila ia berlaku. Kami bina dan terbuka secara umum set data 10k pos dengan dua jenis label toksik per pos, yang diperoleh dari pengarang yang mempertimbangkan (i) kedua-dua pos semasa dan yang sebelumnya sebagai konteks, atau (ii) hanya pos semasa. We introduce a new task, context-sensitivity estimation, which aims to identify posts whose perceived toxicity changes if the context (previous post) is also considered.  Dengan set data baru, kita menunjukkan bahawa sistem boleh dikembangkan untuk tugas ini. Sistem tersebut boleh digunakan untuk meningkatkan set data pengesan toksiciti dengan pos yang lebih bergantung pada konteks atau untuk menyarankan apabila moderator patut mempertimbangkan pos induk, yang mungkin tidak sentiasa diperlukan dan boleh memperkenalkan biaya tambahan.', 'mk': 'User posts whose perceived toxicity depends on the conversational context are rare in current toxicity detection datasets.  Затоа, детекторите за токсичност обучени на сегашните податоци, исто така, ќе го игнорираат контекстот, што ќе го направи детекторот на токсичност чувствителна контекст многу потешко кога ќе се случи. Конструиравме и јавно објавувавме податоци од 10 илјади постови со два вида токсични етикети за пост, добиени од анотаторите кои ги сметаа (i) и сегашниот и претходниот пост за контекст, или (ii) само сегашниот пост. Ние воведуваме нова задача, проценка на контекст-сензитивноста, која има за цел идентификување на места чија перцепирана токсичност се менува ако се разгледува и контекст (претходно место). Користејќи го новиот компјутер на податоци, покажуваме дека системите може да се развијат за оваа задача. Таквите системи би можеле да се користат за зголемување на податоците за детекција на токсичност со поголеми контекстни зависни места или за да се предложи кога модераторите треба да ги разгледуваат родителните места, што можеби не секогаш е потребно и може да воведат дополнителни трошоци.', 'mn': 'Хэрэглэгчийн хувьд тохиромжтой байдал нь орчин үед тохиромжтой мэдээллийн санд ховор байдаг. Тиймээс одоогийн өгөгдлийн санд сургалтын хохирол тогтоогчид нөхцөл байдлыг ч анхаарлаа хандуулж, нөхцөл байдлын мэдрэмжтэй хохирол байдлыг илүү хэцүү болгодог. Бид 10 кг захидалын өгөгдлийн хэлбэрийг нэг захидалд хоёр төрлийн шинж тэмдэглэл бүтээсэн бөгөөд олон нийтэд гаргасан. Одоогийн захидал болон өмнөх захидал нь хоёр төрлийн шинж тэмдэглэл, эсвэл i i) зөвхөн одоогийн захидал гэж үздэг Бид шинэ үйл ажиллагаа, нөхцөл сэтгэл мэдрэмжтэй тооцооллоо тайлбарлаж байна. Хэрвээ нөхцөл байдал (өмнөх үеийн дараа) нь өөрчлөгдсөн байвал тэдгээрийг тодорхойлж чадна. Шинэ өгөгдлийн хэлбэрийг ашиглан бид энэ ажлын тулд системүүд хөгжүүлж чадна гэдгийг харуулж байна. Эдгээр системүүд хохиромжтой байдлын мэдээллийн сангуудыг илүү хамааралтай байдлаар нэмэгдүүлэх боломжтой. Эцэг эхийн сангуудыг хэрэгжүүлэх боломжгүй, нэмэлт зардал тайлбарлах боломжтой.', 'hu': 'A jelenlegi toxicitási kimutatási adatkészletekben ritkák azok a felhasználói posztok, amelyek észlelt toxicitása a beszélgetési kontextustól függ. Ezért a jelenlegi adatkészletekre képzett toxicitási detektorok szintén figyelmen kívül hagyják a kontextust, ami sokkal nehezebbé teszi a kontextusérzékeny toxicitás kimutatását. 10 ezer bejegyzésből álló adatkészletet hoztunk létre és publikáltunk nyilvánosságra bejegyzésenként kétféle toxicitási címkével, amelyeket olyan kommentátoroktól kaptunk, akik (i) mind az aktuális bejegyzést, mind az előzőt kontextusnak tekintették, vagy (ii) csak az aktuális bejegyzést. Bevezetünk egy új feladatot, kontextusérzékenységi becslést, amelynek célja, hogy azonosítsuk azokat a posztokat, amelyeknek észlelt toxicitását a kontextus (korábbi poszt) is figyelembe vesszük. Az új adatkészlet segítségével megmutatjuk, hogy erre a feladatra rendszereket lehet fejleszteni. Ezek a rendszerek használhatók arra, hogy a toxicitást kimutató adatkészleteket a kontextusfüggő bejegyzésekkel javítsák, vagy javasolják, hogy a moderátoroknak mikor kellene figyelembe venniük az anyabejegyzéseket, ami esetleg nem mindig szükséges, és többletköltségekkel járhat.', 'ml': 'സംസാരിക്കുന്നതിനെ ആശ്രയിച്ചിരിക്കുന്ന ഉപയോക്താവിന്റെ പോസ്റ്റുകള്\u200d ഇപ്പോഴത്തെ ടോക്സിക്സിറ്റി ഡാറ അതുകൊണ്ട്, ഇപ്പോഴത്തെ ഡാറ്റാസറ്റുകളില്\u200d പരിശീലിക്കപ്പെട്ട ട ടിക്സിക്സിസ്റ്ററുകള്\u200d പരിശീലിക്കുന്നതിന്റെ കൂട്ടത്തില്\u200d ന നിലവിലുള്ള പോസ്റ്റുകളില്\u200d നിന്നും നിലവിലുള്ള പോസ്റ്റുകളില്\u200d നിന്നും പ്രസ്താവിക്കുന്നവരില്\u200d നിന്നും നിലവിലുള്ള പോസ്റ്റില്\u200d നിന്നും കിട്ട നാം ഒരു പുതിയ ജോലിയെ പരിചയപ്പെടുത്തുന്നു, കോണ്ടെക്സ്റ്റെന്\u200dസിസ്റ്റിവിഷയത്തിന്റെ ഗണന, അതിന്റെ ലക്ഷ്യം മനസ്സിലാക്കുന്ന പുതിയ ഡാറ്റാസെറ്റ് ഉപയോഗിച്ച്, ഈ ജോലിക്കായി സിസ്റ്റമുണ്ടാക്കാന്\u200d സാധിക്കുന്നു ഇതുപോലുള്ള സിസ്റ്റം കൂടുതല്\u200d കൂടുതല്\u200d സംസ്ഥാനങ്ങളുള്ള ഡാറ്റാസ്റ്റുകള്\u200d കൂടുതല്\u200d ആശ്രയിക്കാന്\u200d ഉപയോഗിക്കുന്നതാണ്, അല്ലെങ്കില്\u200d മാതാവിന്റെ പോ', 'pl': 'Posty użytkowników, których postrzegana toksyczność zależy od kontekstu konwersacji, są rzadkie w aktualnych zbiorach danych wykrywania toksyczności. Dlatego detektory toksyczności przeszkolone na bieżących zbiorach danych będą również ignorować kontekst, co sprawia, że wykrywanie toksyczności wrażliwej na kontekst jest znacznie trudniejsze, gdy wystąpi. Zbudowaliśmy i publicznie publikowaliśmy zestaw danych 10k postów z dwoma rodzajami etykiet toksyczności na post, uzyskany od adnotatorów, którzy uważali (i) zarówno bieżący, jak i poprzedni post za kontekst, lub (ii) tylko bieżący post. Wprowadzamy nowe zadanie, szacowanie kontekstowej wrażliwości, którego celem jest identyfikacja postów, których postrzegana toksyczność zmienia się w przypadku uwzględnienia kontekstu (poprzedni post). Korzystając z nowego zbioru danych pokazujemy, że do tego zadania można opracować systemy. Takie systemy mogłyby być wykorzystywane do zwiększenia zbiorów danych dotyczących wykrywania toksyczności o posty bardziej zależne od kontekstu lub do sugerowania, kiedy moderatorzy powinni rozważyć posty nadrzędne, co nie zawsze może być konieczne i może wiązać się z dodatkowymi kosztami.', 'mt': 'Postijiet tal-utenti li t-tossiċità perċepita tagħhom tiddependi fuq il-kuntest ta’ konverżjoni huma rari fis-settijiet ta’ dejta attwali dwar l-individwazzjoni tat-tossiċità. Għalhekk, id-detetturi ta’ tossiċit à mħarrġa fuq settijiet ta’ dejta attwali se jinjoraw ukoll il-kuntest, u b’hekk id-detezzjoni ta’ tossiċità sensittiva għall-kuntest issir aktar diffiċli meta sseħħ. Inbnejna u nħarġu pubblikament sett ta’ dejta ta’ 10k post b’żewġ tipi ta’ tikketti ta’ tossiċità għal kull post, miksuba minn annotaturi li kkunsidraw (i) kemm il-post attwali kif ukoll dak preċedenti bħala kuntest, jew (ii) il-post attwali biss. Aħna nintroduċu kompitu ġdid, stima tas-sensittività għall-kuntest, li għandu l-għan li jidentifika postijiet li t-tossiċità perċepita tagħhom tinbidel jekk jiġi kkunsidrat ukoll il-kuntest (post preċedenti). Bl-użu tas-sett tad-dejta l-ġdid, nuru li s-sistemi jistgħu jiġu żviluppati għal dan il-kompitu. Sistemi bħal dawn jistgħu jintużaw biex itejbu settijiet ta’ dejta dwar l-individwazzjoni tat-tossiċità b’postijiet aktar dipendenti fuq il-kuntest jew biex jissuġġerixxu meta l-moderaturi għandhom jikkunsidraw il-postijiet prinċipali, li mhux dejjem jistgħu jkunu meħtieġa u jistgħu jintroduċu spejjeż addizzjonali.', 'sr': 'Poštovanja korisnika čija je osećana toksičnost zavisi od konverzacionog konteksta rijetka su u sadašnjim setima datoteka otkrivanja toksičnosti. Zato će detektori toksičnosti obučeni na trenutnim podacima takođe odbaciti kontekst, čineći otkrivanje toksičnosti konteksta mnogo teže kada se dogodi. Izgradili smo i javno oslobodili kompleks podataka od 10 k postova sa dve vrste oznake toksičnosti po posto, dobiveni od annotatora koji su smatrali i sadašnjom postalom i prethodnom kao kontekst, ili ii) samo trenutnom postalom. Predstavljamo novi zadatak, procjenu osjetljivosti konteksta, koji je cilj da identifikuje postove čije se percepcija toksičnosti menja ako se smatra i kontekst (prethodna post). Koristeći novi set podataka, pokazujemo da se sistemi mogu razviti za ovaj zadatak. Takvi sistemi bi se mogli koristiti za poboljšanje datoteka otkrivanja toksičnosti sa više postova ovisnih o kontekstu ili da sugeriraju kada moderatori treba razmotriti roditeljske postove, koje ne mogu uvek biti potrebne i mogu predstaviti dodatne troškove.', 'so': 'Qoraayinka isticmaalayaasha xumaatooyinka la garto waxay ku xiran tahay xiriirka kala hadliddu waa yaraan yihiin macluumaadka baaritaanka isticmaalka. Taas darteed waxaa sidoo kale ka sii qalbi jabsada cadaaladda lagu tababariyey qoraalka macluumaadka la soconayo, taas oo aad u adag in lagu ogaado mukhaadaraadka, marka ay dhacdo. Waxaannu dhisnay oo si bayaan ah u dirnay 10k boostadood oo ay leeyihiin labo cayn oo ah calaamado toksiska, waxaana laga helay macaamilooyinka ka fiirsashada boostada joogta ah iyo qoraalkii hore, ama (i i) boostada haatan oo keliya. Waxaannu qabanaynaa shaqo cusub, qiimeynta kooxda, taas oo loogu talogaley in loo caddeeyo warqadaha ay ka bedeshay dhibaatada maandooriyaha, haddii la fiiriyo qoraalka (boostada hore). Using the new dataset, we show that systems can be developed for this task.  Sidoo kale waxaa loo isticmaali karaa in lagu kordhiyo kooxda macluumaadka baaritaanka maandooriyaha oo ku qoran warqado badan oo ku xiran, ama in lagu soo jeediyo marka ay dhaqdhaqaajiyayaashu ka fikiraan boostada waalidka, taas oo aan mar walba u baahnaan karin kharash dheeraad ah.', 'no': 'Brukarpostar som oppdaga toksisk avhengig av konvertasjonskonteksten er sjeldre i gjeldande toksiske oppdagingsdatasett. Derfor vil toksiske oppdagarar som trengte på gjeldande datasett også forstå konteksten, og gjer det vanskeleg å oppdaga kontekstsensitivt toksisk når det skjer. Vi konstruerer og publiserer ein dataset med 10 k postar med to typar toksiske etikettar per post, henta frå annotatorar som gjeld i) både den gjeldande posten og den førre som konteksten, eller ii) berre den gjeldande posten. Vi introduserer ein ny oppgåve, kontekstsensitiviteten, som mål å identifisera postar som oppfatta toksikitet endrar dersom konteksten (førre post) også er anslått. Bruk den nye dataset viser vi at systemet kan utvikla for denne oppgåva. Desse systema kan brukast for å forbetra databaser for å oppdaga toksikitet med meir kontekstavhengige postar eller for å foreslå når moderatorane skal vurdere dei foreldre postene, som kan ikkje alltid vera nødvendige og kan introdusera fleire kostnader.', 'ro': 'Postările utilizatorilor a căror toxicitate percepută depinde de contextul conversațional sunt rare în seturile de date actuale de detectare a toxicității. Prin urmare, detectorii de toxicitate instruiți pe seturile de date actuale vor ignora contextul, făcând detectarea toxicității sensibile la context mult mai dificilă atunci când apare. Am construit și publicat un set de date de 10k postări cu două tipuri de etichete de toxicitate per post, obținute de la adnotatori care au considerat (i) atât postul curent, cât și cel precedent ca context, sau (ii) doar postul curent. Introducem o nouă sarcină, estimarea contextului sensibilității, care vizează identificarea posturilor a căror toxicitate percepută se schimbă dacă contextul (post anterior) este luat în considerare. Folosind noul set de date, arătăm că sistemele pot fi dezvoltate pentru această sarcină. Astfel de sisteme ar putea fi utilizate pentru a îmbunătăți seturile de date privind detectarea toxicității cu posturi mai dependente de context sau pentru a sugera momentul în care moderatorii ar trebui să ia în considerare posturile mamă, ceea ce poate să nu fie întotdeauna necesar și ar putea genera costuri suplimentare.', 'si': 'ප්\u200dරයෝජකයා පොස්ට්ස්ට් විශ්වාසිතාවට අවශ්\u200dය වෙනුවෙන් ප්\u200dරයෝජකයේ ප්\u200dරයෝජකය විශ්වාසිතාවට ප්\u200dර ඉතින්, දැන් තොරතුරු සෙට්ටුවට ප්\u200dරධානය කරලා තියෙන විශ්වාසය පරීක්ෂක පරීක්ෂක පරීක්ෂක පරීක්ෂක පරීක්ෂක විශ්වාස අපි නිර්මාණය සහ ප්\u200dරකාශයෙන් 10 k පොස්ට්ස් වල දත්ත සෙට් එක්ක පොස්ට්ස් වලින් විශේෂතා ලේබල් දෙකක් තියෙනවා, පොස්ට්ස් වලින් විශේෂතා ලේබල් වල අපි අළුත් වැඩක්, සංවේදනය සම්බන්ධතාවක් අනුමාණය කරනවා, ඒකෙන් අදහස් කරනවා පොස්ට්ස් විදිහට පරීක්ෂා වෙනස් කරනවා කියල අපි අළුත් දත්ත සෙට් එක භාවිතා කරන්න, අපි පෙන්වන්නේ මේ වැඩ සඳහා පද්ධතිය ප්\u200dරවෘති කරන්න පුළ මෙම පද්ධතිය භාවිතා වෙන්න පුළුවන් විශේෂතාවක් හොයාගන්න දත්ත සෙට් විශ්වාස කරන්න, සම්බන්ධතාවක් විශේෂතාවක් වෙනුවෙන් නැති වි', 'ta': 'தற்போதைய புவியியல் கண்டுபிடிப்பு தகவல் அமைப்பில் குறைவாக இருக்கும் பேச்சு சார்ந்து இருக்கும் போது தெரி அதனால், தற்போதைய தகவல் அமைப்புகளில் பயிற்சியுள்ள துறை கண்டுபிடிப்பாளர்கள் சூழலைப் புறக்கணிக்கும், சூழல் உணர்வுடைய துன்பத்தை  நாங்கள் 10k புதிய குறிப்புகளை உருவாக்கி பொதுவாக வெளியிட்டோம், ஒவ்வொரு புதிய இரண்டு வகையான புதிய விளையாட்டுகளுடன், தற்போதைய அஞ்சலும் மற்றும் முந் நாம் ஒரு புதிய பணியை குறிப்பிடுகிறோம், சூழல் உணர்வுப் புரிய ஆய்வு, இது போன்ற புதிய குறிப்புகளை குறிப்பிடுகிறது, அதன் புதிய புதிய தரவுத்தளத்தை பயன்படுத்தி, இந்த பணிக்கான அமைப்புகள் உருவாக்கலாம் என்பதை நாம் காட்டுகிறோம். இத்தகைய அமைப்புகள் புவியியல் கண்டுபிடிப்பு தகவல் அமைப்புகளை அதிகரிக்க பயன்படுத்தலாம் மேலும் சூழல் சார்ந்த சார்ந்த புத்தகங்கள் அல்லது பெற்றோர் அஞ்சல', 'sv': 'Användarinlägg vars upplevda toxicitet beror på konversationssammanhanget är sällsynta i nuvarande datauppsättningar för toxicitetsdetektion. Därför kommer toxicitetsdetektorer utbildade på nuvarande datamängder också att bortse från sammanhang, vilket gör detektionen av kontextkänslig toxicitet mycket svårare när den inträffar. Vi har konstruerat och offentligt publicerat en datauppsättning med 10k inlägg med två typer av toxicitetsetiketter per inlägg, erhållna från kommentatorer som betraktade (i) både det aktuella och det föregående inlägget som sammanhang, eller (ii) endast det aktuella inlägget. Vi introducerar en ny uppgift, kontextsensitivitetsbedömning, som syftar till att identifiera inlägg vars upplevda toxicitet förändras om kontexten (tidigare inlägg) också beaktas. Med hjälp av den nya datauppsättningen visar vi att system kan utvecklas för denna uppgift. Sådana system skulle kunna användas för att förbättra datauppsättningar för detektering av toxicitet med mer sammanhangsberoende inlägg eller för att föreslå när moderatorer bör överväga moderinlägg, vilket kanske inte alltid är nödvändigt och kan medföra ytterligare kostnader.', 'ur': 'یوسٹر پوسٹ جن کی سمجھ کی جسمی محسوب ہوتی ہے اس کی نسبت کنٹنسیٹ پر کم ہے جو موجود سمیٹی ڈیٹ سٹ میں ہے. لہٰذا، موجود ڈاٹ سٹ پر آموزش کی جسمی ڈیٹ ڈیٹ سٹ میں جسمی ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈی ہم نے 10 ک پوسٹ کے ڈاٹ سٹ کو بنایا اور ظاہر طور پر آزاد کردیا تھا جو ہر پوسٹ میں دو قسم کی toxicity لابل کے ساتھ آزاد ہو گئی تھی، جو اپنا پوسٹ اور پہلے کو متوسط بنایا تھا، یا (i i) صرف اپنا پوسٹ سمجھا گیا تھا. ہم نے ایک نوی کام پیش کریں، کنٹنسیٹ-حساسیت کا ارزش، جس کا ارزش ہے پوسٹوں کو پہچان سکیں جن کی سمجھ کی جسم بدلتی ہے اگر (پہلے پوسٹ) بھی سمجھ لیا جائے۔ ہم نیا ڈاٹ سٹ کے استعمال کرتے ہیں، ہم دکھاتے ہیں کہ سیسٹم اس کام کے لئے توسعہ کر سکتے ہیں۔ ایسی سیستموں کا استعمال کیا جاتا ہے کہ کس سیستموں کو زیادہ کنٹنسیٹ منتظر پوسٹ کے ساتھ سمجھنے کے لئے ڈیٹسٹ ڈیٹسٹ مزید کریں یا جب مدرساتوروں کو ماں باپ پوسٹ کا نظر کرنا چاہیے، جو ہمیشہ ضرورت نہیں ہے اور اضافہ قیمت', 'uz': "Name Hence, toxicity detectors trained on current datasets will also disregard context, making the detection of context-sensitive toxicity a lot harder when it occurs.  Biz Joriy pochta va keyingi birinchi pochta deb o'ylab turgan taʼlumotlar tarkibini 10 km pochta bilan ochib chiqarishmiz va faqat joriy pochta sifatida o'ylab keladi. Biz yangi vazifa, context-sensitivity qiymatni anglatamiz. Bu maqsadlarni aniqlashga ega bo'ladi, agar xizmatning (oldingi post) ichida o'zgarishni anglatadi. @ info: whatsthis Bu tizimlarni koʻproq qoʻshish qoidalari bilan qo'shimcha tizimni aniqlash uchun foydalanish mumkin yoki moderatorlar foydalanishi kerak boʻlsa, buni doim kerak boʻlmasligi va qoʻshimcha qiymatlarni ishlatish mumkin.", 'vi': 'Người dùng có khả năng nhận thức độc tố phụ thuộc vào môi trường đối thoại rất hiếm trong các dữ liệu về nhiễm độc hiện thời. Do đó, các máy phát hiện độc tính được huấn luyện trên các bộ dữ liệu hiện tại cũng sẽ bỏ qua bối cảnh, làm việc phát hiện độc tố nhạy cảm với ngữ cảnh khó khăn hơn nhiều khi nó xảy ra. Chúng tôi đã xây dựng và công khai phát hành một tập tin chứa 10k với hai loại nhãn độc tố cho mỗi bưu đi ện, được lấy từ các nhà biên bản ghi chú, người đã xem cả bưu điện hiện thời và thư trước là ngữ cảnh, hoặc (II) chỉ là bưu điện hiện tại. Chúng tôi đưa ra một nhiệm vụ mới, đánh giá độ nhạy ngữ cảnh, nhằm mục đích xác định các vị trí có sự thay đổi độc tính nếu cả trường hợp trước cũng được xem xét. Sử dụng bộ dữ liệu mới, chúng tôi cho thấy có thể phát triển hệ thống cho nhiệm vụ này. Những hệ thống này có thể được dùng để tăng cường dữ liệu phát hiện độc tính với các trạm phụ thuộc hoàn cảnh nhiều hơn hoặc để gợi ý khi nào người điều khiển nên cân nhắc các trạm phụ huynh, mà có lẽ không phải luôn cần thiết và có thể gây thêm chi phí.', 'bg': 'Потребителски постове, чиято възприемана токсичност зависи от контекста на разговора, са редки в текущите набори от данни за откриване на токсичност. Следователно детекторите за токсичност, обучени върху текущите набори от данни, също ще пренебрегнат контекста, което прави откриването на чувствителна към контекста токсичност много по-трудно, когато тя се появи. Изградихме и публично пуснахме набор от данни от 10к публикации с два вида етикети за токсичност на публикация, получени от анотатори, които разглеждаха както текущата публикация, така и предишната като контекст, или само текущата публикация. Въвеждаме нова задача, оценка на чувствителността към контекста, която има за цел да идентифицира постове, чиято възприемана токсичност се променя, ако се вземе предвид и контекстът (предишна публикация). Използвайки новия набор от данни, ние показваме, че системи могат да бъдат разработени за тази задача. Такива системи биха могли да се използват за подобряване на наборите от данни за откриване на токсичност с публикации, които зависят от контекста, или за да се предположи кога модераторите следва да разгледат родителските публикации, което не винаги може да е необходимо и да доведе до допълнителни разходи.', 'da': 'Brugerindstillinger, hvis opfattede toksicitet afhænger af samtalekontakten, er sjældne i nuværende datasæt for toksicitetsdetektion. Derfor vil toksicitetsdetektorer, der er uddannet på nuværende datasæt, også ignorere konteksten, hvilket gør detektionen af kontekstfølsom toksicitet meget sværere, når den opstår. Vi konstruerede og offentliggør et datasæt på 10.000 indlæg med to typer toksicitetsmærker pr. indlæg, der er opnået fra kommentatorer, der betragtede (i) både det nuværende indlæg og det foregående som kontekst, eller (ii) kun det nuværende indlæg. Vi introducerer en ny opgave, kontekst-sensitivitet estimering, som har til formål at identificere indlæg, hvis opfattede toksicitet ændrer sig, hvis konteksten (tidligere indlæg) også tages i betragtning. Ved hjælp af det nye datasæt viser vi, at systemer kan udvikles til denne opgave. Sådanne systemer kunne anvendes til at forbedre datasæt vedrørende detektion af toksicitet med mere kontekstafhængige indlæg eller til at foreslå, hvornår moderatorer bør overveje moderindlæggene, hvilket muligvis ikke altid er nødvendigt og kan medføre yderligere omkostninger.', 'id': 'Pos pengguna yang dideteksi toksicitas tergantung pada konteks konversasi jarang dalam set data deteksi toksicitas saat ini. Oleh karena itu, detektor toksicitas dilatih pada set data saat ini juga akan mengabaikan konteks, membuat deteksi toksicitas sensitif konteks jauh lebih sulit ketika terjadi. Kami membangun dan publik melepaskan dataset 10k pos dengan dua jenis label toksicitas per pos, yang diperoleh dari annotator yang mempertimbangkan (i) kedua pos saat ini dan yang sebelumnya sebagai konteks, atau (ii) hanya pos saat ini. Kami memperkenalkan tugas baru, penilaian sensitivitas konteks, yang bertujuan untuk mengidentifikasi pos yang diduga toksicitas berubah jika konteks (pos sebelumnya) juga dianggap. Menggunakan set data baru, kami menunjukkan bahwa sistem dapat dikembangkan untuk tugas ini. Sistem seperti ini dapat digunakan untuk meningkatkan dataset deteksi toksicitas dengan lebih konteks tergantung pos atau untuk menyarankan kapan moderator harus mempertimbangkan pos induk, yang mungkin tidak selalu diperlukan dan dapat memperkenalkan biaya tambahan.', 'de': 'Benutzerbeiträge, deren wahrgenommene Toxizität vom Konversationskontext abhängt, sind in aktuellen Toxizitätsnachweisdatensätzen selten. Daher werden Toxizitätsdetektoren, die auf aktuellen Datensätzen trainiert sind, auch den Kontext ignorieren, was den Nachweis kontextsensitiver Toxizität erheblich erschwert, wenn sie auftritt. Wir haben einen Datensatz von 10k-Beiträgen mit zwei Arten von Toxizitätsetiketten pro Beitrag erstellt und veröffentlicht, der von Kommentatoren erhalten wurde, die (i) sowohl den aktuellen als auch den vorherigen Beitrag als Kontext betrachteten, oder (ii) nur den aktuellen Beitrag. Wir führen eine neue Aufgabe ein, die Kontextsensitivitätsschätzung, die darauf abzielt, Beiträge zu identifizieren, deren wahrgenommene Toxizität sich ändert, wenn auch der Kontext (vorheriger Beitrag) berücksichtigt wird. Anhand des neuen Datensatzes zeigen wir, dass für diese Aufgabe Systeme entwickelt werden können. Solche Systeme könnten verwendet werden, um Datensätze zur Toxizitätsnachweis mit kontextabhängigeren Beiträgen zu erweitern oder um vorzuschlagen, wann Moderatoren die übergeordneten Beiträge berücksichtigen sollten, was möglicherweise nicht immer notwendig ist und zusätzliche Kosten verursachen kann.', 'nl': 'Gebruikersberichten waarvan de waargenomen toxiciteit afhankelijk is van de gesprekscontext zijn zeldzaam in de huidige datasets van toxiciteitsdetectie. Daarom zullen toxiciteitsdetectoren die getraind zijn op huidige datasets ook context negeren, waardoor de detectie van contextgevoelige toxiciteit een stuk moeilijker wordt wanneer deze optreedt. We hebben een dataset gemaakt van 10k posts met twee soorten toxiciteitslabels per post, verkregen van annotatoren die (i) zowel het huidige als het vorige bericht als context beschouwden, of (ii) alleen het huidige bericht. We introduceren een nieuwe taak, contextgevoeligheidsschatting, die gericht is op het identificeren van posten waarvan de waargenomen toxiciteit verandert als de context (vorige post) ook wordt bekeken. Aan de hand van de nieuwe dataset laten we zien dat systemen voor deze taak ontwikkeld kunnen worden. Dergelijke systemen kunnen worden gebruikt om datasets voor toxiciteitsdetectie te verbeteren met meer contextafhankelijke berichten of om te suggereren wanneer moderators rekening moeten houden met de bovenliggende posten, wat misschien niet altijd noodzakelijk is en extra kosten kan opleveren.', 'ko': '현재의 독성 검출 데이터가 집중되어 있는데 그 감지 독성은 대화 상하문에 달려 있는 사용자 게시물이 매우 적다.따라서 현재 데이터 집합에서 훈련된 독성 검출기도 상하문을 소홀히 하여 상하문이 민감한 독성이 발생할 때의 검출이 더욱 어렵다.우리는 10k편의 글을 포함하는 데이터 집합을 구축하고 공개적으로 발표했다. 문장마다 두 가지 독성 라벨이 있는데, 이 라벨들은 주석자에서 나온 것이다. 그들은 (i) 현재 문장과 이전 문장이 모두 상하문이거나 (ii) 현재 문장만 있다고 생각한다.배경 민감도 평가를 도입했는데 배경(이전 게시물)을 동시에 고려하는 상황에서 독성 변화를 감지하는 게시물을 식별하는 것이 목적이다.새로운 데이터 집합을 사용하면, 우리는 이 임무를 위해 시스템을 개발할 수 있음을 나타낸다.이러한 시스템은 독성 검사 데이터 집합을 강화하여 더 많은 상하문과 관련된 게시물을 가지게 하거나, 게시자가 언제 부모의 게시물을 고려할 것인지를 건의할 수 있다. 이것은 항상 필요하지 않을 뿐만 아니라, 추가 비용을 가져올 수도 있다.', 'sw': 'Mtumiaji wa posti ambazo ukosefu wa kutosha unategemea muktadha wa mazungumzo ni nadra sana katika seti za taarifa za uchunguzi wa toksishaji za sasa. Kwa hiyo, watachunguza wakosoaji waliofundishwa kwenye seti za taarifa za sasa pia watapuuza muktadha, na kufanya kutambua vibaya vibaya vibaya wakati huo utatokea. Tumejenga na kuachia hadharani seti ya post i 10,000 zilizo na alama mbili za sumu kwa kila makala, zilizopatikana kutoka kwa watangazaji ambao walifikiri (mimi) makala ya sasa na makala iliyopita kama muktadha, au (ii) makala ya sasa pekee. Tunaweza kuanzisha kazi mpya, uchunguzi wa utambulisho wa mazingira, ambao unakusudia kutambua makala ambazo zile za kutambua mabadiliko ya ukosoaji wa vibaya kama muktadha (makala yaliyopita) pia inachukuliwa. Kwa kutumia seti mpya ya taarifa, tunaonyesha kwamba mifumo inaweza kutengeneza kwa kazi hii. Mfumo huu unaweza kutumika kuongeza taarifa za uchunguzi wa ukosefu wenye makala nyingine zinazotegemea mazingira au kupendekeza wakati wagombea wa kisasa wanapaswa kuangalia makala za wazazi, ambazo hazitahitajika mara zote na inaweza kutangaza gharama za ziada.', 'tr': 'Geditik gabdalyk alyp bilýän sahypalar häzirki toksik deteksiýasynda çalt däldir. Şol sebäpli, häzirki veri setirlerinde eğitilän toksiýet detekleri hem kontekst hasaplanyşyny çaklamak üçin has kyn bir toksiýeti ýok edip biler. Biz birnäçe görnüş 2 tür toksiýet etiketleri bilen 10k postyň veri setini we publika taýýarlapdyk, we edil häzirki görnüş we öňki görnüş diňe häzirki görnüş hasaplanýarlardan berilýäris. Ýöne (i i) diňe häzirki görnüş hasaplanýarlar. Biz täze bir täze zady, kontekst-duýdurlygyny hasaplamak bilen tanyşdyrýarys, meýdançasynyň özüni toksiýatlyk üýtgetmegini amaçlaýar. Täze maglumat setirini ullanýarys, sistemleriň bu zada üçin gelişmegi mümkin edip biljekdigini görkez. Bütin sistemler toksiýet deteksiýasyny köpräk daşarydaky postlar bilen gelişmek üçin ullanylşy bolar ýa-da moderatorlar ene-atasy postlary düşünmelidigini maslahat bermek üçin ullanylşy. Olar hemişe gerekli däl we köpüräk maslahat berilebilir.', 'hr': 'Poštovi korisnika čija je osjećena toksičnost ovisa o konverzacijskom kontekstu rijetki su u sadašnjim podacima otkrivanja toksičnosti. Stoga će detektori toksičnosti obučeni na trenutnim podacima također odbaciti kontekst, čineći otkrivanje toksičnosti konteksta mnogo teže kada se dogodi. Izgradili smo i javno oslobodili skup podataka od 10 k postova sa dvije vrste oznake toksičnosti po posto, dobivenih od annotatora koji su smatrali i sadašnjom postalom i prethodnom kao kontekst, ili ii) samo trenutnom postalom. Predstavljamo novi zadatak, procjenu osjetljivosti konteksta, koji je cilj identificirati postove čije se percepcija toksičnosti mijenja ako se smatra i kontekst (prethodna post). Koristeći novi set podataka, pokazujemo da se sustavi mogu razviti za ovaj zadatak. Takvi sustavi bi se mogli koristiti za poboljšanje datoteka otkrivanja toksičnosti s više mjesta ovisnosti o kontekstu ili predložiti kada bi moderatori trebali razmotriti roditeljske položaje, koje ne mogu uvijek biti potrebne i mogu predstaviti dodatne troškove.', 'af': "Gebruikerposte waarvan gevaardige toksiciteit afhang van die omskakelingskonteks is rare in huidige toksiciteit beskikking datastelle. Daarom sal toxisiteitsdetektors wat op huidige datastelle onderwerp is, ook onderwerp konteks, maak die opspoor van konteks-sensitiewe toksiteit 'n baie harder wanneer dit voorkom. Ons het 'n datastel van 10k pos gebou en openlik verlos met twee soorte toksikiteit etikette per pos, verkry van annotators wat beskou (i) beide die huidige pos en die vorige een as konteks, of (ii) slegs die huidige pos. Ons introduseer 'n nuwe taak, context-sensitiviteit-estimatie, wat doel om pos te identifiseer wie se aangeneem toksiteit verander as die konteks (vorige post) ook aangeneem word. By gebruik van die nuwe datastel, wys ons dat stelsels vir hierdie taak ontwikkeld kan word. Hierdie stelsels kan gebruik word om toxisiteit-beskrywing datastelle met meer kontekstafhangende pos te verbeter of om te voorstel wanneer moderators die ouer-pos te beskou, wat dalk mag nie altyd nodig wees en dalk dalk koste te introduseer.", 'fa': 'نامه\u200cهای کاربر که سمی شناخته شده\u200cاش بستگی دارد از محیط تبدیل در مجموعه\u200cهای داده\u200cهای شناسایی سمی فعلی نادر است. بنابراین، کارآگاه\u200cکننده\u200cهای سمی که روی مجموعه\u200cهای داده\u200cهای جاری آموزش داده شده\u200cاند، همچنین کنترل را نادیده می\u200cگیرند، و وقتی اتفاق می\u200cافتد، کشف سمی حساس\u200cهای محیط بسیار سخت\u200cتر می\u200cکند. ما یک مجموعه اطلاعات ۱۰ کیلومتر با دو نوع نقاشی سمی در یک پست ساختیم و عمومی آزاد کردیم، که از نقاشی که (i) نقاشی فعلی و نخستین را به عنوان محیط و (ii) تنها نقاشی فعلی می\u200cبینند. ما یک کار جدید را معرفی می\u200cکنیم، ارزیابی احساسات محیط، که هدف می\u200cگیرد جایگانی را شناسایی کند که اگر محیط (پست قبلی) همچنین تغییر می\u200cکند. با استفاده از مجموعه داده\u200cهای جدید، نشان می\u200cدهیم که سیستم\u200cها برای این کار می\u200cتوانند توسعه دهند. این سیستم\u200cها می\u200cتوانند برای افزایش داده\u200cهای شناسایی سمی با پوست\u200cهای بستگی بیشتری یا پیشنهاد کنند زمانی که مدیراتورها باید پوست\u200cهای پدر و مادر را در نظر بگیرند، که ممکن است همیشه لازم نیست و ممکن است هزینه\u200cهای بیشتری را معرفی کند.', 'hy': 'Օգտագործողների տեղադրությունները, որոնց թունավորությունը կախված է խոսակցական կոնտեքստից, հազվադեպ են ներկայիս թունավորության հայտնաբերման տվյալների համակարգերում: Այդ իսկ պատճառով, ներկայիս տվյալների համակարգերի վրա սովորեցված թունավոր դետեկտորները նույնպես կանտեսեն կոնտեքստը, ինչը կդարձնի կոնտեքստին զգալի թունավոր դետեկտորների հայտնաբերումը շատ ավելի դժվար, երբ We constructed and publicly release a dataset of 10k posts with two kinds of toxicity labels per post, obtained from annotators who considered (i) both the current post and the previous one as context, or (ii) only the current post.  Մենք ներկայացնում ենք նոր խնդիր, կոնտեքստի զգացմունքի գնահատականներ, որոնց նպատակն է հայտնաբերել տեղեր, որոնց ընկած թունավորությունը փոխվում է, եթե նաև հաշվի առնենք կոնտեքստը (նախորդ տեղը): Օգտագործելով նոր տվյալների համակարգը, մենք ցույց ենք տալիս, որ համակարգերը կարող են զարգանալ այս խնդրի համար: Այսպիսի համակարգեր կարող են օգտագործվել թունավորության հայտնաբերման տվյալների համակարգերի բարելավման համար, որոնք ավելի կախված են կոնտեքստից, կամ առաջարկելու համար, թե երբ են մոդերատորները պետք է հաշվի առնեն ծնողների աշխատանքները, ինչը միշտ կարող է լինել անհր', 'am': 'በተጠቃሚ ጽሑፎች የስክስቲክነት በንግግር ግንኙነት ላይ የሚታመካ የአሁኑ የስክስቲካ ዳታዎችን ማግኘት ጥቂት ነው፡፡ ስለዚህም በአሁኑ ዳታ ማዕከላዎች ላይ የተማሩ የጥምቀት መግለጫ ተቃውሞ ትክክለኛለች፡፡ የአሁኑን ደብዳቤ እና የቀድሞውን ደብዳቤ እና የአሁኑን ደብዳቤ እና የአሁኑን ደብዳቤ በኩል፣ (i i) ብቻ የአሁኑን ደብዳቤ ከሚያሰቡት ሰዎች የሁለት ዓይነት የጥቅረት ምልክቶች እና የአሁኑን ደብዳቤዎች አቀረብን፡፡ አዲስ ስራ፣ የግንኙነት ግንኙነት ማውጣት እናስገድዳለን፡፡ አዲስ የዳታ ሳጥን በመጠቀም ሲስተም ለዚህ ስራ መግለጫ እንዲችል እናሳየዋለን፡፡ እንደዚህ ስርዓቶች ሁልጊዜ ያስፈልጋል፣ የጥምቀት ማግኘት እና አብዛኛዎቹ የጽሑፎች በመታሰሪያ ወይም ማግኘት የሚያስፈልጋቸው የአባቶች ደብዳቤዎችን ማሳየት እንዲችሉ ይችላል፡፡', 'az': 'İstifadəçi məlumatları, haqqında zehirli tanıdıqları məlumatların dəyişdirilməsi üçün dəyişiklik məlumatlarına bağlı olur. Beləliklə, günümüzdeki verilən qurbanlarda təhsil edilən təhsil detektörləri də təhsil edilməyəcək, məlumatların təhsil hisslərinin keşfetməsini daha zorlaşdıracaq. Biz hər postada iki növ toxicit etiketi olan 10 k postu verilən və a çıq-aşkar bir dəyişiklik setini təhsil etdik. Növbəti məlumat və əvvəlki məlumat kimi və ya i i) sadəcə ağımdaki məlumat hesab edənlərdən alındı. Biz yeni bir iş, context-sensitivity təcrübəsini təşkil edirik, ki, əgər məsələn (əvvəlki post) təcrübəsini təşkil edilsə, təcrübəsini təşkil etmək istəyirik. Yeni verilən qurğu istifadə edirək, sistemlərin bu işin üçün təhsil edilə biləcəyini göstəririk. Bütün sistemlər, daha çox kontekst bağlılıqları məlumatları ilə toxicit keşfetməsi üçün istifadə edilə bilər və ya moderatorlar ata-anası məlumatlarını düşünməli və həmişə ehtiyacı olmayan və əlavə malik məlumatları təyin edə bilərlər.', 'bn': 'ব্যবহারকারীর পোস্ট পোস্ট করেছে যাদের দেখা যাচ্ছে ব্যাক্তিগত বিষয়টির উপর নির্ভর করে বর্তমান ব্যাক্সিকি ডাটাট তাই বর্তমান ডাটাসেটে প্রশিক্ষিত ব্যাক্সিক ডিটেক্টর প্রশিক্ষক প্রশিক্ষকদের প্রতিক্রিয়া উপেক্ষা করবে, যার ফলে প্রেক্ষাপট-সং আমরা ১০ কিছু পোস্ট নির্মাণ করেছি এবং প্রকাশ্যে প্রতিটি পোস্টে দুটি ধরনের ব্যস্ত ট্যাক্সিকি লেবেল নির্মাণ করেছি, যারা বর্তমান পোস্ট এবং পূর্ববর্তী প আমরা একটি নতুন কাজ, প্রেক্ষিত-সংবেদনশীল হিসেবে পরিচয় করিয়ে দেই, যার লক্ষ্য হচ্ছে পোস্ট যাদের দৃষ্টিভঙ্গি বিকার পরিবর্তন করা হয়েছে  নতুন ডাটাসেট ব্যবহার করে আমরা দেখাচ্ছি যে এই কাজের জন্য সিস্টেম উন্নয়ন করতে পারে। এই ধরনের সিস্টেম ব্যবহার করা যাবে বেশী কন্টেক্সট- নির্ভরিত পোস্টের সাথে ব্যবহার করে ব্যবহার করে ব্যবহার করা যায় অথবা পরামর্শ দিতে পারে কোন আধুনিক পোস্ট ব', 'ca': "Els posts d'usuari que la toxicitat perceptiva depèn del context conversacional són rars en els conjunts de dades actuals de detecció de toxicitat. Per tant, els detectors de toxicitat entrenats en conjunts de dades actuals també ignoraran el context, fent la detecció de toxicitat sensible al context molt més difícil quan apareix. Vam construir i publicar un conjunt de dades de 10k posts amb dues tipus de etiquetes de toxicitat per post, obtenides d'anotators que consideraven (i) tant el post actual com el anterior com el context, o (ii) només el post actual. Introduïm una nova tasca, estimació de la sensibilitat al contexte, que mira a identificar llocs que canvien la toxicitat perceptiva si també es considera el context (post anterior). Utilitzant el nou conjunt de dades, demostram que els sistemes es poden desenvolupar per a aquesta tasca. Aquests sistemes podrien ser utilitzats per millorar els conjunts de dades de detecció de toxicitat amb postes més dependients del context o per suggerir quan els moderadors haurien de considerar els postes padres, cosa que potser no sempre és necessària i pot introduir costos adicionals.", 'sq': 'Postat e përdoruesve toksiciteti i të cilave varet nga konteksti bisedimor janë të rralla në të dhënat aktuale për zbulimin e toksicitetit. Kështu që detektorët e toksicitetit të trajnuar në të dhënat aktuale do të injorojnë gjithashtu kontekstin, duke bërë zbulimin e toksicitetit të ndjeshëm në kontekst shumë më të vështirë kur ndodh. Ne ndërtuam dhe publikisht lëshojmë një grup të dhënash prej 10k post ësh me dy lloje etiketash toksike për post, të marrë nga anotatorët që konsideronin (i) si postën aktuale dhe të mëparshmen si kontekst, apo (ii) vetëm postën aktuale. Ne futim një detyrë të re, vlerësim të ndjeshmërisë së kontekstit, e cila synon të identifikojë postin e të cilit ndryshon toksiciteti i perceptuar nëse konsiderohet gjithashtu konteksti (posti i mëparshëm). Duke përdorur grupin e të dhënave të reja, ne tregojmë se sistemet mund të zhvillohen për këtë detyrë. Sistemet e tilla mund të përdoren për të përmirësuar grupet e të dhënave për zbulimin e toksicitetit me poste më të varura nga konteksti ose për të sugjeruar kur moderatorët duhet të konsiderojnë postet prindërore, të cilat mund të mos jenë gjithmonë të nevojshme dhe mund të futin kosto shtesë.', 'cs': 'Uživatelské příspěvky, jejichž vnímaná toxicita závisí na kontextu konverzace, jsou v současných datových sadách detekce toxicity vzácné. Proto detektory toxicity trénované na současných datových sadách také ignorují kontext, což znamená, že detekce kontextově citlivé toxicity je mnohem těžší, když k ní dojde. Vytvořili jsme a veřejně zveřejňovali datovou sadu 10k příspěvků se dvěma druhy toxických štítků na příspěvek, získanou od anotátorů, kteří považovali (i) současný a předchozí příspěvek za kontext, nebo (ii) pouze aktuální příspěvek. Představujeme nový úkol, odhad kontextové citlivosti, jehož cílem je identifikovat příspěvky, jejichž vnímaná toxicita se mění, pokud je také kontext (předchozí příspěvek). Pomocí nového datového souboru ukazujeme, že pro tento úkol lze vyvinout systémy. Tyto systémy by mohly být použity k rozšíření souborů údajů o detekci toxicity o příspěvky závislé na kontextu nebo k navrhování, kdy by moderátoři měli zvážit nadřazené příspěvky, což nemusí být vždy nutné a může přinést další náklady.', 'bs': 'Poštovi korisnika čija percepcija toksičnosti ovisi o konverzacijskom kontekstu su rijetki u sadašnjim opsetkama datoteka otkrivanja toksičnosti. Stoga će detektori toksičnosti obučeni na trenutnim podacima također odbaciti kontekst, čineći otkrivanje toksičnosti konteksta mnogo teže kada se dogodi. Izgradili smo i javno oslobodili kompleks podataka od 10 k postova sa dvije vrste oznake toksičnosti po posto, koji su dobili od annotatora koji su smatrali i sadašnjem postu i prethodnom kao kontekst, ili ii) samo sadašnjem postu. Predstavljamo novi zadatak, procjenu osjetljivosti konteksta, koji je cilj identificirati postove čije se percepcija toksičnosti menja ako se smatra i kontekst (prethodna post). Koristeći novi set podataka, pokazujemo da se sistemi mogu razviti za ovaj zadatak. Takvi sustavi bi se mogli koristiti za poboljšanje datoteka otkrivanja toksičnosti sa višim položajama ovisnom o kontekstu ili predložiti kada bi moderatori trebali razmotriti roditeljske položaje, koje ne mogu uvijek biti potrebne i mogu predstaviti dodatne troškove.', 'et': 'Kasutajate postitused, mille tajutav mürgisus sõltub vestluskontekstist, on praeguste toksilisuse tuvastamise andmekogumites haruldased. Seega jätavad praeguste andmekogumite põhjal koolitatud mürgisuse detektorid konteksti arvesse, muutes kontekstitundliku mürgisuse tuvastamise oluliselt raskemaks, kui see toimub. Me ehitasime ja avaldasime avalikult andmekogumi 10k postitusest, millel on kahte liiki toksilisuse märgistused postituse kohta, mis on saadud annotatoritelt, kes pidasid i) nii praegust postitust kui ka eelmist postitust kontekstiks või ii) ainult praegust postitust. Tutvustame uut ülesannet, kontekstitundlikkuse hindamist, mille eesmärk on tuvastada postitused, mille tajutav toksilisus muutub, kui arvestatakse ka kontekstiga (eelmine postitus). Uue andmekogumi abil näitame, et selle ülesande jaoks on võimalik välja töötada süsteeme. Selliseid süsteeme võiks kasutada toksilisuse tuvastamise andmekogumite tõhustamiseks kontekstist sõltuvamate postitustega või selleks, et soovitada, millal moderaatorid peaksid kaaluma algpostitusi, mis ei pruugi alati olla vajalik ja võib kaasa tuua lisakulusid.', 'fi': 'Käyttäjäviestit, joiden koettu myrkyllisyys riippuu keskustelukontekstista, ovat harvinaisia nykyisissä myrkyllisyyden havaitsemistiedoissa. Näin ollen nykyisiin tietoaineistoihin koulutetut myrkyllisyyden ilmaisimet eivät myöskään ota huomioon kontekstia, mikä tekee kontekstille herkän myrkyllisyyden havaitsemisesta paljon vaikeampaa, kun sitä tapahtuu. Rakensimme ja julkistimme 10 000 postausta sisältävän aineiston, jossa on kahdenlaisia myrkyllisyysmerkintöjä per postaus, jotka on saatu huomautuksilta, jotka pitivät (i) sekä nykyistä että edellistä asiayhteyteenä tai (ii) vain nykyistä postausta. Esittelemme uuden tehtävän, kontekstiherkkyyden estimoinnin, jonka tavoitteena on tunnistaa viestit, joiden koettu myrkyllisyys muuttuu, jos myös kontekstia (edellinen postaus) tarkastellaan. Uuden aineiston avulla osoitamme, että tähän tehtävään voidaan kehittää järjestelmiä. Tällaisia järjestelmiä voitaisiin käyttää myrkyllisyyden havaitsemista koskevien tietoaineistojen parantamiseen kontekstista riippuvaisempien julkaisujen avulla tai ehdottamaan, milloin valvojien olisi harkittava vanhempia julkaisuja, mikä ei välttämättä aina ole tarpeen ja saattaa aiheuttaa lisäkustannuksia.', 'jv': 'Ngubah drawable-action Awak dhéwé nggawe lan publik ngembukake perusahaan dataset ning mbutuhaké bantên 10 k karo alamat sugêr sing katêpakan ngêngé kesempatané, awak dhéwé ngerasakno (i) ngono ngêngé awak dhéwé, sampek (i i) ngono ngêngé awak dhéwé. Awak dhéwé nggawe task sing gak, nggunakake kontèks-jutesne sampeyan, sing isih njaluké nggawe oleh nggawe ngubah sing sampeyan seneng nggawe barang tokisane kanggo ngubah kontèks (pub sing sabanjuré) sak ngono. Ngawe ngubah dataset sing bagian, kita ngomong sistem iso dianggawe kanggo nggawe task iki. Sistem sing dipunangé kanggo nambah kanggo nambah datayang dipunangé ngéwangi luwih dumadhi kapan titik-titik penting, ora bisa supoyo supoyo kapan modorator kudu isih beraksi punika isaké, sing ora bisa akeh dumadhi, akeh iso dianggap akeh dumadhi iki.', 'he': 'משימות משתמשים שהרעילות הנבחרת שלהם תלויה בקשר השיחה נדירות בקבוצות נתונים של זיהוי רעילות הנוכחיות. לכן, גלאי רעילות מאומנים על קבוצות נתונים הנוכחיות יהיו גם מתעלמים מהקשר, מה שעושה את גילוי רעילות רגישה לקונקסט הרבה יותר קשה כשזה מתרחש. בנינו ופרסמנו קופסט נתונים של 10k משימות עם שני סוגים של תוויות רעילות לכל משימה, שנקבלו ממכתבים שחשבו (i) גם את המשימה הנוכחית וגם את הקודמת כמקשר, או (ii) רק את המשימה הנוכחית. אנו מציגים משימה חדשה, הערכה של רגישות לקונקסט, שמתכוונת לזהות עמדות שהרעילות המוחשבה שלהם משתנה אם גם הקונקסט (עמוד קודם) נחשב. בשימוש בסט הנתונים החדש, אנחנו מראים שמערכות יכולות להתפתח למשימה הזאת. מערכות כאלה יכולות להשתמש כדי לשפר קבוצות נתונים לגילוי רעילות עם עמדות יותר תלויות בקשר או כדי להציע מתי מודרטורים צריכים לשקול את עמדות ההורים, שאולי לא תמיד הכרחיים ויכולים להכניס עלות נוספות.', 'ha': "Yana da bango masu amfani da kwamfyuta wanda ya gane, yana dõgara kan mazaɓa da mazaɓa, masu sauri ne cikin zane-zane na zaɓen bayani na tozarci yanzu. Wancan, na gane matsayin mai tozaro wanda aka amfani da shi a kan tsari na yanzu, za'a ƙyale context-sensitive zasu yi mafi tsanani idan za ta ci. Mun gina da bayani da aka saka kowace takardar takardar 10,000 da alama biyu na aikin toyi a kowace poster, aka samu daga matangarar waɗanda suka yi tunãni da shi yanzu da wanda ke gaba ta zama mazaɓa, ko (2) kawai da ke gaba. Tuna fara wani aikin da aka sauƙa ƙara muhimman aikin da ke cikin muhimmada, wanda za'a yi amfani da shi zuwa a gane posten wanda za'a canza musamman tozarci na gane idan an ƙayyade lokacin (da aka riga) ko. Yi amfani da tsarin danne-yanzu, za'a nuna cewa an buɗe system don wannan aikin. Wannan na'ura za'a yi amfani da wajen ƙara tsari na gane zaɓallin zane-bayani na masu ƙaranci, ko kuma a shauri idan masu motsi ya kamata su yi bincike maimaimain mahaifan, da ba za'a buƙata ba da amfani da, kuma yana iya ƙayyade kodi.", 'sk': 'Uporabniške objave, katerih zaznana toksičnost je odvisna od pogovornega konteksta, so redke v trenutnih naborih podatkov o odkrivanju toksičnosti. Zato detektorji toksičnosti, usposobljeni na podlagi sedanjih naborov podatkov, ne bodo upoštevali konteksta, zaradi česar bo odkrivanje toksičnosti, občutljive na kontekst, veliko težje, ko se pojavi. Izdelali smo in javno objavili nabor podatkov 10k objav z dvema vrstama oznak toksičnosti na objavo, pridobljenih od opozorilcev, ki so (i) upoštevali tako trenutno objavo kot prejšnjo kot kontekst ali (ii) samo trenutno objavo. Predstavljamo novo nalogo, ocenjevanje občutljivosti konteksta, katere cilj je identificirati objave, katerih zaznana toksičnost se spremeni, če upoštevamo tudi kontekst (prejšnja objava). Z novim naborom podatkov pokažemo, da je sisteme mogoče razviti za to nalogo. Takšni sistemi bi se lahko uporabili za izboljšanje zbirk podatkov o ugotavljanju toksičnosti z objavami, ki so bolj odvisne od konteksta, ali za predlaganje, kdaj bi morali moderatorji upoštevati nadrejene objave, kar morda ni vedno potrebno in lahko povzroči dodatne stroške.', 'bo': 'སྤྱིར་བཏང་བ་དང་འབྲེལ་བ་ཡིན་པའི་སྤྱོད་མཁན་གྱི་གནས་ཚུལ་དེ་ཚོས དེར་བརྟེན། གལ་སྲིད་གཞུང་ཚབ་ནང་ལ་སྨན་པའི་གསལ་བཤད་རྙེད་པ་དེ་ཡང་ཚོར་ཡུན་སྟངས་ལ་ངོས་འཛིན་བྱེད་སྲིད། We constructed and publicly release a dataset of 10k posts with two kinds of toxicity labels per post, obtained from annotators who considered (i) both the current post and the previous one as context, or (ii) only the current post. ང་ཚོས་བྱ་ཚུལ་གསར་བ་ཞིག་སྤྲོད་དགོས་པ་ཞིག་གིས་ཁྱད་ནས་ཡུལ་ཆོས་ལྟ་བུ་བཤད་ཡོད་པའི་གནས་ཚུལ་དང་འཕགས་རྐྱེན་བཟོ་བཅོས་བྱེད་ བེད་སྤྱོད་བཞིན་པའི་ཆ་འཕྲིན་སྒྲིག་ཆ་གསར་བ་སྤྱོད་པར་ང་ཚོས་དུས་སྤྱོད་དགོས་པ ཞིབ་འཇུག་འདི་དག་གི་དོན་དག་གཟུགས་རིས་བཙལ་བའི་གནས་ཚུལ་གཞི་རྟེན་དང་མཉམ་ཡོད་པའི་གནས་ཚུལ་ལ་ཡར་རྒྱས་སྐྱོར་བ་དང་མཉམ་དུ་འཇུག་སྣོད་པ་རྣམས་ལ་བ'}
{'en': 'When the Echo Chamber Shatters : Examining the Use of Community-Specific Language Post-Subreddit Ban', 'ar': 'عندما تتحطم غرفة الصدى: فحص استخدام لغة خاصة بمجتمع ما بعد الحظر الثانوي', 'es': 'Cuando la cámara de eco se rompe: examen del uso del lenguaje específico de la comunidad después de la prohibición de subreddit', 'fr': "Quand la chambre d'écho se brise\xa0: examen de l'utilisation d'un langage spécifique à la communauté après l'interdiction du subreddit", 'pt': 'Quando a câmara de eco se despedaçar: examinando o uso de linguagem específica da comunidade após a proibição do Subreddit', 'hi': 'जब इको चैंबर चकनाचूर हो जाता है: समुदाय-विशिष्ट भाषा पोस्ट-सबरेडिट प्रतिबंध के उपयोग की जांच करना', 'ru': 'Когда палата эха трещит: изучение использования языка, специфичного для сообщества, после запрета субредактирования', 'ja': 'エコーチャンバーが破壊された場合: Subreddit禁止後のコミュニティ固有言語の使用の検討', 'zh': '回音室碎:Subreddit禁社区特定言', 'ga': 'Nuair a Briseann an Seomra Macalla: Ag Scrúdú ar Úsáid Teanga Phobail Shonracha Cosc Iar-fhorshuímh', 'el': 'Όταν η αίθουσα ηχώ καταρρέει: Εξετάζοντας τη χρήση ειδικής γλώσσας για την Κοινότητα μετά την απαγόρευση Subreddit', 'hu': 'Amikor a visszhangkamra összeomlik: a közösségi specifikus nyelv használatának vizsgálata utáni tilalom', 'ka': 'როდესაც ექო სახლის შატატი: საზოგადოებო-სპეციფიკალური ენის გამოყენება', 'lt': 'Ekologinių kamerų triukšmo atveju: Bendrijos konkrečiai kalbai skirto draudimo naudoti po subreddito nagrinėjimas', 'it': "Quando la camera dell'eco si rompe: Esaminare l'uso di un linguaggio specifico per la comunità", 'kk': 'Эхо палатасының көлеңкелері: Компаттың ерекше тілдерінің қолдануын тексеру', 'mk': 'Кога еко комората се растура: испитување на користењето на забраната за пост-суредит на јазикот специфичен за заедницата', 'mt': 'Meta l-Echo Chamber Shatters: Eżami tal-Projbizzjoni tal-Użu tal-Lingwa Speċifika għall-Komunità wara s-Subreddit', 'ml': 'എക്കോ ചേമ്പര്\u200d ഷാറ്റര്\u200d ചെയ്യുമ്പോള്\u200d: സമൂഹത്തിന്റെ പ്രത്യേക ഭാഷയുടെ ഉപയോഗം പരിശോധിക്കുന്നു', 'ms': 'Bila Saluran Echo Berpecah: Memeriksa Penggunaan Saluran Bahasa Khusus-Komuniti', 'mn': 'Экхо өрөөний сүлжээний үед: Нийгэм-төрөлхтний хэл-төрөлхтний дараагийн сүлжээний сүлжээний хэрэглээ шалгаж байна.', 'ro': 'Când camera ecoului se sparge: examinarea utilizării limbajului specific comunității', 'no': 'Når Echo-kamera skyggar: Prøver bruk av utvalet etter undertekst av språk-spesifisert', 'pl': 'Kiedy komora echo się rozbija: badanie stosowania języka specyficznego dla społeczności po zakazie subsredditu', 'sr': 'Kada je Echo Chamber Shatters: Ispitivanje korištenja zabrane za određeni jezik zajednice nakon podredovanja', 'sv': 'När ekokammaren splittras: Undersökning av användningen av gemenskapsspecifikt språk', 'si': 'Echo Chamber Shatter: සමාජිකයෙන් විශේෂ භාෂාව පොස්ටර්ඩිට් බෑන් ප්\u200dරවේශනය කරන්න', 'so': 'Markii uu jarrabo jardiinada Echo: Imtixaamaynaya isticmaalka isticmaalka jamii-Specific language Ban-Subreddit', 'ur': 'جب اکو کمبر شیٹر کرتا ہے: کمپنٹی-خاص زبان کے استعمال کا تحقیق کرتا ہے', 'ta': 'Echo Chamber Shatters: Community- Specific Language Use After Subreddit Ban', 'uz': 'Name', 'vi': 'Khi phòng ngủ âm vang, xem xét việc sử dụng ngôn ngữ riêng biệt', 'bg': 'Когато камерата на ехото се разпадне: проучване на използването на специфичния за общността език след субредакцията забрана', 'nl': 'Wanneer de echokamer verbrijzelt: Onderzoek naar het gebruik van gemeenschapsspecifieke taal na Subreddit Verbod', 'da': 'Når ekkokammeret knuser: Undersøgelse af brugen af fællesskabsspecifikke sprogforbud efter subreddit', 'hr': 'Kada sjene Echo komore: ispitivanje korištenja zabrane za specifični jezik zajednice nakon podredovanja', 'ko': '메아리실 파열: Subreddit 금지령 검사 후 지역사회 특정 언어 사용', 'fa': 'وقتی اتاق Echo Shatters: Examining the use of Community-Specific Language Post-Subreddit Ban', 'de': 'Wenn die Echokammer zerbricht: Prüfung der Verwendung gemeinschaftsspezifischer Sprache nach Subreddit-Verbot', 'id': 'Ketika Kamar Echo Berpecah: Memeriksa Penggunaan Ban Bahasa Khusus-Komunitas Post-Subreddit', 'sw': 'Wakati chama cha Echo kinavamia: Kujaribu matumizi ya Lugha maalum baada ya Subreddit', 'tr': 'Eko oda gölgeleri:Toplumatyň spesifik dillerinin azynlaması', 'af': 'Wanneer die Echo kamer skatters: Ondersoek die gebruik van die gemeenskap-spesifieke taal Post-Subreddit Ban', 'am': 'የኢኮ ኮምፕሬል ሲሰራጨት: የመጠቀም ማኅበረሰብ-Specific language post-Subreddit Ban ሲመርምር', 'sq': 'Kur Dhoma Eko shkatërrohet: shqyrtimi i përdorimit të ndalimit të gjuhës specifike të komunitetit pas paragjykimit', 'hy': 'When the Echo Chamber Shatters: Examining the Use of Community-Specific Language Post-Subreddit Ban', 'az': 'Echo Odası Şərçəklərində: Özünün Özünün Özünün Dili İşləməsini Səfərləndirməsi', 'bs': 'Kada sjenke Echo komore: ispitivanje korištenja zabrane za specifični jezik zajednice nakon podredovanja', 'bn': 'When the Echo Chamber Shatters: Examining the Use of Community-Specific Language Post-Subreddit Ban', 'cs': 'Když se rozbije Echo komora: zkoumání používání jazyka specifického pro komunitu po zákazu subredditu', 'ca': "Quan l'Echo Chamber Shatters: Examinar l'ús del prohibició post-subreddit de llenguatges específics de la comunitat", 'fi': 'Kun kaikukammio hajoaa: yhteisökohtaisen kielen käytön tarkastelu Subreddit-kiellon jälkeen', 'et': 'Kui kajakaja puruneb: kogukonnapõhise keele kasutamise uurimine Subredditijärgse keelu kasutamise uurimine', 'jv': 'Ndoleh nggambar echo Kamer: ngembukake Ndoleh nggawe Ngubah Komunat-Ketoke Ngubah apat-Ngerawat', 'sk': 'Ko se zbornica Echo razbije: preučevanje uporabe jezika, specifičnega za skupnost, po prepovedi subreddita', 'he': 'When the Echo Chamber Shatters: Examining the Use of Community-Specific Language Post-Subreddit Ban', 'ha': 'Idan KCharselect unicode block name', 'bo': 'གཟའ་ཁོའི་ཁང་ལེན་མཁན་དབྱིབས་བསྡུ་ཚོད་སྤྱི་ཚོགས་ཀྱི་དམིགས་འཛུགས་ཀྱི་སྐད'}
{'en': 'Community-level bans are a common tool against groups that enable ', 'ar': 'يُعد الحظر على مستوى المجتمع أداة شائعة ضد المجموعات التي تمكّن المضايقات عبر الإنترنت والكلام الضار. لسوء الحظ ، تمت دراسة فعالية الحظر المجتمعي جزئيًا فقط وكانت النتائج مختلطة. هنا ، نقدم منهجية مرنة غير خاضعة للإشراف لتحديد لغة المجموعة وتتبع نشاط المستخدم على Reddit قبل وبعد حظر المجتمع (subreddit). نحن نستخدم اختلافًا بسيطًا في تكرار الكلمات لتحديد الكلمات غير الشائعة التي يتم تمثيلها بشكل مفرط في مجتمع معين ، ليس كبديل للكلام الضار ولكن كتوقيع لغوي للمجتمع. نطبق طريقتنا على 15 subreddits محظورة ، ونجد أن استجابة المجتمع غير متجانسة بين subreddits وبين مستخدمي subreddit. كان من المرجح أن يصبح كبار المستخدمين أقل نشاطًا بشكل عام ، بينما قلل المستخدمون العشوائيون في كثير من الأحيان من استخدام لغة المجموعة دون تقليل النشاط. أخيرًا ، وجدنا بعض الأدلة على أن فعالية الحظر تتوافق مع محتوى المجتمع. لم يتأثر مستخدمو مجتمعات الدعابة السوداء إلى حد كبير بالحظر بينما كان مستخدمو المجتمعات المنظمة حول تفوق البيض والفاشية هم الأكثر تضررًا. إجمالاً ، تُظهر نتائجنا أن عمليات الحظر لا تؤثر على جميع المجموعات أو المستخدمين على قدم المساواة ، وتمهد الطريق لفهم تأثير الحظر عبر المجتمعات.', 'es': 'Las prohibiciones a nivel comunitario son una herramienta común contra los grupos que permiten el acoso en línea y el discurso perjudicial. Desafortunadamente, la eficacia de las prohibiciones comunitarias solo se ha estudiado parcialmente y con resultados mixtos. Aquí, ofrecemos una metodología flexible sin supervisión para identificar el idioma dentro del grupo y realizar un seguimiento de la actividad de los usuarios en Reddit antes y después de la prohibición de una comunidad (subreddit). Utilizamos una simple divergencia de frecuencia de palabras para identificar palabras poco comunes sobrerrepresentadas en una comunidad determinada, no como un sustituto del lenguaje dañino sino como una firma lingüística de la comunidad. Aplicamos nuestro método a 15 subreddits prohibidos, y encontramos que la respuesta de la comunidad es heterogénea entre los subreddits y entre los usuarios de un subreddit. Los usuarios principales tenían más probabilidades de volverse menos activos en general, mientras que los usuarios aleatorios a menudo reducían el uso del lenguaje del grupo sin disminuir la actividad. Finalmente, encontramos alguna evidencia de que la eficacia de las prohibiciones se alinea con el contenido de una comunidad. Los usuarios de las comunidades de humor negro no se vieron afectados en gran medida por las prohibiciones, mientras que los usuarios de las comunidades organizadas en torno a la supremacía blanca y el fascismo fueron En conjunto, nuestros resultados muestran que las prohibiciones no afectan a todos los grupos o usuarios por igual, y allanan el camino para comprender el efecto de las prohibiciones en todas las comunidades.', 'fr': "Les interdictions au niveau de la communauté sont un outil courant contre les groupes qui permettent le harcèlement en ligne et les discours préjudiciables. Malheureusement, l'efficacité des interdictions communautaires n'a été que partiellement étudiée et les résultats sont mitigés. Ici, nous proposons une méthodologie flexible et non supervisée pour identifier la langue dans le groupe et suivre l'activité des utilisateurs sur Reddit avant et après le bannissement d'une communauté (subreddit). Nous utilisons une simple divergence de fréquence de mots pour identifier des mots peu communs surreprésentés dans une communauté donnée, non pas comme un substitut pour un discours nuisible mais comme une signature linguistique de la communauté. Nous appliquons notre méthode à 15 subreddits interdits et constatons que la réponse de la communauté est hétérogène entre les sous-reddits et entre les utilisateurs d'un sous-reddit. Les principaux utilisateurs étaient plus susceptibles de devenir moins actifs dans l'ensemble, tandis que les utilisateurs aléatoires réduisaient souvent l'utilisation de la langue en groupe sans diminuer l'activité. Enfin, nous trouvons certaines preuves que l'efficacité des bannissements correspond au contenu d'une communauté. Les utilisateurs des communautés d'humour noir n'ont pas été touchés par les interdictions tandis que les utilisateurs des communautés organisées autour de la suprématie blanche et du fascisme ont été les plus touchés. Dans l'ensemble, nos résultats montrent que les interdictions n'affectent pas tous les groupes ou utilisateurs de la même manière, et ouvrent la voie à une compréhension de l'effet des interdictions dans les communautés.", 'pt': 'As proibições em nível de comunidade são uma ferramenta comum contra grupos que permitem assédio online e discurso prejudicial. Infelizmente, a eficácia das proibições comunitárias foi apenas parcialmente estudada e com resultados mistos. Aqui, fornecemos uma metodologia flexível não supervisionada para identificar o idioma do grupo e rastrear a atividade do usuário no Reddit antes e depois do banimento de uma comunidade (subreddit). Usamos uma simples divergência de frequência de palavras para identificar palavras incomuns super-representadas em uma determinada comunidade, não como um proxy de fala prejudicial, mas como uma assinatura linguística da comunidade. Aplicamos nosso método a 15 subreddits banidos e descobrimos que a resposta da comunidade é heterogênea entre subreddits e entre usuários de um subreddit. Os principais usuários eram mais propensos a se tornarem menos ativos em geral, enquanto os usuários aleatórios geralmente reduziam o uso do idioma do grupo sem diminuir a atividade. Finalmente, encontramos algumas evidências de que a eficácia das proibições se alinha com o conteúdo de uma comunidade. Os usuários de comunidades de humor negro não foram afetados pelas proibições, enquanto os usuários de comunidades organizadas em torno da supremacia branca e do fascismo foram os mais afetados. Ao todo, nossos resultados mostram que os banimentos não afetam todos os grupos ou usuários igualmente e abrem o caminho para entender o efeito dos banimentos nas comunidades.', 'ja': 'コミュニティレベルの禁止は、オンラインハラスメントや有害なスピーチを可能にするグループに対する一般的なツールです。 残念ながら、コミュニティ禁止の有効性は部分的にしか研究されておらず、結果はまちまちである。 ここでは、コミュニティの禁止（サブレディット）の前後に、グループ内の言語を識別し、Redditでのユーザーアクティビティを追跡するための柔軟な管理されていない方法論を提供します。 私たちは、単純な単語の頻度の乖離を使用して、特定のコミュニティで過剰に表現されている珍しい単語を特定し、有害な発話の代用としてではなく、コミュニティの言語的特徴として使用します。 15の禁止されたサブレディットにメソッドを適用すると、コミュニティの応答はサブレディット間とサブレディットのユーザー間で異質であることがわかります。 トップユーザーは全体的にアクティブ性が低くなる傾向があり、ランダムユーザーはアクティビティを減らすことなくグループ内言語の使用を減らすことが多かった。 最後に、禁止の有効性がコミュニティのコンテンツと一致している証拠をいくつか見つけます。 ダークユーモアコミュニティのユーザーはほとんど禁止の影響を受けませんでしたが、白人至上主義とファシズムを中心に組織されたコミュニティのユーザーは最も影響を受けました。 総合すると、禁止がすべてのグループやユーザーに同等に影響を及ぼすわけではなく、コミュニティ全体で禁止の効果を理解するための道を開いていることがわかります。', 'zh': '社区层面之禁者,助长在线扰害言之常用工具也。 不幸者,社区禁之功得而论之,美恶参半。 供无监以识别组内言,踪迹社区(subreddit)禁之前,与Reddit之用户。 吾以简词频散识给定社区过度之不常见单词,非为害言之摄也,为社区言之征也。 宜用于15之subreddit,社区应于subreddits、subreddit用户之间异构也。 总体而言顶级用户有不可生者,随时用户常损组内言而不损。 最后证明,禁有效性与社区同。 黑色幽默社区之用户,略不染于禁,而绕白人至上主义、法西斯主义之社区用户最大。 总而言之,吾之治结果表明,禁令不均,群用户不等,为解禁铺平道社区。', 'hi': 'समुदाय-स्तर पर प्रतिबंध उन समूहों के खिलाफ एक सामान्य उपकरण है जो ऑनलाइन उत्पीड़न और हानिकारक भाषण को सक्षम करते हैं। दुर्भाग्य से, सामुदायिक प्रतिबंधों की प्रभावकारिता का केवल आंशिक रूप से अध्ययन किया गया है और मिश्रित परिणामों के साथ। यहां, हम इन-ग्रुप भाषा की पहचान करने और एक समुदाय के प्रतिबंध से पहले और बाद में रेडिट पर उपयोगकर्ता गतिविधि को ट्रैक करने के लिए एक लचीली असुरक्षित पद्धति प्रदान करते हैं (सबरेडिट)। हम किसी दिए गए समुदाय में असामान्य शब्दों की पहचान करने के लिए एक सरल शब्द आवृत्ति विचलन का उपयोग करते हैं, हानिकारक भाषण के लिए प्रॉक्सी के रूप में नहीं बल्कि समुदाय के भाषाई हस्ताक्षर के रूप में। हम अपनी विधि को 15 प्रतिबंधित subreddits पर लागू करते हैं, और पाते हैं कि सामुदायिक प्रतिक्रिया subreddits के बीच और एक subreddit के उपयोगकर्ताओं के बीच विषम है। शीर्ष उपयोगकर्ताओं को समग्र रूप से कम सक्रिय होने की अधिक संभावना थी, जबकि यादृच्छिक उपयोगकर्ताओं ने अक्सर गतिविधि को कम किए बिना इन-ग्रुप भाषा का उपयोग कम कर दिया था। अंत में, हमें कुछ सबूत मिलते हैं कि प्रतिबंधों की प्रभावशीलता एक समुदाय की सामग्री के साथ संरेखित होती है। डार्क ह्यूमर समुदायों के उपयोगकर्ता काफी हद तक प्रतिबंधों से अप्रभावित थे, जबकि सफेद वर्चस्व और फासीवाद के आसपास आयोजित समुदायों के उपयोगकर्ता सबसे अधिक प्रभावित हुए थे। कुल मिलाकर, हमारे परिणाम बताते हैं कि प्रतिबंध सभी समूहों या उपयोगकर्ताओं को समान रूप से प्रभावित नहीं करते हैं, और समुदायों में प्रतिबंधों के प्रभाव को समझने का मार्ग प्रशस्त करते हैं।', 'ru': 'Запреты на уровне сообщества являются распространенным инструментом против групп, которые допускают домогательства в Интернете и вредоносные высказывания. К сожалению, эффективность запретов, введенных в общинах, была изучена лишь частично и дала неоднозначные результаты. Здесь мы предоставляем гибкую неконтролируемую методологию для идентификации языка в группе и отслеживания активности пользователей на Reddit как до, так и после запрета сообщества (subreddit). Мы используем простую частотную дивергенцию слов, чтобы определить необычные слова, чрезмерно представленные в данном сообществе, не как прокси для вредной речи, а как лингвистическую сигнатуру сообщества. Мы применяем наш метод к 15 запрещенным субреддитам и обнаруживаем, что реакция сообщества неоднородна между субреддитами и между пользователями субреддита. Вероятность того, что основные пользователи в целом станут менее активными, была выше, в то время как случайные пользователи часто сокращали использование языка в группе без снижения активности. Наконец, мы находим некоторые доказательства того, что эффективность запретов согласуется с содержанием сообщества. Пользователи сообществ темного юмора в основном не были затронуты запретами, в то время как пользователи сообществ, организованных вокруг белого превосходства и фашизма, были в наибольшей степени затронуты. В целом, наши результаты показывают, что запреты не затрагивают все группы или пользователей одинаково, и прокладывают путь к пониманию эффекта запретов в сообществах.', 'ga': 'Is uirlis choiteann iad toirmisc ar leibhéal an phobail i gcoinne grúpaí a chumasaíonn ciapadh ar líne agus urlabhra dhochrach. Ar an drochuair, ní dhearnadh staidéar ach go páirteach ar éifeachtúlacht na dtoirmeasc pobail agus tá torthaí measctha ann. Anseo, soláthraímid modheolaíocht sholúbtha gan mhaoirseacht chun teanga inghrúpa a aithint agus chun gníomhaíocht úsáideoirí ar Reddit a rianú roimh agus tar éis toirmeasc pobail (subreddit). Bainimid úsáid as éagsúlacht minicíochta focal simplí chun focail neamhchoitianta a aithint a ndéantar ró-léiriú orthu i bpobal ar leith, ní mar sheachfhreastalaí do chaint dhochrach ach mar shíniú teangeolaíoch an phobail. Cuirimid ár modh i bhfeidhm ar 15 subreddits toirmiscthe, agus aimsímid go bhfuil freagairt an phobail ilchineálach idir subreddits agus idir úsáideoirí subreddit. Ba mhó an seans go n-éireodh barrúsáideoirí níos lú gníomhaí ar an iomlán, agus laghdaigh úsáideoirí randamacha úsáid teanga inghrúpa go minic gan gníomhaíocht a laghdú. Ar deireadh, feicimid roinnt fianaise go bhfuil éifeachtúlacht an toirmisc ar aon dul le hábhar an phobail. Ní raibh aon tionchar ag na toirmisc ar úsáideoirí na bpobal grinn dorcha agus ba iad úsáideoirí na bpobal a bhí eagraithe thart ar ardcheannas bán agus faisisteachas ba mhó a chuaigh i gcion orthu. San iomlán, léiríonn ár dtorthaí nach mbíonn tionchar comhionann ag toirmisc ar gach grúpa nó úsáideoir, agus go n-éascaíonn siad an bealach chun éifeacht an toirmisc ar phobail a thuiscint.', 'hu': 'A közösségi szintű tilalom közös eszköz az online zaklatást és a káros beszédet lehetővé tévő csoportok ellen. Sajnos a közösségi tilalom hatékonyságát csak részben tanulmányozták és vegyes eredményekkel. Itt rugalmas, felügyelet nélküli módszertant biztosítunk a csoporton belüli nyelvek azonosítására és a Redditen végzett felhasználói tevékenységek nyomon követésére egy közösség tiltása előtt és után (subreddit). Egy egyszerű szófrekvenciaeltéréssel azonosítjuk a nem gyakori szavakat, amelyek túlreprezentáltak egy adott közösségben, nem mint a káros beszéd helyettesítője, hanem mint a közösség nyelvi aláírása. Módszerünket 15 betiltott alreddire alkalmazzuk, és úgy találjuk, hogy a közösségi válasz heterogén az alredditek és a felhasználók között. A legjobb felhasználók összességében nagyobb valószínűséggel kevésbé lesznek aktívak, míg a véletlenszerű felhasználók gyakran csökkentették a csoporton belüli nyelvhasználatot anélkül, hogy csökkentenék a tevékenységet. Végül bizonyítékot találunk arra, hogy a tiltások hatékonysága összhangban áll a közösség tartalmával. A sötét humor közösségek használóit nagyrészt nem érintették a tilalom, míg a fehér felsőbbség és fasizmus köré szervezett közösségek használóit érintették a leginkább. Eredményeink összességében azt mutatják, hogy a tiltások nem érintik minden csoportot vagy felhasználót egyenlően, és megkönnyítik az utat a tiltások hatásának megértéséhez a közösségek között.', 'ka': 'საზოგადოებო დონეზე დაბანეები არის საერთო ხელსაწყოფილი ჯგუფების შესაძლებლობა, რომლებიც ინტერნეტის დაკავშირება და დაკავშირებული საუ ზალბად, საზოგადოებლოდ, საზოგადოებო ბანზების ეფექტიურობა მხოლოდ ნაწილად განსწავლია და შემდეგ შემდეგ შემდეგ შემდეგ. აქ, ჩვენ მივიღეთ ფლიქსიბური არსებული მეტოლოგია, რომელიც ჯგუფის ენათვის იდენტიფიკაცია და გამოყენებელი ექტივიტების შენახვა Reddit-ზე სამუშაო და სამუშაო დაწყენება (ს ჩვენ გამოყენებთ სიტყვის სიტყვის განსხვავებული სიტყვის, რომელიც განსხვავებული არსხვავებული სიტყვის განსხვავებული საზოგადოებაში, არა როგორც პროქსი დაკავშირებელი სიტყვის, მაგრამ როგ ჩვენ ჩვენი მეთოდის 15 წაშლა წაშლა წაშლა, და დავიწყებთ, რომ საზოგადოებო პასუხი ჰეტერეგენია საზოგადოებო და საზოგადოებო მომხმარების შორის. საუკეთესო მომხმარებელი უფრო შესაძლებელია დააკეთებულია საუკეთესო აქტიური, მაგრამ გამოყენებელი საუკეთესო ჯგუფის ენის გამოყენება უფრო საბოლოოდ, ჩვენ აღმოვაჩინეთ წარმოდგენები, რომ საზოგადოებო შესახებ საზოგადოებო შესახებ. შავი ჰუმორის საზოგადოებების მომხმარებელი უფრო გამოცდილობულია, როცა საზოგადოებების მომხმარებელი უფრო გარდაქმნილი და ტაქსიმური გამოცდილობულია. ყველაფერი, ჩვენი შედეგი ჩვენი შედეგი აჩვენებს, რომ ბანზები არ აკეთებენ ყველა ჯგუფი ან გამოყენებელი განმავლობაში, და გავაკეთებენ გზა, რომელიც გაუცნობა', 'el': 'Οι απαγορεύσεις σε κοινοτικό επίπεδο αποτελούν κοινό εργαλείο κατά ομάδων που επιτρέπουν διαδικτυακή παρενόχληση και βλαβερή ομιλία. Δυστυχώς, η αποτελεσματικότητα των κοινοτικών απαγορεύσεων έχει μελετηθεί μόνο εν μέρει και με μικτά αποτελέσματα. Εδώ, παρέχουμε μια ευέλικτη μεθοδολογία χωρίς επίβλεψη για τον εντοπισμό της γλώσσας εντός της ομάδας και την παρακολούθηση της δραστηριότητας των χρηστών στο τόσο πριν όσο και μετά την απαγόρευση μιας κοινότητας (subreddit). Χρησιμοποιούμε μια απλή απόκλιση συχνότητας λέξεων για να εντοπίσουμε ασυνήθιστες λέξεις υπερεκπροσωπούμενες σε μια δεδομένη κοινότητα, όχι ως αντιπρόσωπο βλαβερής ομιλίας αλλά ως γλωσσική υπογραφή της κοινότητας. Εφαρμόζουμε τη μέθοδο μας σε 15 απαγορευμένα υποreddits και διαπιστώνουμε ότι η ανταπόκριση της κοινότητας είναι ετερογενής μεταξύ των υποreddits και μεταξύ των χρηστών ενός subreddits. Οι κορυφαίοι χρήστες ήταν πιθανότερο να γίνουν λιγότερο ενεργοί συνολικά, ενώ οι τυχαίοι χρήστες συχνά μειώνουν τη χρήση της γλώσσας εντός της ομάδας χωρίς να μειώνουν τη δραστηριότητα. Τέλος, βρίσκουμε κάποια στοιχεία ότι η αποτελεσματικότητα των απαγορεύσεων ευθυγραμμίζεται με το περιεχόμενο μιας κοινότητας. Οι χρήστες κοινοτήτων σκοτεινού χιούμορ δεν επηρεάστηκαν σε μεγάλο βαθμό από τις απαγορεύσεις, ενώ οι χρήστες κοινοτήτων οργανωμένων γύρω από την κυριαρχία των λευκών και τον φασισμό επηρεάστηκαν περισσότερο. Συνολικά, τα αποτελέσματά μας δείχνουν ότι οι απαγορεύσεις δεν επηρεάζουν εξίσου όλες τις ομάδες ή τους χρήστες και ανοίγουν το δρόμο για την κατανόηση των επιπτώσεων των απαγορεύσεων σε όλες τις κοινότητες.', 'kk': 'Компаттың деңгейіндегі жалпы бағдарламалары онлайн жетілдіру және қауіпсіздік сөйлесу мүмкіндігін жеткізетін топтардың жалпы құралы. Кешіріңіз, коммуналық банктарының эффектілігі тек бөлікті оқылған және аралас нәтижелерімен бірге жатқан. Мұнда, біз топ тілдерін анықтау және қоғамды қалдырудың алдында да, алдында да, алдында да, алдында да, алдында да, алдында да, алдында да, қолданыстағы пайдаланушылардың белсенділігін қада Қарапайым сөздердің жиілігін айырмашылығын көрсету үшін кәдімгі сөздердің көпшілігін көрсету үшін қолданамыз. Бұл көпшілікті сөздердің көпшілігін айырмашылығы емес, біра Біз өзіміздің әдімімізді 15 жазылған субредиттерге қолдану және қоғамдық жауаптары субредиттердің мен субредиттердің пайдаланушыларының арасындағы гетерогендық деп табу Жоғарғы пайдаланушылар жұмыс ішінде белсенді болуы мүмкін, кездейсоқ пайдаланушылар топтың тілдерін көбейтіп, белсенділігін азайтып қолдануға болады. Соңында, біз бағдарламалардың эффективнілігі қоғамдық мазмұнымен сәйкес келеді деп білеміз. Қараңғы хумор компаттарының пайдаланушылары көбінде бұл жағдайда бұл жағдайда бұл жағдайда әсер етпейді, бірақ компаттардың пайдаланушылары ақ жоғары мен фашизмді Біздің нәтижелеріміз барлық топтарды не пайдаланушыларға тең әсер етпейді деп көрсетеді, және қоғамдықтардың әсерін түсіну жолын жасайды.', 'mk': 'Community-level bans are a common tool against groups that enable online harassment and harmful speech.  За жал, ефикасноста на забраните на заедницата е само делумно проучена и со мешани резултати. Овде, обезбедуваме флексибилна ненадгледувана методологија за идентификување на јазикот во групата и следење на активноста на корисникот на Reddit и пред и по забраната на заедница (subreddit). Ние користиме едноставна дивергенција на фреквенцијата на зборови за идентификување на необични зборови препретставени во одредена заедница, не како прокси за штетен говор туку како јазички потпис на заедницата. Го применуваме нашиот метод на 15 забранети подредити, и откриваме дека одговорот на заедницата е хетероген помеѓу подредитите и помеѓу корисниците на подредитот. Највисоките корисници најверојатно станаа помалку активни вкупно, додека случајните корисници честопати ја намалуваат употребата на јазикот во групата без намалување на активноста. Конечно, најдовме докази дека ефективноста на забраните се согласува со содржината на заедницата. Корисниците на мрачните хуморски заедници беа во голема мера невлијани на забраните, додека корисниците на заедниците организирани околу белата надлежност и фашизмот беа највлијани. Нашите резултати покажуваат дека забраните не влијаат на сите групи или корисници еднакво и го отвораат патот за разбирање на ефектот на забраните низ заедниците.', 'lt': 'Bendrijos lygmens draudimai yra bendra priemonė prieš grupes, kurios leidžia priekabiavimą internetu ir žalingą kalbą. Deja, bendruomenės draudimų veiksmingumas buvo tik iš dalies ištirtas ir gauta įvairių rezultatų. Čia mes siūlome lanksčią, nepastebimą metodiką, skirtą nustatyti grupės kalbą ir stebėti Reddit naudotojų veiklą tiek prieš, tiek po bendruomenės uždraudimo (subreddit). Mes naudojame paprastą žodžių dažnio skirtumą, kad identifikuotume nedažnus žodžius, pernelyg atstovaujamus konkrečioje bendruomenėje, ne kaip žalingos kalbos atstovą, bet kaip bendruomenės kalbinį parašą. Taikome savo metodą 15 draudžiamų subreddit ų ir nustatome, kad Bendrijos atsakas yra heterogeniškas tarp subredditų ir tarp subreddito naudotojų. Top users were more likely to become less active overall, while random users often reduced use of in-group language without decreasing activity.  Galiausiai turime įrodymų, kad draudimų veiksmingumas atitinka bendruomenės turinį. Tamsio humoro bendruomenių naudotojams beveik neturėjo įtakos draudimai, o labiausiai nukentėjo bendruomenių, organizuotų aplink baltąjį viršenybę ir fašizmą, naudotojai. Iš viso mūsų rezultatai rodo, kad draudimai nedaro vienodo poveikio visoms grupėms ar naudotojams ir sudaro kelią suprasti draudimų poveikį visose bendruomenėse.', 'it': "I divieti a livello comunitario sono uno strumento comune contro i gruppi che consentono molestie online e discorsi dannosi. Purtroppo, l'efficacia dei divieti comunitari è stata solo parzialmente studiata e con risultati contrastanti. Qui, forniamo una metodologia flessibile e non supervisionata per identificare il linguaggio in gruppo e monitorare l'attività degli utenti su Reddit sia prima che dopo il divieto di una community (subreddit). Usiamo una semplice divergenza di frequenza delle parole per identificare parole non comuni sovrarappresentate in una determinata comunità, non come proxy per discorsi dannosi ma come firma linguistica della comunità. Applichiamo il nostro metodo a 15 subreddit banditi e scopriamo che la risposta della community è eterogenea tra subreddit e tra gli utenti di un subreddit. Gli utenti migliori erano più propensi a diventare meno attivi nel complesso, mentre gli utenti casuali spesso riducevano l'uso del linguaggio in gruppo senza diminuire l'attività. Infine, troviamo alcune prove che l'efficacia dei bans si allinea con il contenuto di una community. Gli utenti delle comunità dell'umorismo oscuro sono stati in gran parte non influenzati dai divieti, mentre gli utenti delle comunità organizzate intorno alla supremazia bianca e al fascismo sono stati i più colpiti. Complessivamente, i nostri risultati mostrano che i divieti non riguardano tutti i gruppi o gli utenti allo stesso modo e aprono la strada alla comprensione dell'effetto dei divieti tra le comunità.", 'ms': 'Melarang aras komuniti adalah alat umum terhadap kumpulan yang memungkinkan gangguan online dan ucapan berbahaya. Malangnya, kegunaan larangan komuniti hanya sebahagian belajar dan dengan hasil campuran. Di sini, kami menyediakan metodologi fleksibel yang tidak diawasi untuk mengenalpasti bahasa dalam kumpulan dan mengesan aktiviti pengguna pada Reddit sebelum dan selepas melarang komuniti (subreddit). Kami menggunakan perbezaan frekuensi perkataan sederhana untuk mengenalpasti perkataan yang tidak biasa berlebihan dalam komuniti tertentu, bukan sebagai proksi untuk ucapan yang berbahaya tetapi sebagai tanda tangan bahasa komuniti. Kami melaksanakan kaedah kami kepada 15 subreddit dilarang, dan mendapati bahawa tindak balas komuniti adalah heterogeni antara subreddit dan antara pengguna subreddit. Pengguna tertinggi lebih mungkin menjadi kurang aktif secara keseluruhan, sementara pengguna rawak sering mengurangkan penggunaan bahasa dalam kumpulan tanpa berkurang aktiviti. Akhirnya, kami menemukan beberapa bukti bahawa kegunaan larangan menyesuaikan dengan kandungan komuniti. Pengguna komuniti humor gelap sebahagian besar tidak terpengaruh oleh larangan sementara pengguna komuniti yang disediakan sekitar kekuasaan putih dan fasisme adalah yang paling terpengaruh. Bersama-sama, hasil kita menunjukkan bahawa larangan tidak mempengaruhi semua kumpulan atau pengguna sama, dan membuka jalan untuk memahami kesan larangan di seluruh komuniti.', 'ml': 'സമൂഹത്തിന്റെ നിലപാടുകള്\u200d ഒരു സാധാരണ ഉപകരണമാണ്. അത് ഓണ്\u200dലൈനിലെ കഷ്ടപ്പെടുത്തുന്നതും അപകടത്തിന്റെ വാക്കുകള്\u200d Unfortunately, the efficacy of community bans has only been partially studied and with mixed results.  ഇവിടെ, നമ്മള്\u200d സംരക്ഷിക്കപ്പെടാത്ത ഒരു ഫ്ലാക്സിബിള്\u200d സംരക്ഷിക്കപ്പെടാത്ത രീതിയില്\u200d നിരീക്ഷിക്കുന്നു. ഗ്രൂപ്പില്\u200d ഭാഷ തിരിച ഒരു സമൂഹത്തില്\u200d പ്രതിനിധിക്കപ്പെട്ട അസാധാരണ വാക്കുകള്\u200d തിരിച്ചറിയാന്\u200d ഞങ്ങള്\u200d ഒരു എളുപ്പമായ വാക്കിന്റെ ഫ്രെയിന്\u200dസ് വ്യത്യാസവും ഉപയോഗി നമ്മുടെ രീതിയില്\u200d 15 നിരോധിക്കപ്പെട്ട സബ്രെഡിഡിറ്റിലേക്ക് പ്രയോഗിക്കുന്നു. സമൂഹത്തിന്റെ പ്രതികരണം സബ്രെഡിഡിറ്റു മുകളിലുള്ള ഉപയോക്താക്കള്\u200d സജ്ജീവമാക്കാന്\u200d കുറച്ച് സാധ്യതയുണ്ടായിരുന്നു. കുറ്റമില്ലാത്ത ഉപയോക്താക്കള്\u200d പ്രാ അവസാനം, ഒരു സമൂഹത്തിന്\u200dറെ ഉള്ളടക്കം കൊണ്ട് നിരോധിക്കുന്നതിന്\u200dറെ പ്രവർത്തിയാണെന്ന് നമുക്ക് തെളിവ ഇരുട്ട് തമാശയുടെ സമൂഹത്തിന്\u200dറെ ഉപയോക്താക്കള്\u200d മിക്കവാറും പ്രയാസപ്പെട്ടിരുന്നു. വെളുത്ത ആത്മാവിന്\u200dറെയും ഫാസിസ്തിമി അതുകൊണ്ട്, നമ്മുടെ ഫലങ്ങള്\u200d കാണിക്കുന്നു എല്ലാ ഗ്രൂപ്പുകള്\u200dക്കും ഉപയോക്താക്കള്\u200dക്കും വിലക്കുന്നത് ഒരുപോലെയല്ല എന്നും, സമൂഹത്', 'mt': 'Il-projbizzjonijiet fil-livell Komunitarju huma għodda komuni kontra gruppi li jippermettu fastidju onlajn u diskors ta’ ħsara. Sfortunatament, l-effikaċja tal-projbizzjonijiet tal-komunità ġiet studjata biss parzjalment u b’riżultati mħallta. Hawnhekk, qed nipprovdu metodoloġija flessibbli mhux sorveljata biex nidentifikaw il-lingwa fi ħdan il-grupp u nimtraċċaw l-attività tal-utent fuq Reddit kemm qabel kif ukoll wara l-projbizzjoni ta’ komunità (subreddit). Aħna nużaw diverġenza sempliċi fil-frekwenza tal-kliem biex nidentifikaw kliem mhux komuni rrappreżentati żżejjed f’komunità partikolari, mhux bħala prokura għal diskors ta’ ħsara iżda bħala firma lingwistika tal-komunità. Aħna napplikaw il-metodu tagħna għal 15-il subreddits ipprojbiti, u nsibu li r-rispons komunitarju huwa eteroġenu bejn is-subreddits u bejn l-utenti ta’ subreddit. L-aqwa utenti kienu aktar probabbli li jsiru inqas attivi b’mod ġenerali, filwaqt li l-utenti aleatorji spiss naqqsu l-użu tal-lingwa fil-grupp mingħajr ma naqsu l-attività. Fl-a ħħar nett, isibu xi evidenza li l-effettività tal-projbizzjonijiet tallinja mal-kontenut ta’ komunità. L-utenti tal-komunitajiet tal-humor skur fil-biċċa l-kbira ma kinux affettwati mill-projbizzjonijiet filwaqt li l-utenti tal-komunitajiet organizzati madwar is-supremazija u l-faxxiżmu bojod kienu l-aktar affettwati. B’mod ġenerali, ir-riżultati tagħna juru li l-projbizzjonijiet ma jaffettwawx il-gruppi jew l-utenti kollha b’mod ugwali, u jwittu t-triq biex wieħed jifhem l-effett tal-projbizzjonijiet fil-komunitajiet kollha.', 'ro': 'Interdicțiile la nivel comunitar reprezintă un instrument comun împotriva grupurilor care permit hărțuirea online și vorbirea dăunătoare. Din păcate, eficacitatea interdicțiilor comunitare a fost studiată doar parțial și cu rezultate mixte. Aici, oferim o metodologie flexibilă nesupravegheată pentru identificarea limbajului în grup și urmărirea activității utilizatorilor pe Reddit atât înainte, cât și după interzicerea unei comunități (subreddit). Folosim o simplă divergență de frecvență a cuvintelor pentru a identifica cuvintele neobișnuite suprareprezentate într-o anumită comunitate, nu ca un proxy pentru vorbirea dăunătoare, ci ca o semnătură lingvistică a comunității. Aplicăm metoda noastră la 15 subreddit-uri interzise și constatăm că răspunsul comunității este eterogen între subreddit și între utilizatorii unui subreddit. Utilizatorii de top au fost mai probabili să devină mai puțin activi în general, în timp ce utilizatorii aleatorii au redus adesea utilizarea limbajului în grup fără a scădea activitatea. În cele din urmă, găsim unele dovezi că eficacitatea interdicțiilor se aliniază cu conținutul unei comunități. Utilizatorii comunităților de umor negru au fost în mare măsură neafectați de interdicții, în timp ce utilizatorii comunităților organizate în jurul supremației albe și fascismului au fost cei mai afectați. În total, rezultatele noastre arată că interdicțiile nu afectează toate grupurile sau utilizatorii în mod egal și deschid calea către înțelegerea efectelor interdicțiilor între comunități.', 'mn': 'Нийгмийн хэмжээний шалтгаан нь онлайн зовлонг, хохиромжтой яриаг боловсруулдаг бүлэгтэй эсрэг нийтийн хэрэгсэл юм. Харамсалтай нь нийгмийн бэрхшээлийн үр дүнг зөвхөн хэсэгт судалж, төвөгтэй үр дүнтэй холбогдсон. Энд бид бүлэгтэй хэл тодорхойлж, Reddit-ийн хэрэглэгчийн үйл ажиллагааг өмнө болон нийгмийн бэрхшээлийн дараа тодорхойлж чадахгүй арга замыг хангадаг. Бид нэг нийгэмд илүү ихэвчлэн дүрслэгдсэн үгийг олохын тулд энгийн хэмжээний өөрчлөлт хэрэглэдэг. Харамсалтай ярианы хувьд биш, нийгэмд хэлний үсэг баримтуудын хувьд. Бид 15 хувьсагдсан хүмүүст арга замыг ашиглаж, нийгмийн хариу үйлдвэрлэл нь хувьсагдсан хүмүүсийн хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хоорондоо хооро Хамгийн их хэрэглэгчид илүү актив болж магадгүй, санамсаргүй хэрэглэгчид ажиллагааг багасгахгүй бүлэг хэлний хэрэглээ багасгадаг. Эцэст нь бид холбоотой байгууллагын үр дүнтэй холбоотой гэдгийг баталж байна. Харын хумор нийгмийн хэрэглэгчид ихэнхдээ хамгийн нөлөөлдөггүй байсан. Гэхдээ нийгмийн хэрэглэгчид цагаан өндөр болон фашизм тойронд зохион байгуулагч хамгийн нөлөөлдөг байсан. Бидний үр дүн нь бүх баг эсвэл хэрэглэгчидтэй адилхан нөлөөлөхгүй гэдгийг харуулж, нийгэмд хоригдлын нөлөөлөлийг ойлгох арга замыг нэмэгдүүлдэг.', 'pl': 'Zakazy na szczeblu społeczności są wspólnym narzędziem przeciwko grupom umożliwiającym molestowanie przez internet i szkodliwe wypowiedzi. Niestety skuteczność zakazów społecznościowych została tylko częściowo zbadana i z mieszanymi wynikami. Tutaj zapewniamy elastyczną metodologię bez nadzoru identyfikacji języka wewnątrz grupy i śledzenia aktywności użytkowników na Reddit zarówno przed, jak i po zakończeniu zakazu społeczności (subreddit). Używamy prostej dywergencji częstotliwości słów, aby zidentyfikować nietypowe słowa nadreprezentowane w danej społeczności, nie jako zastępcę szkodliwej mowy, ale jako językowy podpis społeczności. Stosujemy naszą metodę do 15-ciu zakazanych subredditów i stwierdzamy, że odpowiedź społeczności jest heterogeniczna między subredditami i między użytkownikami subredditów. Najlepsi użytkownicy byli bardziej prawdopodobni, że ogólnie stają się mniej aktywni, podczas gdy przypadkowi użytkownicy często ograniczali używanie języka wewnątrz grupy bez zmniejszenia aktywności. Wreszcie znaleźliśmy pewne dowody na to, że skuteczność zakazów jest zgodna z treścią społeczności. Użytkownicy społeczności ciemnego humoru w dużej mierze nie byli wpływani zakazami, podczas gdy najbardziej dotknięci byli użytkownicy społeczności zorganizowanych wokół białej supremacji i faszyzmu. Ogólnie rzecz biorąc, nasze wyniki pokazują, że zakazy nie mają równego wpływu na wszystkie grupy lub użytkowników i torują drogę do zrozumienia skutków zakazów we wszystkich społecznościach.', 'no': 'Fellesskapsnivået er eit vanleg verktøy mot grupper som slår på nettverket påverka og skadelig tale. Dessverre er effektiviteten av fellesskapslinjer berre delvis studiert og med blandede resultat. Her gir vi ein fleksibel usikkerte metodologi for å identifisera i gruppe språk og spora brukaraktivitet på Reddit både før og etter banen av eit samfunn (underreddit). Vi bruker ein enkel ordfrekvensforskjell for å identifisera vanlege ord over representert i eit gitt samfunn, ikkje som mellomtenar for skadelig tale, men som språkstignering av samfunnet. Vi bruker metoden vårt til 15 banna underskriftar, og finn at samfunnsvaret er heterogenesk mellom underskriftar og mellom brukarar av underskrift. Øvre brukarar vart sannsynleg å bli mindre aktiv overalt, mens tilfeldig brukarar ofte reduserte bruk av i gruppespråk utan å redusere aktivitet. I slutt finn vi nokre beviser at effektiviteten av baner er tilsvarande med innhaldet i eit samfunn. Brukarar av mørke humorekommunikasjonar vart stort ikkje påvirka av baner mens brukarar av kommunikasjonar organiserte rundt kvit høgd og fasismen var det mest påvirka. Resultatet våre viser altså at baner ikkje påvirkar alle grupper eller brukarar like, og lager måten til å forstå effekten av baner over samfunn.', 'sr': 'Zabrane na nivou zajednice su zajednički alat protiv grupa koje omogućavaju online uznemiravanje i štetni govor. Nažalost, djelotvornost zabrani zajednice je samo djelomično proučena i sa mešanim rezultatima. Ovde, pružamo fleksibilnu neodređenu metodologiju da identifikujemo jezik grupe i pratimo aktivnost korisnika na Reddit i prije i nakon zabrane zajednice (podreddit). Koristimo jednostavnu razliku frekvencije reèi da identifikujemo neobiène reèi predstavljene u odreðenoj zajednici, ne kao proxy za štetan govor, nego kao jezički potpis zajednice. Primjenjujemo našu metodu na 15 zabranjenih subreddit a i pronađemo da je odgovor zajednice heterogenezan između subreddita i između korisnika subreddita. Vrhunski korisnici su vjerojatnije postali manje aktivni ukupno, dok su nasumični korisnici često smanjili korištenje jezika u grupi bez smanjenja aktivnosti. Konačno, nađemo neke dokaze da učinkovitost zabrani odgovara sadržaju zajednice. Korisnici tamnih humorskih zajednica uglavnom nisu uticali na zabranu, dok su korisnici zajednica organizovane oko bijelog nadmoænosti i fašizma najuticaliji. U potpunosti, naši rezultati pokazuju da zabrani ne utječu na sve grupe ili korisnike jednako i da otkriju način da razumemo učinak zabrani širom zajednica.', 'so': "Bandhiga wada degmada waa qalabka caadiga ah oo ka gees ah kooxaha internetka ka shaqeeya dhibaatooyinka iyo hadalka waxyeellada ah. Nasiib la’aanta, saamaynta bangiyada bulshada waxaa loo baray qeyb ahaan iyo resultiyada isku xiran oo kaliya. Here, we provide a flexible unsupervised methodology to identify in-group language and track user activity on Reddit both before and after the ban of a community (subreddit).  Waxaynu isticmaalnaa isbedelka hadalka fudud si aan u aqoonsanno erayo aan caadi aheyn oo ay ka tirsan yihiin bulshada la siiyey, taas oo aan aheyn ogeysiiska hadalka waxyeellada ah, laakiin sida saxiixiibka afka ee bulshada. Waxaynu isticmaalaynaa qaabkeenna 15 meelo laga diiday, waxaynu aragnaa in jawaabta bulshada ay ka mid tahay dabeecada iyo u dhexeeya isticmaalayaasha subreddit. Inta badan isticmaalayaasha guud waxaa suurtagal ah in ay noqdaan wax ka yar, inta badan isticmaalayaasha isticmaalka kooxaha ah waxqabad la'aan. Ugu dambaysta waxaan helaynaa caddeyn kamid ah in saameynta bangiyadu ay ku sameynaysaa waxyaabaha bulshada. Isticmaalayaasha bulshada mugdiga ah waxey si badan u saameyn ku lahaayeen bangiyada, marka isticmaalayaasha bulshada ku wareegsan gaarka cad iyo fascisiga ayaa ugu saameysan. Intaas waxaa kale oo ay ka muuqataa in bangiyadu aysan saameyn ugu yeelan kooxda oo dhan ama isticmaalayaasha si isku mid ah, waxayna leedahay waddada ay fahamaan saamaynta bangiyada bulshada oo dhan.", 'sv': 'Förbud på gemenskapsnivå är ett gemensamt verktyg mot grupper som möjliggör trakasserier och skadliga tal på nätet. Tyvärr har effekten av samhällsförbud endast delvis studerats och med blandade resultat. Här tillhandahåller vi en flexibel och oövervakad metod för att identifiera gruppspråk och spåra användaraktivitet på Reddit både före och efter förbudet av en community (subreddit). Vi använder en enkel ordfrekvensavvikelse för att identifiera ovanliga ord överrepresenterade i en given gemenskap, inte som en proxy för skadliga tal utan som en språklig signatur för samhället. Vi tillämpar vår metod på 15 bannade subreddit, och finner att gemenskapens svar är heterogen mellan subreddit och mellan användare av en subreddit. Toppanvändare var mer benägna att bli mindre aktiva totalt sett, medan slumpmässiga användare ofta minskade användningen av gruppspråk utan att minska aktiviteten. Slutligen hittar vi några bevis på att effektiviteten av förbud stämmer överens med innehållet i en gemenskap. Användare av mörk humor samhällen påverkades i stort sett inte av förbud medan användare av samhällen organiserade kring vit överhöghet och fascism påverkades mest. Sammantaget visar våra resultat att förbud inte påverkar alla grupper eller användare lika, och banar väg för att förstå effekten av förbud mellan samhällen.', 'si': 'සමාජික ස්ථානය ප්\u200dරතික්\u200dරීයා සාමාන්\u200dය උපකරණයක් වෙනුවෙන් අන්ලයින් විරුද්ධ කණ්ඩායම් සහ අවාසනාවෙන්න, සමාජික ප්\u200dරතික්\u200dරියාවේ ප්\u200dරතික්\u200dරියාත්මක විතරයි අංකයෙන් අධ්\u200dයානය කරලා තියෙනව මෙතන, අපි සමාජයක් ප්\u200dරතික්\u200dරියාත්මක කරන්න පුළුවන් විධානය සඳහා කණ්ඩායම් භාෂාවක් පරික්ෂා කරන්න සහ ප්\u200dරයෝජකයේ ප්\u200dරක අපි සාමාන්\u200dය වචනයක් භාවිතා කරනවා සමාජිකයෙන් ප්\u200dරතිනිධාන වචනයක් ප්\u200dරතිනිධානය කරනවා, සමාජිකයේ භාෂාවික සංඥානයක්  අපි අපේ විධානය 15 ක් ප්\u200dරයෝජනය කරනවා, සමාජික ප්\u200dරතික්\u200dරියාව හොයාගන්න, සමාජික ප්\u200dරතික්\u200dරියාව සමාජික විශේෂය ස ගොඩක් ප්\u200dරයෝජකයෝ සක්\u200dරිය සම්පූර්ණය වෙන්න පුළුවන් විතරයි, සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූ අන්තිමට, අපිට සාක්ෂියක් හොයාගන්න පුළුවන් වෙන්නේ ප්\u200dරතික්\u200dරියාවක් සමාජයක් ගැන සමාගම සමඟ අඳුරු හිමෝර් සමාජයේ ප්\u200dරයෝජකයෝ ගොඩක් අවස්ථාවක් නැති විදියට ප්\u200dරයෝජනය කරලා තියෙන්නේ සමාජයේ ප්\u200dරයෝජක සම්පූර්ණයෙන්ම, අපේ ප්\u200dරතිචාරය පෙන්වන්නේ ප්\u200dරතිචාරයක් සියළු කණ්ඩායමයි ප්\u200dරතිචාරකයන්ට සමාන්\u200dය විදිය', 'ta': 'சமுதாயத்தின் நிலை தடைகள் ஒரு பொதுவான கருவியாகும் ஆன்லைன் துன்பந்தம் மற்றும் காயமான பேச்சை செயல்படுத்து துரதிர்ஷ்டவசமாக, சமூகத்தின் தடை விளைவு பகுதியாக படிக்கப்பட்டுள்ளது மற்றும் கலப்பு முடிவுகளுடன் மட்டும். இங்கே நாம் ஒரு flexible unservised முறைமையை வழங்குகிறோம் குழு மொழியில் கண்டுபிடி கொடுக்கப்பட்ட சமுதாயத்தில் மேல் பிரதிநிதியபட்ட சொல்லின் வெளியீட்டை நாம் ஒரு எளிய வார்த்தை மாறுபாட்டை பயன்படுத்துகிறோம், குறைவ 15 நிறுத்தப்பட்ட உப ப பிரிவுகளுக்கு நாம் எங்கள் முறைமையை பயன்படுத்துகிறோம், மற்றும் சமூகத்தின் பதில் உப ப ரிடிட்டுகளுக்கும மேல் பயனர்கள் மொத்தத்தில் செயல்பாட்டில் குறைவாக இருக்க வேண்டும். குறிப்பில்லாத பயனர் குழு மொழியில் பயன்பாட்டை க இறுதியில், தடை செயல்பாடு ஒரு சமூகத்தின் உள்ளடக்கத்துடன் ஒத்திசைக்கிறது என்று சில தெளிவாக கண்டுபிடி இருள் சுற்றி வெள்ளை மேன்மையான மற்றும் பாசிஸ்ஸிஸ் சுற்றி அமைக்கப்பட்ட சமூகத்தின் பயனீட்டாளர் மேலும், எங்கள் முடிவுகள் காட்டுகிறது எல்லா குழுக்களையும் பயன்படுத்துபவர்களையும் சமமாக பாதிக்காது, மற்றும் சமூகத்தில் தடை வ', 'ur': 'اجتماعی سطح کے منع گروہوں کے مقابلے میں ایک مشترک وسیلہ ہے جو آنلاین کی آزار اور نقصان کی بات کرسکتے ہیں. بدبختی کے ساتھ، کمونٹی منع کی تاثیر صرف حصہ کے ساتھ پڑھی گئی ہے اور مختلف نتائج کے ساتھ۔ یہاں، ہم ایک مضبوط غیر قابل تحقیق کی روش دیتے ہیں کہ گروپ زبان میں پہچان سکیں اور ایک جماعت کے منع سے پہلے اور بعد راڈیٹ پر کارساز فعالیت کو ترک کریں۔ ہم ایک ساده کلمہ فرکانس فرکانس اختلاف کا استعمال کرتے ہیں کہ ایک جماعت میں غیر معمولی کلمات کو پہچان سکیں، نہ نقصان کی بات کے لئے، بلکہ جماعت کی زبان شناسی کے طور پر. ہم اپنے طریقے پر 15 منع کئے گئے ہیں، اور دیکھتے ہیں کہ کمونٹی کی جواب مزید غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر بالا کارساز بہت زیادہ شانس تھا کہ کم فعال ہونے والی تھی، حالانکہ random users often reduced use of in-group language without decreasing activity. بالآخر، ہم نے کچھ نشانیاں پائیں کہ منع کی فعالیت ایک جماعت کے منصوبے سے ملتی ہے۔ اندھیرے ہمور کی کمونٹیوں کے کارساز بہت سے منع کرنے والے نہیں تھے حالانکہ کمونٹیوں کے کارساز سفید بلندی اور فاشیسم کے گرد سب سے زیادہ اثر دیے گئے تھے ہمارے نتیجے دکھاتے ہیں کہ منع تمام گروپ یا کارساز برابر تکلیف نہیں دیتے اور جماعت میں منع کرنے کے اثر کو سمجھنے کے لئے راہ بتا دیتے ہیں.', 'uz': "Community-level bans are a common tool against groups that enable online harassment and harmful speech.  Afsuski, jamiyatlarni bekor qilishning effekti faqat qismdan o'qindilar va minglab natijalar bilan o'qishdi. Bu yerda, biz bir guruh tilni aniqlash uchun fleksiz xavfsiz yo'nalmagan metodini koʻrsatish va bir jamiyatni bekor qilish (subreddit) dan oldin va keyin foydalanuvchi amalni qidirish uchun foydalanuvchining amalni tracking. Biz bir oddiy so'zning freymini aniqlash uchun oddiy so'zni foydalanamiz. Ko'rsatilgan jamiyatdagi oddiy so'zlarni aniqlash uchun oddiy soʻzni foydalanamiz. Biz quyidagi 15 qismlarga qo'llamiz va jamiyat javobi subreddit va subreddit foydalanuvchilar orasidagi yetarli. Yuqori foydalanuvchilar umumiy aktiv boʻlishi mumkin. Tasodifiy foydalanuvchilar foydalanuvchidan foydalanish qoʻllanmagan boʻlmaydi. Biz oxirida, buning tizimning effekti jamiyat tarkibini o'zgartiradi. Qoraq suhbat jamiyatlarining foydalanuvchilari eng katta ishlatadi va oq suhbat va fascism tarkibi jamiyatlarning foydalanuvchilari eng ko'proq qo'llangan edi. Ko'rsatganda, bizning natijalarimiz hamma guruhlar yoki foydalanuvchilarga teng ishlatilmaydi va hamma jamiyatlarning ta'sirini o'rganishga yordam beradi.", 'vi': 'Cấm cấm vận ở cấp trên là một công cụ phổ biến đối với các nhóm có thể quấy rối trực tuyến và nói xấu. Thật không may, hiệu quả của việc cấm hoạt động cộng đồng chỉ được nghiên cứu một phần và kết quả hỗn hợp. Ở đây, chúng tôi cung cấp một phương pháp mềm dẻo mà không giám sát để xác định ngôn ngữ trong nhóm và theo dõi của người dùng trên Reddit cả trước và sau khi bị cấm hoạt động cộng đồng (mặc cảm). Chúng tôi sử dụng một khác biệt đơn giản về tần số từ để xác định những từ không phổ biến quá đại diện trong một cộng đồng, không phải là ủy nhiệm cho ngôn ngữ gây hại mà là dấu hiệu ngôn ngữ của cộng đồng. Chúng tôi áp dụng phương pháp cho 15 bị cấm giảm giá, và phát hiện rằng phản ứng cộng đồng rất khác nhau giữa các giai đoạn giảm giá và giữa người dùng. Người dùng hàng đầu có khả năng trở nên ít hoạt động hơn, trong khi người dùng ngẫu nhiên thường giảm sử dụng ngôn ngữ trong nhóm mà không giảm hoạt động. Cuối cùng, chúng tôi tìm ra bằng chứng cho thấy hiệu quả của việc cấm vận trùng với nội dung của một cộng đồng. Người dùng tính hài hước tối tăm không bị ảnh hưởng bởi việc cấm vận, trong khi người dùng của cộng đồng được tổ chức xung quanh chủ quyền da trắng và chủ nghĩa phát xít là những người bị ảnh hưởng nhất. Tóm lại, kết quả của chúng ta cho thấy rằng cấm vận không ảnh hưởng mọi nhóm hay người dùng ngang nhau, và mở đường để hiểu hiệu quả của cấm vận trên khắp các cộng đồng.', 'bg': 'Забраните на общностно ниво са общ инструмент срещу групи, които позволяват онлайн тормоз и вредно слово. За съжаление ефикасността на забраните в общността е била проучена само частично и с смесени резултати. Тук предоставяме гъвкава, ненадвидена методология за идентифициране на езика в групата и проследяване на активността на потребителите в Редит както преди, така и след забраната на дадена общност (субреддит). Използваме проста отклонение от честотата на думата, за да идентифицираме необичайни думи, които са свръхпредставени в дадена общност, не като прокси за вредна реч, а като лингвистичен подпис на общността. Прилагаме метода си към 15 забранени субреддита и откриваме, че отговорът на общността е хетерогенен между субреддитите и между потребителите на субреддит. Най-добрите потребители са били по-склонни да станат по-малко активни като цяло, докато случайните потребители често намаляват употребата на езика в групата, без да намаляват активността. И накрая, намираме някои доказателства, че ефективността на забраните съответства на съдържанието на дадена общност. Потребителите на общности с тъмен хумор до голяма степен не са засегнати от забраните, докато потребителите на общности, организирани около бяло превъзходство и фашизъм, са най-засегнати. Като цяло нашите резултати показват, че забраните не засягат еднакво всички групи или потребители и проправят пътя към разбирането на ефекта от забраните в общностите.', 'da': 'Forbud på fællesskabsplan er et fælles redskab mod grupper, der muliggør onlinechikane og skadelig tale. Desværre er effektiviteten af samfundsforbud kun delvis undersøgt og med blandede resultater. Her tilbyder vi en fleksibel, uautoriseret metode til at identificere gruppesprog og spore brugeraktivitet på Reddit både før og efter forbuddet af et fællesskab (subreddit). Vi bruger en simpel ordfrekvensdivergens til at identificere usædvanlige ord overrepræsenteret i et givet fællesskab, ikke som en proxy for skadelig tale, men som en sproglig signatur af fællesskabet. Vi anvender vores metode på 15 forbudte subreddits, og finder ud af, at fællesskabets reaktion er heterogen mellem subreddits og mellem brugere af en subreddit. Topbrugere var mere tilbøjelige til at blive mindre aktive generelt, mens tilfældige brugere ofte reducerede brugen af gruppesprog uden at reducere aktiviteten. Endelig finder vi nogle beviser på, at effektiviteten af forbud stemmer overens med indholdet i et fællesskab. Brugere af mørk humor fællesskaber var stort set upåvirket af forbud, mens brugere af fællesskaber organiseret omkring hvid overherredømme og fascisme var mest påvirket. Alt i alt viser vores resultater, at forbud ikke påvirker alle grupper eller brugere ligeligt, og baner vejen for at forstå effekten af forbud på tværs af fællesskaber.', 'nl': 'Verboden op gemeenschapsniveau zijn een gemeenschappelijk instrument tegen groepen die online intimidatie en schadelijke spraak mogelijk maken. Helaas is de effectiviteit van communautaire verboden slechts gedeeltelijk onderzocht en met gemengde resultaten. Hier bieden we een flexibele methodologie zonder toezicht om taal in de groep te identificeren en gebruikersactiviteiten op Reddit te volgen, zowel voor als na het verbod van een community (subreddit). We gebruiken een eenvoudige woordfrequentie divergentie om ongewone woorden te identificeren die oververtegenwoordigd zijn in een bepaalde gemeenschap, niet als een proxy voor schadelijke spraak, maar als een taalkundige handtekening van de gemeenschap. We passen onze methode toe op 15-verboden subreddits, en vinden dat de reactie van de gemeenschap heterogeen is tussen subreddits en tussen gebruikers van een subreddit. Topgebruikers zouden over het algemeen minder actief worden, terwijl willekeurige gebruikers vaak minder gebruik maakten van groepstaal zonder dat de activiteit afnam. Tot slot vinden we enig bewijs dat de effectiviteit van verboden overeenkomt met de inhoud van een community. Gebruikers van donkere humor gemeenschappen werden grotendeels niet beïnvloed door verboden, terwijl gebruikers van gemeenschappen georganiseerd rond blanke suprematie en fascisme het meest getroffen werden. Al met al laten onze resultaten zien dat verbanden niet alle groepen of gebruikers gelijk beïnvloeden, en effenen de weg om het effect van verbanden in gemeenschappen te begrijpen.', 'hr': 'Zabrane na razini zajednice su zajednički alat protiv grupa koje omogućavaju online uznemiravanje i štetni govor. Nažalost, djelotvornost zabrani zajednice je samo djelomično ispitivana i s mješenim rezultatima. Ovdje pružamo fleksibilnu nepotrebnu metodologiju za identifikaciju jezika u grupi i praćenje aktivnosti korisnika na Reddit i prije i nakon zabrane zajednice (podreddit). Koristimo jednostavnu razliku učestalosti riječi kako bi identifikovali neobične riječi predstavljene u određenoj zajednici, ne kao proizvođa č za štetne govore nego kao jezički potpis zajednice. Primjenjujemo našu metodu na 15 zabranjenih podrednika i otkrijemo da je odgovor zajednice heterogeneran između podrednika i između korisnika podrednika. Vrhunski korisnici su vjerojatnije postali manje aktivni ukupno, dok su nasumični korisnici često smanjili primjenu jezika u skupini bez smanjenja aktivnosti. Konačno, nađemo neke dokaze da učinkovitost zabrani odgovara sadržaju zajednice. Korisnici tamnih humorskih zajednica u velikoj mjeri nisu utjecali na zabranu dok su korisnici zajednica organizirane oko bijelog nadmoćnosti i fašizma najpogođeniji. U potpunosti, naši rezultati pokazuju da zabrane ne utječu na sve grupe ili korisnike jednako, te otvaraju način da razumijemo učinak zabrani širom zajednica.', 'de': 'Verbote auf Gemeinschaftsebene sind ein gemeinsames Instrument gegen Gruppen, die Online-Belästigung und schädliche Sprache ermöglichen. Leider wurde die Wirksamkeit von Gemeinschaftsverboten nur teilweise und mit gemischten Ergebnissen untersucht. Hier stellen wir eine flexible, unbeaufsichtigte Methodik zur Verfügung, um Gruppensprache zu identifizieren und Benutzeraktivitäten auf Reddit sowohl vor als auch nach dem Sperren einer Community (subreddit) zu verfolgen. Wir verwenden eine einfache Wortfrequenzdivergenz, um ungewöhnliche Wörter zu identifizieren, die in einer bestimmten Gemeinschaft überrepräsentiert sind, nicht als Stellvertreter für schädliche Sprache, sondern als sprachliche Signatur der Gemeinschaft. Wir wenden unsere Methode auf 15-gebannte Subreddits an und stellen fest, dass die Community-Reaktion zwischen Subreddits und zwischen Benutzern eines Subreddits heterogen ist. Top-Nutzer waren insgesamt eher weniger aktiv, während zufällige Benutzer häufig den Gebrauch der Gruppensprache reduzierten, ohne die Aktivität zu verringern. Schließlich finden wir einige Hinweise darauf, dass die Wirksamkeit von Bans mit dem Inhalt einer Community übereinstimmt. Nutzer von Dark Humor Communities waren weitgehend von Verboten unberührt, während Nutzer von Communities, die um weiße Vorherrschaft und Faschismus organisiert waren, am stärksten betroffen waren. Insgesamt zeigen unsere Ergebnisse, dass Bans nicht alle Gruppen oder Nutzer gleichermaßen betreffen, und ebnen den Weg, die Auswirkungen von Bans in allen Communities zu verstehen.', 'id': 'Melarang tingkat komunitas adalah alat umum terhadap kelompok yang memungkinkan pelecehan online dan pidato yang berbahaya. Sayangnya, efektivitas dari larangan masyarakat hanya sebagian telah dipelajari dan dengan hasil campuran. Di sini, kami menyediakan metodologi fleksibel yang tidak diawasi untuk mengidentifikasi bahasa dalam grup dan melacak aktivitas pengguna di Reddit sebelum dan setelah melarang sebuah komunitas (subreddit). Kami menggunakan divergensi frekuensi kata sederhana untuk mengidentifikasi kata yang tidak biasa berlebihan di komunitas tertentu, bukan sebagai proxi untuk pidato yang berbahaya tetapi sebagai tanda tangan bahasa komunitas. Kami menerapkan metode kami untuk 15 subreddit dilarang, dan menemukan bahwa respon komunitas adalah heterogene antara subreddit dan antara pengguna subreddit. Pengguna terbaik lebih mungkin menjadi kurang aktif secara umum, sementara pengguna acak sering mengurangi penggunaan bahasa dalam kelompok tanpa mengurangi aktivitas. Akhirnya, kami menemukan beberapa bukti bahwa efektivitas larangan menyesuaikan dengan isi komunitas. Users of dark humor communities were largely unaffected by bans while users of communities organized around white supremacy and fascism were the most affected.  Bersama-sama, hasil kami menunjukkan bahwa larangan tidak mempengaruhi semua kelompok atau pengguna sama, dan membuka jalan untuk memahami efek larangan di seluruh komunitas.', 'ko': '지역사회 차원의 금지령은 인터넷 소란과 유해한 언론을 유발하는 단체에 대처하는 흔한 수단이다.불행하게도 지역사회 금지령의 유효성은 일부 연구만 있었고 결과는 좋고 나쁨이 반반이었다.여기서 우리는 커뮤니티(subreddit)가 금지되기 전과 후에 그룹 내의 언어를 식별하고 사용자가 Reddit에서의 활동을 추적하는 유연한 무감독 방법을 제공했다.우리는 간단한 주파수 차이를 이용하여 특정 지역사회에 너무 많은 흔치 않은 단어가 나타나는 것을 식별하는데 유해한 언론의 대표가 아니라 지역사회의 언어 특징으로서 식별한다.우리는 우리의 방법을 금지된subreddit 15개에 적용하여subreddit와subreddit 사용자 간의 지역사회 반응이 이질적인 것을 발견했다.최고급 사용자는 전체적으로 그다지 활발하지 않을 수 있지만, 무작위 사용자는 일반적으로 활동을 줄이지 않는 상황에서 그룹 내 언어의 사용을 줄일 수 있다.마지막으로 우리는 금지령의 유효성이 지역 사회의 내용과 일치한다는 증거를 발견했다.검은색 유머 지역사회의 사용자들은 기본적으로 금지령의 영향을 받지 않고 백인 지상과 파시즘 조직을 둘러싼 지역사회의 사용자들이 가장 큰 영향을 받는다.한 마디로 하면 우리의 연구 결과에 따르면 금지령은 모든 단체나 사용자에게 동등한 영향을 미치지 않는다. 이것은 금지령이 전체 지역사회에 미친 영향을 이해하기 위해 길을 닦았다.', 'fa': 'جلوگیری سطح اجتماعی یک ابزار مشترک در برابر گروهی است که اجازه دهند آزار و سخنرانی خطرناک در آنلاین. متأسفانه، تاثیر بازداشت اجتماعی جز قسمتی تحقیق شده و با نتایج مختلف شده است. در اینجا، ما یک روش فرایند غیرقابل تحسین برای شناسایی زبان گروهی و فعالیت کاربر روی Reddit هر دو پیش و بعد از بازداشتن یک جامعه (زیر تغییر دادن) را پیشنهاد می\u200cکنیم. ما از فرکانس کلمه ساده استفاده می\u200cکنیم تا کلمه\u200cهای غیر عادی را در یک جامعه\u200cی معین مشخص کنیم، نه به عنوان پروکسی برای گفتار خطرناک بلکه به عنوان امضای زبان\u200cشناسی جامعه. ما روش خودمان را به ۱۵ متخصص بازداشته می\u200cکنیم، و پیدا می\u200cکنیم که پاسخ جامعه بین متخصص و بین استفاده\u200cهای متخصص متخصص است. کاربران بالا بیشتر احتمالاً کمتر فعال می\u200cشوند، در حالی که کاربران تصادفی اغلب استفاده از زبان در گروه بدون کاهش فعالیت کم می\u200cکنند. بالاخره، ما مدرک هایی پیدا کردیم که موثرت بازداشتها با محتوای یک جامعه متصل می شوند. استفاده از جامعه های شوخی تاریک بیشتر توسط جلوگیری ها تحت تاثیر قرار نداشتند، در حالی که استفاده از جامعه ها در اطراف برتری سفید و فاشیسم بیشتر تحت تاثیر قرار گرفته بودند. در کل، نتیجه\u200cهای ما نشان می\u200cدهند که نهی\u200cها به همانند تأثیر تمام گروه\u200cها یا کاربران نمی\u200cدهند، و راه را برای فهمیدن اثر نهی\u200cها در جامعه\u200cها قرار می\u200cدهند.', 'tr': 'Toplumatyň düýbünden çykyşlary internetde howpsuzlyk we agyrly çykyş etmäge mümkin bir araç. Gynansakda, jemgyýetiniň etkinliýeti diňe bir bölüm bilen okalýar we çagalan netijeler bilen okalýar. Bu ýerde, topar dilinde tanyş etmek üçin fleksib taýýarlanmadyk bir methodologiýa saýlaýrys we jemgyýetiniň önünde we soňra Reddit etkinleşenleri tanyşdyrmak üçin ullanýan. Biz beýleki jemgyýetde iň az sözleri tanamak üçin basit bir söz düýtgeşigini ulanýarys, güjük sözleri üçin proxy diýip toplumyň dil imzasy hökmünde tapylmadyk. Biz öz yöntemimizi 15 yasaklanýan toparyna uygulaýarys we jemgyýetiň jogabynyň üýtgeşmeleri we subriteleriň arasynda tapawutlarymyz däldir. Iň üst Ullançylar hemme faýly ýaşda aktiw bolup biler meňzeş, isleserden Ullançylar köplenç grup dilinde işlenişini azaltmazdan azaltýarlar. Iň soňunda, maňat täsirini jemgyýetiň maksadyna gollaýandygynyň käbir kanlag tapdyk. Garyş humor jemgyýetleriniň ullanyşylary aňry üstünlik we fašizm töwereginde ýerleşýän jemgyýetleriniň has baglanmasy tarapyndan etmän däldir. Biziň netijelerimiz hemme topar ýa-da ullançylaryň täsirine täsirleşmeýändigini görkezýär we jemgyýetleriň täsirini çykarmak üçin ýola çykarýarlar.', 'sw': 'Uzuizi wa ngazi za jumuiya ni chombo cha kawaida dhidi ya makundi yanayoweza kusababisha udhalilishaji na hotuba mbaya mtandaoni. Kwa bahati mbaya, madhara ya kufungiwa marufuku ya jamii yamekuwa yanasomwa kwa sehemu tu na kwa matokeo yanayochanganyika. Here, we provide a flexible unsupervised methodology to identify in-group language and track user activity on Reddit both before and after the ban of a community (subreddit).  Tunatumia utofauti wa maneno rahisi kwa kutambua maneno yasiyo ya kawaida yaliyowakilishwa katika jamii inayopewa, sio kama mtazamo wa hotuba yenye madhara lakini kama ishara ya lugha ya jamii. Tunatumia mbinu zetu kwa vifaa 15 vilivyozuiwa, na tunagundua kuwa majibu ya kijamii ni tofauti kati ya vigogo vya chini na kati ya watumiaji wa subreddit. Watumiaji wa jumla waliweza kuwa na uwezekano wa kuwa na harakati kidogo zaidi, wakati watumiaji wa asili mara nyingi hupunguza matumizi ya lugha ya kikundi bila kupunguza shughuli. Mwisho, tunagundua ushahidi kwamba ufanisi wa kufungiwa umepanda na maudhui ya jamii. Watumiaji wa jamii za ucheshi wa mweusi waliathirika sana na kupigwa marufuku wakati watumiaji wa jamii walioandaliwa kwa ajili ya utawala weupe na utamaduni uliathirika zaidi. Zaidi ya hayo, matokeo yetu yanaonyesha kuwa vikwazo vya kupigwa marufuku haviwaathiri makundi yote au watumiaji wote kwa usawa, na kuzuia njia ya kuelewa madhara ya kupigwa marufuku katika jamii mbalimbali.', 'af': "Kommunikasievlak-verbansies is 'n gemeenskaplike hulpmiddel teen groepe wat online verdrukking en skadelike spreek aktiveer. Ongelukkig is die effektiviteit van gemeenskapsverbans slegs gedeeltelik ondersoek en met gemengde resultate. Hier, ons verskaf 'n fleksibel ononderwerpende metodologie om in-groep taal te identifiseer en die gebruiker aktiviteit op Reddit beide voor en na die verban van 'n gemeenskap (subreddit). Ons gebruik 'n eenvoudige woord frekvense verskil om onbekende woorde te identifiseer in 'n gegewe gemeenskap, nie as 'n volmag vir skadelike spreek nie, maar as 'n lingwisiese handtekening van die gemeenskap. Ons toewend ons metode aan 15 gebanneerde subreddite, en vind dat gemeenskapsreaksie heterogenees is tussen subreddite en tussen gebruikers van 'n subreddit. Boppe gebruikers was meer waarskynlik om minder aktief te word, terwyl willekeurige gebruikers dikwels gebruik van in-groep taal verduur sonder om aktiviteit te verduur. Ons vind eindelik 'n paar getuienis dat die effektiviteit van die verbans gelyk met die inhoud van 'n gemeenskap. Gebruikers van donker humor gemeenskappe was groot onvloek deur verbanne terwyl gebruikers van gemeenskappe rondom wit hoogheid en fascisme die mees geïnvloor is. Totaal, ons resultate wys dat die verbansing nie alles groepe of gebruikers gelyk het nie, en laat die pad verstaan om die effek van verbansies oor gemeenskappe te verstaan nie.", 'sq': 'Ndryshimet në nivelin komunitar janë një mjet i përbashkët kundër grupeve që mundësojnë ngacmimin online dhe fjalimin e dëmshëm. Fatkeqësisht, efektshmëria e ndalimeve të komunitetit është studiuar vetëm pjesërisht dhe me rezultate të përziera. Here, we provide a flexible unsupervised methodology to identify in-group language and track user activity on Reddit both before and after the ban of a community (subreddit).  Ne përdorim një dallim të thjeshtë të frekuencës së fjalëve për të identifikuar fjalë të pazakonta të mbipërfaqësuara në një komunitet të caktuar, jo si një proxy për fjalim të dëmshëm por si një nënshkrim gjuhësor të komunitetit. Ne aplikojmë metodën tonë për 15 subreddits të ndaluara, dhe zbulojmë se reagimi i komunitetit është heterogjene midis subreddits dhe midis përdoruesve të subreddits. Top users were more likely to become less active overall, while random users often reduced use of in-group language without decreasing activity.  Më në fund, gjejmë disa prova se efektshmëria e ndalimeve përputhet me përmbajtjen e një komuniteti. Përdoruesit e komuniteteve të humorit të errët nuk u prekën kryesisht nga ndalimet ndërsa përdoruesit e komuniteteve të organizuara rreth supremacisë së bardhë dhe fascismit ishin më të prekur. Së bashku, rezultatet tona tregojnë se ndalimet nuk prekin të gjitha grupet apo përdoruesit në mënyrë të barabartë dhe hapin rrugën për të kuptuar efektin e ndalimeve nëpër komunitete.', 'am': 'ማኅበረሰብ ደረጃዎች ላይ የሚከለክሉ የኢንተርኔት ግጭት እና በጉዳይ ንግግር በሚችሉ ቡድን ላይ የተቃውሞ ዕቃ ናቸው፡፡ በመከፋት፣ የማኅበረሰብ እርምጃዎች በኩል ተማርቷል እና በተለያዩ ፍሬዎች ብቻ ነው፡፡ ወደዚህ፣ የቋንቋ ቋንቋ እና የተጠቃሚውን ሥራ አስቀድሞ እና ማኅበረሰብ (subreddit) ከተከለከሉ በኋላ በመግለጽ እናሳውቃለን፡፡ በአካባቢው ማኅበረሰብ ውስጥ የተለየ ቃላትን ለማረጋገጥ ቀላል የቃላት ቁጥጥር እናስቀምጣለን፡፡ የ15 የተከለከሉትን አካባቢዎች እና ማኅበራዊ መልስ በጥቅድሚያ እና በጥቅድሚያ ተጠቃሚዎች መካከል የተለየ ነው ብለን እናገኘዋለን፡፡ Top users were more likely to become less active overall, while random users often reduced use of in-group language without decreasing activity.  በመጨረሻም የከለከሉ ውይይት በማኅበረሰብ ውስጥ የሚደርስ ማስረጃ እናገኛለን፡፡ የጨለማ ሐሳብ ማኅበረሰብ ተጠቃሚዎች በነጭ ውጤት እና ፋሲሲሲም የተሰናከሩ የቤተሰቦች ተጠቃሚዎች አብዛኛዎቹ ተካክለው ነበር፡፡ በተጨማሪም ፍሬዎቻችን የግድ ጉዳዮችን ሁሉ ወይም ተጠቃሚዎችን በአንድ ላይ እንዳያስጨንቋል፣ የግድ ግንኙነታችንን በማስተዋል መንገድን አግኝቷል፡፡', 'bn': 'কমিউনিটি স্তরের নিষেধাজ্ঞা হচ্ছে গ্রুপের বিরুদ্ধে একটি সাধারণ টুল যা অনলাইনে নির্যাতন এবং ক্ষতিগ্রস্ত বক দুর্ভাগ্যবশতঃ সম্প্রদায় নিষেধাজ্ঞার কার্যক্রম শুধুমাত্র অংশে পড়া হয়েছে এবং মিশ্র ফলাফলের মাধ্যমে। এখানে আমরা গ্রুপ ভাষায় পরিচয় চিহ্নিত এবং রেডিডিটে ব্যবহারকারীদের কার্যক্রম চিহ্নিত করার পূর্বে এবং সম্প্রদায়ের নিষিদ্ধ করার পর (সাব্রে আমরা একটি সাধারণ শব্দের ফ্রেঞ্জেন্স ব্যবহার করি একটি নির্দিষ্ট কমিউনিটিতে প্রতিনিধিত্বিত অমান্য শব্দের চিহ্নিত করার জন্য, ক্ষতিকর ভাষণের আমরা আমাদের পদ্ধতি ১৫টি নিষিদ্ধ সাবরেডিটের দিকে প্রয়োগ করি, আর আমরা দেখতে পাই যে সম্প্রদায়ের প্রতিক্রিয়া সাবরেডিট এবং সাবরেডিট উপরের ব্যবহারকারীরা সাধারণত সক্রিয় হয়ে যাওয়ার সম্ভাবনা কম ছিল, কিন্তু অসময়ই ব্যবহারকারীরা প্রায়শই গ্রুপ ভাষায় ব্যবহার করে ক অবশেষে, আমরা কিছু প্রমাণ পেয়েছি যে নিষেধাজ্ঞার কার্যক্রম সম্প্রদায়ের বিষয়বস্তুর সাথে একত্রিত হয়েছে। অন্ধকারের হাসির সম্প্রদায়ের ব্যবহারকারীরা বেশীরভাগ নিষিদ্ধ করে নিষেধাজ্ঞা প্রভাবিত হয়েছে যখন সাদা আত্মশীলতা এবং ফ্যাসিস্ তবে আমাদের ফলাফল দেখা যাচ্ছে যে নিষেধাজ্ঞা সকল গ্রুপ বা ব্যবহারকারীদের একই ভাবে প্রভাব ফেলবে না, আর সারা সম্প্রদায়ের নিষেধাজ্', 'hy': 'Համասարակության մակարդակի արգելքները ընդհանուր գործիք են խմբերի դեմ, որոնք հնարավորություն են տալիս առցանց հարձակման և վնասավոր խոսքի համար: Դժբախտաբար, համայնքի արգելքների արդյունավետությունը միայն մասամբ ուսումնասիրել է և համեմատական արդյունքներով: Այստեղ մենք տրամադրում ենք ճկուն, անվերահսկված մեթոդոլոգիա, որպեսզի բացահայտենք խմբի լեզուն և հետևենք Reddit-ի օգտագործողների գործունեությունը մինչև համայնքի արգելման (ենթակարգելման) հետո: Մենք օգտագործում ենք պարզ բառերի հաճախականության տարբերությունը, որպեսզի բառերը բացահայտենք, որոնք չափազանց հազվադեպ են ներկայացված որոշ համայնքում, ոչ որպես վնասավոր խոսքի ներկայացուցիչ, այլ որպես համայնքի լեզվաբանական նշան: Մենք կիրառում ենք մեր մեթոդը 15 արգելափակված ենթարգետների դեպքում, և հայտնաբերում ենք, որ համայնքային արձագանքը հեթերգեն է ենթարգետների և ենթարգետների օգտագործողների միջև: Ամենաբարձր օգտագործողները ավելի հավանական էին, որ ընդհանուր առմամբ ավելի քիչ ակտիվ կդառնան, մինչդեռ պատահական օգտագործողները հաճախ նվազեցրեցին խմբի լեզուների օգտագործումը առանց նվազեցող ակ Վերջապես, մենք գտանք որոշ ապացույցներ, որ արգելքների արդյունավետությունը համապատասխանում է համայնքի պարունակությանը: Մոտ հումորի համայնքների օգտագործողները հիմնականում անազդեցություն չունեին արգելքների միջոցով, մինչդեռ սպիտակ գերիշխանության և ֆասիզմի շրջապատում կազմակերպված համայնքների օգտագործողները ամենաազդեցությունն ունե Ընդհանուր առմամբ մեր արդյունքները ցույց են տալիս, որ արգելքները չեն ազդում բոլոր խմբերի կամ օգտագործողների հավասար ազդեցության վրա և պատրաստում են ճանապարհ արգելքների ազդեցության հասկանալու համայնքներում:', 'az': "İnternettə təcavüzə və zərərli sözləri fəaliyyətləndirən qruplara qarşı ortaq bir vasitədir. Maalesef ki, toplum qadağanlarının etkinlik yalnız bir qismi təhsil edildi və müxtəlif sonuçlar ilə müxtəlif təhsil edildi. Burada, qrup dilində təsdiqlənmək üçün fleksib təsdiqlənmiş metodoloji təmin edirik və bir toplum qadağan edildikdən sonra da Reddit'də istifadəçilərin fəaliyyətini təsdiqləyirik. Biz sadəcə bir söz frequency fərqli sözləri verilmiş bir ümmətdə a şırı təşkil edilmiş sözləri tanımaq üçün istifadə edirik, zərərli sözlər üçün deyil, ancaq toplumun dil imzası olaraq. Bizim metodumuzu 15 qadağan edilmiş subredditlərə uyğun edirik və toplum reaksiyonu subredditlər arasında və subreddit istifadəçiləri arasında eyni ola bilər. Ən yüksək istifadəçilər daha az aktif olaraq, təsirli istifadəçilər çox dəfə qrup dillərinin istifadəsini azaltmadan azaldırlar. Sonunda, qadağan etkinliği bir toplumun məlumatıyla bərabər olduğuna dair bəzi dəlillər tapırıq. Karanlıq humor cəmiyyətlərinin istifadəçiləri çox qadağan edilmədi, halbuki cəmiyyətlərin istifadəçiləri ağ üstünlük və fashism ətrafında müəyyən edilən ən təsirli idi. Bütün sonuçlarımız bütün gruplar və istifadəçilərə eyni təsiri olmadığını göstərir və toplumların təsirlərinin etkisini anlamaq yolunu göstərir.", 'bs': 'Zabrane na nivou zajednice su zajednički alat protiv grupa koje omogućavaju online uznemiravanje i štetni govor. Nažalost, djelotvornost zabrani zajednice je samo djelomično proučena i sa mešanim rezultatima. Ovdje pružamo fleksibilnu nepotrebnu metodologiju za identifikaciju jezika u grupi i praćenje aktivnosti korisnika na Reddit i prije i nakon zabrane zajednice (podreddit). Koristimo jednostavnu razliku frekvencije riječi kako bi identifikovali neobične riječi predstavljene u određenoj zajednici, ne kao proizvođa č za štetne govore, već kao jezički potpis zajednice. Primjenjujemo našu metodu na 15 zabranjenih poduzetnika i otkrivamo da je odgovor zajednice heterogenezan između poduzetnika i između korisnika poduzetnika. Vrhunski korisnici su vjerojatnije postali manje aktivni ukupno, dok su nasumični korisnici često smanjili korištenje jezika u grupi bez smanjenja aktivnosti. Konačno, pronašli smo neke dokaze da učinkovitost zabrani odgovara sadržaju zajednice. Korisnici tamne humorske zajednice uglavnom nisu utjecali na zabrane, dok su korisnici zajednica organizovane oko bijelog nadmoćnosti i fašizma najpogođeniji. U potpunosti, naši rezultati pokazuju da zabrani ne utječu na sve grupe ili korisnike jednako i da otkriju način da razumijemo učinak zabrani širom zajednica.', 'cs': 'Zákazy na úrovni komunity jsou společným nástrojem proti skupinám, které umožňují on-line obtěžování a škodlivé řeči. Bohužel účinnost komunitních zákazů byla studována pouze částečně a se smíšenými výsledky. Zde poskytujeme flexibilní metodiku bez dohledu pro identifikaci jazyka ve skupině a sledování aktivit uživatelů na Redditu před i po zákazu komunity (subreddit). Používáme jednoduchou divergenci frekvence slov k identifikaci neobvyklých slov v dané komunitě, nikoli jako zástupce škodlivé řeči, ale jako jazykový podpis komunity. Používáme naši metodu na 15 zakázané subreddity a zjišťujeme, že komunitní reakce je heterogenní mezi subreddity a mezi uživateli subredditu. Nejlepší uživatelé byli pravděpodobněji celkově méně aktivní, zatímco náhodní uživatelé často snižovali používání jazyka ve skupině bez snížení aktivity. Nakonec nalezneme některé důkazy, že účinnost zákazů odpovídá obsahu komunity. Uživatelé komunit temného humoru nebyli do značné míry ovlivněni zákazy, zatímco uživatelé komunit organizovaných kolem nadvlády bílých a fašismu byli nejvíce postiženi. Celkově naše výsledky ukazují, že zákazy neovlivňují všechny skupiny nebo uživatele stejně a připravují cestu k pochopení účinků zákazů napříč komunitami.', 'ca': "Els prohibicions a nivell comunitari són una eina comú contra grups que permeten assetjament en línia i discurs nocius. Malauradament, l'eficacia de les prohibicions de la comunitat només s'ha estudiat parcialment i amb resultats mixts. Aquí proporcionem una metodologia flexible sense supervisió per identificar el llenguatge en grup i seguir l'activitat de l'usuari en Reddit tant abans com després de la prohibició d'una comunitat (subreddit). Utilitzem una divergència senzilla de freqüència de paraules per identificar paraules poc comunes sobrepresentades en una comunitat dada, no com a proxi per a un discurs nociu, sinó com a signatura lingüística de la comunitat. Aplicam el nostre mètode a 15 subreddit is prohibits, i descobrim que la resposta comunitaria és heterogenea entre subredditis i entre usuaris d'un subreddit. Top users were more likely to become less active overall, while random users often reduced use of in-group language without decreasing activity.  Finalment, trobem algunes evidències que l'eficacia de les prohibicions s'alineix amb el contingut d'una comunitat. Els usuaris de comunitats d'humor fosc no estaven afectats per prohibicions mentre els usuaris de comunitats organitzats al voltant de la supremacia blanca i el fascisme eren els més afectats. En general, els nostres resultats mostren que les prohibicions no afecten a tots els grups o usuaris igualment, i permeten entendre l'efecte de les prohibicions a les comunitats.", 'et': 'Ühenduse tasandil kehtivad keelud on ühine vahend rühmade vastu, mis võimaldavad internetis ahistamist ja kahjulikku kõnet. Kahjuks on kogukonna keelude tõhusust uuritud vaid osaliselt ja tulemused on erinevad. Siin pakume paindlikku järelevalveta metoodikat rühmasisese keele tuvastamiseks ja kasutajate tegevuse jälgimiseks Redditis nii enne kui ka pärast kogukonna (subreddit) keelamist. Me kasutame lihtsat sõnasageduse erinevust, et tuvastada ebatavalisi sõnu konkreetses kogukonnas üle esindatud, mitte kahjuliku kõne esindajana, vaid kogukonna keelelise allkirjana. Me rakendame oma meetodit 15 keelatud subredditile ja leiame, et kogukonna reaktsioon on heterogeenne subredditide ja subredditi kasutajate vahel. Tippkasutajad muutusid tõenäolisemalt vähem aktiivseks üldiselt, samas kui juhuslikud kasutajad vähendasid sageli rühmasisese keele kasutamist ilma aktiivsuse vähendamata. Lõpetuseks leiame mõningaid tõendeid selle kohta, et keeldude tõhusus on kooskõlas kogukonna sisuga. Pimeda huumori kogukondade kasutajaid keelud enamasti ei mõjutanud, samas kui valge ülemvõimu ja fašismi ümber organiseeritud kogukondade kasutajad olid kõige rohkem mõjutatud. Kokkuvõttes näitavad meie tulemused, et keelud ei mõjuta kõiki rühmi ega kasutajaid võrdselt ning sillutavad teed keeluste mõju mõistmisele kogukondades.', 'fi': 'Yhteisön tason kiellot ovat yhteinen väline verkkohäirintää ja haitallista puhetta mahdollistavia ryhmiä vastaan. Valitettavasti yhteisökieltojen tehoa on tutkittu vain osittain ja tulokset vaihtelevat. Tässä tarjoamme joustavan valvomattoman menetelmän ryhmän kielen tunnistamiseen ja käyttäjien toiminnan seuraamiseen Redditissä sekä ennen yhteisön (subreddit) kieltämistä että sen jälkeen. Käytämme yksinkertaista sanataajuuden eroavaisuutta tunnistamaan epätavallisia sanoja, jotka ovat yliedustettuina tietyssä yhteisössä, ei haitallisen puheen välittäjänä vaan yhteisön kielellisenä allekirjoituksena. Sovellamme menetelmäämme 15 kiellettyyn subredditiin ja huomaamme, että yhteisön vastaus on heterogeeninen subredditien ja subredditin käyttäjien välillä. Huippukäyttäjien aktiivisuus väheni todennäköisemmin, kun taas satunnaiset käyttäjät vähensivät usein ryhmän kielen käyttöä vähentämättä aktiivisuutta. Lopuksi löydämme todisteita siitä, että kieltojen tehokkuus vastaa yhteisön sisältöä. Pimeän huumorin yhteisöt eivät vaikuttaneet kieltoihin, kun taas valkoisen ylivaltaan ja fasismin ympärille järjestäytyneiden yhteisöjen käyttäjät kärsivät eniten. Kaiken kaikkiaan tulokset osoittavat, että kiellot eivät vaikuta kaikkiin ryhmiin tai käyttäjiin tasavertaisesti ja tasoittavat tietä kieltojen vaikutusten ymmärtämiselle eri yhteisöissä.', 'ha': "Ban-da-jamii na zama zance mai ɗabi'a a kan jama'a waɗanda ke iya amfani da haramtar da magana masu cũtar da baka. Babu'am, an karanta fassarar bango na jamii kawai kuma an haɗa fassarar. Hali, Munã samar da wata shirin da ba'a tsare shi ba don mu iya gane cikin harshen jama'a kuma mu bi aikin mai amfani da shi a kan Rededit duk gaba da bayan an hana wani jamii (subrededit). We use a simple word frequency divergence to identify uncommon words overrepresented in a given community, not as a proxy for harmful speech but as a linguistic signature of the community.  Tuna amfani da hanyoyinmu zuwa 15 wanda aka ba shi ba, kuma munã gane cewa cewa cewa cewa karkacin jamii na saurari tsakanin subreddit da tsakanin mãsu amfani da wani subrededit. Mai amfani da shi na sama sun fi kusa su kasance masu ƙaranci ga farat ɗaya, da kuma masu amfani da shi daidai sun ƙara amfani da cikin lugha-ƙungiyõyi ko da ya rage aikin. Gani, za mu sãmu wasu shaidar cewa akan bango yana da abin da ke cikin jamii. Abuse of the black humor jamii was mainly haifi by bans while users of jamii organized around the same supremacy and fasistm are the most significant one. Haƙĩƙa, matsalanmu za'a nuna cewa bango bã zai yi amfani da duk jama'a ko masu amfani da shi daidai, kuma ya kange hanya dõmin ya fahimta matsayin bango a cikin jamii.", 'jv': 'Gebudhakan-Ngerawat komunitas iki bakal terus kanggo kelompok sing ditambah bantuan ngono nggawe online Ngjalaké, efek kanggo langgar-langgar wih dumadhi iki dipunangé ora bisa mlebu tentang karo winih sing ditambah. Punika, awak dhéwé ngewehke sistem sing ora nesaturan perbudhakan kanggo ngilangno kelas karo nggawe barang nggunakake sistem lan nganggep sistem yen manut lan nguasai perbudhakan kanggo nguasai komunitas (supred). Awak dhéwé éntuk sistem sing tatara awak dhéwé nggawe geraluk luwih apik lan nganggep kuwi nggawe komunitas sing gak dhéwé, ora tau ngomong proxy kanggo awak dhéwé nggawe gerakan winih, kepulang ngaweh dumadhi kaé komunitas. Awak dhéwé ngerti cara-cara awak dhéwé kanggo ngerti apa-apa kanggo kowe lan ijol-apa sing beraksi kuwi tindakan apa-apa kanggo nguasai perusahaan karo mulalah sekolah dumadhi. user Lha wih-wih, awak dhéwé ngerti nggawe barang-ngomong nik nggawe barang-ngomong nik nggawe komunitas. Awak dhéwé éntukno komunitas bumur-bumur kuwi wis rampung nik ngêdol ban-ne dipunangé perusahaan winih dhéwé, nik ngubah éntukno komunitas sing berarti gedhèwèké supaya suku lan jelaja-suku kuwi mesthi a sakjane kudu. Yowis wigatining punika, akeh sing ngomong nik nggawe aturan kuwi nggawe kelompok karo pakem, lan ngakus nyimpen kuwi tindakan kejahatan kanggo ngerasah kanggo mbelaké kanggo ngilangno komunitas.', 'sk': 'Prepovedi na ravni Skupnosti so skupno orodje proti skupinam, ki omogočajo spletno nadlegovanje in škodljiv govor. Na žalost je bila učinkovitost prepovedi skupnosti raziskana le delno in z mešanimi rezultati. Tukaj nudimo prilagodljivo, neobzorovano metodologijo za prepoznavanje jezika v skupini in sledenje aktivnosti uporabnikov na Redditu pred in po prepovedi skupnosti (subreddit). Z enostavno frekvenčno razliko besed prepoznamo nenavadne besede, ki so preveč predstavljene v določeni skupnosti, ne kot približek škodljivega govora, temveč kot jezikovni podpis skupnosti. Našo metodo uporabljamo za 15 prepovedanih subredditov in ugotavljamo, da je odziv skupnosti heterogen med subredditi in med uporabniki subreddita. Najboljši uporabniki so na splošno bolj verjetno postali manj aktivni, naključni uporabniki pa so pogosto zmanjšali uporabo jezika znotraj skupine, ne da bi zmanjšali aktivnost. Nazadnje najdemo nekaj dokazov, da je učinkovitost prepovedi usklajena z vsebino skupnosti. Prepovedi niso vplivale na uporabnike skupnosti temnega humor, najbolj pa so bili prizadeti uporabniki skupnosti, organiziranih okoli bele nadvlade in fašizma. Naši rezultati skupaj kažejo, da prepovedi ne vplivajo enako na vse skupine ali uporabnike in utrjujejo pot razumevanju učinka prepovedi v skupnostih.', 'he': 'אסורים ברמה קהילתית הם כלי משותף נגד קבוצות שמאפשרות הטרדה באינטרנט ונאום מזיק. למרבה הצער, יעילות האסורים הקהילתיים למדו רק חלקית ובתוצאות מעורבות. כאן, אנחנו מספקים מטודולוגיה גמישה ללא השגחה לזהות שפת קבוצתית ולעקוב אחרי פעילות משתמש על Reddit גם לפני ואחרי האסור של קהילה (subreddit). אנו משתמשים במחלוקת תדר מילים פשוטה כדי לזהות מילים לא רגילות מייצגות מדי בקהילה מסוימת, לא כתוכנית לנאום פגיע אלא כחתימה שפתית של הקהילה. אנו משתמשים בשיטה שלנו ל-15 תחתים אסורים, ומצאים שהתגובה הקהילתית היא heterogeneous בין תחתים ובין משתמשים של תחתים. משתמשים ראשונים היו יותר סבירים להפוך פחות פעילים באופן כללי, בעוד משתמשים אקראיים לעתים קרובות הפחידו את השימוש בשפה בקבוצה ללא פעילות קטנה. סוף סוף, אנחנו מוצאים כמה ראיות שהיעילות של אסורים מתאימה לתוכן של קהילה. Users of dark humor communities were largely unaffected by bans while users of communities organized around white supremacy and fascism were the most affected.  ביחד, התוצאות שלנו מראות שהאסורים לא משפיעים על כל קבוצות או משתמשים באופן שווה, ומפתחים את הדרך להבין את השפעה של אסורים ברחבי הקהילות.', 'bo': 'ཚོགས་སྡེའི་མཐོ་རིམ་གྱི་བཀག་དམ་དེ་ཚོ་དྲ་རྒྱ་མཐུད་བཟོ་བཅོས་དང་ཉེན་ཁ་བརྗོད་བྱེད་མཁན་གྱི་ལག་ཆ་ཡིན། ལྷུགས་མ་ཟད་པར། ཚོགས་སྡེའི་བཀག འདིར་ང་ཚོས་ཚོགས་སྡེའི་སྐད་ཡིག ང་ཚོའི་ཚོགས་སྡེའི་ནང་དུ་ཕན་རིས་བཀོད་ཅན་གྱི་ཐ་སྙད་ཆ་རྟགས་མ་འདྲ་བ་ཞིག་བེད་སྤྱི་ཚོགས་ཀྱི་ནང་དུ་ཕན་རིས་བཀོད་ཡོད་པའི་བརྗོད་རྟ ང་ཚོའི་ཐབས་ལམ་ལ་བཀག་ཡོད་པའི་རང་ཉིད་ཀྱི་ཕྱོགས་སྤྱི་ཚོགས་ཀྱི་ཆ་ཕྲན་དེ་༡༥་ལ་སྤྱོད་ཐུབ་པ་དང་། ཚོགས སྤྱོད་མཁན་གྱི་ལག་ལེན་པ་ཚོ་ཆེ་མཐོང་ནུས་མེད་བཟོ་བཅོས་པ་འདྲ་བྱུང་བ་རེད། གནད་དོན་རྣམས་སྤྱོད་མཁན་གྱི་སྤྱོད་མཁན མཐའ་མར་མ་དེར། བཀག་དམ་གྱི་ནུས་ཡོད་ཚད་ཚོགས་སྤྱི་ཚོགས་ཀྱི་ནང་དོན་ཡོད་པ་ལ་ཉེན་ཁ་ཤས་རྙེད་ཐུབ། ཚོགས་སྡེའི་ལག་ལེན་པ་ཚོའི་དགོད་ཚད་ནག་པོ་ཞིག་ཡིན་པས་ཚོགས་སྡེའི་ལག་ལེན་པ་ཚོ་རྒྱལ་ཁབ་གྱིས་ནི་བཀག་དམ་མེད་འདུག འཇིག་རྟེན། ང་ཚོའི་འབྲུག་འབྲས་བྱས་ན། བཀག་དམ་ཀྱིས་ཚོགས་སྡེ་ཚན་དང་སྤྱོད་མཁན་གྱི་ཚད་ལྡན་ཡོངས་སུ་གནོད་འགྱུར་བ་མེད་'}
{'en': 'Targets and Aspects in ', 'ar': 'أهداف وجوانب في خطاب الكراهية على مواقع التواصل الاجتماعي', 'pt': 'Alvos e Aspectos do Discurso de Ódio nas Mídias Sociais', 'fr': 'Cibles et aspects du discours de haine sur les réseaux sociaux', 'es': 'Objetivos y aspectos en el discurso de odio en las redes sociales', 'ja': 'ソーシャルメディアのヘイトスピーチのターゲットと側面', 'zh': '社交媒体怨言之所在', 'hi': 'लक्ष्य और सामाजिक मीडिया हेट स्पीच में पहलू', 'ru': 'Цели и аспекты ненавистнических высказываний в социальных сетях', 'ga': 'Spriocanna agus Gnéithe sna Meáin Shóisialta Is fuath liom Caint', 'ka': 'სოციალური მედიაში მიზეზები და აზეკტები', 'hu': 'Célok és aspektusok a közösségi média gyűlölet beszédében', 'el': 'Στόχοι και πτυχές στην ομιλία μίσους στα μέσα κοινωνικής δικτύωσης', 'it': 'Obiettivi e aspetti nel discorso di odio sui social media', 'lt': 'Social in ės žiniasklaidos neapykantos kalbos tikslai ir aspektai', 'kk': 'Социалдық медиаға қарсы сөздерінің мақсаттары мен аспектері', 'ms': 'Sasaran dan Aspekt dalam Ucapan Kebencian Media Sosial', 'mt': 'Targets and Aspects in Social Media Hate Speech', 'mk': 'Targets and Aspects in Social Media Hate Speech', 'pl': 'Cele i aspekty w mowie nienawiści mediów społecznościowych', 'ro': 'Obiective și aspecte în discursul de ură al rețelelor sociale', 'ml': 'സോഷ്യല്\u200d മീഡിയ വെറുപ്പ് സംസാരിക്കുന്ന ലക്ഷ്യങ്ങളും ഭാഷകളും', 'sr': 'Meta i aspekti u govoru o mržnji društvenim medijima', 'si': 'සාමාජික මධ්\u200dයමාධ්\u200dයම විරෝධ කතාවයේ ලක්ෂණය සහ අනතුරුවන්', 'no': 'Comment', 'so': 'Goobaha iyo aragtida ee ku qoran hadalka nebcaada sooshalka', 'sv': 'Mål och aspekter i sociala medier hattal', 'ur': 'سوسیل میڈیا ناپسند بات میں موجود اور آسپٹ', 'ta': 'சமூக ஊடகத்தில் இலக்குகள் மற்றும் பார்வைகள் வெறுப்பு பேச்சு', 'mn': 'Нийгмийн мэдээллийн дуртай ярианд зориулалт болон хариу үзүүлэлт', 'uz': 'Name', 'vi': 'Mục tiêu và khía cạnh trong tiếng nói ghét truyền thông xã hội', 'bg': 'Цели и аспекти в речта на омразата в социалните медии', 'hr': 'Ciljevi i aspekti u govoru o mržnji društvenim medijima', 'da': 'Mål og aspekter i sociale medier Had Tale', 'nl': 'Doelstellingen en aspecten in Hate Speech op sociale media', 'fa': 'هدف و اشکال در سخنرانی متنفر رسانه اجتماعی', 'ko': '소셜 미디어가 언론을 증오하는 목표와 방면', 'de': 'Ziele und Aspekte in Social Media Hate Speech', 'id': 'Targets and Aspects in Social Media Hate Speech', 'af': 'Name', 'sw': 'Tarehe na mtazamo katika Hotuba ya Kuchukia Mitandao ya Kijamii', 'tr': 'Sosyal Maglumaty nyň sözlerinde maksadlar we aspektler', 'hy': 'Սոցիալական լրատվամիջոցների ատելության խոսքի նպատակները և հարցերը', 'az': 'Sosyal Media Nefr톛ti S칬zl톛rind톛 He칞 v톛 Aspektl톛r', 'am': 'ማኅበራዊ ሚዲያ ውስጥ የሚጠሉ ቃላት እና ጉዳዮች', 'sq': 'Objektivi dhe aspektet në fjalimin e urrejtjes së medias sociale', 'bn': 'সামাজিক প্রচার মাধ্যমের লক্ষ্য এবং দৃষ্টিভঙ্গি ঘৃণা ভাষণ', 'cs': 'Cíle a aspekty v projevu nenávisti sociálních médií', 'bs': 'Ciljevi i aspekti u govoru o mržnji društvenim medijima', 'et': 'Sotsiaalmeedia vihkamise kõne eesmärgid ja aspektid', 'fi': 'Sosiaalisen median vihapuheen tavoitteet ja näkökulmat', 'ca': "Els objectius i aspectes del discurs d'odi dels mitjans socials", 'jv': 'TarGet lan Aspect nang Panjenengan Media Normal', 'sk': 'Cilji in vidiki sovražnega govora na družbenih medijih', 'he': 'מטרות ואפקטים במדיה החברתית', 'ha': 'Target and Aspects in Jamii Media Hate Spelling', 'bo': 'སྤྱི་ཚོགས་འབྲེལ་མཐུད་འབྲེལ་མཐུད་བརྗོད་ལ་འགྲོ་སྟངས་དང་Aspects'}
{'en': 'Mainstream research on ', 'ar': 'ركزت الأبحاث السائدة حول خطاب الكراهية بشكل رئيسي حتى الآن على مهمة تصنيف منشورات وسائل التواصل الاجتماعي بشكل أساسي فيما يتعلق بالأنماط المحددة مسبقًا لفئات خطاب الكراهية الرديئة إلى حد ما. قد يكون هذا كافيًا إذا كان الهدف هو اكتشاف وحذف مشاركات اللغة المسيئة. ومع ذلك ، فإن الإزالة ليست ممكنة دائمًا بسبب تشريعات الدولة. كما أن هناك أدلة على أن خطاب الكراهية لا يمكن مكافحته بنجاح بمجرد إزالة منشورات الكلام الذي يحض على الكراهية ؛ يجب مواجهتهم بالتثقيف والروايات المضادة. لهذا الغرض ، نحتاج إلى تحديد (1) من هو الهدف في منشور خطاب كراهية معين ، و (2) ما هي جوانب (أو خصائص) الهدف المنسوبة إلى الهدف في المنشور. كأول تقدير تقريبي ، نقترح تكييف نموذج استخراج مفهوم عام حديث مع مجال خطاب الكراهية. نتائج التجارب واعدة ويمكن أن تكون مصدر إلهام لمزيد من العمل في المهمة', 'es': 'La investigación general sobre la incitación al odio se centró hasta ahora predominantemente en la tarea de clasificar principalmente las publicaciones en las redes sociales con respecto a tipologías predefinidas de categorías de discurso de odio bastante groseras. Esto puede ser suficiente si el objetivo es detectar y eliminar publicaciones en idiomas abusivos. Sin embargo, la expulsión no siempre es posible debido a la legislación de un país. Además, hay pruebas de que la incitación al odio no se puede combatir con éxito simplemente eliminando los mensajes de incitación al odio; deben contrarrestarse con educación y contra-narrativas. Para ello, necesitamos identificar (i) quién es el objetivo en una publicación de discurso de odio determinada, y (ii) qué aspectos (o características) del objetivo se atribuyen al objetivo en la publicación. Como primera aproximación, proponemos adaptar un modelo genérico de extracción de conceptos de última generación al dominio de la incitación al odio. El resultado de los experimentos es prometedor y puede servir de inspiración para seguir trabajando en la tarea.', 'fr': "La recherche courante sur le discours de haine s'est concentrée jusqu'à présent principalement sur la tâche de classer principalement les publications sur les réseaux sociaux en fonction de typologies prédéfinies de catégories de discours de haine plutôt grossières. Cela peut être suffisant si l'objectif est de détecter et de supprimer les publications linguistiques abusives. Toutefois, le renvoi n'est pas toujours possible en raison de la législation d'un pays. En outre, il est prouvé que les discours de haine ne peuvent pas être combattus avec succès en supprimant simplement les messages de haine\xa0; ils devraient être contrés par l'éducation et les contre-discours. À cette fin, nous devons identifier (i) qui est la cible dans un message de discours haineux donné, et (ii) quels aspects (ou caractéristiques) de la cible sont attribués à la cible dans la publication. En première approximation, nous proposons d'adapter un modèle générique d'extraction de concepts de pointe au domaine des discours haineux. Les résultats des expériences sont prometteurs et peuvent servir d'inspiration pour la poursuite des travaux sur cette tâche.", 'pt': 'A principal pesquisa sobre discurso de ódio se concentrou até agora predominantemente na tarefa de classificar principalmente postagens de mídia social em relação a tipologias predefinidas de categorias de discurso de ódio bastante grosseiras. Isso pode ser suficiente se o objetivo for detectar e excluir postagens de linguagem abusiva. No entanto, a remoção nem sempre é possível devido à legislação de um país. Além disso, há evidências de que o discurso de ódio não pode ser combatido com sucesso simplesmente removendo postagens de discurso de ódio; eles devem ser combatidos pela educação e contra-narrativas. Para isso, precisamos identificar (i) quem é o alvo em um determinado post de discurso de ódio e (ii) quais aspectos (ou características) do alvo são atribuídos ao alvo no post. Como primeira aproximação, propomos adaptar um modelo genérico de extração de conceitos de última geração para o domínio do discurso de ódio. O resultado dos experimentos é promissor e pode servir de inspiração para futuros trabalhos na tarefa', 'ja': 'これまでのヘイトスピーチに関する主流の研究は、主にソーシャルメディアの投稿を、かなり粗い粒度のヘイトスピーチカテゴリの事前定義された類型に関連して分類する作業に焦点を当てていた。これは、罵倒的な言葉の投稿を検出して削除することを目的としている場合には十分な場合があります。ただし、国の法律により、必ずしも除外が可能ではありません。また、ヘイトスピーチの投稿を削除するだけでは、ヘイトスピーチに対抗できないという証拠があります。それらは教育や反論で対抗すべきです。この目的のためには、(i)特定のヘイトスピーチ投稿のターゲットは誰か、(ii)ターゲットのどの側面（または特徴）が投稿のターゲットに帰属するかを特定する必要があります。最初の近似として、一般的な最先端の概念抽出モデルをヘイトスピーチ領域に適応させることを提案します。実験の結果は有望であり、タスクに関するさらなる作業のインスピレーションとなる可能性がある', 'zh': '及目前为止,仇言之主,归于社交媒体帖粗恶之预定义分类也。 若检删骂性语言帖子,庶几足矣。 然国家立法,删之不可常得也。 此外,有证明,但以删仇言帖,无以成功击怨之言。 教反难之。 须定(i)谁是给定恨言帖中的,及(ii)的哪些方面(或特征)归因于帖子中的。 为首近似值,议取通用最先进之概于仇言之域。 实验果有望,可以为事。', 'ru': 'Основное исследование ненавистнических высказываний до сих пор было сосредоточено преимущественно на задаче классификации в основном постов в социальных сетях в отношении предопределенных типологий довольно грубо выраженных категорий ненавистнических высказываний. Этого может быть достаточно, если цель заключается в выявлении и удалении оскорбительных лингвистических постов. Однако выдворение не всегда возможно из-за законодательства страны. Кроме того, есть свидетельства того, что с ненавистническими высказываниями нельзя успешно бороться, просто удалив сообщения о ненавистнических высказываниях; им следует противостоять с помощью образования и контрнаративов. Для этого нам нужно определить (i), кто является целью в данной публикации с высказываниями на почве ненависти, и (ii) какие аспекты (или характеристики) цели приписываются цели в записи. В качестве первого приближения мы предлагаем адаптировать универсальную современную модель извлечения понятий к области ненавистнических высказываний. Результаты экспериментов являются многообещающими и могут послужить вдохновением для дальнейшей работы над задачей', 'hi': 'हेट स्पीच पर मुख्यधारा के शोध ने अब तक मुख्य रूप से मुख्य रूप से सोशल मीडिया पोस्ट को वर्गीकृत करने के कार्य पर ध्यान केंद्रित किया है, बल्कि मोटे-दाने वाले घृणा भाषण श्रेणियों के पूर्वनिर्धारित टाइपोलॉजी के संबंध में। यह पर्याप्त हो सकता है यदि लक्ष्य अपमानजनक भाषा पोस्ट का पता लगाने और हटाने के लिए है। हालांकि, किसी देश के कानून के कारण निष्कासन हमेशा संभव नहीं होता है। इसके अलावा, इस बात के सबूत हैं कि हेट स्पीच को केवल हेट स्पीच पोस्ट को हटाकर सफलतापूर्वक मुकाबला नहीं किया जा सकता है; उन्हें शिक्षा और प्रति-कथाओं द्वारा मुकाबला किया जाना चाहिए। इस उद्देश्य के लिए, हमें यह पहचानने की आवश्यकता है (i) किसी दिए गए हेट स्पीच पोस्ट में लक्ष्य कौन है, और (ii) लक्ष्य के किन पहलुओं (या विशेषताओं) को पोस्ट में लक्ष्य के लिए जिम्मेदार ठहराया जाता है। पहले सन्निकटन के रूप में, हम नफरत भाषण डोमेन के लिए एक सामान्य राज्य के कला अवधारणा निष्कर्षण मॉडल को अनुकूलित करने का प्रस्ताव करते हैं। प्रयोगों का परिणाम आशाजनक है और कार्य पर आगे के काम के लिए प्रेरणा के रूप में काम कर सकता है', 'ga': 'Dhírigh taighde príomhshrutha ar chaint fuath go dtí seo go príomha ar an tasc a bhaineann le postálacha meán sóisialta a rangú go príomha maidir le tíopeolaíochtaí réamhshainithe de chatagóirí gráin chainte atá sách garbh. B’fhéidir gur leor é seo más é an sprioc postálacha teanga maslacha a bhrath agus a scriosadh. Mar sin féin, ní féidir é a bhaint i gcónaí mar gheall ar reachtaíocht tíre. Chomh maith leis sin, tá fianaise ann nach féidir fuathchaint a chomhrac go rathúil trí phoist fuathchaint a bhaint; ba chóir go gcuirfeadh oideachas agus frith-inscne ina gcoinne. Chun na críche sin, ní mór dúinn a aithint (i) cé hé/hí an sprioc i bpost cainte gráin tugtha, agus (ii) cad iad na gnéithe (nó tréithe) den sprioc a chuirtear i leith na sprice sa phost. Mar an chéad mheastachán, tá sé beartaithe againn samhail eastósctha coincheap úrscothach cineálach a oiriúnú don fhearann fuathchaint. Tá toradh na dturgnaimh dóchasach agus féadann sé bheith mar inspioráid le haghaidh tuilleadh oibre ar an tasc', 'hu': 'A gyűlöletbeszéd általános kutatásai eddig elsősorban a közösségi média posztok osztályozásának feladatára összpontosították a meglehetősen durva szemű gyűlöletbeszéd kategóriák előre meghatározott tipológiáinak tekintetében. Ez elegendő lehet, ha a cél a visszaélő nyelvi bejegyzések észlelése és törlése. Az eltávolítás azonban nem mindig lehetséges egy ország jogszabályai miatt. Továbbá bizonyíték van arra, hogy a gyűlöletbeszéd nem küzdhető sikeresen a gyűlöletbeszéd bejegyzéseinek pusztán eltávolításával; oktatásnak és ellennarratíváknak kell ellensúlyozniuk őket. Ebből a célból azonosítani kell (i) ki a célpont egy adott gyűlöletbeszéd posztban, és (ii) a célpont milyen aspektusait (vagy jellemzőit) tulajdonítják a célpontnak a posztban. Első közelítésként azt javasoljuk, hogy egy általános, korszerű koncepciókivonási modellt adaptáljunk a gyűlölet beszéd területéhez. A kísérletek eredménye ígéretes és inspirációként szolgálhat a feladat további munkájához', 'el': 'Η κύρια έρευνα για την ρητορική μίσους επικεντρώθηκε μέχρι στιγμής κυρίως στην ταξινόμηση των δημοσιεύσεων στα μέσα κοινωνικής δικτύωσης σε σχέση με προκαθορισμένες τυπολογίες μάλλον χονδροειδείς κατηγορίες ρητορικής μίσους. Αυτό μπορεί να είναι αρκετό εάν ο στόχος είναι ο εντοπισμός και η διαγραφή καταχρηστικών γλωσσικών δημοσιεύσεων. Ωστόσο, η απομάκρυνση δεν είναι πάντα δυνατή λόγω της νομοθεσίας μιας χώρας. Επίσης, υπάρχουν αποδείξεις ότι η ρητορική μίσους δεν μπορεί να καταπολεμηθεί επιτυχώς καταργώντας απλώς δημοσιεύσεις ρητορικής μίσους. Θα πρέπει να αντιμετωπιστούν με εκπαίδευση και αντιπαράθεση. Για το σκοπό αυτό, πρέπει να προσδιορίσουμε (i) ποιος είναι ο στόχος σε μια συγκεκριμένη δημοσίευση ομιλίας μίσους και (ii) ποιες πτυχές (ή χαρακτηριστικά) του στόχου αποδίδονται στον στόχο στη δημοσίευση. Ως πρώτη προσέγγιση, προτείνουμε την προσαρμογή ενός γενικού μοντέλου εξαγωγής εννοιών τελευταίας τεχνολογίας στον τομέα της ομιλίας μίσους. Το αποτέλεσμα των πειραμάτων είναι ελπιδοφόρο και μπορεί να χρησιμεύσει ως έμπνευση για περαιτέρω εργασία στο έργο.', 'lt': 'Pagrindiniai neapykantos kalbos moksliniai tyrimai iki šiol daugiausia buvo susiję su užduotimi klasifikuoti daugiausia socialinės žiniasklaidos pareigas iš anksto apibrėžtų neapykantos kalbos kategorijų tipologijų atžvilgiu. Tai gali pakakti, jei tikslas – nustatyti ir ištrinti piktnaudžiaujančius kalbinius postus. Tačiau dėl šalies teisės aktų pašalinimas ne visada įmanomas. Be to, yra įrodymų, kad neapykantos kalbos negalima sėkmingai kovoti tik pašalinant neapykantos kalbos pareigas; jiems turėtų būti taikomos švietimo ir priešpriešinės narracijos. Šiuo tikslu turime nustatyti i) kas yra tikslinis tam tikroje neapykantos kalbos vietoje ir ii) kokie tikslinio rodiklio aspektai (arba savybės) priskiriami tiksliniam pareigūnui. Kaip pirmasis suderinimas siūlome pritaikyti generinį naujausios koncepcijos ekstrahavimo model į prie neapykantos kalbos srities. The outcome of the experiments is promising and can serve as inspiration for further work on the task', 'it': "La ricerca principale sul discorso d'odio si è finora concentrata prevalentemente sul compito di classificare principalmente i post sui social media rispetto a tipologie predefinite di categorie di discorsi d'odio piuttosto grossolani. Questo può essere sufficiente se l'obiettivo è rilevare ed eliminare messaggi in lingua abusiva. Tuttavia, la rimozione non è sempre possibile a causa della legislazione di un paese. Inoltre, ci sono prove che i discorsi di odio non possono essere combattuti con successo semplicemente rimuovendo i messaggi di incitamento all'odio; dovrebbero essere contrastate dall'educazione e dalle contronarrazioni. A tal fine, dobbiamo identificare (i) chi è il bersaglio in un determinato post di incitamento all'odio, e (ii) quali aspetti (o caratteristiche) del bersaglio sono attribuiti al bersaglio nel post. Come prima approssimazione, proponiamo di adattare un modello generico di estrazione di concetti all'avanguardia al dominio dell'incitamento all'odio. Il risultato degli esperimenti è promettente e può servire da ispirazione per ulteriori lavori sul compito", 'mk': 'Главните истражувања за говорот на омраза се фокусираа досега претежно на задачата да се класификуваат главно позиции на социјалните медиуми во однос на преддефинираните типологии на прилично груби категории на говор на омраза. Ова може да биде доволно ако целта е да се откријат и избришат злоупотребни јазички постови. Сепак, отстранувањето не е секогаш можно поради легислативата на една земја. Исто така, постојат докази дека говорот за омраза не може да биде успешно борен само со отстранување на местата за говор за омраза; тие треба да се спротивстават од образование и контра-приказни. За оваа цел, мораме да идентификуваме (i) кој е метата во одредена позиција за говор на омраза, и (ii) кои аспекти (или карактеристики) на метата се припишани на метата во позицијата. Како прва приближување, предлагаме да се адаптира генерален модел на екстракција на најнов концепт на доменот на говорот за омраза. Резултатот на експериментите е ветувачки и може да служи како инспирација за понатамошна работа на задачата', 'ms': 'Penyelidikan utama tentang ucapan kebencian fokus sejauh ini terutama pada tugas untuk mengklasifikasikan terutamanya pos media sosial mengenai tipologi terdefinisi bagi kategori ucapan kebencian yang agak besar. Ini mungkin cukup jika tujuan adalah untuk mengesan dan menghapuskan pos bahasa yang mengganggu. However, removal is not always possible due to the legislation of a country.  Juga ada bukti bahawa ucapan kebencian tidak dapat berjaya melawan dengan hanya menghapuskan pos ucapan kebencian; seharusnya dihadapi oleh pendidikan dan kontranarrativ. Untuk tujuan in i, kita perlu mengenalpasti (i) siapa sasaran dalam pos ucapan kebencian tertentu, dan (ii) apa aspek (atau ciri-ciri) sasaran ditakrif kepada sasaran dalam pos. As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain.  Hasil eksperimen adalah berjanji dan boleh bertindak sebagai inspirasi untuk kerja lanjut dalam tugas', 'kk': 'Жарамсыз сөйлесу туралы негізгі зерттеулері көбірек әлемдегі социалдық медиа жіберіліктерін алдын- ала анықталған тифологияларға көмектеседі. Бұл мақсат жеткілікті тіл поштасын табу және өшіру мүмкін. Бірақ елдің саясатының себебі өшіру әрқашан мүмкін емес. Сонымен қатар, жек сөйлейтін сөйлейтіні тек жек сөйлейтіні өшіруге болмайды. Олар білім беру және қарсы оқиғалар бойынша қарсы болу керек. Бұл мақсат үшін біз (i) келтірілген сөйлеу поштасының мақсатын анықтау керек, ii) мақсатының (немесе қасиеттері) мақсатына таңдау керек. Бірінші жақсарту үшін, біз өзгерту доменіне жалпы күй- жағдайының түрлендіру үлгісін өзгертуге ұсынамыз. Тәжірибелердің нәтижесі - мұғатты жұмыс істеу және тапсырмасының жаңа істеу үшін', 'ml': 'വെറുപ്പ് സംസാരിക്കുന്നതിനെ പ്രധാനപ്പെടുത്തുന്ന പദ്ധതികള്\u200d പ്രധാനപ്പെട്ട സാമൂഹ്യ മാധ്യമങ്ങളുടെ പോസ്റ്റുകള്\u200d വിശദീകരിക്കുന് അപകടത്തിലുള്ള ഭാഷ പോസ്റ്റുകള്\u200d കണ്ടുപിടിക്കുകയും നീക്കം ചെയ്യുന്നതിനുള്ള ലക്ഷ്യം ഇത് മതി. എന്നാലും ഒരു രാജ്യത്തെ നിയമം കാരണം നീക്കം എപ്പോഴും സാധ്യമല്ല. വെറുപ്പ് സംസാരം മാത്രമേ വെറുപ്പ് സംസാരിക്കുകയുള്ളൂ എന്ന് തെളിവുകളുണ്ട്; വിദ്യാഭ്യാസത്തിന്റെയും വിരോധകഥകളിലെയും അവരെ എതിര്\u200dത്തണം. അതിനുവേണ്ടി നമുക്ക് ലക്ഷ്യം തിരിച്ചറിയേണ്ടതുണ്ട് (i) കൊടുത്ത വെറുപ്പ് സംസാര പോസ്റ്റില്\u200d ആരാണെന്നും, എന്നിട്ട് (ii) ലക്ഷ്യത്തിന്\u200dറെ ലക് ആദ്യത്തെ ആദ്യത്തെ അടുത്തുചേര്\u200dന്നപ്പോള്\u200d, നമ്മള്\u200d ഒരു സാധാരണ സ്ഥാനത്തിന്റെ സാമാന്യത്തിലേക്ക് പ്രാപ്തി ചെയ്യുന്നു.  പരീക്ഷണങ്ങളുടെ ഫലം വാഗ്ദാനം ചെയ്യുന്നതും ജോലിയില്\u200d കൂടുതല്\u200d ജോലി ചെയ്യുന്നതിനായി പ്രബോധനം ചെയ്', 'mt': 'Mainstream research on hate speech focused so far predominantly on the task of classifying mainly social media posts with respect to predefined typologies of rather coarse-grained hate speech categories.  This may be sufficient if the goal is to detect and delete abusive language posts.  Madankollu, it-tneħħija mhux dejjem possibbli minħabba l-leġiżlazzjoni ta’ pajjiż. Barra minn hekk, hemm evidenza li d-diskors ta’ mibegħda ma jistax jiġi miġġieled b’suċċess billi jitneħħew biss il-karigi ta’ diskors ta’ mibegħda; għandhom jiġu miġġielda minn edukazzjoni u kontro-narrattivi. For this purpose, we need to identify (i) who is the target in a given hate speech post, and (ii) what aspects (or characteristics) of the target are attributed to the target in the post.  Bħala l-ewwel approssimazzjoni, nipproponu li jiġi adattat mudell ġeneriku ta’ estrazzjoni ta’ kunċett avvanzat għad-dominju tad-diskors ta’ mibegħda. The outcome of the experiments is promising and can serve as inspiration for further work on the task', 'no': 'Første forskning om hatespråk fokuserte så langt hovudsakelig på oppgåva om å klassifisera hovudsakelig sosiale mediepost med hensyn til føredefinerte typologiar av ganske kryssa hatespråk- kategoriar. Dette kan vera nok dersom målet er å oppdaga og sletta abusive språkpost. Men fjerning er ikkje alltid mogleg på grunn av lovgivnaden til eit land. Det finst også bevis at hatespråk kan ikkje kommunerast med suksess ved å fjerna berre hatespråkpost. dei bør teljast med utdanning og mottaler. For dette målet må vi identifisera i) kva som er målet i ei gitt hatespråkpost, og ii) kva aspektar (eller karakteristikk) av målet er attributta til målet i posten. Som den første nærminga, foreslår vi å tilpassa eit generiske tilstand av kunstkonseptutpakkingsmodul til hatt-taledomenet. Utgåva av eksperimentene er sverdig og kan kalla som inspirasjon for meir arbeid på oppgåva', 'mn': 'Харамсалтай ярианы үндсэн судалгаагаар ихэвчлэн нийгмийн мэдээллийн захирал дээр ихэвчлэн хэлэлцдэг хэлбэрүүдийн илэрхийлэл дээр анхаарлаа хандуулсан. Хэрэв зорилго нь хүчирхийллэг хэлний захирагдалуудыг олох, устгах юм бол энэ хангалттай байж болох юм. Гэхдээ улс орны хуулийн шалтгаан үргэлж устгах боломжгүй. Мөн үзэн ядах илтгэлийг зөвхөн үзэн ядах илтгэлийг устгаж амжилттай зохицуулж чадахгүй гэдгийг баталгаатай байдаг. боловсрол, эсрэг түүхийн тулд тэднийг тодорхойлж чадна. Ийм зорилго дээр бид (i) хэн зөрчилдөөн ярианы захиралд зорилготой бөгөөд (ii) зорилготнуудын хэн асуудлыг тайлбарлах хэрэгтэй. Эхний хамгийн ойртох үед бид үзэн ядах ярианы сүлжээнд ерөнхий хувьд урлагийн загвар гаргах загварыг зохицуулахыг санал болно. Эдгээр туршилтын үр дүнг нь амлалтай, ажлын дасгал ажиллах урам зориг болгож,', 'pl': 'Główne badania nad mową nienawiści skupiały się dotychczas głównie na zadaniu klasyfikowania głównie postów w mediach społecznościowych w odniesieniu do predefiniowanych typologii raczej gruboziarnistych kategorii mowy nienawiści. Może to być wystarczające, jeśli celem jest wykrycie i usuwanie nieprawidłowych postów językowych. Jednak wyprowadzka nie zawsze jest możliwa ze względu na ustawodawstwo danego kraju. Istnieją również dowody na to, że mowa nienawiści nie może być skutecznie zwalczana poprzez jedyne usunięcie postów o mowie nienawiści; Należy im przeciwdziałać edukacja i kontrnarracje. W tym celu musimy zidentyfikować (i) kto jest celem w danym wpisie do mowy nienawiści oraz (ii) jakie aspekty (lub cechy) celu są przypisywane celowi w poście. Jako pierwsze przybliżenie proponujemy dostosowanie ogólnego najnowocześniejszego modelu ekstrakcji koncepcji do domeny mowy nienawiści. Wynik eksperymentów jest obiecujący i może służyć jako inspiracja do dalszych prac nad zadaniem', 'ro': 'Cercetările principale privind discursul la ură s-au concentrat până în prezent în principal pe sarcina de a clasifica postările în principal pe rețelele de socializare în raport cu tipologiile predefinite ale categoriilor de discursuri la ură destul de grosiere. Acest lucru poate fi suficient dacă scopul este detectarea și ștergerea mesajelor în limba abuzivă. Cu toate acestea, eliminarea nu este întotdeauna posibilă datorită legislației unei țări. De asemenea, există dovezi că discursul de ură nu poate fi combătut cu succes prin simpla eliminare a mesajelor de discurs de ură; ar trebui să fie contracarate de educaţie şi contranaraţiuni. În acest scop, trebuie să identificăm (i) cine este ținta într-un anumit post de discurs de ură și (ii) ce aspecte (sau caracteristici) ale țintei sunt atribuite țintei în post. Ca prima aproximare, propunem adaptarea unui model generic de extracție a conceptului de ultimă generație la domeniul discursului de ură. Rezultatul experimentelor este promițător și poate servi drept inspirație pentru lucrările ulterioare la sarcină', 'sr': 'Obično istraživanje o govoru mržnje usredotočilo se do sada predstavno na zadatak klasifikacije uglavnom postova društvenih medija u pogledu predodređenih tipologa kategorija razgovora mržnje. To bi moglo biti dovoljno ako je cilj otkrivanje i izbrisanje nasilnih jezičkih postova. Međutim, uklanjanje nije uvek moguće zbog zakonodavstva zemlje. Takođe, postoje dokazi da govor mržnje ne može biti uspešno borjen samo uklanjanjem govornih postova mržnje; Trebalo bi da se raèunaju obrazovanjem i protivnim prièama. Za ovu svrhu moramo da identifikujemo i) koji je meta u određenom postu govora mržnje, i ii) koji aspekti (ili karakteristike) mete pripisuju meti na postu. Kao prvi približavanje, predlažemo da se prilagodimo generički model izvlačenja koncepta umjetnosti na domenu govora mržnje. Rezultat eksperimenata obećava i može biti inspiracija za daljnji posao na zadatku.', 'so': 'Mainstream research on hate speech focused so far predominantly on the task of classifying mainly social media posts with respect to predefined typologies of rather coarse-grained hate speech categories.  Waxaa ku filan kara haddii goalku yahay in la ogaado oo la deleto boostada afka caafimaadka ah. Si kastaba ha ahaatee guurista ma suurtogal karo sharciga wadanka darteed. Sidoo kale waxaa jira markhaati aan hadalka nebcaan liibaansan karin in la dagaallamo fursado hadalka nacayb oo keliya; waxaa waajib ah in ay iskuul iyo sheekooyin ka gees ah looga jeedo. Sababtaas darteed waa inaannu aqoonsanno (i) kaalmo ku leennahay warqada hadalka nebcaada iyo (ii) qaybaha ay ku leeyihiin waxyaabaha ay ku leeyihiin hagitaanka. Sida ugu horeysa, waxaynu soo jeedaynaa in aan u beddelno qaabab caadi ah oo ah qorshaha la soo saaro farshaxanka, si aan ugu beddelno xafiiska hadalka nebcaada. Imtixaanka dhamaadkeedu waa wax ballan ah, wuxuuna u shaqeyn karaa waxyaabaha la siiyo shaqada dheeraad ah ee shaqada', 'si': 'ප්\u200dරධාන පරීක්ෂණය විරුද්ධ කතාවට ප්\u200dරධාන පරීක්ෂණය විශ්වාස කරලා තියෙන්නේ ඉතින් විශේෂයේ සාමාජික මාධ්\u200dයමාධ්\u200dයම පොස්ට මේක පුළුවන් වෙන්න පුළුවන් ඉලක්කය හොයාගන්න සහ මතක කරන්න. නමුත්, හැමවෙලේම දේශයක් නියෝජනය නිසා අතිරික්ෂණය කරන්න පුළුවන් නෑ. ඒවගේම, ප්\u200dරශ්න සාක්ෂියක් තියෙනවා කියලා වෛර කතාව සමහරවිට සටන් කරන්න බෑ කියලා, වෛර කතාව පොස් ඔවුන්ට ශික්ෂණය සහ කතාවක් විරුද්ධ වෙන්න ඕනි. මේ අදහසට, අපිට අවශ්\u200dයයි (i) කවුද කියලා දැනගත්ත වෛර කතා පොස්ට් වල ඉලක්කයක් තියෙන්න ඕනේ, ඒ වගේම (i) ඉලක්කයේ පොස්ට් වල ඉලක්ක මුලින්ම සම්බන්ධ වෙනුවෙන්, අපි සාමාන්\u200dය ස්ථානයක් සම්බන්ධ කරන්න ප්\u200dරයෝජනය කරනවා කියලා පරීක්ෂණයේ ප්\u200dරතිචාරයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් ඒ වගේම තවත් වැඩේ වැඩ කරන්න පුළුවන්', 'sv': 'Den huvudsakliga forskningen om hatpropaganda fokuserade hittills främst på uppgiften att klassificera främst sociala medier inlägg med avseende på fördefinierade typologier av ganska grovkorniga hattalskategorier. Detta kan vara tillräckligt om målet är att upptäcka och ta bort kränkande språkinlägg. Men avlägsnande är inte alltid möjligt på grund av lagstiftningen i ett land. Det finns också bevis för att hatpropaganda inte kan bekämpas framgångsrikt genom att bara ta bort hatinlägg. De bör motverkas av utbildning och motberättelser. För detta ändamål behöver vi identifiera (i) vem som är målet i ett visst hattal inlägg, och (ii) vilka aspekter (eller egenskaper) av målet som tillskrivs målet i inlägget. Som den första approximationen föreslår vi att en generisk state-of-the-art modell för konceptutvinning anpassas till hattalsdomänen. Resultatet av experimenten är lovande och kan tjäna som inspiration för vidare arbete med uppgiften', 'ta': 'வெறுப்பு பேச்சின் முக்கியமாக முக்கியமாக பொருட்களை வகைப்படுத்துவதற்கு முன்னால் வெறுப்பு பேச்சு வகைப்படுத்தும் வேலையில் முக்கியமா இலக்கு தேவையான மொழியை கண்டுபிடிக்க மற்றும் நீக்குவதற்கு இது போதுமானதாக இருக்கலாம். ஆனால், நாட்டின் சட்டத்தினால் எப்போதும் நீக்க முடியாது. மற்றும், வெறுப்பு பேச்சு வெறுப்பு பேச்சு வெற்றிகரமாக போராட முடியாது என்று தெளிவான அத்தாட்சிகள்  கல்வி மற்றும் எதிர்மறை கதைகளை எதிர்பார்க்க வேண்டும். For this purpose, we need to identify (i) who is the target in a given hate speech post, and (ii) what aspects (or characteristics) of the target are attributed to the target in the post.  முதல் சுருக்கம் என்றால், நாம் ஒரு பொதுவான நிலையை மாற்ற வேண்டும் என்று பரிந்துரைக்கிறோம் வெறுப்பு பேச்சு தளத்திற் பரிசோதனைகளின் முடிவு', 'ur': 'ناپسندیدہ بات کے متعلق اصلی تحقیقات کا ذریعہ یہاں تک پہلی بار سوسیل میڈیا پوسٹ کا کلاس کرنا ہے جو بہت زیادہ ناپسندیدہ بات کا کلاس کرنا ہے۔ یہ کافی ہو سکتا ہے اگر موقع یہ ہے کہ زبان پوسٹوں کو پہچان اور ٹال دینا چاہے۔ لیکن ہمیشہ ملک کی قوانین کے باعث ہمیشہ ہٹنا ممکن نہیں ہے۔ اور کچھ نشانیاں بھی ہیں کہ ناپسند بات کو صرف ناپسند بات کی باتوں کو دور کرنے کے ذریعہ نہیں پہنچا سکتی۔ انہیں تعلیم اور مخالف داستان کے ذریعہ شمار کرنا چاہیے۔ اس لئے ہمیں معلوم ہونا چاہیے کہ (i) کس کا مقصد مقرر کیا گیا ہے؟ اور (ii) مقصد کا مقصد کس کا مقصد مقرر کیا گیا ہے؟ پہلی نزدیک کی حالت میں، ہم ایک عمومی موقعیت کے مطابق مخالف بات ڈمین کے لئے اضافہ کرنے کے لئے پیشنهاد کرتے ہیں. آزمائش کا نتیجہ وعدہ کرتا ہے اور اس کام پر اضافہ کرتا ہے', 'ka': 'სამყარო სიტყვების ძირითადი შესწავლობა, რომელიც სამყარო სიტყვების კლასიფიკაციას უფრო მეტად სოციალური მედია პოსტის კლასიფიკაციას, რომელიც უფრო განსაზღვრებული ტიპოლოგიების ეს შეიძლება იყოს, თუ მიზეზი იგივეა, რომ ძალიან ძალიან ძალიან სიტყვის პოსტის განახსნა და წაშლა. მაგრამ არ ყოველთვის შესაძლებელია გადასვლა ქვეყანის законодательства. ასევე, არსებობს წარმოდგენები, რომ მპატის სიტყვა არ შეიძლება წარმოდგენა მხოლოდ მპატიური სიტყვას წარმოდგენით; ისინი უნდა განახლება და კონტრატიურებით შეცვლა. ამ მიზეზისთვის, ჩვენ უნდა განვიცნოთ, რომელიც არის მიზეზი მიზეზი მიზეზის პოსტში, და i i) რომელიც მიზეზი (ან მიზეზები) მიზეზით მიზეზის მიზეზით პოსტში. როგორც პირველი დაბრუნება, ჩვენ მინდომებით გავაკეთოთ სულისხმების კონცექტის ექსტრექციის მოდელის განმავლობა. ექსპერიმენტების შედეგება იქნება საკუთარი მუშაობა და შესაძლებელია იქნება ინგრექცია დამატებული მუშაობაზე', 'vi': 'Nghiên cứu chủ yếu về ngôn ngữ ghét đến nay chủ yếu tập trung vào nhiệm vụ phân loại các bài phát biểu căm ghét chủ yếu xã hội với những hạng mục đã xác định trước. Điều này có thể là đủ nếu mục tiêu là phát hiện và xóa các bài viết ngôn ngữ lạm dụng. Tuy nhiên, không phải lúc nào cũng có thể loại trừ vì luật pháp của một quốc gia. Ngoài ra, có bằng chứng rằng bài phát biểu căm ghét không thể thành công bằng việc đơn thuần là xóa bỏ các bài phát biểu căm ghét; họ nên bị ngăn lại bởi giáo dục và phản thuật. Để đạt được mục đích, chúng ta cần xác định: i) ai là mục tiêu trong một bài phát biểu căm ghét, và (II) các khía cạnh (hay đặc đi ểm) của mục tiêu được gán cho mục tiêu trong bài báo. Là một khả năng gần nhất, chúng tôi đề nghị thích ứng một mô hình khái niệm kiểu mẫu cũ kĩ theo kiểu trích xuất ghét ngôn ngữ. Kết quả của thí nghiệm là đầy hứa hẹn và có thể là nguồn cảm hứng cho công việc tiếp theo', 'uz': "Hat so'zlari haqida o'zgarishni o'zgartirish, aslida asosiy jamiyat medya postlarini o'rganish vazifasi o'zgartiradi, o'sha paytda qo'llangan yolg'onlarning turlarini o'zgartiradi. Agar qanday maqsad aniqlanish va oʻchirish mumkin boʻlishi mumkin. Lekin, davlatning қонунлиги сабабидан доимо кўчириш имкон эмас. Шунингдек, ҳужжатлар мавжуд, ҳужжатлар мавжуд, қизиқ сўзларни ўчириш учун муваффақиятсиз муваффақиятга олиб кела олмайди. ularni ta'lim va ko'paytlarni boshqarish kerak. Bu sababda, biz quyidagi xavfsiz pochta qoidadagi maqolani aniqlash kerak va (i) jadvalning ma'lumotlari (yoki qoidalar) qoidadagi maqolaga qanday belgilangan. Birinchi taxminan bo'lsangiz, biz yolg'on soʻzning umumiy holatini o'zgartirib chiqarish modeli yolg'on gapirish domenasiga o'zgartirishni talab qilamiz. Tajribalarning natijasi ishni bajarishi mumkin va vazifani davom etishga iloji mumkin.", 'nl': 'Mainstream onderzoek naar haatspraak richtte zich tot nu toe voornamelijk op de taak om voornamelijk social media posts te classificeren met betrekking tot vooraf gedefinieerde typologieën van vrij grove haatspraakcategorieën. Dit kan voldoende zijn als het doel is om beledigende taalberichten op te sporen en te verwijderen. Echter, verhuizing is niet altijd mogelijk vanwege de wetgeving van een land. Er is ook bewijs dat haatspraak niet succesvol kan worden bestreden door alleen maar haatspraakberichten te verwijderen; Ze moeten worden tegengegaan door onderwijs en tegenverhalen. Hiervoor moeten we identificeren (i) wie het doelwit is in een bepaald hate speech post, en (ii) welke aspecten (of kenmerken) van het doelwit worden toegeschreven aan het doelwit in de post. Als eerste benadering stellen we voor om een generiek state-of-the-art concept extraction model aan te passen aan het haatspraakdomein. Het resultaat van de experimenten is veelbelovend en kan als inspiratie dienen voor verder werk aan de taak', 'da': 'Hovedforskningen om hadefuldtale har hidtil hovedsageligt fokuseret på opgaven at klassificere hovedsageligt sociale medier indlæg i forhold til foruddefinerede typologier af temmelig grove hadefulde talekategorier. Dette kan være tilstrækkeligt, hvis målet er at opdage og slette krænkende sprogindlæg. Men fjernelse er ikke altid mulig på grund af lovgivningen i et land. Der er også beviser for, at hadefulde tale ikke kan bekæmpes med succes ved blot at fjerne hadefulde tale indlæg; De bør modvirkes af uddannelse og modfortællinger. Til dette formål er vi nødt til at identificere (i) hvem der er målet i et givet hadefuldtale indlæg, og (ii) hvilke aspekter (eller karakteristika) af målet, der tilskrives målet i indlægget. Som den første tilnærmelse foreslår vi at tilpasse en generisk state-of-the-art konceptudvindingsmodel til hadefulde tale domæne. Resultatet af eksperimenterne er lovende og kan tjene som inspiration til videre arbejde med opgaven', 'bg': 'Основните изследвания на речта на омразата засега се фокусираха предимно върху задачата да класифицират главно публикациите в социалните медии по отношение на предварително определени типологии на доста грубозърнести категории речи на омразата. Това може да е достатъчно, ако целта е откриване и изтриване на злоупотребяващи езикови публикации. Премахването обаче не винаги е възможно поради законодателството на дадена държава. Също така има доказателства, че речта на омразата не може да бъде успешно преодоляна чрез просто премахване на публикациите в речта на омразата; те трябва да бъдат противопоставени чрез образование и контраразкази. За тази цел трябва да идентифицираме (и) коя е целта в дадена публикация за реч на омразата и (ii) какви аспекти (или характеристики) на целта се приписват на целта в публикацията. Като първо сближаване предлагаме да се адаптира генеричен модел за извличане на концепции в областта на речта на омразата. Резултатът от експериментите е обещаващ и може да послужи като вдъхновение за по-нататъшна работа по задачата', 'ko': '지금까지 증오 언론에 대한 주류 연구는 주로 미리 정의된 굵은 입도 증오 언론 유형에 따라 소셜미디어 게시물을 분류하는 임무에 집중됐다.욕설성 언어 게시물을 탐지하고 삭제하는 것이 목표라면 충분할 것 같다.그러나 한 나라의 입법 때문에 항상 그것을 제거할 수 있는 것은 아니다.또한 헤이트 스피치 게시물만 삭제하면 헤이트 스피치를 성공적으로 단속할 수 없다는 증거가 있다.그들은 교육과 반사사를 통해 반격해야 한다.이를 위해 (i)특정한 원한 언론 게시물의 목표가 누구인지, (ii)해당 게시물의 목표가 어떤 부분(또는 특징)이 있는지 확인해야 한다.첫 번째 근사로서, 우리는 통용되는 가장 선진적인 개념 추출 모델을 증오 음성 분야에 응용할 것을 건의합니다.실험의 결과는 희망적이어서 진일보한 작업의 영감으로 삼을 수 있다', 'de': 'Die Mainstream-Forschung zur Hassrede konzentrierte sich bisher vor allem auf die Aufgabe, hauptsächlich Social Media Posts hinsichtlich vordefinierter Typologien eher grobkörniger Hassredekategorien zu klassifizieren. Dies kann ausreichen, wenn es darum geht, missbräuchliche Sprachbeiträge zu erkennen und zu löschen. Allerdings ist ein Umzug aufgrund der Gesetzgebung eines Landes nicht immer möglich. Es gibt auch Beweise dafür, dass Hassrede nicht erfolgreich bekämpft werden kann, indem lediglich Hassrede-Beiträge entfernt werden; Sie sollten durch Bildung und Gegennarrative bekämpft werden. Zu diesem Zweck müssen wir (i) identifizieren, wer das Ziel in einem bestimmten Hassrede-Beitrag ist und (ii) welche Aspekte (oder Merkmale) des Ziels dem Ziel in dem Beitrag zugeschrieben werden. Als erste Annäherung schlagen wir vor, ein generisches State-of-the-Art Konzept Extraktion Modell an die Hassrede Domäne anzupassen. Das Ergebnis der Experimente ist vielversprechend und kann als Inspiration für die weitere Arbeit an der Aufgabe dienen.', 'hr': 'Obično istraživanje o govoru mržnje usredotočilo se do sada predstavno na zadatak klasifikacije uglavnom postignuća društvenih medija u pogledu predodređenih tipologa raznih kategorija razgovora mržnje. To bi moglo biti dovoljno ako je cilj otkrivanje i izbrisanje nasilnih jezičkih postova. Međutim, uklanjanje nije uvijek moguće zbog zakonodavstva zemlje. Također, postoje dokazi da govor mržnje ne može uspješno boriti samo uklanjanjem govornih mjesta mržnje; trebali bi se računati obrazovanjem i protivnim pričama. Za ovu svrhu moramo identificirati i) koji je cilj u određenom postu govora mržnje i ii) koji aspekti (ili karakteristike) mete pripisuju cilju na postu. Kao prvi približavanje, predlažemo prilagoditi generični model izvlačenja koncepta umjetnosti u domenu govora mržnje. Rezultat eksperimenata obećava i može biti inspiracija daljnjeg rada na zadatku.', 'fa': 'تحقیقات اصلی در مورد سخنرانی از نفرت به این مدت بیشتر روی کار کلاس کردن نقطه\u200cهای رسانه\u200cهای اجتماعی در مورد تایپولوژی\u200cهای پیش\u200cفرض از گروه\u200cهای سخنرانی از ناخوشایند غیرقابل تعریف شده است. این ممکن است به اندازه کافی باشد اگر هدف برای شناسایی و حذف کردن پست زبان زبان زبان زبان زبان زبان استفاده است. ولی حذف کردن همیشه ممکن نیست به دلیل قوانین یک کشور. همچنین، نشانه\u200cهایی هستند که از سخنرانی که نفرت دارند، نمی\u200cتوانند با موفقیت مبارزه کنند، فقط با حذف کردن نقطه\u200cهای سخنرانی که نفرت دارند. آنها باید توسط تحصیل و داستان مخالف تحصیل کنند. برای این هدف، ما باید تشخیص بدیم که کیست هدف در یک پست سخنرانی متنفر و (i i) چه نقطه (یا ویژگی) هدف به هدف در پست تعریف می\u200cشود. به عنوان اولین نزدیک شدن، ما پیشنهاد می کنیم که یک مدل استخراج نظریه عمومی در حالت هنری به دامنه سخنرانی متنفر adapt کنیم. نتیجه آزمایشات قول می دهد و می تواند به عنوان الهام برای کار بیشتری در این کار باشد', 'id': 'Penelitian utama tentang pidato kebencian fokus sejauh ini terutama pada tugas untuk mengklasifikasi terutama pos media sosial mengenai tipologi terdefinisi dari kategori pidato kebencian yang agak kasar. This may be sufficient if the goal is to detect and delete abusive language posts.  Namun, penghapusan tidak selalu mungkin karena undang-undang negara. Juga, ada bukti bahwa pidato kebencian tidak dapat berhasil melawan hanya dengan menghapus pos pidato kebencian; seharusnya diharapkan oleh pendidikan dan kontranarratif. Untuk tujuan in i, kita perlu mengidentifikasi (i) siapa sasaran dalam pos pembicaraan kebencian tertentu, dan (ii) aspek apa (atau karakteristik) sasaran yang disebut kepada sasaran di pos. Sebagai pendekatan pertama, kami mengusulkan untuk mengadaptasi model ekstraksi konsep state-of-the-art generik ke domain pidato kebencian. Hasil eksperimen itu berjanji dan dapat menjadi inspirasi untuk kerja lanjut dalam tugas', 'sw': 'Utafiti mkubwa wa hotuba ya chuki ulilenga muhimu sana katika kazi ya kutangaza makala za mitandao ya kijamii hasa kwa kuheshimu aina zilizotanguliwa na makundi ya hotuba ya chuki yanayojiunga mkono. Hii inaweza tosha ikiwa lengo la kutambua na kufuta makala za lugha zinazotumiwa. Hata hivyo, kuondolewa kwa nchi haiwezekani kwa sababu ya sheria ya nchi hiyo. Pia, kuna ushahidi kuwa hotuba ya chuki haiwezi kupambana na mafanikio tu kwa kuondoa makala za hotuba za chuki; wanatakiwa kukabiliana na elimu na hadithi za kupinga. Kwa sababu hii, tunahitaji kutambua (i) ni nani hasira katika makala yenye hotuba ya chuki, na (ii) mambo (au tabia) ya malengo yanayohusishwa na lengo la makala hiyo. Kama ilivyokaribia mara ya kwanza, tunapendekeza kubadilisha hali ya kawaida ya dhana ya utekelezaji wa sanaa kwenye eneo la hotuba ya chuki. Matokeo ya majaribio ni kuahidini na yanaweza kutumika kama hamasa ya kufanya kazi zaidi kwenye kazi hiyo', 'tr': 'Iň ýigrenýän çykyşyň adaty barlamagy üçin esasy ýagdaýda sosyal medýdançalaryň ýerlerinde taýýarlanmagy üçin üns berdi. Eger maksadyň gaýd edilen diller tapmak we pozmak üçin bu ýeterlik bolup biler. Ýöne ýurtyň kanunlygyna sebäpli ýitirmek hemişe mümkin däl. Munuň üçin ýigrenýän sözlerin ýöne ýigrenýän sözlerini ýitirmek üçin mümkin edip bilmeýän kanlag bar. Olar bilim we aýdymlar bilen garşy edilmeli. Bu maksadyň üçin biziň (i) berilen ýigrenç çykyş post-da maksady kimdir, we (ii) maksadyň (ýa-da özellikleri) post-de maksadyň nähili aspektlerini takyklamaly. Ilkinji yaklaşyk bolsa, ýigrenç sözleşme domunyna umumy bir şekilde çykarmak nusgasyny üýtgetmegi teklif ediyoruz. Deneylerin netijesi söz berýän we işiň üstünde ýeterlik iş üçin ilham alyp biler.', 'sq': 'Kërkimet kryesore mbi fjalimin e urrejtjes u përqëndruan deri tani kryesisht në detyrën e klasifikimit kryesisht të posteve të medias sociale lidhur me tipologjitë e paracaktuara të kategorive të fjalimit të urrejtjes me kokërra të mëdha. Kjo mund të jetë e mjaftueshme në qoftë se qëllimi është të zbulojë dhe fshijë postimet e gjuhës abusive. Megjithatë, heqja nuk është gjithmonë e mundur për shkak të legjislacionit të një vendi. Gjithashtu, ka prova se fjalimi i urrejtjes nuk mund të luftohet me sukses vetëm duke hequr postin e fjalimit të urrejtjes; ata duhet të kundërvihen nga arsimi dhe kontranarrativat. Për këtë qëllim, ne duhet të identifikojmë (i) se kush është objektivi në një post të caktuar të fjalimit të urrejtjes dhe (ii) se cilat aspekte (apo karakteristika) të objektivit janë atribuar objektivit në post. Si përafërsimi i parë, ne propozojmë të përshtatemi një model gjeneral të nxjerrjes së konceptit më të lartë në domenin e fjalimit të urrejtjes. Rezultati i eksperimenteve është premtues dhe mund të shërbejë si frymëzim për punë të mëtejshme në detyrë', 'hy': 'Հիմնական հետազոտությունները ատելության խոսքի մասին, որոնք մինչ այժմ հիմնականում կենտրոնացել են հատկապես սոցիալական լրատվամիջոցների դիրքերի դասակարգման խնդրի վրա, հատկապես դասակարգված ատելության խմբերի նախասահմանված տիպոլոգիաների հետ Սա կարող է բավարար լինել, եթե նպատակն է հայտնաբերել և ջնջել չարաշահույթ լեզվի տեղադրությունները: Այնուամենայնիվ, հեռացումը միշտ հնարավոր չէ երկրի օրենսդրության պատճառով: Կան նաև ապացույցներ, որ ատելության խոսքերը չեն կարող հաջողությամբ պայքարել, պարզապես վերացնելով ատելության խոսքերը: նրանք պետք է հակառակվեն կրթությամբ և հակապատմություններով: Այս նպատակի համար մենք պետք է հայտնաբերենք i) ով է նպատակը ատելության խոսքի պաշտոնում, և i) նպատակի ի՞նչ ասպեկտներ (կամ առանձնահատկություններ) են պատասխանում նպատակին պաշտոնում: Ինչպես առաջին մոտեցումը, մենք առաջարկում ենք հարմարեցնել ընդհանուր տեխնոլոգիական գաղափարի վերացման մոդելը ատելության խոսքի ոլորտում: Փորձերի արդյունքը խոստացնող է և կարող է օգտագործել որպես ոգեշնչում աշխատանքի շարունակման համար,', 'az': 'Nöqsanlıq sözləri haqqındakı ilk dəyişiklik təhsil edilən təhsil sözləri daha çox dəyişiklik nifrət sözləri kategoriyalarının əvvəlcə müəyyən edilmiş typoloqlarına görə dəyişiklik göstərməsi işinə baxıldı. Əgər məqsəd zəif dil postalarını keçmək və silmək üçün kifayət ola bilər. Ancaq bir ülkenin qaydalarına görə həmişə silinmək mümkün deyil. Həmçinin nifrət sözlərini yalnız nifrət sözlərini silməklə mübahisə edə bilməyəcəyi dəlillər də var. təhsil və müxtəlif hekayələrlə sayılmalıdır. Bu məqsədilə, bizə verilən nifrət sözlərinin məqsədilə nifrət nifrətində olan məqsədili tanımlamaq lazımdır, və i i) məqsədilərin məqsədilə nələr məqsədilə qoyulmuşdur. İlk yaxınlaşdığımız kimi, nifrət sözləri domenasına generiki bir məlumatın qovuşdurulmasını təklif edirik. Həyatların sonuçları vəd edir və daha çox iş üçün ilham edə bilər.', 'bs': 'Uglavnom istraživanju o govoru mržnje usredotočeno je do sada uglavnom na zadatak klasifikacije uglavnom položaja društvenih medija u pogledu predodređenih tipologa kategorija razgovora mržnje. To bi moglo biti dovoljno ako je cilj otkrivanje i izbrisanje nasilnih jezičkih postova. Međutim, uklanjanje nije uvek moguće zbog zakonodavstva zemlje. Također, postoje dokazi da govor mržnje ne može biti uspješno borjen samo uklanjanjem postova govora mržnje. Trebalo bi se suočavati obrazovanjem i protivnim pričama. Za ovu svrhu moramo identificirati i) koji je cilj u određenom postu govora mržnje, i ii) koje aspekte (ili karakteristike) mete pripisuju cilju na postu. Kao prvi približavanje, predlažemo prilagoditi generični model izvlačenja koncepta umjetnosti na domenu govora mržnje. Rezultat eksperimenata obećava i može biti inspiracija za daljnji posao na zadatku.', 'af': "Onderstremde ondersoek op haat spraak het so ver voordeel gefokus op die taak van klassifiseer hoofsaaklik sosiale media-pos met betrekking na vooraf-definieerde tipologies van eerder uitgevoerde haat spraak kategories. Hierdie dalk mag genoeg wees as die doel is om abusive taalposte te ontdek en uitvee. Maar verwydering is nie altyd moontlik vanweë die wetgewing van 'n land nie. Ook, daar is getuienis dat haat spreek nie suksesvol gemeenskap word deur net die verwyder van haat spraakposte nie; hulle moet deur opvoeding en teenstoratiewe tel word. Vir hierdie doel, moet ons identifiseer (i) wie die doel is in 'n gegewe haat spraakpost, en (ii) wat aspekte (of karakters) van die doel aan die doel in die pos aangewys word. As die eerste toekoms, voorstel ons om 'n generieke staat-van-die-kuns-konsepte uittrekking model aan die haat-sprekkdomein te pas. Die resultaat van die eksperimente is beloftende en kan as inspirasie dien vir verdere werk op die taak", 'am': 'በጥል ንግግር ላይ የመጠቀም ትምህርት ትምህርት ላይ አስቀድሞ በማኅበራዊ አውታር ሚዲያ ፖርቶች ላይ ለመለፍ ነው፡፡ ይህ ይበቃል፡፡ ነገር ግን ማስወገድ ሁልጊዜ በአገሪቱ ሕግ ምክንያት አይቻልም፡፡ Also, there is evidence that hate speech cannot be successfully combated by merely removing hate speech posts;  ትምህርት እና ተቃዋሚዎች ተቃውሞ ይቃወሙ:: ለዚህ ምክንያት (i) በተሰጠው የጥል ንግግር ጽሑፍ የሚሆነውን መግለጫ (i) እና (ii) የዕቅድን ጉዳይ (ወይም የአካባቢው) ምን ጉዳይ እንዲሆን ያስፈልጋል፡፡ የመጀመሪያው አካባቢ መጠን፣ የ-የ-አርእስት አካባቢ አካሄድ ምሳሌ ለጥል ንግግር ድሆችን ለመቀበል እናስባለን፡፡ የሞከሩ ፍጻሜ ተስፋ የሚያደርገው እና ለስራ ላይ ለሌላ ሥራ ማግኘት የሚችል ነው፡፡', 'cs': 'Hlavní výzkum nenávistné řeči se zatím zaměřil především na úlohu klasifikace příspěvků na sociálních médiích s ohledem na předem definované typologie spíše hrubozrnných kategorií nenávistné řeči. To může být dostačující, pokud je cílem odhalit a odstranit zneužívající jazykové příspěvky. Stěhování však není vždy možné vzhledem k právním předpisům dané země. Také existují důkazy, že nenávistná řeč nelze úspěšně bojovat pouhým odstraněním příspěvků na nenávistné řeči; Měly by být čelit vzděláváním a protipříběhy. Za tímto účelem musíme identifikovat (i) kdo je cílem v daném příspěvku o nenávistné řeči a (ii) jaké aspekty (nebo charakteristiky) cíle jsou přiřazeny cíli v příspěvku. Jako první aproximaci navrhujeme adaptaci obecného stavu-of-the-art konceptního extrakčního modelu do domény nenávistné řeči. Výsledek experimentů je slibný a může sloužit jako inspirace pro další práci na úkolu', 'et': 'Vihakõne põhitegevus keskendus seni peamiselt ülesandele klassifitseerida peamiselt sotsiaalmeedia postitusi üsna jämedate vihakõne kategooriate eelnevalt määratletud tüpoloogiate järgi. See võib olla piisav, kui eesmärk on tuvastada ja kustutada kuritarvitavad keelepostid. Kuid riigi õigusaktide tõttu ei ole väljasaatmine alati võimalik. Samuti on tõendeid, et vihakõne vastu ei saa edukalt võidelda vaid vihakõne postituste eemaldamisega; nende vastu tuleks võidelda hariduse ja vastupidiste jutustustega. Sel eesmärgil tuleb tuvastada i) kes on sihtmärk antud vihakõne postituses ja ii) millised sihtmärki aspektid (või omadused) omistatakse sihtmärkile postituses. Esimese lähenemisena teeme ettepaneku kohandada üldist kaasaegset kontseptsioonide ekstraheerimise mudelit vihakõne valdkonnale. Katsete tulemus on paljulubav ja võib olla inspiratsiooniks edasiseks tööks ülesandega', 'fi': 'Vihanpuheen valtavirtatutkimus keskittyi tähän mennessä pääasiassa sosiaalisen median viestien luokitteluun melko karkeiden vihapuheluokkien ennalta määriteltyjen typologioiden perusteella. Tämä voi riittää, jos tavoitteena on tunnistaa ja poistaa loukkaavat kieliviestit. Maan lainsäädännön vuoksi maastapoistaminen ei kuitenkaan aina ole mahdollista. On myös näyttöä siitä, että vihapuhetta ei voida torjua menestyksekkäästi pelkästään poistamalla vihapuheviestejä. Niitä olisi torjuttava koulutuksen ja vastakertomusten avulla. Tätä tarkoitusta varten meidän on tunnistettava (i) kuka on kohde tietyssä vihapuheviestissä, ja (ii) mitä kohtia (tai ominaisuuksia) kohdeviestissä kohdellaan. Ensimmäisenä lähestymistapana ehdotamme geneerisen, viimeisintä tekniikkaa edustavan käsitteen uuttamismallin mukauttamista vihapuheen domeeniin. Kokeiden tulos on lupaava ja voi toimia inspiraationa tehtävän jatkotyöhön', 'bn': 'ঘৃণা ভাষণের প্রধান গবেষণা প্রধান গবেষণা প্রধান সামাজিক যোগাযোগ মাধ্যমের পোস্টগুলোকে বিশ্লেষণ করার কাজের উপর মনোযোগ প্রদান করেছে যারা বেশ This may be sufficient if the goal is to detect and delete abusive language posts.  তবে দেশের আইনের কারণে সবসময় অপসারণ সম্ভব নয়। এছাড়াও প্রমাণ রয়েছে যে ঘৃণা ভাষণ কেবল ঘৃণা বাক্য পোস্ট সরিয়ে দিয়ে সাফল্যের সাথে যুদ্ধ করতে পারে না; তাদের শিক্ষা এবং বিরোধী গল্পের মুখোমুখি হওয়া উচিত। এই উদ্দেশ্যের জন্য আমাদের চিহ্নিত করা দরকার (I) কে একটি ঘৃণা ভাষণ পোস্টে লক্ষ্য করা দরকার এবং (i i) লক্ষ্যবস্তুতে (অথবা চরিত্র) লক্ষ্যবস্তুর জন্যে কি বিষয় প্রথম প্রাথমিক যুক্তি হিসেবে আমরা প্রস্তাব করছি ঘৃণা ভাষণের ডোমেইনে একটি সাধারণ রাষ্ট্রের জেনারিক-শিল্পের ধারণা বের করা পরীক্ষার ফলাফল প্রতিশ্রুতিশীল এবং কাজের উপর আরো কাজের জন্য অনুপ্রেরণা হিসেবে সাহায্য করতে পারে।', 'ca': "La recerca principal sobre el discurs d'odi s'ha centrat fins ara principalment en la tasca de classificar principalment els posts dels mitjans socials en relació a tipologies predefinides de categories de discurs d'odi bastant grossos. Això pot ser suficient si l'objectiu és detectar i eliminar posts de llenguatge abusivs. However, removal is not always possible due to the legislation of a country.  També hi ha evidències de que el discurs d'odi no es pot combatre amb èxit només eliminant posts d'odi; haurien de ser contradits per educació i contranarratives. Per aquest objectiu, hem d'identificar (i) qui és l'objectiu d'un discurs d'odi determinat, i (ii) quins aspectes (o característiques) del objectiu s'atribueixen al objectiu del post. Com a primera aproximació, proposem adaptar un model genèric d'extracció de concepte d'última generació al domini del discurs d'odi. El resultat dels experiments és prometedor i pot servir de inspiració per a seguir treballant en la tasca", 'jv': 'Tolangga Punika sapa kana nggawe goal punika dipakingno karo akeh-akeh oleh basa. Nanging, nggolo-nggolo saiki ora bisa diandelak ning hukum sing paling dhéwé. Mangka, ono bukane pancene ora ngerasakno ora ono nggawe ngubah apakno ora ono nggawe ngubah dilanjuré; ndeloke Kayané iso ngulinakake karo edukasi lan kontribusi. Saiki iki, awake dhéwé kudu nambah (i) sing ngendadi iki bakal terus kesempatan langgar, lan (i i) langgar sampek (obang cara-cara) kebutuhake tarjamahan kanggo langgar sampek winih. When the first confirmation, we proposal to align a generic state-of-the-Art contest extract model to the anti-language domain. Balika nang ujaran ning alih lan gampang lan iso alih luwih dumadhi kanggo nggawe alih dumadhi kanggo nggawe lan kenal', 'ha': "Tayyar da muhimmi a kan magana na ƙi ana fokus a kan aikin su rarrabe maimainli mainli maimainli maimaimainlin mitandan jamii da kuma da tsarin wasu typogi na daban-coacoacoast-graffed-categories of hatsi. Wannan yana da amfani da idan aimakin ya zama na gane kuma ka goge takardar harshen mai zartar da shi. A lokacin da za'a iya tafiyar da shi, bã zai iya so ba daidai ne da sharci na kasancẽwa. Kuma akwai shaidar cẽwa, maganar ƙyãma bã za su ci nasara ba fãce da su tunkuɗe maganar ƙyãma. Ina kamata a kamata da abincin da baka-faɗi. Ga wannan, Munã bukãta mu gane (ni) wãne ne ke da goani a cikin wani hotan na ƙi, kuma (ii) yanda ake ƙayyade gafaka (ko da takwara) cikin bango. Kayya da taki na farkon, za'a goyi musammali na halin-na-zaɓen-kunna zuwa hotin da aka ƙi. Faramar jarrabai yana yi wa'adi da kuma yana iya amfani da aikin da ke iya ƙara a kan aikin wannan", 'sk': 'Glavne raziskave sovražnega govora so se doslej osredotočale predvsem na nalogo razvrščanja predvsem objav v družbenih medijih glede na vnaprej določene tipologije precej grobozrnatih kategorij sovražnega govora. To lahko zadostuje, če je cilj odkrivanja in brisanja zlorabljajočih jezikovnih objav. Vendar odstranitev ni vedno mogoča zaradi zakonodaje države. Obstajajo tudi dokazi, da se sovražnega govora ni mogoče uspešno boriti z zgolj odstranitvijo objav sovražnega govora; se jim je treba zoperstaviti z izobraževanjem in protipogodbami. V ta namen moramo ugotoviti (i) kdo je tarča v določeni objavi sovražnega govora in (ii) kateri vidiki (ali značilnosti) tarče se pripišejo cilju v objavi. Kot prvi približek predlagamo prilagoditev generalnega najsodobnejšega modela ekstrakcije koncepta domeni sovražnega govora. Rezultat poskusov je obetaven in lahko služi kot navdih za nadaljnje delo na nalogi', 'he': 'המחקר המרכזי בנאום שנאה התמקד עד כה בעיקר במשימה להקליף בעיקר עמדות תקשורת חברתית בנוגע לטיפולוגיות מוגדרות מראש של קטגוריות נאום שנאה עצומות למדי. זה עשוי להיות מספיק אם המטרה היא לזהות ולמחק משימות שפה מתעללות. עם זאת, הסירה לא תמיד אפשרית בגלל החוק של מדינה. בנוסף, יש ראיות שאי אפשר להילחם בהצלחה בנאום שנאה על ידי רק להסיר את עמדות הנאום לשנאה; הם צריכים להילחם על ידי חינוך וסיפורים נגד. למטרה זו, אנחנו צריכים לזהות (i) מי המטרה בתור נאום שנאה מסוים, ו (ii) איזה היבטים (או אופיינים) של המטרה מונחים למטרה בתור התור. As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain.  התוצאה של הניסויים מבטיחה ויכולה לשרת בתור השראה לעבודה נוספת על המשימה', 'bo': 'hate speech. གལ་སྲིད་དམིགས་ཡུལ་ནི་བསམ་བཤེར་དང་བསུབ་པ་ཡིན་ཚེ། ཡིན་ནའང་། རྒྱལ་ཁབ་ཀྱི་ཁྲིད་པ་ཞིག་ཀྱང་རྩ་བསྐྲད་གཏོང་ནི་མི་སྲིད། ད་ལྟ་བུའི་རྗེས་སུ་འབྲེལ་བའི་འཇིག་བརྗོད་འདི་རྒྱལ་ཐག་གཅིག་ལས་གཏོང་མི་ཐུབ་པ་ལྟར། ཁོང་ཚོས་ཤེས་ཡོན་དང་གནད་དོན་རྩོལ་བ་དགོས་མིན་འདོད། དམིགས་ཡུལ་འདི་ལ་ང་ཚོར་དམིགས་ཡུལ་གྱི་ཤོག་བྱས་པར་ཕྱི་ཁག་ཅིག་རེད། As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain. བརྟག་ཞིབ་ཀྱི་གྲུབ་འབྲས་བ་དེ་གསལ་བཤད་པ་ཞིག་ཡིན། དེ་ལས་ཀྱི་ལས་ཀ་གཞན་ལས་ཀྱི་སྒེར་སྟོན་རྒྱས་ལས།'}
{'en': 'Racist or Sexist Meme? Classifying Memes beyond Hateful', 'ar': 'ميمي عنصرية أو جنسية؟ تصنيف الميمات بما يتجاوز الكراهية', 'pt': 'Meme racista ou sexista? Classificando memes além de odiosos', 'es': '¿Meme racista o sexista? Clasificar los memes más allá del odio', 'fr': 'Meme raciste ou sexiste\xa0? Classifier les mèmes au-delà de la haine', 'ja': '人種差別主義者か性差別主義者か？ヘイトフルを超えたミームの分類', 'hi': 'नस्लवादी या सेक्सिस्ट मेम? घृणित से परे Memes वर्गीकृत', 'ru': 'Расистский или сексистский мем? Классификация мемов за пределами ненависти', 'zh': '种族主义或性别歧视模因? 其超仇之模因类也', 'ga': 'Meme Ciníoch nó Gnéasach? Memes a rangú thar fuathmhar', 'it': "Meme razzista o sessista? Classificare meme oltre l'odio", 'hu': 'Rasszista vagy szexista Meme? Emék osztályozása a gyűlöleten túl', 'lt': 'Racist or Sexist Meme?  Memorijų klasifikavimas be neapykantos', 'mk': 'Расистичка или сексистичка мема? Класификување мемории надвор од омраза', 'ka': 'პაჟთჟრ თლთ ჟვკჟთჟრ მვმვ? კლასიფიკაცია მემები გარეშე', 'ms': 'Meme Rasis atau Seksi? Classifying Memes beyond Hateful', 'el': 'Ρατσιστικό ή σεξιστικό Meme; Κατάταξη Memes πέρα από το μίσος', 'kk': 'Рассистік не сексистік мемле? Жазбаларды өзгерту', 'no': 'Racist eller seksistisk mem? Klassifiserer meldingar utanfor hattfull', 'ml': 'റെസിസ്റ്റ് അല്ലെങ്കില്\u200d സെക്സിസ്റ്റ് മെമ്മോ? വെറുപ്പുള്ള മെമ്മറുകള്\u200d ക്ലാസിക്ക് ചെയ്യുന്നു', 'mt': 'Mema razzista jew sessista? Il-Klassifikazzjoni tal-Memorji lil hinn mill-Hateful', 'ro': 'Meme rasist sau sexist? Clasificarea memelor dincolo de ură', 'mn': 'Рассист эсвэл сексист сэтгэл санаа? Харамсалтай санаануудын гадна', 'so': 'Racist ama xisxisxist? Xisaabsashada xubnaha ka baxsan', 'sv': 'Rasist eller sexist Meme? Klassificera memes bortom hatisk', 'ta': 'வெற்றியல் அல்லது பெக்சிஸ்ட் மெம்? Classifying Memes beyond Hateful', 'ur': 'روسیست یا سکسیس میم؟ ناپسند کے علاوہ کلاس کرتا ہے', 'pl': 'Rasistowski czy seksistowski Meme? Klasyfikacja Memów ponad nienawiść', 'sr': 'Rasistički ili seksistički Meme? Classifying Memes beyond hate', 'si': 'රේසිස්ටර් නැත්නම් සෙක්සිස්ට් මේම්? @ item: inlistbox Sort', 'vi': 'Báo cáo phân biệt chủng tộc? Những kí ức đáng ghét', 'uz': 'Rasm yoki seksist xotira? Name', 'bg': 'Расист или сексист? Класифициране на мемите отвъд омразата', 'nl': 'Racistisch of seksistisch Meme? Memes classificeren boven haatdragend', 'da': 'Racistisk eller sexistisk meme? Klassificering Memes Beyond Hadeful', 'hr': 'Rasistički ili seksistički Meme? Classifying Memes beyond hate', 'de': 'Rassistisch oder sexistisch Meme? Memes jenseits von Hass klassifizieren', 'ko': '인종차별주의인가 성차별의 모인인가?모인을 원한 이외의 모인으로 분류하다', 'id': 'Rasis atau Meme Sexist? Mengklasifikasikan Memo di luar kebencian', 'fa': 'نژادگر يا ميم سکسيست؟ نامه\u200cهایی که غیر از ناخوشایند قطع می\u200cکنند', 'sw': 'Ubaguzi wa rangi au Kumbukumbu ya Ubaguzi? Kuonyesha kumbukumbu zaidi ya Hati', 'tr': 'Ne oluyor? Hatsyzlyk öňünde nusgala', 'sq': 'Racist apo Sexist Meme? Kujtimet e klasifikuara përtej urrejtjes', 'af': 'Racist of Sexist Meme? Klassifiseer Memes buite Hateful', 'am': 'ባሕላዊ CategoryName', 'hy': 'ռասիստ կամ սեքսիստ մեմ՞ն: Հիշողություններ դասակարգելը ատելությունից դուրս', 'bn': 'Racist or Sexist Meme?  ঘৃণার বাইরে স্মৃতিকে ক্লাসিক করা হচ্ছে', 'bs': 'Rasistički ili seksistički Meme? Classifying Memes beyond hate', 'ca': 'La memòria racista o sexual? Classificar memòries més enllà del odi', 'az': 'Racist ya da Sexist Meme? N칬y칲d-n톛sih톛td톛n qeyri-n톛sih톛tl톛r', 'cs': 'Rasistický nebo sexistický Meme? Klasifikace pamětí za nenávist', 'et': 'Rassist või seksist Meme? Memede liigitamine vihkamisest kaugemale', 'fi': 'Rasisti vai seksistinen Meme? Luokittelemalla muistioita vihamielisemmälle', 'jv': 'Opo rasan po opo-susan ? iCalImp', 'sk': 'Rasist ali seksist Meme? Razvrščanje spominov preko sovražnosti', 'he': 'גזענית או מימית סקסיסטית? מסווג זכרונות מעבר לשנאה', 'bo': 'རྩོམ་སྒྲིག་པོ་དང་མི་ཚོར་བྲོ་བ་སྐྱེས་ཚོགས་ཀྱི་དུས་ཚོད་དམ། ཚད་འཛིན་གྱིས་མེད་པའི་བརྗོད་སྡེར་སྤྱོད་བྱེད་བཞིན་པ', 'ha': '@ action KCharselect unicode block name'}
{'en': 'Memes are the combinations of text and images that are often humorous in nature. But, that may not always be the case, and certain combinations of ', 'fr': "Les mèmes sont des combinaisons de texte et d'images souvent humoristiques. Mais ce n'est peut-être pas toujours le cas, et certaines combinaisons de textes et d'images peuvent représenter de la haine, appelée mèmes haineux. Ce travail présente un pipeline multimodal qui prend en compte les caractéristiques visuelles et textuelles des mèmes pour (1) identifier la catégorie protégée (par exemple race, sexe, etc.) qui a été attaquée\xa0; et (2) détecter le type d'attaque (par exemple mépris, insultes, etc.). Notre pipeline utilise des représentations visuelles et textuelles pré-entraînées de pointe, suivies d'un classificateur de régression logistique simple. Nous utilisons notre pipeline sur le jeu de données Hateful Memes Challenge avec des étiquettes supplémentaires nouvellement créées pour la catégorie protégée et le type d'attaque. Notre meilleur modèle atteint un AUROC de 0,96 pour identifier la catégorie protégée et de 0,97 pour détecter le type d'attaque. Nous publions notre code à l'adresse https://github.com/harisbinzia/HatefulMemes", 'ar': 'الميمات هي مجموعات نصية وصور غالبًا ما تكون مضحكة بطبيعتها. ولكن ، قد لا يكون هذا هو الحال دائمًا ، وقد تصور مجموعات معينة من النصوص والصور الكراهية ، ويشار إليها باسم الميمات البغيضة. يقدم هذا العمل خط أنابيب متعدد الوسائط يأخذ في الاعتبار الميزات المرئية والنصية من الميمات إلى (1) تحديد الفئة المحمية (مثل العرق والجنس وما إلى ذلك) التي تعرضت للهجوم ؛ و (2) الكشف عن نوع الهجوم (مثل الازدراء والافتراءات وما إلى ذلك). يستخدم خط الأنابيب لدينا التمثيلات المرئية والنصية المدربة مسبقًا ، متبوعة بمصنف انحدار لوجستي بسيط. نحن نستخدم خط الأنابيب الخاص بنا في مجموعة بيانات Hateful Memes Challenge مع تسميات دقيقة إضافية تم إنشاؤها حديثًا للفئة المحمية ونوع الهجوم. يحقق أفضل نموذج لدينا AUROC قدره 0.96 لتحديد الفئة المحمية ، و 0.97 لاكتشاف نوع الهجوم. أصدرنا الكود الخاص بنا على https://github.com/harisbinzia/HatefulMemes', 'pt': 'Memes são as combinações de texto e imagens que muitas vezes são de natureza humorística. Mas nem sempre é esse o caso, e certas combinações de textos e imagens podem retratar ódio, chamados de memes de ódio. Este trabalho apresenta um pipeline multimodal que leva em consideração os recursos visuais e textuais dos memes para (1) identificar a categoria protegida (por exemplo, raça, sexo etc.) que foi atacada; e (2) detectar o tipo de ataque (por exemplo, desprezo, insultos etc.). Nosso pipeline usa representações visuais e textuais pré-treinadas de última geração, seguidas por um classificador de regressão logística simples. Empregamos nosso pipeline no conjunto de dados Hateful Memes Challenge com rótulos refinados adicionais recém-criados para categoria protegida e tipo de ataque. Nosso melhor modelo alcança um AUROC de 0,96 para identificar a categoria protegida e 0,97 para detectar o tipo de ataque. Liberamos nosso código em https://github.com/harisbinzia/HatefulMemes', 'es': 'Los memes son las combinaciones de texto e imágenes que a menudo son de naturaleza humorística. Pero, puede que no siempre sea así, y ciertas combinaciones de textos e imágenes pueden representar odio, lo que se conoce como memes de odio. Este trabajo presenta un canal multimodal que tiene en cuenta las características visuales y textuales de los memes para (1) identificar la categoría protegida (por ejemplo, raza, sexo, etc.) que ha sido atacada; y (2) detectar el tipo de ataque (por ejemplo, desacato, insultos, etc.). Nuestra canalización utiliza representaciones visuales y textuales preentrenadas de última generación, seguidas de un simple clasificador de regresión logística. Empleamos nuestra canalización en el conjunto de datos Hateful Memes Challenge con etiquetas adicionales recién creadas para la categoría protegida y el tipo de ataque. Nuestro mejor modelo logra un AUROC de 0.96 para identificar la categoría protegida y 0.97 para detectar el tipo de ataque. Publicamos nuestro código en https://github.com/harisbinzia/HatefulMemes', 'zh': '模因者,文本图像之组,质常幽默也。 然事或不然,文象或画仇雠,谓之仇模因。 其事多模式管道,当管道虑模因中视文本,以(1)识受攻护之类(如种族,性别)。 (2)检击类(如蔑诽谤之)。 我们的管道用最先进的视听和文本表示,然后是一个简逻辑归分类器。 Hateful Memes Challenge 数集上用吾道,加吾新创细粒度。 至 AUROC 为 0.96 ,以知保护,0.97 以检击。 发我 https://github.com/harisbinzia/HatefulMemes  代码', 'ja': 'ミームは、しばしばユーモアのあるテキストと画像の組み合わせです。しかし、常にそうであるとは限らず、テキストと画像の特定の組み合わせは、憎悪ミームと呼ばれる憎悪を描写し得る。この作品は、(1)攻撃された保護されたカテゴリ（人種、性別など）を識別し、(2)攻撃の種類（軽蔑、スラッシュなど）を検出するために、ミームからの視覚的およびテキスト的特徴の両方を考慮したマルチモーダルパイプラインを提示しています。当社のパイプラインは、最先端の事前トレーニングされた視覚的およびテキスト表現を使用し、次に単純なロジスティック回帰分類子を使用します。Hateful Memes Challengeデータセットには、保護されたカテゴリと攻撃の種類のために新たに作成された細かいラベルが追加されたパイプラインが採用されています。当社のBESTモデルでは、保護されたカテゴリを識別するためのAUROCは0.96、攻撃の種類を検出するためのAUROCは0.97となります。https://github.com/harisbinzia/HatefulMemesでコードをリリースします', 'hi': 'मेम्स पाठ और छवियों के संयोजन हैं जो अक्सर प्रकृति में विनोदी होते हैं। लेकिन, यह हमेशा मामला नहीं हो सकता है, और ग्रंथों और छवियों के कुछ संयोजन नफरत को चित्रित कर सकते हैं, जिसे घृणित मेम्स के रूप में जाना जाता है। यह काम एक बहुआयामी पाइपलाइन प्रस्तुत करता है जो मेम्स से दृश्य और पाठ्य दोनों विशेषताओं को ध्यान में रखता है (1) संरक्षित श्रेणी (जैसे दौड़, लिंग आदि) की पहचान करता है जिस पर हमला किया गया है; और (2) हमले के प्रकार का पता लगाएं (उदाहरण के लिए अवमानना, slurs आदि)। हमारी पाइपलाइन अत्याधुनिक पूर्व-प्रशिक्षित दृश्य और पाठ्य प्रतिनिधित्व का उपयोग करती है, जिसके बाद एक सरल रसद प्रतिगमन क्लासिफायर होता है। हम घृणित Memes चैलेंज डेटासेट पर संरक्षित श्रेणी और हमले के प्रकार के लिए अतिरिक्त नव निर्मित ठीक दानेदार लेबल के साथ हमारी पाइपलाइन को नियोजित करते हैं। हमारा सबसे अच्छा मॉडल संरक्षित श्रेणी की पहचान करने के लिए 0.96 का AUROC प्राप्त करता है, और हमले के प्रकार का पता लगाने के लिए 0.97। हम https://github.com/harisbinzia/HatefulMemes पर हमारे कोड जारी', 'ru': 'Мемы - это сочетания текста и изображений, которые часто носят юмористический характер. Но это может быть не всегда так, и некоторые комбинации текстов и изображений могут изображать ненависть, называемую ненавистническими мемами. Эта работа представляет собой мультимодальный конвейер, который учитывает как визуальные, так и текстовые особенности мемов, чтобы (1) идентифицировать защищенную категорию (например, расу, пол и т.д.), которая подверглась нападению; и (2) обнаружить тип нападения (например, презрение, оскорбления и т.д.). В нашем конвейере используются самые современные визуальные и текстовые представления, за которыми следует простой классификатор логистической регрессии. Мы используем наш конвейер на наборе данных Hateful Memes Challenge с дополнительными недавно созданными мелкозернистыми метками для защищенной категории и типа атаки. Наша лучшая модель достигает AUROC 0,96 для идентификации защищаемой категории и 0,97 для обнаружения типа атаки. Мы выпускаем наш код на https://github.com/harisbinzia/HatefulMemes', 'ga': 'Is iad memes na teaglamaí de théacs agus íomhánna a bhíonn greannmhar go minic sa nádúr. Ach, b’fhéidir nach amhlaidh atá an scéal i gcónaí, agus b’fhéidir go léireodh teaglamaí áirithe téacsanna agus íomhánna fuath, ar a dtugtar memes fuatha. Cuireann an saothar seo píblíne ilmhódach i láthair a thógann idir ghnéithe amhairc agus théacsúla ó meimeanna san áireamh chun (1) an chatagóir chosanta (m.sh. cine, gnéas etc.) ar a ndearnadh ionsaí a shainaithint; agus (2) an cineál ionsaithe a bhrath (m.sh. díspeagadh, slurs etc.). Úsáideann ár bpíblíne léirithe amhairc agus téacs réamhoilte den scoth, agus aicmitheoir aischéimnithí lóistíochta simplí ina dhiaidh sin. Bainimid úsáid as ár bpíblíne ar thacar sonraí Dúshlán na Memes Hateful le lipéid mhíne níos nuachruthaithe le haghaidh catagóir cosanta agus cineál ionsaithe. Baineann ár múnla is fearr amach AUROC de 0.96 chun an chatagóir chosanta a shainaithint, agus 0.97 chun an cineál ionsaí a bhrath. Eisímid ár gcód ag https://github.com/harisbinzia/HatefulMemes', 'el': 'Τα υπομνήματα είναι οι συνδυασμοί κειμένου και εικόνων που έχουν συχνά χιούμορ στη φύση τους. Αλλά, αυτό μπορεί να μην συμβαίνει πάντα, και ορισμένοι συνδυασμοί κειμένων και εικόνων μπορεί να απεικονίζουν μίσος, που αναφέρονται ως μίσος μιμίδια. Η παρούσα εργασία παρουσιάζει μια πολυμορφική γραμμή που λαμβάνει υπόψη τόσο τα οπτικά όσο και τα κειμενικά χαρακτηριστικά των μιμιδίων για να (1) προσδιορίσει την προστατευόμενη κατηγορία (π.χ. φυλή, φύλο κ.λπ.) που έχει υποστεί επίθεση. και (2) να ανιχνεύσει το είδος της επίθεσης (π.χ. περιφρόνηση, προσβολές κ.λπ.). Ο αγωγός μας χρησιμοποιεί προηγμένες προ-εκπαιδευμένες οπτικές και κειμενικές αναπαραστάσεις, ακολουθούμενες από έναν απλό ταξινομητή λογιστικής παλινδρόμησης. Χρησιμοποιούμε τον αγωγό μας για το σύνολο δεδομένων Πρόκλησης μίσους Memes με πρόσθετες πρόσφατα δημιουργημένες λεπτόκοκκες ετικέτες για προστατευμένη κατηγορία και τύπο επίθεσης. Το καλύτερο μοντέλο μας επιτυγχάνει το 0.96 για τον προσδιορισμό της προστατευόμενης κατηγορίας και 0.97 για την ανίχνευση του τύπου της επίθεσης. Θα απελευθερώσουμε τον κωδικό μας στο https://github.com/harisbinzia/HatefulMemes', 'it': "Le meme sono le combinazioni di testo e immagini che sono spesso umoristiche in natura. Ma, potrebbe non essere sempre così, e alcune combinazioni di testi e immagini possono rappresentare l'odio, chiamato meme odiosi. Questo lavoro presenta una pipeline multimodale che tiene conto sia delle caratteristiche visive che testuali dei memi per (1) identificare la categoria protetta (ad esempio razza, sesso, ecc.) che è stata attaccata; e (2) rilevare il tipo di attacco (ad esempio disprezzo, insulti ecc.). La nostra pipeline utilizza rappresentazioni visive e testuali pre-addestrate all'avanguardia, seguite da un semplice classificatore di regressione logistica. Utilizziamo la nostra pipeline sul set di dati Hateful Memes Challenge con ulteriori etichette a grana fine create di recente per categoria protetta e tipo di attacco. Il nostro modello migliore raggiunge un AUROC di 0,96 per identificare la categoria protetta e 0,97 per rilevare il tipo di attacco. Rilasciamo il nostro codice a https://github.com/harisbinzia/HatefulMemes", 'ka': 'მემები არის ტექსტის და გამოსახულების კომბინციები, რომლებიც ხშირად ჰუმორურია. მაგრამ, ეს არ ყოველთვის შეიძლება ყოველთვის იყოს, და სწორი ტექსტის და გამოსახულების კომბინციაციები შეიძლება გამოსახულოთ მპატი, რომელიც მპატიური მემები ეს სამუშაო მულტიმოდიალური ფეხლინი, რომელიც მემებიდან ვიზუალური და ტექსტულური ფეხლინი გააკეთება (1) დააკეთებული კატეგორია (მაგალითად, პასუხი, სექსი და ექსუალური) რომე (2) ატაკტის ტიპის განახსნა (მაგალითად, ატაკტირება, ცხოვრება და ა.შ.). ჩვენი პერიოლინი გამოყენებს სახელსაწყისი სახელსაწყისი სახელსაწყისი და ტექსტური რესპეზიციების განმავლობაში, რომელიც განმავლებული ლოგისტიკური რეგრესიის კლასიფი ჩვენ ჩვენი გარეშე მებების გარეშე მონაცემების შესაძლებლობაში დავყენებთ დამატებული ახალი შექმნილი კონტაქტიური ლაბეჭებით დახმარებული კატეგორია და ტიპის გარეშე. ჩვენი საუკეთესო მოდელი 0.96-ის AUROC-ს მიიღება დახმარებული კატეგორია და 0.97-ს დაახმარებისთვის. ჩვენ ჩვენი კოდის გახსნა https://github.com/harisbinzia/HatefulMemes', 'lt': 'Memoriai yra teksto ir vaizdo deriniai, kurie dažnai yra humoriški gamtoje. Tačiau ne visada taip gali būti ir kai kurie tekstų ir vaizdų deriniai gali atspindėti neapykantą, vadinamą neapykantiniais memeis. Šiame darbe pateikiamas daugiarūšis vamzdynas, kuriame atsižvelgiama į vizualias ir tekstines memes savybes, kad (1) būtų nustatyta užpuolta apsaugota kategorija (pvz., rasė, lytis ir t. t.); ir (2) aptikti priepuolio tipą (pvz., neapykantą, slypus ir t. t.). Mūsų vamzdynas naudoja pažangiausius iš anksto apmokytus vaizdinius ir tekstinius rodmenis, po kurių eina paprastas logistinės regresijos klasifikatorius. Naudojame savo vamzdyną Hateful Memes Challenge duomenų rinkinyje su papildomomis naujai sukurtomis smulkių grūdų etiketėmis saugomai kategorijai ir tipo atakai. Mūsų geriausias modelis pasiekia AUROC 0,96 saugomos kategorijos nustatymui ir 0,97 užpuolimo tipo nustatymui. Mes išleidžiame savo kodą https://github.com/harisbinzia/HatefulMemes', 'ms': 'Memi adalah kombinasi teks dan imej yang sering bergembira dalam alam. Tetapi, yang mungkin tidak sentiasa berlaku, dan kombinasi tertentu teks dan imej boleh menggambarkan kebencian, yang disebut sebagai meme kebencian. Kerja ini menghasilkan saluran paip multimodal yang mengambil kedua-dua ciri visual dan teks dari meme ke akaun (1) mengenalpasti kategori yang dilindungi (cth. ras, seks dll.) yang telah diserang; and (2) detect the type of attack (e.g. contempt, slurs etc.).  Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier.  We employ our pipeline on the Hateful Memes Challenge dataset with additional newly created fine-grained labels for protected category and type of attack.  Our best model achieves an AUROC of 0.96 for identifying the protected category, and 0.97 for detecting the type of attack.  Kami melepaskan kod kami di https://github.com/harisbinzia/HatefulMemes', 'mk': 'Меморите се комбинациите на текст и слики кои често се хуморни во природата. Но, можеби не секогаш е така, и одредени комбинации на текстови и слики можат да ја прикажуваат омразата, наречена омразна мема. Оваа работа претставува мултимодилен гасовод кој ги зема во предвид визуелните и текстуалните карактеристики од мемите за (1) да ја идентификува заштитената категорија (на пример расата, сексот итн.) која е нападната; и (2) да го детектираат типот на напад (на пример, презир, кревети итн.). Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier.  Ние го употребуваме нашиот гасовод на податоците на Hateful Memes Challenge со дополнителни новоформирани фини ознаки за заштитена категорија и тип на напад. Нашиот најдобар модел постигнува AUROC од 0,96 за идентификација на заштитената категорија, и 0,97 за детектирање на типот на напад. Го ослободиме нашиот код на https://github.com/harisbinzia/HatefulMemes', 'mt': 'Il-memorji huma l-kombinazzjonijiet ta’ test u immaġni li spiss huma ta’ natura humoruża. Iżda, dan jista’ mhux dejjem ikun il-każ, u ċerti kombinazzjonijiet ta’ testi u stampi jistgħu juru mibegħda, imsemmija bħala memes mibegħda. Dan ix-xogħol jippreżenta pipeline multimodali li tqis kemm il-karatteristiċi viżivi kif ukoll dawk testwali mill-memes sa (1) tidentifika l-kategorija protetta (pereżempju r-razza, is-sess e ċċ.) li ġiet attakata; u (2) jidentifikaw it-tip ta’ attakk (e ż. kontent, slurs eċċ.). Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier.  Aħna nużaw il-pipeline tagħna fuq is-sett tad-dejta dwar l-Isfida tal-Memorji Hateful b’tikketti addizzjonali ġodda maħluqa fin-grains għall-kategorija protetta u t-tip ta’ attakk. L-aħjar mudell tagħna jikseb AUROC ta’ 0.96 għall-identifikazzjoni tal-kategorija protetta, u 0.97 għall-identifikazzjoni tat-tip ta’ attakk. Aħna nħelsu l-kodiċi tagħna fuq https://github.com/harisbinzia/HatefulMemes', 'ml': 'മെമ്മറുകള്\u200d പ്രകൃതിയില്\u200d പലപ്പോഴും തമാശയുള്ള ചിത്രങ്ങളുടെയും കൂട്ടത്തിലാണ്. പക്ഷെ, അത് എപ്പോഴും കേസ് അല്ലായിരിക്കും, ചില ല ലേഖനങ്ങളും ചില ഇങ്ങനെയുള്ള കൂട്ടത്തില്\u200d വെറുപ്പും എന്ന് വിളിക്കുന്നു. ഈ പ്രവര്\u200dത്തിക്കുന്നത് മെമ്മുകളില്\u200d നിന്നും കാഴ്ചകളില്\u200d നിന്നും ടെക്സ്കൂളില്\u200d നിന്നും സംരക്ഷിക്കപ്പെട്ട വിഭാഗങ്ങളിലേക്ക് തിരിച്ചറിയുന്ന ആക്രമണത്തിന്റെ തരത്തെ കണ്ടുപിടിക്കുക. നമ്മുടെ പൈപ്പെലൈന്\u200d മുമ്പ് പരിശീലിക്കപ്പെട്ട കാഴ്ചകളും ടെക്സ്കൂള്\u200d പ്രതിനിധികളും സ്ഥാനം ഉപയോഗിക്കുന്നു. പിന്നീട് ഒരു  നമ്മള്\u200d നമ്മുടെ പൈപ്പെലൈന്\u200d വെറുപ്പുള്ള മെമ്മെസ് ചാലഞ്ചെന്\u200dജ് ഡേറ്റാസെറ്റില്\u200d ഉപയോഗിക്കുന്നു. കൂടുതല്\u200d പുതുതായി സംരക്ഷ സംരക്ഷിക്കപ്പെട്ട വിഭാഗങ്ങളെ തിരിച്ചറിയുന്നതിനായി നമ്മുടെ ഏറ്റവും നല്ല മോഡല്\u200d 0.96-ല്\u200d ഒരു AUROC നേടുന്നു. പിന്നെ 0.97- നമ്മള്\u200d നമ്മുടെ കോഡ് വിടുന്നു https://github.com/harisbinzia/HatefulMemes', 'mn': 'Нөмбөлөгүүд бол байгалийн хувьд ихэвчлэн хямралтай текст болон зургуудын нэгдэл юм. Гэхдээ энэ нь үргэлж биш байж магадгүй. Зарим бичлэг, зураг хоорондоо үзэн ядах сэтгэл санаанууд гэж нэрлэгддэг. Энэ ажил мембраас харагдах болон текстуралдаа (1) хүртэл хамгаалагдсан хэлбэрийг (жишээ нь, урсгал, секс, т.д.) тодорхойлдог олон загварын хоолойн шугам гаргадаг. (2) халдварын төрлийг олж мэднэ (жишээ нь, зөрчилдөөн, булчин, т.д.). Бидний хоолойн шугам нь урлагийн хувьд сургалтын өмнө сургалтын үзүүлэлтийг ашигладаг. Тэгээд энгийн логист сэтгэл хөдлөлийн хэлбэртэй. Бид Hateful Memes Challenge өгөгдлийн сан дээр хоолойн шугам хэрэглэдэг. Хамгаалалтай хэлбэрийн болон төрлийн атлааны хамгаалалтын тулд нэмэлт шинэ бүтээгдэхүүнтэй тэмдэглэгдсэн. Хамгийн шилдэг загвар нь хамгаалалтай хэлбэрийг тодорхойлдохын тулд 0.96 АРОК болон 0.97 атлааны төрлийг тодорхойлдохын тулд. Бид кодыг https://github.com/harisbinzia/HatefulMemes', 'hu': 'A memes a szöveg és kép kombinációja, amely gyakran humoros természetű. De ez nem mindig így van, és a szövegek és képek bizonyos kombinációi gyűlöletet ábrázolhatnak, amit gyűlöletes mémeknek neveznek. Ez a munka egy multimodális csatornát mutat be, amely figyelembe veszi a mémek vizuális és szöveges jellemzőit (1) annak érdekében, hogy azonosítsa a megtámadott védett kategóriát (például faj, nem stb.). és (2) felismerni a támadás típusát (pl. megvetés, káromlás stb.). Csővezetékünk korszerű, előre képzett vizuális és szöveges ábrázolásokat használ, amelyeket egy egyszerű logisztikai regressziós osztályozó követ. A Hateful Memes Challenge adatkészletünket használjuk további újonnan létrehozott finomszemcsés címkékkel a védett kategóriákhoz és típusokhoz. A legjobb modellünk 0,96 AUROC értéket ér el a védett kategória azonosítására, és 0,97 a támadás típusának észlelésére. Kiadjuk a kódot a https://github.com/harisbinzia/HatefulMemes', 'no': 'Memar er kombinasjonane av tekst og bilete som ofte er humør i naturen. Men det kan kanskje ikkje alltid vera tilfellet, og enkelte kombinasjonar av tekst og bilete kan visa hatt, som kalla som hattige memer. Denne arbeidet viser eit multimodal røyrlinje som tar både visuelle og tekstuelle funksjonar frå memer til (1) til å identifisera beskyttet kategori (f.eks. rase, seks osv.) som er brukt. og (2) oppdag type bruk (f.eks. forstørring, slur osv.). Ver røyrlinje bruker føretrainerte visuelle og tekstuelle representasjonar som er tilstand til kunsten, etterfulgt av ein enkel logistisk regresjonsklassering. Vi bruker røyrlinja vårt på Hateful Memes Challenge-dataset med fleire nytt oppretta fin-korn-etikettar for beskyttet kategori og type attack. Det beste modellen vårt finn ein AUROC av 0,96 for å identifisera beskyttet kategori, og 0,97 for å oppdaga typen ataka. Vi løyser koden vår på https://github.com/harisbinzia/HatefulMemes', 'pl': 'Memy to kombinacje tekstu i obrazów, które często mają humorystyczną naturę. Ale nie zawsze tak może być, a pewne kombinacje tekstów i obrazów mogą przedstawiać nienawiść, określane jako memy nienawiści. W pracy przedstawiono multimodalny rurociąg, który uwzględnia zarówno cechy wizualne, jak i tekstowe memów, aby (1) zidentyfikować chronioną kategorię (np. rasę, płeć itp.), która została zaatakowana; i (2) wykryć rodzaj ataku (np. pogarda, obrzydzenia itp.). Nasz rurociąg wykorzystuje najnowocześniejsze, wstępnie przeszkolone reprezentacje wizualne i tekstowe, a następnie prosty klasyfikator regresji logistycznej. Używamy naszego rurociągu na zbiorze danych Hateful Memes Challenge z dodatkowymi nowo utworzonymi drobnoziarnistymi etykietami dla chronionej kategorii i rodzaju ataku. Nasz najlepszy model osiąga AUROC 0.96 do identyfikacji chronionej kategorii, a 0.97 do wykrywania rodzaju ataku. Wydajemy nasz kod pod adresem: https://github.com/harisbinzia/HatefulMemes', 'ro': 'Memele sunt combinațiile de text și imagini care sunt adesea umoristice în natură. Dar, este posibil să nu fie întotdeauna cazul, iar anumite combinații de texte și imagini pot reprezenta ura, denumită meme-uri pline de ură. Această lucrare prezintă o conductă multimodală care ia în considerare atât caracteristicile vizuale, cât și textuale ale memelor pentru a (1) identifica categoria protejată (de exemplu rasă, sex etc.) care a fost atacată; și (2) detectează tipul de atac (de exemplu dispreț, insulte etc.). Conducta noastră utilizează reprezentări vizuale și textuale de ultimă generație pre-instruite, urmate de un simplu clasificator de regresie logistică. Folosim pipeline-ul nostru pe setul de date Hateful Memes Challenge cu etichete noi create cu granule fine pentru categoria protejată și tipul de atac. Cel mai bun model al nostru atinge un AUROC de 0,96 pentru identificarea categoriei protejate și 0,97 pentru detectarea tipului de atac. Ne eliberăm codul la https://github.com/harisbinzia/HatefulMemes', 'si': 'මතකය තමයි පිළිබඳ සහ පිළිබඳ සම්බන්ධතාවක් ස්වභාවිතයේ හිතාවෙන්නේ. ඒත්, ඒක හැම වෙලාවෙම විදියට නෙවෙයි, සහ පිළිපත්තු සහ පිළිපත්තු සම්බන්ධතාවක් විශ්වාස කරන්න පුළුවන්, වෛ This job presents a Multi-Model Pipe line that holds both Visal and textal Fearts from Mems to (1) account to (1) to (e.g. Race, sex etc.) that has be bombed; and (2) ප්\u200dරහාරයේ වර්ගයක් හොයාගන්න (උදාහරණය, ස්ලෝර් ඉතින්). අපේ පායිප්ලයින් පාවිච්චි විදිහට ප්\u200dරධානය කරලා තියෙන්නේ ප්\u200dරධානය සහ පාවිච්චි ප්\u200dරධානය, පස්සේ සාමාන අපි අපේ පායිප්ලින් ප්\u200dරයෝජනය කරනවා Hateful Memes චැල්යැන්ජ් දත්ත සෙට් එක්ක අලුත් අලුත් නිර්මාණය කරලා තියෙන්නේ සුරක අපේ හොඳම මදුල 0.96 වල AUROC එකක් ලැබෙනවා ආරක්ෂා කණ්ඩායම අඳුරගන්න, සහ 0.97 වල පහරක් වර්ගයක් හොයාගන්න. අපි අපේ කෝඩ් එක නිදහස් කරනවා. https://github.com/harisbinzia/HatefulMemes', 'sv': 'Memes är kombinationer av text och bilder som ofta är humoristiska i naturen. Men det kanske inte alltid är fallet, och vissa kombinationer av texter och bilder kan skildra hat, som kallas hatiska memes. Detta arbete presenterar en multimodal pipeline som tar hänsyn till både visuella och textmässiga egenskaper från memes för att (1) identifiera den skyddade kategorin (t.ex. ras, kön etc.) som attackerats; och (2) upptäcka typen av attack (t.ex. förakt, slurs etc.). Vår pipeline använder state-of-the-art förutbildade visuella och textuella representationer, följt av en enkel logistisk regressionsklassificering. Vi använder vår pipeline på Hateful Memes Challenge datauppsättningen med ytterligare nyskapade finkorniga etiketter för skyddad kategori och typ av attack. Vår bästa modell uppnår en AUROC på 0,96 för att identifiera den skyddade kategorin och 0,97 för att upptäcka typen av attack. Vi släpper vår kod på https://github.com/harisbinzia/HatefulMemes', 'sr': 'Memi su kombinacije teksta i slika koje su često humorozne u prirodi. Ali to ne može uvek biti slučaj, a određene kombinacije teksta i slika mogu pokazati mržnju, nazvane kao mržnje meme. Ovaj rad predstavlja multimodalnu cijevinu koja uzima i vizualne i tekstualne karakteristike od meme u obzir do (1) identificira zaštićenu kategoriju (npr. rasu, seks itd.) koja je napadnuta; i (2) otkrivaju vrstu napada (npr. preziranje, slušalice itd.). Naša cijevina koristi predobučene vizuelne i tekstualne predstave, praćene jednostavnim klasifikatorom logističke regresije. Mi zapošljavamo svoju cijevinu na setu podataka o "Hateful Memes Challenge". Naš najbolji model postiže AUROC od 0,96 za identifikaciju zaštićene kategorije i 0,97 za otkrivanje vrsta napada. Puštamo naš kod na https://github.com/harisbinzia/HatefulMemes', 'so': 'Xafiisyadu waa isugu xidhiidha qoraalka iyo sawirada, kuwaas oo inta badan lagu fududeeyo dabiicadda. Laakiin, taasi waa suurtowda inay mar walba ahaato xaalad, oo isbaro qoraal iyo sawirro qaarkood waxay ku soo bandhigi karaan nebcaad, taasoo looga jeedo meymo nebcaad ah. Shaqodanku wuxuu soo bandhigaa baabuur faro badan oo ka soo qaadata xuquuqda aragga iyo qoraalka, si uu u caddeeyo kooxda la ilaaliyey (tusaale ahaan race, sex etc.) oo lagu weeraray; Iyo garashada dagaalka caynkiisa ah. Baalooyinkayada ayaa isticmaalaya xukunka farshaxanta hore iyo muuqashada iyo qoraalka, waxaana sidoo kale fasax fudud qoraalka xisaabinta. Waxaynu ku shaqaynaynaa dabeecadeena ee macluumaadka badbaadada Hateel Memmes Challenge, waxaana ku qornaa calaamado kale oo cusub oo la sameynay kooxo la ilaaliyo iyo cayn kasta oo weerar ah. Tusaale ahaan ugu wanaagsan wuxuu gaadhaa AUROC oo ku qoran 0.96 si uu u aqoonsado kooxda la ilaaliyay iyo 0.97 si uu u ogaado nooca weerarka ah. waxaynu furaynaa sumaddeena https://github.com/harisbinzia/HatefulMemes', 'ta': 'நினைவகங்கள் பெரும்பாலும் வேடிக்கையான உரைகள் மற்றும் படங்களின் இணைப்புகள். ஆனால், அது எப்போதும் விஷயமாக இருக்கலாம், மற்றும் சில உரைகள் மற்றும் பிம்பங்களின் இணைப்புகள், வெறுப்புப் பொருள் என்று க இந்த வேலை ஒரு பல்வேறு புள்ளியை கூட்டுகிறது அது மெம்களில் இருந்து பார்வையும் உரை பண்புகளையும் கணக்கில் எடுத்து (1) பாதுகாப்பாக்கப்பட்ட வகுப்பை கண் and (2) detect the type of attack (e.g. contempt, slurs etc.).  எங்கள் பைப்லைன் முன் பயிற்சி முன் தெரியும் காட்சி மற்றும் நிரல் பார்வைகளை பயன்படுத்துகிறது, பின்னர் ஒரு எளிய நுட்பம் மறுக நாங்கள் வெறுப்பு நினைவுகள் சங்கால தரவுத்தளத்தில் எங்கள் பைப்லைனை வேலை செய்ய வேண்டும் பாதுகாப்பு வகையில் மற்றும் தாக்கு எங்கள் சிறந்த மாதிரி 0. 96-ல் ஒரு AUROC பெறுகிறது பாதுகாப்பான வகுப்பை கண்டறியும், மற்றும் 0. 97 எத்தனை தோற்றம் கண்டறியும். நாங்கள் எங்கள் குறியீட்டை விடுவோம் https://github.com/harisbinzia/HatefulMemes', 'ur': 'Memes are the combinations of text and images that often humore in nature. لیکن یہ ہمیشہ ایسا نہ ہو سکتا ہے، اور بعض پیغام اور تصاویروں کی تعداد کثیر تعداد کثیر تعداد کثیر تعداد کثیر نفرت کو دکھائے جاتے ہیں، جن کا نام ناپسند ذکر ہے۔ یہ کام ایک multimodal pipeline پیش کرتا ہے جو مہموں سے دکھانے والی اور تفصیل کے علائم کو (1) تک پہچان لیتا ہے جو حملہ کیا گیا ہے۔ اور کس طرح حملہ کرتے ہیں ہمارے پائپ لین کے ساتھ ایک ساده لوجیسٹیکی ریگرس کلاسیٹر کے ساتھ استعمال کرتا ہے۔ ہم Hateful Memes Challenge ڈاٹ سٹ پر اپنا پیپ لین استعمال کرتے ہیں اور اس کے ساتھ اضافہ نئے پیدا کیے ہوئے نیک دانے لیبل محفوظت کیے جاتے ہیں ہمارے بہترین موڈل 0.96 کی AUROC کو پہنچا سکتا ہے کہ محفوظت کی کاٹیوں کو پہچان سکتا ہے اور 0.97 حملہ کی طرح کو پہچان سکتا ہے. ہم اپنے کوڈ کو آزاد کرتے ہیں https://github.com/harisbinzia/HatefulMemes', 'kk': 'Жазбалар - тәуелдегі мәтін мен кескіндердің жинақтауы. Бірақ бұл әрқашан болмауы мүмкін, мәтін мен кескіндердің бірнеше жинақтары қарсы деп аталады. Бұл жұмыс мемемдерден көрінетін және мәтіндік қасиеттерін (1) дегенге (мысалы, жұлдыз, секс және т. б.) қорғалған сақталған санаттарды анықтайтын көптеген қорғау жолын көрсетеді. және (2) қарсы түрін анықтау (мысалы, қарсы және т. б.). Қызықтық күй- жағдайды алдын- оқылған көрініс және мәтіндік түсініктерді қолданады, кейін қарапайым логистикалық регрессия классификациясынан келеді. Біз Hateful Memes Challenge деректерін қолданып, қорғалған санаттар мен атқару түрі үшін жаңа жаңа құрылған жарлық жарлық жарлықтарымен қолданып тұрамыз. Біздің ең жақсы моделіміз сақталған санатты анықтау үшін 0, 96 AUROC жұмыс істейді, және 0, 97 атқару түрін анықтау үшін. Біз кодымызды https://github.com/harisbinzia/HatefulMemes', 'uz': "Xotiradan matn va rasmlarning birlashtirish va oddiy tabda juda qiziqarli. Lekin, bu hamisha holatda emas, va bir necha matn va rasmlar bir qanchalik bir qanchalik bir qanday bir qanday bir qanday bir necha narsalarni ko'rsatishi mumkin. Ushbu ishni bir multimodal pipelin koʻrinishi va matnning xususiyatlarini o'zgartirish (1) hisobotidan himoyalangan kategorini (m. g. race, sex va etc.) aniqlash. Ва у(нафс)нинг турли ҳийлаларини билдиради. Bizning pipeline o'rganilgan birinchi o'rganishdan oldin ko'rinish va matn taʼminlovchilardan foydalanadi, keyin oddiy logistik repression classifiseri tomonidan foydalanadi. Biz Xavfsiz xotiralar haqida qo'llanmiz, bir qanchalik taqdim va shamol turini himoyalash uchun yangi qo'shilgan yaxshi qo'llangan yorliqlarni ishlaymiz. Bizning eng yaxshi modelmiz, saqlangan turni aniqlash uchun 0.96'ning AUROC bo'ladi, va 0.97 turini aniqlash uchun. Biz qoidamizni https://github.com/harisbinzia/HatefulMemes", 'vi': 'Những ký ức là những kết hợp của văn bản và hình ảnh thường mang tính hài hước. Nhưng có lẽ không phải lúc nào cũng vậy, và một số kết hợp của văn bản và hình ảnh có thể miêu tả sự thù hận, được gọi là những ký ức đáng ghét. Công trình này là một đường ống đa phương, chứa cả hình ảnh lẫn cấu trúc của các ký ức, để xác định các loại bảo vệ (v. d. chủng tộc, tình dục, v. d. đã bị tấn công; và (2) phát hiện dạng tấn công (v. d. khinh thường, líu dụ, v. d. Đường ống của chúng tôi sử dụng các biểu tượng hình ảnh và kết cấu được đào tạo tiên tiến, sau đó là một chuyên gia phân hồi quy mô đơn giản. Chúng tôi sử dụng đường ống của chúng tôi trên tập tin đáng ghét Memes Challeng cùng với các nhãn đặc sắc mới được tạo thêm cho hạng bảo vệ và kiểu tấn công. Người mẫu tốt nhất đạt được chiếc AUROC của 0.6 để xác định các loại bảo vệ, và 0.97 để phát hiện các kiểu tấn công. Chúng ta giải mã ở... https://github.com/harisbinzia/HatefulMemes', 'bg': 'Мемите са комбинации от текст и изображения, които често са хумористични по природа. Но това може и да не е винаги така и някои комбинации от текстове и изображения могат да изобразяват омраза, наричана омразни меми. Тази работа представя мултимодален тръбопровод, който взема предвид както визуалните, така и текстовите особености от мемите, за да (1) идентифицира защитената категория (например раса, пол и т.н.), която е била атакувана; и (2) открива вида на атаката (напр. презрение, обиди и т.н.). Нашият тръбопровод използва най-съвременни предварително обучени визуални и текстови изображения, последвани от прост логистичен регресионен класификатор. Ние използваме нашия тръбопровод върху набора от данни с допълнителни новосъздадени фино зърнести етикети за защитена категория и тип атака. Най-добрият ни модел постига АУРОК от 0.96 за идентифициране на защитената категория и 0.97 за откриване на вида атака. Ще пуснем кода на https://github.com/harisbinzia/HatefulMemes', 'nl': 'Memes zijn de combinaties van tekst en beeld die vaak humoristisch van aard zijn. Maar dat kan niet altijd het geval zijn, en bepaalde combinaties van teksten en beelden kunnen haat weergeven, aangeduid als hatelijke memes. Dit werk presenteert een multimodale pipeline die zowel visuele als tekstuele kenmerken van memes in aanmerking neemt om (1) de beschermde categorie (bv. ras, geslacht enz.) te identificeren die is aangevallen; en (2) detecteren van het type aanval (bv. minachting, beledigingen enz.). Onze pipeline maakt gebruik van state-of-the-art voorgetrainde visuele en tekstuele representaties, gevolgd door een eenvoudige logistieke regressie classificator. We gebruiken onze pipeline op de Hateful Memes Challenge dataset met extra nieuw gemaakte fijnkorrelige labels voor beschermde categorie en type aanval. Ons beste model bereikt een AUROC van 0.96 voor het identificeren van de beschermde categorie, en 0.97 voor het detecteren van het type aanval. We geven onze code uit op https://github.com/harisbinzia/HatefulMemes', 'hr': 'Memi su kombinacije teksta i slika koje su često humorozne u prirodi. Ali to ne može uvijek biti slučaj, a određene kombinacije teksta i slika mogu pokazati mržnju, nazvane kao mržnje meme. Ovaj rad predstavlja multimodalnu cijevinu koja uzima i vizualne i tekstualne karakteristike od meme u obzir na (1) identificiraju zaštićenu kategoriju (npr. rasu, seks itd.) koja je napadnuta; i (2) otkrivanje vrsta napada (npr. preziranje, slušalice itd.). Naša cijevina koristi predobučene vizuelne i tekstualne predstave, slijedeće jednostavnim klasifikatorom logističke regresije. Mi zapošljavamo cijevin na kompletu podataka o "Hateful Memes Challenge". Naš najbolji model postigne AUROC od 0,96 za identifikaciju zaštićene kategorije i 0,97 za otkrivanje vrsta napada. Puštamo naš kod na https://github.com/harisbinzia/HatefulMemes', 'da': 'Memes er kombinationer af tekst og billeder, der ofte er humoristiske i naturen. Men det er måske ikke altid tilfældet, og visse kombinationer af tekster og billeder kan skildre had, kaldet hadefulde memes. Dette arbejde præsenterer en multimodal pipeline, der tager højde for både visuelle og tekstmæssige træk fra memer for (1) at identificere den beskyttede kategori (f.eks. race, køn osv.), der er blevet angrebet; og (2) opdage typen af angreb (f.eks. foragt, slurs osv.). Vores pipeline bruger state-of-the-art præ-trænede visuelle og tekstlige repræsentationer efterfulgt af en simpel logistisk regressionsklassificator. Vi anvender vores pipeline på Hateful Memes Challenge datasættet med yderligere nyoprettede finkornede etiketter til beskyttet kategori og type angreb. Vores bedste model opnår en AUROC på 0,96 til identifikation af den beskyttede kategori og 0,97 til detektering af typen af angreb. Vi frigiver vores kode på https://github.com/harisbinzia/HatefulMemes', 'de': 'Memes sind die Kombinationen von Text und Bild, die oft humorvoll sind. Aber das mag nicht immer der Fall sein, und bestimmte Kombinationen von Texten und Bildern können Hass darstellen, die als hasserfüllte Meme bezeichnet werden. Diese Arbeit stellt eine multimodale Pipeline vor, die sowohl visuelle als auch textliche Merkmale von Memen berücksichtigt, um (1) die geschützte Kategorie (z.B. Rasse, Geschlecht usw.) zu identifizieren, die angegriffen wurde; und (2) die Art des Angriffs erkennen (z.B. Verachtung, Beleidigungen usw.). Unsere Pipeline verwendet modernste vortrainierte visuelle und textuelle Darstellungen, gefolgt von einem einfachen logistischen Regressionsklassifikator. Wir verwenden unsere Pipeline auf dem Datensatz Hateful Memes Challenge mit zusätzlichen, neu erstellten, feinkörnigen Labels für geschützte Kategorie und Art des Angriffs. Unser bestes Modell erreicht einen AUROC von 0.96 zur Identifizierung der geschützten Kategorie und 0.97 zur Erkennung der Art des Angriffs. Wir veröffentlichen unseren Code unter https://github.com/harisbinzia/HatefulMemes', 'id': 'Memori adalah kombinasi teks dan gambar yang sering humor dalam alam. Tapi, itu mungkin tidak selalu terjadi, dan beberapa kombinasi teks dan gambar bisa menggambarkan kebencian, yang disebut sebagai meme kebencian. Pekerjaan ini mempersembahkan pipa multimodal yang mengambil fitur visual dan tekstual dari meme ke (1) mengidentifikasi kategori yang dilindungi (misalnya ras, seks dll.) yang telah diserang; dan (2) mendeteksi jenis serangan (misalnya penghinaan, penghinaan dan sebagainya). Pipa kami menggunakan represensi visual dan tekstual yang terbaik, diikuti oleh klasifikasi regresi logistik sederhana. Kami menggunakan saluran pipa kami pada set data tantangan Memes Hateful dengan tambahan label baru yang diciptakan fine grained untuk kategori yang dilindungi dan jenis serangan. Model terbaik kita mencapai AUROC 0,96 untuk mengidentifikasi kategori yang dilindungi, dan 0,97 untuk mendeteksi jenis serangan. Kami melepaskan kode kami di https://github.com/harisbinzia/HatefulMemes', 'ko': '모인은 텍스트와 이미지의 조합으로 통상적으로 유머성을 가지고 있다.그러나 상황이 항상 그렇지는 않을 수도 있고 텍스트와 이미지의 일부 조합은 원한을 묘사할 수도 있어 원한의 모인이라고 불린다.이 작업은 모드의 시각과 텍스트 특징을 고려하여 (1) 공격을 받은 보호받는 유형(예를 들어 인종, 성별 등)을 확정하는 다중모드 파이프라인을 제시했다.그리고 (2) 공격 유형(예를 들어 멸시, 비방 등)을 검출한다.우리의 파이프라인은 가장 선진적인 사전 훈련된 시각과 텍스트 표시를 사용하고 그 다음에 간단한 논리 회귀 분류기를 사용한다.우리는 증오의 Memes Challenge 데이터 집합에 우리의 파이프를 사용하고 보호된 공격 종류와 유형에 새로 만든 세립도 라벨을 추가했다.우리의 가장 좋은 모델은 0.96의 AUROC를 실현하여 보호된 종류를 식별하고 0.97을 공격 유형을 검출하는 데 사용했다.우리https://github.com/harisbinzia/HatefulMemes', 'fa': 'اعضای ترکیب متن و تصاویر است که اغلب در طبیعت خنده دارند. ولی این ممکن نیست همیشه موضوع باشد، و تعدادی از متن\u200cها و تصاویرها ممکن است متنفر را نشان دهند، به عنوان متنفر\u200cکنندگان. این کار یک لوله\u200cی چندین مدال را نشان می\u200cدهد که هر دو ویژه\u200cهای دیده\u200cای و متن را از میم\u200cها به حساب می\u200cگیرد تا (۱) گونه\u200cای محافظت شده (مثلاً نژاد، سکس و غیر از آن) که حمله شده است شناسایی می\u200cکند. و نوع حمله را شناسایی کنید. لوله\u200cی ما از نمایش\u200cهای دیده\u200cای و متن پیش آموزش آموزش\u200cشده\u200cای استفاده می\u200cکند، و از طریق یک گروهی ساده\u200cای از گروهی\u200cهای لوژیک استفاده می\u200cکند. ما خط لوله\u200cمون را در مجموعه\u200cی داده\u200cهای دشمنی از Memes Challenge استفاده می\u200cکنیم با نقاشی\u200cهای جدید ساخته شده\u200cای برای مجموعه\u200cهای محافظت و نوع حمله. بهترین مدل ما به یک AUROC از 0.96 برای شناسایی قسمت محافظت و 0.97 برای شناسایی نوع حمله رسیده است. ما کد خود را در https://github.com/harisbinzia/HatefulMemes', 'sw': 'Kumbukumbu ni muunganiko wa maandishi na picha ambazo mara nyingi hufurahisha katika mazingira. Lakini, hiyo haiwezi kuwa kesi, na baadhi ya jumuiya za maandishi na picha zinaweza kuonyesha chuki, inayoitwa kama ujumbe wenye chuki. Kazi hii inaonyesha pipeli ya viumbe vinavyochukua vipande vya kuona na viungo vya maandishi kutoka kwenye ujumbe wa kuangalia (1) kutambua kundi linalolindwa (kama vile rangi, ngono etc.) ambalo limeshambuliwa; na kugundua aina ya shambulio (mfano). Usafiri wetu unatumia hali ya watu wa sanaa walio na mafunzo ya awali na wahamasishaji wa msingi, ukifuatiwa na mwangazaji rahisi wa ukandamizaji wa kisiasa. Tunatumia picha zetu kwenye taarifa za Challenge za Kumbukumbu za Hati kwa kutumia alama mpya zilizotengenezwa vizuri kwa ajili ya kulinda makundi na aina ya mashambulizi. Mfano wetu bora unapata AUROC wa 0.96 kwa kutambua makundi yaliyolindwa, na 0.97 kwa kutambua aina ya shambulio. Tunaachia sheria zetu https://github.com/harisbinzia/HatefulMemes', 'tr': "Hizmetler adatça samsyklykly metin we suratlaryň birleşigidir. Emma bu şekilde elmydama däldir, we metin we suratlaryň belli kombinasyonlary ýigrenç memeler diýip adlandırılýar. Bu işe memelerden hem g örsel hem metin özelliklerini biljek bir multimodal pipelini (1) tarapyna gollanan kategoriýany tanap edýär (mysal ýarym, seks we ş.b.); (2) atyk hilini tanyşdyr (myselýe, harplar oswa.). Bizim kanallarımız basit bir lojik regresi klasifikatörü tarafından eğitilmiş görüntüler ve teknisal temsilleri kullanır. Hateful Memes Challenge datumlarymyzda pipeline'imizi korunan kategoriýa we salyk üçin taze döredilen fin-grain etiketlerimizle işleýäris. Biziň iň gowy nusgymyz 0.96-nji AUROC guruldy goraglanylan kategoriýany tanamak üçin we 0.97-nji salyk hilini tanamak üçin ýetip barýar. Biz öz kodymyzy şol ýerde goýýarys https://github.com/harisbinzia/HatefulMemes", 'af': "Meme is die kombinasies van teks en beelde wat dikwels humoreer is in die natuur. Maar, dit dalk mag nie altyd die geval wees nie, en sekere kombinasies van teks en beelde kan die haat vertoon, terwyl dit as haatlike memos vertoon word. Hierdie werk stel 'n multimodaal pyplyn wat beide visuele en tekstuele funksies neem van memes na rekening tot (1) identifiseer die beskermde kategorie (bv. rase, seks ensfh.) wat geval is; en en (2) die tipe van atak (bv. veragting, slurs ensfh.). Ons pyplyn gebruik state-of-the-art voor-opgelei visuele en tekstuele voorstellings, volg deur 'n eenvoudige logistike regresie klassifiseerder. Ons gebruik ons pyplyn op die Hateful Memes Challenge datastel met addisionele nuwe gemaak fyn-koring etikette vir beskermde kategorie en tipe aanval. Ons beste model het 'n AUROC van 0. 96 bereik om die beskermde kategorie te identifiseer, en 0. 97 vir die tipe van atak te ontdek. Ons verlos ons kode by https://github.com/harisbinzia/HatefulMemes", 'sq': 'Kujtimet janë kombinimet e tekstit dhe imazheve që shpesh janë humore në natyrë. Por, kjo mund të mos jetë gjithmonë rasti, dhe disa kombinime tekstesh dhe imazhesh mund të përshkruajnë urrejtjen, të quajtur meme urrejtje. Ky punë paraqet një tubacion multimodal që merr në konsideratë si karakteristikat vizuale ashtu edhe tekstuale nga memet për (1) të identifikojë kategorinë e mbrojtur (për shembull gara, seksi etj.) që është sulmuar; dhe (2) të zbulojnë llojin e sulmit (për shembull urrejtje, g ënjeshtra etj.). Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier.  Ne përdorim tubacionin tonë në grupin e të dhënave të sfidave të Memories Hateful me etiketa të reja të krijuara të holla për kategorinë e mbrojtur dhe llojin e sulmit. Modeli ynë më i mirë arrin një AUROC prej 0.96 për identifikimin e kategorisë së mbrojtur dhe 0.97 për zbulimin e tipit të sulmit. Ne lëshojmë kodin tonë në https://github.com/harisbinzia/HatefulMemes', 'am': 'ማስታወሻዎች የጽሑፍ እና ምስሎችን ማሰናከል ነው፡፡ ነገር ግን ሁልጊዜ ወቅት እንዳይሆን፣ አንዳንድ የጽሑፎች እና ምስሎች ጥላቻን እንዲያስታውሱ የሚችል፣ የተጠሉ ብልቶች ናቸው፡፡ ይህ ሥራ የተጠበቀውን ክፍል (e.g. race, sex etc.) በተመሳሳይ የዓይነት እና የጽሑፍ ምርጫዎችን ከመጠቀም (1) የሚወስደውን አካል (1) ያሳያል፡፡ (2) የዓይነቱ ምሳሌ ማግኘት ፖሊስነታችን የቀድሞው የራእይ እና የጽሑፍ መልዕክቶችን የሚጠቀም፣ በተጨማሪው የሎጂክ ክፍለ ግንኙነት በተለየ፡፡ የጠልቅ ማስታወቂያውን ዳታ ላይ እናስቀምጣለን፡፡ የተጠበቀውን ክፍል ለማግኘት የ0.96 የሆኑት አርኦሲ አግኝቷል፡፡ ቀድሞችንን በ https://github.com/harisbinzia/HatefulMemes', 'az': 'Memlər təbiətdə çox humor olan mətn və şəkillərin kombinatsiyasıdır. Lakin bu, həmişə olaraq deyil, məktub və şəkillərin bəzi birləşdirilməsi nifrəti göstərə bilər, nifrətli meme kimi adlandırılır. Bu işlər memelərdən g örünürlü və textual özellikləri (1) ilə hesablayan çoxlu modal bor çizgisini göstərir ki, saldıqları mühafizə edilən kategoriyanı (məsələn rası, cins və s.). Və həddi-büluğa nəsib olduqlarını g örün. Bizim bor çizgimiz təhsil edilmiş görünüllü və tekst göstəricilərini istifadə edir, sonra basit logistik regresiya klasifikatçısı tərəfindən istifadə edir. Biz Hateful Memes Challenge verilər qutusunda pipeline istifadə edirik ki, korunmuş kategoriya və salınma türü üçün yeni yaradılmış fin dənəli etiketlər ilə. Bizim ən yaxşı modelimiz qorunmuş kategoriyanı təsdiqləmək üçün 0,96 AUROC və saldırma türünü təsdiqləmək üçün 0,97. Biz kodumuzu https://github.com/harisbinzia/HatefulMemes', 'bn': 'মেমো হচ্ছে টেক্সট এবং ছবির সম্মিলন যা প্রকৃতিতে প্রায়শই মজার। কিন্তু এটা সবসময় কেস নয়, এবং কিছু টেক্সট এবং ছবির সংযোগ হতে পারে ঘৃণা এবং ঘৃণা হিসেবে বলা হয়। এই কাজের একটি মাল্টিমোডাল পাইপেলাইন উপস্থাপন করে যা মেম থেকে দৃশ্য এবং টেক্সুয়াল বৈশিষ্ট্য একাউন্টে নিয়ে যায় (১) সুরক্ষিত শ্রেণীকে চিহ্নিত করা  এবং এই ধরনের আক্রমণ সনাক্ত করুন (যেমন অপমান, ইত্যাদি)। আমাদের পাইপেলাইন শিল্পের পূর্ব প্রশিক্ষিত দৃষ্টিভঙ্গি এবং টেক্সচুয়াল প্রতিনিধিত্ব ব্যবহার করে, তার পরে একটি সহজ লজিস্টিক র আমরা আমাদের পাইপেলাইন ঘৃণা মেমেস চ্যালেঞ্জের ডাটাসেটে চাকুরি করি আরো নতুন সুরক্ষিত শ্রেণীর এবং ধরনের আক্রমণের জন্য নতুন ভালো গ্রে আমাদের সবচেয়ে ভাল মডেল ০. ৯৬ এর একটি AUROC অর্জন করে সুরক্ষিত বিভাগ সনাক্ত করার জন্য এবং এই ধরনের আক্রমণ খুঁজে বের করার জন্য ০. 97। আমরা আমাদের কোড ছেড়ে দেই https://github.com/harisbinzia/HatefulMemes', 'hy': 'Հիշողությունները տեքստի և պատկերների համադրություններ են, որոնք հաճախ հումորային են բնության մեջ: Բայց միշտ այդպես չէ, և տեքստների և պատկերների որոշ համադրություններ կարող են պատկերել ատելությունը, որը կոչվում է ատելության մեմեմ: Այս աշխատանքը ներկայացնում է բազմամոդալ խողովակաշար, որը հաշվի առնում է մեմերից տեսողական և տեքստային հատկությունները, որպեսզի (1) հայտնաբերի հարձակված պաշտպանված կատեգորիան (օրինակ ռասը, սեքսը և այլն): և (2) հայտնաբերել հարձակումների տեսակը (օրինակ անհամբերությունը, համբերումները և այլն): Մեր խողովակաշարը օգտագործում է նախապատրաստված տեսողական և տեքստալ ներկայացումներ, որոնց հետևում է պարզ լոգիստիկ ռեգրեսիայի դասակարգիչ: Մենք օգտագործում ենք մեր խողովակաշարը ատելի հիշողությունների մարտահրավերի տվյալների համակարգում, որտեղ ներկայացված են նորից ստեղծված գեղեցիկ պիտակներ պաշտպանված կատեգորիայի և հարձակումների տեսակի համար: Մեր լավագույն մոդելը հասնում է 0.96-ի ԱՈՌՕԿ-ին պաշտպանված կատեգորիայի հայտնաբերման համար և 0.97-ի հարձակումների տեսակի հայտնաբերման համար: Մենք ազատում ենք մեր կոդը https://github.com/harisbinzia/HatefulMemes', 'bs': 'Memi su kombinacije teksta i slika koje su često humorozne u prirodi. Ali to ne može uvijek biti slučaj, a određene kombinacije teksta i slika mogu pokazati mržnju, nazvane kao mržnje meme. Ovaj rad predstavlja multimodalnu cijevinu koja uzima i vizualne i tekstualne karakteristike od meme u obzir do (1) identificira zaštićenu kategoriju (npr. rasu, seks itd.) koja je napadnuta; i (2) otkrivaju vrstu napada (npr. prezirenje, slanje itd.); Naša cijevina koristi predobučene vizuelne i tekstualne predstave, praćene jednostavnim klasifikatorom logističke regresije. Mi zapošljavamo svoju cijevinu na setu podataka o neprijateljskim Memes Challenge sa dodatnim novorođenim etiketama za zaštićenu kategoriju i vrstu napada. Naš najbolji model postiže AUROC od 0,96 za identifikaciju zaštićene kategorije i 0,97 za otkrivanje vrsta napada. Puštamo naš kod na https://github.com/harisbinzia/HatefulMemes', 'et': 'Memed on teksti ja kujutiste kombinatsioonid, mis on sageli naljakad. Aga see ei pruugi alati nii olla ja teatud tekstide ja piltide kombinatsioonid võivad kujutada vihkamist, mida nimetatakse vihameemideks. Käesolevas töös esitatakse multimodaalne torujuhe, mis võtab arvesse meemide visuaalseid ja tekstilisi omadusi, et (1) tuvastada rünnatud kaitstud kategooria (nt rass, sugu jne); ja (2) tuvastada rünnaku tüüp (nt põlgus, solvamine jne). Meie torujuhe kasutab kaasaegseid visuaalseid ja tekstikujundusi, millele järgneb lihtne logistiline regressiooni klassifitseerija. Me kasutame oma torujuhet Hateful Memes Challenge andmekogumil, millel on täiendavad äsja loodud peeneteralised sildid kaitstud rünnaku kategooria ja tüübi jaoks. Meie parim mudel saavutab AUROC 0,96 kaitstud kategooria tuvastamiseks ja 0,97 rünnaku tüübi tuvastamiseks. Me avaldame oma koodi https://github.com/harisbinzia/HatefulMemes', 'fi': 'Muistot ovat tekstin ja kuvien yhdistelmiä, jotka ovat usein luonteeltaan humoristisia. Mutta niin ei välttämättä aina ole, ja tietyt tekstien ja kuvien yhdistelmät voivat kuvata vihaa, jota kutsutaan vihamielisiksi meemeiksi. Tässä työssä esitellään multimodaalinen putkisto, jossa otetaan huomioon sekä visuaaliset että tekstilliset piirteet meemeistä (1) tunnistetaan suojattu luokka (esim. rotu, sukupuoli jne.). ja (2) havaita hyökkäyksen tyyppi (esim. halveksunta, herjaukset jne.). Putkistomme käyttää huippuluokan esikoulutettuja visuaalisia ja tekstiesityksiä, joita seuraa yksinkertainen logistinen regressioluokittelija. Käytämme putkistoamme Hateful Memes Challenge -tietosarjassa, jossa on uusia hiljattain luotuja hienorakeisia tunnisteita suojatulle hyökkäykselle kategorialle ja tyypille. Paras mallimme saavuttaa AUROC-arvon 0,96 suojatun luokan tunnistamisessa ja 0,97 hyökkäyksen tyypin tunnistamisessa. Julkaisemme koodimme osoitteessa https://github.com/harisbinzia/HatefulMemes', 'ca': "Les memòries són les combinacions de text i imatges que sovint són humoroses a la natura. Però potser no sempre ho és, i certes combinacions de textos i imatges poden representar l'odi, anomenats memes odiosos. Aquesta obra presenta un tub multimodal que pren en compte les característiques visuals i textuals dels memes per identificar (1) la categoria protegida (per exemple raça, sex e, etc.) que ha estat atacada; i (2) detectar el tipus d'atac (com, per exemple, despreci, desolaments, etc.). El nostre gasoducte utilitza representacions visuals i textuals avançades, seguides d'un simple classificador de regressió logística. We employ our pipeline on the Hateful Memes Challenge dataset with additional newly created fine-grained labels for protected category and type of attack.  El nostre millor model aconsegueix una AUROC de 0,96 per identificar la categoria protegida, i 0,97 per detectar el tipus d'atac. We release our code at  https://github.com/harisbinzia/HatefulMemes", 'cs': 'Memy jsou kombinace textu a obrazů, které jsou často humorné povahy. To však nemusí být vždy případ a určité kombinace textů a obrazů mohou zobrazovat nenávist, označované jako nenávistné memy. Tato práce představuje multimodální potrubí, které bere v úvahu vizuální i textové rysy memů a identifikuje chráněnou kategorii (např. rasu, pohlaví apod.), která byla napadena; a (2) zjistit typ útoku (např. pohrdání, urážky atd.). Naše pipeline využívá nejmodernější předškolené vizuální a textové reprezentace, následuje jednoduchý logistický regresní klasifikátor. Používáme naše potrubí na datové sadě Hateful Memes Challenge s dalšími nově vytvořenými jemnými štítky pro chráněnou kategorii a typ útoku. Náš nejlepší model dosahuje AUROC 0,96 pro identifikaci chráněné kategorie a 0,97 pro detekci typu útoku. Vydáváme náš kód na adrese https://github.com/harisbinzia/HatefulMemes', 'he': 'Memes are the combinations of text and images that are often humorous in nature.  אבל, זה לא תמיד יכול להיות המקרה, ושילובות מסוימות של טקסטים ותמונות יכולים לתאר שנאה, שנקרא למימים שנאה. העבודה הזו מציגה צינור רב-מודלי ששוקל את תכונות ויזואליות וגם טקסטליות ממים, בהתחשב ב (1) לזהות את הקטגוריה המוגנת (למשל גזע, סקס jne.) שנתקפה; (2) לגלות את סוג התקפה (לדוגמא קנאה, שטויות וכו.). Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier.  אנו משתמשים בצינור שלנו על קבוצת נתונים של אתגר זיכרונות שנאה עם תוויות חדשות נוספות שנוצרו בקטגוריה מוגנת וסוג התקפה. המודל הטוב ביותר שלנו משיג AUROC של 0.96 לזהות את הקטגוריה המוגנת, ו 0.97 לגלות סוג התקפה. אנחנו משחררים את הקוד שלנו ב https://github.com/harisbinzia/HatefulMemes', 'sk': 'Memes so kombinacije besedila in slik, ki so pogosto humorne narave. Toda to morda ne bo vedno tako, nekatere kombinacije besedil in slik pa lahko prikazujejo sovraštvo, imenovano sovražni memi. V tem delu je predstavljen multimodalni plinovod, ki upošteva vizualne in besedilne značilnosti memov za (1) identifikacijo zaščitene kategorije (npr. rasa, spol itd.), ki je bila napadena; in (2) odkrivati vrsto napada (npr. preziranje, preziranje itd.). Naš cevovod uporablja najsodobnejše predhodno usposobljene vizualne in besedilne reprezentacije, ki mu sledi preprost logistični regresijski klasifikator. Naš plinovod uporabljamo na naboru podatkov Hateful Memes Challenge z dodatnimi na novo ustvarjenimi drobnozrnatimi oznakami za zaščiteno kategorijo in vrsto napada. Naš najboljši model dosega AUROC 0,96 za identifikacijo zaščitene kategorije in 0,97 za zaznavanje vrste napada. Kodo bomo objavili na: https://github.com/harisbinzia/HatefulMemes', 'ha': "Memes are the combinations of text and images that are often humorous in nature.  Amma, akwai tsammãnin ba za ta zama daidai ba, kuma wasu masu haɗuwa na littattafai da zanen za'a ƙayyade haske, kamar an ƙaddara shi da sunayen takayi. Wannan aikin yana bãyar da wata multi-rubutun da yake riƙon wasu fassarai masu gani da rubutu daga maimmani zuwa (1) ya gane category da aka tsare (misali, rase, sex etc.) wanda aka yi attacka; Mãsu husũma, a kan maƙaryata. @ info: whatsthis Tuna amfani da pipelin a kan data na Hatiful Mines Challenge da ana samu da wasu alama na'urar da aka samu a yanzu-danne mai tsari ga category da nau'in attacki. Babu misalinmu ya sami AUROC na 0.96 dõmin a gane nau'in da aka tsare, da 0.97 don ya gane nau'in attacki. Munã sakar da kodinmu a kan https://github.com/harisbinzia/HatefulMemes", 'bo': 'རྣམ་གྲངས་དེ་ནི་རང་བཞིན་ཡུལ་གྱི་ཡིག་དང་བརྙན་རིས་ཀྱི་མཉམ་དུ་བསྡད་ཡོད། འོན་ཀྱང་། དེ་ལ་རྟག་པར་དུ་ཡིག་ཡིག་དང་བརྙན་རིས་ཀྱི་མཉམ་དུ་ཡོད་པའི་ཚིག་ཡིག་གི་མཉམ་དུ་སྟོན་ཚུགས། This work presents a multimodal pipeline that takes visual and textual features from memes to account (1) to (1) identify the protected category (e.g. race, sex etc.) that have been attacked;  (2) དབྱིབས་འཆར་བའི་རིགས་རྟོགས་ཞིང་་་ (དཔེར་ན། སྣང་མེད་བཞག་པ་དང་། སྡོམ་དག་འདྲ་བྱས་མིན་འདུག། Our pipeline uses state-of-the-art pre-trained visual and textual representations, followed by a simple logistic regression classifier. We employ our pipeline on the Hateful Memes Challenge dataset with additional newly created fine-grained labels for protected category and type of attack. ང་ཚོའི་མ་དབྱིབས་རྩོམ་པ་ཆེ་ཤོས་ཀྱིས་0.96 སྤྱི་ཚོགས་ཀྱི་དབྱིབས་བདེ་སྟངས་འཛུགས་ཀྱི་རྒྱལ་ཁབ་ཞིག་དང་། 0.97 སྒྲིག་ཉེན་བརྗོ ང་ཚོས་རང་ཉིད་ཀྱི་ཨང་རིགས་འདོར་བ https://github.com/harisbinzia/HatefulMemes', 'jv': 'Mbum iki combining teks lan gambar sing ngatan pakan budhakan sampeyan. Nanging, iso wae lagi mesthi kaya Kasunyatan, lan kelangan kelangan kelangan kelangan kelangan lan gambar iso nggawe Kasunyatan, mengko iso nggo ndelok Awak iki nambah uga bantêl liya sing ngewehi operasi invisible lan textual dumateng memi nganggo (1) dumateng kategori sing wis awon (ex: rase, secas, njl cet.) 1 Awak dhéwé condolene gampang state-of-the-arts Awak dhéwé nglanggar aturan-sistem sing dibenakake nggawe barang kelas nang otom Beneng berarti dadi sing nyimpen dibenakake nggo ngerayakno kategori lan soko dolanan atak dhéwé model sing paling dhéwé iso nggawe AKER 0.Ning kanggo ngilangno kategori perusahaan karo 0. Awakdhéwé menggo kode nang kana https://github.com/harisbinzia/HatefulMemes'}
