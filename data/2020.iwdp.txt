{'en': 'Context-Aware Word Segmentation for Chinese Real-World Discourse C hinese Real-World Discourse', 'ar': 'تجزئة الكلمات الواعية بالسياق للخطاب الصيني في العالم الحقيقي', 'pt': 'Segmentação de palavras sensível ao contexto para discurso chinês do mundo real', 'fr': 'Segmentation de mots contextuelle pour le discours chinois dans le monde réel', 'es': 'Segmentación de palabras sensible al contexto para el discurso chino del mundo real', 'ja': '中国の現実世界の話題のための文脈意識のある単語セグメンテーション', 'zh': '中文世界语语境感知分词', 'hi': 'चीनी वास्तविक दुनिया के प्रवचन के लिए संदर्भ-जागरूक शब्द विभाजन', 'ru': 'Контекстно-ориентированная сегментация слов для китайского дискурса в реальном мире', 'ga': 'Deighilt Focal Feasach ar Chomhthéacs le haghaidh Dioscúrsa Fíordhomhanda na Síne', 'ka': 'Comment', 'el': 'Κατανομή λέξεων με επίγνωση του περιβάλλοντος για την κινεζική συζήτηση στον πραγματικό κόσμο', 'hu': 'Környezettudatos szószegmentáció a kínai valós világbeli beszélgetéshez', 'it': 'Segmentazione delle parole consapevole del contesto per il discorso del mondo reale cinese', 'kk': 'Қытай реалдық әлемдік дискурстарының контексті- түсінікті сөз сегментациясы', 'lt': 'Kinijos tikrojo pasaulio diskurso žodžių segmentacija, žinoma apie kontekstą', 'mk': 'Сегментација на зборови на контекстна свест за кинескиот реален свет', 'ms': 'Segmentasi Kata Sedia-Konteks untuk Persoalan Dunia-Real Cina', 'ml': 'Name', 'mn': 'Контекст-Aware Word Segmentation for Chinese Real-World Discourse', 'mt': 'Segmentazzjoni tal-kliem konxju mill-kuntest għad-Diskussjoni Ċiniża fid-Dinja Reali', 'no': 'Comment', 'pl': 'Kontekstowa segmentacja słów dla chińskiego dyskursu w rzeczywistym świecie', 'ro': 'Segmentarea conștientă de context a cuvintelor pentru discursul din lumea reală chineză', 'sr': 'Segmentacija reèi o poznavanju konteksta za kineske realne svetske diskurse', 'si': 'Name', 'so': 'Segmentation of Word Segment for Chinese Real-World', 'ta': 'Name', 'sv': 'Kontextmedveten ordsegmentering för kinesiska verkliga diskussioner', 'ur': 'Name', 'uz': 'Name', 'vi': 'Chia thế giới thật Trung Quốc', 'bg': 'Сегментация на думи за китайския дискурс в реалния свят', 'hr': 'Segmentacija riječi o poznavanju konteksta za kineske realne svjetske diskuse', 'nl': 'Contextbewuste woordsegmentatie voor Chinese discussie in de echte wereld', 'da': 'Kontekstbevidst ordsegmentering til kinesisk diskurs i den virkelige verden', 'de': 'Kontextbasierte Wortsegmentierung für den chinesischen Real-World-Diskurs', 'id': 'Segmentasi Word Aware-Konteks untuk Persoalan Dunia-Real Cina', 'ko': '언어 환경에 기초한 중국어 진실 문장 분사', 'fa': 'بخش کلمات آگاهی کنترل برای گفتگوهای واقعی دنیای چینی', 'sw': 'Sehemu ya neno la Kimataifa linalofahamika', 'tr': 'Çinçe Gerçek Dünýä Gezginleri üçin Maýyp Senediýasy', 'af': 'Comment', 'sq': 'Segmentacioni i fjalëve të ndërgjegjshme në kontekst për diskutimin kinez në botën reale', 'am': 'የፊደል ቅርጽ ምርጫዎች', 'hy': 'Չինաստանի իրական համաշխարհային հաղորդակցման համար', 'az': 'Çin Real-World Discourse üçün Context-Aware Word Segmentation', 'bn': 'Name', 'bs': 'Segmentacija riječi o poznavanju konteksta za kineske realne svetske diskuse', 'cs': 'Kontextově orientovaná segmentace slov pro čínský reálný diskurs', 'et': 'Kontekstiteadlik sõna segmenteerimine Hiina reaalmaailma diskursuse jaoks', 'ca': 'Segmentació de paraules conscients del context per al discurs xinès del món real', 'fi': 'Kontekstitietoinen sanasegmentointi Kiinan reaalimaailman diskurssille', 'jv': 'context-Awave Word segmentation for Chinese Actual-world', 'sk': 'Segmentacija besed z ozadjem za kitajski diskurz v realnem svetu', 'ha': 'KCharselect unicode block name', 'bo': 'རྒྱ་ནག་མི་དངོས་གནས་འཛམ་གླིང་ཐོག་བཤད་ལ་ཁ་ཤས་ཀྱི་ཚིག་རྗེས་སྦྲེལ་བ', 'he': 'סגמנטציה מילים מודעת לקונקסט עבור דיבור סיני בעולם האמיתי'}
{'en': 'Previous neural approaches achieve significant progress for Chinese word segmentation (CWS) as a sentence-level task, but it suffers from limitations on real-world scenario. In this paper, we address this issue with a context-aware method and optimize the  solution  at document-level. This paper proposes a three-step strategy to improve the performance for discourse CWS. First, the method utilizes an auxiliary segmenter to remedy the limitation on pre-segmenter. Then the context-aware algorithm computes the  confidence  of each split. The maximum probability path is reconstructed via this  algorithm . Besides, in order to evaluate the performance in  discourse , we build a new  benchmark  consisting of the latest news and Chinese medical articles. Extensive experiments on this  benchmark  show that our proposed method achieves a competitive performance on a document-level real-world scenario for CWS.', 'ar': 'تحقق الأساليب العصبية السابقة تقدمًا كبيرًا في تجزئة الكلمات الصينية (CWS) كمهمة على مستوى الجملة ، لكنها تعاني من قيود على سيناريو العالم الحقيقي. في هذه الورقة ، نتعامل مع هذه المشكلة بطريقة تراعي السياق وتحسين الحل على مستوى المستند. تقترح هذه الورقة استراتيجية من ثلاث خطوات لتحسين أداء خطاب CWS. أولاً ، تستخدم الطريقة قاطعًا إضافيًا لمعالجة القيد المفروض على جهاز التقسيم المسبق. ثم تقوم الخوارزمية المدركة للسياق بحساب ثقة كل تقسيم. يتم إعادة بناء مسار الاحتمال الأقصى عبر هذه الخوارزمية. إلى جانب ذلك ، من أجل تقييم الأداء في الخطاب ، نقوم ببناء معيار جديد يتكون من آخر الأخبار والمقالات الطبية الصينية. تُظهر التجارب المكثفة على هذا المعيار أن طريقتنا المقترحة تحقق أداءً تنافسيًا على سيناريو العالم الحقيقي على مستوى المستند لـ CWS.', 'es': 'Los enfoques neuronales anteriores lograron avances significativos para la segmentación de palabras chinas (CWS) como tarea a nivel de oración, pero adolece de limitaciones en el escenario del mundo real. En este artículo, abordamos este problema con un método sensible al contexto y optimizamos la solución a nivel de documento. Este artículo propone una estrategia de tres pasos para mejorar el desempeño del CWS discursivo. En primer lugar, el método utiliza un segmentador auxiliar para remediar la limitación del pre-segmentador. A continuación, el algoritmo sensible al contexto calcula la confianza de cada división. La ruta de probabilidad máxima se reconstruye a través de este algoritmo. Además, para evaluar el desempeño en el discurso, construimos un nuevo punto de referencia que consiste en las últimas noticias y artículos médicos chinos. Experimentos exhaustivos sobre este punto de referencia muestran que el método propuesto logra un rendimiento competitivo en un escenario real a nivel de documento para CWS.', 'fr': "Les approches neuronales précédentes ont permis de réaliser des progrès significatifs pour la segmentation des mots chinois (CWS) en tant que tâche au niveau de la phrase, mais elle souffre de limites par rapport aux scénarios réels. Dans cet article, nous abordons ce problème avec une méthode sensible au contexte et optimisons la solution au niveau du document. Cet article propose une stratégie en trois étapes pour améliorer les performances des CWS discursive. Tout d'abord, le procédé utilise un segmenteur auxiliaire pour remédier à la limitation du pré-segmenteur. L'algorithme sensible au contexte calcule ensuite la confiance de chaque division. Le chemin de probabilité maximale est reconstruit via cet algorithme. En outre, afin d'évaluer la performance dans le discours, nous construisons une nouvelle référence composée des dernières actualités et des articles médicaux chinois. Des expériences approfondies sur ce point de référence montrent que la méthode que nous proposons permet d'obtenir une performance compétitive sur un scénario réel au niveau du document pour CWS.", 'pt': 'As abordagens neurais anteriores alcançam um progresso significativo para a segmentação de palavras chinesas (CWS) como uma tarefa em nível de sentença, mas sofre de limitações no cenário do mundo real. Neste artigo, abordamos esse problema com um método sensível ao contexto e otimizamos a solução no nível do documento. Este artigo propõe uma estratégia de três etapas para melhorar o desempenho do discurso CWS. Primeiro, o método utiliza um segmentador auxiliar para remediar a limitação do pré-segmentador. Em seguida, o algoritmo sensível ao contexto calcula a confiança de cada divisão. O caminho de probabilidade máxima é reconstruído através deste algoritmo. Além disso, para avaliar o desempenho no discurso, construímos um novo benchmark composto pelas últimas notícias e artigos médicos chineses. Extensos experimentos neste benchmark mostram que nosso método proposto alcança um desempenho competitivo em um cenário do mundo real em nível de documento para CWS.', 'ja': '以前のニューラルアプローチは、文章レベルのタスクとして中国語の単語セグメンテーション（ CWS ）に大きな進歩をもたらしましたが、現実のシナリオに制限があります。本稿では，文脈認識法を用いてこの問題に対処し，文書レベルでの解決を最適化する．本稿では、CWSの言説のパフォーマンスを向上させるための3段階戦略を提案する。第１に、この方法は、補助セグメンタを利用して、セグメンタ前の制限を是正する。次に、コンテキスト認識アルゴリズムは、各分割の信頼性を計算する。最大確率経路は、このアルゴリズムを介して再構築されます。また、対話のパフォーマンスを評価するために、最新のニュースや中国の医学記事からなる新しいベンチマークを構築しています。このベンチマークに関する広範な実験は、提案された方法がCWSのドキュメントレベルの現実世界のシナリオで競争力のあるパフォーマンスを達成することを示しています。', 'zh': '前神经之法,于中文分词(CWS)为句级任务取重大进展,而限于世。 于本文之中,用上下文感知之法,并于文档级优化解决方案。 本文建三步之略,以崇议委员会之绩效。 先之,佐分段器以补预分段器之限。 然后上下文知算法每拆分之置信度。 以此算法重构最大概率路径。 此外评语之表,立最新新闻、医学文章之新准。 广实验之明,CWS文之真,成竞争力之性。', 'hi': 'पिछले तंत्रिका दृष्टिकोण एक वाक्य-स्तर के कार्य के रूप में चीनी शब्द विभाजन (सीडब्ल्यूएस) के लिए महत्वपूर्ण प्रगति प्राप्त करते हैं, लेकिन यह वास्तविक दुनिया के परिदृश्य पर सीमाओं से ग्रस्त है। इस पेपर में, हम इस समस्या को संदर्भ-जागरूक विधि के साथ संबोधित करते हैं और दस्तावेज़-स्तर पर समाधान को अनुकूलित करते हैं। यह पेपर प्रवचन सीडब्ल्यूएस के लिए प्रदर्शन में सुधार करने के लिए तीन-चरणीय रणनीति का प्रस्ताव करता है। सबसे पहले, विधि पूर्व-सेगमेंटर पर सीमा को दूर करने के लिए एक सहायक सेगमेंटर का उपयोग करती है। फिर संदर्भ-जागरूक एल्गोरिथ्म प्रत्येक विभाजन के आत्मविश्वास की गणना करता है। अधिकतम प्रायिकता पथ इस एल्गोरिथ्म के माध्यम से पुनर्निर्मित किया जाता है। इसके अलावा, प्रवचन में प्रदर्शन का मूल्यांकन करने के लिए, हम नवीनतम समाचार और चीनी चिकित्सा लेखों से मिलकर एक नया बेंचमार्क बनाते हैं। इस बेंचमार्क पर व्यापक प्रयोगों से पता चलता है कि हमारी प्रस्तावित विधि CWS के लिए दस्तावेज़-स्तरीय वास्तविक दुनिया के परिदृश्य पर एक प्रतिस्पर्धी प्रदर्शन प्राप्त करती है।', 'ru': 'Предыдущие нейронные подходы достигают значительного прогресса для сегментации китайского слова (CWS) как задачи на уровне предложения, но она страдает от ограничений в реальном мире сценария. В этой статье мы рассматриваем этот вопрос с помощью контекстно-зависимого метода и оптимизируем решение на уровне документа. В настоящем документе предлагается трехступенчатая стратегия повышения эффективности дискурса CWS. Во-первых, способ использует вспомогательный сегментатор для устранения ограничения на предварительный сегментатор. Затем контекстно-зависимый алгоритм вычисляет уверенность каждого раскола. Путь максимальной вероятности реконструируется с помощью этого алгоритма. Кроме того, для того, чтобы оценить производительность в дискурсе, мы строим новый эталон, состоящий из последних новостей и китайских медицинских статей. Обширные эксперименты над этим эталоном показывают, что предлагаемый нами метод обеспечивает конкурентоспособную производительность по реальному сценарию на уровне документа для CWS.', 'ga': 'Baineann cur chuige néarúil roimhe seo dul chun cinn suntasach amach maidir le deighilt focal Sínise (CWS) mar thasc ar leibhéal na habairte, ach tá sé thíos le srianta ar chás an fhíorshaoil. Sa pháipéar seo, tugaimid aghaidh ar an tsaincheist seo le modh atá feasach ar an gcomhthéacs agus leasaítear an réiteach ar leibhéal na doiciméid. Molann an páipéar seo straitéis trí chéim chun an fheidhmíocht don dioscúrsa CWS a fheabhsú. Ar an gcéad dul síos, úsáideann an modh deighleoir cúnta chun an teorannú ar an réamhdheighleog a leigheas. Ansin ríomhann an t-algartam atá feasach ar an gcomhthéacs muinín gach scoilte. Déantar cosán na dóchúlachta uasta a athchruthú tríd an algartam seo. Thairis sin, chun an fheidhmíocht sa dioscúrsa a mheas, tógaimid tagarmharc nua comhdhéanta de na nuacht is déanaí agus earraí leighis na Síne. Léiríonn turgnaimh fhairsing ar an tagarmharc seo go mbaineann ár modh molta feidhmíocht iomaíoch amach ar chás fíor-domhan ar leibhéal doiciméad do CWS.', 'ka': 'წინა ნეიროლური მიღება ჩინეთის სიტყვის სექმენტირებას (CWS) მნიშვნელოვანი პროგრესი, როგორც სიტყვის სექმენტის რაოდენობა, მაგრამ ის მუშაობს რეალური მსოფლი ამ დოკუმენტში, ჩვენ ამ პრობლემას კონტექსტურის შესახებ გავაკეთებთ და დოკუმენტის დოკუმენტის განსხვავება. ეს დოკუმენტი სამჯერ სტრატიგია, რომელიც სამჯერ სტრატიგია CWS-ის განსაზღვრებისთვის. პირველად, მეთოდის გამოყენება დახმარებელი სექმენტერი, რომელიც წინ სექმენტერის განსაზღვრებას. შემდეგ კონტექსტური ალგორიტიმ იმუშაობს ყოველ გაყოფილი თავიდან. მაქსიმალური შესაძლებლობა გეზი ამ ალგორიტიმს გამოყენება. დამატებით, განსაზღვრებისთვის განსაზღვრებისთვის, ჩვენ შევქმნით ახალი ბანქმენტი, რომელიც შექმნის ახალი ახალი ახალი და ჩინეთის მედიცინური წესებიდან. გაფართლებული ექსპერიმენტები ამ ბენქმარკის შესახებ, რომ ჩვენი პროგრამის მიზეზეზი CWS-ის კონკენტებური ექსპერიმენტის შესახებ დოკუმენტის რეალური', 'hu': 'A korábbi neurális megközelítések jelentős előrelépést értek el a kínai szószegmentáció (CWS) szempontjából mondatszintű feladatként, de a valós forgatókönyv korlátaitól szenved. Ebben a tanulmányban környezettudatos módszerrel foglalkozunk ezzel a problémával, és dokumentumszinten optimalizáljuk a megoldást. Ez a tanulmány három lépéses stratégiát javasol a CWS diskurzus teljesítményének javítására. Először is, a módszer egy kiegészítő szegmentálót használ a pre-szegmentáló korlátozásának orvoslására. Ezután a kontextustudatos algoritmus kiszámítja az egyes osztások bizalmát. A maximális valószínűségi útvonalat ezzel az algoritmussal rekonstruáljuk. Emellett a teljesítmény értékelése érdekében új referenciaértéket építünk ki a legfrissebb hírekből és kínai orvosi cikkekből. A referenciaérték kiterjedt kísérletei azt mutatják, hogy javasolt módszerünk a CWS dokumentumszintű valós forgatókönyvében versenyképes teljesítményt ér el.', 'el': 'Οι προηγούμενες νευρωνικές προσεγγίσεις επιτυγχάνουν σημαντική πρόοδο για τον κατακερματισμό κινεζικών λέξεων ως εργασία σε επίπεδο προτάσεων, αλλά πάσχει από περιορισμούς στο σενάριο πραγματικού κόσμου. Σε αυτή την εργασία, αντιμετωπίζουμε αυτό το ζήτημα με μια μέθοδο ευαισθητοποίησης του περιβάλλοντος και βελτιστοποιούμε τη λύση σε επίπεδο εγγράφων. Η παρούσα εργασία προτείνει μια στρατηγική τριών βημάτων για τη βελτίωση της απόδοσης του λόγου. Πρώτον, η μέθοδος χρησιμοποιεί ένα βοηθητικό τμήμα για να διορθώσει τον περιορισμό στο προ-τμήμα. Στη συνέχεια, ο αλγόριθμος με επίγνωση του περιβάλλοντος υπολογίζει την εμπιστοσύνη κάθε διαχωρισμού. Η διαδρομή μέγιστης πιθανότητας αναπαρίσταται μέσω αυτού του αλγόριθμου. Εξάλλου, προκειμένου να αξιολογηθεί η απόδοση του λόγου, χτίζουμε ένα νέο σημείο αναφοράς που αποτελείται από τις τελευταίες ειδήσεις και τα κινεζικά ιατρικά άρθρα. Εκτεταμένα πειράματα σε αυτό το σημείο αναφοράς δείχνουν ότι η προτεινόμενη μέθοδος επιτυγχάνει ανταγωνιστική απόδοση σε πραγματικό σενάριο για CWS σε επίπεδο εγγράφων.', 'it': "I precedenti approcci neurali raggiungono progressi significativi per la segmentazione delle parole cinesi (CWS) come compito a livello di frase, ma soffre di limitazioni sullo scenario reale. In questo articolo affrontiamo questo problema con un metodo contestuale e ottimizziamo la soluzione a livello di documento. Questo articolo propone una strategia in tre fasi per migliorare le prestazioni del discorso CWS. In primo luogo, il metodo utilizza un segmentatore ausiliario per porre rimedio alla limitazione sul pre-segmenter. Quindi l'algoritmo contestuale calcola la fiducia di ogni divisione. Il percorso di probabilità massima viene ricostruito tramite questo algoritmo. Inoltre, al fine di valutare la performance nel discorso, costruiamo un nuovo benchmark composto dalle ultime notizie e articoli medici cinesi. Esperimenti approfonditi su questo benchmark dimostrano che il metodo proposto raggiunge prestazioni competitive su uno scenario reale a livello documentale per CWS.", 'lt': 'Ankstesniais nerviniais metodais Kinijos žodžių segmentacija (CWS) kaip užduotis, susijusi su sakinių lygiu, daroma didelė pažanga, tačiau ji kenčia nuo realiojo pasaulio scenarijaus apribojimų. Šiame dokumente sprendžiame šį klausimą laikantis kontekste suprantamo metodo ir optimizuojame sprendimą dokumentų lygmeniu. Šiame dokumente siūloma trijų žingsnių strategija, kuria siekiama pagerinti diskurso CWS rezultatus. Pirma, taikant šį metodą naudojamas pagalbinis segmentatorius ištaisyti išankstinio segmentatoriaus apribojimą. Tada kontekste žinomas algoritmas apskaičiuoja kiekvieno padalijimo pasitikėjimą. Didžiausia tikimybė atstatoma naudojant šį algoritmą. Be to, siekiant įvertinti rezultatus diskutuojant, sukuriame naują lyginamąjį tašką, sudarytą iš naujausių naujienų ir Kinijos medicinos straipsnių. Išsamūs šio lyginamojo rodiklio eksperimentai rodo, kad mūsų siūlomas metodas pasiekia konkurencinius rezultatus pagal dokumentų lygmens realiojo pasaulio scenarijų CWS srityje.', 'mk': 'Previous neural approaches achieve significant progress for Chinese word segmentation (CWS) as a sentence-level task, but it suffers from limitations on real-world scenario.  Во овој документ, го решаваме ова прашање со метод свесен за контекст и го оптимизираме решението на документно ниво. Овој документ предлага тричекорна стратегија за подобрување на резултатите на дискурсот ЦВС. Прво, методот користи помошник сегментер за да се поправи ограничувањето на пресегментерот. Тогаш алгоритмот свесен за контекст ја пресметува довербата на секоја поделба. Патот на максималната веројатност е реконструиран преку овој алгоритм. Освен тоа, со цел да ја процениме изведбата во дискурс, ние изградуваме нова референциска точка која се состои од последните вести и кинеските медицински статии. Експериментите на оваа споредба покажуваат дека нашиот предложен метод постигнува конкурентна перформанса на сценарио на документно ниво на реалниот свет за ЦВС.', 'kk': 'Алдыңғы невралдық жағдайлары Қытай сөз сегментациясы (CWS) үшін маңызды жұмыс істейді, бірақ ол шын әлемдік сценариясының шектеулерінен болады. Бұл қағазда, бұл мәселеді контексті түсіндіру әдісімен шешіп, құжат деңгейіндегі шешімді оптимизациялау. Бұл қағаз CWS дискурстарының әрекетін жасау үшін үш қадам стратегиясын ұсынады. Біріншіден, әдісі бұрынғы сегментердің шектерін шектеу үшін көмекші сегменттерді қолданады. Содан кейін контексті білмейтін алгоритм әрбір бөліктің сенімін есептеп береді. Осы алгоритм арқылы максималдық ықтималдық жолы қайта құрылады. Осымен қатар, дискурстардың әрекеттерін бағалау үшін, жаңа бағдарлама құрамыз, соңғы жаңалық және қытайша медицина мақалаларынан тұратын жаңа бағдарлама құрамыз. Құжат деңгейіндегі шын әлемдік сценарий үшін құжат деңгейіндегі әлемдік сценариясындағы жұмыс істейтінін көрсетеді.', 'mt': 'Approċċi newrali preċedenti jiksbu progress sinifikanti għas-segmentazzjoni tal-kliem Ċiniż (CWS) bħala kompitu fil-livell tas-sentenza, iżda jbatu minn limitazzjonijiet fuq ix-xenarju tad-dinja reali. F’dan id-dokument, nindirizzaw din il-kwistjoni b’metodu konxju mill-kuntest u noptimizzaw is-soluzzjoni fil-livell tad-dokument. Dan id-dokument jipproponi strateġija ta’ tliet stadji biex tittejjeb il-prestazzjoni tas-CWS ta’ diskors. L-ewwel nett, il-metodu juża segmentatur awżiljarju biex jirrimedja l-limitazzjoni fuq il-pre-segmentatur. Imbagħad l-algoritmu konxju mill-kuntest jikkalkula l-kunfidenza ta’ kull qsim. Il-passaġġ massimu tal-probabbiltà jiġi rikostrutt permezz ta’ dan l-algoritmu. Barra minn hekk, sabiex tiġi evalwata l-prestazzjoni fid-diskors, a ħna nibnu punt ta’ riferiment ġdid li jikkonsisti fl-aħħar aħbarijiet u artikoli mediċi Ċiniżi. Esperimenti estensivi dwar dan il-punt ta’ riferiment juru li l-metodu propost tagħna jikseb prestazzjoni kompetittiva fuq xenarju dinji reali fil-livell tad-dokumenti għas-CWS.', 'ml': 'Previous neural approaches achieve significant progress for Chinese word segmentation (CWS) as a sentence-level task, but it suffers from limitations on real-world scenario.  ഈ പത്രത്തില്\u200d, നമ്മള്\u200d ഈ പ്രശ്നത്തെ ഒരു കെന്\u200dസ്റ്റെക്സ്റ്റെക്സ്റ്റെന്റ് അറിയുന്ന രീതിയില്\u200d വിശദീകരിക ഈ പത്രത്തില്\u200d സിഡ്യൂഎസ് സംസാരിക്കുന്നതിനുള്ള പ്രഭാവം മുന്നേറ്റാന്\u200d മൂന്നു പടിയായ ഒരു പദ്ധതിയ ആദ്യം, പ്രോഗ്മെന്ററിന്റെ അതിര്\u200dമ്മിക്കാന്\u200d ഒരു കൂടുതല്\u200d സെഗ്മെന്റര്\u200d ഉപയോഗിക്കുന്നു. പിന്നെ ഓരോ വിഭാഗത്തിന്റെയും വിശ്വാസത്തെ കണക്ട് ചെയ്യുന്നു. ഈ ആല്\u200dഗോരിതം മുഖേന ഏറ്റവും കൂടുതല്\u200d സാധ്യതയുള്ള വഴി പുനര്\u200dമ്മികമാക്കിയിരിക്കുന്നു. പിന്നെ സംസാരിക്കുന്ന പ്രകടനത്തെ വിശദീകരിക്കാന്\u200d വേണ്ടി, നമ്മള്\u200d പുതിയ വാര്\u200dത്തകളും ചൈനീസ് മെഡിക്കല്\u200d ലേഖനങ്ങളും ഉണ്ടാക് ഈ ബെങ്ക്മാര്\u200dക്കില്\u200d വിശാലമായ പരീക്ഷണങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട രീതിയില്\u200d സിവിഎസിന് ഒരു രേഖന', 'pl': 'Poprzednie podejścia neuronowe osiągają znaczący postęp w segmentacji słów chińskich (CWS) jako zadania na poziomie zdań, ale cierpią one z powodu ograniczeń w scenariuszu rzeczywistym. W niniejszym artykule podejmujemy ten problem metodą kontekstową i optymalizujemy rozwiązanie na poziomie dokumentów. Niniejszy artykuł proponuje trzystopniową strategię poprawy wyników dyskursu CWS. Po pierwsze, metoda wykorzystuje pomocniczy segmenter w celu zaradzenia ograniczeniu na pre-segmenter. Następnie algorytm kontekstowy oblicza zaufanie każdego podziału. Ścieżka maksymalnego prawdopodobieństwa jest rekonstruowana za pomocą tego algorytmu. Poza tym, aby ocenić wyniki w dyskursie, budujemy nowy benchmark składający się z najnowszych wiadomości i chińskich artykułów medycznych. Szeroko zakrojone eksperymenty nad tym wskaźnikiem pokazują, że proponowana metoda osiąga konkurencyjną wydajność na poziomie dokumentów scenariusza rzeczywistego dla CWS.', 'ro': 'Abordările neurale anterioare realizează progrese semnificative pentru segmentarea cuvintelor chinezești (CWS) ca o sarcină la nivel de propoziție, dar suferă de limitări ale scenariului din lumea reală. În această lucrare, abordăm această problemă cu o metodă conștientă de context și optimizăm soluția la nivel de document. Această lucrare propune o strategie în trei etape pentru a îmbunătăți performanța discursului CWS. În primul rând, metoda utilizează un segmenter auxiliar pentru a remedia limitarea pre-segmenter. Apoi algoritmul conștient de context calculează încrederea fiecărei diviziuni. Calea probabilității maxime este reconstruită prin intermediul acestui algoritm. În plus, pentru a evalua performanța în discurs, construim un nou benchmark format din ultimele știri și articole medicale chinezești. Experimentele extinse privind acest benchmark arată că metoda noastră propusă obține o performanță competitivă într-un scenariu real la nivel de document pentru CWS.', 'ms': 'Previous neural approaches achieve significant progress for Chinese word segmentation (CWS) as a sentence-level task, but it suffers from limitations on real-world scenario.  Dalam kertas ini, kita mengatasi isu ini dengan kaedah yang sedar-konteks dan optimize penyelesaian pada aras dokumen. Kertas ini mencadangkan strategi tiga langkah untuk meningkatkan prestasi untuk CWS diskors. Pertama, kaedah menggunakan segmenter bantuan untuk memperbaiki keterangan pada pre-segmenter. Kemudian algoritma yang sedar-konteks menghitung kepercayaan setiap bahagian. Laluan kemungkinan maksimum dibina semula melalui algoritma ini. Selain itu, untuk menilai prestasi dalam pembicaraan, kami membina benchmark baru yang terdiri dari berita terbaru dan artikel perubatan Cina. Extensive experiments on this benchmark show that our proposed method achieves a competitive performance on a document-level real-world scenario for CWS.', 'sr': 'Prethodni neurološki pristupi postižu značajan napredak za kinesku segmentaciju riječi (CWS) kao zadatak na nivou rečenica, ali pati od ograničenja scenarija stvarnog svijeta. U ovom papiru rješavamo ovaj problem sa metodom svjesnog konteksta i optimiziramo rešenje na nivou dokumenta. Ovaj papir predlaže tri koraka strategiju za poboljšanje učinka za diskurse CWS. Prvo, metoda koristi pomoćni segmenter kako bi se popravila ograničenje predsegmentera. Onda algoritam svestan konteksta računa povjerenje svakog podjela. Maksimalni put verovatnosti je rekonstruisan putem ovog algoritma. Osim toga, kako bismo procenili provedbu diskusija, izgradili smo novu kritiku koja se sastoji od najnovijih vesti i kineskih medicinskih članaka. Eksperimenti na ovom kriteriju pokazuju da naš predloženi metod postigne konkurentnu funkciju na scenariju realnog svijeta na nivou dokumenta za CWS.', 'si': 'මුලින් න්\u200dයූරාල් අවස්ථාවයෙන් චීනි වච්ච වාර්ථාවය (CWS) වාර්ථාවක් වෙනුවෙන් විශාල වැඩක් වෙනුවෙන් වැඩක් ල මේ පත්තරේ අපි මේ ප්\u200dරශ්නය සම්බන්ධ විධානයක් තියෙන්නේ සම්බන්ධ විධානයක් සඳහා ප්\u200dරශ්නය සඳහා  මේ පත්තර තුනක් පත්තරයක් ප්\u200dරයෝජනය කරනවා CWS කතා කරන්න ප්\u200dරයෝජනය වැඩි කරන්න. මුලින්ම, විධානය ප්\u200dරධානයක් ප්\u200dරධානයක් ප්\u200dරයෝජනය කරන්න ප්\u200dරධානයක් ප්\u200dරයෝජනය කරයි. ඊට පස්සේ සංවේදනය අල්ගෝරිතම් හැම විශ්වාස කරනවා. මේ ඇල්ගෝරිතම් වලින් විශ්වාසය ප්\u200dරමාණය ආපහු ස්ථාපනය කරලා තියෙනවා. ඒ වගේම, කතාවක් වලින් ක්\u200dරියාත්මක විශ්වාස කරන්න, අපි අළුත් වාර්තාවක් සහ චීනි වෛද්\u200dය විද්\u200dයාත්මක වලින් අලු මේ බෙන්ච්මාර්ක් එක්ක ප්\u200dරශ්නයක් පෙන්වන්නේ අපේ ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් CWS වෙනුවෙන් ලොකු ලෝක සිනාරියෝ ව', 'mn': 'Өмнөх мэдрэлийн ойлголт Хятад үг хэмжээний хэмжээний ажил болгон чухал хөгжлийн хөгжлийг олгодог. Гэхдээ энэ нь бодит ертөнцийн хувилбарт хязгаарлагддаг. Энэ цаасан дээр бид энэ асуудлыг харьцангуй ойлголтын аргын тухай ярилцаж, баримт-түвшинд шийдвэрийг сайжруулж байна. Энэ цаас CWS-ийн ярианы үйл ажиллагааг сайжруулахын тулд гурван давхар стратегийг санал болгодог. Эхлээд, арга нь өмнөх сегментерийн хязгаарыг сайжруулахын тулд тусламжтай сегментерийг ашигладаг. Дараа нь ойлголтын алгоритм нь хуваагдах бүрт итгэл итгэлтэй байдлыг тооцоолж байна. Магадгүй магадлал зам нь энэ алгоритмын аргаар дахин бүтээсэн. Үүнээс хамгийн сүүлийн мэдээ болон Хятад эмнэлгийн баримтуудын бүтээгдэхүүний ажиллагааг үнэлэхэд бид шинэ багц бүтээж байна. Энэ салбарт маш олон туршилтууд бидний санал өгсөн арга нь CWS-ийн баримт-түвшинд жинхэнэ дэлхийн хувилбар дээр өрсөлдөг үйл ажиллагааг гаргадаг.', 'no': 'Førre nøyralnærmingar gjer viktig framgang for kinesisk ordsegmentasjon (CWS) som eit setningsnivåk, men det går frå grenser på verkeleg scenario. I denne papiret adresserer vi dette problemet med ein kontekstsverkt metode og optimaliserer løysinga på dokumentnivå. Denne papiret foreslår ein tresteg strategi for å forbedra utviklinga for diskursar CWS. Først brukar metoden ein hjelpesegmenter for å retta grensesnittet på føresegmenteren. Så algoritmen for kontekst-oppmerkinga reknar ut tillit for kvar delt. Maksimal sannsynlighetsstaten er gjenoppretta via denne algoritmen. I tillegg, for å evaluere utviklinga i diskursar, bygger vi eit nytt benchmarkt som inneheld de siste nyhetane og kinesiske medisinske artiklar. Ekstra eksperimenter på denne benchmarken viser at vårt foreslått metode når det gjer eit konkurentivt utvikling på eit verkeleg scenario for CWS på dokumentnivå.', 'so': 'Dhaqdooyinka neurada ee hore waxay u baahan yihiin horumar muhiim ah oo ku saabsan qeybta afka Shiino (CWS), laakiin waxay ku dhibaataysaa xuduudaha arimaha dunida ee dhabta ah. Warqaddan waxaynu ku sheekaynaa qaab ku qoran qoraal aad u taqaan, waxaana ku habboonaynaa xafiiska sameynta heerka dukumentiga. Qoraalkan wuxuu soo jeedaa qoraal saddex qadood ah si uu u hagaajiyo muuqashada hadalka CWS. Marka ugu horeysa, qaababka ayaa isticmaalaya qeybta si uu u bogsado xadhigga ka hor qeybaha. Markaas waxaa xisaabiya kalsoonaanta kala duwan. The maximum probability path is reconstructed via this algorithm.  Sidoo kale, si aan ugu qiimeyno muuqashada hadalka, waxaynu dhisnaa qoraal cusub oo ka mid ah warqadaha ugu dambeeyey iyo warqadaha caafimaadka Shiinaha. Imtixaan dheeraad ah oo ku saabsan bangiga waxay muuqataa in qaabkeenkeennu uu soo jeeday ay ay sameyn karto tababar-tartank oo ku saabsan muuqashada qoraalka ee caalamka ah ee CWS.', 'sv': 'Tidigare neurala tillvägagångssätt uppnår betydande framsteg för kinesiska ordsegmentering (CWS) som en uppgift på meningsnivå, men det lider av begränsningar i verkliga scenarier. I den här uppsatsen behandlar vi problemet med en kontextmedveten metod och optimerar lösningen på dokumentnivå. Denna uppsats föreslår en trestegsstrategi för att förbättra prestandan för diskursen CWS. För det första använder metoden en hjälpsegmenter för att åtgärda begränsningen av pre-segmenter. Sedan beräknar den sammanhangsberoende algoritmen förtroendet för varje uppdelning. Den maximala sannolikhetsbanan rekonstrueras med hjälp av denna algoritm. För att utvärdera resultatet i diskursen bygger vi dessutom ett nytt riktmärke bestående av de senaste nyheterna och kinesiska medicinska artiklar. Omfattande experiment på detta riktmärke visar att vår föreslagna metod uppnår en konkurrenskraftig prestanda på ett dokumentbaserat realtidsscenario för CWS.', 'ta': 'முந்தைய புதிய அணுகுகள் சீன வார்த்தை பிரிவு (CWS) வாக்கு- மட்டத்திற்கான முன்னேற்றம் பெறுகிறது, ஆனால் உண்மையான உலக பார்வையில் உள்ள வர இந்த காகிதத்தில், நாம் இந்த பிரச்சனையை சூழல் அறிந்து கொள்ள முறையில் முகவரிக்கிறோம் மற்றும் ஆவண- நில இந்த காகிதம் CWS பேசுவதற்கான செயல்பாட்டை மூன்று படி திட்டத்தை மேம்படுத்துவதற்கு ஒரு முறை தேர்வு செய முதலில், முன் துண்டில் உள்ள வரம்பை நீக்க முடியும். பின்னர் சூழல் உணர்ந்து கொள்ளும் முறை ஒவ்வொரு பிரிவின் நம்பிக்கையை கணக்கிடும். The maximum probability path is reconstructed via this algorithm.  மேலும், பேச்சில் செயல்பாட்டை மதிப்பிட, நாம் சமீபத்தில் செய்தி மற்றும் சீன மருத்துவ கட்டுரைகள் உள்ளது ஒரு புதிய பெங்க்க இந்த பெங்க்மார்க் மீது விரிவான சோதனைகள் காட்டுகிறது எங்கள் பரிந்துரைக்கப்பட்ட முறைமையில் CWS ஒரு ஆவண- மட்டத்தில் உண்மையான', 'ur': 'پہلے نیورال کی تقریبا چین کی لفظ سیگنٹ (CWS) کے لئے بڑی پیشرفت حاصل ہوتی ہے، لیکن یہ واقعی دنیا کی سینارییو پر محدود ہوتی ہے۔ اس کاغذ میں ہم اس مسئلہ کو ایک کنٹکس آگاہ طریقہ سے بحث کرتے ہیں اور سند سطح میں حل کو اچھی طریقہ دیتے ہیں۔ یہ کاغذ سی واس کی صحبت کے لئے ایک تین قدم استراتژی پیشنهاد کرتا ہے۔ پہلے، یہ طریقہ ایک مددگار سجنگٹر کو پہلے سجنگٹر پر محدودہ کرنے کے لئے استعمال کرتا ہے. اس کے بعد متوجہ الگوریتم ہر ٹکڑے کی اطمینان کا شمار کرتا ہے۔ اس الگوریٹم کے ذریعہ سب سے زیادہ احتمال مسیر دوبارہ ساختہ ہوا ہے. اور اس کے علاوہ، صحبت میں فعالیت کا ارزش کرنے کے لئے، ہم نے اچھی خبریں اور چین داری مقالہ میں ایک نئی بنچم مارک بنایا ہے۔ اس بنچم مارک پر اضافہ آزمائش دکھاتے ہیں کہ ہماری پیشنهاد کی طریقہ CWS کے لئے ایک دکھانے-سطح حقیقی دنیاوی سناریو پر ایک مسابقه کی فعالیت حاصل کرتی ہے.', 'uz': "Oldingi neyrolik usullari Xitoycha soʻzni ajratish (CWS) sifatida juda muhim darajaga ega bo'ladi, lekin bu xavfsiz dunyodagi chegaralarning chegaralaridan ham qisqarli darajaga ega bo'ladi. Bu hujjatda, biz bu muammolarni context-aware usuli bilan boshqaramiz va hujjatning darajada qiymatni optimiz. Bu qogʻoz CWS bilan suhbat qilishni bajarish uchun uchta qadam strategiya rivojlanadi. Birinchi marta, birinchi segment chegarasini aniqlash uchun foydalanadi. Keyin ma'lumot algoritha har bir bir bir bir guruhga ishonini hisoblash mumkin. The maximum probability path is reconstructed via this algorithm.  Davom etishni tasavvur qilish uchun, biz yangi xabarlar va Xitoycha medisinal maqolalardan yangi obʼektlarni yaramiz. Ushbu benchmark uchun kengaytma taʼminlovchi imtiyozlar CWS uchun qoʻllangan usuli hujjat darajadagi real-dunyo scenarida rivojlanish muvaffaqiyatli bajaradi.", 'vi': 'Trước các phương pháp thần kinh đạt được tiến triển đáng kể cho việc phân biệt các từ Trung Quốc (CS) như một nhiệm vụ cấp bản án, nhưng nó bị hạn chế trong kịch bản thế giới thực. Trong tờ giấy này, chúng tôi xử lý vấn đề này bằng một phương pháp nhận biết ngữ cảnh và tối ưu giải ở mức tài liệu. Đề tài đề xuất một chiến lược ba bước nhằm cải thiện kết quả trong thuyết trình về RWS. Thứ nhất, phương pháp sử dụng một gián điệp hỗ trợ để sửa chữa giới hạn cho chế chế thai nghén. Sau đó thuật toán nhận diện ngữ cảnh tính toán sự tự tin của mỗi chia. Đường dẫn xác suất tối đa được tái tạo bằng thuật toán này. Với lại, để đánh giá khả năng trong thuyết trình, chúng tôi xây dựng một tiêu chuẩn mới, gồm các tin tức mới nhất và các bài báo y tế Trung Quốc. Những thí nghiệm dồi dào trên con số này cho thấy phương pháp của chúng tôi đạt được hiệu suất cạnh tranh trên một kịch bản thực tế trên nền tài liệu cho RWS.', 'nl': 'Eerdere neurale benaderingen bereiken aanzienlijke vooruitgang voor Chinese woordsegmentatie (CWS) als een taak op zinnenniveau, maar het lijdt aan beperkingen in het echte scenario. In dit artikel behandelen we dit probleem met een contextbewuste methode en optimaliseren we de oplossing op documentniveau. Dit document stelt een driestapsstrategie voor om de prestaties van discours CWS te verbeteren. Ten eerste maakt de methode gebruik van een hulpsegmenter om de beperking op pre-segmenter te verhelpen. Vervolgens berekent het contextbewuste algoritme het vertrouwen van elke split. Het maximale waarschijnlijkheidspad wordt gereconstrueerd via dit algoritme. Daarnaast bouwen we, om de performance in discours te evalueren, een nieuwe benchmark bestaande uit het laatste nieuws en Chinese medische artikelen. Uitgebreide experimenten met deze benchmark tonen aan dat onze voorgestelde methode een concurrerende prestatie levert op een documentniveau real-world scenario voor CWS.', 'da': 'Tidligere neurale tilgange opnår betydelige fremskridt for kinesisk ordsegmentering (CWS) som en sætningsniveau opgave, men det lider af begrænsninger i den virkelige verden scenarie. I denne artikel behandler vi dette problem med en kontekstbevidst metode og optimerer løsningen på dokumentniveau. Denne artikel foreslår en tre-trins strategi for at forbedre præstationen for diskursen CWS. For det første bruger metoden en hjælpesegmenter til at afhjælpe begrænsningen på pre-segmenter. Derefter beregner den kontekstbevidste algoritme tilliden for hver opdeling. Den maksimale sandsynlighedssti rekonstrueres via denne algoritme. For at evaluere resultaterne i diskursen bygger vi desuden et nyt benchmark bestående af de seneste nyheder og kinesiske medicinartikler. Omfattende eksperimenter med denne benchmark viser, at vores foreslåede metode opnår en konkurrencepræstation på et dokumentniveau virkelig scenario for CWS.', 'hr': 'Prethodni neuronski pristupi postignu značajan napredak za kinesku segmentaciju riječi (CWS) kao zadatak na razini rečenica, ali pati od ograničenja scenarija stvarnog svijeta. U ovom papiru rješavamo ovaj problem sa metodom svjesnog konteksta i optimiziramo rješenje na razini dokumenta. Ovaj papir predlaže tri koraka strategiju za poboljšanje učinka diskusija CWS-a. Prvo, metoda koristi pomoćni segmenter kako bi se popravila ograničenje predsegmentera. Onda algoritam svestan konteksta računa povjerenje svakog podjela. Maksimalni put vjerojatnosti je rekonstruiran putem ovog algoritma. Osim toga, kako bismo procijenili učinku u diskusiji, izgradili smo novu kritiku koja se sastoji od najnovijih vijesti i kineskih medicinskih članaka. Prošireni eksperimenti na toj kriteriji pokazuju da naš predloženi metod postigne konkurentni učinkoviti na scenariju stvarnog svijeta na razini dokumenta za CWS-a.', 'bg': 'Предишните невронни подходи постигат значителен напредък при сегментацията на китайските думи като задача на ниво изречение, но страдат от ограничения в реалния сценарий. В тази статия разглеждаме този проблем с контекст-съобразен метод и оптимизираме решението на ниво документ. Настоящата статия предлага тристепенна стратегия за подобряване на представянето на дискурсния език. Първо, методът използва помощен сегментатор за отстраняване на ограничението на предсегментатора. След това алгоритъмът, осъзнаващ контекста, изчислява увереността на всяко разделяне. Пътят на максималната вероятност се възстановява чрез този алгоритъм. Освен това, за да оценим представянето в дискурса, изграждаме нов референт, състоящ се от последните новини и китайски медицински статии. Обширни експерименти на този показател показват, че предложеният ни метод постига конкурентно представяне на сценарий в реалния свят на ниво документи.', 'de': 'Bisherige neuronale Ansätze erzielen signifikante Fortschritte bei der chinesischen Wortsegmentierung (CWS) als Aufgabe auf Satzebene, leiden jedoch unter Einschränkungen des realen Szenarios. In diesem Beitrag behandeln wir dieses Problem mit einer kontextbewussten Methode und optimieren die Lösung auf Dokumentenebene. Dieses Papier schlägt eine dreistufige Strategie vor, um die Performance für Diskurs CWS zu verbessern. Erstens verwendet das Verfahren einen Hilfssegmenter, um die Beschränkung auf Pre-Segmenter zu beheben. Dann berechnet der kontextbewusste Algorithmus die Vertrauenswürdigkeit jeder Teilung. Mit diesem Algorithmus wird der maximale Wahrscheinlichkeitspfad rekonstruiert. Außerdem bauen wir, um die Performance im Diskurs zu bewerten, einen neuen Benchmark, bestehend aus den neuesten Nachrichten und chinesischen medizinischen Artikeln. Umfangreiche Experimente an diesem Benchmark zeigen, dass unsere vorgeschlagene Methode eine wettbewerbsfähige Performance auf Dokumentenebene für CWS erreicht.', 'ko': '이전의 신경 네트워크 방법은 중국어분사(CWS)가 문장급 임무로서 중대한 진전을 거두었지만 실제 응용에 한계가 있다.본고에서 우리는 상하문 감지의 방법을 사용하여 이 문제를 해결하고 문서 단계에서 해결 방안을 최적화한다.본고는 3단계 전략을 제시하여 언어 CWS의 성능을 향상시켰다.우선 이 방법은 보조분절기를 이용하여 예분절기의 한계를 보완한다.그리고 상하문 감지 알고리즘은 각 분할의 신뢰도를 계산한다.이 알고리즘을 통해 최대 확률 경로를 재구성했다.또한 말의 표현을 평가하기 위해 최신 뉴스와 중국 의학 문장으로 구성된 새로운 기준을 세웠다.이 기준에 대한 대량의 실험은 우리가 제시한 방법이 문서급 CWS의 실제 장면에서 경쟁력 있는 성능을 얻었다는 것을 보여준다.', 'sw': 'Matokeo yaliyopita ya neura yanapata maendeleo makubwa kwa ajili ya kujitenga kwa neno la China (CWS) kama jukumu la kiwango cha hukumu, lakini inapata vizuizi katika eneo halisi la dunia. Katika karatasi hii, tunazungumzia suala hili kwa njia inayofahamu na kuboresha suluhisho kwa kiwango cha nyaraka. Makala hii inapendekeza mkakati wa hatua tatu wa kuboresha utendaji wa mazungumzo ya CWS. Kwanza, mbinu hiyo inatumia sekta ya ushirikiano ili kurekebisha vizuizi kwa mtangazaji wa awali. Kisha utaratibu wa muktadha unakadiria imani ya kila sehemu. The maximum probability path is reconstructed via this algorithm.  Zaidi ya hayo, ili kutathmini utendaji wa mazungumzo, tunajenga barua mpya yenye makala za habari za hivi karibuni na makala za kitabibu za China. Majaribio mengi kwenye bendera hii yanaonyesha kuwa mbinu zetu zilizopendekezwa inaweza kupata ufanisi wa ushindani katika mtazamo wa kiwango cha dokumentari halisi wa dunia kwa ajili ya CWS.', 'fa': 'نزدیک\u200cهای عصبی قبلی برای جدا کردن کلمه\u200cهای چینی (CWS) به عنوان یک کار سطح مجازات می\u200cرسد، ولی از محدودیت\u200cهای صحنه\u200cی دنیای واقعی رنج می\u200cبرد. در این کاغذ، ما این مسئله را با یک روش آگاهی به محیط بحث می\u200cکنیم و راه حل را در سطح سند بالاترین می\u200cکنیم. این کاغذ یک استراتژی سه مرحله پیشنهاد می\u200cکند تا عملکرد برای صحبت CWS را بهتر کند. اول، روش یک بخش\u200cکننده کمک را برای اصلاح محدودیت پیش\u200cبخش\u200cکننده استفاده می\u200cکند. سپس الگوریتم آگاهی آگاهی محاسبه اعتماد هر قسمتی را محاسبه می کند. مسیر احتمال بالاترین از طریق این الگوریتم دوباره ساخته شده است. علاوه بر این، برای ارزیابی عملکرد در صحبت، ما یک نقشه جدید بسازیم که از اخبار اخیر و مقاله پزشکی چینی است. آزمایش های گسترده روی این مقدار نشان می دهد که روش پیشنهاد ما به یک اجرای مسابقه در یک سناریو جهانی واقعی برای CWS رسیده است.', 'tr': 'Öňki näyral ýakynlaşyklar Çinçe sözleriň segmentasyny (CWS) sözleriň derejesi üçin wajyp ilerlemegini başarýar, ýöne bu dünýäde çykyşlar sahypasynda çykýar. Bu kagyzda, biz bu meseleyi kontekst bilen tanyş yöntemi bilen çözýäris we sened derejesinde çözümi bejerýäris. Bu kagyz CWS diskusiýalary üçin hereket etmek üçin üç-ýoluň strategiýasyny teklip edýär. Ilkinji gezek, segmentiň öňündeki çykgyny çykarmak üçin arkaýyn segmenti ullanýar. Sonra mantıklı algoritm her bölüminiň güvenini hesaplar. Maksimal mümkin yol bu algoritm bilen gaýd edildi. Gürüşmeleriň etkinleşigini deňlemek üçin täze bir kluka düzenledik. Şu ýagdaýda iň soňky täzelikler we Çin çe lukmançylyklaryň bar. Bu benchmark üzerinde örän geniş deneyler biziň teklip eden yöntemimiz CWS-yň düýbündeki düýbündeki düýbündeki düýbündeki düýbündeki uçuş gazanýandygyny görkez.', 'af': "Vorige neurale toegang bereik betekende vordering vir Sjinese woord segmentasie (CWS) as 'n setvlak taak, maar dit lyf van beperkinge op reël-wêreld scenario. In hierdie papier, ons adres hierdie probleem met 'n konteks-bevestig metode en optimaliseer die oplossing op dokumentvlak. Hierdie papier voorstel 'n drie stappe strategie om die prestasie vir diskursie CWS te verbeter. Eerste, die metode gebruik 'n helper segmenter om die beperking op voor- segmenter te herstel. Toe bereken die konteks-bekende algoritme die vertroue van elke dele. Die maksimum waarskynlik pad is herkonstrukteer deur hierdie algoritme. Ons bou 'n nuwe benchmark wat bestaan van die nuutste nuus en Sjinese mediese artikels. Ekstensiewe eksperimente op hierdie benchmark wys dat ons voorgestelde metode 'n mededingstekenis bereik op 'n dokumentvlak reël wêreld scenario vir CWS.", 'am': 'የቀድሞው የናቡር ግንኙነት የቻይና ቃላት አካባቢ (CWS) የፍርድ ደረጃ ሥራ እንዲደረግ ግንኙነት አግኝቷል፡፡ በዚህ ፕሮግራም፣ ይህንን ጉዳይ በሥርዓት ማወቅ ሥርዓት እናቆማለን እናስፈልጋለን፡፡ ይህም ፕሮግራም የCWS ውይይትን ለማሻሻል የሦስት ደረጃ strategy ያሳውሳል፡፡ First, the method utilizes an auxiliary segmenter to remedy the limitation on pre-segmenter.  አካባቢው ማወቅ መሆኑን የሁሉን እየተለያዩ ይቆጥራል፡፡ መተላለፊያ መንገድ በዚህ መግለጫ ላይ የተመሠረተ ነው፡፡ ከዚህም በላይ የአሁኑን ዜና እና የቻይና መድኃኒት ጽሑፎች የሚቆጠሩ አዲስ ገጽ እናደርጋለን፡፡ በዚህ benchmark ላይ የበዛ ፈተናዎች የሞከረ ሥርዓታችን ለCWS የሰነድ-ደረጃ እውነተኛ-ዓለም ስራታዊ ክፍል እንዲያገኝ ያሳያል፡፡', 'sq': 'Përqasjet e mëparshme nervore arrijnë përparim të rëndësishëm për segmentimin e fjalëve kineze (CWS) si një detyrë në nivelin e fjalëve, por vuan nga kufizimet në skenarin e botës reale. Në këtë letër, ne e trajtojmë këtë çështje me një metodë të ndërgjegjshme për kontekstin dhe optimizojmë zgjidhjen në nivel dokumenti. Ky dokument propozon një strategji tre hapash për të përmirësuar performancën për diskursin CWS. Së pari, metoda përdor një segmenter ndihmës për të përmirësuar kufizimin në parasegmenter. Pastaj algoritmi i vetëdijshëm për kontekstin llogarit besimin e çdo ndarje. The maximum probability path is reconstructed via this algorithm.  Përveç kësaj, me qëllim që të vlerësojmë shfaqjen në diskors, ne ndërtojmë një normë të re që përbëhet nga lajmet e fundit dhe artikujt mjekësorë kinezë. Eksperimentet e zgjeruara në këtë referencë tregojnë se metoda jonë e propozuar arrin një shfaqje konkurruese në një skenar të botës reale të nivelit të dokumentit për CWS.', 'hy': "Նախորդ նյարդային մոտեցումները նշանակալի առաջընթաց են հասնում չինական բառերի սեգմետրացիայի (CW S) համար, որպես նախադասության մակարդակի խնդիր, բայց այն տառապում է իրական աշխարհի սցենարի սահմանափակումներից: Այս թղթի մեջ մենք լուծում ենք այս խնդիրը կոնտեքստին գիտակցած մեթոդով և օպտիմացնում ենք լուծումը փաստաթղթի մակարդակում: Այս թղթին առաջարկում է երեք քայլ քայլ ռազմավարություն, որպեսզի բարելավվի խոսակցության CW-ի արդյունքը: Առաջին հերթին, մեթոդը օգտագործում է օգտակար սեգմետր' վերացնելու նախասեգմետրի սահմանափակումները: Հետո կոնտեքստի գիտակցած ալգորիթմը հաշվարկում է յուրաքանչյուր բաժանման վստահությունը: Մաքսիմալ հավանականության ճանապարհը վերակառուցվում է այս ալգորիթմի միջոցով: Ավելին, խոսակցության արդյունքը գնահատելու համար մենք կառուցում ենք նոր համեմատական նպատակ, որը կազմված է վերջին նորություններից և չինական բժշկական հոդվածներից: Այս հարաբերականի վերաբերյալ ընդլայնված փորձարկումները ցույց են տալիս, որ մեր առաջարկած մեթոդը հաջողվում է համընդհանուր արդյունք հասնել փաստաթղթի մակարդակի իրական աշխարհային սցենարիայի համար:", 'id': 'Pendekatan saraf sebelumnya mencapai kemajuan yang signifikan untuk segmentasi kata Cina (CWS) sebagai tugas tingkat kalimat, tetapi menderita dari batasan pada skenario dunia nyata. In this paper, we address this issue with a context-aware method and optimize the solution at document-level.  Kertas ini mengusulkan strategi tiga langkah untuk meningkatkan prestasi untuk diskors CWS. Pertama, metode menggunakan segmenter bantuan untuk memperbaiki batasan pada pre-segmenter. Then the context-aware algorithm computes the confidence of each split.  Laluan kemungkinan maksimum dibangun kembali melalui algoritma ini. Selain itu, untuk mengevaluasi prestasi dalam diskors, kami membangun benchmark baru yang terdiri dari berita terbaru dan artikel medis Cina. Extensive experiments on this benchmark show that our proposed method achieves a competitive performance on a document-level real-world scenario for CWS.', 'bn': 'পূর্ববর্তী নিউরেলের ক্ষেত্রে চীনা শব্দ বিভক্তির (সিডিউএস) বাক্য-স্তরের কাজ হিসেবে গুরুত্বপূর্ণ অগ্রগতি অর্জন করে, কিন্তু এটি বাস এই কাগজটিতে আমরা এই বিষয়টিকে একটি প্রেক্ষিত-সচেতনতার পদ্ধতি দিয়ে আলোচনা করি এবং নথি স্তরে সমাধান সম্ভব করি। এই পত্রিকা সিডিউএস-এর কথোপকথনের প্রভাব উন্নত করার জন্য তিন পদক্ষেপ প্রস্তাব করেছে। প্রথমত, এই পদ্ধতি ব্যবহার করে পূর্ববর্তী বিভিন্ন সীমাবদ্ধ করতে পারে। Then the context-aware algorithm computes the confidence of each split.  এই অ্যালগরিদমের মাধ্যমে সর্বোচ্চ সম্ভাবনার পথ পুনরায় নির্মাণ করা হয়েছে। এছাড়াও, কথোপকথনের প্রকৃতির মূল্যের জন্য আমরা একটি নতুন বেনম্যার্ক তৈরি করি যা সাম্প্রতিক সংবাদ এবং চীনা চীনা চিকিৎসা প্রবন এই বেনম্যার্কের বিস্তারিত পরীক্ষা দেখাচ্ছে যে আমাদের প্রস্তাবিত পদ্ধতি সিডিউএস-এর জন্য প্রতিযোগিতায় প্রতিযোগিতা করার একটি', 'az': 'Əvvəlki nöral yaxınlıqları Çin sözlərin segmentasiyası (CWS) üçün böyük bir tədbir olaraq gəlir, amma bu, həqiqət dünya scenariyasının sınırlarından çəkilir. Bu kağızda, bu məsələni kontekst-bilik metodları ilə çəkirik və dökümət seviyesində çözümü optimizləyirik. Bu kağıt CWS sözlərinin performansını düzəltmək üçün üç adım strateji təklif edir. İlk dəfə, bu metod öncə segmenter üçün hədlərini dəyişdirmək üçün yardımcı segmenter istifadə edər. Sonra context-aware algoritmi hər parçasının güvenini hesablar. Bu algoritm vasitəsilə maksimal mümkün yol yenidən inşa edilir. Təkcə, danışmaq üçün yeni xəbərlər və Çin tıbbi maddələrdən olub yeni bir benchmark in şa edirik. Bu benchmark üzərində çox geniş eksperimentlər CWS üçün təklif edilən metodumuzun müqayisədə olan CWS-in əsas dünya scenariosində müqayisədə müqayisədə göstərir.', 'ca': "Els enfocaments neuronals anteriors aconsegueixen progrés significatiu per la segmentació de paraules xineses (CWS) com a tasca de nivell de frases, però pateix limitacions en l'escenari del món real. En aquest paper, abordem aquesta qüestió amb un mètode conscient del contexte i optimizem la solució a nivell documental. Aquest paper propon una estratègia de tres passos per millorar el rendiment del discurs CWS. Primer, el mètode utilitza un segmentador auxiliar per corregir la limitació del pre-segmentador. Llavors l'algoritme conscient del context calcula la confiança de cada divisió. El camí de probabilitat màxima és reconstruit a través d'aquest algoritme. A més, per tal d'evaluar el rendiment en discurs, construïm un nou punt de referència que consisteix en les últimes notícies i articles mèdics xinesos. Els extensos experiments en aquest punt de referència demostren que el nostre mètode proposat aconsegueix un rendiment competitiu en un escenari real de CWS a nivell documental.", 'cs': 'Předchozí neuronové přístupy dosahují významného pokroku pro segmentaci čínských slov (CWS) jako úlohu na úrovni věty, ale trpí omezením reálného scénáře. V tomto článku se zabýváme tímto problémem kontextově orientovanou metodou a optimalizujeme řešení na úrovni dokumentů. Tento článek navrhuje třístupňovou strategii pro zlepšení výkonnosti diskurzu CWS. Za prvé, metoda využívá pomocný segmenter k nápravě omezení na pre-segmenter. Pak kontextový algoritmus vypočítá důvěru každého rozdělení. Pomocí tohoto algoritmu je rekonstruována cesta maximální pravděpodobnosti. Kromě toho, abychom zhodnotili výkonnost v diskurzu, budujeme nový benchmark sestávající z nejnovějších zpráv a čínských lékařských článků. Rozsáhlé experimenty na tomto benchmarku ukazují, že naše navrhovaná metoda dosahuje konkurenčního výkonu na úrovni dokumentů reálného scénáře CWS.', 'bs': 'Prethodni neuronski pristupi postignu značajan napredak za kinesku segmentaciju riječi (CWS) kao zadatak na nivou rečenica, ali pati od ograničenja scenarija stvarnog svijeta. U ovom papiru rješavamo ovaj problem sa metodom svjesnog konteksta i optimiziramo rješenje na nivou dokumenta. Ovaj papir predlaže tri koraka strategiju za poboljšanje učinka za diskusije CWS. Prvo, metoda koristi pomoćni segmenter kako bi se popravila ograničenje predsegmentera. Onda algoritam svjesnog konteksta računa povjerenje svakog podjela. Maksimalni put vjerojatnosti je rekonstruiran putem ovog algoritma. Osim toga, kako bismo procenili učinku u diskusiji, izgradili smo novu kritiku koja se sastoji od najnovijih vijesti i kineskih medicinskih članaka. Eksperimenti na ovom kriteriju pokazuju da naš predloženi metod postigne konkurentnu funkciju na scenariju realnog svijeta na nivou dokumenta za CWS.', 'et': 'Varasemad närvilähenemised saavutavad märkimisväärset edu hiina sõna segmenteerimisel (CWS) lausetasemel ülesandena, kuid see kannatab reaalse maailma stsenaariumi piirangute tõttu. Käesolevas artiklis käsitleme seda probleemi kontekstiteadliku meetodiga ja optimeerime lahendust dokumendi tasandil. Käesolevas dokumendis pakutakse välja kolmeastmeline strateegia, et parandada CWS diskursuse tulemuslikkust. Esiteks kasutatakse meetodis abisegmenteerijat, et parandada eelsegmenteerimise piirangut. Seejärel arvutab kontekstiteadlik algoritm iga jagamise usalduse. Maksimaalse tõenäosuse tee rekonstrueeritakse selle algoritmi abil. Lisaks ehitame diskursuse tulemuslikkuse hindamiseks uue võrdlusaluse, mis koosneb uusimatest uudistest ja Hiina meditsiinilistest artiklitest. Selle võrdlusaluse põhjalikud katsed näitavad, et meie kavandatud meetodil saavutatakse CWS-i konkurentsivõimeline tulemus dokumentide tasandil reaalmaailma stsenaariumis.', 'fi': 'Aiemmat neurolähestymistavat saavuttavat merkittävää edistystä kiinalaisessa sanasegmentoinnissa (CWS) lausetason tehtävässä, mutta se kärsii rajoituksista reaalimaailmassa. Tässä artikkelissa käsittelemme asiaa kontekstitietoisella menetelmällä ja optimoimme ratkaisun dokumenttitasolla. Tässä työssä ehdotetaan kolmivaiheista strategiaa, jolla parannetaan diskurssin suorituskykyä. Ensinnäkin menetelmässä käytetään apusegmentoria esisegmentointiin kohdistuvan rajoituksen korjaamiseksi. Sitten kontekstitietoinen algoritmi laskee jokaisen jaon luottamuksen. Maksimitodennäköisyyspolku rekonstruoidaan tämän algoritmin avulla. Lisäksi, jotta voimme arvioida diskurssin suorituskykyä, rakennamme uuden vertailukohdan, joka koostuu uusimmista uutisista ja kiinalaisista lääketieteellisistä artikkeleista. Laajat kokeet tästä vertailuarvosta osoittavat, että ehdotetulla menetelmällä saavutetaan kilpailukykyinen suorituskyky dokumenttitasolla reaaliaikaisessa skenaariossa CWS:lle.', 'jv': 'Laptop" and "Desktop deep Awak iki supoyo tresnane kanggo ngerasakno kanggo nggawe barang CWS. Learn Mode politenessoffpolite"), and when there is a change ("assertivepoliteness Laptop" and "Desktop Ing wis malah, nggo kuwi nggawe gerakan kanggo nggawe gerakan dhéwé, awak dhéwé nggawe nyimpen dhéwé kuwi nggawe barang dhéwé karo pertualangan kanggo ngerasakno sing luwih apik lan nganggo dolang dhéwé. Export', 'sk': 'Prejšnji nevronski pristopi dosegajo pomemben napredek pri segmentaciji kitajskih besed (CWS) kot naloga na ravni stavka, vendar trpijo zaradi omejitev realnega scenarija. V tem prispevku obravnavamo to vprašanje z metodo, ki se zaveda konteksta, in optimiziramo rešitev na ravni dokumenta. Ta prispevek predlaga trikoračno strategijo za izboljšanje uspešnosti diskurza CWS. Prvič, metoda uporablja pomožni segmenter za odpravo omejitve predsegmenterja. Nato algoritem, ki se zaveda konteksta, izračuna zaupanje vsakega delitve. Pot največje verjetnosti se rekonstruira s tem algoritmom. Poleg tega, da bi ocenili uspešnost v diskurzu, gradimo novo merilo, ki ga sestavljajo najnovejše novice in kitajski medicinski članki. Obsežni poskusi na tem merilu kažejo, da naša predlagana metoda dosega konkurenčno uspešnost v realnem scenariju na ravni dokumentov za CWS.', 'ha': "Tsarin neural da suka gabata ta sami motsi mai girma wa segment wa maganar China (CWS) kamar wani aikin maganar-daraja, kuma amma yana sami daga tsari kan halin-duniya. Ga wannan takardan, Munã tambayar wannan da ke da wata metode mai haƙƙin, kuma Munã kwaɗa ɗaɗe masu yin suluwa a kan takardar-daraja. Wannan karatun yana bukãtar da wani takwara uku dõmin ya kyautata mazaɓa wa mazaɓa na CWS. Kayyan, shirin ya yi amfani da wani segment mai inganci don ya canza tsarin wa-segment. Sa'an nan algorisin da ke sani na ƙidãya amincin duk tsãge. An canza hanya na ƙayyade tsakanin a sake saka wannan algoritm. Babu, dõmin an ƙayyade faransa da mazaɓa da mazaɓa, muna samar da wani littãfi na ƙarshen da na takarda na China. Akwai jarrabo masu ƙaranci kan wannan bangon zai nuna cewa, hanyonmu da ake buƙata, za'a sami wani rabo mai tsawo a kan wata fasarin dokuman-daraja halin-duniya wa CWS.", 'he': 'גישות עצביות קודמות משיגות התקדמות משמעותית עבור סגמנציה מילים סינית (CWS) בתור משימה ברמה משפטים, אבל היא סובלת מגבלות על תרחיש עולם אמיתי. בעיתון הזה, אנחנו מתייחסים לנושא הזה עם שיטה מודעת לקונקסט ולאופטימיזם את הפתרון ברמה המסמכים. העבודה הזו מציעה אסטרטגיה שלוש שלבים לשפר את ההופעה של CWS דיבור. ראשית, השיטה משתמשת במחלק עזרי כדי לתקן את הגבלה על המחלק הקדמי. ואז האלגוריתם מודע לקונקסט מחשב את האמון של כל חלקה. מסלול הסבירות המקסימלית מתבנה מחדש באלגוריתם הזה. חוץ מזה, כדי להעריך את ההופעה בדיור, אנו בונים נקודת רפואה חדשה שמכילה בחדשות האחרונות ומאמרים רפואיים סינים. ניסויים רחבים על המרמז הזה מראים שהשיטה המוצעת שלנו משיגה ביצוע תחרותי על תרחיש עולם אמיתי ברמה מסמכים עבור CWS.', 'bo': 'སྔོན་གྱི་ཤེས་བྱང་གི་ཐབས་ལམ་ལ་རྒྱ་ནག ང་ཚོས་ཤོག་བྱས་འདིའི་ནང ཤོག་བྱང་འདིས་འདིས་CWS མ་བཤད་ཀྱི་སྒྲུབ་ཚིག་གི་ཡར་རྒྱས་གཏོང་མཁན་གསུམ་གྱི་སྔོན་སྒྲིག་གཏོང་། དང་པོའི་ལམ་ལུགས་འདི་ནི་ཕན་ཐོགས་ཅན་གྱི་སྐྱེས་པའི་ཚད་རྩིས་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད། དེ་ནས་སྐབས་ཡུལ་རྟོགས་པའི་སྒྲིག་སྟངས་ཀྱིས་དབྱེ་བ་རེ་རེད་བསམ་བློ་གཏོང་བ་རེད། རྒྱ་ཆེ་ཤོས་བྱས་པར་ཆེ་ཤོས་མཁན་གྱི་སྒྲིག་སྟངས་འདིས་བསྐྱར་འཛུགས་བྱེད་ཀྱི་ཡོད། འོན་ཀྱང་། discourse་ནང་གི་གོ་སྐབས་ཡོད་ཚད་ལྟར་ཞིབ་འཇུག་གི་ཡིག་ཆ་གསར་བ་ཞིག་བཟོ་བྱས། རྒྱ་བསྐྱེད་པའི་བརྟག་ཞིག་གིས་གསར་བསྐྲུན་འབད་བྱས་ན། ང་ཚོའི་གྲོས་འཆར་བཀོད་པའི་ཐབས་ལམ་ལྟར་CWS ལ་ཡིག་ཆའི་གནས་སྟངས་དང་།'}
{'en': 'Neural Abstractive Multi-Document Summarization : Hierarchical or Flat Structure?', 'ar': 'تلخيص متعدد المستندات تجريدي عصبي: هيكل هرمي أم مسطح؟', 'pt': 'Resumo Neural Abstrativo Multi-Documento: Estrutura Hierárquica ou Plana?', 'es': 'Resumen abstractivo de varios documentos neuronales: ¿estructura jerárquica o plana?', 'fr': 'Synthèse multi-documents abstraite neuronale\xa0: structure hiérarchique ou plate\xa0?', 'ja': 'ニューラル抽象的マルチドキュメントの要約：階層構造または平坦構造？', 'zh': '神经抽象多文档摘要:层构与平面结构?', 'hi': 'तंत्रिका Abstractive बहु दस्तावेज़ Summarization: पदानुक्रमित या फ्लैट संरचना?', 'ru': 'Нейронное абстрактное обобщение нескольких документов: иерархическая или плоская структура?', 'ga': 'Achoimre Ildhoiciméad Neural Abstract: Ordlathach nó Struchtúr Comhréidh?', 'ka': 'ნეირალური აბსტრაქტიგური მრავალური დოკუმენტის კომპანიზაცია: ჰიერარიქური ან ფლანტიური სტრუქტურა?', 'el': 'Νευρική αφηρημένη Σύνοψη πολλών εγγράφων: Ιεραρχική ή Επίπεδη Δομή;', 'hu': 'Neurális absztraktív többdokumentumos összefoglalás: hierarchikus vagy lapos struktúra?', 'it': 'Sintesi astratta neurale multi-documento: struttura gerarchica o piatta?', 'kk': 'Нейралық абстрактивті көптеген құжаттардың тұжырымдамасы: хиерархикалық не кәдімгі құрылымы?', 'lt': 'Neuralinė abstrakti daugiadokumentų santrauka: Hierarchinė ar plokšti struktūra?', 'mk': 'Неурална апстрактивна мултидокументарна резервација: хиерархиска или рамна структура?', 'ms': 'Penapisan Multi-Dokumen Absraktif Neural: Struktur Hierarkik atau Flat?', 'ml': 'Neural Abstractive Multi-Document Summarization: Hierarchical or Flat Structure?', 'mn': 'Сэтгэл санааны абстрактив олон бичгийн нийлүүлэлт: Хиерархик эсвэл төвөгтэй бүтэц?', 'no': 'Neuralabstraktiv sammendrag for fleire dokument: hierarkisk eller flat struktur?', 'mt': 'Sommarju Newrali Abstrattiv Multi-Dokument: Struttura Erarkika jew Ċatta?', 'ro': 'Rezumat abstractiv neural multi-document: Structură ierarhică sau plată?', 'pl': 'Abstrakcyjne podsumowanie wielu dokumentów neuronowych: hierarchiczna lub płaska struktura?', 'sr': 'Neuralna abstraktivna sažetka višestrukog dokumenta: hijerarhička ili plava struktura?', 'si': 'නිර්මාණික විශේෂ විශේෂ විශේෂ විශේෂය: හියාර්චිකල් නැත්තම් සංස්ථාපනය?', 'sv': 'Neural Abstraktiv Sammanfattning av flera dokument: hierarkisk eller platt struktur?', 'so': 'Hierarchical or Flat structure?', 'ta': 'Neural Abstractive Multi-Document Summarization: Hierarchical or Flat Structure?', 'ur': 'Neural Abstractive Multi-Document Summarization: Hierarchical or Flat Structure?', 'uz': 'Neural Abstractive Multi-Document Summarization: Hierarchical or Flat Structure?', 'vi': 'Về tổng kết đa tài liệu thần kinh:', 'hr': 'Neuralna abstraktivna skupljanja višestrukih dokumenta: hijerarhička ili plava struktura?', 'nl': 'Neuronale abstracte multi-document samenvatting: hiërarchische of platte structuur?', 'bg': 'Нервно абстрактивно многодокументално обобщение: йерархична или плоска структура?', 'da': 'Neural Abstraktiv Multi-Document Summarisation: Hierarkisk eller flad struktur?', 'de': 'Neuronale abstraktive Zusammenfassung mehrerer Dokumente: Hierarchische oder flache Struktur?', 'fa': 'تعداد مجموعه\u200cای از سند\u200cهای عصبی: ساختار معمولی یا ساختار معمولی؟', 'ko': '신경 추상 다중 문서 요약: 차원 구조인가 편평 구조인가?', 'id': 'Penapisan Multi-Dokumen Abstraktif Neural: Struktur Hierarkis atau Flat?', 'sw': 'Ujumbe wa nyaraka nyingi za Abstractive Neural: Miundomo ya Nyaraka au Nyaraka?', 'tr': 'Näsaz Abstraktiw Çot-Sened Toplaýyşy: Hierarhiýal ýa Taýik Structure?', 'af': 'Neural Abstractive Multi- Document Opsomming: Hierarchical of Flat Structure?', 'am': 'የኩነቶች Abstractive Multi-Document ማጠቃለያ: Hierarchical or Flat Structure?', 'az': 'Nöral Abstraktiv Çox-Dəstə Toplaşdırma: Hiyerarşik ya da Flat Structure?', 'sq': 'Përshkrimi i Multi-Dokumenteve Abstraktive Neural: Struktura Hierarkike apo e Flat ë?', 'bs': 'Neuralna abstraktivna sažetka višestrukih dokumenta: hijerarhička ili plava struktura?', 'cs': 'Neurální abstrakční multi-dokumentové shrnutí: Hierarchická nebo plochá struktura?', 'ca': 'Resumen Neural Abstractive Multi-Document: Hierarchical or Flat Structure?', 'hy': "Նյարդային բազմաթիվ փաստաթղթերի համառոտագրություն' հիերարքիկական կամ հարկի կառուցվածք:", 'et': 'Neuraalne abstraktne mitme dokumendi kokkuvõte: hierarhiline või tasane struktuur?', 'bn': 'নিউরেল আবত্ত্রিক্যাটিভ মাল্টার-ডকুমেন্ট সামার্জার: হায়েরার্কিয়াল বা ফ্ল্যাট কাঠামোর?', 'fi': 'Neural Abstractive Multi-Document Summarization: Hierarkkinen vai tasainen rakenne?', 'jv': 'Samurasi Njuaral absolute Multi-document Cumaring:', 'he': 'סדרת מסמכים רבים נוירואלית אסטרקטיבית: מבנה הייררכי או שטוח?', 'ha': 'KCharselect unicode block name', 'sk': 'Povzetek večdokumentov: hierarhična ali ravna struktura?', 'bo': 'དཔེ་དབྱིབས་བསྒྱུར་བའི་སྣ་མང་ཡིག་གི་བཅུད་སྡུད་ཚོང：Hierarchical or Flat Structure?'}
{'en': 'With regards to WikiSum (CITATION) that empowers applicative explorations of Neural Multi-Document Summarization (MDS) to learn from large scale dataset, this study develops two hierarchical Transformers (HT) that describe both the cross-token and cross-document dependencies, at the same time allow extended length of input documents. By incorporating word- and paragraph-level multi-head attentions in the decoder based on the parallel and vertical architectures, the proposed parallel and vertical hierarchical Transformers (PHT & VHT) generate summaries utilizing context-aware word embeddings together with static and dynamics paragraph embeddings, respectively. A comprehensive evaluation is conducted on WikiSum to compare PHT & VHT with established models and to answer the question whether hierarchical structures offer more promising performances than flat structures in the MDS task. The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models. Moreover, we recommend PHT given its practical value of higher  inference speed  and greater memory-saving capacity.', 'ar': 'فيما يتعلق بـ WikiSum (CITATION) الذي يمكّن الاستكشافات التطبيقية للتلخيص العصبي متعدد المستندات (MDS) للتعلم من مجموعة البيانات واسعة النطاق ، طورت هذه الدراسة محولين هرميين (HT) يصفان تبعيات الرموز المتقاطعة والوثيقة المتقاطعة ، على تسمح في نفس الوقت بإطالة طول مستندات الإدخال. من خلال دمج الانتباه متعدد الرؤوس على مستوى الكلمات والفقرة في وحدة فك التشفير استنادًا إلى البنى المتوازية والعمودية ، تولد المحولات الهرمية المتوازية والرأسية المقترحة (PHT & VHT) ملخصات باستخدام عمليات دمج الكلمات الواعية بالسياق جنبًا إلى جنب مع حفلات الزفاف الثابتة والديناميكية ، على التوالى. يتم إجراء تقييم شامل على WikiSum لمقارنة PHT و VHT بالنماذج المعمول بها وللإجابة على سؤال ما إذا كانت الهياكل الهرمية تقدم أداءً واعدًا أكثر من الهياكل المسطحة في مهمة MDS. تشير النتائج إلى أن نماذجنا الهرمية تولد ملخصات ذات جودة أعلى من خلال التقاط علاقات عبر المستندات بشكل أفضل ، وتوفير المزيد من مساحات الذاكرة مقارنة بنماذج الهيكل المسطح. علاوة على ذلك ، نوصي باستخدام PHT نظرًا لقيمتها العملية المتمثلة في زيادة سرعة الاستدلال وزيادة سعة توفير الذاكرة.', 'fr': "En ce qui concerne WikiSum (CITATION) qui permet des explorations applicatives de Neural Multi-Document Summarization (MDS) pour apprendre à partir d'un ensemble de données à grande échelle, cette étude développe deux transformateurs hiérarchiques (HT) qui décrivent à la fois les dépendances entre jetons et entre documents, en même temps permettent longueur des documents d'entrée. En incorporant des attentions multi-têtes au niveau des mots et des paragraphes dans le décodeur sur la base des architectures parallèle et verticale, les transformateurs hiérarchiques parallèles et verticaux proposés (PHT & VHT) génèrent des résumés utilisant des incorporations de mots sensibles au contexte ainsi que des paragraphes statiques et dynamiques les intégrations, respectivement. Une évaluation complète est menée sur WikiSum pour comparer les PHT et VHT avec les modèles établis et pour répondre à la question de savoir si les structures hiérarchiques offrent des performances plus prometteuses que les structures plates dans la tâche MDS. Les résultats suggèrent que nos modèles hiérarchiques génèrent des résumés de meilleure qualité en capturant mieux les relations entre documents et en économisant davantage d'espaces mémoire par rapport aux modèles à structure plate. De plus, nous recommandons PHT étant donné sa valeur pratique de vitesse d'inférence plus élevée et de capacité d'économie de mémoire supérieure.", 'es': 'Con respecto a WikiSum (CITATION) que permite las exploraciones aplicativas de la sumarización neuronal de documentos múltiples (MDS) para aprender de un conjunto de datos a gran escala, este estudio desarrolla dos transformadores jerárquicos (HT) que describen tanto las dependencias entre tokens como entre documentos, al mismo tiempo permiten longitud de los documentos de entrada. Al incorporar atenciones de varios cabezales a nivel de palabras y párrafos en el decodificador basadas en las arquitecturas paralela y vertical, los Transformadores jerárquicos paralelos y verticales (PHT y VHT) propuestos generan resúmenes utilizando incrustaciones de palabras sensibles al contexto junto con párrafos estáticos y dinámicos incrustaciones, respectivamente. Se lleva a cabo una evaluación exhaustiva en WikiSum para comparar PHT y VHT con modelos establecidos y responder a la pregunta de si las estructuras jerárquicas ofrecen rendimientos más prometedores que las estructuras planas en la tarea MDS. Los resultados sugieren que nuestros modelos jerárquicos generan resúmenes de mayor calidad al capturar mejor las relaciones entre documentos y ahorrar más espacio de memoria en comparación con los modelos de estructura plana. Además, recomendamos PHT dado su valor práctico de mayor velocidad de inferencia y mayor capacidad de ahorro de memoria.', 'pt': 'Com relação ao WikiSum (CITATION) que capacita explorações de aplicativos de sumarização multi-documentos neurais (MDS) para aprender com conjuntos de dados em grande escala, este estudo desenvolve dois transformadores hierárquicos (HT) que descrevem as dependências entre tokens e documentos cruzados, em ao mesmo tempo permitem um comprimento maior de documentos de entrada. Ao incorporar atenções multi-cabeça de nível de palavra e parágrafo no decodificador com base nas arquiteturas paralela e vertical, os transformadores hierárquicos paralelos e verticais propostos (PHT e VHT) geram resumos utilizando incorporações de palavras com reconhecimento de contexto juntamente com incorporações de parágrafos estáticos e dinâmicos, respectivamente. Uma avaliação abrangente é realizada no WikiSum para comparar PHT & VHT com modelos estabelecidos e para responder à pergunta se as estruturas hierárquicas oferecem desempenhos mais promissores do que as estruturas planas na tarefa MDS. Os resultados sugerem que nossos modelos hierárquicos geram resumos de maior qualidade capturando melhor as relações entre documentos e economizam mais espaço de memória em comparação aos modelos de estrutura plana. Além disso, recomendamos o PHT devido ao seu valor prático de maior velocidade de inferência e maior capacidade de economia de memória.', 'ja': '大規模なデータセットから学習するニューラルマルチドキュメントサマリゼーション（ MDS ）の応用的探索を可能にするWikiSum （引用）に関して、本研究は、クロストークンとクロスドキュメントの両方の依存関係を記述する2つの階層トランスフォーマー（ HT ）を開発すると同時に、入力ドキュメントの長さを延長することを可能にする。 並列および垂直アーキテクチャに基づいてデコーダに単語レベルおよび段落レベルの多頭の注意を組み込むことにより、提案されている並列および垂直階層トランスフォーマー（ PHTおよびVHT ）は、文脈認識の単語埋め込みと静的およびダイナミクスの段落埋め込みをそれぞれ利用して要約を生成する。 ウィキサムでは、PHTとVHTを確立されたモデルと比較し、階層構造がMDSタスクのフラット構造よりも有望なパフォーマンスを提供するかどうかの問題に答えるために、包括的な評価が行われます。 その結果、当社の階層モデルは、ドキュメント間の関係をよりよくキャプチャすることにより、より高品質の要約を生成し、平面構造モデルと比較してより多くのメモリ空間を節約できることが示唆されています。 さらに、より高い推論速度とより大きなメモリ節約容量の実用的な価値を考慮して、PHTをお勧めします。', 'zh': '夫WikiSum(CITATION)者,使神经多文档摘要(MDS)之用,可以大集中学习,本开两变形金刚(HT),言交令牌跨文档,而许广输文档之长。 因其并行垂架构之解码器,入单词段多头注意,拟议并行,与垂直分变形金刚(PHT &VHT)分上下文感知词嵌静动态段落嵌成摘要。 WikiSum上周评,以比PHT、VHT之法式,层次结构于MDS之任,孰与平面结构哉? 结果表明,比于平面,则吾分而益得跨文档以成高质量之摘要,而省多内存空间。 此外,吾辈荐PHT,以其有高理速内存节省能力之用也。', 'ru': 'Что касается WikiSum (ЦИТИРОВАНИЕ), которая позволяет прикладным исследованиям нейронного многодокументного суммирования (MDS) учиться на крупномасштабном наборе данных, это исследование разрабатывает два иерархических трансформатора (HT), которые описывают как кросс-токен, так и кросс-документарную зависимость, в то же время позволяя увеличить длину входных документов. Путем включения словесных и абзацевых многоглавных обращений внимания в декодер на основе параллельной и вертикальной архитектур, предлагаемые параллельные и вертикальные иерархические трансформаторы (PHT иVHT) генерируют сводки, используя контекстно-зависимые вложения слов вместе с вложениями статических и динамических абзацев, соответственно. На WikiSum проводится комплексная оценка для сравнения PHT иVHT с установленными моделями и ответа на вопрос, предлагают ли иерархические структуры более многообещающие характеристики, чем плоские структуры в задаче MDS. Результаты показывают, что наши иерархические модели генерируют сводки более высокого качества, лучше фиксируя взаимосвязи между документами, и экономят больше пространства памяти по сравнению с моделями с плоской структурой. Кроме того, мы рекомендуем PHT, учитывая его практическую ценность - более высокую скорость вывода и большую память-сберегающую способность.', 'hi': 'WikiSum (CITATION) के संबंध में जो बड़े पैमाने पर डेटासेट से सीखने के लिए तंत्रिका बहु-दस्तावेज़ सारांशीकरण (एमडीएस) के लागू अन्वेषणों को सशक्त बनाता है, यह अध्ययन दो पदानुक्रमित ट्रांसफॉर्मर (एचटी) विकसित करता है जो क्रॉस-टोकन और क्रॉस-दस्तावेज़ निर्भरता दोनों का वर्णन करते हैं, एक ही समय में इनपुट दस्तावेजों की विस्तारित लंबाई की अनुमति देते हैं। समानांतर और ऊर्ध्वाधर आर्किटेक्चर के आधार पर डिकोडर में शब्द- और पैराग्राफ-स्तरीय बहु-सिर ध्यान को शामिल करके, प्रस्तावित समानांतर और ऊर्ध्वाधर पदानुक्रमित ट्रांसफॉर्मर (PHT & VHT) क्रमशः स्थैतिक और गतिशीलता पैराग्राफ एम्बेडिंग के साथ संदर्भ-जागरूक शब्द एम्बेडिंग का उपयोग करके सारांश उत्पन्न करते हैं। स्थापित मॉडल के साथ PHT और VHT की तुलना करने के लिए WikiSum पर एक व्यापक मूल्यांकन किया जाता है और इस सवाल का जवाब देने के लिए कि क्या पदानुक्रमित संरचनाएं MDS कार्य में फ्लैट संरचनाओं की तुलना में अधिक आशाजनक प्रदर्शन प्रदान करती हैं। परिणाम बताते हैं कि हमारे पदानुक्रमित मॉडल क्रॉस-दस्तावेज़ संबंधों को बेहतर ढंग से कैप्चर करके उच्च गुणवत्ता के सारांश उत्पन्न करते हैं, और फ्लैट-संरचना मॉडल की तुलना में अधिक मेमोरी स्पेस बचाते हैं। इसके अलावा, हम पीएचटी को उच्च अनुमान गति और अधिक स्मृति-बचत क्षमता के अपने व्यावहारिक मूल्य को देखते हुए सलाह देते हैं।', 'ga': 'Maidir le WikiSum (CITATION) a chumasaíonn taiscéalaíochtaí feidhmitheacha ar Achoimriú Néarach Ildhoiciméad (MDS) chun foghlaim ó thacar sonraí ar scála mór, forbraíonn an staidéar seo dhá Chlaochladán ordlathach (HT) a chuireann síos ar na spleáchais tras-chomharthaí agus trasdhoiciméid, ag ceadóidh an t-am céanna fad leathnaithe na ndoiciméad ionchuir. Trí airdí ilcheann ar leibhéal focal agus alt a ionchorprú sa díchódóir bunaithe ar na hailtireachtaí comhthreomhara agus ingearacha, gineann na Trasfhoirmeoirí ordlathacha comhthreomhara agus ingearacha (PHT & VHT) achoimrí ag baint úsáide as leabaithe focal atá feasach ar an gcomhthéacs mar aon le leabaithe ailt statacha agus dinimic, faoi seach. Déantar meastóireacht chuimsitheach ar WikiSum chun PHT & VHT a chur i gcomparáid le samhlacha seanbhunaithe agus chun an cheist a fhreagairt an dtugann struchtúir ordlathacha feidhmíocht níos bisiúla ná struchtúir chomhréidh sa tasc MDS. Tugann na torthaí le tuiscint go ngineann ár múnlaí ordlathacha achoimrí ar chaighdeán níos airde trí ghaolmhaireachtaí trasdhoiciméid a ghabháil níos fearr, agus go sábhálann siad níos mó spásanna cuimhne i gcomparáid le samhlacha le struchtúr comhréidh. Ina theannta sin, molaimid PHT i bhfianaise a luach praiticiúil a bhaineann le luas tátail níos airde agus cumas coigilte cuimhne níos fearr.', 'hu': 'A WikiSum (CITATION) tekintetében, amely lehetővé teszi a Neural Multi-Document Summarization (MDS) alkalmazási feltárásainak lehetővé tételét, hogy nagyméretű adatkészletből tanulhassanak, ez a tanulmány két hierarchikus transzformátort (HT) fejleszt ki, amelyek leírják mind a kereszttoken, mind a keresztdokumentum függőségeket, ugyanakkor lehetővé teszik a beviteli dokumentumok hosszabb hosszúságát. A párhuzamos és függőleges architektúrákon alapuló szó- és bekezdésszintű többfejű figyelmeztetések beépítésével a javasolt párhuzamos és függőleges hierarchikus transzformátorok (PHT &VHT) összefoglalókat hoznak létre kontextustudatos szóbeágyazásokkal, statikus és dinamikus bekezdésbeágyazásokkal együtt. Átfogó értékelést végeznek a WikiSumon, hogy összehasonlítsák a PHT és VHT modellekkel és válaszoljanak arra a kérdésre, hogy a hierarchikus struktúrák ígéretesebb teljesítményt nyújtanak-e, mint a lapos struktúrák az MDS feladatban. Az eredmények arra utalnak, hogy hierarchikus modelleink jobb minőségű összefoglalókat hoznak létre a dokumentumok közötti kapcsolatok jobb rögzítésével, és több memóriahelyet takarítanak meg a lapos szerkezetű modellekhez képest. Ezenkívül a PHT-t ajánljuk, mivel gyakorlati értéke a nagyobb következtetési sebesség és a nagyobb memória-takarékos kapacitás.', 'el': 'Όσον αφορά το WikiSum (CITATION) που δίνει τη δυνατότητα στις εφαρμογές εξερεύνησης της Νευρικής Συνοψίας Πολυεγγράφων (ΜΔΣ) να μάθουν από το σύνολο δεδομένων μεγάλης κλίμακας, η παρούσα μελέτη αναπτύσσει δύο ιεραρχικούς Μετασχηματιστές (που περιγράφουν τόσο τις διασταυρούμενες όσο και τις διασταυρούμενες εξαρτήσεις εγγράφων, επιτρέποντας ταυτόχρονα το εκτεταμένο μήκος των εγγράφων εισόδου. Με την ενσωμάτωση προσοχής πολλαπλών κεφαλιών σε επίπεδο λέξης και παραγράφου στον αποκωδικοποιητή με βάση τις παράλληλες και κάθετες αρχιτεκτονικές, οι προτεινόμενοι παράλληλοι και κάθετοι ιεραρχικοί μετασχηματιστές (δημιουργούν περιλήψεις χρησιμοποιώντας ενσωμάτωση λέξεων με επίγνωση του περιβάλλοντος μαζί με στατικές και δυναμικές ενσωμάτωση παραγράφου αντίστοιχα. Μια ολοκληρωμένη αξιολόγηση πραγματοποιείται στο WikiSum για να συγκρίνει το PHT &VHT με καθιερωμένα μοντέλα και να απαντήσει στο ερώτημα αν οι ιεραρχικές δομές προσφέρουν πιο ελπιδοφόρες επιδόσεις από τις επίπεδες δομές στο έργο MDS. Τα αποτελέσματα δείχνουν ότι τα ιεραρχικά μοντέλα μας δημιουργούν περιλήψεις υψηλότερης ποιότητας με την καλύτερη καταγραφή των σχέσεων μεταξύ εγγράφων και εξοικονομούν περισσότερους χώρους μνήμης σε σύγκριση με τα μοντέλα επίπεδης δομής. Επιπλέον, συστήνουμε δεδομένης της πρακτικής αξίας της υψηλότερης ταχύτητας συμπερασμάτων και της μεγαλύτερης ικανότητας εξοικονόμησης μνήμης.', 'ka': 'WikiSum-ის (CITATION) შესახებ, რომელიც ნეიროლური მრავალური დოკუმენტის კომპანიზაციაციის (MDS) პროგრამეტური განსხვავებას უფრო ძალიან გავისწავლა დიდი მაგალითა მონაცემების კომპანიზაციაზე, ეს სწავლად განვითარებს ორი hiერაქტიური ტრანფორმე პარალელი და გერტიკალური აქტიქტიკურების ბაზედ მრავალური დაახლოებით სიტყვა- და პარაგრაფიკალური დონეზე მრავალური დაახლოებით, პროგრალელი და გერტიკალური აქტიქტიკურები (PHT &VHT) დაახლოებით კონტექსტური დაახლოებით სიტყვა,  WikiSum-ში ყველაფერი განსაზღვრება გავაკეთება PHT &VHT-ის შემდგენისთვის, რომელიც განსაზღვრებული მოდელთან და დასაუბრუნოთ კითხვას თუ არა იერაქტიკალური სტრუქტურები უფრო მუშაობელი პ წარმოდგენების შესახებ, რომ ჩვენი ჰიერაქტიკური მოდელები უფრო მეტი კაalitეტის საზოგადოებების შესახებ უფრო მეტი დოკუმენტის შესახებ, და უფრო მეტი მეხსიერი სივრცე და დამატებით, ჩვენ შევძლებთ PHT-ს პრაქტიკური მნიშვნელობა, რომელიც უფრო მეტი ინფრენციის სიჩქარე და უფრო მეტი მეხსიერების შესაძლებლობა.', 'it': 'Per quanto riguarda WikiSum (CITATION) che consente alle esplorazioni applicative di Neural Multi-Document Summarization (MDS) di imparare da set di dati su larga scala, questo studio sviluppa due Transformer gerarchici (HT) che descrivono sia le dipendenze cross-token che cross-document, consentendo allo stesso tempo una lunghezza estesa dei documenti di input. Incorporando nel decoder attenzioni multi-testa a livello di parola e paragrafo basate sulle architetture parallele e verticali, i trasformatori gerarchici paralleli e verticali proposti (PHT &VHT) generano riassunti utilizzando incorporazioni di parole consapevoli del contesto insieme a incorporazioni di paragrafi statici e dinamici, rispettivamente. Una valutazione completa è condotta su WikiSum per confrontare PHT &VHT con modelli consolidati e per rispondere alla domanda se le strutture gerarchiche offrono prestazioni più promettenti rispetto alle strutture piatte nel compito MDS. I risultati suggeriscono che i nostri modelli gerarchici generano riassunti di qualità superiore catturando meglio le relazioni tra documenti e risparmiando più spazio di memoria rispetto ai modelli a struttura piatta. Inoltre, raccomandiamo PHT dato il suo valore pratico di maggiore velocità di inferenza e maggiore capacità di risparmio di memoria.', 'lt': 'With regards to WikiSum (CITATION) that empowers applicative explorations of Neural Multi-Document Summarization (MDS) to learn from large scale dataset, this study develops two hierarchical Transformers (HT) that describe both the cross-token and cross-document dependencies, at the same time allow extended length of input documents.  Įtraukiant žodžių ir punktų daugiapakopį dėmesį į lygiagrečią ir vertikalią architektūrą grindžiamą dekoderį, siūlomi lygiagrečiai ir vertikalūs hierarchiniai transformatoriai (PHT &VHT) sukuria santraukas, kuriose naudojami konteksto suprantami žodžių įterpimai kartu atitinkamai statiniai ir dinamiški punktų įterpimai. Visapusiškas WikiSum vertinimas atliekamas siekiant palyginti PHT &VHT su nustatytais modeliais ir atsakyti į klausimą, ar hierarchinės struktūros teikia daug žadančių rezultatų nei plokščios struktūros MDS užduotyje. The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models.  Be to, rekomenduojame PHT, atsižvelgiant į jos praktinę vertę – didesnį išvados greitį ir didesnį atminties taupymo pajėgumą.', 'mk': 'Што се однесува до WikiSum (CITATION) кој овозможува апликативните експерирации на неуралната мултидокументарна резултатација (MDS) да научат од голем набор на податоци, оваа студија развива два хиерархични трансформери (HT) кои ги опишуваат и раскрсните и раскрсните зависности на документите, истовремено овозможуваат проширена должина на ввод Со вклучување на внимание на зборови и параграфски нивоа на мултиглави во декодерот базиран на паралелните и вертикалните архитектури, предложените паралелни и вертикални хиерархични трансформери (PHT &VHT) генерираат резултати користејќи контекстно свесни зборови вклучени заедно со статички и динамички параграфски На WikiSum се спроведува сеопфатна проценка за споредување на PHT &VHT со воспоставени модели и за одговор на прашањето дали хиерархичните структури нудат повеќе ветувачки изведби отколку рамни структури во задачата MDS. The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models.  Покрај тоа, препорачуваме PHT со оглед на својата практична вредност на повисока брзина на конференција и поголем капацитет за зачувување на меморијата.', 'kk': 'WikiSum (CITATION) дегеннен қарай, көпшілікті көпшілікті құжаттар тұжырымдамасын (MDS) үлкен масштабтағы деректер жиындан үйрену үшін қолданатын зерттеулерді көмектеседі, бұл зерттеулер екі иерархиялық түрлендіруші (HT) жасайды. Бұл зерттеулер бірдей кезде,  Параллельді және тік архитектураларда негіздеген декодердің бірнеше сөз- мен абран деңгейінің қатынасын қосу арқылы, параллель және тік иерархиялық түрлендірушері (PHT &VHT) қолданылатын мәтіндіктерді қолданып, контексті түсінікті сөздерді ендіру арқылы,  PHT &VHT дегенді орнатылған үлгілерімен салыстыру үшін WikiSum- да толық оқиға жұмыс істейді, және иерархиялық құрылғылар MDS тапсырмасындағы жеткілікті құрылғылардан артық құрылғылардан артық оқиға Нәтижелер біздің иерархикалық үлгілеріміз құжаттың қатынасын жақсы түсіндіру арқылы, жады бос орындарын бір құрылғы үлгілерімен салыстыру арқылы жоғары сапаттамасын құрады. Қосымша, PHT- ті өзінің практикалық мәнін өзінің жылдамдығын және жады сақтау мүмкіндігін көмектесетін.', 'ms': 'Berkaitan dengan WikiSum (CITATION) yang membenarkan pengeksplorasi aplikatif Penapisan Dokumen-Berbilang Neural (MDS) untuk belajar dari set data skala besar, kajian ini mengembangkan dua Penukar Hierarkikal (HT) yang menggambarkan dependensi salib-token dan salib-dokumen, pada masa yang sama membenarkan panjang panjang dokumen input. Dengan memasukkan perhatian berbilang-kepala aras perkataan dan paragraf dalam dekoder berdasarkan arkitektur selari dan menegak, Penukar Hierarkikal selari dan menegak (PHT &VHT) yang diusulkan menghasilkan ringkasan menggunakan penyembedding perkataan yang sedar-konteks bersama-sama dengan penyembedding paragraf statik dan dinamik, berdasarkan. Evaluasi meliputi dilakukan pada WikiSum untuk membandingkan PHT &VHT dengan model yang ditetapkan dan untuk menjawab soalan sama ada struktur hierarkis menawarkan prestasi yang lebih berjanji daripada struktur rata dalam tugas MDS. Hasilnya menunjukkan bahawa model hierarkis kita menghasilkan ringkasan kualiti yang lebih tinggi dengan menangkap lebih baik hubungan salib dokumen, dan simpan lebih banyak ruang memori dibandingkan dengan model struktur rata. Selain itu, kami cadangkan PHT mengingati nilai praktik kelajuan kesimpulan yang lebih tinggi dan kapasitas penyimpanan ingatan yang lebih besar.', 'ml': 'വികിസ്സുമിന്റെ (CITATION) കാര്യത്തില്\u200d നെയുറല്\u200d പല-രേഖകളുടെ സംഘടനയുടെ പ്രയോഗത്തില്\u200d പഠിക്കാന്\u200d സാധിക്കുന്ന പ്രയോഗത്തിനുള്ള പരിശോധനങ്ങള്\u200dക്ക് സാധ്യതയുണ്ട്. വലിയ സ്കേല്\u200d ഡാറ്റാസറില്\u200d നിന്നും പഠി പാരാളലിലും വെര്\u200dട്ടിക്കല്\u200d സ്ഥാനത്തിനും അടിസ്ഥാനമായി ഡെകോഡെറിലും വാക്ക്- നിലനിര്\u200dമ്മിക്കുന്ന പല തലയിലുള്ള ശ്രദ്ധ കൂട്ടത്തില്\u200d ചേര്\u200dക്കുന്നതിനാല്\u200d പ്രൊദ്ദേശിക്കപ്പെട്ട പാലാള്\u200dലെയിലും വെ PHT &VHT-നെ സ്ഥാപിച്ച മോഡലുകളോടൊപ്പം തുല്യമാക്കുവാനും എംഡിഎസ് ജോലിയിലെ ഫ്ലാറ്റ് ഘടനകളെക്കാള്\u200d ഹിയെരാര്\u200dക്കിക്കല്\u200d സ്ഥാപിക്കുന്ന പണിയു അതിന്റെ ഫലങ്ങള്\u200dക്ക് നിര്\u200dദേശിക്കുന്നത് നമ്മുടെ ഹീയറാര്\u200dക്കിക്കല്\u200d മോഡലുകള്\u200d കൂടുതല്\u200d ഗുരുതപ്രകാരം ഉണ്ടാക്കുന്നു. ക്രിസ്റ്റ് രേഖകളുടെ ബന അതുകൊണ്ട്, പിഎച്ചിറ്റിന്റെ പ്രാകൃതിക വേഗത്തിന്റെയും മെമ്മറി സൂക്ഷിക്കുന്ന കഴിവിന്റെയും കൂടുതല്\u200d മൂല്', 'mt': 'Fir-rigward ta’ WikiSum (CITATION) li jagħti s-setgħa lill-esplorazzjonijiet applikattivi tas-Sommarju Multi-Dokumenti Newrali (MDS) biex jitgħallmu minn sett ta’ dejta fuq skala kbira, dan l-istudju jiżviluppa żewġ Trasformaturi ġerarkiċi (HT) li jiddeskrivu kemm id-dipendenzi trasversali kif ukoll dawk trasversali tad-dokumenti, fl-istess ħin jippermettu tul estiż ta’ dokumenti ta’ input. Permezz tal-inkorporazzjoni ta’ attenzjoni b’ħafna ras fil-livell tal-kliem u tal-paragrafu fid-dekoder ibbażat fuq l-arkitetturi paralleli u vertikali, it-Trasformaturi ġerarkiċi paralleli u vertikali proposti (PHT &VHT) jiġġeneraw sommarji li jużaw inkorporazzjonijiet tal-kliem konxji mill-kuntest flimkien ma’ inkorporazzjonijiet tal-paragrafi statiċi u dinamiċi, rispettivament. Twettqet evalwazzjoni komprensiva fuq WikiSum biex titqabbel PHT &VHT ma’ mudelli stabbiliti u biex titwieġeb il-mistoqsija jekk l-istrutturi ġerarkiċi joffrux prestazzjonijiet aktar promettenti minn strutturi ċatti fil-kompitu tal-MDS. Ir-riżultati jissuġġerixxu li l-mudelli ġerarkiċi tagħna jiġġeneraw sommarji ta’ kwalità ogħla billi jinqabdu aħjar relazzjonijiet bejn id-dokumenti, u jiffrankaw aktar spazji tal-memorja meta mqabbla ma’ mudelli ta’ struttura ċatta. Barra minn hekk, nirrakkomandaw lill-PHT minħabba l-valur prattiku tiegħu ta’ veloċità ogħla ta’ inferenza u kapaċità akbar ta’ ffrankar tal-memorja.', 'mn': 'WikiSum (CITATION) гэдэг нь мэдээллийн хэмжээгээр суралцах боломжтой мэдээллийн хэмжээгээс илүү их хэмжээний өгөгдлийн санаас суралцах боломжтой ажиллагааны судалгааны талаар энэ судалгаа хоёр төвөгтэй шилжүүлэгч (HT) боловсруулдаг. Энэ судалгаа хоёр давхар зураг болон олон баримт бичгийн хамаарал хамаара Параллел болон босоо архитектурууд дээр үндсэн үг болон параграл түвшинд олон толгой удирдлагааг багтааж, санал болгосон параграл болон босоо архитектур түвшигчид (PHT &VHT) нь контекст ойлгомжтой үгийг багтааж байдаг. WikiSum дээр PHT &VHT-г бүтээгдэхүүн загвартай харьцуулахын тулд бүрэн дүгнэлт хийгддэг. Иерактикийн бүтэц нь MDS-ийн ажлын бүтээгдэхүүнээс илүү амлалтай үйл ажиллагааг өгөх эсэхийг асуухад хариулт өгдөг. Үүний үр дүнд бидний төрөлхтний загвар нь бичил баримтын харилцааны илүү өндөр чанарын жинхэнэ хэмжээсүүдийг бий болгодог гэдгийг илүү ойлгож байна. Мөн бид PHT-г илүү өндөр халдварын хурд, санамж хадгалах чадварын үнэ цэнэтэй болгон тайлбарладаг.', 'pl': 'W odniesieniu do WikiSum (CITATION), który umożliwia aplikacyjne badania neuronowego podsumowania wielu dokumentów (MDS) do uczenia się z dużej skali zbioru danych, opracowano dwa hierarchiczne transformatory (HT), które opisują zarówno zależności między tokenami, jak i między dokumentami, jednocześnie umożliwiają wydłużenie długości dokumentów wejściowych. Dzięki włączeniu uwagi wielogłowicowej na poziomie słów i akapitów w dekoderze opartej na architekturze równoległej i pionowej, proponowane równoległe i pionowe hierarchiczne transformatory (PHT &VHT) generują podsumowania wykorzystujące kontekstowe osadzenia słów wraz z osadzeniami akapitów statycznych i dynamicznych, odpowiednio. Przeprowadzona jest kompleksowa ocena na WikiSum, aby porównać PHT &VHT z ustalonymi modelami i odpowiedzieć na pytanie, czy struktury hierarchiczne oferują bardziej obiecujące wydajności niż struktury płaskie w zadaniu MDS. Wyniki sugerują, że nasze hierarchiczne modele generują podsumowania o wyższej jakości poprzez lepsze przechwytywanie relacji między dokumentami i oszczędzają więcej miejsc pamięci w porównaniu z modelami struktury płaskiej. Ponadto zalecamy PHT ze względu na jego praktyczną wartość większej prędkości wnioskowania i większej pojemności oszczędzania pamięci.', 'ro': 'În ceea ce privește WikiSum (CITATION) care permite explorărilor aplicative ale Rezumării Neurale Multi-Document (MDS) să învețe din setul de date la scară largă, acest studiu dezvoltă două Transformatoare ierarhice (HT) care descriu atât dependențele cross-token, cât și cross-document, permițând în același timp o lungime extinsă a documentelor de intrare. Prin încorporarea atențiilor multi-cap la nivel de cuvânt și paragraf în decoder bazate pe arhitecturile paralele și verticale, transformatoarele ierarhice paralele și verticale propuse (PHT &VHT) generează rezumate utilizând încorporări conștiente de context cu cuvinte încorporate împreună cu încorporări statice și dinamice de paragrafe, respectiv. O evaluare cuprinzătoare este efectuată pe WikiSum pentru a compara PHT &VHT cu modelele stabilite și pentru a răspunde la întrebarea dacă structurile ierarhice oferă performanțe mai promițătoare decât structurile plate în sarcina MDS. Rezultatele sugerează că modelele noastre ierarhice generează rezumate de calitate superioară prin captarea mai bună a relațiilor între documente și economisirea mai multor spații de memorie în comparație cu modelele cu structură plată. Mai mult decât atât, recomandăm PHT având în vedere valoarea sa practică de viteză de inferență mai mare și capacitate mai mare de economisire a memoriei.', 'sr': 'S obzirom na WikiSum (CITATION) koji omogućava aplikacijske istraživanja Neuralne višestruke dokumentacije (MDS) da nauče iz velike skupine podataka, ova istraživanja razvija dva hijerarhičkog transformera (HT) koji opisuju i krstotokene i krstodokumenata zavisnosti, istovremeno omogućavaju produženu dužinu ulaznih dokumenta. Uključujući višeglavnu pažnju na reči i nivou paragrafa na dekoderu na temelju paralelnih i vertikalnih arhitektura, predloženi paralelni i vertikalni hijerarhički transformatori (PHT &VHT) stvaraju sažetke korištenje uključujući kontekstsvesne riječi zajedno sa stavnim i dinamičkim stavljanjem paragrafa. Svobuhvatna procjena je provedena na WikiSumu kako bi usporedila PHT &VHT sa uspostavljenim modelima i odgovorila na pitanje da li hijerarhijske strukture nude obećavajuće izvode nego ravne strukture u zadatku MDS-a. Rezultati ukazuju na to da naše hijerarhijske modele stvaraju sažetke višeg kvaliteta boljim prihvaćanjem odnosa preko dokumenta i spašavaju više mesta pamćenja u usporedbi sa modelima ravne strukture. Preporučujemo PHT s obzirom na praktičnu vrijednost veće brzine infekcije i veće kapacitete spašavanja pamćenja.', 'no': 'For WikiSum (CITATION) that empowers applicative explorations of Neural Multi-Document Summarization (MDS) to learn from large scale dataset, this study develops to hierarchical Transformers (HT) that describes both the cross-token and cross-document dependencies, at the same time allow extended length of input documents. Ved å inkludere fleire opplysningar på ordet- og avsnittnivå i dekoderen basert på parallelle og vertikale arkitekturar, vil dei foreslåde parallelle og vertikale hierarkiske transformerande (PHT &VHT) laga samandringar som brukar innbygging av ordet i kontekst- opplysningar saman med innbygging av statiske og dynamiske paragrafer. Eit komplett evaluering gjev på WikiSum for å sammenligne PHT &VHT med oppretta modeller og for å svara på spørsmålet om hierarkiske strukturar gjev meir promising utviklingar enn flate strukturar i MDS- oppgåva. Resultatet tyder på at hierarkiske modeller våre lagar sammendragar med høgare kvalitet ved at det er bedre å henta kryssdokumentrelasjonar og lagra meir minnerområde i sammenligning med flatstrukturmodeller. I tillegg anbefaler vi PHT å gje praktiske verdien til høgare infeksjonsfartet og større minne-lagringsmessighet.', 'si': 'සමග විකිසුම (CITATION) සමග විකිසියම් සම්බන්ධයෙන් සම්බන්ධ කරනවා න්\u200dයූරාල් ගොඩක් ලොකු දත්ත සම්බන්ධයෙන් ඉගෙන ගන්න, මේ පරීක්ෂණය සම්බන්ධයෙන් විසින්ධ විසින්ධ විසින්ධ දෙක By inkorporating word- and paragraf-level Multi-head Attensions in the decoder based on the Parallel and Upper Archives, the advised Parallel and Upper Archive Transferers (PHT & VHT) genere summes use ContextKnow word Embdings with static and ynamics Paragraf Embdings, in a way. Note this is a KRunner keyword;% 1 is a KRunner keyword;% 2 is a KRunner keyword;% 3 is a KRunner keyword A comprehersive evalution is managed on WikiSum to compare PHT & VHT with a set of Models and to the Answer of the ask if the hiyerarArchic Strukts are more Promoting Perfections than the Flat Strukts in the MDS job. ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dර තවත්, අපි PHT ප්\u200dරශ්නය කරන්න පුළුවන් විශාල වේගය සහ වැඩිය මතකය බේරගන්න පුළුවන්', 'so': "Kuwii WikiSum (CITATION) ee uu awoodo dalbasho applikative ah oo ku saabsan qoraalka koowaad ee Neural Multi-Documentation (MDS) inuu ka barto macluumaad aad u weyn, kaasi waxbarashadu wuxuu horumariyaa laba hierarchical Transformers (HT), kaas oo ku sawira iskuul-token iyo iskuul-document ku xiran, isla markaasna wuxuu ruqsan yahay dhererka wargeyska. Hadal- iyo darafka darafka badan ee qodcodka ku qoran meelaha la mid ah iyo meelaha vertikal ah ee la soo jeeday waxay sameeyaan summariyo ku qoran isticmaalaya qoraal-aqoon ah oo ku qoran qoraal-qoraal, waxaana ku qoran qoraalka saxda iyo dynamics, kuwaas oo la soo jeeday parallel iyo vertical hierarchical hierarchical hierarchical hierarchical hierarchical (PHT &VHT). WikiSum waxaa lagu sameeyaa qiimeyn aasaasi ah si uu u simo PHT &VHT sameyno modello la dhisay iyo in uu u jawaabo su'aalaha, in dhismaha hierarchical ay sameeyaan wax ka sii ballan badan dhismaha bannaanta ee shaqada MDS. The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models.  Sidoo kale waxaan ku talinaynaa in PHT la siiyo qiimaheeda caadiga ah oo aad u dheer, iyo awooddiisa badbaadada xusuusta.", 'sv': 'När det gäller WikiSum (CITATION) som gör det möjligt för applikativa utforskningar av Neural Multi-Document Summarization (MDS) att lära av storskalig datamängd, utvecklar denna studie två hierarkiska Transformers (HT) som beskriver både cross-token och cross-document beroenden, samtidigt tillåter utökad längd av indata dokument. Genom att införliva ord- och styckenivåuppmärksamheter på flera huvuden i dekoden baserat på parallella och vertikala arkitekturer genererar de föreslagna parallella och vertikala hierarkiska transformatorerna (PHT &VHT) sammanfattningar med hjälp av kontextmedvetna ordinbäddningar tillsammans med statiska respektive dynamiska styckeinbäddningar. En omfattande utvärdering görs på WikiSum för att jämföra PHT &VHT med etablerade modeller och för att besvara frågan om hierarkiska strukturer erbjuder mer lovande prestanda än platta strukturer i MDS-uppgiften. Resultaten tyder på att våra hierarkiska modeller genererar sammanfattningar av högre kvalitet genom att bättre fånga korsdokumentsrelationer och spara mer minnesutrymme jämfört med flat structure modeller. Dessutom rekommenderar vi PHT med tanke på dess praktiska värde av högre inferenshastighet och större minnesbesparande kapacitet.', 'ta': 'விகிச்சும் (CITATION) பற்றியால் நியூரல் பல- ஆவண சுருக்கம் கற்ற பயன்பாட்டின் வெளியீடுகளை அதிகாரமாக்குகிறது, பெரிய அளவு தரவு அமைப்பிலிருந்து கற்றுக் கொள்ள இந்த படிப்பாடு இரண்டு மாற்றங்களை உருவாக்குகிறது, அது க இணைய மற்றும் செங்குத்து அடிப்படைகளை அடிப்படையில் சேர்க்கும் வார்த்தை- மற்றும் paragraph- மட்டத்தில் பல தலைப்பு கவனம் Name The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models.  மேலும், நாம் PHT அதன் செயல்பாடு மதிப்பை அதிக நோய் வேகம் மற்றும் அதிகமான நினைவு சேமிப்பு சக்தி', 'ur': 'ویکیسسم (CITATION) کے بارے میں جو نیورل Multi-Document Summarization (MDS) کی کاربرد کی تحقیقات پر قادر ہے کہ بڑے اسکیل ڈاٹ سٹ سے سیکھ سکیں، اس تحقیقات دو حیراتیکل تغییرات (HT) کو تغییر دیتا ہے جو کروسٹٹوکنے اور کروسٹوکیم ڈوکیم ڈوکیمٹ ڈوکیمٹ ڈوکیمٹ ڈوکیمٹ ڈوکیمٹ کلمات- اور پاراگراف- سطح کے متعدد-سر کی توجه کے ذریعہ دکھانے کے لئے مختلف اور متعدد معمارات پر بنیاد رکھتے ہیں، پیغمبر کے مطابق مختلف اور متعدد افراطیکل تغییرات (PHT &VHT) کے ذریعہ متوجہ ہونے والی کلمات کے مطابق استٹیکل اور ڈینامیک پاراگراف امڈینگ کے ساتھ پیدا ویکیس سم پر ایک محکم ارزیابی ہے کہ PHT &VHT کو ثابت کئے ہوئے موڈل کے ساتھ مقایسہ کرنے کے لئے اور پوچھنے کے لئے جواب دیں کہ کیا ہیرارک ساخترات MDS کے کام میں فالت ساخترات سے زیادہ وعدہ دینے والی عملکرد پیش کرتی ہیں. نتیجے ان کی توصیف کرتے ہیں کہ ہمارے حیراتیکل موڈلے بلند کیفیت کے ساتھ بہترین ترکیب کے ذریعہ سے زیادہ مہمانی جگہ رکھتے ہیں اور فلاٹ ساختاری موڈلے کے مقابلہ میں زیادہ مہمانی جگہ رکھتے ہیں. اور ہم نے PHT کو اس کے عمدہ مقدار کے ساتھ مہربانی دیتے ہیں کہ اس کی عمدہ مہربانی میں زیادہ سرعت اور زیادہ مہربانی ذخیره کی قابلیت۔', 'uz': "Name Name Name Natijalar esa, bizning hierarchik modellarimiz quyidagi darajalarni kichik darajada yaratish va cross-hujjatning huquqlarini olib tashlash va boshqa xotira joylarini flat-structural modellariga kamaytirish imkoniyatini saqlash mumkin. Ko'rib, biz PHT'ning asosiy qiymatini eng yaxshi qiymatga va xotira saqlash imkoniyatini bajarishimizni talab qilamiz.", 'vi': 'Đối với WikiLSum (độc lập) cho phép sử dụng các khám phá các tiêu chí thần kinh đa tài liệu (MDS) để học từ bộ dữ liệu quy mô lớn, nghiên cứu này phát triển hai Dịch hoá phân cấp (HT) mà mô tả các mối quan hệ giữa các quỹ hình và các tài liệu chéo, đồng thời cho phép dài lâu dài các tài liệu nhập. Bằng cách nhập vào các chức năng đa chữ và đoạn của các bộ giải mã dựa trên các cấu trúc song song và dọc, cấu trúc cấu trúc cấu trúc cấu trúc song song song song và thẳng đứng (PHT (PHT/ VHT) tạo ra các bản tóm tắt nhờ kết hợp nhận diện từ ngữ cảnh cùng với cấu trúc phân tích tích tĩnh và tính chất. Một đánh giá to àn diện được thực hiện trên WikiLSum về việc so sánh PHT, VHT với các mô hình đã xác định và để trả lời câu hỏi liệu cấu trúc cấp cao có đem lại triển vọng nhiều hơn cấu trúc phẳng trong nhiệm vụ MDS. Kết quả cho thấy các mô hình cấp dưới của chúng ta tạo ra các bản tóm tắt chất cao hơn bằng cách nắm giữ các mối quan hệ chéo tài liệu, và tiết kiệm nhiều khoảng bộ nhớ hơn so với các mô hình cấu trúc phẳng. Hơn nữa, chúng tôi đề nghị triết học dựa trên giá trị thực tế của tốc độ nhận ra cao và khả năng tiết kiệm trí nhớ.', 'bg': 'По отношение на Уикисумата (ЦИТАЦИЯ), която дава възможност за апликативни проучвания на невронното многодокументално обобщаване (МДС), за да се научи от широкомащабния набор от данни, това проучване разработва два йерархични трансформатора (ХТ), които описват както зависимостта на кръстосаните символи, така и на кръстосаните документи, като в същото време позволяват удължена продължителност на входните документи. Чрез включването на вниманието на няколко глави на ниво дума и абзац в декодера въз основа на паралелни и вертикални архитектури, предложените паралелни и вертикални йерархични трансформатори (PHT &VHT) генерират резюмета, използвайки контекстното вграждане на думи заедно със статични и динамични вграждания на абзаци съответно. Проведена е цялостна оценка на Уикисум, за да се сравни PHT &VHT с утвърдени модели и да се отговори на въпроса дали йерархичните структури предлагат по-обещаващи резултати от плоските структури в задачата МДС. Резултатите показват, че нашите йерархични модели генерират резюмета с по-високо качество чрез по-добро улавяне на междудокументни взаимоотношения и спестяват повече пространство в паметта в сравнение с моделите с плоска структура. Освен това препоръчваме ПХТ предвид практическата му стойност на по-висока скорост на заключение и по-голям капацитет за спестяване на памет.', 'da': 'Med hensyn til WikiSum (CITATION), der gør det muligt for applikationer at udforske Neural Multi-Document Summarization (MDS) til at lære af store datasæt, udvikler dette studie to hierarkiske Transformers (HT), der beskriver både cross-token og cross-document afhængigheder, samtidig tillader længere længde af inputdokumenter. Ved at indarbejde ord- og afsnitsniveau flerhovedets opmærksomhed i dekoden baseret på parallelle og lodrette arkitekturer, genererer de foreslåede parallelle og vertikale hierarkiske transformatorer (PHT &VHT) resuméer ved hjælp af kontekstbevidste ordindlejringer sammen med henholdsvis statiske og dynamiske afsnitsindlejringer. En omfattende evaluering foretages på WikiSum for at sammenligne PHT &VHT med etablerede modeller og for at besvare spørgsmålet om hierarkiske strukturer giver mere lovende resultater end flade strukturer i MDS-opgaven. Resultaterne tyder på, at vores hierarkiske modeller genererer resuméer af højere kvalitet ved bedre at fange tværs-dokumentrelationer og spare flere hukommelsespladser sammenlignet med flade strukturer modeller. Desuden anbefaler vi PHT i betragtning af dens praktiske værdi af højere inference hastighed og større hukommelsesbesparende kapacitet.', 'hr': 'S obzirom na WikiSum (CITATION) koji omogućava primjene istraživanja Neuralne multidokumentacije (MDS) da nauče iz velike skupine podataka, ova istraživanja razvija dva hijerarhičkog transformatora (HT) koji opisuju i krstotokene i krstodokumenata zavisnosti, istovremeno omogućavaju produženu dužinu ulaznih dokumenta. Uključujući višeglavne pozornosti riječi i razine paragrafa u dekoderu na temelju paralelnih i vertikalnih arhitektura, predloženi paralelni i vertikalni hijerarhički transformatori (PHT &VHT) stvaraju sažetke koji koriste uključujuće kontekstski svesne riječi zajedno s ugrađenjem staničnih i dinamičkih paragrafa. Svobuhvatna procjena je provedena na WikiSum kako bi usporedila PHT &VHT s utvrđenim modelima i odgovorila na pitanje da li hijerarhijske strukture nude obećavajuće učinke nego ravne strukture u zadatku MDS-a. Rezultati ukazuju na to da naše hijerarhijske modele stvaraju sažetke višeg kvaliteta boljim uhvaćenjem odnosa o krstodokumentima i spašavaju više mjesta pamćenja u usporedbi s modelima ravne strukture. Preporučujemo PHT s obzirom na praktičnu vrijednost veće brzine infekcije i veće kapacitete spašavanja pamćenja.', 'nl': 'Met betrekking tot WikiSum (CITATION) dat applicatieve verkenningen van Neural Multi-Document Summarization (MDS) mogelijk maakt om te leren van grootschalige dataset, ontwikkelt deze studie twee hiërarchische Transformers (HT) die zowel de cross-token als cross-document afhankelijkheden beschrijven, tegelijkertijd een langere lengte van invoerdocumenten mogelijk maken. De voorgestelde parallelle en verticale hiërarchische Transformers (PHT &VHT) genereren samenvattingen door gebruik te maken van contextbewuste woordinsluitingen samen met statische en dynamische alinea-insluitingen. Een uitgebreide evaluatie wordt uitgevoerd op WikiSum om PHT &VHT te vergelijken met gevestigde modellen en om de vraag te beantwoorden of hiërarchische structuren veelbelovende prestaties bieden dan platte structuren in de MDS-taak. De resultaten suggereren dat onze hiërarchische modellen samenvattingen van hogere kwaliteit genereren door documentoverschrijdende relaties beter vast te leggen en meer geheugenruimte te besparen in vergelijking met vlakke structuren modellen. Bovendien raden we PHT aan vanwege de praktische waarde van hogere inferentiesnelheid en grotere geheugenbesparende capaciteit.', 'de': 'Im Hinblick auf WikiSum (CITATION), das die applikative Erforschung der neuronalen Multi-Document Summarization (MDS) ermöglicht, aus großen Datensätzen zu lernen, entwickelt diese Studie zwei hierarchische Transformatoren (HT), die sowohl die tokenübergreifenden als auch dokumentübergreifenden Abhängigkeiten beschreiben und gleichzeitig eine längere Länge von Eingabedokumenten ermöglichen. Die vorgeschlagenen parallelen und vertikalen hierarchischen Transformatoren (PHT &VHT) erzeugen Zusammenfassungen, die kontextbewusste Worteinbettungen zusammen mit statischen und dynamischen Absatzeinbettungen verwenden, indem sie Wort- und Absatzaufmerksamkeiten in den Decoder integrieren. Auf WikiSum wird eine umfassende Evaluation durchgeführt, um PHT &VHT mit etablierten Modellen zu vergleichen und die Frage zu beantworten, ob hierarchische Strukturen in der MDS-Aufgabe vielversprechendere Leistungen bieten als flache Strukturen. Die Ergebnisse deuten darauf hin, dass unsere hierarchischen Modelle durch bessere Erfassung dokumentübergreifender Zusammenhänge qualitativ hochwertigere Zusammenfassungen generieren und im Vergleich zu flachen Strukturmodellen mehr Speicherplatz sparen. Darüber hinaus empfehlen wir PHT aufgrund seines praktischen Wertes einer höheren Inferenzgeschwindigkeit und einer größeren Speicherkapazität.', 'ko': 'WikiSum(인용문)에 관해서는 신경 다중 문서 요약(MDS)의 응용 탐색을 대규모 데이터로부터 집중적으로 학습할 수 있도록 한다. 본 연구는 두 개의 차원 변환기(HT)를 개발하여 태그와 문서에 대한 의존 관계를 설명하고 입력 문서의 길이를 연장할 수 있도록 한다.병행과 수직 구조를 바탕으로 하는 디코더에 단어와 단락급 다제목 주의를 추가함으로써 제시된 병행과 수직 차원 변환기(PHT & VHT)는 각각 상하문 감지 단어 삽입과 정적 및 동적 단락 삽입을 이용하여 요약을 생성한다.WikiSum에서 종합 평가를 실시하여 PHT와 VHT를 이미 세워진 모델과 비교하고 MDS 작업에서 층구조가 편평한 구조보다 더 전망적인 성능을 제공하는지에 대한 질문에 대답한다.그 결과 평면 구조 모델에 비해 우리의 층별 모델은 크로스 문서 관계를 더욱 잘 포획하여 더욱 높은 품질의 요약을 생성하고 더 많은 메모리 공간을 절약하는 것으로 나타났다.또한 PHT는 더 높은 추리 속도와 더 큰 저장 용량을 가지고 있기 때문에 추천합니다.', 'id': 'Mengenai WikiSum (CITATION) yang memungkinkan eksplorasi aplikatif dari Penapisan Multi-Dokumen Neural (MDS) untuk belajar dari set data skala besar, penelitian ini mengembangkan dua Transformer Hierarkis (HT) yang menjelaskan kedua ketergantuan cross-token dan cross-document, pada saat yang sama memungkinkan panjang panjang dokumen masukan. By incorporating word- and paragraph-level multi-head attentions in the decoder based on the parallel and vertical architectures, the proposed parallel and vertical hierarchical Transformers (PHT &VHT) generate summaries utilizing context-aware word embeddings together with static and dynamics paragraph embeddings, respectively.  Evaluasi komprensif dilakukan di WikiSum untuk membandingkan PHT &VHT dengan model yang ditetapkan dan untuk menjawab pertanyaan apakah struktur hierarkis menawarkan prestasi yang lebih berjanji daripada struktur rata dalam tugas MDS. Hasilnya menunjukkan bahwa model hierarkis kita menghasilkan ringkasan kualitas yang lebih tinggi dengan menangkap lebih baik hubungan saling dokumen, dan menyimpan lebih banyak ruang memori dibandingkan dengan model struktur rata. Selain itu, kami merekomendasikan PHT mengingat nilai praktis kecepatan inferensi yang lebih tinggi dan kapasitas penyimpanan ingatan yang lebih besar.', 'sw': 'Kuhusu WikiSum (CITATION) ambayo inawezesha kutekeleza matumizi ya Ujumbe wa Makala ya Njerumani (MDS) kujifunza kutoka kwenye seti kubwa ya data, utafiti huu unaendelea kuwa na Transformers wawili wa kiutawala (HT) ambao huelezea namna ya kupitia alama na kutumia nyaraka za kuvuka, wakati huo huo huruhusu muda wa mrefu wa nyaraka za input. Kwa kuunganisha maneno- na paragraph yenye kiwango kikubwa katika kodi kwa kutumia miundombinu yanayofanana na yenye msingi, mapendekezo yanatengeneza muhtasari wa mabadiliko ya kimaenzi na wa juu (PHT &VHT) kwa kutumia ujumbe wa maneno yanayofahamika kwa muktadha pamoja na paragraph ya takwimu na dynamics. A comprehensive evaluation is conducted on WikiSum to compare PHT &VHT with established models and to answer the question whether hierarchical structures offer more promising performances than flat structures in the MDS task.  The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models.  Zaidi ya hayo, tunapendekeza PHT kufuatia thamani yake ya uhalisia ya kiwango cha kuongezeka kwa kasi na uwezo wa kuokoa kumbukumbu.', 'fa': 'در مورد ویکیسوم (CITATION) که بر تحقیقات کاربردی از جمع\u200cسازی چند سند عصبی (MDS) توان می\u200cدهد تا از مجموعه داده\u200cهای مقیاس بزرگ یاد بگیرد، این تحقیقات دو تغییر\u200cسازی (HT) را توسعه می\u200cدهد که هر دو بستگی\u200cهای متصل\u200cترکیب و متصل\u200cترکیب سند را توصیف می\u200cکند، در همین زمان طول مدت با توجه به توجه کلمه- و پاراگراف- سطح متعدد سر در dekoder بر اساس معماری متعدد و عمودی، ترجمه\u200cکننده\u200cهای متعدد و متعدد عمودی (PHT &VHT) جمعیت\u200cها را تولید می\u200cکنند که با توجه\u200cهای پاراگراف\u200cهای ثابت و دینامیک\u200cها با استفاده می\u200cکنند. یک ارزیابی کامل در ویکیسوم برای مقایسه PHT &VHT با مدل\u200cهای ساخته شده و برای پاسخ دادن به سؤال این است که آیا ساختارهای دایره\u200cآرایشی عملکرد\u200cهای قول\u200cدهنده\u200cتر از ساختارهای پایین در کار MDS پیشنهاد می\u200cدهند. نتیجه\u200cها پیشنهاد می\u200cدهند که مدل\u200cهای دایره\u200cآفرینی ما با بهتر گرفتن رابطه\u200cهای دایره\u200cسند، جمع\u200cآوری\u200cهای کیفیت بالاتر را تولید می\u200cکند، و فضای حافظه بیشتری را در مقایسه با مدل\u200cهای ساختار پایین ذخیره می به علاوه، ما توصیه می کنیم که PHT با ارزش عملیاتش از سرعت بیماری بالاتر و توانایی ذخیره حافظه بیشتری داشته باشد.', 'af': "Met betrekking tot WikiSum (KYTATION) wat aansoek toepassiende uitsoek van Neural Multi-Document Opsomming (MDS) om uit groot skaal datastel te leer, word hierdie studie twee hierarkies Transformeerders (HT) ontwikkel wat beide die kruistoken en kruisdokument afhanklikhede beskryf, op dieselfde tyd toelaat uitgebreide lengte van invoer dokumente toe. Deur te inkorporeer woord- en paragraaf- vlak multi- hoof aandag in die dekoder gebaseer op die parallele en vertikale arkitektuur, die voorgestelde parallele en vertikale hierarkies Transformeerders (PHT &VHT) genereer opsommings wat gebruik konteks- wees woord inbettings saam met statiese en dinamiese paragraaf inbettings, respektief. 'n Kompleksie evaluasie is gedoen op WikiSum om PHT &VHT te vergelyk met geïnstalleerde modele en om die vraag te antwoord of hierarkies strukture meer beloftende uitvoerings aanbied as plat strukture in die MDS taak. Die resultate stel voorstel dat ons hierarkies modele opsommings van hoër kwaliteit genereer deur beter kruisdokument verhouding te vang en meer geheue spasies stoor in vergelyking met plat-struktuur modele. Ook, ons beveel PHT gegee sy praktiese waarde van hoër inferensie spoed en groter geheue- stoor kapasiteit.", 'tr': "WikiSum (CITATION) ýagdaýynda näyral Çok-Sened Toplaýyşynyň (MDS) uly ölçek veri setirinden öwrenmesine mümkin edýän işlemleri üçin bu arşiw iki iýerarhiýal terjimeleri (HT) gelinýär. Bu arşiw hem çapda-token we çapda-sened baglanyşlaryny tanyýan, hem-de keçersiz sened boýunlaryna mümkin edýär. parallel we dikel arhitektarlaryň daýanýan söz- we paragraf-derejesi multi-kelli dykglaýyşlaryň içine (PHT &VHT) maslahat edilýän parallel we dikel iýerarhiýal terjimeleri (süýşik we bellenen söz integrlerini statik we dinamik paragraf ködlemeleri bilen ullanýarlar. WikiSumda daşary çykyş edildi, PHT &VHT düzümlendirilen nusgalary bilen karşılaştyrmak we soragyna jogap bermek üçin, iýerarhiýalyk strukturalar MDS göreviniň flat strukturalaryndan has söz berýän performanslary üýtgetmekden has baglanýar. Netijenler biziň iýerarhiýa nusgalarymyz çyk-sened baglaşyklaryny gowy ýazmak üçin ýokary kaliwatlygyny döredip, we ýeterlik ýagtylyk nusgalarymyzy flat-struktur modellere görä gaýd etmek üçin ullanyşýar. Üstelik, biz PHT'i ýokary azalyk tizliginiň praktik mykdaryny we hatyra gaýd etmäge rugsat bererdik.", 'hy': "Ինչ վերաբերում է WiKiSum-ին (CITItion), որը հնարավորություն է տալիս նյարդային բազմաթիվ փաստաթղթերի համառոտագրման (MDS) ծրագրային ուսումնասիրություններին սովորել մեծ մասշտաբով տվյալների համակարգում, այս ուսումնասիրությունը զարգանում է երկու հիերարխիկ տրանֆորմերներ (HTML), որոնք նկարագրում են երկու թղթի և երկու փաստաթղթի Օգտագրելով բառերի և պարագծերի մակարդակի բազմագլխավոր ուշադրությունը դեկոդերի մեջ, որը հիմնված է զուգահեռ և ուղղահայաց ճարտարապետությունների վրա, առաջարկված զուգահեռ և ուղղահայաց հիերարխիկ տրանֆորմերները (PHT և VHTML) ստեղծում են համառոտագրություններ, որոնք օգտագործում են կոնտեքստի գիտակցած WiKiSum-ում կատարվում է ընդհանուր գնահատում, որպեսզի համեմատենք PHT-ն և VHTML-ը հաստատված մոդելների հետ և պատասխանենք հարցին, թե արդյոք հիերարխիկ կառուցվածքները ավելի խոստացնող արտադրություններ են տալիս, քան MDS-ի գործում հաստատվ Արդյունքները ցույց են տալիս, որ մեր հիերարխիկ մոդելները ստեղծում են ավելի բարձր որակի համառոտագրություններ' ավելի լավ վերցնելով թղթափաստաթղթերի միջև հարաբերությունները և ավելի շատ հիշողության տարածքներ պահպանելով հարաբերականների մոդելների հետ: Ավելին, մենք խորհուրդ ենք տալիս PHT-ին, հաշվի առնելով իր գործնական արժեքը ավելի բարձր հետևողության արագությունը և ավելի մեծ հիշողության խնայողության ունակությունը:", 'az': "WikiSum (CITATION) barəsində, böyük ölçü verilən qurğudan öyrənmək üçün nöral çox-döküm Toplaşdırma (MDS) təşkil edilən təşkil keşfetmələrinə güclü olan iki hiyerarşik transformatörü (HT) təşkil edir, bu təşkil həmçinin hər ikisini çox-token və çox-döküm bağlılıqlarını təşkil edir. Sözləri - və paragraf-seviyyəti çox-başlıq dikkatini, paralel və vertical arhitektarları üzərində dayanan dekoderdə, təklif edilən paralel və vertical hiyerarşik transformatörlər (PHT &VHT) təklif edilən təklif-bildirilmiş sözləri birlikdə statik və dinamik paragrafı içərisində istifadə edirlər. WikiSum'da, PHT &VHT'i qurulmuş modellərlə qarşılaşdırmaq üçün, hiyerarşik strukturları MDS işində daha çox vəd verici performanslar təklif edir və yoxdur. Sonuçlarımız hiyerarşik modellərimizin yüksək keyfiyyətinin istifadələrini daha yaxşı döküm əlaqələrini alıb, daha çox hafıza alanlarını düz struktur modellərinə qarşılaşdırmaq üçün qoruyub saxlayır. Daha sonra, PHT'nin praktik qiymətini yüksək infeksiya sürəti və daha böyük hafıza qurtarma kapasitəsini təsdiq edirik.", 'bs': 'S obzirom na WikiSum (CITATION) koji omogućava aplikacijske istraživanja Neuralne multidokumentacije (MDS) da nauče iz velike skupine podataka, ova istraživanja razvija dva hijerarhičkog transformera (HT) koji opisuju i krstotokene i krstodokumenata zavisnosti, istovremeno omogućavaju produženu dužinu ulaznih dokumenta. Uključujući višeglavnu pozornost riječi i nivoa paragrafa na dekoderu na temelju paralelnih i vertikalnih arhitektura, predloženi paralelni i vertikalni hijerarhički transformatori (PHT &VHT) stvaraju sažetke koji koriste uključujuće kontekstski svesne riječi zajedno s stavnim i dinamičkim stavljanjem paragrafa. Svobuhvatna procjena je provedena na WikiSumu kako bi usporedila PHT &VHT sa utvrđenim modelima i odgovorila na pitanje da li hijerarhijske strukture nude obećavajuće učinke nego ravne strukture u zadatku MDS-a. Rezultati ukazuju na to da naše hijerarhijske modele generiraju sažetke višeg kvaliteta boljim uhvaćenjem odnosa preko dokumenta i spašavaju više mjesta pamćenja u usporedbi s modelima ravne strukture. Preporučujemo PHT s obzirom na praktičnu vrijednost veće brzine infekcije i veće kapacitete spašavanja pamćenja.', 'am': 'With regards to WikiSum (CITATION) that empowers applicative explorations of Neural Multi-Document Summarization (MDS) to learn from large scale dataset, this study develops two hierarchical Transformers (HT) that describe both the cross-token and cross-document dependencies, at the same time allow extended length of input documents.  በአካባቢ እና የክፍለ አካባቢ እና የክፍለ አካባቢ መሠረቶች በመጠቀም ቃላት- እና paragraph-ደረጃ የብዙ ራስ ስብሰባዎች በመጠቀም በተፈጻሙ ተቃውሞ እና የክፍተት አዳራቢ መተላለፊያዎች (PHT &VHT) በተለየ ስህተት እና የdynamics paragraph በመጠቀም የሚታወቅ ቃላት ማጠቃለያዎች አቀማመጥ፡፡ በWikiSum ውስጥ PHT &VHT እና በተመሠረቱት ሞዴላዎችን ለማስተካከል ውጤት ይደረጋል፡፡ ፍሬቶቹ የሐራርተርክ ዓይነቶቻችን የክፍለ ሥርዓት ግንኙነትን በመቀበል እና የክፍለ ሰነድ ግንኙነቶችን በመያዝ የሚሻል ማሳየት እና የመስታሰቢያ ቦታዎችን በመስመር ማሳየት ይችላል፡፡ ደግሞም PHT የፍጥረት ፍጥረት እና የማስታወሻ ማዳን ችሎታዋን ለመስጠት እንመክራለን፡፡', 'sq': 'Në lidhje me WikiSum (CITATION) që mundëson eksplorimet aplikative të Somarizimit Neural Multi-Document (MDS) për të mësuar nga grupi i të dhënave në shkallë të madhe, ky studim zhvillon dy Transformuesit hierarkikë (HT) që përshkruajnë si varësitë kryqëzimi ashtu dhe të dokumenteve, në të njëjtën kohë lejojnë gjatësinë e zgjeruar të dokumenteve të hyrjes. By incorporating word- and paragraph-level multi-head attentions in the decoder based on the parallel and vertical architectures, the proposed parallel and vertical hierarchical Transformers (PHT &VHT) generate summaries utilizing context-aware word embeddings together with static and dynamics paragraph embeddings, respectively.  Një vlerësim tërësor është kryer në WikiSum për të krahasuar PHT &VHT me modele të vendosur dhe për të përgjigjur pyetjes në se strukturat hierarkike ofrojnë performanca më të premtueshme se strukturat e rrafshta në detyrën MDS. Rezultatet sugjerojnë se modelet tona hierarkike gjenerojnë përmbledhje të cilësisë më të lartë duke kapur më mirë marrëdhëniet ndërdokumentore dhe duke ruajtur më shumë hapësira kujtese në krahasim me modelet e strukturës së rrafshtë. Përveç kësaj, ne rekomandojmë PHT duke marrë parasysh vlerën e saj praktike të shpejtësisë së inferencës më të lartë dhe kapacitetit më të madh të ruajtjes së kujtesës.', 'et': 'Seoses WikiSumiga (CITATION), mis võimaldab neuroaalse mitme dokumendi kokkuvõtte (MDS) rakenduslikke uuringuid õppida suuremahulistest andmekogumitest, arendatakse käesolevas uuringus välja kaks hierarhilist transformaatorit (HT), mis kirjeldavad nii ristmärkide kui ka ristdokumentide sõltuvust, samal ajal võimaldavad sisenddokumentide pikendatud pikkust. Paralleelsetel ja vertikaalsetel arhitektuuridel põhineva sõna- ja lõiketasandi mitmepealise tähelepanu lisades dekoodrisse, loovad väljapakutud paralleelsed ja vertikaalsed hierarhilised transformaatorid (PHT &VHT) kokkuvõtted, kasutades kontekstiteadlikke sõnade põimimisi koos staatiliste ja dünaamiliste lõikude põimimisega vastavalt. WikiSumis viiakse läbi põhjalik hindamine, et võrrelda PHT ja VHT väljakujunenud mudelitega ning vastata küsimusele, kas hierarhilised struktuurid pakuvad MDS ülesandes paljutõotavamaid tulemusi kui tasased struktuurid. Tulemused näitavad, et meie hierarhilised mudelid loovad kvaliteetsemaid kokkuvõtteid, jäädvustades paremini dokumentidevahelisi seoseid ja säästes rohkem mäluruumi võrreldes lameda struktuuriga mudelitega. Lisaks soovitame PHT-d, kuna selle praktiline väärtus on suurem järelduskiirus ja suurem mälu säästmine.', 'bn': 'উইকিসাম (সিটাটিশন) সম্পর্কে যে নেউরাল মাল্টি ডকুমেন্ট সামার্জারেশন (এমডিএস) এর প্রয়োজনীয় বিস্ফোরণের ক্ষমতা প্রদান করে বিশাল স্ক্যালের ডাটাসেট থেকে শিখতে পারে, এই গবেষণা দুটি হিয়ারেক্যাল ট্রান্সফ প্রস্তাবিত প্যারালেল এবং উল্লেখযোগ্য স্থাপত্যের উপর ভিত্তিতে ডেকোডারে শব্দ- এবং প্যারাফেক্ট- স্তরের মাধ্যমে অন্তর্ভুক্ত মনোযোগ আকর্ষণের মাধ্যমে প্রস্তাবিত প্যারালেল এবং উল্লেখযোগ্য হায়েরা পিএইচটি &ভিএইচটি’র সাথে স্থাপন করা মডেলের তুলনা করার জন্য উইকিসুমে একটি সম্পূর্ণ মূল্য চালানো হয়েছে এবং প্রশ্নের উত্তর দেওয়া হয় এমডিএস কাজের ফ্ল্যাট কাঠামো ফলাফল পরামর্শ প্রদান করে যে আমাদের হিরেরার্কিক মডেলগুলো বেশী মানের সারিগুলো তৈরি করে ক্রস-নথির সম্পর্কের সাথে আরো ভালো স্মৃতি সংরক্ষণ করে ফ্ল এছাড়াও আমরা পিএইচটির প্রাকৃতিক মূল্য প্রদান করি যে তার ব্যাপারে দুর্ভোগের গতি এবং স্মৃতি সংরক্ষণের ক্ষমতা বেশ', 'ca': "With regards to WikiSum (CITATION) that empowers applicative explorations of Neural Multi-Document Summarization (MDS) to learn from large scale dataset, this study develops two hierarchical Transformers (HT) that describe both the cross-token and cross-document dependencies, at the same time allow extended length of input documents.  By incorporating word- and paragraph-level multi-head attentions in the decoder based on the parallel and vertical architectures, the proposed parallel and vertical hierarchical Transformers (PHT &VHT) generate summaries utilizing context-aware word embeddings together with static and dynamics paragraph embeddings, respectively.  A comprehensive evaluation is conducted on WikiSum to compare PHT &VHT with established models and to answer the question whether hierarchical structures offer more promising performances than flat structures in the MDS task.  Els resultats suggereixen que els nostres models jeràrquics generen resumes de millor qualitat capturant millor relacions entre documents i estalviant més espais de memòria en comparació amb models d'estructura plana. A més, recomanem que PHT tingui el seu valor pràctic de més velocitat de inferència i més capacitat d'estalvi de memòria.", 'cs': 'S ohledem na WikiSum (CITATION), který umožňuje aplikační průzkum neuronové multidokumentové shrnutí (MDS) učit se z velkého množství dat, tato studie vyvíjí dva hierarchické transformátory (HT), které popisují jak cross-token, tak cross-dokument závislosti, zároveň umožňují delší délku vstupních dokumentů. Navržené paralelní a vertikální hierarchické transformátory (PHT &VHT) generují souhrny využívající kontextové vložení slov spolu se statickými a dynamickými vloženími odstavců. Na WikiSumu je provedeno komplexní vyhodnocení, aby bylo možné porovnat PHT &VHT se zavedenými modely a zodpovědět otázku, zda hierarchické struktury nabízejí slibnější výkony než ploché struktury v MDS úkolu. Výsledky naznačují, že naše hierarchické modely vytvářejí souhrny vyšší kvality díky lepšímu zachycení vztahů mezi dokumenty a šetří více paměťového prostoru ve srovnání s modely ploché struktury. Navíc doporučujeme PHT vzhledem k praktické hodnotě vyšší rychlosti inference a větší kapacity úspory paměti.', 'fi': 'Mitä tulee WikiSumiin (CITATION), joka mahdollistaa hermojen monidokumenttien yhteenvedon (MDS) applicative explorations of Neural Multi-Document Summarization, tässä tutkimuksessa kehitetään kaksi hierarkkista muuntajaa (HT), jotka kuvaavat sekä merkkien että dokumenttien välisiä riippuvuuksia ja mahdollistavat samalla syöttöasiakirjojen pidemmän pituuden. Yhdistämällä dekooderiin sana- ja kappaletason monipäiset huomiot rinnakkais- ja pystysuuntaisiin arkkitehtuureihin, ehdotetut rinnakkais- ja pystysuuntaiset hierarkkiset muuntajat (PHT &VHT) tuottavat tiivistelmiä käyttäen kontekstitietoisia sanaupotuksia sekä staattisia ja dynaamisia kappaleiden upotuksia. WikiSumissa tehdään kattava arviointi, jossa verrataan PHT &VHT:tä vakiintuneisiin malleihin ja vastataan kysymykseen, tarjoavatko hierarkiset rakenteet MDS-tehtävässä lupaavampaa suorituskykyä kuin litteät rakenteet. Tulokset viittaavat siihen, että hierarkkiset mallit tuottavat laadukkaampia yhteenvedoita tallentamalla dokumenttien välisiä suhteita paremmin ja säästävät enemmän muistitilaa verrattuna litteärakenteisiin malleihin. Lisäksi suosittelemme PHT:tä, koska sen käytännön arvo on suurempi päättelynopeus ja suurempi muistinsäästökapasiteetti.', 'ha': "Ina amfani da WikiSum (CITATItion) wanda yake iya amfani da masu shiryarwa na masu ƙaranci na takardar Kwamfyuta na Neural Muda-Document Summarization (MDS) zuwa a sanar da shi daga tsarin mai girma, wannan littafin yana ƙarfafa biyu hiirarchical Transformers (HT) wanda ke bayyana both the korn-tagon da kuma yana dõgara ga rubutun-takardar-kore, sami da kuma a sami wannan lokacin na yarda da tsawo tsawo takardun ayuka masu shiga. Ina shigar da saurin- da-daraja masu nau'i masu cikin kodi a kan fanel da matsayin masu tsaye, da aka buƙata masu parallel da kuma masu tsayi, za'a ƙididdige fassarar da masu hijarari a tsaye (PHT & vHT) mai amfani da maganar-da-fahimta masu fahimta sami da kuma rubutun na tabar da za'a fito. An samar da kimar ta jumla a WikiSum don ya sami PHT & vHT da shiryoyin da aka tabbatar da shi kuma ya jiba tambayi, shin tsarin hierorchical masu nuna mafiya yi wa'adi ko da tsari masu yi wa'adi da su fi girma cikin aikin MDS. Mataimakin na shawara cewa misalinmu na hiera zata ƙari masu tsari da baƙata tsari mafi kyauta a samu'in ka sami tsari-takardar-takardar, kuma ka tsare filayenai masu ƙaranci da sami da misãlai-mai flat. Kayya, Munã shawarar da PHT ya cika kimar gaskiyar kashi na kasar kashi da awon adana kumbar.", 'sk': 'V zvezi z WikiSumom (CITATION), ki omogoča aplikativne raziskave nevralnega večdokumentskega povzetka (MDS), da se učijo iz obsežnega nabora podatkov, ta študija razvija dva hierarhična transformatorja (HT), ki opisujeta tako odvisnost navzkrižnih žetonov kot navzkrižnih dokumentov, hkrati pa omogočata podaljšano dolžino vhodnih dokumentov. Predlagani vzporedni in vertikalni hierarhični transformatorji (PHT &VHT) z vključitvijo večglavnih pozornosti na ravni besed in odstavkov v dekoder, ki temelji na vzporedni in vertikalni arhitekturi, ustvarjajo povzetke z uporabo kontekstnega ozaveščanja besed skupaj s statičnim in dinamičnim vključevanjem odstavkov. Na WikiSumu smo izvedli celovito oceno, da bi primerjali PHT &VHT z uveljavljenimi modeli in odgovorili na vprašanje, ali hierarhične strukture ponujajo bolj obetavno delovanje kot ravne strukture v nalogi MDS. Rezultati kažejo, da naši hierarhični modeli ustvarjajo povzetke višje kakovosti z boljšim zajemanjem meddokumentnih relacij in prihranijo več pomnilniških prostorov v primerjavi z modeli ravne strukture. Poleg tega priporočamo PHT glede na njegovo praktično vrednost višje hitrosti sklepanja in večje zmogljivosti varčevanja s pomnilnikom.', 'he': 'בנוגע לוויקיסום (CITATION) שמאפשר לחקור אפליקטיבי של סאמריזציה נוירולית של מסמכים רבים (MDS) ללמוד ממערכת נתונים בקנה מידה גדולה, המחקר הזה מפתח שני טרנספורמטרים הייררכיים (HT) שמתארים את תלויות הצלב-סימנים וגם הצלב-מסמכים, באותו הזמן מאפשרים אורך ארוך של מסמכים הכניסה. By incorporating word- and paragraph-level multi-head attentions in the decoder based on the parallel and vertical architectures, the proposed parallel and vertical hierarchical Transformers (PHT &VHT) generate summaries utilizing context-aware word embeddings together with static and dynamics paragraph embeddings, respectively.  הערכה מורכבת נעשת על WikiSum כדי להשוות PHT &VHT עם דוגמנים קבועים ולענות על השאלה אם מבנים הייררכיים מציעים ביצועים מבטים מבטים שווים במשימה MDS. התוצאות מציעות שהדוגמנים היררכיים שלנו יוצרים סדרות של איכות גבוהה יותר על ידי תפיסה טובה יותר מערכות יחסים בין מסמכים, ולחסוך יותר מקומות זיכרון בהשוואה לדוגמנים במבנה שווה. חוץ מזה, אנחנו ממליצים PHT בהתחשב בערך המרשמי שלו של מהירות ההנחה גבוהה יותר ויכולת חיסוך זכרון גדולה יותר.', 'jv': 'Attribute Coverage Sayensi Rejalingan suggeruju di nambah akeh model kita jejer-nambah sing luwih dumateng kapan karo nggawe barang langgar-tokkum ngono nggawe barang langgar-sistem sing luwih dumateng politenessoffpolite"), and when there is a change ("assertivepoliteness', 'bo': 'With regards to WikiSum (CITATION) that empowers applicative explorations of Neural Multi-Document Summarization (MDS) to learn from large scale dataset, this study develops two hierarchical Transformers (HT) that describe both the cross-token and cross-document dependencies, at the same time allow extended length of input documents. By incorporating word- and paragraph-level multi-head attentions in the decoder based on the parallel and vertical architectures, the proposed parallel and vertical hierarchical Transformers (PHT &VHT) generate summaries utilizing context-aware word embeddings together with static and dynamics paragraph embeddings, respectively. A comprehensive evaluation is conducted on WikiSum to compare PHT &VHT with established models and to answer the question whether hierarchical structures offer more promising performances than flat structures in the MDS task. The results suggest that our hierarchical models generate summaries of higher quality by better capturing cross-document relationships, and save more memory spaces in comparison to flat-structure models. འོན་ཀྱང་། ང་ཚོས་PHT དེ་གིས་རང་ཉིད་ཀྱི་གནོད་ཐང་སྙིང་ཚད་མཐོ་ཤོས་དང་དྲན་སྒྲིག'}
