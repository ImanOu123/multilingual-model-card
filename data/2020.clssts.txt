{'en': 'SEARCHER : Shared Embedding Architecture for Effective Retrieval', 'pt': 'SEARCHER: Arquitetura de Incorporação Compartilhada para Recuperação Eficaz', 'ar': 'SEARCHER: هندسة التضمين المشتركة من أجل الاسترداد الفعال', 'es': 'BUSCADOR: Arquitectura de incrustación compartida para una recuperación eficaz', 'fr': "SEARCHER\xa0: Architecture d'intégration partagée pour une récupération efficace", 'zh': '搜索器:共嵌体系结构', 'ja': '検索ツール:効果的な検索のための共有埋め込みアーキテクチャ', 'hi': 'खोजकर्ता: प्रभावी पुनर्प्राप्ति के लिए साझा एम्बेडिंग आर्किटेक्चर', 'ru': 'ПОИСК: Общая архитектура встраивания для эффективного извлечения', 'ga': 'SEARCHER: Ailtireacht Leabú Comhroinnte le hAghaidh Aisghabhála Éifeachtach', 'el': 'ΑΝΑΖΗΤΗΣΗΣ: Κοινή αρχιτεκτονική ενσωμάτωσης για αποτελεσματική ανάκτηση', 'hu': 'Keresés: Megosztott beágyazási architektúra a hatékony visszaszerezés érdekében', 'ka': 'Constellation name (optional)', 'it': 'SEARCHER: architettura di embedding condivisa per un recupero efficace', 'kk': 'САРКАТЫ: Эффективті алу үшін ортақтастырылған ендіру архитектурасы', 'mk': 'SEARCHER: Shared Embedding Architecture for Effective Retrieval', 'ms': 'Constellation name (optional)', 'ml': 'സെയാര്\u200dച്ചര്\u200d: സാക്ഷ്യമായ വീണ്ടെടുക്കുന്നതിനായി പങ്കുചേര്\u200dത്ത എംബെഡിങ്ങ് ആര്\u200dക്ടിക്കറ്റ', 'mt': 'SEARCHER: arkitettura inkorporata kondiviża għall-kisba effettiva', 'mn': 'ШАБЛАГАН: Эффектив авах үед хуваалцагдаг бүтээгдэхүүний архитектур', 'no': 'Constellation name (optional)', 'pl': 'SEARCHER: Wspólna architektura osadzania dla skutecznego odzyskiwania', 'ro': 'CĂUTARE: Arhitectură partajată de încorporare pentru recuperarea eficientă', 'sr': 'Оделена архитектура за ефективно получене', 'si': 'පරීක්ෂක: ප්\u200dරභාවිත පිළිගන්න සඳහා සම්බන්ධ සංවිධානය', 'lt': 'Bendra įdiegta veiksmingo gavimo architektūra', 'so': 'SEARCHER: Shared Embedding Architecture for Effective Retrieval', 'sv': 'SÖKER: Delad inbäddningsarkitektur för effektiv hämtning', 'ta': 'SEARCHER: விளைவான திரும்பப்பெறுவதற்கான பகிர்ந்த உட்பொதித் திட்டம்', 'ur': 'جشنگر: فعالی اٹھانے کے لئے شریک ایمبڈینگ آرکیٹر', 'vi': 'Tìm kiếm: Kiến trúc chung để lấy lại hiệu quả', 'uz': 'SEARCHER: Effektiv tiklash uchun boʻlishilgan embedded architecture', 'bg': 'ТАРЧЕР: Споделена архитектура за вграждане за ефективно извличане', 'hr': 'SEČARČE: Dijeljena arhitektura za uključenje učinkovitog primanja', 'da': 'Søger: Delt indlejringsarkitektur for effektiv hentning', 'nl': 'SEARCHER: Gedeelde Embedding Architecture voor effectieve Retrieval', 'fa': 'ساختار داخلی برای بازیابی تاثیر', 'id': 'Pencari: Shared Embedding Architecture for Effective Retrieval', 'ko': 'SEARCHER: 효과적인 검색을 위한 공유 내장 구조', 'de': 'SEARCHER: Gemeinsame Einbettungsarchitektur für effektives Abrufen', 'sw': 'SEARCHER: Udhibiti wa makazi yanayoshirikishwa kwa ajili ya kurejeshwa kwa ufanisi', 'af': 'Constellation name (optional)', 'tr': 'DELABOşy: Efektiv Mazmunlar üçin Bölünmek Arhitektura', 'sq': 'Arkitektura e përbashkët e përfshirjes për marrje efektive', 'am': 'ምርጫዎች', 'az': 'SEARCHOR: Efektiv almaq üçün paylaşılmış Bölünmə Arhitektura', 'bn': 'সেয়ার্চার: কার্যকর পুনরুদ্ধারের জন্য বেডিং আর্কিচেক্ট শেয়ার করা হয়েছে', 'hy': 'Ավելի արդյունավետ վերադարձման համար ընդգրկված արխիկտուր', 'bs': 'Podijeljena arhitektura za učinkovito uzdržavanje', 'ca': 'ARCÍTEL: Arquitectura integrada compartida per a obtenir efectivament', 'cs': 'SEARCHER: Sdílená architektura vložení pro efektivní vyhledávání', 'et': 'SEARCHER: Jagatud manustamise arhitektuur tõhusaks taastamiseks', 'fi': 'SEARCHER: Jaettu upotusarkkitehtuuri tehokkaaseen noutoon', 'ha': 'KCharselect unicode block name', 'jv': 'architecture', 'he': 'מחפש: ארכיטקטורה משותפת להשיגה אפקטיבית', 'sk': 'SEARCHER: Skupna arhitektura vdelave za učinkovito pridobivanje', 'bo': 'SEARCHER: Shared Embedding Architecture for Effective Retrieval'}
{'en': 'We describe an approach to cross lingual information retrieval that does not rely on explicit translation of either document or query terms. Instead, both queries and documents are mapped into a shared embedding space where retrieval is performed. We discuss potential advantages of the approach in handling polysemy and synonymy. We present a method for training the model, and give details of the model implementation. We present experimental results for two cases : Somali-English and Bulgarian-English CLIR.', 'ar': 'نحن نصف نهجًا لاسترجاع المعلومات اللغوية المتقاطعة لا يعتمد على الترجمة الصريحة لأي من مصطلحات المستند أو الاستعلام. بدلاً من ذلك ، يتم تعيين كل من الاستعلامات والمستندات في مساحة تضمين مشتركة حيث يتم إجراء الاسترداد. نناقش المزايا المحتملة للنهج في التعامل مع تعدد المعاني والمرادفات. نقدم طريقة لتدريب النموذج ، ونعطي تفاصيل عن تنفيذ النموذج. نقدم نتائج تجريبية لحالتين: الصومالية-الإنجليزية والبلغارية-الإنجليزية CLIR.', 'pt': 'Descrevemos uma abordagem para recuperação de informações em vários idiomas que não depende da tradução explícita de documentos ou termos de consulta. Em vez disso, as consultas e os documentos são mapeados em um espaço de incorporação compartilhado onde a recuperação é executada. Discutimos as vantagens potenciais da abordagem no tratamento de polissemia e sinonímia. Apresentamos um método para treinar o modelo e detalhamos a implementação do modelo. Apresentamos resultados experimentais para dois casos: CLIR somali-inglês e búlgaro-inglês.', 'es': 'Describimos un enfoque para la recuperación de información en varios idiomas que no se basa en la traducción explícita de los términos del documento o de la consulta. En cambio, tanto las consultas como los documentos se asignan a un espacio de incrustación compartido donde se realiza la recuperación. Discutimos las posibles ventajas del enfoque en el manejo de la polisemia y la sinonimia. Presentamos un método para entrenar el modelo y damos detalles de la implementación del modelo. Presentamos los resultados experimentales de dos casos: CLIR somalí-inglés y búlgaro-inglés.', 'fr': "Nous décrivons une approche de récupération d'informations multilingues qui ne repose pas sur la traduction explicite des termes du document ou de la requête. Au lieu de cela, les requêtes et les documents sont mappés dans un espace d'intégration partagé où la récupération est effectuée. Nous discutons des avantages potentiels de cette approche dans la gestion de la polysémie et de la synonymie. Nous présentons une méthode de formation du modèle et donnons des détails sur la mise en œuvre du modèle. Nous présentons des résultats expérimentaux pour deux cas\xa0: CLIR somali-anglais et bulgare-anglais.", 'ja': '私たちは、文書またはクエリ用語のいずれかの明示的な翻訳に依存しない、言語間情報検索のアプローチを説明します。代わりに、クエリとドキュメントの両方が、取得が実行される共有埋め込みスペースにマッピングされます。多義性と同義語を扱う際のアプローチの潜在的な利点について考察します。モデルをトレーニングする方法を提示し、モデルの実装の詳細を説明します。ソマリ-英語とブルガリア-英語のCLIRの2つのケースの実験結果を提示します。', 'zh': '述跨语信息检索法,不依文档询显式译。 询与文档俱映行检者共嵌空中。 论其方多义性与同义词之善势。 吾为之教模之法,而与之细节。 二病例之实验:索马里语-英语、保加利亚语-英语CLIR。', 'hi': 'हम पार भाषाई जानकारी पुनर्प्राप्ति के लिए एक दृष्टिकोण का वर्णन करते हैं जो या तो दस्तावेज़ या क्वेरी शर्तों के स्पष्ट अनुवाद पर भरोसा नहीं करता है। इसके बजाय, क्वेरीज़ और दस्तावेज़ दोनों को एक साझा एम्बेडिंग स्थान में मैप किया जाता है जहाँ पुनर्प्राप्ति की जाती है। हम polysemy और पर्यायवाची से निपटने में दृष्टिकोण के संभावित लाभों पर चर्चा करते हैं। हम मॉडल को प्रशिक्षित करने के लिए एक विधि प्रस्तुत करते हैं, और मॉडल कार्यान्वयन का विवरण देते हैं। हम दो मामलों के लिए प्रयोगात्मक परिणाम प्रस्तुत करते हैं: सोमाली-अंग्रेजी और बल्गेरियाई-अंग्रेजी सीएलआईआर।', 'ru': 'Мы описываем подход к перекрестному извлечению языковой информации, который не основывается на явном переводе терминов документа или запроса. Вместо этого как запросы, так и документы отображаются в общем пространстве вложений, где выполняется извлечение. Мы обсуждаем потенциальные преимущества подхода в обращении с полисемией и синонимией. Представляем методику обучения модели, приводим подробности реализации модели. Мы представляем экспериментальные результаты для двух случаев: сомалийско-английский и болгарско-английский CLIR.', 'ga': 'Déanaimid cur síos ar chur chuige maidir le haisghabháil faisnéise trasteangacha nach bhfuil ag brath ar aistriúchán follasach ar théarmaí doiciméad nó ceiste. Ina áit sin, déantar ceisteanna agus doiciméid a mhapáil isteach i spás leabaithe roinnte ina ndéantar iad a aisghabháil. Pléimid buntáistí féideartha an chur chuige maidir le láimhseáil polysemy agus comhchiall. Cuirimid modh i láthair chun an tsamhail a oiliúint, agus tugaimid sonraí ar fheidhmiú an mhúnla. Cuirimid torthaí turgnamhacha i láthair do dhá chás: Somáilis-Béarla agus Bulgáiris-Béarla CLIR.', 'el': 'Περιγράφουμε μια προσέγγιση για την ανάκτηση πληροφοριών που δεν βασίζεται στη ρητή μετάφραση είτε των όρων εγγράφου είτε ερωτήματος. Αντίθετα, τόσο τα ερωτήματα όσο και τα έγγραφα αντιστοιχίζονται σε έναν κοινόχρηστο χώρο ενσωμάτωσης όπου πραγματοποιείται ανάκτηση. Συζητούμε τα πιθανά πλεονεκτήματα της προσέγγισης στον χειρισμό της πολυσεμίας και της συνώνυμης. Παρουσιάζουμε μια μέθοδο για την εκπαίδευση του μοντέλου και δίνουμε λεπτομέρειες για την εφαρμογή του μοντέλου. Παρουσιάζουμε πειραματικά αποτελέσματα για δύο περιπτώσεις: Σομαλ-Αγγλικά και Βουλγαρ-Αγγλικά CLIR.', 'hu': 'Olyan megközelítést írunk le, amely nem támaszkodik sem dokumentum, sem lekérdezés kifejezéseinek kifejezett fordítására. Ehelyett mind a lekérdezések, mind a dokumentumok lekérdezése egy megosztott beágyazási területbe kerül, ahol a visszakeresés végrehajtásra kerül. Beszéljük a megközelítés lehetséges előnyeit a poliszémia és a szinonimák kezelésében. Bemutatjuk a modell képzésének módszerét, és részletesen bemutatjuk a modell megvalósítását. Két kísérleti eredményt mutatunk be: szomáliai-angol és bolgár-angol CLIR.', 'ka': 'ჩვენ განახსენებთ ენგუმენტის ინფორმაციის გაკვირთვის პროგრამა, რომელიც არ განახსენებულია კოკუმენტის ან კითხვის სიტყვების გაკვირთვის. მაშინ, ორივე კითხვები და დოკუმენტები იქნება საზოგადოებულ დამატებული სივრცეში, სადაც მიიღება მოქმედება. ჩვენ განსაკუთრებით პოლისემის და სინონიმის პოლისემის შესაძლებლობა. ჩვენ მოდელის შემწყვებას მეტი და მოდელის შემწყვებას დეტალები. ჩვენ ექსპერიმენტიური წარმოდგენება ორი შემთხვევაში: Somali-English და Bulgarian-English CLIR.', 'it': "Descriviamo un approccio al recupero di informazioni multilingue che non si basa sulla traduzione esplicita di termini di documento o query. Invece, sia le query che i documenti vengono mappati in uno spazio di incorporazione condiviso in cui viene eseguito il recupero. Discutiamo i potenziali vantaggi dell'approccio nella gestione della polisemia e della sinonimia. Presentiamo un metodo per formare il modello e diamo dettagli sull'implementazione del modello. Presentiamo i risultati sperimentali per due casi: somalo-inglese e bulgaro-inglese CLIR.", 'kk': 'Біз тілді мәліметті алу арқылы құжат не сұраныс терминлердің түсінікті аудармасына тәуелді таңдаймыз. Осының орнына, сұраныс мен құжаттардың екеуі жалғастырылған ендіру орынға карталады. Біз полиземияны және синонимияны қамтамасыз ету үшін қолдануға мүмкіндік артықшылықтарды талқылаймыз. Біз үлгі оқыту әдісін келтіріп, үлгі іске асыру үшін егжей- тегжейін береміз. Екі жағдай туралы эксперименталдық нәтижелерін таңдаймыз: Сомали-ағылшын және Болгария-ағылшын CLIR.', 'lt': 'Mes apibūdiname požiūrį į tarpkalbinę informacijos gavimą, kuris nesiremia aiškiu nei dokumentų, nei klausimo terminų vertimu. Vietoj to, tiek klausimai, tiek dokumentai yra mapuojami į bendrą įterpimo erdvę, kurioje atliekamas paieškas. Mes aptariame galimus požiūrio pranašumus, susijusius su polisemija ir sinonimija. Pateikiame modelio mokymo metodą ir išsamiai aprašome modelio įgyvendinimą. Pateikiame eksperimentinius rezultatus dviem atvejais: Somalio-anglų ir Bulgarijos-anglų CLIR.', 'mk': 'Ние опишуваме пристап до крстојачното преземање на информации кои не се потпираат на експлицитно преведување на документите или термините на прашањето. Наместо тоа, и прашањата и документите се мапирани во заеднички вставен простор каде што се извршува преземањето. Разговараме за потенцијалните предности на пристапот во справувањето со полисимијата и синонимијата. Презентираме метод за обука на моделот и даваме детали за имплементацијата на моделот. Презентираме експериментални резултати за два случаи: Сомалско-англиски и бугарско-англиски КЛИР.', 'ms': 'Kami menggambarkan pendekatan untuk mengambil maklumat bahasa salib yang tidak bergantung pada terjemahan eksplicit sama ada dokumen atau terma pertanyaan. Instead, both queries and documents are mapped into a shared embedding space where retrieval is performed.  Kami membincangkan keuntungan potensi pendekatan dalam mengendalikan polisemi dan sinonimi. Kami memperkenalkan kaedah untuk melatih model, dan memberikan perincian pelaksanaan model. Kami memperkenalkan hasil percubaan untuk dua kes: Somali-Inggeris dan Bulgarian-Inggeris CLIR.', 'ml': 'ഭാഷ വിവരങ്ങളുടെ വിവരങ്ങള്\u200d വീണ്ടെടുക്കാനുള്ള ഒരു വഴിയെക്കുറിച്ച് ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. അത് പ്രത്യക്ഷമായ ഒരു ര പകരം ചോദ്യങ്ങളും രേഖകളും പങ്കുചേര്\u200dക്കുന്ന സ്ഥലത്തേക്ക് മാപ്പ് ചെയ്യപ്പെടുന്നു പോളിസിമിയെയും സിനോണിയെയും കൈകാര്യം ചെയ്യുന്നതില്\u200d നമ്മള്\u200d സാധ്യതകള്\u200dക്കുള്ള ഉപകാരങ്ങള്\u200d സംസാര മോഡലിനെ പരിശീലിപ്പിക്കാനുള്ള ഒരു രീതിയില്\u200d ഞങ്ങള്\u200d കൊണ്ടുവന്നിട്ടുണ്ട്, മോഡല്\u200d പ്രവര്\u200dത്തിപ്പി രണ്ടു കേസുകള്\u200dക്കുള്ള പരീക്ഷണ ഫലങ്ങള്\u200d ഞങ്ങള്\u200d കാണിച്ചുകൊടുക്കുന്നു', 'mt': 'We describe an approach to cross lingual information retrieval that does not rely on explicit translation of either document or query terms.  Minflok, iż-żewġ mistoqsijiet u d-dokumenti huma mmappjati fi spazju ta’ inkorporazzjoni kondiviż fejn isir l-irkupru. Aħna niddiskutu l-vantaġġi potenzjali tal-approċċ fl-immaniġġjar tal-polisimja u s-sinonimja. We present a method for training the model, and give details of the model implementation.  Aħna nippreżentaw riżultati sperimentali għal żewġ każijiet: Somali-Ingliż u Bulgari-Ingliż CLIR.', 'no': 'Vi beskriver ein tilnærming til å henta kryss språk- informasjon som ikkje kjem på eksplisitt omsetjing av anten dokument eller spørjingstemmer. I staden blir både spørjingar og dokument kopla inn i eit delt innbyggingsplass der henting vert utført. Vi diskuterer potensielle fordeler av tilnærminga i handling av polysemet og synonym. Vi presenterer ein metode for å lære modellen og gi detaljar om implementasjonen av modellen. Vi presenterer eksperimentelle resultat for to tilfeller: Somali-engelsk og bulgarsk-engelsk CLIR.', 'ro': 'Descriem o abordare a extragerii informațiilor între limbi care nu se bazează pe traducerea explicită a termenilor documentului sau interogării. În schimb, atât interogările, cât și documentele sunt mapate într-un spațiu partajat de încorporare unde se efectuează recuperarea. Discutăm potențialele avantaje ale abordării în manipularea polisemiei și sinonimiei. Prezentăm o metodă de instruire a modelului și oferim detalii privind implementarea modelului. Prezentăm rezultate experimentale pentru două cazuri: somalez-englez și bulgar-englez CLIR.', 'pl': 'Opisujemy podejście do pozyskiwania informacji wielojęzycznych, które nie opiera się na wyraźnym tłumaczeniu ani dokumentu, ani terminów zapytania. Zamiast tego zarówno zapytania, jak i dokumenty są mapowane do wspólnej przestrzeni osadzania, w której wykonywane jest pobieranie. Omówimy potencjalne zalety tego podejścia w obsłudze polisemii i synonii. Przedstawiamy metodę szkolenia modelu oraz podajemy szczegóły wdrożenia modelu. Przedstawiamy wyniki eksperymentalne dla dwóch przypadków: somalijsko-angielskiego i bułgarsko-angielskiego CLIR.', 'mn': 'Бид хэлний мэдээллийг олох аргыг тайлбарлаж өгдөг. Энэ нь баримт эсвэл query томъёогоор тодорхойлж чадахгүй. Үүний оронд, квери болон баримтууд хоёуланг авч авах зай руу хуваалцагдаж байна. Бид полицемийн болон синонимийн тусламжтайгаар тохирох боломжтой давуу талаар ярьдаг. Бид загварыг суралцах, загварын үйлдвэрлэлийн талаар нарийвчлан өгдөг. Бид хоёр тохиолдолд туршилтын үр дүнг үзүүлнэ: Сомали-Англи, Болгари-Англи CLIR.', 'si': 'අපි භාෂාත්මක තොරතුරු ප්\u200dරවේශනය කරන්න ප්\u200dරවේශනයක් විස්තර කරනවා ඒක නොවිශ්වාස කරන්නේ විස්තර විවේශනය කරනව වෙනස්, ප්\u200dරශ්න සහ ලිපින්ත දෙන්නම් සංවිධානයක් සම්බන්ධ කරලා තියෙන්නේ ප්\u200dරශ්න ස්ථානයකට. අපි පොලිසිමිය සහ සමානෝමිය විදියට ප්\u200dරයෝජනයක් කතා කරනවා. අපි මොඩල් ප්\u200dරධානය කරන්න විදිහක් පෙන්වන්න, මොඩල් ප්\u200dරධානය ගැන විස්තර දෙන්න. අපි පරීක්ෂණ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප', 'so': "Waxaannu tilmaamaynaa qaab u baahan kara helitaanka macluumaadka luuqadaha oo aan ku xirnayn turjumidda cad ama qoraalka la xiriira. Instead, both queries and documents are mapped into a shared embedding space where retrieval is performed.  Waxaynu ka sheekeynaynaa faa'iidada suurtagalka ah ee dhaqdhaqaalaha kala qabashada polysemi iyo sinonimo. Waxaynu keennaa qaab ku tababarinta modellka, waxaana siinaynaa macluumaad ku saabsan sameynta modellka. Waxaannu keennaa arimaha imtixaanka labada xaaladood: Soomaali-Ingiriis iyo Bulgarian-Ingiriis CLIR.", 'sr': 'Opišemo pristup prikupljanju jezičkih informacija koji se ne oslanja na pojasno prevod ni dokumenta ni uslova pitanja. Umjesto toga, obje pitanja i dokumente su mapirane u zajednički integracijski prostor u kojem se izvodi prikupljanje. Razgovaramo o potencijalnim prednostima pristupa u rješavanju polizemije i sinonije. Predstavljamo metodu za obuku model a i dati detalje o implementaciji modela. Predstavljamo eksperimentalne rezultate za dva slučaja: Somali-engleski i bugarski-engleski CLIR.', 'sv': 'Vi beskriver ett tillvägagångssätt för tvärspråkig informationssökning som inte bygger på uttrycklig översättning av varken dokument- eller frågetermer. Istället mappas både frågor och dokument till ett delat inbäddningsutrymme där hämtning utförs. Vi diskuterar potentiella fördelar med tillvägagångssättet vid hantering av polysemi och synonymer. Vi presenterar en metod för att utbilda modellen och ger detaljer om modellimplementeringen. Vi presenterar experimentella resultat för två fall: somalisk-engelska och bulgarisk-engelska CLIR.', 'ta': 'நாம் மொழியில் தகவல் மீட்டெடுப்பதற்கு ஒரு வழியை விவரிக்கிறோம். அது வெளிப்படையான மொழிமாற்று அல்லது கேள்வி மொழிகள பதிலாக, கேள்விகள் மற்றும் ஆவணங்கள் இருவரும் பகிர்ந்து கொண்டிருக்கும் இடைவெளியில் வரையப்படுகின்றன மற்றும்  நாங்கள் போலிசேமி மற்றும் ஒத்திசையை கையாளும் சாத்தியமான உபயோகங்களை விவாதம் செய்கிறோம். We present a method for training the model, and give details of the model implementation.  இரண்டு விஷயங்களுக்கு நாம் சோமாலி- ஆங்கிலம் மற்றும் புல்கேரிய- ஆங்கிலத்தின் CLIR.', 'ur': 'ہم زبان کی معلومات حاصل کرنے کے لئے ایک طریقہ کا مفصل بیان کرتے ہیں جو نہ سند یا سوال کی اصل پر صریح ترجمہ کرتی ہے۔ اس عوض، دونوں سؤال اور دفتروں کو ایک شریک ایمبڈینگ جگہ میں نقشه بنا دیا جاتا ہے جہاں پھیرنے کا انجام ہوتا ہے. ہم اس طریقے کے امکان فائدہ کے بارے میں مشورہ کرتے ہیں کہ مشورہ اور مشورہ کے بارے میں۔ ہم مدل کی تعلیم کے لئے ایک طریقہ پیش کرتے ہیں اور مدل کی تعلیم کے معاملات کا تفصیل دیتے ہیں۔ ہم دو مواقع کے لئے آزمائش نتیجے پیش کرتے ہیں: سومالی-انگلیسی اور بلگاری-انگلیسی CLIR۔', 'vi': 'Chúng tôi mô tả một cách tiếp cận việc truy tìm thông tin ngôn ngữ mà không dựa trên một bản dịch rõ ràng của cả tài liệu lẫn các điều khoản truy vấn. Thay vào đó, cả các câu hỏi và tài liệu đều được lập thành một không gian chia sẻ nơi thực hiện việc lấy dữ liệu. Chúng ta thảo luận về lợi ích của cách tiếp cận trong cách điều khiển polysemy và đồng nghĩa. Chúng tôi cung cấp một phương pháp huấn luyện mô hình, và chi tiết về cách thực hiện mô hình. Chúng tôi đưa ra kết quả thử nghiệm cho hai trường hợp:', 'uz': "Biz tilda maʼlumotni olish muvaffaqiyatlarini anglatamiz, bu hujjat yoki soʻrov soʻzlariga shaxsiy tarjima qilmaydi. @ info: whatsthis Biz polysemi va synonymini boshqarish uchun eng muhimlik foydalanuvchilarni javob beramiz. Biz modelni o'rganish uchun usulni hosil qilamiz va modelni bajarish haqida bajaramiz. Biz ikkita tilga tajriba natijalarini hozir qilamiz: Somaliya- Inglizcha va Bulgariy- Inglizcha CLIR.", 'bg': 'Описваме подход за извличане на информация между езиците, който не разчита на изричен превод на нито документ, нито на термини за заявка. Вместо това, както заявките, така и документите се картографират в споделено пространство за вграждане, където се извършва извличане. Обсъждаме потенциалните предимства на подхода при работа с полисемия и синонимия. Представяме метод за обучение на модела, както и подробности за внедряването на модела. Представяме експериментални резултати за два случая: сомалийско-английски и българо-английски.', 'hr': 'Mi opisujemo pristup prikupljanju jezičkih informacija koji se ne oslanja na pojasno prevod ni dokumenta ni uslova pitanja. Umjesto toga, obje ispitivanja i dokumente su mapirane u zajednički ugrađeni prostor u kojem se izvodi prikupljanje. Razgovaramo o potencijalnim prednostima pristupa u rješavanju polizemije i sinonije. Predstavljamo metodu za obuku model a i dati detalje o provedbi modela. Predstavljamo eksperimentalne rezultate za dva slučaja: Somali-engleski i bugarski-engleski CLIR.', 'da': 'Vi beskriver en tilgang til tværsproget informationssøgning, der ikke er afhængig af eksplicit oversættelse af hverken dokument- eller forespørgselsbetingelser. I stedet knyttes både forespørgsler og dokumenter til et delt indlejringsrum, hvor hentning udføres. Vi diskuterer potentielle fordele ved tilgangen til håndtering af polysemi og synonymer. Vi præsenterer en metode til træning af modellen, og giver detaljer om modellens implementering. Vi præsenterer eksperimentelle resultater for to tilfælde: somalisk-engelsk og bulgarsk-engelsk CLIR.', 'nl': "We beschrijven een aanpak voor het ophalen van informatie in meerdere talen die niet afhankelijk is van expliciete vertaling van documenten of query termen. In plaats daarvan worden zowel query's als documenten toegewezen aan een gedeelde insluitruimte waar het ophalen wordt uitgevoerd. We bespreken mogelijke voordelen van de aanpak bij het hanteren van polysemie en synoniem. We presenteren een methode voor het trainen van het model, en geven details over de uitvoering van het model. We presenteren experimentele resultaten voor twee gevallen: Somalisch-Engels en Bulgaars-Engels CLIR.", 'de': 'Wir beschreiben einen Ansatz zur sprachübergreifenden Informationssuche, der nicht auf einer expliziten Übersetzung von Dokumenten oder Abfragebegriffen beruht. Stattdessen werden sowohl Abfragen als auch Dokumente einem gemeinsamen Einbettungsraum zugeordnet, in dem der Abruf durchgeführt wird. Wir diskutieren mögliche Vorteile des Ansatzes im Umgang mit Polysemie und Synonym. Wir stellen eine Methode zur Schulung des Modells vor und geben Details zur Modellimplementierung. Wir präsentieren experimentelle Ergebnisse für zwei Fälle: somalisch-englisch und bulgarisch-englisch CLIR.', 'id': 'Kami menggambarkan pendekatan untuk merebut informasi bahasa yang tidak bergantung pada terjemahan eksplicit dari sama ada dokumen atau istilah pertanyaan. Sebaliknya, kedua pertanyaan dan dokumen dipetakan ke ruang penyembedding berbagi di mana penulisan dilakukan. Kami mendiskusikan keuntungan potensial pendekatan dalam menangani polisemi dan sinonimi. Kami mempersembahkan metode untuk melatih model, dan memberikan rincian tentang implementasi model. Kami mempersembahkan hasil percobaan untuk dua kasus: Somali-Inggris dan Bulgaria-Inggris CLIR.', 'fa': 'ما یک روش برای خروج اطلاعات زبانی را توصیف می\u200cکنیم که بر ترجمه\u200cهای خاصی از سند یا ترجمه\u200cهای پرسیدن اعتماد ندارد. به جای این، هر دو سوال و سند به یک فضای مشترک در جایی که بازیابی انجام می\u200cشود نقشه\u200cبندی می\u200cشوند. ما مطابق منافع\u200cهای پتانسیل از دسترسی در کنترل polysemy و synonymy صحبت می\u200cکنیم. ما روش آموزش مدل را پیشنهاد می\u200cکنیم و جزئیات عملکرد مدل را می\u200cدهیم. ما نتایج آزمایشی را برای دو پرونده نشان می دهیم: سومالی-انگلیسی و بلگاری-انگلیسی CLIR.', 'ko': '우리는 문서나 검색어의 현식 번역에 의존하지 않는 다중 언어 정보 검색 방법을 묘사했다.반대로, 검색과 문서는 공유된 삽입 공간에 비치며, 이 공간에서 검색을 실행합니다.우리는 이런 방법이 다의와 동의어를 처리하는 데 있어 잠재적인 장점을 토론했다.우리는 훈련 모델의 방법을 제시했고 모델이 실현되는 세부 사항을 제시했다.우리는 소말리아 영어와 불가리아 영어 두 사례의 실험 결과를 제시했다.', 'sw': 'Tunaelezea njia ya kupitia upatikanaji wa taarifa za lugha ambazo haitegemea tafsiri ya wazi ya kitabu au vipengele vya kuuliza. Badala yake, maswali na nyaraka zote zimezorodheshwa katika sehemu inayoshirikishwa ambapo kurejeshwa. We discuss potential advantages of the approach in handling polysemy and synonymy.  Tunaweza kuweka mbinu ya mafunzo mifano, na kutoa maelezo ya utekelezaji wa mifano. Tunatoa matokeo ya majaribio kwa kesi mbili: Kisomali-Kiingereza na Kiingereza CLIR.', 'sq': 'Ne përshkruajmë një qasje për marrjen e informacionit gjuhësor që nuk mbështetet në përkthimin eksplicit të as termave të dokumentit, as të pyetjes. Në vend të kësaj, të dy pyetjet dhe dokumentet janë hartuar në një hapësirë të përbashkët të përfshirjes ku kryehet marrja. Ne diskutojmë avantazhet e mundshme të qasjes në trajtimin e polizimit dhe sinonimisë. Ne paraqesim një metodë për trajnimin e modelit dhe japim detaje të zbatimit të modelit. Ne paraqesim rezultate eksperimentale për dy raste: Somali-Anglisht dhe Bullgar-Anglisht CLIR.', 'tr': 'Biz dil maglumaty almak üçin bir gollany tassyýarys. Bu senediň ya da soragy terjime edilmedi. Bu ýerde, hem soraglar hem senedler bir paylaşdyrylýan ýere çykylýar. Biz polysemiýany we synonymyny ýüze çykmak üçin golaýynyň potensial bahallaryny gürrüň berýäris. Biz nusgany okuw etmek üçin bir yöntem görkezip, we nusganyň implementasy barada maglumatlary berip bereris. Biz iki durum üçin synanyşan netijeleri görkeýäris: Somali-Iňlisçe we Bulgarça-Iňlisçe CLIR.', 'af': "Ons beskryf 'n toegang na kruis tale inligting ontvang wat nie op eksplisiese vertaling van óf dokument of navraag terme vertrou nie. In plaas, albei vrae en dokumente word gekap in 'n gedeelde inbêer spasie waar ontvanging uitgevoer word. Ons bespreek potensiele voordeel van die toegang in die handling van polisemie en sinoniem. Ons stel 'n metode om die model te oefen en besonderhede van die model implementering te gee. Ons stel eksperimentale resultate vir twee gevalle: Somali-Engels en Bulgarse-Engels CLIR.", 'hy': 'Մենք նկարագրում ենք լեզվային ինֆորմացիայի փոխադարձման մոտեցումը, որը չի հիմնված ոչ փաստաթղթի, ոչ էլ հարցման տերմինների բացատրական թարգմանման վրա: Փոխարենը, երկու հարցեր և փաստաթղթեր քարտեզագրված են ընդհանուր ներգրավման տարածքում, որտեղ վերադարձում է: Մենք քննարկում ենք պոլիզեմիայի և սինոնիմիայի վերաբերյալ մոտեցման պոտենցիալ առավելությունները: Մենք ներկայացնում ենք մոդելի ուսումնասիրության մեթոդ և ներկայացնում ենք մոդելի իրականացման մանրամասնությունները: Մենք ներկայացնում ենք փորձարկման արդյունքներ երկու դեպքում՝ Սոմալի-անգլերեն և բուլերեն-անգլերեն ԿԼԻՌ:', 'am': 'በቋንቋ ቋንቋ መረጃዎችን ለማስቀበል እናሳውቃለን፡፡ Instead, both queries and documents are mapped into a shared embedded space where retrieval is performed. በፖሊሳሚን እና ሲኒኖኒን ለመቆጣጠር የሚችሉትን የስልጣን ጥቅም እናሳውቃለን፡፡ ምሳሌውን ለማስተማር እናስገራለን የሞዴል ተርጓሚዎቹንም እናስጠጋለን፡፡ ለሁለት ጉዳዮች የሞከር ፍሬዎችን እናቀርባለን፤ ሶማሊ-እንግሊዘኛ እና ቡልጋሪኛ-እንግሊዘኛ CLIR።', 'az': 'Biz dil məlumatlarını almaq üçün tərzini təsdiqləyirik ki, belə bir məlumat və ya soruşma şəkillərinin açıq-aydın tərzinə təvəkkül edilməz. Əvəzində, hər ikisi sual və beləliklər alış yerinə paylaşdırılır. Biz çoxluğu və sinonimi müdafiə etmək üçün mümkün mənfəətlər barəsində mübahisə edirik. Biz modeli təhsil etmək üçün bir metodu göstəririk və modeli təhsil etmək barəsindəki detayları veririk. İki vəziyyət üçün eksperimentli sonuçlar göstəririk: Somali-İngilizce və Bulgarca-İngilizce CLIR.', 'bn': 'আমরা ভাষাভাষী তথ্য পুনরুদ্ধার পার করার একটি উপায় বর্ণনা করি যা কোন নথিপত্রের ব্যাপারে নির্ভর করে না অথবা অনুসন্ধানের শর্ তার পরিবর্তে প্রশ্ন ও নথিপত্র উভয় একটি শেয়ার করা বিভিন্ন স্থানে ম্যাপ করা হচ্ছে যেখানে পুনরুদ্ধার করা হচ্ছে। আমরা পলিসেমি এবং সিনোনিয়ামির মাধ্যমে এই পদ্ধতির সম্ভাব্য সুবিধা নিয়ে আলোচনা করি। আমরা মডেল প্রশিক্ষণের একটি পদ্ধতি উপস্থাপন করি এবং মডেল বাস্তবায়নের বিস্তারিত ব্যাখ্যা দিয়েছি। আমরা দুই মামলার পরীক্ষার ফলাফল উপস্থাপন করছি: সোমালিয়া-ইংরেজি এবং বুলগেরিয়ান-ইংরেজি সিলির।', 'ca': "Descrivem un enfocament per a recuperar informació llengua que no es basa en traducció explícita ni de termes de documentació ni de consulta. En comptes d'això, tant les preguntes com els documents es mapeixen en un espai compartit d'incorporació on es fa la recuperació. Discutem sobre les avantatges potencials de l'enfocament en la gestió de la polissima i la sinonimia. Presentam un mètode d'entrenament del model i donem detalls sobre la implementació del model. Presentam resultats experimentals en dos casos: CLIR somali-anglès i búlgar-anglès.", 'cs': 'Popisujeme přístup k vyhledávání informací v křížových jazycích, který nespoléhá na explicitním překladu dokumentů ani dotazových termínů. Místo toho jsou dotazy i dokumenty mapovány do sdíleného vkládacího prostoru, kde se provádí načtení. Diskutujeme potenciální výhody tohoto přístupu při manipulaci s polysémií a synonymií. Představujeme metodu pro trénink modelu a podrobnosti o implementaci modelu. Představujeme experimentální výsledky pro dva případy: somálsko-anglické a bulharsko-anglické CLIR.', 'et': 'Kirjeldame keeleülese teabe hankimise lähenemisviisi, mis ei põhine dokumendi ega päringuterminite selgesõnalisel tõlkimisel. Selle asemel kaardistatakse nii päringud kui ka dokumendid ühiskasse manustamisruumi, kus teostatakse otsinguid. Arutleme lähenemisviisi võimalikke eeliseid polüseemia ja sünonüümia käsitlemisel. Tutvustame mudeli koolitamise meetodit ja anname üksikasjad mudeli rakendamise kohta. Esitleme eksperimentaalseid tulemusi kahel juhul: somaali-inglise ja bulgaaria-inglise CLIR.', 'bs': 'Opišemo pristup prikupljanju jezičkih informacija koji se ne oslanja na pojasno prevod ni dokumenta ni uslova pitanja. Umjesto toga, obje ispitivanja i dokumente su mapirane u zajednički ugrađeni prostor gdje se izvodi prikupljanje. Razgovaramo o potencijalnim prednostima pristupa u rješavanju polizemije i sinonije. Predstavljamo metodu za obuku model a i dati detalje o implementaciji modela. Predstavljamo eksperimentalne rezultate za dva slučaja: Somali-engleski i bugarski-engleski CLIR.', 'fi': 'Kuvaamme monikieliseen tiedonhakuun perustuvaa lähestymistapaa, joka ei perustu dokumentin tai kyselytermien nimenomaiseen kääntämiseen. Sen sijaan sekä kyselyt että asiakirjat yhdistetään jaettuun upotustilaan, jossa haku suoritetaan. Keskustelemme menetelmän mahdollisista eduista polysemian ja synonyymin käsittelyssä. Esittelemme mallin koulutusmenetelmän ja kerromme yksityiskohtaisesti mallin toteutuksesta. Esitämme kokeellisia tuloksia kahdesta tapauksesta: somali-englanti ja bulgaria-englanti CLIR.', 'jv': 'Awakdhéwé nglarang kapan nganggo nggawe informasi langkung nggawe gerakan kuwi jenis cara-lisan sing paling nggambar tokkum uga ngono ujian terjamahan Tanggal Awak dhéwé éntuk perbudhakan kanggo nggawe polisemi lan senonnyomi. Tulung awak dhéwé éntuk sistem kanggo nggawe model lan ngono njaluk-njaluk ngewehku modèl Awak dhéwé éntukno pancening alaman kanggo kelas rambarang durung: Somali-Inggris lan CLIR Inggris barang.', 'sk': 'Opisujemo pristop k medjezičnemu pridobivanju informacij, ki se ne opira na ekspliciten prevod dokumentov ali poizvedbenih izrazov. Namesto tega so poizvedbe in dokumenti preslikani v prostor za vdelavo v skupni rabi, kjer se izvede pridobivanje. Razpravljamo o potencialnih prednostih pristopa pri ravnanju s polikemijo in sinonimijo. Predstavljamo metodo za usposabljanje modela in podrobnosti o implementaciji modela. Predstavljamo poskusne rezultate za dva primera: somalsko-angleški in bolgarsko-angleški CLIR.', 'ha': "Tuna bayyana wani hanyoyi wa ka samu motsari na information cikin harshen, wanda bai dõgara ga fassarar-bayani na takardar ko kuma don ka tambaye. Babu musamman, za'a rasa koyan tambayar da takardun aiki biyu zuwa wani filin da aka raba shi cikin filin da ake samu da shi. Munã jãyayya masu yiwuwa da amfani na hanyoyi a cikin kudai mulki da sunonini. Tuna gabatar da wata hanyor wa yin wa'azi ga misalin, kuma Muke bayyana misalin ayukan misalin. Tuna halatar da matsaran jarrabãwa biyu: Somaliya-Ingiriya da Bulgaria-Ingiriya CLIR.", 'he': 'אנו מתארים גישה לחצות מידע שפוי שפוי שגיאה שלא תלוי בתרגום ברור של מסמכים או תנאים בקשה. במקום זה, שני השאלות ומסמכים מופיעים לתוך מרחב משותף של קיבלה שבו מבצעים השיגה. אנחנו מדברים על יתרונות פוטנציאליים של הגישה בטיפול בפוליסמיה וסינונימיה. אנחנו מציגים שיטה לאימון הדוגמנית, ולתת פרטים על ההפעלה של הדוגמנית. אנחנו מציגים תוצאות ניסויים לשני מקרים: סומאלי-אנגלי ובולגרי-אנגלי CLIR.', 'bo': 'ང་ཚོས་སྐད་ཡིག་ཆ་དང་འཛམ་གླིང་བའི་བརྡ་འཕྲིན་དོན་ཀྱི་བཟོ་བཅོས་གཅིག་འགྲེལ་བཤད་བྱེད་ཀྱི་མིན འདི་ཚབ་དུ། དྲི་ཞིབ་དང་ཡིག་ཆ་གཉིས་ཀྱིས་ཉར་འཇུག་བྱེད་ཀྱི་ས་སྟོང་ཞིག་ཏུ་སྒྲིག་ཡོད་པ ང་ཚོས་འདྲི་ཚིག་གཟུགས་རིས་དང་མཐུན་རྣམས་ལ་སྐྱོང་ཐབས་ནང་གི་གོ་སྐབས་ཆེ་མཐོང་ཐུབ་པའི་སྐྱོན་འབྲེལ་ ང་ཚོས་མ་དབྱེ་བ་ལྟ་སློང་བྱེད་ཐབས་ལམ་ཞིག་བྱས་ནས་མིག་ཆའི་གསལ་བཤད་མང་ཙམ་སྟོན་ཡོད། ང་ཚོས་ཕལ་ཆེར་བརྟན་པའི་གྲུབ་འབྲས་མང་པོ་ཞིག་འཆར་བྱེད་ཀྱི་ཡོད།སོ་མ་ལི་ཨིན་ཇིས་དང་བུ་ལ་གྷི་ར་ཡི'}
{'en': 'Cross-lingual Information Retrieval with BERT', 'ar': 'استرجاع المعلومات عبر اللغات باستخدام BERT', 'pt': 'Recuperação de informações em vários idiomas com o BERT', 'es': 'Recuperación de información multilingüe con BERT', 'fr': "Extraction d'informations multilingues avec BERT", 'ja': 'BERTによるクロスリンガル情報検索', 'hi': 'BERT के साथ क्रॉस-भाषी सूचना पुनर्प्राप्ति', 'zh': '用 BERT 跨语信息检索', 'ru': 'Кросс-лингвистическое извлечение информации с помощью BERT', 'ga': 'Aisghabháil Faisnéise Trastheangach le BERT', 'ka': 'BERT', 'hu': 'Többnyelvű információgyűjtés a BERT segítségével', 'el': 'Διασγλωσσική ανάκτηση πληροφοριών με τον BERT', 'it': 'Recupero di informazioni multilingue con BERT', 'kk': 'BERT- мен бірнеше тілді мәліметті алу', 'ml': 'BERT ഉപയോഗിച്ചു് ക്രോസ്- ഭാഷ വിവരങ്ങള്\u200d വീണ്ടെടുക്കുക', 'lt': 'Tarpkalbinės informacijos gavimas su BERT', 'mk': 'Добивање на меѓујазични информации со BERT', 'ms': 'Penerimaan Maklumat Selata-Bahasa dengan BERT', 'pl': 'Pozyskiwanie informacji między językami za pomocą BERT', 'mt': 'Il-kisba ta’ informazzjoni translingwistika mal-BERT', 'ro': 'Recuperarea informațiilor translingvistice cu BERT', 'mn': 'БЕРТ-тэй олон хэлний мэдээлэл авах', 'sr': 'Prikupljanje preko jezika informacija sa BERT-om', 'no': 'Krysspråk informasjonshenting med BERT', 'si': 'බෙර්ට් එක්ක ක්\u200dරොස් භාෂාවික තොරතුරු ගන්න', 'ta': 'Name', 'so': 'Heshiiska macluumaadka luuqadaha iskuulka ah ee BERT', 'sv': 'Tvärspråkig informationsinsamling med BERT', 'ur': 'BERT کے ساتھ کروس زبان معلومات حاصل کرنا', 'uz': 'Name', 'vi': 'Truyền thông qua ngôn ngữ rộng', 'bg': 'Извличане на междуезична информация с BERT', 'da': 'Indhentning af information på tværs af sprog med BERT', 'nl': 'Meertalige informatie opvragen met BERT', 'hr': 'Prikupljanje kroz jezičke informacije sa BERT-om', 'de': 'Sprachübergreifende Informationsbeschaffung mit BERT', 'fa': 'بازیابی اطلاعات متوسط زبان با BERT', 'id': 'Penerimaan informasi saling bahasa dengan BERT', 'ko': 'BERT 기반 다국어 정보 검색', 'sw': 'Kurudishwa kwa taarifa za lugha za cross-language with BERT', 'tr': 'BERT bilen Gatlanyş Diller Maglumaty Mazmunlar', 'sq': 'Rimarrja e informacionit ndërgjuhësor me BERT', 'af': 'Kruistale Informasie ontvang met BERT', 'am': 'ቋንቋ', 'hy': 'BER-ի միջլեզվային տեղեկատվության ստանալը', 'az': 'BERT il톛 칞ox dilli m톛lumat almas캼', 'bn': 'BERT এর সাথে ক্রস-ভাষায় তথ্য পুনরুদ্ধার', 'bs': 'Prikupljanje preko jezika informacija sa BERT-om', 'ca': "Obteniment d'informació translingüística amb BERT", 'cs': 'Vyhledávání informací v různých jazycích s BERT', 'et': 'Keeleülene teabe hankimine BERTiga', 'fi': 'Kieltenvälinen tiedonhaku BERT:n kanssa', 'ha': 'Cross-lingual Information Retrieval with BERT', 'sk': 'Medjezično pridobivanje informacij z BERT', 'he': 'קיבלת מידע בין שפתיים עם BERT', 'bo': 'Cross-lingual Information Retrieval with BERT', 'jv': 'ProgressBarUpdates'}
{'en': 'Multiple neural language models have been developed recently, e.g., BERT and XLNet, and achieved impressive results in various NLP tasks including sentence classification, question answering and document ranking. In this paper, we explore the use of the popular bidirectional language model, BERT, to model and learn the relevance between English queries and foreign-language documents in the task of cross-lingual information retrieval. A deep relevance matching model based on BERT is introduced and trained by finetuning a pretrained multilingual BERT model with weak supervision, using home-made CLIR training data derived from parallel corpora. Experimental results of the retrieval of Lithuanian documents against short English queries show that our model is effective and outperforms the competitive baseline approaches.', 'ar': 'تم تطوير نماذج لغة عصبية متعددة مؤخرًا ، على سبيل المثال ، BERT و XLNet ، وحققت نتائج رائعة في مهام معالجة اللغات الطبيعية المختلفة بما في ذلك تصنيف الجملة والإجابة على الأسئلة وترتيب المستندات. في هذه الورقة ، نستكشف استخدام نموذج اللغة ثنائي الاتجاه الشهير ، BERT ، لنمذجة ومعرفة الصلة بين الاستعلامات الإنجليزية والمستندات بلغة أجنبية في مهمة استرجاع المعلومات عبر اللغات. يتم تقديم نموذج مطابقة عميقة الصلة يعتمد على BERT وتدريبه من خلال ضبط نموذج BERT متعدد اللغات سابق التدريب بإشراف ضعيف ، باستخدام بيانات تدريب CLIR محلية الصنع مشتقة من هيئة موازية. تُظهر النتائج التجريبية لاسترداد المستندات الليتوانية مقابل الاستعلامات الإنجليزية القصيرة أن نموذجنا فعال ويتفوق في الأداء على مناهج الأساس التنافسية.', 'pt': 'Vários modelos de linguagem neural foram desenvolvidos recentemente, por exemplo, BERT e XLNet, e alcançaram resultados impressionantes em várias tarefas de PNL, incluindo classificação de frases, resposta a perguntas e classificação de documentos. Neste artigo, exploramos o uso do popular modelo de linguagem bidirecional, BERT, para modelar e aprender a relevância entre consultas em inglês e documentos em língua estrangeira na tarefa de recuperação de informações em vários idiomas. Um modelo de correspondência de relevância profunda baseado em BERT é introduzido e treinado ajustando um modelo BERT multilíngue pré-treinado com supervisão fraca, usando dados de treinamento CLIR caseiros derivados de corpora paralelos. Resultados experimentais da recuperação de documentos lituanos contra consultas curtas em inglês mostram que nosso modelo é eficaz e supera as abordagens de linha de base competitivas.', 'es': 'Recientemente se han desarrollado múltiples modelos de lenguaje neuronal, por ejemplo, BERT y XLnet, y se han logrado resultados impresionantes en varias tareas de PNL, incluida la clasificación de oraciones, la respuesta a preguntas y la clasificación de documentos. En este artículo, exploramos el uso del popular modelo de lenguaje bidireccional, BERT, para modelar y aprender la relevancia entre las consultas en inglés y los documentos en idiomas extranjeros en la tarea de recuperación de información en varios idiomas. Se introduce y entrena un modelo de correspondencia de relevancia profundo basado en BERT mediante el ajuste fino de un modelo BERT multilingüe previamente entrenado con una supervisión débil, utilizando datos de formación CLIR hechos en casa derivados de cuerpos paralelos. Los resultados experimentales de la recuperación de documentos lituanos comparados con consultas breves en inglés muestran que nuestro modelo es eficaz y supera a los enfoques de referencia competitivos.', 'fr': "Plusieurs modèles de langage neuronal ont été développés récemment, par exemple BERT et XLnet, et ont obtenu des résultats impressionnants dans diverses tâches de PNL, y compris la classification des phrases, la réponse aux questions et le classement des documents. Dans cet article, nous explorons l'utilisation du modèle linguistique bidirectionnel populaire, BERT, pour modéliser et apprendre la pertinence entre les requêtes en anglais et les documents en langue étrangère dans la tâche de recherche d'informations multilingues. Un modèle de correspondance de pertinence approfondie basé sur BERT est introduit et formé en peaufinant un modèle BERT multilingue pré-entraîné avec une supervision faible, à l'aide de données de formation CLIR maison dérivées de corpus parallèles. Les résultats expérimentaux de la récupération de documents lituaniens par rapport à de courtes requêtes en anglais montrent que notre modèle est efficace et surpasse les approches de base concurrentielles.", 'ja': '最近、BERTやXLNetなど、複数のニューラル言語モデルが開発され、文章分類、質問回答、文書ランキングを含む様々なNLPタスクで印象的な結果を達成しました。本稿では，一般的な双方向言語モデルであるBERTを用いて，クロスリンガル情報検索の課題における英語の問い合わせと外国語の文書との関連性をモデル化し，研究する． BERTに基づく関連性の深いマッチングモデルを、並列コーラから得られた自家製CLIRトレーニングデータを使用して、弱い監督下で事前にトレーニングされた多言語BERTモデルを微調整することによって紹介し、トレーニングします。短い英語の問い合わせに対するリトアニアの文書の検索の実験結果は、当社のモデルが効果的であり、競合ベースラインのアプローチを上回ることを示しています。', 'zh': '近发神经语言模,如BERT与XLNet,并于诸NLP之中得深刻成果,句类之类,问答文档排名。 本文之中,讨论流行双向语言模形BERT以建模学问英语询与外语文档言语信息检索相关性。 用并行语料库自制 CLIR 练数,弱监多言 BERT 微调,引入习 BERT 之深相关性配之。 短者英语求立陶宛文之实验结果表明,吾形有效,而优于争基线。', 'ru': 'Несколько нейронных языковых моделей были разработаны недавно, например, BERT и XLNet, и достигли впечатляющих результатов в различных задачах NLP, включая классификацию предложений, ответы на вопросы и ранжирование документов. В этой статье мы исследуем использование популярной двунаправленной языковой модели, BERT, для моделирования и изучения релевантности между английскими запросами и иноязычными документами в задаче поиска кросс-лингвистической информации. Внедряется и обучается модель глубокого сопоставления релевантности, основанная на BERT, путем тонкой настройки предварительно обученной многоязычной модели BERT со слабым надзором, с использованием самодельных данных обучения CLIR, полученных из параллельных тел. Экспериментальные результаты поиска литовских документов по коротким английским запросам показывают, что наша модель эффективна и превосходит конкурентные базовые подходы.', 'hi': 'कई तंत्रिका भाषा मॉडल हाल ही में विकसित किए गए हैं, उदाहरण के लिए, BERT और XLNet, और वाक्य वर्गीकरण, प्रश्न उत्तर देने और दस्तावेज़ रैंकिंग सहित विभिन्न एनएलपी कार्यों में प्रभावशाली परिणाम प्राप्त किए। इस पेपर में, हम लोकप्रिय द्विदिश भाषा मॉडल, BERT के उपयोग का पता लगाते हैं, ताकि क्रॉस-लिंगुअल सूचना पुनर्प्राप्ति के कार्य में अंग्रेजी प्रश्नों और विदेशी भाषा के दस्तावेजों के बीच प्रासंगिकता को मॉडल और सीखा जा सके। BERT पर आधारित एक गहरी प्रासंगिकता मिलान मॉडल को कमजोर पर्यवेक्षण के साथ एक पूर्व-प्रशिक्षित बहुभाषी BERT मॉडल को ठीक करके पेश किया जाता है और प्रशिक्षित किया जाता है, समानांतर कॉर्पोरेट से व्युत्पन्न घर-निर्मित CLIR प्रशिक्षण डेटा का उपयोग करके। छोटे अंग्रेजी प्रश्नों के खिलाफ लिथुआनियाई दस्तावेजों की पुनर्प्राप्ति के प्रयोगात्मक परिणाम बताते हैं कि हमारा मॉडल प्रभावी है और प्रतिस्पर्धी बेसलाइन दृष्टिकोणों को बेहतर बनाता है।', 'ga': 'Forbraíodh samhlacha iomadúla néartheanga le déanaí, m.sh., BERT agus XLNet, agus baineadh torthaí suntasacha amach i dtascanna éagsúla NLP lena n-áirítear aicmiú abairtí, freagra ceisteanna agus rangú doiciméad. Sa pháipéar seo, déanaimid iniúchadh ar úsáid na samhla déthreoracha coitianta, BERT, chun an bhaint atá idir ceisteanna Béarla agus doiciméid i dteangacha iasachta a shamhaltú agus a fhoghlaim maidir le haisghabháil faisnéise tras-teangacha. Tugtar isteach múnla meaitseála ábharthacht dhomhain atá bunaithe ar BERT agus cuirtear oiliúint air trí mhionchoigeartú a dhéanamh ar mhúnla ilteangach réamhoilte le maoirseacht lag, ag baint úsáide as sonraí oiliúna CLIR de dhéantús baile a dhíorthaítear ó chorpas comhthreomhar. Léiríonn torthaí trialacha ar aisghabháil doiciméad Liotuáinise i gcoinne fiosrúchán gearr Béarla go bhfuil ár múnla éifeachtach agus go sáraíonn sé na cineálacha cur chuige iomaíoch bonnlíne.', 'ka': 'ბევრი ნეიროლური ენის მოდელები ახლა განვითარებულია, მაგალითად BERT და XLNet, და მიღებულია განსხვავებული NLP დავალებების შესახებ სხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა საქ ამ დოკუმენტში ჩვენ მოვიყვანეთ პოლიპური ბიდერექციონალური ენის მოდელის გამოყენება, BERT, მოდელისთვის და ვისწავლეთ ინგლისური კითხვების და გარეშე ენის დოკუმენტების შესახებ მრავალური BERT-ის ბაზაციაში მნიშვნელოვანი მოდელის შესაძლებლობა იყენება და განსწავლება მნიშვნელოვანი BERT-ის მოდელის გამოყენებით, რომელიც ძალიან დარწმუნებული მოდელის გამოყენება CLIR-ის განსწავლება, რომელიც პა ლთტსანიური დოკუმენტების გამოყენება კონკრეტური ინგლისური კითხვებისთვის გამოყენება ექსპერიმენტიური შედეგია, რომ ჩვენი მოდელი ეფექტიურია და უფრო გავაკ', 'hu': 'A közelmúltban több neurális nyelvi modellt fejlesztettek ki, például BERT és XLNet, és lenyűgöző eredményeket értek el különböző NLP feladatokban, beleértve a mondatok osztályozását, a kérdések megválaszolását és a dokumentumok rangsorolását. Ebben a tanulmányban a népszerű kétirányú nyelvi modell, a BERT alkalmazását vizsgáljuk fel az angol lekérdezések és az idegen nyelvű dokumentumok relevanciájának modellezésére és megismerésére a többnyelvű információlekérdezés feladatában. A BERT alapú, mélyreható relevanciájú párosítási modellt úgy vezetik be és képezik ki, hogy egy előkészített, többnyelvű BERT modell finomhangolásával, gyenge felügyelet mellett, házi CLIR edzési adatokat használnak párhuzamos korpusokból. A litván dokumentumok rövid angol lekérdezésekkel történő lekérdezésének kísérleti eredményei azt mutatják, hogy modellünk hatékony és felülmúlja a versenyképes alapközelítéseket.', 'el': 'Πρόσφατα αναπτύχθηκαν πολλαπλά μοντέλα νευρωνικής γλώσσας, π.χ. και και πέτυχαν εντυπωσιακά αποτελέσματα σε διάφορες εργασίες όπως ταξινόμηση προτάσεων, απάντηση σε ερωτήσεις και κατάταξη εγγράφων. Σε αυτή την εργασία, διερευνούμε τη χρήση του δημοφιλούς μοντέλου αμφίδρομης γλώσσας, για να μοντελοποιήσουμε και να μάθουμε τη συνάφεια μεταξύ αγγλικών ερωτήσεων και εγγράφων ξένης γλώσσας στο έργο της γλωσσικής ανάκτησης πληροφοριών. Ένα μοντέλο αντιστοίχισης βαθιάς συνάφειας βασισμένο στον BERT εισάγεται και εκπαιδεύεται με την τελειοποίηση ενός προ-εκπαιδευμένου πολύγλωσσου μοντέλου BERT με αδύναμη επίβλεψη, χρησιμοποιώντας δεδομένα κατάρτισης που προέρχονται από παράλληλα σώματα. Τα πειραματικά αποτελέσματα της ανάκτησης λιθουανικών εγγράφων με σύντομα αγγλικά ερωτήματα δείχνουν ότι το μοντέλο μας είναι αποτελεσματικό και ξεπερνά τις ανταγωνιστικές προσεγγίσεις βάσης.', 'it': "Diversi modelli di linguaggio neurale sono stati sviluppati recentemente, ad esempio BERT e XLNet, e hanno ottenuto risultati impressionanti in vari compiti NLP, tra cui classificazione delle frasi, risposta alle domande e classificazione dei documenti. In questo articolo esploriamo l'uso del popolare modello di lingua bidirezionale, BERT, per modellare e imparare la rilevanza tra query inglesi e documenti in lingua straniera nel compito di recupero di informazioni cross-lingual. Un modello di corrispondenza di rilevanza profonda basato su BERT viene introdotto e addestrato mettendo a punto un modello BERT multilingue pre-addestrato con supervisione debole, utilizzando dati di allenamento CLIR fatti in casa derivati da corpi paralleli. I risultati sperimentali del recupero di documenti lituani contro brevi query inglesi dimostrano che il nostro modello è efficace e supera gli approcci di base competitivi.", 'ms': 'Beberapa model bahasa saraf telah dikembangkan baru-baru ini, cth., BERT dan XLNet, dan mencapai keputusan yang mengesankan dalam berbagai tugas NLP termasuk kelasukan kalimat, jawapan soalan dan kelasukan dokumen. Dalam kertas ini, kami mengeksplorasi penggunaan model bahasa bidireksi populer, BERT, untuk memmodelkan dan belajar relevansi antara pertanyaan Inggeris dan dokumen bahasa asing dalam tugas pencarian maklumat saling bahasa. Name Keputusan eksperimental untuk mendapatkan dokumen Lithuania melawan pertanyaan Inggeris pendek menunjukkan bahawa model kita berkesan dan melampaui pendekatan asas kompetitif.', 'ml': 'Multiple neural language models have been developed recently, e.g., BERT and XLNet, and achieved impressive results in various NLP tasks including sentence classification, question answering and document ranking.  ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d പ്രധാനപ്പെട്ട ഭാഷ മോഡല്\u200d ബെര്\u200dട്ടിയുടെ ഉപയോഗിക്കുന്നത് ഇംഗ്ലീഷ് ചോദ്യങ്ങള്\u200dക്കും വിദേശ ഭാഷയിലെ രേഖകള്\u200dക്കുമിടയില്\u200d വിവരങ് ബെര്\u200dടിയില്\u200d അടിസ്ഥാനമാക്കിയ ഒരു ആഴത്തെ പൊരുത്തുന്ന മോഡല്\u200d പരിശീലിപ്പിക്കുകയും ചെയ്യുന്നു. പരിശീലിപ്പിക്കുകയും ചെയ്യുന്നു. പാരാളില്\u200d നിന്നുള് ചെറിയ ഇംഗ്ലീഷ് ചോദ്യങ്ങള്\u200dക്കെതിരായി ലിത്തുവാന്\u200d രേഖകള്\u200d വിട്ടുവീണ്ടെടുക്കുന്നതിന്റെ പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നു', 'kk': 'Жуырда бірнеше невралдық тіл үлгілері, мысалы BERT және XLNet, және сұрақ жауап беру және құжаттың жобаларының түрлі NLP тапсырмаларында әсер ететін нәтижелері бар. Бұл қағазда, біз мәліметті екі тіл үлгісін, BERT үлгілеу үшін, ағылшын сұрақтар мен ағылшын тіл құжаттарының арасындағы көп тілді мәліметті алу тапсырмасында үйренеміз. BERT бағдарламасына негізделген терең маңыздылық сәйкестік үлгісі бірнеше тілді BERT үлгісін бақылау үшін ендіру және бақылау үлгісін қолданып, параллел корпорадан шығарылған CLIR оқыту деректерін қолдану ү Литва құжаттарды қалай қысқа ағылшын сұрауларына қарсы алу эксперименталдық нәтижелері біздің моделіміз ең әсер етеді және конкуренциялық негізгі жолдардың жағдайларына қаты', 'mk': 'Неодамна се развиени неколку модели на нервен јазик, на пример BERT и XLNet, и постигнаа импресивни резултати во различни NLP задачи, вклучително и класификација на реченици, одговори на прашања и рангирање на документите. Во овој весник, ја истражуваме употребата на популарниот двојно јазички модел, БЕРТ, за моделирање и научување на релевантноста помеѓу англиските прашања и документите на странски јазик во задачата на прекујазичното преземање информации. A deep relevance matching model based on BERT is introduced and trained by finetuning a pretrained multilingual BERT model with weak supervision, using home-made CLIR training data derived from parallel corpora.  Експерименталните резултати од преземањето на литуанските документи против кратките англиски прашања покажуваат дека нашиот модел е ефикасен и ги надминува конкурентните основни пристапи.', 'lt': 'Neseniai sukurti keli nervų kalbų modeliai, pvz., BERT ir XLNet, ir pasiekti įspūdingi rezultatai įvairiose NLP užduotyse, įskaitant sakinių klasifikavimą, klausimų atsakymą ir dokumentų klasifikavimą. Šiame dokumente tiriame populiaraus dvikryptinio kalbos modelio BERT naudojimą, kad būtų galima modeliuoti ir išmokti anglų klausimų ir užsienio kalbos dokumentų svarbą tarpkalbinės informacijos gavimo užduotyje. A deep relevance matching model based on BERT is introduced and trained by finetuning a pretrained multilingual BERT model with weak supervision, using home-made CLIR training data derived from parallel corpora.  Eksperimentiniai Lietuvos dokumentų surinkimo su trumpalaikiais anglų kalbos klausimais rezultatai rodo, kad mūsų model is yra veiksmingas ir atitinka konkurencinius pagrindinius metodus.', 'no': 'Fleire neuralspråk-modeller er utvikla nyleg, f.eks. BERT og XLNet, og oppnådd uttrykkelige resultat i ulike NLP-oppgåver, inkludert setningsklassifikasjon, spørsmål og dokumentranking. I denne papiret utforskar vi bruken av den populære bidireksjonale språk-modellen BERT for å modellere og lære relevansen mellom engelske spørjingar og eksternspråk-dokument i oppgåva for å henta krysspråk-informasjon. Ein dyp tilsvarende modell basert på BERT vert introdusert og trent ved å finne ein fleirspråk BERT-modell med slag overvåking med hjemmeutvikling av CLIR-opplæringsdata fra parallelle korpora. Eksperimentale resultat av henting av Litauiske dokument mot korte engelske spørsmål viser at modellen vår er effektiv og utfører den konkurentære baseline tilnærminga.', 'mt': 'Dan l-aħħar ġew żviluppati bosta mudelli ta’ lingwi newrali, pereżempju BERT u XLNet, u kisbu riżultati impressjonanti f’diversi kompiti NLP inklużi l-klassifikazzjoni tas-sentenzi, it-tweġiba g ħall-mistoqsijiet u l-klassifikazzjoni tad-dokumenti. F’dan id-dokument, aħna nesploraw l-użu tal-mudell popolari tal-lingwa bidirezzjonali, BERT, biex nimmudellaw u nitgħallmu r-rilevanza bejn mistoqsijiet Ingliżi u dokumenti tal-lingwa barranija fil-kompitu tal-ġbir ta’ informazzjoni translingwistika. Jiġi introdott u mħarreġ mudell ta’ tqabbil ta’ rilevanza profonda bbażat fuq il-BERT billi jiġi ffinalizzat mudell ta’ BERT multilingwi mħarreġ minn qabel b’superviżjoni dgħajfa, bl-użu ta’ dejta ta’ taħriġ CLIR magħmula mid-dar derivata minn korpora parallel a. Ir-riżultati esperimentali tal-ġbir tad-dokumenti Litwani kontra mistoqsijiet qosra bl-Ingliż juru li l-mudell tagħna huwa effettiv u jaqbeż l-approċċi kompetittivi tal-linja bażi.', 'mn': 'Сүүлийн үед олон мэдрэлийн хэл загварууд хөгжүүлсэн. Жишээ нь BERT болон XLNet, олон NLP даалгаваруудын үр дүнг олон хэлбэрүүдийн хуваарилалт, асуулт хариулт болон баримт дүрслэлүүдийн тухай гаргасан. Энэ цаасан дээр бид олон хүн төрөлхтний хэл загварын хэрэглээ, БЕРТ, Англи хэл болон гадаад хэл баримтуудын хоорондох чухал байдлыг олон хэл мэдээллийг авах ажил дээр судалж байна. BERT-ын үндсэн гүн гүнзгий холбоотой загвар багтана. БЕРТ хэлний олон хэлний загварыг сул хязгаарлагддаг, гэр бүлийн CLIR сургалтын өгөгдлийг параллел корпоратаас гаргасан. Литва баримтуудын туршилтын үр дүн нь богино Англи хэлний асуултын эсрэг бидний загвар нь үр дүнтэй болон өрсөлдөг суурь шугамын ойлголтыг илүү үр дүнтэй гэдгийг харуулдаг.', 'pl': 'Ostatnio opracowano wiele modeli języka neuronowego, np. BERT i XLNet, które osiągnęły imponujące wyniki w różnych zadaniach NLP, w tym klasyfikacji zdań, odpowiedzi na pytania i rankingu dokumentów. W niniejszym artykule badamy wykorzystanie popularnego dwukierunkowego modelu języka BERT do modelowania i poznania znaczenia między zapytaniami angielskimi a dokumentami obcymi w zadaniu wielojęzycznego pozyskiwania informacji. Model dopasowania głębokiego znaczenia oparty na BERT został wprowadzony i przeszkolony poprzez dostrojenie wstępnie przeszkolonego wielojęzycznego modelu BERT ze słabym nadzorem, wykorzystując domowe dane treningowe CLIR pochodzące z równoległych korpusów. Wyniki eksperymentalne pobierania litewskich dokumentów na podstawie krótkich zapytań angielskich pokazują, że nasz model jest skuteczny i przewyższa konkurencyjne podejście bazowe.', 'so': "Dhab ahaantii waxaa la horumariyey tusaale ahaan BERT iyo XLNet, waxaana la helay shaqooyin la yaab leh oo kala duduwan oo ah fasaxa qoraalka, su'aalka jawaabta iyo warqada qoraalka. Qoraalkan waxaynu ka baaraannaa isticmaalka modelka luuqada ee maarufu, BERT, si aan u sameyno sameyno oo aan u barno faa’iidada u dhexeeya su'aalaha ingiriisiga iyo dukumentiyada luuqadaha dibadda ah ee xafiiska u qaadashada macluumaadka luuqadaha kala duwan. Tusaale aad u muhiimsan oo u eg BERT, waxaa lagu soo bandhigaa oo lagu tababariyaa fineturing model ah oo af luuqadeed ah oo ka soo hor jeeday BERT, kaas oo lagu isticmaalaa macluumaad waxbarasho oo ku qoran qoyska lambarka ah. Imtixaanka la soo saaray dukumentiyada Lithuaniya oo ka gees ah su'aalaha Ingiriiska gaaban waxay muujinayaan in modellkayagu uu shaqeeyo oo uu ka muujiyaa qaabilaada hoose-bannaanta.", 'ro': 'Mai multe modele de limbaj neural au fost dezvoltate recent, de exemplu BERT și XLNet, și au obținut rezultate impresionante în diferite sarcini PNL, inclusiv clasificarea propozițiilor, răspunsul la întrebări și clasificarea documentelor. În această lucrare, explorăm utilizarea modelului popular de limbă bidirecțională, BERT, pentru a modela și a învăța relevanța dintre interogările în limba engleză și documentele în limba străină în sarcina de recuperare a informațiilor translingvistice. Un model de potrivire cu relevanță profundă bazat pe BERT este introdus și instruit prin ajustarea fină a unui model BERT multilingv pre-instruit cu supraveghere slabă, utilizând date de instruire CLIR realizate acasă derivate din corpore paralele. Rezultatele experimentale ale extragerii documentelor lituaniene în raport cu interogările scurte în limba engleză arată că modelul nostru este eficient și depășește abordările de bază competitive.', 'sv': 'Flera neurala språkmodeller har utvecklats nyligen, t.ex. BERT och XLNet, och uppnått imponerande resultat i olika NLP-uppgifter inklusive meningsklassificering, frågesvar och dokumentrankning. I den här uppsatsen undersöker vi användningen av den populära tvåriktade språkmodellen BERT för att modellera och lära oss relevansen mellan engelska frågor och främmande språk dokument i uppgiften att korspråkig informationssökning. En djuprelevant matchningsmodell baserad på BERT introduceras och utbildas genom finjustering av en förtränad flerspråkig BERT-modell med svag övervakning, med hjälp av hemgjord CLIR-träningsdata som härrör från parallella korpor. Experimentella resultat av inhämtning av litauiska dokument mot korta engelska frågor visar att vår modell är effektiv och överträffar de konkurrensutsatta baslinjerna.', 'ta': 'சமீபத்தில், பிரெட் மற்றும் XLNet பல புதிய மொழி மாதிரிகள் உருவாக்கப்பட்டது, வாக்கு வகைப்படுத்தல், கேள்வி பதில் மற்றும் ஆவணம் வரிசைப்படுத்தல் உள்ள வேண்டிய In this paper, we explore the use of the popular bidirectional language model, BERT, to model and learn the relevance between English queries and foreign-language documents in the task of cross-lingual information retrieval.  BERT அடிப்படையில் அடிப்படையிலான ஒரு ஆழமான தொடர்பு பொருத்தும் மாதிரி பின்துவிடும் பயிற்சி செய்யப்படுகிறது ஒரு முன்னேற்றப்பட்ட பல மொழி பிரெட் மாதிர சிறிய ஆங்கில கேள்விகளுக்கு எதிராக லித்துவேனிய ஆவணங்கள் மீட்டெடுப்பதின் சோதனையின் முடிவு', 'si': 'විශාල භාෂාවක් මොඩේල් අවස්ථානය කරලා තියෙනවා, උදාහරණයෙන්, BERT සහ XLNet, සහ විශාල ප්\u200dරතිචාරයක් සම්බන්ධ විදිහට NLP වැඩේ  මේ පත්තරේ අපි පරීක්ෂා කරනවා ප්\u200dරජාතික භාෂාව ප්\u200dරමාණය, BERT, ඉංග්\u200dරීසි ප්\u200dරශ්නය සහ විදේශ භාෂාව ප්\u200dරශ්නය සඳහා ප්\u200dරශ්නය විද BERT සඳහා අධිරූපයෙන් ගොඩක් විශ්වාසය සම්බන්ධ විදියට සම්බන්ධ විදියට සහ ප්\u200dරධානය කරලා තියෙනවා සහ ප්\u200dරධානය කරලා තියෙනවා ප්\u200dරීට්\u200dර ලිතුවානියා ලිතුවානියා දත්ත පිළිගන්න පුළුවන් පරීක්ෂණ ප්\u200dරශ්නයක් පෙන්වන්න පුළුවන් කියලා අපේ මොඩේල් ප්\u200d', 'sr': 'Nedavno su razvijene višestruke neuralne jezičke modele, npr. BERT i XLNet, i postigle impresivne rezultate u različitim zadacima NLP-a, uključujući klasifikaciju rečenica, odgovor na pitanja i ranking dokumenta. U ovom papiru istražujemo korištenje popularnog dvoričnog jezičkog modela BERT-a da modeliramo i naučimo važnost između engleskih ispitivanja i stranih jezičkih dokumenta u zadatku prikupljanja preko jezika informacija. Duboko odgovarajući model koji se temelji na BERT-u predstavlja se i obučava finetuniranjem multijezičkog model a BERT-a sa slabim nadzorom, koristeći podatke o obuci CLIR-a iz paralelnog korporacije. Eksperimentalni rezultati prikupljanja Litvanskih dokumenta protiv kratkih engleskih ispitivanja pokazuju da je naš model efikasan i nadmašuje konkurentne osnovne pristupe.', 'ur': 'بہت سی نئورل زبان موڈل اچھے وقت تک گھیرے گئے ہیں، جیسے BERT اور XLNet، اور مختلف NLP تاسکیوں میں اثر انگیز نتیجے پہنچ گئے ہیں جن میں sentence classification, question replying and document ranking شامل ہوتے ہیں. ہم اس کاغذ میں مشهور مشهور زبان کی مدل BERT کے استعمال کا مطابق محسوس کرتے ہیں اور انگلیسی سوال اور غریب زبان کے لاسومالک کے درمیان مشتبہ کی تعلیم لیتے ہیں BERT پر بنیاد رکھا ہوا ایک عمیق مرتبہ مولڈ معلوم ہوتا ہے اور تدریس کی جاتی ہے ایک نرمی زبانی BERT مولڈ کے ساتھ کمزور نظر کے ساتھ، گھر کی CLIR تدریس ڈیٹ کے استعمال سے جو پارالی کورپور سے پائی جاتی ہے۔ لٹوئونی دکھانوں کو چھوٹی انگلیسی سوال کے مقابلہ میں لے جانے کے تجربے کا نتیجہ دکھاتا ہے کہ ہمارا موڈل اثبات ہے اور مسابقات بنسلین کے تقریبا سے زیادہ اثبات کرتا ہے.', 'uz': "Yaqinda bir nechta neyural tilning modellari, масалан BERT va XLNet yaratildi, va sentence classification, саволлар ва ҳужжат кўчирилиши орасида кўп NLP вазифалари мувофиқлик natijalariga muvaffaqiyatli bajardi. Bu hujjatda biz bir necha tillar modeli BERT, modeli va ingliz savollari va foreign tillar hujjatlari орасида muhimligni o'rganamiz va o'rganamiz, har xil tildagi maʼlumot olish vazifasidagi vazifa. Name Lithuaniya hujjatlarini qisqa ingliz savollariga olishni tajriba qilish natijalari esa modelmiz ishlaydi va rivojlanadigan foydalanish natijalarini bajaradi.", 'vi': 'Đã phát triển nhiều mô hình ngôn ngữ thần kinh đã được phát triển g ần đây, v.d. BERT và Xylonet, và đã đạt được nhiều kết quả gây ấn tượng trong các nhiệm vụ lập trình độc quyền, gồm phân loại bản án, câu hỏi trả lời và xếp hạng tài liệu. Trong tờ giấy này, chúng tôi khám phá cách sử dụng mô hình ngôn ngữ hai trực tiếp nổi tiếng, BERT, để mô tả và học được sự liên quan giữa các câu hỏi của người Anh và các tài liệu ngoại ngữ trong nhiệm vụ thu thập thông tin xuyên ngôn ngữ. Một mô hình liên kết đầy liên quan dựa trên BERT được đưa vào và được huấn luyện bằng cách tinh chỉnh một mô hình ALT hảo hạng trẻ với sự giám sát kém, sử dụng các dữ liệu giáo huấn kiểu CliR sản xuất từ nhóm song song. Kết quả thử nghiệm của việc lấy tài liệu Hy Lạp để chống lại những câu hỏi ngắn của Anh cho thấy mô hình của chúng ta hiệu quả và hoàn thiện các phương pháp cơ bản cạnh tranh.', 'bg': 'Наскоро бяха разработени множество невронни езикови модели, например BERT и XLNet, и постигнаха впечатляващи резултати в различни задачи на НЛП, включително класификация на изречения, отговор на въпроси и класиране на документи. В настоящата статия изследваме използването на популярния двупосочен езиков модел за моделиране и изучаване на релевантността между английските заявки и чуждоезикови документи в задачата за междуезично извличане на информация. Модел за съвпадение с дълбока релевантност, базиран на BERT, е въведен и обучен чрез фина настройка на предварително обучен многоезичен BERT модел с слаб надзор, като се използват домашни данни за обучение, получени от паралелни корпуси. Експерименталните резултати от извличането на литовски документи срещу кратки английски запитвания показват, че нашият модел е ефективен и превъзхожда конкурентните базови подходи.', 'da': 'Flere neurale sprogmodeller er blevet udviklet for nylig, f.eks. BERT og XLNet, og opnåede imponerende resultater i forskellige NLP-opgaver, herunder sætningsklassificering, spørgsmål besvarelse og dokumentranking. I denne artikel undersøger vi brugen af den populære bidirektionelle sprogmodel, BERT, til at modellere og lære relevansen mellem engelske forespørgsler og fremmedsproglige dokumenter i opgaven med tværsproget informationssøgning. En dyb relevans matchingsmodel baseret på BERT introduceres og trænes ved at finjustere en forudtrænet flersproget BERT-model med svag overvågning ved hjælp af hjemmelavede CLIR-træningsdata fra parallelle korpora. Eksperimentelle resultater af hentning af litauiske dokumenter mod korte engelske forespørgsler viser, at vores model er effektiv og overgår konkurrencebaserede tilgange.', 'nl': "Recent zijn meerdere neurale taalmodellen ontwikkeld, zoals BERT en XLNet, en behaalden indrukwekkende resultaten in verschillende NLP-taken, waaronder zinsclassificatie, vragenantwoord en documentranking. In dit artikel onderzoeken we het gebruik van het populaire bidirectionele taalmodel, BERT, om de relevantie tussen Engelse query's en vreemde talen documenten te modelleren en te leren in de taak van cross-lingual information retrieval. Een diepgaande relevantie matching model gebaseerd op BERT wordt geïntroduceerd en getraind door een vooraf getraind meertalig BERT model met zwak toezicht te finetunen, met behulp van zelfgemaakte CLIR trainingsdata afgeleid van parallelle corpora. Experimentele resultaten van het ophalen van Litouwse documenten aan de hand van korte Engelse vragen tonen aan dat ons model effectief is en beter presteert dan de concurrerende baseline benaderingen.", 'hr': 'Nedavno se razvijaju višestruki neuronski modeli, npr. BERT i XLNet, i postigli su impresivni rezultati raznih zadataka NLP-a uključujući klasifikaciju kazne, odgovor na pitanja i poziciju dokumenta. U ovom papiru istražujemo korištenje popularnog bidirektivnog jezičkog modela BERT-a kako bi modeli i naučili važnost između engleskih ispitivanja i stranih jezičkih dokumenta u zadatku prikupljanja transjezičkih informacija. Duboko odgovarajući model na temelju BERT-a uvodi se i obučava finetuniranjem multijezičkog modela BERT-a s slabim nadzorom, koristeći podatke o obuci CLIR-a iz paralelnog tijela. Eksperimentalni rezultati prikupljanja Litvanskih dokumenta protiv kratkih engleskih ispitivanja pokazuju da je naš model učinkovit i nadmašuje konkurentne početne pristupe.', 'de': 'In jüngster Zeit wurden mehrere neuronale Sprachmodelle entwickelt, z.B. BERT und XLNet, und erzielten beeindruckende Ergebnisse bei verschiedenen NLP-Aufgaben einschließlich Satzklassifizierung, Fragebeantwortung und Dokumentenranking. In diesem Beitrag untersuchen wir die Verwendung des beliebten bidirektionalen Sprachmodells BERT, um die Relevanz zwischen englischen Abfragen und fremdsprachigen Dokumenten bei der Aufgabe des crosslingualen Informationsabrufs zu modellieren und zu erlernen. Ein tiefes Relevanz-Matching-Modell basierend auf BERT wird eingeführt und trainiert, indem ein vortrainiertes mehrsprachiges BERT-Modell mit schwacher Supervision unter Verwendung von hausgemachten CLIR-Trainingsdaten aus parallelen Korpora verfeinert wird. Experimentelle Ergebnisse des Abrufs litauischer Dokumente anhand kurzer englischer Abfragen zeigen, dass unser Modell effektiv ist und die wettbewerbsfähigen Baseline-Ansätze übertrifft.', 'id': 'Beberapa model bahasa saraf telah dikembangkan baru-baru ini, misalnya BERT dan XLNet, dan mencapai hasil yang mengesankan dalam berbagai tugas NLP termasuk klasifikasi kalimat, jawaban pertanyaan dan ranking dokumen. Dalam kertas ini, kami mengeksplorasi penggunaan model bahasa bidireksi populer, BERT, untuk model dan belajar relevansi antara pertanyaan Inggris dan dokumen bahasa asing dalam tugas pencarian informasi saling bahasa. Model yang cocok dengan relevansi dalam berdasarkan BERT diperkenalkan dan dilatih dengan memperbaiki model BERT berbagai bahasa dengan pengawasan yang lemah, menggunakan data pelatihan CLIR dibuat rumah yang berasal dari corpora paralel. Hasil eksperimen dari penemuan dokumen Lithuania melawan pertanyaan Inggris pendek menunjukkan bahwa model kita efektif dan melebihi pendekatan dasar kompetitif.', 'ko': '최근에는 BERT와 XLNet 등 다양한 신경 언어 모델을 개발했고 문장 분류, 문답, 문서 정렬 등 다양한 NLP 작업에서 인상적인 결과를 얻었다.본고에서 우리는 다중 언어 정보 검색 임무에서 유행하는 양방향 언어 모델인 BERT를 이용하여 영어 검색과 외국어 문서 간의 관련성을 모델링하고 학습했다.BERT 기반의 깊이 관련 매칭 모델을 소개하고 평행 어료 라이브러리에서 나온 자체 제작 CLIR 훈련 데이터를 이용하여 약한 감독을 가진 예비 훈련 다중 언어 BERT 모델을 미세하게 조정했다.리투아니아어 문서의 짧은 영어 조회 검색 실험 결과에 의하면 우리의 모델은 효과적이고 경쟁적인 기선 방법보다 우수하다는 것을 알 수 있다.', 'fa': 'مدل های مختلف زبان عصبی اخیرا توسعه داده شده است، مثال BERT و XLNet، و نتیجه های تاثیر انگیز در کار های مختلف NLP، شامل classification of sentence, answer questions and document ranking achieved. در این کاغذ، ما استفاده از مدل زبان معروف، BERT، برای مدل و یاد گرفتن ارتباط بین سوال\u200cهای انگلیسی و مدارک\u200cهای زبان خارجی در کار بازیابی اطلاعات مختلف زبان کشف می\u200cکنیم. یک مدل متفاوت عمیق بر اساس BERT با توجه به مدل BERT چندین زبان با نظارت ضعیف، با استفاده از داده های آموزش CLIR ساخته شده از شرکت متفاوت معرفی و آموزش می شود. نتیجه\u200cهای تجربه\u200cای از بازیافت مدارک\u200cهای لیتوانی بر خلاف سوال\u200cهای کوتاه انگلیسی نشان می\u200cدهند که مدل ما موثر است و بیشتر از نزدیک\u200cهای پایین مسابقه\u200cای انجام می\u200cدهد.', 'sw': 'Mifano mingi ya lugha za kiutaratibu hivi karibuni imetengenezwa, kwa mfano BERT na XLNet, na imepata matokeo ya vizuri katika kazi mbalimbali za NLP ikiwa ni pamoja na usambazaji wa hukumu, maswali yanayojibu na nyaraka. Katika karatasi hii, tunachunguza matumizi ya muundo maarufu wa lugha za kigeni, BERT, kuunda na kujifunza umuhimu kati ya maswali ya Kiingereza na nyaraka za lugha za kigeni katika kazi ya kupata taarifa za lugha mbalimbali. Mradi wenye umuhimu mkubwa unaohusiana na msingi wa BERT unaonyesha na kufundishwa kwa kuitengeneza mifano ya BERT ya lugha mbalimbali yenye ufuatiliaji dhaifu, kwa kutumia taarifa za mafunzo ya CLIR zilizotengenezwa nyumbani zinazotokana na kampuni isiyofanana. Matokeo ya majaribio ya kupelekwa kwa nyaraka za ki-Lithuania dhidi ya maswali machache ya Kiingereza yanaonyesha kuwa mtindo wetu una ufanisi na unaonyesha njia za msingi za kushindana.', 'tr': "Ýakynda birnäçe neiral dil nusgalary döredildi, mysal BERT we XLNet, we NLP täsirlerinde sözler klasifikasyýasy, sorag jogaplary we sened derejesinde täsirli netijesi berildi. Bu kagyzda, biz meýhur diýjek dil nusgasyny BERT'yň ullanyşyny çözýäris we iňlisçe soraglaryň we daşga dil senedleriniň çarpaz dil maglumatyny almak üçin örän wajyplygyny öwreýäris. BERT'a dayanan derin bir eşleşme modeli, parallel korporadan netijeli öýüne gatnaýan CLIR eğitim maglumatlaryny finetmäge tarapyn tanyşdyrylýar we eğitilýär. Litwanyň gysga iňlis soraglaryna garşy almanyň örän netijesi biziň nusgymyzyň täsirli we ýakyşy baz çyzgylyň golaýlaryny ýok edip barýandygyny görkez.", 'af': "Veelvuldige neuraltaal modele is onlangs ontwikkeld, bv. BERT en XLNet, en het inpresief resultate in verskillende NLP opdragte bereik, insluitend setklassifikasie, vraag antwoord en dokument rangering. In hierdie papier, ondersoek ons die gebruik van die populêre bidireksjonale taal model, BERT, om te model en leer die relevansie tussen Engelske vraag en vreemde-taal dokumente in die taak van kruistale inligting ontvang. 'n Deep relevansie ooreenstemmende model wat op BERT gebaseer is, is ingevoer en onderrig deur 'n voortrekende multitaal BERT model met swak supervisie te stel deur die gebruik van huis gemaakte CLIR onderriging data wat van parallele korpora afgelei word. Eksperimentele resultate van die ontvang van Lithuaniese dokumente teen kort Engelse vraagte vertoon dat ons model effektief is en uitvoer die mededingste basisline toegang.", 'sq': 'Modele të shumta gjuhësh nervore janë zhvilluar kohët e fundit, për shembull BERT dhe XLNet dhe kanë arritur rezultate mbresëlënëse në detyrat e ndryshme të NLP përfshirë klasifikimin e fjalëve, përgjigjen e pyetjeve dhe renditjen e dokumenteve. Në këtë letër, ne eksplorojmë përdorimin e modelit popullor të gjuhës dy-drejtues, BERT, për të modeluar dhe mësuar rëndësinë midis pyetjeve angleze dhe dokumenteve të gjuhës së huaj në detyrën e marrjes së informacionit ndërgjuhësor. Një model i rëndësishëm të thellë që përputhet me BERT futet dhe trajnohet duke përmirësuar një model BERT shumëgjuhës me mbikqyrje të dobët, duke përdorur të dhënat e trajnimit të CLIR të prodhuara nga korpra paralele. Rezultatet eksperimentale të marrjes së dokumenteve lituaneze kundër pyetjeve të shkurtra angleze tregojnë se modeli ynë është efektiv dhe ekziston më tepër se metodat konkurruese bazë.', 'am': 'በቅርብ ዘመን ብዙዎች የነዌብ ቋንቋዎች ምሳሌዎች፣ BERT እና XLNet ተደጋጅተዋል፡፡ በዚህ ገጽ፣ የቋንቋ ቋንቋ ምሳሌ፣ BERT፣ በንግግሊዝኛ ጠይቃዎች እና የውጭ ቋንቋ ቋንቋዎች ሰነዶች መካከል ግንኙነት ለመማር እና በተለይ ቋንቋ መረጃ ማግኘት ስርዓት እና ማርናለን፡፡ BERT የተቀመጠው የጥልቅ ግንኙነት ሞዴል በብዙ ቋንቋዎች የBERT ሞዴል በመፍጠር ያስተምራል፡፡ የሊቱአዊ ሰነዱን በአጭራሽ እንግሊዝኛ ጠያፊዎች ላይ የሚያስፈልገውን ፍጻሜ ሞዴሌያችን አካባቢ እና የተዋጋውን የጥረት ደረጃዎችን የሚያደርግ ነው፡፡', 'hy': 'Վերջերս բազմաթիվ նյարդային լեզվի մոդելներ են զարգացել, օրինակ BER և XLNet, և զարմանալի արդյունքներ են ստացել տարբեր ՆԼՊ-ի առաջադրանքներում, ներառյալ նախադասությունների դասակարգման, հարցերի պատասխանի և փաստաթ Այս թղթի մեջ մենք ուսումնասիրում ենք հայտնի երկու ուղղությամբ լեզվի մոդելի BER-ի օգտագործումը, որպեսզի մոդելավորենք և սովորենք անգլերեն հարցերի և օտարլեզվի փաստաթղթերի միջև կարևորությունը լեզվի միջև տեղեկատվության վերաբերյալ վեր BER-ի հիմքում հիմնված խորը կարևորությունը համապատասխանող մոդելը ներկայացվում է և վարժեցվում է նախկին վարժեցված բազմալեզու BER-ի մոդելը թույլ վերահսկողության միջոցով, օգտագործելով զուգահեռ կառուցվածքից ստացված տնային կա Experimental results of the retrieval of Lithuanian documents against short English queries show that our model is effective and outperforms the competitive baseline approaches.', 'bn': 'সম্প্রতি বেশ কয়েকটি নিউরেল ভাষার মডেল উন্নয়ন করা হয়েছে, যেমন বার্টি এবং এক্সএলেন্ট এবং বিভিন্ন এনএলপি কাজের ফলাফল অর্জন করেছে, যার মধ্যে ক্লাস্ফিকেশন, প্রশ্ এই কাগজটিতে আমরা জনপ্রিয় ভাষার মডেল ব্যবহার করি, বেরেটি। ইংরেজি প্রশ্ন এবং বিদেশী ভাষার তথ্য পুনরুদ্ধারের কাজে ইংরেজি প্রশ্ন এবং বিদেশী ভাষার নথীগ বেরেটির ভিত্তিতে ভিত্তিক একটি গভীর প্রযুক্তি মডেল তুলে ধরা হয় এবং প্রশিক্ষণ প্রদান করা হচ্ছে একটি প্রেমিক বহুভাষায় বেরেটি মডেল, যার দুর্বল পর্যবেক্ষণের মা সংক্ষিপ্ত ইংরেজি প্রশ্নের বিরুদ্ধে লিথুয়ানিয়ান নথি পুনরুদ্ধারের পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের মডেল কার্যকর এবং প্রতি', 'az': 'Son zamanlarda çoxlu nöral dil modelləri, bəzisi BERT və XLNet təşkil edilmişdir və cümlələr klasifikasyonu, sual cavab verməsi və dökümət səviyyəsi barəsində müxtəlif NLP işlərində təsirli sonuçlar yetişmişdir. Bu kağızda, məşhur ilk dil model in in, BERT modelinin istifadəsini keşfetirik və İngiliz suallarının və yabancı dil belələrinin çoxlu dil məlumatlarının alınmasını öyrənməsini öyrənirik. BERT vasitəsilə dəyişdirilmiş çoxlu dilli BERT modelini zəif gözləyir, paralel korporadan təhsil edilmiş CLIR təhsil məlumatlarını istifadə edərək təhsil edilir və təhsil edilir. Litvanlıq belələrini qısa İngilizə soruşmalarına qarşı almaq təcrübələrinin nəticəsi göstərir ki, modellərimiz etkilidir və müəllif səhifələrin yaxınlıqlarını aşırı çıxarır.', 'bs': 'Nedavno se razvijaju višestruki neuronski modeli, npr. BERT i XLNet, i postigli su impresivni rezultati u različitim zadacima NLP-a uključujući klasifikaciju kazne, odgovor na pitanja i poziciju dokumenta. U ovom papiru istražujemo korištenje popularnog bidirektivnog jezičkog modela BERT-a da modeliramo i naučimo važnost između engleskih ispitivanja i stranih jezičkih dokumenta u zadatku prikupljanja transjezičkih informacija. Duboko odgovarajući model koji se temelji na BERT-u predstavlja i obučava finetuniranjem multijezičkog model a BERT-a s slabim nadzorom, koristeći podatke o obuci CLIR-a iz paralelne korporacije. Eksperimentalni rezultati prikupljanja Litvanskih dokumenta protiv kratkih engleskih ispitivanja pokazuju da je naš model efikasan i nadmašuje konkurentne početne pristupe.', 'ca': "Recentment s'han desenvolupat múltiples models de llenguatge neural, per exemple BERT i XLNet, i han aconseguit resultats impressionants en diverses tasques del NLP, com la classificació de frases, la resposta a preguntes i la classificació de documents. En aquest article, explorem l'ús del model popular de llenguatge bidireccional BERT, per modelar i aprendre la pertinencia entre les preguntes angleses i els documents de llenguatge estranger en la tasca de la recuperació de informació translingüística. Un model de comparació de profunda relevància basat en BERT es introdueix i s'entrena finant un model de BERT multillenguatge pré-entrenat amb una supervisió dèbil, utilitzant dades de formació CLIR fetes a casa derivades de corpora parallela. Els resultats experimentals de la recuperació de documents lituanis en comparació amb preguntes curtes en anglès demostren que el nostre model és eficaç i supera els enfocaments de base competitius.", 'et': 'Hiljuti on välja töötatud mitmed närvikeele mudelid, nt BERT ja XLNet, mis on saavutanud muljetavaldavaid tulemusi erinevates NLP ülesannetes, sealhulgas lausete klassifitseerimine, küsimustele vastamine ja dokumentide järjestus. Käesolevas töös uurime populaarse kahesuunalise keelemudeli BERT kasutamist, et modelleerida ja õppida inglise päringute ja võõrkeelsete dokumentide asjakohasust keeleülese teabe hankimise ülesandes. BERT-il põhinev sügava asjakohasuse sobitamise mudel tutvustatakse ja koolitatakse, täpsustades eeltreenitud mitmekeelset BERT-mudelit nõrga järelevalvega, kasutades koduseid CLIR-koolitusandmeid, mis on saadud paralleelsetest korpustest. Leedu dokumentide kogumise eksperimentaalsed tulemused lühikeste inglise päringute vastu näitavad, et meie mudel on tõhus ja ületab konkurentsivõimelisi lähtepõhimõtteid.', 'cs': 'V poslední době bylo vyvinuto mnoho neuronových jazykových modelů, např. BERT a XLNet, a dosáhlo působivých výsledků v různých NLP úlohách včetně klasifikace vět, odpovědi na otázky a hodnocení dokumentů. V tomto článku se zabýváme využitím populárního obousměrného jazykového modelu BERT k modelování a naučení relevance mezi anglickými dotazy a cizími jazykovými dokumenty v úkolu vícejazyčného vyhledávání informací. Model hluboké relevance založený na BERT je představen a trénován jemným laděním předtrénovaného vícejazyčného modelu BERT se slabým dohledem za použití domácích CLIR tréninkových dat odvozených z paralelních korpusů. Experimentální výsledky vyhledávání litevských dokumentů na základě krátkých anglických dotazů ukazují, že náš model je efektivní a překonává konkurenční základní přístupy.', 'fi': 'Viime aikoina on kehitetty useita neurokielimalleja, esim. BERT ja XLNet, ja ne ovat saavuttaneet vaikuttavia tuloksia erilaisissa NLP-tehtävissä, kuten lauseiden luokittelussa, kysymyksiin vastaamisessa ja asiakirjojen luokittelussa. Tässä artikkelissa tarkastellaan suositun kaksisuuntaisen kielimallin, BERT:n, käyttöä englanninkielisten kyselyjen ja vieraskielisten asiakirjojen välisen merkityksen mallintamiseen ja oppimiseen monikielisessä tiedonhaussa. BERT-malliin perustuva syvän relevanssin täsmäytysmalli esitellään ja koulutetaan hienosäätämällä esikoulutettua monikielistä BERT-mallia heikolla ohjauksella käyttäen kotitekoista CLIR-harjoitusdataa rinnakkaisista korpusista. Kokeelliset tulokset liettualaisten asiakirjojen hakemisesta lyhyihin englanninkielisiin kyselyihin osoittavat, että mallimme on tehokas ja ylittää kilpailukykyiset lähtökohdat.', 'ha': "An buɗe misãlai masu yawa na harshen neural a yanzu, misali BERT da XLNet, kuma an sami matsala masu fassara cikin aikin NLP masu yawa, kamar fasalin kalmar, mai tambaya da takardar ta ranar. Ga wannan takardan, Munã yin amfani da misalin misalin harshe na ƙaranci, BERT, zuwa motsi da za'a sanar da muhimmada a tsakanin tambayar Ingiriya da takardar harshe na daban-harshe cikin aikin da za'a samu'a motsar information na fassarar-lingui. An introduce da wata motel mai girma mai daidaita matsayin BERT a kan ƙananan BERT na gane shi kuma aka sanar da shi da finfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinfinufa da misalin multilala mai rauni na tsari, a yi amfani da data mai tsarin CLIR da aka samar da shi na sami- Matarin jarrabãwa na motsar takardar Litbaniyan ko kuma kure masu ƙaranci na Ingiriya ya nuna cewa misalinmu yana da amfani da kuma yana samar da hanyoyin bastarwa.", 'jv': 'modells Nang pepulan iki, awak dhéwé iso nggunakake usaha banjur ing model sing populer, BERT, nggawe modèl lan nggambar aturan ingkang karo perusahaan kanggo ngerasakno kesempatan lan dokumen sing itlanjut-ingkang karo pawaran kuwi nggawe informasi tanggal bantuan. Text Rejalaké sing paling nggambar dokumen Liwatan kuwi nggambar aturan pangan Inggris neng akeh barang nggawe modèl kuwi nggawe efek dan nggawe barang apik sing apik dhéwé.', 'sk': 'Pred kratkim so bili razviti več modelov nevronskih jezikov, npr. BERT in XLNet, ki so dosegli impresivne rezultate pri različnih nalogah NLP, vključno z razvrščanjem stavkov, odgovarjanjem na vprašanja in razvrščanjem dokumentov. V tem prispevku raziskujemo uporabo priljubljenega dvosmernega jezikovnega modela BERT za modeliranje in učenje relevantnosti angleških poizvedb in dokumentov v tujem jeziku v nalogi medjezičnega pridobivanja informacij. Model usklajevanja z globoko relevantnostjo, ki temelji na BERT, je uveden in usposobljen z natančnim nastavitvijo predtreniranega večjezičnega BERT modela s šibkim nadzorom, z uporabo domačih podatkov o usposabljanju CLIR iz vzporednih korpusov. Eksperimentalni rezultati pridobivanja litovskih dokumentov v primerjavi s kratkimi angleškimi poizvedbami kažejo, da je naš model učinkovit in presega konkurenčne osnovne pristope.', 'he': 'מודלים רבים של שפת עצבית פותחו לאחרונה, למשל BERT ו XLNet, והשגשו תוצאות מרשים במשימות NLP שונות כולל שיעור משפטים, עניין שאלות ודורג מסמכים. In this paper, we explore the use of the popular bidirectional language model, BERT, to model and learn the relevance between English queries and foreign-language documents in the task of cross-lingual information retrieval.  מודל תואמת עמוקה שמבוסס על BERT מוצג ומאמן על ידי מינוי מודל BERT רב-שפתי מתאמן מראש עם פיקוח חלש, בשימוש נתוני אימון CLIR עשוי בבית שנוצר מקצועי. תוצאות ניסיוניות של השיגת מסמכים ליטאנים נגד שאלות אנגליות קצרות מראות שהמודל שלנו יעיל ומעביר את הגישויים המתחרים.', 'bo': 'འཕྲལ་གསོག་སྐད་ཡིག་གཟུགས་ཀྱི་དཔེ་གཞི་འདྲ་ཞིག་དག་བརྗོད་པ་ཡིན། དཔེར་ན། BERT དང་ XLNet དང་། achieved impressive results in various NLP tasks including sentence classification, question answering and document ranking. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ཆ་འཕྲིན་གྱི་སྐད་ཡིག་གི་མིག་གཟུགས་བཀོད་སྤྱོད་ཀྱི་ནང་དུ་ལྟ་བུ་ཞིབ་དཔྱད་བྱས་ནས་དབྱིན་ཡིག་གཟུགས་དང་ཕྱི་སྐད་ཡི A deep relevance matching model based on BERT is introduced and trained by finetuning a pretrained multilingual BERT model with weak supervision, using home-made CLIR training data derived from parallel corpora. ལི་ཐུ་ཡུལ་གྱི་ཡིག་ཆ་ཚོར་ངེས་པར'}
{'en': 'A Comparison of Unsupervised Methods for Ad hoc Cross-Lingual Document Retrieval', 'ar': 'مقارنة بين الطرق غير الخاضعة للإشراف لاسترجاع المستندات عبر اللغات المخصصة', 'es': 'Comparación de métodos no supervisados para la recuperación ad hoc de documentos multilingües', 'pt': 'Uma comparação de métodos não supervisionados para recuperação ad hoc de documentos entre idiomas', 'fr': 'Comparaison des méthodes non supervisées pour la récupération ad hoc de documents multilingues', 'ja': '臨機応変なクロスリンガル文書検索のための監督されていない方法の比較', 'hi': 'तदर्थ क्रॉस-लिंगुअल दस्तावेज़ पुनर्प्राप्ति के लिए असुरक्षित विधियों की तुलना', 'ru': 'Сравнение неконтролируемых методов специального межъязыкового поиска документов', 'zh': '用临时跨语言文档检索无监督之法较之', 'ga': 'Comparáid idir Modhanna Gan Maoirseacht chun Doiciméad a Aisghabháil Trastheangach ad hoc', 'ka': 'Ad hoc კროსლიგუალური დოკუმენტის მიღებისთვის შემდგომარებაName', 'hu': 'A felügyelet nélküli módszerek összehasonlítása az ad hoc nyelvű dokumentumok lekéréséhez', 'el': 'Σύγκριση μη εποπτευόμενων μεθόδων για την ad hoc διαγλωσσική ανάκτηση εγγράφων', 'it': 'Confronto dei metodi non controllati per il recupero di documenti interlinguali ad hoc', 'kk': 'Ad hoc- тілікті біріктірілген құжатты алу үшін сақталмаған әдістердің салыстыруыName', 'lt': 'Neprižiūrimų ad hoc tarpkalbinių dokumentų gavimo metodų palyginimas', 'mk': 'A Comparison of Unsupervised Methods for Ad hoc Cross-Lingual Document Retrieval', 'ms': 'Comparison of Unsupervised Methods for Ad hoc Cross-Lingual Document Retrieval', 'ml': 'ആദി ഹോക്ക് ക്രോസ്- ലിങ്ഗുവല്\u200d രേഖയുടെ തിരിച്ചുവരുത്തുന്നതിനായി നിരീക്ഷിക്കപ്പെടാത്ത മാറ്റങ്ങളു', 'mn': 'Ad hoc Cross-Lingual Document Retrieval-ын төлөвлөгөөгүй аргын харьцуулалт', 'mt': 'Tqabbil ta’ Metodi Mhux Sorveljati għall-Qbid ad hoc ta’ Dokumenti Translingwi', 'no': 'Name', 'ro': 'O comparație a metodelor nesupravegheate pentru recuperarea ad-hoc a documentelor interlingvistice', 'pl': 'Porównanie niekontrolowanych metod doraźnego pobierania dokumentów wielojęzycznych', 'sr': 'Uspoređenje neodržavanih metoda za prikupljanje Ad hoc krstoLingualnog dokumenta', 'si': 'Name', 'so': 'A Comparison of Unsupervised Methods for Ad hoc Cross-Lingual Return document', 'sv': 'En jämförelse av icke övervakade metoder för ad hoc-överskridande dokumenthämtning', 'ta': 'A Comparison of Unwatched Methods for Ad hoc Cross- Lingual Document Retrieval', 'ur': 'Ad hoc Cross-Lingual Document Retrieval کے لئے ناپابندی طریقے کا مقایسہ', 'uz': 'Name', 'vi': 'Sự so sánh của các phương pháp chưa được giám sát về."', 'bg': 'Сравнение на неконтролирани методи за ad hoc междулингвистично извличане на документи', 'hr': 'Uspoređenje neodržavanih metoda za prikupljanje ad hoc krstojezičkog dokumenta', 'nl': 'Een vergelijking van niet-begeleide methoden voor ad hoc cross-lingual documentopvraging', 'da': 'En sammenligning af ikke-kontrollerede metoder til ad hoc tværsproget dokumenthentning', 'de': 'Ein Vergleich unbeaufsichtigter Methoden für die Ad-hoc-sprachliche Dokumentenerfassung', 'id': 'A Comparison of Unsupervised Methods for Ad hoc Cross-Lingual Document Retrieval', 'fa': 'Name', 'ko': '무감독 다중 언어 문서 검색 방법의 비교', 'sw': 'Kilinganisho cha njia zisizothibitiwa kwa ajili ya Hukumu ya Msalaba wa Kiasili', 'tr': 'Ad hoc Çapr-Dilli Sened Mazmuny üçin Mazmunyzlyksyz Metinlerin Karşılaştyrma', 'sq': 'Një krahasim i Metodave të Pambikqyrura për marrjen e Dokumentit Ad hoc Ndërgjuhësor', 'af': 'Name', 'am': 'ሰነድ', 'hy': 'Comment', 'bn': 'আদি হোক ক্রস- লিঙ্গুয়াল ডকুমেন্ট পুনরুদ্ধারের জন্য অপারেশনযোগ্য পদ্ধতির তুলনা', 'az': 'Ad hoc Xərc Dilli Dökümat alması üçün müəyyən edilməmiş Methodlərin Karşılaşdırması', 'cs': 'Porovnání nedozorovaných metod pro ad hoc crosslingvální vyhledávání dokumentů', 'et': 'Kontrollimata meetodite võrdlus ad hoc keeleülese dokumendi hankimiseks', 'bs': 'Uspoređenje neodređenih metoda za prikupljanje Ad hoc krstoLingualnog dokumenta', 'ca': 'A Comparison of Unsupervised Methods for Ad hoc Cross-Lingual Document Retrieval', 'fi': 'Kontrolloimattomien menetelmien vertailu kielienvälisessä asiakirjojen hakemisessa', 'ha': 'KCharselect unicode block name', 'jv': 'A Compreson of Unlimited Methods for AdvHoc Krot-Lingul document retription', 'sk': 'Primerjava nenadzorovanih metod za ad hoc medjezikovno pridobivanje dokumentov', 'he': 'שיוון של שיטות ללא השגחה להשיג מסמכים צלולוגיים ad hoc', 'bo': 'Ad hoc Cross-Lingual ཡི་གེ་ལེན་སྤྱོད་པར་ཉར་མེད་པའི་ཐབས་ལམ་ལ་མཉམ་འབྱུང་བ'}
{'en': 'We address the problem of linking related documents across languages in a multilingual collection. We evaluate three diverse unsupervised methods to represent and compare documents : (1) multilingual topic model ; (2) cross-lingual document embeddings ; and (3) Wasserstein distance. We test the performance of these methods in retrieving news articles in Swedish that are known to be related to a given Finnish article. The results show that ensembles of the methods outperform the stand-alone methods, suggesting that they capture complementary characteristics of the documents', 'fr': "Nous abordons le problème de la liaison de documents connexes dans différentes langues au sein d'une collection multilingue. Nous évaluons trois méthodes différentes non supervisées pour représenter et comparer des documents\xa0: (1) modèle thématique multilingue\xa0; (2) intégration de documents multilingues\xa0; et (3) distance de Wasserstein. Nous testons les performances de ces méthodes pour récupérer des articles de presse en suédois connus pour être liés à un finnois donné Les résultats montrent que les ensembles de méthodes surpassent les méthodes autonomes, suggérant qu'ils capturent les caractéristiques complémentaires des documents", 'ar': 'نعالج مشكلة ربط المستندات ذات الصلة عبر اللغات في مجموعة متعددة اللغات. نقوم بتقييم ثلاث طرق متنوعة غير خاضعة للإشراف لتمثيل ومقارنة المستندات: (1) نموذج موضوع متعدد اللغات ؛ (2) وثائق الزواج عبر اللغات ؛ و (3) مسافة Wasserstein: نقوم باختبار أداء هذه الأساليب في استرجاع المقالات الإخبارية باللغة السويدية المعروفة بأنها مرتبطة بمقال فنلندي معين ، وتظهر النتائج أن مجموعات الطرق تتفوق في الأداء على الطرق المستقلة ، مما يشير إلى أنها التقاط الخصائص التكميلية للوثائق', 'pt': 'Abordamos o problema de vincular documentos relacionados entre idiomas em uma coleção multilíngue. Avaliamos três métodos não supervisionados diversos para representar e comparar documentos: (1) modelo de tópico multilíngue; (2) incorporação de documentos em vários idiomas; e (3) distância de Wasserstein. Testamos o desempenho desses métodos na recuperação de artigos de notícias em sueco que se sabe estarem relacionados a um determinado artigo finlandês. Os resultados mostram que os conjuntos dos métodos superam os métodos independentes, sugerindo que eles capturar características complementares dos documentos', 'es': 'Abordamos el problema de vincular documentos relacionados entre idiomas en una colección multilingüe. Evaluamos tres métodos diferentes no supervisados para representar y comparar documentos: (1) modelo de tema multilingüe; (2) incrustación de documentos en varios idiomas; y (3) distancia de Wasserstein. Probamos el rendimiento de estos métodos para recuperar artículos de noticias en sueco que se sabe que están relacionados con un finlandés determinado Artículo.Los resultados muestran que los conjuntos de los métodos superan a los métodos independientes, lo que sugiere que capturan características complementarias de los documentos', 'ja': '多言語コレクションで関連するドキュメントを複数の言語にリンクする問題に取り組んでいます。私たちは、文書を表現および比較するための3つの多様な無監督の方法を評価します。（ 1 ）多言語トピックモデル、（ 2 ）クロスリンガル文書埋め込み、（ 3 ）ワッサーシュタイン距離。私たちは、特定のフィンランドの記事に関連することが知られているスウェーデン語のニュース記事を取得するためのこれらの方法のパフォーマンスをテストします。結果は、これらの方法のアンサンブルが単独の方法よりも優れていることを示し、それらが文書の相補的な特徴を捉えていることを示唆します。', 'zh': '多言合语链接相关文档事。 臣等评估三无监督之法,以示较文档:(1)多言主题模形。 (2)跨语言文档嵌; 去(3)瓦瑟斯坦。 试检已知关特定芬兰瑞典语新闻。 结果表明者,合优于独立,明其得文档之互补也。', 'ru': 'Мы решаем проблему увязки соответствующих документов между языками в многоязычной подборке. Мы оцениваем три различных неконтролируемых метода представления и сравнения документов: (1) многоязычная тематическая модель; (2) кросс-лингвистические вложения документов; и (3) расстояние Вассерштейна. Мы проверяем эффективность этих методов в извлечении новостных статей на шведском языке, которые, как известно, связаны с данной финской статьей. Результаты показывают, что совокупности методов превосходят отдельные методы, предполагая, что они отражают дополнительные характеристики документов', 'hi': 'हम एक बहुभाषी संग्रह में भाषाओं में संबंधित दस्तावेजों को जोड़ने की समस्या को संबोधित करते हैं। हम दस्तावेजों का प्रतिनिधित्व करने और तुलना करने के लिए तीन विविध असुरक्षित तरीकों का मूल्यांकन करते हैं: (1) बहुभाषी विषय मॉडल; (2) क्रॉस-लिंगुअल दस्तावेज़ एम्बेडिंग; और (3) Wasserstein दूरी. हम स्वीडिश में समाचार लेखों को पुनः प्राप्त करने में इन विधियों के प्रदर्शन का परीक्षण करते हैं जो किसी दिए गए फिनिश लेख से संबंधित होने के लिए जाने जाते हैं। परिणामों से पता चलता है कि विधियों के ensembles स्टैंड-अलोन विधियों से बेहतर प्रदर्शन करते हैं, यह सुझाव देते हुए कि वे दस्तावेजों की पूरक विशेषताओं को कैप्चर करते हैं', 'ga': 'Tugaimid aghaidh ar an bhfadhb a bhaineann le doiciméid ghaolmhara a nascadh trasna teangacha i mbailiúchán ilteangach. Déanaimid measúnú ar thrí mhodh éagsúil gan mhaoirseacht chun doiciméid a léiriú agus a chur i gcomparáid: (1) múnla topaicí ilteangach; (2) leabaithe doiciméad tras-teangacha; agus (3) achar Wasserstein.Déanaimid tástáil ar fheidhmíocht na modhanna seo chun ailt nuachta a aisghabháil sa tSualainnis arb eol go mbaineann siad le halt áirithe san Fhionlainn. tréithe comhlántacha na ndoiciméad a ghabháil', 'hu': 'A kapcsolódó dokumentumok többnyelvű gyűjteményben történő összekapcsolásának problémájával foglalkozunk. Három különböző, felügyelet nélküli módszert értékelünk a dokumentumok bemutatására és összehasonlítására: (1) többnyelvű témamodell; (2) többnyelvű dokumentumok beágyazása; és (3) Wasserstein távolság. Ezeknek a módszereknek a teljesítményét teszteljük svéd nyelvű olyan cikkek lekérésében, amelyek ismert, hogy kapcsolódnak egy adott finn cikkhez. Az eredmények azt mutatják, hogy a módszerek együttesei felülmúlják az önálló módszereket, ami arra utal, hogy a dokumentumok kiegészítő jellemzőit rögzítik', 'el': 'Αντιμετωπίζουμε το πρόβλημα της διασύνδεσης σχετικών εγγράφων μεταξύ γλωσσών σε μια πολύγλωσση συλλογή. Αξιολογούμε τρεις διαφορετικές μεθόδους χωρίς επίβλεψη για την αναπαράσταση και σύγκριση εγγράφων: (1) πολύγλωσσο θεματικό μοντέλο. (2) ενσωμάτωση γλωσσικών εγγράφων· και (3) απόσταση Wasserstein. Δοκιμάζουμε την απόδοση αυτών των μεθόδων στην ανάκτηση άρθρων ειδήσεων στα σουηδικά που είναι γνωστό ότι σχετίζονται με ένα συγκεκριμένο φινλανδικό άρθρο. Τα αποτελέσματα δείχνουν ότι τα σύνολα των μεθόδων ξεπερνούν τις αυτόνομες μεθόδους, υποδηλώνοντας ότι αποτυπώνουν συμπληρωματικά χαρακτηριστικά των εγγράφων.', 'ka': 'ჩვენ მრავალენგური კოლექციაში დაკავშირებული დოკუმენტების პრობლემას გადაწყენება. ჩვენ სამი განსხვავებული განსხვავებული განსხვავებული მეტოვები, რომელიც დოკუმენტების გამოსახულება და შემდგომარება: Name და (3) გასერსტეინის განტოლება. ჩვენ შევცვალობთ ამ მეტოვების გამოსახულებას, რომელიც ქგვედის ახალგაზრულება, რომლებიც იცნობიან, რომ კონფინური ახალგაზრულებათან ერთადერთიან. წარმოდგენები გამოჩვენებენ, რომ მეტებების შემოწმება უფრო გავაკეთებენ ერთადერთი მეტები, რომლებიც აჩვენებენ, რომ დოკუმენტების კომპლენტური პროგრამეტ', 'it': 'Affrontiamo il problema di collegare documenti correlati tra le lingue in una raccolta multilingue. Valutiamo tre diversi metodi non supervisionati per rappresentare e confrontare documenti: (1) modello di argomento multilingue; (2) incorporazioni di documenti multilingue; e (3) Distanza Wasserstein. Testiamo le prestazioni di questi metodi nel recupero di articoli di notizie in svedese che sono noti per essere correlati a un dato articolo finlandese. I risultati mostrano che insiemi di metodi superano i metodi stand-alone, suggerendo che catturano caratteristiche complementari dei documenti', 'kk': 'Біз бірнеше тіл жинақтағы құжаттарды тілдерге байланыстыру мәселесін шешу. Құжаттарды көрсету және салыстыру үшін үш әртүрлі әдістерді бағалаймыз: (1) көп тілді нақыштар үлгісі; (2) тілді құжат ендіру; Name және (3) Васерстейн аралығы. Біз бұл әдістерді Швецияның жаңалық мақалаларын алу үшін тексереміз. Бұл Финляндық мақалалармен байланысты. Нәтижелер әдістердің символдары жалғыз әдістерінен шығарып, құжаттардың қосымша қасиеттерін алу үшін', 'lt': 'Mes sprendžiame susijusių dokumentų tarpusavio susiejimo daugiakalbėje kolekcijoje problem ą. Vertiname tris įvairius nepastebimus dokumentų pateikimo ir palyginimo metodus: (1) daugiakalbį temų model į; (2) tarpkalbiniai dokumentų įterpimai; ir (3) Wasserstein atstumas. Bandome šių metodų veiksmingumą ieškant naujienų straipsnių švedų kalba, kurie žinomi kaip susiję su konkrečiu Suomijos straipsniu. Iš rezultatų matyti, kad metodų rinkiniai viršija atskirus metodus ir rodo, kad jie apima papildomas dokumentų charakteristikas.', 'mk': 'We address the problem of linking related documents across languages in a multilingual collection.  Ние ги проценуваме трите различни ненадгледувани методи за претставување и споредба на документите: (1) мултијазичен модел на тема; (2) меѓујазични внесувања на документи; NAME OF TRANSLATORS и (3) Оддалеченост од Вассерстин. Ги тестираме изведувањата на овие методи за добивање новински статии на шведски кои се познати како поврзани со одредена финска статија. Резултатите покажуваат дека ансемблите на методите ги надминуваат самостојните методи, предлагајќи дека тие ги заземаат комплементарните карактеристики на документите', 'ml': 'പല ഭാഷയിലുള്ള രേഖകള്\u200d ബന്ധപ്പെടുത്തുന്നതിനെക്കുറിച്ച് ഞങ്ങള്\u200d വിശദീകരിക്കുന്നു. We evaluate three diverse unsupervised methods to represent and compare documents: (1) multilingual topic model;  (2) ക്രിസ്ലിങ്ങ്- ലാങ്കുകളുടെ രേഖകള്\u200d എഴുതിയിരിക്കുന്നു; (3) വാസ്സര്\u200dസ്റ്റീന്\u200d ദൂരം. ഈ രീതികളുടെ പ്രവര്\u200dത്തനം ഞങ്ങള്\u200d പരീക്ഷിക്കുന്നു. സ്വീഡിലെ വാര്\u200dത്താക്കുകള്\u200d വീണ്ടെടുക്കുന്നത് ഫിനിഷ് ലേഖന അതിന്റെ ഫലം കാണിക്കുന്നുണ്ടെങ്കില്\u200d സ്റ്റാന്\u200dറ് ഒറ്റയ്ക്കുള്ള രീതികള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്ന രീതികളുടെ പ്രത', 'ms': 'Kami mengatasi masalah menghubungkan dokumen berkaitan melalui bahasa dalam koleksi berbilang bahasa. Kami menilai tiga kaedah berbeza yang tidak diawasi untuk mewakili dan membandingkan dokumen: (1) model topik berbilang bahasa; (2) penyambungan dokumen saling bahasa; Dan (3) jarak Wasserstein. Kami menguji prestasi kaedah ini dalam mendapatkan artikel berita dalam Swedish yang diketahui berkaitan dengan artikel Finland tertentu. Hasil menunjukkan bahawa kumpulan kaedah melebihi kaedah sendirian, menyarankan bahawa mereka menangkap ciri-ciri komplementari dokumen', 'mt': "Aħna nindirizzaw il-problem a tar-rabta ta’ dokumenti relatati bejn il-lingwi f’kollezzjoni multilingwi. Aħna jevalwaw tliet metodi varji mhux sorveljati biex nirrappreżentaw u nqabblu dokumenti: (1) mudell ta' suġġett multilingwi; (2) inkorporazzjonijiet ta’ dokumenti translingwi; u (3) Distanza ta’ Wasserstein. Aħna nistestjaw il-prestazzjoni ta' dawn il-metodi biex niksbu artikoli tal-a ħbarijiet bl-Isvediż li huma magħrufa li huma relatati ma' artikolu Finlandiż partikolari. The results show that ensembles of the methods outperform the stand-alone methods, suggesting that they capture complementary characteristics of the documents", 'mn': 'Бид олон хэлний цуглуулалд холбоотой баримтуудыг холбоотой асуудлыг асуудаг. Бид баримтуудыг илэрхийлдэг, харьцуулахын тулд гурван өөр өөр төрлийн төлөвлөгдсөн арга баримтуудыг үнэлдэг: (1) олон хэлний сэдвийн загвар; (2) олон хэлний баримтууд бүрдүүлэх; (3) Уасерстейн зай. Бид эдгээр арга замыг Шведийн мэдээллийн баримтуудыг авахын тулд шалгаж үзэж байна. Энэ нь Финляндын баримтуудтай холбоотой. Үүний үр дүнд нь арга замыг ганцаардаг арга замыг дамжуулж, баримтуудын домжуулагч чанарыг барьж авах боломжтой.', 'no': 'Vi adresserer problemet med å kopla tilhøyrande dokument på språk i eit fleirspråkssamling. Vi evaluerer tre ulike ulike ulike metodar for å representera og sammenligna dokument: (1) fleirspråk temamodell; (2) innebygging av krysspråk dokument; Name og (3) Wasserstein avstanden. Vi testar utviklinga av desse metodane i henting av nyttikler i Sverige som er kjent til å vera relatert til eit gitt finnsk artikkel. Resultatet viser at metodane er synleg å utføra dei samme metodane, som tyder på at dei hentar komplementære karakteristikk i dokumenta.', 'pl': 'Zajmujemy się problemem łączenia powiązanych dokumentów między językami w wielojęzycznej kolekcji. Oceniamy trzy różnorodne metody reprezentowania i porównywania dokumentów bez nadzoru: (1) wielojęzyczny model tematyczny; (2) osadzanie dokumentów wielojęzycznych; i (3) odległość Wasserstein. Testujemy skuteczność tych metod w pobieraniu artykułów wiadomościowych w języku szwedzkim, które są związane z danym fińskim artykułem. Wyniki pokazują, że zespoły metod przewyższają metody samodzielne, sugerując, że uwzględniają uzupełniające się cechy dokumentów', 'ro': 'Rezolvăm problema conectării documentelor conexe între limbi într-o colecție multilingvă. Evaluăm trei metode diverse nesupravegheate de reprezentare și comparare a documentelor: (1) model multilingv de subiect; (2) încorporarea documentelor translingvistice; și (3) distanța Wasserstein. Testăm performanța acestor metode în recuperarea articolelor de știri în suedeză care sunt cunoscute ca fiind legate de un anumit articol finlandez. Rezultatele arată că ansamblurile de metode depășesc metodele de sine stătătoare, sugerând că acestea capturează caracteristicile complementare ale documentelor', 'so': 'Dhibaatada ku xiriirka dukumentiyada la xiriira luuqadaha oo dhan waxaan ku sheekeynaynaa urur luuqad kala duduwan. Waxaannu qiimeynaynaa saddex qaabab oo kala duduwan oo aan la ilaalinayn si aan u dhigno oo u barbarbareyno dukumentiyada: (1) Tusaale ahaan mada luuqadaha kala duduwan; (2) Dokumenta luuqadaha kala duwan ee ku qoran; iyo (3) Wadada Wasserstein Waxaannu imtixaannaa sameynta qaababkan marka aad soo qaadaneyso warqadaha warqadaha afka Iswidishka, kuwaas oo la xiriira warqada Finnishka la siiyey. The results show that ensembles of the methods outperform the stand-alone methods, suggesting that they capture complementary characteristics of the documents', 'sv': 'Vi tar itu med problemet med att länka relaterade dokument mellan olika språk i en flerspråkig samling. Vi utvärderar tre olika icke övervakade metoder för att representera och jämföra dokument: (1) flerspråkig ämnesmodell; (2) Flerspråkiga dokumentinbäddningar. och (3) Wasserstein avstånd. Vi testar hur dessa metoder fungerar när vi hämtar nyhetsartiklar på svenska som är kända för att vara relaterade till en viss finsk artikel. Resultaten visar att ensembler av metoderna överträffar de fristående metoderna, vilket tyder på att de fångar kompletterande egenskaper hos dokumenten', 'sr': 'Rešimo problem povezanja povezanih dokumenta na jezicima u multijezičkoj kolekciji. Procjenjujemo tri različite neodređene metode za predstavljanje i usporedbu dokumenta: (1) multijezički model tema; (2) uključenje međujezičkih dokumenta; i (3) Wasserstein udaljenost. Testiramo provedbu tih metoda u prikupljanju novinskih članaka na Švedskom, koje se poznaju da su povezani sa određenim finskom člankom. Rezultati pokazuju da osiguranja metoda iznosi samostalne metode, sugerirajući da uhvate dodatne karakteristike dokumenta', 'si': 'අපි ගොඩක් භාෂාවක් සම්බන්ධයක් වලින් සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන්ධ විදි අපි විවිධ විවිධ විශේෂ විදියට ප්\u200dරතික්\u200dරියා කරන්න සහ ප්\u200dරතික්\u200dරියාත්මක විදියට ප්\u200dරතික්\u200dරියා කරන්න විදි (2) විශාල භාෂාවක් ලිපින්ත සංවිධානය; Name ඒ වගේම (3) වාස්සෙර්ස්ටේන් දුරට. අපි පරීක්ෂා කරනවා මේ විදියට ස්වීඩිෂ් වලින් වාර්තාව අරගෙන ආරක්ෂා කරනවා කියලා දැනගන්නේ ෆින්නිෂ් ලේ ප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරතිප්\u200dරති', 'ta': 'பல மொழிகளில் தொடர்புடைய ஆவணங்களை இணைக்கும் பிரச்சனையை நாம் விளக்குகிறோம். மூன்று வித்தியாசமான பாதுகாப்பாக்கப்படாத முறைகளை நாம் மதிப்பிடுகிறோம் ஆவணங்களை ஒப்பிடுகிறோம்: (1) பல மொழி தலை (2) மொழியில் உள்ளிடப்பட்ட ஆவணம்: (3) வாஸ்ஸர்ஸ்டீன் தூரம். கொடுக்கப்பட்ட பினிஷ் கட்டுரையுடன் தெரியும் செய்தி செய்த செய்தி கட்டுரைகளை மீட்டெடுக்க இந்த வழிகளின் செயல The results show that ensembles of the methods outperform the stand-alone methods, suggesting that they capture complementary characteristics of the documents', 'ur': 'ہم ایک بہت سی زبان کلکسیون میں رابطہ دار لکھنے کے مسئلہ میں مشکل کریں گے۔ ہم تین مختلف غیر قابل تحقیق کے طریقے کا ارزش کررہے ہیں کہ دفتروں کی نمایش اور مقایسہ کریں: (1) بہت سی زبانی ٹوپ موڈل۔ (2) مختلف زبان کے دفتروں میں انبودینگ اور واسسرسٹین کی دور ہم ان طریقوں کی عملکرد کو سوئدی میں اخبار لکھنے کے لئے امتحان کرتے ہیں جو ایک فینلاندی لکھی کے ساتھ ملتے ہیں۔ نتیجے دکھاتے ہیں کہ طریقوں کی مضبوطی ایک دوسرے طریقے سے زیادہ اضافہ کرتی ہیں، یہ بات کرتا ہے کہ وہ سند کے مطابق اضافہ کرنے والی خصوصیات پکڑتے ہیں', 'vi': 'Chúng tôi giải quyết vấn đề liên kết các tài liệu liên quan đến ngôn ngữ trong một bộ sưu tập đa dạng. Chúng tôi đánh giá ba phương pháp không giám sát đa dạng để đại diện và so sánh tài liệu: (2) Nhúng tài liệu qua ngôn ngữ; và(3) Khoảng cách Wasserstein. Chúng tôi kiểm tra khả năng của các phương pháp này trong việc lấy tin tức bằng Thụy Điển được biết là có liên quan đến một bài báo Phần Lan. Kết quả cho thấy các kết hợp của các phương pháp vượt qua các phương pháp đơn độc, cho thấy chúng thu thập các tính chất bổ sung của các tài liệu.', 'uz': "Biz bir necha tillar toʻplamida bogʻ'liq hujjatlarni bogʻlash muammolarini boshqaramiz. Biz hujjatlarni tahrirlash va kamaytirish uchun uch xil tomonini qiymatimiz: (1) muloqat tillar mavzu modeli; (2) Koʻp tillar hujjatlari va Vaserstein orada. Biz bu usullarning bajarishini iswidhish maqolalarini aniqlash uchun imtiyozmaymiz. Koʻrsatilgan Finnish maqola bilan bogʻ'liq mavjud. @ info", 'da': 'Vi løser problemet med at sammenkæde relaterede dokumenter på tværs af sprog i en flersproget samling. Vi evaluerer tre forskellige uautoriserede metoder til at repræsentere og sammenligne dokumenter: (1) flersproget emnemodel; (2) dokumentindlejringer på tværs af sprog og (3) Wasserstein afstand. Vi tester resultaterne af disse metoder ved at hente nyhedsartikler på svensk, der vides at være relateret til en given finsk artikel. Resultaterne viser, at ensembler af metoderne overgår de enkeltstående metoder, hvilket tyder på, at de indfanger komplementære karakteristika ved dokumenterne', 'hr': 'Mi rješavamo problem povezanja povezanih dokumenta na jezicima u multijezičkoj kolekciji. Procjenjujemo tri različite neodređene metode za predstavljanje i usporedbu dokumenta: (1) multijezički model teme; (2) uključenje međujezičkih dokumenta; i (3) Wasserstein udaljenost. Mi testiramo provedbu tih metoda u prikupljanju novinskih članaka na švedskom koje se poznaju povezanim s određenim finskom člankom. Rezultati pokazuju da osiguranja metoda iznosi samostalne metode, sugerirajući da uhvate dodatne karakteristike dokumenta', 'bg': 'Ние разглеждаме проблема с свързването на свързани документи между езиците в многоезична колекция. Оценяваме три различни метода без надзор за представяне и сравняване на документи: (1) многоезичен тематичен модел; (2) междуезични вграждания на документи; и (3) разстояние Васерщайн. Тестваме ефективността на тези методи при извличане на новинарски статии на шведски език, за които е известно, че са свързани с дадена финландска статия. Резултатите показват, че ансамблите от методите превъзхождат самостоятелните методи, което предполага, че те улавят допълващи се характеристики на документите.', 'nl': 'We pakken het probleem aan van het koppelen van gerelateerde documenten in verschillende talen in een meertalige collectie. We evalueren drie verschillende methoden zonder toezicht om documenten te representeren en te vergelijken: (1) meertalig topic model; (2) meertalige insluitingen van documenten; en (3) Wasserstein afstand. We testen de prestaties van deze methoden bij het ophalen van nieuwsberichten in het Zweeds waarvan bekend is dat ze gerelateerd zijn aan een bepaald Fins artikel. De resultaten tonen aan dat ensembles van de methoden beter presteren dan de stand-alone methoden, wat suggereert dat ze complementaire kenmerken van de documenten vastleggen', 'de': 'Wir behandeln das Problem der sprachübergreifenden Verknüpfung verwandter Dokumente in einer mehrsprachigen Sammlung. Wir evaluieren drei verschiedene Methoden, um Dokumente ohne Aufsicht darzustellen und zu vergleichen: (1) mehrsprachiges Themenmodell; (2) mehrsprachige Einbettungen von Dokumenten; und (3) Wasserstein Entfernung. Wir testen die Leistungsfähigkeit dieser Methoden beim Abrufen von Nachrichtenartikeln auf Schwedisch, die bekanntermaßen mit einem bestimmten finnischen Artikel zusammenhängen. Die Ergebnisse zeigen, dass Ensembles der Methoden die eigenständigen Methoden übertreffen, was darauf hindeutet, dass sie komplementäre Merkmale der Dokumente erfassen.', 'id': 'Kami mengatasi masalah menghubungkan dokumen terkait melalui bahasa dalam koleksi berbagai bahasa. Kami mengevaluasi tiga metode yang berbeda untuk mewakili dan membandingkan dokumen: (1) model topik berbagai bahasa; (2) penerbangan dokumen saling bahasa; (3) Jarak Wasserstein. Kami menguji prestasi dari metode ini untuk mendapatkan artikel berita di Swedia yang dikenal terkait dengan artikel Finlandia tertentu. Hasilnya menunjukkan bahwa ensemble dari metode melebihi metode standar, menyarankan bahwa mereka menangkap karakteristik komplementari dokumen', 'ko': '우리는 다중 언어 집합에서 다중 언어 링크와 관련된 문서의 문제를 해결했다.우리는 세 가지 서로 다른 무감독 방법을 평가하여 문서를 표시하고 비교했다. (1) 다언어 주제 모델.(2) 다중 언어 문서 삽입;(3) 와세스탄 거리.우리는 핀란드 기사와 관련된 스웨덴어 기사를 검색할 때의 성능을 테스트했다.그 결과 집적 방법이 독립된 방법보다 우수하다는 것은 문서의 상호 보완 특징을 포착했다는 것을 나타낸다', 'sw': 'Tunajadili tatizo la kuunganisha nyaraka zinazohusiana katika lugha mbalimbali. Tunatathmini njia tatu mbalimbali zisizo na uhakika kuwakilisha na kuwalinganisha nyaraka: (1) mifano ya mada ya lugha mbalimbali; (2) nyaraka za lugha zinazoingizwa; na (3) umbali wa Wasserstein. Tunajaribu utendaji wa njia hizi katika kutafuta makala za habari kwa lugha ya Kiswadishi ambazo zinajulikana yanahusiana na makala fulani ya Kifinni. Matokeo yanaonyesha kuwa viungo vya mbinu vinavyotengeneza njia za msimamo peke yao, zinaonyesha kwamba wanachukua sifa za kompyuta za nyaraka', 'fa': 'ما مشکل ارتباط سند ارتباط به زبان\u200cها در یک مجموعه\u200cی بسیاری زبان حل می\u200cکنیم. ما سه روش متفاوتی را برای نمایش و مقایسه کردن سند ارزیابی می کنیم: (۱) مدل موضوع زیادی زبان (۲) تنظیم سند متوسط زبان; Name و فاصله واسستین. ما اجرای این روش\u200cها را در دریافت مجموعه\u200cهای خبری در سوئدی آزمایش می\u200cکنیم که معلوم می\u200cشود به یک مقاله فنلاندی ارتباط دارند. نتیجه\u200cها نشان می\u200cدهند که نشانه\u200cهای روش\u200cها از روش\u200cهای تنهایی بیش از آن\u200cها انجام می\u200cدهند، پیشنهاد می\u200cدهند که آنها ویژگی\u200cهای اضافه\u200cای از سند\u200cها را بگیرند', 'am': 'በቋንቋ ቋንቋዎች ውስጥ የተገኘውን ሰነድ ማግኘት ጉዳይ እናስቸግራለን፡፡ ሰነዱን ለማስተካከል እናስተካከልም ዘንድ ሦስት ልዩ ያልተጠበቀው ሥርዓቶች እናስተካክላለን:(1) በብዙ ቋንቋዎች የጉዳዩ ምሳሌ; (2) የቋንቋ ቋንቋ ሰነዱን አቀማመጥ; እና (3) Wasserstein ሩቅ:: የዚህን ሥርዓቶች የፊንስ ጽሑፍ ለመቀጠል የሚታወቁትን ስዊድንና የዜና ጽሑፎችን ለማግኘት እንሞክራለን፡፡ ፍሬቶቹ የቆመ ብቻውን የሥርዓት ሥርዓት ማሳየት ሲያሳየው፣ ሰነዱን አካባቢ እውቀት እንዲያሳየው ነው፡፡', 'tr': 'Biz multi dil jemgyýetinde ýaly senedleri bilen baglaşdyrmak kynçylygyny çözýäris. Biz senedi temsil etmek we karşılaştyrmak üçin dürli sanly täzeliklerden çykýarys: (1) köp dilli tema modeli; (2) Çapraz dilli sened ködlemeleri; we (3) Wasserstein aralygy. Biz bu ýolaryň etkinleşigini Şwediýada haberler makalasyny almak üçin bardyk we muny be ýleki Finlandiýa makalasynyň bardygyny bardyk. Netijeler ýagdaýlaryň ýeke özleri diýmek üçin taýýarlandygyny görkezýär.', 'af': "Ons adres die probleem van verwante dokumente te koppel oor tale in 'n veelvuldige versameling. Ons evalueer drie verskillende ongeonderwerpende metodes om dokumente te verteenwoordig en vergelyk: (1) veelvuldige onderwerp model; (2) kruistale dokument inbêdings; Name en (3) Wasserstein afstand. Ons probeer die prestasie van hierdie metodes in die ontvang van nuus artikels in Sweedse wat bekend is om verwante te wees met 'n gegewe Finnish artikel. Die resultate vertoon dat die metodes van die metode uitvoer die standalleen metode, voorstel dat hulle komplementare karakteristieke van die dokumente opneem", 'az': 'Biz çoxlu dil koleksiyonundan əlaqəli belələri bağlamaq problemlərini çəkirik. Biz belələri göstərmək və salmaq üçün üç müxtəlif müəyyən edilməmiş metodları değerləşdiririk: (2) çox dilli döküm inşalları; və Wasserstein uzaqlaşını. Biz bu metodların əməllərini İsveçdə xəbər məktublarını almaq üçün imtahana çəkirik. Belə bir Finlandiya məktublarına bağlı olar. Sonuçlar göstərir ki, metodların təkcə təkcə təkcə təkcə təkcə təkcə təkcə yollarını istifadə edir, belələrin əlavə etdikləri papild xüsusiyyətlərini alırlar.', 'sq': 'Ne trajtojmë problem in e lidhjes së dokumenteve të lidhura nëpër gjuhë në një koleksion shumëgjuhës. We evaluate three diverse unsupervised methods to represent and compare documents: (1) multilingual topic model;  (2) cross-lingual document embeddings;  dhe (3) Wasserstein distancë. Ne testojmë shfaqjen e këtyre metodave në marrjen e artikujve të lajmeve në suedez që janë të njohur se janë të lidhur me një artikull të caktuar finlandez. Rezultatet tregojnë se mbledhjet e metodave tejkalojnë metodat e vetme, duke sugjeruar se ato kapin karakteristikat komplementare të dokumenteve', 'bn': 'আমরা অনেক ভাষায় সংযুক্ত তথ্য লিঙ্ক করার সমস্যা নিয়ে আলোচনা করি। নথি প্রতিনিধিত্ব ও তুলনা করার জন্য আমরা তিনটি বিভিন্ন উপায়ের মূল্যায়ন করি: (1) বহুভাষায় বিষয়বস্তু মডেল; (2) ক্রস-ভাষাভাষী নথি প্রবেশ করা হয়েছে; আর (৩) ওয়াসের্স্টিন দূরত্ব। সুইডিশ ভাষায় সংবাদ প্রবন্ধ পুনরুদ্ধার করার জন্য আমরা এই পদ্ধতির প্রভাব পরীক্ষা করি যারা একটি ফিনিশ প্রবন্ধের সাথে সম ফলাফল দেখা যাচ্ছে যে স্ট্যান্ট-একা পদ্ধতির ব্যাপারে এই পদ্ধতিগুলোর প্রতিষ্ঠান, যার পরামর্শ দেয় যে তারা নথিগুলোর প্রত', 'hy': 'Մենք լուծում ենք հարաբեր փաստաթղթերի կապը լեզուների միջև բազմալեզվով հավաքածում: Մենք գնահատում ենք երեք տարբեր անվերահսկված մեթոդներ փաստաթղթերի ներկայացնելու և համեմատելու համար: (1) բազլեզու թեմային մոդել, (2) միջլեզվային փաստաթղթերի ներդրումներ, և (3) Վասերշտեյնի հեռավորությունը: Մենք ստուգում ենք այս մեթոդների արտադրողականությունը շվեդական նորությունների մասին, որոնք հայտնի է, որ կապված են որոշակի ֆինլական հոդվածի հետ: Արդյունքները ցույց են տալիս, որ մեթոդների համառույցները գերազանցում են ինքնաբերական մեթոդները, առաջարկում են, որ դրանք ներառում են փաստաթղթերի բազմազան հատկությունները,', 'ca': "Ens ocupem del problem a d'enllaçar documents relacionats entre llengües en una col·lecció multilingüe. We evaluate three diverse unsupervised methods to represent and compare documents: (1) multilingual topic model;  (2) incorporacions de documents translingües; i (3) La distància de Wasserstein. Testem el desempeny d'aquests mètodes en recuperar articles de notícies en suec que es coneixen relacionats amb un determinat article finlandès. Els resultats demostren que els conjunts de mètodes superen els mètodes autònoms, suggerent que capturen característiques complementars dels documents", 'cs': 'Problém propojení souvisejících dokumentů napříč jazyky řešíme ve vícejazyčné sbírce. Hodnotíme tři různé metody bez dozoru pro reprezentaci a porovnávání dokumentů: (1) vícejazyčný tématický model; (2) vkládání dokumentů v různých jazycích; a (3) vzdálenost Wassersteina. Testujeme výkonnost těchto metod při získávání zpravodajských článků ve švédštině, o nichž je známo, že souvisejí s daným finským článkem. Výsledky ukazují, že soubory metod překonávají samostatné metody, což naznačuje, že zachycují doplňkové charakteristiky dokumentů.', 'bs': 'Mi rješavamo problem povezanja povezanih dokumenta na jezicima u multijezičkoj kolekciji. Procjenjujemo tri različite neodređene metode za predstavljanje i usporedbu dokumenta: (1) multijezički model teme; (2) uključenje međujezičkih dokumenta; i udaljenost Wasserstein. Testiramo provedbu tih metoda u prikupljanju novinskih članaka na švedskom jeziku koje se poznaju da su povezani s određenim finskom člankom. Rezultati pokazuju da osiguranja metoda iznosi samostalne metode, sugerirajući da uhvate dodatne karakteristike dokumenta', 'et': 'Me tegeleme probleemiga seotud dokumentide sidumisega keelte vahel mitmekeelses kogus. Hindame dokumentide esitamiseks ja võrdlemiseks kolme erinevat järelevalveta meetodit: (1) mitmekeelne teemamudel; (2) keeleülene dokumentide manustamine; ja (3) Wassersteini kaugus. Testime nende meetodite tulemuslikkust rootsikeelsete uudisteartiklite hankimisel, mis on teadaolevalt seotud konkreetse Soome artikliga. Tulemused näitavad, et meetodite komplektid ületavad eraldiseisvaid meetodeid, näidates, et need hõlmavad dokumentide täiendavaid omadusi.', 'fi': 'Käsittelemme ongelmaa, joka liittyy aiheeseen liittyvien asiakirjojen linkittämiseen eri kielillä monikielisessä kokoelmassa. Arvioimme kolmea erilaista, valvomatonta menetelmää asiakirjojen esittämiseen ja vertailuun: (1) monikielinen aihemalli; (2) monikieliset asiakirjojen upotukset; ja (3) Wassersteinin etäisyys. Testaamme näiden menetelmien toimivuutta haettaessa ruotsinkielisiä uutisartikkeleita, joiden tiedetään liittyvän tiettyyn suomalaiseen artikkeliin. Tulokset osoittavat, että menetelmien yhdistelmät suoriutuvat erillisistä menetelmistä, mikä viittaa siihen, että ne kuvaavat dokumenttien toisiaan täydentäviä ominaisuuksia.', 'sk': 'Problem povezovanja povezanih dokumentov med jeziki obravnavamo v večjezični zbirki. Ocenjujemo tri različne nenadzorovane metode za predstavitev in primerjavo dokumentov: (1) večjezični tematski model; (2) večjezične vdelave dokumentov; in (3) Wassersteinova razdalja. Preizkusimo učinkovitost teh metod pri iskanju novic v švedskem jeziku, za katere je znano, da so povezane z določenim finskim člankom. Rezultati kažejo, da so kompleksi metod boljši od samostojnih metod, kar kaže, da zajemajo dopolnilne značilnosti dokumentov.', 'he': 'אנחנו מתמודדים עם הבעיה של הקשר מסמכים קשורים לאורך שפות באספת רבות שפות. אנו מעריכים שלושה שיטות מגוונות ללא השגחה כדי לייצג ולהשוות מסמכים: (1) מודל נושא רב-שפתי; (2) תוספות מסמכים בין שפתיים; (3) מרחק ווסקרסטיין. אנחנו בודקים את ההופעה של השיטות האלה בהחזרה של מאמרים חדשות בשוודית שנודעים שקשורים למאמר פיני מסוים. התוצאות מראות שסמלים של השיטות יוצאים מעל השיטות עצמאות, ומצייעים שהם תופסים אופיינים תוספים של המסמכים', 'ha': "Munã jãyayya masu haɗi takardar da aka yi danganta cikin wasu harshe da yawa. Tuna ƙaddara hanyõyi uku masu da ba'a tsare shi ba, kuma muna daidaita takardar aiki: (1) misali masu cikin multilala; (2) Gansa da takardar cikin harshen mai tsohon; and (3) Wasserstein distance. Munã jarraba mafarin hanyoyin waɗannan da ke samun makaranta da aka samu sune cikin Iswidishki da aka sani ana yi danganta da wani makala na Finnishe. Mataimakin za'a nuna cewa emboli na metoden su nuna metoden-taki kaɗan, sunã shawarar da su samu'ar da takardun takardun", 'jv': 'Awak dhéwé éntukno boton kanggo nggawe dokumen sing nggawe luwih bantuan ing langgar sampeyan luwih. Awak dhéwé éntukno telu sistem sing gak nggawe perusahaan karo nggawe Dokumen: :1) model multi-languang; tema (2) banter-langgambar dokumen basa; akeh basa karo (3) Wassnstain boton. Awak dhéwé éntuk perusahaan kanggo ngerasai perusahaan kuwi nggawe barang-barang kanggo ngerasai perusahaan Finis. Rejalaké mbukak cara-cara sing ngerasah akeh mèdiu sing bisa nguasah sing bakal dumadhi, supoyo supoyo nggawe cara-cara-suarané sing apik dhéwé karo dokumen', 'bo': 'ང་ཚོས་སྐད་རིགས་སྦྲེལ་མཐུད་ཀྱི་ཡིག་ཆ་དང་སྦྲེལ་མཐུད་ཀྱི་དཀའ་ངལ་འདི་ལ་གཏོང་བ ང་ཚོས་ཡིག་ཆ་དང་བསྡུར་ཐབས་ལམ་མི་འདྲ་བ་པར་དབྱེ་བ་གཞན་གསུམ་གྱི་གཟུགས་རིས་བསམ་བྱེད་ཀྱི་ཡོད། (2) སྐད་རིགས་ཀྱི་ཡིག་ཆ་གསར་བསྐྲུན་ཡོད་པ། ༼༣༽ཡང་དེ་ནས་བར་ཐག་པ་རེད། ང་ཚོས་སུའི་ཐབས་ལམ་འདིའི་ལྟར་ཉེན་མཁན་གྱི་བརྗོད་ཀྱི་ཚིག་རྗེས་སྒྲུང་ནང་དུ་གཏོང་བ་དང་འབྲེལ་བ་ཡོད། གྲུབ་འབྲས་བྱ་རིམ་གྱི་རྣམ་པ་དེ་དམིགས་བསལ་ནུས་ཡོད་པ་མཚོན་ན།'}
