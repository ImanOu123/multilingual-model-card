{'en': 'Low Resource Quadratic Forms for Knowledge Graph Embeddings', 'ar': 'أشكال تربيعية منخفضة الموارد لتضمينات الرسم البياني المعرفي', 'es': 'Formularios cuadráticos de bajos recursos para incrustaciones de gráficos de conocimiento', 'fr': 'Formulaires quadratiques à faibles ressources pour les intégrations de graphes de connaissances', 'pt': 'Formulários quadráticos de baixo recurso para incorporação de gráficos de conhecimento', 'ja': 'ナレッジグラフ埋め込みのための低資源二次フォーム', 'zh': '知图谱嵌者低资源二', 'ru': 'Малообеспеченные квадратичные формы для вложений графа знаний', 'hi': 'नॉलेज ग्राफ एम्बेडिंग के लिए कम संसाधन द्विघात प्रपत्र', 'ga': 'Foirmeacha Cearnógacha Íseal Acmhainní le haghaidh Leabú Grafa Eolais', 'el': 'Τετραγωνικές φόρμες χαμηλού πόρων για ενσωμάτωση γραφικών γνώσεων', 'it': 'Forme quadratiche a basso contenuto di risorse per incorporazioni di grafici di conoscenza', 'hu': 'Alacsony erőforrású négyzetméteres űrlapok tudásgraf beágyazásokhoz', 'mk': 'Low Resource Quadratic Forms for Knowledge Graph Embeddings', 'ms': 'Form Kuadratik Sumber rendah untuk Penjelmaan Graf Pengetahuan', 'kk': 'Name', 'mt': 'Formoli Kwadratiċi ta’ Riżorsi Baxxi għall-Inkorporazzjoni ta’ Grafiki ta’ Għarfien', 'lt': 'Mažai išteklių kvadratinės žinių grafikų įterpimo formos', 'mn': 'Мэдлэг график нэмжүүлэхэд бага нөөц квадратик хэлбэрүүд', 'pl': 'Formy kwadratowe o niskich zasobach dla osadzeń wykresów wiedzy', 'no': 'Name', 'ka': 'Name', 'sr': 'Niski kvadratni oblici resursa za integraciju znanja grafika', 'ro': 'Formulare cuadratice cu resurse reduse pentru încorporarea graficului de cunoștințe', 'so': 'Quadratic Forms of Knowledge Graph Embedding', 'ta': 'அறிவிப்பு வரைப்படத்திற்கான குறைந்த மூலம் குறைந்த வடிவங்கள்', 'si': 'Name', 'ur': 'Name', 'ml': 'അറിവ് ഗ്രാഫ് എംബെഡിങുകള്\u200dക്കുള്ള വിഭവങ്ങള്\u200d കുറഞ്ഞ വിഭവങ്ങള്\u200d', 'sv': 'Kvadratiska formulär med låg resurs för inbäddade kunskapsdiagram', 'uz': 'Maò¥lumot bazasini ochish', 'vi': 'KCharselect unicode block name Lý do ví dụ', 'hr': 'Niski kvadratni oblici resursa za uključenje znanja grafika', 'bg': 'Квадратни формуляри с нисък ресурс за вграждане на графики на знанието', 'id': 'Bentuk Kudratik Sumber Terrendah untuk Embedding Graf Pengetahuan', 'ko': '지식도에 삽입된 저자원 2차형', 'fa': 'Name', 'nl': 'Kwadratische formulieren met lage resources voor het insluiten van kennisgrafieken', 'da': 'Kvadratiske formularer med lav ressource til indlejringer af vidensgrafer', 'de': 'Quadratische Formulare mit geringen Ressourcen für Knowledge Graph Embeddings', 'sw': 'Mifumo ya chini ya rasilimali kwa ajili ya Kuingia Sayansi', 'sq': 'Formë katdratike të burimeve të ulta për përfshirjen e grafikut të njohurive', 'hy': 'Comment', 'af': 'Name', 'tr': 'Bilgi Graph Girişinden üçin Az Ressurat Kwadratik FormlarKCharselect unicode block name', 'bs': 'Niski kvadratni oblici resursa za uključenje znanja grafika', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'bn': 'জ্ঞান গ্রাফ এমবেডিং এর জন্য কম উৎস কোয়াড্রেটিক ফর্ম', 'ca': 'Formes quadràtiques de baixos recursos per integrar gràfics de coneixement', 'et': 'Vähese ressursiga ruutvormid teadmisgraafikute manustamiseks', 'az': 'Bilim Grafikl톛rinin 쿮lav톛l톛ri', 'fi': 'Vähävaraiset neliölomakkeet tietokaavion upotuksille', 'cs': 'Kvadratické formuláře s nízkými zdroji pro vložení znalostních grafů', 'jv': 'structural navigation', 'he': 'Forms Quadratic Low Resources for Knowledge Graph Embedding', 'sk': 'Kvadratni obrazci z nizkimi viri za vdelave grafikonov znanja', 'ha': 'KCharselect unicode block name', 'bo': 'ཤེས་པའི་རྣམ་གྲངས་ཀྱི་མཚོན་རིས་ཁ་སྐོང་ལ་མཚུངས་པའི་རྩིས་འབྲེལ་ལ་ཉུང་པོ'}
{'en': 'We address the problem of link prediction between entities and relations of knowledge graphs. State of the art techniques that address this problem, while increasingly accurate, are computationally intensive. In this paper we cast link prediction as a sparse convex program whose solution defines a quadratic form that is used as a ranking function. The structure of our convex program is such that standard support vector machine software packages, which are numerically robust and efficient, can solve it. We show that on benchmark data sets, our model’s performance is competitive with state of the art models, but training times can be reduced by a factor of 40 using only CPU-based (and not GPU-accelerated) computing resources. This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.link prediction between entities and relations of knowledge graphs. State of the art techniques that address this problem, while increasingly accurate, are computationally intensive. In this paper we cast link prediction as a sparse convex program whose solution defines a quadratic form that is used as a ranking function. The structure of our convex program is such that standard support vector machine software packages, which are numerically robust and efficient, can solve it. We show that on benchmark data sets, our model’s performance is competitive with state of the art models, but training times can be reduced by a factor of 40 using only CPU-based (and not GPU-accelerated) computing resources. This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.', 'pt': 'Abordamos o problema de previsão de links entre entidades e relações de grafos de conhecimento. As técnicas de última geração que abordam esse problema, embora cada vez mais precisas, são computacionalmente intensivas. Neste artigo, lançamos a previsão de link como um programa convexo esparso cuja solução define uma forma quadrática que é usada como uma função de classificação. A estrutura do nosso programa convexo é tal que os pacotes de software de máquina de vetor de suporte padrão, que são numericamente robustos e eficientes, podem resolvê-lo. Mostramos que em conjuntos de dados de benchmark, o desempenho do nosso modelo é competitivo com modelos de última geração, mas os tempos de treinamento podem ser reduzidos em um fator de 40 usando apenas recursos de computação baseados em CPU (e não acelerados por GPU). Essa abordagem pode ser adequada para aplicações em que equilibrar as demandas de desempenho de conclusão de grafos em relação à eficiência computacional é uma compensação desejável.', 'ar': 'نعالج مشكلة توقع الارتباط بين الكيانات وعلاقات الرسوم البيانية المعرفية. أحدث التقنيات التي تعالج هذه المشكلة ، على الرغم من أنها دقيقة بشكل متزايد ، إلا أنها مكثفة من الناحية الحسابية. في هذا البحث قمنا بإلقاء نظرة على تنبؤ الوصلة كبرنامج محدب متفرق يحدد حله الشكل التربيعي الذي يستخدم كوظيفة ترتيب. إن هيكل برنامجنا المحدب هو أن حزم برامج آلة المتجه القياسية ، والتي تتميز بالقوة العددية والفعالة ، يمكنها حلها. نوضح أنه في مجموعات البيانات المعيارية ، يتنافس أداء نموذجنا مع أحدث النماذج ، ولكن يمكن تقليل أوقات التدريب بمعامل 40 باستخدام موارد الحوسبة المعتمدة على وحدة المعالجة المركزية (وليس المسرعة بواسطة وحدة معالجة الرسومات). قد يكون هذا النهج مناسبًا للتطبيقات التي يكون فيها موازنة متطلبات أداء إكمال الرسم البياني مقابل الكفاءة الحسابية بمثابة مقايضة مرغوبة.', 'es': 'Abordamos el problema de la predicción de enlaces entre entidades y gráficos de relaciones de conocimiento. Las técnicas de vanguardia que abordan este problema, aunque son cada vez más precisas, son computacionalmente intensivas. En este artículo presentamos la predicción de enlaces como un programa convexo disperso cuya solución define una forma cuadrática que se utiliza como función de clasificación. La estructura de nuestro programa convexo es tal que los paquetes de software de máquinas vectoriales de soporte estándar, que son numéricamente robustos y eficientes, pueden resolverlo. Demostramos que en los conjuntos de datos de referencia, el rendimiento de nuestro modelo es competitivo con los modelos más avanzados, pero los tiempos de entrenamiento se pueden reducir en un factor de 40 utilizando solo recursos informáticos basados en CPU (y no acelerados por GPU). Este enfoque puede ser adecuado para aplicaciones en las que equilibrar las demandas de rendimiento de finalización de gráficos con la eficiencia computacional es una compensación deseable.', 'fr': "Nous abordons le problème de la prédiction de liens entre les entités et les relations des graphes de connaissances. Les techniques de pointe qui résolvent ce problème, bien que de plus en plus précises, nécessitent des calculs intensifs. Dans cet article, nous présentons la prédiction de lien comme un programme convexe clairsemé dont la solution définit une forme quadratique utilisée comme fonction de classement. La structure de notre programme convexe est telle que des progiciels de support standard pour machines vectorielles, robustes et efficaces numériquement, peuvent le résoudre. Nous montrons que sur les ensembles de données de référence, les performances de notre modèle sont compétitives par rapport aux modèles de pointe, mais que les temps d'entraînement peuvent être réduits d'un facteur 40 en utilisant uniquement des ressources informatiques basées sur le processeur (et non accélérées par GPU). Cette approche peut convenir aux applications où l'équilibre entre les exigences de performances de complétion de graphe et d'efficacité de calcul est un compromis souhaitable.", 'ja': 'エンティティとナレッジグラフの関係性との間のリンク予測の問題に取り組んでいる。この問題に対処する最先端の技術は、ますます正確になりながらも、計算的に集中している。本稿では、リンク予測を、その解がランキング関数として用いられる二次形式を定義するまばらな凸プログラムとしてキャストする。当社の凸プログラムの構造は、数値的に堅牢で効率的な標準サポートベクターマシンソフトウェアパッケージがそれを解決できるようにしています。ベンチマークデータセットでは、当社のモデルのパフォーマンスは最先端モデルと競争力がありますが、CPUベースの（ GPUアクセラレーションではなく）コンピューティングリソースのみを使用して、トレーニング時間を40倍に短縮することができます。このアプローチは、グラフ完了性能の要求と計算効率とのバランスが望ましいトレードオフであるアプリケーションに適していてもよい。', 'zh': '实体之间链接知图谱也。 最先进之术虽愈正,而计量甚大。 于本文中,将链接测转换为疏突程序,其解定义了用作排名函数的二次。 吾侪之结构如此,准的向量机软件包,在数上健高效,可以决之。 吾明于准集上,吾性与先进有竞争力,但仅用基于CPU(而非GPU速)之计算资源,练日可减40倍。 此术或宜用于图形成性求与计算效率取平衡者,权衡之用也。', 'hi': 'हम संस्थाओं और ज्ञान रेखांकन के संबंधों के बीच लिंक भविष्यवाणी की समस्या को संबोधित करते हैं। कला तकनीकों की स्थिति जो इस समस्या को संबोधित करती है, जबकि तेजी से सटीक होती है, कम्प्यूटेशनल रूप से गहन होती है। इस पेपर में हम लिंक भविष्यवाणी को एक विरल उत्तल प्रोग्राम के रूप में डालते हैं जिसका समाधान एक द्विघात रूप को परिभाषित करता है जिसका उपयोग रैंकिंग फ़ंक्शन के रूप में किया जाता है। हमारे उत्तल कार्यक्रम की संरचना ऐसी है कि मानक समर्थन वेक्टर मशीन सॉफ्टवेयर पैकेज, जो संख्यात्मक रूप से मजबूत और कुशल हैं, इसे हल कर सकते हैं। हम दिखाते हैं कि बेंचमार्क डेटा सेट पर, हमारे मॉडल का प्रदर्शन कला मॉडल की स्थिति के साथ प्रतिस्पर्धी है, लेकिन प्रशिक्षण समय को केवल सीपीयू-आधारित (और जीपीयू-त्वरित नहीं) कंप्यूटिंग संसाधनों का उपयोग करके 40 के कारक से कम किया जा सकता है। यह दृष्टिकोण उन अनुप्रयोगों के लिए उपयुक्त हो सकता है जहां कम्प्यूटेशनल दक्षता के खिलाफ ग्राफ पूरा करने के प्रदर्शन की मांगों को संतुलित करना एक वांछनीय व्यापार-बंद है।', 'ru': 'Мы рассматриваем проблему прогнозирования связей между сущностями и отношениями графов знаний. Современные методы, которые решают эту проблему, хотя и становятся все более точными, являются вычислительно интенсивными. В этой статье мы бросаем предсказание связи как редкую выпуклую программу, решение которой определяет квадратичную форму, которая используется в качестве функции ранжирования. Структура нашей выпуклой программы такова, что стандартные пакеты программного обеспечения для поддержки векторных машин, которые являются численно надежными и эффективными, могут решить ее. Мы показываем, что на базовых наборах данных производительность нашей модели конкурирует с современными моделями, но время обучения может быть сокращено в 40 раз, используя только вычислительные ресурсы на базе процессора (а не GPU-ускорения). Этот подход может быть подходящим для приложений, где желательным компромиссом является баланс требований к производительности заполнения графа с вычислительной эффективностью.', 'ga': 'Tugaimid aghaidh ar fhadhb an naisc a thuar idir aonáin agus graif caidrimh eolais. Cé go bhfuil na teicníochtaí úrscothacha a thugann aghaidh ar an bhfadhb seo, tá siad dian ar ríomhaireacht. Sa pháipéar seo tugaimid tuar naisc mar chlár dronnach tanaí a shainíonn a réiteach foirm chearnach a úsáidtear mar fheidhm rangú. Tá struchtúr ár gclár dronnach den sórt sin gur féidir le pacáistí bogearraí meaisín veicteora caighdeánacha tacaíochta, atá láidir agus éifeachtach go huimhriúil, é a réiteach. Léirímid, maidir le tacair sonraí tagarmharcála, go bhfuil feidhmíocht ár múnla iomaíoch le samhlacha úrscothacha, ach is féidir amanna oiliúna a laghdú de 40 fachtóir ag baint úsáide as acmhainní ríomhaireachta CPU-bhunaithe (seachas GPU-luath) amháin. D’fhéadfadh an cur chuige seo a bheith oiriúnach d’fheidhmchláir ina bhfuil comhbhabhtáil inmhianaithe idir éilimh fheidhmíocht críochnaithe graf agus éifeachtúlacht ríomhaireachtúil a chothromú.', 'ka': 'ჩვენ განვითარებთ პრობლემა, რომელიც განსაზღვრებული ინტერტიკები და ცნობიერების გრაფიკების შესახებ. სურათის ტექნექციების სტატი, რომელიც ამ პრობლემას გადაწყვეტილება, როცა უფრო კეთესი ხდება, კომპუტექციალურად ინტენექტიურია ამ გვერდიში ჩვენ დავწერეთ წინასწორება როგორც წინასწორი კონგექსის პროგრამი, რომელიც წინასწორება კვადრატიული ფორმის განსაზღვრება, რომელიც გამოყენება როგ ჩვენი კონექსის პროგრამის სტრუქტურაცია იგივეა, რომ სტანდარტური მოქმედების პროგრამის პროგრამის პროგრამის პროგრამის პროგრამი, რომელიც მრიცხველად ჩვენ ჩვენ აჩვენებთ, რომ ბენქმარკური მონაცემების კონფიგურაცია ჩვენი მოდელის კონფიგურაცია კონფიგურაცია ხელსაწყოთა მოდელისთვის, მაგრამ განაცემის დროები 40-ის ფაქტორიდან შეუძლიათ გამოყენებ ეს პროგრამა შეიძლება იყოს საჭირო პროგრამებისთვის, სადაც გრაფიკური დასრულების შესაძლებლობა კომპუტაციონალური ეფექტიურობისთვის გადასრულება უნდა', 'el': 'Αντιμετωπίζουμε το πρόβλημα της πρόβλεψης σύνδεσης μεταξύ οντοτήτων και των σχέσεων των γραφημάτων γνώσης. Οι σύγχρονες τεχνικές που αντιμετωπίζουν αυτό το πρόβλημα, ενώ όλο και πιο ακριβείς, είναι υπολογιστικά εντατικές. Στην παρούσα εργασία προβάλλουμε την πρόβλεψη συνδέσμων ως ένα αραιό κυρτό πρόγραμμα του οποίου η λύση καθορίζει μια τετραγωνική μορφή που χρησιμοποιείται ως συνάρτηση κατάταξης. Η δομή του κυρτού προγράμματός μας είναι τέτοια ώστε τα τυποποιημένα πακέτα λογισμικού διανυσματικών μηχανών υποστήριξης, τα οποία είναι αριθμητικά ανθεκτικά και αποδοτικά, μπορούν να το λύσουν. Δείχνουμε ότι σε σύνολα δεδομένων αναφοράς, η απόδοση του μοντέλου μας είναι ανταγωνιστική με μοντέλα τελευταίας τεχνολογίας, αλλά οι χρόνοι κατάρτισης μπορούν να μειωθούν κατά έναν παράγοντα 40 χρησιμοποιώντας μόνο υπολογιστικούς πόρους βασισμένους στην ΚΜΕ (και όχι επιταχυνόμενους GPU). Αυτή η προσέγγιση μπορεί να είναι κατάλληλη για εφαρμογές όπου η εξισορρόπηση των απαιτήσεων της απόδοσης ολοκλήρωσης γραφήματος με την υπολογιστική αποδοτικότητα αποτελεί επιθυμητό συμβιβασμό.', 'lt': "Mes sprendžiame subjektų prognozių sąsajų ir žinių grafikų santykių problem ą. Šią problem ą sprendžiantys, nors ir tikslesni, pažangiausi metodai yra skaičiavimo požiūriu intensyvūs. Šiame dokumente mes išleidžiame sąsajų prognozę kaip nedidelę konveksinę program ą, kurios sprendimas apibrėžia kvadratinę form ą, kuri naudojama kaip klasifikavimo funkcija. Mūsų konveksinės programos struktūra tokia, kad standartiniai paramos vektorių programinės įrangos paketai, kurie yra skaičiais patikimi ir veiksmingi, gali ją išspręsti. We show that on benchmark data sets, our model's performance is competitive with state of the art models, but training times can be reduced by a factor of 40 using only CPU-based (and not GPU-accelerated) computing resources.  Šis metodas gali būti tinkamas taikomosioms priemonėms, kai pageidautina suderinti grafiko užbaigimo rezultatų reikalavimus su skaičiavimo efektyvumu.", 'hu': 'Az entitások közötti kapcsolat-előrejelzés problémájával foglalkozunk. A legkorszerűbb technikák, amelyek ezt a problémát kezelik, bár egyre pontosabbak, számítástechnikailag intenzívebbek. Ebben a tanulmányban a link predikciót ritka konvex programként vetjük össze, amelynek megoldása egy négyszöges formát határoz meg, amelyet rangsorolási függvényként használnak. Konvex programunk felépítése olyan, hogy a numerikusan robusztus és hatékony szabványos vektorgép szoftvercsomagok megoldhatók legyenek. Megmutatjuk, hogy a benchmark adatkészleteknél modellünk teljesítménye versenyképes a legkorszerűbb modellekkel, de az oktatási idő 40-rel csökkenthető csak CPU-alapú (és nem GPU-gyorsított) számítástechnikai erőforrások használatával. Ez a megközelítés alkalmas lehet olyan alkalmazásokra, amelyekben kívánatos kompromisszumot jelent a grafikonkészítési teljesítmény és a számítási hatékonyság követelményeinek kiegyensúlyozása.', 'ms': 'Kami mengatasi masalah ramalan pautan antara entiti dan hubungan graf pengetahuan. Teknik seni yang mengatasi masalah ini, walaupun semakin akurat, adalah secara komputasi intensiv. Dalam kertas ini kami melemparkan ramalan pautan sebagai program konveks ringkas yang penyelesaiannya menentukan bentuk kuadratik yang digunakan sebagai fungsi rangkaian. Struktur program konveks kita adalah seperti yang pakej perisian mesin vektor sokongan piawai, yang secara numerik kuat dan efisien, boleh menyelesaikannya. Kami menunjukkan bahawa pada set data benchmark, prestasi model kami adalah kompetitif dengan model terbaik, tetapi masa latihan boleh dikurangkan oleh faktor 40 menggunakan hanya sumber komputer berasaskan CPU (dan bukan GPU-accelerated). Pendekatan ini mungkin sesuai untuk aplikasi di mana imbangkan permintaan prestasi pelengkapan graf terhadap efisiensi pengiraan adalah perdagangan yang diinginkan.', 'kk': 'Біз білім графикалық мәселелері мен білім графикалық қатынастары арасындағы байланыстыру мәселесін шешуіміз. Бұл мәселеге шешілетін суреттер техникаларының күйі, дұрыс өте дұрыс болғанда, есептеп жұмыс істейді. Бұл қағазда біз таңдау бағдарламасын квадратикалық функциясы ретінде қолданылатын квадратикалық пішінді анықтайды. Конвекс бағдарламасының құрылымы - стандартты вектор машинасының бағдарламаларын қолдау бағдарламалары. Бұл санның бөлімі және ефективті болып табылады. Біз банкермалық деректер жиындарында, моделіміздің істеміміз сурет үлгілерінің күйіне сәйкес келеді, бірақ оқыту уақыттары тек процессор негізінде (GPU-тез емес) есептеу ресурстарымен 40 факторынан төмендете алады. Бұл бағдарламалар үшін қолданбалар үшін жақсы болуы мүмкін, егер график толтыру талаптарын компьютерлік тәжірибесіне қарсы балансиру керек болады.', 'mt': "We address the problem of link prediction between entities and relations of knowledge graphs.  It-tekniki l-aktar avvanzati li jindirizzaw din il-problema, filwaqt li huma dejjem aktar preċiżi, huma komputazzjonalment intensivi. F’din il-karta a ħna nagħmlu tbassir ta’ rabta bħala programm konvess baxx li s-soluzzjoni tiegħu tiddefinixxi form a kwadratika li tintuża bħala funzjoni ta’ klassifikazzjoni. The structure of our convex program is such that standard support vector machine software packages, which are numerically robust and efficient, can solve it.  We show that on benchmark data sets, our model's performance is competitive with state of the art models, but training times can be reduced by a factor of 40 using only CPU-based (and not GPU-accelerated) computing resources.  Dan l-approċċ jista’ jkun adattat għall-applikazzjonijiet fejn l-ibbilanċjar tad-domandi tal-prestazzjoni tat-tlestija tal-grafika mal-effiċjenza tal-komputazzjoni huwa kompromess mixtieq.", 'mk': 'We address the problem of link prediction between entities and relations of knowledge graphs.  Стандартните техники кои го решаваат овој проблем, иако се попрецизни, се компјутативно интензивни. Во оваа хартија фрлиме предвидување на врските како мала конвексна програма чие решение дефинира квадратска форма која се користи како рангирање функција. Структурата на нашата конвексна програма е таква што стандардните софтверски пакети за векторни машини за поддршка, кои се броевно силни и ефикасни, можат да го решат. Ние покажуваме дека на групите на податоци за споредба, перформансата на нашиот модел е конкурентна со најновите модели, но времето на обука може да се намали со фактор од 40 користејќи само компјутерски ресурси базирани на процесор (а не GPU-забрзани). This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.', 'mn': 'Бид мэдлэг графикийн биетүүд болон харилцааны хоорондоо холбогдох тодорхойлолтын асуудлыг асуудаг. Энэ асуудлыг тодорхойлж буй урлагийн техникуудын хувьд тооцоолж байгаа нь маш их хүчтэй. Энэ цаасан дээр бид таамаглалыг жижиг конвекс програм гэж холбоотой. Энэ шийдэл нь квадратик хэлбэрийг шугам функц гэж хэрэглэгддэг. Бидний конвекс програмын бүтэц бол стандарт дэмжих вектор машин програм хангамжийн багц. Энэ нь маш их хүчтэй, үр дүнтэй байдаг. Бид банкмарк өгөгдлийн багц дээр бидний загварын үйл ажиллагаа урлагийн загварын төвшинд өрсөлдөг гэдгийг харуулж байна. Гэхдээ сургалтын цаг нь зөвхөн CPU-н (GPU-н хурдан) тооцоолох боломжтой багасгаж болно. Энэ арга нь тооцоололтын үр дүнтэй эсрэг график дуусгах хэрэгцээг баланслах хэрэгцээнд зөв байж болно.', 'no': 'Vi handler problemet med å forhåndsvisa lenkje mellom einingar og forholdet til kunnskapsgrafen. Tilstand til kunstteknikkene som handler dette problemet, mens det større nøyaktig er dataintensivt. I denne papiret kastar vi lenkjeforhåndsvising som eit sparse konveks- program som løysinga definerer eit kvadratisk form som vert brukt som ein rangeringsfunksjon. Strukturen av konvex-programmet vår er slik at standardpakkar for vektormaskina er støtta, som er numerisk sterkt og effektivt, kan løysa det. Vi viser at på benchmarkdatasett er modellen vårt konkurrentivt med tilstanden til kunstmodelane, men treningstidane kan reduserast av ein faktor av 40 med bare CPU-baserte (og ikkje GPU-akselererte) dataressursar. Denne tilnærminga kan vera passande for programmer der balansering av etterspørsmåla for fullføring av grafen mot dataeffektivitet er ein ønskjer utvikling.', 'ro': 'Abordăm problema predicției legăturilor dintre entități și relațiile grafice de cunoaștere. Tehnicile de ultimă oră care abordează această problemă, deși sunt din ce în ce mai precise, sunt intense din punct de vedere computațional. În această lucrare vom folosi predicția legăturilor ca un program convex rar a cărui soluție definește o formă pătratică care este folosită ca funcție de clasificare. Structura programului nostru convex este astfel încât pachetele standard de software pentru mașini vectoriale, care sunt robuste numeric și eficiente, să o poată rezolva. Aratăm că pe seturile de date de referință, performanța modelului nostru este competitivă cu modelele de ultimă generație, dar timpul de instruire poate fi redus cu un factor de 40 utilizând numai resurse de calcul bazate pe CPU (și nu accelerate de GPU). Această abordare poate fi adecvată pentru aplicații în care echilibrarea cerințelor de performanță de completare a graficului cu eficiența computațională este un compromis de dorit.', 'pl': 'Zajmujemy się problemem predykcji powiązań między podmiotami a relacjami wykresów wiedzy. Najnowocześniejsze techniki, które rozwiązują ten problem, choć coraz bardziej dokładne, są wymagane obliczeniowo. W niniejszym artykule przedstawiamy predykcję linków jako rzadki program wypukły, którego rozwiązanie definiuje formę kwadratową, która jest używana jako funkcja rankingu. Struktura naszego programu wypukłego jest taka, że standardowe pakiety oprogramowania maszyn wektorowych, które są numerycznie solidne i wydajne, mogą go rozwiązać. Pokazujemy, że w przypadku zestawów danych referencyjnych wydajność naszego modelu jest konkurencyjna w stosunku do najnowocześniejszych modeli, ale czas treningu można skrócić o czynnik 40 przy użyciu wyłącznie zasobów obliczeniowych opartych na procesorze (a nie akceleracji GPU). Takie podejście może być odpowiednie dla zastosowań, w których pożądanym kompromisem jest równoważenie wymagań związanych z wydajnością wykresu z wydajnością obliczeniową.', 'ml': 'വസ്തുക്കള്\u200dക്കും അറിവുള്ള ഗ്രാഫുകള്\u200dക്കും തമ്മിലുള്ള ബന്ധങ്ങള്\u200dക്കുമിടയില്\u200d ബന്ധപ്പെടുന്ന പ്രവച ഈ പ്രശ്നത്തെ വിശദീകരിക്കുന്ന കലാകാര്യ സാങ്കേതികവിദ്യയുടെ അവസ്ഥ, കൂടുതല്\u200d വിശദീകരിച്ചാല്\u200d കണക്കില്\u200d വളര ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d ഒരു സ്പാസ് കോണ്\u200dക്സ് പ്രോഗ്രാമില്\u200d ലിങ്ക് പ്രവചനം ആക്കുന്നു. അതിന്റെ പരിഹാരം ഒരു റാങ്ങിങ്ങ് ഫോ നമ്മുടെ കോണ്\u200dക്സ് പ്രോഗ്രാമിന്റെ അടിസ്ഥാനമാണ് വെക്റ്റര്\u200d പിന്തുണയ്ക്കുന്നത് വെക്റ്റര്\u200d മെഷീന്\u200d സോഫ്റ്റ്വെയര്\u200d പാക ബെങ്ക്മാര്\u200dക്ക് ഡേറ്റാ സജ്ജീകരണങ്ങളില്\u200d ഞങ്ങള്\u200d കാണിക്കുന്നു, ഞങ്ങളുടെ മോഡലിന്റെ പ്രവര്\u200dത്തനം കലാകൃത മോഡലുകളുടെ സ്ഥിതിയോട് മത്സരിക്കുന്നു. പക്ഷെ പരിശീലന ഈ പ്രയോഗങ്ങള്\u200dക്ക് അനുയോജ്യമായിരിക്കാം. ഗ്രാഫ് പൂര്\u200dത്തിയാക്കാനുള്ള ആവശ്യങ്ങള്\u200d തൂക്കം ചെയ്യുന്നതില്\u200d ഗ്രാഫ് പ്രവര്\u200dത്', 'sr': 'Mi rješavamo problem povezanja predviđanja između entiteta i odnosa grafika znanja. Država umjetničkih tehnika koje rješavaju ovaj problem, dok su sve tačnije, računalno intenzivne. U ovom papiru stavljamo predviđanje povezanja kao rezervni konveks program čije rešenje definiše kvadratski oblik koji se koristi kao funkcija reda. Struktura našeg konveksa programa je takva da bi standardni paketi za vektor mašine za softver, koji su brojno robni i efikasni, mogli rešiti to. Pokazujemo da na setu podataka o benchmarku, izvodnja našeg model a je konkurentna sa stanjem umjetničkih modela, ali trening vremena može biti smanjena od faktora od 40 korištenja samo računalnih resursa na CPU-u (a ne GPU-ubrzana). Ovaj pristup može biti prikladan za aplikacije u kojima je željna trgovina izbalansiranje zahtjeva za završavanje grafika protiv računalne efikasnosti.', 'it': "Affrontiamo il problema della previsione dei collegamenti tra entità e relazioni dei grafici di conoscenza. Le tecniche all'avanguardia che affrontano questo problema, pur sempre più accurate, sono computazionali intensive. In questo articolo lanciamo la previsione dei collegamenti come un programma convesso sparso la cui soluzione definisce una forma quadratica che viene utilizzata come funzione di ranking. La struttura del nostro programma convesso è tale che i pacchetti software di macchine vettoriali di supporto standard, che sono numericamente robusti ed efficienti, possono risolverlo. Mostriamo che sui set di dati benchmark le prestazioni del nostro modello sono competitive con i modelli all'avanguardia, ma i tempi di formazione possono essere ridotti di un fattore di 40 utilizzando solo risorse di calcolo basate su CPU (e non accelerate da GPU). Questo approccio può essere adatto per applicazioni in cui bilanciare le esigenze delle prestazioni di completamento dei grafici con l'efficienza computazionale è un compromesso auspicabile.", 'ta': "நாம் பொருள்கள் மற்றும் அறிவு வரைபடங்களின் தொடர்புகளுக்கிடையே இணைப்பு முடிவு பிரச்சனையை விளக இந்த பிரச்சனையை முகவரிக்கும் கலை தொழில்நுட்பத்தின் நிலை, அதிகமாக சரியாக இருந்தால், கணக்கில் மிகவும் உறுதியா இந்த காகிதத்தில் நாம் ஒரு சுருக்கும் கான்க்ஸ் நிரலாக இணைப்பு முன்வாக்கியத்தை எறியும். அதன் தீர்வு ஒரு குவாட்ர எங்கள் நெறிமுறை நிரலின் அமைப்பு என்னவென்றால் இயல்பான ஆதரவு இயந்திர மென்பொருள் தொகுப்புகள், அது எண்ணிக்கையாக தொகுக்கப்பட் We show that on benchmark data sets, our model's performance is competitive with state of the art models, but training times can be reduced by a factor of 40 using only CPU-based (and not GPU-accelerated) computing resources.  இந்த செயல்பாடு பயன்பாடுகளுக்கு பொருத்தமானதாக இருக்கலாம். கணக்கீட்டு விளைவுகளுக்கு எதிராக வரைப்படம் முடிவு செயல்பாட்டின் த", 'sv': 'Vi behandlar problemet med länkprognoser mellan entiteter och relationer mellan kunskapsgrafer. De senaste teknikerna som tar itu med detta problem, även om de blir alltmer korrekta, är beräkningsintensiva. I denna uppsats kastar vi länkprognosen som ett glest konvex program vars lösning definierar en kvadratisk form som används som en rangordningsfunktion. Strukturen i vårt konvexa program är sådan att standardprogramvarupaket för vektormaskiner, som är numeriskt robusta och effektiva, kan lösa det. Vi visar att vår modells prestanda på benchmarkdatauppsättningar är konkurrenskraftig med de senaste modellerna, men utbildningstiderna kan minskas med en faktor på 40 med endast CPU-baserade (och inte GPU-accelererade) datorresurser. Detta tillvägagångssätt kan vara lämpligt för tillämpningar där det är önskvärt att balansera kraven på grafkompletteringsprestanda mot beräkningseffektivitet.', 'si': 'අපි දැනගන්න ප්\u200dරශ්නයක් සහ දන්න අනුවෙන් සම්බන්ධතාවක් අතර සම්බන්ධතාවක් සම්බන්ධතාවක්  මේ ප්\u200dරශ්නය විධානය කරන්න පුළුවන් කිරීමේ විද්\u200dයාප්\u200dරශ්නයේ ස්ථිතිය, විශේෂයෙන් සාධාරණය ව මේ පැත්තේ අපි ප්\u200dරශ්නයක් ස්පර්ස් කෝන්වෙක්ස් වැඩසටහනක් විදිහට සම්බන්ධ වැඩසටහනක් වෙනුවෙන් සම්බන්ධ ව අපේ කෝන්වෙක්ස් වැඩසටහනේ නිර්මාණය තමයි ප්\u200dරමාණය සහාය වෙක්ටර් මැෂින් සොෆ්ටවර් පැකේජ්ස්, සංකේතයෙන්  අපි පෙන්වන්නේ බෙන්ච්මාර්ක් දත්ත සැට් වල, අපේ මොඩේල්ගේ ප්\u200dරභාව ප්\u200dරශ්නයක් කියලා කියලා කියලා කියලා, ඒත් ප්\u200dරශ්නයක් වෙලාවට 40 කාලයක් පහ මේ විදියට පුළුවන් වෙන්න පුළුවන් විදියට යුක්ති වෙන්න පුළුවන් වෙන්න පුළුවන් විදියට, ඒ වගේම ග්\u200dරාෆ්', 'so': 'Waxaannu ka sheekaynaynaa dhibaatada wax ku saabsan aqoonta aqoonta dhexdooda. Shaqada farshaxanka oo ku saabsan dhibaatadan, marka lagu sii kordhayo si saxda ah, waxay ku jiraan xisaab aad iyo aad. Qoraalkan waxaynu ku bandhignaa wax la sii sheego oo ah barnaamijka dhaqdhaqaaqa ee ay ku qoran yihiin foom koox ah oo lagu isticmaalo sida wax lagu qoro. Muuqashada barnaamijkeenna waa tusaale ahaan baakadaha qalabka habaarka ee qalabka midowga ah ee qalabka jidhka, kuwaas oo si tiro ah loo tuuro oo faa’iido leh, way xali karaan. Waxaynu muujinnaa in sameynta sameynta sameynta modellkayagu ay is-khilaafsan tahay xaalada samooyinka farshaxanka, laakiin wakhtiyada waxbarashadu waxay u yaraan karaan sabab 40 ah oo ku isticmaalaya CPU oo kaliya (oo aan ahayn GPU-accelerated). This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.', 'ur': 'ہم ایک متعلق اور علم گراف کے ارتباط کے درمیان لینک کی پیش بینی کے مسئلہ سے مشکل کریں گے۔ اس مسئلہ کے مطابق اضافہ کرنے والے هنر تکنیک کی موقعیت، اور زیادہ دقیق ہے، کامپیوتر سے زیادہ اضافہ ہیں۔ ہم نے اس کاغذ میں تغییر کی تغییر لینک ڈال دی ایک اسپرس کنوکس پروگرام کے طور پر جس کا حل ایک چوڈراٹیک فرم کی تعریف کرتا ہے جو ایک رئنگ فعالیت کے طور پر استعمال کیا جاتا ہے. ہمارے کنوکس پروگرام کا ساختار ایسا ہے کہ استاندارڈ سٹارڈ ویکتور ماشین سوفٹ فوٹ پاکیزوں کی سٹارڈ، جو شمارہ طور پر طاقتور اور عمدہ ہیں، اسے حل کر سکتے ہیں. ہم دکھاتے ہیں کہ بنچم مارک ڈیٹ سٹ پر ہمارے موڈل کی عملکرد آرتی موڈل کے موقعیت سے مساوی ہے، لیکن تعلیم وقت 40 کی ایک فاکتور سے کم کر سکتا ہے صرف CPU-based (اور نہ GPU-accelerated) کمپیوٹ منبع کے مطابق۔ یہ تقریبا کاربریوں کے لئے مناسب ہو سکتا ہے جہاں گراف پر کامل کرنا کی خواہشات کو کمپیوٹریشن کاروباری کے خلاف برالیس کرنا چاہتا ہے۔', 'uz': "Biz ma'lumot grafiklari va bogʻlanuvchilar orasidagi bogʻlash muammolarini boshqaramiz. Bu muammolarni boshqaruvchi sanam teknologiya holati, ammo ko'proq aniqlangan holatda hisoblash juda kattalashtiradi. Ushbu hujjatda biz bogʻlamani kichkina konveks dasturi sifatida qoʻshishimiz. Bu hujjatda qidratik shaklni rang funksiyasi sifatida ishlatiladigan kvdratik formatini aniqlaydi. Konveks dasturining tuzilishi, bu oddiy vektor uskunalar dasturi dasturlarini aniqlash mumkin. Biz benchmark maʼlumotlar tarkibida modelimizning bajarishimiz sanam modellari holatida rivojlanadi, lekin taʼminlovchi vaqtlar faqat CPU asosida (GPU-tezlikga emas) kompyuterni foydalanishi mumkin 40dan foydalanishi mumkin. This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.", 'vi': 'Chúng tôi giải quyết vấn đề tiên đoán liên kết giữa các thực thể và quan hệ về đồ thị kiến thức. Các kỹ thuật nghệ thuật hiện đại nhằm giải quyết vấn đề này, càng chính xác hơn, lại tăng cường tính năng. In this paper we cast link prediction as a spare convex program whose solution describe a quadratic form that is used as a ranking function. Cấu trúc của chương trình ngôn ngữ thông thường như thế những gói phần mềm cỗ máy vector, hỗ trợ sức mạnh và hiệu quả có thể giải quyết nó. Chúng tôi cho thấy rằng trên các bộ dữ liệu tiêu chuẩn, khả năng của mô hình của chúng tôi cạnh tranh với các mẫu nghệ thuật hiện đại, nhưng thời gian huấn luyện có thể bị giảm bằng một nhân tố U40 chỉ s ử dụng các nguồn tính toán dựa trên CPU (và không phải loại tăng tốc GPU). Phương pháp này có thể phù hợp cho ứng dụng khi so sánh nhu cầu hoàn thành đồ thị với hiệu suất tính toán là một sự trao đổi đáng mong đợi.', 'hr': 'Mi rješavamo problem predviđanja veze između entiteta i odnosa znanja. Država umjetničkih tehnika koje rješavaju ovaj problem, dok su sve preciznije, računalno intenzivna. U ovom papiru objavljujemo predviđanje povezanja kao rezervni konveks program čije rješenje definira kvadratski oblik koji se koristi kao redovna funkcija. Struktura našeg konvex programa je tako da standardni paketi za motorne softver za vektore koji su brojno snažni i učinkoviti mogu to riješiti. Pokazujemo da na setu podataka o referenciji, učinkovitost našeg model a je konkurentna s stanjem umjetničkih modela, ali trening vrijeme može biti smanjeno od faktora od 40 koristeći samo računalne resurse na temelju CPU-a (a ne GPU-ubrzano). Ovaj pristup može biti odgovarajući za aplikacije u kojima je željna trgovina izbalansiranja zahtjeva za završavanje grafika protiv računalne učinkovitosti.', 'bg': 'Разглеждаме проблема с прогнозирането на връзките между субектите и отношенията на знанието графики. Най-съвременните техники, които решават този проблем, макар и все по-точни, са изчислително интензивни. В тази статия ние излъчваме прогнозиране на връзките като рядка изпъкнала програма, чието решение определя квадратна форма, която се използва като функция за класиране. Структурата на нашата изпъкнала програма е такава, че стандартните софтуерни пакети за поддръжка на векторни машини, които са цифрово здрави и ефективни, могат да го решат. Показваме, че при базови набори от данни производителността на модела ни е конкурентна с най-съвременните модели, но времето за обучение може да бъде намалено с 40, като се използват само базирани на процесор (а не ускорени от GPU) изчислителни ресурси. Този подход може да бъде подходящ за приложения, при които балансирането на изискванията за изпълнение на графиките спрямо изчислителната ефективност е желателно компромис.', 'nl': 'We behandelen het probleem van koppelvoorspelling tussen entiteiten en relaties van kennisgrafieken. State of the art technieken die dit probleem aanpakken, hoewel steeds nauwkeuriger, zijn rekenintensief. In dit artikel beschouwen we linkvoorspelling als een dun convex programma waarvan de oplossing een kwadratische vorm definieert die wordt gebruikt als een rangschikfunctie. De structuur van ons convexe programma is zodanig dat standaard ondersteuningsvectormachinesoftwarepakketten, die numeriek robuust en efficiënt zijn, het kunnen oplossen. We laten zien dat op benchmarkdatasets de prestaties van ons model concurrerend zijn met state-of-the-art modellen, maar trainingstijden kunnen worden verkort met een factor 40 met alleen CPU-gebaseerde (en niet GPU-versnelde) rekenbronnen. Deze aanpak kan geschikt zijn voor toepassingen waar het balanceren van de eisen van de voltooiing van grafieken tegen rekenefficiëntie een wenselijke compromis is.', 'de': 'Wir behandeln das Problem der Verknüpfungsprädiktion zwischen Entitäten und Beziehungen von Wissensgraphen. State-of-the-art Techniken, die dieses Problem angehen, sind zwar immer genauer, aber rechenintensiv. In diesem Beitrag betrachten wir die Linkprädiktion als spärliches konvexes Programm, dessen Lösung eine quadratische Form definiert, die als Rangfunktion verwendet wird. Die Struktur unseres konvexen Programms ist so, dass Standard-Support-Vektormaschinen-Softwarepakete, die numerisch robust und effizient sind, es lösen können. Wir zeigen, dass auf Benchmark-Datensätzen die Leistung unseres Modells mit den modernsten Modellen konkurriert, aber die Trainingszeiten können um den Faktor 40 reduziert werden, indem nur CPU-basierte (und nicht GPU-beschleunigte) Rechenressourcen verwendet werden. Dieser Ansatz kann für Anwendungen geeignet sein, bei denen ein ausgewogener Ausgleich der Anforderungen an die Leistung der Graphenvervollständigung mit der Recheneffizienz ein wünschenswerter Kompromiss ist.', 'id': 'Kami mengatasi masalah prediksi hubungan antara entitas dan hubungan grafik pengetahuan. Teknik seni yang mengatasi masalah ini, sementara semakin akurat, secara komputasional intens. Dalam kertas ini kita melemparkan prediksi link sebagai program konveks yang jarang yang solusinya mendefinisikan bentuk kuadratik yang digunakan sebagai fungsi peringkat. Struktur dari program konveks kita adalah seperti bahwa paket perangkat lunak vektor standar, yang secara numerik kuat dan efisien, dapat memecahkannya. Kami menunjukkan bahwa pada set data benchmark, prestasi model kami adalah kompetitif dengan model terbaik, tetapi waktu latihan dapat dikurangi oleh faktor 40 menggunakan hanya sumber komputer berdasarkan CPU (dan bukan GPU-accelerated). This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.', 'ko': '우리는 실체 간의 링크 예측과 지식도의 관계 문제를 해결했다.이 문제를 해결하는 최신 기술은 갈수록 정확해지고 있지만 계산량은 매우 크다.본고에서 우리는 체인 예측을 희소한 계획으로 전환하고 2차형을 정의하여 정렬 함수로 사용한다.우리의 캠페인 구조는 표준적인 지원 벡터 패키지가 이 문제를 해결할 수 있다는 것이다. 이런 패키지는 수치적으로 건장하고 효율적이다.기준 데이터 세트에서 우리 모델의 성능은 최첨단 모델과 경쟁력이 있지만 GPU 가속이 아닌 CPU 기반 컴퓨팅 리소스만으로 훈련 시간을 40배 줄일 수 있음을 보여줍니다.이런 방법은 균형 도형의 완성 성능과 계산 효율 수요의 응용에 적용될 수 있다.', 'sw': 'Tunaongelea tatizo la utabiri wa kiungo kati ya vituo na mahusiano ya picha za maarifa. Serikali ya mbinu za sanaa zinazozungumzia tatizo hili, wakati ambapo kinaongezeka kuwa sahihi, zina kiasi kikubwa. Katika karatasi hii tunaweka utabiri wa kiungo kama mpango wa mkanganyiko mkubwa ambao ufumbuzi wake unaelezea aina ya quadratic inayotumiwa kama kazi ya rangi. Miundombinu ya programu yetu ya kompyuta ni kama vile vifaa vya zana za kompyuta za mkono wa viwanda vya kawaida vinaweza kutatua. Tunaonyesha kwamba katika seti za taarifa za bendera, utendaji wa mifano yetu una ushindani na hali ya mifano ya sanaa, lakini wakati wa mafunzo yanaweza kupungua kwa sababu ya 40 tu kwa kutumia rasilimali za kompyuta za CPU tu (na sio GPU-haraka). Hatua hii inaweza kuwa sahihi kwa matumizi ambapo kulinganisha mahitaji ya upatikanaji wa picha dhidi ya ufanisi wa kompyuta ni biashara inayohitajika.', 'da': 'Vi behandler problemet med forbindelsesforudsigelse mellem enheder og relationer af vidensgrafer. De nyeste teknikker, der løser dette problem, selvom de bliver mere nøjagtige, er beregningsintensive. I denne artikel kaster vi link forudsigelse som et sparsomt konvekst program, hvis løsning definerer en kvadratisk form, der bruges som en rangeringsfunktion. Strukturen i vores konvekse program er sådan, at standard support vektor maskine software pakker, som er numerisk robuste og effektive, kan løse det. Vi viser, at vores models ydeevne på benchmarkdatasæt er konkurrencedygtig med topmoderne modeller, men træningstiden kan reduceres med en faktor på 40 ved hjælp af kun CPU-baserede (og ikke GPU-accelererede) computerressourcer. Denne fremgangsmåde kan være velegnet til applikationer, hvor det er ønskeligt at afveje kravene til graffærdiggørelsesydelse mod beregningseffektivitet.', 'af': "Ons adres die probleem van skakel voorskou tussen entiteite en relasies van kennis grafieke. Staat van die kuns teknike wat hierdie probleem aangesluit, terwyl die vermeerder presies is, is rekenaar intensief. In hierdie papier gooi ons skakel voorskou as 'n sparse konveks program wie se oplossing definieer 'n quadratik vorm wat gebruik word as 'n ranking funksie. Die struktuur van ons konvex program is so dat standaard ondersteunde vektor masjien sagteware pakkette, wat numeries kragtige en effektief is, dit kan oplos. Ons wys dat op benchmark data stel, on s model se prestasie is kompetief met staat van die kuns modelle, maar onderwerking tyde kan verduur word deur 'n faktor van 40 deur slegs CPU-gebaseerde (en nie GPU-versneller) rekenaar hulpbronne te gebruik. Hierdie toegang dalk mag geskik wees vir toepassings waar die versoeke van graaf volledige prestasie teen rekenaar effektiviteit balanse is 'n desiewe handel af.", 'tr': 'Biz öz bilim grafikleriniň guramlaryň we babatynyň önümlenişiniň meselesini çözýäris. Bu meseleyi çözýän sungat teknikleriniň durumyny düýbünden has dogry ýagdaýda hasaplanýar. Bu kagyzda biz uzak bir konveks program ı olarak baglaşdyrýarys. çözümi bir kvadratik şeklini düzümlendirir. Konvex program ımızın yapısı, bu şekilde standart vektör makinelerin destekleme paketleri sayıda güçlü ve etkili bir şekilde çözebilir. Biz benchmark maglumaty düzümlerinde, nusgasymyzyň çykyşymyz sungat modelleriň durumynda döwletlidir, ýöne eğitim wagtlary diňe CPU-dan (ýöne GPU-dan geçirilýän) hasaplanjak resurslaryny ulanan 40-nji faktor tarapyndan azaltabiler. Bu ýagdaý kompýuter etkinliýasyna garşy grafik tamamlanmasy isleýän işlemleri üçin ýeterli bolup biler.', 'am': 'የውይይት ግንኙነት እና እውቀት ካርፎች መካከል የግንኙነት ጉዳይ እናቆይታለን፡፡ ይህንን ጉዳይ የሚጠቅምበት የዐርድ ዘጠኝ ስህተት፣ በተጨማሪው ቁጥጥር በቁጥጥር አነስተኛ ነው፡፡ በዚህ ካላት ውስጥ የኮንኮንክስ ፕሮግራም ማሳየትን እናሳውቃለን፡፡ የግንኙነት ፕሮግራሙን መሠረት እንደዚህ ነው፤ የደጋሚ የዌctor መሣሪያን የሶፍትዌር ጥቅሎች፣ እነዚህም በቁጥር የሚነጥፉ እና ፍቃድ ያሉት ሊፈትኑት ይችላል፡፡ በአብልኬት ዳታዎችን እናሳየዋለን፤ የሞዴል አድራሻ የዐርድ ዓይነቶች ግንኙነት ይቃወማል፤ ነገር ግን የተማረከ ዘመናት በCPU-based (GPU-accelerated አይደለም) ክፍተት ብቻ ሳይሆን በ40ው ምክንያት ይጎድላል፡፡ This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.', 'sq': 'Ne trajtojmë problemin e lidhjes parashikimit midis njësive dhe marrëdhënieve të grafikave të njohurive. Teknikët më të larta që trajtojnë këtë problem, ndërsa janë gjithnjë e më të sakta, janë kompjuterikisht intensive. Në këtë letër ne hedhim parashikimin e lidhjes si një program të vogël konveksi, zgjidhja e të cilit përcakton një form ë kuadratike që përdoret si një funksion renditjeje. Struktura e program it tonë të konveksit është e tillë që paketat standarde të softuereve të mjeteve vektorore, të cilat janë numerikisht të forta dhe të efektshme, mund ta zgjidhin atë. Ne tregojmë se në grupet e të dhënave të referuara, performanca e modelit tonë është konkurruese me modelet më të avancuar, por kohët e trajnimit mund të reduktohen me një faktor prej 40 duke përdorur vetëm burime kompjuterike të bazuara në CPU (dhe jo GPU-të të përshpejtuara). Ky qasje mund të jetë i përshtatshëm për aplikimet ku ekuilibrimi i kërkesave të përfundimit të grafikut ndaj efektshmërisë llogaritare është një kompromis i dëshirueshëm.', 'fa': 'ما مشکل پیش بینی از ارتباطات و ارتباطات گرافیک دانش را حل می کنیم. وضعیت تکنیک هنری که این مشکل را حل می\u200cکند، در حالی که بیشتر دقیق می\u200cشود، به محاسبه\u200cی محاسبه شدت است. در این کاغذ ما پیش\u200cبینی\u200cها را به عنوان برنامه\u200cی نقاشی\u200cهای نقاشی که راه حلش یک فرم چهارداریک را تعریف می\u200cکند که به عنوان یک عملکرد نقاشی استفاده می\u200cشود ارتباط می\u200cدهیم. ساختار برنامه convex ما این است که بسته های دستگاه پشتیبانی ویکتور استاندارد است که به طور شماره قدرتمند و موثر هستند، می تواند آن را حل کند. ما نشان می دهیم که روی مجموعه\u200cهای داده\u200cهای صندوق، عملکرد مدل ما با وضعیت مدل هنر مسابقه است، ولی زمان آموزش می\u200cتواند با یک faktor از ۴۰ با استفاده از تنها منابع محاسبه\u200cهای صندوق\u200cهای صندوق (و نه با فشار GPU) کمتر شود. این روش ممکن است برای کاربردهای مناسب باشد که تعداد نیازهای کامل کردن گراف علیه کاربردی محاسبات یک تجارت لازم است.', 'bn': 'আমরা বিষয়বস্তু এবং জ্ঞান গ্রাফের সম্পর্কের মধ্যে লিঙ্কের ভবিষ্যতের সমস্যা নিয়ে কথা বলি। এই সমস্যাটিকে ঠিক করা শিল্প প্রযুক্তির রাষ্ট্র, যারা এই সমস্যার বিষয়টি বাড়তে থাকে, কিন্তু ক্রমশ পরিস্থিতির এই কাগজটিতে আমরা লিঙ্কের ভবিষ্যৎবাণী প্রোগ্রাম হিসেবে প্রকাশ করি যার সমাধান একটি কোয়াড্রাটিক ফর্মের সংশোধন করে যা  আমাদের কনকস্ট প্রোগ্রামের কাঠামো হলো যে স্বাভাবিক সমর্থন মেশিন সফটওয়্যার প্যাকেজ, যা সংখ্যাকভাবে ডাকাতি এবং কার্যকর আমরা দেখাচ্ছি যে বেনম্যার্ক ডাটা সেটে আমাদের মডেলের প্রভাব শিল্প মডেলের রাষ্ট্রের প্রতিযোগিতা করছে, কিন্তু প্রশিক্ষণের সময় শুধুমাত্র সিপিউ ভিত্তিক (জি এই প্রযুক্তিটি সম্ভবত অ্যাপ্লিকেশনের জন্য যথেষ্ট যেখানে গ্রাফ সম্পূর্ণ করার দাবি সমান করা যায়, গণনাত্রিক কার্যকরের বিরু', 'hy': 'Մենք լուծում ենք կապը կանխատեսելու և գիտելիքի գրաֆիկների հարաբերությունների միջև: Այս խնդիրը լուծելու ամենաբարձր տեխնոլոգիաները, սակայն ավելի ճշգրիտ են, հաշվարկների առումով ինտենսիվ են: Այս թղթի մեջ մենք կապ կանխատեսում ենք որպես հազվադեպ ծրագիր, որի լուծումը սահմանում է քառակուսի ձև, որը օգտագործվում է որպես դասակարգման ֆունկցիա: Մեր համընդհանուր ծրագրի կառուցվածքն այնպիսի է, որ ստանդարտ աջակցության մեքենայի ծրագրավորման փաթեթները, որոնք թվային առումով ուժեղ և արդյունավետ են, կարող են լուծել այն: Մենք ցույց ենք տալիս, որ մեր մոդելի արտադրողականությունը համընդհանուր է ամենաբարձր մոդելների հետ, սակայն ուսումնասիրության ժամանակը կարող է կրճատվել 40 գործոնով, օգտագործելով միայն CPU-ի հիմնված (և ոչ GPU-ի արագացված) համակարգչային ռեսուրսները: Այս մոտեցումը կարող է համապատասխանել ծրագրերի համար, երբ հավասարակշռությունը գծագրի ավարտացման պահանջներին համեմատական արդյունավետության հետ կապված է ցանկալի հակամարտությամբ:', 'az': 'Biz m…ôlumatlarńĪn v…ô elm grafikl…ôrinin …ôlaq…ôl…ôri arasńĪnda bańülantńĪlńĪ t…ôdbirl…ôrinin problemini √ß…ôkirik. Bu problemi √ß…ôk…ôn sanat teknikl…ôrin durumu, daha dońüru olaraq, hesabda √ßox Ňüidd…ôtli olaraq. Bu kańüńĪzda biz m√ľ…ôyy…ôn etdiyimiz t…ôdbirl…ôri uzaq bir konveks proqramńĪ olaraq bańülayńĪrńĪq, √ß√∂z√ľm√ľ bir kvadratik formu kimi istifad…ô edilir. Konvex proqramńĪmńĪzńĪn qurulmasńĪ standart vektor maŇüńĪna proqramńĪ paketl…ôridir ki, sayńĪda q√ľvv…ôtli v…ô effektiv olaraq bunu √ß…ôk…ô bil…ôr. Biz g√∂st…ôririk ki, benchmark veril…ôr setl…ôrind…ô modell…ôrin performansńĪ sanat modell…ôrin durumu il…ô m√ľqayis…ôdir, amma t…ôhsil zamanlarńĪ sadece CPU tabanlńĪ (GPU-t…ôl…ôsirli) hesablama resurslarńĪndan istifad…ô ed…ôr…ôk 40 faktoru il…ô azaldńĪrńĪla bil…ôr. Bu t…ôrzim bil…ôr ki, bilgisayar faydalanńĪlńĪqlarńĪna qarŇüńĪ grafik tamamlama t…ôrzl…ôrinin m√ľqabiliyy…ôtini balanlaŇüdńĪrmaq √ľ√ß√ľn uyńüun olar.', 'bs': 'Mi rješavamo problem predviđanja veze između entiteta i odnosa grafika znanja. Država umjetničkih tehnika koje rješavaju ovaj problem, dok su sve preciznije, računalno intenzivna. U ovom papiru stavljamo predviđanje povezanja kao rezervni konveks program čije rješenje definira kvadratični oblik koji se koristi kao redovna funkcija. Struktura našeg konveksa programa je tako da standardni paketi za motorne programe za vektore, koji su brojno robni i efikasni, mogu to riješiti. Pokazujemo da na setu podataka o benchmarku, izvodnja našeg model a je konkurentna sa stanjem umjetničkih modela, ali trening vremena može biti smanjena od faktora od 40 koristeći samo računalne resurse na procesu (a ne GPU-ubrzano). Ovaj pristup može biti odgovaran za aplikacije u kojima je željna trgovina izbalansiranja zahtjeva za završavanje grafika protiv računalne učinkovitosti.', 'fi': 'Käsittelemme entiteettien ja tietokaavioiden välisten yhteyksien ennustamisen ongelmaa. Nykyaikaiset tekniikat, jotka käsittelevät tätä ongelmaa, ovat yhä tarkempia, mutta laskennallisesti intensiivisiä. Tässä työssä luotiin linkkiennuste harvaan kupera ohjelma, jonka ratkaisu määrittelee neliömuodon, jota käytetään sijoitusfunktiona. Kuveksi ohjelmamme rakenne on sellainen, että standardit tukivektorikoneohjelmistopaketit, jotka ovat numeerisesti kestäviä ja tehokkaita, voivat ratkaista sen. Osoitamme, että vertailudatakokonaisuuksissa mallimme suorituskyky on kilpailukykyinen uusimpien mallien kanssa, mutta harjoitusaikoja voidaan lyhentää 40-kertaisesti käyttämällä vain suoritinpohjaisia (eikä GPU-kiihdytettyjä) laskentaresursseja. Tämä lähestymistapa voi soveltua sovelluksiin, joissa graafisen suorituskyvyn ja laskennallisen tehokkuuden vaatimusten tasapainottaminen on toivottavaa kompromissia.', 'ca': "Ens ocupem del problema de la predicció dels enllaços entre les entitats i les relacions dels gràfics del coneixement. Les tècniques més avançades que aborden aquest problema, tot i més exactes, són computacionalment intensives. In this paper we cast link prediction as a sparse convex program whose solution defines a quadratic form that is used as a ranking function.  L'estructura del nostre programa convex és de tal manera que els paquets de software standard de suport per aparells vectors, que són numèricament robustos i eficients, ho poden resoldre. Mostrem que en els conjunts de dades de referència, el rendiment del nostre model és competitiu amb els models més avançats, però el temps d'entrenament pot ser reduït per un factor de 40 utilitzant només recursos informàtics basats en CPU (i no accelerats en GPU). Aquest enfocament pot ser adequat per aplicacions on equilibrar les exigències del rendiment del gràfic amb l'eficiència computacional és un compromís desitjable.", 'cs': 'Řešíme problém predikce vazeb mezi entitami a vztahy znalostních grafů. Nejmodernější techniky, které řeší tento problém, i když jsou stále přesnější, jsou výpočetně náročné. V tomto článku uvádíme predikci vazeb jako řídký konvexní program, jehož řešení definuje kvadratickou formu, která se používá jako funkce hodnocení. Struktura našeho konvexního programu je taková, že standardní podpůrné vektorové softwarové balíčky, které jsou číselně robustní a efektivní, ji mohou vyřešit. Ukazujeme, že na benchmarkových datových sadách je výkon našeho modelu konkurenceschopný nejmodernějším modelům, ale tréninková doba může být zkrácena o čtyřicet pomocí výpočetních zdrojů založených na procesoru (a nikoli akcelerovaných GPU). Tento přístup může být vhodný pro aplikace, kde je žádoucím kompromisem vyvážení požadavků na dokončování grafů s výpočetní efektivitou.', 'et': 'Käsitleme sidemete prognoosimise probleemi üksuste ja teadmiste graafikute vahel. Tipptasemel tehnikad, mis lahendavad seda probleemi, on üha täpsemad, kuid arvutuslikult intensiivsed. Käesolevas töös valame lingi ennustamine kui hõreda kumera programmi, mille lahendus määratleb ruutvormi, mida kasutatakse järjestusfunktsioonina. Meie kumera programmi struktuur on selline, et standardsed toetusvektormasinate tarkvarapaketid, mis on arvuliselt tugevad ja tõhusad, suudavad seda lahendada. Näitame, et võrdlusandmekogumite põhjal on meie mudeli jõudlus konkurentsivõimeline tipptasemel mudelitega, kuid treeningaega saab vähendada 40 korda, kasutades ainult protsessoripõhiseid (ja mitte GPU kiirendatud) arvutiressursse. See lähenemisviis võib sobida rakenduste puhul, kus graafikutöötluse ja arvutustõhususe nõudmiste tasakaalustamine on soovitav kompromiss.', 'jv': 'Awak dhéwé éntuk perbudhakan kanggo nglanggar tarjamahan karo perusahaan kanggo nggawe barang nggawe barang. Tulung sampeyan karo teknik sing beraksi perbudhakan iki, akeh iso akeh sing apik dadi, lan akeh sampeyan tambahan. Awak dhéwé énggo pernik ngéwangaké convex program seng..." Ngubah sistem convex program iki banget supoyo pakan vector-pakan pakan pakan sing sampeyan karo akeh lan alam sing dinor, iso disebarke @bench_BAR_ Ndheke iki iso ngejaraké aplikasi kanggo ngbalan kanggo nggawe geranggap perusahaan mulasar tentang kanggo rawuh akeh komputer', 'ha': "Munã jãyayya matsalar abin da ke iya bayani ga jigo da mazaɓa da masu danganki na fassarar zane. Halin kungiyar da ke tambayar wannan mataimaki, kuma a ƙara yana da ƙayyade lissafi. Ga wannan takardan, Munã jẽfa linki kamar wata shirin samun konsolse na ƙara, wanda suluna na ƙayyade wani fomat wanda za'a yi amfani da shi kamar wata functin rangi. Amfanin shirin ayukanmu na konkox, yana kama da zane buɗe masu amfani da shiryoyin kwamfyutan tebur masu motsi da kwamfyutan tebur masu yiwuwa, da kuma masu iya amfani da shi, za'a nuna shi. Tuna nũna cewa, a kan daidaita data na bangon, mai amfani da misalinmu yana ƙaranci da halin misãlai na sanar, kuma amma yana iya ƙarantar da zaman shawarar da za'a yi amfani da manyan lissafi na CPU kawai (kuma ba GPU-accelerated) ba. This approach may be suitable for applications where balancing the demands of graph completion performance against computational efficiency is a desirable trade-off.", 'sk': 'Obravnavamo problem napovedovanja povezav med entitetami in razmerji znanja grafov. Najsodobnejše tehnike, ki obravnavajo ta problem, so čeprav vse bolj natančne, računalniško intenzivne. V tem članku smo predstavili napoved povezav kot redki konveksni program, katerega rešitev definira kvadratno obliko, ki se uporablja kot funkcija razvrščanja. Struktura našega konveksnega programa je taka, da ga lahko rešijo standardni programski paketi vektorskih strojev, ki so numerično robustni in učinkoviti. Pokazujemo, da je zmogljivost našega modela na podlagi referenčnih podatkovnih nizov konkurenčna z najsodobnejšimi modeli, vendar je čas treninga mogoče skrajšati za 40 faktorjev z uporabo računalniških virov, ki temeljijo na CPU (in ne z GPU pospešenimi). Ta pristop je lahko primeren za aplikacije, kjer je uravnoteženje zahtev glede uspešnosti dokončanja grafov in računalniške učinkovitosti zaželen kompromis.', 'bo': "ང་ཚོས་དབྱིབས་དང་དབྱིབས་འབྲེལ་བ་དང་དབྱིབས་ཤེས་པའི་རྣམ་གྲངས་ཀྱི་སྦྲེལ་མཐུད་ཀྱི་དཀའ་ངལ དཀའ་ངལ་འདི་ལ་བཤད་པའི་སྒྱུ་རྩལ་གྱི་གནས་སྟངས་ཀྱི་གནས་སྟངས་དེ་འགྱུར་མཁན་དེ་ལས་ཀྱང་དཀའ་ངལ་ཡོད་པ་དང་། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་རྒྱབ་སྐྱོར་མིན་པའི་སྔོན་ཚུལ་འབྲེལ་བ་ཞིག་འཇུག ང་ཚོའི་convex བྱ་རིམ་གྱི་དབང་ཆ་ནི་འདིའི་སྔོན་སྒྲིག་གིས་རྒྱབ་སྐྱོར་ཆས་མཉེན་ཆས་ཐུམ་སྒྲིལ་ཚུ།གྲངས་སྒྲིག་ཆ་ཉེན་ We show that on benchmark data sets, our model's performance is competitive with state of the art models, but training times can be reduced by a factor of 40 using only CPU-based (and not GPU-accelerated) computing resources. འདི་ལྟ་བུའི་ཉེར་སྤྱོད་ཀྱིས་ཉེར་སྤྱོད་གཉིས་ལས་ཕན་ཚུལ་རྒྱུ་ཡིན་ན་གྲངས་རྩིས་ལས་སྤྱོད་ཚད་རྩིས་འཁོར་སྐྱོང་བ་དང་མཐར", 'he': 'אנחנו מתייחסים לבעיה של חיזוי קשרים בין יחסים וליחסים של גרפי ידע. טכניקות המאומנות שמטפלות בבעיה הזאת, בעוד מדויקות יותר ויותר, אינטנסיביות מחשבית. In this paper we cast link prediction as a sparse convex program whose solution defines a quadratic form that is used as a ranking function.  המבנה של התוכנית הקונבקס שלנו הוא כזה שתוכלו לפתור את חבילות התוכנות של מכונות ויקטור תמיכה סטנדרטיות אנחנו מראים שבקבוצות נתונים של רנטרל, ההופעה של המודל שלנו תחרותית עם מודלים מוקדמים, אבל זמני האימונים יכולים להיפחות על ידי גורם של 40 באמצעות משאבי מחשב מבוססים רק על CPU (ולא GPU-מאיץ). הגישה הזאת יכולה להיות מתאימה ליישומים כאשר האיזון ביצועים של ביצועי השלמת הגרף עם יעילות מחשבית הוא הסכם רצוי.'}
{'en': 'Limitations of Knowledge Distillation for Zero-shot Transfer Learning', 'pt': 'Limitações da Destilação de Conhecimento para Aprendizado de Transferência Zero-shot', 'ar': 'حدود تقطير المعرفة لتعليم النقل بدون طلقة', 'fr': "Limites de la distillation des connaissances pour l'apprentissage par transfert zéro injection", 'es': 'Limitaciones de la destilación de conocimientos para el aprendizaje de transferencia cero', 'ja': 'ゼロショット転送学習のための知識蒸留の限界', 'ru': 'Ограничения дистилляции знаний для обучения с нулевым выстрелом', 'hi': 'शून्य-शॉट स्थानांतरण सीखने के लिए ज्ञान आसवन की सीमाएं', 'zh': '知识提炼零次迁学之局限性', 'ga': "Teorainneacha ar Dhriogadh Eolais d'Fhoghlaim Aistrithe Nialais", 'hu': 'A tudás desztillációjának korlátai a nulla lövéses transzfer tanuláshoz', 'ka': 'Name', 'el': 'Περιορισμοί της απόσταξης γνώσης για τη μάθηση μηδενικής μεταφοράς', 'mk': 'Ограничување на дистилацијата на знаење за нуларно преносно учење', 'ms': 'Had Distillasi Pengetahuan untuk Pelajaran Pemindahan Semula Tembakan', 'it': "Limitazioni della distillazione della conoscenza per l'apprendimento a trasferimento zero", 'lt': 'Žinių distiliacijos apribojimai, taikomi mokymuisi perkelti nulinius nuotraukus', 'ml': 'Limitations of Knowledge Distillation for Zero-shot Transfer Learning', 'no': 'Avgrensingar av kjennomsnittforstyring for læring av nullstatt overføring', 'pl': 'Ograniczenia destylacji wiedzy dla uczenia się z transferem zerowym', 'ro': 'Limitări ale distilării cunoștințelor pentru învățarea transferului zero-shot', 'sr': 'ograničenja destilacije znanja za učenje nuklearnog prijenosa', 'mt': 'Limitations of Knowledge Distillation for Zero-shot Transfer Learning', 'so': 'Limitaanka sharciga aqoonta barashada wareejinta', 'si': 'Name', 'mn': 'Зуун шоу дамжуулах сургалтын мэдлэг халдварын хязгаарлалт', 'sv': 'Begränsningar av kunskapsdestillation för Zero-shot Transfer Learning', 'kk': 'Нөл түрлі тасымалдау оқыту үшін білім бөлімінің шектеулері', 'ta': 'சூழ்நிலையான மாற்று கற்றத்திற்கான அறிவு திருப்பங்களின் எல்லைகள்', 'ur': 'صفر-شٹ ٹرنسفر سیکھنے کے لئے علم دیسٹلیشن کی محدودیت', 'uz': 'Limitations of Knowledge Distillation for Zero-shot Transfer Learning', 'vi': 'Giới hạn học đòi hỏi phân tách về truyền đạt', 'bg': 'Ограничения на дестилацията на знанията за обучение с нулев трансфер', 'nl': 'Beperkingen van Kennisdestillatie voor Zero-shot Transfer Learning', 'da': 'Begrænsninger af videndedestillation til Zero-shot Transfer Learning', 'hr': 'Ograničenja destilacije znanja za učenje nuklearnog prijenosa', 'ko': '영사 전이 학습 중 지식 추출의 한계성', 'de': 'Grenzen der Wissensdestillation für Zero-Shot Transfer Learning', 'fa': 'محدودیت تغییر دانش برای یادگیری انتقال صفر', 'id': 'Limitasi Distillasi Pengetahuan untuk Pembelajaran Transfer Zero-shot', 'sw': 'Limitations of Knowledge Distillation for Zero-shot Transfer Learning', 'tr': 'Zero-shot öwrenmek üçin Bilim Taýdalygynyň süýtgedmeleri', 'sq': 'Limitimet e Distillimit të njohurive për Mësimin e Transferimit Zero-Shots', 'af': 'Beperking van kennis afdeling vir Nuwe- skoot Oordrag Leer', 'am': 'ምርጫዎች', 'hy': 'Գիտության դիստիլացիայի սահմանափակումները զրո-նկարների փոխանցման ուսումնասիրության համար', 'az': 'Sıfır-vuruş Öyrənməsi üçün Bilim Destilməsi', 'bn': 'শিক্ষা শিক্ষার জন্য জ্ঞান বিভ্রান্তির সীমাবদ্ধ', 'bs': 'ograničenja destilacije znanja za učenje prijenosa nula pucnjave', 'cs': 'Omezení destilace znalostí pro učení s nulovým přenosem', 'et': 'Teadmiste destilleerimise piirangud null-shot ülekande õppeks', 'fi': 'Tietojen tislauksen rajoitukset nollashotin siirtooppimiseen', 'ca': "Limitacions de la distilació del coneixement per a l'aprenentatge de transferència zero", 'jv': 'Ngubah punika dipungot Bilih', 'sk': 'Omejitve destilacije znanja za učenje prenosa ničelnega strela', 'he': 'הגבלות של דיסטילציה של ידע ללימודי העברה של אפס יריות', 'ha': 'KCharselect unicode block name', 'bo': 'སྤྱིར་བཏང་བའི་གནས་ཚུལ་སྐོར་གྱི་གནས་སྟངས་ལ་ཤེས་པའི་སྐོར་ཚད'}
{'en': 'Pretrained transformer-based encoders such as BERT have been demonstrated to achieve state-of-the-art performance on numerous NLP tasks. Despite their success, BERT style encoders are large in size and have high latency during inference (especially on CPU machines) which make them unappealing for many online applications. Recently introduced compression and distillation methods have provided effective ways to alleviate this shortcoming. However, the focus of these works has been mainly on monolingual encoders. Motivated by recent successes in zero-shot cross-lingual transfer learning using multilingual pretrained encoders such as mBERT, we evaluate the effectiveness of Knowledge Distillation (KD) both during pretraining stage and during fine-tuning stage on multilingual BERT models. We demonstrate that in contradiction to the previous observation in the case of monolingual distillation, in multilingual settings, distillation during pretraining is more effective than distillation during fine-tuning for zero-shot transfer learning. Moreover, we observe that distillation during fine-tuning may hurt zero-shot cross-lingual performance. Finally, we demonstrate that distilling a larger model (BERT Large) results in the strongest distilled model that performs best both on the source language as well as target languages in zero-shot settings.', 'ar': 'تم إثبات برامج التشفير المعتمدة مسبقًا على المحولات مثل BERT لتحقيق أداء متطور في العديد من مهام البرمجة اللغوية العصبية. على الرغم من نجاحها ، إلا أن برامج التشفير ذات النمط BERT كبيرة الحجم ولها زمن انتقال مرتفع أثناء الاستدلال (خاصة على أجهزة وحدة المعالجة المركزية) مما يجعلها غير جذابة للعديد من التطبيقات عبر الإنترنت. قدمت طرق الضغط والتقطير التي تم إدخالها مؤخرًا طرقًا فعالة للتخفيف من هذا القصور. ومع ذلك ، فإن تركيز هذه الأعمال كان بشكل أساسي على أجهزة التشفير أحادية اللغة. بدافع من النجاحات الأخيرة في تعلم النقل عبر اللغات بدون طلقة باستخدام برامج تشفير متعددة اللغات مثل mBERT ، نقوم بتقييم فعالية تقطير المعرفة (KD) أثناء مرحلة ما قبل التدريب وأثناء مرحلة الضبط الدقيق على نماذج BERT متعددة اللغات. نوضح أنه على عكس الملاحظة السابقة في حالة التقطير أحادي اللغة ، في بيئات متعددة اللغات ، يكون التقطير أثناء التدريب المسبق أكثر فاعلية من التقطير أثناء الضبط الدقيق لتعلم النقل الصفري. علاوة على ذلك ، نلاحظ أن التقطير أثناء الضبط الدقيق قد يضر بأداء التسديد اللغوي المتقاطع. أخيرًا ، نوضح أن استخلاص نموذج أكبر (BERT Large) ينتج عنه أقوى نموذج مقطر يحقق أداءً أفضل في كل من اللغة المصدر واللغات المستهدفة في إعدادات اللقطة الصفرية.', 'pt': 'Os encoders baseados em transformador pré-treinados, como o BERT, demonstraram alcançar desempenho de última geração em várias tarefas de PNL. Apesar de seu sucesso, os codificadores do estilo BERT são grandes em tamanho e têm alta latência durante a inferência (especialmente em máquinas com CPU), o que os torna pouco atraentes para muitos aplicativos online. Os métodos de compressão e destilação recentemente introduzidos forneceram maneiras eficazes de aliviar essa deficiência. No entanto, o foco desses trabalhos tem sido principalmente em codificadores monolíngues. Motivados por sucessos recentes no aprendizado de transferência multilíngue de tiro zero usando codificadores pré-treinados multilíngues, como mBERT, avaliamos a eficácia da Destilação de Conhecimento (KD) tanto durante o estágio de pré-treinamento quanto durante o estágio de ajuste fino em modelos BERT multilíngues. Demonstramos que, em contradição com a observação anterior no caso de destilação monolíngue, em ambientes multilíngues, a destilação durante o pré-treinamento é mais eficaz do que a destilação durante o ajuste fino para o aprendizado de transferência zero-shot. Além disso, observamos que a destilação durante o ajuste fino pode prejudicar o desempenho linguístico de tiro zero. Por fim, demonstramos que a destilação de um modelo maior (BERT Large) resulta no modelo destilado mais forte que apresenta melhor desempenho tanto no idioma de origem quanto nos idiomas de destino em configurações de tiro zero.', 'fr': "Il a été démontré que les codeurs préentraînés à base de transformateurs tels que BERT offrent des performances de pointe sur de nombreuses tâches de PNL. Malgré leur succès, les encodeurs de style BERT sont de grande taille et ont une latence élevée lors de l'inférence (en particulier sur les machines à processeur), ce qui les rend peu attrayants pour de nombreuses applications en ligne. Les méthodes de compression et de distillation récemment introduites ont fourni des moyens efficaces de pallier cette lacune. Cependant, ces travaux ont principalement porté sur les codeurs monolingues. Motivés par les récents succès dans l'apprentissage par transfert multilingue à zéro coup à l'aide d'encodeurs préformés multilingues tels que mBERT, nous évaluons l'efficacité de la distillation des connaissances (KD) à la fois pendant la phase de pré-formation et pendant la phase de réglage fin sur des modèles BERT multilingues. Nous démontrons qu'en contradiction avec l'observation précédente dans le cas de la distillation monolingue, dans des environnements multilingues, la distillation pendant le pré-entraînement est plus efficace que la distillation pendant le réglage fin pour l'apprentissage par transfert zéro. De plus, nous observons que la distillation pendant le réglage fin peut nuire aux performances de la langue croisée zéro. Enfin, nous démontrons que la distillation d'un modèle plus grand (BERT Large) permet d'obtenir le modèle distillé le plus puissant qui fonctionne le mieux à la fois sur la langue source et sur les langues cibles dans des paramètres de tir zéro.", 'es': 'Se ha demostrado que los codificadores preentrenados basados en transformadores, como BERT, logran un rendimiento de vanguardia en numerosas tareas de PNL. A pesar de su éxito, los codificadores de estilo BERT son de gran tamaño y tienen una alta latencia durante la inferencia (especialmente en máquinas con CPU), lo que los hace poco atractivos para muchas aplicaciones en línea. Los métodos de compresión y destilación introducidos recientemente han proporcionado formas eficaces de aliviar este inconveniente. Sin embargo, el enfoque de estos trabajos se ha centrado principalmente en los codificadores monolingües. Motivados por los éxitos recientes en el aprendizaje de transferencia multilingüe de tiro cero utilizando codificadores multilingües preentrenados como mBERT, evaluamos la eficacia de la Destilación del Conocimiento (KD) tanto durante la etapa de preentrenamiento como durante la etapa de ajuste en los modelos BERT multilingües. Demostramos que, en contradicción con la observación anterior en el caso de la destilación monolingüe, en entornos multilingües, la destilación durante el preentrenamiento es más eficaz que la destilación durante el ajuste fino para el aprendizaje de transferencia de tiro cero. Además, observamos que la destilación durante el ajuste fino puede perjudicar el rendimiento interlingüístico de tiro cero. Finalmente, demostramos que la destilación de un modelo más grande (BERT Large) da como resultado el modelo destilado más fuerte que funciona mejor tanto en el idioma de origen como en los idiomas de destino en entornos de tiro cero.', 'ja': 'BERTなどの事前訓練された変圧器ベースのエンコーダは、多数のNLPタスクで最先端のパフォーマンスを達成することが実証されています。 BERTスタイルのエンコーダは、成功しているにもかかわらず、サイズが大きく、推論中（特にCPUマシン上）の遅延が大きいため、多くのオンラインアプリケーションには魅力的ではありません。 最近導入された圧縮及び蒸留方法は、この欠点を緩和するための効果的な方法を提供している。 しかし、これらの作品は主にモノリンガルエンコーダが中心となってきた。 MBERTなどの多言語事前訓練エンコーダを使用したゼロショットのクロスリンガル転送学習の最近の成功に動機づけられている私たちは、事前訓練段階と多言語BERTモデルの微調整段階の両方で知識蒸留（ KD ）の有効性を評価します。 私たちは、単一言語蒸留の場合の前回の観察とは矛盾して、多言語の設定では、ゼロショット転移学習のための微調整中の蒸留よりも、事前トレーニング中の蒸留の方が効果的であることを実証します。 さらに、微調整中の蒸留は、ゼロショットのクロスリンガルパフォーマンスを損なう可能性があることを観察します。 最後に、より大きなモデル（ BERT LARGE ）を蒸留すると、ゼロショット設定でソース言語とターゲット言語の両方で最高のパフォーマンスを発揮する最強の蒸留モデルが得られることを実証します。', 'hi': 'BERT जैसे पूर्व-प्रशिक्षित ट्रांसफॉर्मर-आधारित एन्कोडर को कई एनएलपी कार्यों पर अत्याधुनिक प्रदर्शन प्राप्त करने के लिए प्रदर्शित किया गया है। उनकी सफलता के बावजूद, BERT शैली एन्कोडर आकार में बड़े होते हैं और अनुमान के दौरान उच्च विलंबता होती है (विशेष रूप से CPU मशीनों पर) जो उन्हें कई ऑनलाइन अनुप्रयोगों के लिए अप्रिय बनाती है। हाल ही में पेश किए गए संपीड़न और आसवन विधियों ने इस कमी को कम करने के लिए प्रभावी तरीके प्रदान किए हैं। हालांकि, इन कार्यों का ध्यान मुख्य रूप से मोनोलिंगुअल एनकोडर पर रहा है। MBERT जैसे बहुभाषी pretrained encoders का उपयोग करके शून्य-शॉट क्रॉस-लिंगुअल ट्रांसफर लर्निंग में हाल की सफलताओं से प्रेरित होकर, हम ज्ञान आसवन (केडी) की प्रभावशीलता का मूल्यांकन करते हैं, दोनों प्रीट्रेनिंग चरण के दौरान और बहुभाषी BERT मॉडल पर ठीक-ट्यूनिंग चरण के दौरान। हम प्रदर्शित करते हैं कि मोनोलिंगुअल आसवन के मामले में पिछले अवलोकन के विपरीत, बहुभाषी सेटिंग्स में, प्रीट्रेनिंग के दौरान आसवन शून्य-शॉट ट्रांसफर सीखने के लिए ठीक-ट्यूनिंग के दौरान आसवन की तुलना में अधिक प्रभावी है। इसके अलावा, हम देखते हैं कि ठीक-ट्यूनिंग के दौरान आसवन शून्य-शॉट क्रॉस-लिंगुअल प्रदर्शन को चोट पहुंचा सकता है। अंत में, हम प्रदर्शित करते हैं कि एक बड़े मॉडल (BERT Large) को डिस्टिल करने के परिणामस्वरूप सबसे मजबूत आसुत मॉडल होता है जो स्रोत भाषा के साथ-साथ शून्य-शॉट सेटिंग्स में लक्ष्य भाषाओं पर सबसे अच्छा प्रदर्शन करता है।', 'zh': '盖变压器之预训练编码器( BERT)已证可以众 NLP 而先进者也。 虽有成功,而BERT风编码器尺寸甚大,而推理之际有高延迟(特)于CPU机器,使无吸引力于在线应用程序。 近引压缩蒸馏,以纾其弊。 然其大体在单语编码器。 近用多言预训练编码器(如mBERT)之零次,跨言迁学之基,估其知识蒸馏(KD)于预练阶段及多言BERT微调之有效性。 吾证与前反于单语蒸馏,多言之境,预练之蒸馏,有效于微蒸馏,以成零次迁学。 观微调之蒸馏,或损零次跨语言性能。 最后,我们证明,提炼一个更大的模样(BERT Large)会生最强的提炼模形,该模形在零触发置下源言语上都最佳。', 'ru': 'Предварительно обученные кодировщики на основе трансформаторов, такие как BERT, продемонстрировали, что они достигают самых современных характеристик при выполнении многочисленных задач NLP. Несмотря на свой успех, кодировщики стиля BERT имеют большие размеры и высокую задержку во время вывода (особенно на CPU машинах), что делает их непривлекательными для многих онлайн-приложений. Недавно внедренные методы сжатия и дистилляции обеспечили эффективные способы устранения этого недостатка. Однако основное внимание в этих работах уделялось одноязычным кодировщикам. Основанные на недавних успехах в межязычном обучении с нулевым выстрелом с использованием многоязычных предварительно обученных кодировщиков, таких как mBERT, мы оцениваем эффективность дистилляции знаний (KD) как на этапе предварительного обучения, так и на этапе тонкой настройки на многоязычных моделях BERT. Мы демонстрируем, что вопреки предыдущему замечанию в случае одноязычной дистилляции, в многоязычных условиях дистилляция во время предварительной подготовки является более эффективной, чем дистилляция во время тонкой настройки для обучения передаче с нулевым выстрелом. Кроме того, мы наблюдаем, что дистилляция во время тонкой настройки может повредить кросс-лингвальную производительность с нулевым выстрелом. Наконец, мы демонстрируем, что дистилляция более крупной модели (BERT Large) дает самую сильную дистиллированную модель, которая лучше всего работает как на исходном языке, так и на целевых языках в условиях нулевого снимка.', 'ga': 'Tá sé léirithe go bhfuil ionchódóirí réamhoilte bunaithe ar chlaochladán ar nós BERT ag baint amach feidhmíocht den scoth ar thascanna iomadúla NLP. In ainneoin a n-rathúlachta, tá ionchódóirí stíl BERT mór i méid agus tá siad ard-foighne le linn tátail (go háirithe ar mheaisíní LAP) rud a fhágann nach bhfuil siad tarraingteach do go leor feidhmchlár ar líne. Chuir modhanna comhbhrú agus driogtha a tugadh isteach le déanaí bealaí éifeachtacha ar fáil chun an t-easnamh seo a mhaolú. Mar sin féin, dhírigh na saothair seo go príomha ar ionchódóirí aonteangacha. Arna spreagadh ag an rath a bhí le déanaí i bhfoghlaim aistrithe tras-teanga gan urchar ag baint úsáide as ionchódóirí réamhoilte ilteangacha ar nós mBERT, déanaimid meastóireacht ar éifeachtacht Dhriogadh Eolais (KD) le linn na céime réamhoiliúint agus le linn na céime mionchoigeartaithe ar mhúnlaí ilteangacha BERT. Léirímid go bhfuil contrártha leis an méid a breathnaíodh roimhe seo i gcás driogtha aonteangacha, i suíomhanna ilteangacha, go bhfuil driogadh le linn réamhoiliúint níos éifeachtaí ná driogadh le linn mionchoigeartaithe don fhoghlaim aistrithe náid. Ina theannta sin, tugaimid faoi deara go bhféadfadh go ndéanfadh driogadh le linn mionchoigeartaithe dochar d’fheidhmíocht thrastheangach le nialas lámhaigh. Mar fhocal scoir, léirímid go n-eascraíonn driogadh múnla níos mó (BERT Large) go bhfuil an tsamhail driogtha is láidre a fheidhmíonn is fearr sa teanga fhoinseach chomh maith leis na sprioctheangacha i suíomhanna náid.', 'ka': 'გამოყენებული ტრანფორმენტერის ფორმები, როგორც BERT, მოდენსტირებულია, რომ მრავლობით NLP დავალების განსაზღვრებისთვის განსაზღვრება. მათი წარმატებით, BERT სტილის კოდერებები დიდი ზომის და უფრო დიდი სიგრძე აქვს ინფრენციის განმავლობაში (განსაკუთრებით CPU მაქსინტებში), რომელიც მათ უფრო მეტი ინტერნეული მიმდინარე შემდეგ კომპრესი და დისტლილიაციის მეტოვები ეფექტიური გზები გადახმარებას. მაგრამ, ეს სამუშაოების ფონსკური მნიშვნელოვანი კოდერებზე იყო. მრავალენგური წარმატებით, როგორც mBERT-ის გამოყენებული მრავალენგური კოდერების გამოყენებაში, ჩვენ განვითარებთ ცოდნენტის განსხვავება (KD) და მრავალენგური BERT მოდელების ეფექტიურობა. ჩვენ გამოჩვენებთ, რომ მონოლენგური დისტლიაციის შემთხვევაში, მრავალენგური პარამეტრებში, დისტლიაცია წინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინაწინ ჩვენ დავხედავთ, რომ დისტლილაცია წარმოდგენის შემდეგ შეუძლია დაავადება ნულ სტრიქტური კრისი ენგური მუშაობა. საბოლოოდ, ჩვენ გამოჩვენებთ, რომ დისტლიქტირება დისტლიქტირებული მოდელეში (BERT დისტლიქტირებული) უფრო ძალიან დისტლიქტირებული მოდელეში გავაკეთება, რომელიც ყველაზე უფრო ძალიან', 'hu': 'Az előkészített transzformátor alapú útmérők, mint például a BERT, bizonyították, hogy a legkorszerűbb teljesítményt érnek el számos NLP feladatnál. Sikerük ellenére a BERT stílusú kódolók nagy méretűek és nagy késleltetéssel rendelkeznek a következtetés során (különösen CPU gépeken), ami miatt sok online alkalmazás esetében nem vonzóak. A közelmúltban bevezetett kompressziós és desztillációs módszerek hatékony módszereket biztosítottak e hiányosság enyhítésére. Ezeknek a munkáknak azonban elsősorban az egynyelvű kódolókra fókuszáltak. A többnyelvű előképzett kódolók, mint például az mBERT alkalmazásával végzett nulla-shot keresztnyelvű transzfer tanulásban a közelmúltbeli sikerek motiválva értékeljük a Knowledge Destillation (KD) hatékonyságát mind a képzés előtti szakaszban, mind a finomhangolási szakaszban többnyelvű BERT modelleken. Kimutatjuk, hogy az előző megfigyelésekkel ellentétben az egynyelvű desztilláció esetében, többnyelvű környezetben a desztilláció hatékonyabb, mint a desztilláció a nulla-shot transzfer tanulás finomhangolása során. Ezenkívül megfigyeljük, hogy a finomhangolás során történő desztilláció árthat a nulla-shot keresztnyelvű teljesítménynek. Végezetül bemutatjuk, hogy egy nagyobb modell (BERT Large) desztillálása a legerősebb desztillált modellt eredményezi, amely a legjobb teljesítményt mind a forrásnyelven, mind a célnyelven nulla lövéses beállításokban.', 'kk': 'BERT секілді түрлендірушілер негіздеген кодерлер, көп NLP тапсырмалардың күй- жайымдығын жеткізу үшін көрсетілді. Бірақ олардың сәттілігіне қарамастан, BERT стилінің кодерлері өлшемінде үлкен және инференциялық кезде (осымен қатар процессордың машиналарында) көптеген қолданбалар үшін көп жағдайда болмайд Жуырдан келтірілген компресс және дислилациялау әдістері бұл келесіні көшірмелеу үшін эффективті жолдар берді. Бірақ бұл жұмыстардың көздегі көздеген көздеген көздеген монолингі кодерлерде болады. МБЕРТ секілді көптілік претензиялық кодерлерді көпшілік тілдерді көпшілік аудару оқытуының жаңа сәттері бойынша көпшілікті көпшілікті көпшілікті претензиялық кодерлерді қолдану үшін білім дистриляциясының Біз бірнеше тілді дисплейциялау үшін, бірнеше тілді параметрлерде дисплейциялау кезінде бірнеше бақылау кезіне қарсы деп көрсетіп тұрамыз, нөл- шофт аудару оқыту үшін дисплейциялау кезінде дисплейциялаудан Сонымен қатар, біз бақылау кезінде дистриляциялау нөл тілдердің көпшілігін өткізу мүмкін. Соңында, біз үлкен үлгі (BERT Үлкен) түрлендіру үлгісін көрсетедік. Бұл үлгісі нөл түрлендіру параметрлерінде, көзінің тілдерінде де және мақсатты тілдерінің ең жақсы түрлендір', 'lt': 'Įrodyta, kad iš anksto parengti transformatoriais pagrįsti kodai, pvz., BERT, siekia pažangiausių rezultatų daugelyje NLP užduočių. Nepaisant jų sėkmės, BERT stilius koduojantys kodai yra dideli ir yra labai vėluojantys daryti išvadas (ypač perdirbimo mašinose), dėl kurių daugelis internetinių programų juos nepasireiškia. Neseniai įvesti slėgio ir distiliavimo metodai padėjo veiksmingai sumažinti šį trūkumą. Tačiau pagrindinis šių kūrinių dėmesys buvo skiriamas vienakalbiams koduotojams. Motyvuojami neseniai sėkmingai baigiant mokymąsi tarpkalbiniu perdavimu nuliniu būdu naudojant daugiakalbius ikimokomus kodus, pvz., mBERT, mes vertiname žinių distiliacijos (KD) veiksmingumą tiek ikimokomo mokymo etape, tiek tobulinimo etape daugiakalbiniuose BERT modeliuose. Mes įrodome, kad, prieštaraujant ankstesniam pastebėjimui vienakalbės distiliacijos atveju, daugiakalbėse aplinkybėse distiliavimas išankstinio apmokymo metu yra veiksmingesnis nei distiliavimas išankstinio apmokymo metu tikslinant mokymąsi apie nulinį perkėlimą. Be to, pastebime, kad distiliavimas tikslinant gali pakenkti nulinio nuotraukos tarpkalbiniam veiksmingumui. Galiausiai įrodome, kad didesnio modelio distiliavimas (BERT Didelis) lemia stipriausią distiliuotą model į, kuris geriausiai pasiekia tiek šaltinio kalbą, tiek tikslines kalbas nulinio nuotraukos sąlygomis.', 'el': 'Οι κωδικοποιητές με βάση τους μετασχηματιστές έχουν αποδειχθεί ότι επιτυγχάνουν επιδόσεις τελευταίας τεχνολογίας σε πολλές εργασίες NLP. Παρά την επιτυχία τους, οι κωδικοποιητές ύφους είναι μεγάλοι σε μέγεθος και έχουν υψηλή καθυστέρηση κατά τη διάρκεια της συναγωγής (ειδικά σε μηχανές ΚΜΕ), γεγονός που τους καθιστά μη ελκυστικούς για πολλές διαδικτυακές εφαρμογές. Πρόσφατα εισαγόμενες μέθοδοι συμπίεσης και απόσταξης έχουν παράσχει αποτελεσματικούς τρόπους για την ανακούφιση αυτής της έλλειψης. Ωστόσο, το επίκεντρο των έργων αυτών ήταν κυρίως στους μονογλωσσικούς κωδικοποιητές. Με κίνητρο τις πρόσφατες επιτυχίες στην εκμάθηση της διασυνοριακής μεταφοράς μηδενικού πυροβολισμού χρησιμοποιώντας πολύγλωσσους προκαθορισμένους κωδικοποιητές όπως το αξιολογούμε την αποτελεσματικότητα της απόσταξης γνώσης (ΚΔ) τόσο κατά τη διάρκεια του σταδίου προετοιμασίας όσο και κατά τη διάρκεια του σταδίου συντονισμού σε πολυγλωσσικά μοντέλα. Αποδεικνύουμε ότι σε αντίθεση με την προηγούμενη παρατήρηση στην περίπτωση της μονογλωσσικής απόσταξης, σε πολυγλωσσικά περιβάλλοντα, η απόσταξη κατά την προεπεξεργασία είναι πιο αποτελεσματική από την απόσταξη κατά τη διάρκεια της τελειοποίησης για μάθηση μεταφοράς μηδενικού πυροβολισμού. Επιπλέον, παρατηρούμε ότι η απόσταξη κατά τη διάρκεια του λεπτού συντονισμού μπορεί να βλάψει την απόδοση μηδενικού πυροβολισμού. Τέλος, καταδεικνύουμε ότι η απόσταξη ενός μεγαλύτερου μοντέλου (έχει ως αποτέλεσμα το ισχυρότερο αποσταγμένο μοντέλο που αποδίδει καλύτερα τόσο στη γλώσσα προέλευσης όσο και στις γλώσσες προορισμού σε ρυθμίσεις μηδενικού πυροβολισμού.', 'it': "È stato dimostrato che encoder pre-addestrati basati su trasformatori come BERT raggiungono prestazioni all'avanguardia in numerose attività NLP. Nonostante il loro successo, gli encoder stile BERT sono di grandi dimensioni e hanno un'elevata latenza durante l'inferenza (soprattutto sulle macchine CPU) che li rendono poco attraenti per molte applicazioni online. I metodi di compressione e distillazione recentemente introdotti hanno fornito modi efficaci per alleviare questa carenza. Tuttavia, il focus di questi lavori è stato principalmente sugli encoder monolingue. Motivati dai recenti successi nell'apprendimento translinguale zero-shot utilizzando encoder pre-addestrati multilingue come mBERT, valutiamo l'efficacia della Knowledge Distillation (KD) sia durante la fase di pre-formazione che durante la fase di fine-tuning su modelli BERT multilingue. Dimostriamo che in contraddizione con quanto osservato in precedenza nel caso della distillazione monolingue, in contesti multilingue, la distillazione durante la pre-formazione è più efficace della distillazione durante la messa a punto per l'apprendimento di trasferimento zero-shot. Inoltre, osserviamo che la distillazione durante la messa a punto può danneggiare le prestazioni cross-lingual zero-shot. Infine, dimostriamo che distillando un modello più grande (BERT Large) si ottiene il modello distillato più forte che funziona meglio sia sulla lingua di origine che sulle lingue di destinazione in impostazioni zero-shot.", 'mk': 'Претренираните кодери базирани на трансформатори, како што е БЕРТ, се демонстрирани за постигнување на најсовремени резултати на бројни НЛП задачи. И покрај нивниот успех, кодерите на стилот БЕРТ се големи во големина и имаат висока тајност за време на инференцијата (особено на процесорските машини) што ги прави непривлечни за многу онлајн апликации. Неодамна воведени методи на компресија и дистилација обезбедија ефикасни начини за олеснување на овој недостаток. Сепак, фокусот на овие дела беше главно на монојазичните кодери. Мотивирано од неодамнешните успеси во нула-снимка крстојанско префрлање учење користејќи мултијазични претренирани кодери како што е mBERT, ја проценуваме ефикасноста на дистилацијата на знаењето (KD) и за време на претренирањето и за време на финотизирањето на мултијазичните BERT модели. Демонстрираме дека во спротивност на претходното набљудување во случајот на монојазична дистилација, во мултијазични услови, дистилацијата за време на претренирање е поефикасна од дистилацијата за време на финетирање за научување на нултиран трансфер. Покрај тоа, набљудуваме дека дистилацијата за време на финетизирање може да повреди нула-снимка преку јазикот. Конечно, демонстрираме дека дестилирањето на поголем модел (БЕРТ Голем) резултира со најсилниот дестилиран модел кој најдобро функционира и на изворниот јазик, како и на метниот јазик во поставувања со нула снимка.', 'ml': 'ബെര്\u200dട്ടി പോലുള്ള മാറ്റങ്ങളുടെ അടിസ്ഥാനത്തുള്ള കോഡോര്\u200dഡുകള്\u200d പ്രദര്\u200dശിപ്പിക്കപ്പെട്ടിരിക്കുന്നു അവരുടെ വിജയം എങ്കിലും ബെര്\u200dടി സ്റ്റൈല്\u200d കോഡോര്\u200dഡുകള്\u200d വലിപ്പം വലിപ്പം ആകുന്നു. പ്രത്യേകിച്ച് സിപിയു യന്ത്രങ്ങളില്\u200d (സിപിയു യന്ത്രങ്ങളില്\u200d) ഉ Recently introduced compression and distillation methods have provided effective ways to alleviate this shortcoming.  എന്നാലും, ഈ പ്രവര്\u200dത്തനങ്ങളുടെ ശ്രദ്ധ പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു മോനോളില്\u200dഭാഷ കോഡുകളില്\u200d. MBERT പോലുള്ള പല ഭാഷകങ്ങള്\u200d ഉപയോഗിച്ച് സൂക്ഷിക്കുന്ന വിജയം മാറ്റുന്നതില്\u200d പൂര്\u200dണ്ണമായി വിജയിക്കപ്പെട്ടിരിക്കുന്നു. ജ്ഞാനത്തിന്റെ വിവരങ്ങള്\u200dക്കുള്ള പ്രവർത്തികമായി നമ് നമ്മള്\u200d പ്രത്യക്ഷപ്പെടുത്തിയിരിക്കുന്നു മുമ്പുള്ള നിരീക്ഷണത്തിന്റെ വിരോധത്തില്\u200d, പല ഭാഷകങ്ങള്\u200d വേര്\u200dപെടുത്തുന്ന കാര്യത്തില്\u200d, മഴ പെയ്യുന്നതിന അതുകൊണ്ട്, നമ്മള്\u200d കാണുന്നു സുന്ദരിയിലെ വേര്\u200dതിരിക്കുമ്പോള്\u200d പൂര്\u200dണ്ണമായി വെടിവെക്കുന്നത് ക്രിസ്ല അവസാനം, ഒരു വലിയ മോഡല്\u200d (ബെര്\u200dട്ടി വലിയ) വേര്\u200dതിരിക്കുന്നത് നമ്മള്\u200d കാണിക്കുന്നു. സോര്\u200dസ്സ് ഭാഷയില്\u200d ഏറ്റവും നല്ലത് പ്രവര്\u200dത്തിക്കുന്ന മോഡലിന് ഏറ്റവും ശക', 'ms': 'Pengenkodar berasaskan pengubah yang dilatih dahulu seperti BERT telah diaktifkan untuk mencapai prestasi state-of-the-art pada banyak tugas NLP. Walaupun mereka berjaya, pengekod gaya BERT adalah besar dalam saiz dan mempunyai keterlaluan tinggi semasa kesimpulan (terutama pada mesin CPU) yang membuat mereka tidak muncul untuk banyak aplikasi online. Kaedah pemampatan dan penapisan yang baru-baru ini telah menyediakan cara yang berkesan untuk mengurangi kekurangan ini. Namun, fokus kerja-kerja ini adalah terutama pada pengekod monobahasa. Motivated by recent successes in zero-shot cross-lingual transfer learning using multilingual pretrained encoders such as mBERT, we evaluate the effectiveness of Knowledge Distillation (KD) both during pretraining stage and during fine-tuning stage on multilingual BERT models. Kami menunjukkan bahawa dalam bertentangan dengan pengamatan sebelumnya dalam kes penapisan monobahasa, dalam tetapan berbilang bahasa, penapisan semasa penapisan lebih berkesan daripada penapisan semasa penyesuaian untuk pembelajaran pemindahan senjata. Selain itu, kami menyaksikan bahawa penapisan semasa penyesuaian boleh menyakiti prestasi saling bahasa 0-shot. Akhirnya, kita menunjukkan bahawa pencucian model yang lebih besar (BERT Besar) menghasilkan model yang paling kuat yang berfungsi baik dalam bahasa sumber dan bahasa sasaran dalam tetapan tembakan sifar.', 'mn': 'БЕРТ шиг шинжлэх ухааны шинжлэх ухааны кодлогчид олон NLP ажил дээр урлагийн үйл ажиллагааг хүргэхийг харуулсан. Амжилтад хүртэл, BERT хэлбэрийн коддогчид хэмжээтэй, халдварын үед (ялангуяа CPU машинууд дээр) өндөр халдвартай байдаг. Энэ нь олон онлайн хэрэглэгчдийн хувьд алга болдог. Саяхан нэгтгэл болон ялгаруулах арга нь энэ тохиолдлыг багасгах эффективны арга зам өгсөн. Гэхдээ эдгээр ажиллуудын төвлөрөл нь ангид хэл хэлний коддогч дээр байдаг. МБЕРТ зэрэг олон хэл хөгжүүлсэн кодеруудыг ашиглаж тэгш хэлний шилжүүлэх сургалтын саяхан амжилтын үр дүнд бид мэдлэг халдварын үр дүнг үнэлдэг. Бид өмнө хэл хэлний шинжилгээний тухай, олон хэл хэлний тохиолдлын тухай анхаарлын эсрэг харагдаж байгааг харуулж байна. Нэг шүтлэг шинжилгээний сургалтын тухай сайжруулах үед тохиолдлуудаас илүү үр дүнтэй гэдгийг харуулж байна. Дараа нь, бид анзаарлаа хийх үед тохиромжтой тохиромжтой үйл ажиллагаа нь тэгш хэл давхар үйл ажиллагаанд нөлөөлж чадна. Эцэст нь бид том загварыг тодорхойлох нь хамгийн хүчтэй тодорхойлогдсон загварын үр дүн нь эх үүсвэрийн хэл дээр хамгийн сайн ажилладаг, мөн зорилготой хэл дээр хамгийн сайн ажилладаг.', 'pl': 'Wykazano, że wstępnie trenowane kodery oparte na transformatorach, takie jak BERT, osiągają najnowocześniejszą wydajność w wielu zadaniach NLP. Pomimo sukcesu kodery w stylu BERT są duże i mają duże opóźnienia podczas inferencji (zwłaszcza na maszynach CPU), co sprawia, że nie są atrakcyjne dla wielu aplikacji online. Ostatnio wprowadzone metody kompresji i destylacji dostarczyły skutecznych sposobów na złagodzenie tego braku. Jednak skupiono się głównie na koderze jednojęzycznym. Motywowani ostatnimi sukcesami w nauce transferowej zero-shot z wykorzystaniem wielojęzycznych koderów wstępnie trenowanych, takich jak mBERT, oceniamy skuteczność destylacji wiedzy (KD) zarówno na etapie treningu wstępnego, jak i na etapie dostrajania wielojęzycznych modeli BERT. Wykazujemy, że w przeciwieństwie do wcześniejszych obserwacji w przypadku destylacji jednojęzycznej, w ustawieniach wielojęzycznych destylacja podczas treningu wstępnego jest skuteczniejsza niż destylacja podczas dostrajania w celu uczenia się transferu zero-shot. Ponadto obserwujemy, że destylacja podczas drobnego dostrajania może zaszkodzić zero-shot cross-lingual osiągnięciu. Wreszcie pokazujemy, że destylacja większego modelu (BERT Large) powoduje najsilniejszy model destylowany, który najlepiej sprawdza się zarówno w języku źródłowym, jak i w językach docelowych w ustawieniach zero-shot.', 'mt': 'Intwera li l-kodifikaturi bbażati fuq trasformaturi mħarrġa minn qabel bħall-BERT jiksbu prestazzjoni avvanzata fuq bosta kompiti tal-NLP. Minkejja s-suċċess tagħhom, il-kodifikaturi tal-istil BERT huma kbar fid-daqs u għandhom dewmien kbir matul l-inferenza (speċjalment fuq magni CPU) li jagħmluhom mhux attraenti għal ħafna applikazzjonijiet onlajn. Metodi ta’ kompressjoni u distillazzjoni introdotti reċentement ipprovdew modi effettivi biex itaffu dan in-nuqqas. Madankollu, l-enfasi ta’ dawn ix-xogħlijiet kienet prinċipalment fuq l-kodifikaturi monolingwi. Motivat minn suċċessi reċenti fit-tagħlim ta’ trasferiment translingwi b’sensiela żero bl-użu ta’ kodifikaturi multilingwi mBERT imħarrġa minn qabel, aħna jevalwaw l-effettività tad-Distillazzjoni tal-Għarfien (KD) kemm waqt l-istadju ta’ qabel it-taħriġ kif ukoll waqt l-istadju ta’ aġġustament fin fuq mudelli multilingwi BERT. Aħna nuru li b’kuntrast mal-osservazzjoni preċedenti fil-każ ta’ distillazzjoni monolingwi, f’ambjenti multilingwi, id-distillazzjoni waqt it-taħriġ minn qabel hija aktar effettiva mid-distillazzjoni waqt l-aġġustament finat għat-tagħlim tat-trasferiment mingħajr skop. Barra minn hekk, nagħmlu osservazzjoni li d-distillazzjoni waqt l-irfinar tista’ tagħmel ħsara lill-prestazzjoni interlingwistika b’firxa żero. Fl-a ħħar nett, nagħmlu xhieda li d-distillazzjoni ta’ mudell akbar (BERT Kbar) tirriżulta fl-aktar mudell distillat b’saħħtu li jwettaq l-aħjar kemm fil-lingwa tas-sors kif ukoll fil-lingwi fil-mira f’ambjenti b’zero shot.', 'no': 'Forhåndsvis transformeringsbaserte kodar som BERT er demonstrert for å oppnå tilstanden av kunsten på mange NLP- oppgåver. Til tross av suksessen, er BERT-stilkodarar stor og har høg latens under infeksjon (særleg på CPU-maskiner), som gjer dei ikkje opna for mange tilkoplingar. Nyleg innførte komprimeringsmetodar og destilasjonsmetodar har gjeve effektiv måtar å løysa denne kortvaringa. Desse arbeida har imidlertid fokusert hovudsakelig på monospråk-kodar. Forskyven av nyleg suksess i læring av krysspråksomføring med fleire språkskoder som mBERT, vi evaluerer effektiviteten av kjennende forstørring (KD) både i læring av null- shot, både i læring av krysspråksmålsmål og under finnstillingsstaden på fleirspråksmålsmålar BERT. Vi demonstrerer at i motsetning til den førre observasjonen i tilfelle for monospråk distillasjon, i fleirspråk innstillingar, destilasjon under trekking er meir effektivt enn distillasjon under finnstilling for læring av null-skritt overføring. I tillegg observerer vi at destilasjonen under finnstilling kan skade nullstatt krysspråk. I slutt viser vi at distillering av ein større modell (BERT Large) resulterer i den sterkeste distilerte modellen som utfører best både på kjeldespråket og målspråk i nullstattinnstillingane.', 'si': 'BERT වගේ ස්ථානය සඳහා ප්\u200dරමාණ කරණාකරණය සඳහා පරීක්ෂණය කරණාකරණය සඳහා පෙන්වන්න පුළුවන් විදිහට NLP වැඩේ සාමාන ඔවුන්ගේ සාර්ථක විශ්වාස කරනවා නමුත්, BERT ස්ටායිල් කෝඩාර්ඩ් විශාල විශාල විශාල විශාල වෙලා තියෙන්නේ (විශේෂයෙන්  අන්තිමේදී සංකූපණය සහ විශේෂණය විදියට ප්\u200dරයෝජනය විදියට ප්\u200dරයෝජනය කරන්න ප්\u200dරයෝජනය විදි නමුත්, මේ වැඩේ අවධානය ප්\u200dරධානයෙන් එක භාෂාවික කෝඩර් වලට තියෙනවා. මුලිභාෂාවක් ප්\u200dරතිභාෂාවක් සඳහා මුලිභාෂාවක් ප්\u200dරතිභාෂාවක් සඳහා මුලිභාෂාවක් ප්\u200dරතිභාෂාවක් සඳහා මුලිභාෂාවක් ප්\u200dරතිභාෂාවක් සඳහා ම අපි ප්\u200dරකාශ කරනවා කියලා ප්\u200dරතිභාෂා කරනවා කියලා ප්\u200dරතිභාෂාවට පසුවෙන් ප්\u200dරතිභාෂා කරනවා කියලා, බොහොම භාෂාවක් සැකසුම් වලින්, ප්\u200dර තවත්, අපි බලාපොරොත්තු කරනවා කියලා හොඳ සංවිධානයක් වෙලාවේ සුන්ධ වෙඩි තියෙන්න පුළුවන් කියල අන්තිමේදි, අපි පෙන්වන්නේ වැඩි මොඩල් එකක් විශාල කරන්න (BERT ලොක්) ප්\u200dරතිචාරයක් විශාල කරනවා කියලා, සුන්ධ විශාල සැකසුම් වල', 'ro': 'S-a demonstrat că encoderele pe bază de transformator precum BERT obţin performanţe de ultimă generaţie în numeroase sarcini NLP. În ciuda succesului lor, codificatoarele în stil BERT au dimensiuni mari și au o latență ridicată în timpul inferenței (în special pe mașinile CPU), ceea ce le face neaplăcute pentru multe aplicații online. Metodele de compresie și distilare introduse recent au oferit modalități eficiente de a atenua această deficiență. Cu toate acestea, accentul acestor lucrări s-a axat în principal pe codificatoarele monolingve. Motivați de succesele recente în învățarea translingvistică zero-shot folosind encodere multilingve pre-instruite, cum ar fi mBERT, evaluăm eficacitatea distilarii cunoștințelor (KD) atât în etapa pre-instruire, cât și în etapa de reglare fină a modelelor BERT multilingve. Demonstrăm că, în contradicție cu observația anterioară în cazul distilării monolingve, în cadrul setărilor multilingve, distilarea în timpul pregătirii este mai eficientă decât distilarea în timpul reglării fine pentru învățarea transferului zero-shot. Mai mult decât atât, observăm că distilarea în timpul reglării fine poate afecta performanța translingvistică zero-shot. În cele din urmă, demonstrăm că distilarea unui model mai mare (BERT Large) duce la cel mai puternic model distilat, care performează cel mai bine atât pe limba sursă, cât și pe limbile țintă în setări zero-shot.', 'sv': 'Förtränade transformatorbaserade kodare som BERT har visat sig uppnå toppmoderna prestanda vid många NLP-uppgifter. Trots deras framgång är BERT-kodare stora i storlek och har hög fördröjning vid inferens (särskilt på CPU-maskiner) vilket gör dem ointressant för många onlineapplikationer. Nyligen införda komprimerings- och destillationsmetoder har gett effektiva sätt att lindra denna brist. Fokus för dessa arbeten har dock främst legat på enspråkiga kodare. Motiverad av de senaste framgångarna inom noll-skott tvärspråkig överföring lärande med flerspråkiga förklädda kodare som mBERT, utvärderar vi effektiviteten av Knowledge Distillation (KD) både under förberedelsestadiet och under finjusteringsstadiet på flerspråkiga BERT-modeller. Vi visar att i motsats till föregående observation när det gäller enspråkig destillation, i flerspråkiga miljöer, destillation under förbehandling är effektivare än destillation vid finjustering för noll-shot transfer learning. Dessutom observerar vi att destillation under finjustering kan skada noll-skott cross-lingual prestanda. Slutligen visar vi att destillering av en större modell (BERT Large) resulterar i den starkaste destillerade modellen som presterar bäst både på källspråket och målspråket i nollskottsinställningar.', 'so': "Qoidaha horumarinta ah ee isbedelka sida BERT waxaa loo muujiyey si uu u gaadho shaqooyin badan oo la sameeyo xaalad-farshaxan. Inta kastoo ay guulaysteen, codsiga BERT waa mid aad u weyn, oo waxay leeyihiin mid aad u dhaqdhaqaaq badan waqtiga la jiro (khusuusan ka sameynta mashiinka CPU) oo ka dhigaya inay u sameyn karto codsiyooyin badan oo internetka ah. Hadii u dhowaad waxaa lagu soo bandhigay qalabka hoos-dhigista iyo kala duwanaanshaha, waxayna leeyihiin jidooyin faa’iido leh si ay u fududaato soo socda. Si kastaba ha ahaatee xujada shaqaalahaas waxaa ugu horeyn qoraalka afka ah. Dhab u soo qaaday barbaarinta luqadaha noocyo-shoodka ah, sida mBERT, waxaynu qiimeynaynaa faa'iidada cilmiga la'aanta (KD) xiliga hore-ka-dhigidda iyo xiliga sameynta sameynta samooyinka luuqadaha badan ee BERT. Waxaynu muujinnaa inay ka duwan tahay aragtidii hore, marka lagu kala soocay kala duwanaanta luuqadaha kala duduwan, kala duwanaanta xiliga hore waa ka faa’iido badan xilliga barashada nooca ah. Sidoo kale waxaynu fiirinaynaa in kala duwanaanshaha xiliga wanaagsanaan uu dhibi karo sameynta luqada oo nooca ah. Ugu dambaysta waxaan muujinnaa in kala soocno qaab weyn (BERT Large) wuxuu sabab u yeelan karaa model aad u daran oo si fiican u sameeya luqada sourceeda iyo sidoo kale xarumaha noocyo ah.", 'ta': 'பெர்ட் போன்ற மாற்று அடிப்படையான குறியீடுகளை நிறைய NLP பணிகளில் செயல்படுத்த முன்னேற்றப்பட்ட மாற்றம் செய்திருக்கிறது. அவர்கள் வெற்றியடைந்த பிரெட் பாணி குறியீடுகள் அளவில் பெரிதாக இருக்கின்றன மற்றும் பாதிப்பின் போது அதிக தாக்கத்திற்கு (சிபியு இயந்தி Recently introduced compression and distillation methods have provided effective ways to alleviate this shortcoming.  ஆனால், இந்த வேலைகளின் கவனம் முக்கியமாக ஒரு மொழி குறியீடுகளில் உள்ளது. MBERT போன்ற பல மொழி மொழிமாற்றி குறியீடுகளை பயன்படுத்தி சூழ்நிலையில் வெற்றிகரமாக மாற்றி கற்றுக்கொண்டு சமீபத்தில் வெற்றிகரமாக இயக்கப்பட்டது, அறிவு விலக்குதலின் விளைவு (KD) மேடை நாம் முந்தைய பார்வையை எதிர்பார்த்துக் கொண்டுள்ளோம் மாதிரியான பார்வையில், பல மொழி அமைப்புகளில், மழை மாற்றும் போது பூஜ்ஜியம் மாற்றும் கற்றத்திற மேலும், நாம் பார்க்க வேண்டும் என்றால் நன்மை தூண்டும் போது வேறுபாடு பூஜ்ஜியமாக சுழற்சி மொழியில் ச இறுதியில், நாம் ஒரு பெரிய மாதிரி (BERT பெரிய) பிரித்துவிடும் என்பதை காட்டுகிறோம். மூல மொழியிலும் சிறந்த முறையிலும் செயல்படுத்தும் மூலத்தி', 'sr': 'Pokazani su pretvarani koderi na transformaciji kao što je BERT postigli predstavu umjetnosti na brojnim zadatkima NLP. Uprkos njihovom uspjehu, koderi stila BERT su veliki i imaju veliku latenciju tokom infekcije (posebno na CPU mašinama), što ih čini da se ne pojavljuju za mnoge online aplikacije. Nedavno uvedene metode kompresije i destilacije pružale su efikasne načine za smanjenje ovog nedostatka. Međutim, fokus ovih radova je uglavnom bio na monojezičkim koderima. Motivirani nedavnim uspjehom u učenju prijenosa nula-snimanja preko jezika koristeći multijezičke kodere kao što je mBERT, procjenjujemo učinkovitost destilacije znanja (KD) i tijekom faze prijenosa i tijekom ispravne faze na multijezičkim modelima BERT-a. Pokazujemo da je u suprotnosti sa prethodnim posmatranjem u slučaju monojezičke destilacije, u mnogim jezičkim nastavama destilacija tijekom pretkivanja efikasnija od destilacije tijekom ispravnog napravljanja za učenje 0-shot transfer. Osim toga, primećujemo da destilacija tijekom fine-tuning može povrijediti nulo-pucanje preko jezika. Konačno, pokazujemo da destilacija većeg model a (BERT Velikog) rezultira najjačim destilacijskom modelu koji najbolje izvršava i na izvornom jeziku, kao i ciljnim jezicima u postavkama nule snimke.', 'ur': 'بہت سی NLP کے کاموں پر قابل تحقیق کرنے کے لئے دکھائے گئے ہیں۔ ان کے کامیابی کے بغیر، BERT styl encoders سائز میں بہت بڑے ہیں اور ان کے اندر زیادہ لاٹینس (مخصوصاً CPU ماشینوں پر) ہیں جو ان کو بہت سی آنلاین کاربریوں کے لئے ظاہر نہیں کرتے۔ اس سے اگلے مضبوط اور تقسیم طریقے کے ذریعہ مہربانی طریقے پیش کیے گئے ہیں۔ لیکن ان کاموں کی تمرکز صرف ایک زبان کے اکڈر پر ہے۔ نور-شٹ کرس-زبان ترنسیٹ کی تعلیم کے اخیر موفقیت کے ذریعے مثال mBERT کے مطابق بہت سی زبان ترنسیٹ کوڈر کے مطابق چلتے ہیں، ہم نے علم Distillation (KD) کی موفقیت کا ارزش کیا ہے دونوں پررینٹ سٹے کے وقت اور بہت سی زبان BERT موڈل پر بہت سی ترنسیٹ ہم دکھاتے ہیں کہ ایک زبان کی جدائی کے مطابق پہلے کی نظر سے مخالف ہے، بہت سی زبان کی تنظیمات میں، ڈیٹرینٹ کے وقت ڈیٹرینٹ ڈیٹرینٹ ڈیٹرینٹ کے مطابق صفر-شٹ ترنسیٹ کی تعلیم کے لئے فائدہ ترنسیٹ کے م اور ہم دیکھتے ہیں کہ پاکیزہ تنظیم کے موقع تفریق صفر-شٹ کروسٹ زبان کی عملکرد کا ضرر پہنچا سکتا ہے۔ آخر میں ہم نشان دیتے ہیں کہ ایک بڑے موڈل (BERT بزرگ) کو جدائی کرنا سب سے طاقتور جدائی موڈل میں نتیجہ دیتا ہے جو سورج زبان میں سب سے بہتر عمل کرتا ہے اور موقع زبانیں صفر-شٹ کے سائٹوں میں بھی۔', 'vi': 'Đã chứng minh những bộ mã hóa giả dựa trên máy biến hình như BERT đã đạt được thành quả tuyệt vời trong nhiều nhiệm vụ khôn ngoan. Mặc dù thành công, hộp mã hóa kiểu BERT có kích thước lớn và có tiềm năng cao trong lúc bốc đồng (đặc biệt trên máy xử lý CPU) làm cho họ không hấp dẫn được nhiều ứng dụng trực tuyến. Những phương pháp nén và chưng cất gần đây đã cung cấp một cách hiệu quả để giảm bớt thiếu hụt này. Tuy nhiên, tiêu điểm của những công trình này chủ yếu là bảo mã độc ngôn. Động đến những thành công gần đây trong việc học chuyển sang ngôn ngữ khác nhau bằng mã hóa giải đa dạng dạng, như mBERT, chúng tôi đánh giá hiệu quả của sự phân tách tri thức (KD) cả trong giai đoạn trước và trong giai đoạn chín của thời gian nghiên cứu mẫu BERT đa dạng. Chúng tôi chứng minh việc chưng cất độc ngôn ngữ, chế độ chế biến dưới chế độ đa dạng, trái ngược với quan điểm trước đó, hiệu quả hơn việc chưng cất khi chưng cất để học chuyển phát bắn không. Chúng tôi cũng nhận thấy rằng việc chưng cất thời gian sẽ ảnh hưởng đến ngôn ngữ khác nhau. Cuối cùng, chúng tôi chứng minh việc chưng cất một mô hình lớn hơn (BERT Large) là kết quả của mô hình chưng cất mạnh nhất được chưng cất tốt nhất cả trên ngôn ngữ nguồn cũng như ngôn ngữ tiêu điểm trong thiết lập bắn không.', 'uz': "Name Ularning muvaffaqiyatlarida BERT uslub kodlash oʻlchami katta va faqat shaxsiyatlar (CPU mashinalarida) juda katta taʼminlik bor. Bu ularni ko'proq tarmoq dasturlari uchun qoʻllanmagan. Yaqinda ishlatilgan kompyuter va ajratish usullari bu qisqarishni kamaytirish uchun ishlatilgan yordamlarni yaratadi. Lekin, bu ishlarning eng fokusi umuman monolingan kodlash usulida edi. Yaqinda ko'pchilik tilida o'rganish muvaffaqiyatli o'rganishda muvaffaqiyatli muvaffaqiyatli o'rganish muvaffaqiyatli o'zgartirildi, mBERT kabi ko'plab-tildagi ko'pchilik kodlardan foydalanishda, biz ilmiy suhbatning effektligini qiymatmiz va ko'pchilik BERT modellarida ko'proq o'xshash holatda Biz birinchi ko'pchilik o'zgarishni o'rganish uchun o'zgarishni o'zgartirish uchun o'zgarishda o'zgarishni o'zgartirish uchun o'zgarishda o'zgarishga tayyorligini ko'rsatganimiz mumkin. Ko'rib chiqqamiz, suhbat sohasida o'zgarishni o'zgartirib turishimiz mumkin. Oxirgi, biz ko'proq modelni (BERT katta) ajratishni ko'rsatishimiz mumkin. Bu ko'p modelni ko'rsatish mumkin, bu soni tilda eng yaxshi ko'proq ishlayotgan modelga va nuqta oʻzgaruvchining tizimlarida eng yaxshi ishlab chiqaradi.", 'bg': 'Доказано е, че предварително тренирани трансформаторни кодери като BERT постигат най-съвременни резултати при многобройни задачи на НЛО. Въпреки успеха си, кодерите в стил са големи по размер и имат висока латентност по време на заключения (особено на процесорни машини), което ги прави непривлекателни за много онлайн приложения. Наскоро въведените методи за компресия и дестилация осигуряват ефективни начини за облекчаване на този недостатък. Фокусът на тези работи обаче е бил основно върху едноезичните кодери. Мотивирани от последните успехи в нулевото междуезично трансферно обучение чрез многоезични предварително тренирани кодери като например оценяваме ефективността на дестилацията на знанието (КД) както по време на етапа на предтрениране, така и по време на етапа на фина настройка на многоезичните модели. Ние демонстрираме, че в противоречие с предишното наблюдение в случай на едноезична дестилация, в многоезични условия дестилацията по време на предтрениране е по-ефективна от дестилацията по време на фина настройка за нулево трансферно обучение. Освен това, наблюдаваме, че дестилацията по време на фина настройка може да навреди на нулевото междуезично представяне. И накрая, демонстрираме, че дестилирането на по-голям модел води до най-силния дестилиран модел, който се представя най-добре както на изходния език, така и на целевите езици в настройки за нулев изстрел.', 'da': 'Fortrænede transformerbaserede encodere som BERT har vist sig at opnå state-of-the-art ydeevne på mange NLP-opgaver. Trods deres succes er BERT-kodere store i størrelse og har høj ventetid under inference (især på CPU-maskiner), hvilket gør dem utilfredsstillende for mange onlineapplikationer. For nylig indførte komprimerings- og destillationsmetoder har givet effektive metoder til at afhjælpe denne mangel. Disse værker har dog hovedsageligt været fokuseret på ensprogede kodere. Motiveret af de seneste succeser inden for nulstrænet tværsproget overførsel læring ved hjælp af flersprogede prætrænede encodere som mBERT, evaluerer vi effektiviteten af Knowledge Distillation (KD) både under prætræningsfasen og under finjusteringsfasen på flersprogede BERT modeller. Vi påviser, at i modsætning til den tidligere bemærkning i tilfælde af ensproget destillation i flersprogede omgivelser er destillation under fortræning mere effektiv end destillation under finjustering for nul-shot transfer learning. Desuden bemærker vi, at destillation under finjustering kan skade nulskud tværsproget ydeevne. Endelig viser vi, at destillering af en større model (BERT Large) resulterer i den stærkeste destillerede model, der fungerer bedst både på kildesproget og målsprog i nulskudsindstillinger.', 'nl': 'Van vooraf getrainde transformatorgebaseerde encoders zoals BERT is aangetoond dat ze state-of-the-art prestaties leveren bij tal van NLP-taken. Ondanks hun succes zijn BERT-stijl encoders groot van formaat en hebben ze een hoge latentie tijdens inferentie (vooral op CPU-machines), waardoor ze onaantrekkelijk zijn voor veel online toepassingen. Recent geïntroduceerde compressie- en distillatiemethoden hebben effectieve manieren geboden om deze tekortkoming te verlichten. De focus van deze werken ligt echter vooral op eentalige encoders. Gemotiveerd door recente successen in zero-shot cross-lingual transfer learning met behulp van meertalige vooraf getrainde encoders zoals mBERT, evalueren we de effectiviteit van Knowledge Distillation (KD) zowel tijdens de voorbereidingsfase als tijdens de fine-tuning fase op meertalige BERT modellen. We tonen aan dat, in tegenstelling tot de vorige waarneming in het geval van eentalige distillatie, destillatie tijdens pretraining effectiever is dan destillatie tijdens finetuning voor zero-shot transfer learning. Bovendien zien we dat distillatie tijdens fine-tuning de zero-shot cross-lingual prestaties kan schaden. Tot slot laten we zien dat het distilleren van een groter model (BERT Large) resulteert in het sterkste gedistilleerde model dat het beste presteert op zowel de brontaal als doeltalen in zero-shot instellingen.', 'hr': 'Pokazani su pretvarani koderi na transformaciji poput BERT-a kako bi postigli postupak stanja umjetnosti na brojnim zadatkima NLP-a. Unatoč njihovom uspjehu, koderi stila BERT su veliki u veličini i imaju visoku latenciju tijekom infekcije (posebno na strojevima CPU-a), što ih čini da se ne pojave za mnoge online aplikacije. Nedavno uvedene metode kompresije i destilacije pružale su učinkovite načine za smanjenje ovog nedostatka. Međutim, fokus ovih radova uglavnom je bio na monojezičkim koderima. Motivirani nedavnim uspjehom u učenju prijenosa nulog snimka s višejezičkim koderima poput mBERT-a, procjenjujemo učinkovitost destilacije znanja (KD) i tijekom faze prijenosa i tijekom finalnog prilagodbe na višejezičkim modelima BERT-a. Pokazujemo da je u suprotnosti prethodnom posmatranju u slučaju monojezičke destilacije, u mnogim jezičkim nastavama destilacija tijekom pretkivanja učinkovitija od destilacije tijekom ispravnog napravljanja za učenje prijenosa nula. Osim toga, primećujemo da destilacija tijekom fino-tuning može povrijediti nulo-pucnjavu preko jezika. Konačno, pokazujemo da destilacija većeg model a (BERT Velikog) rezultira najjačim destilacijskom modelu koji najbolje izvodi i na izvornom jeziku, kao i ciljnim jezicima u postavkama nule snimke.', 'id': 'Pretrained transformer-based encoders such as BERT have been demonstrated to achieve state-of-the-art performance on numerous NLP tasks.  Meskipun mereka berhasil, pengkode gaya BERT besar dalam ukuran dan memiliki keterlaluan tinggi selama kesimpulan (terutama pada mesin CPU) yang membuat mereka tidak muncul untuk banyak aplikasi online. Metode kompresi dan destilasi yang baru saja diperkenalkan telah menyediakan cara yang efektif untuk mengurangi kekurangan ini. Namun, fokus karya-karya ini terutama pada pengekode monobahasa. Dimotifkan oleh sukses akhir-akhir ini dalam pembelajaran transfer saling bahasa nol-shot menggunakan koder multibahasa yang dilatih sebelumnya seperti mBERT, kami mengevaluasi efektivitas Distillasi Pengetahuan (KD) baik dalam tahap penelitian dan dalam tahap penyesuaian baik pada model BERT multibahasa. Kami menunjukkan bahwa secara bertentangan dengan pengamatan sebelumnya dalam kasus destilasi monobahasa, dalam pengaturan multibahasa, destilasi selama pretraining lebih efektif daripada destilasi selama penyesuaian untuk belajar transfer senjata. Selain itu, kami memperhatikan bahwa destilasi selama penyesuaian bisa menyakiti prestasi saling bahasa tanpa tembakan. Akhirnya, kami menunjukkan bahwa mendistilkan model yang lebih besar (BERT Large) menghasilkan model yang paling kuat yang mendistilkan yang terbaik pada bahasa sumber dan bahasa sasaran dalam pengaturan zero-shot.', 'de': 'Vortrainierte transformatorbasierte Encoder wie BERT erreichen nachweislich bei zahlreichen NLP-Aufgaben State-of-the-Art-Performance. Trotz ihres Erfolgs sind BERT-Encoder groß und haben eine hohe Latenz während der Inferenz (insbesondere auf CPU-Maschinen), was sie für viele Online-Anwendungen unattraktiv macht. Kürzlich eingeführte Komprimierungs- und Destillationsmethoden haben wirksame Wege zur Linderung dieses Mangels geliefert. Der Schwerpunkt dieser Arbeiten lag jedoch hauptsächlich auf einsprachigen Encodern. Motiviert durch die jüngsten Erfolge im Zero-Shot Cross-Lingual Transfer Learning mit mehrsprachigen, vortrainierten Encodern wie mBERT bewerten wir die Effektivität von Knowledge Distillation (KD) sowohl während der Vortrainingsphase als auch während der Feinabstimmung an mehrsprachigen BERT Modellen. Wir zeigen, dass im Gegensatz zur bisherigen Beobachtung bei der einsprachigen Destillation in mehrsprachigen Umgebungen die Destillation während des Vortrainings effektiver ist als die Destillation während der Feinabstimmung für Zero-Shot Transfer Learning. Darüber hinaus beobachten wir, dass die Destillation während der Feinabstimmung die Zero-Shot Cross-Lingual Performance beeinträchtigen kann. Schließlich zeigen wir, dass das Destillieren eines größeren Modells (BERT Large) zu dem stärksten destillierten Modell führt, das sowohl auf der Ausgangssprache als auch auf Zielsprachen in Zero-Shot-Einstellungen am besten funktioniert.', 'ko': '예비 훈련 변압기 기반 인코더 (예: BERT) 는 많은 NLP 작업에서 가장 선진적인 성능을 실현할 수 있다는 것이 증명되었다.비록 성공을 거두었지만, 버트식 인코더의 크기가 매우 크고, 추리 과정 (특히 CPU 기계) 에서 매우 높은 지연이 있기 때문에, 이것은 많은 온라인 응용 프로그램에 흡인력이 없다.최근 도입된 압축과 증류 방법은 이 단점을 완화시키는 데 효과적인 경로를 제공했다.그러나 이런 작업의 중점은 주로 단어 인코더이다.최근 다중 언어 예비 훈련 인코더(예를 들어 mBERT)를 사용하여 진행된 0차례의 다중 언어 이동 학습의 성공을 토대로 우리는 다중 언어 BERT 모델의 예비 훈련 단계와 미세 조정 단계에서 지식 추출(KD)의 유효성을 평가했다.우리는 이전에 단어 증류 상황에서 관찰한 결과와 반대로 다중 언어 환경에서 예훈련 기간의 증류가 미조정 기간의 증류보다 더욱 효과적이며 0렌즈 전이 학습에 사용된다는 것을 증명했다.그 밖에 미세 조정 과정 중의 증류가 영사 크로스 언어 성능을 손상시킬 수 있다는 것을 관찰했다.마지막으로 우리는 더 큰 모델(BERT Large)을 추출하면 가장 강한 추출 모델이 생길 수 있다는 것을 증명했다. 이 모델은 제로포 설정에서 원시 언어와 목표 언어에서 가장 잘 표현된다.', 'fa': 'رمز\u200cکننده\u200cهای تغییر\u200cپذیر\u200cکننده\u200cای مانند BERT نشان داده شده\u200cاند که برای رسیدن اجرای موقعیت هنری بر عملهای زیادی NLP تحت تاثیر قرار گرفته\u200cاند. با وجود موفقیت\u200cهایشان، رمزگاران سبک BERT به اندازه بزرگی دارند و در طول آلودگی (مخصوصا در ماشین\u200cهای CPU) بالا دارند که آنها را برای کاربردهای بسیاری آنلاین ناپدید می\u200cکنند. اخیراً روش\u200cهای فشار و جدایی معرفی شده\u200cاند، راه\u200cهای تاثیری برای آسان کردن این کوتاهی را پیشنهاد کرده\u200cاند. با این حال، تمرکز این کارها اصلاً روی کودهای یک زبان است. توسط موفقیت های اخیر در یادگیری از انتقال متوسط زبان صفر با استفاده از رمزهای متوسط زبان مانند mBERT، فعالیت تغییر علم (KD) را در طول تغییر دادن و در طول تغییر\u200cسازی پاکیزه بر مدل\u200cهای متوسط زبان BERT ارزیابی می\u200cکنیم. ما نشان می دهیم که در مقابل نظارت قبلی در مورد تفاوت یک زبان، در تنظیمات متعدد زبان، تفاوت در زمان تفاوت بیشتری از تفاوت در زمان تفاوت نیکو برای یادگیری انتقال صفر موثر است. علاوه بر این، ما مشاهده می\u200cکنیم که تفاوت در زمان تفاوت\u200cسازی نیز ممکن است به انجام دادن زبانی صفر صدمه دهد. بالاخره، ما نشان می دهیم که جدا کردن یک مدل بزرگ (BERT بزرگ) نتیجه\u200cهای قوی\u200cترین مدل جدا شده\u200cای است که بهترین را در زبان منبع و زبانهای هدف در تنظیمات صفر انجام می\u200cدهد.', 'sw': 'Miongoni ya mabadiliko yaliyojiandaa kama vile BERT imeonyeshwa kupata hali ya sanaa katika kazi nyingi za NLP. Pamoja na mafanikio yao, idadi kubwa ya mtindo wa BERT zina kiasi kikubwa na zina hali ya juu wakati wa maambukizi (hasa kwenye mashine za CPU) ambazo zinawafanya hivyo kupunguza kwa matumizi mengi ya mtandaoni. Hivi karibuni, mbinu za kushinikiza na kutofautisha zimepangia njia yenye ufanisi ili kupunguza ufuatiliaji huu. Hata hivyo, lengo la kazi hizi limekuwa likizungumza kwa lugha za kiutaifa. Hatua ya mafanikio ya hivi karibuni katika kujifunza kwa lugha yenye picha sifuri kwa kutumia maeneo ya lugha mbalimbali kama mBERT, tunathmini ufanisi wa Uelezaji (KD) wote wakati wa kutengeneza viwanja na wakati wa jukwaa zuri katika mifano ya BERT kwa lugha mbalimbali. Tunaonyesha kwamba tofauti na mtazamo uliopita katika kesi ya kutenganisha kwa lugha, katika mazingira ya lugha mbalimbali, tofauti wakati wa kutengeneza mvua ni ufanisi zaidi ya kutofautisha wakati wa kujifunza kwa sifa. Zaidi ya hayo, tunaona kuwa tofauti wakati wa mafunzo mazuri kunaweza kuharibu utendaji wa lugha yenye risasi sifuri. Finally, we demonstrate that distilling a larger model (BERT Large) results in the strongest distilled model that performs best both on the source language as well as target languages in zero-shot settings.', 'tr': 'BERT ýaly görkezilen transformer ködlemeleri, birnäçe NLP işinde möhüm taýýarlanmak üçin görkezildi. Olaryň üstünlikleri ýöne, BERT stil ködlemeleri uly uly we çykyş wagtynda (iň bellenen CPU maşynlarynda) gaty uly ýagdaýlaşýar. Olar online uygulamalar üçin birnäçe ýagdaýlaşýar. Soňky döwletleri hasaplamak we taýýarlama yöntemleri bu gysgyny azaltmak üçin etkinlik ýola getirdi. Ýöne bu işleriň fokusy adatça monodil ködlemeleri üstünde bolýar. Öň soňky başarışlardan mBERT ýaly 0-shot karrolyk dil önünde öwrenmek üçin önünde süýtgeýäris. Biz Bilim Distillation (KD) sahypalarynyň etkinligini hem öňünde hem multi dilli BERT modellerinde süýtgeýän sahypalarynda deňleýäris. Biz öňki görnüşimize görä monodil taýýarlanmasy durumynda, öňki diller taýýarlanmasy durumynda, ýakynlanmasy durmuşynda täsirlenmek 0-aty taýýarlanmasy öwrenmesiniň terjime edilmeginden has gowurakdır. Daha da göz önüne ýetişiklik taýýarlanma wagtynda täsirlenme noktaly çyzgyş dilinde bir şekilde görünýär. Soňunda biz uly bir nusgany tapandyrmak (BERT Uly) iň güýçli bir nusga görkezilýäni görkezýäris. Bu nusga dilinde hem 0-resim düzümlerinde iň gowy tapandyrýan nusga görkezýär.', 'af': "Gevorderde transformeerder-gebaseerde koders soos BERT is gedemonstreer om status-of-kuns-prestasie te bereik op veelvuldige NLP-opdragte. Onthou hulle sukses is BERT styl enkoderers groot in grootte en het hoë latensie tydens infensie (veral op CPU masjiene) wat maak hulle onverskyn vir baie aanlyn toepassings. Onlangs ingevoerde kompressie en destilasie metodes het effektief maniere verskaf om hierdie kortpad te verminder. Maar die fokus van hierdie werke is heeltemal op monolingse koders. Gemotiveer deur onlangse sukses in nul- skoot kruis- tale oordrag leer gebruik met multilinglike pretreënde koders soos mBERT, ons evalueer die effektiviteit van kennis afstelling (KD) beide tydens voortreëning stadium en tydens fyn- tuning stadium op multilinglike BERT modele. Ons wys dat in teenstemming tot die vorige observasie in die geval van monolinglike destilasie, in multitaalske instellings, destilasie tydens voortreëning is meer effektief as destilasie tydens fyn-tuning vir nul-skoot oordrag leer. Ook, ons observeer dat destilasie tydens fyn-tuning kan zero-skoot kruistale prestasie skandeer. Eindelik, ons wys dat 'n groter model (BERT Groot) verskillende resultate in die sterkte verskillende model wat beter uitvoer beide op die bron taal en die doel taal in nul-skoot instellings.", 'sq': 'Koduesit me bazë transformuese të paratrajnuar si BERT janë demonstruar për të arritur shfaqjen më të lartë në detyra të shumta NLP. Pavarësisht nga suksesi i tyre, koduesit e stilit BERT janë të mëdhenj në madhësi dhe kanë vonesë të lartë gjatë përfundimeve (veçanërisht në makinat CPU) që i bëjnë të pamundur për shumë aplikime online. Metodat e shtypjes dhe distillacionit të futura kohët e fundit kanë ofruar mënyra efektive për të lehtësuar këtë mungesë. Megjithatë, fokusi i këtyre punëve ka qenë kryesisht në koduesit monogjuhës. Motivuar nga suksesi i kohëve të fundit në mësimin zero-shot trans-gjuhësor duke përdorur koduesit shumëgjuhësorë të paratrajnuar të tillë si mBERT, ne vlerësojmë efektshmërinë e Distillimit të njohurive (KD) si gjatë fazës së paratrajnimit dhe gjatë fazës së rregullimit të mirë në modelet shumëgjuhësorë BERT. Ne demonstrojmë se në kundërshtim me vëzhgimin e mëparshëm në rastin e distillacionit monogjuhësor, në mjedise shumëgjuhësore, distillacioni gjatë parastërvitjes është më efektiv se distillacioni gjatë rregullimit të hollësisë për mësimin e transferimit zero-shot. Përveç kësaj, ne vëzhgojmë se distillacioni gjatë rregullimit të mirë mund të dëmtojë paraqitjen zero-gjuhësore. Më në fund, ne demonstrojmë se distilimi i një modeli më të madh (BERT Large) rezulton në model in më të fortë të distilluar që performon më mirë si në gjuhën e burimit, ashtu dhe gjuhën e objektivit në rregullime zero-shot.', 'am': 'እንደዚህ BERT የሥርዓት-የ-አርእስት ሥርዓት በቁጥር NLP ስራቶች ላይ ለማግኘት ተዘጋጅቷል፡፡ ምንም እንኳን አግኝቷል፣ የBERT ዓይነት ቀለበቶች መጠን ትልቅ ነው፣ ለብዙዎች የመረጃ ፕሮግራሞች ማሳተሚያዎች (ለCPU machines) የራሳቸውን ቅድሚያ አካባቢ ነው፡፡ በቅርብ ጊዜ አካባቢ እና ልዩነት ሥርዓት የዚህን አካላፊያዎችን ለማሳየት ጥያቄ መንገድ ሰጥተዋል፡፡ ነገር ግን የዚህ ሥራ ምሳሌ አብዛኛውን በሙሉ ቋንቋዎች ላይ ነው፡፡ በቅርብ ጊዜ በክፍለ ቋንቋ-ቋንቋ ተማርኮ እንደmBERT የብዙልቋንቋ የተለየ የፊደል ክፍተቶችን በመጠቀም የዕውቀት ግንኙነት (KD) እና በብዙ ልዩ ቋንቋዎች ብሔራዊ BERT ዓይነቶች ላይ በተመሳሳይ ዘመን እናስተዋልታለን፡፡ የቀድሞው የቋንቋ ውይይት፣ በብዛት ቋንቋ አካባቢ፣ ዝናብ በተለየ ቁጥጥር ከ0 በተለወጠው ትምህርት ማወቂያውን ከመለየት የበለጠ ነው ብለን እናሳየዋለን፡፡ እናም በክፍለ ቋንቋ ውስጥ የክፍለ ክፍል የቋንቋ ቋንቋ ይጎዳል ብለን እናስታውቃለን፡፡ በመጨረሻውም፣ ትልቅ ዓይነት (BERT ትልቅ) የሚለይ ምሳሌ በቋንቋ እና በzero-shot ባደረጉት ተሟጋቾች በሚያሳየው የበረታች ሞዴል እናሳየዋለን፡፡', 'hy': 'Պարզվել է, որ BER-ի նման նախապատրաստ վերափոխողների հիմնված կոդերները կարողանում են լավագույն արդյունքները հասնել բազմաթիվ ՆԼՊ-ի առաջադրանքների վրա: Չնայած նրանց հաջողությանը, BER-ի ոճի կոդերները մեծ են և շատ ուշացում են հետևանքների ընթացքում (հատկապես CPU մեքենաների վրա), որոնք ստիպում են դրանք անհայտ լինել շատ առցանց ծրագրերի համար: Recently introduced compression and distillation methods have provided effective ways to alleviate this shortcoming.  Այնուամենայնիվ, այս աշխատանքների կենտրոնացումը հիմնականում միալեզու կոդերների վրա էր: Հրաշարժված վերջին հաջողությամբ զրոյական լեզվի փոխանցման ուսումնասիրության մեջ, օգտագործելով բազմալեզու նախադասական կոդերներ, ինչպիսիք են mBER-ը, մենք գնահատում ենք գիտելիքի դիստիլացիայի (KD) արդյունավետությունը նախադասական փուլում և շատ լեզվի BER-ի մոդելների վերա Մենք ցույց ենք տալիս, որ, հակառակ նախորդ դիտարկումներին միալեզու դիսլիլացիայի դեպքում, բազլեզու միջավայրում, դիսլիլացիան նախադասության ժամանակ ավելի արդյունավետ է, քան դիսլիլացիան զրոյի փոխանցման ուսումնասիրության ժամանակ: Ավելին, մենք նկատում ենք, որ դիսլիլացիան բարելավման ընթացքում կարող է վնասել զրոյի միջլեզվային արտադրողությունը: Վերջապես, մենք ցույց ենք տալիս, որ ավելի մեծ մոդելի (BERT Large) բաղադրումը հանգեցնում է ամենաուժեղ բաղադրված մոդելի, որը լավագույնն է աշխատում նաև աղբյուրների լեզուներում, ինչպես նաև նպատակային լեզուներում զրոյական նկարների միջոցով:', 'az': 'BERT kimi transformer-tabanlı kodlayıcılar çoxlu NLP işləri üzərində müəyyən edilmiş halda göstərilmişdir. Onların başarılı olmasına rağmen, BERT stili kodlayıcıları böyüklükdə və çox online uyğulamalar üçün çox yüksək bir latensiya var. Son zamanlarda sıkıştırma və destilasyon metodları bu azaltma üçün effektiv yollar sağladı. Ancaq bu işlərin məqsədilə monodil kodlayıcılarına odaqlanmışdır. MBERT kimi çoxlu dillərdən öyrənən kodlayıcılar vasitəsilə, sıfır-fəsad çoxlu dil öyrənməsi ilə müvəffəqiyyətində təşkil edilmiş başarılar təşkil edilmişdir. Biz bilgi səviyyəsinin və çoxlu dil BERT modellərinin müfəqiyyətini değerləyirik. Biz göstəririk ki, əvvəlki nəzəriyyət monodil destilasyon vaxtında, çoxlu dil ayarlarında destilasyon sıfır-fırlatma öyrənməsi üçün destilasyondan daha etkilidir. Daha sonra, gözləyirik ki, fərqli tərzdə destilasyon sıfır-fərqli bir dil performansını incitmiş olar. Sonunda, böyük modelləri (BERT Büyük) ayırmaq üçün ən güclü müxtəlif modellərin sonuçlarını göstərdik ki, mənbə dilində də ən yaxşı və məqsəd dillərin 0-shot ayarlarında daha yaxşı işləyir.', 'bn': 'প্রশিক্ষণিত পরিবর্তনের ভিত্তিক কোডার যেমন বিবের্ট-এর মতো প্রদর্শন করা হয়েছে সংখ্যাগরিক এনএলপি কাজের উপর শিল্পের রাষ্ট্র-অফ-শি তাদের সফলতা সত্ত্বেও বেরেটি স্টাইল এনকোডার বিশাল আকারে বিস্তৃত এবং সংক্রান্ত সময় (বিশেষ করে সিপিউ মেশিনে আছে) তাদের অনেক অনলাইন অ্যাপ্ সম্প্রতি সম্প্রতি সম্প্রতি চুক্তি এবং বিচ্ছিন্ন পদ্ধতি কার্যকর উপায় প্রদান করেছে এই সংকট কমানোর জন্য। তবে এই কাজের দৃষ্টিভঙ্গি প্রধানভাবে মোনালিভাষার কোডের উপর। সাম্প্রতিক ক্ষেত্রে শুধুমাত্র শিক্ষা ক্রস-ভাষা পরিবর্তন শিক্ষা ব্যবহার করে মাল্টিভাষার প্রেমিক এনকোডার, যেমন MBERT, আমরা জ্ঞান বিভ্রান্তির কার্যক্রমের মূল্যায়ন করি এবং বহুভাষা আমরা প্রদর্শন করি যে পূর্ববর্তী পর্যবেক্ষণের বিরুদ্ধে মানুষ ভাষার বিচ্ছিন্ন ক্ষেত্রে, বহুভাষার বৈশিষ্ট্যের মাধ্যমে বৃষ্টিপাতের সময় বিচ্ছিন্ন করা কার্য এছাড়াও, আমরা দেখছি যে ভাল ভাষায় বিচ্ছিন্ন হওয়ার সময় বিচ্ছিন্ন হতে পারে শুধুমাত্র ভাষার ক্ষেত্রে। অবশেষে, আমরা দেখাচ্ছি যে বিবের্ট ব্যাপক মডেল (বিবের্ট ব্যাপক) এর ফলে সবচেয়ে শক্তিশালী বিচ্ছিন্ন মডেলের ফলে যা উৎস ভাষায় সর্বোচ্চ ভাষায় এবং শূন্য গু', 'bs': 'Pokazani su pretvarani koderi na transformaciji poput BERT-a kako bi postigli postupak države umjetnosti na brojnim zadatkima NLP-a. Uprkos njihovom uspjehu, koderi stila BERT su veliki i imaju veliku latenciju tijekom infekcije (posebno na CPU mašinama), što ih čini da se ne pojave za mnoge online aplikacije. Nedavno uvedene metode kompresije i destilacije pružale su efikasne načine za smanjenje ovog nedostatka. Međutim, fokus ovih radova uglavnom je bio na monojezičkim koderima. Motivirani nedavnim uspjehom u učenju prijenosa nulog snimanja preko jezika koristeći višejezičke kodere, poput mBERT, procjenjujemo učinkovitost destilacije znanja (KD) i tijekom faze pretvaranja, i tijekom faze finalnog prilagodbe na višejezičkim modelima BERT-a. Pokazujemo da je u suprotnosti sa prethodnim promatranjem u slučaju monojezičke destilacije, u mnogim jezičkim nastavama, destilacija tijekom pretkivanja učinkovitija od destilacije tijekom napravljenja za učenje 0-shot transfer. Osim toga, primećujemo da destilacija tijekom fine-tuning može povrijediti nulo-pucnjavu preko jezika. Konačno, pokazujemo da destilacija većeg model a (BERT Velikog) rezultira najjačim destilacijskom modelu koji najbolje izvodi i na izvornom jeziku, kao i ciljnim jezicima u postavkama nule snimke.', 'fi': 'Esikoulutettujen muuntajapohjaisten kooderien, kuten BERT:n, on osoitettu saavuttavan huippuluokan suorituskyvyn lukuisissa NLP-tehtävissä. Menestyksestään huolimatta BERT-tyyppiset kooderit ovat kooltaan suuria ja niillä on suuri viive pääteltäessä (erityisesti suorittimen koneissa), mikä tekee niistä epämiellyttäviä monille verkkosovelluksille. Äskettäin käyttöön otetut puristus- ja tislausmenetelmät ovat tarjonneet tehokkaita keinoja tämän puutteen lievittämiseksi. Työssä on kuitenkin keskitytty pääasiassa monikielisiin koodereihin. Arvioimme Knowledge Distillation (KD) -menetelmän tehokkuutta sekä esikoulutusvaiheessa että monikielisten BERT-mallien hienosäätövaiheessa. Osoitamme, että vastakohtana aiemmalle havainnolle monikielisessä tislauksessa esikoulutuksen aikana tislaus on tehokkaampaa kuin hienosäätössä nolla-shot-siirtooppimista varten. Lisäksi toteamme, että tislaus hienosäädön aikana voi vahingoittaa nollalaukauksen monikielistä suorituskykyä. Lopuksi osoitamme, että suuremman mallin (BERT Large) tislaaminen johtaa vahvimpaan tislattuun malliin, joka suoriutuu parhaiten sekä lähdekielellä että kohdekielillä nollashot-asetuksissa.', 'cs': 'Bylo prokázáno, že předtrénované snímače na bázi transformátorů, jako je BERT, dosahují nejmodernějšího výkonu při řadě úkolů NLP. I přes svůj úspěch jsou snímače ve stylu BERT velké velikosti a mají vysokou latenci během inference (zejména na počítačích CPU), což z nich dělá nepřitažlivé pro mnoho online aplikací. Nedávno zavedené metody komprese a destilace poskytly efektivní způsoby, jak tento nedostatek zmírnit. Zaměřují se však především na jednojjazyčné kodéry. Motivováni nedávnými úspěchy v zero-shot cross-jazyčném přenosovém učení pomocí vícejazyčných předtrénovaných snímačů, jako je mBERT, hodnotíme efektivitu znalostní destilace (KD) jak během fáze předtréninku, tak během fáze jemného ladění na vícejazyčných BERT modelech. Dokazujeme, že v rozporu s předchozím pozorováním v případě jednojjazyčné destilace je destilace v mnohojazyčném prostředí efektivnější než destilace při jemném ladění pro nulový transfer. Kromě toho pozorujeme, že destilace při jemném ladění může poškodit nulový výkon v křížovém jazyce. Nakonec demonstrujeme, že destilace většího modelu (BERT Large) vede k nejsilnějšímu destilovanému modelu, který nejlépe funguje jak na zdrojovém jazyce, tak i na cílových jazycích v nastavení nulového výstřelu.', 'ca': "S'ha demostrat que codificadors basats en transformadors, com BERT, aconsegueixen un rendiment més avançat en moltes tasques del NLP. Malgrat el seu èxit, els codificadors d'estil BERT són grans en mida i tenen gran retard durant la inferència (especialment en màquines de CPU) que els fa inexistents per a moltes aplicacions en línia. Els mètodes de compressió i destilació introduïts fa poc han proporcionat maneres eficaces per aliviar aquesta deficiència. No obstant això, el foc d'aquestes obres ha estat principalment en codificadors monolingües. Motivada pels èxits recents en l'aprenentatge de transfer ència translingüística de zero fets utilitzant codificadors multilingües pré-capacitats com mBERT, evaluem l'eficacia de la Distillació del Conèixement (KD) tant durant l'etapa de pré-capacitació com durant l'etapa d'ajustament en models multilingües BERT. Demonstrem que, en contradicció a l'observació anterior en el cas de la distillació monolingüe, en entorns multilingües, la distillació durant la pré-treinació és més efectiva que la distillació durant la perfeccionació de l'aprenentatge de transfer ència a zero tiros. A més, observem que la distillació durant l'ajustament pot perjudicar el desenvolupament interlingüístic de fotografies zero. Finalment, demostram que la destilació d'un model més gran (BERT Large) dóna lloc al model més fort destilat que funciona millor tant en el llenguatge d'origen com en el llenguatge d'alvos en configuracions de zero fotografies.", 'et': 'On tõestatud, et eeltreenitud trafopõhised kodeerijad, nagu BERT, suudavad saavutada tipptasemel jõudluse mitmetel NLP-ülesannetel. Vaatamata oma edule on BERT stiilis kodeerijad suured ja neil on suur latentsus järelduste ajal (eriti CPU masinatel), mis muudab need paljude võrgurakenduste jaoks ebameeldivaks. Hiljuti kasutusele võetud surve- ja destilleerimismeetodid on pakkunud tõhusaid viise selle puuduse leevendamiseks. Nende tööde keskmes on aga olnud peamiselt ühekeelsed kodeerijad. Motivaerituna hiljutistest edusammudest nullkeelses ülekandeõppes, kasutades mitmekeelseid eeltreenitud kodeerijaid, nagu mBERT, hindame teadmiste destillatsiooni (KD) efektiivsust nii eeltreeningu etapis kui ka mitmekeelsete BERT mudelite peenhäälestuse etapis. Näitame, et vastupidiselt eelmisele tähelepanekule ühekeelse destilleerimise puhul on mitmekeelsetes tingimustes destilleerimine eeltreeningu ajal efektiivsem kui destilleerimine peenhäälestuse ajal null-shot ülekande õppimiseks. Lisaks täheldame, et destilleerimine peenhäälestuse ajal võib kahjustada null-shot keelte vahelist jõudlust. Lõpuks näitame, et suurema mudeli (BERT Large) destilleerimise tulemuseks on tugevaim destilleeritud mudel, mis toimib kõige paremini nii lähtekeeles kui ka sihtkeeles null-shot seadetes.', 'jv': 'File Ingon ngomong pengguna, koder de styl BERT lak luwih dumadhi lan akeh dumadhi kaya ngono-dumadhi sing luwih dumadhi (supayano karo dolanan ciptan-ciptan) sing gak bakal ngelakon akeh aplikasi online Defs Nanging, nggawe sistem kuwi nggawe barang pengguna-pengguna kuwi kudu akeh-ingkang banget. Ngubah berhasil sing paling nggambar nggawe barang nggawe 0-ot karo perusahaan langgar nggawe sistem multilengkang karo nggambar aturan (mBERT), kita deweke nggawe sistem efetisi layang "knowknowknowness Distillition (KDE) iki dadi neng akeh iso nggawe barang nggawe sistem multilengkang BERT model. Awak dhéwé éntukno ngono nggawe pawartos akeh barêng langgar sapa-barêng, iso nggawe barang langgar sapa-barêng, winih dhéwé, iso nggawe carane terus diuwisan luwih apik sing apik dhéwé, iso nggawe ketemut ujaran cara nggawe 0. Label, kéné ngerti surat kuwi nggambar tarjamahan kanggo masara urip 0. Soalé, kéné mulasaké ngerasakno ngono akeh model sing luwih dumadhi (BERT big) dadi model sing gak bukane sing luwih apik dhéwé, iso disebarke langkung sampeyan luwih apik lan saiki nggawe langkung urip sing wis nul.', 'sk': 'Predtrenirani kodirniki na osnovi transformatorjev, kot je BERT, so dokazali, da dosegajo vrhunsko zmogljivost pri številnih nalogah NLP. Kljub uspehu so kodirniki BERT sloga veliki in imajo visoko latenco med sklepanjem (zlasti na CPU strojih), zaradi česar so neprivlačni za številne spletne aplikacije. Nedavno uvedene metode stiskanja in destilacije so zagotovile učinkovite načine za zmanjšanje te pomanjkljivosti. Vendar pa je bil osredotočen predvsem na enojezične kodirnike. Na podlagi nedavnih uspehov v ničelnem medjezičnem učenju prenosa z večjezičnimi predvadenimi kodirniki, kot je mBERT, ocenjujemo učinkovitost destilacije znanja (KD) tako v fazi predvadenja kot v fazi finega nastavitve na večjezičnih BERT modelih. Dokazujemo, da je v nasprotju s prejšnjim opažanjem pri enojezični destilaciji destilacija v večjezičnih okoljih učinkovitejša od destilacije pri finem nastavitvi za učenje prenosa ničelnega strela. Poleg tega ugotavljamo, da lahko destilacija med finim nastavitvijo škodi ničelni medjezični zmogljivosti. Na koncu dokazujemo, da destilacija večjega modela (BERT Large) prinaša najmočnejši destilacijski model, ki najbolje deluje tako v izvornem jeziku kot tudi v ciljnih jezikih v nastavitvah brez strela.', 'ha': "An nuna kodin transformer-based kamar BERT dõmin a cika halin-the-art kan taskõkin NLP masu yawa. Babu da cin nasara, kodi ɗin BERT sun girma girma kuma sun da sauri mai girma a lokacin da ake yi wa kashi (hasa'a kan mashinaikin CPU) don su samu masu amfani da shiryoyin ayuka masu yawa. A yanzu waɗanda aka introduce, na hanyoyin ƙarasa da zane-zane-zane, sun ƙayyade hanyõyi masu amfani da su sauƙaƙara wannan ƙararrawa. Amma, fokus na waɗannan aikin sun kasance mainli a kan kodi na'ura. An Motsar da marubucin da aka yi amfani da kodi na misãlai na multilingular kamar mBERT, za'a ƙaddara aikin Cilmi (KD) duk a lokacin da aka yi amfani da shi kuma a lokacin da aka zura-tunkuɗe shi a kan misãlai na BERT. Tuna nũna cewa, da sãɓa daga taɓa na farko, a cikin masu tsari na mutane da mulki, masu farin rarrabẽwa a lokacin mutane, ko da kafaffiyar mutane da ko da za'a yi amfani da shi a lokacin da aka sanar da shishi na sifiri. Za da haka, munã ganin da rarrabẽwa a lokacin da za'a zartar da tsarin-lugha na sifanci. Na ƙarami, za mu nuna cewa, rarrabin wata motsi mai girma (BERT Large) ta ƙara cikin motsi mafi tsanani wanda ke aikata mafi kyãwon lugha na source da harshen cikin tsarin sifuri.", 'he': 'הקודנים המבוססים על מעבר מראש, כמו BERT, הוכחו כדי להשיג ביצועים מוקדמים על משימות רבות של NLP. למרות הצלחתם, הקודנים בסגנון BERT גדולים בגודל ויש להם מאוחר גבוה במהלך המסקנה (במיוחד במכונות CPU) שגורמות להם לא מופיעים לתוכניות ברשת רבות. שיטות הלחץ והשטיח שהופעו לאחרונה סיפקו דרכים יעילות להקל על החסר הזה. However, the focus of these works has been mainly on monolingual encoders.  מוטיבציה על ידי הצלחות האחרונות בלימודי העברה לשפתיים בין אפס-יריות באמצעות קודדים רבים שפתיים מתאמנים מראש, כמו mBERT, אנו מעריכים את היעילות של דיסטילציה של ידע (KD) גם במהלך שלב התאמנות מראש ובשלב התאים על דוגמנים BERT רבים שפתיים. אנו מוכיחים שבהתנגדות לאתצפיה הקודמת במקרה של משקה מונושפתי, במסגרות רבות שפות, משקה במהלך הלימודים הוא יעיל יותר משמשק במהלך התאים למידע העברה אפס. חוץ מזה, אנו שומרים על כך שדיסטיל במהלך התאמה עלול לפגוע ביצועים שונים של אפס יריות. סוף סוף, אנו מראים שדגמה גדולה יותר (BERT גדולה) תוצאה במודל הכי חזק שפועל הכי טוב גם בשפה המקורית, וגם בשפות המטרה במקומות אפס-צילומים.', 'bo': 'Pretrained transformer-based encoders such as BERT have been demonstrated to achieve state-of-the-art performance on numerous NLP tasks. དེ་ཚོའི་གྲུབ་འབྲས་ལ་ཡོད་དུས། BERT བཟོ་རྣམ་གྲངས་སྒྲིག་འགོད་ཆས་ཆེ་ཆུང་ལ་ཆུང་པོ་ཞིག་ཡིན་པ་དང་སྐྱེས་ཚད་གཞུང་བའི་ཉེན་ཆས་མང་ཙམ མཐའ་མ་དེར་བརྗོད་བྱུང་བའི་མཐའ་བཅད་དང་དབྱེ་བཟོ་བྱེད་ཀྱི་ཐབས་ལམ་ལ་ཉེ་ཆར ཡིན་ནའང་། ངལ་རྩོལ་འདི་དག་གི་དམིགས་བསལ་ནི་སྐད་ཡིག་ཆ་གཅིག་མཚོན་རྟགས་ཀྱི་ནང་དུ་བཏང་ཡོད། Motivated by recent successes in zero-shot cross-lingual transfer learning using multilingual pretrained encoders such as mBERT, we evaluate the effectiveness of Knowledge Distillation (KD) both during pretraining stage and during fine-tuning stage on multilingual BERT models. འུ་ཅག་གིས་སྐད་ཡིག་ཆ་གསལ་བའི་སྣང་ཚུལ་གྱི་ལྟ་རྟགས་ལ་ངོ་མ་ཕལ་ཚུན་མེད་པའི་སྐབས་ལུ་ སྐད་རིགས་སྒྲིག་འགོད་པའི་སྐབས་ལྟར་མང་ཙམ་རྒྱས་གཏོང་། འོན་ཀྱང་། ང་ཚོས་བརྗོད་རྙེད་སྐབས་ཀྱི་འགྱུར་བརྗོད་འདིས་གྲངས་སུ་རྙེད་ཐུབ་པའི་སྐོར་ལས་སྙམ་ཡིན་པའི་ མཐའ་མར་དུ། འུ་ཚོས་ཀྱིས་རྣམ་པ་ཆེ་བའི་མིག་དཔེ་ཞིག་བཀྲམ་སྟོན་བྱས་ན་(BERT ་ཆེ་ཆུང་ཆེ་བའི)ནང་གི་མིག་དཔེ་གཏོང་ཆེ་ཤོས་ཡོད་པའི་མ་'}
{'en': 'Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering', 'es': 'Combinación de recuperación léxica y densa para una respuesta a preguntas multisalto eficiente desde el punto de vista computacional', 'pt': 'Combinando recuperação léxica e densa para resposta a perguntas com vários saltos computacionalmente eficiente', 'ar': 'الجمع بين الاسترداد المعجمي والكثيف لإجابة أسئلة متعددة القفزات ذات كفاءة حسابية', 'fr': 'Combinaison de la récupération lexicale et dense pour une réponse aux questions multi-sauts efficace sur le plan informatique', 'ja': '計算効率の高いマルチホップクエスチョンアンサーのための語彙検索と濃密検索の組み合わせ', 'zh': '合词法密检,计高效多跳答', 'ru': 'Сочетание лексического и плотного поиска для ответа на вычислительно эффективный многохоповый вопрос', 'hi': 'कम्प्यूटेशनल रूप से कुशल मल्टी-हॉप प्रश्न का उत्तर देने के लिए लेक्सिकल और घने पुनर्प्राप्ति का संयोजन', 'ga': 'Aisghabháil Lexical agus Dlúth a Snaidhmeadh le hAghaidh Freagraí Ceiste Il-hop atá Éifeachtúil ar an Ríomhaireacht', 'ka': 'კომპიუტეციალურად ეფექტიურად მრავალ-ჰოპის კითხვების გასაგებისთვის ლექსიკალური და ცენის გადასრულება', 'hu': 'A Lexikális és a Sűrű Visszaszerzés kombinációja a számítástechnikailag hatékony Multi-Hop kérdések megválaszolásához', 'el': 'Συνδυασμός λεξικής και πυκνής ανάκτησης για υπολογιστικά αποδοτική απάντηση ερωτήσεων πολλαπλών χορού', 'it': 'Combinando il recupero lessico e denso per una risposta multi-hop computazionale efficiente', 'kk': 'Компьютерлік көп- хоп сұрақтар жауап беру үшін лексикалық және тұлғаларды біріктіру', 'lt': 'Kompiuteriniu požiūriu efektyviai atsakyti į daugiapynius klausimus', 'mk': 'Comment', 'ms': 'Menggabungkan Pemulihan Lexik dan Dense untuk Jawapan soalan Berlipat-Hop Efisien Secara Komputer', 'ml': 'കമ്പ്യൂട്ടിഷന്\u200d പ്രയോജനപ്പെടുത്തുന്നതിനായി ലെക്സിക്കലിലും ഡെന്\u200dസിലും വീണ്ടെടുക്കുന്ന ചോദ്യം', 'mt': 'Il-Kombinazzjoni tal-Kisba Lessika u Densa għal Tweġiba għal Mistoqsijiet Multihops Effiċjenti mill-Komputazzjoni', 'mn': 'Компьютерийн үр дүнтэй олон-холбоотой асуулт хариултын хувьд лексикийн болон Dense Retrieval холбоотой', 'no': 'Kombinerer leksisk og densk henting for datamaskin effektiv fleirhopp-spørsmål', 'pl': 'Połączenie leksykalnego i gęstego odzyskiwania w celu wydajnego obliczeniowego odpowiadania na pytania wielokrotnie', 'sv': 'Kombinationen av Lexical och Dense Retrieval för beräkningseffektiv Multi-Hop Question', 'si': 'ලෙක්සිකාල් හා ඩෙන්ස් ප්\u200dරශ්නයක් සම්බන්ධ වෙනුවෙන් පරිගණනය විශේෂ විශේෂ විශේෂ විශේෂ වි', 'so': 'Combining Lexical and Dense Retrieval for Computationally Effective Question Multi-hop', 'ro': 'Combinând extragerea lexicală și densă pentru un răspuns la întrebări multi-hop eficient din punct de vedere computațional', 'sr': 'Kombinacija leksičkog i zubara za odgovor na računalno efikasno multihopsko pitanje', 'ta': 'கணக்கீட்டில் பயனுள்ள பல- hop கேள்விக்கான திரும்பச் சேர்ப்பு', 'ur': 'کمپیوٹریشن کے ذریعے مثبت multi-hop سؤال جواب کے لئے لکسکسیسی اور ڈینس پھیرنے کے ساتھ ملے جاتے ہیں', 'uz': 'Name', 'vi': 'Kết hợp câu trả lời câu hỏi từ Lexical và Dense', 'hr': 'Kombinacija leksičkog i zubara za odgovor na računalno učinkovito multihopski pitanje', 'nl': 'Combinatie van Lexical en Dense Retrieval voor computerefficiënt Multi-hop vragenantwoord', 'bg': 'Комбиниране на лексикално и плътно извличане за компютърно ефективно мулти-хоп отговор на въпроси', 'da': 'Kombinerer Lexical og Tæt Hentning for Computationalt Effektiv Multi-Hop Spørgsmål Besvarelse', 'de': 'Kombination von Lexical und Dense Retrieval für computereffiziente Multi-Hop-Fragebeantwortung', 'fa': 'ترکیب بازیابی سکسیک و دنز برای پاسخ سوال\u200cهای زیادی\u200cهاپ مثبت در کامپیوتر', 'id': 'Menggabungkan Penerimaan Lexik dan Dense untuk Jawaban Pertanyaan Multi-Hop Efisien Secara Komputasi', 'sw': 'Kuunganisha Lexico na Dense kurudishwa kwa ajili ya swali kubwa la Maswali', 'tr': 'Bilgisayardan ýeterli Çoklu-Hop soragy jogap üçin birleştirilýär', 'ko': '어휘와 밀집 검색을 결합하여 계산이 효율적인 다중 퀴즈를 실현하다', 'af': 'Kombineer Leksiese en Dense Ontvaring vir Rekenaasjoneel Effektiewe Multihopvraag Antwoord', 'sq': 'Përbashkimi i marrjes leksikale dhe të dendura për përgjigjet e pyetjeve me shumëkëmbë të efektshme në llogari', 'am': 'Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering', 'hy': 'Համակարգչային արդյունավետ բազմահոսական հարցերի պատասխանի համար', 'bn': 'গণতান্ত্রিকভাবে কার্যকর প্রশ্নের জন্য লেক্সিক্যাল এবং ডেন্স পুনরুদ্ধারের সাথে যোগাযোগ করা হচ্ছে', 'az': 'Bilgisayarlı çoxlu-Hop soruşu cavab vermək üçün Lexical and Dense Retrieval', 'bs': 'Kombiniranje leksičkog i Denskog otkupljanja za računalno učinkovito multihopski odgovor na pitanje pitanja', 'ca': 'Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering', 'cs': 'Kombinace Lexického a hustého vyhledávání pro výpočetně efektivní odpověď na více hopové otázky', 'et': 'Lexikaalse ja tiheda kogumise kombineerimine arvutiliselt tõhusaks mitme hüppega küsimustele vastamiseks', 'fi': 'Lexikaalisen ja tiheän haun yhdistäminen tietokonetehokkaaseen monihyppyyn vastaamiseen', 'jv': 'politenessoffpolite"), and when there is a change ("assertivepoliteness', 'sk': 'Združevanje leksičnega in gostega pridobivanja za računalniško učinkovito odgovarjanje na vprašanja z več koraki', 'he': 'שילוב השיגה לקסית ועקרנות עבור תשובות על שאלות רבות יעילות מחשבית', 'ha': 'KCharselect unicode block name', 'bo': 'Combining Lexical and Dense Retrieval for Computationally Efficient Multi-hop Question Answering'}
{'en': 'In simple open-domain question answering (QA), dense retrieval has become one of the standard approaches for retrieving the relevant passages to infer an answer. Recently, dense retrieval also achieved state-of-the-art results in multi-hop QA, where aggregating information from multiple pieces of information and reasoning over them is required. Despite their success, dense retrieval methods are computationally intensive, requiring multiple GPUs to train. In this work, we introduce a hybrid (lexical and dense) retrieval approach that is highly competitive with the state-of-the-art dense retrieval models, while requiring substantially less computational resources. Additionally, we provide an in-depth evaluation of dense retrieval methods on limited computational resource settings, something that is missing from the current literature.', 'pt': 'Na resposta a perguntas de domínio aberto simples (QA), a recuperação densa tornou-se uma das abordagens padrão para recuperar as passagens relevantes para inferir uma resposta. Recentemente, a recuperação densa também alcançou resultados de última geração em QA multi-hop, onde é necessário agregar informações de várias informações e raciocinar sobre elas. Apesar de seu sucesso, os métodos de recuperação densos são computacionalmente intensivos, exigindo várias GPUs para treinar. Neste trabalho, apresentamos uma abordagem de recuperação híbrida (lexical e densa) que é altamente competitiva com os modelos de recuperação densa de última geração, exigindo substancialmente menos recursos computacionais. Além disso, fornecemos uma avaliação aprofundada de métodos de recuperação densa em configurações de recursos computacionais limitados, algo que está faltando na literatura atual.', 'fr': "Dans les réponses simples aux questions ouvertes (AQ), la récupération dense est devenue l'une des approches standard pour récupérer les passages pertinents afin de déduire une réponse. Récemment, la récupération dense a également permis d'obtenir des résultats de pointe en matière d'assurance qualité multi-sauts, où il est nécessaire d'agréger des informations provenant de plusieurs informations et de raisonner sur celles-ci. Malgré leur succès, les méthodes de récupération denses sont gourmandes en ressources informatiques, nécessitant l'entraînement de plusieurs GPU. Dans ce travail, nous introduisons une approche de récupération hybride (lexicale et dense) qui est très compétitive par rapport aux modèles de récupération dense de pointe, tout en nécessitant beaucoup moins de ressources informatiques. De plus, nous fournissons une évaluation approfondie des méthodes de récupération dense sur des paramètres de ressources informatiques limités, ce qui est absent de la littérature actuelle.", 'es': 'En la respuesta a preguntas (QA) simple de dominio abierto, la recuperación densa se ha convertido en uno de los enfoques estándar para recuperar los pasajes relevantes para inferir una respuesta. Recientemente, la recuperación densa también logró resultados de vanguardia en el control de calidad de múltiples saltos, donde es necesario agregar información de múltiples piezas de información y razonar sobre ellas. A pesar de su éxito, los métodos de recuperación densos son computacionalmente intensivos y requieren varias GPU para entrenarse. En este trabajo, presentamos un enfoque de recuperación híbrido (léxico y denso) que es altamente competitivo con los modelos de recuperación densa de última generación, a la vez que requiere sustancialmente menos recursos computacionales. Además, ofrecemos una evaluación en profundidad de los métodos de recuperación densos en entornos de recursos computacionales limitados, algo que falta en la literatura actual.', 'ar': 'في الإجابة البسيطة على أسئلة المجال المفتوح (QA) ، أصبح الاسترجاع المكثف أحد الأساليب القياسية لاسترداد المقاطع ذات الصلة لاستنتاج إجابة. في الآونة الأخيرة ، حقق الاسترجاع الكثيف أيضًا نتائج متطورة في ضمان الجودة متعدد القفزات ، حيث يلزم تجميع المعلومات من أجزاء متعددة من المعلومات والاستدلال عليها. على الرغم من نجاحها ، إلا أن طرق الاسترجاع الكثيفة تتطلب عمليات حسابية مكثفة ، وتتطلب تدريب العديد من وحدات معالجة الرسومات. في هذا العمل ، نقدم نهج استرجاع هجين (معجمي وكثيف) يتسم بقدرة تنافسية عالية مع أحدث نماذج الاسترجاع الكثيفة ، بينما يتطلب موارد حسابية أقل بشكل كبير. بالإضافة إلى ذلك ، نقدم تقييمًا متعمقًا لأساليب الاسترجاع الكثيفة على إعدادات موارد حسابية محدودة ، وهو أمر مفقود في الأدبيات الحالية.', 'ja': '単純なオープンドメイン質問の回答（ QA ）では、密度の高い検索は、答えを推論するために関連する経路を検索するための標準的なアプローチの1つになっています。最近では、複数の情報から情報を集約して推論する必要があるマルチホップQAにおいても、最先端の結果が得られています。それらの成功にもかかわらず、濃密な検索方法は計算的に集中しており、訓練するために複数のGPUが必要です。この研究では、計算リソースを実質的に削減する一方で、最先端の密度の高い検索モデルと競合するハイブリッド（語彙的および密度の高い）検索アプローチを紹介します。さらに、現在の文献にはない、限られた計算リソース設定に関する濃密な検索方法の詳細な評価を提供します。', 'zh': '简开域问答(QA)中,密检已成检索相关段落以推答案之法。 近者,密集检索于多跳 QA 中亦得最先进,其中须于数息片段中聚息而推之。 虽有成功,而密索术数甚多,须数GPU训练。 凡此等事,引入一混合(词法密集)检索之法,当与最先进密检模有高竞争力,兼须计算资源要少得多。 又有限之计算资源,设密检之法,深加评估,此当时文献所阙也。', 'hi': 'सरल ओपन-डोमेन प्रश्न उत्तर (क्यूए) में, घने पुनर्प्राप्ति एक उत्तर का अनुमान लगाने के लिए प्रासंगिक मार्गों को पुनर्प्राप्त करने के लिए मानक दृष्टिकोणों में से एक बन गया है। हाल ही में, घने पुनर्प्राप्ति ने मल्टी-हॉप क्यूए में अत्याधुनिक परिणाम भी प्राप्त किए, जहां उन पर जानकारी और तर्क के कई टुकड़ों से एकत्रित जानकारी की आवश्यकता होती है। उनकी सफलता के बावजूद, घने पुनर्प्राप्ति विधियां कम्प्यूटेशनल रूप से गहन हैं, जिन्हें प्रशिक्षित करने के लिए कई जीपीयू की आवश्यकता होती है। इस काम में, हम एक हाइब्रिड (लेक्सिकल और घने) पुनर्प्राप्ति दृष्टिकोण का परिचय देते हैं जो अत्याधुनिक घने पुनर्प्राप्ति मॉडल के साथ अत्यधिक प्रतिस्पर्धी है, जबकि काफी कम कम्प्यूटेशनल संसाधनों की आवश्यकता होती है। इसके अतिरिक्त, हम सीमित कम्प्यूटेशनल संसाधन सेटिंग्स पर घने पुनर्प्राप्ति विधियों का गहन मूल्यांकन प्रदान करते हैं, जो वर्तमान साहित्य से गायब है।', 'ru': 'В простых ответах на вопросы открытого домена (QA) плотное извлечение стало одним из стандартных подходов для извлечения соответствующих отрывков, чтобы вывести ответ. В последнее время плотное извлечение также достигло самых современных результатов в многохоповом QA, где требуется агрегирование информации из нескольких частей информации и рассуждения о них. Несмотря на их успех, методы плотного поиска являются вычислительно интенсивными, требуя обучения нескольких графических процессоров. В этой работе мы вводим гибридный (лексический и плотный) подход к поиску, который сильно конкурирует с самыми современными плотными моделями поиска, в то же время требуя значительно меньших вычислительных ресурсов. Кроме того, мы предоставляем углубленную оценку методов плотного поиска по ограниченным настройкам вычислительных ресурсов, чего не хватает в текущей литературе.', 'ga': 'I bhfreagra simplí ar cheisteanna oscailte (QA), tá aisghabháil dhlúth anois ar cheann de na cuir chuige caighdeánacha chun na sleachta ábhartha a aisghabháil chun freagra a fháil. Le déanaí, bhain aisghabháil dhian torthaí úrscothacha amach i QA il-hop, áit a bhfuil gá le comhiomlánú faisnéise ó phíosaí iomadúla faisnéise agus réasúnaíocht ina leith. In ainneoin a n-éireoidh leo, tá dian-mhodhanna aisghabhála i gceist ó thaobh ríomha de, rud a éilíonn oiliúint ar il-GPUanna. San obair seo, tugaimid isteach cur chuige hibrideach (foclóra agus dlúth) aisghabhála atá an-iomaíoch leis na múnlaí dlúth-aisghabhála den scoth, agus a dteastaíonn acmhainní i bhfad níos lú ríomha uathu. Ina theannta sin, cuirimid meastóireacht dhomhain ar fáil ar mhodhanna dlútha aisghabhála ar shocruithe teoranta acmhainní ríomhaireachtúla, rud atá in easnamh ón litríocht reatha.', 'ka': 'საუკეთესო დიომინის გახსნა კითხვა (QA) სხვადასხვა კითხვის შესაძლებელად, სამყარო გახსნა იყო ერთი სტანდარტური გახსნა, რომელიც შესაძლებელი გახსნა გასაგებლად. მიმდინარე, სურათების შესაძლებლობა მრავალ-ჰოპ QA-ში მიიღება, სადაც უფრო მრავალ ინფორმაციის მონაცემების და განსაზღვრების შესაძლებლობა უნდა იყოს ინფორმაცია. მათი წარმატების შემდეგ, ძალიან კომპუტაციალურად ინტერნექტიურია, რაც უნდა უფრო მეტი GPUs გაგრძელება. ამ სამუშაოში ჩვენ ჩვენ ჩვენ შევცვალოთ ჰიბრიტური (ლექსიკალური და მცირები) მოწყობილობა, რომელიც ძალიან კონპექტიურია კონპექტიური მსოფლიოს მოდელებით, რომელიც უნდა უფრო ცოტ დამატებით, ჩვენ განვითარებთ ძალიან განსაზღვრებული კომპუტაციალური რესურსების განსაზღვრების განსაზღვრება, რაც მიმდინარე ლიტურატიდან არსებობს.', 'el': 'Στην απλή απάντηση σε ερωτήσεις ανοικτού τομέα (QA), η πυκνή ανάκτηση έχει γίνει μια από τις τυποποιημένες προσεγγίσεις για την ανάκτηση των σχετικών αποσπασμάτων για να συναχθεί μια απάντηση. Πρόσφατα, η πυκνή ανάκτηση πέτυχε επίσης αποτελέσματα τελευταίας τεχνολογίας σε πολλαπλές ερωτήσεις, όπου απαιτείται η συγκέντρωση πληροφοριών από πολλαπλά κομμάτια πληροφοριών και η συλλογιστική πάνω τους. Παρά την επιτυχία τους, οι μέθοδοι πυκνής ανάκτησης είναι υπολογιστικά εντατικές, απαιτώντας πολλαπλές GPU για την εκπαίδευση. Στην παρούσα εργασία, εισάγουμε μια υβριδική (λεξική και πυκνή) προσέγγιση ανάκτησης που είναι ιδιαίτερα ανταγωνιστική με τα σύγχρονα μοντέλα ανάκτησης πυκνών, ενώ απαιτεί σημαντικά λιγότερους υπολογιστικούς πόρους. Επιπλέον, παρέχουμε μια σε βάθος αξιολόγηση των μεθόδων πυκνής ανάκτησης σε περιορισμένες ρυθμίσεις υπολογιστικών πόρων, κάτι που λείπει από την τρέχουσα βιβλιογραφία.', 'hu': 'Az egyszerű nyílt domain kérdésre adott válasz (QA) esetében a sűrű visszakeresés az egyik szabványos megközelítéssé vált a releváns részek visszakereséséhez, amelyek a válasz levonásához szükségesek. A közelmúltban a sűrű visszakeresés a legkorszerűbb eredményeket is eredményezte a multi-hop minőségbiztosításban, ahol több információból származó információk összesítésére és érvelésére van szükség. Sikerük ellenére a sűrű visszakeresési módszerek számítástechnikailag intenzívek, és több GPU-t igényelnek a képzéshez. Ebben a munkában olyan hibrid (lexikai és sűrű) visszakeresési megközelítést mutatunk be, amely nagyon versenyképes a korszerű sűrű visszakeresési modellekkel, ugyanakkor lényegesen kevesebb számítási erőforrást igényel. Ezenkívül a korlátozott számítási erőforrás-beállítások sűrű visszakeresési módszereinek mélyreható értékelését is nyújtjuk, ami hiányzik a jelenlegi irodalomból.', 'lt': 'In simple open-domain question answering (QA), dense retrieval has become one of the standard approaches for retrieving the relevant passages to infer an answer.  Pastaruoju metu intensyvus surinkimas taip pat pasiekė pažangiausius rezultatus daugiapynių QA atveju, kai reikalinga surinkti informaciją iš įvairių informacijos dalių ir juos pagrįsti. Nepaisant jų sėkmės, dažni atgavimo metodai yra skaičiavimo požiūriu intensyvūs, todėl reikia mokyti kelis GPU. Šiame darbe įvedame hibridinį (lexinį ir tankų) atkūrimo metodą, kuris yra labai konkurencingas su naujausiais tankių atkūrimo modeliais, tačiau reikalauja gerokai mažiau skaičiavimo išteklių. Be to, mes išsamiai vertiname tankių surinkimo metodus, taikomus ribotiems skaičiavimo išteklių nustatymams, o tai dabartinėje literatūroje trūksta.', 'mk': 'Во едноставното отворено одговорување на прашањата (QA), густото преземање стана еден од стандардните пристапи за преземање на релевантните премини за да се заклучи одговор. Recently, dense retrieval also achieved state-of-the-art results in multi-hop QA, where aggregating information from multiple pieces of information and reasoning over them is required.  И покрај нивниот успех, густите методи за преземање се компјутационално интензивни, барајќи повеќе ГПУ за обука. Во оваа работа, воведуваме хибриден (лексикален и густ) пристап на преземање кој е високо конкурентивен со најсовремените густи модели на преземање, истовремено барајќи значително помалку компјутерски ресурси. Покрај тоа, ние обезбедуваме длабока проценка на густите методи за обезбедување на ограничени компјутерски ресурси, нешто што недостасува од сегашната литература.', 'it': "Nella semplice risposta alle domande open-domain (QA), il recupero denso è diventato uno degli approcci standard per recuperare i passaggi pertinenti per dedurre una risposta. Recentemente, il recupero denso ha anche ottenuto risultati all'avanguardia in QA multi-hop, dove è necessario aggregare informazioni da più pezzi di informazioni e ragionare su di esse. Nonostante il loro successo, i metodi di recupero densi sono computazionali intensivi e richiedono più GPU per allenarsi. In questo lavoro, introduciamo un approccio ibrido (lessicale e denso) di recupero che è altamente competitivo con i modelli di recupero denso all'avanguardia, pur richiedendo risorse computazionali sostanzialmente inferiori. Inoltre, forniamo una valutazione approfondita dei metodi di recupero densi su impostazioni di risorse computazionali limitate, cosa che manca dalla letteratura corrente.", 'kk': 'Қарапайым ашылған домен сұрақтарында (QA) жауап беру үшін, жауап беру үшін қолданыстағы парольдерді алу үшін стандартты жағдайдың бірі болды. Жуырдағы уақытта жұмыс алу және бірнеше мәліметтің бөлшектерінен және олардың арасындағы түсініктерінен мәліметті жинақтау үшін көп-хоп QA нәтижесін жеткізді. Бұлардың сәттілігіне қарамастан, тұтас алу әдістері есептеп жатқан, бірнеше GPU-ді оқыту керек. Бұл жұмыс ішінде біз хибридті (лексикалық және жиілік) алу әдісін таңдап береміз. Бұл әдістер күйінде жұмыс қабылдау үлгілерімен көп жарықтық болады. Бірақ компьютерлік ресурстар қажет етеді. Сонымен қатар, біз қазіргі литературадан жоқ әдістерді шектелген компьютерлік ресурстар баптауларының жиілік алу әдістерін түсініктіреміз.', 'ml': 'എളുപ്പമായ തുറന്ന ഡൊമൈന്\u200d ചോദ്യത്തിന്റെ ഉത്തരം (ക്യൂഎ) ഉത്തരം നല്\u200dകുന്നതില്\u200d, ഉത്തരം തുറക്കാനുള്ള പാസ്സുകള്\u200d പിടിച്ചെടുക അടുത്തിടെയുള്ള വിവരങ്ങള്\u200d കൂടുതല്\u200d വിവരങ്ങളില്\u200d നിന്നും വിവരങ്ങള്\u200d കൂടുതല്\u200d വിവരങ്ങളില്\u200d നിന്നും കൂടുതല്\u200d വിവരങ്ങള്\u200d കൂടുതല്\u200d വിവരങ്ങള്\u200d ചേര്\u200dക്കു അവരുടെ വിജയം കഴിഞ്ഞാലും, കണക്കില്\u200d വീണ്ടെടുക്കുന്ന രീതികള്\u200d കണക്കാക്കാക്കുന്നതാണ്. ഒരുപാട് ജിപിയുവിന് പരിശീ ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d ഹൈബ്രിഡിനെ പരിചയപ്പെടുത്തുന്നു (ലെക്സിക്സിക്കലും സൂക്ഷ്മവുമുള്ള) പിന്തിരിച്ചുകൊണ്ടിരിക്കുന്നു. അത് സ്ഥാനത്ത കൂടുതലായി, നിലവിലുള്ള സാഹിത്യത്തില്\u200d നിന്നും കാണാത്ത സാഹിത്യത്തില്\u200d നിന്നും കുറച്ചുപോകുന്ന തരത്തിലുള്ള വിഭവങ്ങളുടെ ആഴത്ത', 'mt': 'F’risposta sempliċi għal mistoqsijiet b’dominju miftuħ (QA), irkupru dens sar wieħed mill-approċċi standard biex jinkisbu l-passaġġi rilevanti biex tiġi inferita risposta. Recently, dense retrieval also achieved state-of-the-art results in multi-hop QA, where aggregating information from multiple pieces of information and reasoning over them is required.  Minkejja s-suċċess tagħhom, metodi densi ta’ rkupru huma komputazzjonalment intensivi, li jeħtieġu taħriġ ta’ diversi GPUs. F’dan ix-xogħol, a ħna nintroduċu approċċ ta’ rkupru ibridu (lexiku u dens) li huwa kompetittiv ħafna mal-mudelli ta’ rkupru dens l-aktar avvanzati, filwaqt li jeħtieġu riżorsi sostanzjalment inqas komputattivi. Barra minn hekk, nagħtu evalwazzjoni fil-fond ta’ metodi ta’ rkupru dens fuq setturi limitati tar-riżorsi komputattivi, xi ħaġa li hija nieqsa mil-letteratura attwali.', 'ms': 'Dalam jawapan soalan domain terbuka sederhana (QA), pemulihan padat telah menjadi salah satu pendekatan piawai untuk mendapatkan laluan berkaitan untuk menyimpulkan jawapan. Baru-baru ini, pemulihan tebal juga mencapai keputusan state-of-the-art dalam QA multi-hop, di mana pengumpulan maklumat dari beberapa kepingan maklumat dan alasan atas mereka diperlukan. Despite their success, dense retrieval methods are computationally intensive, requiring multiple GPUs to train.  Dalam kerja ini, kami memperkenalkan pendekatan pemulihan hibrid (leksikal dan padat) yang sangat bersaing dengan model pemulihan padat terbaik, sementara memerlukan sumber komputasi yang jauh kurang. Lagipun, kami menyediakan penilaian mendalam kaedah pemulihan padat pada tetapan sumber komputasi terbatas, sesuatu yang hilang dari literatur semasa.', 'mn': 'Хариулт олохын тулд энгийн нээлттэй холбоотой асуулт (QA) дээр байнга авах нь хариултыг халдварлахын тулд хамааралтай зам авах стандарт арга болсон. Сүүлийн үед жинхэнэ хүлээн авах нь мөн олон холбоотой QA-ын уламжлалтын үр дүн гарч ирсэн. Мөн олон хэсгийг мэдээллээс хамтын мэдээллийг цуглуулах хэрэгтэй. Тэдний амжилтыг хүртэл, жижиг хүлээн авах аргыг тооцооллоор маш их хүчтэй, олон GPUs сургах хэрэгтэй. Энэ ажлын хувьд бид маш бага тооцоололтын баялаг шаардлагатай гибрид (лексик, жингэн) авах арга загварыг танилцуулдаг. Мөн бид хоорондоо тооцооллын боловсролын байгууллагуудын тухай ихэвчлэн гүн гүнзгий үнэлгээ өгдөг.', 'no': 'I enkelt open-domain spørsmål svaring (QA) er tett retrieval blitt ein av standardtilnærmingane for å henta dei relevante passagene for å gjera ein svar. Nyleg er det også nødvendig å samla informasjon frå fleire deler av informasjon og rasjon over dei nødvendig å oppnå dens henting i multihopp QA. Til tross sine suksess er det tette hendingsmetode kalkulasjonsintensivt, som krev fleire GPU til å trenja. I denne arbeiden introduserer vi ein hybrid (leksisk og tett) tilnærming som er svært konkurrentivt med den kunstende tette hentingsmodulen, mens det krev stort mindre dataressursar. I tillegg tilbyr vi ein dybde evaluering av tett hentingsmetoder på begrenset datamaskinenstillingar, noe som manglar frå gjeldande literatur.', 'ro': 'În răspunsul simplu la întrebări pe domeniu deschis (QA), recuperarea densă a devenit una dintre abordările standard pentru recuperarea pasajelor relevante pentru deducerea unui răspuns. Recent, recuperarea densă a obținut, de asemenea, rezultate de ultimă oră în QA multi-hop, unde este necesară agregarea informațiilor din mai multe informații și raționamentul asupra acestora. În ciuda succesului lor, metodele dense de recuperare sunt intense din punct de vedere computațional, necesitând mai multe GPU-uri pentru a se antrena. În această lucrare, introducem o abordare hibridă (lexicală și densă) de recuperare care este extrem de competitivă cu modelele de recuperare densă de ultimă generație, necesitând în același timp mult mai puține resurse computaționale. În plus, oferim o evaluare aprofundată a metodelor dense de recuperare a setărilor limitate de resurse computaționale, ceva care lipsește din literatura actuală.', 'pl': 'W prostych otwartych odpowiedziach na pytania (QA) gęste odzyskiwanie stało się jednym ze standardowych podejść do pobierania odpowiednich fragmentów w celu wywnioskowania odpowiedzi. Ostatnio gęste odzyskiwanie osiągnęło również najnowocześniejsze rezultaty w multi-hop QA, gdzie wymagane jest agregowanie informacji z wielu fragmentów informacji i rozumowanie nad nimi. Pomimo ich sukcesu, metody gęstego odzyskiwania są intensywne obliczeniowo, wymagające treningu wielu GPU. W niniejszej pracy wprowadzamy hybrydowe (leksykalne i gęste) podejście pobierania, które jest wysoce konkurencyjne w stosunku do najnowocześniejszych modeli gęstego pobierania, przy jednoczesnym wymaganiu znacznie mniejszych zasobów obliczeniowych. Dodatkowo przeprowadzamy dogłębną ocenę metod gęstego pozyskiwania na ograniczonych ustawieniach zasobów obliczeniowych, czego brakuje w obecnej literaturze.', 'si': 'සාමාන්\u200dය ප්\u200dරශ්න ප්\u200dරශ්න (QA) වලින්, ප්\u200dරශ්න ප්\u200dරශ්න ප්\u200dරශ්නයක්, ප්\u200dරශ්නයක් පරික්ෂා කරන්න සඳහා ප්\u200dරමාණයිත ප්\u200dර අලුත් වෙලාවෙන්, ගොඩක් ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විශේෂයෙන් ගොඩක් හොප් QA වලින් ප්\u200dරතික්\u200dරියාත්මක විසින් ලැ ඔවුන්ගේ සාර්ථක විදියට තියෙන්නේ නැත්නම්, ගුණු ප්\u200dරාප්ත විදියට පරීක්ෂණය විදියට පරීක්ෂණය විශේ මේ වැඩේ අපි හායිබ්\u200dරිඩ් එක (ලෙක්සිකාල් හා ගුණුවක්) ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක විදිහට ප්\u200dරතික්\u200dරියාත්මක වෙනුවෙන් ප්\u200d තවත්, අපි ගොඩක් ගොඩක් අවශ්\u200dය විශ්ලේෂණයක් ලැබෙන්නේ අවශ්\u200dය පද්ධතිය පද්ධතිය සැකසුම් සඳහා ගොඩක් අවශ්\u200dය විශ්', 'sv': 'I enkel open-domain question responsing (QA) har tät hämtning blivit en av standardmetoderna för att hämta relevanta passager för att härleda ett svar. Nyligen uppnådde tät hämtning också toppmoderna resultat i multi-hop QA, där aggregering av information från flera delar av information och resonemang över dem krävs. Trots deras framgång är täta hämtningsmetoder beräkningsintensiva, vilket kräver flera GPU:er att träna. I detta arbete introducerar vi en hybrid (lexikal och tät) återvinningsmetod som är mycket konkurrenskraftig med de senaste kompakta återvinningsmodellerna, samtidigt som det kräver betydligt mindre beräkningsresurser. Dessutom ger vi en fördjupad utvärdering av täta insamlingsmetoder på begränsade beräkningsresursinställningar, något som saknas i aktuell litteratur.', 'so': "jawaabta su'aalaha furan oo furan (QA) waxaa laga noqday mid ka mid ah qaababka caadiga ah in loo soo celiyo baasaboorada la xiriira si ay jawaab u gasho. Hadii u dhowayd waxaa sidoo kale helay xaaladda farshaxanka ah, kaas oo looga baahan yahay macluumaad ka sii kordhaya qeybo badan oo macluumaad kala duduwan iyo ka fekero. Inta kastoo ay guulaysteen, hababka dib u soo celinta hoose waa mid xisaab badan, oo waxay u baahan yihiin in GPUs badan la tababaro. Markaas waxan, waxaynu soo bandhignaynaa qaab la soo celinayo (leksikal iyo cidhiidhi) oo aad u dadaalaya qaababka dib u soo celinta ee dowladda farshaxanka, iyadoo aad u baahan in ay u baahan yihiin hanti ka yar xisaabta. Waxaa kaloo dheer, waxaynu qiimeynaynaa meelo hoos u dheer oo ku saabsan qaababka dib u soo celinta ee xisaabta, taas oo aan ka baaqan warqadda hada.", 'sr': 'U jednostavnom odgovoru na pitanje otvorenog domena (QA), gusto povlačenje postalo je jedan od standardnih pristupa za povlačenje odgovarajućih prolaza za uvlačenje odgovora. Nedavno je gusto prikupljanje postiglo i rezultate umetnosti u multihopskom QA-u, gdje je potrebno okupljanje informacija iz višestrukih komada informacija i razmišljanje o njima. Uprkos njihovom uspjehu, guste metode prikupljanja su kompjuterski intenzivne, zahtevajući više GPU-a da treniraju. U ovom poslu predstavljamo hibridni (leksički i gusti) pristup povlačenja koji je vrlo konkurentni sa modelima gustih povlačenja stanja umjetnosti, dok je potrebno značajno manje računalnih resursa. Osim toga, pružamo duboku procjenu gustih metoda povlačenja na ograničene postavke računalnih resursa, nešto što nedostaje iz trenutne literature.', 'ta': 'சுலபமான திறந்த களம் கேள்வி பதில் (QA) கேள்வியில், கூட்டு மீட்டெடுப்பது ஒரு தொடர்பு கடவுச்செல்களை பெறுவதற்கு பதிலை குறைக்க ஒரு  அண்மையில் உள்ள திரும்ப பெறுதல் முடிவுகளும் பல- ஹாப் கியூஏவின் முடிவுகளும் பெற்றுவிட்டது, அதில் பல தகவல் துண்டுகளிலிருந்து தகவலை பெரு அவர்கள் வெற்றியடைந்த பின்னரும், தூரமான மீட்டெடுப்பு முறைமைகள் கணக்கில் கடுமையாக இருக்கிறது, பல ஜிபியூஸை பயிற்சி இந்த வேலையில், நாம் ஒரு ஹைப்ரிட்( லெக்சியல் மற்றும் கனத்தில்) மீட்டெடுப்பு முறைமையை அறிவிக்கிறோம். அது மிகவும் பொருத்தமானது, கலை மீட்டும் மாதிரி கூடுதலாக, நாம் தற்போதைய எழுத்தாக்கத்திலிருந்து காணவில்லை உள்ள அடர்த்திய முறைமைகளை பரிசோதிக்கும் ஆழமான மதிப்புகளை வழங்குகி', 'ur': '(QA) سفید پرسش پرسش میں گہرے پھیرنے کے لئے ایک استاندارڈ طریقے سے ہو گئے ہیں کہ ایک جواب کے ذریعے اہل مسافروں کو پھیرنے کے لئے اہل مسافروں کو اٹھانے کے لئے۔ اچھا، گہرے پھیرنے کے لئے بہت سے ہپ کیا کے نتیجے بھی پہنچ گئے، جہاں بہت سی اطلاعات کے ٹکڑے سے اطلاعات جمع کرنا اور ان کے بارے میں بحث کرنے کی ضرورت ہے. ان کے کامیابی کے بغیر، گہرے پھیرنے کے طریقے کامپیوتروں سے زیادہ زیادہ مضبوط ہیں، اور بہت سی جی پی یوس کو ٹرین کرنا چاہتے ہیں. اس کام میں ہم ایک ہیبریڈ (لکسیکل اور گہرے) پھیرنے کی تقریبا پیش کرتے ہیں جو بہت کم کم کم کامپیوتروں کی منابع کے ساتھ مطابق ہے۔ اور اضافہ، ہم نے محدود محاسبہ محاسبہ کے رسسور سٹینٹوں پر گہرے پھیرنے کے طریقے کی گہرے اندھیرے کا ارزش دیا ہے، جو موجود ادبیات سے گم ہوتی ہے.', 'uz': "Name Yaqinda ko'pchilik maʼlumotni bir necha qismlardan qo'yish va ularning haqida murakkab qilish kerak. Muvaffaqiyatlaridan ham qiymati muvaffaqiyatli o'zgartirish usullari kompyuterni kattalashtiradi, bir nechta GPUs o'rganish kerak. Bu vazifanda, biz hebik (leksikal va qisqa) qayta olish usulini ko'rib chiqaramiz. Bu davlat davlatdan juda qisqarli raqamli raqamlarni qayta olish modellari bilan ishlab chiqaramiz. Koʻrsatilgan, biz kompyuterning cheksiz resource moslamalariga qiymatni qo'shish usullarini qo'shish mumkin. Joriy littatyatdan yo'q narsa.", 'vi': 'Trong câu hỏi đơn giản về vùng mở câu hỏi (QA), việc lấy mật độ dày đã trở thành một trong các phương pháp tiêu chuẩn để lấy các đoạn liên quan để ngụ ý câu trả lời. Gần đây, việc thu hồi dày đặc cũng đạt được kết quả hiện đại nhất của QA đa hop, nơi cần phải tổng hợp thông tin từ nhiều phần thông tin và lý lẽ về chúng. Mặc dù thành công, phương pháp thu hồi dày đặc làm từ tính, cần nhiều GPUS để được huấn luyện. Trong công việc này, chúng tôi giới thiệu một phương pháp thu hồi tối đa (ngôn ngữ văn học và dày) rất bền bỉ với các mô hình thu hồi dày đặc nghệ thuật hiện đại, trong khi cần ít nguồn tính toán hơn. Thêm nữa, chúng tôi cung cấp một đánh giá sâu về phương pháp thu hồi dày đặc trên thiết lập tài nguyên tính giới hạn, thứ gì đó thiếu trong văn học hiện thời.', 'bg': 'При простото отговаряне на въпроси с отворен домейн, плътното извличане се превръща в един от стандартните подходи за извличане на съответните пасажи за извличане на отговор. Наскоро гъстото извличане също постига най-съвременни резултати в мулти-хоп QA, където се изисква агрегиране на информация от множество парчета информация и разсъждения за тях. Въпреки успеха си, методите за събиране на плътни данни са изчислително интензивни и изискват множество графични устройства за обучение. В тази работа въвеждаме хибриден (лексикален и плътен) подход за извличане, който е силно конкурентен с най-съвременните модели за извличане на плътно, като същевременно изисква значително по-малко изчислителни ресурси. Освен това, ние предоставяме задълбочена оценка на методите на плътно извличане на ограничени настройки на изчислителните ресурси, нещо, което липсва в настоящата литература.', 'nl': "In het eenvoudige open-domein vragenantwoord (QA) is dichte retrieval uitgegroeid tot een van de standaardbenaderingen voor het ophalen van relevante passages om een antwoord te kunnen afleiden. Recent behaalde dichte retrieval ook state-of-the-art resultaten in multi-hop QA, waarbij het aggregeren van informatie uit meerdere stukjes informatie en redeneren daarover vereist is. Ondanks hun succes zijn dichte retrievalmethoden rekenintensief en vereisen meerdere GPU's om te trainen. In dit werk introduceren we een hybride (lexicale en dichte) retrieval benadering die sterk concurreert met de state-of-the-art dichte retrieval modellen, terwijl er aanzienlijk minder rekenkundige middelen nodig zijn. Daarnaast bieden we een diepgaande evaluatie van dichte retriefmethoden op beperkte computerinstellingen, iets wat ontbreekt in de huidige literatuur.", 'da': "I simpel open-domain spørgsmål besvarelse (QA) er tæt hentning blevet en af standardmetoderne til at hente de relevante passager til at udlede et svar. For nylig opnåede tæt hentning også state-of-the-art resultater i multi-hop QA, hvor aggregering af oplysninger fra flere stykker information og ræsonnement over dem er påkrævet. På trods af deres succes er tætte hentningsmetoder beregningsintensive, hvilket kræver flere GPU'er at træne. I dette arbejde introducerer vi en hybrid (leksikisk og tæt) hentningsmetode, der er yderst konkurrencedygtig med de avancerede tætte hentningsmodeller, samtidig med at der kræves betydeligt mindre beregningsmæssige ressourcer. Derudover giver vi en dybdegående evaluering af tætte hentningsmetoder på begrænsede beregningsmæssige ressourceindstillinger, noget der mangler i den nuværende litteratur.", 'hr': 'U jednostavnom odgovoru na pitanje otvorenog domena (QA), gusto povlačenje postalo je jedan od standardnih pristupa za povlačenje odgovarajućih prolaza za uvlačenje odgovora. Nedavno je gusto prikupljanje postiglo i rezultate umjetnosti u multihopskom QA-u, gdje je potrebno skupljanje informacija iz višestrukih dijelova informacija i razmišljanje o njima. Uprkos njihovom uspjehu, guste metode povlačenja su računalno intenzivne, zahtijevajući višestruke GPU-e da treniraju. U ovom poslu predstavljamo hibridni (leksički i gusti) pristup povlačenja koji je vrlo konkurentni s modelima gustih povlačenja države umjetnosti, dok je potrebno značajno manje računalnih resursa. Osim toga, pružamo duboku procjenu gustih metoda povlačenja na ograničene postavke računalnih resursa, nešto što nedostaje iz trenutne literature.', 'de': 'In der einfachen Open-Domain Question Responsing (QA) ist das dichte Retrieval zu einem der Standardansätze für das Abrufen relevanter Passagen geworden, um eine Antwort abzuleiten. Kürzlich erzielte das dichte Retrieval auch State-of-the-Art Ergebnisse in Multi-Hop QA, wo die Aggregation von Informationen aus mehreren Teilen von Informationen und deren Argumentation erforderlich ist. Trotz ihres Erfolgs sind dichte Retrieval-Methoden rechenintensiv, sodass mehrere GPUs trainiert werden müssen. In dieser Arbeit stellen wir einen hybriden (lexikalischen und dichten) Retrieval-Ansatz vor, der mit den neuesten Dense Retrieval-Modellen in hohem Maße wettbewerbsfähig ist und dabei wesentlich weniger Rechenressourcen benötigt. Darüber hinaus bieten wir eine eingehende Evaluation von dichten Retrievalmethoden auf begrenzten Rechenressourceneinstellungen, was in der aktuellen Literatur fehlt.', 'id': 'Dalam menjawab pertanyaan domain terbuka sederhana (QA), penemuan padat telah menjadi salah satu pendekatan standar untuk mendapatkan pasar-pasar relevan untuk menyimpulkan jawaban. Baru-baru ini, penemuan dense juga mencapai hasil terbaik dalam multi-hop QA, di mana aggregasi informasi dari beberapa bagian informasi dan alasan atas mereka diperlukan. Meskipun mereka berhasil, metode penemuan padat secara komputasi intens, membutuhkan banyak GPU untuk melatih. Dalam pekerjaan ini, kami memperkenalkan pendekatan pengumpulan hibrid yang sangat kompetitif dengan model pengumpulan tebal state-of-the-art, sementara membutuhkan sumber daya komputasi yang jauh lebih sedikit. Selain itu, kami menyediakan evaluasi mendalam dari metode penemuan padat pada pengaturan sumber daya komputasi terbatas, sesuatu yang hilang dari literatur saat ini.', 'ko': '단순 개방 영역 퀴즈(QA)에서 밀집 검색은 이미 관련 단락을 검색하여 답을 추정하는 표준적인 방법 중의 하나가 되었다.최근 밀집 검색은 멀티플렉스 QA에서도 가장 선진적인 성과를 거두었고 멀티플렉스 QA에서는 여러 정보 세션에서 정보를 모아 추리해야 한다.비록 그들이 성공을 거두었지만, 밀집 검색 방법은 대량의 계산이 필요하고, 여러 개의 GPU가 훈련을 필요로 한다.이 작업에서 우리는 혼합(어휘와 밀집) 검색 방법을 소개했는데 이것은 가장 선진적인 밀집 검색 모델과 강한 경쟁력을 가지며 더욱 적은 계산 자원을 필요로 한다.그 밖에 우리는 유한한 계산 자원 환경에서의 밀집 검색 방법을 깊이 있게 평가했는데 이것은 현재 문헌에서 부족한 것이다.', 'sw': 'Katika jibu la swali rahisi la ndani (QA), kurudishwa kwa kiasi kikubwa umekuwa moja ya njia za kawaida za kupata njia zinazohusika ili kupunguza jibu. Hivi karibuni, mapumziko makubwa pia yalipata matokeo ya sanaa yanayotokana na QA ya watu wengi, ambapo kuongeza taarifa kutoka katika vipande kadhaa vya habari na kujadiliana juu yao inahitaji. Pamoja na mafanikio yao, mbinu za kurejesha kwa kiasi kikubwa zinazidi kukusanyika, zinazohitaji GPUs mbalimbali kufundisha mafunzo. Katika kazi hii, tunaonyesha mbinu za kurudisha bikra (lexico na yenye uchungu) ambazo zinajitahidi sana na mifano yenye uchungu wa kurejesha sanaa, wakati tunahitaji rasilimali zisizo chini ya hisabati. Zaidi ya hayo, tunatoa tathmini za kina za njia za kupatikana kwa kiwango kikubwa juu ya mazingira madhubuti ya rasilimali, jambo ambalo limepotea kutoka fasihi ya sasa.', 'fa': 'در جواب سؤال باز دامنی ساده (QA) بازگیری dense به یکی از دسترسی استاندارد برای بازگیری مسیرهای مربوط به پاسخ آلوده شده است. اخیرا، بازیابی تند همچنین نتیجه\u200cهای موقعیت هنری به چند هپ QA رسیده است، جایی که اطلاعات را از قطعه\u200cهای چندین اطلاعات و منطقی بر آنها جمع می\u200cکنند نیاز دارد. با وجود موفقیت\u200cهایشان، روش\u200cهای بازیابی تند به صورت محاسبه\u200cهای زیادی هستند، که نیاز به چندین جی پی\u200cیوس برای آموزش آموزش می\u200cکنند. در این کار، ما یک دستور بازیابی هیبرید (زبان و داغ) را معرفی می\u200cکنیم که با مدل بازیابی داغ هنری بسیار مسابقه\u200cای است، در حالی که نیاز به منابع محاسباتی کمتر است. به اضافه، ما یک ارزیابی عمیق از روش بازیابی عمیق در مورد تنظیمات منابع محدودیت محدودیت، چیزی را که از ادبیات فعلی گم شده است، پیشنهاد می کنیم.', 'tr': 'Basit açık domuz sorusunda (QA) cevap bermek için yoğun alma, eşit bir cevap almak için önemli pasajları almak için standart yaklaşmalardan biri oldu. Soňky wagtlarda, ýigrimi almak isleýän sanat rezultatynyň köp-hop QA-nyň üstüne ýetip bardy, ol ýerde birnäçe bölümden informasiýa toplamak we olaryň üstüne düşünüşmek gerek. Hatlarynyň üstünliklerine rağmen, ýigrimi alma yöntemleri bilgisayar ýagdaýynda gaty göwni, birnäçe GPUlary trenlemek üçin gerek bolýar. Bu işde biz hybridleriň (leksik we ýigrenç) ýüze çykarma nusgasyny tanyşdyrýarys. Bu nusgasyň durumynda gaty ýakyn hasaplanç çeşmeleri bilen rekabet edilýän. Hemmäçe, häzirki edebiýatyndan ýok bir zat üçin ýigşirlik alma yöntemlerini çykarýarys.', 'af': "In eenvoudige open-domein vraag antwoord (QA), dens ontvanging het een van die standaard toegang geword om die relevante wagwoorde te ontvang om 'n antwoord in te bring. Onlangs, dense ontvanging het ook toestand-of-die-kuns-resultate in multi hop QA bereik, waar die samekoms van inligting van veelvuldige stukke inligting en redering oor hulle benodig is. Terwyl hulle sukses, die dense ontvangmetodes is rekenasielik intensief, wat veelvuldige GPUs nodig om te trein. In hierdie werk introduseer ons 'n hybrid (leksiese en dense) ontvang toegang wat baie kompetief is met die staat van die kuns dense ontvang modele, terwyl ons betekens minder rekenaar hulpbronne benodig. In addition, we provide an in-depth evaluation of dens retrieval methods on limited computational resource settings, something that is missing from the current literature.", 'sq': 'In simple open-domain question answering (QA), dense retrieval has become one of the standard approaches for retrieving the relevant passages to infer an answer.  Recently, dense retrieval also achieved state-of-the-art results in multi-hop QA, where aggregating information from multiple pieces of information and reasoning over them is required. Megjithë suksesin e tyre, metodat e dendura të marrjes janë kompjuterikisht intensive, duke kërkuar trajnimin e GPU-ve të shumta. Në këtë punë, ne paraqesim një qasje hybride (lexike dhe të dendur) që është shumë konkurruese me modelet më të larta të dendura të tërheqjes, duke kërkuar burime më pak kompjuterike. Përveç kësaj, ne ofrojmë një vlerësim të thellë të metodave të zhvillimit të dendura në rregullimet e kufizuara të burimeve llogaritare, diçka që mungon nga literatura aktuale.', 'am': 'በቀላል ክፍት ዶሜን ጥያቄ (QA) መልስ ላይ የተጠቃሚ ማሰናከል የግንኙነት መግቢያ መግለጫ ለመያነስ አንዲቱ ደረጃ ሆነዋል፡፡ በቅርብ ዘመን የጥልቅ ማስታወቂያ የ-አርእስት ግንኙነት አግኝቷል፡፡ ፍላጎታቸውን ምንም እንኳ፣ ጥልቅ የመስጠት ማድረግ አካባቢ ነው፡፡ በዚህ ሥራ፣ የልኬክሲካዊ እና ጥልቅ የሀገሪቱ አካባቢ አካባቢ እናሳውቃለን፡፡ በተጨማሪም፣ የአሁኑ የጽሑፍ ብሔራዊ ቋንቋ ላይ ያልታወቀ የጥልቅ ምርጫዎችን እናሳውቃለን፡፡', 'hy': 'Պարզ բաց տիեզերքի հարցերին պատասխանելու դեպքում խտությունը դարձավ պատասխանը ստանդարտ մոտեցումներից մեկը: Վերջերս խիստ վերականգնումը հասավ նաև ամենահետաքրքիր արդյունքներ բազմահումների QA-ում, որտեղ անհրաժեշտ է համախմբել տեղեկատվությունը բազմաթիվ տեղեկատվության կտորներից և մտածել դրանց մասին: Չնայած նրանց հաջողությանը, խիստ վերականգնման մեթոդները հաշվարկների առումով ինտենսիվ են, որոնք պահանջում են բազմաթիվ GPU-ներ վարժեցնելու համար: Այս աշխատանքի ընթացքում մենք ներկայացնում ենք հիբրիդ (լեքսիկական և խիստ) վերադարձման մոտեցում, որը շատ մրցակցում է ամենաբարձր խիստ վերադարձման մոդելների հետ, միաժամանակ պահանջում է ավելի քիչ հաշվարկների ռեսուրսներ: Ավելին, մենք ներկայիս գրականությունից բացակայում ենք խիստ վերադարձման մեթոդներ սահմանափակ հաշվարկների ռեսուրսների սահմանափակումների վրա:', 'az': 'Basit açıq domena sualına cavab vermək (QA) içində sıxıntılı almaq, cavab vermək üçün məqsədil yolları almaq üçün standart tərzlərindən biri oldu. Son zamanlarda, sıxıntılı alış həmçin in çox-hop QA sonuçlarına bənzər məlumatlardan məlumatları toplamaq və onlardan mübahisə etmək lazımdır. Onların başarısızlığına rağmen, yox alma metodları hesaplamaq üçün çoxlu GPU təhsil etmək istəyirlər. Bu işdə, biz, çox az hesap kaynaqlarına ehtiyacı olan hibrid (leksik və yox) alma metodlarını tanıyırıq. Əksinə, biz müəyyən edilmiş hesaplamalı kaynaqlar qurmaqlarında sıxıntılı alma metodlarının derinliklə değerlendirməsini təmin edirik. Şimdiki dəlilikdən qeyb olan bir şey.', 'ca': "En resposta a preguntes de domini obert (QA), la recuperació densa s'ha convertit en un dels enfocaments estàndard per recuperar les passatges pertinents per a deduir una resposta. Recentment, la recerca densa també ha aconseguit resultats més avançats en QA multihops, on es requereix agregar informació de múltiples peces d'informació i raonar sobre elles. Malgrat el seu èxit, els mètodes densos de recuperació són computacionalment intensivs, i requereixen que múltiples GPU entrenen. En aquesta feina, introduïm un enfocament híbrid de recuperació (lèxic i dens) que és altament competitiu amb els models d'recuperació densa d'última generació, mentre requerem molt menys recursos computacionals. A més, proporcionem una evaluació profunda dels mètodes de recuperació densa en configuracions limitades de recursos computacionals, una cosa que falta de la literatura actual.", 'bs': 'U jednostavnom odgovoru na pitanje otvorenog domena (QA), gusto povlačenje postalo je jedan od standardnih pristupa za povlačenje odgovarajućih prolaza za uvlačenje odgovora. Nedavno je gusto prikupljanje postiglo i rezultate umjetnosti u multihopskom QA-u, gdje je potrebno skupljanje informacija iz višestrukih dijelova informacija i razmišljanje o njima. Uprkos njihovom uspjehu, guste metode povlačenja su kompjuterski intenzivne, zahtevajući više GPU-a da treniraju. U ovom poslu predstavljamo hibridni (leksički i gusti) pristup povlačenja koji je vrlo konkurentni sa modelima države umjetnosti gustih povlačenja, dok je potrebno značajno manje računalnih resursa. Osim toga, pružamo duboku procjenu gustih metoda povlačenja na ograničene postavke računalnih resursa, nešto što nedostaje iz trenutne literature.', 'bn': 'In simple open-domain question answering (QA), dense retrieval has become one of the standard approaches for retrieving the relevant passages to infer an answer.  সম্প্রতি অনেক তথ্যের বিভিন্ন অংশ থেকে তথ্য গ্রেফতার করা এবং তাদের বিষয়ে বিতর্ক করা দরকার। তাদের সফলতা সত্ত্বেও গভীর পুনরুদ্ধারের পদ্ধতি গণনাভাবে বেশী শক্তিশালী, যাদের প্রশিক্ষণের জন্য বেশ কিছু জিপিউ এই কাজে আমরা একটি হাইব্রিড (লেক্সিক্যাল এবং গভীর) পুনরুদ্ধার প্রতিক্রিয়ার পদ্ধতি পরিচালনা করেছি যা রাষ্ট্র-শিল্পের গভীর গভীর পুনরুদ্ধার মডেলের সা তাছাড়াও, আমরা গভীর গভীরভাবে গণমূল্য পুনরুদ্ধার পদ্ধতির মূল্য প্রদান করি, যা বর্তমান সাহিত্য থেকে নিখোঁজ।', 'cs': 'V jednoduchém otevřeném odpovědi na otázky (QA) se husté vyhledávání stalo jedním ze standardních přístupů pro získání relevantních pasáží k odvození odpovědi. Nedávno dosáhlo hustého vyhledávání také nejmodernějších výsledků v multi-hop QA, kde je nutné agregovat informace z více kusů informací a uvažovat nad nimi. Navzdory svému úspěchu jsou metody hustého vyhledávání výpočetně náročné a vyžadují trénink více GPU. V této práci představujeme hybridní (lexikální a hustý) retrieval přístup, který je vysoce konkurenční s nejmodernějšími hustými retrieval modely, přičemž vyžaduje podstatně méně výpočetních zdrojů. Dále poskytujeme hloubkové vyhodnocení metod hustého vyhledávání na omezeném nastavení výpočetních zdrojů, což v současné literatuře chybí.', 'et': 'Lihtsa avatud domeeni küsimustele vastamise (QA) puhul on tihedast tagasivõtmisest saanud üks standardseid lähenemisviise vastavate lõikude leidmiseks vastuse järeldamiseks. Hiljuti saavutas tihe tagasivõtmine kaasaegseid tulemusi ka mitme hüppe kvaliteedi tagamisel, kus on vaja koondada teavet mitmest teabest ja nende üle arutleda. Hoolimata edust on tihedad tagasivõtmismeetodid arvutuslikult intensiivsed, nõudes treenimiseks mitut GPU-d. Käesolevas töös tutvustame hübriidset (leksikaalset ja tihedat) taastamismeetodit, mis on kõrgelt konkurentsivõimeline kaasaegsete tihedate taastamismeetoditega, nõudes samas oluliselt vähem arvutusressursse. Lisaks pakume põhjalikku hindamist tihedate tagasivõtmismeetodite kohta piiratud arvutusressursside seadetel, mis praegusest kirjandusest puudub.', 'fi': 'Yksinkertaisessa avoimen verkkotunnuksen kysymysvastauksessa (QA) tiheästä noutamisesta on tullut yksi tavallisista tavoista hakea asiaankuuluvia kohtia vastauksen päättelyyn. Hiljattain tiheällä haulla saavutettiin myös huipputason tuloksia multi-hop laadunvarmistuksessa, jossa tarvitaan tiedon kokoamista useista tiedoista ja niiden järkeilyä. Menestyksestään huolimatta tiheät hakumenetelmät ovat laskennallisesti intensiivisiä ja vaativat useita näytönohjaimia harjoitteluun. Tässä työssä esitellään hybridi (lexikaalinen ja tiheä) haun lähestymistapa, joka on erittäin kilpailukykyinen uusimpien tiheähaun mallien kanssa, mutta vaatii huomattavasti vähemmän laskennallisia resursseja. Lisäksi tarjoamme perusteellisen arvioinnin tiheän haun menetelmistä rajallisissa laskennallisissa resurssiasetuksissa, mikä puuttuu nykyisestä kirjallisuudesta.', 'ha': "In da tambayar sakan wanda aka buɗe kwamfyuta (QA), motsar masu nau'i ya kasance wani matsayi na daidaita wa ku sami hanya masu hushi dõmin ya ƙara jawab. A yanzu, musammi masu hushi na sami matsayin-kunna na sami matsayin QA, a lokacin da za'a ƙara information daga fili masu yawa da yin husũma a kansu. Babu da cin nasara, hanyoyin retriewa masu nau'i ne mai ƙidãya, kuma suna da wasu GPU masu buƙata dõmin su karanta. Daga wannan aikin, Muke ƙara wata hanyoyi na cewa na cewa (leksi da sauri) wanda ke ƙaranci da muhimmi da misãlai masu motsarwa na-kungiya, kuma Munã tambayar su masu ƙaranci na lissafi. Ina ƙara, Munã ƙayyade tunkuɗe masu iya motsarwa masu bakin filinaiki da ke ƙayyade, da wani abu wanda ba'a sava daga littafan yanzu.", 'he': 'בתשובה לשאלות פתוחות פשוטה (QA), השיגור צפוף הפך לאחד מהגישות הסטנדרטיות להשיג את המעברים הרלוונטיים כדי להוציא תשובה. לאחרונה, השיגה צפופה השיגה גם תוצאות חדשות במיוחד-הופ QA, היכן שדרוש לאסוף מידע ממספר פיסות מידע והגיון עליהם. למרות ההצלחה שלהם, שיטות השיגור צפופויות הן חישובי אינטנסיביות, דורשות GPU מרובים להתאמן. בעבודה הזאת, אנו מציגים גישה היברידית (לקסית וצפויה) שיותרת במיוחד עם הדוגמנים הצפויים ביותר של השיגור, בזמן שדורשים משאבים מחשביים פחות משמעותיים. בנוסף, אנחנו מספקים עריכה עמוקה של שיטות השיגה צפופופות על סדרות משאבים מחשביים מוגבלות, משהו חסר מהספרות הנוכחית.', 'sk': 'Pri preprostem odprtem odgovoru na vprašanja (QA) je gosto iskanje postal eden od standardnih pristopov za iskanje ustreznih odlomkov za sklepanje odgovora. V zadnjem času je gosto iskanje doseglo tudi najsodobnejše rezultate v multi-hop QA, kjer je potrebno združevanje informacij iz več informacij in razmišljanje o njih. Kljub svojemu uspehu so metode gostega pridobivanja računalniško intenzivne, zato so za usposabljanje potrebne več grafičnih ploščic. V tem delu predstavljamo hibridni (leksikalni in gosti) pristop pridobivanja, ki je zelo konkurenčen z najsodobnejšimi modeli gostih pridobivanja, hkrati pa zahteva bistveno manj računalniških virov. Poleg tega ponujamo poglobljeno oceno metod gostega iskanja na omejenih nastavitvah računalniških virov, kar manjka v trenutni literaturi.', 'jv': 'Nang sempling open-domain question responsing Sadurungka, padha ingkang dipunangé kuwi nggawe stad-of-the-arts gambar kelas multi-hol qA, ndheke kuwi ngregawe informasi sithik karo sistem sing ngengatahane sakjane sakjane Ing berbudhakan langgar, dadi yöwek ngerasahan kelas komputer, njuk dianggap si nggawe Nang gunggo iki, kita nambah akeh sedhaya mrogram (Leksik lan Deng-ingkang matang) dadi nyong langgar sampeyan kang kesempatan karo state-of-the-arts Deng-sampeyan intangin model, sampeyan akeh iso nguasai macem komputasi tambah. Mungkin, awak dhéwé nyengé nggawe deep-jewisan kuwi tindakan pangan langgar-jewisan ngono kalem-jewisan sing perusahaan mulasar komputer, sing ora ono sing paling dhéwé basa sing nêmên.', 'bo': 'སྤྱིར་བཏང་བའི་ཁ་ཕྱེད་པའི་དྲི་ཞིག་གིས་ལན་གསལ་པ(QA)ནང་དུ་density retrieval དེ་གཟའ་འཁོར་སྐྱོད་ཀྱི་ཚད་འཛིན་གྱི་གནད ཉེ་ཆར་བར་དུ། ཉམས་ཆེ་བསླངས་ཀྱིས་སྣང་བའི་གནས་སྟངས་མང་ཙམ་འབྱུང་བ་ཡིན་པ། དེ་ཚོའི་གྲུབ་འབྲས་བ་ཡིན་ཀྱང་། dense retrieval methods are computationally intensive, requiring a multiple GPUs to train. In this work, we introduce a hybrid (lexical and dense) retrieval approach that is highly competitive with the state-of-the-art dense retrieval models, while requiring a substantially less computational resources. Additionally, we provide a depth evaluation of dense retrieval methods on limited computational resources settings, something that is missing from the current literature.'}
{'en': 'Learning to Rank in the Age of Muppets : EffectivenessEfficiency Tradeoffs in Multi-Stage Ranking', 'pt': 'Aprendendo a classificar na Era dos Muppets: Compensações Efetividade-Eficiência na Classificação em Vários Estágios', 'fr': "Apprendre à se classer à l'ère des Muppets\xa0: compromis efficacité-efficacité dans le classement en plusieurs étapes", 'ar': 'تعلم الترتيب في عصر الدمى المتحركة: مقايضات الفعالية والكفاءة في الترتيب متعدد المراحل', 'es': 'Aprender a clasificarse en la era de los Muppets: compensaciones entre eficacia y eficiencia en la clasificación de varias etapas', 'zh': '在木偶时学排名:多阶段排名中有效性-效率权衡', 'ja': 'マペットの時代にランク付けを学ぶ：マルチステージランキングの有効性と効率的なトレードオフ', 'hi': 'Muppets की उम्र में रैंक करने के लिए सीखना: बहु-चरण रैंकिंग में प्रभावशीलता-दक्षता Tradeoffs', 'ru': 'Обучение ранжированию в век маппетов: Эффективность-эффективность компромиссов в многоступенчатом рейтинге', 'ga': 'Foghlaim conas rangú a dhéanamh in Aois na Muppets: Comhbhabhtáil Éifeachtúlachta-Éifeachtúlachta i Rangú Ilchéime', 'ka': 'მოპეტების დროს შესწავლობა: ეფექტიფიკაცია-ეფექტიური ტრადიოფიკაცია მრავალური სტაციაში', 'hu': 'A Muppetek korában rangsorolni tanulni: hatékonyság-hatékonyság kereskedelem a többszakaszos rangsorolásban', 'it': "Imparare a classificarsi nell'era dei Muppets: scambi di efficacia-efficienza nel ranking multi-stage", 'mk': 'Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking', 'lt': 'Mokymasis klasifikuoti muppets amžiuje: efektyvumo ir veiksmingumo prekybiniai sandoriai daugiapakopiame klasifikavimo intervale', 'el': 'Μάθηση να κατατάσσεται στην εποχή των Μάπετ: Ανταλλαγές αποτελεσματικότητας-αποδοτικότητας στην πολυσταδιακή κατάταξη', 'ms': 'Belajar untuk Rangkaian pada Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking', 'mt': 'Tagħlim sal-Firxa fl-Età tal-Muppets: Negozjati dwar l-Effiċjenza u l-Effiċjenza f’Firxa Multi-Stadji', 'mn': 'Мөргөлдөр үеийн түвшинд суралцах: олон түвшинд үр дүнтэй, үр дүнтэй салбар', 'kk': 'Мупеттердің кеңістігін оқыту: Көптеген кеңістіктердің эффективнік және эффективнік көлемі традеофтары', 'ml': 'മുപ്പുട്ടുകളുടെ വയസ്സില്\u200d റാങ്കിലേക്ക് പഠിക്കുന്നു: പല സ്റ്റേജ് റാങ്ങിങില്\u200d പ്രഭാവം- ഫാക്ഷന്\u200dസി ട്രായ', 'sr': 'Naučenje pokreta u dobu muppeta: Efektivnost-efikasnost trgovina u višestrukom pokretanju', 'ro': 'Învățarea de a clasa în epoca muppets: schimburi eficiență-eficiență în clasamentul multi-etape', 'pl': 'Nauka rankingu w erze muppetów: efektywność-efektywność w rankingu wieloetapowym', 'no': 'Læring til å gå i løpet i løpet av muppettar: Effektiv-effektiv-tredeoff i fleire stader', 'si': 'මුපෙට්ස් වයසේ රැන්ඩ් වලට ඉගෙන ගන්න', 'so': 'Waxbarashada jardiinada ee da’da tirada: Effective-Effective Traditions in aad leedahay safarka kala duduwan', 'ta': 'குழுக்களின் வயதில் வரிசையில் கற்றுக் கொண்டிருக்கிறது: விளைவு- விளைவு பயணிகள் பல- நிலை வரிசையில்', 'ur': 'موپٹوں کی عمر میں Rank کی تعلیم کرتا ہے: بہت سی سٹیج Ranking میں اثرات اور فعالیت تردیوف', 'sv': 'Att lära sig ranka i Muppets ålder: Effektivitet-effektivitet handel i flerstegs ranking', 'uz': 'Name', 'vi': 'Học bài được xếp hạng trong thời kỳ diễn viên: Hiệu quả hiệu quả:', 'bg': 'Научаване да се класира в епохата на мъпетите: компромиси за ефективност и ефективност в многоетапното класиране', 'de': 'Lernen, im Zeitalter der Muppets zu rangieren: Effektivität-Effizienz-Tradeoffs im mehrstufigen Ranking', 'id': 'Belajar untuk menjangkau di Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking', 'nl': 'Leren rangschikken in het tijdperk van Muppets: Effectiviteit-efficiëntie tradeoffs in Multi-Stage Ranking', 'da': 'At lære at rangere i Muppets alder: Effektivitet-effektivitet handler i Multi-Stage Ranking', 'hr': 'Naučenje pokreta u dobu muppeta: učinkovitosti i učinkovitosti u višestrukom pokretanju', 'fa': 'یاد گرفتن به نقطه در سن موپت: فعالیت و فعالیت تردیوف در نقطه\u200cهای زیادی', 'sw': 'Kujifunza Kusini katika umri wa Vikundi: Maendeleo ya Effective-Effective in Range Multi-Range', 'ko': '인형시대 학습 랭킹: 다단계 랭킹에서의 효율과 효율 평가', 'am': 'በጨዋታው ቁጥር ውስጥ ማር: Effective-Effective Tradeos in Multi-Stage Ranking', 'hy': 'Սովորել դասակարգել կենդանիների տարիքում. արդյունավետություն-արդյունավետություն', 'az': 'Muppetl…ôrin yaŇüńĪndakńĪ d…ôyiŇüiklik √∂yr…ônm…ôk: √ßoxlu d…ôyiŇüiklik d…ôyiŇüiklikd…ô effektiv-effektiv Tradeof', 'tr': 'Golub Gadysynda Ködleme öwrenme', 'bs': 'Naučenje pokreta u dobu muppeta: Efektivnost-učinkovitosti u višestrukom pokretanju', 'bn': 'অনেক স্টেজ রেঙ্কিং-এ কার্যক্রম-প্রভাবিক ট্রেফ', 'af': 'Onderleer na Rank in die Age van Muppets: Effektiviteit-Effektiviteit Tradeof in Multi-Stage Ranking', 'et': 'Muppetide vanuses järjestamise õppimine: efektiivsuse ja efektiivsuse kompromiss mitmeastmelises järjestuses', 'sq': 'Mësimi për të renditur në moshën e muppetëve: tregtarët e efektshmërisë-efektshmërisë në renditjen e shumëfazave', 'cs': 'Naučení se hodnotit ve věku muppetů: účinnost-efektivita obchody v vícefázovém žebříčku', 'fi': 'Oppiminen sijoittumaan muppettien iässä: Tehokkuus-tehokkuuskompromisseja monivaiheisessa rankingissa', 'ca': "Aprendre a classificar-se en l'edat de les muppets: Comercials d'eficiència-eficiència en classificació multietapa", 'jv': 'Gjer-guru kelalen kanggo kelalen winih', 'ha': 'KCharselect unicode block name', 'he': 'Learning to Rank in the Age of Muppets: Effectiveness-Efficiency Tradeoffs in Multi-Stage Ranking', 'sk': 'Učenje uvrstitve v starosti muppetov: kompromisi učinkovitosti in učinkovitosti v večstopenjskem uvrstitvi', 'bo': 'སྙན་ངག་གྱི་དུས་ཚོད་ལྟར་ཤེས་སྦྱར་བ་དང་།'}
{'en': 'It is well known that rerankers built on pretrained transformer models such as BERT have dramatically improved retrieval effectiveness in many tasks. However, these gains have come at substantial costs in terms of efficiency, as noted by many researchers. In this work, we show that it is possible to retain the benefits of transformer-based rerankers in a multi-stage reranking pipeline by first using feature-based learning-to-rank techniques to reduce the number of candidate documents under consideration without adversely affecting their quality in terms of recall. Applied to the MS MARCO passage and document ranking tasks, we are able to achieve the same level of effectiveness, but with up to 18 increase in efficiency. Furthermore, our techniques are orthogonal to other methods focused on accelerating transformer inference, and thus can be combined for even greater efficiency gains. A higher-level message from our work is that, even though pretrained transformers dominate the modern IR landscape, there are still important roles for traditional LTR techniques, and that we should not forget history.', 'es': 'Es bien sabido que los reordenadores basados en modelos de transformadores previamente entrenados, como BERT, han mejorado drásticamente la eficacia de recuperación en muchas tareas. Sin embargo, estas ganancias han tenido un costo sustancial en términos de eficiencia, como han señalado muchos investigadores. En este trabajo, mostramos que es posible conservar los beneficios de los reclasificadores basados en transformadores en una canalización de reclasificación de varias etapas mediante el uso primero de técnicas de aprendizaje de clasificación basadas en funciones para reducir el número de documentos candidatos en consideración sin afectar negativamente su calidad en términos de retirada. Aplicado a las tareas de clasificación de documentos y paso de MS MARCO, podemos lograr el mismo nivel de eficacia, pero con un aumento de hasta 18 en la eficiencia. Además, nuestras técnicas son ortogonales a otros métodos centrados en acelerar la inferencia del transformador y, por lo tanto, se pueden combinar para obtener ganancias de eficiencia aún mayores. Un mensaje de alto nivel de nuestro trabajo es que, a pesar de que los transformadores preentrenados dominan el panorama moderno de IR, todavía hay funciones importantes para las técnicas LTR «tradicionales» y que no debemos olvidar la historia.', 'fr': "Il est bien connu que les reclasseurs basés sur des modèles de transformateurs préentraînés tels que BERT ont considérablement amélioré l'efficacité de la récupération dans de nombreuses tâches. Cependant, ces gains se sont traduits par des coûts substantiels en termes d'efficacité, comme l'ont noté de nombreux chercheurs. Dans ce travail, nous montrons qu'il est possible de conserver les avantages des reclassements basés sur des transformateurs dans un pipeline de reclassement à plusieurs étapes en utilisant d'abord des techniques d'apprentissage au classement basées sur les caractéristiques afin de réduire le nombre de documents candidats considérés sans affecter leur qualité en termes de rappel. Appliqués aux tâches de passage et de classement des documents MS MARCO, nous sommes en mesure d'atteindre le même niveau d'efficacité, mais avec une augmentation de l'efficacité allant jusqu'à 18\xa0%. De plus, nos techniques sont orthogonales à d'autres méthodes axées sur l'accélération de l'inférence des transformateurs, et peuvent donc être combinées pour des gains d'efficacité encore plus importants. Un message de plus haut niveau de notre travail est que, même si les transformateurs préentraînés dominent le paysage IR moderne, les techniques LTR «\xa0traditionnelles\xa0» jouent toujours un rôle important et que nous ne devons pas oublier l'histoire.", 'ar': 'من المعروف أن أجهزة إعادة التصنيف المبنية على نماذج المحولات سابقة التدريب مثل BERT قد حسنت بشكل كبير فعالية الاسترجاع في العديد من المهام. ومع ذلك ، فقد جاءت هذه المكاسب بتكاليف كبيرة من حيث الكفاءة ، كما لاحظ العديد من الباحثين. في هذا العمل ، نوضح أنه من الممكن الاحتفاظ بفوائد أجهزة إعادة التوزيع القائمة على المحولات في خط أنابيب إعادة التوزيع متعدد المراحل من خلال استخدام تقنيات التعلم إلى التصنيف القائمة على الميزات أولاً لتقليل عدد المستندات المرشحة قيد الدراسة دون التأثير سلبًا جودتها من حيث الاسترجاع. عند تطبيقنا على مهام ترتيب وتصنيف المستندات من MS MARCO ، فإننا قادرون على تحقيق نفس المستوى من الفعالية ، ولكن مع زيادة تصل إلى 18 في الكفاءة. علاوة على ذلك ، فإن تقنياتنا متعامدة مع الطرق الأخرى التي تركز على تسريع استدلال المحولات ، وبالتالي يمكن دمجها لتحقيق مكاسب أكبر في الكفاءة. رسالة عالية المستوى من عملنا هي أنه على الرغم من أن المحولات سابقة التدريب تهيمن على مشهد الأشعة تحت الحمراء الحديث ، فلا تزال هناك أدوار مهمة لتقنيات LTR "التقليدية" ، ويجب ألا ننسى التاريخ.', 'ja': 'BERTのような事前訓練された変圧器モデルに構築されたリランカーは、多くのタスクにおける回収の有効性を劇的に向上させたことは周知である。 しかしながら、多くの研究者が指摘しているように、これらの利得は効率の観点から実質的なコストをかけて得られている。 本研究では、まず特徴ベースの学習からランク付けまでの技術を用いて、リコールの面で品質に悪影響を与えることなく、検討中の候補文書の数を減らすことで、多段階のリランキングパイプラインにおける変圧器ベースのリランカーの利点を保持することが可能であることを示した。 MS MARCOのパッセージとドキュメントランキングのタスクに適用すると、同じレベルの有効性を達成できますが、最大18効率が向上します。 さらに、当社の技術は変圧器推論の加速に焦点を当てた他の方法と直交しているため、より大きな効率向上のために組み合わせることができる。 私たちの仕事からのより高いレベルのメッセージは、事前に訓練された変圧器が現代のIR環境を支配しているにもかかわらず、「伝統的な」LTRテクニックには依然として重要な役割があり、歴史を忘れてはならないということです。', 'pt': 'É bem conhecido que os reclassificadores construídos em modelos de transformadores pré-treinados, como o BERT, melhoraram drasticamente a eficácia da recuperação em muitas tarefas. No entanto, esses ganhos tiveram custos substanciais em termos de eficiência, como observado por muitos pesquisadores. Neste trabalho, mostramos que é possível reter os benefícios dos reclassificadores baseados em transformadores em um pipeline de reclassificação de vários estágios usando primeiro técnicas de aprendizado para classificação baseadas em recursos para reduzir o número de documentos candidatos em consideração sem afetar adversamente sua qualidade em termos de recordação. Aplicado às tarefas de passagem e classificação de documentos do MS MARCO, conseguimos atingir o mesmo nível de eficácia, mas com até 18 aumentos de eficiência. Além disso, nossas técnicas são ortogonais a outros métodos focados em acelerar a inferência de transformadores e, portanto, podem ser combinadas para ganhos de eficiência ainda maiores. Uma mensagem de alto nível de nosso trabalho é que, embora os transformadores pré-treinados dominem o cenário moderno de IR, ainda existem papéis importantes para as técnicas LTR “tradicionais” e que não devemos esquecer a história.', 'hi': 'यह अच्छी तरह से ज्ञात है कि BERT जैसे पूर्वप्रशिक्षित ट्रांसफॉर्मर मॉडल पर निर्मित rerankers नाटकीय रूप से कई कार्यों में पुनर्प्राप्ति प्रभावशीलता में सुधार किया है। हालांकि, ये लाभ दक्षता के मामले में पर्याप्त लागत पर आए हैं, जैसा कि कई शोधकर्ताओं द्वारा उल्लेख किया गया है। इस काम में, हम दिखाते हैं कि एक बहु-चरण रीरैंकिंग पाइपलाइन में ट्रांसफॉर्मर-आधारित रीरैंकर्स के लाभों को बनाए रखना संभव है, पहले सुविधा-आधारित सीखने-से-रैंक तकनीकों का उपयोग करके, ताकि याद करने के मामले में उनकी गुणवत्ता को प्रतिकूल रूप से प्रभावित किए बिना विचाराधीन उम्मीदवार दस्तावेजों की संख्या को कम किया जा सके। एमएस मार्को मार्ग और दस्तावेज़ रैंकिंग कार्यों पर लागू, हम प्रभावशीलता के समान स्तर को प्राप्त करने में सक्षम हैं, लेकिन दक्षता में 18 तक की वृद्धि के साथ। इसके अलावा, हमारी तकनीकें ट्रांसफॉर्मर अनुमान को तेज करने पर केंद्रित अन्य तरीकों के लिए ऑर्थोगोनल हैं, और इस प्रकार इसे और भी अधिक दक्षता लाभ के लिए जोड़ा जा सकता है। हमारे काम से एक उच्च स्तरीय संदेश यह है कि, भले ही पूर्वप्रशिक्षित ट्रांसफार्मर आधुनिक आईआर परिदृश्य पर हावी हैं, फिर भी "पारंपरिक" एलटीआर तकनीकों के लिए महत्वपूर्ण भूमिकाएं हैं, और हमें इतिहास को नहीं भूलना चाहिए।', 'zh': '众所周知,基于预练之变压器(如BERT)构之重排名器大大提高于众务之中效率。 然如众人所指,益效率巨贾。 吾明先用学术排名以省方文档之数,而不害于召召,而重排名器于多端。 宜用MS MARCO道文档名,吾能同其有效性,而效率至18。 此外,吾术与他专于速变压器推理之法正交,故可以合而益大效率。 吾事更高层次者,虽习于预教变压器占主导地位于今红外,而旧法LTR术犹有要用,不宜忘之。', 'ru': 'Хорошо известно, что реранкеры, построенные на предварительно подготовленных моделях трансформаторов, таких как BERT, значительно повысили эффективность поиска во многих задачах. Вместе с тем, как отмечали многие исследователи, эти достижения сопряжены со значительными затратами с точки зрения эффективности. В этой работе мы показываем, что можно сохранить преимущества реранкеров на основе трансформаторов в многоступенчатом пере ранжировании, сначала используя функциональные методы обучения ранжированию, чтобы уменьшить количество рассматриваемых документов-кандидатов без негативного влияния на их качество с точки зрения отзыва. Применительно к задачам прохода и ранжирования документов MS MARCO, мы можем достичь такого же уровня эффективности, но с увеличением эффективности до 18. Кроме того, наши методы ортогональны другим методам, ориентированным на ускорение вывода трансформатора, и, таким образом, могут быть объединены для еще большего повышения эффективности. Послание более высокого уровня из нашей работы заключается в том, что, хотя предварительно обученные трансформаторы доминируют в современном ИК-ландшафте, все еще существуют важные роли для «традиционных» методик LTR, и мы не должны забывать историю.', 'ga': 'Is eol go maith go bhfuil feabhas mór tagtha ar éifeachtacht aisghabhála i gcuid mhór tascanna ag athrangaithe a tógadh ar mhúnlaí claochladáin réamhoilte ar nós BERT. Mar sin féin, tháinig costais shuntasacha ar na gnóthachain seo i dtéarmaí éifeachtúlachta, mar a thug go leor taighdeoirí faoi deara. San obair seo, léirímid gur féidir na tairbhí a bhaineann le hathrangaithe atá bunaithe ar chlaochladán a choinneáil i bpíblíne athrangaithe ilchéime trí theicnící foghlama chun céim a dhéanamh bunaithe ar ghné a úsáid ar dtús chun líon na ndoiciméad iarrthóra atá á mbreithniú a laghdú gan dochar a dhéanamh. a gcáilíocht i dtéarmaí athghairme. I bhfeidhm ar an sliocht MS MARCO agus tascanna rangú doiciméad, táimid in ann a bhaint amach ar an leibhéal céanna éifeachtúlachta, ach le suas le 18 méadú ar éifeachtúlacht. Ina theannta sin, tá ár dteicnící orthogonal le modhanna eile atá dírithe ar thátal claochladán a luathú, agus mar sin is féidir iad a chomhcheangal le haghaidh gnóthachain éifeachtúlachta níos mó fós. Teachtaireacht ardleibhéil ónár gcuid oibre is ea, cé go bhfuil claochladáin réamhoilte chun tosaigh sa tírdhreach IR nua-aimseartha, go bhfuil róil thábhachtacha fós ag teicnící LTR “traidisiúnta”, agus nár cheart dúinn dearmad a dhéanamh ar an stair.', 'hu': 'K철ztudott, hogy az el흷k챕sz챠tett transzform찼tormodellekre 챕p체l흷 첬jrat철lt흷k, mint p챕ld찼ul a BERT, jelent흷sen jav챠tott찼k a visszah챠v찼s hat챕konys찼g찼t sz찼mos feladatban. Ezek a nyeres챕gek azonban a hat챕konys찼g szempontj찼b처l jelent흷s k철lts챕gekkel j찼rtak, amint azt sz찼mos kutat처 megjegyezte. Ebben a munk찼ban megmutatjuk, hogy a transzform찼tor alap첬 첬jrat철lt흷k el흷nyeit egy t철bbl챕pcs흷s 첬jrat철lt챕si csatorn찼ban lehets챕ges meg흷rizni, el흷sz철r funkci처alap첬 tanul찼si technik찼k alkalmaz찼s찼val a vizsg찼lt jel철lt dokumentumok sz찼m찼nak cs철kkent챕s챕re an챕lk체l, hogy h찼tr찼nyosan befoly찼soln찼 a visszah챠v찼s min흷s챕g챕t. Az MS MARCO 찼tmeneti 챕s dokumentumok rangsorol찼si feladataira alkalmazva ugyanolyan szint킥 hat챕konys찼got tudunk el챕rni, de ak찼r 18 hat챕konys찼gn철veked챕ssel is. Tov찼bb찼 technik찼ink ortogon찼lisak m찼s, a transzform찼tor k철vetkeztet챕s챕nek felgyors챠t찼s찼ra 철sszpontos챠t처 m처dszerekkel szemben, 챕s 챠gy kombin찼lhat처k a m챕g nagyobb hat챕konys찼gn철veked챕s 챕rdek챕ben. Munk찼nk egyik magasabb szint킥 체zenete, hogy b찼r az el흷k챕pzett transzform찼torok uralj찼k a modern infrav철r철s t찼jat, m챕g mindig fontos szerepek vannak a "hagyom찼nyos" LTR technik찼knak, 챕s nem szabad elfelejten체nk a t철rt챕nelmet.', 'ka': 'ძალიან უცნობიერია, რომ რერენქრენქტები, როგორც BERT-ის მოდელზე დააყენებული ტრანფორმეტრის მოდელზე, დირამატურად უფრო მეტადებულია წარმოიქმნა ეფექტიკური მაგრამ, ეს წარმატები იყო ძალიან მნიშვნელოვანი გამოყენება ეფექტიურობის შემთხვევაში, როგორც ბევრად მსგავსი მსგავსი მსგავსი. ამ სამუშაოში ჩვენ ჩვენ აჩვენებთ, რომ შესაძლებელია გადარტვირუმენტების რერენქრენტების გამოსახულების გამოსახულებლად მრავალ სეტაციის რერენქრების გამოსახულებლად, პირველი გამოყენებლად განსახულების მექნიკონტების გამოსახულებლად, რომ MS MARCO-ის გადატანა და დოკუმენტის რენექტირების დავალებისთვის, ჩვენ შეგვიძლია იგივე ეფექტირების დონეზე გავაკეთოთ, მაგრამ 18 წლის ეფექტირებულობაში. მაგრამ, ჩვენი ტექნოგიები ორტოდონალურია სხვა მეტოვებისთვის, რომლებიც ტრანფორმეტრის ინფრენციაზე სწრაფად დააყენებულია, და ამიტომ შეიძლება შეიძლება შეიძლება კ ჩვენი სამუშაოდან უფრო მეტი სიტყვები არის, რომ, თუმცა სამუშაო ტრანფორმაციები დომინეცირებენ მოდინარებული IR პლანექაპში, არსებობს უფრო მნიშვნელოვანი პროლები "ტრადიციონა', 'el': 'Είναι γνωστό ότι οι επανασυνδέσεις που κατασκευάζονται σε προ-εκπαιδευμένα μοντέλα μετασχηματιστών όπως το έχουν βελτιώσει δραματικά την αποτελεσματικότητα ανάκτησης σε πολλές εργασίες. Ωστόσο, αυτά τα κέρδη έχουν επιφέρει σημαντικό κόστος όσον αφορά την αποτελεσματικότητα, όπως σημειώνουν πολλοί ερευνητές. Σε αυτή την εργασία, καταδεικνύουμε ότι είναι δυνατόν να διατηρηθούν τα οφέλη των μετατροπέων επανακατάταξης σε έναν αγωγό πολλαπλών σταδίων χρησιμοποιώντας πρώτα τεχνικές εκμάθησης-κατάταξης με βάση τα χαρακτηριστικά για να μειωθεί ο αριθμός των υπό εξέταση υποψήφιων εγγράφων χωρίς να επηρεαστεί αρνητικά η ποιότητά τους όσον αφορά την ανάκληση. Εφαρμοσμένοι στα καθήκοντα διαβατηρίου και κατάταξης εγγράφων, είμαστε σε θέση να επιτύχουμε το ίδιο επίπεδο αποτελεσματικότητας, αλλά με έως και 18αύξηση στην αποδοτικότητα. Επιπλέον, οι τεχνικές μας είναι ορθογώνιες σε άλλες μεθόδους που επικεντρώνονται στην επιτάχυνση της συναγωγής μετασχηματιστών, και έτσι μπορούν να συνδυαστούν για ακόμα μεγαλύτερα κέρδη απόδοσης. Ένα ανώτερο μήνυμα από το έργο μας είναι ότι, παρόλο που οι προκαθορισμένοι μετασχηματιστές κυριαρχούν στο σύγχρονο τοπίο υπερύθρων, εξακολουθούν να υπάρχουν σημαντικοί ρόλοι για τις "παραδοσιακές" τεχνικές και ότι δεν πρέπει να ξεχνάμε την ιστορία.', 'it': 'È risaputo che i ricalcolatori costruiti su modelli di trasformatori pre-addestrati come BERT hanno notevolmente migliorato l\'efficacia di recupero in molte attività. Tuttavia, questi guadagni hanno comportato costi considerevoli in termini di efficienza, come rilevato da molti ricercatori. In questo lavoro, mostriamo che è possibile mantenere i benefici dei ri-ranker basati su trasformatori in una pipeline di ri-ranking multistadio utilizzando innanzitutto tecniche di apprendimento-ranking basate su funzionalità per ridurre il numero di documenti candidati in esame senza compromettere la loro qualità in termini di richiamo. Applicati ai compiti di passaggio e classificazione dei documenti MS MARCO, siamo in grado di raggiungere lo stesso livello di efficacia, ma con un aumento di efficienza fino a 18. Inoltre, le nostre tecniche sono ortogonali rispetto ad altri metodi focalizzati sull\'accelerazione dell\'inferenza del trasformatore e quindi possono essere combinate per aumentare ulteriormente l\'efficienza. Un messaggio di livello superiore dal nostro lavoro è che, anche se trasformatori pretrained dominano il panorama IR moderno, ci sono ancora ruoli importanti per le tecniche LTR "tradizionali", e che non dobbiamo dimenticare la storia.', 'mk': 'Добро е познато дека реанкерите изградени на претренирани трансформаторски модели како што е БЕРТ драматично ја подобрија ефективноста на преземањето во многу задачи. Сепак, овие добивки доаѓаат со значителни цени во поглед на ефикасноста, како што забележаа многу истражувачи. Во оваа работа покажуваме дека е можно да се задржат бенефициите од трансформаторските реанкерите во мултифазивен гасовод за реанкерирање со прво употреба на техники за учење на ранг базирани на карактеристики за намалување на бројот на кандидатски документи во разгледување без да се влијае негативно на нивниот квалитет во поглед на Applied to the MS MARCO passage and document ranking tasks, we are able to achieve the same level of effectiveness, but with up to 18 increase in efficiency.  Furthermore, our techniques are orthogonal to other methods focused on accelerating transformer inference, and thus can be combined for even greater efficiency gains.  Порака на повисоко ниво од нашата работа е дека иако претренираните трансформатори доминираат во модерниот ИР пејзаж, сé уште постојат важни улоги за „традиционалните“ ТЛТР техники и дека не треба да ја заборавиме историјата.', 'kk': 'BERT секілді өзгертілген транформациялық моделдеріне құрылған қайталанушылар көптеген тапсырмалардың көпшілігін жақсартқан. Бірақ бұл жетістіктер көптеген зерттеушілердің көптеген ефективнілікті бағаттарына арналған. Бұл жұмыс ішінде біріншіден қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қайта қалдыру мүмкіндігін көрсету мүмкіндігін көрсету мүмкіндігін көрсету мүмкіндігін көрсетеді. MS MARCO жүгірту және құжаттардың бағалау тапсырмаларына қолданылады, біз бір деңгейінде әсер етілген деңгейіне жеткізе аламыз, бірақ 18 деңгейіне әсер етілген. Қосымша, біздің технологиямыз өзгерістерді түрлендірушілердің көмегімен көмектесетін әдістеріне ортогононалдық, сондықтан бұл әдістерді көмектесетін көмектесетін әдістерді Жұмыстың жоғары деңгейіндегі хабарламасы - қазір, қазіргі түрлендірушілер көзгертілген IR жағдайына көзгертілген болса да, әлі әдетті LTR техникаларының маңызды рөлі бар, және біз тарихты', 'lt': 'It is well known that rerankers built on pretrained transformer models such as BERT have dramatically improved retrieval effectiveness in many tasks.  Tačiau, kaip pastebėjo daugelis mokslininkų, šis padidėjimas yra didelis efektyvumo požiūriu. Šiame darbe parodomi, kad galima išsaugoti transformatoriais grindžiamų pakartotinių ankerių naudą daugiapakopiame pakartotinio ankerių vamzdyne, pirmiausia naudojant savybių grindžiamus mokymosi lygiu metodus, kad būtų sumažintas svarstomų dokumentų kandidatų skaičius, nepažeidžiant jų kokybės atšaukimo atšaukimo požiūriu. Taikant valstybių narių MARCO perėjimo ir dokumentų klasifikavimo užduotis, mes galime pasiekti tokį patį veiksmingumo lygį, tačiau padidindami veiksmingumą iki 18 metų. Be to, mūsų metodai yra ortogonali kitiems metodams, kuriais siekiama paspartinti transformatoriaus išvadą, ir todėl gali būti derinami siekiant dar didesnio efektyvumo. Aukštesnio lygio žinia iš mūsų darbo yra ta, kad nors iš anksto apmokyti transformatoriai dominuoja šiuolaikiniu IR kraštovaizdžiu, vis dar yra svarbūs "tradicinių" LTR metodų vaidmenys ir kad neturėtume pamiršti istorijos.', 'mt': 'It is well known that rerankers built on pretrained transformer models such as BERT have dramatically improved retrieval effectiveness in many tasks.  Madankollu, dawn il-kisbiet ġew bi spejjeż sostanzjali f’termini ta’ effiċjenza, kif innutati minn ħafna riċerkaturi. F’dan ix-xogħol, naraw li huwa possibbli li jinżammu l-benefiċċji tal-ankers mill-ġdid ibbażati fuq it-trasformaturi f’pajpijiet ta’ riflessjoni f’diversi stadji billi l-ewwel jintużaw tekniki ta’ tagħlim għal grad ibbażati fuq karatteristiċi biex jitnaqqas in-numru ta’ dokumenti kandidati kkunsidrati mingħajr ma tiġi affettwata ħa żin il-kwalità tagħhom f’termini ta’ riflessjoni. Applikati għall-kompiti ta’ passaġġ u klassifikazzjoni tad-dokumenti tal-Istati Membri MARCO, nistgħu niksbu l-istess livell ta’ effikaċja, iżda b’żieda sa 18-il żieda fl-effiċjenza. Barra minn hekk, it-tekniki tagħna huma ortogonali għal metodi oħra ffukati fuq l-aċċellerazzjoni tal-inferenza tat-trasformatur, u għalhekk jistgħu jiġu kkombinati għal żidiet akbar fl-effiċjenza. Messaġġ ta’ livell ogħla mix-xogħol tagħna huwa li, minkejja li trasformaturi mħarrġa minn qabel jiddominaw il-pajsaġġ modern tal-IR, għad hemm rwoli importanti għat-tekniki “tradizzjonali” tal-LTR, u li m’għandniex ninsew l-istorja.', 'ms': "Ia diketahui bahawa pemancar semula yang dibina pada model pengubah yang dilatih sebelum berlatih seperti BERT telah meningkatkan secara dramatis efektivitas pemulihan dalam banyak tugas. Namun, keuntungan ini telah datang dengan biaya yang besar dalam terma efisiensi, seperti yang dikatakan oleh ramai peneliti. Dalam kerja ini, kami menunjukkan bahawa ia adalah mungkin untuk menyimpan keuntungan pengubah-berdasarkan pemancar semula dalam saluran paip pelbagai tahap dengan menggunakan teknik pembelajaran-ke-tahap berdasarkan ciri-ciri untuk mengurangkan bilangan dokumen calon yang sedang dipertimbangkan tanpa mempengaruhi kualiti mereka dalam terma pengingatan. Diaplikasikan pada laluan MS MARCO dan tugas peringkat dokumen, kami mampu mencapai tingkat yang sama efektiviti, tetapi dengan hingga 18 peningkatan efektiviti. Selain itu, teknik kita adalah ortogonal kepada kaedah lain yang fokus pada mempercepat kesimpulan pengubah, dan oleh itu boleh digabung untuk peningkatan efisiensi yang lebih besar. Mesej tahap tinggi dari kerja kita ialah, walaupun pengubah yang dilatih sebelum berlatih mengawal tanah IR modern, masih ada peran penting untuk teknik LTR 'tradisional', dan kita tidak perlu lupa sejarah.", 'ml': 'ബെര്\u200dട്ടി പോലുള്ള മോഡലുകളില്\u200d വീണ്ടും നിര്\u200dമ്മിക്കപ്പെട്ടിരിക്കുന്ന പുനര്\u200dത്ഥികള്\u200d പല ജോലികളില്\u200d വീണ്ടും വീണ്ടും പ് എന്നാലും പലരും പരിശീലന്മാര്\u200d പറഞ്ഞതുപോലെ ഈ ലാഭങ്ങള്\u200d വലിയ വില കൊണ്ട് വന്നിരിക്കുന്നു. ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d കാണിച്ചിരിക്കുന്നു സാധ്യതയുള്ള മാറ്റങ്ങള്\u200d അടിസ്ഥാനപ്പെടുത്തുന്ന പൈപ്പെലിനില്\u200d മാറ്റിവെക്കുന്ന പ്രാര്\u200dത്ഥിക്കുന്ന രേഖകളുടെ എണ്ണം  എംഎസ് മാര്\u200dക്കോയുടെ പാസ്സേജും രാങ്കിങ്ങ് ജോലികളും പ്രയോഗിച്ചു, നമുക്ക് അതേ സാധ്യതയുടെ ഒരേ നിലയില്\u200d എത്താന്\u200d കഴിയും, പക്ഷെ 18 വരെ പ്ര അതിനുശേഷം, നമ്മുടെ സാങ്കേതികവിദ്യയാണ് മറ്റു രീതികളിലേക്ക് ശ്രദ്ധിക്കുന്നത്. മാറ്റങ്ങളുടെ അപകടത്തിലേക്ക് ശീലിപ്പിക്കുന് നമ്മുടെ ജോലിയില്\u200d നിന്നുള്ള ഒരു ഉയര്\u200dന്ന നിലപാട് സന്ദേശം എന്താണെന്ന് വച്ചാലും ആധുനിക സ്ഥാനത്തിലെ മാറ്റങ്ങള്\u200d പ്രധാനപ്പെട്ടിട്ടുണ്ടെങ', 'pl': 'Powszechnie wiadomo, że ponowne rankery zbudowane na wstępnie przeszkolonych modelach transformatorów, takich jak BERT, znacznie poprawiły efektywność odzyskiwania w wielu zadaniach. Korzyści te przyniosły jednak znaczne koszty pod względem wydajności, jak zauważyło wielu badaczy. W niniejszej pracy pokazujemy, że możliwe jest utrzymanie korzyści płynących z transformatorowych rebankerów w wielostopniowym rurociągu rebankowania poprzez najpierw wykorzystanie funkcjonalnych technik learning-to-ranking w celu zmniejszenia liczby rozpatrywanych dokumentów kandydatów bez negatywnego wpływu na ich jakość w zakresie wycofania. Zastosowane do zadań rankingowych przejść i dokumentów MS MARCO, jesteśmy w stanie osiągnąć ten sam poziom skuteczności, ale przy maksymalnie 18-tym wzrostu efektywności. Ponadto nasze techniki są ortogonalne w stosunku do innych metod ukierunkowanych na przyspieszenie wnioskowania transformatorów, dzięki czemu można je łączyć w celu jeszcze większego wzrostu efektywności. Wyższym poziomem przesłania z naszej pracy jest to, że chociaż wstępnie przeszkolone transformatory dominują w nowoczesnym krajobrazie IR, nadal istnieją ważne role dla "tradycyjnych" technik LTR i że nie powinniśmy zapominać o historii.', 'mn': 'БЕРТ шинжлэх ухааны загвар дээр бүтээгдэхүүнд олон ажил дээр дахин үр дүнг нэмэгдүүлсэн гэдгийг сайн мэднэ. Гэвч эдгээр ялгаа олон судлаачид зарцуулсан үнэтэй үнэтэй болсон. Энэ ажлын тулд бид олон этаж дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин сурах боломжтой технологийг ашиглаж байгааг харуулж байна. MS MARCO-ын хууль болон баримт дүрслэлийн даалгаврыг ашиглан бид ижил үр дүнтэй түвшинд хүргэж чадна, гэхдээ үр дүнтэй 18 хүртэл нэмэгдэж чадна. Мөн бидний техникууд өөр аргыг хурдан шилжүүлэгчийн халдварыг хурдан хүргэхэд төвлөрсөн бөгөөд энэ нь илүү үр дүнтэй өндөрт нийлүүлж болно. Бидний ажлын хамгийн өндөр түвшинд байгаа санаа нь, орчин үеийн ИР-ын газрыг давамгайлдаг ч, уламжлалтай LTR технологиудын төлөө чухал үүрэг байдаг. Бид түүхийг мартах хэрэггүй.', 'no': 'Det er godt kjent at tilbakekallere bygde på transformeringsmodeller som BERT har dramatisk forbedra tilbakekallingsfeilighet i mange oppgåver. Desse forskjellingane har imidlertid komme på stor kostnad i uttrykket av effektivitet, som notert av mange forskere. I denne arbeiden viser vi at det er mulig å beholde fordelene av transformeringsbaserte tilbakestillere i ein fleire stader som gjenoppretter pipelinje ved å første bruka funksjonsbaserte læringstil-rank teknikk for å redusera talet på kandidatdokument under forståelse utan å negativt påvirka kvaliteten sine i gjenoppretting. I bruk av MS MARCO-passasjonen og dokumentrankeringsoppgåver, kan vi oppnå same effektivt nivå, men med opp til 18 øk effektivt. I tillegg er teknikkene våre orthogonale til andre metoder fokusert på akselereringsinfeksjon av transformeringa, og derfor kan kombinerast for enda større effektiviteten. Eit høgare nivåmelding frå arbeidet vårt er at, selv om pretrende transformasjonar dominerer den moderne IR-landskapen, er det fortsatt viktige roller for «tradisjonelle» LTR-teknikkar, og vi bør ikkje glemme historien.', 'ro': 'Este bine cunoscut faptul că rearanjatoarele construite pe modele de transformatoare pre-instruite, cum ar fi BERT, au îmbunătățit dramatic eficiența de recuperare în multe sarcini. Cu toate acestea, aceste câștiguri au venit cu costuri substanțiale în ceea ce privește eficiența, după cum au remarcat mulți cercetători. În această lucrare, arătăm că este posibil să păstrăm beneficiile reîncărcătorilor bazați pe transformatori într-o conductă de reîncărcare în mai multe etape prin utilizarea mai întâi a tehnicilor de învățare-rang bazate pe caracteristici pentru a reduce numărul de documente candidate în cauză fără a afecta negativ calitatea acestora în ceea ce privește rechemarea. Aplicați sarcinilor de trecere și clasare a documentelor MS MARCO, suntem capabili să atingem același nivel de eficiență, dar cu până la 18 creștere a eficienței. În plus, tehnicile noastre sunt ortogonale față de alte metode axate pe accelerarea inferenței transformatorului și, astfel, pot fi combinate pentru creșteri și mai mari de eficiență. Un mesaj de nivel superior din munca noastră este că, deși transformatoarele pre-instruite domină peisajul IR modern, există încă roluri importante pentru tehnicile LTR "tradiționale" și că nu trebuie să uităm istoria.', 'si': "ඒක හොඳටම දැනගන්නවා ප්\u200dරීට්\u200dරේන්ස් වෙනස් මොඩල් වලින් නිර්මාණය කරලා තියෙනවා වගේ BERT වලින් ගොඩක් වැඩේ වැඩි වැඩේ ප්\u200dර නමුත්, මේ ගොඩක් ගොඩක් ගොඩක් විශාල විශාල විදිහට ආවා, ගොඩක් පරීක්ෂකයන් නිර්දේශ කරලා තියෙනවා. මේ වැඩේදී, අපි පෙන්වන්නේ ඒක ප්\u200dරයෝජනය කරන්න පුළුවන් වෙන්නේ ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය සඳහා මුලින්ම ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජනය සඳහා ප්\u200dරයෝජ MS MARCO ප්\u200dරවේශය සහ ලිපින්ත ප්\u200dරවේශය සඳහා ලිපින්ත වැඩ කරන්න පුළුවන්, අපිට එකම ප්\u200dරවේශයක් ලැබෙන්න පුළුවන්, ඒත් ප්\u200dරවේශ ඉතින්, අපේ තාක්ෂණය අනිත් විදියට අනිත් විදියට අවධානය වෙන්න පුළුවන් වෙන්න පුළුවන්, ඒ වගේම තවත් වැඩි විදියට උ අපේ වැඩේ ඉන්න උඩ ස්ථාන පණිවිඩයක් තමයි, ප්\u200dරීට්\u200dරයින් වෙනස් කරුණාකරුවන් අධ්\u200dයාන්\u200dය IR ප්\u200dරමාණය කරනවා නමුත්, තවමත් 'පරමාණික'", 'sr': 'Dobro je poznato da su preuređaji izgrađeni na pretkišnim modelima transformera kao što je BERT dramatično poboljšali učinkovitost povratka u mnogim zadacima. Međutim, ove dobitke su došle na značajne troškove u smislu efikasnosti, kao što je navelo mnogi istraživači. U ovom poslu, pokazujemo da je moguće zadržati koristi prebacivača na transformaciji u višefaznom prebacivanju cijevi, prvo koristeći tehnike učenja na liniji funkcija kako bi smanjili broj kandidatskih dokumenta u razmatranju, a da ne bi negativno utjecali na njihovu kvalitetu u smislu sećanja. Primijenili smo na prolaz MS MARCO-a i zadatke za raspoređivanje dokumenta, možemo postići isti nivo učinkovitosti, ali s povećanjem učinkovitosti do 18 godina. Nadalje, naše tehnike su ortogonalne na druge metode fokusirane na ubrzavanje infekcije transformera, i tako se mogu kombinirati za još veće učinkovitosti. Poruka sa višeg nivoa našeg rada je da, iako pretkivni transformatori dominiraju modernu IR pejzažu, još uvek postoje važne uloge za tehnike "tradicionalne" LTR-a, i da ne bi trebali zaboraviti povijest.', 'so': "Waxaa si wanaagsan loo yaqaan in kuwa dib u dhisay samooyin isbedelka ah sida BERT waxay ku hagaajiyeen faa’iido badan oo ku saabsan shaqooyin badan. Si kastaba ha ahaatee, faa'iidadaadu waxay ku dhaceen kharashaadka aad u weyn, sida ay u soo jeedeen wax baarayaal badan. Shaqadan, waxaan tusnaa in suurtogal ah in lagu haysto faa'iidada kuwa dib u dhigta ee lagu bedelay dugsiyada oo aad u bedelayso heer kala duduwan, marka hore waxaynu isticmaalaynaa qalabka waxbarashada si aad u hesho si uu u hoosayso tirada warqada kandida ah oo aan sharaf leh saameyn ku yeelan qiimahooda xusuusta darteed. Ka codsashada baasaboorka MS MARCO iyo shaqooyinka lagu sameynayo dukumentiyada, waxaynu gaadhi karnaa heerka isku mid ah, laakiin waxaa korodhsan kara ilaa 18. Intaas waxaa dheer in qalabkayagu ay ku habboon yihiin qaababka kale oo ay ku kalsoonaan karaan dhibaatada beddelka, sidaas oo kalena waxaa lagu wada ururin karaa faa'iidada faa'iidada badan. Hadal sare oo shaqadeenna ka yimaada waa in, in kastoo aan ka hor dhignay in beddelaadka ay maamulaan dalalka IR-ka hooseeya, weliba waxaa jira qayb muhiim ah oo ay leeyihiin qalabka caadiga ah ee LTR, si aanan u illoobin taariikhda.", 'sv': 'Det är välkänt att återförankare byggda på förkränade transformatormodeller som BERT dramatiskt har förbättrat återvinningseffektiviteten i många uppgifter. Dessa vinster har dock medfört betydande kostnader när det gäller effektivitet, vilket många forskare har noterat. I detta arbete visar vi att det är möjligt att behålla fördelarna med transformatorbaserade återförankare i en flerstegs återförankning pipeline genom att först använda funktionsbaserad inlärningsteknik för att minska antalet kandidatdokument som behandlas utan att negativt påverka deras kvalitet när det gäller återkallande. Med hjälp av MS MARCO passage- och dokumentrankningsuppgifter kan vi uppnå samma effektivitetsnivå, men med upp till 18 effektiviseringar. Dessutom är våra tekniker ortogonala mot andra metoder som fokuserar på att accelerera transformatorinferens och kan därmed kombineras för ännu större effektivitetsvinster. Ett högre budskap från vårt arbete är att även om förtrränade transformatorer dominerar det moderna IR-landskapet, finns det fortfarande viktiga roller för "traditionella" LTR-tekniker, och att vi inte får glömma historien.', 'ur': "اس سے خوب معلوم ہوتا ہے کہ دوبارہ پیدا کئے ہوئے ٹرانٹر موڈل پر بنائے گئے ہیں جیسے BERT نے بہت سے کاموں میں اثرات حاصل کرنا بہت زیادہ اثرات کی۔ لیکن یہ کامیابی کے مطابق بہت زیادہ قیمت پر آچکے ہیں، جیسے بہت سے تحقیقات کرنے والوں نے یاد کیا ہے. ہم اس کام میں دکھاتے ہیں کہ متغیر بنیاد رکھنے والی رولنگروں کا فائدہ ملتی سٹیوں میں پئیپ لائن کو پہلی بار دکھانے والی سیکھانے والی تکنیک کے مطابق کم کرنے کے لئے موجود ہے کہ ان کے کیفیت کے مطابق ان کے ذکر کے بغیر ان کے کیفیت کے اثر سے کم کریں۔ MS MARCO مسافرت اور سند رینگ کے کام پر استعمال کیا گیا ہے، ہم ایک ہی سطح فعالیت کو پہنچا سکتے ہیں، لیکن اکثریت میں 18 سے بڑھ سکتے ہیں۔ اور اس کے علاوہ ہماری تکنیک دوسری طریقے پر متمرکز ہیں جو تغییر پھیلانے کے ذریعہ تغییر پھیلانے کے ذریعہ تغییر پھیلانے کے لئے تمرکز کئے جاتے ہیں، اور اسی طرح بہت اضافہ پھیلانے کے ہمارے کام سے ایک بلند مرتبہ پیغام یہ ہے کہ، اگرچہ آزمائش آیر کی منظور پر قائم ہوتے ہیں، اب بھی 'آزمائش' LTR تکنیک کے لئے اہم رول ہیں، اور ہم تاریخ بھولنا چاہیے.", 'ta': "BERT போன்ற மாற்று மாதிரிகள் உருவாக்கப்பட்ட மாதிரிகளின் மீண்டும் தெரியும் போது பிரெட் செயல்களில் திரும்ப வேண்டும்  ஆயினும், பல ஆராய்ச்சியாளர்கள் குறிப்பிட்டது போல், இந்த வளர்ச்சிகள் பெரிய விலையில் வருகின்றன. இந்த வேலையில், நாம் காண்பிக்கிறோம் மாற்று அடிப்படையான மீண்டும் பைப்பெல்லின் பலstage மீண்டும் மீண்டும் செலுத்தும் பலநிலையில் மாற்றுபவர்களின் பயன்பாடுகளை வைத்துக் கொ MS MARCO கடவுச் செயல்பாடுகளுக்கும் பயன்படுத்தப்பட்டுள்ளது, நாம் அதே நிலையில் செயல்பாடுகளை அடைக்க முடியும், ஆனால் 18 க்கு மேல் தான்  மேலும், எங்கள் தொழில்நுட்பம் மற்ற முறைமைகளுக்கு முக்கியமாக இருக்கும் முறைமாற்றத்தை வேகமாக்குவதற்கு கவனம் செலுத்தும், அதனால் அதிகமா எங்கள் வேலையிலிருந்து ஒரு உயர்நிலை செய்தி என்னவென்றால், நடத்தும் IR நிலத்தில் மாற்றங்களை மேலாண்மை செய்தாலும் 'மரபார்ந்த' LTR தொழில்நுட", 'uz': 'Bu haqiqatgina aniqlik, BERT kabi vazifalar kabi vazifalarda qayta olish muvaffaqiyatlarini aniqlaydi. Lekin, bu muvaffaqiyatlar ko\'pchilik taʼminlovchilar taʼminlovchisi yordamida katta qiymatga keladi. Bu vazifani ko\'rsatishimiz mumkin, bu vazifani bir necha darajada o\'zgartirishning asosiy raqamlarining imkoniyatlarini o\'zgartirish mumkin va birinchi darajada o\'rganish tugmasini foydalanish mumkin. Taʼminlovchi hujjatlarning soni kamaytirish imkoniyatini eslab qolishi mumkin. Comment Ko\'rsatganda, bizning teknolojiyamiz boshqa usullarga ortodokonalik, o\'zgarishni o\'zgarishga harakat qilish mumkin, va shunday qilib ko\'proq ijodkorga birlashtirish mumkin. Bizning ishimizdan eng yuqori xabar shunday qilib, yangi IR davlatda o\'zgarishlarni tasavvur qilingan bo\'lsa, ammo "tabiiy" LTR teknikalarning muhim roli mavjud, va biz tarixini saqlash kerak.', 'vi': 'Rõ ràng là những cỗ máy được xây dựng dựa trên các mô hình thay thế thế thế thế trước kia như BERT đã tăng cường hiệu quả thu hồi nhanh chóng trong nhiều nhiệm vụ. Tuy nhiên, những lợi nhuận này có một mức giá đáng kể về năng suất, như nhiều nhà nghiên cứu đã ghi nhận. Trong công việc này, chúng tôi cho thấy có thể giữ lại lợi ích của những cỗ máy tái tạo bằng cách sử dụng các kỹ thuật dựa trên các đặc trưng để giảm bớt số tài liệu ứng cử viên đang được cân nhắc mà không ảnh hưởng đến chất lượng thu hồi. Ứng dụng với các công việc theo dõi tập tin và xếp hạng tài liệu của xơ rải rác, chúng tôi có khả năng đạt được cùng một mức độ hiệu quả, nhưng với mức độ hiệu suất cao đến 18. Hơn nữa, kỹ thuật của chúng tôi theo chuẩn với các phương pháp khác tập trung vào việc tăng tốc sức chịu đựng của máy biến đổi, và có thể kết hợp lại để tăng thêm hiệu quả. Một thông điệp cấp cao từ công việc của chúng ta là, mặc dù máy biến thế đang thống trị vùng hồng ngoại hiện đại, vẫn còn vai trò quan trọng cho các kỹ thuật "truyền thống" của LR, và chúng ta không nên quên lịch sử.', 'bg': 'Добре известно е, че пренаредителите, изградени върху предварително тренирани трансформаторни модели като са подобрили драстично ефективността на извличането в много задачи. Тези печалби обаче са направени със значителни разходи по отношение на ефективността, както отбелязват много изследователи. В тази работа показахме, че е възможно да се запазят ползите от трансформаторните пренаредители в многостепенен канал за пренареждане, като първо се използват функционални техники за учене към ранг, за да се намали броят на разглежданите кандидат документи, без да се засяга неблагоприятно тяхното качество по отношение на изтеглянето. Приложени към задачите за преминаване и класиране на документи, ние сме в състояние да постигнем същото ниво на ефективност, но с до 18 увеличение на ефективността. Освен това нашите техники са правоъгълни на други методи, фокусирани върху ускоряване на трансформаторното заключение и по този начин могат да бъдат комбинирани за още по-големи печалби на ефективността. Послание на по-високо ниво от нашата работа е, че макар предварително обучените трансформатори да доминират в съвременния инфрачервен пейзаж, все още има важни роли за "традиционните" техники и че не бива да забравяме историята.', 'da': "Det er velkendt, at omdannere bygget på forudtrænede transformermodeller som BERT har forbedret hentningseffektiviteten dramatisk i mange opgaver. Disse gevinster er imidlertid kommet til betydelige omkostninger med hensyn til effektivitet, som mange forskere har bemærket. I dette arbejde viser vi, at det er muligt at bevare fordelene ved transformer-baserede omdirigeringer i en multi-trins omdirigeringsrørledning ved først at bruge feature-baserede lærings-to-rank teknikker til at reducere antallet af kandidatdokumenter under overvejelse uden at påvirke deres kvalitet i form af tilbagekaldelse negativt. Anvendes til MS MARCO passage- og dokumentranking opgaver, er vi i stand til at opnå det samme niveau af effektivitet, men med op til 18 stigninger i effektivitet. Desuden er vores teknikker ortogonale i forhold til andre metoder, der fokuserer på at accelerere transformer inferens, og kan dermed kombineres for endnu større effektivitetsgevinster. Et højere budskab fra vores arbejde er, at selvom forudtrænede transformere dominerer det moderne IR landskab, er der stadig vigtige roller for 'traditionelle' LTR teknikker, og at vi ikke må glemme historien.", 'de': 'Es ist bekannt, dass Reranker, die auf vortrainierten Transformatormodellen wie BERT basieren, die Retrieval-Effektivität in vielen Aufgaben erheblich verbessert haben. Diese Gewinne sind jedoch mit erheblichen Kosten in Bezug auf die Effizienz verbunden, wie viele Forscher feststellten. In dieser Arbeit zeigen wir, dass es möglich ist, die Vorteile von transformatorbasierten Rerankern in einer mehrstufigen Reranking-Pipeline zu erhalten, indem zunächst feature-based Learning-to-Rank-Techniken verwendet werden, um die Anzahl der betrachteten Kandidatendokumente zu reduzieren, ohne deren Qualität in Bezug auf den Rückruf zu beeinträchtigen. Angewendet auf die MS MARCO Passage und Dokument Ranking Aufgaben, sind wir in der Lage, das gleiche Maß an Effektivität, aber mit bis zu 18 Steigerung der Effizienz zu erreichen. Darüber hinaus sind unsere Techniken orthogonal zu anderen Methoden, die auf die Beschleunigung der Transformatorinferenz fokussiert sind, und können so für noch größere Effizienzgewinne kombiniert werden. Eine übergeordnete Botschaft aus unserer Arbeit ist, dass, obwohl vortrainierte Transformatoren die moderne IR-Landschaft dominieren, es immer noch wichtige Rollen für "traditionelle" LTR-Techniken gibt, und dass wir die Geschichte nicht vergessen sollten.', 'nl': "Het is algemeen bekend dat rerankers die zijn gebouwd op voorgetrainde transformatormodellen zoals BERT, de terugwinningseffectiviteit in veel taken aanzienlijk hebben verbeterd. Deze winsten hebben echter aanzienlijke kosten met zich gebracht in termen van efficiëntie, zoals veel onderzoekers opmerken. In dit werk tonen we aan dat het mogelijk is om de voordelen van transformator-based heringerankers in een meertraps heringeranking pipeline te behouden door eerst feature-based learning-to-ranking technieken te gebruiken om het aantal in aanmerking komende kandidaat documenten te verminderen zonder de kwaliteit ervan in termen van terugroeping nadelig te beïnvloeden. Toegepast op de MS MARCO passage en document ranking taken, zijn we in staat om hetzelfde niveau van effectiviteit te bereiken, maar met maximaal 18 verhoging van de efficiëntie. Bovendien zijn onze technieken orthogonaal ten opzichte van andere methoden gericht op het versnellen van transformatorinferentie, en dus kunnen worden gecombineerd voor nog grotere efficiëntieverbeteringen. Een hogere boodschap uit ons werk is dat, hoewel voorgetrainde transformatoren het moderne IR landschap domineren, er nog steeds belangrijke rollen zijn voor 'traditionele' LTR technieken, en dat we de geschiedenis niet mogen vergeten.", 'hr': "Dobro je poznato da su preuređaji izgrađeni na pretkišnim modelima transformera poput BERT dramatično poboljšali učinkovitost povratka u mnogim zadatkima. Međutim, te dobitke su došle na značajne troškove u smislu učinkovitosti, kao što je navelo mnogi istraživači. U ovom poslu, pokazujemo da je moguće zadržati koristi prebacivača na transformaciji u višefaznom prebacivanju cijevi, prvo koristeći tehnike učenja na liniji funkcija kako bi smanjili broj kandidatskih dokumenta u razmatranju bez negativnog utjecaja na njihovu kvalitetu u smislu sjećanja. Primijenili smo na prolaz MS MARCO-a i zadatke za postizanje reda dokumenta, uspjeli smo postići isti nivo učinkovitosti, ali s povećanjem učinkovitosti do 18 godina. Nadalje, naše tehnike su ortogonalne na druge metode usredotočene na ubrzavanje infekcije transformera, i tako se mogu kombinirati za još veće dobiće učinkovitosti. Poruka na višem nivou našeg rada je da, iako pretkišni transformatori dominaraju modernu IR pejzažu, još uvijek postoje važne uloge za 'tradicionalne' LTR tehnike i da ne bismo trebali zaboraviti povijest.", 'sw': 'Inajulikana vizuri kwamba wageni waliojengwa kwenye mifano ya mabadiliko yaliyojitokeza kama vile BERT imebadilisha ufanisi wa upatikanaji katika kazi nyingi. Hata hivyo, mafanikio haya yametokea kwa gharama kubwa kwa ufanisi, kama ilivyobainishwa na watafiti wengi. Katika kazi hii, tunaonyesha kwamba inawezekana kuendelea faida ya wageni wenye mabadiliko katika viwanja vya mabadiliko kwa kutumia mbinu za kwanza za za kujifunza-kwa-vyeo ili kupunguza idadi ya nyaraka za wagombea zinazotazama bila madhara inayoathiri ubora wao kwa ajili ya kukumbuka. Kutumiwa kwa kutumia ujumbe wa MS MARCO na kazi za makala, tunaweza kufikia kiwango sawa cha ufanisi, lakini kwa kiwango cha kufikia 18 kinaongezeka kwa ufanisi. Furthermore, our techniques are orthogonal to other methods focused on accelerating transformer inference, and thus can be combined for even greater efficiency gains.  Ujumbe wa ngazi juu kutoka kazi yetu ni kwamba, hata kama ilivyojifanya kuwa mabadiliko yanatawala katika eneo la sasa la IR, bado kuna jukumu muhimu kwa mbinu za ‘utamaduni’ za LTR, na kwamba hatupaswi kusahau historia.', 'fa': 'خوب شناخته می شود که بازگشتگران بر مدل تغییر\u200cدهنده\u200cهای پیش\u200cبار ساخته شده\u200cاند، مانند BERT، فعالیت بازگشت در بسیاری از کارها به شدت زیادی بهتر شده\u200cاند. با این حال، این پیروزی با هزینه\u200cهای زیادی در مورد موثیت، همانطور که توسط بسیاری از تحقیقات کنندگان مشخص شده است. در این کار، ما نشان می دهیم که ممکن است سودهایی از بازگشت\u200cکنندگان بر اساس تغییر\u200cکننده\u200cها در یک لوله\u200cهای متعدد مرحله با استفاده از تکنیک\u200cهای یادگیری به مرحله\u200cهای ویژه\u200cای برای کاهش تعداد سند\u200cهای کاندیده\u200cها را تحت توجه بدون خطرناک تأثیر کیفیت آنها به صورت یادگیری کند. به مسیر مسیر MARCO و مسیر صفحه مدارک استفاده می\u200cکنیم، ما می\u200cتوانیم همان سطح فعالیت را بررسی کنیم، ولی با افزایش تا ۱۸ افزایش فعالیت. بعلاوه، تکنولوژی\u200cهای ما به روش\u200cهای دیگر متمرکز به سرعت آلودگی تغییر\u200cدهنده\u200cها هستند، و این\u200cطور می\u200cتواند برای بردن بیشتر موثیت ترکیب شود. پیغام سطح بالاتری از کار ما این است که، اگرچه تغییر دهندگان پیش از نظر آر مدرن را تسلیم کنند، هنوز نقش های مهم برای تکنیک LTR سنتی وجود دارد، و نباید تاریخ را فراموش کنیم.', 'ko': "많은 임무에서 예비 훈련을 바탕으로 하는 변압기 모델(예를 들어 BERT)을 바탕으로 구축된 정렬기는 검색 효율을 크게 향상시켰다.그러나 많은 연구자들이 지적한 바와 같이 이러한 수익은 효율에 있어서 커다란 대가를 치렀다.이 작업에서 우리는 먼저 특징에 기반한 학습 정렬 기술을 사용하여 고려 중인 후보 문서의 수량을 줄이고 리콜의 질에 부정적인 영향을 주지 않으며 다단계 리셋 파이프에서 변환기 기반 리셋의 장점을 유지하는 것이 가능하다는 것을 보여 준다.MARCO 여사의 글과 파일 정렬 작업에 적용되면 우리는 같은 효율 수준에 도달할 수 있지만 효율은 18% 높아졌다.또한 우리의 기술은 다른 가속 변압기 추정에 전념하는 방법과 정교하기 때문에 결합하여 사용하면 더욱 큰 효율적인 이익을 얻을 수 있다.우리의 업무에서 얻은 더욱 높은 차원의 정보는 예비 교육 변압기가 현대 적외선 분야를 주도했지만'전통적인'LTR 기술은 여전히 중요한 역할을 하기 때문에 우리는 역사를 잊어서는 안 된다는 것이다.", 'sq': "Është e njohur mirë se ripërankerat e ndërtuara në modele transformuese të parastërvitura të tilla si BERT kanë përmirësuar dramatikisht efektshmërinë e ripërmarrjes në shumë detyra. Megjithatë, këto fitime kanë ardhur me kosto thelbësore lidhur me efektshmërinë, siç vunë në dukje shumë kërkues. Në këtë punë, ne tregojmë se është e mundur të mbahen përfitimet e transformuesve në një tubacion shumë-fazor të rishikimit duke përdorur së pari teknikat e mësimit në radhë të bazuar në funksione për të reduktuar numrin e dokumenteve kandidate në konsideratë pa prekur keq cilësinë e tyre lidhur me kujtimin. I aplikuar në kalimin e MS MARCO dhe detyrat e renditjes së dokumenteve, ne jemi në gjendje të arrijmë të njëjtin nivel efektiviteti, por me deri në 18 rritje në efektivitet. Përveç kësaj, teknikat tona janë ortogonale ndaj metodave të tjera të përqëndruara në përshpejtimin e përfundimit të transformuesit dhe kështu mund të kombinohen për rritje edhe më të madhe efektshmërie. Një mesazh më i lartë nga puna jonë është se edhe pse transformuesit e parastërvitur mbizotërojnë peisazhin modern IR, ekzistojnë ende role të rëndësishme për teknikat 'tradicionale' të LTR dhe se ne nuk duhet të harrojmë historinë.", 'id': "Hal ini dikenal dengan baik bahwa reranker dibangun pada model transformer yang dilatih sebelum berlatih seperti BERT telah dramatis meningkat efektifitas retrieval dalam banyak tugas. Namun, keuntungan ini telah datang dengan biaya yang besar dalam hal efisiensi, seperti yang dikatakan oleh banyak peneliti. Dalam pekerjaan ini, kami menunjukkan bahwa mungkin untuk mempertahankan keuntungan dari pemancar berubah berdasarkan transformator dalam pipa pemancar ulang multi-tahap dengan pertama menggunakan teknik pembelajaran berdasarkan fitur-ke-rank untuk mengurangi jumlah dokumen kandidat yang sedang dipertimbangkan tanpa mempengaruhi kualitas mereka dalam termasuk ingatan. Diaplikasikan pada MS MARCO penerbangan dan tugas peringkat dokumen, kami mampu mencapai tingkat efektivitas yang sama, tetapi dengan sampai 18 meningkat efektivitas. Selain itu, teknik kita adalah ortogonal untuk metode lain yang fokus pada mempercepat inferensi transformer, dan dengan itu dapat digabung untuk lebih besar keuntungan. Sebuah pesan tingkat tinggi dari pekerjaan kami adalah bahwa, meskipun transformer yang dilatih sebelum dilatih mendominasi tanah IR modern, masih ada peran penting untuk teknik LTR 'tradisional', dan bahwa kita tidak harus melupakan sejarah.", 'hy': 'Լավ հայտնի է, որ նախապատրաստված վերադասակարգչային մոդելների վրա, ինչպիսիք են ԲԵՌՏը, դրամական բարելավել են վերադարձման արդյունավետությունը բազմաթիվ առաջադրանքներում: Այնուամենայնիվ, այս բարձրացումները արդյունավետության տեսանկյունից շատ հետազոտողների կողմից նշանակալի ծախսերով են արվել: Այս աշխատանքի ընթացքում մենք ցույց ենք տալիս, որ հնարավոր է պահպանել փոխակերպման հիմնված վերաճանապարհորդների առավելությունները բազմաաստիճանի վերաճանապարհորդման խողովակաշարի մեջ, առաջին հերթին օգտագործելով առանձնահատկությամբ ուսումնասիրություններ դասավորելու մեթոդներ, որոնք նվազեցնում են թեկնա Համակարգված ՄԱԿՕ-ի և փաստաթղթերի դասակարգման խնդիրներին, մենք կարող ենք հասնել նույն արդյունավետության մակարդակի, բայց արդյունավետության աճով մինչև 18-ը: Ավելին, մեր տեխնիկաները օրթոգոնալ են այլ մեթոդների հետ, որոնք կենտրոնացված են ձևափոխիչ եզրակացության արագացման վրա, և դրանով կարող են համադրվել ավելի մեծ արդյունավետության համար: Մեր աշխատանքից ավելի բարձր մակարդակի հաղորդագրությունն այն է, որ չնայած, որ նախավարժված վերափոխողները գերիշխում են ժամանակակից ԻՌ բնապատկերը, դեռևս կարևոր դերեր կան LTR-ի ավանդական տեխնիկայի համար, և որ մենք չպետք է մոռանանք պատմությունը:', 'af': "Dit is goed bekend dat herankers gebou het op vooraf transformeermodele soos BERT het dramatiese herhaal effektiviteit verbeter in baie taak. Hierdie verkrywings het tog op substantiele koste ingevolge effektief gekom, soos deur baie ondersoekers opgemerk het. In hierdie werk, ons wys dat dit moontlik is om die voordele van transformer-gebaseerde herankers in 'n multistadige herank pipelyn te hou deur die eerste gebruik van funksie-gebaseerde leer-na-rank teknike om die nommer van kandidate dokumente onder aandag te verminder sonder om hulle kwaliteit te noodsaaklik in terms van rekening te beëindig. Aanvank na die MS MARCO-oorgang en dokument-ranking-taak, ons kan die selfde vlak van effektiviteit bereik, maar met tot by 18 oorvloedigheid in effektiviteit. Ons teknike is ook orthogonaal tot ander metodes gefokus op die versnelling van transformeerder inferensie, en dus kan gekombineer word vir selfs groter effektiviteit verkry. 'n Hoër vlak boodskap van ons werk is dat, selfs al die pretreënde transformeerders die moderne IR-landskap domineer, daar is nog belangrik roles vir 'tradisionele' LTR-teknike, en dat ons nie geskiedenis moet vergeet nie.", 'tr': "BERT ýaly öňünde täsirli transformatör modellerinde guruldygy taýýarlançylar birnäçe işlerde gaty täsirli bolup geçirdiklerini gowy bilýär. Ýöne bu gazançlar etkinlik ýagdaýynda örän täsirli täsirli bolup geçirdi. Bu işde, biziň görkezilişimizde, täze taýýarlanan täze taýýarlançylaryň üstünlerini birnäçe stage diňe taýýarlanan täze taýýarlançylyklarynyň üstüne göçürmegi mümkin edip bilýäris. MS MARCO geçişine we sened derejesine uygulanýar, biz bir etkinlik derejesini ýetip bileris, ýöne 18-den etkinlik ýokarynda artyp bileris. Munuň üçin, biziň tekniklerimiz be ýleki metodlara görnüşler üçin üýtgetmeli täsirler üçin birleştirilip biler. Biziň işimizden ýokary dereje bir mesaj şudyr: öňünden geçirilen täsirleriň modern IR dünýäsini dominirýändigine garamazdan hem, 'Däpli' LTR teknikleri üçin häzir möhüm roller bar we geçmişi unutmamalydyrys.", 'am': 'እንደዚህ BERT በብዙ ስራ ውስጥ የውጤት ማቀናቀል ፍላጎታቸውን በመጠቀም እንደተደረገ አዲስ ሰራጆች ተዘጋጅተዋል፡፡ However, these gains have come at substantial costs in terms of efficiency, as noted by many researchers.  በዚህ ስራ፣ በመጀመሪያ የፊደል ትምህርት-ወደ ደረጃ ማቀናጃ የተደረገውን የፋንታ ሰነዶች ቁጥጥር በማንቀሳቀስ ጥቅሞችን በመቀበል በሁለት ደረጃዎች ላይ መቆጣጠር እንደሚችል እናሳያቸዋለን፡፡ ወደ አሜሪካ ማርኮ መግቢያ እና ለሥርዓት ማድረግ ስራዎችን ለመጠቀም እንችላለን፣ ነገር ግን እስከ 18 ያህል በጥቅምነት ማድረግ እንችላለን፡፡ በተጨማሪም፣ ስልጣናችን ለሌሎች መንገዶች አካባቢ ነው፤ ስለዚህም ለውጤት ትክክል ማግኘት ይቻላል፡፡ ከሥራችን ከፍተኛ ደረጃ መልእክት ቢሆን እንኳ የአሁኑን IR መሬት ላይ የተዘጋጀ ለውጦች ቢሆንም እንኳ፣ ለ ‘ ወታደባዊ’ LTR-ቴክክኖችን ያስፈልጋል፣ ታሪክ እንዳንረሳ ያስፈልጋል፡፡', 'az': "BERT kimi əvvəlki transformatçı modellərdə in şa edilmiş yenidən inşa edənlər çoxlu işlərdə geri alma efektivitəsini dəhşətli yaxşılaşdırdılar. Ancaq bu qənimətlər çoxlu araştırmacıların müəyyən edildiyi təqdirdə böyük qiymətlərə gəlmişdir. Bu işdə, biz göstəririk ki, transformer-based re-ankers-in faydalarını çoxlu fərqli tərzdə yenidən fərqli tərzdə öyrənmək-dərəcə tərzlərini ilk dəfə istifadə edərək, fikirləşmək üçün çoxlu fərqli tərzlərin sayını azaltmaq mümkün olar. MS MARCO keçməsinə və dökümət səviyyələrinə istifadə edilmişdir, biz də eyni təsirlik səviyyəsinə yetişə bilərik, amma səviyyətinə 18 nəzər yetişə bilərik. Daha sonra, tekniklərimiz başqa metodlara ortogonaldır, transformer infeksiyonu hızlandırmaq üçün təsirləndirilir, böylece daha böyük faydallıq qazanmaq üçün birləşdiririlir. Bizim işimizdən daha yüksək səviyyə mesajı, əvvəlki transformatçılar moderni IR tərəflərinə hökmranlıq etsələr də, hələ də 'tradicional' LTR teknikləri üçün möhkəm rollər var və tarihi unutmamalıyıq.", 'cs': 'Je dobře známo, že přestavby postavené na předtrénovaných modelech transformátorů, jako je BERT, výrazně zlepšily efektivitu vyhledávání v mnoha úkolech. Tyto zisky však přinesly značné náklady z hlediska efektivity, jak poznamenalo mnoho výzkumných pracovníků. V této práci ukazujeme, že je možné zachovat výhody transformátorových přeskupovačů ve vícestupňovém přeskupovacím potrubí nejprve použitím funkčně založených technik learning-to-rank ke snížení počtu posuzovaných kandidátských dokumentů bez negativního vlivu na jejich kvalitu z hlediska stažení. Aplikované na MS MARCO pasážní a dokumentové hodnocení úkolů, jsme schopni dosáhnout stejné úrovně efektivity, avšak s až 18-ti zvýšením efektivity. Kromě toho jsou naše techniky ortogonální k jiným metodám zaměřeným na urychlení inference transformátorů, a proto lze kombinovat pro ještě větší zvýšení efektivity. Vyšší úroveň poselství z naší práce je, že i když předem trénované transformátory dominují moderní IR krajině, stále existují důležité role pro "tradiční" LTR techniky a že bychom neměli zapomínat na historii.', 'bn': 'এটা ভালোভাবে জানা যাচ্ছে যে পুনরায় বিনিময়ের মডেলের উপর তৈরি করা হয়েছে যেমন বিবের্টের মতো অনেক কাজে পুনরুদ্ধারের কার্যকর্ম কিন্তু অনেক গবেষকের উল্লেখ করেছে যেমনটা বলেছেন, এই অর্থ বিশাল খরচের ব্যাপারে এসেছে। এই কাজে আমরা দেখাচ্ছি যে প্রার্থীর সংখ্যা কমানোর জন্য প্রথমে বিশেষ ভিত্তিক শিক্ষা ব্যবহার করে তাদের মানে বিভিন্ন ভিত্তিক পরিবর্তনের সুবিধা পুনরায় পাইপেলেনের সুবিধা রাখতে  এমএস ম্যার্কো পাসেজ এবং নথিপত্র রেঙ্কিং কাজে প্রয়োগ করা হয়েছে, আমরা একই স্তরে কার্যকর অর্জন করতে পারি, কিন্তু ১৮ জনের পর্যন্ত কার্যকর বৃদ্ধ তাছাড়াও, আমাদের প্রযুক্তিগুলো অন্যান্য পদ্ধতির প্রতি প্রযুক্তিগুলোর দ্বারা মনোযোগ প্রদান করা হয়েছে যে পরিবর্তনের সংক্রান্ত আক্ আমাদের কাজ থেকে একটি উচ্চপর্যায়ের বার্তা হচ্ছে যে যদিও আধুনিক আইআর ভূমিকায় পরিবর্তন করা হয়েছিল, তবুও ‘ঐতিহ্যবাহী’ এলটির প্রযুক্তির জন্য গুরুত্বপূর', 'fi': 'On hyvin tiedossa, että esikoulutettuihin muuntajamalleihin, kuten BERT, rakennetut uudelleenankkurit ovat parantaneet huomattavasti noutotehokkuutta monissa tehtävissä. Kuten monet tutkijat ovat todenneet, näiden hyötyjen tehokkuus on kuitenkin aiheuttanut huomattavia kustannuksia. Tässä työssä osoitetaan, että muuntajapohjaisten uudelleenankkureiden edut voidaan säilyttää monivaiheisessa uudelleenjärjestelyputkessa käyttämällä ensin ominaisuuspohjaisia learning-to-rank -tekniikoita, joilla vähennetään käsiteltävien ehdokasasiakirjojen määrää vaikuttamatta kielteisesti niiden laatuun takaisinkutsun kannalta. MS MARCO -läpikulku- ja asiakirjaranking-tehtäviin sovellettuna pystymme saavuttamaan saman tehokkuuden, mutta jopa 18 tehokkuuden lisäämisellä. Lisäksi tekniikkamme ovat suorakulmaisia muihin muuntajan päättelyn nopeuttamiseen keskittyneisiin menetelmiin nähden, joten niitä voidaan yhdistää entistä suuremmaksi hyötysuhteeksi. Korkeamman tason viesti työstämme on, että vaikka esikoulutetut muuntajat hallitsevat modernia IR-maisemaa, perinteisillä LTR-tekniikoilla on edelleen tärkeitä rooleja ja että historiaa ei pidä unohtaa.', 'et': 'On hästi teada, et eeltreenitud trafo mudelitele, nagu BERT, ehitatud ümberparandajad on paljude ülesannete puhul oluliselt parandanud taastamise efektiivsust. Nagu paljud teadlased märkisid, on selline kasu siiski kaasa toonud märkimisväärseid kulutusi tõhususe osas. Käesolevas töös näitame, et trafopõhiste ümberpankerite eeliseid on võimalik säilitada mitmeastmelises ümberpankimistorustikus, kasutades esmalt funktsioonipõhiseid õppimisvõtteid, et vähendada vaatlusaluste kandidaadidokumentide arvu, kahjustamata nende tagasivõtmise kvaliteeti. Rakendades MS MARCO läbipääsu ja dokumentide järjestamise ülesandeid, suudame saavutada sama tõhususe taseme, kuid kuni 18 tõhususe suurendamisega. Lisaks on meie tehnikad ortogonaalsed teiste meetoditega, mis keskenduvad trafo järelduste kiirendamisele, ja seega saab neid kombineerida veelgi suurema efektiivsuse saavutamiseks. Kõrgema taseme sõnum meie tööst on see, et kuigi tänapäevases infrapunamaastikus domineerivad eeltreenitud transformaatorid, on traditsioonilistel LTR-tehnikatel endiselt olulised rollid ning me ei tohiks ajalugu unustada.', 'bs': 'Dobro je poznato da su prebacivači izgrađeni na pretkišnim modelima transformera poput BERT dramatično poboljšali učinkovitost povratka u mnogim zadatkima. Međutim, te dobitke su došle na značajne troškove u smislu učinkovitosti, kao što je navelo mnogi istraživači. U ovom poslu, pokazujemo da je moguće zadržati koristi prebacivača na transformaciji u višefaznom prebacivanju cijevi, prvo koristeći tehnike učenja na liniji funkcija kako bi smanjili broj kandidatskih dokumenta u razmatranju bez negativnog utjecaja na njihovu kvalitetu u smislu sjećanja. Primjena na prolaz MS MARCO-a i zadatke za postizanje reda dokumenta, možemo postići isti nivo učinkovitosti, ali s povećanjem učinkovitosti do 18 godina. Nadalje, naše tehnike su ortogonalne na druge metode fokusirane na ubrzavanje infekcije transformera, i tako se mogu kombinirati za još veće dobiće učinkovitosti. Poruka sa višeg nivoa našeg posla je da, iako pretkivni transformatori dominaraju modernu IR pejzažu, još uvijek postoje važne uloge za tehnike LTR-a "tradicionalne" i da ne bi trebali zaboraviti povijest.', 'ca': "És ben conegut que els reorganitzadors construïts en models de transformador pré-entrenats com BERT han millorat dramàticament l'eficacia de recuperació en moltes tasques. Tot i així, aquests guanys han arribat a costos substancials en termes d'eficiència, com han observat molts investigadors. En aquesta feina, demostrem que és possible conservar els beneficis dels remolcadors basats en transformadors en un tub de remolc de múltiples etapes utilitzant primer tècniques d'aprenentatge a rangs basades en característiques per reduir el nombre de documents candidats considerats sense afectar negativament la seva qualitat en termes de recuperació. Applied to the MS MARCO passage and document ranking tasks, we are able to achieve the same level of effectiveness, but with up to 18 increase in efficiency.  Furthermore, our techniques are orthogonal to other methods focused on accelerating transformer inference, and thus can be combined for even greater efficiency gains.  A higher-level message from our work is that, even though pretrained transformers dominate the modern IR landscape, there are still important roles for 'traditional' LTR techniques, and that we should not forget history.", 'sk': 'Znano je, da so ponovni bankerji, zgrajeni na predtreniranih transformatorskih modelih, kot je BERT, dramatično izboljšali učinkovitost pridobivanja pri številnih nalogah. Vendar pa so te koristi povzročile znatne stroške v smislu učinkovitosti, kot so ugotovili številni raziskovalci. V tem delu smo pokazali, da je mogoče ohraniti prednosti transformatorskih ponovnih ankerjev v večstopenjskem cevovodu ponovnega ankerjanja z uporabo funkcijskih tehnik učenja-to-rank za zmanjšanje števila obravnavanih kandidatnih dokumentov brez negativnega vpliva na njihovo kakovost v smislu odpoklica. Z uporabo nalog prehoda MS MARCO in razvrščanja dokumentov lahko dosežemo enako stopnjo učinkovitosti, vendar z do 18 povečanjem učinkovitosti. Poleg tega so naše tehnike pravokotne z drugimi metodami, osredotočenimi na pospeševanje sklepanja transformatorjev, zato jih je mogoče kombinirati za še večje povečanje učinkovitosti. Sporočilo našega dela na višji ravni je, da čeprav v sodobni infrastrukturni pokrajini prevladujejo predtrenirani transformatorji, še vedno obstajajo pomembne vloge za "tradicionalne" tehnike LTR in da ne smemo pozabiti zgodovine.', 'he': 'ידוע היטב שבנוסעים מחדש בנויים על דוגמנים משתנים מלפנים כמו BERT השתפרו באופן דרמטי את יעילות ההחזרה במשימות רבות. בכל אופן, הרווחים האלה הגיעו בעלות משמעותיות בנוגע ליכולת, כפי שנבדק על ידי חוקרים רבים. In this work, we show that it is possible to retain the benefits of transformer-based rerankers in a multi-stage reranking pipeline by first using feature-based learning-to-rank techniques to reduce the number of candidate documents under consideration without adversely affecting their quality in terms of recall.  שימוש במעבר של MS MARCO ומסמכים מסווגים משימות, אנחנו מסוגלים להשיג את אותו רמה של יעילות, אבל עם עד 18 גיבוי יעילות. חוץ מזה, הטכניקות שלנו הן אורטוגוניות לשיטות אחרות שמוקדות על האיזמון ההנחה של המעבר, וכך הן יכולות להיות משולבות אפילו עבור תרוויות יעילות גדולות יותר. הודעה ברמה גבוהה יותר מהעבודה שלנו היא שלמרות שינויים מראש אימונים שולטים בנוף IR המודרני, עדיין יש תפקידים חשובים לטכניקות LTR "מסורתיות", ואנחנו לא צריכים לשכוח את ההיסטוריה.', 'jv': 'Punika dipunangé awak dhéwé éntuk mulai perusahaan anyar tentang karo model transformer, kaya BERT dumadhi kapan dadi nggawe barang nggawe barang apik dadi. Kamunyatan, akeh lan saiki akeh dumateng saiki akeh operasi layan, dadi jenis-jenis akeh stiker Nang iki trabah, kita ngomong nik ndelok iso nggawe bener liyane perusahaan nggawe nguasai perusahaan langgar bantayan seneng pisan multi-stajin Digawe nambah kanggo kalalah MARO lan dokumen sing wis ana dadi, kita ngubah iso dianggap perusahaan efek saiki, sane wis 18 pangusahaan efek politenessoffpolite"), and when there is a change ("assertive Masalah sing luwih-luwih sing mengko ning trabah awak dhéwé, tho, nik uwis transformer sing gak nggawe barang IR modèrn, iso diantesik ngupakan barang nggawe \'teknik LTR Tradisyon\' lan soko awak dhéwé kuwi mau kudu ngerti dadi.', 'ha': "An san wasu mutane da aka gina a kan misãlai da aka haramta su kamar BERT sun kyautata amfani da mataimaki cikin aikin mãsu yawa. A lokacin da waɗannan tufãfi sun zo da kima mai girma, kamar yadda mutane mãsu yawa suka faɗa. Daga wannan aikin, Munã nũna wa In a iya iya riƙe amfani da mai canza mai shige da shi a cikin mai sauri-duffai-duffai, da kuma a yi amfani da kowaci da aka amfani da kunnufi-zuwa-daraja, don ya ƙara ƙidãyar takardan kandanta wanda aka yi bincike da shi, kuma bã ya da sharri ga matsayinsu idan an tuna. Applied to the MARCO usage and document ranning tasks, za'a iya iya sãmun babban aiki daidai, amma idan an ƙara 18, za'a ƙãra fassaran. Furan haka, tufãtan mu masu motsi ne zuwa wasu hanyoyin dabam-dabam, ana yi makõmi ga saukarwa wa kasar hanyarwa na transformer, kuma kan ta koma ko da mafiya amfani da akansa. Wata maganar daraja daga aikinmu yana cẽwa, kuma kõ da yaushe aka aibanta transformarin na domin ƙasar IR na yanzu, sai na da kima muhimu ga `watani' na LTR, kuma kada mu manta historian.", 'bo': 'BERT(BERT)བཟོ་བཅོས་མཁན་གྱི་མིག་སྔ་ལྟར་བཟོ་བར་བཀོད་པ་ལྟ་བུ་ཆགས་པ་ཞིག་ཡིན་པ་ལྟ་བུ་བཏུབ་པས། ཡིན་ནའང་། རྒྱལ་ཁབ་འདི་དག་གི་ལས་སྐྱོན་འབྲེལ་བ་མང་པོ་ཞིག་གིས་མཐོང་སྟེ། In this work, we show that it is possible to retain the benefits of transformer-based rerankers in a multi-stage reranking pipeline by first using feature-based learning-to-rank techniques to reduce the number of candidate documents under consideration without adversely affecting their quality in terms of recall. MS MARCO གཡུལ་འགྲུལ་སྐྱོད་དང་ཡིག་ཆ་ལ་འཇུག་གི་བྱ་འགུལ་ལ་འཇུག་སྤྱོད་ཐུབ་པ་ཡིན་ནའང་ཚད་གཅིག འོན་ཀྱང་། ང་ཚོའི་ལམ་ལུགས་འདི་ལ་ཐབས་ལམ་གཞན་ཞིག་གིས་མདངས་བསྐྱེད་པའི་བརྒྱུད་རྐྱེན་ཚད་ལ་དམིགས་གཏོང་བྱེད་ཀྱི་ཡོད། ང་ཚོའི་ལས་ཀྱི་འཕྲིན་དོན་ལས་མཐོ་དཀའ་ངལ་ཞིག་ཡོད་པའི་ཆེ་འཕྲིན་ཡིག་ཆ་ནི།'}
{'en': 'Distiller : A Systematic Study of Model Distillation Methods in Natural Language Processing', 'ar': 'Distiller: دراسة منهجية لطرق التقطير النموذجية في معالجة اللغة الطبيعية', 'pt': 'Distiller: Um Estudo Sistemático de Métodos de Destilação de Modelos em Processamento de Linguagem Natural', 'es': 'Distiller: un estudio sistemático de métodos de destilación modelo en el procesamiento del lenguaje natural', 'fr': 'Distiller\xa0: étude systématique des méthodes de distillation modèles dans le traitement du langage naturel', 'ja': '蒸留器：自然言語処理におけるモデル蒸留法の体系的研究', 'zh': '蒸馏器曰:自然语言治中蒸馏法者治之', 'hi': 'डिस्टिलर: प्राकृतिक भाषा प्रसंस्करण में मॉडल आसवन विधियों का एक व्यवस्थित अध्ययन', 'ru': 'Дистиллятор: систематическое исследование типовых методов дистилляции при обработке на естественном языке', 'ga': 'Driogaire: Staidéar Córasach ar Mhodhanna Driogtha Samhla i bPróiseáil Teanga Nádúrtha', 'ka': 'დისტილერი: მოდელური განსხვავება მეტოდომის სისტემალური შესწავლობა Natural Language Processing', 'el': 'Αποστολέας: Μια συστηματική μελέτη μοντέλων μεθόδων απόσταξης στην επεξεργασία φυσικής γλώσσας', 'hu': 'Desztilláló: Modelldesztillációs módszerek szisztematikus vizsgálata a természetes nyelv feldolgozásában', 'it': "Distillatore: uno studio sistematico dei metodi di distillazione modello nell'elaborazione del linguaggio naturale", 'kk': 'Дистиллер: Түзіндік тіл процессерінде модель өшіру әдістерін жүйесі зерттеу', 'lt': 'Distiliatorius: Sisteminis modelių distiliavimo metodų gamtinės kalbos apdorojimo tyrimas', 'mk': 'Дистилер: Систематска студија на моделните методи за дистилација во природното обработување јазик', 'ms': 'Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing', 'ml': 'ഡിസ്റ്റിലേര്\u200d: സ്വാഭാവ ഭാഷ പ്രവര്\u200dത്തിപ്പിക്കുന്നതില്\u200d മോഡല്\u200d ഡിസ്റ്റിലേഷന്\u200d രീതികളുടെ സിസ്റ്റിമാ', 'mt': 'Distiller: Studju Sistematiku tal-Metodi ta’ Distillazzjoni Mudell fl-Ipproċessar tal-Lingwi Naturali', 'mn': 'Өтгөнч: Байгалийн хэл үйлдвэрлэлийн загварын загварын систематикийн судалгаа', 'no': 'Distiller: Eit systematisk studie av modeller forstyringsmetodar i naturspråk', 'pl': 'Destylator: Systematyczne badanie modelowych metod destylacji w przetwarzaniu języka naturalnego', 'ro': 'Distilator: Un studiu sistematic al metodelor de distilare model în procesarea limbajului natural', 'sr': 'Distiller: Sistemno istraživanje metoda destilacije modela u procesu prirodnog jezika', 'si': 'ස්වභාවික භාෂාව ප්\u200dරක්\u200dරියාසයේ සිස්ටමික පරීක්ෂණය', 'so': 'Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing', 'sv': 'Destiller: En systematisk studie av modelldestillationsmetoder vid behandling av naturligt språk', 'ta': 'டிஸ்டில்டர்: இயல்பான மொழி செயல்பாடு', 'ur': 'ڈیسٹیلر: ایک سیستم تحقیق ماڈل ڈیسٹیلس طریقے کی طبیعی زبان پرسس میں', 'uz': 'Distiller: Name', 'vi': 'Tiểu dịch: A Systematic study of Model disllation Methods in Natural language treatment', 'bg': 'Дестилер: Систематично изследване на моделните методи за дестилация в естествената езикова обработка', 'nl': 'Distiller: Een systematische studie van modeldestilleringsmethoden in de verwerking van natuurlijke taal', 'da': 'Destiller: En systematisk undersøgelse af modeldestillationsmetoder i naturlig sprogbehandling', 'hr': 'Distiller: Sistemno ispitivanje metoda destilacije modela u procesu prirodnog jezika', 'de': 'Distiller: Eine systematische Untersuchung von Modelldestillationsmethoden in der Verarbeitung natürlicher Sprache', 'ko': '증류기: 자연 언어 처리 중 모형 증류 방법의 체계적 연구', 'id': 'Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing', 'fa': 'Distiller: A systematic study of Model Distillation Methods in Natural Language Processing', 'sq': 'Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing', 'af': 'Distiller: 芒聙聶n Sistemiese Studie van Model Distillation Methodes in Natuurlike Taal Prosessering', 'am': 'Distiller: A Systematic Study of Model Distillation Methods in Natural language Processing', 'sw': 'Mchezaji: Utafiti wa Mfumo wa Utafiti wa Utoaji wa Modeli katika Utafiti wa lugha ya asili', 'tr': 'Daýratçy: A sistem Study of Model Distillation Methods in Natural Language Processing', 'hy': 'Դիստիլեր: Բնական լեզվի մշակում գտնվող մոդելների դիստիլացիայի համակարգչային ուսումնասիրություն', 'az': 'Distiller: T…ôbi…ôtli Dil ƒ∞≈ül…ôm…ôsind…ô Model Distillation Methods Sistem √ñyr…ônm…ôsi', 'bs': 'Distiller: Sistemno ispitivanje metoda destilacije modela u procesu prirodnog jezika', 'bn': 'ডিস্টিলার: প্রাকৃতিক ভাষা প্রক্রিয়ার মোডেল ডিস্টিলেশনের একটি সিস্টেমিক গবেষণা', 'et': 'Destiller: loodusliku keele töötlemise mudelite destilleerimismeetodite süstemaatiline uuring', 'ca': 'Destillador: Un estudi sistemàtic de mètodes de destilació model en el processament de llenguatges naturals', 'cs': 'Distiller: Systematické studium modelových destilačních metod ve zpracování přirozeného jazyka', 'fi': 'Distiller: Systemaattinen tutkimus mallitislausmenetelmistĂ¤ luonnollisen kielen prosessoinnissa', 'ha': 'Dakatar: A Systematic Research of Model Dislitation Method in Natural language', 'he': 'דסטילר: מחקר מערכתי של שיטות דגמניות בתהליך שפת טבעית', 'bo': 'Distiller: A sistem study of Model Distillation Methods in Natural Language Processing', 'jv': 'Distil: A Sistem Learn of model Distiltion Methods in Normal Language Proceding', 'sk': 'Destilar: Sistematična študija modelnih destilacijskih metod v obdelavi naravnega jezika'}
{'en': 'Knowledge Distillation (KD) offers a natural way to reduce the latency and memory / energy usage of massive pretrained models that have come to dominate Natural Language Processing (NLP) in recent years. While numerous sophisticated variants of KD algorithms have been proposed for NLP applications, the key factors underpinning the optimal distillation performance are often confounded and remain unclear. We aim to identify how different components in the KD pipeline affect the resulting performance and how much the optimal KD pipeline varies across different datasets / tasks, such as the data augmentation policy, the loss function, and the intermediate representation for transferring the knowledge between teacher and student. To tease apart their effects, we propose Distiller, a meta KD framework that systematically combines a broad range of techniques across different stages of the KD pipeline, which enables us to quantify each component’s contribution. Within Distiller, we unify commonly used objectives for distillation of intermediate representations under a universal mutual information (MI) objective and propose a class of MI-objective functions with better bias / variance trade-off for estimating the MI between the teacher and the student. On a diverse set of NLP datasets, the best Distiller configurations are identified via large-scale hyper-parameter optimization. Our experiments reveal the following : 1) the approach used to distill the intermediate representations is the most important factor in KD performance, 2) among different objectives for intermediate distillation, MI-performs the best, and 3) data augmentation provides a large boost for small training datasets or small student networks.', 'pt': 'A Destilação de Conhecimento (KD) oferece uma maneira natural de reduzir a latência e o uso de memória/energia de modelos massivos pré-treinados que dominaram o Processamento de Linguagem Natural (NLP) nos últimos anos. Embora inúmeras variantes sofisticadas de algoritmos KD tenham sido propostas para aplicações de PNL, os principais fatores que sustentam o desempenho ideal da destilação são frequentemente confusos e permanecem obscuros. Nosso objetivo é identificar como os diferentes componentes no pipeline de KD afetam o desempenho resultante e quanto o pipeline de KD ideal varia em diferentes conjuntos de dados/tarefas, como a política de aumento de dados, a função de perda e a representação intermediária para transferir o conhecimento entre professores e estudante. Para destrinchar seus efeitos, propomos o Distiller, uma estrutura de meta KD que combina sistematicamente uma ampla gama de técnicas em diferentes estágios do pipeline de KD, o que nos permite quantificar a contribuição de cada componente. Dentro do Distiller, unificamos os objetivos comumente usados para a destilação de representações intermediárias sob um objetivo de informação mútua universal (MI) e propomos uma classe de funções objetivo MI com melhor compensação de viés/variância para estimar o MI entre o professor e o aluno. Em um conjunto diversificado de conjuntos de dados NLP, as melhores configurações do Distiller são identificadas por meio da otimização de hiperparâmetros em grande escala. Nossos experimentos revelam o seguinte: 1) a abordagem usada para destilar as representações intermediárias é a\nfator mais importante no desempenho de KD, 2) entre os diferentes objetivos para destilação intermediária, o MI tem o melhor desempenho e 3) o aumento de dados fornece um grande impulso para pequenos conjuntos de dados de treinamento ou pequenas redes de alunos. Além disso, descobrimos que conjuntos de dados/tarefas diferentes preferem algoritmos KD diferentes e, portanto, propomos um algoritmo AutoDistiller simples que pode recomendar um bom pipeline de KD para um novo conjunto de dados.', 'es': 'La destilación del conocimiento (KD) ofrece una forma natural de reducir la latencia y el uso de memoria/energía de los modelos preentrenados masivos que han llegado a dominar el procesamiento del lenguaje natural (NLP) en los últimos años. Si bien se han propuesto numerosas variantes sofisticadas de algoritmos de KD para aplicaciones de PNL, los factores clave que sustentan el rendimiento óptimo de la destilación a menudo se confunden y no están claros. Nuestro objetivo es identificar cómo los diferentes componentes de la canalización de KD afectan al rendimiento resultante y cuánto varía la canalización de KD óptima entre los diferentes conjuntos de datos/tareas, como la política de aumento de datos, la función de pérdida y la representación intermedia para transferir el conocimiento entre profesores y estudiante. Para diferenciar sus efectos, proponemos Distiller, un marco meta KD que combina sistemáticamente una amplia gama de técnicas en diferentes etapas del proceso de KD, lo que nos permite cuantificar la contribución de cada componente. Dentro de Distiller, unificamos los objetivos de uso común para la destilación de representaciones intermedias bajo un objetivo de información mutua universal (IM) y proponemos una clase de funciones de objetivo de IM con una mejor compensación de sesgo/varianza para estimar el IM entre el profesor y el estudiante. En un conjunto diverso de conjuntos de datos de PNL, las mejores configuraciones de Distiller se identifican mediante la optimización de hiperparámetros a gran escala. Nuestros experimentos revelan lo siguiente: 1) el enfoque utilizado para destilar las representaciones intermedias es el\nfactor más importante en el rendimiento de KD, 2) entre los diferentes objetivos para la destilación intermedia, MI funciona mejor, y 3) el aumento de datos proporciona un gran impulso para pequeños conjuntos de datos de capacitación o redes de estudiantes pequeños. Además, descubrimos que diferentes conjuntos de datos/tareas prefieren diferentes algoritmos de KD y, por lo tanto, proponemos un algoritmo de AutoDistiller simple que puede recomendar una buena canalización de KD para un nuevo conjunto de datos.', 'ja': 'ナレッジ蒸留（ KD ）は、近年自然言語処理（ NLP ）を支配するようになった大規模な事前訓練済みモデルのレイテンシとメモリ/エネルギー使用量を削減する自然な方法を提供します。 ＫＤアルゴリズムの多くの洗練されたバリアントは、ＮＬＰ用途に提案されているが、最適な蒸留性能を支える主要な要因はしばしば混乱し、不明なままである。 KDパイプラインのさまざまなコンポーネントが結果のパフォーマンスにどのように影響するか、データ拡張ポリシー、損失関数、教師と生徒の間で知識を転送するための中間表現など、さまざまなデータセット/タスク間で最適なKDパイプラインがどの程度変化するかを特定することを目的としています。 その効果を説明するために、KDパイプラインのさまざまな段階にわたって幅広いテクニックを体系的に組み合わせるメタKDフレームワークであるDistillerを提案します。これにより、各コンポーネントの貢献度を定量化できます。 Distiller内では、中間表現の蒸留のために一般的に使用される目的を普遍的相互情報（ MI ）目的の下で統一し、教師と生徒間のMIを推定するためのより良いバイアス/分散トレードオフを伴うMI -目的関数のクラスを提案します。 多様なNLPデータセットでは、大規模なハイパーパラメータ最適化を介して最良のディスティラー構成が特定されます。 私たちの実験は、以下を明らかにします： 1 ）中間表現を蒸留するために使用されるアプローチは、\nkDパフォーマンスの最も重要な要因は、2 ）中間蒸留のさまざまな目標のうち、MI -パフォーマンスが最も優れていること、および3 ）データ拡張が小さなトレーニングデータセットまたは小さな学生ネットワークに大きなブーストを提供することです。さらに、異なるデータセット/タスクは異なるKDアルゴリズムを好むため、新しいデータセットに良いKDパイプラインを推奨できる簡単なAutoDistillerアルゴリズムを提案しています。', 'ar': 'يوفر تقطير المعرفة (KD) طريقة طبيعية لتقليل زمن الوصول واستخدام الذاكرة / الطاقة للنماذج الضخمة سابقة التدريب التي أصبحت تهيمن على معالجة اللغة الطبيعية (NLP) في السنوات الأخيرة. بينما تم اقتراح العديد من المتغيرات المعقدة لخوارزميات KD لتطبيقات البرمجة اللغوية العصبية ، غالبًا ما تكون العوامل الرئيسية التي يقوم عليها أداء التقطير الأمثل مرتبكة وتظل غير واضحة. نهدف إلى تحديد كيفية تأثير المكونات المختلفة في خط أنابيب KD على الأداء الناتج ومدى اختلاف خط أنابيب KD الأمثل عبر مجموعات البيانات / المهام المختلفة ، مثل سياسة زيادة البيانات ، ووظيفة الخسارة ، والتمثيل الوسيط لنقل المعرفة بين المعلم وطالب. لفصل آثارها ، نقترح Distiller ، إطار عمل Meta KD يجمع بشكل منهجي مجموعة واسعة من التقنيات عبر مراحل مختلفة من خط أنابيب KD ، والتي تمكننا من تحديد مساهمة كل مكون. ضمن Distiller ، نقوم بتوحيد الأهداف شائعة الاستخدام لتقطير التمثيلات الوسيطة تحت هدف معلومات متبادلة عالمية (MI) ونقترح فئة من وظائف MI- الموضوعية مع مفاضلة أفضل للانحياز / التباين لتقدير MI بين المعلم والطالب. في مجموعة متنوعة من مجموعات بيانات البرمجة اللغوية العصبية ، يتم تحديد أفضل تكوينات Distiller من خلال تحسين المعلمات المفرطة على نطاق واسع. تكشف تجاربنا ما يلي: 1) النهج المستخدم لتقطير التمثيلات الوسيطة هو\nالعامل الأكثر أهمية في أداء KD ، 2) من بين الأهداف المختلفة للتقطير المتوسط ، MI- يؤدي الأفضل ، و 3) زيادة البيانات توفر دفعة كبيرة لمجموعات بيانات التدريب الصغيرة أو شبكات الطلاب الصغيرة. علاوة على ذلك ، وجدنا أن مجموعات البيانات / المهام المختلفة تفضل خوارزميات KD مختلفة ، وبالتالي نقترح خوارزمية AutoDistiller بسيطة يمكن أن توصي بخط أنابيب KD جيد لمجموعة بيانات جديدة.', 'fr': "La distillation des connaissances (KD) offre un moyen naturel de réduire la latence et la consommation mémoire/énergie des modèles préentraînés massifs qui ont fini par dominer le traitement du langage naturel (NLP) ces dernières années. Alors que de nombreuses variantes sophistiquées des algorithmes KD ont été proposées pour les applications NLP, les facteurs clés qui sous-tendent les performances de distillation optimales sont souvent confondus et restent flous. Nous visons à identifier comment les différents composants du pipeline KD affectent les performances résultantes et dans quelle mesure le pipeline KD optimal varie selon les différentes données/tâches, telles que la politique d'augmentation des données, la fonction de perte et la représentation intermédiaire pour le transfert des connaissances entre enseignants et étudiant. Pour différencier leurs effets, nous proposons Distiller, un framework Meta KD qui combine systématiquement un large éventail de techniques à différentes étapes du pipeline KD, ce qui nous permet de quantifier la contribution de chaque composant. Au sein de Distiller, nous unifions les objectifs couramment utilisés pour la distillation de représentations intermédiaires sous un objectif d'information mutuelle universelle (MI) et proposons une classe de fonctions d'objectif MI avec un meilleur compromis biais/variance pour estimer l'IM entre l'enseignant et l'élève. Sur un ensemble diversifié de jeux de données NLP, les meilleures configurations Distiller sont identifiées via une optimisation hyperparamétrique à grande échelle. Nos expériences révèlent ce qui suit\xa0: 1) l'approche utilisée pour distiller les représentations intermédiaires est la\nfacteur le plus important dans la performance du KD, 2) parmi les différents objectifs pour la distillation intermédiaire, MI fonctionne le mieux, et 3) l'augmentation des données fournit un gros coup de pouce pour les petits ensembles de données d'entraînement ou les petits réseaux d'étudiants. De plus, nous constatons que différents données/tâches préfèrent différents algorithmes KD, et proposons donc un algorithme AutoDistiller simple qui peut recommander un bon pipeline KD pour un nouveau jeu de données.", 'zh': '知蒸馏(KD)自然以省近年主导自然语言处(NLP)之多预练模范之迟内存/可用。 虽已为NLP多KD算法之变体,而扶持最佳蒸馏性关键因素往往令人困惑,且未详也。 吾等所向定KD管道之异组件何以加之性能,及至佳KD管道在集/之差,如数增策,损函数及在师徒之间。 为理其化,吾发Distler,此一元KD框架,系统地合KD道之广,使吾能量化组件之功。 Distiller之中,一其通用,以互信息(MI)其中,举其类MI函数,有善倚/方差权衡,以度师徒之MI。 异NLP数集上,大超参数优化以识蒸馏器。 吾实验揭示以下内容:1)以炼中为法\nKD性之大者,2)在中蒸馏之中,MI-性最佳,及3)数增强为小练数集及小生网络供大推动力。 又见异数集/更喜异KD算法,故建一简AutoDistiller算法,可为新数集荐一善KD管道。', 'ru': 'Дистилляция знаний (KD) предлагает естественный способ уменьшить задержку и потребление памяти/энергии массовыми предварительно обученными моделями, которые стали доминировать в обработке естественного языка (NLP) в последние годы. Хотя для приложений NLP были предложены многочисленные сложные варианты алгоритмов KD, ключевые факторы, лежащие в основе оптимальной производительности дистилляции, часто путаются и остаются неясными. Мы стремимся определить, как различные компоненты в конвейере KD влияют на результирующую производительность и насколько оптимальный конвейер KD варьируется между различными наборами данных/задачами, такими как политика дополнения данных, функция потерь и промежуточное представление для передачи знаний между учителем и учеником. Чтобы разделить их эффекты, мы предлагаем Distiller, мета KD фреймворк, который систематически объединяет широкий спектр методов на различных этапах KD трубопровода, что позволяет нам количественно оценить вклад каждого компонента. В рамках Distiller мы унифицируем широко используемые цели для дистилляции промежуточных представлений в рамках универсальной цели взаимной информации (MI) и предлагаем класс MI-объективных функций с лучшим компромиссом смещения/дисперсии для оценки MI между преподавателем и студентом. На различных наборах данных NLP лучшие конфигурации дистиллятора определяются с помощью крупномасштабной оптимизации гиперпараметров. Наши эксперименты показывают следующее: 1) подход, используемый для дистилляции промежуточных представлений,\nнаиболее важным фактором в эффективности KD, 2) среди различных целей для промежуточной дистилляции, MI-эффекты лучшие, и 3) увеличение данных обеспечивает большой импульс для небольших наборов данных обучения или небольших студенческих сетей. Кроме того, мы обнаружили, что различные наборы данных/задачи предпочитают разные алгоритмы KD, и поэтому предлагаем простой алгоритм AutoDistiller, который может рекомендовать хороший конвейер KD для нового набора данных.', 'hi': 'नॉलेज आसवन (केडी) बड़े पैमाने पर पूर्व-प्रशिक्षित मॉडल की विलंबता और स्मृति / ऊर्जा उपयोग को कम करने का एक प्राकृतिक तरीका प्रदान करता है जो हाल के वर्षों में प्राकृतिक भाषा प्रसंस्करण (एनएलपी) पर हावी हो गए हैं। जबकि एनएलपी अनुप्रयोगों के लिए केडी एल्गोरिदम के कई परिष्कृत रूपों का प्रस्ताव किया गया है, इष्टतम आसवन प्रदर्शन को रेखांकित करने वाले प्रमुख कारक अक्सर भ्रमित होते हैं और अस्पष्ट रहते हैं। हम यह पहचानने का लक्ष्य रखते हैं कि केडी पाइपलाइन में विभिन्न घटक परिणामी प्रदर्शन को कैसे प्रभावित करते हैं और इष्टतम केडी पाइपलाइन विभिन्न डेटासेट / कार्यों में कितना भिन्न होती है, जैसे कि डेटा संवर्धन नीति, हानि समारोह, और शिक्षक और छात्र के बीच ज्ञान को स्थानांतरित करने के लिए मध्यवर्ती प्रतिनिधित्व। उनके प्रभावों को अलग करने के लिए, हम डिस्टिलर का प्रस्ताव करते हैं, एक मेटा केडी फ्रेमवर्क जो व्यवस्थित रूप से केडी पाइपलाइन के विभिन्न चरणों में तकनीकों की एक विस्तृत श्रृंखला को जोड़ता है, जो हमें प्रत्येक घटक के योगदान को मापने में सक्षम बनाता है। डिस्टिलर के भीतर, हम एक सार्वभौमिक पारस्परिक जानकारी (एमआई) उद्देश्य के तहत मध्यवर्ती प्रतिनिधित्व के आसवन के लिए आमतौर पर उपयोग किए जाने वाले उद्देश्यों को एकजुट करते हैं और शिक्षक और छात्र के बीच एमआई का अनुमान लगाने के लिए बेहतर पूर्वाग्रह / विचरण ट्रेड-ऑफ के साथ एमआई-उद्देश्य कार्यों के एक वर्ग का प्रस्ताव करते हैं। एनएलपी डेटासेट के एक विविध सेट पर, सबसे अच्छा डिस्टिलर कॉन्फ़िगरेशन बड़े पैमाने पर हाइपर-पैरामीटर अनुकूलन के माध्यम से पहचाना जाता है। हमारे प्रयोगों से निम्नलिखित का पता चलता है: 1) मध्यवर्ती अभ्यावेदन को डिस्टिल करने के लिए उपयोग किया जाने वाला दृष्टिकोण क्या है?\nकेडी प्रदर्शन में सबसे महत्वपूर्ण कारक, 2) मध्यवर्ती आसवन के लिए विभिन्न उद्देश्यों के बीच, एमआई-सबसे अच्छा प्रदर्शन करता है, और 3) डेटा वृद्धि छोटे प्रशिक्षण डेटासेट या छोटे छात्र नेटवर्क के लिए एक बड़ा बढ़ावा प्रदान करती है। इसके अलावा, हम पाते हैं कि विभिन्न डेटासेट / कार्य विभिन्न केडी एल्गोरिदम पसंद करते हैं, और इस प्रकार एक साधारण ऑटोडिस्टिलर एल्गोरिथ्म का प्रस्ताव करते हैं जो एक नए डेटासेट के लिए एक अच्छी केडी पाइपलाइन की सिफारिश कर सकता है।', 'ga': 'Cuireann Driogadh Eolais (KD) bealach nádúrtha ar fáil chun foighne agus cuimhne/úsáid fuinnimh na múnlaí ollmhóra réamhoilte atá tagtha chun tosaigh i bPróiseáil Teanga Nádúrtha (NLP) le blianta beaga anuas a laghdú. Cé go bhfuil go leor leaganacha sofaisticiúla de algartam KD molta d’fheidhmchláir NLP, is minic a bhíonn mearbhall ar na príomhfhachtóirí atá mar bhonn agus mar thaca ag an bhfeidhmíocht driogtha is fearr agus ní léir go fóill. Tá sé mar aidhm againn a aithint conas a théann comhpháirteanna éagsúla sa phíblíne KD i bhfeidhm ar an bhfeidhmíocht dá bharr agus cé chomh mór agus a athraíonn an phíblíne KD optamach thar thacair sonraí/tascanna éagsúla, mar shampla an polasaí méadaithe sonraí, an fheidhm chaillteanais, agus an ionadaíocht idirmheánach chun an t-eolas a aistriú idir an múinteoir. agus dalta. Chun a n-éifeachtaí a bhaint astu, molaimid Drioglann, creat meta KD a chomhcheanglaíonn go córasach raon leathan teicnící thar chéimeanna éagsúla den phíblíne KD, a chuireann ar ár gcumas rannchuidiú gach comhpháirte a chainníochtú. Laistigh de driogaire, déanaimid cuspóirí a úsáidtear go coitianta le haghaidh driogadh léirithe idirmheánacha a aontú faoi chuspóir uilíoch faisnéise frithpháirteach (MI) agus molaimid aicme feidhmeanna MI-oibiachtúla le comhbhabhtáil níos fearr le claonas/athraitheas chun an MI idir an múinteoir agus an mac léinn a mheas. Ar shraith éagsúil de thacair sonraí NLP, sainaithnítear na cumraíochtaí Driogaire is fearr trí bharrfheabhsú hipearpharaiméadair ar scála mór. Léiríonn ár dturgnaimh na nithe seo a leanas: 1) is é an cur chuige a úsáidtear chun na hionadaíochtaí idirmheánacha a dhriogadh\nfachtóir is tábhachtaí i bhfeidhmíocht KD, 2) i measc cuspóirí éagsúla do dhriogadh idirmheánach, MI-feidhmíonn an chuid is fearr, agus 3) cuireann méadú sonraí borradh mór do thacair sonraí oiliúna beag nó líonraí mac léinn beag. Ina theannta sin, feicimid gur fearr le tacair shonraí/tascanna éagsúla halgartaim KD éagsúla, agus mar sin molaimid algartam AutoDistiller simplí a fhéadfaidh píblíne maith KD a mholadh le haghaidh tacar sonraí nua.', 'it': "Knowledge Distillation (KD) offre un modo naturale per ridurre la latenza e l'uso di memoria/energia di enormi modelli pre-addestrati che sono arrivati a dominare Natural Language Processing (NLP) negli ultimi anni. Mentre numerose varianti sofisticate di algoritmi KD sono state proposte per le applicazioni NLP, i fattori chiave alla base delle prestazioni ottimali di distillazione sono spesso confusi e rimangono poco chiari. Il nostro obiettivo è identificare come i diversi componenti della pipeline KD influenzano le prestazioni risultanti e quanto la pipeline KD ottimale varia tra diversi set di dati / attività, come la politica di aumento dei dati, la funzione di perdita e la rappresentazione intermedia per il trasferimento delle conoscenze tra insegnante e studente. Per stuzzicare i loro effetti, proponiamo Distiller, un framework meta KD che combina sistematicamente una vasta gamma di tecniche attraverso le diverse fasi della pipeline KD, che ci permette di quantificare il contributo di ogni componente. All'interno di Distiller, uniamo gli obiettivi comunemente usati per la distillazione di rappresentazioni intermedie sotto un obiettivo universale di informazione reciproca (MI) e proponiamo una classe di funzioni MI-obiettivo con un miglior compromesso bias / variance per stimare l'MI tra l'insegnante e lo studente. Su un insieme diversificato di set di dati NLP, le migliori configurazioni Distiller vengono identificate tramite l'ottimizzazione su larga scala degli iper-parametri. I nostri esperimenti rivelano quanto segue: 1) l'approccio utilizzato per distillare le rappresentazioni intermedie è il\nIl fattore più importante nelle prestazioni KD, 2) tra i diversi obiettivi per la distillazione intermedia, MI-esegue il meglio, e 3) l'aumento dei dati fornisce un grande impulso per piccoli set di dati di formazione o piccole reti di studenti. Inoltre, troviamo che diversi dataset/task preferiscono diversi algoritmi KD, e quindi proponiamo un semplice algoritmo AutoDistiller che può consigliare una buona pipeline KD per un nuovo dataset.", 'el': 'Η απόσταξη γνώσης (ΚΔ) προσφέρει έναν φυσικό τρόπο για τη μείωση της καθυστέρησης και της χρήσης μνήμης/ενέργειας μαζικών προ-εκπαιδευμένων μοντέλων που έχουν αρχίσει να κυριαρχούν στην επεξεργασία φυσικής γλώσσας τα τελευταία χρόνια. Ενώ πολλές εξελιγμένες παραλλαγές αλγορίθμων KD έχουν προταθεί για εφαρμογές NLP, οι βασικοί παράγοντες που στηρίζουν τη βέλτιστη απόδοση απόσταξης συχνά μπερδεύονται και παραμένουν ασαφής. Στόχος μας είναι να προσδιορίσουμε πώς διαφορετικά συστατικά στον αγωγό επηρεάζουν την προκύπτουσα απόδοση και πόσο ο βέλτιστος αγωγός ποικίλλει μεταξύ διαφορετικών συνόλων δεδομένων/εργασιών, όπως η πολιτική αύξησης δεδομένων, η λειτουργία απώλειας και η ενδιάμεση αναπαράσταση για τη μεταφορά της γνώσης μεταξύ εκπαιδευτικού και μαθητή. Για να διαχωρίσουμε τα αποτελέσματά τους, προτείνουμε ένα πλαίσιο που συνδυάζει συστηματικά ένα ευρύ φάσμα τεχνικών σε διάφορα στάδια του αγωγού το οποίο μας επιτρέπει να ποσοτικοποιήσουμε τη συνεισφορά κάθε συστατικού. Στο πλαίσιο της ενοποιούμε κοινώς χρησιμοποιούμενους στόχους για την απόσταξη ενδιάμεσων αναπαραστάσεων με στόχο καθολικής αμοιβαίας πληροφόρησης (MI) και προτείνουμε μια κατηγορία αντικειμενικών λειτουργιών με καλύτερη προκατάληψη/διακύμανση για την εκτίμηση της MI μεταξύ του εκπαιδευτικού και του μαθητή. Σε ένα ποικίλο σύνολο δεδομένων εντοπίζονται οι καλύτερες διαμορφώσεις απόσταξης μέσω μεγάλης κλίμακας βελτιστοποίησης υπερπαραμέτρων. Τα πειράματά μας αποκαλύπτουν τα εξής: 1) η προσέγγιση που χρησιμοποιείται για την απόσταξη των ενδιάμεσων αναπαραστάσεων είναι η\nΟ σημαντικότερος παράγοντας στην απόδοση του KD, 2) μεταξύ διαφορετικών στόχων για ενδιάμεση απόσταξη, η MI-αποδίδει την καλύτερη, και 3) η αύξηση δεδομένων παρέχει μια μεγάλη ώθηση για μικρά σύνολα δεδομένων κατάρτισης ή μικρά δίκτυα φοιτητών. Επιπλέον, διαπιστώνουμε ότι διαφορετικά σύνολα δεδομένων/εργασίες προτιμούν διαφορετικούς αλγόριθμους KD, και έτσι προτείνουμε έναν απλό αλγόριθμο που μπορεί να συστήσει έναν καλό αγωγό KD για ένα νέο σύνολο δεδομένων.', 'hu': 'A Knowledge Desztilláció (KD) természetes módja annak, hogy csökkentse a késleltetést és a memória/energiafelhasználást olyan masszív előkészített modellek esetében, amelyek az utóbbi években uralkodtak a Natural Language Processing (NLP). Míg a KD algoritmusok számos kifinomult változatát javasolták NLP alkalmazásokhoz, az optimális desztillációs teljesítményt alátámasztó kulcsfontosságú tényezők gyakran zavarosak és továbbra is tisztázatlanok. Célunk meghatározni, hogy a KD csővezeték különböző komponensei hogyan befolyásolják az eredményes teljesítményt, és mennyire változik az optimális KD csővezeték a különböző adatkészletek/feladatok között, mint például az adatnövelési politika, a veszteségfüggvény, valamint a tudás tanár és diák közötti átvitelére szolgáló közbenső reprezentáció. Hatásaik szétszórására javasoljuk a Distillert, egy meta KD keretrendszert, amely szisztematikusan kombinálja a technikák széles skáláját a KD pipeline különböző szakaszaiban, ami lehetővé teszi számunkra, hogy számszerűsítsük az egyes komponensek hozzájárulását. A Distilleren belül egységesítjük a köztes reprezentációk lepárlására vonatkozó általánosan használt célkitűzéseket egy univerzális kölcsönös információs (MI) célkitűzés keretében, és javasoljuk a MI-objektív funkciók osztályát, amelyek jobb elfogultság/variancia kompromisszumot biztosítanak a tanár és a hallgató közötti MI becslésére. A különböző NLP adatkészleteken a legjobb Distiller konfigurációkat nagyszabású hiperparaméterek optimalizálásával azonosítjuk. Kísérleteink a következőket fedik fel: 1) a közbenső reprezentációk desztillálására alkalmazott megközelítés a\nA KD teljesítményének legfontosabb tényezője, 2) a közbenső desztilláció különböző célkitűzései között az MI-teljesíti a legjobbat, és 3) az adatbővítés nagy lendületet biztosít a kis képzési adatok vagy kis diákhálózatok számára. Ezenkívül úgy találjuk, hogy a különböző adatkészletek/feladatok előnyben részesítik a különböző KD algoritmusokat, ezért javasoljuk egy egyszerű AutoDistiller algoritmust, amely egy jó KD csővezetéket ajánl egy új adatkészlethez.', 'ka': 'Name KD ალგორიტიმების ბევრი სოფისტიკური განრამეტრები NLP პროგრამებისთვის გაჩვენებულია, მაგრამ კლავიფიკური ფაქტორები, რომლებიც პოტიმალური დისტლიაციის გამოსახულებაში, ბევრი შემ ჩვენ მინდა იდენტიფიკაცია, როგორ განსხვავებული კომპონენტები KD-ის პერიოლინეში გამოცდილობას და როგორ განსხვავებული მონაცემების/დავალების განსხვავებას განსხვავებს KD-ის პერიოლინეტის განსხვავება, როგორც მონაცემების აგ მათი ეფექტების გაყოფილებისთვის, ჩვენ განვითარებთ Distiller, მეტა KD ფრამეტა, რომელიც სისტემატიკურად სისტემატიკურად გამოყენებს განსხვავებული ტექნოგიების განსხვავებული ფაეზების განსხვავებული ფაეზების განსხვავება Distiller-ში ჩვენ უბრალოდ გამოყენებული მიზეზეზების განსხვავებას უნივერსალური საერთო ინფორმაციის მიზეზი (MI) მიზეზით და მიზეზით MI-ობიექტიკური ფუნქციების კლასი, რომელიც უფრო უფრო წარმოადგენა/გარიანსი გარდა Name ჩვენი ექსპერიმენტები აღმოჩნდება:\nKD-ის უფრო მნიშვნელოვანი ფაქტორი, 2) განსხვავებული საზოგადომი განსხვავებაში, MI-ს უფრო მნიშვნელოვანია, და 3) მონაცემების აგგენტირება უფრო დიდი მეტი მონაცემების მონაცემებ დამატებით, ჩვენ აღმოჩნეთ, რომ განსხვავებული მონაცემები/დავალებები განსხვავებული KD ალგორიტემის მიზეზეზება, და ამიტომ შეგიძლიათ განსხვავებული მონაცემების ალგორიტემი, რომელიც შეუძლიათ', 'ml': 'അറിവ് ഡിസ്ട്രിലേഷന്\u200d (കെഡി) അടുത്ത വര്\u200dഷങ്ങളില്\u200d സ്വാഭാവിക ഭാഷയുടെ പ്രവര്\u200dത്തനത്തിനുള്ള പ്രക്രിയഭാഷ പ്രവര്\u200dത്തനത്തിനുവേണ്ടി വന്നിട്ടുള്ള പ്രക്രി എംഎല്\u200dപി പ്രയോഗങ്ങള്\u200dക്കായി കെഡി ആല്\u200dഗോരിത്മുകളുടെ പല സോഫിസ്റ്റിക്കേറ്റുകള്\u200d പ്രാര്\u200dത്ഥിക്കപ്പെട്ടിരിക്കുമ്പോള്\u200d, പ്രത്യേക വേ കെഡി പൈപ്പെലൈനിലെ വ്യത്യസ്ത ഭാഗങ്ങള്\u200d എങ്ങനെയാണ് പ്രഭാവം ബാധിക്കുന്നതെന്നും വ്യത്യസ്തമായ കെഡി പൈപ്പെലിന്\u200d വ്യത്യസ്ത ഡാറ്റാസറ്റുകള്\u200d അവയുടെ പ്രഭാവങ്ങള്\u200d വേര്\u200dതിരിക്കാന്\u200d ഞങ്ങള്\u200d ഡിസ്റ്റിലേറ്റര്\u200d, ഒരു മെറ്റാ കെഡി ഫ്രെയിമെറ്റ് ഫ്രെയിക്ക് ചെയ്യുന്നു. കെഡി പൈപ്പെലിനിന്റെ വ്യത്യസ്ത സ ഡിസ്റ്റിലേറ്റരില്\u200d, നമ്മള്\u200d സാധാരണ ഉപയോഗിച്ചിരിക്കുന്ന ലക്ഷ്യങ്ങള്\u200d ഒരു പ്രപഞ്ച വിവരങ്ങള്\u200dക്ക് വേര്\u200dപെടുത്താന്\u200d ഇടയിലുള്ള പ്രതിനിധികള്\u200dക്ക് വേര്\u200dപെടുത്താന്\u200d ഉപയോഗിക ഒരു വ്യത്യസ്ത കൂട്ടത്തില്\u200d NLP ഡേറ്റാസറ്റുകളില്\u200d, ഏറ്റവും നല്ല ഡിസ്റ്റിലേറ്റര്\u200d ക്രമീകരണങ്ങള്\u200d വലിയ ഹൈപ്പര്\u200d പാര്\u200dമീറ്റര്\u200d  നമ്മുടെ പരീക്ഷണങ്ങള്\u200d താഴെ വെളിപ്പെടുത്തുന്നു:\nകെഡിയിലെ പ്രകടനത്തിലെ ഏറ്റവും പ്രധാനപ്പെട്ട കാരണങ്ങള്\u200d, 2) തമ്മിലുള്ള വ്യത്യസ്ത ലക്ഷ്യങ്ങളില്\u200d, MI- പ്രവര്\u200dത്തിപ്പിക്കുന്നതില്\u200d ഏറ്റവും നല്ലത്, 3) ഡേറ്റ വ്യത്യസ്ത ഡേറ്റാസറ്റുകള്\u200d/ജോലികള്\u200dക്ക് വ്യത്യസ്ത കെഡി ആല്\u200dഗോരിത്മുകള്\u200d ഇഷ്ടപ്പെടുന്നു എന്ന് ഞങ്ങള്\u200d കണ്ടെത്തുന്നു. അതുകൊണ്ട് ഒരു സാധാ', 'mt': 'Id-Distillazzjoni tal-Għarfien (KD) toffri mod naturali biex titnaqqas it-latenza u l-użu tal-memorja/enerġija ta’ mudelli massivi mħarrġa minn qabel li ġew biex jiddominaw l-Ipproċessar tal-Lingwi Naturali (NLP) f’dawn l-a ħħar snin. Filwaqt li ġew proposti diversi varjanti sofistikati tal-algoritmi KD għall-applikazzjonijiet NLP, il-fatturi ewlenin li jsostnu l-prestazzjoni ottimali tad-distillazzjoni ta’ spiss huma mħallta u jibqgħu mhux ċari. Għandna l-għan li nidentifikaw kif komponenti differenti fil-pipeline KD jaffettwaw il-prestazzjoni li tirriżulta u kemm il-pipeline KD ottimali jvarja bejn settijiet/kompiti ta’ dejta differenti, bħall-politika ta’ żieda tad-dejta, il-funzjoni tat-telf, u r-rappreżentanza intermedja għat-trasferiment tal-għarfien bejn l-għalliema u l-istudenti. Biex niċċaraw l-effetti tagħhom, nipproponu Distiller, qafas meta KD li sistematikament jikkombina firxa wiesgħa ta’ tekniki fi stadji differenti tal-pipeline KD, li jippermettilna nkwantifikaw il-kontribut ta’ kull komponent. Fi ħdan id-Distiller, a ħna niunifikaw l-objettivi użati b’mod komuni għad-distillazzjoni ta’ rappreżentazzjonijiet intermedji taħt objettiv ta’ informazzjoni reċiproka universali (MI) u nipproponu klassi ta’ funzjonijiet oġġettivi MI b’kompromess aħjar ta’ preġudizzju/varjanza għall-istima tal-MI bejn l-għalliem u l-istudent. Fuq sett diversifikat ta’ settijiet ta’ dejta NLP, l-a ħjar konfigurazzjonijiet tad-Distiller huma identifikati permezz ta’ ottimizzazzjoni ta’ parametri iper fuq skala kbira. L-esperimenti tagħna juru dan li ġej:\nl-aktar fattur importanti fil-prestazzjoni tal-KD, 2) fost objettivi differenti għad-distillazzjoni intermedja, l-MI tagħmel l-a ħjar, u 3) iż-żieda fid-dejta tipprovdi spinta kbira għal settijiet żgħar ta’ dejta ta’ taħriġ jew netwerks żgħar ta’ studenti. Barra minn hekk, isibu li settijiet/kompiti ta’ dejta differenti jippreferu algoritmi KD differenti, u għalhekk jipproponu algoritmu sempliċi AutoDistiller li jista’ jirrakkomanda pipeline KD tajjeb għal sett ta’ dejta ġdid.', 'lt': 'Žinių distiliacija (angl. Knowledge Distillation, KD) siūlo natūralų būdą sumažinti didžiulių ikimokomų modelių, kurie pastaraisiais metais dominuoja gamtinių kalbų apdorojimu, latenciją ir atminties ir (arba) energijos naudojimą. Nors NLP taikymo srityse pasiūlyta daug sudėtingų KD algoritmų variantų, pagrindiniai veiksniai, kuriais grindžiamas optimalus distiliavimo veiksmingumas, dažnai susipainioja ir lieka neaiškūs. We aim to identify how different components in the KD pipeline affect the resulting performance and how much the optimal KD pipeline varies across different datasets/tasks, such as the data augmentation policy, the loss function, and the intermediate representation for transferring the knowledge between teacher and student.  Siekiant išskirti jų poveikį, siūlome Distiller, meta KD sistemą, sistemingai derinančią įvairius metodus įvairiuose KD vamzdyno etapuose, kurie leidžia mums kiekybiškai įvertinti kiekvieno komponento indėlį. Distilierio viduje suvienodinami įprastai naudojami tarpinių atstovybių distiliavimo tikslai pagal universalią tarpusavio informacijos (MI) tikslą ir siūlome MI objektyvių funkcijų klasę su geresniu sąžiningumu ir (arba) skirtumu, kad būtų galima įvertinti mokytojo ir studento MI. On a diverse set of NLP datasets, the best Distiller configurations are identified via large-scale hyper-parameter optimization.  Mūsų eksperimentai atskleidžia:\nsvarbiausias KD veiklos veiksnys, 2) tarp skirtingų tarpinio distiliavimo tikslų, MI geriausiai veikia, ir 3) duomenų didinimas labai skatina mažus mokymo duomenų rinkinius arba mažus student ų tinklus. Be to, nustatome, kad skirtingi duomenų rinkiniai ir (arba) užduotys pirmenybę teikia skirtingiems KD algoritmams, todėl siūlome paprastą AutoDistiller algoritmą, kuris gali rekomenduoti gerą KD vamzdyną naujiems duomenų rinkiniams.', 'kk': 'Мәліметтердің бөлімі (KD) соңғы жылдарда Түзіндік тіл процессерін (NLP) басқару үшін көпшілікті, жады/ энергия пайдалануының көпшілігін көшірмелеу үшін табиғи жолын ұсынады. KD алгоритмдері NLP қолданбалары үшін көптеген көптеген алгоритмдерді таңдағанда, оптималдық дистриляциялау мүмкіндігінің астындағы кілт факторлары көптеген және білмейді. Мұғалім мен студенттер арасындағы мәліметті аудару үшін, KD құрылғысының түрлі компоненттерінің қанша нәтижесін анықтау үшін мақсатымыз келеді. Олардың эффекттерін бөліктіру үшін, Distiller- ді жүйелік түрде KD құрылғысының әр компонентінің қатынасын көлемдеу мүмкіндігін шектеуге мүмкіндік беретін мета KD қоршауын қолданамыз. Дистиллердің ішінде, біз мұғалім мен студент арасындағы MI-нысан функцияларды бағалау үшін көпшілік мәліметтердің орташа мәліметтердің дистриляциялау үшін қолданатын мақсаттарды біріктіреміз. NLP деректер қорларының түрлі баптаулары үлкен масштабтағы гипер параметрлерді оптимизациялау арқылы ең жақсы дистриллер баптаулары анықталады. Біздің тәжірибеміз келесі мәліметтерді көрсетеді:\nKD жылдамдығындағы ең маңызды фактор, 2) орташа дислилациялау үшін әртүрлі мақсаттар арасында, MI- дің ең жақсы жұмыс істейді, және 3) деректерді жақсарту үшін кішкентай оқыту деректер жиындарына не кі Біз басқа деректер қорлары/ тапсырмалар KD алгоритмдерін таңдайды. Сонымен, жаңа деректер қорлары үшін жақсы KD конвертінің қарапайым автодистриллер алгоритмін таңдайды.', 'ms': 'Knowledge Distillation (KD) offers a natural way to reduce the latency and memory/energy usage of massive pretrained models that have come to dominate Natural Language Processing (NLP) in recent years.  Walaupun berbagai varian khusus algoritma KD telah diusulkan untuk aplikasi NLP, faktor kunci yang mendasarkan prestasi destilasi optimal sering berkeliaran dan tetap tidak jelas. Kami bertujuan untuk mengenalpasti bagaimana komponen berbeza dalam saluran paip KD mempengaruhi prestasi yang berasal dan berapa banyak saluran paip KD optimal berbeza melalui set data/tugas berbeza, seperti polisi peningkatan data, fungsi kehilangan, dan mewakili sementara untuk memindahkan pengetahuan antara guru dan pelajar. Untuk menghilangkan kesan mereka, kami melamar Distiller, kerangka meta KD yang secara sistematik menggabungkan julat luas teknik melalui tahap-tahap berbeza paip KD, yang membolehkan kita kuantifikasikan kontribusi setiap komponen. Dalam Distiller, kita menyatukan tujuan yang biasanya digunakan untuk penyembuhan perwakilan antarabangsa di bawah objektif maklumat bersama-sama universal (MI) dan melamar kelas fungsi objektif-MI dengan bias/variasi yang lebih baik untuk menghargai MI antara guru dan pelajar. Pada set data NLP yang berbeza, konfigurasi Distiller terbaik dikenali melalui optimasi hyper-parameter skala besar. Eksperimen kami mengungkapkan yang berikut: 1) pendekatan yang digunakan untuk membersihkan perwakilan antarabangsa adalah\nfaktor yang paling penting dalam prestasi KD, 2) diantara tujuan yang berbeza untuk penapisan sementara, MI-melakukan yang terbaik, dan 3) peningkatan data menyediakan bantuan besar untuk set data latihan kecil atau rangkaian pelajar kecil. Lagipun, kami mendapati set data/tugas yang berbeza lebih suka algoritma KD yang berbeza, dan dengan itu melamar algoritma AutoDistiller sederhana yang boleh menyarankan baris paip KD yang baik untuk set data baru.', 'pl': 'Destylacja wiedzy (KD) oferuje naturalny sposób na zmniejszenie opóźnień i zużycia pamięci/energii masywnych modeli wstępnie trenowanych, które w ostatnich latach zdominowały przetwarzanie języka naturalnego (NLP). Podczas gdy dla aplikacji NLP zaproponowano wiele zaawansowanych wariantów algorytmów KD, kluczowe czynniki podstawowe optymalnej wydajności destylacji są często zamieszane i pozostają niejasne. Naszym celem jest zidentyfikowanie, w jaki sposób różne komponenty w rurociągu KD wpływają na wynikową wydajność i jak bardzo optymalny rurociąg KD różni się w zależności od różnych zbiorów danych/zadań, takich jak polityka powiększania danych, funkcja strat i pośrednia reprezentacja przekazywania wiedzy pomiędzy nauczycielem a uczniem. Aby oddzielić ich efekty, proponujemy Distiller, meta KD framework, który systematycznie łączy szeroki zakres technik na różnych etapach rurociągu KD, co pozwala nam ilościowo określić wkład każdego komponentu. W ramach Distillera ujednolicamy powszechnie stosowane cele destylacji reprezentacji pośrednich w ramach celu uniwersalnej wzajemnej informacji (MI) i proponujemy klasę funkcji obiektywnych MI z lepszym kompromisem stronniczo-wariancyjnym dla oszacowania MI między nauczycielem a uczniem. Na zróżnicowanym zestawie danych NLP najlepsze konfiguracje Distillera są identyfikowane poprzez optymalizację hiperparametrów na dużą skalę. Nasze eksperymenty ujawniają następujące: 1) podejście stosowane do destylacji reprezentacji pośrednich jest:\nNajważniejszy czynnik wydajności KD, 2) wśród różnych celów destylacji pośredniej, MI-osiąga najlepiej, a 3) powiększanie danych zapewnia duży impuls dla małych zbiorów danych szkoleniowych lub małych sieci studentów. Ponadto okazujemy się, że różne zestawy danych/zadania preferują różne algorytmy KD, dlatego proponujemy prosty algorytm AutoDistiller, który może polecić dobry rurociąg KD dla nowego zbioru danych.', 'mk': 'Дистилацијата на знаењето (KD) нуди природен начин за намалување на лантенцијата и употребата на меморијата/енергијата на масовните предобучени модели кои доминираат во процесорот на природен јазик (NLP) во последниве години. Иако за апликациите на НЛП се предложени бројни софистицирани варијанти на КД алгоритми, клучните фактори кои ја поткрепуваат оптималната дестилација честопати се збунети и остануваат нејасни. Ние имаме за цел да идентификуваме како различните компоненти во гасоводот КД влијаат врз резултатната резултат и колку оптималниот гасовод КД се разликува помеѓу различните датотеки/задачи, како што е политиката за зголемување на податоците, функцијата за загуба и меѓувременото претставување за пре За да ги разделиме нивните ефекти, предлагаме Дистилер, мета-KD рамка која систематски комбинира широк опсег техники низ различни фази на гасоводот KD, што ни овозможува да го квантификуваме придонесот на секој компонент. Во Дистилер, ние ги обединуваме заеднички употребените цели за дестилација на меѓувремените претставувања под универзалната објективна информација (МИ) и предложуваме класа на МИ-објективни функции со подобра разлика за предрасуда/разлика за проценка на МИ помеѓу учителот и студентот. На различни набори на податоци на NLP, најдобрите конфигурации на дистилерот се идентификуваат преку оптимизација на големи хиперпараметри. Нашите експерименти откриваат:\nнајважен фактор во перформансата на КД, 2) помеѓу различните цели за меѓувреме дистилација, МИ-перформансите се најдобри, и 3) зголемувањето на податоците обезбедува голем поттик за малите податоци за обука или мали студентски мрежи. Покрај тоа, откриваме дека различните датотеки/задачи преферираат различни KD алгоритми, и со тоа предложуваме едноставен алгоритм AutoDistiller кој може да препорача добар KD гасовод за нов датотек.', 'sr': 'Distilacija znanja (KD) nudi prirodan naèin da smanji latenciju i uspomenu/energiju korištenja masivnih pretkišnih modela koji su došli do dominiranja prirodnim jezikom procesom (NLP) u poslednjih godina. Iako su predloženi brojni sofisticirani varianti KD algoritma za aplikacije NLP-a, ključni faktori koji podržavaju optimalnu funkciju destilacije često su zbunjeni i ostali nejasni. Mi ciljamo da identifikujemo kako različiti komponenti u cjevi KD utječu na rezultate učinka i koliko se optimalna cjevina KD razlikuje u različitim setima podataka/zadataka, kao što su politika povećanja podataka, funkcija gubitka i prosječna predstava za prenošenje znanja između nastavnika i studenta. Da bismo razdvojili njihove učinke, predlažemo Distiller, meta KD okvir koji sistematski kombinira širok raspon tehnika u različitim fazama cjevovoda KD-a, koji nam omogućava da kvantificiramo doprinos svake komponente. U Distilleru, zajednostavljamo često korišćene ciljeve za destilaciju međuvremenih predstavljanja pod univerzalnim zajedničkim informacijama (MI) objektivom i predlažemo klasu MI-objektivnih funkcija sa boljim trgovinom predrasudama/varijancijama za procjenu MI između nastavnika i učenika. Na različitim setima podataka NLP-a, najbolja konfiguracija Distillera su identifikovana putem optimizacije velike skale hiper-parametara. Naši eksperimenti otkrivaju sljedeće:\nnajvažniji faktor u provedbi KD-a, 2) među različitim ciljevima za prosječnu destilaciju, MI-izvršava najbolje, i 3) povećanje podataka pruža veliku poboljšanje za male podatake za obuku ili male studentske mreže. Osim toga, našli smo da različite datasete/zadatke preferiraju različite algoritme KD-a, i stoga predlažemo jednostavan algoritam AutoDistillera koji može preporučiti dobru cjevinovu liniju KD-a za novi set podataka.', 'so': "Aqoonshaha (KD) wuxuu bixiyaa qaab dabiiciga ah si uu u hoosaysiiyo isticmaalka ugu dambeeya iyo xasuusta/isticmaalka dhaqdhaqaaq badan oo u yimid inuu maamulo baaritaanka afka dabiiciga (NLP) ee ugu dambeeyey. Inta lagu talo galay codsiyada NLP waxaa lagu talo galay isbedelyo badan oo qoraal-qoraal ah oo KD ah, sababaha horumarinta ah oo ku qoran jardiinada kala soocnaanta waxaa marar badan la ceebeeyaa waxna uusan garanayn. Waxaan aimaa inaan ogaano sida qaybaha kala duduwan ee ay ku saameyn karaan sameynta sameynta iyo siduu u bedelan karo qoraalka macluumaadka/shaqooyinka kala duduwan, tusaale ahaan siyaasada kordhiska macluumaadka, waxqabadka khasaarada, iyo qaybaha dhexe ee u beddelinta aqoonta macallinka iyo ardayda. Si aan u kala gooyo saameyaashooda, waxaan u soo jeedaynaa Distiller, kaas oo ah framework meta KD oo si rasmi ah ugu soo ururiya teknikado kala duduwan darajada dhaqaalaha KD, kaas oo inagu awoodaa inaannu qiyaasto qeyb kasta contributo. Di Distiller gudaheeda, waxaynu isku daynaa waxyaabaha caadiga ah si aan u kala soocno noocyada dhexe ee macluumaadka labaad ee caalamiga ah (MI) oo aan u soo jeedno fasalka MI-objectiveed functions oo ka wanaagsan baahida/kala bedelashada ganacsiga si aan u qiimeynayno MI dhexe macallinka iyo ardayda. Soo kala duduwan oo NLP-databases ah waxaa lagu aqoonsadaa koonfureedka ugu wanaagsan ee Distiller, sida loo bedelay faa'iidada aad u weyn. Imtixaanadayada waxay muujiyaan soo socda: 1) qaabka loo kala soocaa noocyada dhexe waa\nWaxyaabaha ugu muhiimsan ee sameynta KD, 2) waxaa ka mid ah maadooyin kala duduwan oo kala duduwan kala duduwan oo kala duduwan kala duduwan kala duduwan, MI-ka sameeya waxa ugu wanaagsan, 3) kordhiska macluumaadka waxaa laga bixiyaa boost aad u weyn oo loogu talagalay sawirada waxbarashada ama shabakado ardayda yar. Sidoo kale waxaynu helnaa in qoraal kala duduwan oo KD ah ka dooranaya macluumaad kala duduwan, sidaas darteed waxaan soo jeedinayaa Algoritm oo fudud oo AutoDistiller ah, kaas oo ku talo bixin kara gabayline wanaagsan oo KD u bedelan sawir cusub.", 'sv': 'Knowledge Distillation (KD) erbjuder ett naturligt sätt att minska fördröjningen och minnes-/energianvändningen av massiva förkränade modeller som har kommit att dominera Natural Language Processing (NLP) under de senaste åren. Medan många sofistikerade varianter av KD-algoritmer har föreslagits för NLP-applikationer, är de viktigaste faktorerna som ligger till grund för den optimala destillationsprestandan ofta förvirrade och förblir oklara. Vi strävar efter att identifiera hur olika komponenter i KD pipeline påverkar den resulterande prestandan och hur mycket den optimala KD pipeline varierar mellan olika datauppsättningar/uppgifter, såsom dataaugmentationspolicyn, förlustfunktionen och mellanrepresentationen för överföring av kunskap mellan lärare och elev. För att reta isär deras effekter föreslår vi Distiller, ett meta KD-ramverk som systematiskt kombinerar ett brett spektrum av tekniker över olika stadier av KD-pipeline, vilket gör att vi kan kvantifiera varje komponents bidrag. Inom Distiller förenar vi allmänt använda mål för destillation av mellanliggande representationer under ett universellt ömsesidigt informationsmål (MI) och föreslår en klass av MI-objektiva funktioner med bättre bias/varians trade-off för att uppskatta MI mellan lärare och elev. På en mängd olika NLP-datauppsättningar identifieras de bästa distillerkonfigurationerna via storskalig hyperparameter optimering. Våra experiment avslöjar följande: 1) metoden som används för att destillera de mellanliggande representationerna är\nDen viktigaste faktorn för KD-prestanda, 2) bland olika mål för mellandestillation, MI-presterar bäst, och 3) dataförstärkning ger en stor boost för små utbildningsdataset eller små studentnätverk. Dessutom finner vi att olika datauppsättningar/uppgifter föredrar olika KD algoritmer, och därför föreslår vi en enkel AutoDistiller algoritm som kan rekommendera en bra KD pipeline för en ny datauppsättning.', 'ro': 'Distilarea cunoștințelor (KD) oferă o modalitate naturală de a reduce latența și utilizarea memoriei / energiei modelelor masive pre-instruite care au ajuns să domine procesarea limbajului natural (PNL) în ultimii ani. În timp ce numeroase variante sofisticate de algoritmi KD au fost propuse pentru aplicațiile NLP, factorii cheie care stau la baza performanței optime de distilare sunt adesea confuzi și rămân neclari. Scopul nostru este de a identifica modul în care diferitele componente din conducta KD afectează performanța rezultată și cât de mult variază conducta KD optimă în diferite seturi de date / sarcini, cum ar fi politica de augmentare a datelor, funcția de pierdere și reprezentarea intermediară pentru transferul de cunoștințe între profesor și elev. Pentru a le distruge efectele, propunem Distiller, un cadru meta KD care combină sistematic o gamă largă de tehnici în diferite etape ale conductei KD, ceea ce ne permite să cuantificăm contribuția fiecărei componente. În cadrul Distiller, unificăm obiectivele utilizate în mod obișnuit pentru distilarea reprezentărilor intermediare în cadrul unui obiectiv universal de informare reciprocă (MI) și propunem o clasă de funcții MI-obiective cu un compromis mai bun pentru evaluarea MI între profesor și elev. Pe un set divers de seturi de date NLP, cele mai bune configurații Distiller sunt identificate prin optimizarea hiperparametrului la scară largă. Experimentele noastre dezvăluie următoarele: 1) abordarea utilizată pentru distilarea reprezentărilor intermediare este\nCel mai important factor în performanța KD, 2) printre diferitele obiective pentru distilarea intermediară, MI-performează cel mai bine, și 3) mărirea datelor oferă un impuls mare pentru seturi de date mici de formare sau rețele mici de studenți. Mai mult decât atât, descoperim că diferite seturi de date/sarcini preferă diferiți algoritmi KD, propunând astfel un algoritm simplu AutoDistiller care poate recomanda o bună conductă KD pentru un nou set de date.', 'mn': 'Мэдлэг халдвар (KD) саяхан жилүүдэд Байгалийн хэл Процессорын (NLP) давамгайлах боломжийг багасгах байгалийн арга болон санамж/энергийн хэрэглээ багасгаж байна. KD алгоритмын олон төвөгтэй хувилбарууд NLP хэрэглээнд санал болгосон ч, хамгийн гол шалтгааныг үндэслэж байгаа түлхүүр хүчин зүйлс ихэвчлэн алгоритмыг зовоож байдаг. Бид KD хоолойн хоолойн компонентүүдийн үр дүнд хэрхэн нөлөөлдөг бөгөөд хамгийн сайн KD хоолойн хоолойг өөр өөр өгөгдлийн сангууд/үйл ажиллагаанд хэрхэн өөрчлөгдөж байгааг мэдэх зорилго, өгөгдлийн нэмэлт бодлого, алдагдал функц, багш болон оюутнуудын мэдлэгийг Тэдний үр дүнг хэсэг хэсэг болгохын тулд бид Distiller-г систематикийн мета KD-ийн хэмжээсүүд нь KD хоолойн шугамны олон хэмжээсүүд дээр нийлүүлдэг технологийг санал болгож байна. Энэ нь бидэнд компонент бүрийн үр дүнг тооцоолж чадна. Дистиллерийн дотор бид нийтийн нийтийн мэдээлэл (МОГ) зорилго дотор орчин үеийн үзүүлэлтийг сайжруулахын тулд ашигладаг зорилготнуудыг нэгтгэдэг. МОГ-ын зорилготой функцуудыг багш болон оюутнуудын хоорондын MI-г баталж байхын тулд илүү сайжруул NLP өгөгдлийн сангийн олон хэлбэрээр хамгийн шилдэг Distiller загварууд том хэмжээний гипер-параметр сайжруулах аргаар тодорхойлдог. Бидний туршилтууд дараагийн зүйлийг тайлбарладаг: 1) дундаж үзүүлэлтийг тайлбарлах арга бол\nДОХ-ын үйл ажиллагаанд хамгийн чухал хүчин зүйл, 2) дундаж сайжруулах зорилготой, MI-н хамгийн сайжруулах зорилготой, 3) өгөгдлийн нэмэлт нь жижиг сургалтын өгөгдлийн санг эсвэл жижиг оюутнуудын сүлжээ Мөн бид өөр өгөгдлийн сангууд/үйл ажиллагаа өөр өөр KD алгоритмыг илүү сонирхож байгааг олж мэднэ. Иймээс шинэ өгөгдлийн сангуудын хувьд сайн KD хоолойг зөвшөөрөх энгийн AutoDistiller алгоритмыг санал болгож байна.', 'ta': 'அறிவு திருப்புதல் (KD) சமீபத்திய ஆண்டுகளில் இயல்பான மொழி செயல்பாட்டினை மேலாண்மை செய்யும் பெரிய நினைவகத்தை மற்றும் சக்தி பயன்படுத்தும் மாதிரிகளை க NLP பயன்பாடுகளுக்கு பல முறைப்படுத்தப்பட்ட மாறிகள் கேடி முறைகளின் மாறிகள் பரிந்துரைக்கப்பட்டுள்ளது, விருப்பத்தேர்வு பெரும்பாலும் பிர நாம் கேடி பைப்லைனில் எவ்வாறு வேறு பொருள்கள் முடிவினை பாதிக்கும் மற்றும் வேறு விருப்பமான கேடி பைப்லைன் எவ்வளவு விருப்பமான தகவல் அமைப்புகள்/பணிகளுக்கு மாறுபடும் என்பதை அறி விளைவுகளை பிரித்து வெட்டுவதற்கு, நாம் ஒரு மெடா கேடி சட்டத்தை பரிந்துரைக்கிறோம். இது முறைமையாக குறிப்பிட்ட வித்தியாசமான நுட்பங்களை கேடி பைப்பெல்னி டிஸ்டில்டரின் உள்ளே நாம் பொதுவாக பயன்படுத்தப்பட்ட குறிப்புகளை ஒரு பொதுவான சார்ந்த தகவல்களின் கீழ் பிரித்து ஒரு பொதுவான உபயோகிக்கும் பொருள்களை ஒன்றாக்குகிறோம் மற்ற On a diverse set of NLP datasets, the best Distiller configurations are identified via large-scale hyper-parameter optimization.  நமது சோதனைகள் பின்வரும் தெரியும்: 1) நடுநிலை குறிப்புகளை வேறுபடுத்த பயன்படுத்தப்பட்ட முறையில்\nகேடியின் செயல்பாட்டில் மிகவும் முக்கியமான காரணம், 2) நடுநிலை பிரிப்புக்கான பொருள் மேலும், வேறு தரவுத்தளங்கள்/பணிகள் வேறு கேடி ஆல்பரிமாற்றங்களை விரும்புகிறார்கள் என்பதை நாம் கண்டுபிடிக்கிறோம், அதனால் ஒரு சுலபமான தன்னி', 'si': 'Name KD ඇල්ගෝරිතම් වලින් සම්පූර්ණ වෙනස් විදිහට NLP වැඩසටහන් වෙනුවෙන් ප්\u200dරයෝජනය කරලා තියෙනවා නමුත්, විශේෂ විදිහත් විදිහ අපි අදහස් කරනවා KD පායිප්ලින් වල වෙනස් අංකය කොච්චර ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් තියෙන්නේ කියලා, KD පායිප්ලින් වෙනස් දත්ත සැට/වැඩක් වලින් වෙනස් වෙනස් ව ඔවුන්ගේ ප්\u200dරභාවක් වෙනස් කරගන්න, අපි දිස්තිල්ලර්ව ප්\u200dරශ්නයක් කරනවා, මෙටා KD ක්\u200dරියාමාර්ගයක් පද්ධතියෙන් විශේෂ ප්\u200dරභාවක් සම්බන්ධ ක දිස්තිලෙර් වලින්, අපි සාමාන්\u200dයයෙන්ම භාවිත වෙන්නේ අක්ෂේත්වල් විශාල තොරතුරු සඳහා සාමාන්\u200dයය සම්බන්ධ තොරතුරු සඳහා විශාල තොරතුරු සඳහා විශාල තොරතු Name අපේ පරීක්ෂණය ප්\u200dරකාශ කරනවා පස්සේ: 1) පස්සේ ප්\u200dරතිනිධාන ප්\u200dරතිනිධානය විශේෂ කරන්න ප්\u200dරයෝජනය\nKD ප්\u200dරමාණයේ වැදගත් වැදගත් විශේෂ අක්ෂේත්වය, 2) වෙනස් අක්ෂේත්වය අතර, MI- ප්\u200dරමාණය හොඳයි, සහ 3) දත්ත විශාලනය සඳහා පොඩි ප්\u200dරම අපි හොයාගන්නවා වෙනස් දත්ත සැට/වැඩක් වෙනස් KD ඇල්ගෝරිතම් වලට වඩා වෙනස් කිරීම් වලට, ඒ වගේම සාමාන්\u200dය ස්වයංක්\u200dරියාවක් අල්ගෝරි', 'no': 'Kvitensforstyring (KD) tilbyr ein naturleg måte å redusera latensien og minne/energibruken av massiv forstørrande modeller som har komme til å dominere naturspråk- prosessering (NLP) i siste år. Mens mange sofistikerte variantar av KD- algoritmer er foreslått for NLP- program, er nøkkelfaktorene som understrekar optimal distillasjonsfunksjonen ofte konflikt og blir uventa. Vi må identifisera korleis forskjellige komponentar i KD- røyvinga påvirkar resultatet og kor mykje optimal KDE- røyvinga varierer i ulike datasett/ oppgåver, slik som dataaugmentasjonspolitikk, tapfunksjonen og mellombels representasjon for å overføra kunnskapen mellom læraren og studenten. For å separera effektane sine, foreslår vi Distiller, ein meta KD- rammeverk som systematisk kombinerer eit brett område teknikk på ulike stader av KD- røyrlinja, som gjer oss kvantifisert bidrag til kvar komponent. Innan Distiller er vi ofte brukte mål for å distillera mellom ein universell felles informasjon (MI) og foreslå ein klasse med MI-målsettingsfunksjonar med bedre forskyving/varianstrykk for å estimere MI mellom læraren og studenten. På ein ulik sett av NLP- datasett vert dei beste oppsetta for distribusjonar identifiserte ved hjelp av storskala hyper- parametrar. Eksperimentane våre viser følgjande: 1) tilnærminga brukt til å distillere mediane representasjonane er den\nDei viktigste faktorene i KD-utviklinga, 2) blant ulike målsettingar for intermediate distillasjon, MI-utfører det beste, og 3) utviklinga av data tilbyr stor økning for små opplæringsdatasett eller små studentnettverk. I tillegg finn vi at forskjellige datasett/oppgåver fører forskjellige KD- algoritmer, og derfor foreslår ein enkel AutoDistiller- algoritme som kan anbefalt ein god KD- røyrlinje for ei ny datasett.', 'ur': 'علم Distillation While many sophisticated variants of KD algorithms are proposed for NLP applications, the key factors underneath the optimal distillation performance are often confused and remain unclear. ہم کا ارادہ ہے کہ KD پائپ لین میں کس طرح مختلف قسمتوں کا نتیجہ پائپ لین پر اثر کرتا ہے اور کس طرح اچھی KD پائپ لین مختلف ڈاٹ سٹ/ٹاکس میں متفاوت ہوتا ہے، جیسے ڈاٹ اضافہ پالیس، خسارہ فعالیت، اور معلم اور دانش کے درمیان تغییر دینے کے لئے بی ان کے اثرات کو ٹیٹ کر ڈالنے کے لئے ہم Distiller کو پیشنهاد کرتے ہیں، ایک meta KD فرمیک جو سیستماتیک طور پر ایک گھیری ٹیکنیکوں کی طرح مختلف مرحلے سے کڈ پیپ لین کے درمیان جمع کرتا ہے، جو ہمیں ہر رقم کے اثرات کا مقدار کرنا اجازت دیتا ہے. دیسٹیلر کے اندر ہم عام طور پر استعمال کئے گئے موضوعات کے متفرق کرنے کے لئے ایک واحد متفرق معلومات (MI) موضوع کے ذریعہ اور MI موضوعات کے کلاس کی پیشنهاد کریں کہ MI کے درمیان مطالعہ اور طالب کے درمیان مطالعہ کا مطالعہ کرنے کے لئے بہتر غیر غیر غیر غیر غیر غیر Name ہماری آزمائش نیچے دکھائی جاتی ہے: 1) آزمائش میانہ دکھانے کے لئے استعمال کیا جاتا ہے\nڈیٹا اضافہ کرنا چھوٹے ٹرینگ ڈیٹسٹ یا چھوٹے طالب نیٹورک کے لئے بہت اضافہ کرتا ہے۔ اور ہم دیکھتے ہیں کہ مختلف ڈاٹ سٹ/ٹاکس مختلف KD الگوریتم کو پسند کرتی ہیں، اور اسی طرح ایک ساده AutoDistiller الگوریتم پیشنهاد کرتا ہے جو ایک نوی ڈاٹ سٹ کے لئے ایک اچھی KD پایپ لین کی توصیف کرسکتا ہے.', 'uz': "Knowledge Distillation (KD) offers a natural way to reduce the latency and memory/energy usage of massive pretrained models that have come to dominate Natural Language Processing (NLP) in recent years.  @ info: whatsthis @ info: whatsthis Ularning effektlarini ajratish uchun biz meta KD freymini tizim bilan qo'yish kerakli texnikalarning boshqa darajada bir necha darajada birlashtirish imkoniyatini imkoniyatlash imkoniyatini beradi. Distiller ichida, biz umumiy foydalanuvchilarni birlashtiramiz, universal bir bir bir bir xil ma'lumot (MI) obʼektini ajratish uchun o'zaro qilamiz va o'qituvchi va o'quvchiga o'qituvchi MI o'qituvchisini qiymatga ega bo'ladi. @ info: whatsthis Bizning imtiyozlarimiz quyidagi imtiyozlarimizni ko'rsatadi: 1) o'rtacha tashkilotlarni ajratish uchun ishlatiladigan\nmost important factor in KD performance, 2) among different objectives for intermediate distillation, MI-performs the best, and 3) data augmentation provides a large boost for small training datasets or small student networks.  Ko'rib, biz boshqa maʼlumot sets/vazifalar boshqa KD algoritlarini tanlang, va shunday qilib, yangi maʼlumot sahifasi uchun oddiy avtomatik Distiller algoritni talab qiling.", 'vi': 'Quy trình nấu ăn (KD) là một cách tự nhiên để giảm thiểu tiềm năng và trí nhớ và sử dụng năng lượng của các mô- đun trước mưa lớn đã chiếm lĩnh Chất Học Ngôn ngữ học tự nhiên trong những năm gần đây. Trong khi nhiều biến thể phức tạp của thuật toán KDM đã được đề xuất cho ứng dụng NLP, nhưng yếu tố chủ chốt của phương pháp chưng cất tối ưu thường bị xáo trộn và không rõ ràng. Mục tiêu của chúng tôi là xác định các thành phần khác nhau trong ống dẫn KDE sẽ ảnh hưởng thế nào tới hiệu quả kết quả và khả năng truyền đạt đạt tối ưu bao gồm các tập tin/ các công việc khác nhau, như là chính sách gia tăng dữ liệu, chức năng giảm tổn thất, và đại diện để truyền đạt kiến thức giữa giáo viên và sinh viên. Để phá vỡ hiệu ứng của chúng, chúng tôi đề xuất xuất xuất xuất xuất xuất xuất xuất xuất xuất xuất s ắc, một hệ thống meta-KDat, nó giúp chúng tôi xác định tỷ lệ đóng góp của mỗi thành phần. Chúng tôi thống nhất các mục tiêu dùng chung để chưng cất các biểu tượng trung ương dưới một mục tiêu phổ biến thông tin nội bộ (MI) và đề nghị một hạng các chức năng mục tiêu theo MI với khuynh hướng khác nhau tốt hơn để đánh giá MI giữa giáo viên và học sinh. Trên một loạt các tập tin mẫu lập dị, cấu hình xuất giỏi nhất được xác định qua khả năng đạt siêu tham số lớn. Các thí nghiệm của chúng tôi tiết lộ: 1) phương pháp được dùng để chưng cất các biểu tượng trung ương là\nyếu tố quan trọng nhất trong hiệu ứng KDE, 2) trong các mục tiêu khác nhau của việc chưng cất trung tâm, MI-làm tốt nhất, và 3) việc gia tăng dữ liệu cung cấp một lực lớn cho các tập tin nhỏ hay các mạng sinh viên nhỏ. Hơn nữa, chúng tôi tìm thấy các tập tin/ công việc khác nhau ưa thích các thuật toán KDE khác nhau, và đề xuất một thuật toán Autobot đơn giản có thể đề nghị một đường ống KD cho một bộ dữ liệu mới.', 'bg': 'Дестилацията на знанието (КД) предлага естествен начин за намаляване на латентността и използването на памет/енергия на масивни предварително обучени модели, които доминират в обработката на естествения език (НЛП) през последните години. Въпреки че са предложени множество сложни варианти на алгоритми за НЛП приложения, ключовите фактори, които подкрепят оптималната дестилация, често са объркани и остават неясни. Целта ни е да идентифицираме как различните компоненти в тръбопровода влияят на полученото представяне и колко оптималният тръбопровод варира в различните набори от данни/задачи, като политиката за увеличаване на данните, функцията за загуба и междинното представяне за прехвърляне на знания между учител и ученик. За да разграничим ефектите им, предлагаме мета рамка, която систематично комбинира широк спектър от техники през различните етапи на тръбопровода, която ни позволява да количествено определим приноса на всеки компонент. В рамките на Дестилер обединяваме често използваните цели за дестилация на междинни представяния под цел универсална взаимна информация (МИ) и предлагаме клас от МИ-обективни функции с по-добър компромис на отклонение/вариация за оценка на МИ между учителя и ученика. На разнообразен набор от НЛП набори от данни, най-добрите конфигурации на дестилер се идентифицират чрез мащабна оптимизация на хиперпараметрите. Нашите експерименти разкриват следното: 1) подходът, използван за дестилиране на междинните изображения, е\nнай-важният фактор за ефективността на КД, 2) сред различните цели за междинна дестилация, МИ-изпълнява най-добре, и 3) увеличаването на данните осигурява голям тласък за малки набори от данни за обучение или малки студентски мрежи. Освен това откриваме, че различните набори от данни/задачи предпочитат различни алгоритми и по този начин предлагаме прост алгоритъм, който може да препоръча добър тръбопровод за нов набор от данни.', 'de': 'Knowledge Distillation (KD) bietet eine natürliche Möglichkeit, die Latenz und den Speicher-/Energieverbrauch massiver vortrainierter Modelle zu reduzieren, die in den letzten Jahren die Natural Language Processing (NLP) dominieren. Während zahlreiche anspruchsvolle Varianten von KD-Algorithmen für NLP-Anwendungen vorgeschlagen wurden, sind die Schlüsselfaktoren, die die optimale Destillationsleistung stützen, oft verwirrt und bleiben unklar. Unser Ziel ist es zu identifizieren, wie sich verschiedene Komponenten in der KD-Pipeline auf die resultierende Leistung auswirken und wie sehr die optimale KD-Pipeline zwischen verschiedenen Datensätzen/Aufgaben variiert, wie z.B. der Datenaugenmessungsrichtlinie, der Verlustfunktion und der Zwischendarstellung für den Wissenstransfer zwischen Lehrer und Schüler. Um ihre Effekte zu trennen, schlagen wir Distiller vor, ein Meta-KD-Framework, das systematisch eine breite Palette von Techniken über verschiedene Phasen der KD-Pipeline kombiniert, um den Beitrag jeder Komponente zu quantifizieren. Innerhalb von Distiller vereinheitlichen wir häufig verwendete Ziele für die Destillation von Zwischenrepräsentationen unter einem universellen gegenseitigen Informationsziel (MI) und schlagen eine Klasse von MI-Objektivfunktionen mit besserem Bias/Varianz-Kompromiss für die Schätzung der MI zwischen dem Lehrer und dem Schüler vor. Auf einer Vielzahl von NLP-Datensätzen werden die besten Distiller-Konfigurationen durch großflächige Hyper-Parameter-Optimierung identifiziert. Unsere Experimente zeigen folgendes: 1) der Ansatz, der zur Destillation der Zwischenrepräsentationen verwendet wird, ist die\nDer wichtigste Faktor für die KD-Leistung, 2) unter den verschiedenen Zielen für die Zwischendestillation, MI-Leistung am besten, und 3) Datenauswertung bietet einen großen Schub für kleine Trainingsdatensätze oder kleine Schülernetzwerke. Darüber hinaus stellen wir fest, dass verschiedene Datensätze/Aufgaben unterschiedliche KD-Algorithmen bevorzugen, und schlagen daher einen einfachen AutoDistiller-Algorithmus vor, der eine gute KD-Pipeline für einen neuen Datensatz empfehlen kann.', 'da': 'Knowledge Distillation (KD) tilbyder en naturlig måde at reducere latens og hukommelse / energiforbrug af massive prætrænede modeller, der er kommet til at dominere Natural Language Processing (NLP) i de seneste år. Mens mange avancerede varianter af KD algoritmer er blevet foreslået til NLP applikationer, er de vigtigste faktorer, der understøtter den optimale destillationsydelse, ofte forvirret og forbliver uklare. Vi tilstræber at identificere, hvordan forskellige komponenter i KD pipeline påvirker den resulterende ydeevne, og hvor meget den optimale KD pipeline varierer på tværs af forskellige datasæt/opgaver, såsom dataforøgelsespolitikken, tabsfunktionen og den mellemliggende repræsentation til overførsel af viden mellem lærer og elev. For at drille deres effekter fra hinanden, foreslår vi Distiller, en meta KD ramme, der systematisk kombinerer en bred vifte af teknikker på tværs af forskellige stadier af KD pipeline, som gør det muligt for os at kvantificere hver komponents bidrag. Inden for Distiller forener vi almindeligt anvendte mål for destillation af mellemliggende repræsentationer under et universelt gensidigt informationsmål (MI) og foreslår en klasse af MI-objektive funktioner med bedre bias / varians trade-off til estimering af MI mellem læreren og eleven. På et forskelligt sæt af NLP-datasæt identificeres de bedste Distiller-konfigurationer via storstilet hyperparameter optimering. Vores eksperimenter afslører følgende: 1) Den fremgangsmåde, der anvendes til destillering af de mellemliggende repræsentationer, er\nDen vigtigste faktor i KD ydeevne, 2) blandt forskellige mål for mellemdestillation, MI-yder det bedste, og 3) dataforøgelse giver et stort boost til små træningsdatasæt eller små studerende netværk. Desuden finder vi ud af, at forskellige datasæt/opgaver foretrækker forskellige KD algoritmer, og derfor foreslår vi en simpel AutoDistiller algoritme, der kan anbefale en god KD pipeline til et nyt datasæt.', 'hr': 'Distilacija znanja (KD) nudi prirodan način da smanji latenciju i uspomenu/energiju korištenja masivnih pretkišnih modela koji su došli do dominacije prirodnog procesa jezika (NLP) u posljednjih godina. Iako su predloženi brojni sofisticirani varianti KD algoritma za primjene NLP-a, ključni faktori koji podnose optimalnu funkciju destilacije često su zbunjeni i ostali nejasni. Ciljem smo identificirati kako različiti komponenti u cjevi KD utječu na rezultate učinka i koliko se optimalna cjevina KD-a razlikuje u različitim podacima/zadatkima, poput povećanja politike podataka, funkcije gubitka i prosječne predstave za prenošenje znanja između učitelja i učitelja. Da bismo razdvojili njihove učinke, predlažemo Distiller, meta KD okvir koji sistematski kombinira širok raspon tehnika u različitim fazama cjevovodne linije KD-a, što nam omogućava kvantificirati doprinos svake komponente. U Distilleru, zajednostavljamo često korišćene ciljeve za destilaciju prosječnih predstavljanja pod univerzalnim zajedničkim informacijama (MI) ciljem i predlažemo klasu funkcija MI-objektivnih funkcija sa boljom trgovinom pristrasnosti/varijancijom za procjenu MI između nastavnika i učenika. Na različitim setima podataka NLP-a, najbolja konfiguracija Distillera identificirana su putem optimizacije velike skale hiper-parametara. Naši eksperimenti otkrivaju sljedeće:\nNajvažniji faktor učinkovitosti KD-a, 2) među različitim ciljevima za prosječnu destilaciju, MI-a najbolji čini te 3) povećanje podataka pruža veliku poboljšanje za male podatake obuke ili male studentske mreže. Osim toga, smatramo da različite datasete/zadatke preferiraju različite algoritme KD-a, te stoga predlažemo jednostavan algoritam AutoDistillera koji može preporučiti dobru cjevinu KD-a za novu setu podataka.', 'nl': 'Knowledge Distillation (KD) biedt een natuurlijke manier om de latentie en het geheugen/energieverbruik van massieve voorgetrainde modellen te verminderen die de afgelopen jaren Natural Language Processing (NLP) domineren. Hoewel talrijke geavanceerde varianten van KD-algoritmen zijn voorgesteld voor NLP-toepassingen, zijn de belangrijkste factoren die de optimale distillatieprestaties ondersteunen vaak verward en blijven onduidelijk. We proberen te identificeren hoe verschillende componenten in de KD-pijplijn invloed hebben op de resulterende prestaties en hoeveel de optimale KD-pijplijn varieert tussen verschillende datasets/taken, zoals het beleid voor gegevensvergroting, de verliesfunctie en de intermediaire representatie voor het overbrengen van de kennis tussen docent en student. Om hun effecten uit elkaar te halen, stellen we Distiller voor, een meta KD framework dat systematisch een breed scala aan technieken combineert in verschillende stadia van de KD pijplijn, waarmee we de bijdrage van elke component kunnen kwantificeren. Binnen Distiller verenigen we veelgebruikte doelstellingen voor de distillatie van intermediaire representaties onder een universele wederzijdse informatie (MI) doelstelling en stellen we een klasse van MI-objectieve functies voor met een betere bias/variantie compromis voor het schatten van de MI tussen de leraar en de student. Op een diverse set NLP datasets worden de beste Distiller configuraties geïdentificeerd via grootschalige hyper-parameter optimalisatie. Onze experimenten onthullen het volgende: 1) de methode die wordt gebruikt om de intermediaire representaties te distilleren is de\nDe belangrijkste factor in KD prestaties, 2) tussen verschillende doelstellingen voor intermediaire distillatie, MI-presteert het beste, en 3) data augmentatie biedt een grote boost voor kleine trainingsdatasets of kleine studentennetwerken. Bovendien vinden we dat verschillende datasets/taken de voorkeur geven aan verschillende KD algoritmes, en stellen we daarom een eenvoudig AutoDistiller algoritme voor dat een goede KD pipeline kan aanbevelen voor een nieuwe dataset.', 'fa': 'استفاده از دانش (KD) راهی طبیعی برای کاهش استفاده از مدل\u200cهای بزرگی پیش\u200cگیری که در سال\u200cهای اخیر به فرایند زبان طبیعی (NLP) تحت تسلیم قرار گرفته\u200cاند پیشنهاد می\u200cدهد. در حالی که متغیر\u200cهای زیادی از الگوریتم\u200cهای KD برای کاربردهای NLP پیشنهاد داده شده\u200cاند، کاربردهای کلیدی که بر پایه عملکرد تفاوت optimal distillation اغلب مخلوط می\u200cشوند و ناشناخته می\u200cشوند. ما قصد داریم تشخیص دهیم که چگونه بخش\u200cهای مختلف در خط لوله\u200cهای KD به انجام نتیجه تأثیر می\u200cدهد و چگونه لوله\u200cهای optimal KD در مجموعه\u200cهای داده\u200cهای مختلف تغییر می\u200cدهد، مانند سیاست افزایش داده\u200cها، عملکرد خسارت، و نمایش\u200cهای بین\u200cالمثال علم بین معلم و دانش برای جدا کردن اثرات ایشان، ما پیشنهاد دیستیلر را می\u200cدهیم، یک چهارچوب متا KD که سیستم\u200cپذیر یک مجموعه طولانی از تکنیک\u200cهای مختلف در مرحله\u200cهای لوله\u200cهای KD را ترکیب می\u200cکند، که به ما اجازه می\u200cدهد که تقسیم بخش هر بخش را تعداد دهیم. در داخل دیستیلر، ما معمولاً هدف\u200cهایی را برای جدا کردن نمایش\u200cهای بین\u200cالمللی در زیر یک هدف اطلاعات بین\u200cالمللی (MI) استفاده می\u200cکنیم و یک کلاس عملکرد\u200cهای موجود MI را پیشنهاد می\u200cکنیم که با تجارت\u200cهای بین معلم و دانش\u200cآموزان با تغییر/تغییر بهتر برای ارزیابی MI در مجموعه\u200cای از مجموعه\u200cهای داده\u200cهای NLP بهترین پیکربندی\u200cهای Distiller از طریق optimization of parameter hyper- scale بزرگ شناسایی می\u200cشوند. آزمایشات ما این آزمایشات را نشان می دهند: ۱) روش استفاده می شود تا نمایش\u200cهای بین\u200cالمللی را جدا کنند این است که\nبزرگترین فاکتور مهم در عملکرد KD، ۲) بین هدف\u200cهای متفاوتی برای جدایی بین\u200cالمللی، MI-بهترین عمل می\u200cکند، و ۳) افزایش داده\u200cها برای مجموعه\u200cهای داده\u200cهای کوچک آموزش یا شبکه\u200cهای دانش آموزش کوچک افزایش بزرگی می\u200cدهد علاوه بر این، ما پیدا می\u200cکنیم که مجموعه\u200cهای داده\u200cهای متفاوت/وظیفه\u200cهای مختلف الگوریتم KD را ترجیح می\u200cدهند، و به همین دلیل الگوریتم\u200cهای ساده AutoDistiller را پیشنهاد می\u200cدهیم که می\u200cتواند یک لوله\u200cهای KD خوب برای مجموعه داده\u200cهای جدید', 'tr': "Bilgi baglanyşyk NLP programleri üçin köp karmaşık karmaşık karmaşıklykly KD algoritmalarynyň köp üýtgewleri teklip edildi welin, iň optimal taýýarlama eserini bozmak üçin açary karmaşıklyga çarpylýar we bulary däl. Biz KD pipeliniň dürli komponentleriniň netijesini nähili täsir etjek bolandygyny tanamak amaçlarýarys we optimal KD pipeliniň dürli datasetleriň/zadlaryň arasynda näçe üýtgeýändigini, maglumatyň we okuwçylaryň arasynda göçürmek üçin hedefimiz bar. Hatlaryny bölmek üçin Distiller'i, sistematik bir meta KD çerçevesini sistematik bir şekilde KD pipeline'iň farklı taýýarlarynda birleştirip, bu şekilde her komponentiň täsirini ölçülemegimizi mümkin edir. Distiller'de, Mugallym bilen öwreniň arasynda MI-nji maksadyny hasaplamak üçin adatça bir hedeflerimizi birleştirip ulanýarys. NLP faýllaryň dürli bir toparynda, iň gowy döwletler ýagdaýlary Ullakan-kalapça hiper-paraýatýasynyň optimizasyyla tanişdirler. Deneylerimiz aşağıdaki ifadeleri:1) orta ifadelerini ayırmak için kullanılan metodumuzdur.\nKD başaryşlarynda iň wajyp faktor, 2) orta taýýarlama üçin beýleki maksadlaryň arasynda, MI-ň iň gowy bolup başarýar, we 3) maglumatyň ýetişdirmegi kiçi öwrenme datasetleri ýa kiçi okuwçy netpleri üçin uly täsirleýär. Munuň üçin, farklı veri setirleri/zadalar farklı KD algoritmalaryny tercih edip görýäris we şonuň üçin täze bir veri setirmesi üçin basit bir AutoDistiller algoritmi teklip edip biler.", 'af': "Die kennis Verspreiding (KD) bied 'n natuurlike manier om die latensie en geheue/energiegebruik van massiewe voorreïndeerde modele te verminder wat in onlangse jaar gekom het om Natuurlike Taal Prosessering (NLP) te domineer. Alhoewel veelvuldige sofistikeerde variante van Kde algoritme is voorgestel vir NLP-toepassings, word die sleutel faktore ondersteun van die optimale destilasie-prestasie dikwels beskaamd en onbekende bly. Ons doen doel om te identifiseer hoe verskillende komponente in die Kde pipeline invloek die resulteerde prestasie en hoeveel die optimale Kde pipeline verander oor verskillende datastelle/opdragte, soos die data augmentasie beleid, die verlies funksie, en die middelste prestasie vir die oordra van die kennis tussen onderwyser en studente. Om hulle effekte afskei te maak, voorstel ons Distiller, 'n meta KD raamwerk wat sistematies 'n breë reek teknike kombinieer oor verskillende stadige van die Kde pipeline, wat ons kan quantifiseer elke komponent se bydraag. Binne Distiller, ons het gewoonlik gebruik objekte vir die destilasie van middelste voorstellings onder 'n universele gemeenskaplike inligting (MI) doel eenmaak en 'n klas van MI-objekte funksies voorstel met beter bias/variance handel-off vir die estimatie van die MI tussen die onderwyser en die studente. Op 'n verskeie stel van NLP datastelle word die beste Distiller konfigurasies deur groot- skaal hiper- parameter optimaliseer geïdentifiseer. Ons eksperimente vertoon die volgende: 1) die toegang gebruik word om die middelste voorstellings te distiliseer is die\nDie mees belangrikste faktor in KD-prestasie, 2) onder verskillende doelskappe vir intermediate destilasie, MI-uitvoer die beste, en 3) data-opvoeging verskaf 'n groot booster vir klein opvoeringsdatastelle of klein studentnetwerke. Ook, ons vind dat verskillende datastelle/ taak verkies verskillende KD algoritme, en dus voorstel 'n eenvoudige AutoDistiller algoritme wat kan aanbevestig 'n goeie KD pyplyn vir' n nuwe datastel.", 'ko': '지식 추출(KD)은 최근 몇 년간 자연언어처리(NLP)를 주도해온 대규모 예비훈련 모델의 지연과 메모리/에너지 사용을 줄일 수 있는 자연스러운 방법을 제공한다.많은 복잡한 KD 알고리즘 변형이 NLP 응용에 사용되고 있지만, 최상의 증류 성능을 지탱하는 관건적인 요소는 종종 사람을 곤혹스럽게 하지만, 현재로서는 아직 분명하지 않다.우리의 목표는 KD 파이프의 서로 다른 구성 요소가 최종 성능에 어떻게 영향을 미치는지, 그리고 가장 좋은 KD 파이프가 서로 다른 데이터 집합/임무에서 변화하는 정도, 예를 들어 데이터 증강 전략, 손실 함수와 교사와 학생 간의 지식 전달의 중간 표시를 확정하는 것이다.그것들의 영향을 구분하기 위해 우리는 Diller를 제기했다. 이것은 원 KD 구조로 KD 파이프의 서로 다른 단계의 광범위한 기술을 체계적으로 결합시켜 모든 구성 요소의 공헌을 계량화할 수 있다.증류기에서 우리는 유니버설 상호정보(MI) 목표에서 증류 중간에 표시하는 상용 목표를 통일시켰고 더 좋은 편차/방차권형을 가진 MI 목표 함수를 제시하여 교사와 학생 간의 MI를 평가하는 데 사용했다.다양한 NLP 데이터 세트에서 대규모 하이퍼파라미터 최적화를 통해 최적의 증류기 구성을 결정합니다.우리의 실험은 다음과 같은 몇 가지를 제시했다. 1) 중간 표시를 추출하는 방법은\nKD의 성능에서 가장 중요한 요소는 2) 중간 증류의 서로 다른 목표 중에서 MI의 성능이 가장 좋다. 3) 데이터 강화는 소형 훈련 데이터 집합이나 소형 학생 네트워크에 큰 향상을 제공했다.또한 우리는 서로 다른 데이터 집합/작업이 서로 다른 KD 알고리즘을 선호하는 것을 발견했기 때문에 간단한 자동 추출 알고리즘을 제시하여 새로운 데이터 집합에 좋은 KD 파이프를 추천할 수 있다.', 'sw': 'Kuondolewa kwa maarifa (KD) inatoa njia ya asili ya kupunguza matumizi ya hivi karibuni na kumbukumbu/nishati ya mifano makubwa ya uzoefu ambao imekuja kushinda mchakato wa lugha ya asili (NLP) katika miaka ya hivi karibuni. Wakati mabadiliko mengi ya algorithi za KD yamependekezwa kwa ajili ya matumizi ya NLP, sababu muhimu zinazoonyesha utendaji wa utofauti wa kimapenzi mara nyingi huwa zinachanganyika na bado si wazi. Tuna lengo la kutambua vipi vifaa tofauti katika pipeli ya KD vinavyoathiri ufanisi wa matokeo yake na vipi ambavyo pipeli bora ya KD hutofauti katika seti mbalimbali za data/kazi, kama vile sera ya kuongeza taarifa, kazi ya kupoteza, na uwakilishi wa kati kwa kuhamisha maarifa kati ya mwalimu na wanafunzi. Ili kutenganisha madhara yao, tunapendekeza Distiller, mfumo wa KD ambao kwa mfumo unaunganisha aina mbalimbali ya teknolojia katika hatua mbalimbali za pipeline ya KD, ambayo inatuwezesha kuhakikisha mchango wa kila sehemu. Within Distiller, we unify commonly used objectives for distillation of intermediate representations under a universal mutual information (MI) objective and propose a class of MI-objective functions with better bias/variance trade-off for estimating the MI between the teacher and the student.  Katika seti mbalimbali za taarifa za NLP, miundombinu bora ya Distiller hugunduliwa kwa kupitia optimizi ya kipimo kikubwa cha upepo. Majaribio yetu yanaonyesha yafuatayo: 1) njia iliyotumiwa kutofautisha uwakilishi wa kati ni kuwa\nsababu muhimu zaidi katika utendaji wa KD, 2) miongoni mwa malengo tofauti ya utofauti wa kati, mafunzo ya MI yanafanya vizuri zaidi, na 3) kuongezeka kwa takwimu zinatoa ongezeko kubwa kwa ajili ya seti ndogo za mafunzo au mitandao madogo ya wanafunzi. Zaidi ya hayo, tunagundua kuwa seti za data/kazi tofauti zinapendelea algorithi tofauti za KD, na kwa hiyo tunapendekeza algorithi rahisi ya AutoDistiller inayoweza kupendekeza pipeline nzuri ya KD kwa seti mpya ya data.', 'sq': 'Distillimi i njohurive (KD) ofron një mënyrë natyrore për të reduktuar vonesën dhe përdorimin e kujtesës/energjisë të modeleve masive të parastërvitur që kanë ardhur për të mbizotëruar Procesimin e Gjuhave Natyrore (NLP) në vitet e fundit. While numerous sophisticated variants of KD algorithms have been proposed for NLP applications, the key factors underpinning the optimal distillation performance are often confounded and remain unclear.  Ne synojmë të identifikojmë se si komponente të ndryshme në tubacionin KD ndikojnë në performancën rezultuese dhe sa optimale tubacioni KD ndryshon nëpërmjet grupeve/detyrave të ndryshme të dhënash, të tilla si politika e rritjes së të dhënave, funksioni i humbjes dhe përfaqësimi i ndërmjetësuar për transferimin e njohurive midis mësuesit dhe student ëve. Për të shkatërruar efektet e tyre, propozojmë Distiller, një kuadër meta KD që kombinon sistematikisht një gamë të gjerë teknikash nëpër faza të ndryshme të tubacionit KD, që na lejon të kuantifikojmë kontributin e çdo komponenti. Brenda Distiller, ne bashkojmë objektivat e përdorura zakonisht për distillacionin e përfaqësimeve të ndërmjetësuara nën një objektiv universal të informacionit të ndërsjelltë (MI) dhe propozojmë një klasë funksionesh objektive MI me një ndërmjetësim më të mirë paragjykimi/variancë për vlerësimin e MI midis mësuesit dhe nxënësit. Në një set të ndryshëm të të dhënave NLP, konfigurimet më të mira të Distiller janë identifikuar nëpërmjet optimizacionit në skalë të madhe të hyperparametrave. Eksperimentet tona zbulojnë të ardhshmen: 1) metoda e përdorur për distilimin e përfaqësimeve të ndërmjetësuara është\nfaktori më i rëndësishëm në performancën e KD, 2) midis objektivave të ndryshme për distillacionin ndërmjetësor, MI-performon më të mirën dhe 3) rritja e të dhënave ofron një nxitje të madhe për grupe të dhënash të vogla trainimi apo rrjete të vogla student ësh. Moreover, we find that different datasets/tasks prefer different KD algorithms, and thus propose a simple AutoDistiller algorithm that can recommend a good KD pipeline for a new dataset.', 'id': 'Knowledge Distillation (KD) offers a natural way to reduce the latency and memory/energy usage of massive pretrained models that have come to dominate Natural Language Processing (NLP) in recent years.  Sementara banyak varian sofistikasi dari algoritma KD telah diusulkan untuk aplikasi NLP, faktor kunci yang mendasarkan prestasi destilasi optimal sering bingung dan tetap tidak jelas. We aim to identify how different components in the KD pipeline affect the resulting performance and how much the optimal KD pipeline varies across different datasets/tasks, such as the data augmentation policy, the loss function, and the intermediate representation for transferring the knowledge between teacher and student.  Untuk menghancurkan efek mereka, kami mengusulkan Distiller, kerangka meta KD yang secara sistematis menggabungkan jangkauan teknik luas melalui tahap berbeda dari pipa KD, yang memungkinkan kita untuk mengurangi kontribusi setiap komponen. Dalam Distiller, kita menyatukan tujuan yang biasanya digunakan untuk destilasi dari represisi intermedi di bawah tujuan informasi antara satu sama lain universal (MI) dan mengusulkan kelas fungsi MI-objektif dengan bias/variasi yang lebih baik untuk memperkirakan MI antara guru dan siswa. Pada set data NLP yang berbeda, konfigurasi Distiller terbaik dikenal melalui optimisasi hyper-parameter skala besar. Eksperimen kami mengungkapkan yang berikut: 1) pendekatan yang digunakan untuk mendistil representation intermediate adalah\nfaktor paling penting dalam prestasi KD, 2) diantara tujuan berbeda untuk destilasi intermedi, MI-performs yang terbaik, dan 3) peningkatan data menyediakan dorongan besar untuk set data pelatihan kecil atau jaringan murid kecil. Selain itu, kami menemukan bahwa dataset/tugas yang berbeda memilih algoritma KD yang berbeda, dan sehingga melamar algoritma AutoDistiller sederhana yang dapat merekomendasikan pipeline KD yang baik untuk set data baru.', 'hy': "Գիտության դիստիլացիան (KԴ) բնական միջոց է առաջարկում նվազեցնել հիշողության և էներգիայի ուշացումը վերջին տարիների ընթացքում հսկայական նախավարժված մոդելների, որոնք գերիշխում են բնական լեզվի գործընթացը (ՆԼՊ): Մինչդեռ բազմաթիվ բարդ տարբերակներ են առաջարկվել ՆԼՊ-ի ծրագրերի համար, հիմնական գործոնները, որոնք հիմնականում են օպտիմալ դիսլիլացիայի արտադրողականությունը, հաճախ խառնվում են և մնում անհասկանալի: Մենք նպատակում ենք բացահայտել, թե ինչպես են տարբեր համակարգերը ՔԻ խողովակաշարի մեջ ազդում արդյունքում ստացված արտադրողականության վրա և թե ինչքանով է օպտիմալ ՔԻ խողովակաշարը տարբերվում տարբեր տվյալների համակարգերի միջև, ինչպիսիք են օրինակ տվյալների աճի քաղաքականությունը, կորստի To tease apart their effects, we propose Distiller, a meta KD framework that systematically combines a broad range of techniques across different stages of the KD pipeline, which enables us to quantify each component's contribution.  Դիստիլերի մեջ մենք միավորում ենք տարածաբար օգտագործված նպատակները միջին ներկայացումների դիսլիլացիայի համար համաշխարհային փոխադարձ ինֆորմացիայի (MI) նպատակի տակ և առաջարկում ենք MI-օբյեկտիվ ֆունկցիաների դասարան, որտեղ ավելի լավ կողմնականություն և տարբերությունը փոխարինվում է ուսու ՆԼՊ տվյալների բազմազան համակարգերի վրա լավագույն դիստիլերի կազմակերպությունները հայտնաբերվում են մեծ չափի հիպեր-պարամետրերի օպտիմացման միջոցով: Մեր փորձարկումները բացահայտում են հետևյալը. 1) միջին ներկայացումների բաժանման մոտեցումը\n(2) միջին դիսլիլացիայի տարբեր նպատակների մեջ MI-ն ամենալավն է աշխատում, և 3) տվյալների աճը մեծ ազդեցություն է տալիս փոքր ուսուցման տվյալների կամ փոքր ուսանողների ցանցերի համար: Ավելին, մենք հայտնաբերում ենք, որ տարբեր տվյալների համակարգերը և գործերը նախընտրում են տարբեր K- ի ալգորիթմներ, և այսպես առաջարկում են մի պարզ Auto-Դիստիլեր ալգորիթմ, որը կարող է խորհուրդ տալ նոր տվյալների համակարգի համար լավ K- ի խողովա", 'am': 'እውቀት መግለጫ (KD) ባለፈው ዓመታት ውስጥ የባሕላዊ ቋንቋ ፕሮግራም (NLP) ለመገዛት የመጣውን አካባቢ እና ማስታሰቢያ/የenergy መጠቀሚያ እና አካባቢ እና አካባቢ ጥያቄን ለማጎድልበት የፍጥረት መንገድ ያቀርባል፡፡ ምንም እንኳን ለNLP ፕሮግራሞች የተዘጋጀ የKD አልጎሪትሞች ብዙዎች የተለየ ተቃውሞ ሲሆን፣ በተለየ ማስታወቂያውን የሚያሳዩ የቁልፎች ውጤቶች ብዙ ጊዜ ያፍራሉ እናም አይታወቁም፡፡ እና በKD ፕላይንስ ውስጥ እንዴት የተለየ ክፍሎች ፍለጋውን እንዴት እንዲያስጨንቁበት እና የትኛውን የKD ፕላይና በተለያዩ ዳታተሮች/ስራዎችን የሚለየ እንዴት እንደሆነ እናሳውቃለን፡፡ ፍሬያቸውን ለማስወገድ፣ የKD ፍሬማት በተስማማማሚ የጥያቄ ጥያቄዎችን በተለየ የKD ጥያቄ በተለየ ደረጃዎች ውስጥ በተለየ ጥያቄዎችን እናቆጥራለን፡፡ በዲስታሌር ውስጥ በተለየ ጠቅላላ የሚጠቀሙትን አቃውሞ በአስተማሪና ተማሪው እና ተማሪ መካከል ሚኒ እና ተማሪዎችን መቆጣጠር በማሰናከል የሚጠቅሙትን የመካከለኛ ተሟጋቾችን ለመለየት እና የMI አካባቢ አካባቢዎችን በመጠቀም እና በተማሪዎቹ መካከል መቆጣጠርን እናሳስባታለን፡፡ On a diverse set of NLP datasets, the best Distiller configurations are identified via large-scale hyper-parameter optimization.  ፈተናዎቻችን የሚከተሉትን:1) የመካከለኛውን መልዕክቶች ለመለየት የሚጠይቁትን\nበKD ስርዓት፣ 2) በተለያዩ አቃውንቶች መካከል ለመለየት፣ MI-ማድረግ ትልቅ እና 3) ዳታ ማጨመር ማድረግ ለትንሽ ትምህርት ዳታዎችን ወይም ታናሽ ተማሪ መረብ ማድረጊያውን የሚሰጥ ትልቅ ጉዳይ ነው፡፡ ደግሞም ልዩ ዳታተሮች/ስራዎችን ልዩ KD አልጎርጂቶችን እንደሚመርጥ እናገኛለን፡፡', 'az': "Bilim Bölümü (KD) son illərdə təbiətli dil işləməsinin (NLP) hökmünü dəstəkləyən böyük qüvvətli modellərin latensiya və yaddaşları/enerji istifadəsini azaltmaq üçün təbiətli bir yol təklif edir. NLP uyğulamaları üçün çox sofistikli KD algoritminin variabları təbliğ edildikdə, optimal distillasyon performansının altındakı anahtar faktorları çox sıxıntılı və dəyişməzlər. Biz KD boru çizgisində müxtəlif komponentlərin sonuçlarının təsirini və optimal KD boru çizgisinin müxtəlif veri qurğuları/işləri kimi, məlumatların artırması siyasətini, kaybı funksiyasını və müəllimlərin və öğrencilərin arasındakı bilgiləri daşımaq üçün müxtəlif təsirlərinin nə qədər təsirini təşkil etməsini və Onların təsirlərini parçalamaq üçün Distiller'i, sistematik bir meta KD framework ü təklif edirik ki, hər komponentin qismətini kvantitat edərik. Distiller içində, müəllimin və öğrencinin arasında MI ilə müəyyən edilməsi üçün çox yaxşı tərzdə/varianslıq ticarəti ilə müəyyən edilən MI-objektif funksiyaların sınıfını təklif edirik. NLP veri qurğuları müxtəlif bir dəstədə ən yaxşı Distiller qurğuları böyük-ölçülü hyper-parametru optimizasyonu vasitəsilə tanınır. Bizim təcrübələrimiz belə göstərir:\nKD performancındakı ən önemli faktor, 2) orta destilasyon üçün müxtəlif məqsədilərin arasında, MI-lər ən yaxşı və 3) verilənlər artırması kiçik təhsil verilənlərin və kiçik öğrencilər şəklilərinin böyük artırmasını sağlar. Daha sonra, müxtəlif veri qurğuları/işləri müxtəlif KD algoritmini tercih edir. Beləliklə yeni veri qurğuları üçün yaxşı bir KD pipeline təbliğ edə bilən basit AutoDistiller algoritmi təbliğ edirik.", 'bn': 'সাম্প্রতিক বছরগুলোতে প্রাকৃতিক ভাষা প্রক্রিয়ার (এনএলপি) শাস্তির সাম্প্রতিক এবং স্মৃতি/শক্তির ব্যবহার কমিয়ে দেয়ার জন্য জ্ঞান বিভিন্ন উপায় প্রদ এনএলপি অ্যাপ্লিকেশনের জন্য কেডি অ্যালগরিদমের অনেক সাফিকিস্টিকেট ভেরিয়েন্ট প্রস্তাব করা হয়েছে, কিন্তু অপটিমেল বিচ্ছিন্ন করার কারণে প আমরা চিহ্নিত করার উদ্দেশ্য হচ্ছি কে. ডি. পাইপেলাইনের ভিন্ন ভিন্ন উপাদানের প্রভাব কিভাবে প্রভাবিত করে এবং শিক্ষক ও ছাত্রের মধ্যে জ্ঞান পরিবর্তনের জন্য কেডি পাইপেলাইন বিভিন্ন উপাত তাদের প্রভাব বিভক্ত করার জন্য আমরা ডিস্টিলার, একটি মেটা কেডি ফ্রেমার, যা কেডি পাইপেলাইনের বিভিন্ন পর্যায়ে ব্যাপক প্রযুক্তির সাথে সংযুক্ত করে, যা আমাদের প্রত ডিস্টিলারের ভিতরে আমরা সাধারণত ব্যবহার করি একটি বিশ্বব্যাপী প্রতিনিধিদের মধ্যেকার প্রতিনিধিদের বিচ্ছিন্ন করার উদ্দেশ্যে এবং শিক্ষক এবং ছাত্রের মধ্যে মিআই-এর মাঝে হিসেব বিভিন্ন ধরনের NLP ডাটাটাসেটে, বিশাল স্কেল হাইপার-প্যারামিটারের মাধ্যমে সেরা ডিস্টিলার কনফিগারেশন চিহ্নিত কর আমাদের পরীক্ষাগুলো নিচের পরীক্ষা প্রকাশ করে: ১) মধ্যপ্রতিনিধিদের বিচ্ছিন্ন করার জন্য ব্যবহৃত উপায় হচ্\nকে. ডি. এর প্রদর্শনের সবচেয়ে গুরুত্বপূর্ণ কারণ, ২) মধ্যবর্তী বিচ্ছিন্ন উদ্দেশ্যের মধ্যে বিভিন্ন উদ্দেশ্যের মধ্যে, MI-এর সেরা কাজ করে এবং ৩) ডাটা যো Moreover, we find that different datasets/tasks prefer different KD algorithms, and thus propose a simple AutoDistiller algorithm that can recommend a good KD pipeline for a new dataset.', 'ca': "La Destillació del Conèixement (KD) ofereix una manera natural de reduir la latencia i l'ús de memòria/energia de models massius pré-entrenats que han vingut a dominar el Procesament de Llingua Natural (NLP) en els últims anys. While numerous sophisticated variants of KD algorithms have been proposed for NLP applications, the key factors underpinning the optimal distillation performance are often confounded and remain unclear.  Tenim l'objectiu d'identificar com diferents components del tub de KD afecten al rendiment resultant i quant el tub de KD optim varia en diversos conjunts de dades/tasques, com la política d'augmentació de dades, la funció de pèrdua i la representació intermediària per transferir el coneixement entre professor i estudiant. Per desfer els seus efectes, proposem Distiller, un marc meta KD que combina sistemàticament una gran gamma de tècniques en diferents etapes del pipeline KD, que ens permet quantificar la contribució de cada component. Dentre Distiller, unifiquem els objectius comunament utilitzats per la destilació de representacions intermedies sota un objectiu universal d'informació mutua (MI) i proposem una classe de funcions objectives MI amb millor compromís de bias/variança per estimar el MI entre el professor i l'estudiant. En un conjunt diversificat de conjunts de dades NLP, les millors configuracions del Distiller s'identificen a través d'una gran optimització de hiper paràmetres. Els nostres experiments revelen el següent: 1) l'enfocament utilitzat per destilar les representacions intermedies és\nel factor més important en el rendiment de KD, 2) entre els diferents objectius de distillació intermediària, el MI fa el millor, i 3) el augment de les dades proporciona un gran impuls a petits conjunts de dades d'entrenament o a petites xarxes d'estudiants. A més, trobem que diferents conjunts de dades/tasques prefereixen diferents algoritmes de KD, i així proposem un simple algoritme AutoDistiller que pot recomanar un bon tub de KD per a un nou conjunt de dades.", 'cs': 'Distilace znalostí (KD) nabízí přirozený způsob, jak snížit latenci a spotřebu paměti/energie masivních předtrénovaných modelů, které v posledních letech dominují zpracování přirozeného jazyka (NLP). Zatímco pro aplikace NLP bylo navrženo mnoho sofistikovaných variant algoritmů KD, klíčové faktory, které podporují optimální destilační výkon, jsou často zmatené a zůstávají nejasné. Naším cílem je identifikovat, jak různé komponenty v KD potrubí ovlivňují výsledný výkon a jak se optimální KD potrubí liší v různých datových sadách/úkolech, jako jsou zásady rozšíření dat, funkce ztráty a mezipředstavení pro přenos znalostí mezi učitelem a studentem. Abychom odstranili jejich účinky, navrhujeme Distiller, meta KD framework, který systematicky kombinuje širokou škálu technik napříč různými fázemi KD potrubí, což nám umožňuje kvantifikovat přínos každé komponenty. V rámci Distilleru sjednocujeme běžně používané cíle pro destilaci středních reprezentací pod cílem univerzální vzájemné informace (MI) a navrhujeme třídu MI-objektivních funkcí s lepším kompromisem bias/variance pro odhad MI mezi učitelem a studentem. Na různorodé sadě NLP datových sad jsou nejlepší konfigurace Distilleru identifikovány prostřednictvím rozsáhlé optimalizace hyperparametrů. Naše experimenty odhalují následující: 1) přístup použitý k destilaci meziproduktivních reprezentací je\nNejdůležitější faktor pro výkon KD, 2) mezi různými cíli pro střední destilaci, MI-provádí nejlepší a 3) rozšíření dat poskytuje velký impuls pro malé soubory školení nebo malé studentské sítě. Kromě toho zjišťujeme, že různé datové sady/úlohy preferují různé KD algoritmy, a proto navrhujeme jednoduchý AutoDistiller algoritmus, který může doporučit dobré KD potrubí pro novou datovou sadu.', 'et': 'Teadmiste destillatsioon (KD) pakub loomulikku võimalust vähendada massiivsete eeltreenitud mudelite latentsust ja mälu/energia kasutamist, mis on viimastel aastatel hakanud domineerima loodusliku keele töötlemist (NLP). Kuigi NLP rakenduste jaoks on välja pakutud mitmeid keerukaid KD algoritmide variante, siis optimaalse destilleerimise põhitegureid segatakse sageli ja need jäävad ebaselgeks. Meie eesmärk on tuvastada, kuidas erinevad KD torujuhtme komponendid mõjutavad tulemuslikkust ja kui palju erineb optimaalne KD torujuhtme erinevate andmekogumite/ülesannete vahel, näiteks andmete suurendamise poliitika, kaotusfunktsioon ning vahepealne esindus teadmiste edastamiseks õpetaja ja õpilase vahel. Nende mõjude eristamiseks pakume välja Distilleri, metaKD raamistiku, mis ühendab süstemaatiliselt laia valikut tehnikaid KD torujuhtme erinevates etappides, mis võimaldab meil kvantifitseerida iga komponendi panust. Distilleris ühendame tavaliselt kasutatavad eesmärgid vahepealsete esituste destilleerimiseks universaalse vastastikuse informatsiooni (MI) eesmärgi all ja pakume välja MI-objektiivsete funktsioonide klassi, millel on parem erapooletus/dispersioon, et hinnata MI õpetaja ja õpilase vahel. Mitmekesiste NLP andmekogumite kogumi puhul tuvastatakse Distilleri parimad konfiguratsioonid ulatusliku hüperparameetrite optimeerimise kaudu. Meie katsed näitavad järgmist: 1) vahepealsete representatsioonide destilleerimiseks kasutatav lähenemisviis on\nKõige olulisem tegur KD jõudluses, 2) vahepealse destilleerimise erinevate eesmärkide hulgas on MI parim ja 3) andmete suurendamine annab suure hoogu väikestele koolitusandmekogumitele või väikestele õpilaste võrgustikele. Lisaks leiame, et erinevad andmekogumid/ülesanded eelistavad erinevaid KD algoritme ja seega pakume välja lihtsa AutoDistiller algoritmi, mis võib soovitada head KD torujuhet uue andmekogumi jaoks.', 'fi': 'Knowledge Distillation (KD) tarjoaa luonnollisen tavan vähentää viivettä ja muistin/energian käyttöä massiivisissa esikoulutetuissa malleissa, jotka ovat tulleet hallitsemaan Natural Language Processing (NLP) viime vuosina. Vaikka NLP-sovelluksiin on ehdotettu lukuisia kehittyneitä KD-algoritmeja, optimaalisen tislauksen perustana olevat keskeiset tekijät sekoittuvat usein keskenään ja jäävät epäselviksi. Tavoitteenamme on selvittää, miten KD-putken eri komponentit vaikuttavat tulokseen ja kuinka paljon optimaalinen KD-putken vaihtelee eri tietosarjojen/tehtävien välillä, kuten tietojen lisäämispolitiikan, häviötoiminnon ja tiedonsiirron välitoimituksen välillä opettajan ja oppilaan välillä. Näiden vaikutusten erottamiseksi ehdotamme Distilleriä, metaKD-kehystä, joka yhdistää systemaattisesti laajan valikoiman tekniikoita KD-putken eri vaiheissa, jonka avulla voimme kvantifioida jokaisen komponentin panoksen. Distillerissa yhdistämme yleisesti käytetyt tavoitteet väliesitysten tislaukseen yleismaailmallisen keskinäisen informaation (MI) tavoitteen mukaisesti ja ehdotamme MI-objektiivisten funktioiden luokkaa, jolla on parempi bias/varianssi kompromissi opettajan ja oppilaan välisen MI-arvon arvioimiseksi. Monipuolisissa NLP-tietosarjoissa parhaat Distiller-kokoonpanot tunnistetaan laajamittaisella hyperparametrioptimoinnilla. Kokeet paljastavat seuraavat: 1) menetelmä, jolla tislataan välimerkkejä, on\nTärkein tekijä KD:n suorituskyvyssä, 2) välitislauksen eri tavoitteista MI-suoriutuu parhaiten ja 3) datan lisääminen antaa suuren sysäyksen pienille koulutustiedostoille tai pienille opiskelijaverkostoille. Lisäksi huomaamme, että erilaiset datasetit/tehtävät suosivat erilaisia KD-algoritmeja, joten ehdotamme yksinkertaista AutoDistiller-algoritmia, joka voi suositella hyvää KD-putkea uudelle datasetille.', 'bs': 'Distilacija znanja (KD) nudi prirodan način da smanji latenciju i uspomenu/energiju korištenja masivnih pretkišnih modela koji su došli do dominacije prirodnog procesa jezika (NLP) u posljednjih godina. Iako su predloženi brojni sofisticirani varianti KD algoritma za aplikacije NLP-a, ključni faktori koji podržavaju optimalnu funkciju destilacije često su zbunjeni i ostali nejasni. Ciljem smo identificirati kako različiti komponenti u cjevi KD utječu na rezultate učinka i koliko se optimalna cjevina KD-a razlikuje u različitim podacima/zadacima, poput povećanja politike podataka, funkcije gubitka i prosječne zastupe za prenošenje znanja između nastavnika i učenika. Da bismo razdvojili njihove učinke, predlažemo Distiller, meta KD okvir koji sistematski kombinira širok raspon tehnika u različitim fazama cijevi KD-a, što nam omogućava kvantificirati doprinos svake komponente. U Distilleru, zajednostavljamo često korišćene ciljeve za destilaciju prosječnih predstavljanja pod univerzalnim zajedničkim informacijama (MI) objektivom i predlažemo klasu MI-objektivnih funkcija sa boljom trgovinom predrasudama/varijancijom za procjenu MI između učitelja i student a. Na različitim setima podataka NLP-a, najbolja konfiguracija Distillera identificirana su putem optimizacije velike skale hiper-parametara. Naši eksperimenti otkrivaju sljedeće:\nNajvažniji faktor učinkovitosti KD-a, 2) među različitim ciljevima za prosječnu destilaciju, MI-a najbolje izvršava i 3) povećanje podataka pruža veliku poboljšanje za male podatake za obuku ili male studentske mreže. Osim toga, smatramo da različite datasete/zadatke preferiraju različite algoritme KD-a, i stoga predlažemo jednostavan algoritam AutoDistillera koji može preporučiti dobru cjevinu KD-a za novi set podataka.', 'sk': 'Destilacija znanja (KD) ponuja naraven način za zmanjšanje latence in porabe pomnilnika/energije množičnih predtreniranih modelov, ki so v zadnjih letih prevladovali v obdelavi naravnega jezika (NLP). Medtem ko so bile za aplikacije NLP predlagane številne prefinjene različice algoritmov KD, so ključni dejavniki, ki temeljijo na optimalni destilaciji, pogosto zmedeni in ostajajo nejasni. Naš cilj je ugotoviti, kako različne komponente v cevovodu KD vplivajo na rezultat in koliko se optimalni cevovod KD razlikuje med različnimi nabori podatkov/opravili, kot so politika povečanja podatkov, funkcija izgube in vmesna predstavitev za prenos znanja med učiteljem in učencem. Da bi razlikovali njihove učinke, predlagamo Distiller, metaKD okvir, ki sistematično združuje širok nabor tehnik v različnih fazah KD cevovoda, kar nam omogoča kvantificiranje prispevka vsake komponente. V okviru Distillerja združimo običajno uporabljene cilje za destilacijo vmesnih reprezentacij pod ciljem univerzalne medsebojne informacije (MI) in predlagamo razred MI-objektivnih funkcij z boljšim kompromisom pristranskosti/variance za oceno MI med učiteljem in učencem. Na različnih naborih podatkov NLP so najboljše konfiguracije Distillerja prepoznane z optimizacijo hiperparametrov velikega obsega. Naši poskusi razkrivajo naslednje: 1) pristop, ki se uporablja za destiliranje vmesnih reprezentacij, je\nNajpomembnejši dejavnik v uspešnosti KD, 2) med različnimi cilji za vmesno destilacijo MI-deluje najboljše, in 3) povečanje podatkov zagotavlja veliko spodbudo za majhne nabore podatkov o usposabljanju ali majhne mreže študentov. Poleg tega ugotavljamo, da imajo različni nabori podatkov/opravila raje različne KD algoritme, zato predlagamo preprost algoritem AutoDistiller, ki lahko priporoča dober KD cevovod za nov nabor podatkov.', 'jv': 'Distilling Bilih (KDE) kang ndheke perbudhakan yakuwis sistem yakuwis nggawe nguasai kapan pangan lan ijol-ingkang sistem padha ingkang dianggawe sistem yang cukup. Eror Awak dhéwé kabèh nglanggar pisan sampeyan karo perusahaan KDE sing paling nggawe barang nggawe barang nggawe dataset/tasks gak nggawe dataset Rasane gawe ngubah efekan wong, kita ngubah Distillir, arkane meta KDE sing sistematik ngubah Mèh Distillir, kita sedhaya ngaweh akeh gunakake nggawe tarjamahan kanggo ngilanggar tarjamahan intermediate sing ngetokake nggawe informasi intermediate (MI) iso nggawe kelas sistem MU2-Objecti sing berarti podho bias/Aljane kuwi nggawe MU2 terus alih dumadhi kamunyatan karo akeh umur. In a multi set of NLP dataset, the top Distillir configurations are detected by big-scale caper-parameters Optimisation. 1) Ndheke sing dibutungano barang kelas barang\nProgressBarUpdates Label', 'ha': "@ info: whatsthis Akwai da aka buƙata masu yawa masu sofi da algoritori na KD wa shiryoyin ayuka na NLP, sai maɓallin faktoren da ke ƙara fasalin sigarin da baƙaƙƙe masu amfani da baƙaƙƙe, ana kasa bayan. Tuna aimar mu gane jinsi masu variani cikin pipilin KD sun yi amfani da fasarin ta ƙara kuma da yawa pipipilin KD na da amfani da yawa suka sãɓã a cikin kowaci masu tsari/taskõki, kamar misãlan ƙaramako da data, da ɓarnata, da kuma ma'aunin tsakiya dõmin ta motsari ilmi tsakanin mai macallin da mai kifi. To, ka tsãge Effekt masu, muna goyyar da DisTiler, wata firam na KD wanda ke haɗa wasu masu motsi da ɗabi'a cikin daraja daban-daban na KD, da kuma yana yarda da mu ƙayyade ƙarami ga duk compound. Insen Distiler, Muke uniyyade abubuwa da ana yi amfani da shi ga rarraba masu tsakanin mazaɓa da abubuwa na universal information (MI) objective kuma tuna wani nau'i na MI-objective da mafi kyau ga abinci/variance-offs for estimatin MI tsakanin mai macallin da ardan. Ko cikin wasu daidaita na NLP masu tsari, za'a gane tsarin bayani na tsumarni mai girma da tsohon-parameter. Our experiments reveal the following: 1) the approach used to distill the intermediate representations is the\nQUnicodeControlCharacterMenu Za kuma, za mu gane cewa wasu shiryoyin database/aikin ba su fĩfĩta algoritori na daban KD, don haka, ka buƙata wata algoritm mai sauƙi na farat kwamfyuta da zai buƙata wani pipe mai kyau na KD wa wani tsarin da ake samu.", 'he': "Knowledge Distillation (KD) offers a natural way to reduce the latency and memory/energy usage of massive pretrained models that have come to dominate Natural Language Processing (NLP) in recent years.  למרות שהצעו שינויים רבים מתוחכמים של אלגוריתמים KD לתוכניות NLP, הגורמים המרכזים שמסמכים על ביצועי הדיסיל האופטימלי לעתים קרובות מבולבלים ונשארים לא ברורים. אנו מתכוונים לזהות כיצד רכיבים שונים בצינור KD משפיעים על ההופעה הנוצאה וכמה צינור KD האופטימלי משתנה בין קבוצות נתונים/משימות שונות, כמו מדיניות גידול נתונים, הפונקציה האבדה, והייצוג הביניי להעברת הידע בין המורה לסטודנט. To tease apart their effects, we propose Distiller, a meta KD framework that systematically combines a broad range of techniques across different stages of the KD pipeline, which enables us to quantify each component's contribution.  בתוך דיסטילר, אנו מאחדים מטרות משתמשות באופן רגיל למייצוגים בינוניים תחת מטרה מידע משותף אוניברסלי (MI) ומציעים שיעור של תפקידים אובייקטיביים MI עם מחליף חיווי/שינוי טוב יותר כדי להעריך את MI בין המורה והסטודנט. במערכת מיוחדת של קבוצות נתונים של NLP, הגדרות הטובות ביותר של הדיסטילר מזהה באמצעות אופטימיזציה היפר-פרמטרים בקנה מידה גדולה. הניסויים שלנו חושפים את זה:\nmost important factor in KD performance, 2) among different objectives for intermediate distillation, MI-performs the best, and 3) data augmentation provides a large boost for small training datasets or small student networks.  חוץ מזה, אנחנו מוצאים שמערכות נתונים/משימות שונות מעדיפות אלגוריתמים KD שונים, ולכן מציעים אלגוריתם AutoDistiller פשוט שיכול להמליץ צינור KD טוב לקבוצה נתונים חדשה.", 'bo': "Knowledge Distillation (KD)འཛམ་གླིང་གི་སྔོན་ལྟར་དུ་རང་བཞིན་གྱིས་རྒྱབ་སྐྱོར་དང་དུས་མཐུན་གྱི་ཐབས་ལམ་ལ་ཕར་ཐབས་ཤིང་ཡོད། KD་ཡི་སྒྲིག་སྟངས་ཀྱི་ཆ་རྐྱེན་གྱིས་NLP ཉེར་སྤྱོད་ལ་སྔོན་སྒྲིག་ཡོད་པ་དང་གཙོ་ཆེ་རྐྱེན་གྱིས་ཕན་ཚུན་རྐྱེན་བྱེད་མཁན་དག་རྒྱུན We aim to identify how different components in the KD pipeline affect the resulting performance and how much the optimal KD pipeline varies across different datasets/tasks, such as the data augmentation policy, the loss function, and the intermediate representation for transferring the knowledge between teacher and student. To tease apart their effects, we propose Distiller, a meta KD framework that systematically combines a broad range of techniques across different stages of the KD pipeline, which enables us to quantify each component's contribution. To tease apart their effects, we propose Distiller, a meta KD དབྱིན་འགྱུར་བའི་ནང་དུ་ང་ཚོ་ཚང་མས་སྤྱིར་བཏོན་པའི་དམིགས་བསལ་བ་དང་རྒྱལ་ཁབ་ཀྱི་གནས་ཚུལ་དང་མཐུན་སྒྲིག On a diverse set of NLP datasets, the best Distiller configurations are identified via large-scale hyper-parameter optimization. ང་ཚོའི་བརྟག་ཞིག་གི་སྔོན་ལྟར་བཞིན་བྱེད་མི་འདྲ་བྱེད་ཀྱི་ཐབས་ལམ།\nKD་ཡི་སྒྲུབ་གྲངས་ནང་དུ་ཚོ་གལ་ཆེ་བའི་ཆ་རྐྱེན་བྱས་པ་ཡིན། ཡིན་ཡང་། འུ་ཚོས་ཀྱིས་KD སྒྲིག་ཆ་འཕྲིན་དང་་ལས་ཀ་འདི་སྟབས་མི་འདྲ་བ་ཡིན་པ་ལས་སྔོན་སྒྲིག་ཡིག་ཆ་སྟབས་བདེ་བོ་སྤྲོད་དགོས་པའི་རང་འགུལ་གྱིས་རྩིས"}
{'en': 'Shrinking Bigfoot : Reducing wav2vec 2.0 footprint', 'es': 'Reducir Bigfoot: Reducir la huella de wav2vec 2.0', 'ar': 'تقلص Bigfoot: تقليل أثر wav2vec 2.0', 'pt': 'Encolher Bigfoot: Reduzindo a pegada do wav2vec 2.0', 'fr': "Bigfoot rétrécissant\xa0: réduction de l'empreinte de wav2vec 2.0", 'ja': 'ビッグフットの縮小： wav 2 vec 2.0フットプリントの削減', 'hi': 'सिकुड़ते बिगफुट: wav2vec 2.0 पदचिह्न को कम करना', 'zh': '缩小大脚怪:减wav2vec 2.0迹', 'ga': 'Crapadh Bigfoot: Lorg wav2vec 2.0 a laghdú', 'ru': 'Сжимающийся снежный человек: уменьшение wav2vec 2.0 занимаемой площади', 'ka': 'შემცირება დიგფეტი: wav2vec 2. 0 ფესტის დამატება', 'el': 'Συρρικνωθείς Μεγαλοπόδαρος: Μείωση του αποτυπώματος 2.0', 'hu': 'Zsugorodás Bigfoot: a wav2vec 2.0 lábnyom csökkentése', 'kk': 'Үлкен футты кішірейту: wav2vec 2. 0 футты басып шығару', 'it': "Riduzione del Bigfoot: riduzione dell'impronta wav2vec 2.0", 'lt': 'Didelių pėdų mažinimas: Wav2vec 2,0 pėdų mažinimas', 'mk': 'Намалување на големиот стапал: Намалување на стапалот на wav2vec 2.0', 'ml': 'ബിഗ്ഫൂട്ടിങ്ങ് ചെയ്യുന്നു: വാവ്2vec 2. 0 കാല്\u200dക്കോട്ട് ചുരുക്കുന്നു', 'ms': 'Kurangkan Bigfoot: Kurangkan wav2vec 2.0 jejak kaki', 'mt': 'Tnaqqis tal-Bigfoot: Tnaqqis tal-impronta tal-wav2vec 2.0', 'mn': 'Бигфутыг багасгаж байна: wav2vec 2.0 хөл хэвлэлийг багасгаж байна', 'pl': 'Zmniejszenie wielkiej stopy: zmniejszenie śladu wav2vec 2.0', 'ro': 'Micșorarea Bigfoot: reducerea amprentei wav2vec 2.0', 'no': 'Smøring av Bigfoot: Reduserer wav2vec 2. 0 fottutskrift', 'sr': 'Smanjivanje Velikog stopala: smanjivanje stopala wav2vec 2,0 stopala', 'so': 'Xidididda Bigfoot: Reducing wav2vec 2.0 footprint', 'si': 'බිග්ෆිට් සංකීර්ණය: වැව2වෙක් 2. 0 පුද්ගලිපින්ට වැඩ කරනවා', 'sv': 'Minska Bigfoot: Minska wav2vec 2.0-fotavtrycket', 'ur': 'بڑفوت کم کر رہا ہے: wav2vec 2.0 فوت پرینٹ کم کر رہا ہے', 'ta': 'பிக் ஃபூட்டை சுருக்குகிறது: வாவ்2vec 2. 0 கால் அச்சுப்பொறி குறைக்கப்படுகிறது', 'uz': 'Bigfoot boò£yogò£i: wav2vec 2. 0 foydalanuvchi kamaytirilmoqda', 'vi': 'Thu nhỏ Chân To: Giảm ảnh lượng wappesi 2.0', 'bg': 'Намаляване на големия крак: Намаляване на отпечатъка', 'da': 'Skrumpe Bigfoot: Reducere wav2vec 2.0 fodaftryk', 'nl': 'Het krimpen van Bigfoot: het verminderen van wav2vec 2.0 footprint', 'hr': 'Smanjivanje Velikog stopala: smanjivanje otisaka wav2vec 2,0 stopala', 'de': 'Schrumpfender Bigfoot: Reduzierung des wav2vec 2.0 Footprint', 'ko': '족제비 축소:wav2vec 2.0의 차지 면적 감소', 'id': 'Mengurangi Bigfoot: Mengurangi wav2vec 2.0 jejak kaki', 'fa': 'کاهش پای بزرگ: کاهش اثر پای wav2vec 2. 0', 'sw': 'Kuzungumzia Bigfoot: Kupunguza nyayo za wav2vec 2.0', 'af': 'Verklein Bigfoot: Verklein wav2vec 2. 0 voetskrif', 'am': 'undo-type', 'sq': 'Shkatërrimi i këmbës së Madhe: Shkatërrimi i gjurmës së wav2vec 2.0', 'tr': 'Pigfoot azalýar: wav2vec 2.0 futbol azalýar', 'az': 'Böyük foot azaltma: wav2vec 2.0 ayaq izi azaltma', 'bn': 'বিগফুট শ্রিঙ্কিং: ওয়াভ ২ভেভিক ২. ০ ফুটপ্রিন্ট কমিয়ে আনা হচ্ছে', 'hy': 'Մեծ ոտքերի փոքրացումը. Ուղու2Վ 2.0 ոտքերի փոքրացումը', 'et': 'Suurjala kahanemine: wav2vec 2.0 jalajälje vähendamine', 'bs': 'Smanjivanje Velikog stopala: smanjivanje otisaka wav2vec 2,0 stopala', 'ca': "Reduccionant Bigfoot: Reduccionant l'empremta de wav2vec 2,0", 'fi': 'Pienentävä Bigfoot: Vähentää wav2vec 2.0 jalanjälkeä', 'cs': 'Smršťující se Bigfoot: Snížení stopy wav2vec 2.0', 'sk': 'Krčenje Bigfoot: zmanjšanje odtisa wav2vec 2.0', 'he': 'צמצם רגל גדולה: צמצם טביעת רגל wav2vec 2.0', 'jv': 'Path segment tip', 'bo': 'འདར་བའི་Bigfoot ། wav2vec 2.0 རྩིས་ཡིག་གཟུགས་འབྲི་བཞིན་པ།', 'ha': 'KCharselect unicode block name'}
{'en': 'Wav2vec 2.0 is a state-of-the-art speech recognition model which maps speech audio waveforms into latent representations. The largest version of wav2vec 2.0 contains 317 million parameters. Hence, the inference latency of wav2vec 2.0 will be a bottleneck in production, leading to high costs and a significant environmental footprint. To improve wav2vec’s applicability to a production setting, we explore multiple model compression methods borrowed from the domain of large language models. Using a teacher-student approach, we distilled the knowledge from the original wav2vec 2.0 model into a student model, which is 2 times faster, 4.8 times smaller than the original model. More importantly, the student model is 2 times more energy efficient than the original model in terms of CO2 emission. This increase in performance is accomplished with only a 7 % degradation in word error rate (WER). Our quantized model is 3.6 times smaller than the original model, with only a 0.1 % degradation in WER. To the best of our knowledge, this is the first work that compresses wav2vec 2.0.', 'ar': 'يعد Wav2vec 2.0 نموذجًا متطورًا للتعرف على الكلام يقوم بتعيين الأشكال الموجية الصوتية للكلام إلى تمثيلات كامنة. يحتوي الإصدار الأكبر من wav2vec 2.0 على 317 مليون معلمة. ومن ثم ، فإن الكمون الاستنتاجي لـ wav2vec 2.0 سيكون عنق الزجاجة في الإنتاج ، مما يؤدي إلى ارتفاع التكاليف والبصمة البيئية الكبيرة. لتحسين قابلية تطبيق wav2vec على إعداد الإنتاج ، نستكشف طرق ضغط نماذج متعددة مستعارة من مجال نماذج اللغات الكبيرة. باستخدام نهج المعلم والطالب ، قمنا بتقطير المعرفة من نموذج wav2vec 2.0 الأصلي في نموذج الطالب ، وهو أسرع مرتين ، وأصغر 4.8 مرة من النموذج الأصلي. الأهم من ذلك ، أن نموذج الطالب هو أكثر كفاءة في استخدام الطاقة بمرتين من النموذج الأصلي من حيث انبعاث ثاني أكسيد الكربون. يتم تحقيق هذه الزيادة في الأداء مع انخفاض بنسبة 7 ٪ فقط في معدل أخطاء الكلمات (WER). نموذجنا الكمي أصغر 3.6 مرة من النموذج الأصلي ، مع تدهور بنسبة 0.1 ٪ فقط في WER. على حد علمنا ، هذا هو العمل الأول الذي يضغط wav2vec 2.0.', 'es': 'Wav2vec 2.0 es un modelo de reconocimiento de voz de última generación que mapea formas de onda de audio de voz en representaciones latentes. La versión más grande de wav2vec 2.0 contiene 317 millones de parámetros. Por lo tanto, la latencia de inferencia de wav2vec 2.0 será un cuello de botella en la producción, lo que generará altos costos y una huella ambiental significativa. Para mejorar la aplicabilidad de wav2vec a un entorno de producción, exploramos varios métodos de compresión de modelos tomados del dominio de los modelos de lenguaje grandes. Utilizando un enfoque de profesor-alumno, resumimos el conocimiento del modelo wav2vec 2.0 original en un modelo de estudiante, que es 2 veces más rápido, 4,8 veces más pequeño que el modelo original. Y lo que es más importante, el modelo del estudiante es 2 veces más eficiente energéticamente que el modelo original en términos de emisión de CO2. Este aumento en el rendimiento se logra con solo una degradación del 7% en la tasa de error de palabras (WER). Nuestro modelo cuantificado es 3,6 veces más pequeño que el modelo original, con solo un 0,1% de degradación en el WER. Hasta donde sabemos, este es el primer trabajo que comprime wav2vec 2.0.', 'fr': "Wav2vec 2.0 est un modèle de reconnaissance vocale de pointe qui mappe les formes d'onde audio vocales en représentations latentes. La plus grande version de wav2vec 2.0 contient 317 millions de paramètres. Par conséquent, la latence d'inférence de wav2vec 2.0 constituera un goulot d'étranglement dans la production, entraînant des coûts élevés et une empreinte environnementale significative. Pour améliorer l'applicabilité de wav2vec à un environnement de production, nous explorons plusieurs méthodes de compression de modèles empruntées au domaine des grands modèles de langage. En utilisant une approche enseignant-étudiant, nous avons distillé les connaissances du modèle original wav2vec 2.0 dans un modèle étudiant, qui est 2 fois plus rapide, 4,8 fois plus petit que le modèle original. Plus important encore, le modèle étudiant est deux fois plus économe en énergie que le modèle original en termes d'émissions de CO2. Cette augmentation des performances est réalisée avec seulement une dégradation de 7\xa0% du taux d'erreur de mot (WER). Notre modèle quantifié est 3,6 fois plus petit que le modèle original, avec seulement 0,1\xa0% de dégradation du REH. À notre connaissance, il s'agit du premier travail qui compresse wav2vec 2.0.", 'pt': 'Wav2vec 2.0 é um modelo de reconhecimento de fala de última geração que mapeia formas de onda de áudio de fala em representações latentes. A maior versão do wav2vec 2.0 contém 317 milhões de parâmetros. Portanto, a latência de inferência do wav2vec 2.0 será um gargalo na produção, levando a altos custos e uma pegada ambiental significativa. Para melhorar a aplicabilidade do wav2vec a uma configuração de produção, exploramos vários métodos de compressão de modelo emprestados do domínio de grandes modelos de linguagem. Usando uma abordagem professor-aluno, destilamos o conhecimento do modelo wav2vec 2.0 original em um modelo de aluno, que é 2 vezes mais rápido, 4,8 vezes menor que o modelo original. Mais importante ainda, o modelo do estudante é 2 vezes mais eficiente em termos de energia do que o modelo original em termos de emissão de CO2. Este aumento no desempenho é obtido com apenas uma degradação de 7% na taxa de erro de palavra (WER). Nosso modelo quantizado é 3,6 vezes menor que o modelo original, com apenas 0,1% de degradação no WER. Até onde sabemos, este é o primeiro trabalho que comprime o wav2vec 2.0.', 'ja': 'Wav 2 vec 2.0は、音声音声波形を潜在表現にマッピングする最先端の音声認識モデルです。 Wav 2 vec 2.0の最大バージョンには、3億1700万のパラメータが含まれています。 したがって、wav 2 vec 2.0の推論レイテンシは、生産におけるボトルネックとなり、高コストと顕著な環境フットプリントにつながります。 生産環境へのwav 2 vecの適用性を向上させるために、大規模言語モデルのドメインから借用した複数のモデル圧縮方法を探索します。 教師と学生のアプローチを使用して、元のwav 2 vec 2.0モデルからの知識を学生モデルに抽出しました。これは元のモデルの2倍速く、4.8倍小さいです。 さらに重要なのは、学習者モデルは、CO 2排出量の点で元のモデルの2倍のエネルギー効率です。 このパフォーマンスの向上は、ワードエラー率（ WER ）のわずか7 ％の低下で達成されます。 当社の量子化モデルは、元のモデルよりも3.6倍小さく、WERではわずか0.1%の劣化しかありません。 私たちの知る限りでは、これはwav 2 vec 2.0を圧縮した最初の作品です。', 'hi': 'Wav2vec 2.0 एक अत्याधुनिक भाषण मान्यता मॉडल है जो अव्यक्त प्रतिनिधित्व में भाषण ऑडियो waveforms नक्शे है. wav2vec 2.0 के सबसे बड़े संस्करण में 317 मिलियन पैरामीटर शामिल हैं। इसलिए, wav2vec 2.0 का अनुमान विलंबता उत्पादन में एक बाधा होगी, जिससे उच्च लागत और एक महत्वपूर्ण पर्यावरणीय पदचिह्न होगा। wav2vec की उत्पादन सेटिंग के लिए प्रयोज्यता में सुधार करने के लिए, हम बड़े भाषा मॉडल के डोमेन से उधार लिए गए कई मॉडल संपीड़न विधियों का पता लगाते हैं। एक शिक्षक-छात्र दृष्टिकोण का उपयोग करते हुए, हमने मूल wav2vec 2.0 मॉडल से ज्ञान को एक छात्र मॉडल में आसुत किया, जो मूल मॉडल की तुलना में 2 गुना तेज, 4.8 गुना छोटा है। इससे भी महत्वपूर्ण बात यह है कि छात्र मॉडल CO2 उत्सर्जन के मामले में मूल मॉडल की तुलना में 2 गुना अधिक ऊर्जा कुशल है। प्रदर्शन में यह वृद्धि शब्द त्रुटि दर (WER) में केवल 7% गिरावट के साथ पूरी की जाती है। हमारा क्वांटाइज्ड मॉडल मूल मॉडल की तुलना में 3.6 गुना छोटा है, जिसमें WER में केवल 0.1% गिरावट है। हमारे ज्ञान का सबसे अच्छा करने के लिए, यह पहला काम है कि wav2vec 2.0 compresses है.', 'zh': 'Wav2vec 2.0 者,先进语音之别模形也,射音频波形潜也。 版本之大 wav2vec 2.0 含 3.17 亿个参数。 是以wav2vec 2.0之推迟,将为生瓶颈,致成本显迹。 为wav2vec之适用性,求诸大言压缩道。 师生之法,倍wav2vec 2.0弟子,疾2倍之,小4.8倍之。 弟子模形倍于二氧化碳节能2。 此性能之高,在单词错误率 (WER) 降 7% 也。 吾量化小倍 3.6 ,WER 降 0.1%。 以吾所知,一压缩wav2vec 2.0之事也。', 'ru': 'Wav2vec 2.0 - это современная модель распознавания речи, которая преобразует формы речевых звуковых сигналов в скрытые представления. Самая большая версия wav2vec 2.0 содержит 317 миллионов параметров. Следовательно, задержка вывода wav2vec 2.0 будет узким местом в производстве, что приведет к высоким затратам и значительному экологическому воздействию. Чтобы улучшить применимость wav2vec к производственным настройкам, мы изучаем несколько методов сжатия моделей, заимствованных из области больших языковых моделей. Используя подход «преподаватель-ученик», мы дистиллировали знания из оригинальной модели wav2vec 2.0 в студенческую модель, которая в 2 раза быстрее, в 4,8 раза меньше, чем оригинальная модель. Что более важно, студенческая модель в 2 раза более энергоэффективна, чем исходная модель с точки зрения выбросов CO2. Это увеличение производительности достигается только с 7% ухудшением частоты ошибок в словах (WER). Наша квантованная модель в 3,6 раза меньше, чем исходная модель, с деградацией только 0,1% в WER. Насколько нам известно, это первая работа, которая сжимает wav2vec 2.0.', 'ga': 'Samhail aitheantais cainte úrscothach is ea Wav2vec 2.0 a mapálann tonnta cainte fuaime ina léiriú folaigh. Tá 317 milliún paraiméadair sa leagan is mó de wav2vec 2.0. Mar sin, beidh latency tátal wav2vec 2.0 ina bac sa táirgeadh, as a dtiocfaidh costais arda agus lorg comhshaoil suntasach. Chun feabhas a chur ar infheidhmeacht wav2vec maidir le suíomh táirgthe, déanaimid iniúchadh ar mhodhanna iolracha comhbhrú samhlacha a fuarthas ar iasacht ó fhearann na múnlaí móra teanga. Ag baint úsáide as cur chuige múinteoir-mac léinn, dhriogadh muid an t-eolas ón múnla bunaidh wav2vec 2.0 isteach i múnla mac léinn, atá 2 uair níos tapúla, 4.8 uair níos lú ná an tsamhail bhunaidh. Níos tábhachtaí fós, tá samhail an mhic léinn dhá uair níos tíosaí ar fhuinneamh ná an tsamhail bhunaidh i dtéarmaí astaíochtaí CO2. Baintear an t-ardú feidhmíochta seo amach le díghrádú 7% ar an ráta earráide focal (WER). Tá ár múnla cainníochtaithe 3.6 huaire níos lú ná an tsamhail bhunaidh, agus níl ach díghrádú 0.1% i WER. Chomh fada agus is eol dúinn, is é seo an chéad saothar a chomhbhrúigh wav2vec 2.0.', 'hu': 'A Wav2vec 2.0 egy korszerű beszédfelismerő modell, amely a beszédhang hullámformáit látens reprezentációkká térképezi. A wav2vec 2.0 legnagyobb verziója 317 millió paramétert tartalmaz. Ezért a wav2vec 2.0 késleltetése szűk keresztmetszetet jelent a termelésben, ami magas költségekhez és jelentős környezeti lábnyomhoz vezet. A wav2vec alkalmazhatóságának javítása érdekében többféle modelltömörítési módszert vizsgálunk a nagy nyelvű modellek területén. Tanár-diák megközelítést alkalmazva az eredeti wav2vec 2.0 modellből kétszer gyorsabb, 4,8-szor kisebb, mint az eredeti modell. Ami még fontosabb, a diákmodell kétszer energiahatékonyabb, mint az eredeti modell CO2 kibocsátása szempontjából. Ezt a teljesítménynövekedést a szóhibaarány (WER) mindössze 7%-os romlásával érjük el. Kvantizált modellünk 3,6-szor kisebb, mint az eredeti modell, csak 0,1%-os lebomlással a WER-ben. Legjobb tudásunk szerint ez az első munka, amely tömöríti a wav2vec 2.0.', 'el': "Το 2.0 είναι ένα μοντέλο αναγνώρισης ομιλίας τελευταίας τεχνολογίας που χαρτογραφεί τις μορφές ήχου ομιλίας σε λανθάνουσες αναπαραστάσεις. Η μεγαλύτερη έκδοση του περιέχει 317 εκατομμύρια παραμέτρους. Ως εκ τούτου, η καθυστέρηση συμπερασμάτων του θα αποτελέσει εμπόδιο στην παραγωγή, οδηγώντας σε υψηλό κόστος και σημαντικό περιβαλλοντικό αποτύπωμα. Για να βελτιωθεί η δυνατότητα εφαρμογής του σε μια ρύθμιση παραγωγής, εξερευνούμε πολλαπλές μεθόδους συμπίεσης μοντέλων που δανείζονται από τον τομέα των μοντέλων μεγάλων γλωσσών. Χρησιμοποιώντας μια προσέγγιση δασκάλου-μαθητή, αποστατήσαμε τη γνώση από το αρχικό μοντέλο σε ένα μοντέλο μαθητή, το οποίο είναι δύο φορές γρηγορότερο, 4,8 φορές μικρότερο από το αρχικό μοντέλο. Το πιο σημαντικό είναι ότι το φοιτητικό μοντέλο είναι δύο φορές πιο ενεργειακά αποδοτικό από το αρχικό μοντέλο όσον αφορά τις εκπομπές CO2. Αυτή η αύξηση της απόδοσης επιτυγχάνεται με μόνο 7% υποβάθμιση του ποσοστού σφάλματος λέξεων (WER). Το κβαντισμένο μοντέλο μας είναι 3,6 φορές μικρότερο από το αρχικό μοντέλο, με μόνο 0,1% υποβάθμιση στο WER. Απ' όσο γνωρίζουμε, αυτή είναι η πρώτη εργασία που συμπιέζει 2.0.", 'ka': 'Name wav2vec 2. 0-ის დიდი ვერსია შექმნა 317 მილიონი პარამეტრები. ამიტომ, wav2vec 2.0-ის ინფრენციური ბედნიერება იქნება პროექტის ბედნიერებაში, რომელიც უფრო დიდი ღირებულება და მნიშვნელოვანი სამყარო ფედნიერება. გამოვიყენოთ wav2vec-ის პროექტირების შესაძლებლობა, ჩვენ მრავალ მოდელური კომპრესირების მეტოვების გამოყენება, რომლებიც დიდ ენის მოდელების დიომინდან დავწყენ მასწავლებელი-სტუდენტის მიზეზის გამოყენება, ჩვენ განსხვავებდით უცნობას orijinal wav2vec 2.0 მოდელზე სტუდენტის მოდელში, რომელიც 2-ჯერ უფრო სიჩქარე, 4.8-ჯერ უფრო უფრო მნიშვნელოვანია, სტუდენტის მოდელი 2-ჯერ უფრო ენერგია ეფექტიურია, ვიდრე ორიგინალური მოდელი CO2-ის ამოცემის შესახებ. ეს გამოსახულება მხოლოდ 7% დეგრადიაცია სიტყვების შეცდომა სიტყვების სიტყვებით (WER) დასრულია. ჩვენი კვანტიზური მოდელი 3,6-ჯერ ნაკლებია ორიგინალური მოდელზე, მხოლოდ 0,1% დეგრადიაცია WER-ში. ჩვენი უკეთესი მეცნიერებისთვის, ეს არის პირველი სამუშაო, რომელიც wav2vec 2.0-ს კომპრექცის.', 'it': "Wav2vec 2.0 è un modello di riconoscimento vocale all'avanguardia che mappa le forme d'onda audio vocali in rappresentazioni latenti. La versione più grande di wav2vec 2.0 contiene 317 milioni di parametri. Quindi, la latenza di deduzione di wav2vec 2.0 sarà un collo di bottiglia nella produzione, portando a costi elevati e una significativa impronta ambientale. Per migliorare l'applicabilità di wav2vec a un ambiente di produzione, esploriamo diversi metodi di compressione dei modelli presi in prestito dal dominio dei modelli di grandi lingue. Utilizzando un approccio insegnante-studente, abbiamo distillato le conoscenze dal modello originale wav2vec 2.0 in un modello studente, che è 2 volte più veloce, 4,8 volte più piccolo del modello originale. Ancora più importante, il modello studentesco è 2 volte più efficiente dal punto di vista energetico rispetto al modello originale in termini di emissioni di CO2. Questo aumento delle prestazioni si ottiene solo con una degradazione del 7% nel tasso di errore delle parole (WER). Il nostro modello quantizzato è 3,6 volte più piccolo del modello originale, con solo una degradazione dello 0,1% in WER. Per quanto ne sappiamo, questo è il primo lavoro che comprime wav2vec 2.0.", 'kk': 'Wav2vec 2. 0 - сөйлеу аудио толқынды келесі келтірілгендерге карталау үлгісі. wav2vec 2. 0 деген ең үлкен нұсқасы 317 миллион параметрлер бар. Сондықтан, wav2vec 2. 0- тың көпшілігінің көпшілігі өзгертілігі өзгертілген жағдайда, жоғары бағаттарды және өте маңызды орташа басып шығарылады. wav2vec жасау параметріне қолдану үшін бірнеше үлгі тіл үлгілерінің доменінен алынған компресациялық әдістерін зерттейміз. Мұғалім- студенттердің көмегімен білімдерді бастапқы wav2vec 2.0 моделінен студенттердің моделіне айырдық. Бұл 2 рет жылдам, 4.8 рет бастапқы моделінен кіші. Ең маңызды, студенттер үлгісі CO2 emission нәтижесінде бастапқы үлгісінен 2 рет енергия эффективні болады. Бұл жылдамдығын өзгерту сөздердің қате жылдамдығында ғана 7% деградациясы болады. Біздің квантизияланған үлгіміз бастапқы үлгіден 3,6 рет кіші, WER дегенде тек 0,1% деградациясы бар. Біздің біліміміздің ең жақсы жағдай, бұл wav2vec 2.0 сығылған алғашқы жұмыс.', 'lt': 'Wav2vec 2.0 yra naujausias kalbos atpažinimo model is, kuriame kalbos garso bangų formos žemėlapizuojamos į latentines nuotraukas. Didžiausioje wav2vec 2.0 versijoje yra 317 milijonų parametrų. Hence, the inference latency of wav2vec 2.0 will be a bottleneck in production, leading to high costs and a significant environmental footprint.  Siekiant pagerinti wav2vec taikymą gamybos nustatymui, tiriame kelis modelius suspaudimo metodus, pasiskolintus iš didelių kalbų modelių srities. Naudodami mokytojo ir studento metodą, iš pradinio wav2vec 2.0 modelio išmanymą distiliavome į mokytojo model į, kuris yra 2 kartus greitesnis, 4,8 karto mažesnis nei pradinis model is. More importantly, the student model is 2 times more energy efficient than the original model in terms of CO2 emission.  Šis veiksmingumo padidėjimas pasiekiamas tik 7 % pablogėjus žodžių klaidų dažniui (WER). Mūsų kiekybinis model is yra 3,6 karto mažesnis už pradinį model į, o WER skaidymas yra tik 0,1 %. Kaip žinome, tai pirmasis darbas, kuris spaudžia wav2vec 2.0.', 'mk': 'Wav2vec 2. 0 е најсовремен модел за препознавање на говорот кој ги мапира звуковите бранови на говорот во лантни претставувања. The largest version of wav2vec 2.0 contains 317 million parameters.  Затоа, лантенцијата на инференцијата на wav2vec 2.0 ќе биде пречка во производството, што ќе доведе до високи трошоци и значителен отпечаток на животната средина. За да ја подобриме апликабилноста на wav2vec за производско поставување, истражуваме многуте модели методи на компресија позајмени од доменот на големи јазички модели. Користејќи пристап учител-студент, го дестилиравме знаењето од оригиналниот модел wav2vec 2.0 во студентски модел, кој е 2 пати побрз, 4.8 пати помал од оригиналниот модел. Поважно е, студентскиот модел е двапати поенергетски ефикасен од оригиналниот модел во поглед на емисијата на CO2. This increase in performance is accomplished with only a 7% degradation in word error rate (WER).  Нашиот квантизиран модел е 3,6 пати помал од оригиналниот модел, со само 0,1% деградација во ВЕР. Според нашето знаење, ова е првата работа која го компресира wav2vec 2.0.', 'ml': 'വാവ്2വിക് 2. 0 ഒരു സ്റ്റേറ്റ്- ആർട്ട് സംസാരം തിരിച്ചറിയാനുള്ള മോഡലാണ്. അത് സംസാരിക്കുന്ന ശബ്ദത്തിന്റെ താമസ വാവ്2vec 2. 0-ന്റെ ഏറ്റവും വലിയ പതിപ്പു് 317 മില്ല്യണ്\u200d പരാമീറ്ററുകളുണ്ട്. Hence, the inference latency of wav2vec 2.0 will be a bottleneck in production, leading to high costs and a significant environmental footprint.  ഒരു ഉല്\u200dപാദിപ്പിക്കുന്ന സജ്ജീകരണത്തിനുള്ള വാവ്2വെക്കിന്റെ പ്രയോഗവും മെച്ചപ്പെടുത്താന്\u200d വേണ്ടി, വലിയ ഭാഷ മോഡലുകളില്\u200d  ഒരു ടീച്ചര്\u200d- വിദ്യാര്\u200dത്ഥിയുടെ അടിസ്ഥാനത്തില്\u200d നിന്നും നമ്മള്\u200d അറിവ് വാവ്2വേക്ക് 2. 0 മോഡലില്\u200d നിന്നും വ്യത്യസ്തമാക്കി. അത് രണ്ടു തവണ വേഗത്തില പ്രധാനപ്പെട്ടതിനേക്കാള്\u200d വിദ്യാര്\u200dത്ഥിയുടെ മോഡല്\u200d കോ2 എഴുന്നേല്\u200dപ്പിന്\u200dറെ അടിസ്ഥാനത്തെ മോഡലിനേക്കാള്\u200d  ഈ പ്രവര്\u200dത്തനത്തില്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നത് വാക്കിന്റെ പിഴവില്\u200d 7% ഡിഗ്രേഷന്\u200d മാത്രമേ പൂര്\u200dത്തിയാ നമ്മുടെ നിര്\u200dണ്ണയിക്കപ്പെട്ട മോഡല്\u200d 3.6 പ്രാവശ്യം മൂലം മോഡലിനെക്കാള്\u200d ചെറുതാണ്, WER-ല്\u200d മാത്രമേ 0.1% ഡിഗ്രേ നമ്മുടെ അറിവിന്റെ ഏറ്റവും നല്ലതിന് ഇതാണ് ആദ്യത്തെ ജോലി വാവ്2വിക് 2.0 ചുരുക്കുന്നത്.', 'ms': 'Wav2vec 2.0 merupakan model pengenalan pidato yang terkini yang memetakan bentuk gelombang audio ucapan ke dalam perwakilan tersembunyi. Versi terbesar wav2vec 2.0 mengandungi 317 juta parameter. Oleh itu, ketinggalan kesimpulan wav2vec 2.0 akan menjadi pengendalian dalam produksi, yang menyebabkan biaya tinggi dan jejak persekitaran yang signifikan. Untuk meningkatkan aplikasi wav2vec kepada tetapan produksi, kami mengeksplorasi kaedah pemampatan model berbilang yang dipinjam dari domain model bahasa besar. Dengan pendekatan guru-pelajar, kami mencurahkan pengetahuan dari model wav2vec 2.0 asal ke dalam model pelajar, yang 2 kali lebih cepat, 4.8 kali lebih kecil daripada model asal. Yang lebih penting, model pelajar adalah 2 kali lebih efisien tenaga daripada model asal dalam terma emisi CO2. Peningkatan prestasi ini dilakukan hanya dengan pengurangan 7% dalam kadar ralat perkataan (WER). Model kuantisasi kita adalah 3.6 kali lebih kecil daripada model asal, dengan hanya 0.1% kerosakan dalam WER. Menurut pengetahuan kita, ini adalah kerja pertama yang memaksa wav2vec 2.0.', 'mt': 'Wav2vec 2.0 is a state-of-the-art speech recognition model which maps speech audio waveforms into latent representations.  L-akbar verżjoni ta’ wav2vec 2.0 fiha 317 miljun parametru. Għalhekk, it-tnaqqis fl-inferenza tal-wav2vec 2.0 se jkun ostaklu fil-produzzjoni, li jwassal għal spejjeż għoljin u impronta ambjentali sinifikanti. Biex tittejjeb l-applikabilità ta’ wav2vec għal ambjent ta’ produzzjoni, a ħna nesploraw metodi ta’ kompressjoni multipli mudelli mislufa mid-dominju ta’ mudelli lingwistiċi kbar. Bl-użu ta’ approċċ għalliema-studenti, iddistillajna l-għarfien mill-mudell oriġinali wav2vec 2.0 f’mudell ta’ studenti, li huwa darbtejn aktar mgħa ġġel, 4.8 darbiet iżgħar mill-mudell oriġinali. Aktar importanti minn hekk, il-mudell tal-istudenti huwa darbtejn aktar effiċjenti fl-użu tal-enerġija mill-mudell oriġinali f’termini ta’ emissjonijiet tas-CO2. Din iż-żieda fil-prestazzjoni titwettaq b’degradazzjoni ta’ 7% biss fir-rata ta’ żball fil-kliem (WER). Il-mudell kwantifikat tagħna huwa 3.6 darbiet iżgħar mill-mudell oriġinali, b’degradazzjoni ta’ 0.1% biss f’WER. Għall-aħjar għarfien tagħna, din hija l-ewwel ħidma li tikkompressa wav2vec 2.0.', 'pl': 'Wav2vec 2.0 to najnowocześniejszy model rozpoznawania mowy, który mapuje fale audio mowy na utajone reprezentacje. Największa wersja wav2vec 2.0 zawiera parametry 317 milionów. Dlatego też opóźnienie wnioskowania wav2vec 2.0 będzie wąskim gardłem w produkcji, prowadzącym do wysokich kosztów i znaczącego wpływu na środowisko. Aby poprawić zastosowanie wav2vec do ustawień produkcyjnych, badamy wiele metod kompresji modeli zapożyczonych z domeny dużych modeli językowych. Wykorzystując podejście nauczyciel-uczeń, zdystylowaliśmy wiedzę z oryginalnego modelu wav2vec 2.0 do modelu studenckiego, który jest 2-krotnie szybszy, 4,8 razy mniejszy niż oryginalny model. Co ważniejsze, model studencki jest dwukrotnie bardziej energooszczędny niż oryginalny pod względem emisji CO2. Ten wzrost wydajności osiąga się przy jedynie 7% degradacji współczynnika błędów słowa (WER). Nasz kwantyzowany model jest 3,6 razy mniejszy niż oryginalny model, z tylko 0,1% degradacji w WER. Według naszej najlepszej wiedzy jest to pierwsza praca, która kompresuje wav2vec 2.0.', 'no': 'Name Den største versjonen av wav2vec 2. 0 inneheld 317 millioner parametra. Derfor vil inferensningslatensien av wav2vec 2,0 vera ein botnekk i produksjonen, som fører til høge kostnader og ein signifikant miljøfottutskrift. For å forbetra tilgjengeligheten av wav2vec til eit produksjonsinnstilling, s å utforskar vi fleire modeller for komprimeringsmetodar som låst frå domenet av store språksmodeller. Når vi bruker ein læringsstudenttilnærming, deler vi kunnskapen frå den opprinnelige wav2vec 2,0-modellen til eit studentmodell, som er 2 ganger raskare, 4,8 ganger mindre enn den opprinnelige modellen. Det viktigere er studentmodellen 2 ganger meir energieffektivt enn den opprinnelige modellen med CO2-utslipp. Denne økninga i utviklinga er fullført med berre ein 7% degradasjon i ordfeilrate (WER). Vår kvantisert modell er 3,6 ganger mindre enn den opprinnelige modellen, med berre 0,1% degradasjon i WER. Dette er det første arbeidet som komprimerer wav2vec 2,0.', 'ro': 'Wav2vec 2.0 este un model de recunoaștere a vorbirii de ultimă generație care cartografiază formele de undă audio ale vorbirii în reprezentări latente. Cea mai mare versiune a wav2vec 2.0 conține 317 milioane de parametri. Prin urmare, latența de deducere a wav2vec 2.0 va fi un blocaj în producție, ducând la costuri ridicate și o amprentă semnificativă de mediu. Pentru a îmbunătăți aplicabilitatea wav2vec la un cadru de producție, explorăm mai multe metode de compresie a modelelor împrumutate din domeniul modelelor de limbi mari. Folosind o abordare profesor-elev, am distilat cunoștințele din modelul original wav2vec 2.0 într-un model elev, care este de 2 ori mai rapid, de 4,8 ori mai mic decât modelul original. Mai important, modelul student este de 2 ori mai eficient din punct de vedere energetic decât modelul original în ceea ce privește emisiile de CO2. Această creștere a performanței se realizează cu o degradare de doar 7% a ratei de eroare a cuvintelor (WER). Modelul nostru cuanticizat este de 3,6 ori mai mic decât modelul original, cu o degradare de doar 0,1% în WER. Din câte știm, aceasta este prima lucrare care comprimează wav2vec 2.0.', 'mn': 'Wav2vec 2.0 нь ярианы дуу долгионы хэлбэрийг сүүлийн хэлбэрээр зураг зураг болгодог. wav2vec 2.0-ын хамгийн том хувилбар нь 317 сая параметр байна. Тиймээс, wav2vec 2.0-ын халдвар нь үйлдвэрлэлд маш өндөр зардал болон маш чухал орчин тойрны footprint болно. wav2vec-ын үйлдвэрлэлийн хэрэгжүүлэлтийг сайжруулахын тулд бид том хэл загварын холбоотой олон загварын даралтын аргыг судалж байна. Багш оюутнуудын арга хэмжээгээр бид мэдлэгийг эхний wav2vec 2.0 загвараас оюутнуудын загвар болгон хурдан хуваасан. Энэ нь эхний загвараас 2 дахин хурдан, 4.8 дахин бага. Хамгийн чухал нь, оюутнуудын загвар нь CO2-ын гаралтын хэмжээнд эхний загвараас 2 дахин илүү энергийн үр дүнтэй. Энэ үйл ажиллагааны нэмэлт нь зөвхөн үгийн алдаа хурдаар 7% бууруулсан. Бидний квантизирован загвар нь эхний загвараас 3.6-ыг үржүүлэх нь бага, WER-д 0.1% бууруулж байна. Хамгийн сайн мэдлэгтэй хувьд энэ нь wav2vec 2.0-г цуглуулдаг анхны ажил юм.', 'sr': 'Wav2vec 2.0 je model priznanja govora koji mapira govorne valove u latentne predstave. Najveća verzija wav2vec 2.0 sadrži 317 miliona parametara. Stoga, infekcija latencije wav2vec 2,0 biće u produkciji slaba vrata, što će dovesti do visoke troškove i značajnog otisaka ekoloških stopala. Da bi poboljšali primjenu wav2vec a na nastavu proizvodnje, istražujemo više modela kompresije koji su pozajmljeni iz domena velikih jezičkih modela. Koristeći učiteljski pristup, razdvojili smo znanje od originalnog model a wav2vec 2,0 u studentski model, koji je 2 puta brži, 4,8 puta manji od originalnog modela. Najvažnije, studentski model je 2 puta efikasniji od originalnog modela u smislu emisije CO2. Ovaj povećanje učinka postiže se samo sa degradacijom 7% u stopi greške reči (WER). Naš kvantizirani model je 3,6 puta manji od originalnog model a, sa samo 0,1% degradacijom u WER-u. Za najbolje od našeg znanja, ovo je prvi posao koji kompresira wav2vec 2.0.', 'si': 'Wav2Vec 2.0 is a state-of-the-art language ack Model that map the language sound Wave form in latter presents. Name ඉතින්, වාව 2වෙක් 2.0 ගේ අන්තිම ප්\u200dරශ්නයක් නිර්මාණයේ බොට්ලන්ගෙක් වෙයි, උපරිමාණය සහ විශේෂ ප්\u200dරශ්නයක් වෙ වෙව්වෙක්ගේ ප්\u200dරවෘත්තිය සැකසුම් සඳහා වැඩ කරන්න, අපි විශාල භාෂා මොඩල් වලින් ලොකු භාෂා මොඩල් වලින් ගැන ගැ ගුරුවන්-විද්\u200dයාර්ථික විද්\u200dයාර්ථික විද්\u200dයාර්ථික විද්\u200dයාපනයක් පාවිච්චි කරනවා, අපි මුලින් වැව්වෙක් 2.0 මොඩේල් එකෙන වඩා වැදගත් විදියට, විදියාර්තා මදුල්ය CO2 ප්\u200dරයෝජනයට වඩා ප්\u200dරභාවිත විදියට වඩා ශක්තිමත් වඩා වඩා  මේ වැඩේ විශාලනය විතරයි වචන වැරදි විතරය 7% විතරයි (WER) විතරයි. අපේ ප්\u200dරමාණය විශ්වාස කරලා තියෙන්නේ ප්\u200dරමාණය වඩා 3.6 වතාවක් ප්\u200dරමාණය විතරයි, WER වල 0.1% විතරයි. අපේ දැනගන්න හොඳම දේවල්, මේක තමයි මුලින්ම වැඩ කරන්නේ වැව2වෙක් 2.0 එක්ක.', 'so': 'Wav2vec 2.0 waa model aqoonsashada hadalka farshaxanka ah oo ku sawiraa waveforms of audio into recent representations. Tusaalada ugu weyn wav2vec 2.0 waxaa ku jira 317 million oo parameters. Sababtaas darteed wav2vec 2.0 waxay noqon doontaa dhaqaalaha kharashka dheer iyo lugaha deegaanka ee muhiim ah. Si aan u hagaajino habka wav2vec ee korsashada qoraalka midhaha, waxaynu baaraynaa qaababka hoos-dhigista noocyo badan oo lagu amaahay guriga modellada afka waaweyn. Isku isticmaalaya qaababka macallimiinta, aqoontii asalka ah wav2vec 2.0 ayaannu u kala soocnay model ardayda, taasoo dhaqso u dhaqso 2 jeer, 4.8 jeer ka yar modelkii asalka ahaa. Inta ugu muhiimsan, Tusaale waxbarashadu waa laba jeer oo ka faa’iido badan karta noocyada asalka ah ee CO2 bixinta. This increase in performance is accomplished with only a 7% degradation in word error rate (WER).  Tusaalkayaga qiyaas ah waa 3.6 jeer ka yar qaababka asalka ah, waxayna ku jirtaa 0.1 boqolkiiba WER. Tani waa shaqada ugu horeeya ee ku kooban wav2vec 2.0.', 'sv': 'Wav2vec 2.0 är en toppmodern taligenkänningsmodell som kartlägger talljudvågformer till latenta representationer. Den största versionen av wav2vec 2.0 innehåller 317 miljoner parametrar. Därmed kommer latensen för wav2vec 2.0 att vara en flaskhals i produktionen, vilket leder till höga kostnader och ett betydande miljöpåverkan. För att förbättra wav2vecs användbarhet i en produktionsmiljö undersöker vi flera modellkomprimeringsmetoder som lånats från domänen stora språkmodeller. Med hjälp av en lärare-elevansats destillerade vi kunskapen från den ursprungliga wav2vec 2.0 modellen till en studentmodell, som är 2 gånger snabbare, 4,8 gånger mindre än den ursprungliga modellen. Ännu viktigare är att studentmodellen är 2 gånger mer energieffektiv än den ursprungliga modellen när det gäller koldioxidutsläpp. Denna ökning av prestanda uppnås med endast en 7% försämring av ordfelfrekvensen (WER). Vår kvantiserade modell är 3,6 gånger mindre än den ursprungliga modellen, med endast 0,1% nedbrytning i WER. Så vitt vi vet är detta det första arbetet som komprimerar wav2vec 2.0.', 'ur': 'Wav2vec 2 wav2vec 2.0 کی سب سے بڑی نسخه 317 میلیون پارامتر ہے۔ لہٰذا، wav2vec 2.0 کی نازل کی لاٹینسی پیدائش میں ایک بٹونڈ ہوگی، بہت سی قیمت اور ایک بڑی محیط منطقی فوت پرینٹ کی وجہ سے۔ وائو۲وک کے پیدائش سٹینٹ کے لئے اضافہ کرنے کے لئے، ہم بہت سی موڈل کمپریشن طریقے دیکھتے ہیں جو بڑی زبان موڈل کے ڈومین سے لیا گیا ہے۔ ایک استاد-طالب طریقے سے ہم نے علم کو اصلی wav2vec 2.0 موڈل سے ایک طالب موڈل میں پھیر دیا ہے، جو 2 دفعہ زیادہ سریع ہے، 4.8 دفعہ اصلی موڈل سے چھوٹا ہے. اس سے زیادہ اہم بات ہے کہ استاد مدل CO2 emission کے مطابق دوگنا زیادہ انرژی اثرات سے زیادہ ہے. یہ عملکرد کی بڑھائی صرف کلمات غلطی کے درجے میں 7% (WER) کے ذریعہ پورا ہوتی ہے۔ ہماری کوانتیز موڈل 3.6 دفعہ چھوٹی ہے اوریل موڈل سے، صرف 0.1% دھوکا ہوا ہے. ہمارے بہترین علم کے لئے یہ سب سے پہلے کام ہے جو wav2vec 2.0 کو دھنساتا ہے۔', 'ta': 'வாவ்2vec 2. 0 என்பது கலை பேச்சு அடையாளம் மாதிரியாகும். அது பேச்சு ஒலி அலைவடிவங்களை சமீபத்தில் குறிப்புகளாக வரைபடம். வாவ்2vec 2. 0 யின் பெரிய பதிப்பு 317 மில்லியன் அளபுருகள் உள்ளது. அதனால், வாவ்2வெக் 2. 0 வின் குறைவு தாக்கத்திற்கு ஒரு பாட்டிலேக் இருக்கும், அதிக செலவு மற்றும் முக்கியமான சூழல் காலடிக்கும். பெரிய மொழி மாதிரிகளின் களத்திலிருந்து கடன்பட்ட பல மாதிரி சுருக்கும் முறைகளை மேம்படுத்த வேவ்2வெக்கின் பயன்பாடு ஒரு ஆசிரியர் மாணவர் முறைமையை பயன்படுத்தி, நாம் முதல் வாவ்2vec 2.0 மாதிரியில் இருந்து தெரிவை மாணவர் மாதிரியில் மாற்றினோம். அது 2 முறை வேகமாக,  முக்கியமாக, மாணவன் மாதிரி CO2 வெளியீட்டிற்கு முதல் மாதிரியை விட 2 மடங்கு முறை சக்தி விளைவாக இருக்கும். வார்த்தையின் பிழை விகிதத்தில் மட்டும் 7% செயல்பாட்டின் அதிகரிப்பு முடிந்தது. நம்முடைய அளவு மாதிரி 3.6 பெருக்கல் முதல் மாதிரியை விட சிறியது, WER ல் மட்டும் 0.1% குறைவு. எங்கள் அறிவின் சிறந்த வேலை இது வாவ்2vec 2.0 ஆகும்.', 'uz': "Name Wav2vec 2. 0 ning eng katta versiyasi 317 million parametrlar mavjud. Hullas, wav2vec 2.0 tashkilotlarining cheksizlik taqdimlik taqdimlik bo'ladi, bu ko'p qismi va muhim muhim muhimdir foydalanadi. To improve wav2vec's applicability to a production setting, we explore multiple model compression methods borrowed from the domain of large language models.  O'qituvchi o'qituvchidan foydalanish bilan biz asl wav2vec 2.0 modeldan o'qituvchi modelga o'rganishni o'rganishga o'zgartirdik. Bu 2 marta tez, 4.8 marta asl modeldan kichkina. Muhimlik darajada, o'qituvchi model CO2 tashqari asl modeldan 2 marta energiya yetarligi. Name Bizning qiymati modelimiz asl modeldan 3.6 marta kichik, faqat 0.1% WERdagi 0.1% darajalik. Bizning eng yaxshi aniqligimizga, bu wav2vec 2.0 ta'minlovchi birinchi ish.", 'vi': 'Wav2vector 2.0 là một mô hình nhận dạng ngôn ngữ hiện đại. đã vẽ bản đồ tần sóng âm nói thành các biểu tượng ngầm. Phần lớn nhất của Wav2vec 2.0 chứa hàng triệu tham gia. Do đó, sự xuất hiện của Wav2vec 2.0 sẽ là một nút thắt trong sản xuất, dẫn tới mức giá cao và một dấu chân môi trường quan trọng. Để nâng cao Bệnh trạng của Wav2vec vào một môi trường s ản xuất, chúng ta sẽ tìm ra các phương pháp nén mô hình đa dạng được mượn từ các mô hình ngôn ngữ lớn. Sử dụng phương pháp giáo viên-sinh viên, chúng tôi đã chưng cất kiến thức từ mô hình Wav2vec 2.0: một mẫu sinh viên nhanh gấp đôi, 4.8 hơn mẫu gốc. Quan trọng hơn, mẫu sinh viên đạt hiệu quả năng lượng gấp đôi so với mẫu gốc về năng lượng CO2. Sự tăng suất này chỉ đạt được với một mức độ thoái hoá chỉ trong tỉ lệ lỗi từ (WER). Mẫu lượng của chúng ta là 3.6 thời gian nhỏ hơn mẫu gốc, với chỉ một độ thoái hóa 0.1. trong WER. Theo hiểu biết của chúng tôi, đây là công việc đầu tiên có thể nén được Wav2vec 2.0.', 'bg': 'Wav2vec 2.0 е модерен модел за разпознаване на реч, който картографира речните аудио вълнови форми в латентни изображения. Най-голямата версия на съдържа 317 милиона параметри. Следователно, заключението за латентността на wav2vec 2.0 ще бъде пречка в производството, което ще доведе до високи разходи и значителен отпечатък върху околната среда. За да подобрим приложимостта на wav2vec към производствена настройка, ние изследваме множество методи за компресиране на модели, взети назаем от домейна на големите езикови модели. Използвайки подход учител-студент, ние дестилирахме знанията от оригиналния модел в студентски модел, който е 2 пъти по-бърз, 4,8 пъти по-малък от първоначалния модел. По-важното е, че студентският модел е 2 пъти по-енергийно ефективен от първоначалния модел по отношение на емисиите на СО2. Това увеличение на производителността се постига само с 7% влошаване на скоростта на думична грешка (WER). Нашият квантизиран модел е 3,6 пъти по-малък от първоначалния модел, с само 0,1% разграждане в WER. Доколкото знаем, това е първата работа, която компресира wav2vec 2.0.', 'da': 'Wav2vec 2.0 er en state-of-the-art talegenkendelsesmodel, der kortlægger talelydbølgeformer til latente repræsentationer. Den største version af wav2vec 2.0 indeholder 317 millioner parametre. Derfor vil afslutningen af latensen af wav2vec 2.0 være en flaskehalse i produktionen, hvilket fører til høje omkostninger og et betydeligt miljøaftryk. For at forbedre wav2vecs anvendelighed på en produktionsindstilling, undersøger vi flere modelkomprimeringsmetoder lånt fra domænet store sprogmodeller. Ved hjælp af en lærer-studerende tilgang destillerede vi viden fra den oprindelige wav2vec 2.0 model til en elevmodel, som er 2 gange hurtigere, 4,8 gange mindre end den oprindelige model. Vigtigere er, at elevmodellen er 2 gange mere energieffektiv end den oprindelige model med hensyn til CO2-emission. Denne forøgelse af ydeevnen opnås med kun en 7% nedbrydning i ord fejlrate (WER). Vores kvantiserede model er 3,6 gange mindre end den oprindelige model, med kun 0,1% nedbrydning i WER. Så vidt vi ved, er dette det første arbejde, der komprimerer wav2vec 2.0.', 'nl': "Wav2vec 2.0 is een state-of-the-art spraakherkenningsmodel dat spraakaudiogolfvormen in latente representaties in kaart brengt. De grootste versie van wav2vec 2.0 bevat 317 miljoen parameters. Daarom zal de inferentielatentie van wav2vec 2.0 een knelpunt in de productie vormen, wat leidt tot hoge kosten en een aanzienlijke ecologische voetafdruk. Om wav2vec's toepasbaarheid op een productie setting te verbeteren, onderzoeken we meerdere model compressie methodes geleend uit het domein van grote taalmodellen. Met behulp van een docent-student benadering hebben we de kennis van het originele wav2vec 2.0 model gedistilleerd naar een studentenmodel, dat twee keer sneller, 4.8 keer kleiner is dan het originele model. Belangrijker nog is dat het studentenmodel qua CO2-uitstoot twee keer energiezuiniger is dan het originele model. Deze prestatieverhoging wordt bereikt met slechts een 7% degradatie in woord error rate (WER). Ons gekwantiseerde model is 3,6 keer kleiner dan het originele model, met slechts een 0,1% degradatie in WER. Voor zover wij weten is dit het eerste werk dat wav2vec 2.0 comprimeert.", 'hr': 'Wav2vec 2.0 je model priznanja govora koji mapira zvukovne talase govora u latentne predstave. Najveća verzija wav2vec 2. 0 sadrži 317 milijuna parametara. Stoga će inferencijska latencija wav2vec 2,0 biti slabost u proizvodnji, što će dovesti do visokih troškova i značajnog otisaka okoliša. Da bi poboljšali primjenu wav2vec a na nastavu proizvodnje, istražujemo višestruke metode kompresije koji su posudili iz domena velikih jezičkih modela. Koristeći učiteljski pristup, razdvojili smo znanje od originalnog model a wav2vec 2,0 u studentski model, koji je 2 puta brži, 4,8 puta manji od originalnog modela. Što je važnije, studentski model je 2 puta učinkovitiji od originalnog modela u smislu emisije CO2. Ova povećanja učinka postignuta je samo degradacijom 7% u stopi greške riječi (WER). Naš kvantizirani model je 3,6 puta manji od originalnog model a, s degradacijom samo 0,1% u WER-u. Najbolje od naših znanja, ovo je prvi posao koji kompresira wav2vec 2,0.', 'id': 'Wav2vec 2.0 adalah model pengenalan pidato yang terbaik yang memetakan bentuk gelombang audio pidato ke represisi yang tertutup. Versi terbesar wav2vec 2.0 berisi 317 juta parameter. Oleh karena itu, keterlaluan dari wav2vec 2.0 akan menjadi pengendalian dalam produksi, yang menyebabkan biaya tinggi dan jejak lingkungan yang signifikan. Untuk meningkatkan aplikabilitas wav2vec untuk seting produksi, kami mengeksplorasi metode kompresi berbilang model yang dipinjam dari domain model bahasa besar. Menggunakan pendekatan guru-siswa, kami mendistril pengetahuan dari model wav2vec 2.0 asli ke model siswa, yang 2 kali lebih cepat, 4.8 kali lebih kecil dari model asli. Yang lebih penting, model siswa adalah 2 kali lebih efisien energi daripada model asli dalam terma emisi CO2. This increase in performance is accomplished with only a 7% degradation in word error rate (WER).  Model kuantisasi kita 3,6 kali lebih kecil dari model asli, dengan hanya 0,1% degradasi dalam WER. Untuk yang terbaik dari pengetahuan kita, ini adalah pekerjaan pertama yang mengkompresi wav2vec 2.0.', 'de': 'Wav2vec 2.0 ist ein hochmodernes Spracherkennungsmodell, das Sprachaudio-Wellenformen in latente Darstellungen abbildet. Die größte Version von wav2vec 2.0 enthält 317 Millionen Parameter. Daher wird die Inferenz-Latenz von wav2vec 2.0 zu einem Engpass in der Produktion führen, was zu hohen Kosten und einem erheblichen ökologischen Fußabdruck führt. Um die Anwendbarkeit von wav2vec auf eine Produktionsumgebung zu verbessern, untersuchen wir mehrere Modellkompressionsmethoden, die aus der Domäne großer Sprachmodelle entlehnt wurden. Mit einem Lehrer-Schüler-Ansatz destillierten wir das Wissen aus dem ursprünglichen wav2vec 2.0-Modell in ein Schülermodell, das 2-mal schneller, 4,8-mal kleiner als das ursprüngliche Modell ist. Noch wichtiger ist, dass das Studentenmodell in Bezug auf den CO2-Ausstoß 2-mal energieeffizienter ist als das ursprüngliche Modell. Diese Leistungssteigerung wird mit nur 7% Verschlechterung der Wortfehlerrate (WER) erreicht. Unser quantisiertes Modell ist 3,6-mal kleiner als das Originalmodell, mit nur 0,1% Degradation in WER. Nach bestem Wissen ist dies die erste Arbeit, die wav2vec 2.0 komprimiert.', 'ko': 'Wav2vec 2.0은 음성 오디오 파형을 잠재적인 표현 형태로 매핑하는 최첨단 음성 인식 모델이다.wav2vec 2.0의 최대 버전은 3.17억 개의 파라미터를 포함한다.따라서wav2vec2.0의 추정 지연은 생산 중의 병목이 되어 높은 원가와 현저한 환경 발자취를 초래할 것이다.wav2vec가 생산 환경에 대한 적용성을 높이기 위해 우리는 대형 언어 모델 분야에서 빌려쓰는 다양한 모델 압축 방법을 모색했다.교사와 학생의 합작 방식을 이용하여 우리는 원시wav2vec2.0모델에서의 지식을 학생모델로 추출했는데 이 모델은 원시모델보다 2배, 4.8배 빠르다.더 중요한 것은 이산화탄소 배출에 있어 학생 모델의 에너지 효율은 원시 모델의 2배다.이런 성능의 향상은 글자 오류율(WER)이 7%만 낮아진 상황에서 이뤄졌다.우리의 양적 모델은 원시 모델보다 3.6배 작고 WER는 0.1% 하락하는 데 불과하다.우리가 아는 바에 의하면 이것은 처음으로 웨이브 2vec 2.0을 압축한 작품이다.', 'sw': 'Wav2vec 2.0 ni mfumo wa utambulisho wa hotuba ya sanaa ambao unaorodhesha wimbi za sauti katika uwakilishi wa hivi karibuni. toleo kubwa la wav2vec 2.0 lina parameter milioni 317. Kwa hiyo, uchungufu wa upungufu wa wav2vec 2.0 utakuwa chupa katika uzalishaji, na utapelekea gharama kubwa na nyayo muhimu za mazingira. Ili kuboresha matumizi ya wav2vec kwa kitengo cha uzalishaji, tunachunguza mbinu mbalimbali za kompression zilizochukuliwa kutoka ndani ya mifano makubwa ya lugha. Kwa kutumia mbinu za mwalimu, tulitofautisha maarifa kutoka kwa mtindo wa awali wa wav2vec 2.0 kuwa mfano wa wanafunzi, ambao ni mara mbili haraka, mara 4.8 ndogo zaidi ya mtindo wa asili. Kimuhimu zaidi, modeli ya wanafunzi ni kiwango cha nishati mara mbili zaidi ya mifano ya awali kwa sababu ya utoaji wa CO2. Ongezeko hili la utendaji limetokea kwa asilimia 7 tu katika kiwango cha makosa ya neno (WER). Mfano wetu wa kipimo ni mara 3.6 kidogo kuliko mtindo wa asili, yenye asilimia 0.1 tu ya kuharibiwa na WER. Kwa ufahamu mzuri zaidi, hii ni kazi ya kwanza inayojumuisha wav2vec 2.0.', 'fa': 'Wav2vec 2.0 یک مدل شناسایی سخنرانی هنری است که نقشه\u200cهای موج صوتی را به عنوان نمایش\u200cهای latent نقشه می\u200cدهد. بزرگترین نسخه wav2vec 2. 0 شامل 317 میلیون پارامتر است. بنابراین، آلودگی آلودگی wav2vec 2.0 یک شیشه در تولید خواهد بود که به هزینه\u200cهای بالا و یک اثر پای محیط زیست منظور دارد. برای تأثیر کاربردی wav2vec به یک تنظیم تولید، ما روش\u200cهای فشار مدل\u200cهای متعدد را تحقیق می\u200cکنیم که از دومین مدل\u200cهای زبان بزرگ قرض گرفته شده است. با استفاده از طریق دانش آموزان و دانش آموزان، ما دانش را از مدل اصلی wav2vec 2.0 به مدل دانش آموزان جدا کردیم، که 2 برابر سریعتر است، 4.8 برابر کوچکتر از مدل اصلی است. مهمتر است که مدل دانش آموزان دو برابر بیشتر از مدل اصلی در مورد اخراج CO2 است. این افزایش عملکرد فقط با تنگ شدن 7 درصد در میزان خطای کلمه (WER) انجام می\u200cشود. مدل quantized ما 3.6 برابر کوچکتر از مدل اصلی است، با فقط یک کاهش 0.1% در WER. برای بهترین دانش ما، این اولین کار است که wav2vec 2.0 را فشار می دهد.', 'sq': 'Wav2vec 2.0 është një model i njohjes së fjalimit më i avancuar që harton format e valëve audio të fjalimit në përfaqësime të fshehta. Versioni më i madh i wav2vec 2.0 përmban 317 milion parametra. Kështu, vonesa e përfundimit e wav2vec 2.0 do të jetë një pengesë në prodhimin, që do të çojë në kosto të larta dhe një gjurmë të rëndësishme mjedisore. Për të përmirësuar aplikabilitetin e wav2vec në një vendosje prodhimi, ne eksplorojmë metodat e kompresimit të shumëfishtë të modeleve të huazuara nga domenia e modeleve të mëdha gjuhësh. Duke përdorur një metodë mësues-student ësh, ne e distilluam njohurinë nga modeli origjinal wav2vec 2.0 në një model studentësh, i cili është 2 herë më i shpejtë, 4.8 herë më i vogël se modeli origjinal. Më e rëndësishmja është se modeli i student ëve është dy herë më i efektshëm në energji se modeli origjinal lidhur me emisionin e CO2. Ky rritje në performancë arrihet me vetëm 7% degradim në normën e gabimeve të fjalës (WER). Modeli ynë kuantifikuar është 3.6 herë më i vogël se modeli origjinal, me vetëm një degradim 0.1% në WER. Nga njohuria jonë më e mirë, kjo është puna e parë që kompreson wav2vec 2.0.', 'tr': "Wav2vec 2.0, sesi tanımlama modeldir. Bu, sesi dalgalarını son ifadelere şekillendirir. wav2vek 2.0'un en büyük versiyonu 317 milyon parametri bar. Bu sebäpli, wav2vek 2.0'yň azalyşyklygyny üretimde boş boş boşluk bolar. Yüksek malillere we örän möhüm çevrelikli futbol çarpmasına yol a çar. wav2vek uygulamasını üretim ayarlamasına geliştirmek için, büyük dil modellerinden alınan çoklu modeller s ıkıştırma yöntemlerini keşfettik. Mugallym-okuwçylara golaýy ulanyp bilimi original wav2vec 2.0 nusgasyndan okuwçy nusgasyna çykardyk. Bu 2 gezek çalt we 4.8 gezek orijinal nusgasyndan kiçi. Öň wajyp bolsa, okuwçy nusgasy CO2 emissiýasynda 2 gezek enerji töleýji ukypdyr. Bu etkinlik ýetişimi diňe 7%-de söz hata derejesi bilen ýetişdirilýär. Bizim küçük modelimiz orijinal modelden 3.6 kat küçük ve sadece 0.1% degradasyondur. Bildiğimiz en iyi göre, bu ilk çalışma wav2vec 2.0'yi sıkıştırır.", 'am': 'Wav2vec 2.0 is a state-of-the-art speech recognition model which maps speech audio waveforms into recent representations. የwav2vec 2.0 ትልቁ ክፍል 317 ሚሊዮን parameter አለ። ስለዚህም የwav2vec 2.0 ውጤት አካባቢ ውጤት ነው፤ ከፍተኛ ዋጋ እና ትክክለኛ የሀብት እግር ማውጣት ነው፡፡ የwav2vec አካባቢነት ለመሻለል፣ ከታላቁ ቋንቋ ምሳሌዎች የተሰጠውን የሞዴል አካባቢ ሥርዓቶችን እንፈልጋለን፡፡ አስተማሪ-ተማሪ ልቅናና በመጀመሪያው wav2vec 2.0 model እውቀቱን ለይተን ወደ ተማሪ ሞዴል ለይተን ነበር፡፡ ከዚህም ይልቅ የተማሪ ሞዴል ከCO2 ውጤት ይልቅ ሁለት እጥፍ የenergy ጥቅም ነው፡፡ ይህ ትልቅ አድራሻ በንግግር ስህተት ቁጥር 7 በመቶ ብቻ ይደርሳል (WER). የመጀመሪያው ሞዴል 3.6 እጥፍ ትንሽ ነው፣ በWER ብቻ 0.1 በመቶ ውጤት ነው፡፡ To the best of our knowledge, this is the first work that compresses wav2vec 2.0.', 'af': "Wav2vec 2.0 is 'n state- of- the- art speech recognition model wat kaart spraak oudiogolwe vorms in latent voorstellings. Die grootste weergawe van wav2vec 2. 0 bevat 317 miljoen parameters. Daarom sal die inferensie latensie van wav2vec 2. 0 'n botnek in produksie wees, wat na hoë koste en 'n betekende omgewing voetdruk lei. Om wav2vec se toepassingbaarheid te verbeter aan 'n produksieinstelling, ondersoek ons veelvuldige model komprimeringsmetodes wat uit die domein van groot taal modele geleer is. By die gebruik van 'n onderwyser-studente toegang het ons die kennis van die oorspronklike wav2vec 2.0 model in 'n studentmodel, wat is 2 maal vinniger, 4.8 maal kleiner as die oorspronklike model. Die student model is 2 maal meer energie effektief as die oorspronklike model in terms of CO2 emission. Hierdie vergroot in prestasie is voleindig met slegs 'n 7% vergroot in woord fout tempo (WER). Ons quantiseerde model is 3. 6 maal kleiner as die oorspronklike model, met slegs 'n 0. 1% verderering in WER. Dit is die eerste werk wat wav2vec 2.0 komprimeer.", 'hy': 'Ուավով 2Վ 2.0 խոսքի ճանաչության ամենաբարձր մոդելն է, որը քարտեզագրում է խոսքի ձայնային ալիքների ձևերը թաքնված ներկայացումների մեջ: Ուավով 2վիկ 2.0 ամենամեծ տարբերակը պարամետրեր ունի 317 միլիոն: Ուրեմն, ուշադրության ուշադրությունը կլինի արտադրության շրջանակներում, ինչը կհանգեցնի բարձր արժեքների և կարևոր շրջակա միջավայրի ազդեցության: Որպեսզի բարելավենք wev2vex-ի կիրառելիությունը արտադրության միջոցով, մենք ուսումնասիրում ենք բազմաթիվ մոդելներ ընդգծման մեթոդներ, որոնք փոխառվել են մեծ լեզվի մոդելների ոլորտից: Using a teacher-student approach, we distilled the knowledge from the original wav2vec 2.0 model into a student model, which is 2 times faster, 4.8 times smaller than the original model.  Ավելի կարևոր է, որ ուսանողական մոդելը երկու անգամ ավելի էներգիայի արդյունավետ է, քան սկզբնական մոդելը ածխաթթու գազի արտանետման տեսանկյունից: Այս արտադրողականության աճը կատարվում է միայն 7 տոկոսի դեգրադացիայի միջոցով բառի սխալման արագությամբ (WER). Մեր քվանտավորված մոդելը 3.6 անգամ ավելի փոքր է, քան սկզբնական մոդելը, WER-ում միայն 0.1 տոկոսի դեգրադացիա ունի: To the best of our knowledge, this is the first work that compresses wav2vec 2.0.', 'az': "Wav2vec 2.0, sözlərin davuş dalğalarını latent göstəricilərə qarışdırır. wav2vec 2. 0'nin ən böyük versiyonu 317 milyon parametru içərir. Beləliklə, wav2vec 2.0'nin a şağılığı təhsil edilməsində böyük qiymətlərə və möhkəm çevre izlərinə yol açar. wav2vec təhsil qurğusuna uyğunluğunu daha yaxşılaşdırmaq üçün, çoxlu modeli s ıkıştırma metodlarını böyük dil modellerinin domeinindən alınmış. Muhəmməd-tələbə metodlarına istifadə etdik ki, bilikləri orijinal wav2vec 2.0 modelindən öyrənən modellərə ayırdıq. Bu 2 dəfə daha hızlı, 4.8 dəfə orijinal modellərdən daha kiçik. Önemli olaraq, öğrenci modeli CO2 emisyonu ilə orijinal modelindən 2 kat daha etkilidir. Bu işarətin artırılması sözlərin xəta hüquqlarını (WER) ilə yalnız 7%-dən düşürülmüşdür. Bizim kvantifikat modelimiz orijinal modelden 3,6 kat daha kiçikdir, WER'də yalnız 0,1% degradasyonu var. Bizim elmimizin ən yaxşısına görə, bu, wav2vec 2.0 ilə birləşdirilən ilk işdir.", 'bn': 'ওয়াভ ২ভেক ২. ওয়াভি২ভেক ২. ০ এর সবচেয়ে বড় সংস্করণ আছে ৩১৭ মিলিয়ন প্যারামিটার। তাই ওয়াভ ২. একটি উৎপাদন বৈশিষ্ট্যের জন্য ওয়েভি২ভেসির প্রয়োগ বৃদ্ধি করার জন্য, আমরা বিশাল ভাষার মডেলের ডোমেইন থেকে ঋণের বেশ কিছু মডেল সম্পাদন শিক্ষক-ছাত্রের পদক্ষেপ ব্যবহার করে, আমরা প্রাথমিক ওয়াভি২ভেক ২. আরো গুরুত্বপূর্ণ, ছাত্র মডেল হলো কো২ প্রস্তাবের মাধ্যমে প্রাথমিক মডেলের চেয়ে দুই বার শক্তির কার্যকর। শব্দের ত্রুটির হারে শুধুমাত্র ৭% ডিগ্রেশনের মাধ্যমে এই প্রদর্শনের বৃদ্ধি সম্পন্ন হয়েছে। আমাদের পরিমাণ মডেল প্রাথমিক মডেল থেকে ৩. আমাদের জ্ঞানের সবচেয়ে ভালোভাবে, এটাই প্রথম কাজ যা ওয়াভি২ভেক ২.', 'bs': 'Wav2vec 2.0 je model priznanja govora koji mapira zvukovne valove govora u latentne predstave. Najveća verzija wav2vec 2.0 sadrži 317 miliona parametara. Stoga će infekcija latencija wav2vec 2,0 biti slaba u proizvodnji, dovesti do visokih troškova i značajnog otisaka okoliša. Da bi poboljšali primjenu wav2vec a na nastavu proizvodnje, istražujemo višestruke modele kompresije koji su pozajmljeni iz domena velikih jezičkih modela. Koristeći učiteljski pristup, razdvojili smo znanje od originalnog model a wav2vec 2,0 u studentski model, koji je 2 puta brži, 4,8 puta manji od originalnog modela. Najvažnije, studentski model je 2 puta efikasniji od originalnog modela u smislu emisije CO2. Ova povećanja učinka postignuta je samo degradacijom 7% u stopi greške riječi (WER). Naš kvantizirani model je 3,6 puta manji od originalnog model a, sa samo 0,1% degradacijom u WER-u. Za najbolje od našeg znanja, ovo je prvi posao koji kompresira wav2vec 2.0.', 'ca': "Wav2vec 2.0 és un model de reconeixement de la fala més avançat que mapeix les formes d'ona d'àudio de la fala en representacions latents. La versió més gran de wav2vec 2.0 conté 317 milions de paràmetres. Per tant, la latencia de la inferència de wav2vec 2.0 serà un bloc d'ampolla en la producció, portant a costos alts i una petjada ambiental significativa. Per millorar l'aplicabilitat de wav2vec a un entorn de producció, explorem mètodes de compressió múltiples de model s emprestats del domini de grans models de llenguatge. Using a teacher-student approach, we distilled the knowledge from the original wav2vec 2.0 model into a student model, which is 2 times faster, 4.8 times smaller than the original model.  More importantly, the student model is 2 times more energy efficient than the original model in terms of CO2 emission.  Aquest augment en el rendiment s'aconsegui només amb una degradació del 7% en la tasa d'errors de paraula (WER). El nostre model quantitzat és 3,6 vegades més petit que el model original, amb només una degradació del 0,1% en WER. Segons el nostre coneixement, aquesta és la primera feina que comprima wav2vec 2.0.", 'cs': 'Wav2vec 2.0 je nejmodernější model rozpoznávání řeči, který mapuje zvukové vlny řeči do latentních reprezentací. Největší verze wav2vec 2.0 obsahuje 317 milionů parametrů. Proto bude inferenční latence wav2vec 2.0 úzkým místem ve výrobě, což vede k vysokým nákladům a významné environmentální stopě. Abychom zlepšili aplikaci wav2vec na produkční nastavení, zkoumali jsme několik metod komprese modelů vypůjčených z domény velkých jazykových modelů. Pomocí přístupu učitele-studenta jsme destilovali znalosti z původního wav2vec 2.0 modelu do studentského modelu, který je dvakrát rychlejší, 4,8krát menší než původní model. Důležitější je, že studentský model je z hlediska emisí CO2 dvakrát energeticky účinnější než původní model. Toto zvýšení výkonu je dosaženo pouze s 7% degradací ve slovní chybě (WER). Náš kvantizovaný model je 3,6-krát menší než původní model, s pouze 0,1% degradací ve WER. Podle našich nejlepších znalostí je to první práce, která kompresuje wav2vec 2.0.', 'et': 'Wav2vec 2.0 on kaasaegne kõnetuvastusmudel, mis kaardistab kõne heli lainevormid latentseteks esitusteks. Wav2vec 2.0 suurim versioon sisaldab 317 miljonit parameetrit. Seega on wav2vec 2.0 latentsus tootmises kitsaskoht, mis toob kaasa kõrged kulud ja märkimisväärse keskkonnajalajälje. Et parandada wav2veci rakendatavust tootmisseadetes, uurime mitmeid mudeli tihendamise meetodeid, mis on laenatud suurte keelemudelite domeenist. Õpetaja-õpilase lähenemisviisi abil destilleerisime algsest wav2vec 2.0 mudelist saadud teadmised õpilase mudeliks, mis on 2 korda kiirem, 4,8 korda väiksem kui algne mudel. Veelgi olulisem on see, et õpilaste mudel on CO2 heite osas 2 korda energiatõhusam kui algne mudel. See jõudluse suurenemine saavutatakse ainult 7% halvenemisega sõnaveamääras (WER). Meie kvantiseeritud mudel on 3,6 korda väiksem kui algne mudel, vaid 0,1% lagunemine WER. Meie teadmiste kohaselt on see esimene töö, mis tihendab wav2vec 2.0.', 'fi': 'Wav2vec 2.0 on uusin puheentunnistusmalli, joka kartoittaa puheen ääniaaltomuodot piileviksi representaatioiksi. wav2vec 2.0:n suurin versio sisältää 317 miljoonaa parametria. Näin ollen wav2vec 2.0:n päättelyviive on tuotannon pullonkaula, joka johtaa korkeisiin kustannuksiin ja merkittävään ympäristöjalanjälkeen. Parantaaksemme wav2vecin soveltuvuutta tuotantoympäristöön tutkimme useita suurten kielimallien toimialueelta lainattuja mallipakkausmenetelmiä. Opettaja-oppilas-lähestymistavalla tislasimme alkuperäisen wav2vec 2.0 -mallin tiedon opiskelijamalliksi, joka on 2 kertaa nopeampi, 4,8 kertaa pienempi kuin alkuperäinen malli. Mikä tärkeintä, opiskelijamalli on CO2-päästöjen osalta 2 kertaa energiatehokkaampi kuin alkuperäinen malli. Tämä suorituskyky paranee vain 7%:lla sanavirheprosentista (WER). Kvantisoitu malli on 3,6 kertaa pienempi kuin alkuperäinen malli, jossa WER:ssä hajoaa vain 0,1%. Tietojemme mukaan tämä on ensimmäinen työ, joka pakkaa wav2vec 2.0.', 'he': 'Wav2vec 2.0 הוא מודל זיהוי דיבור מצוין ביותר שמפית צורות גלי דיבור לתוך מיצוגים מוסתרים. The largest version of wav2vec 2.0 contains 317 million parameters.  לכן, המונח של wav2vec 2.0 יהיה בקבוק בפיצוץ, מה שמוביל לעלות גבוהות וטביעת סביבה משמעותית. כדי לשפר את אפשרותו של wav2vec לסיבוב יצירה, אנו חוקרים שיטות דחיסה מרובות מודל שנשאלו ממשטרת דוגמני שפה גדולים. באמצעות גישה מורה-סטודנט, דחפנו את הידע מהמודל המקורי wav2vec 2.0 למודל סטודנט, שהוא 2 פעמים מהיר יותר, 4.8 פעמים קטן יותר מהמודל המקורי. יותר חשוב, המודל הסטודנטי הוא פי שתיים יותר יעיל אנרגיה מהמודל המקורי במונחים של פחידת פחמן חמצני חמצני. This increase in performance is accomplished with only a 7% degradation in word error rate (WER).  המודל הקוונטי שלנו הוא 3.6 פעמים קטן יותר מהמודל המקורי, עם רק פיצול 0.1% ב WER. למיטב הידע שלנו, זו העבודה הראשונה שמלחצת wav2vec 2.0.', 'jv': 'WaV2vec 2.0 Laptop" and "Desktop lah To advance Wavevec\'s Application to a manupulation settings, we istrage Multiple model Compion Methods Burrow from the domain of big language modes. Ngawe ngubah layanan guru kelompok,awake dhéwé wisalaman ngono model Wa2vec 2.0 Awak dhéwé, maneh kuwi jenis iki sakjané luwih apik sing katêpakan ning awak dhéwé sing katêpakan karo model sing katêpakan karo Kewih dhéwé = Kita model sing kelas 3.6 kere pitik, nik 0.1% degradisi wae Awakdhéwé sing paling awakdhéwé, iki dadi sing perusahaan karo nggawe wa2vec 2.0.', 'sk': 'Wav2vec 2.0 je najsodobnejši model prepoznavanja govora, ki kartira govorne avdio valove v latentne reprezentacije. Največja različica wav2vec 2.0 vsebuje 317 milijonov parametrov. Zato bo sklepna latenca wav2vec 2.0 ozka grla v proizvodnji, ki bo povzročila visoke stroške in znaten okoljski odtis. Za izboljšanje uporabnosti wav2veca v produkcijski nastavitvi raziskujemo več metod kompresije modelov, izposojenih iz domene velikih jezikovnih modelov. S pristopom učitelj-študent smo znanje iz originalnega modela wav2vec 2.0 destilirali v študentski model, ki je 2-krat hitrejši, 4,8-krat manjši od originalnega modela. Študentski model je v smislu emisij CO2 dvakrat energetsko učinkovitejši od prvotnega modela. To povečanje zmogljivosti je doseženo z le 7-odstotnim zmanjšanjem stopnje napak besed (WER). Naš kvantizirani model je 3,6-krat manjši od prvotnega modela, z le 0,1% razgradnjo v WER. Kolikor vemo, je to prvo delo, ki stiska wav2vec 2.0.', 'ha': "Wav2vc 2.0 is a state-of-the-art-the-art address that maps screenshots to lately actions. @ info: whatsthis Hence, the inference latency of wav2vec 2.0 will be a bottleneck in production, leading to high costs and a significant environmental footprint.  To, dõmin ya improve shirin ayuka na wav2vc zuwa wani tsari na manunufi, za'a gane wasu shiryoyin ƙararra masu amfani da shi daga duk misalin harshe mai girma. Yin amfani da abincin macallin, muka rarrabe ilimin daga masaluman wav2vc 2.0 na farko zuwa misalin ardayar, wanda ke sauki sau biyu sau biyu, 4.8 sau ƙaranci daga misali na farko. Ki muhimu, misalin karatun yana da wani mai ƙarfi sau biyu ko kuma mafi amfani da amfani na farko a cikin misalin CO2. Wannan ƙãra aikin da aka cika shi kawai da wani wulãkanci na 7% cikin matsayin ɓata (WER). Shirin tudunmu da aka ƙayyade shi ne 3.6 sau ƙaranci daga misalin farko, kuma yana da cewa kawai 0.1 sau cikin WER. Ga mafi kyaun saninmu, wannan ne aikin na farko wanda ke samun wav2vc 2.0.", 'bo': "Wav2vec 2.0 is a state-of-the-art speech recognition model that maps speech audio waveforms into latent representations. It is a state-of-the-art speech recognition model that maps speech waveforms in the latent representations. The largest version of wav2vec 2.0 contains 317 million parameters. The largest version of wav2vec 2.0 དེར་བརྟེན། wav2vec 2.0 ཡི་མཐའ་གནོན་ཚུལ་གྱི་དམ་གསུམ་ཅིག་ཡིན་པས་རྩ་བ་སྐྱེས་པ་ཞིག་ཏུ་འགྱུར་སྲིད། མི་མང་པོ་ཞིག་དང་ཉེ་བར To improve wav2vec's applicability to a production setting, we explore multiple model compression methods borrowed from the domain of large language models. སློབ་འཕྲིན་གྱི་གཟུགས་སྐོར་བ་ཞིག་བྱས་པ་ནི་ང་ཚོས་རང་གི་དབྱིན་ཡོད་པའི་མཐོང་སྣང་ཐོག་ལས་ wav2vec 2.0་ནང་གི་མ་དཔེ་གཞུང་གི་ནང་ནས་དབྱིན འདི་ལས་གལ་ཆེ་ཤོས་བ་ཡིན། སློབ་ཆུང་གིས་མིག་ཆས་འདིར་ནུས་པ་གཉིས་ལས་དཔལ་འབྱོར་བ་རེད། performance་གནས་ཚུལ་འདི་ལྟ་བུའི་ཚད་གྲངས་ཀྱི་འགྱུར་བ་དེ་འགྲོ་བཞིན་པའི་སྐབས་ཡིག་ནོར་འཁྲུལ་ཚད་གཅིག་ཁོ་ན་7% ང་ཚོའི་གྲངས་བསྡུར་བའི་མ་དབྱིབས་དེ་རྨས་གཞི་མིན་པ་ལས་ཉུང་བའི་མ་དབྱིབས་ལྡན་གྲངས་ཀ་འདི་(WER)ནང་ལས་བརྩོན་བ་ ང་ཚོའི་ཆེད་དུ་འཕགས་པ་ཤེས་ཚད་ལྡན་པའི་གྲངས་ཀ་དེ་བརྩིས་ཐོག་དང་པོ་རེད།"}
{'en': 'Unsupervised Contextualized Document Representation', 'ar': 'تمثيل المستندات السياقية غير الخاضع للإشراف', 'pt': 'Representação de Documento Contextualizado Não Supervisionado', 'fr': 'Représentation contextualisée de documents non supervisée', 'es': 'Representación de documentos contextualizados no supervisados', 'ja': 'スーパーバイザーなしのコンテキスト化されたドキュメント表現', 'zh': '无监督者文档示', 'ru': 'Неконтролируемое представление контекстуализированных документов', 'hi': 'असुरक्षित संदर्भित दस्तावेज़ प्रतिनिधित्व', 'ga': 'Ionadaíocht Doiciméad Comhthéacsúil Gan Maoirseacht', 'hu': 'Felügyelet nélküli kontextualizált dokumentumképviselet', 'ka': 'კონტექსტუალური დოკუმენტის გამოსახულება', 'el': 'Αναπροσώπευση εγγράφου χωρίς επιτήρηση', 'it': 'Rappresentanza contestualizzata non sorvegliata', 'ms': 'Perwakilan Dokumen Berkonteks Tidak Dikawal', 'lt': 'Neaprižiūrimas kontekstinis dokumento atstovavimas', 'kk': 'Сәйкестік контекстуалды құжатты таңдау', 'mk': 'Ненадгледувана контекстна претстава на документот', 'mt': 'Unsupervised Contextualized Document Representation', 'ml': 'പരിശോധിച്ചിട്ടില്ലാത്ത രേഖയുടെ പ്രതിനിധി', 'mn': 'Хадгалагдаггүй Сүүлийн үеийн Документын төлөөлөл', 'pl': 'Niekontrolowana kontekstowa reprezentacja dokumentu', 'no': 'Comment', 'so': 'Xukummada aan la ilaalinayn', 'ro': 'Reprezentarea contextualizată nesupravegheată a documentelor', 'sr': 'Представка документа неподржана контекстално', 'si': 'සුරක්ෂා නැති සංවේදනය සඳහා ලිපින්ත ප්\u200dරතිස්ථානය', 'sv': 'Icke övervakad kontextualiserad dokumentrepresentation', 'ur': 'غیر محافظت کی کنٹکسٹولیز ڈوکومٹ ریسپرنسیٹ', 'ta': 'கண்காணிக்கப்படவில்லை', 'uz': '@ info: whatsthis', 'vi': 'KCharselect unicode block name', 'bg': 'Неконтролирано контекстуализирано представяне на документа', 'nl': 'Niet-gecontextualiseerde documentweergave', 'da': 'Ikke-overvåget kontekstualiseret dokumentrepræsentation', 'hr': 'Nepotrebna kontekstualizacija predstavljanja dokumenta', 'de': 'Nicht überwachte kontextualisierte Dokumentdarstellung', 'ko': '무감독의 상하 문화 문서 표시', 'sw': 'Replacement of document', 'tr': '_Senedler', 'af': 'Onondersteunde Konteksualiseerde Dokument Voorstelling', 'am': 'ሰነዱን እንዳለ ምረጡ', 'id': 'Perwakilan Dokumen Konteksual Tidak Disupervisi', 'sq': 'Përfaqësimi i Dokumentit të Konteksualizuar i Pambikqyrur', 'bn': 'পর্যবেক্ষণ করা নথির প্রতিনিধি', 'az': 'Qeyd edilm톛y톛n Kontext D칬k칲man 캻zl톛ri', 'ca': 'Representació Contextualitzada sense supervisió', 'bs': 'Nepotrebna kontekstualizacija predstavljanja dokumenta', 'cs': 'Nekontrolovaná kontextová reprezentace dokumentu', 'fa': 'نمایش سند غیرقابل حفاظت', 'fi': 'Tarkkailematon kontekstualisoitu asiakirjaesitys', 'et': 'Järelevalveta kontekstualiseeritud dokumendi esitus', 'hy': 'Comment', 'jv': 'marker', 'he': 'מייצג מסמכים מקורקסטוליזי ללא השגחה', 'ha': '@ action', 'sk': 'Nenadzorovana kontekstualizirana predstavitev dokumenta', 'bo': 'སྔོན་བསྐྱུར་མེད་པའི་རྣམ་གྲངས་ཀྱི་ཡིག་ཆ་མཚོན་རྟགས'}
{'en': 'Several NLP tasks need the effective repre-sentation of text documents. Arora et al.,2017 demonstrate that simple weighted aver-aging of word vectors frequently outperformsneural models. SCDV (Mekala et al., 2017)further extends this from sentences to docu-ments by employing soft and sparse cluster-ing over pre-computed word vectors. How-ever, both techniques ignore the polysemyand contextual character of words. In thispaper, we address this issue by proposingSCDV+BERT(ctxd), a simple and effective un-supervised representation that combines con-textualized BERT (Devlin et al., 2019) basedword embedding for word sense disambigua-tion with SCDV soft clustering approach. Weshow that our embeddings outperform origi-nal SCDV, pre-train BERT, and several otherbaselines on many classification datasets. Wealso demonstrate our embeddings effective-ness on other tasks, such as concept match-ing and sentence similarity. In addition, we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data andonly few shots examples.', 'ar': 'تحتاج العديد من مهام البرمجة اللغوية العصبية إلى إعادة إرسال المستندات النصية بشكل فعال ، يوضح أرورا وآخرون ، 2017 أن متوسط العمر المرجح لمتجهات الكلمات يتفوق في كثير من الأحيان على النماذج العصبية. يمتد SCDV (Mekala et al. ، 2017) هذا من الجمل إلى المستندات من خلال استخدام مجموعة ناعمة ومتفرقة على متجهات الكلمات المحسوبة مسبقًا. ومع ذلك ، تتجاهل كلتا التقنيتين الطابع متعدد المعاني والسياق للكلمات. في هذه الورقة ، نتناول هذه المشكلة من خلال اقتراح SCDV + BERT (ctxd) ، وهو تمثيل بسيط وفعال غير خاضع للإشراف يجمع بين BERT المنسق للنص (Devlin et al. ، 2019 ) تضمين الكلمات الأساسية لتوضيح معنى الكلمة باستخدام نهج التجميع الناعم SCDV. نلاحظ أن حفلات الزفاف لدينا تفوقت في الأداء على SCDV الأصلي ، والتدريب المسبق لـ BERT ، والعديد من الخطوط الأساسية الأخرى في العديد من مجموعات بيانات التصنيف. نوضح أيضًا فاعلية عمليات التضمين الخاصة بنا في مهام أخرى ، مثل مطابقة المفاهيم وتشابه الجمل. بالإضافة إلى ذلك ، نظهر أن SCDV + BERT (ctxd) يتفوق في الأداء على BERT وتطبيقات التضمين المختلفة في سيناريوهات ذات بيانات محدودة وقليل فقط أمثلة اللقطات.', 'fr': "Plusieurs tâches de PNL nécessitent la représentation efficace de documents textuels. Arora et al., 2017 démontrent que la moyenne pondérée simple des vecteurs de mots surpasse souvent les modèles neuronaux. SCDV (Mekala et al., 2017) étend encore cela des phrases aux documents en utilisant un cluster-ing souple et clairsemé sur des vecteurs de mots précalculés. Cependant, les deux techniques ignorent la polysémie et le caractère contextuel des mots.Dans cet article, nous abordons ce problème en proposant SCDV+BERT (ctxd), une représentation non supervisée simple et efficace qui combine l'intégration de mots basée sur le BERT con-textualisé (Devlin et al., 2019) pour la désambiguïa-tion du sens des mots avec SCDV approche de clustering souple. Nous montrons que nos intégrations surpassent le SCDV d'origine, le BERT pré-entraînement et plusieurs autres lignes de base sur de nombreux ensembles de données de classification. Nous démontrons également l'efficacité de nos intégrations sur d'autres tâches, telles que la correspondance de concepts et la similarité de phrases. De plus, nous montrons que SCDV+BERT (ctxd) surpasse le BERT affiné et les différentes approches d'application d'intégration dans des scénarios avec des données limitées et seulement quelques exemples de plans.", 'es': 'Varias tareas de PNL requieren la representación efectiva de los documentos de texto. Arora et al., 2017 demuestran que el promedio ponderado simple de los vectores de palabras con frecuencia supera a los modelos neuronales. SCDV (Mekala et al., 2017) amplía aún más esto de oraciones a documentos mediante el empleo de agrupamiento suave y disperso sobre vectores de palabras precalculados. Sin embargo, ambas técnicas ignoran la polisemia y el carácter contextual de las palabras. En este artículo, abordamos este tema proponiendo SCDV+BERT (ctxd), una representación simple y eficaz sin supervisión que combina la incrustación de palabras basada en BERT (Devlin et al., 2019) contextualizada para la desambiguación del sentido de las palabras con SCDV enfoque de clustering suave. Demuestramos que nuestras incorporaciones superan al SCDV original, preentrenan BERT y varias otras líneas de base en muchos conjuntos de datos de clasificación. También demostramos la eficacia de nuestras incorporaciones en otras tareas, como la correspondencia de conceptos y la similitud de oraciones. Además, mostramos que SCDV+BERT (ctxd) supera al BERT de ajuste fino y a los diferentes enfoques de incrustación en escenarios con datos limitados y ejemplos de solo unos pocos disparos.', 'pt': 'Várias tarefas de PNL precisam da representação eficaz de documentos de texto. Arora et al., 2017 demonstram que a média ponderada simples de vetores de palavras frequentemente supera os modelos neurais. SCDV (Mekala et al., 2017) estende ainda mais isso de frases para documentos, empregando agrupamento suave e esparso sobre vetores de palavras pré-computados. No entanto, ambas as técnicas ignoram a polissemia e o caráter contextual das palavras. Neste artigo, abordamos essa questão propondo SCDV+BERT(ctxd), uma representação não supervisionada simples e eficaz que combina BERT contextualizado (Devlin et al., 2019 ) incorporação de palavras para desambiguação de sentido de palavras com abordagem de clustering suave SCDV. Mostramos que nossos embeddings superam o SCDV original, BERT pré-treinamento e várias outras linhas de base em muitos conjuntos de dados de classificação. Também demonstramos a eficácia de nossa incorporação em outras tarefas, como correspondência de conceito e similaridade de sentença. exemplos de tiros.', 'ja': 'いくつかのNLPタスクは、テキスト文書の効果的な繰り返し送信を必要とする。rora et al., 2017は、単純なワードベクトルの加重平均時効が、ニューラルモデルを頻繁に上回ることを実証している。 SCDV （ Mekala et al., 2017 ）は、これをさらに、事前に計算された単語ベクトルの上にソフトでまばらなクラスタリングを採用することによって、文から文に拡張します。 どのようにして、両方のテクニックは単語の多義性と文脈的性格を無視しています。本稿では、コンテキスト化されたBERT （ Devlin et al., 2019 ）ベースの単語センスの埋め込みとSCDVソフトクラスタリングアプローチを組み合わせた、シンプルで効果的な無監督表現であるSCDV + BERT （ ctxd ）を提案することで、この問題に対処します。 当社の埋め込みは、多くの分類データセット上で、ORIGI - NAL SCDV、事前トレーニングBERT、およびいくつかの他のベースラインよりも優れていることを示しています。 Wealsoは、コンセプトマッチングや文章の類似性など、他のタスクでの埋め込みの有効性を実証しています。さらに、SCDV + BERT （ ctxd ）は、限られたデータとわずかなショットの例だけのシナリオで、BERTやさまざまな埋め込みアプローチを細かく調整しています。', 'zh': '诸NLP务对文本文档有效者更分之。 Arora等,2017年证,词向量简加权偏老化常优于神经。 SCDV(Mekala等,2017)于预算词向量上用软疏聚类,更广其句于文档。 此二术者,皆略单词之多义,与上下文之征也。 本文中,发SCDV + BERT(ctxd)以决之,此简而效者无监,将基于con-textualized BERT(Devlin等,2019)之基于单词词嵌SCDV软聚类,以成词义消歧义。 吾明嵌诸类集上优于始 SCDV、预练 BERT 及诸基线。 展我嵌有效性,如对句相似性。 此外又明数有限而少镜头示例者,SCDV+BERT(ctxd) 优于精细调 BERT 异者嵌 ap-proaches。', 'ru': 'Несколько задач NLP нуждаются в эффективном воспроизведении текстовых документов. Арора и др., 2017 демонстрируют, что простое взвешенное среднее старение векторов слов часто превосходитневрологические модели. SCDV (Mekala et al., 2017)дополнительно расширяет это от предложений до решений, используя мягкое и разреженное кластеризацию над предварительно вычисленными векторами слов. Тем не менее, обе методики игнорируют полисемию и контекстный характер слов. В этой статье мы решаем эту проблему, предлагая SCDV +BERT(ctxd), простое и эффективное неконтролируемое представление, которое сочетает встраивание слов на основе контекстуализированного BERT (Devlin et al., 2019) для расчленения смысла слова с подходом мягкой кластеризации SCDV. Показано, что наши вложения превосходят исходные SCDV, BERT перед тренировкой и некоторые другиеосновы на многих классификационных наборах данных. Мы также демонстрируем эффективность наших вложений в других задачах, таких как сопоставление концепций и сходство предложений. Кроме того,мы показываем, что SCDV+BERT(ctxd) превосходит тонкую настройку BERT и различные встраивающие аппроксимации в сценариях с ограниченными данными и только несколькими примерами снимков.', 'hi': 'कई NLP कार्यों को पाठ दस्तावेज़ों के प्रभावी repre-sentation की आवश्यकता होती है। अरोड़ा एट अल., 2017 प्रदर्शित करता है कि शब्द वैक्टर के सरल भारित औसत-उम्र बढ़ने अक्सर तंत्रिका मॉडल से बेहतर प्रदर्शन करते हैं। SCDV (Mekala et al., 2017) आगे पूर्व-परिकलित शब्द वैक्टर पर नरम और विरल क्लस्टर-इंग को नियोजित करके वाक्यों से डॉक्यू-मेंट्स तक इसका विस्तार करता है। कैसे-कभी, दोनों तकनीकें शब्दों के पॉलीसेमी और प्रासंगिक चरित्र को अनदेखा करती हैं। इस पत्र में, हम इस मुद्दे को SCDV + BERT (ctxd) का प्रस्ताव करके संबोधित करते हैं, जो एक सरल और प्रभावी संयुक्त राष्ट्र-पर्यवेक्षित प्रतिनिधित्व है जो SCDV नरम क्लस्टरिंग दृष्टिकोण के साथ शब्द भावना disambigua-tion के लिए एम्बेडिंग के लिए con-textualized BERT (Devlin et al., 2019) को जोड़ता है। Weshow कि हमारे embeddings origi-nal SCDV, पूर्व ट्रेन BERT, और कई वर्गीकरण डेटासेट पर कई अन्य आधारों से बेहतर प्रदर्शन करते हैं। Wealdings भी अन्य कार्यों पर हमारे embeddings प्रभावी-नेस का प्रदर्शन, जैसे अवधारणा मिलान और वाक्य समानता के रूप में. इसके अलावा, हम दिखाते हैं कि SCDV + BERT (ctxd) सीमित डेटा और केवल कुछ शॉट्स उदाहरणों के साथ परिदृश्यों में विभिन्न एम्बेडिंग एपी-प्रोच और विभिन्न एम्बेडिंग एपी-प्रोच को मात देता है।', 'ga': 'Teastaíonn athsheoladh éifeachtach na ndoiciméad téacs ó roinnt tascanna NLP. Déanann SCDV (Mekala et al., 2017) é seo a leathnú tuilleadh ó abairtí go doiciméid trí bhraislí bog agus tanaí a úsáid thar veicteoirí focal réamhríofa. Mar sin féin, déanann an dá theicníocht neamhaird ar charachtar ilghnéitheach agus comhthéacsúil na bhfocal. Sa pháipéar seo, tugaimid aghaidh ar an tsaincheist seo trí SCDV+BERT(ctxd) a mholadh, léiriú simplí agus éifeachtach gan maoirsiú a chomhcheanglaíonn BERT comhthéacsúil (Devlin et al., 2019). ) basedword embedding for word sense disambigua-tion with SCDV bog cnuasach chuige. Léiríonn muid go sáraíonn ár leabaithe SCDV bunaidh, CRET réamhthraenála, agus go leor bonnlínte eile ar go leor tacar sonraí aicmithe. Léirímid freisin ár n-éifeachtacht leabú ar thascanna eile, mar mheaitseáil choincheapa agus cosúlacht abairtí. Chomh maith leis sin, léirímid go sáraíonn SCDV+BERT(ctxd) mion-thonn CRET agus cur chuige leabaithe éagsúla i gcásanna le sonraí teoranta agus gan ach beagán acu. samplaí shots.', 'ka': 'რამდენიმე NLP დავალებები იჭირდება ტექსტის დოკუმენტების ეფექტიური განახლება. Arora et al.,2017-ს დემონსტრაცია, რომ სიტყვის გვექტორების მხოლოდ უფრო გავაკეთებული მოდელები. SCDV კაკ თ ეა ვ, ეგამარა რვჳნთკა თდნჲპთპარ ოჲლთჟვმთწრა თ კჲნრვკჟსრნა ოპთფთნა ნა ესმთრვ. ამ სპეპერში, ჩვენ ამ პრობლემას გადაწყენებთ SCDV+BERT(ctxd), საუკეთესო და ეფექტიური არ დააყენებული გამოსახულებელი გამოსახულება, რომელიც კონტექსტულიზებული BERT (Devlin et al., 2019) სპექტირებულია, რომელიც სიტყვის სიტყვის განს ჩვენ ჩვენი კლასიფიკაციის მონაცემები უფრო გავაკეთებთ origi-nal SCDV, pre-train BERT, და რამდენიმე სხვა კლასიფიკაციის მონაცემები. ვილჟჲ ევმონსრპთპა ნაქთრვ თნტვკრთგნჲჟრთ ნა ეპსდთრვ პაბჲრთ, კარჲ კჲნუვოუთ£ა ჟლთფნჲჟრ თ ჟლთფნჲჟრ ნა ოპვეგთე. დამატებით, ჩვენ გამოჩვენებთ, რომ SCDV+BERT(ctxd) ბერტი-ტუნი-ტუნი BERT და განსხვავებული სენარიოში ჩატვირთვა ყველაფერი სენარიოში, რომლებიც დავწერებული მონაცემები და მხოლოდ', 'el': 'Αρκετές εργασίες NLP χρειάζονται την αποτελεσματική αντιπροσώπευση εγγράφων κειμένου. Η Αρόρα κ.λ.,2017 αποδεικνύει ότι η απλή σταθμισμένη αντιστάθμιση των διανυσματικών λέξεων συχνά ξεπερνά τα νευρωνικά μοντέλα. Η SCDV (Mekala et al., 2017)επεκτείνει περαιτέρω αυτό από προτάσεις σε έγγραφα χρησιμοποιώντας μαλακή και αραιή συσσώρευση πάνω από προ-υπολογισμένα διανύσματα λέξεων. Ωστόσο, και οι δύο τεχνικές αγνοούν τον πολυσημιακό και περιεκτικό χαρακτήρα των λέξεων. Σε αυτό το άρθρο, αντιμετωπίζουμε αυτό το ζήτημα προτείνοντας μια απλή και αποτελεσματική μη εποπτευόμενη αναπαράσταση που συνδυάζει την ενσωμάτωση λέξεων με βάση το κείμενο με την προσέγγιση μαλακής ομαδοποίησης. Να δείξουμε ότι οι ενσωματώσεις μας ξεπερνούν την αρχική SCDV, την προ-εκπαίδευση BERT και αρκετές άλλες γραμμές βάσης σε πολλά σύνολα δεδομένων ταξινόμησης. Θα επιδείξουμε επίσης την αποτελεσματικότητα των ενσωματώσεων μας σε άλλες εργασίες, όπως η αντιστοίχιση εννοιών και η ομοιότητα των προτάσεων. Επιπλέον, δείχνουμε ότι το SCDV+BERT(ctxd) ξεπερνά τις επιδόσεις του BERT και τις διαφορετικές προσεγγίσεις ενσωμάτωσης σε σενάρια με περιορισμένα δεδομένα και ελάχιστα παραδείγματα λήψεων.', 'hu': 'Számos NLP-feladatra van szükség a szöveges dokumentumok hatékony megismertetésére. Arora et al., 2017 bizonyítja, hogy a szóvektorok egyszerű súlyozott átlagos öregedése gyakran felülmúlja a teljesítményneurális modelleket. Az SCDV (Mekala et al., 2017) tovább bővíti ezt a mondatoktól a dokumentumokig azáltal, hogy puha és ritka klaszterezést alkalmaz előre kiszámított szóvektorokkal szemben. Mindkét technika azonban figyelmen kívül hagyja a szavak poliszemiás és kontextuális karakterét. Ebben a kérdésben az SCDV+BERT(ctxd), egy egyszerű és hatékony, felügyelet nélküli reprezentáció javaslatával foglalkozunk ezzel a problémával, amely ötvözi a szöveges BERT (Devlin et al., 2019) alapszó beágyazását a szó értelmezésének egyértelműsítéséhez az SCDV soft klaszterelési megközelítésével. Számos osztályozási adatkészleten felülmúlják az eredeti SCDV-t, a BERT-t és számos más alapvonalat. Beágyazásunk hatékonyságát más feladatokban is bemutatjuk, mint például a koncepciók összehasonlítása és a mondatok hasonlósága. Ezenkívül megmutatjuk, hogy az SCDV+BERT(ctxd) teljesítményét a BERT finomhangolásához és a különböző beágyazási eljárásokhoz korlátozott adatokkal és csak néhány felvételi példával rendelkező forgatókönyvekben.', 'it': "Diversi compiti del PNL richiedono una rappresentazione efficace dei documenti di testo. Arora et al.,2017 dimostrano che il semplice averaging ponderato dei vettori di parola spesso supera i modelli neurali prestazionali. SCDV (Mekala et al., 2017) estende ulteriormente questo concetto dalle frasi ai documenti impiegando cluster soft e sparso su vettori di parole pre-calcolati. Tuttavia, entrambe le tecniche ignorano il polisemie e il carattere contestuale delle parole. In questo articolo, affrontiamo questo problema proponendo SCDV+BERT(ctxd), una rappresentazione non supervisionata semplice ed efficace che combina l'embedding basato su parole con testo BERT (Devlin et al., 2019) per la disambiguazione del senso delle parole con l'approccio SCDV soft clustering. In molti set di dati di classificazione, le nostre incorporazioni superano le prestazioni iniziali SCDV, BERT pre-treno e molte altre linee di base. Dimostreremo inoltre l'efficacia delle nostre incorporazioni su altri compiti, come l'abbinamento dei concetti e la somiglianza delle frasi. Inoltre, mostriamo che SCDV+BERT(ctxd) supera le prestazioni di BERT e diverse applicazioni di incorporamento in scenari con dati limitati e solo pochi esempi di scatti.", 'mk': 'На неколку задачи на НЛП им треба ефикасна претстава на текстовите документи. Арора и други, 2017 демонстрираат дека едноставното тежено просечно стареење на векторите на зборови често ги надминува норалните модели. SCDV (Mekala et al., 2017)понатаму го проширува ова од реченици до документи со употреба на меки и мали групирачки вектори над прекомпјутираните зборови. Сепак, двете техники го игнорираат полисемиот и контекстниот карактер на зборовите. Во овој спапер, го решаваме ова прашање предлагајќи SCDV+BERT( ctxd), едноставна и ефикасна ненадгледувана претстава која ги комбинира контекстулизираните BERT (Devlin et al., 2019) базирани зборови за раздвојување на зборовите со слабиот пристап на SCDV кластерирање. Ние покажуваме дека нашите внесувања ги надминуваат оригиналните SCDV, пред возењето BERT, и неколку други бази на многу податоци за класификација. Вилсо ја демонстрира нашата вмешаност ефикасност во другите задачи, како што се концептот на споредба и сличноста на речениците. Покрај тоа, покажуваме дека SCDV+BERT( ctxd) ги надминува резултатите од line- tune BERT и различните вградени ap- proaches во сценарија со ограничени податоци и само неколку примери од снимки.', 'lt': 'Several NLP tasks need the effective repre-sentation of text documents. Arora et al.,2017 m. rodo, kad paprastas svertinis žodžių vektorių vidurkis dažnai viršija neurologinius modelius. SCDV (Mekala et al., 2017 m.) toliau pratęsia nuo sakinių iki dokumentų, naudojant minkštą ir nedidelę klasterizaciją prieš iš anksto apskaičiuotus žodžių vektorius. Vis dėlto abu metodai ignoruoja žodžių polisemiją ir kontekstinį pobūdį. Šiame spaper sprendžiame šį klausimą pasiūlydami SCDV+BERT(ctxd), paprastą ir veiksmingą nepastebimą atstovavimą, kuris sujungia tekstualizuotą BERT (Devlin et al., 2019 m.), grindžiamą žodžių supratimo nesuderinamumu su SCDV minkšto klasterizavimo metodu. Mes parodysime, kad mūsų įdėjimai viršija pradinę SCDV, prieš traukinį BERT ir keletą kitų bazinių linijų daugelyje klasifikavimo duomenų rinkinių. Wealso taip pat įrodo, kad mes įtraukiame veiksmingumą į kitas užduotis, pvz., sąvokų derinimą ir sakinių panašumą. Be to, mes rodome, kad SCDV+BERT(ctxd) rezultatai yra suderinti su BERT ir skirtingi įtraukimo metodai į scenarijus, kuriuose duomenys yra riboti, ir tik keletas fotografijų pavyzdžių.', 'kk': 'Кейбір NLP тапсырмаларында мәтін құжаттарды қайта құру керек. Арора и ал.,2017 жылы сөздердің қарапайым жетілдірілген векторларының көпшілігін өзгерту үлгілерін көрсетеді. SCDV (Mekala et al., 2017) бұл сөздерді сөздерден документтерге қолданып, алдын- есептелген сөздер векторларының арқылы жабысқа және кеңістік кластерін қолдануға арналады. Қалай болса, екеуі техникалар полиземмен контексті сөздердің таңбаларын елемейді. Бұл мәселеге SCDV+BERT( ctxd) дегенді таңдап береміз. Бұл мәселеге контекстуализацияланған BERT (Devlin et al., 2019) бағдарламасын SCDV бағдарламалық кластерлік арқылы сөздердің сезімі үшін дембигуа- таңдау үшін қолданылатын кәдімгі және Біздің ендіруіміздің көпшілік классификациялық деректер қорларындағы көпшілікті SCDV, BERT алдындағы және бірнеше бағдарламалық жолдарды жасайды. Wealso біздің ендіруіміздің басқа тапсырмалардың эффективнігін көрсетеді, мысалы, сәйкестіктер мен сөйлеменің ұқсастығы. Қосымша, біз SCDV+BERT( ctxd) берттеулердің шектелген мәліметтері және тек бірнеше сценариялық сценарияларда әртүрлі бағдарламалардың шектелген жағдайды көрсетедік.', 'ml': 'Several NLP tasks need the effective repre-sentation of text documents. അരോറാ എറ്റ് അല്\u200d.,2017 വാക്ക് വെക്റ്ററുകളുടെ വയസ്സില്\u200d എളുപ്പമുള്ള വയസ്സായിരുന്നു എന്ന് പ്രത്യക്ഷിക്കുന്നു. എസ്സിഡിവി (മെക്കാ എറ്റ് എൽ, 2017) വാക്കുകളില്\u200d നിന്നും ഡോക്ടറിലേക്ക് മാറ്റുന്നത് മുമ്പ് കണക്കിലാക്കുന്ന വാക്ക് വെക്റ്ററുകള എപ്പോഴെങ്കിലും, രണ്ട് സാങ്കേതികവിദ്യകളും വാക്കുകളുടെ കൂട്ടത്തിലുള്ള പോലിസെമിന്റെയും സാധാരണ ക തിസ്പാപ്പരില്\u200d, SCDV+BERT( ctxd) പ്രാദേശിപ്പിക്കുന്നത് നമ്മള്\u200d ഈ പ്രശ്നത്തെക്കുറിച്ച് വിശദീകരിക്കുന്നു. അത് കോണ്\u200dട്ടെക്സ്ച്ചലേഷന്\u200d ബെര്\u200dട്ടി (ഡെവെല്\u200dലിന്\u200d എല്\u200d., 2019) വാക്ക്  ഞങ്ങളുടെ അകത്തേക്ക് പോകുന്നത് ഓറിജി-നാള്\u200d സിഡിവി, മുന്നോട്ട് ട്രെയിന്\u200d ബെര്\u200dട്ടി (BERT), പല വിഭാഗവിവരങ്ങളുടെ ഡാറ്റാസറ്റ മറ്റു ജോലികളില്\u200d നമ്മുടെ അഭിപ്രായത്തിന്റെ പ്രധാനപ്പെടുത്തിവെക്കുന്ന പ്രകടനങ്ങള്\u200d പ്രത്യക്ഷപ്പെടുത്തുന്നു.  കൂടാതെ, SCDV+BERT(ctxd) പുറത്ത് പ്രദര്\u200dശിപ്പിക്കുന്നത് ബെര്\u200dട്ടിയില്\u200d നിന്നും വ്യത്യസ്തമായ എപ്പ്-പ്രോചെക്സുകളും സിനേറ്ററിയോസില്\u200d നി', 'ms': 'Beberapa tugas NLP memerlukan penghantaran semula dokumen teks yang berkesan. Arora et al.,2017 menunjukkan bahawa keseluruhan umur vektor perkataan yang berat sederhana sering melebihi model sneural. SCDV (Mekala et al., 2017)melanjutkan ini dari kalimat ke dokumen dengan menggunakan kelompok lembut dan ringan atas vektor perkataan pra-komputer. Bagaimanapun, kedua-dua teknik mengabaikan aksara polisemyand kontekstual perkataan. Dalam spaper ini, kami mengatasi isu ini dengan melaporkan SCDV+BERT( ctxd), sebuah perwakilan mudah dan efektif tanpa mengawasi yang menggabungkan bentuk BERT (Devlin et al., 2019) berdasarkan teks untuk penyelesaian perkataan dengan pendekatan kelompok lembut SCDV. Kita tunjukkan bahawa penyembedding kita melampaui SCDV asal, BERT sebelum kereta api, dan beberapa garis lain pada banyak set data pengelasahan. Wealso menunjukkan keefektivitas penyembedding kita pada tugas lain, seperti konsep sepadan dan persamaan kalimat. Selain itu, kami menunjukkan bahawa SCDV+BERT(ctxd) melampaui prestasi BERT baris-tune dan proach-embedding berbeza dalam skenario dengan data terbatas dan hanya beberapa contoh tembakan.', 'mt': 'Diversi kompiti tal-NLP jeħtieġu r-rappreżentazzjoni effettiva tad-dokumenti tat-test. Arora et al.,2017 juru li l-medja ppeżata sempliċi tat-tixjiħ tal-vetturi tal-kliem spiss taqbeż il-mudelli newrali. SCDV (Mekala et al., 2017) testendi aktar dan mis-sentenzi għad-dokumenti billi tuża raggruppament dgħajjef u żgħir fuq vetturi tal-kliem ikkumputati minn qabel. Madankollu, iż-żewġ tekniki jinjoraw il-karattru poliżiku u kuntestwali tal-kliem. In thispaper, we address this issue by proposingSCDV+BERT(ctxd), a simple and effective un-supervised representation that combines con-textualized BERT (Devlin et al., 2019) basedword embedding for word sense disambigua-tion with SCDV soft clustering approach.  Nirriżultaw li l-inkorporazzjonijiet tagħna jaqbżu l-SCDV oriġinali, il-BERT ta’ qabel il-ferrovija, u diversi linji oħra fuq ħafna settijiet ta’ dejta ta’ klassifikazzjoni. Wealso juri wkoll l-effettività tal-inkorporazzjonijiet tagħna f’kompiti oħra, bħall-paragun tal-kunċetti u s-similarità tas-sentenzi. Barra minn hekk, aħna nuru li SCDV+BERT(ctxd) irriżultaw minn BERT b’aġġustament fiss u approċċi differenti ta’ inkorporazzjoni fix-xenarji b’dejta limitata u ftit eżempji ta’ shot biss.', 'pl': 'Kilka zadań NLP wymaga skutecznej reprezentacji dokumentów tekstowych. Arora i al.,2017 pokazują, że proste ważone przeciwstarzenie wektorów słowa często przewyższa modele neuronowe. SCDV (Mekala et al., 2017)dodatkowo rozszerza to od zdań do dokumentów, stosując miękkie i rzadkie klastrowanie nad wstępnie obliczonymi wektorami słów. Jednakże obie techniki ignorują polizemię i kontekstowy charakter słów. W tym artykule rozwiązujemy ten problem, proponując SCDV+BERT(ctxd), prostą i skuteczną nienadzorowaną reprezentację, która łączy skontextualizowane BERT (Devlin et al., 2019) oparte na osadzeniu słów dla dyambiguacji sensu słowa z podejściem do miękkiego klastrowania SCDV. Nasze osadzenia przewyższają oryginalne SCDV, BERT i kilka innych linii bazowych na wielu zbiorach danych klasyfikacyjnych. Wykazujemy również efektywność osadzenia w innych zadaniach, takich jak dopasowanie koncepcji i podobieństwo zdań. Dodatkowo pokazujemy, że SCDV+BERT(ctxd) wydaje się lepiej dostroić BERT i różne procesy osadzania w scenariuszach z ograniczonymi danymi i niewieloma przykładami ujęć.', 'ro': 'Mai multe sarcini PNL necesită reprezentarea eficientă a documentelor text. Arora et al., 2017 demonstrează că îmbătrânirea medie ponderată simplă a vectorilor de cuvânt depășește frecvent modelele neuronale performante. SCDV (Mekala et al., 2017) extinde în continuare acest lucru de la propoziții la documente prin utilizarea de cluster-ing soft și rar peste vectori de cuvinte pre-calculați. Cu toate acestea, ambele tehnici ignoră caracterul polisemiși contextual al cuvintelor. În acest articol, abordăm această problemă propunând SCDV+BERT(ctxd), o reprezentare simplă și eficientă fără supraveghere care combină încorporarea cuvintelor bazate pe BERT (Devlin et al., 2019) pentru dezambiguizarea sensului cuvintelor cu abordarea clusterizării soft SCDV. Încorporările noastre depăşesc performanţele SCDV iniţiale, BERT pre-train şi mai multe alte linii de bază pe multe seturi de date de clasificare. De asemenea, să demonstrăm eficiența încorporărilor noastre în alte sarcini, cum ar fi potrivirea conceptului și similitudinea propozițiilor. În plus, arătăm că SCDV+BERT(ctxd) depășește performanțele optime ale BERT și diferite proiecte de încorporare în scenarii cu date limitate și doar câteva exemple de fotografii.', 'mn': 'НЛП-ын олон даалгаврууд текст баримтыг дахин дахин өгүүлэх хэрэгтэй. Арора и аль.,2017 онд энгийн хэмжээний векторуудын хөгжүүлэх нь ихэвчлэн үйл ажиллагааны загвараас илүүтэй. SCDV (Mekala et al., 2017) үүнийг өгүүлбэрээс docu-ments руу нэмэгдүүлдэг. Өмнөх тооцоологдсон үгний векторуудын хувьд бага болон богино кластерийг ашиглаж байна. Яаж ч гэсэн, хоёр техник нь полицемийн, орчин үгний харилцааны харилцааныг эсэргүүцдэг. Энэ асуудлыг бид SCDV+BERT(ctxd) гэсэн санал болгоход энгийн, эффективнэй, удирдлагагүй илтгэл зохион байгуулалт хийдэг. Энэ асуудлыг солилцуулсан BERT (Devlin et al., 2019) суурь зохион байгуулалт нь SCDV бага хэмжээний арга хэмжээнд зохион байгуулагддаг. Бид өөрсдийнхөө хөрөнгө оруулалтын эхний SCDV, BERT-ын өмнө дасгал хөдөлгөөн болон олон төрлийн өгөгдлийн санд олон өөр хэсгүүдийг хийдэг гэдгийг харуулж байна. Уилзо өөр ажил дээр үр дүнтэй байдлыг харуулж байна. Яг л ойлголт тоглох болон өгүүлбэртэй адилхан. Мөн бид SCDV+BERT(ctxd) бүтээгдэхүүний үр дүнг BERT болон хязгаарлагдсан өгөгдлийн хувилбар болон хэдэн зураг жишээлүүдийн хувилбарт өөр өөр нэгдэж байгааг харуулж байна.', 'no': 'Fleire NLP-oppgåver treng det effektive gjenoppretting av tekstdokument. Arora et al.,2017 viser at enkelt vekt lagring av ordvektorar ofte utfører utviklingsmedler. SCDV (Mekala et al., 2017) utvidar dette frå setningar til docu-ments ved å bruka måk og sparse cluster ing over forrekna ordvektorar. Kor mykje, begge teknikkar ignorerer polysemen og kontekst teikn av ord. I denne området er vi oppretta dette problemet ved å foreslå SCDV+BERT(ctxd), eit enkel og effektivt ikkje-oversikt representasjon som kombinerer con-textualisert BERT (Devlin et al., 2019) basedword som innebygger for ordfølelse disambigua-tion med SCDV-måk clustering tilnærming. Vis at innbyggingane våre utfører origi nal nal SCDV, før-treng BERT, og fleire andre ulike linjer på mange klassifikasjonsdata. Wealso viser innbygginga våre effektivt på andre oppgåver, slik som konsept for samsvar med setningar. I tillegg viser vi at SCDV+BERT(ctxd) er utgått av finn-tune BERT og ulike innbygging av ap-proaches i scenarioar med begrensede data og berre få eksemplar på fotografikk.', 'si': 'NLP වැඩක් වෙනස් වැඩක් ලිපින්ත ලිපින්ත ලිපින්ත වාර්තාව ආපහු ප්\u200dරතික්\u200dරියාත්මක කරන්න ඕනි. Arora et al.,2017 පෙන්වන්නන්න පුළුවන් විදිහට වෙක්ටර් වලින් ප්\u200dරමාණයක් නැති විදිහට ප්\u200dරමාණය කරනවා කියලා. SCDV (Mecala et al., 2017) කොහොමද කියලා, දෙන්නම් තාක්ෂණය පොලිසිමියාන් වචන වගේ සංවේදනය අවධානය කරන්න. In this spaper, we address this challenge by preaching SCDV+BERT(ctxm), a strain and ffective un-supervised reposition that combinates Con-textuolized BERT (Devlin et al., 2019) basedword integrating for word sensing disombgua-tion with SCDV software cluster ing approach. අපි පෙන්වන්නම් අපේ ඇම්බෙන්ඩින්ග් ප්\u200dරධාන SCDV, BERT ප්\u200dරධාන ප්\u200dරධාන ප්\u200dරධානය, සහ වෙනස් විශේෂණ දත්ත සේට් වලි විල්සෝ පෙන්වන්නේ අනිත් වැඩවල් වලට අපේ සංවේදනය ප්\u200dරශ්නය කරනවා, ඒ වගේම සංවේදනය සහ වාක්ය වගේම. ඒ වගේම, අපි පෙන්වන්නේ SCDV+BERT(ctxm) නිර්භාවිත BERT වලින් වෙනස් ප්\u200dරශ්නයක් වලින් ප්\u200dරශ්නයක් තියෙනවා සීමාන්\u200dය දත්ත සහ ප්\u200dරශ්නයක', 'sr': 'Nekoliko zadataka NLP-a je potrebno efikasno ponovno rešiti tekstske dokumente. Arora et al.,2017. pokazuje da je jednostavno težino održavanje vektora rečenih vektora često iznad izvornih modela. SCDV (Mekala et al., 2017) dodatno proširi ovo od rečenica na docu-ments koristeći meke i rezervne skustere preko pre-računalnih vektora rečenica. Kako god, obe tehnike ignoriraju polisemijski kontekstualni karakter reèi. U toj oblasti, rješavamo se ovom pitanju predloženjem SCDV+BERT(ctxd), jednostavnom i efikasnom nedovoljnom predstavljanju koja kombinuje kontekstualiziranu BERT (Devlin et al., 2019) baznu ploču koja se uključuje za disambigua-ciju reèima sa mekim pristupom SCDV-a. Pokazujemo da naše uključenje iznosi originalni SCDV, pre vožnje BERT i nekoliko drugih bazena na mnogim klasifikacijskim podacima. Wealso pokazuje naše uključenje učinkovitosti na druge zadatke, kao što su koncept odgovaranja i sličnost rečenica. Osim toga, pokazujemo da je SCDV+BERT(ctxd) iznad izvedbi BERT-a i različite ugrađivanje jabuka u scenarijima sa ograničenim podacima i samo nekoliko primjera snimaka.', 'so': "Shaqooyin badan oo NLP ah waxay u baahan yihiin dib u soo celinta warqadaha qoraalka. Arora et al.,2017 waxay muujiyaan in si fudud u miisaamay waxey si fudud u taqaan wadooyinka hadalka oo marar badan u samaysan qaababka Yurub. SCDV (Mekala et al., 2017) Si kastaba ha ahaatee labada teknikada ayaa ka jeeda qoraalka la yidhaahdo polysemi iyo xarafka qoraalka ah. Taaspaper, waxan ayaannu ka sheekaynaynaa suurtagalka SCDV+BERT(ctxd), kaas oo ah mid fudud oo faa'iido ah oo aan ilaalinayn, kaas oo ku soo ururiya con-textualized BERT (Devlin et al., 2019) Basdword oo ku qoran word disambigua-tion with SCDV approach soft cluster. Weshow in boosasheenna ay ka muuqato origi-nal SCDV, pre-train BERT, iyo qaar kale oo ku qoran koorasyo kala duduwan. Sidoo kale waxaynu muujinnaa shaqaalahayaga saameyn u leh shaqaalaha kale, tusaale ahaan fikrada u eg isku mid ahaanshaha iyo imtixaanka. Waxaa kale oo aan muujinnaa in SCDV+BERT(ctxd) outperformsfine-tune BERT iyo sidoo kale kooxaha ap-wacdiyo kala duduwan oo ay ku haystaan macluumaad xad ah iyo tusaalooyin yar oo ganacsi ah.", 'ta': 'பல NLP பணிகள் உரை ஆவணங்களின் விருப்பமான மீண்டும் உணர்வு தேவை. அரோரா மற்று அல்.,2017 சுலபமான வார்த்தை வெக்டர்கள் சராசரி வயதாக எடுத்தார்கள் என்பதை குறிப்பிடுகிறது. SCDV (மெக்கலா மற்றும் அல்., 2017) முன் கணக்கிடப்பட்ட வார்த்தை வெக்டார்களை பயன்படுத்தி மென் மற்றும் வெக்டார்களை பயன்படுத்தி இதை மேலும் வாக்க How-ever, both techniques ignore the polysemyand contextual character of words. திஸ்பேப்பரில், SCDV+BERT( ctxd), ஒரு எளிய மற்றும் பயன்படுத்தப்படாத கண்காணிக்கப்படாத பகுதியை நாம் இந்த பிரச்சினையை விளக்குகிறோம். இது கூட்டு நூல் நிறுவப்பட்ட BERT (டெப்லின் et al., 2019) க எங்கள் உள்ளீடுகள் ஓரிஜி-நாள் SCDV, முன் பயிற்சி BERT, மற்றும் பல வகுப்பு தரவுத்தளங்களில் பல மேற்கோடுக்கோடுகள். நாம் மற்ற பணிகளில் எங்கள் உள்ளடக்கங்களுக்கு வெளிப்படையான தெளிவாக்கம் காட்டுகிறோம், பொருத்தம் மற்றும் வாக்கியத்தி மேலும், SCDV+BERT(ctxd) வெளியிடும் செயல்பாடு-tune BERT மற்றும் வேறு வித்தியாசமான பிப் பகிர்வாசிகள் காண்பிக்கிறோம் மற்றும் எல்லாம் தகவல்', 'ur': 'بہت سی NLP تاسکیوں کی تاسکیٹ ڈکومکیٹ کے مطابق دوبارہ سنتی کی ضرورت ہے. Arora et al.,2017 دکھاتا ہے کہ کلمات ویکتروں کی ساده وزن کی سنگی ہے، بہت سے زیادہ اضافہ کرنے والی موڈل. SCDV (Mekala et al., 2017) اس کو مفصل سے ڈاکو منٹ تک پہنچا دیتا ہے کہ نرم اور نرم کلسٹر کا استعمال کرتا ہے۔ کہیں بھی، دونوں تکنیک کلمات کی پولیسیم اور متوسط شخصیت کو غافل کرتے ہیں۔ اس جگہ میں ہم اس مسئلہ کو مشورہ کریں گے SCDV+BERT(ctxd) کی پیشنهاد سے، ایک ساده اور اثبات غیر نظارت کی تصویر جو con-textualized BERT (Devlin et al., 2019) بنسٹ ورڈ کو جمع کرتا ہے، جو کلمات کے لئے SCDV نرم کلسٹرینگ طریقے کے ساتھ مکمل ہوتا ہے۔ ہم نشان دیتے ہیں کہ ہمارے ایمبڈینگ آغاز-نال SCDV، پہلے ٹرین BERT اور بہت سی کلاسیکٹ ڈیٹ سٹ پر بہت سی دوسری صفحے ہیں۔ ویلسو ہمارے انڈینگ کو دوسرے کاموں پر اثرات کے ساتھ دکھاتا ہے، جیسے مفصل مطابق اور جماعت کی برابری. اور اس کے علاوہ ہم نشان دیتے ہیں کہ SCDV+BERT(ctxd) فین-ٹون BERT اور مختلف مصنوعی اندازے کے مطابق مختلف مصنوعی کے مطابق اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا ا', 'sv': 'Flera nationella handlingsplaner kräver en effektiv återgivning av textdokument. Arora et al., 2017 visar att enkel viktad averaging av ordvektorer ofta överträffar performanceneurala modeller. SCDV (Mekala et al., 2017) utökar detta ytterligare från meningar till dokument genom att använda mjuk och gles klustring över förberäknade ordvektorer. Båda teknikerna ignorerar dock ordens polysemiska och kontextuella karaktär. I den här artikeln tar vi upp detta problem genom att föreslåSCDV+BERT(ctxd), en enkel och effektiv icke-övervakad representation som kombinerar kontextualiserad BERT (Devlin et al., 2019) baserad ordinbäddning för ordförnimmelse och SCDV mjuk klustring metod. Vi visar att våra inbäddningar presterar bättre än original SCDV, pre-train BERT och flera andra baslinjer på många klassificeringsdatauppsättningar. Vi ska också visa vår inbäddning effektivitet på andra uppgifter, såsom konceptmatchning och meningsliknande. Dessutom visar vi att SCDV+BERT(ctxd) presterar bättre än att finjustera BERT och olika inbäddningsapproacher i scenarier med begränsad data och endast få bilder exempel.', 'uz': "Koʻp nechta NLP vazifalar matn hujjatlarini qayta takrorlash kerak. Arora et al.,2017 oddiy so'z vektorining o'rtacha o'rtacha o'smirligini ko'rsatish mumkin. Name Shunday qilib, ikkita teknologiya polisemiz va ma'lum so'zlarning har xil harfni o'zgartiradi. Bu muammolarni SCDV+BERT(ctxd) rivojlanish orqali, oddiy va effektiv nazorat qilmagan representiyatlarni boshqarish mumkin. Bu biz SCDV va SCDV soʻzni boshqarish usuli bilan birlashtirish uchun oddiy va ishlab chiqaruvchi bo'lgan BERT (Devlin et al., 2019). Weshow bizning tuzilishimiz origi-ichki SCDV, BERT oldin taqdim, va ko'p ta'lim maʼlumotlar tarkibidagi bir necha boshqaruvchilar. Va biz boshqa vazifalarga ishlashimizni tasavvur qilamiz, tushuning o'xshash va gapirish bir xil. Ko'rsatganda, SCDV+BERT(ctxd) outperformsfine-tune BERT (BERT) va scenariosdagi boshqa ap-prokaslari bilan chegara maʼlumot va faqat bir necha shot misollari bilan ishlatiladi.", 'vi': 'Một số công việc của Đảng NLP cần có sự đại diện hiệu quả của văn bản. Arora et Al,2007 chứng minh rằng giá trị trung bình đơn giản của giá trị cổ động từ trường phổ biến thường vượt trội. Tổ chức SCDV (Meuca et al., 2007) nới rộng từ câu này sang biên tập bằng cách sử dụng cụm từ mềm mỏng và mỏng hơn nhiều so với giá trị từ cổ xưa. Tuy nhiên, cả hai kỹ thuật lờ đi tính chất lục địa và ngữ cảnh của từ. Trong nghiên cứu này, chúng tôi giải quyết vấn đề này bằng cách đề xuất SCDV+BERT (ctyxd), một mô hình đơn giản và hiệu quả không được giám sát, kết hợp kết hợp kết cấu kết cấu kết cấu kết hợp BERT (Devlin et al., 209) nền từ ngữ: Chúng tôi làm cách khác để hoàn thành tập tin khủng long khai mạc, Trước mùa đông BERT, và nhiều nền khác trên nhiều tập tin phân loại. chứng minh sự tác hợp hiệu quả của chúng ta với các công việc khác, như khả năng kết hợp và kết án giống nhau. Ngoài ra, chúng tôi cho thấy nhóm SCDV+BERT(ctyxd) thành công vượt trội cho giải mã BERT và nhiều trường hợp khác nhau trong các kịch bản có giới hạn dữ liệu và chỉ vài ví dụ.', 'bg': 'Няколко задачи от НЛП се нуждаят от ефективно представяне на текстови документи. Арора и др., 2017 демонстрират, че простата претеглена средна възраст на векторите на словото често надвишава перфектните неврални модели. SCDV (Mekala et al., 2017) допълнително разширява това от изречения до документи, като използва меко и рядко клъстериране върху предварително изчислени вектори на думи. Както и да е, двете техники игнорират полисемиятконтекстуалния характер на думите. В този раздел ние разглеждаме този проблем, като предлагаме просто и ефективно неконтролирано представяне, което съчетава контекстуализирано BERT (Девлин и др., 2019), базирано на вграждане на думи за изясняване на смисъла на думата с подхода на меко клъстериране SCDV. Ние показваме, че нашите вграждания превъзхождат оригиналните SCDV, предтренажните BERT и няколко други базови линии в много класификационни набори от данни. Ние също така демонстрираме ефективността на вграждането си върху други задачи, като съвпадение на концепции и сходство с изречения. В допълнение, ние показваме, че SCDV+BERT(ctxd) превъзхожда фината настройка на BERT и различните вграждащи приложения в сценарии с ограничени данни и само няколко примера за снимки.', 'da': 'Flere NLP-opgaver kræver effektiv repræsentation af tekstdokumenter. Arora et al., 2017 viser, at simpel vægtet averaging af ordvektorer ofte overperformanceneurale modeller. SCDV (Mekala et al., 2017) udvider dette yderligere fra sætninger til dokumenter ved at anvende blød og sparsom klyngning over forudberegnede ordvektorer. Begge teknikker ignorerer imidlertid ordenes polysemogkontekstuelle karakter. I denne beskrivelse behandler vi dette problem ved at foreslå SCDV+BERT(ctxd), en enkel og effektiv ikke-overvåget repræsentation, der kombinerer kontekstualiseret BERT (Devlin et al., 2019) baseret ordindlejring for ordforståelse med SCDV soft clustering tilgang. Vi mener, at vores indlejringer på mange klassificeringsdatasæt overgår oprindelige SCDV, BERT forud for træningen og flere andre basislinjer. Vi skal også demonstrere vores indlejringer effektivitet på andre opgaver, såsom konceptmatching og sætning lighed. Desuden viser vi, at SCDV+BERT(ctxd) overgår resultaterne finjusteret BERT og forskellige indlejrings-processer i scenarier med begrænsede data og kun få billeder eksempler.', 'nl': "Verschillende NLP-taken vereisen een effectieve representatie van tekstdocumenten. Arora et al.,2017 tonen aan dat eenvoudige gewogen aver-aging van woordvectoren vaak beter presteert dan neurale modellen. SCDV (Mekala et al., 2017)breidt dit verder uit van zinnen naar documenten door gebruik te maken van zachte en schaarse clustering over vooraf berekende woordvectoren. Beide technieken negeren echter het polysemische en contextuele karakter van woorden. In dit artikel pakken we dit probleem aan door SCDV+BERT(ctxd) voor te stellen, een eenvoudige en effectieve niet-begeleide representatie die gecontextualiseerde BERT (Devlin et al., 2019) basedword embedding combineert voor woordsense disambigua met SCDV soft clustering aanpak. We laten zien dat onze embeddings beter presteren dan originele SCDV, pre-train BERT en verschillende andere baselines op veel classificatiedatasets. We demonstreren ook onze effectiviteit bij andere taken, zoals conceptmatching en zinsgelijkenis. Daarnaast laten we zien dat SCDV+BERT(ctxd) beter presteert dan BERT en verschillende embedding-processen in scenario's met beperkte data en weinig shots voorbeelden.", 'hr': 'Nekoliko zadataka NLP-a potrebno je učinkovito ponovno kazanje tekstskih dokumenta. Arora et al., 2017. pokazuje da je jednostavno težino održavanje vektora riječi često iznad izvornih modela. SCDV (Mekala et al., 2017) dalje to proširi od kazne na docu-ments koristeći meke i rezervne skupine preko predračunalnih vektora riječi. Kako god, obje tehnike ignoriraju polisemijski kontekstualni karakter riječi. U toj oblasti, riješimo ovaj problem predloženjem SCDV+BERT(ctxd), jednostavnom i učinkovitom nedovoljnom predstavljanju koji kombinira kontekstualiziranu BERT (Devlin et al., 2019) baznu stroj koja se uključuje za disambigua-ciju riječi s mekim pristupom SCDV-a. Mi pokazujemo da naše ugrađenje iznosi originalni SCDV, pre vožnje BERT i nekoliko drugih bazena na mnogim podacima klasifikacije. Wealso pokazuje naše uključenje učinkovitosti na druge zadatke, poput koncepta odgovaranja i sličnosti rečenica. Osim toga, pokazujemo da je SCDV+BERT(ctxd) nadmažena djelovanja BERT-a i različitih ugrađenih prolaza u scenarijima s ograničenim podacima i samo nekoliko primjera snimaka.', 'ko': '여러 NLP 작업을 수행하려면 텍스트 문서를 효과적으로 표현해야 합니다.아로라 등은 2017년 단어 벡터의 단순가중평균값이 보통 자연모델보다 우수하다는 것을 증명했다.SCDV(Mekala et al., 2017)는 미리 계산된 단어의 벡터에 대해 연성 희소 집합을 실시하여 문장에서 문서로 확장한다.그러나 이 두 가지 기술은 모두 단어의 다의성과 상하문 특징을 소홀히 했다.본고에서 우리는 CDV+BERT(ctxd)를 제시함으로써 이 문제를 해결한다.ctxd는 간단하고 효과적인 무감독 표현으로 상하 문화 BERT(Devlin et al., 2019)의 DWORD를 바탕으로 단어의 뜻을 없애는 방법과SCDV 소프트 집합 방법을 결합시킨다.우리는 많은 분류 데이터 집합에 삽입된 것이 원시 SCDV, 예비 훈련 BERT, 기타 일부 기선보다 우수하다는 것을 보여 주었다.우리는 개념 일치와 문장 유사성 등 다른 임무에 대한 효과적인 삽입도 보여 주었다.그 밖에 SCDV+BERT(ctxd)는 데이터가 유한하고 소량의 렌즈만 있는 상황에서 BERT와 서로 다른 삽입 ap 방법보다 우수하다는 것을 증명했다.', 'fa': 'چندتا کار NLP نیاز به بازگرداندن مدارک متن دارد. Arora et al.,۲۰۱۷ نشان می دهد که سنگین سنگین سنگین سنگین ویکتورهای کلمه اغلب از مدل های عملکرد غیر قابل توجه است. SCDV (Mekala et al., 2017) این را از جمله\u200cها به دوک-ments به وسیله استفاده از کلاستر نرم و نرم بر روی ویکتورهای کلمه پیش\u200cمحاسبه می\u200cکند. هرچقدر، هر دوی تکنیک ها شخصیت پلیسمی و متوسط کلمات را نادیده می دهند. در این مسئله، ما با پیشنهاد SCDV+BERT(ctxd) یک نمایش ساده و تاثیر غیر نظارت\u200cکننده\u200cای درباره\u200cی این مسئله را حل می\u200cکنیم که با توجه به عنوان حس نامبیگو-tion با دستور نرم کلاستر SCDV متصل شده BERT (Devlin et al., 2019) را ترکیب می\u200cکند. ما نشان می دهیم که وسیله\u200cهای ما در مجموعه\u200cهای بسیاری از اطلاعات\u200cشناسی\u200cهای اولیه\u200cی SCDV، BERT پیش\u200cآموزش، و چند تن دیگر را در مجموعه\u200cهای مختلف انجام می\u200cدهند. ویلسو نشان می\u200cدهد که درگیری\u200cهایمان بر روی کارهای دیگر موثر است، مثل مشابه\u200cای که مشابه\u200cای و جمله\u200cها دارند. علاوه بر این، ما نشان می دهیم که SCDV+BERT(ctxd) بیشتر از اجرای صفحه صفحه\u200cهای صفحه\u200cای که داده\u200cهای محدودیت دارند و فقط چند مثال شلیک\u200cهای مختلف دارند.', 'de': 'Mehrere NLP-Aufgaben erfordern die effektive Repräsentation von Textdokumenten. Arora et al.,2017 zeigen, dass einfache gewichtete Abwertung von Wortvektoren häufig neuronale Modelle übertrifft. SCDV (Mekala et al., 2017)erweitert dies weiter von Sätzen zu Dokumenten, indem weiche und spärliche Clustering über vorberechnete Wortvektoren verwendet werden. Allerdings ignorieren beide Techniken den polysemischen und kontextuellen Charakter von Wörtern. In diesem Artikel behandeln wir dieses Problem, indem wir SCDV+BERT(ctxd) vorschlagen, eine einfache und effektive nicht-überwachte Darstellung, die kontextualisierte BERT (Devlin et al., 2019) basierte Einbettung für Wortsinn-Disambigua mit SCDV Soft Clustering Ansatz kombiniert. Wir zeigen, dass unsere Einbettungen bei vielen Klassifikationsdatensätzen die ursprünglichen SCDV, BERT-Vortrainings und mehrere andere Basislinien übertreffen. Wir demonstrieren unsere Einbettungseffektivität auch bei anderen Aufgaben wie Concept Matching und Satzähnlichkeit. Darüber hinaus zeigen wir, dass SCDV+BERT(ctxd) die Feinabstimmung von BERT und verschiedene Einbettungsapplikationen in Szenarien mit begrenzten Daten und nur wenigen Shots übertrifft.', 'tr': "NLP birnäçe zada metin senediň täzeliklerini ýene-täzeliklerini gerek. 2017-nji Arora et al.2017'de basit ağırlı vektörler kelimelerinin çoğunlukla etkisiz modellerinden daha yüksek olduğunu gösteriyor. SCDV (Mekala et al., 2017)further extends this from sentence to docu-ments by employing soft and sparse cluster-ing over pre-computed word vectors. Nähili bolsa, her iki teknikiň polisemiýa we konsekst sözlerin karakterini görmezden gelenok. Bu sahypada, biz bu meseleyi SCDV+BERT(ctxd) teklif eden basit ve etkili bir şekilde gözetlememiş bir temsil çözümleri birleştirerek, WIRT (Devlin et al., 2019) söz duygu üçin birleştirilen baz sözlerimizi çözerek, SCDV yumuşak klusterin yaklaşımı ile birleştirmekten emin bir şekilde çözeriz. Biziň düzümlerimiz origi nal SCDV, BERT öňünden otlydygyny we köp taýýarlama düzümlerinde birnäçe taýýarlama netijesinde çykýandygyny görkez. Wasp biziň daşarymyzyň içinde başga işlerde etkinlik gabdalygymyzy, meňzeş we sözleriň meňzeşligini görkez. Munuň üçin, SCDV+BERT(ctxd) BERT'yň üstüne çykyşynyň üstini görkez we senaryoýla çykyş berüvleri bilen diňe birnäçe eserler bar.", 'af': 'Verskeie NLP-opdragte benodig die effektief herstelling van teksdokumente. Arora et al.,2017 wys dat eenvoudige gewigte stoor-aging van woordevektore dikwels uitgevoerde sneuringsmodelle. SCDV (Mekala et al., 2017) verder verbeter dit van setnings na docu-ments deur sagte en sparse cluster-ing te gebruik oor voorafreken woord vektore. Hoe-ooit, beide teknike ignoreer die poliseme en contextual karakter van woorde. In hierdie spaper, ons adres hierdie probleem deur die voorstel van SCDV+BERT( ctxd), â\x80\x99n eenvoudig en effektief ongesuperviseerde voorstelling wat con- textualiseerde BERT (Devlin et al., 2019) gebasewoord ingesluit vir woord sin disambigua- tion met SCDV sagte clustering toegang. Ons wys dat ons inbêding uitvoer oorspronklike SCDV, voorstrein BERT, en verskeie ander besonderhede op baie klassifikasie datastelle. Wealso wys ons inbêdings effektief-belangheid op ander taak, soos konsepte ooreenstemmende en setgelykheid. In addition, we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data and only few shots examples.', 'id': 'Several NLP tasks need the effective repre-sentation of text documents. Arora et al.,2017 menunjukkan bahwa keseluruhan pemasaran berat sederhana vektor kata sering melebihi model sneural. SCDV (Mekala et al., 2017) melanjutkan ini dari kalimat ke dokumen dengan menggunakan berkumpul lembut dan ringan atas vektor kata pre-komputasi. How-ever, both techniques ignore the polysemyand contextual character of words. In thispaper, we address this issue by proposingSCDV+BERT(ctxd), a simple and effective un-supervised representation that combines con-textualized BERT (Devlin et al., 2019) basedword embedding for word sense disambigua-tion with SCDV soft clustering approach.  Weshow that our embeddings outperform origi-nal SCDV, pre-train BERT, and several otherbaselines on many classification datasets.  Wealso menunjukkan kemampuan kita pada tugas lain, seperti konsep match-ing dan kalimat yang sama. In addition,we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data andonly few shots examples.', 'sq': 'Disa detyra të NLP-së kanë nevojë për përfaqësim të efektshëm të dokumenteve teksti. Arora et al.,2017 demonstrojnë se mesatarja e peshuar e mesatare e vektorëve të fjalës shpesh kalon modelet neuronale. SCDV (Mekala et al., 2017)e zgjeron më tej këtë nga fjalët në dokumente duke përdorur grupe të buta dhe të pakta mbi vektorët e fjalëve të parallogaritur. How-ever, both techniques ignore the polysemyand contextual character of words. Në këtë spaper, ne e trajtojmë këtë çështje duke propozuar SCDV+BERT(ctxd), një përfaqësim i thjeshtë dhe efektiv pa mbikqyrur që kombinon tekstualizuar BERT (Devlin et al., 2019) të mbështetur në përfshirje për fjalë kuptimi të çambiguation me metodën e grupimit të butë SCDV. Ne tregojmë se përfshirjet tona kalojnë SCDV origjinale, para trenit BERT, dhe disa baza të tjera në shumë grupe të dhënash klasifikimi. Wealso demonstrate our embeddings effective-ness on other tasks, such as concept match-ing and sentence similarity. In addition,we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data andonly few shots examples.', 'sw': 'Kazi kadhaa za NLP zinahitaji kuchukuliwa tena kwa ufanisi wa nyaraka za maandishi. Arora et al.,2017 imeonyesha kuwa rahisi ilikuwa na uzee wa wastani wa vectors wa maneno mara nyingi wakifanya mifano ya kijamii. SCDV (Mekala et al., 2017) inaongezea tena hii kutoka hukumu hadi madaktu kwa kutumia mstari mwepesi na kupunguza viungo vinavyotokea vector za maneno yaliyohesabiwa. Kwa namna gani, mbinu zote hizi zinazipuuza mhalisi na tabia za kawaida za maneno. Katika kipindi hiki, tunazungumzia suala hili kwa pendekezo la SCDV+BERT(ctxd), uwakilishi rahisi na wenye ufanisi usiotangaliwa ambao unaunganisha BERT (Devlin et al., 2019) kituo cha msingi kinachojumuisha kwa maneno yanayohusiana na mfumo wa mfumo wa ufundi wa SCDV. Weshow ambazo maeneo yetu yanaendesha SCDV ya asili ya origi, mafunzo ya kabla ya treni BERT, na mistari kadhaa ya watu kwenye seti nyingi za usambazaji. Pia tulionyesha maeneo yetu yenye ufanisi katika kazi nyingine, kama vile dhana inayofanana na hukumu inayofanana. Zaidi ya hayo, tunaonyesha kwamba SCDV+BERT(ctxd) kuonyesha usoni-tune BERT na wapiganaji mpya tofauti katika mitazamo yenye takwimu isiyo na mifano michache tu ya risasi.', 'az': 'Bir neçə NLP işləri mətn belələrinin yenidən ifadə edilməsi lazımdır. Arora et al.,2017-ci ilə, sadəcə ağırlı vektörlərin ağırlığını göstərir. SCDV (Mekala et al., 2017) bunu cümlələrdən docu-ments vasitəsilə, ön-hesaplanmış söz vektörlərinin üstündə yumuşaq və küçük cluster-ing istifadə edərək uzaqlaşdırır. Necə olaraq, hər iki tekniki polisimlə müxtəlif sözlərin karakterini görməz. Bu səbəbdə, SCDV+BERT(ctxd) təbliğ etmək üçün bu məsələni çəkirik. Bu çox basit və efektiv təhlükəsizlik edilməmiş bir göstəricisidir ki, con-textualized BERT (Devlin et al., 2019) sözləri SCDV yumuşaq clustering approach ilə birləşdirir. Biz göstəririk ki, bizim inşallarımız bir çox klasifikasiya verilən qurğularda orijinal SCDV, BERT-dən əvvəl tələb edir və bir çox başqa dəyişiklik qurğularında. Wealso bizim inşallarımızı başqa işlərdə effektiv olmağımızı göstərir, məsələlər eşitmək və cümlələr kimi. Əvvəlcə, SCDV+BERT(ctxd) müxtəlif performances BERT və müxtəlif məlumatlarla müəyyən məlumatlarda fərqli məlumatlar və yalnız bir neçə fərqli məsəllərə istifadə edirik.', 'bn': 'বেশ কয়েকটি এনএলপি কাজের লেখা ডকুমেন্টের কার্যকর পুনরায় প্রতিবেদন দরকার। আরোরা এন্ট আল, ২০১৭ প্রতিবাদ করেছে যে সাধারণত শব্দ ভেক্টরের গড় বয়সের মাধ্যমে সাধারণত উৎপাদনের মডেল। এসসিডিভি (মেকালা এন্ট ২০১৭) আরো এই বিষয়টি ডোকুর কারাদণ্ড থেকে বাড়িয়ে দিয়েছেন ডকুমেন্টের কাছ থেকে নম্রভাবে ব্যবহার করে গণনানোর আগে  যেভাবেই, দুটো প্রযুক্তিগুলো পলিসেমিয়ান এবং প্রাক্তন বাক্যের চরিত্র উপেক্ষা করে। In thispaper, we address this issue by proposingSCDV+BERT(ctxd), a simple and effective un-supervised representation that combines con-textualized BERT (Devlin et al., 2019) basedword embedding for word sense disambigua-tion with SCDV soft clustering approach.  ওয়েস্কো যে আমাদের বিভিন্ন অরিজি-নাল এসসিডিভি, প্রাক্তন ট্রেন বিবের্ট এবং অনেক বিভিন্ন গ্রাফিকেশন ডাটাসেটে বেশ কিছু বেসে আমরা অন্যান্য কাজের উপর আমাদের প্রতিযোগিতার কার্যকর প্রদর্শন করেছি, যেমন ধারণা মিল এবং শাস্তি একই রকম। এছাড়াও, আমরা দেখাচ্ছি যে SCDV+BERT (ctxd) আউটপার্সিফিন-tune BERT এবং বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন প্রোচিকের সাথে সীমিত তথ্য এবং শুধু', 'hy': 'Շատ ՆԼՊ-ի առաջադրանքներ կարիք ունեն տեքստի փաստաթղթերի արդյունավետ ներկայացումը: Arora et al.,2017 demonstrate that simple weighted aver-aging of word vectors frequently outperformsneural models.  ՍԿԴՎ (Meical et al., 2017) ավելի շատ տարածում է սա նախադասություններից դեպի փաստաթղթեր՝ օգտագործելով փափուկ և փոքր խմբավորումներ նախահաշվարկված բառերի վեկտորների վրա: Ինչևէ, երկու տեխնիկաները անտեսում են բառերի պոլիսեմիան և կոնտեքստոնալ բնույթը: Այս պայմաններում մենք լուծում ենք այս խնդիրը առաջարկելով, որ ՍԿԴՎ+ԲԵՌՏ( կկՏՔՍ), մի պարզ և արդյունավետ առանց վերահսկվող ներկայացուցիչ, որը համադրում է կոնտեքստալիզացված ԲԵՌՏ (Devin et al., 2019) բառի զգացմունքի դիզաբիգուգացիայի համար բառի դիզաբիգուգացիայի և ՍԿԴՎ Մենք ցույց ենք տալիս, որ մեր ներդրումները գերազանցում են սկզբնական ՍՔԴՎ-ը, BER-ը նախապատրաստման և բազմաթիվ այլ հիմքերը բազմաթիվ դասակարգման տվյալների համակարգերում: Վիելսոն ցույց է տալիս, որ մեր ներդրումները արդյունավետ են այլ խնդիրների վրա, ինչպիսիք են օրինակ համեմատությունը և նախադասությունների նմանությունը: In addition,we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data andonly few shots examples.', 'am': 'Several NLP tasks need the effective repre-sentation of text documents. Arora et al.,2017 demonstrate that simple weighted aver-aging of word vectors frequently outperformsneural models.  SCDV (Mekala et 2017) ይህንን ከፍርድ ወደ ዶኪዎች አካባቢዎች እና ቀላል እና መቆጣጠር በቁጥጥር የተቆጠሩ ቃላት vectors በመቀጠል ይዘረጋል፡፡ እንዴት እንደሆነ፣ ሁለቱ ቴክኖክቶች የፖሊሲም እና የቃላትን ሁኔታ ጥያቄ ይተዋሉ፡፡ በቴስፓፓር፣ SCDV+BERT(ctxd) በተለየ እናስቀናለን፡፡ የኦሪጂ-የ SCDV፣ የብኤርቴን አስቀድሞ እና በብዙ መግለጫ ዳታዎች ላይ ብዙ ሌሎችን መደገፊያዎች እንዲያሳየው ምዕራብ ነው፡፡ አካባቢነታችንን ለሌሎች ስራዎችን በጥያቄ እና የሥርዓት ብጤት እና ማሳየትን አሳይተናል፡፡ በተጨማሪም፣ SCDV+BERT (ctxd) ውጤት-tune BERT እና በተለየ ቁጥጥር ላይ-ፓርቲዎች በተለየ ዳታ እና ጥቂት ነጥቦች ምሳሌዎች ብቻ እንደሆነ እናሳየዋለን፡፡', 'cs': 'Několik úkolů NLP vyžaduje efektivní reprezentaci textových dokumentů. Arora et al.,2017 ukazují, že jednoduché vážené aver-aging slovních vektorů často překonává neurální modely. SCDV (Mekala et al., 2017)to dále rozšiřuje od vět do dokumentů pomocí měkkého a řídkého clusterování přes předem vypočítané slovní vektory. Obě techniky ovšem ignorují polyzemii a kontextový charakter slov. V této části řešíme tento problém navrhováním SCDV+BERT(ctxd), jednoduché a efektivní reprezentace bez dohledu, která kombinuje kontextualizované BERT (Devlin et al., 2019) založené na vložení slovního smyslu s přístupem měkkého shlukování SCDV. Naše vložení překonávají původní SCDV, BERT před tréninkem a několik dalších základních linek na mnoha klasifikačních datových sadách. Také demonstrujeme naši efektivitu vkládání na další úkoly, jako je například shoda konceptů a podobnost vět. Kromě toho ukazujeme, že SCDV+BERT(ctxd) překonává jemné ladění BERT a různé postupy vkládání v scénářích s omezenými daty a pouze málo příkladů snímků.', 'et': 'Mitmed uue uue tööprogrammi ülesanded vajavad tekstidokumentide tõhusat esitamist. Arora et al., 2017 näitavad, et sõnavaktorite lihtne kaalutud keskmine vananemine ületab sageli täiuslikke neuromudeleid. SCDV (Mekala jt., 2017) laiendab seda veelgi lausetelt dokumentidele, kasutades pehmet ja hõredat klastrit eelnevalt arvutatud sõnavaktorite suhtes. Kuid mõlemad tehnikad eiravad sõnade polüseemiat ja kontekstilist iseloomu. Selles osas käsitleme seda probleemi, pakkudes välja SCDV+BERT(ctxd), lihtsa ja tõhusa järelevalveta esinduse, mis ühendab kontekstualiseeritud BERT-i (Devlin jt., 2019) põhisõna põhisõna põhjendamise ja SCDV pehme klastrite lähenemisviisi. Näitame, et meie manustamised on paljudes klassifitseerimisandmekogumites paremad kui algsed SCDV-d, eelkoolitused BERT-d ja mitmed teised alusjooned. Samuti demonstreerime oma integreerimise tõhusust muudes ülesannetes, nagu kontseptsioonide sobitamine ja lausete sarnasus. Lisaks näitame, et SCDV+BERT(ctxd) on parem kui BERT ja erinevad manustamisprotsessid piiratud andmetega stsenaariumides ja ainult väheste võtete näidetes.', 'ca': "Diverses tasques del NLP necessiten una representació efectiva dels documents de text. Arora et al., 2017 demostren que l'envelliment mitjà ponderat dels vectors de paraules sovint supera els models neuronals. SCDV (Mekala et al., 2017)ho extreu més des de frases a documentacions utilitzant grups suaus i escassos sobre vectors de paraules precomputats. Com sigui, les dues tècniques ignoren el caràcter polisèmic i contextual de les paraules. En aquest spaper, abordem aquest tema proposant SCDV+BERT(ctxd), un a representació senzilla i efectiva sense supervisió que combina el textualitzat BERT (Devlin et al., 2019) basat en incorporació de paraules de desambiguació de sentit amb l'enfocament de clustering suau SCDV. Ens mostren que les nostres incorporacions superen el SCDV origi nal, el BERT previ al tren i diverses altres línies en molts conjunts de dades de classificació. Wealso també demostra l'eficiència de les nostres incorporacions en altres tasques, com la comparació de conceptes i la similitud de frases. In addition,we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data andonly few shots examples.", 'fi': 'Useissa uuden työohjelman tehtävissä tekstiasiakirjojen tehokasta esittämistä tarvitaan. Arora et al., 2017 osoittavat, että sanavektorien yksinkertainen painotettu keskiarvo ylittää usein suorituksen neuromallit. SCDV (Mekala et al., 2017) laajentaa tätä lauseista dokumentteihin käyttämällä pehmeää ja harvaa klusterointia ennalta laskettujen sanavektorien päälle. Kummassakin tekniikassa ei kuitenkaan oteta huomioon sanojen monimuotoista ja kontekstuaalista luonnetta. Tässä artikkelissa käsittelemme tätä ongelmaa ehdottamalla SCDV+BERT(ctxd), yksinkertaista ja tehokasta valvomatonta esitystä, jossa yhdistyvät kontekstualisoitu BERT (Devlin et al., 2019) -pohjainen upotus sanan merkityksen selventämiseksi SCDV soft klustering -lähestymistapaan. Miten upotuksemme suoriutuvat SCDV:stä, BERT:stä ja useista muista lähtökohdista monissa luokitustietoaineistoissa. Meidän on myös osoitettava upotustemme tehokkuutta muihin tehtäviin, kuten konseptien vastaavuuteen ja lauseiden samankaltaisuuteen. Lisäksi osoitamme, että SCDV+BERT(ctxd) suoriutuu BERT:n hienosäätämisestä ja erilaisista upotussovelluksista skenaarioissa, joissa on rajallista dataa ja vain muutamia otoksia.', 'bs': 'Nekoliko zadataka NLP-a je potrebno efikasno ponovno režiranje tekstskih dokumenta. Arora et al., 2017. pokazuje da je jednostavno težino održavanje vektora riječi često iznad izvornih modela. SCDV (Mekala et al., 2017) dodatno proširi to od kazne na docu-ments koristeći meke i rezervne skustere preko pre-računalnih vektora riječi. Kako god, obje tehnike ignoriraju polisemijski kontekstualni karakter riječi. U toj oblasti, riješimo ovaj problem predloženjem SCDV+BERT(ctxd), jednostavnom i efikasnom nedovoljnom predstavljanju koja kombinira kontekstualiziranu BERT (Devlin et al., 2019) baznu ploču koja se uključuje za disambigua-ciju riječi sa mekim pristupom SCDV-a. Mi pokazujemo da naše ugrađenje iznosi originalni SCDV, pre vožnje BERT i nekoliko drugih bazena na mnogim podacima klasifikacije. Wealso pokazuje naše uključenje učinkovitosti na druge zadatke, kao što su koncept odgovaranja i sličnost rečenica. Osim toga, pokazujemo da je SCDV+BERT(ctxd) nadmažena izvedba BERT-a i različite ugrađivanje povreda u scenarijima s ograničenim podacima i samo nekoliko primjera snimaka.', 'jv': 'Awak dhéwé NLP sing disimpen nggawe ngubah werak-seneng nggawe dokumen teks Aara et al. forward expans this from words to docu ments-ments by hiring software and spase cluster ing lah Nan paten, kita diwurung ngobudhakan iki dadi saben nggunakae + (BERT(ct xx) text-box-mode Wacom action-type Label', 'ha': "Kayya cikin aikin NLP, ana ƙayyade fara-ƙara wa takardar littãfi masu inganci. Arora et al.,2017 na nuna cewa yana da gwargwadon mai sauri ga sauri masu tsakanin shiryoyi na maganar ko da yawa suka sami misãlai. SCDV (Mekala et al., 2017) Kayya, duk tufãfi biyu suna ƙyãma ma ma'anar musamman da ma'anar sauri. In titopa, Munã jãyayya wannan masu al'amarin da Muke bukãtar da SCDV+BERT(ctxd), wani mai sauƙi da mai amfani da wanda bai zama mai tsaro ba, mai haɗãwa da con-text-naturated BERT (Devlin et al., 2019) bazaƙord wanda ke shigar da wa maganar sanyi desmbague-tion da SCDV zaɓallin matsayin mai ƙaranci. @ info: whatsthis Kayya, Mun nũna masu da amfani da masu akan aiki na dabam, kamar zato da suka yi daidai da maganar. Ina ƙaranci, Munã nuna SCDV+BERT(ctxd) outperformsfine-tune BERT da wasu taɓallu masu cikin tsarario da aka tsare data da kuma misãlai kaɗan kawai.", 'sk': 'Več nalog novega delovnega programa zahteva učinkovito predstavitev besedilnih dokumentov. Arora et al., 2017 dokazujejo, da preprosta ponderirana povprečna staranja besednih vektorjev pogosto presega izvedbene nevronske modele. SCDV (Mekala et al., 2017) dodatno razširja to iz stavkov na dokumente z uporabo mehkega in redkega grozdnega združevanja nad vnaprej izračunanimi besednimi vektorji. Kljub temu obe tehniki ignorirata polikemijski in kontekstualni značaj besed. V tem dokumentu obravnavamo to vprašanje s predlogom SCDV+BERT(ctxd), preproste in učinkovite nenadzorovane predstavitve, ki združuje konteksturalizirano BERT (Devlin et al., 2019) osnovno vključevanje besednega pomena z mehkim grozdjem SCDV. Kako lahko naše vdelave presegajo originalne SCDV, BERT pred vlakom in več drugih baznih podatkov o klasifikaciji. Pokazali bomo tudi učinkovitost vgradnje pri drugih nalogah, kot sta ujemanje konceptov in podobnost stavkov. Poleg tega pokažemo, da SCDV+BERT(ctxd) izboljšujejo izboljšanje BERT in različnih vdelanih aplikacij v scenarijih z omejenimi podatki in le malo primerov posnetkov.', 'he': 'מספר משימות NLP זקוקות לייצג יעיל של מסמכים טקסט. Arora et al., 2017 מראים שזקנה ממוצעת משקלת פשוטה של ווקטורים מילים לעתים קרובות יותר מודלים נוראלים. SCDV (Mekala et al., 2017) מחביר את זה יותר משפטים לדוקטורטים על ידי השימוש של קבוצות רכות ומנמכות מעל ווקטורי מילים מחשבים מראש. בכל מקרה, שתי הטכניקות מתעלמות מהפוליזמיה והאופי הקונקסטי של מילים. בספרד הזה, אנו מתייחסים לנושא הזה על ידי הצעה SCDV+BERT( ctxd), מייצג פשוט ויכולתי ללא פיקוח שמשולב את BERT (Devlin et al., 2019) המבוסס קונטקסטוליזציה למילה תחושה אנחנו מראים שהקישורים שלנו עולים מעל SCDV מקורי, BERT לפני הרכבת, וכמה קווים אחרים על קבוצות מידע מסווג רבים. ווילסו מציגים את היכולת של ההכניסות שלנו למשימות אחרות, כמו התאמה של מושג וכמויות משפטים. בנוסף, אנו מראים שSCDV+BERT(ctxd) יוצאים מהביצועים של BERT מסוים ומערכות אפ-אפ שונות בתסריטים עם נתונים מוגבלים ורק כמה דוגמאות צילומים.', 'bo': 'NLP ལ་བྱ་འགུལ་མང་པོ་ཞིག་ནི་ཡིག་གེ་ཡིག་གེ་ཡིག་གེ་ཚིག་ཡིག་ཆ་བསྐྱར་དུ་གཏོང་དགོས་པ Arora et al,2017 ཡིས་སྤྱི་ཚོགས་ཀྱི་རྒྱ་ཆེ་མཐོང་ཚད་ལྷག་པའི་གཞན་པ་ཚོའི་ནང་གི་མཐའ་འཁོར་གྱི་དཔེ་དབྱིབས་བཀོད་ཡོད། SCDV (Mekala et al., 2017)further extends this from sentences to docu-ments by employing soft and sparse cluster-ing over pre-computed word vectors. གང་ལྟར་ཞིག་ཡིན་ན། ཐབས་ལམ་གཉིས་ཀྱིས་སྔོན་ཅིག་དང་འཕགས་རིས་ཡི་གེ་སྣང་མེད་བསྐྱུར་བྱེད། In thispaper, we address this issue by proposingSCDV+BERT(ctxd), a simple and effective un-supervised representation that combines con-textualized BERT (Devlin et al., 2019) basedword embedding for word sense disambigua-tion with SCDV soft clustering approach. Weshow that our embeddings outperform origi-nal SCDV, pre-train BERT, and several otherbaselines on many classification datasets. Wealso་གིས་ང་ཚོའི་ནང་དུ་ཡོད་པའི་འཇུག་སྣོད་ནི་ལས་འཕགས་པ་གཞན་དང་མཉམ་དུ་བཀྲམ་སྟོན་ཐུབ། In addition, we show that SCDV+BERT(ctxd) outperformsfine-tune BERT and different embedding ap-proaches in scenarios with limited data and only few shots examples.'}
