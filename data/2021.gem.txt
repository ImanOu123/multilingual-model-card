{'en': 'Semantic Similarity Based Evaluation for Abstractive News Summarization', 'ar': 'التقييم المعتمد على التشابه الدلالي لتلخيص الأخبار التجريدية', 'es': 'Evaluación semántica basada en similitud para el resumen abstractivo de noticias', 'pt': 'Avaliação baseada em similaridade semântica para resumo abstrato de notícias', 'zh': '盖语义相似性之抽象新闻摘要论也', 'fr': 'Évaluation basée sur la similitude sémantique pour la synthèse abstraite des actualités', 'ja': '抽象的なニュースの要約の意味論的類似性に基づく評価', 'ga': 'Meastóireacht Shéimeantach Bunaithe ar Chosúlacht le haghaidh Achoimre ar an Nuacht Teibí', 'ru': 'Оценка семантического сходства для абстрактного обобщения новостей', 'hi': 'शब्दार्थ समानता अमूर्त समाचार Summarization के लिए आधारित मूल्यांकन', 'hu': 'Szemantikus hasonlóság alapú értékelés absztrakt hírek összefoglalásához', 'el': 'Αξιολόγηση με βάση τη σημασιολογική ομοιότητα για αφηρημένη περίληψη ειδήσεων', 'ka': 'Semantic Similarity Based Evaluation for Abstractive News Summarization', 'mk': 'Semantic Similarity Based Evaluation for Abstractive News Summarization', 'it': 'Valutazione basata sulla somiglianza semantica per la sintesi delle notizie astratte', 'kk': 'Абстрактивтік жаңалық тұжырымдамасының семантикалық ұқсастығының негізінде оқу', 'ms': 'Semantic Similarity Based Evaluation for Abstractive News Summarization', 'ml': 'Semantic Similarity Based Evaluation for Abstractive News Summarization', 'lt': 'Semantinis panašumo vertinimas abstraktyvioms žinioms apibendrinti', 'pl': 'Ocena oparta na podobieństwie semantycznym dla streszczenia wiadomości', 'mt': 'Evalwazzjoni Ibbażata fuq Similarità Semantika għas-Sommarju tal-Aħbarijiet Abstrattivi', 'mn': 'Экстрактив шинжлэх ухаан дээр төстэй төстэй дүгнэлт', 'ro': 'Evaluare bazată pe similitudine semantică pentru rezumarea știrilor abstracte', 'sr': 'Semantička sličnost osnovana na osnovu procjene za sažetak abstraktivnih novina', 'si': 'සෙමැන්ටික් සමීලතාවක් ආධාරිත විශ්ලේෂණය අවශ්\u200dය', 'sv': 'Semantisk liklikhetsbaserad utvärdering för abstrakt nyhetssammanfattning', 'no': 'Name', 'so': 'Heeganka u dhexeeya', 'ta': 'செய்தி சுருக்கம்', 'ur': 'سیمنٹی سیمالیٹی بنیاد آب تراکٹی نیویس جماریزو کے لئے ارزش', 'uz': 'Comment', 'vi': 'Phân tích tin tức trừu tượng', 'da': 'Semantisk lighedsbaseret evaluering til abstrakt nyhedsopsummering', 'bg': 'Оценка на семантична прилика за обобщаване на абстрактни новини', 'nl': 'Semantische gelijkenis gebaseerde evaluatie voor abstracte samenvatting van nieuws', 'de': 'Semantic Similarity Based Evaluation for Abstractive News Summarisation', 'hr': 'Semantička sličnost temeljena procjena za sažetak apstraktivnih vijesti', 'sw': 'Uchunguzi wa Habari za Kujitenga', 'id': 'Evaluasi Berdasarkan Kesamaan Semantik untuk Penapisan Berita Abstraktif', 'ko': '의미의 유사도를 바탕으로 하는 추상적인 뉴스 요약 평가', 'tr': 'Semantik Ma첵yklyk Ta첵첵arlama Ta첵첵arlama', 'af': 'Semantiese gelykenis Basiese Evaluering vir Abstractive News Summarization', 'fa': 'ارزیابی شبیه\u200cسازی\u200cهای سیماتیک بر اساس ارزیابی برای جمع\u200cآوری خبرهای ابزار', 'sq': 'Vlerësimi i bazuar në ngjashmëri Semantike për përmbledhjen e lajmeve abstraktive', 'az': 'Abstraktiv Haqq Toplaşdırması üçün Semantik Similaritə Temel Qıymet', 'hy': 'Սեմանտիկ նմանության հիմնված գնահատումը վերացական նորությունների համառոտագրման համար', 'bn': 'সেম্যান্টিক সংবাদ সংক্ষেপের জন্য ভিত্তিক মূল্যায়ন', 'bs': 'Semantička sličnost Na temelju procjene za rezervaciju abstraktivnih vijesti', 'ca': 'Evaluació basada en la Similaritat Semàtica per a una resumen abstract de notícies', 'cs': 'Hodnocení založené na sémantické podobnosti pro abstraktivní shrnutí novinek', 'am': 'የውይይት መድረክ', 'et': 'Semantiline sarnasus põhinev hindamine abstraktsete uudiste kokkuvõtteks', 'fi': 'Semanttinen samankaltaisuus perustuu arviointiin tiivistettyjen uutisten yhteenvetoon', 'jv': 'semanti Similrity', 'sk': 'Evaluacija na podlagi semantične podobnosti za povzetek povzetkov novic', 'ha': 'KCharselect unicode block name', 'he': 'הערכה מבוססת על דמיון סמנטי לסומריזציה חדשות משפחתית', 'bo': 'Semantic Similarity Based Evaluation for Abstractive News Summarization'}
{'en': 'ROUGE is a widely used evaluation metric in text summarization. However, it is not suitable for the evaluation of abstractive summarization systems as it relies on lexical overlap between the gold standard and the generated summaries. This limitation becomes more apparent for agglutinative languages with very large vocabularies and high type / token ratios. In this paper, we present semantic similarity models for Turkish and apply them as evaluation metrics for an abstractive summarization task. To achieve this, we translated the English STSb dataset into Turkish and presented the first semantic textual similarity dataset for Turkish as well. We showed that our best similarity models have better alignment with average human judgments compared to ROUGE in both Pearson and Spearman correlations.', 'fr': "ROUGE est une métrique d'évaluation largement utilisée dans la synthèse de texte. Cependant, il n'est pas adapté à l'évaluation des systèmes de synthèse abstraite car il repose sur le chevauchement lexical entre le standard de référence et les résumés générés. Cette limitation devient plus évidente pour les langues agglutinantes avec de très grands vocabulaires et des ratios type/jeton élevés. Dans cet article, nous présentons des modèles de similarité sémantique pour le turc et les appliquons comme mesures d'évaluation pour une tâche de synthèse abstraite. Pour ce faire, nous avons traduit le jeu de données StSB anglais en turc et présenté le premier jeu de données de similarité textuelle sémantique pour le turc également. Nous avons montré que nos meilleurs modèles de similarité s'alignent mieux avec les jugements humains moyens que ROUGE dans les corrélations de Pearson et de Spearman.", 'es': 'ROUGE es una métrica de evaluación ampliamente utilizada en el resumen de textos. Sin embargo, no es adecuado para la evaluación de sistemas de resumen abstractivo, ya que se basa en la superposición léxica entre el patrón oro y los resúmenes generados. Esta limitación se hace más evidente para los lenguajes aglutinantes con vocabularios muy amplios y altas proporciones tipo/token. En este artículo, presentamos modelos de similitud semántica para el turco y los aplicamos como métricas de evaluación para una tarea de resumen abstractivo. Para lograr esto, tradujimos el conjunto de datos StSB en inglés al turco y presentamos también el primer conjunto de datos de similitud textual semántica para el turco. Demostramos que nuestros mejores modelos de similitud se alinean mejor con los juicios humanos promedio en comparación con ROUGE en las correlaciones de Pearson y Spearman.', 'zh': 'ROUGE 者,文本摘要博用之评指标。 然不宜评估抽象摘要系统,盖赖黄金之格,成摘要之词汇重叠也。 有大词汇量高/比率之言,其制益明。 于本文中,土耳其语语义相似性模样,以为抽象摘要任指标。 以英语STSb数据集翻译成土耳其语,首土耳其语语语义文本相似性数集。 吾见PEarson、Spearman相关性之ROUGE,吾之至善相似性与平人决一致性。', 'hi': 'रूज पाठ सारांश में एक व्यापक रूप से उपयोग किया जाने वाला मूल्यांकन मीट्रिक है। हालांकि, यह अमूर्त सारांशीकरण प्रणालियों के मूल्यांकन के लिए उपयुक्त नहीं है क्योंकि यह सोने के मानक और उत्पन्न सारांश के बीच लेक्सिकल ओवरलैप पर निर्भर करता है। यह सीमा बहुत बड़ी शब्दावली और उच्च प्रकार / टोकन अनुपात के साथ agglutinative भाषाओं के लिए और अधिक स्पष्ट हो जाता है। इस पेपर में, हम तुर्की के लिए शब्दार्थ समानता मॉडल प्रस्तुत करते हैं और उन्हें एक अमूर्त सारांशीकरण कार्य के लिए मूल्यांकन मीट्रिक के रूप में लागू करते हैं। इसे प्राप्त करने के लिए, हमने अंग्रेजी एसटीएसबी डेटासेट का तुर्की में अनुवाद किया और तुर्की के लिए पहला शब्दार्थ पाठ्य समानता डेटासेट भी प्रस्तुत किया। हमने दिखाया कि हमारे सबसे अच्छे समानता मॉडल में पियर्सन और स्पीयरमैन सहसंबंध दोनों में रूज की तुलना में औसत मानव निर्णय के साथ बेहतर संरेखण है।', 'pt': 'ROUGE é uma métrica de avaliação amplamente utilizada na sumarização de texto. No entanto, não é adequado para a avaliação de sistemas de sumarização abstrativos, pois depende da sobreposição lexical entre o padrão-ouro e os resumos gerados. Essa limitação se torna mais aparente para linguagens aglutinativas com vocabulários muito grandes e altas proporções de tipo/token. Neste artigo, apresentamos modelos de similaridade semântica para turco e os aplicamos como métricas de avaliação para uma tarefa de sumarização abstrativa. Para conseguir isso, traduzimos o conjunto de dados STSb em inglês para o turco e apresentamos o primeiro conjunto de dados de similaridade textual semântica para o turco também. Mostramos que nossos melhores modelos de similaridade têm melhor alinhamento com julgamentos humanos médios em comparação com ROUGE nas correlações de Pearson e Spearman.', 'ar': 'ROUGE هو مقياس تقييم يستخدم على نطاق واسع في تلخيص النص. ومع ذلك ، فهي غير مناسبة لتقييم أنظمة التلخيص التجريدي لأنها تعتمد على التداخل المعجمي بين المعيار الذهبي والملخصات الناتجة. يصبح هذا التحديد أكثر وضوحًا للغات التراصية ذات المفردات الكبيرة جدًا ونسب النوع / الرمز المميز. في هذه الورقة ، نقدم نماذج تشابه دلالي للغة التركية ونطبقها كمقاييس تقييم لمهمة تلخيص تجريدي. لتحقيق ذلك ، قمنا بترجمة مجموعة بيانات STSb الإنجليزية إلى التركية وقدمنا أول مجموعة بيانات تشابه نصي دلالي للغة التركية أيضًا. لقد أظهرنا أن أفضل نماذج التشابه لدينا تتمتع بمحاذاة أفضل مع متوسط الأحكام البشرية مقارنةً بـ ROUGE في ارتباطات بيرسون وسبيرمان.', 'ga': 'Is méadrach meastóireachta é ROUGE a úsáidtear go forleathan in achoimriú téacs. Níl sé oiriúnach, áfach, chun córais achoimrithe teibí a mheas mar go mbraitheann sé ar fhorluí foclóireachta idir an caighdeán óir agus na hachoimrí ginte. Éiríonn an teorannú seo níos soiléire do theangacha agglutinative a bhfuil stór focal an-mhór agus cóimheasa ard clóscríofa/chomharthaí. Sa pháipéar seo, cuirimid i láthair múnlaí cosúlachta shéimeantacha don Tuircis agus cuirimid i bhfeidhm iad mar mhéadracht mheastóireachta le haghaidh tasc achoimrithe teibí. Chun é seo a bhaint amach, d’aistrigh muid tacar sonraí STSb Béarla go Tuircis agus chuireamar an chéad tacar sonraí cosúlachta téacs shéimeantach i láthair don Tuircis freisin. Léirigh muid go bhfuil ailíniú níos fearr ag ár múnlaí cosúlachta is fearr le breithiúnais meán an duine i gcomparáid le ROUGE i gcomhghaolta Pearson agus Spearman araon.', 'ja': 'ルージュ(ROUGE)は、テキストの要約において広く用いられる評価指標である。しかし、それは、ゴールドスタンダードと生成された要約との間の語彙的重複に依存しているため、抽象的な要約システムの評価には適していません。この制限は、非常に大きなボキャブラリーと高いタイプ/トークン比を有する凝集性言語に対してより明らかになります。本稿では、トルコ語の意味論的類似性モデルを提示し、抽象的な要約タスクの評価指標として適用する。これを達成するために、英語のSTSbデータセットをトルコ語に翻訳し、トルコ語のための最初のセマンティックなテキスト類似性データセットも提示しました。私たちは、ピアソンとスピアマンの相関の両方において、私たちの最高の類似性モデルが、ルージュと比較して平均的な人間の判断とより良いアラインメントを有することを示しました。', 'ru': 'ROUGE - это широко используемая оценочная метрика при обобщении текста. Тем не менее, он не подходит для оценки систем абстрактного обобщения, поскольку опирается на лексическое перекрытие между золотым стандартом и сгенерированными резюме. Это ограничение становится более очевидным для агглютинативных языков с очень большими словарями и высокими соотношениями типа/токена. В этой статье мы представляем семантические модели сходства для турецкого языка и применяем их в качестве оценочных показателей для задачи абстрактного обобщения. Для этого мы перевели английский набор данных STSb на турецкий язык и представили первый набор данных семантического текстового сходства для турецкого языка. Мы показали, что наши лучшие модели сходства имеют лучшее соответствие со средними человеческими суждениями по сравнению с Ружем в корреляциях Пирсона и Спирмена.', 'el': 'Το ROUGE είναι μια ευρέως χρησιμοποιούμενη μετρική αξιολόγησης στην περίληψη κειμένου. Ωστόσο, δεν είναι κατάλληλο για την αξιολόγηση των συστημάτων αφηρημένης σύνοψης καθώς βασίζεται στη λεξική επικάλυψη μεταξύ του χρυσού προτύπου και των παραγόμενων περιλήψεων. Αυτός ο περιορισμός γίνεται πιο εμφανής για τις συσσωρευμένες γλώσσες με πολύ μεγάλα λεξικά και υψηλές αναλογίες τύπου/σήματος. Στην παρούσα εργασία, παρουσιάζουμε πρότυπα σημασιολογικής ομοιότητας για τα τουρκικά και τα εφαρμόζουμε ως μετρήσεις αξιολόγησης για μια εργασία αφηρημένης σύνοψης. Για να επιτευχθεί αυτό, μεταφράσαμε το αγγλικό σύνολο δεδομένων στα τουρκικά και παρουσιάσαμε το πρώτο σύνολο σημασιολογικών κειμένων ομοιότητας και για τα τουρκικά. Αποδείξαμε ότι τα καλύτερα μοντέλα ομοιότητας μας έχουν καλύτερη ευθυγράμμιση με τις μέσες ανθρώπινες κρίσεις σε σύγκριση με το ROUGE και στους συσχετισμούς Pearson και Spearman.', 'hu': 'A ROUGE egy széles körben használt értékelési metrika a szövegösszefoglalásban. Azonban nem alkalmas absztraktív összefoglaló rendszerek értékelésére, mivel az aranyszabvány és az előállított összefoglalók lexikális átfedésére támaszkodik. Ez a korlátozás egyre nyilvánvalóbbá válik a nagyon nagy szókincsekkel és magas típus/token aránnyal rendelkező agglutinált nyelvek esetében. Ebben a tanulmányban bemutatjuk a török szemantikai hasonlósági modelleket és értékelési mutatóként alkalmazzuk egy absztrakt összefoglaló feladathoz. Ennek érdekében az angol STSb adatkészletet törökre fordítottuk, és bemutattuk az első szemantikus szöveghasonlósági adatkészletet törökre is. Megmutattuk, hogy a legjobb hasonlósági modelleink jobban illeszkednek az átlagos emberi ítéletekhez, mint a ROUGE mind a Pearson, mind a Spearman korrelációban.', 'kk': 'ROUGE - мәтін тұжырымдамасында көп қолданылған мәтінді бағалау метрикалық. Бірақ бұл абстрактивті тұжырымдама жүйелерін бағалау үшін керек емес, себебі ол алтын стандарттың мен құрылған тұжырымдама арасындағы лексикалық тескеріліктеріне тәуелді. Бұл шектеу өте үлкен сөздер мен жоғары түрі/токен қасиеттері бар аглутикалық тілдер үшін көмектеседі. Бұл қағазда Түрк үшін семантикалық ұқсас үлгілерін таңдап, оларды абстрактивті тұжырымдамасының тапсырмасына бағалау метрикалық ретінде қолданамыз. Бұны жеткізу үшін ағылшын STSb деректер жиынын Түрк тіліне аударып, бірінші семантикалық мәтіндік ұқсас деректер жиынын таңдадық. Біз ең жақсы ұқсас үлгілеріміздің орташа адамдардың түсініктерімізге салыстыру үшін Пирсон және Сперман қатынасының түсініктерімізге салыстырылады.', 'ka': 'ROUGE არის ტექსტის სიმბოლოდ გამოყენებული განსაზღვრება მეტრიკა. მაგრამ, ეს არ არის საჭირო აბსტრაქტიგური სისტემის შესაბამისთვის, რადგან ის ლოქსიკალური შესაბამისთვის, როგორც აღმოქმნილი სისტემის შორის და შესაბამისთვის სისტემი ეს დაფართლება უფრო გახდება ადგლუტინატიური ენებისთვის, რომლებიც ძალიან დიდი სიტყვებულებით და მეტი ტიპი/ტოკენის რაოციებით. ამ დომენტში ჩვენ ჩვენ აბსტრაქტიური სიმპანტიკური სიმპანტიკური მოდელების გამოყენება და ისინი გამოყენება როგორც აბსტრაქტიური სიმპანტიკური დავალების მეტრი ეს მივიღეთ, ჩვენ ინგლისური STSb მონაცემების შესახებ ტექსუალური მონაცემების შესახებ ტექსუალური მონაცემების შესახებ ტექსუალური მონაცემების შესახებ რულქ ჩვენ გამოჩვენეთ, რომ ჩვენი უკეთესი სხვადასხვების მოდელები უკეთესი სხვადასხვებით ადამიანის სხვადასხვებით, რომლებიც პერჟონის და სპერმანის კორელაციაში შემდგომარებ', 'ms': 'ROUGE adalah metrik penilaian yang digunakan secara luas dalam ringkasan teks. Namun, ia tidak sesuai untuk penilaian sistem penghuraian abstraktif kerana ia bergantung pada meliputi leksik antara piawai emas dan ringkasan yang dijana. Hadangan ini menjadi lebih jelas untuk bahasa agglutinative dengan vokbulari yang sangat besar dan nisbah jenis/token tinggi. Dalam kertas ini, kami memperkenalkan model persamaan semantik untuk Turki dan melaksanakannya sebagai metrik penilaian untuk tugas ringkasan abstraktif. Untuk mencapai ini, kami menerjemahkan set data STSb Inggeris ke Turki dan memperlihatkan set data sememangan teks semantik pertama untuk Turki juga. Kami menunjukkan bahawa model persamaan terbaik kita mempunyai persamaan yang lebih baik dengan penghakiman manusia rata-rata dibandingkan dengan ROUGE dalam hubungan Pearson dan Spearman.', 'it': 'ROUGE è una metrica di valutazione ampiamente utilizzata nella sintesi del testo. Tuttavia, non è adatto per la valutazione dei sistemi di sintesi astratta in quanto si basa sulla sovrapposizione lessicale tra il gold standard e i riassunti generati. Questa limitazione diventa più evidente per le lingue agglutinative con vocabolari molto grandi e rapporti tipo/token elevati. In questo articolo, presentiamo modelli di somiglianza semantica per il turco e li applichiamo come metriche di valutazione per un compito di sintesi astratta. Per raggiungere questo obiettivo, abbiamo tradotto il dataset inglese STSb in turco e presentato il primo dataset semantico di somiglianza testuale anche per il turco. Abbiamo dimostrato che i nostri migliori modelli di somiglianza hanno un migliore allineamento con i giudizi umani medi rispetto a ROUGE sia nelle correlazioni Pearson che Spearman.', 'mk': 'ROUGE е широко употребена метрика за евалуација во резултатот на текстот. Сепак, тоа не е соодветно за проценка на апстрактивните системи за резултати, бидејќи се потпира на лексикално прекривање помеѓу златниот стандард и генерираните резултати. Оваа ограничување станува поочигледна за аглутинативните јазици со многу големи речници и високи односи тип/токен. Во овој документ, претставуваме семантични модели на сличност за турските и ги применуваме како метрики на евалуација за апстрактивна задача за резултатирање. За да го постигнеме ова, го преведовме англискиот компјутер на податоци STSb на турски и го претставивме првиот семантичен компјутер на податоци за текстуална сличност и за турски. Покажавме дека нашите најдобри модели на сличност имаат подобра согласност со просечните човечки пресуди во споредба со РУГЕ во корелациите на Пирсон и Спирман.', 'lt': 'ROUGE yra plačiai naudojama vertinimo metrija teksto santraukoje. Tačiau jis netinka vertinti abstraktines santraukų sistemas, nes jis grindžiamas tekstiniu aukso standarto ir sukauptų santraukų dubliavimu. Šis apribojimas tampa labiau akivaizdus aglutinacinėms kalboms, turinčioms labai didelius žodynus ir didelį tipo ir tokeno santykį. Šiame dokumente pristatome semantinius panašumo modelius turkų kalba ir juos taikome kaip vertinimo metrijas abstrakčiai apibendrinti užduotį. Norėdami tai pasiekti, perskaičiavome anglų STSb duomenų rinkinį į turkų kalbą ir pristatėme pirmąjį semantinio tekstinio panašumo duomenų rinkinį ir turkų kalba. Mes parodėme, kad mūsų geriausi panašumo modeliai geriau atitinka vidutinius žmogaus sprendimus, palyginti su ROUGE tiek Pearson, tiek Spearman koreliacijose.', 'mn': 'ROUGE бол текст дугаарлалт дээр шинэ хэрэглэгдсэн дүгнэлтийн метрик юм. Гэвч энэ нь алтын стандарт болон үүсгэсэн жишээний хоорондын лексикийн давхарлаас хамаарч байгаа абстрактив жишээлтэй системийн үнэлгээнд хэрэгтэй биш. Энэ хязгаар маш том үг болон өндөр төрлийн/тайван харьцаатай аглуутайн хэлний хувьд илүү ойлгомжтой болдог. Энэ цаасан дээр бид Турк хүмүүст semantic similarity загварыг тайлбарлаж, тэднийг abstractive summarization task-д үнэлэх метрик гэж ашиглаж байна. Үүнийг хүртэхийн тулд бид Англи хэлний STSb өгөгдлийн санг Турк рүү орчуулж, түүний хувьд анхны semantic textual similarity өгөгдлийн санг илтгэсэн. Бид хамгийн шилдэг төстэй загваруудыг Персон болон Спеарманын холбоотой ROUGE-тай харьцуулахад дундаж хүн төрөлхтний шүүмжүүдтэй илүү тохиромжтой гэж үзсэн.', 'pl': 'ROUGE jest szeroko stosowanym wskaźnikiem oceny w podsumowaniu tekstu. Nie nadaje się jednak do oceny abstrakcyjnych systemów podsumowania, ponieważ opiera się on na leksykalnym nakładaniu się między złotym standardem a generowanymi podsumowaniami. Ograniczenie to staje się bardziej widoczne w przypadku języków aglutynatywnych o bardzo dużych słownikach i wysokich proporcjach typu/token. W niniejszym artykule przedstawiamy modele semantycznego podobieństwa dla tureckiego i stosujemy je jako wskaźniki oceny do abstrakcyjnego podsumowania. Aby to osiągnąć, przetłumaczyliśmy angielski zestaw danych STSb na język turecki i zaprezentowaliśmy pierwszy semantyczny zestaw danych tekstowych również dla tureckiego. Wykazaliśmy, że nasze najlepsze modele podobieństwa mają lepsze dopasowanie do przeciętnych osądów ludzkich w porównaniu do ROUGE zarówno w korelacjach Pearsona, jak i Spearmana.', 'no': 'Constellation name (optional) Det er imidlertid ikkje passande for evaluering av abstraktive samanseringssystemer, sidan det dependerer på leksisk overlapping mellom gullstandarda og dei genererte samanseringane. Denne grensen blir meir synleg for agglutiv språk med veldig stor ordlister og høg type/token-forholdet. I denne papiret presenterer vi semantiske similaritetsmodeller for tyrkisk og bruker dei som evalueringsmetrikar for ein abstraktiv samandringsoppgåve. For å oppnå dette, vert vi omsett engelske STSb-datasettet til tyrkisk og presentert den første semantiske tekstulikhetsdatasettet for tyrkisk også. Vi viste at våre beste similaritetsmodeller har bedre innstillingar med gjennomsnittlige menneske sprøytebruk sammenlignet med ROUGE i både Pearson og Spearman-korrelasjonar.', 'ml': 'ടെക്സ്റ്റ് ചുരുക്കം ചെയ്യുന്നതില്\u200d റൂജ് വിശാലമായി ഉപയോഗിക്കുന്ന മെട്രിക്കാണ്. എങ്കിലും സ്വര്\u200dണ്ണസ്ഥാനത്തിനും ജനിപ്പിക്കപ്പെട്ട വേളകള്\u200dക്കും തമ്മിലുള്ള ലെക്സിക്കല്\u200d മൂടുതല്\u200d ആശ്രയിക്കുന്നതുകൊണ്ട് അബ്രാക് ഗ്ലൂട്ടിനേറ്റീവ് ഭാഷകള്\u200dക്കായി ഈ പരിധിയില്\u200d വളരെ വലിയ വാക്കുകളും ഉയര്\u200dന്ന തരത്തിലുള്ള വിഭവങ്ങളുമായി കൂടുതല്\u200d  ഈ പത്രത്തില്\u200d ഞങ്ങള്\u200d തുര്\u200dക്കിക്ക് സെമാന്റിക്ക് തുല്\u200dക്കീഷിന്റെ സാമ്പത്തികമായ മോഡലുകള്\u200d കൊണ്ടുവരുന്നു. അതിനെ വിലാസങ്ങള ഇത് പ്രാപിക്കാന്\u200d, ഞങ്ങള്\u200d ഇംഗ്ലീഷ് STSb ഡേറ്റാസെറ്റ് തുര്\u200dക്കിക്കിലേക്ക് പരിഭാഷപ്പെടുത്തി തുര്\u200dക്കിക്ക് ആദ്യത് We showed that our best similarity models have better alignment with average human judgments compared to ROUGE in both Pearson and Spearman correlations.', 'ro': 'ROUGE este o metrică de evaluare utilizată pe scară largă în rezumarea textelor. Cu toate acestea, nu este potrivit pentru evaluarea sistemelor de sintetizare abstractivă, deoarece se bazează pe suprapunerea lexicală dintre standardul aur și rezumatele generate. Această limitare devine mai evidentă pentru limbile aglutinative cu vocabulare foarte mari și raporturi tip/token ridicate. În această lucrare, prezentăm modele de similitudine semantică pentru limba turcă și le aplicăm ca măsurători de evaluare pentru o sarcină de rezumare abstractivă. Pentru a realiza acest lucru, am tradus setul de date în limba engleză STSb în limba turcă și am prezentat primul set de date semantice de similitudine textuală și pentru limba turcă. Am arătat că cele mai bune modele de similitudine ale noastre au o aliniere mai bună cu judecățile medii umane comparativ cu ROUGE atât în corelațiile Pearson cât și Spearman.', 'so': 'ROUGE waa mid aad u isticmaalaya qiimerida metric ku qoran qoraalka. Si kastaba ha ahaatee uma habboona in lagu qiimeeyo nidaamka jimicsiga ah, sababtoo ah waxay ku xiran tahay isku xiran dahab ah oo u dhexeeya calaamadda dahabka iyo xagaaga soo baxay. Xuduudahan waxay si ka muuqataa luuqadaha afka hooyo oo aad u weyn iyo qeyb aad u dheer/calaamad. Warqadan waxaan Turkish ugu soo bandhignaa tusaalooyin siman oo kale, waxaana u codsanaynaa qiimeynta metric in lagu sameeyo shaqo jimicsi ah. Si aan taas u gaadhno ayaan turjumnay macluumaadka afka Ingiriiska STSb ee Turki ugu horeeyay oo u soo bandhignay macluumaadkii qoraalka ee isugu eg ee Turkish. Waxan tusnay in qaababkayaga ugu wanaagsan ay leeyihiin isbedelka si fiican u dhig xukummada dadka oo la barbardhigay ROUGE labada Pearson iyo Spearman.', 'sv': 'ROUGE är ett allmänt använt utvärderingsmaterial i textsammanfattning. Den är dock inte lämplig för utvärdering av abstrakta sammanfattningssystem eftersom den bygger på lexikal överlappning mellan guldstandarden och de genererade sammanfattningarna. Denna begränsning blir mer uppenbar för agglutinerande språk med mycket stora vokabulärer och höga typ/token-förhållanden. I denna uppsats presenterar vi semantiska likhetsmodeller för turkiska och tillämpar dem som utvärderingsmetoder för en abstraktiv sammanfattningsuppgift. För att uppnå detta översatte vi den engelska STSb-datauppsättningen till turkiska och presenterade den första semantiska textliknande datauppsättningen för turkiska också. Vi visade att våra bästa likhetsmodeller har bättre anpassning till genomsnittliga mänskliga bedömningar jämfört med ROUGE i både Pearson och Spearman korrelationer.', 'ta': 'உரை சுருக்கத்தில் ROUGE ஒரு விரிவாக பயன்படுத்தப்பட்ட மதிப்பின் மெட்ரிக். எனினும், இது செயல்படுத்தப்பட்ட சுருக்கும் அமைப்புகளை evaluation இது பொருத்தமானது இல்லை ஏனெனில் அது தங்கத்தின் நிலைமையான மூடுதல் மற்றும் உருவா மிகப்பெரிய சொல்வளங்கள் மற்றும் உயர்ந்த வகை/குறியீட்டு விகிதத்துடன் agglutinative மொழிகளுக்கு இந்த எல்லைப்பாடுகள்  இந்த காக்கியத்தில், நாம் துருக்கிக்கான பாதிப்பு ஒப்பிடும் மாதிரிகளை கொடுக்கிறோம் மற்றும் அதை மதிப்பிட மெட்ரிக்கள இதை நாங்கள் பெறுவதற்கு, நாங்கள் ஆங்கிலத்தின் STSb தரவுத்தளத்தை துருக்கியில் மொழிபெயர்ப்போம் மற்றும் துருக்கிக்கு மு நாங்கள் எங்கள் சிறந்த ஒப்பு மாதிரிகள் சராசரி மனித தீர்ப்புகளுடன் சிறந்த ஒழுங்குப்படுத்தும் என்பதை காண்பித்தோம் பீர்சன் மற்', 'sr': 'ROUGE je široko korištena metrika procjene u sažetku teksta. Međutim, nije odgovarajuće za procjenu abstraktivnih sažetačkih sustava jer se oslanja na leksičko preklapanje između zlatnog standarda i proizvedenih sažetaka. Ova ograničenja postaje očiglednija za agglutivne jezike sa veoma velikim rečenicama i visokim odnosima tipa/tokena. U ovom papiru predstavljamo semantičke modele sličnosti Turskom i primjenjujemo ih kao mjere procjene za zadatak abstraktivne sažetke. Da bi to postigli, prevodili smo i angleski set podataka STSb na tursku i predstavili prvu semantičku setu podataka sličnosti tekstualnosti i za tursku. Pokazali smo da naši najbolji modeli sličnosti imaju bolje poravnanje sa prosječnim ljudskim osuđivanjima u usporedbi sa ROUGE u odnosima Pearsona i Spearmana.', 'mt': 'ROUGE hija metrika ta’ evalwazzjoni użata ħafna fis-sommarju tat-test. Madankollu, mhuwiex xieraq għall-evalwazzjoni tas-sistemi ta’ sommarju astrattiv peress li jiddependi fuq sovrappożizzjoni lexikali bejn l-istandard tad-deheb u s-sommarji ġġenerati. Din il-limitazzjoni ssir aktar evidenti għal lingwi agglutinattivi b’vokabulariji kbar ħafna u proporzjonijiet ta’ tip/token għoljin. F’dan id-dokument, nippreżentaw mudelli semantiċi ta’ similarità għat-Turkiż u nagħmluhom bħala metriċi ta’ evalwazzjoni għal kompitu ta’ sommarju astrattiv. Biex dan jinkiseb, ittraduċna s-sett tad-dejta STSb Ingliż fit-Turkiż u ppreżentajna l-ewwel sett tad-dejta semantiku ta’ similarità testwali għat-Turkiż ukoll. We showed that our best similarity models have better alignment with average human judgments compared to ROUGE in both Pearson and Spearman correlations.', 'si': 'ROUGE තමයි පාළ සංශ්\u200dයාවයේ විශාල ප්\u200dරයෝජන විශ්ලේෂණ මෙට්\u200dරිකාවක්. නමුත්, ඒක සම්පූර්ණ පද්ධතියේ අවශ්\u200dය විශ්වාස කරන්න අයුතුයි නැහැ වගේම, ඒක සුන්ද්\u200dරව්\u200dය ප්\u200dරමාණය සහ සාමාණය අතර ඉ මේ සීමාව තරම් පැහැදිලි වෙනවා ගොඩක් ලොකු භාෂාවක් සහ උත්සත් වර්ගය/ටෝකෙන් සාමාන්\u200dයය සඳහා. මේ පත්තරේ අපි තුර්කිෂ් වෙනුවෙන් සෙමැන්ටික් සාමාන්තික සාමාන්තික විදියට පෙනුම් කරනවා ඒ වගේම ඒවා අවශ්\u200dයා අපි ඉංග්\u200dරීසි STSb දත්ත සැට්ටුව ටුර්කිෂ් වලට භාවිත කරනවා ඒ වගේම පලවෙනි සැමැන්තික පාළුවන් පාළුවන් පාළුව අපි පෙන්වන්නේ අපේ හොඳම සමාන්\u200dයතාවක් මොඩේල් එක්ක හොඳ සමාන්\u200dයතාවක් තියෙනවා පියර්සන් සහ ස්පෙරමාන් සමාන්\u200dයතාවක් සම', 'ur': 'ROUGE ایک گھیرے طور پر استعمال کیا گیا ارزیابی متریک ہے متن کے ذریعے. However, it is not suitable for the evaluation of abstractive summarization systems as it relies on lexical overlap between the gold standard and the generated summaries. یہ محدودیت بہت بڑے لکھنے والی زبانوں کے لئے زیادہ ظاہر ہوجاتی ہے اور بہت بڑے لکھنے والی لکھنے والی نسبت/ٹوکنوں کے ساتھ۔ اس کاغذ میں، ہم ترکیس کے لئے سیمانٹی سیمانٹی موڈل پیش کرتے ہیں اور ان کو مضبوطی مطالعہ کے طور پر استعمال کرتے ہیں. ہم نے انگلیسی STSb ڈاٹ سٹ کو ترکیسی میں ترکیسی میں ترکیسی کی طرف ترکیسی کے لئے پہلی سیمانٹی ٹیکسٹل برابری ڈاٹ سٹ کو پیش کیا۔ ہم نے دکھایا کہ ہمارے بہترین مثال مثال مثال پررسون اور اسپررمن کی تعلقات کے مقابلہ میں عام انسان کے فیصلے سے بہتر تعلقات ہے.', 'uz': "Name Lekin, obraktiv hisoblash tizimlarini qiymatlashga yetarli emas, chunki u yuqori andoza va yaratilgan hisoblar orasidagi leksikal yuqoriga ishlatadi. Name Bu hujjatda, biz Turkish uchun semantik huddi modellarni hozirganamiz va ularni qiymatlash metriklari sifatida o'ylab tasavvur qilish uchun ishlatamiz. Buni amalga oshirish uchun biz Inglizcha STSb maʼlumotlarini Turkchaga tarjima qildik va Turkish uchun birinchi semantik texnologiya huddi maʼlumotlar tarjima qildik. We showed that our best similarity models have better alignment with average human judgments compared to ROUGE in both Pearson and Spearman correlations.", 'vi': 'ROG là một hệ thống đánh giá phổ biến trong việc tổng kết văn bản. Tuy nhiên, nó không phù hợp cho việc đánh giá các hệ thống tóm tắt trừu tượng vì nó dựa trên sự gấp bội ngôn ngữ giữa tiêu chuẩn vàng và các bản tóm tắt đã tạo ra. Giới hạn này rõ ràng hơn với ngôn ngữ đậm dội với vốn từ rất lớn và tỉ lệ cao. Trong tờ giấy này, chúng tôi đưa ra các mô hình giống nhau theo ngữ nghĩa của Thổ Nhĩ Kỳ và áp dụng chúng như đo hồ sơ cho một nhiệm vụ tổng quát trừu tượng. Để đạt được điều đó, chúng tôi đã dịch dữ liệu STSB (Anh). Chúng tôi cho thấy những mô hình tương đồng tốt nhất của chúng tôi có hiệu ứng tốt hơn với phán quyết con người trung bình so với ROG trong mối liên hệ giữa Pearson và Spearman.', 'da': 'ROUGE er en meget udbredt evalueringsmetric i tekst resuméering. Det er imidlertid ikke egnet til evaluering af abstrakte opsummeringssystemer, da det er baseret på leksikalsk overlapning mellem guldstandarden og de genererede resuméer. Denne begrænsning bliver mere tydelig for agglutinative sprog med meget store ordbøger og høje type/token-forhold. I denne artikel præsenterer vi semantiske lighedsmodeller for tyrkisk og anvender dem som evalueringsmetrics til en abstraktiv opsummeringsopgave. For at opnå dette oversatte vi det engelske STSb datasæt til tyrkisk og præsenterede det første semantiske tekstdatasæt for lighed også for tyrkisk. Vi viste, at vores bedste lighedsmodeller har bedre tilpasning til gennemsnitlige menneskelige vurderinger sammenlignet med ROUGE i både Pearson og Spearman korrelationer.', 'bg': 'ROUGE е широко използван измервателен показател в обобщаването на текста. Той обаче не е подходящ за оценка на системите за абстрактно обобщаване, тъй като разчита на лексикално припокриване между златния стандарт и генерираните резюмета. Това ограничение става по-очевидно за аглутинационните езици с много големи речници и високи съотношения тип/символ. В настоящата статия представяме семантични модели на сходство за турски език и ги прилагаме като измервателни показатели за абстрактна задача за обобщаване. За целта преведохме английския набор от данни на турски език и представихме първия семантичен текстов набор от данни за сходство и за турски език. Показахме, че нашите най-добри модели за сходство имат по-добро съответствие със средните човешки преценки в сравнение с ROUGE в корелациите на Пиърсън и Спиърман.', 'nl': "ROUGE is een veel gebruikte evaluatiemetriek in tekstsamenvatting. Het is echter niet geschikt voor de evaluatie van abstractieve samenvattingssystemen omdat het gebaseerd is op lexicale overlapping tussen de gouden standaard en de gegenereerde samenvattingen. Deze beperking wordt duidelijker voor agglutinatieve talen met zeer grote woordenschaten en hoge type/token ratio's. In dit artikel presenteren we semantische vergelijkingsmodellen voor Turks en passen ze toe als evaluatiemetrics voor een abstracte samenvattingstaak. Om dit te bereiken hebben we de Engelse STSb dataset vertaald naar het Turks en de eerste semantische tekstuele gelijkenis dataset gepresenteerd voor het Turks. We toonden aan dat onze beste gelijkenismodellen een betere afstemming hebben met gemiddelde menselijke oordelen vergeleken met ROUGE in zowel Pearson als Spearman correlaties.", 'hr': 'ROUGE je široko korišćena procjena metrika u sažetku teksta. Međutim, nije odgovarajuće za procjenu sustava abstraktivnog sažetka jer se oslanja na leksičko preklapanje između zlatnog standarda i proizvedenih sažetka. Ova ograničenja postaje očiglednija za agglutivne jezike s veoma velikim riječima i visokim odnosima tipa/tokena. U ovom papiru predstavljamo semantičke modele sličnosti Turskom i primjenjujemo ih kao mjere procjene za zadatak abstraktivne sažetke. Da bismo to postigli, prevodili smo English STSb dataset na tursku i predstavili prvu semantičku tekstualnu sličnost podataka za tursku također. Pokazali smo da naši najbolji modeli sličnosti imaju bolje poravnanje s prosječnim ljudskim osuđivanjima u usporedbi s ROUGE u odnosima Pearsona i Spearmana.', 'ko': 'ROUGE는 텍스트 요약에 널리 사용되는 평가 기준입니다.그러나 추상적 요약 시스템의 평가에는 적용되지 않는다. 왜냐하면 금 기준과 생성된 요약 사이의 어휘가 중첩되기 때문이다.이런 한계성은 어휘가 매우 크고 유형/표기 비율이 높은 접착 언어에서 더욱 뚜렷해진다.본고에서 우리는 터키어의 의미 유사성 모델을 제시하고 이를 추상적 요약 임무의 평가 지표로 삼았다.이를 위해 영문 STSb 데이터 세트를 터키어로 번역하고 첫 번째 터키어 의미 텍스트 유사성 데이터 세트를 제공했다.Pearson과 Spearman의 관련성 측면에서 ROUGE보다 우리의 가장 좋은 유사성 모델이 인간의 평균 판단에 더 부합한다는 것을 발견했다.', 'sw': 'ROUGE ni mtiririko uliotumiwa kwa kiasi kikubwa wa uchunguzi wa maandishi. Hata hivyo, si sahihi ya kutathmini mfumo wa muhtasari wa kutosha kwa sababu inategemea upepo wa lexico kati ya kiwango cha dhahabu na kipindi kilichotengenezwa. Uzuizi huu unakuwa wazi zaidi kwa lugha za asili yenye lugha kubwa na kiwango kikubwa cha aina/alama. Katika gazeti hili, tunaweka mifano ya simu kwa Uturuki na tunazitumia kama mbinu za kutathmini kwa ajili ya kazi ya muhtasari usio na maana. Ili kufikia hili, tulitafsiri takwimu za Kiingereza za za STSb zilizowekwa nchini Uturuki na kuweka taarifa za kwanza za za mfumo wa simu za kimapenzi kwa ajili ya Uturuki pia. Tumeonyesha kuwa mifano yetu bora zaidi imekuwa na usawa zaidi na maamuzi ya wastani ya binadamu ukilinganisha na UKIMWI katika mahusiano ya Pearson na Spearman.', 'id': 'ROUGE adalah metrik evaluasi yang sering digunakan dalam ringkasan teks. Namun, ini tidak cocok untuk evaluasi sistem penghasilan abstraktif karena bergantung pada overlap lexik antara standar emas dan ringkasan yang dibuat. Pembatasan ini menjadi lebih jelas untuk bahasa agglutinatif dengan kata-kata yang sangat besar dan proporsi tipe/token tinggi. Dalam kertas ini, kami mempersembahkan model semantis persamaan untuk Turki dan menerapkannya sebagai metrik evaluasi untuk tugas abstraktif penglihatan. Untuk mencapai hal ini, kami menerjemahkan set data STSb Inggris ke Turki dan mempersembahkan set data semantis tekstual pertama untuk Turki juga. Kami menunjukkan bahwa model persamaan terbaik kita memiliki lebih baik alignment dengan penilaian manusia rata-rata dibandingkan dengan ROUGE dalam korelasi Pearson dan Spearman.', 'de': 'ROUGE ist eine weit verbreitete Auswertungsmetrik in der Textzusammenfassung. Es eignet sich jedoch nicht für die Bewertung abstrakter Zusammenfassungssysteme, da es auf lexikalischer Überlappung zwischen dem Goldstandard und den generierten Zusammenfassungen beruht. Diese Einschränkung wird deutlicher für agglutinative Sprachen mit sehr großen Vokabularen und hohen Typ/Token Verhältnissen. In diesem Beitrag stellen wir semantische Ähnlichkeitsmodelle für Türkisch vor und wenden sie als Bewertungsmetriken für eine abstraktive Zusammenfassungsaufgabe an. Um dies zu erreichen, haben wir den englischen STSb Datensatz ins Türkische übersetzt und den ersten semantischen Textähnlichkeitsdatensatz auch für Türkisch vorgestellt. Wir haben gezeigt, dass unsere besten Ähnlichkeitsmodelle sowohl in Pearson- als auch in Spearman-Korrelationen besser mit den durchschnittlichen menschlichen Urteilen übereinstimmen als ROUGE.', 'tr': 'ROUGE metin holasatynda ullanýan çykyş metrikdir. Ýöne, bu abstraktiv jemgyýet sistemleriniň deňlemesi üçin ýeterli däl sebäbi altyn standartlary we üretilen toparlaryň arasynda degişlenýändir. Bu çykyşler gaty uly sözler we ýokary/token derejesi bilen aglutlandyrýan diller üçin köp görünüşer. Bu kagyzda, Türkçe üçin semantik meňzeşlik nusgalaryny görkezip we olary abstraktiv toparlama görevi deňlenmek metrikleri hökmünde uygulaýarys. Bunu başarmak üçin biz Iňlisler STSb verilerini Türkçe diline terjime etdik we ilkinji semantik metin daşlygyny Türkçe üçin sunadyk. Biz öz iň gowy nusglarymyzyň Pearson we Spearman bilen ortalama adamlaryň çözümlerini ýakynlaşdyrylmagy has gowy çözümlendirdik.', 'fa': 'ROUGE یک متریک ارزیابی وسیع استفاده شده در جمع کردن متن است. با این حال، برای ارزیابی سیستم جمع\u200cآوری abstractive مناسب نیست، زیرا بر تغییر زبانی بین استاندارد طلا و جمع\u200cآوری\u200cهای تولید شده بستگی دارد. این محدودیت برای زبانهای زیادی با کلمات بسیار بزرگ و نسبت نوع/توکین بالاتر ظاهرتر می شود. در این کاغذ، ما مدل\u200cهای شبیه\u200cسازی semantic برای ترکیه را پیشنهاد می\u200cکنیم و آنها را به عنوان متریک ارزیابی برای یک کار جمع\u200cسازی abstractive استفاده می\u200cکنیم. برای رسیدن به این، ما داده های انگلیسی STSb را به ترکیه ترکیه ترکیه ترکیب کردیم و اولین مجموعهٔ داده های شبیه\u200cانگیز متن\u200cشناسی را برای ترکیه هم پیشنهاد کردیم. ما نشان دادیم که بهترین مدل\u200cهای شبیه\u200cانگیزی\u200cمون بهتر از قضاوت\u200cهای متوسط انسان در مقایسه با ROUGE در ارتباطات Pearson و Spearman دارند.', 'af': "Constellation name (optional) Maar dit is nie geskik vir die evaluering van abstraktiewe opsomming stelsels nie, omdat dit op leksies oorvloei tussen die goue standaard en die genereerde opsomming is nie. Hierdie beperking word voorskynlik meer vir aglutinatiewe tale met baie groot woordeboeke en hoë tipe/token ratioes. In hierdie papier, laat ons semantiese gelykenigheidmodele voorsien vir Turks en toewend hulle as evalueringsmetries vir 'n abstraktiewe opsomming taak. Om dit te bereik, vertaal ons die Engelse STSb-datastel in Turkse en voorgestel ons die eerste semantiese tekenslike gelykenis-datastel ook vir Turkse. Ons het gewys dat ons beste gelykenis-modele beter gelykenis het met gemiddelde menslike oordelinge vergelyk met ROUGE in beide Pearson en Spearman-vergelykenisse.", 'am': 'የውይይት መድረክ የጽሑፍ ማቀናጃ ውስጥ በተስፋት የተጠቀመ ማረጋገጫ ነው። However, it is not suitable for the evaluation of abstractive summarization systems as it relies on lexical overlap between the gold standard and the generated summaries.  ይህ ግንኙነት ለመግለጥ ቋንቋዎች እጅግ ታላቅ የቋንቋዎች እና ከፍተኛ ዓይነት/ምልክት ክፍል ይታያል፡፡ በዚህ ፕሮግራም፣ ለቱርክ የሚመስል ምሳሌዎችን እናቀርባታለን እና ለጥያቄ ተሳካሚ ስራ ማድረግ እናደርጋቸዋለን፡፡ ይህንን ለማግኘት እንግሊዘኛ STSb ዳታተርጓል ወደ ቱርክኛ እና የመጀመሪያውን የsemantic ጽሑፍ ብጤት ዳታዎችን አቀረብን፡፡ ብጤዎቻችን በፌርሶን እና سپራማን ግንኙነት ላይ ከሮዩጂ ጋር በመተካከል የሰው ፍርድ የተሻሉ ናቸው ብለን አሳየን፡፡', 'hy': 'ROUge-ը տեքստի համառոտագրության մետրիկ է: Այնուամենայնիվ, այն համապատասխան չէ վերացական համառոտագրական համակարգերի գնահատման համար, քանի որ այն հիմնված է ոսկու ստանդարտի և ստեղծված համառոտագրությունների լեքսիկական կապվածության վրա: Այս սահմանափակումները ավելի ակնհայտ են դառնում շատ մեծ բառարաններով և բարձր տեսակ-տոկին հարաբերություններով: Այս թղթի մեջ մենք ներկայացնում ենք թուրքերի սեմանտիկ նմանության մոդելներ և կիրառում ենք դրանք որպես գնահատման մետրիկ վերացրատիվ համառոտագրման խնդրի համար: Սա հասնելու համար մենք թարգմանեցինք անգլերեն ՍՏՍԲ տվյալների համակարգը թուրքերեն և ներկայացրեցինք նաև առաջին սեմանտիկ տեքստային նմանության տվյալների համակարգը թուրքերի համար: Մենք ցույց տվեցինք, որ մեր լավագույն նմանությունների մոդելները ավելի լավ համապատասխանում են մարդկային միջին դատողությունների հետ, համեմատած Ռոյգեի հետ, ինչպես Պիրսոնի և Սփիրմանի համեմատություններում:', 'bn': 'টেক্সট সার্মিজেশনে রুজের একটি ব্যবহৃত মেট্রিক। তবে সোনার স্ট্যান্ডার এবং তৈরি সংক্ষেপের মধ্যে লেক্সিক্সিক্যাল আপের উপর নির্ভর করার জন্য এটি অস্বীকৃত সংক্রান্ত সংক্ষেপের মূল বিশাল শব্দভাণ্ডার এবং উচ্চ ধরন/চিহ্নের বৈশিষ্ট্যের মাধ্যমে এই সীমাবদ্ধতা আরও প্রকাশিত হয়ে যায়। এই কাগজটিতে আমরা তুরস্কের জন্য সেমেন্টিক সমতুল্য মডেল উপস্থাপন করি এবং তাদের মূল্যায়নের মেট্রিক হিসেবে প্রয়োগ করি এক অক্ষরিক স এটা অর্জনের জন্য আমরা ইংরেজী STSb তথ্য তুরস্কে অনুবাদ করেছি এবং তুরস্কের জন্য প্রথম সেম্পেন্টিক টেক্সচুয়ালের সমতুল্য তথ্য সং আমরা দেখিয়েছি যে আমাদের সেরা মডেলের সাথে সাধারণ মানুষের বিচারের সাথে সাধারণ মানুষের বিচারের সাথে সামান্য পেয়ার্সন এবং স', 'sq': 'ROUGE është një metrik i përdorur gjerësisht në përmbledhjen e tekstit. Megjithatë, nuk është e përshtatshme për vlerësimin e sistemeve abstraktive të përmbledhjes, pasi mbështetet në përmbledhjen lexike midis standartit të artë dhe përmbledhjeve të gjeneruara. This limitation becomes more apparent for agglutinative languages with very large vocabularies and high type/token ratios.  Në këtë letër, ne paraqesim modele semantike të ngjashmërisë për turqin dhe i aplikojmë ato si metrika vlerësimi për një detyrë abstraktive të përmbledhjes. Për të arritur këtë, ne përkthyem të dhënat angleze STSb në turk dhe paraqitëm të dhënat e para semantike të ngjashmërisë tekstuale për turqin gjithashtu. Ne treguam se modelet tona më të mira të ngjashmërisë kanë përputhje më të mirë me gjykimet mesatare njerëzore krahasuar me ROUGE në korrelacionet si Pearson ashtu edhe Spearman.', 'bs': 'ROUGE je široko korišćena procjena metrika u sažetku teksta. Međutim, nije odgovarajuće za procjenu abstraktivnih sažetačkih sustava jer se oslanja na leksičko preklapanje između zlatnog standarda i proizvedenih sažetaka. Ova ograničenja postaje očiglednija za agglutivne jezike sa veoma velikim riječima i visokim odnosima tipa/tokena. U ovom papiru predstavljamo semantičke modele sličnosti Turskom i primjenjujemo ih kao mjere procjene za zadatak abstraktivne sažetke. Da bismo to postigli, prevodili smo i Engleski set podataka STSb na tursku i predstavili prvu semantičku setu podataka sličnosti tekstualnosti i za tursku. Pokazali smo da naši najbolji modeli sličnosti imaju bolje poravnanje s prosječnim ljudskim osuđivanjima u usporedbi s ROUGE u odnosima Pearsona i Spearmana.', 'ca': "ROUGE és una mètrica d'evaluació generalitzada en la resumida del text. No obstant això, no és apropiat per a l'evaluació de sistemes abstractes de resume, perquè es basa en la sobreposió lèxica entre l'estàndard d'or i els resumes generats. Aquesta limitació esdevé més evident per a llengües aglutinatives amb vocabularis molt grans i proporcions de tipus/fitxes alts. In this paper, we present semantic similarity models for Turkish and apply them as evaluation metrics for an abstractive summarization task.  Per aconseguir això, vam traduir el conjunt de dades STSb en turc i vam presentar el primer conjunt de dades semàntiques de similitud textual també en turc. Vam demostrar que els nostres millors models de similitud tenen millor allinjament amb els judicis humans mitjans en comparació amb ROUGE en les correlacions Pearson i Spearman.", 'az': 'ROUGE mətn yığışdırmasında geniş işlədilən değerlendirmə metrikdir. Lakin bu, altın standartlarının və ürəklənmiş toplamların arasındakı leksik üstünlüyündə təvəkkül edir. Bu hədləri çox böyük sözlər və yüksək növ/token qiymətləri olan agglutinativ dillər üçün daha açıq görünür. Bu kağızda, Türkiyə üçün semantik similaritə modelləri göstəririk və onları abstraktiv toplama işləri üçün değerlendirmə metrikləri olaraq uygulayırıq. Bunu başa düşmək üçün biz İngilis STSb verilənlərini Türkiyə çevirdik və ilk semantik textual similarity verilənlərini Türkiyə də göstərdik. Biz ən yaxşı similarlıq modellərimizin Pearson və Spearman ilişkisində olan ROUGE ilə ortalama insan hökmlərimizin daha yaxşısını göstərdik.', 'et': "ROUGE on laialdaselt kasutatav hindamismeetodik teksti kokkuvõttes. Kuid see ei sobi abstraktsete kokkuvõtlussüsteemide hindamiseks, kuna see tugineb kuldstandardi ja genereeritud kokkuvõtete leksikaalsele kattumisele. See piirang muutub selgemaks aglutinaatiliste keelte puhul, millel on väga suured sõnavara ja suur tüübi/märgi suhe. Käesolevas töös esitame semantilise sarnasuse mudeleid türgi keele jaoks ja rakendame neid abstraktse kokkuvõtlusülesande hindamismeetrikutena. Selle saavutamiseks tõlkisime inglise STSb andmekogumi türgi keelde ja esitasime esimese semantilise tekstisarnasuse andmekogumi ka türgi keeles. Näitasime, et meie parimad sarnasuse mudelid on paremini kooskõlas keskmiste inimeste hinnangutega võrreldes ROUGE'iga nii Pearsoni kui Spearmani korrelatsioonides.", 'fi': 'ROUGE on laajasti käytetty arviointimittari tekstien yhteenvedossa. Se ei kuitenkaan sovellu abstraktiivisten yhteenvetojärjestelmien arviointiin, koska se perustuu kultastandardin ja luotujen tiivistelmien lexikaaliseen päällekkäisyyteen. Tämä rajoitus tulee selvemmäksi agglutinaattoreille kielille, joilla on erittäin suuret sanastot ja korkea tyyppi/token suhde. Tässä artikkelissa esittelemme semanttisia samankaltaisuusmalleja turkkilaiselle kielelle ja sovellamme niitä arviointimittareina abstraktiivisessa yhteenvetotehtävässä. Tämän saavuttamiseksi käänsimme englanninkielisen STSb-aineiston turkiksi ja esitimme ensimmäisen semanttisen tekstin samankaltaisuuden aineiston turkiksi. Osoitimme, että parhaat samankaltaisuusmallimme ovat paremmin linjassa keskimääräisten ihmisten arviointien kanssa verrattuna ROUGE-malliin sekä Pearsonin että Spearmanin korrelaatioissa.', 'cs': 'ROUGE je široce používaná hodnotící metrika v textovém shrnutí. Pro hodnocení abstraktivních souhrnných systémů však není vhodný, protože se opírá o lexikální překrytí mezi zlatým standardem a generovanými souhrny. Toto omezení je zřejmější u aglutinativních jazyků s velmi velkými slovníky a vysokým poměrem typu/token. V tomto článku prezentujeme sémantické modely podobnosti pro turečtinu a aplikujeme je jako hodnotící metriky pro abstraktivní souhrnnou úlohu. Abychom toho dosáhli, přeložili jsme anglický datový soubor STSb do turečtiny a představili první sémantickou textovou podobnost i pro turečtinu. Ukázali jsme, že naše nejlepší podobnostní modely mají lepší sladění s průměrnými lidskými úsudky ve srovnání s ROUGE v korelacích Pearsona a Spearmana.', 'jv': 'TOGE politenessoffpolite"), and when there is a change ("assertive limiting Nang paper iki, kita gawe ing semanti Simlarité model kanggo turco karo aplikasyon karo assertion Metika kanggo un sumulasi task apstracative. Rasané iki, awak dhéwé ngertuakake dataset Inggris STAS b ning turké lan nambah dhéwé dataset sing berarti semanti nggo textual kanggo ngerasakno turké sakak dhéwé. Awak dhéwé éntuk sistem sing larang sampeyan gak bener tentang karo hal-hal dadi sing luwih apik karo nggawe barang nggawe barang nggawe barang Perikson karo Winter', 'he': "ROUGE הוא מטריקת עריכה משתמשת רחבה בסכם טקסט. בכל אופן, זה לא מתאים להערכה של מערכות המסכם אוסטרקטיביות כיוון שהוא סומך על התקפלות לקסית בין הסטנדרט הזהב לסטנדרט הנוצר. ההגבלה הזאת הופכת להיות יותר ברורה לשפות אגלוטינטיביות עם מילים גדולים מאוד ו יחסי סוג/סימנים גבוהים. בעיתון הזה, אנו מציגים דוגמנים סמנטיים של דוגמניות לטורקים ולהשתמש בהם כמטריות הערכה למשימה אסטרקטיבית של סאמריזציה. כדי להשיג את זה, התרגמנו את קבוצת הנתונים של STSb האנגלית לטורקית והציגנו את קבוצת הנתונים של דמיון טקסטלי הסמנטי הראשונה גם לטורקית. הראינו שלדוגמנים הדמיונים הטובים ביותר שלנו יש התאמה טובה יותר עם השיפוטים האנושיים הממוצעים בהשוואה לרוג'י בקשר בין פירסון וספרמן.", 'sk': 'ROUGE je pogosto uporabljena merila ocenjevanja v povzetku besedila. Vendar pa ni primeren za vrednotenje sistemov abstraktivnega povzetka, saj se opira na leksikalno prekrivanje zlatega standarda in ustvarjenih povzetkov. Ta omejitev postane bolj očitna za aglutinacijske jezike z zelo velikimi besedišči in visokimi razmerji tipa/žeton. V prispevku predstavljamo semantične modele podobnosti za turščino in jih uporabljamo kot ocenjevalne metrike za abstraktivno povzetek naloge. Za dosego tega smo prevedli angleški nabor podatkov STSb v turščino in predstavili prvi semantični nabor podobnosti besedila tudi za turščino. Pokazali smo, da imajo naši najboljši modeli podobnosti boljšo usklajenost s povprečnimi človeškimi presojami v primerjavi z ROUGE v Pearsonovih in Spearmanovih korelacijah.', 'ha': "ROUGE is a widely used evaluation metric in text summarization.  Ba ya kasa daidai ga evaluation na'urar tsarin tsari na kanrakati, kamar shi na dõgara a kan rufe nau'i na zĩnãriya da ƙari da aka ƙãga. Wannan tsarin ya fi bayyane wa harshen aggulutinative da sauri mai girma da rabon nau'in/matsayi mai girma. Ga wannan takardan, Munã halatar da misalin misãlai masu daidaita wa Tirkiya kuma Munã amfani da su kamar tunkuɗe metric da za'a samu'a ga aikin taƙaitaccen. To, dõmin ku isa wannan, mun fassara data na Sb na Ingiriya zuwa Tirkiya kuma muka bãyar da na farkon matsali na semantic na daidaita kwamfyutan turuki da haka. Mun nũna masu kami da misalinmu sun fi zama masu daidaita a tsakanin mutane da kamarsa a tsakanin RuUGE a tsakanin Pearson da Spearman.", 'bo': 'ROUGE is a widely used evaluation metric in text summarization. ཡིན་ནའང་། རྩ་བ་རྩིས་འབྲེལ་གྱི་བཅུད་སྡུད་རིམ་གྱི་ཚད་ལྟར་ཕན་མེད་པ། གང་ལེགས་ན། འདིས་རྩིས་གཞུང་དང་གསར་བསྐྲུན་པའི་བཅུད་ ཚད་འདི་ནི་བརྡ་སྤྲོད་ཆེན་དང་རིགས་མཐོ་ཁག་པོ་ཡིན་པའི་སྐད་རིགས་ཚིག་དང་མཐོ་རིམ་མཚུངས་པར་མཐོང་ནུས། In this paper, we present semantic similarity models for Turkish and apply them as evaluation metrics for an abstractive summarization task. To achieve this, we translated the English STSb data set into Turkish and presented the first semantic textual similarity data set for Turkish as well. ང་ཚོས་མི་འདྲ་བ་དང་མི་འདྲ་བ་གཉིས་ཀྱིས་རྒྱ་ནག་གི་དབར་གྱི་མཐུན་འགྱུར་བ་དང་མཉམ་དུ་ཆོས་ཉིད་ཅིག་ལ་མཐུན་སྒྲིག'}
{'en': 'The GEM Benchmark : Natural Language Generation, its Evaluation and Metrics', 'ar': 'معيار GEM: توليد اللغة الطبيعية وتقييمها ومقاييسها', 'es': 'El punto de referencia GEM: generación del lenguaje natural, su evaluación y métricas', 'pt': 'O benchmark GEM: geração de linguagem natural, sua avaliação e métricas', 'fr': 'The GEM Benchmark\xa0: Génération du langage naturel, son évaluation et ses métriques', 'ja': 'GEMベンチマーク：自然言語の生成、その評価と指標', 'hi': 'जीईएम बेंचमार्क: प्राकृतिक भाषा पीढ़ी, इसका मूल्यांकन और मीट्रिक', 'ru': 'Эталон GEM: генерация естественного языка, его оценка и метрики', 'zh': 'GEM基:自然语言生,其估指标', 'ga': 'Tagarmharc GEM: Giniúint Teanga Nádúrtha, a Mheastóireacht agus a Méadracht', 'ka': 'GEM ბანქმარი: თავისუფალური ენერგიის განვითარება, მისი Evaluation and Metrics', 'hu': 'A GEM referenciaértéke: a természetes nyelv generálása, értékelése és mérése', 'lt': 'GEM lyginamasis rodiklis: gamtinės kalbos generacija, jos vertinimas ir metrika', 'el': 'Ο δείκτης αναφοράς: Δημιουργία φυσικής γλώσσας, αξιολόγηση και μετρήσεις', 'it': 'Il benchmark GEM: Generazione del linguaggio naturale, sua valutazione e metriche', 'kk': 'GEM бағдарламасы: Natural Language Generation, its Evaluation and Metrics', 'ms': 'Tanda Bentangan GEM: Jenerasi Bahasa Alami, Evaluasi dan Metrik', 'mk': 'ГЕМ benchmark: Natural Language Generation, its Evaluation and Metrics', 'ml': 'The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics', 'mn': 'GEM банкемарк: Байгалийн хэл төрөл, үнэлгээ, метрик', 'pl': 'Wskaźnik odniesienia GEM: generowanie języka naturalnego, jego ocena i wskaźniki', 'sr': 'GEM Benchmark: Generacija prirodnog jezika, njegova evaluacija i metrika', 'ro': 'Criteriul de referință GEM: Generarea limbajului natural, evaluarea și metricile sale', 'mt': 'Il-punt ta’ riferiment tal-GEM: Ġenerazzjoni tal-Lingwa Naturali, l-Evalwazzjoni u l-Metriki tagħha', 'no': 'GEM-benchmarket: Naturelle språk, evalueringa og metrikn', 'si': 'GEM බෙන්ච්මාර්ක්: ස්වභාවික භාෂාව නිර්මාණය, ඒකේ විශ්වාස සහ මෙට්\u200dරික්ස්', 'sv': 'GEM Benchmark: Naturligt språk generation, dess utvärdering och mätvärden', 'ta': 'GEM பென்க்மார்க்: இயல்பான மொழி உருவாக்கம், அதன் மதிப்பு மற்றும் மெட்ரிக்ஸ்', 'ur': 'GEM Benchmark: Natural Language Generation, its Evaluation and Metrics', 'so': 'Qedemeynta GEM: Generation of asalka ah, qiimeynta iyo Metrics', 'uz': 'GEM bogʻlamasi: Natalik tillar yaratish, tasdiqlash va metrik', 'vi': 'Bài tập tổ chức GED: Thế hệ ngôn ngữ tự nhiên, giá trị và sản xuất Metrics.', 'bg': 'Сравнителен показател: генериране на естествен език, неговата оценка и метрики', 'nl': 'De GEM Benchmark: Generatie van natuurlijke taal, de evaluatie ervan en Metrics', 'hr': 'GEM Benchmark: Generacija prirodnog jezika, njegova procjena i metrika', 'da': 'GEM Benchmark: Naturligt sprog generation, dens evaluering og målinger', 'de': 'Der GEM Benchmark: Generierung natürlicher Sprache, ihre Bewertung und Metriken', 'ko': 'GEM 기준: 자연 언어 생성, 평가 및 측정', 'fa': 'برچسب GEM: نسل زبان طبیعی، ارزیابی و متریک آن', 'id': 'Benchmark GEM: Generasi Bahasa Alami, Evaluasi dan Metriknya', 'sw': 'Bendera ya GEM: Uzalishaji wa lugha ya asili, Uchunguzi wake na Utafiti', 'af': 'Die GEM-benchmark: Natuurlike Taal Generasie, sy Evaluasie en Metrike', 'tr': 'GEM Şablon Çykyşy: Dogaty Dil Döredişi, Taýýarlama we Metrikleri', 'sq': 'Benchmark GEM: Natural Language Generation, its Evaluation and Metrics', 'hy': 'ԳԵՄ-ի համեմատական նշանը՝ բնական լեզվի ստեղծման, դրա գնահատման և մետրիկայի', 'az': 'GEM Benchmark: T…ôbi…ôtli Dil M…ôxluqatńĪ, Onun deńüerlendirm…ôsi v…ô Metrikl…ôri', 'am': 'The GEM Benchmark: Natural language generation, its evaluation and Metrics', 'ca': 'The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics', 'bn': 'জিএম বেনকম্যার্ক: স্বাভাবিক ভাষা প্রজন্ম, এর মূল্যায়ন এবং মেট্রিক', 'cs': 'Benchmark GEM: generování přirozeného jazyka, jeho hodnocení a metriky', 'bs': 'GEM Benchmark: Generacija prirodnog jezika, njena procjena i metrika', 'et': 'GEMi võrdlusnäitaja: looduskeele genereerimine, selle hindamine ja mõõdikud', 'fi': 'GEM Benchmark: Natural Language Generation, its Evaluation and Metrics', 'ha': 'KCharselect unicode block name', 'he': 'המרמז של GEM: יצירת שפות טבעיות, הערכה והמטריקה שלה', 'jv': 'GEM Bench-Bench: Generation of Language of Personal, Language of Debian and Metric', 'sk': 'Referenčna merila GEM: Ustvarjanje naravnega jezika, njegovo ocenjevanje in meritve', 'bo': 'GEM Benchmark: Natural Language Generation, its Evaluation and Metrics'}
{'en': 'We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics. This disconnect makes it challenging to identify the limitations of current models and opportunities for progress. Addressing this limitation, GEM provides an environment in which models can easily be applied to a wide set of tasks and in which evaluation strategies can be tested. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop.', 'fr': "Nous présentons GEM, une référence vivante pour la génération du langage naturel (GNL), son évaluation et ses métriques. La mesure des progrès dans le GNL repose sur un écosystème en constante évolution de métriques automatisées, d'ensembles de données et de normes d'évaluation humaine. En raison de cette cible mouvante, les nouveaux modèles continuent souvent d'évaluer des corpus anglo-centriques divergents avec des métriques bien établies mais imparfaites. Cette déconnexion rend difficile l'identification des limites des modèles actuels et des opportunités de progrès. Pour pallier cette limitation, GEM fournit un environnement dans lequel les modèles peuvent facilement être appliqués à un large éventail de tâches et dans lequel les stratégies d'évaluation peuvent être testées. Les mises à jour régulières de l'indice de référence aideront la recherche sur le GNL à devenir plus multilingue et à faire évoluer le défi en parallèle Ce document sert de description des données pour la tâche partagée 2021 lors de l'atelier GEM associé.", 'es': 'Presentamos GEM, un punto de referencia vivo para la generación de lenguaje natural (NLG), su evaluación y métricas. La medición del progreso en NLG depende de un ecosistema en constante evolución de métricas automatizadas, conjuntos de datos y estándares de evaluación humana. Debido a este objetivo móvil, los nuevos modelos a menudo todavía se evalúan en cuerpos anglocéntricos divergentes con métricas bien establecidas, pero defectuosas. Esta desconexión hace que sea difícil identificar las limitaciones de los modelos actuales y las oportunidades de progreso. Al abordar esta limitación, GEM proporciona un entorno en el que los modelos se pueden aplicar fácilmente a un amplio conjunto de tareas y en el que se pueden probar las estrategias de evaluación. Las actualizaciones periódicas del punto de referencia ayudarán a que la investigación de NLG sea más multilingüe y evolucione el desafío junto con los modelos. Este documento sirve como descripción de los datos para la tarea compartida de 2021 en el taller GEM asociado.', 'ar': 'نقدم GEM ، وهو معيار حي لتوليد اللغة الطبيعية (NLG) وتقييمها ومقاييسها. يعتمد قياس التقدم في NLG على نظام بيئي دائم التطور من المقاييس الآلية ومجموعات البيانات ومعايير التقييم البشري. بسبب هذا الهدف المتحرك ، لا تزال النماذج الجديدة غالبًا ما تُقيِّم على مجموعات متباينة متمركزة حول الأنجلو بمقاييس راسخة ، ولكنها معيبة. هذا الانفصال يجعل من الصعب تحديد قيود النماذج الحالية وفرص التقدم. لمعالجة هذا القيد ، يوفر GEM بيئة يمكن من خلالها تطبيق النماذج بسهولة على مجموعة واسعة من المهام والتي يمكن فيها اختبار استراتيجيات التقييم. ستساعد التحديثات المنتظمة للمعيار أبحاث NLG على أن تصبح أكثر تعددًا للغات وتطور التحدي جنبًا إلى جنب مع النماذج. هذه الورقة بمثابة وصف لبيانات مهمة 2021 المشتركة في ورشة عمل GEM المرتبطة.', 'pt': 'Apresentamos o GEM, um benchmark vivo para geração de linguagem natural (NLG), sua avaliação e métricas. A medição do progresso em NLG depende de um ecossistema em constante evolução de métricas automatizadas, conjuntos de dados e padrões de avaliação humana. Devido a esse alvo em movimento, novos modelos geralmente ainda avaliam corpora anglocêntricos divergentes com métricas bem estabelecidas, mas falhas. Essa desconexão torna difícil identificar as limitações dos modelos atuais e as oportunidades de progresso. Resolvendo essa limitação, o GEM fornece um ambiente no qual os modelos podem ser facilmente aplicados a um amplo conjunto de tarefas e no qual as estratégias de avaliação podem ser testadas. Atualizações regulares do benchmark ajudarão a pesquisa do NLG a se tornar mais multilíngue e desenvolver o desafio ao lado dos modelos. Este documento serve como a descrição dos dados para a tarefa compartilhada de 2021 no GEM Workshop associado.', 'zh': '吾言GEM,此自然语言生(NLG),其估指标之生准也。 量 NLG 之进,赖于自动化指标、数、人工之生态系统。 故其移也,新模常异盎格鲁为中心之语料库,语料库有善而有缺陷之指标。 此脱节使定形势之局限性,与进步之机为挑战性。 为此限者,GEM给一境,形势易用于广任,而试策于其中。 定期更新基准将助NLG研究转多语言化,并与模形挑战。 本文相关GEM研讨会2021年共同任务之数据描述也。', 'hi': 'हम GEM, प्राकृतिक भाषा पीढ़ी (NLG), इसके मूल्यांकन और मीट्रिक के लिए एक जीवित बेंचमार्क पेश करते हैं। एनएलजी में प्रगति को मापना स्वचालित मीट्रिक, डेटासेट और मानव मूल्यांकन मानकों के लगातार विकसित पारिस्थितिक तंत्र पर निर्भर करता है। इस चलती लक्ष्य के कारण, नए मॉडल अक्सर अभी भी अच्छी तरह से स्थापित, लेकिन दोषपूर्ण, मीट्रिक के साथ अलग-अलग एंग्लो-केंद्रित कॉर्पोरेट पर मूल्यांकन करते हैं। यह डिस्कनेक्ट वर्तमान मॉडल की सीमाओं और प्रगति के अवसरों की पहचान करना चुनौतीपूर्ण बनाता है। इस सीमा को संबोधित करते हुए, GEM एक ऐसा वातावरण प्रदान करता है जिसमें मॉडल को आसानी से कार्यों के एक विस्तृत सेट पर लागू किया जा सकता है और जिसमें मूल्यांकन रणनीतियों का परीक्षण किया जा सकता है। बेंचमार्क के लिए नियमित अपडेट एनएलजी अनुसंधान को अधिक बहुभाषी बनने और मॉडल के साथ चुनौती विकसित करने में मदद करेगा। यह पेपर संबंधित GEM कार्यशाला में 2021 साझा कार्य के लिए डेटा के विवरण के रूप में कार्य करता है।', 'ja': '自然言語生成（ NLG ）の生きたベンチマークであるGEM、その評価、および指標を紹介します。NLGの進捗状況の測定は、自動化された指標、データセット、および人間の評価基準の常に進化するエコシステムに依存しています。この動くターゲットのため、新しいモデルは、確立されているが欠陥のある指標を持つ異なったアングロ中心のコーパスで評価することがよくあります。この断絶は、現在のモデルの限界と進歩の機会を特定することを困難にします。この制限に対処するために、GEMは、モデルを幅広いタスクに簡単に適用し、評価戦略をテストできる環境を提供します。ベンチマークの定期的な更新は、NLG研究がより多言語になり、モデルと並んで課題を進化させるのに役立ちます。本稿は、関連するGEMワークショップにおける2021年共有タスクのデータの説明として役立つ。', 'ru': 'Мы представляем GEM, живой эталон для генерации естественного языка (NLG), его оценки и метрики. Измерение прогресса в NLG зависит от постоянно развивающейся экосистемы автоматизированных метрик, наборов данных и стандартов оценки человека. Благодаря этой движущейся цели, новые модели часто все еще оценивают на расходящихся англоцентричных телах с хорошо установленными, но несовершенными метриками. Этот разрыв затрудняет выявление недостатков нынешних моделей и возможностей для достижения прогресса. Устраняя это ограничение, ГСМ обеспечивает среду, в которой модели могут быть легко применены к широкому набору задач и в которой могут быть опробованы стратегии оценки. Регулярные обновления эталона помогут NLG исследованиям стать более многоязычными и развить проблему наряду с моделями. Этот документ служит описанием данных для совместной задачи 2021 года на соответствующем семинаре GEM.', 'ga': 'Tugaimid isteach GEM, tagarmharc beo do Ghiniúint teanga nádúrtha (NLG), a Mheastóireacht, agus Méadracht. Braitheann tomhas dul chun cinn sa NLG ar éiceachóras de mhéadracht uathoibrithe, tacair sonraí agus caighdeáin mheastóireachta daonna a bhíonn ag síorathrú. De bharr na sprice gluaisteacha seo, is minic a dhéanann samhlacha nua meastóireacht ar chorpas angla-lárnach éagsúil le méadracht seanbhunaithe ach lochtach. Mar gheall ar an dícheangal seo tá sé dúshlánach teorainneacha na múnlaí reatha agus deiseanna dul chun cinn a aithint. Chun aghaidh a thabhairt ar an teorannú sin, cuireann GEM timpeallacht ar fáil inar féidir samhlacha a chur i bhfeidhm go héasca ar shraith leathan tascanna agus inar féidir straitéisí meastóireachta a thástáil. Cabhróidh nuashonruithe rialta ar an tagarmharc le taighde NLG a bheith níos ilteangaí agus an dúshlán a fhorbairt taobh le samhlacha. Feidhmíonn an páipéar seo mar chur síos ar na sonraí don tasc comhroinnte 2021 ag an gCeardlann GEM gaolmhar.', 'el': 'Παρουσιάζουμε ένα ζωντανό σημείο αναφοράς για τη δημιουργία φυσικών γλωσσών, την αξιολόγηση και τις μετρήσεις. Η μέτρηση της προόδου στο σύστημα βασίζεται σε ένα συνεχώς εξελισσόμενο οικοσύστημα αυτοματοποιημένων μετρήσεων, συνόλων δεδομένων και προτύπων ανθρώπινης αξιολόγησης. Λόγω αυτού του κινούμενου στόχου, νέα μοντέλα συχνά εξακολουθούν να αξιολογούν σε αποκλίνοντα αγγλοκεντρικά σώματα με καλά καθιερωμένες, αλλά ελαττωματικές, μετρήσεις. Αυτή η αποσύνδεση καθιστά δύσκολη την αναγνώριση των περιορισμών των σημερινών μοντέλων και των ευκαιριών προόδου. Αντιμετωπίζοντας αυτόν τον περιορισμό, παρέχει ένα περιβάλλον στο οποίο τα μοντέλα μπορούν εύκολα να εφαρμοστούν σε ένα ευρύ σύνολο εργασιών και στο οποίο μπορούν να δοκιμαστούν στρατηγικές αξιολόγησης. Οι τακτικές ενημερώσεις του δείκτη αναφοράς θα βοηθήσουν την έρευνα να γίνει πιο πολύγλωσση και να εξελιχθεί η πρόκληση παράλληλα με μοντέλα. Η παρούσα εργασία χρησιμεύει ως περιγραφή των δεδομένων για την κοινή εργασία 2021 στο σχετικό εργαστήριο ΓΕΜ.', 'hu': 'Bemutatjuk a GEM-et, a természetes nyelv generációjának (NLG) élő referenciaértékét, értékelését és mérését. Az NLG fejlődésének mérése az automatizált metrikák, adatkészletek és emberi értékelési szabványok folyamatosan fejlődő ökoszisztémáján alapul. Ennek a mozgó célnak köszönhetően az új modellek gyakran még mindig értékelik az eltérő angol-centrikus korpuszokat jól megalapozott, de hibás mutatókkal. Ez a kapcsolat kihívást jelent a jelenlegi modellek korlátainak és a fejlődés lehetőségeinek azonosítása. E korlátozás kezelése érdekében a GEM olyan környezetet biztosít, amelyben a modellek könnyen alkalmazhatók a feladatok széles körére, és amelyben az értékelési stratégiák tesztelhetők. A referenciaérték rendszeres frissítése elősegíti, hogy az NLG kutatásai többnyelvűbbé váljanak, és a modellek mellett fejlesszék a kihívást. Ez a tanulmány a hozzá tartozó GEM Workshop 2021-es megosztott feladatához kapcsolódó adatok leírásaként szolgál.', 'ka': 'ჩვენ GEM-ს გაჩვენებთ, სიცოცხოვრებული ბენქმარკი, სახელსაწყოთა ენის განვითარებისთვის (NLG), მისი განსაზღვრება და მეტრიკისთვის. NLG-ის პროგრესის გაზომილებაზე მუშაობა ავტომატიკური მეტრიკის, მონაცემების და ადამიანის განსაზომილების სტანდარტების ეკოსისტემაზე. ამ მოძრაობის მიზეზით, ახალი მოდელები ზოგიერთად განსხვავებული კომპორაზე მუშაობელია, მაგრამ მუშაობელია, მეტრიკაში. ეს გადაკავშირება განსაზღვრებელია მიმდინარე მოდელების და პროგრესის შესაძლებლობის განსაზღვრებას. GEM-ს განსაზღვრებას შესაძლებელია განსაზღვრება, რომელიც მოდელები უფრო მარტივიდ შეუძლებელია გამოყენება დიდი რაოდენობით დავალებისთვის და რომელიც შეუძლებელია განსაზღვრება რეგილური განახლებები ბანქმერისთვის დახმარება NLG სწავლობას უფრო მრავალენგური იქნება და მოდელების ერთმანეთში განვითარება. ეს დოკუმენტი იმუშაობს როგორც მონაცემების გამოსახულება 2021 წლის გაყოფილი პარამეტრების შესახებ GEM სამუშაოში.', 'lt': 'Pateikiame GEM, gyvą gamtos kalbų generacijos (NLG), jos vertinimo ir metrografijos standartą. Naujosios nacionalinės gairės pažangos vertinimas grindžiamas nuolat besivystančia automatinių metrijų, duomenų rinkinių ir žmogaus vertinimo standartų ekosistema. Dėl šio judančio tikslo nauji modeliai dažnai vis dar vertinami skirtingų kampo centrinių korprų su gerai nustatytais, bet trūkstamais, metriniais rodikliais. Dėl šio nutraukimo sunku nustatyti dabartinių modelių ir pažangos galimybių apribojimus. Atsižvelgiant į šį apribojimą, GEM suteikia aplinką, kurioje modeliai gali būti lengvai taikomi įvairioms užduotims ir kurioje gali būti išbandytos vertinimo strategijos. Nuolatiniai standarto atnaujinimai padės NLG moksliniams tyrimams tapti daugiakalbiais ir kartu su modeliais iššūkį plėtoti. Šiame dokumente aprašomi 2021 m. bendros užduoties duomenys susijusiame GEM seminare.', 'mk': 'Ние го претставуваме ГЕМ, жив стандард за генерација на природен јазик (НЛГ), нејзината евалуација и Метрик. Меркувањето на напредокот во НЛГ се зависи од постојано еволуирачкиот екосистем на автоматизирани метрики, податоци и човечки стандарди за проценка. Поради оваа движлива цел, новите модели честопати сé уште ги проценуваат дивергентните агол-централни корпора со добро утврдени, но недостасувачки метрики. Ова исклучување го прави тешко идентификувањето на ограничувањата на сегашните модели и можностите за напредок. Со решавање на овие ограничувања, ГЕМ обезбедува средина во која моделите лесно можат да се применат на голем број задачи и во која може да се тестираат стратегиите за евалуација. Регуларните ажурирања на benchmark ќе помогнат истражувањето на НЛГ да стане повеќе мултијазично и да го еволуира предизвикот заедно со моделите. Овој документ служи како опис на податоците за заедничката задача во 2021 година на поврзаната работилница ГЕМ.', 'it': "Introducemo GEM, un punto di riferimento vivente per la generazione del linguaggio naturale (NLG), la sua valutazione e metriche. La misurazione dei progressi in NLG si basa su un ecosistema in continua evoluzione di metriche automatizzate, set di dati e standard di valutazione umana. A causa di questo obiettivo in movimento, i nuovi modelli spesso valutano ancora corpora anglo-centrica divergente con metriche ben consolidate, ma difettose. Questa disconnessione rende difficile individuare i limiti dei modelli attuali e le opportunità di progresso. Affrontare questa limitazione, GEM fornisce un ambiente in cui i modelli possono essere facilmente applicati a un'ampia serie di compiti e in cui le strategie di valutazione possono essere testate. Aggiornamenti regolari del benchmark aiuteranno la ricerca NLG a diventare più multilingue e ad evolvere la sfida accanto ai modelli. Questo articolo serve da descrizione dei dati per l'attività condivisa 2021 presso il GEM Workshop associato.", 'kk': 'Біз GEM-ті, табиғи тілді жасау (NLG), оқу және метрикалық тілдер үшін өмір сәйкес белгісін келтіреміз. NLG бағдарламасының өлшемі автоматты метрикалық, деректер қорлары және адамның бағалау стандарттарының экосистеміне тұрақты өзгертілген. Бұл жылжытатын мақсаттың себебі, жаңа моделдер әлі қазір бұрышты ортақ корпораға жақсы құрылған, бірақ жалғыз, метрикалық түрлерді бағалайды. Бұл байланысты бұл қазіргі үлгілер мен жағдайдың мүмкіндіктерінің шектеулерін анықтау үшін әсер етеді. Бұл шектеуді шектеу үшін GEM үлгілерді көп тапсырмалардың және оңай шектеу стратегияларына тексеруге болады. Құрамындағы қалыпты жаңартулар NLG зерттеулерінің көптілігін көмектеседі және моделдердің жағындағы мәселелерді өзгертуге көмектеседі. Бұл қағаз 2021 жылдың ортақ тапсырманың деректерінің сипаттамасы болады.', 'ms': 'Kami memperkenalkan GEM, benchmark hidup untuk Generasi Bahasa Alami (NLG), Evaluasi, dan Metriks. Mengukur kemajuan dalam NLG bergantung pada ekosistem yang terus berkembang metrik automatik, set data, dan standar penilaian manusia. Sebab sasaran bergerak ini, model baru sering masih menilai pada korpra sudut-sentrik yang berbeza dengan metrik yang ditetapkan dengan baik, tetapi cacat. Pemutusan ini membuat ia mencabar untuk mengenalpasti keterangan model semasa dan peluang untuk kemajuan. Menghadapi keterangan ini, GEM menyediakan persekitaran di mana model boleh mudah dilaksanakan pada set tugas luas dan di mana strategi penilaian boleh diuji. Kemaskini biasa ke tanda rujukan akan membantu kajian NLG menjadi lebih berbilang bahasa dan mengembangkan cabaran bersama-sama model. Kertas ini berkhidmat sebagai keterangan data untuk tugas kongsi 2021 di Kerja Kerja GEM yang berkaitan.', 'ml': 'സ്വാഭാവികമായ ഭാഷയുടെ ജനറന്\u200d (NLG), അതിന്\u200dറെ പരിശോധനവും, മെറ്റിക്സുകള്\u200dക്കും ജീവനോടെ ജീവിക്കുന്ന ബെന്\u200dമാര്\u200dക്ക് ഞങ എംഎല്\u200dജിയിലെ അളവിലുള്ള പുരോഗങ്ങള്\u200d നിരന്തരമായി വികസിക്കുന്ന മെട്രിക്കള്\u200d, ഡാറ്റാസറ്റുകള്\u200d, മനുഷ്യരുടെ വിലാസപൂര്\u200dണ് ഈ നീങ്ങുന്ന ലക്ഷ്യം കാരണം പുതിയ മോഡലുകള്\u200d പലപ്പോഴും വ്യത്യസ്തമായിട്ടുള്ള ആങ്ലോ സെന്റ്രിക്ക് കോര്\u200dപ്പോറിയില്\u200d വിലയിച്ച നിലവിലുള്ള മോഡലുകളുടെ പരിധികളും പുരോഗതിക്കുള്ള അവസരങ്ങളും നിരീക്ഷിക്കുന്നതിനായി ഈ ബന്ധം വിലപിക്കു ഈ പരിധിയെക്കുറിച്ച് വിശദീകരിക്കുന്നതിനാല്\u200d ജിഎം ഒരു പരിസ്ഥിതി നല്\u200dകുന്നു. അതില്\u200d മോഡലുകള്\u200dക്ക് എളുപ്പമുള്ള ഒരു കൂട്ടം ജോലി ബെന്\u200dച്മാര്\u200dക്കിലേക്ക് സാധാരണ പുതുക്കങ്ങള്\u200d NLG പരിശോധനത്തെ കൂടുതല്\u200d പല ഭാഷകങ്ങളാക്കുന്നതിന് സഹായിക്കും. പിന്നെ  ഈ പത്രത്തില്\u200d ജിഎം വര്\u200dക്ക്ഷേപ്പില്\u200d 2021 പങ്കാളിയുള്ള ജോലിയുടെ വിവരണത്തിന്റെ വിവരണമായി സേവിക്കുന', 'no': 'Vi introduserer GEM, eit levende benchmarkt for naturspråk generering (NLG), evalueringa og metrikk. Målaring av framgang i NLG er avhengig på ein kontinuerleg utviklingssystem av automatiske metrikar, datasett og menneske evalueringsstandardar. På grunn av denne flytande målet, har nye modeller ofte evaluert på forskjellige vinkelsentrale korpora med godt oppretta, men feil, metrisk. Denne koplinga gjer det vanskeleg å identifisera grensene for gjeldande modeller og muligheter for framgang. Når det gjer denne grensesnittet, vil GEM gje eit miljø der modeller kan enkelt brukast til eit brett sett oppgåver og der evalueringsstrategiar kan testast. Vanlege oppdateringar til benchmarket vil hjelpa til NLG-forskning å bli fleire språk og utvikla utfordringen saman med modeller. Denne papiret tjener som beskrivelsen av data for den delte oppgåva 2021 på den tilknytte GEM- arbeidsområdet.', 'mn': 'Бид GEM-г байгалийн хэл төрөлхтний амьдралын багц (NLG), түүний үнэлгээ, метрикийг танилцуулдаг. NLG-ийн хөгжлийг хэмжих нь автоматжуулагдсан метрик, өгөгдлийн сан болон хүн төрөлхтний оюутнуудын стандарт дээр үргэлж хөгжлийн экосистемээс хамаарна. Энэ хөдөлгөөн зорилготой учраас шинэ загварууд ихэвчлэн өөр өнцөг-төв корпора дээр сайн байгуулсан, гэхдээ алдагдсан, метриктик байдаг. Энэ холбоотой холбоотой нь орчин үеийн загварын, хөгжлийн боломжуудын хязгаарыг тодорхойлох нь хэцүү болгодог. Энэ хязгаарлалтыг хүлээн зөвшөөрөхөд GEM нь олон ажил дээр загваруудыг амархан хэрэглэж болох орчин тойронд хангадаг. НЛГ-ын судалгаагаа олон хэл болж, сорилтыг загварын хамтдаа хөгжүүлэхэд туслах болно. Энэ цаас 2021 оны холбоотой GEM Workshop-д хуваалцагдсан ажлын өгөгдлийн тодорхойлолт юм.', 'ro': 'Introducem GEM, un punct de referință viu pentru generarea limbajului natural (NLG), evaluarea și metricile sale. Măsurarea progresului în NLG se bazează pe un ecosistem în continuă evoluție de măsurători automatizate, seturi de date și standarde de evaluare umană. Datorită acestei ținte mișcătoare, noile modele încă evaluează adesea corpuri anglo-centrice divergente cu valori bine stabilite, dar defecte. Această deconectare face dificilă identificarea limitărilor modelelor actuale și a oportunităților de progres. Soluționând această limită, GEM oferă un mediu în care modelele pot fi aplicate cu ușurință unui set larg de sarcini și în care strategiile de evaluare pot fi testate. Actualizările periodice ale criteriului de referință vor ajuta cercetarea GNL să devină mai multilingvă și să evolueze provocarea alături de modele. Această lucrare servește ca descriere a datelor pentru sarcina partajată 2021 la Atelierul GEM asociat.', 'sr': 'Predstavljamo GEM, živu kritiku prirodnog jezika generacije (NLG), njenu procjenu i metrike. Mjerenje napreda u NLG oslanja se na stalno evoluirajući ekosistem automatskih metrika, seta podataka i standarda ljudske procjene. Zbog ovog pokretnog cilja, novi modeli često i dalje procjenjuju različite anglo-centrične korpore sa dobro uspostavljenim, ali manjim, metričkim. Ovaj otkaz izaziva izazov identifikacije ograničenja trenutnih modela i mogućnosti za napredak. U rješavanju ovog ograničenja, GEM pruža okoliš u kojem se modeli lako primjenjuju na širok skup zadataka i u kojem se mogu testirati strategije procjene. Regularne aktualizacije u kriteriji pomoći će NLG istraživanja postati više multijezičkih i razvijati izazov zajedno s modelima. Ovaj papir služi kao opis podataka za zajednièki zadatak 2021. godine na povezanim GEM radništvu.', 'pl': 'Wprowadzamy GEM, żywy punkt odniesienia dla generowania języka naturalnego (NLG), jego oceny i metryki. Pomiar postępu w NLG opiera się na stale ewoluującym ekosystemie zautomatyzowanych metryk, zbiorów danych i standardów oceny ludzkiej. Z powodu tego ruchomego celu, nowe modele często nadal oceniają rozbieżne korpusy anglo-centryczne z dobrze ustalonymi, ale wadliwymi, wskaźnikami. To odłączenie sprawia, że trudne jest zidentyfikowanie ograniczeń obecnych modeli i możliwości postępu. Rozwiązując to ograniczenie, GEM zapewnia środowisko, w którym modele mogą być łatwo stosowane do szerokiego zestawu zadań i w którym można testować strategie oceny. Regularne aktualizacje referencji pomogą badaniom NLG stać się bardziej wielojęzyczne i rozwijać wyzwanie wraz z modelami. Niniejszy artykuł służy jako opis danych dla wspólnego zadania 2021 podczas powiązanych warsztatów GEM.', 'so': 'Waxaynu soo bandhignaynaa GEM, qoraal nolol ah oo u qoran afka asalka ah (NLG), Qiimeyntiisa iyo Metrics. Heshiiska koritaanka NLG waxay ku xiran tahay nidaamka dhaqaalaha oo joogtada ah oo horumarinaya, metriciyada, data sets iyo standardada qiimeynta dadka. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics.  Halkaas la xiriiro wuxuu ka dhigaa dhibaatooyin in la caddeeyo xadhiidka muuqashada iyo fursadaha horumarinta. Xiriirka GEM wuxuu si fudud ugu codsan karaa tusaalooyin badan iyo in lagu imtixaan karo qorshaha qiimeynta. Baaritaanka NLG waxey ka caawinaysaa wax badan oo luuqado kala duduwan, waxayna horumarinaysaa dhibaatada modellada kale. Kanu wuxuu u adeegaa warqaddan warqadda ku saabsan macluumaadka shaqada lagu qaybiyey 2021 ee warqada GEM la xidhiidha.', 'sv': 'Vi introducerar GEM, ett levande riktmärke för naturligt språk generation (NLG), dess utvärdering och metrik. Att mäta framsteg inom NLG bygger på ett ständigt föränderligt ekosystem av automatiserade mätvärden, datauppsättningar och mänskliga utvärderingsstandarder. På grund av detta rörliga mål utvärderar nya modeller ofta fortfarande divergerande anglocentriska korpora med väletablerade, men bristfälliga, mätvärden. Denna frånkoppling gör det svårt att identifiera begränsningar för nuvarande modeller och möjligheter till framsteg. För att ta itu med denna begränsning erbjuder GEM en miljö där modeller enkelt kan tillämpas på en mängd olika uppgifter och där utvärderingsstrategier kan testas. Regelbundna uppdateringar av riktmärket kommer att hjälpa NLG-forskningen att bli mer flerspråkig och utveckla utmaningen tillsammans med modeller. Denna uppsats fungerar som en beskrivning av data för 2021 delade uppgift vid tillhörande GEM Workshop.', 'si': 'අපි GEM විශ්වාස කරනවා, ස්වාභාවික භාෂාව නිර්මාණය සඳහා ජීවත් බෙන්ච්මාර්ක් එකක්. NLG වල ප්\u200dරධානයක් විශ්වාස කරනවා ස්වයංක්\u200dරීය විශ්වාස කරනවා ස්වයංක්\u200dරීය මෙට්\u200dරික්, ඩේටාසෙට්, මිනිස්සු  මේ හිටියේ ඉලක්කය නිසා අලුත් මොඩේල්ස් තවමත් විශේෂ කොන්ග්ලෝස්ට්\u200dරික් කොන්පෝරාව හොඳ ස්ථාපනය කරලා තියෙ මේ ප්\u200dරවේශනය සහ ප්\u200dරවේශනය සඳහා ප්\u200dරවේශනය සඳහා අවස්ථාවක් තියෙන්න පුළුවන් වෙනුවෙන් ප්\u200dරවේශනය විශ මේ සීමාව සම්බන්ධ කරනවා, GEM පුළුවන් පරික්ෂා කරන්න පුළුවන් පරික්ෂා විදිහට පරික්ෂා කරන්න පුළුවන් පරික්ෂා විද බෙන්චමාර්ක්ට සාමාන්\u200dය අවස්ථාවය NLG පරීක්ෂණය වැඩි භාෂාවක් වෙනුවෙන් උදව් කරන්න පුළුවන් ඒ වගේම අභ මේ පැත්තේ සේවා වෙන්නේ 2021 සම්බන්ධ GEM වැඩසටහනේ සම්බන්ධ වැඩසටහනේ තොරතුරු විස්තර විස්තර.', 'ta': 'நாம் GEM, இயற்கையான மொழி உருவாக்கத்திற்கான ஒரு வாழ்க்கையை அறிமுகப்படுத்துகிறோம் ( NLG), அதன் மதிப்பிட்டு, மற்றும NLG இல் உள்ள முன்னேற்றத்தை அளவிடுதல் தானியங்கிய மெட்ரிக்கள், தரவு அமைப்பு இந்த நகர்த்தும் இலக்கின் காரணத்தால், புதிய மாதிரிகள் பெரும்பாலும் வேறுபட்ட கோண மையம் நிறுவப்பட்டுள்ளது, ஆனால் மெட்ரிக்கள தற்போதைய மாதிரிகளின் எல்லைகளையும் முன்னேற்றத்திற்கான வாய்ப்புகளையும் கண்டுபிடிக்க இந்த த துண்ட Addressing this limitation, GEM provides an environment in which models can easily be applied to a wide set of tasks and in which evaluation strategies can be tested.  பெங்க்மார்க்கு வழக்கமான புதுப்பித்தல் NLG ஆராய்ச்சி அதிக பல மொழிகளாக மாறும் மற்றும் சவால்களை மாதிரிகளுடன் மாற This paper serves as the description of the data for the 2021 shared task in the associated GEM workshop.', 'mt': 'Aħna nintroduċu l-GEM, punt ta’ riferiment ħajjin għall-Ġenerazzjoni tal-Lingwa Naturali (NLG), l-Evalwazzjoni tagħha, u l-Metriks. Il-kejl tal-progress fl-NLG jiddependi fuq ekosistema li qed tevolvi b’mod kostanti ta’ metrika awtomatizzata, settijiet ta’ dejta, u standards ta’ evalwazzjoni umana. Minħabba din il-mira li qed tiċċaqlaq, mudelli ġodda ħafna drabi għadhom jevalwaw fuq korpra anglo-ċentrika diverġenti b’metriċi stabbiliti sewwa, iżda difettużi. This disconnect makes it challenging to identify the limitations of current models and opportunities for progress.  Fl-indirizzar ta’ din il-limitazzjoni, il-GEM jipprovdi ambjent li fih il-mudelli jistgħu jiġu applikati faċilment għal sett wiesa’ ta’ kompiti u li fih jistgħu jiġu ttestjati strateġiji ta’ evalwazzjoni. Aġġornamenti regolari għall-punt ta’ riferiment se jgħinu lir-riċerka tal-NLG issir aktar multilingwi u jevolvu l-isfida flimkien mal-mudelli. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop.', 'ur': 'ہم GEM کو پہنچاتے ہیں، ایک زندہ بنچم طبیعی زبان کی نسل (NLG) کے لئے، اس کا ارزش اور متریک کے لئے۔ NLG میں پیشرفت کا اندازہ پورا کرنا اتماٹریک، ڈاٹ سٹ اور انسان کی ارزیابی استاندارڈ کا ایک ہمیشہ تکامل کرنے والے اکوسیسٹم پر ہے. اس حرکت کی موقع کے باعث، نوی موډل اکثر بھی مختلف انگلوسیٹریک کورپور پر بہت اچھی طرح مضبوط ہے، لیکن غلط، متریک کے ساتھ ارزش کرتے ہیں. یہ قطعہ تخلیق کرتا ہے کہ اس کو اضافہ کرنے کے لئے موجود مدلکوں اور پیشرفت کے فرصت کی محدودیت پہچان کرنے کا مشکل ہے. اس محدودیت کے ساتھ GEM نے ایک محدودیت کو پیش کیا ہے جہاں مدلس ایک گھیرے کاموں کے ساتھ آسان کر سکتے ہیں اور جہاں میں ارزش استراتژی امتحان کر سکتے ہیں۔ بنچم مارک کے سامنے معمولی آدئٹر NLG تحقیقات کی مدد کریں گے بہت زیادہ زبان کی اور مدل کے ساتھ چال کو تکامل کریں گے. This paper serves as the description of the data for the 2021 shared task at the associated GEM Workshop.', 'uz': "Biz GEM, tabiiy tillar Generatish (NLG), Evaluation, Metrics va hayotini ko'rib chiqaramiz. Comment Ushbu koʻchirishni sabab, yangi modellar ham ko'p doim ajratilgan anglo- markazida juda yaxshi qo'llangan, lekin bayroq, metrik bilan qiymatmaydi. Ushbu uzoqlarni joriy modellarning chegarasini aniqlash uchun qiyin qiladi. Bu chegarani boshqarish uchun GEM muhit qilinadi, унда modellar juda oddiy vazifalar qoʻllanishi mumkin va qiymatlash strategiyasi imtixaami mumkin. Bogʻlamaning oddiy yangiliklari NLG ta'limni ko'plab tillar bo'lganligiga yordam beradi va modellar bilan murakkab rivojlanadi. Name", 'vi': 'Chúng tôi giới thiệu GEM, một tiêu chuẩn sống cho Thế Hệ Tự Nhiên (NLG), Bài Đánh giá và Metrics. Sự tiến bộ của NLG phụ thuộc vào một hệ thống sinh thái liên tục tiến bộ của các thước đo đo đo tự động, dữ liệu và tiêu chuẩn đánh giá con người. Do mục tiêu di chuyển này, các mô hình mới vẫn thường đánh giá về dương vật trung tâm khác nhau với tỉ lệ vững chắc, nhưng sai. Sự ngắt kết nối này làm cho nó khó khăn để xác định giới hạn của các mô hình hiện thời và cơ tiến bộ. Với việc áp dụng giới hạn này, GED cho một môi trường cho phép người ta dễ dàng áp dụng cho một loạt các công việc rộng hơn và kiểm tra các chiến lược đánh giá. Sự cập nhật thường xuyên đến tiêu chuẩn sẽ giúp cho việc nghiên cứu về LG trở nên đa dạng hơn và phát triển thử thách cùng với các mẫu. Tờ giấy này dùng làm mô tả dữ liệu cho nhiệm vụ chia sẻ 2021 ở cửa hàng làm việc GME liên kết.', 'bg': 'Представяме ГЕМ, жив еталон за генериране на естествен език (НЛГ), неговата оценка и метрика. Измерването на напредъка в НЛГ разчита на постоянно развиваща се екосистема от автоматизирани показатели, набори от данни и стандарти за оценка на хората. Поради тази движеща се цел новите модели често все още оценяват дивергентните англо-центрични корпуси с добре установени, но недостатъчни показатели. Това прекъсване прави трудно идентифицирането на ограниченията на настоящите модели и възможностите за напредък. Справяйки се с това ограничение, ГЕМ осигурява среда, в която моделите могат лесно да се прилагат към широк набор от задачи и в която стратегиите за оценка могат да бъдат тествани. Редовните актуализации на референтния показател ще помогнат на научните изследвания на НЛГ да станат по-многоезични и да развият предизвикателството заедно с моделите. Настоящата статия служи като описание на данните за споделената задача през 2021 г. на свързания семинар по ГЕМ.', 'nl': "We introduceren GEM, een levende benchmark voor natuurlijke taalgeneratie (NLG), haar evaluatie en Metrics. Het meten van de vooruitgang in NLG is gebaseerd op een voortdurend evoluerend ecosysteem van geautomatiseerde metrics, datasets en menselijke evaluatienormen. Door dit bewegende doel evalueren nieuwe modellen vaak nog op divergente anglo-centric corpora's met gevestigde, maar gebrekkige, metrics. Deze ontkoppeling maakt het uitdagend om de beperkingen van de huidige modellen en mogelijkheden voor vooruitgang te identificeren. Om deze beperking aan te pakken, biedt GEM een omgeving waarin modellen eenvoudig kunnen worden toegepast op een breed scala aan taken en waarin evaluatiestrategieën kunnen worden getest. Regelmatige updates van de benchmark zullen NLG-onderzoek helpen meertaliger te worden en de uitdaging naast modellen verder te ontwikkelen. Dit document dient als beschrijving van de data voor de 2021 gedeelde taak op de bijbehorende GEM Workshop.", 'da': 'Vi introducerer GEM, et levende benchmark for natursproggenerering (NLG), dens evaluering og metrics. Måling af fremskridt i NLG afhænger af et konstant udviklende økosystem af automatiserede metrics, datasæt og menneskelige evalueringsstandarder. På grund af dette bevægelige mål evaluerer nye modeller ofte stadig på divergerende anglo-centrerede korpora med veletablerede, men fejlbehæftede metrics. Denne afbrydelse gør det udfordrende at identificere begrænsningerne i de nuværende modeller og mulighederne for fremskridt. For at imødegå denne begrænsning giver GEM et miljø, hvor modeller nemt kan anvendes til en lang række opgaver, og hvor evalueringsstrategier kan afprøves. Regelmæssige opdateringer af benchmark vil hjælpe NLG-forskningen med at blive mere flersproget og udvikle udfordringen sammen med modeller. Dette papir tjener som beskrivelse af dataene for 2021 delte opgaver på den tilknyttede GEM Workshop.', 'de': 'Wir stellen GEM vor, einen lebendigen Maßstab für die Generierung natürlicher Sprache (NLG), deren Evaluation und Metriken. Die Messung des Fortschritts in NLG beruht auf einem sich ständig weiterentwickelnden Ökosystem aus automatisierten Metriken, Datensätzen und menschlichen Bewertungsstandards. Aufgrund dieses bewegten Ziels bewerten neue Modelle oft noch divergente anglo-zentrische Korpora mit etablierten, aber fehlerhaften Metriken. Diese Trennung macht es schwierig, die Grenzen aktueller Modelle und Möglichkeiten für Fortschritt zu identifizieren. Um dieser Einschränkung entgegenzuwirken, bietet GEM eine Umgebung, in der Modelle leicht auf eine Vielzahl von Aufgaben angewendet werden können und in der Evaluierungsstrategien getestet werden können. Regelmäßige Aktualisierungen des Benchmarks werden dazu beitragen, dass die NLG-Forschung mehrsprachiger wird und die Herausforderung neben Modellen weiterentwickelt wird. Die vorliegende Arbeit dient als Beschreibung der Daten für die gemeinsame Aufgabe im angeschlossenen GEM Workshop.', 'fa': 'ما GEM را معرفی می کنیم، یک مقدار زنده برای نسل زبان طبیعی (NLG), ارزیابش و متریک\u200cها. اندازه\u200cگیری پیشرفت NLG بر روی یک اکوسیستم که همیشه تکامل می\u200cکند از متریک، مجموعه\u200cهای داده\u200cها و استانداردهای ارزیابی انسان است. به دلیل این هدف حرکت، مدل های جدید اغلب هنوز در شرکت متفاوت زاویه مرکزی متفاوت با قابل ثابت، ولی ضعیف، متریک ارزیابی می کنند. این اتصال باعث می\u200cشود که محدودیت مدل\u200cهای فعلی و فرصت\u200cهای پیشرفت را شناسایی کند. در کنار این محدودیت، GEM یک محدودیت را پیشنهاد می\u200cدهد که مدل\u200cها به آسانی بر مجموعه\u200cی عملیات گسترده و در آن استراتژی\u200cهای ارزیابی می\u200cتوانند آزمایش شوند. اخیرات معمولی برای برنامه ریزی به تحقیقات NLG کمک می\u200cکند تا بیشتر از زبان\u200cهای زبان شود و چالش را کنار مدل تکامل دهد. این کاغذ به عنوان توصیف داده\u200cها برای کار مشترک ۲۰۱۲ در کارگاه GEM متصل می\u200cشود.', 'ko': 'GEM, 자연 언어 생성(NLG)의 활성 기준, 평가와 도량을 소개합니다.NLG의 진전을 평가하는 것은 끊임없이 발전하는 자동화 지표, 데이터 집합과 인류 평가 기준 생태계에 의존한다.이러한 끊임없이 변화하는 목표 때문에 새로운 모델은 일반적으로 앵글로어를 중심으로 하는 서로 다른 자료 라이브러리를 바탕으로 평가를 하는데 이런 자료 라이브러리는 완벽하지만 결함이 있는 지표를 가지고 있다.이런 불균형은 현재 모델을 식별하는 한계성과 진전을 이룰 수 있는 기회를 도전적으로 만든다.이러한 한계를 해결하기 위해 GEM은 환경을 제공했다. 이 환경에서 모델은 일련의 광범위한 임무에 쉽게 응용되고 평가 전략을 테스트할 수 있다.정기적으로 기준을 갱신하는 것은 NLG 연구가 더욱 다양한 언어로 변하고 모델과 함께 도전을 발전시키는 데 도움이 될 것이다.본고는 관련 GEM 세미나에서 2021년 공유된 임무의 데이터를 묘사한다.', 'sw': 'Tunawasilisha GEM, bendera ya maisha kwa ajili ya Uzalishaji wa lugha asilia (NLG), Uthibitisho wake, na Metrics. Upatikanaji wa maendeleo katika NLG yanategemea mfumo wa mazingira unaoendelea kuendelea kwa muda mrefu wa mbinu, seti za data na viwango vya uchunguzi wa binadamu. Kutokana na lengo hili linaloendelea, mifano mpya mara nyingi bado hupitia makampuni yenye rangi tofauti ya anglo yenye imara vizuri, lakini vifaa vyema. Uhusiano huu unafanya kuwa na changamoto kutambua vizuizi vya mifano na fursa za maendeleo. Kuhusu kiwango hiki, GEM hutoa mazingira ambayo mifano inaweza kutumika kwa urahisi katika kazi nyingi na ambapo mikakati ya uchunguzi inaweza kujaribu. Regular updates to the benchmark will help NLG research become more multilingual and evolve the challenge alongside models.  Gazeti hili linatumika kama maelezo ya taarifa kwa kazi ya kushirikiana mwaka 2021 katika Warsha ya GEM inayohusiana.', 'id': 'Kami memperkenalkan GEM, benchmark hidup untuk generasi bahasa alam (NLG), Evaluasi, dan Metriks. Mengukur kemajuan di NLG bergantung pada ekosistem yang terus berkembang dari metrik otomatis, dataset, dan standar evaluasi manusia. Karena sasaran bergerak ini, model baru sering masih mengevaluasi pada korpra sudut-sentrik divergent dengan ketentuan yang baik, tapi cacat, metrik. Penghentian ini membuat tantangan untuk mengidentifikasi batasan model saat ini dan kesempatan untuk kemajuan. Menghadapi batasan ini, GEM menyediakan lingkungan di mana model dapat mudah diterapkan pada set besar tugas dan di mana strategi evaluasi dapat diuji. Pemutakhiran biasa ke benchmark akan membantu penelitian NLG menjadi lebih multibahasa dan mengevolusi tantangan bersama model. Kertas ini layak sebagai deskripsi data untuk tugas berbagi 2021 di Workshop GEM terkait.', 'tr': "Biz GEM'i, tebigy dil d철redilmesi (NLG), de흫lenmesi we metrikleri 체챌in 첵a 힊a첵an salgyny tany힊dyr첵arys. NLG'de 철s체mlik 철l챌체si s체rekli 철s체mli metrikler, veri setirleri we adamlary흫 de흫lenme standartlaryny흫 ekosistemine ynamly. Bu hereket eden maksady흫 seb채bi t채ze nusgalar k철plen챌 체첵tge힊ik-merkez korpo첵asynda gowy d철redilen, 첵철ne 첵al흫y힊, metriklerde de흫le첵채rler. Bu 챌yky힊 h채zirki nusgalary흫 we ilerlemek 체챌in m체mkin챌iliklerini tanamak kyn챌ylygyny g철r첵채r. GEM bu 챌yky힊y 챌철zmek 체챌in 철r채n nusgalary a 흫satjag edip, bu nusgalary흫 i챌ine 챌yky힊 stratejileri barlap biljek bir ortam sa첵la첵ar. D체zenli g체ncelle힊meler, NLG ara힊t캇rmalar캇na k철mek eder ve modellerin yan캇nda 챌철z체m체 geli힊tirir. Bu kagyz 2021-nji 첵yldaky GEM 횉al캇힊masynda b철l체n첵채n zady흫 waspy h철km체nde servet ed첵채r.", 'af': "Ons introduseer GEM, 'n lewende benchmark vir natuurlike taal Generasie (NLG), sy evaluasie en metries. Maat vordering in NLG op 'n konstantelik ontwikkelende ekostelsel van outomatiese metries, datastelle en menslike evalueringsstandaarde. Daarom hierdie beweeg doel, nuwe modele het dikwels nog steeds evalueer op verskeie anglo-sentrale korpora met goed geïnstalleer, maar gevaar, metrike. Hierdie afkoppeling maak dit moeilik om die beperkings van huidige modele en moontlikhede vir vordering te identifiseer. By die adres van hierdie beperking, GEM verskaf 'n omgewing waarin modele maklik kan aanwend word na 'n wyse stel van taak en waarin evalueringsstrategies kan toets word. Gewone opdaterings tot die benchmark sal help NLG-ondersoek meer multitaal word en die uitdrukking by die modele ontwikkel. Hierdie papier dien as die beskrywing van die data vir die 2021 gedeelde taak by die geassosieerde GEM Werkskerm.", 'sq': 'Ne prezantojmë GEM, një pikë të gjallë për Gjenerimin e gjuhës natyrore (NLG), vlerësimin e saj dhe Metriks. Mësimi i përparimit në NLG mbështetet në një ekosistem në zhvillim të vazhdueshëm të metrikës automatike, grupeve të dhënash dhe standardeve të vlerësimit njerëzor. Due to this moving target, new models often still evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics.  Kjo shkëputje e bën të vështirë identifikimin e kufizimeve të modeleve aktuale dhe mundësive për përparim. Duke trajtuar këtë kufizim, GEM ofron një mjedis në të cilin modelet mund të zbatohen lehtë në një sërë të gjerë detyrash dhe në të cilin strategjitë e vlerësimit mund të testohen. Përditësimet e rregullta të normës do të ndihmojnë kërkimin e NLG të bëhet më shumëgjuhës dhe të zhvillojë sfidën së bashku me modelet. Ky dokument shërben si përshkrim i të dhënave për detyrën e përbashkët të 2021 në seminarin e lidhur me GEM.', 'hy': 'We introduce GEM, a living benchmark for natural language Generation (NLG), its Evaluation, and Metrics.  ՆԼԳ-ում առաջընթացի չափման հիմնված է ավտոմատիկ մետրիկայի, տվյալների համակարգերի և մարդկային գնահատման ստանդարտների անընդհատ զարգացող էկոհամակարգի վրա: Այս շարժվող նպատակի շնորհիվ նոր մոդելները հաճախ դեռևս գնահատում են տարբեր անկյունից կենտրոնական մարմնի վրա, որոնք ունեն լավ հաստատված, բայց սխալ, մետրիկ: Այս անկապը դժվարանում է հասկանալ ներկայիս մոդելների սահմանափակումները և առաջընթացի հնարավորությունները: Այս սահմանափակումներին վերաբերելով, ԳԵՄ-ն ապահովում է մի միջավայր, որտեղ մոդելները հեշտությամբ կարող են կիրառվել մի շարք խնդիրների վրա և որտեղ կարող են փորձել գնահատման ռազմավարությունները: Համեմարկի առօրյա վերականգնումները կօգնեն ՆԼԳ ուսումնասիրություններին դառնալ ավելի բազմալեզու և զարգացնեն մարտահրավերը մոդելների հետ միասին: Այս աշխատանքը ծառայում է որպես 2021 թվականի ընդհանուր հանձնարարության տվյալների նկարագրություն', 'az': "Biz GEM'i, doğal dil nəzəriyyəti (NLG), değerlendirməsi və metrikləri üçün canlı bir benchmark təşkil edirik. NLG tədbirlərini ölçürmək sürəkli tədbirli metrik, verilənlər və insan değerlendirmə standartlarının ekosisteminə təvəkkül edir. Bu hərəkət məqsədilə yeni modellər hələ də müxtəlif anglo-merkezi korpora ilə müxtəlif möhkəm təyin edilmiş, amma yanlış, metriklərdir. Bu bağlantı, həmin modellərin və ilerleme fırsatlarının sınırlarını təsdiqləməsini çətin edir. Bu limiti çəkmək üçün GEM modellərin çoxlu işlərə asanlıqla istifadə ediləcəyi və çəkinmə stratejilərinin sınaması üçün asanlıqla istifadə ediləcəyi bir ortam təmin edir. NLG araştırmalarının çoxlu dil olmasına kömək edəcək və modellərin yanında çətinlikləri dəyişəcək. Bu kağıt 2021 ilə birlikdə olan GEM İş Hoplarında paylaşılan məlumatların təsbiqi kimi istifadə edir.", 'am': 'GEM፣ ለፍጥረቱ ቋንቋ ትውልድ (NLG)፣ ማስታወቂያውን እና ማትሪክ የሚኖረውን የሕይወት ገጽ እናሳየዋለን፡፡ የNLG ግንኙነት የዘወትር የሚለወጥ የሜትሪክ፣ ዳታተር እና የሰው ማስታወቂያ ድጋፍ ላይ ይደግፋል፡፡ ስለዚህ ለመንቀሳቀስ ዕቅድ፣ አዲስ ዓይነቶች ብዙ ጊዜ በተለየ በክፍለ ክፍል፣ ነገር ግን በተለየ፣ ሚትሪክ ላይ በተለየ የአንዲስ ኮርፖርት ይታያል፡፡ ይህ ግንኙነት የአሁኑን ዓይነቶች እና የግንኙነትን ለመግለጥ የሚችል ነው፡፡ ይህንን ግንኙነት ለመጨመር የGEM ሞዴሎቹ በተለየ ብዙ ስራዎችን ለመጠቀም የሚችሉበት እና ማረጋገጫው strategie ሊፈትኑበት የሚችሉበት አካባቢ ሰጥቷል፡፡ የአሁኑን አሻሻሻል ወደ benchmark ትምህርት የNLG ትምህርት በብዙ ቋንቋዎች ይጨምርበታል እና በዓይነቶች ላይ ግንኙነትን ያደጋል፡፡ ይህ ፕሮግራም በ2021 የተካፈሉት የዳታ ትርጉም በGEM Workshop ውስጥ ነው፡፡', 'ca': "Introduïm GEM, un punt de referència viu per a la generació de llenguatges naturals (NLG), la seva Evaluation i Metrics. Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards.  Gràcies a aquest objectiu en moviment, els nous models sovint encara evaluen sobre corpores anglo-cèntrics divergents amb mètriques ben estables, però defectuoses. Aquesta desconexió fa difícil identificar les limitacions dels models actuals i les oportunitats de progrés. Al tractar aquesta limitació, GEM proporciona un entorn en el qual els models es poden aplicar fàcilment a un gran conjunt de tasques i en el qual es poden provar estratègies d'evaluació. Actualitzacions regulars al punt de referència ajudaran a que la recerca de NLG es torni més multilingüe i evolucionin el repte juntament amb els models. Aquest paper serveix com a descripció de les dades de la tasca compartida del 2021 a l'atelier GEM associat.", 'bn': 'আমরা জিএম, প্রাকৃতিক ভাষা প্রজন্ম (এনএলজি), এর Evaluance এবং মেট্রিক্সের জন্য একটি জীবিত বেনম্যার্ক চিহ্নিত করি। এনএলজিতে অগ্রগতি পরিমাপ নির্ভর করে স্বয়ংক্রিয় মেট্রিক, ডাটাসেট এবং মানুষের মূল্যের স্বাভাবিক পরিস্থিতি বিবর্তনের এই চলতে থাকা লক্ষ্যের কারণে নতুন মডেল প্রায়শই বিভিন্ন অ্যাঙ্ক্লো কেন্দ্রিক কোর্পোরায় ভালোভাবে প্রতিষ্ঠিত, কিন্তু ফ্ল এই বিচ্ছিন্ন সংযোগের ফলে বর্তমান মডেল এবং উন্নয়নের সীমাবদ্ধতা চ্যালেঞ্জ করছে। এই সীমাবদ্ধতার সাথে জিএম একটি পরিবেশ প্রদান করেছে, যেখানে মডেল সহজে প্রয়োগ করা যাবে বিশেষ কাজের জন্য এবং যেখানে মূল্যের কৌশল পরীক্ বেনকম্যার্কে সাধারণত আপডেট এনএলজি গবেষণা বেশী বহুভাষায় পরিণত হবে এবং পাশাপাশি মডেলের চ্যালেঞ্জ বিবর্তন করবে। এই পত্রিকাটি জিএম ওয়ার্কশাপে ২০২১ সালের শেয়ার করা কাজের জন্য তথ্যের বর্ণনা হিসেবে সার্ভিস করে।', 'et': 'Tutvustame GEMi, elusat võrdlusalust looduskeele generatsioonile (NLG), selle hindamisele ja meetritele. NLG edusammude mõõtmine tugineb pidevalt arenevale automatiseeritud mõõdikute, andmekogumite ja inimeste hindamisstandardite ökosüsteemile. Selle liikuva eesmärgi tõttu hindavad uued mudelid sageli endiselt erinevaid anglo-tsentrilisi korpuseid hästi väljakujunenud, kuid vigaste mõõdikutega. Sellise ühenduse katkestamise tõttu on praeguste mudelite piirangute ja eduvõimaluste kindlakstegemine keeruline. Selle piirangu lahendamiseks loob GEM keskkonna, kus mudeleid saab hõlpsasti rakendada paljude ülesannete puhul ja kus hindamisstrateegiaid saab testida. Võrdlusaluse korrapärane ajakohastamine aitab uue töörühma teadusuuringud muutuda mitmekeelsemaks ja arendada väljakutset koos mudelitega. Käesolevas dokumendis kirjeldatakse andmeid seostatud GEM Workshop 2021. aasta jagatud ülesande kohta.', 'bs': 'Predstavljamo GEM, životnu kritiku za prirodnu generaciju jezika (NLG), njenu procjenu i metrike. Mjerenje napreda u NLG oslanja se na stalno evoluirajući ekosistem automatskih metrika, podataka i standarda procjene ljudskih ocjena. Zbog ovog pokretnog cilja, novi modeli često i dalje procjenjuju različite anglo-centrične korpore sa dobro uspostavljenim, ali manjim, metričkim. Ovaj otkaz izaziva izazov identifikacije ograničenja trenutnih modela i mogućnosti za napredak. U rješavanju ovog ograničenja, GEM pruža okoliš u kojem se modeli lako primjenjuju na širok skup zadataka i u kojem se mogu testirati strategije procjene. Obične aktualizacije u kriteriji pomoći će istraživanju NLG-a postati multijezičniji i razvijati izazov zajedno s modelima. Ovaj papir služi kao opis podataka za zajednički zadatak 2021. godine na povezanim GEM radniku.', 'cs': 'Představujeme GEM, živý standard pro generování přirozeného jazyka (NLG), jeho hodnocení a metriky. Měření pokroku v NLG spoléhá na neustále se vyvíjející ekosystém automatizovaných metrik, datových sad a lidských standardů hodnocení. Vzhledem k tomuto pohyblivému cíli, nové modely často stále hodnotí divergentní anglo-centrické korpusy s dobře zavedenými, ale chybnými metrikami. Toto odpojení činí náročné identifikovat omezení současných modelů a příležitosti k pokroku. Při řešení tohoto omezení nabízí GEM prostředí, ve kterém lze modely snadno aplikovat na širokou škálu úkolů a ve kterém lze testovat strategie hodnocení. Pravidelné aktualizace referenčního měřítka pomůže výzkumu NLG stát se mnohojazyčnějším a rozvíjet výzvu vedle modelů. Tento článek slouží jako popis dat pro sdílený úkol 2021 na přidruženém GEM workshopu.', 'fi': 'Esittelemme GEM, elävä vertailukohta luonnollisen kielen Generation (NLG), sen Evaluation ja Metrics. Edistymisen mittaaminen NLG:ssä perustuu jatkuvasti kehittyvään automatisoitujen mittausten, tietoaineistojen ja ihmisten arviointistandardien ekosysteemiin. Tämän liikkuvan tavoitteen vuoksi uudet mallit arvioivat edelleen usein toisistaan poikkeavia anglokeskeisiä korpusia, joilla on vakiintuneet, mutta puutteelliset mittasuhteet. Tämän yhteyden katkeamisen vuoksi on haastavaa tunnistaa nykyisten mallien rajoitukset ja mahdollisuudet edistyä. Tämän rajoituksen korjaamiseksi GEM tarjoaa ympäristön, jossa malleja voidaan helposti soveltaa monenlaisiin tehtäviin ja jossa arviointistrategioita voidaan testata. Vertailun säännölliset päivitykset auttavat NLG:n tutkimusta monikielisemmäksi ja kehittämään haastetta mallien rinnalla. Tämä artikkeli toimii kuvauksena vuoden 2021 yhteiseen tehtävään liittyvässä GEM Workshopissa liittyvistä tiedoista.', 'hr': 'Predstavljamo GEM, životnu kriteriju prirodnog jezika generacije (NLG), njenu procjenu i metrike. Mjerenje napreda u NLG oslanja se na stalno evoluirajući ekosistem automatskih metrika, podataka i standarda procjene ljudskih ocjena. Zbog ovog pokretnog cilja, novi modeli često i dalje procjenjuju različite anglo-centrične korporacije sa dobro uspostavljenim, ali manjim, metričkim. Ovaj otkaz izaziva izazov identifikacije ograničenja trenutnih modela i mogućnosti za napredak. U rješavanju ovog ograničenja GEM pruža okoliš u kojem se modeli lako primjenjuju na širok skup zadataka i u kojem se mogu testirati strategije procjene. Obične aktualizacije u kriteriji pomoći će istraživanju NLG-a postati multijezičniji i razvijati izazov zajedno s modelima. Ovaj papir služi kao opis podataka za zajednički zadatak 2021. godine na povezanim GEM radniku.', 'jv': 'Awak dhéwé nggawe GEM, akeh bendhèké kesempatan kanggo ngilangno Generation (NLG), jewelasar, lan Metric. Ukudiangkat langkung nglanggar NLG usul dumadhi kaya sistem sing gagal evolusuran ekosistem di otomatik Metika, dataset lan kaliwat kuwi nggawe barang dagangan pangan. Ngomongke bukane nggo tarjamahan iki, model sing lunak soalé isih di luwih anglo-centeric Digawe-digawe iki, lak akeh nggawe barang nggawe gerati dadi nggawe model karo peringatan kanggo nggawe gerati. Language Algorithm Workspace', 'ha': "Tuna ƙara da GEM, wani littãfi mai rai wa zaɓen lugha na asili (NLG), Ana iya ƙayyade ta, da Metrics. @ info: whatsthis Dukan wannan tagan da aka motsa, misãlai na dabam yana iya ƙaddara a kan koma mai sãɓãni na tsakanin anglo da mai kyau, kuma amma, mai ƙẽtare, metric. Wannan shirin da ke haɗi ya sanya ta tsummai zuwa gane tsarin misãlai da fursa masu buɗewa. Ga amfani da wannan tsarin, GEM na samar da wata mazaɓa wanda za'a iya amfani da misalin su da sauƙi zuwa wasu aikin daban-daba, da kuma a iya jarraba kayan evaluation. @ info: whatsthis Wannan takardar aiki tanã servici kamar description of the data for the shirin aiki na 2021 at the shirin GM workspace.", 'sk': 'Predstavljamo GEM, živo merilo za generiranje naravnega jezika (NLG), njegovo evalvacijo in metrike. Merjenje napredka v NLG temelji na stalno razvijajočem se ekosistemu avtomatiziranih meritev, naborov podatkov in standardov za ocenjevanje ljudi. Zaradi tega premikajočega se cilja novi modeli pogosto še vedno ocenjujejo na različnih anglo-centričnih korpusih z dobro uveljavljenimi, a napačnimi metrikami. Zaradi tega nepovezanosti je težko opredeliti omejitve sedanjih modelov in priložnosti za napredek. Ob obravnavi te omejitve GEM zagotavlja okolje, v katerem je mogoče modele zlahka uporabiti za širok nabor nalog in v katerem je mogoče preskusiti strategije ocenjevanja. Redno posodabljanje referenčne vrednosti bo pomagalo raziskavam NLG postati večjezičnejše in razvijati izziv skupaj z modeli. Ta prispevek služi kot opis podatkov za skupno nalogo 2021 na pripadajoči delavnici GEM.', 'bo': 'ང་ཚོས་མཐུན་བཟོས་ནུས་མེད་པའི་སྐད་ཡིག་ཆ་ལ་བཅས་ཀྱི་ཚད་འཛིན་གྱི་བཀོད་རྟགས་ཤིག་གམ། Measuring progress in NLG relies on a constantly evolving ecosystem of automated metrics, datasets, and human evaluation standards. Due to this moving target, new models often evaluate on divergent anglo-centric corpora with well-established, but flawed, metrics. སྦྲེལ་མཐུད་འདི་ནི་ད་ལྟོའི་མ་དབྱིབས་དང་གོ་སྐབས་འཚོལ་དགོས་མཁན་དག་གི་ཚད་རྟགས་གཅིག་མཐུན་བཟོ་བཅུག་པ། GEM་གིས་ཚད་འདི་ལྟ་བུའི་ནང་དུ་མིག་གཟུགས་རིས་སྟངས་ལས་འཕགས་པ་ཞིག་བྱེད་ཐུབ་པའི་ཚད་གཞི་འདི་བསྒྲགས་བྱེད་ཀྱི་ཡོད་པ་རེད། རྒྱུན་ལྡན་མིག་གཟུགས་རིས་ཀྱི་ཆ་འཕྲིན་འགྱུར་བའི་ནང་དུ་NLG འཚོལ་ཞིབ་ཆགས་ནི་སྣ་མང་ཆེ་ཤོས་ཡོད་པ་དང་ མ་དཔེ་གཞི་དབ 2021ལ་སྤྱོད་པའི་ཤོག་བྱང་འདིས་འབྲེལ་བའི་GEM ལས་གནས་སྟངས་ལ་མཉམ་གསོག་སྡུད་ཀྱི་འགྲེལ་བཤད་ཀྱི་ཡོད།', 'he': 'אנו מכירים את GEM, רמז חי לגנרציה של שפות טבעיות (NLG), הערכה שלה, ומטריקס. למדוד התקדמות ב-NLG תלוי באקו-מערכת מתפתחת כל הזמן של מטריקה אוטומטית, קבוצות נתונים, וסטנדרטי הערכה אנושיים. בגלל המטרה הזאת, דוגמנים חדשים לעתים קרובות עדיין מעריכים על גופורה זווית-מרכזית שונה עם מטריקה מאושרת היטב, אבל פגומה. ההפסקה הזאת גורמת לאתגר לזהות את הגבלות של הדוגמנים הנוכחים וההזדמנויות להתקדמות. מתמודד עם הגבלה הזו, GEM מספק סביבה שבה דוגמנים יכולים בקלות להיות שימוש על קבוצה רחבה של משימות ובה אפשר לבדוק אסטרטגיות הערכה. העדכונים קבועים למרץ המייחס יעזרו למחקר NLG להיות יותר רבות שפות ותפתח את האתגר לצד דוגמנים. הנייר הזה משמש בתיאור הנתונים למשימה המשותפת של 2021 במסעדה GEM הקשורה.'}
{'en': 'Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation : A Case Study of the HuggingFace and GEM Data and Model Cards', 'ar': 'قوالب وأدلة قابلة لإعادة الاستخدام لتوثيق مجموعات البيانات والنماذج الخاصة بمعالجة اللغة الطبيعية وتوليدها: دراسة حالة لبيانات HuggingFace و GEM وبطاقات النماذج', 'fr': "Modèles et guides réutilisables pour la documentation d'ensembles de données et de modèles pour le traitement et la génération du langage naturel\xa0: une étude de cas sur les données et modèles HuggingFace et GEM", 'pt': 'Modelos e guias reutilizáveis para documentar conjuntos de dados e modelos para processamento e geração de linguagem natural: um estudo de caso dos dados e cartões modelo HuggingFace e GEM', 'es': 'Plantillas y guías reutilizables para documentar conjuntos de datos y modelos para el procesamiento y la generación de lenguaje natural: un estudio de caso de las tarjetas de datos y modelos de HuggingFace y GEM', 'hi': 'प्राकृतिक भाषा प्रसंस्करण और पीढ़ी के लिए डेटासेट और मॉडल के दस्तावेजीकरण के लिए पुन: प्रयोज्य टेम्पलेट्स और मार्गदर्शिकाएँ: HuggingFace और GEM डेटा और मॉडल कार्ड का एक केस स्टडी', 'ja': '自然言語処理と生成のためのデータセットとモデルを文書化するための再利用可能なテンプレートとガイド： HuggingFaceとGEMデータとモデルカードのケーススタディ', 'ru': 'Многоразовые шаблоны и руководства для документирования наборов данных и моделей для обработки и генерации на естественном языке: тематическое исследование данных и карт моделей HuggingFace и GEM', 'zh': '所以纪自然语言治成之数,可用模板南:HuggingFace 、 GEM 数、卡例', 'ga': 'Teimpléid agus Treoracha In-athúsáidte Chun Tacar Sonraí agus Múnlaí le haghaidh Próiseáil agus Giniúint Teanga Nádúrtha a Dhoiciméadú: Cás-staidéar ar Chártaí Sonraí agus Múnlaithe HuggingFace agus GEM', 'ka': 'შესაძლებელი შაბლონი და მონაცემები მონაცემების და მოდელების დოკუმენტირება და მოდელების გამოყენება: HuggingFace და GEM მონაცემების და მოდელური კაртების შესწავლება', 'el': 'Επαναχρησιμοποιήσιμα πρότυπα και οδηγοί για την τεκμηρίωση συνόλων δεδομένων και μοντέλων επεξεργασίας και δημιουργίας φυσικής γλώσσας: Μελέτη περίπτωσης των καρτών δεδομένων και προτύπων και προτύπων', 'hu': 'Újrahasználható sablonok és útmutatók adatkészletek és modellek dokumentálásához a természetes nyelv feldolgozásához és generálásához: esettanulmány a HuggingFace és a GEM adat- és modellkártyákról', 'it': "Modelli riutilizzabili e guide per la documentazione di set di dati e modelli per l'elaborazione e la generazione del linguaggio naturale: un caso di studio dei dati e modelli HuggingFace e GEM", 'kk': 'Құжаттау деректер мен қайта қолданылатын үлгілер мен бағыттаулар Nature Language Processing and Generation үлгілері: HuggingFace және GEM деректер және үлгілер карталарының кіші- кіші оқу', 'lt': 'Pakartotinai naudojami duomenų rinkinių ir gamtinės kalbos apdorojimo ir gamybos modelių dokumentavimo šablonai ir vadovai: HuggingFace ir GEM duomenų ir modelių kortelių atvejų tyrimas', 'mk': 'Повторно употребливи шаблони и водичи за документирање на датотеки и модели за процес и генерација на природен јазик: Студија на случаи на HuggingFace и GEM податоци и моделни картички', 'ms': 'Name', 'no': 'Gjenbrukbare mal og hjelpelinjer for dokumentering av databaser og modeller for naturspråk- handsaming og generering: Eit små bokstavar- studering av HuggingFace og GEM- data og modelkort', 'ml': 'Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards', 'mn': 'Байгалийн хэл процесс болон бүтээлтийн дахин ашиглах шалгалтууд болон загварууд: A Case Study of the HuggingFace, GEM Data and Model Cards for Documentation Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards', 'mt': 'Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards', 'ro': 'Șabloane reutilizabile și ghiduri pentru documentarea seturilor de date și modelelor pentru procesarea și generarea limbajului natural: un studiu de caz al cardurilor de date și modele HuggingFace și GEM', 'pl': 'Wielokrotnego użytku szablony i poradniki do dokumentowania zbiorów danych i modeli do przetwarzania i generowania języka naturalnego: studium przypadku kart danych i modeli HuggingFace i GEM', 'si': 'ප්\u200dරාකෘතික භාෂාව ප්\u200dරවෘතිකරණය සහ නිර්මාණය සඳහා දත්ත සැකසුම් සහ මොඩේල් සඳහා ප්\u200dරවෘතිකරණය සඳහා ප්\u200dරවෘතිකරණය සඳහා ප', 'sr': 'Prekorišteni šabloni i uputstvi za dokumentaciju datoteka i modela prirodnog procesa jezika i generacije: Proučavanje slučajeva HuggingFace i GEM podataka i modelnih kartica', 'so': 'Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the Hugging Face and GEM Data and Model Cards', 'sv': 'Återanvändbara mallar och guider för dokumentering av dataset och modeller för behandling och generering av naturligt språk: En fallstudie av HuggingFace och GEM data- och modellkort', 'ur': 'Name', 'ta': 'இயல்பான மொழி செயல்பாடு மற்றும் உருவாக்கத்திற்கான ஆவணப்படுத்தும் தகவல் அமைப்புகளுக்கான வார்ப்புருக்களும் வழிகாட்டு', 'vi': 'Tập hợp các mẫu và điển dẫn cho dữ liệu và mẫu đơn cung ứng ngôn ngữ tự nhiên: Một nghiên cứu về bộ đồ ôm và thẻ mô hình trang trí trang trí trang trí trang trí', 'uz': 'Name', 'bg': 'Шаблони за многократна употреба и ръководства за документиране на набори от данни и модели за обработка и генериране на естествен език: казус на карти за данни и модели', 'hr': 'Prekorišteni šabloni i uputstvi za dokumentaciju datoteka i modela prirodnog procesa jezika i generacije: Ispitivanje slučajeva HuggingFace i GEM podataka i modelnih kartica', 'nl': 'Herbruikbare sjablonen en gidsen voor het documenteren van datasets en modellen voor natuurlijke taalverwerking en -generatie: een casestudy van de HuggingFace- en GEM-gegevens en modelkaarten', 'da': 'Genbrugelige skabeloner og vejledninger til dokumentering af datasæt og modeller til behandling og generering af naturligt sprog: Et casestudie af HuggingFace og GEM data og modelkort', 'id': 'Model dan Panduan yang Boleh Digunakan untuk Dokumenkan Dataset dan Model untuk Proses dan Generasi Bahasa Alami: Sebuah Studi Kasus dari HuggingFace dan GEM Data dan Kartu Model', 'de': 'Wiederverwendbare Vorlagen und Leitfäden zur Dokumentation von Datensätzen und Modellen für die Verarbeitung und Generierung natürlicher Sprache: Eine Fallstudie der HuggingFace- und GEM-Daten- und Modellkarten', 'ko': '자연 언어 처리와 생성된 데이터 집합과 모델을 기록하는 데 사용되는 재사용 가능한 템플릿과 안내서:HuggingFace와 GEM 데이터와 모델 카드의 사례 연구', 'sw': 'Minamo na Miongozo yanayotumika kwa ajili ya Taarifa na Modeli kwa ajili ya Uendeshaji na Uzalishaji wa Lugha za asili: Utafiti wa Masuala ya HuggingFace na Data na Kards za Modeli za GEM', 'sq': 'Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards', 'am': "ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s", 'tr': 'Natal dil i힊le첵채n we Janla첵y힊 체챌in Ullany힊첵an 힇ablon we Nama첵y힊lyklar: A Case Study of the HuggingFace and GEM Data and Model Cards', 'hy': 'Վերօգտագործելի ձևագծեր և ուղղություններ բնական լեզվի վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ բնական լեզվի վերաբերյալ վերաբերյալ վերաբերյալ վերաբեր', 'af': "Hergebruikbaar Sjabloane en gidse vir Dokumentering Datatasse en Modelle vir Natuurlike Taal Prosessering en Generering: ' n Kas Leer van die HuggingFace en GEM Data en Model Kaart", 'bn': 'প্রাকৃতিক ভাষা প্রক্রিয়া এবং প্রজন্মের জন্য ডকুমেন্টিং ডাটা সেট এবং মোডেল ব্যবহৃত মন্দির এবং গাইডগুলো প্রয়োজন: হাগিং মুখ এবং জিএম ডাটা এবং ম', 'ca': 'Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards', 'cs': 'Opakovaně použitelné šablony a průvodce pro dokumentování datových sad a modelů pro zpracování a generování přirozeného jazyka: případová studie datových a modelových karet HuggingFace a GEM', 'et': 'Korduvkasutatavad mallid ja juhendid looduskeele töötlemise ja genereerimise andmekogumite ja mudelite dokumenteerimiseks: HuggingFace ja GEM andmete ja mudelikaartide juhtumiuuring', 'fi': 'Uudelleenkäytettävät mallit ja oppaat luonnollisen kielen prosessoinnin ja generoinnin tietoaineistojen ja mallien dokumentointiin: tapaustutkimus HuggingFace- ja GEM-datasta ja mallikorteista', 'fa': 'نمونه\u200cهای قابل استفاده و راهنمایی برای تحصیل داده\u200cها و مدل\u200cها برای پرداخت و تولید زبان طبیعی: یک مطالعه پرونده\u200cای از داده\u200cهای HuggingFace و GEM و کارت مدل', 'bs': 'Prekorišteni šabloni i uputstvi za dokumentaciju datoteka i modela prirodnog procesa jezika i generacije: Proučavanje slučajeva HuggingFace i GEM podataka i modelnih kartica', 'az': 'Təbiətli dil işləməsi və nəzəriyyəti üçün Dökümləndirilən Şablon və Rəstlər: HuggingFace və GEM Veriləri və Model Kartları Öyrənməsi', 'jv': 'Reusable temples and guides For Dokumentation data and model for Normal Language Proceding and Generation: A Case Learning of the huggigMask and GEM data and model Kars', 'ha': 'KCharselect unicode block name', 'he': 'דוגמנים ומדרכים שימושיים למסמך קבוצות נתונים ודוגמנים לעבודת וליצור שפות טבעיות: מחקר מקרים של המידע HuggingFace ומידע GEM וכרטיסי דוגמנים', 'sk': 'Predloge in vodniki za večkratno uporabo za dokumentiranje zbirk podatkov in modelov za obdelavo in ustvarjanje naravnega jezika: študija primera HuggingFace in GEM podatkovnih in modelov kartic', 'bo': 'Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards'}
{'en': 'Developing documentation guidelines and easy-to-use templates for datasets and models is a challenging task, especially given the variety of backgrounds, skills, and incentives of the people involved in the building of natural language processing (NLP) tools. Nevertheless, the adoption of standard documentation practices across the field of NLP promotes more accessible and detailed descriptions of NLP datasets and models, while supporting researchers and developers in reflecting on their work. To help with the standardization of documentation, we present two case studies of efforts that aim to develop reusable documentation templates   the HuggingFace data card, a general purpose card for datasets in NLP, and the GEM benchmark data and model cards with a focus on natural language generation. We describe our process for developing these templates, including the identification of relevant stakeholder groups, the definition of a set of guiding principles, the use of existing templates as our foundation, and iterative revisions based on feedback.', 'ar': 'يعد تطوير إرشادات التوثيق والقوالب سهلة الاستخدام لمجموعات البيانات والنماذج مهمة صعبة ، لا سيما بالنظر إلى تنوع الخلفيات والمهارات والحوافز للأشخاص المشاركين في بناء أدوات معالجة اللغة الطبيعية (NLP). ومع ذلك ، فإن اعتماد ممارسات التوثيق القياسية عبر مجال البرمجة اللغوية العصبية (NLP) يعزز الوصول إلى أوصاف أكثر تفصيلاً ومجموعات بيانات ونماذج البرمجة اللغوية العصبية ، مع دعم الباحثين والمطورين في التفكير في عملهم. للمساعدة في توحيد التوثيق ، نقدم دراستي حالة للجهود التي تهدف إلى تطوير قوالب توثيق قابلة لإعادة الاستخدام - بطاقة بيانات HuggingFace ، وبطاقة للأغراض العامة لمجموعات البيانات في البرمجة اللغوية العصبية ، وبيانات معيار GEM وبطاقات النماذج مع التركيز على الطبيعي جيل اللغة. نحن نصف عمليتنا لتطوير هذه النماذج ، بما في ذلك تحديد مجموعات أصحاب المصلحة ذات الصلة ، وتعريف مجموعة من المبادئ التوجيهية ، واستخدام القوالب الموجودة كأساس لدينا ، والمراجعات المتكررة بناءً على التعليقات.', 'fr': "L'élaboration de directives de documentation et de modèles faciles à utiliser pour les ensembles de données et les modèles est une tâche difficile, en particulier compte tenu de la diversité des antécédents, des compétences et des incitations des personnes impliquées dans la création d'outils de traitement du langage naturel (NLP). Néanmoins, l'adoption de pratiques de documentation standard dans le domaine de la PNL favorise des descriptions plus accessibles et plus détaillées des ensembles de données et des modèles de PNL, tout en aidant les chercheurs et les développeurs à réfléchir sur leurs travaux. Pour faciliter la standardisation de la documentation, nous présentons deux études de cas d'efforts visant à développer des modèles de documentation réutilisables\xa0: la carte de données HuggingFace, une carte à usage général pour les ensembles de données en PNL, et les données de référence GEM et les cartes modèles axées sur la génération du langage naturel. Nous décrivons notre processus de développement de ces modèles, y compris l'identification des groupes de parties prenantes concernés, la définition d'un ensemble de principes directeurs, l'utilisation des modèles existants comme base, et les révisions itératives basées sur les commentaires.", 'pt': 'Desenvolver diretrizes de documentação e modelos fáceis de usar para conjuntos de dados e modelos é uma tarefa desafiadora, especialmente devido à variedade de origens, habilidades e incentivos das pessoas envolvidas na construção de ferramentas de processamento de linguagem natural (PLN). No entanto, a adoção de práticas de documentação padrão em todo o campo da PNL promove descrições mais acessíveis e detalhadas de conjuntos de dados e modelos de PNL, ao mesmo tempo em que apoia pesquisadores e desenvolvedores na reflexão sobre seu trabalho. Para ajudar na padronização da documentação, apresentamos dois estudos de caso de esforços que visam desenvolver modelos de documentação reutilizáveis – o cartão de dados HuggingFace, um cartão de uso geral para conjuntos de dados em PNL, e os cartões de dados e modelos de benchmark GEM com foco em natural geração da linguagem. Descrevemos nosso processo para desenvolver esses modelos, incluindo a identificação de grupos de partes interessadas relevantes, a definição de um conjunto de princípios orientadores, o uso de modelos existentes como nossa base e revisões iterativas com base em feedback.', 'es': 'Desarrollar pautas de documentación y plantillas fáciles de usar para conjuntos de datos y modelos es una tarea difícil, especialmente dada la variedad de antecedentes, habilidades e incentivos de las personas involucradas en la creación de herramientas de procesamiento del lenguaje natural (NLP). Sin embargo, la adopción de prácticas de documentación estándar en todo el campo de la PNL promueve descripciones más accesibles y detalladas de los conjuntos de datos y modelos de PNL, al tiempo que ayuda a los investigadores y desarrolladores a reflexionar sobre su trabajo. Para ayudar con la estandarización de la documentación, presentamos dos estudios de casos de esfuerzos que tienen como objetivo desarrollar plantillas de documentación reutilizables: la tarjeta de datos HuggingFace, una tarjeta de propósito general para conjuntos de datos en PNL y los datos de referencia GEM y las tarjetas modelo con un enfoque en la generación de lenguaje natural. Describimos nuestro proceso para desarrollar estas plantillas, incluida la identificación de los grupos de partes interesadas pertinentes, la definición de un conjunto de principios rectores, el uso de plantillas existentes como base y revisiones iterativas basadas en los comentarios.', 'ja': 'データセットとモデルのための文書ガイドラインと使いやすいテンプレートを開発することは、特に自然言語処理（ NLP ）ツールの構築に関わる人々のさまざまな背景、スキル、およびインセンティブを考慮すると、困難な作業です。 それにもかかわらず、NLPの分野全体にわたる標準的な文書実践の採用は、NLPデータセットとモデルのよりアクセスしやすく詳細な説明を促進すると同時に、研究者と開発者の仕事を振り返ることを支援します。 ドキュメントの標準化を支援するために、再利用可能なドキュメントテンプレートの開発を目的とした2つのケーススタディをご紹介します。NLPのデータセット用の汎用カードであるHuggingFaceデータカードと、自然言語生成に焦点を当てたGEMベンチマークデータとモデルカードです。 関連するステークホルダーグループの特定、一連の指針の定義、既存のテンプレートの基礎としての使用、フィードバックに基づく反復的な改訂を含む、これらのテンプレートを開発するためのプロセスについて説明します。', 'zh': '为数集模开文档指南易用者模板一有挑战性之任,特虑与构自然语言处(NLP)具者众背景,技能激劝。 虽然,NLP域用准文档践进NLP数集与模形者易访详,兼赞治开发人员而思之。 助文档之标准化,言两旨在开文档模板之例,究 - HuggingFace数据卡,施于NLP数之通用卡,及GEM准数卡,重自然语言生成。 述其模板事,定其利相关者群体,定义一道,用现模板为基,因反馈迭代修。', 'hi': 'डेटासेट और मॉडल के लिए प्रलेखन दिशानिर्देशों और उपयोग में आसान टेम्पलेट्स विकसित करना एक चुनौतीपूर्ण कार्य है, विशेष रूप से प्राकृतिक भाषा प्रसंस्करण (एनएलपी) उपकरणों के निर्माण में शामिल लोगों की पृष्ठभूमि, कौशल और प्रोत्साहन की विविधता को देखते हुए। फिर भी, एनएलपी के क्षेत्र में मानक प्रलेखन प्रथाओं को अपनाने से एनएलपी डेटासेट और मॉडल के अधिक सुलभ और विस्तृत विवरण को बढ़ावा मिलता है, जबकि शोधकर्ताओं और डेवलपर्स को उनके काम पर प्रतिबिंबित करने में समर्थन मिलता है। प्रलेखन के मानकीकरण में मदद करने के लिए, हम उन प्रयासों के दो मामले के अध्ययन प्रस्तुत करते हैं जिनका उद्देश्य पुन: प्रयोज्य प्रलेखन टेम्पलेट्स विकसित करना है - हगिंगफेस डेटा कार्ड, एनएलपी में डेटासेट के लिए एक सामान्य उद्देश्य कार्ड, और प्राकृतिक भाषा पीढ़ी पर ध्यान केंद्रित करने के साथ जीईएम बेंचमार्क डेटा और मॉडल कार्ड। हम इन टेम्पलेट्स को विकसित करने के लिए अपनी प्रक्रिया का वर्णन करते हैं, जिसमें प्रासंगिक हितधारक समूहों की पहचान, मार्गदर्शक सिद्धांतों के एक सेट की परिभाषा, हमारी नींव के रूप में मौजूदा टेम्पलेट्स का उपयोग, और प्रतिक्रिया के आधार पर पुनरावर्ती संशोधन शामिल हैं।', 'ru': 'Разработка руководств по документации и простых в использовании шаблонов для наборов данных и моделей является сложной задачей, особенно с учетом разнообразия биографических данных, навыков и стимулов людей, участвующих в создании инструментов обработки естественного языка (NLP). Тем не менее, принятие стандартных методов документирования в области NLP способствует более доступному и детальному описанию наборов данных и моделей NLP, одновременно поддерживая исследователей и разработчиков в размышлениях о своей работе. Чтобы помочь в стандартизации документации, мы представляем два тематических исследования усилий, направленных на разработку многоразовых шаблонов документации – карточка данных HuggingFace, карточка общего назначения для наборов данных в NLP, а также эталонные данные GEM и типовые карточки с акцентом на генерацию естественного языка. Мы описываем наш процесс разработки этих шаблонов, включая определение соответствующих групп заинтересованных сторон, определение набора руководящих принципов, использование существующих шаблонов в качестве нашей основы и итеративные пересмотры на основе обратной связи.', 'ga': 'Is tasc dúshlánach é treoirlínte doiciméadaithe agus teimpléid éasca le húsáid a fhorbairt le haghaidh tacair shonraí agus mhúnlaí, go háirithe i bhfianaise éagsúlacht na gcúlraí, na scileanna agus na spreagthaí atá ag na daoine a bhfuil baint acu le tógáil uirlisí próiseála teanga nádúrtha (NLP). Mar sin féin, trí chleachtais chaighdeánacha doiciméadaithe a ghlacadh ar fud réimse an NLP, cuirtear chun cinn tuairiscí níos insroichte agus níos mionsonraithe ar thacair sonraí agus samhlacha NLP, agus ag an am céanna tacaítear le taighdeoirí agus le forbróirí machnamh a dhéanamh ar a gcuid oibre. Chun cabhrú le doiciméadú a chaighdeánú, cuirimid i láthair dhá chás-staidéar ar iarrachtaí a bhfuil sé mar aidhm leo teimpléid doiciméadaithe ath-inúsáidte a fhorbairt – an cárta sonraí HuggingFace, cárta ginearálta sainchuspóireach le haghaidh tacair shonraí in NLP, agus sonraí tagarmharcála GEM agus cártaí samhlacha le fócas ar nádúrtha. glúin teanga. Déanaimid cur síos ar ár bpróiseas chun na teimpléid seo a fhorbairt, lena n-áirítear sainaithint na ngrúpaí páirtithe leasmhara ábhartha, sainmhíniú ar thacar treoirphrionsabail, úsáid na dteimpléad atá ann cheana mar bhunchloch dúinn, agus athbhreithnithe atriallacha bunaithe ar aiseolas.', 'el': "Η ανάπτυξη κατευθυντήριων γραμμών τεκμηρίωσης και εύχρηστων προτύπων για σύνολα δεδομένων και μοντέλα είναι ένα δύσκολο έργο, ειδικά δεδομένου της ποικιλίας υποβάθρου, δεξιοτήτων και κινήτρων των ανθρώπων που εμπλέκονται στην κατασκευή εργαλείων επεξεργασίας φυσικής γλώσσας. Παρ' όλα αυτά, η υιοθέτηση τυποποιημένων πρακτικών τεκμηρίωσης σε όλο τον τομέα της προωθεί πιο προσβάσιμες και λεπτομερείς περιγραφές των συνόλων δεδομένων και μοντέλων, ενώ υποστηρίζει τους ερευνητές και τους προγραμματιστές στο να προβληματιστούν για το έργο τους. Για να βοηθήσουμε στην τυποποίηση της τεκμηρίωσης, παρουσιάζουμε δύο μελέτες περιπτώσεων προσπαθειών που στοχεύουν στην ανάπτυξη επαναχρησιμοποιήσιμων προτύπων τεκμηρίωσης: την κάρτα δεδομένων μια κάρτα γενικής χρήσης για σύνολα δεδομένων στο και τις κάρτες αναφοράς δεδομένων και υποδειγμάτων με έμφαση στην παραγωγή φυσικής γλώσσας. Περιγράφουμε τη διαδικασία ανάπτυξης αυτών των προτύπων, συμπεριλαμβανομένου του εντοπισμού των σχετικών ομάδων ενδιαφερομένων, του ορισμού ενός συνόλου κατευθυντήριων αρχών, της χρήσης των υφιστάμενων προτύπων ως θεμέλιό μας και επαναλαμβανόμενων αναθεωρήσεων με βάση τα σχόλια.", 'hu': 'Az adatkészletek és modellek dokumentációs iránymutatásainak és egyszerűen használható sablonjainak kidolgozása kihívást jelent, különösen a természetes nyelvfeldolgozó eszközök kiépítésében részt vevők sokféle hátterére, készségére és ösztönzőire tekintettel. Mindazonáltal a szabványos dokumentációs gyakorlatok bevezetése az NLP területén előmozdítja az NLP adatkészleteinek és modelleinek hozzáférhetőbb és részletesebb leírását, miközben támogatja a kutatókat és a fejlesztőket a munkájuk átgondolásában. A dokumentáció szabványosításának elősegítése érdekében két esettanulmányt mutatunk be az újrafelhasználható dokumentációs sablonok kidolgozására irányuló erőfeszítésekről: a HuggingFace adatkártyát, amely az NLP adatkészleteihez szükséges általános célú kártyát, valamint a GEM referenciaadatokat és modellkártyákat a természetes nyelv generálására összpontosítva. Leírjuk ezen sablonok fejlesztésének folyamatát, beleértve a releváns érdekeltcsoportok azonosítását, iránymutató elvek meghatározását, a meglévő sablonok alapként való használatát, valamint a visszajelzéseken alapuló iteratív revíziókat.', 'it': "Sviluppare linee guida per la documentazione e modelli di facile utilizzo per set di dati e modelli è un compito impegnativo, soprattutto data la varietà di background, competenze e incentivi delle persone coinvolte nella costruzione di strumenti di elaborazione del linguaggio naturale (PNL). Tuttavia, l'adozione di pratiche di documentazione standard nel campo della PNL promuove descrizioni più accessibili e dettagliate dei set di dati e dei modelli PNL, supportando ricercatori e sviluppatori nella riflessione sul loro lavoro. Per aiutare nella standardizzazione della documentazione, presentiamo due casi di studio degli sforzi volti a sviluppare modelli di documentazione riutilizzabili: la scheda dati HuggingFace, una scheda di uso generale per set di dati in PNL, e le schede di riferimento GEM e modelli con particolare attenzione alla generazione del linguaggio naturale. Descriviamo il nostro processo di sviluppo di questi modelli, tra cui l'identificazione dei gruppi di stakeholder rilevanti, la definizione di una serie di principi guida, l'uso di modelli esistenti come base e revisioni iterative basate su feedback.", 'ka': 'დოკუმენტის მისამართების და ადვილად გამოყენებელი შაბლონების განვითარება მოდენტებისთვის და მოდენტებისთვის შესაძლებელი რაოდენობა, სხვადასხვადასხვადასხვადასხვა ფონდა, მეცნიერების და ინტერტიგების განვითარება, რომელიც მაგრამ, NLP- ის ფართობაში სტანდარტური დოკუმენტის პრაქტიკურების გავაკეთება NLP მონაცემების და მოდელების უფრო მეტი დახმარებელი და დარწმუნებელი აღწერები, რომლებიც მსწავლობელი და განვითა დოკუმენტის სტანდარტაციაზე დახმარება, ჩვენ ჩვენ გამოყენებთ ორი მოცემების სწავლა, რომელიც უნდა გამოყენება შესაძლებელი დოკუმენტის შაბლონების განვითარება - HuggingFace მონაცემების კაртტი, NLP-ში საერთო მისამართლ ჩვენ ჩვენი პროცესი ამ შაბლონების განვითარებისთვის გამოყენება, შესახებ შესაძლებელი ინტერეტიფიკაციის ჯგუფების განსაზღვრება, პროცესების განსაზღვრება, არსებობს შაბლონების გამოყენება როგორც ჩვენი ფუ', 'lt': 'Developing documentation guidelines and easy-to-use templates for datasets and models is a challenging task, especially given the variety of backgrounds, skills, and incentives of the people involved in the building of natural language processing (NLP) tools.  Vis dėlto standartinės dokumentacijos praktikos priėmimas visose NLP srityse skatina prieinamesnius ir išsamesnius NLP duomenų rinkinių ir modelių aprašymus, kartu remia mokslininkus ir vystytojus svarstyti apie jų darbą. Kad padėtume standartizuoti dokumentus, pateiksime du atvejų tyrimus, kuriuose nagrinėjamos pastangos sukurti pakartotinai naudojamus dokumentų šablonus - HuggingFace duomenų kortelę, NLP duomenų rinkinių bendrąjį tikslą, GEM lyginamuosius duomenis ir modelines korteles, daugiausia dėmesio skiriant gamtinei kalbų kūrimui. We describe our process for developing these templates, including the identification of relevant stakeholder groups, the definition of a set of guiding principles, the use of existing templates as our foundation, and iterative revisions based on feedback.', 'ms': 'Pembangunan panduan dokumentasi dan templat mudah digunakan untuk set data dan model adalah tugas yang mencabar, terutama mengingat berbagai latar belakang, keterampilan, dan insentif orang yang terlibat dalam membina alat pemprosesan bahasa semulajadi (NLP). Namun, penerimaan praktik dokumentasi piawai di seluruh medan NLP mempromosikan deskripsi yang lebih mudah dan terperinci bagi set data NLP dan model, sementara menyokong penyelidik dan pembangun dalam merefleksikan kerja mereka. Untuk membantu dengan standardisasi dokumentasi, kami memperkenalkan dua kajian kes usaha yang bertujuan untuk mengembangkan templat dokumentasi yang boleh digunakan semula - kad data HuggingFace, kad tujuan umum untuk set data dalam NLP, dan data benchmark GEM dan kad model dengan fokus pada generasi bahasa biasa. Kami menggambarkan proses kami untuk mengembangkan templat ini, termasuk pengenalan kumpulan stakeholders yang berkaitan, definisi set prinsip panduan, penggunaan templat yang wujud sebagai dasar kami, dan revisi ulang berdasarkan balas balik.', 'mt': "Developing documentation guidelines and easy-to-use templates for datasets and models is a challenging task, especially given the variety of backgrounds, skills, and incentives of the people involved in the building of natural language processing (NLP) tools.  Nevertheless, the adoption of standard documentation practices across the field of NLP promotes more accessible and detailed descriptions of NLP datasets and models, while supporting researchers and developers in reflecting on their work.  To help with the standardization of documentation, we present two case studies of efforts that aim to develop reusable documentation templates - the HuggingFace data card, a general purpose card for datasets in NLP, and the GEM benchmark data and model cards with a focus on natural language generation.  Aħna niddeskrivu l-proċess tagħna għall-iżvilupp ta' dawn il-mudelli, inkluża l-identifikazzjoni ta' gruppi rilevanti ta' partijiet interessati, id-definizzjoni ta' sett ta' prinċipji gwida, l-użu ta' mudelli eżistenti bħala l-bażi tagħna, u reviżjonijiet iterattivi bbażati fuq ir-reazzjonijiet.", 'mn': 'Байгалийн хэл процесс (NLP) хэрэгсэл барилгын бүтээлд оролцсон хүмүүсийн олон түвшин, чадвар, урам зориулалт болон урам зориулалт болон өгөгдлийн сангууд болон загваруудын хувьд амархан ашиглах шаардлагатай шаардлагатай ажил юм. Гэвч NLP салбарын стандарт документацийн дасгал хийх нь NLP өгөгдлийн санг, загваруудыг илүү ашиглах болон нарийвчлан тайлбарлах боломжтой болгодог. Документын стандартизацийн тусламжтайгаар туслахын тулд бид дахин ашиглах баримт бичил баримт шалгалтыг хөгжүүлэх зорилготой хоёр тохиолдол судалгааг үзүүлнэ. HuggingFace өгөгдлийн карт, NLP-д өгөгдлийн сангийн ерөнхий зорилго карт, GEM байгалийн хэл бүтэ Бид эдгээр загваруудыг хөгжүүлэх процессийг тайлбарлаж байна. Харин хамааралтай холбоотой бүлгүүдийн тодорхойлолт, удирдагч зарчмын тодорхойлолт, суурилсан загваруудын хэрэглээ бидний суурилуулалт болон хариу үйлдэл дээр үндсэн дахин', 'ml': 'ഡാറ്റാസറ്റുകള്\u200dക്കും മോഡലുകള്\u200dക്കും രേഖപ്പെടുത്താനുള്ള രേഖകളുടെ വഴികാട്ടികളും ഉപയോഗിക്കാന്\u200d എളുപ്പമുള്ള മാതൃകങ്ങളും സങ്കല്\u200dപ്പിക്കുന്നത് വിലപിടിക്കു എന്നാലും NLP പ്രദേശത്ത് മുഴുവന്\u200d സ്ഥാനമായ രേഖകളുടെ പ്രവര്\u200dത്തനങ്ങള്\u200d പ്രാവര്\u200dത്തിപ്പിക്കുന്നത് കൂടുതല്\u200d വിശദീകരിക്കുന്നതും വിശദീകരിക്കുന്നതും NLP ഡാറ്റ രേഖകളുടെ സ്ഥാനത്തില്\u200d നിന്നും സഹായിക്കാന്\u200d ഞങ്ങള്\u200d രണ്ടു കേസ് ശ്രമിക്കുന്നു. വീണ്ടും ഉപയോഗിക്കുവാന്\u200d ഉദ്ദേശിക്കുന്ന രേഖകളുടെ രേഖകള്\u200d നിര്\u200dമ്മിക്കുവാന്\u200d ഉദ്ദേശിക്കുന് ഈ മാതൃകങ്ങള്\u200d നിര്\u200dമ്മിക്കുന്നതിനായി നമ്മുടെ പ്രക്രിയയെ വിവരിച്ചുകൊടുക്കുന്നു. വിലാസപൂര്\u200dണ്ണമായ സ്റ്റേക്കെര്\u200dവറുകളുടെ തിരിച്ചറിയാന്\u200d, ഒരു കൂ', 'kk': 'Деректер және үлгілер үшін құжаттамасын бағыттау жолдары және қолдануға оңай үлгілер үлгілерін жасау - әсіресе, табиғи тіл процессорын құру құрылғындағы адамдардың әртүрлі аясы, кәсіліктері және стимуттары. Бірақ NLP өрісінде стандартты құжаттамасының практикасын қабылдау үшін NLP деректер қорларының мен моделдерінің көбірек және егжей- тегжейі сипаттамасын көмектеседі, зерттеушілері мен жасаушыларының жұмысына қа Құжаттамасын стандартизациялауға көмектесу үшін, қайта қолданылатын құжаттамасын үлгілеу үшін, HuggingFace деректер картасы, NLP деректер қорларының жалпы мақсатты картасы және GEM белгілеу деректері мен үлгілер картасын табиғи тілдерді құру ү Біз бұл үлгілерді жасау процесімізді, сондай-ақ қатысушылардың топтарды идентификациялауын, басқару принциптерін, бар үлгілерді біздің негізгі ретінде қолдануға және қайталануға негізделген қайталануларды, анықтаймыз.', 'no': 'Utvikling av hjelpelinjer for dokumentasjon og enkelt bruk av maler for datasett og modeller er eit vanskeleg oppgåve, spesielt gjeven forskjellige bakgrunnslar, ferdigheiter og stimuleringar for folk som er involvert i bygging av naturspråksverktøy (NLP). I tillegg til at standard dokumentasjonsprøytebruk gjennom NLP-feltet gjer tilgjengelege og detaljerte skildringar av NLP-datasett og modeller, medan forskere og utviklarar støttar i refleksjon av arbeidet sine. For å hjelpa med standardisering av dokumentasjonen, presenterer vi to tilfeldige studiar av forsøk som må utvikla gjenopprettbare dokumentasjonsmalar – HuggingFace-datakortet, eit generell målkort for datasett i NLP, og GEM-benchmark data og modelkort med fokus på naturspråk. Vi beskriver prosessen vårt for å utvikla desse malene, inkludert identifikasjonen av relevante stakeholdergrupper, definisjonen av eit sett hjelpeprinsipper, bruken av eksisterande malar som fundamentet vårt, og gjentakingar basert på tilbakemeldingar.', 'sr': 'Razvoj uputstva dokumentacije i lako korištenje šablona za sete podataka i modele je izazovan zadatak, posebno s obzirom na razne pozadine, vještine i podsticaje ljudi koji su uključeni u izgradnju alata prirodnog obrade jezika (NLP). Ipak, usvajanje standardnih dokumentacijskih prakse širom polja NLP promovira dostupnije i detaljnije opise seta podataka i modela NLP-a, dok podržavaju istraživače i razvojnike u razmišljanju o njihovom radu. Da bi pomogli sa standardizacijom dokumentacije, predstavljamo dva slučaja ispitivanja napora koje su ciljeve da razviju ponovno korištene dokumentacijske template - kartice podataka HuggingFace, opšte svrhe kartice za sete podataka u NLP-u, i podatke i kartice GEM-a sa fokusom na generaciju prirodnog jezika. Opišemo svoj proces razvoja tih hramena, uključujući identifikaciju relevantnih grupa zainteresovanih strana, definiciju set a vodećih principa, upotrebu postojećih hramena kao našu temelj i iterativne revizije na osnovu reakcije.', 'pl': 'Opracowanie wytycznych dokumentacyjnych i łatwych w użyciu szablonów zbiorów danych i modeli jest trudnym zadaniem, zwłaszcza biorąc pod uwagę różnorodność środowisk, umiejętności i zachęt osób zaangażowanych w budowę narzędzi do przetwarzania języka naturalnego (NLP). Niemniej jednak przyjęcie standardowych praktyk dokumentacyjnych w obszarze NLP promuje bardziej dostępne i szczegółowe opisy zbiorów danych i modeli NLP, a jednocześnie wspiera naukowców i deweloperów w refleksji nad ich pracą. Aby pomóc w standaryzacji dokumentacji, przedstawiamy dwa studia przypadków działań mających na celu opracowanie wielokrotnego użytku szablonów dokumentacji: kartę danych HuggingFace, kartę ogólnego przeznaczenia dla zbiorów danych w NLP oraz kartę danych i modeli GEM z naciskiem na generowanie języka naturalnego. Opisujemy nasz proces tworzenia tych szablonów, w tym identyfikację odpowiednich grup interesariuszy, definicję zestawu zasad wytycznych, wykorzystanie istniejących szablonów jako podstawy oraz iteracyjne korekty oparte na opinii zwrotnej.', 'mk': 'Развојувањето на насоки за документација и лесни шаблони за употреба за компјутери и модели на податоци е предизвикувачка задача, особено со оглед на различната позадина, вештини и стимулирања на луѓето вклучени во изградбата на алатки за природно обработување јазик (НЛП Сепак, усвојувањето на стандардните практики на документација низ целото поле на НЛП промовира попристапни и детални описи на наборите на податоци и моделите на НЛП, истовремено поддржувајќи ги истражувачите и развивачите во размислувањето за нивната работа За да помогнеме во стандардизацијата на документацијата, претставуваме две случаи студии на напорите кои имаат за цел развој на повторно употребливи шаблони на документација - картичката за податоци HuggingFace, картичка за општи цели за податоци во NLP, и германските податоци за benchmark и моделни картички со фокус на Ние го опишуваме нашиот процес за развој на овие шаблони, вклучувајќи ја идентификацијата на релевантните групи на интересни страни, дефиницијата на сет водечки принципи, употребата на постојните шаблони како наша основа, и повторни ревизии базирани на враќање на', 'ro': 'Dezvoltarea orientărilor privind documentația și a șabloanelor ușor de utilizat pentru seturi de date și modele este o sarcină dificilă, în special având în vedere varietatea de medii, competențe și stimulente ale persoanelor implicate în construirea instrumentelor de prelucrare a limbajului natural (PNL). Cu toate acestea, adoptarea practicilor standard de documentare în domeniul PNL promovează descrieri mai accesibile și mai detaliate ale seturilor de date și modelelor PNL, sprijinind totodată cercetătorii și dezvoltatorii în reflecția asupra activității lor. Pentru a ajuta la standardizarea documentației, prezentăm două studii de caz privind eforturile care vizează dezvoltarea șabloanelor de documentație reutilizabile - cardul de date HuggingFace, un card de uz general pentru seturi de date în PNL, și cardurile de referință GEM și cardurile de model cu accent pe generarea limbajului natural. Descriem procesul nostru de dezvoltare a acestor șabloane, inclusiv identificarea grupurilor relevante de părți interesate, definirea unui set de principii directoare, utilizarea șabloanelor existente ca fundație și revizuiri iterative bazate pe feedback.', 'sv': 'Att utveckla riktlinjer för dokumentation och lättanvända mallar för datauppsättningar och modeller är en utmanande uppgift, särskilt med tanke på de olika bakgrunder, färdigheter och incitament som människor som är involverade i att bygga upp verktyg för behandling av naturligt språk (NLP). Antagandet av standardiserade dokumentationsmetoder inom området för NLP främjar dock mer tillgängliga och detaljerade beskrivningar av NLP-datauppsättningar och -modeller, samtidigt som forskare och utvecklare kan reflektera över sitt arbete. För att hjälpa till med standardiseringen av dokumentation presenterar vi två fallstudier av insatser som syftar till att utveckla återanvändbara dokumentationsmallar - HuggingFace datakort, ett allmänt användningskort för datauppsättningar i NLP, samt GEM benchmark data och modellkort med fokus på generering av naturligt språk. Vi beskriver vår process för att utveckla dessa mallar, inklusive identifiering av relevanta intressentgrupper, definition av en uppsättning vägledande principer, användning av befintliga mallar som grund och iterativa revideringar baserade på feedback.', 'so': 'Horumarinta hagitaanka dukumentiyada iyo meelaha lagu isticmaali karo sahlan oo lagu isticmaali karo macluumaadka iyo tusaalayaasha waa shaqa dhibaataysan, khusuusan lagu siiyo sabab-horaadyo kala duduwan, xirfadaha, iyo incentiisa dadka ka qaba dhisidda qalabka baaritaanka afka dabiiciga (NLP). Si kastaba ha ahaatee, korsashada qalabka dukumentiyada ee standardka ah ee duurka NLP wuxuu horumariyaa mid ka sii sawiraan oo faa’iido ah oo ka mid ah qoraalka shabakada iyo modellada NLP, isagoo taageeraya cilmi-baarayaasha iyo horumarinta si ay shuqulkooda uga fikiraan. Si aan ugu caawiyo standardization of documentation, waxaan keenaynaa labo waxbarasho oo isku dayaya in loo hormariyo qoraalka documentation oo la isticmaali karo - kaarka HuggingFace data, kaarka caadiga ah oo u qoran karta macluumaadka NLP, iyo data bangiga iyo kaararka modelka ee GEM, kaas oo focus ugu leh qarniga afka dabiicadda ah. Waxaynu qoraynaa baaraandegista horumarinta macluumaadyadan, kuwaas oo ah aqoonsiga kooxda shaqaalaha la xiriira, sawirida shuruudaha hagitaanka, isticmaalka macluumaadka joogta sida asalkayaga, iyo beddelinta dib u dhigista.', 'ta': 'தகவல் அமைப்புகளுக்கும் மாதிரிகளுக்கும் சுலபமான பயன்படுத்த வார்ப்புருக்களை உருவாக்குதல் மற்றும் சுலபமாக பயன்படுத்துதல் செயல்கள் ஒரு சவாலிக்கக்கூடிய செயல், குறிப ஆனாலும், NLP புலத்தில் முழுவதும் நிலையான ஆவணங்கள் செயல்பாடுகளை பயன்படுத்தி NLP தரவுத்தளங்கள் மற்றும் மாதிரிகளின் விவரங்களை மேம்படுத்துகிறது, ஆராய்ச் ஆவணத்தின் நிலைமைப்படுத்தலை உதவி, மீண்டும் பயன்படுத்தக்கூடிய ஆவண வார்ப்புருவை உருவாக்குவதற்கு நாம் முயற்சிகளின் இரண்டு நிலையான ஆய்வுகளை கொண்டு வருகிறோம் - HuggingFace data card, NLP-ல நாம் இந்த வார்ப்புருவை உருவாக்குவதற்கான எங்கள் செயல்பாடு விவரிக்கிறோம், தொடர்புடைய குழுவின் அடையாளத்தை கொண்டு தேர்ந்தெடுக்கப்பட்டுள்ளது, ஒரு குறி', 'ur': 'ڈاٹ سٹ اور موڈل کے لئے آسان استعمال کرنے کے لئے ڈاکسیٹ منڈلانین کی ہدایت لینڈ اور آسان استعمال کے لئے ٹیپلٹ ڈھیلوں کا ایک مشکل کام ہے، مخصوصاً ان لوگوں کی مختلف پکنے والی، فکرت اور انگیزی کے ذریعہ سے جنہوں نے طبیعی زبان پرسس (NLP لیکن NLP کے میدان میں استاندارڈ ڈیٹسٹ اور نمڈلوں کے مطابق استاندارڈ ڈیٹسٹ اور نمڈلوں کے مطابق استعمال کی تعلیم کے مطابق NLP ڈیٹسٹ اور ڈیٹسٹ کے مطابق بہت زیادہ دسترسی اور مفصل کی توصیف کرتی ہے، اور ہم نے دکھانے کی استاندارڈیزٹ کی مدد کے لئے دو کیس مطالعہ کے مطالعہ پیش کیے ہیں جو دوبارہ استعمال کرنے والے دکھانے والی دکھانے والی ٹیموٹ ٹیموٹ ڈیٹ کارڈ، NLP میں ڈیٹ سٹ کے لئے ایک عمومی موجب کارڈ اور GEM بنچم مارک ڈیٹ اور موڈل کارڈ کو طبیع ہم نے ان ٹیپلٹوں کو ایجاد کرنے کے لئے اپنی پروسس کی تعریف کرتی ہے، جو تعلق داروں گروہوں کی تعریف ہے، ہدایت کے قانون کی تعریف ہے، موجود ٹیپلٹوں کا استعمال ہماری بنیاد کے طور پر، اور فیڈبک پر بنیاد رکھنے والی دوبارہ تغییرات ہے.', 'si': 'දත්ත සඳහා මොඩල් සඳහා ලේසිය ප්\u200dරයෝජනය සහ ප්\u200dරයෝජනය විකාශ කරන්න ප්\u200dරශ්නයක් විශ්වාස කරනවා, විශේෂයෙන් පිළිබඳ පිළිබඳ පිළිබඳ, කුළුවන නමුත්, NLP ක්\u200dෂේත්\u200dරයේ ප්\u200dරමාණික දත්ත ප්\u200dරයෝජනය සහ විස්තර විස්තරයක් NLP දත්ත සැකසුම් සහ මෝඩේල් සඳහා පරීක්ෂකයෝ සහ විකාශකයෝ සහ ව ලිපිනයේ ස්ථාපනය සඳහා උදව් කරන්න, අපි ප්\u200dරයෝජනය කරන්න පුළුවන් ලිපිනය සඳහා ප්\u200dරයෝජනය දෙකක් ප්\u200dරයෝජනය කරන්න පුළුවන් ලිපිනය සඳහා ප්\u200dරයෝජනය කරන්න පුළුවන්  අපි මේ ටෙම්ප්ලේට්ස් විස්තර කරන්න අපේ ප්\u200dරක්\u200dරියාව විස්තර කරනවා, සම්බන්ධ සැකසුම්පත් කණ්ඩායම්පතියේ පරීක්ෂණය සම්බන්ධ වෙනුවෙන්, ප්\u200dරත', 'vi': 'Việc phát triển hướng dẫn tài liệu và các mẫu dễ sử dụng cho các tập tin và mô hình mẫu là một nhiệm vụ khó khăn, đặc biệt là dựa trên các nền tảng, kỹ năng, và động cơ của những người tham gia xây dựng các công cụ xử lý ngôn ngữ tự nhiên. Tuy nhiên, việc phát triển thông tin tiêu chuẩn trên toàn bộ lĩnh vực N.L.A. thúc đẩy mô tả dữ liệu và mô hình của N.L. dễ dàng hơn và chi tiết hơn, đồng thời hỗ trợ các nhà nghiên cứu và phát triển trong việc phản ánh công việc của họ. Để hỗ trợ việc chỉnh sửa tài liệu, chúng tôi đưa ra hai trường hợp nghiên cứu về các nỗ lực nhằm phát triển các mẫu tài liệu có thể tái sử dụng: thẻ dữ liệu HuggingeFace, một thẻ mục tiêu chung cho các bộ dữ liệu tại Njala, và thẻ mô hình của GED với tiêu điểm tập trung vào sản sinh ngôn ngữ tự nhiên. Chúng tôi mô tả quá trình phát triển các mẫu này, bao gồm việc xác định các nhóm liên quan, Định nghĩa các nguyên tắc hướng dẫn, sử dụng các mẫu hiện tại làm nền tảng của chúng tôi, và các phiên bản thay đổi dựa trên phản hồi.', 'uz': 'Name Lekin NLP maydonidagi standard hujjatning qoʻllanmalarini ishlatish imkoniyatini oshirish va NLP maʼlumotlar va modellarning taʼriflarini bajaradi. Ularni ishga tashqi qilish va tuzuvchilarga qoʻllash imkoniyatini qoʻllash mumkin. @ info Biz shu namunalarni yaratish uchun jarayonmizni anglatamiz, murakkab ishlatuvchi guruhlarini aniqlash, qoidalarni aniqlash, tuzilishimiz uchun mavjud namunalarni ishlatish va javob berish asosida yaratish mumkin.', 'nl': 'Het ontwikkelen van documentatierichtlijnen en gebruiksvriendelijke sjablonen voor datasets en modellen is een uitdagende taak, vooral gezien de verscheidenheid aan achtergronden, vaardigheden en prikkels van de mensen die betrokken zijn bij het bouwen van natuurlijke taalverwerkingstools (NLP). Niettemin bevordert de invoering van standaarddocumentatiepraktijken op het gebied van NLP toegankelijkere en gedetailleerde beschrijvingen van NLP-datasets en -modellen, terwijl onderzoekers en ontwikkelaars worden ondersteund bij het reflecteren op hun werk. Om te helpen bij het standaardiseren van documentatie, presenteren we twee casestudies van inspanningen die gericht zijn op het ontwikkelen van herbruikbare documentatiesjablonen, zoals de HuggingFace datakaart, een universele kaart voor datasets in NLP, en de GEM benchmark data en modelkaarten met een focus op het genereren van natuurlijke taal. We beschrijven ons proces voor de ontwikkeling van deze sjablonen, inclusief de identificatie van relevante stakeholdergroepen, de definitie van een set leidende principes, het gebruik van bestaande sjablonen als basis en iteratieve revisies op basis van feedback.', 'da': 'Udvikling af dokumentationsretningslinjer og brugervenlige skabeloner til datasæt og modeller er en udfordrende opgave, især i betragtning af de mange forskellige baggrunde, færdigheder og incitamenter hos de mennesker, der er involveret i opbygningen af værktøjer til behandling af natursprog (NLP). Ikke desto mindre fremmer vedtagelsen af standarddokumentationspraksis på tværs af NLP mere tilgængelige og detaljerede beskrivelser af NLP-datasæt og -modeller, samtidig med at forskere og udviklere støtter deres arbejde med at reflektere over deres arbejde. For at hjælpe med standardisering af dokumentation præsenterer vi to casestudier af indsatsen, der sigter mod at udvikle genbrugelige dokumentationsskabeloner - HuggingFace datakortet, et generelt formål kort til datasæt i NLP, og GEM benchmark data og modelkort med fokus på generering af natursprog. Vi beskriver vores proces for udvikling af disse skabeloner, herunder identifikation af relevante interessentgrupper, definition af et sæt vejledende principper, brug af eksisterende skabeloner som fundament og iterative revisioner baseret på feedback.', 'bg': 'Разработването на указания за документация и лесни за използване шаблони за набори от данни и модели е трудна задача, особено предвид разнообразието от опит, умения и стимули на хората, участващи в изграждането на инструменти за обработка на естествен език (НЛП). Въпреки това приемането на стандартни практики за документация в областта на НЛП насърчава по-достъпни и подробни описания на наборите от данни и модели на НЛП, като същевременно подпомага изследователите и разработчиците при размисъл върху тяхната работа. За да подпомогнем стандартизацията на документацията, представяме две казуси на усилията, които имат за цел разработването на шаблони за многократна употреба - карта за данни с общо предназначение за набори от данни в НЛО и сравнителни данни и модели карти с фокус върху генерирането на естествен език. Описваме нашия процес за разработване на тези шаблони, включително идентифицирането на съответните групи от заинтересовани страни, определянето на набор от ръководни принципи, използването на съществуващи шаблони като наша основа и итеративни ревизии въз основа на обратна връзка.', 'de': 'Die Entwicklung von Dokumentationsrichtlinien und benutzerfreundlichen Vorlagen für Datensätze und Modelle ist eine anspruchsvolle Aufgabe, insbesondere angesichts der Vielfalt der Hintergründe, Fähigkeiten und Anreize der am Aufbau von Tools zur Verarbeitung natürlicher Sprache (NLP) beteiligten Personen. Dennoch fördert die Einführung standardisierter Dokumentationspraktiken im gesamten NLP-Bereich zugänglichere und detailliertere Beschreibungen von NLP-Datensätzen und -Modellen und unterstützt Forscher und Entwickler bei der Reflexion über ihre Arbeit. Zur Vereinheitlichung der Dokumentation stellen wir zwei Fallstudien zur Entwicklung wiederverwendbarer Dokumentationsvorlagen vor: die HuggingFace-Datenkarte, eine universelle Karte für Datensätze in NLP, und die GEM-Benchmark-Daten- und Modellkarten mit Schwerpunkt auf der Generierung natürlicher Sprache. Wir beschreiben unseren Prozess zur Entwicklung dieser Templates, einschließlich der Identifikation relevanter Stakeholder-Gruppen, der Definition einer Reihe von Leitprinzipien, der Verwendung vorhandener Templates als Grundlage und iterativen Revisionen basierend auf Feedback.', 'hr': 'Razvoj uputstva dokumentacije i šablona za lako korištenje podataka i modela je izazovan zadatak, posebno s obzirom na razne pozadine, vještine i podsticaje ljudi koji su uključeni u izgradnju alata prirodnog obrade jezika (NLP). Međutim, usvajanje standardnih dokumentacijskih prakse širom polja NLP-a unapređuje dostupniji i detaljniji opis podataka i modela NLP-a, dok podržava istraživače i razvijače u razmišljanju o njihovom radu. Da bi pomogli standardizaciji dokumentacije, predstavljamo dva slučaja ispitivanja napora koje se ciljaju razviti ponovno korištene dokumentacijske šablone - kartice podataka HuggingFace, općeg svrhe kartice za sete podataka u NLP-u, te podatke i modelne kartice GEM-a s fokusom na stvaranje prirodnog jezika. Mi opisujemo naš proces razvoja tih hramena, uključujući identifikaciju relevantnih skupina zajedničkih strana, definiciju skupa vodećih načela, upotrebu postojećih hramena kao našu temelj i iterativne revizije temeljne na povratku.', 'sw': 'Kutengeneza miongozo ya nyaraka na misitu rahisi ya kutumia seti za data na mifano ni kazi yenye changamoto, hasa kwa kuzingatia tofauti mbalimbali za msingi, ujuzi, na hamasa za watu waliohusika katika kujenga zana za upasuaji wa lugha za asili (NLP). Hata hivyo, utekelezaji wa vitendo vya kawaida vya dokumentari katika eneo la NLP vinamasisha maelezo yanayoweza kupatikana na kina zaidi ya taarifa na mifano ya NLP, wakati wakiwaunga mkono watafiti na maendeleo katika kutafakari kazi zao. Ili kusaidia kutengeneza taarifa, tunatoa tafiti mbili za kesi za juhudi ambazo zinakusudia kuendeleza namba za nyaraka zinazotumika tena - kadi ya data za HuggingFace, kadi ya jumla kwa ajili ya seti za taarifa za NLP, na data za benchmark na kadi za model za GEM yenye lengo la kizazi cha asili. Tunaelezea mchakato wetu wa kutengeneza misitu hizi, ikiwa ni pamoja na kutambua makundi yanayohusiana na washikadi, ufafanuzi wa seti ya kanuni za uongozi, matumizi ya misitu yanayopo kama msingi wetu, na mabadiliko ya viwanda yanayotokana na matokeo hayo.', 'tr': "Dökümentlerin gidişmelerini we veri düzenleri we nusgalar üçin a ňsat ullanmak üçin nusgalary çykaryp biljek zadyr. Özellikle tebigy diller işlemek üçin näçe topar, ukyplary we nusgalar bar. Yöne, NLP sahypalarynda standart dökümentlerin praktikalaryny golaýlaşdyrmak NLP veri setirleriniň we nusgalarynyň has detaylaryny we düşündirilýän tassymlaryny golaýlaýar. Dökümentlerin standardizasynda kömek etmek üçin, ýene ullanılabilir dökümentleri geliştirmek üçin iki kiçi gadyr öwrenmesini görkezýäris - HuggingFace maglumaty karty, NLP'da munuň maksady karty we GEM benchmark maglumaty we tebigat diller döredilmesine fokus eden çabalar. Biz bu modülleri geliştirmek üçin prosesimizi tassyýardyk, möhüm stajyk gruplaryň kimligini, gidir prinsipleriniň bir toparynyň definisýasyny, bar modalaryň esasyny biziň fondasymyz hökmünde we netijeli wersiýalaryň üstine daýrylýar.", 'fa': 'توسعه راهنمایی مدارک و قالبهای ساده برای استفاده از داده\u200cها و مدل\u200cها یک کار مشکل است، مخصوصا با وجود مختلف زمینه\u200cها، مهارت\u200cها و تحریک\u200cها مردمی که در ساختن ابزارهای پردازش زبان طبیعی (NLP) درگیرند. با این وجود، تحویل آموزش مدارک استاندارد در میدان NLP، توصیف\u200cهای دسترسی\u200cتر و جزئیات از مجموعه\u200cهای داده\u200cهای NLP و مدل\u200cها را ترفیع می\u200cدهد، در حالی که تحقیقات کنندگان و توسعه\u200cکنندگان را در تفکرشان بر کار خود حمایت می\u200cکند. برای کمک به استانداردیزی مدارک، دو پرونده مطالعه از تلاش را پیشنهاد می\u200cکنیم که هدف برای توسعه قابل استفاده از مدارک مدارک است - کارت داده\u200cهای HuggingFace، کارت هدف عمومی برای مجموعه\u200cهای داده\u200cها در NLP، و داده\u200cهای مدارک GEM و کارت مدارک با تمرکز روی توسعه زبان ط ما فرآیند خود را برای توسعه این معادلات توصیف می کنیم، شامل شناسایی گروه های مشترک، تعریف مجموعه اصول هدایت، استفاده از معادلات موجود به عنوان بنیاد ما، و تغییرات تغییرات بر پایه پشتیبانی.', 'af': "Ontwikkeling van dokumentasie-gidsline en maklik-gebruik-templates vir datastelle en modele is 'n pragtige taak, veral gegee die verskillende agtergrond, kunstenaars en instruksies van die mense wat in die bou van natuurlike taal-verwerking (NLP) nutsprogramme geantwoord is. Maar die aanvaar van standaard dokumentasie praksies oor die veld van NLP bevestig meer toeganklike en gedetale beskrywings van NLP datastelle en modele, terwyl ondersteun resekers en ontwikkelaars in refleksie van hul werk. Om te help met die standaardizasie van dokumentasie, laat ons twee geval studie van versoekte wat doel om hergebruikbare dokumentasie sjabloane te ontwikkel - die HuggingFace data kaart, 'n algemene doel kaart vir datastelle in NLP en die GEM benchmark data en model kaarte met 'n fokus op natuurlike taal genereering. Ons beskryf ons proses vir die ontwikkeling van hierdie sjabloane, insluitend die identifikasie van relevante belangrikhedige groepe, die definisie van 'n stel van gids prinsipels, die gebruik van bestaande sjabloane as ons fondasie, en iteratiewe hersieninge gebaseer op terugmelding.", 'id': 'Mengembangkan petunjuk dokumentasi dan templat mudah digunakan untuk set data dan model adalah tugas yang menantang, terutama mengingat berbagai latar belakang, keterampilan, dan insentif orang-orang yang terlibat dalam pembangunan alat proses bahasa alam (NLP). Nevertheless, the adoption of standard documentation practices across the field of NLP promotes more accessible and detailed descriptions of NLP datasets and models, while supporting researchers and developers in reflecting on their work.  To help with the standardization of documentation, we present two case studies of efforts that aim to develop reusable documentation templates - the HuggingFace data card, a general purpose card for datasets in NLP, and the GEM benchmark data and model cards with a focus on natural language generation.  Kami menggambarkan proses kami untuk mengembangkan templat-templat ini, termasuk identifikasi kelompok stakeholders relevan, definisi dari set prinsip panduan, penggunaan templat yang ada sebagai dasar kami, dan revisi ulang berdasarkan feedback.', 'am': 'አዲስ የድምፅ ቋንቋ ማቀናጃ (NLP) ሀብትን ለመሥራት የተጠቃሚ የመደቡን፣ እውቀት እና ማጠቃቀሚያ እና ማቀናጃዎችን ለመጠቀም የሚችሉትን አቀማሚ ስራ ነው፡፡ ነገር ግን በNLP እርሻ ውስጥ የነበረውን የአስተዳደር የሰነድ ሥርዓት መግለጫ በመስጠት፣ የNLP ዳታተር እና ሞዴል መግለጫ የሚጨመር እና የተዘረዘ ትርጉም እንዲያስፈልጋል፡፡ ለሰነድ አካባቢ ማስታወቂያውን ለመረዳት፣ ሁለትን የሰነድ ሰነድ ማነጃዎችን ለመደጋገም የሚችሉትን የሥልጣን ጥናት እና የHuggingFace ዳታ ካርድ፣ የዳታ ካርድ በNLP እና የGEM benchmark data እና ሞዴል ካርቶችን በአፍሪካዊ ቋንቋ ትውልድ ላይ ትክክክል ማድረግ እና ማድረግ ካርታዎችን እና አቀረ እነዚህ ምዕራቦችን ለመፍጠር፣ አካባቢ ጉዳዮችን ማረጋገጥ፣ የመሪ የሥርዓት ጉዳይ ማረጋገጫ፣ የአሁኑን ምዕራቦች እንደ መሠረታችን እና በጥያቄ ጥያቄ በመሠረት ላይ የተመሳሳይ ውጤቶች እና የአካባቢ ጉዳዮችን ለመጠቀም እናዘጋጅታለን፡፡', 'ko': '데이터 세트와 모델을 위한 문서 가이드와 사용하기 쉬운 템플릿을 개발하는 것은 도전적인 작업이다. 특히 자연 언어 처리 (NLP) 도구 구축에 참여한 사람들의 다양한 배경, 기능, 동기를 고려하면.그럼에도 불구하고 NLP 분야에서 표준 문서 실천을 통해 NLP 데이터 집합과 모델에 대한 접근이 쉽고 상세한 묘사를 추진하며 연구원과 개발자가 그들의 업무를 반성하도록 지원한다.문서의 표준화를 돕기 위해 우리는 다시 사용할 수 있는 문서 템플릿을 개발하기 위한 두 가지 사례 연구인 HuggingFace 데이터 카드, NLP에서 데이터 집합에 사용되는 유니버설 카드, 그리고 자연 언어 생성에 전념하는 GEM 기준 데이터와 모델 카드를 제공했다.우리는 이러한 템플릿을 개발하는 과정을 묘사했다. 이는 관련 이해관계자 단체를 확정하고 지도 원칙을 정의하며 기존 템플릿을 기초로 하고 피드백을 바탕으로 하는 교체 수정을 포함한다.', 'hy': "Տեղեկատվական համակարգերի և մոդելների համար հեշտ օգտագործվող փաստաթղթերի ուղղությունների զարգացումը դժվար խնդիր է, հատկապես հաշվի առնելով մարդկանց, ովքեր ներգրավված են բնական լեզվի վերամշակման գործիքների կառուցվածքում, բազմաթիվ հիմքերի, հմտություններ Այնուամենայնիվ, ՆԼՊ-ի ոլորտում ստանդարտ փաստաթղթերի գործողությունների ընդունելը խրախուսում է ավելի հասանելի և մանրամասն ՆԼՊ տվյալների համակարգերի և մոդելների նկարագրություններ, միաժամանակ աջակցում է հետազոտողներին և զարգացող Որպեսզի օգնենք փաստաթղթերի ստանդարտիզացման գործընթացը, մենք ներկայացնում ենք երկու դեպքերի ուսումնասիրություններ այն ջանքերի մասին, որոնք նպատակով են զարգացնել կրկին օգտագործվող փաստաթղթերի մոդելներ' Հուգինֆեյսի տվյալների քարտը, ընդհանուր նպատակի քարտը ՆԼՊ Մենք նկարագրում ենք այս մոդելների զարգացման մեր գործընթացը, ներառյալ հետաքրքրված մասնագետների խմբերի հայտնաբերումը, ուղղակի սկզբունքների սահմանումը, գոյություն ունեցող մոդելների օգտագործումը որպես հիմք և կրկնվող վերափոխությունները, հիմնված արձագանքի", 'bn': 'ডাটাসেট এবং মডেলের জন্য নথিপত্রের নির্দেশ এবং সহজে ব্যবহারের মন্দির উন্নয়ন করা একটি চ্যালেঞ্জ কাজ, বিশেষ করে প্রাকৃতিক ভাষা প্রক্রিয়ার (এনএলপি) টুলস নির্মাণের তবে এনএলপি ক্ষেত্রে স্বাভাবিক ডকুমেন্টেশনের প্রচণ্ড গ্রহণ করা এবং এনএলপি ডাটাসেট এবং মডেলের বিস্তারিত বর্ণনা প্রচার করে, এদিকে গবেষকদের এবং ডেভেলপা ডকুমেন্টেশনের স্বাভাবিকভাবে সাহায্য করার জন্য আমরা দুটি কেসের গবেষণা উপস্থাপন করি যার উদ্দেশ্যে পুনরায় ব্যবহৃত নথিপত্রের মন্তব্য তৈরি করার চেষ্টা করছি- হাগিংফেস ডাটা কার্ড আমরা এই মন্দির উন্নয়নের জন্য আমাদের প্রক্রিয়া বর্ণনা করি, যার মধ্যে সংশ্লিষ্ট স্টেকহার গ্রুপের চিহ্নিত, একটি গাইড নীতি নির্ধারণ, বিদ্যমান মন্দির ব্যবহার কর', 'sq': 'Developing documentation guidelines and easy-to-use templates for datasets and models is a challenging task, especially given the variety of backgrounds, skills, and incentives of the people involved in the building of natural language processing (NLP) tools.  Megjithatë, miratimi i praktikave standarde të dokumentacionit anembanë fushës së NLP nxit përshkrime më të pranueshme dhe më të holla të grupeve dhe modeleve të të dhënave NLP, duke mbështetur kërkuesit dhe zhvilluesit në pasqyrimin e punës së tyre. Për të ndihmuar me standardizimin e dokumentacionit, ne paraqesim dy studime rastesh të përpjekjeve që synojnë të zhvillojnë modele dokumentacioni të përdorueshme të përsëritur - kartën e të dhënave HuggingFace, një kartë me qëllim të përgjithshëm për grupet e të dhënave në NLP dhe të dhënat e referencës GEM dhe kartat e modelit me një fokus në gjenerimin natyror të gjuhës. Ne përshkruajmë procesin tonë për zhvillimin e këtyre modeleve, duke përfshirë identifikimin e grupeve të interesuara të lidhura, përcaktimin e një sëre parimesh udhëzuese, përdorimin e modeleve ekzistuese si themelin tonë dhe revizionet përsërituese bazuar në feedback.', 'cs': 'Vývoj dokumentačních pokynů a snadno použitelných šablon pro datové sady a modely je náročný úkol, zejména vzhledem k různým zázemím, dovednostem a pobídkám lidí zapojených do budování nástrojů pro zpracování přirozeného jazyka (NLP). Přijetí standardních dokumentačních postupů v oblasti NLP však podporuje přístupnější a podrobnější popis datových sad a modelů NLP a zároveň podporuje výzkumné pracovníky a vývojáře v reflexi o jejich práci. Pro pomoc při standardizaci dokumentace představujeme dvě případové studie úsilí o vývoj opakovaně použitelných dokumentačních šablon: datovou kartu HuggingFace, univerzální kartu pro datové sady v NLP a referenční datové a modelové karty GEM se zaměřením na generování přirozeného jazyka. Popisujeme náš proces vývoje těchto šablon, včetně identifikace relevantních skupin zainteresovaných stran, definování sady hlavních principů, využití existujících šablon jako základu a iterativní revize založené na zpětné vazbě.', 'ca': "El desenvolupament de directrices de documentació i models fàcils d'utilitzar per a conjunts de dades i models és una tasca difícil, especialment tenint en compte la varietat de contextos, habilitats i incentius de la gent involucrada en la construcció d'eines de processament natural de llenguatges (NLP). No obstant això, l'adopció de pràctiques normalitzades de documentació en el camp de la NLP promou descripcions més accessibles i detalladas de conjunts de dades i models de la NLP, mentre ajuda a investigadors i desenvolupadors a reflexionar sobre el seu treball. Per ajudar a estandaritzar la documentació, presentem dos estudis de cas d'esforços que busquen desenvolupar patrons de documentació reutilitzables - la tarxeta de dades HuggingFace, una tarxeta de propòsit general per a conjunts de dades a NLP, i les dades de referència GEM i les tarxetes models centrades en la generació de llenguatges naturals. Descrivem el nostre procés de desenvolupament d'aquests models, incloent la identificació de grups de stakeholders pertinents, la definició d'un conjunt de principis directors, l'ús de models existents com a fonamenta, i revisions iteratives basades en feedback.", 'et': 'Dokumentatsioonijuhiste ja lihtsalt kasutatavate mallide väljatöötamine andmekogumite ja mudelite jaoks on keeruline ülesanne, eriti arvestades looduskeele töötlemise vahendite loomisega seotud inimeste tausta, oskusi ja stiimuleid. Sellegipoolest soodustab standardsete dokumentatsioonitavade kasutuselevõtt uue õppekava valdkonnas uue õppekava andmekogumite ja mudelite kättesaadavamat ja üksikasjalikumat kirjeldust, toetades samal ajal teadlasi ja arendajaid oma töö üle mõtlemisel. Dokumentatsiooni standardimiseks esitame kaks juhtumiuuringut, mille eesmärk on välja töötada korduvkasutatavad dokumentatsioonimallid - HuggingFace andmekaart, üldotstarbeline kaart andmekogumite jaoks NLP-is ning GEMi võrdlusandmed ja mudelkaardid, mis keskenduvad looduskeele genereerimisele. Kirjeldame nende mallide väljatöötamise protsessi, sealhulgas asjaomaste sidusrühmade kindlaksmääramist, juhtpõhimõtete kogumi määratlemist, olemasolevate mallide kasutamist alusena ning tagasisidel põhinevaid korduvaid parandusi.', 'fi': 'Dokumentaatioohjeiden ja helppokäyttöisten mallipohjien kehittäminen aineistoille ja malleille on haastava tehtävä, varsinkin kun otetaan huomioon luonnollisen kielen käsittelytyökalujen rakentamiseen osallistuvien henkilöiden erilaiset taustat, taidot ja kannustimet. Kuitenkin vakiodokumentointikäytäntöjen käyttöönotto koko NLP:n alueella edistää NLP:n tietoaineistojen ja mallien helppokäyttöisempiä ja yksityiskohtaisia kuvauksia ja tukee tutkijoita ja kehittäjiä pohtimaan heidän työtään. Dokumentaation standardoinnin helpottamiseksi esittelemme kaksi tapaustutkimusta uudelleenkäytettävien dokumentointimallien kehittämisestä: HuggingFace-datakortti, yleiskäyttöinen kortti NLP:n tietoaineistoille sekä GEM-vertailudata- ja mallikortit, joissa keskitytään luonnollisen kielen tuottamiseen. Kuvaamme prosessiamme näiden mallien kehittämiseksi, mukaan lukien asiaankuuluvien sidosryhmien tunnistaminen, ohjaavien periaatteiden määrittely, olemassa olevien mallien käyttö pohjanamme ja palautteen perusteella toistuvat tarkistukset.', 'az': 'Məlumat qurğuları və modellər üçün asanlıqla istifadə etmək üçün belə çətin bir işdir, özlərinə də təbiətli dil işləməsi (NLP) vasitələrinin in şaatında olan insanların çeşitli arxa planları, yetenekləri və təsirlərini təhsil edir. Ancaq NLP sahəsindəki standart dokumentasiya praksilərinin istifadəsi NLP verilənlərin və modellərin daha müfəssəl və detaylı tanımlamalarını təşkil edir, araştırmacıları və təhsil edənləri öz işlərini düşünmək üçün dəstəkləyirlər. Dökümənin standardizasyonu ilə kömək etmək üçün, yenidən istifadə edilə bilən dökümənin şablonlarını təhsil etmək üçün iki məsəl təhsil təhsil təhsil edirik - HuggingFace verilən kartı, NLP-də verilən qurğular üçün genel məqsəd kartı, GEM benchmark verilənlərini və modellərini təbiətli dil təhsil təhsil etməsinə odaqla Biz bu nömrələri inkişaf etmək üçün işləmimizi, mövcud mövcud olan qrupların tanımlaması, doğru yol nömrələrinin təsdiqlənməsini, mövcud nömrələrinin istifadəsini bizim fundamız kimi və yenidən dəyişdirmələri təsdiqləyirik.', 'bs': 'Razvoj uputstva dokumentacije i šablona za lako korištenje podataka i modela je izazovan zadatak, posebno s obzirom na razne pozadine, vještine i podsticaje ljudi koji su uključeni u izgradnju alata prirodnog obrade jezika (NLP). Ipak, usvajanje standardnih dokumentacijskih prakse širom polja NLP-a promovira dostupnije i detaljnije opise seta i modela podataka NLP-a, dok podržava istraživače i razvijače u razmišljanju o njihovom radu. Da bi pomogli sa standardizacijom dokumentacije, predstavljamo dva slučaja ispitivanja napora koje su ciljeve da razviju ponovno korištene dokumentacijske template - kartice podataka HuggingFace, općeg svrhe kartice za sete podataka u NLP-u, te podatke i kartice GEM-a s fokusom na generaciju prirodnog jezika. Mi opisujemo naš proces razvoja tih hramena, uključujući identifikaciju relevantnih grupa zainteresovanih strana, definiciju set a vodećih principa, upotrebu postojećih hramena kao našu temelj i iterativne revizije na osnovu reakcije.', 'jv': 'Tulung nggawe Dokumen Stingkiling lan gampang-gampang template kanggo nggawe dataset lan model sing gawe barang nggawe task sing diranggawe, supoyo akeh sistem sistem sing, caparnan karo akeh lanjut sampeyan karo akeh akeh dumadhi kanggo nguasai perusahaan langgambar (NLP). Nanging kabeh, nggunakake sistem sing sampeyan Dokumen sing dumateng anyar tentang NLP iki dadi wis diakses karo kesalahan kelas karo akeh nyong nggawe dataset NLP karo model, sampeyan ngêlangno cerceturan lan aturan nggawe ngubah cerceturan gambar nggawe cara-cara nggawe gerakan akeh nyong. Sampeyan nganggep dokumen sing dumadhi, kita mulai duruh kelas karbot dadi kapan kanggo nggawe Dokumen templates sing bisa nggawe aturan lagi nggawe Dokumen Awak dhéwé ngpisan penggunaké nggawe templé iki, iso nggawe nambah karo kelompok sing gak bener, nggunaké perusahaan kelompok nggawe barang kelompok, nambah templé sing endistahak dhéwé, lan tarjamahan sing paling dhéwé.', 'ha': "Kuƙara shiryarwa na takardar takardar aiki da ke amfani da shi mai sauƙin amfani da shiryoyin ayuka na danganta da misãlai, yana mai walau, hasa'a, da haske da aka ƙayyade wasu bakin bango, da abinci, da incenuwa na mutane waɗanda ke cikin ƙiƙiro na aikin aiki na fassarar harshe na asili (NLP). A lokacin da, kiyayen takardar takardar dokumen aiki na tsakanin NLP, yana ƙara fassarar da fassaratan na NLP da misãlai, kuma yana ƙaranci kwamfyuta masu motsi da masu motsi a kan aikin su. To, dõmin taimako da daidaitarin takardar takardar, mu zo da aikin biyu masu aikin ƙwarai da za'a iya buɗe wasu takardar takardar aiki masu amfani da shi - Kaarar data na HuggngFace, kardi na jumla ga masu amfani da matsayi na tsari cikin NLP, da data na bangon GEM da wasu kardi na motsi da ke fokus a kan zayen zane-zane. Tuna bayyana aikin mu da za'a buɗe wannan garwaya, kamar yadda za'a gane jama'a masu hususann mãsu tsari, da definin wasu kanuni na shiryarwa, da amfani da mistakardan da ke kai kamar bangonmu, da musanyi masu daidaita matsayi.", 'sk': 'Razvoj dokumentacijskih smernic in enostavnih predlog za zbirke podatkov in modele je zahtevna naloga, zlasti glede na različna ozadja, spretnosti in spodbude ljudi, ki sodelujejo pri gradnji orodij za obdelavo naravnega jezika (NLP). Kljub temu pa sprejetje standardnih praks dokumentiranja na področju NLP spodbuja dostopnejše in podrobnejše opise naborov podatkov in modelov NLP, hkrati pa podpira raziskovalce in razvijalce pri razmišljanju o njihovem delu. V pomoč pri standardizaciji dokumentacije predstavljamo dve študiji primerov prizadevanj za razvoj predlog dokumentacije za večkratno uporabo - podatkovno kartico HuggingFace, kartico splošnega namena za nabore podatkov v NLP ter referenčne podatke GEM in modelne kartice s poudarkom na ustvarjanju naravnega jezika. Opisujemo naš proces razvoja teh predlog, vključno z identifikacijo ustreznih interesnih skupin, opredelitvijo sklopa vodilnih načel, uporabo obstoječih predlog kot temelj in ponavljajočimi revizijami na podlagi povratnih informacij.', 'he': 'פיתוח מדריכים מסמכים ומדגמנים קלים להשתמש עבור קבוצות נתונים ודוגמנים הוא משימה מאתגרת, במיוחד בהתחשב במגוון של רקע, כישורים ומניעים של האנשים שמעורבים בבניית כלי עיבוד שפת טבעית (NLP). למרות זאת, האימוץ של מערכות תיעוד סטנדרטיות ברחבי השטח של NLP מקדם תיאורים אפשריים ומפורטים יותר של קבוצות נתונים ולדוגמנים NLP, בזמן שתומך במחקרים ומתפתחים בהשתקפות על עבודתם. כדי לעזור עם סטנדרטיזציה של תיעוד, אנחנו מציגים שני מחקרים של מאמצים שמתכוונים לפתח מודלים תיעוד שימושיים מחדש - כרטיס מידע HuggingFace, כרטיס מטרה כללית לקבוצות מידע ב-NLP, ואת מידע המרמז של GEM וכרטיסי מודל עם מרכז על יוצר שפה טבעית. אנחנו מתארים את התהליך שלנו לפיתוח הדגמנים האלה, כולל זיהוי קבוצות בעניינים רלוונטיות, הגדרה של קבוצת עקרונות מדריכים, השימוש של דגמנים קיימים כבסיס שלנו, ושיקורים חוזרים מבוססים על חזרה.', 'bo': 'Developing documentation guidelines and easy-to-use templates for datasets and models is a challenging task, especially given the variety of backgrounds, skills, and incentives of the people involved in the building of natural language processing (NLP) tools. Nevertheless, the adoption of standard documentation practices across the field of NLP promotes more accessible and detailed descriptions of NLP datasets and models, while supporting researchers and developers in reflecting on their work. To help with the standardization of documentation, we present two case studies of efforts that aim to develop reusable documentation templates - the HuggingFace data card, a general purpose card for datasets in NLP, and the GEM benchmark data and model cards with a focus on natural language generation. We describe our process for developing these templates, including the identification of relevant stakeholder groups, the definition of a set of guiding principles, the use of existing templates as our foundation, and iterative revisions based on feedback.'}
{'en': 'Decoding Methods for Neural Narrative Generation', 'ar': 'طرق فك التشفير للجيل السردي العصبي', 'fr': 'Méthodes de décodage pour la génération du récit neuronal', 'pt': 'Métodos de decodificação para geração de narrativa neural', 'es': 'Métodos de decodificación para la generación de narrativas', 'ja': 'ニューラルナラティブ生成のためのデコード方法', 'zh': '神经叙事生成解码法', 'hi': 'तंत्रिका कथा पीढ़ी के लिए डिकोडिंग विधियाँ', 'ru': 'Методы декодирования для генерации нейронных повествований', 'ga': 'Modhanna Díchódaithe chun Néarscéal a Ghiniúint', 'ka': 'Name', 'el': 'Μέθοδοι αποκωδικοποίησης για τη δημιουργία νευρωνικής αφήγησης', 'hu': 'Dekódolási módszerek a neurális narratív generációhoz', 'mk': 'Методи за декодирање за неурална нарративна генерација', 'kk': 'Невралдық нарративті құру үшін декодтау әдістері', 'it': 'Metodi di decodifica per la generazione narrativa neurale', 'lt': 'Neuralinės Narracinės generacijos dekodizavimo metodai', 'ms': 'Kaedah Pengkodan untuk Jenerasi Narratif Neural', 'mn': 'Цөмийн эмгэгтэй үеийн шийдвэрлэх арга', 'no': 'Dekodingsmetodar for neiralnarrativ generering', 'pl': 'Metody dekodowania nerwowego generowania narracji', 'ml': 'നെയുറല്\u200d നാററിവ് സൃഷ്ടിക്കുന്നതിനുള്ള കോഡിങ്ങ് രീതികള്\u200d', 'sr': 'Методи декодирања за невралну нарративну генерацију', 'mt': 'Metodi ta’ Dikodifikazzjoni għall-Ġenerazzjoni Narrattiva Newrali', 'so': 'Qoraandegista dhalashada naafada', 'ro': 'Metode de decodare pentru generarea narativă neurală', 'sv': 'Dekodningsmetoder för neural narrativ generering', 'ur': 'نائرل ناراریٹ نسل کے لئے ڈیکوڈینگ طریقے', 'ta': 'குறியீட்டு முறைமைகள்', 'si': 'න්\u200dයූරල් නාර්යාරේටිව සිද්ධානය සඳහා ඩිකෝඩ් විධානය', 'uz': 'Name', 'vi': 'Phương pháp giải mã cho Thế hệ cận thần.', 'bg': 'Методи за декодиране на неврални разкази', 'da': 'Dekodningsmetoder til neural fortællingsgenerering', 'nl': 'Ontcijferingsmethoden voor neurale narratieve generatie', 'hr': 'Metode dekodiniranja za neurološku narativnu generaciju', 'ko': '신경 서사 생성의 디코딩 방법', 'de': 'Dekodierungsmethoden für die Erzeugung neuronaler Narrative', 'fa': 'روش\u200cهای رمزبندی برای نسل مصنوعی عصبی', 'id': 'Decoding Methods for Neural Narrative Generation', 'tr': 'Nätral Narratiw Däplik üçin Ködleme Metleri', 'sq': 'Metodat e dekodimit për Gjenerimin Narrativ Neural', 'sw': 'Takwimu za Uzalishaji wa Nyingira', 'af': 'Dekodering Metode vir Nural Narrative Generasie', 'hy': 'Նյարդային նյարդային սերունդների կոդավորման մեթոդները', 'az': 'Nöral Narrativ Yenilməsi üçün Dekodlama metodları', 'bn': 'নিউরেল নরেটিভ প্রজন্মের জন্য ডিকোডিং পদ্ধতি', 'am': 'አዲስ ዶሴ ፍጠር', 'ca': 'Métodes de descodificació per a la generació narrativa neuronal', 'et': 'Neuraalse jutustuse genereerimise dekodeerimismeetodid', 'bs': 'Metode dekodiniranja za neuronsku narrativnu generaciju', 'cs': 'Metody dekódování pro generování nervového narativu', 'fi': 'Neuraalisen kerronnan luomisen dekoodamismenetelmät', 'ha': 'KCharselect unicode block name', 'bo': 'Neural Narrative Generation için ཕྱིར་གཏོང་ཐབས་ལམ།', 'jv': 'lahi', 'he': 'שיטות קידוד לדורה נררטיבית נוירולית', 'sk': 'Dekodirne metode za ustvarjanje nevronskih pripovedi'}
{'en': 'Narrative generation is an open-ended NLP task in which a model generates a story given a prompt. The task is similar to neural response generation for chatbots ; however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks. We aim to bridge this gap by applying and evaluating advances in decoding methods for neural response generation to neural narrative generation. In particular, we employ GPT-2 and perform ablations across nucleus sampling thresholds and diverse decoding hyperparametersspecifically, maximum mutual informationanalyzing results over multiple criteria with automatic and human evaluation. We find that (1) nucleus sampling is generally best with thresholds between 0.7 and 0.9 ; (2) a maximum mutual information objective can improve the quality of generated stories ; and (3) established automatic metrics do not correlate well with human judgments of narrative quality on any qualitative metric.', 'ar': 'الجيل السردي هو مهمة مفتوحة في البرمجة اللغوية العصبية حيث يولد النموذج قصة في ضوء موجه. المهمة مشابهة لتوليد الاستجابة العصبية لروبوتات المحادثة. ومع ذلك ، غالبًا ما لا يتم تطبيق الابتكارات في توليد الاستجابة على الجيل السردي ، على الرغم من التشابه بين هذه المهام. نهدف إلى سد هذه الفجوة من خلال تطبيق وتقييم التطورات في طرق فك التشفير لتوليد الاستجابة العصبية لتوليد السرد العصبي. على وجه الخصوص ، نحن نستخدم GPT-2 ونجري عمليات الاجتثاث عبر عتبات أخذ عينات النواة والمعلمات الفائقة المتنوعة لفك التشفير - على وجه التحديد ، المعلومات المتبادلة القصوى - لتحليل النتائج عبر معايير متعددة مع التقييم التلقائي والبشري. نجد أن (1) أخذ عينات النواة هو الأفضل بشكل عام مع عتبات بين 0.7 و 0.9 ؛ (2) يمكن أن يؤدي الحد الأقصى من هدف المعلومات المتبادلة إلى تحسين جودة القصص التي يتم إنشاؤها ؛ و (3) المقاييس التلقائية المعمول بها لا ترتبط جيدًا بالأحكام البشرية لجودة السرد على أي مقياس نوعي.', 'fr': "La génération de narration est une tâche de PNL ouverte dans laquelle un modèle génère une histoire à partir d'une invite. La tâche est similaire à la génération de réponse neuronale pour les chatbots\xa0; cependant, les innovations dans la génération de réponses ne sont souvent pas appliquées à la génération de narration, malgré la similitude entre ces tâches. Nous visons à combler cette lacune en appliquant et en évaluant les avancées des méthodes de décodage pour la génération de réponse neuronale à la génération de narration neuronale En particulier, nous utilisons GPT-2 et effectuons des ablations au-delà des seuils d'échantillonnage du noyau et de divers hyperparamètres de décodage, en particulier l'information mutuelle maximale, en analysant les résultats sur plusieurs critères avec une évaluation automatique et humaine. Nous trouvons que (1) l'échantillonnage par noyau est généralement le meilleur avec des seuils compris entre 0,7 et 0,9\xa0; (2) un objectif d'information mutuelle maximale peut améliorer la qualité des histoires générées\xa0; et (3) les mesures automatiques établies ne sont pas bien corrélées avec les jugements humains de la qualité narrative sur n'importe quelle métrique qualitative.", 'es': 'La generación narrativa es una tarea abierta de PNL en la que un modelo genera una historia dada una indicación. La tarea es similar a la generación de respuestas neuronales para los chatbots; sin embargo, las innovaciones en la generación de respuestas a menudo no se aplican a la generación narrativa, a pesar de la similitud entre estas tareas. Nuestro objetivo es cerrar esta brecha aplicando y evaluando los avances en los métodos de decodificación para la generación de respuestas neuronales a la generación de narrativas neuronales. En particular, utilizamos GPT-2 y realizamos ablaciones a través de los umbrales de muestreo del núcleo y diversos hiperparámetros de decodificación, específicamente, la máxima información mutua, analizando los resultados según múltiples criterios con evaluación automática y humana. Encontramos que (1) el muestreo del núcleo generalmente es mejor con umbrales entre 0.7 y 0.9; (2) un objetivo máximo de información mutua puede mejorar la calidad de las historias generadas; y (3) las métricas automáticas establecidas no se correlacionan bien con los juicios humanos de calidad narrativa en ninguna métrica cualitativa.', 'pt': 'A geração narrativa é uma tarefa de PNL aberta na qual um modelo gera uma história a partir de um prompt. A tarefa é semelhante à geração de resposta neural para chatbots; no entanto, as inovações na geração de respostas muitas vezes não são aplicadas à geração de narrativas, apesar da semelhança entre essas tarefas. Nosso objetivo é preencher essa lacuna aplicando e avaliando os avanços nos métodos de decodificação para geração de resposta neural para geração de narrativa neural. Em particular, empregamos GPT-2 e realizamos ablações nos limites de amostragem do núcleo e diversos hiperparâmetros de decodificação - especificamente, informações mútuas máximas - analisando os resultados em vários critérios com avaliação automática e humana. Descobrimos que (1) a amostragem de núcleo é geralmente melhor com limiares entre 0,7 e 0,9; (2) um objetivo máximo de informação mútua pode melhorar a qualidade das histórias geradas; e (3) métricas automáticas estabelecidas não se correlacionam bem com julgamentos humanos de qualidade narrativa em qualquer métrica qualitativa.', 'ja': 'ナラティブ生成は、モデルがプロンプトを与えられたストーリーを生成するオープンエンドのNLPタスクです。このタスクは、チャットボットのニューラルレスポンス生成に似ていますが、応答生成の革新は、これらのタスク間の類似性にもかかわらず、しばしば物語生成には適用されません。神経応答生成から神経物語生成へのデコード手法の進歩を応用し評価することで、このギャップを埋めることを目指しています。特に、ＧＰＴ － ２を採用し、核サンプリング閾値と多様なデコードハイパラメータにわたってアブレーションを行い、具体的には、自動評価とヒト評価を用いた複数の基準にわたる最大相互情報分析結果を提供する。私たちは、（ 1 ）核サンプリングは一般的に0.7から0.9の間の閾値で最良であること、（ 2 ）最大相互情報目標は生成された物語の質を向上させることができること、（ 3 ）確立された自動指標は、いずれの質的指標でも物語の質の人間の判断とうまく相関しないことを発見しました。', 'hi': 'कथा पीढ़ी एक ओपन-एंडेड एनएलपी कार्य है जिसमें एक मॉडल एक संकेत दिए गए एक कहानी उत्पन्न करता है। कार्य चैटबॉट्स के लिए तंत्रिका प्रतिक्रिया पीढ़ी के समान है; हालांकि, प्रतिक्रिया पीढ़ी में नवाचारों को अक्सर इन कार्यों के बीच समानता के बावजूद कथा पीढ़ी पर लागू नहीं किया जाता है। हम तंत्रिका कथा पीढ़ी के लिए तंत्रिका प्रतिक्रिया पीढ़ी के लिए डिकोडिंग विधियों में प्रगति को लागू करने और मूल्यांकन करके इस अंतर को पाटने का लक्ष्य रखते हैं। विशेष रूप से, हम जीपीटी -2 को नियोजित करते हैं और नाभिक नमूना थ्रेसहोल्ड और विविध डिकोडिंग हाइपरपैरामीटर में एब्लेशन करते हैं - विशेष रूप से, अधिकतम पारस्परिक जानकारी - स्वचालित और मानव मूल्यांकन के साथ कई मानदंडों पर परिणामों का विश्लेषण करते हैं। हम पाते हैं कि (1) नाभिक नमूनाकरण आमतौर पर 0.7 और 0.9 के बीच थ्रेसहोल्ड के साथ सबसे अच्छा है; (2) एक अधिकतम पारस्परिक जानकारी उद्देश्य उत्पन्न कहानियों की गुणवत्ता में सुधार कर सकता है; और (3) स्थापित स्वचालित मैट्रिक्स किसी भी गुणात्मक मीट्रिक पर कथा गुणवत्ता के मानव निर्णय के साथ अच्छी तरह से सहसंबंधित नहीं हैं।', 'ru': 'Генерация повествования - это открытая задача NLP, в которой модель генерирует историю, заданную подсказкой. Задача похожа на генерацию нейронных ответов для чат-ботов, однако, несмотря на сходство между этими задачами, инновации в генерации ответов часто не применяются к генерации нарративов. Мы стремимся восполнить этот пробел путем применения и оценки достижений в методах декодирования для генерации нейронного ответа для генерации нейронного нарратива. В частности, мы используем GPT-2 и выполняем абляции через пороги выборки ядер и различные гиперпараметры декодирования, в частности, максимальную взаимную информацию-анализ результатов по нескольким критериям с автоматической и человеческой оценкой. Мы обнаружили, что (1) выборка ядер, как правило, лучше всего с пороговыми значениями от 0,7 до 0,9; (2) максимальная цель взаимной информации может улучшить качество сгенерированных историй; и (3) установленные автоматические метрики плохо коррелируют с человеческими суждениями о качестве повествования по любой качественной метрике.', 'zh': '叙事成开放式NLP,模形示给定成。 事类聊天机器人神经应生。 然新造不叙事,虽有似之。 吾道以质神经应生解码进步以弥合之。 特用GPT-2,并跨细胞核采样阈值及诸解码超参数(尤为最大互信息)行消融,以自与人工评估析数端。 见(1)原子核采样常最好,阈值在0.7、0.9间。 (2)大者互信息所以成事也;大者,所以成事也。 (3)既定之自指标与人定性指标叙事无善相关性。', 'ga': 'Is tasc neamhiata NLP é giniúint insinte ina gineann samhail scéal a thugtar leid. Tá an tasc cosúil le giniúint freagra néarach do chatbots; áfach, is minic nach gcuirtear nuálaíochtaí i nginiúint freagartha i bhfeidhm ar ghiniúint insinte, in ainneoin na cosúlachtaí idir na tascanna sin. Tá sé mar aidhm againn an bhearna seo a líonadh trí dhul chun cinn i modhanna díchódaithe a chur i bhfeidhm agus a mheas chun freagairt néarach a ghiniúint go dtí an scéal a ghiniúint. Go háirithe, bainimid úsáid as GPT-2 agus déanaimid díbleachtaí thar thairseacha samplála núicléas agus hipearpharaiméadair díchódaithe éagsúla - go sonrach, uasfhaisnéis fhrithpháirteach - ag déanamh anailíse ar thorthaí thar ilchritéir le meastóireacht uathoibríoch agus daonna. Faighimid amach go bhfuil (1) sampláil núicléas is fearr go ginearálta le tairseacha idir 0.7 agus 0.9; (2) is féidir le cuspóir faisnéise frithpháirteach uasta feabhas a chur ar cháilíocht na scéalta a ghintear; agus (3) nach bhfuil comhghaol maith idir méadracht uathoibríoch bhunaithe agus breithiúnais dhaonna ar cháilíocht na hinsinte ar aon mhéadracht cháilíochtúil.', 'hu': 'A Narrációs generálás egy nyílt végű NLP-feladat, amelyben egy modell kérésre adott történetet generál. A feladat hasonló a chatbotok idegi válasz generálásához; A válasz generálásával kapcsolatos innovációkat azonban gyakran nem alkalmazzák a narratív generálásra, annak ellenére, hogy e feladatok hasonlóak. Célunk, hogy áthidaljuk ezt a szakadékot azáltal, hogy alkalmazzuk és értékeljük a neurális válasz generálásához szükséges dekódolási módszerek fejlődését a neurális narratív generáláshoz. Különösen GPT-2-t alkalmazunk, és ablációkat végezünk a magmintavételi küszöbértékeken és a különböző dekódolási hiperparamétereken – különösen a maximális kölcsönös információk – több kritérium alapján automatikus és humán értékeléssel. Úgy találjuk, hogy (1) a magmintavétel általában a legjobb, ha a küszöbértékek 0,7 és 0,9 között vannak; (2) egy maximális kölcsönös információs célkitűzés javíthatja az előállított történetek minőségét; és (3) a megállapított automatikus mutatók nem korrelálnak jól a narratív minőség emberi megítéléseivel semmilyen minőségi mutatóban.', 'ka': 'Narrative generation is an open-ended NLP task in which a model generates a story given a prompt. დავალება ნეიროლური პარამეტრების შესახებ შარბოტებისთვის იგივეა; მაგრამ განახლების განახლების განახლების განახლების განახლების განახლებისთვის უნდა გამოყენება, მაგრამ ამ დავალების განსხვავებას განახლებით. ჩვენ მინდომით, რომ ამ განსხვავებას გადავიწყენოთ და გავამუშავოთ განსხვავებას ნეიროლური განსხვავება ნეიროლური განსხვავებაზე. განსაკუთრებით, ჩვენ GPT-2-ს გამოყენებთ და ჩვენ გავაკეთებთ წერტილებების განსაკუთრებული ჰიპეროპარამეტრები და განსხვავებული განსხვავებული განსხვავებული განსხვავებული განსხვავებული ინფორმაციის ანალიზაციის შედეგი მრავა ჩვენ აღმოჩნეთ, რომ (1) ნუკულის გამოყენება უბრალოდ უკეთესია 0.7 და 0.9-ის შორის წინასწორებით; (2) მაქსიმალური საერთო ინფორმაციის მიზეზი შეუძლია შექმნა წარმოიქმნილი ისტორიების კაalitეტის გასაკეთება; და (3) ავტომატიკური მეტრიკის შესაძლებლობა ადამიანის განსაზღვრებების კოლეტატიური მეტრიკის შესაძლებლობით არ კარგალიტური განსაზღვრებით.', 'el': 'Η δημιουργία αφήγησης είναι μια εργασία ανοικτού τέλους στην οποία ένα μοντέλο δημιουργεί μια ιστορία που δίνεται μια ερώτηση. Το έργο είναι παρόμοιο με τη δημιουργία νευρωνικής απόκρισης για chatbots. Ωστόσο, οι καινοτομίες στη δημιουργία απόκρισης συχνά δεν εφαρμόζονται στη δημιουργία αφηγημάτων, παρά την ομοιότητα μεταξύ αυτών των καθηκόντων. Στόχος μας είναι να γεφυρώσουμε αυτό το χάσμα εφαρμόζοντας και αξιολογώντας τις προόδους στις μεθόδους αποκωδικοποίησης για τη δημιουργία νευρωνικής απόκρισης στη δημιουργία νευρωνικής αφήγησης. Ειδικότερα, χρησιμοποιούμε και εκτελούμε απολύσεις σε κατώτατα όρια δειγματοληψίας πυρήνων και ποικίλες υπερπαραμέτρους αποκωδικοποίησης-συγκεκριμένα, μέγιστα αμοιβαία αποτελέσματα ανάλυσης πληροφοριών σε πολλαπλά κριτήρια με αυτόματη και ανθρώπινη αξιολόγηση. Διαπιστώνουμε ότι (1) η δειγματοληψία πυρήνων είναι γενικά καλύτερη με κατώτατα όρια μεταξύ 0.7 και 0.9. (2) ο μέγιστος στόχος αμοιβαίας πληροφόρησης μπορεί να βελτιώσει την ποιότητα των παραγόμενων ιστοριών· και (3) οι καθιερωμένες αυτόματες μετρήσεις δεν συσχετίζονται καλά με τις ανθρώπινες κρίσεις αφηγηματικής ποιότητας σε οποιαδήποτε ποιοτική μέτρηση.', 'kk': 'Наративті құру - ашық аяқталған NLP тапсырмасы. Үлгі келтірілген сұрақ құқығын құрады. Тапсырма шатботтар үшін невралдық жауап жасау сәйкес; тапсырма Осы тапсырмалар арасындағы ұқсас тәртіпсіздігіне қарамастан, жауап жасау үшін инновациялар жасалмайды. Біз бұл аралығын невралдық түсініктерді жасау үшін невралдық жауап жасау әдістерін декодтау және бағалау арқылы көмектесеміз. Әрине біз GPT-2 жұмыс істеп, ядролық түрлендіру деңгейлері мен гиперпараметрлерді түрлендіріп, автоматты түрлендіру мен адамды бағалау арқылы бірнеше критериялардан артық бірнеше мәліметтерді анализиялау нәтижелерін жа Біз 0,7 мен 0,9 арасындағы (1) ядролық түрлендіріміз жақсы болады. (2) Қосымша мәліметтің максималды мақсатын құрылған оқиғалардың сапатын жақсартуға болады; және (3) автоматты метрикалық метрикалық метрикалық түрде адамдардың түсініктемелеріне қарапайды.', 'it': "La generazione narrativa è un'attività PNL a termine aperto in cui un modello genera una storia con un prompt. Il compito è simile alla generazione di risposta neurale per i chatbot; Tuttavia, le innovazioni nella generazione della risposta spesso non vengono applicate alla generazione narrativa, nonostante la somiglianza tra questi compiti. Puntiamo a colmare questo divario applicando e valutando i progressi nei metodi di decodifica per la generazione di risposta neurale alla generazione narrativa neurale. In particolare, utilizziamo GPT-2 ed eseguiamo ablazioni attraverso soglie di campionamento del nucleo e diversi iperparametri di decodifica, in particolare, massimi risultati reciproci di informazione, analizzando i risultati su più criteri con valutazione automatica e umana. Troviamo che (1) il campionamento del nucleo è generalmente migliore con soglie comprese tra 0,7 e 0,9; (2) un obiettivo massimo di informazione reciproca può migliorare la qualità delle storie generate; e (3) le metriche automatiche stabilite non si correlano bene con i giudizi umani della qualità narrativa su qualsiasi metrica qualitativa.", 'ml': 'പ്രത്യേകം നല്\u200dകപ്പെട്ട ഒരു കഥ ഉണ്ടാക്കുന്ന ഒരു മോഡല്\u200d നിര്\u200dമ്മിക്കുന്ന ഒരു തുറന്ന NLP ജോലിയാണ്. ചട്ട്ബോട്ടുകള്\u200dക്കുള്ള പുതുരുവിന്റെ തലമുറയില്\u200d പ്രവര്\u200dത്തിക്കുന്നത് പോലെയാണ്; എന്നാലും പ്രതികരിക്കുന്ന തലമുറതലമുറയിലെ പ്രവർത്തകങ്ങള്\u200d പലപ്പോഴും വിവരങ്ങളുടെ തലമുറയിലേക്ക് പ്രയോഗിക് ന്യൂറല്\u200d പ്രതികരണ തലമുറതലമുറയിലേക്ക് ന്യൂറല്\u200d പ്രതികരിക്കുന്നതിനുള്ള മുന്\u200dഗണങ്ങള്\u200d പ്രയോഗിക്കുകയും വിലയിക്കുകയും ചെയ In particular, we employ GPT-2 and perform ablations across nucleus sampling thresholds and diverse decoding hyperparameters-specifically, maximum mutual information-analyzing results over multiple criteria with automatic and human evaluation.  നമ്മള്\u200d കണ്ടെത്തുന്നു (1) ന്യൂക്ലസ് ടാമ്പിംഗ് സാധാരണ 0. 7 വരെയും 0. 9 വരെയും ഇടയില്\u200d മികച്ച നീര്\u200dഷോളുകള്\u200d ഉള്ളതാ (2) ഏറ്റവും കൂടുതല്\u200d പരസ്പര വിവരങ്ങളുടെ ലക്ഷ്യം ഉല്\u200dപാദിച്ച കഥകളുടെ ഗുണത്തെ മെച്ചപ്പെടുത്താം; (3) സ്ഥാപിക്കപ്പെട്ട സ്വയമായ മെട്രിക്കുകള്\u200d മനുഷ്യരുടെ വിധികളോട് നന്നായി ബന്ധപ്പെടുന്നില്ല.', 'lt': 'Narrativa karta yra atviras NLP uždavinys, kuriame model is sukuria greitą istoriją. užduotis panaši į nervinio atsako generaciją chatbotams; vis dėlto, nepaisant šių užduočių panašumo, atsako kūrimo inovacijos dažnai netaikomos narracinei gamybai. Mes siekiame pašalinti šią spragą taikant ir vertinant pažangą, padarytą dekodiuojant neurologinio atsako generavimo metodus neurologinei narracinei generacijai. Visų pirma mes naudojame GPT-2 ir atliekame abliacijas tarp branduolinių mėginių ėmimo ribų ir įvairių dekodiavimo hiperparatorių, konkrečiai, didžiausių tarpusavio informacijos analizės rezultatų pagal daugelį kriterijų, atliekant automatinį ir žmogaus vertinimą. Nustatome, kad (1) branduoliniai mėginiai paprastai yra geriausi su 0,7–0,9 ribinėmis vertėmis; (2) a maximum mutual information objective can improve the quality of generated stories;  ir (3) nustatyti automatiniai metriniai rodikliai nėra tinkamai suderinti su žmogaus nuomonėmis apie narracinę kokybę bet kokiu kokybiniu metriniu rodikliu.', 'mk': 'Наративната генерација е отворена задача на НЛП во која моделот генерира приказна која е дадена брза. Задачата е слична на генерацијата на нервен одговор за chatbots; however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  Ние имаме за цел да ја преминеме оваа празнина со апликација и проценка на напредокот во декодирањето на методите за генерација на нервен одговор на нервната наративна генерација. In particular, we employ GPT-2 and perform ablations across nucleus sampling thresholds and diverse decoding hyperparameters-specifically, maximum mutual information-analyzing results over multiple criteria with automatic and human evaluation.  Најдовме дека (1) нуклеарното примерување е генерално најдобро со прагови помеѓу 0,7 и 0,9; (2) максималната цел на взаемна информација може да го подобри квалитетот на генерираните приказни; и (3) воспоставени автоматски метрики не се корелираат добро со човечките пресуди за приказни за квалитетна метрика.', 'mn': 'Харамсалтай үе бол нээлттэй төгсгөл NLP даалгавар юм. Цаг үйлдэл нь мэдрэлийн хариу үйлдэлтэй адилхан. Гэхдээ хариу үйлдэлийн шинэчлэлүүд эдгээр үйлдлийн хоорондын адилхан байдал ч гэсэн түүх үеийн хувьд ихэвчлэн хэрэглэгддэггүй. Бид үүнийг мэдрэлийн түүх үеийн мэдрэлийн хариу үйлдвэрлэх арга замыг ашиглаж, үнэлэх арга замыг ашиглаж байна. Ялангуяа бид GPT-2-г ашиглаж, ядролын хэмжээний хэмжээнд ажиллаж, өөр өөр өөр хэлбэрийн шинжилгээний гиперпараметр, автоматик болон хүн төрөлхтний дүгнэлт дээр олон хэмжээсүүд дээр хамгийн их мэдээллийн шинжилгээ хийх үр Бид 0.7-0.9 хоорондох хэмжээсүүдтэй 1 цөмийн жишээн хэмжээсүүдтэй хамгийн сайн харагдаж байна. (2) хамгийн их харилцааны мэдээллийн зорилго үүсгэсэн түүхийн сайн чанарыг сайжруулж чадна. (3) автоматик метрик байгуулсан нь хүн төрөлхтний ямар ч квалифицийн метрик дээр өгүүлэлтийн чанартай холбоотой байхгүй.', 'ms': 'Generasi cerita adalah tugas NLP yang berakhir terbuka di mana model menghasilkan cerita yang diberikan maklumat. Tugas sama dengan generasi balas saraf bagi chatbot; bagaimanapun, inovasi dalam generasi balas sering tidak dilaksanakan pada generasi cerita, walaupun persamaan antara tugas-tugas ini. Kami bertujuan untuk memecahkan ruang ini dengan melaksanakan dan menilai kemajuan dalam kaedah penyahkodan untuk generasi balas saraf kepada generasi cerita saraf. Secara khususnya, kami menggunakan GPT-2 dan melakukan ablasi melalui ambang pengumpulan nukleus dan penyahkodan berbeza-berbeza hyperparameter-khususnya, maksimum maklumat-analisis antara satu sama lain atas kriteria berbilang dengan penilaian automatik dan manusia. We find that (1) nucleus sampling is generally best with thresholds between 0.7 and 0.9;  (2) objektif maklumat bergaul maksimum boleh meningkatkan kualiti cerita yang dijana; Dan (3) metrik automatik yang ditetapkan tidak berkorelasi dengan penilaian manusia kualiti cerita pada mana-mana metrik kualitatif.', 'no': 'Narrativ generasjon er ei opna slutt NLP- oppgåve der eit modell lagar ei historie gjeven ein prompt. Oppgåva er liknande til generering av neuralsvar for samtaler. Dette er imidlertid ikkje ofte brukt i hendingsgenerasjon av inovasjonar i svar, selv om liknande mellom desse oppgåvene. Vi må bryta dette mellomrommet ved å bruka og evaluera avansert i dekoding av metodar for å generera neuralsvar til neuralnarativ generering. I særskilt bruker vi GPT-2 og utfører aktivasjonar over kjerneprøvegrenser og ulike dekodingsparametrar, spesifisert, maksimum delvis informasjonsanalyserende resultat over fleire kriterier med automatisk og menneskelig evaluering. Vi finn at (1) kjerneprøver er vanlegvis beste med grenseverdiar mellom 0,7 og 0,9. (2) ein maksimal gjennomsnittsformasjonsmål kan forbetra kvaliteten til oppretta historiar; og (3) oppretta automatiske metrikar korrelatert ikkje godt med menneske sprøytebrukar med talekvalitet på nokon kvalitetsverdi.', 'pl': 'Generowanie narracji to otwarte zadanie NLP, w którym model generuje historię z podaniem zapytania. Zadanie jest podobne do generowania odpowiedzi neuronowej dla chatbotów; Jednakże innowacje w generowaniu reakcji często nie są stosowane do generowania narracji, pomimo podobieństwa tych zadań. Naszym celem jest wypełnienie tej luki poprzez zastosowanie i ocenę postępów w metodach dekodowania odpowiedzi neuronowej do generowania narracji neuronowej. W szczególności wykorzystujemy GPT-2 i wykonujemy ablacje przez progi pobierania próbek jądrowych i różnorodne hiperparametry dekodowania – w szczególności maksymalne wzajemne wyniki analizy informacji na wielu kryteriach z automatyczną i ludzką oceną. Stwierdzamy, że (1) próbkowanie jądra jest ogólnie najlepsze przy progach od 0,7 do 0,9; (2) maksymalny cel wzajemnej informacji może poprawić jakość generowanych opowieści; i (3) ustalone automatyczne wskaźniki nie korelują dobrze z ludzkimi ocenami jakości narracji na jakiejkolwiek mierze jakościowej.', 'ro': 'Generarea narativă este o activitate deschisă NLP în care un model generează o poveste dată unei solicitări. Sarcina este similară cu generarea de răspuns neural pentru chatbots; Cu toate acestea, inovațiile în ceea ce privește generarea de răspunsuri nu sunt adesea aplicate generarii naraționale, în ciuda similarității dintre aceste sarcini. Scopul nostru este de a depăși acest decalaj prin aplicarea și evaluarea progreselor în metodele de decodare pentru generarea de răspuns neural la generarea narațiunii neurale. În special, utilizăm GPT-2 și efectuăm ablații peste pragurile de eșantionare nucleară și peste diferiți hiperparametri de decodare - în special, maximum de informații reciproce - rezultate de analiză a informațiilor pe mai multe criterii cu evaluare automată și umană. Considerăm că (1) eșantionarea nucleului este, în general, cea mai bună cu praguri cuprinse între 0,7 și 0,9; (2) un obiectiv maxim de informare reciprocă poate îmbunătăți calitatea poveștilor generate; și (3) măsurătorile automate stabilite nu corelează bine cu judecățile umane de calitate narativă pe orice metrică calitativă.', 'mt': 'Il-ġenerazzjoni narrattiva hija kompitu NLP miftuħ li fih mudell jiġġenera storja mogħtija fil-pront. Il-kompitu huwa simili għall-ġenerazzjoni tar-rispons newrali għall-chatbots; madankollu, l-innovazzjonijiet fil-ġenerazzjoni tar-rispons spiss ma jiġux applikati għall-ġenerazzjoni narrattiva, minkejja s-similarità bejn dawn il-kompiti. Għandna l-għan li nilqgħu din id-distakk billi napplikaw u jivvalutaw l-avvanzi fil-metodi tad-dekodifikazzjoni għall-ġenerazzjoni tar-rispons newrali għall-ġenerazzjoni narrattiva newrali. B’mod partikolari, aħna nużaw il-GPT-2 u nagħmlu ablazzjonijiet bejn il-limiti tat-teħid ta’ kampjuni tan-nukleu u diversi parametri tad-dekodifikazzjoni iperparatteriċi speċifiċi, riżultati massimi ta’ analiżi reċiproka tal-informazzjoni fuq diversi kriterji b’evalwazzjoni awtomatika u umana. We find that (1) nucleus sampling is generally best with thresholds between 0.7 and 0.9;  (2) a maximum mutual information objective can improve the quality of generated stories;  u (3) il-metriċi awtomatiċi stabbiliti ma jikkorrellawx tajjeb ma’ sentenzi umani ta’ kwalità narrattiva fuq kwalunkwe metrika kwalitattiva.', 'sr': 'Narativna generacija je otvorena NLP zadatak u kojem model stvara priču koja je određena brzo. Taj zadatak je sličan generaciji neuroloških odgovora za šatbote; međutim, inovacije u generaciji odgovora često se ne primjenjuju na priču generaciju, uprkos sličnosti između tih zadataka. Mi ciljamo da preusmjerimo taj praznik primjenjivanjem i procjenjivanjem napredova u metodama dekodiranja neuroloških reakcija na generaciju neuralne priče. Posebno, upotrebljavamo GPT-2 i obavljamo aktivacije preko praga uzorka nuklearnih uzorka i različitih hiperparametara za dekodiranje, posebno, maksimalne međusobne analize informacija iznad višestrukih kriterija sa automatskom i ljudskom procjenom. Nalazimo da je (1) uzorak nuklearnog prozora najbolji sa praškovima između 0,7 i 0,9; (2) maksimalni zajednički objekt informacija može poboljšati kvalitet proizvedenih priča; i (3) uspostavljene automatske metrike ne povezuju dobro sa ljudskim osuđivanjima priče o kvalitetnoj metriji.', 'si': 'ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් දෙන්න පුළුවන් කතාවක් නිර්මාණය කරනවා. මේ වැඩේ ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාර ප්\u200dරතිචාරය සමහර විදියට සමහර වෙනවා; නමුත්, ප්\u200dරතික්\u200dරියාත්මක ප්\u200dරතික්\u200dරියාත්මක විශාල ප්\u200dරතික්\u200dරියාත්මක විශාල ප්\u200dරතික්\u200dරියාත්මක වි අපි අදහස් කරනවා මේ අවධානය ප්\u200dරතිචාරය අවශ්\u200dයය සහ අවශ්\u200dයය කරනවා න්\u200dයූරාල් කතාව ප්\u200dරතිචාරයේ ප්\u200dරතිචාරයේ  විශේෂයෙන්, අපි GPT-2 භාවිතා කරනවා සහ නූක්ලියස් සැම්ප්ලින් විශේෂයෙන් සහ විවිධ විශේෂයෙන් සාම්ප්\u200dරේෂණය සහ මිනිසුන් විශේෂයෙන් ප අපිට හොයාගන්න පුළුවන් කියලා (1) නුක්ලියුස් සැම්පල් එක සාමාන්\u200dයයෙන්ම හොඳයි 0.7 සහ 0.9 අතර තියෙන තිය (2) ප්\u200dරමාණය සම්බන්ධ තොරතුරු අරමුණක් ප්\u200dරමාණය කරන්න පුළුවන් නිර්මාණය කතාවක් වගේ කුණ සහ (3) ස්වයංක්\u200dරිය මෙට්\u200dරික් ස්ථාපනය කරලා තියෙන්නේ මිනිස්සුන්ගේ කතාවක්ෂතාවක් හොඳට සම්බන්ධ නැහැ', 'so': 'Qarniga Narrative waa shaqada NLP oo furan, kaas oo modelku sameeyo sheeko lagu soo dejiyey si degdeg ah. Shaqadu waa mid u eg qarniga jawaabta neurada ee jabsada chatbotka; however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  Waxaynu ku talo galaynaa in aan isku dayno goobtan si aan u dalbanno iyo qiimeynayno horumarinta koritaanka koritaanka dhalashada neurada ee qarniga cudurada. Si gaar ah, waxaan shaqaynaynaa GPT-2, waxaana sameynaynaa tababaro tusaalayaasha nukleus oo kala duduwan iyo qiyaastii kala duduwan, si gaar ah u baaritaanka macluumaadka kala duduwan, waxaana ka sameynaynaa midhihiisa kaleba qiimeynta iskumar ah iyo qiimeynta dadka. Waxaan ognahay in sameynta nukleus ay inta badan ugu fiican tahay xerada u dhexeeya 0.7-0.9; (2) Hadalka macluumaadka ee ugu badnaan ee macluumaadka la xiriira wuxuu beddeli karaa qiimaha sheekooyinka la sameeyay; (3) qaababka maamulka ah oo la dhisay ma lahaan wax wanaagsan oo la xiriira xukunka dadka ee qiimaha qiimaha qiimaha ku saabsan mid kastoo qiimo leh.', 'ur': 'نارارت نسل ایک کھلی آنے والی NLP کام ہے جس میں ایک موڈل ایک ایسی کہانی پیدا کرتا ہے جن میں ایک پیغام دی گئی ہے. باتبوٹوں کے لئے نیورل جواب کی نسل کی مثال ہے۔ اگرچہ جواب دینے کی نسل کی نوآوری اکثر کہانیاں نسل پر لازم نہیں ہوتی، اگرچہ ان کاموں کے درمیان برابر ہے. ہم نے اس فاصلہ کو دھوپ کرنے کا ارادہ کیا ہے کہ نئورل داستان کی نسل کے لئے نئورل جواب کے مطابق اضافہ کے مطابق اور مطابق اضافہ کرنے کے ذریعہ۔ مخصوصاً ہم GPT-2 کو استعمال کرتے ہیں اور نوکلیوس نمونٹ ڈرشالڈ اور مختلف ڈیکوڈ پارامیٹر کے ذریعہ آزمائش کرتے ہیں، مخصوصاً مختلف معلومات کے مطابق، بہت سی کریٹریٹروں کے ذریعہ سے زیادہ مشترک معلومات کا تحلیل نت ہم دیکھتے ہیں کہ 0.7 اور 0.9 کے درمیان نیکل نمونہ سے بہتر ہے (2) سب سے زیادہ مشترک معلومات کا مقصد پیدا کیا گیا کہانیاں کی کیفیت کو بہتر کر سکتا ہے۔ اور (3) اٹوٹوٹ میٹریک مقرر کیا گیا تھا کہ انسان کے فیصلے میں کسی کیفیت میٹریک کے بارے میں اچھی طرح برابر نہیں ہیں۔', 'ta': 'விரைவான தலைமுறை ஒரு திறந்த NLP செயல் செயல் அரட்டைக்கான புதிய பதில் உருவாக்குதல் போன்றது; ஆனால், பதில் தலைமுறையில் புதிய புதுப்பாக்கங்கள் பெரும்பாலும் கதையான தலைமுறைக்கு பயன்படுத்தப்படவில்லை, இந்த நாம் இந்த இடைவெளியை பிரிக்க நோக்குகிறோம் புதிய செய்தி தலைமுறைகளில் முன்னேற்றங்களை பயன்படுத்தி மதிப்பிடும் முறைகளை  குறிப்பிட்டு, நாம் ஜிபிடி-2 வை பயன்படுத்தி முனைமை முறைகள் முழுவதும் செயல்படுத்துகிறோம் மற்றும் பல குறிப்பிட்ட அளபுருக்கள் குறிப்பிடுகிறது, அதிகபட்ச உய 0. 7 மற்றும் 0. 9 க்கு இடையில் உள்ள விளிம்புகளுடன் சிறந்தது என்று நாம் கண்டுபிடிக்கிறோம். (2) ஒரு அதிகபட்ச தகவல் பொருள் உருவாக்கப்பட்ட கதைகளின் தரம் மேம்படுத்தலாம். (3) நிறுவப்பட்ட தானியங்கி மெட்ரிக்கள் எந்த கூற்று மீட்ரிக்கும் மேலும் செய்யும் வரலாற்று தரம் தரம் மீது மனித த', 'sv': 'Berättande generering är en öppen NLP-uppgift där en modell genererar en berättelse som får en uppmaning. Uppgiften liknar generering av neuralt svar för chatbots; Innovationer inom responsgenerering tillämpas dock ofta inte på narrativ generering, trots likheten mellan dessa uppgifter. Vi strävar efter att överbrygga detta gap genom att tillämpa och utvärdera framsteg i avkodningsmetoder för neuralt responsgenerering till neuralt narrativ generering. I synnerhet använder vi GPT-2 och utför ablationer över kärnprovströskelvärden och olika avkodningshyperparametrar – specifikt, maximal ömsesidig information – analysresultat över flera kriterier med automatisk och mänsklig utvärdering. Vi finner att (1) kärnprovtagning i allmänhet är bäst med trösklar mellan 0,7 och 0,9; (2) Ett maximalt ömsesidigt informationsmål kan förbättra kvaliteten på genererade berättelser. och (3) etablerade automatiska mätvärden korrelerar inte väl med mänskliga bedömningar av narrativ kvalitet på något kvalitativt mätvärde.', 'uz': "Name The task is similar to neural response generation for chatbots;  Lekin, javob generanining ijodkorlari odatda bu vazifalar orasidagi bir xil bir xil avval qo'llanmagan. Biz bu gap nazar taʼminlovchi zahiraga neyural javob yaratish usullarini qo'llash va qiymatish usullarini ko'rib chiqarishni istaysiz. Ko'pchilik, biz GPT-2 bilan ishlayapmiz va nukler misollar sonlarida qo'llanmalarni bajaramiz va ko'plab hyperparametrlarni hosil qilamiz, biz bir necha xil maʼlumot tartiblarni avtomatik va inson qiymatlari bilan bir necha qiymatga aniqlash natijalarini bajaramiz. Biz o'ylaymiz, nuklus misol umumiy 0. 7 va 0.9 orasidagi chegaralar bilan yaxshi ko'rinadi. (2) Umumiy tarixining sifatini oshirish mumkin. (3) aniqlangan avtomatik metriklarga qo'llanmalar qo'shish holati sifatida o'xshash o'ylamaydi.", 'vi': 'Giới nối là một nhiệm vụ lập trình không giới hạn Thức Thức dậy của một mô hình sẽ tạo ra một câu chuyện được đưa ra nhanh chóng. Nhiệm vụ tương tự với hệ thống phản ứng thần kinh của Chatur. Tuy nhiên, sự phát triển trong hệ thống phản ứng thường không được áp dụng cho hệ thống truyện, mặc dù điểm tương đồng giữa các nhiệm vụ. Mục tiêu của chúng tôi là làm gián đoạn khoảng cách này bằng cách áp dụng và đánh giá tiến bộ trong việc giải mã các phương pháp phản ứng thần kinh với hệ thần kinh. Chúng tôi đặc biệt sử dụng GPT-2 và cắt bỏ khả năng vượt qua ngưỡng vi hạt nhân và cách giải mã nhiều thứ, để phân tích dữ liệu lẫn nhau tối đa hơn nhiều tiêu chuẩn với đánh giá tự động và con người. Chúng tôi thấy (1) việc lấy mẫu nhân là tốt nhất với các ngưỡng giữa 0.7 và 0.9; (2) một mục tiêu thông tin lẫn nhau tối đa có thể cải thiện chất lượng của các câu chuyện; và (3) thiết bị đo tự động được xác định không phù hợp với những phán xét về chất lượng lời kể của con người về bất kỳ đo định chất.', 'bg': 'Генерирането на разкази е задача с отворен край, при която модел генерира история, дадена подкана. Задачата е подобна на генерирането на невронни реакции за чатботи; обаче иновациите в генерирането на отговор често не се прилагат при генерирането на разкази, въпреки сходството между тези задачи. Целта ни е да преодолеем тази пропаст чрез прилагане и оценка на напредъка в декодирането на методите за генериране на неврален отговор към генериране на неврален разказ. По-специално, ние използваме ГПТ-2 и извършваме аблации през праговете на вземане на проби от ядра и разнообразни декодиращи хиперпараметри - конкретно, максимална взаимна информация - анализиращи резултати по множество критерии с автоматична и човешка оценка. Намираме, че (1) вземането на проби от ядра обикновено е най-добро с прагове между 0,7 и 0,9; (2) максимална цел за взаимна информация може да подобри качеството на генерираните истории; и (3) установените автоматични показатели не корелират добре с човешките преценки за качество на разказа по никакъв качествен показател.', 'da': 'Fortællingsgenerering er en åben NLP-opgave, hvor en model genererer en historie, der gives en prompt. Opgaven svarer til neural responsgenerering for chatbots; Innovationer i responsgenerering anvendes dog ofte ikke på fortællingsgenerering på trods af ligheden mellem disse opgaver. Vi tilstræber at bygge bro over denne kløft ved at anvende og evaluere fremskridt i afkodningsmetoder til generering af neural respons til neural fortællingsgenerering. Især anvender vi GPT-2 og udfører ablationer på tværs af kerneprøvetagningstærskler og forskellige dekoderingshyperparametre - specifikt maksimal gensidig information - analyseresultater over flere kriterier med automatisk og menneskelig evaluering. Vi finder, at (1) kerneprøveudtagning generelt er bedst med tærskler mellem 0,7 og 0,9; (2) et maksimalt gensidigt informationsmål kan forbedre kvaliteten af de genererede historier og (3) etablerede automatiske metrics korrelerer ikke godt med menneskelige vurderinger af fortællingskvalitet på nogen kvalitativ metric.', 'de': 'Narrative Generierung ist eine offene NLP-Aufgabe, bei der ein Modell eine Story mit einer Aufforderung generiert. Die Aufgabe ähnelt der Erzeugung neuronaler Reaktionen für Chatbots; Innovationen in der Antwortgenerierung werden jedoch trotz der Ähnlichkeit dieser Aufgaben häufig nicht auf die narrative Generierung angewendet. Wir wollen diese Lücke überbrücken, indem wir Fortschritte bei Decodierungsmethoden für die Erzeugung neuronaler Reaktionen auf die Erzeugung neuronaler Narrative anwenden und evaluieren. Insbesondere setzen wir GPT-2 ein und führen Ablationen über Nukleus-Abtastschwellen und verschiedene Dekodierhyperparameter hinweg durch – spezifisch, maximal gegenseitige Informationsanalyseergebnisse über mehrere Kriterien mit automatischer und menschlicher Auswertung. Wir finden, dass (1) Kernprobenahme im Allgemeinen am besten mit Schwellenwerten zwischen 0,7 und 0,9 ist; (2) ein Höchstmaß an gegenseitiger Information kann die Qualität der erstellten Geschichten verbessern; (3) etablierte automatische Metriken korrelieren nicht gut mit menschlichen Einschätzungen der narrativen Qualität auf irgendeine qualitative Metrik.', 'ko': '서사 생성은 개방형 NLP 임무로 모델이 힌트를 주는 상황에서 이야기를 생성한다.이 임무는 채팅 로봇의 신경 반응 생성과 유사하다.그러나 이러한 임무 사이에 비슷한 점이 있지만 반응 생성에서의 혁신은 서사 생성에 적용되지 않는다.우리의 목표는 신경 반응 생성이 신경 서사 생성에 이르는 디코딩 방법의 진전을 응용하고 평가함으로써 이 격차를 메우는 것이다.특히 GPT-2를 사용하여 샘플링 한도값과 서로 다른 디코딩 초과 파라미터 사이를 융해하는데 구체적으로 말하면 여러 기준에서 최대 상호 정보 분석 결과를 상호 평가하고 자동과 인공 평가를 한다.우리는 (1) 샘플링이 보통 가장 좋고 한도값은 0.7에서 0.9 사이인 것을 발견했다.(2) 최대 상호 정보 목표는 이야기 생성의 질을 향상시킬 수 있다.(3) 구축된 자동 지표는 인류가 어떠한 정성 지표에 대한 서사의 질적 판단과 좋은 관련성이 없다.', 'fa': 'نسل مطمئنی یک کار NLP باز است که یک مدل یک داستان را به عنوان پیشنهاد تولید می کند. این وظیفه به نسل پاسخ عصبی برای چاتبت مشابه است. ولی نوآوری در نسل پاسخ اغلب برای نسل داستان، با وجود شباهت بین این وظیفه\u200cها کاری نمی\u200cکنند. ما هدف داریم این فاصله را با کاربرد و ارزیابی پیشرفت در روش\u200cهای دکوندی برای نسل جواب عصبی به نسل داستان عصبی برگردانیم. مخصوصا، ما از GPT-2 استفاده می کنیم و در طول سطح نمونه\u200cهای نوکری انجام می\u200cدهیم و از طریق دکوندن هیپر پارامترهای مختلف مختلف، بیشترین نتایج\u200cهای تحلیل اطلاعات با اطلاعات مشترک بر خلاف کثیرات مختلف با ارزیابی خودکار و انسان انجام می\u200cدهیم. ما پیدا می\u200cکنیم که نمونه\u200cهای (1) هسته\u200cای معمولاً بهترین است با درازهای بین 0.7 و 0.9. (2) هدف بزرگترین اطلاعات مشترک می\u200cتواند کیفیت داستان\u200cهای تولید را بهتر کند. و (3) متریک اتوماتیک ساخته شده، با قضاوت های انسان از کیفیت داستان بر هیچ متریک کیفیت خوبی ارتباط ندارد.', 'id': 'Generasi Narrative adalah tugas NLP terbuka di mana model menghasilkan cerita yang diberikan segera. Tugas ini mirip dengan generasi respon saraf untuk chatbot; however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  Kami bertujuan untuk memecahkan ruang ini dengan menerapkan dan mengevaluasi kemajuan dalam metode dekodifikasi untuk generasi respon saraf ke generasi narratif saraf. Terutama, kami menggunakan GPT-2 dan melakukan ablasi melalui tangga pengumpulan nukleus dan berbeda dekodasi hyperparameter-spesifik, maksimum informasi-analisis reciproc atas berbagai kriteria dengan evaluasi otomatis dan manusia. Kami menemukan bahwa (1) sampel nukleus biasanya terbaik dengan ambang antara 0,7 dan 0,9; (2) objektif informasi mutua maksimum dapat meningkatkan kualitas cerita yang dihasilkan; dan (3) metrik otomatis yang ditetapkan tidak berkorelasi dengan penghakiman manusia kualitas cerita pada metrik kualitatif apapun.', 'nl': 'Vertalingsgeneratie is een open NLP-taak waarbij een model een verhaal genereert met een prompt. De taak is vergelijkbaar met het genereren van neurale respons voor chatbots; Innovaties in responsgeneratie worden echter vaak niet toegepast op narratieve generatie, ondanks de gelijkenis tussen deze taken. We willen deze kloof overbruggen door vooruitgang in decoderingsmethoden toe te passen en te evalueren voor het genereren van neurale reacties op neurale narratieve generatie. In het bijzonder gebruiken we GPT-2 en voeren we ablaties uit over nucleus sampling drempels en diverse decodering hyperparameters-specifiek, maximale onderlinge informatie-analyseresultaten over meerdere criteria met automatische en menselijke evaluatie. We vinden dat (1) kernmonsterneming over het algemeen het beste is met drempels tussen 0.7 en 0.9; (2) een maximale wederzijdse informatiedoelstelling kan de kwaliteit van gegenereerde verhalen verbeteren; en (3) gevestigde automatische metrics correleren niet goed met menselijke beoordelingen van narratieve kwaliteit op een kwalitatieve metric.', 'hr': 'Narrativna generacija je otvorena NLP zadatak u kojem model stvara priču koja je određena brzo. Taj zadatak je sličan generaciji neuralnog odgovora za šatbote; međutim, inovacije u generaciji odgovora često se ne primjenjuju na priču generaciju, uprkos sličnosti između tih zadataka. Ciljem smo premostiti taj praznik primjenjivanjem i procjenjivanjem napreda metoda dekodiranja neuralnih reakcija na neuralnu priču. Posebno, upotrebljavamo GPT-2 i obavljamo aktivacije preko praga uzorka nuklearnih uzorka i različitih hiperparametara za dekodiranje, posebno, maksimalne međusobne analize informacija iznad višestrukih kriterija s automatskim i ljudskim procjenama. Nalazimo da je (1) uzorak nuklearnog prozora najbolji s praga između 0,7 i 0,9; (2) maksimalni objekt zajedničkih informacija može poboljšati kvalitet proizvedenih priča; i (3) uspostavljene automatske metrike ne odgovaraju dobro sa ljudskim osuđivanjima priče o kvalitetnoj metrici.', 'sq': 'Gjenerata narrative është një detyrë e hapur NLP në të cilën një model gjeneron një histori të dhënë të shpejtë. Detyra është e ngjashme me gjenerimin e përgjigjes nervore për chatbotët; megjithatë, inovacionet në gjeneratën e përgjigjes shpesh nuk zbatohen në gjeneratën narrative, pavarësisht nga ngjashmëria midis këtyre detyrave. Ne synojmë të mbulojmë këtë boshllëk duke aplikuar dhe vlerësuar përparimet në metodat e dekodimit për gjeneratën e përgjigjes nervore në gjeneratën e tregimeve nervore. In particular, we employ GPT-2 and perform ablations across nucleus sampling thresholds and diverse decoding hyperparameters-specifically, maximum mutual information-analyzing results over multiple criteria with automatic and human evaluation.  Ne zbulojmë se (1) kampionati i bërthamës është përgjithësisht më i mirë me prag midis 0.7 dhe 0.9; (2) një objektiv maksimal i informacionit të ndërsjelltë mund të përmirësojë cilësinë e historive të gjeneruara; dhe (3) metrikat automatike të vendosura nuk korrelohen mirë me gjykimet njerëzore të cilësisë treguese në ndonjë metrik kualitativ.', 'af': "Narratiewe generasie is 'n open- ended NLP taak waarin' n model genereer 'n storie gegee 'n prompt. Die taak is gelyk aan neurale antwoord generasie vir chatbots; maar inovaties in antwoord generasie word dikwels nie aangewend na narratiewe generasie, ten ag van die gelykheid tussen hierdie werke. Ons doen doel om hierdie gap te brei deur avansies te toewend en te evalueer in dekoding metodes vir neurale reaksie generasie na neurale narratiewe generasie. Spesifieke, ons gebruik GPT-2 en uitvoer ablasies oor nukleus versameling thresholds en verskeie dekodering hiperparameters-spesifieke, maksimum gemeenskaplike inligting-analisering resultate oor veelvuldige kriterie met outomatiese en menslike evaluering. Ons vind dat (1) nukleus versameling algemeen beste is met driesels tussen 0. 7 en 0. 9; (2) â\x80\x99n maksimum gemeenskaplike inligting-doel kan die kwaliteit van genereerde stories verbeter; â\x80\x99n maksimum gemeenskaplike inligting-doel kan en (3) outomatiese metries geïnstalleer het nie goed met menslike oordelings van narratiewe kwaliteit op enige kwaliteit metriek nie.", 'am': 'የውይይት ትውልድ የተከፈተ የNLP ስራ ነው፡፡ የስራ ትውልድ ለchatbots የሚመስል ነው፤ however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  We aim to bridge this gap by applying and evaluating advances in decoding methods for neural response generation to neural narrative generation.  በተለይም፣ የGPT-2 እና በአካባቢ እና በሰው አካላት እና በተለየ የክፍለ ምርጫዎችን እና የክፍለ አካባቢ ማተሚያ ፍሬዎችን በአካባቢ ክፍሎች ላይ እና በአካባቢ እና በሰው ማስታወቂያ ላይ እናሳያል፡፡ (1) ነክሎስ መስኮት በ0.7 እና 0.9 መካከለኛ የመድረክ መድረክ የተሻለ መሆኑን እናገኛለን፡፡ (2) በተጨማሪው የመረጃ አቃውሞ የፍጥረት ታሪክ ጥያቄን ለማሻል ይችላል፡ (3) የተመሠረተችውን አውቶማቲክቶች በማንኛውም ጥያቄ ሚትሪክ ላይ የሰው ፍርድ መልካም አይታሰራም፡፡', 'az': 'Narrativ nəsil a çıq-sonlu NLP işidir. İçində modellər tələb edilən hekayəni yaradır. Bu işin nöral cavab nəslinə bənzəyir. Ancaq, cavab verən nəsillərin yenilənmələri bu işlərin arasındakı bənzərinə baxmayaraq, hekayət nəsillərinə çox dəfə istifadə edilməz. Biz bu boşluğu nöral danışma nəslinə nəzarət verən nöral reaksiyonu nəslinin dekoding metodlarına uygulamaq və değerləşdirmək istəyirik. Özellikle, GPT-2 istifadə edir və nükleer nümunələrini çəkmək çətinlikləri və müxtəlif hiperparametrləri müəyyən edilmiş, avtomatik və insan değerlendirməsi ilə çoxlu kriteria üstündə müxtəlif bir məlumat analizi sonuçlarını çəkirik. Gördük ki, 0.7 ilə 0.9 arasındakı çərdələr arasında nükleər nümunələri daha yaxşıdır. (2) ən böyük müxtəlif məlumat məqsədi yaratdığı hekayələrin kalitetini daha yaxşılaşdıra bilər; ( 3 ) avtomatik metrik təyin edildi ki, heç bir qiymətli metrik barəsində insanların hekayəti kimi qədər yaxşı qədərləri olmaz.', 'sw': 'Kizazi cha uchunguzi ni jukumu la NLP lililofunguliwa wazi ambapo mtindo huo unatengeneza hadithi iliyotolewa haraka. Kazi ni sawa na uzalishaji wa majibu ya ubongo wa mazungumzo; Hata hivyo, ubunifu wa kizazi cha majibu mara nyingi hautumika kwa kizazi cha simulizi, ingawa ni sawa kati ya kazi hizi. Tuna lengo la kuunganisha mapambano haya kwa kutumia na kutathmini maendeleo katika kupunguza mbinu za uzalishaji wa majibu ya ubongo kwa kizazi cha simulizi za kiserikali. Kwa hakika, tunatumia GPT-2 na kutekeleza mabadiliko katika vituo vya vipimo vya nucleus na vipande mbalimbali vya kupunguza vifaa hasa, kwa uchambuzi wa taarifa kwa kiasi kikubwa zaidi ya vigezo vingi pamoja na utafiti wa binadamu. Tumegundua kuwa sampuli ya nucleus kwa ujumla ni bora zaidi na vitambaa kati ya 0.7 na 0.9; (2) lengo la taarifa ambalo linaweza kuboresha ubora wa hadithi zilizotengenezwa; na mbinu za kujitegemea hazihusisha vizuri na maamuzi ya binadamu ya ubora wa simulizi kwa njia yoyote ya sifa.', 'bs': 'Narativna generacija je otvorena NLP zadatak u kojem model stvara priču koja je određena brzo. Taj zadatak je sličan generaciji neuralnog odgovora za chatbots; međutim, inovacije u generaciji odgovora često se ne primjenjuju na priču generaciju, uprkos sličnosti između tih zadataka. Cilj nas je preusmjeriti taj praznik primjenjivanjem i procjenjivanjem napreda metoda dekodiranja neuralnih reakcija na generaciju neuralne priče. Posebno, upotrebljavamo GPT-2 i obavljamo aktivacije preko praga uzorka nuklearnih uzorka i različitih hiperparametara za dekodiranje, posebno, maksimalne međusobne analize informacija iznad višestrukih kriterija s automatskim i ljudskim procjenama. Nalazimo da je (1) uzorak nuklearnog prozora najbolji od praga između 0,7 i 0,9; (2) maksimalni objekt zajedničke informacije može poboljšati kvalitet proizvedenih priča; i (3) uspostavljene automatske metrike ne odgovaraju dobro sa ljudskim osuđivanjima priče o kvalitetnoj metrici.', 'bn': 'ন্যারেটিভ প্রজন্ম একটি উন্মুক্ত এনএলপি কাজ যেখানে একটি মডেল তৈরি করে দ্রুত একটি গল্প তৈরি করে। The task is similar to neural response generation for chatbots;  তবে প্রতিক্রিয়া প্রজন্মের উদ্ভাবন প্রায়শই বর্ণনা প্রজন্মের কাছে প্রযোজ্য নয়, যদিও এই কাজের মধ্যে একই রকম। নিউরেল প্রজন্মের নিউরেল প্রজন্মের জন্য প্রতিক্রিয়া প্রজন্মের উন্নয়নভাবে নির্ধারিত প্রজন্মের উন্নয়নের মাধ্যমে আমরা এই দু বিশেষ করে, আমরা জিপিটি-২ ব্যবস্থা করি এবং পারমাণবিক স্থানের সারা পারমাণবিক স্থান এবং বিভিন্ন ধরনের হাইপার্পারামিটার বিশেষ করে বিভিন্ন সংক্রান্ত তথ্য বিশ আমরা খুঁজে পাচ্ছি (১) পারমাণবিক নমুনা সাধারণত ০. ৭ থেকে ০. (২) সর্বোচ্চ সর্বোচ্চ সাধারণ তথ্যের উদ্দেশ্য তৈরি করা গল্পের মান উন্নত করতে পারে; আর (৩) স্বয়ংক্রিয়ভাবে প্রতিষ্ঠিত স্বয়ংক্রিয় মেট্রিকের মাধ্যমে মানুষের বিচারের সাথে ভালোভাবে যুক্ত নয় যে', 'ca': "La generació narrativa és una tasca de NLP oberta en la qual un model genera una història proporcionada en un moment preciós. La tasca és similar a la generació de respostes neuronals dels chatbots; however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  Tenim l'objectiu de superar aquest buit aplicant i evaluant els avanços en els mètodes de decodificació de la generació de resposta neuronal a la generació narrativa neuronal. En particular, utilitzem el GPT-2 i fem ablacions a través dels umbres de recolliment de mostres nuclears i diferents resultats de decodificació específicament, màxims d'analítica de la informació mutua sobre múltiples criteris amb evaluació automàtica i humana. Trobem que (1) la mostres del nucli és generalment la millor amb umbres entre 0,7 i 0,9; (2) un objectiu màxim d'informació mutua pot millorar la qualitat de les històries generades; i (3) les mètriques automàtiques establertes no correlacionen bé amb els judicis humans de qualitat narrativa en cap mètrica qualitativa.", 'et': 'Jutustuste genereerimine on avatud NLP ülesanne, mille käigus mudel loob loo antud viibi. Ülesanne sarnaneb chatbotide närvireaktsiooni genereerimisele; Kuid reageerimise uuendusi sageli ei rakendata narratiivse genereerimise puhul, vaatamata nende ülesannete sarnasusele. Meie eesmärk on seda lõhet ületada, rakendades ja hinnates edusamme neuroreaktsiooni genereerimise dekodeerimismeetodites neuronarratiivse genereerimise jaoks. Eelkõige kasutame GPT-2 ja teostame ablatsioone üle tuumaproovivõtu läve ja erinevate dekodeerimise hüperparameetrite – spetsiifiliselt maksimaalse vastastikuse informatsiooni analüüsimise tulemusi mitme kriteeriumi alusel automaatse ja inimese hindamisega. Leiame, et (1) tuumaproovide võtmine on üldiselt kõige parem läve vahemikus 0,7 ja 0,9; (2) vastastikuse teabe maksimaalne eesmärk võib parandada loodud lugude kvaliteeti; ja (3) väljakujunenud automaatsed mõõdikud ei korreleeri hästi inimeste hinnangutega narratiivse kvaliteedi kohta mis tahes kvalitatiivse mõõdiku puhul.', 'tr': "Näsaz döwlet a çyk taýýarlanan NLP täblisidir. Bu nusga soragy berilen hekaýany döretýär. Bu zady näraly jogabat täblisasy üçin meňzeşdir; Ýöne jogabat döwletlerinde täzelikler köplenç taryha döwletlere uygulanmaýar. Biz bu gapyny neural hakyky döwletlere uygulap we çözerek ösümlikleri näyral reaksiýa döwletlere kodlamak üçin göz ösümliklere golaýlaýarys. Özellikle, GPT-2'i kullanıyoruz ve nükleer örnek thresholdlar arasında çalışıyoruz ve farklı kodlama hiperparametreleri özellikle, otomatik ve insan değerlendirmesi üzerinde maksimum paylaşma bilgi-analizi sonuçlarını birden fazla kriteriyle çözüyoruz. 0.7 we 0.9 arasyndaky çykyşlar bilen (1) nükleer sammyny gowydyr. (2) Ýüklenmiş hekaýalaryň kalitesini gowylaşdyryp bilýär. (3) Otomatik metrikler adamlaryň hiçhili bir metriýa görä hekaýat kaliwatynyň pikirlerini gowy görnüşmeýär.", 'fi': 'Narratiivinen sukupolvi on avoin NLP-tehtävä, jossa malli luo tarinan kehotukselle. Tehtävä on samanlainen kuin chatbottien neurovasteen luominen; vastausten tuottamiseen liittyviä innovaatioita ei kuitenkaan usein sovelleta narratiiviseen tuottamiseen, vaikka nämä tehtävät ovat samankaltaisia. Pyrimme kuromaan tämän kuilun umpeen soveltamalla ja arvioimalla neurovasteen tuottamisen dekoodamenetelmien kehitystä neuronarratiiviseen tuottamiseen. Erityisesti käytämme GPT-2:ta ja suoritamme ablaatioita ydinnäytteenottokynnysten ja erilaisten dekoodaushyperparametrien yli – erityisesti maksimaalisen keskinäisen informaation – analysoinnin tuloksia useilla kriteereillä automaattisella ja inhimillisellä arvioinnilla. Havaitsemme, että (1) ydinnäytteenotto on yleensä paras kynnysarvojen ollessa 0,7–0,9; (2) keskinäisen tiedottamisen enimmäistavoite voi parantaa tuotettujen tarinoiden laatua; ja (3) vakiintuneet automaattiset mittarit eivät korreloi hyvin ihmisten kertomusten laadun arviointiin millään laadullisella mittarilla.', 'cs': 'Generování vyprávění je otevřený úkol NLP, ve kterém model generuje příběh s výzvou. Úkol je podobný generování nervové odezvy pro chatboty; Nicméně inovace v generování reakcí nejsou často aplikovány na generování narativů, navzdory podobnosti mezi těmito úkoly. Naším cílem je překlenout tuto propast aplikací a hodnocením pokroků v dekódování metod pro generování nervové odezvy na generování nervových narativů. Zejména používáme GPT-2 a provádíme ablace napříč prahovými hodnotami vzorkování jádra a různými dekódovanými hyperparametry – specificky maximálně vzájemně analyzujícími výsledky analýzy informací na více kritériích s automatickým a lidským vyhodnocením. Zjišťujeme, že (1) vzorkování jádra je obecně nejlepší při prahových hodnotách mezi 0,7 a 0,9; (2) maximální vzájemný informační cíl může zlepšit kvalitu vytvořených příběhů; a (3) zavedené automatické metriky dobře nekorelují s lidskými hodnoceními kvality vyprávění na žádné kvalitativní metrice.', 'hy': 'Narrative generation is an open-ended NLP task in which a model generates a story given a prompt.  Նյարդային պատասխանների սերունդը նման է շտաբոտների համար, however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  We aim to bridge this gap by applying and evaluating advances in decoding methods for neural response generation to neural narrative generation.  In particular, we employ GPT-2 and perform ablations across nucleus sampling thresholds and diverse decoding hyperparameters-specifically, maximum mutual information-analyzing results over multiple criteria with automatic and human evaluation.  Մենք հայտնաբերում ենք, որ (1) միջուկի նմուշները սովորաբար լավագույն են 0.7-0.9 սահմաններով: (2) a maximum mutual information objective can improve the quality of generated stories;  և (3) հիմնված ավտոմատիկ մետրիկները լավ չեն կապված պատմության որակի մարդկային դատողությունների հետ որևէ որակային մետրիկայի վրա:', 'jv': 'Generation Narrate is an open-end NLP task in that a model Generes a history given a request. Penangkat sing dikarepaké karo urip maneh nêr, nggo nganggo barang karo bêt;  Nanging, enyarno sing gak bener menyang karo rewarno sak ora aplikasi kanggo nganggo perusahaan kanggo ngerasahan kapan, gak bener perusahaan langgar sampeyan karo perusahaan iki. Awak dhéwé iki luwih nggawe gap iki dadi nggawe nguasal lan nggawe barang kelas supoyo nggawe barang nggawe barang urip kuwi nggawe nguasal urip. In partial, we use GST-2 and do enabled preko Nukleus sampling threshold and Varie decoding guierparameters-Specically, maximum interal information-testing output about Multiple criteria with automatically and Human measurement. Awak dhéwé luwih (1) ngregani alas-alas kuwi adalah luwih apik meluang 0.7 lan 0.9; awak dhéwé (2) kesungano sistem informasi sing luwih dumadhi kanggo luwih-luwih ingkang kesalahan kanggo nggawe barang seneng pisan; ingkang Karo', 'sk': 'Pripovedna generacija je opravilo NLP z odprtim koncem, pri katerem model ustvari zgodbo na poziv. Naloga je podobna generaciji nevronskega odziva za chatbote; Vendar pa se inovacije pri ustvarjanju odzivov pogosto ne uporabljajo pri ustvarjanju pripovedi, kljub podobnosti med temi nalogami. To vrzel želimo premostiti z uporabo in ocenjevanjem napredka pri dekodiranju metod za generiranje nevronskega odziva na generiranje nevronskih pripovedi. Zlasti uporabljamo GPT-2 in izvajamo ablacije prek mejnih vrednosti vzorčenja jedra in različnih hiperparametrov dekodiranja – specifično, maksimalnih medsebojnih informacij – analiziramo rezultate po več kriterijih z avtomatsko in človeško oceno. Ugotovili smo, da je (1) vzorčenje jedra na splošno najboljše z mejnimi vrednostmi med 0,7 in 0,9; (2) največji cilj medsebojnega obveščanja lahko izboljša kakovost ustvarjenih zgodb; in (3) uveljavljene avtomatske meritve se ne povezujejo dobro s človeškimi presojami pripovedne kakovosti pri kateri koli kvalitativni metriki.', 'bo': 'ཆེས་མཁན་གྱི་མི་རབས་ནི་ཁ་ཕྱེས་པའི་NLP ལས་ཀ་ཞིག་རེད། མ་དཔེ་ཅིག་ནང་མ་དཔེ་གཏོང་བརྡ་ཞིག་གསར་བསྐྲུན་ཡོད་པ བྱ་འགུལ་འདི་གླེང་མོལ་གྱི་དཔུད་སྐྱེན་ཚོའི་གླེང་མོལ་དང་མཐུན་པ། འོན་ཀྱང་། ལན་གསལ་བཤད་ཀྱི་མི་རྗེས་སུ་གསར་གཏོད་འགྱུར་བ་ནི་རྒྱུན་ཡང་སྲུང་བཤད་ཀྱི་མིན་པ་ཡིན། ང་ཚོས་བར་སྟོང་འདི་དག་རྐྱེན་འདུག་ལ་ཉེན་སྤྱོད་དང་རྒྱལ་ཁབ་ཀྱི་ཐབས་ལམ་ལུགས་འདི་བསྡུར་བ་དང་མཐུན་རྐྱེན་བཟོ་བ་འདི་ In particular, we employ GPT-2 and perform ablations across nucleus sampling thresholds and diverse decoding hyperparameters-specifically, maximum mutual information-analyzing results over multiple criteria with automatic and human evaluation. ང་ཚོས་0.7 དང་0.9་དབར་གྱི་གཟུགས་རིས་གཅིག་པུ་མཐོང་ན། (2) འཛམ་གླིང་འབྲེལ་གྱི་གནས་ཚུལ་དམིགས་ཡུལ་མང་ཤོས་ཀྱིས་གསར་བསྐྲུན་ཡོད་པའི་གནད་དོན and (3) established automatic metrics do not correlate well with human judgments of narrative quality on any qualitative metric.', 'he': 'Narrative generation is an open-ended NLP task in which a model generates a story given a prompt.  The task is similar to neural response generation for chatbots;  however, innovations in response generation are often not applied to narrative generation, despite the similarity between these tasks.  אנחנו מתכוונים לשבור את הפער הזה על ידי שימוש והערכה התקדמות בשיטות פיתוח לדור תגובה עצבית לדור סיפורי עצבי. במיוחד, אנו משתמשים ב-GPT-2 ולבצע חבלות ברחבי גבולות דגימות גרעיניים ומגוברים של פיתוח היפרפרמטרים במיוחד, תוצאות מקסימומיות של ניתוח מידע משותף על קריטורים רבים עם עריכה אוטומטית ואנושית. אנו מוצאים כי (1) דגימה גרעינית היא בדרך כלל הטובה ביותר עם גבולות בין 0.7 ל-0.9; (2) a maximum mutual information objective can improve the quality of generated stories;  and (3) established automatic metrics do not correlate well with human judgments of narrative quality on any qualitative metric.', 'ha': "Kishi na Narrative yana wani aikin NLP wanda aka buɗe an buɗa ɗe, a cikinsa wani misalin ya ƙãga wani lãbãri wanda aka gaura da shi. Kijan yana daidai da tsarin mai karɓar neural wa chatbots; A lokacin da, mafarin da za'a amfani da kiyãyen mai gaya ba ko da yawa, kuma ingawa, da misãlin tsakanin wannan aikin. Munã nufin mu sami wannan gaura da za'a yi amfani da su canza kodi cikin shiryoyin kodi wa zaɓen ajir neural zuwa kizayen lãbãrin neural. Kayya, za mu yi amfani da GPT-2 kuma munã aiki masu ƙari a tsakanin misãlai na nunuklus da kodi-parameteri masu buƙata, a tsakanin, Analyya fassarar mutane a kan jama'a masu yawa da yana ƙayyade kima farat ɗaya da mutum. Muna gane (1) misalin nuklus na fi zama mafi alhẽri a tsakanin 0.7 zuwa 0.9; (2) An ƙara muhimmin abu na haɗi da jama'a, zai ƙara wa sifar lãbãrin da aka ƙãga; kuma metriki da aka samar da shi farat ɗaya ba su yi daidai da hukuncin mutane na tsari a kan wani mataimaki."}
