{'en': 'Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs', 'ar': 'زيادة المحادثات المعرفة القائمة على الموضوع مع الرسوم البيانية المعرفية الديناميكية المبنية', 'pt': 'Aumentando as conversas fundamentadas no conhecimento com base no tópico com gráficos de conhecimento dinâmicos construídos', 'es': 'Aumentar las conversaciones basadas en el conocimiento con conciencia temática con gráficos de conocimiento dinámicos', 'fr': 'Augmenter les conversations fondées sur les connaissances basées sur des sujets avec des graphiques de connaissances dynamiques intégrés', 'ja': 'ダイナミックな構築されたナレッジグラフを使用したトピック認識知識に基づいた会話の拡張', 'zh': '以动构之知图谱增主知之本', 'hi': 'गतिशील निर्मित ज्ञान रेखांकन के साथ विषय जागरूक ज्ञान-आधारित वार्तालापों को बढ़ाना', 'ru': 'Расширение тематики Осведомленные и основанные на знаниях беседы с помощью динамических построенных графиков знаний', 'ga': 'Comhráite Bunaithe ar an Eolas le Topaic a Mhéadú le Graif Faisnéise Tógtha Dinimiciúla', 'ka': 'აგგგენტირება ტემიკის შეცდომა მეცნიერება და გაზომირებული პარამეტრები დინამიკური შექმნილი მეცნიერება', 'hu': 'Témakörök tudásalapú beszélgetések bővítése dinamikus beépített tudásalapú grafikonokkal', 'el': 'Ενίσχυση συζητήσεων βασισμένων στη γνώση με δυναμικά δομημένα γραφήματα γνώσης', 'it': 'Aumentare le conversazioni basate sulla conoscenza con argomenti consapevoli con grafici di conoscenza integrati dinamici', 'kk': 'Динамикалық ендірілген білім графикалық тақырыптарды көтеру', 'mk': 'Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs', 'lt': 'Didinti žiniomis pagrįstas temas grindžiamas konversacijas su dinaminiais įgytų žinių grafikais', 'ms': 'Meningkatkan Perbualan Berdasarkan Pengetahuan Tema dengan Graf Pengetahuan Dibangun Dinamik', 'mt': 'Żieda fil-konverżjonijiet ibbażati fuq l-għarfien dwar is-suġġett b’Grafiki Dinamiċi ta’ Għarfien Mibni', 'mn': 'Динамик бүтээгдэхүүний мэдлэг графикийн сэдэв', 'ml': 'പ്രമേയത്തിന്റെ അറിവ്- നിലനിര്\u200dമ്മിക്കുന്ന സംസാരം നിര്\u200dമ്മിക്കുന്നു', 'no': 'Oppgradering av emne bekreft kjennomsikt- grunnlagte samtaler med dynamiske innbygde kjennomsiktige grafikk', 'ro': 'Intensificarea conversațiilor bazate pe cunoștințe conștiente de subiecte cu grafice dinamice de cunoștințe construite', 'si': 'විශේෂය ප්\u200dරශ්නයක් විදිහට ප්\u200dරශ්නයක් විදිහට දැනගන්න-ග්\u200dරූන්ඩ් සංවාද සමඟ වාර්තාව', 'sr': 'Povećavajući tema o poznavanju znanja i razgovore sa dinamičkim ografijama napravljenih znanja', 'sv': 'Förstärka ämnesmedvetna kunskapsbaserade konversationer med dynamiska inbyggda kunskapsgrafer', 'ta': 'Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs', 'pl': 'Rozszerzenie konwersacji opartych na wiedzy dzięki dynamicznym wykresom wiedzy', 'ur': 'افزایش موضوع جاننے والی علم-گروڈ کی مکالمات دینامیک سائل علم گراف کے ساتھ', 'so': 'Aqoonshaha bogga aqoonta-aasaaska la xiriira hadallada Dynamic Build Knowledge Graphs', 'uz': 'Name', 'vi': 'Mở rộng Lớp học Nhận thức Xung quanh', 'da': 'Udvidelse af emnebevidste vidensbaserede samtaler med dynamiske indbyggede vidensgrafer', 'bg': 'Разговори, основани на знанието, с динамични графики за изградено знание', 'nl': 'Gesprekken op basis van kennis met topics uitbreiden met dynamische ingebouwde kennisgrafieken', 'hr': 'Povećavajući razgovor s dinamičkim napravljenim znanjem', 'de': 'Erweitern von themenbewussten wissensbasierten Gesprächen mit dynamischen erstellten Wissensdiagrammen', 'ko': '동적 으로 구축된 지식 그래프 를 사용하여 주제 에 기초한 지식 대화 를 강화 하다', 'fa': 'افزایش موضوع آگاهی دانش و مکالمات با گرافهای دانش های دینامیک ساخته شده', 'sw': 'Kusoma mada yenye ufahamu wa ufahamu ulioanzishwa na Mazungumzo na Tafsiri ya Ujuzi wa Dynamics', 'id': 'Meningkatkan Perbualan Berdasarkan Pengetahuan Tema dengan Graf Pengetahuan Dibangun Dinamik', 'af': 'Opgroei onderwerp bekende kennis-groundeerde gesprekke met dinamiese ingeboude kennis grafieke', 'tr': 'Güçlendirilýan Topary Bilgi-Güçlendirilýan Geçmişler Dinamik Girişmiş Bilgi Grafleri bilen', 'am': 'ምርጫዎች', 'sq': 'Rritja e bisedimeve thematike të bazuara në njohuri me grafike dinamike të ndërtuar të njohurive', 'bn': 'ডায়ানিমিক বিন্যাস নির্মাণ বিজ্ঞান গ্রাফের সাথে বিষয়বস্তুর সচেতনতা জ্ঞান-গ্রাফের কথোপকথন', 'hy': 'Գիտության հիմնված գիտելիքի թեմայի աճը դինամիկ կառուցված գիտելիքի գրաֆների հետ', 'az': 'Dinamik Yapılmış Bilim Grafları ilə Özünün Bilməyi-Bilməyi-Zənginləşdirilməsi', 'ca': 'Aumentar les converses basades en el coneixement amb gràfics dinàmics de coneixement construït', 'bs': 'Povećavajući razgovor s dinamičkim ografijama napravljenih znanja', 'fi': 'Aiheeseen perustuvia keskusteluja dynaamisilla rakennetuilla tietokaavioilla', 'et': 'Teadmistepõhised vestlused dünaamiliste ehitatud teadmisgraafikutega', 'cs': 'Rozšíření konverzací založených na znalostech s dynamickými znalostními grafy', 'jv': 'AGmenting Subject Awake Bilih-Gruundd conversations with dynamics Builted knowknowknownGraph', 'sk': 'Pogovori, temelječi na znanju, z dinamičnimi graafi znanja', 'he': 'גידול שיחות מודעות על נושא עם גרפי ידע בנויים דינמיים', 'ha': 'Phonon:: MMF:: EffectFactory', 'bo': 'Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs'}
{'en': 'Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations. However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat. To address this problem, we propose a dynamic knowledge graph-based topical conversation model (DKGT). Given a dialog history context, our model first builds knowledge graphs from the context as an imitation of human’s ability to form logical relationships between known and unknown topics during a conversation. This logical information will be fed into a topic predictor to promote topic management, then facilitate background knowledge selection and response generation. To the best of our knowledge, this is the first attempt to dynamically form  knowledge graphs  between chatting topics to assist dialog topic management during a conversation. Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses comparing to several strong baselines.', 'pt': 'O gerenciamento de tópicos de diálogo e a seleção de conhecimento de fundo são fatores essenciais para o sucesso de conversas de domínio aberto baseadas em conhecimento. No entanto, os modelos existentes são executados principalmente com bases de conhecimento simétricas ou estilizadas com papéis pré-definidos entre parceiros de conversação, enquanto as pessoas geralmente têm seu próprio conhecimento antes de um bate-papo real. Para resolver este problema, propomos um modelo de conversação tópica baseado em grafos de conhecimento dinâmico (DKGT). Dado um contexto de histórico de diálogo, nosso modelo primeiro constrói gráficos de conhecimento a partir do contexto como uma imitação da capacidade humana de formar relações lógicas entre tópicos conhecidos e desconhecidos durante uma conversa. Essas informações lógicas serão alimentadas em um preditor de tópicos para promover o gerenciamento de tópicos e, em seguida, facilitar a seleção do conhecimento básico e a geração de respostas. Até onde sabemos, esta é a primeira tentativa de formar dinamicamente gráficos de conhecimento entre tópicos de bate-papo para auxiliar no gerenciamento de tópicos de diálogo durante uma conversa. Os resultados experimentais demonstram que nosso modelo pode agendar adequadamente os tópicos de conversação e escolher o conhecimento adequado para gerar respostas informativas em comparação com várias linhas de base fortes.', 'fr': "La gestion des sujets de dialogue et la sélection des connaissances de base sont des facteurs essentiels au succès des conversations ouvertes fondées sur les connaissances. Cependant, les modèles existants sont principalement réalisés avec des bases de connaissances symétriques ou stylisés avec des rôles prédéfinis entre partenaires de conversation, tandis que les personnes ont généralement leurs propres connaissances avant un véritable bavardage. Pour résoudre ce problème, nous proposons un modèle de conversation thématique basé sur des graphes de connaissances dynamiques (DKGT). Dans un contexte d'histoire de dialogue, notre modèle construit d'abord des graphes de connaissances à partir du contexte comme une imitation de la capacité de l'être humain à établir des relations logiques entre des sujets connus et inconnus au cours d'une conversation. Ces informations logiques seront introduites dans un prédicteur de sujet afin de promouvoir la gestion des sujets, puis de faciliter la sélection des connaissances de base et la génération de réponses. À notre connaissance, il s'agit de la première tentative de former dynamiquement des graphes de connaissances entre les sujets de discussion afin de faciliter la gestion des sujets de dialogue pendant une conversation. Les résultats expérimentaux montrent que notre modèle peut planifier correctement les sujets de conversation et sélectionner les connaissances appropriées pour générer des réponses informatives par rapport à plusieurs bases de référence solides.", 'ar': 'تعد إدارة موضوع الحوار واختيار الخلفية من العوامل الأساسية لنجاح محادثات المجال المفتوح القائمة على المعرفة. ومع ذلك ، يتم تنفيذ النماذج الحالية بشكل أساسي باستخدام قواعد المعرفة المتماثلة أو بأسلوب منمق بأدوار محددة مسبقًا بين شركاء المحادثة ، بينما يكون لدى الأشخاص عادةً معرفتهم الخاصة قبل محادثة حقيقية. لمعالجة هذه المشكلة ، نقترح نموذج محادثة موضعي ديناميكي قائم على الرسم البياني للمعرفة (DKGT). بالنظر إلى سياق تاريخ الحوار ، يقوم نموذجنا أولاً ببناء الرسوم البيانية المعرفية من السياق كتقليد لقدرة الإنسان على تكوين علاقات منطقية بين الموضوعات المعروفة وغير المعروفة أثناء المحادثة. سيتم تغذية هذه المعلومات المنطقية في متنبئ بالموضوع لتعزيز إدارة الموضوع ، ثم تسهيل اختيار المعرفة الأساسية وتوليد الاستجابة. على حد علمنا ، هذه هي المحاولة الأولى لتشكيل الرسوم البيانية المعرفية ديناميكيًا بين موضوعات الدردشة للمساعدة في إدارة موضوع الحوار أثناء المحادثة. تظهر النتائج التجريبية أن نموذجنا يمكنه جدولة موضوعات المحادثة بشكل صحيح واختيار المعرفة المناسبة لتوليد ردود مفيدة مقارنة بالعديد من الخطوط الأساسية القوية.', 'es': 'La gestión de temas de diálogo y la selección de conocimientos básicos son factores esenciales para el éxito de las conversaciones de dominio abierto basadas en el conocimiento. Sin embargo, los modelos existentes se realizan principalmente con bases de conocimiento simétricas o se estilizan con roles predefinidos entre compañeros de conversación, mientras que las personas generalmente tienen sus propios conocimientos antes de una charla real. Para abordar este problema, proponemos un modelo de conversación temática (DKGT) basado en gráficos de conocimiento dinámico. Dado un contexto de historia de diálogos, nuestro modelo primero construye gráficos de conocimiento a partir del contexto como una imitación de la capacidad del ser humano para formar relaciones lógicas entre temas conocidos y desconocidos durante una conversación. Esta información lógica se incorporará a un predictor de temas para promover la gestión del tema y, a continuación, facilitar la selección de conocimientos básicos y la generación de respuestas. Hasta donde sabemos, este es el primer intento de formar dinámicamente gráficos de conocimiento entre los temas de chat para ayudar a la gestión de los temas de diálogo durante una conversación. Los resultados experimentales demuestran que nuestro modelo puede programar adecuadamente los temas de conversación y elegir el conocimiento adecuado para generar respuestas informativas en comparación con varias líneas de base sólidas.', 'zh': '言主题治背景择以知识为基者,成功之关键因素也。 然今之模形,主于知识库行,或以对侣之预定义角色为风格化,而人常于闲话之前自有知识。 为此一端图谱主题对(DKGT)。 给定言史下文,先构知图谱于上下文,以为知与未知之间成逻辑关系之能。 输入主题预测器中,以趣主司,然后背景知应之。 以吾所知,是始试于聊天主题之间,动成知识图谱,以助对话之对。 实验结果表明,比于诸强基线,吾法可以正言而择其所知以成信息性应。', 'hi': 'संवाद विषय प्रबंधन और पृष्ठभूमि ज्ञान चयन ज्ञान-आधारित ओपन-डोमेन वार्तालापों की सफलता के लिए आवश्यक कारक हैं। हालांकि, मौजूदा मॉडल मुख्य रूप से सममित ज्ञान आधारों के साथ किए जाते हैं या संवादी भागीदारों के बीच पूर्व-परिभाषित भूमिकाओं के साथ स्टाइल किए जाते हैं, जबकि लोगों के पास आमतौर पर वास्तविक चिट-चैट से पहले अपना ज्ञान होता है। इस समस्या को हल करने के लिए, हम एक गतिशील ज्ञान ग्राफ-आधारित सामयिक वार्तालाप मॉडल (DKGT) का प्रस्ताव करते हैं। एक संवाद इतिहास संदर्भ को देखते हुए, हमारा मॉडल पहले एक बातचीत के दौरान ज्ञात और अज्ञात विषयों के बीच तार्किक संबंध बनाने की मानव की क्षमता की नकल के रूप में संदर्भ से ज्ञान ग्राफ बनाता है। इस तार्किक जानकारी को विषय प्रबंधन को बढ़ावा देने के लिए एक विषय भविष्यवक्ता में खिलाया जाएगा, फिर पृष्ठभूमि ज्ञान चयन और प्रतिक्रिया पीढ़ी की सुविधा प्रदान की जाएगी। हमारे ज्ञान का सबसे अच्छा करने के लिए, यह एक वार्तालाप के दौरान संवाद विषय प्रबंधन की सहायता के लिए चैटिंग विषयों के बीच गतिशील रूप से ज्ञान रेखांकन बनाने का पहला प्रयास है। प्रयोगात्मक परिणाम प्रकट करते हैं कि हमारा मॉडल संवादात्मक विषयों को ठीक से शेड्यूल कर सकता है और कई मजबूत बेसलाइन की तुलना में जानकारीपूर्ण प्रतिक्रियाएं उत्पन्न करने के लिए उपयुक्त ज्ञान चुन सकता है।', 'ja': 'ダイアログのトピック管理と背景知識の選択は、知識に基づいたオープンドメインの会話を成功させるために不可欠な要素です。 しかし、既存のモデルは主に対称的な知識ベースで実行されるか、会話パートナー間で事前に定義された役割でスタイル化されるが、人々は通常、実際のチャットチャットの前に独自の知識を持っている。 この問題に対処するために、私たちは動的知識グラフベースのトピック会話モデル（ DKGT ）を提案します。 ダイアログ履歴の文脈を考えると、私たちのモデルはまず、会話中に既知のトピックと未知のトピックの間に論理的な関係を形成する人間の能力の模倣として、文脈から知識グラフを構築します。 この論理的な情報は、トピック管理を促進するためにトピック予測器にフィードバックされ、その後、背景知識の選択と応答生成を促進します。 私たちの知る限りでは、これは会話中のダイアログトピック管理を支援するために、チャットトピック間でナレッジグラフを動的に形成する最初の試みです。 実験結果は、いくつかの強力なベースラインと比較して、私たちのモデルが会話トピックを適切にスケジュールし、情報に基づいた回答を生成するために適切な知識を選択できることを示しています。', 'ru': 'Управление темой диалога и отбор фоновых знаний являются важными факторами успеха основанных на знаниях разговоров в открытой области. Тем не менее, существующие модели в основном выполняются с симметричными базами знаний или стилизованы с заранее определенными ролями между партнерами по разговору, в то время как люди обычно имеют свои собственные знания перед реальным чатом. Для решения этой проблемы мы предлагаем динамическую модель топического разговора на основе графа знаний (DKGT). Учитывая контекст истории диалога, наша модель сначала строит графики знаний из контекста как имитацию способности человека формировать логические отношения между известными и неизвестными темами во время разговора. Эта логическая информация будет введена в предиктор темы, чтобы способствовать управлению темой, а затем облегчить выбор фоновых знаний и генерацию ответов. Насколько нам известно, это первая попытка динамически формировать графики знаний между темами чата, чтобы помочь в управлении темами диалога во время разговора. Экспериментальные результаты показывают, что наша модель может правильно планировать разговорные темы и выбирать подходящие знания, чтобы генерировать информативные ответы по сравнению с несколькими сильными базовыми линиями.', 'ga': 'Is fachtóirí ríthábhachtacha iad bainistíocht topaicí dialóige agus roghnú eolais chúlra chun go n-éireoidh le comhráite fearainn oscailte eolas-bhunaithe. Mar sin féin, déantar samhlacha atá ann cheana féin go príomha le boinn eolais siméadracha nó stílithe le róil réamhshainithe idir comhpháirtithe comhrá, agus is gnách go mbíonn a gcuid eolais féin ag daoine roimh fhíorchat-chomhrá. Chun aghaidh a thabhairt ar an bhfadhb seo, molaimid samhail chomhrá tráthúil bunaithe ar ghraif (DKGT) d’eolas dinimiciúil. I bhfianaise chomhthéacs na staire dialóige, tógann ár múnla graif eolais ón gcomhthéacs ar dtús mar aithris ar chumas an duine caidrimh loighciúla a chruthú idir topaicí aitheanta agus anaithnid le linn comhrá. Cuirfear an fhaisnéis loighciúil seo isteach i réamhaithriseoir topaicí chun bainistíocht topaicí a chur chun cinn, ansin éascóidh sé roghnú eolais chúlra agus giniúint freagraí. Chomh fada agus is eol dúinn, is é seo an chéad iarracht chun graif eolais a fhoirmiú go dinimiciúil idir topaicí comhrá chun cabhrú le bainistíocht topaicí dialóige le linn comhrá. Léiríonn torthaí turgnamhacha gur féidir lenár múnla topaicí comhrá a sceidealú i gceart agus eolas oiriúnach a phiocadh chun freagraí faisnéiseacha a ghiniúint i gcomparáid le roinnt bonnlínte láidre.', 'hu': 'A párbeszédtémakörök kezelése és a háttér-ismeretek kiválasztása alapvető tényező a tudásalapú nyílt domain beszélgetések sikerének. A meglévő modelleket azonban elsősorban szimmetrikus tudásbázisokkal hajtják végre, vagy előre meghatározott szerepekkel stilizálják a beszélgető partnerek között, míg az emberek általában saját tudásukkal rendelkeznek egy igazi csevegés előtt. A probléma megoldására dinamikus tudásgrafokon alapuló aktuális beszélgetési modellt (DKGT) javasolunk. A párbeszédtörténeti kontextusban modellünk először a kontextusból épít tudásgrafokat, mint az ember azon képességének utánzása, hogy logikai kapcsolatokat alakítson ki ismert és ismeretlen témák között egy beszélgetés során. Ezeket a logikai információkat a témakörök előrejelzőjébe tápláljuk, hogy elősegítsük a témakörök menedzsmentjét, majd megkönnyítsük a háttérkutatás kiválasztását és a válasz generálását. Legjobb tudásunk szerint ez az első kísérlet arra, hogy dinamikusan tudásdiagramokat formáljunk a csevegő témák között, hogy segítsük a párbeszédtéma kezelését egy beszélgetés során. A kísérleti eredmények azt mutatják, hogy modellünk megfelelően ütemezi a beszélgetési témákat és kiválasztja a megfelelő ismereteket, hogy információs válaszokat generáljon több erős alapvonalhoz képest.', 'el': 'Η διαχείριση θεμάτων διαλόγου και η επιλογή γνώσεων υπόβαθρου είναι βασικοί παράγοντες για την επιτυχία των συζητήσεων ανοικτού τομέα βασισμένων στη γνώση. Ωστόσο, τα υπάρχοντα μοντέλα εκτελούνται κυρίως με συμμετρικές βάσεις γνώσεων ή στυλοποιημένα με προκαθορισμένους ρόλους μεταξύ συνομιλητών, ενώ οι άνθρωποι συνήθως έχουν τη δική τους γνώση πριν από μια πραγματική κουβεντούλα. Για να αντιμετωπιστεί αυτό το πρόβλημα, προτείνουμε ένα δυναμικό μοντέλο επίκαιρης συνομιλίας βασισμένο σε γραφήματα γνώσης (DKGT). Δεδομένης ενός ιστορικού διαλόγου, το μοντέλο μας δημιουργεί αρχικά γραφήματα γνώσης από το πλαίσιο ως μιμηση της ικανότητας του ανθρώπου να σχηματίζει λογικές σχέσεις μεταξύ γνωστών και άγνωστων θεμάτων κατά τη διάρκεια μιας συνομιλίας. Αυτές οι λογικές πληροφορίες θα τροφοδοτηθούν σε έναν προγνωστή θέματος για να προωθήσει τη διαχείριση θεμάτων, στη συνέχεια να διευκολύνει την επιλογή γνώσεων υποβάθρου και τη δημιουργία απόκρισης. Από ό,τι γνωρίζουμε, αυτή είναι η πρώτη προσπάθεια να διαμορφώσουμε δυναμικά γραφήματα γνώσης μεταξύ θεμάτων συνομιλίας για να βοηθήσουμε τη διαχείριση θεμάτων διαλόγου κατά τη διάρκεια μιας συνομιλίας. Τα πειραματικά αποτελέσματα δείχνουν ότι το μοντέλο μας μπορεί να προγραμματίσει σωστά θέματα συζήτησης και να επιλέξει κατάλληλη γνώση για να δημιουργήσει ενημερωτικές απαντήσεις σε σύγκριση με αρκετές ισχυρές γραμμές βάσης.', 'it': "La gestione degli argomenti di dialogo e la selezione delle conoscenze di base sono fattori essenziali per il successo delle conversazioni a dominio aperto basate sulla conoscenza. Tuttavia, i modelli esistenti sono eseguiti principalmente con basi di conoscenza simmetriche o stilizzati con ruoli predefiniti tra partner conversazionali, mentre le persone di solito hanno le proprie conoscenze prima di una vera chiacchierata. Per affrontare questo problema, proponiamo un modello dinamico di conversazione topica basato su grafici di conoscenza (DKGT). Dato un contesto storico di dialogo, il nostro modello costruisce innanzitutto grafici di conoscenza dal contesto come un'imitazione della capacità umana di formare relazioni logiche tra argomenti noti e sconosciuti durante una conversazione. Queste informazioni logiche saranno inserite in un predittore di argomenti per promuovere la gestione dell'argomento, quindi facilitare la selezione delle conoscenze di base e la generazione di risposte. Per quanto ne sappiamo, questo è il primo tentativo di formare dinamicamente grafici di conoscenza tra argomenti di chat per aiutare la gestione degli argomenti di dialogo durante una conversazione. I risultati sperimentali dimostrano che il nostro modello può pianificare correttamente argomenti conversazionali e scegliere conoscenze adeguate per generare risposte informative rispetto a diverse linee di base forti.", 'ka': 'დიალოგის ტემების მენეჯერო და ფონდის მეცნიერების არჩევა უფრო მნიშვნელოვანი ფაქტორები იქნება ცნობიერების გარეშე დემომინის პარამეტრების წარმა მაგრამ არსებობს მოდელები უფრო სიმტერრიული მეცნიერების ბაზებით ან სტილიზებულია პროლებით, როგორც კონტაქციო პონტერების შორის, მაგრამ ადამიანები უფრო მსგავსი მეცნიერება არსებობს ამ პრობლემას გადაწყვეტისთვის, ჩვენ განვითარებთ დინამიკური ცნობიერების გრაფიკური განსახულების მოდელი (DKGT). დიალოგის ისტორიის კონტექსტის შესახებ, ჩვენი მოდელი პირველად კონტექსტიდან ცნობიერი გრაფიკები შექმნა, როგორც ადამიანის შესაძლებლობის იმიტაცია, როგორც კონტექსტიდა ეს ლოგიკური ინფორმაცია იქნება ტემიკური პროგრამეტრისთვის, რომელიც ტემიკური მენეჯერებას მომხმარება, და შემდეგ გამოყენება ფონდონის ცნობილების და ჩვენი უკეთესი მეცნიერებისთვის, ეს არის პირველი მოცდილობა დინამიკურად ცნობიერების გრაფიკების განმავლობაში, რომლებიც საუბრალობაში დიალოგის ტემების მენეჯეროს დახმარება ექსპერიმენტიური წარმოდგენა, რომ ჩვენი მოდელი შეუძლია სწორად გავაკეთოთ კონტაქციური ტემები და გადაიყენოთ საჭირო ცნობილები, რომ ინფორმაციური პასუხები შექ', 'kk': 'Диалог нақыштарын басқару мен аясын білім таңдау - білім негізінде ашық доменге сәйкестіктер үшін негізгі факторлар. Бірақ бар үлгілер негізінде симметриялық білім негізінде жұмыс істейді немесе алдын- ала анықталған қатынастық партнерлер арасындағы рольдермен стилизацияланады, бірақ адамдар әдетте өзінің білімін шындық ша Бұл мәселеді шешу үшін динамикалық білім график негіздеген нақышты сұрақ үлгісін (DKGT) таңдаймыз. Диалог журналының контексті болса, бірінші моделіміз мәлімет графикаларын адамдың беймәлім мен беймәлім нақыштар арасындағы логикалық қатынасын құру мүмкіндігі ретінде құрады. Бұл логикалық мәлімет тақырыпты басқаруды көмектесу үшін нақышты баптаушыға жіберіледі, сондықтан аясының мәліметін таңдау және жауап беру құралын көме Біздің біліміздің ең жақсы мәліметімізге бұл диалог нақыштарын басқаруға көмектесу үшін бірінші мәлімет графикаларын динамикалық түрлендіру әрекеті. Эксперименталдық нәтижелері біздің моделіміз салыстырмалы тақырыптарды дұрыс жоспарлау және мәліметтік жауап беру үшін бірнеше күш негізгі жолдармен салыстыратын мәліметті', 'lt': 'Dialogo temų valdymas ir foninių žinių atranka yra esminiai žiniomis grindžiamų atviros srities pokalbių sėkmės veiksniai. However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat.  Siekiant išspręsti šią problem ą, siūlome dinamišką žinių grafikoje pagrįstą teminį pokalbio model į (DKGT). Atsižvelgiant į dialogo istorijos kontekstą, mūs ų modelis pirmiausia kuria žinių grafiką iš konteksto kaip žmogaus gebėjimo formuoti loginius ryšius tarp žinomų ir nežinomų temų per pokalbį imitaciją. Ši logiška informacija bus įtraukiama į temų prognozatorių, kad būtų skatinamas temų valdymas, o vėliau būtų palengvinta foninių žinių atranka ir atsako kūrimas. Mūsų žiniomis tai pirmasis bandymas dinamiškai formuoti žinių grafiką tarp pokalbių temų, siekiant padėti dialogo temų valdymui pokalbio metu. Eksperimentiniai rezultatai rodo, kad mūsų modelis gali tinkamai tvarkyti pokalbių temas ir rinkti tinkamas žinias informaciniams atsakams gauti, palyginti su keliomis tvirtomis bazinėmis linijomis.', 'mk': 'Дијалогот за менаџмент на теми и селекција на подложно знаење се суштински фактори за успехот на разговорите на отворени домени врз основа на знаење. Сепак, постоечките модели се претежно изведуваат со симетрични бази на знаење или стилизирани со предефинирани улоги меѓу разговарачките партнери, додека луѓето обично имаат свое знаење пред вистински разговор. За да го решиме овој проблем, предложуваме динамичен модел на точни разговори (DKGT) базиран на график на знаење. Со оглед на контекстот на историјата на дијалогот, нашиот модел прво гради графики на знаење од контекстот како имитација на човечката способност да формира логични односи помеѓу познатите и непознатите теми за време на разговорот. Оваа логична информација ќе биде внесена во предвидувач на тема за промовирање на менаџментот на темата, а потоа олеснување на изборот на подложното знаење и генерација на одговор. За најдобро од нашето знаење, ова е првиот обид динамично да се формираат графики за знаење помеѓу темите за разговарање за помош во менаџментот на темите на дијалогот за време на разговорот. Експерименталните резултати покажуваат дека нашиот модел може соодветно да распоредува разговорни теми и да избере соодветно знаење за генерирање информативни одговори во споредба со неколку силни бази.', 'ms': 'Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations.  Namun, model yang wujud adalah terutama dilakukan dengan asas pengetahuan simetrik atau disertilkan dengan peran yang terdefinisikan-dahulu diantara rakan-rakan perbualan, sementara orang biasanya mempunyai pengetahuan sendiri sebelum percakapan sebenar. To address this problem, we propose a dynamic knowledge graph-based topical conversation model (DKGT).  Mengingat konteks sejarah dialog, model kita pertama membina graf pengetahuan dari konteks sebagai imitasi kemampuan manusia untuk membentuk hubungan logik antara topik yang diketahui dan yang tidak diketahui semasa perbualan. This logical information will be fed into a topic predictor to promote topic management, then facilitate background knowledge selection and response generation.  To the best of our knowledge, this is the first attempt to dynamically form knowledge graphs between chatting topics to assist dialog topic management during a conversation.  Hasil eksperimen menunjukkan bahawa model kita boleh jadual topik perbualan dengan betul dan memilih pengetahuan yang sesuai untuk menghasilkan balasan maklumat dibandingkan dengan beberapa garis dasar yang kuat.', 'ml': 'ഡയലോഗിന്റെ പ്രമേയത്തിനും പശ്ചാത്തലത്തിലെ അറിവുകള്\u200d തെരഞ്ഞെടുക്കുന്നതും അറിവുകളുടെ വിജയത്തിനായി സ്ഥാപിച്ചുവ എന്നാലും നിലവിലുള്ള മോഡലുകള്\u200d പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു, സംസാരിക്കുന്ന പങ്കാളികള്\u200dക്കിടയില്\u200d നിര്\u200dണ്ണയിക്കപ്പെട്ടിരിക്കുന് ഈ പ്രശ്നം വിശദീകരിക്കാന്\u200d, നമ്മള്\u200d ഒരു ഡൈനാമിക്ക് അറിവ് ഗ്രാഫ് അടിസ്ഥാനമായി സംസാരിക്കുന്ന സംസാര മോഡല്\u200d  ഒരു ഡയലോഗ് ചരിത്രത്തിന്റെ ചരിത്രത്തില്\u200d നിന്ന് നമ്മുടെ മോഡല്\u200d ആദ്യം പരിജ്ഞാന ഗ്രാഫുകള്\u200d നിര്\u200dമ്മിക്കുന്നു. ഒരു സംസാരത്തില്\u200d അറിയപ ഈ ലോഗിക്കല്\u200d വിവരങ്ങള്\u200d പ്രദര്\u200dശിപ്പിക്കുന്നതിനായി പ്രധാനപ്പെടുത്തുന്നതിനായി പ്രധാനപ്പെടുത്തുന്ന ഒരു പ്ര നമ്മുടെ അറിവിന്റെ ഏറ്റവും നല്ലതിന് ഇതാണ് ആദ്യത്തെ ശ്രമം, സംസാരിക്കുമ്പോള്\u200d സംസാരിക്കുന്ന പ്രമേയത്തിന്റെ കാര്യത്തില്\u200d സംസാര പരീക്ഷണ ഫലങ്ങള്\u200d വ്യക്തമാക്കുന്നു നമ്മുടെ മോഡല്\u200d സംസാരിക്കുന്ന വിഷയങ്ങള്\u200d ശരിക്കും നിര്\u200dണ്ണയിക്കാന്\u200d സാധിക്കുന്നു. വിവരങ്ങള്\u200d ഉ', 'mt': 'Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations.  Madankollu, mudelli eżistenti jitwettqu primarjament b’bażijiet simetriċi ta’ għarfien jew jiġu stilizzati b’rwoli definiti minn qabel bejn sħab ta’ konverżjoni, filwaqt li n-nies normalment ikollhom l-għarfien tagħhom stess qabel chat reali. Biex nindirizzaw din il-problem a, nipproponu mudell ta’ konverżjoni topika bbażat fuq grafika dinamika tal-għarfien (DKGT). Minħabba kuntest tal-istorja tad-djalogu, il-mudell tagħna l-ewwel jibni grafiċi tal-għarfien mill-kuntest bħala imitazzjoni tal-kapaċità tal-bniedem li jifforma relazzjonijiet loġiċi bejn suġġetti magħrufa u mhux magħrufa matul konverżjoni. Din l-informazzjoni loġika se tiġi mdaħħla f’predikatur ta’ suġġetti biex tippromwovi l-ġestjoni tas-suġġetti, imbagħad tiffaċilita l-għa żla tal-għarfien fl-isfond u l-ġenerazzjoni tar-rispons. To the best of our knowledge, this is the first attempt to dynamically form knowledge graphs between chatting topics to assist dialog topic management during a conversation.  Riżultati esperimentali jidhru li l-mudell tagħna jista’ skeda tajjeb suġġetti ta’ konverżjoni u jagħżel għarfien adattat biex jiġġenera reazzjonijiet informativi meta mqabbel ma’ diversi linji bażi b’saħħithom.', 'mn': 'Диалог сэдэв удирдах болон түүний мэдлэг сонгох нь мэдлэг дээр нээлттэй холбоотой ярилцлагын амжилтын чухал хүчин зүйл юм. Гэвч суурилсан загварууд ихэвчлэн хэлэлцээний хамтрагчдын хоорондоо илүү тодорхойлогдсон мэдлэг суурь, эсвэл хэлэлцээний үйл ажиллагаатай байдаг. Хүмүүс ихэвчлэн жинхэнэ хэлэлцээний өмнө өөрсдийн мэдлэг Энэ асуудлыг бодохын тулд бид динамик мэдлэг график дээр суурилсан сэдвийн ярилцлагын загвар (DKGT) санал болгоно. Диалог түүхийн тухай ярианы тухай бидний загвар эхлээд ярианы үед мэдлэг графикийг хүн төрөлхтний чадварын төлөвлөгөө болгодог. Энэ логикийн мэдээлэл сэдвийн удирдагчийг дэмжих, дараа нь мэдлэг сонголтыг болон хариу үйлдлийг дэмжих сэдвийн таамаглагч болно. Хамгийн сайн мэдлэгтэй нь, энэ бол ярианы үед диалог сэдвийн удирдлагын тулд мэдлэг график бий болгох анхны хичээл юм. Эмчилгээний үр дүнд бидний загвар нь ярилцлагын сэдвийг зөв төлөвлөж, мэдээллийн хариултыг олон хүчтэй суурь шулуунтай харьцуулахын тулд зөв мэдлэг сонгож чадна.', 'no': 'Dialogvindaugehandtering og utval av bakgrunnsverktøy er nødvendige faktorer for suksess på kunnskapslar med open-domain. Men eksisterande modeller vert først utført med symmetriske kunnskapsbaser eller stylt med før-definerte rollar mellom konversjonsprarter, mens folk vanlegvis har sine eige kunnskap før ein verkeleg chit-chat. For å setja opp dette problemet, foreslår vi eit dynamisk kunnskapsmodell (DKGT) basert på diagrambasert temasamtale. Gjennomsikt på eit dialoghistorisk kontekst, bygger vår modell først kunnskap grafikk frå konteksten som imitasjon av menneske kapasiteten til å form logiske forhold mellom kjente og ukjende emne under eit samtale. Denne logiske informasjonen vert sendt inn i eit temaforhåndsvising for å promotera temahandtering, og så gjere tilgjengeleg utval av bakgrunnsinnstillingar og oppretting av svar. Dette er det første forsøket å lage kunnskap grafikk mellom pratetema for å hjelpa dialoghandtering av emne under eit samtale. Eksperimentale resultat viser at modellen vår kan rett planleggja samtaleemne og velja passende kunnskap for å laga informativ svar sammenlignet med fleire sterke baselinjer.', 'pl': 'Zarządzanie tematami dialogowymi i dobór wiedzy podstawowej są niezbędnymi czynnikami sukcesu rozmów opartych na wiedzy o otwartej domenie. Jednak istniejące modele są wykonywane przede wszystkim z symetrycznymi bazami wiedzy lub stylizowane z wcześniej zdefiniowanymi rolami pomiędzy partnerami konwersacyjnymi, podczas gdy ludzie zazwyczaj mają własną wiedzę przed prawdziwym chatem. Aby rozwiązać ten problem, proponujemy dynamiczny, oparty na wykresie wiedzy model aktualnej konwersacji (DKGT). Biorąc pod uwagę kontekst historii dialogu, nasz model najpierw buduje wykresy wiedzy z kontekstu jako imitację zdolności człowieka do tworzenia logicznych relacji między znanymi i nieznanymi tematami podczas rozmowy. Te logiczne informacje zostaną wprowadzone do predyktora tematu, aby promować zarządzanie tematem, a następnie ułatwić wybór wiedzy podstawowej i generowanie odpowiedzi. Według naszej najlepszej wiedzy jest to pierwsza próba dynamicznego tworzenia wykresów wiedzy między tematami czatu, aby ułatwić zarządzanie tematami dialogowymi podczas rozmowy. Wyniki eksperymentalne pokazują, że nasz model potrafi prawidłowo zaplanować tematy konwersacji i wybrać odpowiednią wiedzę do generowania informacyjnych odpowiedzi w porównaniu z kilkoma silnymi liniami bazowymi.', 'si': 'සංවාදය ප්\u200dරධානය සහ පසුබිම දන්නවය තෝරාගන්න අවශ්\u200dය විදියට දැනගන්න ප්\u200dරශ්නයක් තියෙන්නේ. නමුත්, වෙන්න තියෙන්නේ මොඩල් ප්\u200dරධානයෙන් සිමිටර් දන්න බේස් එක්ක හෝ ප්\u200dරධාන විශ්වාස කරන්නේ ප්\u200dරධාන විශ්වාස කරන්නේ ප්\u200dරධාන ව මේ ප්\u200dරශ්නය විසඳන්න, අපි හැමදාමික දැනගන්න තේරුම් ග්\u200dරාෆ් අධාරිත ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් (D සංවාදය ඉතිහාසය සම්බන්ධයක් නිර්මාණය කරනවා, අපේ මොඩල් මුලින්ම සංවාදයෙන් මිනිස්සුන්ගේ පුළුවන් දැනගන්න දන්න බැරි  මේ ලෝකික තොරතුරු විදිහට ප්\u200dරශ්නයක් විදිහට ප්\u200dරශ්නයක් කරනවා, පස්සේ පස්සේ තොරතුරු තෝරණය සහ ප්\u200dරතික අපේ දන්නවයේ හොඳම ප්\u200dරශ්නයක්, මේක තමයි කතාවක් වලින් සංවාද ප්\u200dරධානය සහාය කරන්න පුළුවන් ප්\u200dරශ්නයක් විදියට දන්න පරීක්ෂණාත්මක ප්\u200dරතිචාර ප්\u200dරතිචාර විදිහට අපේ මොඩල් එක හරියටම වාර්තාවක් විදිහට සැකසුම් කරන්න පුළුවන් විදිහට', 'so': 'Maamulka diyaariga iyo doorashada aqoonta dabaqa ah waa sababo muhiim ah oo ku guulaysta hadallada aqoonta lagu dhigay oo furan. Si kastaba ha ahaatee modelalka joogta waxaa marka ugu horeysa lagu sameeyaa aasaaska aqoonta koowaad ama waxaa lagu qoraa qaybaha horay loo yaqaan oo u dhexeeya saaxiibka hadalka, inta badan dadku waxay leeyihiin aqoontooda intaan la hadlin dhab ah. Si aan u qabsado dhibaatadan, waxaynu soo jeedaynaa model sameynta maamulka aqoonta ee ku saleysan karta (DKGT). Sida uu ku qoran taariikhda dialog, modellkayagu marka hore wuxuu dhisaa sawir aqoonta ah oo ka mid ah qaab u eg kara awoodda dadku inuu sameeyo xiriir xiriir xirfadeed oo u dhexeeya mada la aqoon iyo arrimaha a an la aqoonin marka la hadlo. Macluumaadkan la xiriira waxaa lagu soo bandhigi doonaa wax ka hor jeediya mada, si uu u horumariyo maamulka mada, markaasna waxaa sawira doorashada aqoonta sawirka iyo farsamada jawaabta. Marka ugu fiican aqoonteenna, taasi waa isku dayada ugu horeysa in aad si farxad ah u sameyneyso sawirro aqoonta oo u dhexeeya mada hadalka si uu uga caawiyo maamulka ku saabsan baaritaanka dialogka. Imtixaanka waxaa muuqda in modellkayagu uu si hagaagsan u qorsheyn karo maadooyinka hadalka, wuxuuna dooran karaa aqoonta ku habboon si uu u sameeyo jawaabo macluumaad ah oo u barbarbarta qoraalo xoog badan.', 'sv': 'Dialogämneshantering och val av bakgrundskunskap är viktiga faktorer för framgång i kunskapsbaserade öppna domänsamtal. Dock utförs befintliga modeller främst med symmetriska kunskapsbaser eller stiliserade med fördefinierade roller mellan konversationspartners, medan människor vanligtvis har sin egen kunskap inför en riktig pratstund. För att lösa detta problem föreslår vi en dynamisk kunskapsgrafbaserad aktuell konversationsmodell (DKGT). Med tanke på ett dialoghistoriskt sammanhang bygger vår modell först kunskapsgrafer ur sammanhanget som en imitation av människans förmåga att bilda logiska relationer mellan kända och okända ämnen under en konversation. Denna logiska information kommer att matas in i en ämnesprediktor för att främja ämneshantering, sedan underlätta bakgrundskunskapsval och responsgenerering. Så vitt vi vet är detta det första försöket att dynamiskt bilda kunskapsgrafer mellan chattämnen för att underlätta hanteringen av dialogämnen under en konversation. Experimentella resultat visar att vår modell kan schemalägga samtalsämnen korrekt och välja lämplig kunskap för att generera informativa svar jämfört med flera starka baslinjer.', 'ta': 'உரையாடல் தலைப்புகள் மேலாண்மை மற்றும் பின்னணி அறிவு தேர்வு முக்கியமான காரணங்கள் அறிவு அடைந்த த திறந்த களம் பேச்சி However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat.  இந்த பிரச்சனையை தேர்ந்தெடுக்க, நாம் ஒரு தேவையான அறிவு வரைபடத்தை அடிப்படையில் உள்ள தலைப்பு பேச்சு மாதிர ஒரு உரையாடல் வரலாற்று சூழல் கொண்டு, எங்கள் மாதிரி முதலில் அறிவு வரைபடங்களை உருவாக்குகிறது, ஒரு பேச்சில் தெரியாத மற்றும் தெரியாத பொரு பின்னணி அறிவிப்பு தேர்வு மற்றும் பதில் உருவாக்கத்தை மேம்படுத்த இந்த பின்னணி தகவல் தலைப்பு முன்காணிக்கும் தலைப் எங்கள் அறிவின் சிறந்த முயற்சி இது தான் பேசும் போது உரையாடல் தலைப்பு மேலாளரை பேசும் பொருள் மேலாளரை உதவி செய்ய முதல் முயற்சி. முயற்சி முடிவுகள் எங்கள் மாதிரி பேச்சு தலைப்புகளை சரியாக தேர்ந்தெடுக்க முடியும் மற்றும் பல வலிமை அடிப்பகுதிகளுடன் ஒப்பிடும் தக', 'ur': 'Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations. لیکن موجود موجود موجود موجود موجودہ موجود مثالی علم بنسس کے ساتھ عمل کیے جاتے ہیں یا مکالمانی شریکوں کے درمیان پیش تعریف کی رول کے ساتھ استیلیز کیے جاتے ہیں، حالانکہ انسانوں کو معمولاً حقیقی چیت-چیٹ سے پہلے اپنے علم رکھتا ہے. اس مسئلہ کے بارے میں ہم نے ایک ڈینمانیک علم گراف بنیاد رکھی تھوپیٹ کی گفتگو موڈل (DKGT) کی پیشنهاد کریں۔ ہمارا مدل پہلے سمجھ کے گراف بناتا ہے جو انسان کی قابلیت کے طور پر معلوم اور غیرمعلوم موضوع کے درمیان منطقی رابطہ بنانے کے قابل ہے۔ یہ منطقی معلومات ایک موضوع پیش بینی کرنے والے کے لئے کھول دی جائے گی تاکہ موضوع منظورت کو پیش بینی کرے، پھر پچھلے علم کا انتخاب اور جواب کی نسل آسان کرے۔ ہمارے بہترین علم کے لئے یہ سب سے پہلی کوشش ہے کہ ایک بات کے درمیان بحث کے متعلق بحث کے درمیان علم گراف بنانے کی مدد کریں۔ Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses comparing to several strong baselines.', 'sr': 'Upravljanje teme dijaloga i izbor znanja pozadine su ključni faktori za uspjeh razgovora o otvorenom domenu na temelju znanja. Međutim, postojeći modeli su primarno izvedeni simetričnim bazama znanja ili stilirani preddefiniranim ulogama između razgovornih partnera, dok ljudi obično imaju svoje znanje prije pravog razgovora. Za rješavanje ovog problem a predlažemo dinamični model temalnog razgovora na grafiku znanja (DKGT). S obzirom na kontekst istorije dijaloga, naš model prvo izgradi grafike znanja iz konteksta kao imitaciju ljudske sposobnosti da formiraju logičke veze između poznatih i nepoznatih tema tokom razgovora. Ove logičke informacije će biti uložene u predviđa č teme kako bi promovisala upravljanje temama, a zatim olakšala izabranje pozadinskih znanja i generaciju odgovora. Za najbolje od našeg znanja, ovo je prvi pokušaj da dinamički oblikuje grafike znanja između razgovora o temama kako bi pomoglo upravljanju temama dijaloga tokom razgovora. Eksperimentalni rezultati pokazuju da naš model može ispravno rasporediti razgovorne teme i izabrati odgovarajuće znanje da bi stvorili informativne odgovore u usporedbi sa nekoliko jakih osnovnih linija.', 'ro': 'Managementul subiectelor de dialog și selectarea cunoștințelor de fundal sunt factori esențiali pentru succesul conversațiilor bazate pe cunoaștere deschisă. Cu toate acestea, modelele existente sunt realizate în principal cu baze de cunoștințe simetrice sau stilizate cu roluri predefinite între partenerii de conversație, în timp ce oamenii au de obicei propriile lor cunoștințe înainte de un chat real. Pentru a aborda această problemă, propunem un model dinamic de conversație topică bazat pe grafice de cunoaștere (DKGT). Având în vedere un context istoric de dialog, modelul nostru construiește mai întâi grafice de cunoaștere din context ca o imitație a capacității omului de a forma relații logice între subiectele cunoscute și necunoscute în timpul unei conversații. Aceste informații logice vor fi introduse într-un predictor de subiect pentru a promova managementul subiectelor, apoi pentru a facilita selectarea cunoștințelor de fond și generarea de răspunsuri. Din câte știm, aceasta este prima încercare de a forma dinamic grafice de cunoștințe între subiectele de chat pentru a ajuta gestionarea subiectelor de dialog în timpul unei conversații. Rezultatele experimentale manifestă faptul că modelul nostru poate programa în mod corespunzător subiecte conversaționale și alege cunoștințe adecvate pentru a genera răspunsuri informative comparativ cu mai multe linii de bază puternice.', 'uz': "Name Ammo, mavjud modellar asosida symmetrik илм asosida bajariladigan yoki talab qilish bilan bir necha shakl bilan o'xshash qobiliyatlari bilan ishlaydi, va odatda odamlar haqiqiqiy suhbatdan oldin o'zining o'zi biliyatlari bor. Bu muammolani boshqarish uchun biz dynamik ilmiy taʼrif grafik asosida maʼlumot muloqat modeli (DKGT). Dialog tarixi muhit bilan, birinchi modelmiz muloqat mavzu bilan nomaʼlum va nomaʼlum mavzular bilan bogʻlanish qobiliyatlarini yaratadi. Name Bizning eng yaxshi taʼlumot uchun, bu muloqat oynasida muloqat mavzu boshqarishga yordam berish uchun eng birinchi jarayon. Tekshirish natijalari, modelmiz muloqat mavzularini yaxshi tayyorlash mumkin va bir necha xoog asboblar bilan bog'liq maʼlumot javoblarini yaratish uchun juda yetarli ilmoga tanlashi mumkin.", 'vi': 'Việc quản lý hội thoại và chọn kiến thức nền là yếu tố cần thiết cho sự thành công của các cuộc đối thoại mở miền. Tuy nhiên, các mô hình tồn tại được thực hiện với cơ sở kiến thức đối xứng hoặc thiết kế với các vai trò đối thoại được định sẵn, trong khi người ta thường có kiến thức riêng trước khi trò chuyện. Để giải quyết vấn đề này, chúng tôi đề xuất một mẫu hội thoại hiện thời dựa vào kiến thức (DKGT). Dựa vào bối cảnh lịch s ử hộp thoại, mẫu vật đầu tiên xây dựng biểu đồ kiến thức từ ngữ cảnh như mô phỏng khả năng tạo ra các mối quan hệ logic giữa các chủ đề đã biết và chưa biết trong cuộc đối thoại. Thông tin lô-gic này sẽ được đưa vào chuyên môn dự đoán để thúc đẩy việc quản lý chuyên môn, sau đó dễ dàng chọn kiến thức nền và tạo ra phản ứng. Theo kiến thức tốt nhất của chúng tôi, đây là nỗ lực đầu tiên để hình thành biểu đồ kiến thức từ động giữa các chủ đề trò chuyện để hỗ trợ quản lý đối tượng hộp thoại trong cuộc đối thoại. Kết quả thí nghiệm rõ ràng rằng mô hình của chúng ta có thể xếp lịch trình đối thoại thích hợp và chọn kiến thức thích hợp để tạo ra phản ứng thông tin so sánh với nhiều nền tảng vững chắc.', 'da': 'Dialogemnetstyring og udvælgelse af baggrundsviden er afgørende faktorer for succesen af vidensbaserede åbne domænesamtaler. Eksisterende modeller udføres imidlertid primært med symmetriske videnbaser eller stiliseres med foruddefinerede roller mellem samtalepartnere, mens folk normalt har deres egen viden før en rigtig snak. For at løse dette problem foreslår vi en dynamisk vidensgrafbaseret aktuel samtalemodel (DKGT). I betragtning af en dialoghistorisk kontekst bygger vores model først vidensgrafer ud fra konteksten som en efterligning af menneskets evne til at danne logiske relationer mellem kendte og ukendte emner under en samtale. Disse logiske oplysninger vil blive ført ind i en emneforudsiger for at fremme emnetstyring og derefter lette baggrundsvidensudvalg og responsgenerering. Så vidt vi ved, er dette det første forsøg på dynamisk at danne vidensgrafer mellem chat emner for at hjælpe dialog emne styring under en samtale. Eksperimentelle resultater viser, at vores model korrekt kan planlægge samtaleemner og vælge passende viden til at generere informative svar sammenlignet med flere stærke baselines.', 'bg': 'Управлението на темите на диалога и подборът на знания са съществени фактори за успеха на базираните на знанието разговори с отворен домейн. Съществуващите модели обаче се изпълняват предимно със симетрични бази от знания или стилизирани с предварително определени роли между разговорните партньори, докато хората обикновено имат свои знания преди истински чат. За да се справим с този проблем, предлагаме динамичен модел на знание, базиран на графики за тематичен разговор. Предвид диалоговия исторически контекст, нашият модел първо изгражда знание графики от контекста като имитация на способността на човека да формира логически взаимоотношения между известни и неизвестни теми по време на разговор. Тази логическа информация ще бъде въведена в тематичен предсказател, за да се насърчи управлението на темата, след което да се улесни изборът на основни знания и генерирането на отговор. Доколкото знаем, това е първият опит динамично да се формират графики на знанието между темите за чат, за да се подпомогне управлението на темите на диалога по време на разговор. Експерименталните резултати показват, че нашият модел може правилно да планира разговорни теми и да избере подходящо знание, за да генерира информативни отговори в сравнение с няколко силни базови линии.', 'nl': 'Dialogbeheer en selectie van achtergrondkennis zijn essentiële factoren voor het succes van kennisgebaseerde open-domein gesprekken. Bestaande modellen worden echter voornamelijk uitgevoerd met symmetrische kennisbases of gestileerd met vooraf gedefinieerde rollen tussen gesprekspartners, terwijl mensen meestal hun eigen kennis hebben voor een echte chit-chat. Om dit probleem aan te pakken, stellen we een dynamisch kennisgrafiek gebaseerd topisch conversatiemodel (DKGT) voor. Gezien een dialooggeschiedenis context bouwt ons model eerst kennisgrafieken uit de context als een imitatie van het menselijk vermogen om logische relaties te vormen tussen bekende en onbekende onderwerpen tijdens een gesprek. Deze logische informatie zal worden ingevoerd in een topic predictor om topic management te bevorderen en vervolgens achtergrondkennis selectie en responsgeneratie te vergemakkelijken. Voor zover wij weten, is dit de eerste poging om dynamisch kennisgrafieken te vormen tussen chatonderwerpen om het beheer van dialoogonderwerpen tijdens een gesprek te ondersteunen. Experimentele resultaten tonen aan dat ons model gespreksonderwerpen goed kan plannen en geschikte kennis kan kiezen om informatieve reacties te genereren vergeleken met verschillende sterke baselines.', 'de': 'Dialogthemenmanagement und Hintergrundwissen-Auswahl sind wesentliche Faktoren für den Erfolg wissensbasierter Open-Domain-Gespräche. Bestehende Modelle werden jedoch primär mit symmetrischen Wissensbasen durchgeführt oder mit vordefinierten Rollen zwischen Gesprächspartnern stilisiert, während die Menschen in der Regel ihr eigenes Wissen vor einem echten Chat haben. Um dieses Problem anzugehen, schlagen wir ein dynamisches Wissensdiagramm-basiertes topisches Konversationsmodell (DKGT) vor. In einem dialoggeschichtlichen Kontext erstellt unser Modell zunächst Wissensgraphen aus dem Kontext als Imitation der menschlichen Fähigkeit, logische Beziehungen zwischen bekannten und unbekannten Themen während eines Gesprächs zu bilden. Diese logischen Informationen werden in einen Themenprädiktor eingespeist, um das Themenmanagement zu fördern, und erleichtern dann die Auswahl von Hintergrundwissen und die Generierung von Reaktionen. Nach bestem Wissen ist dies der erste Versuch, Wissensdiagramme zwischen Chatthemen dynamisch zu erstellen, um die Verwaltung von Dialogthemen während eines Gesprächs zu unterstützen. Experimentelle Ergebnisse zeigen, dass unser Modell Gesprächsthemen richtig planen und geeignetes Wissen auswählen kann, um informative Antworten im Vergleich zu mehreren starken Baselines zu generieren.', 'hr': 'Upravljanje teme dijaloga i izbor znanja pozadine su ključni faktori za uspjeh razgovora o otvorenom domenu na temelju znanja. Međutim, postojeći modeli su primarno provedeni simetričnim bazama znanja ili stilirani preddefiniranim ulogama između razgovornih partnera, dok ljudi obično imaju svoje znanje prije stvarnog razgovora. Za rješavanje ovog problem a predlažemo dinamični model razgovora na grafiku temeljnog znanja (DKGT). S obzirom na kontekst povijesti dijaloga, naš model prvo izgradi grafike znanja iz konteksta kao imitaciju sposobnosti ljudskog stvoriti logičke veze između poznatih i nepoznatih tema tijekom razgovora. Ove logičke informacije će biti uložene u predviđa č teme kako bi promovirao upravljanje temama, a zatim olakšao odabire pozadinskih znanja i generaciju odgovora. Najbolje od naših znanja, ovo je prvi pokušaj dinamički oblikovati grafike znanja između razgovora o temama kako bi pomoglo upravljanju temama dijaloga tijekom razgovora. Eksperimentalni rezultati pokazuju da naš model može ispravno rasporediti razgovorne teme i izabrati odgovarajuće znanje kako bi stvorili informativne odgovore u usporedbi s nekoliko jakih osnovnih linija.', 'ko': '대화 주제 관리와 배경 지식 선택은 지식을 바탕으로 하는 개방 분야의 대화 성공의 관건적인 요소이다.그러나 기존의 모델은 주로 대칭적인 지식 라이브러리로 집행되거나 대화 파트너 간에 미리 정의된 역할을 사용하여 양식화되고 사람들은 진정한 대화를 하기 전에 자신의 지식을 가진다.이 문제를 해결하기 위해 우리는 동적 지식 그래프를 바탕으로 하는 화제 대화 모델(DKGT)을 제시했다.대화의 역사적 상하문을 정하고 우리의 모델은 상하문에서 지식도를 구축하여 인류가 대화 기간에 이미 알고 있는 것과 미지의 주제 사이에서 논리적 관계를 형성하는 능력을 모방한다.이러한 논리적 정보는 주제 예측기에 입력하여 주제 관리를 추진하고 배경 지식의 선택과 응답 생성을 추진한다.채팅 주제 간에 동태적으로 지식도를 만들어 대화 기간에 대화 주제를 관리하는 데 도움을 주는 것은 이번이 처음인 것으로 알려졌다.실험 결과에 따르면 몇 개의 강력한 기선에 비해 우리 모델은 회화 주제를 정확하게 배정하고 적당한 지식을 선택하여 정보적인 응답을 생성할 수 있다.', 'id': "Manajemen topik dialog dan seleksi pengetahuan latar belakang adalah faktor penting untuk sukses konversasi domain terbuka berdasarkan pengetahuan. Namun, model yang ada terutama dilakukan dengan dasar pengetahuan simetrik atau didefinisikan dengan peran yang terdefinisikan sebelumnya antara rekan-rekan percakapan, sementara orang biasanya memiliki pengetahuan mereka sendiri sebelum percakapan nyata. Untuk mengatasi masalah ini, kami mengusulkan model percakapan topik berdasarkan grafik pengetahuan dinamik (DKGT). Given a dialog history context, our model first builds knowledge graphs from the context as an imitation of human's ability to form logical relationships between known and unknown topics during a conversation.  Informasi logis ini akan dimasukkan ke prediksor topik untuk mempromosikan manajemen topik, kemudian memudahkan seleksi pengetahuan latar belakang dan generasi respon. To the best of our knowledge, this is the first attempt to dynamically form knowledge graphs between chatting topics to assist dialog topic management during a conversation.  Hasil eksperimen menunjukkan bahwa model kita dapat menetapkan topik konversasi dengan benar dan memilih pengetahuan yang tepat untuk menghasilkan respon informatif dibandingkan dengan beberapa garis dasar yang kuat.", 'fa': 'مدیریت موضوع محاوره و انتخاب علم پشتیبانی برای موفقیت صحبت\u200cهای صحبت\u200cهای دومین باز بر اساس علم است. ولی مدلهای موجود در اصل با پایگاه\u200cهای علمی مشابه یا با نقش\u200cهای پیش\u200cتعریف بین شریکان گفتگو انجام می\u200cشود، در حالی که مردم معمولاً پیش از یک صحبت واقعی دانش خود را دارند. برای حل این مشکل، ما یک مدل مکالمه موضوع موضوع (DKGT) را پیشنهاد می\u200cکنیم. با وجود یک محیط تاریخ گفتگو، مدل ما اول گرافیک دانش را از محیط به عنوان تصویر توانایی انسان برای شکل رابطه منطقی بین موضوع شناخته و ناشناخته در طول یک گفتگو ساخته می شود. این اطلاعات منطقی به پیش\u200cبینی\u200cکننده\u200cی موضوع تغییر داده می\u200cشود تا مدیریت موضوع را توسعه دهد، سپس انتخاب علم پشت سر و پاسخ را آسان دهد. برای بهترین دانش ما، این اولین تلاش است که در طول یک مکالمه، گرافیک دانش را دینامیک شکل دهیم بین گفتگوهای موضوع تا کمک کند مدیریت موضوع صحبت کند. نتایج تجربه\u200cای نشان می\u200cدهد که مدل ما می\u200cتواند موضوع مکالمه را به طور درست برنامه\u200cبندی کند و دانش مناسب را انتخاب کند تا پاسخ\u200cهای اطلاعات را در مقایسه با چند خط پایگاه\u200cهای قوی تولید کند.', 'tr': 'Dialoog meýdançasyny we arkaplan bilgileri saýlamak bilgi alan aç-domen sözleriniň başarnygy üçin örän möhüm faktörler. Ýöne bar modeller ilkinji şekilde simetrik bilim üssüsleri bilen edilýär ýa-da söhbetçiler arasyndaky roller bilen tanyşdyrylýar. Adamlar hakyky söhbetçilikden öň öz bilimi bar. Bu meseleni çözmek üçin dinamik bilim grafiklerinden temel sohbet nusgasyny teklip edip görýäris. Dialog geçmişi kontekstinden görä, nusgasymyz ilkinji gezek duşuşykda adamlaryň bilim grafiklerini görkez. Bu logik maglumat meýdançasyny meýdançasyna üýtgetmek üçin bir tema täsirini görkezilip, soňra arkaplan bilgi we jogabat täsirini bejermek üçin bejerilecek. Bilgimiziň iň gowy görä, bu ilkinji gezek temalar arasynda disko meýdançasyna kömek etmek üçin bilim grafiklerini dinamik görkezmäge synanyşýar. Experimental netijelerimiz görkezilýän nusgalarymyz soňra güýçli temalary düzgün planlaşdyryp bilen howpsyzlyk jogaplary döretmek üçin düzgün bilim taýýarlap biler.', 'af': "Dialoog onderwerp bestuurder en agtergrond kennis keuse is noodsaaklike faktore vir die sukses van kennis-gegrond open-domein gesprekke. Alhoewel, bestaande modele is voorspoedig uitgevoer met simetriese kennis bases of styliseer met voor-gedefinieerde roles tussen konversasionale partnere, terwyl mense gewoonlik hul eie kennis het voor 'n regte chit-chat. Om hierdie probleem te adres, voorstel ons 'n dinamiese kennis grafiek-gebaseerde temalike gespreksmemodel (DKGT). Gien 'n dialoog geskiedenis konteks, bou ons model eerste kennis grafieke van die konteks a s 'n imitasie van mens se kapasiteit om logiese verwantings tussen bekende en onbekende onderwerpe te formeer tydens 'n gesprek. Hierdie logiese inligting sal in 'n onderwerp voorskouer gevoer word om onderwerp bestuurder te bevestig, dan laat agtergrond kennis kies en antwoord genereering maak. Op die beste van ons kennis is dit die eerste probeer om kennis grafieke te formeer tussen gesprek onderwerpe om dialoog onderwerp bestuur te help in 'n gesprek. Eksperimentale resultate manifesteer dat ons model kan korrek skeduleer konversasionale onderwerpe en kies geskikte kennis om inligtige reaksies te genereer wat vergelyk word met verskeie sterke basisline.", 'sw': 'Utawala wa mada ya Dialog na uchaguzi wa ufahamu wa nyuma ni sababu muhimu kwa mafanikio ya mazungumzo yanayohusiana na maarifa ya wazi ya ndani. Hata hivyo, mifano iliyopo yanafanywa kwa msingi wa maarifa ya msingi au imetengenezwa na jukumu lililoelezwa kabla kati ya washirika wa mazungumzo, wakati mara nyingi watu hupata maarifa yao kabla ya mazungumzo ya kweli. Ili kukabiliana na tatizo hili, tunapendekeza modeli ya mazungumzo ya maarifa yenye msingi wa picha (DKGT). Kutokana na mukhtadha wa mazungumzo ya mazungumzo, mwelekeo wetu wa kwanza unajenga picha za maarifa kutoka kwenye muktadha kama mfano wa uwezo wa binadamu wa kutengeneza mahusiano ya kimaadili kati ya mada zinazofahamika na isiyojulikana wakati wa mazungumzo. Taarifa hizi za kimaadili zitafungwa kuwa mtabiri wa mada ili kukuza msimamo wa mada, kisha kusaidia uchaguzi wa ufahamu wa nyuma na kizazi cha majibu. Kwa ufahamu mzuri zaidi, hii ni jaribio la kwanza la kutengeneza picha za maarifa katika mada ya mazungumzo ili kusaidia kusimamia mada ya mazungumzo wakati wa mazungumzo. Matokeo ya majaribio yanaonyesha kuwa mtindo wetu unaweza kuandaa mada za mazungumzo sahihi na kuchagua maarifa sahihi ili kutengeneza majibu ya taarifa yanayolinganisha na misingi kadhaa yenye nguvu.', 'am': 'የጦማሪያው አካባቢ እና የመደቡን እውቀት ምርጫ እውቀት የክፈት ዶሜን ንግግር ማቀናኘት የግድ ጉዳይ ነው፡፡ ምንም እንኳን፣ የሥልጣን ሞዴላዎች በመጀመሪያ የሳምቲካዊ እውቀት መቀመጫዎች ወይም በተለያዩ ባልንጀራዎች መካከል አስቀድሞ በተመሳሳይ ተግባር ይደረጋሉ፡፡ ይህንን ጉዳይ ለመቀበል እናስፈልጋለን፡፡ በጥያቄ ታሪክ ክፍል በተሰጠ ጊዜ ሞዴል በመጀመሪያ እና በማይታወቁትና በማያውቁት ትክክለኛዎች መካከል የሎጂካዊ ግንኙነትን ለመፍጠር የሚችለውን እውቀት ቀፎችን ከግንኙነታችን ይሠራል፡፡ ይህ የግንኙነት መረጃ የውይይት ጉዳይ መቆጣጠር ይደረጋል፣ ከዚያም በኋላ የመደቡን እውቀት ምርጫ እና የመስመርት ትውልድ ያበረታል፡፡ ከውቀታችን የተሻለ ነው፣ ይህ በአካባቢው ወሬዎች መካከል የመስመር አካባቢ መሠረት ለመጀመሪያ እውቀትን ማቀናቀፍ ነው፡፡ ፈተና ፍሬዎች ሞዴሌዎቻችን በተለያዩ ብዙዎች የበረታች መሠረቶች የሚያስፈልገውን እና አስተዋይ መልስ ለማፍሰስ የሚችሉትን እውቀት እንዲምረጡ ይገልጣል፡፡', 'bn': 'ডায়ালগ বিষয়বস্তু ব্যবস্থাপনা এবং পটভূমির জ্ঞান নির্বাচনের গুরুত্বপূর্ণ কারণ হচ্ছে জ্ঞান-ভিত্তিক ক্ষেত্রে উন তবে বিদ্যমান মডেল প্রাথমিকভাবে সিম্প্রিয় জ্ঞানের বেস দিয়ে প্রদর্শন করা হয় অথবা কথোপকথনীয় অংশীদারের মধ্যে পূর্বে নির্ধারিত ভূমিকা দিয়ে স্টা এই সমস্যাটিকে ঠিক করার জন্য আমরা একটি ডায়োনামিক জ্ঞান গ্রাফ ভিত্তিক বিষয়বস্তু আলোচনার মডেল প্রস্তাব করি। একটি ডায়ালগ ইতিহাসের প্রেক্ষাপট দিয়ে আমাদের মডেল প্রথমে বিভিন্ন প্রেক্ষাপট থেকে জ্ঞানের গ্রাফ তৈরি করে, যেটি মানুষের ক্ষমতার বিষয়বস্তু ব্যবস্থাপনার প্রচার করার জন্য এই বৈশিষ্ট্যালয়ের তথ্য একটি বিষয়ের প্রধান ভবিষ্যদ্বাণী হিসেবে প্রদান করা হবে,  আমাদের জ্ঞানের সবচেয়ে ভালোভাবে এই প্রথম চেষ্টা হচ্ছে যে আলোচনার সময় আলোচনা বিষয়বস্তু ব্যবস্থাপনার সাহায্য করার প্রচেষ্টা করা হয়। পরীক্ষার ফলাফল প্রকাশ করে যে আমাদের মডেল সঠিকভাবে কথোপকথন বিষয় নির্ধারণ করতে পারে এবং বেশ কয়েকটি শক্তিশালী বেসেলাইনের সাথে তথ্য প্রতি', 'az': 'Dialoog məsələlərinin yönetimi və arxa plan bilgi seçimi bilgi tərzində açıq domena danışmalarının başarısızlığı üçün əsas faktörlərdir. Halbuki mövcud modellər ilk dəfə simetrik bilgi üssələri ilə və ya ön təyin edilmiş məsələlər ilə danışmaq şəriklərinin arasındakı rollərlə istifadə edilirlər. Halbuki insanlar genellikle gerçek chit sohbətindən əvvəl özlərinə elm verirlər. Bu problemi çəkmək üçün dinamik bilgi grafına dayanan məsələn müzakirə modeli (DKGT) təklif edirik. Dialog keçmişi məlumatlarına görə, modelimiz ilk dəfə məlumatlardan elm grafiklərini insanın bilinmiş və bilinmiş məlumatların arasındakı lojik ilişkilerinin imitasyonu kimi inşa edir. Bu lojik məlumat, məlumat yönetimini təşkil etmək üçün bir məlumat öndəyicisinə veriləcək, sonra arxa plan bilgi seçimlərini və cavab verəni asanlaşdıracaq. Bizim elmimizin ən yaxşısına gəldikdə, bu məsələlər barəsindəki məsələlər arasında dinamik olaraq elm grafiklərini məlumatlarına kömək etmək üçün ilk nəsihətdir. Müxtəlif sonuçlarımız modellərimiz müzakirə məsələləri düzgün planlaşdıra bilər və informativ cavab verə bilər ki, çoxlu güclü sətirlərlə qarşılaşdıra bilər.', 'hy': "Խաղախոսության թեմայի ղեկավարումը և հետնային գիտելիքների ընտրությունը կարևոր գործոններ են գիտելիքի հիմնված բաց բնագավառի հաջողության համար: Այնուամենայնիվ, գոյություն ունեցող մոդելները հիմնականում կատարվում են սիմետրիկ գիտելիքների հիմքերով կամ ձևավորվում են նախասահմանափակ դերերով խոսակցական գործընկերների միջև, մինչդեռ մարդիկ սովորաբար իրենց սեփական գիտելիքները ունեն իրական խոսակ Այս խնդիրը լուծելու համար մենք առաջարկում ենք դինամիկ գիտելիքների գրաֆիկայի հիմնված թեմական զրույցի մոդել (DKGT). Given a dialog history context, our model first builds knowledge graphs from the context as an imitation of human's ability to form logical relationships between known and unknown topics during a conversation.  Այս տրամաբանական տեղեկատվությունը կփոխանցվի թեմայի կանխատեսողի մեջ, որպեսզի խրախուսենք թեմայի ղեկավարումը, հետո հեշտացնենք գիտելիքների ընտրությունը և արձագանքը: Մեր լավագույն գիտելիքներից սա առաջին փորձն է դինամիկ ձևավորել գիտելիքի գրաֆիկներ խոսակցող թեմաների միջև, որպեսզի օգնենք խոսակցության ընթացքում խոսակցված թեմաների ղեկավարման համար: Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses comparing to several strong baselines.", 'ca': "La gestió del tema del diàleg i la selecció del coneixement de fons són factors essencials per l'èxit de les converses de domini obert basades en el coneixement. No obstant això, els models existents es produeixen principalment amb bases de coneixements simètriques o estilitzan amb rols predefinits entre parelles de conversa, mentre la gent normalment té el seu propi coneixement abans d'una conversa real. Per abordar aquest problem a, proposem un model de conversa tòpica (DKGT) basat en el gràfic del coneixement dinàmic. Tenint en compte el context històric del diàleg, el nostre model primer construeix gràfics del coneixement del context com una imitació de l'habilitat human a de formar relacions lògiques entre temes coneguts i desconeguts durant una conversa. Aquesta informació lògica s'alimentarà en un preditor de temes per promoure la gestió de temes, i després facilitar la selecció de coneixements de fons i la generació de resposta. Per millor del nostre coneixement, aquest és el primer intent de formar dinàmicament gràfics de coneixement entre temes de conversa per ajudar la gestió de temes de diàleg durant una conversa. Els resultats experimentals manifesten que el nostre model pot planificar adequadament els temes de conversa i triar coneixements adequats per generar respostes informatives comparant-se amb diverses línies de base fortes.", 'bs': 'Upravljanje teme dijaloga i izbor znanja pozadine su ključni faktori za uspjeh razgovora o otvorenom domenu na temelju znanja. Međutim, postojeći modeli su primarno izvedeni simetričnim bazama znanja ili stilirani preddefiniranim ulogama između razgovornih partnera, dok ljudi obično imaju svoje znanje prije stvarnog razgovora. Za rješavanje ovog problem a predlažemo dinamični model temalnog razgovora na grafiku znanja (DKGT). S obzirom na kontekst istorije dijaloga, naš model prvo izgradi grafike znanja iz konteksta kao imitaciju sposobnosti ljudskog stvoriti logičke veze između poznatih i nepoznatih tema tokom razgovora. Ove logičke informacije će biti uložene u predviđa č teme kako bi promovisala upravljanje temama, a zatim olakšala izabranje pozadinskih znanja i generaciju odgovora. Za najbolje od našeg znanja, ovo je prvi pokušaj da dinamički oblikuje grafike znanja između razgovora o temama kako bi pomoglo upravljanju temama dijaloga tijekom razgovora. Eksperimentalni rezultati pokazuju da naš model može ispravno rasporediti razgovorne teme i izabrati odgovarajuće znanje kako bi stvorili informativne odgovore u usporedbi sa nekoliko jakih osnovnih linija.', 'et': 'Dialoogi teemajuhtimine ja taustteadmiste valik on teadmistepõhiste avatud domeeniliste vestluste edukuse olulised tegurid. Kuid olemasolevaid mudeleid teostatakse peamiselt sümmeetriliste teadmistebaasidega või stiliseeritakse eelnevalt määratletud rollidega vestluspartnerite vahel, samas kui inimestel on tavaliselt oma teadmised enne tõelist vestlust. Selle probleemi lahendamiseks pakume välja dünaamilise teadmiste graafikul põhineva aktuaalse vestlusmudeli (DKGT). Dialoogiajaloo konteksti arvestades ehitab meie mudel esmalt kontekstist teadmisgraafikud, jäljendades inimese võimet luua vestluse käigus loogilisi suhteid tuntud ja tundmatute teemade vahel. See loogiline teave sisestatakse teema ennustajasse, et edendada teemajuhtimist, seejärel hõlbustada taustteadmiste valikut ja reageerimist. Meie teadmiste kohaselt on see esimene katse dünaamiliselt kujundada teadmisgraafikuid vestlusteemade vahel, et aidata dialoogi teemade haldamisel vestluse ajal. Eksperimentaalsed tulemused näitavad, et meie mudel suudab korralikult planeerida vestlusteemasid ja valida sobivad teadmised, et luua informatiivseid vastuseid võrreldes mitme tugeva lähtejoonega.', 'fi': 'Vuoropuhelun aiheiden hallinta ja taustatiedon valinta ovat keskeisiä tekijöitä tietopohjaisten avointen keskustelujen onnistumiselle. Kuitenkin olemassa olevat mallit suoritetaan ensisijaisesti symmetrisillä tietopohjilla tai tyylitellään ennalta määritellyillä rooleilla keskustelukumppanien välillä, kun taas ihmisillä on yleensä omat tietonsa ennen oikeaa keskustelua. Tämän ongelman ratkaisemiseksi ehdotamme dynaamista tietografiikkapohjaista ajankohtaista keskustelumallia (DKGT). Dialogihistorian kontekstissa mallimme rakentaa ensin tietokaavioita kontekstista jäljittelemään ihmisen kykyä muodostaa loogisia suhteita tunnettujen ja tuntemattomien aiheiden välille keskustelun aikana. Tämä looginen tieto syötetään aiheen ennustajaan aiheen hallinnan edistämiseksi, minkä jälkeen taustatiedon valinta ja vastausten luominen helpotetaan. Tietojemme mukaan tämä on ensimmäinen yritys luoda dynaamisesti tietokaavioita chatin aiheiden välillä auttaakseen dialogin aiheiden hallintaa keskustelun aikana. Kokeelliset tulokset osoittavat, että mallimme pystyy ajoittamaan keskusteluaiheita oikein ja valitsemaan sopivan tiedon tuottamaan informatiivisia vastauksia verrattuna useisiin vahvoihin lähtökohtiin.', 'cs': 'Správa dialogových témat a výběr pozadí znalostí jsou základními faktory pro úspěch otevřených konverzací založených na znalostech. Stávající modely jsou však primárně prováděny se symetrickými znalostními bázemi nebo stylizovány s předem definovanými rolemi mezi konverzačními partnery, zatímco lidé mají obvykle své vlastní znalosti před skutečným chatem. Pro řešení tohoto problému navrhujeme dynamický znalostní graf založený na aktuálním konverzačním modelu (DKGT). Vzhledem k kontextu historie dialogu, náš model nejprve sestavuje znalostní grafy z kontextu jako imitace lidské schopnosti vytvářet logické vztahy mezi známými a neznámými tématy během konverzace. Tyto logické informace budou vloženy do prediktoru tématu pro podporu řízení tématu, následně usnadní výběr pozadí znalostí a generování reakcí. Podle našeho nejlepšího vědomí je to první pokus dynamicky vytvářet grafy znalostí mezi tématy chatování, které pomohou správě témat dialogu během konverzace. Experimentální výsledky ukazují, že náš model dokáže správně naplánovat konverzační témata a vybrat vhodné znalosti pro generování informativních reakcí ve srovnání s několika silnými základními liniemi.', 'sq': 'Menaxhimi i temave të dialogut dhe zgjedhja e njohurive të sfondit janë faktorë thelbësorë për suksesin e bisedimeve në domeni të hapur bazuar në njohuri. However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat.  Për të trajtuar këtë problem, ne propozojmë një model diskutimi aktual (DKGT) të bazuar në grafikën e njohurive dinamike. Duke pasur parasysh një kontekst historike dialog, modeli ynë fillimisht ndërton grafikë njohurie nga konteksti si një imitim të aftësisë s ë njeriut për të formuar marrëdhënie logjike midis temave të njohura dhe të panjohura gjatë një bisedimi. This logical information will be fed into a topic predictor to promote topic management, then facilitate background knowledge selection and response generation.  Për më të mirën e njohurive tona, kjo është përpjekja e parë për të formuar dinamikisht grafikë njohurie midis temave të bisedës për të ndihmuar menaxhimin e temave të dialogut gjatë një bisede. Rezultatet eksperimentale tregojnë se modeli ynë mund të planifikojë si duhet temat bisedimore dhe të zgjedhë njohuri të përshtatshme për të gjeneruar përgjigje informacionale krahasuar me disa linja bazë të forta.', 'jv': "Dialog title Nanging, model sing saiki bukane saiki dadi nggawe barang sistem matarané karo sistem matarané perusahaan ginarané karo perusahaan ingkang dipolerané karo perusahaan Where's the conversation kanggo nganggo perbudhakan iki, kita supoyo sistem kanggo ngerasakno diagram sing basa gambar nggo resmi (DKGT). Nyong bakal kelas sistem dialog sing paling, model nambah dhéwé nggawe nggawe barang kelas nang kontèké iki dadi ngubah perbudhakan kanggo nggawe barang langgar sampeyan karo perbudhakan sing urip diangkat dhéwé. Puwedhakan informasi iki bakal ngetoke kang dipunangguna temu kanggo nggawe stiftar temu, njuk veyandigo mulasar kelangan bilgi lan jenengan responsa. Panjenengan langkung rawuh akeh bilgi, iki kuwi saiki perusahaan tanggal nggawe gerakan kelalen winih sing dibutuhke tarjamahan kanggo nyebute nggawe conversasi tarjamahan Menu item", 'ha': "Manajan maɓallin zauren akwatin bayani da zaɓen ilmi na bango yana da muhimu wa masu buwãyar da mazaɓa da akwatin bayani-bakin. A lokacin da haka, za'a samar da misãlai masu da ko kuma a ƙayyade su da rolen da aka bayyana a gabãni a tsakanin abõkan mazaɓa, kuma a lokacin da mutane ko ko da kawaici suna da saninsu gaba ga mazaɓa da gaskiya. Domin ka yi addu'a ga wannan mataimaki, Munã buƙata wani misali na mazaɓa da aka ƙayyade fassarar da ilmi (DKGT). Gida wani mazaɓa na zauren zauren akwatin bayanin zauren akwatin bayani, misalinmu na farko yana samar da karatun zane daga mazaɓa kamar misãlin mutum's abinci ya ƙiƙira danganta logiki tsakanin maɓallin da ba'a sani ba a lokacin da ke yi mazaɓa. Wannan maɓalli na logi za'a motsa zuwa wani mai bayani na madaidaici dõmin ya promote manajan madaidaici, sa'an nan kuma ya yi amfani da zaɓen zane na bangon bangon da kuma zaɓen ajiya. Ga mafi kyaun sanyinmu, wannan ne jarraba ta farkon ka sami karatun zane a danna fassarar ilmi a tsakanin mazaɓa da yin magana dõmin ya taimake manajan mazaɓa cikin zauren a lokacin da ake yi musu magana. Matarin jarrabai sun bayyana cewa misalinmu yana iya iya ƙayyade madaidaita masu yin mazaɓa da mazaɓa, kuma ya zãɓi ilmi mai daidaita zuwa ya ƙiƙiro majibu masu inganci da sami'a da misalin wasu masu ƙarfi.", 'he': 'ניהול נושאי דיאלוג ובחירת ידע רקע הם גורמים חיוניים להצלחה של שיחות שטח פתוח על ידי ידע. בכל אופן, דוגמנים קיימים מבצעים בעיקר עם בסיסי ידע סימטרי או מסוגלים עם תפקידים מוגדרים מראש בין שותפים שיחה, בעוד אנשים בדרך כלל יש ידע משלהם לפני שיחה אמיתית. כדי להתמודד עם הבעיה הזאת, אנו מציעים מודל שיחה נושאי (DKGT) מבוסס על גרף הידע דינמי. בהתחשב בקשר ההיסטוריה של הדיולוגים, המודל שלנו קודם בונה גרפים ידע מההקשר כחיקוי של היכולת האנושית ליצור מערכות יחסים הגיוניות בין נושאים ידועים ולא ידועים במהלך שיחה. המידע הגיוני הזה ייתן לחזוי נושא כדי לקדם ניהול נושאים, ואז להקל את בחירת ידע רקע ודור תגובה. למיטב הידע שלנו, זו הניסיון הראשון ליצור דינמית גרפים הידע בין נושאי שיחה כדי לעזור לנהל נושאי דיאלוג במהלך שיחה. תוצאות ניסויים מראות שהדוגמנית שלנו יכולה לקבוע נושאים שיחה כראוי ולבחר ידע מתאים כדי ליצור תגובות מידעיות בהשוואה לכמה קווים בסיסיים חזקים.', 'sk': 'Upravljanje tematskih pogovorov in izbira ozadja sta bistvena dejavnika za uspeh pogovorov na znanju temelječih odprtih domenskih pogovorov. Vendar pa se obstoječi modeli izvajajo predvsem s simetričnimi bazami znanja ali stilizirajo z vnaprej določenimi vlogami med pogovornimi partnerji, medtem ko imajo ljudje običajno svoje znanje pred pravim klepetanjem. Za reševanje tega problema predlagamo dinamični model pogovora na podlagi grafičnega dinamičnega znanja (DKGT). Glede na zgodovinski kontekst dialoga naš model najprej gradi grafe znanja iz konteksta kot posnemanje sposobnosti človeka, da med pogovorom oblikuje logične odnose med znanimi in neznanimi temami. Te logične informacije bodo vnesene v napovedovalnik teme za spodbujanje upravljanja teme, nato pa olajšanje izbire ozadja in ustvarjanje odzivov. Po našem znanju je to prvi poskus dinamičnega oblikovanja grafov znanja med temami klepetanja, ki pomagajo pri upravljanju tematskih pogovorov med pogovorom. Eksperimentalni rezultati kažejo, da lahko naš model pravilno načrtuje pogovorne teme in izbere ustrezno znanje za ustvarjanje informativnih odzivov v primerjavi z več močnimi osnovnimi linijami.', 'bo': 'Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations. ཡིན་ནའང་། གནས་ཡུལ་པའི་མིག་གཟུགས་རིས་འདི་ལྟ་བུའི་རྨས་གཞི་དང་མཉམ་དུ་སྔོན་གྱིས་གཏོང་འབྲེལ་མཐུད་དང་མཐུན་སྒྲིག དཀའ་ངལ་འདི་ལ་བསླབ་ན་འོང་ནི་ང་ཚོས་རང་ཉིད་སྒྱུར་གྱི་རྣམ་གྲངས་གཞི་བཞག་ཡོད་པའི་གཏམ་གླེང་སྒྲུབ་གྱི་ གླེང་སྒྲོམ་གྱི་ལོ་རྒྱུས་ཁོར་ཡུག་ཅིག་ལ་བཞག དེ་ལྟ་བུའི་གྲངས་རིག་གནས་ཚུལ་འདི་ཚོར་མཁན་གྱི་གནད་དོན་དོ་དམ་པ་དང་མཐུན་སྣེ་མངོན་འཆར་བྱེད་དགོས། ང་ཚོའི་ཆེད་དུ་འཕགས་པ་ཤེས་པའི་ཆེད་དུ་འདི་ནི་གླེང་སྒྲོམ་གྱི་ནང་དུ་གཏོང་གི་མཐོང་འབྲེལ་གྱི་མཐོང་རིམ་གྱི་དཔའ་བཅས་དང་པོ་རེ Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses compared to several strong baselines.'}
{'en': 'What Makes My Model Perplexed? A Linguistic Investigation on Neural Language Models Perplexity', 'pt': 'O que deixa meu modelo perplexo? Uma investigação linguística sobre a perplexidade dos modelos de linguagem neural', 'fr': "Qu'est-ce qui rend mon modèle perplexe\xa0? Une enquête linguistique sur la perplexité des modèles de langage neuronal", 'es': '¿Qué hace que mi modelo quede perplejo? Una investigación lingüística sobre la perplejidad de modelos de lenguaje neuronal', 'ar': 'ما الذي يجعل نموذجي في حيرة من أمره؟ استقصاء لغوي عن حيرة نماذج اللغة العصبية', 'ja': '自分のモデルを困惑させるものは何ですか？神経言語モデルの複雑性に関する言語学的調査', 'ru': 'Что делает мою модель озадаченной? Лингвистическое исследование по изучению недоумения нейронных языковых моделей', 'zh': '何以惑吾模特? 神经语言模形困惑之语言学', 'hi': 'क्या मेरे मॉडल को उलझन में डालता है? तंत्रिका भाषा मॉडल पर एक भाषाई जांच उलझन', 'ga': 'Cad a Chuirfeadh Imphlé ar Mo Mhúnla? Imscrúdú Teangeolaíoch ar Mhúnlaí Néar-Theangacha Atá i gceist', 'hu': 'Mi teszi zavarba a modellemet? A neurális nyelvi modellek nyelvi vizsgálata Perplexity', 'ka': 'კაკგჲ ოპაგთ მჲევლყრ მთ? Name', 'el': 'Τι κάνει το μοντέλο μου διεστραμμένο; Γλωσσολογική διερεύνηση της διεφθαρμότητας μοντέλων νευρωνικής γλώσσας', 'lt': 'Kas sutrikdo mano modelį? Kalbų tyrimas, susijęs su nervinių kalbų modelių sutrikimu', 'ms': 'Apa yang membuatkan Model saya terganggu? Name', 'kk': 'Менің үлгімді қайталап тұрады? Невралдық тіл үлгілерінде лингвистикалық зерттеу', 'it': "Cosa rende il mio modello perplesso? Un'indagine linguistica sui modelli linguistici neurali Perplessità", 'mk': 'Што го прави мојот модел збунет? Name', 'ml': 'എന്\u200dറെ മോഡല്\u200d എന്താണ് പ്രശ്നമാക്കുന്നത്? A Linguistic Investigation on Neural Language Models Perplexity', 'no': 'Kva gjer modellen min perpleksert? Name', 'mn': 'Миний загвар юу үүсгэдэг вэ? Сэтгэл хэл загваруудын тухай ярианы судалгаа', 'pl': 'Co sprawia, że mój model jest przekręcony? Językowe badanie nad perplexitą modeli języka neuronowego', 'ro': 'Ce face modelul meu Perplexed? O investigaţie lingvistică asupra modelelor lingvistice neurale Perplexitate', 'si': 'මොකක්ද මගේ මොඩල් ප්\u200dරශ්නයක් කරන්නේ? Name', 'sr': 'Šta čini moj model perpleksiran? Lingistička istraga o neuronskim modelima', 'mt': 'X’jagħmel il-Mudell tiegħi mħallat? Investigazzjoni Lingwistika dwar Mudelli ta’ Lingwi Newrali Perplessità', 'sv': 'Vad gör min modell förvirrad? En språklig undersökning av neurala språkmodeller Perplexity', 'so': 'Muxuu ka dhigaa qaababkayga in la dhibaato? Baaritaanka luqada Neural', 'ur': 'اور میرا نمونہ کس چیز کو دھوکا دیتا ہے؟ نئورل زبان موڈل پرپرلکسٹی پر ایک لینگویسٹی تحقیق', 'ta': 'என் மாதிரி சிக்கலாக்கப்பட்டது என்ன ஆக்குகிறது? Name', 'uz': 'Mening modul muvaffaqiyatli yaratish mumkin? Name', 'vi': 'Điều gì làm cho Mô hình của tôi bối rối? Một cuộc điều tra ngôn ngữ thần kinh về sự phức tạp', 'bg': 'Какво прави модела ми перфектен? Лингвистично изследване на перплекситета на невралните езикови модели', 'da': 'Hvad gør min model forvirret? En sproglig undersøgelse af neurale sprogmodeller Perpleksitet', 'nl': 'Wat maakt mijn model perplex? Een taalkundig onderzoek naar perplexiteit van neurale taalmodellen', 'hr': 'Što čini moj model perpleksiran? Lingistička istraga o neuronskim modelima', 'de': 'Was macht mein Modell perplex? Eine linguistische Untersuchung neuronaler Sprachmodelle Perplexität', 'id': 'Apa yang membuat Modelku terganggu? Sebuah penyelidikan Bahasa tentang Model Bahasa Neural Perpleksity', 'fa': 'چی مدل من رو شکست میده؟ Name', 'ko': '무엇이 나의 모형을 곤혹스럽게 합니까?신경 언어 모델 곤혹스러운 언어학 연구', 'sw': 'Nini kinafanya Modeli yangu kuwa na tatizo? Utafiti wa lugha za Kiingereza kuhusu Tatizo la Utawala', 'tr': 'Meniň nusgamy çalşyrýan? Niral Diller Perpleksiýasy barada hatlary barlamak', 'af': 'Wat maak My Model Verpleksig? Name', 'sq': 'Çfarë e bën modelin tim të prishur? Një hetim gjuhësor mbi modelet e mëkateve të gjuhës nervore', 'am': 'የሞዴል መፍጠር ምን ያደርጋል? A Linguistic Investigation on Neural Language Models Perplexity', 'hy': 'Ի՞նչն է խառնում իմ մոդելը: Նյարդային լեզվի մոդելների խառնաշփության լեզվային հետազոտությունը', 'az': 'M…ônim modelimi nec…ô d…ôyiŇüdirir? N√∂ral dil modell…ôrinin f…ôrqli olmasńĪ bar…ôsind…ô Linguistic Investigation', 'ca': 'What Makes My Model Perplexed?  Una investigació lingüística sobre els models de llenguatge neuronal', 'bn': 'আমার মোডেল কি বানায়? Name', 'bs': 'Što čini moj model perpleksiran? Lingistička istraga o neuronskim modelima', 'cs': 'Co dělá můj model perplexní? Jazykové vyšetřování neurálních jazykových modelů Perplexity', 'et': 'Mis teeb mu mudeli rikutuks? Neuraalsete keelemudelite perpleksiidi keeleline uurimine', 'fi': 'Mikä tekee mallistani sekaisin? Kielellinen tutkimus hermokielimallien perpleksiteetistä', 'jv': 'Kepiye sing gawe modelimu perbleksi ? Name', 'ha': 'What Makes My Model Perplexed?  KCharselect unicode block name', 'he': 'מה גורם לדוגמא שלי להתפשט? חקירה שפותית על מודלים שפות נוירוליות', 'sk': 'Zakaj je moj model zmeden? Jezikovna raziskava o perpleksitnosti živčnih jezikovnih modelov', 'bo': 'ངའི་མ་དབྱིབས་ཡིག་ཆ་འདྲ་བྱེད་མཁན་ཅི་ཞིག་ཡིན་ནམ སྐད་རིགས་འདྲ་བའི་དཔེ་དབྱིབས་དབྱེ་བ་ལ་བརྟག་དཔྱད་གཏོང'}
{'en': 'This paper presents an investigation aimed at studying how the linguistic structure of a sentence affects the perplexity of two of the most popular Neural Language Models (NLMs), BERT and GPT-2. We first compare the sentence-level likelihood computed with BERT and the GPT-2’s perplexity showing that the two  metrics  are correlated. In addition, we exploit linguistic features capturing a wide set of morpho-syntactic and syntactic phenomena showing how they contribute to predict the perplexity of the two NLMs.', 'ar': 'تقدم هذه الورقة تحقيقًا يهدف إلى دراسة كيفية تأثير التركيب اللغوي للجملة على ارتباك اثنين من أشهر نماذج اللغة العصبية (NLMs) ، وهما BERT و GPT-2. نقارن أولاً الاحتمالية على مستوى الجملة المحسوبة باستخدام BERT وحيرة GPT-2 التي توضح أن المقياسين مرتبطان. بالإضافة إلى ذلك ، نحن نستغل الميزات اللغوية لالتقاط مجموعة واسعة من الظواهر النحوية الصرفية والنحوية التي توضح كيفية مساهمتها في التنبؤ بحيرة اللغتين NLM.', 'fr': "Cet article présente une enquête visant à étudier comment la structure linguistique d'une phrase affecte la perplexité de deux des modèles de langage neuronal (NLM) les plus populaires, BERT et GPT-2. Nous comparons d'abord la probabilité au niveau de la phrase calculée avec BERT et la perplexité du GPT-2 en montrant que les deux métriques sont corrélées. De plus, nous exploitons des caractéristiques linguistiques qui capturent un large éventail de phénomènes morpho-syntaxiques et syntaxiques montrant comment elles contribuent à prédire la perplexité des deux NLM.", 'ja': '文の言語構造が最も人気のある2つの神経言語モデル（ NLM ）であるBERTとGPT -2の複雑さにどのように影響するかを研究することを目的とした調査を提示した。まず、BERTで計算された文レベルの尤度と、2つの指標が相関していることを示すGPT -2の難解さを比較します。さらに、2つのNLMの複雑さを予測するためにそれらがどのように貢献するかを示す、形態構文および構文現象の幅広いセットを取り込む言語学的特徴を利用する。', 'pt': 'Este artigo apresenta uma investigação que visa estudar como a estrutura linguística de uma sentença afeta a perplexidade de dois dos mais populares Modelos de Linguagem Neural (NLMs), BERT e GPT-2. Primeiro comparamos a verossimilhança em nível de sentença calculada com o BERT e a perplexidade do GPT-2, mostrando que as duas métricas estão correlacionadas. Além disso, exploramos recursos linguísticos capturando um amplo conjunto de fenômenos morfossintáticos e sintáticos mostrando como eles contribuem para prever a perplexidade dos dois NLMs.', 'es': 'Este artículo presenta una investigación destinada a estudiar cómo la estructura lingüística de una oración afecta la perplejidad de dos de los Modelos de Lenguaje Neural (NLM) más populares, BERT y GPT-2. Primero comparamos la probabilidad a nivel de oración calculada con BERT y la perplejidad de GPT-2, lo que demuestra que las dos métricas están correlacionadas. Además, explotamos las características lingüísticas que capturan un amplio conjunto de fenómenos morfosintácticos y sintácticos que muestran cómo contribuyen a predecir la perplejidad de los dos NLM.', 'hi': 'यह पेपर एक जांच प्रस्तुत करता है जिसका उद्देश्य यह अध्ययन करना है कि एक वाक्य की भाषाई संरचना सबसे लोकप्रिय न्यूरल लैंग्वेज मॉडल (एनएलएम), बर्ट और जीपीटी -2 में से दो की उलझन को कैसे प्रभावित करती है। हम पहले BERT और GPT-2 की उलझन के साथ गणना की गई वाक्य-स्तर की संभावना की तुलना करते हैं जो दिखाता है कि दो मीट्रिक सहसंबद्ध हैं। इसके अलावा, हम भाषाई विशेषताओं का शोषण करते हैं जो मॉर्फो-सिंटैक्टिक और वाक्यात्मक घटनाओं के एक विस्तृत सेट पर कब्जा कर लेते हैं जो दिखाते हैं कि वे दो एनएलएम की उलझन की भविष्यवाणी करने में कैसे योगदान करते हैं।', 'ru': 'В данной работе представлено исследование, направленное на изучение того, как лингвистическая структура предложения влияет на недоумение двух наиболее популярных моделей нейронного языка (NLM), BERT и GPT-2. Сначала мы сравниваем вероятность на уровне предложения, рассчитанную с БЕРТОМ, и недоумение GPT-2, показывающее, что эти две метрики коррелируют. Кроме того, мы используем лингвистические особенности, захватывающие широкий набор морфо-синтаксических и синтаксических явлений, показывающих, как они способствуют прогнозированию недоумения двух NLM.', 'zh': '本文举一勘,旨在研句语结构,何妨两行神经语言(NLM)BERTGPT-2之惑。 先较用BERT算之句,与GPT-2之困,明二指标相关也。 语言获句法句法,展其两NLM之惑。', 'ga': 'Cuireann an páipéar seo imscrúdú i láthair a bhfuil sé mar aidhm aige staidéar a dhéanamh ar an gcaoi a dtéann struchtúr teanga abairte i bhfeidhm ar aimhréiteach dhá cheann de na Múnlaí Neural Language (NLManna), BERT agus GPT-2. Déanaimid comparáid ar dtús idir an dóchúlacht ar leibhéal na habairte a ríomhtar le CRET agus le haimsearacht GPT-2 a thaispeánann go bhfuil comhghaol idir an dá mhéadracht. Chomh maith leis sin, bainimid leas as gnéithe teangeolaíocha ag gabháil do shraith leathan feiniméin mhorpho-chomhréireacha agus chomhréire a thaispeánann an chaoi a gcuidíonn siad le haimneastacht an dá NLM a thuar.', 'ka': 'ამ დოკუნტის შესახებ შესახებ, როგორ სიტყვების ლინგურისტიკური სტრუქტურაციაზე გააკეთება ორი პოლიპური ნეირალური ენის მოდელში (NLMs), BERT და GPT-2. ჩვენ პირველი შემდეგ გადასწორებთ ბერტით და GPT-2-ის დასწორება, რომ ორი მეტრიკის კოლელიაცია იქნება. დამატებით, ჩვენ ვაკეთებთ ლინგურისტიკური განსაზღვრებები, რომლებიც მოპო-სინტაქტიკური და სინტაქტიკური ფენომენების უფრო დიდი ნაწილი, რომლებიც ისინი გავაკეთებენ ორი NLMs-ის და', 'el': 'Η παρούσα εργασία παρουσιάζει μια έρευνα με στόχο τη μελέτη του τρόπου με τον οποίο η γλωσσική δομή μιας πρότασης επηρεάζει την σύγχυση δύο από τα πιο δημοφιλή μοντέλα Νευρικής Γλώσσας (ΝLM), BERT και GPT-2. Πρώτα συγκρίνουμε την πιθανότητα επιπέδου πρότασης που υπολογίζεται με το BERT και την σύγχυση του GPT-2 δείχνοντας ότι οι δύο μετρήσεις συσχετίζονται. Επιπλέον, αξιοποιούμε γλωσσικά χαρακτηριστικά που αποτυπώνουν ένα ευρύ σύνολο μορφοσυντακτικών και συντακτικών φαινομένων δείχνοντας πώς συμβάλλουν στην πρόβλεψη της σύγχυσης των δύο ΜΜs.', 'hu': 'Jelen tanulmány bemutatja, hogy egy mondat nyelvi struktúrája hogyan befolyásolja a két legnépszerűbb Neural Language Model (NLM), a BERT és a GPT-2 zavaróságát. Először összehasonlítjuk a BERT-vel kiszámított mondatszintű valószínűséget és a GPT-2 zavaróságát, ami azt mutatja, hogy a két mutató korrelálódik. Emellett a morfo-szintaktikus és szintaktikus jelenségek széles körét rögzítő nyelvi tulajdonságokat használjuk ki, amelyek bemutatják, hogyan járulnak hozzá a két NLM zavaróságának előrejelzéséhez.', 'it': "Questo articolo presenta un'indagine volta a studiare come la struttura linguistica di una frase influisca sulla perplessità di due dei modelli linguistici neurali più popolari (NLM), BERT e GPT-2. Per prima cosa confrontiamo la probabilità a livello di frase calcolata con BERT e la perplessità del GPT-2 mostrando che le due metriche sono correlate. Inoltre, sfruttiamo le caratteristiche linguistiche catturando un ampio insieme di fenomeni morfo-sintattici e sintattici mostrando come contribuiscono a prevedere la perplessità dei due NLM.", 'kk': 'Бұл қағаз тілінің лингвистикалық құрылымының қалай әсер ететін зерттеулерді көрсетеді. Бұл сөйлеменің екі нақты нейралық тіл үлгілерінің (NLMs), BERT және GPT-2 үлгілерінің қалай әсер ететінін зерт Біз біріншіден BERT және GPT-2 деңгейінде есептелген сөз деңгейінің мүмкіндігін салыстырып, екі метрикалық коррелелегенін көрсетеді. Қосымша, біз лингвистикалық мүмкіндіктерді қолдану үшін көптеген морфосинтактикалық және синтактикалық пайдалануларды көрсетеді.', 'lt': 'Šiame dokumente pateikiamas tyrimas, kuriuo siekiama ištirti, kaip kalbinė bausmės struktūra daro poveikį dviejų populiariausių neuralinių kalbų modelių (NLM), BERT ir GPT-2 perpleksijai. Pirmiausia palyginame sakinio lygio tikimybę, apskaičiuotą su BERT ir GPT-2 perpleksija, rodančia, kad šios dvi metrijos yra koreliuojamos. Be to, mes naudojame kalbinius požymius, gaunančius platų morfosintaksinių ir sintaksinių reiškinių rinkinį, rodantį, kaip jie padeda prognozuoti dviejų NLM perpleksiją.', 'ml': 'ഈ പത്രത്തില്\u200d ഒരു അന്വേഷണം കൊണ്ടുവരുന്നു. വാക്കിന്റെ ഭാഷ സ്ഥാനം എങ്ങനെയാണ് പ്രധാനപ്പെട്ട നെയുറല്\u200d ഭാഷ മോഡലുകളില്\u200d രണ്ടില്\u200d പ്രശസ്തമായി സംഭവിക്കു നമ്മള്\u200d ആദ്യം വാക്കിന്റെ നില വാക്കുകള്\u200d ബെര്\u200dട്ടിയോടൊപ്പം കണക്കാക്കിയിരിക്കുന്നു. ഈ രണ്ട് മെട്രിക്കുകള്\u200d ബന്ധപ്പെട്ടി അതുകൂടാതെ, നമ്മള്\u200d ഭാഷയിലെ വിശേഷതകള്\u200d ഉപയോഗിക്കുന്നു. ഒരു കൂടുതല്\u200d മോര്\u200dഫോ-സിനിട്ടിക്കും സിനിട്ടാക്കിക്കൊണ്ടും പിടിക്കുന്നു. രണ്ട് എംഎല്\u200dഎസി', 'mt': 'Dan id-dokument jippreżenta investigazzjoni mmirata lejn l-istudju ta’ kif l-istruttura lingwistika ta’ sentenza taffettwa l-perplessità ta’ tnejn mill-mudelli lingwistiċi newrali l-aktar popolari (NLMs), BERT u GPT-2. L-ewwel nett inqabblu l-probabbiltà tal-livell tas-sentenza kkalkulata mal-BERT u l-perplessità tal-GPT-2 li turi li ż-żewġ metriċi huma korrelati. Barra minn hekk, nisfruttaw karatteristiċi lingwistiċi li jaqbdu sett wiesa’ ta’ fenomeni morfosintattiċi u sintattiċi li juru kif jikkontribwixxu biex jipprevedu l-perplessità taż-żewġ NLMs.', 'mk': 'Овој весник претставува истрага со цел да се проучува како јазичката структура на реченицата влијае врз збунетоста на двата од најпопуларните Неурални јазични модели (НЛМ), БЕРТ и ГПТ-2. Прво ја споредуваме веројатноста на нивото на реченица обчистена со БЕРТ и заглуженоста на ГПТ-2 покажувајќи дека двете метрики се поврзани. Покрај тоа, ние ги искористуваме јазичните карактеристики кои заземаат широк сет морфосинтактички и синтактички феномени кои покажуваат како тие придонесуваат за предвидување на збунетоста на двете НЛМ.', 'pl': 'W artykule przedstawiono badanie mające na celu zbadanie, w jaki sposób struktura językowa zdania wpływa na zagmatwanie dwóch najpopularniejszych modeli języka neuronowego (NLM), BERT i GPT-2. Najpierw porównujemy prawdopodobieństwo na poziomie zdania obliczone z BERT i zdezorientowanie GPT-2 pokazując, że oba wskaźniki są skorelowane. Ponadto wykorzystujemy cechy językowe uchwytujące szeroki zestaw zjawisk morfoskładni i składni, pokazując, w jaki sposób przyczyniają się one do przewidywania zagmatwań dwóch NLM.', 'mn': 'Энэ цаас хэвлэлийн хэлний бүтэц яаж хамгийн алдартай мэдрэлийн хэл загварын хоёр төрөлхтний тулд нөлөөлдөг талаар судлах зорилго гаргадаг. Бид эхлээд BERT болон GPT-2-ийн хувьд тооцоолж байгаа өгүүлбэртэй магадлалыг харьцуулж байна. Мөн бид хэлний хувьд морфо-синтактик болон синтактик үзэгдлийг хэрхэн нөлөөлдөг талаар ашигладаг.', 'no': 'Denne papiret viser eit forsøk med å studera korleis språkstrukturen av eit setning påvirkar at to av de populærste neirale språk-modelane (NLMs), BERT og GPT-2 påvirkar. Vi sammenliknar først sannsynligheten for setningsnivå kalkulart med BERT og GPT-2-en som viser at to metrikane er korrelaterte. I tillegg bruker vi lingviske funksjonar som får eit brett sett av morpho-syntaktiske og syntaktiske fenomen som viser korleis dei bidrar til å foregå forskjelligheten av to NLMs.', 'si': 'මේ පත්තරය පෙනුවෙන් පරීක්ෂණයක් තියෙනවා අධ්\u200dයානය කරන්නේ කොහොමද වාර්තාවේ භාෂාවික ස්ථානය ප්\u200dරශ්නයක් තියෙන්නේ ප්\u200dරශ්නයක් නිර අපි මුලින්ම වාක්ය සම්බන්ධතාවය BERT සහ GPT-2 ගැන සම්බන්ධතාවය සම්බන්ධතාවය පෙන්වන්න පුළුවන් ඒ වගේම, අපි භාෂාවික අවශ්\u200dය භාෂාවික අවශ්\u200dය ප්\u200dරවේශ කරනවා මොර්ෆෝ සංකේතික සහ සංකේතික අවශ්\u200dයාවක් සම්බන්ධයක් පෙන්වන්', 'sr': 'Ovaj papir predstavlja istragu u cilju proučavanja kako jezička struktura kazne utječe na kompleksnost dva najpopularnijih neuronskih modela (NLMs), BERT i GPT-2. Prvo uspoređujemo vjerojatnost na nivou rečenice računalo sa BERT-om i GPT-2 kompleksnost pokazujući da su dve metrike povezani. Osim toga, mi koristimo lingvističke karakteristike koje uključuju širok set morfosintaktičnih i sintaktičnih fenomena pokazujući kako oni doprinose da predviđaju kompleksnost dve NLG-e.', 'ms': 'This paper presents an investigation aimed at studying how the linguistic structure of a sentence affects the perplexity of two of the most popular Neural Language Models (NLMs), BERT and GPT-2.  Kita pertama-tama membandingkan kemungkinan tahap kalimat yang dikira dengan BERT dan perpleksi GPT-2 menunjukkan bahawa dua metrik berkorrelasi. In addition, we exploit linguistic features capturing a wide set of morpho-syntactic and syntactic phenomena showing how they contribute to predict the perplexity of the two NLMs.', 'so': 'Qoraalkan waxaa soo saara baaritaan oo lagu talo galay barashada siduu dhismaha luqada ku qoran saameyn ugu yeelan karo dhibaatada labada noocyada ugu badan ee afka Neural (NLMs), BERT iyo GPT-2. Marka ugu horeysa waxaynu isbarbardhignaa heerka ereyga oo ku saabsan BERT iyo dhibaatada GPT-2, waxaana muujinaynaa in labada metric ay isku xiran yihiin. Intaas waxaa dheer, waxaynu isticmaalnaa xarumaha luuqadaha oo aad u badan oo la qabsaday munaafiqiinta iyo issyntactika ah oo tusinaya sida ay ugu faa’iidaysan in ay ka hor dhigto dhibaatada labada xafiiska ah ee NLMs.', 'ro': 'Lucrarea prezintă o investigație care vizează studierea modului în care structura lingvistică a unei propoziții afectează perplexitatea a două dintre cele mai populare modele de limbaj neural (NLM), BERT și GPT-2. Comparăm mai întâi probabilitatea de nivel de propoziție calculată cu BERT și perplexitatea GPT-2 arătând că cele două măsurători sunt corelate. În plus, exploatăm caracteristicile lingvistice captând un set larg de fenomene morfo-sintactice și sintactice care arată modul în care acestea contribuie la prezicerea perplexității celor două NLM.', 'ta': 'இந்த தாள் ஒரு வாக்கியத்தின் மொழி வடிவமைப்பு எப்படி பாதிக்க வேண்டும் என்பதை அறிவிக்கும் ஒரு விசாரத்தை குறிப்பிடுகிறது அதிகப்பெரிய நெயுரல் மொழி மோட நாம் முதலில் வாக்கு -மட்டத்தை BERT என்று ஒப்பிடுகிறோம் மற்றும் GPT-2 என்ற பிரச்சனையை காண்பிக்கிறோம். மேலும், நாம் மொழி குணங்களை பயன்படுத்துகிறோம் மோர்போ-ஒத்திசைவு மற்றும் ஒத்திசைவு பொருளை பிடித்துக் கொண்டுள்ளோம். அவை இரண்டு NLMs குழப்பத்', 'sv': 'Denna uppsats presenterar en undersökning som syftar till att studera hur den språkliga strukturen i en mening påverkar förvirringen hos två av de mest populära Neural Language Models (NLM), BERT och GPT-2. Vi jämför först sannolikheten på meningsnivå beräknad med BERT och GPT-2:s förvirring som visar att de två mätvärdena är korrelerade. Dessutom utnyttjar vi språkliga funktioner som fångar en bred uppsättning morfosyntaktiska och syntaktiska fenomen som visar hur de bidrar till att förutsäga förvirringen hos de två NLMs.', 'ur': 'یہ کاغذ ایک تحقیقات کو پیش کرتا ہے جس کا مطالبہ کرنا چاہتا ہے کہ ایک جماعت کی زبان کی ساختاری کس طرح مشهور نئورل زبان موڈل (NLMs), BERT اور GPT-2 کی مخلوقات پر اثر دیتی ہے. ہم پہلی بار BERT اور GPT-2 کی پیچیدگی کے ساتھ محاسبات کی سفارش کے سفارش کے مطابق مقایسہ کرتے ہیں کہ دو میٹریک مرتبہ ہیں۔ اور اس کے علاوہ ہم زبان شناسی فرضیات کو استعمال کرتے ہیں کہ ان دونوں NLMs کی مغلوب کی پیش سے کس طرح حاصل کرتے ہیں۔', 'uz': "Bu hujjat gapiradi, bir so'zning tillar tuzilishini o'rganishga qanday o'rganish uchun qidirish imkoniyatini beradi. Bu hujjatning eng maqsadi Neural Til Modellarining (NLMs), BERT va GPT-2 (NLMs). Biz birinchi so'zni BERT va GPT-2 haqida o'ylab, ikkita metrik bilan bog'liq deb o'ylaymiz. Ko'pchilik, biz ko'p murfo-syntactik va syntactik xususiyatlarini ko'rib turishimiz va ular ikkita NLMsning murakkablarini qanday qilishni anglatadi.", 'vi': 'Tờ giấy này đưa ra một bài điều tra nhằm học về cách kiến trúc ngôn ngữ của một câu ảnh hưởng đến sự phức tạp của hai trong các mô hình ngôn ngữ thần kinh phổ biến (NLMs), BERT và GPT-2. Trước tiên, chúng ta so s ánh mức độ đọ súng mức án được tính với BERT và sự phức tạp của GPT-2 cho thấy hai âm lượng đo được tương quan. Bên cạnh đó, chúng tôi khai thác các tính năng ngôn ngữ chụp được một loạt các hiện tượng morphine-sync và cú pháp, cho thấy cách chúng dự đoán sự phức tạp của hai NLM.', 'da': "Denne artikel præsenterer en undersøgelse, der tager sigte på at undersøge, hvordan den sproglige struktur af en sætning påvirker forvirringen af to af de mest populære Neural Language Models (NLM), BERT og GPT-2. Vi sammenligner først sandsynligheden for sætningsniveau beregnet med BERT og GPT-2's forvirring, der viser, at de to målinger er korrelerede. Derudover udnytter vi sproglige træk, der fanger et bredt sæt morfosyntaktiske og syntaktiske fænomener, der viser, hvordan de bidrager til at forudsige forvirringen af de to NLM'er.", 'nl': 'Dit artikel presenteert een onderzoek gericht op het bestuderen van hoe de taalstructuur van een zin invloed heeft op de verwarring van twee van de meest populaire Neural Language Models (NLMs), BERT en GPT-2. We vergelijken eerst de kans op zinsniveau berekend met BERT en de verwarring van de GPT-2 waaruit blijkt dat de twee metrics gecorreleerd zijn. Daarnaast gebruiken we linguïstische kenmerken die een brede reeks morfosyntactische en syntactische fenomenen vastleggen en laten zien hoe ze bijdragen aan het voorspellen van de verwarring van de twee NLMs.', 'bg': 'Настоящата статия представя изследване, което има за цел да проучи как езиковата структура на изречение влияе върху объркването на два от най-популярните модела на неврален език (НЛМ), BERT и GPT-2. Първо сравняваме вероятността от ниво изречение, изчислена с BERT и объркването на GPT-2, което показва, че двете показатели са корелационни. В допълнение, ние използваме лингвистични черти, улавящи широк набор от морфосинтактични и синтактични явления, показващи как те допринасят за предсказване на объркването на двете НЛМ.', 'hr': 'Ovaj papir predstavlja istragu u cilju proučavanja kako jezička struktura kazne utječe na kompleksnost dvije najpopularnije neuronske jezičke modele (NLMs), BERT i GPT-2. Prvo uspoređujemo vjerojatnost razine rečenica računalo sa BERT-om i GPT-2 kompleksnost pokazujući da su dvije metrike korelirane. Osim toga, koristimo jezičke karakteristike koji uključuju širok set morfosintaktičnih i sintaktičnih fenomena pokazujući kako doprinose predvidjeti kompleksnost dvije NLG-e.', 'fa': 'این کاغذ یک تحقیقات را نشان می دهد که هدف دارد مطالعه کنید که چگونه ساختار زبان یک جمله چگونه تأثیر قابلیت دو مدل زبان عصبی\u200cترین (NLMs), BERT و GPT-2 را تأثیر می\u200cدهد. ما اولین بار احتمال سطح جمله را با BERT و پیچیدگی GPT-2 مقایسه می کنیم که نشان می دهیم که دو متری مرتبط هستند. علاوه بر این، ما ویژه\u200cهای زبان\u200cشناسی را استفاده می\u200cکنیم که یک مجموعه عمومی از نمایش\u200cهای مورفو-سنتاکتیک و سنتاکتیک را می\u200cگیریم که نشان می\u200cدهند چگونه آنها برای پیش بینی کردن پیچیدگی دو NLMs کمک می\u200cکنند.', 'ko': '본고는 문장의 언어 구조가 두 가지 가장 유행하는 신경언어모델(NLM)의 복잡성, 즉 버트와 GPT-2에 어떻게 영향을 미치는지 연구하고자 한다.우리는 우선 BERT로 계산된 문장급 유사성과 GPT-2의 곤혹도를 비교한 결과 이 두 지표가 관련이 있음을 나타냈다.또한 우리는 언어 특징을 이용하여 대량의 형태-문법과 문법 현상을 포착하여 이 두 NLM의 복잡성을 예측하는 데 어떻게 도움이 되는지 보여 주었다.', 'tr': 'Bu kagyz sözleriniň lingwistiki strukturasynyň nähili meňzeşli Neural Dil Modelleriniň (NLMs), BERT we GPT-2-iň täsirini öwrenmek üçin amasyklygyny çykarýar. Ilkinji gezek BERT bilen hasaplanýan s özlem derejesini we GPT-2-iň çykyşlygyny görkez. Ayrıca, biz lingwistiki özellikleri morfosintaktik we sintaktik fenomenlerden nähili olaryň karmaşıklygyny tahmin etmek üçin nähili kömekleşip geçirýänlerini ulanýarys.', 'de': 'In diesem Beitrag wird untersucht, wie die sprachliche Struktur eines Satzes die Verwirrung von zwei der beliebtesten Neural Language Models (NLMs) beeinflusst: BERT und GPT-2. Zunächst vergleichen wir die mit BERT berechnete Wahrscheinlichkeit auf Satzlebene und die Verwirrung des GPT-2, was zeigt, dass die beiden Metriken korreliert sind. Darüber hinaus nutzen wir linguistische Merkmale, die eine breite Palette von morphosyntaktischen und syntaktischen Phänomenen erfassen und zeigen, wie sie dazu beitragen, die Verwirrung der beiden NLMs vorherzusagen.', 'af': "Hierdie papier stel 'n ondersoek voor te leer hoe die lingwisiese struktuur van 'n seting die verpligtigheid van twee van die mees populêre neurale taal Modelle (NLMs), BERT en GPT-2 afvloek. Ons vergelyk eerste die voorwerp-vlak waarskynlik bereken is met BERT en die GPT-2 se perpleksie wat vertoon dat die twee metries korrelasieer is. In addition, we exploit linguistic features capturing a wide set of morpho-syntactic and syntactic phenomena showing how they contribute to predict the perplexity of the two NLMs.", 'id': 'Kertas ini menunjukkan penyelidikan yang bertujuan untuk mempelajari bagaimana struktur bahasa kalimat mempengaruhi kekacauan dua dari Model Bahasa Neural yang paling populer (NLMs), BERT dan GPT-2. Pertama kita membandingkan kemungkinan tingkat kalimat yang dihitung dengan BERT dan perplexitas GPT-2 menunjukkan bahwa dua metrik berkorelasi. Selain itu, kita mengeksploitasi ciri-ciri bahasa yang menangkap set lebar fenomena morfo-sintaksi dan sintaksi yang menunjukkan bagaimana mereka berkontribusi untuk memprediksi kekacauan dua NLM.', 'am': 'ይህ ገጽ የቋንቋው ግንኙነት ሥርዓት ከሁለቱ በታላቁ የናውሬል ቋንቋ ሞዴል (NLMs)፣ BERT እና GPT-2 በሚያስጨንቁበት የቋንቋው ሥርዓት እንዴት የሚያደርገውን ለማስተምር የሚያስፈልገውን ምርመራ ያቀርባል፡፡ መጀመሪያ የፍርዱን ደረጃን BERT እና GPT-2 ተቃውሞ እና ሁለቱ ሜትሪክ ተገናኝነት እንደሆነ እናሳውቃለን፡፡ በተጨማሪም፣ በቋንቋ ቋንቋዎች ላይ የሞሮፎ-syntactic እና የሴንተቲክ አካባቢዎችን እንዴት እንደሚያሳዩ የሁለቱን የNLMs ውጤት እንዴት እንደሚያሳዩ እናሳውቃለን፡፡', 'hy': 'This paper presents an investigation aimed at studying how the linguistic structure of a sentence affects the perplexity of two of the most popular Neural Language Models (NLMs), BERT and GPT-2.  Սկզբում մենք համեմատում ենք նախադասության մակարդակի հավանականությունը BER-ի և GPT-2 խառնաշփոթության հետ, ցույց տալով, որ երկու մետրերը կապված են: Ավելին, մենք օգտագործում ենք լեզվաբանական առանձնահատկությունները, որոնք վերցնում են մի շարք մորֆոսինտակտիկ և սինտակտիկ երևույթներ, որոնք ցույց են տալիս, թե ինչպես են նրանք ներդրում երկու ՆԼՄ-ների խառնաշփոթյանը կանխատեսելու համար:', 'sq': 'Ky dokument paraqet një hetim që ka për qëllim të studiojë se si struktura gjuhësore e një dënimi ndikon në hutinë e dy nga modelet më të popullorë të gjuhës nervore (NLMs), BERT dhe GPT-2. Ne s ë pari krahasojmë mundësinë e nivelit të fjalës të llogaritur me BERT dhe perplexitetin e GPT-2 duke treguar se dy metrikat janë korrelacionuar. Përveç kësaj, ne shfrytëzojmë karakteristikat gjuhësore duke kapur një sërë të gjerë fenomenesh morfo-sintaktike dhe sintaktike që tregojnë se si kontribuojnë për të parashikuar perpleksinë e të dy NLMs.', 'sw': 'Makala hii inaonyesha uchunguzi wa lengo la kusoma jinsi muundo wa lugha wa hukumu unavyoathiri utata wa Modeli maarufu wa Lugha za Kiurali (NLMs), BERT na GPT-2. Kwanza tunalinganisha uwezekano wa kiwango cha hukumu kinachohesabika na BERT na tatizo la GPT-2 zinazoonyesha kuwa mitiri hizo mbili zinaunganishwa. Zaidi ya hayo, tunatumia utambulisho wa lugha unaoelezea mfululizo mkubwa wa simu za viganjani na pamoja na kuonyesha jinsi wanavyochangia kutabiri utata wa wanachama hao wawili wa NLMs.', 'az': "Bu kağıt cümlənin dil quruluğunun ən məşhur nöral Dil Modellərinin (NLMs), BERT və GPT-2-nin müxtəlifliyinə nəticə edildiyini öyrənmək məqsədilə təşkil edir. İlk dəfə BERT ilə hesablanmış cümləlik s əviyyəsini və GPT-2'nin sarsıntısını göstərdik ki, iki metrik bağlı olduğunu göstərir. Əvvəlcə, biz dil-sintaktik və sintaktik fenomenlərin çoxluğunu təsbit etmək üçün növbənöv NLMslərin müəyyən edilməsini göstərir.", 'bn': 'এই পত্রিকাটি একটি তদন্ত উপস্থাপন করেছে যার লক্ষ্য হচ্ছে কিভাবে একটি বাক্যের ভাষাগত কাঠামো কিভাবে প্রভাবিত হয়েছে তার মধ্যে সবচেয়ে জনপ্রিয় নিউরাল ভাষার মডেল আমরা প্রথমে বার্টি এবং জিপিটি-২ এর বিষয়টির সাথে এই বাক্যের স্তরের সম্ভাবনার তুলনা করি যে দুটি মেট্রিকের সংশ্লিষ্ট। এছাড়াও আমরা ভাষার বিষয়বস্তু ব্যবহার করি বিশাল মোর্ফো-সিন্ট্যাক্টিক এবং সিন্ট্যাক্টিক বিষয়বস্তুকে তুলে ধরা এবং দেখাচ্ছি যে তারা দুই এনএলএমএসে', 'bs': 'Ovaj papir predstavlja istragu u cilju proučavanja kako jezička struktura kazne utječe na kompleksnost dva najpopularnijih neuronskih modela (NLMs), BERT i GPT-2. Prvo uspoređujemo vjerojatnost na nivou rečenice računalo sa BERT i GPT-2 kompleksnost pokazujući da su dvije metrike korelirane. Osim toga, mi koristimo lingvističke karakteristike koje uključuju širok set morfosintaktičnih i sintaktičnih fenomena pokazujući kako doprinose predvidjeti kompleksnost dvije NLMs.', 'fi': 'Tämä artikkeli esittelee tutkimuksen, jonka tarkoituksena on tutkia, miten lauseen kielellinen rakenne vaikuttaa kahden suosituimman neurokielimallin, BERT:n ja GPT-2:n hämmennykseen. Vertailemme ensin BERT:llä laskettua lausetason todennäköisyyttä ja GPT-2:n hämmennystä osoittaen, että nämä kaksi mittaria korreloivat. Lisäksi hyödynnämme kielellisiä piirteitä, jotka kuvaavat laajan joukon morfosyntaktisia ja syntaktisia ilmiöitä, jotka osoittavat, miten ne vaikuttavat ennustamaan kahden NLM:n hämmennystä.', 'cs': 'Tento článek představuje šetření zaměřené na studium toho, jak jazyková struktura věty ovlivňuje zmatenost dvou nejpopulárnějších modelů neuronového jazyka (NLM), BERT a GPT-2. Nejprve porovnáme pravděpodobnost na úrovni věty vypočtenou s BERT a zmatenost GPT-2 ukazující, že obě metriky jsou korelovány. Kromě toho využíváme jazykové vlastnosti zachycující širokou sadu morfosyntaktických a syntaktických jevů, které ukazují, jak přispívají k předpovědi zmatenosti obou NLM.', 'et': 'Käesolevas töös esitatakse uurimus, mille eesmärk on uurida, kuidas lause keeleline struktuur mõjutab kahe populaarsema neurokeelemudeli (NLM) hämmeldust, BERT ja GPT-2. Esmalt võrdleme BERT-ga arvutatud lausetaseme tõenäosust ja GPT-2 segadust, mis näitab, et need kaks mõõdikut on korrelatsioonis. Lisaks kasutame keelelisi tunnuseid, mis hõlmavad laia hulka morfosüntaktilisi ja süntaktilisi nähtusi, mis näitavad, kuidas need aitavad ennustada kahe NLMi segadust.', 'ca': "Aquest article presenta una investigació mirada a estudiar com l'estructura lingüística d'una frase afecta la perplexitat de dos dels models neuronals més populars (NLMs), BERT i GPT-2. Primer comparem la probabilitat de nivell de frases calculada amb BERT i la perplexitat del GPT-2 mostrant que les dues mètriques estan correlacionades. A més, explotam característiques lingüístiques capturant un gran conjunt de fenomens morfosíntacis i sintactics mostrant com contribueixen a predir la perplexitat de les dues LNM.", 'ha': "Wannan takardan na bãyar da wani fitina wanda aka yi nufin karanta jinsi muhallin harshen maganar ta shagala ga matsayin biyu daga mafiya famous cikin Lugha na Neural (NLM), BERT da GPT-2. Kayya, muna samfane maganar-daraja da aka lissafa BERT da GPT-2 da ke nuna cewa matarikan biyu ne. Da wannan, za mu yi amfani da wasu fasafa na harshen, masu kãma ko wani abu mai cikakken morfo-syntactic da syntactic na nuna jinin su ƙara ko ko ko ko da za'a gabani ga matabbata biyu na NLM.", 'sk': 'V prispevku je predstavljena raziskava, katere namen je preučiti, kako jezikovna struktura stavka vpliva na zmedenost dveh najbolj priljubljenih modelov nevronskega jezika (NLM), BERT in GPT-2. Najprej primerjamo verjetnost stavka, izračunano z BERT, in zmedenost GPT-2, ki kaže, da sta obe meritvi korelacijski. Poleg tega izkoriščamo jezikovne značilnosti, ki zajemajo širok nabor morfo-sintaktičnih in sintaktičnih pojavov, ki kažejo, kako prispevajo k napovedovanju zmedenosti obeh NLM.', 'he': "העיתון הזה מציג חקירה שמתכוונת ללמוד איך המבנה השפתי של משפט משפיע על התבלבות של שני מהמודלים השפה הנוראלית הכי פופולריים (NLMs), BERT וג'י-פי-טי-2. ראשית אנחנו משווה את הסיכוי של רמת המשפט מחשב עם BERT ועל התבלבות של GPT-2 מראה ששני המטריקות מקושרות. In addition, we exploit linguistic features capturing a wide set of morpho-syntactic and syntactic phenomena showing how they contribute to predict the perplexity of the two NLMs.", 'bo': "ཤོག་བྱང་འདིས་དམིགས་ཡུལ་དེ་ལ་ཚིག་ཡིག་གི་སྐད་རིགས་ཀྱི་བཟོ་བཅོས་དེ་ག་དེ་སྣང་ཚུལ་ལས་ཕན་ཚུན་བརྗོད་ཡོད། We first compare the sentence-level likelihood computed with BERT and the GPT-2's perplexity showing that the two metrics are correlated. ད་དུང་། ང་ཚོས་སྐད་ཡིག", 'jv': 'Gambar iki bakal ngewehhita karo akeh nyong nggawe ujaran piye isakno ning sampeyan anyar tentang tanggal idiwang karo hal pangan karo duruh populer sing model Neral Language Modes (NLM), BERT karo GNU-2. Awak dhéwé ngolesi perusahaan kelas perangkat sabanjuré karo BERT karo perusahaan GST-2 kuwi nggawe iki metar sing diranggawe Nambah, awak dhéwé luwih-luwih éntuk akeh perusahaan anyar tentang mruput karo hal-sinaksi lan seneng pisan seneng pisan kawit dhéwé iso nguasai perusahaan karo hal iki NLM.'}
{'en': 'What BERTs and GPTs know about your brand? Probing contextual language models for affect associations BERT s and  GPT s know about your brand? Probing contextual language models for affect associations', 'ar': 'ما الذي تعرفه BERTs و GPTs عن علامتك التجارية؟ استقصاء نماذج اللغة السياقية للجمعيات المؤثرة', 'pt': 'O que BERTs e GPTs sabem sobre sua marca? Provando modelos de linguagem contextual para associações de afeto', 'fr': "Que savent les BERT et les GPT de votre marque\xa0? Recherche d'associations d'effets dans des modèles de langage contextuels", 'es': '¿Qué saben los BERT y los GPT sobre su marca? Sondeo de modelos de lenguaje contextual para asociaciones de afectos', 'zh': 'BERT与GPT知品牌多少? 探其上下文语', 'ja': 'あなたのブランドについてBERTとGPTは何を知っていますか？影響関連付けのための文脈言語モデルの調査', 'hi': 'BERTs और GPTs आपके ब्रांड के बारे में क्या जानते हैं? प्रभावित संघों के लिए प्रासंगिक भाषा मॉडल की जांच', 'ru': 'Что BERT и GPT знают о вашем бренде? Изучение контекстных языковых моделей для ассоциаций affect', 'ga': 'Cad atá ar eolas ag BERTs agus GPTanna faoi do bhranda? Samhlacha teanga comhthéacsúla a scrúdú le haghaidh comhlachais tionchair', 'ka': 'კაკგჲ ჱნაწრ ბვპრ თ GPT ჱა ბპანე? კონტექსტური ენის მოდელების შემოწმება აზოციაციებისთვის', 'el': 'Τι ξέρουν οι BERT και οι GPT για την μάρκα σας; Έλεγχος γλωσσικών μοντέλων περιβάλλοντος για συσχετίσεις επιδράσεων', 'hu': 'Mit tudnak a BERT 챕s a GPT-k az 횜n m찼rk찼j찼r처l? Kontextu찼lis nyelvi modellek vizsg찼lata a hat찼ssal kapcsolatos asszoci찼ci처khoz', 'it': 'Cosa sanno i BERT e i GPT del tuo marchio? Esame di modelli linguistici contestuali per associazioni di effetti', 'lt': 'Ką BERT ir GPT žino apie tavo prekės ženklą? Įvairių asociacijų kontekstinių kalbų modelių bandymas', 'mk': 'What BERTs and GPTs know about your brand?  Истражување на контекстни јазички модели за влијание врз асоцијациите', 'kk': 'Брэндіңіз туралы BERTs мен GPT не біледі? Тіркемдерге әсер ету үшін контекстуалды тіл үлгілерін тексеру', 'mt': 'X’jafu l-BERTs u l-GPTs dwar il-marka tiegħek? L-ittestjar ta’ mudelli lingwistiċi kuntestwali għall-assoċjazzjonijiet li jaffettwaw', 'ml': 'നിങ്ങളുടെ ബെര്\u200dട്ടിനെക്കുറിച്ചും ജിപിടിസിനെയും അറിയാമോ? സങ്കീര്\u200dണങ്ങള്\u200dക്ക് വേണ്ടി നിലവിലുള്ള ഭാഷ മോഡലുകള്\u200d പരിശോധിക്കുന്നു', 'ms': 'What BERTs and GPTs know about your brand?  Probing contextual language models for affect associations', 'mn': 'Брэндийн тухай BERTs болон GPT нь юу мэддэг вэ? Холбоонуудын нөлөөлдөг орчин үеийн хэл загваруудыг шалгах', 'no': 'Kva vet BERTS og GPT om merket ditt? Prøver kontekst språk- modeller for å påvirka tilknytingar', 'pl': 'Co BERT i GPT wiedzą o Twojej marki? Badanie kontekstowych modeli językowych dla skojarzeń dotyczących efektów', 'ro': 'Ce știu BERT și GPT despre marca dvs.? Analizarea modelelor lingvistice contextuale pentru asocierile afectelor', 'sr': 'Šta BERTS i GPT znaju o tvojoj brandi? Probanje kontekstualnih jezičkih modela za utjecanje na asocijacije', 'si': 'ඔයාගේ බ්\u200dරෑන්ඩ් ගැන BERTs සහ GPT මොනවද දන්නේ? සම්බන්ධතාවට පරීක්ෂා කරන්න සම්බන්ධ භාෂා මොඩේල්ස්', 'ta': 'உங்கள் கிராண்ட் பற்றி பெர்ட்ஸ் மற்றும் GPT என்ன தெரியும்? இணைப்புகளை பாதிக்கும் தற்போதைய மொழி மாதிரி மாதிரிகளை சோதிக்கிறது', 'sv': 'Vad BERT och GPT vet om ditt varumärke? Undersöka kontextuella språkmodeller för påverkansammanslutningar', 'so': 'Maxay taqaan BERT iyo GPT oo ku saabsan laantaada? Probing contextual language models for affect associations', 'ur': 'BERTS اور GPT آپ کے برند کے بارے میں کیا جانتے ہیں؟ متوسط زبان موڈل کی تحقیق کی جاتی ہے', 'uz': '@ info Name', 'vi': 'Nhân viên cấp cứu và cấp cứu biết gì về thương hiệu của anh? Trình bày các mô- đun ngôn ngữ ngữ ngữ ngữ ngữ ngữ ngữ ngữ ảnh hưởng', 'bg': 'Какво знаят за вашата марка? Проучване на контекстуални езикови модели за асоциации на ефекта', 'da': "Hvad ved BERT'er og GPT'er om dit brand? Undersøgelse af kontekstuelle sprogmodeller for påvirkningsassociationer", 'nl': "Wat weten BERT's en GPT's over uw merk? Contextuele taalmodellen testen op affectassociaties", 'hr': 'Što BERTS i GPT znaju o vašem znaku? Testiranje kontekstualnih jezičkih modela za utjecanje na udruženja', 'de': 'Was wissen BERTs und GPTs über Ihre Marke? Untersuchung kontextueller Sprachmodelle für Affektassoziationen', 'fa': 'برت ها و جي پي تي ها درباره برند تو چي ميدونن؟ تحقیق مدلهای زبان متوسط برای تأثیر ارتباطات', 'id': 'What BERTs and GPTs know about your brand?  Mencoba model bahasa kontekstual untuk pengaruh asosiasi', 'sw': 'BERT na GPT wanajua nini kuhusu alama zako? Kujaribu mifano ya lugha za kisasa kwa ajili ya kuathiri mashirika', 'ko': 'BERTs와 GPT는 브랜드에 대해 얼마나 알고 있습니까?감정과 관련된 어경 언어 모델을 탐구하다', 'tr': 'BERTS we GPT oglanlaryňyz hakynda nähili bilýärler? Äplikeýşenler üçin metin dili nusgalary barlaň', 'sq': 'Çfarë dinë BERTs dhe GPT për markan tënde? Probimi i modeleve kontekstuale të gjuhës për ndikimin e shoqatave', 'am': 'BERS እና GPT ስለ ቅርንጫፎችህ ምን ያውቃሉ? የአሁኑን ቋንቋ ሞዴሌዎች ለመጠቀም', 'af': 'Wat weet BERTS en GPT oor jou brand? Probeer contextual taal modele vir afvloek toesamenskappe', 'hy': 'Ի՞նչ գիտեն BER-ները և GPT-ները ձեր բրենդի մասին: Կոնտեքստային լեզվի մոդելների փորձը կապվածությունների ազդեցության համար', 'bn': 'তোমার ব্র্যান্ড সম্পর্কে বের্ট আর জিপিটিস কি জানে? প্রভাবিত সম্প্রদায়ের জন্য বর্তমান ভাষার মডেল প্রস্তুত করা হচ্ছে', 'az': 'BERTS v톛 GPT sizin markan캼z haqq캼nda n톛 bilirl톛r? 쿮lif톛l톛r 칲칞칲n m칲xt톛lif dil modell톛rini s캼namaq', 'bs': 'Šta BERTS i GPT znaju o tvojoj brandi? Testiranje kontekstualnih jezičkih modela za utjecanje na asocijacije', 'ca': 'Què saben BERTs i GPT sobre la vostra marca? Probar models de llenguatge contextualper afectar associacions', 'fi': 'Mitä BERT ja GPT tietävät brändistäsi? Vaikutussuhteiden kontekstuaalisten kielimallien kartoittaminen', 'et': 'Mida BERT ja GPT teavad teie brändi kohta? Kontekstiliste keelemudelite uurimine mõju seoste jaoks', 'cs': 'Co BERT a GPT vědí o vaší značce? Testování kontextových jazykových modelů pro asociace efektů', 'jv': 'Ngopo BERT karo Gpta sing ngerti barang tho ? label', 'ha': 'QUnicodeControlCharacterMenu Ana jarraba misalin harshen da ke cikin yanzu wa masu yin amfani da associations', 'sk': 'Kaj BERT in GPT vedo o vaši blagovni znamki? Prodiranje kontekstualnih jezikovnih modelov za vplivne povezave', 'he': 'מה BERTs וג.פי.טי יודעים על הסימן שלך? ניסוי דוגמני שפה קונטקסטיים לאיגוד השפעה', 'bo': 'ཁྱོད་ཀྱི་མིང་རྟགས་སྐོར་གྱི་BERTs་དང་GPTs་ག་རེ་ཤེས་ཡིན་ནམ། སྦྲེལ་མཐུད་ལ་བརྗོད་པའི་contextual language models'}
{'en': 'Investigating brand perception is fundamental to  marketing strategies . In this regard,  brand image , defined by a set of attributes (Aaker, 1997), is recognized as a key element in indicating how a brand is perceived by various stakeholders such as consumers and competitors. Traditional  approaches  (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient. In the era of  digital marketing , both brand managers and consumers engage with a vast amount of  digital marketing content . The exponential growth of  digital content  has propelled the emergence of pre-trained language models such as BERT and GPT as essential tools in solving myriads of challenges with textual data. This paper seeks to investigate the extent of brand perceptions (i.e., brand and image attribute associations) these  language models  encode. We believe that any kind of bias for a brand and attribute pair may influence customer-centric downstream tasks such as  recommender systems ,  sentiment analysis , and  question-answering , e.g., suggesting a specific brand consistently when queried for innovative products. We use  synthetic data  and real-life data and report comparison results for five contextual LMs, viz. BERT, RoBERTa, DistilBERT, ALBERT and BART.', 'ar': 'يعد التحقيق في تصور العلامة التجارية أمرًا أساسيًا لاستراتيجيات التسويق. في هذا الصدد ، يتم التعرف على صورة العلامة التجارية ، التي تحددها مجموعة من السمات (Aaker ، 1997) ، كعنصر أساسي في الإشارة إلى الكيفية التي ينظر بها إلى العلامة التجارية من قبل مختلف أصحاب المصلحة مثل المستهلكين والمنافسين. الأساليب التقليدية (على سبيل المثال ، الاستطلاعات) لمراقبة تصورات العلامة التجارية تستغرق وقتًا طويلاً وغير فعالة. في عصر التسويق الرقمي ، يتفاعل كل من مديري العلامات التجارية والمستهلكين مع قدر هائل من محتوى التسويق الرقمي. دفع النمو الهائل للمحتوى الرقمي إلى ظهور نماذج لغوية مُدرَّبة مسبقًا مثل BERT و GPT كأدوات أساسية في حل عدد لا يحصى من التحديات باستخدام البيانات النصية. تسعى هذه الورقة إلى التحقيق في مدى تصورات العلامة التجارية (أي ارتباطات سمات العلامة التجارية والصورة) ترميز نماذج اللغة هذه. نعتقد أن أي نوع من التحيز للعلامة التجارية وزوج السمات قد يؤثر على المهام النهائية التي تتمحور حول العميل مثل أنظمة التوصية ، وتحليل المشاعر ، والإجابة على الأسئلة ، على سبيل المثال ، اقتراح علامة تجارية معينة باستمرار عند الاستعلام عن منتجات مبتكرة. نحن نستخدم البيانات التركيبية وبيانات الحياة الواقعية ونبلغ عن نتائج المقارنة لخمسة LMs سياقية ، بمعنى. بيرت وروبيرتا وديستيلبيرت وألبيرت وبارت.', 'fr': "L'étude de la perception de la marque est essentielle aux stratégies marketing. À cet égard, l'image de marque, définie par un ensemble d'attributs (Aaker, 1997), est reconnue comme un élément clé pour indiquer comment une marque est perçue par diverses parties prenantes telles que les consommateurs et les concurrents. Les approches traditionnelles (par exemple, les enquêtes) pour surveiller les perceptions de la marque sont chronophages et inefficaces. À l'ère du marketing numérique, tant les responsables de marque que les consommateurs interagissent avec une grande quantité de contenu marketing numérique. La croissance exponentielle du contenu numérique a favorisé l'émergence de modèles linguistiques préformés tels que BERT et GPT en tant qu'outils essentiels pour résoudre une myriade de défis liés aux données textuelles. Cet article cherche à étudier l'étendue des perceptions de la marque (c'est-à-dire les associations d'attributs de marque et d'image) codées par ces modèles linguistiques. Nous pensons que tout type de biais pour une paire de marques et d'attributs peut influencer les tâches en aval centrées sur le client, telles que les systèmes de recommandation, l'analyse des sentiments et les réponses aux questions, par exemple, suggérer une marque spécifique de manière cohérente lorsqu'on demande des produits innovants. Nous utilisons des données synthétiques et des données réelles et nous rapportons des résultats de comparaison pour cinq LM contextuels, à savoir BERT, Roberta, DistilBERT, ALBERT et BART.", 'es': 'Investigar la percepción de marca es fundamental para las estrategias de marketing En este sentido, la imagen de marca, definida por un conjunto de atributos (Aaker, 1997), se reconoce como un elemento clave para indicar cómo una marca es percibida por varias partes interesadas, como consumidores y competidores. Los enfoques tradicionales (por ejemplo, encuestas) para monitorear las percepciones de la marca requieren mucho tiempo y son ineficientes. En la era del marketing digital, tanto los gerentes de marca como los consumidores interactúan con una gran cantidad de contenido de marketing digital. El crecimiento exponencial del contenido digital ha impulsado el surgimiento de modelos lingüísticos previamente entrenados, como BERT y GPT, como herramientas esenciales para resolver miles de desafíos con datos textuales. Este artículo busca investigar el alcance de las percepciones de marca (es decir, asociaciones de atributos de marca e imagen) que codifican estos modelos de lenguaje. Creemos que cualquier tipo de sesgo para una marca y un par de atributos puede influir en las tareas posteriores centradas en el cliente, como los sistemas de recomendación, el análisis de opiniones y la respuesta a preguntas, por ejemplo, sugerir una marca específica de forma coherente cuando se le solicite productos innovadores. Utilizamos datos sintéticos y datos de la vida real e informamos los resultados de la comparación de cinco LM contextuales, a saber, BERT, ROBerta, Distilbert, ALBERT y BART.', 'pt': 'Investigar a percepção da marca é fundamental para as estratégias de marketing. Nesse sentido, a imagem da marca, definida por um conjunto de atributos (Aaker, 1997), é reconhecida como um elemento chave para indicar como uma marca é percebida por diversos stakeholders, como consumidores e concorrentes. As abordagens tradicionais (por exemplo, pesquisas) para monitorar as percepções da marca são demoradas e ineficientes. Na era do marketing digital, tanto os gerentes de marca quanto os consumidores se envolvem com uma grande quantidade de conteúdo de marketing digital. O crescimento exponencial do conteúdo digital impulsionou o surgimento de modelos de linguagem pré-treinados, como BERT e GPT, como ferramentas essenciais na resolução de inúmeros desafios com dados textuais. Este artigo procura investigar a extensão das percepções de marca (ou seja, associações de atributos de marca e imagem) que esses modelos de linguagem codificam. Acreditamos que qualquer tipo de viés para um par de marca e atributo pode influenciar tarefas downstream centradas no cliente, como sistemas de recomendação, análise de sentimentos e respostas a perguntas, por exemplo, sugerir uma marca específica de forma consistente quando consultada por produtos inovadores. Usamos dados sintéticos e dados da vida real e relatamos resultados de comparação para cinco LMs contextuais, viz. BERT, RoBERTa, DistilBERT, ALBERT e BART.', 'zh': '勘品牌认知度者,营销策之基也。 此其类义之品牌形象(Aaker,1997年)以为明消费者竞争对手之利相关者视品牌之关键因素也。 监控品牌识旧法(如勘)既耗时又低效。 当数营销时,品牌经理消费者皆与大数营销。 数长推先训之言(如BERTGPT)之见,以为解文数挑战之具。 本文旨在研究此语编码品牌感知(即品牌与图像属性相关)也。 臣愚以为品牌性之偏见,或以客户为心,如荐系统,情析问答,询创物之始,始终如一特定品牌。 合数与今实数,并告五上下文LM比较结果,即BERT,RoBERTa,DistilBERT,ALBERTBART。', 'ja': 'ブランド認識を調査することは、マーケティング戦略の基本です。 この点で、一連の属性によって定義されるブランドイメージ（ Aaker、1997 ）は、消費者や競合他社などのさまざまな利害関係者がブランドをどのように認識しているかを示すための重要な要素として認識されています。 ブランド認識を監視するための従来のアプローチ（調査など）は、時間がかかり、非効率的です。 デジタルマーケティングの時代には、ブランドマネージャーと消費者の両方が膨大な量のデジタルマーケティングコンテンツに関与しています。 デジタルコンテンツの指数関数的な成長は、テキストデータで数多くの課題を解決するための不可欠なツールとして、BERTやGPTなどの事前にトレーニングされた言語モデルの出現を促進しました。 この論文は、これらの言語モデルがコードするブランド認識（すなわち、ブランドとイメージの属性の関連）の程度を調査しようとしている。 ブランドと属性のペアに対するあらゆる種類のバイアスは、顧客中心のダウンストリームタスクに影響を与える可能性があると考えています。たとえば、推奨者システム、感情分析、質問への回答などです。たとえば、革新的な製品を求められたときに、特定のブランドを一貫して提案するなどです。 合成データと実際のデータを使用し、5つのコンテキストLM、すなわち BERT, RoBERTa, DistilBERT, ALBERT and BART.', 'hi': 'ब्रांड धारणा की जांच विपणन रणनीतियों के लिए मौलिक है। इस संबंध में, ब्रांड छवि, विशेषताओं के एक सेट (Aaker, 1997) द्वारा परिभाषित, यह इंगित करने में एक महत्वपूर्ण तत्व के रूप में पहचाना जाता है कि उपभोक्ताओं और प्रतियोगियों जैसे विभिन्न हितधारकों द्वारा एक ब्रांड को कैसे माना जाता है। ब्रांड धारणाओं की निगरानी के लिए पारंपरिक दृष्टिकोण (उदाहरण के लिए, सर्वेक्षण) समय लेने वाले और अक्षम हैं। डिजिटल मार्केटिंग के युग में, ब्रांड प्रबंधक और उपभोक्ता दोनों डिजिटल मार्केटिंग सामग्री की एक विशाल राशि के साथ संलग्न होते हैं। डिजिटल सामग्री के घातीय विकास ने पूर्व-प्रशिक्षित भाषा मॉडल जैसे कि BERT और GPT के उद्भव को पाठ्य डेटा के साथ चुनौतियों के असंख्य को हल करने में आवश्यक उपकरण के रूप में प्रेरित किया है। यह पेपर ब्रांड धारणाओं (यानी, ब्रांड और छवि विशेषता संघों) की सीमा की जांच करना चाहता है, ये भाषा मॉडल एन्कोड करते हैं। हमारा मानना है कि एक ब्रांड और विशेषता जोड़ी के लिए किसी भी प्रकार का पूर्वाग्रह ग्राहक-केंद्रित डाउनस्ट्रीम कार्यों को प्रभावित कर सकता है जैसे कि सिफारिशकर्ता सिस्टम, भावना विश्लेषण, और प्रश्न-उत्तर देना, उदाहरण के लिए, अभिनव उत्पादों के लिए पूछताछ किए जाने पर लगातार एक विशिष्ट ब्रांड का सुझाव देना। हम सिंथेटिक डेटा और वास्तविक जीवन डेटा का उपयोग करते हैं और पांच प्रासंगिक एलएम के लिए तुलना परिणामों की रिपोर्ट करते हैं, जैसे कि BERT, RoBERTa, DistilBERT, ALBERT और BART।', 'ru': 'Изучение восприятия бренда имеет основополагающее значение для маркетинговых стратегий. В этом отношении имидж бренда, определяемый набором атрибутов (Aaker, 1997), признается в качестве ключевого элемента, указывающего на то, как бренд воспринимается различными заинтересованными сторонами, такими как потребители и конкуренты. Традиционные подходы (например, опросы) к мониторингу восприятия бренда занимают много времени и неэффективны. В эпоху цифрового маркетинга как бренд-менеджеры, так и потребители взаимодействуют с огромным количеством цифрового маркетингового контента. Экспоненциальный рост цифрового контента привел к появлению предварительно обученных языковых моделей, таких как BERT и GPT, в качестве важных инструментов в решении множества проблем с текстовыми данными. В настоящем документе предпринята попытка исследовать степень восприятия бренда (т.е. ассоциации атрибутов бренда и образа), кодируемые этими языковыми моделями. Мы считаем, что любая предвзятость в отношении пары брендов и атрибутов может повлиять на выполнение клиентоориентированных задач, таких как системы рекомендаций, анализ настроений и ответы на вопросы, например, предлагая конкретный бренд последовательно при запросе инновационных продуктов. Мы используем синтетические данные и данные из реальной жизни и сообщаем результаты сравнения для пяти контекстуальных LM, а именно. BERT, RoBERTa, DistilBERT, ALBERT and Bart.', 'ga': 'Tá iniúchadh braistint branda bunúsach do straitéisí margaíochta. Maidir leis seo, aithnítear íomhá branda, arna sainmhíniú ag sraith tréithe (Aaker, 1997), mar phríomhghné chun an dearcadh atá ag geallsealbhóirí éagsúla ar nós tomhaltóirí agus iomaitheoirí a chur in iúl. Tógann cur chuige traidisiúnta (m.sh. suirbhéanna) chun monatóireacht a dhéanamh ar bhraistintí branda am-íditheach agus neamhéifeachtúil. I ré na margaíochta digití, téann bainisteoirí branda agus tomhaltóirí araon i ngleic le méid ollmhór ábhar margaíochta digiteach. Spreag fás easpónantúil an ábhair dhigitigh teacht chun cinn samhlacha teanga réamhoilte mar BERT agus GPT mar uirlisí riachtanacha chun an iliomad dúshlán a réiteach le sonraí téacsúla. Féachann an páipéar seo le hiniúchadh a dhéanamh ar mhéid braistintí branda (i.e., cumainn tréithe branda agus íomhá) a ionchódaíonn na samhlacha teanga seo. Creidimid go bhféadfadh tionchar a bheith ag claonadh de chineál ar bith do phéire branda agus tréithe ar thascanna iartheachtach atá dírithe ar an gcustaiméir ar nós córais mholtóra, anailís sentiment, agus freagra ceisteanna, m.sh., branda sonrach a mholadh go comhsheasmhach nuair a chuirtear ceist faoi maidir le táirgí nuálacha. Bainimid úsáid as sonraí sintéiseacha agus sonraí fíorshaoil agus tuairiscímid torthaí comparáide le haghaidh cúig LM comhthéacsúla, viz. BERT, RoBERTa, DistilBERT, ALBERT agus BART.', 'ka': 'ბრენდის აღმოჩენების ინსტიგურაცია მარკეტინგის სტრატეგიებისთვის ფუნდამეტურია. ამ შემთხვევაში, ბრენდის გამოსახულება, რომელიც ატრიბუტებების ნაწილი (Aaker, 1997) განსახულებულია, როგორც კლავის ელემენტი იყოს, როგორც განსხვავებული ინტერესოტების გამოსახულება, როგორც მომხ ტრადიციონალური დახმარებები (მაგალითად, შემოწმებები) ბრენდის აღმოწმებების მონარჩენისთვის არის დროის გამოყენება და არაფექციელი. დიზიტალური მარკეტინგის ენერაში, რომელიც ბრენდის მენეჯერი და მომხმარებელი უფრო დიზიტალური მარკეტინგის შემდგომარებით დაკავშირდება. დიზიტალური ინტერნეტის ექსპონენციალური პროგენციალური პროგენციალური პროგენციაში, როგორც BERT და GPT იყო მნიშვნელოვანი ხელსაწყოები ტექსტულური მონაცემებით გამოწვებას მირიაცი ეს დოკუმენტი უნდა გამოვაკეთოთ ბრენდის აღმოჩენების განსაზღვრება (მაგალითად, ბრენდი და ატრიბუტის აღმოჩენების აღმოჩენები) ამ ენის მოდელების კოდის. ჩვენ ვფიქრობთ, რომ ყველაფერი ბრენდის და ატრიბუტის ზოგის წარმოდგენების შესაძლებელია კოლენტირების ცენტრიკური კოლენტირების შესახებ, როგორც მუშაობელი სისტემები, სენტიმენტის ანალიზი, და კითხვის გასაგებლა ჩვენ გამოყენებთ სინტეტიკური მონაცემები და რეალური ცხოვრების მონაცემები და გამოყენებთ მონაცემების შემთხვევაში ხუთი კონტექსტური LMs, viz. ბვპრ, პჲბვპრა, ეთჟრთლბვპრ, ალბვპრ თ ბაპრ.', 'el': 'Η διερεύνηση της αντίληψης της μάρκας είναι θεμελιώδης για τις στρατηγικές μάρκετινγκ. Από την άποψη αυτή, η εικόνα της μάρκας, η οποία ορίζεται από ένα σύνολο χαρακτηριστικών (Aaker, 1997), αναγνωρίζεται ως βασικό στοιχείο για την ένδειξη του τρόπου με τον οποίο μια μάρκα αντιλαμβάνεται διάφορα ενδιαφερόμενα μέρη, όπως οι καταναλωτές και οι ανταγωνιστές. Οι παραδοσιακές προσεγγίσεις (π.χ. έρευνες) για την παρακολούθηση των αντιλήψεων της μάρκας είναι χρονοβόρες και αναποτελεσματικές. Στην εποχή του ψηφιακού μάρκετινγκ, τόσο οι διαχειριστές εμπορικών σημάτων όσο και οι καταναλωτές ασχολούνται με μια τεράστια ποσότητα ψηφιακού περιεχομένου μάρκετινγκ. Η εκθετική ανάπτυξη του ψηφιακού περιεχομένου έχει οδηγήσει την εμφάνιση προ-εκπαιδευμένων γλωσσικών μοντέλων όπως και ως απαραίτητα εργαλεία για την επίλυση μυριάδων προκλήσεων με τα δεδομένα κειμένου. Η παρούσα εργασία επιδιώκει να διερευνήσει την έκταση των αντιλήψεων εμπορικών σημάτων (δηλ. συσχετισμών χαρακτηριστικών μάρκας και εικόνας) που κωδικοποιούν αυτά τα γλωσσικά μοντέλα. Πιστεύουμε ότι κάθε είδους προκατάληψη για ένα ζευγάρι εμπορικών σημάτων και χαρακτηριστικών μπορεί να επηρεάσει τις επόμενες εργασίες που επικεντρώνονται στον πελάτη, όπως συστήματα συστάσεων, ανάλυση συναισθημάτων και απάντηση σε ερωτήσεις, π.χ. προτείνοντας μια συγκεκριμένη μάρκα με συνέπεια όταν ερωτηθείτε για καινοτόμα προϊόντα. Χρησιμοποιούμε συνθετικά δεδομένα και δεδομένα πραγματικής ζωής και αναφέρουμε αποτελέσματα σύγκρισης για πέντε συναφή LM, δηλαδή. BERT, ROBERTA, DistilBERT, ALBERT και BART.', 'hu': 'A márkaészlelés vizsgálata alapvető fontosságú a marketing stratégiák szempontjából. Ebben a tekintetben a különböző érdekelt felek, például a fogyasztók és versenytársak által meghatározott márkakép kulcsfontosságú elemként ismerik el a márkát (Aaker, 1997). A márkaészlelések figyelemmel kísérésére szolgáló hagyományos megközelítések (például felmérések) időigényesek és nem hatékonyak. A digitális marketing korszakában mind a márka menedzserei, mind a fogyasztók hatalmas mennyiségű digitális marketing tartalommal foglalkoznak. A digitális tartalom exponenciális növekedése elősegítette az előre képzett nyelvi modellek megjelenését, mint például a BERT és a GPT, mint alapvető eszközök a szöveges adatokkal kapcsolatos kihívások milliárdjainak megoldásához. Ez a tanulmány arra törekszik, hogy megvizsgálja a márkaészlelések mértékét (azaz a márka és az arculat attribútumok asszociációit), amelyeket ezek a nyelvi modellek kódolnak. Meggyőződésünk, hogy a márka és attribútumpár bármilyen elfogultsága befolyásolhatja az ügyfélközpontú downstream feladatokat, mint például ajánlói rendszerek, hangulatelemzés és kérdésválasz, például egy konkrét márka következetes javaslatát, amikor innovatív termékeket kérdeznek. Szintetikus adatokat és valós adatokat használunk, és összehasonlítási eredményeket jelentünk öt kontextuális LM-re, azaz. BERT, RoBERTa, DistilBERT, ALBERT és BART.', 'kk': 'Бранд ойлауын зерттеу маркетинг стратегиясына негізгі. Бұл үшін бренд кескіні, атрибуттар жиынынан анықталған (Aaker, 1997), қолданушылар мен конкурсорлар секілді, бренд қалай қалай қалады дегенді көрсету үшін көпшілік элементі ретінде анықталады. Брендің ойымдарын қарау үшін дәстүрлі арқылы (мысалы, зерттеулері) уақытты пайдалану және жеткілікті емес. Дижиталық маркетинг кезінде бренд менеджерлері мен пайдаланушылар көп бөлшекті дижиталық маркетинг мазмұнымен қатынайды. Дижиталық мазмұның экспоненциялық өсімі, BERT және GPT секілді алдын- оқылған тіл үлгілерін мәтіндік деректермен мәселелерді шешу үшін мәселелердің мириадаларын шешу құралы ретінде өзгерт Бұл қағаз бұл тіл үлгілерінің кодтамасын (яғни бренд және кескінің атрибуттары қосымшаларының) шектеу үшін іздейді. Біз бренд мен атрибуттардың кез бір түрлі бөлшектері, мысалы, инновациялық продукттарды сұрау үшін, клиенттердің ортасындағы төменгі тапсырмаларына, көңіл анализ және сұрақтар жауап беру үшін, тұрақтық брендің көңіл-күй Біз синтетикалық деректер мен шын өмір деректерін және бес контекстік LMs, т. б. BERT, RoBERTa, DistilBERT, ALBERT және BART.', 'it': "Investigare sulla percezione del marchio è fondamentale per le strategie di marketing. A questo proposito, l'immagine del marchio, definita da una serie di attributi (Aaker, 1997), è riconosciuta come elemento chiave per indicare come un marchio è percepito da vari stakeholder come consumatori e concorrenti. Gli approcci tradizionali (ad esempio, indagini) per monitorare la percezione del marchio richiedono tempo e inefficienti. Nell'era del marketing digitale, sia i brand manager che i consumatori si impegnano con una vasta quantità di contenuti di marketing digitale. La crescita esponenziale dei contenuti digitali ha spinto l'emergere di modelli linguistici pre-formati come BERT e GPT come strumenti essenziali per risolvere miriadi di sfide con i dati testuali. Questo articolo cerca di indagare l'estensione delle percezioni del marchio (cioè associazioni di attributi di marca e immagine) codificate da questi modelli linguistici. Crediamo che qualsiasi tipo di bias per una coppia di marchi e attributi possa influenzare attività downstream incentrate sul cliente come sistemi di raccomandazione, analisi del sentiment e risposta alle domande, ad esempio suggerendo un marchio specifico in modo coerente quando richiesto per prodotti innovativi. Utilizziamo dati sintetici e dati reali e riportiamo risultati di confronto per cinque LM contestuali, vale a dire. BERT, RoBERTa, DistilBERT, ALBERT e BART.", 'lt': 'Investigating brand perception is fundamental to marketing strategies.  In this regard, brand image, defined by a set of attributes (Aaker, 1997), is recognized as a key element in indicating how a brand is perceived by various stakeholders such as consumers and competitors.  Tradiciniai metodai (pvz., tyrimai), kuriais siekiama stebėti prekių ženklo suvokimą, užtrukdo daug laiko ir neveiksmingi. Skaitmeninės prekybos epokoje tiek prekių ženklų valdytojai, tiek vartotojai užsiima didele skaitmeninės prekybos apimtimi. Skaitmeninio turinio eksponencinis augimas paskatino parengtus kalbų modelius, pavyzdžiui, BERT ir GPT, kaip esmines priemones daugeliui tekstinių duomenų problemų spręsti. Šiame dokumente siekiama i štirti prekių ženklo suvokimo mastą (t. y. prekių ženklo ir vaizdo požymių asociacijas), kurį koduoja ši e kalbos modeliai. Manome, kad bet koks sąžiningas prekių ženklo ir požymių poros pobūdis gali turėti įtakos vartotojų centrinėms tolesnėms užduotims, pvz., rekomendacinėms sistemoms, jausmų analizei ir klausimų atsakymui, pvz., nuosekliai siūlant konkretų prekių ženklą, kai prašoma naujoviškų produktų. Naudojame sintetinius duomenis ir realiojo gyvenimo duomenis ir pateikiame palyginimo rezultatus penkioms kontekstinėms LM, t. y. BERT, RoBERTa, DistilBERT, ALBERT and BART.', 'mk': 'Истражувањето на перцепцијата на маркетингот е фундаментално за маркетинг стратегиите. Во врска со ова, сликата на брендот, дефинирана од множина атрибути (Акер, 1997), се признава како клучен елемент во индикацијата на тоа како брендот е перцепиран од различни интересни страни како што се потрошувачите и конкурентите. Traditional approaches (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient.  In the era of digital marketing, both brand managers and consumers engage with a vast amount of digital marketing content.  The exponential growth of digital content has propelled the emergence of pre-trained language models such as BERT and GPT as essential tools in solving myriads of challenges with textual data.  Овој весник има за цел да го испита степенот на перцепциите на брендовите (т.е., здруженијата на брендовите и сличните атрибути) кои ги кодираат овие јазички модели. Веруваме дека секој вид на пристрасност за бранд и пар атрибути може да влијае врз задачите центрирани на клиентите, како што се препорачувачките системи, анализите на чувствата и одговорите на прашањата, на пример, предлагајќи константно специфичен бранд кога се бараат иновативни производи. Користиме синтетички податоци и реални податоци и известуваме за резултатите на споредбата за пет контекстни ЛМ. BERT, RoBERTa, DistilBERT, ALBERT and BART.', 'ms': 'Menyelidiki percepsi tanda adalah dasar untuk strategi pemasaran. Dalam hal ini, imej tanda, ditakrif oleh set atribut (Aaker, 1997), dikenali sebagai unsur utama dalam menunjukkan bagaimana tanda diterima oleh pelbagai pihak berwenang seperti konsumen dan kompetitor. Pendekatan tradisional (contohnya, survei) untuk mengawasi perperhatian tanda adalah memakan masa dan tidak berkesan. In the era of digital marketing, both brand managers and consumers engage with a vast amount of digital marketing content.  Pertumbuhan eksponensial kandungan digital telah mendorong muncul model bahasa pra-dilatih seperti BERT dan GPT sebagai alat penting untuk memecahkan banyak cabaran dengan data teks. Kertas ini bermaksud untuk menyelidiki jangkauan persepsi markah (iaitu persepsi markah dan atribut imej) model bahasa ini mengekodkan. Kami percaya bahawa setiap jenis bias untuk pasangan tanda dan atribut mungkin mempengaruhi tugas downstream pusat pelanggan seperti sistem rekomendasi, analisis perasaan, dan jawapan soalan, cth., mencadangkan tanda tertentu secara konsisten apabila diminta untuk produk inovatif. Kami menggunakan data sintetik dan data nyata dan laporkan hasil perbandingan untuk lima LMs kontekstual, viz. BERT, RoBERTa, DistilBERT, ALBERT dan BART.', 'ml': 'ബ്രാങ്കിന്\u200dറെ അന്വേഷണം പരിശോധിക്കുന്നത് മാര്\u200dക്കറ്റ് ചെയ്യുന്ന ഘടനയുടെ അടിസ്ഥാനമാണ്. ഈ കാര്യത്തില്\u200d, ഒരു കൂട്ടിക ക്രമത്തിന്\u200dറെ (ആഖേര്\u200d, 1997) നിര്\u200dണയിക്കുന്ന ബ്രാന്\u200dഡ് ചിത്രം, ഒരു കൂട്ടിയ ഗുണപൂര്\u200dണ്ണമായ മൂലകങ്ങളായി തിരിച്ചറിയ ബ്രാന്റിന്റെ കാര്യങ്ങള്\u200d നിരീക്ഷിക്കുന്നതിനുള്ള പാഠമായ വഴികള്\u200d (ഉദാഹരണമായ പരിശോധനം) സമയം ഉപയോഗിക്കുന്നതും പരിഗണന In the era of digital marketing, both brand managers and consumers engage with a vast amount of digital marketing content.  ഡിജിറ്റല്\u200d ഉള്ളടക്കത്തിന്റെ എക്സ്പോണ്\u200dട്രെയിന്\u200dറ്മെന്\u200dറ് വളര്\u200dച്ചയായി പഠിപ്പിക്കപ്പെട്ട ഭാഷ മോഡലുകളുടെ ഉയര്\u200dച്ചയെടുക്കുന്നു. ബെര്\u200dട് ഈ പത്രത്തില്\u200d ബ്രാന്റ് കാഴ്ചപ്പെടുത്തുന്നതിന്റെ വ്യത്യാസങ്ങളുടെ (ഉദാഹരണത്തിന്റെ ബ്രാന്\u200dഡും ചിത്ര കൂട്ടത്തില We believe that any kind of bias for a brand and attribute pair may influence customer-centric downstream tasks such as recommender systems, sentiment analysis, and question-answering, e.g., suggesting a specific brand consistently when queried for innovative products.  നമ്മള്\u200d സിന്തിറ്ററിക്ക് ഡേറ്റായും യഥാര്\u200dത്ഥ ജീവിതത്തിലെ വിവരങ്ങളും ഉപയോഗിക്കുന്നു. അഞ്ച് വിക്സ്റ്റര്\u200d എ ബെര്\u200dട്ട്, റോബെര്\u200dത്ത, ഡിസ്തില്\u200dബെര്\u200dട്ട്, അല്\u200dബെര്\u200dട്ട്, ബാര്\u200dട്ട്.', 'mt': 'L-investigazzjoni tal-perċezzjoni tal-marka hija fundamentali għall-istrateġiji tal-kummerċjalizzazzjoni. F’dan ir-rigward, l-immaġni tal-marka, definita minn sett ta’ attributi (Aaker, 1997), hija rikonoxxuta bħala element ewlieni fl-indikazzjoni ta’ kif marka hija perċepita minn diversi partijiet interessati bħall-konsumaturi u l-kompetituri. L-approċċi tradizzjonali (e ż., stħarriġ) biex jiġu mmonitorjati l-perċezzjonijiet tal-marka huma li jieħdu ż-żmien u ineffiċjenti. Fl-era tal-kummerċjalizzazzjoni diġitali, kemm il-maniġers tal-marki kif ukoll il-konsumaturi jimpenjaw ruħhom b’ammont kbir ta’ kontenut tal-kummerċjalizzazzjoni diġitali. It-tkabbir esponenzjali tal-kontenut diġitali xpruna l-ħolqien ta’ mudelli lingwistiċi mħarrġa minn qabel bħall-BERT u l-GPT bħala għodod essenzjali biex jiġu solvuti għadd kbir ta’ sfidi bid-dejta testwali. Dan id-dokument ifittex li jinvestiga l-firxa tal-perċezzjonijiet tal-marka (jiġifieri, assoċjazzjonijiet tal-attributi tal-marka u tal-immaġni) li dawn il-mudelli lingwistiċi jikkodifikaw. We believe that any kind of bias for a brand and attribute pair may influence customer-centric downstream tasks such as recommender systems, sentiment analysis, and question-answering, e.g., suggesting a specific brand consistently when queried for innovative products.  We use synthetic data and real-life data and report comparison results for five contextual LMs, viz.  BERT, RoBERTa, DistilBERT, ALBERT u BART.', 'mn': 'Брэндийн ойлголтыг судалгаагаар маркетингийн стратегийг үндсэн. Энэ талаар бренд зураг, хэрэглэгчид болон өрсөлдөгчдийн мэт олон сонирхогчид хэрхэн бренд хүлээн зөвшөөрөгдөж байгааг илэрхийлж чадна. Брэнд ойлголтыг удирдах уламжлалтай арга зам нь цаг хугацаанд хэрэглэж, үр ашиггүй. Дижитал маркетингийн үед бренд менеджер болон хэрэглэгчид маш их хэмжээний дижитал маркетингийн contentsтай холбогддог. Дижитал бүтээгдэхүүний эсрэг өсөлт нь BERT болон GPT зэрэг сургалтын өмнө сургалтын хэл загваруудын тусламжтай байдал болсон. Энэ цаас нь бренд ойлголтын хэмжээг судалж, тэр хэл загварын кодлох хэмжээний хэмжээг судалж байна. Бид бренд болон атрибут хоёрын аль нэг төрлийн өрөөсгөл нь хэрэглэгчдийн төв доорх үйл ажиллагаанд нөлөөлж чадна гэдэгт итгэдэг. Жишээлбэл, сэтгэл санааны шинжилгээ, асуултын хариулт, жишээлбэл, шинэчлэлийн бүтээгдэхүүнд суралцах Бид синтетик өгөгдлийг, жинхэнэ амьдралын мэдээллийг ашиглаж таван орчин үеийн LMs, viz. Берт, Роберта, ДистилБерт, Алберт, Барт.', 'no': 'Investigasjon av merkeloppfatning er grunnleggjande for markedsstrategiar. I denne måten er markeringsbiletet, definert av eit sett attributt (Aaker, 1997), gjenkjent som ein nøkkelelement for å visa korleis eit merke vert gjenkjent av forskjellige stakeholderar som brukarar og konkurentar. Tradisjonale tilnærmingar (f.eks. undersøkingar) for å overvåka merkeloppfatningar er tidsforbruk og ikkje effektiv. I tidspunktet digital markering, både markedshandsamarar og brukarar har eit stor mengd digital markedsinnhald. Eksponensielt vekst av digitalt innhald har første utvikling av første språk-modeller som BERT og GPT som viktige verktøy i løysing av myriader av utfordringar med tekstdata. Denne papiret forsøker å undersøke storleiken på merkeloppfatningar (t.d. merkelappen og bilettributtsamlingar) desse språk-modelane. Vi tror at alle slags forvirkningar for eit merke og attributtpar kan påvirke klientsentrale nedstrømmeoppgåver slik som anbefalingssystemet, sentimentanalyse og spørsmål-svar, f.eks. tyder på eit spesifikk merke konsistent når du spørsmål om inovative produktar. Vi bruker syntetiske data og verkeleg livsdata og rapporterer sammenligningslingsresultat for fem kontekstlege LMs, dvs. BERT, ROBERTA, DistilBERT, ALBERT og BART.', 'pl': 'Badanie postrzegania marki jest podstawowe dla strategii marketingowych. W tym względzie wizerunek marki, zdefiniowany przez zestaw atrybutów (Aaker, 1997), jest uznawany za kluczowy element wskazujący, jak marka jest postrzegana przez różne interesariusze, takie jak konsumenci i konkurenci. Tradycyjne podejścia (np. ankiety) do monitorowania postrzegania marki są czasochłonne i nieefektywne. W erze marketingu cyfrowego zarówno menedżerowie jak i konsumenci angażują się w ogromną ilość cyfrowych treści marketingowych. Wykładniczy wzrost treści cyfrowych doprowadził do pojawienia się wstępnie przeszkolonych modeli językowych, takich jak BERT i GPT, jako niezbędne narzędzia w rozwiązywaniu niezliczonych wyzwań z danymi tekstowymi. Niniejszy artykuł ma na celu zbadanie zakresu postrzegania marki (tj. skojarzeń atrybutów marki i wizerunku), które te modele językowe kodują. Wierzymy, że każdy rodzaj uprzedzeń do pary marki i atrybutów może wpływać na zadania zorientowane na klienta, takie jak systemy rekomendujące, analiza sentymentów i odpowiadanie na pytania, np. konsekwentne sugerowanie konkretnej marki w przypadku zapytania o innowacyjne produkty. Wykorzystujemy dane syntetyczne i dane rzeczywiste i raportujemy wyniki porównywania dla pięciu kontekstowych LM, tj. BERT, RoBERTa, DistilBERT, ALBERT i BART.', 'ro': 'Investigarea percepției mărcii este fundamentală pentru strategiile de marketing. În acest sens, imaginea mărcii, definită printr-un set de atribute (Aaker, 1997), este recunoscută ca un element cheie în indicarea modului în care un brand este perceput de diferite părți interesate, cum ar fi consumatorii și concurenții. Abordările tradiționale (de exemplu, sondajele) pentru monitorizarea percepției mărcii sunt consumatoare de timp și ineficiente. În era marketingului digital, atât managerii de brand, cât și consumatorii se angajează cu o cantitate vastă de conținut de marketing digital. Creșterea exponențială a conținutului digital a propulsat apariția unor modele lingvistice pre-instruite, cum ar fi BERT și GPT, ca instrumente esențiale în rezolvarea a nenumărate provocări cu ajutorul datelor textuale. Această lucrare urmărește să investigheze amploarea percepțiilor mărcii (adică asociațiile de marcă și atribute de imagine) pe care aceste modele lingvistice le codifică. Credem că orice tip de părtinire pentru o pereche de marcă și atribute poate influența sarcinile din aval centrate pe client, cum ar fi sistemele de recomandare, analiza sentimentului și răspunsul la întrebări, de exemplu, sugerând în mod constant un anumit brand atunci când se solicită produse inovatoare. Folosim date sintetice și date din viața reală și raportăm rezultatele comparației pentru cinci LM contextuale, și anume. BERT, RoBERTa, DistilBERT, ALBERT şi BART.', 'sv': 'Att undersﾃｶka varumﾃ､rkesuppfattning ﾃ､r grundlﾃ､ggande fﾃｶr marknadsfﾃｶringsstrategier. I detta avseende erkﾃ､nns varumﾃ､rkesbilden, som definieras av en uppsﾃ､ttning attribut (Aaker, 1997), som en nyckelfaktor fﾃｶr att indikera hur ett varumﾃ､rke uppfattas av olika intressenter sﾃ･som konsumenter och konkurrenter. Traditionella metoder (t.ex. undersﾃｶkningar) fﾃｶr att ﾃｶvervaka varumﾃ､rkesuppfattningar ﾃ､r tidskrﾃ､vande och ineffektiva. I den digitala marknadsfﾃｶringens era engagerar bﾃ･de varumﾃ､rkeschefer och konsumenter sig med en stor mﾃ､ngd digitalt marknadsfﾃｶringsinnehﾃ･ll. Den exponentiella tillvﾃ､xten av digitalt innehﾃ･ll har drivit fram framvﾃ､xten av fﾃ､rdigutbildade sprﾃ･kmodeller som BERT och GPT som viktiga verktyg fﾃｶr att lﾃｶsa myriader av utmaningar med textdata. Denna uppsats syftar till att undersﾃｶka omfattningen av varumﾃ､rkesuppfattningar (dvs varumﾃ､rkes- och bildattributassociationer) dessa sprﾃ･kmodeller kodar. Vi tror att alla typer av bias fﾃｶr ett varumﾃ､rke och attributpar kan pﾃ･verka kundcentrerade nedstrﾃｶmsuppgifter sﾃ･som rekommendationssystem, sentimentalys och frﾃ･gesvar, t.ex. fﾃｶreslﾃ･ ett specifikt varumﾃ､rke konsekvent nﾃ､r de frﾃ･gas efter innovativa produkter. Vi anvﾃ､nder syntetiska data och verkliga data och rapporterar jﾃ､mfﾃｶrelseresultat fﾃｶr fem kontextuella LM:er, dvs. BERT, RoBERTa, DistilBERT, ALBERT och BART.', 'so': "Qiimeynta aragtida farsamada ayaa muhiim u ah qorshaha suuqa. Sidan darteed waxaa looga aqoonsadaa sawir rasmi ah oo lagu yaqaan noocyo gaar ah (Aaker, 1997), taas oo looga muujiyo sida ay u muuqato sawir ay u eg yihiin dadka isticmaalaya iyo khiyaanayaal ah. Dhaqdhaqaaqyada caadiga ah (tusaale ahaan baaritaanka) in la soconayo aragtida calaamadda waa isticmaalka waqtiga, waana ku filan yihiin. Waqtigii suuqa digitalinta, maamulaha deyrka ah iyo kuwa isticmaalaya waxay ka qabanqaabiyaan waxyaabo badan oo ka mid ah suuqa digital. koritaanka waxyaabaha digital waxaa horumariyey soo baxa modelalka afka hore ee lagu tababaray, sida BERT iyo GPT oo ah qalabka muhiimka ah si ay u xalliyaan muran-khilaaf ah oo ku saabsan macluumaadka qoraalka. This paper seeks to investigate the extent of brand perceptions (i.e., brand and image attribute associations) these language models encode.  Waxaynu aaminsanahay in noocyo cayn ah oo ku saameyn karo shaqaalaha badda hoose e e macaamiisha, tusaale ahaan nidaamka hagaajiya, analysinta xisaabta fikirka iyo jawaabta su'aalaha, tusaale ahaan waxaa looga jeedaa laan cayiman marka la weyddiiyo waxyaabaha abuurka ah. Waxaynu isticmaalnaa macluumaad la xiriira iyo macluumaadka nolosha ee runta ah iyo wargelinaynaa arimaha isbarbardhigga shanta xilliga ah ee LMs, viz. iyo BERT, iyo Robertaa, iyo Distilberta, iyo ALBERT iyo BART.", 'si': 'බ්\u200dරෑන්ඩ් දැනුම් පරීක්ෂණය විශ්වාස කරන්නේ මාර්කේට් එක්ක පරීක්ෂණ ප්\u200dරමාණය. මේ ගැන, බ්\u200dරෑන්ඩ් පින්තූර, විශේෂතාවක් සම්බන්ධයක් නිර්දාශ කරලා තියෙන්නේ (Aaker, 1997), විශේෂතාවක් වලින් බ්\u200dරෑන්ඩ් කිරීමක් ව සාමාන්\u200dය ප්\u200dරවේශනය (උදාහරණය, පරීක්ෂණය) බ්\u200dරෑන්ඩ් බලන්න සැකසුම් පරීක්ෂණය වෙනුවෙන් වෙලාවක් ප්\u200dරවේශන ඩිජිටල් මාර්කේටින්ග් වර්ගයේදී, බ්\u200dරෑන්ඩ් මැනේජර්ස් සහ පාවිච්චිකරුවන් දෙන්නම් ගොඩක් සංචාර ඩිජිටල් සාමාන්\u200dය විශාල විශාලයෙන් ප්\u200dරශ්නය කරපු භාෂා මොඩේල් වලින් BERT සහ GPT වලින් ප්\u200dරශ්නයික උපකරණය වලින් ප්\u200dරශ්නය ව මේ පත්තුව හොයාගන්නේ බ්\u200dරෑන්ඩ් හොයාගන්න ප්\u200dරමාණය (ඉතින්, බ්\u200dරෑන්ඩ් හා පින්තූර සංවිධානය) මේ භාෂා මොඩේ අපි විශ්වාස කරනවා බ්\u200dරෑන්ඩ් එක්ක සහ ගොඩක් ගොඩක් ප්\u200dරශ්නයක් සඳහා ප්\u200dරශ්නයක් ප්\u200dරශ්නයක් වෙන්න පුළුවන් විදිහට සැකසුම් පද්ධතිය, සංවේදනය විශ අපි සංවිධානය දත්ත සහ ඇත්ත ජීවිත දත්ත භාවිතා කරනවා සහ සංවිධානය පහකට වාර්තා කරන්න ප්\u200dරතිචාරණ ප්\u200d බෙර්ට්, රොබෙර්ටා, ඩිස්ටිල්බර්ට්, ඇල්බර්ට් සහ බර්ට්.', 'ur': 'مارکیٹینگ استراتژی کے لئے بنیادی ہے۔ اس کے بارے میں برند تصویر، جو ایک گروہوں کے مجموعہ سے مقرر کیا گیا ہے (Aaker, 1997) کو ایک کلی عنصر کے طور پر پہچان لیا جاتا ہے کہ نشان دکھاتا ہے کہ ایک برند کس طرح مختلف علاقمندوں کے ذریعہ کس طرح سمجھ لیا جاتا ہے۔ برندوں کی نظر نظر نظر کرنے کے لئے آسانی طریقے (جیسے تحقیقات) وقت مصرف کرتے ہیں اور بے فائدہ ہیں۔ ڈیجیٹل مارکیٹنگ کی عصر میں، دونوں برندوں مدیرانوں اور مصروف کرنے والوں کے ساتھ بہت سی اندازہ ڈیجیٹل مارکیٹنگ منصفات کے ساتھ مشغول ہیں. ڈیجیٹل منصوبات کی اکسپونسیل رشد نے پہلے تدریس کی زبان موڈل کی اضطراری بنائی ہے جیسے BERT اور GPT کی بنیادی ابزار کے طور پر تدریس ڈیٹا کے ساتھ چالیں کی میریڈ حل کرنے کے لئے۔ This paper seeks to investigate the extent of brand perception (i.e. brand and image attribute associations) these language models encode. ہم یقین رکھتے ہیں کہ ایک برند اور آبریٹ جوڑ کے لئے ہر قسم کی مخالفت ممکن ہے کہ مشتری-منطقه ڈونسٹریک کاموں کی تاثیر پہنچا سکتی ہے جیسے توفیق دینے والے سیستم، احساسات تحلیل، اور سوال جواب دینے والی، جیسے، ایک خاص برند کی توفیق دیتا ہے جب نوآوری مواد کے لئے سوال کیا جاتا ہم سینٹیٹیک ڈیٹا اور حقیقی زندگی ڈیٹا استعمال کرتے ہیں اور پانچ کنٹیکسٹیوال LMs کے لئے مقایسہ نتائج راپورت کرتے ہیں۔ BERT, ROBERTA, DistilBERT, ALBERT اور BART.', 'ta': 'கிளை பார்வையை ஆய்வு செய்வது சந்தை துறைகளுக்கு முக்கியமானது. இந்த குணங்களின் கூட்டு குணங்கள் (Aaker, 1997) வரையறுக்கப்பட்ட கிளை பிம்பம், விளையாடுபவர்கள் மற்றும் விருப்பங்கள் போன்ற வித்தியாட்டாளர்கள் எவ்வாறு க Traditional approaches (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient.  டிஜிட்டல் சந்தையின் காலத்தில், கிளை மேலாளர்கள் மற்றும் பயனர்கள் இருவரும் விரிவான டிஜிட்டல் சந்தையின் உள்ளடக்கத்த டிஜிட்டல் உள்ளடக்கத்தின் அடுக்கு வளர்ச்சி முன் பயிற்சி மொழி மாதிரிகளின் வெளியேற்றத்தை பிரித்துள்ளது, BERT மற்றும் GPT போன்ற முக்கியமான கர இந்த தாள் கிளை பார்வைகள் (அதாவது, கிளை மற்றும் பிம்பம் குணங்கள் இணைப்புகள்) இந்த மொழி மாதிரி குறியீடு நாங்கள் நம்புகிறோம் ஒரு கிளை மற்றும் குணங்களுக்கு எந்த வகையான வழிகாட்டு ஜோடி பரிந்துரைப்பு அமைப்புகள், உணர்வு ஆராய்வு மற்றும் கேள்வி கேட்பார்கள் போன்று பரிந்துரை We use synthetic data and real-life data and report comparison results for five contextual LMs, viz.  பெர்ட், ரோபெர்டா, டிஸ்டில்பெர்ட், அல்பெர்ட் மற்றும் பார்ட்.', 'sr': 'Istraživanje percepcije brenda je osnovna za strategije marketinga. U tom pogledu, pregled znakova, definisan sa grupom atributa (Aaker, 1997), priznaje se kao ključni element u kojem se ukazuje kako se znak smatra različitim zainteresovanim stranama poput potroša ča i konkurenta. Tradicionalni pristupi (npr. istraživanja) za praćenje percepcija znaka su potrošnje vremena i neefektivni. U doba digitalnog marketing a, i menadžeri znakova i potroša či uključuju ogromnu količinu sadržaja digitalnog marketinga. Eksponencijalni rast digitalnog sadržaja izazvao je izazov predobučenih jezičkih modela poput BERT i GPT kao ključni alat u rješavanju mirijada izazova sa tekstualnim podacima. Ovaj papir pokušava da istraži razinu percepcija znakova (tj. udruženja znakova i atributa slike) tih jezičkih modela. Vjerujemo da svaka vrsta predrasude za brand i atribut pair može utjecati na poslove klijenta-centrične downstream kao što su preporučujući sisteme, analizu sentiment a i odgovor na pitanje, npr. predlaže ći određeni znak u konsekvenciji kada se pitaju za inovativne proizvode. Koristimo sintetičke podatke i podatke o stvarnom životu i prijavimo rezultate usporedbe za pet kontekstualnih LMs, viz. BERT, ROBERTA, DISTILBERT, ALBERT I BART.', 'uz': "Qidirish qo'llanmalar tashkilotlari suhbat strategiyaning muhim. Bu yerda, xotiralar (Aaker, 1997) turli rasm (AKR) sifatida aniqlangan qismi element deb belgilangan. Bu yerda, foydalanuvchilar va rivojlanuvchilar kabi qanday qismini aniqlanadi. Name Digital soʻzda, boshqaruvchilar va foydalanuvchilar juda ko'p raqamli soʻzning tarkibi bilan ishlaydi. Raqamli tarkibining eksponent uzoqli, birinchi o'rganilgan tillar modellari, BERT va GPT kabi muhim asboblar, matn maʼlumotlar bilan murakkab qilish uchun muhim asboblar. Bu qogʻoz bu tilning modellari kodlash usulining darajasini qidirishni xohlaydi. Biz shunday ishonamizki, bir qancha qismlar va taxminan bir necha xil harakatlar, boshqaruvchi tizim, hissiyot analyzeri va savol javobi, masalan, ijodkorlik narsalarni talab qilayotganda foydalanuvchi markazida foydalanuvchining markaziy vazifani ishga tushirishi mumkin. Biz syntetik maʼlumot va haliy hayot maʼlumotidan foydalanamiz va qidirish natijalarini 5 davomida LMs, viz uchun kamaytirish natijasi haqida xabar beramiz. Name", 'vi': 'Điều tra nhận thức của thương mại là điều quan trọng đối với marketing. Thay vào đó, hình ảnh của dấu hiệu, được xác định bởi một bộ thuộc tính (Aaker, 1997) được công nhận là một yếu tố then chốt trong việc chỉ ra cách các cá nhân khác nhau cảm nhận của một thương hiệu như là người tiêu dùng và đối thủ cạnh tranh. Các phương pháp truyền thống (ví dụ, khảo sát) để theo dõi nhận thức của thương mại là tốn thời gian và không hiệu quả. Trong thời đại thương mại kỹ thuật số, cả những người quản lý và người tiêu dùng đều có một lượng lớn nội dung thị trường kỹ thuật số. Sự tăng trưởng nhân bản của nội dung kỹ thuật số đã thúc đẩy sự xuất hiện của các mô hình ngôn ngữ được đào tạo trước như BERT và GPT như những công cụ thiết yếu để giải quyết hàng loạt thử thách bằng các dữ liệu cấu hình. Tờ giấy này tìm kiếm để xác định mức độ nhận dạng thương hiệu (các liên minh nhãn hiệu và hình ảnh) của các mô hình ngôn ngữ này được mã hóa. Chúng tôi tin rằng bất kỳ khuynh hướng nào đối với một nhãn hiệu và một đôi thuộc các loại có thể ảnh hưởng tới các công việc xuôi dòng khách hàng như các hệ thống liên minh hơn, phân tích tình cảm và câu trả lời câu hỏi, ví dụ, đề xuất một thương hiệu đặc biệt liên tục khi hỏi về các sản phẩm khác. Chúng tôi sử dụng dữ liệu tổng hợp và dữ liệu đời thực và báo cáo kết quả so sánh cho năm xu ngữ chung, viz. BERT, RoBERTa, DisulBERT, ALBERT và BART.', 'bg': 'Проучването на възприемането на марката е от основно значение за маркетинговите стратегии. В тази връзка имиджа на марката, определен от набор от атрибути (Аекер, 1997), се признава като ключов елемент за показване на начина, по който марката се възприема от различни заинтересовани страни като потребители и конкуренти. Традиционните подходи (напр. проучвания) за наблюдение на възприятията на марката отнемат време и са неефективни. В ерата на дигиталния маркетинг мениджърите и потребителите се занимават с огромно количество дигитално маркетингово съдържание. Експонденталният растеж на цифровото съдържание стимулира появата на предварително обучени езикови модели като като основни инструменти за решаване на безброй предизвикателства с текстови данни. Настоящата статия има за цел да проучи степента на възприятията на марката (т.е. асоциации на атрибутите на марката и изображението), които тези езикови модели кодират. Вярваме, че всякакъв вид пристрастие към двойка марка и атрибути може да повлияе на задачите, насочени към клиента надолу по веригата, като например системи за препоръки, анализ на сентимента и отговор на въпроси, например да предложим конкретна марка последователно, когато се търси иновативни продукти. Използваме синтетични данни и данни от реалния живот и отчитаме резултатите от сравняването за пет контекстуални МУ, т.е. Берт, Роберта, Дестилберт, Алберт и Барт.', 'da': "Undersøgelse af brand perception er grundlæggende for markedsføringsstrategier. I den forbindelse anerkendes brandimage, defineret ved et sæt attributter (Aaker, 1997), som et centralt element i at angive, hvordan et brand opfattes af forskellige interessenter såsom forbrugere og konkurrenter. Traditionelle tilgange (f.eks. undersøgelser) til at overvåge mærkeopfattelsen er tidskrævende og ineffektive. I en æra med digital markedsføring engagerer både brandledere og forbrugere sig i en enorm mængde digitalt markedsføringsindhold. Den eksponentielle vækst i digitalt indhold har hjulpet fremkomsten af forududdannede sprogmodeller som BERT og GPT som væsentlige værktøjer til at løse utallige udfordringer med tekstdata. Denne artikel søger at undersøge omfanget af brand perception (dvs. brand og image attribut associationer) disse sprogmodeller koder. Vi mener, at enhver form for bias for et brand- og attributpar kan påvirke kundeorienterede downstream-opgaver såsom anbefalingssystemer, sentiment analyse og spørgsmål-besvarelse, f.eks. foreslå et bestemt brand konsekvent, når de spørges om innovative produkter. Vi bruger syntetiske data og virkelige data og rapporterer sammenligningsresultater for fem kontekstuelle LM'er, dvs. BERT, RoBERTa, DistilBERT, ALBERT og BART.", 'hr': 'Istraživanje percepcije znakova temeljno je za tržišne strategije. U tom pogledu, značka slika, definirana skupom atributa (Aaker, 1997.), priznaje se kao ključni element u kojem se ukazuje kako se znak smatra različitim dionicima kao što su potroša či i konkurenti. Tradicionalni pristupi (npr. ispitivanja) za praćenje percepcije znakova su potrošnje vremena i neefektivni. U doba digitalnog tržišta, i menadžeri znakova i potroša či uključuju ogromnu količinu sadržaja digitalnog tržišta. Eksponencijalni rast digitalnog sadržaja izazvao je izazov predobučenih jezičkih modela poput BERT i GPT kao ključne alate u rješavanju mirijada izazova s tekstualnim podacima. Ovaj papir pokušava istražiti razinu percepcija znakova (tj. udruženja znakova i pridruživanja prikaza o prikazu slike) tih jezičkih modela. Vjerujemo da svaka vrsta predrasude za znak i atributni par može utjecati na zadatak klijenta-centralni dolje kao što su preporučujući sustave, analizu osjećaja i odgovor na pitanje, na primjer, sugerirajući određeni znak u konsekvenciji kada se pitaju za inovativne proizvode. Koristimo sintetičke podatke i podatke o stvarnom životu i prijavimo rezultate usporedbe za pet kontekstnih LMs, viz. BERT, ROBERTA, DISTILBERT, ALBERT I BART.', 'nl': 'Het onderzoeken van merkperceptie is fundamenteel voor marketingstrategieën. In dit verband wordt merkimago, gedefinieerd door een reeks attributen (Aaker, 1997), erkend als een belangrijk element om aan te geven hoe een merk wordt ervaren door verschillende stakeholders zoals consumenten en concurrenten. Traditionele benaderingen (bijvoorbeeld enquêtes) om merkpercepties te monitoren zijn tijdrovend en inefficiënt. In het tijdperk van digitale marketing houden zowel merkmanagers als consumenten zich bezig met een enorme hoeveelheid digitale marketingcontent. De exponentiële groei van digitale inhoud heeft geleid tot de opkomst van vooraf getrainde taalmodellen zoals BERT en GPT als essentiële hulpmiddelen bij het oplossen van talloze uitdagingen met tekstuele gegevens. Dit artikel probeert de mate van merkpercepties (d.w.z. merk- en beeldattributenassociaties) te onderzoeken die deze taalmodellen coderen. Wij geloven dat elke vorm van vooroordelen voor een merk- en attributenpaar van invloed kan zijn op klantgerichte downstreamtaken zoals aanbevelingssystemen, sentimentanalyse en vragenbeantwoording, bijvoorbeeld door consequent een specifiek merk te suggereren wanneer gevraagd wordt naar innovatieve producten. We gebruiken synthetische gegevens en real-life data en rapporteren vergelijkingsresultaten voor vijf contextuele LMs, namelijk. BERT, RoBERTa, DistilBERT, ALBERT en BART.', 'de': 'Die Untersuchung der Markenwahrnehmung ist grundlegend für Marketingstrategien. In diesem Zusammenhang wird das Markenimage, definiert durch eine Reihe von Attributen (Aaker, 1997), als Schlüsselelement erkannt, um anzuzeigen, wie eine Marke von verschiedenen Stakeholdern wie Verbrauchern und Wettbewerbern wahrgenommen wird. Traditionelle Ansätze (z.B. Umfragen) zur Überwachung der Markenwahrnehmung sind zeitaufwändig und ineffizient. Im Zeitalter des digitalen Marketings beschäftigen sich sowohl Markenmanager als auch Verbraucher mit einer Vielzahl digitaler Marketinginhalte. Das exponentielle Wachstum digitaler Inhalte hat dazu geführt, dass vortrainierte Sprachmodelle wie BERT und GPT als wesentliche Werkzeuge zur Lösung unzähliger Herausforderungen mit Textdaten entstanden sind. Der vorliegende Beitrag untersucht das Ausmaß der Markenwahrnehmungen (d.h. Assoziationen von Marken- und Bildattributen), die diese Sprachmodelle kodieren. Wir glauben, dass jede Art von Verzerrung für ein Marken- und Attributpaar kundenorientierte nachgelagerte Aufgaben wie Empfehlungssysteme, Stimmungsanalyse und Fragebeantwortung beeinflussen kann, z.B. indem eine bestimmte Marke konsequent vorgeschlagen wird, wenn nach innovativen Produkten gefragt wird. Wir verwenden synthetische Daten und reale Daten und berichten Vergleichsergebnisse für fünf kontextbezogene LMs, nämlich: BERT, RoBERTa, DistilBERT, ALBERT und BART.', 'ko': '브랜드 감지를 조사하는 것은 마케팅 전략의 기초이다.이런 측면에서 하나의 속성으로 정의된 브랜드 이미지(Aaker, 1997)는 소비자와 경쟁자 등 서로 다른 이해관계자가 브랜드를 어떻게 생각하는지 보여주는 관건적인 요소로 여겨진다.브랜드 인지를 모니터링하는 전통적인 방법(예를 들어 조사)은 시간도 소모되고 효과도 낮다.디지털 마케팅 시대에 브랜드 매니저와 소비자들은 모두 대량의 디지털 마케팅 내용에 참여했다.디지털 콘텐츠의 지수급 증가는 BERT와 GPT 등 사전 훈련을 거친 언어 모델의 출현을 추진했고 텍스트 데이터가 직면한 수많은 도전을 해결하는 기본적인 도구이다.본고는 이러한 언어 모델 인코딩의 브랜드 인지 정도(즉 브랜드와 이미지 속성 관련)를 조사하고자 한다.우리는 브랜드와 속성에 대한 어떠한 편견도 고객 중심의 하류 임무, 예를 들어 추천 시스템, 정서 분석과 질문에 대한 대답에 영향을 미칠 수 있다고 생각한다. 예를 들어 혁신 제품을 물어볼 때 시종일관 특정 브랜드를 건의한다.우리는 합성 데이터와 실제 데이터를 사용하고 다섯 개의 상하문 LMs의 비교 결과를 보고한다. 즉,버트, 로버타, 디스티버트, 알버트와 바트.', 'id': 'Menyelidiki persepsi merk adalah dasar strategi pemasaran. Dalam hal ini, gambar merk, didefinisikan oleh set atribut (Aaker, 1997), dikenal sebagai unsur kunci dalam menunjukkan bagaimana sebuah merk dipercaya oleh berbagai pihak berwenang seperti konsumen dan kompetitor. Pendekatan tradisional (contohnya, survei) untuk mengawasi persepsi merk memakan waktu dan tidak efektif. Di era pemasaran digital, manajer dan konsumen bertarung dengan banyak isi pemasaran digital. Pertumbuhan eksponensial dari konten digital telah mendorong muncul model bahasa pra-terlatih seperti BERT dan GPT sebagai alat penting untuk memecahkan banyak tantangan dengan data teks. Kertas ini berusaha menyelidiki jangkauan persepsi merk (i.e., asosiasi merk dan atribut gambar) model bahasa ini mengekodi. Kami percaya bahwa setiap jenis bias untuk sebuah pertanda dan pasangan atribut mungkin mempengaruhi tugas downstream klien-sentrik seperti sistem rekomendasi, analisis perasaan, dan jawaban pertanyaan, misalnya, menyarankan pertanda spesifik secara konsisten ketika diminta untuk produk inovatif. Kami menggunakan data sintetis dan data kehidupan nyata dan melaporkan hasil perbandingan untuk lima LMs kontekstual, viz. BERT, RoBERTa, DistilBERT, ALBERT and BART.', 'sw': 'Kuchunguza mtazamo wa alama ni msingi wa mikakati ya soko. Katika suala hili, picha iliyoandaliwa na seti ya wataalam (Aaker, 1997), inajulikana kama kitengele muhimu katika kuonyesha jinsi vifaa vinavyoelewa na wateja kadhaa kama vile wateja na wapinzani. Traditional approaches (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient.  Katika kipindi cha soko la kidijitali, wawili wakuu na wateja wote wanahusisha na kiasi kikubwa cha maudhui ya soko ya kidijitali. Ukubwa wa maudhui ya kidigitali umetangaza kuongezeka kwa mifano ya lugha zilizofunzwa kabla kama vile BERT na GPT kama zana muhimu katika kutatua changamoto za takwimu za msingi. Gazeti hili linalenga uchunguzi wa kiwango cha mitazamo (yaani jumuiya za wimbo na taswira) mifano hii ya lugha. Tunaamini kwamba aina yoyote ya upendeleo kwa kitengo na viwili vinaweza kuathiri kazi za wateja katikati ya mito kama vile mapendekezo, uchambuzi wa hisia, na majibu ya maswali, kwa mfano, inaonyesha alama maalum kwa ujumla unapoulizwa kwa bidhaa za ubunifu. Tunatumia takwimu za pamoja na taarifa za maisha halisi na kuripoti matokeo yanayolinganisha kwa ajili ya Ms.M. BERT, RoBERT, DistilBERT, ALBERT na BART.', 'fa': 'تحقیق نظر برند بنیادی برای استراتژی بازاری است. در این مورد، تصویر برند، که توسط یک مجموعه از ویژه\u200cها (Aaker, 1997) تعریف شده است، به عنوان عنصر کلید شناخته می\u200cشود که نشان می\u200cدهد چگونه یک برند توسط گروههای مختلف مشترک مانند مصرف کنندگان و رقابتان می\u200cشود. نزدیک\u200cهای سنتی (مثال تحقیقات) برای کنترل مشاهده\u200cهای برند، زمان\u200cconsumption و بی\u200cفایده است. در زمان بازارینگ دیجیتال، هر دو مدیران برند و مصرف کنندگان با محتوای بسیاری از بازارینگ دیجیتال مشغول می شوند. رشد نمایش محتوای دیجیتال اضطراری مدل های پیش آموزش زبانی مانند BERT و GPT را به عنوان ابزار اصلی برای حل میریاد چالش\u200cها با داده\u200cهای متن به راه انداخته است. این کاغذ می\u200cخواهد به تحقیق اندازه احساسات برند (یعنی واحد برند و واحد\u200cهای ویژه\u200cهای تصویر) این مدل\u200cهای زبان کود کند. ما باور می\u200cکنیم که هر نوع طبیعی برای یک جفت برند و خصوصی می\u200cتواند به کار های پایین\u200cترین مرکز مشتریان، مانند سیستم\u200cهای پیشنهاد، تحلیل احساسات و پاسخ\u200cجواب سوال، مثال، یک برند خاص را پیشنهاد می\u200cدهد که وقتی برای محصولات نوآوری پرسیده می\u200cشود، تأثیر می\u200c ما از اطلاعات سناتیک و داده های زندگی واقعی استفاده می کنیم و نتیجه مقایسه را برای پنج LMs contextual, viz گزارش می کنیم. برت، روبرت، دیستیلبرت، آلبرت و بارت', 'tr': 'Marka gözüni barlamak bazarlama stratejilerine esasy düýbüldir. Şol ýagdaýda, marka resim, tüketiciler we ýaryşykçylar ýaly nähili möhüm adamlar tarapyndan nähili marka alyp bilýän hökmünde tanalýar. Däpli g örnüş ýagdaýlary (meseläm, araştyrmalar) marka düşünýänlerini gözlemek üçin wagt tüketmesi we ýetersiz däldir. Dijital bazarlyk döwletinde hem marka müdiri hem tüketiciler hem digital bazarlyk mazmunlaryna golaýlaşýarlar. Dijital mazmunlaryň eksponensiýaly öňünden öňünden eğlenen dil nusgalarynyň, BERT we GPT ýaly metin maglumaty bilen kynçylyklary çözmek üçin esasy aletler döredi. Bu kagyz bu dil nusgalaryň näçe ködlemelerini barlamak isleýär. Biz bir marka we atribut çift üçin her hili bir nähili bias müşterileriň-centrik a şak täsirlerini, maslahat sistemalary, duýgular analizi we sorag jogaplary ýaly maslahat beren ýaly, meselâ täze bir marka diňe täsirli täsirlerini maslahat edip biler. Biz sintetik verileri ve gerçek yaşamlı verileri kullanırız ve beş contextual LMs için karşılaştırma neticelerini rapor ediyoruz. BERT, RoBERTa, DistilBERT, ALBERT we BART.', 'sq': 'Hetimi i perceptimit të markave është thelbësor për strategjitë e marketingut. Në këtë lidhje, imazhi i markave, i përcaktuar nga një sërë atributesh (Aaker, 1997), është njohur si një element kyç në tregimin se si një marka perceptohet nga interesante të ndryshme të tilla si konsumatorët dhe konkurrentët. Përqasjet tradicionale (për shembull sondazhet) për të mbikqyrur perceptimet e markave janë kohë-konsumuese dhe jo-efektive. In the era of digital marketing, both brand managers and consumers engage with a vast amount of digital marketing content.  Rritja eksponenciale e përmbajtjes dixhitale ka nxitur daljen e modeleve gjuhësore të paratrajnuar të tillë si BERT dhe GPT si mjete thelbësore në zgjidhjen e shumë sfidave me të dhënat tekstuale. Kjo letër kërkon të hetojë shkallën e perceptimeve të markave (pra, shoqatat e atributeve të markave dhe imazheve) që këto modele gjuhësh kodojnë. Ne besojmë se çdo lloj paragjykimi për një çift markash dhe atributesh mund të ndikojë në detyrat poshtë të qendrës së klientëve të tilla si sistemet rekomanduare, analizat e ndjenjave dhe përgjigjet pyetjeve, për shembull, duke sugjeruar një marka të veçantë në mënyrë konsistente kur kërkohet për prodhime inovative. Ne përdorim të dhënat sintetike dhe të dhënat e jetës reale dhe raportojmë rezultatet e krahasimit për pesë LMs kontekstuale, viz. Bert, Roberta, DistilBert, Albert dhe Bart.', 'am': 'የቅርንጫፎች አስተያየት የሸንጎ ዘጠኝነት ለመግለጫ መሠረት ነው፡፡ በዚህም ጉዳይ፣ የቅርንጫፍ ምስል (አኬር፥ 1997) በተለየ የቅርንጫፎች አካል እና ተቃዋሚዎች እንደሚያሳዩ የቁልፍ አካል ሆኗል፡፡ የባሕላዊ ደረጃዎች (ምሳሌ መረጃ) እውቀትን ለመከልከል የጊዜው መጠቀሚያ እና ጥቅም ነው፡፡ በዲጂታል ገበያ ዘመን፣ የቅርንጫፎች መጋቢዎች እና ተጠቃቂዎች በዲጂታል ገበያ ውስጥ ብዙ ጥያቄ ያጋራሉ፡፡ The exponential growth of digital content has propelled the emergence of pre-trained language models such as BERT and GPT as essential tools in solving myriads of challenges with textual data.  ይህ ፕሮግራም የቋንቋ ምሳሌዎች የደረጃ አካባቢ (አዲስ ቅርጽ እና የምስል ምርጫዎች) ክፍተቶችን ለመመርመር ይፈልጋል፡፡ እናምናለን፣ የቅርንጫፎች እና የአካባቢ ሁለቶች፣ የመታሰቢያ ስርዓት፣ አስተያየት እና የጥያቄ መልስ፣ ለፍጥረት አካባቢዎች በተጠየቁ ጊዜ የተለያየ ቅርንጫፎች እንዲያስፈልጋሉ የሚችሉትን የግዜ-ማዕከላዊ ስርዓቶች እንዲያስቀምጥ እና እንደምናደርጋለን፡፡ የሲንቲካዊ ዳታ እና እውነተኛ የሕይወት ዳታ እና ትክክል ፍሬዎችን ለአምስት ግንኙነት LMs. ቤርቴት፥ ሮቤርታ፥ ዲሽብሬት፥ ዓልቤርትና ቤርት።', 'hy': 'Բրենդի ընկալումը հետազոտելը մարքեթինգային ռազմավարությունների հիմնական մասն է կազմում: Այս առումով, բրենդի պատկերը, որը սահմանվում է մի շարք առանձնահատկությունների կողմից (Աքեր, 1997), ընդունվում է որպես կարևոր տարր տարրեր, որոնք ցույց են տալիս, թե ինչպես է բրենդը ընկալում տարբեր հետաքրքրված մասնագետներ, ինչպիսիք են սպառո Բրենդի ընկալումների վերահսկման ավանդական մոտեցումները (օրինակ հարցումները) ժամանակ պահանջում են և ոչ արդյունավետ են: Թվային մարքեթինգի ժամանակաշրջանում բրենդի ղեկավարները և սպառողները գործում են թվային մարքեթինգի հսկայական պարունակության հետ: Թվային պարունակության էքսպոնենցիալ աճը խրախուսեց նախապատրաստված լեզվի մոդելների, ինչպիսիք են BER-ը և GPT-ը, առաջացումը որպես կարևոր գործիքներ տեքստային տվյալների հետ բազմաթիվ մարտահրավերներ լուծելու համար: Այս աշխատանքը փորձում է ուսումնասիրել բրենդի ընկալումների ծավալը (այսինքն, բրենդի և պատկերի առանձնահատկությունների համախմբումները) այս լեզվի մոդելները կոդավորում են: Մենք հավատում ենք, որ բրենդի և առանձնահատկությունների զույգի ցանկացած կողմնականությունը կարող է ազդել հաճախորդի կենտրոնական հետևյալ խնդիրների վրա, ինչպիսիք են խորհուրդ տալու համակարգերը, զգացմունքների վերլուծությունը և հարցերի պատասխանը, օրինակ, հատուկ բրենդի խորհուրդը,  Մենք օգտագործում ենք սինթետիկ տվյալներ և իրական կյանքի տվյալներ և համեմատության արդյունքներ հաղորդում ենք Բերթ, Ռոբերթ, Դիստիլբերթ, Ալբերթ և Բարթ:', 'af': "Die ondersoek van brand oorvloediging is fundamenteel vir marketing strategies. In hierdie betrekking, brandbeeld, gedefinieer deur 'n stel eienskappe (Aaker, 1997), is herken as 'n sleutel element in die aanduidelik van hoe 'n brand aangeneem word deur verskillende staatskappers soos gebruikers en mededingers. Tradisjoneel toegange (bv. ondersoek) om brand aansoek te monitoreer is tyd-gebruik en oneffektief. In die tyd van digitale markering, beide brandbestuurders en gebruikers het met 'n groot hoeveelheid digitale markering inhoud betrokke. Die eksponensiele groei van digitale inhoud het die uitbreiding van voorafgevorderde taal modele soos BERT en GPT as behoorlike nutsprogramme in die oplossing van myriade van uitdagings met tekstuele data. Hierdie papier soek na ondersoek die uitbreiding van merk verstaan (bv. brand en beeldattributte assosiasies) hierdie taal modele kodeer. Ons glo dat enige soort bias vir 'n brand en eienskappy kan beïnvloor kliënt-sentrale onderstreem opdragte soos aanbeveelderstelsels, sentimentanalisie en vraag-antwoord, bv. voorstel 'n spesifieke brand konsistentlik wanneer gevra word vir inovatiewe produkte. Ons gebruik sintetiese data en reële lewensdata en raporteer vergelyking resultate vir vyf contextual LMs, viz. BERT, ROBERTA, DistilBERT, ALBERT en BART.", 'bn': 'ব্র্যান্ডের দৃষ্টিভঙ্গি বিজ্ঞাপনের কৌশলের জন্য মৌলিক। এই বিষয়টিতে ব্র্যান্ড চিত্র (আকার, ১৯৯৭) বিভিন্ন বিভিন্ন প্রতিযোগিতাদের দ্বারা কিভাবে ব্র্যান্ডের ব্র্যান্ড ব্যবহারকারী এবং প্রতিয ব্র্যান্ডের দৃষ্টিভঙ্গি পর্যবেক্ষণের জন্য ঐতিহ্যবাহী উপায় (উদাহরণস্বরূপ জরিপ) সময়-ভর্তি এবং যথেষ্ট। ডিজিটাল বাজারের যুগে, ব্র্যান্ড ম্যানেজার এবং ব্যবহারকারীরা ব্যাপারে ডিজিটাল বাজারের বিষয়বস্তুর সাথে জ ডিজিটাল বিষয়বস্তুর এক্সপোনেট বৃদ্ধি প্রথম প্রশিক্ষিত ভাষার মডেলের উৎপাদনের ব্যাপারে প্রচার করেছে, যেমন বিআরটি এবং জিপিটি টেক্সটুলের মূল এই পত্রিকাটি ব্র্যান্ডের ধারণা (যেমন ব্র্যান্ড এবং ছবি বৈশিষ্ট্যাবলী সংস্থা) এই ভাষার মডেল এনকোডের পরিমাণ তদন্ত করতে চ আমরা বিশ্বাস করি যে ব্র্যান্ড এবং বৈশিষ্ট্যের জন্য কোন ধরনের বৈষম্যের প্রভাব ফেলবে যেমন সুপারিশার সিস্টেম, আবেগ বিশ্লেষণ এবং প্রশ্নের উত্তর, যেমন সুনির্দিষ্ট ব্র্যান্ড আমরা সিন্টেটিক ডাটা এবং সত্যিকারের জীবনের তথ্য ব্যবহার করি এবং পাঁচটি বিদ্যমান এলএমএস, ভিজের জন্য তুলনার ফলাফল প্রতিব বের্ট, রবের্তা, ডিস্টিলবার্ট, এল্বার্ট এবং বার্ট।', 'bs': 'Istraživanje percepcije branda je temeljno za strategije marketinga. U tom pogledu, pregled znakova, definiran niz atributa (Aaker, 1997), priznat se kao ključni element u kojem se ukazuje kako se znak smatra različitim zainteresovanim stranama poput potroša ča i konkurenta. Tradicionalni pristupi (npr. istraživanja) za praćenje percepcija znaka su potrošnje vremena i neefektivni. U doba digitalnog marketing a, i menadžeri branda i potroša či uključuju ogromnu količinu sadržaja digitalnog marketinga. Eksponencijalni rast digitalnog sadržaja izazvao je izazov predobučenih jezičkih modela poput BERT i GPT kao ključni alat u rješavanju mirijada izazova sa tekstualnim podacima. Ovaj papir pokušava istražiti razinu percepcija znakova (tj. udruženja znakova i atributa slike) tih jezičkih modela. Vjerujemo da bi svaka vrsta predrasude za znak i atributni par mogla utjecati na zadatak klijenta-centralnog downstream kao što su preporučujući sisteme, analizu osjećaja i odgovor na pitanje, na primjer, predložavajući određeni znak u konsekvenciji kada se pitaju za inovativne proizvode. Koristimo sintetičke podatke i podatke o stvarnom životu i prijavimo rezultate usporedbe za pet kontekstualnih LMs, viz. BERT, ROBERTA, DISTILBERT, ALBERT I BART.', 'cs': 'Zkoumání vnímání značky je základní pro marketingové strategie. V tomto ohledu je image značky definovaná sadou atributů (Aaker, 1997) uznáván jako klíčový prvek při indikaci toho, jak je značka vnímána různými zúčastněnými stranami, jako jsou spotřebitelé a konkurenti. Tradiční přístupy (např. průzkumy) ke sledování vnímání značky jsou časově náročné a neefektivní. V éře digitálního marketingu se manažeři značek i spotřebitelé zabývají obrovským množstvím digitálního marketingového obsahu. Exponenciální růst digitálního obsahu poháněl vznik předškolených jazykových modelů, jako jsou BERT a GPT, jako základních nástrojů při řešení nesčetných výzev s textovými daty. Tento článek se snaží zkoumat rozsah vnímání značky (tj. asociace atributů značky a obrazu), které tyto jazykové modely kódují. Jsme přesvědčeni, že jakýkoliv druh zaujatosti pro značku a pár atributů může ovlivnit následné úkoly orientované na zákazníka, jako jsou doporučovací systémy, analýza sentimentů a odpovědi na otázky, např. důsledně navrhnout konkrétní značku při dotazu na inovativní produkty. Používáme syntetická data a reálná data a sestavujeme výsledky porovnání pro pět kontextových LM, tj. BERT, RoBERTa, DistilBERT, ALBERT a BART.', 'et': 'Brändi tajumise uurimine on turundusstrateegiate jaoks väga oluline. Sellega seoses tunnustatakse kaubamärgi kuvandit, mida defineerivad mitmed atribuudid (Aaker, 1997), kui võtmeelementi, mis näitab, kuidas erinevad sidusrühmad, nagu tarbijad ja konkurendid, tajuvad brändi. Traditsioonilised lähenemisviisid (nt uuringud) bränditajude jälgimiseks on aeganõudvad ja ebatõhusad. Digitaalse turunduse ajastul tegelevad nii brändijuhid kui ka tarbijad suure hulga digitaalse turunduse sisuga. Digitaalse infosisu eksponentsiaalne kasv on ajendanud eelõpetatud keelemudelite, nagu BERT ja GPT, esilekerkimist oluliste vahenditena tekstiandmetega mitmete probleemide lahendamisel. Käesolevas töös püütakse uurida, millist ulatust need keelemudelid kodeerivad brändi tajumisel (st brändi ja imago atribuutide seostel). Usume, et igasugune kaubamärgi- ja atribuudipaari eelarvamus võib mõjutada kliendikeskseid järgnevaid ülesandeid, nagu soovitussüsteemid, sentimentaalüüs ja küsimustele vastamine, nt konkreetse kaubamärgi järjepidev soovitamine uuenduslike toodete pärimisel. Me kasutame sünteetilisi andmeid ja reaalseid andmeid ning aruande võrdlustulemusi viie kontekstilise LM jaoks, st. BERT, RoBERTa, DistilBERT, ALBERT ja BART.', 'az': 'Marka görünüşünü araşdırmaq marketing stratejilərinə əslində dəyişdirir. Bu məsələdə, müxtəlif və müəlliflər kimi növbənöv istifadəçilər və müəlliflər kimi növbənöv istifadəçilər tarafından növbənöv əlaqələr təsbit edilən marka surəti (Aaker, 1997). Zəng g örünüşünü gözləmək üçün növbətiyyətli yaxınlıqlar zamanı istifadə etmək və kifayətsizdir. Digital marketing dönüşündə, hem marka müdürləri də, hem müştəqilər çox çox dijital marketing məlumatı ilə iştirak edirlər. Dijital məlumatının eksponensiyal büyüyü, BERT və GPT kimi əvvəlcə təhsil edilmiş dil modellerinin məlumatlarını textual məlumatları ilə çəkmək üçün əsas vasitələr kimi təhsil etdi. Bu kağıt bu dil modellerinin kodlamasının böyüklüyünü incidmək istəyir. Biz inanırıq ki, bir marka və atribut çift üçün hər cür təsirlər müşterilər-centrik a şağı təsirlər sistemlərinə, hisslərin analizi və sual-cavab verməyi, məsələn, yeni proqramlar haqqında soruşduğu zaman müəyyən edilən bir marka təsiri olar. Biz sintetik məlumatları və həyat məlumatlarını istifadə edirik və beş contextual LMs, viz. BERT, ROBERTA, DistilBERT, ALBERT və BART.', 'ca': "Investigating brand perception is fundamental to marketing strategies.  En aquest sentit, la imatge de la marca, definida per un conjunt d'atributs (Aaker, 1997), es reconeix com un element clau en indicar com una marca és perceptida per diverses partes interessats com els consumidors i els competidors. Els enfocaments tradicionals (per exemple, enquestes) per monitoritzar la percepció de les marques són temps consumidors i ineficients. En l'era del màrqueting digital, tant els directors de marcas com els consumidors es dediquen a una gran quantitat de continguts de màrqueting digital. El creixement exponencial del contingut digital ha impulsat l'aparició de models de llenguatge pré-entrenats com BERT i GPT com eines essencials per resoldre molts reptes amb dades textuals. Aquest article busca investigar l'extensió de les percepcions de les marques (i.e., associacions d'atributs de marques i imatges) que codifiquen aquests models lingüístics. Creiem que qualsevol tipus de bias per a una marca i un parell d'atributs pot influir en tasques downstream centrades en el client, com els sistemes de recomanació, l'anàlisi de sentiments i la resposta a preguntes, per exemple, suggerent una marca específica de manera constant quan es demana productes innovadors. Utilitzem dades sintètiques i dades de vida real BERT, RoBERTa, DistilBERT, ALBERT i BART.", 'fi': 'Brändin havainnoinnin tutkiminen on olennaisen tärkeää markkinointistrategioiden kannalta. Tässä suhteessa brändikuva, joka määritellään ominaisuuksien avulla (Aaker, 1997), tunnustetaan keskeiseksi tekijäksi, joka osoittaa, miten eri sidosryhmät, kuten kuluttajat ja kilpailijat, pitävät brändin. Perinteiset lähestymistavat (esim. kyselyt) brändikäsitysten seurantaan ovat aikaa vieviä ja tehottomia. Digitaalisen markkinoinnin aikakaudella sekä brändipäälliköt että kuluttajat käyttävät valtavasti digitaalista markkinointisisältöä. Digitaalisen sisällön eksponentiaalinen kasvu on vauhdittanut esikoulutettujen kielimallien, kuten BERT:n ja GPT:n, syntymistä keskeisiksi työkaluiksi lukuisten tekstidatan haasteiden ratkaisemisessa. Tässä artikkelissa pyritään selvittämään, miten laajasti nämä kielimallit koodaavat brändikäsityksiä (eli brändi- ja imago-attribuuttioita). Uskomme, että mikä tahansa ennakkoluulo brändin ja attribuuttiparin suhteen voi vaikuttaa asiakaslähtöisiin loppupään tehtäviin, kuten suosittelijärjestelmiin, tunteiden analysointiin ja kysymyksiin vastaamiseen, esimerkiksi tietyn brändin johdonmukaiseen ehdottamiseen, kun kysytään innovatiivisista tuotteista. Käytämme synteettistä dataa ja tosielämän dataa sekä raportoimme vertailutuloksia viidelle kontekstuaaliselle LM:lle, ts. BERT, RoBERTa, DistilBERT, ALBERT ja BART.', 'jv': 'Rasané awak-awak sing paling-endimbang kuwi basa kanggo tutorian-endimbang. Nanging kuwi, tengahane sampeyan, dadi nggawe barang nggawe atiribusi Traditional logic (e.g. dipunahayo) to Monitor Punctuation Jejaring Ngubah yang pamungan sing paling Digital kuwi nggawe ngubah jejaring Perintah sing dipunangé nungsaken nglanggar kapan Rong-Pasang Awak dhéwé ngpisan nganggep kuwi cah-cah bias a kanggo awak dhéwé karo nganggep nggawe barang-sistem sing nyimpen, winih dhéwé, lan mbukalungot-suarané, isih: Awak dhéwé ngéwangi sistem data lan data-sistem sing gawe ngupakan karo perusahaan dadi kanggo limo contextual LM, Vis. BERT, RBERT, DistilBERT, ARBERT lan BERT.', 'ha': "Ina ƙidãya fikra na'anar shine na muhimmi ne ga mataimaki. A cikin wannan, an gane shi zane mai tsaro da aka ƙayyade wasu halin (Aakere, 1997), an gane shi kamar wata maɓalli da ke nuna jinin a gane wata tsari na misãlai mai amfani da waɗandasu. Yin zaman shawara (misali, suriyar) dõmin a tsare taskõkin na gannai, yana da amfani da lokaci kuma bã ya kasancẽwa. Ga bayan salon digitali, masu shiryi da mãsu amfani da shi sun yi amfani da abu mai girma cikin salon digitali. Kibuɗe faɗi na tsarin digitali ya promote masu fitarwa na misãlai na harshen zaman-tunkuɗe kamar BERT da GPT kamar zance na muhimu cikin kure masu motsi da data na rubutu. Wannan takardan na neman yin ƙidãya a tsakanin zane-zane (misali, shirin misalin na rubutu da zane) waɗannan kode-zane-zane. Tun yi ĩmãni cẽwa, ko wane irin ɓangare wa wani rubutu da mazaɓa biyu, za su yi amfani da aikin mai shiryarwa na ƙarƙashin mitam kamar masu shawarar da masu shagala, Ana yi anayyar hisani, da kuma masu jibi da tambayar tambaya, misali, yana gaya wata rubutu mai daidaita idan an tambaye wa manunuwan da za'a iya lokaci. @ info @ item: inlistbox KDE dictionary.", 'sk': 'Raziskovanje dojemanja blagovne znamke je bistvenega pomena za marketinške strategije. V zvezi s tem je podoba blagovne znamke, opredeljena z vrsto atributov (Aaker, 1997), priznana kot ključni element pri označevanju, kako različne deležnike, kot so potrošniki in konkurenti, dojemajo blagovno znamko. Tradicionalni pristopi (npr. ankete) za spremljanje zaznavanja blagovne znamke so zamudni in neučinkoviti. V dobi digitalnega trženja se tako vodje blagovnih znamk kot potrošniki ukvarjajo z veliko količino vsebin digitalnega trženja. Eksponentna rast digitalnih vsebin je spodbudila nastanek predhodno usposobljenih jezikovnih modelov, kot sta BERT in GPT, kot bistvenega orodja za reševanje številnih izzivov z besedilnimi podatki. V prispevku želimo raziskati obseg zaznavanja blagovne znamke (tj. povezav znamke in atributov slike), ki jih ti jezikovni modeli kodirajo. Verjamemo, da lahko kakršna koli pristranskost za par blagovne znamke in atributov vpliva na naloge, ki so usmerjene v stranke, kot so sistemi priporočevalcev, analiza čustev in odgovarjanje na vprašanja, npr. dosledno predlaganje določene blagovne znamke, kadar iščete inovativne izdelke. Uporabljamo sintetične podatke in podatke iz realnega življenja ter poročamo rezultate primerjave za pet kontekstualnih LM, tj. BERT, RoBERTa, DistilBERT, ALBERT in BART.', 'he': "חקירת התפיסה של מסומם היא בסיסית לאסטרטגיות השיווק. בנוגע לזה, דמות מסימה, מוגדרת על ידי קבוצת תכונות (Aaker, 1997), מוכרת כאלמנט מפתח בהצבעה איך מסימה מתייחסת על ידי מעניינים שונים כמו לקוחות ומתחרים. גישות מסורתיות (למשל סקריות) כדי לעקוב אחרי התפיסה של מסימות הן משתמשות בזמן ולא יעילות. בתקופת השיווק הדיגיטלי, גם מנהלי הסימנים וגם לקוחות מתעסקים עם כמות גדולה של תוכן השיווק הדיגיטלי. הגידול האקספונציאלי של תוכן דיגיטלי דחף את התפתחות של דוגמני שפת מאומנים מראש כמו BERT וג'י.פי.טי. ככלים חיוניים בפתרון מירידים של אתגרים עם נתונים טקסטיים. העיתון הזה מנסה לחקור את המידה של התפיסה של מסימות (כלומר, איגודים של מסימות ותמונות ותמונות) דוגמני שפה אלה קודים. אנו מאמינים שכל מין ההתמחות לזוג מסומם ואיכויים יכול להשפיע על משימות מרכזיות לקוחות למטה, כמו מערכות ממלצות, ניתוח רגשות, ומעניין שאלות, למשל להציע מסומם מסוים בתקבילות כשמבקשים מוצרים חדשים. אנחנו משתמשים במידע סינטטי ומידע חיים אמיתיים ודווחים על תוצאות השוואה עבור חמישה LMs קונטקסטיים, viz. ברט, רוברטה, דיסטילברט, אלברט ובארט.", 'bo': 'ཟིན་བྲིས་བསམ་བློ་གཏོང་གི་ཐབས་ལམ་ལ་རྨན་གཞུང་ཞིག་ཡིན་པ་རེད། འདི་ལྟ་བུའི་ནང་དུ། མིང་རྟགས་གཟུགས་རིས། ངོ་བོའི་ཁྱད་ཆོས་ཀྱི་སྒྲིག་ཆ་རྐྱེན་པ་ཞིག་གིས་མཐོང རྒྱུན་ལྡན་གྱི་གཟུགས་རིས། དེ་ནི་གྲངས་སྤྱོད་པའི་དུས་ཚན་ནང་དུ་བྱུང་མཁན་ལས་དོ་དམ་པ་དང་ལག་ལེན་པ་ཚོ་གཉིས་ཀྱིས་གྲངས་སྤྱོད་པའི་ནང་དོན་འདུག གྲངས་སྒྲིག་ནང་དོན ཤོག་བྱང་འདིས་སྐད་རིགས་ཀྱི་མིང་དཔེ་རྟགས་ཀྱི་ཆེ་ཆུང་དང་རྣམ་པའི་སྦྲེལ་མཐུད་དེ་ལ་བལྟ་ཞིབ་བྱེད་འདོད་པ་ཡིན། ང་ཚོས་བློ་གཏད་པ་ཞིག་དང་ཁྱད་ཆོས་གཅིག་གི་གནད་དོན་ཡིན་མིན་ན་ལག་ཨིན་པ་-centric downstream tasks དཔེར་ན་གསལ་བཤད་པ་དང་། མི་རྣམ་གྲངས་དབྱེ་སྟངས་དང་། འདྲི་ཚིག་དང་། དཔེར་ན།  ང་ཚོས་རང་ཚོར་སྐྱོན་བརྗོད་བྱ་ཚིག་དང་འཚོལ་བའི་ཆ་འཕྲིན་ཡིག་ཆ་དང་ཐོག་ལས་ཚོར་བསྡུར་བའི་འབྲས་བ་ཚེ། BERT, RoBERTa, DistilBERT, ALBERT དང་ BART.'}
{'en': 'Attention vs non-attention for a Shapley-based explanation method', 'ar': 'الانتباه مقابل عدم الانتباه لطريقة الشرح المبنية على Shapley', 'es': 'Atención frente a falta de atención para un método de explicación basado en Shapley', 'fr': "Attention ou non-attention pour une méthode d'explication basée sur Shapley", 'pt': 'Atenção versus não atenção para um método de explicação baseado em Shapley', 'zh': '盖沙普利之说,注意与非注意也', 'ja': 'Shapleyベースの説明方法に対する注意と非注意', 'ru': 'Внимание или невнимание к методу объяснения на основе Шапли', 'hi': 'एक Shapley-आधारित स्पष्टीकरण विधि के लिए ध्यान बनाम गैर-ध्यान', 'ga': 'Aird vs neamhaird ar mhodh mínithe Shapley-bhunaithe', 'el': 'Προσοχή έναντι μη προσοχής για μια μέθοδο επεξήγησης βασισμένη στο Shapley', 'hu': 'Figyelem kontra figyelem nem figyelem Shapley-alapú magyarázat esetén', 'it': 'Attenzione vs non attenzione per un metodo di spiegazione basato su Shapley', 'mk': 'Внимание против невнимание за метод на објаснување базиран на Шапли', 'lt': 'Atkreipimas į Shapley pagrįstą paaiškinimo metodą', 'ms': 'Perhatian vs tidak-perhatian untuk kaedah penjelasan berdasarkan Shapley', 'ml': 'ശാപ്ലി അടിസ്ഥാനമായി വിശദീകരിക്കുന്ന രീതിയില്\u200d ശ്രദ്ധിക്കുക', 'kk': 'Name', 'mt': 'Attenzjoni kontra nuqqas ta’ attenzjoni għal metodu ta’ spjegazzjoni bbażat fuq Shapley', 'pl': 'Uwaga vs brak uwagi na metodę wyjaśnienia opartą na Shapley', 'ro': 'Atenție vs non-atenție pentru o metodă de explicație bazată pe Shapley', 'mn': 'Шапли-д суурилсан тайлбарлалтын арга болон анхаарал биш,', 'no': 'Name', 'so': 'Attention vs non-attention for a Shapley-based explanation method', 'sv': 'Uppmärksamhet vs icke-uppmärksamhet för en Shapley-baserad förklaringsmetod', 'ta': 'நிழலில் அடிப்படையிலான விளக்கம் முறையில் கவனம் எதிர்பார்ப்பு', 'si': 'Name', 'ka': 'შაპლის განახსნავის მეთოდისთვის დაახსნა', 'ur': 'شیپلی کی بنیادی توضیح طریقہ کے لئے اظہار غیر توجه', 'sr': 'Pažnja protiv ne-pažnje za metodu objašnjenja na Shapley-u', 'uz': 'Name', 'vi': 'Chú ý chống không chú ý đến phương pháp giải thích hình mẫu', 'bg': 'Внимание срещу липса на внимание за метод на обяснение базиран на Shapley', 'de': 'Aufmerksamkeit vs. Nicht-Aufmerksamkeit für eine Shapley-basierte Erklärungsmethode', 'nl': 'Aandacht vs niet-aandacht voor een op Shapley gebaseerde uitleg methode', 'da': 'Opmærksomhed vs. ikke-opmærksomhed for en Shapley-baseret forklaringsmetode', 'ko': 'Shapley 해석 방법에 근거한 주의와 부주의', 'sw': 'Attention vs non-attention for a Shapley-based explanation method', 'fa': 'توجه علیه توجه غیر توجه برای روش توضیح بر اساس شیپلی', 'id': 'Perhatian vs nonperhatian untuk metode penjelasan berdasarkan Shapley', 'hr': 'Pažnja protiv ne-pažnje za metodu objašnjenja na osnovu Shapley a', 'af': 'Name', 'sq': 'Vëmendje kundër jo-vëmendjes për një metodë shpjegimi bazuar në Shapley', 'am': 'ተቃውሞ ሳይታወቅ ለShapley-based ትርጉም', 'hy': 'Ուշադրություն հակառակ ոչ ուշադրությունը Շեփլին հիմնված բացատրության մեթոդի համար', 'bn': 'শ্যাপলি ভিত্তিক ব্যাখ্যা পদ্ধতির জন্য মনোযোগ বিরোধী', 'tr': 'Shapley tabanly düşündirim yöntemi üçin üns berilmeýän', 'ca': 'Attention vs non-attention for a Shapley-based explanation method', 'cs': 'Pozornost versus nepozornost pro metodu vysvětlení založenou na Shapley', 'et': 'Tähelepanu vs tähelepanuväärtus Shapley-põhise seletusmeetodi puhul', 'fi': 'Huomio vs. huomiotta jättäminen Shapley-pohjaisessa selitysmenetelmässä', 'az': 'Shapley tabanlı a çıqlama yöntemi üçün dikkat edilməz', 'bs': 'Pažnja protiv ne-pažnje za metodu objašnjavanja na Shapley-u', 'jv': 'Attribute', 'ha': 'AttAttachment', 'bo': 'ཆ་འཕྲིན་ལྷན་པ་དང་ལྷན་མེད་པའི་ཕྱོགས་སྟོན་ལམ་ལ་བཞག་ནི།', 'sk': 'Pozornost v primerjavi z nepozornostjo za metodo razlage, ki temelji na Shapleyju', 'he': 'תשומת לב נגד לא תשומת לב לשיטת הסבר מבוססת על שיפלי'}
{'en': 'The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks. The extent to which such methods   that are often proposed and tested in the domain of  computer vision    are appropriate to address the explainability challenges in  NLP  is yet relatively unexplored. In this work, we consider Contextual Decomposition (CD)   a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models   and we test the extent to which it is useful for models that contain attention operations. To this end, we extend CD to cover the  operations  necessary for attention-based models. We then compare how long distance subject-verb relationships are processed by models with and without  attention , considering a number of different syntactic structures in two different languages :  English  and  Dutch . Our experiments confirm that CD can successfully be applied for attention-based models as well, providing an alternative Shapley-based attribution method for modern  neural networks . In particular, using  CD , we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.', 'ar': 'شهد مجال الذكاء الاصطناعي القابل للتفسير مؤخرًا انفجارًا في عدد طرق التفسير للشبكات العصبية العميقة غير الخطية للغاية. إلى أي مدى تكون هذه الأساليب - التي غالبًا ما يتم اقتراحها واختبارها في مجال رؤية الكمبيوتر - مناسبة للتعامل مع تحديات قابلية التفسير في البرمجة اللغوية العصبية (NLP) لم يتم استكشافها بعد نسبيًا. في هذا العمل ، نعتبر التحليل السياقي (CD) - طريقة إسناد ميزات الإدخال المستندة إلى Shapley والتي ثبت أنها تعمل بشكل جيد لنماذج البرمجة اللغوية العصبية المتكررة - ونختبر مدى فائدتها للنماذج التي تحتوي على عمليات الانتباه. تحقيقا لهذه الغاية ، نقوم بتمديد القرص المضغوط لتغطية العمليات اللازمة للنماذج القائمة على الانتباه. ثم نقارن بعد ذلك مدى المسافة الطويلة التي تتم بها معالجة علاقات الفاعل والفعل بواسطة النماذج مع الانتباه أو بدون الانتباه ، مع الأخذ في الاعتبار عددًا من الهياكل النحوية المختلفة في لغتين مختلفتين: الإنجليزية والهولندية. تؤكد تجاربنا أنه يمكن تطبيق القرص المضغوط بنجاح على النماذج القائمة على الانتباه أيضًا ، مما يوفر طريقة إسناد بديلة قائمة على Shapley للشبكات العصبية الحديثة. على وجه الخصوص ، باستخدام القرص المضغوط ، أظهرنا أن النموذجين الإنجليزي والهولندي يظهران سلوك معالجة متشابهًا ، ولكن هناك اختلافات ثابتة بين نماذج الانتباه وعدم الانتباه لدينا.', 'pt': 'O campo da IA explicável viu recentemente uma explosão no número de métodos de explicação para redes neurais profundas altamente não lineares. Até que ponto esses métodos – que são frequentemente propostos e testados no domínio da visão computacional – são apropriados para enfrentar os desafios de explicabilidade da PNL ainda é relativamente inexplorado. Neste trabalho, consideramos a Decomposição Contextual (CD) – um método de atribuição de recursos de entrada baseado em Shapley que demonstrou funcionar bem para modelos recorrentes de PNL – e testamos até que ponto é útil para modelos que contêm operações de atenção. Para este fim, estendemos o CD para cobrir as operações necessárias para modelos baseados em atenção. Em seguida, comparamos como as relações sujeito-verbo de longa distância são processadas por modelos com e sem atenção, considerando várias estruturas sintáticas diferentes em duas línguas diferentes: inglês e holandês. Nossos experimentos confirmam que o CD também pode ser aplicado com sucesso para modelos baseados em atenção, fornecendo um método alternativo de atribuição baseado em Shapley para redes neurais modernas. Em particular, usando CD, mostramos que os modelos inglês e holandês demonstram comportamento de processamento semelhante, mas que sob o capô existem diferenças consistentes entre nossos modelos de atenção e não atenção.', 'fr': "Le domaine de l'IA explicable a récemment connu une explosion du nombre de méthodes d'explication pour les réseaux de neurones profonds hautement non linéaires. La mesure dans laquelle de telles méthodes — qui sont souvent proposées et testées dans le domaine de la vision par ordinateur — sont appropriées pour relever les défis d'explicabilité de la PNL est encore relativement inexplorée. Dans ce travail, nous examinons la décomposition contextuelle (CD) — une méthode d'attribution d'entités en entrée basée sur Shapley qui fonctionne bien pour les modèles de PNL récurrents — et nous testons dans quelle mesure elle est utile pour les modèles qui contiennent des opérations d'attention. À cette fin, nous étendons le CD pour couvrir les opérations nécessaires aux modèles axés sur l'attention. Nous comparons ensuite la façon dont les relations sujet-verbe à distance sont traitées par des modèles avec et sans attention, en tenant compte d'un certain nombre de structures syntaxiques différentes dans deux langues différentes\xa0: l'anglais et le néerlandais. Nos expériences confirment que la CD peut également être appliquée avec succès aux modèles basés sur l'attention, fournissant une méthode d'attribution alternative basée sur Shapley pour les réseaux neuronaux modernes. En particulier, à l'aide de CD, nous montrons que les modèles anglais et néerlandais présentent un comportement de traitement similaire, mais que sous le capot, il existe des différences constantes entre nos modèles d'attention et de non-attention.", 'es': 'El campo de la IA explicable ha visto recientemente una explosión en el número de métodos de explicación para redes neuronales profundas altamente no lineales. Todavía no se ha explorado hasta qué punto tales métodos, que a menudo se proponen y prueban en el dominio de la visión artificial, son apropiados para abordar los desafíos de la explicabilidad en la PNL. En este trabajo, consideramos la descomposición contextual (CD), un método de atribución de entidades de entrada basado en Shapley que ha demostrado funcionar bien para modelos de PNL recurrentes, y probamos hasta qué punto es útil para modelos que contienen operaciones de atención. Con este fin, ampliamos el CD para cubrir las operaciones necesarias para los modelos basados en la atención. Luego comparamos cómo las relaciones sujeto-verbo a larga distancia son procesadas por modelos con y sin atención, considerando una serie de estructuras sintácticas diferentes en dos idiomas diferentes: inglés y holandés. Nuestros experimentos confirman que la EC también se puede aplicar con éxito para modelos basados en la atención, proporcionando un método de atribución alternativo basado en Shapley para las redes neuronales modernas. En particular, al usar CD, mostramos que los modelos inglés y holandés demuestran un comportamiento de procesamiento similar, pero que bajo el capó hay diferencias consistentes entre nuestros modelos de atención y falta de atención.', 'ja': '説明可能なAIの分野では、最近、非常に非線形な深層ニューラルネットワークの説明方法の数が爆発的に増加しています。 コンピュータビジョンの領域でしばしば提案され、テストされるこのような方法が、NLPにおける説明可能性の課題に対処するのにどの程度適切であるかは、まだ比較的未解明である。 この研究では、Shapleyベースの入力機能帰属法であるContextual Decomposition (CD)を検討し、再発NLPモデルにうまく機能することが示されており、注意演算を含むモデルにとってどの程度有用かを検証します。 そのために、注目モデルに必要な操作をカバーするようにCDを拡張します。 次に、英語とオランダ語の2つの異なる言語のさまざまな構文構造を考慮して、注意を払っているかどうかにかかわらず、モデルによってどのくらいの距離の主語と動詞の関係が処理されるかを比較します。 私たちの実験は、CDが注意に基づくモデルにもうまく適用できることを確認し、現代のニューラルネットワークに代わるShapleyベースの帰属方法を提供します。 特に、CDを使用すると、英語とオランダ語のモデルが同様の処理挙動を示していることがわかりますが、フードの下では、私たちの注目モデルと非注目モデルの間に一貫した違いがあることがわかります。', 'zh': '说AI近见高非线性深神经网络之说,其数爆炸式长。 此法-常于计算机视领中试-于多大程度上宜解NLP中可解释性挑战,未得其对。 于此之中,吾思上下文分解(CD)——一本于Shapley之输归因,已验于循环NLP效矣——吾试其有用于意也。 是以广其 CD,涵盖其形势。 然后较之以意力,与无意之形相离主语 - 动词关系多长,思两语之多异句法:英语与荷兰语。 吾实验证之,CD亦可以成功于注意,为今世神经网络供一代之Shapley归因法。 用CD者,英国与荷兰相似也;引擎盖者,用意与非意相似也。', 'ru': 'В области объяснимого ИИ недавно произошел взрыв в количестве методов объяснения для высоко нелинейных глубоких нейронных сетей. Степень, в которой такие методы – которые часто предлагаются и тестируются в области компьютерного зрения – подходят для решения проблем объяснимости в NLP, еще относительно не изучена. В этой работе мы рассматриваем контекстное разложение (CD) – метод атрибуции входных признаков на основе Shapley, который, как было показано, хорошо работает для повторяющихся моделей NLP, и мы проверяем, насколько он полезен для моделей, которые содержат операции внимания. С этой целью мы расширяем КР, с тем чтобы охватить операции, необходимые для моделей, основанных на внимании. Затем мы сравниваем, как отношения между субъектом и глаголом на большом расстоянии обрабатываются моделями с вниманием и без внимания, учитывая ряд различных синтаксических структур на двух разных языках: английском и голландском. Наши эксперименты подтверждают, что CD можно успешно применять и для моделей, основанных на внимании, предоставляя альтернативный метод атрибуции на основе Шепли для современных нейронных сетей. В частности, используя CD, мы показываем, что английская и голландская модели демонстрируют сходное поведение обработки, но под капотом есть последовательные различия между нашими моделями внимания и невнимательности.', 'hi': 'समझाने योग्य एआई के क्षेत्र ने हाल ही में अत्यधिक गैर-रैखिक गहरे तंत्रिका नेटवर्क के लिए स्पष्टीकरण विधियों की संख्या में एक विस्फोट देखा है। किस हद तक इस तरह के तरीके - जो अक्सर प्रस्तावित और कंप्यूटर दृष्टि के डोमेन में परीक्षण किए जाते हैं - एनएलपी में व्याख्यात्मकता चुनौतियों को संबोधित करने के लिए उपयुक्त हैं, अभी तक अपेक्षाकृत अनपेक्षित है। इस काम में, हम प्रासंगिक अपघटन (सीडी) पर विचार करते हैं - एक शैप्ले-आधारित इनपुट फीचर एट्रिब्यूशन विधि जिसे आवर्तक एनएलपी मॉडल के लिए अच्छी तरह से काम करने के लिए दिखाया गया है - और हम उस हद तक परीक्षण करते हैं जिसमें यह उन मॉडलों के लिए उपयोगी है जिनमें ध्यान संचालन शामिल हैं। इस अंत तक, हम ध्यान-आधारित मॉडल के लिए आवश्यक संचालन को कवर करने के लिए सीडी का विस्तार करते हैं। फिर हम तुलना करते हैं कि दो अलग-अलग भाषाओं में कई अलग-अलग वाक्यात्मक संरचनाओं पर विचार करते हुए, ध्यान के साथ और बिना मॉडल द्वारा लंबी दूरी के विषय-क्रिया संबंधों को कैसे संसाधित किया जाता है: अंग्रेजी और डच। हमारे प्रयोगों की पुष्टि है कि सीडी सफलतापूर्वक ध्यान आधारित मॉडल के लिए लागू किया जा सकता है के रूप में अच्छी तरह से, आधुनिक तंत्रिका नेटवर्क के लिए एक वैकल्पिक Shapley-आधारित एट्रिब्यूशन विधि प्रदान करते हैं. विशेष रूप से, सीडी का उपयोग करके, हम दिखाते हैं कि अंग्रेजी और डच मॉडल समान प्रसंस्करण व्यवहार का प्रदर्शन करते हैं, लेकिन हुड के तहत हमारे ध्यान और गैर-ध्यान मॉडल के बीच लगातार अंतर हैं।', 'ga': 'Tháinig méadú le déanaí i réimse an AI inmhínithe ar líon na modhanna mínithe do líonraí néaracha doimhne neamhlíneacha. Níl iniúchadh déanta fós ar a mhéid a bhíonn modhanna den sórt sin - a mholtar agus a thástáiltear go minic i réimse fhís an ríomhaire - oiriúnach chun aghaidh a thabhairt ar na dúshláin inmhínithe in NLP. San obair seo, breithnímid ar Dhianscaoileadh Comhthéacsúil (CD) – modh sanntar gné ionchuir atá bunaithe ar Shapley a léiríodh go n-oibríonn sé go maith do mhúnlaí athfhillteacha NLP – agus déanaimid tástáil ar a mhéid atá sé úsáideach do mhúnlaí ina bhfuil oibríochtaí aird. Chuige sin, leathnaímid CD chun na hoibríochtaí atá riachtanach do mhúnlaí aird-bhunaithe a chlúdach. Déanaimid comparáid ansin maidir le cé chomh fada agus a phróiseálann samhlacha le haird agus gan aird ar ghaolmhaireachtaí ábhar-briathar, ag smaoineamh ar roinnt struchtúir chomhréire difriúla in dhá theanga dhifriúla: Béarla agus Ollainnis. Deimhníonn ár dturgnaimh gur féidir CD a chur i bhfeidhm go rathúil ar mhúnlaí aird-bhunaithe freisin, ag soláthar modh leithdháilte eile atá bunaithe ar Shapley do líonraí neural nua-aimseartha. Go háirithe, ag baint úsáide as CD, léirímid go léiríonn samhlacha Béarla agus Ollainnis iompar próiseála cosúil leis, ach go bhfuil difríochtaí comhsheasmhacha idir ár múnlaí aird agus neamhaird faoin gcochall.', 'ka': 'აღწერილი AI-ის პანელი აღმოჩნდა ექსპლეციას, რამდენიმე განახსნავის მეტოვების რაოდენობაში, ძალიან ბოლონური ნეიროლური ქსელებისთვის. რომელიც ეს მეტი - რომელიც ძალიან მოწყვეტილია და ტესტირებულია კომპიუტერის ხედის დიომინში - უფრო საჭიროა NLP-ში განახსნა განახსნა განსაზღვრებელობის განსაზღვრება - არაფერად ამ სამუშაოში, ჩვენ ვფიქრობთ კონტექსტური განკომპოზაცია (CD) - შაფლის დაბათი შეტყობინებული შეტყობინებების მეტი, რომელიც გამოჩვენებულია, რომ მუშაობს რეკონტური NLP მოდელებისთვის - და ჩვენ ვცადოთ ამ მიზეზით, ჩვენ CD-ს გავაზრუნეთ, რომ აღმოჩენოთ მოდელებისთვის მონაცემებისთვის მონაცემები. შემდეგ ჩვენ განსხვავებული სინტექტიკური სტრუქტურების რამდენიმე განსხვავებული ენები: ანგლისური და დონდელისური. ჩვენი ექსპერიმენტები დარწმუნდება, რომ CD შეიძლება მსოფლიოდ დააყენებული მოდელებისთვის დააყენება, რომლებიც აღმოჩენა ალტენტრუმენტური შაპლის დაბათი ატრი განსაკუთრებით, CD გამოყენებული, ჩვენ ჩვენ აჩვენებთ, რომ ანგლისური და დონდენური მოდელები გამოყენებენ განსხვავებული პროცესის ქცევა, მაგრამ ჩვენი მოდელების განსხვავება არსებობს ჩ', 'hu': 'A megmagyarázható AI területe a közelmúltban robbanást tapasztalt a rendkívül nemlineáris mélyneurális hálózatok magyarázatainak számában. Viszonylag feltáratlan, hogy a számítógépes látás területén gyakran javasolt és tesztelt ilyen módszerek milyen mértékben alkalmasak az NLP megmagyarázhatósági kihívásainak kezelésére. Ebben a munkában a Contextual Decomposition (CD) egy Shapley-alapú bemeneti funkció attribúciós módszert veszünk figyelembe, amely jól működik a visszatérő NLP modelleknél, és teszteljük, milyen mértékben hasznos a figyelemműveleteket tartalmazó modelleknél. Ennek érdekében a CD-t kiterjesztjük a figyelem alapú modellekhez szükséges műveletekre. Ezután összehasonlítjuk, hogy a modellek milyen távolsági alany-ige kapcsolatokat dolgoznak fel figyelemmel és anélkül, figyelembe véve számos különböző szintaktikus struktúrát két különböző nyelven: angol és holland. Kísérleteink megerősítik, hogy a CD sikeresen alkalmazható figyelem-alapú modellekhez is, alternatív Shapley-alapú attribúciós módszert biztosítva a modern neurális hálózatok számára. Különösen CD használatával mutatjuk meg, hogy az angol és holland modellek hasonló feldolgozási viselkedést mutatnak, de hogy a motorháztető alatt következetes különbségek vannak figyelmünk és figyelmünk nélküli modelleink között.', 'el': 'Ο τομέας της εξηγητής τεχνητής νοημοσύνης έχει πρόσφατα δει μια έκρηξη στον αριθμό των μεθόδων επεξήγησης για εξαιρετικά μη γραμμικά βαθιά νευρωνικά δίκτυα. Ο βαθμός στον οποίο τέτοιες μέθοδοι, οι οποίες συχνά προτείνονται και δοκιμάζονται στον τομέα της υπολογιστικής όρασης, είναι κατάλληλες για την αντιμετώπιση των προκλήσεων εξηγησιμότητας στο ΝΛΠ, είναι ακόμη σχετικά ανεξερεύνητος. Σε αυτή την εργασία, εξετάζουμε τη μέθοδο απόδοσης χαρακτηριστικών εισαγωγής που έχει αποδειχθεί ότι λειτουργεί καλά για επαναλαμβανόμενα μοντέλα και εξετάζουμε τον βαθμό στον οποίο είναι χρήσιμο για μοντέλα που περιέχουν λειτουργίες προσοχής. Για το σκοπό αυτό, επεκτείνουμε το CD για να καλύψει τις απαραίτητες λειτουργίες για μοντέλα με βάση την προσοχή. Στη συνέχεια, συγκρίνουμε τον τρόπο επεξεργασίας των μεγάλων αποστάσεων σχέσεων υποκειμένου-ρήματος από μοντέλα με και χωρίς προσοχή, λαμβάνοντας υπόψη μια σειρά διαφορετικών συντακτικών δομών σε δύο διαφορετικές γλώσσες: Αγγλικά και Ολλανδικά. Τα πειράματά μας επιβεβαιώνουν ότι το CD μπορεί να εφαρμοστεί με επιτυχία και σε μοντέλα βασισμένα στην προσοχή, παρέχοντας μια εναλλακτική μέθοδο αποδόσεως βασισμένη στο Shapley για τα σύγχρονα νευρωνικά δίκτυα. Ειδικότερα, με τη χρήση του δείχνουμε ότι το αγγλικό και το ολλανδικό μοντέλο παρουσιάζουν παρόμοια συμπεριφορά επεξεργασίας, αλλά κάτω από την κουκούλα υπάρχουν συνεπείς διαφορές μεταξύ των μοντέλων προσοχής και μη προσοχής.', 'it': "Il campo dell'IA spiegabile ha recentemente visto un'esplosione nel numero di metodi di spiegazione per reti neurali profonde altamente non lineari. La misura in cui tali metodi - spesso proposti e testati nel campo della visione informatica - siano appropriati per affrontare le sfide di spiegabilità della PNL è ancora relativamente inesplorata. In questo lavoro consideriamo Contextual Decomposition (CD) - un metodo di attribuzione delle funzionalità di input basato su Shapley che ha dimostrato di funzionare bene per i modelli NLP ricorrenti - e testiamo fino a che punto è utile per i modelli che contengono operazioni di attenzione. A tal fine, estendiamo il CD per coprire le operazioni necessarie per modelli basati sull'attenzione. Confrontiamo quindi le relazioni a distanza soggetto-verbo elaborate da modelli con e senza attenzione, considerando una serie di diverse strutture sintattiche in due lingue diverse: inglese e olandese. I nostri esperimenti confermano che il CD può essere applicato con successo anche per modelli basati sull'attenzione, fornendo un metodo alternativo di attribuzione basato su Shapley per le moderne reti neurali. In particolare, utilizzando il CD, mostriamo che i modelli inglesi e olandesi dimostrano un comportamento di lavorazione simile, ma che sotto il cofano ci sono differenze consistenti tra i nostri modelli di attenzione e di non attenzione.", 'lt': 'The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks.  Šie metodai, kurie dažnai siūlomi ir bandomi kompiuterinės vizijos srityje, yra tinkami NLP paaiškinimo problemoms spręsti, vis dar nėra išnagrinėti. Šiame darbe manome, kad kontekstinė dekompozicija (CD) – Shapley pagrindu pagrįstas įėjimo savybių priskyrimo metodas, įrodytas gerai veikiantis pakartotiniams NLP modeliams – ir bandome, kiek tai naudinga modeliams, kuriuose yra dėmesio operacijų. Šiuo tikslu išplečiame CD, kad apimtų veiksmus, reikalingus dėmesiu pagrįstiems modeliams. Tuomet palyginame, kaip ilgo atstumo objekto ir žodžio santykius tvarko modeliai su dėmesiu ir be jo, atsižvelgiant į įvairias sintaktines struktūras dviem skirtingomis kalbomis: anglų ir olandų kalbomis. Mūsų eksperimentai patvirtina, kad CD galima sėkmingai taikyti ir dėmesiu pagrįstiems modeliams, suteikiant alternatyvų Shapley pagrįstą priskyrimo metodą šiuolaikiniams nerviniams tinklams. In particular, using CD, we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.', 'mk': 'Пологот на објаснливата ВИ неодамна виде експлозија во бројот на објаснувачки методи за високо нелинеарни длабоки неурални мрежи. До каде ваквите методи - кои честопати се предложени и тестирани во доменот на компјутерската визија - се соодветни за решавање на предизвиците за објаснливост во НЛП се сé уште релативно неиспитани. Во оваа работа, ја сметаме Контекстуалната декомпозиција (ЦД) - метод на припишување на внатрешни функции базиран на Shapley кој се покажа дека функционира добро за рецидентни NLP модели - и го тестираме степенот во кој е корисен за моделите кои содржат операции на внимание. За ова, го прошируваме ЦД за да ги покриеме операциите потребни за моделите базирани на внимание. Потоа споредуваме колку долга оддалеченост врските со субјектите се процесирани од модели со и без внимание, земајќи во предвид број различни синтактички структури на два различни јазици: англиски и холандски. Нашите експерименти потврдуваат дека ЦД може успешно да се примени и за модели базирани на внимание, обезбедувајќи алтернативен метод на припишување базиран на Шепли за модерните нервни мрежи. Посебно, користејќи ЦД, покажуваме дека англиските и холандските модели демонстрираат слично однесување на процесорот, но дека под капутата постојат константни разлики помеѓу нашето внимание и моделите без внимание.', 'kk': 'Түсініктіретін AI өрісі жаңа-ақ түсіндіретін түсіндіру әдістерін сызық емес түсіндіретін невралдық желілердің саны көрді. Компьютердің көрінісінің доменінде тексерілген әдістер NLP- деген түсініктердің мәселелерін шешу үшін әлі салыстырмалы түсініктемесіз. Бұл жұмыс ішінде Contextual Decomposition (CD) - Shapley- негіздеген келтіру мүмкіндіктерінің қайталанатын NLP үлгілерінде жақсы жұмыс істеу әдісін қалаймыз. Біз қайталанатын NLP үлгілерінде қайталанатын үлгілер үшін пайдалы шект Бұл үшін, біз CD-ді қажетті үлгілер үшін қолдану үшін қолдануға арналған әрекеттерді кеңейту үшін кеңейту. Содан кейін, қанша ұзындық тақырыпты верб қатынастары үлгілерімен, қанша ұзындық құрылымдарды салыстырып, екі түрлі тілде бірнеше синтактикалық құрылымдарды: ағылшын және Нидерландша Біздің тәжірибелеріміз CD-нің қазіргі невралдық желілердің альтернативті үлгілеріне сәтті қолдануға болады. Ағылшын және Нидерландық моделдері ұқсас процесстердің қасиеттерін көрсетеді, бірақ көпшілігінің астында біздің тәртіпсіздіктеріміз мен тәртіпсіздік үлгілеріміздің арасындағы қасиеттері', 'ms': 'Medan AI yang boleh dijelaskan baru-baru ini telah melihat letupan dalam bilangan kaedah penjelasan untuk rangkaian saraf dalam yang tidak linear tinggi. Sejauh mana kaedah-kaedah seperti itu - yang sering diusulkan dan diuji dalam domain penglihatan komputer - sesuai untuk mengatasi cabaran penjelasan dalam NLP masih relatif tidak dikenalpasti. In this work, we consider Contextual Decomposition (CD) - a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models - and we test the extent to which it is useful for models that contain attention operations.  Untuk tujuan ini, kami memperluas CD untuk menutupi operasi yang diperlukan untuk model berdasarkan perhatian. Kemudian kita membandingkan bagaimana jarak jauh hubungan subjek-verb diproses oleh model dengan dan tanpa perhatian, mempertimbangkan sejumlah struktur sintaktik berbeza dalam dua bahasa berbeza: Bahasa Inggeris dan Belanda. Eksperimen kami mengesahkan bahawa CD boleh berjaya dilaksanakan untuk model berdasarkan perhatian juga, menyediakan kaedah atribut berdasarkan Shapley alternatif untuk rangkaian saraf modern. Terutama, menggunakan CD, kita menunjukkan bahawa model Inggeris dan Belanda menunjukkan perilaku pemprosesan yang sama, tetapi di bawah kapus terdapat perbezaan konsisten antara perhatian kita dan model yang tidak perhatian.', 'ml': 'The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks.  കമ്പ്യൂട്ടര്\u200d ദര്\u200dശനത്തിന്റെ ഡോമെയിനില്\u200d പ്രായശ്ചിത്തമായി പരീക്ഷിക്കപ്പെടുകയും ചെയ്യുന്ന ഇങ്ങനെ രീതികള്\u200d- എംഎല്\u200dപിയിലെ വിശദീകരണവ ഈ പ്രവര്\u200dത്തനത്തില്\u200d, നമ്മള്\u200d കോണ്\u200dട്ടെക്സ്റ്റെക്സ്റ്റല്\u200d ഡികോമ്പോസിഷന്\u200d (സിഡി) - ഒരു ഷാപ്ലി അടിസ്ഥാനമായിട്ടുള്ള ഇന്\u200dപുട്ടിന്റെ വിശേഷപ്രദര്\u200dശിപ്പിക്കുന് ഈ അവസാനത്തിനു വേണ്ടി നമ്മള്\u200d സിഡിയിലേക്ക് വികസിപ്പിക്കുന്നു. ശ്രദ്ധിക്കുന്ന മോഡലുകള്\u200dക്ക്  പിന്നീട് നമ്മള്\u200d എത്ര ദൂരം വിഷയങ്ങളുടെ ബന്ധങ്ങള്\u200d പ്രവര്\u200dത്തിപ്പിക്കുന്നുവെന്ന് തുല്യമാക്കുന്നു. മോഡലുകള്\u200d ശ്രദ്ധിക്കാതെയാണ്  നമ്മുടെ പരീക്ഷണങ്ങള്\u200d സിഡിയില്\u200d വിജയകരമായി ശ്രദ്ധിക്കുന്ന മോഡലുകള്\u200dക്കും വേണ്ടി പ്രയോഗിക്കാന്\u200d സാധിക്കുന്നു എന്ന് ഉറപ്പ് വരുത് പ്രത്യേകിച്ച്, സിഡിയില്\u200d ഉപയോഗിച്ച്, ഇംഗ്ലീഷും ഡച്ചും മോഡലുകളും ഒരേ പ്രക്രിയ നടപടിക്രമങ്ങള്\u200d കാണിക്കുന്നു, പക്ഷെ ഹൂട്ടിന്\u200dറെ കീഴി', 'mt': 'Il-qasam tal-AI spjegabbli dan l-aħħar wera splużjoni fin-numru ta’ metodi ta’ spjegazzjoni għal netwerks newrali profondi mhux lineari ħafna. Il-punt sa fejn metodi bħal dawn - li spiss jiġu proposti u ttestjati fil-qasam tal-viżjoni tal-kompjuter - huma xierqa biex jindirizzaw l-isfidi ta’ spjegabbiltà fil-NLP għadu relattivament mhux esplorat. In this work, we consider Contextual Decomposition (CD) - a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models - and we test the extent to which it is useful for models that contain attention operations.  Għal dan il-għan, aħna jestendu CD biex ikopri l-operazzjonijiet meħtieġa għal mudelli bbażati fuq l-attenzjoni. Imbagħad nipparagunaw kemm ir-relazzjonijiet bejn is-suġġett u l-verb fuq distanza twila jiġu pproċessati minn mudelli b’attenzjoni u mingħajr attenzjoni, filwaqt li nikkunsidraw għadd ta’ strutturi sintattiċi differenti f’żewġ lingwi differenti: l-Ingliż u l-Olandiż. L-esperimenti tagħna jikkonfermaw li CD jista’ jiġi applikat b’suċċess ukoll għal mudelli bbażati fuq l-attenzjoni, billi jipprovdi metodu alternattiv ta’ attribuzzjoni bbażat fuq Shapley għal netwerks newrali moderni. B’mod partikolari, bl-użu tas-CD, nuru li l-mudelli Ingliżi u Olandiżi juru mġiba ta’ pproċessar simili, iżda li taħt il-kappa hemm differenzi konsistenti bejn l-attenzjoni tagħna u mudelli mhux ta’ attenzjoni.', 'pl': "W dziedzinie wytłumaczalnej sztucznej inteligencji doszło ostatnio do eksplozji liczby metod wyjaśniania wysoce nieliniowych głębokich sieci neuronowych. W jakim stopniu takie metody, które są często proponowane i testowane w dziedzinie wizji komputerowej, są właściwe do sprostania wyzwaniom związanym z wytłumaczalnością w NLP, jest jeszcze stosunkowo niezbadane. W niniejszej pracy rozważamy metodę atrybucji cech wejściowych opartą na Shapley, która okazała się dobrze działać dla modeli powtarzających NLP oraz testujemy, w jakim stopniu jest ona przydatna dla modeli zawierających operacje uwagi. W tym celu rozszerzamy CD o operacje niezbędne dla modeli uwagi. Następnie porównujemy, jak długodystansowe relacje podmiot-czasownik są przetwarzane przez modele z uwagą i bez uwagi, biorąc pod uwagę szereg różnych struktur składni w dwóch różnych językach: angielskim i holenderskim. Nasze eksperymenty potwierdzają, że CD można z powodzeniem zastosować również do modeli opartych na uwadze, zapewniając alternatywną metodę atrybucji opartą na Shapley'u dla nowoczesnych sieci neuronowych. W szczególności przy użyciu CD pokazujemy, że model angielski i holenderski wykazuje podobne zachowanie przetwarzania, ale pod maską istnieją konsekwentne różnice między naszymi modelami uwagi a modelami nieuwagi.", 'ro': 'Câmpul AI explicabil a văzut recent o explozie în numărul de metode de explicare pentru rețelele neuronale profunde extrem de non-liniare. Măsura în care astfel de metode - care sunt adesea propuse și testate în domeniul viziunii informatice - sunt adecvate pentru a aborda provocările de explicabilitate din PNL este încă relativ neexplorată. În această lucrare, considerăm Contextual Decomposition (CD) - o metodă de atribuire a caracteristicilor de intrare bazată pe Shapley care s-a dovedit a funcționa bine pentru modelele recurente NLP - și testăm măsura în care este utilă pentru modelele care conțin operațiuni de atenție. În acest scop, extindem CD-ul pentru a acoperi operațiunile necesare modelelor bazate pe atenție. Comparăm apoi cât de lungă distanță sunt procesate relațiile subiect-verb de modele cu și fără atenție, luând în considerare o serie de structuri sintactice diferite în două limbi diferite: engleză și olandeză. Experimentele noastre confirmă că CD-ul poate fi aplicat cu succes și pentru modelele bazate pe atenție, oferind o metodă alternativă de atribuire bazată pe Shapley pentru rețelele neurale moderne. În special, folosind CD, arătăm că modelele engleze și olandeze demonstrează un comportament similar de procesare, dar că sub capotă există diferențe consistente între modelele noastre de atenție și cele de non-atenție.', 'mn': 'Тайлбарлах боломжтой AI-ын талбар саяхан мэдрэлийн гүн гүнзгий мэдрэлийн сүлжээнд маш олон тодорхойлолтын арга замыг харсан. Компьютерийн үзэл дүрэм дээр шийдвэрлэгдэж, шалгаж үзэх ийм арга зам нь NLP-д тайлбарлах боломжгүй сорилтуудыг зохиохын тулд хэрэгтэй. Энэ ажил дээр бид "Contextual Decomposition" (CD) - Шапли-д суурилсан орнуудын харилцааны арга загвар нь дахин дахин ажиллаж байгаа NLP загваруудын хувьд сайн ажиллах боломжтой болсон юм. Мөн бид анхаарлын ажиллагааны загваруудын хувьд хэрхэн хэрэг Энэ төгсгөлд бид CD-г анхаарлын үндсэн загваруудын тулд хэрэгтэй үйл ажиллагааг дэлгэрүүлнэ. Дараа нь бид хоёр өөр хэл дээр олон синтактик бүтээгдэхүүнийг харьцуулж, анхаарлын загвараар хэр урт зай холбоотой вэ гэдгийг харьцуулдаг. Бидний туршилтууд CD-г анхаарлын үндсэн загваруудын тулд амжилттай ашиглаж чадна гэдгийг батладаг. Шапли-н үндсэн өөр арга загваруудыг орчин үеийн мэдрэлийн сүлжээнд хангах арга загвар өгдөг Ялангуяа, CD-г ашиглан, Англи болон Далландын загварууд төстэй процесс үйл ажиллагааг харуулж байна. Гэхдээ бидний анхаарал болон анхаарлын анхаарлын биш загваруудын хооронд төстэй ялгаа байдаг.', 'no': 'Feltet for forklarbare AI har nyleg sett eit eksplosjon i antall forklaringsmetodar for stor ikkje-lineær dyp neuralnettverk. Kor mykje slike metodar - som ofte vert foreslått og testa i domenet for datavising - er tilgjengeleg for å handtera utfordringane for forklaringar i NLP er enno relativt uventa. I denne arbeida ser vi på kontekst- dekomposisjon (CD) - ein funksjonsattribusjonsmetode for inndata basert på Shapley som er vist å fungera bra for gjentaande NLP- modeller - og vi testar kor mykje det er nyttig for modeller som inneheld oppmerksomhetar. I denne slutten utvidar vi CD for å dekka operasjonane som treng for oppmerksbaserte modeller. Vi sammenliknar så kor lang avstandsverktøy av temaverbverb-relasjonar vert handsama av modeller med og utan oppmerksomhet, ved å sjå på mange ulike syntaktiske strukturar i to ulike språk: engelsk og nederlandsk. Eksperimentane våre stadfestar at CD kan vellykkeleg brukast til oppmerksbaserte modeller også, og tilbyr ein alternativ metode for Shapley-basert attribusjon for moderne neuralnettverk. I særskilt bruk av CD viser vi at engelske og nederlandske modelane demonstrerer liknande handlingsmodular, men at under høyden er det konsistent forskjeller mellom våre oppmerksområde og ikkje-oppmerksområde.', 'so': 'beerta AI ee la caddeeyo ugu dhowaan wuxuu arkay baabuur oo ku yaal hababka kala duduwan ee shabakado hoos u dheer oo neurada ah. The extent to which such methods - that are often proposed and tested in the domain of computer vision - are appropriate to address the explainability challenges in NLP is yet relatively unexplored.  Markaas waxan ka fiirsanaynaa daboolka hoose-hoose (CD) - qaab ah oo hoos-hoos u saaran, oo loo muujiyey inuu si wanaagsan u shaqeeyo tusaalayaasha NLP ee soo socda - waxaana imtixaamaynaa darajada ay u faa’iido u leedahay modellada ku haysta waxqabadka digtoonaanta. Taas darteed waxaynu ku fidinnaa CD si aan u daboolno shuqullada loo baahan yahay tusaalaha daryeelka caafimaadka. Markaas waxaynu isbarbardhignaa inta badan xiriirka la xiriira warqada ah waxaa lagu baaraandegayaa tusaale ahaan islamarkaasna aan la tahayn, waxaana ka fiirsanaynaa dhismo kala duduwan oo ku qoran laba luqadood: Ingiriis iyo Holand. Imtixaankayadu waxay xaqiijineysaa in CD lagu codsan karo samooyin aad u taxadaraysan karto, sidoo kale, in lagu siiyo qaab kale oo Shapley ku saleyn karo shabakado nooca ah. Si gaar ah, isticmaalka CD, waxaynu muujinnaa in noocyada Ingiriiska iyo Dutch ay muujiyaan dabeecada isku mid ah, laakiin daboolka hoosteeda waxaa ku jira kala duwanaansho kala duwan oo u dhexeeya fiirsashada iyo modelalka aan la jeedin.', 'sv': 'Inom området förklaringsbar AI har nyligen sett en explosion i antalet förklaringsmetoder för mycket icke-linjära djupa neurala nätverk. I vilken utsträckning sådana metoder - som ofta föreslås och testas inom området datorseende - är lämpliga för att ta itu med förklaringsutmaningarna i NLP är fortfarande relativt outforskade. I detta arbete betraktar vi Contextual Decomposition (CD) - en Shapley-baserad metod för tilldelning av indatfunktion som har visat sig fungera bra för återkommande NLP-modeller - och vi testar i vilken utsträckning det är användbart för modeller som innehåller uppmärksamhetsoperationer. För detta ändamål utökar vi CD till att omfatta den verksamhet som krävs för uppmärksamhetsbaserade modeller. Vi jämför sedan hur långa distansrelationer mellan subjekt och verb behandlas av modeller med och utan uppmärksamhet, med hänsyn till ett antal olika syntaktiska strukturer på två olika språk: engelska och nederländska. Våra experiment bekräftar att CD framgångsrikt kan användas även för uppmärksamhetsbaserade modeller, vilket ger en alternativ Shapley-baserad attributionsmetod för moderna neurala nätverk. Särskilt med hjälp av CD visar vi att de engelska och nederländska modellerna uppvisar liknande bearbetningsbeteende, men att det under huven finns konsekventa skillnader mellan våra uppmärksamhets- och icke-uppmärksamhetsmodeller.', 'si': 'විස්තර කරන්න පුළුවන් AI ක්ෂේත්රයේ අවසානයෙන් ප්\u200dරවේශනයක් දැක්කා ගොඩක් ගොඩක් ගොඩක් න්\u200dයුරෝල් ජාලයේ න පරිගණක දර්ශනයේ පරීක්ෂණය සහ පරීක්ෂණය කරලා තියෙන අවස්ථාව - NLP වලින් පැහැදිලි අවස්ථාවක් තියෙන්න සමහර විශ්වාස කරන්න මේ වැඩේ අපි හිතන්නේ ප්\u200dරතිස්ථිත විස්තරය (CD) - ශාප්ලි විස්තරයෙන් ඇතුළු ඇතුළු විශේෂ විශේෂ විධානය සඳහා හොඳ වැඩ කරන්න පෙන්වන්න පුළුවන මේ අවසානයෙන්, අපි CD විස්තර කරන්න අවශ්\u200dය වැඩ කරන්නේ අවධානය අධාරිත මොඩල් වලට අවශ්\u200dය වැඩ කරන්න. අපි ඊට පස්සේ කොච්චර දුරක් විදියට ප්\u200dරශ්න විදියට සම්බන්ධතා වෙනුවෙන් මොඩේල් එක්ක හා අවධානයක් නැතුව, වෙනස් භාෂාවල අපේ පරීක්ෂණය සාධාරණය කරන්න පුළුවන් කියලා සිඩි එක සමහරවිට අවධානය අධාරිත විද්\u200dයාපයක් සඳහා අවධානය කරන්න පුළුවන විශේෂයෙන්, CD භාවිතා කරන්න, අපි පෙන්වන්නේ ඉංග්\u200dරීසි සහ ඩච්ච් මොඩේල්ස් වල වගේ ප්\u200dරතික්\u200dරියාව පෙන්වන්න පුළුවන් වෙන', 'ta': 'தற்போது விளக்கமுடியாத AI புலம் மிகவும் கோடு இல்லாத நெறிய பிணையங்களின் எண்ணிக்கையில் ஒரு வெடிப்பை பார்த்துள்ளது. கணினி காட்சியின் களத்தில் பெரும்பாலாக பரிந்துரைக்கப்பட்டு சோதிக்கப்படும் இவ்வாறு முறைகளின் அளவு - NLP விளக்கமுடியாத சவால்களை முட இந்த வேலையில், நாம் உள்ளடக்க Decomposition (சிடி) - வடிவமைப்பு அடிப்படையில் உள்ளீடு குணங்கள் கூடுதல் முறைமையை கருதுகிறோம். மீண்டும் நிகழ்வு NLP மாதிரிகளுக்கு நன்றாக வேல இந்த முடிவிற்கு, நாம் சிடி விரிவாக்கி கவனத்தை அடிப்படையான மாதிரிகளுக்கு தேவையான செயல்களை மறை பிறகு நாம் எவ்வளவு நீண்ட தூரத்தை பொருள் சார்ந்த உறவுகளை மாதிரிகளால் செயல்படுத்தப்படுகிறது மற்றும் கவனத்தில்லாமல் ஒப்பிடுகிறோம். பல Our experiments confirm that CD can successfully be applied for attention-based models as well, providing an alternative Shapley-based attribution method for modern neural networks.  In particular, using CD, we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.', 'sr': 'Polje objašnjavajućih AI nedavno je vidio eksploziju u broju metoda objašnjenja za visoko neolinearne duboke neuralne mreže. Koliko su takve metode - koje su često predložene i testovane u domenu kompjuterske vizije - odgovaraju za rješavanje izazova objašnjivosti u NLP-u, još je relativno neobjašnjivo. U ovom poslu razmišljamo o kontekstualnoj dekompoziciji (CD) - metodi privlačenja ulaznih karakteristika na Shapley-u koji je pokazan da dobro funkcioniše za rekonstruirane modele NLP-a - i testiramo koliku je koristan za modele koji sadrže operacije pažnje. Za taj cilj, proširimo CD da pokrijemo operacije potrebne za modele na pažnji. Onda uspoređujemo koliko duge veze sa tema-verbom obrađuju modeli sa i bez pažnje, s obzirom na broj različitih sintaktičkih struktura na dva različita jezika: engleski i holandski. Naši eksperimenti potvrđuju da se CD može uspešno primjenjivati i za modele na osnovu pažnje, pružajući alternativnu metodu privlačenja na osnovu Shapley-a za moderne neuralne mreže. Posebno, koristeći CD, pokazujemo da engleski i holandski modeli pokazuju slièno ponašanje procesa, ali da pod kapuljom postoje konsistentne razlike između naših pažnje i modela neopažnje.', 'ur': 'مفصل صاف صاف صاف صاف صاف صاف صاف صاف صاف طریقوں کی تعداد میں ایک انفجار دیکھا ہے جو بالکل غیر لینی نیورل نیورل نیٹورک کے لئے ہے. جس طرح یہ طریقے - جو اکثر کمپیوٹر دیدئون کے ڈمین میں آزمائش کی جاتی ہیں اور آزمائش کی جاتی ہیں - NLP میں واضح طریقے کی چالوں کے بارے میں بہت مناسب ہیں، اب بھی نسبتا غیر واضح ہے. اس کام میں، ہم نے Contextual Decomposition (CD) کو سمجھ لیا ہے - ایک شاپلی بنیاد رکھی اینپ فوجیٹ کا اضافہ طریقہ جو دکھائی گئی ہے کہ دوبارہ NLP موڈل کے لئے اچھا کام کرے - اور ہم اس طرح امتحان کرتے ہیں جس طرح یہ موڈل کے لئے مفید ہے جو توجه کی عملیات حاوی رکھتے ہیں اس کے لئے ہم سی ڈی کو ڈھیل دیتے ہیں کہ توجه کی بنیادی موڈل کے لئے ضرورت کی عملیات کو پورا کریں۔ اس کے بعد ہم مثال بیان کرتے ہیں کہ کس طرح دور کی دور کی معاملات کے معاملات میں موڈل کے ذریعے اور بغیر توجه کے مطابق، دو مختلف زبانوں میں مختلف سینٹکتیک ساختاروں کی تعداد کی توجه کرتی ہے: انگلیسی اور ڈرچ. ہماری آزمائش کی تصدیق کرتی ہے کہ سی دی موڈل پر بھی موفقیت کے ساتھ کاروبار کر سکتی ہے، جو مدرنی نیورل نیٹورک کے لئے ایک الٹ شیپلی بنیاد آزمائش طریقہ دے رہی ہے. مخصوصا، سی دی استعمال کرتے ہیں، ہم نشان دیتے ہیں کہ انگلیسی اور ڈچ ڈیچ موڈلز ایسی طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح', 'uz': "Yaqinda ko'pchilik AI maydoni juda qiyin qo'l tarmoq tarmoqlarining tarkibi sonlarda eksplosini ko'rdi. Ушбу усуллар - компьютер кўриниши доменидаги маълумотлар таклиф қилинаётган ва тафтиш - NLP тўғрисида аниқ маслаҳатларни талаб қилиш мумкин. In this work, we consider Contextual Decomposition (CD) – a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models – and we test the extent to which it is useful for models that contain attention operations.  Bu hozir uchun biz murakkab qilish modellari uchun kerak amallarni kodlash uchun CD ni uzatimiz. Keyin biz bir necha necha uzun masofadagi masofadagi munosabatlar modellar bilan ishlab chiqarishimizni kamaytamiz, ikkita xil tillarda ko'p bir necha sintaktik tuzuvlarini tasavvur qilamiz: Ingliz va Dutch. Bizning imtiyozlarimizni tasdiqlash imkoniyatlarimizga, CD muvaffaqiyatli foydalanishi mumkin va yangi neyrol tarmoqlari uchun boshqa shaklga hisoblash usulini qoʻllash mumkin. Ko'rsatilgan, CD yordamida biz Ingliz va Dutch modellari bir xil jarayonlarning xuddi ko'rsatadi, lekin odamning ichida bizning taqdimiz va o'xshash modellarimiz orasidagi tofautimiz bor.", 'vi': 'Đồng vực của AI có triển vọng gần đây đã chứng kiến một vụ nổ trong số lượng các phương pháp giải thích cho các mạng thần kinh sâu không tuyến tính cao. Độ sâu mà các phương pháp như vậy Độ cao 8111, thường được đề xuất và thử nghiệm trong lĩnh vực ảo thuật máy tính, bây giờ vẫn chưa được kiểm tra. Trong công việc này, chúng ta xem xét sự phân phối kép (CD) 2;8111; một phương pháp phân biệt tính năng nhập dựa trên hình thể được cho thấy hoạt động tốt cho các mô hình lập chuỗi NLP  8111; và chúng ta thử độ nó có ích cho các mô hình chứa các thao tác tập trung. Vì vậy, chúng tôi mở rộng CD để bao gồm các thao tác cần thiết cho các mô hình tập trung. Sau đó chúng ta so sánh cách các mối quan hệ đối tượng dài hạn được xử lý bởi các mô hình không cần chú ý, xem xét một số cấu trúc cú pháp khác nhau trong hai ngôn ngữ khác nhau: Anh và Hòa Lan. Những thí nghiệm của chúng tôi xác nhận rằng CD cũng có thể được áp dụng với các mô hình dựa trên sự chú ý, cung cấp phương pháp phân bổ khác cho mạng thần kinh tân. Đặc biệt, dùng đĩa CD, chúng tôi cho thấy các mô hình Anh và Hòa Lan có hành vi xử lý tương tự, nhưng dưới lớp mũ có sự khác biệt nhất quán giữa các mô hình chú ý và không chú ý.', 'bg': 'В областта на обяснимия изкуствен интелект наскоро се наблюдава експлозия в броя на обяснителните методи за високо нелинейни дълбоки невронни мрежи. Все още е сравнително неизследвана степента, до която такива методи, които често се предлагат и тестват в областта на компютърното зрение, са подходящи за справяне с обясняемите предизвикателства в НЛП. В тази работа разглеждаме метода за приписване на входни функции, който е доказано, че работи добре при повтарящи се модели на НЛП, и тестваме до каква степен е полезен за модели, които съдържат операции по внимание. За тази цел разширяваме компактдиска, така че да обхване операциите, необходими за моделите, базирани на вниманието. След това сравняваме как отношенията субект-глагол на дълги разстояния се обработват от модели с и без внимание, като се вземат предвид редица различни синтактични структури на два различни езика: английски и холандски. Нашите експерименти потвърждават, че компактдискът може успешно да бъде приложен и за модели, базирани на вниманието, като предоставя алтернативен метод за присвояване на Shapley базиран на съвременни невронни мрежи. По-специално, използвайки компактдиска, показваме, че английските и холандските модели демонстрират подобно поведение на обработка, но че под капака има последователни разлики между нашите модели на внимание и не внимание.', 'nl': 'Het gebied van verklarbare AI heeft onlangs een explosie gezien in het aantal verklaringsmethoden voor zeer niet-lineaire diepe neurale netwerken. In hoeverre dergelijke methoden, die vaak worden voorgesteld en getest op het gebied van computervisie, geschikt zijn om de verklarbaarheidsuitdagingen in NLP aan te pakken, is nog relatief onontdekt. In dit werk beschouwen we Contextual Decomposition (CD) als een Shapley-gebaseerde input feature attributie methode waarvan is aangetoond dat het goed werkt voor terugkerende NLP modellen en we testen in hoeverre het nuttig is voor modellen die aandachtsoperaties bevatten. Daartoe breiden we CD uit tot de bewerkingen die nodig zijn voor aandachtsmodellen. Vervolgens vergelijken we hoe lange afstand subject-werkwoord relaties verwerkt worden door modellen met en zonder aandacht, rekening houdend met een aantal verschillende syntactische structuren in twee verschillende talen: Engels en Nederlands. Onze experimenten bevestigen dat CD ook succesvol kan worden toegepast op attentie-based modellen, wat een alternatieve Shapley-gebaseerde attributiemethode biedt voor moderne neurale netwerken. Met name met behulp van CD laten we zien dat de Engelse en Nederlandse modellen hetzelfde verwerkingsgedrag vertonen, maar dat er onder de motorkap consistente verschillen zijn tussen onze aandacht- en niet-aandacht modellen.', 'hr': 'Polje objašnjavajućih AI nedavno je vidjelo eksploziju u broju metoda objašnjavanja za visoko neolinearne duboke neuralne mreže. Koliko su takve metode - koje su često predložene i testirane u domenu računalnog vizije - odgovarajuće za rješavanje izazova objašnjivosti u NLP-u, još je relativno neobjašnjivo. U ovom poslu razmišljamo o kontekstualnoj dekompoziciji (CD) - metodi privlačenja ulaznih karakteristika na osnovi Shapley a koja je pokazala kako dobro funkcionira za rekonstruirane modele NLP-a - i testiramo mjeru u kojoj je korisno za modele koji sadrže operacije pažnje. Za taj cilj, proširimo CD da pokrijemo operacije potrebne za modele na temelju pažnje. Onda uspoređujemo koliko duge veze s tema-verbom obrađuju modeli s i bez pažnje, s obzirom na broj različitih sintaktičkih struktura na dva različita jezika: engleski i holandski. Naši eksperimenti potvrđuju da se CD može uspješno primjenjivati i za modele na temelju pažnje, pružajući alternativnu metodu privlačenja na temelju Shapley-a za moderne neuralne mreže. Posebno, koristeći CD, pokazujemo da engleski i nizozemski modeli pokazuju slično ponašanje procesa, ali da pod kapuljom postoje konsistentne razlike između naših pažnje i modela neopažnje.', 'da': 'Området for forklarelig AI har for nylig oplevet en eksplosion i antallet af forklaringsmetoder for meget ikke-lineære dybe neurale netværk. I hvilket omfang sådanne metoder - som ofte foreslås og afprøves inden for computersyn - er egnede til at imødegå forklaringsudfordringerne i NLP, er stadig relativt uudforsket. I dette arbejde betragter vi Contextual Decomposition (CD) - en Shapley-baseret input feature attribution metode, der har vist sig at fungere godt for tilbagevendende NLP modeller - og vi tester i hvilket omfang det er nyttigt for modeller, der indeholder opmærksomhedsoperationer. Til dette formål udvider vi CD til at dække de operationer, der er nødvendige for opmærksomhedsbaserede modeller. Vi sammenligner derefter, hvor langdistance subjekt-verbe relationer behandles af modeller med og uden opmærksomhed, idet vi tager hensyn til en række forskellige syntaktiske strukturer på to forskellige sprog: engelsk og hollandsk. Vores eksperimenter bekræfter, at CD med succes kan anvendes til opmærksomhedsbaserede modeller også, hvilket giver en alternativ Shapley-baseret attribution metode til moderne neurale netværk. Især ved hjælp af CD viser vi, at de engelske og hollandske modeller viser lignende bearbejdningsadfærd, men at der under emhætten er konsekvente forskelle mellem vores opmærksomheds- og ikke-opmærksomhedsmodeller.', 'ko': '최근 인공지능을 해석할 수 있는 분야에서 고도의 비선형 심층신경망의 해석 방법이 급증하고 있다.이러한 방법은 컴퓨터 시각 분야에서 자주 제기되고 테스트되는데 그것이 어느 정도에 자연 언어 처리에서의 해석 가능한 도전을 해결하기에 적합한지 아직 분명하지 않다.이 작업에서 우리는 상하문 분해(CD)-Shapley 기반의 입력 특징 귀인 방법을 고려하여 반복적으로 나타나는 NLP 모델에 효과가 있음을 증명하고 주의 조작을 포함하는 모델에 대한 유용도를 테스트했다.이렇게 하려면 CD를 주의력 기반 모델에 필요한 작업으로 확장합니다.그리고 영어와 네덜란드어 두 가지 서로 다른 언어 중의 많은 서로 다른 문법 구조를 고려하여 우리는 주의와 무주의 모델이 원거리 주술 관계를 처리하는 정도를 비교했다.우리의 실험은 CD도 주의 기반 모델에 성공적으로 응용되고 현대 신경 네트워크에 또 다른 Shapley 기반 귀인 방법을 제공할 수 있음을 증명했다.특히 CD를 사용해 영어와 네덜란드어 모델이 비슷한 가공 행위를 보였다는 것을 증명했지만 우리의 주의 모델과 비주의 모델 사이에 일치된 차이가 있었다.', 'de': 'Der Bereich der erklärbaren KI hat in jüngster Zeit eine Explosion in der Anzahl der Erklärungsmethoden für hochgradig nichtlineare tiefe neuronale Netze erlebt. Inwieweit solche Methoden, die häufig im Bereich des Computer Vision vorgeschlagen und getestet werden, geeignet sind, um die erklärbaren Herausforderungen im NLP anzugehen, ist noch relativ unerforscht. In dieser Arbeit betrachten wir Contextual Decomposition (CD) eine Shapley-basierte Eingabefeature-Attributionsmethode, die nachweislich gut für wiederkehrende NLP-Modelle funktioniert, und wir testen, inwieweit sie für Modelle nützlich ist, die Aufmerksamkeitsoperationen enthalten. Zu diesem Zweck erweitern wir CD um die für aufmerksamkeitsbasierte Modelle notwendigen Operationen. Anschließend vergleichen wir, wie lange Distanz Subjekt-Verb-Beziehungen von Modellen mit und ohne Aufmerksamkeit verarbeitet werden, wobei wir eine Reihe verschiedener syntaktischer Strukturen in zwei verschiedenen Sprachen berücksichtigen: Englisch und Niederländisch. Unsere Experimente bestätigen, dass CD auch für aufmerksamkeitsbasierte Modelle erfolgreich angewendet werden kann und eine alternative Shapley-basierte Attributionsmethode für moderne neuronale Netze darstellt. Insbesondere mit CD zeigen wir, dass das englische und das niederländische Modell ein ähnliches Verarbeitungsverhalten aufweisen, aber dass unter der Haube konsistente Unterschiede zwischen unseren Aufmerksamkeits- und Nicht-Aufmerksamkeitsmodellen bestehen.', 'sw': 'Ardhi ya AI inayoelezea hivi karibuni imeshuhudia mlipuko katika idadi ya mbinu za maelezo kwa mitandao ya kisasa isiyo na msingi. The extent to which such methods - that are often proposed and tested in the domain of computer vision - are appropriate to address the explainability challenges in NLP is yet relatively unexplored.  Katika kazi hii, tunachukulia hatua inayotumiwa na mfumo wa kudhalilisha madaraka (CD) - mwelekeo wa kituo kinachotumiwa na msingi unaoonyeshwa kufanya kazi vizuri kwa ajili ya mifano ya NLP yanayoendelea - na tunajaribu kiwango ambacho kinafaa kwa mifano inayohusu shughuli za ufuatiliaji. Mpaka mwishoni huu, tunaongeza CD kwa ajili ya kuweka shughuli zinazohitajika kwa mifano yenye mwangalizi. We then compare how long distance subject-verb relationships are processed by models with and without attention, considering a number of different syntactic structures in two different languages: English and Dutch.  Majaribio yetu yanathibitisha kwamba CD inaweza kutumiwa kwa mafanikio ya mifano yenye msimamo wa ufuatiliaji na pia, kutoa njia mbadala ya kujitolea kwa mitandao ya kisasa ya kisasa. hasa, kwa kutumia CD, tunaonyesha kuwa modeli za Kiingereza na Dutch zinaonyesha tabia za namna hiyo, lakini chini ya pande hilo kuna tofauti tofauti tofauti tofauti kati ya hisia zetu na modeli zisizo za kusikiliza.', 'id': 'Lapangan AI yang dapat dijelaskan baru-baru ini melihat ledakan dalam jumlah metode penjelasan untuk jaringan saraf dalam yang sangat tidak linear. The extent to which such methods - that are often proposed and tested in the domain of computer vision - are appropriate to address the explainability challenges in NLP is yet relatively unexplored.  In this work, we consider Contextual Decomposition (CD) - a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models - and we test the extent to which it is useful for models that contain attention operations.  Untuk tujuan ini, kami memperluas CD untuk menutupi operasi yang diperlukan untuk model berdasarkan perhatian. Lalu kita membandingkan bagaimana jarak jauh hubungan subjek-verb diproses oleh model dengan dan tanpa perhatian, mempertimbangkan sejumlah struktur sintaksi yang berbeda dalam dua bahasa berbeda: Inggris dan Belanda. Eksperimen kami mengkonfirmasi bahwa CD dapat berhasil diterapkan untuk model berdasarkan perhatian juga, menyediakan metode atribut alternatif berdasarkan Shapley untuk jaringan saraf modern. Terutama, menggunakan CD, kami menunjukkan bahwa model Inggris dan Belanda menunjukkan perilaku proses yang sama, tetapi di bawah kapus ada perbedaan konsisten antara perhatian kita dan model yang tidak perhatian.', 'af': "Die veld van verduidelik AI het onlangs 'n eksplosie gesien in die aantal uitduidelingsmetodes vir hoë nie- lineêre diep neuralnetwerke. Die uitbreiding waarmee sodanige metodes - wat dikwels voorgestel word en toegestel word in die domein van rekenaar sien - is geskik om die verduidelikheidsverdigheidsverdigheidsverdighede in NLP te adres is nog relativief ongeverklar. In hierdie werk, ons beoorsaak Konteksual Deskompositie (CD) - ' n Shapley-gebaseerde invoer funksie toewysing metode wat gewys is om goed te werk vir herhaalde NLP modele - en ons toets die uitbreiding waarin dit is nuttig vir modele wat aandag operasies bevat. Na hierdie einde, ons uitbrei CD om die operasies wat nodig is vir aanmerksgebaseerde modele te oordek. Ons vergelyk dan hoe lank afstand onderwerp-verb verhoudings deur modele met en sonder aandag verwerk word, terwyl ons 'n aantal verskillende sintaktiske strukture in twee verskillende tale: Engels en Nederlandse. Ons eksperimente bevestig dat Cd suksesvol kan aangepas word vir aandag-gebaseerde modele ook, en verskaf 'n alternatiewe Shapley-gebaseerde toewysing metode vir moderne neuralnetwerke. In besonderhede, gebruik ons CD, wys ons dat die Engelse en Nederlandse modele soortgelyke verwerking gedrag bevestig, maar dat onder die hoof daar bestaande verskille tussen ons aandag en nie-aandag modele is.", 'fa': 'زمینه های AI قابل توضیح اخیراً در تعداد روش توضیح برای شبکه های عصبی عمیق غیر خطی یک انفجار دیده است. مقداری که این روش\u200cها - که اغلب پیشنهاد می\u200cشوند و در حوزه دید کامپیوتر آزمایش می\u200cشوند - مناسب است برای حل چالش\u200cهای توضیح\u200cپذیری در NLP هنوز نسبتا بی\u200cتوضیح است. در این کار، ما نظر می\u200cگیریم که یک روش ویژه\u200cهای ورودی بنیاد شاپلی برای مدل\u200cهای NLP بازگشت خوب کار می\u200cکند، و ما به اندازه\u200cای که برای مدل\u200cهای توجه دارند مفید است، آزمایش می\u200cکنیم. برای این قسمت، ما سی دی را گسترش می\u200cدهیم تا عملیات نیاز برای مدل\u200cهای بنیاد توجه را پوشش دهیم. سپس ما مقایسه می\u200cکنیم که چقدر رابطه\u200cهای موضوع و کلمه\u200cهای فاصله با مدل\u200cها و بدون توجه، با توجه به تعداد ساختارهای متفاوتی در دو زبان متفاوت: انگلیسی و هلندی پرداخته می\u200cشوند. آزمایشات ما تایید می\u200cکند که سی\u200cدی می\u200cتواند موفق به موفقیت برای مدل\u200cهای بنیاد توجه استفاده می\u200cشود، و به عنوان یک روش تهیه\u200cکننده\u200cای بر اساس شیپلی برای شبکه\u200cهای عصبی مدرن استفاده می\u200cکند. مخصوصا، از استفاده از سی دی، نشان می دهیم که مدل انگلیسی و هلندی رفتار پردازش مشابه را نشان می دهند، ولی در زیر محل تفاوت مشابه بین مدل توجه و توجه غیر توجه ما وجود دارد.', 'sq': 'fusha e AI të shpjeguar ka parë kohët e fundit një shpërthim në numrin e metodave shpjeguese për rrjetet nervore të thella shumë jo-lineare. Mënyra në të cilën metodat e tilla - që shpesh propozohen dhe testohen në fushën e vizionit kompjuterik - janë të përshtatshme për të trajtuar sfidat e shpjegueshmërisë në NLP është ende relativisht e pazgjidhur. Në këtë punë, ne konsiderojmë Dekompozimin Konteksual (CD) - një metodë atribucioni i elementeve të hyrjes bazuar në Shapley që është treguar se funksionon mirë për modelet e përsëritur NLP - dhe ne testojmë shkallën në të cilën është e dobishme për modelet që përmbajnë operacionet e vëmendjes. Për këtë qëllim, ne shtrijmë CD për të mbuluar operacionet e nevojshme për modelet bazuar në vëmendje. Ne pastaj krahasojmë se sa distancë të gjatë lidhjet subjekt-verb procesohen nga modele me dhe pa vëmendje, duke konsideruar një numër strukturash sintaktike të ndryshme në dy gjuhë të ndryshme: anglisht dhe hollandez. Eksperimentet tona konfirmojnë se CD mund të aplikohet me sukses edhe për modele bazuar në vëmendje, duke ofruar një metodë alternative të atribucionit bazuar në Shapley për rrjetet moderne neurale. Në veçanti, duke përdorur CD, ne tregojmë se modelet angleze dhe hollandeze demonstrojnë sjellje të ngjashme procesimi, por nën kapuçin ka dallime të konsistenta midis vëmendjes sonë dhe modeleve jo të vëmendjes.', 'am': 'የአ.আই. መሬት በቅርብ ጊዜ በጥልቅ ጥልቅ የደዌብ መረብ ላይ ያልተረፈ የጥልቅ የጥልቅ የጥልቅ ጥረት ጥያቄ የሚደረገውን የውጤት አግኝቷል፡፡ በኮምፒውተር ራእይ ውስጥ እንደዚህ ዓይነት ልማድ - ብዙ ጊዜም በተመሳሳይና በሚፈትኑት የኮምፒዩተር ራእይ ውስጥ - የNLP የግልጽን የግልጽ ጥቃት ገና በተለየ ፍላጎት ያልታወቀ ነው፡፡ በዚህ ስራ ውስጥ የውይይት አካባቢ አካባቢ (CD) - በShapley-based የinput attribution method - ለቀጥተኛ NLP ሞዴላዎች መልካም ለመሥራት የተገለጸ ነው - እና በቁጥጥር ለሞዴላዎች የሚጠቅመውን ቁጥጥር እንሞክራለን፡፡ ለዚህ መጨረሻ፣ ለጥያቄ ምሳሌዎች የሚያስፈልገውን ስርዓቶች ለማክበር ሲዲን እንጨርጋለን፡፡ ከዚያም በኋላ የሩቅ ጉዳዩ-የቃላት ግንኙነት እንዴት ያህል እንደተቃውሞ እና ያለ ማስታወቂያ እንደሆነ እናሳስመስላለን፤ በተለያዩ ቋንቋዎች፣ እንግሊዘኛ እና ዶሎክ፡፡ ፈተናዎቻችን ሲዲዲ በጥቅምት የተመሳሳይ እና በጥቅምት የተመሳሳይ ጥያቄ ላይ የተመሳሳይ የናውሬል መረብ ላይ የተመሳሳይ የጥያቄ ድርጅት እንዲሰጥ እንዲችል ያረጋግጣሉ፡፡ በተለይም CD በመጠቀም እንግሊዘኛ እና ድል ሞላት መሰላቸውን የሥርዓት ሥርዓት ማሳየት እናደርጋለን፤ ነገር ግን ከሀገራው በታች በጥያቄያችን እና በማይጠያየቅ ሞዴላዎች መካከል የሚተያየው ልዩነት አሉ፡፡', 'bn': 'সম্প্রতি ব্যাখ্যাত AI-এর ক্ষেত্রে ব্যাখ্যা করা হয়েছে যে ব্যাখ্যা ব্যাখ্যা করা হয়েছে তার সংখ্যা ব্যাখ্যার মাধ্যমে ব কোন ধরনের পদ্ধতি- যা প্রায়শ কম্পিউটার ভিশনের ডোমেইনে প্রস্তাব করা এবং পরীক্ষা করা হয়- এনএলপির ব্যাখ্যাত চ্যালেঞ্জের ব্যাখ্যা করার জন্য এই কাজে আমরা বিভিন্ন বিষয়বস্তু (সিডি) - একটি শ্যাপলি ভিত্তিক ইনপুট বৈশিষ্ট্যাবলিক বৈশিষ্ট্যের মাধ্যমে পুনরায় এনএলপি মডেলের জন্য ভালো কাজ করার জন্য প্রদর্শন করা হয়েছ To this end, we extend CD to cover the operations necessary for attention-based models.  তারপর আমরা দুই ভাষায় বিভিন্ন ভিন্ন ভিন্ন ভাষায় বিভিন্ন সিন্ট্যাক্টিক কাঠামো বিবেচনা করি, ইংরেজি এবং ডাচ। আমাদের পরীক্ষা নিশ্চিত করেছে যে সিডি সফলভাবে মনোযোগ মোডেলের জন্য প্রয়োগ করা যাবে এবং আধুনিক নিউরেল নেটওয়ার্কের জন্য একটি বিকল্প শ্যা In particular, using CD, we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.', 'tr': "Aňlanabilýän AI sahypasy ýakynda ýokary çyzgyly döwletler üçin düşündirilmeýän netral netrallaryň sanynda patlamasyny gördü. NLP'deki düşündirilebilirlik kynçylyklary çözmek üçin (köplenç teklip edilen we maslahat edilen) netijesi kompýuter görünüşünde nähili döwletlere golaýdyr. Bu işde, Kontekst Beýik gabdalyk (CD) diýip pikir edýäris - Shapley tabanly gabdaly gaýd etmek üçin bir NLP modelleri üçin gowy işleýär we üns beren modelleriň üçin ullanyşyny barýarys. Bu üçin, biz CD-i üns daýanýan nusgalar üçin gerekli işleri örtmek üçin genişletip uzadyrys. Soňra tema-verb ilişkileri örän uzak nusga bilen örän üns berilýän nusga bilen we üns berilmeýän nusga bilen, iki dürli dilde birnäçe dürli syntaktik strukturlary düşünýäris: Iňlisçe we Holandiýa. Biziň deneylerimiz CD üns tabanly nusgalara hem başarıyla üýtgedilip biler diýip pikir edýärler. Şol günümizdeki nusgalar üçin Shapley tabanly takyklama yöntemi üýtgedip biler. Aýratyn CD ullanýarys, iňlisçe we holandiýa nusgalaryň meňzeş işleýän davranışyny görkezýäris, ýöne bu nusgalaryň altynda dikkatimiz we üns etmeýän nusgalarymyzyň arasyndaky düýbürlikleri bar.", 'bs': 'Polje objašnjavajućih AI nedavno je vidio eksploziju u broju metoda objašnjavanja za visoko neolinearne duboke neuralne mreže. Koliko su takve metode - koje su često predložene i testirane u domenu kompjuterske vizije - odgovarajuće za rješavanje izazova objašnjivosti u NLP-u, još je relativno neobjašnjivo. U ovom poslu razmišljamo o kontekstualnoj dekompoziciji (CD) - metodi privlačenja ulaznih funkcija na Shapley-u koja je pokazala kako dobro funkcioniše za rekonstruirane modele NLP-a - i testiramo mjeru u kojoj je korisno za modele koji sadrže operacije pažnje. Za taj cilj, proširimo CD da pokrijemo operacije potrebne za modele na osnovu pažnje. Onda uspoređujemo koliko duge veze s tema-verbom obrađuju modeli sa i bez pažnje, s obzirom na broj različitih sintaktičkih struktura na dva različita jezika: engleski i holandski. Naši eksperimenti potvrđuju da se CD može uspješno primjenjivati i za modele na osnovu pažnje, pružajući alternativnu metodu privlačenja na osnovu Shapley-a za moderne neuralne mreže. Posebno, koristeći CD, pokazujemo da engleski i holandski modeli pokazuju slično ponašanje procesa, ali da pod kapuljom postoje konsistentne razlike između naših pažnje i modela neopažnje.', 'cs': 'V oblasti vysvětlitelné umělé inteligence v poslední době došlo k explozi počtu metod vysvětlení vysoce nelineárních hlubokých neuronových sítí. Rozsah, do jaké jsou tyto metody, které jsou často navrženy a testovány v oblasti počítačového vidění, vhodné pro řešení výzev vysvětlitelnosti v NLP, je dosud relativně neprozkoumán. V této práci uvažujeme o metodě atribuce vstupních vlastností založené na Shapley, která funguje dobře pro recidivující NLP modely a testujeme, do jaké míry je užitečná pro modely obsahující operace pozornosti. Za tímto účelem rozšíříme CD o operace potřebné pro modely založené na pozornosti. Následně porovnáme, jak jsou vztahy subjektu-slovesa na dlouhou vzdálenost zpracovávány modely s pozorností a bez pozornosti, s ohledem na řadu různých syntaktických struktur ve dvou různých jazycích: angličtině a nizozemštině. Naše experimenty potvrzují, že CD lze úspěšně aplikovat i na modely založené na pozornosti, což poskytuje alternativní Shapleyovou atribuční metodu pro moderní neuronové sítě. Zejména pomocí CD ukazujeme, že anglický a nizozemský model vykazují podobné chování zpracování, ale že pod kapotou existují konzistentní rozdíly mezi našimi modely pozornosti a modely bez pozornosti.', 'ca': "The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks.  The extent to which such methods - that are often proposed and tested in the domain of computer vision - are appropriate to address the explainability challenges in NLP is yet relatively unexplored.  En aquesta feina, considerem la descomposició contextual (CD) - un mètode d'atribució de característiques d'entrada basat en Shapley que ha demostrat que funciona bé per a models recurrents de NLP - i compruem el punt en què és útil per models que contén operacions d'atenció. Per això estendem CD per cobrir les operacions necessàries per a models basats en l'atenció. Llavors comparem com de llarga distància les relacions subjecte-verb es processen per models amb i sense atenció, considerant una sèrie d'estructures sinàctiques diferents en dues llengües diferents: anglès i holandes. Els nostres experiments confirmen que el CD també es pot aplicar amb èxit a models basats en l'atenció, proporcionant un mètode alternativ d'atribució basat en Shapley per a xarxes neurals modernes. En particular, utilitzant CD, demostram que els models anglès i holandeses demostren comportaments de processament semblants, però que sota el capítol hi ha diferències consistents entre la nostra atenció i els models sense atenció.", 'et': 'Selgitatava tehisintellekti valdkonnas on hiljuti nähtud plahvatust väga mittelineaarsete sügavate närvivõrkude seletusmeetodite arvus. Kui palju sellised meetodid, mida sageli pakutakse välja ja testitakse arvutinägemise valdkonnas, sobivad uue õppekava seletatavusprobleemide lahendamiseks, on veel suhteliselt uurimata. Käesolevas töös käsitleme kontekstuaalset dekompositsiooni (CD) - Shapley-põhist sisendifunktsioonide omistamise meetodit, mis on näidanud toimivat korduvate NLP mudelite puhul - ja testime, mil määral on see kasulik tähelepanu operatsioone sisaldavate mudelite puhul. Selleks laiendame CD-d tähelepanupõhiste mudelite jaoks vajalikele toimingutele. Seejärel võrdleme, kuidas teema-verbi suhteid käsitletakse tähelepanuta ja tähelepanuta mudelites, arvestades erinevaid süntaktilisi struktuure kahes erinevas keeles: inglise ja hollandi keeles. Meie eksperimendid kinnitavad, et CD-d saab edukalt rakendada ka tähelepanupõhistele mudelitele, pakkudes alternatiivset Shapley-põhist atributsioonimeetodit kaasaegsetele närvivõrkudele. CD kasutades näitame eelkõige, et Inglise ja Hollandi mudelid näitavad sarnast töötlemiskäitumist, kuid kapoti all esineb järjepidevaid erinevusi meie tähelepanu- ja tähelepanuta jätmise mudelite vahel.', 'az': 'Açıqlanabilir AI sahəsi çox yaxın zamanda çox çətin nöral ağları üçün açıqlama metodlarının sayısında bir patlama gördü. NLP\'deki açıq-aydınlıq çətinliklərini çəkmək üçün bu metodlar - çox dəfə təbliğ edilən və sınaqlanan kompjuter görünüşünün domeinində təşkil edilən və təşkil edilən münasibdir. Bu işdə, biz "Contextual Decomposition" (CD) – Shapley-ə dayanan giriş fəaliyyəti təmizləmə metodlarını düşünürük. NLP modelləri üçün daha yaxşı çalışmaq üçün göstərilmişdir. Bütün bunlara görə, biz CD\'yi dikkati modellərə görə ehtiyacı olan işləri örtüb genişləyirik. Sonra, müxtəlif dillərdə bir neçə müxtəlif sintaktik quruları ilə modellər ilə işlədiləcək və təsirsiz işlədiləcək müxtəlif məsələlər ilə qarşılaşdırırıq: İngilizce və Holanda. Bizim təcrübələrimiz CD\'nin dikkati daxilində olan modellərə də müvəffəqiyyətlə uygulanabileceğini təsdiqləyir, modern nöral ağları üçün Shapley tabanlı başqa bir təcrübə metodu təklif edir. Özellikle, CD vasitəsilə, İngilizci və Holandi modellərin bənzər işləmə davranışlarını göstərdiyini göstərdik, amma qeyd altında dikkatimiz və dikkatimiz olmayan modellərin arasında müxtəlif fərqlər vardır.', 'hy': 'The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks.  Այսպիսի մեթոդները, որոնք հաճախ առաջարկում են և փորձարկում են համակարգչային տեսողության ոլորտում, համապատասխանում են ՆԼՊ-ի բացատրելիության խնդիրներին լուծելու համար, դեռևս համեմատաբար չեն ուսումնասիրել: Այս աշխատանքի ընթացքում մենք համարում ենք Կոնտեքստալ Դեկոմպոզիցիայի (CD) մեթոդ, որը հիմնված է Շեփլեյի ներմուծի հատկանիշների հատկանիշների հատկանիշների մեթոդ է, որը ցույց է տալիս, որ լավ է աշխատում կրկնվող ՆԼՊ մոդելների համար, և մենք ստուգում ենք To this end, we extend CD to cover the operations necessary for attention-based models.  Այնուհետև մենք համեմատում ենք, թե որքան երկար հեռավորության թեմա-բայ հարաբերությունները վերլուծում են մոդելներով ուշադրության հետ և առանց, հաշվի առնելով տարբեր սինտակտիկ կառուցվածքներ երկու տարբեր լեզուներում՝ անգլերեն և հոլանդ Մեր փորձարկումները հաստատում են, որ CD-ը կարող է հաջողությամբ կիրառվել նաև ուշադրության հիմնված մոդելների համար, տրամադրելով այլընտրանքային ShaPLY-ի հիմնված հատկագրման մեթոդ ժամանակակից նեյրոնական ցանցերի համար: Հատկապես, օգտագործելով CD-ը, մենք ցույց ենք տալիս, որ անգլերենի և հոլանդացի մոդելները ցույց են տալիս նման վերամշակման վարքագիծ, սակայն գլխարկի տակ կա համեմատական տարբերություններ մեր ուշադրության և ոչ ուշադրության մոդելների միջ', 'fi': 'Selittävän tekoälyn kentällä on viime aikoina ollut räjähdysmäinen määrä selittämismenetelmiä erittäin epälineaarisille syvähermoverkoille. Sitä, missä määrin tällaiset menetelmät, joita usein ehdotetaan ja testataan tietokonenäön alalla, soveltuvat vastaamaan selittettävyyshaasteisiin NLP:ssä, on vielä suhteellisen tutkimatonta. Tässä työssä tarkastellaan kontekstual decompositionia (CD) - Shapley-pohjaista syöttöominaisuuden määritysmenetelmää, jonka on osoitettu toimivan hyvin toistuvissa NLP-malleissa - ja testaamme, missä määrin se on hyödyllinen huomiotoimintoja sisältävissä malleissa. Tätä varten laajennamme CD:n kattamaan huomiopohjaisten mallien edellyttämät toiminnot. Tämän jälkeen vertaamme kuinka pitkän matkan subjekti-verbi-suhteita käsitellään malleissa huomiotta ja huomiotta ottaen huomioon useita erilaisia syntaktisia rakenteita kahdella eri kielellä: englanti ja hollanti. Kokeet vahvistavat, että CD:tä voidaan soveltaa menestyksekkäästi myös huomiopohjaisiin malleihin, tarjoten vaihtoehtoisen Shapley-pohjaisen määritysmenetelmän nykyaikaisille hermoverkoille. Erityisesti CD:n avulla osoitamme, että englanninkieliset ja hollantilaiset mallit osoittavat samanlaista prosessointikäyttäytymistä, mutta että konepellin alla on johdonmukaisia eroja huomio- ja huomiokyvyttömyysmallien välillä.', 'sk': 'Na področju pojasnljive umetne inteligence je pred kratkim prišlo do eksplozije števila metod pojasnjevanja zelo nelinearnih globokih nevronskih omrežij. Obseg, v katerem so takšne metode, ki se pogosto predlagajo in preizkušajo na področju računalniškega vida, primerne za obravnavanje izzivov pojasnljivosti pri NLP, je še razmeroma neraziskan. V tem delu obravnavamo kontekstualno razgradnjo (CD) - metodo dodeljevanja vhodnih funkcij, ki temelji na Shapleyju, za katero je bilo dokazano, da dobro deluje pri ponavljajočih se modelih NLP - in testiramo, v kolikšni meri je uporabna pri modelih, ki vsebujejo operacije pozornosti. V ta namen CD razširimo na operacije, potrebne za modele, ki temeljijo na pozornosti. Nato primerjamo, kako razmerja med subjekti in glagoli na dolgi razdalji obdelujejo modeli s pozornostjo in brez nje, pri čemer upoštevamo številne različne sintaktične strukture v dveh različnih jezikih: angleščini in nizozemščini. Naši eksperimenti potrjujejo, da je CD mogoče uspešno uporabiti tudi za modele, ki temeljijo na pozornosti, in zagotavljajo alternativno metodo pripisovanja na osnovi Shapleyja za sodobna nevronska omrežja. Zlasti z uporabo CD-ja pokažemo, da angleški in nizozemski modeli kažeta podobno obdelavo, vendar so pod pokrovom dosledne razlike med modeli pozornosti in nepozornosti.', 'jv': 'deep Kowe mesthi apik karo hal-hal sing sampeyan karo hal-hal bisa nguasai sak ujian ing domain komputer In this job, we count contextual Deompposition Nambah iki, kita ngubah cd kanggo ngilangno operasi layanan kanggo model sing isingan atens Awak dhéwé ngerasakno piye pangan langgar sampeyan Subject-verb resmi sing nyeasakno karo model karo ngono kuwi kesempatan, nggunakake sistem sing sampeyan sampeyan sampeyan karo langgar sampeyan: Inggris karo Pak holandh. Awak dhéwé éntuk dhéwé ngerasahi Cdromek iso nguasai nggawe modèlan sing wis nguasai nggawe barang nggawe tarjamahan, supoyo akeh sistem anyar sumungot na shapely Genjer-Genjer, iso nggambar cd, kita ngomong nik model ingkang karo Pak holes kuwi bisa diuntingi podho operasi sing mengko, nangut nguasai karo nguasai kapan karo perusahaan langgar sampeyan ingkang sampeyan ingkang sampeyan ingkang sampeyan ingkang sampeyan ingkang sampeyan pakan.', 'ha': "Bayyar AI da ake fassarawa a yanzu ya gane wata firgita cikin ƙidãyar shiryoyin ayuka na bayyana wa zanayen masu tsari na masu tsarin taruwar neural na sarki. @ action: button A cikin wannan aikin, munã bincike da tsarin Dekkomposition (CDs) - wata shirin cikin shirin ayuka na Shafi wanda aka nuna shi don ya aikata aiki mai kyau wa misãlai na NLP wanda aka sake koma-bayan - kuma muna jarraba gwargwadon da yake ya amfani da shi ga misãlai wanda ke ƙunsa da aikin muhimmanci. Ga wannan, Munã faɗa cd dõmin mu rufe aikin da za'a buƙata zuwa misali masu bincike. Sa'an nan kuma, muna samfani da gwargwadon zumunta masu nau'i da mazaɓa masu nau'i da misãlai, kuma bã da saurãre, kuma masu bincike da wasu bakwai masu taratiki cikin lugha biyu dabam-dabam: Ingiriya da Dukkan. Kayan jarrabõnmu sun gaskata cewa za'a saka wa CDs a sami da misãlai masu bincike, da kuma a sami wata hanyor cire-na-Shappy-da-yanzu zuwa zanen neural na yanzu. Kayyai, da amfani da CDs, muna nuna misãlai Ingiriya da Dutsu sun nuna aikin aiki mai kama da shi, kuma amma, a ƙarƙashin bangonmu akwai diffaniki mai daidai a tsakanin aikin mu da misãlai masu bincike.", 'bo': 'གནད་དོན་འགྲེལ་བཤད་རུང་བའི་AI་གི་སྒོ་ཕྱེ་བ་དེ་ཉེ་ཆར་ཡོད་པ་དེ་ཉིད་ཆས་རང་ཉིད་ཀྱི་དྲ་རྒྱ་ལ་ཉིད་ལ་སྐྱེས་ཉེན NLP ནང་གི་འགྲེལ་བཤད་ཀྱི་གདོང་ལེན་ཚད་དཔག་ཡོད་པ་དང་རྩིས་འཁོར་ཐོག་གི་མཐོང་ཐོག་ཏུ་བརྟག་ཞིབ་བྱེད་པའི་གནས་སྟངས In this work, we consider Contextual Decomposition (CD) - a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models - and we test the extent to which it is useful for models that contain attention operations. མཇུག་མམ་དེ་ལ། འོད་ཀྱིས་འོད་སྡེར་སྒྲུབ་འདོད་བྱས་པའི་བྱ་སྤྱོད་ཚོར་མཁན་མཐུན་ཡོད་པ We then compare how long distance subject-verb relationships are processed by models with and without attention, considering a number of different syntactic structures in two different languages: English and Dutch. ང་ཚོའི་བརྟག་ཞིབ་ཀྱིས་འོད་སྡེར་སྟེང་གི་གནད་དོན་བཟོ་བྱས་ན་མཐར་འཁྱོར་སྐྱོད་བྱས་ཡོད་པ་དང་མཐུན་སྒྲིག་གི་ཐབས་ལམ་ལ་ཉ ང་ཚོས་རང་ཉིད་ཀྱི་འོད་སྡེར་སྤྱོད་སྤྱད་པར་ཨིན་རིས་དང་རྒྱ་ནག་གི་མིག་དཔེ་གཟུགས་རིས་ཀྱིས་ལས་སྦྱོར་བྱ་སྟངས་དང་མཐུན་རྐྱེན་པའི་', 'he': 'השדה של AI הסביר ראה לאחרונה פיצוץ במספר שיטות הסבר לרשתות עצביות עמוקות מאוד לא לינריות. המידה שבה שיטות כאלה - שלעתים קרובות מציעות ומבחנות בתחום חזון המחשב - מתאימות להתמודד עם אתגרי ההסבירות ב-NLP עדיין לא נחקרת יחסית. בעבודה הזו, אנו שוקלים את התפרצות הקונקסטית (CD) - שיטת שימוש של תכונות הכניסה מבוססת על Shapley שהוכיח לעבוד היטב עבור דוגמנים NLP חוזרים - ואנחנו בודקים את המידה עד כמה זה שימושי עבור דוגמנים שמכילים פעולות תשומת לב. למטרה זו, אנו ממשיכים את הדיסק כדי לכסות את המבצעים הנדרשים לדוגמנים מבוססים על תשומת לב. ואז נשווה כמה מערכות יחסים מרחק ארוך נושא-אלברים מתעסקות על ידי דוגמנים עם ולא תשומת לב, בהתחשב במספר מבנים סינטקטיים שונים בשתי שפות שונות: אנגלית ולנדית. הניסויים שלנו מאשרים שדיסק ניתן להשתמש בהצלחה גם במודלים מבוססים על תשומת לב, ומספקים שיטה אלטרנטיבית של שיפלי מבוססת שיפוט לרשתות עצביות מודרניות. In particular, using CD, we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.'}
