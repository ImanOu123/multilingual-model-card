{'en': 'Modeling Discourse Structure for Document-level Neural Machine Translation', 'pt': 'Modelagem da estrutura do discurso para tradução automática neural em nível de documento', 'ar': 'نمذجة هيكل الخطاب للترجمة الآلية العصبية على مستوى الوثيقة', 'fr': 'Modéliser la structure du discours pour la traduction automatique neuronale au niveau du document', 'es': 'Modelado de la estructura del discurso para la traducción automática neuronal a nivel de documento', 'ja': '文書レベルのニューラル・マシン・トランスレーションのためのモデリング・ディスコース構造', 'zh': '文档级神经机器译语构建模', 'ru': 'Моделирование структуры дискурса для нейронного машинного перевода на уровне документа', 'hi': 'मॉडलिंग प्रवचन संरचना दस्तावेज़ स्तर तंत्रिका मशीन अनुवाद के लिए', 'ga': 'Struchtúr Dioscúrsa Samhaltaithe le haghaidh Aistriúchán Inneall Néarach ar leibhéal Doiciméad', 'el': 'Μοντελοποίηση δομής συζήτησης για νευρολογική μηχανική μετάφραση σε επίπεδο εγγράφου', 'hu': 'Beszédstruktúra modellezése dokumentumszintű idegszintű gépi fordításhoz', 'lt': 'Dokumentų lygio neurologinių mašinų vertimo diskurso struktūros modeliavimas', 'it': 'Modellazione della struttura del discorso per traduzione automatica neurale a livello di documento', 'kk': 'Құжат деңгейіндегі невралдық машинаның аудармасының дискурстар құрылғысын үлгілеу', 'mk': 'Name', 'ms': 'Name', 'ml': 'രേഖയുടെ ന്യൂറല്\u200d മെഷീന്\u200d പരിഭാഷപ്പെടുത്തുന്നതിനുള്ള മോഡോളിങ് ഡിസ്കോര്\u200dസ് സ്ട്രൂക്ടേറ്റ', 'mt': 'Mudellar tal-Istruttura tad-Diskors għat-Traduzzjoni tal-Makkinarju Newrali fil-livell tad-Dokument', 'mn': 'Документын түвшинд мэдрэлийн машин хөгжүүлэх хэлбэрийн бүтэц загварчлал', 'no': 'Comment', 'ka': 'Comment', 'pl': 'Modelowanie struktury dyskursu dla neuronowego tłumaczenia maszynowego na poziomie dokumentu', 'ro': 'Modelarea structurii discursului pentru traducerea automată neurală la nivel de document', 'sr': 'Modeliranje strukture diskursa za prevod neuralne mašine na nivou dokumenta', 'si': 'Comment', 'so': 'Modeling Discourse Structure for Document-level Neural machine Translation', 'sv': 'Modellering av diskursstruktur för neural maskinöversättning på dokumentnivå', 'ta': 'Comment', 'ur': 'دکھانے-سطح نیورال ماشین ترجمہ کے لئے ڈیسکورس ساخترک مدل کیا جاتا ہے', 'uz': 'Modeling Discourse Structure for Document-level Neural Machine Translation', 'vi': 'Chế độ phân giải cho cấu trúc thần kinh của Tài liệu', 'bg': 'Моделиране на дискурсната структура за неврален машинен превод на ниво документ', 'da': 'Modellering af diskursstruktur til neural maskinoversættelse på dokumentniveau', 'hr': 'Modeliranje strukture diskursa za prijevod neuroloških strojeva na razini dokumenta', 'nl': 'Modeling discoursstructuur voor neuronale machinevertaling op documentniveau', 'de': 'Modellierung der Diskursstruktur für neuronale maschinelle Übersetzung auf Dokumentenebene', 'id': 'Modeling Struktur Discourse untuk Translation Mesin Neural Tingkat Dokumen', 'sw': 'Modeling Discourse Structure for Document-level Neural Machine Translation', 'fa': 'مدل ساختار گفتگو برای ترجمه ماشین عصبی سطح سند', 'ko': '문서급 신경기계 번역의 문장 구조 모델링', 'tr': 'Sened derejesi Näral Mazmunlar terjimesine üçin Azyk strukturuny nusgala', 'am': 'Modeling Discourse Structure for Document-level Neural Machine Translation', 'af': 'Name', 'sq': 'Modelimi i strukturës së diskutimit për përkthimin e makinës nervore në nivel të dokumentit', 'hy': 'Comment', 'bs': 'Modeliranje strukture diskursa za prevod neuroloških strojeva na nivou dokumenta', 'az': 'D칬k칲man s톛viyy톛si N칬ral Makina 칂eviri 칲칞칲n Diskurs Structure Modeling for Document-level Neural Machine Translation', 'bn': 'ডকুমেন্ট- স্তরের নিউরেল মেশিন অনুবাদের জন্য মডেলিং ডিসার্স ক্ষেত্র', 'ca': "Modelar l'estructura del discurs per a la traducció de màquines neuronals a nivell de documents", 'cs': 'Modelování diskurzní struktury pro neuronový strojový překlad na úrovni dokumentu', 'et': 'Diskursuse struktuuri modelleerimine dokumenditasemel neuroaalse masintõlke jaoks', 'fi': 'Dokumenttitason neurokääntämisen diskurssirakenteen mallintaminen', 'jv': 'structural navigation', 'ha': 'KCharselect unicode block name', 'sk': 'Modeliranje strukture diskurza za živčni strojni prevod na ravni dokumenta', 'bo': 'Modeling Discourse Structure for Document-level Neural Machine Translation', 'he': 'מודל מבנה דיסקורס לתרגום מכונות נוירויות ברמה המסמכים'}
{'en': 'Recently, document-level neural machine translation (NMT) has become a hot topic in the community of ', 'ar': 'في الآونة الأخيرة ، أصبحت الترجمة الآلية العصبية على مستوى المستندات (NMT) موضوعًا ساخنًا في مجتمع الترجمة الآلية. على الرغم من نجاحها ، تجاهلت معظم الدراسات الحالية معلومات بنية الخطاب الخاصة بوثيقة الإدخال المراد ترجمتها ، والتي أظهرت فعاليتها في المهام الأخرى. في هذه الورقة ، نقترح تحسين NMT على مستوى المستند بمساعدة معلومات بنية الخطاب. يعتمد برنامج التشفير الخاص بنا على شبكة اهتمام هرمية (HAN) (Miculicich et al. ، 2018). على وجه التحديد ، نقوم أولاً بتحليل مستند الإدخال للحصول على هيكل الخطاب الخاص به. بعد ذلك ، نقدم مشفر مسار قائم على المحولات لتضمين معلومات بنية الخطاب لكل كلمة. أخيرًا ، نقوم بدمج معلومات بنية الخطاب مع كلمة التضمين قبل إدخالها في المشفر. تظهر النتائج التجريبية على مجموعة البيانات من الإنجليزية إلى الألمانية أن نموذجنا يمكن أن يتفوق بشكل كبير على كل من Transformer و Transformer + HAN.', 'pt': 'Recentemente, a tradução automática neural em nível de documento (NMT) tornou-se um tema quente na comunidade de tradução automática. Apesar do sucesso, a maioria dos estudos existentes ignorou as informações da estrutura discursiva do documento de entrada a ser traduzido, o que tem se mostrado eficaz em outras tarefas. Neste artigo, propomos melhorar a NMT em nível de documento com o auxílio de informações de estrutura de discurso. Nosso codificador é baseado em uma rede de atenção hierárquica (HAN) (Miculicich et al., 2018). Especificamente, primeiro analisamos o documento de entrada para obter sua estrutura de discurso. Em seguida, introduzimos um codificador de caminho baseado em Transformer para incorporar as informações da estrutura do discurso de cada palavra. Por fim, combinamos a informação da estrutura do discurso com a incorporação da palavra antes de ser inserida no codificador. Resultados experimentais no conjunto de dados de inglês para alemão mostram que nosso modelo pode superar significativamente o desempenho do Transformer e do Transformer+HAN.', 'fr': "Récemment, la traduction automatique neuronale (NMT) au niveau des documents est devenue un sujet brûlant dans la communauté de la traduction automatique. Malgré son succès, la plupart des études existantes ont ignoré les informations sur la structure du discours du document d'entrée à traduire, qui se sont révélées efficaces dans d'autres tâches. Dans cet article, nous proposons d'améliorer la NMT au niveau du document à l'aide d'informations sur la structure du discours. Notre encodeur est basé sur un réseau d'attention hiérarchique (HAN) (Miculicich et al., 2018). Plus précisément, nous analysons d'abord le document d'entrée pour obtenir sa structure de discours. Ensuite, nous introduisons un encodeur de chemin basé sur Transformer pour intégrer les informations de structure du discours de chaque mot. Enfin, nous combinons les informations de structure du discours avec l'incorporation de mots avant qu'ils ne soient introduits dans l'encodeur. Les résultats expérimentaux sur le jeu de données de l'anglais vers l'allemand montrent que notre modèle peut largement surpasser Transformer et Transformer+HAN.", 'es': 'Recientemente, la traducción automática neuronal (NMT) a nivel de documento se ha convertido en un tema candente en la comunidad de la traducción automática. A pesar de su éxito, la mayoría de los estudios existentes ignoraron la información de la estructura del discurso del documento de entrada a traducir, lo que ha demostrado ser eficaz en otras tareas. En este artículo, proponemos mejorar la NMT a nivel de documento con la ayuda de la información de la estructura del discurso. Nuestro codificador se basa en una red de atención jerárquica (HAN) (Miculicich et al., 2018). Específicamente, primero analizamos el documento de entrada para obtener su estructura de discurso. Luego, introducimos un codificador de ruta basado en Transformer para incrustar la información de la estructura del discurso de cada palabra. Finalmente, combinamos la información de la estructura del discurso con la palabra incrustación antes de introducirla en el codificador. Los resultados experimentales del conjunto de datos de inglés a alemán muestran que nuestro modelo puede superar significativamente a Transformer y Transformer+HAN.', 'ja': '最近、ドキュメントレベルのニューラル機械翻訳（ NMT ）は、機械翻訳のコミュニティで熱い話題となっています。その成功にもかかわらず、ほとんどの既存の研究は、翻訳されるインプットドキュメントの話題構造情報を無視し、他のタスクで効果的であることが示された。本稿では，言説構造情報を活用して，文書レベルのNMTを改善することを提案する．当社のエンコーダは、階層的注意ネットワーク（ HAN ）に基づいています（ Miculicich et al., 2018 ）。具体的には、まず入力ドキュメントを解析して、その論証構造を得る。そして、トランスフォーマーベースのパスエンコーダを導入し、各ワードの話題構造情報を埋め込む。最後に、ディスクロージャー情報をエンコーダに送る前に、埋め込む単語と組み合わせます。英語からドイツ語へのデータセットの実験結果は、当社のモデルがTransformerとTransformer + HANの両方を大幅に上回ることができることを示しています。', 'zh': '近者,文档级神经机器翻译(NMT)已为机器翻译社区热门话题。 虽有成功,大抵略于译文档之语,他事之效也。 于本文中,请借语结信以进文档级NMT。 吾编码器基于分网络(HAN)(Miculicich等,2018)。 具体来说,先解析输文档以得其语。 然后引入一Transformer路编码器嵌单词语结信。 最后,我们将话结构信息与嵌入词相合,然后再输入编码器。 英德数集之实验结果表明,吾形可以明优于TransformerTransformer+HAN。', 'ru': 'В последнее время нейронный машинный перевод (НМП) на уровне документа стал горячей темой в сообществе машинного перевода. Несмотря на свой успех, большинство существующих исследований игнорировали информацию о структуре дискурса исходного документа, подлежащего переводу, что показало свою эффективность в других задачах. В данной работе мы предлагаем усовершенствовать НБД на уровне документа с помощью информации о структуре дискурса. Наш кодер основан на иерархической сети внимания (HAN) (Miculicich et al., 2018). В частности, мы сначала анализируем входной документ, чтобы получить его структуру дискурса. Затем мы вводим кодер пути на основе трансформатора для встраивания информации о структуре дискурса каждого слова. Наконец, мы объединяем информацию о структуре дискурса со словом embedding перед тем, как она подается в кодировщик. Экспериментальные результаты по набору данных «Английский-немецкий» показывают, что наша модель может значительно превосходить как Трансформатор, так и Трансформатор+ХАН.', 'hi': 'हाल ही में, दस्तावेज़-स्तरीय तंत्रिका मशीन अनुवाद (NMT) मशीन अनुवाद के समुदाय में एक गर्म विषय बन गया है। इसकी सफलता के बावजूद, अधिकांश मौजूदा अध्ययनों ने अनुवादित किए जाने वाले इनपुट दस्तावेज़ की प्रवचन संरचना जानकारी को अनदेखा कर दिया, जिसने अन्य कार्यों में प्रभावी दिखाया है। इस पेपर में, हम प्रवचन संरचना जानकारी की सहायता से दस्तावेज़-स्तरीय एनएमटी में सुधार करने का प्रस्ताव करते हैं। हमारा एनकोडर एक पदानुक्रमित ध्यान नेटवर्क (HAN) (Miculicich et al., 2018) पर आधारित है। विशेष रूप से, हम पहले इसकी प्रवचन संरचना प्राप्त करने के लिए इनपुट दस्तावेज़ को पार्स करते हैं। फिर, हम प्रत्येक शब्द की प्रवचन संरचना जानकारी को एम्बेड करने के लिए एक ट्रांसफॉर्मर-आधारित पथ एन्कोडर पेश करते हैं। अंत में, हम प्रवचन संरचना की जानकारी को शब्द एम्बेडिंग के साथ जोड़ते हैं, इससे पहले कि इसे एन्कोडर में खिलाया जाए। अंग्रेजी-से-जर्मन डेटासेट पर प्रयोगात्मक परिणाम बताते हैं कि हमारा मॉडल ट्रांसफॉर्मर और ट्रांसफॉर्मर + एचएएन दोनों को काफी बेहतर बना सकता है।', 'ga': 'Le déanaí, tá an t-aistriúchán meaisín néarach ag leibhéal doiciméad (NMT) ina ábhar te i bpobal an aistriúcháin mheaisín. In ainneoin a rathúlachta, rinne an chuid is mó de na staidéir a bhí ann cheana neamhaird ar fhaisnéis struchtúr dioscúrsa an doiciméid ionchuir a bhí le haistriú, rud a léirigh éifeachtach i dtascanna eile. Sa pháipéar seo, tá sé beartaithe againn NMT ag leibhéal doiciméad a fheabhsú le cabhair ó fhaisnéis faoi struchtúr dioscúrsa. Tá ár n-ionchódóir bunaithe ar líonra aird ordlathach (HAN) (Miculicich et al., 2018). Go sonrach, déanaimid an doiciméad ionchuir a pharsáil ar dtús chun a struchtúr dioscúrsa a fháil. Ansin, tugaimid isteach ionchódóir cosán Trasfhoirmeoir-bhunaithe chun faisnéis struchtúr dioscúrsa gach focal a leabú. Ar deireadh, comhcheanglaímid an fhaisnéis struchtúr dioscúrsa leis an bhfocal leabú sula gcuirtear san ionchódóir é. Léiríonn torthaí turgnamhacha ar an tacar sonraí Béarla-go-Gearmáinis gur féidir lenár múnla sárfheidhmíocht a dhéanamh níos fearr ná Transformer agus Transformer+HAN araon.', 'ka': 'მიმდინარე დოკუმენტის დოკუმენტის ნეიროლური მაქინის გაგრძელება (NMT) მოხდა მაქინის გაგრძელება საზოგადოებაში. მისი წარმატების მაგრამ, მსგავსი კვლევების უფრო დისკურსური სტრუქტურის ინფორმაცია, რომელიც გადაწყენებული დოკუმენტის შესახებ, რომელიც სხვა დავალებში ე ამ დოკუმენტის შესახებ, ჩვენ გვეძლოთ გავაკეთოთ NMT დოკუმენტის დოკუმენტის უფრო მეტი, რომელიც განსახულებული სტრუქტურის ინფორმა ჩვენი კოდირები იერაქტიკური ინტერნექტი (HAN) (Miculicich et al., 2018). განსაკუთრებულია, ჩვენ პირველად გავაწერეთ შეტყობინებული დოკუმენტის სტრუქტურაციას. შემდეგ ჩვენ ტრანფორმეტრის ფოსტის კოდერის შესახებ, რომელიც ყოველ სიტყვის სიტყვის დისკურსის სტრუქტურაციის ინფორმაციის შესახებ. საბოლოოდ, ჩვენ კოდირების სტრუქტურის ინფორმაციას კოდირებისთვის შემდეგ სიტყვებით დავყენებთ. ექსპერიმენტიური მონაცემების ინგლისურ-გერმანური მონაცემების შესაძლებელია, რომ ჩვენი მოდელი შეუძლებელია მნიშვნელოვანი გავაკეთოთ ტრანფორმენტრის', 'el': 'Πρόσφατα, η νευρολογική μηχανική μετάφραση σε επίπεδο εγγράφων έχει γίνει ένα καυτό θέμα στην κοινότητα της μηχανικής μετάφρασης. Παρά την επιτυχία του, οι περισσότερες από τις υπάρχουσες μελέτες αγνόησαν τις πληροφορίες της δομής του λόγου του προς μετάφραση εγγράφου εισόδου, οι οποίες έχουν αποδειχθεί αποτελεσματικές σε άλλα καθήκοντα. Στην παρούσα εργασία, προτείνουμε τη βελτίωση της NMT σε επίπεδο εγγράφων με τη βοήθεια πληροφοριών για τη δομή του λόγου. Ο κωδικοποιητής μας βασίζεται σε ένα ιεραρχικό δίκτυο προσοχής (κ.α., 2018). Συγκεκριμένα, πρώτα αναλύουμε το έγγραφο εισόδου για να αποκτήσουμε τη δομή του λόγου. Στη συνέχεια, εισάγουμε έναν κωδικοποιητή διαδρομής βασισμένο στον μετασχηματιστή για να ενσωματώσουμε τις πληροφορίες δομής λόγου κάθε λέξης. Τέλος, συνδυάζουμε τις πληροφορίες της δομής του λόγου με τη λέξη ενσωμάτωση πριν τροφοδοτηθεί στον κωδικοποιητή. Τα πειραματικά αποτελέσματα στο σύνολο δεδομένων της αγγλικής προς γερμανικής δείχνουν ότι το μοντέλο μας μπορεί να ξεπεράσει σημαντικά τόσο τον μετασχηματιστή όσο και τον μετασχηματιστή+HAN.', 'hu': 'A közelmúltban a dokumentumszintű neurális gépi fordítás (NMT) forró témává vált a gépi fordítás közösségében. Sikere ellenére a legtöbb meglévő tanulmány figyelmen kívül hagyta a fordítandó bemeneti dokumentum diskurzusszerkezeti információit, ami más feladatokban is hatékonynak bizonyult. Jelen tanulmányban javasoljuk a dokumentumszintű NMT fejlesztését diskurzusszerkezeti információk segítségével. Kódolónk hierarchikus figyelemhálózaton alapul (HAN) (Miculicich et al., 2018). Konkrétan először elemezzük a bemeneti dokumentumot, hogy megszerezzük a diskurzus struktúráját. Ezután bevezetünk egy Transformer-alapú útkódolót, amely beágyazza az egyes szavak diskurzusszerkezetének információit. Végezetül kombináljuk a diskurzus struktúra információit a beágyazás szóval, mielőtt bekapcsolódna a kódolóba. Az angol-német adatkészlet kísérleti eredményei azt mutatják, hogy modellünk jelentősen felülmúlhatja a Transformert és a Transformer+HAN teljesítményt.', 'it': "Recentemente, la traduzione automatica neurale a livello di documento (NMT) è diventata un argomento caldo nella comunità della traduzione automatica. Nonostante il suo successo, la maggior parte degli studi esistenti ignorava le informazioni sulla struttura del discorso del documento di input da tradurre, che si sono rivelate efficaci in altri compiti. In questo articolo, proponiamo di migliorare l'NMT a livello documentale con l'aiuto di informazioni sulla struttura del discorso. Il nostro encoder si basa su una rete di attenzione gerarchica (HAN) (Miculicich et al., 2018). Nello specifico, analizziamo prima il documento di input per ottenere la sua struttura del discorso. Quindi, introduciamo un codificatore di percorso basato su Transformer per incorporare le informazioni sulla struttura del discorso di ogni parola. Infine, combiniamo le informazioni sulla struttura del discorso con la parola embedding prima che venga immessa nell'encoder. I risultati sperimentali sul set di dati inglese-tedesco mostrano che il nostro modello può superare significativamente sia Transformer che Transformer+HAN.", 'kk': 'Жуырда құжат деңгейіндегі невралдық компьютерді аудару (NMT) машинаны аудару коммуникасында жылу нақышы болды. Бұл сәттілігіне қарамастан, барлық зерттеулердің көпшілігі басқа тапсырмаларда әсер ететін келтіру құжаттың дисков құрылымының мәліметін елемейді. Бұл қағазда, NMT құжаттың деңгейіндегі дискурс құрылғы мәліметінің көмегімен құжаттар деңгейін жақсарту керек. Біздің кодеріміз иерархиялық қарау желіне негізделген (HAN) (Miculicich et al., 2018). Ескерту үшін бірінші келтірілген құжатты дискурстардың құрылымын алу үшін талдаймыз. Содан кейін, әрбір сөздің дискурстардың құрылғы мәліметін ендіру үшін Трансферлердің негіздеген жол кодерін келтіреміз. Соңында, оны кодерге ендіру алдында дискурстың құрылғысының мәліметін біріктіреміз. Ағылшын- неміс деректер жиынының эксперименталдық нәтижелері біздің үлгіміз Трансформация және Трансформация+HAN- дан да өте жақсы болады.', 'mk': 'Неодамна, неуралниот превод на машина на ниво на документ (НМТ) стана жешка тема во заедницата на машински превод. И покрај неговиот успех, повеќето постоечки студии ги игнорираа информациите за дискурсната структура на внатрешниот документ кој треба да се преведе, што покажа ефикасност во другите задачи. Во овој документ предложуваме подобрување на НМТ на документно ниво со помош на информации за дискурсната структура. Нашиот кодер се базира на хиерархична мрежа на внимание (ХАН) (Микуличиќ и други, 2018). Specifically, we first parse the input document to obtain its discourse structure.  Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word.  Конечно, ја комбинираме информацијата за дискурсната структура со зборот вграден пред да биде внесен во кодерот. Експерименталните резултати на англиско-германското податочно множество покажуваат дека нашиот модел може значително да го надмине трансформерот и трансформерот+Хан.', 'lt': 'Pastaruoju metu dokumentų lygmens nervinių mašin ų vertimas (NMT) tapo karšta mašinų vertimo bendruomenės tema. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks.  Šiame dokumente siūlome pagerinti dokumentų lygmens NMT naudojant diskurso struktūros informaciją. Mūsų kodas grindžiamas hierarchiniu dėmesio tinklu (HAN) (Miculicich ir kt., 2018 m.). Konkrečiai, pirmiausia analizuojame įvestį dokumentą, kad gautume jo diskurso struktūrą. Tuomet įvedame Transformuotoju pagrįstą kelio kodą, kuris įtraukia kiekvieno žodžio diskurso struktūros informaciją. Galiausiai mes deriname diskurso struktūros informaciją su žodžiu įterpiama prieš įterpiant ją į kodą. Eksperimentiniai anglų ir vokiečių duomenų rinkinio rezultatai rodo, kad mūsų modelis gali gerokai viršyti Transformer ir Transformer+HAN.', 'ms': 'Baru-baru ini, terjemahan mesin saraf aras dokumen (NMT) telah menjadi topik panas dalam komuniti terjemahan mesin. Walaupun ia berjaya, kebanyakan kajian yang ada mengabaikan maklumat struktur diskors dokumen input yang hendak diterjemahkan, yang telah menunjukkan berkesan dalam tugas lain. Dalam kertas ini, kami cadangkan untuk memperbaiki NMT aras dokumen dengan bantuan maklumat struktur diskors. Pengekod kami berdasarkan rangkaian perhatian hierarkik (HAN) (Miculicich et al., 2018). Secara khusus, pertama kali kita hurai dokumen input untuk mendapatkan struktur diskursnya. Kemudian, kita memperkenalkan pengekod laluan berasaskan Transformer untuk memasukkan maklumat struktur diskors setiap perkataan. Akhirnya, kita menggabungkan maklumat struktur diskors dengan perkataan yang dibina sebelum ia dimasukkan ke dalam pengekod. Keputusan percubaan pada set data Inggeris-Jerman menunjukkan bahawa model kita boleh jauh lebih daripada Transformer dan Transformer+HAN.', 'mt': 'Dan l-a ħħar, it-traduzzjoni tal-magni newrali fil-livell tad-dokument (NMT) saret suġġett sħun fil-komunità tat-traduzzjoni tal-magni. Minkejja s-suċċess tiegħu, il-biċċa l-kbira tal-istudji eżistenti injoraw l-informazzjoni dwar l-istruttura ta’ diskors tad-dokument ta’ input li għandu jiġi tradott, li wriet effettiv f’kompiti oħra. F’dan id-dokument, qed nipproponu li tittejjeb l-NMT fil-livell ta’ dokumenti bl-għajnuna ta’ informazzjoni dwar l-istruttura ta’ diskors. Il-kodifikatur tagħna huwa bbażat fuq netwerk ta’ attenzjoni ġerarkika (HAN) (Miculicich et al., 2018). Speċifikament, l-ewwel nagħmlu analiżi tad-dokument ta’ input biex inkisbu l-istruttura ta’ diskors tiegħu. Imbagħad, a ħna nintroduċu kodifikatur tal-mogħdija bbażat fuq it-Trasformer biex jinkorporaw l-informazzjoni dwar l-istruttura ta’ diskors ta’ kull kelma. Fl-aħħar nett, aħna ngħaqdu l-informazzjoni dwar l-istruttura tad-diskors mal-kelma inkorporata qabel ma tiġi inkorporata fil-kodifikatur. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.', 'ml': 'അടുത്തുതന്നെ മെഷീന്\u200d പരിഭാഷണത്തിന്റെ സമൂഹത്തില്\u200d ഒരു ചൂടുള്ള വിഷയം ആയിരിക്കുന്നു. അതിന്റെ വിജയത്തിനു ശേഷം, നിലവിലുള്ള പഠനങ്ങളിലേറെപ്പേരും ഇന്\u200dപുട്ട് രേഖയിലെ സംസാരം സംസാരിക്കുന്നതിന്റെ വിവരങ്ങള്\u200d അ ഈ പത്രത്തില്\u200d, നമ്മള്\u200d രേഖയുടെ നില NMT മെച്ചപ്പെടുത്തുന്നത് സംസാരിക്കുന്ന സംഘടനയുടെ സഹായം കൊണ്ട്. ഞങ്ങളുടെ കോഡെര്\u200d ഹൈറാര്\u200dക്കിക്കല്\u200d ശ്രദ്ധ നെറ്റ്\u200c (HAN) (മികുലിസിച്ച് എറ്റ് അല്\u200d, 2018) അടിസ്ഥാനമാണ്. പ്രത്യേകിച്ച്, നമ്മള്\u200d ആദ്യം ഇന്\u200dപുട്ട് രേഖയെ പാര്\u200dസ് ചെയ്യുന്നു. അതിന്റെ സംസാരം സംസാരിക്കുന എന്നിട്ട് ഓരോ വാക്കിന്റെയും സംസാരിക്കുന്ന സംസാരത്തിന്റെ അടിസ്ഥാനത്തിലുള്ള പാത്തിന്റെ കോഡിറ്റര അവസാനം, സംസാരിക്കുന്ന സംസാരത്തിന്റെ അടിസ്ഥാനത്തിലെ വിവരങ്ങള്\u200d കൂട്ടിചേര്\u200dക്കുന്നതിന് മുമ്പ് അത് കോഡെ ഇംഗ്ലീഷില്\u200d നിന്നും ജര്\u200dമ്മന്\u200d ഡാറ്റാസെറ്റില്\u200d പരീക്ഷണ ഫലങ്ങള്\u200d കാണിക്കുന്നു നമ്മുടെ മോഡല്\u200d ട്രാന്\u200dസ്ഫോര്\u200dമാന്\u200dസ', 'mn': 'Сүүлийн үед баримт-түвшинд мэдрэлийн машин хөгжүүлэлт (NMT) машины хөгжүүлэлтийн нийгэмд халуун сэдэв болсон. Амжилтын үр дүнд ч ихэнх судалгаанууд бичил баримтын ярианы бүтэц мэдээллийг орчуулах боломжтой, бусад үйл ажиллагаанд үр дүнтэй харуулсан. Энэ цаасан дээр бид баримтын түвшинд NMT-г ярианы бүтэц мэдээллийн тусламжтай сайжруулахыг санал болно. Бидний коддогч нь анхаарал төвлөрүүлэх сүлжээнд суурилсан (HAN) (Miculicich et al., 2018). Ялангуяа бид эхлээд ярианы бүтцийг олж авахын тулд оролцооны баримтыг хуваалцах болно. Дараа нь бид үг бүрийн ярианы бүтэц мэдээллийг оруулахын тулд Трансфер дээр суурилсан замын коддогчийг танилцуулдаг. Эцэст нь бид ярианы бүтэц мэдээллийг кодлогчид өгөхөөс өмнө нэгтгэх үгийг нэгтгэнэ. Англи болон Герман өгөгдлийн сангийн туршилтын үр дүнд бидний загвар нь Трансформ болон Трансформ+ХаН хоёулаас илүү чухал болж чадна.', 'no': 'Nyleg har omsetjinga av dokumentnivå neuralmaskin (NMT) blitt eit varmt emne i samfunnet med maskinsomsetjing. I tillegg til suksess, har dei fleste eksisterande studiane ignorert diskursstrukturinformasjonen om inndatadokumentet som skal oversettest, som har vist effektivt i andre oppgåver. I denne papiret foreslår vi å forbetra NMT-nivå med hjelp til diskursstruktureinformasjon. Koderet vårt er basert på eit hierarkisk oppmerksnettverk (HAN) (Miculicich et al., 2018). Spesifikke, vi tolkar først inndatadokumentet for å få diskursstrukturen sin. Så introduserer vi ein banenkoder med Transformeringsbasert bane for å innebygge diskursstrukturinformasjonen om kvar ord. I slutt kombinerer vi diskursstrukturenformasjonen med ordet innebygd før den vert fede inn i koderen. Eksperimentale resultat på datasettet til engelsk til tysk viser at modellen vårt kan utføre både Transformer og Transformer+HAN.', 'pl': 'Ostatnio neuronowe tłumaczenie maszynowe na poziomie dokumentów (NMT) stało się gorącym tematem w społeczności tłumaczeń maszynowych. Pomimo sukcesu większość istniejących badań ignorowała informacje o strukturze dyskursu dokumentu wejściowego, który ma być przetłumaczony, co okazało się skuteczne w innych zadaniach. W niniejszym artykule proponujemy ulepszenie NMT na poziomie dokumentów za pomocą informacji o strukturze dyskursu. Nasz koder oparty jest na hierarchicznej sieci uwagi (HAN) (Miculicich et al., 2018). W szczególności najpierw analizujemy dokument wejściowy, aby uzyskać jego strukturę dyskursu. Następnie wprowadzamy koder ścieżek oparty na Transformerze, aby osadzić informacje o strukturze dyskursu każdego słowa. Na koniec łączymy informacje o strukturze dyskursu ze słowem embedding zanim zostaną wprowadzone do kodera. Wyniki eksperymentalne na zbiorze danych angielsko-niemieckim pokazują, że nasz model może znacznie przewyższyć zarówno Transformer, jak i Transformer+HAN.', 'ro': 'Recent, traducerea automată neurală la nivel de document (NMT) a devenit un subiect fierbinte în comunitatea traducerii automate. În ciuda succesului său, majoritatea studiilor existente au ignorat informațiile structurii discursului din documentul de intrare care urmează să fie tradus, ceea ce s-a dovedit eficient în alte sarcini. În această lucrare, propunem îmbunătățirea NMT la nivel de document cu ajutorul informațiilor despre structura discursului. Encoder-ul nostru se bazează pe o rețea de atenție ierarhică (HAN) (Miculicich et al., 2018). Mai precis, analizăm mai întâi documentul de intrare pentru a obține structura discursului. Apoi, introducem un codificator de cale bazat pe Transformer pentru a încorpora informațiile structurii discursului fiecărui cuvânt. În cele din urmă, combinăm informațiile structurii discursului cu cuvântul încorporat înainte de a fi introdus în codificator. Rezultatele experimentale ale setului de date din limba engleză în germană arată că modelul nostru poate depăși semnificativ atât Transformer, cât și Transformer+HAN.', 'sr': 'Nedavno je prevod neuralne mašine na nivou dokumenta (NMT) postao vruća tema u zajednici prevoda mašine. Uprkos uspjehu, većina postojećih ispitivanja ignorirala je informacije o strukturi diskursa o ulaznom dokumentu koji će biti prevedeni, što je pokazalo efikasno u drugim zadacima. U ovom papiru predlažemo da poboljšamo NMT nivou dokumenta uz pomoć informacija o strukturi diskursa. Naš koder je baziran na hijerarhičkoj mreži pažnje (HAN) (Miculicich et al., 2018). Posebno, prvo analiziramo ulazni dokument kako bi dobili strukturu diskursa. Onda predstavljamo koder puteva na transformatoru kako bi uključili informacije o strukturi diskursa svake reči. Konaèno, kombinujemo informacije o strukturi diskursa sa reèima ukljuèenim pre nego što se naðe u koder. Eksperimentalni rezultati na setu podataka engleskog do njemačkog pokazuju da naš model značajno može izvršiti i Transformer i Transformer+HAN.', 'so': 'Mudankii ugu dhowaaday turjumista qoraalka-level neural machine (NMT) wuxuu noqday madam kulul oo ku qoran bulshada turjumaadda machine. Inta kastoo ay liibaantay, waxbarasho badan oo joogta ayaa diiday macluumaadka dhismaha ee warqada lagu turjumo qoraalka input, taas oo waxqabad ku saabsan shaqada kale. Qoraalkan waxaan ku soo jeedaynaa in aan ku hagaajino heerka dukumentiga ee NMT iyadoo lagu caawiyo macluumaadka dhismaha hadalka. Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018).  Si gaar ah, marka ugu horeysa waxaynu baaraynaa dukumentiga gudaha si aan u helno dhismaha hadalka. Markaas waxaynu soo bandhignaa koox wado ku saleysan ah si aan u soo saarno macluumaadka dhismaha hadalka ee hadal walba. Ugu dambaysta, waxaynu macluumaadka dhismaha hadalka ku daryeelaynaa erayga ku qoran intaan la quudiyin kooxda. Imtixaanka ku saabsan macluumaadka afka Ingiriiska-Jarmalka waxaa muujin kara in modellkayagu si muhiim ah u sameyn karo Transformer iyo Transformer+HAN.', 'si': 'අලුත් වෙලාවට, ලේඛන- තත්වය න්\u200dයූරල් මැෂින් පරිවර්තනය (NMT) පරිවර්තනය සමාජයේ විශේෂයක් වුනා. එයාගේ සාර්ථක විදියට නමුත්, ගොඩක් අභ්\u200dයාසයක් තියෙන්නේ ඉතින් අභ්\u200dයාසයක් වෙනුවෙන් ඇතුළු ලිපිණියේ කතාවක මේ පත්තරේ අපි ප්\u200dරශ්නයක් කරනවා නිර්මාණය සඳහා ලිපින්ත තොරතුරු සඳහා ලිපින්ත NMT ස්ථානය වැඩ කරන්න අපේ සංකේතකය අධාරිත අවධාන ජාලය (HAN) (Miculicech et al., 2018). විශේෂයෙන්, අපි මුලින්ම ඇතුළුම් ලිපිණියක් පරීක්ෂා කරනවා එයාගේ කතාව ස්ථාපනය ගන්න. ඊට පස්සේ, අපි හැම වචනයේ කතාවක් සංවිධාන තොරතුරු සම්බන්ධ කරන්න ප්\u200dරවර්තනය සඳහා මාර්ගය සංවිධානය අන්තිමේදි, අපි කතාවක් සංවිධානය තොරතුරු සම්බන්ධ කරනවා වචනය සම්බන්ධ කරන්න කලින්. ඉංග්\u200dරීසියෙන් ජර්මන් දත්ත සෙට් එක්ක පරීක්ෂණ ප්\u200dරතිචාරයක් පෙන්වන්න පුළුවන් අපේ මොඩේල් විශේෂයෙ', 'sv': 'Nyligen har neural maskinöversättning (NMT) på dokumentnivå blivit ett hett ämne i gemenskapen för maskinöversättning. Trots framgång ignorerade de flesta av de befintliga studierna diskursstrukturen i det indata dokument som ska översättas, vilket har visat sig vara effektivt i andra uppgifter. I denna uppsats föreslår vi att man förbättrar NMT på dokumentnivå med hjälp av diskursstrukturens information. Vår encoder är baserad på ett hierarkiskt uppmärksamhetsnätverk (HAN) (Miculicich et al., 2018). Specifikt tolkar vi först indatadokumentet för att få dess diskursstruktur. Sedan introducerar vi en Transformer-baserad sökvägskodare för att bädda in diskursstrukturens information för varje ord. Slutligen kombinerar vi diskursstrukturens information med ordet inbäddning innan den matas in i kodaren. Experimentella resultat på den engelsk-tyska datauppsättningen visar att vår modell avsevärt kan överträffa både Transformer och Transformer+HAN.', 'ur': 'اچھے سے، دفتر-سطح نیورل ماشین ترجمہ (NMT) ماشین ترجمہ کی کمونٹی میں ایک گرم موضوع ہو گیا ہے۔ اس کے کامیابی کے بغیر، اکثر موجود تحقیقات کے مطالعہ کے ذریعہ انٹرنیٹ دکھانے کے لئے ترجمہ کیے جاتے ہیں، جو دوسرے کاموں میں اثر دکھائی جاتی ہے. اس کاغذ میں ہم ڈکورس ساختر معلومات کی مدد کے ساتھ دکھانے کی سطح NMT کو بہتر کرنے کے لئے پیشنهاد کرتے ہیں. Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018). مخصوص طور پر، ہم پہلی بار اینپیٹ ڈکومئنٹ کو پارس کر رہے ہیں کہ اس کی ڈکورس ساختار حاصل کریں۔ پھر ہم ایک ٹرانسفور بنیاد پاؤں کا کوڈر معلوم کرتے ہیں کہ ہر کلمہ کی صحبت کی ساختار معلومات میں داخل کریں۔ بالآخر، ہم کلام کے ذریعے کلمات کے ساتھ بات ساختہ معلومات کو پیدا کرتے ہیں قبل اس کے کہ اسے کوڈر میں ملا جائے۔ انگلیسی سے جرمانی ڈاٹ سٹ پر تجربہ کا نتیجہ دکھاتا ہے کہ ہمارا موڈل معلوم ہوتا ہے کہ تغییر پھیلانے اور تغییر پھیلانے+HAN', 'ta': 'சமீபத்தில், ஆவண- நிலை புதிய இயந்திரம் மொழிபெயர்ப்பு (NMT) கணினி மொழிபெயர்ப்பில் ஒரு சூடான தலைப்பு ஆகிவிட்டது. இது வெற்றியடைந்த பின்னரும் தற்போதைய ஆய்வுகளில் பெரும்பாலும் உள்ளீட்டு ஆவணத்தை மொழிபெயர்க்க வேண்டிய பேச்சு உரையாடல இந்த காகிதத்தில், நாம் ஆவண- நிலை NMT மேம்படுத்துவதற்கு பரிந்துரைக்கிறோம் பேச்சு உரையாடல் அமைப்பு தகவல் உதவ எங்கள் குறியீட்டாக்கம் ஒரு ஹைரார்சிக் கவனம் வலைப்பின்னல் அடிப்படையாக உள்ளது (HAN) (மைக்லிசிச் மற்றும் al., 2018). குறிப்பிட்டு, நாம் முதலில் உள்ளீட்டு ஆவணத்தை பிரித்து அதன் பேச்சு உரைமையை பெற. பின்னர், நாம் ஒவ்வொரு வார்த்தையும் பேச்சு கட்டுப்பாட்டு தகவலை சேர்த்து ஒரு மாற்று அடிப்படையான பாதைக்  இறுதியாக, நாம் பேச்சு அமைப்பு தகவலை குறியீட்டுக்குறியீட்டிற்கு முன் சொல்லுடன் சேர்க்கிறது. ஆங்கிலத்தில் இருந்து ஜெர்மன் தரவுத்தளத்தில் சோதனையின் முடிவுகள் காட்டுகிறது மாதிரி மற்றும் மாற்றி மற்றும் மாற்', 'vi': 'Gần đây, dịch chuyển máy thần kinh cấp tài liệu (NMB) đã trở thành một chủ đề nóng trong cộng đồng dịch chuyển máy. Mặc dù thành công, hầu hết các nghiên cứu hiện tại đã bỏ qua cấu trúc ngôn ngữ của tài liệu nhập cần dịch, mà đã cho thấy hiệu quả trong các nhiệm vụ khác. Trong tờ giấy này, chúng tôi đề nghị cải thiện công ty NMT trong tài liệu bằng cách hỗ trợ thông tin cấu trúc. Bộ mã hóa của chúng ta dựa trên một mạng lưới chú ý cấp bậc (HAN) (Miculicich et al., 208). Cụ thể, chúng tôi phân tích nội dung tài liệu để có được cấu trúc của nó. Sau đó, chúng ta sẽ giới thiệu một bộ mã hóa đường dẫn Transformer để nhúng thông tin cấu trúc của từng từ. Cuối cùng, chúng ta kết hợp thông tin cấu trúc văn phòng với từ nhúng trước khi nó được đưa vào bộ mã hóa. Kết quả thí nghiệm trên bộ dữ liệu Anh-sang-Đức cho thấy mô hình của chúng ta có thể vượt trội hơn cả Transformer và Transformer+HAN.', 'uz': "Yaqinda, hujjat- darajasi neyrolik tarjima (NMT) machine tarjima jamoasidagi issiq mavzu бўлиб қолди. @ info Bu hujjatda, biz talab qilish tuzuvlarini yordamida hujjat darajasini oshirishni talab qilamiz. Kodlash usuli hierarchik taqdimot tarmoqda (HAN) (Miculicich et al., 2018). Koʻrsatilgan, biz birinchi marta yozuvchi hujjatni o'zgartirish uchun qoʻllanmiz. Keyin biz bir so'zning bir so'zning tuzilishini o'rganish uchun Transformer asosiy yoʻl kodi. Oxirgi, biz kodlash qoidaga kirishdan oldin so'zlarni birlashtiramiz. Ingliz tilida Olmonchaga taʼminlovchi natijalar taʼminlovchi natijalarini koʻrsatish mumkin, bizning modelmiz Transformer va Transformer+HAN bilan juda muhim bajarishi mumkin.", 'bg': 'Напоследък невронният машинен превод на ниво документи се превърна в гореща тема в общността на машинния превод. Въпреки успеха си, повечето от съществуващите изследвания игнорират информацията за структурата на дискурса на входния документ, който трябва да бъде преведен, която се оказва ефективна при други задачи. В настоящата статия предлагаме да се подобри НМТ на документно ниво с помощта на дискурсна структура информация. Нашият кодер се основава на йерархична мрежа за внимание (Микулич и др., 2018). По-конкретно, първо анализираме входния документ, за да получим неговата дискурсна структура. След това въвеждаме трансформаторен кодер за път, за да вградим информацията за структурата на дискурса на всяка дума. И накрая, комбинираме информацията за структурата на дискурса с думата вграждане преди тя да бъде въведена в кодера. Експерименталните резултати от английско-германския набор от данни показват, че нашият модел може значително да надмине както трансформатор, така и трансформатор+хан.', 'da': 'For nylig er neural maskinoversættelse (NMT) på dokumentniveau blevet et varmt emne i fællesskabet af maskinoversættelse. Trods succesen ignorerede de fleste eksisterende undersøgelser diskursstrukturen i det inputdokument, der skal oversættes, hvilket har vist sig at være effektivt i andre opgaver. I denne artikel foreslår vi at forbedre NMT på dokumentniveau ved hjælp af diskursstruktur information. Vores encoder er baseret på et hierarkisk opmærksomhedsnetværk (HAN) (Miculicich et al., 2018). Specielt analyserer vi først input dokumentet for at opnå dets diskursstruktur. Derefter introducerer vi en Transformer-baseret sti encoder til at integrere diskursstrukturens information for hvert ord. Endelig kombinerer vi diskursstrukturens information med ordet indlejring, før det føres ind i koderen. Eksperimentelle resultater på det engelsk-tyske datasæt viser, at vores model kan overgå både Transformer og Transformer+HAN betydeligt.', 'hr': 'Nedavno je prevod neuralnih strojeva na razini dokumenta (NMT) postao vruća tema u zajednici prevoda strojeva. Unatoč njenom uspjehu, većina postojećih ispitivanja ignorirala je informacije o strukturi diskursa o ulaznom dokumentu koji će biti prevedeni, što je pokazalo učinkovito u drugim zadacima. U ovom papiru predlažemo poboljšati NMT razinu dokumenta s pomoć informacija o strukturi diskursa. Naš koder je temeljen na hijerarhičkoj mreži pažnje (HAN) (Miculicich et al., 2018). Posebno, prvo analiziramo ulazni dokument kako bi dobili strukturu diskursa. Onda predstavljamo koder puteva na transformeri kako bi uključili informacije o strukturi diskursa svake riječi. Konačno, kombiniramo informacije o strukturi diskursa s riječima uključenom prije nego se nahrani u koder. Eksperimentalni rezultati na setu podataka engleskog do njemačkog pokazuju da naš model značajno može izvršiti i Transformer i Transformer+HAN.', 'de': 'In letzter Zeit ist die neuronale maschinelle Übersetzung auf Dokumentenebene (NMT) ein heißes Thema in der Gemeinschaft der maschinellen Übersetzung geworden. Trotz ihres Erfolgs ignorierten die meisten existierenden Studien die Diskursstrukturinformationen des zu übersetzenden Eingabedokuments, was sich bei anderen Aufgaben als wirksam erwiesen hat. In diesem Beitrag schlagen wir vor, NMT auf Dokumentenebene mithilfe von Diskursstrukturinformationen zu verbessern. Unser Encoder basiert auf einem hierarchischen Aufmerksamkeitsnetzwerk (HAN) (Miculicich et al., 2018). Konkret analysieren wir zuerst das Eingabedokument, um seine Diskursstruktur zu erhalten. Dann führen wir einen Transformer-basierten Pfadencoder ein, um die Diskursstrukturinformationen jedes Wortes einzubetten. Schließlich kombinieren wir die Diskursstrukturinformationen mit dem Wort Einbettung, bevor sie in den Encoder eingespeist werden. Experimentelle Ergebnisse auf dem englisch-deutschen Datensatz zeigen, dass unser Modell sowohl Transformer als auch Transformer+HAN deutlich übertreffen kann.', 'nl': 'Recent is neuronale machinevertaling op documentniveau (NMT) een hot topic geworden in de gemeenschap van machinevertaling. Ondanks het succes negeerden de meeste bestaande studies de informatie over de discoursstructuur van het te vertalen invoerdocument, wat effectief is gebleken bij andere taken. In dit artikel stellen we voor om NMT op documentniveau te verbeteren met behulp van discoursstructuurinformatie. Onze encoder is gebaseerd op een hiërarchisch attentienetwerk (HAN) (Miculicich et al., 2018). Specifiek, we parsen eerst het invoerdocument om de discoursstructuur te verkrijgen. Vervolgens introduceren we een op Transformer gebaseerde pad encoder om de discoursstructuur informatie van elk woord in te sluiten. Tot slot combineren we de discoursstructuurinformatie met het woord embedding voordat deze in de encoder wordt ingevoerd. Experimentele resultaten op de Engels-Duitse dataset tonen aan dat ons model zowel Transformer als Transformer+HAN aanzienlijk kan overtreffen.', 'id': 'Baru-baru ini, terjemahan mesin saraf tingkat dokumen (NMT) telah menjadi topik panas dalam komunitas terjemahan mesin. Meskipun sukses, kebanyakan studi yang ada mengabaikan informasi struktur diskors dari dokumen masukan yang akan diterjemahkan, yang telah menunjukkan efektif dalam tugas lain. Dalam kertas ini, kami mengusulkan untuk meningkatkan tingkat dokumen NMT dengan bantuan informasi struktur diskors. Koder kami berdasarkan jaringan perhatian hierarkis (HAN) (Miculicich et al., 2018). Secara spesifik, pertama kali kita menguji dokumen masukan untuk mendapatkan struktur diskursinya. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word.  Finally, we combine the discourse structure information with the word embedding before it is fed into the encoder.  Hasil eksperimen dari set data Inggris-Jerman menunjukkan bahwa model kita dapat meningkatkan lebih dari Transformer dan Transformer+HAN.', 'sw': 'Hivi karibuni, tafsiri ya mashine yenye kiwango cha nyaraka (NMT) imekuwa mada yenye moto katika jamii ya tafsiri ya mashine. Pamoja na mafanikio yake, tafiti nyingi zinazopo zimepuuza taarifa za miundombinu ya mazungumzo ya nyaraka hiyo inayotafsiriwa, ambayo imeonyesha ufanisi katika kazi nyingine. Katika karatasi hii, tunapendekeza kuboresha kiwango cha nyaraka cha NMT kwa msaada wa miundombinu ya mazungumzo. Kodi letu lina msingi wa mtandao wa ufuatiliaji (HAN) (Miculicich et al., 2018). Kwa ujumla, kwanza tunachapisha nyaraka ya ndani ili kupata muundo wake wa mazungumzo. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word.  Mwisho, tunaunganisha taarifa za miundombinu ya mazungumzo na neno linaloingizwa kabla ya kuingia kwenye kodi. Matokeo ya majaribio kwenye seti ya data ya Kiingereza-hadi Ujerumani yanaonyesha kuwa mtindo wetu unaweza kufanya kazi kwa kiasi kikubwa na Transfer na Transformer+HAN.', 'tr': 'Soňky wagtlar, sened derejesi näral maşynyň terjimesinde (NMT) maşynyň terjimesinde yssy bir tema bolup geçdi. Iň üstünliki ýöne bolan öýde bar işleriň köp bölegi terjime edilmeli girdi senediň diskusiýa maglumatyny görmezden çykardy. Bu kän iş başga görerlerde etkinlik görkezilýär. Bu gazetde NMT-iň derejesini diskurs struktur maglumatynyň kömegi bilen geliştirmegi teklip edýäris. Biziň kodçymyz iýerarhiýa üns çekmegi (HAN) (Miculicich et al., 2018). Biz ilkinji gezek disklerniň strukturyny almak üçin girdi senedi analyz edip görýäris. Sonra, her sözüň diskusiýa strukturyň maglumatyny dahyl etmek üçin transformer ýörüne tabanly bir ködlemeni tanyşdyrýarys. Soňunda, diskusiýa strukturyň maglumatyny koderden öň içine girmek bilen birleştirip bileris. Iňlisçe-we Almança maglumatlaryň netijesi biziň modelimiz hem Transformer hem Transformer hem HAN-yň üstüne çykyp biljekdigini görkez.', 'ko': '최근 몇 년 동안 문서급 신경기계번역(NMT)은 이미 기계번역 분야의 핫이슈가 되었다.비록 성공을 거두었지만 기존의 대다수 연구는 번역을 위해 입력한 문서의 문장 구조 정보를 소홀히 했고 이것은 다른 임무에서도 유효성을 나타냈다.이 문서에서는 문서 수준의 NMT를 개선하기 위해 문장 구조 정보를 활용하는 것을 권장합니다.우리의 인코더는 층별 주의 네트워크(Han)(Miculicch 등, 2018년)를 기반으로 한다.구체적으로 말하자면, 우리는 먼저 입력 문서를 분석하여 그 문장 구조를 얻는다.그리고 우리는 모든 단어의 문장 구조 정보를 삽입하기 위해 변환기를 기반으로 하는 경로 인코더를 도입했다.마지막으로, 우리는 언어 구조 정보와 단어를 삽입해서 인코더에 입력할 것이다.영어에서 독일어 데이터 집합까지의 실험 결과에 의하면 우리의 모델은 Transformer와 Transformer+Han보다 현저히 우수하다는 것을 알 수 있다.', 'af': "Onlangs het dokumentvlak neurale masjien vertaling (NMT)  'n warm onderwerp geword in die gemeenskap van masjien vertaling. Onthou sy sukses, die meeste van bestaande studies het geïgnoreer die diskurse struktuur inligting van die invoer dokument om te vertaal, wat effektief in ander taak vertoon het. In hierdie papier voorstel ons om dokumentvlak NMT te verbeter met die hulp van diskurse struktuur informasie. Ons enkoder is gebaseer op 'n hierarchiese aandagnetwerk (HAN) (Miculicich et al., 2018). Spesifieke, ons verwerk eerste die invoer dokument om sy diskurse struktuur te kry. Dan, ons introduseer 'n Transformer-gebaseerde pad enkoder om die diskurse struktuur inligting van elke woord in te voer. Eindelik, ons kombinieer die diskursie struktuur inligting met die woord ingesluit voordat dit in die enkoder verskaf word. Eksperimentale resultate op die Engels- na- Duitse datastel vertoon dat ons model betekenlik kan uitvoer beide Transformer en Transformer+HAN.", 'fa': 'اخیراً ترجمه دستگاه عصبی سند (NMT) یک موضوع گرم در جامعه ترجمه دستگاه شد. با وجود موفقیت آن، بیشتر مطالعه\u200cهای موجود اطلاعات ساختار صحبت صحبت را نادیده گرفته است از سند ورودی که باید ترجمه شود، که در کارهای دیگر موثر است. در این کاغذ، ما پیشنهاد می\u200cکنیم که NMT سطح سند را با کمک اطلاعات ساختاری صحبت کنیم. Encoder ما بر روی شبکه توجه معمولی است (HAN) (Miculicich et al., 2018). دقیقا، اولین بار سند ورودی را برای دریافت ساختار صحبت اش بررسی می کنیم. سپس، ما یک کودهر مسیر بر اساس تغییر دهنده را معرفی می\u200cکنیم تا اطلاعات ساختار صحبت هر کلمه را وارد کنیم. بالاخره، ما اطلاعات ساختاری صحبت را با کلمه وارد کردن قبل از اینکه آن را به کدهر غذا داده شود ترکیب می کنیم. نتیجه\u200cهای تجربه روی مجموعه داده\u200cهای انگلیسی و آلمانی نشان می\u200cدهند که مدل ما می\u200cتواند به طور معنی از تغییر\u200cدهنده و تغییر\u200cدهنده+HAN بیشتر انجام دهد.', 'hy': 'Վերջերս, փաստաթղթի մակարդակի նյարդային մեքենայի թարգմանությունը (NMT) դարձավ մեքենայի թարգմանման համայնքի տաք թեմա: Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks.  Այս թղթի մեջ մենք առաջարկում ենք բարելավել փաստաթղթի մակարդակը NMT-ը խոսակցական կառուցվածքի տեղեկատվության օգնությամբ: Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018).  Մասնավորապես, մենք առաջին անգամ վերլուծում ենք ներդրված փաստաթղթին, որպեսզի ստանանք խոսակցության կառուցվածքը: Այնուհետև մենք ներկայացնում ենք Transforme-ի հիմնված ճանապարհի կոդերը, որպեսզի ներառենք յուրաքանչյուր բառի խոսքի կառուցվածքի տեղեկատվությունը: Վերջապես, մենք համադրում ենք խոսակցական կառուցվածքի տեղեկատվությունը բառի հետ, մինչ այն ներդրվում է կոդերի մեջ: Անգլերեն-գերմանացի տվյալների համակարգի փորձարկման արդյունքները ցույց են տալիս, որ մեր մոդելը կարող է նշանակալիորեն գերազանցել Transforme և Transforme+HAN-ը:', 'am': 'በአሁኑ ጊዜ፣ የሰነድ-ደረጃን የነዌብ መሣሪያን ትርጉም (NMT) በመሳዊ ትርጉም ማኅበረሰብ ላይ ትኩሳት ጉዳይ ሆኖአል፡፡ ምንም እንኳን አግኝቷል፣ አብዛኞቹ ተማሪዎቹ የኢንተርኔት ሰነዱን የመረጃ የግንኙነት አካባቢ መረጃዎችን ተሳሳትተዋል፡፡ በዚህ ፕሮግራም፣ የሰነድ ደረጃን NMT በማድረግ የንግግር አካባቢ መረጃዎችን ለመሻል እናስባለን፡፡ Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018).  በተለያይነት፣ አስቀድመን የinput ሰነዱን አካባቢ ለመግኘት እናስፈልጋለን፡፡ ከዚህም በኋላ የቃላትን የንግግር አካባቢ መረጃዎችን ለማግኘት የፎርማሚ መንገድ አካባቢ እናሳውቃለን፡፡ Finally, we combine the discourse structure information with the word embedding before it is fed into the encoder.  በንግግሊዝና-ጀርመን ዳታተር ላይ የመፈተና ውጤቶች የሞክረታችን ሞዴል ትርጓሜ እና ትርጓሜ+HAN በሙሉ ማሳየት ይችላል፡፡', 'sq': 'Kohët e fundit, përkthimi i makinave nervore në nivel të dokumentit (NMT) është bërë një temë e nxehtë në komunitetin e përkthimit të makinave. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks.  Në këtë letër, propozojmë të përmirësojmë nivelin e dokumentit NMT me ndihmën e informacionit të strukturës diskursore. Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018).  Veçanërisht, ne analizojmë së pari dokumentin e hyrjes për të marrë strukturën e diskursit të tij. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word.  Finally, we combine the discourse structure information with the word embedding before it is fed into the encoder.  Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.', 'ca': "Recentment, la traducció de màquines neurals a nivell documental (NMT) s'ha convertit en un tema calent en la comunitat de traducció de màquines. Malgrat el seu èxit, la majoria dels estudis existents ignoraven la informació sobre l'estructura del discurs del document d'entrada que s'ha traduit, que ha demostrat eficaç en altres tasques. En aquest paper, proposem millorar la NMT a nivell documental amb l'ajuda d'informació sobre l'estructura del discurs. Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018).  Concretament, primer analitzem el document d'entrada per aconseguir la seva estructura de discurs. Llavors introduïm un codificador de camí basat en Transformer per incorporar la informació sobre l'estructura del discurs de cada paraula. Finalment, combinam la informació sobre l'estructura del discurs amb la paraula incorporada abans de ser incorporada al codificador. Els resultats experimentals del conjunt de dades anglès-alemanès mostren que el nostre model pot superar significativament tant Transformer com Transformer+HAN.", 'bs': 'Nedavno je prevod neuralnih strojeva na nivou dokumenta (NMT) postao vruća tema u zajednici prevoda strojeva. Uprkos uspjehu, većina postojećih ispitivanja ignorirala je informacije o strukturi diskursa o ulaznom dokumentu koji će biti prevedeni, što je pokazalo učinkovito u drugim zadacima. U ovom papiru predlažemo poboljšati NMT nivo dokumenta uz pomoć informacija o strukturi diskursa. Naš koder je baziran na hijerarhičkoj mreži pažnje (HAN) (Miculicich et al., 2018). Posebno, prvo analiziramo ulazni dokument kako bi dobili strukturu diskursa. Onda predstavljamo koder puteva na transformeri kako bi uključili informacije o strukturi diskursa svake riječi. Konačno, kombiniramo informacije o strukturi diskursa sa riječima uključenom prije nego što se nahrani u koder. Eksperimentalni rezultati na setu podataka engleskog do njemačkog pokazuju da naš model značajno može izvršiti i Transformer i Transformer+HAN.', 'bn': 'সম্প্রতি নথিপত্র-স্তরের নিউরেল মেশিন অনুবাদ (এনএমটি) মেশিন অনুবাদ সম্প্রদায়ের গরম বিষয়ে পরিণত হয়েছে। তার সফলতা সত্ত্বেও বেশীরভাগ গবেষণা অনুবাদ করার জন্য ইনপুট নথির কাঠামো তথ্য উপেক্ষা করেছে, যা অন্যান্য কাজে কার্যকর কর করেছে। এই কাগজটিতে আমরা নথিপত্র-স্তরের স্তরে এনএমটিকে উন্নত করার প্রস্তাব দিচ্ছি কথোপকথনের কাঠামোর তথ্যের সাহা আমাদের এনকোডার একটি হিয়ারার্কিক্যাল মনোযোগ নেটওয়ার্ক (হান) (মাইকুলিসিচ এন্ট আল, ২০১৮)। বিশেষ করে, আমরা প্রথমে ইনপুট নথি পার্স করি তার কথোপকথন কাঠামো পাওয়ার জন্য। তারপর আমরা ট্রান্সফার্মার ভিত্তিক পথ এনকোডার পরিচয় করিয়ে দিচ্ছি প্রত্যেক শব্দের কথোপকথন কাঠামো তথ্য প্রবেশ শেষ পর্যন্ত, আমরা এই কথোপকথন কাঠামোর তথ্য সংযুক্ত করি এনকোডারে ভর্তি করার আগের শব্দের সাথে। ইংরেজি থেকে জার্মান ডাটাসেটের পরীক্ষার ফলাফল দেখাচ্ছে যে আমাদের মডেল গুরুত্বপূর্ণ ভাবে ট্রান্সফার্নার এবং ট্', 'fi': 'Viime aikoina dokumenttitason neurokonekäännös (NMT) on noussut kuumaksi aiheeksi konekäännösyhteisössä. Menestyksestään huolimatta suurin osa nykyisistä tutkimuksista sivuutti käännettävän aineiston diskurssirakenteen informaation, joka on osoittautunut tehokkaaksi muissa tehtävissä. Tässä työssä ehdotamme dokumenttitason NMT:n parantamista diskurssirakenteen informaation avulla. Kooderimme perustuu hierarkkiseen huomioverkkoon (HAN) (Miculicich et al., 2018). Tarkemmin sanottuna analysoimme ensin syöttöasiakirjan saadaksemme sen diskurssirakenteen. Sitten esittelemme Transformer-pohjaisen polkukooderin, joka upottaa jokaisen sanan diskurssirakenteen tiedot. Lopuksi yhdistämme diskurssirakenteen informaation sanan upottamiseen ennen kuin se syötetään kooderiin. Kokeelliset tulokset englanti-saksa-aineistosta osoittavat, että mallimme voi merkittävästi ylittää sekä Transformer että Transformer+HAN.', 'cs': 'V poslední době se neuronový strojový překlad (NMT) na úrovni dokumentů stal horkým tématem v komunitě strojového překladu. Navzdory svému úspěchu většina stávajících studií ignorovala informace o struktuře diskurzu ve vstupním dokumentu, který má být přeložen, což se ukázalo jako efektivní v jiných úkolech. V tomto článku navrhujeme zlepšit NMT na úrovni dokumentů pomocí informací o struktuře diskurzu. Náš kodér je založen na hierarchické pozornostní síti (HAN) (Miculicich et al., 2018). Konkrétně nejprve analyzujeme vstupní dokument, abychom získali jeho strukturu diskurzu. Poté představíme transformátorový kodér cesty, který vkládá informace o struktuře diskurzu každého slova. Konečně kombinujeme informace o struktuře diskurzu se slovem embedding před jejich vložením do kodéru. Experimentální výsledky na anglicko-německé datové sadě ukazují, že náš model může výrazně překonat jak Transformer, tak Transformer+HAN.', 'et': 'Hiljuti on dokumenditasemel neuromasintõlke (NMT) saanud masintõlke kogukonnas kuum teema. Vaatamata edule ignoreeris enamik olemasolevatest uuringutest tõlkitava sisenddokumendi diskursuse struktuuri informatsiooni, mis on osutunud efektiivseks teistes ülesannetes. Käesolevas töös teeme ettepaneku parandada dokumenditasemel NMT diskursuse struktuuri informatsiooni abil. Meie kodeerija põhineb hierarhilisel tähelepanuvõrgul (HAN) (Miculicich et al., 2018). Konkreetsemalt parsime sisenddokumendi, et saada selle diskursuse struktuur. Seejärel tutvustame Transformer-põhist teekodeerijat, mis sisaldab iga sõna diskursuse struktuuri teavet. Lõpuks kombineerime diskursuse struktuuri informatsiooni sõnaga manustamine enne kodeerijat. Inglise-saksa andmekogumi eksperimentaalsed tulemused näitavad, et meie mudel suudab oluliselt ületada nii Transformer kui Transformer+HAN.', 'az': 'Son zamanlarda, dökümət-seviyyəti nöral maşın çevirimi (NMT) maşın çevirilməsinin toplumunda sıcak məsəl oldu. Yaxşılığına baxmayaraq, mevcut çalışmaların çoxu, başqa işlərdə faydalı göstərilən girdi dökümünün müzakirə məlumatını görmədi. Bu kağızda, söhbət strukturları məlumatının köməyi ilə NMT səviyyəsini düzəltmək üçün təklif edirik. Kodlayıcımız hiyerarşik dikkati a ğı (HAN) (Miculicich et al., 2018). Beləliklə, biz ilk dəfə onun diskursu yapısını almaq üçün girdi dökümünü ayırırıq. Sonra hər sözünün müzakirə quruluş məlumatını daxil etmək üçün Transformer tabanlı yol kodlayıcını tanıdırıq. Sonunda, sözlərin quruluş məlumatını kodlamadan əvvəl içərilən sözlərlə birləşdiririk. İngilizə-Almanca veri qutusundakı təcrübə sonuçları modellərimiz Transformer və Transformer+HAN ilə mövcuddur.', 'sk': 'V zadnjem času je nevronsko strojno prevajanje na ravni dokumentov postalo vroča tema v skupnosti strojnega prevajanja. Kljub uspehu je večina obstoječih študij prezrla informacije o strukturi diskurza vhodnega dokumenta, ki ga je treba prevesti, kar se je izkazalo za učinkovito pri drugih nalogah. V prispevku predlagamo izboljšanje NMT na ravni dokumentov s pomočjo informacij o strukturi diskurza. Naš kodirnik temelji na hierarhični mreži pozornosti (HAN) (Miculicich et al., 2018). Natančneje, najprej razčlenimo vhodni dokument, da bi dobili njegovo strukturo diskurza. Nato predstavimo kodirnik poti, ki temelji na transformatorju, ki vključuje informacije o strukturi diskurza vsake besede. Na koncu združimo informacije o strukturi diskurza z besedo vdelavo, preden se vnese v kodirnik. Eksperimentalni rezultati angleško-nemškega nabora podatkov kažejo, da lahko naš model znatno preseže tako Transformer kot Transformer+HAN.', 'ha': "@ info: whatsthis Babu da babban rabo, mafi yawansu masu ƙidãya na fassarar lãbãrin mazaɓa na fassarar takardan input in, da ya nuna mai amfani cikin wasu aikin daban. Ga wannan takardan, Munã goyyade in ƙarfafa kodi-daraja na NMT da taimakon mazaɓa da tsarin mazaɓa. Koda'anta na samar a kan jerin muhimmanci (MAN) (Miculicich et al., 2018). A ƙayyade, za'a yin parse farkon takardar inputi dõmin ka sami bakin mazaɓa da shi. Sa'an nan kuma za mu sami kodi na Transformer don ya sami bakin mazaɓa da duk maganar. Gani, Munã haɗa ma'anar bakin ayuka da aka shigar da shi da kalma wanda ke cikin kodi. Tajararin matsala a kan data set na Ingiriya-zuwa-Jarman yana nuna cewa misalinmu yana iya ƙaranci bayani ga tare da TransTransformer da Transformer+HasN.", 'he': 'לאחרונה, התרגום של מכונות עצביות ברמה של מסמכים (NMT) הפך לנושא חם בקהילה של התרגום מכונות. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks.  In this paper, we propose to improve document-level NMT with the aid of discourse structure information.  Our encoder is based on a hierarchical attention network (HAN) (Miculicich et al., 2018).  במיוחד, אנחנו קודם מעבדים את מסמך הכניסה כדי להשיג את מבנה הדיבור שלה. ואז, אנחנו מציגים קודד מסלול מבוסס על Transformer כדי להכניס את מידע מבנה הדיוקרס של כל מילה. סוף סוף, אנו משלבים את מידע מבנה הדיווח עם המילה הקליטה לפני שהוא מוכנה לקודר. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.', 'bo': 'ཉེ་ཆར་བར་དུ་ཡིག་ཆ་གྱི་གནས་རིམ་དཔུད་ཆས་ཀྱི་འགོད་སྤྱི་ཚོགས་ཆས་ནང་དུ་གཏན་ཁེལ་བ་ཞིག་ཆགས་ཡོད། Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks. In this paper, we propose to improve document-level NMT with the help of discourse structure information. ང་ཚོའི་Encoder་འདིས་ས hierarchical attention network (HAN)ཞིག་གཞི་རྟེན་འདུག Specifically, we first parse the input document to obtain its discourse structure. དེ་ནས་འུ་ཚོས་བརྗེད་པ་དང་གཞི་བརྒྱུད་པའི་འགྲུལ་ལམ་ཨིན་ཀོ་ཌིས་ནང་སྤྲོད་ཀྱི་རྩ་སྒྲིག་ཆ་འཕྲིན་དེ་སྟོན་གྱི་ཡོད། Finally, we combine the discourse structure information with the word embedding before it is fed in the encoder. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.', 'jv': 'file-action input document Nang pepul iki, kita nyumbang nggawe NMT luwih nggawe informasi banget nggawe Awakdhéwé koder tentang karo netengan karo diketekno (HAN)(miculitich et al, 2008). string" in "context_BAR_stringLink politenessoffpolite"), and when there is a change ("assertivepoliteness user Menu item to Open \'Search for Open Files\' dialog'}
